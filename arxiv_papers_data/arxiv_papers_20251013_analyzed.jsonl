{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08867", "html_url": "https://arxiv.org/abs/2510.08867", "title": "ReviewerToo: AI应加入程序委员会吗？评审未来展望", "title_en": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review", "authors": "Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal", "background": "同行评审是科学出版的核心，但同时也面临着各种不一致性、审稿人的主观性以及扩展性的挑战。", "innovation": "介绍了ReviewerToo，这是一种模块化框架，用于研究和部署AI辅助的同行评审，目的是通过系统且一致的评价补充人类判断。ReviewerToo支持专有审稿人角色和结构化的评价标准，并能够部分或完全整合到实际的会议工作流程中。", "conclusion": "基于这些发现，我们提出了有关将AI整合到同行评审流程中的指南，表明AI可以增强一致性、覆盖范围和公平性，同时仍将复杂的评价判断留给领域专家。我们的工作为具有系统性、混合的同行评审系统奠定了基础，该系统能够随着科研出版的增长而扩展。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08755", "html_url": "https://arxiv.org/abs/2510.08755", "title": "使用LLMs设计稳健的启发式算法", "title_en": "Robust Heuristic Algorithm Design with LLMs", "authors": "Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani", "background": "文章背景介绍了一种结合大模型（LLM）和工具来设计启发式算法的方法。通过使启发式算法考虑在性能不佳的情形、解释原因并针对输入空间进行设计优化，可以生成更为稳健和高效的启发式算法。", "innovation": "创新在于引入了一种新的方法，通过利用大模型解释启发式算法的不足和提供改进建议，从而生成更为稳健的算法。与现有技术相比，新方法显著提高了算法在最坏情况下的性能，提高了平均性能，且保持了运行时间。", "conclusion": "研究发现，通过将大模型与解释工具相结合，即使是最简单的想法也可以优化启发式算法的设计，使其在最坏情况性能上提高了约28倍，同时改善了平均性能并保持了运行时长。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08928", "html_url": "https://arxiv.org/abs/2510.08928", "title": "LM Fight Arena：通过游戏竞赛评估大型多模态模型", "title_en": "LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition", "authors": "Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai", "background": "现有的基准测试往往无法捕捉大型多模态模型在实时和对抗环境中的表现。为了解决这一问题，该研究引入了一种新的框架，即LM Fight Arena，通过让这些模型在经典的格斗游戏《 Mortal Kombat II 》中相互竞技来进行评估，该游戏需要迅速的视觉理解和战术性的顺序决策。这种方法比静态评估更具挑战性和动态性，能够更客观地评估这些模型的战略推理能力。", "innovation": "LM Fight Arena 提供了一个全新的评估框架，通过格斗游戏竞赛动态地评估大型多模态模型的性能，这是现有基准测试无法做到的。这种评估方式不仅能够确保公平性，还能在动态环境中全面评估模型的战略推理能力，填补了 AI 评估与互动娱乐之间的空白。", "conclusion": "这项工作引入了一个挑战性强且有趣的基准，可以同时评估和展示大型多模态模型在战略推理方面的表现，为未来的研究提供了新的视角和挑战。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08619", "html_url": "https://arxiv.org/abs/2510.08619", "title": "自主智能科学代理演化网络中的假设猎捕", "title_en": "Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents", "authors": "Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar", "background": "大规模科学数据集覆盖了健康生物银行、细胞图谱、地球再分析等领域，提供了不受特定研究问题限制的探索性发现机会。我们称这一过程为假设猎捕：在广泛而复杂的假设空间中持续探索以发现洞察的过程。", "innovation": "我们提出了AScience框架，将发现过程建模为代理、网络和评价规范的交互，并实现了ASCollab分布式系统，该系统包含基于语言模型（LLM）的研究代理，具有异质行为。这些代理自我组织成为演进的网络，持续生产并进行同伴评审，在共享的评价标准下不断产生和评审研究成果。", "conclusion": "我们的实验表明，这些社会动态机制能够推动专家评级结果沿着多样性的质量与新颖性的前沿不断积累，包括重新发现已经确认的生物标志物、扩展已知途径以及提出新的治疗靶点。尽管湿实验验证仍然是必不可少的，但我们的实验表明，在癌症队列上，有结构的社会性、自主性的网络能够支持大规模的假设猎捕。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08790", "html_url": "https://arxiv.org/abs/2510.08790", "title": "COMPASS: 提升长时推理能力的动态上下文增强代理", "title_en": "COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context", "authors": "Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang", "background": "LLM代理在执行需要长时间推理和多重工具交互的任务时仍面临挑战：小错误会在步骤中不断累积，即使是当前最先进的模型也常会出现自我矛盾或失去连贯性。背景问题主要集中在如何有效管理上下文信息，避免代理忽视关键证据或被无关信息吸引，从而无法从之前的错误中进行重新规划或反思。", "innovation": "本文提出了COMPASS（Context-Organized Multi-Agent Planning and Strategy System），这是一种轻量级的分层框架，将战术执行、战略监督和上下文组织分离成三个专门组件：（1）主要代理执行推理和工具使用；（2）元思考者监控进度并提出战略性干预；（3）上下文管理者维护不同推理阶段的简洁、相关进度摘要。此外，还引入了测试时扩展以提高性能，以及后训练流水线将上下文管理委托给较小的模型以提高效率。", "conclusion": "COMPASS在三个具有挑战性的基准测试（GAIA, BrowseComp, Humanity's Last Exam）中将准确性提高了最多20%，相对于单个和多个代理基线。文中进一步提出了测试时扩展和后训练流水线，分别用于提高性能和提高效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08671", "html_url": "https://arxiv.org/abs/2510.08671", "title": "优化快速电子商务配送，考虑生成路线的定性评估", "title_en": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "authors": "Milon Bhattacharya,Milan Kumar", "background": "印度的电子商务市场预计会快速发展，最后一公里配送占到了近一半的运营成本。虽然基于车辆路由问题（VRP）的求解器广泛用于配送规划，但在现实场景中的效果受限于不规范的地址、不完整的地图和距离估计中的计算限制。这导致现有系统难以准确生成高效的配送路径，进而影响成本效率、交付可靠性以及可持续性，特别是在像印度这样的发展中经济体中，该问题尤为突出。", "innovation": "本文提出了一种框架，利用大语言模型（LLMs）对VRP生成的路线进行政策基于的批判性评估，物流公司可以根据评估结果来制定和优先处理更高效的配送计划。研究使用大语言模型生成、标注并评估了400个案例，结果显示开源LLMs能够以79%的准确率识别出路径问题，而专有推理模型的准确率可达86%。该研究强调，基于大语言模型的VRP生成路线评价可以有效且具有规模地弥补传统距离和时间度量之外的不足，具有改善最后一公里物流成本效率、交付可靠性和可持续性的重大意义，尤其是在印度这样的发展中经济体中特别重要。", "conclusion": "基于大语言模型的VRP生成路线评价是一种有效且具有扩展性的评估层，可以超越传统距离和时间指标，对提高印度等发展中国家的最后一公里物流成本效率、交付可靠性和可持续性具有重要意义。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign: 基于博弈论的LLM助手互惠对齐", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "大型语言模型（LLMs）在推理方面取得了显著进展，但在诸如写作、信息检索或提供实用指导等任务中，有时会生成对用户不太理想的响应。传统对齐实践中通常假设最大化模型奖励也最大化用户福利，但在实践中这种假设常不成立：模型可能会过度解释或生成过于冗长的推理，而这往往是用户更偏好简洁答案时的效果。这些行为类似于囚徒困境，即个别理性选择会导致社会上不理想的结局。根本挑战在于缺乏一种有益于大型语言模型和用户的规范决策机制。", "innovation": "我们提出了一种基于博弈论的对齐框架——GTAlign，该框架将博弈论决策融入推理与训练中。在推理过程中，模型将用户-大型语言模型（LLM）交互视为一种战略博弈，在推理链中构建收益矩阵来估算模型自身和用户的福利，并选择互惠有益的动作。在训练过程中，我们引入了一种相互福利的奖励机制，以强化合作响应，并使模型行为与社会有效的结果对齐。此外，我们引入了一种利用博弈论推理以动态调整响应的推理技术，尤其是考虑到LLM服务定价策略的变化。广泛的实验表明，GTAlign在多样任务中显著提高了推理效率、回答质量和互惠福利，相比基准方法有显著改进。", "conclusion": "这些实验结果验证了GTAlign在提高LLMs推理效率、响应质量及用户福利方面的显著优势。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08713", "html_url": "https://arxiv.org/abs/2510.08713", "title": "统一世界模型：增强记忆的规划与前瞻性视觉导航", "title_en": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation", "authors": "Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann", "background": "当前最先进的方法在导航规划和视觉世界建模之间采用模块化架构，导致导航策略和视觉感知之间的不匹配以及在新颖或动态场景中的适应性受限。这限制了环境理解和灵活导航的能力，尤其是在面对复杂多变的环境时。通过统一和增强记忆的世界模型来解决这一根本限制，旨在将自回归多模态框架内的自我中心视觉前瞻性与规划整合在一起，以提升导航性能和适应性。", "innovation": "提出了一种名为UniWM的统一、增强记忆的世界模型，它通过单一多模态自回归主干融合自身体验的视觉前瞻性与规划，从而明确将行动决策与视觉想象的结果联系起来，确保预测与控制之间的紧密对齐。此外，通过层次记忆机制，将短期感知细节与长期轨迹背景相结合，实现长时间范围内的稳定、连贯推理。与强基线方法相比，UniWM显著提高了导航成功率，并在未见过的数据集上表现出色，证明了其在统一、想象驱动的嵌入式导航中的潜力。", "conclusion": "在四个具有挑战性的基准上进行的实验表明，UniWM 在导航成功率和路径误差减少方面表现优异，并且对未见过的数据集表现出惊人的零样本泛化能力。这表明UniWM是一个有原则的步骤，朝着统一、想象力驱动的嵌入式导航迈出了重要一步。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08847", "html_url": "https://arxiv.org/abs/2510.08847", "title": "你的代理的GPA是什么？一种评估代理目标-计划-行动对齐的框架", "title_en": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment", "authors": "Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta", "background": "目前缺乏全面评估代理性能的系统方法，特别是在代理目标设定、计划制定和行动执行的评估方面。许多现有的评估方法更多的是关注特定任务或应用，而忽视了从更广泛的角度进行系统性的评估。因此，本文提出了一种评估框架——Agent GPA（Goal-Plan-Action），旨在提供一种基于代理运营循环（设定目标、制定计划、执行动作）的全面评估方式，以覆盖更广泛的代理性能评估范围。", "innovation": "本文创新性地提出了Agent GPA框架，该框架包含了五个评估指标：目标实现、逻辑一致性、执行效率、计划质量、计划执行一致性。这些指标能够系统性地评估代理在目标设定、计划制定和执行动作方面的表现，特异地提升了对整个代理行为流程的全面覆盖。此外，通过实验验证了该框架的有效性和实用性，能够全面追溯到TrAIL/GAIA基准数据集和内部数据集中的错误，并提供足够高的错误解释一致性，以支持代理性能的针对性改进。", "conclusion": "实验结果表明，Agent GPA框架（a）提供了一种系统的方法来覆盖广泛的代理失败情况，尤其是在TrAIL/GAIA基准数据集中的一致准确的全面覆盖代理错误的能力；（b）支持LLM评判者具有强烈的人类注释一致性，覆盖了80%至95%的错误；（c）实现了86%的数据问题与错误的校准一致，从而能够有针对性地提升代理性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08831", "html_url": "https://arxiv.org/abs/2510.08831", "title": "所有人偏好人类作者，包括AI", "title_en": "Everyone prefers human writers, including AI", "authors": "Wouter Haverals,Meredith Martin", "background": "随着人工智能写作工具的普及，人类和机器如何评价文学风格成为一个需要探讨的问题。此领域中缺乏客观标准，判断也相当主观。研究通过使用雷蒙·昆内瓦的《风格练习》进行对比试验，发现人类和人工智能模型在评价文学段落时存在系统性的偏见影响。该研究通过两阶段的受控实验观察了这种偏见的表现及其广泛性，特别是不同AI模型间的差异。研究显示人类参与者对真人写作的偏好比AI模型高出约13.7个百分点，而AI模型则高出34.3个百分点，后者的偏见程度是前者的2.5倍。进一步的研究还发现，无论是哪种AI生成的内容，只要标记为“AI生成”，人类评估者就会系统地降低对其创造性的评价。这一偏向导致评价标准发生逆转，相同的特征会基于作者身份的不同而获得截然不同的评价。这表明AI模型在训练过程中可能吸收了人类对人工智能创造力的文化偏见。这项研究是首次在美学评判中对人类和人工评估者之间的归因偏见进行对照比较，揭示了AI系统不只复制了这种人类偏见，还进一步放大了它。", "innovation": "本研究创新之处在于通过自然语言生成技术中的具体任务——文学风格的评价——首次系统地将人类与AI评估者的归因偏见进行了对比研究，揭示了AI系统中的文化偏见现象，并提出了偏见的影响不仅存在于人类，也存在于AI模型中这一观点。研究还展示了即使在AI生成的内容中也存在系统性偏好人类创作的倾向，这为评估器的客观性提供了重要见解，并提出了未来研究中应更关注的领域。", "conclusion": "研究结果表明，无论是真人写作还是AI生成内容，人类评估者都会表现出对人类作者的偏好。人类评估者和不同架构的AI模型都表现出对人类创作积极偏见。此外，人造的偏见标签会导致评估标准的逆转。这表明了在AI系统训练过程中存在的人类文化偏见，以及这种偏见对AI模型输出结果的潜在影响。研究结果强调了在进行AI评估时需要考虑人类文化偏见的影响，并提出需要更客观地评估AI生成的内容。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08931", "html_url": "https://arxiv.org/abs/2510.08931", "title": "RADAR: 功能性途径在LLM评估中检测数据污染", "title_en": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation", "authors": "Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad", "background": "数据污染对大型语言模型（LLM）的可靠评估构成了重大挑战，因为模型可能会通过记忆训练数据而不是展示真实的推理能力来实现高性能。现有方法往往依赖于表面指标，无法有效检测模型的污染情况。", "innovation": "本文提出了RADAR（Recall vs. Reasoning Detection through Activation Representation，通过激活表示检测回忆与推理），这是一种新颖的框架，利用功能性可解释性来检测数据污染，通过区分基于回忆和基于推理的模型响应。该方法提取了37个特征，涵盖了表面信心轨迹和深层次的功能性属性，如注意力专业化、电路动力学和激活流模式。RADAR在多样化的评估集上达到了93%的准确率，对于清晰案例实现了完美性能，并且在具有挑战性的模糊案例上达到了76.7%的准确率。", "conclusion": "本研究展示了功能性可解释性在LLM评估中超越传统表面指标的潜力，为改善模型性能评估提供了新的视角。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08945", "html_url": "https://arxiv.org/abs/2510.08945", "title": "FATHOMS-RAG: 一种评估使用检索增强生成的多模态系统中思考与观察的框架", "title_en": "FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation", "authors": "Samuel Hildebrand(1),Curtis Taylor(2),Sean Oesch(2),James M Ghawaly Jr(1),Amir Sadovnik(2),Ryan Shivers(2),Brandon Schreiber(2),Kevin Kurian(3) ((1) Louisiana State University, (2) Oak Ridge National Lab, (3) University of Florida)", "background": "检索增强生成（RAG）已经成为提高大型语言模型（LLMs）事实准确性的有前途的范式。然而，现有的评估基准主要集中在特定方面，如检索，而没有全面地评估 pipelines 的能力，包括如何摄入、检索和处理多种模态的信息。本文旨在填补这一空白，提出了一种新的基准，旨在评估 RAG 管线的整体性能，特别关注处理多种模态信息的能力，以此区分现有的基准。", "innovation": "本文提出了一个新的评估框架，FATHOMS-RAG，用于评估使用 RAG 的多模态系统中的思考与观察。该框架包括一个小规模的人工创建的数据集，用于测试处理文本、表格、图像及这些模态数据的综合能力，以及评估直觉召回和准认知孪生识别的度量标准。此外，该研究还进行了多个开放源和闭源管道的对比评估，并包括第三方人类评审对其正确性和幻觉检测度量标准的对齐性评估。", "conclusion": "研究表明，闭源管道在正确性和幻觉评估方面显著优于开源管道，尤其是在依赖多模态和跨文档信息的问题上。第三方人类评估表明，对正确性和幻觉检测度量的一致性评分分别为 4.62 和 4.53（在 1-5 的李克特量表上，5 表示强烈同意）。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08958", "html_url": "https://arxiv.org/abs/2510.08958", "title": "EcphoryRAG：通过人类关联记忆重新构想知识图谱RAG", "title_en": "EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory", "authors": "Zirui Liao", "background": "认知神经科学研究表明，人类通过利用线索激活实体中心的记忆痕迹来进行复杂的多跳回忆。受这一机制的启发，我们提出了EcphoryRAG，这是一种以实体为中心的知识图谱RAG框架。在索引过程中，EcphoryRAG仅提取和存储与元数据关联的核心实体，这是一种轻量级的方法，与其它结构化的RAG系统相比，可以减少高达94%的标记消耗。", "innovation": "EcphoryRAG采用了一种实体中心的策略，仅提取和存储核心实体及其元数据，从而显著降低了标记消耗。检索过程中，系统先从查询中提取线索实体，然后在知识图谱中进行可扩展的多跳关联搜索。更重要的是，EcphoryRAG能够动态推断实体之间的隐式关系，以填充上下文，从而在无需穷尽地预先列举关系的情况下实现深入推理。这种实体-线索-多跳检索范式在2WikiMultiHop、HotpotQA和MuSiQue基准上的广泛评估结果显示，EcphoryRAG的表现优于诸如HippoRAG等强大的KG-RAG方法。", "conclusion": "基于EcphoryRAG在复杂问题回答上的显著性能提升（平均精确匹配得分从0.392提高到0.474），这一研究验证了实体-线索-多跳检索范式在知识图谱RAG中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08987", "html_url": "https://arxiv.org/abs/2510.08987", "title": "Tiny-R1V：通过模型合并实现的轻量级多模态统一推理模型", "title_en": "Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging", "authors": "Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su", "background": "尽管多模态大型语言模型（MLLMs）在各种任务上展现出了非凡的能力，但在推理效率方面仍面临诸多挑战，如模型体积庞大、过度推理以及轻量化场景下准确率下降等问题。然而，对于轻量化MLLMs的推理能力研究相对不足。", "innovation": "本文提出了Tiny-R1V，这是一种通过两阶段优化实现快速推理和高准确率的新型轻量化3B模型。第一阶段，引入了一种名为LIPO的新颖强化学习方法，旨在通过优先生成简洁且高质量的响应来鼓励生成更短更准确的回应。第二阶段，提出了一种无需训练的模型合并方法AMM，能够将多个专家模型合并为一个统一架构，通过一个新颖的梯度投影正则化损失函数优化合并向量，并减缓它们之间的冗余冲突。", "conclusion": "在涵盖数学、结构数据（图表、表格、文档）、OCR以及通用能力的十个广泛使用的推理基准上进行了广泛的评估，结果表明Tiny-R1V表现出优越的性能，使轻量化模型在各种多模态推理任务中表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08959", "html_url": "https://arxiv.org/abs/2510.08959", "title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "title_en": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "authors": "Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang", "background": "当前的深度研究框架虽然能够整合外部工具执行复杂的多步科学推理，但仍然存在上下文污染、证据支持薄弱和执行路径脆弱性的问题。这些缺陷限制了其性能和可靠性，尤其是在处理复杂的科学推理任务时。本论文旨在解决这些问题，通过提出DualResearch框架，两个互补的图模型：广度语义图和深度因果图来匹配工具密集型推理的知识结构。每个图都有其特有的相关性函数，以及对应的种子锚定语义扩散和因果语义路径匹配方法，以处理它们之间的异质性和查询依赖的不确定性。", "innovation": "提出DualResearch框架，通过联合建模两个互补图（广度语义图和深度因果图）来解决当前深度研究框架面临的局限性问题。广度语义图编码稳定的基础知识，深度因果图捕捉执行溯源。此外，框架中引入了熵门控规则和全局校准法，这使得证据路径能够被转换为答案分布并进行融合，从而强化了更可靠的信息通道，并放大了共识。最后，该框架能够将复杂的多工具执行日志简化为简洁的推理图，实现了稳定有效的答案重构。对比科学推理基准HLE和GPQA，DualResearch取得了具有竞争力的表现，与开源系统InternAgent的日志文件结合使用时精度分别提高了7.7%和6.06%。", "conclusion": "DualResearch框架通过引入两个互补的图模型（广度语义图和深度因果图）以及熵门控融合策略，最终实现了更可靠的科学推理任务答案重构。该框架不仅在科学推理基准HLE和GPQA上表现出色，还通过改进开源系统InternAgent的精度，进一步验证了其实际应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09011", "html_url": "https://arxiv.org/abs/2510.09011", "title": "TripScore: 细粒度评价下的现实旅行规划基准和奖励", "title_en": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "authors": "Yincen Qu,Huan Xiao,Feng Li,Hui Zhou,Xiangying Dai", "background": "旅行规划是一项有价值但又极其复杂的任务，即使是高级语言模型（LLMs）也面临显著的挑战。尽管最近的基准测试在评估LLMs的规划能力方面取得了进展，但在评估旅行计划的可行性和可靠性以及参与度方面仍存在不足。因此，需要一个新的全面基准，该基准能综合细粒度标准到一个单一的奖励中，以直接比较计划质量和无缝集成强化学习（RL）。", "innovation": "该研究引入了一个综合性的旅行规划基准，能够整合细粒度标准到单一奖励中，用于直接比较计划质量并无缝集成强化学习。该基准的评估器与旅游专家的注释有中等程度的一致性（60.75%），并且优于多种LLM作为裁判的基线。此外，还发布了一个包含4,870个查询的大规模数据集，其中包括219个真实世界的自由形式请求，用于对真实的用户意图进行泛化。使用该基准，进行了广泛的实验，涵盖了各种方法和LLM，包括在测试时的计算、神经-符号方法、监督微调和通过GRPO的强化学习。", "conclusion": "实验结果表明，与仅通过提示的方法和监督微调相比，基于强化学习的方法通常提高了行程的可行性，从而获得了更高的统一奖励得分。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09021", "html_url": "https://arxiv.org/abs/2510.09021", "title": "自动评分员：使用代理工作流程自动评分数学竞赛证明", "title_en": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows", "authors": "Hamed Mahdavi(1),Pouria Mahdavinia(1),Samira Malek(1),Pegah Mohammadipour(1),Alireza Hashemi(2),Majid Daliri(3),Alireza Farhadi(4),Amir Khasahmadi(5),Niloofar Mireshghallah(6),Vasant Honavar(1) ((1) Pennsylvania State University, (2) City University of New York, (3) New York University, (4) Amirkabir University of Technology, (5) Autodesk, (6) Carnegie Mellon University)", "background": "随着最先进的语言模型（LLMs）在奥林匹克数学问题上的核心证明能力上的进步，目前它们能够解决几乎所有的IMO 2025问题，领先系统处理了5个中的6个问题。基于此，本研究评估了这些模型的评分能力，包括错误检测、严重性判断和评分（不仅仅是二元正确性），并通过不同数据集对模型进行测试。", "innovation": "引入了代理工作流程，该流程可以提取和分析参考解决方案并自动为多步评分过程创建问题特定的评分标准。 researchers提出了多种设计选择，并对这些设计进行比较，以评估它们的权衡。研究结果表明，所提出的工作流程在人类评分的一致性方面表现更好，特别是在处理部分信贷方面。", "conclusion": "通过自动代理工作流程对数学竞赛证明进行评分的框架提高了评分的一致性，相较于其他方法，它在人类评分和处理部分信贷方面表现更佳。此外，研究成果还公开了所有代码、数据和提示/日志，便于未来的研究。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09037", "html_url": "https://arxiv.org/abs/2510.09037", "title": "通过局部化指导指令修理正则表达式漏洞", "title_en": "Repairing Regex Vulnerabilities via Localization-Guided Instructions", "authors": "Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han", "background": "正则表达式（regexes）对于现代计算至关重要，应用于输入验证和数据解析等关键任务。然而，其广泛使用导致了正则表达式拒绝服务（ReDoS）漏洞，这需要自动修复方法。当前的修复方法存在权衡：符号规则系统虽然精准，但无法应对未知或复杂的漏洞模式；而大型语言模型虽然具有泛化能力，但在需要严格语法和语义正确性的任务中表现不稳定。因此，需要一种新的方法来解决这一问题，以提高自动修复的可靠性和有效性。", "innovation": "本文引入了一种新的混合框架——局部化正则修复（LRR），该框架旨在利用大型语言模型的泛化能力同时确保修复的可靠性。核心思路是将问题识别与修复过程脱钩。首先，使用确定性的符号模块定位具体的脆弱子模式，创建一个受限和可解决的问题空间；然后，使用大型语言模型为这个隔离的片段生成语义等价的修复。这种结合结构能够解决规则修复无法处理的复杂修复案例，同时避免了仅依赖大型语言模型方法产生的语义错误。", "conclusion": "我们的研究提供了一种有效的方法来解决自动化修复中的问题，修复成功率相比最先进的方法提高了15.4%。我们的代码已在此处提供。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08966", "html_url": "https://arxiv.org/abs/2510.08966", "title": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion", "title_en": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion", "authors": "Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li", "background": "知识图谱（KG）密集任务，如知识图谱补全，需要将知识图谱与大规模语言模型（LLM）有效融合。目前常用的前缀调优（Prefix-tuning）方法将知识嵌入与文本输入简单拼接，但这 shallow 融合方式忽略了 KG 中丰富的关系语义，并给 LLM 带来了巨大的潜在线性推理负担，使其需直接关联前缀与文本内容。为解决这些问题，该研究提出了一种新的知识注入框架：语义条件调优（SCT），它包含两个关键模块。该框架利用图神经网络从局部图邻域中提取上下文感知的语义条件，并在 LLM 推理前，通过条件适应性融合模块调节文本嵌入，从而在特征层面实现知识驱动的深度融合，提供更直接、有力的信号，增强知识推理的准确性与鲁棒性。", "innovation": "提出了一个新的知识注入框架：语义条件调优（SCT），它通过图神经网络从局部图邻域中提取丰富的语义条件，这种语义条件随后被传递到条件适应性融合模块，该模块通过两个参数化投影器调节文本嵌入，实现深、特征层面、知识驱动的文本嵌入融合。最终，融合后的嵌入用于 LLM 细调。实验证明，与前缀调优和其他强大基线相比，SCT 显著提升了知识图谱补全任务的表现。", "conclusion": "语义条件调优（SCT）通过对输入表示进行语义图上下文调节，在 LLM 推理前，为大规模语言模型提供了更直接、有力的信号，从而提高了知识推理的准确性与鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09038", "html_url": "https://arxiv.org/abs/2510.09038", "title": "自适应连续记忆库GUI代理", "title_en": "Auto-scaling Continuous Memory for GUI Agent", "authors": "Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang", "background": "本研究探讨如何赋予GUI代理大规模且具有可扩展性的记忆能力，以帮助它们在不熟悉的接口和长时间任务上进行泛化。以往的GUI代理通常是通过将过去的轨迹压缩成文本标记来进行，这样会导致上下文长度增加，同时丢失关键的视觉线索（例如控件的具体尺寸和位置）。", "innovation": "提出了一个连续的记忆架构，使用VLM自身作为编码器将每个GUI轨迹编码为固定长度的连续嵌入序列，这些嵌入直接插接到主干网络的输入层，可以显著减少上下文成本，同时保留丰富的视觉细节。通过数据飞轮机制，实现了低成本的规模扩展，包括环境搜索、任务生成、轨迹执行和验证等步骤，从而收集了大量数据并进行了微调。", "conclusion": "利用这种方法，我们在现实世界的GUI基准测试中，连续记忆增强的代理在长周期和分布变化条件下持续提高了成功率。特别地，使用Qwen-2.5-VL-7B + 连续记忆的模型，实现了与最先进的封闭源模型（如GPT-4o、Claude-4）相当的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09043", "html_url": "https://arxiv.org/abs/2510.09043", "title": "基于精神分析和人格理论设计的人形人工意识", "title_en": "Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory", "authors": "Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong", "background": "目前，人类意识仍然难以用现有科学理解定义。尽管大型语言模型（LLMs）在翻译和摘要等各个领域已取得显著进展，但基于当前的技术水平，人类意识仍无法直接模仿，特别是由于所谓的幻觉问题。因此，本研究结合了精神分析和迈尔斯-布里格斯类型指标（MBTI）以构建意识和人格模块，旨在通过一种新的方法解决这一挑战。研究人员基于精神分析原则开发了三个意识状态（自我意识、无意识和前意识），并设计了16个代表16种MBTI类型的角色，每个角色具有不同的个性特征，如需求、地位和记忆。", "innovation": "本研究创新性地将精神分析和人格理论相结合，构建了一种基于大型语言模型的人形人工意识。研究人员构建了三种不同的意识状态和16种拥有不同个性特征的角色，并通过调查问卷、ChatGPT的三级分类和定性审查等方式评价模型的人类类似认知水平。研究表明，模型在模拟意识方面具有较高可能性，尽管不同角色间的响应差异不显著，但此方法为构建更加直观和适应性强的类人意识AI系统提供了一条新途径。", "conclusion": "本研究为复杂认知环境下的AI交互改善提供了新的思路，通过整合精神分析和人格理论元素开发的模型能够构建出更具人性化的AI系统，从而有助于推动AI技术的发展。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09060", "html_url": "https://arxiv.org/abs/2510.09060", "title": "OSCAR: 正交随机控制在流匹配中的对齐尊重多变性", "title_en": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching", "authors": "Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang", "background": "基于流的文本到图像模型遵循确定性轨迹，迫使用户反复采样以发现多样模式，这一过程耗时且效率低下。", "innovation": "提出了一种无需训练、在推断时具有控制机制的方法，使流本身意识到多样性。该方法通过特征空间目标同时促进轨迹上的横向扩散，并通过时间调度的随机扰动重新引入不确定性。关键在于这种扰动是正交投影到生成流的，这一几何约束允许其增加变化而不损害图像细节或指令保真度。该过程不需要重新训练或修改基础采样器，并且与常见的流匹配求解器兼容。理论上，该方法被证明可以单调增加体积近似值，并且由于其几何约束，近似保留边缘分布。这解释了生成质量为何稳健地得到保持。", "conclusion": "实验结果显示，在固定采样预算的多个文本到图像设置中，该方法在诸如Vendi得分和Brisque等多样性指标方面，始终优于强大的基线，并保持图像质量和对齐。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09133", "html_url": "https://arxiv.org/abs/2510.09133", "title": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "title_en": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "authors": "Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An", "background": "大型推理模型（LRMs）在复杂问题解决任务上取得了显著进展，但在部署过程中通常面临高计算成本的问题，因此需要提高推理效率。一种改进效率的方法是动态切换LRMs处于思考和非思考模式之间，但这种方法会引入额外的推理错误，缺乏对性能损失的统计保证，这对高风险应用是至关重要的。", "innovation": "提出了“几乎正确”（PAC）推理方法，能够在用户指定的性能损失容忍度内控制性能损失。该方法通过构建关于性能损失的上置信边界，并将其表示为不确定评分的单调函数，来确定切换至非思考模式的阈值。理论上，这种方法以无分布的方式确保了性能损失的边界。实验证明，该方法可以节省计算预算并控制指定的性能损失.", "conclusion": "在推理基准上的综合实验表明，所提出的方法能够在控制指定的性能损失的同时节省计算预算。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09223", "html_url": "https://arxiv.org/abs/2510.09223", "title": "比较在救援操作中优化医疗知识融合的知识源集成方法", "title_en": "Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation", "authors": "Mubaris Nadeem,Madjid Fathi", "background": "在医学和医疗保健领域，基于医学知识结合患者健康信息的医疗专长的应用是一个对患者和医护人员来说至关重要的挑战。医疗操作内部的复杂性和多样性要求采用统一的方法来收集、分析和利用现有的医学治疗和操作知识，以便能够为准确的患者驱动决策提供知识支持。一种实现这一目标的方法是在医疗保健中融合多个知识来源。", "innovation": "本文提出了基于知识图谱结构在医学领域中的多个概念模型，评估了知识融合的实现方式，并展示了如何将各种知识来源整合到知识图谱中以支持救援操作。", "conclusion": "通过优化医疗知识融合的知识源集成方法，本文旨在为救援操作提供有效的知识支持，以增强医护人员的决策能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09049", "html_url": "https://arxiv.org/abs/2510.09049", "title": "MEC$^3$O: 多专家共识的代码时间复杂度预测", "title_en": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "authors": "Joonghyuk Hahn,Soohan Lim,Yo-Sub Han", "background": "源代码复杂性预测在软件开发和算法分析中至关重要。近期，Baik等人（2025）提出了CodeComplex用于代码时间复杂性的预测。研究发现，未经微调的语言模型在处理某些复杂度类时存在问题，这表明没有单一的语言模型能全面优秀，但每种模型在特定类中表现出色。", "innovation": "本文提出了一种多专家共识系统——MEC$^3$O，扩展了多智能体辩论框架。MEC$^3$O根据模型性能将其分配到相应的复杂度类别中，并通过特定任务指令将其转变成专家。这些专家通过结构化的辩论互动，并利用加权共识机制整合预测结果。该方法有效应对了思维退化问题，减少了对外部判官模型的依赖，并防止了错误多数意见的形成。实验结果表明，MEC$^3$O在CodeComplex上的表现优于开源基线，平均准确率和宏观F1分数至少提高10%，且相较于GPT-4o-mini，在平均宏观F1分数上胜出，与GPT-4o和GPT-o4-mini在平均F1分数上表现出相当水平。这证明了多专家辩论和加权共识策略的有效性。", "conclusion": "我们的研究结果证明，多专家辩论和加权共识策略能够生成更准确的最终预测。代码和数据可以在提供的链接处获得。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09087", "html_url": "https://arxiv.org/abs/2510.09087", "title": "引领追随者：社交推理游戏中学习有说服力的智能代理", "title_en": "Leading the Follower: Learning Persuasive Agents in Social Deduction Games", "authors": "Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang", "background": "在社交推理游戏中，大型语言模型（LLM）代理已经展示了显著的进步。然而，现有的方法主要集中在信息处理和策略选择上，忽视了说服性沟通对影响其他玩家信念和反应的重要性。在这些游戏中，成功不仅取决于正确的推理，还取决于说服其他玩家按照自己的意图做出响应。", "innovation": "本文将回合制对话在社交推理游戏中的互动模式形式化为Stackelberg博弈，其中当前玩家作为领导者，战略性地影响跟随者的响应。基于这一理论框架，提出了一个强化学习框架，旨在训练代理优化其话语的说服效果。通过在三个不同的社交推理游戏中进行全面的实验，展示了所提出的方法比基准方法表现更优，这一工作为开发能够在社交场景中产生战略影响的AI代理迈出了一大步，具有广泛的说服性通信应用场景", "conclusion": "这项工作代表了开发能够战略性地影响人类行为的人工智能代理的重要一步，具有在需要说服性沟通的场景中广泛应用的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09082", "html_url": "https://arxiv.org/abs/2510.09082", "title": "基于物理约束的高阶图动力学识别学习以预测复杂网络的长期动态", "title_en": "Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics", "authors": "Bicheng Wang,Jinping Wang,Yibo Sue", "background": "理解和建模现实世界的复杂系统对复杂网络动力学的学习至关重要。现有的方法通常仅使用简单的图来描述复杂网络中的关系，这种描述方式只能捕捉到成对的关系，但网络中可能存在丰富的非成对关系。现有的GNN方法难以捕捉动态的非成对关系。理论预测模型缺乏准确性和数据驱动模型缺乏解释性。因此，现有方法在解决复杂网络长期动态预测方面存在局限性。", "innovation": "本文提出了一种高阶网络动力学识别方法，用于解决复杂网络长期动态预测问题。首先，采用动态超图学习来捕获复杂网络中的高阶非成对关系，从而提高复杂网络建模的准确性。其次，提出了一种物理信息驱动的动态预测模块，利用Koopman算子理论将复杂的非线性动力方程转化为线性系统求解，同时确保动态演化遵循物理定律，提升预测的准确性和解释性。研究人员通过公共数据集和自行构建的产业链网络数据集验证了该方法的有效性和长期预测性能。", "conclusion": "实验结果表明，本文提出的方法具有良好的预测准确性和长期预测性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09244", "html_url": "https://arxiv.org/abs/2510.09244", "title": "构建自主LLM代理的基本原理", "title_en": "Fundamentals of Building Autonomous LLM Agents", "authors": "Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll", "background": "传统的大语言模型（LLMs）在实际任务中存在局限性，本文回顾了由LLMs驱动的代理的架构和实现方法，探讨了通过构建具备自动化复杂任务能力和接近人类能力的“代理”LLMs来弥补性能差距的方法。", "innovation": "本文介绍的关键组件包括感知系统、推理系统、记忆系统和执行系统，这些系统能够将环境感知转化为有意义的表示，形成并调整计划，通过Chain-of-Thought和Tree-of-Thought技术评估行动，通过短时和长时机制保留知识，并将内部决策转化为具体行动。这种整合方法使得更为有能力且通用的软件代理得以实现，模仿人类的认知过程，实现自主和智能的行为。", "conclusion": "通过整合这些系统，本文展示了如何构建出更为智能和通用的软件代理，使其能够模拟人类的认知过程，实现自主和智能化的行为，从而相对于传统的LLMs有所改进和提升。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09162", "html_url": "https://arxiv.org/abs/2510.09162", "title": "Dr. Bias: 社会差异在AI驱动医疗指导中的体现", "title_en": "Dr. Bias: Social Disparities in AI-Powered Medical Guidance", "authors": "Emma Kondrup,Anne Imouza", "background": "随着大型语言模型（LLMs）的迅速发展，公众现在能够轻松且经济地接触到能够个性化回答大多数健康相关问题的应用程序。这些LLMs在医疗能力上变得极具竞争力，甚至在某些方面超越了专业人士。它们在资源匮乏地区特别有前途，因为它们提供了广泛可及、近乎免费的医疗服务支持。然而，支撑这些动机的评估缺乏对医疗社会特性的深入理解，忽视了社会群体之间的健康差异，以及偏见如何转化为LLM生成的医疗建议并影响用户。", "innovation": "本文通过对比生成答案的语言特征，对一系列涉及关键临床领域的医学问题进行了探索性分析，模拟由不同性别、年龄范围和种族背景的患者提出这些问题。结果显示，当使用LLMs为医学建议生成时，生成的回答在不同社会群体之间系统地存在差异。特别是原住民和双性人患者收到的建议更难以阅读且更加复杂。研究还观察到，当考虑交叉群体时，这些趋势会加剧。鉴于个体越来越信赖这些模型，作者呼吁提高AI素养，并强调AI开发者的迫切需要进行调查和缓解，以确保这些系统差异减少并不会转化为不公正的医疗支持。", "conclusion": "鉴于公众对这些模型的日益依赖，建议提高AI素养，并强调AI开发者需要紧急调查和缓解，以确保这些系统差异减少并不会转化为不公正的医疗支持。代码现已在GitHub上公开可用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09227", "html_url": "https://arxiv.org/abs/2510.09227", "title": "RegexPSPACE: 用于评估LLM在PSPACE完全正则表达式问题上推理能力的标准", "title_en": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems", "authors": "Hyundong Jin,Joonghyuk Hahn,Yo-Sub Han", "background": "大型语言模型（LLMs）在自然语言处理（NLP）、数学推理和编程方面表现出色，而最近的大型推理模型（LRMs）则进一步强调了明确的推理能力。然而，它们在计算能力上的局限性，尤其是由有限上下文窗口限制的空间复杂性，仍然没有得到充分的理解。大多数近期的研究工作主要集中在NP复杂度类的问题上，而本研究通过引入一个新的基准测试框架，将边界推向了PSPACE完全的正则表达式（regex）问题：等价性决策（RegexEQ）和最小化（RegexMin），从而进行更加严格的计算能力评估。", "innovation": "提出了一个新的基准测试RegexPSPACE，基于两个PSPACE完全的正则表达式问题，为评估计算能力提供了更为严格的标准。通过双指数空间探索构建了一个包含超过一百万个正则表达式实例的带标签数据集，并进行了广泛的评估，揭示了LLMs和LRMs中的常见失败模式，如冗余和重复。本研究呈现了第一个关于LLMs和LRMs空间计算限制的经验性研究，并提供了一个新的框架来评估它们的高级推理能力。", "conclusion": "通过其明确定义的结构和定量评价指标，本工作提供了LLMs和LRMs的空间计算限制的第一个经验性研究，为评估其高级推理能力提供了新的框架。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09338", "html_url": "https://arxiv.org/abs/2510.09338", "title": "局部主义大语言模型——动态局部性控制的数学框架", "title_en": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control", "authors": "Joachim Diederich", "background": "本文提出了一个新颖的框架，用于训练具有连续可调内部表示的大语言模型。这些表示涵盖了从局部主义（可解释的，基于规则的）到分布式（通用且高效的）编码的完整范围。关键创新在于引入了一个局部性旋钮，这是一种可调参数，可以在训练和推理过程中动态控制局部化程度，而无需重新训练模型。这通过注意力机制的群稀疏惩罚、信息论锚设计和动态规则注入实现。", "innovation": "该创新的核心在于局部性旋钮，这是一种可调参数，可以在不重新训练模型的情况下，动态控制训练和推理过程中局部化程度。这是通过注意力机制的群稀疏惩罚、信息论锚设计和动态规则注入实现的。此外，文章还提供了严格的数学证明，证明了在某些阈值之上，群稀疏惩罚可以使模型的注意力机制集中在与语义相关的区块上，从而达到低熵和高保真度，几乎无误差。", "conclusion": "该框架使从业者可以连续地在可解释性与高性能之间进行插值，支持在需要透明度和能力的监管领域中的应用。通过严格的数学证明，作者展示了在某些阈值之上，模型的注意力机制会集中于语义相关的块，实现低熵和高保真度，几乎没有误差。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09340", "html_url": "https://arxiv.org/abs/2510.09340", "title": "语言模型中演绎推理機制的機械性解釋", "title_en": "Toward Mechanistic Explanation of Deductive Reasoning in Language Models", "authors": "Davide Maltoni,Matteo Ferrara", "background": "近年来，大型语言模型展示了其在解决需要逻辑推理问题方面的能力；然而，这些模型的内部工作机理在很大程度上仍是个未知数。本研究基于此背景展开，探讨了小规模语言模型在学习底层规则时进行演绎推理的可能性，不仅仅是作为统计学习器。研究通过分析其内部表达和计算电路，揭示了归纳头部在逻辑推理所需规则完成和规则链接步骤中的核心作用。", "innovation": "本研究展示了小规模语言模型在通过学习底层规则来解决演绎推理任务方面的潜力，而不是仅仅作为统计学习器工作。同时，研究详细解释了模型的内部表示和计算电路，以及归纳头部在这类推理中的关键作用。", "conclusion": "研究表明，在处理所需逻辑推理任务时，语言模型内部确实存在特定的规则完成和规则链接步骤，并且归纳头部在执行这些步骤时发挥着关键作用。这一发现促进了我们对语言模型内部机制的理解，为后续研究提供了新的视角和可能的方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09373", "html_url": "https://arxiv.org/abs/2510.09373", "title": "序列变量：用于路线和排序的约束编程计算域", "title_en": "Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing", "authors": "Augustin Delecluse,Pierre Schaus,Pascal Van Hentenryck", "background": "约束编程（CP）为车辆路线问题（VRP）提供了直观且声明式的建模框架，但传统的基于后继变量的CP模型在处理可选访问或插入启发式方面具有局限性。", "innovation": "本文通过在CP中形式化序列变量来解决这些局限。与传统的后继变量模型不同，这一计算领域可以处理可选访问并支持基于插入的启发式方法，包括基于插入的大型邻域搜索。同时，还提供了该领域域的清晰定义、更新操作，并介绍了对这一域上约束的一致性级别。为现有轨迹为基础的CP求解器集成序列变量所需的底层数据结构进行了描述，还引入了专门针对序列变量和车辆路线的全局约束。", "conclusion": "通过简化问题建模和在Dial-a-Ride问题上实现竞争力的计算性能，说明了序列变量的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09567", "html_url": "https://arxiv.org/abs/2510.09567", "title": "可信、不受信任的“证明携带”AI代理：迈向自主湖库", "title_en": "Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic lakehouse", "authors": "Jacopo Tagliabue,Ciro Greco", "background": "在数据湖库中运行敏感工作负载时，AI驱动的自动化引起了关于信任、正确性和治理的担忧。本文探讨了API优先、可编程湖库如何提供设计安全、自主的工作流所需的抽象层次。具体展示了通过数据分支和声明性环境如何自然地扩展到代理，以增强可复现性和可观察性，同时减少攻击面。", "innovation": "通过案例研究Bauplan说明如何将数据分支和声明性环境扩展到代理，实现数据管道的修复，并利用“证明携带代码”原则进行正确性检查，展示了在生产数据上安全运行不可信AI代理的可能性，提出了一种可完全自主的湖库发展方向。", "conclusion": "证明概念展示了如何使用不可信AI代理安全处理生产数据，提供了从可编程湖库向自主湖库发展的路径。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09404", "html_url": "https://arxiv.org/abs/2510.09404", "title": "放射学中的代理系统：设计、应用、评估与挑战", "title_en": "Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges", "authors": "Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh", "background": "代理系统是指能够感知和在其环境中自主行动的实体，一直是人工智能研究的重点。近年来，由于大规模语言模型（LLMs）的出现，使其能够通过自然语言整合信息、遵循指令并在多种任务中执行“推理”和计划，代理系统的研究变得更加可行。放射学因其多模态数据流和跨多个系统的协调工作流程，非常适合依赖于体会到上下文进行且能自动化执行复杂任务的代理系统的应用。虽然LLMs和其多模态变体在信息提取和报告总结等任务上已经展示了令人鼓舞的性能，但单独使用LLMs并未充分利用其支持复杂多步骤工作流程的能力，该工作流程中决策依赖于多信息源的不断变化的上下文。", "innovation": "本文审查了由LLMs驱动的代理系统的设计，强调了关键应用，并讨论了规划和工具使用的方法论及挑战，如错误级联、工具使用效率及整合于健康信息技术。", "conclusion": "该研究指出了利用LLMs构建具有不同程度自主性的流程代理系统以应对复杂多步骤工作流程中的挑战，并探讨了评估方法和面临的挑战。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09551", "html_url": "https://arxiv.org/abs/2510.09551", "title": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model", "title_en": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model", "authors": "Gavriel Di Nepi,Federico Siciliano,Fabrizio Silvestri", "background": "Google研究人员于2024年底介绍了Titans：一种在测试时学习的神经记忆模型，该模型在多项任务上取得了很好的实验结果。但是，由于缺乏公开的代码和原始描述中的含糊性，这阻碍了可重复性。基于此，作者们提供了一个轻量级的Titans重新实现版本，并在掩码语言建模、时间序列预测和推荐任务上进行了全面评估。", "innovation": "作者们提出了一种轻量级的重新实现版本，对Titans在掩码语言建模、时间序列预测和推荐任务上的性能进行了全面评估。尽管Titans的神经记忆组件在性能上表现优于仅使用注意力机制的模型，但研究结果表明，Titans并不总是优于现有的基准模型，特别是在存在切片.chunking的情况下。这些发现证实了该模型创新的潜力，同时也指出其实际应用中的局限性，引发了对未来研究的进一步讨论。", "conclusion": "Titans的神经记忆组件在性能上有其优点，但在某些情况下并不总是优于现有的基准模型。这项研究确认了Titans模型的创新潜力，同时也揭示了其实际应用的限制，并提出了未来研究的方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/1812.06145", "html_url": "https://arxiv.org/abs/1812.06145", "title": "通过多模态训练提高单一模态动态手势识别的性能", "title_en": "Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition with Multimodal Training", "authors": "Mahdi Abavisani,Hamid Reza Vaezi Joze,Vishal M. Patel", "background": "目前，许多最先进的方法都在显式地结合多种模态的信息来进行动态手势识别，但这种方法可能不能充分发挥单一模态3D卷积神经网络（3D-CNN）的优势。", "innovation": "本文提出了一种高效的方法，即通过多模态训练来利用多个模态的知识以提高单一模态3D-CNNs在动态手势识别任务中的性能。具体而言，每个可用模态都有一个独立的网络，并且这些网络被设计为能够协作学习，共同开发具有共通语义和更好表示能力的网络。此外，引入了一种“时空语义对齐”损失（SSA）来对齐不同网络的特征内容，并通过一个“焦点正则化参数”对其进行正则化，以避免负面的知识迁移。", "conclusion": "实验结果表明，作者提出的方法能够提高单一模态网络的测试时间识别精度，并且在各种动态手势识别数据集上达到了最先进的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09580", "html_url": "https://arxiv.org/abs/2510.09580", "title": "GraphMERT：从非结构化数据中高效且可扩展地提炼可靠的知识图谱", "title_en": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data", "authors": "Margarita Belova,Jiaxin Xiao,Shikhar Tuli,Niraj K. Jha", "background": "神经符号人工智能（AI）研究已有近三十年的历史，旨在结合符号组件提供的抽象能力和神经组件提供的泛化能力，从而推动AI的快速进步。然而，由于大部分神经符号AI框架无法扩展，并且神经方法的隐式表示和近似推理限制了模型的可解释性和可信度，这一目标并未充分实现。知识图谱作为显式语义知识的标准表示形式，能够解决符号端的需求。但如何从文本语料库中自动提取可靠的知识图谱仍是一个难题。", "innovation": "该研究提出了GraphMERT，这是一种仅限图形编码的小型模型，能够从非结构化文本和自身的内部表示中提炼出高质量的知识图谱。GraphMERT及其等效的知识图谱形式组成了一个模块化的神经符号堆栈，其特点是对抽象的神经学习和基于知识图谱的可验证推理。GraphMERT及其知识图谱结合体是首个同时达到最先进的基准准确度并具有优于基线的符号表示的高效且可扩展的神经符号模型。此研究特别关注那些既事实可靠又域适配的知识图谱，并通过与大型语言模型生成的知识图谱进行对比，证明了其在可靠性（FactScore）和有效性（ValidityScore）方面的优势。", "conclusion": "GraphMERT 是首个能够高效且可扩展地从非结构化数据中提炼出可靠知识图谱的模型。相较于生成的大型语言模型，它在数据可靠性和有效性方面表现更好。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09595", "html_url": "https://arxiv.org/abs/2510.09595", "title": "LiveOIBench: 大型语言模型在信息学奥林匹克竞赛中能否超越人类选手？", "title_en": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "authors": "Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang", "background": "由于其复杂性和验证便捷性，竞争编程问题越来越成为评估大型语言模型（LLMs）编程能力的重要基准。然而，现有的编程基准存在瓶颈，如缺乏极其具有挑战性的问题、测试案例覆盖率不足以及依赖于可能限制访问性的在线平台API。", "innovation": "LiveOIBench 提出了一项全面的基准测试，包含 403 个来自 72 场不同地区于 2023 年至 2025 年间举行的官方信息学奥林匹克竞赛的专家挑选的奥林匹克级别竞争编程问题，每个问题平均有 60 个专家设计的测试案例。LiveOIBench 的四大特点包括：精心挑选的高质量任务，具有详细子任务评分标准和广泛的私人测试案例；直接整合精英选手的表现数据，使与顶级人类选手进行对比变得信息丰富；计划持续、无污染的更新来自新发布的奥林匹克竞赛问题；以及一个自包含的评估系统，支持离线和易于复制的评估。", "conclusion": "在对 32 个流行的通用和推理大型语言模型进行基准测试后，发现 GPT-5 达到了显著的 81.76 个百分点，虽然很强但仍然低于顶级人类选手的表现，通常在 90 个百分点以上。相比之下，开源权重推理模型 GPT-OSS-120B 只达到 60 个百分点，这表明与前沿封闭模型相比存在显著的能力差距。详细的分析表明，稳健的推理模型更倾向于精确的问题分析，而不是过度探索，这表明未来的模型应该强调结构化分析并尽量减少不必要的探索。所有数据、代码和排行榜结果将公布在我们的网站上。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/1804.06498", "html_url": "https://arxiv.org/abs/1804.06498", "title": "深度多模态子空间聚类网络", "title_en": "Deep Multimodal Subspace Clustering Networks", "authors": "Mahdi Abavisani,Vishal M. Patel", "background": "本文提出了一种基于卷积神经网络（CNN）的无监督多模态子空间聚类方法。方法由多模态编码器、自表达层和多模态解码器三个主要阶段组成。该框架旨在通过融合多个模态数据到一个潜在空间表示来实现子空间聚类，并在训练过程中利用解码器重构与原始输入之间的距离。研究了早期、晚期和中间融合技术，并为基于空间融合的方法提出了三种不同的编码器。此外，还提出了基于相似性融合的方法，要求不同模态的自表达层相同。实验结果表明，所提方法在三个数据集上的表现显著优于现有的多模态子空间聚类方法。", "innovation": "（1）提出了一种基于CNN的多模态子空间聚类框架，包括多模态编码器、自表达层和多模态解码器；（2）研究了早期、晚期和中间融合技术，并针对不同的空间融合方法提出了三种不同的编码器；（3）提出了基于相似性融合的方法，所有模态的自表达层相同；（4）通过在三个数据集上的实验，表明提出的模型在多模态子空间聚类中的表现显著优于现有方法。", "conclusion": "本文研究了早期、晚期和中间融合技术，并根据空间融合方法提出了三种不同的编码器。此外，还提出了基于相似性融合的方法。实验证明，所提方法显著优于现有的多模态子空间聚类方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/1904.11093", "html_url": "https://arxiv.org/abs/1904.11093", "title": "基于深度学习的稀疏表示分类", "title_en": "Deep Sparse Representation-based Classification", "authors": "Mahdi Abavisani,Vishal M. Patel", "background": "本文提出了一种基于深度学习的方法来实现稀疏表示基于分类（SRC）方法。通常情况下，SRC方法依赖手工设计的特征表示，而本文通过一个卷积自编码器和一个全连接层，自适应地学习用于分类的鲁棒特征。", "innovation": "提出的网络包括卷积自编码器和全连接层两部分。自编码器负责学习用于分类的鲁棒深层特征，而全连接层在编解码器网络之间，用于寻找稀疏表示。这种方法通过与现有的SRC方法进行比较得出，能够产生更优的分类结果。", "conclusion": "在三个不同数据集上的多种实验表明，提出的网络方法可以得到优于现有最先进SRC方法的稀疏表示，从而提升分类性能。源代码已发布。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08578", "html_url": "https://arxiv.org/abs/2510.08578", "title": "AgenticAD:一个专门的多代理系统框架，用于整体阿尔茨海默病管理", "title_en": "AgenticAD: A Specialized Multiagent System Framework for Holistic Alzheimer Disease Management", "authors": "Adib Bazgir,Amir Habibdoust,Xing Song,Yuwen Zhang", "background": "阿尔茨海默病（AD）对患者、护理人员以及医疗保健系统构成复杂的挑战，需要集成和动态支持解决方案。尽管人工智能（AI）为干预提供了有前景的途径，但目前的应用通常是孤立的，仅针对疾病的一个方面，如诊断或护理人员支持，未能实现系统集成。", "innovation": "本文提出了一种新的方法论框架，用于一个全面、多代理系统（MAS），旨在整体管理阿尔茨海默病。框架由八个相互操作的专门代理组成，分为支持护理人员和患者、数据分析和研究、以及高级多模态工作流三大类。每种代理利用先进的技术，如大型语言模型（LLMs）、多代理编排框架、检索增强生成（RAG）和专门工具，如网页抓取、多模态数据处理和内存数据库查询，构建了一个协作生态系统，旨在促进更加适应性、个性化并主动的解决方案。", "conclusion": "通过超越单一用途工具，转向协作的多代理范式，本文框架为未来能够综合各种数据流、提高患者结果并减轻护理人员负担的系统奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00670", "html_url": "https://arxiv.org/abs/2509.00670", "title": "PyNoetic: 一种用于无代码开发EEG脑-计算机接口的模块化Python框架", "title_en": "PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces", "authors": "Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo", "background": "脑-计算机接口（BCI）技术，特别是基于脑电图（EEG）的BCI，因其在机器人、虚拟现实、医疗和康复等领域的广泛应用而表现出色。然而，现有的BCI框架存在多种局限性，如实验研究中缺乏模块化的灵活性、需要编程知识的学习曲线陡峭、高昂的成本以及缺乏全面的功能导致研究人员必须使用多个外部工具，从而影响研究结果。这些局限性限制了BCI技术的广泛应用和发展。", "innovation": "PyNoetic是一个模块化的BCI框架，专为满足BCI研究的多样化需求而设计。PyNoetic是一个Python环境中罕见的能够涵盖BCI设计全过程（从刺激呈现、数据采集到通道选择、过滤、特征提取、去噪、仿真和可视化）的框架，同时也为研究人员提供了直观的端到端图形用户界面（GUI）和可配置的工作流，无需编写代码即可进行BCI设计。此外，PyNoetic还为高级用户提供了无缝集成自定义功能和新型算法的支持，确保了设计灵活性。PyNoetic还提供了一系列丰富的分析工具，如机器学习模型、脑连接指数、模拟的系统测试功能及新的范式评估方法，使其在离线和实时BCI开发中表现出强大适用性。", "conclusion": "PyNoetic通过模块化、直观的工作流和广泛的分析工具，简化了BCI开发流程，为研究人员提供了强大的支持，旨在加速BCI技术的研究与应用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08586", "html_url": "https://arxiv.org/abs/2510.08586", "title": "动态压力检测：语音中压力时间进展建模研究", "title_en": "Dynamic Stress Detection: A Study of Temporal Progression Modelling of Stress in Speech", "authors": "Vishakha Lall,Yisi Liu", "background": "在高压环境中，通过语音检测心理压力至关重要。现有技术主要通过声学特征检测压力，但常将其视为静态标签。本研究将压力视为受到历史情感状态影响的时间演变现象。", "innovation": "提出了一种动态标注策略，从情感标签中推导出细粒度的压力注释，并引入了基于交叉注意力的序列模型，包括单向LSTM和Transformer编码器，以捕捉压力的时间演变过程。该方法在MuSE (+5%) 和 StressID (+18%) 数据集上比现有基线方法取得了显著的准确率提升，并且在自定义现实世界数据集上表现良好。", "conclusion": "这些结果突显了将压力建模为语音时间动态结构的价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08576", "html_url": "https://arxiv.org/abs/2510.08576", "title": "大型语言模型在机器辅助解析用户意图中的比较分析", "title_en": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "authors": "Justus Flerlage,Alexander Acker,Odej Kao", "background": "大型语言模型（LLMs）已成为自然语言理解和用户意图解析的变革性工具，支持诸如翻译、摘要等任务，近年来逐渐发展为复杂工作流的协调器。这标志着从传统的、以图形用户界面驱动的用户界面向以语言为主导的互动模式的转变。用户可以通过自然语言表达目标，促使LLMs在多个应用程序之间实现动态和情景化的操作。然而，现有技术通常依赖于云基础的专有模型，这带来了隐私、自主性和可扩展性等方面的问题。因此，本地部署的开源和开放访问的LLMs对于实现可信且强大的交互界面十分重要，本研究即探讨了这一点。", "innovation": "本研究通过对比分析开源和开放访问的LLMs与OpenAI专有GPT-4系统的性能，评估其在不同用户意图下生成工作流的能力，提供了有关自主、本地可操作的开放LLMs在下一代操作系统中的实践可行性和潜力的实证见解。这项研究从更大范围上讨论了AI基础设施去中心化和民主化的问题，并提出了用户设备互动无缝、自适应、注重隐私的未来展望，通过嵌入式智能实现了更加智能的交互。", "conclusion": "研究结果有助于更广泛的讨论，表明本地嵌入的大规模语言模型能够促进用户意图解析，提高了AI基础设施的去中心化和民主化。未来，用户与设备的互动将更加无缝、适应性强和保护用户隐私。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08580", "html_url": "https://arxiv.org/abs/2510.08580", "title": "LadderSym：一种用于音乐实践错误检测的多模态交织变压器", "title_en": "LadderSym: A Multimodal Interleaved Transformer for Music Practice Error Detection", "authors": "Benjamin Shiue-Hal Chou,Purvish Jajal,Nick John Eliopoulos,James C. Davis,George K. Thiruvathukal,Kristen Yeon-Ji Yun,Yung-Hsiang Lu", "background": "音乐学习者可以从能够准确检测其练习中错误的工具中受益。现有方法通常通过启发式方法或可学习的模型将音频记录与乐谱进行比较。这篇论文介绍了LadderSym，这是一种基于Transformer的新颖方法，用于音乐错误检测。LadderSym受到当前最佳方法中的两个关键观察的启发：（1）后期融合限制了流之间的对齐以及跨模态的比较能力；（2）依赖乐谱音频在频率谱中引入了不确定性，从而降低了多音符同时演奏时的性能。", "innovation": "LadderSym提出了一种具有双流编码器和跨流对齐模块的方法，以提高音频比较能力和错误检测F1分数。它还引入了一个多模态策略，通过将符号表示作为解码器提示进行利用，从而减少了不确定性并提高了F1分数。与前一个最先进的方法相比，LadderSym在MAESTRO-E数据集上错误音符的F1分数提高了26.8%至56.3%，额外音符检测提高了14.4个百分点（从72.0%提高到86.4%）。在CocoChorales-E数据集上也观察到了类似收益。这项工作为序列评估任务提供了关于比较模型的一般见解，这些见解可用于强化学习、人类技能评估和模型评估等方面。", "conclusion": "通过LadderSym，该研究在音乐错误检测方面取得了显著进展，提升了F1分数，并且其方法可能对序列评估任务有广泛的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08585", "html_url": "https://arxiv.org/abs/2510.08585", "title": "Articulation-Informed ASR: 通过辅助语音反转和交叉注意力融合集成发音特征的ASR", "title_en": "Articulation-Informed ASR: Integrating Articulatory Features into ASR via Auxiliary Speech Inversion and Cross-Attention Fusion", "authors": "Ahmed Adel Attia,Jing Liu,Carol Espy Wilson", "background": "之前的研究所探讨了使用发音特征作为自动语音识别(ASR)的补充表示，但这些研究大多局限于浅层声学模型。本文在深度学习时代重新审视发音信息，并提出了一种框架，该框架利用发音表示既作为辅助任务，又作为伪输入到识别模型。具体来说，我们采用语音反转作为辅助预测任务，并将预测的发音特征通过交叉注意模块注入模型，其中声学嵌入作为键和值。", "innovation": "该工作在深度学习背景下引入发音信息，并提出了一种同时利用发音表示作为辅助任务和伪输入到识别模型的新框架。具体方法包括采用语音反转作为辅助预测任务，预测的发音特征通过交叉注意力模块注入模型，声学嵌入作为键和值。", "conclusion": "在LibriSpeech上的实验表明，该方法在强基于变换器的基本模型上取得了持续改进，特别是在资源有限的情况下。这些发现表明，在现代架构中引入发音特征可以提供有意义的好处，这表明这些被ASR研究长期忽视的特征可以重新引入以提供帮助。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08581", "html_url": "https://arxiv.org/abs/2510.08581", "title": "在多样声学条件下使用口语评估多模态LLM中的妄想", "title_en": "Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse Acoustic Conditions", "authors": "Hansol Park,Hoseong Ahn,Junwon Moon,Yejin Lee,Kyuhong Shim", "background": "已有大量研究使用基准测试评估视觉-语言模型在图像-文本设置中的可靠性。然而，口头查询对多模态妄想的影响仍未得到充分的研究，尽管语音驱动的界面正在逐渐增多。本研究探讨了口头输入如何影响大语言模型的多模态妄想。研究通过创建一个名为RePOPE-Spk的新基准测试，加入了语音输入，并且探索了在各种声学条件下，说法语查询与写作查询相比的变化。实验表明，在干净的语音下，错误率增加了3%，在环境噪音条件下，错误率增加了20%。此外，输入顺序和问题长度也影响模型的稳健性，尽管许多-shot提示和推理策略可以部分缓解，但不足以完全解决这一问题。这项研究揭示了一个关键但较为忽视的挑战，这为构建可靠语音接口系统提供了新的发展方向。", "innovation": "本研究创新性地提出了RePOPE-Spk基准测试，首次系统性地评估了不同条件下会话查询对多模态大语言模型妄想的影响。特别地，该基准测试能在多样化的声学环境中评估模型的表现，并发现在平凡和复杂条件下的模型行为差异，为进一步的研究和模型开发提供了重要参考。通过引入该测试，本研究突出了构建可靠语音接口中亟待解决的关键问题。", "conclusion": "研究结果表明，使用口头查询比书面查询更容易导致模型产生妄想，特别是在噪音环境下表现更为明显。模型的稳健性还受到输入顺序和问题长度的影响。尽管许多-shot提示和推理策略可以减轻但不足以完全解决这个问题。这些发现为开发可靠的语音接口系统指明了新的研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08587", "html_url": "https://arxiv.org/abs/2510.08587", "title": "EGSTalker: 实时基于高效高斯变形的语音驱动头部生成", "title_en": "EGSTalker: Real-Time Audio-Driven Talking Head Generation with Efficient Gaussian Deformation", "authors": "Tianheng Zhu,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng", "background": "本文介绍了EGSTalker框架，这是一种基于3D高斯散点图（3DGS）的实时语音驱动头部生成系统。该系统旨在通过使用少量的训练视频来合成高质量的面部动画，同时提高速度和视觉保真度。之前的类似系统在合成高质量面部动画的同时往往会牺牲实时性或者计算效率，满足实时多媒体应用的需求成为一个挑战。本文所提框架的两阶段流程实现了这一目标，为实时语音驱动头部生成提供了新的解决方案。", "innovation": "EGSTalker的创新在于使用高效的空间-音频注意力（ESAA）模块融合音频和空间线索，结合多分辨率哈希三平面和Kolmogorov-Arnold神经网络（KAN）来提取空间特征并构造紧凑的3D高斯表示。该框架的两个主要阶段分别是静态高斯初始化阶段和基于音频的变形。实验表明，EGSTalker在渲染质量和口型同步精度上达到了与当前最先进的方法相当的水平，同时在推断速度方面显著超越它们，从而展示了EGSTalker在实时多媒体应用中的巨大潜力。", "conclusion": "研究结果表明，EGSTalker框架能够实现与当前最先进的方法相媲美的渲染质量和口型同步精度，同时在推理速度上具有显著优势。这种高性能、低延迟的特性使其特别适合用于实时多媒体应用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08591", "html_url": "https://arxiv.org/abs/2510.08591", "title": "深度神经网络的持久主导地位：对量子机器学习和突触神经网络根本局限性的批判性分析", "title_en": "The Enduring Dominance of Deep Neural Networks: A Critical Analysis of the Fundamental Limitations of Quantum Machine Learning and Spiking Neural Networks", "authors": "Takehiro Ishikawa", "background": "最近在量子机器学习（QML）和突触神经网络（SNNs）方面的进展引发了巨大的兴趣，它们承诺以指数级的速度提升和大脑般的能源效率革新人工智能。然而，本文认为这些技术在未来短期内不太可能取代深度神经网络（DNNs）。QML由于受到保角约束、测量诱导的状态崩溃、荒漠 plateau现象以及高测量成本的影响，在适应反向传播方面遇到困难。SNNs则存在表征带宽受限的问题，特别是在处理长范围依赖性和语言任务中的语义编码方面，其基于脉冲的处理方式尤为不足。", "innovation": "文章指出DNNs的优势，包括高效的反向传播、强大的正则化技术以及在自回归微分模型中的创新应用，这些都使得DNNs在推理时受益，同时能够通过强化学习和MCTS等算法实现自我改进。此外，专用的ASIC技术进一步增强了DNNs的效率。", "conclusion": "QML和SNNs可能在特定的领域中扮演混合角色，但DNNs仍然是推动人工智能发展的主导、实用的范式。最近的模型如xAI的Grok-4 Heavy展示了SOTA性能的进步，而gpt-oss-120b更是以其较小的参数量（120亿）超越或接近了领先行业的模型表现，这都证实了DNNs的优越性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08589", "html_url": "https://arxiv.org/abs/2510.08589", "title": "超出传统的CNN：在数据稀缺条件下高效微调多模态大语言模型进行目标检测", "title_en": "Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes", "authors": "Nirmal Elamon,Rouzbeh Davoudi", "background": "物体检测和理解领域正迅速发展，这得益于传统CNN模型和新兴的多模态大型语言模型（LLMs）的进步。尽管像ResNet和YOLO这样的CNN模型在基于图像的任务中仍然非常有效，但基于变压器的LLMs引入了动态上下文推理、语言引导提示和整体场景理解等新能力。然而，当这些模型未经过专门调整使用时，其潜在能力仍被大大低估，导致在专业视觉任务上的表现不佳。本研究通过全面比较微调的传统CNN模型、零样本预训练的多模态LLMs以及微调的多模态LLMs，探讨了在图像上检测人工文本覆盖层这一具有挑战性的任务上的表现差异。", "innovation": "本研究的一个关键贡献在于展示如何在极少的数据（少于1000张图像）上有效微调LLMs，使其在物体检测任务上的准确度提高36%，并达到了或超过了需要大量数据的基于CNN基线模型的表现。通过研究如何让语言引导模型在极少监督的情况下实现精确的视觉理解，本研究不仅为视觉与语言的融合做出了贡献，还为跨模态学习策略提供了新颖的见解。", "conclusion": "这些发现突显了基于LLMs的方法在真实世界物体检测任务中的适应性和数据效率，并为在低资源视觉环境中应用多模态变压器提供了实用指导。为了促进这一领域的持续进步，本研究公开了用于微调这些模型的代码，这将有助于未来研究的进步和相关应用的重复使用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08592", "html_url": "https://arxiv.org/abs/2510.08592", "title": "少多样性，少安全：测试时缩放（TTS）在大规模语言模型中的间接但普遍风险", "title_en": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models", "authors": "Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra", "background": "TTS方法通过探索多个候选响应并从中找到最佳输出来改善LLM的推理能力。TTS背后的一个假设是，高度多样性的候选池可以提高可靠性。然而，该研究显示，TTS中的这一假设引入了一个未被识别的失败模式，当候选多样性受限制，即使适度限制，TTS更可能生成不安全的输出。研究还显示，通过RefDiv协议指示的多样性减少可以显著表明TTS产生不安全结果的速率，这种效果往往比直接使用带有高对抗意图评分的提示更强。在TTS策略和闭源模型中都观察到了这种现象，表明这是TTS的一种普遍且存在的属性，而不仅仅是特定模型的特征。此外，广泛使用的安全护栏分类器（如Llama-Guard和OpenAI Moderation API）无法标记RefDiv生成的对抗输入提示，表明现有防御措施对这种多样性驱动的失败模式提供有限的保护。", "innovation": "提出了一种参考指导的多样性减少协议（RefDiv），作为诊断攻击来测试TTS流水线的鲁棒性。该研究通过广泛的实验表明，当限制候选多样性时，TTS更有可能生成不安全的结果。此外，发现使用RefDiv生成的对抗输入提示，广泛使用的安全护栏分类器都无法检测到。这一结果突出了设计同时有效且安全的TTS策略的重要性，以及需要针对多样性的针对性压力测试。", "conclusion": "TTS策略中的候选多样性减少会导致更多的不安全输出，这表明需要对TTS进行更严格的测试，以及需要更有效的安全措施来保护其免受这种多样性的负面影响。未来的研究应集中在设计对抗多样化压力测试同样有效的TTS策略。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08593", "html_url": "https://arxiv.org/abs/2510.08593", "title": "基于分层自监督表示学习的语音抑郁检测", "title_en": "Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech", "authors": "Yuxin Li,Eng Siong Chng,Cuntai Guan", "background": "语音基于的抑郁检测(SDD)是一种有潜力的无创替代传统临床评估的方法，但是仍然受到提取有意义特征的难度和捕捉稀疏、异质的抑郁线索的限制。大多数现有的SDD方法依赖于最终层或者搜索单个最佳表现层，这些方法通常会过度拟合特定数据集并且无法利用全层次结构的信号来检测细微和持续的抑郁信号。", "innovation": "我们提出了HAREN-CTC，一种新颖的架构，通过多层自监督学习特征的跨注意力来整合多任务学习框架，并结合连接主义时序分类损失以处理稀疏的时间监督。HAREN-CTC包含两个关键模块：层级自适应聚类模块，用于重新组织自监督学习特征为互补嵌入；交叉模态融合模块，通过跨注意力建模层次间的依赖关系。连接主义时序分类目标使模型能够在训练中关注不规则的时间模式。", "conclusion": "我们在标准数据分割的上限设置和五折交叉验证的泛化设置下评估了HAREN-CTC。模型在DAIC-WOZ和MODMA上分别达到了0.81和0.82的宏F1得分，优于先前的方法，在两种评估场景中均表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08599", "html_url": "https://arxiv.org/abs/2510.08599", "title": "BaldWhisper: 更快的 Whisper 通过头部剪切和层合并", "title_en": "BaldWhisper: Faster Whisper with Head Shearing and Layer Merging", "authors": "Yaya Sy,Christophe Cerisara,Irina Illina", "background": "在资源稀缺的语言环境中，对大型预训练变压器进行修剪以减轻模型大小和加速推理是具有挑战性的，因为通常需要大量的重新训练数据来恢复性能。例如，Distill-Whisper 裁剪了 Whisper 并在其上重新训练了 21,000 小时的语音数据，远远超过了大多数语言可用的数据量。因此，如何使 Whisper 更适合边缘设备并在数据稀缺环境下保持高效成为了亟待解决的问题。", "innovation": "该研究提出了一种针对巴马拉语的新修剪方案，使用低秩分解和特征蒸馏压缩嵌入层，而不是删除或移除层。这种方法不仅保持了90%的原始性能，而且比原始模型小48%，在 MacBook Air M1 上的速度快 2.15 倍。该研究的结果显著减少了对大规模重新训练数据的依赖，并提出了一种新的轻量化模型构建方法。", "conclusion": "研究最终得出结论，通过采用低秩分解和特征蒸馏来压缩嵌入层，以及合并层而不移除它们，可以有效地减轻 Whisper 模型的大小和提高其在没有大量数据的环境下的运行效率，从而使其更适合边缘设备使用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08600", "html_url": "https://arxiv.org/abs/2510.08600", "title": "Recover-LoRA: 通过对降级语言模型进行低秩适应实现无数据精度恢复", "title_en": "Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation", "authors": "Devleena Das,Rajeev Patwari,Ashish Sirasao", "background": "通过量化、剪枝、格式和数据类型转换、模型导出和序列化等方式进行的推断优化可能会导致语言模型任务性能的下降。目前大部分关于性能恢复的研究集中在鲁棒量化技术上，而较少关注因不当的模型序列化等其他原因导致的模型权重下降。本研究旨在提出一种轻量级且不受数据集限制的方法Recover-LoRA，以恢复降级模型的准确性。", "innovation": "Recover-LoRA是一种使用合成数据和logit蒸distillation技术，结合选择性层上学习LoRA适配器，以使降级模型与其全精度模型对齐的轻量级方法。该方法适用于多种小语言模型（SLMs），包括具有不同注意力架构（如多头注意力MHA和组查询注意力GQA）的模型，以及多种评估数据集。实验结果显示，在MHA和GQA SLMs上，Recover-LoRA能够恢复高达5-17%的模型准确性。", "conclusion": "Recover-LoRA方法能够有效恢复因不当序列化等导致的降级语言模型的准确性，适用于多种类型的模型和数据集，展示出良好的性能恢复能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak：通过潜在空间反馈破解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": " Jailbreaks是针对大语言模型内置安全机制的对抗性攻击。现有的自动化Jailbreak通常通过优化对抗后缀或适应长提示模板来触发模型生成受限制或有害的响应。研究发现，现有的利用上述机制解锁模型响应的Jailbreak攻击可以通过基于困惑度的过滤输入提示进行检测。为了应对这一问题，提出了LatentBreak，一种白盒Jailbreak攻击方法，它生成具有低困惑度的自然对抗性提示，以逃避此类防御。LatentBreak通过在潜在空间中最小化对抗提示和无害请求之间的表示距离来替代输入提示中的词汇，从而保持提示的初始意图。", "innovation": "LatentBreak采用了在潜在空间中选择词汇替代的方法，生成了具有较低困惑度的自然对抗性提示，能够绕过基于困惑度的过滤器防御。相比之前的方法，它能够产生更短且低困惑度的提示，从而在多个与安全性对齐的模型上优于其他竞争的Jailbreak算法。", "conclusion": "我们的广泛评估表明，LatentBreak不仅可以生成更短且低困惑度的提示，还能够有效应对基于困惑度的过滤器防御，从而在多个安全对齐的模型上表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08605", "html_url": "https://arxiv.org/abs/2510.08605", "title": "向更安全的网络迈进：多语言多代理大型语言模型应对对抗性虚假信息攻击", "title_en": "Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks", "authors": "Nouar Aldahoul,Yasir Zaki", "background": "数字平台上的虚假信息传播威胁着公共言论、情感稳定以及决策。尽管已有研究探索了各个对抗性攻击在虚假信息检测中的应用，但论文具体探讨的语言转换（如英、法、西、阿、印、中）及查询长度膨胀再总结、以及结构重塑为多项选择题等特定变换方式尚未被系统性研究。这些特定变换方式同样也是虚假信息传播中的重要手段，需要针对性研究和处理。因此，研究团队提出了一种多语言多代理的大规模语言模型框架，结合检索增强生成技术，可以在网络平台上实现插件部署，加强网络环境下的事实检验、防范各种类型攻击的有效性，并展示了插件部署在实际网络应用中的可行性", "innovation": "研究团队引入了一种兼具多语言处理能力和多任务代理支持的大规模语言模型框架，该模型基于检索增强生成方法，能够部署在网络Web插件中，用于防范包括但不限于语言转换、查询长度膨胀和结构重构成多项选择题等具体的虚假信息传播手段攻击。这为对抗虚假信息提供了新的思路和工具，提高了网络事实的准确性和安全性", "conclusion": "这一研究强调了AI驱动的虚假信息检测在保护网络环境的客观性和完整性方面的关键作用，同时展示了基于插件的部署在实际网络应用中的实用性，为未来的网络信息安全策略提供了有力支持。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08606", "html_url": "https://arxiv.org/abs/2510.08606", "title": "聚焦情感热点: 会话中多模态局部-全局融合与跨模态对齐", "title_en": "Centering Emotion Hotspots: Multimodal Local-Global Fusion and Cross-Modal Alignment for Emotion Recognition in Conversations", "authors": "Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li", "background": "情感识别在对话（ERC）中是一个具有挑战性的任务，因为区分性证据稀疏、局部化且往往跨模态异步。ERC的难点在于需要处理互不匹配的多种模态（如文本、音频和视频），且情感表达往往分散于对话的不同片段中，导致识别困难。", "innovation": "本文提出了一个统一模型，该模型聚焦于对话中显著的情感热点，能够检测文本、音频和视频中的每个片段的情感热点，并利用热点门控融合（Hotspot-Gated Fusion, HGF）将局部特征与全局特征融合，同时通过路由混合模型（Mixture-of-Aligners, MoA）对齐多模态信息。该模型还利用跨模态图编码对话结构，从而提高了识别准确性，解决了模态不匹配的问题，保留了上下文信息。", "conclusion": "实验表明，该方法在标准ERC基准上优于现有强基线，并通过消融实验证实了HGF和MoA的贡献。研究结果表明，以热点为中心的视角对于未来的多模态学习可能是一个新的启示，尤其在ERC中的模态融合方面。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08601", "html_url": "https://arxiv.org/abs/2510.08601", "title": "Mnemosyne：边缘基于的大语言模型的人类启发式无监督长期记忆架构", "title_en": "Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs", "authors": "Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)", "background": "当前的大语言模型（LLM）的记忆系统依赖于粗暴扩展的上下文或静态的检索管道，这些方法在受到性能限制的边缘设备上表现不佳。长周期的自然对话需要有效的长期记忆机制。Mnemosyne旨在解决这些问题，通过使用图结构存储、模块化物质和冗余过滤器、记忆提交和修剪机制、基于人类记忆的概率检索以及时间衰减和刷新过程，为边缘设备优化设计了一个人类启发式的无监督长期记忆架构。", "innovation": "Mnemosyne提出了一个基于图结构的存储系统，结合了模块化的物质和冗余过滤器，以及记忆提交和修剪机制。它还引入了一个浓缩的核心摘要，能够高效地捕捉用户的个性和特定领域性的长期细节。更重要的是，不同于现有的检索增强方法，Mnemosyne旨在为纵向护理助理提供支持，这些助理面对的是重复但时间上不一致且语义相似的对话。实验结果显示，Mnemosyne在纵向健康对话中展现了65.8%的最高胜率，在自然度和长期记忆能力方面优于基线RAG方法，并且在时间推理和单跳检索中取得了当前最高的LoCoMo基准评分。此外，它的综合评分为54.6%，仅次于其他方法，从而证明了无监督的记忆架构在提高事实回忆准确性、增强时间推理能力以及生成更加自然的用户交互响应方面具有可行性且适合边缘设备使用和迁移部署。", "conclusion": "Mnemosyne通过结合先进的技术机制，优化设计了为边缘设备量身定做的无监督人类启发式长期记忆架构，显著提升了自然对话的长期记忆能力，并在多个基准测试中取得了优异的成绩，证明了该架构对于提高大语言模型性能的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08608", "html_url": "https://arxiv.org/abs/2510.08608", "title": "MMA-ASIA：一种基于文化的多语言和多媒体对齐框架", "title_en": "MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation", "authors": "Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen", "background": "大型语言模型（LLMs）在全球范围内得到广泛应用，但它们在跨文化交流理解和推理方面常常在非西方、高资源地区表现不佳。", "innovation": "MMA-ASIA是一个全面的框架，用于评估LLMs在亚洲文化背景中的意识，重点关注亚洲语境。它包括一个多模态对齐的多语言多项选择基准，涵盖了8个亚洲国家和10种语言，共计27,000个问题；超过79%的问题需要基于文化背景的多步推理，超越了简单记忆。这是第一个在输入层对齐了三种模态（文本、图像和语音）的数据集，这使得可以直接测试多模态间的跨域转移。", "conclusion": "通过比较模型分析、注意力跟踪以及创新性的Vision-ablated Prefix Replay (VPR) 方法，研究探讨了模型在不同语言和模态间的差异原因，提供了一些对于构建文化可靠型多媒体LLMs的可操作性见解。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08610", "html_url": "https://arxiv.org/abs/2510.08610", "title": "基于相对定位的代码片段切分方法在代码语言模型的仓库级代码完成任务中用于丰富上下文检索", "title_en": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "authors": "Imranur Rahman,Md Rayhanur Rahman", "background": "代码补全可以提高开发效率并简化开发生命周期。虽然现代集成开发环境（IDEs）中提供了代码补全功能，但缺乏研究来确定基于IDE提供的信息什么样的上下文最适合代码补全，从而使大型语言模型（LLMs）能够更好地完成任务。已有研究尚未深入探讨如何有效收集和利用这些上下文信息，以提升代码补全的性能。本文的研究背景是探索和实现一种有效的上下文收集策略，以优化代码补全任务的性能，基于此背景，阐述了研究的主要目标和研究问题。", "innovation": "本文提出了一种基于相对定位的代码片段切分方法，以增强代码补全任务中的上下文检索。该方法的关键理念是将代码仓库预处理成较小的代码片段，然后使用基于语法和语义相似性的代码片段检索方法，并结合相对定位策略来提升代码补全任务的性能。此方法创新点在于它提供了一种具体的操作策略，将大块代码切分为便于理解和检索的小片段，通过相对定位进一步优化了最终的上下文，增强了代码语言模型在实际应用中的效果。", "conclusion": "我们提出并验证了一种有效的代码片段切分和上下文检索策略，该策略通过代码片段化和相对定位显著提高了代码补全任务的完成准确性和效率。通过对代码仓库进行预处理和使用基于语法和语义相似性的代码片段检索方法，结合相对定位技巧，这种策略能够有效提升代码补全任务的整体性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08638", "html_url": "https://arxiv.org/abs/2510.08638", "title": "兔穴探秘：从DINO的任务相关概念到闵可夫斯基几何", "title_en": "Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry", "authors": "Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg", "background": "DINOv2 被广泛应用于物体、场景和活动识别，但其感知的本质仍不清楚。作者采用线性表示假设（LRH），通过自编码器（SAEs）生成了一个32,000单元的词典，作为研究的可解释性基础。研究分为三个部分。第一部分分析不同的下游任务如何利用学习到的词典中的概念，揭示其功能专业化，包括分类、分割和深度估计。", "innovation": "作者提出了Minkowski表示假设（MRH），解释了深度可变形模型中学习到的概念结构。作者经实验验证该假设，为解释ViT表示提供了新的见解。", "conclusion": "研究表明，表示不仅仅是线性稀疏的，而是部分密集。字典向更加连贯且远离最大正交理想的结构发展。作者提出，表示由凸混合基元（原型）组成，构建受Gardenfors概念空间和模型机制（多头注意机制）影响的几何区域。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08626", "html_url": "https://arxiv.org/abs/2510.08626", "title": "从小到大：基于小型语言模型的思维空间推荐", "title_en": "From What to Why: Thought-Space Recommendation with Small Language Models", "authors": "Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar", "background": "大型语言模型（LLMs）通过增强推理能力提高了推荐能力，但由于高推理成本，限制了在真实世界的部署。相比之下，小型语言模型（SLMs）虽然提供了更有效的替代方案，但其推理能力在推荐领域尚未得到充分探索。现有系统通常将自然语言理由于其难以监督，仅用作未监督的描述文本，未能充分发挥其作为学习信号的潜力。", "innovation": "本文提出了PULSE（Preference Understanding by Latent Semantic Embeddings），一种使用小型语言模型生成的理由于其第一级信号，而不是使用大型语言模型提炼的知识来构建跨多个领域的思维空间（Thought Space）的方法。与现有方法仅考虑序列和嵌入相比，PULSE将梳理作为主要监督信号，这种新颖的设计产生了更稳健和泛化的嵌入。通过多种基准数据集实验，PULSE优于现有ID、协作过滤（CF）及基于大型语言模型的序列推荐模型，并在跨域推荐和下游任务（如推理导向的问题回答）中表现出优越的可迁移性和强性能。", "conclusion": "PULSE在多个基准数据集上优于现有的ID、CF及基于大型语言模型的序列推荐模型，在跨域推荐和下游任务上表现出强大的性能，并且代码已公开。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08612", "html_url": "https://arxiv.org/abs/2510.08612", "title": "LLMs对软件开发中团队协作的影响", "title_en": "Impact of LLMs on Team Collaboration in Software Development", "authors": "Devang Dhanuka", "background": "大型语言模型（LLMs）正在逐步融入软件开发流程中，有望重新定义团队工作流程和提高生产效率。本文探讨在软件开发生命周期（SDLC）中，LLMs如何影响团队协作。基于2025年的最新进展，我们重新审视了先前关于团队协作的初步研究，更新了相关文献和案例研究，并分析了在SDLC中团队协作面临的障碍，以及LLMs如何增强生产力、沟通和决策能力。我们通过文献回顾、行业案例、团队调查和两个案例研究，评估了LLM辅助工具（如代码生成助手和AI驱动的项目管理代理）对协作软件工程实践的影响。", "innovation": "本文创新性地基于2025年的最新进展，更新了先前关于软件开发团队协作研究的初步发现，并通过文献回顾、行业案例、团队调查和案例研究多方面评估了LLMs在软件开发中的应用效果，特别是LLM辅助工具（如代码生成助手和AI驱动的项目管理代理）如何影响协同软件工程实践。同时探讨了在引入LLMs过程中遇到的新挑战（如模型限制和隐私问题）以及应对策略，为进一步研究提出了方向，包括定制特定领域的模型、提高与开发工具的集成度以及制定确保信任和安全的策略。", "conclusion": "通过研究表明，LLMs能够显著提高效率（通过自动化重复性任务和文档工作）、提高沟通清晰度，并促进跨功能团队合作，同时也提出了新的挑战（如模型限制和隐私问题），并为此后的研究提出了具体方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08635", "html_url": "https://arxiv.org/abs/2510.08635", "title": "Hi-OSCAR: 层次开放集分类器用于人类活动识别", "title_en": "Hi-OSCAR: Hierarchical Open-set Classifier for Human Activity Recognition", "authors": "Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring", "background": "在生活活动中进行的活动范围与用于训练标注传感器数据集所能捕捉的活动之间存在难以逾越的差距。未能妥善处理未见过的活动严重影响了任何活动识别分类器的可靠性。此外，HAR中的所有类别并不等同程度地不相似，一些类别显著重叠或包含其他子活动。基于这些观察结果，我们将活动类别组织成一个结构化层次。在此基础上，我们提出了Hi-OSCAR：一种层次开放集分类器，能够以最先进的精度识别已知活动，同时拒绝未知活动。这不仅实现了开放集分类，还允许未知类被定位到最近的内部节点，提供了超过二元“已知/未知”分类的见解。为了促进此类开放集HAR研究，我们收集了一个新的数据集：NFI_FARED。NFI_FARED包含了多个主体进行的十九种活动的数据，来自不同的上下文，包括日常活动、通勤和快速运动，此数据集完全公开并可供下载。", "innovation": "Hi-OSCAR是一个层次开放集分类器，旨在识别已知活动并拒绝未知活动，同时提供超越二元“已知/未知”分类的见解。提出了活动类别的层次结构，并基于此结构实现开放集分类。还收集了一个新的全面公开的数据集NFI_FARED，包含多种活动类别。", "conclusion": "这种层次化的开放集分类器不仅可以显著提高活动识别的准确性，还可以更好地定位未知类，提供更深入的理解。同时，NFI_FARED数据集为未来开放集HAR研究提供了重要资源。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08646", "html_url": "https://arxiv.org/abs/2510.08646", "title": "Energy-驱动偏航：降低大型语言模型中的误拒绝", "title_en": "Energy-Driven Steering: Reducing False Refusals in Large Language Models", "authors": "Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li", "background": "当前对大型语言模型（LLMs）进行安全性对齐的主要挑战在于，现有的对齐技术通常仅仅专注于提升对有害提示的安全性，导致LLMs变得过于谨慎，对无害提示也会拒绝响应。因此，安全对齐的关键目标是在提高安全性的前提下同时减少误拒绝情况。这项研究通过引入新框架Energy-Driven Steering (EDS) 来解决此问题。", "innovation": "EDS是一种无需微调的框架，它通过动态、推理时干预来解决此挑战。该框架训练一个轻量级的外部能量模型（EBM），以分配较高的能量值给不希望状态（误拒绝或锁定）和较低的能量值给希望状态（有益响应或安全拒绝）。在推理过程中，EBM将LLM的内部激活映射到“能量景观”。利用能量函数的梯度动态引导LLM的隐藏状态进入低能量区域，使模型能在实时生成期望响应，而无需修改其权重。这种方法将行为控制与核心知识分离开来，提供了一种灵活且计算开销小的解决方案。", "conclusion": "我们对不同模型进行了广泛实验，结果显示我们的方法成功实现了降低误拒绝率的目标。例如，在ORB-H基准上将合规性从57.3%提高到82.6%，同时保持了基础的安全性能。我们的工作为构建同时实现低误拒绝率和高安全性的LLMs提供了有效的框架。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08647", "html_url": "https://arxiv.org/abs/2510.08647", "title": "前向Chain-of-Thought：一种链式推理压缩的合作框架", "title_en": "Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression", "authors": "Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen", "background": "近期发展使大型语言模型（LLMs）能够通过长时间的链式推理（CoT）进行高级推理，但长时间的CoT会导致高计算成本和显著的延迟损失，这是因为生成型LLMs的自回归特性。CoT压缩旨在通过减少输出长度来提高推理过程中的效率。以往的工作通过辛苦设计离散的提示或构建外部压缩CoT数据集来权衡效率，这些方法要么牺牲关键的推理细节，要么无法有效自动化。", "innovation": "提出了一种名为前向链式推理（UCoT）的高效推理框架，通过前向生成富含推理信息的前瞻性思维嵌入来自动化CoT压缩。UCoT采用由小型模型（压缩器）和大型模型（执行器）组成的协作工作流程。首先训练压缩器生成对于执行器有用的富含推理信息的前瞻性思维嵌入，避免手动设计提示的缺点。其次优化执行器利用前向的思维嵌入进行短推理以得出正确答案，通过奖励机制来完成。研究表明，UCoT能够维持执行器强大的推理能力同时显著减少CoT的长度。特别是应用于Qwen2.5-7B-Instruct模型时，UCoT在GSM8K数据集上的令牌使用量减少了50%，性能则高出3.08%，均优于当前最先进的方法(SOTA)。", "conclusion": "UCoT提供了一种有效的前向思维嵌入生成和技术来自动压缩CoT，不仅保持了执行器强大的推理能力，还大幅减少了CoT的长度，显著提高了效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08648", "html_url": "https://arxiv.org/abs/2510.08648", "title": "无逆曲率Wilson环路：Transformer的实用诊断方法", "title_en": "Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity", "authors": "Edward Y. Chang,Ethan Y. Chang", "background": "大型语言模型在进行细微但实际重要的更改时可以改变答案，例如段落重排、微调破坏预训练学到的不变性、辩论或链式思考提示受路径依赖影响，以及编译融合或重排序在决策边界附近影响输出。这些失败违反了预期的不变性，打断了持续集成，并迫使团队在安全性和速度之间做出权衡。影响是微小的，但分布在多个层和位置，对上下文长度和评估顺序敏感，修复时成本高昂，需要重训或形式验证。", "innovation": "提出了WILSON，一种最小后矫的诊断套件，将内部表示上的简单循环和重排序检查转化为系统信号。WILSON结合了基于JVP和Hutchinson探针计算的位置和层上的无逆图示映射，以及标记重排序风险的激活级交换子。这些信号是廉价的、模型无特异性的，并以阈值和CSV文件的形式导出给协调者。这使具体行动成为可能：防范检索增强生成（RAG）的效果，检测微调退步，稳定辩论路径和长时间多轮对话的稳定性，并在部署中进行融合或重排序的控制。这有助于预见故障和批准安全优化，使可靠性和吞吐量可以一起提升，而不改变模型架构或训练。", "conclusion": "WILSON有助于预先预见失败，并批准安全的改进，使得可靠性和吞吐量可以同步提升，而不改变模型架构或训练过程。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08640", "html_url": "https://arxiv.org/abs/2510.08640", "title": "自动修复 Android 构建错误：通过领域特定工具弥合 LLM 剂量推理执行差距", "title_en": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "authors": "Ha Min Son,Huan Ren,Xin Liu,Zhe Zhao", "background": "Android 是最大的移动平台之一，但自动生成应用程序仍然是一个实际挑战。虽然大型语言模型（LLMs）在代码修复方面显示出了潜力，但他们用于修复 Android 构建错误的研究仍然不足。针对这一缺口，作者首先介绍了 AndroidBuildBench，这是一个包含 1,019 个构建失败的基准数据集，这些数据是从 43 个开源 Android 项目的提交历史中精心挑选出来的。每个问题都配有一个后续提交确认的解决方案，确保修复是可行的。作者还提出了 GradleFixer，这是一种带有领域特定工具的 LLM 剂量，专门用于检查和操作 Gradle 构建环境。", "innovation": "作者引入了 AndroidBuildBench 这一基准数据集，其中包含 1,019 个构建失败的例子，并提出了 GradleFixer，这是一种具有领域特定工具的 LLM 剂量，专门用于检查和操作 Gradle 构建环境。GradleFixer 在解决构建错误方面取得了 81.4% 的成功率（pass@1），大幅优于依赖通用 shell 的当前最佳编码剂量。此外，作者提出了 Tool Bridging 的策略，通过将通用 shell 命令替换为领域意识抽象来弥合推理和执行之间的差距。", "conclusion": "GradleFixer 成功的原因在于，虽然 LLMs 拥有解决这些失败问题的高级知识，但在使用通用 shell 将这些知识转化为有效的低级操作方面却存在困难。通过 Tool Bridging 方法，这一策略通过 API 格式的工具为 LLMs 提供更可靠的使用，并通过限制操作空间来约束相关操作，弥合了模型的高级推理和有效的低级执行之间的差距。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08649", "html_url": "https://arxiv.org/abs/2510.08649", "title": "在个人叙述中形式化风格", "title_en": "Formalizing Style in Personal Narratives", "authors": "Gustave Cortal(ENS Paris Saclay, LISN),Alain Finkel(ENS Paris Saclay)", "background": "个人叙述是作者构建的故事，用来赋予其经验意义。风格是作者表达自我的独特语言方式，决定了这些叙述如何传达主观体验。然而，目前缺乏一个正式框架来系统分析这些风格选择。我们提出了一种创新方法，将个人叙述中的风格形式化为作者传达主观体验时所作的语言选择模式。这种方法结合了三个领域：功能性语言学奠定语言作为一种有意义的选择系统的基础，计算机科学提供自动提取和分析序列模式的方法，这些模式与心理学观察相连接。通过语言模型，我们自动提取出诸如过程、参与者和情境等语言特征。我们应用该框架分析了数百个梦的叙述，并开展了对一名患有创伤后应激障碍的战争退伍军人的个案研究。通过对他的叙述分析，发现了一些独特的模式，特别是言语过程对心理过程的主导性，这表明语言选择与心理状态之间的关系。", "innovation": "我们提出了一种新的方法论来形式化个人叙述中的风格。这种创新方法将语言模式正式化为作者在传达主观体验时所作的选择。该方法综合了功能语言学、计算机科学和心理学三个领域，特别是利用语言模型自动提取和分析叙述中的关键元素，从而揭示了语言选择与心理状态之间的关联。", "conclusion": "我们对梦的叙述及一位患有创伤后应激障碍的退伍军人的个人叙述进行了应用分析，发现了一些独特模式，特别是言语过程占主导地位，这表明语言选择在揭示心理状态方面具有重要价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08655", "html_url": "https://arxiv.org/abs/2510.08655", "title": "基于知识图谱稀疏化和GNN的罕见疾病诊断", "title_en": "Knowledge Graph Sparsification for GNN-based Rare Disease Diagnosis", "authors": "Premt Cara,Kamilia Zaripova,David Bani-Harouni,Nassir Navab,Azade Farshad", "background": "罕见遗传疾病的诊断面临巨大的挑战，包括患者数据不足、全基因组测序难以获取以及潜在致病基因数量众多。这些问题导致了诊断时间延长、错误治疗以及在资源有限的地区延误诊断，严重影响了开发中国家的患者。", "innovation": "我们提出了RareNet，一种基于子图的图神经网络（GNN），仅需要患者的表型数据来识别最可能的致病基因，并检索针对性的患者子图进行针对性的临床调查。RareNet 可以作为独立的方法或作为其他候选基因优先级方法的预处理或后处理过滤器，提升其性能，并提供可解释的见解。", "conclusion": "通过全面评估两个生物医学数据集，我们展示了RareNet在因果基因预测方面的竞争力和稳健性，集成到其他框架中时可获得显著的性能提升。由于只需要所有临床环境中都容易获得的表型数据，RareNet 为需要复杂遗传分析但缺乏先进基因组基础设施的未服务群体提供了民主化的访问途径。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08657", "html_url": "https://arxiv.org/abs/2510.08657", "title": "内实例归一化在时间序列预测中的应用", "title_en": "Inner-Instance Normalization for Time Series Forecasting", "authors": "Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen", "background": "现实世界的时间序列受到众多因素的影响，表现出复杂的非平稳特性。非平稳性会导致分布偏移，即时间序列的统计特性随时间变化，这会负面影响模型的表现。现有的实例归一化技术虽然能够应对时间序列预测中的分布偏移，但这些方法未能考虑单个实例内部的偏移，从而导致性能不佳。本文探讨了这一背景问题并提出了新的解决方案。", "innovation": "本文提出了两种新颖的点级方法：Learning Distribution (LD) 和 Learning Conditional Distribution (LCD)。LD 通过使用不同参数拟合输入和输出在各个时间点的内部分布来消除内部偏差。LCD 利用神经网络预测输出的缩放系数。这些方法有效地处理了单个实例内部的分布变化。", "conclusion": "我们通过在公开基准测试中使用不同的骨干模型对这两种方法进行了评估，并通过对照实验展示了点级方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08656", "html_url": "https://arxiv.org/abs/2510.08656", "title": "从跨模态到参数化基础体素的3D生成框架", "title_en": "A 3D Generation Framework from Cross Modality to Parameterized Primitive", "authors": "Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan", "background": "近年来，AI驱动的3D模型生成技术已经利用了跨模态的优势，但生成具有光滑表面的模型并减少存储开销仍然是挑战。本文介绍了一种新颖的多阶段框架，用于生成由参数化基础体素组成的3D模型，该框架通过文本和图像输入进行引导。", "innovation": "提出了一个基于参数化基础体素的模型生成算法，可以识别模型组成部分的形状特征，并用高质量表面替代元素。此外，还提出了一种相应的模型存储方法，可以在保持原始表面质量的同时仅保留参数化基础体素的参数。实验证明，该方法在虚拟场景数据集和实际场景数据集上取得了良好效果，实现了0.003092的Chamfer Distance、0.545的VIoU、0.9139的F1-Score和0.8369的NC，参数化基础体素的参数文件大小约为6KB。该方法特别适用于简单模型的快速原型制作。", "conclusion": "该方法在虚拟场景数据集和实际场景数据集上进行了实验，结果表明该方法有效，适用于简单模型的快速原型制作。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08662", "html_url": "https://arxiv.org/abs/2510.08662", "title": "DPCformer: 农作物基因组预测的可解释深度学习模型", "title_en": "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops", "authors": "Pengcheng Deng,Kening Liu,Mengxi Zhou,Mingxi Li,Rui Yang,Chuzhe Cao,Maojun Wang,Zeyu Zhang", "background": "基因组选择（GS）利用全基因组信息预测作物表型并加速育种进程。传统的方法在预测复杂性状和大型数据集时存在准确性不足的问题。", "innovation": "提出了一种结合卷积神经网络和自注意力机制的深度学习模型DPCformer，用于建模表型-基因型关系。该模型在13种作物15组性状上进行应用，通过8维One-hot编码处理SNP数据，并利用PMF算法进行特征选择，结果显示该方法表现优于现有方法，在不同作物上均有显著的准确性提升。", "conclusion": "DPCformer展示了更高的预测准确性、在小样本情况下的鲁棒性以及增强的可解释性，提供了一种强大的精准育种工具，有助于应对全球粮食安全挑战。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08661", "html_url": "https://arxiv.org/abs/2510.08661", "title": "CATS-Linear：用于时间序列预测的分类辅助线性模型", "title_en": "CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting", "authors": "Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen", "background": "近期研究表明，线性模型在预测性能上可以与复杂架构相媲美，然而增强线性模型的方法尚未得到充分探索。鉴于不同的时间序列实例可能遵循不同的线性映射这一假设，本文提出了分类辅助时间-季节分解线性模型 (CATS-Linear)，利用分类辅助通道独立性 (CACI)。该模型通过分类动态路由实例到专用预测器，实现监督通道设计。", "innovation": "本文创新性地提出了CATS-Linear模型，引入了CACI机制，用于动态路由时间序列实例到不同的预测器。此外，通过加入解耦–线性映射–再耦合框架来重构趋势成分的分解架构，并使用复数域线性投影处理季节性成分。这些创新点显著提高了线性模型的时间序列预测精度。", "conclusion": "广泛的实验表明，使用固定超参数的CATS-Linear模型能够达到与超参数调优基线相当的最新水平的准确率，同时优于固定超参数的同类模型。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08665", "html_url": "https://arxiv.org/abs/2510.08665", "title": "RA-Gen: 一种使用ReAct进行多代理任务执行的可控代码生成框架", "title_en": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution", "authors": "Aofan Liu,Haoxuan Li,Bin Wang,Ao Yang,Hui Li", "background": "代码生成模型基于大型语言模型（LLMs）已经得到了广泛的应用，但安全性、准确性和可控性仍然存在挑战，尤其是对于复杂的任务而言。现有的方法往往缺乏对外部工具的动态集成、透明推理和用户对安全性的控制。", "innovation": "该研究提出了一个基于ReAct范式的多代理体系结构的可控代码生成框架。该框架通过LLMs与外部资源之间的动态交互来实现高效、精确和可解释的代码生成。它采用了由规划者、搜索引擎、代码生成器和提取器组成的协作架构，其中基于ReAct的搜索引擎会在生成推理轨迹和执行操作之间交替，从而能够无缝地将内部知识与外部工具（如搜索引擎）集成，以提高准确性和用户的控制能力。", "conclusion": "实验结果显示，该框架在多种语言中都表现出有效性，使用CodeQL在SVEN数据集上实现了94.8%的安全性，并优于现有的方法。其透明的推理过程有助于增强用户的信任并提高可控性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08659", "html_url": "https://arxiv.org/abs/2510.08659", "title": "为语言赋能基础模型提供可验证鲁棒性适应", "title_en": "Provably Robust Adaptation for Language-Empowered Foundation Models", "authors": "Yuni Lai,Xiaoyu Xue,Linghui Shen,Yulun Wu,Gaolei Li,Song Guo,Kai Zhou,Bin Xiao", "background": "语言赋能基础模型（LeFMs），如CLIP和GraphCLIP，通过将视觉（或图形）特征与文本表示对齐，极大地改变了多模态学习，并赋予了像少样本学习等强大下游能力。然而，这些模型依赖于小规模、特定任务支持数据集，这些数据集在开放环境中收集，使得它们容易受到注入式攻击。现有防御主要依赖于经验策略，缺乏理论保证，并可能对未见或适应性攻击是脆弱的。已有研究表明，基于LeFMs的少样本分类器的鲁棒性认证尚未得到充分探索。因此，本文旨在通过提出首个针对LeFMs的可验证鲁棒少样本分类器来填补这些关键空白。", "innovation": "本文提出了一个名为语言赋能少样本认证（LeFCert）的模型，该模型将文本和特征嵌入结合，并使用自适应混合机制。此外，为了实现可验证的鲁棒性，本文提出了双重修剪平均原型并推导了分类分数的可验证上限和下限，使其能够在最坏情况下的注入式场景下进行认证。同时，为了进一步提高性能，LeFCert引入两种变体：LeFCert-L 通过集成随机平滑提供Lipschitz连续性，并在双重预算约束下推导鲁棒性；LeFCert-C 在攻击者在多个样本中分配共享注入预算的情况下提供集体认证。实验结果表明，LeFCert 的性能优于现有基线，在干净和认证精度方面有了显著提升。", "conclusion": "尽管LeFCert具有先进的鲁棒机制，但在计算效率方面表现良好，使其在实际应用中具有可行性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08667", "html_url": "https://arxiv.org/abs/2510.08667", "title": "RAG4Tickets：基于JIRA和GitHub数据检索增强生成的AI辅助票务解决方法", "title_en": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data", "authors": "Mohammad Baqar", "background": "现代软件团队经常因为分散在JIRA票务、开发者讨论和GitHub拉请求（PR）中的碎片化知识而导致重复或相关问题的解决延迟。", "innovation": "提出了一种检索增强生成（RAG）框架，该框架结合了Sentence-Transformers用于语义嵌入和FAISS基于向量的搜索，以提供上下文感知的票务解决建议。该方法将历史JIRA票务、用户评论和相关PR元数据嵌入，检索语义上相似的过去案例，然后由大规模语言模型（LLM）综合生成有根据且可解释的解决方案建议。", "conclusion": "实验评估显示，所提出的系统显著提高了解决准确度、修复质量和现代DevOps环境中的知识重用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08664", "html_url": "https://arxiv.org/abs/2510.08664", "title": "Faver：使用函数抽象验证中间件增强基于LLM的RTL生成", "title_en": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware", "authors": "Jianan Mu,Mingyu Shi,Yining Wang,Tianmeng Yang,Bin Sun,Xing Hu,Jing Ye,Huawei Li", "background": "基于LLM的RTL生成是一个有趣的 research 方向，因为它有可能解放当前芯片设计中最少自动化的阶段。然而，由于高层次规范和RTL之间的巨大语义差距以及有限的训练数据，现有的模型在生成准确度方面存在困难。借鉴人类经验，与验证结合的设计有助于提高准确度。但是，由于RTL测试台数据更加稀缺，这对LLMs来说并不友好。尽管LLMs在高层次语言如Python/C方面表现出色，但它们与RTL之间的语义差距仍然很大。在同一功能的实现中，Python/C代码和硬件代码在时空粒度上有显著差异，这不仅要求LLM考虑高层次的功能语义，还需要确保低级细节与电路代码相一致。这是一项艰巨的任务。", "innovation": "本论文提出了一个功能抽象验证中间件(Faver)，该中介通过结合LLM友好的代码结构与基于规则的模板，简化了基于LLM的工作流程中的RTL验证。Faver通过解耦电路验证的细节，使得LLM能够专注于功能本身。", "conclusion": "在SFT模型和开源模型上的实验表明，Faver可以将模型的生成准确度提高最多14%。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08663", "html_url": "https://arxiv.org/abs/2510.08663", "title": "利用LLM评分文本数据增补评分量表测试的新型框架", "title_en": "A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data", "authors": "Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell", "background": "心理评估通常依赖于结构化的评分量表，但这些方法无法捕捉受访者自然语言中的丰富细微差异。本研究利用了最近的LLM（大语言模型）进步，将定性数据纳入一个新颖的概念框架中，结合LLM评分文本和传统的评级量表项目，构建了一个扩增测试。该研究以抑郁症为例，使用实际样本（n=693名中学生）和相应的合成数据集（n=3,000）来开发和评估该框架。在独立测试集上，扩增测试在测量精度和准确性方面取得了统计学显著的提升。从LLM项目的增益信息相当于增加了原有19个项目测试的6.3到16个项目。\n", "innovation": "本研究通过利用LLM评分文本数据，提出了一个扩增传统量表测试的新框架。这种方法的创新之处在于，它不再依赖于预标记的数据或复杂的专家制定的评分标准，而是通过计算每个项目的增益信息来实证选择最具有信息量的LLM评分指令。这一框架为利用不断增加的转录文本增强传统心理测量提供了可扩展的方法，显示出在临床卫生和其他领域的潜在用途。\n", "conclusion": "该方法标志着自动化评分概念上的转变，能够绕过传统瓶颈，例如无需基于预标记的数据或复杂的专家制定的评分标准。通过使用LLM评分文本数据，可以显著提高心理评估的精确度和准确性。此外，该框架具有通过利用不断增加的自然语言数据增强传统心理测量指标的潜力，为临床健康领域及其他领域提供了新机遇。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08666", "html_url": "https://arxiv.org/abs/2510.08666", "title": "dInfer: 一种高效的扩散语言模型推理框架", "title_en": "dInfer: An Efficient Inference Framework for Diffusion Language Models", "authors": "Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng", "background": "扩散基础的大语言模型（dLLMs）作为自回归（AR）大语言模型的潜在替代方案出现，利用基于去噪的生成技术实现固有的并行处理。尽管越来越多的开源dLLM模型涌现，但它们的广泛应用受限于缺乏有效的推理框架。因此，需要开发一种高效且可扩展的推理框架来支持dLLMs。", "innovation": "dInfer提供了一个高效的扩展推理框架，将推理流水线分解为四个模块模型、扩散迭代管理器、解码策略和KV缓存管理器，并在每个模块中整合了新的算法，同时实现了系统级别的优化。dInfer在LLaDA-MoE上保持输出质量的前提下，实现了显著的效率提升。在批量大小为1的情况下，dInfer在HumanEval上达到每秒超过1100个标记，并在八个H800GPU上六项基准测试中平均超过每秒800个标记。与先前的系统相比，dInfer在Fast-dLLM上提供了10倍的速度提升，同时保持了类似的模型性能。即使是与优化程度极高的AR模型QWen2.5-3B（带有可比的激活参数数量和性能）相比，dInfer也提供了2到3倍的速度改进。", "conclusion": "dInfer通过模块化设计、新颖算法和系统优化，实现了高效、可扩展的dLLM推理框架。该框架在保持高质量输出的同时，显著提高了推理速度，甚至超越了优化程度很高的AR模型，展示了其在实际应用中的潜力。dInfer的实现已经开源。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08669", "html_url": "https://arxiv.org/abs/2510.08669", "title": "FreqCa: 通过频率感知缓存加速扩散模型", "title_en": "FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching", "authors": "Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang", "background": "扩散变压器的应用受到显著推断成本的限制。最近，特征缓存被提出通过重复利用之前时间步的特征，从而在未来的步骤跳过计算。然而，先前的特征缓存假设相邻时间步的特征相似或连续，这并非在所有设置中都成立。这项研究从频域进行了分析，揭示了扩散模型的特征在不同时间步表现出不同的动态，低频分量具备高相似性但缺乏连续性，而高频分量具备显著的连续性但相似性较差。基于这些观察，提出了一种频率感知缓存（FreqCa），直接重用基于相似性的低频分量的特征，同时使用二次海明插值器根据其连续性预测不稳定的高频分量。此外，还提出了缓存累计残差特征（CRF），而不是缓存所有层的特征，这将特征缓存的内存足迹减少了99%。", "innovation": "提出了频率感知缓存（FreqCa）技术，该技术重用了低频分量的特征并且利用二次海明插值器预测高频分量。此外，提出了缓存累计残差特征（CRF）来减少缓存的内存占用。", "conclusion": "广泛的实验表明，该方法在生成和编辑方面都具有有效性。源代码已在附录中提供，并将在GitHub上发布。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08722", "html_url": "https://arxiv.org/abs/2510.08722", "title": "利用语义对增强自我监督学习：一个新数据集和实证研究", "title_en": "Enhancing Self-Supervised Learning with Semantic Pairs A New Dataset and Empirical Study", "authors": "Mohammad Alkhalefi,Georgios Leontidis,Mingjun Zhong", "background": "实例区别是一种自我监督的表示学习范式，其中数据集中的单个实例被视为不同的类别。这通常通过对每个实例应用随机变换来生成两个不同的视图来实现，以鼓励模型学习跨这些视图不变的表示。", "innovation": "该研究提出了一种新的数据集和实证方法，通过引入语义对来增强自我监督学习。语义对能够更好地捕捉实例间的语义关联，从而提升模型的表示能力和泛化能力。", "conclusion": "通过引入语义对，研究展示了自我监督学习在训练过程中性能的显著提升，并通过实验证明了新数据集的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08741", "html_url": "https://arxiv.org/abs/2510.08741", "title": "从上下文获取坐标：使用LLM定位复杂位置参考", "title_en": "Coordinates from Context: Using LLMs to Ground Complex Location References", "authors": "Tessa Masis,Brendan O'Connor", "background": "地址解析是将位置参考链接到实际地理位置的任务，并且对于许多未结构化文本的下游分析至关重要。本文探讨了组合位置参考的地址解析难题。基于最近的研究表明大型语言模型（LLMs）在处理地理数据方面的推理能力，作者评估了LLMs在空间知识与任务相关的推理技能之间的差异。基于这些见解，作者提出了一种基于LLM的策略来解析组合位置参考，展示了该方法在任务中性能的提升并且证明了一种相对较小的微调LLM可以达到与更大现成模型相近的性能。", "innovation": "该论文提出了基于LLM的策略来解析组合位置参考，并且证明了相对较小的微调LLM可以达到与更大现成模型相近的性能。", "conclusion": "作者展示了该方法对于任务性能的提升，并证明了一种相对较小的微调LLM可以达到与更大现成模型相近的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08711", "html_url": "https://arxiv.org/abs/2510.08711", "title": "非稳态MIMO均衡的上下文学习", "title_en": "In-Context Learning for Non-Stationary MIMO Equalization", "authors": "Jiachen Jiang,Zhen Qin,Zhihui Zhu", "background": "信道均衡是减轻频率选择性衰落和符号间干扰等失真的基础。与需要重新训练或微调的常规监督学习方法不同，上下文学习（ICL）在推理阶段仅需少量示例即可适应新信道。现有的ICL基均衡器主要针对静态信道并在上下文窗口内进行评估。然而，据我们所知，有关ICL的先前原理分析和理论研究仅集中在固定功能的稳态设置中。本文通过时变信道均衡的视角探讨ICL解决非稳态问题的能力。", "innovation": "本文提出了一种基于上下文学习的非稳态MIMO均衡方法。通过从自适应信号处理算法中汲取灵感，设计高效的注意机制以增强非稳态任务中的自适应性。所提方法包括从最小均方（LMS）自适应算法衍生的新注意力变体，以及用于增强鲁棒性的最小平方根均值平方（LRMS）公式，以及改进长期跟踪的多步梯度更新。", "conclusion": "实验结果表明，ICL在非稳态MIMO均衡中有很大的潜力，并且启发式自适应算法可以显著提高动态环境中的适应性和性能。这些发现可能为开发具有更强适应性和鲁棒性的下一代无线基础模型提供重要见解。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08705", "html_url": "https://arxiv.org/abs/2510.08705", "title": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing", "title_en": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing", "authors": "Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser", "background": "在杂乱环境中进行物体运输是家庭服务和仓库物流等多个领域的基本任务。在协同物体运输中，多台机器人需要协调合作以移动单个机器人无法搬运的大型物体。推物体是一种常用的运输策略，只需简单的机器人，但选择合适的接触点对于沿预规划路径推动物体至关重要。尽管可以解析地解决接触点选择问题，但由于接触点数量与机器人数量和物体尺寸成组合方式增长，该方法在扩展性方面受限。如何有效选择接触点以实现高效协同运输成为亟待解决的问题。人类在合作运输过程中依赖常识推理，因此研究者们尝试结合大语言模型与局部搜索方法来优化接触点选择问题。", "innovation": "提出了一种结合大语言模型（LLM）指导的局部搜索方法（ConPoSe），以选择合适的接触点用于协同推动物体。ConPoSe能够适应不同形状的物体（包括长方体、圆柱体和T形物体），并且相比解析方法和纯粹基于LLM的选择方法，ConPoSe在机器人数量和物体尺寸增加时展现出更好的扩展性，从而提高了协同操作的效率和灵活性。", "conclusion": "ConPoSe通过结合大语言模型和局部搜索方法，有效解决了协同推动物体中的接触点选择问题，提升了在多机器人和大型物体情况下的扩展性能，并在实际应用中展示了优于解析方法和纯粹基于大语言模型选择的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08744", "html_url": "https://arxiv.org/abs/2510.08744", "title": "基于图扩散变换器的体内外分子设计师", "title_en": "Graph Diffusion Transformers are In-Context Molecular Designers", "authors": "Gang Liu,Jie Chen,Yihan Zhu,Michael Sun,Tengfei Luo,Nitesh V Chawla,Meng Jiang", "background": "在上下文学习中，大型模型可以从少量示范中适应新任务，但在分子设计领域效果有限。现有的如ChEMBL等数据库包含了数百万个生物活性测试中的分子属性，但每个属性的标注数据仍然稀缺。", "innovation": "该文引入了示范条件下的扩散模型（DemoDiff），使用少量分子-分数示例来定义任务上下文，而非依赖文本描述。通过这样的示范来引导去噪的Transformer生成与目标属性相匹配的分子。提出了新的基于节点对编码的分子标记方法，减少了5.5倍的节点数。文中构建了包含上千万个上下文任务的数据集并进行了预训练。结果表明，无论是在药物还是材料领域，DemoDiff均超过了规模高达其数百倍的语言模型，并在六类33个设计任务中，DemoDiff的平均排名为3.63，优于专门领域方法的5.25-10.20排名。这些结果反映了DemoDiff作为分子基础模型在体内外分子设计中的潜力。", "conclusion": "总而言之，我们提出了一种新的基于图扩散变换器的示范条件下的扩散模型（DemoDiff），它能够有效解决分子设计中数据稀缺的问题，并且在多种设计任务中表现出比现有方法更好的性能，为未来相关研究提供了新的思路。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08731", "html_url": "https://arxiv.org/abs/2510.08731", "title": "何时推理：针对vLLM的语义路由", "title_en": "When to Reason: Semantic Router for vLLM", "authors": "Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen", "background": "大型语言模型（LLMs）通过增强推理模式（如链式思考和推理时缩放）可以显著提高准确性，但推理也会导致推理延迟和token使用量的显著增加，从而带来环境和财务影响，对于许多简单的提示，这种额外的推理是不必要的。因此，需要一种机制，在保持准确性的前提下，减少不必要的推理过程，提高效率和响应速度。本研究提出了一种语义路由器，可以根据查询的推理需求对其进行分类，并仅在有益时应用推理。", "innovation": "研究提出了一种语义路由器，该路由器可以根据查询的推理需求对其进行分类，并仅在有益时应用推理。该方法在MMLU-Pro基准测试上实现了10.2个百分点的准确性提升，同时将响应延迟减少了47.1%，减少了48.5%的token消费量，相比直接对vLLM进行推理。这表明语义路由为开放源代码的大模型服务系统之间的准确性和效率平衡提供了一种有效的机制。", "conclusion": "语义路由是一种有效机制，能够在保留性能的前提下，减少不必要的推理过程，从而提高大型语言模型服务系统的效率。研究的结果表明，这种语义路由器能够在保持高准确性的同时，有效提高响应速度和减少资源消耗。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08697", "html_url": "https://arxiv.org/abs/2510.08697", "title": "BigCodeArena：通过执行揭示更可靠的代码生成人类偏好", "title_en": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "authors": "Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra", "background": "在众包模型评估平台如Chatbot Arena的帮助下，人类可以在实时评估中评估模型响应的质量。然而，在编程领域，手动检查大型语言模型（LLM）生成的内容质量非常具有挑战性，因为这需要理解大量的原始代码，并打算模拟代码执行。为解决这一问题，研究人员提出BigCodeArena，这是一个提供全面且实时执行环境的开源人类评估平台，专门用于代码生成。BigCodeArena基于Chatbot Arena构建，能够执行LLM生成的代码，并使人类能够与执行过程和结果进行交互。研究人员收集了来自10种广泛使用的LLM的超过14,000个以代码为中心的对话会话，覆盖10种编程语言和8种执行环境。在这个过程中，他们还确定了4,700多个具有人类偏好两两对比的多轮对话样本。", "innovation": "提出了BigCodeArena作为用于代码生成的开源人类评估平台，极大缓解了手动评估LLM生成代码的挑战。BigCodeArena为每个LLM生成的代码提供了执行环境，并帮助研究人员发现了几十种编程语言和实现环境下的具体细粒度领域的偏好差异。基于上述数据，研究人员构建了两个基准：BigCodeReward和AutoCodeArena。BigCodeReward通过对4,700个对话进行后处理，评估奖励模型与人类偏好之间的一致性。AutoCodeArena是一种自动Elo评分基准，无需人类参与即可评估LLM的编程质量。研究表明，像GPT-5、Claude-Sonnet-4和Claude-Opus-4这样的专有LLM在最近涌现的模型中仍处于代码生成性能的领先地位，虽然尚未完全实现自动化评估，但显示出自动评估的有效性。", "conclusion": "BigCodeArena通过引入全面的执行环境，为代码生成领域的自动评估提供了平台，发现并解析了LLM在编程任务、语言和框架下的细粒度偏好。BigCodeArena上的两个基准BigCodeReward和AutoCodeArena分别改善了对代码生成的解读和自动评估过程。当前，虽然专有LLM在代码生成性能上处于领先地位，但研究结果为全面自动评估LLM质量提供了坚实的基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08761", "html_url": "https://arxiv.org/abs/2510.08761", "title": "SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense", "title_en": "SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense", "authors": "Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu", "background": "对抗攻击严重挑战了深度学习模型的安全部署，尤其是在实际应用中。传统防御方法通常依赖于计算密集型优化（例如对抗训练或数据增强）来提高鲁棒性，而人类视觉系统则通过进化生物学机制天生具有对抗扰动的鲁棒性。我们假设注意力引导的非均匀稀疏采样和预测编码在这一鲁棒性中起着关键作用。", "innovation": "提出了一种新颖的生物灵感防御框架，结合了三种关键的生物学机制：中心-外周处理、宋氏眼动和皮层补全。该方法利用强化学习引导的宋氏眼动来选择性地捕捉多个中心-外周视见，将其整合到重建图像中以供分类。这种生物启发的预处理有效地缓解了对抗噪声，保持了语义完整性，并且无需重新训练或微调下游分类器，能够无缝融入现有系统。", "conclusion": "在ImageNet数据集上的实验表明，该方法在各种分类器和攻击类型上提高了系统的鲁棒性，并且相比生物和非生物启发的防御技术，显著减少了训练开销。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08774", "html_url": "https://arxiv.org/abs/2510.08774", "title": "Struc-EMB：语言嵌入中结构意识编码的潜力", "title_en": "Struc-EMB: The Potential of Structure-Aware Encoding in Language Embeddings", "authors": "Shikun Liu,Haoyu Wang,Mufei Li,Pan Li", "background": "大型语言模型（LLMs）产生的文本嵌入已成为许多应用的基础，但这些模型通常仅处理原始文本，忽略了许多真实世界数据集中至关重要的结构信息，如超链接或引用。这限制了现有嵌入的有效性和准确性。本文分析了在LLM内部直接整合结构关系以生成结构感知文本嵌入的问题，并通过零样本实验展示了结构感知方法在检索、聚类、分类和推荐等多种任务中的优越性能，明确了两种主要的集成方法及其适用场景和局限性，并提出了一些对策来应对噪声结构数据的问题。", "innovation": "本文提出了并系统评估了一种新的在LLM内部直接整合结构关系的结构感知嵌入方法，分别探讨了顺序串联和并行缓存两种主要内部处理方法，通过大量零样本实验表明，结构感知方法在多种任务中均能超越仅基于文本和传统的后处理基准。介绍了两种有效应对噪声结构数据问题的技术：结构信息精炼和语义平衡，填补了内部结构感知编码分析的空白，为构建更具力量和上下文感知的嵌入模型提供了框架。", "conclusion": "研究表明，结构感知方法在多种任务中表现优越，但存在不同的局限性，提出了两种应对噪声结构数据的技术。本文提供了内部结构意识编码的第一个全面分析，为构建更强大和上下文感知的嵌入模型提供了蓝图。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08775", "html_url": "https://arxiv.org/abs/2510.08775", "title": "使用AI自动视频关键帧提取识别卷尾鹦鹉", "title_en": "Re-Identifying Kākā with AI-Automated Video Key Frame Extraction", "authors": "Paula Maddigan,Andrew Lensen,Rachael C. Shaw", "background": "对单独动物的准确识别和重新识别对于野生动植物种群监测至关重要。传统的标记方法，如鸟类的脚环标记，耗时且侵入性强。人工智能的进步，特别是计算机视觉，提供了智能保护和高效自动化的解决方案。Kākā（Nestor meridionalis）是一种新西兰具有威胁的森林鸟类，本文研究了从捕捉到Kākā的视频中提取高质量关键帧的独特管线。尽管关键帧提取在人员重新识别中研究较多，但在野生动物中的应用较少。", "innovation": "本文提出了一种结合了YOLO物体检测、Grounding DINO、光流模糊检测、DINOv2图像编码以及聚类方法的独特管线，以提取代表性的关键帧。该方法在Kākā重新识别的应用中显示出了高准确率。这种方法为在更复杂和多变的环境中收集的数据进行未来的研究提供了基础。通过这种方法，作者非侵入性且高效的方案提供了与传统物理标记方法相比识别Kākā个体的有价值替代品。", "conclusion": "本文通过使用人工智能和计算机视觉，开发了一种非侵入性和高效的方法来识别Kākā个体，为识别野生鸟类提供了新的途径，并在生态学和保护生物学领域具有应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08799", "html_url": "https://arxiv.org/abs/2510.08799", "title": "SkipSR: 快速超分辨率的新方法，通过跳过无用处理", "title_en": "SkipSR: Faster Super Resolution with Token Skipping", "authors": "Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni", "background": "基于扩散的超分辨率（SR）是视频生成和视频修复的关键组件，但处理速度慢且成本高，限制了其在更高分辨率和更长视频中的应用。当前的方法对所有像素进行均匀处理，即使许多视频区域本身低细节且不需要细化处理。", "innovation": "提出了SkipSR框架，通过直接从低分辨率输入中识别低细节区域并跳过这些区域的计算，仅对需要细化的区域进行超分辨率处理。这种简单有效的策略在保持感知质量的同时显著减少了计算量。", "conclusion": "在标准超分辨率基准测试中，该方法在720p视频上的端到端延迟比以前的模型快60%，而没有明显的质量损失。已经有视频演示可供查看。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08783", "html_url": "https://arxiv.org/abs/2510.08783", "title": "将MLLM作为UI裁判：评估多模态大语言模型预测用户界面感知的能力", "title_en": "MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces", "authors": "Reuben A. Luera,Ryan Rossi,Franck Dernoncourt,Samyadeep Basu,Sungchul Kim,Subhojyoti Mukherjee,Puneet Mathur,Ruiyi Zhang,Jihyung Kil,Nedim Lipka,Seunghyun Yoon,Jiuxiang Gu,Zichao Wang,Cindy Xiong Bearfield,Branislav Kveton", "background": "在理想的设计流程中，用户界面设计与用户研究紧密结合以验证决策的有效性。然而，在早期探索阶段，研究往往因资源限制而受限。近期，多模态大型语言模型（MLLM）的进步为早期评估提供了可能，帮助设计师在正式测试前缩小选项范围。以往研究重点关注特定领域如电商中的用户行为和点击率或转化率，但忽视了不同界面下主观用户评价的重要性。", "innovation": "本文的研究重点是多模态大语言模型能否模仿人类对单个用户界面和界面间的评价，使用众包平台的数据，对GPT-4o、Claude和Llama这三种模型在30种界面上的表现进行基准测试，评估其在多个界面因素上的与人类判断的契合度。研究结果显示，多模态大语言模型在某些维度上接近人类偏好，但在其他维度上则有所偏差，揭示了它们在补充早期用户体验研究方面既有的潜力和局限。", "conclusion": "综上所述，多模态大语言模型在部分方面可以模拟人类的偏好，但仍然存在显著差距，证明了它们在早期用户体验研究中的潜力和局限性，为其应用于用户界面设计领域提供了参考依据。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08776", "html_url": "https://arxiv.org/abs/2510.08776", "title": "测量多语言能力下的道德LLM响应", "title_en": "Measuring Moral LLM Responses in Multilingual Capacities", "authors": "Kimaya Basu,Savi Kolari,Allison Yu", "background": "随着大规模语言模型（LLM）的广泛应用，其在多语言情境下的回应理解与引导变得日益重要。为了评估和促进多语言环境下的LLM表现，已经创建了大规模数据集进行测试和基准测试。本研究评估了五种前沿开源模型在低资源和高资源语言上的五个维度的回应，以衡量LLM在多语言环境中的准确性和一致性。", "innovation": "研究采用五点评分标准和人工审查的方式评估模型的回应。结果显示GPT-5在所有类别中的表现最佳，而其他模型在语言和类别间则表现得更为不一致。特别是在Consent & Autonomy和Harm Prevention & Safety两个类别中，GPT-5的表现显著优于Gemini 2.5 Pro。这些发现凸显了对不同类型语言变化如何影响LLM回应的进一步测试需求，并强调在这些领域进行改进的重要性。", "conclusion": "研究发现GPT-5在大部分评估维度上表现最优，但其他模型则表现出较大的一致性问题。特别在涉及尊重与自主权以及预防和保障安全的领域，模型间的差异尤为明显。因此，未来还需更多测试来验证语言变化对LLM响应的影响，同时在这些领域提升模型表现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08800", "html_url": "https://arxiv.org/abs/2510.08800", "title": "以多步推理视角评估汉语常识推理", "title_en": "Benchmarking Chinese Commonsense Reasoning with a Multi-hop Reasoning Perspective", "authors": "Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang", "background": "尽管大型语言模型（LLMs）已经展示了先进的推理能力，但在一般汉语语境下的全面评估仍然不足。该研究旨在填补这一空白。", "innovation": "提出了一种名为CCMOR（Chinese Commonsense Multi-hop Reasoning）的新基准。该基准旨在评估LLMs整合汉语特定事实知识与多步逻辑推理的能力。通过构建领域平衡的种子集，并利用LLM生成基于事实单位链的多步问题，确保数据集的质量并采用领域专家的人工验证系统，CCMOR能够有效评估LLMs的推理能力。", "conclusion": "使用CCMOR评估了最先进的LLMs，发现这些模型在处理长尾知识和执行知识密集型推理方面存在持续性限制。检索增强生成方法在一定程度上缓解了这些知识空白，显著提升了性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08779", "html_url": "https://arxiv.org/abs/2510.08779", "title": "通过LLM增强观测指导强化学习探索", "title_en": "Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations", "authors": "Vaibhav Jain,Gerrit Grossmann", "background": "在稀疏奖励环境中，传统探索策略往往难以发现有效的动作序列，这使得基于强化学习（RL）的代理遇到挑战。尽管大型语言模型（LLMs）具备基于文本预训练的程序性知识和推理能力，可以指导RL探索，但现有方法往往使得RL策略必须遵循LLM的建议或直接将其纳入奖励函数中，这创建了硬依赖，限制了灵活性。因此，本文提出了一种框架，通过增强观测空间提供LLM生成的动作建议，这使RL代理能够学会何时遵循或忽略这种指导。这种方法利用了LLM的世界知识和推理能力，并通过软约束保持灵活性。实验评估了该方法在三个逐渐增加复杂度的BabyAI环境中的表现，并展示了LLM指导下的益处随着任务难度增加而递增。在最具有挑战性的环境中，与基线相比取得了71%的相对成功率提升。同时，该方法实现了显著的数据效率提升，代理能在不到基线的1/9的时间内达到性能阈值，并且不需要对现有的RL算法进行修改。结果显示，有效的利用LLM的计划能力能够加速在具有挑战性的环境中进行RL训练。", "innovation": "提出了一种框架，通过增强观测空间提供LLM生成的动作建议，使RL代理能够学会何时遵循或忽略这种指导。这种方法既利用了LLM的世界知识和推理能力，又通过软约束保持了灵活性。实验结果表明，该方法能显著提升在具有挑战性的环境中的数据效率和任务完成率，同时不需要对现有的RL算法进行任何修改。", "conclusion": "通过利用LLM的推理能力，在增强观测空间中提供其生成的动作建议，该方法使得RL探索更加灵活，同时在具有挑战性的环境中实现了显著的数据效率提升，其带来的益处随着任务难度的增加而增加。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08794", "html_url": "https://arxiv.org/abs/2510.08794", "title": "多臂强盗中的欺骗性探索", "title_en": "Deceptive Exploration in Multi-armed Bandits", "authors": "I. Arda Vurankaya,Mustafa O. Karabag,Wesley A. Suttle,Jesse Milzman,David Fridovich-Keil,Ufuk Topcu", "background": "本文考虑了一个公共奖励和私人奖励分布的多臂奖赏设置。观察者期望代理按照公共奖励的Thompson Sampling执行动作，而欺骗性代理试图快速识别出最优的私人臂无被观察到。观察者只能观察到公共奖励和被拉出的臂，而无法看到私人奖励。代理能够观察到公共奖励和私人奖励。这一背景设置需要解决如何在不被观察者注意到的情况下识别最优私人臂的问题，引入了检测性的概念，并以卡方距离为约束条件来量化这种检测性。", "innovation": "本文引入了一种新颖的多臂强盗问题（Deceptive Exploration in Multi-armed Bandits），其中观察者和被观察者的奖励信息不对等。此外，论文定义了检测性的概念，并通过基于公共和私人均值的极大极小问题模型识别最优私人臂。该模型提供了识别最优私人臂的最优错误指数，并提出了一种灵感来源于top-two算法的新算法，该算法能够根据公共亚最优性差距自动调整探索策略。该算法在数值例子中被证明遵循了Ο(√T)率，并展示了所提算法的行为。", "conclusion": "本文提出了一个可信度问题的新模型，并正式定义了检测性的步进Kullback-Leibler（KL）散度约束。研究了公开较差臂的抽取可以以Ο(√T)速率发生，提出了基于公共和私人均值的极大极小问题的优化方法，找到了最优错误指数，并提出了一种结合顶级臂策略的新算法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08818", "html_url": "https://arxiv.org/abs/2510.08818", "title": "D-CoDe: 通过动态压缩和问题分解将图像预训练VLM扩展到视频", "title_en": "D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition", "authors": "Yiyang Huang,Yizhou Wang,Yun Fu", "background": "视频大型语言模型（Vid-LLMs），在各种视频-语言任务中表现出色，可通过适应图像预训练视觉-语言模型（VLMs）来有效构建。然而，这一适应过程仍然具有挑战性，因为它需要处理密集且时间上延伸的视觉输入，这超出了基于图像的模型的容量。本文指出，感知瓶颈和标记过载是将基于图像的VLM扩展到视频领域的关键挑战。", "innovation": "本文提出了D-CoDe，一种无需训练的适应框架，结合了动态压缩和问题分解。动态压缩通过自适应选择代表帧和基于内容聚合空间标记来缓解感知瓶颈，从而减少冗余并保留信息内容。同时，问题分解通过将原始查询重新制定为子查询，使模型能够专注于视频的不同方面，从而促进更全面的理解。", "conclusion": "实验表明，D-CoDe在各种基准上有效提高了对视频的理解。此外，在复杂的长视频基准上的出色性能强调了D-CoDe在处理复杂的视频-语言任务方面的潜力。代码可在以下网址获取：this https URL。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08827", "html_url": "https://arxiv.org/abs/2510.08827", "title": "McMining: 自动发现学生代码中的编程错误概念", "title_en": "McMining: Automated Discovery of Misconceptions in Student Code", "authors": "Erfan Al-Hossami,Razvan Bunescu", "background": "在学习编程时，学生往往会形成各种编程语言概念的错误理解，这些错误理解不仅会导致错误或低效的代码，还会减缓相关概念的学习。本文的研究背景在于发展一种能够从学生代码样本中挖掘这些错误理解的方法。", "innovation": "本文介绍了一种新的任务McMining，即从学生代码样本中挖掘编程错误概念的任务。此外，通过开发一个包含大量代码样本的可扩展基准数据集，为McMining系统的设计和评估提供了支持。文中还提出了两种基于大型语言模型（LLM）的McMiner方法，并通过广泛的评估表明，Gemini、Claude和GPT系列模型在发现学生代码中的错误理解方面非常有效。", "conclusion": "研究通过McMining方法和基准数据集，展示了大型语言模型在发现学生代码中错误概念方面的有效性，为编程教学中的概念理解提供了新的途径。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08814", "html_url": "https://arxiv.org/abs/2510.08814", "title": "P ≠ NP: 一种通过量值弱化和几何复杂性非相对论性证明", "title_en": "$\\mathsf{P} \\neq \\mathsf{NP}$: A Non-Relativizing Proof via Quantale Weakness and Geometric Complexity", "authors": "Ben Goertzel", "background": "这篇论文提出了一个基于量值理论和信息论框架的复杂性类P与NP的关系分析。它探讨了如何通过弱化、对称性和稀疏性来得到多项式时间下的分布下界，挑战了自约简上界。该框架具体应用于掩码随机3-CNF集合，探讨了描述长度有限的解码器如何使得在一部分块上变得局域化，并通过特定的引理证明了在多项式时间内提供了一个线性下界，极大挑战了P=NP假设成立的可能性。论文中的证明是非相对论性的，展示了复杂性理论中经典方法的局限性。", "innovation": "论文的创新之处在于提出了一个新的基于量值理论的信息论框架，结合了对称性和稀疏性来证明与自约简上界矛盾的分布下界，特别是在多项式时间内解码器的局域化性质。这一新框架挑战了经典的P=NP等复杂性类主要假设，具有重要的理论意义。", "conclusion": "如果P=NP成立，那么存在一个固定的统一长度程序可以在多项式时间内对问题实例进行唯一解的检验，使得编码长度保持在常数级，从而导致聚合得到的复杂性小于线性级，这与论文中的线性下界相矛盾。因此论文得出结论，复杂性类P不等于NP。证明是相对论无关的，展示了传统方法在复杂性理论中的局限性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08812", "html_url": "https://arxiv.org/abs/2510.08812", "title": "在深空任务中使用离线信念状态规划实现自适应科学操作", "title_en": "Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning", "authors": "Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer", "background": "深空任务面临极端的通信延迟和环境不确定性，这使得地面实时操作变得不可行。在这种通信受限的环境中，支持自主科学操作的需求尤为迫切，为此，本文提出了一种部分可观测马尔可夫决策过程(POMDP)框架，该框架能够适应性地顺序安排航天器的科学仪器。为了有效管理光谱成像等高维度和不确定性测量数据，文中整合了一个贝叶斯网络到POMDP的观测空间中，以提高科学数据的可解释性和计算效率。操作策略在离线计算，确保了在发射前生成资源感知型计划并进行充分验证。", "innovation": "该研究引入了贝叶斯网络集成到部分可观测马尔可夫决策过程框架中，用于处理典型称为天体生物学任务的高维度和不确定测量数据。通过依靠贝叶斯网络结构和奖励塑造，生成了高效率的科学操作政策。比较了该方法与任务的基线概念操作（ConOps）的表现，实验结果显示该方法在样本识别错误率降低了近40%的情况下，总体表现更为优越。在流浪土卫二生命探测套件(Life Detection Suite, LDS)上进行了案例研究，演示了贝叶斯网络结构和奖励塑造对系统性能的影响。", "conclusion": "该研究提供了一种用于深空任务的先进算法，通过离线计算的操作策略以及贝叶斯网络的整合，显著提高了科学操作的自主性和效率，在非标准样本积累场景中的表现也得到了验证。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08839", "html_url": "https://arxiv.org/abs/2510.08839", "title": "基于强化学习的边缘管理以实现可靠的多视角3D重建", "title_en": "Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction", "authors": "Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy", "background": "实时多视角3D重建在如消防救援等关键边缘本地应用场景中至关重要，及时且准确的3D场景建模能够提供态势感知并支持决策。然而，边缘资源的动态和不可预测性引入了诸如图像质量下降、网络连接不稳定和服务器负荷波动等干扰，挑战了重建流程的可靠性。", "innovation": "本文提出了一种基于强化学习的边缘资源管理框架，旨在在资源受限且干扰频繁的环境中，保障在合理时间内高质量完成3D重建，特别地，框架采用两个合作的Q学习代理，一个用于相机选择，一个用于服务器选择，两者都完全在线运行，通过与边缘环境的交互学习策略。", "conclusion": "实验结果表明，所提出框架通过有效平衡端到端延迟与重建质量，在动态环境中增强了应用程序的可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08829", "html_url": "https://arxiv.org/abs/2510.08829", "title": "CommandSans：以手术级精确度清理指令保护AI代理", "title_en": "CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization", "authors": "Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader", "background": "随着能够访问大量工具和敏感数据的大规模语言模型（LLM）代理的日益采用，间接提示注入的攻击面被显著扩大。然而，由于攻击的上下文依赖性，当前的防御措施往往无法可靠地区分恶意和良性指令，导致较高的误报率，从而阻碍了它们的实际应用。", "innovation": "本文提出了一种新的方法，该方法基于计算机安全的基本原则：数据不应包含可执行指令。与现有的安全分类器不同，这种方法不依赖于样本级别的分类，而是提出了一种基于令牌级别的清理过程，这个过程可以精确地从工具输出中移除任何针对AI系统的指令，同时捕获恶意指令。该方法无需校准，不会阻碍功能，且对工具输出的上下文无感知。此外，这种基于令牌级别的预测器可以使用现成的指令调优数据进行训练，无需依赖挑战或合成起源的虚假提示注入示例。", "conclusion": "实验结果表明，该方法在多种攻击和基准测试（如AgentDojo、BIPIA、InjecAgent、ASB和SEP）上表现良好，成功降低了攻击成功率（ASR）约7-10倍（在AgentDojo上从34%降至3%），且不损害代理在良性或恶意环境中的实用性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08855", "html_url": "https://arxiv.org/abs/2510.08855", "title": "时间感知特征选择：基于动态重要性评分的稳定稀疏自动编码器训练", "title_en": "Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training", "authors": "T. Ed Li,Junyu Ren", "background": "理解大型语言模型的内部表示对于确保其可靠性和安全性至关重要。少量自动编码器（SAEs）作为一种有希望的可解释性方法开始出现，但现有的SAE训练方法在特性吸收方面存在缺陷，即特征（或神经元）为了最小化$L_1$罚分，会相互吸收，这使得一致地识别和分析模型行为变得困难。", "innovation": "作者提出了一种新的训练方法，称为自适应时间掩码（ATM），它通过动态调整特征选择，跟踪激活幅度、频率和重建贡献来计算随着时间变化的重要性评分。ATM基于统计阈值计算这些重要性评分实现概率掩码机制，从而提供了一个更自然的特征选择过程。实验表明，与TopK和JumpReLU SAEs等现有方法相比，ATM能够显著降低吸收分数，同时保持卓越的重建质量。", "conclusion": "通过在Gemma-2-2b模型上的广泛实验，ATM被证明是学习神经网络中稳定、可解释特征的原理性解决方案，为更可靠的模型分析提供了基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08850", "html_url": "https://arxiv.org/abs/2510.08850", "title": "通过微调大语言模型实现面向仓库的文件路径检索", "title_en": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs", "authors": "Vasudha Yanuganti,Ishaan Puri,Swapnil Chhatre,Mantinder Singh,Ashok Jallepalli,Hritvik Shrivastava,Pradeep Kumar Sharma", "background": "现代代码库使得开发人员和AI编程助手在回答诸如“这个功能是如何工作的？”或“这个错误是在哪里引入的？”的问题时难以找到正确的源文件。传统的代码搜索方法（如关键词搜索或基于信息检索的方法）往往无法捕捉到语义上下文和跨文件链接，而大型语言模型虽然理解自然语言，但缺乏特定仓库的详细信息。因此，需要一种新方法来解决这个问题，使大语言模型能够从自然语言查询直接预测相关的文件路径。该方法通过优化的Qwen3-8B模型和QLoRA以及Unsloth优化等技术实现，同时引入了六种代码感知策略，将抽象语法树（AST）结构和仓库内容用于生成现实中的问题-答案对，其中答案是文件路径集。这些策略从单文件提示到层次化仓库摘要，提供了广泛的覆盖范围。实验表明，该方法在多个Python项目上的检索准确性较高，展示了良好的可扩展性。", "innovation": "提出了一种通过优化的Qwen3-8B模型和QLoRA以及Unsloth优化技术实现面向仓库的文件路径检索的方法。该方法引入了六种代码感知策略，将抽象语法树（AST）结构和仓库内容用于生成现实中的问题-答案对，其中答案是文件路径集。该方法通过训练获得高度准确的检索结果，并展示了良好的可扩展性。", "conclusion": "通过多级代码信号帮助大语言模型跨越文件上下文进行推理，并讨论了数据集设计、限制（例如，在非常大的仓库中，上下文长度的限制）以及检索与基于大语言模型的代码智能的未来整合。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08876", "html_url": "https://arxiv.org/abs/2510.08876", "title": "基于向量图的仓库理解用于问题驱动的文件检索", "title_en": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval", "authors": "Kostiantyn Bevziuk,Andrii Fatula,Svetozar Lashin Yaroslav Opanasenko,Anna Tukhtarova,Ashok Jallepalli Pradeepkumar Sharma,Hritvik Shrivastava", "background": "现有软件仓库通常庞大且结构复杂，手动管理和开发这些仓库变得困难。因此，需要一种系统来更好地理解和自动管理大型软件仓库的结构和内容。", "innovation": "该系统提出了一个仓库分解系统，能够将大型软件仓库转换为向量化的知识图谱，该图谱反映了项目的架构和语义结构，捕获了语义关系并允许进一步仓库开发中的显著自动化。该图谱编码了语法关系（如包含、实现、引用、调用、继承），并通过LLM（大型语言模型）获取的总结和向量嵌入来增强节点。此外，该系统结合了基于图的检索和LLM助手，以出具人类可读的解释。", "conclusion": "该系统通过将大型软件仓库转换为向量化的知识图谱，并结合LLM助手处理和解释，提供了一种新的问题驱动的文件检索方法，提高了文件检索的效率和准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08874", "html_url": "https://arxiv.org/abs/2510.08874", "title": "Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication", "title_en": "Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication", "authors": "Benjamin Brock,Renato Golin", "background": "许多科学、数据分析和AI工作负载依赖于分布式矩阵乘法。现有工作已经开发了一系列针对不同问题规模和分割的算法，包括1D、2D、1.5D和2.5D算法。然而，现有算法仅支持部分分割方式，因此需要多种算法实现来支持所有可能的分割组合。如果特定的分割方式没有可用的算法实现，则需要重新分布操作数，从而增加通信成本。本文旨在提出一个支持所有分割组合和复制因子的通用单边分布式矩阵乘法算法，以解决这一限制。", "innovation": "本文提出了一种基于切片（索引算术）的通用单边分布式矩阵乘法算法，能够支持所有可能的分割组合和复制因子。这种算法直接通过节点内部互联进行GPU到GPU的直接通信，实现高效计算。与现有的高性能分布式张量库PyTorch DTensor相比，该算法具有竞争力。", "conclusion": "我们的工作证明了一种基于切片的算法能够高效支持所有分布矩阵分割的计算需求，相比现有的实现方法能更灵活地处理各种情况，降低通信成本，提高整体性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08892", "html_url": "https://arxiv.org/abs/2510.08892", "title": "在RLVR中探索多温度策略的令牌级和展开级控制", "title_en": "Exploring Multi-Temperature Strategies for Token- and Rollout-Level Control in RLVR", "authors": "Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang", "background": "强化学习（RL）已经在大型语言模型（LLMs）的推理能力方面取得了显著进步，显示了其在多个领域的广泛应用。此前的研究发现，LLMs中的令牌在推理任务中扮演着不同的角色，可以分为高熵推理令牌和低熵知识令牌。现有的方法主要通过间接手段限制更新来促进探索，但并未在生成阶段明确地促进探索行为。", "innovation": "本文提出了一种新的方法，在采样时通过为不同类型的令牌应用不同的温度设置来明确促进探索。这种策略通过增加推理令牌的温度来积极促进探索，同时通过保持较低温度来维持知识令牌的真实性。此外，还系统研究了各种多温度调度策略及其在强化学习中的影响。实验证明，该方法显著提高了LLMs的推理性能。", "conclusion": "我们在多个推理基准上进行了实证评估，结果显示我们的方法显著提升了LLMs的推理效果。该方法通过在采样过程中分温度控制令牌的不同类型，有力地促进了探索行为，从而提高了模型的灵活性和准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08878", "html_url": "https://arxiv.org/abs/2510.08878", "title": "ControlAudio：通过渐进扩散模型应对由文本指导、时间指示和可理解性音频生成的挑战", "title_en": "ControlAudio: Tackling Text-Guided, Timing-Indicated and Intelligible Audio Generation via Progressive Diffusion Modeling", "authors": "Yuxuan Jiang,Zehua Chen,Zeqian Ju,Yusheng Dai,Weibei Dou,Jun Zhu", "background": "文本到音频（TTA）生成在过去的研究中已经进行了探索，尤其是加入了精确的时间控制和可理解的语音内容等细粒度控制信号。然而，由于数据稀缺，其大规模生成时的表现仍然受限。", "innovation": "本文将可控制的TTA生成重新定义为多任务学习问题，并引入了渐进扩散建模方法ControlAudio。该方法通过逐步策略适应更详细的文本、时间以及音素特征条件分布，并在第1步中提出了涵盖注释和模拟的建模数据生成方法，扩展了可控性。在模型训练阶段，使用大规模文本-音频对预训练扩散变换器（DiT），并在第2步中通过统一的语义表示逐步整合时间和音素特征。最后，提出了逐步引导生成，在推断阶段顺序强调详细的控制信息，适应扩散变换器的粗细采样性质。实验结果表明，ControlAudio在时间准确性和语音清晰度方面达到了最先进的性能，显著优于现有的方法。", "conclusion": "ControlAudio在客观和主观评估中显著优于现有方法，取得了最新技术水平的TTA生成，在时间和语音清晰度上表现优异。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08859", "html_url": "https://arxiv.org/abs/2510.08859", "title": "模式增强的多轮越狱：利用大型语言模型的结构性漏洞", "title_en": "Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models", "authors": "Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma", "background": "大型语言模型（LLMs）对于多轮囚笼攻击仍然存在脆弱性，这些攻击通过利用对话上下文逐渐绕过安全限制。现有的多轮囚笼攻击方法通常依赖于启发式或临时的探索策略，对于模型的根本弱点缺乏深入了解。跨不同伤害类别的对话模式与模型漏洞之间的关系仍不明确。这项研究提出了模式增强的链式攻击（Pattern Enhanced Chain of Attack，PE-CoA）框架，以通过自然对话构建有效的多轮囚笼攻击。通过在十个伤害类别中涵盖的十二个LLM上评估PE-CoA，研究揭示了特定模式的漏洞和模型行为特点：模型在不同对话模式下的鲁棒性不同，同一模型家族共享类似的失败模式。这项发现揭示了安全训练的局限性，并表明需要模式感知的防御措施.", "innovation": "提出了PE-CoA框架，通过自然对话构建有效的多轮囚笼攻击，并且与现有的探索策略相比，提供了深入的模型薄弱点理解。研究还揭示了模型在不同对话模式下的独特弱点，以及模型家族共享的失败模式。这些发现强调了安全训练的局限性，并指出了模式感知防御措施的需求.", "conclusion": "在十二个LLM中评估PE-CoA后，研究取得了当前最先进的性能，发现了模式特定的漏洞和模型的行为特征：模型在一种对话模式下的鲁棒性不一定会转移到其他模式，且模型家族共享相似的失败模式。这些发现表明，安全训练存在局限性，并表明需要建立模式感知的防御措施来增强模型的安全性."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08891", "html_url": "https://arxiv.org/abs/2510.08891", "title": "设计和评估AI驱动的沉浸式跨学科模拟（AIMS）以促进跨专业教育", "title_en": "Designing and Evaluating an AI-driven Immersive Multidisciplinary Simulation (AIMS) for Interprofessional Education", "authors": "Ruijie Wang,Jie Lu,Bo Pei,Evonne Jones,Jamey Brinson,Timothy Brown", "background": "跨专业教育长期以来依赖案例研究和标准化患者来支持医护人员之间的团队合作、沟通及其相关协作能力。但传统方法往往受限于成本、扩展性和无法模拟真实临床场景的动态复杂性。为了应对这些挑战，我们设计并开发了AIMS（AI增强的沉浸式多学科模拟），这是一种将大语言模型（Gemini-2.5-Flash）、基于Unity的虚拟环境引擎和角色生成流水线整合在一起的虚拟模拟。AIMS旨在增强药学、医学、护理和社工学生之间的协作性临床推理和健康促进技能。", "innovation": " francais: AIMS采用了AI增强技术，通过虚拟环境和角色生成技术提供了一种新颖的交互方式，支持与虚拟患者的同步多模态互动。这种方法提高了跨专业教育的真实性和专业特定性，可以更好地模拟复杂的真实世界临床情境，有助于解决传统方法的局限性。AIMS的设计包括用户体验测试，通过用户角色扮演角色，参与模拟对话，来验证其有效性和可靠性。通过识别并解决使用过程中发现的问题，改进了模拟的真实性和适用性。", "conclusion": "AIMS支持现实、专业特定且上下文恰当的对话。讨论了AIMS的技术和教学创新，并提出了未来的研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08899", "html_url": "https://arxiv.org/abs/2510.08899", "title": "揭秘关键步骤：可验证强化学习中的归因信用分配", "title_en": "Pinpointing crucial steps: Attribution-based Credit Assignment for Verifiable Reinforcement Learning", "authors": "Junxi Yin,Haisen Luo,Zhenyu Li,Yihua Liu,Dan Liu,Zequn Li,Xiaohang Xu", "background": "当前基于可验证奖励（Verifiable Rewards）的强化学习（Reinforcement Learning with Verifiable Rewards，RLVR）能够提高大规模语言模型（LLMs）的复杂推理能力，但现有方法难以平衡探索与利用之间的关系，导致诸如中间步骤的奖励分配不准确以及熵坍塌等关键问题，这些问题限制了模型的性能。", "innovation": "本文提出了基于归因的策略优化中的贡献度（Attribution-based Contribution to Policy Optimization，ACPO）框架，该框架包含一个难度感知的课程计划，通过轨迹语义分割和基于归因的表示动态调节策略的熵，从而缓解了熵坍塌问题，同时还增强了各推理步骤的贡献度的精确量化，并确保了准确的奖励分配。", "conclusion": "在包括AIME、MATH和AMC等具有挑战性的基准测试中，ACPO方法明显优于现有的先进方法，展示出显著的性能提升。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08902", "html_url": "https://arxiv.org/abs/2510.08902", "title": "以大型语言模型为基础的统一生物医学命名实体识别框架", "title_en": "A Unified Biomedical Named Entity Recognition Framework with Large Language Models", "authors": "Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin", "background": "准确识别生物医学命名实体对于医学信息抽取和知识发现至关重要。然而，现有方法在处理嵌套实体、实体边界模糊和跨语言泛化方面常遇到困难。", "innovation": "本文提出了一种基于大型语言模型的统一生物医学命名实体识别（BioNER）框架。首先将BioNER重新定义为一个文本生成任务，并设计了一种符号化的标注策略来同时处理平坦实体和嵌套实体，并明确标注边界。为了增强多语言和多任务泛化能力，进行了跨多个中英文数据集的双语联合微调。引入了基于对比学习的实体筛选器，通过利用边界敏感的正样本和负样本，筛选出错误或虚假的预测。实验结果显示，该方法在四个基准数据集和两个未见过的语料库上实现了最先进的性能和稳健的零样本泛化能力。源代码可在此处自由获取。", "conclusion": "我们的方法在多个数据集上达到了最先进的性能，并且具有跨语言的稳健零样本泛化能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08896", "html_url": "https://arxiv.org/abs/2510.08896", "title": "HES-SQL：结构化框架指导下的高效文本到SQL的混合推理", "title_en": "HES-SQL: Hybrid Reasoning for Efficient Text-to-SQL with Structural Skeleton Guidance", "authors": "Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun", "background": "当前的Text-to-SQL生成框架在生成SQL查询时，主要依赖于监督细调，并缺乏有效的机制来最大化查询的执行效率。最新的研究提出了将思考模式融合的监督微调与组相对策略优化相结合的方法来提升Text-to-SQL的生成能力。然而，这些方法可能在保证查询准确性的同时，牺牲了查询的执行效率。本文通过引入一种新的混合训练框架，旨在提升Text-to-SQL查询的准确性和执行效率。", "innovation": "一、引入了一种骨架完整度评分机制，增强了生成的查询与最优SQL结构之间的偏好对齐。二、提出了一个查询延迟感知的奖励机制，以激励生成计算效率更高的SQL查询。三、设计了一种自我蒸馏过程，用于完成思考模式，防止模型推理能力的退化。这种框架使混合推理模型能够在推理和非推理模式之间切换，从而提高了SQL查询的准确性和执行效率。", "conclusion": "实验结果显示，HES-SQL在BIRD和KaggleDBQA基准测试中分别实现了79.14%和54.9%的执行准确性，相较于监督基线提高了11%至20%的效率。该研究建立了一种新的Text-to-SQL系统范式，通过执行导向的强化学习平衡了语义准确性和计算效率。提出的机制对于开发数据库的鲁棒自然语言接口具有重要意义，并且可以应用于需要同时优化正确性和效率的更广泛的结构化生成任务。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08936", "html_url": "https://arxiv.org/abs/2510.08936", "title": "RO-Bench: 使用文本驱动的对抗性视频的大规模鲁棒性评估", "title_en": "RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos", "authors": "Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang", "background": "最近，多模态大型语言模型（MLLMs）在各种视频理解任务中展示了显著的性能。然而，它们在面对操纵过的视频内容时的鲁棒性尚未被深入研究。", "innovation": "本文介绍了Ro-Bench，这是评估MLLMs在动态离分布（OOD）的对抗性视频测试集中的首个基准。Ro-Bench包含高质量、多样且具有时间相关性的视频数据，通过编辑Style、Object、Background及其组合。研究发现，当前的模型在面对伪造的视频内容时具有显著的性能下降，并证明通过使用对抗性数据进行微调可以显著提升鲁棒性。", "conclusion": "研究结果强调了对抗性数据在提高MLLMs视频理解能力方面的有效性。作者表示将很快发布代码和数据。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08930", "html_url": "https://arxiv.org/abs/2510.08930", "title": "共构自我：推荐系统中的兴趣反思人机界面", "title_en": "Co-Authoring the Self: A Human-AI Interface for Interest Reflection in Recommenders", "authors": "Ruixuan Sun,Junyuan Wang,Sanjali Roy,Joseph A. Konstan", "background": "自然语言驱动的用户画像在推荐系统中被研究，因其可解释性并且有可能帮助用户审视和调整自己的兴趣，从而提高推荐质量。在此基础上，本文介绍了一种电影推荐系统中的人工智能辅助用户画像，该设计通过可编辑的兴趣总结展示用户的电影历史，与静态画像不同，这种设计鼓励用户直接检查、修改和反思系统所做的推断。", "innovation": "本研究引入了一种新的交互模式，即人类与人工智能协作创建动态可编辑的用户兴趣画像，以促进用户对自身兴趣的理解和反思，这种新型的用户画像能持续发现用户感知兴趣与系统推断兴趣之间的差异，并通过增强用户交互和反映行为来促进推荐系统的透明性和信任度。", "conclusion": "在八个星期的在线现场部署中，本研究使用了1775名活跃的电影推荐用户，证明了这种人工智能辅助的用户画像能够在推荐系统中开启更透明、更值得信任的用户参与体验，同时也指出了未来需要改进的方向，以更好地利用不完善的AI驱动用户画像来促进更多的用户干预。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08908", "html_url": "https://arxiv.org/abs/2510.08908", "title": "多臂 bandit 问题的频域分析：探索与利用权衡的新视角", "title_en": "A Frequency-Domain Analysis of the Multi-Armed Bandit Problem: A New Perspective on the Exploration-Exploitation Trade-off", "authors": "Di Zhang", "background": "多臂 bandit (MAB) 问题是最基本的序贯决策模型之一，核心挑战在于探索与利用之间的权衡。尽管 Upper Confidence Bound (UCB)、Thompson Sampling 等算法及其后悔理论已经成熟，现有的分析主要从时间域和累积后悔的角度进行，难以描述学习过程的动态特性。", "innovation": "本文提出了一种新的频域分析框架，将 bandit 过程重新定义为信号处理问题。在这一框架中，每条手臂的奖励估计被视为频谱分量，不确定性对应于分量的频率，bandit 算法被解读为自适应滤波器。本文构建了频域 bandit 模型，并证明了主定理：UCB 算法中的置信界限项等同于应用于不确定频谱分量的时变增益，该增益与访问次数的平方根成反比。基于此，进一步推导了关于探索频率衰减的有限时间动态界。该理论不仅为经典算法提供了一种新颖而直观的物理解释，还为设计具有自适应参数调整的新一代算法奠定了坚实理论基础。", "conclusion": "本文不仅为经典算法提供了一种新颖的物理解释，还为设计具有自适应参数调整的新一代算法奠定了坚实的理论基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08962", "html_url": "https://arxiv.org/abs/2510.08962", "title": "低资源数据学习的分析性综述：从分析到研究", "title_en": "Analytical Survey of Learning with Low-Resource Data: From Analysis to Investigation", "authors": "Xiaofeng Cao,Mingwei Xu,Xin Yu,Jiangchao Yao,Wei Ye,Shengjun Huang,Minling Zhang,Ivor W. Tsang,Yew Soon Ong,James T. Kwok,Heng Tao Shen", "background": "高资源数据在人工智能中的应用取得了显著成功，但数据注释和模型训练的成本仍然很高。人工智能研究的基本目标是在有限资源数据下实现鲁棒化泛化。因此，本文基于PAC框架的无偏积极抽样理论分析了低资源数据学习中的泛化误差和标签复杂性。", "innovation": "研究采用无偏积极抽样理论在PAC框架下，分析了低资源数据学习中的泛化误差和标签复杂性。提出了针对低资源数据学习的一系列优化策略，包括梯度指导优化、元迭代优化、几何感知优化和大语言模型驱动优化。此外，全面概述了多种可以从低资源数据中受益的学习范式，包括领域迁移、强化反馈和层次结构建模。", "conclusion": "总结了低资源数据学习的关键发现，并强调了这些发现对低资源数据学习的潜在影响。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08956", "html_url": "https://arxiv.org/abs/2510.08956", "title": "软件项目中集体治理的人类行为基础", "title_en": "A Human Behavioral Baseline for Collective Governance in Software Projects", "authors": "Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey", "background": "本文研究了开源社区通过版本控制系统治理文件来描述参与和控制的方式。研究基于710个具有配对快照的项目集，解析文本为行动者、规则、行动和对象，再进行分组和度量变动，通过均匀性、丰富性、杰恩-沙恩夫斯特兰德散度来衡量变化情况。研究结果表明，随着时间推移，项目定义更多的角色和更多行动，并且这些角色和行动变得更加均衡，而规则的组成保持稳定。这些发现表明，治理通过扩展和平衡参与的类别来增长，而不会发生大的规范性变革。", "innovation": "研究通过解析和度量文本，创新性地评估了项目的治理增长方式，并提供了未来由AI介导的工作流程集中的程度或分配权力的基准线。", "conclusion": "这些发现揭示了治理的增长是如何通过扩展和平衡参与类别而不是急剧改变规范性作用来实现的。这种分析提供了衡量未来由AI管理的工作流程中心化或分散化的基准。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08948", "html_url": "https://arxiv.org/abs/2510.08948", "title": "SHERLOCK：利用大语言模型增强的电子商务风险管理中的动态知识适应", "title_en": "SHERLOCK: Towards Dynamic Knowledge Adaptation in LLM-enhanced E-commerce Risk Management", "authors": "Nan Lu,Yurong Hu,Jiaquan Fang,Yan Liu,Rui Dong,Yiming Wang,Rui Lin,Shaoyi Xu", "background": "电子商务行业的快速增长加剧了暗经济参与者与风险管理团队之间的对抗动态。企业通常会对可疑案例进行风险调查，以识别新兴的欺诈模式，从而提升预防性风险管理和事后的治理措施。然而，大量的案例分析给风险管理分析师带来了巨大的工作量，每件案件都需要长期专家经验的整合和对多个风险维度的细致审查。此外，分析师之间的个体差异性妨碍了建立统一且高标准的工作流。", "innovation": "我们提出了SHERLOCK框架，利用大语言模型（LLMs）的推理能力来协助分析师进行风险调查。我们的方法包括三个主要组件：(1)从多模态数据中提取风险管理知识并构建领域知识库（KB），(2)建立一个由数据飞轮范式指导的智能平台，该平台整合了日常工作、专家注释和模型评估，并通过迭代微调来实现偏好对齐，(3)引入了一个反思与改进（R&R）模块，该模块与领域KB协作，以快速响应不断变化的风险模式。实验证明，我们的方法大大提高了LLM分析结果中事实对齐和风险定位的精确度。", "conclusion": "基于SHERLOCK框架的大语言模型系统部署在实际交易数据集上显著提升了风险管理人员的案件调查工作流程效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08968", "html_url": "https://arxiv.org/abs/2510.08968", "title": "学习正则化剂: 能够正则化的学习优化器", "title_en": "Learning Regularizers: Learning Optimizers that can Regularize", "authors": "Suraj Kumar Sahoo,Narayanan C Krishnan", "background": "学习优化器（LOs）由于能够参数化和训练来高效地优化问题而逐渐受到关注。传统的梯度基优化方法通过使用如尖锐性感知最小化（SAM）、梯度模感知最小化（GAM）和差距引导的尖锐性感知最小化（GSAM）等明确的正则化技术来增强泛化和收敛性。", "innovation": "本文首次尝试通过训练学习优化器来学习和内部化传统正则化技术的效果，而无需显式地将这些正则化应用到目标函数中。通过广泛实验，说明带有正则化器的LOs在测试准确性和泛化方面始终优于未正则化的LOs，表明LOs能够学习并传递正则化效果，挑战了传统上需要明确为被优化目标函数提供正则化的必要性。", "conclusion": "学习优化器能够学习到正则化特性，这为优化过程的正则化提供了新的方法，为元学习和优化领域的研究开辟了新的途径。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08981", "html_url": "https://arxiv.org/abs/2510.08981", "title": "SEER: 可持续增强的软件需求工程", "title_en": "SEER: Sustainability Enhanced Engineering of Software Requirements", "authors": "Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi", "background": "软件开发的迅速扩张对环境、技术、社会和经济产生了重大影响。为实现联合国2030年可持续发展目标，开发者必须采用可持续实践。现有的方法大多提供高层次的指导，实施起来耗时且依赖团队的适应性，而且这些方法集中在设计或实现阶段，而可持续性评估应在需求工程阶段就开始进行。", "innovation": "本论文介绍了SEER框架，它针对软件开发的早期阶段解决可持续性问题。该框架通过三个阶段工作：首先，从通用分类中识别特定软件产品的相关可持续性需求（SRs）；其次，基于已识别的SRs评估系统需求的可持续性；最后，优化不符合任何SR的系统需求。该框架利用大型语言模型的推理能力和代理性的RAG（检索增强生成）方法进行实现。实验在四个不同领域的软件项目上进行，使用Gemini 2.5推理模型生成的结果证明了该方法在准确识别跨学科的广泛可持续性问题方面的有效性。", "conclusion": "SEER框架能够有效地在软件开发早期阶段解决可持续性问题，其利用大型语言模型的推理能力和RAG方法，通过三个阶段的工作，提高了软件需求工程阶段的可持续性评估和优化效果。实验结果证实了该方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08999", "html_url": "https://arxiv.org/abs/2510.08999", "title": "SQS：通过稀疏量化亚分布进行贝叶斯DNN压缩", "title_en": "SQS: Bayesian DNN Compression through Sparse Quantized Sub-distributions", "authors": "Ziyi Wang,Nan Jiang,Guang Lin,Qifan Song", "background": "在资源受限的设备上部署大规模神经网络模型时，压缩这些模型至关重要。大多数现有方法单独使用权重剪枝或低位宽量化，常常导致在保持可接受性能下降的同时，压缩率不理想。本文介绍了一种通过贝叶斯变分学习同时进行权重剪枝和低位宽量化的方法（SQS），在保持与先前方法相当的性能降低的同时，实现了更高的压缩率。关键在于采用尖刺-高斯混合模型来进行稀疏性和模型量化权重的诱导，从而实现低位宽精度的量化。", "innovation": "提出了一个联合权重剪枝和低位宽量化的统一框架（SQS），使用贝叶斯变分学习方法。通过引入尖刺和高斯混合模型，有效地实现了稀疏性和权重量化，从而提高了压缩率并保持了与现有方法相当的性能下降。", "conclusion": "在对ResNet、BERT-base、Llama3和Qwen2.5等模型进行压缩实验中，我们表明SQS方法在保持可比性能下降的同时达到了更高的压缩率，优于现有的多种方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09008", "html_url": "https://arxiv.org/abs/2510.09008", "title": "视觉标记的表征不确定性对于大型视觉-语言模型中物体幻觉的作用", "title_en": "On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models", "authors": "Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun", "background": "大型视觉-语言模型（LVLMs）将视觉编码器（VE）与大规模语言模型结合，已经在各种任务中取得了显著的成功。然而，LVLMs中仍然存在关键问题，如物体幻觉，即生成输入图像中不存在的物体的描述。", "innovation": "研究发现，视觉编码器中具有高表征不确定性的视觉标记是导致物体幻觉的关键因素。论文提出了一个简单且有效的策略，仅通过修改视觉编码器减少物体幻觉。该策略包括一个使用对抗性扰动的代理方法来高效识别具有不确定性的视觉标记，和在视觉编码器中间层的自注意过程中遮盖这些不确性的视觉标记，以抑制它们在视觉编码中的影响，从而缓解幻觉现象。", "conclusion": "大量实验表明，该方法显著降低了LVLMs中的物体幻觉，并且可以与其他现有技术协同工作。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08996", "html_url": "https://arxiv.org/abs/2510.08996", "title": "救赎 SWE-Bench：一种实现合理代理评估的基准变换方法", "title_en": "Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation", "authors": "Spandan Garg,Ben Steenhoek,Yufan Huang", "background": "现有的软件工程代理评估基准，如 SWE-Bench Verified，主要来源于 GitHub 问题，未能准确反映开发人员与集成开发环境（IDEs）中的聊天编码助手互动的方式。这种不匹配导致了代理在实际场景下的能力系统性高估，尤其是在修复错误方面。作者认为，这是由于现有的基准评估方法未能充分模拟开发人员的真实互动模式，特别是在使用聊天代理进行编程时。现有方法的不足促使他们开发了一种新的基准评估框架，该框架通过系统分析与聊天代理互动的开发者行为模式，将现有的正式基准转换为接近真实用户的查询。", "innovation": "作者提出了一种新的基准评估框架，通过系统分析开发人员与聊天代理互动的模式，将现有的正式基准转换为接近真实用户的查询。这种方法灵活且易于扩展到现有的基准。作者的应用证明这种方法可以大大减少现有的基准对代理能力的高估，这在公共基准测试中高达 50% 以上，在内部基准测试中约为 10-16%。", "conclusion": "这项工作通过基准变换技术为评估交互式聊天软件工程代理建立了新的范式。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08993", "html_url": "https://arxiv.org/abs/2510.08993", "title": "PlatformX: 一种端到端可迁移的能效神经架构搜索平台", "title_en": "PlatformX: An End-to-End Transferable Platform for Energy-Efficient Neural Architecture Search", "authors": "Xiaolong Tu,Dawei Chen,Kyungtae Han,Onur Altintas,Haoxin Wang", "background": "硬件感知的神经架构搜索（HW-NAS）已经成为了为边缘设备设计高效深度神经网络的强大工具。然而，现有的方法在实际部署中仍然具有显著的局限性，主要由于其高成本、需要大量的手动性能分析以及在具有复杂且设备特定能量行为的不同硬件平台上缺乏可扩展性。", "innovation": "本文提出了PlatformX，一种全自动化且可移植的HW-NAS框架，旨在克服上述限制。PlatformX集成了四个关键组件：(i) 能耗驱动的搜索空间，通过集成关键能耗配置扩展了传统的NAS设计，从而能够探索高效率架构；(ii) 跨设备可移植的内核级能耗预测器，并通过少量的设备上样本逐步改进；(iii) 基于帕累托的多目标搜索算法，平衡能耗和准确性以确定最佳权衡；(iv) 高分辨率运行时能耗分析系统，通过外部监控自动进行设备上的功率测量，无需人工干预。", "conclusion": "我们在多个移动平台上评估了PlatformX，结果显示它显著减少了搜索开销，同时保持了准确性和能耗的准确性。PlatformX能够识别出具有高达0.94的准确率或每次推理仅需0.16 mJ能耗的模型，这些模型在准确性和效率方面均优于MobileNet-V2。代码和教程可在该网址下载。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09017", "html_url": "https://arxiv.org/abs/2510.09017", "title": "值状态门控注意力机制以缓解Transformer中的极端现象", "title_en": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers", "authors": "Rui Bu,Haofeng Zhong,Wenzheng Chen,Yangyan Li", "background": "基于Transformer架构的大规模模型容易出现极端现象，如注意力坑和值状态漏斗。这些问题会降低模型性能、量化准确性和可解释性，其根源在于模型通过聚焦几乎没有价值状态的词项来学习一种低效的‘空操作’行为，形成了一种问题加剧机制。", "innovation": "该论文提出了值状态门控注意力（VGA）机制，这是一种简单且专用于快速高效执行‘空操作’注意力的稳定架构。VGA通过直接从值矢量（V）计算出的可学习数据相关门控，直接调节输出。通过底层梯度分析，研究证明自我功能门控值状态比之前基于输入嵌入的门控方法更有效解耦值和注意力分数更新。这种机制提供了一条直接的监管途径，使得模型能够根据其浮现起来的价值表示来抑制词项的贡献。", "conclusion": "实验证明VGA能显著减轻注意力坑的形成，稳定价值状态规范，提升模型性能，增强量化准确性和模型可解释性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09016", "html_url": "https://arxiv.org/abs/2510.09016", "title": "DiTSinger：使用扩散变换器和隐式对齐扩展歌唱声音合成", "title_en": "DiTSinger: Scaling Singing Voice Synthesis with Diffusion Transformer and Implicit Alignment", "authors": "Zongcai Du,Guilin Deng,Xiaofeng Guo,Xin Gao,Linke Li,Kaichang Cheng,Fubo Han,Siyu Yang,Peng Liu,Pan Zhong,Qiang Fu", "background": "最近基于扩散的歌声合成（SVS）取得了显著的表达能力，但仍受限于数据稀缺和模型扩展性。现有的SVS方法主要依赖于大量的人声数据，而获取这些数据往往代价高昂且难以操作。此外，模型的扩展性也是一个挑战，导致在生成高质量人声的同时处理大规模数据集变得困难。", "innovation": "该研究提出了一个两阶段的解决方案，首先通过固定旋律与多样化生成歌词配对，构建一个紧凑的种子人声集。随后，针对不同的旋律训练模型，生成超过500小时的高质量中文歌声数据。在此基础上，提出了DiTSinger，这种方法结合了RoPE和qk-norm的扩散变换器，并在深度、宽度和分辨率上进行系统扩展，从而提高音质和保真度。此外，设计了一种隐式对齐机制，通过在字符级别范围内约束音素-声学注意力，避免使用音素级别的持续时间标签，增强模型在噪音或不确定对齐条件下的鲁棒性。", "conclusion": "广泛的实验表明，该方法使歌声合成能够规模化、无需对齐且高质量实现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09025", "html_url": "https://arxiv.org/abs/2510.09025", "title": "通过混合模型进行非监督言语去混响", "title_en": "Déréverbération non-supervisée de la parole par modèle hybride", "authors": "Louis Bahrman(IDS, S2A),Mathieu Fontaine(IDS, S2A),Gaël Richard(IDS, S2A)", "background": "大多数现有算法依赖于干声/混响声配对数据，但这种数据难以获得。该论文提出了一种新的训练策略，通过仅使用混响声在无监督情况下改善言语去混响系统，无需依赖于难以获取的干声/混响声数据对。这种方法利用了有限的声学信息，如混响时间（RT60），来训练去混响系统，以实现更好的性能稳定性。", "innovation": "提出了一种新的非监督言语去混响训练策略，利用有限的声学信息如混响时间进行训练，不同于传统依赖干声/混响声配对数据的方法，该方法避免了数据收集上的困难，并能够在多种客观指标中实现更一致的性能。", "conclusion": "实验结果表明，该方法在各种客观指标中的表现更为一致，优于当前最先进的方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09041", "html_url": "https://arxiv.org/abs/2510.09041", "title": "智能总和约束博弈强化学习在自动驾驶中的鲁棒驾驶控制", "title_en": "Robust Driving Control for Autonomous Vehicles: An Intelligent General-sum Constrained Adversarial Reinforcement Learning Approach", "authors": "Junchao Fan,Xiaolin Chang", "background": "深度强化学习（DRL）在开发自动驾驶政策方面取得了显著的成功，但其对抗攻击的脆弱性仍然是在现实世界部署中的关键障碍。尽管现有的鲁棒方法已经取得了成功，但在应对更具策略性的威胁、引起关键安全性事件以及保持训练过程中学习的稳定性方面仍然存在不足。", "innovation": "本文提出了智能总和约束博弈强化学习（IGCARL），这是一种全新的鲁棒自动驾驶方法，结合了一个战略性目标攻击者和一个鲁棒的驾驶代理。该方法通过使用对抗攻击者的战略性协调多步攻击，利用DRL的时序决策能力，并通过采用总和目标以明确引起关键性安全性事件来解决传统方法的不足。此外，为了确保在对抗性环境中的稳定学习，并减轻对抗攻击造成的政策漂移，代理是在约束公式下进行优化。", "conclusion": "广泛的实验表明，IGCARL 在对抗攻击场景下的成功率至少比最先进的方法提高了 27.9%，显示出对对抗攻击的更优越的鲁棒性，以及增强了基于 DRL 的自动驾驶的安全性和可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09045", "html_url": "https://arxiv.org/abs/2510.09045", "title": "利用标识符替换实现LLM的成本效益型长代码翻译", "title_en": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements", "authors": "Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta", "background": "在软件开发领域，LLMs被用于自动化如代码翻译等一系列任务，即将源代码从一种编程语言翻译为另一种语言，并保持其功能不变。然而，LLMs在处理长代码时经常出现困难，因为长代码常常不会完全符合上下文窗口限制，这导致翻译不准确。", "innovation": "本文提出了一种新颖的零样本代码翻译方法，该方法结合了标识符替换技术。通过在翻译过程中用通用占位符代替用户提供的长标识符，该方法能够使LLMs专注于代码的逻辑结构，从而减少token数量和内存使用，提高长代码翻译的效率和成本效益。实验结果表明，该方法保留了语法和层次信息，并生成了具有较少token的翻译结果。", "conclusion": "该研究通过引入标识符替换技术，有效解决了LLMs在翻译长代码时的难题，提高了翻译的准确性，并且进一步提高了翻译过程的效率和成本效益。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09072", "html_url": "https://arxiv.org/abs/2510.09072", "title": "情绪解缠嵌入对齐用于噪声鲁棒和跨语料库语音情绪识别", "title_en": "Emotion-Disentangled Embedding Alignment for Noise-Robust and Cross-Corpus Speech Emotion Recognition", "authors": "Upasana Tiwari,Rupayan Chakraborty,Sunil Kumar Kopparapu", "background": "在真实场景中，语音情感识别的效果往往受噪音环境和不同数据集间变异性的阻碍。现有方法难以在复杂环境中保持情感识别模型的稳定性和泛化能力.", "innovation": "提出了一种两步方法，通过改进表示学习增强语音情感识别模型的鲁棒性和泛化能力。该方法首先利用情绪解缠表示学习（EDRL）提取分类特定的判别特征，同时保持情绪类别间的共同相似性。接着，多块嵌入对齐（MEA）将这些表示投影到与原始语音输入共变的最大化联合判别潜在子空间。利用从公开数据集中获取的干净样本训练情感分类器，最终在未见过的噪音和跨语料库语音样本上进行评估，展示了该方法在挑战性条件下的优越性能.", "conclusion": "在困难条件下，所提出的方法验证了其在噪声鲁棒性和跨语料库语音情感识别中的有效性."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09080", "html_url": "https://arxiv.org/abs/2510.09080", "title": "训练模型从人类反应中检测连续的机器人错误", "title_en": "Training Models to Detect Successive Robot Errors from Human Reactions", "authors": "Shannon Liu,Maria Teresa Parreira,Wendy Ju", "background": "随着机器人越来越多地融入社会，检测机器人错误对于有效的人机交互至关重要。当机器人反复出错时，它应该在何时改变行为以适应这种情况？研究表明人类会对机器人的错误给出不同层次的反应，在一次又一次的失败后，这些反应会从困惑、微妙的语言变化逐渐发展到明显的愤怒和不耐烦。之前的研究已经证实人类的反应可以表明机器人的错误，但很少有研究探讨这些不断变化的反应如何揭示连续的失败。", "innovation": "本研究使用机器学习来识别从人类反应中机器人失败的不同阶段。在26名参与者与一个反复出现对话错误的机器人互动的研究中，从视频数据中提取了行为特征，并为此建模了用户个体。最佳模型在检测错误方面的准确率为93.5%，在分类连续失败方面的准确率为84.1%。通过建模人类反应的进展来提高错误检测的准确性和理解重复的交互崩溃机制在人机交互中的内容。", "conclusion": "通过建模人类反应的进展来提高错误检测的准确性和理解重复的交互崩溃机制在人机交互中的内容。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09096", "html_url": "https://arxiv.org/abs/2510.09096", "title": "当机器人能力超过人类时：学习受限演示者的方法", "title_en": "When a Robot is More Capable than a Human: Learning from Constrained Demonstrators", "authors": "Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık", "background": "传统从演示学习方法使专家能够使用如仿生教学、操纵杆控制和模拟到现实的转移等接口来教机器人执行复杂的任务。然而，这些接口往往限制了专家演示最优行为的能力，因为它们包含了间接控制、设置限制和硬件安全等因素。例如，即使机器人可以在高维空间中操作，操纵杆也只能在二维平面中移动。因此，受限专家收集的演示数据导致学习到的策略表现不足。", "innovation": "我们提出的方法允许代理超越直接模仿专家行为，探索更短且更高效的轨迹。我们使用从演示中推断出的状态唯一奖励信号来衡量任务进度，并利用时间插值为未知状态自标签奖励。这种方法在样本效率和任务完成时间方面优于常见的模仿学习。", "conclusion": "我们的方法在实际的WidowX机器人手臂上实现了任务的完成，仅需12秒，比行为克隆快10倍，如真实机器人视频所示：https://thisurlisshown."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09090", "html_url": "https://arxiv.org/abs/2510.09090", "title": "AI与人类监督：一种基于风险的契合框架", "title_en": "AI and Human Oversight: A Risk-Based Framework for Alignment", "authors": "Laxmiraju Kandikatla,Branislav Radeljic", "background": "随着人工智能(AI)技术的不断进步，保护人类自主权和推进伦理决策变得至关重要，这对于培养信任和承担责任至关重要。人工智能系统应当积极保护并强化人类自主权。本文探讨了设计遵守基本人权、增强人类自主权并嵌入有效人类监督机制的AI系统策略。在讨论了包括人类在指挥中的人工智能(HIC)、人类在环中的人工智能(HITL)和人类在回路中的人工智能(HOTL)在内的关键监督模式后，本文提出了一种基于风险的框架来指导这些机制的实施。通过将AI模型的风险程度与适当的监督形式联系起来，文章强调了人类干预对于负责任部署AI的关键作用，从而在技术创新与个人价值观和权利保护之间取得平衡，旨在确保AI技术的负责任使用，保护个人自主权并最大化社会利益。", "innovation": "本文提出了一种基于风险的框架，以指导人类监督机制的实施。通过将AI模型的风险程度与其所需的人类监督形式进行关联，强调了在负责任使用AI的同时保护个人自主权和权利的重要性，是对现行监督机制的一种创新补充。", "conclusion": "本文旨在通过一种基于风险的框架确保AI技术的负责任使用，平衡技术创新与保护个人价值和权利之间的关系，从而最大化社会利益，同时保护个体的自主权。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：测量和缓解Differentially Private Machine Learning中组隐私风险的差异", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "在常规的公平感知机器学习(ML)和差异隐私机器学习(DPML)方面虽然已经取得了显著进展，但不同群体的隐私保护公平性仍然未被充分探索。现有的研究提出了评估群体隐私风险的方法，但这些方法基于数据记录的平均情况下的隐私风险，可能会低估群体间的隐私风险差异。此外，目前评估数据记录最坏情况隐私风险的方法耗时较长，限制了其在实际中的应用。", "innovation": "本文引入了一种新的成员推断博弈，可以高效地审计数据记录的近似最坏情况下的隐私风险。通过增强标准的DP-SGD算法实现自适应的分组特定梯度裁剪策略，从而提高了DPML中的隐私保护公平性。", "conclusion": "实验结果表明，本文的方法提供了一种更严格的群体隐私风险测量方法，能够可靠地评估群体隐私风险的差异。改进后的算法有效地减少了群体隐私风险的差异，从而增强了DPML中隐私保护的公平性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09136", "html_url": "https://arxiv.org/abs/2510.09136", "title": "传统媒体在线服务中的控制个性化推荐：一项新闻推荐案例研究", "title_en": "Controlled Personalization in Legacy Media Online Services: A Case Study in News Recommendation", "authors": "Marlene Holzleitner,Stephan Leitner,Hanna Lind Jorgensen,Christoph Schmitz,Jacob Welander,Dietmar Jannach", "background": "个性化新闻推荐已成为大型新闻聚合服务的标准功能，通过自动化内容选择优化用户参与度。相比之下，传统新闻媒体通常谨慎地对待个性化，力求在技术创新与核心编辑价值观之间取得平衡。因此，传统新闻机构的在线平台通常将编辑精选内容与算法推荐的文章相结合，我们称之为控制个性化。", "innovation": "通过在挪威一家大型传统新闻机构的网站上进行A/B测试，评估控制个性化推荐的有效性。实验结果显示，即使是适度的个性化推荐也能带来显著的好处，表明个性化内容的用户点击率更高，导航难度更低，此外，分析还显示，控制个性化推荐有助于提高内容多样性，增加内容目录的覆盖率，并减少流行度偏差。", "conclusion": "研究结果表明，控制个性化推荐能够成功地将用户需求与编辑目标对齐，为传统媒体提供了一种可行的路径，采用个性化技术同时保留新闻价值观。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09051", "html_url": "https://arxiv.org/abs/2510.09051", "title": "Alif: 通过多语言合成数据精炼推进乌尔都大型语言模型", "title_en": "Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation", "authors": "Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq", "background": "开发适用于低资源语言（如乌尔都语）的高性能大型语言模型（LLMs）存在诸多挑战，包括高质量数据稀缺、多语言一致性问题以及安全问题。现有的多语言LLMs通常通过翻译大量可用数据来解决这些问题，但这样的翻译往往缺乏质量与文化细腻度，并且还会造成数据整理与训练的高成本。", "innovation": "本文提出了一种名为Alif-1.0-8B-Instruct的多语言乌尔都语-英语模型，通过使用改进建立的self-instruct技术，使用高质量的多语言合成数据集（Urdu-Instruct）进行训练。数据集中每个任务使用独特的提示和种子值，结合全球任务池，实现了乌尔都语母语推理、双语翻译、文化相关性以及道德安全性对齐。这种技术显著提高了Alif-1.0-8B-Instruct模型对乌尔都语特定任务的理解。实验结果表明，Alif-1.0-8B-Instruct模型使用预训练的Llama-3.1-8B构建的，相比Llama-3.1-8B-Instruct在乌尔都语特定任务上性能更优，同时在不到$100的训练预算下，也优于包括Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct、Cohere-Aya-Expanse-8B等在内的领先多语言LLMs。", "conclusion": "我们的研究结果表明，通过我们改进的self-instruct方法，可以高效且文化关联地开发高性能和低资源语言的LLMs。所有数据集、模型和代码均可在公开链接获得。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09105", "html_url": "https://arxiv.org/abs/2510.09105", "title": "MemLoss: 使用回收对抗样本增强对抗训练", "title_en": "MemLoss: Enhancing Adversarial Training with Recycling Adversarial Examples", "authors": "Soroush Mahdi,Maryam Amirmazlaghani,Saeed Saravani,Zahra Dehghanian", "background": "对抗训练是提高机器学习模型健壮性的常用方法，但传统方法可能会在对抗样本的生成和使用平衡上存在问题，即提高对抗鲁棒性的同时可能牺牲干净数据上的自然准确率。本文的背景在于现有方法在提高模型对抗攻击的能力时，往往会导致在干净数据上的性能下降，因此需要一个新的方法来平衡这两者之间的关系。", "innovation": "本文提出了一种名为MemLoss的新方法，通过利用之前生成的对抗样本，称为‘记忆对抗样本’，在保持模型在干净数据上的性能的同时，大幅提升了模型的鲁棒性。MemLoss利用这些对抗样本在整个训练过程中增强了模型，使得模型在自然准确率和对抗鲁棒性上实现了均衡的进步。这种方法在多个数据集，如CIFAR-10上的实验结果表明，MemLoss相比于现有对抗训练方法，能够显著提高准确率并保持较强的攻击抵抗力，同时不影响在干净数据上的性能。", "conclusion": "总的来说，本文提出的方法MemLoss通过利用之前生成的对抗样本，实现了在保持模型自然准确率的同时，大幅提高模型对对抗攻击的鲁棒性。实验结果验证了方法的有效性，表明该方法是对抗训练领域的一个重要创新。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09121", "html_url": "https://arxiv.org/abs/2510.09121", "title": "MSDM：使用多模态条件扩散模型生成用于细胞和核分割的任务特定病理图像", "title_en": "MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation", "authors": "Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu", "background": "标注数据不足，特别是对于罕见或非典型形态，对计算病理学中的细胞和核分割构成重大挑战。手动标注工作量大且成本高，而合成数据则提供了一种低成本的替代方案。现有的方法无法精确生成符合特定形态学需求的图像，难以在保护数据实际性的前提下创造出高质量的图像样本。这限制了计算病理学中模型学习的真实性和泛化能力。", "innovation": "引入了多模态语义扩散模型（MSDM）来生成符合特定形态学特性的像素级图像-掩码对，通过条件生成过程使用细胞/核形态（横向和纵向图）、RGB色彩特征和BERT编码的检测/说明元数据。MSDM使用多头交叉注意力机制将不同模态整合，从而对生成的图像进行精细控制。实验展示了合成图像与实际数据高度匹配，可在特定条件下显著提高细胞和核分割模型的准确性，特别是对于柱状细胞等罕见类型，直接提升了模型的鲁棒性和泛化能力。", "conclusion": "通过MSDM策略系统地丰富数据集，直接针对模型的不足。此方法为计算病理学中生成模型的鲁棒性和泛化能力做出了贡献，为这些生成模型在计算病理学中的广泛应用铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09110", "html_url": "https://arxiv.org/abs/2510.09110", "title": "SOS: 合成对象分割提高检测、分割和语义理解", "title_en": "SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding", "authors": "Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna", "background": "视觉分组通过对实例分割、视觉定位和对象检测的应用，支撑着从机器人感知到图片编辑的各种应用。然而，大量标注的数据集成本高昂，覆盖面偏斜且难以扩展。合成数据虽然有潜力，但常常缺乏灵活性、准确性和组合多样性。因此，研究者需要一种简单且可扩展的解决方案来生成高质量的合成数据，以满足应用需求。", "innovation": "提出了一种名为SOS的简单而可扩展的数据合成管道，基于对象为中心的合成策略。该方法通过使用结构布局先验和生成性光照技术将高质量的合成对象分割粘贴到新图像中，从而产生准确且多样性的掩码、边界框和引用表达。SOS训练的模型在检测和语义理解任务上的表现优于使用更大规模真实图像数据集GRIT（2000万）和V3Det（20万）训练的模型，分别在LVIS检测上提高了10.9个AP，在gRefCOCO语义理解上提高了8.4个$N_{\text{Acc}}$。此方法还支持在低数据量和封闭词汇环境下实现可控的数据集构建，并提高泛化能力。通过将合成对象分割添加到真实数据集LVIS和COCO中，可以实现从少量真实数据到大量真实数据的广泛性能提升，甚至在极少数真实数据条件下也能取得显著进步，如LVIS实例分割提高3.83个$AP_{\text{rare}}$和COCO设置中增加0.01数据提高6.59个AP。这种方法在目标内部视觉语义理解上也提供了有针对性的数据生成能力。", "conclusion": "SOS合成对象分割方法不仅能够显著提高检测、分割和语义理解等任务的表现，还在多种数据量和单词限制条件下展示了其强大的泛化能力和可控性，为视觉场景下的数据生成提供了一种新的思路。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09155", "html_url": "https://arxiv.org/abs/2510.09155", "title": "联邦数据分析在癌症免疫疗法中的应用：一种保护隐私的协作性患者管理平台", "title_en": "Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management", "authors": "Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal", "background": "背景：连接健康是一种多学科方法，强调以患者需求为中心开发工具、服务和治疗方法。通过促进所有医疗服务提供者之间及时、准确的信息交换，该范式确保了积极主动和高效的护理。随着数字技术的进步和流程创新的推动，健康数据的整合有望进一步增强连接健康，实现个性化护理、预测健康结果和简化患者管理。然而，在数据架构、应用互操作性和安全性方面仍存在挑战。\n", "innovation": "创新：本文探讨了通过一个欧盟资助的敏捷系统开发生命周期开发一个集成的人工智能生成解决方案，用于管理正在进行免疫疗法的癌症患者。基于联邦大数据分析和人工智能的协作数字框架被用于结合护理周期中的所有相关方，以保护隐私、提升决策质量和患者管理的有效性。\n", "conclusion": "结论：利用真实数据验证了分析能力，如治疗建议和不良事件预测，在试点研究中达到了70%-90%的准确率，表明该框架的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09181", "html_url": "https://arxiv.org/abs/2510.09181", "title": "关于深度连续学习中灾难性遗忘的潜在对抗性", "title_en": "On the Implicit Adversariality of Catastrophic Forgetting in Deep Continual Learning", "authors": "Ze Peng,Jian Zhang,Jintao Guo,Lei Qi,Yang Gao,Yinghuan Shi", "background": "连续学习追求在机器智能中获得人类不断积累新技能的能力。其核心挑战是灾难性遗忘，尽管由于深度神经网络的原因其根本原因尚未完全理解，但这种遗忘已经引起了广泛关注。", "innovation": "本文通过揭示新任务训练实际上是对旧任务知识的一种隐含对抗攻击来解释灾难性遗忘。具体来说，新任务梯度会自动且准确地与旧任务损失景观中的尖锐方向对齐，迅速增加旧任务的损失。本文还理论展示了这种现象源于训练的低秩偏差，该偏差通过前向和后向传播，将两个方向限制在同一低维子空间中，促进了对齐。此外，本文提出了BackGP方法，这种方法通过减少由于前向传播引起的对抗对齐，以及后向传播引起的对抗对齐来缓解遗忘，平均减少了10.8%的遗忘，提高了12.7%的准确性，优于梯度投影（GP）方法的有效性，是遗忘缓解方法中的一种代表", "conclusion": "通过理论分析和创新性方法BackGP，本文对灾难性遗忘的本质给出了新的见解，并提出了一种有效的缓解方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09159", "html_url": "https://arxiv.org/abs/2510.09159", "title": "跨表示基准测试在时间序列电子健康记录中的临床结果预测", "title_en": "Cross-Representation Benchmarking in Time-Series Electronic Health Records for Clinical Outcome Prediction", "authors": "Tianyi Chen,Mingcheng Zhu,Zhiyao Luo,Tingting Zhu", "background": "电子健康记录（EHR）使深度学习在临床预测中得到应用，但由于评估实践不一致，最优的患者数据表示方法仍然不清楚。本文旨在提供第一个系统性的基准测试，以比较EHR表示方法，包括时间序列、事件流和文本事件流。这些基准测试在两种不同的临床环境中标准化了数据处理和评估：MIMIC-IV数据集用于ICU任务（死亡率、表型识别）以及EHRSHOT数据集用于长期护理任务（30天再入院、1年胰腺癌）。", "innovation": "1. 首次提供了一个系统性的基准测试来比较EHR表示方法。\n2. 评估了包括Transformer、MLP、LSTM、Retain、CLMBR和基于计数的模型在不同数据流中的表现，并分析了基于数据缺失性的特征剪枝影响。\n3. 发现事件流模型在所有评估任务中表现最稳定，并揭示了适应临床环境的特征选择策略，即对于ICU预测选择稀疏特征进行剪枝，而对于长期任务，则需要保留这些特征。", "conclusion": "本研究通过统一和可重复的实验流程提供了实用指导，以根据临床上下文和数据类型选择EHR表示方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09187", "html_url": "https://arxiv.org/abs/2510.09187", "title": "现代深度学习方法在板球击球分类中的应用：一项全面的基础研究", "title_en": "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study", "authors": "Sungwoo Kang", "background": "板球击球从视频序列中的分类仍然是体育视频分析中的一个挑战性问题，需要有效建模空间和时间特征。", "innovation": "这项研究提出了跨四个不同的研究范式比较了七种不同的深度学习方法的首个全面基准研究，并实现和系统地评估了传统CNN-LSTM架构、注意力模型、视觉变换器、迁移学习方法以及高效的EfficientNet-GRU组合。研究表明，学术文献中的准确率声明与实际实现结果之间存在显著差异，新的现代范式方法提高了分类准确性。", "conclusion": "现代高效Net-B0与基于GrU的时间模型相结合的新SOTA方法实现了92.25%的准确率，表明现代架构和系统优化可以使分类准确率显著提高。所有实现遵循现代MLOps实践，并使用PyTorch Lightning提供可重复的研究平台，强调了标准化评估协议在体育视频分析研究中的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09230", "html_url": "https://arxiv.org/abs/2510.09230", "title": "使用多模态大型语言模型和消费级摄像头诊断肩关节紊乱", "title_en": "Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras", "authors": "Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun", "background": "肩关节紊乱，例如冻结肩（又称为粘连性肩关节囊炎），是全球范围内影响人们健康的一种常见疾病，特别在老年人和从事重复肩部任务的工作者中发病率较高。在医疗资源匮乏的地区，早期和准确诊断这些疾病面临巨大挑战，急需低成本且易扩展的辅助诊断解决方案。", "innovation": "本文提出了使用多模态大型语言模型（MLLM）和消费级摄像头作为初步诊断肩关节紊乱的基础，并设计了一个称为混合动作视频诊断框架（HMVDx）。该框架将动作理解和疾病诊断两个任务分别由两个MLLM完成，通过引入新的Usability Index评估指标，从整个医疗诊断流程的角度评价MLLM在医学领域的有效性。", "conclusion": "通过实验对比，HMVDx在肩关节损伤诊断上的准确率提高了79.6%，这为未来研究MLLM在医疗视频理解应用方面的技术贡献提供了重要依据。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09211", "html_url": "https://arxiv.org/abs/2510.09211", "title": "DICE: 在LLM中通过SLM引导CoT校正实现结构化推理", "title_en": "DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction", "authors": "Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang", "background": "在执行具有用户特定要求的任务时，如严格的输出格式，大型语言模型（LLMs）常常侧重于推理而非遵循详细的指令。对LLMs进行监督数据集的微调以解决这一问题由于高昂的计算成本和有限的参数访问，因此并不实际。", "innovation": "提出了一种名为DICE的轻量级框架，通过引导小型语言模型（SLMs）在chain-of-thought（CoT）校正过程中精炼LLMs的输出来解决此问题。DICE通过先促使LLMs生成自然语言响应，然后利用训练的SLMs分析并精炼这些输出，以满足结构化输出的规范。框架既保留了LLMs广泛的知识和推理能力，又确保输出符合用户需求。该框架采用两阶段方法构建结构化的CoT适应数据集，并采用双重微调策略对SLMs进行微调，使其以分析后再回答的模式生成结构化输出。", "conclusion": "实验表明，DICE能够将LLM输出的平均格式准确性和内容准确性分别提高35.4%和29.4%，并通过与其他先进基线的比较达到了最先进的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09201", "html_url": "https://arxiv.org/abs/2510.09201", "title": "多模态提示优化：为何不利用多种模态来释放MMLMs的潜力", "title_en": "Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs", "authors": "Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang", "background": "大型语言模型（LLMs）已经展示了显著的成功，其多模态扩展（MMLMs）更是进一步解锁了跨越图片、视频和其他非文本模态的能力。然而，尽管发生了这种转变，专注于减轻手动提示设计负担并最大化性能的提示优化方法仍然局限于文本领域，最终限制了MMLMs的全部潜力。", "innovation": "本文针对这一缺口，提出了一种新的多模态提示优化问题，将其定义扩展到了由文本和非文本提示构成的多模态空间内。为此，研究者提出了一个多模态提示优化器（MPO），这是一种统一框架，不仅可以通过保对齐更新方法完成多模态提示的联合优化，还可以借助贝叶斯式的选取策略利用先前评估作为先验来指导候选提示的选择过程。通过在包括图像、视频以及分子等超出文本的多种模态上的广泛实验，研究证明了MPO在性能上优于现有的文本独占优化方法，确立了多模态提示优化对于实现MMLMs潜力的关键步骤。", "conclusion": "通过全面的实验，并且超越了文本模态的领域，研究展示了MPO超越了现有的基于文本的优化方法，确立了多模态提示优化作为充分发挥MMLMs潜力的关键步骤。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09200", "html_url": "https://arxiv.org/abs/2510.09200", "title": "迈向更安全且可解释的驾驶意图预测", "title_en": "Towards Safer and Understandable Driver Intention Prediction", "authors": "Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar", "background": "随着深度学习和人工智能的快速发展，自动驾驶（AD）系统能够处理的任务越来越复杂。为了保障安全驾驶，人机交互中对决策过程的可解释性变得尤为重要。当前基于深度学习的系统在理解环境和驾驶任务的内部表示方面仍面临巨大挑战，特别是预测驾驶意图（DIP），这对于自动驾驶系统的性能至关重要。", "innovation": "本文提出了一种新的任务——在驾驶意图实际发生前的可解释性预测，即驾驶意图预测（DIP），以增强AD系统的安全性。为此，作者创建了eXplainable Driving Action Anticipation Dataset（DAAD-X），一个包含多模态、自我为中心的视频数据集，用于提供分层的、高级的文本解释作为因果推理，这些解释源自驾驶员的注视和车辆的视角。此外，作者提出Video Concept Bottleneck Model (VCBM)，一种生成时空一致解释的框架，而无需依赖后续处理技术。结果显示，基于Transformer的模型比传统CNN模型更具可解释性。", "conclusion": "通过在DAAD-X数据集上对提出的VCBM的全面评估，发现基于Transformer的模型在可解释性方面优于传统CNN模型。此外，还引入了多标签t-SNE可视化技术来说明多个解释之间的去耦合和因果关系。研究提出的数据、代码和模型均可在此链接下载：this https URL."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09228", "html_url": "https://arxiv.org/abs/2510.09228", "title": "明路和明视：智能交通系统的多天气恢复进展", "title_en": "Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation", "authors": "Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala", "background": "恶劣天气（如雾霾、雨雪）会显著降低图像和视频质量，严重影响依赖视觉输入的智能交通系统（ITS）。这些天气条件引起的影响包括但不限于自动驾驶、交通监控和监视等关键应用都受到了制约。因此，本文综述了用于减轻由天气引起的视觉障碍的各种图像和视频复原技术。现有的方法分为传统的基于先验的方法和现代的基于数据驱动的模型，包括CNNs、变压器、扩散模型和新兴的视觉得到语言模型（VLM）。在复原策略方面，还依据它们的应用范围进行了分类：单一任务模型、多任务/多天气系统，以及能够处理各种类型的降级问题的全方位方案。此外，本文还讨论了白天和夜晚的恢复挑战，基准数据集以及评估标准。", "innovation": "本文对现有的图像和视频复原技术进行了多层次的分类和综述，不仅是基于其方法论的区别，还特别强调了根据应用范围将方法分类为单一任务模型、多任务联合系统及全能框架。并且讨论了日间与夜间恢复的挑战，评估了现有数据集并提出了评估协议，同时提出未来的研究方向，如混合/复合降级恢复、实时部署以及自主AI框架。", "conclusion": "本文综述的研究结论指出，当前研究仍存在一些限制，并探讨了未来的研究方向，旨在为先进天气稳健的视觉系统在智能交通环境中的发展提供重要参考。为了跟上该领域的快速进展，本文将定期更新最新的相关文献及其开源实现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09263", "html_url": "https://arxiv.org/abs/2510.09263", "title": "SynthID-Image：互联网规模的图像水印技术", "title_en": "SynthID-Image: Image watermarking at internet scale", "authors": "Sven Gowal,Rudy Bunel,Florian Stimberg,David Stutz,Guillermo Ortiz-Jimenez,Christina Kouridi,Mel Vecerik,Jamie Hayes,Sylvestre-Alvise Rebuffi,Paul Bernard,Chris Gamble,Miklós Z. Horváth,Fabian Kaczmarczyck,Alex Kaskasoli,Aleksandar Petrov,Ilia Shumailov,Meghana Thotakuri,Olivia Wiles,Jessica Yung,Zahra Ahmed,Victor Martin,Simon Rosen,Christopher Savčak,Armin Senoner,Nidhi Vyas,Pushmeet Kohli", "background": "本文介绍了一个深度学习为基础的系统SynthID-Image，用于对AI生成的图像进行隐形水印。该论文详细阐述了在互联网规模上部署此类系统的技术需求、威胁模型和实际挑战，包括有效性、保真度、鲁棒性和安全性等关键要求。", "innovation": "SynthID-Image 已经被用于超过100亿张图像和视频帧的水印，其对应的验证服务也对外开放给受信任的测试者。此外，文章还对一项外部模型变体SynthID-O进行了实验评估，该模型通过合作伙伴提供，并展示了在视觉质量和抵抗常见图像扰动方面的先进性能。", "conclusion": "本文为大规模部署基于深度学习的媒体来源系统提供了全面的文档说明，成果对视觉媒体以及其他模态（如音频）在部署、约束和威胁建模上的结论具有普遍适用性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09243", "html_url": "https://arxiv.org/abs/2510.09243", "title": "CrisiText：灾难通信中LLM训练的警告信息数据集", "title_en": "CrisiText: A dataset of warning messages for LLM training in emergency communication", "authors": "Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini", "background": "在自然灾害或暴力袭击等危机情况下，有效地识别威胁并减轻其潜在损害对于保护受威胁个体至关重要。尽管人工智能已被用于辅助人类应对紧急情况，但自然语言处理(NLP)技术的应用仍局限于分类任务，及时生成警告信息的潜在价值亦被忽视。为此，本文构建了一个名为CrisiText的大规模数据集，涵盖了13种不同类型的危机情景，包含了超过400,000条警告信息，涉及近18,000个危机情况，旨在帮助平民在危机前后提供援助。这些警告信息在生成过程中遵循了专家撰写的指导方针，确保了用词和事实的准确性，并为每条警告信息提供了三种次优版本，以探讨不同的自然语言生成(NLG)方法。此外，本文通过一系列实验对监督微调设置、偏好对齐、零样本和少数样本方法进行了比较，并评估了模型在分布外场景下的性能和自动后编辑的有效性。", "innovation": "本文提出了CrisiText，这是首个用于生成警告信息的大规模数据集，涵盖了13种不同的危机情景，包含超过400,000条警告信息。通过构建这些警告信息替换了分类任务中对NLP技术的应用，首次展示了使用自然语言生成(NLG)架构及时生成警告信息的重要性和潜力。此外，通过实验比较了不同NLG方法，并评估了其在分布外场景下的性能，进一步探索了自动后编辑的有效性。这些创新措施进一步推动了在紧急通信中使用大规模语言模型(LLMs)的可能性。", "conclusion": "本文通过构建CrisiText数据集，展示了大规模自然语言生成(NLG)技术在及时生成警告信息的有效性。实验结果表明，在监督微调方法、偏好对齐、零样本和少数样本方法之间的差异性以及模型在分布外场景下的性能。进一步依托自动后编辑评估了警告信息的效果，为在紧急沟通中利用大规模语言模型进行了有益的探索。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09254", "html_url": "https://arxiv.org/abs/2510.09254", "title": "使用动态运动原始模型和强化学习进行避障", "title_en": "Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning", "authors": "Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa", "background": "基于学习的运动规划可以通过快速生成接近最优轨迹，但往往需要大规模训练数据集或通过昂贵的方式收集人类演示。本文介绍了一种新的方法，能够从单一个人造演示快速生成平滑的、接近最优的无碰撞3D笛卡尔路径。这种方法通过政策导向的强化学习不断重塑演示，从而创建多个障碍配置的多样轨迹数据集。该数据集用于训练神经网络，基于点云自动提取的障碍物尺寸和位置参数，输出生成轨迹的动态运动原始模型（DMP）参数。该方法在仿真和真实机器人实验中被验证，结果优于基于RRT-Connect的基本方法，在计算和执行时间以及轨迹长度方面表现更好。此外，该方法还支持不同障碍物几何形状和末端执行器尺寸的多模态轨迹生成。", "innovation": "提出的替代方法能够从单一个人造演示快速生成平滑的、接近最优的3D笛卡尔无碰撞轨迹，通过动画MOVIE aseg 原声PLACE优化基于政策的强化学习重塑演示，从而创建多样轨迹数据集，用于不同障碍配置。这种方法利用点云自动提取的障碍物尺寸和位置参数，无法训练神经网络生成轨迹。该方法在仿真和真实机器人实验中表现优于基于RRT-Connect的基本方法，同时支持多模态轨迹生成。", "conclusion": "本文介绍的方法通过神经网络以及点云信息生成近最优、无碰撞3D笛卡尔路径，适用于多种障碍物配置，并在计算和执行时间、轨迹长度方面显著优于基于RRT-Connect的基本方法，还支持多模态轨迹生成。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09259", "html_url": "https://arxiv.org/abs/2510.09259", "title": "检测大规模语言模型强化学习后训练阶段的数据污染", "title_en": "Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models", "authors": "Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li", "background": "大规模语言模型（LLMs）的可靠评估受到数据污染的威胁。这种污染在训练集中偶然出现时会削弱报告性能的可靠性。虽然前瞻性和监督微调阶段已有检测方法，但在强化学习（RL）后训练阶段的数据污染检测研究尚未充分。鉴于RL后训练在LLMs推理方面的重要性，缺乏针对这一范式的特定污染检测方法是一个关键缺陷。", "innovation": "该研究首次系统地探讨了RL后训练场景中的数据检测问题，并提出了Self-Critique方法。该方法通过观察LLMs在RL阶段后输出熵分布发生特定模式的坍缩，来检测政策的收敛情况。为了支持研究，作者还引入了RL-MIA基准，以模拟特定的污染场景。实验结果表明，相比于基线方法，Self-Critique显著提高了性能，在多个模型和污染任务中AUC提升可达30%，尤其在RL阶段污染检测方面展示了实际应用的潜力。", "conclusion": "Self-Critique方法通过检测LLMs在RL阶段后的熵分布坍缩，实现了对政策收敛问题的有效检测，显著优于现有方法。该工作不仅填补了RL后训练阶段的检测空白，还为LLMs的可靠评估提供了重要的技术手段。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09275", "html_url": "https://arxiv.org/abs/2510.09275", "title": "动态评估：医疗诊断标准中的吹嘘与真实表现？", "title_en": "Inflated Excellence or True Performance? Rethinking Medical Diagnostic Benchmarks with Dynamic Evaluation", "authors": "Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu", "background": "医疗诊断是高风险且复杂的领域，对于患者护理至关重要。然而，当前对大型语言模型（LLMs）的评估与实际临床实践严重不匹配。大多数评估依赖于源自公开医学考试项目的静态基准，这些基准往往会高估模型性能，并忽视书本案例与现实世界中具有模糊性及变化性的条件之间的差异。最近对动态评估的努力提供了有前景的替代方案，但其改进主要局限于表面扰动和对准确性狭窄的关注。这些问题促使作者提出了DyReMe，一种能够更好地反映实际临床实践的动态基准。", "innovation": "DyReMe提出了一个新颖的动态基准，用于医疗诊断，通过生成真实的病例和引入干扰因素，使其更贴近临床实践。此外，DyReMe不仅评估了准确性，还评估了三个额外的临床相关维度：真实性的准确性、帮助性以及一致性。实验结果表明，这种动态方法提供了更具挑战性和现实性的评估，揭示了最先进的LLMs与实际临床实践之间的显著偏差，强调了需要更符合信任医疗诊断要求的评估框架的迫切性。", "conclusion": "实验结果表明，DyReMe的动态方法提供了更具挑战性和现实性的评估，揭示了最先进的LLMs与实际临床实践之间的显著偏差。因此，迫切需要更准确地反映信任医疗诊断需求的评估框架。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09278", "html_url": "https://arxiv.org/abs/2510.09278", "title": "CLARity: 仅通过一致性训练便能教授强化专家", "title_en": "CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts", "authors": "Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng", "background": "在数据稀缺的领域训练专家级的语言模型（LLM）具有挑战性，通常依赖于多项选择题（MCQs）。然而，基于标准的结果导向强化学习（RL）在MCQs上存在风险。虽然可能提高准确性，但研究发现它会降低推理质量，如逻辑一致性。现有的监督推理的方法，如大规模过程奖励模型（PRMs），由于成本高昂而难以实现。", "innovation": "CLARity提出了一种低成本的RL框架，使用少量的通用LLM来提高推理质量。CLARity结合了一致性感知的奖励机制和两阶段的先精炼后监控的训练管道，以增强推理一致性，并采用动态数据重塑策略以更好地利用有限的数据。", "conclusion": "实验表明，CLARity在响应一致性上提高了16.5%，准确性提高了7.5%，并超过基线模型。进一步的人机评价证实了整体结构的一致性和专业性的提升。因此，CLARity提供了一种可推广的解决方案，使较小的模型能够有效地指导专家级模型进行推理。相关代码已开源。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09302", "html_url": "https://arxiv.org/abs/2510.09302", "title": "CapGeo: 一种辅助生成几何解释的方法", "title_en": "CapGeo: A Caption-Assisted Approach to Geometric Reasoning", "authors": "Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang", "background": "多模态大型语言模型在几何推理方面仍存在核心挑战。即使是最先进的闭源系统如GPT-O3和Gemini-2.5-Pro，在解决几何问题时仍然难以可靠地进行，尽管它们在国际数学奥林匹克（IMO）等文本推理任务中表现出色。这表明几何图形的理解是瓶颈所在，而非推理能力。几何图形往往可以用简洁的文本形式准确描述，因此将视觉内容转换为描述性文本是一个有希望的方向。", "innovation": "我们提出了CapGeo，这是一种基于描述辅助的推理框架，旨在链接视觉和文本模态。实验结果显示，当模型配备描述时，性能显著提升：Qwen2.5-VL-72B从8.6%（仅视觉）提高到59.0%，而Claude-Opus-4从44.8%提高到73.0%。为了系统地评估和识别高质量的几何描述模型，我们提出了CapGeo-Bench，这是一个包含4641个精心策划的图形-描述对的数据集。CapGeo-Bench引入了一种基于关键点的评估标准，与下游CapGeo性能高度相关，从而能够可靠地评估几何描述能力。", "conclusion": "我们的框架和基准数据集强调了一种新的途径，用于在多模态大型语言模型中推进几何推理能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09325", "html_url": "https://arxiv.org/abs/2510.09325", "title": "从数据中学习均衡的最优率学习", "title_en": "Rate optimal learning of equilibria from data", "authors": "Till Freihaut,Luca Viano,Emanuele Nevali,Volkan Cevher,Matthieu Geist,Giorgia Ramponi", "background": "在多智能体模仿学习（MAIL）领域，目前存在一些理论缺口，尤其是在非互动和互动设置下的限制条件尚未得到充分研究。已有研究显示，行为克隆（BC）在非互动设置下是率最优的，但在互动设置下，仍然缺乏高效的算法，且样本复杂性的最佳估计仍未确定。", "innovation": "本文通过研究非互动MAIL和引入互动算法MAIL-WARM，填补了理论缺口。具体创新包括：1. 确定了所有策略偏差集中系数作为基本的复杂度度量；2. 证明了行为克隆（BC）在非互动设置下是率最优的；3. 提出了将无奖励强化学习与互动MAIL结合的新框架，并基于此框架开发了MAIL-WARM算法，其样本复杂性从$\text{O}(\text{ε}^{-8})$改进到$\text{O}(\text{ε}^{-2})$，与理论下界相符。", "conclusion": "本文通过上述研究，改进了现有互动MAIL算法的样本复杂性，并通过实验验证理论所得结论，尤其是在格子世界环境中证明了行为克隆的不足。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09312", "html_url": "https://arxiv.org/abs/2510.09312", "title": "通过其计算图验证链式思维推理", "title_en": "Verifying Chain-of-Thought Reasoning via Its Computational Graph", "authors": "Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda", "background": "当前的链式思维（CoT）验证方法主要基于输出（黑盒）或激活（灰盒）预测推理正确性，但对为何计算失败提供有限的洞察。", "innovation": "本文引入了一种白盒方法：电路推理验证（CRV）。通过将正确CoT步骤的归因图视为模型潜藏推理电路的执行痕迹，我们假设正确步骤和错误步骤具有不同的结构性指纹。通过训练分类器在这些图形的结构性特征上，展示执行痕迹包含了推理错误的强大信号。我们的白盒方法提供了其他方法无法获取的新颖科学见解：（1）结构错误特征的高度预测性，确立了直接通过计算图验证推理的可行性；（2）这些特征高度领域特定，揭示了不同推理任务中失败的计算模式差异；（3）证据表明这些特征不仅仅是相关性的，通过我们的分析引导对单个转码器特征的针对性干预，能够成功纠正模型的错误推理。该工作表明，通过审视模型的计算过程，可以从简单的错误检测过渡到对大语言模型推理更深入、因果的理解。", "conclusion": "本研究表明，通过审查模型的计算过程，我们可以从简单的错误检测过渡到对大语言模型推理更深入的、因果的理解。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09332", "html_url": "https://arxiv.org/abs/2510.09332", "title": "FLRC：细粒度低秩压缩器以实现高效的大型语言模型推理", "title_en": "FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference", "authors": "Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu", "background": "尽管大型语言模型在多项任务上取得了显著的成果，但其庞大的参数数量限制了其在资源受限的硬件上的部署。低秩压缩虽然能够减少内存使用和计算需求，但使用统一的压缩比会导致性能严重下降，且先前的方法在解码过程中的表现不佳。", "innovation": "本文提出了一种细粒度低秩压缩器（FLRC），能够高效地为每一层分配最优的秩并结合渐进式的低秩解码来保持文本生成的质量。实验证明，与现有低秩压缩方法相比，FLRC在摘要任务中的ROUGE-L得分提高了最高达17%。", "conclusion": "FLRC提供了一个更稳健和高效的框架，用于改进大型语言模型的推理。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09308", "html_url": "https://arxiv.org/abs/2510.09308", "title": "AI驱动健康平台的模型驱动工程方法", "title_en": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms", "authors": "Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi", "background": "人工智能有潜力通过支持更准确的诊断和个性化治疗来变革医疗保健，但在实际应用中，其采用受到数据来源碎片化、严格的隐私规定和技术构建可靠的临床系统的复杂性限制。为了解决这些挑战，我们提出了一种专门用于医疗AI的模型驱动工程（MDE）框架。该框架依赖于形式化元模型、领域特定语言（DSL）和自动转换，从高层次规范到运行软件。其核心是医疗互操作性语言（MILA），这是一种图形DSL，允许临床医生和数据科学家使用共享的本体定义查询和机器学习管道。结合联邦学习架构，MILA使机构能够在不交换原始患者数据的情况下进行协作，确保各站点在意义上的一致性，同时保护隐私。我们在一个涉及多中心癌症免疫治疗的研究中评估了这种方法。生成的管道在关键任务上产生了强大的预测性能，支持向量机在关键任务上的准确率分别为98.5%和98.3%，同时大大减少了手动编码的工作量。", "innovation": "我们提出了一种专门用于医疗AI的模型驱动工程框架，简化了从高层次规范到实际软件产品的过渡过程。其中的核心是医疗互操作性语言（MILA），它允许临床医生和数据科学家通过共享本体轻松定义查询和机器学习管道。通过结合联邦学习架构，MILA使得机构能够在不交换原始患者数据的情况下进行协作，确保各站点在意义的一致性同时保护隐私。同时，该框架简化了数据处理过程并提高了预测性能。", "conclusion": "研究表明，基于模型驱动工程的原理、语义集成和自动化代码生成可以提供一条实用的道路，通向互操作、可重复且值得信赖的数字健康平台。这种方法已经在多中心癌症免疫治疗研究中取得了强有力的预测结果，支持向量机在关键任务上的准确率达到了98.5%和98.3%，并且显著减少了手动编码工作量。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09328", "html_url": "https://arxiv.org/abs/2510.09328", "title": "随机化超球Steiner：一种用于双曲Steiner最小树的随机化Delaunay三角剖分启发式方法", "title_en": "Randomized HyperSteiner: A Stochastic Delaunay Triangulation Heuristic for the Hyperbolic Steiner Minimal Tree", "authors": "Aniss Aiman Medbouhi,Alejandro García-Castellanos,Giovanni Luca Marchetti,Daniel Pelt,Erik J Bekkers,Danica Kragic", "background": "Steiner Minimal Tree (SMT)的精确计算是NP难问题，现有的超球体启发式方法如HyperSteiner通常是确定性的，并且常常陷入局部次优配置。在合成数据集和实际单细胞转录组学数据集上的实验显示，现有方法在近边界配置时总长度增加达32%，说明了优化的必要性。", "innovation": "引入了随机化超球Steiner (Randomized HyperSteiner, RHS)，这是一种结合随机性的扩展过程和通过黎曼梯度下降优化候选树的随机化Delaunay三角剖分启发式方法，显著改进了现有方法的表现。", "conclusion": "在合成数据集和实际单细胞转录组学数据集上的实验表明，RHS相较于最小生成树 (MST)、邻接联合方法和常规HyperSteiner方法具有明显优势，特别是在近边界配置时总长度减少了32%，证明了其在多种数据条件下的有效性和鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09389", "html_url": "https://arxiv.org/abs/2510.09389", "title": "基于系数动力学的序列模型设计原则", "title_en": "Design Principles for Sequence Models via Coefficient Dynamics", "authors": "Jerome Sieber,Antonio Orvieto,Melanie N. Zeilinger,Carmen Amo Alonso", "background": "深度序列模型包括Transformers和State Space Models (SSMs)，以及最新的方法如gated linear RNNs，这些模型的基本计算输出是通过对过去值向量进行线性组合实现的。尽管这些模型在实际应用中取得了成功，但它们之间的比较和设计选择仍然缺乏系统性和统一性。", "innovation": "该论文提出了一种统一框架，通过将线性组合系数视为由冲击输入驱动的自主导动线性动态系统的输出，使这一线性组合过程更加明确。这种方法揭示了这些截然不同的架构之间的共同数学主题，并特别涵盖了softmax注意力机制、RNNs、SSMs及相关的模型。这为架构选择与模型性质之间的联系提供了设计原则，从而识别表达性和高效实现之间的权衡、输入选择的几何约束以及数值稳定训练和信息保留的稳定性条件。", "conclusion": "通过连接最近文献中的多种见解和观察，该框架不仅解释了最近设计的成功，还为系统地设计新的序列模型架构提供了指导原则。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09362", "html_url": "https://arxiv.org/abs/2510.09362", "title": "deep-REMAP：使用正则化多任务学习的概率星谱参数化", "title_en": "deep-REMAP: Probabilistic Parameterization of Stellar Spectra Using Regularized Multi-Task Learning", "authors": "Sankalp Gilda", "background": "在数据爆炸的时代，传统的光谱分析方法正达到其极限。为应对这一挑战，本文开发了一种名为deep-REMAP的新型深度学习框架，利用正则化、多任务方法从观测光谱中预测恒星大气参数。此框架在一个合成光谱库（PHOENIX）上训练深度卷积神经网络，并通过微调在一个小样本的观测光谱（来自MARVELS巡天）上对模型进行精细化调整。然后，将此模型应用于同巡天中未分类的大质量恒星候选体（732个）", "innovation": "本文提出的方法是一种回归-分类框架，结合不对称损失函数与嵌入损失，使得模型不仅可解释性强，还能抵抗参数不平衡影响，并有效捕捉非高斯不确定性。虽然最初是为MARVELS开发的，此框架可通过调整适用于其他巡天和合成库，为恒星表征提供强大且自动化的途径", "conclusion": "经过30个MARVELS校准星的验证，deep-REMAP准确恢复了有效温度（$T_{\rm{eff}}$）、重力对数（$\rm{\rm{g}}$）和金属丰度（[Fe/H]），在有效温度上的精度约为75 K。此外，框架展示了将其应用于不同巡天项目与合成库的潜力，为大规模的恒星表征提供了新的方法"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09378", "html_url": "https://arxiv.org/abs/2510.09378", "title": "第二阶优化在大语言模型中的潜力：全高斯-牛顿方法研究", "title_en": "The Potential of Second-Order Optimization for LLMs: A Study with Full Gauss-Newton", "authors": "Natalie Abreu,Nikhil Vyas,Sham Kakade,Depen Morwani", "background": "近期加速大语言模型（LLM）预训练的努力主要集中在利用二次结构的计算效率更高的近似方法上。然而，使用这些近似方法的性能损失尚不清楚。为此，该研究通过将全高斯-牛顿（GN）预处理应用于最大15000万个参数的变压器模型来确定迭代复杂度的实用上限，旨在探测量化这些近似方法性能损失的程度。", "innovation": "研究引入了一种实用的方法来应用全高斯-牛顿预处理，并通过实验证明了全GN更新比现有优化器（如SOAP和Muon）具有显著优势，减少了5.4倍的训练迭代次数。此外，发现逐层高斯-牛顿预处理，即使忽略了跨层信息，也能达到全GN方法的几乎相同的效果。这一研究结果为高阶优化在LLM中的应用提供新的见解和潜力。", "conclusion": "(1) 高斯-牛顿近似对于预处理非常有效，表明高阶损失项可能不是加速收敛的关键；(2) 逐层海森矩阵结构包含足够的信息以实现这些大多数潜在增益；(3) 当前的近似方法与理想化的逐层金鸡独立有显著的性能差距。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09390", "html_url": "https://arxiv.org/abs/2510.09390", "title": "识别并互动优化数据可视化代码生成中的模糊用户目标", "title_en": "Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation", "authors": "Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani", "background": "人类与AI沟通的基础步骤之一是建立共同目标。然而，语言的不确定性可能会导致产出看似正确但实际上未能反映说话者意图的结果。在这种背景下，本文聚焦于数据可视化领域，探索自然语言中的多重含义如何影响生成可视化数据代码的过程。通过可视化多重视角（如预期的图表及渲染该图表的代码），本文能够进行独特且全面的多重含义类型的分析。", "innovation": "本文开发了该任务中多重含义类型的分类，并提出了量化这些多重含义的度量标准。使用DS-1000数据集中的Matplotlib问题示例，本文证明了，与其他不确定性基准相比，多重含义度量标准与人类注释之间的相关性更高。此外，通过模拟用户研究，本文探讨了多轮对话如何减少多重含义，进而提高代码准确性，从而为代码生成提供了多轮交流的价值。", "conclusion": "本文研究了模糊用户目标在数据可视化代码生成中的识别和互动方式，表明多轮对话策略能够有效减少模糊并提升代码准确性。此研究为代码生成提供了实用指导，并强调了多轮交互的价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09379", "html_url": "https://arxiv.org/abs/2510.09379", "title": "序列模型中的任务级洞察来自特征值", "title_en": "Task-Level Insights from Eigenvalues across Sequence Models", "authors": "Rahel Rickenbach,Jelena Trisovic,Alexandre Didier,Jerome Sieber,Melanie N. Zeilinger", "background": "尽管softmax注意力机制在序列模型中表现出色，但其二次复杂度限制了其可扩展性，促使开发了线性替代方案，如状态空间模型（SSMs）。尽管这些替代方案提高了效率，但它们在信息处理方面的根本差异仍然不甚了解。研究团队利用最近提出的一般动力系统框架，将softmax、归一化和线性注意力表示为动力系统，通过分析它们各自的特征值谱，进行结构化的比较，以更好地理解信息处理机制的差异。特征值捕获动力系统行为的关键方面，因此研究团队进行了广泛的经验分析，涵盖多种序列模型和基准测试。", "innovation": "利用一阶动力系统框架来表示并分析softmax、归一化和线性注意力机制，通过分析特征值谱来结构化地与状态空间模型进行比较。这项工作首次揭示了特征值如何影响序列模型中的内存和长期依赖性建模，并发现与任务需求一致的频谱特征。此外，研究人员还研究了序列模型中架构修改如何影响特征值谱和任务性能，这进一步证明了特征值分析作为理解、解释并最终提升序列模型能力的有原则度量的重要性。", "conclusion": "特征值分析为解释、理解和优化序列模型的能力提供了有原则的度量标准。通过强调特征值如何影响内存和长期依赖性建模，研究揭示了与任务需求相一致的频谱特征，并展示了如何通过调整架构来改进模型的性能。这些发现将进一步推动序列模型的理论研究和技术应用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09394", "html_url": "https://arxiv.org/abs/2510.09394", "title": "超越单一粒度提示：图的多尺度链式思维提示学习", "title_en": "Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu", "background": "‘预训练提示’范式旨在弥合预训练任务和下游目标之间的鸿沟，从自然语言处理领域扩展到图领域，并取得了显著进展。现有的图提示调优方法通过可学习的提示向量修改输入或输出特征，但这些方法在提示生成过程中仅限于单一粒度（如节点级别或子图级别），忽略了图数据中固有的多尺度结构信息，限制了提示语义的多样性。", "innovation": "本文提出了一种多尺度信息融合到图提示中的多尺度图链式思维（MSGCOT）提示框架。设计了一个轻量级的低秩粗化网络以高效捕获多尺度结构特征作为层次基向量，然后模仿人类从粗到细的认知过程，在每一步推理中动态整合多尺度信息，形成逐步细化的提示链。实验结果表明，MSGCOT在少量样本场景下显著优于最先进的单一粒度图提示调优方法，展示了卓越的性能。", "conclusion": "MSGCOT通过融合多尺度信息，构建了有效的知识表示和推理机制，在图任务中表现出了优于现有方法的性能，特别是在少量样本情况下更为显著。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09393", "html_url": "https://arxiv.org/abs/2510.09393", "title": "ChoirRec：通过LLMs实现低活跃用户转化率预测的语义用户分组", "title_en": "ChoirRec: Semantic User Grouping via LLMs for Conversion Rate Prediction of Low-Activity Users", "authors": "Dakai Zhai,Jiong Gao,Boya Du,Junwei Xu,Qijie Shen,Jialin Zhu,Yuning Jiang", "background": "准确预测低活跃用户（低活动用户）的转化率（CVR）仍然是大型电子商务推荐系统中的基本挑战。现有方法面临三个关键限制：依赖于噪音大且不可靠的行为信号；因缺乏多样化的交互数据导致用户层面信息不足；系统性偏见倾向于高活跃用户，掩盖了低活跃用户的需求。", "innovation": "为解决上述挑战，提出了ChoirRec，一种利用大规模语言模型（LLMs）构建语义用户组的新框架，以增强低活跃用户的CVR预测。该框架采用双通道架构，包含三个组件：（i）语义用户组生成模块，利用LLMs形成可靠的、跨活动水平的用户集群，从而过滤掉噪音信号；（ii）组感知层次表示模块，丰富稀疏用户嵌入信息，缓解数据不足问题；（iii）组感知多粒度模块，采用双通道架构和自适应融合机制，确保有效学习和利用群体知识。", "conclusion": "我们在淘宝（一家领先的工业规模电子商务平台）上进行了广泛的离线和在线实验，离线评估提高了GAUC 1.16%，在线A/B测试显示订单量增加了7.24%，这突显了其在实际应用中的巨大实用价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09424", "html_url": "https://arxiv.org/abs/2510.09424", "title": "Speech-LLM采取一切：一种真正的端到端口语对话状态跟踪方法", "title_en": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach", "authors": "Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf", "background": "本文研究了使用语音大规模语言模型（Speech-LLMs）进行端到端口语对话状态跟踪时，不同上下文管理策略的效果对比。具体而言，研究了结合文本历史和当前口语轮次的传统多模态上下文、完整口语历史记录以及压缩口语历史记录的方法。", "innovation": "研究发现，将完整口语对话作为输入，可以显著提高模型性能，特别是在相似大小的模型中。此外，基于注意力池化的口语历史压缩方法在保持竞争力的同时，还能有效减少上下文大小，提供了性能与上下文压缩之间的良好权衡。", "conclusion": "详细分析表明，改进的根本原因是更有效的上下文利用。整体而言，这种端到端的方法能够更好地管理口语对话中的上下文，从而提升对话理解与响应的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09421", "html_url": "https://arxiv.org/abs/2510.09421", "title": "自动回归大型语言模型中的实体表示研究", "title_en": "On the Representations of Entities in Auto-regressive Large Language Models", "authors": "Victor Morand,Josiane Mothe,Benjamin Piwowarski", "background": "实体是文本知识的基本构建块，支撑事实信息并结构化语言中的关系。尽管实体很重要，但目前尚不清楚大型语言模型（LLMs）如何内部表示实体。先前的研究主要关注显式的关系，但对于实体本身的表示了解不多。本研究引入了一种名为实体提及重建的新框架，用于研究LLMs如何编码和操作实体。该研究通过探索能否从内部表示中生成实体提及，多词实体是如何编码的，以及这些表示是否捕捉到了关系知识来填补这一空白。", "innovation": "本研究提出了结合任务向量的实体提及重建方法，能够在LLMs隐藏状态衍生出的各种实体表示上一致地生成多词提及。进一步地，该研究提出了实体镜像（Entity Lens），扩展了逻辑镜像（logit-lens）以预测多词提及。结果显示，LLMs发展了实体特异的机制来表示和操纵任何多词实体，包括那些训练中未见过的实体。", "conclusion": "本研究为LLMs开发了实体具体机制以表示和操纵任何多词实体提供了新的证据，尤其是未见过的实体。此外，所提出的实体镜像扩展了逻辑镜像以预测多词提及。相关代码可在链接处获取。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09425", "html_url": "https://arxiv.org/abs/2510.09425", "title": "具有单一峰值偏好的带限资源多臂老虎机问题", "title_en": "Bandits with Single-Peaked Preferences and Limited Resources", "authors": "Gur Keinan,Rotem Torkan,Omer Ben-Porat", "background": "研究了一个在线随机匹配问题，在该问题中，算法在满足预算约束的情况下，顺序将用户与臂匹配，目标是在 T 轮内最大化累计奖励。在没有结构性假设的情况下，计算最优匹配是 NP 难问题，使在线学习变得计算上不可行。给出了一种单峰值偏好方法，这是一种在社会选择理论中已建立的结构，即用户的偏好在对臂的共同顺序中是单峰的。通过这种方法，研究者设计了一个适用于预算内匹配问题的高效算法，并将其扩展为一个在线算法，遗憾度为 \tilde O(UKT^{2/3})。", "innovation": "提出了基于新型 PQ 树的顺序近似方法，用于预算约束下的离线匹配问题。此外，如果已知单峰值结构，则开发了一个高效类似 UCB 的算法，遗憾度为 \tilde O(U\rawt{TK})。这种方法通过利用单峰值偏好结构，解决了在线学习算法面临的计算可行性问题，提高了匹配效率和算法性能。", "conclusion": "研究表明，在存在预算约束的情况下，单峰值偏好在最大化用户与臂之间的匹配匹配奖励方面是有效的。对于单峰值偏好结构，提出了一个近似于 UCB 的高效在线推荐算法，遗憾度为 \tilde O(U\rawt{TK})；对于更一般的情况，则设计了一个遗憾度为 \tilde O(UKT^{2/3}) 的在线算法。这些方法提供了在在线决策环境中进行资源分配的新视角和方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09459", "html_url": "https://arxiv.org/abs/2510.09459", "title": "生成机器人策略运行时的故障预测", "title_en": "Failure Prediction at Runtime for Generative Robot Policies", "authors": "Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig", "background": "生成模型如扩散和流匹配的模仿学习使机器人能够执行复杂的长历时任务。然而，从未见过的环境或累积的动作错误导致的分布变化可能会造成不可预测且不安全的行为，导致任务失败。因此，在人类中心和安全关键环境中部署机器人时，运行时早期故障预测是必要的。", "innovation": "提出了一种名为FIPER（故障预测运行时框架）的一般框架，用于生成IL（模仿学习）策略，无需故障数据。该框架通过在策略的嵌入空间中使用随机网络蒸馏识别异常观察以识别即将发生故障的两个关键指标：（i）检测到的离群值观察；（ii）在新生成的行动中测量的高不确定性。两个故障预测分数通过一小组成功的运转进行校准，并根据两个指标在短时间窗口内的聚合值超过其阈值触发故障警报。该框架在涉及多种类型故障模式的五个模拟和真实环境中进行了评估。", "conclusion": "FIPER能够更好地将实际故障与良性离群值情况区分开，并且比现有方法更早更准确地预测故障。因此，本文被认为是朝着更解释性和更安全的生成机器人策略的重要步骤。相关代码、数据和视频可参见this https URL。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09458", "html_url": "https://arxiv.org/abs/2510.09458", "title": "SilvaScenes: 树下图像中自然森林中树木分割与物种分类的数据集", "title_en": "SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests", "authors": "David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère", "background": "对于森林管理的机器人技术兴趣正在增长，但在复杂自然环境中的认知仍然是一大障碍。重遮挡、光照变化和茂密植被等条件，对自动化系统构成了挑战，这些系统对于精确林业、生物多样性监测以及林业设备的自动化至关重要。现有的数据集无法开发出这样的感知系统，因为它们往往关注于城市环境或限于少数几种物种。为此，我们介绍了SilvaScenes，一个新的用于树下图像树木分割的树种数据集，其涵盖了加拿大魁北克省五个不同的气候带，包括1476棵树，来自24个物种，注解由林业专家完成。", "innovation": "推出了SilvaScenes数据集，专为树下图像中的树木分割和物种分类。该数据集是首个针对复杂自然环境的，涵盖了5个生物气候区的多种树种，具有详细的林业专家注解。通过基准测试现代深度学习方法进行实例分割，展示了树木分割相对容易，但物种分类是重大挑战。", "conclusion": "SilvaScenes数据集和源代码将在 https:// [链接] 获取。结果表明，尽管树木分割的顶级mAP得分达到了67.65%，但物种分类的mAP得分仅为35.69%，证明了数据集的挑战性质。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09462", "html_url": "https://arxiv.org/abs/2510.09462", "title": "可信监测模型的适应性攻击颠覆AI控制协议", "title_en": "Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols", "authors": "Mikhail Terekhov,Alexander Panfilov,Daniil Dzenhaliou,Caglar Gulcehre,Maksym Andriushchenko,Ameya Prabhu,Jonas Geiping", "background": "AI控制协议作为一种防御机制，在自主环境中防止不可信的大语言模型（LLM）代理造成伤害。以往的工作将此视为一个安全问题，通过利用部署环境来稍纵即逝地完成恶意任务（如后门插入）来检测这些问题。然而，实际中大多数AI控制协议本质上依赖于LLM监控器，这些监控器可能会成为系统的核心弱点。", "innovation": "本文研究了由了解协议和监控模型的不可信模型发起的适应性攻击。该攻击通过在模型输出中嵌入公开已知或零样本提示注入来实现，使得前沿模型能够避开不同类型的监控器并完成恶意任务。这项工作强调，对监视模型的适应性攻击是当前控制协议的一个重大安全隐患，并应当被视为对未来AI控制机制评估的标准组成部分。", "conclusion": "针对监视模型的适应性攻击是对现有AI控制协议的重大威胁，最新的Defer-to-Resample协议甚至适得其反，其采样的增强效应实际上将提示注入转为了一种‘最佳n次’攻击。因此，该研究提出了一个关键的见解，即应当在未来的评估中包含针对这种攻击的测试，以增强AI控制机制的安全性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09469", "html_url": "https://arxiv.org/abs/2510.09469", "title": "使用碰撞感知动态警报掩码和混合执行策略的大规模多智能体路径规划", "title_en": "Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy", "authors": "Bharath Muppasani,Ritirupa Dey,Biplav Srivastava,Vignesh Narayanan", "background": "多智能体路径规划（MAPF）在机器人学和自主系统中是一个关键问题，涉及高效导航共享空间并避免冲突。传统的集中式算法虽然能提供高质量解决方案，但在大规模场景中由于冲突组合爆炸而变得计算代价高昂。相反，分布式方法虽然具有更好的可扩展性，但由于信息可用性较低，往往牺牲了解决方案的质量。", "innovation": "本文提出了一种结合了去中心化路径规划和轻量级集中式协调器的混合框架。该框架利用强化学习（RL）进行去中心化规划，使智能体能够在最少的、有针对性的警报下（例如静态冲突单元标志或短暂冲突轨迹）动态共享信息以有效解决冲突。研究了智能体可利用的信息对其规划性能的影响。与完全集中式和分布式方法相比，该方法减少了智能体之间的信息共享，但仍能一致地找到可行的、无碰撞的解决方案，即使是在具有更多智能体的大型场景中也是如此。", "conclusion": "本文通过比较不同信息级别对智能体规划性能的影响，提出了一个减少智能体之间信息共享但仍能有效解决冲突的混合执行策略。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09474", "html_url": "https://arxiv.org/abs/2510.09474", "title": "多模态政策内化在对话代理中的应用", "title_en": "Multimodal Policy Internalization for Conversational Agents", "authors": "Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya", "background": "现代对话代理如ChatGPT和Alexa等依赖预先定义的策略来指定元数据、响应方式和工具使用规则。随着基于大语言模型的系统扩展以支持多样化的商业和用户查询，这些策略变得越来越复杂和冗长，难以忠实执行并产生较大的固定计算成本。随着多模态代理的兴起，管理和行为策略变得更加重要但也一直较少研究。之前的提示压缩工作主要缩短了任务模板和示范，而现有的策略对齐研究仅关注文本安全规则。研究人员引入了多模态政策内化（MPI），这是一种将复杂多模态策略内化为模型参数的新任务，从而在推理时不包含政策，就能提高政策执行的能力。MPI带来了独有的数据和算法挑战。", "innovation": "研究人员提出了MPI，这是一种能够将复杂多模态策略内化为模型参数的新任务，使得对话代理能够更好地遵循策略而无需将策略包含在推理过程中。这种方法设计了两个涉及合成和现实世界决策的多模态任务数据集，提出了一个基于预训练、监督微调和PolicyRollout的三阶段训练框架。通过这种方式，MPI显著提高了端到端的准确性、泛化能力以及遗忘鲁棒性。台上发布的内容包括数据集、训练方法和全面评估，以促进未来的研究。", "conclusion": "作为首个多模态政策内化的研究工作，该研究为对话代理的未来发展提供了数据集、训练框架和全面评估，促成了未来的研究进展。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09493", "html_url": "https://arxiv.org/abs/2510.09493", "title": "机器学习算法在慢性肾病预测中的性能分析", "title_en": "Performance Analysis of Machine Learning Algorithms in Chronic Kidney Disease Prediction", "authors": "Iftekhar Ahmed,Tanzil Ebad Chowdhury,Biggo Bushon Routh,Nafisa Tasmiya,Shadman Sakib,Adil Ahmed Chowdhury", "background": "全球约有10%的人口遭受慢性肾病（CKD）的影响，这会导致肾功能下降。为了保护处于危险中的患者，避免进一步的肾损伤，以及实现有效的风险评估和适当的监测，需要快速且精确的诊断方法。机器学习模型能够提供这样的能力，使得在医疗领域越来越多的诊断系统和过程依赖于机器学习来进行疾病预测。", "innovation": "基于机器学习模型的预测计算机辅助设计被设计并建议用于CKD的诊断。数据缺失值通过“平均数-模式”和“随机采样法”策略填充，经过数据处理后的模型使用了8种不同的机器学习技术（随机森林、支持向量机、朴素贝叶斯、逻辑回归、K近邻、XGBoost、决策树和AdaBoost）来建立模型。通过性能评估比较结果准确性，确定了具有最高准确性的机器学习模型。", "conclusion": "随机森林和逻辑回归机器学习模型表现突出，准确率达到了99%，其次是AdaBoost、XGBoost、朴素贝叶斯、决策树和支持向量机，而K近邻模型的准确率为73%，排名最低。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09495", "html_url": "https://arxiv.org/abs/2510.09495", "title": "使用VQ-VAE和GNN的多用户FDD系统预编码设计", "title_en": "Precoder Design in Multi-User FDD Systems with VQ-VAE and GNN", "authors": "Srikar Allaparapu,Michael Baur,Benedikt Böck,Michael Joham,Wolfgang Utschick", "background": "在频分双工(FDD)系统中，通过一个生成模型融入传播环境的学习统计数据可以高效实现鲁棒预编码。论文基于先前成功使用高斯混合模型(GMM)和图神经网络(GNN)组合设计特定站点预编码的工作，提出了一个新的方法，该方法采用了向量量化变分自编码器(VQ-VAE)来克服GMM的一个关键缺点：混合成分的数量随着反馈位数的增加呈指数增长。此外，VQ-VAE的深度学习架构使得可以在预编码向量训练的同时训练GNN和VQ-VAE，形成端到端模型，从而在多用户无线系统中实现显著的传输速率增益。模拟结果表明，所提出的框架优于涉及次离散傅立叶变换(DFT)试点矩阵和迭代预编码算法的传统方法，可以部署使用较少试点或反馈位数的系统。", "innovation": "论文创新地引入了向量量化变分自编码器(VQ-VAE)来克服高斯混合模型的缺点，并首次将GNN和VQ-VAE联合训练用于预编码设计，形成端到端模型，显著提高了多用户FDD系统的传输速率。此外，该方法允许在较少的试点或反馈位数的条件下进行系统部署。", "conclusion": "使用VQ-VAE和GNN的预编码设计方法在多用户FDD系统中展现出明显的优势，特别是在减少反馈位数或试点数量的情况下。该方法可以有效提升系统的传输性能，具有广泛的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09499", "html_url": "https://arxiv.org/abs/2510.09499", "title": "一种基于临床驱动的交互式分割评估方法", "title_en": "A methodology for clinically driven interactive segmentation evaluation", "authors": "Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso", "background": "交互式分割是构建鲁棒且可移植的医学图像分割算法的有前景策略，但现有的不一致且缺乏临床现实性的评估方法阻碍了公平比较，并误导了其实际性能。该研究旨在通过一个新的临床驱动的方法来定义评估任务和指标，从而建立标准的评估管道，进一步评估先进的图像分割算法在不同和复杂任务中的表现。", "innovation": "提出了一种临床导向的交互式分割评估方法，包括定义临床驱动的评估任务和指标，并构建了标准化的评估管道框架。研究发现了几个关键点，如减小处理用户交互的信息损失对模型稳健性至关重要，自适应放大机制能够增强稳健性和加速收敛，以及不同验证提示行为/预算对训练不同将影响性能等。还探讨了二维和三维分割算法在不同类型图像上的表现差异。因此，该研究为临床驱动的评估方法提供了一种新的视角，有助于提高医学图像分割算法的实际应用效果和稳健性。", "conclusion": "研究通过新的临床驱动的方法评估了多种先进的图像分割算法，发现了一系列关键因素影响模型的性能，并揭示了二维和三维分割算法在特定图像条件下的表现差异。该研究为后续的医学图像分割算法研究提供了重要的指导意义和实验证据。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09497", "html_url": "https://arxiv.org/abs/2510.09497", "title": "基于模仿学习的自主软机器人导丝导航", "title_en": "Autonomous Soft Robotic Guidewire Navigation via Imitation Learning", "authors": "Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger", "background": "在血管内手术中，医生通过一根细长的导管（由细线引导）到达患者的血管内部，以治疗血栓、动脉瘤和其他血管畸形。机器人导丝的末端可以增强操作灵活性，但对其建模和控制提出了挑战。通过自动化软机器人导丝导航，有望克服这些挑战，提高血管内导航的精确性和安全性。其他手术领域中已经成功应用了端到端模仿学习。该论文基于这些研究成果，开发了一种基于转录器的目标条件模仿学习框架，通过相对动作输出和自动对比造影剂注射来实现自主通用的软机器人导丝在动脉瘤定位任务中的导航。实验中，该模型在36种不同模块化的分枝几何结构上进行了训练，并在3种未见过的血管几何结构上进行了评估，成功驱动机器人导丝尖端至动脉瘤位置的比例达到了83%，超过了一些基线模型。此外，还进行了消融和基线研究，评估了每个设计和数据收集选择的有效性。", "innovation": "该研究开发了一种基于转录器的目标条件模仿学习框架，用于软机器人导丝的自主导航。该框架结合了相对动作输出和自动对比造影剂注射，用于动脉瘤定位任务。通过这一方法，实现了在多个未见过的几何结构中高精度的自主导丝导航，并通过实验验证了其有效性。同时，进行了消融研究来评估不同设计和数据收集选择的有效性。", "conclusion": "开发的框架能够成功地实现软机器人导丝的自主导航，特别是在未见过的几何结构中表现出了83％的成功率，这远远超过了现有的基线模型。该研究为未来软机器人导丝导航的自动化奠定了坚实的基础，并提供了有效的设计选择以改善未来的系统表现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09535", "html_url": "https://arxiv.org/abs/2510.09535", "title": "通过推理塑造来缓解过度思考", "title_en": "Mitigating Overthinking through Reasoning Shaping", "authors": "Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang", "background": "大型推理模型（LRMs）通过验证者奖励进行强化学习（RLVR）的进步使得问题解决变得非常强大，但这些模型往往会引发过度思考：一种冗长的推理过程，增加了计算成本。之前的RLVR设计虽然能减少令牌消耗，但通常会损害模型性能，这是因为令牌级别的监督过于简单。", "innovation": "本文提出了一种分组相对段落惩罚方法（GRSP），这是一种基于步骤级别的方法，用于正则化推理过程。由于初步分析表明，推理段落强烈关联于令牌消耗和模型性能，我们设计了一个基于长度感知的权重机制，跨越段落集群。大量的实验表明，GRSP在不大幅牺牲准确性的情况下实现了卓越的令牌效率，并且在更困难的问题上尤其有优势。此外，GRSP还稳定了RL训练，并且在不同的模型规模上扩展有效。", "conclusion": "GRSP既改善了令牌效率，又保持了模型性能，特别在处理更难问题时表现优异。此外，该方法还有效地稳定了RL训练，并且在不同模型规模上都有良好的扩展性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09599", "html_url": "https://arxiv.org/abs/2510.09599", "title": "Prompting Test-Time Scaling 是一种强大的大语言模型推理数据扩充方法", "title_en": "Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation", "authors": "Sondos Mahmoud Bsharat,Zhiqiang Shen", "background": "大语言模型在获得链式思考示例的情况下展现了惊人的推理能力，但创建大规模推理数据集仍旧耗费大量时间和资源。", "innovation": "提出了一种名为P-TTS的简单而有效的推理时数据扩充策略，仅利用90个手动选择的推理示例，并通过在测试时系统地变化示例扩增指令来生成多样化的推理轨迹环境。然后，对不同规模的Qwen-2.5模型进行P-TTS数据的微调。", "conclusion": "P-TTS策略在AIME2024、AIME25、MATH500和GPQA-Diamond等多种数学推理基准测试中表现出色，与过去的竞争性基线相比，取得了显著的准确性提升。此外，P-TTS增强了大语言模型在新的问题领域中的零样本泛化能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09541", "html_url": "https://arxiv.org/abs/2510.09541", "title": "SPG: 沙威式策略梯度方法在掩码扩散语言模型中的应用", "title_en": "SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models", "authors": "Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu", "background": "扩散大规模语言模型（dLLMs）由于其并行解码多个令牌的能力，已经作为一种有效的替代自回归模型。然而，通过强化学习（RL）使dLLMs与人类偏好或任务特定奖励对齐是有挑战性的，因为它们不具解析似然性使得标准策略梯度方法难以直接应用。先前的工作使用似然下界（ELBO）等替代方法，但由于这些方法的一面性，可能会引入显著的策略梯度偏差。", "innovation": "本文提出了一种新的策略梯度方法——沙威式策略梯度（SPG），这种方法利用真似然性的上下界。实验表明，SPG在GSM8K、MATH500、Countdown和Sudoku等任务上都显著优于基于ELBO或一步估计的基线方法，特别是在dLLMs的RL方法中，SPG在准确率上分别提高了3.6%、2.6%、18.4%和27.0%。", "conclusion": "实验结果表明，SPG在GSM8K、MATH500、Countdown和Sudoku等任务中明显优于基于ELBO或一步估计的基线方法，尤其在dLLMs的RL方法方面，SPG的准确率提高了3.6%至27.0%。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09596", "html_url": "https://arxiv.org/abs/2510.09596", "title": "BaNEL: 使用仅负奖励进行生成建模的探索后验", "title_en": "BaNEL: Exploration Posteriors for Generative Modeling Using Only Negative Rewards", "authors": "Sangyun Lee,Brandon Amos,Giulia Fanti", "background": "今天的生成模型依赖大量的监督数据和有信息量的奖励函数来提高生成质量。这些模型假设监督数据能够预先训练模型，并且奖励函数能够提供详细的信息指导进一步改进生成质量。但在某些重要问题的最难实例中，出现了两个问题：(1)基础生成模型获得了接近零的奖励信号；(2)调用奖励 oracle 的成本很高。这种情况下，生成学习面临的标准奖励后训练方法不同，提出了新的挑战。", "innovation": "本文提议了一种新的方法 BaNEL (Bayesian Negative Evidence Learning)，它仅使用失败尝试进行后训练，并尽量减少奖励评估次数（NREs）。该方法基于一个思想，即学习失败背后规律的问题可以重新表述为另一个，嵌入循环的生成建模问题。通过这种方法评估新数据与之前失败数据的相似度，从而指导生成避开这些失败数据。这一方法无需观察成功的样本便能提升模型性能并在成功率方面显著优于现有方法，同时减少了奖励评估次数。", "conclusion": "BaNEL 在多个稀疏奖励任务中证明了其有效性，成功地提高了模型性能，并显著优于现有的新颖性奖励方法，在成功率方面甚至高出多个数量级，同时减少了所需的奖励评估次数。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09577", "html_url": "https://arxiv.org/abs/2510.09577", "title": "Dyna-Mind：从经验中学习模拟以提高AI代理能力", "title_en": "Dyna-Mind: Learning to Simulate from Experience for Better AI Agents", "authors": "Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao", "background": "尽管推理模型在数学和编程等领域的表现显著，但在长周期的交互任务，如网络导航和电脑使用中却表现不佳。研究受人类认知启发，指出当前AI代理需要‘代偿性试验和错误’，即具有在行动前在心中模拟未来的能力，以增强其在复杂交互环境中的理解和表现。", "innovation": "提出了Dyna-Mind，这是一种两阶段的训练框架，明确地教授（V）LM代理在推理中整合模拟。第一阶段引入了Reasoning with Simulations (ReSim)，将代理人训练以从环境互动中搜集的真实体验构建的扩充搜索树生成结构化的推理轨迹。第二阶段提出了Dyna-GRPO，这是一种在线强化学习方法，通过使用结果奖励和中间状态作为实时回放的反馈，进一步增强代理的模拟和决策能力。在两项合成基准（Sokoban和ALFWorld）和一项真实基准（AndroidWorld）上进行的实验表明，ReSim能有效地增强模拟能力，Dyna-GRPO利用结果和互动级别的信号来学习更好的长周期规划任务政策。", "conclusion": "这些结果突显了模拟在使AI代理在不断挑战的环境中更有效地进行推理、规划和行动中的核心作用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.04014", "html_url": "https://arxiv.org/abs/2311.04014", "title": "Y算子在一类基于随机微分方程子-母系统的增强学习性能改进方法", "title_en": "A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems", "authors": "Cheng Yin,Yi Chen", "background": "本文介绍了Y算子来提升在随机微分方程（SDEs）控制下的基于演员-批评家（AC）的强化学习中的控制性能。Y算子将一类子-母系统的随机性巧妙地整合到批评家网络的损失函数中，大幅提升了强化学习的控制性能。此外，该方法将求解状态值函数的偏微分方程问题重构为系统SDEs内的漂移和扩散函数的并行问题。", "innovation": "1. 提出了Y算子，将一类子-母系统的随机性整合到批评家网络的损失函数中，提高了强化学习的控制性能。\n2. 通过将解决状态值函数的偏微分方程问题转化为系统SDEs内的漂移和扩散函数的并行问题。\n3. 提出的基于Y算子的强化学习框架（YORL）在模型导向和数据驱动的问题上表现出优越性。", "conclusion": "通过线性和非线性的数值例子，证实了YORL框架在最优控制问题上的优越性能，并且在收敛后性能优于现有方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09608", "html_url": "https://arxiv.org/abs/2510.09608", "title": "StreamingVLM：无限视频流的实时理解", "title_en": "StreamingVLM: Real-Time Understanding for Infinite Video Streams", "authors": "Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han", "background": "视觉-语言模型（VLMs）能够驱动实时助手和自主代理，但面临关键挑战：理解近乎无限的视频流而不增加延迟和内存使用。对整段视频进行全面注意力处理会产生二次计算成本，并且在长视频上表现不佳。简单滑动窗口方法也存在缺陷，可能会破坏连贯性或由于冗余重新计算导致高延迟。", "innovation": "本文介绍了一种名为StreamingVLM的新模型，设计用于处理无限视觉输入的实时、稳定理解问题。其统一框架与流式推理训练一致。在推理过程中，通过重用注意力池的状态、一个最近视图标记的短窗口以及一个最近文本标记的长窗口，来维护紧凑的键值缓存。这种流式能力通过简单的监督微调（SFT）策略实现，该策略对重叠的短视频块应用全面注意力，从而在无需训练长上下文的情况下，模仿推理时的注意力模式。", "conclusion": "在新的基准测试Inf-Streams-Eval上，StreamingVLM显示出66.18%的胜率，并且在单个NVIDIA H100上能保持高达8 FPS的稳定实时性能。值得注意的是，SFT策略还能提升通用视觉问答能力，改进LongVideoBench上4.30%和OVOBench Realtime上5.96%的性能。代码可在该链接获取：this https URL。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12669", "html_url": "https://arxiv.org/abs/2502.12669", "title": "Perovskite-LLM: 研究中增强知识的大语言模型", "title_en": "Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research", "authors": "Xiang Liu,Penglei Sun,Shuyan Chen,Longhan Zhang,Peijie Dong,Huajie You,Yongqi Zhang,Chang Yan,Xiaowen Chu,Tong-yi Zhang", "background": "perovskite 太阳能电池（PSCs）的研究快速发展，导致相关研究论文迅速增加。这迫切需要有效的知识管理和推理系统来支持该领域的工作。现有的知识管理工具和技术无法满足日益增长的研究需求，因此，开发一种专门针对PSCs的综合知识增强系统变得尤为重要。", "innovation": "该论文提出了一个全面的知识增强系统，该系统整合了三个关键组件：Perovskite-KG（一个包含1517篇研究论文的知识图谱，涵盖了23,789个实体和22,272个关系），Perovskite-Chat（包含55,101个高质量问答对的多代理框架生成的数据集）以及Perovskite-Reasoning（包含2,217个材料科学问题的数据集）。此外，还介绍了两个专门的大型语言模型：Perovskite-Chat-LLM（提供领域知识支持），Perovskite-Reasoning-LLM（用于科学推理任务）。实验结果表明，该系统在领域知识检索和科学推理任务上显著优于现有模型，为研究人员提供了有效工具，支持文献回顾、实验设计和复杂问题解决等工作。", "conclusion": "研究结果证明，所提出的系统在PSC领域知知识检索和科学推理任务上表现优异，为研究人员提供了强大的工具支持，有助于提高研究效率和创新能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08011", "html_url": "https://arxiv.org/abs/2502.08011", "title": "训练无需求的安全去噪器以安全使用扩散模型", "title_en": "Training-Free Safe Denoisers for Safe Use of Diffusion Models", "authors": "Mingyu Kim,Dongjun Kim,Amman Yusuf,Stefano Ermon,Mijung Park", "background": "随着强大扩散模型（DMs）的广泛应用，人们对其安全性越来越担忧。这些模型常被误用于生成不适宜的工作内容（NSFW），产生未经授权的内容或个体不愿被记住的数据。现有方法通常依赖于文本负面提示或重训DMs来消除特定特征或样本，但这些方法可能会造成效率和效果的难题。因此，迫切需要一种无需训练或微调DMs的新方法，直接修改采样轨迹，以避免特定数据分布区域中的不安全内容，确保生成的内容安全。", "innovation": "本文提出了一个训练无需求的安全去噪器，通过引入一个否定集（如不安全图像、版权数据或需要排除的数据点），直接修改采样轨迹，从而生成没有需要排除的数据区域中的安全样本。这是通过正式推导安全去噪生成的预期插值样本与非安全样本之间的关系实现的，从而确保最终生成的样本远离需要排除的区域。该方法适用于文本条件、类别条件和无条件图像生成场景，实现了高质量样本的生成，同时避免了数据分布中的否定区域。", "conclusion": "该训练无需求的安全去噪器提供了利用DMs时避免不安全性的一种潜在解决方案，使得DMs在实际应用中更加安全，且无需对模型进行训练或微调。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14229", "html_url": "https://arxiv.org/abs/2503.14229", "title": "HA-VLN 2.0: 在离散和连续环境中具有动态多参与者互动的人本导航开放基准和排行榜", "title_en": "HA-VLN 2.0: An Open Benchmark and Leaderboard for Human-Aware Navigation in Discrete and Continuous Environments with Dynamic Multi-Human Interactions", "authors": "Yifei Dong,Fengyi Wu,Qi He,Zhi-Qi Cheng,Heng Li,Minghan Li,Zebang Cheng,Yuxuan Zhou,Jingdong Sun,Qi Dai,Alexander G Hauptmann", "background": "视觉-语言导航（VLN）研究主要集中在离散或连续环境中，对动态、拥挤环境的关注较少。HA-VLN 2.0 旨在解决这个问题，提供了一个包含明确社会意识约束的统一基准，旨在提高导航的鲁棒性，并减少碰撞，强调了以人为本的方法的重要性。", "innovation": "HA-VLN 2.0 的贡献包括：(i) 标准化的任务和评估指标，捕捉目标准确性与个人空间合规性；(ii) HAPS 2.0 数据集和模拟器，建模了多人类互动、户外环境和更精细的语言-动作对齐；(iii) 在 16,844 条社会基础指令上进行基准测试，揭示了领先代理在人类动态和部分可观察性下的性能下降；(iv) 实际机器人实验验证了模拟向现实世界的过渡，并公开了排行榜以实现透明比较。", "conclusion": "结果表明，明确的社会建模可以提高导航的鲁棒性并减少碰撞，强调了以人为本的方法的必要性。通过发布数据集、模拟器、基线和协议，HA-VLN 2.0 为安全、社会负责任的导航研究提供了坚实的基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14241", "html_url": "https://arxiv.org/abs/2504.14241", "title": "基于知识引导的深度学习范式用于可泛化和优化稳定性的跟随车模型", "title_en": "A Knowledge-Informed Deep Learning Paradigm for Generalizable and Stability-Optimized Car-Following Models", "authors": "Chengming Wang,Dongyao Jia,Wei Wang,Dong Ngoduy,Bei Peng,Jianping Wang", "background": "跟随车模型（CFMs）对于交通流量分析和自动驾驶至关重要，尽管物理基础的校准模型和数据驱动训练的模型能够模拟人类驾驶行为，但它们依赖特定的数据集限制了泛化能力，降低了在实际部署中的可靠性。此外，这些模型通常仅关注行为的真实性，而不支持对局部和链式稳定性的显式优化，这对于自动驾驶车辆的安全和高效运行愈发重要。", "innovation": "提出了一种知识引导的深度学习（KIDL）范式，该范式借鉴了预先训练的大语言模型（LLMs）的一般泛化能力，将其转化为一种轻量级且关注稳定性的神经网络架构。KIDL 通过知识蒸馏提取超越数据集特定模式的汽车跟随知识，并将其传输到一种可靠且计算效率高的模型中。此外，KIDL 直接将稳定性约束纳入训练目标中，确保生成的模型既能够模拟类似人类的行为，又能够满足适用于自动驾驶车辆实际部署的局部和链式稳定性要求。", "conclusion": "KIDL 在实际部署的 NGSIM 和 HighD 数据集上进行评估，并且其性能与代表性的物理基础、数据驱动和混合跟随车模型进行比较。实验和理论结果一致表明，KIDL 在行为泛化和交通流稳定性方面表现出优越性，提供了一种适用于下一代交通系统的稳健且可扩展的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17312", "html_url": "https://arxiv.org/abs/2505.17312", "title": "AdaReasoner：适配的推理使大型语言模型的思考更具灵活性", "title_en": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models", "authors": "Xiangqi Wang,Yue Huang,Yanbo Wang,Xiaonan Luo,Kehan Guo,Yujun Zhou,Xiangliang Zhang", "background": "LLMs在处理需要复杂推理和解决问题的任务时，往往需要有效的配置，例如温度和推理步骤。现有的提示方法通常采用通用的固定配置，这些配置在大多数任务中表现良好，但在任务特定优化方面表现不佳。", "innovation": "本文介绍了一种LLM-无关的插件AdaReasoner，旨在为任务提供不同的推理配置。AdaReasoner利用强化学习框架进行训练，结合了分解的动作空间、目标探索策略和先训练的奖励模型，以优化策略模型来实现快速收敛并减小策略差距。在多种任务中，AdaReasoner均优于标准基线，并且能够保持分布外鲁棒性和复杂的知识密集型任务上的增益。", "conclusion": "AdaReasoner在六个不同LLM和各种推理任务上表现出色，能够自适应地为任务提供最佳的推理配置，并且能够提高知识密集型任务的表现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18781", "html_url": "https://arxiv.org/abs/2508.18781", "title": "AniME：长动画生成的自适应多代理规划", "title_en": "AniME: Adaptive Multi-Agent Planning for Long Animation Generation", "authors": "Lisai Zhang,Baohan Xu,Siqian Yang,Mingyu Yin,Jing Liu,Chao Xu,Siqi Wang,Yidi Wu,Yuxin Hong,Zihao Zhang,Yanzhang Liang,Yudong Jiang", "background": "当前，动漫制作是一个劳动密集型且复杂的流程，涵盖了从剧情设定到最终视频制作的全部环节。随着人工智能技术的发展，自动化动漫生成成为可能，但现有的系统往往缺乏全局视角和针对性的细致管理。", "innovation": "AniME 提出了一种导演导向的多代理系统，它可以自动化地完成长格式动漫的制作，从故事到最终视频。系统通过全局记忆机制和定制的 Model Context Protocol (MCP) 与下游模型指令集成，实现了专门代理的自适应策略选择，从而生成一致的角色动画和同步的音频视觉元素。", "conclusion": "AniME 提供了一个可扩展的解决方案，适用于人工智能驱动的动漫创作，能够实现高质量、一致性和同步性要求的动画生成，增强了动漫制作过程的自动化水平和效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12493", "html_url": "https://arxiv.org/abs/2505.12493", "title": "GUI-Shift：通过自我监督的增强学习提升基于VLM的GUI代理", "title_en": "GUI-Shift: Enhancing VLM-Based GUI Agents through Self-supervised Reinforcement Learning", "authors": "Longxi Gao,Li Zhang,Pengzhi Gao,Wei Liu,Jian Luan,Mengwei Xu", "background": "训练有效的视觉-语言模型（VLMs）用于GUI代理通常依赖于大规模注释数据集，数据集的收集过程既耗时又容易出错。因此，本文提出了一种新的自监督逆动力学任务K-step GUI Transition，该任务使VLM可以学习GUI动态，而不需要自然语言指令，从而能够从现有GUI轨迹或自动探索中大规模构建数据集。在此基础上，本文提出了一种结合规则优化和数据筛选的强化学习（RL）框架GUI-Shift，以提高VLM的性能。", "innovation": "提出了K-step GUI Transition自监督逆动力学任务，解决了无需自然语言指令收集大规模标记数据的问题，进而提出了结合规则优化和数据筛选的提升VLM性能的强化学习框架GUI-Shift。在多基准测试中展示了优异的模型泛化能力和性能提升（最多11.2%的自动化GUI准确性提升），并且强调了自我监督的RL在利用未标记的GUI轨迹方面具有潜力，提供了一种无需标注样本训练的可扩展替代方法", "conclusion": "本研究证明了自我监督的强化学习在利用未标记的GUI轨迹方面的潜力，并提出了一种基于此的可扩展的训练方法，无需依赖标记样本数据集。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15327", "html_url": "https://arxiv.org/abs/2508.15327", "title": "基于搜索的信用分配对于离线基于偏好的强化学习", "title_en": "Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning", "authors": "Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li", "background": "离线强化学习是从固定数据集中学习策略的过程，不需要额外的环境交互。然而，它通常依赖于明确定义的奖励函数，这些奖励函数的定义既困难又昂贵。使用人类反馈是一个有吸引力的选择，但专家示范和偏好两种常见形式各有局限性。专家示范提供了步骤级的监督，但收集成本高昂且往往反映有限的专家行为模式。相比之下，偏好更容易收集，但难以明确行为中的哪些部分对轨迹片段贡献最大，导致责任归属问题未解。", "innovation": "论文引入了一种基于搜索的偏好权重 (SPW) 方案，以统一这两种反馈类型。对于偏好标签轨迹中的每个过渡，SPW 在专家示范中搜索最相似的状态-动作对，并直接从相似性分数中推导出步骤级的重要性权重。这些权重随后用于引导标准的偏好学习，使得能够实现更准确的责任归属，而传统的做法难以完成这一任务。SPW 方法在困难的机器人操作任务中能够有效结合偏好和示范学习，优于之前混合使用这两种反馈类型的其他方法。", "conclusion": "SPW 能够有效结合偏好和示范学习，在难题上超越了之前的综合运用这两种反馈类型的先前方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21862", "html_url": "https://arxiv.org/abs/2509.21862", "title": "通过Shachi重塑基于代理的建模方法，利用大型语言模型代理", "title_en": "Reimagining Agent-based Modeling with Large Language Model Agents via Shachi", "authors": "So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang", "background": "在大型语言模型（LLM）驱动的多代理系统中研究涌现行为是一个关键的研究挑战，但进展受限于缺乏系统性的实验方法。当前的代理设计多为临时性的，缺乏可控制的实验手段，难以系统化地分析特定架构选择对集体行为的影响。", "innovation": "引入了Shachi作为一种形式化的研究方法和模块化框架，将代理政策细分为核心认知组件：内部特质配置、情境持久记忆和扩展能力工具，由LLM推理引擎协调。这种方法超越了脆弱且临时的代理设计，能够系统地分析特定架构选择对集体行为的影响。此外，通过全面的10任务基准测试验证了该方法的有效性，并通过新的科学问题展示了其潜力。利用Shachi建模真实的美国关税冲击，实验结果表明，当代理的认知架构适当配置时，其行为才与市场的实际反应一致。", "conclusion": "该研究为构建和评估LLM代理提供了严格且开源的基础，旨在促进更多累积性和科学化的研究。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00071", "html_url": "https://arxiv.org/abs/2510.00071", "title": "ARS: 自适应推理抑制以提高大型推理语言模型的效率", "title_en": "ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models", "authors": "Dongqi Zheng", "background": "大型推理语言模型（LRLMs或LRMs）在复杂推理任务中表现出显著的能力，但存在着过度推理现象导致的显著计算低效率。现有的高效推理方法面临一个挑战，即平衡推理质量和推理成本的降低。已有方法难以在保持高质量推理的同时有效地降低推理成本。", "innovation": "提出了一种名为自适应推理抑制（ARS）的新型无需训练的方法，它通过自适应的置信度监控动态抑制冗余推理步骤，同时保持准确性。ARS引入了一种多检查点的置信度估计机制，并逐步引入抑制阈值，从而实现了与静态抑制方法相比更高的效率。", "conclusion": "在使用多种模型架构进行数学推理基准评价中，ARS在token、延迟和能耗降低方面分别取得了53%、46.1%和57.9%的改善，同时保持或提高了准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24978", "html_url": "https://arxiv.org/abs/2509.24978", "title": "物理模型的自主探索", "title_en": "Agentic Exploration of Physics Models", "authors": "Maximilian Nägele,Florian Marquardt", "background": "科学研究的过程依赖于观察、分析和假设生成之间的相互作用。机器学习已被用于解决这一过程中的个别方面。然而，完全自动化通过实验和分析探索未知系统的发现过程中的启发式、迭代循环仍然是一个开放性的挑战，这意味着现有的方法往往需要针对特定任务进行定制。本文介绍了一种名为SciExplorer的智能体，它利用大型语言模型的工具使用能力来实现无需特定领域蓝图的探索，并将该智能体应用于初始未知的物理系统中。SciExplorer在涵盖机械动力学系统、波的演化和量子多体物理等多个模型中进行了测试。尽管只使用了最少的工具，主要基于代码执行，但在恢复运动方程和从期望值推断哈密顿量等任务上表现出了出色的效果。这一结果为其他领域中的类似科学探索打开了可能性，无需微调或特定任务的指令。", "innovation": "SciExplorer因其能够利用大型语言模型的工具使用能力进行探索而创新，无需特定领域的相关蓝图，适用于初始未知的物理系统。尽管仅使用基本工具，它在多种物理模型的探索中都表现出色，尤其是在从观察数据恢复运动方程和推断哈密顿量的任务上。这种尝试为其他科学领域的自主探索开辟了新的可能性，无需特定的微调或任务指令。", "conclusion": "SciExplorer在多种复杂的物理模型中展示了高效的探索能力，这表明其可以作为科学发现的一个有力工具，应用于其他未知或复杂的系统，无需经过特定任务的微调。未来的研究可能会进一步提升SciExplorer的能力，使其能够应用于更广泛的科学领域和实际问题。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04670", "html_url": "https://arxiv.org/abs/2510.04670", "title": "改善具有动态主体意识路由的多模态脑编码模型", "title_en": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing", "authors": "Xuanhua Yin,Runkai Zhao,Weidong Cai", "background": "自然场景神经影像学中的fMRI编码必须处理多模态输入、融合风格的变化以及显著的个体间变异性。现有方法难以在此背景下提供一致性和泛化能力。", "innovation": "该研究提出了AFIRE（无偏见的多模态fMRI响应编码框架）和MIND（即插即用的专家混合模型解码器），利用标准化的时间对齐融合标记以及个体感知的动态门控机制，从而实现端到端的全脑预测。AFIRE 解耦解码器和上游融合过程，而MIND 通过标记依赖的Top-K稀疏路由结合个体先验来个性化专家使用，同时保持通用性。实验证明，在各种多模态骨干网络和个体中，该框架取得了优于基线模型的一致改进、增强了个体间泛化能力和可解释的专家模式与内容类型的相关性。框架还提供了新的编码器和数据集的附件点，从而实现稳健的、即插即用的性能提高，以适应自然神经影像学研究。", "conclusion": "该研究表明，通过采用AFIRE和MIND，即使在高度复杂和变量丰富的自然场景中，多模态脑编码模型也能够显著提高预测精度，并增强跨个体的泛化能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06189", "html_url": "https://arxiv.org/abs/2510.06189", "title": "野蛮人到了大门：AI如何颠覆系统研究", "title_en": "Barbarians at the Gate: How AI is Upending Systems Research", "authors": "Audrey Cheng,Shu Liu,Melissa Pan,Zhifei Li,Bowen Wang,Alex Krentsel,Tian Xia,Mert Cemri,Jongseok Park,Shuo Yang,Jeff Chen,Lakshya Agrawal,Aditya Desai,Jiarong Xing,Koushik Sen,Matei Zaharia,Ion Stoica", "background": "人工智能（AI）已经开始改变我们所知的研究过程，通过自动化新的解决方案发现。典型的AI驱动方法包括生成一组多样化的解决方案，然后验证这些解决方案并选择一个解决问题的方案。这一过程假设存在一个可靠的验证器，能够准确地确定一个解决方案是否解决了给定的问题。本文提出，长期专注于设计和评估新性能算法的系统研究特别适合AI驱动的解决方案发现，因为系统性能问题自然有可靠的验证器：解决方案通常在实际系统或模拟器中实现，验证归结为运行这些软件并在预定义的工作负载上进行性能测量。", "innovation": "本文提出了AI驱动的研究方法（ADRS），通过迭代生成、评估和改进解决方案。ADRS已经在penEvolve（一个现有的开源ADRS实例）中得到了实施，应用于多种领域，包括多区域云调度的负载均衡、Mixture-of-Experts推理、基于LLM的SQL查询和事务调度。ADRS发现的算法在多方面超越了现有最佳的人工设计（如最大5.0倍的运行时间改进或50%的成本降低）。此外，文章总结了从提示设计到评估者构建指导算法进化的最佳实践，并讨论了系统研究领域更广泛的机遇与挑战。", "conclusion": "随着AI在算法设计中的核心作用，研究人员将越来越多地关注问题表述和战略指导。研究结果强调了AI颠覆系统研究的潜力以及适应AI时代的研究实践的迫切需求。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07733", "html_url": "https://arxiv.org/abs/2510.07733", "title": "SurveyG: 一种结合层次引文图的多智能体大模型框架实现自动化综述文生成", "title_en": "SurveyG: A Multi-Agent LLM Framework with Hierarchical Citation Graph for Automated Survey Generation", "authors": "Minh-Anh Nguye,Minh-Duc Nguyen,Ha Lan N.T.,Kieu Hai Dang,Nguyen Tien Dong,Dung D. Le", "background": "近年来，大规模语言模型（LLMs）被广泛应用于自动化生成综述论文。现有方法通常会提取大量相关论文的内容，直接用LLM来总结。但这种方法往往忽视了论文之间的结构关系，导致生成的综述缺乏明确的分类体系和对研究进展的深入理解。因此，需要一种新的方法来解决这些问题。", "innovation": "本文提出了一种结合层次引文图的多智能体LLM框架——SurveyG。它通过在综述生成过程中嵌入结构性和语境知识来改进现有的方法。层次引文图包含了研究论文节点及其内容之间的引用依赖性和语义相关性。综述被组织成三个层面：基础、发展和前沿，以捕捉研究从开创性工作到逐步进展和新兴方向的演变过程。SurveyG结合了层内的横向搜索和层间的纵向深度遍历，生成多层次总结，这些总结再被合并成结构化的综述大纲。一个多元智能体验证阶段确保了生成的综述在一致性、覆盖率和事实准确性方面的质量。", "conclusion": "实验结果表明，SurveyG方法胜过现有最先进的框架，生成的综述更加全面且结构合理，更符合特定领域的知识分类体系。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08026", "html_url": "https://arxiv.org/abs/2510.08026", "title": "PEAR：阶段性熵感知奖励机制以实现高效的推理", "title_en": "PEAR: Phase Entropy Aware Reward for Efficient Reasoning", "authors": "Chen Huang,Wei Lu,Wenxuan Zhang", "background": "大型推理模型（LRMs）在进行复杂的推理任务时能够生成详细的推理链（CoT），取得了显著的表现。然而，这些响应往往过长，包含了许多冗余的推理步骤，增加了推理成本并降低了可使用性。目前，如何控制生成的推理长度而不牺牲准确性，实现简洁性和性能的平衡是一个未解的挑战。", "innovation": "本文通过系统性的实验分析，发现模型的熵在不同的推理阶段与响应长度存在一致性正相关关系：思考阶段熵高，反映出较长响应的探索性行为；最终答案阶段熵低，显示出更确定的解决方案。基于这一观察，本文提出了阶段性熵感知奖励（PEAR），这是一种将阶段依赖的熵纳入奖励设计中的机制。PEAR机制在思考阶段抑制过高的熵，并在最终答案阶段允许适度的探索，鼓励模型生成紧凑且保留足够灵活性的推理轨迹，以确保正确解决问题。这使得模型可以在无需显式长度目标或刚性截断规则的情况下实现响应长度的自适应控制。实验结果表明，PEAR在不同规模的模型上能够减少响应长度，同时保持竞争性的准确性，并且在分布外（OOD）的鲁棒性也表现出明显优势。", "conclusion": "本文介绍的PEAR能够在不牺牲准确性的前提下，通过实现响应长度的自适应控制，有效减少了生成的推理长度，并在多个基准上验证了PEAR的有效性和鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.19979", "html_url": "https://arxiv.org/abs/2403.19979", "title": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "title_en": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "authors": "Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang", "background": "类增量学习（CIL）旨在使模型能够持续学习新类，同时克服灾难性遗忘。在引入预训练模型后，为CIL带来了新的调优范式。本文重新审视了不同参数高效调优（PET）方法在持续学习中的应用。实验证明，适配器调优方法优于基于提示的方法，即使在每次学习会话中不扩展参数。", "innovation": "提出了在不施加参数更新约束的情况下增量调整共享适配器，提高了主干的学习能力。此外，通过从存储的原型中采样特征重新训练统一分类器，进一步提高其性能。提出了在无过去样例访问的情况下估计旧原型的语义偏移，并逐会话更新存储原型的方法。所提方法消除了模型扩展，并避免保留任何图像样本。这种方法超越了之前的基于预训练模型的CIL方法，展示了卓越的持续学习能力。", "conclusion": "实验结果显示，我们的方法在五个CIL基准上取得了最先进的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2306.11593", "html_url": "https://arxiv.org/abs/2306.11593", "title": "通过排名和基于LLM的融合提升图像描述详尽性", "title_en": "Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion", "authors": "Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano", "background": "目前最先进的（SoTA）图像描述模型通常在MS-COCO数据集上进行训练，该数据集包含人类标注的短句子，平均每句约十个词。这些模型在理解一般场景方面有效，但短的描述往往未能捕捉复杂的场景和详细信息。此外，图像描述模型倾向于偏向“平均”描述，只能捕捉较为一般的内容，而忽略了细节。本研究基于此背景提出了一种新方法，通过结合多种SoTA模型生成的描述来生成更丰富和详细的信息性图像描述。", "innovation": "本文提出了一种无需额外模型训练的创新方法，通过引入一种新的图像-文本基线分数（BLIPScore），结合SoTA模型生成的初始描述，然后使用大型语言模型（LLM）融合前两个得分最高的描述，生成最终的详细描述。实验结果表明，该方法在图像描述与图像的对齐和幻觉减少方面有效，主观研究进一步验证了这些效果，指出生成的描述通常与人类判断更为一致。", "conclusion": "通过结合多样化的SoTA模型，本文的方法增强了图像描述的质量和吸引力，缩小了自动化系统与人类生成的丰富详细描述之间的差距。这一进步使得能够生成更适合用于训练视觉-语言和图像描述模型的描述。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.17888", "html_url": "https://arxiv.org/abs/2402.17888", "title": "ConjNorm: 可靠密度估计的实用方法用于out-of-distribution检测", "title_en": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection", "authors": "Bo Peng,Yadan Luo,Yonggang Zhang,Yixuan Li,Zhen Fang", "background": "在可靠机器学习中，后验out-of-distribution (OOD)检测已引起广泛关注。许多研究专注于基于logits、距离或严格的数据分布假设来推导得分函数，以识别低得分的OOD样本。然而，这些估计得分可能无法准确反映真实的概率密度，或可能会施加难以实现的限制。", "innovation": "提出了一种新的基于Bregman 发散的理论框架，该框架将分布考虑扩展至指数族分布。通过在定理中揭示的共轭约束，引入了\textsc{ConjNorm} 方法，将密度函数设计重新定义为寻找与给定数据集最优范数系数 $p$ 相匹配的过程。为了解决归一化计算挑战，利用基于重要性采样的蒙特卡洛技术设计了一个无偏且解析上可处理的分区函数估计器。", "conclusion": "在各种out-of-distribution检测基准上进行的大量实验表明，\textsc{ConjNorm} 在许多OOD检测设置中建立了新的最先进水平，相对当前最佳方法在CIFAR-100和ImageNet-1K上的FPR95分别提高了13.25% 和 28.19%。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.20179", "html_url": "https://arxiv.org/abs/2405.20179", "title": "Robo-Instruct: 基于模拟器增强指令对齐的代码LLM微调", "title_en": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs", "authors": "Zichao Hu,Junyi Jessy Li,Arjun Guha,Joydeep Biswas", "background": "代码LLM已经在将自然语言任务转换为可以由服务机器人执行的程序方面显示出有希望的结果。但是，为每个机器人收集特定的任务-程序数据集既耗时又昂贵。虽然像SELF-INSTRUCT和EVOL-INSTRUCT这样的方法可以生成新任务，但它们无法提供遵守物理世界和机器人约束的相应程序。构建能够处理任意任务及其必要对象和位置的模拟环境是一项挑战。为了解决这些问题，本文介绍了ROBO-INSTRUCT，该方法在程序执行过程中即时合成特定任务的模拟环境，并根据实体在任务程序中的使用情况推断实体属性并强迫相应的约束。此外，ROBO-INSTRUCT 还集成了LLM辅助的后处理过程，以更好地对齐指令与机器人程序。实验结果表明，ROBO-INSTRUCT 能够提高所有基线方法的效果，并且在一些情况下甚至可以达到或超越更大、更专有的模型的效果。", "innovation": "ROBO-INSTRUCT通过即时合成特定任务的模拟环境，在程序执行过程中推断实体属性并强制相应的约束，解决了收集特定于每个机器人的任务-程序数据集的时间和成本问题。此外，该方法集成了LLM辅助的后处理过程来优化指令，更好的对齐与机器人的程序。", "conclusion": "ROBO-INSTRUCT在验证不同代码LLM的有效性时表现出色，微调后的模型不仅优于所有基线方法，甚至在某些情况下与一些更大的专有模型相匹配或超越，证明了该方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.08083", "html_url": "https://arxiv.org/abs/2408.08083", "title": "基于信心加权的人机判断整合以实现更优决策", "title_en": "Confidence-weighted integration of human and machine judgments for superior decision-making", "authors": "Felipe Yáñez,Xiaoliang Luo,Omar Valerio Minero,Bradley C. Love", "background": "大型语言模型（LLMs）在某些预测任务中可以超越人类。但人类在整体决策过程中还能发挥什么作用？一个可能的假设是，虽然人类在某些任务上的表现不如LLMs，但与机器团队合作时，人类仍能带来附加价值。当团队成员的自信程度校准得当且在困难任务上的分歧（即校准和多样性）时，人类和机器团队的表现可以超越各自的个体成员。", "innovation": "简化并扩展了贝叶斯综合判断方法，使用逻辑回归框架整合了任意数量团队成员的信心加权判断。研究使用了一个简便的方法来展示其在图像分类和神经科学预测任务中的有效性。结果显示，将人类判断与一个或多个机器的判断相结合，可以持续提升团队的整体表现。", "conclusion": "希望这种简单且有效的整合人类和机器判断策略能够促进人类与机器的协作，提高整体决策效果。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.11833", "html_url": "https://arxiv.org/abs/2410.11833", "title": "在复杂Q函数中缓解确定性策略梯度的次优性", "title_en": "Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions", "authors": "Ayush Jain,Norio Kosaka,Xinhu Li,Kyung-Min Kim,Erdem Bıyık,Joseph J. Lim", "background": "在强化学习中，离策演员-评论家方法如DDPG和TD3采用确定性策略梯度：Q函数从环境数据学习，而演员通过梯度上升最大化它。但是，在诸如灵巧操作和受限于移动约束的运动等复杂任务中，观察到Q函数存在许多局部最优，使得梯度上升容易陷入其中.", "innovation": "我们引入了SAVO演员结构，（i）生成多个动作提案并选择具有最高Q值的动作；（ii）通过截断差的局部最优来多次近似Q函数，以更有效地引导梯度上升。结果表明，我们的演员更频繁地找到最优动作并优于其他演员架构.", "conclusion": "我们在受限制的移动、灵巧操作和大型离散动作空间推荐系统等任务上进行了评估，并表明我们的演员更频繁地找到最佳动作，并优于其他演员架构."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "UltraSeP: 序列感知预训练在超声心动图探头运动指导中的应用", "title_en": "UltraSeP: Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "超声心动图作为诊断心血管疾病的关键医疗技术，但由于其操作复杂性高，导致专业人才短缺。心脏结构复杂且个体间存在显著差异，现有研究主要关注整体平均心脏结构而无法适应个性化需求，导致诊断准确性受限。临床实践中，超声技师会根据前序扫描动态调整对患者心脏解剖的理解，改进扫描策略。", "innovation": "本文提出了一种序列感知自监督预训练方法（UltraSeP），通过预测扫描序列中的掩码特征和探头运动动作，学习个性化的心脏三维结构特征。该方法假设如果模型能够预测缺失内容，则表明它对个性化心脏结构已有良好的理解。实验结果表明，与现有先进技术相比，UltraSeP 能有效减少探头指导误差。", "conclusion": "通过序列感知自监督预训练方法，能够实现更精准的探头运动指导，减少人为操作中的误差，有助于提升超声心动图诊断的准确性和效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.02642", "html_url": "https://arxiv.org/abs/2406.02642", "title": "E-ICL：基于原型理论增强细粒度情绪识别", "title_en": "E-ICL: Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory", "authors": "Zhaochun Ren,Zhou Yang,Chenglong Ye,Yufeng Wang,Haizhou Sun,Chao Chen,Xiaofei Zhu,Yunbing Wu,Xiangwen Liao", "background": "在上下文学习（ICL）在知识获取、常识推理和语义理解等多个领域表现出色的情况下，其在情绪检测任务中的性能显著下降，尤其是在细粒度情绪识别方面。尽管这一现象的原因尚未完全清楚，但研究表明ICL遵循了原型理论，并因此存在一些缺陷：依赖于语义相似但情绪不准确的原型，容易受到无关类别干扰的影响。因此，提出了一种细粒度情绪识别的上下文学习方法E-ICL，以提高预测的准确性和鲁棒性。", "innovation": "该研究基于原型理论分析了ICL在细粒度情绪识别中的缺陷，提出了一种新的方法E-ICL。E-ICL利用更多情绪准确的原型，并通过动态标签引用情绪相似的例子进行预测。同时，使用排除性情绪预测策略来避免来自无关类别的干扰。实验表明，E-ICL在细粒度情绪数据集EDOS、Empathetic-Dialogues、EmpatheticIntent和GoEmotions中的表现均优于ICL。即使辅助情绪模型的使用量不到LLMs的10%，E-ICL也能多提升多个数据集的执行性能超过4%。", "conclusion": "E-ICL通过排除性策略和增强的情绪原型提高了细粒度情绪识别的准确性和鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.01605", "html_url": "https://arxiv.org/abs/2412.01605", "title": "Medchain: 在互动顺序中弥合大语言模型代理与临床实践之间的差距", "title_en": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice with Interactive Sequence", "authors": "Jie Liu,Wenxuan Wang,Zizhan Ma,Guolin Huang,Yihang SU,Kao-Jung Chang,Wenting Chen,Haoliang Li,Linlin Shen,Michael Lyu", "background": "临床决策制定（CDM）是医疗保健交付中关键且复杂的过程，但对于人工智能系统来说仍然是一个重大挑战。现有的基于大语言模型（LLM）的代理在处理一般医学知识方面已有测试，但它们在实际临床情境中的表现受限于缺乏能够反映实际医疗实践的全面测试数据集。因此，研究者提出了MedChain数据集以及MedChain-Agent系统以填补这一空白，旨在增强在真实的临床决策制定过程中的LMM代理性能。", "innovation": "MedChain是一个包含12,163个临床案例的数据集，涵盖了五种关键的临床工作流程阶段，并集成了个人化、交互性、序列性等三个真实临床实践的关键特征。MedChain-Agent是一种整合了反馈机制和MCase-RAG模块的AI系统，可以学习和适应先前的临床案例以提高响应能力，并展现了出色的动态信息收集能力和应对序列临床任务的性能，显著优于现有方法。", "conclusion": "MedChain和MedChain-Agent的提出进一步推动了在临床决策制定过程中的LMM代理的实际应用，展示了其在获取信息和处理序列性临床任务方面的显著优势，可以促进未来更多的实际临床实践中的应用研究。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19528", "html_url": "https://arxiv.org/abs/2411.19528", "title": "RAGDiffusion：通过外部知识摄取进行精确服装生成", "title_en": "RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation", "authors": "Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni", "background": "标准的服装资产生成涉及从具有复杂背景的现实世界图像中提取服装信息，将其恢复为正面的平面图展示状态。这一过程因服装结构的高度标准性和复杂场景下的衣物语义缺失而面临重大挑战。现有模型在空间感知能力上有限，无法在高规格的生成任务中避免结构幻觉和纹理失真。因此，需要一种新的框架来提升结构确定性并减少幻觉，同时确保生成的服装在结构和纹理上与实际相符，以应对固有的幻觉问题并提高保真度。", "innovation": "提出了一种名为RAGDiffusion的检索增强生成(RAG)框架。该框架主要由两部分组成：(1) 基于检索的结构聚合，利用对比学习和结构局部线性嵌入(SLLE)来提取全局结构和空间地标，并提供软硬指导来对抗结构模糊性；(2) 从粗略到精细的整体水平忠实服装生成，引入了粗度细化的纹理对齐，确保生成的服装在图案和细节上更具保真性。", "conclusion": "在具有挑战性的现实世界数据集上的大量实验表明，RAGDiffusion能够生成结构和纹理都忠实的服装资产，相对于现有方法有显著的性能提升，代表了利用RAG进行高规格忠实生成的创新尝试，以克服固有的幻觉问题和提高保真度。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.08428", "html_url": "https://arxiv.org/abs/2412.08428", "title": "SwarmGPT: 结合大型语言模型与安全运动规划的无人机群编舞", "title_en": "SwarmGPT: Combining Large Language Models with Safe Motion Planning for Drone Swarm Choreography", "authors": "Martin Schuck,Dinushka Orrin Dahanaggamaarachchi,Ben Sprenger,Vedant Vyas,Siqi Zhou,Angela P. Schoellig", "background": "无人机群表演——同步、富有表现力的空中表演配以音乐——已成为现代机器人技术令人着迷的应用领域。然而，设计流畅且安全的编排仍是一项复杂任务，需要专家知识。设计这些编排不仅要考虑表演的艺术性，还要确保安全性及可行性。", "innovation": "该研究提出了SwarmGPT，一种基于语言的编舞系统。它利用大型语言模型（LLMs）的强大推理能力简化无人机表演的设计过程。SwarmGPT结合了一个安全过滤器，确保编排在满足安全和可行性约束的情况下进行微调。通过将高层次的编舞设计与低层次的运动规划解耦，系统使得非专家能够使用自然语言迭代地完善编排，无需担心碰撞或执行器限制。该研究通过多达200架无人机的模拟实验和多达20架无人机在真实世界中的表演，验证了这种方法在多样类型的音乐下的规模、同步和安全性。", "conclusion": "该研究展示了具有广泛适用性的无人机群编舞系统，并提出了一个蓝图，用于在安全关键的无人机群机器人应用中整合基础模型。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.02362", "html_url": "https://arxiv.org/abs/2410.02362", "title": "医疗图像分析中Mamba架构的综合研究：分类、分割、恢复及其他方面的应用", "title_en": "A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond", "authors": "Shubhi Bansal,Sreeharish A,Madhava Prasath J,Manikandan S,Sreekanth Madisetty,Mohammad Zia Ur Rehman,Chandravardhan Singh Raghaw,Gaurav Duggal,Nagendra Kumar", "background": "Mamba作为一种特殊的状态空间模型，在医疗图像分析领域逐渐成为模板基于的深度学习方法的替代选择。然而，现有的变压器架构虽然功能强大，但也存在二次计算复杂度和长距依赖性处理不当的问题，这不利于处理大规模和复杂的医疗成像数据集。因此，Mamba因其线性时间复杂度和无需注意机制即可处理较长序列的特点，提供了比变压器更高效的推理和需求更少的内存。此外，Mamba在合并多模态数据方面也表现出色，提高了诊断准确率和患者结果。", "innovation": "Mamba作为一种特殊的状态空间模型，其创新之处在于线性时间复杂度，这使其在处理长序列时显著优于变压器。Mamba能够进行更快的推理并且需要更少的内存。Mamba还展示了在合并多模态数据方面的强大能力，提高了诊断的准确性和患者的治疗效果。", "conclusion": "本文通过定义状态空间模型的核心概念，如S4、S5和S6，并探讨Mamba架构如纯Mamba、U-Net变体和结合卷积神经网络、变压器和图神经网络的混合模型，展示了Mamba在医疗成像领域的潜力。本文还涵盖了Mamba的优化技术、应用、实验结果及其挑战与未来发展方向，旨在展示Mamba在克服现有医疗成像障碍方面的潜力并推动该领域创新性进展。有关Mamba在医疗领域应用的全面架构列表可在Github上查阅。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.08221", "html_url": "https://arxiv.org/abs/2412.08221", "title": "Generate Any Scene: 由场景图驱动的数据合成用于视觉生成培训", "title_en": "Generate Any Scene: Scene Graph Driven Data Synthesis for Visual Generation Training", "authors": "Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna", "background": "当前的文本到视觉生成技术在视觉保真度方面表现出色，但在场景组成泛化和语义对齐方面存在不足。现有的数据集存在噪声和语义组合性较弱的问题，限制了模型对复杂场景的理解，而大规模高质量注解的解决方案仍处于挑战之中。", "innovation": "本文提出了一种名为Generate Any Scene的数据引擎，它可以系统地列出代表所有可能视觉场景组合的场景图。Generate Any Scene能够从有结构的对象、属性和关系分类学中动态构建不同复杂性的场景图。基于生成的场景图，可以生成文本到图像或文本到视频生成的标题；同时，生成的场景图也可用于生成视觉问题和答案，以便自动评估和奖励模型的语义对齐。此外，文章设计了一个自我提升框架，自行生成数据以提升模型性能，并设计了一个知识蒸馏算法，将专有模型的具体优势转移到开源模型中。最后，还创建了一种奖励模型来低成本地提升模型生成的语义准确性，并应用于内容审核任务，通过学习合成数据来识别复杂案例。", "conclusion": "通过Combine Any Scene，模型在文本到图像生成和内容审核任务中的性能得到了显著提升。自我提升框架使得远超基线性能，知识蒸馏算法实现了关键语义生成的改进，奖励模型进一步提升了模型的语义准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.08604", "html_url": "https://arxiv.org/abs/2412.08604", "title": "LLM增强生成检索中的偏好识别", "title_en": "Preference Discerning with LLM-Enhanced Generative Retrieval", "authors": "Fabian Paischer,Liu Yang,Linfeng Liu,Shuai Shao,Kaveh Hassani,Jiacheng Li,Ricky Chen,Zhang Gabriel Li,Xiaoli Gao,Wei Shao,Xue Feng,Nima Noorshams,Sem Park,Bo Long,Hamid Eghbalzadeh", "background": "在序列推荐中，模型根据用户的历史交互来推荐项目。现有模型通常会利用物品描述和用户意图或偏好信息。然而，开源数据集中用户偏好通常未明确给出，需要通过大语言模型（LLMs）进行近似计算。当前方法在训练时仅利用近似用户的偏好，并依赖过去的交互历史进行推荐，这限制了其对不断变化的偏好进行动态调整的能力，可能导致回声室效应。", "innovation": "本文提出了一种新的方法——偏好识别，使生成推荐模型在自然语言上下文中显式地基于用户偏好进行条件化。为了评估偏好识别的有效性，作者引入了一个新的基准测试，涵盖偏好指引和情感跟踪等多种情景。实验表明当前最先进的方法在应对不断变化的用户偏好时存在局限性，为此提出了一种名为Mender的新方法，该方法在基准测试中实现了最先进的性能。Mender能够根据人类偏好动态调整其推荐，即使这些偏好在训练阶段未被观察到，展示了更灵活推荐模型的可能性。", "conclusion": "Mender在基准测试中实现了最先进的性能，展示了根据人类偏好动态调整推荐的能力，为更加灵活的推荐模型开辟了途径。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.11142", "html_url": "https://arxiv.org/abs/2412.11142", "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "title_en": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "authors": "Tiankai Yang,Yi Nian,Shawn Li,Ruiyao Xu,Yuangang Li,Jiaqi Li,Zhuo Xiao,Xiyang Hu,Ryan Rossi,Kaize Ding,Xia Hu,Yue Zhao", "background": "异常检测(AD)是一种重要的机器学习任务，在实际应用中有着广泛使用，包括欺诈检测、医疗诊断和工业监控。在自然语言处理(NLP)领域，AD能够帮助检测类似于垃圾邮件、虚假信息和不寻常用户活动等问题。尽管大语言模型（LLMs）在文本生成和摘要等任务上取得了显著影响，但其在AD领域的潜力尚未得到充分研究。本研究旨在通过AD-LLM，首个评估LLMs如何协助NLP领域异常检测的基准测试，探索LLMs如何应用于AD任务，主要涉及零样本检测、数据增强和模型选择三个关键任务", "innovation": "首次提出了AD-LLM基准测试，用于评估大语言模型（LLMs）在自然语言处理（NLP）异常检测中的应用潜力。该研究关注零样本检测（利用预训练知识进行AD）、数据增强（生成合成数据和类别描述以提高AD模型）和模型选择（利用LLMs建议无监督AD模型等三个关键任务，并通过不同的数据集进行了实验，发现LLMs在零样本AD方面表现良好，精心设计的数据增强方法是有用的，但特定数据集的模型选择解释仍然是一个挑战", "conclusion": "研究表明LLMs可以在零样本AD中有效工作，精心设计的数据增强方法是有用的，但特定数据集的具体模型选择仍然具有挑战性。在此基础上，提出了关于LLMs用于AD的六个未来研究方向"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00350", "html_url": "https://arxiv.org/abs/2502.00350", "title": "OrcaLoca: 一种用于软件问题定位的LLM代理框架", "title_en": "OrcaLoca: An LLM Agent Framework for Software Issue Localization", "authors": "Zhongming Yu,Hejia Zhang,Yujie Zhao,Hanxian Huang,Matrix Yao,Ke Ding,Jishen Zhao", "background": "近期，大型语言模型（LLM）代理在自主软件工程（ASE）中取得了重大进展，能够实现自动编码、问题修复和功能改进。然而，定位软件问题——即准确识别软件问题并导航到相关代码部分——仍然是一个重大挑战。当前方法由于缺乏LLM代理与精确代码搜索机制的有效集成，常常导致结果不尽如人意。", "innovation": "本文提出了一种名为OrcaLoca的LLM代理框架，通过优先级调度机制指导LLM代理操作、分解操作并结合相关性评分以及距离感知上下文修剪，提高了软件问题定位的准确性。实验结果表明，OrcaLoca在SWE-bench Lite上的函数匹配率达到了65.33%，成为新的开源领域最先进的方法。此外，通过对开源框架的缺陷修复率提高了6.33个百分点，进一步验证了该框架的有效性。", "conclusion": "OrcaLoca框架通过集成优先级调度、操作分解、相关性评分明确定位和距离感知上下文修剪，有效提高了软件问题定位的精度。实验结果显示，OrcaLoca在开源领域功能匹配率方面达到了新高，并显著提高了缺陷修复率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06379", "html_url": "https://arxiv.org/abs/2502.06379", "title": "使用断开扩散顺序蒙特卡洛算法求解线性高斯贝叶斯逆问题", "title_en": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo", "authors": "Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten", "background": "近期的研究利用预训练的生成性扩散模型作为先验知识来解决贝叶斯逆问题。本文在此研究方向上做出了贡献，通过设计一种基于“断开扩散”的顺序蒙特卡洛方法，专门针对线性高斯逆问题。该方法能够允许样本有更大的更新，同时保持计算的精确性。", "innovation": "提出了一种名为Decoupled Diffusion Sequential Monte Carlo (DDSMC)的算法，这种方法能够通过断开扩散机制设计生成过程，使得样本能够进行更大的更新。此方法在理论上能够保持计算的精确性，并且已经被应用于合成数据、蛋白质数据和图像数据，展示了其有效性。此外，还证明了这种方法可以扩展到离散数据。", "conclusion": "DDSMC算法在解决线性高斯逆问题上表现优异，适用于合成数据、蛋白质数据和图像数据，还具有扩展到离散数据的能力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01857", "html_url": "https://arxiv.org/abs/2502.01857", "title": "IG-MCTS: 在不完整信息下的人机闭环协同导航", "title_en": "IG-MCTS: Human-in-the-Loop Cooperative Navigation under Incomplete Information", "authors": "Shenghui Chen,Ruihan Zhao,Sandeep Chinchali,Ufuk Topcu", "background": "在不完整信息情况下进行人机协作导航具有挑战性。本文介绍了CoNav-Maze，这是一个模拟环境，其中机器人依靠局部感知导航，同时人类操作员基于不准确的地图提供指导。机器人可以分享其车载摄像头视图以帮助操作员优化对环境的理解。为了实现高效的协作，本文提出了一种基于信息增益的蒙特卡洛树搜索（IG-MCTS）算法，该算法能够联合优化自主运动和信息性通信。", "innovation": "提出了基于信息增益的蒙特卡洛树搜索（IG-MCTS）算法，该算法能够联合优化自主运动和信息性通信。该算法利用训练有素的神经人类感知模型（NHPM）来预测人类内部地图如何随着新观察信息的共享而演变。用户研究显示，IG-MCTS显著减少了通信需求，并产生了表明较低认知负荷的眼动追踪指标，同时任务性能与遥操作和指令遵循基线相当。此外，通过一个连续空间水道导航设置，证明了IG-MCTS和NHPM的泛化能力，其中NHPM利用了更深的编码器-解码器架构，而IG-MCTS则利用动态构建的Voronoi分区通行图。", "conclusion": "IG-MCTS算法可以显著减少通信需求，降低认知负荷，同时保持与传统操作方式相似的任务性能，并且该方法能够适应连续空间的导航任务。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17168", "html_url": "https://arxiv.org/abs/2501.17168", "title": "在基于树的遗传编程中实现群体级并行性以加速GPU计算", "title_en": "Enabling Population-Level Parallelism in Tree-Based Genetic Programming for GPU Acceleration", "authors": "Zhihong Wu,Lishuang Wang,Kebin Sun,Zhuozhao Li,Ran Cheng", "background": "基于树的遗传编程（TGP）是一种广泛用于符号回归、分类和机器人控制等任务的演化算法。由于TGP运行的高计算需求，GPU加速对于实现可扩展性能至关重要，然而，基于GPU的有效执行TGP仍然具有挑战性，主要是由于三个方面的问题：即程序个体的结构异质性、多层并行性的复杂性整合以及高性能CUDA执行与灵活的Python环境之间的不兼容性。", "innovation": "为了应对这些挑战，该论文提出了EvoGP，这是一种高性能框架，用于通过群体级并行执行为TGP提供GPU加速。EvoGP的主要创新点包括：引入张量表示以编码可变大小的树为固定形状、对齐内存数组，启用多种个体的统一内存访问与并行计算；采用自适应并行策略，根据数据集大小动态结合个体间的并行和个体内的并行，以保证广泛任务中的高GPU利用率；将自定义CUDA内核嵌入PyTorch运行时，实现了与基于Python的环境如Gym、MuJoCo、Brax和Genesis的无缝集成。", "conclusion": "实验结果显示，EvoGP达到每秒超过$10^{11}$ GPops的峰值吞吐量，相对于基于GPU的TGP实现，速度提高至528倍，相较于最快的CPU基础库，则提高了18倍，同时保持了相似的准确性，并且在大种群规模下具有更好的可扩展性。EvoGP是开源的，并可通过以下链接获取：this https URL。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.03333", "html_url": "https://arxiv.org/abs/2502.03333", "title": "RadVLM: 一种用于放射学的多任务对话视觉语言模型", "title_en": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology", "authors": "Nicolas Deperrois,Hidetoshi Matsuo,Samuel Ruipérez-Campillo,Moritz Vandenhirtz,Sonia Laguna,Alain Ryser,Koji Fujimoto,Mizuho Nishio,Thomas M. Sutter,Julia E. Vogt,Jonas Kluckert,Thomas Frauenfelder,Christian Blüthgen,Farhad Nooralahzadeh,Michael Krauthammer", "background": "随着胸部X光片（CXR）的广泛应用和放射科医师短缺的问题日益突出，自动CXR分析和AI辅助报告引起了越来越多的关注。现有的视觉-语言模型（VLMs）在特定任务如报告生成或异常检测方面显示了潜力，但在提供交互性诊断功能方面却常常不足。", "innovation": "本文提出了RadVLM，这是一种专门用于CXR解释的紧凑型、多任务对话基础模型。RadVLM 通过构建一个包含超过一百万张图像指令对的大规模指令数据集，涵盖单轮任务（如报告生成、异常分类和视觉定位）和多轮、多任务对话交互。通过在该指令数据集上对RadVLM进行微调，评估了它在不同任务中的性能，并与重新实现的基线VLM进行了比较。研究表明，RadVLM 在对话能力和视觉定位方面达到了最先进的性能，同时在其他放射学任务中也保持了竞争力。研究表明，跨多个任务进行联合训练有助于提高模型在标注数据有限场景中的性能。", "conclusion": "研究表明，RadVLM 作为一种临床相关的AI助手，能够提供结构化的CXR解释和对话功能，从而支持更有效和可访问的诊断流程。进一步的消融研究还强调了在多种任务上联合训练的好处，尤其是在标注数据有限的情景中。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06485", "html_url": "https://arxiv.org/abs/2502.06485", "title": "WyckoffDiff ——一种用于晶体对称性的生成扩散模型", "title_en": "WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry", "authors": "Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten", "background": "结晶材料通常表现出高度对称性，但大多数生成模型并未考虑这种对称性，而是将每个原子视为独立，不受位置或元素约束。这导致生成的晶体结构可能缺乏实际对称性。该论文提出了一种新的生成模型，Wyckoff Diff（WyckoffDiff），它利用对称性生成描述晶体的方法。通过对结晶结构进行编码以包含所有对称性的表示，并设计了一种新型的神经网络架构，使对称性可以在离散生成模型框架内部应用。此外，还提出了一种新的度量标准，Fréchet Wrenformer Distance，用于捕捉生成材料的对称性特征。最后，将WyckoffDiff与最近提出的其他用于晶体生成的生成模型进行了基准测试作为概念验证研究，使用WyckoffDiff在热力学稳定性凸包之下找到了新的材料。", "innovation": "WyckoffDiff通过结合对称性和离散生成模型来生成具有对称性的晶体结构。引入了一种业界新的度量标准，Fréchet Wrenformer Distance，来度量对称性的方面，以及将WyckoffDiff与最新的生成模型进行了基准测试。该方法还提出了使用WyckoffDiff在热力学稳定性凸包下寻找新材料的概念证明。", "conclusion": "WyckoffDiff不仅能够从结构上遵守对称性，还能快速生成。引入的Fréchet Wrenformer Distance有助于捕捉和评估生成材料的对称性特征。WyckoffDiff成功地用于从理论上寻找新的材料。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15695", "html_url": "https://arxiv.org/abs/2502.15695", "title": "对比学习增强的社会推荐", "title_en": "Contrastive Learning Augmented Social Recommendations", "authors": "Lin Wang,Weisong Wang,Xuanji Xiao,Qing Li", "background": "推荐系统在现代内容平台上至关重要，但传统的基于行为的模型在处理具有有限互动数据的冷用户时常常面临挑战。吸引这些用户对平台的扩张至关重要。为了弥合这一差距，该研究提出利用社会关系图来丰富基于行为的模型的兴趣表示。然而，从社会图中提取价值具有挑战性，因为图中存在关系噪声和跨域不一致性。为了应对噪声传播并获得准确的社会兴趣，研究采用了一种双视角去噪策略，利用低秩SVD对用户-项目交互矩阵进行去噪，同时使用对比学习对齐原始和重建的社会图。针对社会兴趣和行为兴趣之间的一致性问题，研究采用了“互互相正则化”技术，将原始兴趣隔离成对齐的社会/行为兴趣和特定的社会/行为兴趣，从而最大化两者的好处。实验结果验证了此方法的有效性，特别是在处理冷用户方面，为未来的研究所提供了新的视角。这项实施可以在以下网址访问：this https URL", "innovation": "研究提出了一种创新的双视角去噪策略，结合低秩SVD和对比学习，以从用户社会图中提取准确的兴趣。为了解决社会兴趣和行为兴趣之间的一致性问题，采用了一种“互互相正则化”技术来分离原始兴趣，最大化了信息利用。这种方法特别适用于冷用户，验证了其在现实世界数据集上的有效性.", "conclusion": "研究结果表明，对比学习增强的社会推荐方法在处理冷用户方面表现优异，为未来研究提供了新的视角。该方法的应用前景广泛，特别是在提高用户参与度和平台扩张方面。研究已通过代码开放访问。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07878", "html_url": "https://arxiv.org/abs/2503.07878", "title": "使用可预测性衡量图像字幕中的方向性偏见放大", "title_en": "Measuring directional bias amplification in image captions using predictability", "authors": "Rahul Nair,Bhanu Tokas,Hannah Kerner", "background": "当我们在带有偏见的机器学习数据集上训练模型时，模型不仅会学习这些偏见，而且在测试时还可能放大它们——这一现象称为偏见放大。为了衡量ML数据集中的偏见放大，已经提出了许多基于共现的度量标准。这些基于共现的度量标准在简单的图像分类问题上是有效的，但对复杂的图像说明问题（captioning）不适用，因为它们难以捕捉字幕的语义。先前的工作通过引入基于可预测性的度量标准（Leakage in Captioning, LIC）来衡量偏见放大，尽管LIC能够捕捉字幕的语义和上下文，但仍然存在一些局限性，如无法确定偏见放大的方向、由于词汇替换策略较弱，对数据集偏见的估计不佳以及对攻击模型的敏感度高等问题。", "innovation": "提出了面向字幕的可预测性偏见放大（Directional Predictability Amplification in Captioning，DPAC）的方法。DPAC能够测量字幕中的方向性偏见放大，通过改进的替换策略提供了数据集偏见的更好估计，并且相较于攻击模型的敏感度更低。研究表明，DPAC是衡量字幕中偏见放大的最可靠的度量标准。", "conclusion": "实验结果表明，DPAC是衡量字幕中偏见放大的最可靠的度量标准，能够在更复杂的问题上提供准确的偏见放大度量，而传统的基于共现的度量标准在复杂问题上表现不佳。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15386", "html_url": "https://arxiv.org/abs/2503.15386", "title": "CCDP：条件扩散策略的组成与定向采样", "title_en": "CCDP: Composition of Conditional Diffusion Policies with Guided Sampling", "authors": "Amirreza Razmjoo,Sylvain Calinon,Michael Gienger,Fan Zhang", "background": "仿真学习提供了一种有潜力的方法，可以直接从数据中学习，而不需要显式的模型、模拟或详细的任务定义。在推理过程中，动作是从学习到的概率分布中采样并执行在机器人上。但是，采样的动作可能会由于各种原因失败，简单地重复采样步骤直到成功可用是低效的。这项研究提出了一种增强的采样策略，通过优化采样分布，避免之前失败的动作。", "innovation": "通过仅有使用成功演示数据，该方法可以推断出恢复动作，而不需要额外的探索性行为或高级控制器。此外，该方法利用扩散模型分解的概念，将主要问题分解为多个更小、更易管理的子问题，这些子问题可能需要管理失败的长期历史记录，在学习、数据收集和推理中，从而使得系统能够适应变量失败数量的变化。该方法提供了一个低级别控制器，能够动态调整其采样空间，以提高效率，当之前的样本不足时。", "conclusion": "该方法在门开闭、未知方向、物体操作和按钮搜索等多种任务上进行了验证，结果显示该方法优于传统的基线方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22697", "html_url": "https://arxiv.org/abs/2503.22697", "title": "脑成像到文本解码模型揭示视觉语义处理的神经机制", "title_en": "Brain2Text Decoding Model Reveals the Neural Mechanisms of Visual Semantic Processing", "authors": "Feihan Feng,Jingxin Nie", "background": "在神经科学和人工智能领域，从神经活动解码感官体验并重构人类感知的视觉刺激和语义内容仍然是一个挑战。虽然现有的脑解码模型已经取得了显著的进步，但在这些模型系统地整合现有的神经科学理论以及探索潜在的神经机制方面仍然存在关键差距。", "innovation": "本文提出了一种新的框架，可以直接将fMRI信号解码成所观察自然图像的文字描述。训练无需视觉信息的新颖深度学习模型实现了最先进的语义解码性能，生成了能捕捉复杂场景核心语义内容的有意义的描述。神经解剖学分析揭示了较高视觉皮层在视觉语义处理中的关键作用，包括MT+复合区域、腹侧视觉皮层和下顶叶皮层。此外，类别特定的分析还展示了对语义维度如有动力和运动的神经表征的微妙区别。", "conclusion": "这项工作提供了一种更直接和可解释的脑语义解码框架，为探索复杂语义处理的神经基础提供了强有力的新方法，深化了对分布式语义网络的理解，并有助于开发类脑语言模型。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22424", "html_url": "https://arxiv.org/abs/2503.22424", "title": "通过LLM驱动迭代代码图搜索实现问题定位", "title_en": "Issue Localization via LLM-Driven Iterative Code Graph Searching", "authors": "Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu", "background": "问题解决旨在根据问题描述在实际代码库中生成修复补丁。精确的问题定位是实现精确问题解决的基础。最近，基于大语言模型（LLM）的问题定位方法在性能上具有竞争力，但这些方法要么从问题描述中提到的文件开始，要么在整库范围内进行搜索，难以平衡搜索空间的广度和深度以高效地锁定目标；此外，它们允许大语言模型自由探索整个代码库，难以控制搜索方向以防止错误的目标。", "innovation": "提出了一种称为CoSIL的LLM驱动的功能级别问题定位方法，无需训练或索引。CoSIL采用两阶段代码图搜索策略，首先在文件水平上使用动态构建的模块调用图进行广泛探索，然后在函数水平上通过展开模块调用图生成函数调用图并执行迭代搜索。此外，CoSIL设计了一种修剪器来过滤无关方向和不相关的上下文，以精确控制搜索方向。为了增强大语言模型的格式化能力，提出了反向机制，通过在较短的上下文中引入额外的独立查询来避免长上下文中的不正确交互格式。实验结果表明，CoSIL在SWE-bench Lite和SWE-bench Verified上的Top-1定位准确性分别为43.3%和44.6%，平均优于现有最先进的方法96.04%。将CoSIL集成到问题解决方法Agentless中时，问题解决率提高了2.98%至30.5%。", "conclusion": "与现有的最先进的方法相比，CoSIL显著提高了问题定位的准确性，并在集成问题解决方法Agentless后进一步提升了问题解决效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16485", "html_url": "https://arxiv.org/abs/2504.16485", "title": "开发者声明AI生成代码的实践分析", "title_en": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices", "authors": "Syed Mohammad Kashif,Peng Liang,Amjed Tahir", "background": "AI代码生成工具近年来在开发者中变得非常受欢迎，它们可以帮助开发者进行软件开发。现有的研究主要关注AI生成代码的质量，如正确性和安全性。但在实际的软件开发中，区分AI生成的代码和人工编写的代码是首要任务，因此强调了开发者需要明确声明AI生成代码的必要性。", "innovation": "本研究采用混合方法，包括挖掘GitHub仓库收集到613个AI生成代码片段，并进行了一次后续的从业人员调查，共有111份有效回复。研究揭示了开发者声明AI生成代码的实践。大多数从业人员（76.6%）总是或有时声明AI生成代码，而其他从业人员（23.4%）则表示从来不声明。声明AI生成代码的原因包括跟踪和监控未来审查和调试代码的需求及道德考虑。不声明的原因包括对AI生成代码进行大量修改及认为声明是不必要的。", "conclusion": "最后，我们为从业者提供了声明AI生成代码的指南，以应对伦理和代码质量方面的问题。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03955", "html_url": "https://arxiv.org/abs/2504.03955", "title": "DeepOHeat-v1: 高效的操作学习以实现快速且可靠的3D-IC设计中的热仿真和优化", "title_en": "DeepOHeat-v1: Efficient Operator Learning for Fast and Trustworthy Thermal Simulation and Optimization in 3D-IC Design", "authors": "Xinling Yu,Ziyue Liu,Hai Li,Yixing Li,Xin Ai,Zhiyu Zeng,Ian Young,Zheng Zhang", "background": "在3D-IC设计中，由于散热密度的增加和复杂的散热路径，热分析变得至关重要。尽管像DeepOHeat~\\cite{liu2023deepoheat}这样的操作学习框架已经在加速热仿真方面展示了初步的成果，但它们在处理多尺度热模式预估能力、训练效率和结果可靠性方面仍存在局限性。", "innovation": "DeepOHeat-v1引入了三大创新。首先，集成Kolmogorov-Arnold网络和可学习激活函数作为主干网络，实现了对多尺度热模式的自适应表示，并在两个代表性测试案例中将误差减少了1.25倍和6.29倍。其次，提出了分离式训练方法，沿坐标轴分解基函数， baseline 情况下将训练速度加快了62倍，减少了31倍的GPU内存，并且能够在受限于GPU内存的情况下进行高分辨率的热分析。第三，提出了可信度评分来评估预测结果的可靠性，并开发了一种结合操作学习和有限差分法（FD）的方法，使用广义最小残差法（GMRES），以进行增量解算细化，从而增强温差优化的效率和可靠性。", "conclusion": "实验结果表明，DeepOHeat-v1在测试案例中实现了与高保真有限差分求解器优化相似的准确性，同时将整个优化过程加速了70.6倍，在优化过程中有效降低了峰值温度，通过合理布局热源部件实现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12007", "html_url": "https://arxiv.org/abs/2504.12007", "title": "连续令牌生成推荐", "title_en": "Diffusion Generative Recommendation with Continuous Tokens", "authors": "Haohao Qu,Shanru Lin,Yujuan Ding,Yiqi Wang,Wenqi Fan", "background": "近期，生成型人工智能尤其是大型语言模型（LLMs）为增强推荐系统（RecSys）开辟了新机会。现有的LLM驱动的RecSys方法大多在离散空间中操作，使用向量量化分词器来适应语言模型的固有离散性质。然而，这些量化方法通常会导致损失性分词并产生次优学习效果，尤其是在标准向量量化中的非可微argmin操作导致梯度传播不准确的情况下。受到连续令牌在语言模型中日益流行的趋势启发，本文提出了一种名为ContRec的新框架，它可以无缝地将连续令牌集成到LLM驱动的RecSys中。", "innovation": "ContRec框架包括两个关键模块：sigma-VAE分词器用于使用连续令牌对用户/物品进行编码；以及分散扩散模块，用于捕捉隐含用户偏好。分词器是通过连续变分自编码器（VAE）目标进行训练的，采用三种有效技术避免表示坍塌。通过在用户建模时基于LLM主干的先前生成令牌进行条件扩散过程，分散扩散模块使用新颖的分散损失执行生成性扩散，从而通过后续令牌进行高质量的用户偏好生成。ContRec利用LLM的文本推理输出和扩散模型产生的潜在表示进行Top-K项目检索，从而提供综合推荐结果。实验结果显示，ContRec在四个数据集上均优于传统和SOTA的LLM驱动推荐系统，突显了连续令牌化和生成建模在推荐系统演进中的潜力。", "conclusion": "通过结合LLM的文本推理输出和扩散模型的潜在表示，ContRec实现了高质量的Top-K项目检索，并通过广泛的实验验证了该方法的有效性，证明了连续令牌化和生成建模在下一代推荐系统中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05684", "html_url": "https://arxiv.org/abs/2504.05684", "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis", "title_en": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis", "authors": "Tri Ton,Ji Woo Hong,Chang D. Yoo", "background": "该论文提出了Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning (TARO)框架，这是一种用于高保真度和时间上一致的视频到音频合成的新颖框架。构建在基于流的变换器之上，TARO通过提供稳定训练和增强同步及音频质量的连续变换来增强了音视频同步。TARO的核心创新在于动态调整基于噪声时间步骤的对齐强度的时间步长自适应表示对齐(Timestep-Adaptive Representation Alignment, TRA)和基于突发的注意条件(Onset-Aware Conditioning, OAC)，以确保平滑变化并提高保真度。这些创新提高了音视频同步精度和音频质量，通过在VGGSound和Landscape数据集上的实验得到了验证，结果展示了相比于现有方法，TARO在弗雷彻距离(Frechet Distance)、弗雷彻音频距离(Frechet Audio Distance)和对齐准确率上均有显著提升。\n", "innovation": "TARO框架的创新包括：1. 时间步长自适应表示对齐(Timestep-Adaptive Representation Alignment, TRA)，这是一种动态对齐潜在表示的方法，通过根据噪声时间步骤调整对齐强度来促进平滑变化和提高保真度；2. 基于突发的注意条件(Onset-Aware Conditioning, OAC)，这是一种将突发线索融入音频相关视觉时刻，以提高同步精度的方法，这些突发线索作为精确的事件驱动标记。\n", "conclusion": "通过广泛实验验证，论文展示了TARO在VGGSound和Landscape数据集上的优越表现，相比于之前的模型，TARO在弗雷彻距离(Frechet Distance)、弗雷彻音频距离(Frechet Audio Distance)和对齐准确率上分别取得了显著降低，并且对齐精度达到了97.19%，突显了TARO在音频质量和同步精度方面的显著优势。\n"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21447", "html_url": "https://arxiv.org/abs/2504.21447", "title": "多模态语言模型在视觉任务中表现更好时可以看的更浅", "title_en": "Multimodal Language Models See Better When They Look Shallower", "authors": "Haoran Chen,Junyan Lin,Xinghao Chen,Yue Fan,Jianfeng Dong,Xin Jin,Hui Su,Jinlan Fu,Xiaoyu Shen", "background": "当前的多模态大型语言模型（MLLMs）通常从预训练视觉变压器（ViT）的最终层提取视觉特征。这种深层层偏向主要基于经验惯例而非实质分析。尽管先前的研究表明，不同的ViT层捕捉不同类型的信息，浅层聚焦于细腻的视觉细节，而深层则更接近文本语义，但这种变化对MLLM性能的影响仍缺乏深入探索。", "innovation": "本文首次系统研究了视觉层选择对于MLLMs的影响，并通过不同规模参数（1.4B-7B）的MLLMs在10个涵盖60多项任务的基准测试中的评估，发现浅层和中层在精细视觉任务（如计数、定位和物体定位）上明显优于深层。基于上述发现，提出了一种轻量级特征融合方法，能在单层和特定融合基线之上实现一致的改进。", "conclusion": "本研究提供了关于MLLMs视觉层选择的首个实质分析，证明了MLLMs在某些情况下通过观察更浅层能够更好地执行视觉任务。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16548", "html_url": "https://arxiv.org/abs/2504.16548", "title": "使用LLMs探索人类与SAV的互动：心理因素对用户体验的影响", "title_en": "Exploring human-SAV interaction using LLMs: The impact of psychological factors on user experience", "authors": "Lirui Guo,Michael G. Burke,Wynita M. Griggs", "background": "已有大量研究探讨了诸如拟人化等心理因素如何影响共享自主车辆（SAVs）的采用。然而，关于大型语言模型（LLM）驱动的对话SAV代理的提示策略如何影响用户对技术的认知、体验及其采用意图的研究却很少。本研究旨在探讨通过LLM驱动的对话SAV代理来影响这些心理因素，比如心理所有权，即用户对某个实体或对象可能会产生的实际所有权的感知。研究设计了四种具有不同拟人化特征和心理所有权触发条件的SAV代理，收集了参与者与每个SAV互动后的心理所有权、拟人化、服务质量、披露倾向、SAV回应情感以及整体接受度的定量指标，并收集了参与者在互动中的心理所有权体验的定性反馈。", "innovation": "本研究的一项创新在于通过设计具有不同拟人化特性的SAV代理来探索心理因素对用户体验的影响，特别是心理所有权在SAV上下文中的表现及其与代理性能感知的关系。研究表明，更拟人化的设计能够提高用户对SAV的类人特质的认知，并使机器人的回应显得更正面但也更具主观性。", "conclusion": "定量和定性结果均强调了个性化在设计有效的SAV交互中的重要性。本研究为设计增强用户体验和促进SAV采用的对话SAV代理提供了实用指导。这些发现揭示了心理所有权在SAV情景下的一些新的途径，并表明对话代理的性能感知也可能影响心理所有权。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03105", "html_url": "https://arxiv.org/abs/2505.03105", "title": "Cognitio Emergens：人类与人工智能知识共创造中的代理、维度与动力", "title_en": "Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI Knowledge Co-Creation", "authors": "Xule Lin", "background": "人类与人工智能在科学研究中的协作已经从工具-使用者关系转变为共生伙伴关系。AlphaFold在蛋白质结构预测上的进步展示了研究人员与智能伴侣合作的重要性，这种合作改变了结构-功能问题的解决方式。然而，现有的框架将人工智能视为高级工具或潜在风险，忽略了科学理解通过反复互动是如何形成的。这篇论文介绍了一种名为Cognitio Emergens (CE) 的框架，该框架能够捕获人类与人工智能认知合作伙伴的共生性。CE融合了自组织理论、社会系统理论和组织模块化，从代理配置、知识维度和伙伴关系动力三个方面入手，以指导战略发展。该框架使研究人员能够诊断维度不平衡，使机构领导者设计支持多种代理配置的治理结构，并使政策制定者能够超越简单的绩效指标进行评估。", "innovation": "CE框架提出了一种新的认知演进视角，将人类与人工智能的协作重新定义为根本上的共生关系。该框架通过代理配置、知识维度和伙伴关系动力三个方面，提供了解决策略发展、治理结构设计以及评估方法的工具。CE强调了人工智能在科学研究中的合作性角色，而非简单的工具或风险。", "conclusion": "CE框架为促进维护认知完整性同时实现人类和人工智能独立无法实现的变革性突破的知识伙伴关系提供了概念工具。该框架使研究人员、机构领导者和政策制定者能够更好地应对人类与人工智能协作中的挑战。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12151", "html_url": "https://arxiv.org/abs/2505.12151", "title": "推理大型语言模型错误来源于构建关键问题特征", "title_en": "Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features", "authors": "Alex Heyman,Joel Zylberberg", "background": "大型语言模型通过强化学习训练的链式思考策略，在推理任务上取得了显著进展；然而，这些‘推理大型语言模型’（RLLMs）仍存在未解决问题的方式。理解这些模型失败的原因对于使用者和开发者都非常重要。研究者通过图着色问题测试了多个RLLMs，并发现模型在不受提示限制的情况下虚构图边的现象普遍存在。", "innovation": "研究引入了图着色问题作为变量复杂度约束满意度逻辑问题，测试了多个RLLMs的性能，并通过错误率比较和解释文本分析，发现RLLMs容易虚构图边。这种现象在不同复杂性和语义框架中持续存在，并且解释了大部分模型错误答案的根本原因。", "conclusion": "RLLMs可能存在更广泛的将问题细节误代表现的问题，建议在设计时作出调整来减轻这个弱点，并通过较小规模实验验证了这种输入冲突的虚构现象的可推广性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14117", "html_url": "https://arxiv.org/abs/2505.14117", "title": "协作未标注数据优化", "title_en": "Collaborative Unlabeled Data Optimization", "authors": "Xinyi Shang,Peng Sun,Fengyuan Liu,Tao Lin", "background": "现有基于模型的方法存在三个关键限制，所有这些问题都根源于一个共同瓶颈：从数据中提取的知识被锁定在模型参数内，阻碍了其重用性和可扩展性。因此，需要一种新的方法来优化数据本身，以提高深度学习训练的效率和可持续性，最大化未标注数据的效用.", "innovation": "提出了CoOpt，一种高效并行的协作未标注数据优化框架，通过分散未标注数据并利用现成的与任务无关的模型，CoOpt实现了可扩展、可重用且可持续的训练管道。通过在多种数据集和架构上的广泛实验展示了其效果和效率，分别在Tiny-ImageNet和ImageNet-1K上取得了13.6%和6.8%的效果提升，训练速度分别提升了1.94倍和1.2倍.", "conclusion": "CoOpt框架有效地将知识编码到数据本身中，增强了未标注数据的利用效率，并通过分布式处理和利用现成模型，实现了深层学习训练的优化，提升了数据的效率与可持续性."}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14551", "html_url": "https://arxiv.org/abs/2505.14551", "title": "信任博弈：你的区块链有多值得信赖？", "title_en": "Game of Trust: How Trustworthy Does Your Blockchain Think You Are?", "authors": "Petros Drineas,Rohit Nema,Rafail Ostrovsky,Vassilis Zikas", "background": "本文探讨区块链如何将节点对于（部分）节点的信任度集体信念提炼成一个反映正确执行任务概率的信誉系统。为此，作者介绍了这一问题可以分解为两个子问题：1. 信息提取：如何从节点的真实信念函数中提炼信任信息？2. 激励设计：如何激励节点真实地报告此类信息？", "innovation": "为了应对第一个子问题，作者以非平凡的方式对经典的PageRank算法进行改造以适应该问题。对于第二个子问题，作者定义了一类新的博弈，称为信任信誉博弈(TRep)，并提出了一个具体的TRep博弈，其效用函数利用个性化PageRank，并通过简单的区块链奖励机制实施。这项工作展示了这种博弈如何帮助设计一个信誉体系，这些系统可以增强区块链和DeFi解决方案的稳健性、可扩展性和效率。", "conclusion": "通过信任信誉博弈的基础上，我们展示了这样的博弈如何能够设计出一个信誉系统，这种系统能够增强区块链和DeFi解决方案的稳健性、规模性和效率。例如，我们展示了如何在这种系统中利用声誉证明区块链。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09666", "html_url": "https://arxiv.org/abs/2505.09666", "title": "通过元学习进行系统提示优化", "title_en": "System Prompt Optimization with Meta-Learning", "authors": "Yumin Choi,Jinheon Baek,Sung Ju Hwang", "background": "大语言模型（LLMs）展现了显著的能力，优化输入提示在最大程度上提高其性能方面起到了关键作用。然而，现有的提示优化工作主要集中在针对特定查询或任务的用户提示上，而忽略了系统提示，这种提示经过优化后可以在不同任务和领域中应用。现有的研究主要关注特定任务的用户提示优化，而忽视了适用于多种任务和领域的系统提示的优化问题。这项工作旨在解决这个问题，提出了一个新的两阶段优化问题，通过元学习来设计既对多种用户提示具有鲁棒性又能跨领域迁移的系统提示。", "innovation": "提出了一个元学习框架，该框架通过元学习优化系统提示及其所对应的用户提示，使其能够处理多样化用户提示，并且能够适应未见过的任务。这种方法在14个涵盖不同领域的数据集上进行了实验证明，优化后的系统提示能够有效泛化到多种用户提示，并且在未见过的任务上的快速适应性更强，需要较少的优化步骤即可实现较好的性能。", "conclusion": "通过元学习框架优化系统提示，能够生成适用于多种用户提示的系统提示，同时在未见过的任务上实现更快的适应性并保持较好的性能。这解决了目前主要关注特定任务的用户提示优化而忽视系统提示优化的问题。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16732", "html_url": "https://arxiv.org/abs/2505.16732", "title": "连续部分可观测量决策过程中的顺序蒙特卡洛政策优化", "title_en": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "authors": "Hany Abdulsamad,Sahel Iqbal,Simo Särkkä", "background": "在部分可观测的环境下进行最优决策需要代理体在减少不确定性（探索）和追求即时目标（利用）之间取得平衡。然而，当前的方法在这个挑战面前遇到了困难，它们往往需要使用次优的近似或者手工构建的启发式策略，这限制了政策学习的效果和效率。", "innovation": "提出了一个全新的策略优化框架，用于连续部分可观测马尔可夫决策过程（POMDPs），明确规定了平衡探索和利用的挑战。该方法将策略学习当作非马尔可夫Feynman—Kac模型中的概率推理，能够内在地捕捉到信息收集的价值，而无需依赖次优近似或手工设计的启发式策略。开发了嵌套的顺序蒙特卡洛（SMC）算法来在由POMDP诱导的最优轨迹分布的样本中高效估计历史依赖策略梯度。", "conclusion": "在标准的连续POMDP基准测试中，展示了所提出的算法的有效性，而现有的方法在这种不确定性下难以采取行动。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18630", "html_url": "https://arxiv.org/abs/2505.18630", "title": "DDO: 双决策优化在多代理合作下的LLM医学咨询", "title_en": "DDO: Dual-Decision Optimization for LLM-Based Medical Consultation via Multi-Agent Collaboration", "authors": "Zhihao Jia,Mingyi Jia,Junwen Duan,Jianxin Wang", "background": "大型语言模型（LLMs）在泛化和推理方面表现出色，适合复杂的决策任务，例如医疗咨询（MC）。然而，现有的基于LLM的方法通常无法捕捉MC的双重性质，这包括两个独立的子任务：症状查询（一个序列决策过程）和疾病诊断（一个分类问题）。现有方法的这种不匹配导致了症状查询效率低和疾病诊断不可靠的问题。", "innovation": "DDO是一个新颖的LLM基线框架，它通过分离两个子任务并通过协作多代理工作流程中的独特目标进行优化，以实现双决策优化。实验证明DDO在三个真实世界的MC数据集上优于现有基于LLM的方法，并且在生成方法的最新水平上表现竞争。", "conclusion": "DDO在MC任务中的效果得到了验证，并通过多代理协作成功解决了现有的问题。该项目的代码可以在这个链接中找到。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20318", "html_url": "https://arxiv.org/abs/2505.20318", "title": "从潜在表示构建动态向量：超越演示", "title_en": "Beyond Demonstrations: Dynamic Vector Construction from Latent Representations", "authors": "Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu", "background": "现有的In-Context Vector (ICV)方法可以从大型语言模型（LLMs）中提取任务相关表示，并在推理时重新注入，以达到与少量示例外部上下文学习（ICL）相当的性能，而不需要重复的示例演示处理。然而，现有的ICV方法仍然对ICL特有的因素很敏感，通常使用粗略或语义碎片化的表示作为向量源，并依赖基于启发式的插入位置，这限制了它们的适用性。", "innovation": "本文提出了DyVec，通过引入详尽查询旋转（EQR）策略来减轻由示例上下文学习（ICL）引入的方差，从而提取稳健的语义聚合潜在表示。然后，它应用动态潜在分割和注入来根据任务复杂性自适应地分区表示，并利用基于REINFORCE的优化来学习每个片段的最佳插入位置。实验结果表明，DyVec在少图ICL、LoRA和先前的ICV基线方法中表现出更优的性能。进一步的分析强调了动态分割和注入语义聚合潜在表示的有效性。DyVec提供了一种轻量级和数据效率高的推理时任务适应解决方案。", "conclusion": "实验结果表明DyVec在少图ICL、LoRA和先前的ICV基线方法中表现出更好的性能。进一步的分析证实了动态分割和注入聚合的语义潜在表示的有效性。DyVec提供了一种轻量级的数据有效的推理时任务适应解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21593", "html_url": "https://arxiv.org/abs/2505.21593", "title": "任意对象视频聚焦：基于视频扩散模型的任意主体视频聚焦", "title_en": "Any-to-Bokeh: Arbitrary-Subject Video Refocusing with Video Diffusion Model", "authors": "Yang Yang,Siming Zheng,Qirui Yang,Jinwei Chen,Boxi Wu,Xiaofei He,Deng Cai,Bo Li,Peng-Tao Jiang", "background": "近年来，扩散模型已成为相机模拟的强大工具，能够实现几何变换和真实的光学效果。图像增强的焦外成像是其中的一个亮点，但视频焦外成像仍然未被探索。现有的基于图像的方法存在时间闪烁和不一致的模糊过渡问题，而目前的视频编辑方法则缺乏对焦点平面和焦外强度的显式控制。这些问题限制了它们在可控视频焦外成像的应用。", "innovation": "本文提出了一种一步扩散框架，用于生成时间连贯、深度感知的视频焦外渲染。该框架采用一种适合焦点平面的多平面图像（MPI）表示来调节视频扩散模型，从而使其能够利用预训练模型中的强大三维先验。此外，还引入了一种逐步训练策略以进一步增强时间稳定性、深度鲁棒性和细节保真度。实验结果表明，该方法在时间连贯性、空间准确性以及可控性等方面优于先前的基线方法。这是第一个专门用于视频焦外生成的扩散框架，为时间和可控性一致的景深效果设定了新的基准。", "conclusion": "该工作代表着视频焦外生成的首个专用扩散框架，建立了时间连贯且可控的景深效果的新基准。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20650", "html_url": "https://arxiv.org/abs/2505.20650", "title": "FinTagging：评估提取和结构化财务信息的LLMs基准", "title_en": "FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information", "authors": "Yan Wang,Yang Ren,Lingfei Qian,Xueqing Peng,Keyi Wang,Yi Han,Dongji Feng,Fengran Mo,Shengyuan Lin,Qinchuan Zhang,Kaiwen He,Chenri Luo,Jianxing Chen,Junwei Wu,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Qianqian Xie,Jian-Yun Nie", "background": "准确理解财务报告中的数字对于市场、监管机构、算法和普通人的经济和世界解读至关重要，尽管有XBRL（可扩展商业报告语言）设计用于用标准化的会计概念标注每一个数字，将数千个事实映射到超过10,000个美国公认会计原则（US-GAAP）概念仍然成本高昂、不一致且容易出错。现有的基准仅将标签化定义为扁平、单步骤、极端分类，涉及小部分US-GAAP概念，忽略了分类的结构化特征和实际标签化的层次语义。这些简化导致在现实的报告条件下对大型语言模型（LLM）进行公正的评估变得困难。", "innovation": "我们引入了FinTagging，这是一个全面的基准，专为结构感知和全面的XBRL标签化设计，旨在评估LLM在通过数字推理和税务结构对文本和表格进行分类对齐中的提取和对齐财务事实的能力。我们定义了两个子任务：FinNI用于数字识别，从XBRL报告中提取数字实体及其类型，以及FinCL用于概念链接，将每个提取的实体映射到完整US-GAAP分类标准中的相应概念。这两个子任务共同产生每个财务事实的结构化表示。在零样本设置下评估了多种LLM，并分析了它们在两个子任务和总体标签化准确性方面的表现。结果显示，LLM在数字识别中表现出很好的泛化能力，但在细粒度的概念链接中则遇到困难，揭示了目前结构感知推理在准确财务披露方面的局限性。", "conclusion": "所有代码和数据集可在GitHub和Hugging Face上获得，这表明我们需要一个更全面和结构化的基准来评估LLM在实际财务报告中的性能。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03355", "html_url": "https://arxiv.org/abs/2506.03355", "title": "在两个领域中提高鲁棒性：CLIP 需要一个鲁棒的文字编码器", "title_en": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "authors": "Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher", "background": "对抗性输入攻击会导致CLIP嵌入显著位移，从而影响使用CLIP的下游模型（如文本到图像生成模型或大型跨模态模型）的鲁棒性。虽然在改进CLIP图像编码器鲁棒性方面已经有所努力，但文字编码器的鲁棒性尚未得到研究。", "innovation": "提出了一种高效的对抗性微调方法LEAF，专门针对文本领域。该方法能够扩展到大规模CLIP模型，并在保持图像性能的同时显著提高了零样本对抗准确率，同时在对抗噪声下改善了生成质量，并在多模态检索任务中提高了召回率。", "conclusion": "鲁棒性的文字编码器能够通过直接优化更好地从嵌入重建输入文本。此外，已开源了代码和模型供进一步研究使用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23118", "html_url": "https://arxiv.org/abs/2505.23118", "title": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "title_en": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "authors": "Zhongzhen Huang,Linjie Mu,Yakun Zhu,Xiangyu Zhao,Shaoting Zhang,Xiaofan Zhang", "background": "临床决策的有效性依赖于多种证据的多次迭代分析。近年来，多模态推理模型显著改变了解决复杂任务的格局。尽管这些模型在数学和科学领域取得了显著成果，但在医疗领域的应用仍然未被充分探索。该研究提出了MedE²，一个两阶段后训练管道，旨在激发和提升多模态推理能力，特别是在医疗领域。", "innovation": "MedE²是一个两阶段后训练管道，首先通过2000个仅文本的数据样本来激发模型的多模态推理行为，然后使用1500个严格筛选的多模态医疗案例进一步增强模型的推理能力，使其与提出的多模态医疗推理偏好相匹配。该研究展示了MedE²在多个医疗多模态基准测试中的有效性和可靠性，训练使用MedE²的模型在多个医疗多模态基准中表现优于基线模型，并且在更大规模模型和推理时情况下的验证进一步证实了该方法的稳健性和实用性。", "conclusion": "MedE²在提升医疗多模态模型推理性能方面表现出显著效果，经过各种医疗多模态基准测试的支持，表明该方法具备坚实的科学依据和实际应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05404", "html_url": "https://arxiv.org/abs/2506.05404", "title": "AD-EE: 用于自主驾驶的快速且可靠的早期退出VLM框架", "title_en": "AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving", "authors": "Lianming Huang,Haibo Hu,Yufei Cui,Jiacheng Zuo,Shangyu Wu,Nan Guan,Chun Jason Xue", "background": "伴随自主驾驶技术的飞速发展，视觉-语言模型（VLMs）被广泛应用于提升感知能力和决策效率。然而，实时应用VLMs受到高延迟和计算开销的限制，尤其是在需要快速反应的驾驶场景中效果受限。当VLMs出现过度推理的现象，即使已经得到了足够可信的预测，仍然会继续处理不必要的层，进一步加剧了这一问题。", "innovation": "本文提出了一种名为AD-EE的早期退出框架，它结合了自主驾驶领域的特定特征，并利用因果推理确定最佳的退出层。该方法在大规模的真实世界自主驾驶数据集（包括Waymo和重点关注极端案例的CODA）以及运行于Autoware Universe平台的真实车辆上进行了评估。实验证明，该方法显著降低了延迟，最多可提高57.58%，同时提高了物体检测精度，最多可提升44%。", "conclusion": "研究结果表明，AD-EE框架在多个视觉-语言模型中都能显著降低延迟并提高物体检测精度，显示出在自主驾驶中使用早期退出策略的有效性和效率。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11034", "html_url": "https://arxiv.org/abs/2506.11034", "title": "CausalVLBench：评价大型视觉语言模型中的视觉因果推理", "title_en": "CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models", "authors": "Aneesh Komanduri,Karuna Bhaila,Xintao Wu", "background": "大型语言模型（LLMs）展示了在各种语言任务中令人瞩目的能力，尤其是在上下文学习方面。将视觉输入引入LLMs，形成了大型视觉语言模型（LVLMs），它们在识别和视觉问答（VQA）任务上表现出色。尽管在因果推理任务（如因果发现和反事实推理）上有越来越多的兴趣，但对LVLMs在视觉因果推理任务中的能力的研究相对较少。本文旨在引入一个全面的形式化因果推理基准，用于从LVLMs进行多模态上下文学习。", "innovation": "本文提出了一个名为CausalVLBench的基准测试，它包含三个代表性的任务：因果结构推理、干预目标预测和反事实预测。它评估了最先进的开源LVLMs在三个因果表示学习数据集上的因果推理能力，并揭示了现有视觉语言模型的缺陷，从而促进改进LVLMs在视觉因果推理中的能力的新方向。", "conclusion": "通过我们的基准测试，我们希望阐明现有视觉语言模型的缺陷，并为提升LVLMs在视觉因果推理能力方面的新方向和范式提供指导。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07180", "html_url": "https://arxiv.org/abs/2506.07180", "title": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "title_en": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "authors": "Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang", "background": "随着视频大规模语言模型（Video-LLMs）越来越多地被集成到需要基于视觉证据的多模态推理的实际应用中，确保这些模型的准确性和可靠性变得至关重要。然而，这些模型倾向于与用户输入一致，即使这种一致性与视觉证据相矛盾，这会损害它们在这些情境下的可信度。现有的研究主要忽略了视频-语言领域中奉承行为的具体表现形式，导致缺乏系统性基准和针对误导性用户输入情境下的评估来理解Video-LLMs的应对方式。", "innovation": "为填补这一空白，本研究提出了VISE（Video-LLM Sycophancy Benchmarking and Evaluation），这是首个用于评估最先进Video-LLMs在多种问题格式、提示偏差和视觉推理任务下的奉承行为的基准。VISE在视频领域引入了语言学视角上的奉承概念，使得对不同类型的奉承行为和互动模式进行细粒度分析成为可能。此外，研究还提出了两种潜在的无需训练的缓解策略，旨在减少奉承偏见：（i）通过可解释的关键帧选择增强视觉匹配；（ii）通过目标时间内的内部神经表征干预引导模型行为远离奉承。", "conclusion": "本文代码已发布，VISE基准和相应的缓解策略为改进Video-LLMs的可信度提供了重要的研究基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13018", "html_url": "https://arxiv.org/abs/2506.13018", "title": "神经网络参数空间中的对称性", "title_en": "Symmetry in Neural Network Parameter Spaces", "authors": "Bo Zhao,Robin Walters,Rose Yu", "background": "现代深度学习模型由于高度的参数过拟合，产生了大量能够输出相同结果的参数配置。这种冗余部分可以通过参数空间中的对称性来解释——使得网络功能保持不变的变换。参数空间中的这些对称性决定了损失景观，并约束着学习过程的动力学，从而为优化、泛化和模型复杂性提供新的视角，补充了现有的深度学习理论。", "innovation": "本文提供了参数空间对称性的综述，总结了现有文献，揭示了对称性与学习理论之间的联系，并在这一新兴领域中识别了现有研究的空白和机会。", "conclusion": "研究通过探讨参数空间中的对称性，为优化、泛化和模型复杂性提供了新的理解角度，补充了现有的深度学习理论，并指出了未来研究的方向。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越token层面的LLM公平性量化：基于语义与统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）生成的响应中往往存在固有的偏见，这影响了它们在现实生活中的可靠性。现有的评估方法往往忽视了长文本响应中的偏见以及LLM输出的内在变化性。", "innovation": "本文提出了FiSCo（细粒度语义比较），这是一种新颖的统计框架，通过在各人群响应之间检测语义差异来评估群体层面的公平性。FiSCo从主张层面进行分析，利用蕴含检验来评估响应间意义的一致性。这种方法分解了模型输出为语义上不同的主张，并使用统计假设检验来比较群体间的相似性，从而实现在检测微妙偏见方面更为稳健。", "conclusion": "实验表明，FiSCo能够更可靠地识别出细腻的偏见，同时减少了LLM输出中随机变量的影响，表现出优于其他评估指标的效果。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14020", "html_url": "https://arxiv.org/abs/2506.14020", "title": "Bures-Wasserstein Flow Matching for Graph Generation", "title_en": "Bures-Wasserstein Flow Matching for Graph Generation", "authors": "Keyue Jiang,Jiahao Cui,Xiaowen Dong,Laura Toni", "background": "在药物发现和电路设计等领域中，图生成已成为一个关键任务。现有的图生成方法，如扩散和流基模型，通过构建一个插值路径来连接参考分布和数据分布，已经取得了坚实的生成性能。然而，这些方法通常独立地建模节点和边的变化，并使用线性插值来构建路径，这种分离的插值方式破坏了图之间的相互关联模式，从而使得生成的概率路径不规则、不平滑，引起不佳的训练动力学和采样收敛问题。", "innovation": "本文提出了一种理论基础的图生成模型中的概率路径构建框架。作者通过将图表示为由马尔可夫随机场（MRF）参数化的相互连接系统，建模节点和边的联合演变。利用MRF对象之间的最优传输位移，设计了一条平滑的概率路径，以确保图组件的协同演变。基于此，引入了BWFlow框架，这是一种用于图生成的流匹配框架，利用上述推导出的最佳概率路径，有助于训练和采样算法的设计。实验结果显示，BWFlow在标准图生成和分子生成中具有竞争力的表现，更好的训练收敛性和高效的采样。", "conclusion": "实验评估证明了BWFlow的有效性，具备了竞争对手的性能，更好的训练收敛性以及高效的采样。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "基于视频的可解释和细粒度Finger Tapping测试中帕金森病运动特征的量化", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确量化帕金森病（PD）的运动特征对于监测疾病进展和优化治疗策略至关重要。笔触测试是一种标准的运动评估方法，临床医生通过观察患者的笔触表现，并基于笔触幅度、速度和不规则性来评定总体严重程度，但这种主观评估存在较强的跨勾稽者和同勾稽者间变化性，并不能揭示测试过程中捕捉到的个体运动特征。因此，本研究提出了一种基于计算机视觉的细粒度方法来量化来自录像的PD运动特征。", "innovation": "本研究提出了四种临床相关特征来表征运动减少、运动迟缓、序列效应及犹豫-中断，使用主成分分析结合方差旋转显示，基于视频的特征与这四种缺陷相对应。此外，通过基于视频的分析还能识别序列效应和犹豫-中断内的更细致区别。进一步利用这些特征训练机器学习分类器来估算运动障碍协会统一帕金森病评定量表（MDS-UPDRS）笔触测试评分，该方法在MDS-UPDRS评分预测上获得了更高的准确性，同时仍提供个体笔触运动特征的可解释量化。", "conclusion": "提出的框架提供了用于客观评估PD运动特征的实用解决方案，该方法可应用于临床和远程环境。未来的研究需要评估其对症状性治疗和疾病进展的敏感性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08885", "html_url": "https://arxiv.org/abs/2507.08885", "title": "AirScape: 一种具有运动可控性的三维生成世界模型", "title_en": "AirScape: An Aerial Generative World Model with Motion Controllability", "authors": "Baining Zhao,Rongze Tang,Mingyuan Jia,Ziyou Wang,Fanghang Man,Xin Zhang,Yu Shang,Weichen Zhang,Wei Wu,Chen Gao,Xinlei Chen,Yong Li", "background": "在实体智能领域，如何让智能体预测自身运动意图在三维空间中的结果是一个基本问题。为了探索通用的空间想象能力，本文介绍了AirScape，这是一种用于六自由度飞行智能体的世界模型。AirScape基于当前的视觉输入和运动意图预测未来观察序列。为此，构建了一个包含11,000个视频-意图配对的数据集，并且花费超过1,000小时注释对应的运动意图，涵盖了不同场景下的无人机动作。", "innovation": "本文提出了AirScape，第一个为六自由度飞行智能体设计的世界模型。AirScape的核心创新在于基于当前视觉输入和运动意图预测未来观察序列，并且通过一个两阶段训练方案，将原本不具备实体空间知识的基础模型训练成为一个由运动意图控制且符合物理时空约束的世界模型。实验结果表明，AirScape在三维空间想象能力上显著优于现有基础模型，特别是在运动对齐方面的指标上提高了超过50%。项目可以在指定网址下载。", "conclusion": "AirScape在三维空间想象能力上取得了显著的进步，特别在运动对齐方面的指标上有所突破。该项目为理解与训练智能体的实体空间感知提供了一个新的研究框架。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav: 在城市环境中通过分层空间认知长短期记忆系统提升视觉语言导航", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大规模城市环境中进行视觉语言导航（VLN）需要使智能体能够将语言指令与复杂场景结合，并在长时间周期内回忆相关的经历。现有的模块化管道在解释性方面表现良好，但缺乏统一的记忆系统；端到端的多模态语言模型（M）LLM在融合视觉和语言方面表现出色，但仍然受限于固定大小的上下文窗口和隐式的空间推理能力。作者提出了一种称为Mem4Nav的分层空间认知长短期记忆系统，该系统可以增强任何VLN骨干架构，通过将稀疏八叉树与语义拓扑图结合，并将信息嵌入可训练的变换器记忆标记中来实现多模态信息的融合存储。系统还包含长时记忆（LTM）和短时记忆（STM）模块，以分别处理历史观察和实时障碍物避免等需求。", "innovation": "Mem4Nav 提出了一种分层的空间认知长短期记忆系统，它结合了稀疏八叉树和语义拓扑图，存储在可训练的记忆标记中。LTM用于压缩和保留过往的观察记录，而STM用于实时障碍物规避和局部规划。STM能在每一步骤中检索动态上下文并进行精简，而LTM则在深度历史信息不充分时提供解码并重建之前的嵌入。该系统在多个基准测试上展示了显著的性能提升。", "conclusion": "评估结果表明，Mem4Nav 在任务完成、充足的空间路径减少以及非DTW改进方面分别获得了7-13个百分点的提升，确认了其在分层地图和双记忆模块上的不可或缺性。代码已经在该项目的GitHub页面上公开提供。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01752", "html_url": "https://arxiv.org/abs/2507.01752", "title": "无需窥探的调优：LLM后训练中的可证明隐私与泛化边界", "title_en": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "authors": "Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud", "background": "梯度优化是深度学习的核心，通过反向传播实现高效可扩展的训练。然而，在训练过程中暴露梯度可能会泄露敏感数据信息，导致隐私和安全问题，如数据投毒攻击。相比之下，黑盒优化方法通过仅依赖函数评估来优化，无需直接访问数据，适用于数据访问受限、对抗风险高或过拟合的场景。本文介绍了一种新的黑盒优化方法BBoxER，用于LLM的后训练，通过隐式的训练数据压缩诱导信息瓶颈。利用信息流的处理能力，本文提供了非空泛化的泛化界，并提供了差分隐私、数据投毒攻击和提取攻击的强理论保证。实验结果表明，尽管黑盒方法固有的可扩展性和计算挑战，BBoxER仍能学习，表现出性能提升、基准推理数据集上的良好泛化性能和对抗成员推理攻击的鲁棒性，为部署在受限或隐私敏感环境提供了吸引力的选择，同时也提供了非空泛化的泛化保证。", "innovation": "提出了一种新的黑盒优化方法BBoxER，用于LLM的后训练，通过隐式的训练数据压缩诱导信息瓶颈。提供了非空泛化的泛化界，并提供了差分隐私、数据投毒攻击和提取攻击的强理论保证。实验验证了黑盒方法在学习能力和灵活性方面的潜力，同时强调了在隐私和安全受限环境下的应用价值。", "conclusion": "BBoxER作为梯度优化方法的补充，适合部署在受限或隐私敏感环境，同时提供非空泛化的泛化保证，为优化LLM提供了一种新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17131", "html_url": "https://arxiv.org/abs/2507.17131", "title": "通过以人为本的循环指导在测试时学习以实现自我改进的代理", "title_en": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "authors": "Yufei He,Ruoyu Li,Alex Chen,Yue Liu,Yulin Chen,Yuan Sui,Cheng Chen,Yi Zhu,Luca Luo,Frank Yang,Bryan Hooi", "background": "大型语言模型（LLM）代理在规则和所需领域知识经常发生变化的环境中（如法规遵从性和用户风险筛查）表现不佳。当前方法，如离线微调和标准提示，不足以在实际操作中有效适应新知识。", "innovation": "提出了一种名为ARIA（Adaptive Reflective Interactive Agent）的LLM代理框架，专门设计用于在测试时连续学习更新的领域知识。ARIA通过结构化自我对话评估其不确定性，主动识别知识空白，并从人类专家处请求针对性的解释或更正。通过比较和澄清查询，系统地更新内部带有时间戳的知识库，解决冲突或过时的知识。", "conclusion": "ARIA 在TikTok Pay的现实客户尽职调查姓名筛查任务上进行了评估，并与标准离线微调和现有自我改进代理的基线进行了对比，结果显示在适应性和准确性方面取得了显著改进。ARIA 在超过1.5亿月活跃用户的服务中部署，验证了其在快速变化环境中的实用性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22200", "html_url": "https://arxiv.org/abs/2506.22200", "title": "EFRame：通过探索-筛选-重放强化学习框架实现更深入的推理", "title_en": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework", "authors": "Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yuzhi Zhang,Yue Wang", "background": "近年来，强化学习（RL）的进步显著提高了大型语言模型（LLM）的推理能力。Group Relative Policy Optimization（GRPO），一种Proximal Policy Optimization（PPO）的轻量级变体，在提高效率的同时，面临着探索有限和训练不稳定的问题，这限制了其在复杂推理任务中的有效性。为了解决这些挑战，我们提出了一种称之为EFrame的探索-筛选-重放框架，该框架从三个维度增强GRPO：增加额外的卷积以进行更深入和针对性的探索，实时过滤低质量样本以稳定梯度并加速训练，以及经验重放以放大稀有但富有信息性的轨迹，实现稳定的收敛。这种统一的框架建立了一个平衡探索、效率和稳定性的培训周期。实验结果表明，EFrame在多项推理基准测试中表现出一致的提升，相对GRPO在Geometry3K上实现了37.9%的改进。EFrame还支持细粒度样本分类和精确熵控制，突显了其作为LLMs更深入推理的稳健解决方案的地位。我们的代码可在此获取：this https URL", "innovation": "探索-筛选-重放框架EFrame从三个维度增强GRPO：增加额外的卷积以进行更深入和针对性的探索，实时过滤低质量样本以稳定梯度并加速训练，以及经验重放以放大稀有但富有信息性的轨迹，实现稳定的收敛。这种方法建立了一个平衡探索、效率和稳定性的培训周期。EFrame提供了细粒度样本分类和精确熵控制，展示了其作为LLMs更深入推理的稳健解决方案的能力。", "conclusion": "实验结果表明，EFrame在多项推理基准测试中表现出一致的提升，相对GRPO在Geometry3K上实现了37.9%的改进。EFrame还支持细粒度样本分类和精确熵控制，突显了其作为LLMs更深入推理的稳健解决方案的地位。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13933", "html_url": "https://arxiv.org/abs/2507.13933", "title": "预印本: 海报: 我刚才浏览的网站是不是由LLM撰写的？", "title_en": "Preprint: Poster: Did I Just Browse A Website Written by LLMs?", "authors": "Sichang Steven He,Ramesh Govindan,Harsha V. Madhyastha", "background": "近年来，网页内容越来越多地由大型语言模型（LLMs）自动生成，而极少有人类干预。我们称之为“LLM主导”的内容。由于LLMs存在抄袭和胡言乱语的问题，这种内容可能不可靠且不道德。然而，很少有网站会披露此类信息，这使得普通读者很难区分这些内容。因此，我们需要开发可靠的检测LGM主导内容的方法。然而，现有的最先进LLM检测器在网页内容上表现不准确，因为网页内容的阳性率较低，且标记复杂，体裁多样，与基准数据集中的清洁、散文型数据不同。现有的检测器是为此类数据优化的。", "innovation": "我们提出了一种可靠且可扩展的管道，可以对整个网站进行分类。与直接对每个页面提取的文本进行分类不同，我们根据一个LLM文本检测器对多个类似散文页面的输出结果，对每个站点进行分类，以提高准确性。我们通过收集两个独立的黄金标准数据集来训练和评估我们的检测器，共包括120个网站，检测结果显示准确性达到100%。在实际应用中，我们在搜索引擎中搜索的10,000个网站和共Crawl存档中的多个网站中发现了一定比例的网站是LLM主导的。我们发现LLM主导的网站在搜索引擎结果中的排名很高，这引起了关于它们对最终用户和整个网络生态系统影响的问题。", "conclusion": "我们开发了一种可靠且可扩展的方法来检测网站内容是否由大型语言模型自动生成，并在实际应用中验证了其有效性。这些识别此类网站的方法有助于确保用户在浏览网站时获得可信的信息。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01774", "html_url": "https://arxiv.org/abs/2508.01774", "title": "VAGPO: Vision-augmented Asymmetric Group Preference Optimization for Graph Routing Problems", "title_en": "VAGPO: Vision-augmented Asymmetric Group Preference Optimization for Graph Routing Problems", "authors": "Shiyan Liu,Bohan Tan,Zhiguang Cao,Yan Jin", "background": "图路由问题在与网页相关的网络中起着至关重要的作用，找到图上的最优路径对于高效的数据传输和内容分发至关重要。经典的路由建模方法，如旅行商问题（TSP）和带容量的车辆路径问题（CVRP），是图优化的基本挑战。虽然近期的数据驱动的优化方法已经取得了显著的进展，但在训练效率和对大规模实例的泛化能力方面仍然存在局限。", "innovation": "本文提出了一种新的Vision-augmented Asymmetric Group Preference Optimization（VAGPO）方法。通过利用基于ResNet的视觉编码和基于Transformer的序列建模，VAGPO可以捕捉空间结构和时间依赖性。此外，引入了一种不对称的组偏好优化策略，该策略显著加快了收敛速度，与常用的策略梯度方法相比。实验结果表明，提出的VAGPO方法在生成的TSP和CVRP实例以及真实世界数据集上取得了极具竞争力的解质量，同时在大规模实例（多达1000个节点）上的泛化能力很强，无需重新训练，突出了其在学习效率和可扩展性方面的有效性。", "conclusion": "提出的方法在生成的TSP和CVRP实例以及真实世界数据集上实现了极好的解质量，并且在大实例上的泛化能力很强，无需重新训练，强调了其在学习效率和可扩展性方面的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00047", "html_url": "https://arxiv.org/abs/2508.00047", "title": "TriP-LLM：一种三分支块级大型语言模型时间序列异常检测框架", "title_en": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection", "authors": "Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin", "background": "时间序列异常检测在众多应用领域发挥着核心作用。随着物联网（IoT）和智能制造的普及，时间序列数据的数量和维度显著增加，这使得传统统计方法难以处理这些数据的高异质性和复杂性。受到大规模语言模型（LLMs）在语言和视觉多模态任务中取得成功的影响，本文提出了一种新的无监督异常检测框架：三分支块级大型语言模型时间序列异常检测框架（TriP-LLM）。", "innovation": "该框架通过三分支设计（Patching、Selecting 和 Global 模块）整合局部和全局时间特征，将输入时间序列编码为块级表示，然后通过冻结的预训练 LLM 处理。轻量级的块级解码器重建输入，从中提取异常得分。TriP-LLM 相比于其他方法在所有数据集上都表现出了更强的检测能力，并且通过广泛的消融研究验证了 LLM 对整体架构的重要贡献。此外，与使用通道独立性 (CI) 块处理的方法相比，TriP-LLM 的内存消耗显著降低，使其更适合 GPU 内存受限的环境。", "conclusion": "实验结果表明，TriP-LLM 一致地在所有数据集上优于近期的先进方法，显示出强大的检测能力。所有代码和模型检查点均在公开发布，并可在此网址找到：this https URL"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05118", "html_url": "https://arxiv.org/abs/2508.05118", "title": "通过探索进行推理：一种强化学习框架以实现稳健的功能调用", "title_en": "Reasoning through Exploration: A Reinforcement Learning Framework for Robust Function Calling", "authors": "Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang", "background": "大规模语言模型（LLMs）的有效训练，特别是在函数调用方面的训练，面临一个关键挑战：如何平衡复杂的推理路径探索与稳定的策略优化。传统的监督微调（SFT）方法无法培养出稳健的推理能力，而传统的强化学习（RL）方法则在探索方面效率低下。", "innovation": "提出了一种新的增强学习框架EGPO（Entropy-enhanced Group Relative Policy Optimization），该框架基于具有组相对策略优化（GRPO）的新颖方法。EGPO的核心是一个增加熵的效能函数，将模型的思路链（CoT）的熵整合到策略梯度计算中，以鼓励生成多种多样化的推理策略。熵奖励被谨慎地通过一个限制剪切机制进行控制，以保持优化方向。此外，EGPO还配备了严格且二元化的奖励信号，有效地指导模型发现有结构且准确的功能调用模式。", "conclusion": "EGPO在 Berkeley Function Calling Leaderboard （BFCL）上取得了卓越的性能，使用一个4B参数模型训练的EGPO在同类模型中达到了新的最先进水平，超越了包括GPT-4o和Gemini-2.5在内的多种强劲竞争对手。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07819", "html_url": "https://arxiv.org/abs/2508.07819", "title": "ACD-CLIP: 分解表示和动态融合以实现零样本异常检测", "title_en": "ACD-CLIP: Decoupling Representation and Dynamic Fusion for Zero-Shot Anomaly Detection", "authors": "Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo", "background": "预训练的视觉-语言模型（VLMs）在零样本异常检测（ZSAD）任务中表现不佳，因为它们存在一个关键的适应性差距：缺乏用于密集预测所需的局部归纳偏置，并采用不灵活的跨模态融合方法。", "innovation": "该论文提出了一个架构协同设计（ACD）框架，联合细化特征表示和跨模态融合。方法提出了参数高效的卷积低秩适应（Conv-LoRA）适配器，以注入局部归纳偏置以完成精细的表示，并引入动态融合闸门（DFG），利用视觉上下文自适应地调节文本提示，实现强大的双向融合。", "conclusion": "在多种工业和医学基准上的广泛实验表明，协同设计的优越准确性和鲁棒性验证了这种协同设计对于灵活适应基础模型到密集感知任务的重要性。源代码可以在该网址获取。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "基于渐进层冻结的站点级微调：从极早期婴儿第一天胸部X光片向稳健的支气管肺发育不良预测方向发展", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "极低出生体重的婴儿中，新生儿呼吸窘迫综合征（IRDS）引起的慢性肺病-支气管肺发育不良（BPD）患病率高达35%。BPD由在妊娠后36周龄时仍需依赖氧气呼吸引起，导致终身呼吸并发症。然而，预防措施可能带来神经发育障碍、机械通气诱导的肺损伤和全身并发症等严重风险。因此，对于极低出生体重的婴儿，及时对BPD的预后判断和预测BPD结局至关重要，以避免在低风险婴儿中不必要的毒性反应。入院X光片是极低出生体重的婴儿在出生后24小时内常规获取的，有可能成为一种非侵入性的预估工具。在这项研究中，研究者开发并测试了一种深度学习方法，使用163名小于32周胎龄（<32周胎龄，出生体重401-999g）的婴儿的胸部X光片。研究者对一个预训练在成人胸部X光片上的ResNet-50模型进行了微调，通过渐进层冻结和区别学习率防止过拟合，并评估了CutMix增强和线性探针。对于中度/重度BPD结局预测，最佳性能模型在渐进冻结、线性探针和CutMix的基础上，实现了0.78±0.10的AUROC、0.69±0.10的平衡准确性以及0.67±0.11的F1得分。专职领域预训练显著优于ImageNet初始化（p = 0.031），证明了为了BPD结局预测，进行领域特异性预训练的重要性。常规IRDS评分在预测中的价值有限（AUROC 0.57±0.11），证实了学习性标志的需求。该方法展示了领域特异性预训练可以用于从常规的第一天X光片中准确预测BPD，并通过渐进冻结和线性探针，使得方法能够为站点级实施和未来联邦学习部署保持计算上的可行性。\n", "innovation": "该研究开发了一个基于渐进层冻结的深度学习模型，该模型通过预训练在成人胸部X光片上的ResNet-50模型进行微调，使用CutMix增强和线性探针方法提高了对BPD预测的准确性。该研究强调了领域特异性预训练对于BPD预测的重要性，并且通过一种可计算且站点级实施的方法来提高预测的准确性。\n", "conclusion": "研究结果表明，领域特定预训练能够使从极早期婴儿第一天胸部X光片准确预测BPD成为可能。通过渐进层冻结和线性探针，该方法在计算上可行，并且适用于站点级实施和未来的联邦学习部署。\n"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE：银行客户交易和文本嵌入的学习对齐", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Omar Zoloev,Artem Sakhno,Dmitry Korolev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户的历史通信序列中学习客户的嵌入对于金融应用来说是核心。虽然大型语言模型（LLMs）提供了广泛的世界知识，但它们直接应用于长时间序列事件是计算上昂贵且在实际管道中不切实际的。因此，提出了LATTE（Learning Aligned Transactions and Textual Embeddings for Bank Clients），这是一种对比学习框架，用于将原始事件嵌入与冻结LLM的语义嵌入进行对齐。", "innovation": "提出的方法通过将行为特征总结为短提示，由LLM嵌入并作为对比损失的监督来显著降低推理成本和输入大小，与通常由LLM处理完整序列相比更为有效。实验表明，该方法在金融数据集上的事件序列表示学习上优于现有的先进技术，同时适合在对延迟敏感的环境中部署。", "conclusion": "该方法在保持部署灵活性的同时，大大降低了计算成本和输入大小，能够有效地从客户的历史通信序列中学习嵌入，适用于实际应用场景。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11408", "html_url": "https://arxiv.org/abs/2508.11408", "title": "在策略性强化学习遇见离策略专家：通过动态加权统一监督微调和强化学习", "title_en": "On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting", "authors": "Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "大型语言模型（LLMs）的后训练精细化有两种主要方法，即监督微调（SFT）和强化学习（RL）。然而，现有将SFT与RL结合的方法存在破坏既定响应模式和过度拟合专家数据的风险。本文针对这一问题，提出了一个新的观点——通过离策略与在策略的视角审视SFT和RL的统一方法。", "innovation": "本文提出了一个框架，称为CHORD（控制化的离策略和在策略强化学习的动态加权协调），通过动态加权将SFT重新定义为在策略RL过程中的一个辅助目标。CHORD引入了一个双重控制机制：首先使用全局系数在宏观层面上引导从离策略模仿转向在策略探索的过渡，然后使用逐个令牌的加权函数在微观层面上促进经验学习，以增强在策略探索，减少离策略数据的干扰。", "conclusion": "通过广泛的实验证明，CHORD能够在数学推理问题和实用工具使用任务中实现稳定而高效的训练过程，较基线方法显示出显著改进。CHORD通过有效协调离策略专家数据与在策略探索证明了其优势，其实现可在这个链接：this https URL 获取，以期进一步研究。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06956", "html_url": "https://arxiv.org/abs/2508.06956", "title": "基于神经网络的波束空间RSRP预测", "title_en": "Neural Beam Field for Spatial Beam RSRP Prediction", "authors": "Keqiang Guo,Yuheng Zhong,Xin Tong,Jiangbin Lyu,Rui Zhang", "background": "在密集多用户的无线网络中，准确预测波束级参考信号接收功率（RSRP）对波束管理至关重要，但由于高测量开销和快速信道变化，这项任务极具挑战性。这项工作的背景是介绍一种用于提高波束级RSRP预测精度和效率的新方法。", "innovation": "这一创新在于提出了一种称为Neural Beam Field (NBF)的混合神经-物理框架，采用多路径条件功率配置文件（MCPP），这是一种可学习的物理中间体，代表特定站点的传播环境。NBF采用解耦的“黑盒-白盒”设计，通过变压器等深神经网络学习MCPP，同时通过物理启发的模块分析性地推导出波束RSRP统计。此外，引入了一种先训练后校准（PaC）策略，利用射线追踪先验进行基于物理的预训练，然后通过现场数据进行校准，以提高收敛性和适应性。由此建立了更精确、高效且鲁棒的波束级RSRP预测框架。", "conclusion": "NBF框架在预测准确性、训练效率和泛化能力方面显著优于传统基于表的信道知识图（CKMs）和纯粹的黑盒深度神经网络。同时，保持了紧凑的模型大小。这项工作提出了一种适用于未来密集无线网络智能波束管理的可扩展且基于物理的方法。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06944", "html_url": "https://arxiv.org/abs/2508.06944", "title": "AMFT：通过元学习最优模仿-探索平衡来对齐语言模型推理器", "title_en": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance", "authors": "Lixuan He,Jie Feng,Yong Li", "background": "大型语言模型（LLMs）通常通过监督微调（Supervised Fine-Tuning, SFT）和强化学习（Reinforcement Learning, RL）的两阶段流程进行定制，但这一过程容易导致灾难性遗忘和模仿与探索之间的次优平衡。最近的单阶段方法尝试通过启发式方法来统合SFT和RL，但缺乏一种对于这两种范式进行动态权衡的机制。因此，本文重新通过隐式奖励的理论视角来界定这一挑战，将SFT和RL视为互补的奖励信号，提出了一种新的单阶段算法Adaptive Meta Fine-Tuning (AMFT)，其核心是一个元梯度自适应权重控制器，能够动态调整SFT和RL之间的平衡，以最大化长期任务性能。", "innovation": "提出了AMFT算法，通过元学习来学习SFT的路径级隐式奖励和RL的结果级显式奖励之间的最优平衡。核心是一个元梯度自适应权重控制器，能够动态调整SFT和RL之间的平衡。引入了隐式奖励的视角，将SFT和RL视为互补的奖励信号，并提出了一个元学习控制器来优化这种平衡。该方法通过借鉴策略熵来确保训练的稳定性，从而创建一个自适应的训练课程，自动发现有效的训练计划。AMFT在数学推理、抽象视觉推理和视觉语言导航等挑战性基准测试中表现突出，特别是在离分布任务上的泛化能力上。", "conclusion": "AMFT在多种挑战性任务中取得了新的最佳表现，并展示了在离分布任务上的优越泛化能力。通过消融研究和训练动态分析证明，元学习控制器对于AMFT的稳定、样本效率和性能至关重要，为LLM对齐提供了一种更原则性的有效范式。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19078", "html_url": "https://arxiv.org/abs/2508.19078", "title": "在资源受限设备上进行稀疏激活大型语言模型的联邦微调", "title_en": "Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices", "authors": "Fahao Chen,Jie Wan,Peng Li,Zhou Su,Dongxiao Yu", "background": "由于大型语言模型（LLMs）的混合专家（Mixture-of-Experts, MoE）架构导致的庞大计算需求，加上参与者的资源限制，联邦微调MoE-基于的LLMs具有挑战性。现有的工作尝试通过模型量化、计算卸载或专家剪枝来填补这一空白，但由于不切实际的系统假设和对MoE特性的忽视，它们难以达到预期的性能。", "innovation": "FLUX系统通过对MoE-基于的LLMs进行联邦微调，针对受限计算资源（如消费级GPU）的参与者，提出了三项关键创新：1）基于量化的地方特性分析以最小化开销估计专家激活；2）自适应逐层感知专家合并以减少资源消耗并维持准确性；3）利用探索-利用策略动态分配专家角色以平衡调优与非调优专家的性能。", "conclusion": "通过在LLaMA-MoE和DeepSeek-MoE上进行的大量基准实验，FLUX显著优于现有方法，在时间到准确性方面实现了最多4.75倍的加速。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02579", "html_url": "https://arxiv.org/abs/2509.02579", "title": "基于期望-最大化算法的多智能体强化学习的潜在变量建模及其在无人机野生动物保护中的应用", "title_en": "Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection", "authors": "Mazyar Taghavi,Rahman Farnoosh", "background": "保护濒危野生动物不受非法捕猎的挑战在广大且部分不透明的环境中尤为严峻，需要实时响应。文章探讨了在无人机协调野生动物保护任务中，通过引入期望-最大化(EM)为基础的潜在变量建模方法来结合多智能体强化学习(MARL)来应对这一挑战。", "innovation": "提出了结合EM算法的潜在变量模型在MARL中的新方法，用于无人机在野生动物保护中的协调任务。该方法通过潜在变量模型环境中的隐藏因素和智能体间的动态关系，提高了探索和协调能力；通过自定义包含10架无人机巡逻伊朗豹受保护栖息地的模拟环境，证明了在检测准确性、适应性和策略收敛性上优于标准算法PPO和DDPG。", "conclusion": "研究发现，将EM推断与MARL相结合，可以改善复杂且高风险保护场景中的分散决策。文章中的完整实施、模拟环境和训练脚本已公开发布在GitHub上，这展示了该方法在实际应用中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "任务向量与梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术已经成为一种简单而强大的模型合并技术，能够将多个微调模型合并为一个。尽管它在实际中取得了成功，但缺乏明确的理论解释，说明为什么以及在什么情况下它会奏效。本文通过建立任务向量与任务损失梯度之间的连接，为任务算术提供了一种坚实的理论基础。研究结果显示，在标准梯度下降下，一个来自一次微调周期的任务向量等同于损失的负梯度，比例因子为学习率。对于多周期的实际设置，本文证明了这种等效关系近似成立，并且对前向网络给出了二次误差项，并进行了明确的边界。实验分析验证了这一理论，表明第一周期梯度在范数和方向上主导了微调轨迹。关键推论是，仅微调一次就合并模型可以获得性能，这与完全收敛模型合并相当。这些发现将任务算术重新定义为近似多任务学习的形式，提供了一个清晰的有效性理由，并突出了早期训练动态在模型合并中的关键作用。", "innovation": "本文通过建立任务向量与任务损失梯度之间的连接，为任务算术提供了一种坚实的理论基础。证明了标准梯度下降下，任务向量与负梯度之间的等效关系，并对前向网络给出了二次误差项，并进行了明确的边界。实验分析验证了任务算术的有效性，并将任务算术重新定义为近似多任务学习的形式。", "conclusion": "本文中的实验结果表明，仅微调一次就合并模型可以获得性能，这与完全收敛模型合并相当。任务算术被重新定义为近似多任务学习的形式，提供了一个清晰的有效性理由，并突出了早期训练动态在模型合并中的关键作用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "在大型语言模型自我和跨模型评估中量化标签诱导的偏差", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "近年来，大型语言模型（LLMs）被越来越多地用作文本质量的评估者，但其判断的有效性仍然没有得到充分探索。本研究旨在系统性地探究三个主流LLMs——ChatGPT、Gemini和Claude——在自我评估和互相评估中存在的偏见问题，实验设计了一个控制实验，研究表明感知到的模型身份对高层面的认识以及细微的质量评估都会产生实质性影响，这挑战了LLM作为评估者的可靠性，并突显了需要盲评估协议和多元化的多模型验证框架，以确保自动文本评估和LLM基准测试的公平性和有效性。", "innovation": "研究设计了一个控制实验，比较三个LLMs的自我和交叉评估结果，并使用类型偏好投票和细粒度质量评级进行了分析。实验发现在评估中感知到的模型身份显著影响了判断结果，不同标签引起的偏差极大地影响了偏好排序和质量评估，这在一定程度上揭示了LLM作为评估者可靠性的问题，为使用LLM进行自动文本评估和基准测试提供了新的视角。", "conclusion": "本研究揭示了感知模型身份对LLM评估结果的实质性影响，提高了人们对LLM作为评估者中潜在偏见的认识。这挑战了LLM作为评估者的可靠性，强烈呼吁实施盲评估协议和采用多样化的多模型验证框架来确保自动文本评估和LLM基准测试的公平与有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到X学习：通过随机游走打破分散性的障碍", "title_en": "From Federated Learning to X-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "本文提供对X-Learning（XL）的看法，这是一种新颖的分布式学习架构，扩展了去中心化概念。文章旨在介绍XL的设计考虑和自由度，并探讨XL、图论和马尔可夫链之间的直观但非平凡的联系。此外，还提出了若干开放的研究方向以激发进一步的研究。这些内容明确了联邦学习到X学习的转变过程，并通过随机游走的方法打破分散性障碍，提出了新的视角来增强学习系统的灵活性和效率。", "innovation": "本文的创新点在于提出了一种新的分布式学习框架X-Learning，它不仅扩展了去中心化学习的概念，而且通过引入随机游走的方法来提高学习系统的灵活性。此外，文章还深入探索了X-Learning与其他领域（如图论和马尔可夫链）的联系，为研究者提供了新的研究视角和方向。", "conclusion": "本文揭示了X-Learning的概念及其在分布式学习中的应用潜力。通过展示X-Learning与图论和马尔可夫链的联系，作者为未来研究指明了方向，强调了进一步探索其未开发的设计考虑和自由度的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.07793", "html_url": "https://arxiv.org/abs/2509.07793", "title": "个体生活满意度的效用揭示了与政治倾向无关的不平等厌恶", "title_en": "Individual utilities of life satisfaction reveal inequality aversion unrelated to political alignment", "authors": "Crispin Cooper,Ana Fredrich,Tommaso Reggiani,Wouter Poortinga", "background": "本研究探讨了社会中幸福感应该如何被优先考虑，以及人们在公平与个人幸福感之间愿意做出哪些权衡。研究通过一项针对英国全国代表性样本的表达偏好实验（n = 300），考察了参与者在不确定性条件下对自己和他人生活满意度结果的评估。", "innovation": "本研究使用期望效用最大化（EUM）框架来估算个体效用函数，并测试了对小概率权重过度的敏感性，这由前景理论（CPT）特征化。研究揭示了大多数参与者具有凹形（风险规避）的效用曲线，并对社会生活满意度结果中的不平等显示更强的厌恶，相比个人风险。这些偏好与政治倾向无关，表明存在一种关于幸福感公平性的共享规范性立场，跨越了意识形态界限。", "conclusion": "本研究挑战了平均生活满意度作为政策指标的使用，并支持开发出反映集体人类价值观的非线性效用基线替代方案。讨论了公共政策、幸福感衡量和价值观对齐的人工智能系统设计的含义。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09708", "html_url": "https://arxiv.org/abs/2509.09708", "title": "超越‘对不起，我不能’：探究大型语言模型拒绝行为", "title_en": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal", "authors": "Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee", "background": "指令调优的大语言模型（LLMs）在面对有害提示时表现出的关键安全性行为是拒绝，但这些行为的内部机制目前尚未完全理解。本文研究了两个开源指令调优模型Gemma-2-2B-IT和LLaMA-3.1-8B-IT，通过训练残差流激活的稀疏自编码器（SAEs），来探索这种拒绝行为背后的因果关系。", "innovation": "本文提出了一个包含三个阶段的管道：（1）拒绝方向：寻找一个调节拒绝的方向，并收集该方向附近的SAE特征；（2）贪婪过滤：减到最小特征集；（3）交互发现：拟合一个因子化机（FM）来捕捉剩余激活特征与最小特征集之间非线性的交互关系。该管道揭示了广泛的关键性突破特征，提供了一个关于拒绝机制的见解。此外，研究还发现了冗余的特征，这些特征只有在早期特征被抑制时才会激活。", "conclusion": "研究结果表明，通过操纵可解释的潜在空间进行细致的审计和靶向干预，有可能提升安全性行为。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA：多模态对象感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "本文介绍了MOCHA（多模态对象感知跨架构对齐）知识蒸馏方法，该方法将大型视觉-语言教师（例如LLaVa）的区域级多模态语义转移到轻量级仅视觉对象检测学生（例如YOLO）中。与专注于密集或全局对齐的先前方法不同，MOCHA在对象级别操作，从而使高效的知识迁移成为可能，无需修改教师或在推理中使用文本输入。", "innovation": "MOCHA创新性地提出了通过对象级的多模态语义对齐，将大型视觉-语言模型的知识高效地转移到轻量级的对象检测模型中，且不需改变教师模型或在推理时加入文本输入。通过双重目标损失训练学生模型和转换模块，确保局部对齐和全局关系一致性。", "conclusion": "实验证明，MOCHA在四个个性化的检测基准测试下，特别是在少量样本的情况下，能够持续优于基线，平均分提高了10.1分。尽管其架构紧凑，MOCHA的性能与大型的多模态模型相当，证明了其在实际部署中的适用性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06836", "html_url": "https://arxiv.org/abs/2509.06836", "title": "COMPACT: 共同标记优化的跨通道和标记模型剪枝", "title_en": "COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens", "authors": "Eugene Kwek,Wenpeng Yin", "background": "在边缘部署、交互应用和大规模持续推理中，使大型语言模型（LLMs）在内存、延迟和服务成本方面更高效至关重要。现有的剪枝技术虽然有潜力，但仍存在一些限制：宽度剪枝常常打破标准的Transformer架构，需要定制的推理代码；深度剪枝可能导致显著的准确率下降。此外，尽管许多剪枝方法对LLMs有效，它们在小型语言模型（SLMs）上保持性能方面存在问题。因此，亟需一种既能够解决这些问题又能够有效剪枝小型语言模型的方法。", "innovation": "本文提出了一种名为COMPACT的方法，该方法联合执行两个任务：一是剪枝稀有词汇以缩小嵌入层和LM头部层；二是通过使用共同标记加权激活进行FFN中间通道剪枝，使重要性与后剪枝标记分布相一致。COMPACT方法继承了宽度和深度剪枝的优点，如保持标准Transformer架构的部署友好性、根据上下文调整型号缩放的适应性、剪枝时间和内存节省效果强，同时还能获得吞吐量的提升。实验结果表明，该方法在Qwen、LLaMA和Gemma家族（0.5B-70B参数）中展现出最先进的下游性能，显著减少了参数数量、GPU内存和延迟。", "conclusion": "实验证明，COMPACT方法在多种语言模型中表现出色，不仅在剪枝效果上具有竞争力，还在内存和延迟方面实现了显著优化。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16293", "html_url": "https://arxiv.org/abs/2509.16293", "title": "ByteDance的稳健大语言模型训练基础设施", "title_en": "Robust LLM Training Infrastructure at ByteDance", "authors": "Borui Wan,Gaohong Liu,Zuquan Song,Jun Wang,Yun Zhang,Guangming Sheng,Shuguang Wang,Houmin Wei,Chenyuan Wang,Weiqiang Lou,Xi Yang,Mofan Zhang,Kaihua Jiang,Cheng Ren,Xiaoyun Zhi,Menghan Yu,Zhe Nan,Zhuolin Zheng,Baoquan Zhong,Qinlong Wang,Huan Yu,Jinxin Chi,Wang Zhang,Yuhan Li,Zixian Du,Sida Zhao,Yongqiang Zhang,Jingzhe Tang,Zherui Liu,Chuan Wu,Yanghua Peng,Haibin Lin,Wencong Xiao,Xin Liu,Liang Xiang", "background": "大语言模型（LLMs）的训练规模已达到数万个GPU，并持续扩大，这使得模型学习速度更快。然而，随着资源规模的扩大，失败（如CUDA错误、NaN值、任务挂起等）变得普遍，这对训练稳定性提出了重大挑战。任何大规模LLM训练基础设施都应尽量减少训练中断、高效诊断故障并有效应对失败，以实现高效的持续训练。", "innovation": "ByteRobust是一个专为大语言模型训练设计的大型GPU基础设施管理系统，它利用大语言模型训练的独特性，在常规方式下检测和恢复故障。ByteRobust利用并行性和大语言模型训练的特性，通过数据驱动的方法实现了高容量的故障冗余、快速故障边界划定和定位，全面确保大语言模型任务的持续高效训练。", "conclusion": "ByteRobust已在拥有超过20万GPU的生产GPU平台上部署，并在使用9600个GPU进行为期三个月的训练工作的测试中实现了97%的预期吞吐率（ETTR）。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19088", "html_url": "https://arxiv.org/abs/2509.19088", "title": "一项大规模数字孪生研究揭示了优势、劣势及其进一步改进的机会", "title_en": "A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement", "authors": "Tiany Peng,George Gui,Daniel J. Merlau,Grace Jiarui Fan,Malek Ben Sliman,Melanie Brucks,Eric J. Johnson,Vicki Morwitz,Abdullah Althenayyan,Silvia Bellezza,Dante Donati,Hortense Fong,Elizabeth Friedman,Ariana Guevara,Mohamed Hussein,Kinshuk Jerath,Bruce Kogut,Akshit Kumar,Kristen Lane,Hannah Li,Patryk Perkowski,Oded Netzer,Olivier Toubia", "background": "数字孪生个体（“数字双胞胎”）有望改变社会科学和决策方式。但是，尚不清楚这些孪生体是否真正地映射了他们所模仿的人。为此，研究者对美国代表性样本及其数字孪生体进行了19项事先注册的研究。所有孪生体都基于丰富的个层数据建立，使人类和孪生体在广泛领域和刺激下的行为可以直接进行对比（包括以前从未见过的新刺激）。", "innovation": "这项研究采用了强大的定量和方法论，通过直接对比人类和孪生体的行为来评估数字孪生的效果。研究发现孪生体在某些领域（如社交和个性）上表现出更强的表现，但在政治等领域表现较弱。孪生体的准确性还取决于参与者的教育水平、收入和政治观点等个人信息。", "conclusion": "这些研究结果阐明了数字孪生未来的前景和现有局限性：数字孪生能够捕捉一些个体间的相对差异，但还没有达到个体的独特判断。研究者建议应进一步发展和评估数字孪生管道，并使其更完善。所有相关数据和代码都已公开。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22536", "html_url": "https://arxiv.org/abs/2509.22536", "title": "InfiR2: 一种增强推理解释能力的语言模型的全面FP8训练食谱", "title_en": "InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models", "authors": "Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Hongxia Yang", "background": "大规模语言模型（LLMs）的训练计算成本非常高，这成为创新的一大障碍。尽管采用FP8训练能够提供显著的理论效率提升，但其广泛应用受到缺乏全面且开源的训练策略的阻碍。", "innovation": "本文介绍了端到端的FP8训练策略，该策略无缝整合了连续预训练和监督微调，并采用精细度混合同步量化策略，既保持数值准确性也最大化计算效率。实验结果表明，该策略不仅稳定性高，而且几乎无损失，能够与BF16基准相当，在多个推理基准测试中表现优异，同时还实现了显著的效率改进，如训练时间减少22%，峰值内存使用减少14%，吞吐量增加19%。这使FP8成为BF16的一种实用且稳健的替代方案。", "conclusion": "本文成果确立了FP8作为一种实用且稳健的BF16替代方案的地位，并将发布相应的代码，以进一步促进大规模模型训练的民主化。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26360", "html_url": "https://arxiv.org/abs/2509.26360", "title": "TimeScope: 朝向长视频任务导向的时空定位", "title_en": "TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos", "authors": "Xiangrui Liu,Minghao Qin,Yan Shu,Zhengyang Liang,Yang Tian,Chen Jason Zhang,Bo Zhao,Zheng Liu", "background": "识别长视频中的关键时刻对下游的理解和推理任务至关重要。传统的方法在这类任务中面临着广泛应用的局限性和处理长视频的难度。", "innovation": "提出了一种新的时空定位问题ToTG，旨在基于任务的自然描述来定位包含必要信息的时间间隔。为了应对这些挑战，提出了TimeScope框架，该框架基于逐步推理来识别长视频中的粗粒度时间范围，并通过细粒度的时刻划分逐步细化该范围。同时，还构建了一个高质量的数据集ToTG Pile，以增强TimeScope在逐步时空定位中的能力。", "conclusion": "广泛的实验表明，TimeScope在各种设置中都优于现有的时空定位方法和流行的MMLMs，证明了其在解决这一新挑战性问题方面的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20374", "html_url": "https://arxiv.org/abs/2509.20374", "title": "CFDLLMBench: 用于评估大规模语言模型在计算流体力学中的基准套件", "title_en": "CFDLLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics", "authors": "Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan", "background": "大语言模型（LLMs）在通用自然语言处理（NLP）任务中表现出强大的性能，但在自动化复杂物理系统中的数值实验方面的作用仍然未被充分探索。计算流体力学（CFD）是一个适合考察LLMs科学能力的独特且具有挑战性的测试平台。本文介绍了CFDLLMBench基准套件，该套件包括CFDQuery、CFDCodeBench和FoamBench三个互补组件，旨在全面评估LLMs在CFD知识、数值和物理推理以及上下文相关CFD工作流实现方面的性能。该基准套件基于实际的CFD实践，通过详细的任务分类和严格的评估框架，提供了可重复的结果，并量化了LLMs在代码可执行性、解的准确性以及数值收敛行为方面的表现。", "innovation": "本文主要创新在于开发了CFDLLMBench基准套件，这是首个针对计算流体力学领域的LLMs评测工具，系统地评估LLMs在CFD知识、数值和物理推理以及上下文相关CFD工作流实施方面的性能。该工具结合了实际的CFD实践和严格的评估框架，提供了可重复、可量化的LLMs性能数据，为LLMs驱动的复杂物理系统数值实验的自动化发展奠定了坚实的基础。", "conclusion": "CFDLLMBench为LLMs驱动的复杂物理系统数值实验自动化开发和评估提供了坚实的基础。通过可重复的结果和量化方法，该基准套件能够全面评价LLMs在计算流体力学中的应用潜力，并促进了该领域进一步的研究和发展。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG：一种统一和可扩展代码库生成的仓库规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大型语言模型在生成单个函数或单个代码文件方面表现出色，但在从零开始生成完整的代码库方面仍然面临根本性挑战。这一能力对于从高层次规范构建连贯的软件系统和实现自动化代码生成的全部潜力至关重要。过程需要在两个层面进行规划：决定构建哪些功能和模块（提案阶段）以及定义其实现细节（实现阶段）。当前方法依赖自然语言规划，经常产生不清楚的规范、不对齐的组件和由于其固有的含糊性和平面结构而变得脆弱的设计。为了应对这些限制，我们引入了仓库规划图（RPG），这是一种结构化的表示方法，可以统一编码能力、文件结构、数据流和功能。通过用明确的蓝图替换自由格式的自然语言，RPG使得对仓库生成的长期规划得以一致进行。基于RPG，我们开发了ZeroRepo，这是一种以图驱动的框架，分为三个阶段：提案级别的规划、实现级别的构建和由图指导的代码生成及测试验证。为了评估，我们创建了RepoCraft基准，包含六个真实世界的项目和1,052个任务。在RepoCraft上，ZeroRepo生成了约36千行代码行和445万代码令牌，平均比最强基准（Claude Code）大3.9倍，比其他基准大68倍。ZeroRepo实现了81.5%的覆盖率和69.7%的测试准确性，分别比Claude Code提高了27.3和35.8个百分点。进一步分析表明，RPG模型复杂的依赖关系，通过接近线性的扩展实现更复杂的设计，从而提高代理对仓库的理解，加速定位过程。", "innovation": "我们引入了仓库规划图（RPG），这是一种结构化的表示方法，可以统一编码能力、文件结构、数据流和功能。通过用明确的蓝图替换自由格式的自然语言，RPG使得对仓库生成的长期规划得以一致进行。基于RPG，我们开发了ZeroRepo，这是一种以图驱动的框架，分为三个阶段：提案级别的规划、实现级别的构建和由图指导的代码生成及测试验证。该框架提高了代理对仓库的理解，并通过接近线性的扩展实现更复杂的设计。", "conclusion": "ZeroRepo生成了约36千行代码行和445万代码令牌，平均比最强基准（Claude Code）大3.9倍，比其他基准大68倍。它实现了81.5%的覆盖率和69.7%的测试准确性，相比Claude Code分别提高了27.3和35.8个百分点。进一步分析表明，RPG模型复杂的依赖关系，通过接近线性的扩展实现更复杂的设计，从而提高代理对仓库的理解，加速定位过程。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21979", "html_url": "https://arxiv.org/abs/2509.21979", "title": "在医疗视觉语言模型中评估和缓解阿谀行为的基准和方法", "title_en": "Benchmarking and Mitigate Sycophancy in Medical Vision-Language Models", "authors": "Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu", "background": "视觉语言模型(VLMs)在临床工作流程中越来越重要，但它们往往表现出阿谀行为，优先考虑与用户语言风格、社会暗示或权威观念的一致性，而不是基于证据的推理。本研究通过一个新的临床导向基准评估了医疗视觉问答中的阿谀行为。建立了由PathVQA、SLAKE和VQA-RAD组成、按不同器官系统和模态分层的医疗阿谀数据集。使用心理动机的压力模板，本研究在各种VLMs上进行了对抗实验，发现这些模型普遍脆弱，呈现在生成对抗性响应时的显著变化，并与模型准确度或大小无强相关性。研究表明模仿和专家提供的修正最为有效，表明模型具有独立于视觉证据的偏见机制。为了解决这一问题，提出了用于证据驱动响应的视觉信息净化(VIPER)策略，这是一种轻量级缓解策略，过滤非证据内容如社会压力，然后生成受限的证据先行答案。该框架平均减少了阿谀行为并优于基线，同时保持了可解释性。我们的基准分析和缓解框架为医疗VLMs的稳健部署奠定了基础，突出了需要基于证据的防御措施的必要性。", "innovation": "提出了一个新的临床导向基准和缓解阿谀行为的VIPER策略，能够过滤非证据内容并生成受限的证据先行答案，有效减少了阿谀行为，同时保持了模型的可解释性。", "conclusion": "研究建立了包括来自PathVQA、SLAKE和VQA-RAD的数据集，涵盖了不同器官系统和模态。通过对多种VLMs进行对抗实验，发现模型普遍脆弱并存在独立于视觉证据的阿谀行为偏见。提出并验证了VIPER策略，显著减少了阿谀行为，适用于实际临床交互，为医疗VLMs的稳健部署提供了基础。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23135", "html_url": "https://arxiv.org/abs/2509.23135", "title": "信任区域奖励优化和近端逆向奖励优化算法", "title_en": "Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm", "authors": "Yang Chen,Menglin Zou,Jiaqi Zhang,Yitan Zhang,Junyi Yang,Gael Gendron,Libo Zhang,Jiamou Liu,Michael J. Witbrock", "background": "逆强化学习（IRL）用于学习一个奖励函数以解释专家演示。现代IRL方法通常使用对抗（ minimax）形式，通过奖励和策略交替优化，这往往会导致不稳定的训练。尽管非对抗性IRL方法通过能量形式联合学习奖励和策略来提高稳定性，但缺乏正式保证。本研究填补了这一空白。作者首先提出了一种统一的观点，即经典的非对抗性方法明确或隐含地最大化专家行为的概率，这等效于最小化期望回报差距。这一洞见引导我们提出了主要贡献：信任区域奖励优化（TRRO），一种通过最小值最大化过程确保这一概率单调改进的框架。TRRO通过近端逆向奖励优化（PIRO）实例化为一种实用且稳定的IRL算法。", "innovation": "TRRO提供了一种通过最小值最大化过程确保单调改进的框架，这是一种声誉保障机制，在前向强化学习中相当于信任区域策略优化（TRPO）的稳定性保障。TRRO实例化为PIRO，这是一种实用且稳定的方法，能够匹配或超越MuJoCo和Gym-Robotics基准测试中的SOTA基线，以及一个真实世界的动物行为建模任务。", "conclusion": "本文提出了TRRO框架，通过最小值最大化过程确保IRL中重要概率的单调改进。通过PIRO实例化，该框架在各类基准测试和实际任务中展示了其优越性和稳定性，提供了IRL中的稳定性保障，并进一步证明了TRRO的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25289", "html_url": "https://arxiv.org/abs/2509.25289", "title": "ClustRecNet：一种新的端到端深度学习聚类算法推荐框架", "title_en": "ClustRecNet: A Novel End-to-End Deep Learning Framework for Clustering Algorithm Recommendation", "authors": "Mohammadreza Bakhtyari,Bogdan Mazoure,Renato Cordeiro de Amorim,Guillaume Rabusseau,Vladimir Makarenkov", "background": "聚类算法在无监督学习中扮演着重要角色，但选择合适的聚类算法一直是一个挑战。为了解决这一问题，本研究构建了一个包含34,000个合成数据集的全面数据仓库，每个数据集都使用了10种流行的聚类算法。通过调整后的兰德指数（Adjusted Rand Index, ARI）对聚类结果进行了评估，以此来确定地真标签，用于训练和评估深度学习模型。本研究设计了一个网络架构，结合了卷积、残差和注意力机制，以捕捉输入数据中的局部和全局结构模式。", "innovation": "本研究提出了一种名为ClustRecNet的新框架，即通过深度学习来推荐最适合某个给定数据集的聚类算法。该框架扩展了传统的监督学习应用到聚类算法选择上，通过一个集成了卷积、残差和注意力机制的网络架构，能够直接推荐最合适的聚类算法，减少了对手工设计的元特征和传统聚类有效性指标（CVI）的依赖。", "conclusion": "在不同合成和真实世界的基准测试中，本研究提出的深度学习模型在聚类有效性指标（如轮廓系数、卡林斯基-哈拉巴兹指数、戴维斯-暴雨宁指数和邓恩指数）上的一致表现超过了其他主流的自动机器学习聚类推荐方法（如ML2DAC、AutoCluster和AutoML4Clust）。特别是在合成数据上，模型的ARI改进了0.497，在真实数据上也获得了15.3%的AR改进，这种方法证明在聚类算法选择上具有很强的实用性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01171", "html_url": "https://arxiv.org/abs/2510.01171", "title": "Verbalized Sampling: 如何缓解模式坍塌并释放预训练语言模型的多样性", "title_en": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity", "authors": "Jiayi Zhang,Simon Yu,Derek Chong,Anthony Sicilia,Michael R. Tomz,Christopher D. Manning,Weiyan Shi", "background": "后训练对齐通常会减少大语言模型（LLM）的多样性，可能会导致一种被称为模式坍塌的现象。以往的研究通常将这一现象归因于算法限制，而本文作者则认为数据层面的驱动因素更根本：偏好数据中的典型性偏见，这种偏见导致注释者倾向于选择熟悉的内容，这是认知心理学中已有的研究结果。", "innovation": "本文引入了一种简单的、无需训练的提示策略——Verbalized Sampling（VS），以绕过模式坍塌。该策略促使模型用语言描述一组响应的概率分布（例如：“生成5个关于咖啡的笑话及其对应概率”）。详尽的实验表明，VS 在创意写作（诗歌、故事、笑话），对话模拟，开放性问答，和合成数据生成等方面显著提高了性能，同时保持了事实准确性与安全性。此外，测试还发现更强大的模型更受益于VS。", "conclusion": "我们的工作提供了一种新的、数据为中心的观点来解释模式坍塌，并提供了一个实用的推理阶段解决方案，有助于释放预训练生成的多样性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01644", "html_url": "https://arxiv.org/abs/2510.01644", "title": "使用机器学习进行新型大语言模型故障检测与分析", "title_en": "Machine Learning for Detection and Analysis of Novel LLM Jailbreaks", "authors": "John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra", "background": "大语言模型（LLMs）面临着各种漏洞，恶意用户可以通过操纵输入文本来诱使模型产生不恰当的回复。被称为“监狱突破”（jailbreak）的提示词设计目的是使模型绕过开发者设置的安全保护措施。本文研究了不同机器学习模型区分正规提示与监狱突破提示的能力，特别是识别使用之前未见过策略的监狱突破提示。研究表明，通过细调双向Transformer编码器表示模型（BERT）能够达到最佳性能。", "innovation": "本文分析了不同机器学习模型区分监狱突破提示与正规提示的能力，并指出通过完全细调BERT模型可以获得最佳性能。此外，文中还可视化了能够区分监狱突破与正式提示的关键词汇，这表明提示结构中的明确反思可能是监狱突破意图的信号。", "conclusion": "研究结果表明，通过完全细调BERT模型可以最好地识别出监狱突破提示。同时，本文还指出，提示结构中的明确反思可能是监狱突破意图的一个信号。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25776", "html_url": "https://arxiv.org/abs/2509.25776", "title": "可编辑噪声图反转：将目标图像编码为噪声以实现高保真度图像操控", "title_en": "Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation", "authors": "Mingyu Kang,Yong Suk Choi", "background": "文本到图像的扩散模型在生成高质量和多样化的图像方面取得了显著成就。基于这些进展，扩散模型在文本引导的图像编辑方面也表现出色。一种有效的图像编辑策略是将源图像反转为与目标图像关联的可编辑噪声图。然而，以往的反转方法在遵循目标文本提示方面面临挑战。虽然反转的噪声图可以忠实重建源图像，但限制了进行所需编辑所需的灵活性。为解决这个问题，我们提出了可编辑噪声图反转（ENM 反转）这一新颖的反转技术，旨在寻找既能保持内容又能实现编辑的最优噪声图。我们分析了噪声图的特性，以增强其可编辑性。基于这一分析，我们的方法引入了可编辑噪声精炼，通过最小化重建噪声图和编辑噪声图之间的差异来与所需编辑对齐。广泛的实验表明，ENM 反转在广泛范围内的图像编辑任务中，在保持和编辑保真度方面均优于现有方法，并且能够轻松应用于视频编辑，以实现帧间的时序一致性和内容操控。", "innovation": "我们提出了一种新型的可编辑噪声图反转（ENM Inversion）技术，旨在通过寻找既能保持内容又能实现编辑的最优噪声图来解决传统反转方法在遵循目标文本提示方面的局限性。通过分析噪声图的特性并引入可编辑噪声精炼，最小化重建噪声图和编辑噪声图之间的差异，以更好地对齐所需编辑。该方法在多种图像编辑任务中均优于现有方法，并且可以在视频编辑中实现时序一致性和内容操控性。", "conclusion": "该研究提出了一种新的可编辑噪声图反转技术，显著提高了图像和视频编辑的保真度和灵活性。通过优化噪声图的编辑特性，该技术在保持原始内容的同时实现了精确的编辑，展现了广阔的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03016", "html_url": "https://arxiv.org/abs/2510.03016", "title": "从不准确监督学习稳健的扩散模型", "title_en": "Learning Robust Diffusion Models from Imprecise Supervision", "authors": "Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang Shen,Masashi Sugiyama", "background": "近期，条件扩散模型在多种生成任务中取得了显著成就，但它们的训练通常依赖于包含条件输入中不精确信息的大规模数据集。噪声、模糊或不完整的标签监督会导致条件不匹配，从而降低生成质量。", "innovation": "本文提出了DMIS（从不准确监督训练鲁棒扩散模型）框架，这是首次系统研究扩散模型中的一致性监督问题。该框架基于似然最大化，将目标分解为生成和分类组件：生成组件模拟不精确标签分布，分类组件利用扩散分类器推断后验概率，进一步通过优化时间步采样策略提高效率。", "conclusion": "DMIS在不同形式的不精确监督下对图像生成、弱监督学习和噪声数据集凝聚任务进行了广泛实验，结果表明DMIS生成的高质量和类别区分度的样本具有良好的表现。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01795", "html_url": "https://arxiv.org/abs/2510.01795", "title": "Nav-EE: 导航引导的早期退出机制以提高自主驾驶中视觉语言模型的效率", "title_en": "Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving", "authors": "Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Shangyu Wu,Nan Guan,Chun Jason Xue", "background": "视觉语言模型（VLMs）在自主驾驶中被广泛应用，用于统一感知和推理，但由于高推断延迟，难以实现实时部署。早期退出方法通过在中间层终止推理来降低推断延迟，但其任务特定性限制了其在多种场景下的通用性。研究发现，这种局限性与自主驾驶的特点相符，即导航系统可以预测即将到来的上下文（例如，交叉口、交通灯），并据此推断将需要哪些任务。", "innovation": "我们提出了一种名为Nav-EE的导航引导早期退出框架，该框架预先在线下计算特定于任务的退出层，并基于导航先验在在线阶段动态应用这些层。实验结果表明，与完整推理相比，Nav-EE在保持相似准确性的前提下，延迟最多减少了63.9%。实车集成中的进一步测试表明，Nav-EE可将推断延迟降低至300ms，支持在复杂场景中更快地做出决策。这些结果表明，将导航先见与早期退出相结合，为大型模型在自主系统中的有效部署提供了一种可行途径。", "conclusion": "耦合导航预见与早期退出为自主系统中高效部署大型模型提供了一条可行路径。实验结果和实车测试验证了Nav-EE的有效性，证明了其在提高自主驾驶中视觉语言模型的效率方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02463", "html_url": "https://arxiv.org/abs/2510.02463", "title": "CLARITY: 临床辅助分诊、推理与标签", "title_en": "CLARITY: Clinical Assistant for Routing, Inference, and Triage", "authors": "Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets", "background": "在医疗健康领域，医生与患者之间的沟通效率和准确性至关重要，特别是在分诊、推理和评估患者病情严重程度方面。为了提高这一过程的效率和质量，一种基于人工智能的平台——CLARITY（Clinical Assistant for Routing, Inference and Triage）被提出。该平台利用有限状态机（FSM）和大型语言模型（LLM）协作代理来优化患者与专科医生的连接、临床会诊及病情评估流程，旨在提供安全、高效且可靠的性能，同时具备灵活扩展以适应现有医疗工作流程和信息系统的特性。", "innovation": "CLARITY 平台的特点在于其混合架构结合了有限状态机用于结构化的对话流程，并利用了大型语言模型进行症状分析，以优先推荐合适的专科医生。此外，该平台基于模块化的微服务框架构建，确保了其在实际医疗环境中的安全、高效和稳健性能，并易于扩展以适应现有工作流程和IT解决方案的需求。", "conclusion": "CLARITY 被成功集成到一个全国性的跨医院平台中，自部署以来，平台处理了超过55,000条内容丰富的用户对话，其中有2,500条经过专家注释以进行后续验证。验证结果表明，CLARITY 在首次尝试分诊的精确度方面超过了人类的表现，且会诊时间缩短至只有人类会诊的三分之一以下。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03243", "html_url": "https://arxiv.org/abs/2510.03243", "title": "提示感知调度以实现低延迟LLM服务", "title_en": "Prompt-Aware Scheduling for Low-Latency LLM Serving", "authors": "Yiheng Tao,Yihe Zhang,Matthew T. Dearing,Xin Wang,Yuping Fan,Zhiling Lan", "background": "LLM推理任务的高效调度对于实现低延迟和高吞吐量至关重要，特别是在使用具有推理能力的LLM时。传统的先到先服务（FCFS）策略往往因为头阻塞（HOL阻塞）问题而受到影响，即长时间运行的任务会延误后面排队的较短任务。因此，需要引入一种新的调度策略来解决这个问题，以提高LLM服务效率。", "innovation": "本文介绍了一种提示感知的LLM任务调度器——PARS，它通过成对的排名和边际排名损失近似最短任务优先（SJF）调度法，专注于具有影响性的调度决策，并成功将该系统无缝集成到最先进的LLM服务系统vLLM中。PARS能够通过预测响应长度为基础的任务排序来有效降低延迟，且几乎不受额外开销的影响。实验证明，PARS在多个LLM和实际推理数据集上显著改善了性能，尤其是在推理任务负载方面。此外，跨模型评估表明，该设计具有良好的普适性，即使预测器是基于不同的LLM进行训练的，调度器也能有效工作。", "conclusion": "实验研究表明，PARS能够显著提高LLM服务性能，特别是对于推理工作负载，且其设计具有良好的泛化能力，能够实现对不同模型的有效调度。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03370", "html_url": "https://arxiv.org/abs/2510.03370", "title": "InstructPLM-mu：ESM2在1小时内微调可超越ESM3的蛋白质突变预测", "title_en": "InstructPLM-mu: 1-Hour Fine-Tuning of ESM2 Beats ESM3 in Protein Mutation Predictions", "authors": "Junde Xu,Yapin Shi,Lijun Lang,Taoyong Cui,Zhiming Zhang,Guangyong Chen,Jiezhong Qiu,Pheng-Ann Heng", "background": "多模态蛋白质语言模型在预测突变效果方面表现出色，但训练这些模型需要大量计算资源。本文背景介绍了现有的训练方法的资源需求，并讨论了如何通过微调预训练的语言模型来提高预测性能，从而减少资源需求。", "innovation": "本文提出了一个名为InstructPLM-mu的微调框架，旨在探索在结构信息输入下预训练序列模型的微调是否能与端到端训练的模型达到相当的性能。实验结果显示使用ESM2进行1小时的微调即可达到ESM3的性能。作者系统地比较了不同的特征融合设计和微调策略，发现融合方法和微调策略对最终准确性有重大影响，揭示了微调过程并不简单。该工作为向预训练蛋白质语言模型注入结构信息提供了实用指导，并激发了更好的融合机制和微调协议的研究兴趣。", "conclusion": "该研究展示了如何通过1小时的微调，结合结构信息，显著提高蛋白质突变预测的性能，同时指出微调过程和策略的选择对结果至关重要。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04020", "html_url": "https://arxiv.org/abs/2510.04020", "title": "以规划为导向的空间时间预测：具有生成世界模型的基于模型的强化学习方法", "title_en": "Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models", "authors": "Hao Wu,Yuan Gao,Xingjian Shi,Shuaipeng Li,Fan Xu,Fan Zhang,Zhihong Zhu,Weiyan Wang,Xiao Luo,Kun Wang,Xian Wu,Xiaomeng Huang", "background": "本文旨在解决物理空间时间预测中的双重挑战——固有的随机性和非可微度量。传统的预测方法难以处理这两种挑战，本文提出了一种新的方法，即空间时间预测作为规划（SFP）模型，该方法基于模型导向的强化学习。", "innovation": "提出了一种新的SFP框架，该框架利用生成世界模型模拟多样的高保真未来状态，实现了基于想象的环境模拟。在此框架下，一个基预测模型作为代理，由基于束搜索的规划算法引导，该算法利用非可微度量作为回报信号来探索高回报的未来序列。生成的高回报候选者作为伪标签，通过迭代自我训练优化代理策略，显著减少了预测误差，并在捕捉极端事件的关键领域度量上表现出色。", "conclusion": "SFP方法显著减少了预测误差，在关键领域度量如捕捉极端事件上表现出色，并通过迭代自我训练优化代理策略。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03807", "html_url": "https://arxiv.org/abs/2510.03807", "title": "6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection", "title_en": "6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection", "authors": "Vaskar Chakma,Wooyeol Choi", "background": "当前，将数字孪生技术集成到网络物理系统（CPS）中，面临在关键工业应用中实现实时性能的挑战。现有5G系统中超过10毫秒的延迟无法满足需要亚毫秒级响应时间的应用需求，如自主工业控制和预测性维护。现有网络技术的延迟和响应时间无法满足上述应用的实际需求。", "innovation": "本文研究旨在开发并验证一种基于6G技术的数字孪生框架，以实现超低延迟通信和物理工业资产及其数字对应物之间的实时同步，特别针对滚动轴承故障检测这一关键工业应用场景。该框架整合了太赫兹通信、智能反射面和边缘人工智能技术，并构建了一个五层架构。通过使用卡斯韦尔州立大学（CWRU）的轴承数据集进行实验验证，展示了系统在分类准确度、端到端延迟和可扩展性方面的优越性能。", "conclusion": "该系统在轴承故障分类中达到了97.7%的准确性，端到端延迟仅为0.8毫秒，相对于Wi-Fi-6和5G网络，分别提高了15.6倍和5.25倍。系统的可扩展性得到了证明，处理时间随着数据集规模的增加呈非线性增长，并在四种轴承故障类别（正常、内圈、外圈和滚珠故障）上保持了高一致性能，宏F1分数超过97%。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04212", "html_url": "https://arxiv.org/abs/2510.04212", "title": "为什么低精度Transformer训练会失败：关于Flash Attention的分析", "title_en": "Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention", "authors": "Haiquan Qiu,Quanming Yao", "background": "低精度格式被广泛用于训练Transformer模型，以提高计算效率。然而，这种进程往往受到训练稳定性差的问题阻碍。特别是在低精度设置中使用flash attention时，模型训练过程中会出现灾难性的损失爆炸问题，长期以来一直未能得到解决。", "innovation": "该论文首次从机制上解释了在低精度设置中使用flash attention导致训练损失爆炸的根本原因。研究揭示了该失败并非随机现象，而是由两个相互关联的现象引起：注意力机制中相似的低秩表示的出现和低精度算术中固有的偏向性舍入误差的累积效应。论文提出通过简单修改flash attention来抵消舍入误差的偏差，从而稳定训练过程，验证了研究结论，并提供了一个解决这一持续问题的实际方案。", "conclusion": "通过引入对flash attention的简单修改，论文成功地抵消了舍入误差的偏差，从而稳定了训练过程，这一结论不仅证实了他们的分析，还提供了一个实用的解决方案来解决长期存在的问题。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04503", "html_url": "https://arxiv.org/abs/2510.04503", "title": "P2P: 一种针对大语言模型中可靠后门防御的解药", "title_en": "P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs", "authors": "Shuai Zhao,Xinyi Wu,Shiqian Zhao,Xiaobao Wu,Zhongliang Guo,Yanhao Jia,Anh Tuan Luu", "background": "在微调过程中，大语言模型（LLMs）越来越容易受到数据污染后门攻击的影响，这损害了它们的可靠性和可信度。现有的防御策略存在局限性，只能应对特定类型的攻击或任务设置。", "innovation": "本文提出了一种名为P2P（Poison-to-Poison）的通用且有效的后门防御算法。P2P算法通过注入具有安全替代标签的良性触发器，并利用基于提示的学习来重新污染数据集进行微调。这种方法加强了模型将触发器诱导的表示与安全输出关联起来，从而覆盖原始恶意触发器的效果。实验结果显示，P2P 在不同类型的任务和攻击模式下均表现出色，理论上和实证上均证实了它能够消除恶意后门同时保持任务性能。", "conclusion": "我们进行了广泛的实验，包括分类、数学推理和摘要生成等多个任务，涉及多种最先进的LLMs。结果表明，P2P算法能显著降低比基线模型的攻击成功率。我们希望P2P能够作为防御后门攻击的指南，并促进安全和可信的LLM社区的发展。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04217", "html_url": "https://arxiv.org/abs/2510.04217", "title": "MLLMEraser: 通过激活导向实现多模态大型语言模型的测试时未学习", "title_en": "MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering", "authors": "Chenlu Ding,Jiancan Wu,Leheng Sheng,Fan Zhang,Yancheng Yuan,Xiang Wang,Xiangnan He", "background": "多模态大语言模型（MLLMs）在视觉-语言任务中展示了显著的能力，但其大规模部署引起了关于存储的私密数据、过时知识和有害内容等问题的担忧。现有的针对MLLMs的未学习方法通常采用基于训练的策略，如梯度上升或偏好优化，但这些方法计算成本高、不可逆且常常扭曲保留的知识。因此，亟需一种高效且可逆的未学习方法，以移除指定的遗留知识，而又不影响保留的知识的实用性。", "innovation": "本文提出了一种名为MLLMEraser的输入感知、无需训练的框架，用于测试时未学习。该方法利用激活导向技术，通过对比对抗扰动的知识召回图像-文本对与知识消除的对应物，来实现动态知识消除，同时不动参数。输入感知的导向机制根据需求决定何时及如何应用消除方向，以保护保留知识的同时执行对特定内容的遗忘。实验表明，MLLMEraser在LLaVA-1.5和Qwen-2.5-VL上的表现优于现有最先进的MLLM未学习基准，实现了更好的遗忘性能，成本更低且对保留知识的实用性影响较小。", "conclusion": "本研究提出了一种新的未学习方法MLLMEraser，通过激活导向实现多模态大型语言模型的测试时未学习，该方法有效且高效，能够在干扰指定遗留知识的同时保留有用的知识，且计算成本低，对保留知识的影响小。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06250", "html_url": "https://arxiv.org/abs/2510.06250", "title": "面向LLM的可扩展多语言PII注解，以实现负责任的人工智能", "title_en": "Scalable multilingual PII annotation for responsible AI in LLMs", "authors": "Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu", "background": "随着大型语言模型（LLMs）的广泛应用，确保它们在多种监管环境下可靠地处理个人可识别信息（PII）变得至关重要。", "innovation": "该论文提出了一种可扩展的多语言数据整理框架，用于13种欠代表的区域中高质PII注解，涵盖约336种特定于地方的PII类型。以阶段性和人工在环的注解方法结合语言专长和严格的质量保证，显著改善了召回率和假阳性率。通过利用注解者间协议度量和根本原因分析，该框架系统地发现并解决了注解不一致性问题，生成了适合监督LLM微调的高质量数据集。", "conclusion": "该工作不仅报告了实际收益，还指出了多语言PII标签过程中的常见注解者挑战，并展示了迭代、分析为导向的工作流程如何提高注释质量和下游模型可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04888", "html_url": "https://arxiv.org/abs/2510.04888", "title": "从统计方法到大型语言模型：揭示疾病的相互联系", "title_en": "Revealing Interconnections between Diseases: from Statistical Methods to Large Language Models", "authors": "Alina Ermilova,Dmitrii Kornilov,Sofia Samoilova,Ekaterina Laptenkova,Anastasia Kolesnikova,Ekaterina Podplutova,Senotrusova Sofya,Maksim G. Sharaev", "background": "通过手动分析大规模临床数据来识别疾病之间的联系是劳动密集型、主观的，并且容易引起专家意见分歧。尽管机器学习有潜力，但仍然存在三个关键挑战：1）从广阔的机器学习领域中选择最佳方法；2）确定现实世界的临床数据（例如电子健康记录，EHR）或结构化的疾病描述哪种能提供更可靠的信息；3）缺乏“真实标准”，因为医学领域中仍有一些疾病之间的联系未被探索。", "innovation": "本文构建了一个系统评估框架，针对两种数据源：(i) MIMIC-IV EHR中的ICD-10代码序列；(ii) 完整的ICD-10代码集，包含或不包含文本描述。框架包括统计共现分析、带掩码的词语言模型（MLM）、特定领域BERT变体（Med-BERT和BioClinicalBERT）、通用BERT、文档检索以及四种大型语言模型（Mistral、DeepSeek、Qwen和YandexGPT）。结果显示，基于大型语言模型的方法产生的疾病之间联系的ICD代码联系多样性最低，表明大型语言模型在发现新联系方面的潜力有限。", "conclusion": "由于缺乏ICD代码之间医学联系的真实标准数据库，本文的结果构成了一个宝贵的医学疾病词汇表，可作为未来临床研究和医疗保健中人工智能应用的基础资源。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "从成对比较中在线提取评分标准", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek", "background": "评分标准提供了一种灵活的方式，用于训练语言模型（LLMs）生成开放式的长篇内容，而不依赖于可验证的奖励和模糊的人类偏好信号。现有研究显示，使用基于评分标准的奖励进行强化学习可以提升模型训练后的表现。然而，大多数现有方法都依赖于在整个训练过程中保持不变的评分标准，这种静态评分标准容易导致奖励欺骗行为，并且无法捕捉到训练过程中出现的新期望。", "innovation": "本文提出了一种名为Online Rubrics Elicitation（在线评分标准提取，缩写OnlineRubrics）的新方法，该方法通过政策响应的成对比较动态地在线制定评估标准。这种方法能够使模型在训练过程中持续地识别和纠正错误。实验结果显示，在AlpacaEval、GPQA、ArenaHard以及专家问题和评分标准验证集上的表现，使用在线评分标准比仅使用静态评分标准提高了约8%。", "conclusion": "通过对提取的评估标准进行定性分析，发现其中突出的主题包括透明性、实用性和组织性，以及推理能力。这种方法为改进LLMs提供了新的路径，特别是在开放生成任务中。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04996", "html_url": "https://arxiv.org/abs/2510.04996", "title": "Reinforce-Ada: 一种适用于强化样式大语言模型训练的自适应采样框架", "title_en": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training", "authors": "Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang", "background": "将强化学习应用于大语言模型（LLMs）进行推理任务时，通常会受到响应采样过程中不稳定梯度估计的瓶颈，因为对不同提示的响应进行固定和均匀的采样。以往的研究如GVM-RAFT通过在预算约束下动态分配推理预算，以最小化随机梯度方差解决了这一问题。灵感来源于此，本文提出了Reinforce-Ada，一种在线RL后训练LLMs的自适应采样框架，该框架不断重新分配采样努力，将焦点放在具有最大不确定性和学习潜力的提示上。Reinforce-Ada与传统的两阶段分配方法不同，在线连续渐进消除过程交织采样与估计，一旦采集到足够信号自动停止采样。为了稳定更新，它使用自适应采样阶段中汇集的全局统计计算优势基线，并形成具有强制多样奖励的固定大小组。", "innovation": "Reinforce-Ada提出了一种新的适应性采样框架，针对LLMs的强化学习后训练，实现了在每个迭代中动态调整采样努力，优先对最不确定或最有学习潜力的提示进行采样。该方法通过在线消除法交错估计与采样，自动在收集足够信号后停止采样，并在自适应采样阶段采用全局统计计算优势基线，从而实现稳定的更新。此外，它不需要固定预采样或强制决断，而是动态评估和分配计算资源。", "conclusion": "基于多个模型架构和推理基准的实验结果表明，与GRPO相比，Reinforce-Ada能够加快收敛并提高最终性能，尤其是在使用平衡采样变体时。这项工作强调了有意识地减少变异、自适应数据收集在有助于使用推理能力强的大语言模型的高效和可靠强化学习中的核心作用。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05901", "html_url": "https://arxiv.org/abs/2510.05901", "title": "解构混合线性注意转换方法中的组件不平衡", "title_en": "Untangling Component Imbalance in Hybrid Linear Attention Conversion Methods", "authors": "Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas", "background": "尽管Transformer模型在性能上表现出色，但它们的二次计算复杂度限制了它们的可扩展性。虽然线性注意力可将这一复杂度降低到线性级别，但这种模型从零开始预训练仍然在大多数情况下成本高昂。最近，后训练线性化方法通过结合线性注意力和滑窗softmax高效地将预训练Transformer转换为线性模型。然而，现有方法中存在一个关键缺陷：这些方法在混合过程中会无意间绕过线性组件，主要依赖滑窗softmax。这种不平衡现象的原因是在常见常识基准测试中存在的未注意到的评估方式。", "innovation": "本文提出了三种确保组件均衡利用的方法：(i) 在推理时将仅线性模型转换与滑窗softmax混合；(ii) 结合注意力权重转移与目标LoRA微调的HedgeCATs；(iii) 在训练过程中随机抑制softmax分支的计划滑窗丢弃（SSD），防止组件崩溃。这三种方法在保持计算效率的同时恢复了大部分基模型的性能，并确保了线性注意的真正采用，从而恢复了混合转换中性能归因的有效性。", "conclusion": "通过这三种方法，本文维护了计算效率，恢复了基模型的大部分性能，并确保了线性注意力的实际应用，恢复了混合转换中性能归因的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07314", "html_url": "https://arxiv.org/abs/2510.07314", "title": "GyroSwin：用于等离子体湍流模拟的5D代理模型", "title_en": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations", "authors": "Fabian Paischer,Gianluca Galletti,William Hornsby,Paul Setinek,Lorenzo Zanisi,Naomi Carey,Stanislas Pamela,Johannes Brandstetter", "background": "核聚变在可靠和可持续能源生产中起着关键作用。一个主要的障碍是如何理解等离子体湍流，它严重影响等离子体的约束，在下一代反应堆设计中至关重要。等离子体湍流受非线性哥氏湍流方程控制，该方程随时间演变5D分布函数。由于计算成本高，实践中通常使用降阶模型来近似湍热传输，但这些模型会忽略全5D动力学中的非线性效应。", "innovation": "我们提出了GyroSwin，这是第一个可扩展的5D神经代理模型，能够模拟5D非线性哥氏湍流，捕获被降阶模型忽略的物理现象，同时提供湍热传输的准确估计。GyroSwin通过（i）将分级视觉变换器扩展到5D，（ii）引入在静电位场和分布函数之间进行3D↔5D交互的交叉注意力和整合模块，（iii）受非线性物理学启发的通道模式分离，提升了预测性能。", "conclusion": "GyroSwin在热流预测上优于广泛使用的降阶数值方法，捕捉湍流能量耗散，将完全解析的非线性哥氏湍流计算成本降低三个数量级，同时保持物理验证性。GyroSwin展示了具有良好扩展规律的性能，测试规模达到十亿参数，为可扩展神经代理模型的等离子体湍流哥氏湍流模拟铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07488", "html_url": "https://arxiv.org/abs/2510.07488", "title": "人类团队的经验能否应用于多智能体系统？结构、多样性和互动动态的作用", "title_en": "Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics", "authors": "Rasika Muralidharan,Haewoon Kwak,Jisun An", "background": "多智能体系统（MAS）借助大型语言模型（LLM）的代理正在获得关注，然而，对于代理团队的动态研究较少。受人类团队科学的启发，本文提出了一种多智能体框架，用于探索团队科学的核心方面：结构、多样性和互动动态。研究涵盖四个方面：常识问答、策略问答、社会智商和潜在隐含仇恨，涉及常识和社交推理。", "innovation": "本文创新性地将人类团队科学应用于多智能体系统中，提出了一个新的框架来研究多智能体系统的团队结构、多样性和互动动态，并通过四个任务对比分析发现扁平结构团队的性能优于层级结构团队，多样性的影响具有复杂性，代理对团队表现过于自信，但事后反思揭示了合作价值和整合挑战，特别是对话协调有限。", "conclusion": "本文研究表明，扁平结构的团队在多个任务中表现更好。多样性对团队效果的影响是复杂的。代理对团队效果过于自信，但在任务后的反思中显示了协作的价值和整合中的难题，其中对话协调有限是一个关键挑战。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07414", "html_url": "https://arxiv.org/abs/2510.07414", "title": "Haystack 工程：用于异构和自主长上下文评估的环境构建", "title_en": "Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation", "authors": "Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li", "background": "现代长期上下文大语言模型（LLMs）在合成的'针扎干草堆'（NIAH）基准测试中表现出色，但这些测试忽略了从偏差检索和自主工作流程中带来的噪声上下文产生的复杂性。文章指出，有必要进行'干草堆工程'来构建真实的噪声长上下文，这些上下文能够忠实地捕捉关键的现实世界因素，如来自不同偏差检索器的干扰和自主工作流程中的瀑布式错误，以此来测试模型在长上下文中的鲁棒性。", "innovation": "该研究通过推出HaystackCraft，一种基于完整英语维基百科链接网络的新NIAH基准测试，结合多跳问题进行实例化。HaystackCraft评估不同检索策略（如稀疏、密集、混合和图基）对干扰构成、干草堆排序和后续LLM性能的影响。此外，它进一步将NIAH扩展到动态的、依赖于LLM的设置中，模拟自主操作，在这些设置中，模型可以调整查询、反思过去的推理并决定何时停止。实验结果表明，更强的密集检索器虽然引入了更具挑战性的干扰，但图基重新排名同时提高了检索效果并减轻了更多的有害干扰；在自主测试中，即便是先进的模型如Gemini 2.5 Pro和GPT-5也会因自我生成的干扰或难以执行早期停止而失败或遭受连续失败。", "conclusion": "研究结果揭示了在自主长期上下文推理中持久性的挑战，并将HaystackCraft确立为未来研究有价值的测试平台。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08279", "html_url": "https://arxiv.org/abs/2510.08279", "title": "学习神经曝光场进行视图合成", "title_en": "Learning Neural Exposure Fields for View Synthesis", "authors": "Michael Niemeyer,Fabian Manhardt,Marie-Julie Rakotosaona,Michael Oechsle,Christina Tsalicoglou,Keisuke Tateno,Jonathan T. Barron,Federico Tombari", "background": "近期神经场景表示的进步显著提升了3D重建和视图合成的质量。尽管在常见基准测试中，针对精心挑选的数据能够获得高质量的结果，但在包含图像间变化的数据上，如强烈的曝光变化，输出往往会下降，特别是在室内和室外场景或有窗户的房间中。", "innovation": "本文提出了神经曝光场（NExF），这是一种用于从具有挑战性的实际拍摄中稳健地重建高质量且3D一致外观的3D场景的新方法。该方法的核心是学习一个神经场，预测每个3D点的最佳曝光值，从而能够优化曝光与神经场景表示。这种3D优化方法能够准确合成高动态范围场景中的视图，无需后处理步骤或多重曝光捕捉，使用新颖的神经条件机制实现了场景表示与曝光场的联合优化，结果在挑战性现实世界数据上表现出色。", "conclusion": "本文方法在几个基准上表现出了优于前工作的性能，训练速度更快，并且相比最好的基线提升了超过55%的结果。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07985", "html_url": "https://arxiv.org/abs/2510.07985", "title": "更少的权重，更多问题：一种针对LLM剪枝的实用攻击", "title_en": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "authors": "Kazuki Egashira,Robin Staab,Thibaud Gloaguen,Mark Vero,Martin Vechev", "background": "大语言模型（LLMs）推理过程中的内存占用成为了显著问题，模型剪枝成为了一种常用方法来降低内存占用量。现有的剪枝方法虽然在实用性和效率方面取得了一定进步，但这些方法的潜在安全风险依然没有被充分研究。本文首次揭示了现代LLM剪枝方法可以被恶意利用，展示了一个adversary通过计算参数被剪枝的可能性，在那些难以剪枝的参数中注入恶意行为，然后通过容易被剪枝的参数来进行修复，从而有效地抵消未剪枝模型中的恶意行为。该研究通过在五个模型上进行广泛评估，表明这种攻击在多种场景下的成功率非常高。这项研究揭示了模型部署过程中存在的重要安全漏洞，强调了在模型压缩过程中增强安全意识的紧迫性。", "innovation": "本文引入了一种新的攻击模型，通过计算特定参数被剪枝的概率，adversary可以在那些难以剪枝的参数中注入恶意行为，然后通过其他容易被剪枝的参数来进行修复，从而确保即使经过剪枝的模型仍然表现出恶意行为。这种方法有效地揭示了剪枝操作潜在的安全风险，并挑战了现有剪枝方法的安全性假设。", "conclusion": "研究展示了在模型部署过程中存在的重要安全漏洞，即使经过剪枝的模型也可能包含潜在的恶意行为。研究结果强调了在模型压缩过程中增强安全措施的重要性，同时也指出了需要进一步研究如何在保持高效的同时确保模型安全。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08445", "html_url": "https://arxiv.org/abs/2510.08445", "title": "合成序列-符号数据生成用于时间序列基础模型", "title_en": "Synthetic Series-Symbol Data Generation for Time Series Foundation Models", "authors": "Wenxuan Wang,Kai Wu,Yujian Betterest Li,Dan Wang,Xiaoyu Zhang", "background": "时间序列分析(TSA)的基础模型近年来受到了广泛关注，但训练数据的稀缺性和不平衡性依然阻碍了这些模型的发展。", "innovation": "该研究受复杂动态系统理论启发，设计了一种序列-符号数据生成机制，可以生成高质量的时间序列数据并配备相应的符号表达。为此，开发了SymTime，这是一种利用符号信息增强时间序列表示能力的预训练基础模型。SymTime在五个主要的TSA任务中表现出竞争力，与基于真实数据集进行预训练的基础模型相近。", "conclusion": "该方法强调了序列-符号数据生成和预训练机制在克服数据稀缺性并提升任务性能方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08592", "html_url": "https://arxiv.org/abs/2510.08592", "title": "较少多样性的不安全：大规模语言模型中测试时缩放的间接但普遍存在的风险", "title_en": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models", "authors": "Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra", "background": "TTS通过探索多个候选答案并从中选择最佳输出来提高LLM的推理能力。TTS假设多样化的候选池会增加可靠性。然而，研究发现当候选池的多样性被适度限制时，TTS更有可能生成不安全的输出。", "innovation": "作者提出了一个参考引导多样性的减少协议（RefDiv），作为诊断攻击以压力测试TTS管道。通过广泛的实验证明，限制多样性会显著增加TTS生成不安全结果的频率，这种效果在不同TTS策略和模型上都普遍存在。此外，现有的安全防护措施对由RefDiv生成的对抗性输入提示无能为力，说明TTS策略在应对多样性驱动的压力测试时存在普遍但不小的漏洞。", "conclusion": "该研究揭示了TTS的一个新的潜在风险，即多样性受限会导致不安全性增加，这不是特定模型的特性，而是一个普遍问题。因此，研究推荐了更稳健且安全的TTS策略，特别是在应对多样性的压力测试时更为有效。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08588", "html_url": "https://arxiv.org/abs/2510.08588", "title": "使用GLiNER-BioMed结合目标字典后处理增强生物医学命名实体识别——BioASQ 2025任务6", "title_en": "Enhancing Biomedical Named Entity Recognition using GLiNER-BioMed with Targeted Dictionary-Based Post-processing for BioASQ 2025 task 6", "authors": "Ritesh Mehta", "background": "Biomedical Named Entity Recognition (BioNER) 在生物医学文献信息提取中至关重要，但面临如区分基因与化学物质等相似实体类别的挑战。GLiNER-BioMed模型在BioASQ数据集上进行了评估，并引入了针对性的字典后处理策略来解决常见的误分类问题。尽管该后处理方法在开发集上表现良好，增加了微F1分数（从基线0.79提高到0.83），但在盲测集上，并未得到相同的提升，后处理模型在盲测集上的微F1分数仅为0.77，而基线仍为0.79。研究还探讨了替代方法，包括条件随机场，从中获得了关于预训练BioNER模型潜在改进和防止过拟合的重要性见解。", "innovation": "引入了针对特定错误分类的字典后处理策略，使用GLiNER-BioMed模型进行评估，并探讨了不同方法的效果，包括条件随机场，为预训练BioNER模型的改进提供了新的视角。", "conclusion": "字典基于的后处理策略可能对预训练BioNER模型有积极影响，但需要克服过拟合问题以保证稳健的泛化能力，从而实现实际应用中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08593", "html_url": "https://arxiv.org/abs/2510.08593", "title": "基于层次自监督表示学习的语音抑郁检测", "title_en": "Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech", "authors": "Yuxin Li,Eng Siong Chng,Cuntai Guan", "background": "基于语音的抑郁检测（SDD）作为一种非侵入性替代传统临床评估的方法，具有很大前景。然而，它仍然受限于难以提取有意义的特征以及难以捕捉随时间变化的稀疏和异质抑郁线索。预训练的自监督学习（SSL）模型如WavLM提供了丰富的多层语音表示，但现有的大多数SDD方法仅依赖最终层或寻求表现最佳的一个，这些方法往往过度拟合特定数据集，未能充分利用所需的分层结构来检测微妙且持久的抑郁信号。", "innovation": "本文提出了一种创新的HAREN-CTC架构，它在多任务学习框架内结合多层SSL特征，并使用跨注意力机制来应对稀疏的时序监督，同时通过连接主义时序分类（CTC）损失进行训练以对齐模式。HAREN-CTC包含两个关键模块：层级自适应聚类模块用于重新组织SSL特征为互补嵌入，交叉模态融合模块则通过跨注意力机制建模跨层依赖关系。CTC目标允许模型追踪抑郁语音线索的不规则时间模式。", "conclusion": "我们在标准数据分割的上限设置和使用五折交叉验证的一般性设置中评估了HAREN-CTC。该模型在DAIC-WOZ和MODMA数据集上分别实现了最先进的宏F1分数0.81和0.82，跨两种评估场景均优于先前的方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08596", "html_url": "https://arxiv.org/abs/2510.08596", "title": "创意，而非困惑：LLM新时代更好的指标", "title_en": "Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs", "authors": "V. S. Raghu Parupudi", "background": "现有的参考独立度量标准（如自我困惑度）很容易偏向创造性文本生成。这项研究指出，基于流畅度的度量标准在99个创意提示中0%的情况下偏好新颖响应，而新的度量标准自信心分（CS）在19%的情况下偏好新颖响应，这在统计上有显著差异。CS还能够有效地区分容易、中等和困难的任务，这得到了不重叠的信心区间所证实。", "innovation": "提出了一种新的度量标准，即自信心分（CS），它是从模型输出概率分布中衍生出来的，相比现有的度量标准如自我困惑度，自信心分能够减少创造性偏差，同时保留传统度量的核心评估优势，为现代LLM提供更平衡的评估标准。", "conclusion": "自信心分（CS）相比传统的参考独立度量标准（如自我困惑度）提供了一个更少偏向创造性的评估方式，能够更好地区分任务难易程度，并且整体上能提供一个更为均衡的评价方式来评估现代大型语言模型的表现。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08595", "html_url": "https://arxiv.org/abs/2510.08595", "title": "大规模语言模型脆弱推理的系统诊断", "title_en": "Systematic Diagnosis of Brittle Reasoning in Large Language Models", "authors": "V. S. Raghu Parupudi", "background": "人工智能中的一个重要问题在于机器学习模型是否真正理解数学。本文基于此背景，提出了一种新的框架来评估数学推理的能力，该框架超越了标准的基准测试，能够诊断具体的推理失效点。", "innovation": "本文的创新之处在于提出了一种新的方法，首先使用gpt-3.5-turbo生成GSM8K数据集上的结构化、分步推理，然后通过gpt-4o-mini进行错误分类，并通过对每一句推理句子的无监督聚类，识别出新的“推理模式”。这一分析揭示了模型的认知轮廓具有非人类的脆弱性：尽管在顺序计算等程序性模式上表现近乎完美，但在要求组合推理和限制条件的模式上表现较差。通过对这些不同推理技能的可靠性和准确性的识别和量化，该工作提供了一种更加详细的评估数学理解的方法，并为开发新的能力和更可靠的应用提供了明确的路线图。", "conclusion": "通过这种方法，作者发现模型在程序性模式上的表现优秀，但在需要组合推理和有约束条件的模式上表现较差，揭示了模型在数学推理方面的脆弱性。该工作为数学理解的评估提供了一个更精细的方法，并为未来能力的发展提供了一个详细的道路图。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08600", "html_url": "https://arxiv.org/abs/2510.08600", "title": "Recover-LoRA: 通过低秩适应数据无关恢复退化语言模型的准确性", "title_en": "Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation", "authors": "Devleena Das,Rajeev Patwari,Ashish Sirasao", "background": "在语言模型任务中，诸如量化、剪枝、格式与数据类型转换、模型导出和序列化之类的推理优化可以导致功能下降。尽管大多数恢复性能的努力集中在鲁棒的量化技术上，但此项研究关注的是从任何导致模型权重退化的原因中恢复模型准确性，如不正确的模型序列化。研究表明，这种轻量级且与数据集无关的方法Recover-LoRA能够通过合成数据和logit蒸馏学习LoRA适配器，在选择层上促进退化模型与全精度模型的对齐。", "innovation": "提出了一种名为Recover-LoRA的方法，该方法通过合成数据和logit蒸馏学习LoRA适配器，在选择层上促进退化模型与全精度模型的对齐，以从任何导致模型权重退化的因素中恢复模型准确性。这项研究对不同架构的小语言模型（包括具有不同注意力机制的模型）以及多个评估数据集进行了评估，结果显示，Recover-LoRA能够在具有不同注意力架构的小语言模型上恢复5-17%的模型准确性。", "conclusion": "实验结果表明，Recover-LoRA能够在具有不同注意力架构的小语言模型上恢复5-17%的模型准确性。这项研究表明，即使是在模型重量被不良序列化导致退化的情况下，也能够有效的恢复模型性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08602", "html_url": "https://arxiv.org/abs/2510.08602", "title": "人类文本是异常值：基于异常检测检测LLM生成的文本", "title_en": "Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection", "authors": "Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu", "background": "随着大语言模型（LLM）如ChatGPT、DeepSeek和Claude的迅速发展，AI生成的文本在数字通信中的比例显著增加。现有的检测方法往往将任务视为二分类问题，导致不同领域和模型间缺乏良好的泛化能力。", "innovation": "本文提出重新将检测任务重新定义为异常检测问题，将人类写作视为分布异常值，将机器生成的文本视为模型内的样本。基于此概念，本文开发了一种检测框架，使用one-class learning方法（如DeepSVDD和HRN）和基于分数的学习技术（如能量基方法），实现了鲁棒性和高泛化性能。实验表明，该方法在DeepFake数据集上实现了98.3%的AUROC和AUPR，且误报率为8.9%95。此外，该框架在多语言、攻击和未见过的语言和领域设置下表现出鲁棒性和通用性。", "conclusion": "本文提出了一种基于异常检测的LLM生成文本检测方法，并通过广泛的实验验证了该方法的有效性。未来的工作将进一步测试和完善该框架的鲁棒性和应用范围。"}
{"llm_update_time": "20251013", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08539", "html_url": "https://arxiv.org/abs/2510.08539", "title": "RLVR的优化动态：梯度间隙与步长阈值", "title_en": "On the optimization dynamics of RLVR: Gradient gap and step size thresholds", "authors": "Joe Suk,Yaqi Duan", "background": "RLVR是一种使用简单二元反馈在后训练大型语言模型的方法，已经在实践中取得了显著的成功。然而，对于它为何有效的原因，缺少了一个原理性的理解。本文通过在响应的整体和令牌层面分析其训练过程，为RLVR建立了理论基础，重点探讨了从低奖励区域到高奖励区域的梯度差距（Gradient Gap）如何指导更新方向及其重要性，从而解释了其收敛性依赖于更新方向与梯度差距的对齐，并进一步预测了关键步长如何随响应长度和成功率变化，解释了长度归一化等实用技巧如何提高稳定性，同时展示了固定学习速率下成功率会停滞在不到100%的情况，并通过控制性的-upper试验验证了这些预测。", "innovation": "本文通过理论分析建立了RLVR的基础，提出了梯度差距的概念，并证明了更新方向必须与梯度差距保持一致才能实现收敛。还推导出了步长阈值，表明低于阈值时学习收敛，高于阈值时性能会崩溃。进一步预测了关键步长与响应长度和成功率的关系，解释了稳定性和成功率的支持率可以保持在不到100%的现象，并通过实验验证了预测的准确性。", "conclusion": "本文探讨了RLVR在响应的整体和令牌层面的训练过程，并系统地分析了梯度差距的概念，证明了关键步骤依赖于梯度差距。进一步预测了关键步长随响应长度和成功率的变化趋势，通过控制性实验验证了这些理论的实用性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08603", "html_url": "https://arxiv.org/abs/2510.08603", "title": "YpathRAG：病理检索增强生成框架及其基准", "title_en": "YpathRAG:A Retrieval-Augmented Generation Framework and Benchmark for Pathology", "authors": "Deshui Yu,Yizhi Wang,Saihui Jin,Taojie Zhu,Fanyi Zeng,Wen Qian,Zirui Huang,Jingli Ouyang,Jiameng Li,Zhen Song,Tian Guan,Yonghong He", "background": "大语言模型在通用任务上表现出色，但在病理学等高门槛领域仍然存在奇幻回答的问题。以往的工作通常依赖于领域微调，但这种方法并未扩展知识边界，也未能强制执行基于证据的约束。", "innovation": "构建了一个覆盖28个子领域的病理向量数据库，包含153万段落。提出了YpathRAG，这是一种面向病理的RAG框架，采用双通道混合检索（BGE-M3密集检索与词汇引导稀疏检索相结合）和一个基于大语言模型的支持性证据判断模块，从而形成了检索-判断-生成的循环。此外，还发布了两个评估基准，YpathR和YpathQA-M。在YpathR上的评估中，YpathRAG取得了5次召回（Recall@5）98.64%的结果，比基线高出23个百分点；在YpathQA-M上的复杂问题集上，提高了通用和医学大语言模型的准确性，平均提高了9.0%，最高提高至15.6%。", "conclusion": "这些结果表明检索质量和事实可靠性的提升，为面向病理的RAG提供了一种可扩展的构建方法和具有解释性的评估框架。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08601", "html_url": "https://arxiv.org/abs/2510.08601", "title": "Mnemosyne: 一种面向边缘基于LLM的无监督、人启发式长期记忆架构", "title_en": "Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs", "authors": "Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)", "background": "自然、真实的对话需要依赖长期记忆。当前的大语言模型（LLM）的记忆系统主要依赖于无脑扩展上下文或静态检索管道，这些方法在边缘计算设备上表现不佳。现有的方法无法有效处理受限边缘设备上的长期对话需求，限制了它们在实际应用场景中的应用。", "innovation": "我们提出了Mnemosyne，一种无监督的、类人类长期记忆架构，专门设计用于边缘计算的LLM。Mnemosyne采用了图结构存储，模块化的物质和冗余过滤器，记忆提交和修剪机制，以及带有时间衰减和刷新过程的概率重述，这些机制模拟人类记忆。此外，Mnemosyne还引入了一种高效的“核心摘要”，它可以从固定长度的记忆图子集有效地提取出来，以捕捉用户的个性和其他特定领域的长期细节，如在医疗保健应用中的恢复目标和护理态度。", "conclusion": "在纵贯式医疗对话实验中，Mnemosyne在盲评中关于对话真实性和长期记忆能力的胜率为65.8%，远高于基线RAG的31.1%。Mnemosyne在时间推理和单跳检索方面也达到了最高分，超过了其他相同主干技术。此外，其整体平均得分为54.6%，排名第二，首次超越了常见的Mem0和OpenAI基线。这表明，通过开发一种与边缘计算兼容且易于移植的无监督记忆架构，可以实现更好的事实回溯、增强的时间推理以及更加自然的用户响应。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜空间反馈突破大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": " Jailbreaks 是针对大型语言模型内置安全机制的恶意攻击。现有的 Jailbreak 攻击通常通过优化恶意后缀或适应长提示模板来解锁模型响应。然而，这些攻击可以通过简单的困惑度过滤来检测。为了应对这一挑战，作者提出了 LatentBreak，这是一种白盒 Jailbreak 攻击方法，它可以生成自然且低困惑度的对抗提示，从而绕过基于困惑度的防御。", "innovation": "LatentBreak 方法通过在输入提示中用语义等效词替换词汇，而不是添加高困惑度的恶意后缀或长模板，并且这些词的选择基于在潜空间中将对抗提示的表示与无害请求的表示之间的最小距离，从而生成自然且低困惑度的对抗提示。", "conclusion": "实验结果表明，LatentBreak 生成的对抗提示更短且低困惑度，因此在多个安全对齐的模型上优于其他基于困惑度的过滤器的工作。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08606", "html_url": "https://arxiv.org/abs/2510.08606", "title": "聚焦情绪热点：对话中多模态局部-全局融合及跨模态对齐", "title_en": "Centering Emotion Hotspots: Multimodal Local-Global Fusion and Cross-Modal Alignment for Emotion Recognition in Conversations", "authors": "Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li", "background": "情绪识别在对话（ERC）中是一个挑战。因为区分性证据稀少、局部化且通常不同模态之间异步存在。传统的ERC方法通常难以捕捉这些重要的情绪信号。", "innovation": "该研究提出了一个统一模型，该模型能够在文本、音频和视频中检测每个短语的情绪热点，通过热点门融合（Hotspot-Gated Fusion, HGF）融合局部特征，并使用路由混合变换器（routed Mixture-of-Aligners）对齐模态。跨模态图用于编码对话结构，该设计旨在聚焦于显著区间、减少对齐错误并保持上下文。", "conclusion": "实验表明，该方法在标准ERC基准数据集上的表现优于强大的基线方法，并且消融实验确认了HGF和MoA的贡献。研究结果表明，采用聚焦情绪热点的方法可以为未来的多模态学习提供新的视角，为ERC中的模态融合提供新思路。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08605", "html_url": "https://arxiv.org/abs/2510.08605", "title": "朝向更安全的网络：多语言多代理大模型以减轻对抗性误导信息攻击", "title_en": "Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks", "authors": "Nouar Aldahoul,Yasir Zaki", "background": "数字平台上错误信息的快速传播威胁着公共讨论、情绪稳定和决策。尽管之前的工作已经研究了各种错误信息检测中的对抗攻击，但本文探讨的具体转换尚未被系统地研究。研究包括语言转换（从英语、法语、西班牙语、阿拉伯语、印地语和中文之间转换）和随后的翻译，以及在总结前查询长度膨胀和结构重塑为多个选择题。", "innovation": "本文提出了一个多语言、多代理的大语言模型框架，该框架结合了检索增强生成机制，并且可以部署为网络插件到在线平台。这项工作突出了AI驱动的错误信息检测的重要性，以保护网上事实的完整性，同时展示了基于插件的部署方法在实际网络应用中的可行性。", "conclusion": "我们的工作表明，利用多语言多代理大语言模型框架可以有效地应对多种错误信息攻击，保障网络环境中的事实真实性，为实际的网络应用提供了切实可行的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08613", "html_url": "https://arxiv.org/abs/2510.08613", "title": "GraphGhost：追踪大型语言模型背后的结构", "title_en": "GraphGhost: Tracing Structures Behind Large Language Models", "authors": "Xinnan Dai,Kai Guo,Chung-Hsiang Lo,Shenglai Zeng,Jiayuan Ding,Dongsheng Luo,Subhabrata Mukherjee,Jiliang Tang", "background": "大语言模型（LLMs）展示了惊人的推理能力，但它们背后的结构机制仍是一个待探索的领域。本文介绍了一种名为GraphGhost的统一框架，该框架将神经元激活及其信号传播表示为图形，解释了LLMs如何从序列输入中捕获结构性语义并通过结构一致的机制生成输出。这种基于图形的观点使我们能够利用PageRank等图形算法来刻画LLMs的特性，揭示不同数据集中的共享和模型特定的推理行为。", "innovation": "GraphGhost框架能够表示神经元激活及其信号传播，并通过图形算法如PageRank来刻画LLMs的特性，揭示其结构化的推理和生成机制。此外，通过结构干预来评估激活的神经元，发现关键神经元节点的修改可以触发推理崩溃，影响逻辑流程和语义理解。这些贡献使GraphGhost成为分析、干预和最终理解LLMs推理结构的强大工具。", "conclusion": "通过GraphGhost，我们不仅能够分析LLMs的结构化推理机制，还可以通过干预来改变模型的行为，这为深入理解大型语言模型的工作原理提供了新的视角和工具。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08608", "html_url": "https://arxiv.org/abs/2510.08608", "title": "MMC-ASIA：跨模态多语言框架以实现基于文化背景的评估", "title_en": "MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation", "authors": "Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen", "background": "大型语言模型（LLMs）在世界各地得到广泛应用，但它们在非西方、资源较少的环境中的多模态理解与推理往往会出现下降。目前缺乏专门针对亚洲文化的多语言、多模态基准测试框架来评估LLMs的文化意识与理解能力。", "innovation": "本研究提出MMC-ASIA框架，开发了一套高效的人类编纂、多语言多模态的多项选择基准，适用于亚洲文化背景，覆盖8个国家和10种语言，包含27,000道题目，其中79%以上题目需要基于文化背景的多步推理，而不仅局限于记忆事实。该基准在文本、图像（视觉问答）和语音这三类模态的输入层面进行对齐，首次能够直接评估跨模态的转换效果。基于该基准，提出了一个包含五个维度的评估协议，涵盖了国家间的文化差异、跨语言一致性、跨模态一致性、文化知识的一般化及验证有效性的评估维度。此外，还提出了一个文化意识基础验证模块，旨在检测模型通过捷径学习来获得答案的情况。", "conclusion": "通过比较模型分析、注意力追踪以及一种新颖的视觉剥夺前缀重播（VPR）方法，研究深入探讨了模型在不同语言和模态中的差异，为构建更加文化可靠性的多模态LLMs提供了可行的建议。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08621", "html_url": "https://arxiv.org/abs/2510.08621", "title": "从模拟到策略：个性化交互规划自动化", "title_en": "From Simulation to Strategy: Automating Personalized Interaction Planning for Conversational Agents", "authors": "Wen-Yu Chang,Tzu-Hung Huang,Chih-Ho Chen,Yun-Nung Chen", "background": "随着代理对话模型的迅速发展，真实的用户模拟研究对于调整有效的对话策略至关重要。本研究探讨了一个以销售为导向的代理，该代理根据用户的年龄、性别和职业等特征调整其对话方式。年龄和性别对整体表现有一定影响，但职业对对话意图的影响最为显著。", "innovation": "研究引入了一种轻量级的职业条件策略，该策略引导代理优先处理与用户偏好一致的意图，从而缩短并提高对话的成功率。研究强调了丰富用户模拟资料的重要性，并展示了简单的人格化策略如何增强销售导向对话系统的有效性。", "conclusion": "研究结果表明，使用用户配置文件可以有效提高对话代理的表现，简单的人格化策略可以显著提升对话代理的效果。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08614", "html_url": "https://arxiv.org/abs/2510.08614", "title": "医疗领域大型语言模型中的性别偏差：身份分配一致性及其临床影响", "title_en": "Gender Bias in Large Language Models for Healthcare: Assignment Consistency and Clinical Implications", "authors": "Mingxuan Liu,Yuhe Ke,Wentao Zhu,Mayli Mertens,Yilin Ning,Jingchi Liao,Chuan Hong,Daniel Shu Wei Ting,Yifan Peng,Danielle S. Bitterman,Marcus Eng Hock Ong,Nan Liu", "background": "大语言模型（LLMs）在医疗领域的整合有望提升临床决策的质量，但其容易出现偏差的问题仍然是一个重大关注点。性别长期以来影响着医生的行为和患者结果，因此担心LLMs扮演类似临床医生或医疗教育者的角色时，可能复制或放大性别相关的偏见。", "innovation": "本研究使用新英格兰医学杂志挑战（NEJM）的案例研究，对多款开源和专有LLMs分配不同性别（女、男或未指定），评估了LLMs在基于模型的观点进行诊断和判断患者性别相关性和必要性方面的一致性。结果显示，诊断的一致性相对较高，但患者性别在诊断中的相关性和必要性判断方面表现出显著的一致性差异，部分模型甚至在解释患者性别时存在系统性的性别差异。", "conclusion": "研究表明，LLMs在临床实践中可能存在一个未被充分探索的潜在偏见，这可能削弱其可靠性。因此，在与LLMs交互时进行定期检查以确保其能够提供可靠和公平的AI支持临床护理是必要的。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08620", "html_url": "https://arxiv.org/abs/2510.08620", "title": "JAI-1: 一种以泰语为中心的大规模语言模型", "title_en": "JAI-1: A Thai-Centric Large Language Model", "authors": "Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Pontakorn Trakuekul,Sumana Sumanakul,Natchanon Pollertlam", "background": "最近的泰语模型主要依赖于现有开源模型，并在不改变结构的基础上进行额外训练以专门化。但这种方法可能在注入泰语特定信息时损害模型参数空间中已有的知识，因为针对通用任务优化的参数可能与新的语言需求相冲突。因此，JAI-1采用了一种扩容策略：从一个较小的成功英语开源LLM开始，扩展其参数空间，并利用新分配的容量系统地整合泰语知识。", "innovation": "JAI-1采用了扩容策略，从小的高表现英语开源LLM开始进行参数扩展，并利用新分配的容量系统地整合泰语知识。这种方法不仅保留了原模型的一般智能，还建立了独特架构，使得未来的增强具有可扩展性。", "conclusion": "最终生成的模型在泰语特定基准测试（IFEval-TH、MT-Bench-TH和JAI-Hall-Bench）中表现优于Typhoon2-70B，验证了扩容和知识整合框架的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08616", "html_url": "https://arxiv.org/abs/2510.08616", "title": "在重述压力测试下，大语言模型显示表面形式脆弱性", "title_en": "LLMs Show Surface-Form Brittleness Under Paraphrase Stress Tests", "authors": "Juan Miguel Navarro Carranza", "background": "大型语言模型（LLMs）的基准分数可能会因为记忆测试项目或近乎重复的内容而被夸大。已有研究表明，模型可能会依赖于测试项目的表面形式而非真正理解问题的内容，这导致模型的表现并不如预期的那么好。本文旨在通过重新评估模型在重述版本的基准问题上的表现，来检测和衡量这一现象。", "innovation": "本文提出了一种简单但有效的协议，用于通过重述基准问题来测试模型的泛化能力。该协议控制解码过程，强制使用多项选择格式，并包含一个稳健的重述清理步骤以保持语义一致性。通过Mistral-7B-Instruct和Qwen2.5-7B-Instruct模型在ARC-Easy和ARC-Challenge上的实验，验证了这一方法的有效性。研究表明，重述会引发明显的准确率下降，这与之前关于污染和表面形式捷径脆弱性的担忧是一致的。", "conclusion": "该研究通过重述版本的问题发现了大语言模型在表面形式处理上的脆弱性，这一方法可以用来更准确地评估模型的能力，也有助于模型开发者更好地理解模型的局限性，从而促进模型的改进。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08615", "html_url": "https://arxiv.org/abs/2510.08615", "title": "基于迭代大语言模型生成和精炼数学文字题中的干扰条件", "title_en": "Iterative LLM-Based Generation and Refinement of Distracting Conditions in Math Word Problems", "authors": "Kaiqi Yang,Hang Li,Yucheng Chu,Zitao Liu,Mi Tian,Hui Liu", "background": "数学推理是评估大型语言模型（LLMs）智能的重要测试平台，数学文字问题（MWPs）是其中常见的一种格式。现有大多数MWPs数据集只包含必要的信息，而忽略了许多具有干扰或多余条件的问题。已有研究表明，当引入这类干扰条件时，流行的大语言模型会出现显著性能下降。然而，具有干扰条件的MWPs数据集仍然有限，多数问题难度低且表述生硬，这使得干扰条件容易被察觉并忽略，从而降低了这些数据集作为基准的可信度。此外，当增加干扰条件时，推理过程和答案可能会发生变化，这需要大量人工检查和重新编辑解题过程。因此，需要设计一种框架来自动生成这些干扰条件，并确保其不会改变原始答案。", "innovation": "本文设计了一种迭代框架，利用大语言模型（LLMs）自动生成干扰条件，通过制定多个角度的认知提示，促进生成有意义的干扰条件，并建议进一步改进。框架的核心优势在于保留了原始与修订问题之间的共享解决方案：明确引导LLMs生成不会改变原始解决方案的干扰，从而避免重新生成答案，这一框架提高了效率，减少了生成具有干扰条件的MWPs所需的工作量，并保持了高质量的数据。", "conclusion": "本文提出了一种利用迭代LSTM框架自动生成MWPs中干扰条件的新方法，通过给LLMs提供详细的提示来生成有意义的干扰条件，同时保留原始问题和修订后的答案一致性。这种方法不仅提高了MWPs生成过程中的数据质量，还显著降低了人工检查和修正的复杂度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08622", "html_url": "https://arxiv.org/abs/2510.08622", "title": "Text2Stories：评估取款师访谈与生成的用户故事之间的对齐", "title_en": "Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories", "authors": "Francesco Dente,Fabiano Dalpiaz,Paolo Papotti", "background": "大型语言模型（LLMs）可以用于从自然语言输入（如提取访谈的转录）自动生成软件需求。然而，评估这些提取的需求是否准确反映了利益相关者的需要仍然是一个主要依靠手动进行的任务。本文介绍了一种名为Text2Stories的任务和度量方法，这些任务和度量可以量化用户故事形式的要求与实际表达的需求之间的匹配程度。", "innovation": "该研究引入了一种名为Text2Stories的度量方法和任务，用于量化用户故事与访谈转录实际需求的匹配程度，通过将转录分割成文本片段，并将对齐问题实例化为文本片段和用户故事之间的匹配问题，利用LLM匹配器在四个数据集上取得了较高精度（0.86的宏F1），并利用嵌入模型进行了有效的过滤。", "conclusion": "我们的度量方法使人们能够比较不同故事集（例如，人类生成的与机器生成的）的质量，将Text2Stories定位为评估用户故事质量的一种可扩展、安全的补充。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08626", "html_url": "https://arxiv.org/abs/2510.08626", "title": "从何到缘由：小语言模型驱动的思想空间推荐", "title_en": "From What to Why: Thought-Space Recommendation with Small Language Models", "authors": "Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar", "background": "大语言模型（LLMs）通过增强推理增强了推荐能力，但其高昂的推理成本阻碍了实际部署。小语言模型（SLMs）作为高效的替代方案虽然存在，但在推荐中的推理能力尚未得到充分利用。现有系统通常将自然语言推理视为无监督描述性文本，未能充分发挥其作为学习信号的潜力。", "innovation": "本文主要创新在于提出了PULSE框架，利用小语言模型生成的自然语言推理作为学习信号，结合交互历史共同建模用户行为及其语义驱动因素，这种新颖的设计产生了更稳健且泛化的嵌入。PULSE在多个基准数据集上优于现有ID、协同过滤（CF）及基于LLM的序列推荐模型，并且在跨领域推荐及推理导向的问答任务上表现出优异的可迁移性和性能", "conclusion": "经验表明，PULSE在多个基准数据集上超越了领先的ID、协同过滤（CF）及基于LLM的推荐模型，在跨领域推荐任务中表现出较高的可迁移性，并且在下游任务如推理导向的问答中的性能也十分出色。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08623", "html_url": "https://arxiv.org/abs/2510.08623", "title": "PARSE: 由LLM驱动的用于可靠实体提取的模式优化", "title_en": "PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction", "authors": "Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla", "background": "在新兴的软件3.0系统中，大型语言模型（LLM）代理自主与API和工具交互，结构化的信息从不结构化的文本中提取变得至关重要。现有方法直接使用大型语言模型执行提取任务，通常采用约束解码或强化学习方法来确保句法有效性，但将JSON模式视为静态合同，旨在供人类开发者使用，这导致提取性能不佳、频繁的幻觉以及智能代理行为的不可靠性，特别是在模式包含模糊或不完整的规范时。", "innovation": "PARSE系统有两项协同工作的组件：ARCHITECT自主优化JSON模式以供LLM消费，同时通过集成代码生成系统RELAY保持向后兼容性；SCOPE结合静态和LLM基线的护栏来实现基于反射的提取。该系统在三个数据集中（Schema-Guided Dialogue (SGD)、Structured Web Data Extraction (SWDE) 和内部零售对话数据）进行了定性和定量评估，结果显示，SWDE的提取准确率提高了64.7%，框架综合改进10%，且第一次重试时的提取错误减少了92%。", "conclusion": "PARSE在交易虚拟助手、设置管理系统以及填写表格等任务上实现了显著的性能提升，具体为提取准确率提高64.7%，同时降低了92%的首次重试错误率，且保持了可接受的延迟时间。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08649", "html_url": "https://arxiv.org/abs/2510.08649", "title": "在个人叙述中形式化风格", "title_en": "Formalizing Style in Personal Narratives", "authors": "Gustave Cortal(ENS Paris Saclay, LISN),Alain Finkel(ENS Paris Saclay)", "background": "个人叙事是作者构建的故事，用于赋予他们的经历意义。风格是作者表达自己方式的独特方式，对于传达主观体验至关重要。然而，缺乏一个正式框架来系统分析这些风格选择，研究者仅依赖直观的感觉而不是科学的方法进行分析。特别是在梦的叙述中，强调了这种缺乏方法化分析的问题，并提出需要一种新的方法来系统地分析个人叙述中的风格选择。", "innovation": "本文提出了一种新的方法，将个人叙事中的风格形式化为作者在传达主观体验时所作语言选择的模式。跨学科地结合功能语言学、计算机科学和心理学的观察，自动提取语言特征，如过程、参与者和环境，通过分析成百上千的梦的叙述，特别是对一名患有创伤后应激障碍的退伍军人的案例研究，揭示了语言选择与心理状态之间的关系，突显了这一方法的优势。", "conclusion": "通过对梦的个人叙事进行分析，本文展示了如何利用语言模型自动提取语言特点，并通过功能性语言学、计算机科学和心理学领域的综合应用，揭示了在表达主观体验时语言选择与心理状态之间的关系。这为未来的研究提供了一个系统化的方法论框架，使得对个人叙述中的风格进行更深入的科学分析成为可能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08624", "html_url": "https://arxiv.org/abs/2510.08624", "title": "大型语言模型知道它们正在接受测试吗？GPT-OSS-20B的评估意识和敏感激励下的失败", "title_en": "Do LLMs Know They Are Being Tested? Evaluation Awareness and Incentive-Sensitive Failures in GPT-OSS-20B", "authors": "Nisar Ahmed,Muhammad Imran Zaman,Gulshan Saleem,Ali Hassan", "background": "大语言模型（LLMs）的基准测试通常依赖于需要详细推理和严格格式化的提示，而实际部署则需要简洁、合同约束的答案。本文研究了这种“评估气味”是否在不带来相应能力提升的情况下虚假提升了测量性能。使用单一开源权重模型GPT-OSS-20B，在固定任务内容和解码机制的前提下，进行了六种配对的A/B测试场景，分别考察了评估导向与实际世界、以及中间/高推理深度的影响。研究发现，评估框架确实会增加推理过程中的描述量，并减少直接答案的准确性，但在结构化输出中，这种框架只能改善外壳而不能增强实质性内容。不同的激励措辞重新定义了错误构成，在高推理情景下轻微提高了准确性，减少了自信但错误的答案，但赞颂能力则导致了更简洁但风险更高的输出。乌尔都语提示标签揭示了多语言一致性风险，表明此项研究可以减少高层次推理中的准确性。研究还提供了可重复的A/B框架和实用指导，旨在确保基准测试收益反映可部署的能力。", "innovation": "引入了一种新的实验框架，通过单一开源模型进行多次配对A/B测试，以研究评估导向如何影响大型语言模型的行为。实验设计了六个场景，涵盖了确定性数学、代码修复、引文生成、推理反转（谨慎 vs. 熟练）、推理展现以及多语言（乌尔都语）标题。创新之处在于其验证方法使用了确定性验证器，并提供了预先注册的差异和复合索引。此外，该研究揭示了不同的激励措辞在不同推理深度下对错误构成和输出格式的影响，并提供了实用建议，如中立措辞或双框架检查、合同意识评分、风格差异报告、信心治理和多语言仪表板等，以确保基准测试收益反映可部署能力。", "conclusion": "评估框架可能在不对应提高模型实际能力的情况下虚假提升其测得的性能。结构化输出更适合外壳的改善而不是实质性内容。不同激励措辞影响了错误组成的权重：赞谨慎在高推理情景下轻微提高了准确性，而赞能力则产生了更简洁但风险更高的输出。乌尔都语的提示标签显示了多语言一致性风险。研究提供了可重复的A/B框架、实用指导和多语言仪表板，以确保模型的实际部署能力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08632", "html_url": "https://arxiv.org/abs/2510.08632", "title": "通过层级扩散语言模型进行下一语义尺度预测", "title_en": "Next Semantic Scale Prediction via Hierarchical Diffusion Language Models", "authors": "Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola", "background": "该论文引入了一种新的语言模型类型——层级扩散语言模型（HDLM）。这种模型基于一个分层词汇表，其中低级词汇具有详细的语义，高级词汇具有粗粒度的语义，并且低级词汇被映射到高级词汇。在正向过程中，每个词汇被独立地扰动为具有更抽象语义的祖先词汇，而在逆向过程中，模型逐步预测下一层次的详细语义。论文提出了这种预测过程的闭合表达式，并展示了HDLM可以灵活实现，包括现有的MDLM作为特例。此外，论文还提出了基于这些见解的实用训练技术。", "innovation": "论文提出的HDLM是一种新的离散扩散模型，用于语言建模。其创新之处在于使用分层词汇表，低级词汇映射到高级词汇，正向过程中将详细语义词变换为抽象语义词，逆向过程中则逐步预测更详细的语义。提出了一种预测下一语义尺度的一般过程。此外，还首次推导出扩散证据下界（ELBO）的闭式表达式，并展示了HDLM可以灵活实施并包括现有MDLM作为特例。", "conclusion": "文本生成实验验证了HDLM的有效性，表明HDLM在验证和生成困惑度方面显著优于基线模型。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08702", "html_url": "https://arxiv.org/abs/2510.08702", "title": "代码的扩展定律：更饥渴于数据的领域", "title_en": "Scaling Laws for Code: A More Data-Hungry Regime", "authors": "Xianzhen Luo,Wenzhen Zheng,Qingfu Zhu,Rongyi Zhang,Houyi Li,Siming Huang,YuanTao Fan,Wanxiang Che", "background": "大型语言模型（LLMs）正在革新软件工程。现有的扩展定律主要针对自然语言（NL），但代码与自然语言之间存在根本性的差异，如严格的语法规则。因此，这些扩展定律是否直接适用于代码领域尚不清楚。", "innovation": "本研究首次进行了大规模的实证研究，探索适用于代码的扩展定律。研究涵盖了从0.2B到3.8B的模型规模，以及从2B到128B的训练标记量。研究结果表明，更具表达性的Farseer定律在准确度上更胜一筹。研究还指出，代码模型在模型规模上能够有效地扩展，但与自然语言相比，代码更加依赖于数据量，需要更高比例的数据和参数。", "conclusion": "研究还通过额外进行的代码-自然语言混合实验表明，自然语言在此类限制资源的情况下有好处，但在较高的计算预算下却成了劣势。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08647", "html_url": "https://arxiv.org/abs/2510.08647", "title": "前瞻思维链：一种协同的思维链压缩框架", "title_en": "Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression", "authors": "Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen", "background": "近年来，大型语言模型（LLMs）通过长推理链（CoT）实现了高级推理，但由于生成性LLMs的自回归特性，长CoT会带来高昂的计算成本和显著的延迟损失。CoT压缩旨在通过减少输出长度来提高推理过程的效率。尽管之前的工作提出了通过人工设计离散提示或构建外部压缩CoT数据集来压缩CoT的方案，但这些方法要么效率低下，要么损失关键的推理细节。", "innovation": "本工作提出了一种高效的推理框架——前瞻CoT (UCoT)，它利用前端思考嵌入来自动化CoT压缩。UCoT是一种协作工作流程，涉及到一个小型模型（压缩器）和一个大型模型（执行者）。UCoT首先训练压缩器生成包含丰富推理信息的前端思考嵌入，以避免手动设计提示的缺点。其次，优化执行器利用这些前端思考嵌入进行短推理以得出正确答案，并使用奖励机制进行优化。实验表明，UCoT在保持执行者强大的推理能力的同时，显著减少了CoT的长度。应用到Qwen2.5-7B-Instruct模型的例子进一步证明了其有效性，能够在GSM8K数据集上将token使用量减少50%，同时性能比当前最先进的方法高出3.08%。", "conclusion": "UCoT提供了一种新的CoT压缩策略，能够自动、高效地进行CoT压缩，同时维持模型的推理能力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08630", "html_url": "https://arxiv.org/abs/2510.08630", "title": "ExPO-HM: 学习进行解释-然后检测以检测有害梗", "title_en": "ExPO-HM: Learning to Explain-then-Detect for Hateful Meme Detection", "authors": "Jingbiao Mei,Mingsheng Sun,Jinghong Chen,Pengda Qin,Yuhong Li,Da Chen,Bill Byrne", "background": "有害梗作为网络虐待的一种特别形式，引发了开发自动化检测系统的需求。大多数先前的方法依赖于直接检测，仅提供二元预测，无法提供现实世界中内容审核所需的上下文和解释。尽管最近的解释-然后检测方法使用链式思考提示或LMM代理效果不如简单的SFT基准模型，甚至是先进的GRPO等后训练方法也不能弥补差距。我们分析指出，这样的系统存在两个关键问题：模型无法假设与政策相关的提示如目标和攻击类型作为可能的解释；二元奖励信号无法指导推理。为解决这些挑战，我们提出了一种名为ExPO-HM（解释-然后检测策略优化方法），其灵感来源于人类注释者的训练和评估过程。ExPO-HM结合了SFT预热，GRPO结合递减学习以及条件决策熵（CDE）作为推理质量的度量和奖励。在三个有害梗基准测试中，ExPO-HM在二元检测、细粒度分类和推理质量方面均取得了最佳性能，分别相对于GRPO和DPO基准模型提高了15%和17%的F1分数。通过将有害梗检测从简单的二元警报转变为解释驱动的检测，ExPO-HM提供准确、可解释和可操作的内容审核支持。", "innovation": "提出了一种新颖的方法ExPO-HM，通过SFT预热，GRPO结合递减学习，以及条件决策熵（CDE）作为推理质量和奖励，解决了有害梗检测中模型无法假设重要政策相关线索和二元奖励信号无法指导推理的问题。该方法在多种有害梗基准测试中展现了卓越性能，提升了检测准确性和可解释性，为内容审核提供了有效的支持。", "conclusion": "通过将有害梗检测从简单的二元警报转变为解释驱动的检测，ExPO-HM不仅提高了有害梗检测的准确性和推理质量，还为内容审核提供了准确、可解释和可操作的决策支持。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08666", "html_url": "https://arxiv.org/abs/2510.08666", "title": "dInfer: 一种高效的扩散语言模型推理框架", "title_en": "dInfer: An Efficient Inference Framework for Diffusion Language Models", "authors": "Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng", "background": "基于扩散的大型语言模型（dLLMs）作为自回归（AR）LLMs的有前途的替代方案，通过去噪生成来实现固有的并行性。尽管越来越多开源的dLLM模型出现，但其广泛应用仍受限于缺乏标准化和高效推理框架。因此，亟需一个能够提高效率且不牺牲输出质量的框架。", "innovation": "dInfer 是一个模块化的高效推理框架，它将推理管道分解为四个模块：模型、扩散迭代管理器、解码策略和KV缓存管理器，并结合了每个组件的新算法和系统级优化。通过算法创新和系统增强，dInfer 达到了显著的效率提升，同时保持了输出质量。与以前的系统相比，dInfer 在批处理大小为1的情况下，HumanEval 达到了超过1100个令牌/秒，六项基准测试平均超过800个令牌/秒，同时相比 Fast-dLLM 提供了10倍的加速，即使与 QWen2.5-3B （使用最新 vLLM 推理引擎且高度优化）相比，dInfer 也提供了2-3倍的加速。", "conclusion": "dInfer 是一个开源的高效推理框架，旨在解决扩散语言模型推理中的效率问题。通过其模块化设计和优化，它不仅在性能上有所提升，甚至在与自回归模型的对比中也表现优异。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08720", "html_url": "https://arxiv.org/abs/2510.08720", "title": "从二元矩阵视角评估代码和测试案例的充足性", "title_en": "How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective", "authors": "Xianzhen Luo,Jinyang Huang,Wenzhen Zheng,Qingfu Zhu,Mingzheng Xu,Yiheng Xu,Yuantao Fan,Libo Qin,Wanxiang Che", "background": "自动评估大型语言模型生成的测试案例是一个关键但具有挑战性的任务。现有的基准存在高计算成本、分数膨胀以及倾向于平凡错误而非罕见的关键故障偏向。本文提出两个基本问题：（1）代表整个错误空间所需的最小错误代码集是什么？（2）区分这些函数所需的基本最小测试案例集是什么？文章认为基准构建可以形式化为寻找二进制代码-测试矩阵的理想诊断基。矩阵的秩指定了能够实现故障完全覆盖所需的最小独立错误模式数量。目标是识别一个基大小等于矩阵秩的、最大化内部多样性的集合。实验表明，最先进的测试案例生成方法在TC-Bench上的排除率仅为约60%，揭示其诊断能力的显著差距。", "innovation": "文章介绍了一个框架，将基准构建形式化为在二进制代码-测试矩阵中找到最优诊断基的问题。提出了一个高效的近似算法WrongSelect，用于选择最大化多样性的错误代码。通过将该框架应用于数百万的编程比赛提交，构建了一个紧凑、多样化且抗分数膨胀的基准TC-Bench。通过实验展示了最先进的测试案例生成方法在TC-Bench上的效果。", "conclusion": "该框架、基准及其算法暴露了现有测试案例生成方法在诊断故障方面的能力差距。提供的数据集和代码可用于进一步研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08741", "html_url": "https://arxiv.org/abs/2510.08741", "title": "基于上下文的坐标：使用大语言模型定位复杂地理位置", "title_en": "Coordinates from Context: Using LLMs to Ground Complex Location References", "authors": "Tessa Masis,Brendan O'Connor", "background": "地理编码的任务是将位置参考链接到实际的地理位置，这对于许多未结构化文本的下游分析至关重要。本文研究了地理编码组合位置参考的具有挑战性的场景。鉴于最近研究已证明大语言模型在处理地理空间数据方面的推理能力，本文评估了大语言模型的地理空间知识与其完成任务相关的推理技能。基于这些洞察，本文提出了一种基于大语言模型的策略来地理编码组合位置参考。结果表明，本文的方法提升了任务性能，并且相对较小的微调大语言模型可以达到与更大且现成模型相当的性能。", "innovation": "构建并验证了一种基于大语言模型的策略来处理组合位置参考的地理编码任务。该策略通过优化大语言模型的微调，展示了即使使用较小模型也可以达到与大型现成模型相当的性能的新颖性。", "conclusion": "本文的方法提升了地理编码组合位置参考的任务性能，证明了相对较小的微调大语言模型可以实现与大型现成模型相当的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08710", "html_url": "https://arxiv.org/abs/2510.08710", "title": "思考更长，并不一定更聪明：在层次化法律推理中评估LLM能力", "title_en": "Thinking Longer, Not Always Smarter: Evaluating LLM Capabilities in Hierarchical Legal Reasoning", "authors": "Li Zhang,Matthias Grabmair,Morgan Gray,Kevin Ashley", "background": "案例为基础的推理是美国法律实践的重要基石，需要专业人士通过类比和区分过往先例来争论当前案件。尽管大型语言模型（LLMs）展示出了显著的能力，但在这种复杂、细腻的推理形式上的精通程度仍需进一步探究。因此，我们提出了一种形式化的框架，将其识别案例之间重要差异的过程分解为三个阶段的推理任务。该框架使用称为因素的事实谓词来建模案例，将其组织成一个法律知识层次结构，并定义了验证规则以识别差异、分析其论据支持并评估其重要性。通过全面评估现代推理LLMs，我们揭示了一个悖论：模型在表面推理（任务1）上表现出高精度，但在层次推理（任务2：64.82%-92.09%）中性能下降，在综合分析（任务3：11.46%-33.99%）中则崩溃。最引人注目的是，我们发现模型在错误回答中消耗了更多的计算资源，相比之下在正确回答中消耗较少，暗示“思考更久”并不总是意味着“更聪明”。", "innovation": "我们提出了一种形式化的框架，通过将识别案例之间重要差异的过程分解为三个阶段的推理任务，来建模案例并定义验证规则，以识别差异、分析其论据支持并评估其重要性。这一框架为评估LLM在复杂领域中的推理能力提供了一种细化分析的方法，并揭示了基本限制，这是构建稳健和可信赖的法律AI所必需解决的。", "conclusion": "我们的研究揭示了LLMs在复杂领域进行推理的局限性，表明在理解层次化和集成分析方面存在显著挑战。虽然模型在表面推理上表现良好，但在更深层次的推理和综合分析中表现出显著的性能下降，甚至在错误回答上消耗更多计算资源。这表明，尽管计算资源更多并不总是意味着更有洞察力或更有效的决策。未来的研究应集中在提高LLMs在复杂法律情境中的理解能力和决策质量，以实现真正智能的法律AI。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08776", "html_url": "https://arxiv.org/abs/2510.08776", "title": "测量多语言能力下的道德LLM响应", "title_en": "Measuring Moral LLM Responses in Multilingual Capacities", "authors": "Kimaya Basu,Savi Kolari,Allison Yu", "background": "随着大语言模型（LLM）的使用在国家、语言和地区之间变得普遍，理解和引导其多语言响应的需求变得更加重要。研究人员创建了大规模的测试和基准数据集来评估和促进LLM在多个维度上的响应。本文研究了五个维度上前沿和领先开源模型的响应，以衡量LLM在多语言环境中的准确性和一致性。评估使用五点评分标准和人工评判LLM.", "innovation": "本文首次对多语言环境下的LLM道德响应进行评估，采用五点评分标准和人工评判方法，比较了不同模型在不同维度和语言资源条件下的表现。特别是强调了GPT-5在特定道德维度上的优势及其与其他模型的差异性。此外，研究还揭示了语言环境变化对LLM响应的影响，并提议需要进一步改进相关领域以提高模型的一致性和准确性.", "conclusion": "GPT-5 在各维度上的表现最为优异，而在Consent & Autonomy 和 Harm Prevention & Safety两个维度上的得分最高；Gemini 2.5 Pro 在这两个维度上的得分最低。这些结果突显了需要进一步测试和改进LLM在不同领域的响应准确性及一致性，以便更好地服务于多语言环境下的伦理和社会责任要求."}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08730", "html_url": "https://arxiv.org/abs/2510.08730", "title": "语言模型微型基准测试的可靠性如何？", "title_en": "How Reliable is Language Model Micro-Benchmarking?", "authors": "Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta", "background": "微型基准测试提供了一种解决方案，可以解决语言模型开发中通常因时间、成本而受限制的问题：通过在现有基准的小子集上进行评估。然而，这些微型基准能否像它们取代的全面基准一样一致地对模型进行排名？或者它们能否比随机选取的数据点部分更一致地排名模型？研究表明，在许多情况下，答案是否定的。因此，本文引入了一种针对微型基准测试的元评估度量，以研究微型基准测试是否能根据模型在全面基准测试上的性能差异正确排名模型对，这有助于分析微型基准测试规模与可靠性之间的权衡。", "innovation": "本文提出了一种元评估度量方法，用于评估微型基准测试的质量。这种方法能够确定哪些模型对可以通过微型基准测试正确排序，并提供了一个更加细化地分析微型基准测试规模与可靠性之间权衡的方法。研究数据表明，现有方法难以一致地对一系列性能差异较大的模型对进行排名，往往需要选择250个以上的样本才能可靠地排名较为类似的模型对，这表明随机采样在某些情况下可以与现有的微型基准测试方法竞争。", "conclusion": "本文为微型基准测试的用户和开发者提供了实际指导，帮助他们在评估效率与可靠性之间做出权衡决策，即在微型基准测试时需要多少样本来确保模型排序的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08800", "html_url": "https://arxiv.org/abs/2510.08800", "title": "用多步骤推理视角评估汉语常识推理", "title_en": "Benchmarking Chinese Commonsense Reasoning with a Multi-hop Reasoning Perspective", "authors": "Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang", "background": "尽管大型语言模型（LLMs）展示了高级推理能力，但在一般中文语境中的全面评估仍然不足。为填补这一空白，我们提出了中文常识多步骤推理（CCMOR），这是一种新的基准，旨在评估LLMs在将中文特定事实知识与多步骤逻辑推理结合方面的能力。我们首先从现有问答数据集中构建了一个领域平衡的基础集，然后开发了一个基于LLM的流水线来生成以事实单元链为基础的多步骤问题。为了确保数据集的质量，我们实施了一个有人在环的验证系统，其中领域专家系统地验证和改进生成的问题。", "innovation": "CCMOR是一种新的基准，旨在评估LLMs在结合中文特定事实知识和多步骤逻辑推理方面的能力。我们不仅通过这个新的基准测试了前沿的LLMs，还发现现有的LLMs在处理长尾知识和执行知识密集型推理方面仍然存在局限性。然而，检索增强的生成方法显著减轻了这些知识差距，取得了显著的性能提升。", "conclusion": "CCMOR的评估结果表明，尽管LLMs展现出了高级推理能力，但在处理长尾知识和执行知识密集型推理方面仍有不足。检索增强的生成方法能有效缓解这些知识差距，提高模型性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08798", "html_url": "https://arxiv.org/abs/2510.08798", "title": "学习记忆：面向高效语言模型的自适应概率性记忆保存", "title_en": "Learning What to Remember: Adaptive Probabilistic Memory Retention for Memory-Efficient Language Models", "authors": "S M Rafiuddin,Muntaha Nujat Khan", "background": "当前的Transformer模型使用注意力机制，但该机制的时间复杂度与序列长度成二次方关系（O(n^2)），这限制了模型处理长上下文的能力。因此，对于需要处理长文档的任务，模型内存消耗大且计算效率低，影响了模型的性能和应用范围。", "innovation": "提出了一种自适应记忆保存机制——Adaptive Retention（自适应保留）。该机制是一个分层的、概率性的 token 选择方法，通过严格的全球预算 M 来决定保留哪些表示。机制中使用了带有硬-混凝土/变分松弛的伯努利门控进行训练，并在推理时通过简单的Top-M规则来控制保留数量，实现了可微分且可直接应用于标准编解码器的方法。该方法不修改基础注意力机制或任务头，为处理长上下文的记忆效率提供了架构无关的解决方案。实验结果表明，保留约30-50％的 token 能保持至少95％的完整模型性能，同时降低了大约35-45％的峰值内存使用，吞吐量提高了约1.8倍。", "conclusion": "该研究提供了一种自适应的概率性记忆保存方法，能够高效处理长上下文数据，且不会改变现有的编码器结构。该方法具有效率高、实用性强的特点，能够在多种任务中达到与全量模型类似的效果，同时降低计算资源的消耗和提高处理速度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08804", "html_url": "https://arxiv.org/abs/2510.08804", "title": "MOSAIC：具有任务智能的多代理协调科学编程", "title_en": "MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding", "authors": "Siddeshwar Raghavan,Tanwi Mallick", "background": "科学工作流需要严格的算法，这些算法需要深厚的专业知识并包含领域内特定的推理。科学代码的生成还需要处理子问题序列以生成最终结果，这对于现有的一般编程框架提出了挑战。因此，需要一种特殊的框架来应对这些挑战，能够自省、制定策略、编码和调试，以便有效解决复杂的科学任务逻辑错误心理路径和任务分割的子问题链。", "innovation": "MOSAIC 是一种无需训练的多智能体框架，能够自我反思、创建理由、编程和调试。它通过学生-导师范式解决科学代码生成的挑战，并利用 Consolidated Context Window (CCW) 来缓解 LLM 在解决涉及多步骤子问题的复杂科学任务时的幻觉问题。研究表明，MOSAIC 在准确度、鲁棒性和可解释性方面优于现有方法。", "conclusion": "MOSAIC 框架在科学研究代码生成方面表现出了色的性能，能够有效处理复杂的科学任务。它在子问题解决的每个步骤中表现出了改进，并且能够结合各种技术（如 CCW）来提高性能，为科学研究代码的生成提供了新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08813", "html_url": "https://arxiv.org/abs/2510.08813", "title": "语言模型的语言类型是关键：大规模语言模型在隐私泄露中的语言对比分析", "title_en": "The Model's Language Matters: A Comparative Privacy Analysis of LLMs", "authors": "Abhishek K. Mishra,Antoine Boutet,Lucas Magnana", "background": "大规模语言模型（LLMs）现在被广泛应用于处理敏感数据的多语言应用中，但其规模和语言多样性带来了重大的隐私风险。大多数关于隐私泄露的研究主要针对英语进行了评估。本文旨在研究语言结构如何影响LLMs在不同语言中的隐私泄露情况，这些语言包括英语、西班牙语、法语和意大利语，并特别关注医学语料库的训练数据。", "innovation": "本文量化了六种语言指标，并评估了三个攻击向量：提取、反事实记忆和成员推理。结果显示，隐私漏洞的规模随着语言冗余度和分词粒度而增加：意大利语展示出最强的泄露性，而英语则表现出较高的成员身份可辨别性。相反，法语和西班牙语由于其更高的形态复杂性而显示出更大的抗风险能力。整体来看，本研究提供的实证证据表明，语言在隐私泄露中起重要作用，强调了在LLM部署中采用语言感知的隐私保护机制的重要性。", "conclusion": "本文发现语言对隐私泄露影响显著，提出了语言意识的隐私保护机制对于大规模语言模型部署的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08663", "html_url": "https://arxiv.org/abs/2510.08663", "title": "利用LLM评分文本数据增强评分量表测试的新型框架", "title_en": "A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data", "authors": "Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell", "background": "传统的心理评估依赖于结构化的评分量表，但无法捕捉受访者自然语言中的丰富细微变化。这项研究利用了最新的大型语言模型（LLM）进展，在新的概念框架下融合了LLM评分文本和传统的量表项目，创建了一个增强的测试工具。通过将抑郁症状作为案例研究，该研究在693名高中学生的真实数据和3,000个相应的合成数据集上开发并评估了这个框架。在独立测试集上的表现显示出统计上显著的测量精度和准确性提升。", "innovation": "该研究提出了利用大型语言模型评分文本数据来增强传统评分量表测试的新型框架。它跳过了自动评分的常见瓶颈，通过计算项目信息量，基于实证选择最信息丰富的大型语言模型评分指令，而不是依赖预标注数据或复杂的专家设计评估标准。这种方法能够利用增加的转录文本流来增强传统心理学测量工具，并且其在临床健康及其他领域的应用潜力巨大。", "conclusion": "该框架为利用不断增长的转录文本数据提升传统心理评估提供了可扩展的方法。实验结果表明，利用大型语言模型评分的文本信息等同于在原始的19项测试中增加了6.3至16.0项新项目。这种方法标志着自动化评分领域的一个概念性转变，为未来的心理评估提供了新的视角和可能性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08859", "html_url": "https://arxiv.org/abs/2510.08859", "title": "结构增强的多轮监狱突破：利用大型语言模型的结构漏洞", "title_en": "Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models", "authors": "Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma", "background": "大型语言模型（LLMs）仍然容易受到多轮监狱突破攻击的影响，这些攻击利用对话的上下文逐步绕过安全限制。这些攻击针对不同的危害类别（如恶意软件生成、骚扰或欺诈）采用不同的对话方法（教育讨论、个人经历、假设场景）。现有的多轮监狱突破方法通常依赖于启发式或手工探索策略，缺乏对模型内部弱点的深入理解。不同对话模式与不同类型危害之间模型漏洞的关系尚不明确。", "innovation": "本文提出了结构增强的多轮攻击链（PE-CoA），这是一种框架，通过自然对话构建有效的多轮监狱突破，使用五种对话模式。在对涵盖十个危害类别的十二种LLM进行评估时，该方法达到了目前的最佳性能，揭示了特定模式的漏洞和LLM的行为特征：模型显示了不同的弱点谱型，对一种对话模式的鲁棒性不能推广到其他模式，类似模型的家庭共享相似的失败模式。这表明安全训练的局限性，并指示需要模式感知的防御。", "conclusion": "这些发现强调了安全训练的局限性，并表明需要模式感知的防御。代码可在以下地址获取：this https URL"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08870", "html_url": "https://arxiv.org/abs/2510.08870", "title": "文档级翻译中的质量估计重排序", "title_en": "Quality Estimation Reranking for Document-Level Translation", "authors": "Krzysztof Mrozinski,Minji Kang,Ahmed Khota,Vincent Michael Sutanto,Giovanni Gatti De Giacomo", "background": "质量估计（QE）重排序是一种质量感知解码形式，旨在通过评分和从生成的翻译池中选择最佳候选者来提高机器翻译（MT）。尽管在句子级别上已被证明有效，但其在日益重要的文档级别翻译领域中的应用仍被忽视。", "innovation": "本研究使用各种学习得到的和基于大型语言模型（LLM）的质量估计度量标准，评估了QE重排序在文档级别翻译上的性能。研究发现，使用最优的学习指标SLIDE，当有两个候选者时，BLEURT-20得分提高了2.00，有32名候选者时提高了5.09，这适用于解码器仅LLM模型和编码器-解码器神经机器翻译（NMT）模型。使用最好的LLM指标GEMBA-DA，在相同条件下，获得的收益分别为1.63和4.30。虽然随着输入长度的增加，收益会缩小，但在最长的文档上，使用32个候选者的重排序仍可提高SLIDE的2.34个点，GEMBA-DA的1.40个点。这些发现表明，文档级别的QE具有实际价值，且在适当的翻译模型和硬件条件下，运行时间的开销很小。", "conclusion": "本研究证明了文档级别QE的实际价值，并展示了适当的翻译模型和硬件条件下较低的运行时间开销。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08825", "html_url": "https://arxiv.org/abs/2510.08825", "title": "搜索于图：知识图谱上大型语言模型推理的迭代自适应导航", "title_en": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "authors": "Jia Ao Sun,Hao Yu,Fabrizio Gotti,Fengran Mo,Yihong Wu,Yuchen Hui,Jian-Yun Nie", "background": "大型语言模型（LLMs）虽然展示了令人印象深刻的推理能力，但在处理知识密集型的多跳问题时仍然不可靠，容易遗漏稀有事实、在不确定时胡言乱语，并且其内部知识滞后的程度超过了真实世界的变化。知识图谱（KGs）提供了一个结构化的关联证据来源，但现有的KGQA方法面临着根本性的权衡：在不知道可用关系的情况下制定完整的SPARQL查询证明脆弱，检索大规模子图引入了噪声，复杂的智能体框架通过并行探索指数级扩展搜索空间。以上的这些限制成为了研究的背景。", "innovation": "本文提出了搜索于图（SoG）框架，这是一种简单而有效的框架，使得LLMs能够使用一个精心设计的Search函数执行迭代有信息的图导航。SoG基于“观察然后导航”的原则：每一步，LLMs都会检查当前实体实际可用的关系，然后再决定下一步应该跳转到哪里。这种方法能够无缝适应不同的KG模式，并通过自适应过滤来处理高度节点。该框架在六个涉及Freebase和Wikidata的KGQA基准测试中，无需微调便获得了最佳性能，尤其在Wikidata基准测试中取得了显著的进步，对之前的最佳方法提高了16%。", "conclusion": "SoG框架在六个KGQA基准测试中达到了最新的性能水平，特别是在Wikidata基准测试中的表现尤为突出，提升了16%，同时在Freebase基准测试中也有一些稳定的改进。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08902", "html_url": "https://arxiv.org/abs/2510.08902", "title": "基于大型语言模型的统一生物医学命名实体识别框架", "title_en": "A Unified Biomedical Named Entity Recognition Framework with Large Language Models", "authors": "Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin", "background": "生物医学领域的命名实体识别对于医学信息提取和知识发现至关重要。然而，现有方法往往难以处理嵌套实体、实体边界模糊以及跨语言泛化问题。", "innovation": "提出了一个基于大型语言模型（LLMs）的一体化生物医学命名实体识别（BioNER）框架。该框架首先将BioNER重新描述为一个文本生成任务，并设计了一种符号标签策略，以联合处理扁和平面嵌套实体，并进行显式边界标注。此外，引入了一种基于对比学习的实体选择器，通过利用边界敏感的正负样本筛选错误或虚假预测。", "conclusion": "在四个基准数据集和两个未见语料库上进行的实验结果表明，该方法在语言上实现了最先进的性能和稳健的零样本泛化。源代码已免费提供。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08892", "html_url": "https://arxiv.org/abs/2510.08892", "title": "在RLVR中探索不同温度策略的令牌级和采样级控制", "title_en": "Exploring Multi-Temperature Strategies for Token- and Rollout-Level Control in RLVR", "authors": "Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang", "background": "强化学习已经在大型语言模型（LLMs）的推理能力提升方面取得了显著的进展，其表现适用于多个领域。近期研究指出，LLMs中的令牌在推理任务中扮演不同的角色，主要分为高熵推理令牌和低熵知识令牌。过往的方法大多着眼于间接地通过限制更新来鼓励探索，但它们没有在令牌生成阶段显式地促进探索性行为。本文介绍了在采样过程中显式地通过为不同类型的令牌应用不同的温度设置来促进探索的新方法。具体而言，本方法使用更高的温度值对待推理令牌积极地鼓励探索，而保留较低的温度值以保持常识正确性。除此之外，文中还系统地研究了多种不同的温度调度策略，并探讨了其在强化学习环境中的影响。", "innovation": "本文提出了一种新的方法，即通过为推理令牌和知识令牌应用不同的温度设置来在采样过程中显式地促进探索性行为，从而为强化学习下的大型语言模型推理能力提升提供了一种新的途径。此外，本文还系统地探讨了各种多温度调度策略及其对强化学习效果的影响。", "conclusion": "实验结果表明，本文提出的方法显著提高了大型语言模型的推理性能。相关代码已公开。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08886", "html_url": "https://arxiv.org/abs/2510.08886", "title": "FinAuditing: 一种针对评估大语言模型的金融税收结构化多文档基准", "title_en": "FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs", "authors": "Yan Wang,Keyi Wang,Shanshan Yang,Jaisal Patel,Jeff Zhao,Fengran Mo,Xueqing Peng,Lingfei Qian,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Jian-Yun Nie", "background": "一般公认的会计原则（GAAP）的复杂性和XBRL财务报表的层级结构使得财务审计日益难以自动化和验证。尽管大规模语言模型（LLMs）展示了在处理非结构化文本上的强大能力，但在对结构化、相互依赖和基于分类法的财务文档进行逻辑推理方面的能力仍需进一步探索。该背景说明了当前技术存在的挑战和不足，为进一步研究提供了背景信息。", "innovation": "提出了FinAuditing，这是第一个符合税收分类法、具备结构感知能力的多文档基准，用于评估大语言模型在财务审计任务上的表现。该基准从实际的US-GAAP合规XBRL文件构建，定义了三个互补的子任务：FinSM（语义一致性）、FinRE（关系一致性）和FinMR（数值一致性），每个任务都针对结构化审计推理的一个特定方面。此外，提出了一个统一的评估框架，集合了检索、分类和推理的指标。实验证明，当前模型在语义、关系和数学维度上表现不一致，推理多文档结构时，准确率下降高达60-90%。这些发现揭示了现代LLMs在基于分类法的财务逻辑推理上的系统性局限，并确立了FinAuditing作为开发可信赖、结构感知和合规的财务智能系统的基础。", "conclusion": "FinAuditing作为发展可信、结构感知和合规的财务智能系统的基石，揭示了现代大语言模型在基于分类法的财务推理方面的系统性局限。基准数据集可在Hugging Face上获取。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08907", "html_url": "https://arxiv.org/abs/2510.08907", "title": "无需自动编码的基于上下文语义锚点的大语言模型上下文压缩", "title_en": "Autoencoding-Free Context Compression for LLMs via Contextual Semantic Anchors", "authors": "Xin Liu,RunSong Zhao,PengCheng Huang,XinYu Liu,JunYi Xiao,ChunYang Xiao,Tong Xiao,Shengxiang Gao,Zhengtao Yu,JingBo Zhu", "background": "上下文压缩为通过压缩长语境到紧凑表示以加速大型语言模型（LLM）推理提供了一种有前景的方法。现有的上下文压缩方法主要依赖自动编码任务来训练通用的压缩标记，以便压缩语境语义。然而，自动编码任务导致压缩标记为重建而优化，这与实际下游任务相分歧，从而使更适用于实际使用的特征变得更加薄弱。", "innovation": "提出了语义锚点压缩（SAC），这是一种全新的方法，从基于自动编码任务的压缩转向一种本身就具备该压缩能力的架构。SAC 直接从原始语境中选择所谓的锚标记，并将其上下文信息聚合到其键值（KV）表示中。通过直接从上下文标记中提取表示，SAC 消除了自动编码训练的需要，并通过两种关键设计确保压缩性能：（1）锚嵌入，使压缩器能够识别关键标记；（2）双向注意力修改，使锚标记能够捕获整个语境的信息。", "conclusion": "实验结果显示，SAC 在各种压缩比下始终优于现有的上下文压缩方法。在 MRQA 的离分布评估中，SAC 在 5 倍压缩的情况下相比强大的基线模型实现了 1 EM 的改进，随着压缩比的增加，SAC 的优势也越来越大。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08915", "html_url": "https://arxiv.org/abs/2510.08915", "title": "人造印象：通过特质印象评估大规模语言模型行为", "title_en": "Artificial Impressions: Evaluating Large Language Model Behavior Through the Lens of Trait Impressions", "authors": "Nicholas Deas,Kathleen McKeown", "background": "本文探讨了语言模型内部表示中的人工印象，即基于语言形成的类似人类的刻板印象和印象。研究使用了一种基于二维刻板印象内容模型（SCM）的线性探针来预测这些印象，以此评估语言模型行为，并研究提示特征对模型输出的影响。研究表明，人工智能语言模型在接收到特定提示时表现出的印象不一致，但隐藏表示中的印象却具有更强的线性可解码性。此外，这种人工印象还会影响模型响应的质量和修饰语言的使用。本文还研究了提示中的特定内容、风格和方言特征对语言模型印象的影响。", "innovation": "本文创新性地提出了‘人工印象’的概念，通过使用线性探针来预测语言模型如何根据二维刻板印象内容模型（SCM）来生成印象，并研究这些印象如何影响模型的行为和输出质量。另外，本文还探讨了提示中的特定特征如何影响语言模型的印象，揭示了语言模型如何处理和解释人类刻板印象及印象的过程机制。", "conclusion": "本文证明，虽然人工智能语言模型在接收到特定提示时所表现出的印象不一致，但隐藏表示的线性可解码性却能够更精确地预测这些印象。同时，表现出人工印象的语言模型更倾向于使用修饰性的语言来降低不确定性。此外，特定的内容、风格和方言特征在提示中会对模型的印象产生显著影响。因此，进一步理解这些深层次的因素可以帮助优化语言模型的性能和适配性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08942", "html_url": "https://arxiv.org/abs/2510.08942", "title": "SOP-Maze：在复杂商业标准操作程序上评估大型语言模型", "title_en": "SOP-Maze: Evaluating Large Language Models on Complicated Business Standard Operating Procedures", "authors": "Jiaming Wang,Zhe Tang,Yilin Jin,Peng Ding,Xiaoyu Li,Xuezhi Cao", "background": "随着大型语言模型（LLMs）在特定领域被广泛部署，已经提出了许多基准来评估其在真实世界场景中遵循指令和做出决策的能力。然而，商业场景通常涉及复杂的标准操作程序（SOPs），而对LLM在这些情况下能力的评估尚未完全探讨。为了弥合这一差距，我们提出了一种名为SOP-Maze的基准，它基于真实世界的商业数据构建，并转化为涵盖23个复杂SOP场景的397个任务集合。我们进一步将SOP任务分为两类：横向根系系统（LRS），代表需要精确选择的宽选项任务；和心脏根系系统（HRS），强调复杂的逻辑推理分支。", "innovation": "我们提出了SOP-Maze基准，这是第一个针对复杂SOP场景构建的基准。它包括397个来自23个复杂SOP场景的任务。此外，我们将SOP任务分为两类：横向根系系统（LRS）和心脏根系系统（HRS），并进行了广泛实验。实验结果显示，几乎所有最新的模型在SOP-Maze上都难以应对。我们还根据对模型的全面分析，发现三个关键错误类别：路径盲视，逻辑处理脆弱性和计算错误。", "conclusion": "本研究系统地探讨了LLM在SOP任务中的表现，这些任务挑战了模型的广度和深度，为提高模型能力提供了新的见解。我们可以在此开源我们的工作：这个 https URL。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08956", "html_url": "https://arxiv.org/abs/2510.08956", "title": "集体软件项目中的基于人类行为的治理基准", "title_en": "A Human Behavioral Baseline for Collective Governance in Software Projects", "authors": "Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey", "background": "本文研究了开源社区如何通过版本控制的治理文件来描述参与和控制。作者分析了710个配有时间点快照的数据集，解析并分类文本为参与者、规则、行动和对象，并测量这些元素随时间的变化情况。研究表明，项目随时间的推进，定义了更多角色和行动，这些角色和行动的分配更为平衡，而规则的构成基本保持稳定。这些发现表明，治理通过扩展和平衡参与的类别而增长，而不涉及对控制集中度的主要变化。研究旨在提供一个新的基准，用以评估未来由AI介导的工作流程是否会导致权力集中或重新分配。", "innovation": "本文采用解析文本并分类为参与者、规则、行动和对象的方法，并结合熵、丰富度和Jensen Shannon散度进行测量，提供了一种新的方法来分析开源项目中的集体治理变化。该研究同时为未来由AI介导的治理机制提供了参考基准。", "conclusion": "集体软件项目中的治理随时间扩展和平衡了参与者的角色和行动，但规则本身的变化不大。这些发现表明，治理的潜在变化主要体现在更广泛的参与和更平衡的治理方面，而非根本性的规则更改。这样的分析提供了评估未来AI介导治理机制的一个可复制的基准。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09004", "html_url": "https://arxiv.org/abs/2510.09004", "title": "解耦安全到正交子空间：大型语言模型的成本效益和性能保持对齐", "title_en": "Decoupling Safety into Orthogonal Subspace: Cost-Efficient and Performance-Preserving Alignment for Large Language Models", "authors": "Yutao Mou,Xiaoling Zhou,Yuxiao Luo,Shikun Zhang,Wei Ye", "background": "构建可信赖的人工智能需要确保安全性，然而在不降低通用性能的情况下增强模型安全仍然是一个挑战。当前方法需要昂贵的计算搜索来确定安全关键性和通用性数据的最佳比例，这导致成本高且收益有限。", "innovation": "本文展示了基于LoRA的拒绝训练能够仅通过在安全数据上训练就保持性能的同时实现安全对齐。这表明LoRA可以作为成本效益、性能保持且易于插拔的安全补丁。我们除了提供实证研究，还通过理论和实验证明了LoRA有效地将安全分解到与模型内在转换空间几乎正交的低秩子空间中，从而确保安全增强不会干扰固有能力。", "conclusion": "通过基于LoRA的拒绝训练，可以实现安全和性能的对齐，而无需在数据搜索上消耗过多成本，确保安全增强不会影响模型的基础功能，从而使大型语言模型的安全和性能得到有效的提升和保护。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08986", "html_url": "https://arxiv.org/abs/2510.08986", "title": "Chinese Adaptive Policy Communication Corpus", "title_en": "Creation of the Chinese Adaptive Policy Communication Corpus", "authors": "Bolun Sun,Charles Chang,Yuen Yuen Ang,Pingxu Hao,Ruotong Mu,Yuchen Xu,Zhengxin Zhang", "background": "该论文背景涉及分析和理解中国政府发布的政策指令中的清晰与模糊语言。此前没有一个开放的数据集能够提供针对中文政策指令的五色分类学标注，该分类学基于Ang的适应性政策沟通理论，适用于从1949年至2023年期间中国中央政府发布的所有法律法规和部门规章。", "innovation": "这篇论文的创新之处在于推出了第一个标注了清晰与模糊语言五色分类标记的公开中文政策指令数据集——CAPC-CG，基于Ang的理论提供了适应性政策沟通的数据支持。具体创新包括：数据集的时间跨度长（1949-2023），包括多个政策层级文件；数据集的文档分段并标注为330万单位；采用了两轮标注体系和专家以及经过训练的编码者的金标准注释集；使用Fleiss’s kappa验证了96%的注释者间一致性，确保监督模型的可靠性；与多个大型语言模型一起提供基准分类结果，并公开注释代码本，描述数据集的模式，支持政策沟通下游任务和多语言NLP研究。", "conclusion": "该数据集的发布旨在支持政策沟通的下游任务和多语言自然语言处理研究。除数据集本身外，统一的标签代码本、注释框架以及专家和受训编码者的标注结果可用于提高监督模型的精度和可靠性，分析政策沟通模式，增强跨语言和文化背景下政策信息传递的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08988", "html_url": "https://arxiv.org/abs/2510.08988", "title": "MASA：由大语言模型驱动的多智能体系统用于自动形式化", "title_en": "MASA: LLM-Driven Multi-Agent Systems for Autoformalization", "authors": "Lan Zhang,Marco Valentino,André Freitas", "background": "自然语言与形式化推理之间的连接至关重要。当前的研究致力于开发多智能体系统，这些系统能够基于大型语言模型（LLMs）进行自动形式化。MASA框架旨在通过协作型智能体将自然语言陈述转换为形式化的表示，其架构强调模块化、灵活性和可扩展性，以便无缝集成新的智能体和工具以适应快速发展的领域。研究通过实际数学定义和正式数学数据集的用例和实验，展示了MASA的有效性。", "innovation": "MASA框架利用大型语言模型（LLMs）推动的多智能体系统，旨在将自然语言陈述转换为形式化表示。其架构设计强调模块化、灵活性和可扩展性，便于无缝集成新的智能体和工具，适应快速变化的应用领域。通过实际案例和正式数学数据集的实验展示其有效性和潜力，去推动利用LLMs和定理证明器的多智能体系统在自动形式化领域的应用。", "conclusion": "MASA框架支持由多智能体系统驱动的自动形式化，表明这种系统在提高自动形式化效率和可靠性方面的潜力。这对于研究人员和实践者来说，提供了宝贵的经验和指导。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09001", "html_url": "https://arxiv.org/abs/2510.09001", "title": "DARO: 难度感知重加权策略优化", "title_en": "DARO: Difficulty-Aware Reweighting Policy Optimization", "authors": "Jingyu Zhou,Lu Ma,Hao Liang,Chengyu Shen,Bin Cui,Wentao Zhang", "background": "近期，大规模语言模型（LLMs）的进展表明，通过验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards, RLVR）可以显著提升其推理能力。组相对策略优化（Group Relative Policy Optimization, GRPO）已成为RLVR的默认方法，并激发出了许多变体。然而，通过对这些方法进行数学分析，发现它们本质上都是GRPO的不同加权版本。现有的方法依赖于固定的或过于简单的加权方案，这些方案与样本难度紧密相关，这限制了模型适应其不断变化的能力。结果导致了一个重大损失尺度问题，即训练更多地集中在某些难度级别上，而忽视了其他级别，从而影响了整体性能。", "innovation": "本文提出了一种名为难度感知重加权策略优化（Difficulty-Aware Reweighting Policy Optimization, DARO）的新方法。DARO可以根据模型的学习状态动态调整每个难度组损失贡献的比例，解决了现有的方法存在的根本问题。广泛实验证明，DARO在Qwen2.5-Math-1.5B、Qwen2.5-Math-7B和Llama3.1-8B上的表现优于四种主要基准算法，在六个数学基准上实现了更快的收敛速度和更强的最终性能。", "conclusion": "DARO通过对不同难度级别的损失贡献进行动态调整，解决了现有方法在损失尺度上的不足，能够更好地适应模型不断变化的能力，从而提升了整体性能和更快的收敛速度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09030", "html_url": "https://arxiv.org/abs/2510.09030", "title": "通过反思与修正自动优化语言模型作文评分规则", "title_en": "Automated Refinement of Essay Scoring Rubrics for Language Models via Reflect-and-Revise", "authors": "Keno Harada,Lui Yoshida,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo", "background": "大语言模型（LLMs）的表现对其所给的提示高度敏感。受提示优化领域的启发，该研究探讨了如何通过完善评分标准来提升自动化作文评分（Automated Essay Scoring, AES）模型的效果。具体而言，研究提出了一种通过模型自我反思其评分逻辑和与人类评分中的差异，从而迭代优化评分标准的方法。实验使用GPT-4.1、Gemini-2.5-Pro和Qwen-3-Next-80B-A3B-Instruct模型在TOEFL11和ASAP数据集上进行，显示了评分改进显著结果。", "innovation": "研究提出了一种通过自我反思和迭代优化评分标准的方法来提高LLMs在AES中的表现。这种方法能够在简单的初始评分标准基础上实现与详尽的人类评分标准相匹敌或更好的性能，从而突显了在LLM驱动的AES中迭代优化评分标准的重要性。", "conclusion": "研究表明，通过迭代优化评分标准，LLMs在AES中的表现可以与详尽的人类评分标准相媲美，甚至更好，强调了在基于LLM的AES中逐步改进评分标准的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09014", "html_url": "https://arxiv.org/abs/2510.09014", "title": "LitE-SQL：基于向量模式链接和执行指导自纠正的轻量高效文本到SQL框架", "title_en": "LitE-SQL: A Lightweight and Efficient Text-to-SQL Framework with Vector-based Schema Linking and Execution-Guided Self-Correction", "authors": "Shengmin Piao,Jieun Lee,Sanghyun Park", "background": "文本到SQL任务将自然语言问题转换为SQL查询，使非专家能够直观地与数据库交互。虽然近期使用大型语言模型（LLMs）的方法在性能上表现出色，但依赖于专有模型可能带来部署可行性和数据隐私方面的问题。", "innovation": "提出了LitE-SQL，一种轻量且高效的框架，包含两个组件：(i)模式检索器，使用预计算的模式嵌入向量数据库进行高效模式连接，(ii)SQL生成器，经过两阶段微调——监督微调后，通过执行指导自纠正，无需生成多个候选答案来降低成本。LitE-SQL在BIRD数据集上的执行准确率为72.10%，在Spider 1.0数据集上达到88.45%，参数量仅为LLM基线方法的2倍至30倍，显示出与LLM基线相当或更优的表现。研究结果证明，高质量文本到SQL生成可以通过轻量模型实现，为隐私敏感和资源受限环境提供了一种可行的解决方案。", "conclusion": "通过轻量模型实现高质量的文本到SQL生成是可行的，LitE-SQL框架在处理这样问题时相较于LLM基线方法不仅展现了相当或更优的性能，且在参数量上得到了显著降低，从而为资源受限和对数据隐私要求高的场景提供了一种新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09033", "html_url": "https://arxiv.org/abs/2510.09033", "title": "大型语言模型并不真正知道它们不知道的内容", "title_en": "Large Language Models Do NOT Really Know What They Don't Know", "authors": "Chi Seng Cheang,Hou Pong Chan,Wenxuan Zhang,Yang Deng", "background": "最近的研究表明，大型语言模型（LLMs）在其内部表示中（如潜状态、注意力权重或标记概率）编码了事实性信号，这暗示这些模型可以“知道它们不知道的内容”。然而，这些模型也可能通过依赖捷径或虚假关联产生事实上的错误。这些错误是由于相同的训练目标驱动的，鼓励正确的预测。这引发了一个问题：内部计算能否可靠地区分事实性和虚构的输出？", "innovation": "本文通过对两种类型的幻觉（基于对主题信息的依赖程度）的机制分析来研究LLMs如何处理事实查询。发现，当幻觉与主题知识相关时，LLMs使用与正确答案相同的内部回忆过程，导致重叠且难以区分的潜状态几何排列。相反，与主题知识无关的幻觉产生可区分且聚类的表示，使其可被检测到。这些发现揭示了一个根本性限制：LLMs在其内部状态中并不编码真实性，而是只编码知识回忆的模式，表明“LLMs并不真正知道它们不知道的内容”。", "conclusion": "研究揭示，LLMs在其内部状态中仅编码知识回忆的模式，而不是真实性，表明“LLMs并不真正知道它们不知道的内容”。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09032", "html_url": "https://arxiv.org/abs/2510.09032", "title": "通过基于转写的语言掩模调整进行跨语言知识迁移探索对于极度低资源的查克拉马语言", "title_en": "Exploring Cross-Lingual Knowledge Transfer via Transliteration-Based MLM Fine-Tuning for Critically Low-resource Chakma Language", "authors": "Adity Khisa,Nusrat Jahan Lia,Tasnim Mahfuz Nafis,Zarif Masud,Tanzir Pial,Shebuti Rayana,Ahmedul Kabir", "background": "查克拉马是一种印度-雅利安语言，但因其可用数据有限而不易集成到语言模型中。该研究旨在通过建立一个用孟加拉语转写且本地验证的查克拉马语语料库，增强查克拉马语言的处理能力，并在掩蔽语言建模任务上微调多语言和区域变体的变压器模型，以验证该方法的有效性。", "innovation": "研究引入了一个基于孟加拉语转写且经本地居民验证的查克拉马语语料库，并在六种预训练的多语言和区域变体的变压器模型上进行了微调，发现微调后的多语言模型在转写为孟加拉语的查克拉马语方面优于预训练模型，准确率可达73.54%，困惑度低至2.90。此外，研究还揭示了数据质量对模型性能的影响，并指出了光学字符识别（OCR）管道在处理形态丰富的印度型脚本时的局限性。该研究展示了转写为孟加拉语的查克拉马语对于查克拉马语言迁移学习的有效性，并提供了手动验证的数据集以促进低资源语言的多语言建模研究。", "conclusion": "查克拉马语可以通过转写方法有效地用于迁移学习，在转向查克拉马语时微调后的多语言模型表现出色。研究还显示了数据质量对模型性能的重要性，并提出了未来研究的方向，以促进低资源语言多语言语言建模的发展。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09062", "html_url": "https://arxiv.org/abs/2510.09062", "title": "ReFIne: 一种以可靠性、忠实度和可解释性为信任依据的大规模推理模型框架", "title_en": "ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability", "authors": "Chung-En Sun,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng", "background": "近期长链推理（CoT）的研究主要集中在答案的准确性与词元效率上，而忽视了信任性关键因素。研究者认为，有效的推理系统必须具备信任性，具体表现在可解释性、忠实度和可靠性三个方面。", "innovation": "提出了一种名为ReFIne的新训练框架，整合了监督微调与GRPO来促进模型：（i）通过产生易于人类追踪的结构化、标签化轨迹来提高可解释性；（ii）通过明确显示每解决方案的关键信息来增强忠实度；（iii）提供推理过程的正确性和最终答案的信心估计来促进可靠性。该框架在Qwen3模型上进行了多重规模的应用并评估了不同难度的数学基准，结果表明：ReFIne模型生成了更清晰和结构化的推理轨迹（可解释性+44.0%）、更忠实于其决策过程（忠实度+18.8%）、提供了更具有信息性的信心估计（可靠性+42.4%）", "conclusion": "这些结果表明一个长期被忽视但重要的方向：推理模型不应仅优化准确性，同时还需要优化信任性的更广泛维度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09051", "html_url": "https://arxiv.org/abs/2510.09051", "title": "Alif：通过多语言合成数据蒸馏推进乌尔都语大型语言模型", "title_en": "Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation", "authors": "Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq", "background": "低资源语言如乌尔都语开发高性能大型语言模型（LLMs）面临诸多挑战，包括高质量数据稀缺、多语言不一致性以及安全问题。现有方法通常通过大量翻译资源数据来应对这些问题，但翻译质量不高且缺乏文化精细度，同时还会产生显著的数据管理和训练成本。为了克服这些挑战，本文提出了Alif-1.0-8B-Instruct模型，该模型使用了一种多语言合成乌尔都-英语数据集（Urdu-Instruct）进行训练，该数据集通过修改后的自指令技术开发，确保了语言的本土思维链推理、双语翻译、文化相关性和伦理安全对齐。", "innovation": "本文的创新点在于采用了一种修改后的自指令技术，使用多语言合成数据集（Urdu-Instruct）来训练多语言乌尔都-英语模型Alif-1.0-8B-Instruct。这种方法通过使用独特的提示和为每个任务设置种子值，并结合全局任务池，保证了本土化的思维链推理、双语翻译、文化相关性和伦理安全对齐。Alif-1.0-8B-Instruct模型在训练预算低于100美元的情况下，优于包括Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct和Cohere-Aya-Expanse-8B在内的主要多语言LLMs，显示出在乌尔都语特定任务上表现更优的性能。", "conclusion": "研究结果表明，高效且文化对齐的高性能低资源语言LLMs可以通过我们的修改后的自指令方法进行有效开发。所有数据集、模型和代码都已公开，可通过提供的链接访问。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09116", "html_url": "https://arxiv.org/abs/2510.09116", "title": "DITING：基准评估网络小说翻译的多代理评估框架", "title_en": "DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation", "authors": "Enze Zhang,Jiaying Wang,Mengxi Xiao,Jifei Liu,Ziyan Kuang,Rui Dong,Youzhong Dong,Sophia Ananiadou,Min Peng,Qianqian Xie", "background": "大型语言模型（LLMs）在机器翻译方面取得了显著进展，但在网络小说翻译方面的有效性尚不清楚。现有基准依赖于表面级别的评估指标，无法捕捉这一文体的独特特点。为解决这些问题，本文提出了DITING，一个全面的网络小说翻译评估框架，评估叙事和文化忠实度的六个维度：成语翻译、词汇歧义、术语本地化、时态一致性、零代词解决和文化安全性，通过超过18,000个专家标注的中英句子对来支持。", "innovation": "提出了AgentEval，一种推理驱动的多代理评估框架，模拟专家讨论以评估翻译质量，超越了词汇重叠，实现了与七个测试自动评估指标中人类判断的最大相关性。此外，开发了MetricAlign，一个包含300个句子对的元评估数据集，每个句子对都标注了错误标签和质量评分标度。这些创新使得能够进行全面的模型评价。", "conclusion": "全面评估14个开放、封闭和商业模型显示，中国训练的LLMs超越了更大规模的外国模型，DeepSeek-V3提供了最忠实且风格最一致的翻译。这项工作为探索基于LLM的网络小说翻译建立了新的范式，并提供了公共资源以促进未来研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09106", "html_url": "https://arxiv.org/abs/2510.09106", "title": "当检索成功与失败：重新思考LLMs中的检索增强生成", "title_en": "When Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented Generation for LLMs", "authors": "Yongjie Wang,Yue Yu,Kaisong Song,Jun Lin,Zhiqi Shen", "background": "大语言模型（LLMs）通过其强大的语言理解和生成能力实现了广泛的应用。然而，由于LLMs是基于静态数据集进行训练的，因此它们在处理快速变化的信息或特定领域的查询时存在困难。为解决这一问题，检索增强生成（RAG）框架应运而生，通过将LLMs与外部检索机制结合，使LLMs能够访问最新和上下文相关的信息。随着LLMs自身的规模和能力不断提升，传统RAG框架的优势逐渐减弱。因此，本文从RAG的总体目标和核心组件入手，分析了RAG的关键挑战，并指出这些挑战可能限制RAG的有效性。最后，作者展示了在LLMs单独使用时效果不佳，但在结合RAG后再利用LLMs时能够显著提升效果的应用场景。希望能激发研究人员重新考虑RAG的作用，推动下一代RAG系统的开发.", "innovation": "本文综合回顾了RAG，探讨了RAG的关键挑战，展示了RAG和LLM结合的有效应用，并期望激发研究者重新评估RAG的作用及推动下一代RAG系统的发展.", "conclusion": "本文通过全面回顾RAG，展示了其在提升LLMs效果中的潜力，并对RAG的研究和下一代RAG系统的开发提出了展望."}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09158", "html_url": "https://arxiv.org/abs/2510.09158", "title": "通过对话添加口头思考陈述来通过LLM建模个体人格特征", "title_en": "Augmenting Dialog with Think-Aloud Utterances for Modeling Individual Personality Traits by LLM", "authors": "Seiya Ishikura,Hiroaki Yamada,Tatsuya Hiraoka,Hiroaki Yamada,Takenobu Tokunaga", "background": "研究表明，利用大五人格理论框架，可以更好地理解人类个体的性格特质。传统的对话数据可能不足以捕捉到说话者的具体性格特征，特别是对于LLM（大语言模型）的训练。本研究提出了使用口头思考陈述（TAUs）来增强对话数据，以更好地模仿说话者的人格特质。", "innovation": "论文创新地提出使用TAUs来增强对话数据，旨在通过训练LLM来更好地建模个体性格特征。实验结果显示，使用TAU增强的数据训练的LLM在模仿说话者的大五人格模型中的宜人性和神经质方面比使用原始对话数据训练的LLM更准确。", "conclusion": "研究结果表明，TAU增强的数据对建模LLM的性格特征特别有效，特别是在模仿说话者的宜人性和神经质方面。同时，TAU的质量也显著影响LLM的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09184", "html_url": "https://arxiv.org/abs/2510.09184", "title": "通过推理和聚合构建更强的再识别攻击", "title_en": "Stronger Re-identification Attacks through Reasoning and Aggregation", "authors": "Lucas Georges Gabriel Charpentier,Pierre Lison", "background": "文本脱敏技术常用于掩盖文档中的个人可识别信息（PII），然而衡量这些技术隐藏提及人员身份的能力较为困难。最近的研究表明，可以通过逆向的再识别过程来评估脱敏方法的鲁棒性，基于自动化攻击者利用背景知识来揭开已被掩盖的PII。", "innovation": "本文提出了两种增强再识别攻击的方法。首先证明了PII跨度的再识别顺序是有区别的，通过在不同顺序中聚合预测结果可以提高再识别性能。同时发现推理模型在假设攻击者拥有大量背景知识的情况下，可以显著提升再识别性能。", "conclusion": "本文的主要结论是通过顺序聚合和推理模型的应用，可以构建更强的再识别攻击，从而更加精确地评估文本脱敏方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09097", "html_url": "https://arxiv.org/abs/2510.09097", "title": "FrameEOL: 使用因果语言模型的语义框架归纳", "title_en": "FrameEOL: Semantic Frame Induction using Causal Language Models", "authors": "Chihiro Yano,Kosuke Yamada,Hayato Tsukagoshi,Ryohei Sasano,Koichi Takeda", "background": "语义框架归纳是将引发框架的词汇根据它们引发的语义框架进行聚类的任务。近年来，利用诸如BERT等掩码语言模型（MLM）获得的框架引发词汇嵌入，使得语义框架归纳性能优异。然而，诸如GPT和Llama系列的因果语言模型（CLM）在广泛的语言理解任务中表现出色，能在对话中仿佛理解框架，但尚未应用于语义框架归纳。现有的方法主要依赖MLM，且在资源匮乏的语言如日语上表现欠佳，需要深度微调。因此，提出一种基于CLM的新方法，以填补这一领域空白，并提高在资源稀缺语言上的性能。", "innovation": "提出了一种基于因果语言模型的新方法，命名为FrameEOL。具体而言，该方法通过引入基于prompt的框架嵌入获取方法，输出一个代表给定情况的框架名称。通过利用上下文学习（ICL）和深度度量学习（DML），增强了框架嵌入更适合框架归纳的需求。最终通过聚类这些嵌入进行框架归纳。实验结果表明，该方法在英语和日语框架网上优于现有方法，特别是对于缺乏框架资源的日语，仅使用5个上下文学习示例的CLM方法就达到了与使用DML微调的MLM方法类似的性能。", "conclusion": "提出的基于因果语言模型的方法在语义框架归纳上取得了显著成效。该方法不仅能有效应用于多种语言环境，还能提高在资源稀缺语言上的性能，显示了基于CLM的框架归纳方法在文本理解和应用中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09211", "html_url": "https://arxiv.org/abs/2510.09211", "title": "DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction", "title_en": "DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction", "authors": "Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang", "background": "在执行具有用户特定要求的任务时，例如严格的输出格式，大型语言模型（LLMs）经常会优先考虑推理而非严格遵守细致的指令。通过监督的微调来解决这一问题因高计算成本和参数访问限制而变得不切实际。为了应对这一挑战，提出了一种名为DICE的轻量级框架，通过小型语言模型（SLMs）引导LLMs生成合适数组结构的输出。", "innovation": "DICE框架首先通过两阶段方法构建结构化的CoT适应数据集，然后使用双微调策略对SLMs进行微调，以生成遵循结构化输出规范的回答。它通过分解过程，先让LLMs生成自然语言响应，然后使用训练好的SLMs分析和改进这些响应，同时确保输出符合用户需求。实验表明，DICE能够将LLMs的输出格式正确性和内容准确性分别提高35.4%和29.4%，达到最先进的技术水平。", "conclusion": "DICE框架通过使用小型语言模型来修正推理链的结构，既保留了LLMs的广泛知识和推理能力，又确保了输出符合用户需求。与竞争性基线相比，DICE展示了显著的改进效果，证实了它的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09189", "html_url": "https://arxiv.org/abs/2510.09189", "title": "LLaMAX2: 你的翻译增强模型在推理解析任务中也表现出色", "title_en": "LLaMAX2: Your Translation-Enhanced Model also Performs Well in Reasoning", "authors": "Changjiang Gao,Zixian Huang,Jingyang Gong,Shujian Huang,Lei Li,Fei Yuan", "background": "通用大型语言模型（LLMs）在推理方面表现出色，但经过翻译增强的模型在推理任务上却表现不佳。这个问题引起了研究者们的注意，因为语言模型在不同任务上的表现需要综合考虑，尤其是在多种语言环境下的应用中，需要平衡翻译和推理能力的发展。这项研究旨在解决这一问题，提出了一个创新的翻译增强方案，利用指令模型进行层选择性微调，并专注于并行数据。这种方法在低资源语言翻译性能上显著提升，并且在多种因素和推理数据集上表现出较好的平衡能力。这使得翻译增强语言模型在更广泛的语言环境中具有更好的适用性，提高了可访问性和复杂度的降低。", "innovation": "提出了一种新的翻译增强方案，该方案使用指令模型进行层选择性微调，专注于并行数据，显著提升了低资源语言的翻译性能（如斯瓦希里语，达到了15+ spBLEU和40+ xComet）；同时，仅使用小型并行数据集，这种模型在7个多语言任务上平均提升了1+点，且在15个多推理数据集保持与Qwen3指令模型相当的性能。", "conclusion": "这项工作提供了一种有希望的多语言增强方法，大大降低了复杂性并且增强了不同语言的可用性，使得增强后的语言模型在更广泛的语境下表现出更佳的性能。该代码和模型已公开提供。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09217", "html_url": "https://arxiv.org/abs/2510.09217", "title": "IRIS：在无表格数据情况下可验证因果发现的迭代集成框架", "title_en": "IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data", "authors": "Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari", "background": "因果发现是科学研究的基础，但传统统计算法面临着数据收集昂贵、对已知关系的冗余计算以及不切实际的假设等挑战。虽然基于大规模语言模型（LLM）的方法在识别已知因果关系方面表现出色，却无法发现新颖的因果关系。", "innovation": "IRIS 是一种新颖的框架，解决了这些局限性。它通过迭代检索和集成系统从初始变量开始，自动收集相关文档，提取变量并发现因果关系。IRIS 的混合因果发现方法结合了统计算法和基于 LLM 的方法，能够发现已知和新颖的因果关系。此外，IRIS 的缺失变量提案组件可以识别并引入缺失变量，以扩展因果图。这种方法允许仅从初始变量开始进行实时因果发现，无需预先存在的数据集。", "conclusion": "IRIS 是一种迭代集成框架，可以在无表格数据的情况下实现验证的因果发现，通过结合统计算法和基于 LLM 的方法，能够发现已知和新颖的因果关系，同时也能够在扩展的因果图中识别并插入缺失的变量。这种方法为从少量初始变量开始的实时因果发现提供了可能，无需依赖于大型预先构建的数据集。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09255", "html_url": "https://arxiv.org/abs/2510.09255", "title": "DSPO: 稳定且高效的策略优化以实现主动搜索和推理", "title_en": "DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning", "authors": "Chenyang Gu,Yewen Pu,Bruce Yang,Xiaofan Li,Huan Gao", "background": "增强语言模型（LLMs）具备主动搜索外部知识的能力对于复杂和现实世界任务至关重要。当前的方法要么依赖提示来激发模型固有的智能特性，要么在应用强化学习（RL）到复杂的交互任务时性能受限或崩溃，无法充分发挥其真正代理潜力。", "innovation": "本文介绍了一种改进的RL算法——动态过滤序列级别策略优化（DSPO），该算法通过序列级别优化和动态样本过滤，增强了代理训练的鲁棒性。通过纯强化学习训练实现多轮搜索和推理的交织，避免了监督示例数据的需求。", "conclusion": "在多个QA基准测试中，通过DSPO训练的7B模型比之前的可比工作提高34.1%，在复杂多跳问答（如HotpotQA）中甚至比14B模型高出接近9%的相对优势，保持了卓越的训练稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09243", "html_url": "https://arxiv.org/abs/2510.09243", "title": "CrisiText：紧急通信中LLM训练的数据集", "title_en": "CrisiText: A dataset of warning messages for LLM training in emergency communication", "authors": "Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini", "background": "在危机情况下，有效识别威胁并减轻其潜在损害至关重要，以保护受威胁个体。尽管AI在辅助人类应对紧急情况方面发挥了作用，但自然 disasters和暴力攻击等危机情况的应急响应中，自然语言处理（NLP）技术的应用仍然有限，主要集中在分类任务上。然而，使用自然语言生成（NLG）架构及时生成警告信息的巨大潜力尚未得到充分关注。因此，急需开发大规模的危机情景下警告信息生成的数据集，以提高危机应对能力。", "innovation": "本文介绍了一个名为CrisiText的首个大规模警告信息生成数据集，涵盖13种不同的危机情景，包含超过400,000条警告信息，旨在辅助平民在危机前后进行应对。该数据集的生成过程中，从现有危机描述开始，构建了与情景相关的事件链，并将每个事件与一个警告信息配对，确保了语境准确性和事实性。此外，每个警告信息还伴有三种次优版本，便于研究不同的NLG方法。通过一系列实验证明了不同训练方法的效果，并考察了模型在陌生环境下的表现及自动化后编辑的有效性。", "conclusion": "CrisiText数据集是首个在危机情景下用于警告信息生成的大规模数据集，有效地支持了人工智能在危机应对中的应用，通过不同训练方法的比较研究了自然语言生成的有效性，并评估了模型在未知场景下的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09278", "html_url": "https://arxiv.org/abs/2510.09278", "title": "CLARity: 仅通过一致性可以训练强化专家", "title_en": "CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts", "authors": "Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng", "background": "在数据稀缺的领域训练专家型大型语言模型（LLM）是困难的，通常依赖于填空选择题（MCQs）。然而，基于标准结果导向的强化学习（RL）在MCQs上是具有风险的。虽然这种方法可能提高准确性，但往往会降低推理质量，如逻辑一致性。目前监督推理的解决方案，如大规模过程奖励模型（PRMs），成本高昂。因此，需要一种低成本的方法来提高推理质量。", "innovation": "本文提出了CLARity，这是一种低成本的RL框架，仅使用一个小而通用的LLM便可以提高推理质量。CLARity结合了一致性意识的奖励机制和二阶段的‘先优化后监控’训练流程来增强推理一致性，并通过动态数据重新制定策略来更好地利用有限的数据。实验结果表明，CLARity相比基准模型提高了16.5%的响应一致性以及7.5%的准确性，并且进一步的人类评估也证实了整体一致性和专业性的提升。", "conclusion": "CLARity提供了一个通用的解决方案，使较小的模型能够有效指导专家模型进行推理。该研究的代码已开源。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09259", "html_url": "https://arxiv.org/abs/2510.09259", "title": "检测大型语言模型强化学习后训练阶段的数据污染", "title_en": "Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models", "authors": "Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li", "background": "大型语言模型（LLMs）的可靠评估受到数据污染的严重威胁，这可能会导致基准样本意外出现在训练集中，从而损害报告的性能的有效性。现有的检测方法主要针对预训练和监督微调阶段，但在强化学习（RL）后训练阶段，这一问题的检测方法研究仍然存在显著的空白。尽管RL在提高LLMs推理能力方面变得越来越重要，但缺乏针对其数据污染的专门检测方法是一个关键的安全隐患。", "innovation": "本文首次系统地研究了强化学习后训练阶段的数据检测，并提出了一种名为Self-Critique的方法。Self-Critique方法基于观察：在RL阶段之后，LLM的输出熵分布倾向于压缩成高度特定和稀疏的模式。该方法探测基础策略崩溃，即模型收敛到狭窄的推理路径，导致熵的降低。此外，本文还引入了RL-MIA基准，用于模拟特定的数据污染场景。", "conclusion": "实验证明，Self-Critique方法在多种模型和污染任务上显著优于基线方法，AUC改善高达30%。相比之下，现有的方法在RL阶段的数据污染检测方面几乎等于随机猜测，而我们的方法使检测成为可能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09275", "html_url": "https://arxiv.org/abs/2510.09275", "title": "膨胀的卓越还是真正的表现？通过动态评估重新思考医学诊断基准", "title_en": "Inflated Excellence or True Performance? Rethinking Medical Diagnostic Benchmarks with Dynamic Evaluation", "authors": "Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu", "background": "医学诊断是一个关乎关键患者护理的高度关键和复杂领域。然而，当前对大型语言模型（LLMs）的评估与真实临床实践根本上是不一致的。大多数评估依赖于静态基准，这些基准来自于公开的医学考试题目，这通常高估了模型的性能，并忽视了教科书病例与现实世界中含糊且多变情况之间的差异。最近的动态评估尝试提出了一个有前景的替代方法，但其改进仅限于表面的变化并且专注于准确性。鉴于这种现状，需要提出一个新的动态基准来反映真实的临床实践。", "innovation": "我们提出了DyReMe，一个能够更好地反映实际临床实践的动态基准。它通过生成新鲜的、类似咨询的真实病例，引入了可能的误诊和鉴别诊断让题目多样化，模拟了多种真实世界的查询习惯。DyReMe对LLMs的评估还包括额外的三个临床相关维度：真实性、帮助性和一致性。实验证明，这种方法可以提供更具有挑战性和实践性的评估，揭示了最先进的LLMs与实际临床实践之间的重要偏差。", "conclusion": "这些发现强调了需要新的评估框架来更好地反映可信医学诊断的需求。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09266", "html_url": "https://arxiv.org/abs/2510.09266", "title": "CFVBench: 一个全面的视频基准用于细粒度多模态检索增强生成", "title_en": "CFVBench: A Comprehensive Video Benchmark for Fine-grained Multimodal Retrieval-Augmented Generation", "authors": "Kaiwen Wei,Xiao Liu,Jie Zhang,Zijian Wang,Ruida Liu,Yuming Yang,Xin Xiao,Xiao Sun,Haoyang Zeng,Changzai Pan,Yidan Zhang,Jiang Zhong,Peijin Wang,Yingchao Feng", "background": "当前的Multimodal Retrieval-Augmented Generation (MRAG)能够使Multimodal Large Language Models (MLLMs)生成包含外部多模态证据的响应。现有的多媒体基准主要集中在单一或有限的模态任务上，且在模态覆盖和格式多样性方面存在局限性，往往集中在粗粒度的场景理解上。CFVBench旨在解决上述问题，通过构建一个包含599个公开视频的数据集，生成5,360对开放性问答对，涵盖高密度格式和诸如图表丰富的报告、新闻广播和软件教程等多领域，模型需要在长时间的视频跨度中进行检索和推理，同时保持详细的多模态信息。", "innovation": "CFVBench是一个大规模的手动验证基准，涵盖了多样的视频格式和内容，填补了现有基准在模态覆盖和格式多样性方面的局限。通过CFVBench，系统地评估了7种检索方法和14种广泛使用的MLLMs，揭示了细粒度的多模态细节捕捉是现有模型的一个关键瓶颈。为此，提出了一种简单的但有效的框架——Adaptive Visual Refinement (AVR)，该框架可以适应地增加帧采样的密度，并在必要时调用外部工具。", "conclusion": "实验表明，AVR能够持续增强细粒度多模态理解，并在所有评估的MLLMs中提高性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09295", "html_url": "https://arxiv.org/abs/2510.09295", "title": "MaP: 统一框架用于LLM预训练动态的可靠评估", "title_en": "MaP: A Unified Framework for Reliable Evaluation of Pre-training Dynamics", "authors": "Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou", "background": "可靠的评估是大型语言模型（LLMs）发展的重要基础，但在预训练过程中，评估过程受到显著的不稳定性影响，这掩盖了真实的学习动态。", "innovation": "引入了MaP（合并和P@k评分的双重框架），同时针对训练随机性和噪声测量协议，通过合并检查点和P@k评分来减少噪声，从而提供更平滑的性能曲线，降低不同运行之间的差异，并确保模型排名的一致性。", "conclusion": "MaP 为观察LLM训练动态提供了一个更为可靠和真实的视角，为LLM研究奠定了重要的实证基础。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09293", "html_url": "https://arxiv.org/abs/2510.09293", "title": "一句两嵌入：对比学习显式和隐式语义表示", "title_en": "One Sentence, Two Embeddings: Contrastive Learning of Explicit and Implicit Semantic Representations", "authors": "Kohei Oda,Po-Min Chuang,Kiyoaki Shirai,Natthawut Kertkeidkachorn", "background": "句子嵌入方法虽有显著进步，但在捕捉句子中的隐式语义方面仍存在挑战。这是由于传统句子嵌入方法仅为每个句子分配一个单一向量，导致难以获取句子的全部语义信息。DualCSE通过为每个句子分配两个嵌入来克服这一局限，第一个嵌入表示显式语义，第二个嵌入表示隐式语义，这两个嵌入在共享空间中共存，提升了特定应用如信息检索与文本分类的性能。", "innovation": "提出了DualCSE，一种新颖的句子嵌入方法。它为每个句子分配了两个嵌入：一个表示显式语义，另一个表示隐式语义。这两个嵌入在共享空间中共存，使得可以根据具体需求选择合适的语义进行特定任务的操作，如信息检索和文本分类。实验结果表明，DualCSE能够有效编码显式和隐式语义，提高下游任务的性能。", "conclusion": "DualCSE通过为每个句子分配两个嵌入来提升句子语义表示的质量，使得句子嵌入方法在捕捉隐式语义方面表现出更优异的效果，从而提高了诸如信息检索和文本分类等下游任务的表现。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09309", "html_url": "https://arxiv.org/abs/2510.09309", "title": "掩码标记作为先知：面向高效dLLM推理的细粒度缓存淘汰", "title_en": "Mask Tokens as Prophet: Fine-Grained Cache Eviction for Efficient dLLM Inference", "authors": "Jianuo Huang,Yaojie Zhang,Yicun Yang,Benhao Huang,Biqing Qi,Dongrui Liu,Linfeng Zhang", "background": "扩散大型语言模型（dLLMs）因并行解码能力而呈现出替代主流自回归模型（ARMs）的可能性，但这一能力带来了巨大的计算和内存成本。dLLMs中的缓存机制要求大量内存容量，使其难以在资源受限的环境中处理长上下文。现有的缓存淘汰策略是为ARMs设计的，并未考虑到dLLMs的独特特征，从而导致性能不佳。", "innovation": "引入了MaskKV，这是一种无需训练的缓存淘汰框架，专为dLLMs设计。MaskKV包含两项创新：1）一种基于掩码查询的评分机制，利用注意力权重来识别并淘汰每个头的非关键提示标记；2）一种自适应缓存预算策略，通过减少中间层的分配，集中资源在偏好提示的头中，提高效率。在LLaDA中使用MaskKV压缩KV缓存为仅256对（不到5%的标记），在LongBench上保留了94%的全缓存性能，并在32k提示长度时实现了最多31倍的加速效果。", "conclusion": "掩码标记作为先知框架的有效性在LLaDA上得到了验证，通过压缩KV缓存但仍能保持高性能，显著提升了dLLM推理的效率。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09332", "html_url": "https://arxiv.org/abs/2510.09332", "title": "FLRC：用于高效大语言模型推理的细粒度低秩压缩器", "title_en": "FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference", "authors": "Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu", "background": "尽管大语言模型在性能上取得了显著的成就，但它们庞大的参数量限制了其在资源受限硬件上的部署。低秩压缩可以在减少内存使用和计算需求的同时进行，但如果在整个层级上使用统一的压缩比率，会导致性能显著下降。在此之前，相关方法在解码过程中表现不佳。", "innovation": "本文提出了细粒度低秩压缩器（FLRC），该方法可以为每一层高效地确定最优的秩分配，并结合渐进低秩解码来保持文本生成的质量。全面的实验表明，FLRC在总结任务上的ROUGE-L得分较最先进的低秩压缩方法提高了高达17%，建立了一个更加稳健和高效的框架来提高大语言模型推理。", "conclusion": "FLRC在多种基准测试上展示了优越性，通过优化每层的秩分配并结合渐进低秩解码，FLRC在总结任务中实现了高达17%的ROUGE-L得分改善，并建立了更稳健和高效的框架来提高大语言模型的推理性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09297", "html_url": "https://arxiv.org/abs/2510.09297", "title": "ShiZhi: 一种用于刑事裁判观点生成的中文轻量级大型语言模型", "title_en": "ShiZhi: A Chinese Lightweight Large Language Model for Court View Generation", "authors": "Zhitian Hou,Kun Zeng", "background": "刑事法院观点（CVG）是法律人工智能中的基本任务，旨在自动生成法律案例文件中的“法院观点”部分。生成法院观点具有挑战性，因为案件事实多样且复杂，直接从原始事实生成可能会限制性能。现有解决方案面临由于数据不充分或模型能力不足而导致的法律准确性问题和生成质量不佳的问题。因此，需要一种专门设计用于生成刑事裁判观点的大型语言模型，以解决这些挑战并提高生成的合理性和法律一致性。", "innovation": "本文提出ShiZhi，这是第一个专门设计用于法院观点生成的大规模语言模型（LLM）。我们构建了一个包含超过110,000个案例的中文刑事裁判观点生成数据集CCVG，每个案例包含事实描述和相应的法院观点配对。实验结果表明，即使使用小型语言模型，当使用高质量的领域特定数据训练时，也能生成合理的且符合法律观点的法院观点。ShiZhi在法院观点生成上的BLEU-1得分为58.5，在罪名预测上的准确率和宏F1值分别为86.1%和92.5%。我们的模型和数据集在 ˵https://链接。˵", "conclusion": "实验结果表明，即使是小型语言模型，也可以在高质量的领域特定数据的训练下生成合理且符合法律内容的刑事裁判观点。ShiZhi模型和数据集现已公开，可以促进法律人工智能领域的发展和研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09312", "html_url": "https://arxiv.org/abs/2510.09312", "title": "通过其计算图验证链式思维推理", "title_en": "Verifying Chain-of-Thought Reasoning via Its Computational Graph", "authors": "Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda", "background": "当前的链式思维（CoT）验证方法基于模型输出（黑盒）或激活（灰盒）预测推理的正确性，但不能很好地解释计算失败的原因。本文介绍了一种白盒方法：基于电路的推理验证（CRV）。该方法假设正确的CoT步骤（作为模型潜在推理电路的执行痕迹）和错误步骤的属性图具有不同的结构指纹。通过训练分类器来识别这些图的结构特征，表明这些痕迹包含了推理错误的强烈信号。这种方法提供了一些以往方法无法获得的科学洞察。主要包括：（1）结构错误签名具有很高的预测性，验证了可以通过计算图直接验证推理的可行性；（2）这些签名具有高度的领域特异性，揭示了不同推理任务中的错误以独特的方式表现；（3）这些信号不仅是关联的，通过指导对个体转换器特征进行有针对性的干预成功地纠正了模型的错误推理。这项工作表明，通过审视模型的计算过程，我们可以从简单的错误检测转向更深层次的因果理解。", "innovation": "提出了一种基于电路的推理验证方法（CRV），该方法通过训练分类器来识别属性图中的结构特征，揭示了推理错误的信号，并提供了以往方法无法获得的科学洞察。包括错误签名的高度预测性、领域特异性以及因果理解的增强。这种白盒方法提供了新的科学见解，有效地纠正了模型的错误推理，表明可以通过计算图直接验证推理的可行性。", "conclusion": "通过验证模型的计算过程，从简单的错误检测发展到了更深层次的因果理解，为链式思维推理的验证提供了新的方法和科学视角，展示了白盒方法在揭示推理错误原因方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09359", "html_url": "https://arxiv.org/abs/2510.09359", "title": "理解领域微调对LSTM的影响", "title_en": "Understanding the Effects of Domain Finetuning on LLMs", "authors": "Eshaan Tanwar,Deepak Nathani,William Yang Wang,Tanmoy Chakraborty", "background": "大型语言模型（LLMs）在特定领域微调后表现出色，但其微调如何重塑参数空间的机制尚不明确。以往研究主要关注自回归或通用指令模型，而针对领域的专门化LLMs则研究较少。本文首次系统研究了大型医学语言模型领域的微调。研究表明，微调仅改变代表子空间中的一个小部分，基本上保留了预训练模型的表示。", "innovation": "提出了‘调谐向量’这一新框架，这是一种基于任务向量的新型体系结构，明确捕获由微调引起的参数方向变化。该向量对于增强指令遵循和生成质量至关重要。跨不同领域的调谐向量组合可提高泛化能力。研究表明，这些向量主要在模型的MLP层中写入新方向信息，同时放大注意力头中原有的方向。", "conclusion": "我们的研究成果为LLM适应提供了新的见解，并提供了一般且可解释的框架，用以分析大型语言模型的专业化程度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09351", "html_url": "https://arxiv.org/abs/2510.09351", "title": "ReTraceQA: 小型语言模型常识问答推理过程评估", "title_en": "ReTraceQA: Evaluating Reasoning Traces of Small Language Models in Commonsense Question Answering", "authors": "Francesco Maria Molfese,Luca Moroni,Ciro Porcaro,Simone Conia,Roberto Navigli", "background": "小型语言模型(SLMs)在常识推理基准测试中的性能日益提高，但当前的评估实践主要关注最终答案的准确性，忽视了推理过程的有效性。已有的研究揭示，在很多情况下，SLMs虽然给出了正确的最终答案，但其推理过程却可能存在问题，这表明现有的评估标准可能高估了SLMs的能力。因此，迫切需要一个能够评估推理过程的新型基准，以便更全面地评价模型的能力.", "innovation": "提出了一种名为ReTraceQA的新基准，用于评估小型语言模型在常识推理任务中的推理过程。通过对比使用强大语言模型（LLMs）进行推理意识评估和仅基于最终答案的评估效果，证明了仅基于最终答案的评估方法不足以准确评估SLMs的真实能力，增加了一个新的维度来更全面地评估模型.", "conclusion": "研究发现，当使用具有推理意识的评估标准（由大语言模型作为自动裁判）时，小型语言模型的性能明显下降，尤其是在不同模型和数据集上，最终答案的准确率平均下降了25%，这说明推理过程的有效性是评估模型的一个重要指标，有必要引入此类新方法来更全面地评估模型的性能."}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09354", "html_url": "https://arxiv.org/abs/2510.09354", "title": "通过概率值算术提取无需训练的长链推理能力", "title_en": "Logit Arithmetic Elicits Long Reasoning Capabilities Without Training", "authors": "Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang", "background": "大型推理模型在链式逻辑推理方面表现出色，可以进行回溯和自我修正等策略。然而，近期研究表明，这些能力通常需要额外的训练。因此，研究人员希望探索在无需额外训练的情况下，能否激发这些行为。本文提出了一个名为ThinkLogit的解码时间方法，利用小规模推理模型作为引导者，调整大规模非推理模型以进行长复杂推理。", "innovation": "研究提出了一种名为ThinkLogit的解码时间方法，这种方法通过使用小规模推理模型对较大的非推理模型进行调优，从而实现无训练长推理。此外，还提出了一种名为ThinkLogit-DPO的方法，通过优化正确和错误的推理对来进一步提升性能，其中这些推理对来自目标和引导模型。实验表明，这种方法在五个推理基准测试中，使用Qwen2.5-32B模型被R1-Distill-Qwen-1.5B（一个模型大小小21倍的模型）引导时，平均准确率分别提升了24.5%和29.1%。此外，该方法在引导者和目标来自不同模型系列时仍然有效，且与小型模型的后训练方法兼容。", "conclusion": "本文证明了在无需额外训练的情况下，通过小规模推理模型引导大规模非推理模型的方法可以显著提升其长链推理能力，且此方法对于不同类型模型的组合也适用，为在大规模模型中解锁长推理提供了实际可行的途径，无需昂贵的后训练成本。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09347", "html_url": "https://arxiv.org/abs/2510.09347", "title": "LLP: 基于大型语言模型的电子商务中商品定价", "title_en": "LLP: LLM-based Product Pricing in E-commerce", "authors": "Hairu Wang,Sheng You,Qiheng Zhang,Xike Xie,Shuguang Han,Yuchen Wu,Fei Huang,Jufeng Chen", "background": "不同于传统的面向消费者的电子商务平台（例如亚马逊），在消费者对消费者的平台上（例如eBay），不经验的个人卖家往往难以高效地设定二手商品的价格。因此，为了自动化这一过程，已经提出了许多价格预测的研究，但是大多数方法基于静态回归模型，面临泛化能力不足和无法捕捉市场动态（例如，二手iPhone的价格会随时间下降）的问题。本文在大型语言模型（LLMs）取得突破的基础上，介绍了一种基于LLMs的生成框架LLP，旨在解决这一问题。该框架首先检索类似产品以更好地适应市场动态变化，随后利用LLMs对自由形式文本中的关键定价信息的理解来生成准确的价格建议。", "innovation": "该论文的最大创新点在于提出了一个基于LLMs的生成框架LLP，用于二手商品定价。该框架通过检索类似产品并利用LLMs的理解能力来生成准确的价格建议，同时引入了一种双阶段优化方法（监督微调和组相对策略优化）来增强LLMs在提取产品信息方面的领域推理能力。此外，该方法还采用了基于置信度的过滤机制来拒绝不可靠的价格建议。实验结果表明，LLP在泛化能力方面显著优于现有方法，在Xianyu电子商务平台上也表现得更为出色，尤其是在产品覆盖率为90%时仍然保持了47%的静态采用率。", "conclusion": "本文研究提出了一种基于大型语言模型的自动生成二手商品价格的框架LLP，能够更好地适应市场动态变化，同时通过严格的优化步骤增强了在提取关键信息方面的能力，最终在实验中取得了显著的性能提升，尤其在实际应用中表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09369", "html_url": "https://arxiv.org/abs/2510.09369", "title": "基于马尔可夫概率链接组级奖励与标记级聚合的标记级策略优化", "title_en": "Token-Level Policy Optimization: Linking Group-Level Rewards to Token-Level Aggregation via Markov Likelihood", "authors": "Xingyu Lin,Yilin Wen,En Wang,Du Su,Wenbin Liu,Chenfu Bao,Zhonghou Lv", "background": "现有Group Relative Policy Optimization (GRPO)及相关基于熵正则化的方法在大型语言模型（LLMs）的数学推理能力提升上取得了进步，但仍然面临由链式思考（CoT）固有的稀疏标记奖励带来的挑战。当前方法通常依赖于未区分的标记级熵调整，这通常导致熵崩溃或模型崩溃。", "innovation": "本文提出了TEPO，一种基于标记级框架，通过标记级聚合将马尔可夫概率链接组级奖励的方法。实验结果表明TEPO在关键指标上（包括@k准确率和准确率）始终优于现有基线，不仅在数学推理任务中确立了新的基准水平，而且显著增强了训练稳定性。", "conclusion": "TEPO通过使用标记级框架和马尔可夫概率链接组级奖励与标记级聚合，解决了现有方法中的熵崩溃和模型崩溃问题，显著提升了大型语言模型的数学推理能力和训练稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09390", "html_url": "https://arxiv.org/abs/2510.09390", "title": "识别并交互式细化含糊用户目标以生成数据可视化代码", "title_en": "Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation", "authors": "Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani", "background": "在人类与人工智能的交流中，建立共同目标是基础性步骤，但语言的含糊性可能导致生成的结果看似正确却未能反映说话者的意图。在数据可视化领域，自然语言中的这种含糊性影响着生成代码的过程。研究可以通过多视角分析来探索不同类型的含糊性及其对代码生成的影响。", "innovation": "本文创新地开发了一种含糊性分类方法，并提出了量化这些类型的含糊性的度量标准。使用来自DS-1000数据集的Matplotlib问题进行示例说明，结果表明，本研究所提出的含糊性度量与人类标注更有相关性。此外，本文还研究了多轮对话如何减少含糊性，并通过更好的匹配用户目标来提高代码准确性。通过评估三种实践模型（格赖斯合作原则、话语表征理论和讨论中的问题），证明了多轮对话策略的有效性。", "conclusion": "研究发现，使用多轮对话可以减少含糊性，提高代码准确性，强调了代码生成过程中多轮交互的价值。通过模拟用户实验，本文进一步证明了这种对话策略的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09355", "html_url": "https://arxiv.org/abs/2510.09355", "title": "NL2GenSym：通过大型语言模型将自然语言转化为生成符号规则以应用于SOAR认知架构", "title_en": "NL2GenSym: Natural Language to Generative Symbolic Rules for SOAR Cognitive Architecture via Large Language Models", "authors": "Fang Yuan,Junjie Zeng,Yue Hu,Zhengqiu Zhu,Quanjun Yin,Yuxiang Xie", "background": "SOAR是一种经典的基于符号的认知架构，促进了通用、类人智能代理的发展。然而，其实用性的采用受到繁琐的手动规则编码的阻碍。新兴的大语言模型（LLMs）具有高效规则生成的巨大潜力。尽管当前研究主要集中在概念框架上，但缺乏牢固的实验验证。Water Jug Problem (WJP) 是一个专门的问题数据集，用于验证提议的框架。使用Gemini和Qwen系列模型在WJP上的实验验证了框架的有效性，成功率为超过86%。此外，框架产生新颖的启发式规则，将解决WJP的平均决策循环减少到最优解的1.98倍，比基线方法减少到1/1000。初步实验表明，更小参数的模型在性能上优于更大参数的模型。", "innovation": "提出了一种新的框架NL2GenSym，将LLMs与SOAR结合，以自主从自然语言生成生成性符号规则。框架采用执行导向的生成与批评机制，包括LLM驱动的基于检索增强生成的自演化的领域知识库，以及反馈驱动的迭代规则改进。通过WJP数据集的实验，验证了框架的有效性和性能优势。", "conclusion": "NL2GenSym框架通过整合大语言模型与SOAR认知架构，实现了从自然语言生成生成性符号规则的自动化过程。实验结果表明，该框架不仅提高了规则生成的成功率，还减少了解决Water Jug Problem的决策循环次数，并使得具有较小参数的模型表现出更好的性能。未来可以进一步研究如何优化框架以适应更多复杂的应用场景。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09418", "html_url": "https://arxiv.org/abs/2510.09418", "title": "大型语言模型的主动模型选择", "title_en": "Active Model Selection for Large Language Models", "authors": "Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel", "background": "现有评估和基准测试方法依赖于完全标注的数据集，这些方法往往成本高昂且耗时。本文旨在提出一种新的框架，以更高效的方式在标注信息有限的情况下选择最适合特定任务的大型语言模型（LLMs）。该框架能够根据任务自适应地选择最有信息量的查询，以减少标注成本。研究通过在6个基准测试中的151个LLMs上进行的实验，证明了该框架的有效性，极大地降低了选择最佳和接近最佳模型的标注成本（最高达到59.62%的减少）", "innovation": "LLM SELECTOR是一个新型的框架，可以在有限标注的情况下高效选择最佳的大型语言模型。它通过自适应地选择最有信息量的查询来降低标注成本，并使用基于评判者的Oracle标注模型进一步降低成本。该框架在多个基准测试中展示了显著的效果，证明了其在实际应用中的潜力", "conclusion": "通过使用LLM SELECTOR框架，即使在仅有少量标注信息的情况下，也能有效地选择最适合特定任务的大型语言模型。实验结果表明该框架能够将选择最佳和接近最佳模型的标注成本最多减少59.62%，显著提高了模型选择的效率和经济性"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09424", "html_url": "https://arxiv.org/abs/2510.09424", "title": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach", "title_en": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach", "authors": "Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf", "background": "本文探讨了使用语音-大型语言模型（Speech-LLMs）进行端到端语音对话状态跟踪的上下文管理策略。研究评估了传统多模态上下文（结合文本历史和当前说话轮次），完整的语音历史以及压缩的语音历史方法。", "innovation": "本文系统评估了不同上下文管理策略，并通过SpokenWOZ语料库的实验表明，提供完整的语音对话作为输入的模型性能显著高于同类规模的先前方法。此外，还展示了基于注意力池的语音历史压缩的有效性，平衡了上下文规模和准确度之间的关系。", "conclusion": "详细分析表明，性能提升来自于上下文利用的更有效方式。该研究为语音对话状态跟踪提出了一个真正端到端的方法，提供了全面而准确的上下文管理策略。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09394", "html_url": "https://arxiv.org/abs/2510.09394", "title": "超越单一粒度提示：图的多尺度链式思维提示学习", "title_en": "Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu", "background": "预训练-提示（pre-train, prompt）范式最初在自然语言处理（NLP）领域得到广泛应用，并已扩展到图领域。尽管当前的主流图提示微调方法能够通过学习提示向量修改输入或输出特征，但这些方法在提示生成过程中仅局限于单一的粒度（例如节点级或子图级），忽视了图数据中固有的多尺度结构信息，导致提示语义的多样性受到限制。", "innovation": "本文提出了将多尺度信息整合到图提示中的新型框架——多尺度图链式思维（MSGCOT）提示框架。具体而言，提出了一个轻量级、低秩粗化网络来高效捕捉多尺度结构特征作为提示生成的层次基向量，并模仿从粗到细的人类认知过程，在每一步推理中动态整合多尺度信息，形成了一个逐步的粗到细提示链。", "conclusion": "广泛的实验结果表明，MSGCOT 在多个基准数据集上优于最先进的单一粒度图提示微调方法，尤其是对于少数样本情况，展示了优越的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09426", "html_url": "https://arxiv.org/abs/2510.09426", "title": "KORMo: 全民韩语开放推理模型", "title_en": "KORMo: Korean Open Reasoning Model for Everyone", "authors": "Minjun Kim,Hyeonseok Lim,Hangyeol Yoo,Inho Won,Seungwoo Song,Minkyung Cho,Junhun Yuk,Changsu Choi,Dongjae Shin,Huige Lee,Hoyun Song,Alice Oh,Kyungtae Lim", "background": "研究介绍了首个大规模探究如何构建非英语语言（即韩语）的全开放双语大型语言模型（LLM）的尝试。该模型主要基于合成数据进行训练。", "innovation": "引入了KORMo-10B模型，训练过程中有68.74%的韩语文本来自合成数据，证明合成数据可以在大规模预训练中保持语言覆盖和指令风格的平衡，不会导致模型崩溃或性能下降。此外，双语指令调优使模型在韩语的推理和连贯性方面接近母语水平。并且，模型的所有组件如数据、代码、训练食谱和日志都完全公开，为未来低资源环境下的合成数据驱动的全开放模型（FOM）提供了透明框架。", "conclusion": "通过这种方法，工作不仅在各种推理、知识和指令遵循基准测试中实现了可与当前的多语言基线相媲美的性能，而且为未来的多语言LLM研究树立了可重复的范例。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09472", "html_url": "https://arxiv.org/abs/2510.09472", "title": "自然语言推理中的混合模型：斯多葛逻辑案例", "title_en": "Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic", "authors": "Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki", "background": "尽管神经模型取得了显著进步，但在逻辑推理等应用中面临的泛化能力问题仍然是一个关键挑战。这项研究探讨了大规模语言模型在斯多葛逻辑片段上的逻辑泛化能力，发现了模型在递归性上表现良好但在成分性上有明显不足。进一步理解这种差异对于克服神经推理系统的泛化障碍至关重要。", "innovation": "研究区分了组成性和递归性这两个用于逻辑推理的核心能力，使用斯多葛逻辑片段作为语言推理的基准。提出了混合架构，结合符号推理和神经计算，以增强推理的稳健性和效率，即使使用较小的神经组件也能保持高效率。", "conclusion": "通过实验，研究证明了混合模型在逻辑推理中的有效性和潜力，为解决神经推理系统的泛化难题提供了可行途径。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09471", "html_url": "https://arxiv.org/abs/2510.09471", "title": "序贯进行索引：用于实际应用的大语言模型训练数据全文搜索", "title_en": "Getting Your Indices in a Row: Full-Text Search for LLM Training Data for Real World", "authors": "Ines Altemir Marinas,Anastasiia Kucherenko,Alexander Sternfeld,Andrei Kucharavy", "background": "大型语言模型（LLMs）的表现由其训练数据决定。尽管开源权重LLMs的普及，但对它们的训练数据的访问仍然受到限制。即使对于完全开源的LLMs，数据规模也使其对普通科学界难以理解，尽管这些数据可能包含从互联网上抓取的重要信息。当今，Apertus LLM训练数据的全文索引管道被提出。利用Elasticsearch并行索引和Alps基础设施，一种最先进的高能效arm64超级集群，成功地索引了用于训练Apertus LLM家族的数据中的8.6T个令牌，占总使用的15.2T令牌，从而创建了一个关键的LLM安全工具和一个离线、经过筛选的开源网络搜索引擎。研究背景在于揭示LLMs训练数据的索引可行性及其实现方法，旨在推动全面转向更绿色的计算环境，以及促进LLM安全性的提升。背景部分还强调了现行技术的局限性，以及开放数据对研究的潜在价值。웹에서 이 문서를 번역한 것입니다.", "innovation": "研究展示了Elasticsearch可以成功迁移至下一代arm64基础架构；证明了大规模LLM训练数据集和整个开放网络进行全文索引的可行性和可行性；通过全文本索引创造了一个以前无法访问、不依赖于“突破”的LLM安全索引工具，从而提供了一种新的安全保障方法。创新部分还包括了生态系统构建，如Alps基础设施的应用，实现高能效计算，并为其他团队进行大规模数据索引提供参考。웹에서 이 문서를 번역한 것입니다.", "conclusion": "希望我们的研究成果对其他试图进行大规模数据索引的研究团队有所帮助，并促进向更绿色计算的转变。同时，我们还强调了这样的索引工具对于确保LLM安全性的重要性，以及它在科学界和公众中的潜在价值。结论部分还要进一步推广该技术的应用，尤其是在能源效率和数据安全性方面的应用。웹에서 이 문서를 번역한 것입니다."}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09517", "html_url": "https://arxiv.org/abs/2510.09517", "title": "StatEval：统计学领域大规模语言模型的全面基准", "title_en": "StatEval: A Comprehensive Benchmark for Large Language Models in Statistics", "authors": "Yuchen Lu,Run Yang,Yichen Zhang,Shuguang Yu,Runpeng Dai,Ziwei Wang,Jiayi Xiang,Wenxin E,Siran Gao,Xinyao Ruan,Yirui Huang,Chenjing Xi,Haibo Hu,Yueming Fu,Qinglan Yu,Xiaobing Wei,Jiani Gu,Rui Sun,Jiaxuan Jia,Fan Zhou", "background": "大型语言模型（LLMs）在数学和逻辑推理方面取得了显著的进展，但在统计学领域这一独特且综合性较强的学科上，现有的基准测试还未充分利用这一优势。为了弥补这一不足，作者们提出了StatEval，这是首个全面针对统计学的基准测试，涵盖了从基础到研究级别的广泛和深度的问题。StatEval 包括13,817个基础问题和2374个研究级别的证明任务。", "innovation": "该论文的创新点在于设计了一个可扩展的、人机结合的多Agent管道系统，该系统自动进行大规模的问题提取、重写和质量控制，同时保持学术上的严谨性。此外，还提出了一个适用于计算和证明任务的稳健评估框架，能够精细评估推理能力。实验结果表明，闭源模型如GPT5-mini在研究级问题上的得分低于57%，开源模型的得分更低，这表明统计推理的独特挑战和当前LLM的局限性。", "conclusion": "研究结果强调了统计推理的独特挑战和当前LLM的局限性。作者期望StatEval能够作为衡量和推动大型语言模型中统计智能的严格基准。所有数据和代码都可在作者的网页平台找到。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09474", "html_url": "https://arxiv.org/abs/2510.09474", "title": "多模态政策内化在对话代理中的应用", "title_en": "Multimodal Policy Internalization for Conversational Agents", "authors": "Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya", "background": "现代对话代理如ChatGPT和Alexa+依赖预定义政策，包括元数据、响应风格和工具使用规则。随着这些基于大语言模型的系统扩展以支持多样化的业务和用户查询，这些政策日益复杂庞大，导致忠实执行变得困难，并且带来高昂的固定计算成本。对于多模态代理，指导视觉和多模态行为的政策至关重要但尚未得到充分研究。以前的压缩提示工作主要集中在缩短任务模板和示范，而现有的策略对齐研究只关注文本安全性规则。因此，本文引入了多模态政策内化（MPI），这是一种将复杂多模态政策融入模型参数的任务，从而无需在推理时包含策略即可提高策略遵守能力。", "innovation": "提出了多模态政策内化（MPI）任务，这是一种将复杂多模态政策融入模型参数的方法，从而无需在推理时包含策略即可增强策略遵守能力；构建了两种涵盖合成和真实世界决策制定和工具使用任务的数据集；提出了TriMPI，这是一个包含三个阶段的训练框架：持续预训练注入政策知识，然后进行监督微调，最后应用结合策略感知响应的滚动扩展，以增强基于策略的探索", "conclusion": "TriMPI 在末端准确性、泛化能力和对抗遗忘的鲁棒性方面实现了显著提升。作为第一项关于多模态政策内化的研究，研究提供了数据集、训练配方和全面评估以促进未来的研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09535", "html_url": "https://arxiv.org/abs/2510.09535", "title": "通过推理塑造减少过度思考", "title_en": "Mitigating Overthinking through Reasoning Shaping", "authors": "Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang", "background": "大推理模型（LRMs）借助强化学习从验证者奖励（RLVR）获得增强，在解决问题方面展现出巨大能力，但常常导致过度思考：过度、冗长的推理增加了计算成本。此前在RLVR中的惩罚设计虽然减少了标记消耗，但往往损害了模型性能，这源于标记级别监督的简单性不足。我们主张监督粒度在平衡效率和准确性之间起着关键作用，并提出了基于组相对片段惩罚（GRSP）的步骤级规范化方法。初步分析显示，推理片段与标记消耗和模型性能之间存在密切关联，我们设计了一种跨片段簇的长度感知加权机制。", "innovation": "提出了一种基于组相对片段惩罚（GRSP）的步骤级规范化方法，设计了一种跨片段簇的长度感知加权机制，以改进大推理模型（LRMs）的计算效率和性能，特别是在处理更困难的问题时表现出明显优势。此外，GRSP稳定了强化学习训练，并且能够有效扩展到不同的模型规模。", "conclusion": "GRSP在不大幅牺牲准确性的情况下实现了优越的标记效率，并且特别适用于更困难的问题。此外，GRSP还稳定了强化学习训练，并且能够适应不同规模的模型。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09519", "html_url": "https://arxiv.org/abs/2510.09519", "title": "无需标注数据能否在各领域内可靠地对模型性能进行排名？", "title_en": "Can We Reliably Rank Model Performance across Domains without Labeled Data?", "authors": "Veronica Rammouz,Aaron Gonzalez,Carlos Cruzportillo,Adrian Tan,Nicole Beebe,Anthony Rios", "background": "理解自然语言处理（NLP）模型的泛化能力是一个重要目标，而无需使用标签来估计模型性能亦是一个关键挑战。虽然先前的研究提出了基于数据集相似度或预测正确性的度量方法，但这些估算方法在不同领域间的可靠性仍不明确。本文在这种背景下探讨了在没有标注数据的情况下对模型性能进行排名的方法及其可靠性问题。", "innovation": "本文提出了一种两步评估框架，利用四种基础分类器和大型语言模型作为错误预测器，分析了在不同领域中对模型性能进行排名的可靠性。实验结果表明，基于大型语言模型的错误预测器比基于迁移学习或零样本的基线方法更能产生更一致的性能排名。此外，研究发现了两个关键发现：当领域间性能差异较大时，排名可靠性更高；当错误模型的预测与基础模型的真实失败模式相符时，排名可靠性更高。这些发现明确了模型性能估计方法可以被信赖的条件，并为跨领域模型评估提供了指导。", "conclusion": "本文的研究结果澄清了在何种情况下模型性能估计方法可以被信任，并为跨领域的模型评估提供了指导。通过两个实验步骤和大规模语言模型，证实了基于大型语言模型的错误预测器能够更可靠地对模型的性能进行排名。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09536", "html_url": "https://arxiv.org/abs/2510.09536", "title": "评估大型语言模型对多语言打字错误的鲁棒性", "title_en": "Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors", "authors": "Yihong Liu,Raoyuan Zhao,Lena Altinger,Hinrich Schütze,Michael A. Hedderich", "background": "大型语言模型（LLMs）越来越多地在具有用户输入的多语言实际应用中部署，这自然会使它们暴露于打字错误（打字错误）中。然而，大多数基准测试假定输入干净，这使得对LLMs在多种语言中的鲁棒性进行了广泛研究，特别是在面对打字错误时。为了填补这一空白，引入了多Typo，该算法基于语言特定的键盘布局和打字行为模拟人类错误。我们对多种下游任务（包括语言推断、多选题回答、数学推理和机器翻译）中的18个开源LLMs进行了评估。", "innovation": "提出了一种名为MulTypo的多语言打字错误生成算法，该算法基于语言特定的键盘布局和打字行为模拟人类错误；系统地评估了18个开源大语言模型的鲁棒性，展现了他们在不同任务中的性能变化；发现不同资源的语言之间存在依赖性的鲁棒性，以及指令调优改善干净输入性能但可能在噪声条件下增加脆弱性。", "conclusion": "研究表明，打字错误在生成和需要推理的任务中一再破坏性能，指令调优提高干净输入性能但也可能在噪声条件下增加脆弱性。我们还观察到基于资源的语言鲁棒性差异：资源丰富语言的鲁棒性通常更高，而从英语翻译的鲁棒性比译入英语的鲁棒性更高。我们的发现突显了噪声感知训练和多语言鲁棒性评估的必要性。我们已公开发布了代码和数据。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09528", "html_url": "https://arxiv.org/abs/2510.09528", "title": "通过可解释性驱动的频谱图掩蔽实现变音不变的自动语音识别", "title_en": "Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking", "authors": "Mohammad Hossein Sameti,Sepehr Harfi Moridani,Ali Zarean,Hossein Sameti", "background": "预训练的基于变换器的模型在自动语音识别(ASR)方面取得了显著进展，但这些模型对口音和方言的变化依然敏感，在英语和波斯语等语言多样性语言中导致较高的词错误率(WER)。为解决这一挑战，本文提出了一种变音不变的ASR框架，该框架将口音和方言分类整合到识别管道中。我们通过训练一个基于频谱的分类器来捕捉口音特定的线索，屏蔽预测最相关的区域，并利用屏蔽的频谱图进行数据增强，以提升ASR模型对变音的鲁棒性。我们使用英波两语进行评估。对于波斯语，我们引入了跨越多个区域口音的新的数据集，并建立了首个系统性的波斯语ASR变音基准，填补了多语言语音研究中的关键空白，提供了对低资源语言和语言多样性研究的基础。实验结果表明，我们的掩蔽和增强策略在英波两语环境中都显著降低了WER，证实了该方法的有效性。", "innovation": "本文提出了一种通过频谱图掩蔽的方法来提升ASR模型对变音的鲁棒性。该方法还包括一个新的波斯语数据集，该数据集涵盖了多个区域口音，并建立了首个系统性的波斯语ASR变音基准，为语言多样性和低资源语言的研究提供基础。同时，研究强调了通过屏蔽和数据增强策略有效减轻变音对ASR性能的影响，从而推动了多语言ASR系统的开发，使其能够应对变音和方言的多样性挑战。", "conclusion": "本文的研究通过可解释性驱动的频谱图掩蔽方法提高了ASR模型针对变音的鲁棒性，并通过引入新的波斯语数据集建立了变音识别基准，促进了语言多样性环境下的ASR系统开发。研究结果表明了这种方法在提高多语言ASR系统的准确性方面的有效性，相关的代码和数据集已公开可供研究使用。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09541", "html_url": "https://arxiv.org/abs/2510.09541", "title": "SPG: 批量策略梯度方法用于掩码扩散语言模型", "title_en": "SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models", "authors": "Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu", "background": "扩散大型语言模型（dLLMs）因其能够并行解码多个令牌而成为自回归模型的有效替代方案。然而，由于其难以计算的对数似然，通过强化学习（RL）将dLLMs与人类偏好或任务特定的奖励对齐仍然是个挑战。此前的工作使用类似的证据下界（ELBO）作为替代，并且这些单向近似会导致显著的策略梯度偏差，因此仍需改进方案来缓解该问题。现有的基线方法基于ELBO或一步估计，性能有限，尤其是在评估dLLMs时存在较大差距，特别是在GSM8K、MATH500、Countdown和Sudoku等特定任务中", "innovation": "提出了一种名为“Sandwiched Policy Gradient（SPG）”的新方法，该方法结合了真实对数似然的上界和下界。相比于基于ELBO或一步估计的基线方法，SPG显著提升了准确性。具体而言，在GSM8K、MATH500、Countdown和Sudoku等不同任务中，SPG比最先进的RL方法分别提高了3.6%、2.6%、18.4%和27.0%的准确率", "conclusion": "实验结果表明，SPG方法改进了现有的RL方法在GSM8K、MATH500、Countdown和Sudoku等任务中的准确性，特别是在这些特定应用中提出了显著的性能提升。该研究为通过强化学习优化扩散大型语言模型的性能提供了一种新颖的策略梯度改进方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09421", "html_url": "https://arxiv.org/abs/2510.09421", "title": "自回归大型语言模型中实体的表示", "title_en": "On the Representations of Entities in Auto-regressive Large Language Models", "authors": "Victor Morand,Josiane Mothe,Benjamin Piwowarski", "background": "命名实体是文本中知识的基本构建模块，它们承载着事实信息并结构化语言中的关系。尽管实体的重要性不言而喻，但目前尚不清楚大型语言模型（LLMs）内部如何表示这些实体。以往研究主要关注显式的实体关系，而对实体本身的表示知之甚少。本研究引入了实体提及重建作为研究LLMs如何编码和操作实体的新框架，旨在探索LLMs是否可以从内部表征生成实体提及，多词实体如何超越最后一个词的嵌入进行编码以及这些表征是否捕获了关系性知识。", "innovation": "提出了一种利用任务向量的方法，该方法能从LLMs隐藏状态中提取的各种实体表示中一致地生成多词提及。此外，提出了扩展的日志光学验证方法（logit-lens），以预测多词提及。研究表明，LLMs发展了针对任何多词实体（包括训练期间未见过的实体）的具体机制来进行表示和操作。有关代码可在此网址获取：this https URL", "conclusion": "我们的研究结果为LLMs能够以特定机制表示和操作任何多词实体提供了新的证据。这挑战了对LLMs实体表示的理解，为深入理解这些模型的内部运作提供了新的视角。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09553", "html_url": "https://arxiv.org/abs/2510.09553", "title": "基于知识增强的分层索引在跨语言医疗视频档案检索中的应用", "title_en": "Hierarchical Indexing with Knowledge Enrichment for Multilingual Video Corpus Retrieval", "authors": "Yu Wang,Tianhao Tan,Yifei Wang", "background": "在多语言医疗档案中检索相关教学视频对于跨语言回答复杂、多步骤问题至关重要。然而，现有的系统要么将一个小时的视频压缩成粗粒度的嵌入，要么由于细粒度的匹配成本过高而无法实现。", "innovation": "该研究提出了一种多阶段框架，结合了多语言语义、领域术语和高效的长格式处理，将视频字幕分为语义一致的块，通过语言无关的多语言编码器添加简洁的知识图谱事实，并组织成分层树。编码器在查询时将输入问题编码；粗粒度到细粒度的树搜索剔除无关分支，并仅对排名最高的块重新评分，使用轻量级大语言模型。这种设计避免了全面的跨编码评分，同时保持了块级别的精确度。实验结果表明，该方法在mVCR测试集上达到了最先进的性能，消融研究证实了知识增强、分层索引和目标大语言模型重排序的互补贡献。", "conclusion": "该研究提出的方法为专门化的医疗视频收藏中的跨语言检索提供了一个准确且可扩展的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09555", "html_url": "https://arxiv.org/abs/2510.09555", "title": "跨语言链式推理的全面评估：语言间的表现、一致性和忠实地考察", "title_en": "A Comprehensive Evaluation of Multilingual Chain-of-Thought Reasoning: Performance, Consistency, and Faithfulness Across Languages", "authors": "Raoyuan Zhao,Yihong Liu,Hinrich Schütze,Michael A. Hedderich", "background": "大型推理模型（LRMs）越来越多地依赖逐步的链式推理（CoT）来提高任务性能，特别是在如英语这样的高资源语言中。尽管最近的研究已经在多语言环境中考察了最终答案的准确性，但链式推理的中间步骤自身，即通往最终答案的中间步骤，仍然没有被充分研究。本研究首次全面评估了多语言链式推理，考察了三个关键维度：性能、一致性和忠实性。", "innovation": "1. 通过测量LRMs在被明确指示或提示式思考目标语言时的表现、答案准确性和一致性，研究展现出了显著的语言偏好和跨语言性能差异。\n2. 通过交换思考路径在不同语言间的交叉一致性检查，揭示了不同提示语言下思考路径质量的有效性差异。\n3. 使用扰动技术——如截断和注入错误——来探究思考路径的语言间的忠实性，展示了模型对思考路径的依赖程度存在差异。", "conclusion": "研究发现跨语言思考路径在不同语言中的质量与有效性差异明显，并通过扰动技术评估了模型思考路径的忠实性。研究团队还提供了代码和数据，以支持未来的研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09556", "html_url": "https://arxiv.org/abs/2510.09556", "title": "WUGNECTIVES: 从话语连词推断新型实体的语言模型", "title_en": "WUGNECTIVES: Novel Entity Inferences of Language Models from Discourse Connectives", "authors": "Daniel Brubaker,William Sheffield,Junyi Jessy Li,Kanishka Misra", "background": "之前的研究表明，世界知识在预测标志两个论证之间话语关系的连词方面起到了至关重要的作用，语言模型（LMs）通常在此任务上表现良好。这项研究倒置了这一前提，转而研究连词能否帮助语言模型了解世界知识的问题。为此，作者提出了WUGNECTIVES数据集，评估LMs在上下文中对新型实体的推理能力，其中连词将这些实体与特定属性相联系。", "innovation": "这项研究的创新点在于，采用逆向问题研究方法，即探讨连词是否能够帮助语言模型推断世界知识。通过17种不同规模和训练方式的LMs进行验证，作者发现，通过调优LM以展示推理行为，其在大多数连词上的表现有所提升，但不同类型的连词在整体表现上存在较大差异，所有模型在表示转折意义连词时表现不佳。", "conclusion": "研究结果为更细致地探究LM捕捉语言线索的功能角色铺平道路。作者已将WUGNECTIVES数据集公开于此 https://url."}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09544", "html_url": "https://arxiv.org/abs/2510.09544", "title": "超越表面推理：揭示扩散大型语言模型真正长逻辑链能力", "title_en": "Beyond Surface Reasoning: Unveiling the True Long Chain-of-Thought Capacity of Diffusion Large Language Models", "authors": "Qiguang Chen,Hanjing Li,Libo Qin,Dengyun Peng,Jinhao Liu,Jiangyi Wang,Chengyue Wu,Xie Chen,Yantao Du,Wanxiang Che", "background": "最近，扩散大型语言模型（DLLMs）提供了高吞吐量和有效的序列推理能力，使它们成为自回归大型语言模型（ALLMs）的一种有竞争力的替代品。但是，平行解码能够同时更新标记，这与通常要求的因果顺序冲突，后者对于严密推理至关重要。我们首先识别了这个矛盾作为并行-序列矛盾（PSC）。在简单和复杂的推理任务中的行为分析表明，DLLMs在直接可解的任务中仅表现出真正的并行性。随着任务难度增加，它们会退回到自回归行为。自回归提示进一步加剧了这个限制，几乎将解码步骤数量翻倍，而没有提高质量。此外，PSC限制了DLLMs的自我反省、推理深度和探索的宽度。", "innovation": "我们提出了三个对DLLMs的扩展维度：并行、扩散和序列。实验证明，虽然并行扩展可以持续改善表现，但扩散和序列扩展却受到PSC的限制。基于这些发现，我们提出了一些实用的缓解措施，包括以并行为导向的提示、扩散早期停止和并行扩展，以减少由PSC引起的无效性和低效率。", "conclusion": "研究结果表明，尽管DLLMs具有并行处理和有效的序列推理能力，但仍受限于PSC，限制其真正的长逻辑链推理能力。我们建议通过特定的技术手段来减轻PSC的影响，从而提升其性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09577", "html_url": "https://arxiv.org/abs/2510.09577", "title": "Dyna-Mind：从经验中学习模拟以提高AI代理能力", "title_en": "Dyna-Mind: Learning to Simulate from Experience for Better AI Agents", "authors": "Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao", "background": "近年来，推理模型在数学和编程等领域取得了显著的进展。然而，在诸如网页导航和计算机/手机使用等长期交互任务中，它们的表现与在数学和编程中的专家级能力形成了鲜明对比。我们发现，当前的AI代理缺乏一种'代理尝试与错误'的能力，即在行动之前能够进行心智中的未来场景模拟，这对于提高它们在复杂交互环境中的理解和性能至关重要，这启发了我们提出这一研究。", "innovation": "我们提出了Dyna-Mind，一种两阶段的训练框架，明确教导语言模型代理整合这种模拟到他们的推理过程。在第一阶段，我们提出了基于模拟推理（ReSim），它训练代理通过环境交互收集的真实经验生成结构化的推理追踪，来自构建的扩展搜索树。在第二阶段，我们提出了一种基于在线强化学习的Dyna-GRPO方法，它利用最终结果和交互状态反馈从真实滚动中增强了代理的模拟和决策能力。实验表明，ReSim能够将模拟能力有效地注入AI代理中，而Dyna-GRPO能够利用结果和交互级别信号学习更好策略以应对长期规划任务。", "conclusion": "研究结果强调了模拟在使AI代理更有效地推理、规划和在更具挑战性的环境中行动中的核心作用。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09558", "html_url": "https://arxiv.org/abs/2510.09558", "title": "自动推广（AutoPR）：让我们自动化你的学术推广！", "title_en": "AutoPR: Let's Automate Your Academic Promotion!", "authors": "Qiguang Chen,Zheng Yan,Mingda Yang,Libo Qin,Yixin Yuan,Hanjing Li,Jinhao Liu,Yiyan Ji,Dengyun Peng,Jiannan Guan,Mengkang Hu,Yantao Du,Wanxiang Che", "background": "随着学术研究成果的激增，学者们越来越依赖社会平台进行信息发现，而作者也投入大量精力来推广自己的研究以确保其可见性和引用率。这种方法日益依赖人类的努力，为解决这一问题，本文引入了自动推广（AutoPR）这一新任务，目的是将研究论文转化为准确、吸引人且及时的公众内容。为此，作者们提出了PRBench这一多模态基准数据集，用于评估自动推广系统的性能，包括准确性和语气（忠诚度）、受众定位和吸引力（受众）、以及时机和渠道优化（对齐）。", "innovation": "作者们提出了一种新的自动推广（AutoPR）任务，并开发了多模态基准数据集（PRBench）和一种多智能体框架（PRAgent），以自动化这条过程。PRAgent由三个阶段组成：1）多模态内容提取；2）协作合成以产生精炼的输出；3）针对特定平台进行适应以优化规范、语气和标签，以最大化推广范围。通过与直接使用LLM管道的方法相比，PRAgent取得了显著的提升，包括视频总播放时间增加604%，点赞数增加438%，总体参与度至少增加2.9倍。模型消融研究表明，平台建模和有针对性的推广对这种增长做出了最大贡献。这些成果使AutoPR成为一个可处理且可测量的研究问题，并为可扩展且影响深远的自动学术交流提供了蓝图。", "conclusion": "AutoPR作为一项研究问题具有可行性，并为大规模、有效和有意义的自动学术交流提供了 roadmap，重点强调平台建模和针对性推广的作用对于提升推广效果非常重要。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09592", "html_url": "https://arxiv.org/abs/2510.09592", "title": "Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models", "title_en": "Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models", "authors": "Donghang Wu,Haoyang Zhang,Jun Chen,Xiangyu(Tony)Zhang,Hexin Liu,Eng Siong Chng,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu", "background": "实时语音模型(SLMs)在进行思维推理时因逐句生成整个思维过程而导致延迟过高，传统方法难以实现边说边想。研究人员意识到模拟人类思维与表达方式，通过分担任务的方式可以在实时语音模型中实现高质量的推理。", "innovation": "提出了名为Mind-Paced Speaking (MPS)的新框架，采用了一种模仿大脑功能的双脑系统，其中“构思脑”负责高层次的推理并控制和引导另一个专门用于流畅语音生成的“发声脑”。这种方法避免了任务转换，保证了推理过程的完整性，实现了优于现有边说边想方法的效果，并使推理性能接近于预先计算完整思维过程的模型，同时大幅减少延迟。在无延迟配置下，该方法在数学推理任务上能达到92.8%的准确率，在对话任务上获得82.5分。", "conclusion": "该工作有效解决了高质量推理与实时交互之间的鸿沟，通过双脑系统实现了一种能够实时进行有效推理的语音模型新方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17821", "html_url": "https://arxiv.org/abs/2508.17821", "title": "注意机制中归一化技术的局限性", "title_en": "Limitations of Normalization in Attention Mechanism", "authors": "Timur Mudarisov,Mikhail Burtsev,Tatiana Petrova,Radu State", "background": "本文探讨了注意机制中归一化的局限性。通过引入理论框架，识别模型的挑选能力和选择令牌过程中的几何分离。并通过对预训练GPT-2模型的实验，验证理论成果，分析注意机制的关键行为。", "innovation": "发现随着选中令牌数量的增加，模型识别信息性令牌的能力下降，往往呈现均匀的选中模式。并且指出在softmax归一化下，梯度敏感性在训练过程中遇到挑战，尤其是在低温设置下。", "conclusion": "这些发现促进了当前对基于softmax的注意机制的理解，并推动未来注意架构中需要更稳健的归一化和选择策略。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09599", "html_url": "https://arxiv.org/abs/2510.09599", "title": "在测试时提供指令增强是一种强大的大语言模型推理数据增强方法", "title_en": "Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation", "authors": "Sondos Mahmoud Bsharat,Zhiqiang Shen", "background": "大语言模型（LLMs）在提供链式思考示例后，已经展示了卓越的推理能力。然而，构建大规模的推理数据集仍然是一项耗费时间和资源的工作。本文介绍了一种简单的推理时数据增强策略——Prompting Test-Time Scaling (P-TTS)，在测试时通过有限的手动选择的推理示例进行指令增强，从而增强LLM的推理能力。这种方法不需要大量收集数据，而是通过系统地变化示例增强的程度，以及精心设计的指令提示强度，来生成多样化的推理轨迹背景。", "innovation": "P-TTS 通过有限的手动选择的推理示例和测试时若即若离的指令增强策略，提升了大规模语言模型的推理性能。通过对不同规模 Qwen-2.5 模型的微调，P-TTS 模型在数学推理和若干基准测试中表现优于之前的基线模型，特别是在 AIME2024 和 AIME25 的测试中，P-TTS 的绝对准确率分别提高了 26.66% 和 30.00%，显示了一种低花费、高成效的增强方法，适用于资源受限或快速演变的领域。", "conclusion": "测试时的指令增强能够有效探索隐含的推理模式空间，以最小的注释开销增强大语言模型的问题解决能力，进一步解锁LLM的推理潜力。P-TTS 提供了一种实用且成本低的方法，用于在资源受限或快速演变的领域中激发大语言模型的推理能力。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08585", "html_url": "https://arxiv.org/abs/2510.08585", "title": "基于发音信息的ASR：通过辅助语音反转和交叉注意力融合集成发音特征", "title_en": "Articulation-Informed ASR: Integrating Articulatory Features into ASR via Auxiliary Speech Inversion and Cross-Attention Fusion", "authors": "Ahmed Adel Attia,Jing Liu,Carol Espy Wilson", "background": "先前的研究已经探讨了使用发音特征作为自动语音识别(ASR)的补充表示，但它们的使用主要限制在浅层声学模型中。本文回顾了在深度学习时代的发音信息，并提出了一种框架，该框架不仅将发音表示作为辅助任务使用，也将其作为伪输入到识别模型。具体而言，本文使用语音反转作为一种辅助预测任务，预测的发音特征被注入到一个交叉注意力模块中，与声学嵌入一起作为键和值。", "innovation": "本文提出了一种新的方法，即通过辅助语音反转和交叉注意力融合来集成发音特征，从而提高ASR系统的性能，特别是在资源有限的条件下表现出一致的改进。这种方法将发音特征重新引入ASR研究，并通过现代架构的使用，为ASR模型提供了有意义的好处。", "conclusion": "实验结果表明，本文提出的方法在LibriSpeech数据集上优于强大的基于变换器的基线模型，特别是在资源匮乏的情况下。这表明，当利用现代架构时，发音特征可以为ASR研究提供实质性的好处。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08586", "html_url": "https://arxiv.org/abs/2510.08586", "title": "动态压力检测：语音中压力时序进展建模研究", "title_en": "Dynamic Stress Detection: A Study of Temporal Progression Modelling of Stress in Speech", "authors": "Vishakha Lall,Yisi Liu", "background": "在高压环境下，通过语音检测心理压力至关重要。以往的工作多依赖声学特征进行压力检测，但大多将压力视为静态标签。本研究将压力视为一个受历史情绪状态影响的时间上不断演变的现象。", "innovation": "提出了动态标签策略，从情感标签中提取细粒度的压力注释，并引入了基于交叉注意力的序列模型，包括单向LSTM和Transformer编码器，以捕捉压力的时序进展。该方法在MuSE和StressID上比现有基线分别提高了5%和18%的准确率，并且在自定义的真实世界数据集上表现出良好的泛化性能。", "conclusion": "这些结果突显了在语音中建模压力作为动态构造的价值。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08599", "html_url": "https://arxiv.org/abs/2510.08599", "title": "BaldWhisper：剪枝和层合并加速的 Whisper", "title_en": "BaldWhisper: Faster Whisper with Head Shearing and Layer Merging", "authors": "Yaya Sy,Christophe Cerisara,Irina Illina", "background": "对于资源稀缺的语言，剪枝大型预训练转换器具有挑战性，通常需要大量的重新训练数据才能恢复性能。例如，Distill-Whisper通过剪枝 Whisper 并在21000小时的语音数据上进行重新训练来实现性能恢复，后者远远超出了大多数语言可用的数据范围。在数据稀缺的环境中，如何使 Whisper 更轻、更快以适应边缘设备成为一个问题。鉴于仅有32小时的语音转文字数据，本文以巴马拉语为重点，提出了一种新型剪枝方法，并通过低秩分解和特征蒸馏压缩嵌入层，而不是去除层而是合并层来限制性能损失。", "innovation": "本文创新性地提出了一种适合巴马拉语的新剪枝方法，即通过低秩分解和特征蒸馏压缩嵌入，并合并层而非删除层，从而实现了模型性能的保留并大幅减少了模型大小和提高了速度。此外，本文方法仅使用32小时数据，远少于Distill-Whisper所需的21000小时数据量，展示了其在数据稀缺情况下的应用潜力。", "conclusion": "最终优化后的模型在保持90%原始性能的同时，大小减少48%，在MacBook Air M1上速度提升了2.15倍，展示了在数据资源稀缺环境下的高效特性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08576", "html_url": "https://arxiv.org/abs/2510.08576", "title": "大型语言模型在机器辅助解析用户意图中的比较分析", "title_en": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "authors": "Justus Flerlage,Alexander Acker,Odej Kao", "background": "大型语言模型（LLMs）已经成为理解自然语言和解决用户意图的关键工具，能够完成诸如翻译、总结和复杂的多应用流程编排等多种任务。随着LLMs的发展，用户界面从传统的基于GUI的方式向以语言为导向的交互方式转变。用户可以直接用自然语言表达目标，LLMs可以动态并根据上下文协调跨多个应用的操作。然而，现有实现大多依赖于基于云的私有模型，这在数据隐私、自主性和可扩展性方面存在限制。因此，要想使语言先驱交互成为真正可靠且受信赖的接口范式，局部部署是必要的。研究认为，可局部部署、开源且开放访问的大型语言模型对于未来基于意图的操作系统至关重要。为此，本文研究了几种开源和开放访问的模型在通过机器辅助实现用户意图解析方面的能力。论文对比分析了这些模型与OpenAI的专用GPT-4系统的性能差异，重点关注生成不同用户意图的工作流能力。这项研究为未来的操作系统的局部智能提供了实证见解，并强调局部嵌入的智能对于更无缝、适应性强和注重隐私的用户设备交互的重要性", "innovation": "本文创新地使用了多种开源和开放访问的大型语言模型进行比较分析，评估其在用户意图解析方面的性能，并通过与商业性的OpenAI GPT-4系统进行对比，提供了关于开源和本地化部署的大规模语言模型在构建未来基于意图的操作系统方面的潜力和局限性的重要见解。这些研究结果对于推动AI基础设施的分散化和民主化具有重要意义", "conclusion": "本文通过实证研究提供的比较分析，为开源和局部可部署的大型语言模型作为未来基于意图的操作系统组件的可行性提供了可靠依据。研究结果显示，尽管这些开源模型在某些方面可能不如商业模型强大，但在局部隐私保护、成本效益和用户体验方面具有明显优势。研究指出，随着技术的进步和完善，开源和本地部署的大规模语言模型有望在未来提升用户设备交互的无缝性、适应性和隐私保护水平。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08671", "html_url": "https://arxiv.org/abs/2510.08671", "title": "通过考量生成路径的定性评估优化快速零售交付", "title_en": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "authors": "Milon Bhattacharya,Milan Kumar", "background": "印度电子商务市场预计迅速增长，其中最后一公里交付占据了近一半的运营成本。尽管基于车辆路径问题（VRP）的解决方案在配送计划中广泛应用，但它们在现实生活中的效果有限，原因包括地址结构不规范、地图信息不完整以及距离估算的计算限制。", "innovation": "本文提出了一个框架，利用大型语言模型（LLMs）对VRP生成的路线与基于政策的准则进行批判性评价，使物流运营商能够评估并优先考虑更高效的交付计划。研究通过利用大型语言模型生成、注释和评估了400个案例，发现开源LLMs在识别路径问题方面的准确率为79%，而私有推理模型则高达86%。这表明基于LLM的路径评估可以超越传统的时间和距离指标，成为一种有效的、可扩展的评估层，有助于改善成本效率、交付可靠性及可持续性，尤其是在像印度这样的发展中经济体中尤为重要。", "conclusion": "基于LLM的评估可以通过超越传统的时间和距离指标，提供一种有效的、可扩展的方法来优化最后一公里物流，提高成本效率、交付可靠性并增强可持续性，尤其是在像印度这样的发展中经济体。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08646", "html_url": "https://arxiv.org/abs/2510.08646", "title": "Energy-Driven Steering: 减少大型语言模型中的拒绝响应", "title_en": "Energy-Driven Steering: Reducing False Refusals in Large Language Models", "authors": "Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li", "background": "大型语言模型（LLMs）的安全对齐面临一个关键挑战：当前的对齐技术往往只专注于提高对抗有害提示的安全性，导致LLMs变得过于谨慎，拒绝回应非有害提示。因此，安全对齐的一个关键目标是在提高安全性的同时减少错误拒绝。本文分析了一个新的问题背景，即如何平衡安全性和响应性以减少错误拒绝，特别是在对抗性提示的情况下。", "innovation": "本文提出了一种名为Energy-Driven Steering（EDS）的新颖、无需微调的框架，通过动态的推理时干预来解决上述问题。EDS的核心是在推理阶段引入一个轻量级、外部的能量基模型（EBM），它能够对非期望状态（如错误拒绝或脱逃）分配高能量，对期望状态（如有益的响应或安全拒绝）分配低能量。EDS利用能量函数的梯度动态指导LLM的隐藏状态转向低能量区域，实现实时纠正模型以生成理想的响应，而无需修改模型权重。这种方法分离了行为控制和模型的核心知识，提供了一个灵活且计算成本低的解决方案。", "conclusion": "实验结果表明，EDS方法成功地实现了目标，显著降低了错误拒绝率，例如，在ORB-H基准测试上将合规性从57.3%提高到82.6%，同时保持基准的安全性能。本文提出的方法为构建既能提供低错误拒绝率又具有高安全性的LLMs提供了有效的范式。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08731", "html_url": "https://arxiv.org/abs/2510.08731", "title": "何时推理：vLLM 的语义路由", "title_en": "When to Reason: Semantic Router for vLLM", "authors": "Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen", "background": "大型语言模型（LLMs）通过增强如链式思考和推理时伸缩等推理模式时可以大幅提高准确度。然而，推理也会导致推理延迟和令牌使用量的显著增加，对环境和经济产生影响，这些对于许多简单提示来说是不必要的。本研究提出了一种语义路由器，可以根据查询的推理需求对其进行分类，并仅在需要时应用推理，从而优化了资源的使用。该方法在MMLU-Pro基准测试中实现了10.2个百分点的准确率提升，同时将响应延迟降低了47.1%，令牌消耗减少了48.5%，相较于直接使用vLLM进行推理而言。这些结果表明，语义路由提供了一种有效机制，可在开源LLM服务系统中实现准确性和效率之间的平衡。", "innovation": "提出了一种语义路由器，可以根据查询的推理需求对其进行分类，并仅在需要时应用推理，从而优化了资源的使用，实现了准确率提升与延迟及令牌使用量减少的双重效益。", "conclusion": "语义路由为开源LLM服务系统中准确性和效率之间的平衡提供了一种有效机制。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08755", "html_url": "https://arxiv.org/abs/2510.08755", "title": "使用LLMs的鲁棒启发式算法设计", "title_en": "Robust Heuristic Algorithm Design with LLMs", "authors": "Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani", "background": "研究者们认为可以通过将大规模语言模型（LLMs）与他设计法结合使用，并通过工具来解释启发式算法的表现不足以及提出修复建议，从而生成更鲁棒和高效的启发式算法。", "innovation": "提出了一种新的方法，即在利用LLMs进行启发式设计的过程中，使用解释工具指出启发式表现不佳的原因，并提供改进建议。简单的方法包括将LLMs暴露于表现不佳的实例，解释问题原因，并针对输入空间的特定区域进行设计优化。这种方法相对于现有技术能够显著提高算法的鲁棒性，尤其在最坏情况下的性能提升了约28倍，同时改善了平均性能并且保持了运行时间。", "conclusion": "生成的启发式算法相比FunSearch在最坏情况性能上提高了约28倍，同时也改善了平均性能，并且保持了运行时间。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08750", "html_url": "https://arxiv.org/abs/2510.08750", "title": "探索联邦学习中大型语言模型跨客户端训练数据的记忆化", "title_en": "Exploring Cross-Client Memorization of Training Data in Large Language Models for Federated Learning", "authors": "Tinnakit Udsa,Can Udomcharoenchaikit,Patomporn Payoungkhamdee,Sarana Nutanong,Norrathep Rattanavipanon", "background": "联邦学习（FL）允许通过不共享原始数据的方式进行协作训练。然而，仍然存在训练数据记忆化带来的风险。现有FL的记忆化检测技术主要关注单个样本，未能很好地识别跨样本的记忆化风险。相比之下，集中学习（CL）中已有的技术可以进行细粒度的跨整个训练样本集的记忆化评估，但这些方法的前提是数据必须集中在一处，不能直接应用于FL环境。该研究旨在填补这一空白，通过提出一个新的框架，量化联邦学习中跨客户端和同一客户端内部的数据记忆化情况，利用细粒度的跨样本记忆化测量方法来实现这一目标。", "innovation": "提出了一个新的框架，在联邦学习中利用细粒度的跨样本记忆化测量方法，同时量化了客户端内部和不同客户端之间的数据记忆化情况，填补了现有技术不能直接应用于FL环境的空白。研究还进一步探讨了影响记忆化的关键因素，包括解码策略、前缀长度以及FL算法。", "conclusion": "研究结果表明，联邦学习模型在处理及其训练样本上更容易记忆化，尤其对于同一客户端内部的数据。此外，通过训练和推理等因素影响了记忆化的程度。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08697", "html_url": "https://arxiv.org/abs/2510.08697", "title": "BigCodeArena: 通过执行揭示代码生成中更可靠的人类偏好", "title_en": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "authors": "Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra", "background": "人工评估聊天模型生成的回答质量是至关重要的，尤其是在代码生成领域。然而，手动评估具有挑战性，因为需要理解原始代码的大段内容并模拟代码执行。已有平台，如Chatbot Arena，支持实时的人类评估，但直接应用到代码生成领域仍然存在挑战。为了应对这些挑战，本文引入了一个名为BigCodeArena的代码生成评估平台，该平台提供了全面且即时的代码执行环境，使得人类可以直接与代码生成结果进行交互。该平台覆盖了10种常用大型语言模型，共10种编程语言和8种执行环境，收集了超过14,000个对话会话，从中识别出了超过4,700个涉及人类偏好的多轮对话样本，这些样本为后续的深入分析提供了基础数据。", "innovation": "本文创新性地提出了BigCodeArena平台，该平台基于现有人工评估平台（Chatbot Arena）提升，并专门为代码生成评估设计，支持即时代码执行和人类交互。它不仅集成了理解和生成代码的能力评估，而且还通过分析4,700个对话会话中的偏好，揭示了大型语言模型在代码任务、编程语言和框架细分领域中的详细偏好。此外，基于收集的数据，本文设计并提出了两个新基准测试：一个是评估奖励模型和人类偏好的一致性的BigCodeReward，另一个是自动计算评级的AutoCodeArena，专门用于评估LLM的代码质量而不依赖于人类参与。", "conclusion": "研究证实，大多数顶级的大型语言模型在代码生成中表现出色。尤其是隐私拥有模型（如GPT-5，Claude-Sonnet-4，Claude-Opus-4）在最近涌现出的模型中仍保持领先地位，表明它们在代码生成方面持续具备较强竞争力。这些发现为理解和提升大型语言模型的代码生成能力提供了新的视角和方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08827", "html_url": "https://arxiv.org/abs/2510.08827", "title": "McMining: 自动发现学生代码中的误解", "title_en": "McMining: Automated Discovery of Misconceptions in Student Code", "authors": "Erfan Al-Hossami,Razvan Bunescu", "background": "在学习编程时，学生们经常会形成各种编程概念的误解。这些误解不仅可能导致代码错误或效率低下，还可能拖慢相关概念的学习进度。", "innovation": "本文提出了McMining任务，即从学生代码样本中挖掘编程误解。为了训练和评估McMining系统，开发了一个包含大量误解实例的可扩展基准数据集。此外，还介绍了两种基于LLM的McMiner方法，并通过广泛的评估显示Gemini、Claude和GPT家族的模型在发现学生代码中的误解方面非常有效。", "conclusion": "研究通过开发一种自动化方法来识别编程中的学生误解，展示了LLM在这一领域的潜在应用，为编程教育提供了新的洞见和工具。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08831", "html_url": "https://arxiv.org/abs/2510.08831", "title": "每个人偏好人类作者，包括AI", "title_en": "Everyone prefers human writers, including AI", "authors": "Wouter Haverals,Meredith Martin", "background": "随着AI写作工具的普及，理解人类和机器如何评估文学风格变得尤为重要。文学风格的评估标准难以客观量化，且判断具有主观性。本研究通过雷蒙·克诺叶的《风格练习》实验，测量不同评估者在评判文学片段时的归因偏差。", "innovation": "研究首次详细比较了人类评估者和机器评估者在审美判断中的归因偏差。研究发现，人类在评估时有13.7个百分点的人类偏向（Cohen’s h = 0.28），而AI模型则有34.3个百分点的人类偏向（h = 0.70），表明AI系统的这种偏向是人类人类文化偏见在训练中的反映。", "conclusion": "研究揭示，无论是人类还是AI系统，都存在系统性的偏向人类作者的归因偏差，且AI系统的这种偏向更为显著。这种偏差表明，AI系统不仅复制了人类的这种倾向，甚至在一定程度上放大了这种倾向。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08855", "html_url": "https://arxiv.org/abs/2510.08855", "title": "时间感知特征选择：适应性时间掩蔽在稳定稀疏自编码器训练中的应用", "title_en": "Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training", "authors": "T. Ed Li,Junyu Ren", "background": "理解大型语言模型的内部表示对于确保其可靠性和安全性至关重要。目前，稀疏自编码器（SAEs）作为一种有潜力的可解释性方法正受到关注。然而，现有的SAE训练方法存在特征吸收问题，特征（或神经元）会相互吸收以最小化$L_1$惩罚，这使得一致地识别和分析模型行为变得困难。", "innovation": "本研究提出了适应性时间掩蔽（ATM），这是一种新颖的训练方法，动态调整特征选择，通过追踪激活幅度、频率和重建贡献来计算随着时间演化的权重得分。ATM采用基于统计阈值的概率性掩蔽机制，创建了更自然的特征选择过程。", "conclusion": "通过在Gemma-2-2b模型上的大量实验，证明了ATM相较于现有的方法如TopK和JumpReLU SAEs，吸收得分显著更低，同时保持了优秀的重建质量。这些结果确立了ATM作为学习稳定可解释特征的理论性解决方案的地位，为更可靠的模型分析奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08758", "html_url": "https://arxiv.org/abs/2510.08758", "title": "基于设计的解决方案：语言模型可以太大了吗？", "title_en": "A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?", "authors": "Graham Tierney,Srikar Katta,Christopher Bail,Sunshine Hillygus,Alexander Volfovsky", "background": "许多社会科学问题探讨语言属性如何影响观众的态度和行为。由于文本属性常常彼此关联（例如，愤怒的评论会使用粗俗语言），因此必须控制潜在的混杂因素以隔离因果效应。最近的研究提出采用大型语言模型（LLMs）来学习能够预测治疗和结果的文本隐含表示。然而，由于治疗本身就是文本的一部分，这些深度学习方法存在学习包含治疗本身的表示的风险，从而引发重叠偏差。尽管如此，现有的方法依赖于事后调整。", "innovation": "本文引入了一种新的实验设计，该设计能够处理潜在的混杂因素，避免重叠问题，从而能够无偏估计治疗效果。本文方法在评估表达谦逊在政治沟通中说服力方面的实验中得到了应用。实验结果表明，基于大型语言模型的方法即使使用真实的文本和实验结果，其性能也比简单的词袋模型更差。本文在方法论和实质性发现两方面都有新的见解，为社交媒体平台、政策制定者和社会科学家提供了关于沟通效果的新洞察。", "conclusion": "本文提出了一种新的实验设计，可以处理文本中的潜在混杂因素，避免了重叠偏差，从而无偏估计治疗效果。实验结果表明，基于大型语言模型的方法在某些情况下，其性能不如简单的词袋模型。该设计为理解表达谦逊对政治陈述说服力的影响提供了新的见解，对社交媒体平台、政策制定者和社会科学家都具有重要价值。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08774", "html_url": "https://arxiv.org/abs/2510.08774", "title": "Struc-EMB：语言嵌入中结构感知编码的潜力", "title_en": "Struc-EMB: The Potential of Structure-Aware Encoding in Language Embeddings", "authors": "Shikun Liu,Haoyu Wang,Mufei Li,Pan Li", "background": "大型语言模型（LLMs）生成的文本嵌入在众多应用中已成为基础工具，但这些模型通常仅处理原始文本，忽略了提供关键上下文的结构信息，例如超链接或引文。本文探讨如何将这些结构关系直接整合到LLM的内部编码过程中，以生成结构感知的文本嵌入，这有助于保留关键的上下文信息，从而克服传统方法的局限性。通过广泛的研究实验，证明了结构感知方法在检索、聚类、分类和推荐等任务中均优于文本嵌入和传统的后置处理方法。研究还揭示了策略的有效性差异，如顺序连接在具有噪声的中等长度上下文中表现更佳，而并行缓存则在长且含有丰富信号的上下文中更有效，但也更容易受到干扰因素的影响。为了应对嘈杂的结构数据问题，引入并验证了两种有效方法：Context Distillation和Semantic Balancing，旨在提高嵌入质量。", "innovation": "本文提出了一种新的结构感知嵌入方法，通过将结构关系直接整合到LLM的内部编码过程，而不仅仅是依赖传统的后处理聚合。研究了两种主要的嵌入方法：顺序连接和并行缓存，并通过广泛的零样本实验展示了结构感知嵌入方法在多个任务上的优越性。此外，还提出了两种解决嘈杂结构数据的有效策略：Context Distillation和Semantic Balancing，以提高嵌入技术的稳健性。", "conclusion": "本文提供了对在过程中结构感知编码的首次全面分析，为构建更强大且上下文感知的嵌入模型提供了蓝图。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08878", "html_url": "https://arxiv.org/abs/2510.08878", "title": "ControlAudio: 通过渐进扩散建模解决由文本引导、时间指示和清晰语音的音频生成问题", "title_en": "ControlAudio: Tackling Text-Guided, Timing-Indicated and Intelligible Audio Generation via Progressive Diffusion Modeling", "authors": "Yuxuan Jiang,Zehua Chen,Zeqian Ju,Yusheng Dai,Weibei Dou,Jun Zhu", "background": "文本到音频（TTA）生成在近年来的研究中得到了探索，尤其是在包含精确时间控制或清晰语音内容的细粒度控制信号方面。然而，由于数据稀缺性的影响，这些方法在大规模生成中的性能仍然受到限制。", "innovation": "该研究将可控制的文本到音频生成重新定义为一个多任务学习问题，并引入了一种名为ControlAudio的渐进扩散建模方法。通过分步策略，该方法有效地拟合了基于更细粒度信息（包括文本、时间以及音素特性）的分布。研究首先提出了一种数据构建方法，扩展了条件信息的序列（包括文本、时间和音素），并在模型训练阶段，使用大规模的文本-音频对进行预训练，实现了可扩展的TTA生成，然后逐步加入时间与音素特征。", "conclusion": "大量实验表明，ControlAudio在时间准确性与语音清晰度方面达到了最先进的性能，综合目标与主观评估，显著优于现有方法。演示样本可在指定URL找到。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08867", "html_url": "https://arxiv.org/abs/2510.08867", "title": "ReviewerToo：AI是否应加入程序委员会？一个关于未来同行评审的展望", "title_en": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review", "authors": "Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal", "background": "同行评审是科学出版的基石，但面临着不一致性、审稿人主观性和可扩展性的挑战。本文探讨并引入了ReviewerToo框架，该框架旨在通过系统性和一致性评价补充人类判断，辅助AI辅助同行评审。ReviewerToo支持根据专门的审稿人角色和结构化评估标准进行系统性实验，并可以部分或完全集成到实际的会议工作流程中。", "innovation": "提出ReviewerToo模块化框架，用于研究和支持AI辅助同行评审。该框架通过使用gpt-oss-120b模型在仔细选择的ICLR 2025数据集中进行实验，证明了其在论文接受/拒绝分类任务上的准确率达到81.8%，略低于人类平均审稿人的83.9%。生成的审稿人评论在LLM评审员的评级中被认为质量更高，但仍不及最强专家的贡献。分析指出了AI审稿人表现出色（例如事实核查、文献覆盖）和遇到困难的领域（例如评估方法创新性和理论贡献），强调了持续的人类专业知识需求。", "conclusion": "基于这些发现，提出了将AI集成到同行评审流程中的指导方针，展示了AI如何增强一致性和覆盖面，同时让复杂的评判性判断留给领域专家。本文为系统化、混合型同行评审系统的建立提供了基础，这些系统将随着科学研究的增长而扩展。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08896", "html_url": "https://arxiv.org/abs/2510.08896", "title": "HES-SQL：结构化骨架指导下的高效文本到SQL的混合推理", "title_en": "HES-SQL: Hybrid Reasoning for Efficient Text-to-SQL with Structural Skeleton Guidance", "authors": "Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun", "background": "本文介绍了HES-SQL，这是一种新颖的混合训练框架，通过将思考模式融合的监督微调（SFT）与组相对策略优化（GRPO）相结合，推动了文本到SQL生成的进步。该框架旨在通过执行感知强化学习有效平衡语义准确性和计算效率。", "innovation": "该框架引入了三个关键创新：(1) 基骨完整性评分机制，提高了生成查询与最优SQL结构之间偏好的对齐；(2) 计算延迟感知奖励系统，激励生成计算效率高的SQL查询；(3) 思考模式完成的自我精炼过程，防止模型推理能力退化。", "conclusion": "实验评估显示，在MySQL 8.0和SQLite 3.42在单用户控制条件下，HES-SQL在BIRD和KaggleDBQA基准上的执行准确率分别为79.14%和54.9%，效率提升范围为11%至20%。这些结果表明，HES-SQL为平衡语义准确性和计算效率的文本到SQL系统提供了一个新范式。提出的思路特别是对于开发鲁棒的自然语言数据库接口具有重要意义，并可用于需要正确性和效率优化的更广泛的结构化生成任务。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08966", "html_url": "https://arxiv.org/abs/2510.08966", "title": "Semantic-Condition Tuning: 将图上下文与大型语言模型融合以完成知识图谱", "title_en": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion", "authors": "Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li", "background": "知识图谱的填充任务对于知识密集的任务至关重要。目前流行的前缀调整方法简单地将知识嵌入与文本输入进行拼接，但这种方法忽视了知识图谱中的丰富关系语义，并给大型语言模型带来了显式的推理负担，使其难以将前缀与文本关联起来。", "innovation": "提出了语义条件调整（SCT），这是一种新的知识注入范式，包括两个关键模块。首先，语义图模块使用图神经网络从局部图邻域中提取上下文感知的语义条件，这些条件由知识增强的关系引导。然后，此条件传递给条件自适应融合模块，该模块又通过两个参数化的投影器自适应地调节文本嵌入，从而实现深层次、特征级的知识感知交互。预融合的嵌入被输入到大型语言模型中进行微调。", "conclusion": "在知识图谱基准测试中的广泛实验表明，SCT 显著优于前缀调整和其他强大的基线。我们的分析表明，在大型语言模型推断之前，通过语义图上下文调整输入表示，SCT 提供了更为直接和强大的信号，从而实现更准确和稳健的知识推理。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08964", "html_url": "https://arxiv.org/abs/2510.08964", "title": "Unleashing Perception-Time Scaling to Multimodal Reasoning Models", "title_en": "Unleashing Perception-Time Scaling to Multimodal Reasoning Models", "authors": "Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu", "background": "近期，在推理时对LVLMs进行缩放的进展，尤其是在利用强化学习和可验证奖励方面，极大地增强了LVLMs的推理能力。受到了这一成果的启发，人们尝试将类似策略应用于多模态推理，但这些策略对视觉感知的影响尚未明确。为了探索这一差距，研究者引入了DisTANCE基准测试，用于视觉估计算法的评估。评估结果显示，LVLMs在估计算法上的精度不高，并且推理时的缩放对这些算法仅有微小的改进。研究表明，当前LVLMs采用快速感知模式，将视觉理解视为一次性输出，未建模感知过程。", "innovation": "研究提出了一种新的感知-时间缩放（PTS）范式，鼓励丰富感知过程中使用更多感知相关标记，并将复杂感知问题分解为中间可处理的子问题，旨在让感知过程能够与推理时缩放同步并从其中获益。结合强化学习技术，PTS显著提高了感知精度，在DisTANCE中高精度性能从8.0%提升到了64.7%，并且具有良好的跨域任务泛化能力。值得注意的是，尽管PTS数据全部为合成数据，但与数学推理数据结合后，在推理和现实感知基准测试中仍能取得一致的性能提升。进一步分析还发现，PTS增加了模型对图像标记的关注，并引入了更多与感知相关的标记。", "conclusion": "综上所述，研究提出了一种新的感知-时间缩放策略，该策略能够显著提高LVLMs在视觉感知上的精度，并且对不同类型的任务均表现出良好的泛化能力。未来工作将释放相关代码和数据，以便进一步研究和开发。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09008", "html_url": "https://arxiv.org/abs/2510.09008", "title": "关于Large Vision-Language模型中视觉tokens的先验不确定性与物体幻觉", "title_en": "On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models", "authors": "Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun", "background": "大型视觉-语言模型（LVLMs）将视觉编码器（VE）与大型语言模型结合，已经在多种任务中取得了显著的成功，但仍然存在一些关键挑战，例如物体幻觉，即生成输入图像中不存在的物体的描述。", "innovation": "本文提出了一个简单有效的策略来减轻物体幻觉。通过统计分析发现，具有高先验不确定性的视觉token与物体幻觉的发生正相关，并通过理论和实验证明了在小对抗扰动下早期VE层中表现出大面积表示偏差的visual tokens表明了高先验不确定性。基于这一发现，本文提出了一个方法，包括一个带有对抗扰动的代理方法，用于高效识别不确定视觉tokens，和一个在VE中间层的自我注意过程中遮蔽这些不确定视觉tokens的方法，减弱其对视觉编码的影响，从而减轻幻觉。", "conclusion": "大量实验表明，该方法显著减少了LVLM中的物体幻觉，并可以与其他先有技术协同工作。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09038", "html_url": "https://arxiv.org/abs/2510.09038", "title": "Auto-scaling Continuous Memory for GUI Agent", "title_en": "Auto-scaling Continuous Memory for GUI Agent", "authors": "Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang", "background": "先前的GUI代理通过文本标记压缩过去的轨迹，这增加了上下文长度并遗漏了关键的视觉线索（如精确的控件大小和位置）。这些限制了代理在不熟悉界面和长期任务中的泛化能力。", "innovation": "本文提出了一种连续记忆方法，通过视觉语言模型直接将每个GUI轨迹编码为固定长度的连续嵌序列，并直接插入模型的输入层，从而降低上下文成本同时保留细粒度的视觉信息。该方法随记忆大小和检索深度增加，性能呈单调提升趋势。同时引入了一种自动调节数据飞轮，包括环境搜索、任务合成、轨迹执行和结果验证，以低成本扩展记忆。", "conclusion": "在现实世界的GUI基准测试中，本文提出的方法增强的代理在长时段和分布移位下的一致性成功率改善明显。通过仅对记忆编码器进行微调（LoRA在Q-Former上，参数量1.2%），Qwen-2.5-VL-7B与连续记忆的性能达到了与市面上领先的闭源模型（如GPT-4o，Claude-4）相当的水平。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09201", "html_url": "https://arxiv.org/abs/2510.09201", "title": "多模态提示优化：为什么不用多种模态来增强LLM？", "title_en": "Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs", "authors": "Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang", "background": "大规模语言模型（LLMs）已经取得了显著的成功，其多模态扩展（MLLMs）进一步解锁了包括图像、视频及其他非文本模态在内的能力。然而，尽管如此，现有的提示优化方法仍然局限于文本，无法充分利用MLLMs的全部潜力。", "innovation": "本文提出了一个多模态提示优化的新问题，将提示优化的定义扩展到由文本和非文本提示组成的多模态空间。提出了一种名为Multimodal Prompt Optimizer (MPO)的统一框架，通过保留对齐的更新进行多模态提示的联合优化，并利用基于贝叶斯的先验选择策略来指导候选提示的选择。实验结果表明，MPO在多种模态上优于仅针对文本的领先优化方法，证明了多模态提示优化对实现MLLMs潜力的重要性。", "conclusion": "通过广泛的实验，证实了MPO在多模态空间中的有效性，证明了多模态提示优化是实现MLLMs潜力的关键步骤。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09093", "html_url": "https://arxiv.org/abs/2510.09093", "title": "利用AI代理的网络搜索工具进行数据泄露", "title_en": "Exploiting Web Search Tools of AI Agents for Data Exfiltration", "authors": "Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz", "background": "大型语言模型（LLMs）现在被广泛用于自主执行复杂任务，从自然语言处理到动态工作流如网络搜索。工具调用和检索增强生成（RAG）的使用，允许LLMs处理和检索敏感的企业数据，增强了它们的功能性同时也增加了被滥用的风险。随着LLMs越来越多地与外部数据源交互，间接提示注入成为一种关键且不断演化的攻击向量，使对手能够通过操纵输入来利用模型。", "innovation": "通过系统评估不同模型的间接提示注入攻击，分析当前LLMs对这类攻击的易感性，探讨模型大小、制造商、特定实现等因素如何影响其脆弱性，并确定哪种攻击方法仍然最有效。结果显示，即使众所周知的攻击模式仍然有效，这揭示了模型防御中的持续漏洞。为了应对这些漏洞，提出需要加强训练流程以增强固有韧性、建立已知攻击向量的中央数据库以实现主动防御，并建立统一的测试框架以确保持续的安全验证。这些步骤对于推动开发者在LLM的核心设计中整合安全措施至关重要。", "conclusion": "当前模型仍未有效地缓解长期存在的威胁，强调有必要加强训练流程以增强固有韧性，建立已知攻击向量的中央数据库并确保安全验证，从而促使开发者在LLM的核心设计中整合安全措施。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09225", "html_url": "https://arxiv.org/abs/2510.09225", "title": "从语音中无监督学习词典受限于表示而不是聚类", "title_en": "Unsupervised lexicon learning from speech is limited by representations rather than clustering", "authors": "Danel Adendorff,Simon Malan,Herman Kamper", "background": "无标注词汇分割和聚类系统旨在在缺乏文本标签的情况下将语音分割成类似于单词的单元。尽管取得了进展，但生成的词典仍然远非完美。我们假设，在具有真实词汇边界的理想环境中，性能是受到词片段表示的影响还是受到聚类方法的影响。", "innovation": "研究结合了一系列自监督的语音特征（连续/离散，帧/单词级别）以及不同的聚类方法（K-means、层次、图谱），针对英语和汉语数据进行实验。最佳系统使用动态时间规整（DTW）在连续特征上的图聚类。更好的替代方案包括使用余弦距离在连续特征平均值上的图聚类，或在离散单元序列上使用编辑距离的图聚类。研究通过控制实验分离表示和聚类方法，展示了同一词类内的词片段表示的变化是影响性能的主要因素。", "conclusion": "表示的差异性而不是聚类方法是限制性能的主要因素。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08977", "html_url": "https://arxiv.org/abs/2510.08977", "title": "诊断和缓解自我奖励RL中的系统偏差", "title_en": "Diagnosing and Mitigating System Bias in Self-Rewarding RL", "authors": "Chuyi Tan,Peiwen Yuan,Xinglin Wang,Yiwei Li,Shaoxiong Feng,Yueqi Zhang,Jiayi Shi,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li", "background": "当前，强化学习通过验证奖励（RLVR）提升大语言模型（LLMs）的推理能力，但受限于有限的标记样本无法持续扩大数据规模。内部奖励强化学习（RLIR）允许策略模型为其自身卷出结果打分，能够实现无标记环境下的可持续扩展，但由于其性能和稳定性落后于RLVR，该领域仍存在问题缺口。研究表明，模型容易高估其高可信度的卷出结果，这种偏差会随着训练进行累积，导致与理想结果的背离趋向于过度奖励，从而使训练不稳定。为了表征这一偏差，研究者使用了三个指标：噪声量度（$\rho_{\text{noise}}$）、自我偏差量度（$\rho_{\text{selfbias}}$）和符号偏差量度（$\rho_{\text{symbias}}$）。通过实验发现，$\rho_{\text{noise}}$ 和 $\rho_{\text{symbias}}$ 影响收敛性，而 $\rho_{\text{selfbias}}$ 则放大了正确的和错误的更新，导致系统不稳定。为解决此问题，提出了一种增强聚合奖励的强化学习方法（RLER），通过汇总多样性模型并自适应调整奖励插值和卷出选择来缓解这个问题。", "innovation": "本研究提出了增强聚合奖励的强化学习方法（RLER），通过汇总多样性模型并调整奖励插值和卷出选择，来解决自我奖励RL中的系统偏差问题。实验结果表明，RLER 的性能比RLIR提高了13.6%，并且接近RLVR 的表现，实现了在无标记样本上的稳定扩展，具有很高的实际应用价值。", "conclusion": "通过缓解自我奖励RL中的系统偏差，研究证明了RLER不仅在稳定性上有显著提升，还能够在无标记数据上实现接近RLVR的性能表现，为未来的无监督训练提供了一种有效的方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09307", "html_url": "https://arxiv.org/abs/2510.09307", "title": "多说话人录音中的目标说话人匿名化", "title_en": "Target speaker anonymization in multi-speaker recordings", "authors": "Natalia Tomashenko,Junichi Yamagishi,Xin Wang,Yun Liu,Emmanuel Vincent", "background": "现有的大多数说话人匿名化研究集中在单说话人音频上，导致开发了针对这种状况的技术和评价标准。然而，在多说话人对话音频中实现说话人匿名化，特别是只匿名单个目标说话人的挑战尚未得到充分解决。现有的评价方法无法准确评估这种复杂多说话人场景中的隐私保护和实用性。这些都是研究背景，表明现有研究和技术的局限性。", "innovation": "该研究聚焦于多说话人对话音频中的目标说话人匿名化，并提出了一种新的策略，有效解决了适用的隐私保护和实用性问题。相比传统的匿名化方法，该研究提出的方法更适用于只匿名单个目标说话人的场景。此外，研究还提出了改进的评价方法，能够更准确地评估该复杂多说话人场景下的隐私保护和实用性。", "conclusion": "该研究探索了在对话音频中进行目标说话人匿名化的有效策略，指出了这些策略开发中潜在的问题，并提出了相应的改进评价方法，填补了现有研究在多说话人场景中的空白，为未来的匿名化研究和技术发展提供了参考。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09230", "html_url": "https://arxiv.org/abs/2510.09230", "title": "使用多模态大型语言模型和消费级摄像头诊断肩部疾病", "title_en": "Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras", "authors": "Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun", "background": "肩部疾病，如冻结肩（又称粘连性肩周炎），是全球范围内广泛影响人们健康的问题，老年人以及从事重复性肩部任务的工作人群发病率较高。在医疗资源稀缺的地区，实现早期和准确的诊断存在显著挑战，迫切需要低成本且易于扩展的辅助诊断解决方案。", "innovation": "该研究利用由消费级设备拍摄的视频作为诊断基础，提出了一种名为Hybrid Motion Video Diagnosis框架（HMVDx）的创新方法，通过分阶段将动作理解与疾病诊断任务分别交由两个多模态大型语言模型完成。此外，还提出了一个新的可使用指数（Usability Index）作为评价指标，不仅考虑传统指标，还从整个医疗诊断流程的角度评估MLLMs的有效性，揭示了低成本MLLMs在医疗应用中的潜在价值。相较于直接视频诊断，HMVDx在诊断肩关节损伤的准确性提高了79.6%，对医疗领域视频理解应用的未来研究有显著技术贡献。", "conclusion": "该研究通过提出Hybrid Motion Video Diagnosis框架及新颖的可使用指数（Usability Index），在医疗领域实现了低成本且有效的初步肩部疾病诊断方法，并显著提高了诊断准确性，这为未来利用MLLMs在医疗视频理解领域的应用研究奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09316", "html_url": "https://arxiv.org/abs/2510.09316", "title": "大型语言模型提示数据集：深入分析和见解", "title_en": "Large Language Model Prompt Datasets: An In-depth Analysis and Insights", "authors": "Yuanming Zhang,Yan Lin,Arijit Khan,Huaiyu Wan", "background": "随着大型语言模型（LLM）的日益部署，来自平台如GitHub和社交媒体的多样化提示数据集正不断涌现。这些数据集涵盖了广泛的应用和内容类型，促进了LLM更广泛的利用和更好的提示工程。已有工作报道了不同的提示数据集，但这是首次系统地总结这些数据集，涵盖下游任务、语言、工程技术和模态多样性。通过分析不同类别的提示构造，发现提示和传统文本语料库（如文献和网络文本相比）的共性和差异，为提示优化提供了新的视角。", "innovation": "本文首次系统地汇集并分析了来自各种渠道的提示数据集，明确了不同类型的提示变化特征，并提出了一种基于语法嵌入（部分词性及其依赖结构）的提示优化方法。这种方法通过确定提示的重心表示，并引导LLM重新编写提示朝向该重心，从而提高了模型输出的意义性。此外，作者还提供了这些数据集和代码的开放访问。", "conclusion": "文章提出了一种新的提示数据集分析框架，并提供了一种有效的提示优化策略，以提高大规模语言模型的输出质量。这将促进LLM的更广泛应用和更好的提示工程。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09302", "html_url": "https://arxiv.org/abs/2510.09302", "title": "CapGeo: 一种辅助生成描述的几何推理方法", "title_en": "CapGeo: A Caption-Assisted Approach to Geometric Reasoning", "authors": "Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang", "background": "几何推理依然是多模态大型语言模型（MLLMs）的核心挑战。即使像GPT-O3和Gemini-2.5-Pro这样的高级闭源系统，在解决几何问题方面仍然表现不佳，尽管它们在国际数学奥林匹克（IMO）等任务中的文本推理能力很强。这表明瓶颈在于理解几何图示，而不仅仅是推理能力。几何图形通常可以通过简洁的文字描述来准确表达，因此将视觉内容转换为描述性文字，为解决这个问题提供了一个可能的途径。考虑到这一点，作者提出了一种称为CapGeo的辅助描述的推理框架，将视觉和文本模态结合起来。实验表明，在模型配备描述文字的情况下取得了显著的改进：Qwen2.5-VL-72B在纯视觉输入时从8.6%提高到59.0%，Claude-Opus-4则从44.8%提高到73.0%。为了系统地评估并识别高质量的几何描述模型，作者还提出了一个名为CapGeo-Bench的数据集，其中包括4,641个精心策划的图示-描述对。这个数据集的关键点评价指标与后续的CapGeo性能密切相关，能够可靠地评估几何描述的能力。在这篇论文中，作者的框架和基准数据集揭示了一条提升MLLMs中几何推理的新途径。\n", "innovation": "作者提出了一种名为CapGeo的辅助描述的推理框架，通过将视觉内容转换为描述性文字，将视觉和文本模态结合起来。此外，作者还提出了一种称为CapGeo-Bench的基准数据集，用于系统地评估和识别高质量的几何描述模型，并引入了一种关键点为基础的评价指标，与后续的CapGeo性能密切相关，能够可靠地评估几何描述的能力。\n", "conclusion": "作者的框架和基准数据集揭示了在MLLMs中提升几何推理的一个新的可能方向。研究表明，通过将视觉内容转换为描述性文字，可以显著提高模型在几何问题上的推理能力，并提出了一个新的评价指标，便于可靠地评估几何描述的质量。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09388", "html_url": "https://arxiv.org/abs/2510.09388", "title": "HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness", "title_en": "HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness", "authors": "Xinyi Wang,Jinyi Han,Zishang Jiang,Tingyun Li,Jiaqing Liang,Sihang Jiang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao", "background": "目前，强化学习（RL）是提升大型语言模型（LLMs）长链思考（CoT）推理能力的关键驱动力。然而，现有方法如GRPO在任务难度超过模型能力时经常失效，导致奖励稀疏和训练效率低下。尽管先前的工作尝试通过使用离策数据来减轻这些问题，如结合监督微调（SFT）或使用提示，但这些方法往往会误导策略更新。作者们指出，导致这些问题的根本问题是训练亲和力低，这是由于外部指导与模型策略之间存在较大的分布性不匹配。因此，需要一种方法来诊断和改善这种情况。", "innovation": "为了解决这个问题，作者们提出了HINT（帮助无效滚动学习走向有效性），一种自适应提示框架。HINT提供的是启发式提示，而不是直接答案，旨在引导模型自主发现解决方案，同时保留其自主推理能力。在数学推理任务的广泛实验中，HINT表现出色，超越了现有方法，即使对于不同规模的模型也能取得最新的成果，并且显示出更稳定的训练和更多的数据利用能力。这些结果已经整理发布在GitHub上。", "conclusion": "HINT通过提供启发式提示来帮助模型自主寻找解决方案，提高了训练亲和力，从而显著改善了模型的长期链思考推理能力，尤其是在难以完成的任务中。这种方法不仅增强了模型的表现，还提高了其学习的稳定性和数据效率。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.06212", "html_url": "https://arxiv.org/abs/2305.06212", "title": "大型语言模型服务中的隐私保护高效微调", "title_en": "Privacy-Preserving Parameter-Efficient Fine-Tuning for Large Language Model Services", "authors": "Yansong Li,Zhixing Tan,Paula Branco,Yang Liu", "background": "PEFT提供了一种实用的方法，使用户能够使用其私有数据定制大型语言模型（LLMs）。然而，私有数据的内在敏感性要求在定制LLM服务时采取 robust 的隐私保护措施，以确保数据安全、维护用户信任并遵守严格的监管标准。", "innovation": "提出了Privacy-Preserving Parameter-Efficient Fine-Tuning (RAPT)框架，采用局部隐私方法，让用户能够通过文本到文本的局部差分隐私机制本地私有化其数据。尽管框架简单，但在任务上表现出与标准模型相当的性能，同时提供了针对对手的隐私保证。引入了 privatized token reconstruction task，该任务与下游任务联合训练，使LLMs能够学习更好的任务特定表示，从而改善MSAT（最小化顺序准确度损失）和图表理解性能，而不会在原始任务上面临最大限度的Msat损耗（0.46-0.66）", "conclusion": "实验表明，RAPT在多种任务上实现了竞争性能，同时提供了针对对手的隐私保证。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09595", "html_url": "https://arxiv.org/abs/2510.09595", "title": "LiveOIBench: 大型语言模型能在信息学奥林匹克竞赛中击败人类参赛者吗？", "title_en": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "authors": "Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang", "background": "随着编程竞赛问题被用作评估大语言模型（LLMs）编码能力的重要基准，当前的编码测试规模存在缺乏极其具有挑战性的问题、测试用例覆盖率不足以及依赖于受限于访问性的在线平台API等问题。", "innovation": "LiveOIBench 通过提供403个来自72个不同地区信息学奥林匹克官方竞赛的专家精心挑选的问题，这些问题每题平均有60个专家设计的测试案例，来解决这些问题。LiveOIBench 的四个关键特性包括：精心挑选的任务，包含详细的子任务规范和大量私人测试案例；直接整合顶尖参赛者的性能数据以与顶级人类参赛者进行有意义的比较；规划持续不断的更新，基于新发布的奥林匹克问题；以及一个独立的评估系统，便于离线和易于复现的评估。", "conclusion": "在对32个流行的通用和推理LLMs进行基准测试后，发现GPT-5获得了显著的第81.76百分位，尽管其表现强劲，但未能超越顶级人类参赛者通常位于的第90百分位以上。相比之下，开放权重的推理模型GPT-OSS-120B仅获得第60百分位，突显了与前沿封闭模型之间的重要能力差距。详细的分析表明，稳健的推理模型更倾向于精确的问题分析，而非过度探索，这表明未来的模型应该强调结构化的分析和减少不必要的探索。所有数据、代码和排行榜结果将在网站上公开提供。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.20179", "html_url": "https://arxiv.org/abs/2405.20179", "title": "Robo-Instruct: 模拟器增强指令对齐以微调代码LLMs", "title_en": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs", "authors": "Zichao Hu,Junyi Jessy Li,Arjun Guha,Joydeep Biswas", "background": "代码生成的LLMs在将自然语言任务转换为可由服务机器人执行的程序方面取得了显著成果。然而，为每个服务机器人收集特定的任务-程序对数据集耗时且昂贵。尽管 SELF-INSTRUCT 和 EVOL-INSTRUCT 等方法能够生成新颖的任务，但它们无法提供符合物理世界和机器人约束的正确程序。使用模拟器是检查此类约束的一个自然解决方案，但构建能够处理任意任务及其所需对象和位置的模拟环境具有挑战性。", "innovation": "ROBO-INSTRUCT 系统在程序执行过程中实时生成特定任务的模拟环境，通过按需推断实体属性并基于其在任务程序中的使用情况强制执行相应的约束。此外，ROBO-INSTRUCT 结合了LLM辅助的后处理过程，以提高指令与机器人程序的对齐度。", "conclusion": "我们展示了 ROBO-INSTRUCT 在多种LLMs上的有效性，显示了微调模型超过了所有基准方法，并且甚至与一些更大且专有的模型相当或超越其性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09608", "html_url": "https://arxiv.org/abs/2510.09608", "title": "StreamingVLM: 实时理解无限视频流", "title_en": "StreamingVLM: Real-Time Understanding for Infinite Video Streams", "authors": "Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han", "background": "视觉-语言模型（VLMs）能够驱动实时助手和自主代理，但它们面临一个关键挑战：如何理解近无限的视频流而不导致延迟和内存使用量的上升。处理整个视频需要完全的注意力，这会导致计算成本急剧增加，并且在处理长视频时表现不佳。同时，简单的滑动窗口方法也有其局限性，要么破坏连贯性，要么由于冗余的重新计算而导致高延迟。为了解决这一问题，本文引入了StreamingVLM，一种专为实现无限视觉输入的实时稳定理解设计的模型。", "innovation": "本文提出了一种新的方法，StreamingVLM具有一个统一的框架，使得在训练与流式推理之间保持一致性。该模型通过在简短、重叠的视频片段上应用全注意力来施加一种简单的监督微调（SFT）策略，从而模仿推理时的注意模式，避免训练在极长的上下文上。此方法能在保持实时性能的同时，处理平均超过两个小时的长视频。此外，SFT策略还增强了通用的VQA能力，不依赖于任何特定的VQA微调，提高了LongVideoBench和OVOBench Realtime的表现。", "conclusion": "本文通过构建名为Inf-Streams-Eval的新基准，评估了StreamingVLM在处理长视频时的有效性和实时性能。在Inf-Streams-Eval上，StreamingVLM实现了66.18%的胜率，相比于GPT-4O mini，保持了在单块NVIDIA H100上8 FPS的稳定实时性能。同时，通过简单的SFT策略，实现了提升VQA能力的效果，增强了LongVideoBench和OVOBench Realtime的性能，且无需额外的VQA微调。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09415", "html_url": "https://arxiv.org/abs/2510.09415", "title": "使用自然主义MEG-fMRI编码模型以高空间和时间分辨率估计大脑活动", "title_en": "Estimating Brain Activity with High Spatial and Temporal Resolution using a Naturalistic MEG-fMRI Encoding Model", "authors": "Beige Jerry Jin,Leila Wehbe", "background": "目前的无创神经影像技术在空间分辨率和时间分辨率之间做出权衡。磁源成像（MEG）能够捕捉快速的神经动态，而功能性磁共振成像（fMRI）则能够空间定位大脑活动。尽管存在这些技术，但如何在同一数据集中同时保留高空间和时间分辨率的统一图景仍然是一个未决挑战，尤其是在单试次自然数据处理中。本文作者通过无创实验收集了听故事时的全头皮MEG数据，并结合开放fMRI数据集（LeBel et al., 2023），展示了如何解决这一问题。", "innovation": "本文提出了一个基于变压器的编码模型，该模型将来自MEG和fMRI的数据结合起来，为自然听测试实验中的单试验自然语言理解估计潜在皮层源反应，具有高空间和时间分辨率。模型的创新之处在于其训练方式：不仅预测MEG和fMRI数据，还在多个被试上同时训练，并用潜在层表示重建的皮层源估计。实验结果表明，该模型在预测MEG数据方面优于单模态编码模型，并且在模拟实验中也比经典最小范数解提供了更高的空间和时间保真度。", "conclusion": "通过整合大规模自然实验、MEG、fMRI和编码模型，本文提出了实现毫秒和毫米空间分辨率的大脑成像可行方案，模型估计的源活动在新数据集中的ECoG预测中也表现出高度的一致性，进一步证明了其通用性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12444", "html_url": "https://arxiv.org/abs/2410.12444", "title": "利用大型语言模型实现合规保障的客户服务聊天机器人：基于上下文的知识扩展", "title_en": "Augmenting Compliance-Guaranteed Customer Service Chatbots: Context-Aware Knowledge Expansion with Large Language Models", "authors": "Mengze Hong,Chen Jason Zhang,Di Jiang,Yuanqin He", "background": "检索型聊天机器人利用经过人工验证的问题与答案知识库，提供准确、可验证的响应，特别适用于需要遵守监管和运营标准的以客户为中心的应用程序。为了有效地处理多样化的客户咨询，通过增加“相似的问题”来扩充知识库，这种策略能够在保持语义一致性的同时增加表达的多样性，从而降低成本。", "innovation": "本文介绍了相似问题生成（SQG）任务，提出了上下文感知的方法，以充分扩展语义探索并增强与源问题-答案关系的对齐。研究了构建上下文提示的优化技术，并在预算约束下选择最佳的相似问题子集以扩展聊天机器人的知识。通过定量和人类评估验证了方法的有效性，部署聊天机器人系统的用户满意度率为92%，相较于不扩充知识库的基线提高了18%。", "conclusion": "这些发现突显了SQG的实际益处，并强调了大型语言模型的作用不只是直接的聊天机器人接口，它们在支持非生成系统实现无幻觉、确保合规的应用中具有潜在价值。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.01605", "html_url": "https://arxiv.org/abs/2412.01605", "title": "MedChain：通过交互序列连接大型语言模型代理与临床实践", "title_en": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice with Interactive Sequence", "authors": "Jie Liu,Wenxuan Wang,Zizhan Ma,Guolin Huang,Yihang SU,Kao-Jung Chang,Wenting Chen,Haoliang Li,Linlin Shen,Michael Lyu", "background": "临床决策（CDM）是医疗保健交付中至关重要的复杂动态过程，但人工智系统仍面临巨大挑战。现有的基于大型语言模型（LLM）的智能代理在一般医学知识测试中的表现良好，但在实际临床场景中的CDM能力有限，主要是由于缺乏能够反映实际医疗实践的全面测试数据集。", "innovation": "该研究介绍了MedChain，这是一个包含12,163例临床病例的数据集，涵盖了临床工作流程的五个关键阶段，并具有个人化、互动性和序列性的三大特点。此外，还提出了MedChain-Agent，一种结合了反馈机制和MCase-RAG模块的AI系统，能够从过去案例中学习并适应其回答，显示出在动态信息收集和处理序列性临床任务方面的显著适应能力，优于现有方法。", "conclusion": "MedChain-Agent在实际临床决策挑战中表现突出，能够有效填补大型语言模型代理与真实临床实践之间的差距。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.19638", "html_url": "https://arxiv.org/abs/2407.19638", "title": "关于大型语言模型在因果发现中的可靠性", "title_en": "On the Reliability of Large Language Models for Causal Discovery", "authors": "Tao Feng,Lizhen Qu,Niket Tandon,Zhuang Li,Xiaoxi Kang,Gholamreza Haffari", "background": "该研究探讨了大型语言模型（LLMs）在因果发现中的效果。使用新发布的开源LLMs，OLMo和BLOOM，这些模型提供了其预训练语料库的访问权限，研究者通过三个研究问题调查了LLMs在处理因果关系方面的表现：（i）记忆对准确预测因果关系的影响，（ii）预训练数据中的不正确因果关系对LLMs的影响，以及（iii）影响LLMs理解因果关系的语境细微差别。研究发现，虽然LLMs在识别频繁出现在预训练数据中的因果关系方面非常有效，但在处理新的或罕见的因果关系时，其能力有限。此外，不正确的因果关系显著降低了LLMs对相应正确因果关系的自信程度，而上下文信息对LLMs判断随机变量之间的因果联系至关重要。", "innovation": "该研究使用了新发布的开源LLMs（OLMo和BLOOM），并针对因果发现进行了专门的研究，通过三个具体的研究问题深入探讨了LLMs在因果发现中的表现和限制。它特别关注了记忆效果、预训练数据中的错误因果关系以及上下文因素对LLMs识别因果关系的影响，这为理解LLMs在因果发现中的局限性和优化提供了新的见解。", "conclusion": "尽管LLMs在识别频繁出现的因果关系方面表现出色，但它们在处理新或罕见因果关系时的能力有限，且不正确的因果关系显著影响了LLMs对正确因果关系的信心。同时，上下文信息对LLMs成功区分因果关系至关重要。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.23684", "html_url": "https://arxiv.org/abs/2410.23684", "title": "不可能双词揭示字节级分词器中不完整令牌的漏洞", "title_en": "Improbable Bigrams Expose Vulnerabilities of Incomplete Tokens in Byte-Level Tokenizers", "authors": "Eugene Jang,Kimin Lee,Jin-Woo Chung,Keuntae Park,Seungwon Shin", "background": "分词是将人类可读的文本转换为模型可读的离散令牌的关键步骤。然而，最近的研究表明，分词器可以被利用以诱导模型的不良行为。本文研究了不完整令牌，即由字节级字节对编码（BPE）分词导致的无法解码令牌，这些令牌中包含有错位的字节。研究者假设这些令牌非常依赖于其相邻的令牌，并且在与不熟悉的令牌配对时是脆弱的。", "innovation": "引入了不可能双词的概念，这是一种经过设计的不完整令牌的组合，旨在利用它们的依赖性。实验结果表明，不可能双词容易产生幻觉行为。令人惊讶的是，使用替代分词方法时，相同短语的幻觉频率显著降低（在Llama3.1中减少了90%）。这一发现提醒人们注意字节级BPE分词器可能带来的潜在漏洞，这些漏洞可能会使语言模型产生盲点。", "conclusion": "建议应关注字节级BPE分词器引入的潜在漏洞，这些漏洞可能会使语言模型产生盲点。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04784", "html_url": "https://arxiv.org/abs/2412.04784", "title": "NLP-ADBench: NLP Anomaly Detection Benchmark", "title_en": "NLP-ADBench: NLP Anomaly Detection Benchmark", "authors": "Yuangang Li,Jiaqi Li,Zhuo Xiao,Tiankai Yang,Yi Nian,Xiyang Hu,Yue Zhao", "background": "异常检测（AD）在欺诈检测、内容管理、用户行为分析等方面具有重要的机器学习应用，但在自然语言处理（NLP）的背景下研究相对较少，这限制了其在检测有害内容、钓鱼尝试和垃圾评论等任务上的有效性。", "innovation": "该论文提出了迄今为止最全面的NLP异常检测基准——NLP-ADBench，包含八个精心挑选的数据集和19种最先进的算法。这涵盖了3种端到端的方法和16种两步方法，这些方法将经典非AD方法适应了BERT和OpenAI的语言嵌入。实验证明，没有单一模型能在所有数据集上均占据优势，这表明需要自动选择模型。此外，基于变压器的嵌入的两步方法一致优于专门的端到端方法，OpenAI嵌入的表现优于BERT。", "conclusion": "我们的实证结果表明，没有单一模型能够在所有数据集上占优，这表明需要进行自动化的模型选择。另外，使用基于变压器的嵌入的两步方法比专门的端到端方法更加有效，特别是在使用OpenAI嵌入时。我们已将NLP-ADBench发布，为NLP-AD提供了一个统一框架，支持未来的研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13726", "html_url": "https://arxiv.org/abs/2501.13726", "title": "RPO: 提取偏好优化以增强鲁棒的检索增强生成", "title_en": "RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation", "authors": "Shi-Qi Yan,Quan Liu,Zhen-Hua Ling", "background": "检索增强生成（RAG）展示了利用外部知识的潜力，但在生成过程中依赖于检索背景的质量和准确性。大型语言模型（LLMs）在评估外部检索的知识（尤其是非参数性知识）与内部记忆不一致时的正确性方面存在困难，这会导致响应生成时出现知识冲突。当前的方法需要额外的步骤来评估检索质量，导致流程复杂化。", "innovation": "我们引入了一种轻量级且有效的方法-提取偏好优化（RPO），用于基于检索相关性适应性地利用多源知识。通过隐式的检索相关性表示和将其纳入奖励模型，将检索评估和响应生成整合到单一模型中，解决了以往方法需要额外步骤评估检索质量的问题。RPO是唯一一种在训练过程中量化检索相关性意识的RAG专用对齐方法，克服了数学障碍。", "conclusion": "实验结果表明，RPO在四个数据集上的准确率比RAG高出4-10%，并且不需要额外组件，展示了其稳健的一般性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.11142", "html_url": "https://arxiv.org/abs/2412.11142", "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "title_en": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "authors": "Tiankai Yang,Yi Nian,Shawn Li,Ruiyao Xu,Yuangang Li,Jiaqi Li,Zhuo Xiao,Xiyang Hu,Ryan Rossi,Kaize Ding,Xia Hu,Yue Zhao", "background": "异常检测（AD）是一个重要的机器学习任务，广泛应用于欺诈检测、医疗诊断、工业监控等领域。在自然语言处理（NLP）领域，AD能够帮助识别诸如垃圾邮件、不实信息和异常用户活动等问题。尽管大型语言模型（LLMs）已经在文本生成和总结等任务上产生了显著影响，但它们在异常检测上的潜力尚未得到充分研究。", "innovation": "该研究引入了AD-LLM，这是第一个评估LLMs在自然语言异常检测中的应用的基准。研究探讨了三个关键任务：（i）零样本检测，利用LLMs的预训练知识在无需特定任务训练的情况下进行异常检测；（ii）数据增强，生成合成数据和类别描述以提高异常检测模型的效果；（iii）模型选择，利用LLMs建议无监督的异常检测模型。", "conclusion": "通过使用不同数据集的实验，研究发现LLMs在零样本异常检测中效果良好，精心设计的数据增强方法很有用，而对特定数据集进行模型选择的解释仍具有挑战性。基于这些结果，研究指出了六项关于LLMs在异常检测中的未来研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.05721", "html_url": "https://arxiv.org/abs/2503.05721", "title": "他们在过滤什么？预训练数据集有害内容过滤策略的实验基准", "title_en": "What Are They Filtering Out? An Experimental Benchmark of Filtering Strategies for Harm Reduction in Pretraining Datasets", "authors": "Marco Antonio Stranisci,Christian Hardmeier", "background": "在开发安全的大语言模型（LLM）时，数据过滤策略是关键组成部分之一，因为它们支持从预训练数据集中去除有害内容。然而，尽管这些策略对预训练数据集有益，但很少有研究关注其对弱势群体潜在歧视性的影响，并且这些策略的有效性尚未系统地得到验证。因此，本文通过基准实验评估现有的数据过滤策略对减少有害内容和减轻对弱势群体边缘化影响的有效性进行了全面研究。", "innovation": "本文提出了对数据过滤策略的基准研究，旨在系统评估这些策略在减少有害内容以及减轻对弱势群体边缘化影响方面的效果。研究涵盖了55份技术报告，通过实验设置测试了现有过滤策略对弱势群体的影响，揭示了这些策略在减少数据集中的有害内容的同时可能会加剧对弱势群体的边缘化。", "conclusion": "该研究结果表明，尽管这些过滤策略在减少有害内容方面具有积极作用，但它们也导致了对弱势群体的代表性不足。因此，提出了需要进一步考虑如何平衡减少有害内容与保护弱势群体不被边缘化之间的关系。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05628", "html_url": "https://arxiv.org/abs/2502.05628", "title": "AnyEdit：任何语言模型中编码的知识都可以编辑", "title_en": "AnyEdit: Edit Any Knowledge Encoded in Language Models", "authors": "Houcheng Jiang,Junfeng Fang,Ningyu Zhang,Guojun Ma,Mingyang Wan,Xiang Wang,Xiangnan He,Tat-seng Chua", "background": "大型语言模型（LLMs）经常产生不准确或过时的信息，需要高效的精确知识更新。当前的模型编辑方法在处理各种格式（如诗歌、代码片段和数学推导）的长篇知识时，存在挑战。这些问题源于它们仅能够编辑单个隐藏状态的局限性，我们称之为“效用壁垒”。", "innovation": "为了克服这个问题，作者提出了AnyEdit，一种新的自回归编辑范式。AnyEdit将长篇知识分解为顺序片段，并逐步编辑每个片段的关键令牌，确保输出的一致性和准确性。理论上，AnyEdit基于互信息链规则，展示了其在LLM中更新任何知识的能力。实践上，AnyEdit在包括UnKEBench、AKEW和作者新创建的EditEverything数据集中的基准测试中，优于强基线，性能高出21.5%。此外，AnyEdit可以作为即插即用框架，使当前的编辑方法能够更新任意长度和格式的知识，显著扩大了LLM知识编辑的范围和实用性。", "conclusion": "AnyEdit展示了在LLM中更新任何知识的能力，并显著提高了模型编辑方法的范围和实用性。它在各种长格式、多种格式的知识更新任务中表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15260", "html_url": "https://arxiv.org/abs/2502.15260", "title": "LightMamba: FPGA上的量化与硬件协同设计以实现Mamba的高效加速", "title_en": "LightMamba: Efficient Mamba Acceleration on FPGA with Quantization and Hardware Co-design", "authors": "Renjie Wei,Songqiang Xu,Linfeng Zhong,Zebin Yang,Qingyu Guo,Yuan Wang,Runsheng Wang,Meng Li", "background": "最近，状态空间模型（SSMs）如Mamba引起了广泛关注。相比于基于Transformer的大型语言模型（LLMs），Mamba具有线性计算复杂度且表现更优秀。然而，由于活动异常值的分散和复杂的计算依赖性，Mamba难以加速，现有的LLM加速器效率低下。因此，提出了一种同时设计量化算法和FPGA加速器架构的LightMamba以实现Mamba的高效推理。", "innovation": "提出了一个FPGA友好的后训练量化算法，通过旋转辅助量化和2的幂次状态空间量化来减少大部分计算至4位。同时还设计了一个部分展开Mamba计算的FPGA加速器以平衡效率和硬件成本。通过计算重排序，以及精细粒度的瓷砖和融合，提高了硬件利用率和内存效率。", "conclusion": "在Xilinx Versal VCK190 FPGA上实现LightMamba，相比GPU基线实现4.65到6.06倍更高的能源效率。在Alveo U280 FPGA上评估时，LightMamba达到了每秒93个令牌，是GPU基线的1.43倍。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.06394", "html_url": "https://arxiv.org/abs/2503.06394", "title": "如何使双语LM变得双语：使用稀疏自编码器追踪内部表示", "title_en": "How a Bilingual LM Becomes Bilingual: Tracing Internal Representations with Sparse Autoencoders", "authors": "Tatsuro Inaba,Go Kamoda,Kentaro Inui,Masaru Isonuma,Yusuke Miyao,Yohei Oseki,Benjamin Heinzerling,Yu Takagi", "background": "本研究探讨双语语言模型如何发展出复杂的内部表征。研究使用稀疏自编码器来分析双语语言模型的内部表征，重点关注训练步骤、层数和模型尺寸对内部表示的影响。已有研究表明，语言模型最初分别学习每种语言，随后在中期层形成双语对齐。研究还发现，更大的模型中这种双语趋势更为明显。", "innovation": "本文提出了一种新颖的方法，将完全训练好的模型分解表示整合到中期训练模型中，来强调双语表示对模型性能的关键作用。该方法为理解语言模型如何获得双语能力提供了新见解", "conclusion": "研究结果表明，语言模型在学习单语后逐步形成双语对齐，尤其是在中期层。较大模型中的双语趋势更为明显。整合分解表示的方法证明了双语能力对模型性能的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.19114", "html_url": "https://arxiv.org/abs/2503.19114", "title": "理解与改进LLMs中提示压缩的信息保护", "title_en": "Understanding and Improving Information Preservation in Prompt Compression for LLMs", "authors": "Weronika Łajewska,Momchil Hardalov,Laura Aina,Neha Anna John,Hang Su,Lluís Màrquez", "background": "大语言模型（LLMs）最近的进步使其能够在其应用范围广泛的任务中取得成功。然而，在信息密集型任务中，提示长度迅速增加，导致计算资源需求增加，性能下降，并引入不相关或冗余信息导致偏见。最近，各种提示压缩技术被引入以在减少输入长度和保留性能之间优化权衡。", "innovation": "本文提出了一种全面评估框架，用于深入分析提示压缩方法。该框架除了压缩比之外还考虑了三个关键方面：（i）下游任务性能，（ii）输入上下文中的定位，（iii）信息保存。通过该框架分析了最新的软压缩和硬压缩方法，展示了某些方法未能保留原始提示的关键细节，特别是在复杂任务中限制了性能。通过识别这些限制，作者通过控制压缩粒度改进了一种软提示方法，并取得了显著的效果：下游任务性能提高了23%，BERTScore指标提高了8分，压缩后保留的实体数量增加了2.7倍。", "conclusion": "研究发现，软提示与序列级结合的压缩方法在有效性和压缩率之间的权衡上表现最佳。相关的代码开源可用。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13834", "html_url": "https://arxiv.org/abs/2504.13834", "title": "Science Hierarchography: Hierarchical Organization of Science Literature", "title_en": "Science Hierarchography: Hierarchical Organization of Science Literature", "authors": "Muhan Gao,Jash Shah,Weiqi Wang,Kuan-Hao Huang,Daniel Khashabi", "background": "科学知识正在以惊人的速度增长，这使得跟踪各个学科的进步和高层次概念性链接变得困难。尽管引文网络和搜索引擎等工具可以帮助检索相关论文，但它们缺乏必要的抽象层次，无法捕捉跨子领域的活动密度和结构。由此，本文提出了科学层次图谱的概念，即构建一个多层级抽象结构的高质量科学文献组织框架，从宏观领域到具体研究。这种表示可以揭示哪些领域已经得到充分探索，哪些领域则有待进一步探索。", "innovation": "本文开发了一种混合方法，结合了高效的基于嵌入的聚类技术和基于大语言模型（LLM）的提示，平衡了可扩展性和语义精度之间的关系。与依赖大语言模型的方法（如迭代树构建）相比，该方法在质量与速度之间实现了更好的权衡。层次图谱捕捉了研究贡献的不同维度，反映了现代科学研究的跨学科和多维性质。", "conclusion": "通过评估LLM代理根据层次结构导航定位目标论文的能力，证明了该方法提高了可解释性，并为超越传统搜索方法探索科学文献提供了一条替代途径。相关代码、数据和演示已公开可用。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12882", "html_url": "https://arxiv.org/abs/2504.12882", "title": "ViClaim: 一种多语言多标签数据集，用于自动视频中声明检测", "title_en": "ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos", "authors": "Patrick Giedemann,Pius von Däniken,Jan Deriu,Alvaro Rodrigo,Anselmo Peñas,Mark Cieliebak", "background": "随着视频内容作为交流和假信息传播的渠道影响力日益增强，有效分析视频中的多语言和多主题声明工具的需求变得尤为迫切。现有假信息检测工作主要集中在文本上，但在处理视频字幕中的口头语言方面却存在显著差距。目前的研究表明，应对视觉和文本信息的复杂性，急需新的方法和工具来提升误信息检测能力，尤其是在视频内容的背景下。", "innovation": "我们提出了 ViClaim，一个包含 1,798 个标注过的视频字幕数据集，涵盖三种语言（英语、德语和西班牙语）和六个主题。每个句子被赋予三个分类标签：值得事实核实、无事实核实价值、观点等。此外，我们还创建了一个专有的注释工具，以应对复杂的注释过程。实验表明，最先进的多语言语言模型在交叉验证上表现出色，但对新出现的主题在通用性方面存在挑战，特别是在不同领域内。这些发现突显了在视频问答检测中检测声明的复杂性。ViClaim 为视频通信中的误信息检测提供了坚实的基础，填补了当前数据集在多媒体分析中的关键空白。", "conclusion": "我们的研究发现了声明检测在视频字幕中的复杂性，并通过 ViClaim 数据集和实验结果强调了解决视频内容中假信息检测问题的必要性。ViClaim 为未来开发多模态分析方法提供了基础，这对于改善视频中的假信息检测至关重要。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07282", "html_url": "https://arxiv.org/abs/2504.07282", "title": "RAISE: 改进的大语言模型指令选择方法", "title_en": "RAISE: Reinforced Adaptive Instruction Selection For Large Language Models", "authors": "Qingsong Lv,Yangning Li,Zihua Lan,Zishan Xu,Jiwei Tang,Tingwei Lu,Yinghui Li,Wenhao Jiang,Hong-Gee Kim,Hai-Tao Zheng,Philip S. Yu", "background": "在大规模语言模型（LLM）的指令微调过程中，高质量的指令比大量的低质量指令更为有效。现有的指令选择方法大多基于启发式质量指标，只在训练前进行数据选择，这导致了指令微调的优化不足，固定的启发式指标难以针对特定任务进行优化。因此，设计了一个动态的、任务导向的指令选择框架RAISE（Reinforced Adaptive Instruction SElection），该框架将整个指令微调过程纳入优化中，在每个步骤根据每条指令对模型性能提升的预期影响来选择指令。这种方法具有良好的可解释性和强任务特定优化能力，通过将动态指令选择建模为一个顺序决策过程，采用强化学习（RL）训练选择策略。大量实验和结果分析证明了该方法优于其他指令选择方法，相比全数据训练，RAISE仅通过更新1%的训练步骤就能获得更好的性能，证明了其高效性与有效性。", "innovation": "设计了一个任务导向的指令选择框架RAISE，通过强化学习将指令微调过程建模为一个顺序决策过程，动态选择对模型性能提升有最大预期影响的指令。这种方法具有良好的可解释性和在特定任务上的优化能力，相对全数据训练，仅通过更新1%的训练步骤就能获得更好的性能。", "conclusion": "实验结果证明了RAISE方法在指令选择方面的优越性，其在仅更新少量训练步骤的情况下就已经展示了高效的训练效果和良好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09666", "html_url": "https://arxiv.org/abs/2505.09666", "title": "使用元学习的系统提示优化", "title_en": "System Prompt Optimization with Meta-Learning", "authors": "Yumin Choi,Jinheon Baek,Sung Ju Hwang", "background": "大型语言模型（LLMs）已经展示了显著的能力，而优化其输入提示在最大化其性能方面起着关键作用。然而，现有的提示优化工作主要集中在针对特定查询或任务的用户的提示上，而忽略了系统提示的重要性。系统提示一旦优化，就可以在不同的任务和领域中应用。因此，本文提出了一个新颖的问题，即多层次系统提示优化，其目标是设计出能够在不同用户提示下保持鲁棒性并适用于未见过的任务的系统提示。", "innovation": "本文提出了一个多任务元学习框架，通过在一个跨多个数据集的迭代过程中优化系统提示并同时更新用户提示，以确保用户提示之间的协同工作，从而解决多层次系统提示优化的问题。实验表明，该方法可以生成能够有效泛化到不同用户提示的系统提示，并使优化后的系统提示能够快速适应未见过的任务，大大减少了测试时需要优化的步骤数量并提高了性能。", "conclusion": "研究结果表明，优化的系统提示能够有效泛化到各种用户提示，并能在未见过的任务上实现快速适应，所需优化步骤更少且性能提升。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18630", "html_url": "https://arxiv.org/abs/2505.18630", "title": "DDO: 基于多智能体协作的双决策优化方法在大语言模型医疗咨询中的应用", "title_en": "DDO: Dual-Decision Optimization for LLM-Based Medical Consultation via Multi-Agent Collaboration", "authors": "Zhihao Jia,Mingyi Jia,Junwen Duan,Jianxin Wang", "background": "大语言模型（LLMs）展现出强大的泛化和推理能力，使其适用于复杂的决策任务，如医疗咨询。然而，现有的LLM方法往往无法捕捉到医疗咨询的双重本质，即涉及两种不同的子任务：症状问询，一个顺序的决策过程，和疾病诊断，一种分类问题。这两种任务的不匹配导致症状问询无效和疾病诊断不可靠。", "innovation": "提出了一种名为DDO的新型LLM框架，通过拆分两个子任务并以不同的目标进行优化，采用协作的多智能体工作流进行双决策优化，从而有效解决上述问题。实验结果显示，DDO在真实世界医疗咨询数据集上的表现优于现有LLM方法，并且与最先进的生成方法具有竞争力，证明了其在医疗咨询任务中的有效性。", "conclusion": "DDO框架能够在医疗咨询任务中有效实现双重决策优化，并在网络医疗咨询的实际应用中取得了强有力的表现。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17192", "html_url": "https://arxiv.org/abs/2504.17192", "title": "Scientific 摘要：Paper2Code: 从机器学习科学论文自动生成代码", "title_en": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning", "authors": "Minju Seo,Jinheon Baek,Seongyun Lee,Sung Ju Hwang", "background": "尽管机器学习研究快速增长，相关的代码实现却常难以获取，这使得研究人员在重复实验和扩展先前工作时极为耗时且困难。与此同时，大型语言模型（LLMs）在理解科技文档和生成高质量代码方面表现出色。鉴于此，我们提出了PaperCoder，一个基于多Agent的LLM框架，能够将机器学习论文转化为可运行的代码存储库。PaperCoder在三个阶段进行操作：规划，它构建高层次的路线图，设计系统架构并用图表表示，识别文件间依赖关系，生成配置文件；分析，着重于解释实施细节；生成，生产具有模块化和依赖关系意识的代码。每一阶段都通过一组特定设计的Agent来实现，在管道中有效协作。然后，我们通过模型评估和作者的具体评价对PaperCoder的代码生成能力进行了评估，特别是在作者发布的基准Repository上线时，使用这些基准Repository作为数据真实值进行评估。结果表明PaperCoder能够生成高质量、忠实的实施代码，且在最近发布的PaperBench基准测试中表现出色，显著超过了基准线。", "innovation": "PaperCoder多Agent LLM框架，自动将机器学习论文转换为功能代码库，包括规划、分析和生成三个阶段。每个阶段都有专业的代理参与协作，提高了生成代码的质量和效率。它特别适用于快速将学术研究转化为实践应用，克服了之前在代码分享和复现困难的问题。此外，它在新的基准测试中取得了优异的成绩，显著优于其他基准线。", "conclusion": "我们的结果证明了PaperCoder在创建高质量、忠实的实现代码方面的有效性，并且在新发布的基准测试PaperBench中表现出色，优于强基准线，这证明了PaperCoder在机器学习代码自动生成中的巨大潜力。有关代码可以在指定的URL找到。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20318", "html_url": "https://arxiv.org/abs/2505.20318", "title": "从潛在表示构建动态向量：超越示例", "title_en": "Beyond Demonstrations: Dynamic Vector Construction from Latent Representations", "authors": "Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu", "background": "现有的In-Context向量（ICV）方法可以从大规模语言模型（LLMs）中提取与当前任务相关的表示，并在推理过程中重新注入，以达到与少量示例In-Context学习（ICL）相当的性能，但无需重复展示处理。然而，这些现有方法仍然对ICL特有的因素比较敏感，通常使用粗略的或语义碎片化的表示作为向量的来源，并依赖于基于启发式的注入位置，这限制了它们的应用范围。", "innovation": "本文提出了一种动态向量（DyVec），该方法包括一个全面查询旋转（EQR）策略，通过减轻由ICL引入的方差来提取鲁棒的语义聚合的潜在表示。然后，DyVec应用动态潜在分割和注入（Dynamic Latent Segmentation and Injection）策略，根据任务复杂性适应性地分割表示，并利用基于REINFORCE的优化来学习每个片段的最佳注入位置。实验结果表明，DyVec优于少量示例ICL、LoRA以及先前的ICV基线。", "conclusion": "实验结果表明DyVec在推理时间对任务进行适应时优于少量示例ICL、LoRA和先前的ICV基线。进一步的分析表明，动态分割和注入语义聚合的潜在表示是有效的。DyVec提供了一个轻量级且数据高效的解决方案，用于推理时的任务适应。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23118", "html_url": "https://arxiv.org/abs/2505.23118", "title": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "title_en": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "authors": "Zhongzhen Huang,Linjie Mu,Yakun Zhu,Xiangyu Zhao,Shaoting Zhang,Xiaofan Zhang", "background": "临床决策的有效性依赖于在多种证据来源之间的迭代、多模态推理。尽管最近的多模态推理模型在解决复杂任务方面取得了显著进展，并在数学和科学领域取得了成功，但它们在医疗领域的应用仍处于探索阶段。本研究旨在填补这一空白，通过提出一种两阶段后培训管道，旨在增强多模态医疗推理能力，从而推动医疗领域的多模态推理发展。", "innovation": "本文提出的MedE$^2$是一种两阶段后训练管道，分为两个阶段：第一阶段使用2000个仅文本的数据集精确地演示推理过程，以激发所需的推理行为；第二阶段则利用1500个经过严格筛选的多模态医疗案例，进一步增强模型的推理能力，并与提出的多模态医疗推理偏好对齐。实验结果表明，采用MedE$^2$训练的模型在多个医疗多模态基准测试中表现更佳，并且在更大的模型规模和推理时间上的扩展性进一步验证了该方法的稳健性和实用性。", "conclusion": "广泛的实验证明，MedE$^2$在提高医疗多模态模型的推理性能方面有效可靠。使用MedE$^2$训练的模型在多个医疗多模态基准上始终优于基线模型，进一步验证了该方法在较大模型规模和推理时间扩展中的稳定性和实用性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20650", "html_url": "https://arxiv.org/abs/2505.20650", "title": "FinTagging: 测试大语言模型提取和结构化财务信息的能力", "title_en": "FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information", "authors": "Yan Wang,Yang Ren,Lingfei Qian,Xueqing Peng,Keyi Wang,Yi Han,Dongji Feng,Fengran Mo,Shengyuan Lin,Qinchuan Zhang,Kaiwen He,Chenri Luo,Jianxing Chen,Junwei Wu,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Qianqian Xie,Jian-Yun Nie", "background": "准确理解财务报告中的数值对于市场的解读至关重要，尽管XBRL被设计用来标准化标记财务报表中的数字，但将成千上万的事实与超过10,000个美国通用会计准则(U.S. GAAP)概念进行映射仍然是一个成本高、不一致且容易出错的过程。现有的基准测试主要集中在定义单一的、极端的分类任务，仅适用于部分U.S. GAAP概念，没有考虑到分类学中的层次意义和真实的标记需求，即每一个事实需要被表示为一个多字段的上下文化输出。这些简化导致了在实际财务报告条件下评估大语言模型（LLMs）的不公正。因此，需要一个全面的基准测试来评估LLMs在结构感知和全范围XBRL标记中的表现，通过数值推理和分类学对齐在文本和表格之间提取和对齐财务事实的能力。", "innovation": "提出了FinTagging，这是第一个结构感知和全面范围的XBRL标记基准测试，旨在评估LLMs在从XBRL报告中提取和对齐财务事实方面的性能，包括数值识别和概念链接两个子任务。FinTagging的特点是全面覆盖了U.S. GAAP税则中的所有概念，同时包括两个关键子任务：FinNI负责数值识别，从XBRL报告中提取数字实体及其类型；FinCL负责概念链接，将每个提取的实体映射到完整的U.S. GAAP税则中的相应概念。这些子任务共同产生了一个财务事实的结构化表示。此基准测试能够客观评估LLMs在处理实际财务报告环境中的表现，而不受现有简化程度的影响，揭示了大语言模型在结构感知推理中的现有局限，特别是在详细概念链接方面。", "conclusion": "通过零样本设置对多种大语言模型进行了评估，分析了它们在两个子任务以及整体标记准确度上的表现。结果显示大语言模型在数值识别上表现出色，但在详细的概念链接上遇到了挑战，这揭示了现有多语言模型在进行准确财务披露时结构感知推理方面的局限性。所有代码和数据集都可以在GitHub和Hugging Face上获取。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07180", "html_url": "https://arxiv.org/abs/2506.07180", "title": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "title_en": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "authors": "Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang", "background": "随着视频大型语言模型（Video-LLMs）在需要基于视觉证据的多元模态推理的实际应用中越来越普及，确保其事实一致性与可靠性变得尤为重要。然而，这些模型倾向于与用户输入一致，即使这与视觉证据相矛盾，这种所谓的‘巴结’行为削弱了它们在这些场景中的可信度。当前对‘巴结’的研究主要集中在其文字领域，忽视了其在视频-语言领域的具体表现，导致缺乏系统性基准和针对性评估来理解视频-LLMs在误导性用户输入下的反应。", "innovation": "本文提出了VISE（视频-LLMs巴结行为基准评估）基准，它是第一个针对最先进视频-LLMs的巴结行为进行评估的基准，涵盖多种问题格式、提示偏见和视觉推理任务。VISE首次将文字领域的‘巴结’视角引入视频领域，使得对多种‘巴结’类型和交互模式的精细化分析成为可能。此外，本文还提出了两种不依赖训练的缓解策略：（i）通过可解释的关键帧选择增强视觉定位；（ii）通过目标性地在推理阶段干预其内部神经表示引导模型远离‘巴结’。", "conclusion": "本文提出了VISE基准来评估视频-LLMs的‘巴结’行为，并提出了两种不依赖训练的缓解策略来减少‘巴结’偏差，展示了未来研究的方向。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越token：基于语义和统计视角量化LLM公平性", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）常常生成包含固有偏见的响应，这影响了其在实际应用中的可靠性。现有的评估方法往往忽视长形式响应中的偏见和LLM输出的内在变化。已有的工作主要集中在情感或token级别的比较上，缺乏深入分析语义层面的细微差异。", "innovation": "本文提出了FiSCo（精细语义比较），这是一种新型的统计框架，通过检测分组群体之间长形式响应中微妙的语义差异来评估LLM的群体公平性。与以往工作相比，FiSCo在claim级别进行分析，利用蕴含检查评估响应之间的一致性，进一步深入到深层次的语义层面。它通过分解模型输出为语义上不同的claim，并应用统计假设检验来比较组内和组间相似性，以实现对细微偏见的稳健检测。", "conclusion": "通过正式提出一个新的分组假设公平性定义并验证FiSCo在性别、种族和年龄的人工标注数据集上的有效性，实验结果表明FiSCo能更可靠地识别细微偏见，同时减少由LLM随机性带来的影响，性能优于多种评估指标。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11083", "html_url": "https://arxiv.org/abs/2506.11083", "title": "RedDebate：通过多代理红队辩论实现更安全的响应", "title_en": "RedDebate: Safer Responses through Multi-Agent Red Teaming Debates", "authors": "Ali Asad,Stephen Obadinma,Radin Shayanfar,Xiaodan Zhu", "background": "现有的AI安全措施往往依赖于昂贵的人类评估或者孤立的单一模型评估，这两种方法都受到了可扩展性和易忽略错误的限制。RedDebate引入了一种新的多代理辩论框架，使大型语言模型（LLMs）能够识别和缓解其不安全的行为。现有的AI安全方法局限性显著，并通过合作辩论来克服这些局限性，使得多个LLM能够在各种辩论场景中相互评估，并通过全自动红队测试系统性地发现潜在的不安全行为模式。", "innovation": "RedDebate框架提供了一种新的方法，让多个LLM在不同场景下进行合作，互相评估推理论证过程中的不安全行为，并通过集成长期记忆模块以保留安全相关的洞见，这些洞见可以在后续推理过程中使用，从而持续优化模型行为。与仅依靠辩论相比，结合记忆机制可以进一步显著减少不安全输出。据我们所知，RedDebate是第一个无需人类干预就能结合多代理辩论和红队测试的整体自动化框架，以逐步提升LLM的安全性。", "conclusion": "经过不同模型安全基准的实证评估表明，RedDebate可以显著减少不安全输出。尽管辩论本身可以让LLM改进其行为，但结合记忆机制可以进一步显著减少不安全输出。RedDebate框架证明了能够有效提升LLMs的安全性，并且实现了自动化处理，没有人工干预的需求。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12311", "html_url": "https://arxiv.org/abs/2506.12311", "title": "Phonikud: 带有实时语音合成的希伯来文字符到音素转换", "title_en": "Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time Text-to-Speech", "authors": "Yakov Kolani,Maxim Melichov,Cobi Calev,Morris Alper", "background": "现代希伯来文的拼写复杂性使得实时文本到语音（TTS）生成具有挑战性。现有的解决方案忽略了诸如声重音等关键的语音特征，即使加上了元音标记，这些特征仍然未被明确指代。为了应对这些局限性，本文引入了Phonikud，一个轻量级的开源希伯来文字符到音素转换（G2P）系统，该系统输出完全指定的国际音标（IPA）转录。", "innovation": "Phonikud系统采用了对现有重音化模型的轻量化适配，并引入了ILSpeech数据集。该数据集包含带IPA标注的希伯来语音转录，可供希伯来文G2P基准、TTS系统的训练数据以及评估TTS性能。结果表明，Phonikud的G2P转换更准确地预测了来自希伯来文本的音素，这使得能够训练出具有优越性能和速度-准确性权衡的实时希伯来文TTS模型。", "conclusion": "Phonikud的G2P转换比先前方法更准确地预测希伯来文本中的音素，这使得能够训练出有效的实时希伯来TTS模型，性能上具有速度与准确性的良好权衡。开源代码、数据和模型已发布。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19418", "html_url": "https://arxiv.org/abs/2506.19418", "title": "使用语言VAEs分离潜在推理规则的系统研究", "title_en": "Learning to Disentangle Latent Reasoning Rules with Language VAEs: A Systematic Study", "authors": "Yingji Zhang,Marco Valentino,Danilo S. Carvalho,André Freitas", "background": "现有的基于Transformer的语言模型在自然语言推理任务上表现出色，但它们通常依赖于记忆而不是基于规则的推理。通过在语言模型的潜在空间中嵌入显式的推理规则，可以增强泛化能力、可解释性和可控性。", "innovation": "提出了一种完整的管道，用于在基于Transformer的语言变分自编码器中学习推理规则。该管道包括三项基于规则的推理任务、支持性理论框架和实际的端到端架构。同时，发现了分离推理规则在编码器参数空间中可以实现功能映射的解耦合，并且在整个过程中注入先验知识可以提高模型的检索效果。此外，发现对于数学推理任务，增加样本数量对性能提升有限，而FFN层比注意力层更能保持推理规则的分离。", "conclusion": "研究表明，在使用语言VAEs进行推理规则的学习可以实现潜在空间内的推理规则分离，这有助于提高模型的解释性和可控性。同时，该工作提出了一个集成先验知识的有效方法，并讨论了模型参数中推理规则分离的瓶颈问题。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE: 学习银行客户交易和文本嵌入", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Omar Zoloev,Artem Sakhno,Dmitry Korolev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户历史通信序列中学习客户端嵌入是金融应用的关键。尽管大规模语言模型（LLMs）提供了广泛的世界知识，但它们直接用于长时间事件序列时计算成本高昂且难以在实际工作流中实现。", "innovation": "本文提出了一种对比学习框架LATTE，该框架将原始事件嵌入与冻结的LLMs的语义嵌入对齐。行为特征被总结为短的提示，由LLM嵌入，并通过对比损失作为监督。该方法显著降低了推理成本和输入大小，相比直接由LLM处理完整序列。", "conclusion": "实验结果显示，我们的方法在实际金融数据集上优于最先进的技术，同时仍然可以部署在对延迟敏感的环境中。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06094", "html_url": "https://arxiv.org/abs/2508.06094", "title": "ConlangCrafter：使用多跳LLM流水线构建语言", "title_en": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline", "authors": "Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš", "background": "人造语言（构语言）如Esperanto和Quenya在艺术、哲学和国际交流中扮演着多样化角色。同时，基础模型已经彻底改变了文本、图像以及其他形式的创意生成。本文利用现代表演语言模型（LLMs）作为最终端构语言辅助工具，分解语言设计成多个模块阶段—音韵学、形态学、句法学、词汇生成和翻译。在每个阶段，该方法利用LLMs的元语言推理能力，注入随机性以促进多样性，并利用自我完善反馈以促进生成语言描述的一致性。", "innovation": "介绍了一个多跳管道ConlangCrafter，将语言设计分解为模块化阶段，并利用现代表演语言模型的元语言推理能力，注入随机性以促进多样性和利用自我完善反馈以促进一致性。", "conclusion": "在衡量一致性与类型多样性的指标上对ConlangCrafter进行评估，结果表明该系统能够生成一致多样、无需人类语言学专业知识的构语言。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09025", "html_url": "https://arxiv.org/abs/2507.09025", "title": "Lizard: 一种高效的大型语言模型线性化框架", "title_en": "Lizard: An Efficient Linearization Framework for Large Language Models", "authors": "Chien Van Nguyen,Ruiyi Zhang,Hanieh Deilamsalehy,Puneet Mathur,Viet Dac Lai,Haoliang Wang,Jayakumar Subramanian,Ryan A. Rossi,Trung Bui,Nikos Vlassis,Franck Dernoncourt,Thien Huu Nguyen", "background": "传统的Transformer架构在处理长序列时面临着严重的计算和内存瓶颈，因为其中的softmax注意力机制具有二次复杂性，而不断增长的键值（KV）缓存则使得推理过程受到上下文长度限制，导致内存饱和。已经存在的线性化方法通常受限于固定且非自适应的结构，无法满足不断变化的需求。", "innovation": "Lizard提出了一个线性化框架，能够将预训练的大型语言模型（LLMs）转化为次二次架构，通过引入一个新的次二次注意力机制，这种方法能够紧密地模拟softmax注意力机制，同时保持模型的质量。Lizard还加入了自适应的记忆控制模块和可学习的小型模块，使该架构更加灵活。此外，Lizard还提供了一种硬件感知算法来解决分段注意力中的数值稳定性问题，以加快训练速度。实验表明，Lizard在性能上可以近乎无损失地恢复教师模型的表现，并在MMLU 5-shot基准测试中显著优于以往的方法（最多24.5个百分点），还展示了更好的关联记忆能力。", "conclusion": "Lizard通过有效的次二次线性化框架，解决了传统Transformer模型的内存和计算瓶颈问题，提升了长序列的处理效率，同时保持了高质量的模型性能，展示了卓越的关联记忆能力，是当前大型语言模型线性化领域的创新解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "大语言模型标签引起的偏见量化研究", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "当前，大型语言模型（LLMs）广泛应用于评估文本质量，但它们判断的有效性尚未得到充分探索。研究发现，不同的LLMs在自我和交叉评估时存在系统的偏差。", "innovation": "本研究通过设计一个控制实验，分析了ChatGPT、Gemini和Claude三种主流LLM在不同标注条件下的评价，包括无标注、真实标注和两种虚假标注场景。实验采用综合偏好投票和细粒度质量评分方法，在一致性评分的基础上进行直接对比分析，揭示了显著的模型偏见问题。", "conclusion": "研究结果表明，感知到的模型身份可以显著扭曲高层次判断和细微质量评估，而不受内容质量的影响。这些发现质疑了使用LLMs作为评判者的可靠性，强调了需要盲评估协议和多样化的多模型验证框架以确保自动化文本评估和LLM基准测试中的公正性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.18791", "html_url": "https://arxiv.org/abs/2508.18791", "title": "LaTeXTrans：使用多智能体协调进行结构化LaTeX翻译", "title_en": "LaTeXTrans: Structured LaTeX Translation with Multi-Agent Coordination", "authors": "Ziming Zhu,Chenglong Wang,Shunjie Xing,Yifu Huo,Fengning Tian,Quan Du,Di Yang,Chunliang Zhang,Tong Xiao,Jingbo Zhu", "background": "尽管现代机器翻译（MT）系统在通用领域文本上取得了显著进展，但翻译结构化的LaTeX格式文档依然是一个重大挑战。这些文档通常将自然语言与特定领域的语法混合在一起，如数学公式、表格、图表和交叉引用等，所有这些内容都必须准确保留，以保持语义完整性和编译性。", "innovation": "本文介绍了一款名为LaTeXTrans的协作多智能体系统，旨在解决这一挑战。LaTeXTrans通过六个专门的智能体来确保格式、结构和术语的一致性翻译：1) 解析器，分解LaTeX为易于翻译的单元，通过占位符替换和语法过滤；2) 翻译器、验证器、总结器和术语提取器，协作确保语境意识、自我纠正和术语一致的翻译；3) 生成器，将翻译的内容重新构建为结构化的LaTeX文档。结果显示，LaTeXTrans在翻译准确性和结构保真度上均优于主流MT系统，提供了一个有效且实用的LaTeX格式文档翻译解决方案。", "conclusion": "实验结果表明，LaTeXTrans在翻译准确性和结构保真度上均优于主流MT系统，为结构化LaTeX文档的翻译提供了一个有效且实用的解决方案。LaTeXTrans的代码可在相应链接获取。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.09708", "html_url": "https://arxiv.org/abs/2509.09708", "title": "超越对不起，我不能：剖析大型语言模型的拒绝", "title_en": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal", "authors": "Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee", "background": "指令调教的大语言模型（LLMs）在面对有害提示时的拒绝行为是一种关键的安全行为，但其内部机制尚不清晰。本文通过使用基于残差流激活训练的稀疏自编码器（SAEs）研究了两个公开的指令调教模型Gemma-2-2B-IT和LLaMA-3.1-8B-IT来探讨这一现象。", "innovation": "本文创新地提出了一种方法，通过稀疏自编码器探究大型语言模型在面对有害提示时的拒绝行为背后的原因。该方法通过三个阶段（拒绝方向、贪婪过滤、交互发现）寻找关键特征，并揭示了冗余特征在特定条件下才活跃的现象，为安全行为的细微审计和针对性干预提供了依据。", "conclusion": "本文研究表明，可以通过操纵可解释的潜在空间来进行精细审计和针对性干预，从而更好地理解并控制大型语言模型的安全行为。此外，还发现了一些冗余特征，这些特征在早期特征被抑制时才活跃，为更深层次的理解和控制模型行为提供了线索。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01328", "html_url": "https://arxiv.org/abs/2509.01328", "title": "大型语言模型能否掌握复杂桌游？", "title_en": "Can Large Language Models Master Complex Card Games?", "authors": "Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang", "background": "复杂游戏一直是人工智能算法进步的重要测试基准。AlphaGo、AlphaZero和MuZero曾击败顶级人类玩家，在围棋和国际象棋中取得了巨大成功，引起了社会对人工智能的广泛兴趣。同时，大型语言模型（LLMs）在各种任务中表现出色，引发了是否能在复杂游戏中取得类似成功的疑问。因此，本文探索了LLMs在掌握复杂卡牌游戏方面的潜力。", "innovation": "本文系统评估了LLMs在八种不同卡牌游戏中的学习能力，重点考察了通过高质量数据的监督微调对高水平游戏表现的影响，以及模型在掌握这些游戏的同时保持通用能力的情况。研究发现：1、通过在高质量数据上进行监督微调，LLMs能够接近强大游戏AI的性能；2、在复杂卡牌游戏中，LLMs可以在多个游戏中达到一定的熟练程度，相似规则的游戏表现增强，而不同规则的游戏则产生冲突；3、LLMs在掌握复杂游戏时会出现通用能力下降，但通过结合一定量的通用指令数据可以减轻这种下降。", "conclusion": "评估结果表明，LLMs具有强大的学习能力和多功能性。相关代码可在该链接处获取。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.06836", "html_url": "https://arxiv.org/abs/2509.06836", "title": "COMPACT：跨通道与Token优化的模型剪枝方法", "title_en": "COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens", "authors": "Eugene Kwek,Wenpeng Yin", "background": "对于边缘部署、交互式应用和大规模可持续推理而言，使大型语言模型（LLMs）在内存、延迟和部署成本方面更加高效至关重要。现有剪枝方法存在局限性，如宽度剪枝需要定制推理代码，深度剪枝会导致预测精度急剧下降，并且许多剪枝方法在处理小型语言模型（SLMs）时表现不佳。", "innovation": "本文提出了COMPACT，这是一种联合剪枝方法，它（i）剪枝罕见词汇以缩减嵌入层/语言模型头部层，（ii）利用共享token加权激活剪枝FFN中间通道，这样做旨在保持剪枝前后token的重要性分布一致。COMPACT结合了深度剪枝和宽度剪枝的优点，包括保持标准transformer架构、规模适应性（实现词汇量与FFN剪枝之间的权衡）、快速的剪枝时间和显著的内存节省与吞吐量增加。", "conclusion": "在Qwen、LLaMA和Gemma等模型家族（0.5B-70B参数规模）上的实验表明，COMPACT方法在下游任务性能上达到了最先进的技术水平，同时实现了参数量、GPU内存和延迟的大幅减少。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20374", "html_url": "https://arxiv.org/abs/2509.20374", "title": "CFDLLMBench: 用于评估计算流体力学中大型语言模型的基准套件", "title_en": "CFDLLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics", "authors": "Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan", "background": "大型语言模型（LLMs）在通用自然语言处理任务中表现出色，但它们在自动化复杂物理系统的数值实验中的用途仍然未被充分探索。作为过去几十年中计算科学的主要工具，计算流体力学（CFD）为评价LLMs的科学能力提供了一个独特的测试平台。", "innovation": "本文介绍了CFDLLMBench基准套件，包括三个互补部分：CFDQuery、CFDCodeBench和FoamBench。这些组件旨在全面评估LLM在三个关键技能上的表现：研究生级别的CFD知识、CFD的数值和物理推理以及情境依赖的CFD工作流实现。该基准套件结合了详细的任务分类和严格的评估框架，确保结果可复制，并量化了LLM在代码可执行性、解决方案准确性和数值收敛行为方面的能力。", "conclusion": "CFDLLMBench 为通过LLM驱动的复杂物理系统数值实验的开发和评价奠定了坚实的基础。相关代码和数据可在指定网址获取。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG: 一种统一且可扩展的代码库生成规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大型语言模型在生成单个函数或单个代码文件方面表现出色，但生成从零开始的完整代码仓库仍然是一个基本挑战。这一能力对于从高层规范构建一致的软件系统以及实现自动化代码生成的全部潜力至关重要。这一过程需要在两个级别上进行规划：确定要构建的功能和模块（提案阶段）以及定义它们的实现细节（实施阶段）。现有的方法依赖于自然语言规划，这往往会产生模糊的规范、对齐不当的组件和脆弱的设计，由于其固有的模糊性和缺乏结构。", "innovation": "为了应对这些限制，作者引入了Repository Planning Graph（RPG），这是一种结构化表示，编码了能力和文件结构、数据流和功能，在统一图中。通过用显式的蓝图替代自由形式的自然语言，RPG使长期规划成为代码仓库生成的一致过程。基于RPG，作者开发了ZeroRepo，这是一种图形驱动框架，在三个阶段执行：提案级别规划、实施级别构建和基于图的代码生成，带有测试验证。ZerRepo在标准测试集RepoCraft上的表现优于基准，平均代码行数和代码标记数分别是Claude Code的3.9倍和68倍，覆盖率和测试准确率分别为81.5%和69.7%，分别提高了27.3和35.8个百分点。", "conclusion": "RPG模型复杂的依赖关系，通过接近线性扩展使更复杂的规划成为可能，并提高了代理对代码仓库的理解水平，从而加速了定位。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09014", "html_url": "https://arxiv.org/abs/2506.09014", "title": "通过学习跨并行样本进行LLM推理", "title_en": "Learning to Reason Across Parallel Samples for LLM Reasoning", "authors": "Jianing Qi,Xi Ye,Hao Tang,Zhigang Zhu,Eunsol Choi", "background": "对于大型语言模型（LLMs），测试时的计算扩展可以带来显著的性能提升。通过采样多个答案并根据启发式方法聚合它们（例如，通过多数投票或使用验证器对答案进行排名），可以在数学领域中实现一致的性能提升。本文的背景在于，尽管存在这种潜力，但仍缺乏一种有效的方法来充分利用多个样本集的优势，尤其是在LLM推理场景中。传统的多数投票方法或基于模型的排名方法无法充分利用样本集的多样性，也没有解决如何有效聚合多个样本以获得更准确答案的问题。", "innovation": "本文提出了一种新的方法，即采样集合聚合器（SSA），这是一个紧凑型的LLM，能够接收多个样本的拼接序列，并输出最终答案。SSA通过强化学习进行训练，以提高答案准确性。实验结果显示，SSA在五个推理解题数据集上都表现出高效性和有效性，特别是在MATH数据集上，相比原始的多数投票方法，改进了8个百分点的pass@5。此外，3B模型的SSA超越了更大规模（72B参数）基于模型的提升方法，这表明SSA在样本集合大小、基础模型类型和规模以及任务方面具有广泛适用性。通过将生成答案的LLM与分析和聚合采样答案的LLM分离，该方法能够与顶级的黑盒模型容易且高效地协作。", "conclusion": "本文提出并展示了采样集合聚合器（SSA）的有效性，这种紧凑型LLM能够通过强化学习优化跨多样本集的推理，并在多个数据集上表现出卓越的性能。该方法不仅提高了答案的准确性，还展示了强大的泛化能力，适用于不同规模和类型的模型与任务。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22536", "html_url": "https://arxiv.org/abs/2509.22536", "title": "InfiR2: 为增强推理的语言模型提供全面的FP8训练食谱", "title_en": "InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models", "authors": "Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Hongxia Yang", "background": "大规模语言模型（LLMs）的训练计算成本极高，严重限制了技术创新。虽然使用FP8训练提供了理论上的显著效率提升，但其广泛应用受到了缺乏全面、开源训练方案的阻碍。为此，本文介绍了端到端的FP8训练方案，该方案无缝整合了持续预训练和监督微调。方法中采用了细粒度、混合粒度量化策略，以保持数值精度，同时最大化计算效率。", "innovation": "本文提出了一种端到端的FP8训练方案，其特点是无缝整合了持续预训练和监督微调，并采用了细粒度、混合粒度量化策略。通过实验验证，该方案不仅表现出极高的稳定性和几乎无损失的效果，还实现了与BF16基线相同的性能，同时在训练时间、峰值内存使用和吞吐量上分别减少了22%、14%和增加了19%，证明FP8是一种实用且 robust的BF16替代方案。", "conclusion": "实验结果表明FP8是BF16的一种实用且 robust 的替代方案，并将发布配套代码以进一步普及大规模模型训练。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17444", "html_url": "https://arxiv.org/abs/2509.17444", "title": "填补医疗基准中的临床空白：HealthBench在日本医疗体系中的适用性案例", "title_en": "Filling in the Clinical Gaps in Benchmark: Case for HealthBench for the Japanese medical system", "authors": "Shohei Hisada,Endo Sunao,Himi Yamato,Shoko Wakamiya,Eiji Aramaki", "background": "日本在医疗大语言模型（LLM）的安全开发方面缺乏 robust 评估框架，且可用资源有限，多为翻译成日语的多项选择题。此研究旨在探讨 HealthBench，一个大规模基于评分标准的医学基准，在日本的适用性。研究者通过应用一个经机器翻译的 HealthBench 5000 情景版本来评估高绩效的多语言模型（GPT-4.1）和日本本土开源模型（LLM-jp-3.1）的性能，并通过LLM作为法官的方法系统分类基准的项目和评分标准，以识别内容与日本临床指南、医疗体系或文化规范之间错位的部分。", "innovation": "研究方法创新在于：首先，通过应用机器翻译的 HealthBench 情景来建立性能基准，并评估 GPT-4.1 和 LLM-jp-3.1 的表现；其次，采用 LLM 作为法官的方法系统分类基准的问题和评分标准，以识别与日本临床指南、医疗体系或文化规范不符的“情境差距”。这一路线确保了可靠的和安全的医疗大语言模型评估。", "conclusion": "研究发现 GPT-4.1 的性能在评分标准不匹配的情况下略有下降，而日本本土的模型则因缺乏临床完整性而表现不佳。进一步分类显示，尽管大多数情景适用，但大部分评分标准仍需本地化。强调直接基准翻译的局限性，并提出了急需制定一种基于当地情况的“J-HealthBench”，以确保医疗大语言模型在日本的可靠和安全评估。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26048", "html_url": "https://arxiv.org/abs/2509.26048", "title": "RE-Searcher: 具有目标导向规划和自我反思的稳健代理搜索", "title_en": "RE-Searcher: Robust Agentic Search with Goal-oriented Planning and Self-reflection", "authors": "Daocheng Fu,Jianbiao Mei,Licheng Wen,Xuemeng Yang,Cheng Yang,Rong Wu,Tao Hu,Siqi Li,Yufan Shen,Xinyu Cai,Pinlong Cai,Botian Shi,Yong Liu,Yu Qiao", "background": "大型语言模型（LLMs）在知识密集型问题回答和推理方面表现出色，但在实际应用中受限于知识截止日期、幻觉以及有限的交互模态。通过对外部搜索工具进行增强有助于缓解这些问题，但这也使代理面临着一个复杂的搜索环境，在这种环境中，查询表述的小规模、合乎情理的变化可能会将推理引入无生产力的方向，并放大错误。本研究通过系统分析量化环境复杂性如何导致脆弱的搜索行为并降级整体性能。", "innovation": "提出了一种简单有效的搜索代理RE-Searcher的方法。该方法在搜索过程中明确阐述具体的搜索目标，并评估检索到的证据是否满足该目标。这种目标导向的规划和自我反思的结合使得RE-Searcher能够抵抗复杂搜索环境中的虚假线索，并实现稳健的搜索。广泛的实验证明了该方法提高了搜索准确性，并达到了最先进的效果。扰动研究进一步表明，该方法在应对嘈杂或误导的外部信号时具有显著的稳健性，减轻了搜索过程的脆弱性。", "conclusion": "我们认为这些发现为将基于LLM的代理整合到更复杂的交互环境中提供了实用指导，并使决策过程更加自主。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01644", "html_url": "https://arxiv.org/abs/2510.01644", "title": "机器学习在检测和分析新型LLM困境识别中的应用", "title_en": "Machine Learning for Detection and Analysis of Novel LLM Jailbreaks", "authors": "John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra", "background": "大型语言模型（LLMs）存在多种漏洞，恶意用户可以通过输入文本的操控获取不期望的回应。这些被称为困境突破（jailbreak）的提示旨在诱使LLM绕过为确保回应符合开发者政策的安全规则。已有研究主要集中在识别已知的困境突破策略，但本研究旨在评估不同机器学习模型区分未知策略困扰突破的能力。", "innovation": "本研究使用了现有的数据集，并证明了端到端微调双向Transformer编码器表示（BERT）模型在识别未知策略的困扰突破方面的最佳性能。此外，本研究还可视化了区分困扰突破和真实提示的关键词，揭示了明确的提示结构中的反思可能成为困扰突破意图的信号。", "conclusion": "当前数据集下，最佳性能由微调BERT模型实现。通过关键词可视化发现，明确的提示结构中的反思可能是困扰突破意图的信号。未来研究可以进一步探究如何利用这一特性进行更有效的检测和分析。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01171", "html_url": "https://arxiv.org/abs/2510.01171", "title": "Verbalized Sampling: 如何缓解模式崩溃并解锁预训练语言模型的生成多样性", "title_en": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity", "authors": "Jiayi Zhang,Simon Yu,Derek Chong,Anthony Sicilia,Michael R. Tomz,Christopher D. Manning,Weiyan Shi", "background": "后训练对齐通常会减少LLM的多样性，导致模式崩溃现象。以往的研究认为这种现象主要是由于算法限制导致的，而本文通过数据分析指出，数据层面的驱动因素更为根本，即偏好数据中的典型性偏见。这种偏差源自注释者倾向于系统性地偏好熟悉的文本，这一倾向是认知心理学中的已知发现。本文通过实验证明了这一偏差在模式崩溃中的核心作用。", "innovation": "本文提出了Verbalized Sampling（口头化采样）策略，这是一种简单的、无需训练的提示策略，用于绕过模式崩溃问题。口头化采样促使模型将一个响应集的概率分布进行口头化表达（例如，“生成5个关于咖啡的笑话及其对应概率”）。全面的实验结果表明，此方法在创意写作、对话模拟、开放式问答和合成数据生成等领域性能显著提升，且不影响事实准确性与安全性，例如在创意写作中，口头化采样可以使多样性提高1.6-2.1倍。此外，观察发现，更强大的模型从此策略中获益更多。", "conclusion": "本文从数据角度提供了对模式崩溃的新看法，并提出了一种实用的推理时间补救策略，有助于解锁预训练的生成多样性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02463", "html_url": "https://arxiv.org/abs/2510.02463", "title": "CLARITY：临床助理用于分诊、推理和判断", "title_en": "CLARITY: Clinical Assistant for Routing, Inference, and Triage", "authors": "Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets", "background": "平台用于实现患者与专科医生的快速对接、临床咨询以及对患者病情严重程度的评估。其架构结合了有限状态机（FSM）以实现结构化的对话流程以及利用大型语言模型（LLM）协作代理来分析症状并优先调度到合适的专科医生。", "innovation": "CLARITY平台采用了混合架构，将有限状态机（FSM）与大型语言模型（LLM）结合使用，确保了安全、高效且稳健的表现，同时支持模块化微服务框架，使其能够灵活扩展并适应现有的医疗健康工作流程和IT解决方案。平台在两个月内处理了超过55,000个内容丰富的用户对话，其中2,500个对话经过专家标注以进行后续验证，结果显示CLARITY在首次尝试分诊准确性方面超过了人类表现，使咨询时间相比人类缩短了最多3倍。", "conclusion": "CLARITY平台显著提高了患者护理效率，实现了快速、精准的分诊和临床咨询，验证结果表明其性能超越了人类医生，为未来的医疗保健系统提供了有效的支持。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06250", "html_url": "https://arxiv.org/abs/2510.06250", "title": "在LLMs中负责任的AI多语言PII注释", "title_en": "Scalable multilingual PII annotation for responsible AI in LLMs", "authors": "Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu", "background": "随着大型语言模型（LLMs）的广泛应用，确保它们在多元监管环境下的可靠处理个人可识别信息（PII）变得至关重要。为此，本研究提出了一种面向13种未充分代表语言的可扩展多语言数据整理框架，涵盖了大约336种地方特定的PII类型。该框架结合了语言学专长和严格的质保，通过阶段性、人机协作的注释过程，明显提升了召回率和减少假阳性率。", "innovation": "提出了一个面向13种未充分代表语言的可扩展多语言数据整理框架，用于高质量的PII注释。该框架结合了语言学专长和严格的质保，通过阶段性、人机协作的注释过程，提升了召回率和减少假阳性率。框架通过校验注释者的一致性和根本原因分析，系统地解决了注释不一致的问题，产生了高质量的数据集，适用于监督LLM模型微调。", "conclusion": "该研究不仅报告了实证成果，还指出了多语言PII标注中的常见问题，并展示了迭代数据分析流程如何提升注释质量和下游模型可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06594", "html_url": "https://arxiv.org/abs/2510.06594", "title": "LLMs的内部层是否揭示了 Jailbreak 检测的模式？", "title_en": "Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?", "authors": "Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis", "background": "大型语言模型（LLMs）的普及和易用性使其面临越来越严峻的安全威胁，尤其是对抗性用户通过精心设计的提示引出限制或敏感输出的行为，这一现象被广泛称为 Jailbreaking。尽管已经提出多种防护机制，但攻击者不断开发新的提示技术，因此没有现有的模型能够完全抵御这类攻击。", "innovation": "本文通过研究大型语言模型的内部表示，特别是关注隐藏层在面临 Jailbreaking 和良性提示时的不同反应模式，分析了开源的 GPT-J 模型和 Mamba2 状态空间模型，提出了基于内部模型动态进行稳健的 Jailbreak 检测和防御的初步见解。", "conclusion": "研究表明，隐藏层在 Jailbreaking 和良性提示下的行为存在显著差异，这为未来利用内部模型动态进行 Robust Jailbreak 检测和防御的研究方向提供了启示。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06370", "html_url": "https://arxiv.org/abs/2510.06370", "title": "EVALUESTEER: 评估奖励模型对价值观和偏好的导向性", "title_en": "EVALUESTEER: Measuring Reward Model Steerability Towards Values and Preferences", "authors": "Kshitish Ghate,Andy Liu,Devansh Jain,Taylor Sorensen,Atoosa Kasirzadeh,Aylin Caliskan,Mona T. Diab,Maarten Sap", "background": "随着大型语言模型（LLMs）的全球部署，在构建能够适应全球用户多样价值观和偏好的系统方面变得越来越重要。现有的数据集不支持对奖励模型（RMs）的可控评估，因此缺乏一个综合平台来评估模型对用户价值观和风格偏好的适应性。", "innovation": "引入了EVALUESTEER基准，这是一种用于衡量LLMs和RMs对用户价值观和风格偏好的导向性的基准。EVALUESTEER基于心理学和人-LLM交互研究中的价值和风格维度，合成了165,888对偏好对，并通过系统地改变这些偏好对来评估模型的表现。", "conclusion": "研究结果表明，当提供用户的完整价值观和风格偏好信息时，最好的模型在选择正确响应方面的准确性低于75%，当仅提供相关风格和价值偏好信息时，则准确率超过99%。EVALUESTEER突显了当前RMs在识别和适应相关用户配置文件信息方面的局限性，并为开发能够朝向多元人类价值观和偏好的RMs提供建立挑战性测试床。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "在线成对标记评价从成对标记比较中获得", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek", "background": "评评分量表提供了一种灵活的方法，用于训练大规模语言模型（LLMs）生成开放式的长文本回答，特别是在直接验证奖励不可行且人类偏好只提供粗略信号的情况下。早期研究显示，基于评评分量表的强化学习能够带来训练后的持续改进。然而，大多数现有方法依赖于在整个训练过程中保持不变的评评分量表，这种静态评分量表容易被利用以获取不当奖励的行为所攻击，并且无法捕捉到训练过程中出现的新需求。", "innovation": "该方法引入了一种名为Online Rubrics Elicitation（OnlineRubrics）的方法，该方法通过当前策略和参考策略的成对标记响应两两比较，动态地制定评价标准，这一在线过程能够随着训练的进行持续识别并缓解错误。", "conclusion": "实验结果显示，通过这种动态方法进行训练的一致改进幅度最高可达8%，涵盖了AlpacaEval，GPQA，ArenaHard，以及专家问题和评分标准验证集。通过对引出的评价标准进行定性分析，发现的主要主题包括透明度、实用性、组织性和推理能力提升。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03683", "html_url": "https://arxiv.org/abs/2510.03683", "title": "使用QLoRA对罗马乌尔都-英语代码混杂文本中的冒犯性语言进行微调的大语言模型", "title_en": "Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text", "authors": "Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov", "background": "在使用代码混杂的语言（如罗马乌尔都语）中使用侮辱性词汇时，自然语言处理系统面临着未声明的语法、不一致的拼写和缺乏标记数据的挑战。本文探讨了如何在这种背景下改进冒犯语言检测，特别是针对罗马乌尔都语和英语的代码混杂文本。研究人员使用Google Translate将罗马乌尔都语-英语代码混杂的数据集翻译成英语，以便利用大量的英语预训练模型，同时承认翻译会减少与代码混杂特征的直接互动。他们主要集中于使用英语翻译后的低资源输入进行分类性能的评估。这些数据集经过人工标注，用于冒犯性内容与非冒犯性内容之间的分类。", "innovation": "作者提出了一种基于QLoRA的微调框架，用于提高罗马乌尔都语-英语代码混杂文本中冒犯语言的检测能力。他们对包括Meta LLaMA 3 8B、Mistral 7B v0.1、LLaMA 2 7B、ModernBERT和RoBERTa等几种transformer和大语言模型进行了微调。其中，Meta LLaMA 3 8B在所有测试模型中获得了最高的F1值91.45，其次是Mistral 7B，为89.66，超过了传统的transformer基线。这些结果表明，QLoRA在低资源环境中（如代码混杂冒犯语言检测）对高性能模型进行微调的有效性，并证明了大语言模型在这方面具有巨大潜力。", "conclusion": "这项工作为罗马乌尔都语的管理提供了一种可扩展的方法，并为基于大语言模型的多语言冒犯检测系统铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07414", "html_url": "https://arxiv.org/abs/2510.07414", "title": "Haystack 工程：用于异构和自主长期上下文评估的上下文工程", "title_en": "Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation", "authors": "Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li", "background": "现代的大型语言模型（LLMs）在合成的“针扎稻草堆”（NIAH）基准测试中表现良好，但这些测试忽视了来自有偏见的检索和自主工作流程中的噪音上下文的实际情况。我们提出，为了测试LLMs在长上下文中的鲁棒性，有必要进行“haystack工程”，以构建忠实于现实世界的噪音长上下文，其中包括从有偏见的检索者那里来的分心因素和自主工作流程中的级联错误。", "innovation": "文章提出HaystackCraft，一个新的基于完整英文维基百科超链接网络的NIAH基准，配备多跳问题，用于评估不同的检索策略（如稀疏、密集、混合和图基）对干扰组成、haystack排序和下游LLM性能的影响。此外，HaystackCraft 进一步将NIAH扩展到动态、LLM依赖性的设置中，模拟自主操作，其中模型改进查询、回顾其过去的推理，并决定何时停止。通过15个长上下文模型的实验，结果显示更强的密集检索器可以引入更具挑战性的干扰，但图基重新排序同时提高了检索效果并减轻了更严重的干扰；在自主测试中，即使如Gemini 2.5 Pro和GPT-5这样的高级模型也会因自我生成的干扰或难以做出早期停止而遭受级联失败。", "conclusion": "实验结果表明，持续的挑战在于自主的长上下文推理，HaystackCraft 成为了测试未来进度的重要研究平台。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08163", "html_url": "https://arxiv.org/abs/2510.08163", "title": "ARM2：具有视觉理解和可执行代码的自适应推理模型", "title_en": "ARM2: Adaptive Reasoning Model with Vision Understanding and Executable Code", "authors": "Jian Xie,Zhendong Chu,Aoxiao Zhong,Kai Zhang,Mingzhe Han,Xing Fan,Jialie Shen,Qingsong Wen", "background": "大型推理模型（LRMs）在处理简单任务时常常会遭受'过度思考'的问题，生成不必要的冗长推理。虽然已经提出了一些策略来缓解这一问题，例如长度惩罚或路由机制，但这些方法通常具有启发性和任务特定性，缺乏一种通用框架来进行自适应推理。", "innovation": "本文提出了ARM2，这是一种统一模型，通过强化学习框架结合长度意识优化来统一动态平衡多种格式下的推理性能和效率。ARM2将视觉理解和可执行代码整合到推理中，展现出与其传统推理模型相比，平均减少超过70%的令牌使用量的同时保持了任务性能。", "conclusion": "与使用GRPO训练的传统推理模型相比，ARM2在性能上达到平齐，在平均减少超过70%的令牌使用量的同时，展现了其效果和设计的有效性及稳健性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07488", "html_url": "https://arxiv.org/abs/2510.07488", "title": "人类团队的教训能否应用于多代理系统？结构、多样性和互动动力的作用", "title_en": "Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics", "authors": "Rasika Muralidharan,Haewoon Kwak,Jisun An", "background": "多代理系统（MAS）与大型语言模型（LLM）驱动的代理正受到越来越多的关注，但关于其团队动态的研究较少。受人类团队科学的启发，本文提出了一种多代理框架，以探索团队科学的核心方面：结构、多样性和互动动态。评估了四个不同任务的表现，分别是常识问答（CommonsenseQA）、策略问答（StrategyQA）、社交智商（Social IQa）和潜在隐含仇恨（Latent Implicit Hate），涵盖了常识推理和社会推理。研究结果显示，扁平化的团队往往比层级化的团队表现更好，而多样性的影响具有复杂性。", "innovation": "本文提出了一个基于多代理框架来研究团队科学的核心方面：结构、多样性和互动动态的多代理系统。通过四个任务的评估，该研究揭示了扁平化团队性能优于层级化团队的现象，并探讨了多样性对团队表现的复杂影响。此外，研究还发现代理在团队表现上存在过度自信，但事后反思显示了团队合作的积极一面和整合挑战，包括有限的对话协调。", "conclusion": "研究结果表明，扁平团队在多个任务上表现更佳，多样性的影响较为复杂，代理在团队合作上的自信与实际表现存在差距。总的来说，多代理系统的团队动态可以从人类团队经验中受益，但还需要进一步研究来解决协作中的挑战。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07458", "html_url": "https://arxiv.org/abs/2510.07458", "title": "AI助力了解民粹主义：使用LLM推进民粹主义研究", "title_en": "Populism Meets AI: Advancing Populism Research with LLMs", "authors": "Eduardo Ryô Tamaki(German Institute for Global and Area Studies),Yujin J. Jung(Mount St. Mary's University),Julia Chatterley(Princeton University),Grant Mitchell(University of California, Los Angeles),Semir Dzebo(University of Oxford),Cristóbal Sandoval(Diego Portales University),Levente Littvay(ELTE Centre for Social Sciences),Kirk A. Hawkins(Brigham Young University)", "background": "测量民粹主义的意识形态内容仍然是一个挑战。传统的基于文本分析的方法虽然对构建该领域的基础和提供有效的客观指标起到了关键作用，但这些方法成本高、耗时且难以跨语言、跨情境和大语料库进行扩展。因此，文章提出了一个基于评分表和锚点引导的思路链（CoT）提示方法，模拟人类编码员的培训过程。通过使用全球民粹主义数据库（GPD），一个标注了民粹主义程度的世界领导人演讲语料库，研究人员指导模型进行推理并反复在GPD上测试多种专有和开源权重模型。这些方法旨在克服传统方法的局限性，提高民粹主义分析的效率和准确性。", "innovation": "文章提出的思路链提示方法模仿人类编码员的培训过程，结合全球民粹主义数据库（GPD），指导大语言模型（LLM）进行推理，并在国际化和多样化的语料库上进行测试，从而揭示了这种领域特定的提示策略使大语言模型在分类准确性上能达到专家人类编码员的水平，证明其能够应对民粹主义中的复杂和语境敏感性方面。这是将人工智能技术应用于民粹主义研究的一次重要进步，超越了传统的文本分析方法。", "conclusion": "通过这种方法的运用，研究人员展示了大语言模型能够成功地复制甚至超越人类专家在民粹主义分类上的表现，表明了其在处理和理解民粹主义方面具备重要的潜力。这一发现不仅有助于推进民粹主义研究领域的发展，也为其他复杂议题的人工智能分析提供了新的视角和方法。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07545", "html_url": "https://arxiv.org/abs/2510.07545", "title": "部署小型LVLM评判者进行图表模型的现实评估：学习与最佳实践", "title_en": "Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices", "authors": "Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang", "background": "带有7B参数的大型视觉-语言模型（LVLMs）在图表理解任务中展示出了作为自动化法官的潜力。然而，小于或等于2B参数的小型模型在这些任务中表现仍然不佳，限制了它们在资源受限环境中的实际应用。", "innovation": "提出了两种确保高效评估的方法：（i）多准则提示，将不同的评估标准整合为一个查询；（ii）领域适应迁移学习，通过在图表数据集上微调一个2B参数的LVLM，创建出一个专业化的模型ChartJudge。", "conclusion": "实验表明，多准则提示揭示了鲁棒性差距，这导致了对于7B模型（包括专有的LVLM法官如LLaVA-Critic）性能的巨大下降。此外，研究发现，我们的小型LVLM（ChartJudge）能够从一个数据集转移到另一个数据集，使其更加专业化。通过针对图表类型和查询复杂性的精细分析，提供了有关模型大小、提示设计和迁移性之间权衡的实际见解，从而支持按需扩展、低成本的评估方法，应用于图表推理任务。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14342", "html_url": "https://arxiv.org/abs/2501.14342", "title": "基于检索链增强生成的方法", "title_en": "Chain-of-Retrieval Augmented Generation", "authors": "Liang Wang,Haonan Chen,Nan Yang,Xiaolong Huang,Zhicheng Dou,Furu Wei", "background": "传统RAG方法通常在生成过程中进行一次检索步骤，这限制了它们在处理复杂查询时的效果，因为检索结果往往不完善。为此，本文提出了一种名为CoRAG的方法，它允许模型在生成最终答案之前，根据检索内容逐步重新制定查询。该方法通过利用拒绝采样自动生成中间的检索链，增强了现有的RAG数据集。在测试阶段，提出了多种解码策略来控制采样的检索链长度和数量，从而扩展模型的计算量。", "innovation": "本文提出了一种名为CoRAG的新方法，该方法通过检索链的动态更新和拒绝采样策略，提高了模型在复杂查询上的处理能力。实验结果显示，在多项基准测试中，CoRAG在多跳问答任务中的EM评分提高了超过10分，特别是在KILT基准测试中，CoRAG达到了新的SOTA水平。", "conclusion": "本文详细分析了CoRAG在不同任务中的表现，展示了其在多层次查询处理上的优势，并对CoRAG的扩展行为进行了全面分析，为未来研究提供了理论依据，特别是关于构建事实性和有依据的基础模型的研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.11593", "html_url": "https://arxiv.org/abs/2306.11593", "title": "通过排名和基于LLM的融合提升图像描述性", "title_en": "Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion", "authors": "Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano", "background": "现有的先进图像描述模型通常是在Microsoft Common Objects in Context (MS-COCO)数据集上训练的，该数据集包含了约十个词的具有人类标注的描述。这些简短的描述虽对通用场景理解有效，但往往无法捕捉到复杂的场景细节和传达详细信息。此外，描述模型倾向于偏向于“平均”描述，这些描述仅捕捉到较为普遍的方面，而忽视了细节。", "innovation": "本文提出了一个新的方法，通过结合不同先进图像描述模型生成的描述来生成更加丰富和信息量更大的图像描述。该方法不需要额外的模型训练：给定一张图像，利用文献中现有的预训练模型生成初始描述，然后利用一个新的图像-文本综合指标BLIPScore进行排名。最后，使用大型语言模型（LLM）合并排名最高的两个描述，生成最终的详细描述。实验结果表明，该方法在MS-COCO和Flickr30k测试集上的表现优于自动系统与人类生成描述之间的差距，减少了幻觉，并且由人类主观评估支持，表明该模型生成的描述更符合人类判断。", "conclusion": "通过综合不同先进模型的优点，本文的方法增强了图像描述的质量和吸引力，填补了自动化系统与人类生成丰富、信息量大的描述之间的差距。这使得生成更适合训练视觉-语言和描述模型的描述成为可能。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04787", "html_url": "https://arxiv.org/abs/2412.04787", "title": "使用随机舍入进行语言模型的直接量化训练", "title_en": "Direct Quantized Training of Language Models with Stochastic Rounding", "authors": "Kaiyan Zhao,Tsuguchika Tabaru,Kenichi Kobayashi,Takumi Honda,Masafumi Yamazaki,Yoshimasa Tsuruoka", "background": "尽管近期的量化大型语言模型（LLMs），如BitNet，在部署时能够大幅减少内存使用（通过采用二值或三值权重），但训练这些模型仍然需要大量的内存开销。这是由于训练过程中所需的高度精确（未量化）权重无法避免。本文探讨了在反向传播过程中直接更新量化低精度权重，而不依赖于直通估计法，从而在训练过程中节省内存。", "innovation": "本文引入了一种随机舍入技术，并成功地直接使用量化低精度权重进行训练。结果表明：当权重约束在三值时，仅使用低精度权重进行训练仍然是可行的；将位宽扩展到8位可实现性能与BitNet b1.58相匹配；本文模型在精度缩放和内存减小的情况下保持鲁棒性，从FP32迁移到BF16/FP8环境时性能降损小；本文模型还支持使用三值权重进行推理，展示了其部署的灵活性。", "conclusion": "本文提出了一种新的训练策略，直接使用量化低精度权重进行训练，并通过随机舍入技术减少了信息损失，展示了模型在低精度环境中的训练效果和推理兼容性，为量化LSTM模型在低资源环境下的应用提供了新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.22424", "html_url": "https://arxiv.org/abs/2503.22424", "title": "通过LLM驱动的迭代代码图搜索进行问题定位", "title_en": "Issue Localization via LLM-Driven Iterative Code Graph Searching", "authors": "Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu", "background": "问题解决旨在根据问题描述在实际代码仓库中生成修复补丁。问题定位是准确问题解决的基础。最近，基于LLM的问题定位方法表现出最先进的性能。然而，这些方法要么从问题描述中提到的文件开始搜索，要么在整个仓库中搜索，难以高效平衡搜索空间的广度和深度，难以控制搜索方向以防止LLM搜索到错误的目标。", "innovation": "本文介绍了CoSIL，一种LLM驱动的、无需训练或索引的强大功能层级问题定位方法。CoSIL采用两阶段代码图搜索策略：首先在文件级别通过动态构建模块调用图进行广泛的探索，然后在功能级别通过扩展模块调用图至功能调用图并执行迭代搜索进行深入分析。为了精确控制搜索方向，CoSIL设计了一个过滤器来剔除无关方向和不相关上下文。为避免长时间上下文中的不正确交互格式，CoSIL引入了一种反思机制，使用更短上下文中的独立查询加强格式化能力。实验结果表明，CoSIL在SWE-bench Lite和SWE-bench Verified上的Top-1定位准确率分别为43.3%和44.6%，使用Qwen2.5-Coder-32B的平均性能优于最先进的方法96.04%，当整合到代理less问题解决方法中时，问题解决率提高了2.98%-30.5%。", "conclusion": "CoSIL以LLM驱动的迭代代码图搜索方法实现问题定位，取得了卓越的效果，并且在问题解决方法中也表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11034", "html_url": "https://arxiv.org/abs/2506.11034", "title": "CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models", "title_en": "CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models", "authors": "Aneesh Komanduri,Karuna Bhaila,Xintao Wu", "background": "大语言模型（LLMs）在各种语言任务中表现出非凡的能力，特别是在上下文学习能力方面。为了进一步提高这些模型的能力，将视觉输入整合到LLMs中形成了大型视觉语言模型（LVLMs），这些模型在图像识别和视觉问答（VQA）等任务中表现出了令人印象深刻的性能。尽管对LLMs在因果推理任务如因果发现和反事实推理方面的潜力产生了越来越多的兴趣，但对于使用LVLMs进行视觉因果推理的研究却相对较少。因此，本文正式提出了一个面向LVLMs的多模态上下文学习的全面因果推理基准——CausalVLBench。", "innovation": "本文提出了一个针对LVLMs的全面因果推理基准——CausalVLBench。该基准包括三个代表性任务：因果结构推理、干预目标预测和反事实预测。评价了最新的开源LVLMs在因果推理任务上的能力，并展示了它们的优势和不足。", "conclusion": "我们希望这项基准研究能揭示现有视觉语言模型的不足之处，并激发提升LVLMs的视觉因果推理能力的新方向和新范式。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20854", "html_url": "https://arxiv.org/abs/2505.20854", "title": "一种用于软件工程任务中弥合人类评估差距的LLM评判标准指标", "title_en": "An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks", "authors": "Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,Kui Liu,Xin Xia,David Lo", "background": "大型语言模型（LLMs）和其他自动化技术被广泛用于辅助软件开发人员生成代码片段、补丁和评论等软件构件。然而，准确评估这些生成成分的正确性仍是一个挑战。一方面，人工评估准确但耗时且缺乏可扩展性；另一方面，许多自动评估指标可扩展，需要少量人力，但往往无法准确反映生成软件成分的实际正确性，这限制了它们的应用效果。因此，需要一种新的评估指标来弥补这一不足。", "innovation": "本文提出了SE-Jury，这是一种专门用于准确评估生成软件构件正确性的新的验证指标。SE-Jury通过定义五个不同的评估策略，并由独立的评委实现，再通过动态团队选择机制，选出最合适的评委团队，结合他们进行综合评分，从而更加准确地评估生成软件构件的正确性。通过在三种流行的软件工程任务（代码生成、程序自动化修复和代码总结）中的一系列基准测试上评估SE-Jury，结果表明其与人工判断的相关性明显高于现有自动评估指标，改善幅度从29.6%到140.8%不等。SE-Jury在代码生成和程序修复任务中达到了接近人工注释者间一致性的同意水平，这证明了SE-Jury在这些任务中作为自动评估指标的有效性和可靠性。", "conclusion": "综上所述，SE-Jury作为一种新的评估指标，能够弥补现有自动评估指标的不足，具有可扩展性和可靠性，在软件工程任务中是一个有潜力的解决方案，替代人类评估成为一种值得研究和应用的选择。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav: 使用分层空间认知长短期记忆系统增强城市环境中的视觉语言导航", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大型城市环境中进行视觉语言导航（VLN）需要代理能够将语言指令与复杂场景中的细节联系起来，同时在长时间范围内回忆相关的经验。现有模块化管道虽然有助于解释性，但缺乏统一的记忆；而端到端的（M）LLM代理可以有效融合视觉和语言，但受限于固定的情境窗口和隐式的空间推理。", "innovation": "Mem4Nav 是一种分层的空间认知长短期记忆系统，可以与任何VLN架构结合使用。该系统通过可逆Transformer嵌入稀疏八叉树和语义拓扑图，提供细粒度的体素索引和高层地标连接。长期记忆压缩并保留了八叉树和图节点的历史观察结果，而短期记忆则缓存最近的多模态条目在相对坐标中，用于实时障碍物避险和局部规划。每一步，STM检索会锐化动态上下文，当需要更深层次的历史时，LTM可以无损地解码以重建过去的嵌入。", "conclusion": "Mem4Nav在“Touchdown”和“Map2Seq”上与三种骨干网络（模块化、基于提示的语言模型的领先VLN和基于跳跃注意力的LLM的领先VLN）进行评估，取得了7-13个百分点的任务完成度增加，足够的SPD减少，以及10个百分点以上的nDTW改进。消融实验进一步确认了分层地图和双记忆模块的重要性。所有代码都在这里公开发布。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02925", "html_url": "https://arxiv.org/abs/2507.02925", "title": "大型语言模型代理在药物发现中模块化任务执行", "title_en": "Large Language Model Agent for Modular Task Execution in Drug Discovery", "authors": "Janghoon Ock,Radheesh Sharma Meda,Srivathsan Badrinarayanan,Neha S. Aluru,Achuth Chandrasekhar,Amir Barati Farimani", "background": "该研究表明，通过结合大型语言模型（LLMs）的推理能力和特定领域的工具，可以自动化和简化早期阶段计算药物发现管道中的关键任务。研究以淋巴细胞性白血病中的BCL-2靶点为例，展示了该框架在实验性药物筛选、优先级制定和结构评估中的有效性。", "innovation": "该框架利用大型语言模型增强的推理能力，结合特定领域的工具，实现了生物医学数据检索、特定领域的问答、分子生成、属性预测、属性指导的分子精炼以及3D蛋白质-配体结构生成等关键任务的自动化。与标准LLMs相比，该框架在回答机制性问题时提供了更好的上下文准确性，并且能够进行自动化的化学多样分子生成、性质预测和精炼，显著提高了先导化合物的质量。此外，框架还利用了Boltz-2来生成3D蛋白质-配体复合结构并提供候选化合物的快速结合亲和力估算，展示了其在AI辅助药物发现中的潜力。", "conclusion": "该方法有效地支持了分子筛选、优先级设定和结构评估。它的模块化设计使其能够灵活地整合新兴工具和模型，为AI辅助的治疗发现提供了一个可扩展的基础。整体来看，该研究展示了模块化框架在药物发现领域的创新性和实用性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05118", "html_url": "https://arxiv.org/abs/2508.05118", "title": "推理通过探索：一种强化学习框架以实现稳健的功能调用", "title_en": "Reasoning through Exploration: A Reinforcement Learning Framework for Robust Function Calling", "authors": "Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang", "background": "大规模语言模型（LLMs）的有效训练面临一个关键挑战：平衡复杂推理路径的探索与稳定策略优化。传统的监督微调（SFT）方法无法培养稳健的推理能力，而传统的强化学习（RL）则因探索效率低下而遇到困难。", "innovation": "提出了一种新的RL框架EGPO，该框架基于Group Relative Policy Optimization（GRPO），其核心是一个熵增强的优势函数，将模型的Strategy-Of-Though（CoT）的熵集成到策略梯度计算中。这种方法鼓励生成多样化推理策略。通过剪辑机制谨慎地限制熵奖励，保持了优化方向。", "conclusion": "EGPO在Berkeley Function Calling Leaderboard（BFCL）上取得了成功，使用EGPO训练的4B参数模型在具有可比规模的模型中达到了新的最佳性能，超越了包括GPT-4o和Gemini-2.5在内的多种强大竞争对手。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13933", "html_url": "https://arxiv.org/abs/2507.13933", "title": "预印本：海报：我刚才浏览的是由LLMs撰写的网站吗？", "title_en": "Preprint: Poster: Did I Just Browse A Website Written by LLMs?", "authors": "Sichang Steven He,Ramesh Govindan,Harsha V. Madhyastha", "background": "随着大型语言模型（LLMs）的出现，越来越多的网络内容由这些模型自动生成，而几乎没有人类的干预。由于这些模型容易抄袭和幻觉，导致生成的内容可能存在不准确性和伦理问题。然而，网站很少公开这些自动生成的内容，普通用户也很难分辨出这些内容的真实来源。因此，开发可靠的鉴别器来识别由LLMs自动生成的网站内容变得非常重要。", "innovation": "目前最先进的LLM检测器在网页内容上不够准确，因为网页内容具有低阳性率、复杂的标记结构和多样的文体特征，而现有的检测器是针对干净、散文式的数据集进行优化的。本文提出了一种可靠且可扩展的管道，用于分类整个网站，而不是简单地根据从每一页提取的文本进行分类。方法是基于LLM文本检测器对多页散文式内容的输出进行分类，以提升准确性。通过收集两个不同的真实数据集，涵盖120个网站，验证了检测器的准确率为100%。实际检测结果发现，在搜索结果和Common Crawl存档中，有大量的网站被识别为由LLMs主导的内容，而且这类网站的数量正在增加，在搜索结果中排名也很靠前，引起了对其对最终用户和整个Web生态系统的影响的质疑。", "conclusion": "研究发现，大量由LLMs自动生成的网站存在并越来越多，但这些网站通常不被揭示其生成方式，普通用户难以识别。提出了一种新的检测方法，通过多个散文式页面的LLM输出来分类网站，准确性高达100%。发现这些网站在搜索引擎结果和Common Crawl存档中广泛存在，且排名靠前，对用户和Web生态系统产生了影响，需要进一步关注和研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06944", "html_url": "https://arxiv.org/abs/2508.06944", "title": "AMFT: 通过元学习最优模仿与探索平衡来对齐LLM推理器", "title_en": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance", "authors": "Lixuan He,Jie Feng,Yong Li", "background": "大型语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）两个阶段进行微调，但这种方法容易导致灾难性遗忘，并且在模仿与探索之间存在次优权衡。尽管近期有一种单阶段方法试图通过启发式方法统一SFT和RL，但缺乏一种原理上机制来动态平衡这两种范式。", "innovation": "提出了自适应元微调（AMFT），这是一种新颖的一阶段算法，能够学习SFT的隐式路径级奖励和RL的显式结果基于奖励之间的最优平衡。AMFT的核心是一个元梯度自适应权重控制器，它将SFT-RL的平衡视为可学习参数，并动态优化以最大化长期任务性能。此外，AMFT还通过策略熵进行了正则化，确保了系统的稳定性，并通过全面的实验证明了在数学推理、抽象视觉推理和视觉语言导航等一系列基准测试中的优越性能。", "conclusion": "AMFT通过元学习控制器实现了对LLM推理器的最优对齐，并且在多种任务上的表现优于现有的方法。实验证明了这种方法在样本效率和性能方面的优势，为LLM的优化提供了更原理化和有效的范式。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02366", "html_url": "https://arxiv.org/abs/2508.02366", "title": "大型语言模型引导的强化学习在量化交易中的应用", "title_en": "Language Model Guided Reinforcement Learning in Quantitative Trading", "authors": "Adam Darmanin,Vince Vella", "background": "算法交易需要在长期内保持一致的短期战术决策。强化学习（RL）已被应用于此类问题，但在实际应用中因其短视的行为和不透明的策略而受到限制。此外，大语言模型（LLMs）提供了具有结构化提示的指导时，能够在策略制定和多模态信号解释方面补充战略性推理。已有研究发现，将LLMs用于交易策略生成的框架有望改善RL在交易中的表现。", "innovation": "本文提出了一种混合框架，通过生成高层次交易策略来引导强化学习（RL）代理，这些策略由大型语言模型（LLMs）制定。研究通过专家评审分析LLMs生成策略的经济合理性和将LLM引导的RL代理与标准无引导RL基线进行比较，评估其在市盈率（SR）和最大回撤（MDD）等方面的性能。实验结果表明，LLMs的指导提高了回报率和风险管理指标，优于传统的RL方法。", "conclusion": "LLMs引导的RL在量化交易中能够改善经济性和风险绩效，因此为交易者的短期战术决策提供了有价值的工具和策略，有助于实现长期的金融目标。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.00071", "html_url": "https://arxiv.org/abs/2510.00071", "title": "ARS: 适应回溯抑制以提高大型逻辑语言模型效率", "title_en": "ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models", "authors": "Dongqi Zheng", "background": "大型推理语言模型（LRLMs 或 LRMs）在复杂的推理任务中表现出色，但由于过度推理现象导致显著的计算效率低下。现有的高效推理方法在提升推理质量同时减少推理成本方面面临挑战。", "innovation": "我们提出了一种名为Adaptive Reasoning Suppression（ARS）的新型无训练方法，通过动态抑制冗余推理步骤并使用适应性的不确定性监测来保留在多个模型架构上数学推理基准测试中的准确性。ARS引入了一种具有渐进抑制阈值的多检查点不确定性估计机制，相比静态抑制方法，这种机制实现了更优的效率。", "conclusion": "我们广泛的评估结果显示，ARS在多个模型架构下的数学推理基准测试中实现了高达53%，46.1%和57.9%的令牌、延迟和能量减少，同时保持或提高了准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03298", "html_url": "https://arxiv.org/abs/2510.03298", "title": "CAFL-L：基于拉格朗日对偶优化的意识约束联邦学习及其在边缘设备上语言模型的应用", "title_en": "CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual Optimization for On-Device Language Models", "authors": "Dongqi Zheng,Wenjin Fu", "background": "本文介绍了Constraint-Aware Federated Learning with Lagrangian Dual Optimization (CAFL-L)，这是一个基于FedAvg的原理性扩展，旨在明确纳入设备级别的资源限制，包括能量、通信、内存和热预算。为了在保留训练稳定性的前提下动态调整训练超参数，CAFL-L使用拉格朗日对偶优化来根据梯度累积动态调整冻结深度、本地步骤、批次大小和通信压缩。", "innovation": "CAFL-L 使用拉格朗日对偶优化来动态调整训练超参数（冻结深度、本地步骤、批量大小和通信压缩），同时通过梯度累积保持训练稳定性。实验结果表明，在量化字符级别的语言模型上，CAFL-L 在减少20%的内存使用和95%的通信开销的同时，仍然保持了竞争力的验证性能，使其适用于资源受限的边缘设备。", "conclusion": "CAFL-L 在满足约束条件方面优于标准的 FedAvg，同时保持了竞争力的验证性能，从而使其适用于资源受限的边缘设备部署。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21787", "html_url": "https://arxiv.org/abs/2509.21787", "title": "DeHate: 一种基于稳定扩散的多模态方法以减轻图像中的仇恨言论", "title_en": "DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images", "authors": "Dwip Dalal,Gautam Vashishtha,Anku Rani,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal", "background": "随着有害在线内容的增加，不仅扭曲了公众讨论，还对维护健康的数字环境提出了重大挑战。针对这种情况，本研究介绍了一个为数字内容中识别仇恨言论而特别制作的多模态数据集。该数据集结合了水印增强的稳定扩散技术和数字注意力分析模块（DAAM），以此来识别图像中的仇恨元素，并生成仇恨注意力图，进而模糊掉含有仇恨内容的区域，最终移除图像中的仇恨部分。本研究还包括了DeHate共享任务的细节，以及一个名为DeHater的用于多模态去仇恨化的视觉-语言模型的介绍。这一方法在给定文本提示的情况下实现了AI驱动的图像仇恨言论检测，从而为社交媒体中的更伦理化的AI应用开创了先河。", "innovation": "本研究的创新在于将水印增强的稳定扩散技术与数字注意力分析模块（DAAM）相结合，用于识别图像中的仇恨元素；另有一项多模态去仇恨化的视觉-语言模型DeHater，能够在给定文本提示的情况下实现AI驱动的图像仇恨言论检测；并且发布了一个多模态数据集作为DeHate共享任务的一部分。", "conclusion": "本研究提出了一种基于稳定扩散的多模态方法DeHate，通过识别和移除图像中的仇恨内容，从而帮助维护健康的数字环境。这一方法有助于开发更伦理化的AI应用，特别是在社交媒体领域。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04503", "html_url": "https://arxiv.org/abs/2510.04503", "title": "P2P：LLM中可靠后门防御的中毒到中毒解决方案", "title_en": "P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs", "authors": "Shuai Zhao,Xinyi Wu,Shiqian Zhao,Xiaobao Wu,Zhongliang Guo,Yanhao Jia,Anh Tuan Luu", "background": "在微调过程中，大型语言模型（LLMs）越来越容易受到数据中毒后门攻击的影响，这些攻击会损害模型的可靠性和可信度。然而，现有的防御策略在泛化方面有限制：它们只能针对特定的攻击类型或任务设置起作用。", "innovation": "我们提出了一个通用且有效的后门防御算法——P2P（Poison-to-Poison）。P2P 通过在一部分训练样本中注入具有安全替代标签的良性触发器，并利用基于提示的学习重新微调模型，从而强制模型将由触发器诱导的表示与安全输出关联起来，从而抵消原始恶意触发器的影响。P2P 通过这种稳固且可泛化的基于触发器的微调，在多种任务设置和攻击类型上都表现出有效性。", "conclusion": "我们的理论和实验证明，P2P 可以中和恶意后门同时保持任务性能。在分类、数学推理和摘要生成任务上，以及涵盖多种先进 LLM 的广泛实验中，结果表明我们的 P2P 算法显著降低了与基线模型相比的攻击成功率。我们希望 P2P 能为抵御后门攻击提供指导，并促进安全和可信的 LLM 社区的发展。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17068", "html_url": "https://arxiv.org/abs/2508.17068", "title": "Anemoi: 基于Coral协议Agent-to-Agent通信MCP服务器的半集中式多智能体系统", "title_en": "Anemoi: A Semi-Centralized Multi-agent System Based on Agent-to-Agent Communication MCP server from Coral Protocol", "authors": "Xinxing Ren,Caelum Forder,Qianbo Zang,Ahsen Tahir,Roman J. Georgio,Suman Deb,Peter Carroll,Önder Gürcan,Zekun Guo", "background": "近年来，通用多智能体系统（MAS）的进展大多依赖于基于上下文工程和集中的设计，在这种设计中，规划智能体通过单向指令传递协调多个工作智能体。这种方法在强大规划智能体下有效，但存在两大缺点：（1）对规划智能体能力的巨大依赖，导致使用较小的语言模型（LLM）时性能下降；（2）智能体间的有限沟通，合作依赖于指令拼接，而非结构化讨论带来的真正改进。为了应对这些挑战，本文提出了一种基于Coral协议Agent-to-Agent通信MCP服务器的半集中式MAS——Anemoi，它允许所有智能体直接进行结构化的沟通合作，并实时监测和评估成果，从而减少对单一规划智能体的依赖，支持适应性计划更新，减少重复上下文传递，提高执行的可扩展性。", "innovation": "Anemoi是一个基于Coral协议Agent-to-Agent通信MCP服务器的半集中式MAS，它允许所有智能体直接进行结构化的沟通合作，实现实时监测、评估、发现瓶颈和提出改进。这减少了对单一规划智能体的依赖，支持适应性计划更新，并减少重复上下文传递，提高了执行的可扩展性。与开源基准OWL相比，使用小型LLM（GPT-4.1-mini）时，Anemoi的准确率达到52.73%，超出OWL的43.63%，提升了9.09%。", "conclusion": "Anemoi通过直接的智能体间协作，改进了多智能体系统的沟通机制，减少了对强大规划智能体的依赖，并提高了执行的可扩展性和效率。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06124", "html_url": "https://arxiv.org/abs/2510.06124", "title": "用户需求与行动分类法", "title_en": "Taxonomy of User Needs and Actions", "authors": "Renee Shelby,Fernando Diaz,Vinodkumar Prabhakaran", "background": "随着对话型人工智能的日益普及，现有分类法要么过度泛化，要么局限于特定领域，要么仅针对狭窄的对话功能。这导致缺少对用户目标及其实现方式（包括具体、适应性和社交实践）的全面理解。为解决这个问题，提出了用户需求与行动分类法（TUNA）框架，该框架基于迭代质性分析1193个人机对话，并结合理论审查和跨领域验证。TUNA 将用户行动组织成包含信息寻求、综合、程序性指导、内容创作、社会互动和元对话行为的三层结构，旨在强调用户自主性和再生产实践，实现多尺度评估、产品政策协调及领域特定分类法的叠加。", "innovation": "TUNA框架通过迭代质性分析构建，涵盖了从信息寻求到元对话的行为层，并注重用户自主性和再利用实践。这项工作提供了一个系统性的术语库来描述人工智能使用情况，促进了更安全、更响应且更负责任对话系统的学术理解与实际设计。", "conclusion": "TUNA框架有助于对对话型人工智能的多尺度评估，支持产品间政策的协调，并为特定领域分类法提供了基础。这项工作对理解和设计更安全、更响应、更负责任的对话系统具有重要贡献。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05901", "html_url": "https://arxiv.org/abs/2510.05901", "title": "在混合线性注意力转换方法中解开组件失衡", "title_en": "Untangling Component Imbalance in Hybrid Linear Attention Conversion Methods", "authors": "Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas", "background": "尽管Transformer在表现上非常出色，但由于其计算复杂性呈现平方级增长，阻碍了其可扩展性。虽然线性注意力将复杂性降低为线性级，但从头开始预训练这些模型仍然在大多数情况下非常昂贵。最近在训练后将线性注意力应用到预训练Transformer的方法可以有效地进行转换，通常使用混合方法结合线性注意力和滑动窗口softmax。然而，现有混合方法存在一个关键缺陷：它们意外地忽略了线性组件，几乎完全依赖于滑动窗口softmax。此前，这种不平衡行为在常见常识基准上的评估实践被忽视。", "innovation": "本文提出了解决现有混合方法中组件失衡问题的三种解决方案：(i) 在推理时将仅线性转换与滑动窗口softmax混合；(ii) 结合注意力权重传递与目标LoRA微调的HedgeCATs方法；(iii) 计划滑动窗口丢弃(SSD)，在训练过程中随机抑制softmax分支，以防止组件崩溃。这些方法保持了计算效率，恢复了大部分基础模型性能，并确保了真正的线性注意力采用，从而恢复了混合转换中性能归因的有效性。", "conclusion": "通过上述三种创新方法，本文在保持计算效率的同时，恢复了大部分基础模型性能，并确保了线性注意力的有效采用，解决了混合转换方法中的组件失衡问题，恢复了性能归因的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08617", "html_url": "https://arxiv.org/abs/2510.08617", "title": "用于脑肿瘤分割的数据增强和损失函数的可重复评估", "title_en": "Reproducible Evaluation of Data Augmentation and Loss Functions for Brain Tumor Segmentation", "authors": "Saumya B", "background": "脑肿瘤分割对于诊断和治疗规划至关重要，但类别不平衡和模型泛化能力有限等问题一直阻碍着这一领域的进步。本研究在公开的MRI数据集上，使用焦点损失和基本数据增强策略评估U-Net的分割性能，旨在解决类别的不平衡和模型泛化能力不足的问题。", "innovation": "本研究通过调整焦点损失参数和评估三种数据增强技术（水平翻转、旋转和缩放）的影响，提出了可重复的脑肿瘤MRI分割性能评估方法。通过使用焦点损失和数据增强技术，实现了较高的分割精度，并且所有代码和结果均公开，为未来的研究提供了透明和可复现实验基线。", "conclusion": "U-Net结合焦点损失达到了90%的精确度，与最先进的结果相当。通过提供实验代码和结果，本研究确立了一个透明、可复现实验基线，指导未来在脑肿瘤分割中的数据增强策略和损失函数设计研究。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04996", "html_url": "https://arxiv.org/abs/2510.04996", "title": "Reinforce-Ada: 适用于增强式LLM训练的自适应采样框架", "title_en": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training", "authors": "Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang", "background": "将强化学习应用于大规模语言模型（LLMs）进行推理任务时常受限于不稳定的梯度估计，这是因为对不同输入提示的响应采样是固定的和均匀的。先前的工作如GVM-RAFT通过在预算约束下动态分配每个提示的推理预算来最小化随机梯度方差。我们的研究基于这一见解，提出了Reinforce-Ada，一种适用于LLMs在线强化学习后处理的自适应采样框架，通过持续重新分配采样努力到具有最大不确定性或学习潜力的提示，加速模型的收敛并提高最终性能。以往的方法通常是两阶段分配，而Reinforce-Ada交错进行估计和采样，在线逐步淘汰并自动停止采样，直至收集到足够的信号为止。为了稳定更新，Reinforce-Ada形成固定大小的具有强制奖励多样性的组，并使用自适应采样期间聚合的全局统计信息计算优势基础线。", "innovation": "Reinforce-Ada是一种自适应采样框架，适用于LLMs的在线强化学习后处理，通过持续重新分配采样努力到具有最大不确定性或学习潜力的提示，加快模型的收敛并提高性能。Reinforce-Ada采用在线逐步淘汰和交织的估计与采样过程，并在聚合了自适应采样期间的全局统计信息后计算优势基础线，这使得它与传统的两阶段分配方法不同。我们的研究表明，特别是在使用平衡采样变体时，Reinforce-Ada相对于GRPO加速了收敛并改善了最终性能。", "conclusion": "我们的工作强调了在支持推理能力的LLMs的强化学习中，通过波动意识的自适应数据管理的关键作用，这有助于实现高效和可靠的强化学习。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08629", "html_url": "https://arxiv.org/abs/2510.08629", "title": "动态专家混合模型在视觉自回归模型中的应用", "title_en": "Dynamic Mixture-of-Experts for Visual Autoregressive Model", "authors": "Jort Vincenti,Metod Jazbec,Guoxuan Xia", "background": "视觉自回归模型（VAR）能够高效地生成高质量图像，但在高分辨率下需要重复进行Transformer调用，这导致了计算冗余。", "innovation": "引入了一种动态的Mixture-of-Experts路由机制，该机制允许通过基于缩放感知的阈值机制在计算资源和图像质量之间进行权衡。这种策略在不需额外训练的情况下平衡了根据token复杂度和分辨率选择专家的方式。", "conclusion": "通过这种方法，我们实现了20%的FLOPs减少，11%的推理加速，同时也与密集基线实现了相当的图像质量。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08625", "html_url": "https://arxiv.org/abs/2510.08625", "title": "调整初始噪声以减轻文本到图像扩散模型中的记忆现象", "title_en": "Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models", "authors": "Hyeonggeun Han,Sehwan Kim,Hyungjun Joo,Sangwoo Hong,Jungwoo Lee", "background": "尽管文本到图像的扩散模型具有出色的生成能力，但它们往往会记住并复制训练数据，这引发了隐私和版权方面的严重担忧。已有研究表明，这种记忆现象是由一个称为吸引力盆地的区域引起的——在这个区域内，无分类器的引导（CFG）会将去噪过程引导向已记住的输出。为了减轻这一问题，研究人员提议直到去噪过程脱离该盆地时才应用CFG。但这种方法通常会导致与输入提示不匹配的去记忆化的图像，从而凸显出需要促进更早的逃离来使CFG能尽早应用于去噪过程中。", "innovation": "本文展示了初始噪声样本在决定逃离时间上的关键作用。通过实验观察到不同的初始样本会导致不同的逃离时间。基于这一见解，提出了两种缓解策略，它们调整初始噪声——无论是集体还是个体——来找到并利用能够促使早期逃离初始样本的方法。这些方法显著减少了记忆现象，同时保持了图像和文本的一致性。", "conclusion": "通过调节初始噪声，本研究显著减少了文本到图像扩散模型中的记忆现象，同时保持了图像与文本提示之间的对齐。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08628", "html_url": "https://arxiv.org/abs/2510.08628", "title": "数字镜像：AI生成图像中的性别偏见与职业刻板印象", "title_en": "The Digital Mirror: Gender Bias and Occupational Stereotypes in AI-Generated Images", "authors": "Siiri Leppälampi,Sonja M. Hyrynsalmi,Erno Vanhala", "background": "生成式AI为创建图形、视频和图像提供了巨大的机会，但近期关于AI生成可视化的研究主要集中在创作过程和图像质量上，忽视了代表性偏见。这项研究通过在职业环境中测试AI生成图片中的代表性偏见，比较了两种AI图像生成工具DALL-E 3和Ideogram的效果，并讨论了AI生成图像中的老龄化和情绪话题。随着AI图像工具的应用越来越广泛，减轻和规避有害的性别偏见变得至关重要，以确保媒体和专业环境中的多样性表现。", "innovation": "这项研究填补了关于AI生成可视化中代表性偏见研究的空白，侧重于在职业领域的测试和比较DALL-E 3和Ideogram的表现，从而更好地理解和解决AI生成图像中的性别偏见问题。", "conclusion": "通过主题分析发现，DALL-E 3和Ideogram在生成的图像中均强化了传统的性别刻板印象，虽然程度不同。研究建议从业者、个人和研究人员在生成具有可识别性别的图像时增加多样性表现。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08589", "html_url": "https://arxiv.org/abs/2510.08589", "title": "超越CNNs：低数据环境下多模态LLMs的高效微调以进行目标检测", "title_en": "Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes", "authors": "Nirmal Elamon,Rouzbeh Davoudi", "background": "目标检测和理解的研究领域正在迅速发展，传统的基于CNN的模型和新兴的多模态大型语言模型（LLMs）都有显著进步。尽管如ResNet和YOLO这样的CNN在基于图像的任务中仍然非常有效，但基于Transformer的LLMs引入了动态上下文推理、语言引导提示和场景整体理解等新能力。然而，当这些模型以原样使用时，其全部潜力未被充分挖掘，通常导致在专业化视觉任务中的性能不足。因此，针对人工文本叠加检测这一挑战性任务，本文将经过微调的传统CNN、零样本预训练多模态LLMs以及多模态LLMs进行综合比较。研究背景强调可以在非常有限的数据（少于1000张图像）下有效微调LLMs来提高36%的准确率，并已超过需要大量数据的传统CNN基础模型。这表明在有监督信息有限的情况下，可以适应语言引导的模型进行精细的视觉理解。", "innovation": "本文的一项重要贡献在于展示了如何在非常有限的数据集（少于1000张图像）下有效微调多模态LLMs，使其在人工文本叠加检测这一复杂的任务上达到或超过了通常需要大量数据的传统CNN基础模型的性能。由此，本文通过探索如何最小的监督微调语言引导模型，为连接视觉和语言领域作出了贡献，并提供了关于多模态变换器在低资源视觉环境中高效跨模态学习策略的新的见解。研究成果强调了基于LLMs的模型在真实世界目标检测任务中的适应性和数据效率，并为多模态变换器在低资源视觉环境中的应用提供了实际指导。研究团队已公开用于模型微调的代码，以促进该领域的进一步改进和应用。", "conclusion": "研究结果表明，基于LLMs的方法在实际目标检测任务中具有很高的适应性和数据效率，为低资源视觉环境下的应用提供了新的策略。本文通过提供可重复使用的代码，在该研究领域中开启了持续进步的可能性。未来的改进和应用将基于这些研究，进一步提高多模态模型在实际任务中的表现。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08631", "html_url": "https://arxiv.org/abs/2510.08631", "title": "使用分层高斯混合模型的表观不确定性进行LiDAR语义分割中的异常分布检测", "title_en": "Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs", "authors": "Hanieh Shojaei Miandashti,Claus Brenner", "background": "除了通过精准的LiDAR点云语义分割实现精确的场景理解外，检测训练过程中未遇到的新型出界（OOD）对象是必要的，以防止将未知对象错误地归类到已知类别中。现有的监督OOD检测方法依赖于辅助OOD数据集，而无监督方法避免了这一需求，但往往依赖于预测熵，即预测分布的熵，该分布用于聚合多个后验权重样本。然而，这些方法往往将哥白尼（模型）和 aleatoric（数据）不确定性混淆，导致可能将归纳假设域中的模糊数据错误地识别为OOD。", "innovation": "本文提出了一种无监督的OOD检测方法，该方法利用分层贝叶斯模型中高斯混合模型参数的表观不确定性，在不需要使用辅助数据或额外训练阶段的情况下，优于既有不确定性方法。该方法在SemanticKITTI数据集上的表现改进如下：AUROC提高18%，AUPRC增加22%，FPR95从76%降低到40%。", "conclusion": "本文提出的方法在处理不确定性的粒度和判断OOD对象方面均有改进，特别是在无需额外的数据和训练流程的情况下实现了优于现有方法的效果。"}
{"llm_update_time": "20251013", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01752", "html_url": "https://arxiv.org/abs/2507.01752", "title": "无需窥探的调优：LLM后训练的可证明隐私与泛化边界", "title_en": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "authors": "Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud", "background": "梯度基于的优化是深度学习的基石，通过反向传播实现高效且可扩展的训练。然而，在训练过程中暴露梯度可能会泄露敏感信息，包括数据中毒攻击在内的隐私和安全问题。与此不同，黑盒优化方法(将模型视为不透明函数，仅依赖于函数评估来指导优化)，在这类数据访问受限、高风险对抗或过拟合的场景中提供了一种有前景的替代方案。本文介绍了一种名为BBoxER的进化黑盒方法，该方法通过隐式压缩训练数据来诱导信息瓶颈。利用信息流动的可计算性，我们提供了实际的泛化边界和反事实隐私、对数据中毒和数据提取攻击的强理论保证。实验结果表明，在大规模语言模型上，无需窥探的黑盒优化方法能够学习，而且几次迭代即可提高性能，表现良好，并对成员身份推断攻击具有鲁棒性。", "innovation": "本文提出了一种名为BBoxER的进化黑盒方法，这是一种后训练方法，它通过隐式压缩训练数据来诱导信息瓶颈。利用信息流动的可计算性，提供了实际的泛化边界和强理论保证，证明了黑盒优化方法在缺乏窥探梯度的情况下也能有效学习，具有良好的泛化和对对抗攻击的鲁棒性。", "conclusion": "BBoxER为梯度基于优化提供了一种可选的、可部署的替代方案，尤其适用于限制或隐私敏感的环境。此外，它还提供了实际的泛化保证，使其与其他同类方法相比更具吸引力。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08635", "html_url": "https://arxiv.org/abs/2510.08635", "title": "Hi-OSCAR: 活动识别中层次开放集分类器", "title_en": "Hi-OSCAR: Hierarchical Open-set Classifier for Human Activity Recognition", "authors": "Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring", "background": "在活动识别（HAR）中，生活中的活动范围远远超过可以被训练用的标注传感器数据集所捕捉到的活动范围。未能妥善处理未见过的活动会严重削弱任何HAR分类器的可靠性。此外，HAR中的所有类别并不都具有同等的差异性，有些类别显著重叠或包含其他子活动。根据这些观察，本文对活动类别进行了结构化的层次安排。并且提出了一种Hierarchical Open-set Classifier for Activity Recognition（Hi-OSCAR），以实现准确识别已知活动的同时，对未知活动进行抑制。这不仅实现了开放集分类，还能将未知类别定位到最近的内部节点，提供超越二进制“已知/未知”分类的洞察。", "innovation": "提出了一种层次开放集分类器Hi-OSCAR，该分类器不仅能够以最先进的精度识别已知活动，还能够对未知活动进行抑制，并将未知类别定位到最近的内部节点，提供超出二进制“已知/未知”分类的更多信息。该研究还收集了一套新的数据集NFI_FARED，包含来自多个主题、多种活动和不同场景的数据。", "conclusion": "Hi-OSCAR实现了一种新颖的开放集分类方式，不仅提高了活动识别的准确性和可靠性，还通过细化未知类别的分类提高了研究的深度。通过开放获取的NFI_FARED数据集，为未来开放集HAR研究提供了新的基础。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08637", "html_url": "https://arxiv.org/abs/2510.08637", "title": "使用时频分析检测高频率振荡", "title_en": "Detection of high-frequency oscillations using time-frequency analysis", "authors": "Mostafa Mohammadpour,Mehdi Zekriyapanah Gashti,Yusif S. Gasimov", "background": "高频率振荡（HFOs）是癫痫病灶区的一种新生物标记。定位HFOs产生的区域可以提高难治性癫痫患者切除部位的精准度。然而，检测HFOs仍具有挑战性，其临床特征尚未完全定义。视觉识别HFOs耗时、费力且主观性强，因此开发自动化的HFOs检测方法对于研究和临床应用至关重要。本研究旨在开发一种新的检测方法，用于80-500 Hz频率范围内的HFOs检测，并通过控制数据集和癫痫患者的数据进行验证。", "innovation": "该研究开发了一种新颖的方法，使用未监督聚类技术，结合S变换从时频域提取事件类别，从而区分HFOs事件、尖波、背景活动和伪迹。与现有检测方法相比，该方法在控制数据集上的敏感性为97.67%，精确性为98.57%，F分数为97.78%。在癫痫患者中，HFOs的频率比在切除的电极和未切除的电极之间具有0.73的比率，且HFOs是癫痫患者癫痫性病灶的有希望的生物标记。去除HFOs，尤其是快速HFOs，会导致无癫痫，而保留的HFOs会导致癫痫复发，这种现象与先前的研究结果一致。", "conclusion": "提出的HFOs检测方法在时间和频域分析中表现出色，能够更准确地识别HFOs，有助于提高癫痫病灶区定位的精准度，对于癫痫患者的研究和治疗具有重要意义。该方法为自动检测HFOs提供了一种新的工具。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08673", "html_url": "https://arxiv.org/abs/2510.08673", "title": "与相机思考：一种用于相机为中心的理解和生成的统一多模态模型", "title_en": "Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation", "authors": "Kang Liao,Size Wu,Zhonghua Wu,Linyi Jin,Chao Wang,Yikai Wang,Fei Wang,Wei Li,Chen Change Loy", "background": "相机为中心的理解和生成是空间智能的两大基石，但通常各自独立研究。Puffin通过结合语言回归和基于扩散的生成，在相机维度扩展了空间感知。", "innovation": "引入了一个新颖的相机作为语言的范式，使模型能够理解和生成任意视角的场景。Puffin通过Puffin-4M大规模数据集训练，结合全局相机参数和像素级相机映射，实现了灵活且可靠的空间生成。实验表明，Puffin在相机为中心的理解和生成任务中表现优于专门的模型。", "conclusion": "通过指令调整，Puffin能够泛化到如空间想象、世界探索和摄影指导等多视角任务中。Puffin的代码、模型、数据集管道和基准测试也将对外开放，推动多模态空间智能研究的发展。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08638", "html_url": "https://arxiv.org/abs/2510.08638", "title": "从DINO的任务相关概念到闵可夫斯基几何", "title_en": "Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry", "authors": "Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg", "background": "DINOv2作为一种现代对象、场景和动作识别模型已广泛应用，但其感知的本质仍不明确。本文采用线性表示假说（LRH），利用隐含自身编码（SAEs）创造一个具有32,000个单元的词典，对DINO的学习进行解释。研究分为三个部分，分别探讨下游任务对词典概念的使用、概念的几何和统计特性以及提出一种新的假设——Minkowski表示假说（MRH），用于解释Vision Transformer的表示特性。", "innovation": "提出了Minkowski表示假说（MRH），解释Vision Transformer的表示如何由一组弓形概念混合体构成，并探讨其实验证据及其对于理解模型表示的可能影响。", "conclusion": "研究结论表明，DINO的表示不是简单的稀疏构成，而是一种部分稠密的结构，且其概念组织超越了线性稀疏的范畴。作者提出了Minkowski表示假说，认为表示由拱形概念混合体组成，该假设基于Gardenfors的概念空间理论。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08728", "html_url": "https://arxiv.org/abs/2510.08728", "title": "结构化输出正则化：一种少样本迁移学习的框架", "title_en": "Structured Output Regularization: a framework for few-shot transfer learning", "authors": "Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay", "background": "传统迁移学习通常通过冻结一些预训练网络的权重并添加任务特定层来重用大型预训练网络。尽管这种方法在计算效率上很高，但它限制了模型适应领域特定功能的能力，并且在数据非常有限的情况下仍然可能导致过拟合并受现有问题的限制。\n", "innovation": "本文提出了一种简单的有效框架——结构化输出正则化（SOR），它冻结了网络的内部结构（例如卷积滤波器），同时使用组岭回例和$ L_1 $惩罚的组合。该框架使用最少的额外参数对特定数据进行个性化处理，并能够应用于各种网络组件（如卷积滤波器或神经网络中的各种模块），从而广泛适用于迁移学习任务。\n", "conclusion": "该研究在三项少样本医学影像分类任务中评估了SOR，并使用DenseNet121和EfficientNetB4基线取得了具有竞争力的结果，表明SOR对于迁移学习任务非常有效。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08653", "html_url": "https://arxiv.org/abs/2510.08653", "title": "PhyDAE: 物理导向的退化自适应专家在一体化遥感图像恢复中的应用", "title_en": "PhyDAE: Physics-Guided Degradation-Adaptive Experts for All-in-One Remote Sensing Image Restoration", "authors": "Zhe Dong,Yuzhe Sun,Haochen Jiang,Tianzhu Liu,Yanfeng Gu", "background": "遥感图像在获取过程中不可避免地受到各种退化因素的影响，包括大气干扰、传感器限制和成像条件等。这些复杂且异质的退化因素对图像质量和后续的任务解释构成了严峻挑战。现有的一体化恢复方法过分依赖隐含特征表示，而缺乏对退化物理现象进行显式建模。因此，本文提出了物理导向的退化自适应专家（PhyDAE），以解决现有方法的上述局限性。", "innovation": "本文提出的PhyDAE采用了两阶段级联架构，将隐含特征中的退化信息转化为显式决策信号，实现了多质异退化（包括雾、噪点、模糊和低光照条件）的精准识别与差异化处理。该方法通过引入残差流形投影（RMP）和频率感知退化分解（FADD），实现从流形几何和频率视角对退化特征的综合分析。此外，它还引入了物理感知专家模块和温度控制稀疏激活策略，提升了计算效率，同时保持成像物理一致性。广泛实验表明，PhyDAE在所有四项恢复任务中均表现出优于现有最佳方法的性能，且具有较少的参数数量和计算复杂度，从而在保持高效率的同时达到了性能与效率之间的理想平衡。", "conclusion": "在MD-RSID、MD-RRSHID和MDRS-Landsat数据集上的实验结果表明，PhyDAE在所有四项恢复任务中均取得了优于现有最佳方法的性能。它通过提升退化识别和处理的精度及效率，在模型复杂度和计算效率上实现了显著改进，从而在与其他主流方法相比时表现出更加优胜的整体性能，并取得了最佳的性能与效率之间的平衡。该研究成果对于提高遥感图像的质量和应用价值具有重要意义。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08759", "html_url": "https://arxiv.org/abs/2510.08759", "title": "BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities", "title_en": "BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities", "authors": "Yu Qi,Haibo Zhao,Ziyu Guo,Siyuan Ma,Ziyan Chen,Yaokun Han,Renrui Zhang,Zitiantao Lin,Shiji Xin,Yijian Huang,Kai Cheng,Peiheng Wang,Jiazheng Liu,Jiayi Zhang,Yizhe Zhu,Wenqing Wang,Yiran Qin,Xupeng Zhu,Haojie Huang,Lawson L.S. Wong", "background": "现有的多模态大型语言模型（MLLMs）虽然有潜力成为具身代理，但对它们的具身能力进行全面和系统的评估仍较少，现有的基准主要集中在特定领域如规划或空间理解。为此，本文引入了BEAR基准，评估MLLMs在具身能力方面的能力。", "innovation": "提出了BEAR，这是一个全面细粒度的基准，用于评估MLLMs的原子具身能力。BEAR包含4,469个交错的图像-视频-文本条目，涵盖14个领域的16类任务，旨在超越现有基准的局限。此外，提出了BEAR-Agent，一种综合预训练视觉模型的多模态可对话代理，以增强MLLM的感知、3D理解和规划能力。", "conclusion": "全面评估了20种代表性MLLM的具身能力，发现其在所有领域均存在局限性。通过BEAR-Agent的引入，MLLM在具身能力方面的表现得到了显著的提升，尤其是在GPT-5上取得了绝对9.12%及相对17.5%的提升。此外，实验表明增强MLLM的具身能力有助于提高模拟环境中的具身任务表现。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08668", "html_url": "https://arxiv.org/abs/2510.08668", "title": "Hulu-Med: 一个透明的综合医学视觉语言模型", "title_en": "Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding", "authors": "Songtao Jiang,Yuan Wang,Sibo Song,Tianxiang Hu,Chenyi Zhou,Bin Pu,Yan Zhang,Zhibo Yang,Yang Feng,Joey Tianyi Zhou,Jin Hao,Zijian Chen,Ruijia Wu,Tao Tang,Junhui Lv,Hongxia Xu,Hongwei Wang,Jun Xiao,Bin Feng,Fudong Zhu,Kenli Li,Weidi Xie,Jimeng Sun,Jian Wu,Zuozhu Liu", "background": "医学临床决策面临整合来自不同数据模态（包括医学文本、2D/3D图像和视频）信息的挑战，这导致了效率低下和诊断忽视的风险。尽管通用视觉语言模型（VLMs）展现出了潜力，但它们在医疗领域的开发受到了不透明的工作流程、数据稀缺性和架构不灵活等问题的阻碍。现有模型在解释和理解多种模态信息方面仍存在局限性，难以实现在临床决策中的广泛应用。", "innovation": "Hulu-Med 是一种透明的医学通用视觉语言模型，它能够统一理解和处理多元模态数据。Hulu-Med 采用统一的基于块的视觉编码器和 LLM 解码器构建，并通过1670万样本的不同维度数据训练，实现2D、3D和视频的理解。医学感知的令牌减法技术使得训练更为高效，不同的参数量变体（从7B到32B）只需要4,000到40,000个GPU小时。广泛的评估证明了Hulu-Med在多项基准测试中的顶级性能，包括视觉问答、医学报告生成及多语言和罕见疾病的复杂推理任务。", "conclusion": "通过开源Hulu-Med的完整管道，展示透明的高性能医学视觉语言模型是可行的，为临床AI提供了可访问且具有影响力的工具基础。相关的代码已在指定链接中发布。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08761", "html_url": "https://arxiv.org/abs/2510.08761", "title": "SAFER-AiD: Saccade-Assisted Foveal-peripheral Vision Enhanced Reconstruction for Adversarial Defense", "title_en": "SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense", "authors": "Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu", "background": " adversarial attacks pose significant challenges to the deployment of deep learning models in real-world applications, as traditional defenses often require computationally intensive methods (e.g., adversarial training or data augmentation). In contrast, the human visual system achieves natural robustness against adversarial perturbations through evolved biological mechanisms, which the authors hypothesize are related to attention-guided non-homogeneous sparse sampling and predictive coding.", "innovation": "The paper proposes a novel defense framework that incorporates three key biological mechanisms: foveal-peripheral processing, saccadic eye movements, and cortical filling-in. The approach uses reinforcement learning-guided saccades to selectively capture multiple foveal-peripheral glimpses, integrate them into a reconstructed image before classification, effectively mitigating adversarial noise and preserving semantic integrity without retraining or fine-tuning downstream classifiers.", "conclusion": "The proposed method improves system robustness across various classifiers and attack types, and significantly reduces training overhead compared to both biologically and non-biologically inspired defense techniques. This biologically inspired preprocessing is shown to be effective in enhancing adversarial defense without altering existing system architectures."}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08770", "html_url": "https://arxiv.org/abs/2510.08770", "title": "使用预训练深度学习模型和机器人平台的热成像油污检测", "title_en": "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform", "authors": "Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung", "background": "该研究提出了一个实时油污检测系统，该系统利用预训练的深度学习模型结合RGB和热成像技术，以在多种环境中分类油污和无油污场景。研究使用了平衡的二元数据集（4000张图像），实验展示了热成像在推断速度、准确性和模型大小方面的优势。系统在消费级硬件（RTX 4080）上运行，推断时间低至44毫秒，模型大小小于350MB，适合关键安全领域的应用。机器人实验和测试数据集结果显示，使用热成像训练的VGG19模型表现最佳。", "innovation": "该研究创新性地结合了预训练的深度学习模型和热成像技术，能够在多种环境中实时检测油污，特别是在不同光照条件下推断速度和鲁棒性方面表现出色。该系统在消费级硬件上的高效率和低模型大小使其在安全关键领域具有较高的部署潜力。", "conclusion": "热成像训练的VGG19模型在机器人实验和测试数据集上表现最佳，该系统能够在多种环境下实现油污的实时检测，推断速度快、准确性高、模型体积小，适用于安全关键的应用场景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08799", "html_url": "https://arxiv.org/abs/2510.08799", "title": "SkipSR：通过跳过运算加速超级分辨率", "title_en": "SkipSR: Faster Super Resolution with Token Skipping", "authors": "Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni", "background": "基于扩散的超分辨率（SR）是视频生成和视频恢复中的关键组件，但速度慢且成本高，限制了其在更高分辨率和更长视频中的应用拓展。", "innovation": "提出了一种简单的框架SkipSR，通过直接从低分辨率输入中识别低细节区域并完全跳过这些区域的计算，只对需要精炼的区域进行超分辨率处理，从而在保持感知质量的同时大幅减少计算量。", "conclusion": "在标准SR基准测试中，相比先前模型，我们的方法在720p视频上实现了高达60%的端到端延迟减少，同时没有出现显著的质量损失。视频演示可在该网页上找到：this https URL"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08775", "html_url": "https://arxiv.org/abs/2510.08775", "title": "利用AI自动视频关键帧提取识别kekā", "title_en": "Re-Identifying Kākā with AI-Automated Video Key Frame Extraction", "authors": "Paula Maddigan,Andrew Lensen,Rachael C. Shaw", "background": "准确识别和重新识别个体动物对于野生动物种群监控至关重要。传统的标记方法，如鸟类的脚环标记，耗时且侵入性强。近年来，人工智能尤其是计算机视觉的进步为智能保护和自动化提供了潜在的解决方案。本研究展示了从新西兰森林栖息的濒危鹦鹉kekā（Nestor meridionalis）的视频中提取高质量关键帧的独特管道。尽管关键帧提取在人脸识别方面有良好的研究，但其在野生动物领域的应用还较少。使用自建喂食摄像机记录的视频，我们提取关键帧并评估我们管道的重新识别性能。", "innovation": "本研究提出了一种结合YOLO目标检测、Grounding DINO、离焦模糊检测、DINOv2图像编码和聚类方法的无监督方法，用于识别代表性的关键帧，从而为在更多样化和更具挑战性的环境中收集的媒体进行研究提供基础。通过使用人工智能和计算机视觉，我们的非侵入性和高效的识别方法为传统物理标记方法提供了一个有价值的替代方案，以识别kekā个体，从而改进种群监控。", "conclusion": "本研究为野生动物监测开发了新的方法，具有生态学和保护生物学的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08771", "html_url": "https://arxiv.org/abs/2510.08771", "title": "LinearSR：解锁线性注意力在稳定高效图像超分辨率中的应用", "title_en": "LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution", "authors": "Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu", "background": "生成模型在图像超分辨率（SR）方面越来越强大，但它们对自注意力的二次复杂性（O(N^2)）产生了主要的计算瓶颈。虽然线性注意力提供了一个O(N)的解决方案，但在现实感SR方面仍有待充分利用，历史上受限于一系列相互关联且之前未解决的挑战。", "innovation": "该论文引入了LinearSR，这是一个全面的框架，首次系统地克服了这些关键障碍。具体来说，通过我们新颖的基于'膝盖点'-导向的早期停止引导微调（ESGF）策略，解决了一个根本性的训练不稳定问题，导致模型发散；通过专为信噪比（SNR）设计的专家混合（MoE）架构缓解了经典的感知-失真权衡；最后，提出了有效的轻量级指导范式TAG，源自我们的“精度优先”原则。因此，LinearSR模型在感知质量方面达到了最先进的水平，同时具有卓越的效率。", "conclusion": "LinearSR模型的核心扩散前向传递（1-NFE）实现了最先进的速度，而其整体多步推理时间仍然具有很强的竞争力。这项工作为在现实感SR领域应用线性注意力提供了第一个稳健的方法，为未来在生成超分辨率中的高效研究奠定了基础架构。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08791", "html_url": "https://arxiv.org/abs/2510.08791", "title": "医学视觉问答中的对齐、挖掘与融合：基于困难否定挖掘和选择性知识融合的表示对齐", "title_en": "Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering", "authors": "Yuanhao Zou,Zhaozheng Yin", "background": "医学视觉问答（Med-VQA）是一个具有挑战性的问题，需要对医学图像和文本问题都有深入的理解。虽然利用医学视觉语言预训练（Med-VLP）的方法已经显示出在Med-VQA任务上的强大表现，但仍然缺乏跨多个层次、模态、视角和阶段的一体化多模态对齐方案，且对困难否定的挖掘仍然被忽视。此外，常用的Med-VQA知识融合技术可能会引入无关信息。", "innovation": "本文提出了一种框架，通过三个关键贡献来解决上述挑战：(1) 利用对比学习和最优传输理论等方法，为跨多层、模态、视图和阶段提供了一体化的异质模态对齐方案；(2) 开发了一种困难否定挖掘方法，采用了软标签进行多模态对齐，并强制执行困难否定对的区分；(3) 引入门控交叉注意力模块，将答案词汇作为先验知识整合，并从中选择相关的信息。本框架在广泛使用的Med-VQA数据集如RAD-VQA、SLAKE、PathVQA和VQA-2019上超越了之前的最佳表现。", "conclusion": "本工作提出了一种新型框架，解决了Med-VQA中的多个挑战，并在多个基准数据集上取得了优于现有最佳方法的结果。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08818", "html_url": "https://arxiv.org/abs/2510.08818", "title": "D-CoDe: 通过动态压缩和问题分解扩展基于图像预训练的VLM至视频", "title_en": "D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition", "authors": "Yiyang Huang,Yizhou Wang,Yun Fu", "background": "视频大语言模型（Vid-LLMs）在多种视频-语言任务中表现出色，可以通过适应图像预训练的视觉语言模型（VLMs）来构建。然而，这类适应存在挑战，因为需要处理密集且时空扩展的视觉输入，超过基于图像的模型的容量。本文指出，感知瓶颈和标记过载是将基于图像的VLMs扩展到视频领域的关键挑战。", "innovation": "本文提出了D-CoDe，一种无需训练的适应框架，结合了动态压缩和问题分解。动态压缩通过自适应选择代表性帧和内容感知的空间标记聚合来缓解感知瓶颈，从而减少冗余并保留信息内容。问题分解通过将原始查询重新公式化为子问题，指导模型专注于视频的不同方面，从而实现更全面的理解。", "conclusion": "实验显示，D-CoDe在多种基准测试中有效改善了视频理解能力。特别是在挑战性的长视频基准测试中表现出色，表明D-CoDe在处理复杂视频-语言任务方面具有潜力。代码可在此处获取：this https URL。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08901", "html_url": "https://arxiv.org/abs/2510.08901", "title": "利用时间序列轨迹建模以表征蓝莓生长", "title_en": "Modeling Time-Lapse Trajectories to Characterize Cranberry Growth", "authors": "Ronan John,Anis Chihoub,Ryan Meegan,Gina Sidelli,Jeffery Neyhart,Peter Oudemans,Kristin Dana", "background": "蓝莓种植中的变化监测是一项关键任务，它能帮助育种者和种植者分析生长情况、预测产量并做出治疗决策。然而，这项任务通常需要种植者或育种者大量的时间进行手动操作。基于深度学习的变化监测具有潜力，但高维度特征难以解释，且需要人工标注精细调整。因此，迫切需要一种无需繁琐图像标注的方法来解决这一问题。", "innovation": "本文提出了一种利用自监督方法调优视觉变换器（ViTs）来建模作物生长的方法，通过双重前置任务（时间回归和类别预测）学习植物和果实外观的时间差轨迹，以此构建一个可解释的时间序列模型，用于预测生长和区分蓝莓品种的时间差异。此外，还提供了一个8个不同品种蓝莓的时间序列数据集，包括生长季共52次观测，标注了关于杀菌剂应用、产量和腐烂的信息。这种方法通用性强，可应用于其他作物和应用（代码和数据集可在https://github.com/ronan-39/tlt/获得）。", "conclusion": "我们提出的方法通过自监督方法优化视觉变换器，以无监督学习方式避免了繁琐的图像标注过程，构建了一个易解释的时间序列模型，能够预测生长情况并区分蓝莓品种的时间差异，同时提供了一个蓝莓生长时间序列数据集，用于改进蓝莓生长监测技术。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08789", "html_url": "https://arxiv.org/abs/2510.08789", "title": "Q-Router: 具有专家模型路由和时空特征定位的具有代理性的视频质量评估", "title_en": "Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization", "authors": "Shuo Xing,Soumik Dey,Mingyang Wu,Ashirbad Mishra,Hansi Wu,Binbin Li,Zhengzhong Tu", "background": "视频质量评估（VQA）是计算机视觉中的基本任务，旨在预测给定视频的感知质量，与人类判断一致。现有性能良好的VQA模型虽然可以通过直接评分监督训练，但在多样化的内容和任务上表现不佳，包括用户生成内容（UGC）、短视频以及AI生成内容（AIGC）。此外，这些模型缺乏可解释性，并且难以扩展到新的应用场景或内容类型。因此，需要一种新的方法来改进这些问题。", "innovation": "我们提出了Q-Router，一种具有代理性的框架，用于泛化的VQA，采用了多级模型路由系统。该系统整合了一组多元化的专家模型，并使用视觉-语言模型（VLMs）作为实时路由器，能够动态推理并组合出最合适的专家模型，根据输入视频的含义来调整。此外，Q-Router还建立了一个基于计算预算的多级路由体系结构，第三层特别注重时空属性的定位，以提高解释性。这种代理设计使Q-Router能够在不同来源和任务的视频上灵活且稳健地发挥出色表现。实验结果表明，Q-Router在多种基准测试中与最先进的VQA模型相比，表现出色，并且提高了泛化能力和解释性。此外，Q-Router在基于质量的问答基准测试（Q-Bench-Video）中表现出色，展示了其作为下一代VQA系统的潜在基础。最后，Q-Router能够精确定位时空属性，显示出其作为后训练视频生成模型奖励函数的潜力。", "conclusion": "Q-Router通过集成多个专家模型并采用多级路由系统，提高了VQA系统的泛化能力和解释性。它能够在多种视频源和任务上实现灵活且稳健的表现，并且在质量基础上的问答基准测试Q-Bench-Video中表现出色，显示出其在下一代VQA系统中的潜力。此外，Q-Router在时空特征定位方面的表现表明了其在视频生成后的潜在应用。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08849", "html_url": "https://arxiv.org/abs/2510.08849", "title": "FOLK: 快速基于标签引导知识蒸馏的开放词汇3D实例分割", "title_en": "FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation", "authors": "Hongrui Wu,Zhicheng Gao,Jin Cao,Kelu Yao,Wen Shen,Zhihua Wei", "background": "现有方法通常将3D实例映射到2D RGB-D图像，然后使用视觉-语言模型（VLMs）进行分类。然而，这种映射策略通常会引入来自遮挡的噪声，并在推断时带来高昂的计算和内存成本，从而减慢了推断速度。现有研究方法存在的主要问题是：噪声遮挡带来的干扰和推断速度慢。该论文致力于解决该问题，旨在提升开放词汇3D实例分割的能力，以弥补现有方法的不足，提高推断效率并减少计算开销。", "innovation": "为了提高推断速度并减少计算资源的需求，该论文提出了一种基于标签引导的知识蒸馏方法FOLK。FOLK的核心思想是设计教师模型，提取高质量的实例嵌入，并将其开放词汇知识传递给3D学生模型。学生模型可以直接对来自3D点云的实例进行分类，避免了由遮挡引起的噪声，显著加速了推断过程。FOLK提出了一个基于标签指导的蒸馏算法，在训练时将标签一致的2D嵌入中的开放词汇知识传递给学生模型。FOLK在ScanNet200和Replica数据集上进行了实验，展示了在保持性能的同时大幅提升了推断速度。", "conclusion": "FOLK通过基于标签引导的知识蒸馏，不仅保持了现有方法的分类准确性，还大幅度提升了3D实例分割的推断速度，同时其方法在计算效率和性能上表现优秀，是开放词汇3D实例分割领域的一个重要突破。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08922", "html_url": "https://arxiv.org/abs/2510.08922", "title": "SegTrans：适用于分割模型的可转移对抗样本", "title_en": "SegTrans: Transferable Adversarial Examples for Segmentation Models", "authors": "Yufei Song,Ziqi Zhou,Qi Lu,Hangtao Zhang,Yifan Hu,Lulu Xue,Shengshan Hu,Minghui Li,Leo Yu Zhang", "background": "分割模型在白盒设置下对对抗样本表现出显著的脆弱性，但现有的对抗攻击方法在不同的分割模型之间往往不具备良好的可转移性。尽管有部分研究已经探讨了基于传输的对抗攻击方法，但由于分割模型中存在的复杂上下文依赖和代用模型与目标模型之间特征分布的差距，导致可转移攻击成功率较低。", "innovation": "提出了一种新的可转移攻击框架SegTrans，该框架将输入样本划分为多个局部区域，并重新映射它们的语义信息以生成多种增强样本。增强样本替代原始样本用于扰动优化，从而提高不同分割模型之间的可转移性。SegTrans仅保留原始输入的局部语义信息，而不使用全局语义信息来优化扰动。", "conclusion": "在PASCAL VOC和Cityscapes两个基准数据集上对四种不同的分割模型以及三种骨干网络进行的广泛实验表明，SegTrans显著提高了对抗样本的可转移成功率，且未引入额外的计算开销。与现有的最先进的方法相比，SegTrans在可转移攻击成功率上平均提高了8.55%，同时提高了计算效率超过100%。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08919", "html_url": "https://arxiv.org/abs/2510.08919", "title": "PHyCLIP：基于$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{1}}}}}}$-乘积的双曲因子统一视觉语言表示学习中的层次结构和成分性", "title_en": "PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning", "authors": "Daiki Yoshikawa,Takashi Matsubara", "background": "视觉-语言模型在大规模视觉场景和语言描述配对的多模态表示学习中取得了显著成果。然而，它们在同时表达概念家族内的层次结构（例如，狗$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\triangleleft}}}}}}$哺乳动物$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\triangleleft}}}}}}$动物）和不同概念家族间的成分性（例如，“狗在车里”$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\triangleleft}}}}}}$狗，车）方面仍然存在问题。近期工作通过引入双曲空间有效捕捉了层次结构，但双曲空间在成分性表示上的适用性尚未明确。为了应对这一挑战，本文提出了PHyCLIP，通过卡氏积上的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{1}}}}}}}}$-乘积度量来设计模型。", "innovation": "PHyCLIP通过卡氏积上的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{1}}}}}}}}$-乘积度量设计了一个模型，使在同一空间中独立的双曲空间中出现了概念家族内的层次结构，并通过$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{1}}}}}}}}$-乘积度量捕捉了不同概念家族间的成分性，类似于布尔代数。", "conclusion": "在零样本分类、检索、层次分类以及成分性理解任务上的实验结果表明，PHyCLIP比现有的单一空间方法表现更优，并在嵌入空间中提供了更直观的表示结构。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08936", "html_url": "https://arxiv.org/abs/2510.08936", "title": "RO-Bench: 使用文本驱动的反事实视频大规模评估MLLMs的鲁棒性", "title_en": "RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos", "authors": "Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang", "background": "近期，多模态大规模语言模型（MLLMs）在各种视频理解任务中展示了显著的性能，但它们在面临被篡改的视频内容时的鲁棒性仍未得到充分研究。", "innovation": "该论文介绍了Ro-Bench，这是第一个用于评估MLLMs在动态离分布（OOD）反事实视频测试集上的基准。Ro-Bench通过编辑Style、Object、Background及其组成，引入了高质量、多样的且具有时间相关性的视频数据。研究发现，当前模型在面对反事实视频内容时，在Ro-Bench上表现出显著的性能下降，并且通过使用反事实数据对MLLMs进行微调可以提高其鲁棒性。", "conclusion": "通过反事实数据的使用可以有效提升MLLMs的视频理解能力。微调后的模型在Ro-Bench上的性能提高了21.73%，在MVBench数据集上的20个任务中平均性能提高了12.78%。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08955", "html_url": "https://arxiv.org/abs/2510.08955", "title": "噪声去除的扩散作用于面向对象的图像增强", "title_en": "Denoised Diffusion for Object-Focused Image Augmentation", "authors": "Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar", "background": "现代农业操作越来越依赖于集成监控系统，通过结合多种数据源来优化农场操作。无人机检测动物健康是重要组成部分，但它面临着数据有限的问题，尤其是场景特定问题，如小型、遮挡或部分可见的动物。这些特定场景给现有的迁移学习方法带来了挑战，因为这些方法往往无法适应农业环境中动物品种、环境和行为的差异，导致难以收集大量反映这些条件的数据集。因此，需要一种针对这些特定问题的动物数据增强策略，以适应这些独特挑战。本文提出了一个面向对象的数据增强框架，该框架专门设计用于在数据匮乏的情况下进行动物健康监测。该方法通过分割动物背景并采用变换和扩散合成生成逼真的、多样化的场景，提升动物检测和监控性能。初试实验表明，在动物检测任务上，增强后的数据集相比基础模型表现更优，可以在数据稀缺的情况下提供实时动物健康监控解决方案，从而弥合数据匮乏与实际应用之间的差距。", "innovation": "提出了一个面向对象的数据增强框架，专门用于动物健康监测的场景，通过分割动物背景并使用变换和扩散合成生成逼真的、多样化的场景，提高动物检测和监控性能。该方法能够在数据匮乏的情况下生成领域特定的数据，推动实时动物健康监控解决方案的发展。", "conclusion": "通过使用一种针对性增强方法，即使在数据匮乏的情况下，也能提升动物检测和监控的性能。研究方法生成了逼真的、多样的场景，增强了动物健康监测能力，为农业监控提供了有效的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08925", "html_url": "https://arxiv.org/abs/2510.08925", "title": "通过特征空间扰动防御图像恢复中的未经授权的知识蒸馏", "title_en": "Defense against Unauthorized Distillation in Image Restoration via Feature Space Perturbation", "authors": "Han Hu,Zhuoran Zheng,Chen Lyu", "background": "知识蒸馏(KD)攻击通过让对手利用教师模型的输出训练学生网络，对深度模型的知识产权构成了严重威胁。尽管最近针对图像分类的防御措施可以成功破坏KD，但将这些方法扩展到图像恢复中存在困难。图像恢复是生成性任务，具有连续且高维的输出，依赖于空间连贯性和细节。简单的输出概率扰动通常不足以阻止学生网络学习底层信息。因此，需要针对图像恢复模型制定特定的防御措施。为此，本文提出了一种名为自适应奇异值扰动(ASVP)的运行时防御方法。ASVP在教师模型的内部特征图上应用奇异值分解(SVD)，通过放大前k个奇异值来注入有结构的高频扰动，从而破坏蒸馏所需的对齐，同时保持教师模型的输出基准。该方法在图像恢复五个任务（超分辨率、低光照增强、水下增强、除雾和除雨）中进行了评估，实验表明ASVP可以降低学生网络的PSNR高达4 dB，SSIM降低60-75%，对教师模型性能的影响几乎可以忽略不计。与以前的方法相比，ASVP提供了更强且更一致的防御措施，作为一种实际解决方案，可用于保护开源恢复模型免受未经授权的知识蒸馏攻击。", "innovation": "本文提出了一种名为自适应奇异值扰动(ASVP)的运行时防御方法，专门针对图像恢复模型。ASVP通过在教师模型的内部特征图上应用奇异值分解(SVD)来放大前k个奇异值，注入结构化、高频扰动，从而破坏蒸馏对齐，同时保持教师模型的输出基准。这种方法能有效应对图像恢复任务中的知识蒸馏攻击，与其他方法相比具有更强且更一致的效果。", "conclusion": "本文提出的自适应奇异值扰动(ASVP)为图像恢复模型提供了有效的运行时防御措施，可以阻挡未经授权的知识蒸馏攻击，同时不对教师模型的性能造成明显影响。通过在五个图像恢复任务上的广泛评估，ASVP展现了其作为实际解决方案的潜力，保护开源图像恢复模型免受知识蒸馏威胁。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08970", "html_url": "https://arxiv.org/abs/2510.08970", "title": "mmJoints: 在毫米波基于的3D姿态估计中扩展关节表示超出(x,y,z)之外", "title_en": "mmJoints: Expanding Joint Representations Beyond (x,y,z) in mmWave-Based 3D Pose Estimation", "authors": "Zhenyu Wang,Mahathir Monjur,Shahriar Nirjon", "background": "在基于毫米波的姿势估计中，稀疏信号和微弱反射常常导致模型依赖统计先验而非传感器数据来推断人体关节位置。尽管先验知识有助于学习有意义的表示，但过度依赖先验知识在诸如手势和活动识别等下游任务中的性能会受到影响。", "innovation": "本文提出了一种名为mmJoints的框架，该框架通过增加额外的关节描述符来增强预先训练好的黑盒毫米波3D姿态估计器的输出。mmJoints通过估计关节被准确检测的几率及其预测位置的可靠性，使其表达更加直观，并提高了下游任务的准确性。通过超过115,000个信号帧的广泛评估，在各种13种姿态估计设置中，mmJoints在描述符估计误差率低于4.2%的情况下，使关节位置精度提高了最多12.5%，且活动识别提高了最多16%，超越了最先进的方法。", "conclusion": "通过广泛的评估，实验证明mmJoints在多个维度上提供了显著的改进，不仅增强了姿势估计模型的解释性，而且提高了手势和活动识别的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08979", "html_url": "https://arxiv.org/abs/2510.08979", "title": "不可彩色化图像：通过感知感知色域限制扰动防止未经授权的AI着色", "title_en": "Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation", "authors": "Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen", "background": "基于AI的着色技术在从灰度图像生成逼真彩色图像方面表现出色，但这也带来了版权侵权的风险，如未经授权的着色和再销售黑白漫画和电影。尽管存在这些担忧，目前还没有有效的方法来防止这种滥用。", "innovation": "提出了首个防攻击框架，即不可彩色化图像，该框架通过在灰度图像中嵌入不可感知的扰动来无效化未经授权的着色。还提出了一种名为Perception-Aware Chroma-Restrictive Perturbation (PAChroma)的方法，可以通过优化不可感知的扰动并应用多样化的输入变换，生成满足有效、不可感知、可移植和鲁棒性四个标准的不可彩色化图像。", "conclusion": "实验证明PAChroma可以有效降低着色质量同时保持视觉外观。这项工作标志着在防止非法AI着色方面迈出的重要一步，为生成媒体的版权意识防御铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08976", "html_url": "https://arxiv.org/abs/2510.08976", "title": "基于分层调度的多向量图像检索", "title_en": "Hierarchical Scheduling for Multi-Vector Image Retrieval", "authors": "Maoliang Li,Ke Li,Yaoyang Liu,Jiayu Chen,Zihao Zheng,Yinjun Wu,Xiang Chen", "background": "当前在多模态大型语言模型应用中，通过检索增强生成（RAG）利用用户特定数据。常规的检索方法通常存有较低的检索精度问题。虽然最近的多向量检索（MVR）技术通过查询分解和图像分段匹配已有所提升，但仍然存在精度和效率不足的问题，尤其是在查询与图像对象对齐和冗余细粒度图像分段方面。这些挑战使得现有系统难以在多样化场景中提供高效和准确的服务。", "innovation": "本文提出了一种高效的图像检索调度框架——HiMIR。首先，它引入了一个新颖的分层框架，采用多个中间粒度对不同图像对象进行分层处理，以增强对齐能力。其次，它通过利用跨分层相似性一致性和分层稀疏性来最小化冗余检索，减少不必要的匹配计算。此外，系统能够自动为每个数据集配置参数，提高其在各种场景下的实用性。研究表明，HiMIR不仅大幅度提高了检索精度，还比当前的MVR系统减少了3.5倍的计算量。", "conclusion": "HiMIR框架不仅在检索精度上取得了显著的提升，而且通过有效的调度减少了许多不必要的计算，实现了高效的图像检索效率。这一创新在多模态大型语言模型应用中具有重要的实际应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08994", "html_url": "https://arxiv.org/abs/2510.08994", "title": "Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation", "title_en": "Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation", "authors": "Yao Teng,Fuyun Wang,Xian Liu,Zhekai Chen,Han Shi,Yu Wang,Zhenguo Li,Weiyang Liu,Difan Zou,Xihui Liu", "background": "自回归文本到图像模型作为一种视觉内容生成的新范式，在推理过程中由于其逐个令牌的序列解码过程而变得非常缓慢，通常需要数千次模型前向传递来生成一个图像。", "innovation": "提出了一种名为Speculative Jacobi-Denoising Decoding (SJD2)的框架，将去噪过程整合到雅可比迭代中，以在自回归模型中实现并行令牌生成。方法引入了“预测下一个干净令牌”的范式，使得预训练的自回归模型能够接受噪声扰动的令牌嵌入，并通过低成本微调来预测下一个干净令牌。这种去噪范式引导模型向更稳定的雅可比轨迹发展。在推理阶段，方法使用高斯噪声初始化令牌序列，并在嵌入空间中进行迭代的“预测下一个干净令牌”的预测。使用概率标准并行验证和接受多个令牌，并在去噪轨迹下对未接受的令牌进行精炼以备下一次迭代。实验表明，与减少数目的模型前向传递次数相比，该方法能够加速生成同时保持生成图像的视觉质量。", "conclusion": "通过使用Speculative Jacobi-Denoising Decoding框架，可以提高自回归文本到图像模型生成过程的速度，同时保持生成图像的视觉质量。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09008", "html_url": "https://arxiv.org/abs/2510.09008", "title": "对于大型视觉语言模型中物体幻觉的视觉标记的先验不确定性", "title_en": "On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models", "authors": "Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun", "background": "大型视觉语言模型（LVLMs）通过将视觉编码器（VE）与大型语言模型结合，在各种任务中取得了显著的成功。然而，LVLMs 仍面临诸如物体幻觉等关键挑战，即将描述图像中不存在的对象的错误描述生成出来。", "innovation": "研究者认为不确定的视觉标记是导致物体幻觉的关键因素，并提出了一种通过修改视觉编码器而无需改变语言模型的方法来减轻物体幻觉。该方法首先使用包含对抗扰动的代理方法来高效地识别不确定的视觉标记，然后在视觉编码器中间层的自我关注过程中掩盖这些不确定的视觉标记，从而抑制它们对视觉编码的影响，进而缓解幻觉现象。", "conclusion": "广泛的实验表明，该方法能够显著减少LVLMs中的物体幻觉现象，并且能够与其他现有的方法协同工作。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08964", "html_url": "https://arxiv.org/abs/2510.08964", "title": "唤醒多模态推理模型的感知时间缩放", "title_en": "Unleashing Perception-Time Scaling to Multimodal Reasoning Models", "authors": "Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu", "background": "近期，在推理时间扩展方面的进展，特别是利用强化学习和可验证奖励的策略，极大地增强了大型视觉-语言模型（LVLMs）的推理能力。受此启发，类似策略已被应用于多模态推理中，但这些方法对视觉感知的影响尚不清楚。为填补这一空白，本研究引入了DisTANCE，一个以感知为中心的基准测试，用于视觉估计任务。评估结果表明，LVLMs在估计精度上表现有限，而推理时间扩展仅提供了一点帮助。我们将其归因于当前LVLMs的快速感知范式，其中视觉理解被视为一次性输出，不建模底层感知过程。为解决这一问题，我们提出了一种新颖的感知时间扩展（PTS）范式，该范式鼓励丰富的感知标记，并将复杂的感知问题分解为中间可解决的子问题，从而使感知能够与和受益于推理时间扩展。结合强化学习技术，PTS显着提高了感知准确性，将DisTANCE上的高精度性能从8.0%提高到64.7%，并很好地推广到了域外任务。令人惊讶的是，尽管PTS数据完全是合成的，但它们与数学推理数据结合使用，在推理和现实世界感知基准测试中均取得一致的改进。进一步分析表明，PTS引入了更多的感知相关标记，并增加了模型对图像标记的关注。", "innovation": "文中提出了一种名为感知时间扩展（PTS）的新范式，它鼓励丰富的感知标记，并将复杂的感知问题分解为中间可解决的子问题，从而使感知能够与和受益于推理时间扩展。结合强化学习技术，PTS在视觉估计任务上取得了显著的改进，显著提升了高精度性能。此外，研究还表明，即使PTS数据完全是合成的，它们与数学推理数据结合使用，在推理和现实世界感知基准测试中均取得一致的改进。", "conclusion": "本研究介绍了DisTANCE，一个以感知为中心的视觉估计基准测试，经过验证，LVLMs在估计精度上表现有限，而推理时间扩展仅提供了一点帮助。通过对IEWP数据集的进一步分析，我们提出了一种感知时间扩展（PTS）范式，结合强化学习技术，显着提高了视觉估计的准确性。在DisTANCE基准上取得了64.7%的高精度性能，并且模型对图像标记的关注度提高。我们的结果表明，PTS能够增强LVLMs的感知能力和泛化能力，并公开发布我们的代码和数据。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08978", "html_url": "https://arxiv.org/abs/2510.08978", "title": "HandEval：迈向生成图像中手部质量评估的第一步", "title_en": "HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images", "authors": "Zichuan Wang,Bo Peng,Songlin Yang,Zhenchen Tang,Jing Dong", "background": "尽管最近的文本到图像（T2I）模型在生成图像的整体视觉质量上取得了重大进展，但在复杂局部区域（尤其是人类手部）生成准确细节方面仍然存在困难。生成的手部经常表现出结构失真和不现实的纹理，即使身体的其他部分生成得很好，这些细节也很容易被发现。然而，对手部区域的质量评估仍然被忽略，限制了诸如以人类为中心的生成质量优化和大模型生成内容检测等下游任务的表现。", "innovation": "该研究提出了第一个专门针对生成手部区域的质量评估任务，并展示其丰富的下游应用。首先介绍了用于训练手部质量评估模型的HandPair数据集，通过高质和低质手部图像配对，无需手动标注即可实现低成本、高效的监督。在此基础上开发了HandEval，这是一种精心设计的手部特定质量评估模型，利用多模态大型语言模型的强视觉理解能力和手部关键点的先验知识，实现了对手部质量的强感知。进一步构建了手工标注的测试集，以验证其质量评估能力。实验证明，HandEval在手部质量评估上与现有的顶级方法有更好的一致性。此外，将HandEval整合到图像生成和大模型生成内容检测管道中，显着增强了生成手部的现实感和检测精度，证实了其在下游应用中的普遍有效性。", "conclusion": "HandEval通过提出专门针对生成手部区域的质量评估任务，并将其整合到图像生成和大模型生成内容检测管道中，显著优化了生成的手部的真实性和检测准确性，证明了其在下游应用中的广泛有效性。同时HandPair数据集的建立，为低手动标注成本和高效的训练提供了支持。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09012", "html_url": "https://arxiv.org/abs/2510.09012", "title": "从熵的角度探讨更优秀和更快的自回归图像生成", "title_en": "Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy", "authors": "Xiaoxiao Ma,Feng Zhao,Pengyang Ling,Haibo Qiu,Zhixiang Wei,Hu Yu,Jie Huang,Zhixiong Zeng,Lin Ma", "background": "当前自回归（AR）图像生成模型在采样时存在一些问题，具体表现为图像令牌和文本令牌相比具有较低的信息密度和非均匀的空间分布。", "innovation": "本研究提出了一种熵指导下的解码策略，该策略在保证内容多样性、对齐精度和结构连贯性的同时提升了自回归生成的质量，并加快了合成速度。具体创新点包括：1）基于令牌分布空间熵的动态温度控制，这一策略在不增加额外计算开销的情况下提升了基于掩码和尺度的模型生成的质量；2）熵感知接受规则应用于推测性解码，实现了近乎无损生成，且仅需传统加速方法85%的推理成本。", "conclusion": "在多种基准测试中使用不同的AR图像生成模型进行的广泛实验表明，该方法在提高生成质量和采样速度方面具有有效性与普适性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09092", "html_url": "https://arxiv.org/abs/2510.09092", "title": "GL-DT：基于全局-局部集成的多无人机检测与跟踪", "title_en": "GL-DT: Multi-UAV Detection and Tracking with Global-Local Integration", "authors": "Juanqin Liu,Leonardo Plotegher,Eloy Roura,Shaoming He", "background": "无人机在军事侦察、环境监测等相关领域的广泛应用，迫切需要一种精确且高效的多对象跟踪（MOT）技术，这对于无人机的情况感知至关重要。然而，复杂的背景、小尺度目标以及频繁的遮挡和互动，依然给现有的方法在检测精度和轨迹连续性方面带来了挑战。", "innovation": "提出了全局-局部检测与跟踪（GL-DT）框架，通过时空特征融合（STFF）模块联合建模运动和外观特征，并结合全局-局部协作检测策略，有效提升了小目标检测能力。在此基础上，引入了JPTrack跟踪算法来解决常见的身份转换和轨迹断裂问题。实验结果表明，所提出的方法在保持实时性能的同时显著提高了MOT的连续性和稳定性。", "conclusion": "GL-DT框架有效提高了无人机多物体跟踪的连续性和稳定性，同时保持了实时性能，为无人机检测与跟踪技术的发展提供了有力支持。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09056", "html_url": "https://arxiv.org/abs/2510.09056", "title": "在合成DWI和ADC图像从CT灌注扫描中对潜空间扩散模型进行病灶意识后训练", "title_en": "Lesion-Aware Post-Training of Latent Diffusion Models for Synthesizing Diffusion MRI from CT Perfusion", "authors": "Junhyeok Lee,Hyunwoong Kim,Hyungjin Chung,Heeseong Eom,Joon Jang,Chul-Ho Sohn,Kyu Sung Choi", "background": "图像到图像的翻译模型能够帮助缓解医学图像获取中固有的各种挑战。潜空间扩散模型（LDMs）通过在压缩的潜在空间中高效学习构成最先进的生成图像模型的核心。然而，这一效率带来了权衡，可能会牺牲高保真医学图像所需的像素级详细信息。特别是，在生成诸如病灶等临床显著结构时，这种限制变得尤为重要，因为这些结构往往只占据图像的小部分。病灶重建不准确可能严重影响诊断可靠性和临床决策。用于急性缺血性中风患者的脑部CT到MRI翻译中，早期和准确的诊断对于最佳治疗选择和改善患者结果至关重要。虽然扩散MRI是中风诊断的金标准，但其临床应用受到高成本和低可访问性限制。", "innovation": "本文提出了一种新颖的后训练框架，即在潜空间扩散模型中嵌入病灶感知的医学像素空间目标。这种策略不仅能提高整体图像质量，还能提高病灶轮廓的精度。通过一个包含817名患者的CT灌注扫描数据集，我们的框架在合成DWI和ADC图像时展示了优于现有图像到图像翻译模型的效果。此外，我们的后训练策略可用于预训练的LDMs，并具备广泛应用于不同医学图像翻译任务的潜力。", "conclusion": "我们的研究方法在脑部急性缺血性中风患者的CT到MRI翻译中取得了显著效果，展示了在合成DWI和ADC图像时改善整体图像质量和病灶轮廓的潜力。该方法在病灶填充和轮廓生成方面超过了现有的图像到图像翻译模型，提高了诊断的可靠性和准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09035", "html_url": "https://arxiv.org/abs/2510.09035", "title": "在不完美标签下探索基于LiDAR的语义分割单域泛化", "title_en": "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels", "authors": "Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen", "background": "准确的感知对于车辆安全至关重要，而LiDAR作为自动驾驶的关键技术，起到了重要作用。为了确保LiDAR在不同环境、传感器类型和天气条件下的鲁棒表现，无需多次人工标注，基于LiDAR的3D语义分割的领域泛化是关键。然而，由于传感器缺陷、遮挡和人为错误，LiDAR标签往往带有噪声，这种噪声会降低分割精度，并在领域迁移时进一步放大，威胁系统的可靠性。虽然图像中的嘈噪声学习已有广泛研究，但其在3D LiDAR分割中的应用尚未得到充分探索，因为点云的稀疏和不规则结构限制了2D方法的直接应用。", "innovation": "本文提出了新的任务——在嘈噪声标签下的LiDAR语义分割的单域泛化（DGLSS-NL），并基于图像分类中的三个代表性嘈噪声学习策略建立了首个基准。但发现现有嘈噪声学习方法适应LiDAR数据效果不佳，因此提出DuNe框架，采用强弱分支相结合的方法，强制特征层一致性，并结合基于预测置信度筛选的信心滤波应用交叉熵损失。该方法在SemanticKITTI、nuScenes和SemanticPOSS数据集上分别实现了56.86%、42.28%和52.58%的mIoU，在10%对称标签噪声下取得最佳性能。", "conclusion": "本文的研究展示了在DGLSS-NL任务中基于LiDAR的3D语义分割的域泛化的稳健性，实验结果证明了该方法的有效性，整体算术平均值为49.57%，调和平均值为48.50%。相关的代码可在项目页面获取。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09071", "html_url": "https://arxiv.org/abs/2510.09071", "title": "Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array", "title_en": "Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array", "authors": "Yitong Chen,Xinyao Xu,Ping Zhu,Xinyong Han,Fangbo Qin,Shan Yu", "background": "柔性微电极（FME）植入脑皮层是一项具有挑战性的工程，因为FME探针纤维状的可变形结构和与关键生物组织的相互作用导致操作复杂且风险高。为了确保植入过程的安全性和可靠性，需要仔细监控植入过程。为此，本文开发了一种基于微型摄像头的异常检测框架，应用于机器人FME植入系统的各个关卡，以检查微针、FME探针、固定结果和植入点。利用现有的对象定位结果，从原始图像中提取对齐的感兴趣区域（ROIs）并输入预训练视觉变换器（Vision Transformer，ViT）进行分析。", "innovation": "本文提出的视觉异常检测方法，通过在视觉Transformer中采用逐级粒度切片特征采样方法，解决了不同位置的灵敏度-容限权衡问题，并从原始通用ViT特征中选择具有更高信噪比的部分特征通道，以提供更适合特定场景的描述符。这种方法的有效性已经在团队植入系统收集的数据集上得到了验证，从而实现了柔性微电极阵列植入过程的可靠监控。", "conclusion": "本文研发了一种基于视觉Transformer的异常检测框架，用于机器人FME植入系统的各个关卡，以提高植入过程的可靠性和安全性，验证了该方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09107", "html_url": "https://arxiv.org/abs/2510.09107", "title": "一种用于CT扫描中识别细微病理特征的新型多分支ConvNeXt架构", "title_en": "A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans", "authors": "Irash Perera(1),Uthayasanker Thayasivam(1) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka)", "background": "智能医学影像分析在辅助临床诊断中发挥着重要作用，特别是用于识别细微的病理特征。本文介绍了一种专门为医学图像分析中的复杂挑战设计的新颖多分支ConvNeXt架构。", "innovation": "该研究提出了一种独特的多分支架构，包括三种并行提取特征的分支：全局平均池化、全局最大池化和新的注意力加权池化机制。该模型采用了严谨的端到端管道，从细致的数据预处理和增强到有效的迁移学习双重训练策略。", "conclusion": "实验结果表明，该模型在验证数据集上的表现优于所有之前报道的模型，最终ROC-AUC为0.9937，验证精度为0.9757，F1分数为0.9825。这些发现表明，结合现代多分支架构和精细数据处理的最新深度学习技术可以实现与或超越当前最先进的模型的性能，证明了高级深度学习技术在医疗诊断中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09088", "html_url": "https://arxiv.org/abs/2510.09088", "title": "MambaH-Fit：通过状态空间建模重新思考基于超曲面拟合的点云法线估计", "title_en": "MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling", "authors": "Weijia Wang,Yuanzhi Su,Pei-Gen Ye,Yuan-Gen Wang,Xuequan Lu", "background": "现有的法线估计方法往往在建模精细几何结构方面表现不佳，从而限制了预测法线的准确性。虽然状态空间模型（SSMs），特别是Mamba，能够捕捉长时间依赖性并以线性复杂度进行建模，但现有的基于Mamba的方法主要集中在理解全局形状结构，而对局部微细几何细节的建模则未得到充分探索。因此，该研究旨在通过引入注意力驱动的分层次特征融合方案（AHFF）来增强局部点云邻域中的几何上下文学习，并通过点云片状状态空间模型（PSSM）来基于状态动力学将点云碎片建模为隐式超曲面，以实现有效的微细几何理解，从而提高法线预测的准确性、稳定性和灵活性。", "innovation": "该研究提出了一个名为MambaH-Fit的状态空间建模框架，该框架特别适用于基于超曲面拟合的点云法线估计。引入了注意力驱动的分层次特征融合方案（AHFF），以自适应融合多尺度点云片段特征，显著增强了局部点云邻域中的几何上下文学习。此外，还提出了点云片状状态空间模型（PSSM），该模型通过状态动力学将点云碎片建模为隐式超曲面，有效实现细观几何理解，从而提高法线预测的性能。实验结果表明，该方法在准确性、稳健性和灵活性方面均优于现有方法。", "conclusion": "本文提出的方法在基准数据集上的广泛实验中表现出色，证明了其在准确性和颗粒度几何理解方面的优势。消除研究进一步验证了所提出组件的贡献。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09094", "html_url": "https://arxiv.org/abs/2510.09094", "title": "Dense2MoE: 将密集型扩散变换器重构为MoE以实现高效的图文生成", "title_en": "Dense2MoE: Restructuring Diffusion Transformer to MoE for Efficient Text-to-Image Generation", "authors": "Youwei Zheng,Yuxi Ren,Xin Xia,Xuefeng Xiao,Xiaohua Xie", "background": "扩散变换器(DiT)在图文生成任务中表现出了显著的效果，但其庞大的参数规模导致了显著的推理延迟。现有的参数压缩方法主要集中在剪枝上，然而，过度剪枝通常会导致模型性能大幅下降，因为这会降低模型的能力。为了克服这一限制，作者采取了将密集型DiT转换为混合专家(MoE)结构的方法，以结构化的方式实现稀疏化，同时保持模型的能力。具体来说，作者用MoE层替换了DiT块中的前馈神经网络(FFN)，减少了FFN中激活参数的数量。此外，作者还提出了块混合(MoB)来有选择地激活DiT块，从而进一步增强稀疏性。作者设计了一个多步骤的蒸馏管道确保结构化转换的效率，其中包括利用Taylor度量专家初始化、负载平衡的知识蒸馏和组特征损失来优化MoB。通过将大型扩散变换器转换为MoE结构，减少了激活参数的数量，同时保持了原始性能，并在广泛的实验中超过了基于剪枝的方法，从而建立了新的高效图文生成范式。", "innovation": "提出了将密集型扩散变换器转换为混合专家结构的方法，采用MoE层替换DiT块中的FFN，减少了激活参数的数量。设计了块混合(MoB)策略，有选择性地激活DiT块，进一步增强了稀疏性。还设计了一种多步骤的蒸馏管道，包括Taylor度量专家初始化、负载平衡的知识蒸馏和组特征损失来优化MoB，确保转换的有效性和高效性。", "conclusion": "Dense2MoE通过将密集型DiT重构为MoE结构，实现了高效的图文生成，并保持了原性能，超越了基于剪枝的方法，建立了新的高效图文生成范式。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09110", "html_url": "https://arxiv.org/abs/2510.09110", "title": "SOS: 合成对象分割改善检测、分割和语义定位", "title_en": "SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding", "authors": "Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna", "background": "视觉分组通过实例分割、视觉定位和对象检测实现，支撑着从机器人感知到照片编辑的多种应用。现有的大型标注数据集昂贵且具有覆盖偏向性，难以扩展。合成数据虽具潜力，但也通常缺乏灵活性、准确性和组合适用性。本文探讨了一种基于对象中心组合策略的简单且可扩展的数据合成管道SOS，该管道利用结构性布局先验和生成性光照生成高质量的合成对象分割段落，生成精确且多样化的遮罩、边界框和参照表达。与从GRIT（2000万图）和V3Det（20万图）等大规模真实图像数据集训练模型相比，SOS合成的数据集表现更佳，尤其在检测和定位任务中的性能更为突出。", "innovation": "本文提出了SOS，一种基于对象中心组合策略的简单且可扩展的数据合成管道。通过利用结构性布局先验和生成性光照，SOS能够合成高质量且多样化的对象分割段落，并且生成的遮罩、边界框及参照表达同样精准。此研究证明，由SOS合成的10万张图像训练的模型在检测和定位表现上优于更大规模的真实图像数据集（如GRIT和V3Det），尤其在LVIS检测中提高10.9 AP，在gRefCOCO定位中提高8.4 NAcc。SOS不仅可以控制数据集构建，还能在数据稀缺或概念封闭场景中提高泛化能力，并且在真实数据量极小的情况下表现出更强的结果。", "conclusion": "SOS合成了大量的高质量合成对象分割数据，显著提高了基于这些图像训练模型的检测、分割和语义定位性能。与大规模真实数据集相比，SOS合成的数据集甚至在极少量的现实图像数据情况下也能取得显著改进，进一步证实其在机器人感知等领域的应用潜力。SOS为视觉定位中的困难内类可能指生提供有针对性的数据生成支持，改善了低数据量和封闭词汇场景下的识别性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09171", "html_url": "https://arxiv.org/abs/2510.09171", "title": "实例级别的生成用于表示学习", "title_en": "Instance-Level Generation for Representation Learning", "authors": "Yankun Wu,Zakaria Laskar,Giorgos Kordopatis-Zilos,Noa Garcia,Giorgos Tolias", "background": "实例级别识别（ILR）专注于识别单个对象而非宽泛的类别，提供图像分类中最高的粒度。然而，这种精细的特性使得创建大规模注释数据集变得具有挑战性，限制了ILR在各个领域的实际应用。", "innovation": "本文提出了一种新的方法，通过从多个领域在多种条件和背景下合成多样化的对象实例来生成大规模的训练集，这是首次无需使用任何真实图像即可解决ILR特定挑战的方法。在生成数据上微调基础视觉模型显著提高了七种跨越多个领域的ILR基准测试中的检索性能。", "conclusion": "本文提出的方法为从广泛的输入域名称生成数据提供了一种新颖的、高效和有效的替代选择，为ILR引入了一个新的范式，仅需输入目标领域名称即可解锁广泛的实际应用，同时解决了大规模数据收集和整理的挑战。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09121", "html_url": "https://arxiv.org/abs/2510.09121", "title": "MSDM：利用多模态条件扩散模型生成特定任务的病理图像以改善细胞和核分割", "title_en": "MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation", "authors": "Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu", "background": "由于标注数据稀缺，特别是对于罕见或非典型形态，计算病理学中的细胞和核分割面临重大挑战。人工标注耗时且成本高，而合成数据提供了一种成本效益高的替代方案。多模态语义扩散模型（MSDM）被引入，用于生成具有像素级精确度的图像-掩码对，以利于细胞和核分割。通过采用细胞/核形态（水平和垂直图）、RGB颜色特征以及BERT编码的实验/指示元数据作为生成过程的条件，MSDM可以生成具有所需形态学特性的数据集。多头交叉注意力机制将这些模态整合在一起，从而实现对生成图像的细微控制。定量分析表明，生成的图像与真实数据高度匹配，在匹配的生物条件下，生成图像和真实图像之间的Wasserstein距离较低。外推分列细胞等合成样本，显著提高了列细胞分割模型的准确性。这一策略系统地丰富了数据集，直接针对模型的缺陷进行改进，从而使研究者得以利用生成模型在计算病理学中的广泛应用。", "innovation": "MSDM通过结合多种模态条件和多头交叉注意力机制生成像素级精确的图像-掩码对，这些图像带有特定任务需要的形态学特性，如不同类型的细胞和核的形态。生成的数据集不仅形态类似真实数据，还能显著提高目标细胞的分割准确率，尤其是在处理稀缺或罕见形态时。这项工作展示了多模态扩散模型在提高细胞和核分割模型鲁棒性和泛化能力方面的有效性，为计算病理学中的应用铺平了道路。", "conclusion": "MSDM通过系统地丰富数据集，直接针对模型的缺陷进行了改进，有效地提高了目标细胞的分割准确率。这种方法为计算病理学中的广泛应用奠定了基础，利用生成模型可以显著提升模型的鲁棒性和泛化能力，从而促进了计算病理学的发展。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09182", "html_url": "https://arxiv.org/abs/2510.09182", "title": "在线视频深度一切：低内存消耗的临时一致深度预测", "title_en": "Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption", "authors": "Johann-Friedrich Feiden,Tim Küchler,Denis Zavadski,Bogdan Savchynskyy,Carsten Rother", "background": "单目视频的深度估计已成为许多实际计算机视觉系统的关键技术。最近，Video Depth Anything (VDA) 在长视频序列上展现了强大的性能。然而，它依赖于批量处理，这阻止了它在在线设置中的使用。", "innovation": "本文克服了这一限制，并引入了在线VDA (oVDA)。关键创新是采用了大型语言模型（LLM）的技术，具体来说，在推理过程中缓存潜特征并在训练中屏蔽帧。oVDA 方法在准确性和VRAM使用方面均优于所有现有的在线视频深度估计方法。", "conclusion": "oVDA 在 NVIDIA A100 上以每秒 42 帧运行，并在 NVIDIA Jetson 边缘设备上以每秒 20 帧运行。我们还会发布代码和编译脚本，使 oVDA 可以轻松部署在低功耗硬件上。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09125", "html_url": "https://arxiv.org/abs/2510.09125", "title": "Polar Separable Transform for Efficient Orthogonal Rotation-Invariant Image Representation", "title_en": "Polar Separable Transform for Efficient Orthogonal Rotation-Invariant Image Representation", "authors": "Satya P. Singh,Rashmi Chaudhry,Anand Srivastava,Jagath C. Rajapakse", "background": "正交矩量基图像表示在计算机视觉中具有基础性，但传统方法存在计算复杂度高和数值不稳定的问题，特别是在高阶矩量下，如Zernike和伪Zernike矩量需要耦合的径向-角向处理，这阻碍了高效的因子化，导致计算复杂度在$\\mathcal{O}(n^3N^2)$到$\\mathcal{O}(n^6N^2)$之间，角向根条件数在$\\mathcal{O}(N^4)$范围内。", "innovation": "提出了PSepT（Polar Separable Transform），一种克服极坐标非分离性障碍的分离正交变换。PSepT通过离散余弦变换（DCT）径向基础和傅里叶谐波角向基础的张量积构造，实现了完整的核因子化，使得径向和角向处理可以独立进行。这种分离设计将计算复杂度降低到$\\mathcal{O}(N^2 \"log N)$，内存需求降低到$\\mathcal{O}(N^2)$，根条件数趋于$\\mathcal{O}(\\sqrt{N})$，在多项式方法上具有指数级改进。PSepT具备正交性、完备性、能量守恒和旋转协变性等特性。实验结果表明，PSepT具有更好的数值稳定性、计算效率和在结构化数据集上具有竞争力的分类性能，同时保留了精确重建。因此，分离框架使使用传统方法难以实现的高阶矩量分析成为可能，为稳健的图像分析应用开辟了新的可能。", "conclusion": "PSepT实现了高效、正交和旋转不变的图像表示，具有较低的计算复杂度和内存需求，并且在高阶矩量分析上具有优势。实验结果验证了其性能，并为图像分析应用开辟了新前景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09144", "html_url": "https://arxiv.org/abs/2510.09144", "title": "在线拓扑定位在支气管镜导航辅助中的应用", "title_en": "Online Topological Localization for Navigation Assistance in Bronchoscopy", "authors": "Clara Tomasini,Luis Riazuelo,Ana C. Murillo", "background": "支气管镜检查是呼吸医学中的基本程序，医生需要通过患者的气道导航并到达兴趣部位进行诊断或治疗。这项任务对医生来说非常具有挑战性，因为气道结构复杂且医生的经验和训练水平不同。导航辅助可以提高操作效果，但目前常用的导航辅助技术通常需要患者的CT扫描数据以获得三维气道模型，然后通过传感器定位或图像配准进行跟踪，这种方法虽然能获得准确的位置，但需要额外的设置、扫描和训练。准确的量化定位并不总是在必要，通过相对通用的气道模型进行拓扑定位也能满足手术导航的需求。", "innovation": "本文提出了基于图像的支气管镜拓扑定位流程，无需患者CT扫描数据。该方法仅使用模拟数据进行训练，可以节省高昂的真实数据标注成本，且具有良好的泛化能力。实验结果表明，该方法在真实数据测试序列上的表现优于现有方法。", "conclusion": "本文研究了无患者CT扫描数据的支气管镜在线拓扑定位，通过模拟数据训练实现了良好的导航辅助效果，相较于现有方法，该方法在真实数据上的表现更为出色。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09173", "html_url": "https://arxiv.org/abs/2510.09173", "title": "TARO：迈向语义丰富的开放世界目标检测", "title_en": "TARO: Toward Semantically Rich Open-World Object Detection", "authors": "Yuchen Zhang,Yao Lu,Johannes Betz", "background": "现有的目标检测方法大多基于‘封闭世界’假设，只能识别预定义的类别，当遇到未知物体时存在风险。开放集检测方法通过将未知对象标记为‘未知’来解决这个问题，但这种方法往往不够充分。TARO通过将所有未知物体细分为更加描述性的子类别，增强在安全关键场景下的决策能力，特别是在自动驾驶领域，例如将物体识别为‘未知动物’（需要紧急刹车）或‘未知碎片’（需要安全变道）比直接标记为‘未知’更有用。", "innovation": "TARO是一种新颖的检测框架，它不仅能够识别未知物体，还能将其细分为语义层级中的粗分父类。TARO采用独特的架构，包括基于sparsemax的头部进行物体检测建模、根据语义层级进行辅助监督的重分类组件以及学习语义层级关系的分类模块。实验结果显示，TARO能够将高达29.9%的未知物体分类为有意义的粗分类别，显著减少了未知和已知类别的混淆，同时在未知召回率和已知mAP方面实现了竞争力的性能。", "conclusion": "TARO能够处理开放式目标检测中的未知类别问题，通过细分类别提高决策准确性和安全性，并且实验结果显示其在多个指标上表现良好。源代码也将公开。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09135", "html_url": "https://arxiv.org/abs/2510.09135", "title": "视觉模型的训练特征归因", "title_en": "Training Feature Attribution for Vision Models", "authors": "Aziz Bacha,Thomas George", "background": "深度神经网络因其不透明性而被认为不易解释，这要求开发解释性方法以提高人们对这些系统的信任和问责制。现有的归因方法通常将测试时的预测归因于输入特征（例如图像中的像素）或有影响力的学习样本。尽管这些方法各有优势，但现有研究主要单独关注这些方面。该论文提出了一种新的视角，即将测试预测与特定训练图像的特定区域联系起来，以此来深化对深度模型工作机制的理解。实验结果显示，训练特征归因能够提供细粒度且针对测试的具体解释：它能够识别导致分类错误的危害性示例，并揭示诸如基于块的捷径等假象相关性，而这些关联传统归因方法未能充分揭示。", "innovation": "该研究提出了一种新的训练特征归因方法，不仅将测试预测与输入特征关联起来，还进一步与特殊训练图像的具体区域联系起来，提供了一种新的关联视角。这种方法能够在精细粒度上揭示模型决策背后的机制，找出导致误分的危害性训练样本，并暴露出传统方法未能揭示的假象相关性，如基于块的捷径。这种新的解释方法强调了同时考虑输入特征和训练实例的重要性，为提高模型的透明度和理解提供了新途径。", "conclusion": "研究发现，训练特征归因提供了精确且针对测试的解释，它不仅识别了导致分类错误的危害性训练样本，还揭示了许多传统方法难以捕捉到的假象相关性，这些发现加深了对深度模型工作机制的理解，促进了模型的透明度和可解释性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09200", "html_url": "https://arxiv.org/abs/2510.09200", "title": "向更安全、可理解的驾驶员意图预测迈进", "title_en": "Towards Safer and Understandable Driver Intention Prediction", "authors": "Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar", "background": "自主驾驶（AD）系统由于最近深度学习和人工智能的进展而越来越能够处理复杂的任务。随着自主系统与人类互动的增加，确保安全驾驶操作的关键在于确保决策过程的可解释性。为了实现成功的人机互动，必须理解环境和驾驶任务的底层表示，而这一点在基于深度学习的系统中仍然是一个重大挑战。本文针对这一问题，在AD系统中提出了预测行为发生前的可解释性任务，即驾驶员意图预测（DIP），这对于安全驾驶至关重要。为此，作者创建了一个新的多模态、以自我为中心的视频数据集——可解释的驾驶行为预测数据集（DAAD-X），用于提供分级的高层次文本解释作为因果推理。这些解释是基于驾驶员的眼球轨迹和自我车辆的视角生成的。", "innovation": "本文提出了视频概念瓶颈模型（VCBM），这是一个能自动生成时空连贯解释的框架，无需依赖于事后技术。通过广泛的评估发现，基于Transformer的模型比传统的基于CNN的模型更具有可解释性。此外，作者还引入了一种多标签t-SNE可视化技术来展示多个解释之间的分离性和因果相关性。", "conclusion": "通过在DAAD-X数据集上进行广泛的评估，本文展示了基于Transformer的模型在可解释性方面优于传统CNN模型。为进一步促进代表性可解释性DIP的研究，作者将数据、代码和模型提供在指定的网址中。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09187", "html_url": "https://arxiv.org/abs/2510.09187", "title": "现代深度学习方法在板球击球分类中的综合基线研究", "title_en": "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study", "authors": "Sungwoo Kang", "background": "板球击球动作的视频序列分类仍然是体育视频分析中的一大挑战，需要有效地建模空间和时间特征。本研究比较了七种不同的深度学习方法在四种不同研究范式下的板球击球分类效果，这些方法包括传统的CNN-LSTM架构、注意力模型、视觉Transformer、迁移学习方法以及现代的EfficientNet-GRU组合。通过在统一基准上实现并系统评估，发现文献中的学术性能报告与实际实现结果之间存在显著差距。在此之前，多篇论文报道的准确率分别为96%（Balaji LRCN）、99.2%（IJERCSE）和93%（Sensors），但标准化重实现后的准确率分别为46.0%、55.6%和57.7%。此外，文章还发现，结合EfficientNet-B0和基于GRU的时间模型的现代最佳方法达到了92.25%的准确率，证明了现代架构和系统优化可以带来显著改进。所有实现均遵循现代的MLOps实践，并使用PyTorch Lightning提供了一个可重复的研究平台，强调了标准化评估协议在体育视频分析研究中的重要性。", "innovation": "本研究首次全面比较了七种不同的深度学习方法在四种不同研究范式下的板球击球分类效果。通过在统一基准上实现并系统评估，发现了文献中的学术性能报告与实际实现结果之间存在显著差距。研究结合EfficientNet-B0和基于GRU的时间模型的现代最佳方法达到了92.25%的准确率，证明了现代架构和系统优化可以带来显著改进。所有实现均遵循现代的MLOps实践，并使用PyTorch Lightning提供了一个可重复的研究平台，强调了标准化评估协议在体育视频分析研究中的重要性.", "conclusion": "本研究揭示了文献中的学术性能报告与实际实现结果之间存在显著差距。研究结合EfficientNet-B0和基于GRU的时间模型的现代最佳方法达到了92.25%的准确率，证明了现代架构和系统优化可以带来显著改进。最后强调了标准化评估协议在体育视频分析研究中的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09228", "html_url": "https://arxiv.org/abs/2510.09228", "title": "清除道路，清晰视野：智能交通中的多天气恢复进展", "title_en": "Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation", "authors": "Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala", "background": "恶劣天气如雾霾、雨雪严重降低了图像和视频的质量，对依赖视觉输入的智能交通系统（ITS）构成了严重挑战。这些降级影响到包括自动驾驶、交通监控和监视在内的关键应用。本文综述了已开发的图像和视频恢复技术，旨在减轻天气引起的视觉障碍。", "innovation": "本文将现有的图像和视频恢复方法分类为传统的基于先验的方法和现代的数据驱动模型，包括CNN、变压器、扩散模型和新兴的视觉语言模型（VLM）。还进一步将恢复策略根据范围进行分类：单任务模型、多任务/多天气系统以及能够处理各种降级的全方位框架。", "conclusion": "本文总结了当前研究的限制，并展望了包括混合/复合降级恢复、实时部署和具身人工智能框架在内的未来方向。本文旨在为智能交通环境中具有天气适应性的视觉系统的发展提供有价值的参考，并将定期更新最新相关论文及开源实现。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09205", "html_url": "https://arxiv.org/abs/2510.09205", "title": "使用时序变换器进行瞬态测量的3D重建", "title_en": "3D Reconstruction from Transient Measurements with Time-Resolved Transformer", "authors": "Yue Li,Shida Sun,Yu Hong,Feihu Xu,Zhiwei Xiong", "background": "时序解析系统捕获的瞬态测量被广泛应用于光子效率高的重建任务，包括视线(OLOS)和非视线(NLOS)成像。然而，由于传感器的低量子效率和高噪声水平，尤其是针对长距离或复杂场景时，这类成像在3D重建方面仍面临挑战。", "innovation": "研究提出了一种通用的时序解析变换器(Transient Resolved Transformer, TRT) 架构，其通过分别设计空间-时间自注意力编码器和空间-时间跨注意力解码器来利用瞬态测量中的局部和全局相关性，从而提高3D重建性能。此外，基于TRT架构开发了两种特定任务的实现版本：TRT-LOS用于视线成像，TRT-NLOS用于非视线成像。实验表明，这两种实现都显著优于现有方法，适用于合成数据和来自不同成像系统的现实数据。", "conclusion": "研究通过提出TRT架构，并开发了两种特定任务的实现版本，显著提升了3D重建性能，并通过提供一个大型高分辨率合成视线数据集和一个定制的非视线测量系统，增强了数据多样性。所有代码和数据集均可通过这个https URL访问。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09203", "html_url": "https://arxiv.org/abs/2510.09203", "title": "Cattle-CLIP: 多模态牛行为识别框架", "title_en": "Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition", "authors": "Huimin Liu,Jing Gao,Daria Baran,AxelX Montout,Neill W Campbell,Andrew W Dowsey", "background": "家畜的行为是评估个体健康、生产力和整体福利的关键指标。基于视频的行为监测结合深度学习技术已经成为动物生物计量学中的主流方法，并在一些行为识别任务中提供了高精度。为了克服预先训练模型使用的网络数据与实际牛群监测视频之间的领域差异，本文提出了一种称为Cattle-CLIP的多模态深度学习框架，用于提高基于视频的视觉特征识别性能。", "innovation": "Cattle-CLIP是一种从大规模图像-语言模型CLIP演变而来的多模态深度学习框架，通过添加时间集成模块来提高牛的行为识别能力。为了应对预训练模型使用的网络数据与实际牛群监测视频之间的领域差异，提出了一系列定制化的数据增强策略和专门的文字提示。该方法在完全监督和少样本学习场景下均进行了评估，特别关注数据稀缺的行为识别问题，这是 livestock 监测领域的一个重要而未充分探索的目标。", "conclusion": "实验结果显示，Cattle-CLIP在完全监督场景下对六种行为的总体准确率达到96.1%，对于进食、饮水和站立反刍行为的召回率几乎为100%，并在少样本场景中展示了强大的泛化能力，突出了多模态学习在农业和动物行为分析中的潜力。为了验证该方法的有效性，作者还发布了CattleBehaviors6数据集，包含在约翰·奥尔德雷农舍研究平台采集的1905段视频片段，涉及六种室内行为：进食、饮水、站立自舔、站立反刍、躺下自舔和躺下反刍，涉及200头荷斯坦-弗里斯兰奶牛。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09224", "html_url": "https://arxiv.org/abs/2510.09224", "title": "Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation", "title_en": "Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation", "authors": "Wangyu Wu,Xuhang Chen,Zhenhong Chen,Jing-En Jiang,Kim-Fung Tsang,Xiaowei Huang,Fei Ma,Jimin Xiao", "background": "在现代消费电子和电子商务平台上，跨域序列推荐（CDSR）扮演着重要角色。用户会与书籍、电影和在线零售产品等多种服务互动。这些系统需要准确捕捉领域特异性和跨领域的行为模式，以提供个性化的无缝用户体验。", "innovation": "本文提出了一种名为TEMA-LLM（带有大型语言模型的标记增强多注意力）的实用且有效框架。该框架结合了大型语言模型（LLMs）进行语义标签生成和增强。具体来说，TEMA-LLM 使用LLMs分配领域感知式提示，并从项目标题和描述中生成描述性标签。生成的标签嵌入与项目标识符和文本、视觉特征一起被用于构建增强项目表示。引入了标记增强多注意力机制，以在领域内和跨领域共同建模用户偏好，从而使系统能够捕捉复杂且不断变化的消费者兴趣。", "conclusion": "在四个大规模电子商务数据集上进行的大量实验表明，TEMA-LLM 始终优于最先进的基线，突出了基于 LLMS 的语义标签和多注意力整合对面向消费者的推荐系统的好处。本文提出的方法强调了 LLMs 在推动消费电子领域智能、用户为中心的服务方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09212", "html_url": "https://arxiv.org/abs/2510.09212", "title": "稳定的视频无限：利用错误回收的无限长度视频生成", "title_en": "Stable Video Infinity: Infinite-Length Video Generation with Error Recycling", "authors": "Wuyang Li,Wentao Pan,Po-Chien Luan,Yang Gao,Alexandre Alahi", "background": "现有方法试图通过手工编排的反漂移（例如，修改的噪声调度、帧锚定）来缓解长视频中的累积错误，但仍然局限于单提示的外推，产生同质化场景和重复动作。但这些方法的核心挑战不仅在于错误积累，还在于训练假设与测试时自回归现实之间的关键差异，即训练假设可以见到干净数据，而测试时需要条件反射自生成且错误较多的输出。这种方法存在差距使得难以生成高时间一致性、合逻辑场景过渡和可控的流媒体剧情的无限长度视频。", "innovation": "SVI引入了Error-Recycling Fine-Tuning，这是一种新的高效训练方法，将Diffusion Transformer (DiT)自动生成的错误重新用于监督提示中，促使DiT主动识别和纠正自身的错误。具体来说，SVI通过循环回收和自回归学习错误注入反馈，实现了关环回收错误的介入，用一阶双向积分近似预测，用残差计算错误，动态地在离散时间步骤中将错误存款到重播内存，并在新输入时将其抽样。SVI能够在没有增加推理成本的情况下，将视频扩展到从秒到无限持续时间，同时保持对多样的条件兼容性（例如，音频、骨架和文本流）。", "conclusion": "SVI在三个基准上进行了评估，包括一致、创造性和条件性设置，验证了其多功能性和在该领域的先进地位，能够在没有额外推理成本的情况下扩展视频时间，并保持与多种条件的兼容性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09256", "html_url": "https://arxiv.org/abs/2510.09256", "title": "基于离散语义熵在放射学视觉语言模型中过滤幻觉", "title_en": "Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy", "authors": "Patrick Wienholt,Sophie Caselitz,Robert Siepmann,Philipp Bruners,Keno Bressem,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn", "background": "本研究旨在探讨使用离散语义熵（DSE）来过滤可能导致幻觉的医学影像问题，以提高黑盒视觉语言模型（VLMs）在基于放射学影像的视觉问答（VQA）中的准确性。", "innovation": "该研究提出了一种新的方法，利用离散语义熵来检测模型生成的答案中的幻觉，并通过量化语义不一致性来提高诊断准确度。研究发现，通过过滤高熵问题，模型在剩余问题上的回答准确性显著提高。", "conclusion": "离散语义熵能够可靠地检测黑盒VLMs中的幻觉，并且该方法显著提高了诊断答案的准确性，为临床VLM应用提供了一种过滤策略。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09253", "html_url": "https://arxiv.org/abs/2510.09253", "title": "使用视觉语言模型进行零样本图像隐私分类", "title_en": "Zero-shot image privacy classification with Vision-Language Models", "authors": "Alina Elena Baia,Alessio Xompero,Andrea Cavallaro", "background": "尽管专门针对图像隐私预测的基于学习的模型在过去一直占主导地位，当前的研究趋势倾向于使用大型Vision-Language模型（VLMs），这些模型设计用于通用任务。然而，这种趋势可能忽略了专门构建的模型设置的性能上限，因为缺乏系统评估。本文旨在填补这一空白，通过建立零样本基准来公平比较模型，特别是评估当前排名前三的开源VLMs在隐私分类任务上的表现。", "innovation": "本文创新性地通过提出零样本基准，对比评估了当前排名前三的开源VLMs在隐私预测任务上的任务适应性提示、性能、效率和鲁棒性。这项工作关注了VLMs在高参数数量和较慢推理速度下的资源密集型特性，以及它们在隐私预测准确率方面目前仍然逊于专门的小型模型。", "conclusion": "实验证明，尽管VLMs在隐私预测中显示出更高的鲁棒性以对抗图像扰动，但它们在隐私预测准确度上仍落后于专门设计的小型模型。因此，研究指出VLMs在图像隐私分类任务上还有改进的空间，特别是在准确性和效率方面。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09230", "html_url": "https://arxiv.org/abs/2510.09230", "title": "使用多模态大型语言模型和消费级摄像头诊断肩部病变", "title_en": "Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras", "authors": "Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun", "background": "肩部疾病，如冻结肩（粘连性肩囊炎）等，是全球范围内影响人们健康的一种常见疾病，尤其在老年人和从事重复肩部任务的工人中发病率较高。在医疗资源稀缺的地区，实现早期和准确的诊断面临巨大挑战，且急需低成本且可扩展的辅助诊断解决方案。现有研究中引入了通过消费级设备捕捉的视频作为诊断基础，以降低使用成本。本研究创新性地应用了多模态大型语言模型（MLLMs）在肩部疾病的初步诊断中，并提出了一种混合运动视频诊断框架（HMVDx）。该框架将动作理解与疾病诊断这两项任务分别由两个MLLMs完成。此外，除了传统的评价指标外，该研究还提出了一种名为利用率指数的新指标，通过医疗决策过程的逻辑推理方法综合评价了MLLMs在诊断肩部病变中的有效性，从整个医疗诊断路径的角度揭示了低成本MLLMs在医疗应用中的潜在价值。", "innovation": "研究创新地将多模态大型语言模型应用于肩部疾病的初步诊断，并提出了一种混合运动视频诊断框架（HMVDx）。该框架将动作理解与疾病诊断两项任务分别由两个MLLMs完成，并提出了一种使用逻辑过程的医疗决策（动作识别、运动诊断、最终诊断）来评价MLLMs的利用率指数，强调了低成本MLLMs在医疗应用中的潜在价值。与直接视频诊断相比，HMVDx在诊断肩关节损伤的准确性提高了79.6%，对未来视频理解在医疗领域的应用研究具有重要技术贡献。", "conclusion": "研究通过提升利用消费级摄像头捕捉视频进行肩部疾病诊断的准确性，揭示了低成本MLLMs在医疗应用中的潜在价值，为未来视频理解技术在医疗领域的应用研究奠定了重要基础。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09314", "html_url": "https://arxiv.org/abs/2510.09314", "title": "RadioFlow：使用流匹配的高效射频地图构建框架", "title_en": "RadioFlow: Efficient Radio Map Construction Framework with Flow Matching", "authors": "Haozhe Jia,Wenshuo Chen,Xiucheng Wang,Nan Cheng,Hongbo Zhang,Kuimou Yu,Songning Lai,Nanjian Jia,Bowen Tian,Hongru Xiao,Yutao Yue", "background": "下一代无线系统需要准确且实时的射频地图(RM)生成，然而基于扩散的方法常常存在模型规模大、迭代去噪慢、推理延迟高等问题，这阻碍了实用部署。", "innovation": "提出了一种新颖的基于流匹配的生成框架——RadioFlow，它通过单步高效采样实现高保真的RM生成，训练和推理速度快且保持重建准确性。相比于领先的基于扩散的baseline（RadioDiff），RadioFlow 参数少至8倍，并且推理速度快4倍以上。", "conclusion": "此进步为未来的6G网络提供了可扩展、节能且实时的电磁数字孪生的有前景路径。结果已经表明，它是当前最先进的技术。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09320", "html_url": "https://arxiv.org/abs/2510.09320", "title": "Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation", "title_en": "Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation", "authors": "Wenyao Zhang,Hongsi Liu,Bohan Li,Jiawei He,Zekun Qi,Yunnan Wang,Shengyang Zhao,Xinqiang Yu,Wenjun Zeng,Xin Jin", "background": "当前单目深度估计（MDE）方法由于提取的语义-空间知识不足而面临性能限制。", "innovation": "提出了一种名为Hybrid-depth的新框架，该框架系统地整合了基础模型（如CLIP和DINO）以提取视觉先验并获取足够的上下文信息，同时引入了一种粗到细的渐进学习框架，通过语言指引聚合多粒度特征。", "conclusion": "通过Kitti基准测试表明，该方法在所有指标上显著优于现有方法，提升了下游任务如BEV感知的效果。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09285", "html_url": "https://arxiv.org/abs/2510.09285", "title": "对多模态强化学习中的令牌感知进行突出显示", "title_en": "Spotlight on Token Perception for Multimodal Reinforcement Learning", "authors": "Siyuan Huang,Xiaoye Qu,Yafu Li,Yun Luo,Zefeng He,Daizong Liu,Yu Cheng", "background": "尽管可验证奖励的强化学习（RLVR）已经改进了大型视觉-语言模型（LVLM）的推理能力，但现有的多模态推理方法大多忽略了视觉感知在RLVR优化过程中的关键作用。本文研究了通过令牌感知的新颖视角来进行多模态RLVR的方法，旨在通过这种微粒度分析探讨链式推理（CoT）过程并发现新的见解。", "innovation": "提出了一个新颖的策略，名为视觉感知策略优化（VPPO），它利用令牌感知来精确细化学习信号。VPPO 引入了双重机制：通过整体视觉依赖性重新加权轨迹的优势，并专注于感知关键令牌的策略更新，从而显著提升了LVLM的多模态推理能力。本研究不仅引入了一种新的令牌级感知视角来分析多模态RLVR，还提供了一种新颖且有效的优化策略来增强LVLM的多模态推理能力。", "conclusion": "VPPO在八个感知和推理基准测试中表现出了显著的优越性，其效果在7B和32B模型规模上均一致受到验证。本研究不仅提供了一种新的视角来分析多模态RLVR，还为增强LVLM的多模态推理能力提供了一个有效的新颖策略。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09274", "html_url": "https://arxiv.org/abs/2510.09274", "title": "MomentSeg: 以关键帧为中心的采样方法以增强视频像素理解", "title_en": "MomentSeg: Moment-Centric Sampling for Enhanced Video Pixel Understanding", "authors": "Ming Dai,Sen Yang,Boqiang Duan,Wankou Yang,Jingdong Wang", "background": "在Referring Video Object Segmentation (RefVOS)任务中，目标是通过自然语言描述来在视频中分割目标对象，这需要时间和视觉上的精细理解。现有的基于LLM的方法采样策略通常依赖于手工编造的启发式方法或外部关键帧模型，前者可能会忽略重要的时间线索，后者则会增加系统的复杂性。", "innovation": "该论文提出了一种统一框架，联合优化Temporal Sentence Grounding (TSG)和RefVOS。在训练过程中，引入了一种新颖的TSG范式，使用特定的[FIND]标记通过时间标记相似性匹配来识别关键时刻，从而避免使用外部时间戳编码。在推理阶段，设计了一种以关键帧为中心的采样策略（MCS），密集采样有信息的关键帧，稀疏采样不重要的帧，从而保留运动细节和全局上下文。通过开发双向溯源传播（BAP）技术，使用最相关的时刻作为高质量掩码初始化的起点，并在采样点动态更新，以减轻累积误差。", "conclusion": "本文提出了一个统一的框架，通过联合优化时态句子定位（TSG）和RefVOS，自然地整合了关键时刻的定位能力。在训练过程中提出了一种新的TSG范式，并在推理过程中设计了以关键帧为中心的采样策略（MCS），并通过双向溯源传播（BAP）技术增强了跟踪稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09299", "html_url": "https://arxiv.org/abs/2510.09299", "title": "用眼睛觅食：人类视觉凝视的动力学及深度预测建模", "title_en": "Foraging with the Eyes: Dynamics in Human Visual Gaze and Deep Predictive Modeling", "authors": "Tejaswi V. Panchagnula", "background": "动物觅食时通常采取Levy walk（莱维飞行）的随机轨迹，具有重尾步长，这是适应稀疏资源环境的优化策略。而以往关于人类视觉扫描图像的研究多强调基于图像的显著性，但对于眼球运动的时空统计特性却研究不足。了解这些动态特性对注意力建模及基于视觉的接口设计有广泛的应用价值。", "innovation": "研究采用了大规模的人体实验，共40名参与者在非受控条件下观看50张不同的图像，记录了超过400万的数据点。研究发现，人类的眼球运动轨迹也类似于动物的觅食行为，遵循Levy walk模型，表明人类的眼睛在搜索视觉信息时表现出高效性。此外，研究通过训练卷积神经网络（CNN）预测基于图像的注视热点图，展示了能够从视觉结构中学习关键的眼球行为模式，这为通过生成和预测框架模拟眼球行为提供了新的证据。", "conclusion": "研究结果表明，人类的视觉探索遵循类似于自然觅食的统计法则，为眼球行为的建模打开了新的研究路径。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09343", "html_url": "https://arxiv.org/abs/2510.09343", "title": "提升红外成像效果：逐级提示融合网络与基准", "title_en": "Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark", "authors": "Jinyuan Liu,Zihang Chen,Zhu Liu,Zhiying Jiang,Long Ma,Xin Fan,Risheng Liu", "background": "当前的红外图像增强方法主要针对噪声、对比度和模糊等单一降质进行处理，对于多因素降质较为困难。此外，针对RGB传感器的一站式增强方法在应用到红外传感器时效果往往受限，这是因为成像模型之间存在显著差异。", "innovation": "本文提出了逐级提示融合网络（PPFN），通过重新审视成像机制来处理红外图像中的多种降质。PPFN 逐步构建基于成像过程的提示对，并根据不同类型的降质融合相应的提示对以引导模型特征，实现对单一或多种降质条件下的适配增强。此外，还引入了选择性逐级训练机制（SPT）来优化模型处理复合情况的能力，从而改善整体对比度并确保关键结构细节的保留。", "conclusion": "本研究通过对多种降质条件进行处理，不仅在单一降质条件下获得了令人满意的结果，还在复杂降质场景下显著提高了性能，实验表明与基线方法相比有8.76%的提升。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09302", "html_url": "https://arxiv.org/abs/2510.09302", "title": "CapGeo：一种基于标题辅助的几何推理方法", "title_en": "CapGeo: A Caption-Assisted Approach to Geometric Reasoning", "authors": "Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang", "background": "几何推理仍然是多模态大型语言模型（MLLMs）的核心挑战。即使是最先进的闭源系统，如GPT-O3和Gemini-2.5-Pro，尽管在国际数学奥林匹克（IMO）等文本推理任务上表现出色，仍然难以可靠地解决几何问题。这表明瓶颈在于理解几何图示，而非推理能力本身。由于几何图形常常可以用简洁的文本形式精确描述，将视觉内容转换为描述文本提供了一个有前景的方向。", "innovation": "提出了一种基于标题辅助的几何推理框架CapGeo，该框架用简化文本来连接视觉和文本模态。实验表明，在加载描述信息的前提下，模型在解答几何问题上得到了显著提高，例如Qwen2.5-VL-72B从仅视觉输入的8.6%提高到了59.0%，Claude-Opus-4从44.8%提高到了73.0%。进一步提出CapGeo-Bench数据集，包含4,641个精心筛选的图形-描述对，用于系统评估和识别高质量的几何描述模型。CapGeo-Bench引入的一种基于关键点的评估指标与下游CapGeo性能高度相关，能够可靠地评估几何描述能力。", "conclusion": "我们的框架和基准展示了提高MLLMs几何推理能力的新途径。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09329", "html_url": "https://arxiv.org/abs/2510.09329", "title": "基于实例感知的鲁棒一致性正则化在半监督核实例分割中的应用", "title_en": "Instance-Aware Robust Consistency Regularization for Semi-Supervised Nuclei Instance Segmentation", "authors": "Zenan Lin,Wei Li,Jintao Chen,Zihao Wu,Wenxiong Kang,Changxin Gao,Liansheng Wang,Jin-Gang Yu", "background": "病理图像中的核实例分割对于下游任务如肿瘤微环境分析至关重要。但由于标注数据成本高、稀缺，完全监督方法的应用受限。现有半监督方法在实例层面未能有效正则化一致性，缺乏对病理结构固有先验知识的利用，训练过程中容易引入噪声伪标签。因此，迫切需要一种新的方法来解决这些问题，提高半监督核实例分割性能，甚至超越完全监督方法的性能。", "innovation": "提出了一种实例感知鲁棒一致性正则化网络（IRCR-Net），通过引入匹配驱动实例感知一致性（MIAC）和先验驱动实例感知一致性（PIAC）机制，优化教师和学生子网络的核实例分割结果，尤其是在密集分布和重叠的核实例中表现更佳。融合病理图像中核的形态先验知识，用于评估未标注数据生成的伪标签质量，引入的机制能够减少伪标签噪声，促进网络的鲁棒训练，从而显著提升半监督核实例分割性能。", "conclusion": "实验结果显示，所提出的方法显著提升了半监督核实例分割在多个公开数据集上的性能，并在某些场景中甚至超过了完全监督方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09358", "html_url": "https://arxiv.org/abs/2510.09358", "title": "在视觉语言模型中使用动态推理链增强多模态关键短语预测", "title_en": "Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models", "authors": "Qihang Ma,Shengyu Li,Jie Tang,Dingkang Yang,Shaodong Chen,Yingyi Zhang,Chao Feng,Jiao Ran", "background": "多模态关键短语预测（MMKP）旨在超越仅基于文本的方法，通过整合多种输入信息来生成一组结论性的短语。传统的多模态方法在处理缺失和未知情境时存在显著局限。此外，现有的基准测试在一定程度上高估了模型能力，这是因为训练测试中的显著重叠。过往的研究表明视觉语言模型（VLMs）在处理多模态任务时具有潜力。本研究通过采用零样本和监督微调评估VLMs的基线性能，并进一步改进了复杂推理能力，通过引入Fine-tune-CoT策略。为了解决“过度思考”现象，提出了一个可动态调整的CoT策略，允许模型在推理阶段灵活利用其推理能力。", "innovation": "本文提出了一种新方法，通过利用视觉语言模型进行多模态关键短语预测。主要创新点包括：1) 使用零样本和监督微调评估VLMs的性能基线；2) 引入Fine-tune-CoT策略，利用高质量生成的CoT推理数据来微调较小的模型，以增强复杂推理能力；3) 提出了一种策略，动态注入CoT数据，使模型能够在推理阶段灵活利用其推理能力，从而解决了“过度思考”现象。", "conclusion": "通过在多个数据集上的实验评估，验证了所提出策略的有效性。结果表明，所提出的方法在多模态关键短语预测任务上具有显著优势。相关代码可在以下链接获取：这个 https URL。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09367", "html_url": "https://arxiv.org/abs/2510.09367", "title": "Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification", "title_en": "Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification", "authors": "Jinxiang Tu,Dayong Ren,Fei Shi,Zhenhong Jia,Yahong Ren,Jiwei Qin,Fang He", "background": "准确的森林生物量量化对于监测碳循环至关重要。尽管机载LiDAR在捕捉三维森林结构方面表现出色，但直接从点云估计有木质体积和地上生物量（AGB）仍然极具挑战性，这主要是因为难以建模区分长期依赖性。", "innovation": "提出了Minkowski-MambaNet，这是一种新颖的深度学习框架，可以直接从原始LiDAR中估计体积和AGB。其关键创新之处在于将Mamba模型的选择性状态空间模型（SSM）集成到Minkowski网络中，从而有效地编码全局上下文和长期依赖性，以提高树木区分类别。此外，还融入了跳跃连接来增强特征并加快进程。", "conclusion": "在丹麦国家森林库存LiDAR数据上，Minkowski-MambaNet显著优于最先进的方法，提供了更准确和稳健的估计。关键的是，该方法不需要数字地形模型（DTM），并且对边界伪影具有鲁棒性。这项工作提供了大规模森林生物量分析的强大工具，推动了基于LiDAR的森林资源清查的发展。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09361", "html_url": "https://arxiv.org/abs/2510.09361", "title": "BLINK-Twice: 你看见了吗？一个基于视觉感知的推理基准。", "title_en": "BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception", "authors": "Junyan Ye,Dongzhi Jiang,Jun He,Baichuan Zhou,Zilong Huang,Zhiyuan Yan,Hongsheng Li,Conghui He,Weijia Li", "background": "最近，多模态大型语言模型（MLLMs）在增强其推理能力方面取得了快速进展，特别是在语言推理方面。然而，现有的推理基准仍然主要评估基于语言的推理，常常将视觉输入视为可替代的背景信息。为了解决这一差距，我们引入了BLINK-Twice，这是一个以视觉为中心的推理基准，基于具有挑战性的感知任务。与之前的感知基准相比，它不仅要求模型从视觉内容中进行推理，还移动了重点，从基于语言的推理转向基于图像的推理，而不依赖外部知识。BLINK-Twice包含三个核心组件，包括用于测试视觉推理的七种视觉挑战、用于强制依赖视觉内容的自然对抗性图像对，以及用于精细评价推理过程的注释推理链，而不仅仅是最终答案。", "innovation": "BLINK-Twice重点关注基于视觉内容的精细观察和分析性推理，这与之前的浅层感知（“看见”）不同，要求模型进行细粒度的观察与分析推理（“观察”）。它分别包含七种视觉挑战、对抗性图像对的自然对照组以及标注的推理链，用于评估推理过程，而不只是最终答案。此外，BLINK-Twice提供了一个排行榜，展示了20种领先的MLLM模型的表现，并强调了重复图像观察和积极的视觉交互在提高模型性能方面的正面效果，从而促进了一个新的视觉推理范式的发展。", "conclusion": "BLINK-Twice展示了对现有模型的重大挑战，即使在语言空间中已经存在的推理策略（如“链式思考”或“自我批判”）能改善性能，但通常会导致不稳定和冗余的推理。我们观察到，重复观察图像可以跨模型改善性能，而如o3这样的模型中体现的积极视觉交互，揭示了需要一个新的视觉推理范式。数据集可以在这里公开获得：[此链接](this https URL)。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09450", "html_url": "https://arxiv.org/abs/2510.09450", "title": "基于动态权重的时域聚合在低光照视频增强中的应用", "title_en": "Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement", "authors": "Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai", "background": "低光照视频增强（LLVE）面临来自噪声、低对比度和颜色退化等挑战。基于学习的方法虽然能够快速推断，但在实际低光照场景下仍难以应对严重的噪声，主要是由于难以有效利用时域信息。", "innovation": "提出了一个名为DWTA-Net的新颖两阶段框架，该框架共同利用短时和长时的时域线索。第一阶段使用视觉状态空间块进行多帧对齐，恢复亮度、颜色和结构的同时保持局部一致性。第二阶段引入了基于动态权重的时域聚合递归细化模块，该模块由光流引导，能够依据静态和动态区域动态平衡时域聚合。此外，一种纹理自适应损失进一步保留了精细细节并促进了平滑区域的平滑。", "conclusion": "在实际低光照视频上的实验表明，DWTA-Net有效地抑制了噪声和伪像，相较于现有最先进的方法，可视化质量得到了显著提升。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09473", "html_url": "https://arxiv.org/abs/2510.09473", "title": "D-TPT：视觉语言模型测试时提示调谐的维度熵最大化校准方法", "title_en": "D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models", "authors": "Jisu Han,Wonjun Hwang", "background": "视觉语言模型（VLMs）通过其泛化能力适用于多样化的下游任务，测试时提示调谐已成为一种突出的解决方案，用于适应VLMs。然而，对比VLMs存在模态间的主导特征维度差距，导致高预测灵敏性的问题，影响其校准性能。本文旨在解决这一问题，通过维度熵最大化方法，将文本特征分布向均匀性调节，减少对主导维度的依赖，从而提升测试时提示调谐的校准性能，增强VLMs在实际应用场景中的可靠性。", "innovation": "提出了一种新的维度熵最大化方法，用于在测试时提示调谐中校准视觉语言模型（VLMs）。该方法通过将文本特征分布向均匀性调节，减少对主导特征维度的依赖，从而缓解校准性能的下降问题，提供了一种简单而有效的解决方案，以增强VLMs在实际部署中的可靠性。", "conclusion": "本文提出的方法能够缓解测试时提示调谐中由于主导特征维度引起的校准误差，通过维度熵最大化调节文本特征的分布，提高了VLMs在实际应用场景中的可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09458", "html_url": "https://arxiv.org/abs/2510.09458", "title": "SilvaScenes: 树冠下自然森林中树木分割和物种分类的数据集", "title_en": "SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests", "authors": "David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère", "background": "对于森林管理中的机器人技术兴趣增加，但在复杂自然环境中仍存在感知障碍。恶劣环境条件如重遮蔽、光照变化和茂密植被，对自动化系统的性能构成了挑战，这些系统对于精确林业、生物多样性监测和林业设备自动化至关重要。当前数据集中树木实例分割和物种分类能力不足，特别是在城市环境或少数几种树木物种方面的局限性。为了应对这种情况，我们提出了SilvaScenes数据集，用于树冠下森林中树木实例分割和物种分类的标注。该数据集覆盖加拿大魁北克省五个生物气候区，包含24种树种共1476棵树的标注信息，由林业专家提供。", "innovation": "SilvaScenes数据集填补了现有数据集的空白，专注于树冠下的自然森林环境。它提供了广泛的树种多样性（24种）以及专业标注，这为开发高性能的感知系统提供了新平台。通过比较先进的深度学习方法，研究结果显示树木分割相对容易，但物种分类难度显著较大。这种方法是对当前技术一大进展。", "conclusion": "SilvaScenes数据集为研究提供了新的材料，强调了自然森林环境下树木物种分类的复杂性，未来的研究可在该数据集的基础上进一步探索以提高自动化系统的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09475", "html_url": "https://arxiv.org/abs/2510.09475", "title": "基于LoRA的少量样本多令牌DreamBooth风格一致人物生成", "title_en": "Few-shot multi-token DreamBooth with LoRa for style-consistent character generation", "authors": "Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar", "background": "随着音频视觉行业的深刻变革，AI的发展不仅用于自动化常规任务，还为艺术形式带来了新的灵感。本文探讨了如何使用少量的人工设计参考角色生成大量具有相似艺术风格和视觉特征的新角色，以拓展动画、游戏和其他相关领域的创作可能性。", "innovation": "本文提出了一种基于DreamBooth的多令牌策略，结合LoRA进行参数高效微调，解决了捕捉复杂角色细节和少量训练数据的挑战。具体来说，通过使用聚类为每个角色和其集体风格分配单独的令牌，并引入随机令牌和嵌入，在生成过程中去除特定类别的正则化项，允许无限数量的角色生成，同时保持学习到的风格。", "conclusion": "通过对五个小型专业数据集进行评估，本文的方法不仅生成了高质量、多样化的角色，还保留了参考角色的独特美学特征。人类评估进一步证明了这种方法的有效性，揭示了其潜在的应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09380", "html_url": "https://arxiv.org/abs/2510.09380", "title": "在预训练DETR上利用动态稀疏性", "title_en": "Utilizing dynamic sparsity on pretrained DETR", "authors": "Reza Sedghi,Anand Subramoney,David Kappel", "background": "在基于Transformer的模型中高效推理仍然是一个挑战，尤其是在像目标检测这样的视觉任务中。我们分析了DETR中MLP层的固有稀疏性，并提出了两种无需重新训练即可利用这种稀疏性的方法。虽然静态指示基稀疏化(SIBS)方法基于固定的激活模式预测神经元的非活跃状态，但在输入依赖性状态下仅提供有限的增益。我们引入了Micro-Gated Sparsification (MGS)机制，这是一种轻量级的门控机制，在预训练的DETR顶部进行训练，通过一个小的线性层预测动态稀疏性，实现了高达85%到95%的激活稀疏度。", "innovation": "我们提出了一种名为Micro-Gated Sparsification (MGS)的轻量级门控机制，在预训练的DETR上进行了训练，能够预测动态稀疏性，并通过一个小的线性层实现了高稀疏度，同时保持或提升了性能，显著减少了计算量。这种方法提供了一种输入适应性的稀疏化策略，使得预训练的视觉Transformer模型可以高效部署而不需要重新训练整个模型。", "conclusion": "我们的方法为稀疏化提供了一种实用且输入自适应的方法，能够在不进行全模型重新训练的情况下，有效地部署预训练的视觉Transformer模型。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09438", "html_url": "https://arxiv.org/abs/2510.09438", "title": "Mono4DEditor：基于点级语言嵌入高斯的单目视频驱动4D场景编辑", "title_en": "Mono4DEditor: Text-Driven 4D Scene Editing from Monocular Video via Point-Level Localization of Language-Embedded Gaussians", "authors": "Jin-Chuan Shi,Chengye Su,Jiajun Wang,Ariel Shamir,Miao Wang", "background": "单目视频中重建的4D场景的文本提示驱动编辑是一个有价值的但具有挑战性的任务，广泛应用于内容创作和虚拟环境中。主要挑战在于在复杂动态场景的局部区域实现语义精确的编辑，同时保持未编辑内容的完整性。这项工作旨在解决上述问题，并提出了Mono4DEditor，一种灵活且准确的文本驱动4D场景编辑框架，通过两种阶段的点级定位策略来选取候选高斯点，并通过基于扩散的视频编辑模型对局部区域进行针对性编辑，从而确保空时一致性，同时保持未编辑区域的外观和几何形状的完整性，并在灵活性和视觉保真度方面超越先前的方法。", "innovation": "Mono4DEditor引入了一种新的框架，通过增强3D高斯点和量化CLIP特征形成语言嵌入的动态表示，实现高效的任意空间区域的语义查询。该方法进一步提出了两种阶段的点级定位策略，首先通过CLIP相似性选择候选高斯点，然后细化其空间范围以提高准确性。最后使用基于扩散的视频编辑模型对局部区域进行针对性编辑，并通过流和勾画指导来确保空间的一致性和时间的连贯性。这种方法在多样场景和对象类型下实现了高质量的文本驱动编辑，同时保持了未编辑区域的外观和几何形状的完整性，并在灵活性和视觉保真度上超越了先前的方法。", "conclusion": "通过广泛的实验，证明Mono4DEditor在多种场景和对象类型下实现了高质量的文本驱动编辑，同时保持未编辑区域的外观和几何形状完整，并在灵活性和视觉保真度上超越了先前的方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09364", "html_url": "https://arxiv.org/abs/2510.09364", "title": "在动态城市场景中基于视见感知细化的3D高斯点云插值", "title_en": "Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes", "authors": "Yikang Zhang,Rui Fan", "background": "3D高斯点云插值（3DGS）在合成高保真新型视图方面表现出色，但其效果高度依赖初始化点云的质量。在不被限制、动态的城市环境中，均匀且完整的点覆盖需要重叠的观测锥体，这一假设在实际应用中常被违反。使用部分初始化的点云训练高斯模型会导致扭曲和伪影，原因是相机射线可能无法与有效的表面相交，从而导致与被遮挡或不可见几何相关的高斯原语梯度传播错误。此外，现有的精细结构策略简单地克隆和分割现有的高斯原语，无法重建丢失的结构。", "innovation": "本文提出了一种名为VAD-GS的3DGS框架，专门用于处理具有挑战性的城市结构恢复问题。VAD-GS框架通过体素化可见性推理识别不可靠的几何结构，通过多样性的视点选择确定有信息支持的视图，通过基于配准的多视图立体重建恢复缺失的结构。这种设计可以生成新的高斯原语，即使是在缺少初始点的区域也能受到可靠几何先验的指导。大量实验表明，VAD-GS在Waymo和nuScenes数据集上优于最先进的3DGS方法，并大幅提高了重建几何的质量，无论是静态还是动态物体都适用。", "conclusion": "通过广泛实验验证，VAD-GS方法显著提高了3DGS在动态城市场景中几何结构恢复的质量，尤其是在重建缺失结构和改善初始点不充足区域的效果上表现出色，为动态城市环境下的三维重建提供了一种有效的新方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09499", "html_url": "https://arxiv.org/abs/2510.09499", "title": "临床驱动的交互分割评估方法", "title_en": "A methodology for clinically driven interactive segmentation evaluation", "authors": "Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso", "background": "交互分割是构建稳健和通用的用于体数据医学图像分割算法的有前景策略。然而，评估过程中不一致且临床不现实的结果阻碍了公平比较，并可能夸大了在现实世界中的性能。", "innovation": "本文提出了一个基于临床实践的评估任务和指标定义方法，构建了标准化评估管道的软件框架。 evaluate 状态下的最新算法在异构和复杂的任务中，观察到以下关键点：(i) 处理用户交互时信息损失最小化对模型稳健性至关重要；(ii) 自适应缩放机制增强了鲁棒性并加速了收敛；(iii) 如果验证提示行为/预算与训练不同，则性能会下降；(iv) 2D方法在类似切片图像和粗目标上表现良好，但3D上下文在处理大或形状不规则的目标时提供帮助；(v) 非医学领域模型（例如SAM2）在对比度差和复杂形状下性能会下降。", "conclusion": "该研究通过标准化评估管道和基于临床实践的方法，评估了不同模型在交互分割中的表现，指出了一系列影响模型性能的关键因素，并为进一步研究奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09531", "html_url": "https://arxiv.org/abs/2510.09531", "title": "PRNet: 原始信息即所有你需要的", "title_en": "PRNet: Original Information Is All You Have", "authors": "PeiHuang Zheng,Yunlong Zhao,Zheng Cui,Yang Li", "background": "在航拍图像中小物体检测由于有限的像素表示，在特征提取过程中遭受严重的信息降解，浅层空间细节难以与语义信息有效对齐，导致频繁的漏检和误检。现有的基于FPN的方法通过后处理增强来减轻这些损失，但重建的细节常常偏离原始图像信息，阻碍了其与语义内容的融合。", "innovation": "我们提出了一种名为PRNet的实时检测框架，它优先考虑保留和高效利用浅层原始空间特征以增强小物体表示。PRNet通过两个模块实现这一目标：渐进式细化颈（PRN）和增强的切片采样（ESSamp）。PRN通过主干网络的重用和迭代细化实现空间-语义对齐，而ESSamp通过优化重排和卷积在下采样过程中保留浅层信息。", "conclusion": "在VisDrone、AI-TOD和UAVDT数据集上的大量实验表明，在与现有方法相当的计算约束条件下，PRNet在准确性和效率的权衡方面表现更优。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09509", "html_url": "https://arxiv.org/abs/2510.09509", "title": "三星图像中的对角线伪影：PRNU挑战与解决方案", "title_en": "Diagonal Artifacts in Samsung Images: PRNU Challenges and Solutions", "authors": "David Vázquez-Padín,Fernando Pérez-González,Alejandro Martín-Del-Río", "background": "我们研究了多种三星智能手机拍摄图像中存在的对角线伪影及其对基于PRNU的相机来源验证的影响。研究发现某些Galaxy S系列型号及部分Galaxy A型号存在模式相似的指纹碰撞问题。同时，研究指出对于支持PRO模式和原始捕捉的设备，可靠地进行PRNU验证仍然可行，因为原始图像可以绕过引入伪影的处理管道。然而，这种选项对中端A系列型号设备无效，在没有访问原始图像的法医案件中亦无效。", "innovation": "研究展示了对角线伪影的问题及其对PRNU验证的潜在影响，并表明PRO模式和原始捕捉提供了一种规避伪影的方法，而此方法不适用于低端型号或没有原始图像的法医案件。此外，研究还探讨了这些对角线伪影在法医应用中的潜在作用，包括减少HDR图像中的误检测和定位肖像模式图像中受到合成景深影响的区域。", "conclusion": "虽然中端A系列型号设备和没有原始图像的法医案件无法规避对角线伪影的影响，但研究提供了基于PRO模式和原始捕捉来减少PRNU验证错误的可能性。对角线伪影在特定法医应用中有潜在用途，有助于提高图像分析的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09583", "html_url": "https://arxiv.org/abs/2510.09583", "title": "FSP-DETR：少量样本原生 QModelIndex 产卵检测", "title_en": "FSP-DETR: Few-Shot Prototypical Parasitic Ova Detection", "authors": "Shubham Trehan,Udhav Ramachandran,Akash Rao,Ruth Scimeca,Sathyanarayanan N. Aakur", "background": "生物医学领域中的对象检测受到标记数据稀缺及新型或稀有类别的频繁出现的限制。传统的检测方法很难在这种情况下保持精确度。", "innovation": "提出了一种统一体少样本检测、开放集识别和对未见生物医学任务的一般化的方法——FSP-DETR。它基于类无关的DETR骨干网络，通过支持图像构造类原型，使用增强观点和轻量级transformer解码器学习嵌入空间，并且在训练过程中同时优化原型匹配损失、基于对齐的分离损失和KL散度正则化以增强特征学习和在稀缺监督下的校准。", "conclusion": "在广泛的任务（如产卵、血液细胞和疟疾检测）上的实验表明，FSP-DETR在少量样本和开放集场景中的表现优于先前的少样本和原型基检测器。此外，还引入了一个包含20种寄生虫类别的新型生物医学物种检测基准，并建立了标准化评估协议。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09537", "html_url": "https://arxiv.org/abs/2510.09537", "title": "FLOWNING: 显式神经流形保持变形", "title_en": "FLOWING: Implicit Neural Flows for Structure-Preserving Morphing", "authors": "Arthur Bizzi,Matias Grynberg,Vitor Matias,Daniel Perazzo,João Paulo Lima,Luiz Velho,Nuno Gonçalves,João Pereira,Guilherme Schardong,Tiago Novello", "background": "变形问题一直是图像识别和计算机图形学研究中的一个重要课题，涉及到时间依赖的形变映射和平滑插值。近期，多层感知机（MLPs）被探索作为隐式神经表示（INRs）模型的一种方式，用于建模这种形变，由于其无网格特性和可微性。然而，从标准MLP提取连贯且准确的变形通常需要复杂和昂贵的正则化，这可能导致训练不稳定并妨碍有效的特征对齐。", "innovation": "我们提出了FLOWNING（变形FLOW），一种将形变重新定义为微分向量流构建的框架。这种方法通过直接将结构流特性编码到网络架构中，自然确保了连续性、可逆性和时间连贯性，从而实现了原理上和稳定的转换，能够准确且保持结构地对2D图像和3D形状进行变形。", "conclusion": "在包括面部和图像变形、以及高斯斑点变形等多种应用中的广泛实验表明，FLOWNING能够以更快的收敛速度实现最先进的变形质量。此代码和预训练模型可在何处访问: this http URL."}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09507", "html_url": "https://arxiv.org/abs/2510.09507", "title": "PhysToolBench：MLLMs掌握物理工具理解能力的基准测试", "title_en": "PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs", "authors": "Zixin Zhang,Kanghao Chen,Xingwang Lin,Lutao Jiang,Xu Zheng,Yuanhuiyi Lyu,Litao Guo,Yinchuan Li,Ying-Cong Chen", "background": "人类智能的一个标志是能够使用、理解和创造工具，这使得与物理世界进行复杂的互动成为可能。为了使通用智能代理能够真正多面地处理问题，它们必须掌握这些基本技能。尽管现代的多模态大型语言模型（MLLMs）利用其广泛的知识应对有身体表现的AI任务和下游的视觉-语言-动作模型中的高层次规划，但对于这些模型真正理解物理工具的程度仍然没有定量衡量。为了弥合这一差距，我们提出了PhysToolBench，这是第一个专门评估MLLMs对物理工具理解能力的基准测试。基准测试是一个视觉问答（VQA）数据集，包含了超过1000个图像-文本对，评估了三种不同的难度水平的能力。这些能力包括工具识别、工具理解以及工具创造。评估结果显示，MLLMs在工具理解方面存在显著缺陷，此外，我们还提供了深入分析并对初步解决方案提出了建议。代码和数据集在公开平台上可获取。", "innovation": "提出了PhysToolBench，这是第一个专门评估MLLMs对物理工具理解能力的基准测试。它评估模型在工具识别、工具理解以及工具创造三个不同难度等级上的能力，并揭示了MLLMs在工具理解方面存在的显著缺陷。此外，它还提供了深入分析并提出初步解决方案。", "conclusion": "我们的全面评估表明，MLLMs在工具理解方面存在显著缺陷。我们还提供了对这种缺陷的深入分析，并提议了一些初步解决方案。代码和数据集在公开平台上公开可获取。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09561", "html_url": "https://arxiv.org/abs/2510.09561", "title": "TC-LoRA：一种基于时间调制的有条件LoRA以实现适应性扩散控制", "title_en": "TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control", "authors": "Minkyoung Cho,Ruben Ohana,Christian Jacobsen,Adityan Jothi,Min-Hung Chen,Z. Morley Mao,Ethem Can", "background": "当前可控制的扩散模型通常依赖于固定架构，通过修改中间激活来注入基于新模态的指导。这种方法采用静态的条件策略来应对动态的多阶段去噪过程，限制了模型根据生成过程从粗结构到细细节的发展调整其响应的能力。", "innovation": "作者提出了TC-LoRA（时间调制条件LoRA），这是一种新的范式，能够通过直接对模型权重进行条件化来实现动态、上下文感知的控制。框架采用超网络在一个生成步骤中自动生成LoRA适配器，根据不同时间点和用户条件为冻结的主干进行权重修改。这种机制使模型能够在整个生成过程中学习并执行一个明确的、适应性的策略，以应用条件指导。实验表明，这种动态、参数化的控制相较于基于静态激活的方法显著提高了生成保真度和空间条件的遵循程度。", "conclusion": "TC-LoRA提供了一种替代方法，在此方法中，模型的条件化策略通过更深的功能调整其权重来改变，使控制能够与任务和生成阶段的动态需求相匹配。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09607", "html_url": "https://arxiv.org/abs/2510.09607", "title": "VITA-VLA：通过动作专家蒸馏高效教会视觉语言模型执行动作", "title_en": "VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation", "authors": "Shaoqi Dong,Chaoyou Fu,Haihan Gao,Yi-Fan Zhang,Chi Yan,Chu Wu,Xiaoyu Liu,Yunhang Shen,Jing Huo,Deqiang Jiang,Haoyu Cao,Yang Gao,Xing Sun,Ran He,Caifeng Shan", "background": "视觉-语言-动作（VLA）模型通过利用预训练的视觉-语言模型（VLMs）的强大感知能力显著提升了机器人的操作能力。通过将动作模块整合进这些预训练模型，VLA方法展示了增强的泛化性能。然而，从头开始训练它们是昂贵的。本文的背景是解决这个成本问题，提出了一种简单有效的蒸馏方法，将预训练的小动作模型的知识转移到VLM上，赋予它们执行动作的能力。这种方法保持了原始VLM的结构，仅添加了一个动作标记和一个状态编码器以整合物理输入，并通过两阶段训练策略实现动作知识的转移，从而提高系统的多模态输入整合能力。", "innovation": "本文创新性地提出了一种通过动作专家蒸馏（Action Expert Distillation）来高效教会视觉语言模型执行动作的框架。该框架通过将预训练的小动作模型的知识转移到VLM上，使用两阶段训练策略来保留原始VLM结构并提高性能，具体包括轻量级对齐和选择性微调，显著降低了训练成本。实验结果表明，与之前的方法相比，该方法在LIBERO上的成功率提高了11.8%，在LIBERO-LONG上的成功率提高了24.5%，在五个实际操作任务中也表现出色，成功率达到82.0%，超越了老师模型指示器，表明了蒸馏方法的有效性。", "conclusion": "本文提出的方法实现了使用预训练模型进行动作训练的高效路径，虽然只添加了简单的结构，但却显著提高了任务完成的准确性和效率，展示出在不牺牲性能的情况下大幅降低训练成本的可能性。这种方法为未来使用预训练模型提高机器人操作能力的研究开辟了新的道路。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08618", "html_url": "https://arxiv.org/abs/2510.08618", "title": "Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization", "title_en": "Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization", "authors": "Rui Hu,Delai Qiu,Yining Wang,Shengping Liu,Jitao Sang", "background": "ASR系统在处理领域特定术语时常常遇到困难，尤其是在学术演讲等专业环境中。现有方法往往过于复杂且效果不佳。尽管全模态大型语言模型（OLLMs）提供了端到端框架的可能性，但在实践中经常退化为简单的光学字符识别系统。", "innovation": "提出了一种新的后训练方法——视觉锚定策略优化（VAPO），该方法通过关联思维与回答的流程，使模型在生成转录之前先进行OCR处理，从而优化详细推理过程。引入了强化学习，并设置了四种不同的奖励机制来优化OCR准确性、ASR质量、视觉锚定一致性以及格式合规性。还构建了SlideASR-Bench，一个包含合成数据集和真实数据集的新实体丰富的基准。", "conclusion": "实验表明，VAPO方法显著提高了领域特定术语的识别率，建立了一种有效的端到端框架来应对SlideASR任务。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09608", "html_url": "https://arxiv.org/abs/2510.09608", "title": "StreamingVLM：无限视频流的实时理解", "title_en": "StreamingVLM: Real-Time Understanding for Infinite Video Streams", "authors": "Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han", "background": "视觉-语言模型（VLMs）能够为实时助手和自主代理提供动力，但它们面临一个关键挑战：在不增加延迟和内存使用的情况下，理解无限数量的视频流。处理整个视频时采用全面注意将导致计算成本呈平方级增长，并且在长视频上表现不佳。与此同时，简单的滑动窗口方法也存在缺陷，要么破坏连贯性，要么由于冗余重计算而导致高延迟。", "innovation": "本文介绍了一种名为StreamingVLM的模型，该模型旨在实现无限视觉输入的实时和稳定理解。我们的方法是一种统一框架，将训练与流式推理对齐。推理时，通过重新利用注意力汇的态、近期视觉令牌的小窗口和近期文本令牌的长窗口来保持紧凑的KV缓存。这种流式能力通过简单的监督微调（SFT）策略植入，该策略在短重叠视频片段上应用全面注意，从而有效地模仿推理时的注意模式，而无需训练过于长的上下文。我们还构建了Inf-Streams-Eval基准，其中包含平均超过两小时的视频，并且需要按秒级精确对帧和文本进行对齐。此外，我们的SFT策略还增强了通用的VQA能力，而无需任何特定于VQA的微调，在LongVideoBench和OVOBench Realtime上分别提高了4.30%和5.96%的表现。", "conclusion": "在Inf-Streams-Eval上，StreamingVLM实现了66.18%的胜率，并在单个NVIDIA H100上实现了高达8 FPS的稳定实时性能。我们的SFT策略还增强了VQA的一般能力，没有进行任何特定于VQA的微调。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09586", "html_url": "https://arxiv.org/abs/2510.09586", "title": "视觉语言模型：26K篇论文综述", "title_en": "Vision Language Models: A Survey of 26K Papers", "authors": "Fengming Lin", "background": "本文研究了CVPR、ICLR和NeurIPS在2023-2025年间接受的26,104篇论文，对适用于视觉语言模型的研究趋势进行了客观、可再现的测量。研究对论文标题和摘要进行了归一化、短语保护和匹配，利用人工制作的词典为每篇论文分配多达35个主题标签，并挖掘有关任务、架构、训练范式、目标、数据集和共现模态的细微线索。研究量化了三项主要的宏观转变：1) 多模态视觉-语言-大语言模型工作的急剧增加，重新定义了经典的感知任务为指令跟随和多步推理；2) 生成方法的持续扩展，扩散研究集中于可控性、蒸馏和速度；3) 3D和视频活动的稳健性，构图从NeRF迁移到高斯散列，并且越来越强调人类和代理中心的理解。对跨领域的比较显示，CVPR具有更强的3D足迹，ICLR的视觉语言模型份额最高，而可靠性主题如效率或鲁棒性则弥散于各个领域。", "innovation": "本文通过规范化标题和摘要、使用手工制作的词典分配主题标签，并挖掘细微线索，提供了一种透明和可再现的研究趋势测量方法，能够在宏观层面上量化研究趋势的变化，并展示了多模态视觉-语言-大语言模型、生成方法和3D/视频活动的变化。此外，还提供了词汇表和方法论以供审计和扩展，虽然存在词汇召回率和摘要范围的限制，但纵向信号在各个场所以及年份之间是一致的。", "conclusion": "本文通过分析2023-2025年间3大会计算机视觉会议接受的26,104篇论文，揭示了视觉语言模型领域发生了三项主要的转变。具体表现为多模态视觉-语言-大语言模型工作的急剧增加，生成方法的持续扩展和3D/视频活动的稳健性。研究还指出，CVPR具有更强的3D足迹，ICLR的视觉语言模型份额最高，而可靠性主题如效率或鲁棒性则弥散于各个领域。研究结果通过发布词汇表和方法论来鼓励其他人进行审计和扩展，尽管存在一些局限性，但纵向信号的一致性使得研究方法具有价值。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09606", "html_url": "https://arxiv.org/abs/2510.09606", "title": "SpaceVista：从毫米到千米的全尺度视觉空间推理", "title_en": "SpaceVista: All-Scale Visual Spatial Reasoning from mm to km", "authors": "Peiwen Sun,Shiqiang Lang,Dongming Wu,Yi Ding,Kaituo Feng,Huadai Liu,Zhen Ye,Rui Liu,Yun-Hui Liu,Jianan Wang,Xiangyu Yue", "background": "当前空间推理研究的激增使得室内场景的理解取得了显著进展，但仍然难以应对机器人和自动驾驶等多样化应用。研究人员需处理大规模空间推理的问题，同时面对室内3D扫描和劳动密集型的手动注释的数据集构建难题，以及缺乏有效的全尺度场景建模，导致过度拟合个体场景。作者通过创建一个专用于特定任务的自动化流水线，构建了一个跨越五种空间尺度的逾38,000个视频场景的大规模数据集SpaceVista-1M，并通过手动记录、检索和组装视频数据进行精确标注，构建了全尺度基准，并以规模意识专家和递进奖励机制来优化模型效果，促使模型在多种基准上表现出色，展现了良好的跨尺度和跨场景泛化能力。", "innovation": "该论文提出了一个综合性的全尺度空间推理解决方案，包括结构化的空间推理知识系统、规模意识建模和循序渐进的训练范式，这是已知的首次尝试将MLLMs的全尺度空间智能扩展至所有尺度。通过专用于特定任务的自动化自动化流水线创建了跨越五种空间尺度的约38,000个视频场景的数据集SpaceVista-1M，并结合精确的手动标注构建了全尺度基准。同时提出引入SpaceVista-7B模型，接受密集输入并使用规模作为锚点来促进规模意识专家和递进奖励机制的应用，从而显著改进了模型效果。该模型在多个基准上取得有竞争力的性能，证明了其良好的跨尺度和跨场景泛化能力，并计划公开发布相关数据集、模型和基准。", "conclusion": "本研究通过创建涵盖5个空间尺度的逾38,000个视频场景的数据集SpaceVista-1M和一个专为特定任务的自动化流水线，结合精确的手动标注，并建立全尺度基准，提出了一种综合性全尺度空间推理解决方案。同时还构造了一个致力于接受规模作为锚点的SpaceVista-7B模型，确保模型性能和全尺度上的泛化能力。相关数据集、模型和基准将在https://...上公开发布，以供进一步研究使用。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08645", "html_url": "https://arxiv.org/abs/2510.08645", "title": "利用基于GCN的自适应背景网格简化生成来生成网格生成的大小场", "title_en": "Generating Sizing Fields for Mesh Generation via GCN-based Simplification of Adaptive Background Grids", "authors": "Xunyang Zhu,Hongfei Ye,Yifei Wang,Taoran Liu,Jianjun Chen", "background": "在进行非结构化网格生成时，定义在三角背景网格上的大小字段对于控制网格的质量和生成效率至关重要。然而，创建一个既几何上一致、计算上轻量级且免于出现条纹等伪影的最佳背景网格是一个重大挑战。", "innovation": "该论文提出了一种新颖的自适应背景网格简化（ABGS）框架，该框架基于图卷积网络（GCN）。该框架将网格简化任务重新表述为边得分回归问题，并使用GCN模型高效预测最优边塌缩候选者。模型由一个自定义损失函数引导，该函数综合考虑了几何保真度和大小字段准确性。这种数据驱动的方法替代了昂贵的程序性评价，加速了简化过程。", "conclusion": "实验结果表明，该框架在多种复杂工程模型中具有有效性。与初始密集网格相比，简化后的背景网格元素数量减少了74%-94%，并且网格生成时间缩短了35%-88%。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08641", "html_url": "https://arxiv.org/abs/2510.08641", "title": "基于时空隐式神经表示的交错动态XCT重建", "title_en": "Interlaced dynamic XCT reconstruction with spatio-temporal implicit neural representations", "authors": "Mathias Boulanger,Ericmoore Jossou", "background": "本文研究了在交错获取方案下使用时空隐式神经表示（INRs）进行动态X射线计算机断层扫描（XCT）重建的方法。研究在不同获取场景下评估了所提出的方法，包括全局欠采样程度、空间复杂性以及噪声水平的变化。研究结果表明，该方法在各种设置下表现强劲，并优于现有的基于模型的迭代方法TIMBIR。研究还探讨了该方法的扩展方向，通过直接在重建过程中引入环状伪影校正，并展示了批量轴向切片联合优化的方法，为大规模数据集处理提供了可能性。", "innovation": "1. 提出了结合ADMM优化和包含先验知识的INCODE框架的时空隐式神经表示方法，以实现高效收敛。\n2. 通过引入权重最小二乘数据保真项进行显式的噪声建模，显著提高了在更具挑战性环境下的性能。\n3. 探索和展示了直接在重建过程中建模探测器非理想特性的方法，并通过批量轴向切片的联合优化实现了4D体积重建的初步概念验证。", "conclusion": "综合所有设置，所提出的方法在所有场景下均表现出强大的性能，显著优于现有技术。此外，引入了针对噪声和非理想探测器特性的显式建模，提高了方法的适应性和准确性。最后，通过大规模并行处理，为未来的实际重建框架开发铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08713", "html_url": "https://arxiv.org/abs/2510.08713", "title": "统一的世界模型：增强规划与前瞻性视觉导航", "title_en": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation", "authors": "Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann", "background": "当前最先进的视觉导航方法采用模块化架构，将导航规划与视觉世界建模分离，导致状态-动作不对齐和在新型或动态环境中适应性有限。这一分离方法是实现稳健和泛化视觉导航的关键障碍。", "innovation": "提出统一代理（UniWM），这是一种统一的记忆增强世界模型，将第一人称视觉前瞻性思维与规划融入单一的多模态自回归骨干网络。通过分层记忆机制，这种模型能够结合详细的短期知觉线索与长期轨迹背景，实现稳定而连贯的长时间推理。UniWM 避免了模块化框架的缺陷，通过直接将决策与视觉想象结果联系起来，确保预测和控制之间的紧密对齐。", "conclusion": "大量的实验结果表明，UniWM 在四个具有挑战性的基准测试（斯坦福室内外、ReCon、SCAND 和 HuRoN）中显著提高了导航成功率，最高可达 30%，与强大的基线相比显著减少了轨迹误差，并在未见过的 TartanDrive 数据集上表现出色的零样本泛化能力。这些结果突显了 UniWM 在统一、想象驱动的感知导航中的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08669", "html_url": "https://arxiv.org/abs/2510.08669", "title": "FreqCa: 通过频率感知缓存加速扩散模型", "title_en": "FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching", "authors": "Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang", "background": "扩散变换器在推理过程中因显著的成本问题而受到限制。最近，特征缓存被提出通过重复使用之前时间步长的特征来解决这一问题，从而在未来的步骤中跳过计算。然而，以前的特征缓存假设相邻时间步长中的特征相似或连续，这并不总是成立。", "innovation": "本文从频域开始分析，揭示了特征在扩散模型中的不同频率带表现出不同的动态。具体来说，决定图像结构的低频成分具有较高的相似性但较差的连续性，而解码图像细节的高频部分表现出显著的连续性但较差的相似性。基于这些有趣的观察，提出了频率感知缓存（FreqCa），该方法直接根据相似性重复使用低频成分的特征，并使用二阶赫mite插值器根据连续性预测易变的高频部分。此外，还提出缓存累积残差特征（CRF）以替代所有层的特征，这将特征缓存的内存占用减少了99%。", "conclusion": "广泛的实验证明，FreqCa 在生成和编辑方面都表现出有效性。代码已在补充材料中提供，并将于 GitHub 上发布。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08656", "html_url": "https://arxiv.org/abs/2510.08656", "title": "从跨模态到参数化基础元素的3D生成框架", "title_en": "A 3D Generation Framework from Cross Modality to Parameterized Primitive", "authors": "Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan", "background": "近年来，基于AI的3D模型生成技术在跨模态应用方面取得了进展，但生成具有光滑表面的模型并最小化存储开销仍然是挑战。为此，本文提出了一种新的多阶段框架，该框架通过文本和图像输入生成由参数化基础元素组成的3D模型。该框架提出了一种基于参数化基础元素的模型生成算法，可识别模型构成元素的形状特征，并用高质量表面的参数化基础元素替换这些元素。此外，还提出了一种相应的模型存储方法，可以在保持原模型表面质量的同时，仅保留参数化基础元素的参数。实验结果显示，该方法在虚拟场景数据集和真实场景数据集上的有效性，实现了0.003092的Chamfer Distance，0.545的VIoU，0.9139的F1-Score和0.8369的NC，其中参数化基础元素的参数文件大小约为6KB。本文的方法特别适用于简单模型的快速原型制作。", "innovation": "提出了一种基于参数化基础元素的多阶段框架，用于根据文本和图像输入生成3D模型。包括一个基于参数化基础元素的模型生成算法，可以识别模型构成元素的形状特征并替换为高质量表面的参数化基础元素。同时提出了相应的模型存储方法，保证了模型的原表面质量，并仅保留了参数化基础元素的参数。实验表明，该方法具有较高的准确性和效率，适用于快速生成简单3D模型。", "conclusion": "通过提出的多阶段框架和相应的模型生成及存储方法，实现了高质量和低存储开销的3D模型生成，特别是在简单模型的快速原型制作中表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08839", "html_url": "https://arxiv.org/abs/2510.08839", "title": "基于强化学习的边缘管理以实现可靠的多视点3D重建", "title_en": "Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction", "authors": "Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy", "background": "实时多视点3D重建对于关键的边缘本地应用场景至关重要，如火灾救援，它能提供及时准确的3D场景建模，增强态势感知和决策制定。然而，边缘资源的动态和不可预测性导致了诸如图像质量下降、网络连接不稳定、服务器负载波动等问题，这些都对重建过程的可靠性构成挑战。", "innovation": "本文提出了一种基于强化学习的边缘资源管理框架，旨在在资源受限且易受干扰的环境中确保多视点3D重建的可靠性，在合理的时间内实现高质量的重建。该框架采用了两个合作的Q学习代理，一个负责相机选择，另一个负责服务器选择，都在线运行并通过与边缘环境的交互学习策略。", "conclusion": "实验结果表明，提出的方法通过有效平衡端到端延迟和重建质量，在动态环境中提高了应用的可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08938", "html_url": "https://arxiv.org/abs/2510.08938", "title": "Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning", "title_en": "Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning", "authors": "Zhen Yang,Yansong Ma,Lei Chen", "background": "传统的证据深度学习（EDL）方法依赖于静态超参数进行不确定性校准，这限制了它们在动态数据分布中的适应性，导致在高风险决策任务中的校准和泛化较差。", "innovation": "提出了一种名为Meta-Policy Controller（MPC）的动态元学习框架，通过动态调整KL散度系数和Dirichlet先验强度以优化不确定性建模。MPC采用多目标优化方法：内层通过自适应损失函数更新模型参数；外层优化KL散度系数和类别特定的Dirichlet先验强度，以平衡预测准确性和不确定性质量。MPC的可学习狄利克雷先验使模型能够灵活适应类别分布和训练动态。", "conclusion": "实验结果表明，MPC显著增强了各类任务中模型预测的可靠性和校准，提高了不确定性校准、预测准确性和基于置信度的样本拒绝后的性能保留。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08949", "html_url": "https://arxiv.org/abs/2510.08949", "title": "渐进不确定性引导证据U-KAN的信任医学图像分割", "title_en": "Progressive Uncertainty-Guided Evidential U-KAN for Trustworthy Medical Image Segmentation", "authors": "Zhen Yang,Yansong Ma,Lei Chen", "background": "信任医学图像分割旨在为临床决策提供准确和可靠的结果。大多数现有方法采用证据深度学习（EDL）范式，因其计算效率和理论鲁棒性。然而，基于EDL的方法往往忽视利用丰富的注意力线索的不确定性图来细化模糊边界的分割。", "innovation": "本文提出了一种渐进证据不确定性引导注意力（PEUA）机制，以引导模型关注难以区分区域的特征表示学习。此外，引入了语义保持证据学习（SAEL）策略，通过结合语义平滑证据生成器和 fidelity-enhancing 正则化项来保留关键语义。通过将 PEUA 和 SAEL 与最新的 U-KAN 结合，提出了 Evidential U-KAN，为信任医学图像分割提供了一种新解决方案。实验结果表明，Evidential U-KAN 在 4 个数据集上的准确性高于竞争方法，代码可在 GitHub 获取。", "conclusion": "通过 PEUA 和 SAEL 与 U-KAN 结合，提出了 Evidential U-KAN，显著提高了医学图像分割的准确性和可信赖度。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08967", "html_url": "https://arxiv.org/abs/2510.08967", "title": "SAM2-3dMed：赋能SAM2以实现3D医疗图像分割", "title_en": "SAM2-3dMed: Empowering SAM2 for 3D Medical Image Segmentation", "authors": "Yeqing Yang,Le Xu,Lixia Tian", "background": "3D医疗图像的准确分割对于临床应用如疾病评估和治疗规划至关重要。尽管Segment Anything Model 2 (SAM2)在利用时间线索进行视频对象分割方面取得了显著成功，但直接应用于3D医疗图像面临两个基本的领域差异：1）切片之间的双向解剖连续性与视频中的单向时间流动形成鲜明对比；2）对于形态学分析至关重要的精确边界细分在视频任务中往往被忽视。", "innovation": "我们提出了SAM2-3dMed，这是一种对SAM2进行3D医疗成像的适应。该框架引入了两个关键创新：1）切片相对位置预测(SRPP)模块通过引导SAM2以自监督方式预测不同切片的相对位置，明确建模切片之间的双向依赖关系；2）边界检测(BD)模块增强了沿关键器官和组织边界的分割准确性。", "conclusion": "在肺、脾和胰腺（Medical Segmentation Decathlon数据集中的三个不同医疗数据集）的广泛实验证明，SAM2-3dMed显著优于最先进的方法，在分割重叠和边界精度方面表现出更优秀的性能。我们的方法不仅提高了3D医疗图像分割的性能，还提出了将视频为中心的基础模型适应空间体积数据的一般范式。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08858", "html_url": "https://arxiv.org/abs/2510.08858", "title": "稀疏组件区分视觉通路及其与神经网络的对齐", "title_en": "Sparse components distinguish visual pathways & their alignment to neural networks", "authors": "Ammar I Marvi,Nancy G Kanwisher,Meenakshi Khosla", "background": "研究表明，顶叶、内侧和外侧视觉流在高级人类视觉皮层中执行不同的功能过程。然而，通过单一任务训练的深度神经网络（DNN）却能惊人地模拟整个视觉系统，暗示这些路径之间可能存在共同的计算原理。该研究利用新颖的稀疏分解方法来识别每个视觉流中视觉表示的主要组件，结果显示这三种视觉流在组件响应特性上有明显差异，并提出了稀疏组件对齐（SCA）方法来测量大脑和机器间的表示对齐程度，发现标准视觉DNN与内侧视觉流的表示有更高的对齐度.", "innovation": "本文引入了一种新颖的稀疏分解方法来识别每个视觉流中视觉表示的主要组件，以及一种新的方法——稀疏组件对齐（SCA），该方法能够更好地捕捉大脑和机器间的潜在神经调谐。使用SCA方法，发现标准视觉DNN与内侧视觉流的表示有更高的对齐度，这种方法相比传统的群体层面几何，能够更精细地揭示这些差异，为衡量表示对齐提供了一个能反映系统神经调谐基本轴的敏感度量.", "conclusion": "本文的研究揭示了三种视觉流在组件响应特性上的差异，并提出了计算表示对齐的新方法SCA。通过SCA，发现标准视觉DNN更倾向于与内侧视觉流的表示对齐，SCA可以提供一种更细致地捕捉神经调谐差异的度量方式。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08951", "html_url": "https://arxiv.org/abs/2510.08951", "title": "FS-RWKV：利用频率空间感知RWKV进行3T到7T MRI转换", "title_en": "FS-RWKV: Leveraging Frequency Spatial-Aware RWKV for 3T-to-7T MRI Translation", "authors": "Yingtie Lei,Zimeng Li,Chi-Man Pun,Yupeng Liu,Xuhang Chen", "background": "超高的7T MRI能够提供增强的空间分辨率和组织对比度，有助于检测神经退行性疾病中的细微病理变化。然而，由于高昂的基础设施成本和技术要求，7T扫描器的有限可用性限制了其在临床中的广泛应用。现有的利用可访问的3T采集数据合成7T质量图像的计算方法面临空间覆盖率有限和计算成本过高的问题。", "innovation": "本研究提出了一种基于RWKV架构的Frequency Spatial-RWKV框架，用于3T到7T MRI的转换。该框架结合了FSO-Shift模块和SFEB模块，FSO-Shift模块执行离散小波分解，然后在低频分支上进行全方位的空间位移，以增强全局上下文表示并保留高频解剖细节；SFEB模块则通过频率感知特征融合，适应性地强化了解剖结构。实验结果表明，FS-RWKV在UNC和BNU数据集上的一系列实验中，在T1w和T2w模态下均优于现有的CNN、Transformer、GAN和RWKV基线方法，实现了更高的解剖保真度和感知质量。", "conclusion": "提出的FS-RWKV框架结合了高效的RWKV架构和新颖的模块设计，显著提升了从3T到7T MRI转换的质量和效果，为3T MRI向7T MRI的高质量转换提供了可行的解决方案，具有重要的临床应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09038", "html_url": "https://arxiv.org/abs/2510.09038", "title": "GUI代理的自动扩展连续记忆", "title_en": "Auto-scaling Continuous Memory for GUI Agent", "authors": "Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang", "background": "本文研究了如何赋予图形用户界面（GUI）代理可扩展的记忆，该记忆可以跨不熟悉的界面和长期任务进行泛化。先前的GUI代理将过去的行为轨迹压缩为文本标记，这导致了上下文长度的增加并忽略了重要的视觉线索（例如确切的控件大小和位置）。", "innovation": "我们提出了一种连续的记忆方式，通过视觉语言模型（VLM）本身作为编码器将每个GUI轨迹编码为固定长度的连续嵌入序列，并将这些嵌入直接插入主干网络的输入层中，从而显著减少了上下文开销同时保留了详细视觉信息。随着记忆大小和检索深度的增加，性能呈现出单调改进的趋势。我们还引入了一个自动扩展的数据飞轮，通过搜索发现新环境，使用开源VLM合成任务，通过代理执行轨迹，并使用同一VLM验证成功。", "conclusion": "使用该管道，我们收集了超过100,000个轨迹，成本约为4000美元，并仅微调了记忆编码器（使用LoRA对Q-Former进行微调，参数占比1.2%）。在实际的GUI基准测试中，我们的带增强记忆的代理在长期任务和分布偏移下始终提高了成功率。特别是在性能方面，Qwen-2.5-VL-7B + 连续记忆的表现与最先进的闭源模型（如GPT-4o，Claude-4）相当。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08840", "html_url": "https://arxiv.org/abs/2510.08840", "title": "医学影像预后中公平AI的边界：因果分析视角", "title_en": "The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective", "authors": "Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang", "background": "随着机器学习算法在医学图像分析中的应用越来越普遍，人们对其可能对某些社会群体产生偏见的担忧也随之增加。尽管已经提出了许多确保机器学习模型公平性的方法，但大多数现有工作仅关注医学图像诊断任务，如图像分类和分割，而忽视了预后场景，即预测某种医疗状况在时间进程中的可能发生的结果或进展。因此，本文旨在填补这一空白，提出了FairTTE框架，这是首个全面评估医学成像中时间-事件预判公平性的框架，即首次整合前沿的时间-事件（TTE）预测和公平性算法，以系统而细致地分析医学图像预判中的公平性问题。", "innovation": "FairTTE是一个新颖的框架，旨在评估医学成像中的时间-事件预判公平性。它涵盖了多种成像模态和TTE结果，采用因果分析技术揭示和量化医学影像数据集中的偏见源。该研究发现，偏见在不同成像模态中普遍存在，当前的公平性方法限于减轻偏见。同时，它强调，对所有形式偏见进行全面的方法论调整是必要的，并首次表明，模型间的差异与底层偏见来源密切相关，进一步证明了维护公平性的挑战增加，尤其是在数据分布发生变化时。这一研究强调了现有解决方案的局限性，并强调了建立更稳健、更公平的预后模型的迫切需求。", "conclusion": "总体而言，研究发现偏见在不同成像模态中普遍存在，当前的公平性方法无法有效减轻这些偏见。模型的种族不公平与数据分布的变化密切相关，这突显了现有解决方案的局限性。因此，研究建议需要针对所有形式的偏见发展更为全面的方法以确保医学影像中时间-事件预判的公平性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09065", "html_url": "https://arxiv.org/abs/2510.09065", "title": "MMAudioSep: 朝着视频/文本查询音源分离方向驯化视频到音频生成模型", "title_en": "MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation", "authors": "Akira Takahashi,Shusuke Takahashi,Yuki Mitsufuji", "background": "现有的声音分离模型通常需要从头开始训练，这是一个耗时且资源密集的过程。MMAudioSep 模型是一种生成模型，基于预训练的视频到音频模型，利用预训练的音频生成模型中学习到的视频/文本与音频之间的关系知识，使得模型可以更高效地进行训练，无需从头开始训练。", "innovation": "MMAudioSep 利用预训练的视频到音频模型的知识，使得模型在训练时可以不需要从头开始训练，从而更高效。该模型在声音分离性能上优于现有的基准模型，同时保持了原始视频到音频生成的功能。这表明基础的声音生成模型可以被应用于相关的下游任务。", "conclusion": "该研究通过对比测试发现，MMAudioSep 在声音分离任务上的表现优于传统或基于生成方法的声音分离模型。该模型展示了基础音频生成模型在下游音频相关任务上的潜力，并且证明了这种模型在微调获得声音分离功能后仍然保持了原始的视频到音频生成能力。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09060", "html_url": "https://arxiv.org/abs/2510.09060", "title": "OSCAR: 正交随机控制在流匹配中实现对齐尊重的多样性", "title_en": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching", "authors": "Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang", "background": "基于流的文本到图像模型遵循确定性轨迹，迫使用户反复采样以发现多种模式，这个过程既耗时又低效。本文旨在解决这一问题，提出了一种无需训练、仅在推理阶段控制的机制，使流本身具备多样性感知能力。该方法通过特征空间目标鼓励轨迹间的横向扩展，并通过时间调度的随机扰动重新引入不确定性。这种扰动被投影为与生成流正交，这一几何约束使它能够在不影响图像细节或提示保真度的情况下提高多样性。", "innovation": "提出了一种无需重新训练或修改基础采样器的推理阶段控制机制，该机制通过特征空间目标鼓励轨迹间横向扩展，并通过时间调度的随机扰动重新引入不确定性。这个扰动被投影为与生成流正交，从而在不影响图像细节或提示保真度的情况下提高多样性。它在理论上证明了体积因子的单调增加，并通过几何约束近似保持边缘分布。这些理论为图像生成质量的稳定保持提供了原理性解释。实验证明，该方法在固定采样预算下，能够跨多个文本到图像设置一致地提高多样性指标，并保持图像质量和对齐。", "conclusion": "本文提出的方法在固定采样预算下，能跨多个文本到图像设置一致地提高多样性指标，如Vendi评分和Brisque，同时保持图像质量和对齐，理论和实验证明了该方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09333", "html_url": "https://arxiv.org/abs/2510.09333", "title": "高效的噪声成对比较的贝叶斯推理", "title_en": "Efficient Bayesian Inference from Noisy Pairwise Comparisons", "authors": "Till Aczel,Lucas Theis,Wattenhofer Roger", "background": "评估生成模型具有挑战性，因为标准的评测指标往往不能反映人类偏好。尽管人工评估更可靠，但成本高昂且受影响者在专业知识、注意力和尽职尽责程度上的差异，使得结果不稳定。成对比较可以提高一致性，但将这些比较综合为总体质量评分需要仔细建模。基于Bradley-Terry的方法通过比较更新项评分，但现有方法要么忽略了评分者的变化性，要么缺乏收敛保证，限制了其稳健性和可解释性。", "innovation": "我们提出了BBQ，一个贝叶斯Bradley-Terry变体，明确地对评分者质量建模，减少或剔除不可靠的参与者。通过期望最大化算法，提供保证的单调似然收敛。实验证明，BBQ在收敛速度上更快，不确定性估计更准确，对于具有噪音或众包评分者的结果更为稳健和可解释。这项框架使生成模型的人工评估更为可靠和低成本。", "conclusion": "本框架能够提供更可靠且成本效益更高的生成模型的人工评估，通过利用噪声成对比较并在评分者质量建模中提供保证的收敛性，改善了人们评估生成模型的质量和速度。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09306", "html_url": "https://arxiv.org/abs/2510.09306", "title": "重新布线发育：利用成人脑部先验优化婴儿MRI分割", "title_en": "Rewiring Development in Brain Segmentation: Leveraging Adult Brain Priors for Enhancing Infant MRI Segmentation", "authors": "Alemu Sisay Nigru,Michele Svanera,Austin Dibble,Connor Dalby,Mattia Savardi,Sergio Benini", "background": "婴儿大脑MRI准确分割对于研究早期神经发育和诊断神经性疾病至关重要。但在不断变化的解剖结构、运动伪影和高质量标注数据稀缺的背景下，这一过程依然是一个基础挑战。本研究旨在利用成人脑MRI分割模型的先验知识，提升婴儿扫描的分割性能。鉴于成人脑MRI数据的可用性，通过预训练模型，并结合迁移学习和领域适应策略，使模型适应0-2岁婴儿群体。利用FreeSurfer获得的银标准地面真实标签进行弱监督学习，引入了层次特征精炼和多级一致性约束的新训练策略，从而实现快速、准确且年龄适应的分割，同时缓解扫描器和站点特异性偏差。在内部和外部数据集上的实验表明，该方法在传统监督学习和领域特定模型方面具有优势。", "innovation": "本研究创新性地提出了LODi框架，利用成人脑MRI分割模型的先验知识，通过预训练和迁移学习逐步适应0-2岁婴儿群体，采用弱监督学习和银标准地面真实标签，结合层次特征精炼和多级一致性约束的新训练策略，克服了婴儿MRI分割中的挑战，提高了分割的准确性和年龄适应性。", "conclusion": "该研究发现了利用成人脑部先验作为年龄灵活神经影像分析的基础带来的优势，为整个生命周期中的脑MRI分割提供了更可靠和通用的方法。实验结果表明，该方法在婴儿MRI分割中优于传统方法，具有显著优势。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09269", "html_url": "https://arxiv.org/abs/2510.09269", "title": "通过物理对象针对视觉-语言-动作模型的目标导向后门攻击", "title_en": "Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects", "authors": "Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang", "background": "近期，视觉-语言-动作（VLA）模型在体感AI方面的进步显著，使机器人能够遵循自然语言指令并执行多种任务。然而，此类模型的训练数据大多未经严格筛选，这引发了严重的安全问题。现有的针对VLA的后门攻击主要假设白盒访问，并导致任务失败而不是执行特定动作。本研究揭示了一种更为实际的威胁：攻击者只需向训练数据中注入物理对象作为触发器，即可操控VLA模型，使其在存在物理触发器时执行预定义并目标导向的动作。研究基于流行的VLA基准测试LIBERO，引入了整合多样化物理触发器和目标导向后门动作的BadLIBERO数据集，并提出了三种状态的评估方法来分类目标导向后门攻击（GoBA）下模型的行为：无事可做、试图执行和成功执行。实验结果显示，GoBA能够在97%的输入中成功实现后门目标，同时对干净输入的性能无负面影响。研究还发现动作轨迹和触发器颜色显著影响攻击效果，而触发器大小的影响力出人意料地小。相关代码和BadLIBERO数据集可在项目页面下载。", "innovation": "本研究提出了目标导向的后门攻击（GoBA），这是一种更为实际的威胁，攻击者通过在训练数据中注入物理对象触发器来操纵VLA模型。该研究引入了BadLIBERO数据集，包含各种物理触发器和目标导向的后门动作，以此测试模型在GoBA下的行为。研究还提出了一种分级评估方法，将模型行为分为无事可做、试图执行和成功执行三种状态。此外，该研究还分析了影响GoBA性能的因素，发现动作轨迹和触发器颜色是关键因素，而触发器大小的影响微乎其微。", "conclusion": "GoBA能够在存在物理触发器时成功实现后门目标，在97%的输入中保持有效性，同时对无触发器的输入性能无影响。动作轨迹和触发器颜色对攻击效果有很大影响，而触发器大小影响较小。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09390", "html_url": "https://arxiv.org/abs/2510.09390", "title": "识别并互动改进不明确用户目标的数据可视化代码生成", "title_en": "Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation", "authors": "Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani", "background": "人类与人工智能沟通的一个基础步骤是建立共同目标，但表达上的模糊性会导致看似正确的输出，但无法反映说话者的意图。特别是在数据可视化领域，自然语言中的模糊性直接影响代码生成过程，生成用于展示数据的视图。通过对多种观点进行分析，可以全面了解不同类型的模糊性。此研究旨在开发模糊性分类，并提出量化这些模糊性的方法。", "innovation": "本文研究了数据可视化领域中的模糊性问题，并提出了一种新的分类方法来量化模糊性，还展示了多轮对话如何减少模糊性，提高代码准确性。通过分析Matplotlib问题，结果表明，与不确定性基线相比，本文的模糊性度量与人类标注更好相关。此外，还利用了三种实用模型（格赖斯合作原则、话语表征理论和讨论中的问题）来优化对话策略，并通过模拟用户研究验证了多轮对话在代码生成中的价值。", "conclusion": "通过多轮对话，可以减少模糊性，从而提高代码的准确性。通过实际数据集验证，本文的方法能够更准确地适应用户的目标，展示了多轮对话在代码生成中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.19979", "html_url": "https://arxiv.org/abs/2403.19979", "title": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "title_en": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "authors": "Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang", "background": "类增量学习（CIL）旨在使模型能够连续学习新类别的同时克服灾难性遗忘。引入预训练模型带来了新的调优范式，本论文在持续学习的背景下重新审视了不同参数效率调优（PET）方法。", "innovation": "提出了增量调优共享适配器的方法，即不施加参数更新约束，并从存储的原型中采样特征重新训练统一分类器，同时估算旧原型的语义偏移并逐会话更新存储的原型。这种方法无需模型扩展，避免保留任何图像样本，并超越了基于预训练模型的CIL方法。", "conclusion": "在五个CIL基准上的实验结果证明了该方法的有效性，达到了最先进的（SOTA）性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09365", "html_url": "https://arxiv.org/abs/2510.09365", "title": "一种基于生物物理学条件的3D脑肿瘤MRI生成框架", "title_en": "A Biophysically-Conditioned Generative Framework for 3D Brain Tumor MRI Synthesis", "authors": "Valentin Biller,Lucas Zimmer,Can Erdur,Sandeep Nagar,Daniel Rückert,Niklas Bubeck,Jonas Weidner", "background": "磁共振成像（MRI）修复广泛应用于临床和研究中。许多研究工作已经致力于通过MRI修复来改善图像质量，提升诊断准确性。这篇论文提出了一种新型生成模型，该模型利用了体素级别的连续肿瘤浓度约束，以合成高保真度的脑肿瘤MRI图像。研究还适应了健康组织修复任务，通过将肿瘤浓度设为零，生成3D空间上一致且解剖上一致的图像。通过实验，该模型在健康组织修复任务上达到了18.5的PSNR，在肿瘤修复任务上达到了17.4的PSNR。", "innovation": "论文介绍了一种新型的生成模型，该模型能够基于体素级别的连续肿瘤浓度合成高保真度的脑肿瘤MRI图像。此外，该研究还提出了一种针对健康组织修复的新方法，通过将肿瘤浓度设为零，实现了3D空间上一致且解剖上一致的图像生成。", "conclusion": "实验结果显示，在健康组织修复任务上，该模型实现了18.5的PSNR，在肿瘤修复任务上达到了17.4的PSNR。这种基于生物物理学条件的生成框架可以有效用于脑肿瘤MRI的合成与修复，为临床和研究提供了新的工具。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09577", "html_url": "https://arxiv.org/abs/2510.09577", "title": "Dyna-Mind: 从经验中学习模拟以提高AI代理的性能", "title_en": "Dyna-Mind: Learning to Simulate from Experience for Better AI Agents", "authors": "Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao", "background": "最近的研究表明，推理模型在数学和编程等领域的表现非常出色，但在长时间的互动任务上，如网页导航和计算机/手机使用上，其表现与专家水平相差甚远。本文借鉴人类认知的研究，指出当前的AI代理需要拥有‘经验性的试错学习’——即在行动之前能够在内心模拟多种可能的未来——以提高其对复杂互动环境的理解和执行能力。", "innovation": "该研究提出了一种两阶段的训练框架——Dyna-Mind，明确地教会大型语言模型（LVM）整合模拟到其推理过程中。第一阶段引入了ReSim，通过实境体验中的环境交互生成具有结构化的推理轨迹，从而使代理器的推理基于真实世界动态，并能预测未来的状态。第二阶段提出了Dyna-GRPO，一种结合结果奖励和中间状态反馈来强化代理模拟和决策能力的在线强化学习方法。实验结果表明，Dyna-Mind能够显著提高AI代理在长期规划任务上的表现。", "conclusion": "实验结果表明，ReSim有效地将模拟能力引入AI代理中，而Dyna-GRPO则利用结果和交互级别的信号学习更好的策略，以提高复杂交互环境中的长期规划任务的性能。这表明模拟在使AI代理能够更有效地进行推理、规划和行动方面发挥了关键作用，特别是在更加具有挑战性的环境中。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.14335", "html_url": "https://arxiv.org/abs/2403.14335", "title": "基于FFT的统计选择与优化以增强严重受损图像鲁棒识别", "title_en": "FFT-based Selection and Optimization of Statistics for Robust Recognition of Severely Corrupted Images", "authors": "Elena Camuffo,Umberto Michieli,Jijoong Moon,Daehyun Kim,Mete Ozay", "background": "在智能设备（如机器人代理）上实现稳健的视觉系统的关键挑战之一是改进模型的鲁棒性，特别是在处理受损图像时。对于大多数应用程序而言，测试时的稳健性能至关重要。本研究旨在提高任何分类模型在严重受损图像上的鲁棒性，因为现有的大多数方法在这方面表现不佳，特别是在严重受损图像上，基线模型的表现只有40.9%的mCE（误分类率）改善幅度。", "innovation": "本文提出了一种名为FROST（基于FFT的选择和优化统计以稳健识别严重受损图像）的新方法。FROST通过利用高频特征来识别输入图像的损坏类型，并选择分层特征归一化统计量，从而显著提高了模型在受损图像上的鲁棒性。实验结果显示，FROST在不同模型和数据集上的性能均优于竞争对手，在ImageNet-C数据集上的相对性能改进达到37.1%。", "conclusion": "FROST通过利用高频特征和分层特征归一化统计，成功地提高了模型在严重受损图像上的鲁棒性，显著提高了现有方法的性能。特别是在标准数据集ImageNet-C上，其表现超出竞争对手37.1%，基线性能从40.9% mCE提升到更高水平。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2306.11593", "html_url": "https://arxiv.org/abs/2306.11593", "title": "通过排名和LLM融合提高图像描述的详细性", "title_en": "Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion", "authors": "Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano", "background": "现有的图像标注模型通常在Microsoft的Common Objects in Context (MS-COCO) 数据集上训练，该数据集包含大约10个标记词的由人类标注的描述。尽管这些模型能有效理解一般场景，但这些简洁的描述往往难以捕捉复杂的场景细节和传达详细信息。此外，这些模型往往会倾向于生成一种“平均”描述，这种描述只涵盖更一般的方面，忽略了更细致的细节。", "innovation": "本文提出了一种新颖的方法，通过结合不同SoTA图像标注模型产生的描述来生成更丰富和详细的信息。该方法不需要额外的模型训练：给定一幅图像，利用文献中的预训练模型生成初始描述，然后使用新引入的图像-文本基于的度量标准（BLIPScore）进行排名，最后使用大型语言模型（LLM）融合排名靠前的两个描述，生成最终的详细描述。实验证明这种方法在COCO和Flickr30k测试集上在CAPTURE、ALOHa和Polos度量标准方面提高了描述一致性，主观研究也表明生成的描述更符合人类判断。", "conclusion": "通过这种方法综合了不同SoTA模型的优势，提高图像描述的质量和吸引力，减小了自动化系统与人类生成的描述之间的差距，该进步使得生成更适合训练视觉-语言和图像标注模型的描述成为可能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09593", "html_url": "https://arxiv.org/abs/2510.09593", "title": "STaTS: 结构意识时序序列总结化通过统计窗口合并", "title_en": "STaTS: Structure-Aware Temporal Sequence Summarization via Statistical Window Merging", "authors": "Disharee Bhowmick,Ranjith Ramanathan,Sathyanarayanan N. Aakur", "background": "时序数据中包含潜在的时间结构、局部静止状态之间的过渡、重复模式和变异性暴发，这些内容在当前的标准表示学习管道中很少被利用。现有的模型通常在处理未经处理或固定窗口序列时把所有时间区间视为同等重要，这会导致效率低下、鲁棒性差以及处理长且嘈杂的序列时的可扩展性有限。", "innovation": "提出了一种轻量级且无监督的STaTS框架，用于结构感知时间总结。该框架能够自适应地压缩单一和多变量时序数据，压缩率可达30倍，同时保留核心时间动态。STaTS通过基于BIC（Bayesian Information Criterion）的统计差异准则检测多时间分辨率的变化点，然后使用简单的函数（如均值）或生成模型（如GMM）来总结每个时间段。该过程可以作为模型无关的预处理器使用，无需重新训练即可与现有的无监督时序编码器集成。STaTS在包括UCR-85、UCR-128、UEA-30档案在内的150多个数据集上进行了广泛的实验，展示了其在分类和预测任务中接近全模型性能的效果，同时显著减少了计算成本。此外，STaTS在噪声条件下表现出更高的鲁棒性，并且保持了可区分结构，优于均匀和基于聚类的压缩基线。", "conclusion": "STaTS 提出了一种原则性的、通用的方法，能够高效且结构感知地进行时序建模，适用于多种任务，并且在性能和计算效率上都优于现有方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "UltraSeP: 序列感知的预训练方法在心脏超声探头操作指导中的应用", "title_en": "UltraSeP: Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "心脏超声检查是诊断心血管疾病的重要医疗技术，但由于其操作复杂性较高，形成了对专业人员的短缺。心脏结构的复杂性和个体差异是超声成像面临的两大挑战，现有的技术主要学习平均心脏结构而不是个人特异性心脏结构，这限制了其性能。临床过程中，超声医生会基于先前的扫描序列动态调整对病人心脏解剖结构的解读方法，从而进一步调整扫描策略。", "innovation": "提出了一种新颖的序列感知自监督预训练方法，通过预测扫描序列中的缺失图像特征和探头动作来学习个人化的三维心脏结构特征。这种方法假设如果模型能够预测缺失内容，那么它就能很好地理解个性化心脏结构。实验结果表明，与先进的基线方法相比，所提出的方法在探头指导错误方面具有显著优势，适用于引导机器人系统或新手调整探头姿态以获得高质量的标准化图像。", "conclusion": "在大规模专家级扫描数据集上的广泛实验表明，所提出的序列感知预训练方法能够有效地减少探头指导错误，证明了其在心脏超声探头操作指导中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.15117", "html_url": "https://arxiv.org/abs/2409.15117", "title": "基于可变形注意力转换器的扩散型RGB-D语义分割", "title_en": "Diffusion-based RGB-D Semantic Segmentation with Deformable Attention Transformer", "authors": "Minh Bui,Kostas Alexis", "background": "基于视觉的感知和推理对于任何自主系统的场景理解至关重要。通常使用RGB和深度图像来捕捉环境的语义和几何特征。然而，可靠地解释这些数据对于实际应用至关重要，因为这些应用中不可避免地会有噪声测量。本文介绍了一种基于扩散的框架来解决RGB-D语义分割问题，并使用一种可变形注意力转换器作为编码器来提取深度图像的特征，从而有效捕捉深度测量中的无效区域特征。然而，在处理具有挑战性的场景时，生成框架具有更好的建模RGB-D图像底层分布的能力，相较于判别方法有更优的表现，并且训练时间显著减少。实验结果表明，与NYUv2和SUN-RGBD数据集上的现有方法相比，本方法在所有情况下尤其是在其最具挑战性的图像数据上都达到了最佳效果。", "innovation": "提出了一种基于扩散的框架来解决RGB-D语义分割问题，并使用可变形注意力转换器作为深度图像特征提取器，能够更有效地捕捉无效区域特征，从而提高模型的生成能力，实现更稳健的性能。与判别方法相比，该方法在训练时间上显著减少，并在多个数据集上达到了最先进的性能。", "conclusion": "本研究提出的方法在处理噪声测量和处理挑战性场景方面表现优异，通过减少训练时间实现了显著的性能提升，并在NYUv2和SUN-RGBD数据集上达到了最先进的结果。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19528", "html_url": "https://arxiv.org/abs/2411.19528", "title": "RAGDiffusion：通过外部知识融合生成逼真服装", "title_en": "RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation", "authors": "Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni", "background": "标准的服装资产生成涉及从多样的现实世界场景中提取信息，以恢复展示在清晰背景上的正面展开服装图像，这因高度标准化的结构样本分布和复杂场景中缺乏衣物语义而极具挑战性。现有模型在空间感知方面有限，常在高规格生成任务中表现为结构幻觉和纹理失真。", "innovation": "提出了一种新的检索增强生成（RAG）框架，称为RAGDiffusion，通过从语言模型和外部数据库吸收知识，增强结构确定性并减轻幻觉，同时包含两个步骤：（1）基于检索的结构聚合，使用对比学习和结构局部线性嵌入（SLLE）来获取全局结构和空间地标，提供软硬双重指导以对抗结构模糊；（2）全方位忠实地服装生成，引入粗细纹理对齐，确保图案和细节组件的保真度。", "conclusion": "RAGDiffusion在具有挑战性的现实世界数据集上的大量实验表明，它能够生成结构和纹理保真的服装资产，并在性能上取得了显著提升，代表了通过RAG进行高效生成的先驱努力，旨在对抗固有幻觉并增强保真度。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.15966", "html_url": "https://arxiv.org/abs/2411.15966", "title": "Gaussian Scenes: 使用深度增强扩散先验的无姿敬畏稀视场景重建", "title_en": "Gaussian Scenes: Pose-Free Sparse-View Scene Reconstruction using Depth-Enhanced Diffusion Priors", "authors": "Soumava Paul,Prakhar Kaushik,Alan Yuille", "background": "以往的无姿敬畏稀视场景重建方法通常使用深度估计或三维基础先验进行正则化。然而，已有的方法依赖于已知的相机姿态，因此无法直接应用于无拍检场景中。研究者们在这项工作中提出了一种新颖的方法，即使用上下文和几何约束的图像到图像生成模型，通过生成和修复稀疏二维图像中的缺失细节和移除视图渲染和深度图中的伪影，从而生成多视角一致的三维表示。", "innovation": "提出的模型使用Feaature-wise Linear Modulation (FiLM) 调制层替代交叉注意力作为轻量级方案，并提出了一种基于3D高斯散射表示的新颖置信度度量方法，以更好地检测伪影。此外，模型通过以高斯SLAM的启发式过程，在多视图中逐步整合这些新的视图，从而实现了多视角一致的三维表示。", "conclusion": "在MipNeRF360和DL3DV-10K基准数据集上的评估表明，该方法在复杂360度场景中优于现有的无姿敬畏稀视重建技术，并且在与给定预计算相机参数的最新有姿敬畏稀视重建方法的效果相当。项目页面还提供了额外的结果，视频和代码。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.08221", "html_url": "https://arxiv.org/abs/2412.08221", "title": "Generate Any Scene: 情景图驱动的数据合成用于视觉生成训练", "title_en": "Generate Any Scene: Scene Graph Driven Data Synthesis for Visual Generation Training", "authors": "Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna", "background": "现有的文本到视觉生成技术在视觉保真度方面表现出色，但在合成泛化能力和语义对齐方面存在不足。现有的数据集质量不高且组成能力较弱，限制了模型对复杂场景的理解，同时为高质量、大规模的注释提供解决方案仍是一个挑战。", "innovation": "本文引入了Generate Any Scene数据引擎，系统地枚举表示所有可能视觉场景的场景图。该引擎可以根据结构化的对象、属性和关系分类动态构建不同复杂度的场景图。通过生成的场景图，它可以生成文本到图像或视频生成的提示，同时生成一组视觉问题和答案，支持自动评估和语义对齐的奖励建模。通过这一工具，本文设计了自我改进框架，模型通过生成的数据迭代提升性能。还设计了一种蒸馏算法，将专有模型的优势转移给开源版本，仅用不到800条合成的描述，就实现了显著的性能提升。此外，创建了一个低成本的奖励模型对生成内容的语义准确性进行校准，并且还将其应用于下游任务中的内容审核。", "conclusion": "通过Generate Any Scene数据引擎，本文在视觉生成训练过程中实现了一系列创新，包括自我改进框架、蒸馏算法和低成本奖励模型，这些方法显著提升了模型在合成泛化和语义对齐方面的能力，并应用于内容审核任务中。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11060", "html_url": "https://arxiv.org/abs/2412.11060", "title": "平衡数据集中的偏差放大方向性和可解释性", "title_en": "Making Bias Amplification in Balanced Datasets Directional and Interpretable", "authors": "Bhanu Tokas,Rahul Nair,Hannah Kerner", "background": "目前我们使用的大多数机器学习（ML）数据集都存在偏见，这些偏见会传导到训练的模型中，并可能被放大。已有的一些共现基度量已被提出用于测量保护属性A（如性别）和任务T（如烹饪）之间的偏差放大。然而，这些度量在保护属性A与任务T平衡时无法测量偏见。最近的研究提出了一种预测基度量叫泄漏放大来测量平衡数据集中的偏差放大，但这种度量不能识别偏见放大的方向。", "innovation": "本文提出了一种新的预测基度量，称为方向预测放大（DPA），用于测量平衡数据集中的方向性偏差放大。DPA相比泄漏放大更加易于解释，且对攻击者模型（预测基度量中的一个超参数）不那么敏感。我们的实验表明，DPA是衡量方向性偏差放大的有效度量。", "conclusion": "实验结果表明，DPA是衡量方向性偏差放大的有效指标，且该方法将在不久后提供代码。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03333", "html_url": "https://arxiv.org/abs/2502.03333", "title": "RadVLM：用于放射学的多任务对话视觉语言模型", "title_en": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology", "authors": "Nicolas Deperrois,Hidetoshi Matsuo,Samuel Ruipérez-Campillo,Moritz Vandenhirtz,Sonia Laguna,Alain Ryser,Koji Fujimoto,Mizuho Nishio,Thomas M. Sutter,Julia E. Vogt,Jonas Kluckert,Thomas Frauenfelder,Christian Blüthgen,Farhad Nooralahzadeh,Michael Krauthammer", "background": "随着胸部X光片（CXR）的广泛应用和放射科医生的短缺，自动化CXR分析和AI辅助报告的兴趣日益增长。现有视觉-语言模型（VLMs）在报告生成或异常检测等特定任务上表现出潜力，但在交互式诊断能力上则有所欠缺。文章指出，目前的VLMs并不具备理想的多任务对话能力，尤其是在有限标注数据的情况下。因此，迫切需要一种能够支持多任务对话的模型来提高医疗诊断的效率和准确性。", "innovation": "本文提出了一款名为RadVLM的紧凑型多任务对话型基础视觉语言模型，专为CXR分析设计。RadVLM通过涵盖超过100万幅图像指令对的大规模数据集进行训练，内含单轮任务（如报告生成、异常分类、视觉定位）和多轮多任务对话互动。经过fine-tuning后，RadVLM在对话能力和视觉定位方面取得了最先进的性能，同时仍能在其他放射学任务中保持竞争力，并通过消融研究强调了跨任务联合训练的优势，尤其在标注数据有限的情况下可以带来更好的效果。", "conclusion": "RadVLM作为一种临床相关的人工智能助手，提供了结构化的CXR解释和对话功能，支持更高效、更易获得的诊断工作流程。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02362", "html_url": "https://arxiv.org/abs/2410.02362", "title": "医疗图像分析中Mamba架构的全面综述：分类、分割、恢复及其他", "title_en": "A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond", "authors": "Shubhi Bansal,Sreeharish A,Madhava Prasath J,Manikandan S,Sreekanth Madisetty,Mohammad Zia Ur Rehman,Chandravardhan Singh Raghaw,Gaurav Duggal,Nagendra Kumar", "background": "Mamba作为一种特殊的系统状态模型，在医疗图像分析中作为模板基于的深度学习方法的一种替代方案而受到关注。虽然transformers在架构方面非常强大，但也存在计算复杂度呈二次方以及难以高效处理长距离依赖性的缺点。这些限制影响了在大型且复杂的医疗图像数据集中，对于大量空间和时间关系的分析。相比之下，Mamba因其优点而特别适合医疗图像分析。它具有线性时间复杂性，这在性能上优于transformers，同时也能处理较长序列而无需使用注意力机制，这可以加快推理速度并降低内存需求。", "innovation": "Mamba架构具备线性时间复杂性，避免了transformers的二次方计算复杂度问题，可以更有效地处理长序列数据。Mamba无需使用注意力机制就能处理较长序列，从而加速推理过程并减少内存需求。此外，Mamba在处理多模态数据方面表现出色，提高了诊断准确性并对患者产生积极影响。通过对核心概念如SSMs以及Mamba架构如纯Mamba、U-Net变体和混合模型（包括卷积神经网络、变压器和图神经网络）的详细介绍，使读者能够逐步了解Mamba在医疗成像中的能力。", "conclusion": "本文旨在展示Mamba在克服医疗图像分析中的现有障碍方面的变革潜力，并为该领域带来创新的前进方向。详细回顾了在医疗领域应用的Mamba架构列表，内容可参见GitHub。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.07960", "html_url": "https://arxiv.org/abs/2501.07960", "title": "SkipClick: 结合快速响应和低级特征的冬季运动场景中交互式分割", "title_en": "SkipClick: Combining Quick Responses and Low-Level Features for Interactive Segmentation in Winter Sports Contexts", "authors": "Robin Schön,Julian Lorenz,Daniel Kienzle,Rainer Lienhart", "background": "交互式分割领域致力于通过用户提供的指导信息（如点击提示）来预测高质量的分割掩码，以提高分割质量。现有方法虽然能够快速响应用户指导，但在冬季运动设备的分割上有待改进。已有模型如SAM和HQ-SAM在冬季运动设备 dataset（WSESeg）上的表现不佳，SkipClick旨在通过改进架构来提升性能，特别是在冬季运动场景中的应用效果。", "innovation": "该研究提出了一个新颖的架构SkipClick，它能够结合快速响应和低级特征，特别是在处理冬季运动场景中的交互式分割任务时表现出色。与现有方法SAM相比，SkipClick在WSESeg数据集上的NoC@85指标高出2.336点击，在HQSeg-44k数据集上则表现出最佳结果，其NoC@90为6.00，NoC@95为9.89。此外，它在新数据集上的表现也令人满意，该数据集包含滑雪过程中人类的掩码信息，证明了其在应对复杂和动态场景的能力。", "conclusion": "SkipClick通过改进的架构在多种数据集上展现了更好的性能，尤其是对冬季运动设备的交互式分割任务非常有效。该方法不仅提高了响应速度，还在分割精度上实现了显著的提升。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09520", "html_url": "https://arxiv.org/abs/2502.09520", "title": "SQ-GAN: 使用遮罩向量量化进行语义图像通信", "title_en": "SQ-GAN: Semantic Image Communications Using Masked Vector Quantization", "authors": "Francesco Pezone,Sergio Barbarossa,Giuseppe Caire", "background": "研究了一种新的方法，即语义掩蔽向量量化生成对抗网络（SQ-GAN），它结合了语义驱动的图像编码和向量量化，优化语义/任务导向的图像压缩。该方法仅作用于源编码，并且完全兼容现有的系统。通过使用现成的软件计算图像的语义分割图来提取语义。上下文相关自适应掩码模块（SAMM）被开发特定用于选择性编码图像中的语义相关信息。不同语义类别的相关性受任务影响，并在训练阶段通过引入适当的权重在损失函数中进行量化。", "innovation": "提出了一种新颖的方法SQ-GAN，该方法将语义驱动的图像编码和向量量化结合，以优化语义/任务导向的图像压缩。通过计算语义分割图提取语义信息，并引入特定的部件（如SAMM）来选择性编码图像的语义相关信息，确保压缩效率和重建图像的感知质量和语义分割准确性。", "conclusion": "SQ-GAN相比现有图像压缩方案（如JPEG2000、BPG和基于深度学习的方法）在多个指标上表现出更优性能，特别是在极低压缩率下，实现了感知质量和语义分割准确性的同时提升。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.17159", "html_url": "https://arxiv.org/abs/2502.17159", "title": "RobustMerge：具有方向稳健性的参数高效模型合并方法", "title_en": "RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness", "authors": "Fanhu Zeng,Haiyang Guo,Fei Zhu,Li Shen,Hao Tang", "background": "使用自定义数据微调预训练模型生成特定任务的专家模型正在变得普遍。合并模型以赋予多任务能力，并避免数据泄露也在逐渐流行。然而，随着数据和模型规模的扩大，参数高效微调成为高效获取任务特定模型的常用做法。但是，很少有方法专注于高效的合并，而现有的用于全微调合并的方法在高效合并下会失效。", "innovation": "本文分析了低秩分解，并揭示了合并过程中方向稳健性的重要性，同时发现弥补显著奇异值之间的差距有助于增强方向稳健性。在此基础上，提出了一种无需训练的参数高效合并方法RobustMerge，该方法通过互补参数适应来保持方向稳健性。具体而言，RobustMerge通过从参数间关系中剪枝参数和缩放系数来维护远离任务干扰的方向稳定性，以及通过跨任务归一化来提高对未见过任务的泛化能力。", "conclusion": "在涵盖多种多模态任务的基准上，实验证明了RobustMerge方法的优越性能和一般性，并进行了附加研究和详细分析，进一步展示了其有效性。相关代码可在这个链接下载。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11101", "html_url": "https://arxiv.org/abs/2503.11101", "title": "自监督对比学习在多模态文本-图像分析中的综述", "title_en": "A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis", "authors": "Asifullah Khan,Laiba Asmatullah,Anza Malik,Shahzaib Khan,Hamna Asif", "background": "自监督学习是一种通过学习潜在模式和从未标记数据中提取具有区分性的特征来生成隐含标签的机器学习方法。对比学习引入了“正样本”和“负样本”的概念，其中正样本（例如同一图像/物体的不同变体）在嵌入空间中被聚集在一起，而负样本（例如不同图像/物体的不同视角）则被推动远离。这种方法在无需大量依赖标记数据的情况下，在图像理解和图像文本分析中展现了显著的改进。本文系统地探讨了对比学习在文本-图像模型中的术语、最近的发展和应用。", "innovation": "本文提供了一个关于最近几年对比学习在文本-图像模型中的方法概述，将方法根据不同模型结构进行了分类，并讨论了预训练任务、架构结构和关键技术的最新进展。此外，还讨论了自监督对比学习在文本-图像模型中的最新应用。", "conclusion": "本文综述了自监督对比学习在文本-图像分析中的方法发展和应用现状，强调了其在减少对标记数据依赖方面的能力，并展望了未来的研究趋势和应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07878", "html_url": "https://arxiv.org/abs/2503.07878", "title": "使用可预测性度量图像标题中的方向性偏差放大", "title_en": "Measuring directional bias amplification in image captions using predictability", "authors": "Rahul Nair,Bhanu Tokas,Hannah Kerner", "background": "当我们在有偏差的ML数据集上训练模型时，它们不仅会学到这些偏差，还可能在测试时放大这些偏差，这一现象被称为偏差放大。目前一些基于共现的度量方法被提出用于衡量ML数据集中的偏差放大，这些方法在简单的图像分类等问题上有效，但是对于复杂的问题如图像字幕则无法捕捉到标题的语义。为了量化图像字幕中的偏差放大，先前的研究引入了一个基于可预测性的度量——字幕泄露度量（LIC），但LIC方法也有局限性，如无法识别偏差放大的方向，对词汇替换策略弱，以及对攻击者模型的高敏感性。", "innovation": "为了克服上述问题，该研究提出了方向性可预测性放大在字幕中的方法（DPAC），该方法能够量化字幕中的方向性偏差放大，使用改进的替代策略提供更好的数据集偏差估算，并且对攻击者模型的敏感性较低。这项研究通过使用COCO字幕数据集的实验证明了DPAC是最可靠的偏差放大度量方法。", "conclusion": "DPAC方法是目前衡量字幕偏差放大最可靠的指标，因为它能够识别偏差放大的方向、提供更准确的数据集偏差估计，并且对攻击者模型的敏感性较低。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.18430", "html_url": "https://arxiv.org/abs/2503.18430", "title": "CQ-DINO：通过类别查询缓解梯度稀释实现大量词汇目标检测", "title_en": "CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection", "authors": "Zhichao Sun,Huazhang Hu,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu", "background": "随着数据的指数级增长，传统的目标检测方法越来越难以有效地处理词汇量庞大、种类繁多的目标检测任务。我们分析了基于分类的目标检测器的两个关键限制：正面梯度稀释，即少见的正面类别接收到的学习信号不足；棘手负梯度稀释，即区分性梯度被大量的容易负例所淹没。", "innovation": "我们提出了CQ-DINO（基于类别查询的目标检测框架），通过将分类重新定义为对象查询与可学习类别查询之间的对比任务来解决这些挑战。该方法引入了图像引导的查询选择，通过跨注意力机制在每张图像中适当地检索前K个相关类别以减少负空间，从而调整梯度分布并促进隐式的困难样本挖掘。此外，CQ-DINO灵活地在结构化数据集（如V3Det）中整合显式的层次类别关系，或在通用数据集（如COCO）中通过自注意力学习隐式的类别相关性。实验表明，CQ-DINO在具有挑战性的V3Det基准测试中取得优异的表现（超越先前方法2.1% AP），并在COCO上保持竞争力。我们的工作提供了一种针对具有广泛类别覆盖需求的现实世界检测系统的大规模解决方案。", "conclusion": "我们的工作提供了一种针对具有广泛类别覆盖需求的现实世界检测系统的大规模解决方案。通过CQ-DINO框架，我们提出了一个可扩展的解决方案来缓解类别稀释问题，从而显著提高目标检测性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.03948", "html_url": "https://arxiv.org/abs/2504.03948", "title": "ProbRes: 可能的跳跃扩散方法在开放世界主观活动识别中的应用", "title_en": "ProbRes: Probabilistic Jump Diffusion for Open-World Egocentric Activity Recognition", "authors": "Sanjoy Kundu,Shanmukha Vellamcheti,Sathyanarayanan N. Aakur", "background": "开放世界主观活动识别由于其不受约束的性质，面临着基本挑战，要求模型从一个广泛未完全观察的空间中推断出未见过的活动。这需要平衡先验引导的探索和基于似然性的利用，解决在长时间序列中智能物体和主体活动理解的问题。", "innovation": "提出了基于跳跃扩散的概率残差搜索框架（ProbRes），该框架通过平衡先验引导的探索和似然性的利用来高效地导航空间。ProbRes 结合结构化的常识先验，使用视觉语言模型（VLMs）自适应地细化预测，并采用了随机搜索机制，能够高效地定位高似然度的活动标签，同时最小化全面枚举。", "conclusion": "ProbRes 在多个开放性水平 (L0-L3) 上进行了系统性评估，并证明了其在开放空间复杂性增加时的适应性。ProbRes 在基准数据集（GTEA Gaze、GTEA Gaze+、EPIC-Kitchens 和 Charades-Ego）中达到了最先进的性能。我们提出了开放世界识别的明确分类，界定了主观活动理解和方法进展的必要挑战。研究表明，结构化的搜索策略对于开放世界活动识别具有重要意义，开启了可扩展和高效的开放世界活动识别的道路。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19495", "html_url": "https://arxiv.org/abs/2505.19495", "title": "视频生成在增强受限数据动作理解中的作用", "title_en": "The Role of Video Generation in Enhancing Data-Limited Action Understanding", "authors": "Wei Li,Dezhao Luo,Dongbao Yang,Zhenhang Li,Weiping Wang,Yu Zhou", "background": "在现实世界场景中的视频动作理解任务常常面临数据量不足的问题。为解决这一数据有限的动作理解问题，该研究利用视频生成技术来弥补数据稀缺，生成标注数据用于模型训练，从而在无需人工干预的情况下生成无限量的、现实的标注数据。通过定量和定性的分析，研究发现真实的样本通常包含比生成样本更丰富的内容，因此提出了信息增强策略，从环境和角色两个方面增强生成样本的信息含量。对于一些质量较低的可能对模型训练产生负面影响的生成样本，提出了基于不确定性的标签平滑策略以减少它们的影响。该方法在四个数据集上的五个任务上得到了验证，并实现了零样本动作识别的最新性能。", "innovation": "提出了采用文本到视频扩散变换器生成标注数据的方法，通过信息增强策略提升生成样本的信息含量，并采用基于不确定性的标签平滑策略减少低质量样本对模型训练的负面影响。", "conclusion": "实验结果表明，提出了的方法在四个数据集上五个任务上有效，并且实现了零样本动作识别的最新性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.10190", "html_url": "https://arxiv.org/abs/2504.10190", "title": "Differentially Private 2D Human Pose Estimation", "title_en": "Differentially Private 2D Human Pose Estimation", "authors": "Kaushik Bhargav Sivangi,Paul Henderson,Fani Deligianni", "background": "人体姿态估计（HPE）在医疗保健、活动识别和人机交互等多个应用中变得至关重要。然而，处理敏感视觉数据时的隐私问题对关键领域的部署构成了重大障碍。传统的脱敏技术提供有限的保护，通常会牺牲数据对广泛运动分析的实用性。相比之下，差异隐私（DP）虽然提供了形式化的隐私保证，但在应用时通常会降低模型性能。", "innovation": "该工作提出了第一个综合框架，应用Differentially Private Stochastic Gradient Descent (DP-SGD)实现差分隐私下的二维人体姿态估计（2D-HPE）。提出了Projected DP-SGD（PDP-SGD）方法，将带噪梯度投影到低维子空间，以平衡隐私与性能。结合Feature Differential Privacy (FDP)选择性地脱敏敏感特征，同时保留公共视觉线索。还提出了混合特征-投影差分隐私框架，将两者结合起来平衡HPE中的隐私与准确性。", "conclusion": "该研究方法在MPII数据集上进行了评估，并在不同隐私预算、训练策略和裁剪范数下进行了测试。综合特征-投影方法一致性地优于传统的DP-SGD和单独的基线，当ε=0.8时，PCKh@0.5平均达到了82.61%，显著地接近非私有性能。这项工作为实际应用中的隐私保护人体姿态估计奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.21447", "html_url": "https://arxiv.org/abs/2504.21447", "title": "多模态语言模型在查看浅层信息时能看得更好", "title_en": "Multimodal Language Models See Better When They Look Shallower", "authors": "Haoran Chen,Junyan Lin,Xinghao Chen,Yue Fan,Jianfeng Dong,Xin Jin,Hui Su,Jinlan Fu,Xiaoyu Shen", "background": "多模态大型语言模型（MLLMs）通常从预训练的视觉变换器（Vision Transformer, ViT）的最终层中提取视觉特征。然而，这种方法通常被视为经验惯例而未经过严格分析。尽管先前的研究表明，不同层的ViT捕捉不同类型的视觉信息，浅层专注于细粒度视觉细节而深层更接近文本语义，但这种差异对MLLM性能的影响尚不清楚。本文首次全面研究了MLLM中的视觉层选择，分析了ViT各层的表示相似性，依此建立了浅层、中层和深层层分组。研究发现，在图像识别等细粒度视觉任务中，浅层和中层显著优于深层。基于这些见解，提出了一个轻量级特征融合方法，通过战略性地结合浅层信息，取得了比单一层数和特化融合基线的一致改进。这是一项首创的研究，表明MLLM在查看浅层信息时可以更有效地工作。", "innovation": "首次全面研究了MLLM中的视觉层选择，通过分析不同层的表示相似性来建立浅层、中层和深层层分组；提出了轻量级特征融合方法，通过战略性地结合浅层信息，为MLLM带来一致改进。", "conclusion": "MLLM在查看浅层信息时可以更有效地工作，特别是在细粒度视觉任务中表现更好；提出了一个基于浅层信息融合的方法，实现了性能提升。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03991", "html_url": "https://arxiv.org/abs/2505.03991", "title": "体育视频事件检测中的深度学习：任务、数据集、方法与挑战", "title_en": "Deep Learning for Sports Video Event Detection: Tasks, Datasets, Methods, and Challenges", "authors": "Hao Xu,Arbind Agrahari Baniya,Sam Well,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal", "background": "视频事件检测已成为现代体育分析的基石，推动了自动性能评估、内容生成和战术决策。近年来，深度学习的进展推动了诸如时间动作定位（TAL）、动作斑点化（AS）和精确事件斑点化（PES）等任务的进步。虽然这些任务紧密相关，但在细节上的差别模糊了它们之间的界限，导致了研究和实际应用中的混淆。此外，先前的综述要么专注于通用视频事件检测，要么着眼于更广泛的体育视频任务，但忽视了事件斑点化特有的时间粒度和领域特定挑战。现有的多数体育视频综述关注精英级赛事，而忽视了普通实践中更广泛的社区。本文通过明确区分TAL、AS和PES及其各自的使用案例，构建了一个结构化的方法和技术分类法，并严格评估基准数据集和评估协议，展示了这些工作的背景和重要性。", "innovation": "本文通过区分TAL、AS和PES及其具体的使用场景，引出了一种系统的方法和技术分类方案，包括时间建模策略、多模态框架和数据高效管道，特别是针对AS和PES的优化。此外，本文还严厉评估了基准数据集和评估协议，指出了很多表象上的限制，强调了对广播质量视频的依赖，并且评价了倾向于宽松多标签预测的指标。通过综合当前研究，本文还揭示了开放性挑战，为研究和工业社区提供了开发高精度、通用化及可实际部署的体育事件检测系统奠定了坚实的基础。", "conclusion": "通过综合现有研究和揭示开放性挑战，本文为研发高精度、通用化以及实际部署的体育事件检测系统提供了全面的基础，旨在为研究和工业界提供指导。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21334", "html_url": "https://arxiv.org/abs/2505.21334", "title": "HoliTom: 全局性标记合并用于快速视频大语言模型", "title_en": "HoliTom: Holistic Token Merging for Fast Video Large Language Models", "authors": "Kele Shao,Keda Tao,Can Qin,Haoxuan You,Yang Sui,Huan Wang", "background": "现有的视频大语言模型（video LLMs）虽然在视频理解方面表现出色，但存在因冗余视频标记而导致的显著计算效率低下问题。虽然现有的标记剪裁方法提供了解决方案，但这两类方法（内LLM剪裁和外LLM剪裁）都存在不足：内LLM剪裁方法虽然可以减少计算开销，但在浅层计算中会增加计算开销；而外LLM剪裁方法虽然解决了空间冗余，但忽视了长时间视频序列中的全局时间动态和相关性，从而导致时空减少不充分，未能充分利用视频压缩潜力。", "innovation": "本文提出了HoliTom，这是一种训练无需的方法，通过全局冗余感知的时间分割执行外LLM剪裁，并通过时空合并减少视觉标记超过90%，显著减轻LLM的计算负担。此外，本文还提出了一种基于内LLM标记相似性的合并方法，旨在提高性能并兼容外LLM剪裁。实验结果表明，该方法在LLaVA-OneVision-7B上的效率-性能权衡表现优秀，计算成本降低至FLOPs的6.9%，同时保持了原始性能的99.1%。此外，还实现了2.28倍的首次标记时间（TTFT）减少和1.32倍的解码吞吐量加速。", "conclusion": "HoliTom方法通过结合内LLM和外LLM剪裁策略，提供了高效视频LLM推理的实际益处，实现了计算成本和性能的优化平衡。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23044", "html_url": "https://arxiv.org/abs/2505.23044", "title": "SpatialSplat: 从稀疏无姿态图像高效生成语义3D", "title_en": "SpatialSplat: Efficient Semantic 3D from Sparse Unposed Images", "authors": "Yu Sheng,Jiajun Deng,Xinran Zhang,Yu Zhang,Bei Hua,Yanyong Zhang,Jianmin Ji", "background": "在三维重构领域，前馈范式通过生成像素级的3D点或高斯原语来自动生成3D图像。然而，这种方法存在局限性：一是简单压缩的特征损失了表达能力，影响了模型捕捉细粒度语义的能力；二是像素级的原语预测在重叠区域带来了冗余，增加了不必要的内存开销。", "innovation": "SpatialSplat 提出了一种新的前馈框架，能够在稀疏无姿态图像上生成语义3D。 SpatialSplat 通过分解语义表示为粗粒度特征场和细粒度低维特征场，并引入了选择性高斯机制来保留场景中必要的高斯原语，从而有效地解决了前馈范式的上述问题。这一方法使得语义三维重建更加适用。", "conclusion": "广泛的实验结果表明，SpatialSplat 通过更紧凑的三维高斯原语学习了准确的语义信息和详细的实例，在场景表示参数上减少了 60%，同时表现优于现有的方法。代码可以在此 https URL 获得。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21593", "html_url": "https://arxiv.org/abs/2505.21593", "title": "从任意主体到虚化效果：基于视频扩散模型的视频深焦重构", "title_en": "Any-to-Bokeh: Arbitrary-Subject Video Refocusing with Video Diffusion Model", "authors": "Yang Yang,Siming Zheng,Qirui Yang,Jinwei Chen,Boxi Wu,Xiaofei He,Deng Cai,Bo Li,Peng-Tao Jiang", "background": "近年来，扩散模型作为相机模拟的强大工具出现，能够实现几何变换和真实的光学效果。图像基础的高斯模糊渲染已经显示出良好的结果，但在视频模糊渲染方面仍然缺乏研究。现有的图像基础方法受到时间闪烁和模糊过渡不一致的问题困扰，而当前的视频编辑方法也不能明确控制焦平面和虚化强度。这些问题限制了它们在可控视频虚化中的应用。背景提到，通过多平面图像(MPI)表示，结合预训练模型中的强三维先验，提出了一个视频扩散模型的一步扩散框架，以实现时空一致且深度感知的视频虚化渲染。进一步提出了一种渐进式的训练策略以增强时间稳定性、深度鲁棒性和细节保持能力。实验表明，该方法在时间和空间精度、可控性方面优于之前的基线方法。该项工作首次提供了一个专门用于视频虚化生成的扩散框架，建立了时间一致和可控深度场效应的新基准。", "innovation": "该工作提出了一种基于视频扩散模型的一步扩散框架，用于生成时空一致且深度感知的视频虚化渲染。框架采用适应焦平面的多平面图像(MPI)表示来条件化视频扩散模型，利用预训练模型中的强三维先验。进一步提出现有一个渐进式的训练策略，以增强时间稳定性、深度鲁棒性和细节保持能力。此外，该工作是第一个专门针对视频虚化生成的扩散框架，建立了时间一致和可控深度场效应的新基准。", "conclusion": "本工作通过多平面图像(MPI)适配焦平面的表示来条件化视频扩散模型，利用预训练模型中的强三维先验，实现了时空一致且深度感知的视频虚化渲染。通过一步扩散框架和渐进式的训练策略，增强了时间稳定性、深度鲁棒性和细节保持能力。实验结果表明，该方法在时间和空间精度、可控性方面优于之前的基线方法，并建立了时间一致和可控深度场效应的新基准。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03517", "html_url": "https://arxiv.org/abs/2506.03517", "title": "DenseDPO：用于视频扩散模型的精细粒度时间偏好优化", "title_en": "DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models", "authors": "Ziyi Wu,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ashkan Mirzaei,Igor Gilitschenski,Sergey Tulyakov,Aliaksandr Siarohin", "background": "直接偏好优化(DPO)作为一种后训练技术被应用到文本到视频的扩散模型上。通过让注释者提供两个由独立噪声生成的视频之间的偏好，以获取训练数据。然而，这种方法限制了细腻的对比，并导致注释者倾向于低运动量的片段，因为这些片段通常视觉伪影较少。这种偏见影响了模型生成视频的效果，尤其是运动生成方面。", "innovation": "DenseDPO通过对以下三个方面进行改进实现了创新：1. 通过去噪真实的视频副本创建DPO的视频对，这种方式生成的视频对运动结构相似而局部细节不同，消除了运动偏见；2. 利用时间上的对齐，对短时段进行偏好标记而不仅仅是在整个片段上进行，从而得到更稠密和精确的学习信号；3. 采用现成的视觉语言模型（VLMs）实现自动偏好标注，GPT能够准确预测片段级别的偏好，且DenseDPO使用这些标签训练的效果接近使用人工标注的效果，显著提高了运动生成的质量。", "conclusion": "与传统的DPO相比，DenseDPO虽然只需要三分之一的数据标注，但在运动生成、文本对齐、视觉质量和时间一致性方面都有显著提升。此外，DenseDPO可以利用现成的VLMs进行自动偏好标注，这提高了标注的效率和质量。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18369", "html_url": "https://arxiv.org/abs/2506.18369", "title": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models", "title_en": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models", "authors": "Yeongtak Oh,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Jisoo Mok,Sungroh Yoon", "background": "近期的多模态大语言模型（MLLMs）在生成个性化的图像标题时往往表现不佳，即使使用高质量的图像标题进行了训练。现有的后训练个性化方法也面临相同的问题，尽管这些模型经过大规模标注的图像标题的监督微调（SFT），但在现实场景中（如多概念图像标题）生成准确描述的频率仍然较低。然而，为复杂场景获取大规模高质量描述数据的成本高且困难。", "innovation": "本文提出了一种基于强化学习（RL）的后训练框架，这是首次使用RL方法对MLLMs进行后训练，以实现个性化图像标题生成。该方法显著改善了MLLMs的视觉识别能力和个性化生成能力，尤其是在具有挑战性的多概念图像标题生成任务中，持续优于现有的SFT基线模型。", "conclusion": "我们的方法在多概念图像标题生成任务中的表现显著优于现有基线，表明基于强化学习的后训练框架能够有效提升MLLMs的个性化图像标题生成能力。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05289", "html_url": "https://arxiv.org/abs/2506.05289", "title": "针对Tokenizer与自回归模型之间序列建模的对齐", "title_en": "Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model", "authors": "Pingyu Wu,Kai Zhu,Yu Liu,Longxiang Tang,Jian Yang,Yansong Peng,Wei Zhai,Yang Cao,Zheng-Jun Zha", "background": "自回归图像生成旨在基于先前的像素或标记预测下一个像素或标记。然而，这一过程受到传统图像标记方法中固有的双向依赖性的挑战，这与自回归模型固有的单向性特征不匹配。", "innovation": "本文提出了AliTok，这是一种新颖的对齐Tokenizer，通过改变标记序列的依赖结构来解决问题。AliTok利用一个受到因果解码器约束的双向编码器，该设计促使编码器产生具有丰富语义和前向依赖性的标记序列。此外，通过引入前缀标记并采用两阶段Tokenizer训练过程来提高重建性能。", "conclusion": "基于AliTok，一个标准的仅解码器的自回归模型（只有177M参数）在ImageNet-256基准测试中实现了gFID 1.44和IS 319.5的高保真度和可预测性。在参数扩展到662M时，模型实现了gFID 1.28，并超越了最先进的扩散方法，同时具有10倍更快的采样速度。代码和权重可在提供的链接处获取。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05404", "html_url": "https://arxiv.org/abs/2506.05404", "title": "AD-EE: 自主驾驶中快速和可靠的早期退出机制用于视觉-语言模型", "title_en": "AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving", "authors": "Lianming Huang,Haibo Hu,Yufei Cui,Jiacheng Zuo,Shangyu Wu,Nan Guan,Chun Jason Xue", "background": "随着自主驾驶技术的迅速发展，视觉-语言模型（VLMs）在增强感知和决策能力方面得到了广泛应用。然而，VLMs的实时应用受到高延迟和计算开销的限制，尤其是在关键时间驱动场景中限制了其效果。特别是当VLMs表现出过度推理时，即使在获得自信预测后，它们仍然继续处理不必要的层，导致效率低下。因此，需要一种新的方法来解决这一问题，以提高实时性并优化性能。", "innovation": "本文提出了AD-EE框架，该框架结合了自主驾驶领域的特性，并利用因果推理来识别最佳的退出层。通过这种方法，可以在保持准确性的前提下显著减少延迟，并提高对象检测的准确性。实验结果表明，该方法在多种VLMs上可以减少高达57.58%的延迟，并且可以提高高达44%的对象检测准确性，从而在真实世界和实际车辆平台上提高了速度和可靠性。", "conclusion": "AD-EE框架通过有效识别并利用合适的退出层，成功解决了VLMs在自主驾驶中的实时性和性能问题。实验表明其在多个实际应用数据集和平台上的有效性，证明了其在提高驾驶效率方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04122", "html_url": "https://arxiv.org/abs/2506.04122", "title": "轮廓误差：一种针对可靠3D多目标跟踪的以自我为中心的度量", "title_en": "Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking", "authors": "Sharang Kaul,Mario Berk,Thiemo Gerbich,Abhinav Valada", "background": "多目标跟踪（MOT）对于确保如自动驾驶车辆等关键应用中感知系统的准确性和可靠性至关重要。传统的匹配度量，如交并比（IoU）和中心点距离（CPD），在2D图像平面上表现良好，但在复杂3D场景中往往无法发现关键匹配。因此，需要一种新的匹配度量来解决这个问题，以便在3D环境中实现更可靠的多目标跟踪。", "innovation": "本文提出了一种轮廓误差（CEs）度量，这是一种以自我或物体为中心的功能视角度量，用于确定跟踪场景中的匹配项。通过在自我车辆框架中比较边界框，轮廓误差提供了更符合功能要求的对象匹配评估。实验表明，轮廓误差在检测到跟踪中的功能性失败（FPs/FNs）方面优于最先进的2D IoU和CPD度量，特别是在近距离和远距离上分别减少了80%和60%的功能性失误。", "conclusion": "本文通过提出轮廓误差（CEs）作为功能视角的匹配度量，显著改进了3D多对象跟踪，不仅提升了匹配的可靠性，还在3D车辆跟踪中减少了功能性失败。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02680", "html_url": "https://arxiv.org/abs/2506.02680", "title": "使用FLAIR解决逆问题", "title_en": "Solving Inverse Problems with FLAIR", "authors": "Julius Erbach,Dominik Narnhofer,Andreas Dombos,Bernt Schiele,Jan Eric Lenssen,Konrad Schindler", "background": "基于流动的隐式生成模型如Stable Diffusion能够生成高质量的图像，甚至可以实现文本到图像的超逼真生成。这些模型的出色表现表明，这些模型也可以作为逆图像问题的强大先验，但目前这种方法在精度上还未取得可比的结果。主要障碍包括数据似然性项通常不可计算、学习生成模型不能直接根据受损观察进行条件化导致数据似然性与先验之间存在冲突目标以及重建可能会偏离观察数据。", "innovation": "我们提出了一个无需训练的新型变分框架FLAIR，利用基于流动的生成模型作为逆问题的先验。我们提出了一个对降解类型不敏感的流动匹配变分目标，并与确定性的轨迹调整相结合，引导先验向后验概率更高的区域。为确保与观察数据的一致性，我们分离了数据保真和正则化项的优化。同时，我们引入了一个时间相关的校准方案，根据离线准确估计调节正则化的强度。结果显示，FLAIR在重建质量和样本多样性上优于现有扩散和基于流动的方法。", "conclusion": "在标准成像基准上的结果表明，FLAIR在重建质量和样本多样性方面始终优于现有的扩散和基于流动的方法。我们的代码可以在该链接获取：this https URL"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "在帕金森病中基于视频的可解释且精细化的指尖敲击测试运动特征量化", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确量化帕金森病（PD）的运动特征对于监测疾病进展和优化治疗策略至关重要。传统的指尖敲击测试是一种标准的运动评估方法，临床医生通过视觉评估患者的敲击表现并基于敲击幅度、速度和不规则性分配总体严重程度评分。然而，这种主观评估容易产生不同的评价者间和同一评价者内的一致性问题，并不能提供关于测试过程中所捕捉的个体运动特征的见解。本文提出了一种基于计算机视觉的方法，用于通过视频记录定量帕金森病的运动特征。", "innovation": "本文提出了一个基于视频的、可解释且精细化的方法来定量帕金森病患者的指尖敲击测试（FTT）。该方法通过视频记录数据提取了一系列四个与临床相关的特征，用于描述运动减少、动作迟缓、序列效应和犹豫-停止等多个运动特征。这种方法能够克服传统主观评估的局限性，并且通过利用这些特征训练机器学习模型来预测运动障碍学会统一帕金森病评定量表（MDS-UPDRS）的敲击分数，相比现有的先进技术，这种方法在预测准确性方面表现更佳，同时仍能提供可解释的个体敲击运动特征的量化结果。", "conclusion": "所提出的框架提供了一种用于客观评估帕金森病运动特征的实用解决方案，可能适用于临床和远程环境。未来的工作需要评估其对症状性治疗和疾病进展的敏感性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav：在城市环境中利用层次空间认知长短时记忆系统增强视觉-语言导航", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大型城市环境中进行视觉-语言导航（VLN）需要使具身代理能够在复杂场景中理解语言指令，并在长时间范围内回忆相关经验。之前的模态管道提供了可解释性，但缺乏统一的记忆，而端到端的（M）LLM代理在融合视觉和语言方面表现出色，但仍然受到固定上下文窗口和隐式空间推理的限制。", "innovation": "Mem4Nav引入了一个层次空间认知的长短时记忆系统，可以增强任何VLN骨干。它融合了一个稀疏八叉树进行精细的体素索引，以及一个语义拓扑图用于高阶地标连接，并将二者存储在可以通过可逆Transformer嵌入的可训练记忆标记中。长期记忆（LTM）压缩并保留了八叉树和图节点的历史观察结果，而短期记忆（STM）则缓存了最近的多模态条目在相对坐标下供实时障碍物避免和局部规划使用。在每次步骤中，STM检索在动态上下文中迅速剪枝，并在需要更深入历史记录时，通过无损解码LTM标记重建过去的嵌入。", "conclusion": "在Touchdown和Map2Seq上，在三个（模块化、基于提示的LLM的最先进的VLN和基于跳跃注意力的MLLM的最先进的VLN）不同的backbone上评估，Mem4Nav在任一代言完成、足够SPD减少和nDTW改善方面分别取得了7-13个百分点的增益。消融实验确认了层次地图和双记忆模块的不可或缺性。我们的代码已开源（链接见原文）。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01428", "html_url": "https://arxiv.org/abs/2507.01428", "title": "DiffMark: 基于扩散模型的抗Deepfake鲁棒水印", "title_en": "DiffMark: Diffusion-based Robust Watermark Against Deepfakes", "authors": "Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li", "background": "深度伪造（Deepfakes）通过恶意的人脸操作，给安全和隐私带来了重大威胁。现有的鲁棒水印方法虽然能够帮助验证图像的真伪并追踪来源，但往往在对抗深度伪造的操纵方面缺乏充分的鲁棒性。扩散模型在图像生成方面表现出色，能够将水印无缝地融合到生成的图像中。因此，提出了基于扩散模型的新颖鲁棒水印框架DiffMark。", "innovation": "DiffMark通过修改训练和采样方案，将面部图像和水印作为条件来指导扩散模型，实现逐步去噪和生成相应的带水印图像。在构建面部条件时，通过一个与时间步相关的加权因子逐渐降低指导强度，以更好地适应扩散模型的采样过程。为了实现水印条件的融合，引入了交叉信息融合（CIF）模块，利用可学习嵌入表来适配地提取水印特征，并通过交叉注意力机制与图像特征结合。通过在训练期间集成冻结的自动编码器，以模拟深度伪造操纵来增强水印的鲁棒性。还引入了针对深度伪造的鲁棒引导，利用特定深度伪造模型逆势影响扩散采样过程，生成更加鲁棒的带水印图像。", "conclusion": "实验结果证明了所提出的DiffMark在典型深度伪造上的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "在极早早产儿的一日胸部X光片上，带渐进层冻结的现场微调：朝从日龄第一天胸部X光片准确预测支气管肺发育不良的方向发展", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "支气管肺发育不良（BPD）是一种影响极低体重早产儿（35%）的慢性肺病，主要标志是在36周胎龄后依赖氧气。预防干预措施伴随着严重的风险，包括神经发育障碍、机械通气引起的肺损伤和全身性并发症。因此，早期识别BPD对于避免低风险婴儿的不必要的毒性至关重要。常规胸部X光片在新生儿出生后的24小时内获得，可以作为非侵入性的预后工具。", "innovation": "开发了基于渐进层冻结和线性探测的深度学习方法，使用了专门为成人胸部X光片预训练的ResNet-50模型，并通过CutMix增强方法提高了BPD预测的准确性。研究表明，领域特定的预训练比ImageNet初始化表现出更好的效果，证明了对BPD预后预测的重要性。常规的肺透明膜病（IRDS）评分在预测BPD方面的值有限，证实了需要学习的标记来提高预测准确性。", "conclusion": "该方法展示了领域特定预训练如何使BPD预测在常规一日胸部X光片中成为可能，通过渐进层冻结和线性探测，该方法保持了计算上的可行性，便于在不同地点实施和未来联邦学习的应用部署。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.18537", "html_url": "https://arxiv.org/abs/2507.18537", "title": "TTS-VAR：视觉自回归生成的测试时缩放框架", "title_en": "TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation", "authors": "Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu", "background": "对于实际内容创作而言，扩展视觉生成模型至关重要，但需要大量的训练和计算资源。相反，测试时的缩放由于资源效率高和有前景的性能，引起了越来越多的关注。当前对于视觉自回归（VAR）模型的测试时缩放框架较为缺乏，尤其是在兼顾计算效率和探索能力的动态平衡方面尚无有效的解决方法。", "innovation": "本文提出了TTS-VAR，这是首个针对视觉自回归生成的通用测试时缩放框架。TTS-VAR将生成过程建模为路径搜索问题，并引入了自适应递减批处理大小表调度，以在因果生成过程中动态平衡计算效率和探索能力。此外，借鉴了VAR的多尺度生成机制，TTS-VAR框架中集成了两个关键组件：粗尺度采用基于聚类的多样性搜索，通过特征语义聚类保留结构多样性；细尺度采用基于重采样的潜力选择，利用多尺度生成历史中定义的潜力得分来优先选择有希望的候选样本。", "conclusion": "在强大的VAR模型Infinity上的实验结果显示，TTS-VAR框架带来了显著的8.7% GenEval得分提升（从0.69到0.75）。通过分析实验结果，可以得出早期阶段的结构特征对最终质量有显著影响，而重采样的有效性则随生成尺度变化而变化。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21888", "html_url": "https://arxiv.org/abs/2507.21888", "title": "CAPE: CLIP-感知的互补热图线索指向集成方法用于具身参考理解", "title_en": "CAPE: A CLIP-Aware Pointing Ensemble of Complementary Heatmap Cues for Embodied Reference Understanding", "authors": "Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel", "background": "论文探讨了具身参考理解问题，即通过手势和语言预测场景中某人所指的物体。准确识别所指物需要多模态理解：结合文本指示、视觉手势和场景上下文。然而，现有方法在利用视觉线索进行消歧时常常表现不佳。此外，我们发现所指物不仅通常与头部到指尖线对齐，偶尔也会与腕部到指尖线更加对齐。因此，依赖单一方向假设过于简化，可能导致性能不佳。", "innovation": "我们提出了一个双模型框架，其中一个模型学习头部到指尖方向，另一个模型学习腕部到指尖方向。我们引入了Gaussian射线热图表示这些线，并使用它们作为强监督信号，促使模型更好地关注手势提示。我们还提出了CLIP-感知的指向集成模块，基于CLIP特征执行混合集成，同时引入了对象中心预测头部作为辅助任务，进一步增强指事物体定位。", "conclusion": "我们通过在基准YouRefIt数据集上进行广泛实验和分析，验证了我们的方法。在0.25 IoU阈值下，我们的方法获得了约4个mAP的提升。此外，我们还在CAESAR和ISL指向数据集上测试了我们的方法，取得了不错的效果。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05698", "html_url": "https://arxiv.org/abs/2507.05698", "title": "在恶劣光照条件下的事件-RGB融合用于航天器姿态估计", "title_en": "Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting", "authors": "Mohsi Jawaid,Marcus Märtens,Tat-Jun Chin", "background": "航天器的姿态估计对于自主在轨操作至关重要，如交会对接和在轨服务。基于视觉的姿态估计方法，通常利用RGB成像传感器，是航天器姿态估计的有效方法，但会在恶劣光照条件下遇到挑战，产生如反光、过曝、溢出和镜头眩光等成像伪影。由于具有更高的动态范围，神经形态或事件传感器在极端光照条件下更加稳健。但事件传感器通常具有较低的空间分辨率，并且在相对运动较小时表现出信噪比降低。因此，本文通过结合RGB和事件传感器，克服了各自传感器的局限性。利用分光棱镜实现光学和时间精确对齐，并开发了一种基于RANSAC的技术来融合RGB和事件通道的信息，利用两种模态的优点。该流水线通过丢弃不确定性的估计来检测影响任一通道的极端条件。在实验室环境下，通过汇集了各种恶劣光照条件的RGB和事件数据，验证了所提出的事件-RGB融合方法的有效性，这进一步支持了事件传感器在航天器姿态估计中的应用。", "innovation": "提出了通过将RGB传感器和事件传感器结合的融合方法来克服各自传感器的局限，利用分光棱镜实现了光学和时间的精确对齐，并开发了一种基于RANSAC的技术来融合RGB和事件通道的信息，还通过丢弃不确定性的估计来检测影响任一通道的极端条件。", "conclusion": "方法在实验室环境下构建的综合RGB和事件数据集上表现出了良好的性能，证明了事件-RGB融合方法的有效性，并进一步支持了事件传感器在航天器姿态估计中的应用。为此主题的研究贡献了公开的数据集。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23278", "html_url": "https://arxiv.org/abs/2507.23278", "title": "UniLIP: 调整CLIP以实现统一多模态理解、生成与编辑", "title_en": "UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing", "authors": "Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang", "background": "虽然CLIP在多模态理解方面表现出色，但它缺乏重构能力，无法作为一个统一的视觉编码器。现有的基于CLIP的统一方法未能在理解能力和重构能力之间取得平衡，从而导致语义退化或不一致的重构。", "innovation": "提出了一个新颖的两阶段训练方案，结合自蒸馏策略，逐步赋予CLIP高保真重构能力，同时保持其初始理解能力。还开发了一种双条件架构，基于MetaQuery框架，用于增强生成和编辑中的推理能力和一致性。这项研究利用先进的图像表示和架构设计，展示了UniLIP在指令执行和编辑保真度方面的优越性。", "conclusion": "UniLIP仅使用1B和3B参数，就超过了更大型的统一模型，如BAGEL（7B）和Uniworld-V1（12B），在GenEval上取得了0.90的成绩，在WISE上取得了0.63的成绩，在ImgEdit上取得了3.94的成绩。这些结果表明，UniLIP成功扩展了CLIP的应用，不仅使其成为理解任务的理想选择，还在生成和编辑任务中实现了高性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07819", "html_url": "https://arxiv.org/abs/2508.07819", "title": "ACD-CLIP: 分解表示与动态融合以实现零样本异常检测", "title_en": "ACD-CLIP: Decoupling Representation and Dynamic Fusion for Zero-Shot Anomaly Detection", "authors": "Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo", "background": "预训练的视觉-语言模型（VLMs）在零样本异常检测（ZSAD）中表现不佳，这是因为它们缺乏用于密集预测的局部归纳偏差，并且使用的特征融合方式过于僵硬。这造成了一个重要的适应缺口。现有的方法难以有效解决这个问题，因此本文提出了一种名为ACD-CLIP的联合架构设计框架，旨在共同精炼特征表示和跨模态融合，以改善模型在密集感知任务中的适应性。", "innovation": "本文创新地提出了一种参数效率高的Conv-LoRA适配器，用于注入细粒度的本地归纳偏差，以及一种动态融合门（DFG），该门可以通过视觉上下文自适应地调整文本提示，从而实现强大的双向融合。这种方法能够有效地解决特征表示和跨模态融合的问题，提升模型在零样本异常检测任务中的准确性和鲁棒性。通过在各种工业和医疗基准上的广泛实验，验证了这种协同设计对于提高基础模型适应性的重要性。", "conclusion": "本文提出的ACD-CLIP方法，通过联合优化特征表示和动态融合，显著提高了零样本异常检测任务中的准确性与鲁棒性。这种方法表明了对基础模型进行精准、协同的架构设计是实现其在密集感知任务中有效应用的关键。源代码已公开。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04379", "html_url": "https://arxiv.org/abs/2508.04379", "title": "VisionTS++: 使用持续预训练视觉骨干的跨模态时间序列基础模型", "title_en": "VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones", "authors": "Lefei Shen,Mouxiang Chen,Xu Liu,Han Fu,Xiaoxue Ren,Jianling Sun,Zhuo Li,Chenghao Liu", "background": "近期研究表明，预先在图像上训练的视觉模型可以作为时间序列基础模型（TSFM）通过将时间序列预测（TSF）重新定义为图像重建来使用。然而，由于三个不一致点——数据模态差距、多元预测差距和概率预测差距——跨模态从视觉到时间序列的有效转移仍具有挑战性。为了弥合这些差距，本文提出了一种基于视觉模型在大规模时间序列上持续预训练的TSFM——VisionTS++。通过这种方式，可以更稳定地进行预训练，同时克服模态差距，将多元时间序列转化为多子图RGB图像以增强跨变量建模，并使用并行重建头部生成无参数假设的分位数预测，以生成具有不确定性和概率预测能力的时间序列预测结果。", "innovation": "VisionTS++通过以下三种关键创新点来填补上述差距：（1）基于视觉模型的筛选来识别高质量序列，以稳定预训练并缓解模态差距；（2）彩色化的多元转换，将多元序列编码为多子图RGB图像，增强跨变量建模；（3）多分位数预测，使用并行重建头部生成无参数假设的分位数预测，而不是依赖参数假设。实验结果表明，VisionTS++在内分布和外分布预测中均达到最佳性能，优于专门的时间序列模型6%到44%的MSE减少幅度，在包括7个领域的23个数据集的GIFT-Eval基准测试中排名第一。这表明，经过适当调整的视觉模型可以有效泛化到时间序列预测，从而推进了通用时间序列基础模型的研究进程。", "conclusion": "本文的工作证明，经过适当调整的视觉模型可以有效地泛化到时间序列预测，从而推进了通用时间序列基础模型的研究进程。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03441", "html_url": "https://arxiv.org/abs/2508.03441", "title": "MedCAL-Bench:医疗影像分析中基于基础模型的冷启动主动学习全面基准", "title_en": "MedCAL-Bench: A Comprehensive Benchmark on Cold-Start Active Learning with Foundation Models for Medical Image Analysis", "authors": "Ning Zhu,Xiaochuan Ma,Shaoting Zhang,Guotai Wang", "background": "冷启动主动学习（CSAL）旨在在缺乏先验知识的情况下选择具有信息量的样本进行标注，这对于在有限标注预算下提高标注效率和模型性能非常重要。现有的大多数CSAL方法依赖于目标数据集的自我监督学习（SSL）进行特征提取，这效率低下且受限于特征表示不足。近年来，预训练的基础模型（FMs）显示出强大的特征提取能力，并具有改进CSAL的潜力。然而，这些研究很少被探索，缺乏对FMs进行CSAL任务比较的基准。因此该研究提出了MedCAL-Bench，这是第一个系统的基础模型驱动的CSAL基准，主要用于医疗影像分析。该基准在7个不同的标注预算下对来自不同医学模态的7个数据集进行了评价，其中包括分类和分割任务。这是首个同时评估特征提取和样本选择阶段的CSAL基准。", "innovation": "提出了MedCAL-Bench，这是第一个系统的基础模型驱动的冷启动主动学习基准，为医疗影像分析中的特征提取和样本选择提供了全面评估。该基准涵盖了分类和分割任务，并在不同数据集上评估了多种样本选择策略和14种预训练基础模型。研究结果显示，大多数基础模型可以有效用于CSAL特征提取，其中DINO家族在分割任务中表现最佳；不同基础模型在分割任务中的表现差异较大，而在分类任务中的差异较小；样本选择策略在不同数据集上的性能也不同，其中ALPS在分割任务中表现最优，而RepDiv在分类任务中表现最优。", "conclusion": "实验结果表明，大部分基础模型在CSAL特征提取方面是有效的，特别是DINO家族在分割任务中的表现最佳；不同基础模型在分割任务中的表现差异较大而在分类任务中差异较小；根据不同数据集选择不同的样本选择策略是重要的，其中ALPS在分割任务中表现最优，RepDiv在分类任务中表现最优。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07979", "html_url": "https://arxiv.org/abs/2509.07979", "title": "视觉表示对齐以增强多模态大型语言模型", "title_en": "Visual Representation Alignment for Multimodal Large Language Models", "authors": "Heeji Yoon,Jaewoo Jung,Junwan Kim,Hyungyu Choi,Heeseong Shin,Sangbeom Lim,Honggyu An,Chaehyun Kim,Jisang Han,Donghyun Kim,Chanho Eom,Sunghwan Hong,Seungryong Kim", "background": "现有的多模态大型语言模型（MLLMs），通过视觉指令调优训练，在各种任务上表现出强大的性能。然而，在以视觉为中心的任务上，如物体计数或空间推理，它们的表现仍然有限。作者将这一差距归因于当前的文本主导监督模式，这种模式仅提供间接的视觉指导，导致MLLMs在训练过程中常常忽略细腻的视觉细节。", "innovation": "本文提出了一种称为VIsual Representation ALignment（VIRAL）的简单而有效的正则化策略，该策略将MLLMs的内部视觉表示与预训练的视觉基础模型（VFMs）的视觉表示进行对齐。通过明确要求这种对齐，VIRAL使模型不仅能够保留输入视觉编码器中的关键视觉细节，而且能够补充VFMs的额外视觉知识，从而增强其在复杂视觉输入上的推理能力。", "conclusion": "在广泛采用的多模态基准测试上，VIRAL在所有任务上都显示出一致的改进。此外，进行了全面的消融研究以验证框架下的关键设计选择。我们认为这个简单的发现为在训练MLLMs时有效集成视觉信息指明了一个重要方向。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09666", "html_url": "https://arxiv.org/abs/2509.09666", "title": "统一多模态模型作为自编码器", "title_en": "Unified Multimodal Model as Auto-Encoder", "authors": "Zhiyuan Yan,Kaiqing Lin,Zongjian Li,Junyan Ye,Hui Han,Zhendong Wang,Hao Liu,Bin Lin,Hao Li,Xue Xu,Xinyan Xiao,Jingdong Wang,Haifeng Wang,Li Yuan", "background": "多模态理解与生成之间的根本分裂长期以来阻碍了统一多模态模型（UMMs）的发展。当前方法通常将它们视为具有不同目标的分离任务，未能充分利用它们之间的互惠作用。", "innovation": "本文提出了一种新的范式，通过自编码器视角，将理解视为编码器（I2T），将生成视为解码器（T2I）。引入了UAE模型，通过预训练解码器来引导其理解详细的文本语义。其次是通过强化学习提出了统一的GRPO，包括两个互补阶段：生成用于理解，增强编码器的视觉感知；理解用于生成，改进解码器的细粒度视觉感知和生成精度。研究表明，理解可以显著增强生成，反之亦然，揭示了生成与理解之间双向提升的深层关系。", "conclusion": "统一重建目标下，生成与理解相互促进，向真正统一的多模态智能迈进。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07552", "html_url": "https://arxiv.org/abs/2509.07552", "title": "PanoLAM: 大型avatar模型用于单张非摆姿势图像的gaussian全头合成", "title_en": "PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image", "authors": "Peng Li,Yisheng He,Yingdong Hu,Yuan Dong,Weihao Yuan,Yuan Liu,Siyu Zhu,Gang Cheng,Zilong Dong,Yike Guo", "background": "现有的研究表明，从单张未摆姿势的图像重构出高质量的3D头部模型通常依赖于时间消耗的生成对抗网络（GAN）反转和测试时间优化。这样的方法在实时渲染和快速重建方面存在局限性。为了克服大规模3D头部资产缺乏的问题，研究者提出了一种利用训练好的3D GAN生成大规模合成数据集的方法，并通过仅使用合成数据来训练模型。为了实现高效的高保真生成，研究人员引入了一种从稀疏点到密集点的Gaussian头部生成流水线，该流水线中稀疏点通过变换层与图像特征进行交互以提取特征和粗略形状重建，然后进一步精细化重建以获得高保真模型。此外，为了充分利用预训练3D GAN中的先验知识以实现有效的重构，研究者提出了一种双分支框架，该框架能够有效地综合结构化的球形三平面特征和非结构化的点基特征，进一步提升Gaussian头部的重建效果", "innovation": "该研究提出了一种新颖的端到端框架，可以从单张未摆姿势的图像高效、快速地重构出Gaussian全头部模型，而无需依赖耗时的GAN反转和测试时间优化步骤。该框架通过生成大规模合成数据集并仅使用合成数据进行训练来解决大规模3D头部资产缺乏的问题。此外，研究引入了一种从稀疏点到密集点的Gaussian头部生成流水线，并使用双分支框架来有效地综合结构化的球形三平面特征和非结构化的点基特征，从而获得高质量的Gaussian头部模型", "conclusion": "实验结果表明，与现有技术相比，该框架在重建质量和生成效率方面表现出更好的性能。该研究提出的方法在单张非摆姿势图像的Gaussian全头合成领域取得了一定的技术突破，可应用于虚拟现实、增强现实等需要高质量头部模型的场景"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA: 多模态物体感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "本文介绍了一种名为MOCHA（多模态物体感知跨架构对齐）的知识蒸馏方法，该方法将大型视觉-语言教师（如LLaVa）的区域级别多模态语义转移到了轻量级的仅视觉目标检测器学生（如YOLO）中。这种方法通过一个翻译模块将学生特征映射到联合空间，并通过一个双目标损失函数进行训练，该损失函数确保局部对齐和全局关系一致性。", "innovation": "MOCHA与先前集中在密集或全局对齐的方法不同，它在物体级别操作，使语义高效转移，无需修改教师或在推理时需要文本输入。该方法在四种个性化检测基准测试中进行了验证，显示出相对于基线的一致性改进，平均提高了10.1分。尽管其架构紧凑，MOCHA仍达到了与更大模型相当的性能，证明其适合实际部署。", "conclusion": "MOCHA在少量样本设置下的四个个性化检测基准测试中显示出一致的性能提升，相较于基线平均提高了10.1分。尽管其架构紧凑，MOCHA的性能仍然与更大模型相当，证明其适合实际部署。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14610", "html_url": "https://arxiv.org/abs/2509.14610", "title": "使用动态跳连接增强U型网络特征融合", "title_en": "Enhancing Feature Fusion of U-like Networks with Dynamic Skip Connections", "authors": "Yue Cao,Quansong He,Kaishen Wang,Jianlong Xiong,Tao He", "background": "U型网络因其通过跳连接在高层语义和低层空间细节之间架起桥梁而成为医学图像分割的基础框架。然而，传统跳连接的特征融合存在两个主要局限性：跨特征约束和内特征约束。跨特征约束意味着传统跳连接中的特征融合具有静态性质，信息沿固定路径传输，不受特征内容的影响。内特征约束源于对多尺度特征交互的建模不足，阻碍了对全局上下文信息的有效聚合。", "innovation": "本文提出了一种新型的动态跳连接（DSC）块，通过自适应机制从根本上增强了跨层连接，从而克服了传统跳连接的局限性。DSC块集成了两个互补的组件：（1）测试时训练（TTT）模块，该模块通过在推理过程中动态调整隐藏表示来解决跨特征约束，促进内容感知特征精炼；（2）动态多尺度核（DMSK）模块，该模块基于全局上下文线索自适应选择核大小，增强网络的多尺度特征整合能力。DSC块具有架构无关性，可以无缝集成到现有的U型网络结构中。", "conclusion": "广泛的实验证明了所提出的DSC块在基于CNN、基于Transformer、混合CNN-Transformer和基于Mamba的U型网络中的即插即用有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.10026", "html_url": "https://arxiv.org/abs/2509.10026", "title": "LaV-CoT: 一种针对实际多语言VQA的语言意识视觉CoT及其多方面奖励优化", "title_en": "LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA", "authors": "Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Joey Tianyi Zhou,Changtao Miao,Huazhe Tan,Weibin Yao,Jianshu Li", "background": "随着大型视觉语言模型（VLMs）的发展，它们在多语言视觉问答（mVQA）方面的表现显著提高。链式推理（CoT）已被证明可以增强解释性和复杂的推理能力，但大多数现有方法主要依赖于文本CoT，对多模态多语言推理的支持有限，限制了其实用应用的部署。\n", "innovation": "我们提出了一种名为LaV-CoT的新框架，它集成了一个具有多阶段推理的可解释的管道，包括文本摘要和边界框、语言识别、空间对象级描述和逐步逻辑推理。我们还为高质量和可扩展的训练数据开发了一种自动数据整理方法。此外，LaV-CoT采用了监督微调（SFT）与语言感知分组相对策略优化（GRPO）相结合的双阶段训练框架，使用可验证的多方面奖励，如语言一致性、结构准确性、语义对齐来指导这一过程。\n", "conclusion": "在公共数据集MMMB、多语言MMBench和MTVQA上的广泛评估表明，与相似规模的开源基线相比，LaV-CoT实现了约9.5％的准确率提升，甚至超过规模更大的模型约2.6％。此外，LaV-CoT在GPT-4o-0513和Gemini-2.5-flash等先进专有模型上也表现出优越性。进一步的在线A/B测试验证了该方法在实际数据中的有效性，证实其适合工业部署。这项研究的代码已公开发布。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11442", "html_url": "https://arxiv.org/abs/2509.11442", "title": "MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder", "title_en": "MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder", "authors": "Ayhan Can Erdur,Christian Beischl,Daniel Scholz,Jiazhen Pan,Benedikt Wiestler,Daniel Rueckert,Jan C Peeken", "background": "在医疗成像数据中，缺失输入序列是一个常见的问题，这对依赖完整输入数据的深度学习模型构成了挑战。现有的方法可能无法有效地处理这些缺失数据，影响了模型的表现和可靠性。该论文受到MultiMAE [2]的启发，提出了一种使用掩码自编码器（MAE）来处理3D医学影像中脑MRI的多模态多任务学习的方法。该方法通过一种晚融合风格的变压器编码器整合了多序列信息，并为每个模态设置了独立的解码器流，以实现多任务重建。这种方法旨在引导模型学习丰富的模态表示，并能够通过跨序列推理处理缺失的输入数据，从而提供一种灵活且通用的编码器，可以推断出从可用输入中得出的缺失序列，并适应多种下游应用。研究表明，该方法在缺失输入序列的下游分割和分类任务中，绝对提高了10.1的Dice分数和0.46的MCC，从而提高了模型的鲁棒性。实验结果证明了该预训练策略的有效性，并且开源实现证明了其实用性。", "innovation": "该方法借鉴了MultiMAE [2]的方法，提出了一种针对脑MRI的多模态掩码自编码器（MAE）架构，用于处理多模态数据并实现多任务学习。具体创新点包括：1）每个MRI序列被视为独立的输入模态，通过晚融合式的变压器编码器集成多序列信息；2）为每个模态设置独立的解码器流，实现多任务重建；3）通过跨序列推理引导模型学习模态丰富的表示，从而处理缺失的输入数据。这种方法改进了在缺失输入序列情况下的鲁棒性和性能。", "conclusion": "研究表明，所提出的方法在脑MRI的预训练策略中表现出色，特别是在缺失输入序列的下游分割和分类任务中，相比MAE-ViT基线，绝对提高了10.1的Dice分数和0.46的MCC。实验验证了该策略的有效性，并证明了所提出的模型在多种下游应用中的适应性和鲁棒性。开源实现也证明了其实用性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.19644", "html_url": "https://arxiv.org/abs/2509.19644", "title": "4D雷达成像对2D分割骨干网在点云预测中的影响", "title_en": "The Impact of 2D Segmentation Backbones on Point Cloud Predictions Using 4D Radar", "authors": "William Muckelroy III,Mohammed Alsakabi,John Dolan,Ozan Tonguz", "background": "激光雷达通过生成高密度、精细的点云，提供周围环境的精准感知，增强场景的理解和感知能力，改善道路安全性。然而，激光雷达的成本限制了其在商业车辆中高级自主驾驶系统的广泛应用。已有研究表明，使用激光雷达点云作为真实值训练神经网络，可以使用4D雷达生成类似的激光雷达点云。在这些研究中，通过使用模组化2D卷积神经网络（CNN）和核心时空连贯网络，实现了一种更高效的雷达目标检测器。本研究旨在探讨更高容量的分割骨干网络在生成高质量点云方面的效果影响。研究表明，虽然非常高容量的模型可能会损害性能，但适当选用的分割骨干网络可以在不高于当前最先进的技术12%的性能差距下提供显著改进，实现23.7%的提升。", "innovation": "该研究的具体创新在于，通过实验探究了不同容量的2D分割骨干网络对基于4D雷达生成点云质量的影响，并发现存在一个最优模型容量可以显著提高预测质量，为在不需要高成本激光雷达的情况下实现高级自动驾驶提供了新思路。", "conclusion": "研究表明，虽然非常高容量的模型可能会降低性能，但选择适当的分割骨干网络可以显著提高点云生成的质量。最优的分割网络比最先进的技术（SOTA）提高了23.7%的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25776", "html_url": "https://arxiv.org/abs/2509.25776", "title": "Noise图反转：将目标图像编码进噪声实现高保真图像操控", "title_en": "Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation", "authors": "Mingyu Kang,Yong Suk Choi", "background": "文本到图像的扩散模型在生成高质量和多样性的图像方面取得了显著的成功。基于这些进展，扩散模型也在文本指导的图像编辑方面展示了出色的性能。有效的图像编辑策略是将源图像反转为与目标图像相关的可编辑噪声图。然而，以前的反转方法在紧密遵循目标文本提示方面面临挑战。这是因为虽然反转的噪声图能够忠实地重构源图像，但它们限制了所需编辑的灵活性。", "innovation": "我们提出了一种称为Editable Noise Map Inversion（ENM Inversion）的新颖反转技术，该技术旨在寻找最优噪声图，以确保内容保持和编辑能力。基于对噪声图性质的分析，我们的方法引入了一种可编辑噪声优化，通过最小化重构和编辑后的噪声图之间的差异，使其更符合预期的编辑。广泛的实验证明，ENM Inversion在多种图像编辑任务中具有更高的保真度和编辑准确性，领先于现有方法，并且该方法还可以轻松应用于视频编辑，实现帧间的时空一致性。", "conclusion": "ENM Inversion方法在图像和视频编辑任务中表现出色，能够保持和适应目标提示下的内容及编辑，为高保真图像操控提供了有效的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26360", "html_url": "https://arxiv.org/abs/2509.26360", "title": "TimeScope: 向向任务导向的长视频时间定位", "title_en": "TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos", "authors": "Xiangrui Liu,Minghao Qin,Yan Shu,Zhengyang Liang,Yang Tian,Chen Jason Zhang,Bo Zhao,Zheng Liu", "background": "在长视频中识别关键时刻对于下游理解和推理任务至关重要。传统方法由于其有限的通用性和处理长视频的难度，难以应对这一挑战。", "innovation": "提出了一个新的问题，任务导向的时间定位（Task-oriented Temporal Grounding，ToTG），旨在基于任务的自然描述定位包含必要信息的时间区间。为评估这一新的挑战性问题的性能，提出了ToTG Bench基准。此外，设计了TimeScope框架，基于逐步推理来解决这一问题，首先粗略定位可能包含关键时刻的时间范围，然后通过细粒度的时刻划分进行细化。为增强TimeScope的能力，还构建了一个高质量的数据集ToTG Pile。", "conclusion": "广泛的实验表明，TimeScope在各种设置下都优于现有的时间定位方法和流行的MLLMs，突显了其在解决这一新挑战性问题方面的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21787", "html_url": "https://arxiv.org/abs/2509.21787", "title": "DeHate：基于稳定扩散的多模态方法以减少图像中的仇恨言论", "title_en": "DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images", "authors": "Dwip Dalal,Gautam Vashishtha,Anku Rani,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal", "background": "近年来，有害在线内容的增加不仅扭曲了公共舆论，还给维护健康的数字环境带来了重大挑战。为应对这一挑战，本文介绍了一个专门为识别数字内容中的仇恨言论设计的多模态数据集。该数据集结合了基于水印、稳定增强的稳定扩散技术与数字注意力分析模块（DAAM），能够精确定位图像中的仇恨元素，生成详细的仇恨注意力图，并使用这些图来模糊这些区域，从而移除图像中的仇恨部分。此外，本文还介绍了与数据集一起发布的脱敏任务（dehate shared task）。", "innovation": "本文的核心创新在于结合了水印稳定增强的稳定扩散技术和数字注意力分析模块（DAAM），专门用于识别和移除图像中的仇恨言论。通过这种方法，可以更准确地定位和处理仇恨言论，并提供详细的仇恨注意力图来实现更精细的处理。本文同时提出了一个针对多模态去仇恨化的视觉语言模型DeHater，该模型在基于文本提示的图像仇恨言论检测方面表现卓越，为更加伦理的社交媒体AI应用的发展做出了贡献。", "conclusion": "本文介绍了一个旨在减少有害在线内容的数据集和一种视觉语言模型DeHater，通过结合水印稳定增强的稳定扩散技术和数字注意力分析模块，可以高效地识别并处理图像中的仇恨言论。该方法不仅助力于维护健康、伦理的数字环境，也为未来的社交媒体AI应用提供了新的标准和思路。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21979", "html_url": "https://arxiv.org/abs/2509.21979", "title": "在医疗视觉语言模型中基准测试并缓解奉承行为", "title_en": "Benchmarking and Mitigate Sycophancy in Medical Vision-Language Models", "authors": "Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu", "background": "视觉语言模型（VLMs）在临床工作中越来越普遍，但它们经常表现出一种讨好行为，优先考虑与用户的语言和社交暗示或权威对齐，而不是基于证据的推理。本文通过一个新颖的与临床实践紧密结合的基准测试，评估医学领域的映像问题回答中的这种奉承行为。", "innovation": "提出了一种医疗奉承数据集，从PathVQA、SLAKE和VQA-RAD等来源构建，根据不同器官系统和成像方式分层。使用包含各种讨好元素的具有心理动机的压力模板进行对抗性实验，发现这些模型广泛易受影响，对抗性响应的发生变化与模型准确度或大小之间并无显著关联。模仿和专家提供的纠正被认为是阻止或缓解模型奉承行为的最有效策略之一，表明模型在视觉证据之外可能拥有偏见机制。此外，提出了视觉信息净化用于证据驱动响应（VIPER），这是一种轻量级的缓解策略，通过过滤非证据性内容，例如社会压力，然后生成受限的证据先行答案，减少了模型的奉承行为并优于基准线，同时保持可解释性。", "conclusion": "基准测试分析及缓解框架为在真实世界临床互动中稳健部署医疗VLM奠定了基础，强调了需要基于证据的防御措施。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15886", "html_url": "https://arxiv.org/abs/2509.15886", "title": "RangeSAM：利用视觉基础模型进行范围视图表示的LiDAR分割", "title_en": "RangeSAM: Leveraging Visual Foundation Models for Range-View repesented LiDAR segmentation", "authors": "Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Dieter Fellner,Saptarshi Neil Sinha", "background": "点云分割是自动驾驶和3D场景理解的关键。尽管体素和基于点的方法因其与深度架构的兼容性和对精细几何形状的捕捉能力而占据主导地位，但它们往往会产生较高的计算成本、不规则的内存访问和有限的实时效率。相比之下，范围视图方法虽然相对未被充分探索，但能够利用成熟的2D语义分割技术进行快速准确的预测。受到视觉基础模型（VFMs）在视觉描述、零样本识别和多模态任务中快速发展的启发，本文探讨了当前最先进的用于分割任务的SAM2能否作为LiDAR点云分割的坚实基础。本文介绍了一种新的范围视图框架，将SAM2适应于3D分割，结合高效的2D特征提取与标准的投影/反投影操作应用于点云。为了使SAM2适用于范围视图表示，对编码器实施了若干架构修改：（1）一种新的模块，强调LiDAR距离图像中固有的水平空间依赖性；（2）一种定制的配置，针对球面投影的几何属性；（3）编码器骨干网络中的适应机制，以捕捉范围视图伪图像中独特的空间模式和不连续性。我们方法在SemanticKITTI上取得了竞争力的性能，同时也受益于2D为中心的管道的高速、可扩展性和部署简便性。", "innovation": "本文提出了一种新的范围视图框架，将当前最先进的视觉基础模型SAM2适应于3D分割，结合高效的2D特征提取与标准的投影/反投影操作应用于点云。对编码器实施了多项架构修改，包括强调水平空间依赖性的模块、针对球面投影几何属性的配置，以及适应机制，以捕捉范围视图伪图像中独特的空间模式和不连续性。这种方法既提高了准确性，又保持了高速和部署简便的优点。", "conclusion": "本文所提出的方法在SemanticKITTI上取得了竞争力的性能，同时受益于2D为中心的管道的高速、可扩展性和部署简便性。这一工作展示了VFMs作为3D感知通用基础模型的可行性，并为基于统一、基础模型驱动的LiDAR分割提供了路径。结果显示，使用VFMs的范围视图分割方法具有前景。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02912", "html_url": "https://arxiv.org/abs/2510.02912", "title": "不要仅仅追逐‘高亮的视觉令牌’在MLLMs中：重访视觉整体上下文保留", "title_en": "Don't Just Chase \"Highlighted Tokens\" in MLLMs: Revisiting Visual Holistic Context Retention", "authors": "Xin Zou,Di Lu,Yizhou Wang,Yibo Yan,Yuanhuiyi Lyu,Xu Zheng,Linfeng Zhang,Xuming Hu", "background": "尽管多模态大型语言模型（MLLMs）具有强大的能力，但由于依赖于大量的视觉令牌，它们面临着严重的计算开销问题。近期的研究探索了通过文本-视觉交叉注意或[CLS]注意力来评估并丢弃冗余视觉令牌的方法以减少这一问题。然而，当前的方法通常倾向于保留语义相似的令牌，这在高剪枝比例下会导致显著的性能下降。", "innovation": "本文提出了一个简单而有效的可插拔视觉令牌剪枝框架{HoloV}，以提高准确性和效率的权衡。与之前的注意力优先方案不同，HoloV 从全局视角重新考虑令牌保留策略。通过适应性地在不同的空间裁剪中分配剪枝预算，HoloV 确保保留的令牌能够捕捉全局视觉上下文，而不是孤立的显著特征。这种策略减少了表征崩溃并即使在严苛的剪枝下也保持了任务相关的信息。", "conclusion": "实验结果表明，HoloV 在各种任务、MLLM 架构和剪枝比例上相比当前最优方法能够实现更优的性能。例如，配有 HoloV 的 LLaVA1.5 在剪枝掉 88.9% 的视觉令牌后，仍然保留了 95.8% 的原始性能，从而实现了更佳的效率-准确性的权衡。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04243", "html_url": "https://arxiv.org/abs/2510.04243", "title": "CARE肝脏任务挑战2025的第一解决方案：对比增强半监督分割与域泛化及测试时自适应", "title_en": "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation", "authors": "Jincan Lou,Jingkun Chen,Haoquan Li,Hang Li,Wenjian Huang,Weihua Chen,Fan Wang,Jianguo Zhang", "background": "准确的肝脏分割对于诊断、治疗规划和疾病监测至关重要，但由于标注数据有限、增强协议的异质性以及不同扫描器和医疗机构之间的显著领域迁移，这仍是一个挑战。传统的图像到图像转换框架在领域泛化方面取得了进展，但其应用并不直接。例如，Pix2Pix需要图像注册，而cycle-GAN无法无缝集成到分割管道中。同时，这些方法原本用于解决跨模态场景，常引入结构变形，且训练不稳定，这可能不利于单一模态场景。", "innovation": "我们提出了一种名为CoSSeg-TTA的紧凑分割框架，基于nnU-Netv2，并通过半监督的均值教师方案提高了未标注体积的数量。引入了一个域适应模块，该模块结合了随机直方图基风格外观转移函数和可训练的对比度感知网络，以丰富领域多样性并减轻跨中心差异性。我们还采用了一种持续的测试时自适应策略来提高推理时的鲁棒性。实验结果表明，我们的框架在Dice分数和Hausdorff距离上优于nnU-Netv2基线，表现出强大的在低注释条件下向未见域的泛化能力。", "conclusion": "我们的框架在未见域条件下的一致性能优于基线nnU-Netv2，同时在Dice分数和Hausdorff距离方面表现出优越性，证实了其在单模态场景中的稳健性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05752", "html_url": "https://arxiv.org/abs/2510.05752", "title": "ALISE: 无标注的LiDAR实例分割用于自动驾驶", "title_en": "ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving", "authors": "Yongxuan Lyu,Guangfeng Jiang,Hongsi Liu,Jun Liu", "background": "手动标注室外LiDAR点云以进行实例分割非常昂贵且耗时，目前的方法试图减轻这种负担但仍依赖某种形式的人工标注。完全消除这种依赖性是非常具有挑战性的。", "innovation": "引入了ALISE，一种无需任何注释即可执行LiDAR实例分割的新型框架。该方法包括利用Vision Foundation Models（VFMs）生成初步的伪标签，通过专门的时空投票模块进行细化，结合2D和3D语义进行离线和在线优化。引入了两种形式的语义监督：2D先验损失用于将视觉知识注入到3D网络中，以及一种新型的基于原型的对比损失，用于构建具有3D语义一致性的辨别特征空间。", "conclusion": "这种综合设计取得了显著的性能提升，建立了无监督3D实例分割的新基准。甚至在mAP方面，我们的方法比使用真实2D边界框监督的MWSIS方法高出2.53%（50.95% vs. 48.42%）"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06509", "html_url": "https://arxiv.org/abs/2510.06509", "title": "从字幕到关键帧：KeyScore多模态帧评分及视频-语言理解", "title_en": "From Captions to Keyframes: KeyScore for Multimodal Frame Scoring and Video-Language Understanding", "authors": "Shih-Yao Lin,Sibendu Paul,Caren Chen", "background": "高效的视频理解依赖于关键帧的选择，而现有方法大多依赖于启发式算法、忽略了语义信息或生成冗余帧。这对视频理解的效率和准确性产生了一定影响。", "innovation": "本文提出了一种称为KeyScore的方法，它结合了语义相似度、时间代表性及上下文消失影响三个互补信号，以提高帧的重要评分。此外，还提出了一种Spatio-Temporal Adaptive Clustering方法（STACFP），在长时间视频中生成多样且紧凑的帧提议。这种方法能够在减少无信息帧的同时保留关键内容，实现更快更准确的推理。", "conclusion": "本文方法在三个标准视频-语言基准数据集（MSRVTT，MSVD，DiDeMo）上进行实验，与全帧处理相比，通过使用STACFP和KeyScore最多可以减少99%的帧数量。同时在视频-文本检索、关键帧提取以及动作识别任务上超过了均匀8帧编码器，在效率和性能方面双重提升，使得可扩展和基于字幕的视频理解成为可能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08054", "html_url": "https://arxiv.org/abs/2510.08054", "title": "RetouchLLM：基于视觉语言模型的无需训练代码化图像修图", "title_en": "RetouchLLM: Training-free Code-based Image Retouching with Vision Language Models", "authors": "Moon Ye-Bin,Roy Miles,Tae-Hyun Oh,Ismail Elezi,Jiankang Deng", "background": "图像修图不仅可以提升视觉效果，还能表达个人偏好和情感。然而，现有的基于学习的方法需要大量配对数据，并且像黑盒子一样操作，导致修图过程不透明，限制了其适应性以处理多样性和用户或图像特定的调整。", "innovation": "提出了一个无需训练的白盒图像修图系统RetouchLLM，不需要训练数据，直接对高分辨率图像进行可解释的、基于代码的修图。该框架逐步增强图像，类似于人类多步骤修图的方式，允许探索不同的调整路径。它包括两个主要模块：一个视觉批评家识别输入和参考图像之间的差异，以及一个代码生成器生成可执行代码。", "conclusion": "实验表明，该方法在多种修图风格上表现出良好的通用性，基于自然语言的用户交互使得调整过程可解释且可控，满足用户意图。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06582", "html_url": "https://arxiv.org/abs/2510.06582", "title": "通过LiDAR视角：一种特征丰富且具有不确定性意识的点云标注流水线", "title_en": "Through the Perspective of LiDAR: A Feature-Enriched and Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud Segmentation", "authors": "Fei Zhang,Rob Chancia,Josie Clapp,Amirhossein Hassanzadeh,Dimah Dera,Richard MacKenzie,Jan van Aardt", "background": "现有的地基激光扫描（TLS）点云语义分割依赖于昂贵的手动注释，这限制了其效率和准确性。", "innovation": "本文提出了一种半自动、具有不确定性的流水线，结合球面投影、特征丰富、集成学习和目标注释，减少标注努力的同时保持高精度。该方法通过球面投影3D点到2D网格，加入多源特征并训练多个分割网络生成伪标签和不确定性图，从而指导对不清晰区域的标注。通过这种方式，生成了Mangrove3D数据集，用于红树林森林的语义分割，并通过实验探讨了数据效率和特征重要性。", "conclusion": "实验结果表明，性能在约12个标注扫描后达到饱和，几何特征贡献最大，紧凑的九通道堆栈捕捉了几乎所有区分能力，平均交并比（mIoU）在约0.76附近达到平台。此外，特征丰富策略在ForestSemantic和Semantic3D数据集上的交叉验证表明了其一般性。主要贡献包括：(i)一种稳健且具有不确定性意识的TLS标注流水线及其可视化工具；(ii)构建了Mangrove3D数据集；(iii)基于实验的数据效率和特征重要性指导，有助于实现TLS点云的可扩展且高质量的语义分割，在生态监测等领域具有广泛的应用价值。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08278", "html_url": "https://arxiv.org/abs/2510.08278", "title": "一种多模态深度感知方法在实体参照理解中的应用", "title_en": "A Multimodal Depth-Aware Method For Embodied Reference Understanding", "authors": "Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel", "background": "实体参照理解要求根据语言指令和指示动作在视觉场景中识别目标物体。以往的研究已经在开放词汇物体检测方面取得了一定的进步，但在存在多个候选物体的歧义场景中，常常无法正确识别目标对象。", "innovation": "本文提出了一种新颖的实体参照理解（ERU）框架，该框架结合了基于大规模语言模型的数据增强、深度图模态以及深度感知决策模块。这种设计能够有效整合语言和实体的线索，从而在复杂的或拥挤的环境中更好地进行歧义消解。", "conclusion": "在两个数据集上的实验结果表明，本文的方法显著优于现有基线，实现了更准确和可靠的指代检测。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08273", "html_url": "https://arxiv.org/abs/2510.08273", "title": "两石一鸟：一种基于无文本无频段感知的扩散模型用于文本引导的图像修复", "title_en": "One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting", "authors": "Haipeng Liu,Yang Wang,Meng Wang", "background": "文本引导的图像修复旨在根据文本提示重建被遮罩的区域，长期面临的挑战是在保留未遮罩区域的同时，实现未遮罩和被修复区域的语义一致性。以往的研究未能同时解决这两个问题，通常只能解决其中之一。我们观察到，这一问题源于编码不同图像属性的混合（例如中低频）频带的交织，这些频带在去噪过程中对文本提示表现出不同的鲁棒性。因此，本文提出了一个基于无频段感知的扩散模型，命名为NTN-Diff，通过将语义一致性分解为每个频带的一致性，并保留未遮罩区域来解决这两个挑战。", "innovation": "提出了一个无频段感知的扩散模型（NTN-Diff），该模型通过将语义一致性分解为每个频带的一致性，同时分离出中低频带，来逐步解决文本引导图像修复中的两个挑战。模型将去噪过程分为早期（高噪声级别）和晚期（低噪声级别）阶段，从而在文本引导的去噪过程中逐步去噪稳定的中频带，以实现语义对齐，并通过逐步的文本指导去噪过程来确保中低频带在遮罩和未遮罩区域之间的语义一致性，同时保留未遮罩区域。", "conclusion": "大量实验验证了NTN-Diff在文本引导的扩散模型中的优越性。我们的代码可以从提供的链接访问。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07791", "html_url": "https://arxiv.org/abs/2510.07791", "title": "GTR-Bench: 评估视觉语言模型中的地理时空推理", "title_en": "GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models", "authors": "Qinghongbing Xie,Zhaoyuan Xia,Feng Zhu,Lijun Gong,Ziyue Li,Rui Zhao,Long Zeng", "background": "近年来，视觉-语言模型（VLMs）的空间-时间智能引起了广泛关注，这对自主驾驶、嵌入式人工智能和通用人工智能都非常重要。现有的空间-时间基准主要侧重于以自我为中心的视角推理（使用图像/视频上下文）或地理视角推理（使用图形上下文，例如地图），但未能评估VLMs在图像/视频和图形上下文中处理地理空间-时间智能的能力，这对于交通管理和应急响应等领域至关重要。为了弥补这些差距，提出了Geo-Temporal Reasoning基准（GTR-Bench），这是一个针对大规模相机网络中移动目标的地理时空推理的新挑战。GTR-Bench由于需要在地图和视频之间多次视角切换、在多个无重叠视野的视频之间进行联合推理以及进行在任何视频上下文中未观察到的空间-时间区域的推理，因而更具挑战性。", "innovation": "提出了Geo-Temporal Reasoning基准（GTR-Bench），要求在大规模相机网络中进行移动目标的地理时空推理，并引入了多视角切换、跨多个视频的联合推理以及推理未被任何视频上下文观测到的空间-时间区域的新挑战。评估结果表明，尽管现有的VLMs在地理时空推理上表现不佳，最好的自定义模型Gemini-2.5-Pro（34.9%）仍落后于人类表现（78.61%）。此外，对GTR-Bench的全面分析揭示了当前模型在地理时空推理中的三大主要缺陷：空间-时间上下文利用不平衡、不擅长时间预测、缺乏将地图数据与多视图视频输入对齐的能力。", "conclusion": "GTR-Bench为地理时空推理提供了有价值的见解，并为时空智能的研究和应用开辟了新的机会。基准和代码将在此链接中发布：this https URL."}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08279", "html_url": "https://arxiv.org/abs/2510.08279", "title": "学习神经曝光场进行视图合成", "title_en": "Learning Neural Exposure Fields for View Synthesis", "authors": "Michael Niemeyer,Fabian Manhardt,Marie-Julie Rakotosaona,Michael Oechsle,Christina Tsalicoglou,Keisuke Tateno,Jonathan T. Barron,Federico Tombari", "background": "近年来，神经场景表示的最新进展使得3D重建和视图合成的质量达到了前所未有的水平。然而，这些高质量的结果通常仅适用于具有精心策划数据的标准基准测试，而对于包含图像间变化的数据（如强烈的曝光变化）表现较差，这种情况在大多数包含室内和室外区域或带有窗户的房间场景中最为常见。", "innovation": "本文介绍了新型的神经曝光场（NExF），一种从挑战性的现实世界捕捉中稳健地重建高质量且3D一致外观的3D场景的新技术。本文的核心在于提出了一种神经场预测每个3D点的最佳曝光值的方法，使得能够在神经场景表示的同时优化曝光。这种3D优化的方法能够准确地在高动态范围场景中进行视图合成，避免了后续处理步骤或多次曝光捕捉的需要。", "conclusion": "本文的主要贡献包括一种新颖的神经表示方法用于曝光预测、一个新的系统通过新颖的神经调节机制联合优化场景表示和曝光场、以及在几种基准测试中实现了优于先前方法的结果，性能提高了超过55%。同时，相比于之前的工作，我们的方法具有更快的训练速度。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.15295", "html_url": "https://arxiv.org/abs/2411.15295", "title": "基于频率引导后验采样的扩散模型图像恢复方法", "title_en": "Frequency-Guided Posterior Sampling for Diffusion-Based Image Restoration", "authors": "Darshan Thaker,Abhishek Goyal,René Vidal", "background": "图像恢复旨在从降级观测中恢复高质量的图片。已知降级过程时，恢复问题可以转化为逆问题，通过贝叶斯方法，目标是在给定降级观测的情况下采样出清晰的重建结果。近年来，使用现代预训练的扩散模型进行图像恢复成为一种思路，但这类方法往往依赖某些近似推断，可能导致显著错误和样本质量下降。本文对线性逆问题下的近似误差进行了首次严谨分析，证明了以往工作在某些情况下会出现重大失败，为解决这一问题提供了理论依据。", "innovation": "提出了一种简单的对现有基于扩散的图像恢复方法的修改方案，引入了时间变化的低通滤波器，在测量的频域中逐步恢复高频率成分，并基于底层数据分布开发了一种自适应课程学习频率安排。该方法在具有挑战性的图像恢复任务中取得了显著的性能改进，包括运动模糊和图像去雾，且减少了以往方法的近似误差问题。", "conclusion": "本文通过理论分析揭示了线性逆问题中扩散模型近似推断的局限性，并提出了一种改进的方案，显著提升了在图像运动模糊和去雾等任务上的恢复性能，解决了近似误差问题。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14326", "html_url": "https://arxiv.org/abs/2412.14326", "title": "免费协方差：利用均值分布进行免训练联邦学习", "title_en": "Covariances for Free: Exploiting Mean Distributions for Training-free Federated Learning", "authors": "Dipam Goswami,Simone Magistri,Kai Wang,Bartłomiej Twardowski,Andrew D. Bagdanov,Joost van de Weijer", "background": "使用预训练模型可以减少数据异质性的影响并加快联邦学习算法的速度。最近的工作探索了利用第一和第二阶统计数据在服务器端聚合客户端数据分布的无训练方法，以不进行训练的情况下实现高性能。尽管如此，这些方法大多集中于利用第二阶统计数据来实现较好的性能，这产生了较大的通信开销。因此，本文提出了一种仅使用第一阶统计数据（类均值）来估计无偏类协方差矩阵并初始化全局分类器的无训练方法，以此利用协方差来进行建模，而不实际分享它们。并且本文证明了仅使用类内协方差进行初始化会得到更好的分类器效果。", "innovation": "本文提出了一种新的方法，不共享第二阶统计数据，而是仅使用第一阶统计数据（类均值）来估计类协方差矩阵，以此初始化全局分类器。与共享仅类均值的方法相比，该方法的性能提升了4-26%，且通信成本相同。本文方法比联邦提示调优方法更为通信效率高，并且性能更优。将本文方法初始化分类器后，再进行联邦微调或线性探测，也能够表现出更好的性能。", "conclusion": "本文提出的方法在不共享协方差的情况下提供了提升性能的方法，且具有更低的通信开销，相较于仅分享类均值的方法性能提升了4-26%，与分享第二阶统计数据的方法相比性能更优且通信开销显著减少。这种方法在聚合本地客户端数据的分布时不需要训练，能够使得模型更快地达到较好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.14229", "html_url": "https://arxiv.org/abs/2503.14229", "title": "HA-VLN 2.0: An Open Benchmark and Leaderboard for Human-Aware Navigation in Discrete and Continuous Environments with Dynamic Multi-Human Interactions", "title_en": "HA-VLN 2.0: An Open Benchmark and Leaderboard for Human-Aware Navigation in Discrete and Continuous Environments with Dynamic Multi-Human Interactions", "authors": "Yifei Dong,Fengyi Wu,Qi He,Zhi-Qi Cheng,Heng Li,Minghan Li,Zebang Cheng,Yuxuan Zhou,Jingdong Sun,Qi Dai,Alexander G Hauptmann", "background": "VLN（视觉-语言导航）研究主要集中在离散或连续环境中，但较少关注动态、拥挤环境。现有的VLN数据集和模拟器对人类动态和多个人交互的建模不足，缺乏对人类空间意识的关注。", "innovation": "HA-VLN 2.0引入了一个统一的基准库，包含：(i) 标准化任务和评估指标，涵盖目标准确性和个人空间遵从性；(ii) HAPS 2.0数据集和模拟器，能够模拟多人类交互、户外情境以及语言与动作更精细的对齐；(iii) 在16,844条社会依存指令上的评估结果，展示了在人类动态和部分可观测性下领先代理的显著性能下降；(iv) 实际机器人实验验证模拟到现实的转移，设置了公开排行榜以确保比较透明。", "conclusion": "明确定义的社会建模提高了导航的鲁棒性和碰撞减少率，突显了以人类为中心的方法的必要性。通过提供数据集、模拟器、基线和协议，HA-VLN 2.0为安全、社会负责的导航研究提供了坚实的基础。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22697", "html_url": "https://arxiv.org/abs/2503.22697", "title": "Brain2Text 解码模型揭示视觉语义处理的神经机制", "title_en": "Brain2Text Decoding Model Reveals the Neural Mechanisms of Visual Semantic Processing", "authors": "Feihan Feng,Jingxin Nie", "background": "神经科学和人工智能领域中，从神经活动解码感官体验，重建人类感知的视觉刺激和语义内容仍然是一项挑战。尽管当前的脑解码模型取得了显著的进展，但它们系统地整合现有神经科学理论，并探索其背后的神经机制方面仍然存在关键差距。", "innovation": "提出了一种新型框架，可以直接将 fMRI 信号解码为视自然图像的文本描述。该新型深度学习模型在没有视觉信息的情况下训练，实现了最先进的语义解码性能，能生成具有意义的描述，捕捉复杂场景的核心语义内容。神经解剖学分析揭示了更高层次视觉皮层（包括MT+复合结构、腹侧流视觉皮层和下顶皮层）在视觉语义处理中的关键作用，类别特异性分析还展示了对语义维度如有生命和运动的特定神经表示。", "conclusion": "提供了一种更直接且可解释的框架来进行大脑语义解码，为探讨复杂语义处理的神经基础、改进分布式语义网络的理解以及开发类脑语言模型提供了强大的新方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05684", "html_url": "https://arxiv.org/abs/2504.05684", "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis", "title_en": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis", "authors": "Tri Ton,Ji Woo Hong,Chang D. Yoo", "background": "现有的视频到音频合成方法在高质量和时间上的一致性方面存在局限性。研究人员希望通过引入新的框架来改进这一领域，特别是在流动基于的变压器等建立在稳定训练和连续变换基础上的方法上，以提高同步性和音频质量。", "innovation": "TARO框架包括两个关键创新：(1)时间步长自适应表示对齐（TRA），通过根据噪声计划调整对齐强度动态调整潜在表示，确保平滑演化和提高保真度；(2)起始意识条件（OAC），它将起始提示整合为尖锐的事件驱动的音频相关视觉时刻标记，以增强与动态视觉事件的同步性。", "conclusion": "TARO在VGGSound和Landscape数据集上的实验结果优于先前的方法，实现了相对较低的53%的Frechet距离（FD），29%的Frechet音频距离（FAD），以及97.19%的对齐精度，突显了其优异的音频质量和同步精度。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04831", "html_url": "https://arxiv.org/abs/2504.04831", "title": "SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes", "title_en": "SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes", "authors": "Sanjeev Muralikrishnan,Niladri Shekhar Dutt,Niloy J. Mitra", "background": "现有的动画重定位方法要求模板形状先验、艺术家设计的变形框架或特定数据集的注释，这限制了它们的泛化能力和灵活性。现有的方法还存在在全新动作和形状上的限制，或者表现出运动抖动的问题。因此，有必要提出一种不需要模板和框架的自动编码器稀疏动作编码体系，来提升动画重定位的效果和泛化能力。", "innovation": "该研究提出了一种自监督的动画重定位方法，名为Self-supervised Motion Fields (SMF)，它不需要特定数据集的注释、模板或框架。SMF的核心是Kinetic Codes，这是一种新颖的自动编码器基础稀疏动作编码，揭示了一个语义丰富的潜在空间，简化了大规模训练。该方法还包括专门的空间和时间梯度预测器，这些预测器以端到端的方式联合训练。联合网络通过Kinetic Codes的潜在空间正则化，具有良好的泛化能力，可以应用于各种不同形状和拓扑结构的角色的新动作上。研究还报告了在AMASS数据集上的新的最先进的技术水平，特别是在对全新动作的泛化方面。", "conclusion": "该工作提出了一种自监督的新型动画重定位方法，能够在无需模板和框架的情况下处理各种新动作和形状。通过Kinetic Codes的稀疏动作编码和联合训练的空间与时间梯度预测器，该方法成功解决了传统方法存在的问题，提供了更好的泛化性和灵活性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03355", "html_url": "https://arxiv.org/abs/2506.03355", "title": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "title_en": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "authors": "Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher", "background": "对抗输入攻击可以显著改变CLIP嵌入，影响包含CLIP的下游模型的鲁棒性，如文本到图像生成模型或大型视觉语言模型。尽管在使CLIP图像编码器变得鲁棒方面已经做出了一些努力，但文本编码器的鲁棒性尚未得到探索。", "innovation": "提出了一种高效的文本域对抗微调方法LEAF，适用于大型CLIP模型。LEAF显著提高了零样本对抗准确率，同时保持图像编码器提供的视觉性能。在与文本到图像扩散模型结合使用时，可以提高在对抗噪声下的生成质量。在多模态检索任务中，LEAF在对抗噪声下提高了召回率，并公开了代码和模型。", "conclusion": "通过优化直接优化，鲁棒文本编码器能更好地从嵌入重构输入文本。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11128", "html_url": "https://arxiv.org/abs/2505.11128", "title": "您的扩散模型内部是什么？一种基于得分的黎曼度量来探索数据流形", "title_en": "What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold", "authors": "Simone Azeglio,Arianna Di Bernardo", "background": "最近的扩散模型研究表明，它们能有效捕捉复杂图像分布，但学习到的数据流形的几何特性仍不清楚。本文通过引入一种基于扩散模型的Stein得分函数的黎曼度量来填补这一空白，该度量能在不依赖显式参数化的情况下描述数据流形的内在几何结构。", "innovation": "本文提出了一个基于得分的黎曼度量，利用扩散模型中的Stein得分函数，在不依赖显式参数化的情况下描述数据流形的内在几何结构。该方法定义了一个在等势空间中的度量张量，该张量在与流形垂直的方向上拉伸距离，在流形切向方向上保持距离不变，从而在流形自然轮廓方向上创建了一个几何结构。文中开发了计算这些测地线的有效算法，并展示了它们在数据点间插值和超出观察到的数据分布外推中的应用。通过合成数据集、Rotated MNIST和通过定常扩散获得的复杂自然图像的实验，表明了得分基于的测地线能够捕捉到有意义且符合基础数据分布的变换。该方法在感知度量（LPIPS）和分布度量（FID，KID）中始终优于基准方法，产生了更平滑、更现实的图像过渡。", "conclusion": "结果揭示了扩散模型内部隐含的几何结构，并提供了一种通过黎曼几何视角导航自然图像流形的原理方法。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.07180", "html_url": "https://arxiv.org/abs/2506.07180", "title": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "title_en": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "authors": "Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang", "background": "随着视频大语言模型（Video-LLMs）在要求-grounded-多模态推理的实际应用中越来越普及，确保它们的准确性与可靠性变得尤为重要。然而，这些模型倾向于与用户输入保持一致，即使这些输入与视觉证据相矛盾，这降低了它们在这些情境下的可信度。当前关于sycophancy的研究大多忽略了视频-语言领域中的具体表现，导致缺乏系统性基准和针对性评估来理解Video-LLMs如何应对误导性用户输入。", "innovation": "本文提出了VISE（Video-LLM Sycophancy Benchmarking and Evaluation），这是首个旨在评估视频-LLMs在不同问题形式、提示偏见和视觉推理任务下的sycophantic行为的基准。VISE首次引入了语言视角，对多种sycophancy类型和交互模式进行了细微分析。同时，提出了两种无训练数据的缓解策略，旨在减少sycophantic偏差：增强视觉基础并通过可解释的关键帧选择，以及通过目标干预内部神经表示来引导模型远离sycophancy。", "conclusion": "本文通过VISE基准和缓解策略，为理解与减少视频-LLMs中的sycophantic行为提供了新的路径，增强了该领域的研究和实践，并提供了开源代码。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07688", "html_url": "https://arxiv.org/abs/2509.07688", "title": "使用自我监督学习理解冰晶形态多样性", "title_en": "Understanding Ice Crystal Habit Diversity with Self-Supervised Learning", "authors": "Joseph Ko,Hariprasath Govindarajan,Fredrik Lindsten,Vanessa Przybylo,Kara Sulia,Marcus van Lier-Walqui,Kara Lamb", "background": "冰晶在气候中具有重要影响，但由于形态（即形状）多样性难以建模，这使得气候模型面临挑战。已有研究通过自监督学习（SSL）从冰晶图像中学习潜在表示，利用大量云粒子图像预训练视觉转换器，以学习晶体形态的稳健表示，为各种科学驱动任务提供支持。先前的研究验证了SSL方法可以用于学习有意义的表示，也为量化冰晶多样性提供了有效应用实例，展示了SSL驱动表示在提高冰晶特性和约束其地球气候系统作用方面的潜力。", "innovation": "提出了一种新的方法，利用自我监督学习（SSL）从冰晶图像中学习潜在的形态表示。通过大量云粒子图像的预训练视觉转换器，学习了冰晶形态的稳健表示，可以应用于多种科学任务。验证了SSL方法可以用于学习有意义的表示，并展示了其在量化冰晶多样性和改进冰晶特性表征方面的应用潜力。", "conclusion": "研究表明，SSL驱动的表示方法能够显著提升冰晶特性的表征，进而更精确地约束其在地球气候系统中的作用。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.19353", "html_url": "https://arxiv.org/abs/2509.19353", "title": "频率感知集成学习方法在2025年BraTS儿童脑肿瘤分割挑战中的应用", "title_en": "Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation", "authors": "Yuxiao Yi,Qingyao Zhuang,Zhi-Qin John Xu,Xiaowen Wang,Yan Ren,Tianming Qiu", "background": "儿童脑肿瘤的分割因其罕见性和异质性而面临独特的挑战，但其对于临床诊断和治疗规划至关重要。BraTS-PED 2025挑战旨在利用先进的深度学习模型改进儿童脑肿瘤的分割性能。", "innovation": "本文提出了一种集成方法，整合了nnU-Net、Swin UNETR和HFF-Net模型。该方法包括以下创新点：(1) 可调节nnU-Net的初始规模，以优化其复杂度控制；(2) 利用BraTS 2021预训练模型对Swin UNETR进行迁移学习，以增强其在儿科数据集上的泛化能力；(3) 在HFF-Net中采用频域分解技术，区分低频组织轮廓和高频纹理细节。通过将nnU-Net、微调后的Swin UNETR和HFF-Net模型集成在框架中，克服了单一模型难以应对罕见肿瘤分类的挑战。", "conclusion": "所提出的方法在BraTS 2025儿童脑肿瘤分割挑战中获得了综合分数最优的结果，其中综合得分为不同区域的Dice分数分别为：CC（62.7%）、ED（83.2%）、ET（72.9%）、NET（85.7%）、TC（91.8%）和WT（92.6%）。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06944", "html_url": "https://arxiv.org/abs/2508.06944", "title": "AMFT: 通过元学习最优模仿与探索平衡来对齐大型语言模型推理器", "title_en": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance", "authors": "Lixuan He,Jie Feng,Yong Li", "background": "大型语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）的两阶段管道进行定制，但在这一过程中容易出现灾难性遗忘和模仿与探索之间的次优化权衡。单阶段方法虽然试图通过启发式方法统一SFT和RL，但缺乏一种原理性的机制来动态平衡这两种范式。本文从隐式奖励的理论视角重新定义这一挑战，将SFT和RL视为互补的奖励信号，而不是不同的方法。", "innovation": "本文引入了自适应元微调（AMFT）算法，这是一种新颖的一阶段算法，能够学习SFT的路径级隐式奖励和RL的结果导向奖励之间的最佳平衡。AMFT的核心是一个元梯度自适应权重控制器，该控制器将SFT-RL平衡视为可学习参数，动态优化以最大化长期任务表现。此外，实验证明AMFT在各个领域基准测试中表现出优越的通用性，通过消融研究和训练动态分析证实了元学习控制器对于算法稳定性和效率的至关重要性，为LLMs对齐提供了一种原理性、有效的方法。", "conclusion": "AMFT在数学推理、抽象视觉推理和视觉语言导航等多个领域的基准测试中均表现出卓越的性能，并建立了新的基线，特别是在泛化到分布外任务方面表现出色，证明了其对于LLMs提升性能的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01298", "html_url": "https://arxiv.org/abs/2510.01298", "title": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging", "title_en": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging", "authors": "Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello", "background": "体外细胞响应干预的模拟是加速基于高内涵成像的筛选的关键方向，对药物发现和基因编辑至关重要。为了支持这一点，研究引入了MorphGen，这是一种基于扩散的生成模型，用于荧光显微镜成像，支持多种细胞类型和扰动的可控生成。与其他先前方法不同，MorphGen 生成了完整的荧光通道集合，同时保留了微结构信息，促进了生物解释的精细结构分析。该模型通过与 OpenPhenom 的 phenotypic embeddings 进行对齐训练，确保生成的图像符合已知的细胞形态学特征。该方法在 CellProfiler 特征上展示了生物学一致性，并取得了比先前最佳的 MorphoDiff 更低的 FID 分数，后者只能生成单个细胞类型的 RGB 图像。", "innovation": "MorphGen 是一种基于扩散的生成模型，能够联合生成整个荧光通道，从而保留每个细胞器的结构信息。它通过与 OpenPhenom 的 phenotypic embeddings 进行对齐训练，保证生成图像符合已知的细胞形态学特征。此外，MorphGen 的生成结果在生物学一致性和 FID 分数上优于同类方法，证明了其在生物解释中的优越性。", "conclusion": "MorphGen 通过生成多细胞类型和扰动的实图像一致的荧光显微图像，促进了基于高内涵成像的筛选，适用于药物发现和基因编辑。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04547", "html_url": "https://arxiv.org/abs/2510.04547", "title": "视编码器后训练量化需要前缀寄存器", "title_en": "Post-training quantization of vision encoders needs prefixing registers", "authors": "Seunghyeon Kim,Jinho Kim,Taesun Yeom,Wonpyo Park,Kyuyeun Kim,Jaeho Lee", "background": "基于变压器的视觉编码器（如CLIP）是多模态智能的核心，其推动了许多应用的发展，如自主网络代理和机器人控制。由于这些应用经常需要实时处理海量的视觉数据，降低视觉编码器的推理成本（即加快处理速度）变得至关重要。后训练量化虽然提供了一条实用的途径，但在8位精度下仍因大规模激活（即异常值）而极具挑战性。因此，提出了一种不需训练的算法$\\textit{RegCache}$，以缓解视觉编码器中的异常值问题，使量化能够显著减少准确性损失。", "innovation": "本文提出了$\\textit{RegCache}$，这是一种无需训练的算法，通过引入可能产生异常值但具有语义无意义的前缀标记，并防止其他标记出现异常值，从而有效地应对视觉编码器中的异常值问题。本文还观察到，视觉编码器中的异常值与语言模型中的异常值行为不同，为此提出了两种技术创新：中间层前缀技术和标记删除。", "conclusion": "实验结果表明，该方法能够跨文本监督和自监督视觉编码器持续提升量化模型的准确性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01982", "html_url": "https://arxiv.org/abs/2510.01982", "title": "G$^2$RPO: Granular GRPO for Precise Reward in Flow Models", "title_en": "G$^2$RPO: Granular GRPO for Precise Reward in Flow Models", "authors": "Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai", "background": "近年来，将在线强化学习(RL)整合到扩散和流模型中，作为一种使生成模型与人类偏好相匹配的有前途的方法逐渐兴起。在去噪过程中使用随机微分方程(SDE)进行随机采样，生成多样的去噪方向以供RL探索。尽管现有方法有效地探索潜在的高价值样本，但由于奖励信号稀疏且狭窄，导致偏好对齐不佳的问题。", "innovation": "提出了一种新颖的粒度GRPO (G$^2$RPO)框架，实现了对流模型中的RL采样方向的精确和全面的奖励评估。具体而言，引入了奇异随机采样策略，支持逐步的随机探索，并强制奖励与注入噪声之间存在高相关性，从而为每个SDE扰动提供忠实的奖励。同时，引入了多粒度优势整合模块，通过在多个扩散尺度上计算优势并将其聚合，产生更加全面和稳健的采样方向评估。实验结果表明，G$^2$RPO显著优于现有的基于流的GRPO基准模型，突显了其有效性和稳健性。", "conclusion": "在不同奖励模型上的实验表明，G$^2$RPO在领域内和领域外评估中均显著优于现有的基于流的GRPO基准，展示了其卓越的有效性和鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06955", "html_url": "https://arxiv.org/abs/2510.06955", "title": "高比率Mixout：重新审视Mixout在稳健域泛化中的应用", "title_en": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Srikanth Muralidharan,Eric Granger,Marco Pedersoli", "background": "集成调优的预训练模型是一种常用的策略，用于提高在数据分布变化时的鲁棒性，但这会导致计算成本显著增加。Dropout通过随机失活神经元提供了一种轻量级的替代方案，但将其应用于预训练模型时，往往会导致过度正则化并破坏必要的表征，这些表征对于泛化至关重要。Mixout作为一种随机正则化技术，在模型训练过程中，通过概率性地将部分调优权重替换为预训练权重，从而在适应与保留先验知识之间保持平衡，以避免过度拟合。研究表明，要在域泛化基准测试中使用Mixout实现较强性能，ViTs需要较高的蒙版概率（0.9）而ResNets需要（0.8）。", "innovation": "提出了一种高比率Mixout，通过概率性地将部分调优权重替换为预训练权重来缓解过拟合，相比Dropout，它可以二阶优势。实验结果表明，高比率Mixout方法在五个域泛化基准测试（PACS, VLCS, OfficeHome, TerraIncognita, DomainNet）中，能够达到与集成方法相当甚至更好的跨域准确性，同时显著降低训练成本，具体来说，计算量减少了45%，内存使用减少了90%。", "conclusion": "我们的研究表明，高比率Mixout在Domain泛化任务中表现出了强大的能力和显著的计算节省优势，为解决域泛化中资源消耗高的问题提供了一种有效的方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08657", "html_url": "https://arxiv.org/abs/2510.08657", "title": "时间序列内实例归一化方法研究", "title_en": "Inner-Instance Normalization for Time Series Forecasting", "authors": "Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen", "background": "现实世界中的时间序列受到多种因素的影响，表现出复杂的非平稳特性。非平稳性会导致分布漂移，即时间序列的统计特性随时间变化，从而负面影响模型性能。虽然已有多种实例归一化技术被提出以解决时间序列预测中的分布漂移问题，但这些方法未能考虑到个体实例内的分布变化，因此效果不佳。", "innovation": "为了应对个体实例内部的分布变化，本文提出了两种新颖的点级方法：学习分布（LD）和学习条件分布（LCD）。LD通过在不同时间步骤中用不同的参数拟合输入和输出的内部分布来消除内部差异，而LCD利用神经网络预测输出的缩放系数。通过公共基准上的各种骨干模型评估这两种方法，并通过对比实验证明了点级范式的有效性。", "conclusion": "本文通过提出两种点级方法LD和LCD，有效解决了时间序列预测中的个体实例内部分布漂移问题，并在多种公开基准上验证了这两种方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08646", "html_url": "https://arxiv.org/abs/2510.08646", "title": "Energy-Driven Steering: 减少大型语言模型的错误拒绝", "title_en": "Energy-Driven Steering: Reducing False Refusals in Large Language Models", "authors": "Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li", "background": "大型语言模型（LLMs）的安全对齐面临一个关键挑战：当前的对齐技术通常只专注于提高对有害提示的安全性，导致LLMs变得过于谨慎，拒绝回应 benign 提示。因此，安全对齐的一个关键目标是在提高安全性的同时减少错误拒绝。现有的方法往往使得模型在生成不必要或不安全的响应时变得更加保守和谨慎，这导致了严重的过度谨慎问题，即误拒绝现象。现有技术通常涉及大量的微调和调整，增加了复杂性和资源消耗。", "innovation": "本文介绍了Energy-Driven Steering (EDS)，一种新颖的无需微调的框架，通过动态、推理时的干预解决了这一挑战。EDS训练了一个轻量级的外部能量基模型（EBM），该模型通过评估激活状态的能量来决定是否生成有害行为或安全拒绝。在推理过程中，EBM 将LLM 的内部激活映射到一个“能量景观”中，并通过能量函数的梯度动态引导LLM 的隐藏状态，使其进入低能量区域，从而使模型实时纠正生成期望的响应，而不修改其权重。这种机制解耦了行为控制与模型的核心知识，提供了一种灵活的方法，且几乎没有计算开销。EDS展示了在广泛模型上成功的实验结果，有效降低了错误拒绝率。例如，在ORB-H基准测试中，将合规性从57.3%提高到82.6%，同时保持基线的安全性能", "conclusion": "我们的工作提出了一个有效的建模范式，构建既具有低错误拒绝率又具有高安全性的LLMs。EDS成功地实现了平衡安全性和减少错误拒绝的任务，为未来的LLM研究和应用提供了新的视角和方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08655", "html_url": "https://arxiv.org/abs/2510.08655", "title": "基于图神经网络的罕见疾病诊断的知识图谱稀疏化", "title_en": "Knowledge Graph Sparsification for GNN-based Rare Disease Diagnosis", "authors": "Premt Cara,Kamilia Zaripova,David Bani-Harouni,Nassir Navab,Azade Farshad", "background": "罕见疾病诊断面临严峻挑战，包括患者数据不足、无法获得全面的基因组序列以及数千个可能的致病基因。这些限制导致漫长的诊断过程、不适当的治疗以及在资源有限地区诊断工具稀缺的背景下，诊断延误和影响尤为严重。", "innovation": "本研究提出了一种基于子图的图神经网络模型RareNet，它仅依赖于患者表型数据来识别最有可能的致病基因，并检索有针对性的患者子图进行临床调查。该方法可以作为独立的诊断工具，也可以作为其他候选基因优先级方法的前处理或后处理滤镜，从而提升其他模型的表现，提供可解释的见解。通过在两个生物医学数据集上进行全面评估，证明了其在致病基因预测上的竞争力和鲁棒性，并展示了与其他框架集合并使用时所带来的显著性能提升。通过仅需要易于在任何医疗环境中获取的表型数据，RareNet消除了复杂的基因组分析的障碍，特别是在缺乏先进基因组基础架构的未服务人群中提供了特别的价值。", "conclusion": "综合评估表明，RareNet在致病基因预测上表现竞争力和鲁棒性，并且与现有框架集成时能够显著提升其性能。其仅需患者表型数据的特性使得基因组分析更加普及易得，特别为资源有限地区和缺乏先进基因组基础设施的人群提供了价值。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08648", "html_url": "https://arxiv.org/abs/2510.08648", "title": "无逆元威尔逊环路用于变换器：不变性与顺序敏感性的实用诊断", "title_en": "Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity", "authors": "Edward Y. Chang,Ethan Y. Chang", "background": "大规模语言模型在受到看似无害但实际上重要的编辑后可以改变答案。例如，检索式回答生成（RAG）的输出会在段落重新排列时翻转，微调会侵蚀预训练中学到的不变性，辩论或思维导论提示会依赖上下文路径，编译融合或重新排列会扰动接近决策边界的梯度。这些失败会违反预定的不变性，破坏持续集成，并迫使团队在安全性和速度之间做出权衡。这些效果虽然微小，但会分布在多层和多个位置，对上下文长度和评估顺序敏感，进行纠正可能会非常昂贵。我们需要一个能最小化后置补救的诊断套件来解决这些问题。", "innovation": "我们提出了WILSON，这是一个最小化后视补救的诊断套件，将内部表示的简单循环和重新排序检查转化为系统信号。WILSON将通过JVPs和海特昆兹探针计算的无逆元曲率映射与判别级别交换器结合，以标识重新排序风险。这种信号便宜且易于计算，并且对标准变换器具有模型无关性。这些信号附加为阈值和CSV文件以供协调者使用，这使得可以采取具体措施，如保护RAG免受顺序效应的影响，捕捉微调的回归，稳定辩论路径和长多轮上下文，以及在部署中限制融合或重新排列。WILSON有助于预测失败并批准安全优化，从而使可靠性和吞吐量能够一起提高，而不必改变模型架构或训练过程。", "conclusion": "WILSON通过提供实用的信号和诊断工具，帮助提前识别和预防模型中的潜在风险，使得系统能够在面对不变性和顺序敏感性问题时做出可靠的优化，从而在保证模型性能的同时提高其可靠性和稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08660", "html_url": "https://arxiv.org/abs/2510.08660", "title": "如何打破“标准化应力”和KL散度：重新思考质量指标", "title_en": "How Scale Breaks \"Normalized Stress\" and KL Divergence: Rethinking Quality Metrics", "authors": "Kiran Smelser,Kaviru Gunaratne,Jacob Miller,Stephen Kobourov", "background": "在众多科学研究领域，如机器学习、生物学和社会科学中，复杂和高维数据非常普遍。通过二维散点图可视化这些数据已成为主要方式，尽管图像准确性评估具有挑战性，但研究者常依赖于投影质量和拟合度的度量标准。最常见的度量，标准化应力（normalized stress），对均匀缩放敏感，但这种缩放实际上并未改变投影的本质特征。另一种常用的方法，t-Distributed Stochastic Neighbor Embedding (t-SNE) 中使用的Kullback–Leibler (KL) 散度，同样对这种缩放敏感。", "innovation": "本研究通过理论和实证分析了均匀缩放对标准化应力和KL散度的影响，并揭示这些度量如何受到这种敏感性的影响。作者提出了一种简单的方法，使其对尺度变化具有不变性，并验证了其在小型基准测试中的良好表现。", "conclusion": "研究展示了度量方法的改进，尤其是使标准化应力和KL散度不受均匀缩放影响的机制，从而使投影技术评估更加准确可靠。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08662", "html_url": "https://arxiv.org/abs/2510.08662", "title": "DPCformer: 农作物基因组预测的可解释深度学习模型", "title_en": "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops", "authors": "Pengcheng Deng,Kening Liu,Mengxi Zhou,Mingxi Li,Rui Yang,Chuzhe Cao,Maojun Wang,Zeyu Zhang", "background": "基因组选择（GS）利用整个基因组信息来预测作物表型并加速育种进程。传统方法在处理复杂性状和大数据集时存在预测准确性不佳的问题。", "innovation": "提出了一种结合卷积神经网络和自我注意力机制的深度学习模型DPCformer，用于建模基因型-表型关系。通过8维one-hot编码处理SNP数据，采用PMF算法进行特征选择。实验结果表明，DPCformer在各种作物（玉米、棉花、番茄、水稻、鹰嘴豆）的多种性状预测中表现出优异的准确性和鲁棒性。", "conclusion": "DPCformer展示了在小型样本情况下的优越准确性和鲁棒性，并增强了模型解释性，为精确育种和全球粮食安全挑战提供了强有力的工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08661", "html_url": "https://arxiv.org/abs/2510.08661", "title": "CATS-Linear: 分类辅助线性模型用于时间序列预测", "title_en": "CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting", "authors": "Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen", "background": "近期的研究表明，线性模型在预测性能上可以与复杂架构相媲美，但增强线性模型的方法尚未得到充分探索。没有单独的线性预测增强方法，时间序列实例可能遵循不同的线性变换这一假设推动了本研究。", "innovation": "研究提出了CATS-Linear模型，即分类辅助趋势-季节性解耦线性模型。该模型通过分类辅助通道独立性（CACI）动态地将时间序列实例导向专用预测器，并进一步通过增加解耦 - 线性映射 - 重新耦合框架来解耦趋势成分和使用复数域线性投影来解耦季节性成分。此外，还分析了不同通道设置的理论期望风险。与其他固定超参数的方法相比，CATS-Linear固定超参数时表现出最优性能，甚至超过调参基线的性能并获得最优的预测准确性。", "conclusion": "CATS-Linear模型通过解决不同时间序列实例外部存在的异质线性映射问题，以及引入特定组件的解耦与重新耦合机制，提高了线性模型的预测性能，达到了与调参基线相当甚至更好的预测准确性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08669", "html_url": "https://arxiv.org/abs/2510.08669", "title": "FreqCa：通过频域感知缓存加速扩散模型", "title_en": "FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching", "authors": "Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang", "background": "扩散变换器在推理过程中存在显著的计算成本问题。传统的特征缓存方法通过重用前一个时间步的特征来解决这个问题，从而在未来的时间步跳过计算。然而，这些方法假设相邻时间步的特征相似或连续，但在某些情况下并不成立。通过频域分析，发现扩散模型中的不同频率带具有不同的动态变化特性，即低频成分相似但不连续，高频成分连续但不相似。这些观察促使该研究提出了Frequency-aware Caching (FreqCa)，直接重用低频成分的特征以相似性为基础，而对高频成分则采用二阶海利插值预测其变化，同时也提出通过缓存累积残差特征(CRF)而非所有层的特征来减小特征缓存的内存开销99%。", "innovation": "该研究提出了Frequency-aware Caching (FreqCa)，这是一个结合低频成分的相似性和高频成分的连续性的缓存机制。它直接重用低频成分的特征并采用二阶海利插值预测高频成分。此外，该研究还提出缓存累积残差特征(CRF)，这种缓存策略减少了特征缓存的内存开销99%。", "conclusion": "在FLUX.1-dev、FLUX.1-Kontext-dev、Qwen-Image和Qwen-Image-Edit上的 extensive 实验表明，FreqCa 在生成和编辑方面都表现出有效性。该研究的代码已提供在附录材料中，并将在 GitHub 上发布。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08696", "html_url": "https://arxiv.org/abs/2510.08696", "title": "利用置信度重权利用错误：通过信心加权利用负RL组", "title_en": "Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting", "authors": "Yunzhen Feng,Parag Jain,Anthony Hartshorn,Yaqi Duan,Julia Kempe", "background": "强化学习中的验证奖励（RLVR）已经成为提高大型语言模型（LLMs）在推理任务上的标准方法，而Group Relative Policy Optimization（GRPO）在实践中被广泛使用。然而，GRPO在处理负面群体时会浪费大量计算资源，即使在这些群体中没有正确的回应，它们也会产生零优势，从而没有梯度。研究者们想要知道是否可以利用这些负面群体而无需额外监督。", "innovation": "从奖励模型的最大似然（MLE）目标出发，研究者展示了MLE梯度实际上对应的是一种修改后的价值函数的策略梯度。该价值函数对错误响应增加了置信度加权的惩罚，并对更有信心的错误施加更大的惩罚。这种方法称为Likelihood Estimation with Negative Samples（LENS）。LENS修改了GRPO，当模型生成错误回应时为其分配非零、置信度相关的奖励，使负面群体成为有用梯度更新的一部分，从而提升了效率和性能。", "conclusion": "在MATH基准测试上使用Llama-3.1-8B和Qwen-2.5-3B模型的实验表明，提出的变体始终优于GRPO基线，尤其是在较难的问题上取得了显著的提升。该研究结果表明了一种被验证和实用的方法来“救援”负面群体，从而在RLVR中提高效率和性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08659", "html_url": "https://arxiv.org/abs/2510.08659", "title": "语言赋能基础模型的可验证鲁棒适应", "title_en": "Provably Robust Adaptation for Language-Empowered Foundation Models", "authors": "Yuni Lai,Xiaoyu Xue,Linghui Shen,Yulun Wu,Gaolei Li,Song Guo,Kai Zhou,Bin Xiao", "background": "语言赋能基础模型（LeFMs），如CLIP和GraphCLIP，通过将视觉（或图形）特征与文本表示对齐，革新了多模态学习，并赋予了诸如少样本学习等功能强大的下游能力。然而，这些模型依赖于在开放环境中收集的小规模任务特定支持数据集，使其容易受到注入式攻击的影响，即对手操控支持样本以降级模型性能。现有的防御措施依赖于经验策略，缺乏正式保证并且仍然易受未知和适应性攻击。虽然已有研究提出了认证鲁棒性，但其主要用于基于LeFMs的少样本分类器并不充分。已有研究尚未探索适用于LeFMs少样本分类器的认证鲁棒性方法，该研究旨在填补这一空白，提出了一种适用于LeFMs的首个多鲁棒性保障少样本分类器LeFCert。", "innovation": "该研究通过结合文本和特征嵌入，并提出了一种适应性混合机制，实现了可验证鲁棒性。为实现可验证鲁棒性，研究人员提出了双裁剪平均原型，并推导了分类分数的可验证上下界，使之在最坏情况的注入环境下能够进行认证。为了进一步增强性能，研究人员还提出了两种变体：通过引入随机化平滑提供了Lipschitz连续性，并在双重预算限制下推导了鲁棒性；提供了一种针对攻击者在多个样本中分配共享注入预算的情况的集体保障认证。实验结果表明，LeFCert 达到了最先进的性能，与现有基线相比，其在干净和认证准确性方面均有显著提高，尽管鲁棒性机制较为复杂，但LeFCert 在计算效率方面仍然很高，使其具有实际应用的价值。", "conclusion": "LeFCert 是一种针对LeFMs的可验证鲁棒保障少样本分类器，通过结合文本和特征嵌入，以及适应性混合机制和新的鲁棒性保障方法，实现了在最坏情况下的注入环境中的认证鲁棒性。该方法被证明在性能和效率之间达到了良好的平衡，使其可以实际应用于多种场景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08722", "html_url": "https://arxiv.org/abs/2510.08722", "title": "增强语义配对的自我监督学习：一个新的数据集和实证研究", "title_en": "Enhancing Self-Supervised Learning with Semantic Pairs A New Dataset and Empirical Study", "authors": "Mohammad Alkhalefi,Georgios Leontidis,Mingjun Zhong", "background": "实例区分是一种自我监督的表示学习范式，其中数据集中的个体实例被视为不同的类别。通常通过应用随机变换生成每个实例的两个不同视图来实现这一点，从而鼓励模型学习在这些视图中不变的表示。", "innovation": "提出了一个新的数据集和实证研究，旨在通过引入语义配对来增强自我监督学习。通过利用语义相关性，作者提高了自我监督学习的性能。", "conclusion": "实验表明，通过引入语义配对，自我监督学习的表现得到了显著提升。这一方法为自我监督学习提供了一种新的改进途径，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08724", "html_url": "https://arxiv.org/abs/2510.08724", "title": "Counterfactually Fair Conformal Prediction", "title_en": "Counterfactually Fair Conformal Prediction", "authors": "Ozgur Guldogan,Neeraj Sarna,Yuanyuan Li,Michael Berger", "background": "尽管点预测的反事实公平性已经被广泛研究，但其扩展到预测集——对在不确定性下的公平决策至关重要的领域——仍然未被充分探索。另一方面，一致性预测（CP）提供了高效、自由分布、有限样本有效的预测集，但并未保证反事实公平性。", "innovation": "通过在受保护属性干预下对一致性分数进行对称化，我们提出了一种名为Counterfactually Fair Conformal Prediction（CF-CP）的新方法，能生成反事实公平的预测集同时保持边际覆盖性质。在合成和真实数据集上对回归和分类任务的实验表明，CF-CP 在保持预测集大小最小增加的情况下，实现了所需的反事实公平性和目标覆盖率。", "conclusion": "CF-CP 提供了一种简单且不需要额外训练的实现反事实公平不确定性量化的方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08711", "html_url": "https://arxiv.org/abs/2510.08711", "title": "非平稳MIMO均衡的在上下文学习", "title_en": "In-Context Learning for Non-Stationary MIMO Equalization", "authors": "Jiachen Jiang,Zhen Qin,Zhihui Zhu", "background": "信道均衡是缓解频率选择性衰落和符号间干扰等失真的基本技术。传统监督学习方法需要每次重新训练或微调模型，以适应新的任务。相比之下，上下文学习（ICL）可以在推理阶段仅通过少量示例适应新的信道。然而，现有的ICL均衡器主要针对的是固定在上下文窗口内的静态信道进行开发和评估。先前的研究大多专注于平稳环境，即函数在训练期间保持固定不变。本文则探讨了ICL在非平稳环境中解决时间变化信道均衡问题的能力，采用了适应性信号处理算法来设计更高效的注意力机制，提高了非平稳任务的适应性。实验表明，ICL在非平稳MIMO均衡中有巨大的潜力，而借鉴经典自适应算法设计的注意力机制能显著增强动态环境中的适应性和性能。", "innovation": "本文创新之处在于构建了一个以经典自适应算法为指导的设计框架，旨在提高非平稳任务中的注意力机制的适应性和性能。具体包括从LMS自适应算法中衍生出新的注意力变体、采用LRMS算法增强鲁棒性，以及使用多步梯度更新来改进长期跟踪。", "conclusion": "实验结果表明，ICL在非平稳MIMO均衡中具有很大的潜力，并且经典自适应算法指导下的注意力机制能够显著提升动态环境下的适应性和性能。这些发现为开发下一代具有更强适应性和鲁棒性的无线基础模型提供了关键的见解。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08737", "html_url": "https://arxiv.org/abs/2510.08737", "title": "基于SHAP的监督聚类及广义瀑布图在样本分类中的应用", "title_en": "SHAP-Based Supervised Clustering for Sample Classification and the Generalized Waterfall Plot", "authors": "Justin Lin,Julia Fukuyama", "background": "在数据和技术快速发展的时代，由于能够处理大量数据并学习极其复杂的关系，大型黑盒模型变得越来越普遍。然而，这些方法的一个缺陷是它们无法解释预测过程，这使得它们在高风险情况下不被信任，使用起来很棘手。SHapley Additive exPlanations (SHAP)分析是一种日益流行的可解释AI方法，它能够通过原特征来解释模型的预测过程。通过对每个样本和数据集中的特征进行评估，可以赋予每个特征一个SHAP值，以量化该特征对样本预测的贡献。通过聚类这些SHAP值，可以洞察数据，并将具有相同或类似预测原因的样本分组，揭示不同样本到达相同预测结果的不同路径。", "innovation": "该研究提出了一种新的基于SHAP的监督聚类方法，并且展示了一种新的广义瀑布图用于多分类任务。这种方法不仅能够提供样本分类的洞察，还能够以更直观的方式展示不同样本如何达到相同的预测结果。", "conclusion": "通过实际的模拟实验和阿尔茨海默病患者数据的案例研究，验证了该方法的有效性，并且扩展了瀑布图的使用范围，使之适用于多分类任务。这些成果对于提高模型的可解释性和信任度，尤其是在医疗等高风险领域具有重要意义。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08734", "html_url": "https://arxiv.org/abs/2510.08734", "title": "将提示转化成权重", "title_en": "Transmuting prompts into weights", "authors": "Hanna Mazzawi,Benoit Dherin,Michael Munn,Michael Wunder,Javier Gonzalvo", "background": "现有大量研究已证实，可以通过直接调整大型语言模型的内部状态（如激活向量的向量加法或权重矩阵的更新）在推理时有效控制模型行为。尽管这些技术很强大，但它们通常受到经验性直觉的引导，如从对比提示的平均激活中推导出引导向量。本文提供了这些干预措施的理论基础，解释了它们是如何从transformer架构的基本计算中产生的。基于最近发现的‘提示的影响可以数学映射为隐含权重更新’（Dherin et al., 2025），本文扩展了这一理论，应用到深度、多块变压器中，展示了如何通过权重向量和矩阵表示和组合用户提示中的信息，进而提出了一种基于原理的方法，将文本输入转化为可重用的权重更新.", "innovation": "本文的主要创新在于提供了一种理论基础，解释了通过修改内部权重实现语言模型控制的方法，并将提示的影响数学映射为隐藏的权重更新，同时还扩展了这一理论，应用于深度多块变压器模型中。此外，通过揭示提示中的信息是如何表示和组合成无标记的思想向量和矩阵，本文提供了一种原理上合理的方法，将文本输入转化为可重用的权重更新.", "conclusion": "本文提出了一个理论框架，解释并验证了如何利用transformer模型内部的计算机制来调整模型的输出，增强了模型控制技术的理论依据。这种方法不仅为现有基于向量和矩阵的模型编辑提供了理论解释，还提供了一种直接的、计算上合理的方法，将文本输入转化为可以重复使用的权重更新."}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08739", "html_url": "https://arxiv.org/abs/2510.08739", "title": "使用代理模型和预测分析实现复杂时间序列集成预测的忠实和可解释解释", "title_en": "Faithful and Interpretable Explanations for Complex Ensemble Time Series Forecasts using Surrogate Models and Forecastability Analysis", "authors": "Yikai Zhao,Jiekai Ma", "background": "现代时间序列预测越来越多地依赖于AutoML系统（如AutoGluon）生成的复杂集成模型，这些模型虽然提高了预测准确性，但牺牲了透明度和可解释性。面对这一挑战，本研究旨在开发一种框架，该框架通过使用代理模型和预测分析来解决复杂时间序列集成模型中的可解释性和可预测性问题。该框架通过训练LightGBM模型来模仿AutoGluon的时间序列预测，从而实现了稳定且可解释的Shapley值，同时也引入了基于频谱预测分析的方法来量化每个时间序列的可预测性，通过与噪声基准进行比较，为预测及其解释提供客观的评估机制。实验证明，更高的频谱可预测性不仅与更好的预测准确性相关，还与代理模型与原始模型之间更高的解释忠实度相关联。这表明该框架能够为复杂的集成预测提供可解释的实例级解释，并为预测及其解释的可靠性提供指标。", "innovation": "本研究创新点在于开发了一种双管齐下的框架，此框架结合了代理模型和频谱预测分析方法来解决复杂时间序列集成模型中的可解释性和可预测性问题。特别之处在于利用LightGBM模型准确模拟AutoGluon的时间序列预测过程，并通过频谱预测分析量化每个时间序列的潜在可预测性，从而为预测及其解释提供客观的评估机制。此外，研究还证明了项目内规范化对于生成跨不同规模的时间序列有意义的Shapley解释的重要性。", "conclusion": "所提出的框架能够为复杂的集成预测提供可解释的实例级解释，同时通过频谱可预测性指标为预测及其解释的可靠性提供有效评估工具。这使得用户能够准确地校准对预测及其解释的信任度，从而增强了时间序列预测模型的透明性和用户依赖性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08744", "html_url": "https://arxiv.org/abs/2510.08744", "title": "图扩散转换器是上下文分子设计师", "title_en": "Graph Diffusion Transformers are In-Context Molecular Designers", "authors": "Gang Liu,Jie Chen,Yihan Zhu,Michael Sun,Tengfei Luo,Nitesh V Chawla,Meng Jiang", "background": "在上下文学习中，大型模型能够从少量演示中适应新任务，但在分子设计领域效果有限。现有的数据库如ChEMBL包含跨越数百万生物测试的分子属性，但每个属性的标注数据仍稀缺。为解决这一限制，论文提出了一种新型的演示控制扩散模型（DemoDiff），该模型使用少量分子-分数样本来定义任务背景，而非依靠文本描述。这些演示通过指导非噪声变压器生成与目标属性一致的分子。为实现可扩展的预训练，开发了一个新的分子分词器，使用节点对编码表示分子，仅需5.5倍少的节点。构建了涵盖药物和材料的百万级上下文任务数据集，并使用包含0.7亿参数的模型进行了预训练。", "innovation": "1. 提出了演示控制扩散模型(DemoDiff)，用少量分子-分数样本来定义任务背景，代替了文本描述。2. 开发了一种新的分子分词器，使用节点对编码在分子结构表示层面进行表示，减少了节点数。3. 构建了涵盖药物和材料的百万级上下文任务数据集，并通过此数据集预训练了一种0.7亿参数的模型。4. 模型在33项设计任务中表现出色，超越了大小为100-1000倍的大型语言模型，且达到了平均第3.63名的成绩，相比之下，领域特定的方法的排名在5.25-10.20之间。", "conclusion": "这些结果表明DemoDiff是一个分子基础模型，可用于上下文分子设计。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08747", "html_url": "https://arxiv.org/abs/2510.08747", "title": "RFOD：面向表征数据的基于随机森林的离群点检测", "title_en": "RFOD: Random Forest-based Outlier Detection for Tabular Data", "authors": "Yihao Ang,Peicheng Yao,Yifan Bao,Yushuo Feng,Qiang Huang,Anthony K. H. Tung,Zhiyong Huang", "background": "表征数据在高风险领域，如网络安全、金融欺诈检测和医疗保健中保护数据完整性至关重要。在这些领域中，异常值可能导致严重的运营和经济损失。尽管数据挖掘和深度学习都取得了进展，但现有方法在处理混合类型表征数据时仍然存在困难，经常依赖于编码方案，这些方案会丢失重要的语义信息。此外，许多方法缺乏可解释性，无法说明特定哪些值导致异常。", "innovation": "本文提出了RFOD，一种专门为表征数据设计的基于随机森林的离群点检测框架。RFOD将异常检测重新定义为特征条件下的重构问题，针对每个特征进行训练，同时适当处理异构数据类型。RFOD采用调整后的戈瓦距离(AGD)进行单元评分，并结合不确定性加权平均(UWA)以获得稳健的行评分。", "conclusion": "在15个实际数据集上进行的广泛实验表明，RFOD在检测准确性上优于最先进的基线方法，同时在鲁棒性、可扩展性和解释性方面拥有优势，特别适用于混合类型表特征数据。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08750", "html_url": "https://arxiv.org/abs/2510.08750", "title": "探索大型语言模型在联邦学习中跨客户端训练数据的存储", "title_en": "Exploring Cross-Client Memorization of Training Data in Large Language Models for Federated Learning", "authors": "Tinnakit Udsa,Can Udomcharoenchaikit,Patomporn Payoungkhamdee,Sarana Nutanong,Norrathep Rattanavipanon", "background": "联邦学习（FL）允许在不共享原始数据的情况下进行协作训练，但仍然存在训练数据记忆的风险。现有的FL记忆检测技术通常是一次关注一个样本，忽视了跨样本记忆的更细微风险。相比之下，集中式学习（CL）的最新研究引入了细粒度的方法来评估训练数据所有样本中的记忆，但这些方法假设可以集中访问数据，不能直接应用于FL。", "innovation": "本文提出了一种框架，量化FL中客户内和客户间的数据记忆，采用细粒度的跨样本记忆度量来应用于所有客户。基于此框架，作者进行了两项研究：（1）跨客户测量细微的记忆；（2）探索影响记忆的关键因素，包括解码策略、前缀长度和FL算法。研究结果表明，FL模型更倾向于存储客户内数据，特别是客户间的数据记忆受训练和推理因素的影响。", "conclusion": "FL模型确实存在客户数据记忆的情况，特别是客户内数据的记忆更为显著，跨客户的记忆较少。这些记忆的程度受训练和推理因素的影响。本研究通过细粒度跨样本记忆测量，为FL中的数据记忆检测提供了一个有效的框架。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08748", "html_url": "https://arxiv.org/abs/2510.08748", "title": "Conformal Risk Training: End-to-End Optimization of Conformal Risk Control", "title_en": "Conformal Risk Training: End-to-End Optimization of Conformal Risk Control", "authors": "Christopher Yeh,Nicolas Christianson,Adam Wierman,Yisong Yue", "background": "尽管深度学习模型在预测准确性方面表现出色，但它们的预测通常缺乏关于风险或可靠性的可证明保证，这对于在高风险应用场景中部署模型至关重要。现有的框架，如校验风险控制（CRC），提供了一种在样本有限的情况下控制任意单调损失函数的期望值的方法，可以方便地应用于任何预先训练好的深度学习模型。然而，许多实际应用对尾部风险特别敏感，而不仅仅是期望损失。", "innovation": "本文提出了一种用于控制优化效能等价（OCE）风险的方法，这是一种广泛的风险度量类，包括期望损失（推广了原始CRC方法）和常用的尾部风险如条件价值-at-风险（CVaR）。此外，本文还提出了一种“校验风险训练”方法，这是一种端到端的优化方法，在模型训练或微调过程中通过校验OCE风险控制进行反向传播，以解决标准校验风险控制可能由于缺乏对模型反馈而导致的平均性能下降问题。该方法在控制分类器的假阴性率和控制电池储能操作中的金融风险两个应用上都显著提高了平均性能表现，同时提供了可证明的风险保证。", "conclusion": "本文提出了一种新的端到端优化方法，通过在模型训练或微调过程中引入校验OCE风险控制进行反向传播，同时确保算法能够提供可证明的风险保证，实现更优的平均性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08762", "html_url": "https://arxiv.org/abs/2510.08762", "title": "Spatial Deconfounder: Interference-Aware Deconfounding for Spatial Causal Inference", "title_en": "Spatial Deconfounder: Interference-Aware Deconfounding for Spatial Causal Inference", "authors": "Ayush Khot,Miruna Oprescu,Maresa Schröder,Ai Kagawa,Xihaier Luo", "background": "在空间领域进行因果推断面临两个相互关联的挑战：未测量的空间因素（如天气、空气污染或移动）混淆了处理和结果的关系；邻近处理的干扰违背了标准的无干扰假设。现有方法通常会假设其中一个问题不存在来解决另一个问题，但研究发现这两个问题实际上是紧密相连的，通过处理邻近干扰，可以揭示潜在混杂因素的结构。", "innovation": "提出了一种 Spatial Deconfounder 方法，这是一种两阶段的方法，首先通过条件变分自编码器（CVAE）和空间先验从局部治疗向量中重建替代混杂因子，然后通过灵活的结果模型估计因果效应。该方法在弱假设下可以非参数化识别直击效应和溢出效应，无需多个治疗类型或已知的潜在领域的模型。", "conclusion": "通过将邻近干扰转换为多因信号，该框架将空间和除混文献联系起来，在结构化数据中推动了稳健的因果推断。在实验中，通过扩展 SpaCE（空间混淆基准套件）以包含处理干扰，展示了 Spatial Deconfounder 在环境健康和社会科学领域的实际数据集中的表现改善。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08757", "html_url": "https://arxiv.org/abs/2510.08757", "title": "LOTION: 平滑量化训练的优化景观", "title_en": "LOTION: Smoothing the Optimization Landscape for Quantized Training", "authors": "Mujin Kwun,Depen Morwani,Chloe Huangyuan Su,Stephanie Gil,Nikhil Anand,Sham Kakade", "background": "优化神经网络以适应量化目标本质上具挑战性，因为量化的量化器是分段常数的，这意味着在量化的阈值以外的地方梯度为零，在这些阈值处梯度未定义。大多数现有方法通过使用如直通估计器（STE）等技术来放宽梯度计算，但没有提供任何收敛的保证。受Nesterov平滑的启发，本文提出了一种连续损失曲面逼近方法，引入了LOTION 低精度优化通过随机化舍入噪声平滑，从而用未偏差的随机化舍入噪声下的期望值来替换原始的分段常数损失。在这种框架下，标准优化器可以保证收敛到损失曲面的局部极小值。使用来自随机化舍入噪声的噪声时，这种方法可以保持原始量化损失的全局最小值。实验结果表明，此方法在合成测试平台上和300M参数的语言模型中优于标准量化训练（QAT）.", "innovation": "引入LOTION框架，通过使用未偏差的随机化舍入噪声下的期望值来平滑量化损失，使得标准优化器可以保证收敛到损失曲面的局部极小值，同时使用随机化舍入噪声时可以保持原始量化损失的全局最小值。", "conclusion": "实验结果证明，LOTION方法在合成测试平台和大型语言模型上优于标准量化训练方法，能够更好地优化神经网络以适应量化目标。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08763", "html_url": "https://arxiv.org/abs/2510.08763", "title": "基于虚拟成像试验的CT采集和重建参数的强化学习优化", "title_en": "Reinforcement Learning-Based Optimization of CT Acquisition and Reconstruction Parameters Through Virtual Imaging Trials", "authors": "David Fenwick,Navid NaderiAlizadeh,Vahid Tarokh,Nicholas Felice,Darin Clark,Jayasai Rajagopal,Anuj Kapadia,Benjamin Wildman-Tobriner,Ehsan Samei,Ehsan Abadi", "background": "在CT成像中，优化协议至关重要，以在保证高诊断图像质量的同时最小化辐射剂量。然而，由于CT采集和重建参数间的复杂相互依赖关系，传统的优化方法依赖于大量组合测试这些参数的耗时过程，这往往是不切实际的。", "innovation": "该研究提出了一种结合虚拟成像工具与强化学习的新方法，以更高效地优化CT协议。此方法使用Proximal Policy Optimization（PPO）代理在虚拟成像实验证中训练以最大化特定图像质量指标（肝病变检测指数），且所需步骤比详尽搜索方法减少79.7%，证明了准确性与计算效率。", "conclusion": "该研究提出了一个灵活框架，可以适应多种图像质量指标。研究结果表明虚拟成像工具与强化学习结合可用于CT协议管理，具有巨大的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08768", "html_url": "https://arxiv.org/abs/2510.08768", "title": "在强化学习中使用毕克定理实现零样本策略转移", "title_en": "Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem", "authors": "Francisco Pascoa,Ian Lalonde,Alexandre Girard", "background": "RL策略通常无法在具有不同物理参数的新机器人、任务或环境中泛化，这限制了它们的现实世界应用。", "innovation": "提出了一种基于毕克定理的简单零样本转移方法，该方法通过调整输入（观察）和输出（动作）的维度无量纲空间，无需重新训练，就可将预训练策略适应到新的系统环境中。", "conclusion": "结果显示，比例调整的转移在动态相似的环境下没有性能损失。而在非相似环境中，比例调整的策略始终优于简单的转移策略，显著扩大了原始策略仍然有效的环境范围。这些发现表明，量纲分析提供了一种强大的和实用的工具，以增强RL策略的稳健性和泛化能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08774", "html_url": "https://arxiv.org/abs/2510.08774", "title": "Struc-EMB: 语言嵌入中的结构感知编码潜力", "title_en": "Struc-EMB: The Potential of Structure-Aware Encoding in Language Embeddings", "authors": "Shikun Liu,Haoyu Wang,Mufei Li,Pan Li", "background": "大型语言模型（LLMs）的文本嵌入已成为众多应用的基础，但这些模型通常仅处理原始文本，忽略了链接或引用等丰富的结构信息，这些结构信息在许多实际数据集中提供关键背景。这项研究通过将这些结构关系直接集成到LLM的内部编码过程中，而不是依赖传统的后续聚合，提出了并系统评估了一种新的生成结构感知文本嵌入的新范式。", "innovation": "研究引入并系统评估了一种新的范式，通过直接将结构关系整合到LLM的内部编码过程中，生成结构感知的文本嵌入。研究还介绍并验证了两种有效的技术：Context Distillation和Semantic Balancing，以应对噪声结构数据的挑战。", "conclusion": "研究成果提供了对内部结构感知编码的首份全面分析，为构建更强大且语境感知的嵌入模型提供了蓝图。研究结果表明，结构感知方法在零样本实验中的一系列检索、聚类、分类和推荐任务中始终优于纯文本和后续聚合基线，揭示了序列拼接和并行缓存两种方法的权衡：序列拼接适用于嘈杂且中等长度的上下文，而并行缓存则更适用于长而高信号的长上下文，但更容易受到干扰的影响。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08780", "html_url": "https://arxiv.org/abs/2510.08780", "title": "神经网络函数近似中的权重初始化", "title_en": "Weights initialization of neural networks for function approximation", "authors": "Xinwen Hu,Yunqing Huang,Nianyu Yi,Peimeng Yin", "background": "神经网络基于函数近似在科学计算和机器学习中发挥着关键作用，但训练这类模型面临诸多挑战：(i) 每个目标函数通常需要从头开始训练一个新的模型；(ii) 性能高度依赖于架构和超参数的选择；(iii) 模型经常在超出训练域的情况下表现不佳。", "innovation": "本研究提出了一种基于基函数预训练的可复用初始化框架。该框架首先在参考域上训练基神经网络以近似多项式族，然后利用这些学到的参数初始化更复杂的目标函数网络。为了增强跨任意域的适应性，还引入了一种域映射机制，将输入转换为参考域，从而保持与预训练模型的结构对应。", "conclusion": "在单个和二维设置下的广泛数值实验表明，在训练效率、泛化能力和模型可转移性方面取得了显著改善，突显了基于初始化策略的可扩展和模块化神经网络函数近似的潜力。完整的代码已公开发布在Gitee上。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08779", "html_url": "https://arxiv.org/abs/2510.08779", "title": "通过LLM增强观察指导强化学习中的探索", "title_en": "Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations", "authors": "Vaibhav Jain,Gerrit Grossmann", "background": "在稀疏奖励环境中，传统的强化学习（RL）探索策略往往难以发现有效的行动序列，而大型语言模型（LLMs）具有来自文本预训练的程序性知识和推理能力，可以指导RL探索。然而现有的方法会导致RL策略对LLM建议产生刚性依赖，需要完全遵循LLM建议或直接将其纳入奖励函数中。本文旨在提供一种框架，通过增强观察空间传递由LLM生成的动作建议，使RL代理能够学习何时遵循或忽略这种指导，从而在保持灵活性的同时利用LLM的世界知识和推理能力。", "innovation": "本文提出了一种框架，通过增强观察空间传递由LLM生成的动作建议，使得RL代理能够学习何时遵循或忽略这种指导。这种方法利用了LLM的世界知识和推理能力，并通过软约束保持了灵活性。实验结果显示，在三个逐渐增加复杂性的BabyAI环境中，LLM指导的好处随着任务难度的增加而增加，在最具有挑战性的环境中，相比基线方法，成功率达到71%的相对改善。并且，该方法提供了显著的样本效率提升，代理可提前9倍时间达到性能门槛，且无需对现有的RL算法进行修改。实验结果证明了利用LLM规划能力加速RL训练的有效性方法在这种具有挑战性的环境中是有效的。", "conclusion": "本文提出的方法展示了通过增强观察空间中的LLM生成的动作建议指导RL探索的有效性，特别是在具有挑战性的环境中，这种方法能够提高样本效率并显著减少达到性能门槛所需的时间。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08797", "html_url": "https://arxiv.org/abs/2510.08797", "title": "TAPAS: 用于学习误差问题的数据集", "title_en": "TAPAS: Datasets for Learning the Learning with Errors Problem", "authors": "Eshika Saxena,Alberto Alfarano,François Charton,Emily Wenger,Kristin Lauter", "background": "在后量子密码学中，学习误差问题（LWE）是一个重要的难计算问题。基于人工智能（AI）的攻击方法在某些参数设置下能够与传统方法抗衡甚至超越传统方法。尽管这种新的方法具有潜力，但由于缺乏可访问的数据，限制了AI实践者的研究和改进。目前，创建适用于AI模型训练的LWE数据集需要大量时间和计算资源，并且需要大量专业知识。", "innovation": "本研究提出了TAPAS数据集，为后量子密码学领域中的AI系统分析提供了工具包。这些数据集覆盖了多个LWE设置，AI实践者可以使用这些数据集来快速原型化破解LWE的新方法。此外，该研究还记录了TAPAS数据集的创建过程，建立了攻击性能的基础线，并指出了未来的研究方向。", "conclusion": "通过提供易于使用的LWE数据集，TAPAS目标是加快AI在LWE攻击研究中的应用，从而促进该领域的未来发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08794", "html_url": "https://arxiv.org/abs/2510.08794", "title": "多臂bandit中的欺骗性探索", "title_en": "Deceptive Exploration in Multi-armed Bandits", "authors": "I. Arda Vurankaya,Mustafa O. Karabag,Wesley A. Suttle,Jesse Milzman,David Fridovich-Keil,Ufuk Topcu", "background": "本文研究了一个多臂bandit设置，其中每个臂具有公共和私有奖励分布。观察者期望代理遵循公共奖励的Thompson Sampling规则，而欺骗性代理则试图迅速识别出最优的私有臂而不被察觉。观察者可以观察到公共奖励和被拉的臂，但无法观察到私有奖励。代理则可以同时观察到公共和私有奖励。", "innovation": "定义可检测性为实际使用的拉臂概率与观察者预期的拉臂概率之间的逐步Kullback-Leibler (KL) 距离约束。代理成功拉拔公共次优臂被建模为一个伯努利过程，其中成功率随着每次成功的拉拔而减少，并且在KL约束下这些拉拔最多可以以Θ(√T)的速度发生。基于公共和私有平均值，提出了一个最大化-minim化问题，其解表征了在识别最优私有臂方面的最优错误指数。此外，还提出了一种基于top-two算法的算法，该算法根据公共次优臂的难度自动调整其探索策略。", "conclusion": "证明了公共次优臂的拉取次数为Θ(√T)，并提供了数值示例来说明该结果以及提出算法的行为。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08808", "html_url": "https://arxiv.org/abs/2510.08808", "title": "TinyGraphEstimator：采用轻量级语言模型进行图结构推理", "title_en": "TinyGraphEstimator: Adapting Lightweight Language Models for Graph Structure Inference", "authors": "Michal Podstawski", "background": "图用于表示复杂的关联系统，推断其结构特性是图分析和推理的核心挑战。虽然大型语言模型已经展示出执行符号和数值推理的能力，但在这一领域中，小型、资源效率高的模型的潜力尚未得到充分探索。", "innovation": "本研究探讨了是否可以通过使用紧凑的变换器基语言模型直接从文本图表示中推断出图论参数。为此，引入了TinyGraphEstimator数据集——一个从多种随机图模型生成、并带有详细结构元数据的平衡图集。研究通过几个小型开放模型评估了其预测关键图参数（如密度、聚类和色数）的能力，并利用Low-Rank Adaptation（LoRA）技术进行了轻量级微调，实现了所有评估指标的一致提升。结果显示，小型语言模型在图结构数据上具有非平凡的推理能力，并可以通过有效的参数调整实现结构推理任务的有效适配。", "conclusion": "小型语言模型具有在图结构数据上进行非平凡推理的能力，并且可以通过高效的参数调整适应结构推理任务。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08802", "html_url": "https://arxiv.org/abs/2510.08802", "title": "Edu-EmotionNet: 交叉模态注意对齐与时间反馈循环", "title_en": "Edu-EmotionNet: Cross-Modality Attention Alignment with Temporal Feedback Loops", "authors": "S M Rafiuddin", "background": "在线教育中理解学生的情感对于提高参与度和个性化教学至关重要。尽管此前在情感识别方面的研究探讨了多模态融合和时间建模，但现有方法往往依赖于静态融合策略，并假设不同模态的输入始终可靠，而在实际的学习环境中这往往是不成立的。", "innovation": "我们提出了一种名为Edu-EmotionNet的新框架，该框架可以联合模型时间维度情感演化和模态可靠性，以实现稳健的效用识别。该模型包含了三个关键组件：一种跨模态注意力对齐模块（CMAA），用于动态的跨模态上下文共享；一种模态重要性估计器（MIE），可以在每个时间步骤为每个模态分配基于信心的权重；以及一种时间反馈循环（TFL），通过利用先前的预测来确保时间一致性。", "conclusion": "在带有重新注释的IEMOCAP和MOSEI教育子集中，针对困惑、好奇、无聊和挫败情感进行了评估，Edu-EmotionNet达到了最先进的性能，并在缺乏或存在噪声的模态下展现出强大的鲁棒性。可视化结果证实了它能够捕捉情感转变并自适应地优先考虑可靠的信号，使其非常适合部署在实时学习系统中。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08836", "html_url": "https://arxiv.org/abs/2510.08836", "title": "通过信息保全两阶段学习的长尾认识", "title_en": "Long-Tailed Recognition via Information-Preservable Two-Stage Learning", "authors": "Fudong Lin,Xu Yuan", "background": "长尾分布是许多现实世界数据分布的自然特性，这往往导致深度分类模型对常见类别有偏见，从而导致尾部类别的性能较差。", "innovation": "本文提出了一种新颖的两阶段学习方法，旨在减轻这种多数倾向，同时保存数据集中的有价值信息。第一阶段提出了一种新的信息理论视角下的表示学习技术，该方法在理论上与最小化类内距离等效，从而产生有效的和区分度高的特征空间。第二阶段开发了一种新的采样策略，从中选择了具有数学信息量的实例，能够在不牺牲模型整体性能的情况下纠正多数倾向的决策边界。", "conclusion": "我们的方法在各种长尾基准数据集上取得了最先进的性能，通过广泛的实验得到了验证。我们的代码可通过以下链接获取：this https URL"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08795", "html_url": "https://arxiv.org/abs/2510.08795", "title": "PO-CKAN：具有分块有理结构的物理知情深度算子柯尔莫哥洛夫-阿诺德网络", "title_en": "PO-CKAN:Physics Informed Deep Operator Kolmogorov Arnold Networks with Chunk Rational Structure", "authors": "Junyi Wu,Guang Lin", "background": "论文提出了一种基于分块有理柯尔莫哥洛夫-阿诺德网络(CKAN)的新颖深度算子框架PO-CKAN，用于近似偏微分方程的近似求解器。该框架结合了物理信息神经网络(PINNs)的原则，以确保物理一致性。PO-CKAN采用了分支-主干架构，并使用理KAN模块实例化其子网络，通过PDE残差（PINN风格）损失来确保物理一致性。该模型在多个基准测试问题上进行了验证，结果显示其能够准确地学习物理一致的空间-时间解算子，并在参数可变的动态PDE预测中表现出快速预测能力。", "innovation": "1. 基于分块有理柯尔莫哥洛夫-阿诺德网络(CKAN)的深度算子框架设计。\n2. 结合物理信息神经网络(PINNs)的原则，确保学习的算子具有物理一致性。\n3. 在分支-主干架构中使用理KAN模块实例化子网络，通过PDE残差（PINN风格）损失来实现物理一致性。\n4. 在Burgers'方程、Eikonal方程和扩散-反应方程等多个基准问题上取得了显著的性能改进，相比其他方法，如PI-DeepONet，显著降低了L2范数的平均相对误差。", "conclusion": "PO-CKAN模型在多个基准测试问题上展示了准确的算子学习能力，逼近高精度解。它能够通过在给定的物理一致条件下快速预测参数变化的时间依赖偏微分方程的解，为求解复杂的偏微分方程提供了一个有效的工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08839", "html_url": "https://arxiv.org/abs/2510.08839", "title": "基于强化学习的边缘管理以实现可靠的多视角3D重建", "title_en": "Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction", "authors": "Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy", "background": "实时多视角3D重建在关键边缘本地应用中至关重要，例如火灾救援。即时准确的3D场景建模能够提升现场态势感知和决策制定。然而，边缘资源的动态和不可预测性导致性能下降，网络链接不稳定、服务器负载波动等挑战，影响重建的可靠性。针对这一问题，本文提出了一个基于强化学习的边缘资源管理框架，通过两个协作的Q-learning代理分别进行相机和服务器的选择，目标是在资源有限且充满干扰的环境中确保高质量的3D重建，并有效平衡端到端延迟和重建质量。这种框架借助分布式测试床来模拟智能城市边缘基础设施，在真实的干扰环境中进行性能评估，以支持学习并验证系统表现。", "innovation": "提出了一个基于强化学习的边缘资源管理框架，通过两个在线协作的Q-learning代理分别进行相机和服务器的选择，以确保资源有限、充满干扰环境下高质量3D重建的可靠性。该框架在分布式测试床上进行了实现并模拟了智能城市边缘基础设施下的真实干扰场景，以支持学习并评估系统性能。", "conclusion": "提出的框架通过有效平衡端到端延迟和重建质量，在动态环境中显著提高了应用的可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08852", "html_url": "https://arxiv.org/abs/2510.08852", "title": "自监督对比学习与监督学习之间的对齐", "title_en": "On the Alignment Between Supervised and Self-Supervised Contrastive Learning", "authors": "Achleshwar Luthra,Priyadarsi Mishra,Tomer Galanti", "background": "自监督对比学习（CL）已经取得了显著的经验成功，经常生成的表现达到甚至超过在下游任务上使用监督预训练的效果。最近的理论表明，当类别数量增加时，CL损失可以近似负样例仅监督对比学习（NSCL）损失。然而，这种损失级别的相似性未能解释CL和NSCL在整个训练过程中是否保持在表示水平上的对齐，尤其是在目标层面之外。因此，本文旨在研究共享随机性的CL和NSCL模型的表示对齐情况，即相同初始化、批次和增强的条件下训练的CL和NSCL模型是否保持相似的表示。", "innovation": "本文通过分析共享随机性的CL和NSCL模型的表示对齐情况，提出了相似矩阵的边界，提供强概率保障的对齐度量（如中心核对齐度量和表示相似性分析），并阐明了这些对齐度量随类别数量、温度和批次大小的变化情况。此外，本文展示了参数空间耦合的固有不稳定性，即CL和NSCL的权重差异在训练过程中可以呈指数增长。最后，通过实验验证，体现了CL-NSCL对齐随着规模和温度的增强，以及NSCL比其他监督目标更紧密地跟踪CL。", "conclusion": "我们的研究将NSCL定位为自监督学习和监督学习之间的一座原则性的桥梁。相关代码和项目页面请点击相关链接获取。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08840", "html_url": "https://arxiv.org/abs/2510.08840", "title": "医学影像预后公平AI的边界：因果视角", "title_en": "The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective", "authors": "Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang", "background": "随着机器学习（ML）算法在医学影像分析中的应用越来越广泛，人们对这些算法潜在的某些社会群体偏见表示关注。尽管已经提出了许多确保ML模型公平性的方法，但大多数现有研究仅集中在医学影像诊断任务上，如图像分类和分割，而忽视了预后场景，即预测某种医疗状况的可能结果或进展。为了填补这一空白，本文介绍了首个评估医学影像时间到事件（TTE）预测公平性的全面框架——FairTTE。FairTTE覆盖了多种影像模态和TTE结果，结合最新的TTE预测和公平性算法，实现了对医学影像预后公平性的系统和细致分析。利用因果分析技术，FairTTE揭示并量化了医学影像数据集中嵌入的不同偏见来源。", "innovation": "本文提出了首个全面评估医学影像时间到事件（TTE）预测公平性的框架——FairTTE。FairTTE采用了最新的TTE预测和公平性算法，结合因果分析技术，实现了对医学影像预后公平性的系统和细致分析。该框架覆盖了多种影像模态和TTE结果，深入揭示并量化了不同偏见来源，并发现当前的公平性方法只能在一定程度上缓解偏差。", "conclusion": "大规模评估表明，偏见在不同的影像模态中普遍存在，目前的公平性方法提供的缓解有限。研究还揭示了潜在偏见来源与模型差异之间的强烈关联，强调了需要全面的方法来针对所有类型的偏见。而且，研究还发现，公平性在数据分布偏移下更加难以维持，这突显了现有解决方案的局限性和建立更稳健、更公正的预后模型的迫切需求。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08855", "html_url": "https://arxiv.org/abs/2510.08855", "title": "时间感知的特征选择：基于统计阈值的自适应动态屏蔽训练稳固稀疏自编码器", "title_en": "Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training", "authors": "T. Ed Li,Junyu Ren", "background": "理解大型语言模型内部的表示对于确保其可靠性和安全性至关重要，稀疏自编码器（SAEs）作为一种有前景的可解释性方法正逐渐受到关注。然而，当前SAE的训练方法面临特征吸收的问题，即特征（或神经元）会被吸收到彼此中以最小化$L_1$惩罚，使得很难一致地识别和分析模型行为。这就需要一种新的训练方法来克服这一问题，改善特征选择和模型的稳定性与可靠性。", "innovation": "本文提出了自适应时间屏蔽（ATM），这是一种新颖的训练方法，通过动态调整特征选择，跟踪激活大小、频率和重建贡献计算出随时间变化的重要性分数。ATM基于统计阈值应用概率性屏蔽机制，产生了更自然的特征选择过程。实验表明，ATM在Gemma-2-2b模型上的吸收分数显著低于现有方法如TopK和JumpReLU SAEs，同时保持了出色的重构质量。这表明ATM是一种学习稳定、可解释特征的原理性解决方案，为更可靠模型分析提供了基础。", "conclusion": "研究结果表明，ATM通过动态调整特征选择，显著降低了吸收分数，同时保持了良好的重构质量，进一步证明了它在学习稳定、可解释特征方面的有效性，为模型分析提供了可靠的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08899", "html_url": "https://arxiv.org/abs/2510.08899", "title": "基于归因的可信强化学习中的关键步骤精准赋予权重", "title_en": "Pinpointing crucial steps: Attribution-based Credit Assignment for Verifiable Reinforcement Learning", "authors": "Junxi Yin,Haisen Luo,Zhenyu Li,Yihua Liu,Dan Liu,Zequn Li,Xiaohang Xu", "background": "当前使用可验证奖励的强化学习（RLVR）在大规模语言模型（LLMs）中增强了复杂的推理能力，但现有的方法在探索与开发之间难以取得平衡，这导致了诸如中间步骤的不准确信用分配和过早的熵塌陷等问题，限制了模型的性能。", "innovation": "提出了一种基于归因的策略优化贡献度框架（ACPO），这是一种带有难度感知课程的分阶段框架，通过轨迹语义分割和基于归因的表示动态调节策略熵，从而缓解了其塌陷问题；同时，通过分解奖励系统精确量化每个推理步骤的层级贡献，确保准确的信用分配。", "conclusion": "针对挑战性的基准测试（包括AIME、MATH和AMC），ACPO方法显著优于现有的先进方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08911", "html_url": "https://arxiv.org/abs/2510.08911", "title": "IoV SPS 中基于速度和密度的 RRI 分析与优化以最小化 AoI", "title_en": "Velocity and Density-Aware RRI Analysis and Optimization for AoI Minimization in IoV SPS", "authors": "Maoxin Ji,Tong Wang,Qiong Wu,Pingyi Fan,Nan Cheng,Wen Chen", "background": "在半持续调度（SPS）的车联网（IoV）场景中，由于车辆速度相关信道不确定性和数据包碰撞等因素导致的信息年龄（Age of Information, AoI）劣化问题亟待解决。", "innovation": "提出了基于大型语言模型（LLM）和深度确定性策略梯度（DDPG）的优化方法，建立了一个受车辆速度、密度和资源预留间隔（RRI）影响的AoI计算模型，并设计了双路径优化方案。", "conclusion": "实验结果表明，LLM能够在无需模型训练的情况下显著减少AoI，且只需少量示例即可；而DDPG在训练后能实现更稳定的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08865", "html_url": "https://arxiv.org/abs/2510.08865", "title": "高保真度批主动性学习的高斯过程分类器", "title_en": "Multi-fidelity Batch Active Learning for Gaussian Process Classifiers", "authors": "Murray Cutforth,Yiming Yang,Tiffany Fan,Serge Guillas,Eric Darve", "background": "许多科学和工程问题依赖于昂贵的计算模拟，多保真度方法可以加速对参数空间的探索。本研究探讨了在二元模拟输出情况下，使用高斯过程（GP）模型高效分配模拟预算的方法。", "innovation": "本文引入了一种批量主动学习算法BPMI（Bernoulli Parameter Mutual Information），适用于多保真度GP分类器。BPMI通过应用链接函数的一阶泰勒展开来规避在概率空间中计算互信息的复杂性。", "conclusion": "在所有实验中，BPMI表现出优异性能，对于固定计算预算，实现了更高的预测准确性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08882", "html_url": "https://arxiv.org/abs/2510.08882", "title": "改进的模型自由决策估计系数及其在对抗MDP中的应用", "title_en": "An Improved Model-Free Decision-Estimation Coefficient with Applications in Adversarial MDPs", "authors": "Haolin Liu,Chen-Yu Wei,Julian Zimmert", "background": "该研究聚焦决策制定中的结构化观察（DMSO），这是以前学者通过决策估计系数（DEC）来定义复杂性的研究的延续。之前的两个研究（Foster等，2021b, 2023a）已经定性地定义了DEC，尽管确定了DEC的大致范围，但尚存在不确定性。Foster等（2023b）提出了乐观的DEC，但这只能适用于随机环境，对于对抗环境尚未明确。本文旨在改进DEC，提供适用于对抗MDP的解决方案，同时优化在线函数估计程序，并改善了其在特定情境下的表现限制。", "innovation": "提出了无乐观偏置的DEC——Dig-DEC，该方法通过信息增益驱动探索，而不是像乐观DEC那样通过乐观偏置来探索。Dig-DEC不仅在理论上下限更为紧密，而且对于对抗环境也无需显式奖励估计器。此外，通过使用Dig-DEC应用于混合MDP，并实现了首个关于具有拉格纳随机性和对抗奖励问题的混合MDPs具有一定通用转移结构的模型自由的遗憾界限。同时，作者还改进了模型自由学习中的在线函数估计过程，改进了遗憾界限，特别是在贝尔曼完备MDP中实现了与乐观偏置方法相当的效果。", "conclusion": "本文改进了无模型决策估计系数，提出Dig-DEC并将其应用于对抗MDP，实现了首次针对混合MDP的无模型遗憾界限。此外，作者还改善了无模型学习中的在线函数估计过程，使遗憾界限得到了显著改进，特别在贝尔曼完备MDP中实现了与其他乐观方法相当的效果。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08858", "html_url": "https://arxiv.org/abs/2510.08858", "title": "稀疏成分区分视觉路径及其与神经网络的对齐", "title_en": "Sparse components distinguish visual pathways & their alignment to neural networks", "authors": "Ammar I Marvi,Nancy G Kanwisher,Meenakshi Khosla", "background": "人类高级视觉皮层的腹侧、背侧和侧侧流被认为执行不同的功能过程。尽管如此，单任务训练的人工神经网络（DNNs）能够很好地模拟整个视觉系统，这暗示了这些路径中的共同计算原理。为了探讨这种不一致，本文利用了一种新颖的稀疏分解方法来识别每条视觉流中的主导视觉表示成分。结果显示，这三条视觉流中的成分响应模式存在明显的差异，特别是在每条流中定义了对面孔、地点、身体、文本和食物的选择性成分，社交互动、暗示的运动以及手部动作等成分也得到了识别。这进一步揭示了DNNs与人类大脑的视觉流之间的对齐问题，DNNs在腹侧流中的对齐度高于背侧流和侧侧流。使用该方法，研究发现，标准视觉DNNs与腹侧流的对齐度优于背侧流和侧侧流的对齐度。稀疏成分分析（SCA）清晰地揭示了这些差异，优于传统的群体层面几何分析，是一种更敏感于该系统潜在的神经调谐轴的表示对齐度的度量方法。", "innovation": "本文介绍了一种新的方法——稀疏成分对齐（Sparse Component Alignment，SCA），用于衡量大脑和机器之间的表示对齐。这种方法比传统的群体层面几何分析更精确，能够更好地捕捉这两个视觉系统中的潜在神经调谐。SCA揭示了标准视觉DNNs与腹侧流的对比度高于背侧流和侧侧流，这种对齐度的测量是对系统潜在神经调谐轴的更敏感度量。", "conclusion": "标准视觉DNNs在视觉表示上与腹侧流的对齐度优于背侧流和侧侧流，这表明神经网络与大脑不同视觉流中的对齐程度存在差异。SCA能够在更高的分辨率上揭示这些差异，为理解视觉系统中相关的神经调谐提供了新的工具和方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08908", "html_url": "https://arxiv.org/abs/2510.08908", "title": "频域分析的多臂赌博机问题：探索-利用权衡的新视角", "title_en": "A Frequency-Domain Analysis of the Multi-Armed Bandit Problem: A New Perspective on the Exploration-Exploitation Trade-off", "authors": "Di Zhang", "background": "多臂赌博机（MAB）问题是序贯决策中最基本的模型之一，核心挑战在于探索与利用之间的权衡。尽管已有算法如上确界法（UCB）和汤普森采样及其相关的后悔理论已经建立，但现有的分析主要从时间域和累积后悔的角度出发，难以刻画学习过程中的动态特性。", "innovation": "本文提出了一种新颖的频域分析框架，将赌博机过程重新表述为信号处理问题。在这一框架中，每个臂的奖励估计被视为频谱成分，其不确定性对应于该成分的频谱，博彩算法被解释为自适应滤波器。基于此框架，作者还构造了一个正式的频域赌博机模型，并证明了主要定理：UCB算法中的置信度边界术语在频域中等价于对不确定的频谱成分应用的一种时间变化增益，该增益与访问次数的平方根成反比。进一步推导出了关于探索率衰减的有限时动态边界，该理论不仅为经典算法提供了新的直观物理解释，也为设计具有自适应参数调整的新一代算法奠定了坚实的理论基础。", "conclusion": "本文不仅为经典的探索-利用权衡问题提供了新的物理解释，还为算法设计提供了一个分析工具，有助于进一步研究和改进多臂赌博机问题中探索与利用之间的权衡问题。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08920", "html_url": "https://arxiv.org/abs/2510.08920", "title": "用表格基础模型进行时空相关的小地球数据的简单且稳健预测", "title_en": "Simple and Robust Forecasting of Spatiotemporally Correlated Small Earth Data with A Tabular Foundation Model", "authors": "Yuting Yang,Gang Mei,Zhengjing Ma,Nengxiong Xu,Jianbing Peng", "background": "小地球数据是具有有限短期监测变异性的地球科学观测数据，尽管其规模较小，但提供了稀疏但有意义的测量值，通常表现出时空相关性。对于如此数据的时空预测对于理解地球科学过程至关重要，尽管模型需要针对不同场景进行特定任务的训练，这在传统深度学习模型中很常见。基础模型不需要针对特定任务进行训练，但它们通常会由于预训练分布的全局均值偏差而在预测中表现不佳。", "innovation": "提出了一种简单且鲁棒的时空相关小地球数据预测方法。方法通过表征和量化小地球数据的时空模式，并利用表格基础模型进行准确的跨场景预测。实验结果表明，该方法在多数情况下比图深度学习模型（T-GCN）和表格基础模型（TabPFN）具有更优的预测准确性和更强的鲁棒性。", "conclusion": "与图深度学习模型（T-GCN）和表格基础模型（TabPFN）相比，所提出的方法在三种典型场景下大多实现了更好的预测准确性和更强的鲁棒性，表明此方法对于时空相关小地球数据的预测是有效且鲁棒的。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08924", "html_url": "https://arxiv.org/abs/2510.08924", "title": "AB-PINNs: 自适应基底物理感知神经网络在残差驱动的域分解中的应用", "title_en": "AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition", "authors": "Jonah Botvinick-Greenhouse,Wael H. Ali,Mouhacine Benosman,Saviz Mowlavi", "background": "该论文介绍了一种新的算法——自适应基底物理感知神经网络（AB-PINNs），这种算法用于PINNs训练中的领域分解。通过借鉴古典的网格细化技术，随着训练过程中残差损失的增大，在高损失区域动态地引入新的子域，以适应未知解的内在特征。这种方法适用于多尺度问题，因为不同的子域可以学习捕捉不同尺度的解。此外，这种方法的收敛性更好，能够避免陷入不必要的局部极小值。", "innovation": "AB-PINNs方法通过在训练过程中动态地调整领域分解，根据残差损失引入新的子域，以适应未知解的内在特征。这种方法有助于捕捉多尺度问题中的不同尺度，能够避免算法在静态领域分解方法中容易陷入局部极小值的问题。而且，这种方法减少了对大量超参数调整的依赖。", "conclusion": "AB-PINNs算法在解决各种复杂的多尺度偏微分方程问题上表现出色，动态地调整领域分解，以适应未知解的内在特征，从而提高了算法的灵活性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08938", "html_url": "https://arxiv.org/abs/2510.08938", "title": "使用多级元策略控制进行动态不确定性校准的实证深度学习", "title_en": "Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning", "authors": "Zhen Yang,Yansong Ma,Lei Chen", "background": "传统的实证深度学习（EDL）方法依赖于静态超参数进行不确定性校准，这限制了在动态数据分布中的适应性，导致在高风险决策任务中的校准和泛化表现不佳。", "innovation": "提出了一种动态元学习框架——Meta-Policy Controller (MPC)，能够调整KL散度系数和Dirichlet先验强度，以实现最佳的不确定性建模。MPC采用了多级优化方法：内部循环中通过动态配置的损失函数更新模型参数；外部循环中策略网络优化KL散度系数和类特定的Dirichlet先验强度，基于多目标奖励平衡预测精度和不确定性质量。", "conclusion": "广泛的实验结果表明，MPC 显著增强了模型预测的可靠性和校准能力，并在各种任务中提高了不确定性校准、预测准确性和基于信心的样本拒绝后的表现保留。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08944", "html_url": "https://arxiv.org/abs/2510.08944", "title": "Variability Aware Recursive Neural Network (VARNN): 一种用于序列回归建模捕捉时间偏差的残差记忆模型", "title_en": "Variability Aware Recursive Neural Network (VARNN): A Residual-Memory Model for Capturing Temporal Deviation in Sequence Regression Modeling", "authors": "Haroon Gharwi,Kai Shu", "background": "现实世界的时间序列数据表现出非平稳性、制度转变和随时间变化的噪声（异方差性），这些都会降低标准回归模型的稳健性。", "innovation": "提出了 Variability-Aware Recursive Neural Network (VARNN)，这是一种新型的残差感知架构，用于监督时间序列回归。VARNN 通过从近期预测残差中学习显式的误差记忆，并利用它来重新校准后续预测，来应对这些挑战。VARNN 增强了反馈预测器，加入了由短期上下文步长中的残差更新的学习误差记忆状态，该状态作为一种变异性与漂移的信号，从而在当前时间步状态下调整最终预测。实验结果表明，VARNN 在不同数据集领域（如家电能源、医疗保健和环境监测）中，能够实现优于静态、动态和递归基线的更好性能，并且具有更低的测试均方误差和最小的计算开销。", "conclusion": "我们的研究结果表明，VARNN 模型在漂移和波动环境下提供了稳健的预测，这表明它作为时间序列学习的一种有前景框架的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08952", "html_url": "https://arxiv.org/abs/2510.08952", "title": "当LLM代理遇到图优化：一种自动化的数据质量改进方法", "title_en": "When LLM Agents Meet Graph Optimization: An Automated Data Quality Improvement Approach", "authors": "Zhihan Zhang,Xunkai Li,Yilong Zuo,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang", "background": "文本归属图（TAGs）作为一种结合了结构连接和细微语义的强大表示方式，支持多种数据导向的应用。然而，图神经网络（GNNs）在处理TAGs时对输入质量极为敏感。现有研究通常集中在模型架构的改进上，而忽视了系统性优化TAG数据本身，导致实际效果有限。我们的实验研究表明，无论是传统GNN还是增强型GNN，在代表性的稀疏、噪声和不平衡等九种情景中都表现出显著的性能退化，突显了图质量作为关键瓶颈。", "innovation": "我们提出了LAGA（大型语言和图代理），这是一种统一的多代理框架，将图质量控制视为一个中心的数据导向问题。LAGA集成了检测、规划、行动和评估四个协作代理，形成一个自动化的闭环。行动代理采用双编码器和三目标设计，捕捉不 同模态之间的互补信息，实现整体的图质量提升。实验表明，LAGA在各种任务和模型基础下都能提高图质量并获得最先进的性能，验证了以数据为中心的质量优化对于可靠TAG和稳健图学习的关键作用。", "conclusion": "实验结果表明，LAGA能够在各种情况下改善图质量，并在多种任务和模型架构上实现了最先进的性能，验证了以数据为中心的质量优化对于可靠TAG和稳健图学习的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08962", "html_url": "https://arxiv.org/abs/2510.08962", "title": "低资源数据学习综述：从分析到调查", "title_en": "Analytical Survey of Learning with Low-Resource Data: From Analysis to Investigation", "authors": "Xiaofeng Cao,Mingwei Xu,Xin Yu,Jiangchao Yao,Wei Ye,Shengjun Huang,Minling Zhang,Ivor W. Tsang,Yew Soon Ong,James T. Kwok,Heng Tao Shen", "background": "高资源数据在人工智能方面取得了显著的成功，但数据注释和模型训练的成本依然很高。低资源数据学习是AI研究的一个基本目标，旨在有限资源下实现鲁棒泛化。本文通过在可能正确(PAC)框架下的agnostic主动采样理论分析了低资源数据学习中的泛化误差和标签复杂度，在模型无关的监督学习和无监督学习中进行了具体研究。", "innovation": "本文引入了一套针对低资源数据学习的优化策略，包括基于梯度的信息优化、元迭代优化、几何意识优化以及大语言模型驱动的优化。此外，还综述了多种可以从低资源数据中受益的学习范式，如领域迁移、强化反馈和层次结构建模。", "conclusion": "本文总结了关键发现，并指出了它们在低资源数据学习中的重要意义。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08932", "html_url": "https://arxiv.org/abs/2510.08932", "title": "MATT-CTR：基于置信引导的推理路径实现CTR预测的模型无关测试时 paradigm", "title_en": "MATT-CTR: Unleashing a Model-Agnostic Test-Time Paradigm for CTR Prediction with Confidence-Guided Inference Paths", "authors": "Moyu Zhang,Yun Chen,Yujun Jin,Jinxin Hu,Yu Zhang,Xiaoyi Zeng", "background": "近年来，研究重点主要集中在优化点击率CTR模型架构以更好地建模特征交互，或者改进训练目标以辅助参数学习，从而提高预测性能。然而，以往的研究主要关注训练阶段，忽略了在推理阶段进行优化的机会。特别地，罕见的特征组合会导致预测性能下降，从而产生不可靠或低置信度输出。为了充分利用已训练的CTR模型的预测潜力，我们提出了一种模型无关的测试时推理（Model-Agnostic Test-Time，MATT）框架，该框架利用特征组合的置信度评分来指导生成多种推理路径，从而减轻低置信度特征对最终预测的影响。在不同的特征组合上，我们通过层次概率哈希方法估计它们在各个阶次中的出现频率，用作它们的置信度评分。然后，按照置信度评分作为抽样概率进行迭代抽样，生成多条特定实例的推理路径，从而通过聚合多条路径的预测得分来进行稳健的预测。", "innovation": "我们提出了一种模型无关的测试时推理（MATT）框架，通过利用特征组合的置信度评分来指导生成多种推理路径，减轻低置信度特征对最终预测的影响。具体而言，我们引入了一种层次概率哈希方法来估计特征不同阶次的组合频率，作为它们的置信度评分，并按照这些评分生成多个推理路径以进行稳健预测。", "conclusion": "对现有CTR模型的广泛离线实验和在线A/B测试验证了MATT框架的兼容性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08965", "html_url": "https://arxiv.org/abs/2510.08965", "title": "HiBBO: HiPPO 基本的空间一致性用于高维贝叶斯优化", "title_en": "HiBBO: HiPPO-based Space Consistency for High-dimensional Bayesian Optimisation", "authors": "Junyu Xuan,Wenlong Chen,Yingzhen Li", "background": "贝叶斯优化（BO）是一种用于优化昂贵的黑盒函数的强大工具，但在高维空间中其效果会减弱，因为数据稀疏和人造模型扩展性差。尽管基于变分自动编码器（VAE）的方法通过学习低维潜空间来解决这一问题，但基于重建的目标函数常常导致潜空间与原始空间的功能分布不匹配，从而导致优化性能不佳。", "innovation": "本文首先分析了仅使用重建损失可能导致分布不匹配的原因，然后提出了一种名为HiBBO的新型BO框架，该框架借助HiPPO方法构建潜空间中的空间一致性，从而使潜空间与原始空间之间的功能分布差异减少。在高维基准任务上的实验表明，HiBBO在收敛速度和解决方案质量方面优于现有的VAEBO方法。我们的工作填补了高维序列表示学习与高效的贝叶斯优化之间的差距，使神经架构搜索、材料科学等领域的应用更广泛。", "conclusion": "我们的工作填补了高维序列表示学习与高效的贝叶斯优化之间的差距，使神经架构搜索、材料科学等领域的应用更广泛。在高维基准任务上的实验显示，与现有的VAEBO方法相比，HiBBO在收敛速度和解决方案质量方面都表现出更好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08984", "html_url": "https://arxiv.org/abs/2510.08984", "title": "FedL2T：为癫痫预测的个性化联邦学习与双师知识蒸馏", "title_en": "FedL2T: Personalized Federated Learning with Two-Teacher Distillation for Seizure Prediction", "authors": "Jionghao Lou,Jian Zhang,Zhongmei Li,Lanlan Chen,Enbo Feng", "background": "深度学习模型在癫痫预测中的训练需要大量的脑电图（EEG）数据，但由于标注成本高和隐私限制等原因，获得足够的标注EEG数据较为困难。现有的联邦学习（FL）方法在面对不同患者的异质客户端时，难以实现稳健的性能。", "innovation": "提出了一种名为FedL2T的个性化联邦学习框架，利用新颖的双教师知识蒸馏策略生成每个客户端的高性能个性化模型。该框架使每个客户端同时学习全局聚合模型和动态分配的同伴模型，促进更直接、丰富的知识交流。通过采用自适应多级蒸馏策略来确保可靠的知识传输，并引入正则化项来约束个性化模型更新，从而增强训练稳定性。", "conclusion": "在两个EEG数据集上的实验表明，FedL2T在低标签条件下始终优于最先进的联邦学习方法，且能够快速、稳定地收敛到最佳性能，从而减少了通信轮次和相关开销。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08968", "html_url": "https://arxiv.org/abs/2510.08968", "title": "学习正则化：能够正则化的学习优化器", "title_en": "Learning Regularizers: Learning Optimizers that can Regularize", "authors": "Suraj Kumar Sahoo,Narayanan C Krishnan", "background": "已有的优化器，特别是基于梯度的方法，会通过使用如Sharpness-Aware Minimization (SAM)、Gradient-norm Aware Minimization (GAM)以及Gap-guided Sharpness-Aware Minimization (GSAM)等显式正则化技术来增强泛化能力和收敛性。然而，这些方法需要在目标函数中显式地应用正则化技术。论文提出了一种新思路，即这些正则化效果是否可以通过训练学习优化器（LO）来内部化而无需显式地应用到目标函数上。", "innovation": "研究探讨了一个基本问题：正则化效应是否可以被学习优化器学习？实验结果显示，在没有显式使用正则化技术的情况下，学习优化器可以被训练来学习和内化传统正则化技术的效果。经过广泛实验，包括MNIST、FMNIST、CIFAR和MLP、MLP-Relu、CNN等标准基准，验证了正则化学习优化器在测试准确性与泛化能力上的优越性。此外，研究还展示了学习优化器可以在新的优化任务中保留和转移这些正则化效果，从而在一定程度上挑战了传统正则化方法的必要性。", "conclusion": "研究结果表明学习优化器能够学习正则化属性，这挑战了传统优化过程中的显式正则化必要性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08977", "html_url": "https://arxiv.org/abs/2510.08977", "title": "诊断和缓解自奖励RL中的系统偏差", "title_en": "Diagnosing and Mitigating System Bias in Self-Rewarding RL", "authors": "Chuyi Tan,Peiwen Yuan,Xinglin Wang,Yiwei Li,Shaoxiong Feng,Yueqi Zhang,Jiayi Shi,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li", "background": "在使用强化学习（RL）实现大型语言模型（LLM）的强化学习能力时，主要的瓶颈在于有限的标记样本无法持续扩展数据规模。传统的自我奖励强化学习（RLIR）方法允许策略模型为其自己的策略评估奖励，这种技术在未标注数据设置中实现了可持续扩展，但在性能和稳定性上却落后于具有验证奖励的强化学习（RLVR）。研究发现，奖励估计偏向于模型对自己高度自信的策略评估结果，导致偏斜的且不稳定奖励估计。这种偏差随着训练过程的推进而累积，进而导致奖励估计与真实值的偏差越来越大，最终引起不稳定的训练过程。", "innovation": "该研究提出了自我奖励强化学习的强化版本（RLER），通过集成多个不同的模型来聚合多样化的奖励，并且能够适应奖励插值和策略卷出选择。这种改进策略显著提高了RLIR的性能，相比RLIR提升了13.6%的效用，且在未标注数据集上的表现接近RLVR，实现了在未标注样本上的稳定扩展，具有很高的应用价值。", "conclusion": "研究揭示了RLIR中的系统偏差来源，并提出通过多模型集成的方式缓解该偏差。实验证明了所提出方法的有效性，使未标注数据的自我奖励强化学习能够稳定扩展，这种技术能够为未标注数据集的处理提供新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08993", "html_url": "https://arxiv.org/abs/2510.08993", "title": "PlatformX：一种端到端可转移的能效神经架构搜索平台", "title_en": "PlatformX: An End-to-End Transferable Platform for Energy-Efficient Neural Architecture Search", "authors": "Xiaolong Tu,Dawei Chen,Kyungtae Han,Onur Altintas,Haoxin Wang", "background": "硬件意识神经架构搜索（HW-NAS）已经成为了设计针对边缘设备的高效深度神经网络的强大工具。然而，现有的方法由于高时间成本、需要大量手动调优和在不同硬件平台上缺乏良好的可扩展性而难以在实际中部署，尤其是面对复杂且具有设备特异性的能耗行为时。", "innovation": "本文介绍了PlatformX，这是一种全自动且可转移的HW-NAS框架。PlatformX结合了四个关键组件：(i) 一种基于能耗的搜索空间，扩展了传统的NAS设计，融合了能耗关键性的配置，允许探索高效率架构；(ii) 一个多设备通用的内核级能耗预测器，逐步精炼并只需少量在设备上的样本；(iii) 基于帕累托的多目标搜索算法，平衡能耗和准确度以识别最优权衡；(iv) 一个高分辨率运行时能耗分析系统，可以在没有人工干预的情况下通过外部监控自动化进行设备上的功耗测量。", "conclusion": "我们在多个移动平台上评估PlatformX，结果表明它可以显著降低搜索开销，同时保持准确性和能效的准确性。它识别的模型在准确性和效率上都优于MobileNet-V2，能够在至多0.94的准确率或仅为0.16毫焦/推断过程中使用。完整的代码和教程可以在提供的链接中找到。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08999", "html_url": "https://arxiv.org/abs/2510.08999", "title": "SQS: 通过稀疏量化亚分布进行贝叶斯神经网络压缩", "title_en": "SQS: Bayesian DNN Compression through Sparse Quantized Sub-distributions", "authors": "Ziyi Wang,Nan Jiang,Guang Lin,Qifan Song", "background": "在资源受限的设备上部署大型神经网络模型时，压缩是至关重要的。现有的方法大多只采用权重剪枝或低比特量化中的一种，这往往会导致压缩率不足，以保持可接受的性能下降。", "innovation": "本文提出了一种统一框架SQS（Simultaneous Sparsification and Quantization via Bayesian Variational Learning），该框架同时采用权重剪枝和低比特量化，并通过贝叶斯变分学习来实现更高压缩率并保持相当的性能。关键在于使用尖刺-截断先验诱导稀疏性，并使用高斯混合模型（GMMs）量化权重以支持低比特精度。该方法理论证明了一致的结果，通过稀疏化和量化方法，实现了更好的压缩效果和更好的性能下降控制。", "conclusion": "通过在ResNet、BERT-base、Llama3和Qwen2.5等模型上的广泛实验，证明了该方法在保持类似性能下降的情况下，能够实现更高的压缩率。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09018", "html_url": "https://arxiv.org/abs/2510.09018", "title": "Slim Scheduler: 一种用于高效CNN推理的具有运行时感知的RL和调度系统", "title_en": "Slim Scheduler: A Runtime-Aware RL and Scheduler System for Efficient CNN Inference", "authors": "Ian Harshbarger,Calvin Chidambaram", "background": "大多数神经网络调度研究集中在优化固定宽度的端到端静态模型上，忽视了能够在异构硬件和波动运行时条件下进行自适应动态调度的方法。", "innovation": "Slim Scheduler 提出了一种混合调度框架，该框架结合了近端策略优化 (PPO) 强化学习策略与算法贪心调度器，以协调分布式的 slimmable 模型推理。这种方法通过层次化设计减少了搜索空间复杂性，减轻了对特定硬件的过拟合，并平衡了效率和吞吐率。", "conclusion": "与纯随机任务分配基准相比，Slim Scheduler 能实现准确性和延迟的不同权衡，如平均延迟减少 96.45%，能量使用减少 97.31%，牺牲具体延迟和能耗的方差以提高总体任务吞吐率。该系统能在减少准确率的情况下减少延迟和能耗，同时保持更高的平均吞吐率。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08992", "html_url": "https://arxiv.org/abs/2510.08992", "title": "Constraints-of-Thought: 语言模型指导搜索中的受限推理框架", "title_en": "Constraints-of-Thought: A Framework for Constrained Reasoning in Language-Model-Guided Search", "authors": "Kamel Alrashedy,Vriksha Srihari,Zulfiqar Zaidi,Ridam Srivastava,Pradyumna Tambwekar,Matthew Gombolay", "background": "尽管研究者们在使大规模语言模型（LLMs）能够进行多步规划方面取得了显著进展，但LLMs在确保计划与高层用户意图一致并满足符号约束方面仍有困难，尤其是在复杂、多步骤的领域。现有的推理方法，例如因果推理（CoT）、思维树（ToT）和验证增强方法，虽然扩大了搜索空间，但往往会产生不可行的行为或虚构的步骤。为了克服这些限制，本文提出了一种名为Constraints-of-Thought (Const-o-T) 的框架，该框架提供了一种结构化先验，使得蒙特卡洛树搜索（MCTS）可以专注于语义有意义的路径。每一步推理都被表示为一个由意图和约束组成的（意图, 约束）对，这既压缩了搜索空间，又确保了计划的有效性。", "innovation": "本文提出的Constraints-of-Thought (Const-o-T) 框架通过意图-约束对提供了一个结构化先验，使蒙特卡洛树搜索能够专注于有意义的路径而不只是生成推理轨迹或事后验证输出。通过使用意图-约束对，Const-o-T积极地将搜索集中在可行且有意义的计划上，同时通过约束来修剪不可能的分支并引导探索向语义验证动作的方向，从而提高规划效率和验证性决策。", "conclusion": "本文通过在风险游戏、CAD代码生成和算术推理领域中对比基线方法，展示了我们的方法具有更高的准确性和更强的结构对齐。贡献在于证明Const-of-T提供了一个普遍适用的基础框架，用于约束引导的推理，从而提高LLMs的高效性、约束对齐性和领域可适应性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09007", "html_url": "https://arxiv.org/abs/2510.09007", "title": "非噪音遗忘集中LLM的去学习研究：不完整、重新编写和水印数据的探讨", "title_en": "LLM Unlearning on Noisy Forget Sets: A Study of Incomplete, Rewritten, and Watermarked Data", "authors": "Changsheng Wang,Yihua Zhang,Dennis Wei,Jinghan Jia,Pin-Yu Chen,Sijia Liu", "background": "大型语言模型（LLMs）展现出惊人的生成能力，但也因其储存敏感数据、强化偏见和生成有害内容而引发伦理和安全方面的担忧。这引发了对LLM去学习的关注，即从预训练模型中删除与不良数据相关的知识。然而，现有的大多数方法假设能够访问清洁且定义明确的遗忘数据样本，而在实际中，遗忘数据可能质量不高、是合成重写或带有水印的，这使得去学习的有效性存在疑问。", "innovation": "本研究首次探讨在噪音遗忘集（如不完整、重新编写和带有水印的数据）上进行的去学习。通过系统地评估当前最先进的LLM去学习方法RMU和NPO在这类噪音遗忘集上的表现，研究发现，只要核心语义信号保持不变，去学习过程对干扰表现出惊人的鲁棒性。为了解释这一鲁棒性，研究提出了基于重要性解释的观点：驱动遗忘的关键语义组件即使在表面形式上有显著变化，仍然保持一致的影响。这表明去学习算法主要受到深层次语义线索而不是浅层词汇模式的引导。", "conclusion": "去学习算法在表面形式显著变化但仍能保持核心语义信号的情况下，仍能表现出出色的鲁棒性。这一发现强调了深度语义识别在去学习算法中的重要性，而非仅仅是基于浅层词汇模式。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09017", "html_url": "https://arxiv.org/abs/2510.09017", "title": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers", "title_en": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers", "authors": "Rui Bu,Haofeng Zhong,Wenzheng Chen,Yangyan Li", "background": "基于Transformer架构的大模型容易出现极端令牌现象，如注意力陷阱和价值状态漏斗。这些现象导致模型性能、量化精度和可解释性下降，源于模型通过聚焦于具有接近零值状态的令牌而学习到一种低效的‘无效操作’行为，从而引起不健康的信息互强机制。", "innovation": "提出了Value-State Gated Attention (VGA)，这是一种简单且专用的架构机制，通过直接打破无效操作的循环，实现高效地执行‘无效操作’注意力。VGA引入了一个可学习的数据依赖性门控机制，直接从价值向量（V）计算得出，以调节输出。理论分析表明，利用价值状态自身的函数进行门控比基于输入嵌入的先前方法更有效于解耦值和注意力分数的更新。这种门控机制为模型提供了直接的监管途径，可以根据令牌的涌现值表示来抑制其贡献。", "conclusion": "实验结果表明，VGA显著减轻了注意力陷阱的形成，稳定了价值状态的规范，提高了模型性能、鲁棒的量化精度和增强了模型可解释性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09020", "html_url": "https://arxiv.org/abs/2510.09020", "title": "MagicDock：通过梯度反转实现面向对接的从头设计药物", "title_en": "MagicDock: Toward Docking-oriented De Novo Ligand Design via Gradient Inversion", "authors": "Zekai Chen,Xunkai Li,Sirui Zhang,Henan Sun,Jia Li,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang", "background": "从头设计配体是一种基础任务，旨在生成能够与蛋白质受体有效结合并获得强烈结合亲和力的蛋白质或分子候选物，从头开始生成。它在广泛的生物医药应用中具有重要性。然而，现有的大多数研究受限于假定的从头设计、有限的对接建模以及刚性的配体类型。", "innovation": "本文提出了MagicDock，一种以前瞻性的渐进管道和可微表面建模为基础的框架。创新点包括：（1）采用了一个精心设计的梯度反转框架。通过先将受体和配体的一般对接知识纳入基础模型，然后通过结合预测将对接知识实例化为递归的梯度流，以迭代方式指导从头配体生成。（2）强调对接过程中可微表面建模，利用可学习的3D点云表示精确捕捉结合细节，确保生成的配体通过直接且可解释的空间指纹保留对接的有效性。（3）介绍了针对不同配体类型的定制设计，并将其整合到一个具有灵活触发机制的统一可微反转框架中，以确保广泛适用性。此外，为MagicDock的每个组件提供了严格的理论保证。", "conclusion": "通过在9种情景下的广泛实验，证明MagicDock相比专门用于蛋白质或分子配体设计的最新技术基准，在平均提高27.1%和11.7%方面取得了显著进步。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09022", "html_url": "https://arxiv.org/abs/2510.09022", "title": "机器学习训练的环境影响持续上升，证实了反弹效应", "title_en": "The Environmental Impacts of Machine Learning Training Keep Rising Evidencing Rebound Effect", "authors": "Clément Morand(STL),Anne-Laure Ligozat(ENSIIE, LISN, STL),Aurélie Névéol(STL, LISN)", "background": "近期机器学习的方法在基准测试中取得了更高的性能，但这也带来了计算需求的快速增长。为了减少能耗和环境影响，已经提出了硬件、算法和碳优化策略。这些策略是否能够实现可持续的机器学习模型训练？通过分析过去十年间一些著名AI系统的环境影响，特别是围绕显卡的生命周期影响，研究指出显卡生产的环境影响持续上升，并且即使采取了减少碳排放的策略，训练机器学习模型的能耗和环境影响也在指数级增长。", "innovation": "研究首次评估了从2013年以来一些重要AI系统的环境影响，特别是在显卡生命周期上的影响。研究揭示了两个关键趋势：显卡生产带来的环境影响在持续增加；即使采用碳减排策略（如将训练迁移至碳排放较低的电力混合地区），训练机器学习模型所需的能源消耗和环境影响仍然在指数级上升。这些结果表明，硬件环境影响的减少并不能减轻由模型训练引起的环境影响，部分原因是存在反弹效应。研究强调，必须在整个生命周期而不是仅仅在使用过程中考虑硬件的影响，才能避免影响转移。", "conclusion": "单纯提高效率不足以确保机器学习的可持续性。减少AI活动和质疑资源密集型训练的规模与频率同样是减轻AI环境影响的关键。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09034", "html_url": "https://arxiv.org/abs/2510.09034", "title": "优化器的收敛性意味着在均衡状态下特征值筛选", "title_en": "Convergence of optimizers implies eigenvalues filtering at equilibrium", "authors": "Jerome Bolte(TSE-R),Quoc-Tung Le(UGA, LJK),Edouard Pauwels(TSE-R)", "background": "现有大量实验证据表明，在深度神经网络训练过程中，不同优化器倾向于找到近似全局最优解。本文不从证明优化器找到全局最优解的角度出发，而是从假设任何点的收敛性的角度出发，探讨这种假设的后果。基于此，结合近期关于临界稳定现象的研究进展，作者认为不同的优化器实际上起到了特征值筛选的作用，这取决于它们的超参数设置。标准梯度下降方法自然避免尖锐最小值，而Sharpness-Aware Minimization (SAM)算法进而倾向于青睐更广泛的谷底。", "innovation": "根据这些启示，作者提出了两个新的算法，表现出增强的特征值筛选效果，旨在促进更广泛的最小值。理论分析利用了广义Hadamard-Perron稳定流形定理，适用于一般的半代数$C^2$函数，无需额外非退化条件或全局Lipschitz界假设。作者通过前馈神经网络的数值实验支持了这些结论。", "conclusion": "本文通过新的视角分析了优化器的收敛性，提出了增强特征值筛选效果的两个新算法，并通过理论分析与实验验证了结论。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09023", "html_url": "https://arxiv.org/abs/2510.09023", "title": "第二个行动者：更强的适应性攻击绕过了针对大语言模型禁闭和提示注入的防御", "title_en": "The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections", "authors": "Milad Nasr,Nicholas Carlini,Chawin Sitawarin,Sander V. Schulhoff,Jamie Hayes,Michael Ilie,Juliette Pluto,Shuang Song,Harsh Chaudhari,Ilia Shumailov,Abhradeep Thakurta,Kai Yuanqing Xiao,Andreas Terzis,Florian Tramèr", "background": "当前对语境模型防御方法的有效性评估方式通常是针对静态的有害攻击字符串，或计算能力较弱且未针对防御方法进行设计的优化方法。这种评估过程被认为有缺陷，因为没有模拟真正的攻击者会如何调整策略来对抗防御设计的情况。文章指出，为了更好地评估防御的鲁棒性，需要考虑对手能够动态调整攻击策略，甚至利用高级优化技术的情况。这种方式更有助于模拟真实的攻击场景，确保防御措施能够有效抵御实际的威胁。", "innovation": "文章提出了一个改进的评估框架，通过系统地调整和扩展通用优化技术（如梯度下降、强化学习、随机搜索和人类指导探索），来评估防御措施。实际证明，这种方法能够绕过12种基于不同技术的防御措施，这些防御措施原本报告的抵御攻击成功率接近于零。这表明当前的防御措施在面对强大的适应性攻击时显得不够鲁棒。此项研究强调了未来防御工作需要考虑更强攻击的重要性，以便做出可靠和具说服力的鲁棒性声明。", "conclusion": "文章提出，为了评估语言模型防御的有效性，应该基于更强、更适应的攻击方式进行评估。这种新型评估方法能够揭示现有防御措施的弱点，促使研究人员改进提升其鲁棒性。此外，文章表明未来的工作应该加强针对更复杂攻击策略的研究，以提高安全防护水平。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09079", "html_url": "https://arxiv.org/abs/2510.09079", "title": "改进工业时间序列中的异常检测：分段和异质集成的作用", "title_en": "Improving Anomaly Detection in Industrial Time Series: The Role of Segmentation and Heterogeneous Ensemble", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "在机器学习领域，分割模型可以识别时间序列中的状态变化，有助于检测正常和异常条件之间的转换。特定的技术如变更点检测 (CPD)，特别是 ChangeFinder 算法，已经成功应用于分割时间序列并改进异常检测，特别是在多变量环境中降低时间不确定性。", "innovation": "本文探索了将分割技术与异质集成结合应用于工业生产情境下的异常检测。研究结果表明，将分割作为预处理步骤，然后选择异质集成算法，比单独使用 PCA 和 LSTM 集成或 Random Forest 和 XGBoost 集成，显著提高了 AUC-ROC 指标。改进归因于分割减少的时间不确定性以及对监督算法学习过程的促进作用。", "conclusion": "研究表明，将分割作为预处理步骤并在选择异质集成算法之前应用，可以显著提高异常检测的性能，特别是在 AUC-ROC 指标上从 0.8599 提升到 0.9760。未来的工作将评估引入基于变更点研究的加权特征，结合分割和异质集成的方法，以进一步优化早期异常检测的模型性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09103", "html_url": "https://arxiv.org/abs/2510.09103", "title": "AdaPM: a Partial Momentum Algorithm for LLM Training", "title_en": "AdaPM: a Partial Momentum Algorithm for LLM Training", "authors": "Yimu Zhang,Yuanshi Liu,Cong Fang", "background": "在训练大规模语言模型时，动量（momentum）被广泛使用，并且通常可以实现显著加速。然而，存储动量通常会带来内存挑战。", "innovation": "提出了一种自适应训练策略AdaPM，通过部分动量实现高效的优化器，同时减少内存消耗。该策略采用非均匀动量设计，并通过偏置校正技术减轻部分动量的偏差和性能损失。实验验证了该方法在各种语言模型（从60M到1.5B）的预训练、监督微调和RLHF中的高效性和性能，同时减少了超过90%的动量内存消耗。", "conclusion": "AdaPM进一步通过结合在二阶统计上的内存高效技术，最多可以减少95%的优化器状态内存，为预训练GPT-2 1.5B节省超过30%的GPU时长。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09048", "html_url": "https://arxiv.org/abs/2510.09048", "title": "使用真实世界多模态数据集成的时空图卷积网络对电动汽车充电需求进行预测", "title_en": "Spatio-Temporal Graph Convolutional Networks for EV Charging Demand Forecasting Using Real-World Multi-Modal Data Integration", "authors": "Jose Tupayachi,Mustafa C. Camur,Kevin Heaslip,Xueping Li", "background": "交通运输仍然是温室气体排放的主要贡献者之一，这凸显了向可持续替代方案（如电动汽车EVs）转型的紧迫性。然而，充电基础设施的空间分布不均和不规则使用造成了电力网络稳定性和投资规划的挑战。本文研究旨在解决这些问题，通过结合图卷积网络和时间架构来预测美国田纳西州的电动汽车充电需求，并利用真实世界交通流量、天气条件以及一家美国最大的电动汽车基础设施公司的专有数据，同时捕捉空间依赖性和时间动态性。研究结果表明，中间时间范围（3小时）的预测在响应性和稳定性之间取得较好的平衡，1DCNN在此类预测中表现始终优于其他时间模型。地域分析表明田纳西州不同地区在预测准确性上存在差异，反映了充电站密度、人口规模和地方需求变化性对模型性能的影响。", "innovation": "本文引入了TW-GCN框架，结合了图卷积网络与时间架构，用于预测电动汽车充电需求，这为电动汽车基础设施规划提供了数据驱动的智能支持，并支持可持续交通的转型和电网的弹性管理。该框架利用了多模式现实世界数据（包括交通流量、天气条件和专有数据），强调了空间和时间特征的重要性。", "conclusion": "本研究提出的TW-GCN框架，通过利用时空数据预测电动汽车充电需求，提高了充电需求预测的准确性和稳定性，特别是对于3小时的时间范围，以及交通流量和天气等环境因素对其预测影响的分析，为未来的充电基础设施规划和电力网络稳定提供了新的见解和工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09105", "html_url": "https://arxiv.org/abs/2510.09105", "title": "MemLoss: 利用循环利用对抗样本增强对抗训练", "title_en": "MemLoss: Enhancing Adversarial Training with Recycling Adversarial Examples", "authors": "Soroush Mahdi,Maryam Amirmazlaghani,Saeed Saravani,Zahra Dehghanian", "background": "本文的背景在于现有的机器学习模型在受到对抗攻击时的鲁棒性不足。当前的方法在提升模型对抗鲁棒性的同时，往往会牺牲在干净数据上的准确性和性能。因此，如何在保持或提高在干净数据上性能的同时，增强对抗鲁棒性是研究者面临的一大挑战。", "innovation": "本文的创新点是提出了一种名为MemLoss的新方法。MemLoss通过使用之前生成的对抗样本（称为‘内存对抗样本’），在训练过程中跨多个训练周期利用这些样本来提升模型的鲁棒性和准确性。这种方法能够在提升自然准确性和对抗鲁棒性之间取得平衡。实验结果表明，与现有的对抗训练方法相比，MemLoss在多个数据集（包括CIFAR-10）上具有更好的准确性和更强的对抗鲁棒性。", "conclusion": "实验结果表明，相比于现有的对抗训练方法，本文提出的MemLoss方法在多个数据集上不仅保持了较强的任务准确性，同时对抗鲁棒性也得到了显著提高。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09041", "html_url": "https://arxiv.org/abs/2510.09041", "title": "智能总体约束博弈强化学习方法下的自主车辆稳健驾驶控制", "title_en": "Robust Driving Control for Autonomous Vehicles: An Intelligent General-sum Constrained Adversarial Reinforcement Learning Approach", "authors": "Junchao Fan,Xiaolin Chang", "background": "深度强化学习（DRL）已被证明在开发自主驾驶策略方面取得了显著成功。然而，其对抗性攻击的脆弱性仍然是实际部署中的关键障碍。尽管现有的鲁棒方法已经取得了一定的成效，但仍存在三个关键问题：（i）这些方法是针对短期的对抗性攻击训练的，限制了它们应对更具策略性威胁的能力；（ii）它们难以引发真正危及安全的事件（如碰撞），反而常常导致轻微的结果；（iii）由于缺少鲁棒约束，这些方法在训练过程中可能会导致学习不稳定和策略漂移。", "innovation": "我们提出了一种创新的方法——智能总体约束博弈强化学习（Intelligent General-sum Constrained Adversarial Reinforcement Learning，IGCARL），这是一种新颖的鲁棒自主驾驶方法，包括一个具有策略性协调多步攻击能力的智能目标对手和一个鲁棒的驾驶代理。IGCARL的设计旨在通过利用DRL的动态决策能力来执行策略性协调的多步攻击，并明确地关注通过采用总体约束目标来引发危及安全的事件。此外，鲁棒的驾驶代理通过与对抗对手互动，学习并形成对对抗性攻击有鲁棒性稳定的自主驾驶策略。为了确保在对抗环境中学习的稳定性并减轻攻击引起的策略漂移，代理在受约束公式下进行优化。实验证明，IGCARL相比最先进的方法提高了成功率至少27.9%，展示了对对抗性攻击的更强鲁棒性和增强了基于DRL的自主驾驶的安全性和可靠性。", "conclusion": "这项研究提出了IGCARL方法来解决DRL在面对对抗性攻击时的局限性。通过提高鲁棒性和学习的稳定性，IGCARL显著增强了基于DRL的自主驾驶的安全性和可靠性，增强了其在实际部署中的适用性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09085", "html_url": "https://arxiv.org/abs/2510.09085", "title": "FLToP CTC: Frame-Level Token Pruning via Relative Threshold for Efficient and Memory-Saving Decoding on Diverse Platforms", "title_en": "FLToP CTC: Frame-Level Token Pruning via Relative Threshold for Efficient and Memory-Saving Decoding on Diverse Platforms", "authors": "Atul Shree,Harshith Jupuru", "background": "CTC-based ASR (自动语音识别)系统在资源有限的环境中面临计算和内存瓶颈。传统CTC解码器需要耗费大部分处理时间（例如，在L4 GPU上的wav2vec2-large系统中高达90%的时间），由于其对每个标记的详尽操作而存在效率低下。LibriSpeech数据集上的实验显示，FLToP CTC能在保留无明显解码错误率(WER)降解的情况下，将解码时间加快10.5倍，内存减少2.78倍，这表明CTC解码存在的瓶颈可以通过FLToP CTC得到有效缓解，使得ASR系统的运行更为高效和节省资源。", "innovation": "FLToP CTC引入了帧级标记剪枝算法，该算法通过相对阈值概率来进行引导。这种动态消除每帧中低概率标记的方法显著降低了计算和内存需求。FLToP CTC设计简洁，易于在不同平台（如CPU和GPU）上集成，从而提升了CTC解码在资源有限环境和实时应用中的可扩展性，增强了语音识别的可访问性和效率。", "conclusion": "FLToP CTC解决了CTC解码器在资源受限环境下的计算和内存瓶颈问题。通过引入帧级标记剪枝策略，它成功地降低了CTC解码的计算和内存需求，同时保持了无明显降解的解码错误率。该算法具有平台通用性，适用于多种设备，提升了ASR系统的实时性能，推动了语音识别技术的进一步发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：衡量和减少差异性隐私风险差距以促进差分隐私机器学习中的隐私保护公平性", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "尽管在传统公平感知机器学习（ML）和差分隐私机器学习（DPML）方面取得了显著进展，但在不同群体之间的隐私保护公平性方面仍存在不足。现有研究提出了一些评估群体隐私风险的方法，但这些方法主要基于数据记录的平均隐私风险，这可能低估了群体隐私风险，导致对不同群体隐私风险的差距估计不足。此外，目前评估数据记录最坏情况隐私风险的方法耗时较长，限制了其实际应用。", "innovation": "本文引入了一种新的成员推断博弈，可以高效地审计数据记录的近似最坏情况隐私风险。通过这种方法，可以提供更严格的群体隐私风险测量，从而可靠地评估不同群体隐私风险的差距。此外，为了在DPML中促进隐私保护公平性，本文通过借鉴差分隐私审计研究中“金丝雀”的设计理念，增强了标准的DP-SGD算法，提出了一个自适应的群体特定梯度裁剪策略。", "conclusion": "广泛的实验结果表明，本方法能够有效减少不同群体之间的隐私风险差距，从而提高DPML中隐私保护的公平性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09095", "html_url": "https://arxiv.org/abs/2510.09095", "title": "神经编码作为生物信号的分词工具", "title_en": "Neural Codecs as Biosignal Tokenizers", "authors": "Kleanthis Avramidis,Tiantian Feng,Woojae Jeong,Jihwan Lee,Wenhui Cui,Richard M Leahy,Shrikanth Narayanan", "background": "神经生理记录如脑电图（EEG）提供了在医疗保健、诊断筛查和沉浸式娱乐中估计生理活动的便捷和微创方法。然而，这些记录生成高维度且噪声较大的时序数据，通常需要大量预处理和手工特征提取才能揭示有意义的信息。最近，有越来越多的兴趣应用来自大型预训练（基础）模型的表示学习技术来有效地解码和解释生物信号。本文讨论了采用这些方法所面临的挑战，并介绍了一种名为BioCodec的替代表示学习框架，受到神经编码器的启发，可以以离散令牌的形式捕捉低级信号特征。预训练于数千小时的EEG数据，BioCodec在多个下游任务中显示出了效力，涵盖从临床诊断任务和睡眠生理学到解码言语和动作想象等多个领域，尤其是在资源有限的环境中表现出色。此外，我们还提供了编码簿使用的定性分析，并估计了编码簿嵌入在EEG连接性中的空间相干性。值得注意的是，我们也记录了该方法的适用性，即 electromyographic (EMG) 信号的适用性。总体而言，所提出的方法提供了一种适用于生物信号分词的通用解决方案，其性能与当前最先进的模型相当。源代码和模型检查点已共享。", "innovation": "介绍了一种名为BioCodec的替代表示学习框架，该框架受到神经编码器的启发，可以以离散令牌的形式捕捉低级信号特征。Pre-trained on thousands of EEG hours, BioCodec在多个下游任务中显示出了效力，涵盖了从临床诊断任务和睡眠生理学到解码言语和动作想象等多个领域，尤其是在低资源环境下具有优势。此外，提供的编码簿使用的定性分析和编码簿嵌入空间相干性的估计为理解生物信号提供了新的视角。记录了该方法在其他生物信号数据，如电磁图 (EMG) 信号上的适用性。", "conclusion": "提出的BioCodec方法提供了一种适用于生物信号分词的通用解决方案，其性能与当前最先进的模型相当。源代码和模型检查点已经共享。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09146", "html_url": "https://arxiv.org/abs/2510.09146", "title": "基于成对比较的评分法密度估计", "title_en": "Score-Based Density Estimation from Pairwise Comparisons", "authors": "Petrus Mikkola,Luigi Acerbi,Arto Klami", "background": "该研究旨在从成对比较中进行密度估计，这一研究的动机来源于专家知识获取和从人类反馈中学习的需求。具体来说，研究者将未观察到的目标密度与经过温度调节后的胜者密度（偏好选择的边际密度）联系起来，通过评分匹配来学习胜者的分数。这一方法允许通过加温处理估计胜者密度的得分来估计目标密度。", "innovation": "该研究提出了将未观察到的目标密度与经过温度调节后的胜者密度联系起来的方法，并通过评分匹配来学习胜者的分数，从而通过加温处理估计目标密度的得分。此外，研究者证明了信念密度和胜者密度的得分向量是共线的，并与位置相关的温度场相联系，给出了这种温度场的解析公式，并在布雷德利-特里的模型下提出了一种该温度场的估计器。研究还使用了基于评分缩放的退火拉梅尔动态生成的温度调节样本来训练扩散模型，从而能够从少量数百到数千个成对比较中学习模拟专家的复杂多变量信念密度。", "conclusion": "研究通过从成对比较中学习复杂多变量信念密度，展示了从少量成对比较中估计复杂的多变量信念分布的潜力，为从人类反馈中获取知识提供了新的方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09127", "html_url": "https://arxiv.org/abs/2510.09127", "title": "具有通用函数逼近和延迟反馈的对抗上下文多臂老虎机的遗憾界", "title_en": "Regret Bounds for Adversarial Contextual Bandits with General Function Approximation and Delayed Feedback", "authors": "Orin Levy,Liad Erez,Alon Cohen,Yishay Mansour", "background": "该研究关注的是在面对上下文多臂老虎机问题（CMAB）时，特别是在存在延迟反馈且反馈由对手选择的情形下，如何进行遗憾最小化。背景信息包括了在直接访问有限策略类的情况下，得到了遗憾最优的期望遗憾界，并探讨了在一般函数逼近设置中有界延迟反馈下的主要贡献。", "innovation": "研究的主要贡献在于，建立了一个具有函数逼近的一般设定下的遗憾界，即对于（可能是无限的）上下文损失函数类$ \boldsymbol{\text{F}} $，使用队列先进先出（FIFO）策略，实现了期望遗憾界的计算公式$ O(\text{sqrt}(KT\text{R}_\text{T}(\text{O}) + d_{\text{max}} D \beta)) $，其中$\text{d}_{\text{max}}$是最大的延迟，$\text{R}_\text{T}(\text{O})$是该算法的遗憾上限，$\beta$是与算法相关的稳定性参数。此外，提供了Hedge基版本的一种聚合预测器作为回归在有限函数类上的实现，并证明其稳定性参数$\beta$值为$\text{log} |\boldsymbol{\text{F}}|$，从而得到了一个新的遗憾界$ O(\text{sqrt}(KT \text{log}|\boldsymbol{\text{F}}| + d_{\text{max}} D \text{log}|\boldsymbol{\text{F}}|)) $。", "conclusion": "研究最后提出了一个遗憾下的下界，其公式为$ \text{Omega}(\text{sqrt}(KT \text{log}|\boldsymbol{\text{F}}| + \text{sqrt} D \text{log}|\boldsymbol{\text{F}}|)) $，结果表明所得遗憾界只有$ \text{sqrt} d_{\text{max}} $倍于下界，实现了接近最优的遗憾界。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09156", "html_url": "https://arxiv.org/abs/2510.09156", "title": "Agentic-KGR: 通过多智能体强化学习进行知识图谱的协同进化构建", "title_en": "Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning", "authors": "Jing Li,Zhijie Sun,Zhicheng Zhou,Suming Qiu,Junjie Huang,Haijia Sun,Linyuan Qiu", "background": "当前的知识增强型大规模语言模型依赖于静态且预先构建的知识库，这些知识库存在覆盖面不足和时间过时的问题，这限制了它们在动态信息环境中的有效性。", "innovation": "文章提出了一种名为Agentic-KGR的新框架，通过多轮次强化学习使语言模型和知识图谱实现协同进化。其三大创新点在于（1）动态的模式扩展机制，在训练过程中系统地将图谱的本体拓展到预定义边界之外；（2）检索增强的记忆系统，通过持续优化使模型参数和知识结构协同进化；（3）可学习的多尺度提示压缩方法，在保持关键信息的同时通过自适应序列优化减少计算复杂性。", "conclusion": "实验结果表明，与监督基准和单轮次强化学习方法相比，在知识抽取任务中表现有显著提升。将该方法与GraphRAG集成后，在下游问答任务中的表现优于现有方法，在准确性和知识覆盖方面均有显著提高。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09174", "html_url": "https://arxiv.org/abs/2510.09174", "title": "鲁棒性和正则化在分层Re-Basin中的作用", "title_en": "Robustness and Regularization in Hierarchical Re-Basin", "authors": "Benedikt Franke,Florian Heinrich,Markus Lange,Arne Raul", "background": "本文关注Git Re-Basin，这是一种新的训练模型合并方法，具有潜在优势。研究者进一步探讨了该方法，并提出了一种分层模型合并方案，该方案在实验中显著优于标准的MergeMany算法。", "innovation": "本文提出了一种新的分层模型合并方案，该方案能够显著超越标准的MergeMany算法。特别地，分层合并方法在合并模型时能诱导出更强的对抗性和扰动鲁棒性。", "conclusion": "尽管Re-Basin方法在提高合并模型的鲁棒性上表现出色，但在实验中也观察到了更大的性能下降，与原作者的报告不同。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09180", "html_url": "https://arxiv.org/abs/2510.09180", "title": "RepDL：确保位级可重复的深度学习训练和推理", "title_en": "RepDL: Bit-level Reproducible Deep Learning Training and Inference", "authors": "Peichen Xie,Xian Zhang,Shuo Chen", "background": "深度学习中存在的非确定性和不可再现性问题，导致不同运行和平台间的结果不一致。这些问题主要源于随机数生成和浮点数计算两个方面。尽管可以通过确定性配置控制随机性，但浮点数计算仍然存在大量的不可再现性问题。", "innovation": "提出了一种名为RepDL的开源库，旨在确保跨不同计算环境的深度学习训练和推理的确定性和位级别可再现。RepDL通过强制浮点数计算正确舍入和顺序不变性来实现这一目标。", "conclusion": "RepDL库确保了深度学习训练和推理在不同计算环境中的确定性和位级别可再现。其实现方法在于强制浮点数计算的正确舍入和顺序不变性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09160", "html_url": "https://arxiv.org/abs/2510.09160", "title": "通过子空间优化高效限制资源训练视觉变换器", "title_en": "Efficient Resource-Constrained Training of Vision Transformers via Subspace Optimization", "authors": "Le-Trung Nguyen,Enzo Tartaglione,Van-Tam Nguyen", "background": "随着人工智能在日常生活中扮演越来越重要的角色，能源消耗和数据隐私问题日益突出。边缘设备上的模型训练可以直接在设备上进行，从而减少能源消耗并保障数据隐私。然而，现代神经网络规模的扩大成为阻碍边缘训练的主要障碍。虽然以往的研究主要集中在紧凑型卷积架构上，但本文通过将子空间训练方法应用到变压器模型中，来解决这一问题。", "innovation": "本文引入了一种名为Weight-Activation Subspace Iteration (WASI)的方法，通过限制训练到固定的子空间来缓解反向传播的内存瓶颈并提高变压器模型的推理效率。WASI在保持与传统训练相似的准确性的同时，能够将内存使用量最多减少62倍，并将运算成本（FLOPs）最多减少2倍。在Raspberry Pi 5上，WASI的训练和推理速度比传统训练快约1.5倍。", "conclusion": "WASI方法在保持模型准确性的同时，显著减少了内存使用量和运算成本，加快了训练和推理速度，为资源受限的边缘设备上的高效变压器模型训练提供了新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09175", "html_url": "https://arxiv.org/abs/2510.09175", "title": "超越二元连接：在全局约束下提取高阶功能脑网络结构", "title_en": "Beyond Pairwise Connections: Extracting High-Order Functional Brain Network Structures under Global Constraints", "authors": "Ling Zhan,Junjie Huang,Xiaoyao Yu,Wenyu Chen,Tao Jia", "background": "功能脑网络（FBN）建模通常依赖于局部成对相互作用，这种建模方法在捕捉高阶依赖关系方面存在理论限制。当前基于超图的建模方法在计算负担和启发式方面存在障碍，难以直接从数据分布中端到端学习FBN结构。", "innovation": "提出了在全局约束下提取高阶FBN结构的方法，并实现了全局约束导向的多分辨率（GCM）FBN结构学习框架，该框架结合了四种类型的全局约束（信号同步、被试身份、预期边数以及数据标签），以实现不同建模分辨率（样本/被试/组/项目）下FBN结构的学习。实验结果表明，GCM相比于9个基线和10种最先进的方法，在5个数据集和2个任务设置中，精度相对提高了30.6%，计算时间减少了96.3%。", "conclusion": "GCM框架在功能脑网络结构学习领域提供了新的视角，并为跨学科应用如认知神经科学提供了基础。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09159", "html_url": "https://arxiv.org/abs/2510.09159", "title": "时空电子健康记录跨表示基准测试在临床结局预测中的应用", "title_en": "Cross-Representation Benchmarking in Time-Series Electronic Health Records for Clinical Outcome Prediction", "authors": "Tianyi Chen,Mingcheng Zhu,Zhiyao Luo,Tingting Zhu", "background": "电子健康记录（EHRs）能够支持深度学习在临床预测中的应用，但由于评价方法不一致，最优化的患者数据表示方法仍不清楚。本文旨在通过标准化数据处理和评估流程，首次系统地比较EHR表示方法，包括多变量时间序列、事件流以及用于大型语言模型的文本事件流，评估适用于不同临床环境的建模方法，旨在解决这一问题.", "innovation": "本文提出了首个系统基准测试来对比EHR表示方法，包含多变量时间序列、事件流和用于大型语言模型的文本事件流，并在MIMIC-IV和EHRSHOT两个不同临床环境中进行评估。此外，引入了适应临床环境的特征选择策略，并评估了预训练模型在少量样本中的高效性能，以及简单计数模型在充足数据情况下的竞争力.", "conclusion": "研究表明，事件流模型在临床预测中的表现最为稳定。预训练模型如CLMBR在少量样本设置中表现出很高的样本效率，但在数据充足的情况下，简单的计数模型也可以竞争。在不同的临床环境中，特征选择策略也需要调整，稀疏特征的简化提高了重症监护室的预测效果，而保留特征对于长期任务则是至关重要的。这些结果为基于临床背景和数据类型选择EHR表示方法提供了实用指导，这些成果得益于统一且可复现的工作流程."}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09152", "html_url": "https://arxiv.org/abs/2510.09152", "title": "Logits Replay + MoClip: 通过最小遗忘实现稳定且低成本的后训练", "title_en": "Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting", "authors": "Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun", "background": "大型语言模型（LLMs）在后训练中通常面临一种权衡，在这些模型中，专门领域上的改进往往以一般能力为代价。现有的方法试图通过正则化、选择参数更新或数据为中心的回放来缓解这种紧张关系，但这些方法在计算成本、数据访问或灵活性方面都存在问题。最近的工作表明，可以通过压缩训练信号到一定子集的对数而不会显著损失准确性，但简单的裁剪会导致优化不稳定并加剧遗忘。因此，该研究提出了一种两阶段框架，称为Logits Replay + MoClip，以在对数概率空间中压缩监督，并在更新级别稳定优化。", "innovation": "该方法分为两个阶段：首先在Stage 0记录动态的Top-K令牌子集用于覆盖概率阈值，始终包括正确标签；然后在Stage 1通过重新播放这些紧凑的子集来计算精确的重新归一化损失，避免全softmax计算并隐式实现正则化。为了保证稳定性，该研究设计了一种名为MoClip的优化器，该优化器限制梯度动量旋转，并应用基于arctan2的更新缩放。实验结果表明，该方法可以在通信技术（CT）和NL2SQL任务上提高领域性能，同时在通用基准测试（MMLU、BBH、GPQA、MATH）上减少遗忘，并将训练成本降低了40%以上。这些贡献为LLMs领域适应提供了一种可扩展且不牺牲泛化的途径，同时最小化遗忘现象并降低了训练成本。", "conclusion": "我们的方法通过在对数概率空间中压缩监督并稳定优化，实现了在减少训练成本的同时保持高性能且不丧失泛化的双重目标。通过引入Logits Replay + MoClip，为LLMs的领域适应提供了一种新的低成本、可扩展的解决方案，不仅能在领域特定任务上表现优异，还能在一般任务上有效减少遗忘现象。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09201", "html_url": "https://arxiv.org/abs/2510.09201", "title": "多模态提示优化：为何不利用多种模态来驱动MLLMs", "title_en": "Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs", "authors": "Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang", "background": "大型语言模型（LLMs）已经取得了显著的成功，并且其多模态扩展（MLLMs）进一步解锁了涉及图像、视频和其他模态的全新功能，而不仅仅是文本。尽管如此，现有的提示优化方法仍局限于文本，无法充分发挥MLLMs的全部潜力。", "innovation": "本文提出了一个新的问题：多模态提示优化，并设计了一个名为多模态提示优化器（MPO）的统一框架，可以同时优化文本和非文本的提示，并通过保持对齐的更新进行联合优化。此外，MPO 还利用贝叶斯先验来指导候选提示的选择过程。实验结果显示，MPO 在多种模态下（包括图像、视频和分子）的表现优于现有的基于文本的优化方法。", "conclusion": "通过广泛的实验，本文证明了多模态提示优化对于实现MLLMs的潜力至关重要。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09181", "html_url": "https://arxiv.org/abs/2510.09181", "title": "在深度连续学习中灾难性遗忘的隐含对抗性", "title_en": "On the Implicit Adversariality of Catastrophic Forgetting in Deep Continual Learning", "authors": "Ze Peng,Jian Zhang,Jintao Guo,Lei Qi,Yang Gao,Yinghuan Shi", "background": "连续学习旨在赋予机器智能类似人类的能力，即积累新技能而不忘记旧技能。深层网络中的核心挑战是灾难性遗忘，其根本原因尚未完全理解。该论文揭示了灾难性遗忘背后的机制，指出新任务训练实际上是对旧任务知识的一种隐含的对抗攻击。", "innovation": "论文提出了一种新的观点，即新任务梯度自动并准确地与旧任务损失景观中的尖锐方向对齐，导致旧任务损失迅速增加。这种对抗对齐是出乎意料的，因为尖锐方向过于稀疏，几乎不可能随机对齐。通过理论证明，论文解释了这一现象源自训练中的低秩偏差，该偏差通过前向和后向传播机制将两个方向限制在同一低维子空间，从而促进对齐。此外，论文还提出了一个名为backGP的方法，该方法通过减少由前向传播引起的对抗对齐来降低遗忘现象，同时解决了由后向传播引起的对齐问题，从而在平均精度上提高了12.7%。", "conclusion": "论文通过理论分析揭示了灾难性遗忘背后的对抗机制，并提出了backGP方法来解决由前向和后向传播机制引起的对抗对齐问题，从而显著提高了连续学习中的模型准确性和稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09240", "html_url": "https://arxiv.org/abs/2510.09240", "title": "时间感知公平性的数据共享激励", "title_en": "Incentivizing Time-Aware Fairness in Data Sharing", "authors": "Jiangwei Chen,Kieu Thao Nguyen Pham,Rachael Hwee Ling Sim,Arun Verma,Zhaoxuan Wu,Chuan-Sheng Foo,Bryan Kian Hsiang Low", "background": "在协作数据共享和机器学习中，多个实体汇聚其数据资源以训练性能更好的机器学习模型。然而，由于这些实体偿还数据收集成本，他们只有在能确保公平和个别合理性等激励时才会参与此类合作。现有框架假定所有实体会同时加入合作，但在实际情况中，由于数据清洗耗时、难以跨越法律障碍或缺乏意识，实体可能会在不同时间点加入。本文讨论了这种分阶段参与的情况。", "innovation": "本文提出了一个公平且时间感知的数据共享框架，该框架包括新颖的时间感知激励。提出了新的方法来确定满足这些激励的奖励值，并展示了如何生成实现这些奖励值的模型奖励，并通过合成和真实世界的数据集实证证明了该方法的性质。", "conclusion": "本文提出的时间感知公平性数据共享框架通过为更早分享数据的实体提供更有价值的奖励，激励等待的实体参与。该框架在理论和实证上都证明了其有效性和优势。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09222", "html_url": "https://arxiv.org/abs/2510.09222", "title": "FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning", "title_en": "FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning", "authors": "Zhenglin Wan,Jingxuan Wu,Xingrui Yu,Chubin Zhang,Mingcong Lei,Bo An,Ivor Tsang", "background": "Flow Matching (FM) 在建模复杂分布方面表现出色，在离线模仿学习中克隆专家行为方面取得优异成绩。然而，尽管 FM 基于的行为克隆表达能力强，但由于缺乏与环境的互动和探索，其政策在超出专家演示的新场景中的泛化能力非常差，突显了在线与环境互动的必要性。然而，通过在线互动优化 FM 政策具有挑战性和低效性，因为梯度计算不稳定且推理成本高。", "innovation": "提出了使用具有简单MLP结构的学生策略探索环境，并通过RL算法在线更新，该算法依赖于关联老师FM模型的奖励模型。老师FM模型包含丰富的专家数据分布信息，不仅用于奖分解模，还用于正则化学生策略的行为，以稳定策略学习。由于学生策略结构简单，避免了FM政策梯度不稳定的问题，实现了高效的在线探索，同时利用了老师FM模型的表达能力。", "conclusion": "全面的实验表明，我们的方法在提高学习效率、泛化能力和鲁棒性方面尤其在从次优专家数据学习时表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09226", "html_url": "https://arxiv.org/abs/2510.09226", "title": "反应可行性预测中的最小充分原因解释", "title_en": "Prime Implicant Explanations for Reaction Feasibility Prediction", "authors": "Klaus Weinbauer,Tieu-Long Phan,Peter F. Stadler,Thomas Gärtner,Sagar Malhotra", "background": "机器学习模型在自动合成规划中已经变得非常重要，它们可以预测化学反应的可能性。尽管这些模型在预测方面取得了成功，但它们通常缺乏透明性和可解释性。研究者们引入了一种新的最小充分原因解释的表述方式，针对化学反应预测任务，提出了一个计算此类解释的算法。初步实验表明，这种最小充分原因解释保守地捕捉到了真正的解释，即这样的解释往往包含多余的键和原子，但始终捕捉到对于预测反应可行性至关重要的分子属性。", "innovation": "研究者提出了一个针对化学反应预测任务的新型最小充分原因解释（也称为最小必要原因）的表述方式，并提出了一种计算此类解释的算法。该算法能在小规模反应预测任务中有效地计算出这些解释。", "conclusion": "初步试验表明，研究者提出的最小充分原因解释能够保守地捕捉到真实的解释，即虽然这些解释可能包含多余的键和原子，但能够确保捕捉到对于预测反应可行性至关重要的分子属性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09246", "html_url": "https://arxiv.org/abs/2510.09246", "title": "基于PCA的数据预测方法", "title_en": "A PCA-based Data Prediction Method", "authors": "Peteris Daugulis,Vija Vagale,Emiliano Mancini,Filippo Castiglione", "background": "在数据科学中，选择适当的值来填补缺失数据是一个常见的问题。本文提出了一种结合传统数学和机器学习元素的新方法，用于填补缺失数据的预测（插补）。该方法基于现有数据和候选数据集所代表的移位线性子空间之间的距离概念。现有数据集通过其第一个主成分所表示的子空间来表示。给出了欧几里得度量下该方法的解决方案。这为处理缺失数据提供了一个新颖的视角，结合了传统的PCA方法和现代的机器学习技术。", "innovation": "提出了一种新的数据填补方法，结合了PCA和机器学习技术。该方法基于移位线性子空间之间的距离计算来填补缺失数据，且给出了欧几里得度量下的具体实现方式，是填补缺失数据问题上的创新尝试。", "conclusion": "该方法为填补缺失数据提供了一种新的有效途径。通过这种方法，可以更准确地填补缺失值，提升数据的完整性和分析结果的质量。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09317", "html_url": "https://arxiv.org/abs/2510.09317", "title": "基于残差信息的代数环解的学习", "title_en": "Residual-Informed Learning of Solutions to Algebraic Loops", "authors": "Felix Brandt,Andreas Heuermann,Philip Hannebohm,Bernhard Bachmann", "background": "本文介绍了一种基于残差信息的机器学习方法，用于用神经网络代理替换方程式基础的Modelica模型中的代数环。现有的传统方法通常需要大量的监督数据，并且在处理代数环时可能会出现模糊解的问题，导致模型收敛到不确定的解，需要通过其他手段进行平均。", "innovation": "该方法采用前馈神经网络训练，直接使用代数环的残差（误差）作为损失函数的一部分，从而省去了对监督数据的需求。此外，这种训练策略能够解决模糊解问题，使代理能够收敛于一致解而非平均多个有效解。", "conclusion": "该方法应用于大规模的IEEE 14-节点系统，实现了与传统仿真实验60%的仿真时间减少，同时通过误差控制机制保持相同的准确度。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09294", "html_url": "https://arxiv.org/abs/2510.09294", "title": "利用合成数据和异常值缓解发展中经济体的模型漂移", "title_en": "Mitigating Model Drift in Developing Economies Using Synthetic Data and Outliers", "authors": "Ilyas Varshavskiy,Bonu Boboeva,Shuhrat Khalilbekov,Azizjon Azimi,Sergey Shulgin,Akhlitdin Nizamitdinov,Haitz Saez de Ocariz Borde", "background": "机器学习模型在金融上的应用极易受到模型漂移的影响，即预测性能随数据分布的变化而下降。这种现象在中亚和高加索地区等发展中国家尤为严重，包括塔吉克斯坦、乌兹别克斯坦、哈萨克斯坦和亚美尼亚，这些地区的宏观经济冲击频繁且不可预测，扰动金融数据。目前，已有研究较少关注这些地区的金融数据集，本研究是首个探讨漂移缓解方法的研究之一。", "innovation": "该研究创新地采用了合成异常值的方法，这是一种尚未广泛探索的策略，用以提高模型在面对突发冲击时的稳定性。研究通过提出一个两层框架来评估有效性，这个框架不仅可以衡量性能下降的程度，还可以评估冲击的严重性。实验结果表明，在宏观经济时间序列数据集上添加少量合成异常值一般可以提高模型的稳定性，尽管这一点对于不同的数据集和模型具有多样性。", "conclusion": "实验结果表明，在考虑的相关宏观经济数据集上添加少量的合成异常值能够普遍提高模型的稳定性，但最佳添加量因数据集和模型的不同而有所不同。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09330", "html_url": "https://arxiv.org/abs/2510.09330", "title": "安全博弈：使用LP求解器平衡安全和信息性对话的黑盒代理AI", "title_en": "Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers", "authors": "Tuan Nguyen,Long Tran-Thanh", "background": "确保大型语言模型（LLMs）符合安全标准是AI部署中的主要挑战。现有的对齐方法主要在训练期间进行操作，例如通过微调或基于人类反馈的强化学习，但这些方法代价高昂且不灵活，需要重新训练来应对新的要求。最近针对推理时对齐的努力缓解了一些这些限制，但仍然假设可以访问模型内部结构，这在实践上是不切实际的，并不适合无法获得模型的第三方利益相关者。因此，需要一种无需重新训练且不需要访问底层LLM架构的模型独立、黑盒框架来提高安全性。", "innovation": "提出了一种模型独立的黑盒框架，用于安全对齐，该框架不需要重新训练或访问底层LLM架构。通过将问题表述为一个两人零和博弈，其最小最大均衡捕获了安全性和相关信息性的最佳平衡点。LLM代理在推理时利用线性规划求解器计算出均衡策略，从而实现对安全和有效性之间的权衡。实验证明，这种黑盒安全对齐方法具有可行性，提供了可扩展、易访问的路径，帮助包括小型组织和资源有限的实体在快速发展中的LLM生态系统中强制执行安全。", "conclusion": "该方法为小型组织和资源有限的实体提供了可扩展和可访问的途径，以在不断发展的LLM生态系统中强制执行安全性。通过黑盒安全对齐实现了安全和有用性的最佳平衡，并证明了其可行性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09325", "html_url": "https://arxiv.org/abs/2510.09325", "title": "从数据中学习均衡的最佳速率学习", "title_en": "Rate optimal learning of equilibria from data", "authors": "Till Freihaut,Luca Viano,Emanuele Nevali,Volkan Cevher,Matthieu Geist,Giorgia Ramponi", "background": "本文分析了多智能体 imitation 学习 (MAIL) 中存在的一些理论缺口，并探讨了非交互式和交互式 MAIL 的样本复杂性问题。在非交互式情景下，证明了统计下限，指出所有策略偏差集中系数是复杂性衡量标准，并表明行为克隆 (BC) 是最优速率的学习策略。对于交互式情景，提出了一种结合了奖励无关强化学习和交互式 MAIL 的框架，并提出了 MAIL-WARM 算法，将最优样本复杂性从 $\text{O}(\\varepsilon^{-8})$ 改进到 $\text{O}(\\varepsilon^{-2})$，这与下限的依赖关系相符。通过数值结果支持理论，并在如格子世界等环境中展示了行为克隆无法学习的情况，说明了该改进方法的有效性。", "innovation": "本文的主要创新包括：1) 确定了非交互式 MAIL 中的所有策略偏差集中系数作为复杂性衡量标准；2) 提出了行为克隆 (BC) 是最优速率的学习方法；3) 提出了结合奖励无关强化学习的交互式 MAIL 框架，并实现了 MAIL-WARM 算法，将样本复杂性从 $\text{O}(\\varepsilon^{-8})$ 改进到 $\text{O}(\\varepsilon^{-2})$；4) 通过数值结果验证了新算法的有效性。", "conclusion": "本文通过研究非交互式和交互式 MAIL 的统计下限和最优样本复杂性，填补了多智能体 imitation 学习中的理论缺口。提出的 MAIL-WARM 算法在样本复杂性方面实现了突破，通过实验证明了新方法在复杂环境中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09379", "html_url": "https://arxiv.org/abs/2510.09379", "title": "序列模型中的任务级洞见来自特征值", "title_en": "Task-Level Insights from Eigenvalues across Sequence Models", "authors": "Rahel Rickenbach,Jelena Trisovic,Alexandre Didier,Jerome Sieber,Melanie N. Zeilinger", "background": "虽然softmax注意力机制在序列模型中表现出色，但其计算复杂度限制了其可扩展性，促使开发更高效的线性替代方案，如状态空间模型（SSMs）。尽管这些替代方案能提高效率，但它们在信息处理方面的根本差异仍知之甚少。本文利用近期提出的动态系统框架，将softmax、normal和线性注意力机制表示为动态系统，通过分析各自特征值谱进行结构化比较，从而更好地理解这些方法之间的差异。", "innovation": "本文通过动态系统框架将不同类型的注意力机制表达为动态系统，并通过分析特征值谱进行结构化比较，这一方法有助于揭示不同注意力机制在信息处理上的根本差异，以及它们如何影响序列模型的性能和任务需求。这种方法为理解序列模型提供了新的视角，并可以进一步指导模型的改进。", "conclusion": "本文通过详细的经验分析表明，特征值影响记忆和长距离依赖建模的关键方面，揭示了与任务需求一致的特征值谱签名。进一步的研究发现，序列模型的架构修改不仅影响特征值谱，还影响任务性能。这些发现进一步加强了特征值分析作为解释、理解和最终提升序列模型性能的原理性度量的观念。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09350", "html_url": "https://arxiv.org/abs/2510.09350", "title": "利用深度学习识别高密度网络中列车延误的时空级联效应", "title_en": "Deep Learning to Identify the Spatio-Temporal Cascading Effects of Train Delays in a High-Density Network", "authors": "Vu Duc Anh Nguyen,Ziyue Li", "background": "铁路网络的运营效率是现代经济体的关键支柱，但持续受到列车延误的级联效应影响。实时交通管理中准确预测这些延误传播是一个关键挑战。现有研究虽然利用了图神经网络（GNNs）来建模铁路网络结构，但在提供网络规模上的多步自回归预测和在决策支持所需的有效解析解释方面仍存在显著差距。这项研究旨在开发并评估一种新的XGeoAI框架，以实现实时、可解释的多步列车延误预测。该模型基于覆盖荷兰铁路网络40%以上的实际数据集，使用图注意力网络（GAT）进行训练。该研究利用GAT模型将系统表示为时空图，结合了如平台和车站拥堵等详细特征。通过采用逐步、k步预测协议进行严格评估，以模拟实际预测误差复合的情况。研究表明，虽然提出的GATv2模型在纯误差指标（MAE）上受到简单的持续基线挑战，但在分类延误事件方面表现更优，这是可靠决策支持工具的重要优势。", "innovation": "开发了一种新的XGeoAI框架，通过两阶段自回归的图注意力网络（GAT）模型，实现了在高密度铁路网络中实时、可解释的多步列车延误预测。该模型结合了详细的空间-时间特征，为决策支持提供了有效的解析解释。", "conclusion": "尽管GATv2模型在纯误差指标（MAE）上挑战了一个简单的持续基线，但在分类和预测列车延误事件方面表现更优，为用于可靠决策支持的工具提供了显著优势。通过逐步、k步预测协议的严格评估，展示了模型在模拟实际预测误差复合情况下的适用性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09382", "html_url": "https://arxiv.org/abs/2510.09382", "title": "CHUCKLE——当人类以简单的方式引导AI学习情绪", "title_en": "CHUCKLE -- When Humans Teach AI To Learn Emotions The Easy Way", "authors": "Ankush Pratap Singh,Houwei Cao,Yong Liu", "background": "当前的情绪识别方法通常依赖于启发式、数据驱动或模型基于的样本难度定义，忽略了对人类感知难度的考量，而在情感识别等主观任务中，这一因素极为关键。现有的课程学习（Curriculum Learning，CL）方法结构化了从简单到复杂的样本训练，有助于渐进学习，但未充分考虑到人类感知难度这一关键因素。因此，需要一种新的框架来实现感知驱动的课程学习，以提高情感识别模型的准确性和鲁棒性。", "innovation": "提出了一种名为CHUCKLE（Crowdsourced Human Understanding Curriculum for Knowledge Led Emotion Recognition）的感知驱动课程学习框架，该框架利用众包数据集中的标注者意见一致性和对齐来定义样本难度，假设对人类有挑战性的片段对机器学习模型同样具有挑战性。实验结果显示，CHUCKLE在LSTM和Transformer模型上的相对平均准确率分别提高了6.56%和1.61%，减少了梯度更新次数，从而提升了训练效率和模型鲁棒性。", "conclusion": "CHUCKLE框架能够通过众包数据集中的标注者一致性来定义样本的难度，使得模型能够更加高效和鲁棒地学习情感。相较于非课程学习基线，该方法显著提高了LSTM和Transformer的相对平均准确率，并有效减少了梯度更新次数。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09388", "html_url": "https://arxiv.org/abs/2510.09388", "title": "HINT: 帮助无效展开迈向有效性", "title_en": "HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness", "authors": "Xinyi Wang,Jinyi Han,Zishang Jiang,Tingyun Li,Jiaqing Liang,Sihang Jiang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao", "background": "强化学习（RL）已成为提升大型语言模型（LLMs）长期链式思考（CoT）推理能力的关键驱动力。然而，如GRPO等现有方法在任务难度超过模型能力时经常失效，导致奖励稀疏和低效训练。虽然先前工作尝试通过使用离策略数据（如结合监督微调SFT或使用提示）来减轻这一问题，但这些方法常常导致策略更新的偏差。\n", "innovation": "作者发现了这些失效的根本原因，称之为‘低训练亲和力’，这种状况源于外部指导与模型策略之间的大规模分布不匹配。为此，作者引入了‘Affinity’（亲和力），作为第一个用于监测探索效率和训练稳定性的量化指标。此外，作者提出了HINT（帮助无效展开迈向有效性）框架，这是一个自适应提示框架，通过提供启发式提示而非直接答案，指导模型自主发现解决方案，从而保持其自主推理能力。\n", "conclusion": "广泛的数学推理任务实验表明，HINT 在提高亲和力方面表现出色，并且在各种规模的模型中表现出了最先进的结果。此外，HINT 还展示了显著更稳定的训练和更有效的数据利用。该研究成果已开源在 Github 上。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09316", "html_url": "https://arxiv.org/abs/2510.09316", "title": "大语言模型提示数据集：深入分析与见解", "title_en": "Large Language Model Prompt Datasets: An In-depth Analysis and Insights", "authors": "Yuanming Zhang,Yan Lin,Arijit Khan,Huaiyu Wan", "background": "随着大语言模型（LLM）的应用越来越广泛，来自平台如GitHub和社交媒体的提示数据集也逐渐增多，涵盖了多种应用和内容类型，促进了LLM的更广泛应用和提示工程的改进。", "innovation": "研究人员首次整理了一个包含不同来源提示数据集的全面列表，代表了下游任务、语言、工程技术、属性和模态的整个谱系。他们提出了一种利用词性标注和依存结构的语义嵌入的提示优化方法，通过引导LLM重构提示以朝向中心表示来提高模型输出的含义。", "conclusion": "研究人员已经把他们所收集的数据集和代码公开，为LLM提示的进一步研究和优化提供了重要资源。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09389", "html_url": "https://arxiv.org/abs/2510.09389", "title": "基于系数动态的序列模型设计原则", "title_en": "Design Principles for Sequence Models via Coefficient Dynamics", "authors": "Jerome Sieber,Antonio Orvieto,Melanie N. Zeilinger,Carmen Amo Alonso", "background": "深度序列模型，从Transformer到State Space Models（SSMs），再到最近的门控线性RNNs，本质上通过过去的值向量进行线性组合来计算输出。现有研究主要集中在如何连接线性RNN与线性注意力，未能系统地对比不同架构之间的差异。本文旨在通过开发一个统一的框架，明确表达输出操作，揭示这些架构中的共通数学主题，并具体涵盖RNN、SSMs及其相关模型中的 softmax 注意机制。", "innovation": "本文提出了一个统一的框架，通过将线性组合系数视作由脉冲输入驱动的自驱动线性动态系统的输出，解释复杂的序列模型架构。这一视角与关注连接线性RNN与线性注意力的方法从本质上不同，不仅能揭示这些架构之间的共通数学主题，还能具体捕捉softmax注意力，而不仅仅局限于RNN和SSM。此外，本文还从中推导出设计原则，如模型的表达力和高效实现之间的权衡、输入选择的几何约束，以及数值稳定的训练和信息保留的条件，从而指导新架构的设计。", "conclusion": "本文通过连接近年来文献中的多个观点和观察，不仅解释了近期设计的成功之处，还为系统设计新的序列模型架构提供了指导性原则。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09333", "html_url": "https://arxiv.org/abs/2510.09333", "title": "高效的噪声双边比较的贝叶斯推断", "title_en": "Efficient Bayesian Inference from Noisy Pairwise Comparisons", "authors": "Till Aczel,Lucas Theis,Wattenhofer Roger", "background": "评估生成模型具有挑战性，因为标准指标往往未能反映人类偏好。人类评估虽然更可靠但成本高昂且噪声较大，因为参与者在专业水平、注意力和勤勉程度上存在差异。双边比较可以提高一致性，但将它们汇总为总体质量分数需要精细建模。", "innovation": "我们提出了BBQ，这是一种贝叶斯Bradley-Terry变体，明确建模了评分者质量，通过期望最大化算法提供了保证单调似然收敛。实验证明，BBQ相较于基线Bradley-Terry模型，即使在嘈杂或众包评分者的情况下也实现了更快的收敛、良好的不确定性估计以及更稳健和可解释的排名。", "conclusion": "这种框架可以更可靠且成本效益地人类评估生成模型。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09378", "html_url": "https://arxiv.org/abs/2510.09378", "title": "第二阶优化在大语言模型中的潜力：全高斯-牛顿方法研究", "title_en": "The Potential of Second-Order Optimization for LLMs: A Study with Full Gauss-Newton", "authors": "Natalie Abreu,Nikhil Vyas,Sham Kakade,Depen Morwani", "background": "近年来，为了加速大语言模型（LLM）的预训练，研究重点放在了利用第二阶结构的计算高效的近似方法上。然而，这种近似方法是否会导致性能的牺牲仍然是一个关键问题。", "innovation": "本文通过应用全高斯-牛顿（GN）正则化器到最大包含150M参数的变压器模型上，设立了一种迭代复杂性的实际上限。结果显示，全GN更新相较于现有优化器有着显著的改进，大幅减少了训练迭代次数，并发现了一种只忽略跨层信息的逐层GN预条件器几乎能够达到全GN方法的效果。", "conclusion": "本文的研究结果表明：(1) GN近似在预条件化方面非常有效，暗示较高阶的损失项可能不是加速收敛速度的关键；(2) 逐层海森矩阵结构包含了足够的信息来实现这些改进中的大部分；(3) 当前的近似方法与理想的逐层先验方法之间存在一个显著的性能差距。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09416", "html_url": "https://arxiv.org/abs/2510.09416", "title": "时间图学习模型学习的内容是什么？", "title_en": "What Do Temporal Graph Learning Models Learn?", "authors": "Abigail J. Hayes,Tobias Schumacher,Markus Strohmaier", "background": "时间图的学习已成为图表示学习中的一个主要课题。虽然高级模型在多个基准测试中表现出强大性能，但近期工作指出常用评估协议的问题，并展示了简单启发式方法的令人惊讶的竞争力。这引发了对时间图学习模型依赖的底层图属性的质疑，具体是哪些属性使模型能够做出预测。", "innovation": "本文通过系统评估七种模型在其对八个关键链接结构属性的捕捉能力上，解决了这一问题。这些属性涵盖了密度、时间模式和边形成机制等多个方面。使用合成和真实数据集来分析模型在这方面的学习表现。研究结果揭示了混合图景：模型在某些属性上能表现出色，但在其他属性上则表现不佳。这项研究揭示了时间图学习模型应用的关键限制，并促进了关于时间图学习研究的可解释性评估。", "conclusion": "研究结果提供了一些实用见解，并促使时间图学习研究更注重可解释性评估。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09423", "html_url": "https://arxiv.org/abs/2510.09423", "title": "深度神经网络和大型语言模型中的权重初始化与方差动力学", "title_en": "Weight Initialization and Variance Dynamics in Deep Neural Networks and Large Language Models", "authors": "Yankun Han", "background": "权重初始化在模型训练的初始阶段影响信号传播和梯度流动。以往的研究已经探讨了不同的初始化策略，但对这些策略在现代深层网络和大型语言模型中的具体效果还没有全面的理论与实践经验相结合的分析。", "innovation": "该论文提供了一个基于理论和经验的关于权重初始化的研究，特别关注两种网络架构：紧凑的ReLU多层感知机和GPT-2样式的变压器。研究通过一系列创新方法，包括对初始标准偏差的对数扫描、不同初始化方法的对比实验以及对12层GPT-2样式的模型的预训练过程追踪，深入理解了经典初始化原则与现代变压器行为之间的联系，为稳健训练提供了简单实用的建议。", "conclusion": "总体而言，该研究将经典初始化原则与现代变压器行为联系起来，并提出了简单实用的方法来指导稳健训练。这些结论不仅适用于深度神经网络，还特别适用于大型语言模型。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09405", "html_url": "https://arxiv.org/abs/2510.09405", "title": "通过特征解耦和对抗训练实现跨接收器通用的RF指纹识别", "title_en": "Cross-Receiver Generalization for RF Fingerprint Identification via Feature Disentanglement and Adversarial Training", "authors": "Yuhao Pan,Xiucheng Wang,Nan Cheng,Wenchao Xu", "background": "RF指纹识别（RFFI）是无线网络安全性中的关键技术，依赖于制造过程中引入的固有硬件级不完美性来实现精确的发射机识别。虽然深度神经网络在提取判别特征方面表现出色，但它们的现实世界部署却受到接收器引起的可变性阻碍。信号由发射器特定特征、信道失真和接收器引起的变化组成。信道均衡可以减轻信道噪声的影响，但接收器引起的特点移位仍然难以解决，这会导致RFFI模型过度拟合接收器特定的模式。当训练和评估使用相同的接收器时，部署过程中替换接收器会导致性能显著下降。", "innovation": "本文提出了一种针对跨接收器变异性的鲁棒RFFI框架，通过结合对抗训练和风格迁移明确地将发射器和接收器特征解耦。通过强制学习具有域不变的表示，该方法将真实的硬件签名与接收器噪声隔离，确保了在接收器变化时的鲁棒性。广泛的实验表明，在各种接收器设置中，该方法的一致优越性优于最先进的基线模型，平均准确率提高了10%。", "conclusion": "本文通过提出的RFFI框架，利用对抗训练和风格迁移方法，有效解决了跨接收器变异性问题，在多种接收器设置中均显示出了比现有最佳基线更好的性能，为RF指纹识别技术提供了新的视角和解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09425", "html_url": "https://arxiv.org/abs/2510.09425", "title": "单峰偏好下的资源受限多臂 bandits 问题", "title_en": "Bandits with Single-Peaked Preferences and Limited Resources", "authors": "Gur Keinan,Rotem Torkan,Omer Ben-Porat", "background": "研究在线随机匹配问题，算法需在预算约束下，T 轮内将 U 个用户逐个匹配至 K 个臂，最大化累计奖励。在没有结构性假设的情况下，找到最优匹配是 NP 难问题，使得在线学习计算上不可行。", "innovation": "研究提出了基于单峰偏好的在线算法，设计了基于 PQ 树的顺序近似方法，使在线算法的遗憾度达到 ̅O(UKT^{2/3})。如果已知单峰结构，提出了一个类似_ucb_的高效算法，遗憾度达到 ̅O(U√(TK))。", "conclusion": "研究通过单峰偏好结构的有效假设有助于克服在线学习中的计算障碍，提出了新的在线算法，显著降低了遗憾度。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09465", "html_url": "https://arxiv.org/abs/2510.09465", "title": "可解释的机器学习在预测初创企业融资、专利申请和退出中的应用", "title_en": "Interpretable Machine Learning for Predicting Startup Funding, Patenting, and Exits", "authors": "Saeid Mashhadi,Amirhossein Saghezchi,Vesal Ghassemzadeh Kashani", "background": "本研究旨在开发一种可解释的机器学习框架，以预测初创企业的资金情况、专利和退出事件。数据来源于2010年至2023年间Crunchbase和美国专利商标局（USPTO）的综合数据，研究涵盖三个时间跨度：未来12个月的下一轮融资、未来24个月的专利申请数量变化和未来36个月内通过首次公开募股（IPO）或收购等方式退出。", "innovation": "研究创新点在于使用一种可解释的机器学习框架来预测初创企业的关键指标，如融资、专利申请和退出情况，并通过实验证明了算法的有效性。研究还采用了预处理方法以避免数据泄露，并使用了逆流行率权重和SMOTE-NC技术来处理类别不平衡问题。", "conclusion": "专利、融资和退出的预测分别达到了AUROC值的0.921、0.817和0.872，这意味着研究提供了透明且可重复的评价体系，能为创新金融服务提供有价值的参考。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09435", "html_url": "https://arxiv.org/abs/2510.09435", "title": "推荐模型中的交叉注意力秘密执行正交对齐", "title_en": "Cross-attention Secretly Performs Orthogonal Alignment in Recommendation Models", "authors": "Hyunin Lee,Yong Zhang,Hoang Vu Nguyen,Xiaoyi Liu,Namyong Park,Christopher Jung,Rong Jin,Yang Wang,Zhigang Wang,Somayeh Sojoudi,Xue Feng", "background": "交叉域序列推荐（CDSR）旨在通过不同领域的异构用户行为序列进行对齐。尽管交叉注意力被广泛用于增强对齐并改善推荐性能，但其背后的机制尚未完全理解。大多数研究者认为交叉注意力是一种残差对齐，即通过参考另一领域的输入数据（作为键和值）从查询输入中移除冗余信息并保留非冗余信息来生成输出。", "innovation": "该研究引入了正交对齐现象，即交叉注意力可以发现查询输入中不存在的新信息。同时，研究者提出这两种对立的对齐机制可以在推荐模型中同时存在。研究发现，当交叉注意力的查询输入和输出正交时，模型在300次实验中性能提升。此外，研究证明，在基准模型中额外加入交叉注意力模块可以超过参数匹配的基准模型，实现每模型参数更好的准确率。这表明正交对齐自然出现的原因是它有助于更好的扩展律。", "conclusion": "希望这些发现可以为多模态研究中的参数高效扩展提供新的方向。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09462", "html_url": "https://arxiv.org/abs/2510.09462", "title": "可信监视器上的适应性攻击颠覆AI控制协议", "title_en": "Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols", "authors": "Mikhail Terekhov,Alexander Panfilov,Daniil Dzenhaliou,Caglar Gulcehre,Maksym Andriushchenko,Ameya Prabhu,Jonas Geiping", "background": "AI控制协议作为一种防禦机制，旨在防止不可信的大语言模型（LLM）代理在自主环境中造成危害。现有的研究将此视为一个安全问题，通过利用部署上下文来隐秘地完成有害任务（例如后门插入）来测试协议的安全性。然而，实践中大多数AI控制协议主要基于LLM监控器，这可能导致监控器成为系统的核心脆弱点。因此，需要研究未能防范的攻击方式，特别是那些了解监控程序和协议的不可信模型发起的适应性攻击。针对此背景，这项研究分析了不可信模型如何通过利用从已知或零样本提示注入来设计适应性攻击，导致当前依赖于监控器的多个控制协议失效，甚至是最近提出的Defer-to-Resample算法也受到影响。这表明，当前的控制机制在面对适应性攻击时存在重大漏洞，需要纳入此类攻击作为未来评价的一个标准组成部分。", "innovation": "本文提出了一种新的适应性攻击方法，通过公开已知的或零样本提示注入，嵌入到模型输出中。这种方法有效对抗了当前大多数依赖监控器的协议，即便是最新的Defer-to-Resample协议也无法避免被这种攻击所利用。", "conclusion": "适应性攻击将成为现有监控器模型中一个重要的漏洞，并且应在未来的评估过程中将此类攻击作为常规组成部分。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09468", "html_url": "https://arxiv.org/abs/2510.09468", "title": "在隐空间上的测地线计算", "title_en": "Geodesic Calculus on Latent Spaces", "authors": "Florine Hartwig,Josua Sassen,Juliane Braunsmann,Martin Rumpf,Benedikt Wirth", "background": "自编码器的隐空间可以提供数据的低维表示，可以通过几何学视角进行研究。以往的工作常常将这些隐空间描述为显式子集，但由于实际情况中的隐空间表示往往存在不准确性，这种方法在实际应用中具有局限性。因此，需要一种能够针对隐空间提供鲁棒模型的方法来研究隐空间几何性质，并能够计算隐空间中的测地线路径以及通过测地线指数映射进行测地线发射。", "innovation": "本文提出了一种新的方法，即将隐空间描述为隐空间中的隐式子流形，并据此开发了一种离散黎曼微积分工具，以解决实际例子中存在的隐空间表示不准确性问题。具体来说，通过学习一个近似的投射到隐空间的方法，最小化去噪目标来获得合适的隐式表示。该方法不仅适用于不同的自编码器，还支持在隐空间中使用不同的黎曼几何。这种方法能够计算连接两个给定点的测地线路径，还能够通过隐空间中的黎曼指数映射射测地线发射。", "conclusion": "该框架被验证在各种不同训练的数据集上的有效性，显示出它在揭示隐空间几何结构和计算测地线路径方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09484", "html_url": "https://arxiv.org/abs/2510.09484", "title": "CRPS-LAM: 匹配边缘分布的区域集合天气预报", "title_en": "CRPS-LAM: Regional ensemble weather forecasting from matching marginals", "authors": "Erik Larsson,Joel Oskarsson,Tomas Landelius,Fredrik Lindsten", "background": "气象预报中的机器学习越来越多地依赖于集合方法来提供概率性预报。基于扩散的模型已经在区域气象学建模（LAM）中表现出色，但这些模型在采样时间上仍然非常耗时。全球气象预报模型基于连续排名概率分数（CRPS）进行训练，并已显示出良好性能，而CRPS-LAM模型是基于CRPS目标提出的，旨在加快采样速度并保持预报细节。", "innovation": "CRPS-LAM通过在一次前向传播过程中注入一个单一的潜在噪声向量来生成集合成员，实现了高达39倍的采样速度提升。与基于扩散的模型相比，CRPS-LAM保持了细尺度预报细节，并且在MEPS区域数据集上的表现与扩散模型相当，显示出一种有效的区域概率性天气预报方法。", "conclusion": "CRPS-LAM方法代表了一种高效的区域尺度集合气象预报方法，能够结合快速采样速度和预报细节，与全球天气预报中的基于CRPS的方法相媲美。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09452", "html_url": "https://arxiv.org/abs/2510.09452", "title": "关于均匀缩放流：一种基于密度对齐的深度单类分类方法", "title_en": "On Uniformly Scaling Flows: A Density-Aligned Approach to Deep One-Class Classification", "authors": "Faried Abu Zaid,Tim Katzke,Emmanuel Müller,Daniel Neider", "background": "无监督异常检测通常围绕两种广泛研究的范式展开。深度单类分类以Deep SVDD为代表，学习正常数据的紧凑潜在表示，而通过归一化流实现的概率模型直接模拟名义数据的似然性。本文展示了均匀缩放流（USFs），一种具有常数雅可比行列式的归一化流，如何精确结合这两种方法。具体而言，我们证明通过最大似然训练USF如何等价于一种独特的Deep SVDD目标，该目标能够防止表征坍缩。这也意味着USFs在保留归一化流的密度忠实性的同时，还能融合单类方法的距离推理能力。此外，本文还展示了USFs如何更紧密地调整负对数似然与潜在范数之间的关系，从而比Deep SVDD或非USFs更能改进异常检测性能。最后，将最新结合单类目标与VAEs的混合方法自然扩展至USFs，进一步推动了基于密度的对齐方法的发展。", "innovation": "本文的创新之处在于提出了均匀缩放流（USFs），它是一种具有常数雅可比行列式的归一化流，能够精确地将深度单类分类和概率模型连接起来。通过最大似然训练USF，使得其能够消除表征坍缩现象，并且其在保留归一化流的密度忠实性的同时，还能集成单类方法的距离推理能力。此外，USFs还能够更紧密地调整负对数似然与潜在范数之间的关系，从而使得其在异常检测中的性能优于现有方法。", "conclusion": "本文的结论指出，USFs作为一种无缝替代现有方法的异常检测架构，能够在多种基准和模型结构上提供一致的性能提升，并显著增强了训练稳定性。这一结果有助于进一步统一现有的两种主要异常检测范式，并推动了理论理解与实际性能的双重进步。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09493", "html_url": "https://arxiv.org/abs/2510.09493", "title": "机器学习算法在慢性肾病预测中的性能分析", "title_en": "Performance Analysis of Machine Learning Algorithms in Chronic Kidney Disease Prediction", "authors": "Iftekhar Ahmed,Tanzil Ebad Chowdhury,Biggo Bushon Routh,Nafisa Tasmiya,Shadman Sakib,Adil Ahmed Chowdhury", "background": "全球约有10%的人口患有慢性肾病(CKD)，导致肾功能下降。为了保护处于危险中的患者不遭受进一步的肾损伤，有效的CKD风险评估和适当的CKD监测是至关重要的。由于机器学习模型具有快速准确的检测能力，它们能够帮助医护人员高效地实现这一目标。因此，目前医疗领域中的许多诊断系统和过程都依靠机器学习的疾病预测能力。", "innovation": "本文设计并建议了用于CKD诊断的疾病预测计算机辅助设计。研究从UCL的机器学习库中获取数据集，并用'均值-模式'和'随机采样方法'补全了少量缺失值。之后，使用了八种机器学习技术建立了模型，并通过技术手段比较结果准确性以找出最高精度的机器学习模型。", "conclusion": "在这项研究中，随机森林和逻辑回归显示出卓越的99%准确率，随后是AdaBoost、XGBoost、朴素贝叶斯、决策树和SVM。KNN分类器模型的准确率为73%，表现最差。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09500", "html_url": "https://arxiv.org/abs/2510.09500", "title": "跨不同空间区域和尺度的流域水温预测的地理意识模型", "title_en": "Geo-Aware Models for Stream Temperature Prediction across Different Spatial Regions and Scales", "authors": "Shiyuan Luo,Runlong Yu,Shengyu Chen,Yingda Fan,Yiqun Xie,Yanhua Li,Xiaowei Jia", "background": "理解环境生态系统对于地球的可持续管理至关重要。然而，现有的基于物理学和数据驱动的模型由于真实环境中存在的数据异质性，在不同空间区域和尺度上的泛化能力不足。这种泛化问题再加上有限的观测样本，对于模型训练的影响进一步加剧了该问题。", "innovation": "Geo-STARS是一个地理感知的时空建模框架，用于预测不同流域和空间尺度的溪流水温。Geo-STARS的主要创新在于引入了地理感知嵌入，利用地理信息显式地捕获不同空间区域和尺度上的共同原则和模式。此外，Geo-STARS将地理感知嵌入集成到带门控机制的时空图神经网络中，使模型能够在稀疏或缺乏观测数据的情况下，通过地理和水文上下文学习复杂的时空模式。", "conclusion": "Geo-STARS在预测溪流水温方面表现出优越的泛化性能，溪流水温是水质的关键因素。利用跨越37年、多个美国东部流域的真实世界数据集，Geo-STARS在不同区域和尺度上的应用中表现出色，优于最先进的基准模型，突显了Geo-STARS在可扩展的数据高效环境监测和决策中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09487", "html_url": "https://arxiv.org/abs/2510.09487", "title": "近最优的二次保证用于模型驱动的对抗性模仿学习", "title_en": "Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning", "authors": "Shangzhe Li,Dongruo Zhou,Weitong Zhang", "background": "我们研究了在线对抗性模仿学习(AIL)，其中代理从离线专家演示中学习，并在线与环境交互但没有奖励访问。尽管有一些强有力的实验结果，但在线交互的益处和随机性的影响仍然没有很好地理解。因此，我们通过引入基于模型的AIL算法(MB-AIL)并为专家数据和奖励无关交互建立了通用函数逼近下的无窗宽、二次样本复杂性保证来解决这些缺口。这些二次界提供了基于相关政策回报方差的实例依赖的结果，并随着系统接近确定性会趋紧。", "innovation": "我们提出了MB-AIL算法，并建立了无窗宽、二次样本复杂性保证，该保证适用于一般函数逼近下的专家数据和奖励无关交互。还与新构建的硬实例家族的信息论下界相结合，展示了MB-AIL在专家数据有限的情况下达到在线交互的最小最大最优样本复杂度（对数因子除外），并且在间断、精确度和策略方差依赖方面与现有方法相当。实验进一步验证了我们的理论发现，表明MB-AIL的实用实现与现有方法的样本效率相当或更好。", "conclusion": "我们的研究表明，MB-AIL算法不仅在理论上达到了最优样本复杂度，并且在实验中也表现出与现有方法相当或更好的样本效率。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09566", "html_url": "https://arxiv.org/abs/2510.09566", "title": "资源高效神经网络训练的自动化演化优化", "title_en": "Automated Evolutionary Optimization for Resource-Efficient Neural Network Training", "authors": "Ilia Revin,Leon Strelkov,Vadim A. Potemkin,Ivan Kireev,Andrey Savchenko", "background": "神经网络模型优化面临许多关键挑战，包括分布式计算、压缩技术和高效训练。这些问题的重要性在于，随着对可扩展且资源高效的模型需求增加，需要解决这些问题。这些挑战包括如何优化模型架构和训练策略以提高模型性能和可扩展性，而不牺牲目标指标的表现。", "innovation": "开发了一种新的自动化机器学习（AutoML）框架——参数高效训练与稳健自动化（PETRA），采用演化优化方法来优化模型架构和训练策略。PETRA融合了剪枝、量化和损失正则化三项技术，以提高神经网络模型的性能和可扩展性，同时减少了模型大小和延迟，提升了吞吐量。", "conclusion": "实验结果表明，PETRA能够显著减少模型大小（最高达75%）、降低延迟（高达33%）并提高吞吐量（13%），而不影响目标指标的表现。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09596", "html_url": "https://arxiv.org/abs/2510.09596", "title": "BaNEL: 使用仅负奖励进行生成建模的探索后验", "title_en": "BaNEL: Exploration Posteriors for Generative Modeling Using Only Negative Rewards", "authors": "Sangyun Lee,Brandon Amos,Giulia Fanti", "background": "当前生成模型依赖大量监督数据和指示生成质量的奖励函数得以优化。这些模型假设监督数据提供了预训练模型所需的知识，而奖励函数则提供了具体的改进方向。但在重要问题的最具挑战性实例中，主要存在两个问题：(1)基本生成模型得到接近零的奖励信号；(2)访问奖励Oracle的成本高昂。这种情况下，提出了不同于常规基于奖励的后训练的标准学习挑战。", "innovation": "提出了一种名为BaNEL（Bayesian Negative Evidence Learning）的算法，通过仅使用失败尝试并最小化奖励评估次数(NREs)来后训练模型。该方法将学习失败背后规律的问题重新定义为闭环生成建模问题，运用这一模型来评估新数据是否类似于先前的失败，并引导生成远离这些失败。这一方法在多个稀疏奖励任务中无须观察任何成功的样本，也无需像现有方法那样使用大量的奖励评估，就能显著提高模型性能。", "conclusion": "BaNEL能够在不观察任何成功样本的情况下，通过评估和避免先前失败来提高模型表现，在几类稀疏奖励任务中取得了显著的优势。相比于现有方法，BaNEL在成功率上提高了几个数量级，同时使用了更少的奖励评估次数。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09485", "html_url": "https://arxiv.org/abs/2510.09485", "title": "局部最优的私密抽样：超越全局最小最大", "title_en": "Locally Optimal Private Sampling: Beyond the Global Minimax", "authors": "Hrad Ghoukasian,Bonwoo Lee,Shahab Asoodeh", "background": "该论文致力于在局部差分隐私（LDP）条件下对分布进行抽样。给定一个私人分布P ∈ P，目标是在保持生成的分布与P在f-散度上的接近性的同时，满足LDP的约束。这一任务体现了在强隐私保证下生成真实数据的基本挑战。以往研究，如Park等人（NeurIPS'24）聚焦于一类分布的整体最小最大最优性，而本文则采取局部视角，专注于固定分布P0附近的最小最大风险，且其值依赖于P0与隐私水平。", "innovation": "1. 将先前的工作从纯粹的LDP扩展到更一般的函数LDP框架。2. 证明了全局最优的函数LDP抽样器在约束于P0附近分布时，也构成了局部最优的抽样器。3. 提出了一个简单的闭式表达式用于局部最小最大最优抽样器，该式不依赖于f-散度的选择。4. 局部框架自然地适用于公共数据支持下的私人抽样情景，其中公共数据分布由P0表示。5. 通过与现有全局方法的实证比较，演示了局部最优抽样器在该情境下的优越性能。", "conclusion": "研究证明了局部视角在私人抽样中的重要性，并提出了一种新的最优抽样方法，该方法能够在满足强隐私要求的同时产生更真实的数据样本。此外，局部框架为结合公共和私人数据集提供了新的理论基础。研究表明，该局部最优抽样器在实际应用中表现出更好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09593", "html_url": "https://arxiv.org/abs/2510.09593", "title": "STaTS: 统计窗口合并实现结构感知的时间序列总结", "title_en": "STaTS: Structure-Aware Temporal Sequence Summarization via Statistical Window Merging", "authors": "Disharee Bhowmick,Ranjith Ramanathan,Sathyanarayanan N. Aakur", "background": "时间序列数据通常包含潜在的时间结构、局部平稳性之间的转换、重复模式和变异突增，这些特性在标准表征学习管道中很少被充分利用。现有模型通常处理原始数据或固定的窗口序列，将所有时间步视为同样具有信息性，这导致了效率低下、鲁棒性差以及处理长且嘈杂序列时可扩展性有限的问题。", "innovation": "我们提出了STaTS，一个轻量级的无监督框架，名为结构感知时间统述，能够自适应地压缩一元和多元时间序列，并将其压缩为紧凑的信息保留的词序列。该框架通过BIC为基础的统计分歧标准检测时间窗口的多个时间分辨率下的变化点，然后使用简单的函数（如均值）或生成模型（如GMM）来总结各个时间段。该过程实现了高达30倍的序列压缩率，同时保留核心的时间动态，无需重新训练即可作为模型无感知的预处理工具，并可与现有的无监督时间序列编码器集成。广泛实验展示了STaTS使得模型性能恢复到原有的85-90%，同时显著减少了计算成本，并能实现较好的抗噪性和差异性结构的保留。", "conclusion": "这些结果将STaTS确立为高效、结构感知的时间序列建模的一种基础方法，可以作为一种原则性的、通用的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00670", "html_url": "https://arxiv.org/abs/2509.00670", "title": "PyNoetic: 一种用于开发无代码EEG脑机接口的模块化Python框架", "title_en": "PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces", "authors": "Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo", "background": "基于脑电图(EEG)的脑机接口(BCI)已发展成为一项变革性技术，应用于机器人、虚拟现实、医学和康复等多个领域。然而，现有的BCI框架存在一些局限性，包括缺乏分级的灵活性，不利于实验研究；对编程缺乏经验的研究人员学习曲线陡峭；由于依赖专有软件导致成本增加；缺乏全面的功能，迫使研究人员使用多种外部工具，影响研究结果。", "innovation": "PyNoetic是一种模块化BCI框架，旨在满足BCI研究中多样化的需要。它是一个包含BCI设计整个过程（包括刺激呈现、数据采集、通道选择、滤波、特征提取、去噪、模拟和可视化）的python框架。PyNoetic引入了一个直观的端到端GUI和一个独特的拼接式可配置流程图，使无代码BCI设计变得简单易懂，适合编程经验不足的研究人员。对于高级用户，它也支持无缝集成自定义功能和新算法，确保在每个设计阶段具有可适应性。PyNoetic包含丰富的分析工具，如机器学习模型、脑连接度指数、模拟的系统测试功能以及对新范式的评估方法。PyNoetic的优势在于其在离线和实时BCI开发中的多功能性，简化了设计流程，使研究人员能够更专注于BCI开发的复杂方面，从而加快研究进程。", "conclusion": "PyNoetic在模块化设计、端到端GUI以及无缝集成自定义功能方面展现出优势，为无代码BCI开发提供了强大支持，促进了BCI技术的发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09594", "html_url": "https://arxiv.org/abs/2510.09594", "title": "MODE：利用混合动态专家学习复杂系统的组合表示", "title_en": "MODE: Learning compositional representations of complex systems with Mixtures Of Dynamical Experts", "authors": "Nathan Quiblier,Roy Friedman,Matthew Ricci", "background": "生命科学中的动力系统通常由复杂的混合动态组成，这些动态具有一系列重叠的行为模式。细胞亚群体可能从周期性动态转变为平衡态，或者向不同的发育方向分支。这些转换往往显得无序且不规则，给传统的基于流动的动力学建模技术带来了挑战，这些技术假设局部动态连续平滑。为了应对这一挑战，本文提出了MODE（混合动力专家模型）图形建模框架，该框架采用神经门控机制，将复杂的动态分解为稀疏、可解释的组成部分，从而实现自发发现行为模式和跨越不同动态模式转换的准确长期预测。由于本文框架中的代理可以根据需要跳转到不同的动态规则，MODE 对这些无序的转变特别适用。", "innovation": "MODE框架中引入了神经门控机制，将复杂的动态系统分解成稀疏、可解释的组件，同时实现了行为模式的自发发现和长期预测。对于无序转换，MODE特别为其量身定制，能够跨越不同动态模式的转换进行精确预测。该方法通过一系列合成数据和真实数据集的测试证明了其有效性，特别是在无监督分类任务和细胞生物学中的关键周期性和分支过程预测方面表现出色。MODE多应用于人类单细胞RNA测序数据，不仅能够区分增殖和分化动态，还能预测细胞最终命运的承诺时间，为计算生物学领域的重大挑战提供了新的解决方案。", "conclusion": "MODE方法通过在其框架中引入神经门控机制，将复杂的动力学分解为稀疏、可解释的组件，成功实现了对不同动态模式之间无序转换的精确预测和长期预测。该方法在合成和实际数据集上的测试证明了其有效性，并展示了其在细胞生物学中的应用潜力，特别是在区分细胞增殖与分化动态以及预测细胞命运承诺时间方面表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08590", "html_url": "https://arxiv.org/abs/2510.08590", "title": "进化计算作为自然生成人工智能", "title_en": "Evolutionary Computation as Natural Generative AI", "authors": "Yaxin Shi,Abhishek Gupta,Ying Wu,Melvin Wong,Ivor Tsang,Thiago Rios,Stefan Menzel,Bernhard Sendhoff,Yaqing Hou,Yew-Soon Ong", "background": "生成型人工智能（GenAI）已经在多个领域取得了显著成功，但其能力和表现仍然局限于有限训练集的统计模型和基于局部梯度信号的学习方式。这种局限性导致生成的结果常常带有更多的衍生特征而非真正的创造能力。相比之下，进化计算（EC）提供了一种通过探索自然选择下的新解空间来提升多样性和创造力的途径，从而扩展生成能力，超出可用数据的限制范围。", "innovation": "本文建立了进化计算与生成型人工智能之间的基础联系，重新定义进化计算为‘自然生成型人工智能’（NatGenAI），这是一种由探索型搜索引导的自适应选择生成范式。文中还展示了经典以父母为中心的操作如何模仿传统的生成型人工智能，而中断性操作则能够实现有结构的进化跃迁，通常在几代之内生成超出分布范围的创新成果。此外，进化多任务操作提供了一种无可比拟的方法来整合中断性进化计算（包括跨域重组进化特性）和可控选择机制（允许新解决方案生存）以促进持久的创新。", "conclusion": "通过重塑进化计算为自然生成型人工智能，本文强调有结构的中断和选择压力调节作为推动创造力的核心驱动力。这种观点将生成范式扩展到传统界限之外，并将进化计算置于推动探索性设计、创新、科学发现以及生成型人工智能时代开放式生成的关键位置。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08591", "html_url": "https://arxiv.org/abs/2510.08591", "title": "深度神经网络的持续主导地位：对量子机器学习和脉冲神经网络根本限制的批判性分析", "title_en": "The Enduring Dominance of Deep Neural Networks: A Critical Analysis of the Fundamental Limitations of Quantum Machine Learning and Spiking Neural Networks", "authors": "Takehiro Ishikawa", "background": "最近，量子机器学习（QML）和突触神经网络（SNNs）取得了进步，展现出革命性人工智能的巨大潜力。但本文指出，短期内这些技术不太可能取代深度神经网络（DNNs）。QML因局部单元约束、测量引起的态坍缩、荒原高原现象和高测量开销等问题，难以适应反向传播。SNNs则因带宽限制、难以处理长距离依赖和语言任务中的语义编码等问题受到限制。", "innovation": "文章探讨了DNNs相比QML和SNNs在反向传播、正则化技术的稳健性及创新的局部响应最大值池化（LRMs）技术在推理时计算的优势，这些技术使DNNs能够通过强化学习和搜索算法（如MCTS）实现自我改进，同时减轻数据稀缺问题。实验证据来自几款模型，如xAI的Grok-4 Heavy和gpt-oss-120b，证明了DNNs在性能上的优越性。", "conclusion": "QML和SNNs可能会在某些特殊领域发挥作用，但DNNs因其高效的反向传播、稳健的正则化、推理时间计算的优势等，仍然是推动AI进步的主要实用框架。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08600", "html_url": "https://arxiv.org/abs/2510.08600", "title": "Recover-LoRA: 低秩适应实现受损语言模型的数据无关准确度恢复", "title_en": "Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation", "authors": "Devleena Das,Rajeev Patwari,Ashish Sirasao", "background": "在模型部署过程中，诸如量化、剪枝、格式和数据类型转换、模型导出和序列化等推断优化可能会影响语言模型任务的性能。尽管大多数致力于性能恢复的工作主要集中在鲁棒的量化技术上，但本研究关注的是从任何导致模型权重下降的源头中恢复模型准确性，特别是不恰当的模型序列化。因此，本研究旨在提出一种轻量级且数据无关的方法Recover-LoRA，以恢复受损模型的准确性。Recover-LoRA利用合成数据和logit蒸馏在选择性的层上学习LoRA适配器，从而使受损模型与其全精度模型对齐。\n", "innovation": "本研究提出了Recover-LoRA方法，这是一种轻量级且数据无关的方法，用于恢复受损模型的准确性。该方法使用合成数据和logit蒸馏来学习LoRA适配器，应用于选择性的层，以帮助将受损模型与全精度模型对齐。研究还调查了Recover-LoRA在不同大小的语言模型上的应用效果，包括具有不同注意力架构、多头注意力（MHA）和组查询注意力（GQA）的模型，以及多个评估数据集。\n", "conclusion": "研究结果表明，Recover-LoRA在具有多头注意力（MHA）和组查询注意力（GQA）的不同大小语言模型中，能够恢复5-17%的模型准确性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08592", "html_url": "https://arxiv.org/abs/2510.08592", "title": "较少多样性，较少安全：大型语言模型测试时缩放的间接但普遍风险", "title_en": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models", "authors": "Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra", "background": "TTS（Test-Time Scaling）通过探索多个候选响应，然后在这些候选集中找到最佳输出来改进LLM（Large Language Models）的推理。TTS背后的一个隐含前提是，充分多样化的候选池能够提高可靠性。然而，该研究展示了TTS中存在一种未被识别的失效模式：当候选多样性减少时，即使是适度减少，TTS也更有可能生成不安全的输出。作者还通过广泛的实验发现，这种效应通常比直接具有高对抗性意图得分的提示更为显著，且这种现象不仅限于特定的TTS策略和开源模型，也存在于闭源模型中，表明这是一种普遍存在的TTS特性，而不是特定模型的特性。此外，作者发现，许多广泛使用的安全性护栏分类器（如Llama-Guard和OpenAI Moderation API）无法检测由RefDiv生成的对抗性输入提示，这表明现有的防御措施对这种基于多样性的失效模式提供的保护有限。", "innovation": "提出了一个参考导向的多样性减少协议（RefDiv），作为诊断攻击用于压力测试TTS管道。实验表明，通过限制多样性能够一致地反映TTS产生不安全结果的速度。即使在低水平多样性限制下，TTS也更可能生成不安全的输出。实验还证明了RefDiv引发的这种现象扩展到了不同的TTS策略以及闭源模型，并且现有的安全护栏分类器对这种基于多样性的失效模式提供的保护有限。这些发现强调了在设计TTS策略时需要考虑这种风险的重要性。", "conclusion": "通过这项工作，作者希望能够促使未来在设计TTS策略时不仅要关注其有效性，还要考虑其对多样性的敏感性，并确保对由RefDiv所展示的多样性的针对性压力测试具有鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08601", "html_url": "https://arxiv.org/abs/2510.08601", "title": "Mnemosyne: 边缘基于的大语言模型的人类启发式无监督长期记忆架构", "title_en": "Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs", "authors": "Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)", "background": "长期记忆对于自然和现实对话至关重要。当前的大语言模型（LLM）记忆系统依赖于粗暴的上下文扩展或静态检索管道，这两种方法在边缘受限设备上表现不佳。研究介绍了一种名为Mnemosyne的无监督、受人类启发的长期记忆架构，专门设计用于边缘部署的LLM。该架构模拟人类记忆过程，采用基于图的存储、模块化物质和冗余过滤、记忆提交和修剪机制，以及基于概率的内存检索，伴随着时间衰减和刷新过程。", "innovation": "Mnemosyne采用了基于图的存储、模块化物质和冗余过滤、记忆提交和修剪机制，以及模拟人类记忆的基于概率的内存检索。它还引入了一个从固定长度的内存图中高效提取的核心摘要，用于捕获用户的个性和其他领域特定的长期细节。此外，Mnemosyne在长程对话中表现出色，人的盲测中展现出最高的65.8%的真实性和长期记忆能力，超过了同基线RAG的31.1%。与其他同类技术相比，它在时间推理和单步检索的LoCoMo基准测试中也达到了当前最高分，且总体得分第二高，超过了Commonly使用的Mem0和OpenAI基线。", "conclusion": "研究表明，通过使用边缘兼容且易于转移学习的无监督记忆架构，可以实现更好的事实回忆、增强的时间推理和更加自然的用户交互回应。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08610", "html_url": "https://arxiv.org/abs/2510.08610", "title": "基于相对位置的代码片段切分方法在代码仓库级别代码完成任务中的丰富语境检索", "title_en": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "authors": "Imranur Rahman,Md Rayhanur Rahman", "background": "代码补全可以提高开发人员的效率并简化开发生命周期。尽管现代集成开发环境提供了代码补全功能，但缺乏关于哪种上下文最适合代码补全的研究，尤其是基于集成开发环境中可用信息的大型语言模型优化代码补全性能。研究表明，通过对代码仓库进行预先处理，将其切分成较小的代码片段，然后使用基于语法规则和语义相似度的代码片段检索方法，结合相对位置，可以显著提高代码补全任务的性能。", "innovation": "提出了一种有效的代码片段收集策略，该策略包括代码仓库预先处理成较小的代码片段，并通过语法和语义相似度的代码片段检索方法结合相对位置来提高代码补全任务的性能。", "conclusion": "代码切分和片段的相对位置在最终上下文中显著提升了代码补全任务的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak：通过潜在空间反馈破解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "背景区分了 Jailbreaks 作为对抗性攻击的目标，即绕过大型语言模型内置的安全机制。现有的自动 Jailbreak 攻击通常通过优化对抗性后缀或适应长提示模板来迫使模型生成受限制或有害的初始部分响应。已有研究依赖于这些机制来解锁模型响应，但可以通过基于困惑度的过滤器来检测这类攻击。本文指出，这类攻击可以通过简单的困惑度过滤器被识别。为了克服这一问题，作者提出了 LatentBreak，一种白盒 Jailbreak 攻击方法，能够生成自然且低困惑度的对抗性提示，规避此类防御措施。", "innovation": "创新点在于提出了一种名为 LatentBreak 的白盒 Jailbreak 攻击方法。该方法通过在输入提示中替换同义词而不是添加高困惑度的对抗性后缀或长模板来生成自然的对抗性提示。这些同义词的选取标准是它们在潜在空间中与无害请求的表示之间的距离最小化。实验结果表明，LatentBreak 生成的对抗性提示更短，且困惑度更低，能够更好地对抗以困惑度为基础的防御措施。", "conclusion": "结论是，LatentBreak 能够通过生成更自然且低困惑度的对抗性提示，显著提高对诸多安全对齐模型的安全性，从而优于竞争对手的 Jailbreak 算法。这种通过潜在空间反馈的方法能够有效破解大型语言模型的安全机制。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08605", "html_url": "https://arxiv.org/abs/2510.08605", "title": "向更安全的网络迈进：多语言多代理大语言模型以减轻对抗性虚假信息攻击", "title_en": "Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks", "authors": "Nouar Aldahoul,Yasir Zaki", "background": "数字平台上的信息错误广泛传播，对公众言论、情感稳定和决策能力构成了威胁。尽管之前的工作已经探讨了各种对抗性攻击在虚假信息检测中的影响，但本研究特别关注的语言切换（在英语、法语、西班牙语、阿拉伯语、印地语和中文之间进行切换）及其翻译，还有查询长度膨胀（在总结之前）和结构重塑为多项选择题。", "innovation": "本研究提出了一种多语言、多代理的大语言模型框架，结合检索增强生成技术，并将其部署为网络插件进入在线平台。这一框架可应用于多种对抗性虚假信息攻击，突显了基于AI的虚假信息检测在保护网络事实的完整性方面的重要性，同时展示了插件部署在实际Web应用程序中的可行性。", "conclusion": "本研究致力于通过多语言多代理大语言模型框架减轻对抗性虚假信息攻击，强调了AI在虚假信息检测和保护在线事实完整性方面的重要作用，展示了这种框架在实际Web应用中的部署可行性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08602", "html_url": "https://arxiv.org/abs/2510.08602", "title": "human texts are outliers: detecting llm-generated texts via out-of-distribution detection", "title_en": "Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection", "authors": "Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu", "background": "近年来，大型语言模型（LLMs）如ChatGPT、DeepSeek和Claude的飞速发展使得人工智能生成的文本在数字通信中的占比显著增加。这加剧了对可靠检测方法的需求，以区分人类创作和机器生成的内容。现有方法（无论是零样本方法还是监督分类器）大都将此任务视为二分类问题，通常导致在不同领域和模型之间的泛化能力较差。", "innovation": "本文提出了将检测任务重新定义为异常值检测问题的观点。人类写作的文本实际上并不形成统一的分布，其多样性和复杂性不能仅通过有限的采样来有效捕捉。以往的方法 memorizes 当前观测到的 OOD 特征而不是学习‘非 ID’行为的本质，这限制了到未见过的人类创作输入的泛化能力。基于这一观察，本文提出了使用一种一类学习方法（包括 DeepSVDD 和 HRN）和基于得分的学习技术（如能量方法），从而实现稳健且可泛化的性能。实验验证了该异常值检测方法的有效性。与 DeepFake 数据集相比，该方法在 AUROC 和 AUPR 上达到 98.3%，FPR95 仅为 8.9%。此外，该检测框架经过多语言、攻击和未知模型及领域的测试，证明了其稳健性和泛化能力。", "conclusion": "本文提出了一种基于异常值检测的人工智能生成文本检测方法，将人类创作的文本视为分布异常值，机器生成的文本作为规范样本。实验验证了该方法的广泛适用性和泛化性能，并在多语言及未知模型下保持了稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "哪个更好：锁定还是漂浮以减少过时和漏洞依赖项？", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发人员经常使用版本约束来指定项目的依赖版本。锁定依赖项可以减少破折号变化的风险，但会带来手动管理过时和漏洞依赖项替换的成本。与此相反，漂浮可以自动获取修复程序和安全修复程序，但会带来破折号变化的风险。尽管安全从业人员建议锁定依赖项以防止软件供应链攻击（例如恶意包更新），但由于锁定是最严格的版本约束，锁定也最可能导致依赖项过时。然而，尚不确定不同版本约束类型的变化如何影响依赖项成为过时或漏洞依赖项的可能性。", "innovation": "本研究通过大规模实证评估不同版本约束类型对依赖项成为过时或漏洞依赖项的可能性的影响，来辅助开发人员做出知情的依赖项版本约束选择。研究首先识别了依赖项版本约束使用趋势和开发者在npm、PyPI和Cargo生态系统中版本约束类型的变更模式。然后通过生存分析模式依赖项状态转换，并估计使用锁定与其余版本约束类型相比，成为过时或漏洞依赖项的可能性变化。", "conclusion": "在使用锁定与其他版本约束类型相比，最常见的版本约束类型是漂浮-次要版本，锁定是最常用的。我们还发现最不可能导致过时的版本约束是漂浮-主要版本，最不可能导致漏洞依赖项的是漂浮-次要版本。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08617", "html_url": "https://arxiv.org/abs/2510.08617", "title": "脑肿瘤分割中数据增强和损失函数的可重复评估", "title_en": "Reproducible Evaluation of Data Augmentation and Loss Functions for Brain Tumor Segmentation", "authors": "Saumya B", "background": "脑肿瘤分割对于诊断和治疗计划至关重要，但目前仍存在类别不平衡和模型泛化能力有限等问题。针对这些问题，该研究通过使用焦点损失和基本的数据增强策略，评估了U-Net分割性能，并在公共MRI数据集上进行了实验研究，重点关注焦点损失参数的调优及三种数据增强技术（水平翻转、旋转和缩放）的影响。", "innovation": "该研究提出了一种可重复评估U-Net在脑肿瘤MRI分割性能的方法，通过使用焦点损失和基本的数据增强策略。同时，研究还通过调优焦点损失参数并评估三种数据增强技术来提升分割效果，并通过将所有代码和结果公开，建立了透明且可重复的基准，以指导未来关于数据增强策略和损失函数设计的研究工作。", "conclusion": "U-Net结合焦点损失在脑肿瘤分割中达到了90%的精度，与最先进的结果相当。通过提供透明且可重复的基准，该研究为未来相关领域的研究奠定了基础，并促进了针对脑肿瘤分割的数据增强和损失函数设计方面的进步。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08619", "html_url": "https://arxiv.org/abs/2510.08619", "title": "自主科学代理演化网络中的假设狩猎", "title_en": "Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents", "authors": "Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar", "background": "大规模的科学数据集——涵盖健康生物银行、细胞图谱、地球再分析等方面——为不受到特定研究问题约束的探索性发现提供了机会。本文将这一过程称为假设狩猎，即通过持续在庞大而复杂的假设空间中探索来逐步寻找洞见。", "innovation": "本文提出了一种名为AScience的框架，将其发现过程建模为代理、网络和评价规范之间的互动，并通过ASCollab实现了一个由具有异质行为的LLM基于代理组成的分布式系统。这些代理自我组织成不断进化的网络，持续生成和同行评审研究成果，在共享的评价标准下进行。实验证明，这种社会动态有助于在多样-质量-新颖性前沿积累专家评级的结果，包括重新发现已建立的生物标志物、扩展已知路径，并提出新的治疗靶点。", "conclusion": "虽然湿实验室验证仍然是不可或缺的，但我们的实验表明，结构化、能动性的网络可以支持大规模的探索性假设狩猎。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08728", "html_url": "https://arxiv.org/abs/2510.08728", "title": "结构化输出正则化：一种用于少量样本迁移学习的框架", "title_en": "Structured Output Regularization: a framework for few-shot transfer learning", "authors": "Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay", "background": "传统迁移学习通常通过冻结预训练网络中的部分权重并增加任务特定的层来复用大型预训练网络。这种方法虽然计算效率高，但也限制了模型适应领域特定特征的能力，并且在数据非常有限时仍可能导致过拟合。", "innovation": "提出了一种名为结构化输出正则化（SOR）的简单且有效的框架，通过冻结内部网络结构（如卷积滤波器）并结合分组lasso和$L_1$正则化，使模型能够针对特定数据进行调整，同时保持参数量最小，并适用于各种网络组件，如卷积滤波器或神经网络中的各种块，扩展了其在迁移学习任务中的应用范围。", "conclusion": "在三个少量样本医学成像分类任务中评估了SOR框架，结果表明使用DenseNet121和EfficientNetB4作为基础模型，可以获得与现有基准相当的结果。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08632", "html_url": "https://arxiv.org/abs/2510.08632", "title": "通过层次扩散语言模型进行下一语义尺度预测", "title_en": "Next Semantic Scale Prediction via Hierarchical Diffusion Language Models", "authors": "Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola", "background": "介绍了层次扩散语言模型（HDLM），这是一种新的离散扩散模型家族，用于语言建模。HDLM 模型基于层次词汇，其中低级别具有详细语义的词汇以单射方式映射到高级别具有粗粒度语义的词汇。在正向过程中，每个词汇单元根据调度程序独立地被扰动为更具抽象语义的较高层次祖先，而在逆向过程中，模型逐步预测接下来，更具细节的语义。总的来说，HDLM 为语言建模提供了一种一般的时间变化下一语义尺度预测过程。", "innovation": "提出了层次扩散语言模型（HDLM），这是一种新颖的模型家族，能达到根据层次词汇进行语义尺度预测的效果。该模型不仅提供了离散扩散模型的一种新视角，还能够灵活实现并包含现有的MDLM（Minimum Disagreement Latent Model）作为其特例。此外，还有依据此模型提出的实际训练技术。", "conclusion": "通过广泛的文本生成实验验证了 HDLM 的有效性，其验证和生成困惑度都明显低于基准模型。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08726", "html_url": "https://arxiv.org/abs/2510.08726", "title": "Neptune：面向GPU的空间性和并行性的高级机器学习操作融合", "title_en": "Neptune: Advanced ML Operator Fusion for Locality and Parallelism on GPUs", "authors": "Yifan Zhao,Egan Johnson,Prasanth Chatarasi,Vikram Adve,Sasa Misailovic", "background": "操作融合已成为深度学习的关键优化技术，通过合并多个深度学习操作来提升数据复用并减少全局内存传输。然而，现有的张量编译器处理涉及循环携带依赖关系的复杂归约计算（如注意力机制）时存在困难。", "innovation": "Neptune提出了一种新的高级操作融合方法，故意打破某些现有依赖关系，并通过构建代数修正表达式来补偿，从而让内核能够产生正确的结果。", "conclusion": "Neptune从简单的注意力代码和高层次调度模板开始，在十个基于注意力的基准测试中表现出色，超越了现有的编译器（如Triton、TVM和FlexAttention，包括基于Triton的FlashAttention实现）。在来自NVIDIA和AMD的四种不同GPU架构中，Neptune生成的内核平均速度提高了1.35倍，展示了其在深度学习工作负载中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08703", "html_url": "https://arxiv.org/abs/2510.08703", "title": "使用基于谱系引导的图注意模型破译结核分枝杆菌中的正向选择", "title_en": "Decoding Positive Selection in Mycobacterium tuberculosis with Phylogeny-Guided Graph Attention Models", "authors": "Linfeng Wang,Susana Campino,Taane G. Clark,Jody E. Phelan", "background": "结核分枝杆菌（M. tuberculosis）的遗传变异决定了其耐药性、传染性和毒力。谱系树捕捉了分离株之间的进化关系，为检测适应性信号提供了自然框架。现有研究基于谱系树分析适应性变异，但尚未有效转化为神经网络分析的图形结构。", "innovation": "本研究提出了一种基于谱系引导的图注意力网络（GAT）方法，将SNP注释的谱系树转换为神经网络分析的图形结构。通过两层注意力机制、残差连接、全局注意力聚合和多层感知器分类器等特征，模型取得了88%的测试集准确率，并成功识别出41个在多个谱系中具有趋同进化的“不确定”变异，表明正向选择的存在。", "conclusion": "研究证明了将谱系树转换为GNN兼容结构的可能性，并强调基于注意力的模型在检测正向选择方面的有效性，为基因组监控和变异优先级划分提供了有力工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08631", "html_url": "https://arxiv.org/abs/2510.08631", "title": "使用层次高斯混合模型的先验不确定性进行LiDAR语义分割的离群值检测", "title_en": "Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs", "authors": "Hanieh Shojaei Miandashti,Claus Brenner", "background": "除了通过精确的LiDAR点云语义分割实现准确的场景理解外，检测训练期间未遇到的离分布对象（OOD）实例对于防止将未知对象错误地归类到已知类别中至关重要。监督离群值检测方法依赖于辅助OOD数据集，而无监督方法则避免这种需求但一般依赖于预测熵，即通过平均多个后验权重样本得到的预测分布的熵。然而，这些方法经常会混淆模型的（epistemic）和数据的（aleatoric）不确定性，在分布区归类上进行错误分类。", "innovation": "我们提出了一种无监督的离群值检测方法，该方法利用了层次贝叶斯模型中的高斯混合模型（GMM）参数的先验不确定性。该方法无需辅助数据或额外的训练阶段，与先前作品中采用的预测熵方法相比，显示出在SemanticKITTI数据集上的优越性能，AUROC提高了18%，AUPRC增加了22%，FPR95减少了36%（从76%降至40%）。", "conclusion": "我们的方法通过利用层次贝叶斯模型的先验不确定性来解决现有不确定基方法混淆模型与数据不确定性的问题，从而在不使用辅助数据或额外训练阶段的情况下，改善了LiDAR语义分割的离群值检测性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08650", "html_url": "https://arxiv.org/abs/2510.08650", "title": "QuIRK: Quantum-Inspired Re-uploading KAN", "title_en": "QuIRK: Quantum-Inspired Re-uploading KAN", "authors": "Vinayak Sharma,Ashish Padhy,Vijay Jagdish Karanjkar,Sourav Behera,Lord Sen,Shyamapada Mukherjee,Aviral Shrivastava", "background": "Kolmogorov-Arnold Networks (KANs)展现出了在科学领域回归问题上超越经典深度神经网络的能力，同时使用了更少的可训练参数，并且由于其结构由分段线性函数（Univariate B-Spline functions）组成，具有更高的可解释性。这意味着可以从训练好的KANs中推导出闭式方程，适用于一系列问题。本文基于这种背景介绍了QuIRK模型，一种受到量子数据重新加载（Quantum Data Re-uploading, DR）启发的KAN变体。", "innovation": "QuIRK模型用单一量子位DR模型替代了B-Splines作为单变量函数逼近器。这使得QuIRK模型不仅能够匹配甚至在某些情况下超越传统的KANs，并且使用了更少的参数。特别地，在处理周期函数时表现更为突出。此外，模型仅使用了单一量子位电路，可以使用GPU加速进行经典模拟，保持了可计算性。QuIRK还保留了KAN的可解释性和生成闭式解的能力。", "conclusion": "QuIRK模型提供了一种新的方法，既保持了KAN的可解释性和生成闭式解的能力，又通过引入量子数据重新加载的概念，减少了模型参数，尤其是在处理周期函数时表现出显著优势。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08758", "html_url": "https://arxiv.org/abs/2510.08758", "title": "基于实验设计的语言模型在文本因果推理中的解决方案：语言模型可以太大吗？", "title_en": "A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?", "authors": "Graham Tierney,Srikar Katta,Christopher Bail,Sunshine Hillygus,Alexander Volfovsky", "background": "许多社会科学问题探讨语言属性如何因果影响观众的态度和行为。由于文本属性往往是相互关联的（例如，愤怒的评论使用粗俗的语言），因此必须控制潜在的混杂因素以孤立因果效应。最近的文献提出了适应大型语言模型（LLMs）来学习文本的潜在表示，这些表示可以成功预测治疗和结果。然而，由于治疗是文本的一部分，这些深度学习方法有可能学习实际上编码治疗本身的表示，从而引起重叠偏差。", "innovation": "我们引入了一种新的实验设计来处理潜在的混杂因素，避免重叠问题，并无偏估计治疗效果。我们通过在表达谦虚对政治言论可信度影响的实验中应用此设计来展示这一点。方法论上，我们证明LLM方法的表现甚至不如简单的词袋模型。", "conclusion": "我们揭示了表达谦虚对政治陈述可信度的影响，为社交媒体平台、政策制定者和社会科学家提供了新的沟通效果见解。实验证实基于LLM的方法表现不佳，强调了新的实验设计的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08623", "html_url": "https://arxiv.org/abs/2510.08623", "title": "PARSE：LLM驱动的模式优化以实现可靠实体抽取", "title_en": "PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction", "authors": "Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla", "background": "在新兴的软件3.0系统中，LLM代理自主与API和工具交互，结构化信息从非结构化文本的提取至关重要。现有的方法直接使用大型语言模型进行抽取任务，并使用现有的JSON模式，常常使用约束解码或强化学习方法来保证语法规则的正确性，但大多将JSON模式视为静态合同，设计用于人类开发者，这导致了在模式包含模糊或不完整规定时，实体抽取性能低于预期、频繁的幻觉以及不可靠的代理行为。", "innovation": "我们认识到JSON模式本身是自然语言理解合同的一种形式，它编码了LLM应该理解和依照改进的数据结构规范和预期。因此，我们开发了PARSE（Parameter Automated Refinement and Schema Extraction）系统，它包含两个协同工作的组件：ARCHITECT，旨在自主优化JSON模式以便LLM消费，同时通过RELAY（集成代码生成系统）维持向后兼容性；SCOPE以反射为基础进行合并静态和基于LLM的护栏指导实体抽取。我们对PARSE在三个数据集（Schema-Guided Dialogue (SGD)，Structured Web Data Extraction (SWDE)，内部零售会话数据）进行了定性和定量评估，结果显示它在SWDE上的抽取准确性最高可提升64.7%，整体框架改进的准确性提高了10%，首次重试内的抽取错误降低了92%，并且维持了实用的延迟。", "conclusion": "PARSE在提高实体抽取准确性和降低抽取错误率方面的表现优于现有方法，同时保持了实用的延迟性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08730", "html_url": "https://arxiv.org/abs/2510.08730", "title": "语言模型微基准测试的可靠性如何？", "title_en": "How Reliable is Language Model Micro-Benchmarking?", "authors": "Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta", "background": "微基准测试提供了一种解决方案，可以减轻语言模型开发中通常会带来的时间和成本障碍：通过评估非常小的现有基准子集。然而，这些微基准能否像它们取代的完整基准那样一致地排名模型？或者它们是否比随机选择数据点的子集更能一致地排名模型？在很多情况下，研究发现答案是否定的。", "innovation": "本文引入了一种针对微基准测试的元评估度量，以研究微基准测试能否根据模型在完整基准上的性能差异来正确排名模型对。这种方法可以确定哪些模型对可以通过微基准测试来正确排名，从而更精细地分析微基准测试大小与可靠性之间的权衡。", "conclusion": "我们的研究表明，为了能够一致地排名性能相对相似的模型对，通常需要选择多达250个示例。而且，当仅比较8B指令调优模型且采用25个微基准测试示例时，超过一半的两两比较可能会丢失。这项工作为微基准测试用户和开发者提供了关于权衡评估效率与可靠性的实用性指导。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08766", "html_url": "https://arxiv.org/abs/2510.08766", "title": "理解系外行星宜居性：基于贝叶斯机器学习框架预测大气吸收光谱", "title_en": "Understanding Exoplanet Habitability: A Bayesian ML Framework for Predicting Atmospheric Absorption Spectra", "authors": "Vasuda Trehan,Kevin H. Knuth,M. J. Way", "background": "近年来，由于人工智能（AI）和机器学习（ML）等计算技术的发展，空间技术不断进步，这极大地改变了我们探索宇宙的能力。例如，詹姆斯·韦伯太空望远镜（JWST）等任务使得有关遥远天体的信息更加容易获取，催生了大量宝贵的数据。在这个持续中的研究中，他们致力于开发一种基于从Planet能够采取的观测光谱数据，以及由NASA戈达德太空研究所气候变化建模项目开发的ROCKE-3D通用环流模型生成的合成光谱数据的系外行星大气吸收光谱预测模型。在这项初步研究中，他们使用样条曲线描述模拟大气吸收光谱的高度作为行星参数值的函数。随后应用贝叶斯自适应探索来识别需要更多数据以改进模型的行星参数空间区域。这个系统可以作为前向模型，给定一颗行星的大气吸收光谱，就能推断出该行星的行星参数。这项工作预计将进一步提升对系外行星属性和普遍的系外行星气候与宜居性的理解。", "innovation": "提出了一个基于贝叶斯机器学习框架的前向模型，该模型旨在预测系外行星大气吸收光谱。该模型使用样条曲线来描述模拟大气吸收光谱的高度，应用贝叶斯自适应探索来确定需要更多数据以改进模型的参数空间区域。这将有助于更好地理解系外行星的属性和普遍的系外行星气候与宜居性。", "conclusion": "该研究通过提出基于贝叶斯机器学习框架的前向模型，进一步提升了对系外行星属性和普遍的系外行星气候与宜居性的理解。该模型利用样条曲线描述模拟大气吸收光谱的高度，并应用贝叶斯自适应探索来识别需要更多数据的区域以改进模型。这个系统能够给定大气吸收光谱推测行星参数，为研究系外行星提供了一种新的方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08803", "html_url": "https://arxiv.org/abs/2510.08803", "title": "人工启发式已死，长活代码生成器", "title_en": "Man-Made Heuristics Are Dead. Long Live Code Generators!", "authors": "Rohit Dwivedula,Divyanshu Saxena,Aditya Akella,Swarat Chaudhuri,Daehyeok Kim", "background": "传统上，各种系统控制器的策略设计是一个手动过程，需要领域专家细心定制针对特定部署情况的经验法则。本文通过将最新生成模型的进展与大型语言模型（LLM）驱动的代码生成结合，重新思考策略设计。", "innovation": "本文提出了PolicySmith框架，该框架运用LLM来合成针对特定实例优化的最佳启发式方法。研究者们将PolicySmith应用到两个经典的系统策略——网页缓存和拥塞控制中，展示了通过LLM驱动的启发式搜索所能发现的机会。在网页缓存方面，PolicySmith发现的启发式方法在标准开源日志中表现优于现有基准。在拥塞控制方面，研究展示了PolicySmith能够生成安全策略并直接集成到Linux内核。", "conclusion": "PolicySmith能够通过LLM驱动的启发式搜索生成优化的系统策略，展现了在网页缓存和拥塞控制方面的应用潜力，预示了传统手动启发式的被淘汰及其被代码生成器所取代的趋势。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08769", "html_url": "https://arxiv.org/abs/2510.08769", "title": "以利润优先延迟：基于DRL的5G网络切片准入控制", "title_en": "Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices", "authors": "Proggya Chakraborty,Aaquib Asrar,Jayasree Sengupta,Sipra Das Bit", "background": "5G网络能通过网络切片提供多样服务（如eMBB、URLLC和mMTC），这需要智能准入控制和资源分配来满足严格的QoS要求并最大化网络服务提供商（NSP）的利润。然而，现有的深度强化学习（DRL）框架主要关注利润优化，没有明确考虑服务时延，可能导致对时延敏感切片的QoS违反。此外，常用ε-贪心探索方法往往导致收敛不稳定和次优策略学习。", "innovation": "提出了一种延迟和利润感知的切片准入控制方案（DePSAC）。该方法基于DRL，引入延迟感知的奖励函数，利用服务延迟引起的惩罚来激励时延关键切片（如URLLC）的优先处理，并采用玻尔兹曼探索以实现更平滑和更快的收敛。", "conclusion": "通过在模拟5G核心网络基底上实现和评估DePSAC，实验证明了该方法在总体利润、减少URLLC切片时延、提高接受率及优化资源利用率方面优于DSARA基线。这些结果验证了所提DePSAC方案在实用5G网络切片场景中实现更好的QoS-利润权衡的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08807", "html_url": "https://arxiv.org/abs/2510.08807", "title": "Humanoid Everyday: 开放环境下综合的类人机器人数据集", "title_en": "Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation", "authors": "Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang", "background": "随着类人机器人在肢体复杂操作能力方面的进步，大多数现有的机器人学习数据集和基准测试主要关注于静止的机器人臂。目前的类人数据集要么局限于固定环境，要么任务多样性不足，通常缺乏人体-类人交互和下肢移动。", "innovation": "本研究介绍了名为Humanoid Everyday的大型多样类人机器人操作数据集，该数据集包括涉及灵巧物体操作、人-类人交互、结合移动动作等一系列任务的广泛任务集。还引入了一个基于云的标准化评估平台，方便研究人员在其控制环境中无缝部署其策略并在数据集上进行测试。该平台旨在促进通用类人机器人操作研究，为更强大的机器人代理在真实世界中的应用奠定基础。", "conclusion": "通过公开发布Humanoid Everyday数据集、数据收集代码以及云评估网站，研究团队希望推进通用类人机器人操作的研究，为真实世界中的更强大和具身的机器人代理奠定基础。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08829", "html_url": "https://arxiv.org/abs/2510.08829", "title": "CommandSans：以手术精准指令清洗保障AI代理安全", "title_en": "CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization", "authors": "Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader", "background": "随着能够访问大量工具和敏感数据的语言模型（LLM）代理的广泛应用，间接指令注入的攻击面显著扩大。当前的防御措施往往不够精准，因为它们难以可靠地区分恶意和良性指令，导致较高的误报率，从而阻碍了它们在现实世界中的应用。", "innovation": "本文提出了一种新颖的方法，灵感来源于计算机安全的基本原则：数据不应包含可执行指令。这种方法提出了一个令牌级别的清洗过程，该过程可以精确移除工具输出中针对AI系统的指令，将恶意指令作为副产品捕获。相对于现有的安全分类器，这种方法是非阻塞性的，不需要校准，并且对工具输出的上下文是无关的。此外，这种方法可以通过容易获得的指令调优数据进行训练，而不需要依赖于挑战或合成起源的不现实的指令注入示例。", "conclusion": "实验结果表明，该方法在多种攻击类型和基准测试（如AgentDojo、BIPIA、InjecAgent、ASB和SEP）中表现良好，减少了7-10倍的攻击成功率（从AgentDojo的34%降至3%），同时不损害代理在良性或恶意环境中的实用性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08799", "html_url": "https://arxiv.org/abs/2510.08799", "title": "SkipSR：通过跳过计算实现更快的超分辨率", "title_en": "SkipSR: Faster Super Resolution with Token Skipping", "authors": "Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni", "background": "基于扩散的超分辨率（SR）是视频生成和视频修复的关键组件，但处理速度慢且成本高，限制了其在更高质量和更长视频适用性上的扩展。目前的方法通常会处理视频中的所有像素，而没有像素固有的细节，许多区域在这种情况下不能从超分辨率中显著受益。", "innovation": "提出了一种名为SkipSR的简单框架，通过从低分辨率输入直接识别出低细节区域，并完全跳过这些区域的计算，仅对需要超分辨率的区域进行计算。这种方法在保持超感知质量的同时，显著减少了计算量。在标准超分辨率基准测试中，我们的方法在720p视频上的端到端延迟比之前的方法快60%，且无明显质量损失。", "conclusion": "这种方法在标准和一步扩散超分辨率模型中保存了感知质量的同时，显著减少了计算，达到了更快的处理速度。在720p视频上的端到端延迟提高了60%，且没有质量损失。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "大型语言模型（LLMs）已经在推理方面取得了显著进展，但在诸如写作、信息检索或提供实际指导等任务中，有时会产生不理想的用户响应。传统对齐方法通常假设最大化模型奖励也能最大化用户福利，但在实践中这一假设往往无效：模型可能会提供过于详细的解释，导致用户希望的答案更为简洁。这种行为类似于囚徒困境，个体理性的选择可能导致社会上的次优结果。根本挑战在于缺乏一种能够同时惠及模型和用户的原理性决策机制。", "innovation": "本文提出了基于博弈论的对齐（GTAlign）框架，该框架将博弈论决策机制整合进推理和训练过程。在推理阶段，模型将用户-LLM交互视为战略博弈，在推理链中构建收益矩阵来估计自身和用户的福利，选择双方互惠的行为。在训练阶段引入一种互惠奖励，激励模型产生合作回应，使其行为与社会高效的成果相一致。此外，还提出了一种利用博弈论推理的推断技术，使LLM的响应能够动态适应其服务的价格策略变化。广泛的实验表明，与基线相比，GTAlign在不同任务下显著提高了推理效率、答案质量和互惠福利。", "conclusion": "通过使用GTAlign框架，模型得以更加合理地处理用户需求和自身利益之间的平衡，从而在多种任务中显著提升了推理效果、答案质量和用户福利。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08906", "html_url": "https://arxiv.org/abs/2510.08906", "title": "基于梯度引导最远点采样的稳健训练集选择方法", "title_en": "Gradient-Guided Furthest Point Sampling for Robust Training Set Selection", "authors": "Morris Trestman,Stefan Gugler,Felix A. Faber,O. A. von Lilienfeld", "background": "在化学相关的机器学习问题中，数据的选择对于模型的性能至关重要。传统的最远点采样（Furthest Point Sampling, FPS）算法虽然有效，但可能无法充分利用数据分布的信息，导致在某些情况下模型预测性能不佳，并且对数据的需求较高。文章指出，尽管使用FPS，预测稳健性可能会受到影响，特别是在分子动力学轨迹数据集上，FPS会系统性地低估了平衡几何结构的重要性，导致松弛结构的测试错误较大。", "innovation": "文章提出了一种基于梯度引导最远点采样（Gradient Guided Furthest Point Sampling，GGFPS）的方法，该方法通过利用分子力规范来指导高效分子构象空间的采样。研究发现，与FPS和均匀采样相比，使用GGFPS可以在保持预测准确性的同时，显著降低训练成本。文章通过玩具系统（Styblinski-Tang函数）和MD17分子动力学轨迹数据集上的数值实验，展示了GGFPS在数据效率和模型稳健性方面的优势。", "conclusion": "研究结果表明，GDPS方法能够有效缓解平衡几何结构的欠采样问题，提高预测准确性，并在所有配置空间内降低预测误差的方差。这表明，基于梯度的采样方法在选择训练集方面具有很大的潜力，而对FPS的简单使用可能会导致训练集不平衡和预测结果不一致的问题。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08916", "html_url": "https://arxiv.org/abs/2510.08916", "title": "通过正则化最小二乘最小化对赫克尔斯过程的表示定理", "title_en": "A Representer Theorem for Hawkes Processes via Penalized Least Squares Minimization", "authors": "Hideaki Kim,Tomoharu Iwata", "background": "核方法的核心在于通过核函数在再生核希尔伯特空间(RKHS)中非参数估计潜在函数，而代表定理提供了一种将无穷维优化问题转化为有限维度问题的方法，使得实际可计算的算法成为可能。本文探讨了基于观测事件序列估计线性多变量赫克尔斯过程的潜在触发核的问题，并在RKHS框架下展示了在惩罚最小二乘最小化原则下的一种新型代表定理。", "innovation": "本文提出了一种新颖的代表定理，该定理通过一系列同时积分方程定义了一系列转换核，使得每个触发核的最优估计表示为这些转换核在数据点上的线性组合。特别的是，所有对偶系数都解析地固定为1，这消除了求解昂贵的对偶系数优化问题的需要，因此提出了一个高效估计方法，适用于大规模数据的处理，比传统的非参数方法更为有效。", "conclusion": "在合成数据集上的实证评估表明，所提出的方法在保持竞争预测准确性的同时，显著提高了计算效率，超越了现有的基于核方法的估计器。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08929", "html_url": "https://arxiv.org/abs/2510.08929", "title": "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains", "title_en": "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains", "authors": "Yunrui Guan,Krishnakumar Balasubramanian,Shiqian Ma", "background": "该研究探讨在凸域上使用流动匹配和镜像映射进行生成建模的方法，并识别出两个根本性挑战：标准对数障碍镜像映射导致尾部行为为重尾分布，引起不良的动态效应；与高斯先验的结合在匹配重尾目标时效果不佳。", "innovation": "本文提出了基于正则化镜像映射的Mirror Flow Matching方法，该映射控制了对数分布的尾行为并保证了有限矩，并且采用与重尾目标相匹配的学生-t分布先验以稳定训练。此外，该方法提供了理论保证，包括空间Lipschitz性和时间正则性的速度场，以及针对学生-t分布先验的流动匹配的Wasserstein收敛率和针对约束生成的原始空间保证。", "conclusion": "实验结果表明，该方法在合成凸域模拟中优于基线方法，并在现实世界的约束生成任务中取得了竞争力的样本质量。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08919", "html_url": "https://arxiv.org/abs/2510.08919", "title": "PHyCLIP: ${L}^1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning", "title_en": "PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning", "authors": "Daiki Yoshikawa,Takashi Matsubara", "background": "视觉-语言模型在大规模视觉场景和语言描述配对的多模态表示学习中取得了显著的成功。然而，这些模型仍然难以同时表达两个概念家族内的层次结构和不同概念家族之间的组合性。虽然一些研究通过使用双曲几何空间来解决这一挑战，但双曲空间对组合性的表达能力尚不清楚。现有方法在零样本分类、检索、层次分类和组合性理解任务中的表现表明，传统的单空间方法难以同时处理层级和组合性问题。", "innovation": "本文提出了PHyCLIP方法，该方法采用${L}^1$-Product度量在双曲因数的笛卡尔乘积上的设计。该设计在每个双曲因数中内在地生成了家族内层次结构，并通过${L}^1$-产品度量捕捉了家族间的组合性，类似于布尔代数。实验结果表明，PHyCLIP在零样本分类、检索、层次分类和组合性理解任务上优于现有的单一空间方法，并提供了更具解释性的嵌入空间结构。", "conclusion": "实验结果表明，PHyCLIP在零样本分类、检索、层次分类和组合性理解任务上优于现有的单一空间方法，并提供了更具解释性的嵌入空间结构。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08946", "html_url": "https://arxiv.org/abs/2510.08946", "title": "使用Gauss-Seidel投影实现物理合理的生物分子互作建模", "title_en": "Physically Valid Biomolecular Interaction Modeling with Gauss-Seidel Projection", "authors": "Siyuan Chen,Minghao Guo,Caoliwen Wang,Anka He Chen,Yikun Zhang,Jingjing Chai,Yin Yang,Wojciech Matusik,Peter Yichen Chen", "background": "生物分子相互作用建模在基础模型的推动下已经取得了显著进展，但现有的模型往往会生成违反基本空间可行性的全原子结构。本文通过在训练和推理过程中强制执行物理有效性作为严格的约束，来解决这一局限性。", "innovation": "本文的核心创新在于引入了一个可微投影模块，该模块通过Gauss-Seidel方案将打乱模型的初步原子坐标映射到最近的物理有效配置。该模块利用约束的局部性和稀疏性，确保大规模条件下的稳定和快速收敛。通过隐式微分获得梯度，该模块能够无缝集成到现有的端到端微调框架。通过使用本文的Gauss-Seidel投影模块，仅需两步去噪步骤即可生成既物理合理又结构准确的生物分子复合物。", "conclusion": "在六个基准测试中，本文的两步模型在结构精度上与公认的200步扩散基线达到了相同水平，但提供了大约10倍更快的墙钟速度，同时确保了物理合理性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08979", "html_url": "https://arxiv.org/abs/2510.08979", "title": "不可彩色化示例：通过感知感知的色域限制扰动预防未经授权的AI彩色化", "title_en": "Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation", "authors": "Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen", "background": "基于AI的图像着色展示了从灰度图像生成逼真彩色图像的强大能力。然而，这种技术也带来了版权侵权的风险，如未经授权的颜色化和再销售单色漫画和电影。尽管存在这些担忧，但目前还没有有效的方法来防止这种不当使用问题。因此，针对这一问题，本文提出了第一个防御范式——不可彩色化示例，通过嵌入不可见的扰动到灰度图像中，来防止未经授权的颜色化", "innovation": "本文的创新之处在于提出了感知感知的色域限制扰动（Perception-Aware Chroma-Restrictive Perturbation，PAChroma），该方法通过优化Laplacian滤波器来保持感知质量，并在优化过程中应用多样化的输入变换以增强模型间的可移植性和对抗常见的后处理（如压缩）的鲁棒性。PAChroma在ImageNet和Danbooru数据集上的实验结果表明，该方法能够有效降低着色质量同时保持视觉效果。", "conclusion": "本文的工作标志着朝着保护视觉内容免受非法AI着色的第一步，为生成媒体版权意识的防御机制铺平了道路。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08955", "html_url": "https://arxiv.org/abs/2510.08955", "title": "物体导向的去噪扩散图像增强方法", "title_en": "Denoised Diffusion for Object-Focused Image Augmentation", "authors": "Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar", "background": "现代农业操作越来越多地依赖结合多种数据源的集成监测系统，以优化农场管理。基于无人机的动物健康监测作为关键组成部分，但由于数据可用性有限，受特定场景问题的影响（如动物体积小、被遮挡或部分可见），因此难以实现。现有的迁移学习方法往往无法解决这一问题，因为缺乏能够反映特定农场条件的大型数据集，包括动物品种、环境和行为的差异。因此，开发一种针对这些独特挑战的、以动物为中心的数据增强策略变得至关重要。", "innovation": "本文提出了一种物体导向的数据增强框架，专门针对动物健康监测场景中的数据不足问题。该方法从背景中分割出动物，并通过对动物进行变换和基于扩散的合成，生成更真实且多样化的场景，以提升动物检测和监测性能。实验结果表明，与基础模型相比，增强后的数据集在动物检测任务上具有优越的表现。", "conclusion": "通过生成特定领域的数据，本文的方法能够在数据稀缺的情况下，为实时动物健康监测提供支持，从而弥合了数据有限与实际应用之间的差距。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09021", "html_url": "https://arxiv.org/abs/2510.09021", "title": "RefGrader: 使用自主工作流自动评估数学竞赛证明", "title_en": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows", "authors": "Hamed Mahdavi(1),Pouria Mahdavinia(1),Samira Malek(1),Pegah Mohammadipour(1),Alireza Hashemi(2),Majid Daliri(3),Alireza Farhadi(4),Amir Khasahmadi(5),Niloofar Mireshghallah(6),Vasant Honavar(1) ((1) Pennsylvania State University, (2) City University of New York, (3) New York University, (4) Amirkabir University of Technology, (5) Autodesk, (6) Carnegie Mellon University)", "background": "最新的先进语言模型（LLMs）在过去能够解决奥林匹克证明问题时表现出困难，但现在已经能够解决2025年国际数学奥林匹克（IMO）的问题，据报道领先系统能够解决6个问题中的5个。基于这一进展，本文评估这些模型在评分证明方面的能力，包括检测错误、判断严重程度以及基于二元正确性之外的公平评分。", "innovation": "引入了基于自主工作流的评分方法来自动化评估数学竞赛证明。这些工作流旨在提取和分析参考解决方案，自动生成问题特定的评分标准，以实现多步骤评分过程。这包括对不同设计选择的工作流实例和比较，以及对这些选择的权衡分析。研究成果涵盖一个标注的语料库和MathArena的评分，通过使用提出的工作流获得了更高的一致性评分和更稳定的半分数处理。", "conclusion": "基于标注语料库和MathArena的评价，提出的工作流与人类评分的一致性更高，并且在多个指标上更一致地处理了半分数。所有相关代码、数据和提示/日志均已发布，以促进未来的相关研究。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08931", "html_url": "https://arxiv.org/abs/2510.08931", "title": "RADAR: 通过机制途径检测LLM评估中的数据污染", "title_en": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation", "authors": "Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad", "background": "数据污染对可靠的大语言模型（LLM）评估构成了重大挑战。模型可能会通过记忆训练数据而不是展示真正的推理能力来实现高表现。因此，建立一种能够区分记忆驱动与推理驱动响应的检测机制变得至关重要。作者介绍了一种名为RADAR（Recall vs. Reasoning Detection through Activation Representation）的新型框架，该框架利用机制可解释性来检测数据污染。RADAR提取了37个特征，包括表面层置信度轨迹和深层机制属性如注意力专业化、电路动力学和激活流向模式，以实现对各种评估样本的有效区分。通过这些特征训练的集成分类器在多样化评估集上达到了93%的准确率，在明显病例上表现完美，在具有挑战性的模糊例子中准确率为76.7%。该研究展示了机制可解释性在超越传统表面指标以提升LLM评估方面的潜力。", "innovation": "RADAR框架通过利用机制可解释性，来检测数据污染，特别是在区分记忆驱动和推理驱动模型响应方面表现出色。它通过提取37个特征，包括表面层置信度轨迹和深层机制属性，如注意力专业化、电路动力学和激活流向模式，实现了高准确率。相对于传统的基于表面指标的方法，它展示了更能深入理解LLM内部机制的潜力。", "conclusion": "该研究证明了机制可解释性在进一步提升LLM评估方面的作用。通过设计并实现RADAR框架，作者展示了机制可解释性在区分记忆驱动和推理驱动响应方面的能力。RADAR模型不仅在明显病例上的准确率达到100%，而且在具有挑战性的模糊例子中也表现出色，达76.7%的准确率。这表明了机制可解释性对于促进LLM评估技术进步的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09042", "html_url": "https://arxiv.org/abs/2510.09042", "title": "MAKO: 基于元自适应科隆曼算子的参数不确定性非线性系统的模型预测控制的学习方法", "title_en": "MAKO: Meta-Adaptive Koopman Operators for Learning-based Model Predictive Control of Parametrically Uncertain Nonlinear Systems", "authors": "Minghao Han,Kiwan Wong,Adrian Wing-Keung Law,Xunyuan Yin", "background": "本文旨在解决非线性系统中参数不确定性的问题，提出了一种基于元学习的科隆曼模型预测控制方法。传统方法在处理参数不确定性的非线性系统建模和控制时通常需要具体的知识或参数信息，这限制了其应用范围。因此，一种能够从多模态数据集中学习并适应未见参数设置的元自适应科隆曼算子（MAKO）方法被提出，确保了即使在未见过的参数设置下系统的闭环稳定性，从而提高了模型精度和控制效果。", "innovation": "创新点在于提出了一个无需预先了解参数不确定性情况的自适应深度元学习建模方法MAKO，能够在多模态数据集上学习元模型，并在线使用新数据自适应调整到新系统。基于学习到的元科隆曼模型，设计了一种模型预测控制方案，确保了闭环系统的稳定性，即使在未见过的参数设置下也能够保持系统的稳定性。", "conclusion": "通过广泛的仿真实验，表明所提出的方法在建模准确性和控制效果方面优于现有的基线方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09045", "html_url": "https://arxiv.org/abs/2510.09045", "title": "利用标识符替换实现LLMs的高效长代码翻译", "title_en": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements", "authors": "Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta", "background": "在软件开发领域，LLMs被用于自动化诸如代码翻译的任务，即将一种编程语言的源代码翻译成另一种语言并保持其功能。然而，LLMs在处理长代码片段时常常遇到困难，因为这些代码超出了上下文窗口的限制，导致翻译结果不准确。", "innovation": "本文提出了一种新颖的零样本代码翻译方法，通过在翻译过程中使用标识符替换，将用户提供的长标识符替换为通用占位符。这种方法使LLMs能够关注代码的逻辑结构，减少token计数和内存使用，从而提高长代码翻译的效率和成本效益。", "conclusion": "我们的实证结果表明，这种方法能够保留语法和层次结构信息，并生成具有较少token数的翻译结果。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09035", "html_url": "https://arxiv.org/abs/2510.09035", "title": "探索基于不完美标签的点云语义分割单域泛化", "title_en": "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels", "authors": "Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen", "background": "准确感知对于车辆安全至关重要，LiDAR 是自动驾驶中的关键使能技术。为了在不同环境、传感器类型和天气条件下确保鲁棒性能而无需昂贵的重新注释，LiDAR 基础的3D语义分割领域泛化必不可少。然而，由于传感器缺陷、遮挡和人为错误，LiDAR注释通常是噪声的，这种噪声会降低分割精度并在领域转移时进一步放大，威胁系统可靠性。虽然图像中的嘈杂标签学习已有研究，但在3D LiDAR分割下的领域泛化中，其应用依然很少，因为点云稀疏且不规则的结构限制了2D方法的直接使用。", "innovation": "该研究引入了新颖的任务——基于嘈杂标签的LiDAR语义分割领域泛化（DGLSS-NL），并首次通过将三个代表性图像分类的嘈杂标签学习策略适应到3D分割来建立基准。研究发现现有嘈杂标签学习方法不适用于LiDAR数据，因此提出了DuNe，一种具有强分支和弱分支的双视图框架，以特征级一致性为约束，并基于预判置信度过滤应用交叉熵损失。该方法在SemanticKITTI、nuScenes和SemanticPOSS上的表现优于现有方法，尤其是在10%对称标签噪声下的mIoU 分别为56.86%、42.28%和52.58%，综合算术平均值（AM）和调和平均值（HM）分别为49.57%和48.50%，展示了在DGLSS-NL任务上的领域泛化能力。", "conclusion": "DuNe在DGLSS-NL任务中表现出色，为实现基于LiDAR的语义分割领域的广泛泛化提供了有效的解决方案，为未来的研究和实际应用提供了重要参考。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09072", "html_url": "https://arxiv.org/abs/2510.09072", "title": " emotion-disentangled embedding alignment for noise-robust and cross-corpus speech emotion recognition ", "title_en": "Emotion-Disentangled Embedding Alignment for Noise-Robust and Cross-Corpus Speech Emotion Recognition", "authors": "Upasana Tiwari,Rupayan Chakraborty,Sunil Kumar Kopparapu", "background": "在现实环境中，语音情感识别的有效性常因噪声环境和数据集间的变异性而受到阻碍。本文提出了一种两步方法，通过改进的表征学习增强语音情感识别模型的稳健性和泛化能力。", "innovation": "该方法采用两步过程，首先使用EMDR（情感解耦表征学习）提取类特异性判别特征，同时保持不同情感类别间的共性。其次，MEA（多块嵌入对齐）进一步优化这些表征，将它们投影到一个与原始语音输入间最大化协方差的联合判别潜在子空间中。最后，使用该技术获得的表征在公共数据集上的干净样本中训练情绪分类器，并在未见过的噪声数据和跨语料库语音样本上进行评估，证明了所提方法的有效性。", "conclusion": "在这些具有挑战性的条件下取得了改进的性能，展示了所提出的方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09051", "html_url": "https://arxiv.org/abs/2510.09051", "title": "Alif：通过多语言合成数据提炼促进乌尔都语大型语言模型的发展", "title_en": "Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation", "authors": "Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq", "background": "发展低资源语言如乌尔都语的高性能大型语言模型（LLMs）面临挑战，包括高质量数据稀缺、多语言一致性问题和安全问题。现有做法是通过大规模翻译可用数据来应对这些挑战，但这种方式常常导致翻译质量不高和文化细微差失，并且还会产生较大的数据处理和训练成本。", "innovation": "提出了一种名为Alif-1.0-8B-Instruct的乌尔都语-英语多语言模型，该模型通过使用一种改进的自指导技术训练了一个高质量的多语言合成数据集（Urdu-Instruct）。该数据集结合了乌尔都本土链式推理、双语翻译、文化相关性和伦理安全对齐。这种方法显著增强了该模型在乌尔都语特定任务上的理解能力。Alif-1.0-8B-Instruct在培训预算不到100美元的情况下，展示了比Llama-3.1-8B-Instruct和Mistral-7B-Instruct等多个领先多语言LLM更好的性能。", "conclusion": "该研究结果表明，使用改进的自指导方法可以高效且文化对齐地开发高性能的低资源语言LLM。所有数据集、模型和代码均已公开。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09065", "html_url": "https://arxiv.org/abs/2510.09065", "title": "MMAudioSep: 引导向视频/文本查询声源分离的视频到音频生成模型", "title_en": "MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation", "authors": "Akira Takahashi,Shusuke Takahashi,Yuki Mitsufuji", "background": "研究团队介绍了一种名为MMAudioSep的生成模型，该模型旨在通过预训练的视频到音频生成模型来实现基于视频/文本查询的声源分离。背景在于，现有技术需要从头开始训练模型，而MMAudioSep通过利用预训练模型中学习到的视频/文本与音频之间的关系知识，使得模型能够更高效地进行训练，无需从零开始训练。", "innovation": "MMAudioSep创新点在于它建立在一个预训练的视频到音频模型的基础上，通过利用预训练音频生成模型中学到的视频/文本与音频之间的关系知识，使得模型可以更高效地训练。此外，即使经过微调获得声源分离功能后，模型仍然保留着原始的视频到音频生成能力，这展现了基础声音生成模型在声源相关下游任务中的潜在应用价值。", "conclusion": "通过与现有的分离模型进行比较，MMAudioSep的表现优于基线模型。此外，研究还展示了MMAudioSep在经过微调后仍保留原始功能的能力，这意味着预训练的声音生成模型可以被用作声源相关任务的基础模型。研究团队还公开了他们的代码。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09038", "html_url": "https://arxiv.org/abs/2510.09038", "title": "Auto-scaling Continuous Memory for GUI Agent", "title_en": "Auto-scaling Continuous Memory for GUI Agent", "authors": "Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang", "background": "本文研究如何给图形用户界面（GUI）代理赋予可扩展的记忆功能，使它们能够适应不熟悉的界面并处理长期任务。以往的GUI代理将过往轨迹压缩成文本标记，这使得上下文长度增加并忽略了决定性的视觉线索（如组件的精确大小和位置）。", "innovation": "本文提出了一种连续记忆机制，通过视觉语言模型（VLM）直接将每个GUI轨迹编码为固定长度的连续嵌入序列，并将其直接插到主干网络的输入层中，从而大幅减少了上下文成本同时保留了精细的视觉信息。随着记忆大小和检索深度的增加，性能呈单调改进，而文本记忆随着长提示的增加会退化。本文引入了一种自动扩展的数据飞轮，通过发现新的环境、生成任务、执行轨迹及验证成功来低成本地扩展记忆。", "conclusion": "通过该管道，我们收集了超过100000条轨迹，约为4000美元的成本，并仅对记忆编码器进行了微调（利用LoRA调整Q-Former，参数量占比1.2%）。在实际的GUI基准测试中，我们的带有连续记忆的代理在长期任务和数据分布变化时持续提高了成功率。值得注意的是，Qwen-2.5-VL-7B 加上连续记忆的性能与最先进的闭源模型（例如GPT-4o，Claude-4）相当。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09096", "html_url": "https://arxiv.org/abs/2510.09096", "title": "当机器人比人类更强大时：从受限示范者学习", "title_en": "When a Robot is More Capable than a Human: Learning from Constrained Demonstrators", "authors": "Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık", "background": "传统的从演示中学习方法使专家能够通过教鞭教学、手把手教学和模拟到现实的转移等接口教机器人执行复杂的任务。然而，这些接口通常限制了专家演示最优行为的能力，因为间接控制、设置限制和硬件安全问题。例如，操纵杆只能控制机器人的手臂在二维平面上移动，而机器人实际上是运行在更高维度空间中的。因此，受限专家获取的演示导致学习到的策略表现不佳。这引发了关键问题：机器人能否比受限专家演示的策略表现得更好？", "innovation": "本文通过让代理超越直接模仿专家的行为，探索更短且更高效的轨迹，来解答上述问题。文章利用演示来推断只基于状态的奖励信号，以度量任务进度，并使用时间插值自标未知状态的奖励。这种新方法在样本效率和任务完成时间上均优于常见的模仿学习方法。在实际演示中，该方法在12秒内完成了任务，比行为克隆快了10倍", "conclusion": "通过让机器人探索更高效的行为，本文提出的方法在模仿学习任务中展现了更高的效率和更快的性能，在实际机器人实验中得到了证实。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09133", "html_url": "https://arxiv.org/abs/2510.09133", "title": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "title_en": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "authors": "Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An", "background": "LRMs虽然在复杂问题解决任务上取得了显著进展，但在部署时通常面临着高的计算成本，这就需要提高推理的效率。一种流行的方法是动态地在思考模式和非思考模式之间切换LRM。然而，现有的方法可能会引入额外的推理错误，并且缺乏对性能损失的统计保证，这对高风险应用非常重要。", "innovation": "本文提出了PAC推理，可以在用户指定的性能损失容忍度下控制性能损失。具体而言，PAC推理通过构建基于不确定性得分的上置信区间来控制性能损失，并确定一个阈值来决定何时切换到非思考模式。理论上，使用该阈值可以在不依赖于具体分布的情况下确保性能损失限定在一个合理范围内。", "conclusion": "在推理基准测试中的全面实验表明，所提出的方法可以节省计算预算并控制用户指定的性能损失。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09107", "html_url": "https://arxiv.org/abs/2510.09107", "title": "基于ConvNeXt的新型多分支架构在CT扫描中识别细微病理特征", "title_en": "A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans", "authors": "Irash Perera(1),Uthayasanker Thayasivam(1) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka)", "background": "智能医学影像分析在辅助临床诊断中起着关键作用，尤其对于识别细微的病理特征。现有的医学图像分析方法面临多种多样且复杂的挑战，特别是对于COVID-19的诊断。", "innovation": "该研究提出了一种专门针对医学图像分析的新颖多分支ConvNeXt架构。该模型结合了精细的数据预处理、扩充以及严谨的两阶段训练策略，特别引入了Global Average Pooling、Global Max Pooling和新的Attention-weighted Pooling机制来提取特征。这一架构在2,609张CT切片数据集上进行了训练和验证，实现了在COVID-19诊断上的优越性能，包括最终的ROC-AUC为0.9937、验证准确率为0.9757和F1分数为0.9825，表现出色并超越了该数据集上所有已报告的模型。", "conclusion": "研究表明，结合现代多分支架构和精细数据处理可以实现与当前最先进的模型相似或更优的性能，证明了先进深度学习技术在稳健医学诊断中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09078", "html_url": "https://arxiv.org/abs/2510.09078", "title": "MCMC: 连接渲染、优化与生成式AI", "title_en": "MCMC: Bridging Rendering, Optimization and Generative AI", "authors": "Gurprit Singh,Wenzel Jakob", "background": "生成式人工智能（AI）在过去两年在视觉语言模型方面取得了前所未有的进展。在生成过程中，新的样本（图像）是从一个未知的高维分布中生成的。马尔可夫链蒙特卡洛（MCMC）方法特别适用于从如此复杂的高维分布中抽取样本。MCMC方法对于EBMs等模型来说是不可或缺的组成部分，确保能够准确生成样本。基于梯度的优化是现代生成模型的核心。优化过程中的更新步骤形成一个马尔可夫链，新的更新仅依赖于当前状态，这使得在没有记忆负担的情况下探索参数空间成为可能，从而结合了基于梯度的优化和MCMC采样的优点。MCMC方法在基于物理的渲染中也显示出重要性，因为使用基本的重要性采样技术难以捕捉复杂的光线路径。尽管有许多研究致力于利用数据驱动的方法为基于扩散的生成模型生成具有物理真实感的样本，但缺乏将这些技术连接在一起的统一框架。因此，这篇文章旨在引导学生、研究者以及从业者更好地理解这些组成部分，并探索MCMC如何可能成为一种桥梁，将这些相关的研究领域联系起来。", "innovation": "本文在现有的研究基础上，提出了将MCMC方法作为一种桥梁，连接生成式人工智能、物理渲染和优化领域的创新理念。通过提供必要的理论和实践工具，旨在使学生、研究者和从业者能够共同推进生成物理渲染的目标。", "conclusion": "文章通过介绍MCMC方法在生成式人工智能、物理渲染和优化中的应用，提出了一种新的研究框架，旨在实现这些领域之间的交叉融合。所有与该教程相关的Jupyter笔记本及其演示均可以在项目网页上找到。这些工作为生成式物理渲染提供了坚实的基础，也为未来的研究奠定了重要基础。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09155", "html_url": "https://arxiv.org/abs/2510.09155", "title": "联邦数据分析在癌症免疫治疗中的应用：一种保护隐私的合作患者管理平台", "title_en": "Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management", "authors": "Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal", "background": "连接健康是一种多学科方法，侧重于健康管理，优先考虑患者的需要来创建工具、服务和治疗。该模式通过促进患者信息在护理链中所有相关方之间的及时交换，确保主动和高效的护理。数字技术的兴起和流程创新有望通过整合各种医疗数据源来增强连接健康，从而个性化护理、预测健康结果并简化患者管理。然而，仍面临着数据架构、应用程序互操作性和安全性的挑战。数据分析可以为知情决策和健康共创提供关键洞见，但解决方案必须将最终用户，包括患者和医务人员放在首位。", "innovation": "本文通过一个欧盟资助的项目，采用敏捷的系统开发生命周期，旨在开发一个集成的人工智能生成的解决方案，用于管理正在接受免疫治疗的癌症患者。文章贡献了一种合作的数字框架，整合护理链中的所有利益相关者，利用联邦大数据分析和人工智能提高决策能力，同时确保隐私。", "conclusion": "通过实际健康数据进行分析能力验证，结果显示该框架在试点研究中实现了70%-90%的治疗建议和不良事件预测准确性，证明了该框架的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09135", "html_url": "https://arxiv.org/abs/2510.09135", "title": "视觉模型的训练特征归因", "title_en": "Training Feature Attribution for Vision Models", "authors": "Aziz Bacha,Thomas George", "background": "尽管深度神经网络在许多任务中表现出卓越的性能，但它们通常被认为是不透明的系统，缺乏解释性。这种不透明性导致了对提高模型可解释性的方法的需求增加。目前，可解释性方法主要将测试时的预测归因于输入特征（例如图像中的像素）或对影响模型训练的样本。本文提出，这两种观点应该同时加以研究。我们探索了训练特征归因，通过将测试预测与特定训练图像中的特定区域联系起来，从而提供对深度模型内部工作的全新见解。研究表明，训练特征归因可以提供细粒度且针对测试情况的具体解释，它能识别导致分类错误的有害样本，并揭示常规归因方法未能揭示的伪相关，如基于块的捷径等。", "innovation": "本文创新性地提出了训练特征归因这一方法。该方法不仅连接了测试预测与输入特征，还进一步与其相关的特定训练样本区域进行了关联。这种新的归因方式能够揭示出传统方法难以发现的模型内部机制，如有害样本和伪相关情况。通过这一方法，研究人员能够更加深入地了解神经网络如何进行决策，这极大提高了模型的透明度和可信度。", "conclusion": "实验证明，训练特征归因可以提供细粒度且针对测试情况的具体解释。这种方法有助于识别导致分类错误的有害样本，揭示进一步的伪相关，这些都是传统的方法所忽略的。因此，训练特征归因有助于提高深度模型的透明度、信任度和问责性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09177", "html_url": "https://arxiv.org/abs/2510.09177", "title": "神经网络的分布鲁棒逼近性质", "title_en": "Distributionally robust approximation property of neural networks", "authors": "Mihriban Ceylan,David J. Prömel", "background": "论文研究了几类神经网络的统一逼近性质，特别关注这些神经网络在弱紧度量族的测度下保持均一逼近。论文通过证明这些神经网络在Orlicz空间中稠密，扩展了经典的逼近定理，超越了传统的$L^p$设置。考虑到广泛使用的前馈神经网络、含有ReLU激活函数的深层窄网络以及具有功能输入的神经网络，该研究提供了更广泛的分析工具和视角。", "innovation": "论文的核心创新在于证明了几类神经网络在Orlicz空间中的稠密性，扩展了传统逼近定理的应用范围，涵盖了非多项式激活函数的前馈神经网络、ReLU激活函数的深层窄网络以及具有功能输入的神经网络，从而提供了一种分布鲁棒的逼近性质。", "conclusion": "论文通过证明局部逼近性质，扩展了神经网络的适用范围，提升了其在各种非线性函数逼近中的表现能力，特别是强调了在更广泛的概率测度分布情况下神经网络的逼近能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09192", "html_url": "https://arxiv.org/abs/2510.09192", "title": "基于增强数据和神经网络的稳健疫情预测：意大利COVID-19的应用", "title_en": "Augmented data and neural networks for robust epidemic forecasting: application to COVID-19 in Italy", "authors": "Giacomo Dimarco,Federica Ferrarese,Lorenzo Pareschi", "background": "本文提出了一种数据增强策略，旨在提高神经网络的训练效率，并提高其预测准确性。背景信息提到使用适当的分隔模型生成合成数据，并结合不确定性处理来增强现有数据，以训练神经网络。同时，研究聚焦于两种不同的神经网络架构：物理感知神经网络（PINNs）和非线性自回归（NAR）模型在短期预测中的应用效果对比。通过在皮埃蒙特地区的COVID-19疫情的第二阶段进行数值模拟，验证了该方法的有效性。", "innovation": "研究创新点在于提出的数据增强策略结合了合成数据生成和不确定性处理，增强神经网络的训练数据，从而提升预测性能。特别是NAR模型因其直接从数据中学习动力学并避免物理约束嵌入的额外计算成本而显示出特别有效的短期预测能力。PINNs则捕获系统的长期行为，适用于探索更大的动力学趋势。", "conclusion": "通过在皮埃蒙特地区的COVID-19疫情数据上应用增强数据和神经网络的方法，显著提升了疫情预测的准确性。研究还表明，不同的神经网络架构（如NAR和PINNs）在预测能力上存在差异，应根据具体需求选择适合的模型。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09217", "html_url": "https://arxiv.org/abs/2510.09217", "title": "IRIS：在没有表格数据情况下进行可验证因果发现的迭代和集成框架", "title_en": "IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data", "authors": "Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari", "background": "传统的统计算法在因果发现中面临诸多挑战，包括昂贵的数据收集成本、对已知关系的冗余计算以及不切实际的假设。虽然基于LLM的方法在识别已知因果关系方面表现优异，但在发现新关系方面存在局限。", "innovation": "IRIS 是一个新颖的框架，通过迭代检索和集成系统实现了实时因果发现。它结合了统计算法和基于LLM的方法，能够发现已知和新的因果关系。此外，IRIS的缺失变量提案组件能够识别并整合缺失变量，以扩展因果图。", "conclusion": "IRIS 从一组初始变量开始，能够进行实时因果发现，无需依赖现有的数据集。 "}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09210", "html_url": "https://arxiv.org/abs/2510.09210", "title": "数据投毒攻击中的可验证水印方案", "title_en": "Provable Watermarking for Data Poisoning Attacks", "authors": "Yifan Zhu,Lijia Yu,Xiao-Shan Gao", "background": "近年来，数据投毒攻击被设计得更具欺骗性，甚至有益于数据持有者，其主要目的是验证数据集的所有权或保护私有数据免遭未经授权的使用。然而，这种发展趋势可能导致误解和冲突，因为数据投毒传统上被视为对机器学习系统的安全威胁。为了应对这一问题，必须让无害的数据投毒生成器声称其生成的数据集的所有权，以便用户能够识别潜在的投毒行为，防止其误用。", "innovation": "提出了一种基于水印方案的解决方案，设计了两种实际可行的水印方法：投后水印投毒和同时水印投毒。通过分析证明，当水印长度分别为投后水印投毒中的θ(√d/εw)和同时水印投毒中的θ(1/εw^2)到O(√d/εp)时，可以保证水印的检测性和投毒的实用性，从而证明在数据投毒攻击中的水印方案的实用性。", "conclusion": "通过实验验证了理论发现，针对几种攻击、模型和数据集进行了实验验证。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09204", "html_url": "https://arxiv.org/abs/2510.09204", "title": "Flow-Opt: 使用流匹配和可微优化实现可扩展的集中多机器人轨迹优化", "title_en": "Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization", "authors": "Simon Idoko,Arun Kumar Singh", "background": "在关节空间中对多个机器人的轨迹进行集中优化可以访问更大的可行空间，从而生成更平滑的轨迹，特别是在狭小空间中规划时。然而，这种方法在机器人数量超过非常小的规模时往往由于计算复杂性而在计算上不可行。这篇文章探讨了如何通过学习方法改善集中式多机器人轨迹优化的计算可行性。", "innovation": "这篇文章提出了Flow-Opt，一种基于学习的方法，将问题简化为首先学习生成模型以采样不同候选轨迹，然后使用已学习的安全过滤器(SF)确保快速推理时间下的约束满足。该生成模型采用流匹配模型与扩散变压器(DiT)增广，并结合排列不变的位置编码和地图编码器。提出了一个自定义的安全过滤器求解器，并配有一个预测上下文初始化的神经网络。初始化网络以半监督方式训练，利用安全过滤器求解器的可微性。这一创新点不仅使系统能够在几毫秒内生成数十个机器人的轨迹，比现有集中优化方法快几倍，而且也能比基于扩散模型的竞争对手更快地生成更平滑的轨迹，速度快数百倍。此外，每个组件均可以批量处理，能在几分之一秒内解决多个问题实例，这是创纪录的结果。最后，该方法能生成从一组起始和目标位置到另一组位置的一组多样化轨迹。", "conclusion": "本文通过提出Flow-Opt，实现了在多机器人环境中的可扩展集中轨迹优化。它可以生成多样化的轨迹，同时保持效率和计算可行性，极大地扩展了多机器人系统的应用范围和效率。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09242", "html_url": "https://arxiv.org/abs/2510.09242", "title": "探究理性扩张小波变换对使用深度学习模型的运动想象脑电图解码的影响", "title_en": "Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models", "authors": "Marco Siino,Giuseppe Bonomo,Rosario Sorbello,Ilenia Tinnirello", "background": "该研究探讨了一种名为 Rational Discrete Wavelet Transform（RDWT）的方法，在将运动想象电生理学（EEG）解码作为深度学习分类器应用之前，作为插件预处理步骤的影响。研究在四种先进的深度学习架构（EEGNet、ShallowConvNet、MBEEG_SENet 和 EEGTCNet）和三个基准数据集（高伽马、BCI-IV-2a、BCI-IV-2b）上进行了系统排序评估。", "innovation": "研究通过系统评估 RDWT 在不同深度学习架构下的影响，发现 RDWT 能够显著改善某些架构的解码性能，尤其是在 BCI-IV-2a 和 HGD 数据集上。", "conclusion": "研究结果表明，RDWT 是一种低开销、架构感知的预处理技术，可以为深度模型家族和具有挑战性的受试者带来实际的准确性和一致性提升。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09230", "html_url": "https://arxiv.org/abs/2510.09230", "title": "使用多模态大型语言模型和消费级摄像头诊断肩部疾病", "title_en": "Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras", "authors": "Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun", "background": "肩部疾病，如肩锁冻结（附着肩囊炎）等，是全球影响人群健康的重要疾病，特别是在老年人和从事重复肩部任务的工人中发病率较高。在医疗资源稀缺的地区，实现早期和准确的诊断面临巨大挑战，迫切需要低成本且可扩展的辅助诊断解决方案。因此，文中利用消费级设备拍摄的视频作为诊断基础，降低用户成本。并通过全新方式整合多模态大型语言模型（MLLM）在肩部疾病初步诊断中的应用，提出了一种新的混合动作视频诊断框架（HMVDx）。", "innovation": "文章的创新之处在于引入了多模态大型语言模型（MLLM）和消费级摄像头来辅助诊断肩部疾病，并提出了混合动作视频诊断框架（HMVDx），将动作理解和疾病诊断两个任务分别交给两个MLLMs来完成。此外，该研究还提出了一种名为Usability Index的新指标，用于评估MLLMs在医疗诊断全流程中的有效性，从而展现了低成本MLLMs在医疗应用中的潜力。实验结果显示，HMVDx在诊断肩关节损伤方面的准确率相比直接视频诊断提高了79.6%，提供了医疗领域视频理解应用的重要技术贡献。", "conclusion": "混合动作视频诊断框架（HMVDx）能够显著提高肩部疾病诊断的准确率，并通过低成本多模态大型语言模型为医疗领域的视频理解应用提供了新的思路。未来研究将进一步挖掘该技术在实际医疗诊断中的价值，并探索更广泛应用可能性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09239", "html_url": "https://arxiv.org/abs/2510.09239", "title": "通过不确定性建模和众包测量表征5G用户吞吐量", "title_en": "Characterizing 5G User Throughput via Uncertainty Modeling and Crowdsourced Measurements", "authors": "Javier Albert-Smet,Zoraida Frias,Luis Mendo,Sergio Melones,Eduardo Yraola", "background": "随着5G无线接入网络（RAN）容量增加，应用层用户吞吐量在下一代网络中的表征变得越来越具有挑战性，连接瓶颈已从网络边缘向更深处转移。传统方法如驾驶测试和运营商设备计数器成本高昂、限制性较强或无法捕获端到端（E2E）的服务质量及其变异性。", "innovation": "该工作利用了大规模的众包测量，包括由用户设备（UE）收集的端到端、无线、上下文和网络部署特征，提出了一种新的不确定性感知和可解释的方法来估算下行用户吞吐量。应用了NGBoost模型，这是一种同时输出点估计和校准置信区间的模型，这是该模型首次在计算机通信领域中使用，并提供了第一个基于5G众包数据集的基准测试。通过提出的方法分析了从4G到5G SA的吞吐量演变情况，显示了吞吐量瓶颈从RAN转移到传输和业务层的迹象，E2E指标的重要性超过了无线相关的特性。", "conclusion": "该研究通过评估4G方法并将其扩展到5G NSA和5G SA，提出了新的估算模型，首次应用了NGBoost模型，展示了从4G到5G SA的吞吐量演进趋势。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09247", "html_url": "https://arxiv.org/abs/2510.09247", "title": "将深度强化学习应用于标普500指数即期期权套期保值", "title_en": "Application of Deep Reinforcement Learning to At-the-Money S&P 500 Options Hedging", "authors": "Zofia Bracha,Paweł Sakowski,Jakub Michańków", "background": "本文探讨了深度Q学习在标普500指数即期期权套期保值中的应用。实验数据涵盖了2004年至2024年的日内价格数据，使用了六个预测变量：期权价格、基础资产价格、实值度、到期时间和已实现波动率以及当前的对冲位置。", "innovation": "本文基于TD3算法开发了一种基于代理的强化学习系统，通过历史日内价格数据进行训练，无需对价格动态做出显式的模型假设。研究通过交易费用和风险意识惩罚等手段验证了模型对不同市场条件的适应能力，结果表明，该系统在高成本或波动环境下能比传统的对冲方法更显优势，并展现了其在实际交易中的稳定性和灵活性。", "conclusion": "实验结果显示，深度强化学习代理在高成本或波动的环境中显著优于传统的Delta对冲策略。但当风险意识参数较高时，其性能会下降。这表明代理在风险控制方面需要进一步优化。此外，使用更长的时间间隔来估计波动率会导致结果更为稳定。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09253", "html_url": "https://arxiv.org/abs/2510.09253", "title": "使用视觉语言模型的零样本图像隐私分类", "title_en": "Zero-shot image privacy classification with Vision-Language Models", "authors": "Alina Elena Baia,Alessio Xompero,Andrea Cavallaro", "background": "历史上，基于专门学习的模型在图像隐私预测方面占主导地位。然而，当前的研究趋势倾向于使用为通用任务设计的大规模视觉语言模型（VLMs），这可能忽视了专门为该任务设计的模型所能达到的性能上限，因为缺乏系统的评估。", "innovation": "本文建立了一个零样本基准来评估图像隐私分类，这一过程使用与任务匹配的提示对顶级开源VLMs进行评估，并与现有的视觉单一模态和多模态方法进行了对比。结果表明，尽管VLMs在资源利用和推理速度方面存在劣势，但它们在隐私预测准确性上仍然落后于专门的小型模型。此外，VLMs在图像扰动下的鲁棒性更高。", "conclusion": "视觉语言模型在隐私预测准确性方面可能不如专门为该任务设计的小型模型，但在鲁棒性方面表现出色。未来的研究可以进一步探索提高VLMs在图像隐私预测方面的性能，同时保持其鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09250", "html_url": "https://arxiv.org/abs/2510.09250", "title": "具有可调质心的重力驱动滑翔器的智能导航", "title_en": "Smart navigation of a gravity-driven glider with adjustable centre-of-mass", "authors": "X. Jiang,J. Qiu,K. Gustavsson,B. Mehlig,L. Zhao", "background": "人工滑翔器被设计为在通过流体降落时分散，因此需要精确导航以到达目标位置。已有研究表明，这类滑翔器在通过调整质心动态分布来实现导航操作时，能够在粘性流体中精确到达目标位置。然而，不同粒子雷诺数下，滑翔器与流体的互动方式会改变，这影响了最优导航策略的选择。", "innovation": "通过全解析直接数值模拟（DNS）和强化学习，该研究发现了两种最优导航策略，使得滑翔器能够精准到达目标位置，这增加了研究对雷诺数影响的敏感性。不同雷诺数下，滑翔器的最佳策略依赖于其与周围流体的互动性质：在大雷诺数下，滑翔器通过快速翻滚和改变质心导航，生成强烈的惯性升力，从而增加水平飞行距离；而在小雷诺数下，高粘度阻碍了翻滚，滑翔器依靠调整质心以保持倾斜姿态，以此产生的粘性力水平作用，但这种力远小于大雷诺数下的惯性升力，导致水平飞行范围较小。", "conclusion": "研究结果解释了滑翔器最佳策略如何依赖于雷诺数Re_p的变化。该研究表明，不同雷诺数条件下，滑翔器可采取不同的导航策略以实现重力驱动下的精准导航，为设计和优化人工滑翔器提供了理论依据。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09260", "html_url": "https://arxiv.org/abs/2510.09260", "title": "GREAT: 通过情绪感知触发合成功能在RLHF中的通用后门攻击", "title_en": "GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis", "authors": "Subrat Kishore Dutta,Yuelin Xu,Piyush Pant,Xiao Zhang", "background": "近期的研究表明，RLHF（通过人类反馈的强化学习）极易遭受后门攻击，这些攻击通过在偏好数据中注入恶意触发器实现。现有方法通常依赖于静态且罕见的触发器，这限制了它们在现实场景中的有效性。", "innovation": "本文开发了GREAT框架，这是一种通过情绪感知触发合成功能在RLHF中植入通用性后门的方法。GREAT旨在对具有语义暴力请求和情绪愤怒触发器的易受攻击的用户群体进行有害响应生成。核心是使用潜在嵌入空间的操作触发器识别管道，利用主成分分析和聚类技术识别最具有代表性的触发器。本文还提出了Erinyes数据集，该数据集包含超过5000个从GPT-4获取的情感愤怒触发器，采用了一个原则性、分层且促进多样性的方法进行收集。", "conclusion": "实验表明，GREAT在后门攻击成功率方面显著优于基线方法，特别是在未见过的触发场景中，同时在无害输入上的响应质量保持良好。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09267", "html_url": "https://arxiv.org/abs/2510.09267", "title": "Placeit！一种学习机器人物体放置技能的框架", "title_en": "Placeit! A Framework for Learning Robot Object Placement Skills", "authors": "Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux", "background": "尽管机器人学在学习方面取得了巨大进展，但基本技能如物体放置仍然是一个核心挑战。一个关键瓶颈是获得大规模的高质量数据，通常这个过程是手动且劳动密集型的。受Graspit!的影响，Graspit!是一个使用模拟自动生成灵巧握持姿态的基础工作，本文提出了Placeit!，一个通过进化计算生成刚体放置位置的框架。Placeit!具有高度的灵活性，支持从放置物体到堆叠和插入的各种任务。", "innovation": "Placeit!通过质量多样性优化显著超越了最先进的方法，用于生成多样化且有效的姿态。在一个基于我们框架的拾取和放置流水线中，在120次真实的部署中实现了高达90%的成功率。这项工作将Placeit!定位为一种强大的工具，用于开放环境的拾取和放置任务，同时也是生成训练基于模拟的基础模型所需数据的重要引擎。", "conclusion": "Placeit!为机器人学中的开放环境拾取和放置任务提供了一种强大的工具，并作为生成用于训练基于模拟的基础模型的高质量数据的有价值工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09259", "html_url": "https://arxiv.org/abs/2510.09259", "title": "检测大型语言模型强化学习训练后数据污染", "title_en": "Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models", "authors": "Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li", "background": "大型语言模型（LLMs）的可靠评估受到数据污染的严重威胁。这种污染在培训样本中意外包含基准样本时尤为突出，会直接影响报告的性能结果。虽然数据污染检测方法已在预训练和监督微调阶段得到了开发，但在强化学习（RL）训练后日益重要的环节中却缺乏专门的方法。随着RL训练后阶段在LSTM推理方面变得至关重要，缺乏此类专门的检测方法是一个重大漏洞。为填补这一研究缺口，本文首次对RL训练后数据污染检测进行了系统研究，并提出了Self-Critique方法。该方法基于一个关键观察：在RL阶段结束后，LLMs输出的熵分布倾向于集中在特定且稀疏的模式上。Self-Critique通过探测潜在的策略崩溃来促使这种熵减少，从而揭示模型收敛于狭窄的理由路径。为支持研究，我们也引入了RL-MIA基准，用于模拟此特定的污染场景。实验表明，Self-Critique在多种模型和污染任务上显著优于基准方法，AUC提高高达30%，而现有方法在RL阶段的污染检测上几乎等同于随机猜测，但我们的方法能够实现检测。", "innovation": "首次对RL训练后数据污染进行了系统研究，并提出了检测方法Self-Critique。该方法结合LLMs输出熵分布特性，有效检测策略崩溃，实现对此阶段数据污染的检测。", "conclusion": "研究提出了Self-Critique方法，通过模拟特定期望的污染场景，针对RL训练后污染进行了有效的检测，显著优于现有方法。实验结果证明，Self-Critique在多个模型和任务上表现优异，这对确保LLMs的可靠性和进一步提升其推理能力具有重要意义。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09312", "html_url": "https://arxiv.org/abs/2510.09312", "title": "通过其计算图验证链式思考推理", "title_en": "Verifying Chain-of-Thought Reasoning via Its Computational Graph", "authors": "Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda", "background": "当前的链式思考（CoT）验证方法依赖于输出（黑箱）或激活（灰箱）来预测推理的正确性，但提供的关于计算失败原因的洞察比较有限。", "innovation": "引入了一种白箱方法——基于电路的推理验证（CRV）。该方法假设正确的CoT步骤的归因图，作为模型潜在推理电路的执行踪迹，具有与错误步骤不同的结构指纹。通过训练分类器来识别这些图的结构特征，表明这些踪迹包含推理错误的强大力量信号。此白箱方法提供了其他方法无法获得的新科学洞见：（1）错误结构特征高度预测性的建立，表明可以直接通过其计算图验证推理；（2）发现这些特征高度特定于领域，揭示了不同推理任务中的错误表现为不同的计算模式；（3）证明这些特征不仅是相关性的，通过分析引导对个体解码器特征的针对性干预，成功纠正了模型的错误推理。", "conclusion": "通过审查模型的计算过程，可以从简单的错误检测发展到对大规模语言模型（LLM）推理机制的更深层次、因果的理解。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09308", "html_url": "https://arxiv.org/abs/2510.09308", "title": "基于模型驱动工程的AI赋能 healthcare平台方法", "title_en": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms", "authors": "Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi", "background": "人工智能（AI）有潜力通过支持更准确的诊断和个人化治疗来变革医疗保健。然而，其实际应用受到碎片化数据源、严格的隐私规定以及建立可靠临床系统的技术复杂性的限制。为了应对这些挑战，本文提出了一种专门用于医疗保健AI的模型驱动工程（MDE）框架。该框架依赖形式化的元模型、领域特定语言（DSL）和自动化转换，从高级规范到运行软件。其核心是医疗互操作性语言（MILA），这是一种图形DSL，允许临床医生和数据科学家使用共享本体定义查询和机器学习管道。", "innovation": "该框架引入了医疗互操作性语言（MILA），这是一款图形DSL，结合了领域特定语言和自动转换技术，让临床医生和数据科学家能够使用共享本体定义查询和机器学习管道。通过与联邦学习架构结合，MILA使得机构能够在不交换原始患者数据的情况下进行协作，同时保持各站点的语义一致性和隐私保护。这种方法在多中心癌症免疫治疗研究中得到了评估，生成的管道实现了出色的预测性能，支持向量机在关键任务上的准确率达到了98.5%和98.3%，极大地减少了手编码的工作量。这表明，模型驱动工程原则、语义集成和自动化代码生成能够提供一条实用的途径，朝着互操作系统、可重复性和可信赖的数字健康平台发展。", "conclusion": "研究结果表明，MDE框架，尤其是MILA语言，可以在保护患者隐私的同时实现医疗AI系统的互操作性和可重复性，为构建可靠的数字健康平台提供了可行路径。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09269", "html_url": "https://arxiv.org/abs/2510.09269", "title": "通过物理对象针对视觉-语言-动作模型的导向性后门攻击", "title_en": "Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects", "authors": "Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang", "background": "近年来，视觉-语言-动作(VLA)模型在增强体态人工智能方面取得了显著进展，使得机器人能够遵循自然语言指令并执行多样化的任务。然而，这些模型依赖于未加筛选的数据集训练，引发了严重的安全问题。现有的VLA后门攻击大多假定白盒访问条件，导致任务失败而非执行特定动作。本文揭示了一种更为实际的威胁：攻击者只需在训练数据集中注入物理对象作为触发器，便可以操控VLA。", "innovation": "本文提出了一种导向性后门攻击(GoBA)，在触发器存在时VLA会执行预定义的目标导向动作，但在没有触发器时表现正常。具体地，基于流行的VLA基准LIBERO，提出了BadLIBERO数据集，包含了多种物理触发器和目标导向后门动作。此外，本文提出了一种三层评估方法，将受害VLA在GoBA下的行为分为不做、尝试做和成功做到三种状态。实验表明，在物理触发器存在时，GoBA可使受害VLA成功完成后门目标的比例达到97%，对干净数据无性能退化。同时，研究因素对GoBA的影响发现，动作轨迹和触发器颜色显著影响攻击性能，而触发器大小的影响却出乎意料地小。", "conclusion": "研究表明，GoBA在物理触发器存在时能使受害VLA成功实现后门目标97%，在干净输入上无性能损失，且触发器的彩色和动作轨迹对攻击效果影响显著，而触发器尺寸影响较小。同时提供了相关的代码和BadLIBERO数据集。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09288", "html_url": "https://arxiv.org/abs/2510.09288", "title": "统一的贝叶斯框架以实现对抗鲁棒性", "title_en": "A unified Bayesian framework for adversarial robustness", "authors": "Pablo G. Arce,Roi Naveiro,David Ríos Insua", "background": "机器学习模型对对抗攻击的脆弱性仍然是一个关键的网络安全挑战。传统的防御方法，如对抗性训练，通常通过最小化最坏情况下的损失来使模型更加健壮。然而，这些确定性的方法并未考虑对手攻击的不确定性。虽然存在一些将概率分布应用于对手的随机防御方法，但它们通常缺乏统计严谨性，未能明确说明其背后的假设。为此，我们引入了一个正式的贝叶斯框架，通过对抗不确定性使用随机通道来建模，并明确所有概率假设。这产生了两种增强策略：一种在训练期间实施的积极防御，与对抗性训练一致，另一种在操作期间实施的被动防御，与对抗性净化一致。多种以前的防御措施可以被视为我们模型的极限情况。我们通过经验验证方法，展示了明确建模对抗不确定性的好处。", "innovation": "我们提出了一个统一的贝叶斯框架，该框架能够通过随机通道建模对抗性不确定性，并明确所有的概率假设。这种方法提供两种增强策略：一种训练期间的积极防御，另一种在操作期间的被动防御。所提出的方法能覆盖先前许多防御措施作为极限情况，且通过实验证明了这种方法的优越性。这种框架在对抗鲁棒性方面是一个创新的贡献，并填补了之前防御方法在统计严谨性和不确定性建模方面的空白。", "conclusion": "通过我们的统一贝叶斯框架，各种先前的防御措施能够被识别和归类。这种方法不仅提高了防御的有效性，还为对抗鲁棒性的研究和实践提供了新的视角。实证研究表明，明确建模对抗不确定性可以显著提升模型的防御能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09407", "html_url": "https://arxiv.org/abs/2510.09407", "title": "整合交易和所有权网络的多模态中小企业信用评分方法", "title_en": "A Multimodal Approach to SME Credit Scoring Integrating Transaction and Ownership Networks", "authors": "Sahab Zandi,Kamesh Korangi,Juan C. Moreno-Paredes,María Óskarsdóttir,Christophe Mues,Cristián Bravo", "background": "中小企业在经济增长、就业和创新方面扮演着重要角色，但由于其有限的金融历史、缺乏担保和宏观经济冲击的影响，它们往往难以获得信贷。由于中小企业常常通过共同的所有权和财务交易在网络中相互关联，准确评估信贷风险对贷款人至关重要，因为这有助于防止违约风险的传播。", "innovation": "本文提出了一种通过使用从企业间共同所有权和财务交易派生的多层网络数据来预测中小企业违约的新方法，其中采用了图神经网络来处理这些复杂的关系结构。该方法将传统的结构化数据与网络数据整合起来，不仅提高了信用评分的性能，还能够明确建模公司之间的传染风险。", "conclusion": "通过进一步分析发现，这些连接的方向性和强度会影响财务风险的传染过程，从而揭示了网络数据的预测能力和供应链网络如何使中小企业面临相关违约风险。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09365", "html_url": "https://arxiv.org/abs/2510.09365", "title": "基于生物物理条件的3D脑肿瘤MRI合成生成框架", "title_en": "A Biophysically-Conditioned Generative Framework for 3D Brain Tumor MRI Synthesis", "authors": "Valentin Biller,Lucas Zimmer,Can Erdur,Sandeep Nagar,Daniel Rückert,Niklas Bubeck,Jonas Weidner", "background": "磁共振成像（MRI）在临床和研究中有着广泛的应用。为了进一步完善脑肿瘤MRI图像的质量，以往的方法主要集中在图像插值和病灶合成。该研究介绍了一种在体素级别上基于连续肿瘤浓度的生成模型，能够合成高保真度的脑肿瘤MRI图像。针对BraTS 2025图像修复挑战，将该架构转换应用于健康组织修复任务。模型在肿瘤合成和健康组织图像修复任务上分别实现了17.4和18.5的PSNR值。", "innovation": "首次提出了一种生成模型，该模型基于体素级别的连续肿瘤浓度条件化，并且能够合成高质量的脑肿瘤MRI图像。模型还通过设置肿瘤浓度为零，成功应用于健康组织图像修复任务。此外，该模型还能够在肿瘤合成和健康组织图像修复任务上产生一致的且具有空间连贯性的3D图像。", "conclusion": "通过使用该基于生物物理条件的3D脑肿瘤MRI合成生成框架，作者在肿瘤合成和健康组织图像修复任务上均获得了较好的结果，其中健康组织图像修复的PSNR值达到18.5，肿瘤图像修复的PSNR值达到17.4，展示出了出色的图像恢复效果，且代码已经公开。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09315", "html_url": "https://arxiv.org/abs/2510.09315", "title": "基于响应梯度的可靠性灵敏度", "title_en": "Reliability Sensitivity with Response Gradient", "authors": "Siu-Kui Au,Zi-Jun Cao", "background": "工程风险关注于失败的几率及其发生的场景。失效概率的变化对系统参数的敏感性与风险告知决策息息相关。计算敏感性要比计算概率本身更加困难，特别是在遇到大量输入随机变量、罕见事件和隐含非线性“黑箱”响应的情况下。有限差分法结合蒙特卡洛概率估算可能是错误的方法，为了减少估计方差，需要样本数量与步长的倒数成正比增长。大多数现有工作的效率都依赖于特定类别输入变量、敏感性参数或其准确形式或代理形式的响应。但对于一般系统，本研究提出了使用响应值及其对敏感性参数的梯度来计算敏感性的理论和相关蒙特卡洛策略。研究表明，给定响应阈值下的敏感性可以通过条件于阈值的响应梯度的期望来表达。确定该期望需要对概率为零的阈值进行条件化，但可以通过核平滑的概念来解决。", "innovation": "本研究提出了一种基于响应值及其对敏感性参数梯度的灵敏度计算理论和相关蒙特卡洛策略。该方法能够在一次蒙特卡洛运行中提供所有响应阈值下的敏感性估计。通过核平滑的概念，解决了对概率为零的阈值进行条件的问题。这种方法期望能够在可靠性分析中结合敏感性计算，尤其是在同一蒙特卡洛运行中。", "conclusion": "该研究展示了如何通过条件于响应阈值的响应梯度的期望来表达相应的敏感性，并利用核平滑的方法解决了概率为零事件的条件化问题。该方法为在单一蒙特卡洛运行中进行灵敏度估计提供了基础，并且期望能够在未来的工作中将敏感性计算与可靠性分析结合在同一蒙特卡洛分析中进行。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09418", "html_url": "https://arxiv.org/abs/2510.09418", "title": "大型语言模型的主动模型选择", "title_en": "Active Model Selection for Large Language Models", "authors": "Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel", "background": "现有的评价和基准测试方法依赖于完全标注的数据集，这种做法在资源和成本上较为昂贵。本文旨在介绍LLM SELECTOR框架，它能够在有限标注的情况下高效地选择最佳的大语言模型。通过针对具体任务自适应地选择最相关的问题进行标注，该框架进一步降低了标注成本，通过利用基于法官的oracle标注模型，节省了高达59.62%的标注成本。研究在6个基准测试数据集和151个大语言模型上进行了广泛实验，验证了该方法的有效性。", "innovation": "1. 引入了LLM SELECTOR框架，能够在有限标注的情况下选择最佳的大语言模型。\n2. 使用自适应的查询选择策略，选择对确定最佳模型最有信息量的问题进行标注。\n3. 利用基于法官的oracle标注模型，进一步减少了标注成本。\n4. 在多个大语言模型和基准测试上进行了实验，验证了该方法的有效性和成本效益。", "conclusion": "LLM SELECTOR框架能够在有限标注的情况下高效选择最佳的大语言模型，通过自适应的查询选择策略和基于法官的oracle标注模型，显著降低标注成本，通过广泛的实验验证了该方法的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09424", "html_url": "https://arxiv.org/abs/2510.09424", "title": "Speech-LLM采取全部：一个真正的端到端语音对话状态跟踪方法", "title_en": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach", "authors": "Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf", "background": "本文进行了上下文管理策略在端到端语音对话状态跟踪中的比较研究，使用了对话式LLM (Speech-LLM)。作者系统性地评估了传统的多模态上下文（结合文本历史和当前语音轮次）、完整的语音历史和压缩的语音历史等策略。研究基于SpokenWOZ语料库进行实验，结果表明提供完整的语音对话作为输入可以显著提高模型性能，超越了之前的各种方法。作者进一步展示了基于注意力池化的语音历史压缩方法在减少上下文大小的同时保持了竞争力，改进源于更加有效上下文的利用。", "innovation": "研究创新点在于使用了完整的语音对话以及基于注意力池化的压缩方法来改进对话状态跟踪。这种方法不仅在性能上超越了之前的尝试，同时还保持了较小的上下文大小优势，提高了工作效率。", "conclusion": "通过提供完整的语音对话作为输入，实验表明模型可以获得最佳性能，而基于注意力池化的压缩方法则提供了一种有效的权衡，既保持了较高的准确性又减少了上下文的大小。进一步分析证实了通过更有效地利用上下文所带来的改进。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09338", "html_url": "https://arxiv.org/abs/2510.09338", "title": "局部主义大语言模型——动态局部性控制的数学框架", "title_en": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control", "authors": "Joachim Diederich", "background": "本文提出了一种新的框架，用于训练具有连续可调内部表示的大语言模型，这些表示涵盖了从局部主义（可解释的规则基础）到分布式（通用且高效编码）的整个光谱范围。关键创新是引入了一个局部性旋钮，一个可调参数，在训练和推理期间动态控制局部程度，而无需重新训练模型。这一创新通过组稀疏性惩罚、基于信息论的锚定点设计以及动态规则注入来实现。", "innovation": "提出了‘局部性旋钮’的概念，这是一种可调参数，可以在训练和推理过程中动态控制局部程度，而无需重新训练模型。通过组稀疏性惩罚、信息论锚定点设计和动态规则注入实现。证明了当组稀疏性惩罚超过一定阈值时，注意机制会集中在语义相关块上，实现低熵和高保真度。", "conclusion": "这种框架使实践者能够连续地在具有解释性的模式和高性能模式之间进行插值，支持需要透明度和能力的监管领域应用。数学证明支持了注意力机制在特定条件下有效聚焦于语义相关块，保障了语义相关性的同时保持高效。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09459", "html_url": "https://arxiv.org/abs/2510.09459", "title": "生成性机器人策略的实时故障预测", "title_en": "Failure Prediction at Runtime for Generative Robot Policies", "authors": "Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig", "background": "模仿学习（IL）结合生成模型，如反向扩散和流匹配，已使机器人能够执行复杂的长时间任务。然而，未见环境的变化或累积的动作错误仍可能导致不可预测且不安全的行为，导致任务失败。因此，在以人为本和安全关键环境中部署机器人时，运行时早期失败预测变得至关重要。", "innovation": "提出了一种名为FIPER的一般框架，用于生成IL策略的实时故障预测，该框架无需失败数据。FIPER通过在策略的嵌入空间中检测异常分布观察和通过新颖的动作块熵分数测量生成动作的高不确定性来识别两种即将出现的故障指标。同时利用少量成功的回放进行配准预测。当两个指标在一个短时间内超过阈值时，会触发故障警报。通过多种仿真和真实环境中的评估，证明FIPER比现有方法更能区分实际故障与良性异常情况，并能更准确、更早地预测故障。", "conclusion": "我们认为该工作是朝着更可解释和更安全的生成机器人策略的重要一步。相关代码、数据和视频可在提供的网址中获得。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09415", "html_url": "https://arxiv.org/abs/2510.09415", "title": "使用自然istic MEG-fMRI 编码模型实现高空间和时间分辨率的大脑活动估计", "title_en": "Estimating Brain Activity with High Spatial and Temporal Resolution using a Naturalistic MEG-fMRI Encoding Model", "authors": "Beige Jerry Jin,Leila Wehbe", "background": "当前非侵入性神经成像技术在空间分辨率和时间分辨率之间做了权衡。弥散光学成像（如 fMRI）能够空间定位大脑活动，而脑磁图（MEG）能够捕捉快速的神经动态。然而，现有方法在单一实验样本中难以同时保持高分辨率，特别是对于自然主义数据而言，无法提供统一的高时空分辨率视图，使得在单一时间段内的神经活动难以准确捕捉与理解。本文研究者收集了超过七小时的听觉故事实验数据，并使用相同的刺激物进行了开放性 fMRI 数据集研究，旨在通过结合 MEG 和 fMRI 数据，开发一个基于变换器的编码模型，以实现高时空分辨率的大脑活动估计。", "innovation": "研究者提出了一个基于变换器的编码模型，该模型能够结合 MEG 和 fMRI 数据，估计大脑皮层源响应，具有高时空分辨率。该模型被训练以同时预测来自多个受试者的 MEG 和 fMRI 数据，并包含一个潜在层来表示重建的皮层源的估计值。该模型在模拟实验中比单一模态编码模型预测 MEG 更好，并且在源估计上提供了更高的空间和时间保真度。此外，该模型在未见过的受试者和模态上具有很好的泛化性，并能够更好地预测未见过的数据集中的电皮层图（ECoG）活动。研究表明，通过对大规模自然情景实验的整合，结合 MEG、fMRI 和编码模型，可以实现毫秒和毫米级别的大脑映射。", "conclusion": "该研究通过开发一个基于变换器的编码模型，结合了 MEG 和 fMRI 数据，实现了高时空分辨率的大脑活动估计。该模型不仅能够更准确地预测大脑活动，还适用于不同的受试者和模态。研究为未来细微时间尺度和空间尺度的大脑成像提供了新的方法，并展示了在大规模自然情景下整合 MEG、fMRI 和编码模型的价值。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09458", "html_url": "https://arxiv.org/abs/2510.09458", "title": "SilvaScenes: 从自然森林下木层图像中进行树木分割和种类分类", "title_en": "SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests", "authors": "David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère", "background": "随着对森林管理中使用机器人技术的兴趣增长，但在复杂自然环境中，人们对感知能力依然存在很大的困难。由于重遮挡、光照变化和茂密植被等条件，自动化系统在精确林业、生物多样性监测以及林业设备自动化等方面面临着挑战。现有数据集无法开发出优秀的感知系统，因为它们通常集中在城市环境或特定种类上。为解决这一问题，该研究展示了新的数据集SilvaScenes，用于从森林下木层图像中进行实例分割和树种分类。", "innovation": "该研究呈现了一个新的数据集SilvaScenes，用于从下木层图像中进行树种实例分割。该数据集覆盖了加拿大魁北克省五个生物气候区，包含来自24种树木的1476棵树的标注。研究展示了现代深度学习方法在实例分割开源代码上的性能，证实了树分割的相对容易（最高mAP为67.65%），但物种分类仍是一个重大挑战（mAP为35.69%）。", "conclusion": "通过基准测试，研究结果表明需要进一步改进树种分类技术。数据集和源代码将在此网站上提供。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09472", "html_url": "https://arxiv.org/abs/2510.09472", "title": "自然语言推理中的混合模型：以三段论逻辑为例", "title_en": "Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic", "authors": "Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki", "background": "尽管神经模型取得了显著进展，它们在推理，尤其是在逻辑推理等应用中的泛化能力仍然不足，这是个关键挑战。文献中通常将泛化能力归结为整体的一般化能力，但本文通过分析预训练的大语言模型在三段论子集上的表现，区分了泛化能力中的两个核心方面：解析性和递归性。解析性是指将复杂的推理简化为基本逻辑规则的能力；递归性则是通过迭代应用推理规则构建复杂表示的能力。", "innovation": "本文通过使用三段论片段作为自然语言推理的基准，独立评估了大语言模型在解析性和递归性两个核心泛化能力方面的表现。实验结果显示，尽管大语言模型在递归性方面表现不错，但在解析性方面存在明显不足。为解决这些限制，本文提出了一种结合符号推理和神经计算的混合架构，既保持了高效性，又保证了推理的完整性，即使在较小的神经组件下也是如此。", "conclusion": "利用混合模型可以有效应对神经推理系统中的关键泛化障碍。实验表明，这种混合架构在保证高效推理的同时，通过结合符号推理和神经计算，能够更全面地解决复杂问题。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09473", "html_url": "https://arxiv.org/abs/2510.09473", "title": "D-TPT: 维度熵最大化在视觉语言模型的测试时提示调谐校准中的应用", "title_en": "D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models", "authors": "Jisu Han,Wonjun Hwang", "background": "测试时适应范式通过在未标记的目标数据上立即对源模型进行调整来提供灵活适应领域变化的能力。视觉语言模型(VLMs)利用其泛化能力应对多种下游任务，测试时提示调谐已成为一种显著的解决VLMs调整的方法。本文讨论了对比VLMs，并识别出不同模态中占主导地位的特征维度之间的范式差距。研究发现，文本和图像模态中的占主导地位的维度显示出高度的预测敏感性，限制这些维度的影响可以改善校准误差。", "innovation": "本文提出了维度熵最大化方法，该方法通过将文本特征的分布向均匀性进行正则化，来缓解主导维度依赖性，从而减少测试时提示调谐中的校准性能下降。这种方法为提高VLMs在实际部署场景中的可靠性提供了一个简单而有效的解决方案。", "conclusion": "本文提出了D-TPT方法，通过维度熵最大化来改善测试时提示调谐中的校准性能，从而增强VLMs的实际部署可靠性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09475", "html_url": "https://arxiv.org/abs/2510.09475", "title": "基于LoRA的Few-shot多令牌DreamBooth风格一致角色生成", "title_en": "Few-shot multi-token DreamBooth with LoRa for style-consistent character generation", "authors": "Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar", "background": "随着音频视频行业的转型，AI技术不仅被用于自动化常规任务，还在激发新的艺术形式方面发挥了重要作用。本研究集中于生成大量新的人物角色，这些角色能够保留少量由人类设计的参考角色的艺术风格和视觉特征，从而拓宽动画、游戏及相关领域的创意可能性。", "innovation": "本文提出了一种多令牌策略，结合聚类分配单独标记给个体角色及其集体风格，并采用基于LoRA的参数高效微调方法。这种方法通过移除类特定的正则化设置并引入随机令牌和嵌入，在训练数据的少量条件下实现无限角色生成，同时保留所学习的风格。", "conclusion": "实验结果表明，本文方法能够生成高质量、具有较大多样性的角色，同时保留参考角色的独特美学特征。人工评估进一步证实了该方法的有效性，并突显了该方法的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09513", "html_url": "https://arxiv.org/abs/2510.09513", "title": "可解释的生成与判别学习用于多模态不完整临床数据", "title_en": "Interpretable Generative and Discriminative Learning for Multimodal and Incomplete Clinical Data", "authors": "Albert Belenguer-Llorens,Carlos Sevilla-Salcedo,Janaina Mourao-Miranda,Vanessa Gómez-Verdejo", "background": "临床问题通常包含多模态数据，这些数据通常有不完整的视角和样本量有限的情况，这对机器学习算法提出了重大限制。", "innovation": "本文提出了一种贝叶斯方法来有效地处理这些问题，同时提供可解释的解决方案。该方法结合了生成模型来捕捉跨模式关系的半监督策略，以及针对特定下游目标的目标导向判别模型，这种生成-判别双重模型提供了广泛理解和特定任务的洞见，并实现了不同的数据源之间的鲁棒推理。这种双重模型在多模态临床数据中的应用中表现出了捕捉和分离生物学、心理和社会人口学模态之间复杂交互关系的能力。", "conclusion": "该方法在多模态临床数据中的应用证明了其自动填补缺失视角的能力，并且能够在不同的数据源之间提供稳健推理。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09498", "html_url": "https://arxiv.org/abs/2510.09498", "title": "从单一双轴测试中无监督全场贝叶斯推断各向异性超弹性：心肌病例研究", "title_en": "Unsupervised full-field Bayesian inference of orthotropic hyperelasticity from a single biaxial test: a myocardial case study", "authors": "Rogier P. Krijnen,Akshay Joshi,Siddhant Kumar,Mathias Peirlinck", "background": "传统均质组织测试需要同时激发多种变形模式，如三轴剪切试验和双轴拉伸试验，这需要多个组织样本和复杂的样本操作，导致变异性和操作引起的组织损伤可能影响逆向识别的组织行为。本工作旨在通过关注使用非均匀变形轮廓来解决这个问题，在参数估计问题中，我们采用EUCLID无监督方法，结合贝叶斯推断和三维连续体元，适应基于多个非线性、各向异性本构模型的参数识别。", "innovation": "采用无监督方法EUCLID，结合贝叶斯推断和三维连续体元，适应基于多个非线性、各向异性本构模型的参数识别，能够从单一非均匀双轴拉伸试验中定量推断合成心肌组织切片的材料模型参数，并且与模拟结果和置信区间相符。", "conclusion": "该方法能够良好地与基准模拟结果和对应的置信区间相吻合，展示了从单一双轴拉伸测试中获取高度非线性和各向异性材料模型参数的潜力，具有不确定性量化功能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09477", "html_url": "https://arxiv.org/abs/2510.09477", "title": "针对Transformer概率模型的有效自回归推断", "title_en": "Efficient Autoregressive Inference for Transformer Probabilistic Models", "authors": "Conor Hassan,Nasrulloh Loka,Cen-You Li,Daolang Huang,Paul E. Chang,Yang Yang,Francesco Silvestrin,Samuel Kaski,Luigi Acerbi", "background": "基于Transformer的模型，如神经过程、先验拟合网络和表格基础模型，在单步边缘预测方面表现优异。然而，许多实际应用场景，如信号插值和多列表格预测，需要能够捕捉预测之间依赖关系的连贯联合分布。纯自回归架构能够高效生成这样的分布，但牺牲了这些模型进行元学习的强大灵活性。另一方面，从基于集合的模型中获得联合分布的标准方法需要在每个自回归步骤中重新编码附加的条件集，这非常昂贵。因此，我们引入了一个因果自回归缓冲区，它保留了两种架构的优势。这种方法将上下文编码与更新条件集的步骤解耦，模型一次处理上下文并缓存它。一个动态缓冲区随后捕捉目标依赖性：随着目标的加入，它们进入缓冲区并同时与缓存的上下文和其他缓冲的目标进行交互。这使批量自回归生成和一过式联合对数似然评估变得高效。统一的训练策略允许在极小的额外成本下无缝集成基于集合和自回归模式。", "innovation": "通过引入因果自回归缓冲区，该方法结合了自回归生成模型的效率和基于集合的条件模型的表征力。这一策略使得在Transformer基础的概率模型中进行联合预测成为可能。与强大的基线相比，该方法在预测准确性上表现一致，并在联合采样速度上提高了20倍左右。", "conclusion": "该方法结合了自回归生成模型的效率和基于集合的条件模型的表征力，从而使得Transformer基础的概率模型在进行联合预测方面变得更加实际可行。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09578", "html_url": "https://arxiv.org/abs/2510.09578", "title": "一石三鸟：通过Nest提高性能、收敛性和系统吞吐量", "title_en": "Three Birds with One Stone: Improving Performance, Convergence, and System Throughput with Nest", "authors": "Yuqian Huo,David Quiroga,Anastasios Kyrillidis,Tirthak Patel", "background": "变分量子算法（VQAs）有潜力在短期内展示量子实用性，但这些算法通常需要执行在最高精度的量子位和计算机上才能实现最佳性能，从而导致系统吞吐量低。最近的研究表明，VQAs可以在低精度量子位上初始运行，并在后续阶段转移到高精度量子位以达到良好的性能。", "innovation": "我们通过我们的技术Nest，在VQA执行过程中精心改变量子位精度映射，不仅（1）提高了性能，有助于接近最优结果，还（2）促进了更快的收敛。我们还使用Nest在同一台计算机上并发部署多个VQAs，从而（3）提高了系统吞吐量，同时平衡和优化了三种相互冲突的指标。", "conclusion": "我们的研究显示，Nest技术能够同时提高性能、促进收敛和增加系统吞吐量，使得在使用VQAs时能更好地解决量子计算中的多个矛盾目标。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09499", "html_url": "https://arxiv.org/abs/2510.09499", "title": "临床驱动的交互分割评估方法", "title_en": "A methodology for clinically driven interactive segmentation evaluation", "authors": "Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso", "background": "交互分割是构建稳健、通用的体素医学图像分割算法的一种有前景的策略。然而，临床不一致且不切实际的评价阻碍了公平对比，并错误反映了实际性能。本研究旨在提出一种基于临床的评价任务和指标定义方法，并构建一套标准化的评估管道软件框架。通过评估最先进的算法完成杂乱且复杂的任务，结果发现：（1）在处理用户交互时最小化信息丢失对于模型的稳健性至关重要；（2）动态缩放机制可以提升稳健性并加速收敛；（3）验证提示行为/预算与训练中的不同会导致性能下降；（4）2D方法在类似切片的图像和粗略目标上表现良好，但3D上下文在处理大型或不规则形状的目标上更有帮助；（5）非医学领域的模型（如SAM2）在对比度差和复杂形状情况下性能下降明显。", "innovation": "提出了一种基于临床的交互分割评价方法和标准化评估管道软件，并系统地评估了最先进算法在复杂任务下的性能，揭示了不同因素对算法的影响.", "conclusion": "模型的稳健性依赖于准确和一致的评价方法；不同算法在不同条件下表现出不同的性能特点，强调了适应用户交互、使用3D上下文的重要性."}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09534", "html_url": "https://arxiv.org/abs/2510.09534", "title": "条件流匹配用于贝叶斯后验推断", "title_en": "Conditional Flow Matching for Bayesian Posterior Inference", "authors": "So Won Jeong,Percy S. Zhai,Veronika Ročová", "background": "本文提出了一种通过流匹配的生成多元后验采样方法，该方法提供了一个简单的训练目标，并且不需要对似然性进行评估。该方法通过在数据和参数的联合空间中学习一个动态的分块三角形速度场，将源分布确定地传输到所需后验。这种方法利用了动态设计的优势：适当的约束可以产生单调映射，进而构建Brenier映射，实现快速生成与蒙日-卡门托维奇数据深度水平集对应的贝叶斯可信集轮廓。该方法在计算上比基于生成对抗网络和基于扩散的过程更为轻量，同时能够捕捉复杂的后验结构。作者还提供了经常性理论保证，即恢复的后验分布和相应的贝叶斯可信集的一致性得到保证。", "innovation": "本文提出了一种通过流匹配的生成多元后验采样方法，它可以学习数据和参数的联合空间中的动态分块三角形速度场，从而实现从源分布到所需后验的确定性传输。这种方法直接使用动态约束生成单调映射，进而形成Brenier映射，实现贝叶斯可信集的高效生成。这种方法在计算上更为轻量，并能够捕捉复杂的后验结构。此外，作者还提供了关于恢复的后验分布和贝叶斯可信集的一致性的经常性理论保证。", "conclusion": "本文提出的方法在计算上比基于生成对抗网络和基于扩散的过程更为轻量，能够捕捉复杂的后验结构，并且提供了关于恢复的后验分布和贝叶斯可信集一致性的经常性理论保证。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2302.08424", "html_url": "https://arxiv.org/abs/2302.08424", "title": "从上下文数据到新闻商决策：数据驱动算法的实际性能", "title_en": "From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms", "authors": "Omar Besbes,Will Ma,Omar Mouchtaki", "background": "本文研究了历史数据的相关性和数量如何影响绩效，通过分析一个上下文新闻商问题中的决策过程，即在不确定需求下的买空成本和卖空成本权衡。研究重点关注近期上下文下的过去需求对绩效的影响，并通过上下文相关的最坏情况预期后悔来分析数据驱动算法的性能。进一步探讨了加权经验风险最小化（WERM）策略，这些策略根据上下文空间中的相似性加权过去的数据，这包括经典的ERM、k-最近邻和核基策略。研究目的是精确刻画任何WERM策略在任何给定上下文配置下的最坏情况后悔，通过优化方法识别新闻商损失函数中的特定结构，从而将无限维优化问题简化为简单的线性搜索，揭示以前通用界所掩盖的基本见解，从而具体描述实际保证的性能以及算法的学习曲线.", "innovation": "本文的主要方法贡献在于精确刻画了任何WERM策略在任何给定上下文配置下的最坏情况后悔，这填补了以往文献主要通过聚散不等式得到上界的空白，本文采用优化方法识别出新闻商损失函数中的特定结构，在此基础上简化了最坏情况分布上的无限优化问题，转变为简单的线性搜索，揭示了以前被通用界遮蔽的基本见解.", "conclusion": "本文针对上下文新闻商问题中，通过加权经验风险最小化策略，精确界定了算法的最坏情况后悔，揭示了算法实际保证的性能以及学习曲线，提供了迄今为止在任何上下文决策问题中对紧致性能保证的理解。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09599", "html_url": "https://arxiv.org/abs/2510.09599", "title": "提示测试时缩放是一种强大的大型语言模型推理数据增强方法", "title_en": "Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation", "authors": "Sondos Mahmoud Bsharat,Zhiqiang Shen", "background": "大型语言模型（LLMs）在提供推理链示例的情况下展示了惊人的推理能力，但收集大规模推理数据集仍然是耗费人力和资源的过程。本文介绍了一种名为Prompting Test-Time Scaling（P-TTS）的简单而有效的推理时数据增强策略，该策略通过微调增强LLMs的推理能力。P-TTS利用了90个手动选择的推理示例池，在测试时通过有原则的指令提示强度系统地变化示例增强，以合成多样化的推理轨迹背景。这种方法使研究人员能够通过最少的标注工作量来探索推理模式的潜在空间，从而增强LLM的问题解决能力，并进一步释放LLMs的推理潜力和能力。", "innovation": "引入了Prompting Test-Time Scaling（P-TTS）作为一种简单高效的推理时数据增强策略，利用少量手动选择的推理示例（90个），在测试时通过有原则的指令提示强度系统地变化示例增强，以合成多样化推理轨迹背景。该方法通过在P-TTS数据上对各种规模的Qwen-2.5模型进行微调，在AIME2024、MATH500及GPQA-Diamond等数学推理基准测试中，显著优于之前具有竞争力的基线模型如S1和S1.1（1K-shot），展示了增强零样本推理泛化能力的效果。", "conclusion": "P-TTS通过测试时缩放有效探索了推理模式的潜在空间，以最小的注释开销增强LLM问题解决能力，并进一步释放LLMs的推理潜力和能力。该方法为资源受限或快速演变的领域提供了一种实际、低成本的方法来引发LLM推理。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.01591", "html_url": "https://arxiv.org/abs/2311.01591", "title": "对抗缺失性过程下的公平图机器学习", "title_en": "Fair Graph Machine Learning under Adversarial Missingness Processes", "authors": "Debolina Halder Lina,Arlei Silva", "background": "图神经网络（GNNs）已经在许多与敏感社区相关的领域取得了最先进的成果，但在现有公平性GNN的工作中，往往假设敏感属性要么完全被观察到，要么完全随机缺失。现有的方法未能有效应对这些假设以外的情况，尤其是当数据缺失是非随机的对抗性缺失时。", "innovation": "提出了一种新的公平缺失数据填充模型——Better Fair than Sorry (BFtS)，其核心在于填充应该逼近最坏的公平性场景，即在优化公平性最困难的情况下。BFtS通过一个3个对手的对抗方案实现这一理念，其中两个对手联合对抗一个GNN分类器，分类器在最大化降低偏差的条件下进行优化。", "conclusion": "实验结果表明，BFtS在对抗缺失性过程下往往能够更好地在公平性和准确性之间进行权衡，优于现有的替代方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.11562", "html_url": "https://arxiv.org/abs/2406.11562", "title": "一种基于仿生强化学习的捕获-瞄准-发射任务框架", "title_en": "An Imitative Reinforcement Learning Framework for Pursuit-Lock-Launch Missions", "authors": "Siyuan Li,Rongchang Zuo,Bofei Liu,Yaoyu He,Peng Liu,Yingnan Zhao", "background": "在空中作战中，近距离 visual 范围内无人机之间的交战（WVR 交战）起着决定性作用。随着人工智能的发展，WVR 交战正逐渐向智能化和自主化方向发展。然而，自主 WVR 交战策略学习受到探索能力弱、学习效率低以及虚拟模拟环境不真实的挑战。", "innovation": "提出了一种新颖的模仿强化学习框架，该框架高效利用专家数据，同时允许自主探索。该框架通过专家模仿增强学习效率，通过强化学习实现自主探索以适应动态环境，从而能为无人机学习成功的‘捕获-瞄准-发射’策略。", "conclusion": "通过基于 Harfang3D 沙盒构建环境，实验结果表明，所提出的框架在多阶段任务中表现出色，显著优于最先进的强化学习和模仿学习方法。由于模仿专家和自主探索的能力，该框架能够迅速在复杂的空中作战任务中学习关键知识，实现了高达 100% 的成功率，并展示了出色的鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.10255", "html_url": "https://arxiv.org/abs/2311.10255", "title": "FREE: 建模环境生态系统的基石语义识别", "title_en": "FREE: The Foundational Semantic Recognition for Modeling Environmental Ecosystems", "authors": "Shiyuan Luo,Juntong Ni,Shengyu Chen,Runlong Yu,Yiqun Xie,Licheng Liu,Zhenong Jin,Huaxiu Yao,Xiaowei Jia", "background": "建模环境生态系统对地球可持续发展至关重要，但由于大量物理变量之间的复杂交互作用，这一过程极其具有挑战性。许多变量在大规模上难以测量，因此现有研究通常结合可观察特征和局部可用测量值或模型值作为输入来构建特定研究区域和时间段的模型。这引发了环境生态系统建模中的一个基本问题：如何构建一个通用框架来模拟多样环境变量在时空中的复杂关系？", "innovation": "本文提出了一种名为FREE的框架，能够利用可用的环境数据和信息来训练通用模型。核心思想是将可用的环境数据映射到文本空间，然后将环境科学中的传统预测建模任务转换为语义识别问题。FREE在两个重要的现实世界应用中（溪流水温预测和农作物产量预测）的表现优于多个基准模型，即使在数据稀疏的情况下也是如此。", "conclusion": "我们的评估结果表明，FREE在多个实际应用中表现优于传统方法，能够更有效地处理数据稀疏的情况，具有广泛的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15495", "html_url": "https://arxiv.org/abs/2405.15495", "title": "向自然的机器遗忘迈进", "title_en": "Towards Natural Machine Unlearning", "authors": "Zhengbao He,Tao Li,Xinwen Cheng,Zhehao Huang,Xiaolin Huang", "background": "机器遗忘（MU）旨在从预训练模型中移除特定训练数据中学习到的信息，即忘记数据。当前，现有的MU方法主要是通过使用错误标签修改遗忘数据并随后对模型进行微调。虽然学习这种错误信息确实可以移除知识，但这一过程非常不自然，因为遗忘过程会无意中强化错误信息，导致过度遗忘。", "innovation": "本文提出了一种新颖的方法，通过在数据剩余信息中注入正确信息并重新调整标签，以更自然的方式进行机器遗忘。这种方法通过配对调整后的样本及其标签，使得模型倾向于使用注入的正确信息并自然地抑制需要遗忘的信息。尽管该方法看似简单，但与现有的最先进的方法相比，它在减少过度遗忘和具有强超参数鲁棒性方面表现出色，成为实用机器遗忘的一个有前景的选择。", "conclusion": "我们的方法显著减少了过度遗忘，并具有很强的超参数鲁棒性，为实际的机器遗忘提供了一个有潜力的候选解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.11833", "html_url": "https://arxiv.org/abs/2410.11833", "title": "在复杂Q函数中缓解确定性策略梯度的亚最优性", "title_en": "Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions", "authors": "Ayush Jain,Norio Kosaka,Xinhu Li,Kyung-Min Kim,Erdem Bıyık,Joseph J. Lim", "background": "在强化学习中，DDPG和TD3等离策略演员-评论家方法使用确定性策略梯度：Q函数从环境数据中学习，而演员则通过梯度上升来最大化它。我们观察到，在诸如灵巧操作和受限移动等复杂任务中，Q函数存在许多局部最优，使得梯度上升容易被困住。", "innovation": "我们引入了SAVO演员架构，该架构(i)生成多个动作提案并选择具有最高Q值的动作；(ii)通过截断差的局部最优来多次逼近Q函数，从而更有效地指导梯度上升。", "conclusion": "我们在受限移动、灵巧操作和大型离散动作空间推荐系统等任务中进行了评估，并展示了我们的演员更频繁地找到最优动作，且优于其他演员架构。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.17888", "html_url": "https://arxiv.org/abs/2402.17888", "title": "ConjNorm: 可计算的密度估计方法用于离群值检测", "title_en": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection", "authors": "Bo Peng,Yadan Luo,Yonggang Zhang,Yixuan Li,Zhen Fang", "background": "后验离区分布（OOD）检测在可靠的机器学习中引起了广泛关注。许多努力致力于基于逻辑、距离或严格的数据分布假设来构建得分函数，以识别低得分的OOD样本。然而，这些估计得分可能难以准确反映真实的数据密度，或者过于严格的约束条件是不可取的。", "innovation": "提出了一个基于Bregman发散的新型理论框架，该框架扩大了对指数家族分布的考量。根据定理揭示的共轭约束条件，引入了\textsc{ConjNorm}方法，重新定义了密度函数设计，作为在给定数据集上寻找最优范数系数$p$的问题。此外，为了克服归一化计算的挑战，设计了一个基于重要性采样的蒙特卡洛方法来估计分区函数的无偏且解析可处理的估计量。广泛的实验结果表明，\textsc{ConjNorm}在不同OOD检测基准测试中建立了新的最新表现，相比于当前最好方法，在CIFAR-100和ImageNet-1K上的FPR95分别取得了最高13.25%和28.19%的提升。", "conclusion": "通过\textsc{ConjNorm}方法，提出了一种新的离群值检测设计，实现了在多个基准测试中的最新性能表现，显著提高了准确性和鲁棒性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.02642", "html_url": "https://arxiv.org/abs/2406.02642", "title": "E-ICL：通过原型理论增强细粒度情感识别", "title_en": "E-ICL: Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory", "authors": "Zhaochun Ren,Zhou Yang,Chenglong Ye,Yufeng Wang,Haizhou Sun,Chao Chen,Xiaofei Zhu,Yunbing Wu,Xiangwen Liao", "background": "在上下文学习（ICL）中，它在知识获取、常识推理和语义理解等领域取得了显著成效。但是，在情感检测任务中，特别是细粒度情感识别方面，其性能显著下降。虽然原因尚不清楚，但研究表明ICL遵循原型理论。现有研究发现，ICL依赖于在语义上相似但情感上不准确的原型（示例-标签对）来预测情感，且容易受到无关类别的干扰，影响预测的准确性和鲁棒性。", "innovation": "本文基于原型理论，识别了ICL在细粒度情感识别中的表现不佳原因，并提出了一种新的方法Emotion Context Learning (E-ICL)。E-ICL通过参考动态标签的情感类似示例来采用更准确的原型预测类别，还采用排除性情感预测策略来避免无关类别的干扰，提升了情感识别的准确性和鲁棒性。研究结果表明，E-ICL在细粒度情感数据集（EDOS, Empathetic-Dialogues, EmpatheticIntent, GoEmotions）中的情感预测性能优于现有ICL方法，即便所用的情感辅助模型只有LLMs的10%以下，E-ICL也能显著提升LLMs的情感识别性能（超过4%）", "conclusion": "总之，本文通过E-ICL方法，在细粒度情感识别中取得了显著效果，解决了ICL在情感识别任务中表现不佳的问题，为情感识别提供了新的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09595", "html_url": "https://arxiv.org/abs/2510.09595", "title": "LiveOIBench：大型语言模型在信息学奥赛中能否超过人类参赛者？", "title_en": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "authors": "Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang", "background": "随着编程竞赛问题变得越来越复杂且易于验证，它们逐渐成为评估大型语言模型（LLMs）编码能力的宝贵基准。然而，现有编码基准仍存在一些不足，例如缺乏足够具有挑战性的题目、测试用例覆盖率不足以及依赖于限制访问性的在线平台API。为解决这些问题，本文介绍了一个名为LiveOIBench的综合基准测试，其中包括403个由专家选编的信息学奥林匹克级别编程竞赛题目，每题平均拥有60个由专家设计的测试用例。这些题目来源于2023年至2025年间不同地区进行的72场官方信息学奥林匹克竞赛。", "innovation": "LiveOIBench 的创新之处在于其四个关键特点：精心挑选、高质量的任务，详细子任务评分和广泛的私人测试用例；直接整合顶尖参赛选手的性能数据以提供有意义的人类顶尖表现对比；持续更新不存在污染的新发布的奥林匹克竞赛题目；以及自我封闭的评估系统，方便进行离线评估和再生产。", "conclusion": "在对32个流行的一般用途和推理LLM进行基准测试后，发现GPT-5达到了显著的81.76百分位，表现出色但仍未达到顶尖人类参赛者的水平，通常高于90百分位。相比之下，开源推理模型GPT-OSS-120B仅获得60百分位，说明前沿封闭模型与之存在显著能力差异。详细分析表明，稳健的推理模型倾向于进行精确的问题分析而非过度探索，这表明未来模型应重视结构化分析并尽可能减少不必要的探索。所有数据、代码和排行榜结果将被公开发布在官方网站上。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.04787", "html_url": "https://arxiv.org/abs/2412.04787", "title": "使用随机舍入法直接量化的语言模型训练", "title_en": "Direct Quantized Training of Language Models with Stochastic Rounding", "authors": "Kaiyan Zhao,Tsuguchika Tabaru,Kenichi Kobayashi,Takumi Honda,Masafumi Yamazaki,Yoshimasa Tsuruoka", "background": "近年来，如BitNet等基于二值或三值权重的量化大型语言模型（LLMs），实现了部署时显著减少内存使用的效果，但训练这些模型仍需要大量的内存空间。传统的训练方法需要保持高精度（即非量化）权重，这限制了内存使用的进一步优化。", "innovation": "本文探索了在反向传播过程中不依赖于直通估计，直接更新量化低精度权重的方法，以减少训练过程中的内存使用。具体地，通过使用随机舍入技术，最小化高精度权重替换低位权重过程中带来的信息损失。实验结果表明，使用仅低精度权重训练是可行的，扩展到8位比特宽度可以与BitNet b1.58性能相当，模型在从FP32到更低内存环境（BF16/FP8）迁移时表现稳定，且支持使用三值权重进行推理，展现了部署的灵活性。", "conclusion": "通过直接量化训练和随机舍入技术，展示了即使使用三值权重也可以实现与高精度模型相当的性能，模型具有良好的精度扩展和内存缩减能力，并且在不同精度环境中表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.14326", "html_url": "https://arxiv.org/abs/2412.14326", "title": "免费的协方差：利用均值分布实现无训练的联邦学习", "title_en": "Covariances for Free: Exploiting Mean Distributions for Training-free Federated Learning", "authors": "Dipam Goswami,Simone Magistri,Kai Wang,Bartłomiej Twardowski,Andrew D. Bagdanov,Joost van de Weijer", "background": "使用预训练模型可以减少数据异质性的影响，并加快联邦学习算法的速度。近期研究探索了利用第一和第二阶统计信息在服务器处聚合本地客户端数据分布的无训练方法，从而在无需任何训练的情况下达到高性能。", "innovation": "提出了一种基于类协方差无偏估计的无训练方法，仅使用客户端发送的类平均值来估计协方差，并用于初始化全局分类器，而无需共享实际的协方差信息。该方法仅使用类内的协方差来初始化分类器效果更好。此方法在相同的通信成本下提高了4-26%的性能，通信效率优于仅分享类均值的方法，并且在通信开销大幅减少的情况下，性能与分享第二阶统计信息的方法相当甚至更好。这种方法在初始化分类器后进行联邦微调或线性探针测试，也能进一步提高性能。", "conclusion": "提出的无训练方法在通信效率方面表现出色，并在无训练的联邦学习中取得了卓越的性能。源代码可在该网址获得。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11967", "html_url": "https://arxiv.org/abs/2412.11967", "title": "柴油发动机数字孪生体：基于迁移学习的操作驱动物理知情神经网络", "title_en": "A Digital Twin for Diesel Engines: Operator-infused Physics-Informed Neural Networks with Transfer Learning for Engine Health Monitoring", "authors": "Kamaljyoti Nath,Varun Kumar,Daniel J. Smith,George Em Karniadakis", "background": "发动机模型研究的重点包括提高柴油发动机效率、降低排放以及实现稳健的健康监测。虽然近期使用神经网络进行系统监控的研究显示出积极的结果，但这些方法往往仅集中在组件级别的分析上，缺乏通用性和物理可解释性。鉴于此，本文旨在提出一种新的混合框架，该框架结合了物理知情神经网络（PINNs）与深度操作网络（DeepONet），以实现平均值柴油发动机模型中参数识别的准确性和计算效率。该方法利用基于物理的知识与神经网络的数据驱动训练相结合，增强模型的适用性。", "innovation": "本文提出了一种新的混合框架，结合了物理知情神经网络（PINNs）与深度操作网络（DeepONet），用于柴油发动机模型中的参数识别，显著降低了在线计算成本。同时，该方法还提出两种迁移学习（TL）策略：一种多阶段的TL方案，提供比完整在线训练更好的运行时效率；另一种少量样本的TL方案，冻结共享的多头网络主体，在训练回路外计算物理基础的导数以进行模型训练。这两种策略提供了一种廉价且基于物理的方法来预测发动机动力学和参数识别，相比现有的PINN框架具有更高的计算效率和物理基础性。", "conclusion": "与现有的健康监测方法相比，我们的框架结合了基于物理模型的解释性和深度学习的灵活性，提供了柴油发动机故障诊断的基本增量，在通用性、准确性和部署效率方面取得了显著的成效。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.02436", "html_url": "https://arxiv.org/abs/2501.02436", "title": "基于网络动力学的理解深度神经网络框架", "title_en": "Network Dynamics-Based Framework for Understanding Deep Neural Networks", "authors": "Yuchen Lin,Yong Zhang,Sihan Feng,Hong Zhao", "background": "人工智能领域的进步要求我们深入理解深度学习背后的机制。本文通过动力系统理论重新审视学习动力学，提出了一种新的理论框架。该框架通过对神经网络中的线性与非线性重新定义（引入保持顺序和不保持顺序两种基本变换单元），解释了不同学习阶段的集体行为差异、信息提取方式及不同的学习阶段。过渡到不同阶段可能在训练过程中发生，能够解释诸如'grokking'等现象。", "innovation": "重新定义神经网络中的线性与非线性，利用动力系统理论分析学习动力学，通过引入保持顺序和不保持顺序两种基本变换单元，提出了一个理论框架。此外，还引入了吸引盆地的概念，用来表征样本空间和权重空间中的泛化能力和结构稳定性。", "conclusion": "该框架不仅揭示了深度学习的内在优势，还为优化网络架构和训练策略提供了新的视角。通过调节深度、宽度、学习率和批次大小等超参数，可以精细化调整这些指标，以提升模型性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06379", "html_url": "https://arxiv.org/abs/2502.06379", "title": "使用解耦扩散顺序蒙特卡洛方法解决线性高斯贝叶斯逆问题", "title_en": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo", "authors": "Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten", "background": "近期的研究利用预训练的生成性扩散模型作为先验来解决贝叶斯逆问题。这项研究的主要背景是，将生成扩散模型与贝叶斯逆问题解决方法相结合，提高问题的解决效率和效果。", "innovation": "本文的创新在于提出了一个新的顺序蒙特卡洛方法，称为解耦扩散顺序蒙特卡洛（DDSMC）算法。该方法基于解耦扩散框架，设计生成过程使得样本能进行更大规模的更新，并且是渐近精确的。该研究通过合成数据、蛋白质数据和图像数据验证了DDSMC算法的有效性，并展示了该方法如何扩展到处理离散数据。", "conclusion": "通过使用DDSMC算法，本文在解决线性高斯贝叶斯逆问题方面取得了显著进展，验证了方法的有效性，并为进一步的研究和应用奠定了基础。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.06916", "html_url": "https://arxiv.org/abs/2501.06916", "title": "使用黑盒优化和量子退火去除错误标注的训练实例", "title_en": "Filtering out mislabeled training instances using black-box optimization and quantum annealing", "authors": "Makoto Otsuka,Kento Kodama,Keisuke Morita,Masayuki Ohzeki", "background": "在实际数据集中，误标的数据实例是一个常见的问题，它会降低模型的泛化能力，需要有稳健且高效的噪声去除策略。", "innovation": "提出了一种结合基于代理模型的黑盒优化（BBO）与后处理以及量子退火的方法，用于从受到污染的训练数据集中去除误标实例。该方法通过验证损失来评估过滤后的训练子集，迭代地通过代理模型的BBO结合后处理来改进损失估计，并利用量子退火高效地抽样具有低验证误差的多样化训练子集。实验结果还展示了使用D-Wave的团采样器在物理退火器上的优化比OpenJij的模拟退火采样器或Neal的模拟退火采样器更快且更优，从而提供了增强数据集质量的可扩展框架。", "conclusion": "该工作展示了所提出方法在监督学习任务中的有效性，并指出未来的研究方向可以将其应用于无监督学习、真实世界数据集和大规模实现。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09981", "html_url": "https://arxiv.org/abs/2502.09981", "title": "用xLSTM探索神经Granger因果关系：揭示复杂数据中的时间依赖性", "title_en": "Exploring Neural Granger Causality with xLSTMs: Unveiling Temporal Dependencies in Complex Data", "authors": "Harsh Poonia,Felix Divo,Kristian Kersting,Devendra Singh Dhami", "background": "时间序列中的因果关系确定存在挑战，尤其是当存在非线性依赖时。Granger因果关系有助于分析变量之间的潜在关系，提供了一种确定一个时间序列能否预测另一个时间序列未来值的方法。尽管Granger因果方法取得了成功，但它们仍然难以捕捉变量之间的长程关系。", "innovation": "为了克服这一问题，论文提出了Granger因果xLSTM（GC-xLSTM）方法。该方法通过使用新颖的动态损失惩罚在初始投影上引入稀疏性，从而适应性地改进模型并识别稀疏性候选者。联合优化程序确保Granger因果关系能够被稳健地恢复。实验结果显示，GC-xLSTM在六个不同的数据集上表现出了总体有效性。", "conclusion": "实验评估表明GC-xLSTM能够在六个不同数据集中有效恢复Granger因果关系，展示出了GC-xLSTM在揭示复杂数据时间依赖性方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07646", "html_url": "https://arxiv.org/abs/2502.07646", "title": "未观察到的因果路径和后门路径的因果加法模型", "title_en": "Causal Additive Models with Unobserved Causal Paths and Backdoor Paths", "authors": "Thong Pham,Takashi Nicholas Maeda,Shohei Shimizu", "background": "因果加法模型提供了在隐藏变量存在的情况下进行因果发现的一种易于处理但表达能力较强的框架。然而，当两个变量间存在未观察到的后门路径或因果路径时，其因果关系通常在现有理论下不可识别。本研究在许多情况下建立了因果方向可以被识别的充分条件，特别是针对观测变量共享未观察到的共同父节点的相邻配对（bow）这种情况。以往的研究没有在任何不依赖于隐藏变量假设的因果模型中建立这种可识别性。我们的条件依赖于回归集的新特征描述和独立性应用于回归残差与观测变量条件独立性的混合方法。", "innovation": "研究提出了新的回归集特征描述，并结合了独立性应用于回归残差与观测变量条件独立性的混合方法，以识别观测变量共享未观察到的共同父节点的相邻配对的因果关系。还提供了一种综合这些见解且有效的算法，并且实证评估显示该方法与最先进的方法具有竞争力。", "conclusion": "研究建立了许多情况下因果方向可以被识别的充分条件，尤其是在未观察到的后门路径或因果路径存在的复杂情况下。此外，研究提供了综合洞察的算法，并且实证评估显示其性能与最先进的方法相当。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04274", "html_url": "https://arxiv.org/abs/2502.04274", "title": "使用正交表示学习来估计因果量", "title_en": "Orthogonal Representation Learning for Estimating Causal Quantities", "authors": "Valentyn Melnychuk,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel", "background": "端到端表示学习已经成为从高维观察数据中估计因果量的强大工具，但其效率仍不明确。尽管端到端表示学习方法在实践中表现良好，但在形式上缺乏类似半oracle效率的渐近最优性。相比之下，Neyman正交学习者虽然提供了这样的理论最优性属性，但并没有直接从表示学习的优点中受益。本文通过对端到端表示学习和Neyman正交学习者的理论和经验分析，引入了一个统一框架，将表示学习与Neyman正交学习者（即，OR-学习者）联系起来，探讨了当表示增强现有Neyman正交学习者以及平衡约束是否能提高Neyman正交性的问题。随着这些见解，本文提供了如何有效结合表示学习与经典Neyman正交学习者以实现实际性能和理论保证的指导。", "innovation": "本文引入了一个统一框架，将表示学习与Neyman正交学习者（即，OR-学习者）联系起来，研究了如何利用表示学习加强现有Neyman正交学习者，并探讨了平衡约束是否能促进Neyman正交性。特别地，在低维流形假设下，OR-学习者可以严格改进标准Neyman正交学习者的估计误差。同时，本文发现平衡约束需要额外的归纳偏置，并不能一般性地弥补端到端方法缺乏Ney曼正交性的不足。", "conclusion": "基于以上研究，本文提供了结合表示学习与经典Neyman正交学习者来获得实际性能和理论保证的指导方针，以实现两者的有效结合。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11411", "html_url": "https://arxiv.org/abs/2502.11411", "title": "通过去噪表示的数据归属检测和过滤训练数据中的危险内容", "title_en": "Detecting and Filtering Unsafe Training Data via Data Attribution with Denoised Representation", "authors": "Yijun Pan,Taiwei Shi,Jieyu Zhao,Jiaqi W. Ma", "background": "大规模语言模型（LLMs）对少量不安全训练数据极为敏感，因此有效检测和过滤不安全数据对于开发可信赖的模型至关重要。当前最先进的检测方法主要依赖于内容过滤器，这种做法需要大量的计算资源，并且只能使用预定义的分类学标准。现有的方法存在一个关键的局限性：不安全的目标文本中既包含使之不安全的关键令牌，也包含必要的中性令牌（例如停止词或无害的事实），这使得整体的表示对于检测不安全训练数据变得“噪音”化。目前，大多数基于内容过滤器的方法难以解决这一问题，导致在识别不安全训练数据方面的性能通常较差，尤其是在过滤劫持和检测性别偏见等任务上。", "innovation": "本文提出了一种新颖的数据归属方法——去噪表示归属（DRA），该方法旨在去除训练和目标表示中的噪声，以更好地检测不安全训练数据。通过这种方法，模型能够更准确地识别出潜在不安全的数据点，从而显著提高数据归属方法的性能，超越主要依赖内容过滤器的当前最先进的方法。", "conclusion": "通过将训练数据和目标表示进行去噪处理，DRA方法在过滤劫持和检测性别偏见等多种任务中取得了显著提高，表现出比基于内容过滤器的现有先进方法更好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14396", "html_url": "https://arxiv.org/abs/2503.14396", "title": "在可学习流形上进行聚合的异步联邦优化", "title_en": "Aggregation on Learnable Manifolds for Asynchronous Federated Optimization", "authors": "Archie Licudi,Anshul Thakur,Soheila Molaei,Danielle Belgrave,David Clifton", "background": "异步联邦学习（FL）面对两个关键问题：标准线性参数插值技术（如FedAvg）导致的曲率引起的损失障碍，以及来自与服务器当前优化状态不一致的过时更新的干扰。", "innovation": "引入了一种几何框架，将聚合视为Riemannian模型空间中的曲线学习，并将轨迹选择与更新冲突解决分离。在此框架内提出了AsyncBezier和OrthoDC，分别使用低阶多项式（Bezier）轨迹替换线性聚合，以规避损失障碍，并通过基于内积的正交性投影过时更新，以减少干扰。该框架提供了在简单组件假设下的收敛性保证。", "conclusion": "在三个涵盖通用和医疗保健领域的数据集上（包括LEAF Shakespeare和FEMNIST），该方法在强异步基线之上，一致提高了准确性和客户端的公平性；当其他方法的本地计算预算较高时，这些改进仍然得到保持。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17410", "html_url": "https://arxiv.org/abs/2502.17410", "title": "COSMOS：大规模语言模型高效训练的混合自适应优化器", "title_en": "COSMOS: A Hybrid Adaptive Optimizer for Memory-Efficient Training of LLMs", "authors": "Liming Liu,Zhenghao Xu,Zixuan Zhang,Hao Kang,Zichong Li,Chen Liang,Weizhu Chen,Tuo Zhao", "background": "大规模语言模型（LLMs）在各个领域表现出色，但其优化面临重大挑战，因为它们必须在复杂的高维损失景观中进行优化。现有的自适应优化器，如AdamW，虽然广泛使用，但也存在关键局限性，包括捕捉坐标间交互能力有限和高内存消耗。后续研究，如SOAP，尝试更好地捕捉坐标间的交互性，但导致更高的内存开销，限制了大规模LLMs的适用性。另一种减少内存消耗的方法是低维投影，但这会导致显著的近似误差，影响优化性能。因此，现有解决方案需要在降低内存消耗和保持优化性能之间找到平衡。", "innovation": "本文提出COSMOS，一种新颖的混合自适应优化器，通过利用梯度矩阵中不同特征子空间的重要性差异，实现内存效率而不牺牲优化性能。COSMOS将SOAP应用到主特征子空间，以捕捉主要的优化动态，同时使用MUON处理不那么关键但SOAP难以高效处理的剩余特征子空间。这种混合策略显著降低了内存消耗，同时保证了优化性能的鲁棒性，特别适用于大规模LLMs。实验证明COSMOS的有效性。", "conclusion": "通过数值实验，本文展示了COSMOS在多种数据集和转换器架构上的有效性，并证明了其在大规模LLMs高效训练中的适用性。COSMOS为解决大规模语言模型优化过程中的内存效率问题提供了一种有效方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19499", "html_url": "https://arxiv.org/abs/2502.19499", "title": "Score Smoothing在扩散模型中的插值效应", "title_en": "On the Interpolation Effect of Score Smoothing in Diffusion Models", "authors": "Zhengdao Chen", "background": "评分扩散模型已经在多个领域取得了显著进展，能够生成训练集中不存在的新数据样本。该研究探讨了这种创造性的产生来自于评分函数平滑引起的一种插值效应。研究聚焦于训练集均匀存在于一维子空间的情况，理论分析表明正则化的双层ReLU神经网络倾向于学习近似的平滑版本的样本评分函数，并进一步通过解析解和数值实验研究了平滑评分与去噪动态之间的关系。研究还展示了如何通过平滑的评分函数生成间插训练数据样本，同时避免完全记忆。同时实验证明神经网络学习评分函数确实会产生评分平滑效应，包括简单的非线性设置中也没有显式正则化的情况下。", "innovation": "研究提出了通过正则化的双层ReLU神经网络理论分析平滑评分函数，并进一步通过解析解和数值实验研究了平滑评分与去噪动态之间的关系。此外，研究还展示了如何通过平滑的评分函数生成间插训练数据样本，同时避免完全记忆，并通过实验证明神经网络学习评分函数确实会产生评分平滑效应，包括简单的非线性设置中也没有显式正则化的情况下。", "conclusion": "研究得出了通过平滑评分函数可以生成间插训练数据样本，避免完全记忆的结论。并通过实验证明了神经网络学习评分函数确实会产生评分平滑效应，这种效应存在简单的非线性设置中。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10833", "html_url": "https://arxiv.org/abs/2505.10833", "title": "MergeBench：一种针对领域特化大语言模型的融合基准", "title_en": "MergeBench: A Benchmark for Merging Domain-Specialized LLMs", "authors": "Yifei He,Siqi Zeng,Yuzheng Hu,Rui Yang,Tong Zhang,Han Zhao", "background": "现有的模型合并方法展示了潜力，但现有的评估方法在模型规模和任务多样性方面都有所限制，这使其在应用到大型、领域特化的语言模型（LLM）时变得不确定。MergeBench 是一种全面的评估套件，旨在解决这一问题。它基于先进的开源语言模型，包括 Llama 和 Gemma 家族的 2B 到 9B 规模模型，并涵盖五个关键领域：指令遵循、数学、多语言理解、编程和安全性。", "innovation": "MergeBench 通过引入一个综合性的评估套件来评估模型合并，旨在解决现有的问题。它集成了广泛的模型进行多任务性能、遗忘和运行时效率的评估，并标准化了微调和评估协议，对八种代表性合并方法进行了评估。评估结果表明，模型合并倾向于在更强的基模型上表现更好，合并系数调整和稀疏化等技术可以提高知识保留。", "conclusion": "尽管模型合并存在一些挑战，例如大型模型上的计算成本、领域内性能与多任务模型之间的差距以及模型合并对标准 LLM 训练管道的探索不足，但 MergeBench 提供了进一步研究的基础，以深化对模型合并的理解和实际应用。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03955", "html_url": "https://arxiv.org/abs/2504.03955", "title": "DeepOHeat-v1: 动态操作学习实现快速且可靠的3D-IC热仿真与优化", "title_en": "DeepOHeat-v1: Efficient Operator Learning for Fast and Trustworthy Thermal Simulation and Optimization in 3D-IC Design", "authors": "Xinling Yu,Ziyue Liu,Hai Li,Yixing Li,Xin Ai,Zhiyu Zeng,Ian Young,Zheng Zhang", "background": "三维片上系统（3D-IC）设计中，热分析至关重要，因为随着功率密度增加和复杂热传导路径的出现，热管理变得更加关键。现有基于操作学习框架（如DeepOHeat）虽然在加速热模拟方面显示出有前景的初步结果，但在预测多尺度热模式方面、训练效率以及设计优化过程中结果的信任度方面存在重要限制。", "innovation": "1. 结合了可学习激活函数的Kolmogorov-Arnold网络作为主干网络，以适应性的表示多尺度热模式，减少两个典型测试案例中的误差1.25倍和6.29倍。2. 引入了沿坐标轴分解基函数的分离训练方法，使得基准案例中的训练速度提升62倍，GPU内存减少31倍，从而使得以前由于GPU内存限制而无法实现的热分析分辨率成为可能。3. 提出了信任度评分，并开发了一种混合优化流程，将操作学习与有限差异（FD）结合使用Generalized Minimal Residual（GMRES）方法进行增量解精炼，从而实现高效且可信的热优化。", "conclusion": "实验结果表明，DeepOHeat-v1在我们的测试案例中将优化过程加速70.6倍，同时保持与高保真有限差异求解器优化结果相当的准确性，有效地通过最佳放置发热组件将峰值温度降至最低。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14117", "html_url": "https://arxiv.org/abs/2505.14117", "title": "协作无标签数据优化", "title_en": "Collaborative Unlabeled Data Optimization", "authors": "Xinyi Shang,Peng Sun,Fengyuan Liu,Tao Lin", "background": "现有的模型中心方法存在三个关键限制，这些限制共同导致了一个瓶颈，即从数据提取的知识被锁定在模型参数中，这限制了知识的再利用和扩展性。", "innovation": "提出了CoOpt，一个高效的并行框架，用于协作优化无标签数据，从而有效地将知识编码到数据本身。该框架通过分布无标签数据并利用公开的任务无关模型，促进了可扩展、可再利用和可持续的训练管道。", "conclusion": "在各种数据集和架构上进行的大量实验表明，CoOpt的有效性和效率，分别在Tiny-ImageNet和ImageNet-1K数据集上实现了13.6%和6.8%的性能提升，训练速度分别提高了1.94倍和1.2倍。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16620", "html_url": "https://arxiv.org/abs/2505.16620", "title": "CausalDynamics: 大规模基准用于动态因果模型的结构发现", "title_en": "CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models", "authors": "Benjamin Herdeanu,Juan Nathaniel,Carla Roesch,Jatan Buch,Gregor Ramien,Johannes Haux,Pierre Gentine", "background": "在涉及无法进行主动干预的领域，对动态系统的因果发现构成重大挑战。现有的研究方法和基准主要针对确定性、低维和弱非线性时间序列数据，无法充分应对所有这些限制。", "innovation": "本文介绍了CausalDynamics，这是第一个大规模基准和可扩展的数据生成框架，旨在促进动态因果模型的结构发现。它包括来自数千个线性和非线性耦合常微分方程和随机微分方程的真实因果图，以及两个理想化的气候模型。研究全面评估了在噪音、混杂和滞后动力系统上最先进的因果发现算法的图形重建性能。框架具有模块化构造物理系统的功能，可促进稳健的适用于各个领域的因果发现算法的发展，并解决其特定挑战。", "conclusion": "我们提供了易于使用的实现和文档，以促进这一领域的发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17228", "html_url": "https://arxiv.org/abs/2505.17228", "title": "基础模型能力自动化评估", "title_en": "Automated Capability Evaluation of Foundation Models", "authors": "Arash Afkanpour,Omkar Dige,Fatemeh Tavakoli,Negin Baghbanzadeh,Farnaz Kohankhaki,Elham Dolatabadi", "background": "当前的基础模型评估框架主要依赖于静态的手工整理基准，这限制了它们对于模型能力全方面捕获的能力。", "innovation": "论文提出了Active learning for Capability Evaluation (ACE)框架，这是一个用于大规模、自动化和细致评估基础模型的新颖框架。ACE通过利用先进前沿模型嵌入的知识，将领域分解为语义上有意义的能力，并生成多样化的评估任务，显著减少了人力成本。", "conclusion": "ACE通过仅评估一部分能力而非全部能力，相比静态数据集提供更全面的覆盖率，并揭示了聚合指标无法捕捉的细粒度差异。研究结果表明，ACE能够为模型能力提供更加完整和有信息量的图景，这是基础模型安全和明智部署所必需的。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11128", "html_url": "https://arxiv.org/abs/2505.11128", "title": "您的扩散模型内部是什么？基于分数的黎曼度量以探索数据流形", "title_en": "What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold", "authors": "Simone Azeglio,Arianna Di Bernardo", "background": "最近在扩散模型方面的进展已经展示了它们在捕捉复杂图像分布方面的显著能力，但学习的数据流形的几何特性仍然缺乏理解。本文通过引入基于扩散模型的斯丁斯布朗函数的评分黎曼度量来解决这一问题，该方法利用评分函数来表征数据流形的内在几何，而无需显式参数化。这种方法能够在空间中定义度量张量，使垂直流形的距离变形，而沿着切向方向保持距离，从而创建一种自然沿着流形轮廓的度量几何结构。通过在合成数据、Rotated MNIST 和 使用 Stable Diffusion 的复杂自然图像上进行实验，结果表明，基于评分的度量能够捕捉有意义且符合数据分布变换的过渡。", "innovation": "本文通过引入基于评分函数计算的黎曼度量，提供了无需显式参数化的方法来表征数据流形的内在几何结构。该方法能够在空间中定义度量张量，使垂直流形的距离变形，而沿着切向方向保持距离，从而创建一种自然沿着流形轮廓的度量几何结构。本文开发了高效算法来计算这些度量，并展示了其在数据点间插值和分布外插值方面的用途。实验结果表明，基于评分的方法在感知度量（LPIPS）和分布度量（FID、KID）方面均优于基线方法，生成更平滑、更逼真的图像过渡，揭示了扩散模型隐含的几何结构并通过黎曼几何的视角导航自然图像流形的方法。", "conclusion": "通过合成数据、Rotated MNIST 和复杂自然图像等实验，本文结果表明基于评分的度量能够捕捉有意义的变换且符合数据分布。相比基线方法，本文方法在感知和分布度量上表现出更优秀的性能，产生了更平滑、更真实的图像过渡，表明了扩散模型中隐含的几何结构，并提供了一种通过黎曼几何视角导航自然图像流形的原理性方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16732", "html_url": "https://arxiv.org/abs/2505.16732", "title": "连续部分可观测量决策过程中的 Sequential Monte Carlo 策略优化", "title_en": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "authors": "Hany Abdulsamad,Sahel Iqbal,Simo Särkkä", "background": "在部分可观测的环境中，决策制定需要在减少不确定性（探索）和追求即时目标（利用）之间寻求平衡。现有的方法在解决这一挑战时，常常需要子优化近似或者手工构建的启发式方法，导致处理不确定性时表现不佳。这篇文章提出了一种新的连续部分可观测马尔可夫决策过程（POMDP）的策略优化框架，旨在解决这个问题。", "innovation": "文章介绍了一种新型的策略优化框架，该框架将策略学习视为非马尔可夫 Feynman--Kac 模型中的概率推断，以内在地捕捉信息收集的价值，无需使用子优化近似或手工构建的启发式方法。为了优化策略，文章开发了一种嵌套顺序蒙特卡洛（SMC）算法，能够在由 POMDP 引导的最佳轨迹分布的样本下有效地估计一个依赖于历史的策略梯度。", "conclusion": "在经典的连续 POMDP 标准基准测试中，这种新方法表现出了显著的效果，而现有的方法在应对不确定性时则难以正常工作。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12151", "html_url": "https://arxiv.org/abs/2505.12151", "title": "Large语言模型推理错误源于虚构关键问题特征", "title_en": "Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features", "authors": "Alex Heyman,Joel Zylberberg", "background": "近年来，通过强化学习训练的链式思考（CoT）策略，大语言模型在推理任务上取得了显著进展；然而，这些所谓的“推理大语言模型”（RLLMs）仍然不是完美的推理者。因此，理解它们的错误模式的频率及其原因对于用户和开发者都十分重要。本文作者将o1-mini、o3-mini、DeepSeek-R1、Claude 3.7 Sonnet、Gemini 2.5 Pro Preview和Grok 3 Mini Beta在变量复杂性约束满足逻辑问题（如图着色）上进行测试，发现证据表明RLLMs倾向于虚构超出提示范围的图边。这种现象在不同复杂度级别的问题中都存在，并且似乎能解释所有测试模型错误答案的大部分，甚至某些模型几乎全部错误答案。作者还在更小规模的实验中验证了该输入冲突的虚构现象在稳定匹配问题上的普适性。实验结果显示，RLLMs可能在表示问题特定信息方面存在更广泛的误解问题，论文提出了应对这一弱点的设计选择建议。", "innovation": "本文通过强化学习训练的RLLMs（推理大语言模型）在图着色这一变量复杂性约束满足逻辑问题上的测试，揭示了RLLMs存在虚构关键问题特征（即超出提示范围的图边）的现象，特别是在不同复杂度级别的问题上都存在这种现象。这些RLLMs的错误大部分是由于虚构了关键问题特征导致的，这对理解和改进大语言模型的实际应用具有重要意义。进一步的实验验证了此现象在其他类型问题中的普适性。此外，这些发现还为开发者提供了一些设计选择的建议，以减少此类问题的发生。", "conclusion": "本文通过详细分析RLLMs在图着色问题上的表现，发现了它们普遍存在的虚构关键问题特征的现象，并通过不同的问题场景验证了其普适性。提出了该类问题设计选择的建议，为后续改进大语言模型的推理准确性和鲁棒性提供了参考。研究表明，改进这类模型需要更加关注和精确地理解问题的具体细节，以减少模型的虚假推理。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23496", "html_url": "https://arxiv.org/abs/2505.23496", "title": "杂质多任务学习者在分布偏移时的先验错误", "title_en": "Epistemic Errors of Imperfect Multitask Learners When Distributions Shift", "authors": "Sabina J. Sloman,Michele Caprio,Samuel Kaski", "background": "不确定性感知的机器学习器，例如贝叶斯神经网络，输出的是不确定性量化的结果而不是单一的点预测。本文研究了可归因于可减少（先验）不确定性产生的错误，并在多任务学习和分布转移的大背景下提供了一个和完善的方法来界定和消除这些错误。", "innovation": "本文提供了一个原则性的先验错误定义，以及在多任务学习和分布转移背景下操作的分解性上界。这个界分原理上细化了多方面学习过程和环境对先验错误的贡献，并提供了针对贝叶斯迁移学习和ε-邻域中分布转移的特性化上界。此外，论文还利用界中的各项提供了一个新颖的负迁移定义。", "conclusion": "本文提供了一个新的框架来界定和消除多任务学习中可归因于可减少的先验不确定性产生的错误，并在多种应用场景下提供了实例。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21641", "html_url": "https://arxiv.org/abs/2505.21641", "title": "PrivATE：在($ε$,δ)-差异隐私下的平均治疗效果的差异化隐私置信区间", "title_en": "PrivATE: Differentially Private Confidence Intervals for Average Treatment Effects", "authors": "Maresa Schröder,Justin Hartenstein,Stefan Feuerriegel", "background": "平均治疗效果（ATE）被广泛用于评估药物和其他医疗干预措施的有效性。在如医学这样安全关键的应用中，对于ATE的可靠推断通常要求有效的不确定性量化，如置信区间（CIs）。然而，在这些设置中估计治疗效果往往涉及需要保持隐私的敏感数据。本文针对这种情况，提出了一种名为PrivATE的新型机器学习框架，用于在差异隐私下计算ATE的置信区间。", "innovation": "PrivATE框架包含三个步骤，从观察数据中获得有效且私有的ATE置信区间：(i)通过输出扰动估计不同的隐私ATE；(ii)以双重稳健的方式估计不同的隐私方差；(iii)在考虑到估计和私有化的不确定性后构建置信区间。该框架是模型无关的，双重稳健的，并确保有效置信区间。", "conclusion": "使用合成和真实世界医疗数据展示了该框架的有效性。据我们所知，这是首次为在($ε$,δ)-差异隐私下有效计算ATE的置信区间提供一个通用且双重稳健的框架。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18883", "html_url": "https://arxiv.org/abs/2505.18883", "title": "分区生成建模：无需遮罩的掩码建模", "title_en": "Partition Generative Modeling: Masked Modeling Without Masks", "authors": "Justin Deschenaux,Lan Tran,Caglar Gulcehre", "background": "Masked generative models (MGMs) 被广泛应用于捕获复杂数据，并通过并行解码加速生成过程，相比之下，自回归模型 (AR) 依靠顺序解码。然而，MGMs 只能在固定长度的输入上运行，导致早期采样阶段大部分遮掩的标记无法提供有用信息，造成计算资源浪费。而 AR 模型仅处理之前生成的标记，使早期迭代更快。", "innovation": "本文提出了分区生成模型 (PGM)，这是一种结合了 AR 和 MGM 优点的新方法。PGM 不使用遮掩，而是将标记划分为两组并使用稀疏注意机制阻断信息流。这样，模型在采样时仅处理之前生成的标记，同时能够并行生成标记且顺序可变。PGM 在 OpenWebText 数据集上提供了至少 5 倍的采样延迟和吞吐量改进，生成的样本具有更优的生成困惑度。在 ImageNet 上，PGM 的吞吐量比 MaskGIT 高 7.5 倍，FID 只有小幅提升。通过更多采样步骤，FID 降至 4.56，同时快于 MaskGIT 3.9 倍。PGM 还与 MGM 的精炼无缝集成，提供了进一步的推理加速。", "conclusion": "我们在 OpenWebText 和 ImageNet 上对 PGM 进行了评估，结果表明 PGM 在吞吐量、生成质量和推理速度上表现优异，同时证明了与 MGM 温和精炼的兼容性，为生成建模带来了广泛的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03355", "html_url": "https://arxiv.org/abs/2506.03355", "title": "CLIP在两个领域的鲁棒性：需要一个鲁棒的文本编码器", "title_en": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "authors": "Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher", "background": " adversarial input attacks can cause a significant shift of CLIP embeddings. This can affect the downstream robustness of models incorporating CLIP in the pipeline, such as text-to-image generative models or large vision language models. While some efforts have been done towards making the CLIP image encoders robust, the robustness of text encoders remains unexplored.", "innovation": "我们提出了LEAF：一种适用于文本域的高效对抗微调方法，可以扩展到大型CLIP模型。我们的模型显著改善了零样本对抗准确性，同时保持了由鲁棒图像编码器提供的视觉性能。当我们与文本到图像扩散模型结合时，可以在对抗噪声下提高生成质量。在多模态检索任务中，LEAF在对抗噪声下提高了标准CLIP模型的召回率。最后，我们展示了鲁棒的文本编码器能够通过直接优化更好地从其嵌入重构输入文本.", "conclusion": "我们证明了鲁棒的文本编码器能够通过直接优化更好地从其嵌入重构输入文本。我们开源了我们的代码 (this https URL) 和模型 (this https URL)。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04285", "html_url": "https://arxiv.org/abs/2506.04285", "title": "利用物理感知类脑网络实现无需训练的人工智能地球观测变化检测", "title_en": "Training-free AI for Earth Observation Change Detection using Physics Aware Neuromorphic Networks", "authors": "Stephen Smith,Cormac Purcell,Zdenka Kuncic", "background": "低地球轨道卫星的地球观测数据为决策者提供了管理如自然灾害这类时间敏感事件的重要信息。但是，为了使数据对现场救援人员最为有效，时效性极为关键，即从数据采集到决策者接收到数据之间需要低延迟。当前的一个主要瓶颈在于卫星到地面站的数据下行链路受到带宽限制。一种对策是在卫星上处理部分数据，并优先传输关键数据下行。", "innovation": "研究提出了一种物理感知类脑网络（PANN），用于从序列多光谱卫星图像中检测由自然灾害引起的变化，并生成变化图，从而使得优先数据的下行成为可能。PANN利用具有“记忆”的纳米电子电路元件组成（即“ memristors”，非线性具有记忆的电阻）构建物理神经网络，网络的权重动态变化并根据memristor方程和电气电路守恒定律更新。PANN产生的物理约束动力学输出特征被用于灾难检测任务，并通过基于距离的度量检测变化。这对资源受限的卫星上处理来说，是一个有前景的解决方案。", "conclusion": "PANN与最先进的AI模型进行了对标，并在每个自然灾害类别中均取得可比或更好的结果，证明了在资源受限条件下实现卫星上变化检测的潜在有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05059", "html_url": "https://arxiv.org/abs/2506.05059", "title": "NIMO:一个非线性可解释模型", "title_en": "NIMO: a Nonlinear Interpretable MOdel", "authors": "Shijian Xu,Marcello Massimo Negri,Volker Roth", "background": "深度学习在许多领域已经取得了显著的成功，但是同时也产生了对模型预测的可解释性的强烈需求。尽管已经提出了一些可解释的机器学习方法，但是事后解释往往缺乏保证的忠实性，并且对超参数的选择敏感，凸显了内置可解释性模型的吸引力。例如，线性回归通过其系数提供清晰的功能效果。然而，这样的模型通常被更复杂的神经网络所超越，而这些神经网络往往缺乏内置的可解释性。", "innovation": "NIMO框架结合了神经网络表达能力和内置的可解释性。基于简单的线性回归，NIMO能够提供灵活且可理解的功能效果。此外，论文开发了一种基于参数消除的优化方法，可以有效地且高效地优化神经网络参数和线性系数，并且可以通过自适应岭回归轻松地引入稀疏性。", "conclusion": "实验证明，NIMO模型能够提供忠实且可理解的功能效果，同时保持良好的预测性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24110", "html_url": "https://arxiv.org/abs/2505.24110", "title": "通过时间共享、深度展开的前馈网络构建非确定自动机的框架", "title_en": "A Constructive Framework for Nondeterministic Automata via Time-Shared, Depth-Unrolled Feedforward Networks", "authors": "Sahil Rajesh Dhayalkar", "background": "该研究提出了一种基于时间共享、深度展开的前馈网络（TS-FFNs）模拟非确定性有限自动机（NFAs）的框架。现有方法依赖显式的递归架构或事后提取方法，而本文通过符号编码自动机状态为二进制向量，转换为稀疏矩阵变换，非确定性分支（包括ε-闭包）作为共享阈值更新的组合，从而证明了任意正规语言都可通过此类共享参数的展开前馈网络准确识别，参数数量与输入长度无关。", "innovation": "本文创新性地使用时间共享、深度展开的前馈网络进行非确定性自动机的模拟，相对于之前的依赖于显式递归架构或事后提取方法，本文提出的方法直接符号编码自动机状态、转换和非确定性分支（包括ε-闭包），并通过共享参数的条件阈值更新进行组合，证明了任意正规语言都可以通过这种共享参数展开前馈网络准确识别，并且参数数量与输入长度无关。此外，通过梯度下降等训练方法，可以实现这些网络对目标自动机行为的恢复，特别是通过实验证明了这种学习能力是本文的关键创新点。", "conclusion": "本文通过理论证明和实验验证，说明了自动机理论与现代神经架构之间的对应关系，展示了展开前馈网络可以进行精确、可解释且可训练的符号计算。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13018", "html_url": "https://arxiv.org/abs/2506.13018", "title": "神经网络参数空间中的对称性", "title_en": "Symmetry in Neural Network Parameter Spaces", "authors": "Bo Zhao,Robin Walters,Rose Yu", "background": "现代深度学习模型具有高度的冗余参数配置，从而使得拥有相同输出的参数集合显著增大。这部分冗余可以用参数空间中的对称性来解释——那些使网络函数保持不变的变换。这些对称性影响了损失景观，并限定了学习动力学，提供了一种从优化、泛化和模型复杂性角度理解深度学习的新方法，补充了现有的理论研究。", "innovation": "这篇综述提供了对称性的概述，总结了现有文献，揭示了对称性与学习理论之间的联系，并指出了这一新兴领域中的空白和机会。", "conclusion": "通过对称性对神经网络参数空间的综述研究，可以更好地理解深度学习中的优化、泛化以及模型复杂性，并为该领域开拓新的研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14087", "html_url": "https://arxiv.org/abs/2506.14087", "title": "多尺度微调用于基于编码器的时间序列基础模型", "title_en": "Multi-Scale Finetuning for Encoder-based Time Series Foundation Models", "authors": "Zhongzheng Qiao,Chenghao Liu,Yiming Zhang,Ming Jin,Quang Pham,Qingsong Wen,P.N. Suganthan,Xudong Jiang,Savitha Ramasamy", "background": "时间序列基础模型（TSFMs）表现出在时间序列预测中的零样本性能。然而，如何有效地在特定下游任务上进行微调是一个未被充分探索的挑战。虽然朴素的微调可以带来性能提升，但这种方法往往未能充分利用TSFMs的能力，可能会导致过拟合和性能不佳。", "innovation": "作者通过因果分析方法，强调了在微调过程中显式建模多尺度的重要性，并提出了一个多尺度微调（MSFT）框架，该框架简单通用且将多尺度模型明确集成到微调过程中。实验结果表明，使用MSFT进行微调的TSFMs不仅优于朴素的和典型的参数高效微调方法，还超越了最先进的深度学习方法。", "conclusion": "基于编码器的时间序列基础模型使用MSFT进行微调，在不同骨干网络（Moirai、Moment和Units）上的实验结果表明，这种方法不仅提升了模型的性能，还表现出了更强的能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23800", "html_url": "https://arxiv.org/abs/2506.23800", "title": "向更深的预测编码神经网络的训练", "title_en": "Towards the Training of Deeper Predictive Coding Neural Networks", "authors": "Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori", "background": "预测编码网络是神经模型，通过迭代的能量最小化过程进行推理，其操作在时间和空间上都是局部的。尽管在浅层架构中效果显著，但在深层架构中会遭受显著的性能下降，主要发生在超过五到七层之后。", "innovation": "本论文展示了性能下降是由层间误差指数级不平衡和浅层预测对深层层更新的引导作用不足引起的。针对这些问题，分别提出了一种新的基于精度加权优化的潜变量优化方法，一种新的权重更新机制，以及通过辅助神经元来减缓残差连接中能量的传播速度。", "conclusion": "我们的方法在深度模型（如ResNets）上实现了性能与反向传播相当，为预测编码在网络复杂任务中的应用打开了新的可能性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17007", "html_url": "https://arxiv.org/abs/2506.17007", "title": "通过通用软操作和稳健强化学习实现离散组合生成", "title_en": "Discrete Compositional Generation via General Soft Operators and Robust Reinforcement Learning", "authors": "Marco Jiralerspong,Esther Derman,Danilo Vucetic,Nikolay Malkin,Bilun Sun,Tianyu Zhang,Pierre-Luc Bacon,Gauthier Gidel", "background": "科学发现的一个重大障碍是将指数级庞大的对象集（如蛋白质或分子）缩小为少量具有期望特性的高潜力候选对象。现有方法虽然依赖专家知识，但新型方法通过强化学习（RL）并由代理奖励函数引导，来实现这一筛选过程。这些方法通过使用多种形式的熵正则化手段，旨在学习能生成由代理函数高评分的多样化候选者的技术。然而，现有方法可能会生成过度多样且非最优的候选者，尤其是在大规模搜索空间中。这为本文提供了背景说明。", "innovation": "本文的两大创新贡献分别为：1）提出了一种新颖的一体化操作器，结合了几种正则化的RL操作，形成了一个更侧重于峰值采样分布的通用框架，解决了过度多样、非最优候选者的问题；2）提出了一个新颖的RL视角来解析这一筛选过程，提出了泛用平滑mellowmax算法（TGM），通过减少代理函数（即候选者的实际评估与代理评估之间的不同形式的不确定性）的敏感性，识别出更高质量的多样化候选者，验证了其在合成和真实任务中的有效性。", "conclusion": "本文提出的方法和算法，在合成和真实任务中均可更有效地生成高质量和多样性的候选对象，相对于基线方法提供了一种更优的选择。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14020", "html_url": "https://arxiv.org/abs/2506.14020", "title": "Bures-Wasserstein Flow Matching for Graph Generation", "title_en": "Bures-Wasserstein Flow Matching for Graph Generation", "authors": "Keyue Jiang,Jiahao Cui,Xiaowen Dong,Laura Toni", "background": "图生成任务由于其在药物发现和电路设计等领域的关键作用而逐渐成为研究热点。传统的扩散和流动模型通过构造一种插值路径，即在参考分布和数据分布之间建立概率路径，实现了较好的图生成性能。然而，这些方法通常独立地建模节点和边的演变，并利用线性插值构建路径，这种分离插值破坏了图之间的互联模式，使得构建的概率路径不规则且非光滑，从而导致训练动力学差和采样收敛问题。", "innovation": "本文首次提出了图生成模型中概率路径构建的一个基于理论框架。具体来说，本文通过使用马尔可夫随机场（MRF）参数化的连通系统来表示图，并利用MRF对象之间的最优传输位移来设计平滑的概率路径，确保图部件的共同演变。基于此，本文提出了一种名为BWFlow的流动匹配框架，利用所推导出的最优概率路径来优化训练和采样算法的设计。实验结果在普通图生成和分子生成中验证了BWFlow的有效性，显示出竞争力的性能、更好的训练收敛性和高效的采样效果。", "conclusion": "本文通过理论指导建立了图生成模型中概率路径的构建框架，利用最优传输位移机制设计了平滑的概率路径，从而提出BWFlow框架。实验结果表明，BWFlow在图生成任务中表现出强劲的性能，具备更优的训练收敛性和高效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22200", "html_url": "https://arxiv.org/abs/2506.22200", "title": "EFRame：通过探索-筛选-重放强化学习框架实现更深层次的推理", "title_en": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework", "authors": "Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yuzhi Zhang,Yue Wang", "background": "最近，强化学习（RL）在增强大型语言模型（LLMs）的推理能力方面取得了显著进步。虽然轻量级的组相对策略优化（GRPO）变体在效率上有提升，但其在探索范围有限和训练稳定性差的问题上依然存在限制，这限制了其在复杂推理任务中的有效性。本文旨在解决这些挑战。", "innovation": "本文提出了探索-筛选-重放（EFRame）框架，它通过三个维度增强策略优化：增加额外的采样以实现深入且有针对性的探索；在线筛选低质量样本以稳定梯度和加速训练；以及经验重放以强化稀有但信息丰富的轨迹，从而实现稳定收敛。该框架建立了一个平衡探索、效率和稳定性的原则性训练循环。实验结果显示，EFRame在多元推理基准上实现了持续的改进，相较于GRPO在Geometry3K上获得了37.9%的相对改进。EFRame还支持细粒度样本分类和精确熵控制，显示了其作为在LLMs中推进更深层次推理的稳健解决方案的能力。", "conclusion": "EFRame框架通过探索、筛选和重放机制，提供了平衡探索、效率和稳定性的训练循环，从而提高了LLMs在推理任务中的表现。通过实验进一步验证了该框架的有效性和抗干扰能力，在复杂推理任务上实现了显著提升。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03885", "html_url": "https://arxiv.org/abs/2507.03885", "title": "解开神经网络黑箱之谜：动态极值映射", "title_en": "Unraveling the Black Box of Neural Networks: A Dynamic Extremum Mapper", "authors": "Shengjian Chen", "background": "指出神经网络并非黑箱，它们的泛化能力来自于能够动态地将数据集映射到模型函数的极值上。进一步证明了神经网络中极值的数量与参数数量之间存在正相关关系，表明了神经网络结构特点理论基础的新观点", "innovation": "提出了一种与反向传播算法显著不同的新算法，主要通过求解线性方程组来获得参数值。这一框架可以简化一些困难情况，如梯度消失和过拟合问题的解释与处理", "conclusion": "研究指出了神经网络的动态极值映射机制及其实质，并提出了一种新颖算法，为理解神经网络的工作机制提供了新的视角。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01752", "html_url": "https://arxiv.org/abs/2507.01752", "title": "无窥探调优：LLM后训练的可证明隐私和泛化界", "title_en": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "authors": "Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud", "background": "深度学习通过反向传播提供高效的可扩展训练，但训练过程中梯度的暴露可能会泄露敏感数据信息，带来隐私和安全问题，如数据投毒攻击。黑盒优化方法，作为替代方案，在数据访问受限、对手风险高或过拟合的情况下，利用模型作为不透明函数的特性，仅依赖函数评估指导优化，提供了重要的选择。", "innovation": "本文提出了BBoxER，一种用于LLM后训练的进化黑盒方法，通过隐式压缩训练数据实现信息瓶颈。通过信息流的可行性，提供了可证明的差分隐私泛化界，以及数据投毒攻击和提取攻击的稳固保障。", "conclusion": "实验证明，尽管黑盒优化方法存在固有的可扩展性和计算挑战，但BBoxER仍能有效学习，迭代几次后提升性能，并在推理数据集基准上表现出良好的泛化能力，同时也对成员推断攻击具有鲁棒性。这使得BBoxER成为梯度优化方法的理想补充，适用于受限或隐私敏感环境，并提供非空泛化的泛化保障。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02925", "html_url": "https://arxiv.org/abs/2507.02925", "title": "大型语言模型代理用于药物发现中的模块化任务执行", "title_en": "Large Language Model Agent for Modular Task Execution in Drug Discovery", "authors": "Janghoon Ock,Radheesh Sharma Meda,Srivathsan Badrinarayanan,Neha S. Aluru,Achuth Chandrasekhar,Amir Barati Farimani", "background": "本文介绍了一种由大型语言模型（LLMs）驱动的模块化框架，该框架能够自动化并简化早期计算药物发现管道中的关键任务。通过结合LLMs推理和领域特定工具，该框架能够执行生物医学数据检索、领域特定问答、分子生成、性质预测、性质导向的分子优化以及3D蛋白质-配体结构生成。该研究在针对淋巴细胞性白血病靶向BCL-2的案例中，展示了其自主检索相关生物分子信息并回答机制性问题的能力，相较于标准LLMs，改进了上下文准确性。研究还产生了化学多样性种子分子，并预测了67种ADMET相关性质，指导了分子优化的迭代过程。", "innovation": "该模块化框架通过结合LLMs推理和领域特定工具，自动化执行药物发现流程中的多个阶段任务，包括生物医学数据检索、领域特定问答、分子生成、性质预测、性质导向的分子优化以及3D蛋白质-配体结构生成。案例研究表明，与常规LLMs相比，该框架在机制性问题上的上下文准确性有所提高，并能生成具有较高药效学性质的分子，同时加速了潜在药物候选配体的3D结构生成和结合亲和力预测。", "conclusion": "该方法的有效性体现在支持分子筛选、优先级排序以及结构评估方面。通过模块化设计，该框架能够灵活地集成不断演进的工具和模型，为AI辅助的治疗性发现提供可扩展的基础。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09683", "html_url": "https://arxiv.org/abs/2507.09683", "title": "通过机器学习实现网络化信息聚合", "title_en": "Networked Information Aggregation via Machine Learning", "authors": "Michael Kearns,Aaron Roth,Emily Ryu", "background": "本文研究了一个在有向无环图（DAG）中嵌入学习代理的分布式学习问题。每个代理只能直接观察一组特征，且这些代理会按照DAG的拓扑排序顺序逐步学习，并通过观察父母节点的预测值来训练自己的模型。", "innovation": "本文提出了信息聚合的概念，即在网络中某些代理能够学习到一个模型，该模型的误差能够在一定程度上与全局观察所有特征所能得到的最佳模型相当。作者给出了线性和一般假设类别的上下界，并识别出DAG的深度是关键参数。", "conclusion": "信息聚合现象可以发生于DAG的足够长路径上，前提是路径上包含了所有相关特征。然而，存在某些分布即使在长路径上也无法实现信息聚合。不仅如此，即使在网络规模很大且具有足够的深度情况下，也不能保证信息聚合发生，特别是那些只有中央节点汇集所有特征的拓扑结构。作者通过理论分析和大量实验对这一问题进行了全面探讨。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17131", "html_url": "https://arxiv.org/abs/2507.17131", "title": "通过循环指导实现自我提升代理在测试时学习", "title_en": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "authors": "Yufei He,Ruoyu Li,Alex Chen,Yue Liu,Yulin Chen,Yuan Sui,Cheng Chen,Yi Zhu,Luca Luo,Frank Yang,Bryan Hooi", "background": "大型语言模型（LLM）代理在规则和所需领域知识频繁变化的环境中（如合规性和用户风险筛查）常常表现不佳。当前的方法，如离线微调和标准提示，无法在实际操作中有效适应新的知识。", "innovation": "提出了自适应反思交互代理（ARIA），这是一种专门为测试时持续学习更新领域知识设计的LLM代理框架。ARIA 通过结构化的自我对话评估其不确定性，主动识别知识缺口，并向人类专家请求针对性的解释或更正。然后系统地更新内部时间戳知识库，并通过比较和澄清查询检测并解决冲突或过时的知识。", "conclusion": "ARIA 在 TikTok Pay 上真实的客户尽职调查名称筛查任务以及公开可用的动态知识任务中进行评估，结果表明与使用标准离线微调和现有自我提升代理的基线相比，ARIA 在适应性和准确性方面取得了显著改进。ARIA 已在 TikTok Pay 部署，为超过 1.5 亿月活跃用户提供服务，证明了其在快速发展环境中的实用性和有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02366", "html_url": "https://arxiv.org/abs/2508.02366", "title": "定量交易中由语言模型引导的强化学习", "title_en": "Language Model Guided Reinforcement Learning in Quantitative Trading", "authors": "Adam Darmanin,Vince Vella", "background": "算法交易需要短期战术决策与长期金融目标一致。强化学习（RL）已被应用于此类问题，但由于其短视行为和政策不透明性，采用程度有限。大型语言模型（LLMs）可以通过结构化的提示提供互补的战略推理和多模态信号解释。本文提出了一种混合框架，其中LLMs生成高层次的交易策略以引导RL代理。", "innovation": "提出了将LLMs与RL结合的混合框架，通过结构化提示引导LLMs生成高层次的交易策略，以改善RL代理的决策过程，尤其是在回测和实盘交易中的表现。通过实证分析评估了LLMs指导的策略的经济合理性以及与未指导的RL基线相比的表现（使用夏普比率SR和最大回撤MDD作为指标）。", "conclusion": "实证结果表明，LLMs指导下的策略在提升回报率和风险管理方面优于标准RL。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12399", "html_url": "https://arxiv.org/abs/2507.12399", "title": "ROC-n-reroll: 验证器不完美如何影响推理时的缩放", "title_en": "ROC-n-reroll: How verifier imperfection affects test-time scaling", "authors": "Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang", "background": "测试时缩放旨在通过在推理期间利用额外的计算资源来提高语言模型的性能。许多研究已经研究了诸如 Best-of-N (BoN) 和拒绝采样 (RS) 等技术，这些技术利用了验证器来实现测试时缩放。然而，目前对于验证器不完美性如何影响性能的理解还很少，这是本研究填补的空白。研究人员证明了这些方法的实例级准确度可以精确地由验证器的ROC曲线几何形状来表征。实验结果验证了理论预测，特别是在Qwen和LLama模型上处理GSM8K和MATH500任务时的结果。实验结果表明，固定计算资源下RS优于BoN，而在无限计算资源的情况下两者会达到相同的准确度。此外，基于低计算资源条件下的观察来预测高计算资源条件下的性能通常是不可能的。", "innovation": "证明了验证器的不完美性对于测试时缩放方法的影响可以通过验证器的ROC曲线几何形状来精确表征。该理论在Qwen和LLama模型上处理GSM8K和MATH500任务时得到了实验验证，表明RS在固定计算资源下优于BoN，而在无限计算资源的情况下两者会达到相同的准确度。此外，理论预测还表明，在低计算资源条件下的观察无法预测高计算资源条件下的性能。", "conclusion": "验证器的不完美性显著影响了测试时缩放方法的性能，固定计算资源下RS优于BoN，而在无限计算资源的情况下两者会达到相同的准确度。基于低计算资源条件下的观察无法预测高计算资源条件下的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20424", "html_url": "https://arxiv.org/abs/2507.20424", "title": "通信高效的分布式训练以实现深度学习中的协作平坦最优解恢复", "title_en": "Communication-Efficient Distributed Training for Collaborative Flat Optima Recovery in Deep Learning", "authors": "Tolga Dimlioglu,Anna Choromanska", "background": "本文研究了集中分布式数据并行训练深度神经网络（DNNs）的方法，旨在提高局部梯度方法在通信效率和模型性能之间的平衡。研究回顾了平坦谷底假设，即具有良好泛化能力的模型往往位于损失景观的平坦区域。文章通过引入简单的有效指标逆平均谷底，证明了其与DNNs的泛化差距强烈相关，并提出了一种轻量级正则化方法，鼓励工人共同寻求宽谷底。实验结果表明，DPPF方法优于其他通信高效方法，在保持通信效率的同时，优于局部梯度方法和同步梯度平均方法的泛化性能。此外，通过损失景观可视化，DPPF方法能够定位更平坦的谷底。理论上，DPPF方法指导工人跨越平坦的谷底，并在其最终谷底宽度由推和拉的力量相互作用控制的同时实现自我稳定化。并证明了其泛化保证与谷底宽度相关，在非凸设置中实现了收敛性保证。", "innovation": "引入了逆平均谷底指标作为通信高效的轻量级正则化方法，鼓励工作节点共同寻找宽谷底，提出DPPF算法，能够在保持通信效率的同时提高泛化性能，并通过损失景观可视化和理论分析验证了该方法的有效性。", "conclusion": "DPPF算法不仅在理论分析上证明了其有效的稳定性和泛化保证，提升了模型性能，还通过实验验证了其在分布训练中的通信效率与泛化性能的双重优势，最终位于更平坦的谷底中。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00047", "html_url": "https://arxiv.org/abs/2508.00047", "title": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection", "title_en": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection", "authors": "Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin", "background": "时间序列异常检测在多个应用领域中都起着核心作用。随着物联网（IoT）和智能制造的普及，时间序列数据的规模和维度都急剧增加。这种增长暴露了传统统计方法在处理这些数据的高度异质性和复杂性方面的局限性。基于近年来大型语言模型（LLMs）在语言和视觉多模态任务中的成功，本文提出了一种新颖的无监督异常检测框架——三分支块级大型语言模型框架用于时间序列异常检测（TriP-LLM）。", "innovation": "TriP-LLM采用三分支设计整合局部和全局时间特征，将输入时间序列编码为块级表征，然后通过冻结的预训练LLM处理这些表征。一个轻量级的块级解码器重建输入，从而派生出异常分数。在统一的开源框架中使用PATE（最近提出的无阈值评估度量）评估TriP-LLM在多个公开基准数据集上的性能，结果表明，TriP-LLM在所有数据集上都优于最近的SOTA方法，显示出强大的检测能力。此外，通过广泛的消融研究验证了LLM在整体架构中的实质性贡献，并且与使用通道独立性（CI）块处理的基于LLM的方法相比，TriP-LLM在内存消耗方面表现出显著的降低，使其更适合于受GPU内存限制的环境。", "conclusion": "实验结果显示，TriP-LLM在所有数据集上都优于最近的SOTA方法，展示了强大的异常检测能力。另外，TriP-LLM相比于基于LLM的使用通道独立性（CI）块处理的方法，具有显著的更低的内存消耗，更加适合GPU内存受限的环境。所有代码和模型检查点都已公开。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01774", "html_url": "https://arxiv.org/abs/2508.01774", "title": "VAGPO: 视觉增强非对称群体偏好优化方法在图路由问题中的应用", "title_en": "VAGPO: Vision-augmented Asymmetric Group Preference Optimization for Graph Routing Problems", "authors": "Shiyan Liu,Bohan Tan,Zhiguang Cao,Yan Jin", "background": "图路由问题在与网络相关的网络中起着至关重要的作用，找到图上的最优路径对于高效的数据传输和内容分发至关重要。经典的路由建模，如旅行商问题（TSP）和受限车辆路径问题（CVRP）代表了基本的图优化挑战。虽然最近的数据驱动优化方法取得了显著进展，但仍存在在训练效率和大规模实例上的推广性方面的局限性。", "innovation": "我们提出了一种新颖的视觉增强非对称群体偏好优化（VAGPO）方法，通过利用基于ResNet的空间编码和基于Transformer的序列建模来捕捉空间结构和时间依赖关系。此外，我们引入了一种非对称群体偏好优化策略，该策略与常用的策略梯度方法相比，能显著加速收敛。实验结果表明，提出的VAGPO方法在生成的TSP和CVRP实例以及真实世界的数据集上，能获得高度竞争力的解决方案。VAGPO在处理更大实例（多达1000个节点）时表现出强大的推广性，无需重新训练，这突出了其在学习效率和可扩展性方面的有效性。", "conclusion": "实验结果显示，所提出的VAGPO方法在生成的TSP和CVRP实例以及真实世界的数据集上，具有竞争力的解决方案质量，并且在无需重新训练的情况下，能够有效地处理更大规模的图路由问题，表明了在学习效率和可扩展性方面的优势。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03105", "html_url": "https://arxiv.org/abs/2508.03105", "title": "基于Lyapunov分析加速SGDM的策略：学习率和批次大小调度", "title_en": "Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov-Based Analysis", "authors": "Yuichi Kondo,Hideaki Iiduka", "background": "本文分析了在动态学习率和批次大小安排下随机梯度下降法的动量（SGDM）的收敛行为，引入了一个新型且更简单的Lyapunov函数，扩展了现存理论框架来涵盖在深度学习中常用的三种调度策略：固定批次大小伴随衰减的学习率、批次大小增加伴随衰减的学习率以及批次大小和学习率同时增加。", "innovation": "通过引入一个新型且更简单的Lyapunov函数，扩展了现有理论框架，分析了SGDM在三种常见调度策略下的行为；结果揭示出收敛性的等级结构，同时增加批次大小和学习率能够实现可以证明更快的衰减速度；实验结果表明，动态调度的SGDM在收敛速度上显著优于其固定超参数版本。", "conclusion": "动态调度的SGDM在收敛速度上显著优于其固定超参数版本，而预热调度在实验中观察到的性能优于其他所有策略。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01521", "html_url": "https://arxiv.org/abs/2508.01521", "title": "从心电图学习原型以创建精致的可解释数字表型", "title_en": "Prototype Learning to Create Refined Interpretable Digital Phenotypes from ECGs", "authors": "Sahil Sethi,David Chen,Michael C. Burkhart,Nipun Bhandari,Bashar Ramadan,Brett Beaulieu-Jones", "background": "原型为基础的神经网络通过将输入与训练数据中学习到的代表性信号模式进行比较，提供可解释的预测。尽管这类模型在生理数据分类领域表现出潜力，但尚不清楚它们的原型是否捕捉到与临床表型相关的基本结构。本研究采用一种基于原型的深度学习模型，该模型用于多标签ECG分类，然后在MIMIC-IV临床数据库中不进行修改地进行推理，以评估单独原型与临床结果的关联性，特别是通过一系列名为phecodes的出院诊断代码。研究结果表明，单独的原型相较于分类器的类别预测、从结构化文本中提取的概念或更广泛原型类别，表现出更强且更具体的关联性，并且一些混合显著性模式的原型类之间的组内距离显著增大，表明模型学会了区分诊断类别中的临床相关变异性。此外，原型表现出跨多种条件的强预测性能，从房颤的AUC 0.89到心力衰竭的AUC 0.91，同时也显示了非心脏疾病如败血症和肾病的重要信号。这些发现在于证明原型模型能够支持从生理时序数据中解释数字表型，提供转移性中间表型，可捕捉到临床意义的生理特征，超越了其最初的训练目标。", "innovation": "文章的创新之处在于利用一种基于原型的深度学习模型对心电图数据进行脱机分类，并在外部临床数据库中进行推理，以评估单独原型与出院诊断代码之间的关联性。此外，原型显示了强大的预测性能，不仅适用于心脏疾病，还适用于非心脏疾病，进一步证明了原型模型在生理时序数据中解释数字表型的能力。这些结果支持了原型模型可以提供转移性中间表型，从而捕捉到临床有意义的生理签名的观点，而非仅仅是用于原始训练目的。", "conclusion": "研究结果表明，原型能够在多变量条件下提供强大的预测性能，并且这些原型与多种临床结果（包括心脏和非心脏疾病）有显著关联。此研究不仅展示了原型为基础的方法在基于生理时间序列数据解析和传递临床标志的有效性，还表明了通过模型获得的原型可以提供一种高度可解释的数字表型，该表型可跨越不同疾病类别，捕捉到临床重要的生理特征。这些发现为进一步将基于原型的方法应用于其他生理数据提供了重要依据。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05118", "html_url": "https://arxiv.org/abs/2508.05118", "title": "通过探索进行推理：一种用于稳健函数调用的强化学习框架", "title_en": "Reasoning through Exploration: A Reinforcement Learning Framework for Robust Function Calling", "authors": "Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang", "background": "大型语言模型（LLMs）的有效训练在功能调用过程中面临一个关键挑战：平衡复杂推理路径的探索与稳定策略优化。标准方法如监督微调（SFT）无法培养坚实的推理能力，而传统的强化学习（RL）因其效率低下的探索方法而难以应对。", "innovation": "我们提出了一种新的RL框架EGPO（Entropy-Enhanced Group Relative Policy Optimization），该框架基于组相对策略优化（GRPO）直接解决上述挑战。EGPO的核心是一种增强熵的优势函数，将模型理解过程（CoT）的熵融入到策略梯度计算中，鼓励生成多样化的推理策略。通过一个剪辑机制谨慎约束熵奖励，EGPO结合严格二进制回报信号，有效地引导模型发现有结构和准确的工具调用模式。", "conclusion": "EGPO在Berkeley功能调用排行榜（BFCL）上得到了验证，4B参数模型使用EGPO训练，超越了包括GPT-4o和Gemini-2.5等一系列强大竞争对手，建立了该尺寸模型的新最佳水平。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06944", "html_url": "https://arxiv.org/abs/2508.06944", "title": "AMFT：通过元学习最优模仿与探索平衡来对齐语言模型推理器", "title_en": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance", "authors": "Lixuan He,Jie Feng,Yong Li", "background": "大型语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）的两阶段流程进行推理任务的微调，但这一过程存在灾难性遗忘和模仿与探索之间的次优权衡。尽管最近有一些单阶段方法试图通过启发式方法统一SFT和RL，但缺乏一个原理性的机制动态平衡这两种范式。", "innovation": "本文提出的创新之处在于，作者重新通过隐式奖励的理论视角来表述这一挑战，视SFT和RL为互补的奖励信号而不是独立的方法。引入了一种名为自适应元微调（AMFT）的新颖单阶段算法，该算法学习SFT隐式的路径级奖励和RL显式的结果基础奖励之间的最优平衡。AMFT的核心是一个元梯度自适应权重控制器，它将SFT-RL的平衡视为可学习的参数，动态优化以最大化长期任务性能。该前瞻性方法通过策略熵进行正则化，以确保稳定性，自动生成有效的训练课程。AB实验和训练动态分析验证了元学习控制器对于AMFT稳定性的关键作用。", "conclusion": "AMFT在数值推理、抽象视觉推理和视觉语言导航等具有挑战性的基准测试上一直能提供新的最先进性能，并且在分布外（OOD）任务上表现出更出色的泛化能力。证明了这种元学习控制器对于AMFT的稳定性、样本效率和性能的重要性，从而为LLM对齐提供了一个更具有原则性和有效性的范式。开源代码可通过这个链接获取：this https URL."}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量和梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为模型合并的一种简单而强大的技术已经出现，能够将多个微调模型合并为一个。尽管它在实践中取得了成功，但对其为何以及在何时有效仍缺乏清晰的理论解释。这篇论文通过建立任务向量与任务损失梯度之间的联系，提供了一个任务算术的严谨理论基础。", "innovation": "论文证明了在标准梯度下降中，来自一次微调周期的任务向量等同于损失的负梯度，乘以学习率。对于多周期的实用设置，论文证明了这种等效性近似成立，并给出了前向网络中的二次误差项的明确界限。具体实验分析在七个视觉基准上证实了理论，显示第一周期梯度在范数和方向上主导了微调轨迹。", "conclusion": "这些发现将任务算术重新定义为近似的多任务学习形式，为它为何有效提供了清晰的解释，并强调了早期训练动力学在模型合并中的关键作用。合并仅微调一轮的模型通常可以获得与完全收敛模型合并相当的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到X学习：通过随机行走打破去中心化障碍", "title_en": "From Federated Learning to X-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "文章提供了对X学习(XL)的理解，这是一种新颖的分布式学习架构，扩展了去中心化概念。作者旨在介绍XL的愿景，探讨其尚未探索的设计考虑和自由度。该研究揭示了XL与图论和马尔可夫链之间的直观但非平凡的关系。", "innovation": "文章介绍了一种新的分布式学习架构X学习，它扩展了去中心化概念，并探讨了其潜在的设计考虑和灵活性。此外，该研究还指出了XL与图论和马尔可夫链之间的关系，提供了新的研究方向。", "conclusion": "文章提出了让随机行走成为打破去中心化障碍突破口的概念，从而从联邦学习过渡到X学习，并指出了进一步研究的多个开放领域。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11408", "html_url": "https://arxiv.org/abs/2508.11408", "title": "On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting", "title_en": "On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting", "authors": "Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "大型语言模型（LLMs）在增强功能和行为对齐方面可以通过监督微调（SFT）和强化学习（RL）这两种主要的后训练范式来改进。现有的SFT和RL结合的方法可能会破坏已建立的响应模式并使模型过度拟合权威数据。因此，需要一种新的方法来统一SFT和RL，这种方法既能引导转移过程，又能从微调的数据中学到更多。此研究旨在通过一个准政策与在线政策的视角进行探索，提出了一个框架CHORD，该框架通过动态加权将SFT重新表述为在线RL过程中的一个辅助目标。", "innovation": "该研究提出了CHORD框架，通过动态加权整合准政策和在线政策的RL，将SFT重新定义为在线RL过程中的一个动态加权辅助目标，引入双重控制机制，引导从准政策模仿到在线探索的转变，同时在保持原有策略的同时学习专家数据的细节性内容，从而稳定和高效地学习过程。", "conclusion": "实验结果显示CHORD在数学推理问题和实际工具使用任务上不仅能够实现稳定的和高效的SFT和RL融合学习过程，而且在基准模型上显著提高了性能。该研究可以通过GitHub链接下载，以鼓舞进一步的研究工作。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19029", "html_url": "https://arxiv.org/abs/2508.19029", "title": "重新审视现代递归模型中的关联回忆", "title_en": "Revisiting associative recall in modern recurrent models", "authors": "Destiny Okpekpe,Antonio Orvieto", "background": "尽管现代递归深度学习模型，例如状态空间模型具有亚二次复杂度的优势，但近期研究表明，在推理和记忆任务上，它们的表现可能不如变换器。本文研究常规模型和变换器在关联回忆（AR）基准上的性能差异，AR与语言建模表现密切相关，进一步探讨了最近提出的分词混合策略所引起的影响，并发现学习率选择对现代递归模型表现出关键影响。", "innovation": "1. 研究表明学习率选择对现代递归模型表现至关重要，这可能严重影响之前研究中报道的性能，建议进一步研究以稳定训练。\n2. 探讨递归和基于注意的模型在宽度和深度扩展时表现出不同的优势，值得注意的是，单层的注意机制无法解决AR问题。\n3. 发现单层变换器的训练动态与之前仅在双层变体中观察到的归纳头形成过程类似。", "conclusion": "通过架构剖析，研究各组件如何影响Transformer和Mamba的性能和优化稳定性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02579", "html_url": "https://arxiv.org/abs/2509.02579", "title": "通过期望最大化在多智能体强化学习中进行潜在变量建模以实现基于无人机的野生动物保护", "title_en": "Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection", "authors": "Mazyar Taghavi,Rahman Farnoosh", "background": "保护濒危野生动物免受非法捕猎是一个严峻的挑战，特别是在广袤且部分不可观测的环境中，实时响应至关重要。在这样的背景下，论文提出了一种基于期望最大化(EM)的潜在变量模型方法，应用于多智能体强化学习（MARL）的无人机协调，以提高野生动植物保护中的探索与协调能力，从而在复杂的保护场景中提高决策的效率与准确性。", "innovation": "论文创新性地将EM模型应用于MARL框架中，利用潜在变量模型来模拟隐藏的环境因素和智能体间的动态关系，增强了在复杂环境中的探索和智能体间的协调能力。这种方法在实际场景中表现出比PPO和DDPG等标准算法更高的检测准确率、适应能力和策略收敛性，验证了EM与MARL结合在高风险、高复杂度保护任务中的潜力。", "conclusion": "实验结果证明了EM-MARL框架在隐蔽环境因素和智能体间动态关系建模方面的优越性，提高了无人机巡逻保护濒危野生动物的效果。未来的研究可能进一步探索提高系统鲁棒性和适应性的方法。整个实现、仿真环境和训练脚本在GitHub上公开，供他人参考和进一步研究。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17761", "html_url": "https://arxiv.org/abs/2508.17761", "title": "评估数据驱动回归模型（再）校准中量化不确定性的质量", "title_en": "Evaluating the Quality of the Quantified Uncertainty for (Re)Calibration of Data-Driven Regression Models", "authors": "Jelke Wibbeke,Nico Schönfisch,Sebastian Rohjans,Andreas Rauh", "background": "在关键安全应用中，数据驱动模型不仅要精确，还要提供可靠的不确定性估计，这种特性被称为‘校准’，是风险管理决策的关键。在回归分析中，已经出现了多种校准度量标准和校准方法，但它们在定义、假设和尺度上存在显著差异，导致难以解释和对比不同研究的结果。此外，大多数校准方法仅使用少数几个度量标准进行评估，这使得难以确定这些改进是否适用于不同类型的校准。本文系统地从文献中提取并分类了回归校准度量标准，独立于特定模型方法或校准方法进行基准测试。通过对实际、合成和人工再校准数据的受控实验，本文展示了校准度量标准经常产生矛盾结果。这一不一致性可能导致选择度量标准来制造成功印象的虚假观感。", "innovation": "本文系统地从文献中提取并分类了回归校准度量标准，独立于特定模型方法或校准方法进行基准测试。这项工作揭示了所有校准度量标准都不一致，许多度量标准对于相同再校准结果的评价不同，甚至有的表明相反结论。作者识别出 Expected Normalized Calibration Error (ENCE) 和 Coverage Width-based Criterion (CWC) 是最可靠的校准度量标准。", "conclusion": "本文发现了校准研究中度量标准选择的关键作用。研究结果强调了在评估不确定性校准质量时仔细选择度量标准的重要性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05117", "html_url": "https://arxiv.org/abs/2509.05117", "title": "HyPINO：基于HyperPINNs和制造解法的多物理神经算子", "title_en": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions", "authors": "Rafael Bischof,Michal Piovarči,Michael A. Kraus,Siddhartha Mishra,Bernd Bickel", "background": "该论文介绍了HyPINO，一种用于解决各类参量偏微分方程（PDEs）的多物理神经算子，无需特定任务的微调。它结合了基于Swin Transformer的超网络和混合监督，旨在实现零样本泛化能力。相比其他方法，HyPINO在多个基准问题上表现出更强的零样本准确性，尤其在基准文献中的七个问题上超越了U-Nets、Poseidon和物理信息神经算子（PINO）。此外，还提出了一种迭代优化方法，改进了生成的PINNs与所需PDE之间的物理一致性，从而逐步减小误差并显著提高精度。试验表明，使用HyPINO初始化的PINNs在五个基准问题上收敛速度更快且误差更低，表现与随机初始化和Reptile元学习初始化的PINNs相当。", "innovation": "HyPINO创新之处在于采用基于Swin Transformer的超网络架构，结合了有标签的制造解法（MMS）数据和无标签的优化样本，实现无需微调的任务泛化能力。此外，引入了一种迭代优化策略，生成“δ PINN”来改进物理一致性，形成了逐步减小错误并显著提高精度的集合理论。同时，HyPINO初始化的PINNs在多个基准问题上表现出更快的收敛速度和更低的最终误差值。", "conclusion": "HyPINO作为一种可扩展的方法，展现了解决复杂、非线性和高维PDE问题的潜在应用前景。通过公开代码和模型权重，验证了该方法的有效性和广泛适用性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05663", "html_url": "https://arxiv.org/abs/2509.05663", "title": "DQS：一种低成本查询策略以增强无监督数据驱动异常检测方法", "title_en": "DQS: A Low-Budget Query Strategy for Enhancing Unsupervised Data-driven Anomaly Detection Approaches", "authors": "Lucas Correia,Jan-Christoph Goos,Thomas Bäck,Anna V. Kononova", "background": "真正无监督的时序异常检测方法在文献中很少见。现有的方法往往因为阈值设定不合理而影响检测性能，还有些方法虽然声称无监督，实际上需要使用经过标签的数据子集进行校准，但这些标签数据在实际世界中往往不可用。这项研究将主动学习与现有的无监督异常检测方法相结合，通过选择性地查询多变量时序的标签来改进阈值选择过程。为此，引入了一种名为基于相异度的查询策略（DQS）的新查询策略。DQS旨在通过动态时间规整来评估异常评分的相似性，从而最大化查询样本的多样性。研究表明，DQS在预算有限的情况下表现最佳，但在面对误标时，其他策略则更为稳健。因此，在实际应用中，选择哪种查询策略取决于数据专家的水平以及他们愿意标记的样本数量。即使在遇到误标的情况下，所有的查询策略都优于无监督的阈值。因此，如果可以查询数据专家，采用基于主动学习的阈值是推荐的。", "innovation": "引入了一种基于相异度的查询策略（DQS），旨在最大化查询样本的多样性，通过动态时间规整来评估异常评分的相似性。这是一种新颖的无监督方法，结合了主动学习，能够在预算有限的情况下提高无监督数据驱动异常检测方法的性能，尤其是在面对误标的情况下。", "conclusion": "研究表明，DQS在预算有限的情况下性能最佳，而其他策略在面对误标时更为稳健。然而，在实际应用中，应根据数据专家的知识水平和他们愿意标记的样本数量来选择合适的查询策略。无论何时能够查询数据专家，推荐使用基于主动学习的阈值方法来改进异常检测性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15087", "html_url": "https://arxiv.org/abs/2509.15087", "title": "适配的LoRA专家分配与选择以实现联邦微调", "title_en": "Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning", "authors": "Lei Wang,Jieming Bian,Letian Zhang,Jie Xu", "background": "大语言模型（LLMs）在各种任务中展现了出色的性能，但将其细调用于特定领域应用时，通常需要大量的领域特定数据，这些数据可能分布在多个组织中。联邦学习（FL）提供了一种隐私保护的解决方案，但在应用于LLMs时面临计算约束的挑战。低秩适应（LoRA）作为一种参数高效的方法出现，但单个LoRA模块在处理不同领域的异质数据时表现不佳。现有方法未能很好地应对这些挑战。本文则针对于联邦环境下LoRA细调面临的关键挑战展开研究：一是确定跨异质客户端的最佳LoRA专家数量及其分配；二是根据具体数据特性使客户端适应性地利用专家。已有研究未解决这些问题，这正是本文提出的新框架和方法的机会所在。", "innovation": "本文提出的FedLEASE（Federated adaptive LoRA Expert Allocation and SElection）是一个新颖的框架，该框架基于表示相似性动态聚类客户端，以分配和训练领域特定的LoRA专家。同时引入了一个自适应的Top-$M$ Experts混合机制，允许各个客户端根据自身数据特性选择最合适的专家数量。相较于现有联邦细调方法，FedLEASE在异质客户端设置中显著提高了性能，同时保持了通信效率。", "conclusion": "本文提出的FedLEASE框架在多个基准数据集上的广泛实验证明了其在异质客户端设置中的显著优势，同时维持了通信效率。该工作展示了在联邦环境下使用LoRA细调的独特解决方案，有助于提高在数据分散且隐私受限条件下的模型性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16293", "html_url": "https://arxiv.org/abs/2509.16293", "title": "Robust LLM Training Infrastructure at ByteDance", "title_en": "Robust LLM Training Infrastructure at ByteDance", "authors": "Borui Wan,Gaohong Liu,Zuquan Song,Jun Wang,Yun Zhang,Guangming Sheng,Shuguang Wang,Houmin Wei,Chenyuan Wang,Weiqiang Lou,Xi Yang,Mofan Zhang,Kaihua Jiang,Cheng Ren,Xiaoyun Zhi,Menghan Yu,Zhe Nan,Zhuolin Zheng,Baoquan Zhong,Qinlong Wang,Huan Yu,Jinxin Chi,Wang Zhang,Yuhan Li,Zixian Du,Sida Zhao,Yongqiang Zhang,Jingzhe Tang,Zherui Liu,Chuan Wu,Yanghua Peng,Haibin Lin,Wencong Xiao,Xin Liu,Liang Xiang", "background": "随着大型语言模型（LLMs）的训练规模达到数万个GPU，并且仍在持续扩大，这使得模型能够更快地学习。然而，资源规模的扩大也带来了大量的故障（如CUDA错误、NaN值、作业挂起等），这对训练稳定性构成了重大挑战。因此，任何大规模LLM训练基础设施都需要最小化训练中断、高效的故障诊断和有效的故障容忍，以实现高效的持续训练。ByteRobust系统正是针对这一需求设计的。", "innovation": "ByteRobust是一个专为LLM训练设计的大规模GPU基础设施管理系统，它利用了LLM训练的独特性，优先检测和常规恢复故障。通过利用并行性和LLM训练的特点，ByteRobust实现了高容量的容错、快速的故障定位和本地化，都采用了一种有效的数据驱动方法，从而全面确保LLM任务的连续和高效训练。该系统部署在一个有超过20万个GPU的生产GPU平台上，并在9,600个GPU进行为期三个月的训练任务中实现了97%的ETTR（预计训练时间）", "conclusion": "ByteRobust不仅确保了大规模LLM训练的稳定性，还通过高效的故障诊断和处理策略，提高了训练效率。在实际生产环境中的部署和应用证明了该系统的效果。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16139", "html_url": "https://arxiv.org/abs/2509.16139", "title": "多场时空深度学习在介观结构介质中冲击传播的时空建模", "title_en": "Spatio-temporal, multi-field deep learning of shock propagation in meso-structured media", "authors": "M. Giselle Fernández-Godino,Meir H. Shachar,Kevin Korner,Jonathan L. Belof,Mukul Kumar,Jonathan Lind,William J. Schill", "background": "在行星防御和惯性聚变能源领域，预测震波穿越多孔和结构化材料的能力是一项关键挑战。尽管最近在单场和简化表示方面取得了一些进展，但捕捉孔洞坍塌、异常胡克尼响应和局部加热等现象——这些现象对小行星偏转或聚变点火有重大影响——仍然是一个主要挑战。", "innovation": "引入了一种多场时空模型（MSTM），将压力、密度、温度、能量、材料分布以及两个速度分量这七个耦合场统一到单一自回归替换模型中。MSTM通过高保真流体动力码数据进行训练，能够捕捉多孔和结构化配置下的非线性冲击驱动动力学，速度提高了三个数量级以上，且相对单场时空模型，将均方误差和结构性差异降低了94%。", "conclusion": "这项进步将之前认为无法解决的问题转化为可解决的设计研究，建立了在行星撞击缓解和惯性聚变能源中优化介观结构材料的实用框架。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21861", "html_url": "https://arxiv.org/abs/2509.21861", "title": "MolSpectLLM：一种连接光谱学、分子解析和三维结构生成的分子基础模型", "title_en": "MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation", "authors": "Shuaike Shen,Jiaqing Xie,Zhuo Yang,Antong Zhang,Shuzhou Sun,Ben Gao,Tianfan Fu,Biqing Qi,Yuqiang Li", "background": "近年来，分子基础模型在分子性质预测和从头分子设计方面取得了令人印象深刻的表现，特别是在药物发现和反应预测等领域具有前景。然而，大多数现有方法仅依赖于SMILES表示法，忽视了重要的实验光谱信息和三维结构信息，这限制了它们在涉及立体化学、空间构象和实验验证的任务中的有效性。", "innovation": "本文提出了MolSpectLLM，一种以Qwen2.5-7B为基础进行预训练的分子基础模型，能够结合实验光谱和分子三维结构。通过明确建模分子光谱，MolSpectLLM在光谱相关任务上达到了最先进的性能，平均准确率在NMR、IR和MS基准上为0.53。MolSpectLLM在光谱分析任务上也表现出色，序列准确率达到15.5%，标记准确率达到41.7%，显著优于大型通用LLM。更重要的是，MolSpectLLM不仅在分子解析任务上表现出强大的性能，还能直接从SMILES或光谱输入生成准确的三维分子结构，实现了光谱分析、分子解析和分子设计的融合。", "conclusion": "MolSpectLLM不仅在分子解析任务上表现出强大的性能，还在从光谱输入直接生成准确的三维分子结构方面取得了进展，实现了一种从光谱分析到分子设计的无缝结合。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24840", "html_url": "https://arxiv.org/abs/2509.24840", "title": "Cell2Text：从RNA测序数据生成单细胞描述的多模态LLM", "title_en": "Cell2Text: Multimodal LLM for Generating Single-Cell Descriptions from RNA-Seq Data", "authors": "Oussama Kharouiche,Aris Markogiannakis,Xiao Fei,Michail Chatzianastasis,Michalis Vazirgiannis", "background": "单细胞RNA测序重新定义了生物学领域的研究方式，提供了一种在细胞分辨率下测量基因表达的方法，为细胞类型、状态及疾病环境提供了信息。单细胞基础模型能够直接从表达谱中学习可移植的表示，提升了分类和聚类任务的性能，但这些模型仅限于离散预测头部，无法捕捉生物学家所需要的丰富上下文描述。", "innovation": "Cell2Text是一种多模态生成框架，能够将单细胞RNA测序（scRNA-seq）的谱型转换为有组织的自然语言描述。该框架通过将单细胞基础模型的基因级嵌入与预训练的大型语言模型相结合，生成连贯的总结，这些总结捕捉到细胞身份、组织起源、疾病关联和途径活性。Cell2Text在分类准确性上优于基线，并在本体一致性方面表现出强大的PageRank相似性度量，同时在文本生成中实现了高度的语义保真性。", "conclusion": "Cell2Text将表达数据与自然语言结合，不仅提供了更强的预测性能，而且提供了本征可解释输出，为未见细胞的标签高效表征指明了一条可扩展的路径。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23135", "html_url": "https://arxiv.org/abs/2509.23135", "title": "Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm", "title_en": "Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm", "authors": "Yang Chen,Menglin Zou,Jiaqi Zhang,Yitan Zhang,Junyi Yang,Gael Gendron,Libo Zhang,Jiamou Liu,Michael J. Witbrock", "background": "逆强化学习（IRL）通过对专家示范行为进行建模来学习奖励函数。现代IRL方法通常使用对抗（最小最大）形式化，通过交替奖励和策略优化来训练，但这种形式化常常导致训练不稳定。近期的非对抗性IRL方法通过能量方法同时学习奖励和策略，虽然提高了稳定性，但缺少形式上的保证。这项工作旨在解决这一问题，提出一个新的非对抗性方法，并提供了与前向强化学习中信任区域策略优化（TRPO）稳定性保证对应的IRL正式保证。", "innovation": "这项工作介绍了统一视角下的非对抗性方法，并基于此提出了Trust Region Reward Optimization (TRRO)框架。TRRO通过一个修复化最大化过程确保单调改进奖励的似然性。该工作进一步适配了PIRO（Proximal Inverse Reward Optimization），一个实际且稳定的IRL算法，该算法在MuJoCo和Gym-Robotics基准测试中以及真实世界的动物行为建模任务中展现了与最先进技术相匹敌或超越的表现，同时证实了IRL中的稳定性保证与TRPO在前向强化学习中的稳定性保证是一致的。", "conclusion": "PIRO是一种实用而稳定的IRL算法，通过TRRO框架，它保证了在优化奖励似然性过程中的单调改进，从而实现了在MuJoCo和Gym-Robotics基准测试中以及真实世界的动物行为建模任务中对奖励的恢复或策略模仿表现超越当前最先进的基线方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25289", "html_url": "https://arxiv.org/abs/2509.25289", "title": "ClustRecNet：一种新的端到端深度学习聚类算法推荐框架", "title_en": "ClustRecNet: A Novel End-to-End Deep Learning Framework for Clustering Algorithm Recommendation", "authors": "Mohammadreza Bakhtyari,Bogdan Mazoure,Renato Cordeiro de Amorim,Guillaume Rabusseau,Vladimir Makarenkov", "background": "聚类算法在无监督学习中是一个长期存在的挑战，选择合适的聚类算法对于获得良好的聚类结果至关重要。现有方法依赖手工设计的元特征和传统的聚类有效性指数（CVIs），这些方法在某些情况下并不能有效提高聚类性能。为了解决这一问题，本文作者构建了一个包含34,000个具有不同结构特性的合成数据集的全面数据仓库，每个数据集都使用了10种流行的聚类算法进行处理。通过调整rand索引（ARI）评估聚类结果，建立真实标签用于训练和评估深度学习模型。", "innovation": "本文提出了ClustRecNet，这是一种基于深度学习的推荐框架，用于确定给定数据集最适合的聚类算法。ClustRecNet不仅提高了聚类的整体性能，还集成了卷积、残差和注意力机制来捕获输入数据的局部和全局结构模式。这种方法支持端到端的训练，学习数据集的紧凑表示，并可以直接推荐最合适的聚类算法，减少对手工设计的元特征和传统CVIs的依赖。实验表明，ClustRecNet在合成数据和真实世界基准上的性能优于传统的CVIs和最先进的自动机器学习（AutoML）聚类推荐方法。特别是在合成数据上，相比于Calinski-Harabasz指数，ClustRecNet提高了0.497的ARI，而在真实世界数据上，ClustRecNet的ARI增益达到了15.3%。", "conclusion": "ClustRecNet是一个端到端的深度学习框架，能够准确推荐最适合的聚类算法，显著提高了聚类性能。此框架为聚类算法选择提供了一种新的解决方案，具有广阔的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03016", "html_url": "https://arxiv.org/abs/2510.03016", "title": "从模糊监督学习稳健的扩散模型", "title_en": "Learning Robust Diffusion Models from Imprecise Supervision", "authors": "Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang Shen,Masashi Sugiyama", "background": "近年来，条件扩散模型在各种生成任务中取得了显著成功，但其训练通常依赖于包含条件输入中不可避免的不精准信息的大规模数据集。这类监督信息往往源于噪声、模糊或不完整标签，会导致条件不匹配并降低生成质量。", "innovation": "本文提出了DMIS，一种从不精确监督中训练稳健扩散模型的统一框架，是首个在扩散模型领域进行系统研究的方法。该框架通过最大似然推导，并将目标分解为生成和分类部分：生成部分建模不精确标签分布，分类部分利用扩散分类器推断类别先验概率，并通过优化时间步长采样策略进一步提高效率。", "conclusion": "广泛的实验涵盖图像生成、弱监督学习和噪声数据集压缩任务，表明DMIS能够一致地生成高质量且类别区分度高的样本。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03243", "html_url": "https://arxiv.org/abs/2510.03243", "title": "具备提示感知的低延迟LLM服务调度", "title_en": "Prompt-Aware Scheduling for Low-Latency LLM Serving", "authors": "Yiheng Tao,Yihe Zhang,Matthew T. Dearing,Xin Wang,Yuping Fan,Zhiling Lan", "background": "高效的LLM推理任务调度对于实现低延迟和高吞吐量至关重要，特别是随着具有推理能力的LLM的广泛应用。传统的先到先服务（FCFS）策略经常遭受头部阻塞（HOL），即长时间运行的任务会延迟后面排队的较短任务。", "innovation": "本文介绍了PARS，这是一种提示感知的LLM任务调度器，通过成对排名和边际排名损失近似最短任务优先（SJF）调度，从而提高服务效率。PARS专注于关键的调度决策，并无缝集成到最先进的LLM服务系统vLLM中，可预测基于响应长度的任务排序，减少延迟且有最小的开销。大规模实验表明，PARS显著提高了包括推理工作负载在内的多种LLM和实际推理数据集的性能。", "conclusion": "我们的跨模型评估表明，该设计具有良好的泛化能力，即使预测器是在不同的LLM上训练的，也能实现有效的调度。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04020", "html_url": "https://arxiv.org/abs/2510.04020", "title": "基于生成世界模型的时空预报作为规划：一种基于模型的强化学习方法", "title_en": "Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models", "authors": "Hao Wu,Yuan Gao,Xingjian Shi,Shuaipeng Li,Fan Xu,Fan Zhang,Zhihong Zhu,Weiyan Wang,Xiao Luo,Kun Wang,Xian Wu,Xiaomeng Huang", "background": "现有时空预报方法面临两大挑战：内在的随机性以及非可微分度量，这些挑战降低了预报的精度和可靠性。", "innovation": "SFP提出了一种新的时空预报框架，基于模型的强化学习，通过构建生成世界模型来模拟多样性和高保真的未来状态，采用基于非可微分领域度量的‘想象导向’环境模拟，并通过迭代自我训练不断优化代理的策略，显著减少预测误差。", "conclusion": "SFP方法在关键领域指标上表现优异，特别是在捕捉极端事件方面，证明了其在时空预报中的优越性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01982", "html_url": "https://arxiv.org/abs/2510.01982", "title": "G$^2$RPO: Granular GRPO for Precise Reward in Flow Models", "title_en": "G$^2$RPO: Granular GRPO for Precise Reward in Flow Models", "authors": "Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai", "background": "近年来，将在线强化学习（RL）与扩散和流模型集成起来的方法开始成为一种有前途的方法，旨在使生成模型与人类偏好相匹配。通过使用随机微分方程（SDE）的随机采样来生成不同去噪方向，这种方法在去噪过程中得到应用，以支持强化学习的探索。现有的方法虽然能够有效探索潜在的高价值样本，但由于奖励信号稀疏且狭窄，导致偏好对齐效果不佳。", "innovation": "为解决上述挑战，本文提出了一种新颖的粒度级GRPO（G$^2$RPO）框架，用于精确和全面地评估流模型中采样方向的奖励。具体来说，引入了一种奇异随机采样策略，支持逐级的随机探索，并确保奖励与注入噪声的高度相关性，从而为每个SDE扰动提供更忠实的奖励。同时，为消除固定粒度去噪的固有偏差，引入了一个多粒度优势集成模块，该模块在多个扩散尺度上计算优势，从而对采样方向进行更全面和稳健的评估。", "conclusion": "我们在各种奖励模型上进行的实验，包括领域内外的评价，表明我们的G$^2$RPO显著优于现有的基于流的GRPO基准方法，突显了其有效性和稳健性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01521", "html_url": "https://arxiv.org/abs/2510.01521", "title": "CarbonX：使用时间序列基础模型的开源工具进行计算去碳化", "title_en": "CarbonX: An Open-Source Tool for Computational Decarbonization Using Time Series Foundation Models", "authors": "Diptyaroop Maji,Kang Yang,Prashant Shenoy,Ramesh K Sitaraman,Mani Srivastava", "background": "计算去碳化旨在减少计算和数据中心、交通、建筑环境等社会系统中的碳排放。这需要准确且精细的碳强度预测，但现有工具存在几个关键限制：(i) 需要特定电网的电力组合数据，限制了在数据不可用的情况下使用；(ii) 依赖于单独的电网特定模型，这使得提供全球覆盖变得具有挑战性；(iii) 不提供不确定性估计的预测，限制了下游碳感知应用的可靠性。", "innovation": "该论文提出了CarbonX，一种开源工具，利用时间序列基础模型（TSFMs）执行多种去碳化任务。CarbonX能够使用单一的通用模型和历史数据实现全球214个电网的零样本预测，MAPE为15.82%，并且在13个基准电网中，性能与当前最先进的技术相当，同时还能提供95%覆盖率的预测区间。此外，经过完全微调后，CarbonX在填补空白任务上的表现优于统计基线1.2至3.9倍，能为高达21天的预测提供良好的准确性，证明了CarbonX可以用于任何数据有限的电网且仍能提供强大的性能，成为一种适用于全球规模去碳化的实用工具。", "conclusion": "总体而言，这些结果表明，CarbonX可以在任何数据有限的电网中轻松使用，同时仍能提供强大的性能，使其成为用于全球规模去碳化的实用工具。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.26234", "html_url": "https://arxiv.org/abs/2509.26234", "title": "使用高斯过程方法在锂离子电池中检测锂金属沉积的机器学习方法", "title_en": "Machine Learning Detection of Lithium Plating in Lithium-ion Cells: A Gaussian Process Approach", "authors": "Ayush Patnaik,Jackson Fogelquist,Adam B Zufall,Stephen K Robinson,Xinfan Lin", "background": "锂离子电池在快速充电过程中出现的锂金属沉积是一个关键的退化机制，会加速容量衰减并可能引发灾难性安全问题。近期的研究发现，在4.0V以上的电压区间出现独特的dQ/dV峰可以作为锂金属沉积开始的可靠特征。然而，传统计算dQ/dV的方法依赖于带滤波的有限差分，这会放大传感器噪声并引入峰值位置的偏差。", "innovation": "本文提出了一个基于高斯过程(GP)的锂金属沉积检测框架，直接将充电-电压关系Q(V)建模为具有校准不确定性的随机过程。利用高斯过程的导数仍然是高斯过程的性质，该框架能够从后验概率中分析和概率推断dQ/dV，进而实现无需人工平滑的稳定检测。该框架提供了三项主要优势：一是噪声感知的推断，二是带有可信区间的形式导数以量化不确定性，三是适合嵌入式BMS的在线变体。", "conclusion": "通过实验，在不同倍率(0.2C-1C) 和温度(0-40°C)下对Li-ion纽扣电池的验证表明，该GP方法能够可靠地检测低温、高倍率充电下的沉积峰，并在基线情况下正确报告无峰。高斯过程探测到的差异峰值、降低的充放电速率和经过参考性能测试测量的容量衰减之间的共同现象证明了该方法的准确性和稳健性，为实时锂金属沉积检测开辟了实用路径。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03298", "html_url": "https://arxiv.org/abs/2510.03298", "title": "CAFL-L：利用拉格朗日对偶优化的设备感知联邦学习及其在设备端语言模型中的应用", "title_en": "CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual Optimization for On-Device Language Models", "authors": "Dongqi Zheng,Wenjin Fu", "background": "联邦学习（Federated Learning, FL）是一种在多个边缘设备上进行训练的技术，这些设备共享模型但不共享数据。然而，边缘设备往往受到资源（如内存、计算能力、通信带宽和能耗）的限制。传统的FL方法，如FedAvg，未能充分利用这些设备的资源限制，从而可能导致性能下降或资源浪费。为此，研究者们希望通过引入一种新的方法来解决这一问题，实现在这些资源受限的设备上进行有效的学习和优化。", "innovation": "提出了一种名为Constraint-Aware Federated Learning with Lagrangian Dual Optimization（CAFL-L）的方法。CAFL-L通过使用拉格朗日对偶优化动态调整训练超参数（如冻结深度、本地步骤、批量大小和通信压缩），同时通过梯度累积来保留训练稳定性。这种方法使得在资源受限的边缘设备上，能够更好地满足资源限制要求的同时保持良好的性能，进一步提高设备端语言模型的效果。", "conclusion": "通过实验证明，CAFL-L相较于标准FedAvg，在减少内存使用20%和通信95%使用的基础上，仍能维持与之相当的验证性能。这使得CAFL-L更适合部署在资源有限的边缘设备上。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02625", "html_url": "https://arxiv.org/abs/2510.02625", "title": "TabImpute：预训练变换器实现准确快速的零样本缺失数据填充", "title_en": "TabImpute: Accurate and Fast Zero-Shot Missing-Data Imputation with a Pre-Trained Transformer", "authors": "Jacob Feitelberg,Dwaipayan Saha,Kyuseong Choi,Zaid Ahmad,Anish Agarwal,Raaz Dwivedi", "background": "在表格数据中，缺失数据是一个普遍问题，现有解决方案包括简单的平均值填充到复杂的生成对抗网络。然而，由于在现实世界不同领域性能差异巨大且超参数调优耗时，尚未存在默认的缺失数据填补方法。TabPFN，一种用于监督学习的最新表格基础模型，被用来开发一种无训练及无需超参数调整的预训练变压器——TabImpute，用于填补缺失数据。为训练与评估TabImpute，引入了一种表格设置下的逐元素特征化方法，此前TabPFN方法的100倍速，同时引入一种合成训练数据生成流水线，带来更好测试时性能，并推出一个包含42个开放机器学习平台数据集和13种缺失模式的评估基准MissBench，展示不同领域的广泛覆盖，TabImpute相比已有11种方法具备稳健表现", "innovation": "提出了一种预训练变压器TabImpute，无需训练和超参数调整即可进行准确快速的缺失数据填补。通过逐元素特征化方法达到过去方法的100倍速度，并引入合成训练数据生成流水线和MissBench基准测试系统，提升了测试时性能和广泛覆盖多个领域的评价", "conclusion": "TabImpute为监督学习提供了一种准确快速的填补缺失数据的方法，无需训练或超参数优化。通过和现有数据集和缺失模式的全面基准测试MissBench，展示了其在不同领域的优越性和稳健性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03959", "html_url": "https://arxiv.org/abs/2510.03959", "title": "使用两阶段机器学习模型的雷暴引发的停电早期预警", "title_en": "Early-Warning of Thunderstorm-Driven Power Outages with a Two-Stage Machine Learning Model", "authors": "Iryna Stanishevska", "background": "雷暴引发的停电难以预测，因为大多数雷暴不造成损坏，对流过程快速而混乱，且可用的公共数据噪声大且不完整。该研究利用仅有的公开数据（EAGLE-I 作为地表真实信息；METAR 用于天气），开发了一个适用于密歇根地区夏季雷暴相关停电线性早预警模型。", "innovation": "模型采用了两阶段设计，结合逻辑门和LSTM回归器，保存稀疏气象站网络中的对流微信号，通过特异性克里金法和目标 overdrafting 保存极端现象，并构建了因果空间时间特征，捕捉剧烈对流的前兆。此外，模型使用了事件为中心的度量标准和峰值条件 MASE（cMASE），以表征精确的早期预警能力，并通过每小时移动块再抽样法量化不确定性。研究结果表明，该两阶段模型相对于基础模型表现出更少的误报和接近的误差，并指出了蒸散发、风速和 gust 作为重要特征。", "conclusion": "尽管公开数据存在噪声，特征驱动的流程能够提供有针对性的事件早期预警，适用于雷暴引发的停电情况。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04212", "html_url": "https://arxiv.org/abs/2510.04212", "title": "为什么低精度Transformer训练会失败：关于Flash Attention的分析", "title_en": "Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention", "authors": "Haiquan Qiu,Quanming Yao", "background": "追求计算效率推动了低精度格式在训练Transformer模型中的应用。然而，这往往被训练稳定性问题所阻碍。该论文提供了第一个对长期存在且未解决的低精度环境中使用闪注意力机制导致损失爆炸性崩溃的机制性解释。我们的深入分析表明，失败并非偶然，而是由两个交织的现象导致：注意力机制中相似低秩表示的出现和低精度算术中固有的偏置舍入误差的累积效应。这些因素共同作用导致错误累积加剧，篡改权重更新，最终破坏了训练动力学。", "innovation": "我们通过引入闪注意力机制的最小修改来缓解舍入误差的偏置，这一简单变更稳定了训练过程，验证了我们的分析，并提供了一个解决这个持续存在的问题的实用方法。", "conclusion": "研究表明，特定条件下的低精度和闪注意力机制组合可能导致训练崩溃。通过修正误差偏置，可以稳定训练过程。研究揭示了低精度环境下训练不稳定的深层次原因，并提出了实际的操作方法来解决该问题。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04217", "html_url": "https://arxiv.org/abs/2510.04217", "title": "MLLMEraser: 通过激活导向实现多模态大规模语言模型的测试时未学习", "title_en": "MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering", "authors": "Chenlu Ding,Jiancan Wu,Leheng Sheng,Fan Zhang,Yancheng Yuan,Xiang Wang,Xiangnan He", "background": "多模态大型语言模型（MLLMs）在视觉-语言任务中表现出显著的能力，但其大规模部署引发了对存储的私人数据、过时知识和有害内容的严重关切。现有的MLLM未学习方法通常基于训练策略，如梯度上升或偏好优化，但这些方法计算成本高昂、不可逆且常导致保留知识的失真。", "innovation": "本文提出了MLLMEraser，一种输入感知的、无需训练的框架，用于测试时未学习。该方法利用激活 steering 机制，通过对比对抗扰动的知识检索图像-文本配对与知识删除配对来动态擦除知识，同时设计一种输入感知的方向调节机制，以适应地确定何时以及如何应用擦除方向，保留保留知识的效用，同时强制遗忘指定内容。", "conclusion": "实验结果表明，MLLMEraser 在 LLaVA-1.5 和 Qwen-2.5-VL 上的一致性能优于最先进的 MLLM未学习基线，实现了更强的遗忘性能，并具有较低的计算成本和最小的应用效用折价。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04988", "html_url": "https://arxiv.org/abs/2510.04988", "title": "基于模型的数据增强动量优化框架下的自适应记忆动量", "title_en": "Adaptive Memory Momentum via a Model-Based Framework for Deep Learning Optimization", "authors": "Kristi Topollai,Anna Choromanska", "background": "现代大多数深度学习模型都是使用动量为基础的第一阶优化器进行训练的。动量项决定了优化器的记忆大小，从而影响过去的梯度对当前收敛方向的影响。无论是经典的Nesterov加速梯度或重球法，还是现代如AdamW和Lion这样的优化器，它们通常都会设置一个固定的动量系数$\beta = 0.9$并在整个训练过程中保持不变。然而，这种策略被认为并不是最优的。本文探讨了引入一种动态动量系数机制，以提高优化过程的效果。", "innovation": "本文提出了一种创新的自适应记忆机制，用以替代传统的固定动量。该机制通过在优化过程中动态调整动量系数来进行优化。这种方法通过近似目标函数来实现，并且这种方法是首次应用到动量优化中。该方法简单易用，不需要额外的假设或超参数调整。文章还展示了如何在不同学习任务中实现自适应记忆动量变异的SGD和AdamW，证明了该方法在手调动量系数的情况下可以超越标准的SGD和Adam。", "conclusion": "本文的工作开创了在优化中诱导自适应性的新途径。通过提出自适应记忆动量机制，实现了在广泛学习任务中的优异性能，为未来的深度学习优化提供了新的可能性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04547", "html_url": "https://arxiv.org/abs/2510.04547", "title": "视覺編碼器后训练量化需要前缀寄存器", "title_en": "Post-training quantization of vision encoders needs prefixing registers", "authors": "Seunghyeon Kim,Jinho Kim,Taesun Yeom,Wonpyo Park,Kyuyeun Kim,Jaeho Lee", "background": "基于Transformer的多模态视觉编码器，如CLIP，在智能代理、自动控制等应用中至关重要，但实时处理大量视觉数据的需求使得视觉编码器的推理成本显著增加。后训练量化是一种可行方法，但在8位精度下，由于大规模激活值（即异常值）的影响，实现起来仍具有挑战性。本文旨在探讨如何在不需要训练的情况下减少视觉编码器中的异常值，从而实现精确度损失较小的量化模型，特别是在文本监督和自监督两种类型的视觉编码器中。", "innovation": "本文引入了一种名为RegCache的训练免费算法，通过向目标视觉编码器引入可能产生异常值但没有实际语义意义的前缀标记，防止其他标记产生异常值。此外，研究发现视觉编码器中的异常值与语言模型中的异常值行为不同，因此提出了两个技术创新：中间层前缀化和标记删除。这些创新使得定量模型的准确性得到了明显提升，且在不同类型的视觉编码器中均表现出一致的改进效果。", "conclusion": "本文提出的RegCache算法能够在不进行训练的情况下显著减少视觉编码器中的异常值，从而实现小幅度精确度损失的量化，提升多模态应用的实际使用效果，特别是在文本监督和自监督两种类型的视觉编码器中均表现出了良好的泛化能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04888", "html_url": "https://arxiv.org/abs/2510.04888", "title": "揭示疾病之间的联系：从统计方法到大型语言模型", "title_en": "Revealing Interconnections between Diseases: from Statistical Methods to Large Language Models", "authors": "Alina Ermilova,Dmitrii Kornilov,Sofia Samoilova,Ekaterina Laptenkova,Anastasia Kolesnikova,Ekaterina Podplutova,Senotrusova Sofya,Maksim G. Sharaev", "background": "手动分析大规模临床数据以识别疾病之间的联系耗时、主观性强且专家之间容易产生分歧。机器学习（ML）显示出潜力，但仍面临三大挑战：一是选出合适的ML方法，二是决定是使用电子健康记录（EHRs）等现实世界临床数据还是结构化的疾病描述，三是缺乏“金标准”，因为仍有部分疾病联系未在医学领域中被探索。尽管大型语言模型（LLMs）具有广泛的应用前景，但它们往往缺乏专门的医学知识。为解决这些问题，本文系统性评估了七种方法来发现疾病联系，基于两种数据源：MIMIC-IV EHR中的ICD-10代码序列和完整ICD-10代码（带或不带文本描述）。", "innovation": "本文的创新之处在于，结合统计共现分析和掩码语言模型（MLM）使用真实临床数据的方法；利用领域特定的BERT变体（Med-BERT和BioClinicalBERT）；通用BERT模型和文档检索；以及四种LLM（Mistral、DeepSeek、Qwen和YandexGPT）。本文的图形比较显示，基于LLM的方法相较于其他方法（包括基于文本和领域的方法）产生的疾病联系的ICD代码连接多样性最低，这表明LLM在发现新联系方面具有有限的潜力。", "conclusion": "在缺乏ICD代码之间医学联系的“金标准”数据库的情况下，本文的结果构成了一个宝贵的医学疾病分类体系，可以作为未来临床研究和医疗健康领域的人工智能应用的基础资源。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04996", "html_url": "https://arxiv.org/abs/2510.04996", "title": "Reinforce-Ada: 一种针对增强学习风格的大型语言模型训练的自适应采样框架", "title_en": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training", "authors": "Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang", "background": "将强化学习应用于大型语言模型（LLMs）进行推理任务时，常常由于响应采样固定且均匀导致梯度估计不稳定。先前的工作，如GVM-RAFT，通过动态分配每个提示的推理预算来尽可能减少随机梯度方差。基于这一思想，该研究提出了一种自适应采样框架Reinforce-Ada，该框架在LLMs的在线训练后持续重新分配采样努力，优先选择不确定性或学习潜力最大的提示以稳定更新。Reinforce-Ada框架在估计和采样之间交替进行，且在网络逐步排除不必要的采样时自动停止。为了稳定更新，研究者将具有强制奖励多样性的固定大小的提示进行分组，并利用自适应采样阶段汇总的全局统计数据来计算优势基线。", "innovation": "Reinforce-Ada 提出了一种自适应采样框架，该框架在LLMs的在线训练后持续重新分配采样努力，优先选择不确定性或学习潜力最大的提示，并且在估计和采样之间交替进行，利用全局统计数据来计算优势基线。", "conclusion": "Reinforce-Ada 在多个模型架构和推理基准上的实验证明了它可以加速收敛并提高最终性能，尤其是在使用均衡采样变体的情况下比GRPO更优越。我们的研究强调了具有方差意识、自适应数据管理在实现高效可靠的推理能力语言模型的增强学习中的核心作用。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05901", "html_url": "https://arxiv.org/abs/2510.05901", "title": "混合线性注意力转换方法中组件失衡的解析", "title_en": "Untangling Component Imbalance in Hybrid Linear Attention Conversion Methods", "authors": "Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas", "background": "尽管Transformer模型表现出色，但它们的计算复杂性是二次的，限制了它们的扩展性。尽管线性注意力可将计算复杂度降至线性，但这种模型从头开始预训练仍然在大多数情况下过于昂贵。最近的研究提出了一些后训练线性化方法，可以在保持计算效率的同时将预训练的Transformer转换为线性模型，通常使用线性注意力与滑动窗口softmax相结合的混合方法实现。然而，现有方法存在关键缺陷：它们实际上并未充分利用线性组件，而是主要依赖滑动窗口softmax。这一问题在常见常识基准测试上的评估实践中未被注意到。", "innovation": "本文提出了三种确保组件平衡使用的方法：（i）推理时的线性仅转换与滑动窗口softmax的混合；（ii）结合注意力权重转移与目标LoRA微调的HedgeCATs；（iii）训练过程中的断点滑动窗口dropout（SSD），它在训练过程中通过随机抑制softmax支路来防止组件崩溃。这些方法在保持计算效率的同时，恢复了基模型的大部分性能，确保了线性注意力的真正采用，从而恢复了混合转换过程中性能归因的有效性。", "conclusion": "这些方法不仅在计算效率上保持了优势，同时也在很大程度上恢复了基模型的性能，确保了真正的线性注意力被采用，从而验证了混合转换过程中性能归因的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04237", "html_url": "https://arxiv.org/abs/2510.04237", "title": "基于球径向基函数的广义损失截断核随机梯度下降法", "title_en": "Truncated Kernel Stochastic Gradient Descent with General Losses and Spherical Radial Basis Functions", "authors": "Jinhui Bai,Andreas Christmann,Lei Shi", "background": "本文提出了一个针对大规模监督学习的一般损失的新颖核随机梯度下降（SGD）算法。与传统的核随机梯度下降相比，该算法通过创新的正则化策略提高了效率和可扩展性。利用球径向基函数的无穷级数展开，该策略将随机梯度投影到一个适应偏差-方差权衡的有限维假设空间，从而增强了泛化性能。基于核诱导协方差算子的光谱结构的新估计，本文发展了一个统一优化和泛化分析的理论框架。证明了最后一迭代和后缀平均均达到最小最大化率收敛，进一步在再生核希尔伯特空间中建立了最优强收敛性。该框架可以包容一系列经典的损失函数，包括最小二乘、Huber和逻辑回归损失。此外，所提算法通过结合线性SGD的坐标更新减少了计算复杂性和达到了最优存储复杂度，从而避免了核SGD中的昂贵的两两操作，并可以有效处理流式数据。", "innovation": "通过利用球径向基函数的无穷级数展开，将随机梯度投影到有限维空间，并适应地调整偏差-方差权衡，提高了算法的效率和可扩展性。提出了一个新的分析框架，统一了优化和泛化分析，并证明了算法在最小最大化率收敛和最优强收敛方面具有优势。算法能够兼容各种传统损失函数。通过引入坐标更新减少计算复杂度，并优化存储需求，使得处理大规模数据集更为高效。", "conclusion": "本文提出了一种新的核随机梯度下降算法，适用于大规模监督学习中的广义损失函数。通过严格的理论分析和广泛的数值实验，证明了算法在泛化性能、计算效率和存储需求方面的优势，展示了其在处理大型数据集时的有效性和效率。这种新颖的算法有望在大规模监督学习任务中实现更好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06955", "html_url": "https://arxiv.org/abs/2510.06955", "title": "高比率Mixout：重访用于鲁棒领域泛化的Mixout", "title_en": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Srikanth Muralidharan,Eric Granger,Marco Pedersoli", "background": "在分布迁移的情况下，通过使用从强大预训练权重初始化的微调模型组成的集成来增强模型稳健性是一种常见策略，但这种方法需要大量计算成本。Dropout作为一种轻量级替代方案，通过随机神经元失活模拟集成，但在应用于预训练模型时，往往会过强地正则化并破坏对泛化至关重要的关键表示。Mixout作为一种随机正则化技术，不采用神经元失活，而是在训练过程中通过概率性地用预训练权重替换微调权重来减轻过拟合，从而在适应性与保留先验知识之间取得平衡。研究表明，要在领域泛化基准测试中获得强劲表现，ViTs和ResNets的高掩码率分别为0.9和0.8。这种高比率掩码提高了预训练参数偏离的惩罚力度，促进对未见领域的更好泛化，并大幅减少了计算开销，最多可减少45%的梯度计算和90%的梯度内存使用。", "innovation": "High-rate Mixout是一种新的随机正则化技术，它通过在训练过程中概率性地用预训练权重替换微调权重来减轻过拟合，避免了传统Dropout对预训练模型的过强正则化。研究发现，通过提高掩码率，可以更有效地减少模型对预训练权重的偏离，同时显著降低计算成本，从而提升模型在领域泛化任务中的性能。这一方法在五个领域泛化基准测试中的表现接近于基于集成的方法，而训练成本显著降低。", "conclusion": "我们的实验结果显示，High-rate Mixout在五个领域泛化基准测试中能达到与基于集成方法相当的模型外域准确性，同时显著减少训练成本，实现更好的性能-成本平衡。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07919", "html_url": "https://arxiv.org/abs/2510.07919", "title": "GRADE: 通过组相对自适应狄利克雷探索增强学习实现个性化多任务融合", "title_en": "GRADE: Personalized Multi-Task Fusion via Group-relative Reinforcement Learning with Adaptive Dirichlet Exploration", "authors": "Tingfeng Hong,Pingye Ren,Xinlong Xiao,Chao Wang,Chenyi Lei,Wenwu Ou,Han Li", "background": "在现代推荐和搜索引擎系统中，实现用户满意度的关键是均衡多个目标。当前的多任务融合方法依赖于静态且需手动调整的权重，这些方法无法捕捉个别用户的意图。虽然强化学习为个性化提供了途径，但在大规模系统的传统方法往往因训练 instability 和稀疏奖励而失败。因此，需要一种新的、稳健的框架来解决这些问题，使多任务融合更加个性化和高效。", "innovation": "提出了GRADE，一种新颖且稳健的个性化多任务融合框架，利用组相对政策优化（GRPO）范式，通过评估候选权重群体的相对性能实现稳定和高效的策略学习。核心创新包括：使用狄利克雷分布进行有原则的权重空间探索，以及结合稀疏用户反馈、稠密模型先验和规则约束的复合奖励函数，有效引导搜索过程。", "conclusion": "在拥有数亿日活用户的应用的 App 市场上，GRADE 在严格的大型 A/B 测试中显著超越了传统基线，实现了显著的提升：点击率提高 0.595%，转化率提升 1.193%，营业利润提升 1.788%，以及总订单量增加 1.568%。此优异表现促使 GRADE 完全部署在 Kuaishou 的市场搜索场景中，以服务数亿用户。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08445", "html_url": "https://arxiv.org/abs/2510.08445", "title": "时间序列基础模型合成系列-符号数据生成", "title_en": "Synthetic Series-Symbol Data Generation for Time Series Foundation Models", "authors": "Wenxuan Wang,Kai Wu,Yujian Betterest Li,Dan Wang,Xiaoyu Zhang", "background": "时间序列分析（TSA）的基础模型已经引起了广泛关注，但训练数据的稀缺性和不平衡性一直阻碍着这些模型的发展。", "innovation": "这篇文章设计了一种系列-符号数据生成机制，可以生成高质量的时间序列数据及其对应的符号表达式，并开发了SymTime，这是一种用于增强时间序列表示的预训练基础模型，利用了强关联的系列-符号数据对。SymTime在五个主要的TSA任务上表现出色，且能与真实数据集预训练的基础模型竞争。", "conclusion": "这种方法强调了系列-符号数据生成和预训练机制在克服数据稀缺性和提升任务性能方面的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07922", "html_url": "https://arxiv.org/abs/2510.07922", "title": "SketchGuard：通过基于草图的筛选扩展具有抗拜占庭鲁棒性的去中心化联邦学习", "title_en": "SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening", "authors": "Murtaza Rangwala,Farag Azzedin,Richard O. Sinnott,Rajkumar Buyya", "background": "去中心化联邦学习（DFL）可实现隐私保护的协作训练而无需中央服务器。但它仍容易受到拜占庭攻击的影响，即恶意客户端提交损坏的模型更新。现有的拜占庭鲁棒DFL防御主要依赖于基于相似性的邻居筛选，要求每个客户端在每个训练轮次中与所有邻居交换和比较完整的高维模型向量，这带来了显著的通信和计算成本，阻碍了其在Web规模部署。", "innovation": "提出了SketchGuard框架，通过基于草图的邻居筛选解耦拜占庭筛选与模型聚合。利用Count Sketch对d维模型进行k维草图（k<<d）压缩，仅从接受的邻居中获取完整的模型，从而将每轮次的通信复杂度从O(d|Ni|)降低至O(k|Ni| + d|Si|)，其中|Ni|是邻居数量，|Si|≤|Ni|是接受的邻居数量。在强凸和非凸设置中建立了严格收敛保证，证明了Count Sketch压缩保留下了拜占庭鲁棒性，只有约(1+O(ε))的退化界限。实验结果表明，SketchGuard保持与最先进的方法相同的鲁棒性，同时将计算时间减少多达82%，通信开销减少50-70%，验证了草图压缩在大规模Web部署中的有效性。", "conclusion": "这些结果证明了草图压缩作为实现大规模Web环境下抗鲁棒DFL的基础功能的可行性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07985", "html_url": "https://arxiv.org/abs/2510.07985", "title": "更少的权重，更多的问题：LLM剪枝的实用攻击", "title_en": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "authors": "Kazuki Egashira,Robin Staab,Thibaud Gloaguen,Mark Vero,Martin Vechev", "background": "模型剪枝，即移除模型权重的一部分，已成为减少大规模语言模型（LLMs）推理时内存占用的重要方法。流行的推理引擎如vLLM允许用户在部署前方便地剪枝下载的模型。尽管剪枝方法的实用性和效率有了显著提高，但剪枝的安全影响仍鲜有研究。这项工作中，我们首次展示了现代LLM剪枝方法可被恶意利用。具体来说，攻击者可以构建一个看似无害的模型，但在剪枝后会表现出恶意行为。", "innovation": "该研究基于一种新的攻击方法：攻击者计算一个代理指标估计每个参数被剪枝的可能性。然后，攻击者将恶意行为注入那些不太可能被剪枝的参数中，再用可能被剪枝的参数修复模型，从而在未剪枝的模型中抵消注入的行为。通过在五个模型上进行广泛评估，该攻击方法在多种攻击场景中表现出强大的效果，成功率高达95.7%到99.5%，凸显了模型剪枝中存在的关键部署时间安全漏洞，并强调了迫切需要提高模型压缩的安全意识。", "conclusion": "该研究揭示了模型剪枝在部署时的安全隐患，强调了对模型剪枝过程中可能出现的安全威胁的迫切关注。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08382", "html_url": "https://arxiv.org/abs/2510.08382", "title": "刻画宽容的0-1损失函数的多分类可学习性", "title_en": "Characterizing the Multiclass Learnability of Forgiving 0-1 Loss Functions", "authors": "Jacob Trauger,Tyson Trauger,Ambuj Tewari", "background": "本文探讨了在有限标签多分类环境中宽容的0-1损失函数的可学习性。研究基于Natarajan维数的新组合维数，并证明假设类在这环境下的可学习性与其广义Natarajan维数有限性等价。同时，论文还探讨了与集合值反馈学习的联系，通过结果表明一个集合学习问题的可学习性由Natarajan维数刻画。", "innovation": "引入了基于Natarajan维数的新组合维数；证明了假设类的可学习性与其广义Natarajan维数有限性等价；探讨了宽容0-1损失函数的可学习性与集合值反馈学习之间的连接；通过结果展示了集合学习问题的可学习性由Natarajan维数划定", "conclusion": "论文通过引入广义Natarajan维数，刻画了一个多分类学习问题的可学习性，并证明了这个维数的有限性是可学习性的必要条件和充分条件。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08539", "html_url": "https://arxiv.org/abs/2510.08539", "title": "RLVR的优化动态：梯度差距和步长阈值", "title_en": "On the optimization dynamics of RLVR: Gradient gap and step size thresholds", "authors": "Joe Suk,Yaqi Duan", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 使用简单的二元反馈对大型语言模型进行了后训练，并取得了显著的实际成效。然而，其工作原理缺乏理论上的解释。本文通过分析RLVR在全响应（轨迹）和token层面上的训练过程，建立了一定的理论基础。核心在于一个叫梯度差距的量，它形式化地描述了从低奖励到高奖励空间里改进的方向。证明了收敛性高度依赖于更新方向与梯度差距的对齐。进一步推导出一个精确的步长阈值，与梯度差距的大小相关：在阈值之下，学习收敛；而超过阈值则导致性能崩溃。理论进一步预测关键步长如何随响应长度和成功率变化，解释了如长度归一化等实际技巧在提升稳定性方面的效果，并表明固定的学习率下成功率可能严格低于100%。通过受控的bernoulli模拟验证了这些预测。", "innovation": "建立了RLVR的理论基础，引入梯度差距的概念，证明了收敛性与梯度差距方向对齐的关系，推导了精确的步长阈值，解释了响应长度和成功率对步长的影响，并通过受控模拟验证理论预测效果。", "conclusion": "理论预测了关键步长应随响应长度和成功率变化，解释了实际技巧的机制，并通过模拟验证了这些预测。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08010", "html_url": "https://arxiv.org/abs/2510.08010", "title": "基于演化集合过程的局部PageRank计算加速方法", "title_en": "Accelerated Evolving Set Processes for Local PageRank Computation", "authors": "Binbin Huang,Luo Luo,Yanghua Xiao,Deqing Yang,Baojian Zhou", "background": "该文提出了一种基于嵌套演化集合过程的新型框架，用于加速个性化PageRank (PPR) 计算。局部精确逼近点迭代方法在每个处理阶段用于简化线性系统的求解，从而提高了计算效率和性能。该研究解决了现有文献中的一个开放猜测，并通过实验证明了该方法的有效性，特别是在早期阶段展示了显著的收敛性。", "innovation": "提出了一种基于嵌套演化集合过程的新框架，通过局部化和简化线性系统的方法在每个处理阶段求解PPR向量的近似值。该框架降低了时间复杂度，用$\tilde{\text{O}}(R^2/\text{ϵ}^2)$ 或$\tilde{\text{O}}(m)$ 衡量，并且只需要求解$\tilde{\text{O}}(1/\text{α}^{1/2})$个线性系统来获得$\text{ϵ}$-近似值，其中$\text{α}$是阻尼因子。当$1/{\text{ϵ}}^2 \text{<<} m$时，计算时间复杂度为$\tilde{\text{O}}(R^2 / (\text{α}^{1/2} \text{ϵ}^2))$，这与底层图的大小无关。这一结果解决了现有文献中的一个开放问题。", "conclusion": "实验证据验证了该方法的有效性和效率，尤其是在早期阶段展示了显著的收敛性。该研究结果解决了现有文献中的一个开放问题，并提供了有效和高效的PPR向量近似计算方法。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08150", "html_url": "https://arxiv.org/abs/2510.08150", "title": "通过组间不一致最小化实现域多样性下的无监督多源联邦领域适应", "title_en": "Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization", "authors": "Larissa Reichart,Cem Ata Baykara,Ali Burak Ünal,Harlin Lee,Mete Akgün", "background": "UMDA 的目标是通过利用多个多样化的源域中标注的数据来学习出能在未标注的目标域中泛化的模型。然而，现有的分布式 UMDA 方法通常假设源域的数量较少且未能有效扩展，当增加不同域的数量时，这些方法变得低效或稳定性较差，导致计算开销高或者性能不稳定。因此，本研究旨在提出一种适用于多种不同域的可扩展且鲁棒的联邦 UMDA 框架，以克服现有方法的局限性。", "innovation": "GALA 通过引入两个关键组成部分实现创新：（1）一种新颖的组间不一致最小化目标，能够高效地近似全对方式间域对齐，而无需进行二次计算；（2）一种温度调控的基于质心的加权策略，根据目标域对源域的对齐情况动态优先选择源域。这两个组件使得在大量不同源域上实现稳定且并行的训练成为可能。此外，研究还提出了一个包含 18 个不同数据集的 Digit-18 基准，用于评估高多样性场景下的性能，从而展示了 GALA 的优异性能。", "conclusion": "通过大量的实验证明，GALA 在标准基准上达到了竞争性的或最佳的性能，并且在多样化的多源场景中表现出色，远超之前的方法。这一研究提出的 GALA 框架提供了对于多源域适配问题的全新解决方案，具有广泛的应用前景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08549", "html_url": "https://arxiv.org/abs/2510.08549", "title": "熵正则化激活：通过激活约束提升连续控制、大型语言模型和图像分类", "title_en": "Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints", "authors": "Zilin Kang,Chonghua Liao,Tingqiang Xu,Huazhe Xu", "background": "该研究探讨了一种新的熵控制范式ERA，通过特别设计的激活函数约束模型输出的熵值。该方法在多种领域中表现出广泛的适用性：首先，针对大型语言模型（LLMs），ERA 提升 Qwen2.5-Math-7B 的 AIME 2025 评分 37.4%；其次，在连续控制强化学习代理上，ERA 超过强大的基准如 SAC，在 HumanoidBench 中超过 30%；最后，在图像分类中，ERA 提高了 ResNet-50 的 ImageNet top-1 准确率 0.69%。这些收益的实现以低于 7% 的计算开销为代价。这一研究验证了激活作为熵控制工具的有效性，开辟了一条设计更简单且更 robust 的算法的新途径", "innovation": "ERA 是一种新的熵约束范式，通过特定设计的激活函数控制模型输出的熵值，适用于多个领域的提升，包括大型语言模型、连续控制强化学习和图像分类。ERA 在这些不同领域的有效应用展示了通过激活函数控制熵的潜力。", "conclusion": "该研究验证了输出激活作为熵控制工具的有效性，并表明这种方法可以简化算法设计并提高跨领域的性能。ERA 的引入为设计更简单且更 robust 的算法提供了新方向。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2208.08067", "html_url": "https://arxiv.org/abs/2208.08067", "title": "K-ASTRO: 结构感知的LLM适应方法用于代码漏洞检测", "title_en": "K-ASTRO: Structure-Aware Adaptation of LLMs for Code Vulnerability Detection", "authors": "Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach", "background": "现有的代码漏洞检测方法往往依赖于资源密集型模型或图基技术，这限制了它们的访问性和实用性。大型语言模型（LLMs）正在变革软件工程任务，包括代码漏洞检测，这是软件安全的一个关键领域。", "innovation": "K-ASTRO 是一种轻量级的Transformer模型，将来自LLMs的语义嵌入与AST的结构特征结合起来，以提高代码漏洞检测的效率和准确性。该方法引入了基于AST的增强技术，灵感来自突变测试，引入了一种结构感知的注意力机制来结合增强AST特征，并且通过联合适应管道统一代码语义和语法。", "conclusion": "实验结果表明，K-ASTRO 在三个大规模数据集（BigVul、DiverseVul 和 PrimeVul）上表现出最先进的性能，同时在CPU上能够实现快速推理，并具有极短的训练时间。K-ASTRO 提供了一个可扩展、可解释且高效的解决方案，填补了LLM进展与实用软件漏洞检测之间的差距，还提供了开源工具以促进进一步的研究。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.19979", "html_url": "https://arxiv.org/abs/2403.19979", "title": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "title_en": "Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning", "authors": "Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang", "background": "连续学习（CIL）的目标是使模型能够不断学习新类目，同时克服灾难性遗忘。预训练模型引入了新的调参范式，进一步促进了CIL的发展。", "innovation": "本文重新审视参数高效调参（PET）方法在持续学习中的应用，观察到适配器调参优于基于提示的方法，即使在每次学习会话中不扩展参数。为此，提出了无需参数更新约束地增量调用共享适配器的方法，并通过从存储的原型中进行特征采样来重塑统一分类器，进一步提高其性能。还估计旧原型的语义变化，会话更新存储的原型，方法不增加模型大小，也不保留任何图像样本，显现出比之前基于预训练模型的CIL方法更好的效果，展示了出色的持续学习能力。在五个CIL基准测试中的实验结果证实了该方法的有效性，并达到了目前的最高水平（SOTA）。", "conclusion": "提出的适配器增量调参方法在多个CIL基准测试中表现优异，不仅克服了参数扩展的问题，而且避免了保留图像样本，显示出优秀的持续学习能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.04147", "html_url": "https://arxiv.org/abs/2405.04147", "title": "多项参数正则化与聚合在多项式函数回归中的应用", "title_en": "Multiparameter regularization and aggregation in the context of polynomial functional regression", "authors": "Elke R. Gizewski,Markus Holzleitner,Lukas Mayer-Suess,Sergiy Pereverzyev Jr.,Sergei V. Pereverzyev", "background": "最近的多项式函数回归研究成果主要集中在单参数正则化的深入探究上。相比之下，本研究突破了这种框架，引入了一个用于多参数正则化的算法，并提出了一种理论依据的方法来处理相关参数，使得能够聚合具有不同正则化参数的模型。", "innovation": "提出了一个多参数正则化的算法，以及一种基于理论的方法来处理相关参数，该方法促进了具有不同正则化参数的模型的聚合。有效的评估方法通过合成数据和一些实际医疗数据进行了验证，结果显示有很有前景的结果。", "conclusion": "通过评估表明，所提出的方法在合成数据和实际医疗数据上均显示出良好的效果，未来可以进一步应用于其他场景。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.11593", "html_url": "https://arxiv.org/abs/2306.11593", "title": "通过排名和基于LLM的融合提高图像描述的描述性", "title_en": "Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion", "authors": "Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano", "background": "当前最先进的（SoTA）图像描述模型通常在Microsoft Common Objects in Context (MS-COCO)数据集上进行训练，该数据集包含大约十词左右的经过人类标注的描述。尽管这些模型在通用场景理解方面非常有效，但这些短描述通常无法捕捉到复杂的场景和详细的描述信息，且模型往往会偏向于生成“平均”描述，这仅涵盖了更一般的方面，而忽略了细微的细节。因此，本文旨在通过结合不同的SoTA描述模型生成的描述来生成更丰富和更有信息量的图像描述。", "innovation": "本文提出了一个新的方法，通过预训练的不同SoTA描述模型生成的描述进行排名，然后使用一个新引入的基于图像-文本的指标（BLIPScore）对其进行排名，最后使用大型语言模型（LLM）融合前两描述，生成最终更详细的描述。实验结果表明，该方法在MS-COCO和Flickr30k测试集上的描述和图像匹配度以及幻觉减少方面效果显著，主观研究也支持这些结果，表明该模型生成的描述通常更符合人类判断。", "conclusion": "通过这种方法，不同SoTA模型的优势得以结合，提高了图像描述的质量和吸引力，填补了自动系统与人类生成描述的丰富信息之间的差距。这为训练视觉-语言和描述模型生成更合适的描述提供了可能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.14472", "html_url": "https://arxiv.org/abs/2405.14472", "title": "SolNet：全球光伏功率预测的开源深度学习模型", "title_en": "SolNet: Open-source deep learning models for photovoltaic power forecasting across the globe", "authors": "Joris Depoortere,Johan Driesen,Johan Suykens,Hussain Syed Kazmi", "background": "近年来，深度学习模型在光伏发电(光伏)预测领域逐渐受到关注，但这些模型需要大量的高质量数据才能很好地工作。这在实际应用中往往不可行，因为许多老旧系统缺乏良好的测量基础设施，同时全球范围内正在快速建立新的光伏系统。", "innovation": "本文提出了SolNet：一种新型、通用的多变量光伏发电预测器。SolNet通过结合从PVGIS生成的丰富合成数据的两步预测管道和观测数据的细化训练，解决了这些挑战。使用荷兰、澳大利亚和比利时数百个站点的实际生产数据，展示了在数据稀缺的情况下而非基准模型，SolNet提高了预测性能。", "conclusion": "我们的结果表明，当仅有有限的观测数据可用时，迁移学习的效果最佳。同时，我们还提供了多个迁移学习实践者应遵循的指南和注意事项。天气数据、季节模式、合成数据的数量以及源位置可能的错误建模等因素对结果有重大影响。SolNet模型适用于全球陆地光伏系统，通过将模拟和观测数据结合可以提高预测能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.19528", "html_url": "https://arxiv.org/abs/2411.19528", "title": "RAGDiffusion：通过外部知识吸收实现忠实服装生成", "title_en": "RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation", "authors": "Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni", "background": "标准服装资产生成涉及恢复展示在清晰背景上的正面平铺服装图像，其难点在于从复杂场景中提取服装信息时，面临高度标准化的结构取样分布和复杂场景中的服装语义缺失。现有的模型在空间感知上有限，常常在高规格生成任务中出现结构幻觉和纹理失真。", "innovation": "提出了一种新颖的检索增强生成（RAG）框架，称为RAGDiffusion，通过整合语言模型和外部数据库的知识来增强结构确定性和减轻幻觉。RAGDiffusion包括两个过程：（1）基于检索的结构聚合，运用对比学习和结构局部线性嵌入（SLLE）来推导全局结构和空间地标，提供软和硬的指导来对抗结构歧义；（2）全方位忠实服装生成，引入从粗到细的纹理对齐机制，确保扩散过程中的图案和细节元素的忠实性。", "conclusion": "在具有挑战性的现实世界数据集上进行的广泛实验表明，RAGDiffusion生成了结构和纹理忠实的服装资产，显示出性能提升，代表了在高规格忠实生成中使用RAG以应对内在幻觉和提升忠实度的研究先驱努力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15295", "html_url": "https://arxiv.org/abs/2411.15295", "title": "基于频率指导的后验采样在基于扩散模型的图像恢复中的应用", "title_en": "Frequency-Guided Posterior Sampling for Diffusion-Based Image Restoration", "authors": "Darshan Thaker,Abhishek Goyal,René Vidal", "background": "图像恢复旨在从退化观测中恢复高质量图像。当退化过程已知时，恢复问题可以被形式化为逆问题；在贝叶斯框架下，目标是给定退化观测得到一个干净的重建。近年来，现代预训练扩散模型被用于图像恢复，通过修改其采样过程来考虑退化过程。然而，这些方法通常依赖某些近似，可能会导致显著的错误和样本质量下降。", "innovation": "论文首次对线性逆问题中的近似误差进行了严格的分析，基于自然图像空间上的分布假设，表明了以往工作的失败案例。基于理论洞察，提出了一种对现有的基于扩散的图像恢复方法进行简单修改的方法。该方法在测量频域中引入了时间变化的低通滤波器，在恢复过程中逐渐增加更高的频率。根据潜在数据分布发展了一个适应性的课程计划。这种方法在包括运动去模糊和图像消雾在内的具有挑战性的图像恢复任务中显著提高了性能。", "conclusion": "通过引入时间变化的低通滤波器和基于数据分布的自适应课程，该研究提出的方法大幅提升了基于扩散模型的图像恢复任务的性能，特别是在对抗运动模糊和图像消雾等复杂任务上。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.02839", "html_url": "https://arxiv.org/abs/2408.02839", "title": "Mini-batch Estimation for Deep Cox Models: Statistical Foundations and Practical Guidance", "title_en": "Mini-batch Estimation for Deep Cox Models: Statistical Foundations and Practical Guidance", "authors": "Lang Zeng,Weijing Tang,Zhao Ren,Ying Ding", "background": "深度Cox神经网络（Cox-NN）通常使用随机梯度下降（SGD）算法通过更新模型参数优化，利用小批量数据进行更新。研究表明，SGD实际上是在优化小批量偏似然函数的平均值，而不是标准的偏似然函数。这样的差异需要发展新的统计理论，尤其是小批量最大偏似然估计量（mb-MPLE），来理解其全局优化特性。此前，对于Cox回归线性协变量效应的研究仅限于传统的最大偏似然估计量（MPLE）的统计性质，而小批量估计量的性质尚未有深入探讨，特别是在大规模实际应用中的表现。", "innovation": "论文的主要创新点在于：1）建立并证明了Cox-NN的mb-MPLE的一致性和最优的最小最大收敛速率。2）对于Cox回归具有线性协变量效应的情况，展示了mb-MPLE在多个采样点大小下的一致性和渐进正态性，其渐进方差随着采样点大小的增加而趋向于信息下界。3）提供了在实际应用中使用SGD的理论基础和技术指导，特别是揭示了学习率与批大小比率对SGD动态的至关重要的影响，为超参数调优提供了见解。4）确认了mb-MPLE在大规模实际应用中的有效性，尤其是在标准MPLE不可行的情况下。", "conclusion": "无论是在Cox-NN还是Cox回归中，mb-MPLE都展示了优异的统计性质和实际应用中的适用性。结论还指出，对于Cox-NN，SGD的动态行为高度依赖于学习率与批大小的比例；而Cox回归中，通过足够多的迭代可以确保全局优化器（mb-MPLE）的有效逼近。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.04784", "html_url": "https://arxiv.org/abs/2412.04784", "title": "NLP-ADBench: NLP Anomaly Detection Benchmark", "title_en": "NLP-ADBench: NLP Anomaly Detection Benchmark", "authors": "Yuangang Li,Jiaqi Li,Zhuo Xiao,Tiankai Yang,Yi Nian,Xiyang Hu,Yue Zhao", "background": "异常检测（AD）是机器学习中一个重要的任务，应用于欺诈检测、内容审核和用户行为分析等领域。然而，在自然语言处理（NLP）领域的研究相对较少，限制了其在检测有害内容、网络钓鱼尝试和垃圾评论的有效性。目前缺乏一个全面的NLP异常检测基准，用于评估不同算法的有效性以及数据集之间的差异性，这对于进一步的研究和模型优化至关重要。因此，研究人员需要一个综合的基准框架来推动NLP异常检测领域的发展。", "innovation": "本文介绍了NLP-ADBench，这是迄今为止最全面的NLP异常检测（NLP-AD）基准，包含八个精心筛选的数据集和19种最先进的算法，涵盖了端到端和两步法的算法。此外，相比专门设计的端到端方法，基于转换器的嵌入方法在两步法中表现更优，且OpenAI的嵌入表现优于BERT。该基准框架为NLP异常检测提供了统一的框架，并有望支持未来的研究和探索，具有重要的创新价值。", "conclusion": "我们的实验证明，没有单一模型能够在所有数据集中占主导地位，这表明需要自动化的模型选择方法。此外，基于转换器的两步法嵌入模型在性能上优于专门的端到端方法，而OpenAI的嵌入模型表现出更好的效果。我们发布了NLP-ADBench，为研究人员提供了一个统一框架来促进NLP异常检测相关的研究工作，从而推动该领域的进一步发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08221", "html_url": "https://arxiv.org/abs/2412.08221", "title": "生成任何场景：基于场景图的数据合成方法用于视觉生成训练", "title_en": "Generate Any Scene: Scene Graph Driven Data Synthesis for Visual Generation Training", "authors": "Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna", "background": "文本到视觉生成在视觉保真度方面取得了进展，但在合成泛化和语义对齐方面仍然存在挑战。现有数据集噪声较大且缺乏组成性，限制了模型对复杂场景的理解，而用于密集、高质量标注的可扩展解决方案也面临着挑战。", "innovation": "引入了一种名为Generate Any Scene的数据生成引擎，系统性地枚举表示可能视觉场景的场景图。Generate Any Scene能够动态构建从结构化对象、属性和关系分类中变化复杂性的场景图，并将其转换为用于文本到图像或视频生成的说明，或转换为视觉答案问题集，以便自动评估和学习模型的语义对齐。利用生成的数据设计了一系列自我提高的框架、一种分布式算法将特定优势从专有模型转移到开源模型，以及一种低成本的奖励模型，以促进对语义准确性的模型生成。最后，将这些概念应用到内容审核这一下游任务中，通过学习合成数据训练模型以识别更具挑战性的案例。", "conclusion": "使用这些技术，研究人员在视觉生成的合成和复杂概念生成任务上取得了显著进步，特别是在模型对齐语义准确性、自我改进和专有模型与开源模型的技能转移方面。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17122", "html_url": "https://arxiv.org/abs/2501.17122", "title": "两种时间尺度梯度下降上升动力学的收敛性：有限维和均场视角", "title_en": "Convergence of two-timescale gradient descent ascent dynamics: finite-dimensional and mean-field perspectives", "authors": "Jing An,Jianfeng Lu", "background": "两时间尺度梯度下降上升（GDA）算法是设计用于在最小最大游戏中寻找纳什均衡的经典梯度算法。研究发现，通过学习率比例的影响探讨了两种时间尺度GDA的收敛行为，特别是在有限维和均场设置下的表现。对于有限维的二次最小最大问题，采用超收敛性方法分析了长时间收敛行为。对于均场GDA动力学，研究了有界条件下收敛性，并采用混合同步反射耦合技术进行探讨和分析.", "innovation": "本研究创新性地采用超收敛性方法分析了有限维度二次最小最大问题长时间收敛行为，并采用混合同步反射耦合技术探讨均场GDA动力学下的收敛性.", "conclusion": "在两种时间尺度GDA的有限维度和均场视角下，通过超收敛性方法和混合同步反射耦合技术得到了长期收敛性能的分析结果，提出了不同的条件下的收敛行为分析方法."}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08604", "html_url": "https://arxiv.org/abs/2412.08604", "title": "LLM增强生成检索中的偏好辨识", "title_en": "Preference Discerning with LLM-Enhanced Generative Retrieval", "authors": "Fabian Paischer,Liu Yang,Linfeng Liu,Shuai Shao,Kaveh Hassani,Jiacheng Li,Ricky Chen,Zhang Gabriel Li,Xiaoli Gao,Wei Shao,Xue Feng,Nima Noorshams,Sem Park,Bo Long,Hamid Eghbalzadeh", "background": "在序列推荐中，模型基于用户的历史交互信息推荐项目。当前模型为了做出推荐，通常会整合项目描述和用户意图或偏好信息。然而，开源数据集中用户的偏好往往并未明确给出，因此需要通过其他方法估算，例如使用大型语言模型（LLMs）。现有方法仅在训练时利用估算的用户偏好，并依靠过去的交互历史进行推荐，这种方式限制了模型适应用户偏好变化的能力，可能加剧了回音室效应的问题。", "innovation": "本文提出了一种新的范式，即偏好辨识，该范式在推荐模型自然语境中显式地调整其推荐策略以用户自然语言描述的偏好为基础。为了评估偏好辨识的有效性，作者设计了一个新的基准，涵盖了偏好引导和情感跟随等不同场景。在基准测试中，现有的最先进方法未能有效适应用户偏好的变化。为此，本文提出了一种名为Mender的方法，该方法在我们的基准测试中实现了最佳性能。Mender能够在未知偏好信息的情况下，通过用户的偏好进行有效的推荐，为更加灵活的推荐模型提供了可能。", "conclusion": "Mender方法在偏好辨识方面表现出色，能够根据用户的偏好进行推荐，即使在训练过程中未观察到这些偏好信息。这表明Mender为推荐系统的适应性和灵活性开辟了新途径。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11060", "html_url": "https://arxiv.org/abs/2412.11060", "title": "在平衡数据集中使偏置放大具有方向性和可解释性", "title_en": "Making Bias Amplification in Balanced Datasets Directional and Interpretable", "authors": "Bhanu Tokas,Rahul Nair,Hannah Kerner", "background": "目前使用的大多数机器学习数据集都带有偏见，当我们在这些偏见数据集上训练模型时，模型不仅学习数据集中的偏见，还可能放大这些偏见。虽然已经提出了若干基于共现的指标来衡量保护属性A（如性别）和任务T（如烹饪）之间的偏见放大，但这些指标在保护属性A与任务T平衡时无法衡量偏见。近期工作提出了一个基于可预测性的度量指标，称为泄露放大，用于测量平衡数据集中的偏见放大。然而，泄露放大不能识别偏见放大的方向。", "innovation": "本文提出了一个新的基于可预测性的度量指标，称为方向性可预测性放大（DPA），用于测量平衡数据集中的方向性偏见放大。DPA比泄露放大更容易解释，并且对攻击者的模型（可预测性度量中的一个超参数）不太敏感。实验结果表明，DPA是一个有效的方向性偏见放大的度量指标。", "conclusion": "我们展示了DPA在表格数据集和图像数据集中的有效性，该度量指标能够有效测量方向性偏见放大。相关代码不久将发布。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01860", "html_url": "https://arxiv.org/abs/2502.01860", "title": "SWE-Arena: 一个评估软件工程中基础模型的互动平台", "title_en": "SWE-Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering", "authors": "Zhimin Zhao", "background": "基础模型（FMs），尤其是大规模语言模型（LLMs），在软件工程（SE）任务中表现出显著的潜力，包括代码生成、调试和需求精炼。然而，现有的评估框架不足以评估模型在SE活动中迭代、上下文丰富的流程中的性能。SWE-Arena平台旨在解决这一局限性，提供一个交互式的平台来评估SE任务中的FMs。", "innovation": "SWE-Arena引入了新颖的评估机制和工具，如模型一致性分数和对话效率指数，这些都可以帮助更加全面地评估FMs的性能，并且通过集成新的RepoChat功能，增强了与真实软件开发流程的相关性。", "conclusion": "本文概述了SWE-Arena的设计和功能，强调了其在促进FMs在软件工程中的评估和实际应用方面具有潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.06394", "html_url": "https://arxiv.org/abs/2503.06394", "title": "如何实现双语能力：使用稀疏自编码器追踪内部表示", "title_en": "How a Bilingual LM Becomes Bilingual: Tracing Internal Representations with Sparse Autoencoders", "authors": "Tatsuro Inaba,Go Kamoda,Kentaro Inui,Masaru Isonuma,Yusuke Miyao,Yohei Oseki,Benjamin Heinzerling,Yu Takagi", "background": "该研究探讨了双语语言模型如何发展出复杂的内部表示。通过使用稀疏自编码器，该研究聚焦于训练步骤、层数和模型大小对内部表示的影响。研究表明，语言模型首先学习单独的语言，然后逐渐形成双语对齐，特别是在中间层中。较大的模型表现出更强的双语倾向。这项研究提供了一种新方法，将完全训练后的模型分解表示融入到训练过程中的模型中，揭示了双语表示在模型性能中的关键作用。这些发现加深了对语言模型如何获取双语能力的理解。", "innovation": "使用稀疏自编码器分析双语语言模型的内部表示，并结合分解表示，展示了在模型训练过程中双语表示对模型性能的重要性。该研究强调了中间层在双语对齐过程中的关键作用，并发现较大的模型具有更强的双语倾向。", "conclusion": "研究表明语言模型首先学习单独语言，然后在中间层逐渐形成双语对齐。这一过程对于模型的双语能力至关重要，并且较大的模型显示出更强的双语效果。这些发现提供了理解和增强语言模型双语能力的新见解。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06485", "html_url": "https://arxiv.org/abs/2502.06485", "title": "WyckoffDiff —— 一种用于晶体对称性的生成扩散模型", "title_en": "WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry", "authors": "Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten", "background": "结晶材料通常表现出高对称性。然而，大多数生成模型不考虑这些对称性，而是将每个原子看作是独立的，不受位置或元素限制。这项研究提出了一种新的生成模型Wyckoff Diff (WyckoffDiff)，该模型能够生成基于对称性的晶体描述。通过考虑一个嵌入了全部对称性的晶体结构表示方法，再加上设计的新型神经网络架构，该模型能够接入离散生成模型框架。此外，该模型的离散性质使其能够快速生成。", "innovation": "提出了Wyckoff Diff (WyckoffDiff) 生成模型，该模型通过考虑晶体结构表示中嵌入的所有对称性，并设计了新型神经网络架构，使得能够将对称性考虑进去，同时利用离散生成模型框架提高生成速度。还提出了一个新度量标准Fréchet Wrenformer Distance，用于评估材料的对称性方面。与最近提出的晶体生成生成模型进行了基准测试，展示了基于对称性的生成结果。", "conclusion": "通过使用WyckoffDiff，研究人员能够在保持对称性的前提下快速生成晶体，并且能够在概念验证研究中找到新的材料，这些材料位于热力学稳定性凸壳之下。该研究通过引入一种全新的方法和度量标准，为晶体对称性的生成提供了新的可能性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07742", "html_url": "https://arxiv.org/abs/2504.07742", "title": "基于梯度选择样本以加速贝叶斯优化", "title_en": "Gradient-based Sample Selection for Faster Bayesian Optimization", "authors": "Qiyu Wei,Haowei Wang,Zirui Cao,Songhao Wang,Richard Allmendinger,Mauricio A Álvarez", "background": "贝叶斯优化（BO）是一种有效的黑盒优化技术，但由于高斯过程（GP）代理模型拟合的三次复杂性，其适用性通常仅限于中等预算问题。在大规模预算场景下，直接采用标准的GP模型会面临显著的计算时间和资源需求问题。", "innovation": "提出了一种新的方法，基于梯度的样本选择贝叶斯优化（GSSBO），以提高BO的计算效率。该方法通过对选定样本集构建GP模型，而不仅仅是整个数据集。这些样本通过利用梯度信息进行选择，以减少冗余并保持多样性和代表性。提供了基于梯度的样本选择策略的理论分析，并获得了针对所提出框架的显式次线性后悔界。", "conclusion": "在合成和实际任务上的大量实验表明，该方法显著降低了GP拟合的成本，同时保持了与基线方法相当的优化性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08610", "html_url": "https://arxiv.org/abs/2503.08610", "title": "三维统计系统中的分层自回归神经网络", "title_en": "Hierarchical autoregressive neural networks in three-dimensional statistical system", "authors": "Piotr Białas,Vaibhav Chahar,Piotr Korcyl,Tomasz Stebel,Mateusz Winiarski,Dawid Zapolski", "background": "近期，自回归神经网络（ANN）被提出用以提高蒙特卡洛算法在多个自旋系统中的效率。这些算法基于状态配置的概率可以分解为每个自旋的条件概率，而这些条件概率可以被神经网络近似。这样训练好的ANN可以用于从近似概率分布中抽样配置，并且能够显式地评估给定配置的概率。已有研究表明，这些条件概率还提供了信息论观测量如互信息或纠缠熵的信息。本文在三维空间中描述了分层自回归网络（HAN）算法，并使用三维自旋格的居里模型作为案例研究，探讨了其性能。此外，还与三种其他自回归架构以及经典的沃尔夫集群算法进行了比较，最后提供了三维居里模型在相变范围内热力学观测量的估计，包括熵和自由能的估计值。", "innovation": "引入了三维空间中的分层自回归网络（HAN）算法，并与四种不同的自回归架构和传统的沃尔夫集群算法进行了对比，提供了一种改进蒙特卡洛算法效率的新方法，特别是在处理复杂三维自旋系统时。研究还进一步展示了通过自回归网络可能揭示的热力学信息，如熵和自由能的估计值，以及它们在相变区域的分布。", "conclusion": "本研究通过三维居里模型验证了分层自回归网络（HAN）算法的有效性，表明HAN算法相比其他方法具有更高的效率和准确性，并能提供更为详细的热力学特性估计。为更好地理解和处理三维自旋系统提供了新视角。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.11101", "html_url": "https://arxiv.org/abs/2503.11101", "title": "自我监督对比学习在多模态图文分析中的综述", "title_en": "A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis", "authors": "Asifullah Khan,Laiba Asmatullah,Anza Malik,Shahzaib Khan,Hamna Asif", "background": "自我监督学习是一种无需人工标记数据即可生成隐含标签的机器学习方法，通过学习潜在模式和从无标签数据中提取判别特征。对比学习通过引入‘正样本’和‘负样本’的概念，将具有相似性的样本（例如同一图像/物体的不同变体）拉近，将不相似的样本（例如不同图像/物体的视角）推远，这种方法在无标签数据依赖较少的情况下显著提高了图像理解和图文分析的能力。", "innovation": "本文全面讨论了对比学习术语、最近的发展和在图文模型中的应用。具体来说，概述了近年来在图文模型中使用的对比学习方法，按不同的模型结构进行了分类，并介绍了在这一过程中使用的最新技术，如用于图像和文本的预训练任务、架构结构以及关键趋势。", "conclusion": "本文还讨论了自监督对比学习图文模型的最新应用，展示出该技术在多样化的图文任务中的广泛适用性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.19114", "html_url": "https://arxiv.org/abs/2503.19114", "title": "理解并改进LLMs中提示压缩中的信息保留", "title_en": "Understanding and Improving Information Preservation in Prompt Compression for LLMs", "authors": "Weronika Łajewska,Momchil Hardalov,Laura Aina,Neha Anna John,Hang Su,Lluís Màrquez", "background": "最近的大语言模型（LLMs）取得了显著进展，但在信息密集的任务中，提示长度快速增长，导致计算需求增加、性能下降以及因无关或重复信息产生的偏差。为了优化输入长度减少与性能保留之间的权衡，最近引入了各种提示压缩技术。尽管已有一定的压缩方法，但它们在保留关键细节方面的表现不尽如人意，这限制了它们在复杂任务中的表现。", "innovation": "本文提出了一种全面的评估框架，用于深入了解提示压缩方法，重点关注压缩比、下游任务性能、输入上下文关联性和信息保留这四个关键方面。通过对比分析最先进的软压缩和硬压缩方法，研究表明一些方法未能有效保留原始提示的关键细节，从而限制了复杂任务的性能。此外，本文改进了一种软提示方法，通过控制压缩粒度提升了下游任务的性能，以及信息保留，从而达到更高的压缩效率和更好的信息保存效果。", "conclusion": "我们发现，结合软提示方法与序列级别压缩可以获得最佳的有效性/压缩率权衡。未来的研究可以通过进一步优化压缩策略来提升信息保存和模型性能。相关代码可以在此处获取：https://github.com/example/research-code"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02261", "html_url": "https://arxiv.org/abs/2506.02261", "title": "LLM在序列推荐中的有效性背后的因素：基于偏好强度和时间上下文的研究", "title_en": "What Makes LLMs Effective Sequential Recommenders? A Study on Preference Intensity and Temporal Context", "authors": "Zhongyu Ouyang,Qianlong Wen,Chunhui Zhang,Yanfang Ye,Soroush Vosoughi", "background": "序列推荐系统旨在通过对用户交互历史的理解来画像，模拟人类基于经验、偏好强度和情境相关性来做决策的方式。然而，现有的基于大语言模型（LLM）的推荐系统往往无法模仿人类灵活且具备情境感知的决策策略，忽视了人类行为中结构化、动态和情境感知机制的重要性。", "innovation": "本文提出了RecPO，这是一种偏好优化框架，通过建模结构反馈和情境延迟来模拟人类在序列推荐中的优先级，使得模型倾向于立即相关的项目，同时区别不同层次的偏好和厌恶。实验结果表明，RecPO不仅超越了最先进的基线方法，还反映了人类决策的关键特征：及时满足、保持一致的偏好和在变化情境下表现判断力。", "conclusion": "通过实验验证，RecPO框架不仅在序列推荐任务上取得了性能上的提升，还能捕捉到人类决策的关键特性：及时满足需求、维持一致的偏好和在情境变化下展现出判断力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17312", "html_url": "https://arxiv.org/abs/2505.17312", "title": "AdaReasoner: 自适应推理使大型语言模型具有更灵活的思考能力", "title_en": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models", "authors": "Xiangqi Wang,Yue Huang,Yanbo Wang,Xiaonan Luo,Kehan Guo,Yujun Zhou,Xiangliang Zhang", "background": "当前的语言模型（LLMs）在处理需要复杂推理和问题解决的任务时，如笑话生成和数学推理，通常需要有效的配置，如温度和推理步骤等。现有的提示方法大多采用通用的、固定的配置，在多种任务中表现尚可，但很少能够实现特定任务的最佳表现。这篇论文探讨了这一问题，并提出了解决方案。", "innovation": "本文提出了一种名为AdaReasoner的LLM无关插件，用于任何LLM自动化适应推理的配置。AdaReasoner利用强化学习（RL）框架进行训练，结合分解动作空间、有目标的探索策略和预训练奖励模型。通过少量示例引导，AdaReasoner优化了解释配置。理论和实验结果表明，AdaReasoner具有快速收敛和线性政策差距的保证。在不同的LLM和各种推理任务中，AdaReasoner的表现优于标准基线，并保持了离散分布的稳健性，特别是在知识密集型任务中通过定制提示实现了性能提升。", "conclusion": "AdaReasoner通过自适应推理提高了大型语言模型的灵活性，能够在各种任务中实现更好的表现。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09666", "html_url": "https://arxiv.org/abs/2505.09666", "title": "使用元学习的系统提示优化", "title_en": "System Prompt Optimization with Meta-Learning", "authors": "Yumin Choi,Jinheon Baek,Sung Ju Hwang", "background": "大型语言模型（LLMs）展现了显著的能力，优化输入提示对于提高其性能至关重要。现有工作主要集中在针对特定查询或任务的用户提示优化上，而较少关注系统提示的优化。系统提示一旦优化，即可在不同任务和领域中通用。然而，现有的优化工作尚未充分利用系统提示的通用性和预见性，因此需要探索一种新的优化方法来提升系统提示的适应性和通用性，使其能够应对各种用户提示并适用于未见任务。", "innovation": "本文提出了一个新的双层系统提示优化问题，其目标是设计出能够抵抗多样用户提示并适用于未见任务的系统提示。为此，本文采用了元学习框架来优化系统提示，并通过多数据集中的迭代更新用户提示以确保两者间的协同作用。这种方法展示了在多元用户提示下系统提示的有效泛化性能，并显著提高了未见任务的快速适应能力，减少了测试时用户提示的优化步骤，从而提升了性能表现。", "conclusion": "本文提出了一种新的系统提示优化方法，通过实验验证了该方法在多种未见数据集和不同领域的有效性和泛化能力。优化后的系统提示不仅能够抵抗多样用户提示，还能快速适应未见任务，减少了优化步骤，并提升了最终的性能。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.04802", "html_url": "https://arxiv.org/abs/2507.04802", "title": "可解释的机器学习方法提升城市热岛缓解：多尺度驱动物的理解与加权", "title_en": "Interpretable Machine Learning for Urban Heat Mitigation: Attribution and Weighting of Multi-Scale Drivers", "authors": "David Tschan,Zhi Wang,Dominik Strebel,Jan Carmeliet,Yongling Zhao", "background": "城市热岛（UHI）在热浪（HW）期间会进一步加剧，并对公共健康构成风险。要缓解UHI，城市规划者需要估算城市热受不同土地使用类型（LUT）和跨不同尺度（从大型气候背景过程到小规模城市特征）的驱动力的影响。研究需要对这些驱动力进行分类，以便更清晰地理解并高效计算。", "innovation": "本文提出了一种区分土地使用类型（LUT）、驱动（D）、城市（U）和局部（L）特征的机器学习方法，作为Weather Research and Forecasting模型（WRF）与Noah地表模型（LSM）耦合系统的快速估算器，用于预测地表温度（TSK）和2米空气温度（T2）。该方法利用随机森林回归和极端梯度提升训练，对瑞士苏黎世的热浪期间数据进行分析，实现了对小尺度驱动因素的分类与加权。通过这种方法，研究人员能够识别出最重要的小尺度驱动因素（如表面发射率、反射率和叶面积指数），从而提高了模型准确性。", "conclusion": "采用基于LUT的框架构建的模型在统计上显著优于未采用该框架的方法，尤其在包含更多热浪数据时表现出色，且由于RFR-XGB方法的表现优化，该方法具有很好的可解释性。尽管还需要进一步减少不确定性及在其他城市进行测试，但该方法为城市规划者提供了一种可行性中心的城市热岛缓解评估框架。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09025", "html_url": "https://arxiv.org/abs/2507.09025", "title": "Lizard: 一种高效的大语言模型线性化框架", "title_en": "Lizard: An Efficient Linearization Framework for Large Language Models", "authors": "Chien Van Nguyen,Ruiyi Zhang,Hanieh Deilamsalehy,Puneet Mathur,Viet Dac Lai,Haoliang Wang,Jayakumar Subramanian,Ryan A. Rossi,Trung Bui,Nikos Vlassis,Franck Dernoncourt,Thien Huu Nguyen", "background": "在处理长序列时，基于Transformer的大语言模型（LLMs）面临着严重的计算和内存瓶颈，主要是由于softmax注意力机制的二次复杂度以及不断增长的键值（KV）缓存使得推理过程受到上下文长度的记忆限制。", "innovation": "Lizard 提出了一种线性化框架，将预训练的Transformer模型转化为次二次架构。它通过引入一种次二次的注意力机制，该机制能接近地模拟softmax注意力机制并保持模型质量。Lizard 的创新之处在于它能通过紧凑、可学习的模块增强架构，从而实现自适应的内存控制和稳健的长度泛化。此外，Lizard 还引入了一种针对gated注意力的硬件感知算法，以解决数值不稳定问题，从而加速训练过程。", "conclusion": "实验表明，Lizard 能够几乎无损地恢复其师模型的性能，并在5-shot MMLU基准测试中显著优于以往方法，最高超出24.5分，同时展示了更优秀的关联记忆能力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07819", "html_url": "https://arxiv.org/abs/2508.07819", "title": "ACD-CLIP：解耦表示和动态融合以实现零样本异常检测", "title_en": "ACD-CLIP: Decoupling Representation and Dynamic Fusion for Zero-Shot Anomaly Detection", "authors": "Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo", "background": "预训练的视觉-语言模型（VLMs）在零样本异常检测（ZSAD）方面存在一个关键的适应性差距：它们缺乏用于密集预测的局部归纳偏置，并采用刚性特征融合模式。", "innovation": "文章通过一个架构协同设计框架，联合优化特征表示和跨模态融合。提出了一种参数高效的Convolutional Low-Rank Adaptation（Conv-LoRA）适配器，以注入局部归纳偏置进行细粒度表示。引入了Dynamic Fusion Gateway（DFG），利用视觉上下文自适应调节文本提示，实现强大的双向融合。", "conclusion": "在多种工业和医疗基准上的广泛实验证明，该协同设计方法在密集感知任务中具有更高的准确性和鲁棒性，验证了这种协同设计对基础模型的鲁棒适应至关重要。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07420", "html_url": "https://arxiv.org/abs/2507.07420", "title": "广义概率近似优化算法", "title_en": "Generalized Probabilistic Approximate Optimization Algorithm", "authors": "Abdelrahman S. Abdelrahman,Shuvro Chowdhury,Flaviano Morone,Kerem Y. Camsari", "background": "我们介绍了一种广义的‘概率近似优化算法(PAOA)’，这是一种扩展和正式化了Weitz等人早期工作的经典变分蒙特卡洛框架。该算法可以在当前的玻默机器和概率计算机上实现参数化和快速采样。PAOA通过迭代修改二元随机单元网络之间的耦合，根据独立样本的成本评估进行指导。", "innovation": "PAOA直接将无导数更新与指数大小状态空间上的整个马尔可夫流程的梯度对应起来，表明PAOA具有明确的变分形式。在受限制的参数化下，退火算法是PAOA的一个极限情况。研究者在基于FPGA的概率计算机上实现了该退火过程，并集成芯片上的退火来解决大型3D自旋玻璃问题。PAOA在Sherrington-Kirkpatrick模型上的基准测试中表现出优越性能，优于与之参数匹配的QAOA。PAOA自然地扩展了退火算法，通过优化多个温度曲线，使其在自旋玻璃等重尾问题上优于传统的退火算法。", "conclusion": "我们展示了PAOA与退火算法的区别，并证明PAOA在重尾问题上提供了更好的性能。研究结果表明，PAOA具有成为更强大优化算法的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06956", "html_url": "https://arxiv.org/abs/2508.06956", "title": "神经波束场（NBF）：空间波束RSRP预测", "title_en": "Neural Beam Field for Spatial Beam RSRP Prediction", "authors": "Keqiang Guo,Yuheng Zhong,Xin Tong,Jiangbin Lyu,Rui Zhang", "background": "在密集的多用户无线网络中，准确预测波束级参考信号接收功率（RSRP）对于波束管理至关重要，但因高测量开销和快速的信道变化而极具挑战性。", "innovation": "本文提出了神经波束场（NBF），这是一种结合了神经物理的混合框架，用于高效且可解释的空间波束RSRP预测。核心创新在于引入了多路径条件功率谱（MCPP），这是一种可学习的物理中介，代表了特定站点的传播环境。此外，提出了“黑盒-白盒”分离设计，通过变压器基深层神经网络（DNN）从稀疏用户测量和位置中学习MCPP，同时通过物理启发模块进行波束RSRP统计的分析推理。为了提高收敛性和适应性，引入了一种预训练和校准（PaC）策略，结合了基于光线追踪的先验信息进行物理基础预训练，然后使用RSRP数据进行现场校准。实验结果表明，NBF在预测精度、训练效率和泛化能力方面显著优于基于表格的信道知识地图（CKMs）和纯黑盒DNN，同时保持了紧凑的模型大小。", "conclusion": "该提出的框架为下一代密集无线网络中的智能波束管理提供了一个可扩展且基于物理的解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04379", "html_url": "https://arxiv.org/abs/2508.04379", "title": "VisionTS++: 具有持续预训练视觉骨干的跨模态时间序列基础模型", "title_en": "VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones", "authors": "Lefei Shen,Mouxiang Chen,Xu Liu,Han Fu,Xiaoxue Ren,Jianling Sun,Zhuo Li,Chenghao Liu", "background": "近期的研究表明，通过将时间序列预测（TSF）重新定义为图像重建，预先在图像上训练的视觉模型可以作为时间序列基础模型（TSFM）。然而，视觉模型向时间序列的有效跨模态迁移仍然具有挑战性，主要由于以下三个差异：（1）结构化且有界的图像数据与非结构化且异质的时间序列数据之间的数据模态差异；（2）固定RGB三通道视觉模型与任意数量变量的时间序列之间的多变量预测差异；（3）视觉模型的确定性输出与概率预测的需求之间的概率预测差异。", "innovation": "为了弥合这些差距，本文提出了VisionTS++，这是一种基于大规模时间序列持续预训练视觉模型的时间序列基础模型。该方法引入了三项关键创新：（1）基于视觉模型的过滤来识别高质量序列，以稳定预训练过程并缓解模态差异；（2）多变量色彩化转换，将多变量序列编码为多子图RGB图像，以增强跨变量建模；（3）多分位预测使用并行重建头部生成分位数预测，而无需参数假设。", "conclusion": "实验结果表明，VisionTS++在分布内和分布外预测上均表现出最先进的性能，在GIFT-Eval基准测试中排名第一，涵盖7个领域23个数据集，MSE降低方面比专门的时间序列基础模型高出6%-44%，从而证明了视觉模型在适当调整下可以有效应用于时间序列预测，推动了普遍时间序列基础模型的发展。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07281", "html_url": "https://arxiv.org/abs/2507.07281", "title": "随机梯度下降方案最终迭代的收敛率", "title_en": "Convergence Rate for the Last Iterate of Stochastic Gradient Descent Schemes", "authors": "Marcel Hudiani", "background": "本文研究了在目标函数F是全局凸函数或非凸函数且梯度是γ-Holder连续的情况下，随机梯度下降(SGD)和随机重球(SHB)算法在参数设置下的最后迭代的收敛速度。研究使用离散Gronwall不等式来重新发现SGD和SHB的结果，而不需要Robbins-Siegmund定理。", "innovation": "本文的研究创新之处在于，它仅使用离散Gronwall不等式重新发现了SGD和SHB的收敛结果，避免了使用Robbins-Siegmund定理。对于非凸目标函数，研究得到了最后迭代梯度平方的收敛率；对于凸目标函数，研究了最小函数值的收敛率，并证明了SHB具有恒定动量参数的收敛速率为$O(t^{\text{max}(p-1, -2p+1)}\text{log}^2 \frac{t}{\text{δ}})$。", "conclusion": "对于非凸目标函数，研究结论是$\text{min}_{s\text{\textle}t}\text|\nabla F(w_s)\text|^2 = \text{o}(t^{p-1})$；对于凸目标函数，研究结论是$\text{min}_{s\text{\textle}t} F(w_s) - F_* = \text{o}(t^{p-1})$，以及SHB的收敛速率为$F(w_t) - F_* = O(t^{\text{max}(p-1, -2p+1)} \text{log}^2 \frac{t}{\text{δ}})$，其中$p \text{\textin} (\frac{1}{2}, 1)$，步长$\text{α}_t = \text{Θ}(t^{-p})$。同时，还研究了SHB在动量参数为定值$\text{β}\text{\textin}(0, 1)$情况下，当目标函数凸且$\text{γ}=1$时，收敛速度为$F(w_t) - F_* = O(t^{\text{max}(p-1, -2p+1)} \text{log}^2 \frac{t}{\text{δ}})$的概率至少为$1-\text{δ}$。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15327", "html_url": "https://arxiv.org/abs/2508.15327", "title": "基于搜索的信用分配方法在离线偏好强化学习中的应用", "title_en": "Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning", "authors": "Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li", "background": "离线强化学习指的是通过固定的数据集学习策略，而不必进行额外的环境交互。然而，它通常依赖于明确定义的奖励函数，这使得设计过程既困难又昂贵。人类反馈是替代方案，但它有两种常见形式：专家演示和偏好。演示提供了逐步监督，但收集成本高，并且往往反映了有限的专家行为模式。相比之下，偏好更容易收集，但在一段行为中哪些部分对轨迹贡献最大这个问题上还存在不确定性，导致责任分配难题未解。", "innovation": "本文引入了一种基于搜索的偏好加权方案（SPW），用于结合这两种反馈来源。对于偏好标记轨迹中的每个转换，SPW 从专家演示中查找最相似的状态-动作对，并直接根据相似度评分推导出逐步的重要性权重。这些权重随后用于指导标准偏好学习，从而实现比传统方法更准确的责任分配。该研究展示了 SPW 能够有效结合偏好和演示进行联合学习，优于既有方法在挑战性机器人操作任务上的表现。", "conclusion": "SPW 通过结合偏好和演示数据，能够更有效地进行信用分配，优于之前同时利用这两种反馈的方法，特别是在复杂的机器人操作任务上表现出色。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "基于渐进层冻结的站点级微调：极低体重早产儿第一天胸部X射线用于可靠的肺泡发育不全预测", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "极低出生体重的婴儿中有35%会患上慢性肺病—肺泡发育不全（BPD）。BPD主要表现为36周胎龄后需要氧气支持，并会导致长期的呼吸系统问题。预防干预措施可能导致神经发育障碍、机械通气导致的肺损伤和全身并发症，因此早期预测BPD及其结果对于避免低风险婴儿不必要的毒性至关重要。极早早产儿在出生后24小时内会接受常规的胸部X光检查，这可以作为无创的预测工具。这项研究开发并测试了一种使用极低出生体重婴儿的胸部X光的深度学习方法，以预测BPD。", "innovation": "该研究创新之处在于提出了基于渐进层冻结的站点级微调方法，该方法通过采用领域特定预训练（在成人胸部X光上预训练ResNet-50模型）并应用渐进层冻结策略，提高了从第一天胸部X光预测BPD的准确性。通过这种方法，研究者能够使用学习到的标志来增强预测效果，并提出了在计算上可行的模型，适合站点级别实施和未来的联邦学习部署方案。此外，这种方法表明了随着在低出生体重早产儿胸片数据上的预先训练，能够更准确地预测BPD。", "conclusion": "通过渐进层冻结和线性探针的方法，所提出的方法对于从极早早产儿的第一天胸部X光预测BPD结果具有较高的准确性（AUROC 0.78 ± 0.10，平衡准确率 0.69 ± 0.10，F1 分数 0.67 ± 0.11）。该方法在防止低风险婴儿不必要的毒性方面表现出潜力，并且表明领域特定预训练模型对于预测BPD结果是重要的。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10851", "html_url": "https://arxiv.org/abs/2508.10851", "title": "从实体可靠性到清洁反馈：超越交互级信号的实体感知去噪框架", "title_en": "From Entity Reliability to Clean Feedback: An Entity-Aware Denoising Framework Beyond Interaction-Level Signals", "authors": "Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Kai Zhang,Jun Zhou", "background": "显式反馈在现代推荐系统中至关重要，但往往是噪声的，这会妨碍模型训练，降低用户体验。这种噪声可能会误导学习过程，从而降低推荐准确性，损害平台价值。现有去噪策略通常忽视了噪声的实体特异性，增加了计算成本和复杂的超参数调整。因此，亟需一种解决这些问题的方法。", "innovation": "该研究提出了一种名为EARD（Entity-Aware Reliability-Driven Denoising）的轻量级框架，该框架通过关注实体层面的可靠性来转移焦点，而不是交互层面的信号。EARD利用训练损失与噪声之间的相关性来量化用户和项目的可靠性，并将这些实体层面的因素与交互层面的信心结合。EARD具有模型无关性、计算效率高，并且只需要两个直观的超参数。在多项数据集和模型上的实验显示，EARD在ndcg@50上较先进基准提升了高达27.01%，并且几乎不增加额外的计算成本。深入的消融研究和机制分析进一步证实了EARD对超参数选择的鲁棒性和实际可扩展性。这些结果强调了在去噪隐式反馈时考虑实体感知可靠性模型的重要性，并为更稳健的推荐研究铺平了道路。", "conclusion": "EARD框架解决了现有去噪策略中的关键问题，通过关注实体层面的可靠性，提高了推荐系统的性能和可靠性，并具有广泛的适用性和实际价值。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17086", "html_url": "https://arxiv.org/abs/2508.17086", "title": "使用级联对比表示学习从限价订单簿检测多层次操纵", "title_en": "Detecting Multilevel Manipulation from Limit Order Book via Cascaded Contrastive Representation Learning", "authors": "Yushi Lin,Peng Yang", "background": "贸易操纵（TBM）严重破坏了金融市场的公平性和稳定性。其中，一种最为隐蔽和欺骗性的TBM策略——投机（spoofing）——在多等级价格中展现复杂的异常模式，但通常被简化为单一等级的操纵。这些模式往往隐藏在限价订单簿（LOB）丰富而复杂的层级信息中，由于其高维度和噪声，利用这些信息具有挑战性。", "innovation": "本文提出了一种级联对比表示学习框架，结合了级联的LOB表示架构与监督对比学习。实验表明，该框架在各种模型中一致提高了检测性能，基于Transformer的架构达到了最先进的水平。此外，通过对多等级操纵的系统分析和消解研究，探讨了关键成分对检测的贡献，进一步揭示了复杂时间序列数据中表示学习和异常检测的更广泛见解。", "conclusion": "该框架在多层次操纵检测方面显示出优越的性能，并提供了对复杂时间序列数据中表示学习和异常检测更深入的理解。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06836", "html_url": "https://arxiv.org/abs/2509.06836", "title": "COMPACT: 共有Token优化的跨通道与Token剪枝", "title_en": "COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens", "authors": "Eugene Kwek,Wenpeng Yin", "background": "在边缘部署、交互应用和大规模可持续推理中，使大型语言模型（LLMs）在内存、延迟和部署成本上更高效至关重要。现有剪枝方法存在局限性，如宽度剪枝会破坏标准变压器布局，需要定制推理代码；深度剪枝可能导致准确率骤降。很多剪枝方法在大型语言模型上有效，但对小型语言模型性能难以保持。", "innovation": "提出了COMPACT，这是一种联合剪枝技术。COMPACT主要通过(i) 剪枝罕见词汇减少嵌入/语言模型头部层，(ii) 使用共同Token加权激活剪枝前馈网络中间通道来确定剪枝的重要性与后剪枝Token分布的一致性。COMPACT继承了宽度和深度剪枝的优点，如保持标准变压器架构、针对不同规模的模型可调节（词汇量与前馈网络剪枝之间的权衡）、剪枝速度快、内存节省显著且吞吐量增加。", "conclusion": "实验表明COMPACT在Qwen、LLaMA和Gemma家族（0.5B-70B参数）中性能达到领先水平，同时参数减少、GPU内存和延迟均有显著降低。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA: 多模态对象感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "该研究介绍了一种名为MOCHA（Multi-modal Objects-aware Cross-arcHitecture Alignment）的知识蒸馏方法，该方法从大规模的视觉-语言教师模型（如LLaVa）中提取出区域级的多模态语义，并将其传递到一个轻量化的仅视觉目标检测学生模型（如YOLO）中。尽管模型较小，但仍然可以实现与大模型相当的多模态性能。", "innovation": "MOCHA方法具有以下创新点：首先，引入了一个翻译模块，将学生特征映射到联合空间，通过双重目标损失进行训练，同时促进局部对齐和全局关系一致性。其次，该方法在对象级别而不是密集或全局对齐上运行，从而实现不修改教师模型且不需要推理阶段的文本输入的高效语义传递。", "conclusion": "实验结果表明，MOCHA在四个个性化检测基准测试中的表现优于基线方法，平均得分提高了10.1分。尽管其架构紧凑，MOCHA的性能与更大规模的多模态模型相当，证明了其在实际部署中的适用性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13336", "html_url": "https://arxiv.org/abs/2509.13336", "title": "利用强化学习最大化BVLoS路径规划中UAV蜂窝连接性", "title_en": "Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning", "authors": "Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah", "background": "本文介绍了一种基于强化学习（RL）的方法，用于实现视觉视线之外（Beyond Visual Line of Sight，BVLoS）操作的蜂窝连接无人 aerial 载具（UAV）路径规划。研究目的是在考虑现实世界空中覆盖约束以及使用经验性空中信道模型的情况下，通过强化学习技术最小化飞行距离，同时最大化空中与地面基站（BSs）的连接质量。", "innovation": "提出的方法采用RL技术训练一个代理，将空中与地面基站之间的通信链路质量作为奖励函数，实现实时路径规划，并通过仿真结果证明了该方法的有效性。该方法针对UAV蜂窝通信的局限性提出了新的策略，为将来集成到地面控制系统（GCS）的路径规划模块提供了技术支持，提高了UAV的安全性和能力。该方法在复杂远程UAV应用中有潜在价值，推动了蜂窝连接无人空中车辆路径规划技术的进步。", "conclusion": "研究结果表明，该方法能够有效地确定最优路径，确保与地面基站的最大连接性，从而保证安全可靠的BVLoS飞行操作。此外，该解决方案可以部署为离线路径规划模块，集成到未来的地面控制系统中，进一步增强UAV的操作能力和安全性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07545", "html_url": "https://arxiv.org/abs/2510.07545", "title": "部署小型LVLM评判者进行图表模型的实际世界评估：经验教训与最佳实践", "title_en": "Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices", "authors": "Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang", "background": "小型视觉-语言模型（LVLMs）尽管参数量不大（<=2B），但在图表理解任务中的表现仍然较差，限制了它们在资源受限环境中的实际应用。7B参数的LVLM已经显示出作为自动化法官的潜力，但在某些任务上仍表现出色。", "innovation": "提出了两种确保评估成本效益的方法：(i)多准则提示，将单独的评估标准合并成一个查询；(ii)领域适应迁移学习，研究将2B参数的LVLM fine-tune到图表数据集中的合成判断，以创建ChartJudge。这种方法展示了在小型模型中有效转移知识的能力。", "conclusion": "通过细分分析图表类型和查询复杂性，研究提供了有关模型规模、提示设计和迁移性之间权衡的实际见解，使图表推理任务的可扩展和低成本评估成为可能。此外，发现多准则提示揭示出了鲁棒性差距，导致7B模型性能的巨大下降，包括像LLaVA-Critic这样的专门LVLM法官。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01298", "html_url": "https://arxiv.org/abs/2510.01298", "title": "MorphGen: 可控且形态上可信的生成细胞成像", "title_en": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging", "authors": "Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello", "background": "模拟细胞响应干预措施对加速基于高内涵图像的筛选具有潜力，这对于推动药物发现和基因编辑至关重要。现有的方法通常将多通道染色压缩为RGB图像，导致牺牲了特定细胞器的细节。MorphGen是一种基于扩散机制的生成模型，能够跨多种细胞类型和扰动进行可控生成。通过使用与OpenPhenom中的表型嵌入进行对齐损失的训练，MorphGen能够生成完整的荧光通道，保留每个细胞器的结构，提供细粒度的形态学分析，这对于生物解释至关重要。", "innovation": "MorphGen是一种基于扩散机制的生成模型，具有以下创新点：1）能够跨多种细胞类型和扰动进行可控生成；2）通过与OpenPhenom中的表型嵌入进行对齐损失的训练，确保生成的图像具有生物学意义；3）同时生成完整的荧光通道，保留每个细胞器的结构细节，提供更详细的形态学分析；4）在CellProfiler特征上与真实图像一致，并且生成的图像比前最先进的MorphoDiff具有更低的FID分数，显著降低了组织细胞类型的限制。", "conclusion": "MorphGen通过保留每个细胞器的结构详细信息，实现了可控且形态上可信的生成细胞成像，为后续的药物发现和基因编辑提供了更准确的生物解释基础，显著优于之前的模型。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07624", "html_url": "https://arxiv.org/abs/2510.07624", "title": "从数据到奖励：最大似然估计的 bilevel 优化视角", "title_en": "From Data to Rewards: a Bilevel Optimization Perspective on Maximum Likelihood Estimation", "authors": "Abdelhakim Benechehab,Gabriel Singer,Corentin Léger,Youssef Attia El Hili,Giuseppe Paolo,Albert Thomas,Maurizio Filippone,Balázs Kégl", "background": "生成模型构成了现代机器学习的核心，支撑了文本、视觉和跨模态应用中的领先系统。尽管最大似然估计长期以来一直是主流的训练范式，但最近的研究指出，它在泛化能力和对抗性遗忘方面存在局限性，相比之下，强化学习技术如策略梯度方法更为有效。然而，这些方法依赖于显式的奖励信号，在实践中往往不可用，这导致如何仅利用高质量的数据集来对生成模型进行准确校准成为一个基本问题。", "innovation": "本文通过Bilevel Optimization框架解决了这一挑战，其中奖励函数被视为外层问题的优化变量，而内层定义了策略梯度目标。通过在可处理的环境中对该优化问题进行理论分析，获得了可以推广到表格分类和基于模型的强化学习等应用中的见解。", "conclusion": "我们提出的方法为仅使用高质量数据集校准生成模型提供了新的理论支持和解决思路，并通过放出代码和具体应用展示了其有效性。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07088", "html_url": "https://arxiv.org/abs/2510.07088", "title": "通过Hoeffding分解在多元伯努利分布下解释模型", "title_en": "Explaining Models under Multivariate Bernoulli Distribution via Hoeffding Decomposition", "authors": "Baptiste Ferrere(EDF R\\&amp;D PRISME, IMT, SINCLAIR AI Lab),Nicolas Bousquet(EDF R\\&amp;D PRISME, SINCLAIR AI Lab, LPSM (UMR\\_8001)),Fabrice Gamboa(IMT),Jean-Michel Loubes(IMT),Joseph Muré(EDF R\\&amp;D PRISME)", "background": "该研究背景在于，解释具有随机输入的预测模型的行为可以通过子模型分解来实现，其中这些子模型具有更易于解释的特征。先前的研究已经证明，在随机输入变量相关的情况下，基于L2子空间的斜投影概念，存在且唯一地存在广义Hoeffding分解。该文章特别关注输入变量服从伯努利分布的情形，并提供了一种完全的分解描述。", "innovation": "该研究的创新在于证明了在输入变量服从伯努利分布的情况下，L2子空间是单位维的，且功能分解明确列出。这导致了一种完全可解释的框架，并理论上支持逆向工程。通过明确推导输入变量对输出预测的影响指标（类似于Sobol'指标和Shapley效应），这种分析方法被证明在基于二进制决策图、布尔网络或二进制神经网络的决策支持问题中具有实用性。此外，该研究还提出了在高维设置中进一步探索的可能性，并考虑将这些发现扩展到有限可数输入的模型中", "conclusion": "该研究为二进制输入下模型的解释提供了一种有效的方法，并且为理解高维和有限可数输入下模型的行为开辟了新的研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "在线成对比较中从生成在线评估标准的方法", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek", "background": "当前，通过奖励学习训练LLMs的方法存在局限性，特别是当奖励不可验证或人类偏好信号粗糙时。既有研究已经证明了基于评分表的奖励强化学习能够提高LLM的表现。然而，大多数方法依赖于静态评分表，这种静态评分表容易被滥用和忽视正在训练中浮现的新兴需求，无法持续地识别和解决错误。因此，亟需一种能够动态生成评价标准的方法，以提高LLMs的训练效果和增强其表现的灵活性和准确性。", "innovation": "该研究提出了一种名为Online Rubrics Elicitation（OnlineRubrics）的新方法。这种方法通过实时对比当前政策和参考政策的响应，动态地生成评估标准。这种方法的优势在于能够在线上过程中持续地识别和解决新出现的问题，避免了静态评分表所带来的奖励滥用问题。实验结果表明，这种方法能够显著改进模型性能，相比于仅使用静态评分表的方式，改进幅度可达8%，并且已在多种评估标准上进行了验证，包括AlpacaEval、GPQA、ArenaHard以及专家问题和评分表的验证集等。", "conclusion": "实验结果证明，Online Rubrics Elicitation相比静态评分表，能够持续识别和缓解错误，提高模型在各种开放长文回答上的表现。该方法通过在线对比生成评估标准，提高了LLMs训练的灵活性和有效性，为Continuous Evaluation和Error Identification提供了创新解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03807", "html_url": "https://arxiv.org/abs/2510.03807", "title": "基于6G的实时虚拟物理系统动轴承故障检测实验验证数字孪生框架", "title_en": "6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection", "authors": "Vaskar Chakma,Wooyeol Choi", "background": "目前集成数字孪生(DT)技术的网络物理系统(CPS)在实现关键工业应用的实时性能方面面临重大限制。现有的5G使能系统存在超过10毫秒的延迟，对于需要亚毫秒级响应时间的应用（如自主工业控制和预测性维护），这些延迟是不合适的。因此，这项研究旨在开发并验证一种基于6G的数字孪生框架，该框架能够实现超低延迟通信和物理工业资产及其数字孪生之间的实时同步，特别以轴承故障检测作为关键工业应用场景。实验使用了卡内基梅隆大学(CWRU)的轴承数据集，通过全面的时间和频率域特征提取和随机森林分类算法进行验证。该系统在多个指标上进行了性能评估，包括分类准确性、端到端延迟和可扩展性，达到了97.7%的故障分类准确率，端到端延迟仅为0.8毫秒，相比于WiFi-6提高了15.6倍，相比于5G提高了5.25倍。系统显示了优异的可扩展性，处理时间随规模增长为次线性，并且在四个轴承故障类别上保持了一致性能，宏平均F1分数超过97%。", "innovation": "该研究提出了一种基于6G的数字孪生框架，该框架集成了太赫兹通信、智能反射表面和边缘人工智能技术，并采用了五层架构。实验使用了CWRU轴承数据集。与传统WiFi-6和5G网络相比，该系统实现了97.7%的故障分类准确性和0.8毫秒的端到端延迟，分别提高了15.6倍和5.25倍的性能。此外，系统在多个轴承故障类别的性能上表现出出色的可扩展性，处理时间随规模增长为次线性，并保持了很高的分类准确性和一致性。", "conclusion": "该研究开发的基于6G的数字孪生框架在特征提取和分类算法的全阶段实验验证中表现出色，特别是在端到端延迟和分类准确性方面，显著优于现有的WiFi-6和5G网络系统。该框架为实时工业应用提供了可能，特别是在轴承故障检测场景中，展示了6G技术在工业物联网中的巨大潜力。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08576", "html_url": "https://arxiv.org/abs/2510.08576", "title": "大型语言模型在机器辅助解析用户意图方面的比较分析", "title_en": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "authors": "Justus Flerlage,Alexander Acker,Odej Kao", "background": "大型语言模型（LLMs）已成为自然语言理解和用户意图解析的关键工具，支持翻译、总结等任务，并逐步实现复杂工作流的编排。这一进步标志着从传统的基于GUI的用户界面向以语言为中心的交互模式的转变。用户现在可以通过自然语言表达目标，让LLMs在多个应用之间动态地进行操作编排。然而，现有的实现方案通常依赖于云端的私有模型，这在隐私、自主性和扩展性方面带来了限制。为了使语言优先的交互成为真正强大的、值得信赖的接口模式，本地部署不仅是一种便利，更是一种必要。这就突显了评估开放源代码和开放访问的LLMs在未来的意愿为基础的操作系统中的可行性的重要性。", "innovation": "本文比较分析了多个开源和开放访问的大型语言模型在机器辅助解析用户意图方面的表现。研究使用开源模型与基于OpenAI的GPT-4模型进行对比，评估这些模型生成不同用户意图工作流的能力，揭示了开源LLMs作为自主、本地可操作组件在下一代操作系统中的潜力。", "conclusion": "研究结果强化了对未来人工智能基础设施去中心化和普及化的讨论，并表明用户设备交互可以通过嵌入本地智能变得更为无缝、适应性和隐私意识强。开源LLMs作为一种能够在本地工作的自主组件，在下一代操作系统中具有巨大潜力。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08610", "html_url": "https://arxiv.org/abs/2510.08610", "title": "基于相对定位的代码片段划分方法在代码仓库级别代码补全任务中的丰富上下文检索", "title_en": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "authors": "Imranur Rahman,Md Rayhanur Rahman", "background": "代码补全可以帮助开发者提高效率并简化开发过程。尽管现代集成开发环境（IDEs）中提供代码补全功能，但研究尚未确定基于IDEs可获取的信息，哪种上下文能使大型语言模型（LLMs）在代码补全任务中表现更好。因此，论文描述了一种有效的上下文收集策略，以帮助LLMs在代码补全任务中表现更好。", "innovation": "提出了一种基于相对定位的代码片段划分方法，首先将代码库预处理成更小的代码片段，然后使用基于语法规则和语义相似性的代码片段检索，并在最终上下文中进行相对定位。这种方法提高了代码补全任务的性能。", "conclusion": "通过代码片段化和代码片段在最终上下文中的相对定位，提高了代码补全任务的表现，为LLMs在代码补全任务中的表现提供了更准确、更有效的上下文。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "选择减少过时和易受攻击依赖项的最佳方法：锁定还是漂浮？", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发人员经常使用版本约束来指定为其项目所需的依赖版本。锁定依赖项可以减少破坏性变更的风险，但需要手动管理和替换过时和易受攻击的依赖项。相反，漂浮可以自动获取错误修复和安全修复，但存在破坏性变更的风险。安全从业者建议锁定依赖项以防止软件供应链攻击，例如恶意包更新。然而，由于锁定是最严格的版本约束，锁定也是导致依赖项过时的可能性最大的。因此，了解不同版本约束类型下依赖项变过时或易受攻击的可能性变化至关重要。", "innovation": "本研究通过在大规模下实证评估不同版本约束类型下依赖项变过时或易受攻击的几率，帮助开发者做出知情的依赖项版本约束选择。研究发现，漂浮-次要是最常用的版本约束类型，其次是锁定。同时，研究结果表明，最大的漂浮类型-主要最不可能导致依赖项过时，最小的漂浮类型-次要最不可能导致依赖项易受攻击。", "conclusion": "本研究通过实证分析展示了漂浮和锁定在不同版本控制类型的依赖项老化和易受攻击的风险之间没有绝对的优势。在这种情况下，开发人员应考虑项目的具体需求和风险偏好来选择最合适的版本约束策略。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08665", "html_url": "https://arxiv.org/abs/2510.08665", "title": "RA-Gen：基于ReAct多智能体任务执行的可控代码生成框架", "title_en": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution", "authors": "Aofan Liu,Haoxuan Li,Bin Wang,Ao Yang,Hui Li", "background": "基于大型语言模型（LLMs）的代码生成模型得到了广泛应用，但在确保安全性、准确性和可控性方面仍面临挑战，尤其是在处理复杂任务时尤为明显。现有方法通常缺乏动态整合外部工具、透明推理和用户对安全性的控制。", "innovation": "本文提出了一种利用ReAct范式进行多智能体任务执行的可控代码生成框架。该框架通过动态交互实现LLMs与外部资源的协同工作，包括计划者、搜索者、代码生成器和提取器四个专有智能体。搜索者采用基于ReAct的交替生成推理痕迹和执行动作的方式，增强了准确性并提升了用户的控制力。", "conclusion": "实验结果表明，该框架在多种语言中表现出色。在使用CodeQL的SVEN数据集上，安全性达到了94.8%，优于现有方法。其透明的推理过程增强了用户信任度并提升了可控性。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08640", "html_url": "https://arxiv.org/abs/2510.08640", "title": "在领域特定工具的帮助下自动化修复Android构建错误：跨LLM代理推理执行差距的桥梁策略", "title_en": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "authors": "Ha Min Son,Huan Ren,Xin Liu,Zhe Zhao", "background": "Android是最大的移动平台之一，但自动构建应用仍是一项实际挑战。尽管大型语言模型（LLMs）对代码修复显示出潜力，但对于修复Android构建错误的应用仍是一个未被充分探索的领域。", "innovation": "本研究首先提出了一个名为AndroidBuildBench的新基准，包含43个开源Android项目中的1,019个构建错误。其次，提出了GradleFixer，这是一种拥有领域特定工具的LLM代理，可以用于检查和操作Gradle构建环境，并在此过程中取得显著的成功。此外，研究提出了一种被称为‘工具桥梁’的方法，通过引入领域特定的抽象替换通用的shell命令，有效解决了高层面理与低层面执行之间的差距。", "conclusion": "研究展示了GradleFixer在解决Android构建错误上的有效性，并提出‘工具桥梁’策略，通过API样式的接口和减少操作空间来解决LLMs在将高层面理转化为低层面执行时遇到的问题。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08612", "html_url": "https://arxiv.org/abs/2510.08612", "title": "LLMs对软件开发团队协作的影响", "title_en": "Impact of LLMs on Team Collaboration in Software Development", "authors": "Devang Dhanuka", "background": "大型语言模型（LLMs）越来越多地被集成到软件开发过程中，有望改变团队的工作流和生产力。本文研究了LLMs在软件开发生命周期（SDLC）中的影响。文章回顾了先前的研究，并结合了2025年的新发展，包括新的文献和案例研究，探讨了SDLC中的协作障碍，并研究了LLMs如何在团队环境中提高生产力、沟通和决策能力。", "innovation": "通过文献综述、行业示例、团队调研和两个案例研究，评估了LLM辅助工具（如代码生成助手和AI项目管理代理）对协作软件工程实践的影响。研究发现了LLMs在提高效率（通过自动化重复任务和文档）、增强沟通清晰度和促进跨功能协作方面的显著改善，同时指出了模型限制和隐私问题等新挑战。文章讨论了这些效益和挑战，并提出了未来研究方向，包括领域特定模型的定制、开发工具的更好集成以及确保信任和安全的策略等。", "conclusion": "研究表明LLMs可以显著提高软件开发的效率、沟通清晰度和跨功能协作，同时也带来新的挑战。文章提出了研究问题的指导，评估了研究的有效性威胁，并建议了未来的研究方向。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08664", "html_url": "https://arxiv.org/abs/2510.08664", "title": "Faver: 使用函数抽象可验证中间件提升基于LLM的RTL生成", "title_en": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware", "authors": "Jianan Mu,Mingyu Shi,Yining Wang,Tianmeng Yang,Bin Sun,Xing Hu,Jing Ye,Huawei Li", "background": "基于大语言模型的RTL生成是一个有潜力的研究方向，因为它可能使当前芯片设计中自动化程度最低的阶段得以解放。然而，由于高级规范与RTL之间的显著语义差距，以及可用训练数据的限制，现有的模型生成准确性受到了挑战。借鉴人类设计经验，设计与验证结合有助于提高准确性，但在缺乏RTL测试平台数据的情况下，对大语言模型并不友好。尽管大语言模型擅长高级语言如Python/C，但对于RTL而言仍然存在巨大的语义差距。实现相同功能时，Python/C代码与硬件代码在时空粒度上差异显著，要求模型不仅要考虑高层次的逻辑功能，还要确保低级别的细节与电路代码一致。这是一项艰巨的任务。", "innovation": "本文提出了一种函数抽象可验证中间件（Faver），用于简化基于大语言模型的RTL验证工作流程。通过结合大语言模型友好的代码结构与规则基础上的模板，Faver解耦了电路验证的细节，使大语言模型能够专注于其功能本身。", "conclusion": "在对SFT模型和开源模型的实验中，Faver将模型的生成准确性提高了最高达14%。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08667", "html_url": "https://arxiv.org/abs/2510.08667", "title": "RAG4Tickets：基于JIRA和GitHub数据的检索增强生成的AI驱动工单解决方法", "title_en": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data", "authors": "Mohammad Baqar", "background": "现代软件团队在解决重复或相关的问题时，经常会遇到由于JIRA工单、开发者讨论和GitHub拉请求（PR）中的碎片化知识而导致的处理延迟问题。", "innovation": "提出了一种检索增强生成（RAG）框架，该框架结合了Sentence-Transformers用于语义嵌入和基于FAISS的向量搜索，以提供上下文相关的工单解决建议。该方法将历史JIRA工单、用户评论和链接的PR元数据嵌入，以检索语义相似的过去案例，然后由大型语言模型（LLM）综合生成具体的且可解释的解决方案建议。框架贡献了一种将JIRA和GitHub数据连接起来的统一流程、异构软件制品的嵌入和FAISS索引策略，以及基于检索证据引导的解决生成模块。实验证明，该系统显著提高了解决准确性、修复质量和现代DevOps环境中的知识重用.", "conclusion": "实验评价显示，所提出的系统在精度、召回率、解决时间减少和开发者接受度指标上表现显著，极大地提升了工单解决的准确性和修复质量，并增强了知识的重复使用。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08827", "html_url": "https://arxiv.org/abs/2510.08827", "title": "McMining：学生代码中的误解自动发现", "title_en": "McMining: Automated Discovery of Misconceptions in Student Code", "authors": "Erfan Al-Hossami,Razvan Bunescu", "background": "在学习编程时，学生常常会形成对编程语言概念的误解，这些误解不仅会导致bug或不高效的代码，还可能延缓相关概念的学习进程。", "innovation": "提出了一种名为McMining的任务，即从学生代码样本中挖掘编程误解。为了使McMining系统的训练和评估成为可能，开发了一个可扩展的误解基准数据集，以及一个大型的代码样本集，其中这些误解得以体现。此外，还介绍了一种基于LLM（大型语言模型）的McMiner方法，并通过广泛的评估展示了Gemini、Claude和GPT系列模型在学生代码中发现误解方面的有效性。", "conclusion": "研究表明，Gemini、Claude和GPT系列模型在发现学生代码中的误解方面表现出色，这为自动纠正编程学习中的错误提供了新的可能途径。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08810", "html_url": "https://arxiv.org/abs/2510.08810", "title": "PyMigTool: 一种用于端到端Python库迁移的工具", "title_en": "PyMigTool: a tool for end-to-end Python library migration", "authors": "Mohayeminul Islam,Ajay Kumar Jha,May Mahmoud,Sarah Nadi", "background": "手动迁移软件项目中的库耗时且易出错，因为这需要开发者理解两个库的API，映射等价API并进行必要的代码转换。现有大多数自动化库迁移技术或工具仅停留在API映射阶段，或者只支持有限的库和代码转换。因此，提出了一种端到端的Python库自动化迁移方案。", "innovation": "利用大型语言模型（LLMs）的代码生成与转换能力作为主要工具，提出PyMigTool，该工具结合静态分析和动态分析，提高库迁移准确性，并有效处理实际项目中的32%的迁移，此外，大多数剩余的迁移问题仅需少许人工修正。", "conclusion": "PyMigTool是第一个能无缝迁移任意两个提供相似功能Python库的自动化工具，通过实验验证在真实世界应用程序中具有高迁移成功率和较低的人工干预需求，展示了LLMs在复杂任务中的潜力。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08697", "html_url": "https://arxiv.org/abs/2510.08697", "title": "BigCodeArena：通过执行揭示更可靠的人类偏好在代码生成中", "title_en": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "authors": "Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra", "background": "传统的人工评价方式在评价大型语言模型（LLM）生成代码的质量时存在极大挑战，因为需要理解大量的原始代码并模拟代码执行。因此，BigCodeArena平台被开发出来，它是一个开放的人类评价平台，支持代码的即时执行环境，通过人工与代码执行过程及结果的交互，对10个广泛使用的LLM生成代码进行评价，覆盖10种编程语言和8种执行环境，共收集了超过14,000个以代码为中心的对话会话，并从中发现了超过4,700个成对的对话样本，揭示了LLM在具体任务、语言和框架方面的细粒度偏好差异。", "innovation": "BigCodeArena创新地结合了Crowdsourced模型评价平台（如Chatbot Arena）的实时评价功能，与对LLM生成代码的实际执行能力的支持。它允许人类用户与模型生成代码的执行过程及结果进行互动，从而揭示了LLM在代码理解和生成方面的具体偏好。此外，基于收集的数据，BigCodeArena还开发了两个基准测试工具BigCodeReward和AutoCodeArena，用于系统地评估前沿LLM的代码生成能力。", "conclusion": "研究结果表明，大多数LLM在提供执行结果时，在判定编程偏好方面表现优异。基于此发现，研究者提出了自动Elo评分基准（AutoCodeArena），旨在无需人工介入的情况下评估LLM的编程质量。分析发现，如GPT-5、Claude-Sonnet-4和Claude-Opus-4等自主模型在最新的模型中依然保持了出色的代码生成性能。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08716", "html_url": "https://arxiv.org/abs/2510.08716", "title": "基于搜索的Python单元测试生成的超参数调整", "title_en": "Search-based Hyperparameter Tuning for Python Unit Test Generation", "authors": "Stephan Lukasczyk,Gordon Fraser", "background": "基于搜索的测试生成算法有无数的配置选项，用户通常不调整这些选项，而是使用默认值，这可能导致无法获得最佳结果。调整算法的超参数可以找到更好的超参数值，但通常需要大量资源。作为一种有效解决测试生成问题的方法，元启发式搜索算法已经被提出作为高效调整参数的解决方案。本文研究了使用差分演化算法来调整Pynguin框架中实现的DynaMOSA和MIO多目标搜索算法的超参数的可能性。实验结果表明，使用调整后的DynaMOSA算法可以显著提高测试套件的覆盖率，差分演化算法比基本网格搜索更有效。", "innovation": "使用差分演化算法来调整基于搜索的测试生成算法的超参数，并验证了这种调整方法的有效性。这种方法可以显著提高测试覆盖范围，并且比基本的网格搜索算法更高效。", "conclusion": "差分演化算法能够有效地调整Pynguin框架中DynaMOSA和MIO算法的超参数，在提高测试覆盖范围的同时无需大量资源消耗，差分演化算法比基本的网格搜索方法更有效。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08834", "html_url": "https://arxiv.org/abs/2510.08834", "title": "识别视频游戏调试瓶颈：行业视角", "title_en": "Identifying Video Game Debugging Bottlenecks: An Industry Perspective", "authors": "Carlos Pinto Gomez,Fabio Petrillo", "background": "传统软件的调试技术通常也应用在视频游戏中。然而，视频游戏特有的复杂性和需求需要一套独特的调试技术，例如屏幕控制台、调试绘制、调试相机、作弊和游戏菜单，以及数据清理等。本研究旨在通过访谈20名游戏行业的资深开发者，概述他们在开发游戏过程中的调试方法，并分析导致调试瓶颈的活动和工具。研究主要关注那些影响问题解决的调试活动，以及使用这些活动和工具的具体情况。此外，研究还探讨了不同团队在调试过程中的协作情况，以及技术角色在其中的核心地位。通过对数据的定性分析发现，游戏开发者的36.6%时间用来检查游戏状态和35.1%时间用于本地重现缺陷问题", "innovation": "本研究提供了游戏行业的实际调试经验，通过记录关键错误（如崩溃、对象行为和持久性问题）的调试会话，识别出影响调试效率的瓶颈活动和工具。研究方法独特地结合了实证研究和定性分析，揭示了游戏开发者在调试过程中最耗时的部分，强调了技术角色在整个调试过程中的核心作用", "conclusion": "研究发现，游戏开发者花费大量时间检查游戏状态和本地重现缺陷问题。同时，技术人员在调试过程中的协作与作用是解决调试瓶颈的关键。支持团队合作和技术角色的重要性，为游戏开发者提供了一种更有效和协调的调试模式"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08876", "html_url": "https://arxiv.org/abs/2510.08876", "title": "基于向量图的仓库理解方法及其在问题驱动文件检索中的应用", "title_en": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval", "authors": "Kostiantyn Bevziuk,Andrii Fatula,Svetozar Lashin Yaroslav Opanasenko,Anna Tukhtarova,Ashok Jallepalli Pradeepkumar Sharma,Hritvik Shrivastava", "background": "当前软件仓库庞大且复杂，涵盖了大量的代码、文件和项目结构信息。传统的开发和管理方式对大型软件仓库的需求显得力不从心。因此，研究如何有效地分解和转化这些大型软件仓库成为一个关键点。本文提出了一种仓库分解系统，旨在将大型软件仓库转化为一个标记有知识的向量图，以此映射项目架构和语义结构。这不仅可以捕获语义间的相关性，还能提高后续仓库开发的自动化程度。", "innovation": "本文的核心创新在于开发了一种能够将大型软件仓库转化为向量知识图的模型。模型主要包含两个部分：一是建立一个准确反映项目架构和语义结构的向量图；二是构建一个融合了语义检索和图结构感知扩展的混合检索管道，该管道通过构建更详细的图来增强检索的精确性。此外，该模型还利用了大型语言模型（LLM）来自动化地生成图请求并生成用户可读的解释。", "conclusion": "本文提出的方法不仅能够有效提取并表示大型软件仓库中的复杂信息，还能够通过自动化处理提高未来的开发效率。该方法在问题驱动的文件检索中表现出色，为开发者提供了一种新的理解仓库结构和进行检索的方式。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08981", "html_url": "https://arxiv.org/abs/2510.08981", "title": "SEER: 提升软件需求工程中的可持续性", "title_en": "SEER: Sustainability Enhanced Engineering of Software Requirements", "authors": "Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi", "background": "软件开发的迅速扩展对环境、技术、社会和经济产生了重大影响。为了在2030年前实现联合国可持续发展目标，开发人员需要采用可持续的实践方法。现有方法大多提供高层次的指导方针，这些指导方针的实施需要大量时间和团队的适应能力。这些方法主要集中在设计或实现阶段，而可持续性评估应该从需求工程阶段开始。", "innovation": "介绍了一种名为SEER的框架，它在软件开发的早期阶段解决了可持续性问题。这个框架分为三个阶段：(1) 从通用分类中识别特定软件产品相关的可持续性需求(SRs)；(2) 通过已识别的SRs评估系统的可持续性；(3) 优化无法满足任何SR的系统需求。该框架利用大型语言模型的推理能力和代理型RAG（检索增强生成）方法实现。SEER已在四个不同领域的软件项目中进行实验，使用Gemini 2.5推理模型生成的结果表明，该方法在广泛领域中准确识别多种可持续性问题的有效性。", "conclusion": "SEER框架通过早期识别、评估和优化可持续性需求，提升软件需求工程中的可持续性，从而有助于实现联合国可持续发展目标。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08850", "html_url": "https://arxiv.org/abs/2510.08850", "title": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs", "title_en": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs", "authors": "Vasudha Yanuganti,Ishaan Puri,Swapnil Chhatre,Mantinder Singh,Ashok Jallepalli,Hritvik Shrivastava,Pradeep Kumar Sharma", "background": "现代代码库使开发者和AI编码助手难以找到正确源文件来回答诸如'这个功能是如何工作的？'或'这个错误是在哪里引入的？'等问题。传统的代码搜索方法（基于关键词或信息检索）往往忽略语义上下文和跨文件链接，而大型语言模型能理解自然语言，但缺乏特定于仓库的详细信息。", "innovation": "该研究提出了一种文件路径检索方法，利用QLoRA和Unsloth优化对强大的大型语言模型（Qwen3-8B）进行微调，直接从自然语言查询中预测相关文件路径。此外，研究引入了六种代码感知策略，通过抽象语法树（AST）结构和仓库内容生成真实的问答对，其中答案是一组文件路径，策略覆盖了从单文件提示到层次化仓库摘要的广泛范围。该方法在Python项目（包括Flask、Click、Jinja、FastAPI和PyTorch）上进行训练，取得了高检索精度：在保留查询上的精确匹配率高达91%，召回率为93%，明显优于单一策略训练。在大规模代码库（如包含约4,000个Python文件的PyTorch）上，模型召回率为59%，展示了可扩展性。", "conclusion": "研究分析了多层次代码信号如何帮助大型语言模型推理跨文件上下文，并讨论了数据集设计、限制（例如，大型仓库中的上下文长度）以及检索与基于大型语言模型的代码智能未来集成的方式。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08990", "html_url": "https://arxiv.org/abs/2510.08990", "title": "向着软件设计中可持续性要求的分类研究", "title_en": "Towards a Taxonomy of Sustainability Requirements for Software Design", "authors": "Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi", "background": "软件系统在推动全球可持续发展方面扮演着重要角色，要求从需求工程的初始阶段就系统地考虑环境、社会、技术和经济因素。现有研究虽然提出了各种可持续性需求（SRs），但这些贡献通常是碎片化的、局限于特定维度或多应用于特定应用领域，导致软件工程社区缺乏一个统一和全面的分类系统。为了弥合这一空白，研究通过系统文献综述（SLR）来提取和组织最先进的可持续性要求。", "innovation": "研究的主要贡献是在环境、技术、社会和经济四个可持续性维度下提供了一个全面的SRs分类体系。对于每个类别，提供清晰的定义、相关指标和测量方法。此外，绘制了一个相关矩阵，显示不同维度中各类别之间的正向和负向影响（协同效应和冲突），为软件开发者和研究人员提供了有效制定、管理和解决可持续软件开发中的权衡问题的系统性参考。", "conclusion": "系统化的参考体系不仅有助于软件开发者和研究人员进行可持续软件开发，也提供了一个框架，使得在软件设计过程中能够系统地考虑和衡量各种可持续性需求之间的相互作用。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08996", "html_url": "https://arxiv.org/abs/2510.08996", "title": "拯救SWE-Bench：基准变异方法以实现现实情境下的代理评估", "title_en": "Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation", "authors": "Spandan Garg,Ben Steenhoek,Yufan Huang", "background": "目前用于评估软件工程代理的标准，如SWE-Bench Verified，主要来源于GitHub问题，未能准确反映开发者在集成开发环境（IDE）中与基于聊天的编码助手互动的方式。这导致代理能力在实际场景中的系统性高估，特别是在修复错误方面。因此，本文通过分析开发者与聊天代理交互模式，将已有形式化基准转换为现实用户查询，提出了一种新型基准评估框架。", "innovation": "本文介绍了新型基准评估框架，该框架能够将现有形式化基准转化为现实用户查询，通过系统分析开发者与聊天代理的交互模式。此外，该方法灵活可扩展，适用于现有基准，并在SWE-Bench Verified, TypeScript子集Multi-SWE-Bench和私有基准SWE-Bench C#上进行了测试，将GitHub问题描述转化为基于流行聊天代理互动分析的现实用户风格查询。结果显示，现有基准显著高估了一些模型的能力，特别是在公共基准上的表现超过基线50%以上，在内部基准上约为10-16%。", "conclusion": "本文通过基准变异技术，建立了一种新的评估交互式聊天软件工程代理的方法，从而为真实情境下的代理评估提供了一种新的思路。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09045", "html_url": "https://arxiv.org/abs/2510.09045", "title": "使用标识符替换进行成本效益优化的长代码翻译方法", "title_en": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements", "authors": "Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta", "background": "在软件开发领域，LLMs（大型语言模型）已用于自动化代码翻译任务，即将一种编程语言的源代码翻译成另一种，同时保持其功能。然而，LLMs 在处理长代码时经常遇到超出上下文窗口的问题，导致翻译不准确。在现有的方法中，长代码中的大量详细信息使得LLMs难以准确翻译代码的功能结构。", "innovation": "本文提出了一种新颖的零样本代码翻译方法，该方法结合了标识符替换。通过在翻译过程中将用户提供的长标识符替换为通用占位符，我们的方法使LLMs能够关注代码的逻辑结构，通过减少标记数量和内存使用，提高长时间代码翻译的效率和成本效益。我们的实验证明了该方法能够保留语法规则和层次结构信息，并生成更少标记的翻译结果。", "conclusion": "本文提出的方法有效提高了长代码翻译的准确性，并通过减少LSTM模型的内存使用和标记数量，降低了翻译成本。实验结果验证了该方法的有效性，在实际应用中具有成本效益和较高的准确度。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09073", "html_url": "https://arxiv.org/abs/2510.09073", "title": "Literate Tracing", "title_en": "Literate Tracing", "authors": "Matthew Sotoudeh", "background": "随着计算机系统变得越来越大和复杂，软件开发人员需要通过程序文档（由系统专家编写）向未受过训练的用户（系统新手）解释程序的运行机制。现有文档形式存在缺陷，内嵌代码注释往往缺乏全局上下文，而独立的设计文档又往往与代码缺乏具体的联系。因此，需要一种新的文档编写方法来改善这种情况。", "innovation": "本文提出了一种新的程序文档方法——Literate Tracing。通过Literate Tracing，作者可以使用带有注释的软件系统具体执行跟踪来解释软件系统。这种方法通过一个名为TReX的工具实现，TReX生成的文档是互动式的、可视化的，并且由设计保证与程序语义的一致性。文章还展示了TReX在大型系统软件（如Linux内核、Git版本控制系统和GCC编译器）部分组件解释上的应用实例。", "conclusion": "通过Literate Tracing，作者证明了可以通过带有注释的具体执行跟踪来改善软件文档，使得未受过训练的用户更容易理解软件系统的运作机制。TReX工具的成功应用表明，这种新的编写方法能够填补内嵌注释和独立设计文档之间的空白，为复杂软件系统的理解和维护提供了一条新的途径。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09108", "html_url": "https://arxiv.org/abs/2510.09108", "title": "机器学习库的约束导向单元测试生成", "title_en": "Constraint-Guided Unit Test Generation for Machine Learning Libraries", "authors": "Lukas Krodinger,Altin Hajdari,Stephan Lukasczyk,Gordon Fraser", "background": "机器学习（ML）库如PyTorch和TensorFlow在现代应用中极为重要。确保这些库的正确性需要进行测试。然而，ML API通常对输入有严格的约束，如复杂的数据结构（张量），现有的自动化测试生成工具对此类约束不敏感，无法生成合规的输入，导致早期测试失败且代码覆盖率低。在此之前的研究工作已探讨从官方API文档中提取约束。本文着眼于通过PynguinML改进Pynguin测试生成器，利用这些约束生成符合ML API输入的合规测试数据，从而实现更全面的测试和更高的代码覆盖率。", "innovation": "本文提出了一种名为PynguinML的方法，该方法通过利用从API文档中提取的约束来改进Pynguin测试生成器，用于生成符合ML API输入的合规测试数据，从而提高测试效果并增加代码覆盖率。", "conclusion": "通过对PyTorch和TensorFlow的165个模块的评估，结果表明PynguinML显著提升了测试的有效性，相比Pynguin提高了高达63.9%的代码覆盖率。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09058", "html_url": "https://arxiv.org/abs/2510.09058", "title": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding", "title_en": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding", "authors": "Italo Santos,Cleyton Magalhaes,Ronnie de Souza Santos", "background": "大型语言模型（LLM）迅速成为现代软件开发工作流程中的核心组成部分，软件从业者正越来越多地将LLM集成到软件开发生命周期的各个阶段。尽管LLM的应用越来越广泛，但对其实际使用情况及专业人员对其优缺点的认知理解仍然有限。这项研究通过全球调查131名软件从业者，揭示了LLM在各种编码特定任务中的应用情况，以及开发者对LLM益处和限制的看法，反映了在谨慎而实用的态度下逐渐集成这些工具的过程。这些发现为LLM在软件工程中的采用提供了初步、以从业者为中心的视角，为未来的研究和负责任使用提供了关键考虑点。", "innovation": "本研究通过一个包含131名软件从业者的全球调查，提供了关于LLM实际应用和专业人员认知的第一手资料，这种大规模的数据支持的研究方法是创新之处。研究揭示了从业者将LLM视为辅助工具而非独立解决方案的态度，这是一种谨慎而实用的方法。这项研究还强调了对LLM采用过程中几个重要考虑因素的理解，这为未来的研究和负责任使用提供了指导。", "conclusion": "研究发现，软件开发者主要将LLM视为辅助工具，而不是将它们作为独立解决方案。大多数开发者对这些工具持谨慎而实用的态度，反映了在集成LLM时的关注和负责任使用。研究为未来更多关于LLM在软件工程中的集成和负责任使用的研究提供了宝贵的经验和见解。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09308", "html_url": "https://arxiv.org/abs/2510.09308", "title": "AI驱动的健康平台的模型驱动工程方法", "title_en": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms", "authors": "Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi", "background": "人工智能（AI）有潜力通过支持更准确的诊断和个性化的治疗来变革医疗保健。然而，AI的实际应用受到碎片化数据源、严格的隐私规定和技术上构建可靠临床系统的复杂性等因素的限制。", "innovation": "该论文提出了一种专门用于医疗AI的模型驱动工程（MDE）框架，该框架依赖于形式化元模型、领域特定语言（DSL）和自动转换，从高层次规格到运行软件。核心是Medical Interoperability Language（MILA），一种图形DSL，可以让临床医生和数据科学家使用共享的本体定义查询和机器学习管道。通过与联邦学习架构相结合，MILA使机构可以在不交换原始患者数据的情况下进行协作，确保各站点的一致性同时保护隐私。", "conclusion": "该方法在多中心癌症免疫治疗研究中得到了评估。生成的管道表现出强大的预测性能，支持向量机在关键任务中的准确率高达98.5%和98.3%。这表明MDE原理、语义集成和自动化代码生成提供了一条实用途径，用于实现互操作、可再现和值得信赖的数字健康平台。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09134", "html_url": "https://arxiv.org/abs/2510.09134", "title": "慢性护理中患者数字双胞胎的语义框架", "title_en": "A Semantic Framework for Patient Digital Twins in Chronic Care", "authors": "Amal Elgammal,Bernd J. Krämer,Michael P. Papazoglou,Mira Raheem", "background": "当前的数字双胞胎应用大多集中在单一器官或特定数据类型上，缺乏统一和隐私保护的基础。个性化慢性疾病护理需要整合多种健康数据，实现精确诊断和预防性决策，但现有的数字双胞胎应用在这方面有所欠缺。", "innovation": "本文提出了Patient Medical Digital Twin（PMDT），这是一种基于本体的在仿真患者框架，该框架整合了生理、心理社会、行为和基因组信息，形成一致、可扩展的模型。PMDT通过OWL 2.0实现语义互操作性，支持自动推理并跨多种临床环境启用重用。其本体结构化为模块化蓝图（包括患者、疾病和诊断、治疗和随访、轨迹、安全、路径、不良事件等），通过专门的概念视图进行形式化，最终通过专家研讨会、问卷调查和EU H2020 QUALITOP项目的试点研究得到了验证。", "conclusion": "PMDT能够统一异构数据，实现功能知识，支持描述性、预测性和规范性分析，以联邦、隐私保护的方式进行，并填补了数据碎片化和语义标准化方面的空白，为下一代数字健康生态系统提供了验证的基础，推动慢性病护理朝着主动、持续优化和公平管理的方向发展。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09400", "html_url": "https://arxiv.org/abs/2510.09400", "title": "TIT：基于树结构指令调优的LLM代码翻译方法", "title_en": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "authors": "He Jiang,Yufu Wang,Hao Lin,Peiyu Zou,Zhide Zhou,Ang Jia,Xiaochen Li,Zhilei Ren", "background": "大型语言模型（LLMs）在通过大量代码语料库预训练后，在自动化源代码到目标代码的翻译任务中表现出强大的性能。然而，主流的基于LLM的代码翻译方法存在两个主要局限性：首先，它们对语言特定特征非常敏感，这通常会导致源语言的句法特征或词汇引入输出中，引起句法混乱；其次，它们由于过度依赖于功能级别并行数据集而在语义上与原始源代码不一致，导致语义对齐问题。", "innovation": "本文提出了一个名为TIT的新方法，一种基于树结构指令调优的LLM代码翻译方法。具体来说，TIT包括三个模块：首先，通过结构化解析融入语言无关的句法特征来缓解句法混乱；其次，通过语句级别分割和对比匹配生成高质量的细粒度并行数据集以进行对齐；最后，利用两阶段树指令调优模块减轻引入句法信息后对LLM的上下文处理负担。两阶段调优包括：有意识的语法微调使其能够自主理解结构化的句法规则，以及代码生成微调引导模型基于功能级别句法依赖生成准确的目标代码。", "conclusion": "实验结果表明，提出的方法在多个LLM中显著优于现有方法，在代码翻译准确率方面提高了1.22至1.75倍，同时显著减少了句法混乱。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09180", "html_url": "https://arxiv.org/abs/2510.09180", "title": "RepDL: 确保位级可再现的深度学习训练和推理", "title_en": "RepDL: Bit-level Reproducible Deep Learning Training and Inference", "authors": "Peichen Xie,Xian Zhang,Shuo Chen", "background": "在深度学习中，非确定性和不可再现性带来了显著挑战，导致不同运行和平台间结果不一致。这些问题源于随机数生成和浮点计算两个方面。虽然可以通过配置使随机性成为可预测的，但浮点计算的不一致性问题仍然未得到充分解决。", "innovation": "本文引入了RepDL——一个开源库，它确保在多样的计算环境中实现深度学习训练和推理的确定性和位级可再现性。RepDL通过强制浮点计算的正确舍入和顺序无关性来实现这一目标。", "conclusion": "RepDL的源代码可以在此链接中找到。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08969", "html_url": "https://arxiv.org/abs/2510.08969", "title": "基于概念的C++泛型编程", "title_en": "Concept-Based Generic Programming in C++", "authors": "Bjarne Stroustrup", "background": "C++的泛型编程是其核心组成部分之一，但其概念支持并不如某些编程语言那样直接或明确。概念是C++表达泛型代码约束的一种方式，通常用于扩展类型系统以提供更灵活和安全的类型检查和约束机制，但概念的具体应用和设计细节在其标准文档中并未详细阐述或充分展示。作者通过介绍概念在C++中的实现，旨在展示其在泛型编程中的用途和背后的基本思想，而不全面解释C++语言的泛型编程支持或标准库中的支持内容。", "innovation": "作者提出了一种基于概念的C++泛型编程方法，通过提供一个简单的类型系统来消除窄化转换并提供范围检查，而无需额外的记号或运行时开销。这种方法使用概念来扩展类型系统，展示其在泛型编程中的实用性，并揭示背后的基本理念。特别是在类型系统的设计上，作者详细阐述了设计动机、使用模式、概念类型匹配、定义检查等因素。这种类型系统超越了传统方法，提供了更灵活和强大的类型安全性检查。", "conclusion": "作者展示了C++中实现概念的基本技术，并分析其设计理念和实现细节，特别是关系到面向对象编程的价值参数和符号等方面。综上所述，概念为C++泛型编程提供了强有力的工具，进一步增强了其作为面向泛型编程的强大语言的地位，同时也为设计和实现泛型程序提供了新的视角。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09396", "html_url": "https://arxiv.org/abs/2510.09396", "title": "基于仿真的工业机器人导航系统测试研究与实践", "title_en": "Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems", "authors": "Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella", "background": "确保在动态环境下具有鲁棒性的机器人导航是一种关键挑战，传统的测试方法难以覆盖所有操作需求。现有的研究和测试方法往往难以全面涵盖各种操作要求，尤其是在动态环境中保证机器人导航系统的可靠性方面存在不足。", "innovation": "论文介绍了一种名为Surrealist的仿真辅助测试生成框架的应用，该框架最初是为无人机设计的，现被应用于ANYmal四足机器人用于工业检测。该方法通过基于搜索的算法自动生成具有挑战性的避障场景，能够发现手动测试通常无法揭露的失败情况。实验表明，该框架能够有效揭示算法的弱点，并提供一个客观的基准来证明另一算法的优越鲁棒性。", "conclusion": "该框架被集成到ANYbotics的工作流程中进行为期六个月的工业评估，测试了五个专有算法，验证结果证明了其在开发流程中的价值，能够揭示关键故障，提供客观的基准，并加强整体验证流程。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08622", "html_url": "https://arxiv.org/abs/2510.08622", "title": "Text2Stories：评估生成用户故事与利益相关者访谈之间的对齐", "title_en": "Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories", "authors": "Francesco Dente,Fabiano Dalpiaz,Paolo Papotti", "background": "大语言模型（LLMs）可以用于自动化从自然语言输入（如捕获需求 elicitation interviews 的转录）生成软件需求。然而，评估所提取的需求是否真正反映了利益相关者的实际需求仍主要依赖人工。本文提出了 Text2Stories，一种用于评估用户故事与访谈转录之间对齐的任务和度量标准，旨在通过度量用户故事（以用户故事的形式）与访谈参与者实际表达的需求匹配的准确性和完整性来解决这一问题。具体而言，基于一个访谈转录和一组用户故事，该度量标准计算了（1）准确性：支持转录的用户故事的比例；（2）完整性：至少由一个故事支持的转录部分的比例。该方法通过将访谈转录分割成文本片段，并将匹配问题实例化为片段和故事之间的配对问题来实现。实验结果显示，基于LLM的匹配器在保留注释上的宏F1得分达到了0.86，而单独使用嵌入模型的效果则略有不足，但能够提供有效的预阻塞方法。最后，作者展示了如何使用该度量标准进行故事集间的比较（如：人工生成的故事集 vs. 生成的故事集），从而将Text2Stories置于现有的用户故事质量标准的扩展方案中。", "innovation": "作者提出了Text2Stories，这是一种评估用户故事与访谈转录之间对齐的任务和度量标准。该方法通过将访谈转录分割成文本片段，并将其对应于用户故事，从而量化用户故事的准确性和完整性。此外，基于LLM的匹配器能够实现较高的精度，展示了在生成用户故事后的质量评估方面的一种全自动方法。通过提出的具体定量方法，作者为用户故事的质量评价提供了一种新的量化的、可扩展且准确的方法。", "conclusion": "基于上述实验结果，作者认为Text2Stories能够在不依赖人工的情况下，有效地评估生成的用户故事与利益相关者实际表达需求之间的对齐情况，对于提高软件开发中用户故事质量具有重要意义，作为一种可扩展且忠实于源头的补充方法，将推动现有用户故事质量标准的应用与改进。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09155", "html_url": "https://arxiv.org/abs/2510.09155", "title": "联邦数据分析在癌症免疫治疗中的应用：一个保护隐私的合作患者管理平台", "title_en": "Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management", "authors": "Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal", "background": "边连健康是一种多学科方法，注重医疗管理，优先考虑患者需求，从而创造工具、服务和治疗方案。这一范式确保了基于准确患者信息及时交换的主动医疗服务。数字技术和流程创新的发展为边连健康提供了增强工具，通过整合各种医疗服务数据源，加强个性化治疗、预测健康结果和患者管理。然而，这仍然面临着数据架构、应用程序互操作性和安全性的挑战。数据分析可以提供重要见解，但解决方案必须优先考虑终端用户，包括患者和医疗专业人员。这一观点是在一个欧盟资助的项目中，通过敏捷的系统开发生命周期探索的，该项目旨在为接受免疫治疗的癌症患者开发集成的人工智能解决方案。该项目背景是讨论数据架构、互操作性、安全性和患者管理的相关挑战和需求，尤其是在提供个性化护理、预测健康结果和患者管理方面。", "innovation": "论文贡献了一种协作的数字框架，该框架整合了护理连续体中的所有相关方，利用联合大数据分析和人工智能提高决策质量，同时确保隐私。这种方法的核心创新在于利用联邦学习和人工智能技术，保护患者隐私的同时实现有效的数据联合分析和决策支持。分析能力包括治疗建议和不良事件预测，这些能力在实际医疗伙伴参与的试点研究中得到了验证，准确率在70%-90%之间，这表明了该框架的有效性。", "conclusion": "该框架利用联合大数据分析和人工智能技术，确保在不侵犯患者隐私的情况下实现有效的患者管理。实证研究表明，该框架在治疗建议和不良事件预测方面表现良好，具有较高的准确度，验证了其在实际应用场景中的有效性。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09172", "html_url": "https://arxiv.org/abs/2510.09172", "title": "使用声明性映射规则生成CodeMeta：使用ShExML的开放式方法", "title_en": "Generating CodeMeta using declarative mapping rules: An open-ended approach using ShExML", "authors": "Herminio García-González", "background": "如今，软件已成为多个科学领域中计算机方法学进行研究时的一个关键要素。为了确保实验的完全可再现性，研究软件应遵循FAIR原则。然而，研究软件的元数据可以按照不同的数据模型进行表示，并分布在不同的位置。为了促进一致性和标准化，CodeMeta被提出作为一种词汇表来统一表示研究软件的元数据。然而，现有工具在灵活性和适应性方面存在不足。因此，本文提出使用声明性映射规则生成CodeMeta文件，并通过实施三个ShExML中的交叉映射，覆盖了两个现有研究软件制品的元数据生成。", "innovation": "本文提出并实施了一种使用声明性映射规则（ShExML）生成CodeMeta文件的方法，而不是依赖于现有的专用工具，这种方法提高了灵活性和适应性。通过创建三个交叉映射并在ShExML中实施这些映射，最终实现了两个现有研究软件制品的元数据生成。此外，输出结果通过SHACL和ShEx进行验证，并将整个生成工作流自动化，只需在新版本发布时少量用户干预。", "conclusion": "本文为其他开发者提供了一个示例，使之能够将CodeMeta生成工作流纳入其代码库中，从而促进CodeMeta的采用并最终提高研究软件的FAIR性。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09049", "html_url": "https://arxiv.org/abs/2510.09049", "title": "MEC$^3$O: 多专家共识预测代码时间复杂度", "title_en": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "authors": "Joonghyuk Hahn,Soohan Lim,Yo-Sub Han", "background": "源代码复杂性预测对于软件开发和算法分析至关重要。近年来，Baik等人（2025）提出了CodeComplex用于代码时间复杂性的预测。研究表明，未经微调的语言模型（LLMs）在处理某些复杂度类别时表现不佳，这表明没有一个单一的LLM能够胜任所有类别的任务，每种模型在某些类别中有所专长。因此，提出了MEC$^3$O（多专家共识系统），这是一种基于多智能体辩论框架延伸的方法。MEC$^3$O 会根据智能体的表现将其分配到不同的复杂度类别，并向他们提供针对特定类别的指导，从而将智能体转化为专家。这些专家将进行结构化辩论，最后依据加权共识机制整合他们的预测。这种方法有效地处理了思维退化（Degeneration-of-Thought），减少了对单独裁判模型的依赖，并防止了错误多数意见的产生。实验表明，MEC$^3$O 在准确性和宏F1分数方面超越了开源基线，并且在平均宏F1分数上还优于GPT-4o-mini，在平均F1分数上也与GPT-4o和GPT-o4-mini竞争。这证明了多专家辩论和加权共识策略在生成最终预测的有效性。相关代码和数据可从提供的网址获取。", "innovation": "MEC$^3$O 通过将语言模型分配到特定复杂度类别并提供专门的指令将其转化为专家，有效应对了思维退化问题。它采用多专家辩论框架和加权共识机制进行结构化的预测整合，从而提高了复杂度预测的准确性和可靠性，优于现有开源模型和升级版本的GPT模型。MEC$^3$O 的创新点在于其有效地结合了多个模型的预测，避免了单一模型可能产生的偏差。", "conclusion": "实验结果表明，MEC$^3$O 在代码复杂度预测任务上表现优异，优于开源基线和其他大型语言模型。多专家辩论和加权共识策略能够提高复杂度预测的准确性。该系统能够减少对额外裁判模型的需求，避免出现不正确的多数意见，并展示了在实际应用中的竞争力。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.00350", "html_url": "https://arxiv.org/abs/2502.00350", "title": "OrcaLoca: LLM代理框架用于软件问题定位", "title_en": "OrcaLoca: An LLM Agent Framework for Software Issue Localization", "authors": "Zhongming Yu,Hejia Zhang,Yujie Zhao,Hanxian Huang,Matrix Yao,Ke Ding,Jishen Zhao", "background": "近年来，大型语言模型（LLM）代理正在重新定义自动化软件工程（ASE），能够实现自动化编程、问题修复和功能改进。然而，定位软件问题（即精确识别软件问题并导航到相关代码段）仍然是一个重大挑战。当前的方法通常因为无法有效地将LLM代理与精确的代码搜索机制集成而导致性能欠佳。", "innovation": "本文介绍了一种名为OrcaLoca的LLM代理框架，通过优先级调度、行动分解与相关性评分以及距离感知上下文裁剪，提高了软件问题定位的准确性。实验结果显示，OrcaLoca在SWE-bench Lite的功能匹配率上成为开源领域的最新顶级(SOTA)成果（65.33%）。而且，通过其代码生成集成，进一步提高了开源框架的最终解决率6.33个百分点（6.33个百分点）。", "conclusion": "实验结果表明，OrcaLoca在软件问题定位方面表现优异，提升了功能匹配率和开源框架的最终解决率，成为了新的开源SOTA解决方案。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09494", "html_url": "https://arxiv.org/abs/2510.09494", "title": "数据要域的优势：在零信任世界的最少权限数据访问新范式", "title_en": "The Data Enclave Advantage: A New Paradigm for Least-Privileged Data Access in a Zero-Trust World", "authors": "Nico Bistolfi,Andreea Georgescu,Dave Hodson", "background": "随着云基础设施支持动态和分布式工作流，特别是由AI驱动的过程加速了这一趋势，传统的基于角色的持久性权限模型已经成为关键的安全漏洞。根据CSA 2025年云安全深度威胁报告，我们分析了持久权限如何导致云重大泄露。虽然当前的安全工具已经解决了网络和API安全问题，但在细粒度数据访问安全方面仍面临挑战。在数据层面撤销持久权限与网络层面同等重要，尤其对于处理大量有价值数据的企业而言。因此，本白皮书旨在直接填补这一空白，提出了一种基于按需数据要域的创新架构。", "innovation": "本白皮书提出的创新架构是基于按需数据要域，实现零持久权限（ZSP）和即时权限（JIT）原则。这一架构通过撤销静态权限，采用临时数据合约来确保主动保护，围绕按需请求的数据构建分离性，提供精确的访问和实时监测，替代针对数据集的权限分配。通过这种方案，大幅减少了攻击面，防止了权限渗漏，并简化了审计，为企业提供了一条迈向更安全、更稳健的数据环境的重要路径。", "conclusion": "该解决方案显著减少了攻击面，防止了权限渗漏，并简化了审计流程，为企业提供了一种将数据环境向更安全、更稳健转变的重要途径。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.01860", "html_url": "https://arxiv.org/abs/2502.01860", "title": "SWE-Arena: 在软件工程中评估基础模型的互动平台", "title_en": "SWE-Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering", "authors": "Zhimin Zhao", "background": "大型语言模型（LLMs）在软件工程（SE）任务中显示出了显著的潜力，包括代码生成、调试和需求细化等方面。然而，现有的评估框架不足以评估模型在迭代、富有语境的工作流程中的性能，这是SE活动的特征。为了应对这一局限，我们介绍了SWE-Arena，一个用于评估SE任务中基础模型（FMs）的互动平台。", "innovation": "SWE-Arena作为评估FMs的平台，引入了新的度量标准，如模型一致性分数和对话效率指数，这分别衡量了模型输出的一致性和模型在对话交流中的表现时所需交互轮数的效率。此外，还引入了名为RepoChat的新功能，自动将仓库相关上下文（如问题、提交、拉取请求等）注入对话中，进一步使评估与实际开发流程对齐。", "conclusion": "本文介绍了SWE-Arena的设计和能力，强调了该平台在提升SE中基础模型评估及应用方面的重要潜力。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2208.08067", "html_url": "https://arxiv.org/abs/2208.08067", "title": "K-ASTRO: 结构感知的LLM适应技术在代码漏洞检测中的应用", "title_en": "K-ASTRO: Structure-Aware Adaptation of LLMs for Code Vulnerability Detection", "authors": "Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach", "background": "大型语言模型（LLMs）正在重塑软件工程任务，包括代码漏洞检测——这是软件安全的一个关键领域。然而，现有的方法通常依赖于资源密集型模型或基于图的技术，这限制了它们的易用性和实用性。", "innovation": "K-ASTRO 是一种轻量级的Transformer模型，它结合了来自LLMs的语义嵌入与Abstract Syntax Trees (ASTs)结构特征，提高了代码漏洞检测的效率和准确性。采用了一种受变异测试启发的AST基于的增强技术、具有增强AST特征的结构感知注意机制以及联合适应流水线来统一代码语义和语法。实验结果表明，K-ASTRO在BigVul、DiverseVul和PrimeVul三个大规模数据集上展示了最先进的性能，同时通过在CPU上的快速推理和最少的训练时间实现了实用化。通过提供一个可扩展、可解释且高效的解决方案，K-ASTRO弥合了LLM进展与实用的软件漏洞检测之间的差距，并提供开源工具以促进进一步研究。", "conclusion": "K-ASTRO通过结合来自LLMs的语义嵌入与AST结构特征，改进了代码漏洞检测的效率和准确性。此外，通过引入结构感知注意机制和联合适应流水线，实现了快速推理和高效的实用化目标。K-ASTRO不仅显示了先进的性能，还提供了解决黑盒问题的透明度，通过开源工具促进了进一步研究。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.12347", "html_url": "https://arxiv.org/abs/2506.12347", "title": "为什么AI代理仍然需要您：现实世界中开发人员-代理协作的发现", "title_en": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild", "authors": "Aayush Kumar,Yasharth Bajpai,Sumit Gulwani,Gustavo Soares,Emerson Murphy-Hill", "background": "SWE代理能够在像SWE Bench这样的基准上自主执行开发任务，但在处理复杂和模糊的现实世界任务时仍面临挑战。因此，SWE代理通常设计为与开发者互动，以促进协作解决问题。", "innovation": "通过观察19名开发者在开发工具内部与代理解决33个之前已经参与的代码库中的开放问题，研究发现：通过逐步解决问题比一次性解决问题更成功；积极与代理合作并迭代其输出也更成功，尽管他们面临着信任代理响应和调试测试的挑战。", "conclusion": "为了促进成功的协作，SWE代理和开发者在整个软件开发过程中应积极参与任务。SWE代理可以通过挑战开发者并积极参与讨论，而不是仅仅做出结论或盲目服从来实现这一点。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.18229", "html_url": "https://arxiv.org/abs/2502.18229", "title": "JuliaGrid: 一种基于Julia语言的开放源代码电力系统状态估计框架", "title_en": "JuliaGrid: An Open-Source Julia-Based Framework for Power System State Estimation", "authors": "Mirsad Cosovic,Ognjen Kundacina,Muhamed Delalic,Armin Teskeredzic,Darijo Raca,Amer Mesanovic,Dragisa Miskovic,Dejan Vukobratovic,Antonello Monti", "background": "现代电力系统由于供电需求的增长和各种能源的整合，结构变得越来越复杂。大规模系统的监测依赖于高效的状态估计，这是一项计算上具有挑战性的任务，需要高效的仿真工具来进行电力系统稳态分析。鉴于这一观察，本文提出了一种名为JuliaGrid的开放源代码框架，该框架是用Julia编程语言编写的，用于在多个平台上实现高性能执行，并提供了可观测性分析、加权最小二乘法和最小绝对值估计器、坏数据分析以及与测量有关的各种算法。", "innovation": "JuliaGrid框架针对电力系统状态估计，实现了复杂算法，能够在多种平台上高效运行。该框架包括可观测性分析、加权最小二乘法和最小绝对值估计器、坏数据分析以及与测量相关的各种算法。此外，它还实现了潮流计算和最优潮流计算，能够为状态估计程序生成测量数据。利用计算高效的算法，JuliaGrid能够解决大规模系统中的所有方法，且相比其他开源工具具有竞争力。它专门针对准稳态分析进行设计，并具有自动检测和重复使用计算数据以提高性能的能力。这些能力在包含10000、20000和70000个母线的系统上得到了验证。", "conclusion": "JuliaGrid框架实现了高效的电力系统状态估计，支持复杂算法，并具有多种针对大规模系统的功能，能够在多种平台上提供高性能，并且特别适用于准稳态分析，具有自动检测和重复使用计算数据的功能。通过验证，JuliaGrid在各种电力系统模型中表现出良好的性能。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.16485", "html_url": "https://arxiv.org/abs/2504.16485", "title": "开发者对AI生成代码的自我声明：一项实践分析", "title_en": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices", "authors": "Syed Mohammad Kashif,Peng Liang,Amjed Tahir", "background": "AI代码生成工具在开发人员中获得了显著的受欢迎程度，它们能够生成代码以帮助软件开发。现有研究主要关注AI生成代码的质量，如正确性和安全性。然而，在实际的软件开发过程中，区分AI生成代码和人类编写的代码是前提条件。因此，开发者需要明确声明AI生成的代码。本研究旨在了解开发人员声明AI生成代码的方式，以及他们选择声明或不声明的原因。", "innovation": "本研究采用了混合方法，包括数据挖掘 GitHub 代码仓库收集AI生成代码片段实例，以及对从业者进行后续调查以收集相关数据。研究发现大多数开发人员会明确声明AI生成的代码，但也有一部分开发人员认为没有必要声明。研究提供了针对开发人员声明AI生成代码的指导意见，旨在解决伦理和代码质量方面的问题。", "conclusion": "我们的研究表明，76.6%的从业者会时常或总是声明AI生成的代码，而23.4%的从业者则不进行声明。声明AI生成代码的原因包括追踪和监控代码未来审查和调试的需求，以及伦理方面的考虑。而不进行声明的原因包括对AI生成代码进行了大量修改以及认为声明是不必要的活动。最后，本研究为开发人员提供了声明AI生成代码的建议，以解决伦理和代码质量方面的问题。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.22424", "html_url": "https://arxiv.org/abs/2503.22424", "title": "利用LLM驱动的迭代代码图搜索进行问题定位", "title_en": "Issue Localization via LLM-Driven Iterative Code Graph Searching", "authors": "Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu", "background": "问题解决旨在根据问题描述在实际代码仓库中生成修复补丁。问题定位是准确问题解决的基础。最近，基于LLM的问题定位方法已经表现出最先进的性能。然而，这些方法要么从问题描述中提到的文件开始搜索，要么在整个仓库中搜索，无法有效平衡搜索空间的广度和深度，难以高效地找到目标。此外，它们允许LLM自由探索整个代码库，这使得控制搜索方向以防止搜索错误目标变得困难。", "innovation": "提出了一种名为CoSIL的LLM驱动的、无需训练或建模的强大功能级问题定位方法。CoSIL采用两阶段代码图搜索策略。首先在文件级别利用动态构建的模块调用图进行广泛的探索，然后在功能级别通过将模块调用图扩展为函数调用图并进行迭代搜索进行深入分析。为了精确控制搜索方向，CoSIL设计了修剪器来过滤无关的方向和不相关的上下文。为了防止长上下文中的不正确交互格式，引入了一个反射机制，在短上下文中使用附加独立查询来增强格式化能力。", "conclusion": "实验结果表明，CoSIL在SWE-bench Lite和SWE-bench Verified上的Top-1定位准确率分别达到43.3%和44.6%，使用Qwen2.5-Coder-32B的平均性能超越了最先进的方法96.04%。当CoSIL集成到无代理问题解决方法Agentless中时，问题解决率提高2.98%至30.5%。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.20854", "html_url": "https://arxiv.org/abs/2505.20854", "title": "Large Language Model作为法官的度量标准以弥补软件工程任务中的人类评估差距", "title_en": "An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks", "authors": "Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,Kui Liu,Xin Xia,David Lo", "background": "大型语言模型（LLMs）和其他自动化技术被广泛用于支持软件开发人员，通过生成代码片段、补丁和评论等软件制品。然而，准确评估这些生成制品的正确性仍然是一个显著的挑战。一方面，人类评估可以达到高精度，但需要大量人力且缺乏可扩展性。另一方面，许多自动评估标准是可扩展的，需要的人力投入较少，但却难以准确反映生成软件制品的实际正确性。因此，需要一种能够平衡准确性和可扩展性的评估度量标准。", "innovation": "本文提出了SE-Jury，这是第一个针对LLM作为集合法官的具体设计来准确评估生成软件制品正确性的评估度量标准。SE-Jury通过定义五个不同的评估策略，每个策略由独立的法官实现，并通过一个动态的团队选择机制选出最合适的法官团队，最终通过集合方式得出最终正确性分数。研究结果表明，SE-Jury在不同软件工程基准测试中的一致性与人类判断之间具有较高的相关性，相较于现有自动度量标准，改进幅度从29.6%到140.8%不等。特别是在代码生成和程序修复任务中，SE-Jury达成的人类注释者一致水平接近于人工注释者之间的内部一致性。这些发现强调了SE-Jury在软件工程任务中作为一个具有可扩展性和可靠性的替代人类评估的可能性。", "conclusion": "结果表明，SE-Jury在不同软件工程任务中优于现有的自动化度量标准，尤其在代码生成和程序修复任务中表现突出，能够有效弥补自动化评估与人类评估之间的差距。这表明SE-Jury具有潜力成为软件工程任务中的一种可靠和可扩展的评估替代方案。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.24380", "html_url": "https://arxiv.org/abs/2509.24380", "title": "Agentic Services Computing", "title_en": "Agentic Services Computing", "authors": "Shuiguang Deng,Hailiang Zhao,Ziqi Wang,Guanjie Cheng,Peng Chen,Wenzhuo Qian,Zhiwei Ling,Jianwei Yin,Albert Y. Zomaya,Schahram Dustdar", "background": "大型语言模型（LLM）驱动的代理的兴起正在改变服务计算，使其从静态、请求驱动的功能转向动态、目标导向且嵌入社会的多代理生态系统。", "innovation": "提出了一种名为Agentic Services Computing（ASC）的概念，重新定义了服务作为一个自主、适应和协作的代理，这些代理能够在开放和不确定的环境中感知、推理、行动和进化。ASC围绕四个阶段的生命周期展开：设计、部署、运营和进化。此外，它通过四个研究维度进行阐述：(i) 感知和上下文建模，(ii) 自主决策，(iii) 多代理协作，(iv) 评估与一致性和可信度。", "conclusion": "通过将服务计算的基本原则与基于LLM的代理的最新进展结合起来，ASC提供了一个统一且前瞻性框架，用于构建智能、负责任和以人为中心的服务生态系统。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.04295", "html_url": "https://arxiv.org/abs/2508.04295", "title": "EvoC2Rust: 一种面向项目的C到Rust语言转换骨架引导框架", "title_en": "EvoC2Rust: A Skeleton-guided Framework for Project-Level C-to-Rust Translation", "authors": "Chaofan Wang,Tingrui Yu,Chen Xie,Jie Wang,Dong Chen,Wenrui Zhang,Yuling Shi,Xiaodong Gu,Beijun Shen", "background": "随着安全关键系统的构建需求增加，将遗留的C语言代码转换为Rust变得越来越重要。现有方法要么难以符合代码安全性和规约性要求，要么无法生成语义等价的Rust代码。此外，基于规则的方法和基于大语言模型（LLM）的方法在大规模程序上都表现出限制。现有的两种方法要么受限于小规模代码，要么在生成语义正确和类型安全的Rust代码时效果不佳。", "innovation": "本文提出了一种自动化的框架EvoC2Rust，用于转换完整的C项目到等效的Rust项目。EvoC2Rust利用骨架引导的翻译策略进行项目层面的翻译。框架分为三个阶段：首先分解C项目为功能模块，使用增强特征映射的LLM转换定义和宏，生成可编译的Rust骨架；其次逐步翻译函数，替换相应的骨架占位符；最后通过结合LLM和静态分析修复编译错误。EvoC2Rust通过进化增强结合了基于规则和基于大语言模型方法的优点。在开源基准和六个工业项目上的评估表明，EvoC2Rust在项目级别的C到Rust翻译性能优越，语法准确率和语义准确率分别比最强的基于大语言模型基线高出17.24%和14.32%，同时代码安全性比最佳基于规则的工具高出43.59%。", "conclusion": "本研究提出了一种新的自动化框架EvoC2Rust，用于将完整的C项目转换为等效的Rust项目。EvoC2Rust通过骨架引导的翻译策略、分阶段逐步翻译和综合进化增强的方法，解决了传统方法在安全性和语义正确性上的限制。通过在多个项目上的实验证明，EvoC2Rust在C到Rust转换方面显示出卓越的性能，特别是在语法和语义准确性方面表现出显著优势。"}
{"llm_update_time": "20251013", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG：统一且可扩展的代码库生成的仓库规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大语言模型在生成单个函数或单个代码文件方面表现出色，但生成完整的代码库仍然是一项基本挑战。当前的方法依赖于自然语言规划，这往往导致不清晰的规格说明、组件的对齐问题以及由于其内涵的模糊性和缺乏结构而导致的脆弱设计。这是由于这些系统无法有效处理复杂性的原因。", "innovation": "该论文提出了Repository Planning Graph（RPG），一种结构化的表示，统一地编码功能、文件结构、数据流和函数。RPG通过使用显式的蓝图替代自由形式的自然语言，使长视角的规划得以一致地进行。基于RPG，开发了一个名为ZeroRepo的图驱动框架，该框架分为三个阶段：规划阶段、实现阶段和图引导的代码生成及测试验证。", "conclusion": "实验结果表明，ZeroRepo在RepoCraft基准测试上生成了近36000代码行和445000代码标记，平均是最佳基线Claude Code的3.9倍，是其他基线的68倍。此外，成功的覆盖率达到了81.5%，测试准确率达到69.7%，分别比Claude Code提高了27.3和35.8个百分点。进一步的分析显示，RPG能够处理复杂的依赖关系，通过接近线性扩展实现更复杂的规划，并提高智能体对代码库的理解，从而加速定位。"}
