# 20250727
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 视觉化帮助AI理解数据吗？ [PDF](https://arxiv.org/pdf/2507.18022), [HTML](https://arxiv.org/abs/2507.18022)
### Authors
Victoria R. Li,Johnathan Sun,Martin Wattenberg
### Background
本文探讨了图表和图形对于AI系统的帮助作用，提出了两个商业化的视觉-语言模型（GPT 4.1和Claude 3.5），通过三个代表性数据分析任务，研究在有散点图等图表辅助的情况下，这些模型对数据集的描述能力和准确性是否得到提升。
### Innovation
实验结果显示，在复杂数据集分析任务中，当提供散点图等图表时，这两个模型对数据集的描述更加精确和准确。对比空白图表和不匹配数据的图表基线模型，实验验证了图表内容的提升作用，初步证明了AI系统可以从可视化中受益，类似于人类。
### Conclusion
本文的研究结果表明，AI系统在进行数据分析时，可以通过参考图表来提升理解准确性和描述的精确度，这种能力类似于人类利用图形化视觉来分析数据的方法。
## 2. `cs.AI` - 模型架构发现的AlphaGo时刻 [PDF](https://arxiv.org/pdf/2507.18074), [HTML](https://arxiv.org/abs/2507.18074)
### Authors
Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu
### Background
虽然AI系统的功能呈现指数级提升，但AI研究的步伐依然受限于人类的认知能力，形成了一个日益严峻的发展瓶颈。为此，本文提出了ASI-Arch，这是首次将人工智能超智能应用于AI研究中的神经架构发现领域，实现了完全自主的体系，颠覆了以往人类定义搜索空间的神经架构搜索方法。AI可以自主进行科学探索，提出新颖的架构概念，实现编码，通过严格的实验和经验验证其性能。
### Innovation
本文引入了一种从自动化优化到自动化创新的新范式，并通过ASI-Arch自主进行了1773次实验，在2万台GPU小时的计算量下，发现了106种创新的、处于前沿的线性注意力架构。这些架构展示了系统性超越人类设计基准的新兴设计原则，展示了未知的架构创新路径。更重要的是，论文首次确立了科学发现的理论计算扩展规律，证明了架构突破可以通过计算资源扩展实现，从根本上将研究进程从人力限制转变为计算可扩展过程。
### Conclusion
本文详细分析了这些突破背后的涌现设计模式和自主研究能力，建立了自我加速AI系统的蓝图。
## 3. `cs.AI` - 避免确定化的时间线基规划策略合成 [PDF](https://arxiv.org/pdf/2507.17988), [HTML](https://arxiv.org/abs/2507.17988)
### Authors
Dario Della Monica,Angelo Montanari,Pietro Sala
### Background
该论文基于时间线的定性规划模型，将领域分为相互独立但相互作用的组件，并通过定性的时间约束（同步规则）来控制这些组件随时间的行为。已知该模型的计划存在问题是PSPACE完全的，特别是通过将其归约到非确定性有限自动机的非空性问题，已经证明了其PSPACE成员资格。然而，直接使用非确定性自动机来合成规划策略是不可行的，因为需要进行昂贵的确定化步骤。
### Innovation
本文识别出一种时间线基定性规划模型的片段，其计划存在问题可以直接映射到确定性有限自动机的非空性问题，从而可以直接合成策略。此外，论文还识别出一个符合此类确定性片段的亚集Allen的链接关系。
### Conclusion
通过避免确定化步骤，直接将时间线基定性规划模型的问题映射到确定性有限自动机非空性问题中，实现了更为高效的规划策略合成。
## 4. `cs.AI` - SMARTAPS：增强型LLM在运营管理中的应用 [PDF](https://arxiv.org/pdf/2507.17927), [HTML](https://arxiv.org/abs/2507.17927)
### Authors
Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang
### Background
大型语言模型（LLMs）提供了提升用户与传统算法和工具在实际应用中交互的机会。高级规划系统（APS）利用优化技术帮助运营规划人员创建、解释和修改操作计划，但在实际应用中，由于需要经常性的顾问费用，许多用户被 APS 排斥在外。因此，为了满足供应链规划人员对更易访问的 APS 的需求，本文提出了一种基于工具增强型大语言模型的对话系统——SmartAPS。
### Innovation
SmartAPS 系统提供了一种直观的自然语言聊天界面，使运营规划人员能够查询信息、执行假设性分析、获取建议并执行场景分析，以更好地管理其运营。该系统利用工具增强的大语言模型，提升了用户交互的便捷性和可访问性，降低了使用高级规划系统的门槛。
### Conclusion
SmartAPS 提供了一种新的操作管理方式，通过工具增强的大语言模型技术，使运营规划人员能够更加方便、直观地进行操作计划的管理。这一系统不仅提升了运营效率，还增强了用户对高级规划工具的易用性和接受度。
## 5. `cs.AI` - I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis [PDF](https://arxiv.org/pdf/2507.17874), [HTML](https://arxiv.org/abs/2507.17874)
### Authors
SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam
### Background
近年来，代理系统在数据分析中的应用不断进步，强调了通过多智能体框架和编排层来实现洞察生成的自动化。尽管这些系统能够有效管理查询翻译、数据转换和可视化等任务，但往往忽视了作为分析性思维基础的结构化推理过程。较大的语言模型（LLMs）通常作为通用问题解决者进行训练，导致其推理或思维步骤不符合特定任务的固定过程。因此，现实世界的数据分析需要一致的认知工作流程：解释模糊的目标、基于上下文知识进行定位、构建抽象计划，并根据中间结果调整执行过程。
### Innovation
本文提出了I2I-STRADA（Information-to-Insight via Structured Reasoning Agent for Data Analysis），这是一种代理架构，旨在明确定义这一推理过程。I2I-STRADA关注如何通过模块化的子任务来建模分析的发展过程，这些子任务反映了分析推理的认知步骤。评估结果表明，I2I-STRADA在计划一致性和洞察力对齐方面优于先前的系统，强调了在数据分析代理设计中结构化认知流程的重要性。
### Conclusion
在DABstep和DABench基准数据集上的评估显示，I2I-STRADA在规划连贯性和洞察力对齐方面表现出色，突显了结构化认知工作流程在数据分析代理设计中的重要性。
## 6. `cs.AI` - 积极评估和学习关键区别：从急诊分诊记录中检测疫苗安全信号 [PDF](https://arxiv.org/pdf/2507.18123), [HTML](https://arxiv.org/abs/2507.18123)
### Authors
Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black
### Background
随着COVID-19疫苗的快速开发，全球社会展现了对抗传染病的能力。然而，由于临床试验和早期广泛实施过程中有限的安全数据收集窗口，对于上市后的监控系统的需求增加。本研究旨在利用自然语言处理技术和主动学习，快速开发一种分类器，用于从急诊部门笔记中检测疫苗潜在的安全问题。急诊部门的初步分诊笔记提供了进入医疗系统时患者的简明重要信息，可以显著提高对疫苗安全信号的及时监控。关键词分类方法虽然有效，但可能会产生误报，并且需要频繁调整关键词。这在疫苗相关的急诊呈现罕见且与其它急诊原因相似的背景下被加剧。自然语言处理可以提供更准确和高效的方法，尽管这些方法通常需要稀缺的标注数据。
### Innovation
本研究结合了主动学习、数据增强以及主动学习和评估技术，以创建一个能够从急诊分诊笔记中增强疫苗安全监控的分类器。这种方法可以优化标注过程和标注数据的质量，从而实现更快的模型实施和提高模型性能。主动学习特别优化了注释过程和注释数据的质量，而数据增强则增加了训练数据的多样性，有助于提高模型的泛化能力。
### Conclusion
本研究通过利用自然语言处理技术和主动学习方法，提出了一种新的分类器，能够有效地从急诊分诊笔记中检测到疫苗的安全信号问题。这种方法不仅提高了在有限数据条件下的模型性能，还减少了需要频繁调整关键词的问题。该研究对未来疫苗上市后的安全监控系统的发展提供了新的思路。
## 7. `cs.AI` - ASP辅助符号回归：揭示流体力学中的隐含物理 [PDF](https://arxiv.org/pdf/2507.17777), [HTML](https://arxiv.org/abs/2507.17777)
### Authors
Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis
### Background
与传统的机器学习（ML）方法不同，常常被批评为‘黑箱’，符号回归（SR）因其能够揭示复杂物理系统的可解释数学关系而饱受赞誉，无需事先假设模型结构。鉴于在流体力学中，对流体力学物理的理解与准确预测同样重要，本研究旨在应用SR来建模一个基本的三维不可压缩流在矩形通道中的流动，特别是在层流条件下研究轴向速度和压力场。通过使用PySR库，直接从数值模拟数据中推导出紧凑的符号方程，揭示了流体动力学的关键特性。这些方程不仅能够逼近所研究流体流动中观察到的双峰速度分布和压力降，还与文献中的解析解完美吻合。此外，文章提出了一种创新的方法，将SR与知识表示框架（KRR）中的回答集编程（ASP）相结合，结合了SR的生成能力和ASP的声明性推理优势。提出的SR/ASP混合框架确保生成的符号表达不仅在统计上准确，而且在物理上合理，符合特定领域的原则。
### Innovation
提出了一种将SR与ASP相结合的创新方法，将SR的生成能力与ASP的声明性推理结合起来，从而确保SR生成的符号表达不仅在统计上准确，而且在物理上合理，符合特定领域的原则。
### Conclusion
本研究强调了SR简化复杂流动行为以产生简洁可解释的方程，以及知识表示方法如何提高数据驱动SR模型与领域原理的一致性和可靠性的两个关键贡献。通过对三维渠道流动的研究，为将此类混合方法整合到高效框架中铺平了道路，特别是在需要可解释预测和实时数据分析的场景下。
## 8. `cs.AI` - AlphaPhysics术语重写系统在物理考试代数表达式评分中的应用 [PDF](https://arxiv.org/pdf/2507.18337), [HTML](https://arxiv.org/abs/2507.18337)
### Authors
Peter Baumgartner,Lachlan McGinness
### Background
评估学生对物理题目答案的正确性是一个具有挑战性的任务。本文提出了一种自动标记物理学考试的方法，通过结合计算机代数系统、SMT求解器和术语重写系统来评估学生答案的正确性。文章还探讨了如何使用大规模语言模型来解释和纠正学生的回答，并将这些回答转换为机器可读格式。
### Innovation
本文创新点在于开发了一个专门针对物理考试问题的术语重写系统，并详细描述了此系统的开发过程，包括保证该系统具备终止性和会聚性的复杂步骤。此外，还使用了两个方法进行自动化定理证明：现成的SMT求解器和针对包含三角表达式的物理问题定制的术语重写系统。
### Conclusion
研究团队评估了该系统在2023年澳大利亚物理奥林匹克竞赛中的1500多个真实学生考试响应上，结果表明该系统在自动化评分方面表现良好。
## 9. `cs.AI` - 比较回答集编程中非最小化析取语义 [PDF](https://arxiv.org/pdf/2507.18198), [HTML](https://arxiv.org/abs/2507.18198)
### Authors
Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal
### Background
本文比较了四种不同的析取语义，这些语义与传统的稳定模型不同，不遵循模型最小化的原则。与传统的稳定模型不同，这些方法提供了非最小化的析取语义。此类方法包括Cabalar和Muñiz的‘证明模型’、Doherty和Szalas的‘强支持模型’以及Aguado等人提出的‘分支’和Shen与Eiter提出的‘确定推理’（DI）语义。文章证明了三项方法（分支、证明模型和DI语义的一个合理推广）实质上是相同的，构成了单一的方法在不同定义下表现一致。并且这种共同的语义总是稳定模型的超集（实际上，在任何上下文中都是），并且比强支持模型严格更强。
### Innovation
作者比较了四种不同的析取语义方法，并证明了其中三种方法实质上是相同的，提供了共同的非最小化析取语义。这种共同的语义不仅扩展了稳定模型，还比强支持模型更强大。
### Conclusion
本文的主要结论是，三种方法（分支、证明模型及其合理的扩展）实际上构成了相同的非最小化析取语义，这种共同的语义提供了稳定模型的超集，并且在强度上优于强支持模型。
## 10. `cs.AI` - Agentic AI框架用于端到端医学数据推理 [PDF](https://arxiv.org/pdf/2507.18115), [HTML](https://arxiv.org/abs/2507.18115)
### Authors
Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha
### Background
由于医疗健康领域的机器学习解决方案在建立和部署过程中存在高昂的费用和繁重的人力任务，涉及碎片化的预处理流程、模型兼容性问题以及严格的数据隐私限制。本研究旨在解决这些挑战，通过建立一个自动化整个临床数据管道的Agentic AI框架，从数据摄取到推理，通过模块化、任务特定的代理系统来实现自动化操作。这些代理能够处理结构化和非结构化数据，自动筛选特征、选择模型和推荐预处理方法，而无需人工干预。
### Innovation
该研究引入了Agentic AI框架，这是一种自动化整个临床数据管道的系统，通过模块化任务特定的代理来实现从数据摄取到推理的全过程自动化。该框架支持结构化和非结构化数据处理，能够自动选择特征、模型和推荐预处理方法。例如，在结构化数据（焦虑数据）和非结构化数据（结肠镜息肉数据）的情况下，首先由Ingestion Identifier代理识别文件类型，然后由Data Anonymizer确保隐私合规，接着Feature Extraction代理根据嵌入法处理表格数据，使用多阶段的MedGemma方法处理图像数据以推断模态和病症名称。这些特征指导Model-Data Feature Matcher代理选择最佳模型。Preprocessing Recommender和Preprocessing Implementor代理根据数据类型和模型需求提供定制化的预处理。最后，Model Inference代理运行选定模型并生成可解释的输出，使用像SHAP、LIME和DETR注意力图这样的工具。该框架通过自动化机器学习生命周期中的这些摩擦环节，大大减少了重复专家干预的需求，提供了一条适用于临床环境的可扩展、成本效益高的AI实现途径。
### Conclusion
该Agentic AI框架为医学数据推理过程提供了一种端到端自动化解决方案，通过引入模块化任务特定的代理系统，能够处理结构化和非结构化数据，自动筛选特征、选择模型、推荐预处理方法，确保隐私合规，并生成可解释的输出，从而降低反复专家干预的需求，为在临床环境中实现可扩展、低成本的AI应用提供了一条高效途径。
## 11. `cs.AI` - 保护基本权利的AI风险管理基础 [PDF](https://arxiv.org/pdf/2507.18290), [HTML](https://arxiv.org/abs/2507.18290)
### Authors
Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor
### Background
本章介绍了基于欧盟人工智能法案背景的AI定性风险评估的概念框架，探讨了法律合规和基本权利保护的复杂性，通过定义平衡和非经典推理相结合的方法来应对这些挑战。定义平衡利用比例分析解决竞争性权利之间的冲突，而非经典推理则适应了法律决策的动态性。
### Innovation
提出了一种结合定义平衡和非经典推理的方法来系统地分析AI部署场景，识别潜在的法律违反和多层次的基本权利影响。该框架为AI风险管理提供了哲学基础，并强调了在概念上理解和交互AI部署场景与基本权利间关系的重要性，以及如何根据具体情境促进或撤销权利。
### Conclusion
该研究提出了分层方法来评估高风险AI系统和泛用人工智能系统(GPAI)的风险，强化了对基本权利保护的AI风险管理，并计划开发正式模型和有效的算法来提升AI风险管理，将理论洞察与实际应用相结合，以支持负责任的AI治理。
## 12. `cs.AI` - 通过信息瓶颈 revisit 大语言模型推理 [PDF](https://arxiv.org/pdf/2507.18391), [HTML](https://arxiv.org/abs/2507.18391)
### Authors
Shiye Lei,Zhihao Cheng,Kai Jia,Dacheng Tao
### Background
大语言模型（LLMs）通过强化学习带有验证奖励（RLVR）已经展示了在推理能力方面的显著进步。通过利用简单的基于规则的奖励，RL 有效地激励 LLM 生成扩展的链式思考（CoT）推理轨迹，逐步引导其向正确答案迈进。然而，现有的方法主要依赖于启发式和直觉，限制了有原则的方法的发展。
### Innovation
本文提出了一种基于信息瓶颈（IB）原理的 LLM 推理理论化表征，引入了 IB 意识下的推理优化（IBRO）框架，该框架鼓励推理轨迹既有关于最终正确答案的信息性，又在多样的提示中具有可泛化性。通过推导出实用的标记级代理目标，并提出有效的近似方法，形成了轻量级的信息瓶颈正则化方法。该技术可以无缝集成到现有的基于 RL 的后训练框架中，而无需额外的计算开销，只需一行代码修改即可。实验证明，该方法在多个数学推理基准和 RL 算法中提高了 LLM 的推理性能，
### Conclusion
本文通过信息瓶颈原理重新审视大语言模型的推理，提出了一种基于信息瓶颈的推理优化框架，简化了 RL 的后训练框架，有效提升了 LLM 的推理性能。
## 13. `cs.AI` - Multi-Agent Guided Policy Optimization [PDF](https://arxiv.org/pdf/2507.18059), [HTML](https://arxiv.org/abs/2507.18059)
### Authors
Yueheng Li,Guangming Xie,Zongqing Lu
### Background
在合作多智能体强化学习(MARL)中，受限于部分可观测性和有限通信等实际约束，集中训练与分散执行(CTDE)已成为主导的范式。现有的CTDE方法往往未能充分利用集中训练，或者缺乏理论保证。
### Innovation
提出了一种新的框架——多智能体引导策略优化(MAGPO)，该框架通过将集中指导与分散执行结合，更好地利用集中训练。MAGPO使用自回归联合策略进行可扩展且协调的探索，并明确地与分散策略对齐，以确保在部分可观测性下的可部署性。提供理论保证，证明了策略改进的单调性，并在6个不同环境中的43个任务上进行了实证评估。
### Conclusion
结果证明，MAGPO在性能上优于强CTDE基线，并且能够与完全集中的方法匹敌或超越，为分散的多智能体学习提供了一个有原则且实际的解决方案。代码和实验数据可以在指定网址找到。
## 14. `cs.AI` - 使用强化学习优化呼叫中心运营：值迭代与渐近策略优化的比较 [PDF](https://arxiv.org/pdf/2507.18398), [HTML](https://arxiv.org/abs/2507.18398)
### Authors
Kwong Ho Li,Wathsala Karunarathne
### Background
本文探讨了使用强化学习（RL）优化呼叫中心的呼叫路由，以减少客户等待时间和员工空闲时间的方法。研究中比较了两种方法：基于模型的方法使用值迭代（VI）在已知系统动态条件下进行优化，以及基于经验的方法使用渐近策略优化（PPO）进行学习。
### Innovation
研究通过将问题建模为马尔可夫决策过程（MDP），并在技能基路由（SBR）框架下进行建模，并使用蒙特卡洛离散事件模拟（DES）结合OpenAI Gym环境进行模型自由训练，这是一种新的研究方法。此外，研究对比了值迭代（VI）和渐近策略优化（PPO）在优化呼叫中心操作方面的性能，结果表明PPO在奖励、客户等待时间和员工空闲时间方面表现更优，尽管训练时间较长。
### Conclusion
通过搭载PPO方法，能够在呼叫中心运营中实现更高的效率和更好的服务体验，尽管需要更多的训练时间。
## 15. `cs.AI` - E.A.R.T.H.: 通过生成模型中的错误构建创意进化的结构 [PDF](https://arxiv.org/pdf/2507.18004), [HTML](https://arxiv.org/abs/2507.18004)
### Authors
Yusen Peng,Shuhua Mao
### Background
当前AI主要依赖模仿，缺乏真正的创新。本文探讨如何使AI从模仿转向真正的创造力，并提出了E.A.R.T.H.框架，这是一种五阶段生成管道，通过错误生成、放大、筛选、转换和利用反馈将模型生成的错误转化为创意资产。
### Innovation
提出了E.A.R.T.H.框架，这是一种创新的五阶段生成管道，能通过错误生成、放大、筛选、转换和利用反馈将模型生成的错误转化为创意资产。管道结合了认知科学和生成建模，通过结构化提示、语义评分和人工监督来操作创意潜力。实验结果表明，通过这种框架，创意评分提高了52.5%，最终输出提高了70.4%，贴近度和相关性显著提升，从而证明了基于错误和反馈驱动的生成可以提升创造力。
### Conclusion
此研究展示了错误中心、反馈驱动的生成可以增强创造力，提供了一条向自我进化的、与人协同的创意AI发展的可扩展路径。
## 16. `cs.AI` - GPU加速Compact-Table传播算法 [PDF](https://arxiv.org/pdf/2507.18413), [HTML](https://arxiv.org/abs/2507.18413)
### Authors
Enrico Santi,Fabio Tardivo,Agostino Dovier,Andrea Formisano
### Background
约束编程是在Logistics编程中于八十年代发展的；如今，所有Prolog系统都包含能够处理有限域变量约束求解的模块。这种工作中，研究了一种特定形式的约束，即所谓的表格约束，用于变量值作为备选选项的枚举。尽管这些可以被所有其他约束最终表达，表格可以模拟，但因每种情况都可能出现成百上千个有效案例，常规CPU方法处理起来可能效率太低。因此，介绍了高效的Compact-Table（CT）传播算法，并探索了如何利用现代GPU的大量计算能力来处理大型表格约束问题，同时将其集成到现有求解器中，并在大量实例上进行实验验证.
### Innovation
本文提出了将Compact-Table (CT) 算法加速的技术，通过利用现代GPU提供的强大计算能力解决大型表格约束问题，并将该算法集成到现有约束求解器中，从而显著提高了解决这类问题的效率和可扩展性.
### Conclusion
对通过使用GPU加速的Compact-Table传播算法在现有约束求解器中的设计与实现以及在大量实例上的实验证明进行了描述，结果表明，该方法能够有效处理大规模的约束问题，并显示出显著的性能提升.
## 17. `cs.AI` - mean GNNs的逻辑表征 [PDF](https://arxiv.org/pdf/2507.18145), [HTML](https://arxiv.org/abs/2507.18145)
### Authors
Moritz Schönherr,Carsten Lutz
### Background
研究图神经网络（GNNs）的表达能力，特别是在使用均值作为聚合函数的情况下，与比例模态逻辑的关系。
### Innovation
证明了均值GNNs在非均匀设置下的表达能力与比例模态逻辑相同，在均匀设置下的表达能力与自由交替模态逻辑相同，均值GNNs的表达能力低于求和GNNs和最大GNNs。
### Conclusion
在均匀设置下，相对于MSO，均值GNNs的表达能力严格低于求和GNNs和最大GNNs。若上述假设之一不成立，表达能力会增加。
## 18. `cs.AI` - 异质性学习：基于分布鲁棒优化的动态面部表情识别泛化 [PDF](https://arxiv.org/pdf/2507.15765), [HTML](https://arxiv.org/abs/2507.15765)
### Authors
Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang
### Background
动态面部表情识别（DFER）在情感计算和人机交互中起着关键作用。尽管现有方法取得了相当的性能，但由于多源数据和个体表情变化多样性的样本异质性问题，它们不可避免地会表现出性能下降。
### Innovation
提出了一种新的框架，称为异质性感知分布框架（HDF），并设计了两个插件模块来增强时间-频率建模和缓解由难样本引起的优化不均衡。具体来说，时间-频率分布注意力模块（DAM）通过双重注意力设计捕捉时间一致性与频率稳健性，提高对序列不一致和视觉风格变化的容忍度。基于梯度灵敏性和信息瓶颈原理，引入了自适应优化模块分布感知缩放模块（DSM），动态平衡分类损失和对比损失，实现更具稳定性和区分性的表示学习。
### Conclusion
在两个广泛使用的数据集DFEW和FERV39k上进行的大量实验表明，HDF显著提高了识别准确性和鲁棒性。我们的方法在加权平均召回率（WAR）和未加权平均召回率（UAR）上表现优越，同时保持了对多样且不平衡场景的强大泛化能力。源代码已发布。
## 19. `cs.AI` - SafeWork-R1: 在AI-45°法则下同步演化安全与智能 [PDF](https://arxiv.org/pdf/2507.18576), [HTML](https://arxiv.org/abs/2507.18576)
### Authors
Shanghai AI Lab:Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu
### Background
SafeWork-R1 是一种先进的多模态推理模型，展示了能力与安全的同步进化。它基于我们提出的 SafeLadder 框架开发，该框架包括大规模、渐进、以安全为导向的增强学习，并由一系列多元原则验证器支持。SafeWork-R1 相对于其基础模型 Qwen2.5-VL-72B 在安全相关基准测试上的平均改进为 46.54%，且不牺牲通用能力，其安全性表现优于领先的私有模型 GPT-4.1 和 Claude Opus 4。通过引入两种不同的推理阶段干预方法和审议式搜索机制，SafeWork-R1 进一步增强了可靠性，从而构建出了稳健、可靠和可信赖的一般人工智能框架。
### Innovation
SafeWork-R1 和 SafeLadder 框架通过大规模、渐进、以安全为导向的增强学习以及多方原则验证器，使得模型在学习人类偏好之外，还能够发展出内在的安全推理和自我反思能力。SafeWork-R1 能够超越现有技术（如 RLHF），在确保能力的同时，显著提高安全性。此外，SafeLadder 框架还通过干预方法和审议式搜索机制增强了模型的可靠性。
### Conclusion
SafeWork-R1 和衍生模型 SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B 和 SafeWork-R1-Qwen2.5VL-7B 显示了在支持推理阶段验证机制下，安全与能力能够实现协同进化的可能性。这体现了我们框架在建立稳健、可靠和值得信赖的一般人工智能方面的普遍适用性。
## 20. `cs.AI` - 铁路专业人员的见解：重新思考铁路关于安全和自主性的假设 [PDF](https://arxiv.org/pdf/2507.17756), [HTML](https://arxiv.org/abs/2507.17756)
### Authors
Josh Hunter,John McDermid,Simon Burton
### Background
本研究调查了铁路行业专业人士对安全概念的看法，旨在为未来的技术发展提供指导。通过与驾驶员、路线规划人员和行政人员的访谈，研究了当前的安全实践状况、自动化潜力以及铁路作为系统中的理解。关键发现包括对自动化持谨慎态度、偏好辅助技术以及整合了人、系统和技术因素的安全复杂理解。研究还指出了将汽车自动化技术转移到铁路中的局限性，并强调了需要针对铁路特定因果模型的重要性，以更好地评估和提高在不断发展的技术环境中的安全性。
### Innovation
本研究通过与铁路行业专业人士的访谈，深度了解了他们对安全实践和自动化技术的看法，提出需要开发针对铁路的特定因果模型来更好地评估和提升安全性。
### Conclusion
本研究旨在弥合当前研究与实际应用之间的差距，促进更有效的安全指标的发展。
## 21. `cs.AI` - 探索数学问题解决中协作大语言模型代理的通信策略 [PDF](https://arxiv.org/pdf/2507.17753), [HTML](https://arxiv.org/abs/2507.17753)
### Authors
Liang Zhang,Xiaoming Zhai,Jionghao Lin,Jionghao Lin,Jennifer Kleiman,Diego Zapata-Rivera,Carol Forsyth,Yang Jiang,Xiangen Hu,Arthur C. Graesser
### Background
近年来，大型语言模型（LLM）代理逐渐被应用于AI辅助教育领域，以支持辅导和学习。有效的代理间沟通策略可以提高协作问题解决的效率，并促进教育领域的经济有效应用。然而，很少有研究系统评估不同沟通策略对代理问题解决的影响。本文在使用OpenAI的GPT-4o模型构建的双代理、基于聊天的数学问题解决环境中，考察了四种沟通模式：教师-学生互动、同侪-同侪合作、相互教学和批判性辩论，研究的不同沟通模式在对数学数据集（MATH）进行评估时，显示双代理设置优于单代理，同侪-同侪合作表现出最高的准确性。对话行为如陈述、认可和提示在合作问题解决中起关键作用。多代理框架尽管能增强计算任务，但有效的沟通策略对于解决AI教育中的复杂问题至关重要。
### Innovation
本文采用OpenAI的GPT-4o模型，在数学问题解决环境中评估不同沟通模式的效果，发现双代理设置优于单代理，特别指出同侪-同侪合作表现出最高准确性。此外，强调对话行为如陈述、认可和提示在多代理系统中的重要作用。
### Conclusion
研究结果表明，有效的沟通策略对于提高多代理系统的协同问题解决能力和解决复杂问题非常重要，多代理系统可以提升问题解决任务的效率，而合作式的交流方式可以进一步优化这种改善。
## 22. `cs.AI` - 一种自定义的环境记述员可以减轻远程医疗临床医生的认知负担和文档负担 [PDF](https://arxiv.org/pdf/2507.17754), [HTML](https://arxiv.org/abs/2507.17754)
### Authors
Justin Morse,Kurt Gilbert,Kyle Shin,Rick Cooke,Peyton Rose,Jack Sullivan,Angelo Sisante
### Background
临床医生的职业倦怠促使了诊所环境记述员技术的广泛应用。在这样的背景下，这项研究介绍了一个自定义集成到EHR系统的环境记述员应用程序，该应用程序是由提供个性化一站式医疗服务（包括远程医疗服务）的Included Health公司开发的。该应用程序使用Whisper进行转录，并采用了GPT-4o的模块化上下文学习管道来自动生成SOAP笔记和患者说明。
### Innovation
该创新主要涉及一个自定义的环境记述员移动端应用程序，嵌入到EHR系统中，利用Whisper进行语音转录，并通过GPT-4o生成高质量的SOAP笔记。此外，该应用程序展示了生成的笔记经过微调的BART模型后处理后可以提高简洁性，表明了AI系统在减轻行政负担和支持高效率医疗服务方面有潜力。在模拟的就诊数据上展示的笔记质量超过了专家手写的笔记。
### Conclusion
研究结果表明，应用程序能够显著减轻临床医生的认知负担和文档负担。超过一半的受调查临床医生报告在使用该应用程序期间认知负担降低，97%的临床医生认为该应用程序减少了文档工作量。此外，通过微调BART模型处理的笔记变得更加简洁，这些发现凸显了AI系统在行政负担减轻和提升临床高效高质量服务中的潜力。
## 23. `cs.AI` - 在LLMs中分离知识和推理：基于认知双系统理论的探索 [PDF](https://arxiv.org/pdf/2507.18178), [HTML](https://arxiv.org/abs/2507.18178)
### Authors
Mutian Yang,Jiandong Gao,Ji Wu
### Background
大语言模型（LLMs）在推理过程中结合了知识和逻辑推理，但区分它们的能力在模型分析、可解释性和开发中起着关键作用。受认知双系统理论的启发，本文提出了一种认知属性框架，以分解知识和推理的贡献。该框架将LLMs的认知过程分解为两个阶段：知识检索（阶段1）和推理调整（阶段2）。
### Innovation
提出了认知属性框架以分离知识和推理的贡献，并将LLMs的生成过程分解为知识检索和推理调整两个阶段。通过不同的认知模式（快速思考和慢速思考）来分离这两个阶段，并分析不同认知模式下的性能以定量地衡量知识和推理的贡献。
### Conclusion
研究表明：（1）推理调整具有领域特异性，有利于推理密集型领域（如数学、物理和化学），可能损害知识密集型领域。（2）参数缩放可以提升知识和推理的效果，但知识提升更为显著。此外，参数缩放使LLMs的推理变得更审慎，但智能程度略有增加。（3）知识主要存在于较低网络层，而推理则在较高层运作。该框架不仅有助于从‘分离’的角度理解LLMs，还为现有研究提供了新的见解，包括缩放定律、层次知识编辑和小模型推理的局限性。
## 24. `cs.AI` - 超越显而易见：在金融场景中评估LLMs的发散和收敛思维能力 [PDF](https://arxiv.org/pdf/2507.18368), [HTML](https://arxiv.org/abs/2507.18368)
### Authors
Zhuang Qiang Bok,Watson Wei Khong Chua
### Background
大多数针对LLMs的推理基准着重于事实准确性或逐步逻辑推理。然而，在金融领域，专业人士不仅需要达成最优决策，还需要在不确定性中生成具有创意和现实可能性的未来情景。本文提出了一种名为ConDiFi的新基准，旨在评估LLMs在金融任务中的发散和收敛思维能力。
### Innovation
ConDiFi基准引入了607个宏观经济金融提示和990个多级对抗选择题，以联合评估LLMs的发散和收敛推理能力。研究发现，尽管流畅度高，GPT-4o在新颖性和可行动性方面表现不佳，而DeepSeek-R1和Cohere Command R+等模型在生成有助于投资决策的结果方面表现出色。
### Conclusion
ConDiFi提供了一种全新的视角，用于评估确保LLMs在金融领域安全和战略部署所需的关键推理能力。
## 25. `cs.AI` - 如何通过教学顺序和个人化支持影响诊断策略学习 [PDF](https://arxiv.org/pdf/2507.17760), [HTML](https://arxiv.org/abs/2507.17760)
### Authors
Fatma Betül Güreş,Tanya Nazaretsky,Bahar Radmehr,Martina Rau,Tanja Käser
### Background
在教育的不同领域中，支持学生发展有效的诊断推理是一项关键挑战。初学者往往受到如过早结案和过度依赖启发式方法等认知偏差的影响。基于案例的学习(CBL)能够通过提供现实案例体验和迭代练习来应对这些挑战，但不同的教学序列和问题解决活动的最佳顺序仍然不明确。这项研究探讨了如何将个性化支持融入不同的教学序列中，并考察了在解决问题之前(v-i)还是之后(PS-I)提供明确的诊断策略指导对学习及其迁移的影响。研究在一个名为PharmaSim的在线CBL环境中进行，该环境模拟了药剂师学徒与真实客户互动的情境。结果表明，虽然两种指导方式都有利，但在解决问题之后提供指导(PS-I)对迁移任务的表现有显著提高效果。
### Innovation
研究创新在于它探索了在解决问题之前(v-i)还是之后(PS-I)提供明确的诊断策略指导对学习及其迁移的影响。通过在线模拟环境PharmaSim进行实验，为适用于类似教育情境下的有效方法提供了实证依据。
### Conclusion
研究结果显示，虽然在两类教学序列中都提供了有效的指导，但在解决问题之后提供指导的方法能显著提高迁移任务的表现。这一发现对优化教育过程中的教学设计具有重要的实际意义。
## 26. `cs.AI` - 在物联网环境中的联邦学习通信成本减少的缓存技术 [PDF](https://arxiv.org/pdf/2507.17772), [HTML](https://arxiv.org/abs/2507.17772)
### Authors
Ahmad Alhonainy(1),Praveen Rao(1) ((1) University of Missouri, USA)
### Background
联邦学习（FL）允许多个分布式的设备共同训练一个共享的模型，而无需集中数据，但是通信成本仍然是一个主要瓶颈，尤其是在资源受限的环境中。
### Innovation
引入了缓存策略——FIFO、LRU 和优先级基，通过选择性地转发重要更新，降低带宽使用量同时保持模型准确性。
### Conclusion
实验表明，在CIFAR-10和医疗数据集上的结果说明了减少通信和最小化准确度损失之间取得平衡的可能性。结果证实了智能缓存策略能提高大规模部署的效率，内存使用效率，并且支持边缘物联网网络中的可靠的联邦学习，使其适用于智能城市、医疗和其他敏感延迟的应用场景。
## 27. `cs.AI` - 基于ASR的说话人角色会话分割与分割指导下的ASR解码 [PDF](https://arxiv.org/pdf/2507.17765), [HTML](https://arxiv.org/abs/2507.17765)
### Authors
Arindam Ghosh,Mark Fuhs,Bongjun Kim,Anurag Chowdhury,Monika Woszczyna
### Background
传统的演讲者分割（SD）方法通常给演讲者分配通用标签，如演讲者1、演讲者2等，并且对于特定应用场景如医生 vs. 患者、主持人 vs. 客人等，基于角色的演讲者角色分割（RD）更为有用。最近的端到端模型中，自动语音识别（ASR）+SD框架通过同步ASR编码器的辅助SD转录器来预测每个词的演讲者标签，但并未考虑角色分配的个性化需求。
### Innovation
1. 简化训练方式，通过强制对齐和交叉熵损失替代RNN-T损失。2. 证明了词预测和角色预测需要不同的预测器上下文，从而提出分离任务特定预测器的方法，不同于现有共享预测器模型。3. 提出了利用说话人角色分割后验活动来影响ASR解码过程的方法，从而减少短词删除错误。
### Conclusion
通过上述三大贡献，该研究扩展了ASR+SD框架到基于角色的演讲者角色分割，并且有效地提升了ASR解码的准确度，特别是在处理短词识别方面。
## 28. `cs.AI` - 人机协同创作：智能系统中合作设计的框架 [PDF](https://arxiv.org/pdf/2507.17774), [HTML](https://arxiv.org/abs/2507.17774)
### Authors
Zhangqi Liu
### Background
随着人工智能（AI）从后台计算工具逐渐转变为互动的、生成性的合作者，它在早期设计过程中的集成需要重新思考人本中心设计的传统工作流程。本文探讨了人机共同创作的新兴范式，在这种范式中，AI 不仅用于自动化或效率提升，还积极参与到创意生成、视觉概念化和决策制定中。
### Innovation
本文研究了大型语言模型（LLMs）如 GPT-4 和多模态扩散模型如 Stable Diffusion 在设计师与之互动的迭代提案、批评和修正循环中作为创造代理的应用。这是一种创新方法，超越了传统的人工智能工具的应用，将 AI 更深层次地整合到设计过程中。
### Conclusion
本文提出了一种框架，用以指南智能系统中的合作设计。该框架强调了人机共同创作的重要性，不仅能够提升设计的效率和质量，还能够促进人与 AI 之间的有效沟通与协作，从而进一步推动设计流程的现代化和智能化。
## 29. `cs.AI` - 由先进AI驱动的数据库系统 [PDF](https://arxiv.org/pdf/2507.17778), [HTML](https://arxiv.org/abs/2507.17778)
### Authors
M. Tedeschi,S. Rizwan,C. Shringi,V. Devram Chandgir,S. Belich
### Background
当前的数据库系统尽管有效，但在复杂性和易用性方面存在严重问题，特别是一些缺乏技术专长但不了解查询语言（如SQL）的个体。这些问题使得数据库管理变得更加困难和复杂。
### Innovation
该论文提出了一种由人工智能支持的新数据库系统，旨在利用自然语言处理（NLP）为基础的直观界面、自动创建结构化查询和半结构化数据格式（如YAML、JSON、API文档）来改进数据管理。系统通过整合大型语言模型（LLMs）和高级机器学习算法，旨在自动化数据建模、模式创建、查询理解及性能优化等基本任务。该AI数据库系统采用生成性模式推断和格式选择来构建其模式模型和执行格式，以此降低对技术技能和性能调整的需求，并减少人为错误的可能性。
### Conclusion
该论文介绍的系统旨在解决现有数据库技术的主要问题。其目标是降低对技术技能的需求、减少因性能调优所需的手动操作，以及避免人为错误。
## 30. `cs.AI` - Helix 1.0: 开源框架用于表格科学数据的可重复且可解释的机器学习 [PDF](https://arxiv.org/pdf/2507.17791), [HTML](https://arxiv.org/abs/2507.17791)
### Authors
Eduardo Aguilar-Bejarano,Daniel Lea,Karthikeyan Sivakumar,Jimiama M. Mase,Reza Omidvar,Ruizhe Li,Troy Kettle,James Mitchell-White,Morgan R Alexander,David A Winkler,Grazziela Figueredo
### Background
随着透明实验数据分析需求的增加，现有机器学习流程缺乏记录、可访问性、可重复性和可理解性，特别是在表格数据的处理上。Helix旨在解决这一问题，提供一个开源、可扩展且基于Python的软件框架，以促进表格数据上的可重复和可解释的机器学习工作流程。
### Innovation
Helix框架包含标准化的数据预处理、可视化、机器学习模型训练、评估、解释、结果检查和对未见过数据的模型预测模块。特别地，Helix提供了一个用户友好的界面，使得未受过正式数据科学训练的研究人员也能从计算实验中获取有意义且可操作的见解，包括使用语义术语的一种新颖的机器学习决策解释方法。
### Conclusion
Helix以MIT许可发布，可通过GitHub和PyPI访问，支持社区驱动的发展，并促进遵循FAIR原则。
## 31. `cs.AI` - 与机器合作者共同的梦境：与机器合作者十年数学发现 [PDF](https://arxiv.org/pdf/2507.17780), [HTML](https://arxiv.org/abs/2507.17780)
### Authors
Randy Davila,Boris Brimkov,Ryan Pepper
### Background
在过去十年中，自动化猜想生成系统TxGraffiti生成了四个开放的图论猜想。这些猜想简洁、基于自然图不变量，并在数百个图上得到了经验验证。尽管投入了大量努力，但它们仍未得到解决，既无法证明也无法找到反例。这些猜想不仅是数学挑战，也是创意表达，源于符号模式识别和数学家定义的启发式方法，这些方法在多年的人类对话中不断提炼，现在被提供给社区作为合作成果。这些猜想不仅激励人们进行形式化的证明，还促进了对机器如何激发惊奇、激发好奇心及其如何为发现提供基础材料的思考。
### Innovation
TxGraffiti自动化猜想生成系统生成了四个关于图论的新猜想。这些猜想简洁明了，基于自然图不变量，并且在大量图上得以验证。尽管进行了大量的努力，但是这些猜想仍然没有被解决，这说明了机器在数学发现过程中的可能贡献，它们不仅提供了新的数学挑战，同时也促进了人机合作的新形式，使得机器可以成为创造性过程的一部分。
### Conclusion
通过提出这些问题，作者旨在激发人类数学家和AI系统参与解决这些问题，不仅仅是寻找解决方案，更是在机器参与数学思考创造过程时的反思。这些猜想不仅是一个数学挑战，同时也是激发人类创造力和好奇心的新方法。
## 32. `cs.AI` - 基于自回归大规模语言模型的排名中适应性重复策略以缓解位置偏差 [PDF](https://arxiv.org/pdf/2507.17788), [HTML](https://arxiv.org/abs/2507.17788)
### Authors
Ali Vardasbi,Gustavo Penha,Claudia Hauff,Hugues Bouchard
### Background
在使用自回归大语言模型（LLM）根据给定标准排名或评估答案时，候选项目的顺序会影响模型的最终决策。这种对提示中项目位置的敏感性被称为位置偏差。先前的研究表明，即便是在大型模型中，位置偏差也普遍存在，但其严重程度会因不同的模型和任务而异。此外，LLM 在重复调用时还会表现出不同程度的低重复一致性，即使用相同的候选顺序重复调用模型可能会导致不同的排名。常规的方法是通过多次用不同的候选顺序提示模型并采用多数投票的方式聚合结果，但这种方法会显著增加计算成本。我们的研究发现，位置偏差的大小和方向甚至在同一个数据集内也会有很大差异，这一现象凸显了实例级缓解策略的必要性。
### Innovation
本文提出了一种动态退出策略，该策略可以根据每个实例的具体情况灵活地确定重复调用的次数，有效减少了LLM调用次数，同时保持了准确性。此外，还提出了一种基于置信度的动态退出策略增强，进一步减少了LLM调用次数，仅在准确性上存在微小的折衷。
### Conclusion
通过对三种不同规模的LLM进行评估，并在重排和对齐任务上进行测试，我们展示了动态重复策略可以将LLM调用次数平均减少81%，同时保持准确性。基于置信度的动态重复策略进一步降低了87%的调用次数，仅在准确性上只有轻微的折衷。
## 33. `cs.AI` - 概念探查在性能方面的研究：数据的影响（扩展版本） [PDF](https://arxiv.org/pdf/2507.18550), [HTML](https://arxiv.org/abs/2507.18550)
### Authors
Manuel de Sousa Ribeiro,Afonso Leote,João Leite
### Background
近年来，概念探查作为一种帮助解释人工神经网络的方法引起了越来越多的关注。由于人工神经网络通常非常庞大且具有亚符号性质，使得直接通过人类解读变得不太实际。概念探查通过训练额外的分类器以便将模型的内部表示映射到人类关注的概念中，从而帮助人类窥探人工神经网络的内部。然而，现有研究大多集中在被探查模型或探查模型本身，对用于训练此类探查模型所需的数据关注不足。本文聚焦于图像分类任务中的概念探查，探讨了用于训练探查模型的数据对其性能的影响。
### Innovation
本文填补了该领域对用于训练探查模型的数据关注不足的空白，对图像分类任务中的概念探查进行了研究，探讨了训练数据对探查模型性能的影响，并提供了两个广泛使用的数据集的概念标签。
### Conclusion
本文通过研究用于训练探查模型的数据对模型性能的影响，揭示了数据质量对概念探查的重要作用，并为理解高层抽象概念提供了新的工具。此外，通过提供两个数据集的概念标签，有助于研究者深入分析人工神经网络的内部机制。
## 34. `cs.AI` - 不同毒理学试验数据环境下的优化几何深度学习架构比较 [PDF](https://arxiv.org/pdf/2507.17775), [HTML](https://arxiv.org/abs/2507.17775)
### Authors
Alexander D. Kalian,Lennart Otte,Jaewook Lee,Emilio Benfenati,Jean-Lou C.M. Dorne,Claire Potter,Olivia J. Osborne,Miao Guo,Christer Hogstrand
### Background
几何深度学习是人工智能驱动的化学信息学中的新兴技术，但对于不同图形神经网络（GNN）架构的独特影响研究尚不充分。本文对比了在7种不同毒性试验数据集上图形卷积网络（GCNs）、图形注意力网络（GATs）和图形同构网络（GINs）的表现。这些数据集在数据丰富程度和终点方面各不相同，用于执行毒性试验激活的二进制分类。
### Innovation
通过对每种GNN在每种毒性试验数据集上的优化，进行了21项独立的贝叶斯优化。研究发现，对于最具数据丰富性的5种毒性试验，GINs表现最佳；但对于数据稀缺的2种毒性试验，GATs表现显著优于其他架构。此外，分析发现，GCNs和GATs在优化状态上的接近度相比GINs更为接近。
### Conclusion
研究得出，对于数据丰富度较高的环境，GINs是更优的架构选择；而对于数据稀缺的环境，GATs是更适合的架构。此外，GINs作为GNN算法的独特性得到了进一步证明。
## 35. `cs.AI` - SV3.3B: 一种用于动作识别的体育视频理解模型 [PDF](https://arxiv.org/pdf/2507.17844), [HTML](https://arxiv.org/abs/2507.17844)
### Authors
Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam
### Background
传统的自动体育视频分析受到计算密集型模型的限制，这些模型需要服务器端处理，并且缺乏对运动员动作的精细理解。现有方法在捕捉对有意义的体育分析至关重要的细微生物力学过渡时存在困难，经常未能识别如准备、执行和随随动作等在几秒内发生的决定性阶段。虽然很多人试图解决这些问题，但尚未出现有效的解决方案。因此，迫切需要一种能够在设备上高效部署且计算要求较低的体育视频理解模型，以改善现有水平。
### Innovation
本文提出了一种轻量级的3.3B参数视频理解模型——SV3.3B，它结合了新颖的时域运动差异采样与自监督学习，旨在实现高效的设备端部署。该模型通过一种基于DWT-VGG16-LDA的帧提取机制，能够智能地从体育序列中找到最具代表性的16帧，然后利用预训练模型和LLM进行编码和解码，从而实现了对体育动作详细描述的生成。与传统的文本生成指标和体育特定评估标准相比，该模型的表现更优，尤其是在关键验证指标上超越了包括GPT-4o变体在内的大型闭源模型，同时命令要求显著降低。
### Conclusion
SV3.3B模型展示了在生成技术详细且分析丰富的体育描述方面具有优越的能力，尤其是在地truth验证指标上取得了29.2%的提升，同时在信息密度、动作复杂性和测量精度等方面也取得了显著的改进，这些对于全面的运动员分析至关重要。该模型已经可以在 https://... 地址获得。
## 36. `cs.AI` - 定义Rumsfeld不确定性 [PDF](https://arxiv.org/pdf/2507.17776), [HTML](https://arxiv.org/abs/2507.17776)
### Authors
Jie Fan
### Background
近期，Kit Fine发表了一篇论文，探讨了第一阶无知、第二阶无知以及Rumsfeld无知的逻辑性质。虽然Rumsfeld无知可以由无知定义，这使得一些现有结果和公理化问题变得简单。主要原因是两类无知的知识操作符的隐含可达关系相同。
### Innovation
本文假设计划中的两种可达关系不同，其中一种是另一种的任意子集。这一假设避免了定义问题并保留了大多数先前有效的结论。主要成果是对多种适当双框架类进行了公理化。
### Conclusion
最终，我们将该框架应用于分析Kit Fine的结果。
## 37. `cs.AI` - 数字化病理学中稳健基础模型的探索 [PDF](https://arxiv.org/pdf/2507.17845), [HTML](https://arxiv.org/abs/2507.17845)
### Authors
Jonah Kömen,Edwin D. de Jong,Julius Hense,Hannah Marienwald,Jonas Dippel,Philip Naumann,Eric Marcus,Lukas Ruff,Maximilian Alber,Jonas Teuwen,Frederick Klauschen,Klaus-Robert Müller
### Background
生物医学基础模型（FMs）正在快速改变AI驱动的医疗健康研究，并进入临床验证阶段。然而，这些模型容易学习非生物学技术特征，如手术/内窥镜技术、实验室程序和扫描设备的差异，这对临床应用构成了风险。论文首次系统地调查了病理FMs在非生物学特征方面的稳健性。研究表明，缺乏稳健性会导致病理FMs的非稳健表示，可能导致重大的诊断错误和临床失误，阻碍安全的临床应用。本研究通过提出了一套新的评估方法和框架，旨在提升病理FMs的稳健性，减少这些风险。这些发现强调了在临床应用前评估和提高病理FMs稳健性的重要性，表明未来的FMs开发必须将稳健性作为核心设计原则。
### Innovation
引入了用于量化FMs稳健性的新措施；展示了稳健性受限的后果；提出了FMs稳健性提升的框架；开发了PathoROB基准，包含四个数据集和三个新指标，覆盖34家医疗机构的28个生物分类；通过实验证明了稳健性差异的存在，以及更多稳健的FMs和事后稳健性处理可以显著减少错误的风险。
### Conclusion
本研究确立了在临床应用前评估和验证病理FMs稳健性的必要性，并证明了将稳健性作为未来FMs核心设计原则的重要性。PathoROB为跨生物医学领域评估稳健性的提供了蓝图，指导了FMs改进努力，使其更加稳健、代表性和适合临床应用，优先处理生物学信息而非技术性特征。
## 38. `cs.AI` - 大规模5G核心部署中的性能评估与威胁缓解 [PDF](https://arxiv.org/pdf/2507.17850), [HTML](https://arxiv.org/abs/2507.17850)
### Authors
Rodrigo Moreira,Larissa F. Rodrigues Moreira,Flávio de Oliveira Silva
### Background
大规模软件基5G核心功能的部署面临着重大挑战，因为其依赖于优化和智能的资源分配。许多研究集中在使用数学模型、队列理论甚至人工智能分析资源分配对复杂部署的影响。已有研究关注DDoS引起的混沌工作负载如何影响用户设备注册性能，以及不同网络功能（NFs）的性能差异，强调在大规模5G核心部署中满足服务级别协议（SLA）的必要性。此外，对数据包捕获方法的分析进一步展示了内核基础监控在大规模安全威胁防御中的潜力。
### Innovation
该研究通过分析DDoS引起混沌工作负载的影响，特别强调了不同NFs的性能差异，并进一步通过分析数据包捕获方法，展示了内核基础监控在大规模安全威胁防御中的潜力，为复杂场景下5G NFs的有效部署提供了实证评估。
### Conclusion
该研究提供了大规模5G核心部署中有效地部署5G NFs的重要见解，特别是在满足SLA和应对安全威胁方面。内核基础的监控方法被证明是一种有效的威胁防御手段，并且实验评估为复杂部署环境下的实践应用提供了宝贵的数据支持。
## 39. `cs.AI` - 通过基于GenAI的图像合成促进AI基皮肤病变分类器的公平性评估 [PDF](https://arxiv.org/pdf/2507.17860), [HTML](https://arxiv.org/abs/2507.17860)
### Authors
Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel
### Background
深度学习在边缘设备上的应用在皮肤癌如黑素瘤的例行筛查中展现出巨大的潜力。然而，随着这项技术带来预期优势的同时，潜在的偏见问题也随之而来，因此评估和改进此类系统的公平性至关重要。公平性评估的关键挑战在于确保评估数据集能充分代表不同的人口可识别信息（如性别、年龄和种族）以及其他少数群体。
### Innovation
本研究利用最先进的生成型人工智能（GenAI）LightningDiT模型，评估公开可用的黑素瘤分类器的公平性。研究结果表明，使用高度现实的合成数据进行公平性评估是一个有前途的方向。然而，研究发现，当用于评估的黑素瘤检测模型的数据与用于生成合成图像的数据集不同时，验证公平性变得更加困难。尽管如此，该研究提出了通过合成数据评估和提升医疗影像GenAI系统公平性的新途径。
### Conclusion
尽管存在挑战，本研究提出的方法为利用合成数据评估和增强医疗影像GenAI系统公平性提供了有价值的新途径。
## 40. `cs.AI` - 基于深度Q网络的动作列表强化学习分量解码算法 [PDF](https://arxiv.org/pdf/2507.17893), [HTML](https://arxiv.org/abs/2507.17893)
### Authors
Milad Taghipour,Bane Vasic
### Background
本文探讨了使用强化学习技术提升基于位翻转和寻找最优决策的线性分组码解码性能的应用。作者将迭代解码过程映射到马尔科夫决策过程（MDP），并提出减少MDP状态数的方法。此外，还提出了一种基于自同构群的反馈方法来优化现有高性能解码器的性能，并展示了射线球效应和算法的性能提升，最后通过低密度奇偶校验码（LDPC）在二进制对称信道（BSC）上的实验结果验证了这些方法的有效性
### Innovation
作者提出了一个基于MDP的动作列表解码方案，并设计了一个基于深度Q网络的动作列表解码器，有效地减少了强化学习模块的复杂性。此外，还提出了一种基于自同构群的方法来进一步提高码的性能，以及一种反馈方法来利用并增强现有高性能解码器的性能
### Conclusion
本文利用强化学习技术改进了线性分组码解码，特别是提出了一种基于MDP的动作列表解码方案，并且通过低密度奇偶校验码在二进制对称信道上的实验验证了其有效性
## 41. `cs.AI` - Technical Implementation of Tippy: 多智能体架构和系统设计在药物发现实验室自动化中的应用 [PDF](https://arxiv.org/pdf/2507.17852), [HTML](https://arxiv.org/abs/2507.17852)
### Authors
Yao Fehlis,Charles Crain,Aidan Jensen,Michael Watson,James Juhasz,Paul Mandel,Betty Liu,Shawn Mahon,Daren Wilson,Nick Lynch-Jonely,Ben Leedom,David Fuller
### Background
本文基于作者之前关于制药研究中代理型人工智能的概念框架，提供了Tippy多智能体系统的技术实现，该系统旨在自动化药物发现实验室的工作流程。文章详细介绍了Tippy系统的技术架构，包括五个专门化的智能体（监督者、分子、实验室、分析、报告）以及它们如何通过OpenAI Agents SDK进行协调，并利用Model Context Protocol（MCP）接入实验室工具。这些智能体通过异步通信模式协同工作，并通过基于Git的版本控制系统进行配置管理。文章还介绍了生产部署策略，包括使用Kubernetes进行容器编排、Docker容器化以及CI/CD管道进行自动化测试和部署。此外，系统还利用向量数据库实现RAG功能，并使用Envoy反向代理来提供安全的外部访问。这些技术展示了如何通过标准协议将专门设计的AI智能体成功地集成到复杂的实验室工作流程中，确保了安全、可扩展、可靠并能够与现有的实验室基础设施无缝对接
### Innovation
文章创新地提出了一个分布式的微服务架构，利用五个专门化的智能体协调实验室自动化流程，同时解决了异步通信和安全性问题，通过标准化协议实现了与现有实验室基础设施的无缝集成。创造性地利用了向量数据库和技术进行了RAG功能的集成，以及利用Envoy进行了外部安全访问的实现
### Conclusion
通过Tippy多智能体系统的实现，本文展示了专门设计的AI智能体能够有效协调复杂的药物发现实验室工作流程，同时保持安全、可扩展、可靠，并且能够与现有的实验室基础设施标准协议对接。该系统的生产部署模式为其他实验室自动化项目提供了参考。
## 42. `cs.AI` - Hyperbolic Deep Learning for Foundation Models: A Survey [PDF](https://arxiv.org/pdf/2507.17787), [HTML](https://arxiv.org/abs/2507.17787)
### Authors
Neil He,Hiren Madhu,Ngoc Bui,Menglin Yang,Rex Ying
### Background
基础模型（包括大型语言模型、视觉-语言模型和大型多模态模型）在多样化下游任务中表现出色。然而，这些模型存在一些根本性的局限性，如有限的表征能力、较低的适应性和可扩展性上的衰减。这些问题引发了一个重要问题：欧几里得几何是否适用于所有基础模型，还是可以通过引入不同的几何空间来改善模型与现实数据内在结构的对齐，从而提升推理过程？双曲空间作为一种非欧几何空间，以距离的指数增长来描述体积增长，提供了数学上的解决方案。这种空间能够以较少的维度低失真嵌入层次结构（如树、分类学）和幂律分布。
### Innovation
基于双曲空间的近似低维嵌入特性，研究者以前所未有的方式改进了基础模型，包括增强大型语言模型的复杂推理能力和零样本泛化能力，以及视觉-语言模型在跨模态语义对齐中的表现，同时保持参数效率。
### Conclusion
本文对双曲神经网络及其在基础模型中的最新发展进行了全面回顾，并进一步概述了该领域面临的关键挑战和研究方向，以推动该领域的发展。
## 43. `cs.AI` - Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models [PDF](https://arxiv.org/pdf/2507.17853), [HTML](https://arxiv.org/abs/2507.17853)
### Authors
Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang
### Background
近期，文本到图像（T2I）生成取得了显著的视觉效果。然而，这些模型在处理复杂的提示文本时仍面临重大挑战，尤其是涉及多个具有不同属性的主题时。现有的T2I模型未能有效捕捉复杂的布局和细节，难以生成精细且准确的图像。鉴于此，研究者受到人类绘图过程的启发，提出了一种无需训练的框架——Detail++，以应对这一问题。该框架通过逐步分解复杂提示为简化子提示，利用自我注意机制确保整体布局，然后进行精确的细节修正，来改进图像生成效果。
### Innovation
Detail++框架引入了新颖的渐进式细节注入（PDI）策略，通过逐步分解复杂的提示为简化的子提示，首先利用自我注意机制确保整体布局的正确性，然后进行精确的细节修正。此外，它还利用了交叉注意机制和支持测试阶段的重心对齐损失，以减少属性与对应主题之间的配对噪声，增强一致性。这使得Detail++在面对多个对象和复杂的风格条件时表现出显著的优势，相比于现有方法，能够显著提高图像生成质量。
### Conclusion
详细实验结果表明，与现有的方法相比，Detail++在T2I-CompBench和一个新构建的风格组合基准数据集上取得了显著的性能提升，特别是在涉及多个物体和复杂风格条件的场景中表现尤为突出。
## 44. `cs.AI` - 深度学习辅助的多孔超材料逆设计 [PDF](https://arxiv.org/pdf/2507.17907), [HTML](https://arxiv.org/abs/2507.17907)
### Authors
Phu Thien Nguyen,Yousef Heider,Dennis M. Kochmann,Fadi Aldakheel
### Background
研究最终目标是利用基于深度学习的生成框架探索多孔超材料的逆设计。研究中开发了一种属性变分自编码器（pVAE），这是一种带回归器的变分自编码器（VAE），用于生成具有定制液压性能（如孔隙率和渗透率）的结构化超材料。虽然研究利用格子玻尔兹曼方法（LBM）为有限的多孔微观结构生成内嵌渗透张量数据，但采用自下而上的方法训练卷积神经网络（CNN）以预测有效液压性能，从而大大降低了直接LBM模拟的计算成本。
### Innovation
研究首次提出将属性变分自编码器（pVAE）用于多孔超材料的结构设计，并通过卷积神经网络（CNN）使用自下而上的方法预测有效液压性能。这种组合显著降低了计算成本。研究还使用合成数据集和CT扫描的实物体积元数据来训练模型，通过VAE的编码-解码结构捕获关键微观结构特征，并映射到紧凑且可解释的潜在空间，以实现结构-性能探索。
### Conclusion
研究提供了关于潜在空间的详细分析和解释，展示了其在结构-性能映射、插值和逆设计中的作用，支持生成具有所需性能的新超材料。研究中的数据集和代码将被开放访问，以支持进一步的研究工作。
## 45. `cs.AI` - 通过结构外部性解释图神经网络 [PDF](https://arxiv.org/pdf/2507.17848), [HTML](https://arxiv.org/abs/2507.17848)
### Authors
Lijun Wu,Dong Hao,Zhiyi Fan
### Background
图神经网络（GNNs）在广泛的任务上取得了出色的表现，但其“黑盒”特性使其可解释性面临重大挑战，现有的方法往往无法有效捕捉网络中节点间错综复杂的交互模式。
### Innovation
该论文提出了一种名为GraphEXT的新解释框架，利用合作博弈论和社会外部性的概念。GraphEXT将图节点划分为联盟，将原始图分解成独立子图。GraphEXT通过将图结构作为外部性、结合外部性的Shapley值，量化节点对GNN预测的边际贡献，从而在网络节点在联盟间过渡时评定节点的重要性。与主要关注节点属性的传统Shapley值方法不同，GraphEXT更注重节点间的交互以及结构变化对GNN预测的影响。
### Conclusion
实证研究在合成和真实世界数据集上显示，GraphEXT在不同的GNN架构中都优于现有基准方法，在提升GNN模型的解释性方面表现出显著的优越性。
## 46. `cs.AI` - VeriMinder: 在NL2SQL中缓解分析漏洞 [PDF](https://arxiv.org/pdf/2507.17896), [HTML](https://arxiv.org/abs/2507.17896)
### Authors
Shubham Mohole,Sainyam Galhotra
### Background
自然语言接口到数据库（NLIDBs）的应用已经使得数据解析更加普及化。然而，这同时也带来了一个迫切的问题：如何帮助那些不具备统计分析背景的用户，使其能够提出无偏差的分析问题。尽管关于文本生成SQL的精度已经有大量的研究，但如何在分析问题中解决认知偏差仍然相对较少研究。
### Innovation
我们提出了VeriMinder，这是一个交互式的系统，用于检测并缓解分析漏洞，其创新点包括：（1）针对特定分析情境的语境语义映射框架，（2）将难以变动原则可操作化以引导用户的系统化数据分析，（3）通过多重候选，批评反馈和自我反省生成高质量、特定任务的提示的优化的LLM驱动系统。
### Conclusion
用户测试表明，VeriMinder的方法有显著的好处。直接经验评价中，82.5%的参与者报告说这种方法改善了分析的质量。在比较性评估中，按分析的具象化、全面性和准确性指标考虑，VeriMinder的表现至少比其他方法高出20%。我们的系统作为一个网络应用，旨在帮助用户在数据分析过程避免“问错问题”的漏洞。VeriMinder的代码库和提示可以通过MIT许可证的形式在开源社区中进行进一步的研究和采用。
## 47. `cs.AI` - UrbanPulse: 一种跨城市深度学习框架，用于超精细人群转移预测 [PDF](https://arxiv.org/pdf/2507.17924), [HTML](https://arxiv.org/abs/2507.17924)
### Authors
Hongrong Yang,Markus Schlaepfer
### Background
准确的人口流动预测对于城市规划、交通运输管理和公共卫生至关重要。现有方法存在一些关键限制：传统模型依赖静态空间假设，深度学习模型在跨城市泛化中表现不佳，大规模语言模型虽然具有高度准确性和泛化能力，但由于计算成本高且无法捕捉空间结构，而损失时间分辨率或仅关注子区域的许多方法也限制了其在城市级分析中的应用。
### Innovation
UrbanPulse 是一种可扩展的深度学习框架，它可以以每个人的地点兴趣点（POI）作为独立节点，提供超精细的城市级OD（origin-destination）流预测。它结合了时空图卷积编码器和基于变换器的解码器来建模多尺度的空间和时间依赖关系。UrbanPulse 使用三阶段迁移学习策略确保在不同城市背景下的稳健泛化：大规模城市图上的预训练、冷启动适应和强化学习。
### Conclusion
在超过1亿3千万条加利福尼亚州三个大都市区清理的GPS记录上，UrbanPulse 达到了最先进的准确性和可伸缩性。通过高效的迁移学习，UrbanPulse 朝着在不同城市中进行高分辨率、人工智能驱动的城市预测的实际部署迈出了一步。
## 48. `cs.AI` - 多模态细粒度推理用于帖子质量评估 [PDF](https://arxiv.org/pdf/2507.17934), [HTML](https://arxiv.org/abs/2507.17934)
### Authors
Xiaoxu Guo,Siyan Liang,Yachao Cui,Juxiang Zhou,Lei Wang,Han Cao
### Background
准确评估帖子质量需要复杂的关联推理能力，以捕捉主题和帖子之间微妙的关系。然而，现有研究存在三大局限性：（1）将任务视为单一模式分类，无法充分利用多模态线索和细粒度质量区分；（2）在深度多模态融合过程中引入噪声，导致误导性信号；（3）缺乏捕捉复杂语义关系（如相关性和完整性）的能力。
### Innovation
本文提出了多模态细粒度主题-帖子关联推理框架（MFTRR），该框架模仿人类认知过程。MFTRR重新定义了帖子质量评估为排序任务，并结合多模态数据以更好地捕捉质量变化。它包括两个关键模块：（1）局部-全局语义相关推理模块，该模块在局部和全局水平上建模帖子和主题之间的细粒度语义交互，通过最大信息融合机制来抑制噪声；（2）多级证据关联推理模块，该模块探索宏和微观水平的关联线索，以增强基于证据的推理。
### Conclusion
MFTRR在三个新构建的多模态主题-帖子数据集和公共Lazada-Home数据集上进行了评估。实验结果表明，MFTRR显著优于当前最先进的基线方法，在Art History数据集上NDCG@3提高了9.52%。
## 49. `cs.AI` - Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation [PDF](https://arxiv.org/pdf/2507.17937), [HTML](https://arxiv.org/abs/2507.17937)
### Authors
Jaechul Roh,Zachary Novack,Yuefeng Peng,Niloofar Mireshghallah,Taylor Berg-Kirkpatrick,Amir Houmansadr
### Background
歌词到歌曲（LS2）生成模型承诺从文本实现端到端的音乐合成，但它们在训练数据记忆化方面存在的脆弱性仍被忽视。研究表明，尽管歌词在意义上被篡改但在语音结构上保持不变，这些模型仍然能够生成与训练内容高度相似的输出，尤其是在音频领域中。这种现象打破了以前对LS2模型仅在直接记忆原词的情况下易受攻击的认知，揭示出对语音线索的敏感性也是普遍存在的。结果表明，这不仅在不同语言和音乐体裁中有效，甚至在与原始内容无关的视觉提示下，基于文本到视频模型也会生成与原曲视频元素高度相似的内容。
### Innovation
作者提出了新颖的对抗首音拼字提示（Adversarial PhoneTic Prompting，APT）攻击方法。通过使用同音词替换手段，即使对歌词进行意义上的篡改但也保留了其音节结构，发现LS2模型存在对语音记忆的强力亚词级别存储，即使在多个语言和音乐类型中模型仍然会生成类似之前训练内容的输出。此外，研究还发现了基于文本到视频模型会仅通过对语音修改的歌词产生视觉元记忆的现象，称其为语音到视觉的反刍（phonetic-to-visual regurgitation），这一现象进一步指出了统计信息学习方法在多媒体生成约束下的潜在风险，即单独的语音提示就能解锁存储在模型中的录音和视觉内容。
### Conclusion
研究揭示了转录条件下的多媒体生成模型存在一个关键的脆弱性，即仅仅通过语音提示就能解锁录音和视觉内容，这意味着现代生成系统在版权、安全及内容来源方面都面临紧急的问题。这种现象强调了对生成系统设计中的潜在数据记忆现象进行深入研究和谨慎处理的必要性。研究结果提供了对现有LS2模型的深刻理解，并指出了未来的改进方向及需要解决的重要问题。
## 50. `cs.AI` - 使用DeepSeek生成的文本评估AI文本检测器的表现、少样本和链式思维提示 [PDF](https://arxiv.org/pdf/2507.17944), [HTML](https://arxiv.org/abs/2507.17944)
### Authors
Hulayyil Alshammari,Praveen Rao
### Background
大型语言模型（LLMs）的快速发展已经改变了书面材料的创作方式。这引发关于写作诚信的问题，进而推动了AI检测技术的发展。之前的多项研究主要集中在ChatGPT等知名LLM上，并展示了不同的检测器准确率。然而，关于最近发布的DeepSeek LLM的研究则较少。因此，该研究旨在调查六种常用的AI检测工具——AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2和GPTZero——是否能持续识别由DeepSeek生成的文本，同时引入了常见的对抗攻击测试这些检测器的鲁棒性。
### Innovation
该研究的独特之处在于使用了一个新发布的LLM DeepSeek，并通过对抗攻击评估了六种AI检测工具在识别DeepSeek生成文本时的表现，特别是通过少样本和链式思维提示进行分类测试，这提供了一种新的检测方法来提高识别准确性。
### Conclusion
在检测DeepSeek生成的文本时，QuillBot和Copyleaks显示出接近完美的性能，但在使用诸如简化和人性化的人工攻击后，其他检测器如AI Text Classifier和GPT-2则表现出不一致性。人类化攻击是最有效的攻击方式，将Copyleaks、QuillBot和GPTZero的准确性分别降低到71%、58%和52%。少样本和链式思维提示的分类测试显示出最佳的准确性，其中五样本提示的误分类率仅为2%。
## 51. `cs.AI` - LLM信念更新是否符合贝叶斯定理 [PDF](https://arxiv.org/pdf/2507.17951), [HTML](https://arxiv.org/abs/2507.17951)
### Authors
Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson
### Background
研究旨在探讨大型语言模型在面对上下文证据时，是否能够更一致地更新其对命题的“信念”，并用贝叶斯定理作为理论基础。为此，研究者提出了一个贝叶斯一致性系数（BCC）指标，并设计了一个数据集来量化模型的BCC。研究还包括了多个预训练模型，从模型参数数量、训练数据量及通用基准测试表现等维度进行比较分析，以验证更大和更先进的预训练模型是否更符合贝叶斯定理。这项研究对于语言模型的理解和治理有重要启示作用。
### Innovation
研究创新之处在于开发了一个新的度量标准——贝叶斯一致性系数（BCC），用于评估语言模型在证据面前信息更新的一致性。这种崭新的度量方法能够更准确地分析大型语言模型的更新行为是否遵循了贝叶斯定理的原则。通过这种方法，研究者能够更全面地理解模型的学习机制和表现特性。
### Conclusion
研究结果支持假设，即更大的预训练语言模型能够产生与贝叶斯定理更加一致的信念更新。这为理解大型语言模型的工作原理提供了新的视角，并对这些模型的管理与治理具有重要的实际意义。
## 52. `cs.AI` - 提高GeoAggregator的计算效率和可解释性 [PDF](https://arxiv.org/pdf/2507.17977), [HTML](https://arxiv.org/abs/2507.17977)
### Authors
Rui Deng,Ziqi Li,Mingshu Wang
### Background
地理空间表数据（GTD）的准确建模和解释对于理解地理现象及其内在过程至关重要。近期的一项研究提出了一种新颖的基于变压器的深度学习模型GeoAggregator（GA），该模型优于其他统计和机器学习方法。这项研究展示了新模型能够提供更高的预测准确性和更好的计算效率。
### Innovation
1. 提出了一个优化的工作流程，加速了数据装载过程并优化GA的前向传播过程，从而提高计算效率；2. 引入了模型集成策略，以及基于GeoShapley框架的模型事后解释方法，增强了模型的可解释性。这些改进措施在实验中被验证有效，提升了原始版本中GA模型的预测准确性和推理速度，同时GA能够有效捕捉设计的合成数据集中的内在空间效应。进一步的工作已经对外公开提供使用。
### Conclusion
优化后的GA模型在合成数据集上的实验结果证明了所提出策略的有效性，不仅提升了预测准确性和推理速度，还增强了模型对于合成数据集中内在空间效应的捕捉能力。
## 53. `cs.AI` - VERIRAG：依托检索增强生成的统计审计的医疗索赔验证 [PDF](https://arxiv.org/pdf/2507.17948), [HTML](https://arxiv.org/abs/2507.17948)
### Authors
Shubham Mohole,Hongjun Choi,Shusen Liu,Christine Klymko,Shashank Kushwaha,Derek Shi,Wesam Sakla,Sainyam Galhotra,Ruben Glatt
### Background
检索增强生成（RAG）系统在临床决策支持中被广泛应用，然而这些系统在方法论上仍存在盲点——它们能够检索证据，但却无法验证证据的科学质量。例如，一篇声称“抗氧化蛋白在异种干扰素治疗后减少”的文章和一项严格的多实验室重复研究将被视为同样可信，即使前者缺乏科学研究的严谨性甚至被撤稿。因此，论文提出了VERIRAG框架，旨在改进RAG系统的证据评估能力，为临床医学提供更可靠的决策支持。
### Innovation
VERIRAG框架做出了以下三个显著贡献：(i) 可信赖指标，一个包含11项的清单，用于评估每个来源的方法学严谨性，包括数据完整性和统计有效性；(ii) 难以改变（HV）得分，这是一个定量综合指标，根据证据的质量和多样性对其进行加权；(iii) 动态接受阈值，根据声明的非凡性调整所需的证据量。在四个数据集（包括撤稿、争议、全面和成熟科学文献库）的测试中，VERIRAG方法在所有基线方法中表现最佳，绝对F1评分从0.53到0.65不等，与其次优方法相比分别提高了10到14个点。
### Conclusion
研究团队将发布所有用于复制成果的材料。VERIRAG框架通过引入更严格的证据评估机制，显著提升了 healthcare claim verification 的准确性，尤其是在处理 RAG 系统中的方法学盲点方面取得了重要进展。
## 54. `cs.AI` - 从种子到收割：利用AI增强人类创造力对文本到图像模型进行红队攻击 [PDF](https://arxiv.org/pdf/2507.17922), [HTML](https://arxiv.org/abs/2507.17922)
### Authors
Jessica Quaye,Charvi Rastogi,Alicia Parrish,Oana Inel,Minsuk Kahng,Lora Aroyo,Vijay Janapa Reddi
### Background
文本到图像（T2I）模型在各种应用中越来越普遍，因此对其面对对抗性攻击的稳健评估变得至关重要。当前生成对抗性提示的方法要么完全由人工撰写，要么是合成生成的。人工制作的数据集通常规模较小且文化、情境代表性不平衡。相比之下，合成生成的提示数据集规模较大，但通常缺乏人类制作的提示中现实的细腻之处和富有创意的对抗策略。为结合人类和机器方法的优势，作者提出了Seed2Harvest，一种用于生成文化多样性的、人工制作的对抗性提示种子的混合红队方法。
### Innovation
Seed2Harvest是一种混合红队方法，能够生成具有文化多样性的、人工制作的对抗性提示种子。它结合了人类的创意和机器的计算能力，以实现全面、可扩展的红队攻击，评估T2I模型的安全性。
### Conclusion
本文证明了人类与机器合作的重要性，通过发挥人类的创造力和机器的计算能力，实现全面、可观的红队攻击，持续评估T2I模型的安全性。
## 55. `cs.AI` - MeAJOR Corpus: 多源数据集用于钓鱼邮件检测 [PDF](https://arxiv.org/pdf/2507.17978), [HTML](https://arxiv.org/abs/2507.17978)
### Authors
Paulo Mendes(1),Eva Maia(1),Isabel Praça(1) ((1) GECAD, ISEP, Polytechnic of Porto, Portugal)
### Background
钓鱼邮件继续通过欺诈性内容和恶意负载对网络安全构成重大威胁，利用了人类的漏洞。虽然机器学习模型在检测钓鱼威胁方面非常有效，但它们的表现很大程度上依赖于训练数据的质量和多样性。现有资源存在关键限制，如数据不足和多样性不高等问题。本研究旨在提出一种新的、多源的钓鱼邮件数据集，以解决这些问题，并通过系统实验评估其在钓鱼检测研究中的实用性。
### Innovation
本研究提出了一个新的数据集MeAJOR（Merged email Assets from Joint Open-source Repositories）Corpus，它整合了135894个样本，涵盖了多种钓鱼技术和合法邮件，并使用了广泛特征工程。该数据集用于解决常见挑战，如类别失衡、泛化能力和可重复性等问题，同时为钓鱼检测研究提供了可重用和一致的资源。
### Conclusion
实验结果表明，该数据集在使用XGB模型时能实现98.34%的F1得分，展示了其在钓鱼检测研究中的有效性和实用性。该数据集通过集成多个类别中的广泛特征，提供了可重用且一致的资源，并能够有效应对常见的挑战。
## 56. `cs.AI` - 最小最大数据脱敏及其对抗推理中的失真约束 [PDF](https://arxiv.org/pdf/2507.17942), [HTML](https://arxiv.org/abs/2507.17942)
### Authors
Amirarsalan Moatazedian,Yauhen Yakimenka,Rémi A. Chou,Jörg Kliewer
### Background
本文研究了一个隐私保护的数据共享场景，其中数据提供者（数据优化器）将私人数据转换为监控用户的授权重构者以及两个具有与私人数据相关侧信息的非授权对手所观察到的清洗版本。重构者是根据失真函数进行评估的，而对手则是根据各自的损失函数进行评估。数据优化器确保用户的重构失真保持在固定阈值之下，同时最大化两个对手中的最小损失。这种双对手设置模拟了单独用户无法准确重建数据，但其结合的侧信息则可在这个失真阈值内进行估计的情况。
### Innovation
本文将此问题表述为一个受约束的数据驱动最小最大优化问题，并提出了一种交替更新数据优化器、重构者和对手的数据驱动训练方法。此外，本文还分析了高斯和二进制情况下的特殊情况，以获得最优解。这些理论最优结果可以作为评估所提最小最大训练方法的标准。
### Conclusion
本文所提出的方法通过最大化个别对手的损失，实现了数据优化器在允许通过合作进行准确重建时的数据脱敏，同时提供了一个衡量数据驱动训练方法效果的标准。
## 57. `cs.AI` - 交通状态估计与预测的机器遗忘 [PDF](https://arxiv.org/pdf/2507.17984), [HTML](https://arxiv.org/abs/2507.17984)
### Authors
Xin Wang,R. Tyrrell Rockafellar,Xuegang(Jeff)Ban
### Background
数据驱动的交通状态估计与预测(TSEP)依赖于包含敏感信息的数据源。尽管丰富数据促进了包括机器学习方法在内的重大突破，但这也引发了隐私、网络安全和数据新鲜度等方面的问题，这些问题可能损害公众对智能交通系统的信任。最近，法规引入了“被遗忘的权利”，允许用户要求删除其私有数据。然而，考虑到机器学习模型可以记住旧数据，仅从后端数据库中删除数据是不够的。为应对这些挑战，该研究提出了一种新的学习范式——机器遗忘交通状态估计与预测(TSEP)，使训练好的TSEP模型能够选择性地忘记敏感、有毒或过时的数据，从而增强数据驱动的交通TSEP的可靠性和可信度。
### Innovation
提出了一种新的学习范式——机器遗忘TSEP，使训练好的TSEP模型能够选择性地忘记敏感、有毒或过时的数据。这解决了以往仅仅是从数据库中删除数据不足以解决的问题，从而增强智能交通系统的数据安全性、隐私保护和模型可靠性。
### Conclusion
通过帮助模型实现“遗忘”，该研究旨在提升数据驱动的交通状态估计与预测系统的可靠性和可信度，确保智能交通系统能够更加安全地处理敏感数据，维护用户信任。
## 58. `cs.AI` - VIBE: 视频输入的大脑编码器用于fMRI响应建模 [PDF](https://arxiv.org/pdf/2507.17958), [HTML](https://arxiv.org/abs/2507.17958)
### Authors
Daniel Carlstrom Schad,Shrey Dixit,Janis Keck,Viktor Studenyak,Aleksandr Shpilevoi,Andrej Bicanski
### Background
该研究旨在利用多模态信息（视频、音频和文本）来预测功能磁共振成像（fMRI）活动。它基于现有的开放源代码模型（Qwen2.5、BEATs、Whisper、SlowFast、V-JEPA），并利用Transformer架构融合这些模态的信息。研究通过使用旋转嵌入来解码这些信息，以期改进fMRI的预测准确性。
### Innovation
研究提出了一种两阶段的Transformer模型（VIBE），它能够融合视频、音频和文本多模态数据，以预测fMRI活动。这是一种新颖的方法，因为它利用了多个数据源的信息，并通过跨20个种子的集成提高了预测性能。该模型在Algonauts 2025挑战赛中表现出色，特别是在预测不同数据集上的fMRI响应方面。
### Conclusion
研究结果表明，VIBE模型提升了fMRI活动的预测精度，特别是在内部数据集（《老友记》S07）和外部数据集（六部不同电影）上的表现。与之前的工作相比，VIBE模型在测试中展示了更好的泛化能力和预测准确性。
## 59. `cs.AI` - Fashion-AlterEval：一个改进对话推荐系统评估的数据集，包含替代相关项目的人类判断 [PDF](https://arxiv.org/pdf/2507.18017), [HTML](https://arxiv.org/abs/2507.18017)
### Authors
Maria Vlachou
### Background
在对话推荐系统（CRS）中，用户在每次迭代中提供反馈以改进推荐。为了应对需要大量数据的挑战，通常使用用户模拟器进行训练和评估。现有模拟器依赖于单个目标项目的相关知识并对长时间的多次交互表现出宽容，但这种评估在离线设置中受到限制。因此，研究者提出了一种名为Fashion-AlterEval的新数据集，它包含在常见时尚CRS数据集中添加新注释的人类判断，以及两种新的元用户模拟器，能够模拟用户不仅表达对替代物品的偏好，还能改变其偏好和耐心水平。通过实验发现，使用模拟器关于替代物品的知识可以显著影响现有CRS模型的评估结果，尤其是传统的单目标评估低估了这些模型的有效性，当允许模拟用户考虑替代相关项目时，系统能够迅速响应，更快地满足用户的需求。
### Innovation
提出了一种名为Fashion-AlterEval的新数据集，它通过在常用时尚CRS数据集中添加新注释包含了人类对替代相关物品的判断；此外，还提出了两种新的元用户模拟器，这些模拟器不仅允许模拟用户表达对替代物品的偏好，还能改变其偏好和耐心水平。这种改进的模拟机制克服了现有模拟器的局限性，提供了更准确的评估。
### Conclusion
使用新数据集和改进的用户模拟器可以对现有的对话推荐系统模型进行更准确的评估，特别指出传统的单目标评估低估了这些模型的有效性，而允许模拟用户考虑替代相关项目时，系统能够迅速响应，更好地满足用户需求。
## 60. `cs.AI` - Tigrinya语的自然语言处理：当前状态与未来方向 [PDF](https://arxiv.org/pdf/2507.17974), [HTML](https://arxiv.org/abs/2507.17974)
### Authors
Fitsum Gaim,Jong C. Park
### Background
尽管有数百万人使用，但提格雷尼亚语在自然语言处理（NLP）研究中仍然严重不足。这项研究对自2011年至2025年超过10年的超过40项关于提格雷尼亚语的NLP研究进行了全面回顾。
### Innovation
系统地分析了从形态分析到机器翻译，再到语音识别和问答等十个不同下游任务的当前状态，并揭示了从基于规则的基础系统到现代神经架构的明确进步路径。着重指出了提格雷尼亚语的形态复杂性和资源稀缺性带来的关键挑战，并提出了形态感知建模、跨语言转移和以社区为中心的资源开发等有希望的研究方向。
### Conclusion
本工作不仅为研究者提供了全面的参考，也为推进提格雷尼亚语的NLP指明了道路。还提供了一份经过精简的元数据，包含了研究和资源。
## 61. `cs.AI` - ViGText: 使用视觉-语言模型解释和图神经网络的深伪图检测 [PDF](https://arxiv.org/pdf/2507.18031), [HTML](https://arxiv.org/abs/2507.18031)
### Authors
Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan
### Background
随着深伪技术的快速发展，这种技术能够生成逼真的但具有欺诈性的数字内容，威胁到了媒体的真实性。传统的深伪检测方法往往难以应对高度定制的、复杂的深伪，在泛化能力和抵御恶意攻击的鲁棒性方面表现不佳。
### Innovation
ViGText 是一种新的方法，它在图框架中结合了视觉数据和 Vision Large Language Model (VLLM) 生成的相关文本解释，通过图神经网络 (GNN) 对图像进行分块和分析，从而提高了深伪检测的准确性和鲁棒性。其创新之处在于将详细解释与视觉数据相结合，因为与通常缺乏具体性和无法揭示细微不一致性的图注释相比，它提供了更全面的上下文分析。
### Conclusion
广泛的实验证明，ViGText 显著提高了泛化能力，并在检测用户定制的深伪时取得了显著的效果提升。具体而言，泛化评估下的平均 F1 分数从 72.45% 提高到 98.32%。此外，当面对利用其基于图结构的架构的针对性攻击时，ViGText 的召回率提高了 11.1%，且分类性能下降不超过 4%。ViGText 通过详细的视觉和文本分析，重新设定了检测深伪的标准，有助于确保媒体的真实性与信息的完整性。
## 62. `cs.AI` - 使用大型语言模型生成短语分割预测的合成数据 [PDF](https://arxiv.org/pdf/2507.18044), [HTML](https://arxiv.org/abs/2507.18044)
### Authors
Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim
### Background
当前的短语分割预测方法侧重于文本转语音系统的关键语调方面，但需要大量的人工注释来自音频或文本，这需要大量的手工努力和成本。口语领域的固有变异性，由发音因素驱动，进一步增加了获得一致、高质量数据的难度。近年来，大型语言模型（LLMs）在自然语言处理（NLP）中取得了成功，通过生成定制的合成数据并在一定程度上减少人工注释的需求，解决了数据挑战。
### Innovation
通过利用LLM生成合成的短语分割注释，以解决手动注释和与口语相关的任务挑战，并通过与传统注释进行比较，评估跨多个语言的有效性。研究结果表明，基于LLM的合成数据生成有效缓解了短语分割预测中数据挑战，并揭示了LLM在口语领域的潜在应用价值作为可行的解决方案。
### Conclusion
基于LLM的合成数据生成有效缓解了短语分割预测中的数据挑战，并突出展现了LLM在口语领域的潜在应用价值。
## 63. `cs.AI` - 解码教学对话：大规模教师使用AI工具的人机协作分析 [PDF](https://arxiv.org/pdf/2507.17985), [HTML](https://arxiv.org/abs/2507.17985)
### Authors
Alex Liu,Lief Esbenshade,Shawon Sarkar,Victor Tian,Zachary Zhang,Kevin He,Min Sun
### Background
大型语言模型（LLMs）在教育工具中的整合有望极大地影响教师的教学规划、支持多样化的学习者以及进行专业反思。然而，关于教师如何实际使用这些工具以及如何大规模研究其与人工智能的交互知之甚少。
### Innovation
本文提出了一种人机协作的方法，用于大规模定性分析来自K-12教师使用的一家生成式AI平台的超过140,000条教师-AI对话。该研究通过四个阶段的编码流程，结合归纳主题发现、代码本开发、结构化注释和模型基准测试，来研究教师参与模式并评估LLM在定性编码任务中的性能。本文还展示了一项分层代码本，该代码本与已有的教师评估框架对齐，捕捉到教师的教学目标、情境需求和教学策略。此外，研究结果表明，尤其是Claude 3.5 Haiku，LLM能够可靠地支持主题识别、拓展人类在复杂情境下的识别能力，并在准确性和结构性可靠度上超越了开放权重模型。
### Conclusion
分析揭示了教师利用AI增强教学实践、创编或调整内容、支持评估和反馈循环、关注学生个性化教学需求以及协助其他专业职责的具体模式，突出了新兴的AI相关技能，这对教师培训和专业发展有直接影响。这项研究提供了一种可扩展且透明的AI增强的定性研究模型，并为生成式AI在教育实践中的演变角色提供了基础性的见解。
## 64. `cs.AI` - GRR-CoCa: 利用LLM机制在多模态模型架构中的应用 [PDF](https://arxiv.org/pdf/2507.18009), [HTML](https://arxiv.org/abs/2507.18009)
### Authors
Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi
### Background
当前最先进的（SOTA）图像和文本生成模型是多模态模型，与大型语言模型（LLMs）有许多相似之处。尽管这些模型表现强大，但主流的多模态模型架构通常在架构复杂性上落后于当代的LLMs。为了提高模型性能和适应能力，本文提出了一种名为GRR-CoCa的改进SOTA对比式图示模型，通过将Gaussian误差门控线性单元、根均方归一化及旋转位置嵌入引入文本解码器和视觉变换器（ViT）编码器中。
### Innovation
GRR-CoCa模型在文本解码器和ViT编码器中融入了Gaussian误差门控线性单元、根均方归一化及旋转位置嵌入。与Baseline CoCa相比，后者使用了相同的修改后的文本解码器但保留了CoCa的原ViT编码器。通过标准预训练和微调流程，GRR-CoCa在对比性和生成任务上显著优于Baseline CoCa。具体来说，在预训练数据集上的对比损失降低了27.25%，困惑度降低了3.71%，CoCa损失降低了7.15%。在多种微调数据集上，对比损失提高了13.66%，困惑度提高了5.18%，CoCa损失提高了5.55%。表明GRR-CoCa的改进架构在视觉语言领域具有更好的性能和泛化能力。
### Conclusion
GRR-CoCa在多模态模型架构中采用了大型语言模型的机制，通过具体的改进模式显著提高了模型在预训练和微调任务上的性能和泛化能力，证明了这些改进的有效性。
## 65. `cs.AI` - NeuralDB: 使用神经键值数据库将知识编辑扩展到100,000项事实的LLMs [PDF](https://arxiv.org/pdf/2507.18028), [HTML](https://arxiv.org/abs/2507.18028)
### Authors
Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu
### Background
在大规模语言模型（LLMs）中高效地编辑存储的知识，能够在无需大规模训练的情况下更新模型。一种可能的解决方案是Locate-and-Edit（L&E），它可以同时修改大量的事实。然而，这种编辑可能会损害模型的一般能力甚至导致编辑的事实在大量修改时被遗忘。目前，大多数线性L&E方法将问题视为查询键值（KV）数据库。
### Innovation
本文将现有的线性L&E方法视为查询KV数据库，并提出了一种新的编辑框架NeuralDB，它通过引入一个非线性门控检索模块来显式地表示编辑的事实，该模块仅在涉及编辑事实的推理时才操作，从而有效地保持了模型的总体性能。
### Conclusion
在ZsRE和CounterFacts数据集上的10,000个事实的编辑实验表明，NeuralDB不仅在编辑有效性、泛化能力、精确性、流畅性和一致性方面表现出色，还能够在六个代表性文本理解和生成任务中保持总体性能。进一步的实验还表明，NeuralDB即使扩展到100,000个事实（比先前工作多50倍）仍然有效。
## 66. `cs.AI` - GrAInS: 基于梯度的归因用于LLMs和VLMs的推理时调整 [PDF](https://arxiv.org/pdf/2507.18043), [HTML](https://arxiv.org/abs/2507.18043)
### Authors
Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal
### Background
推理时的转向方法提供了一种轻量级替代方案，用于在不更新模型权重的情况下对大型语言模型（LLMs）和多模态视觉语言模型（VLMs）进行微调，通过在测试时间修改内部激活。然而，大多数现有方法依赖于固定的全局干预向量，忽视了单个输入令牌的因果影响，并且未能利用模型logits中的有益梯度，特别是在视觉和文本输入贡献不均匀的多模态场景中。这些限制迫使研究人员寻找新的方法来优化模型的推理行为，特别是在语言和视觉信息高度相互作用的场景下。
### Innovation
GrAInS 是一种多模态模型和任务中推理时转向的创新方法，结合了对比和梯度基础的归因机制，特别是使用 Integrated Gradients 方法识别正面和负面归因的最influential tokens，然后基于这些tokens构建方向性的转向向量，捕捉从不良行为到良好行为的语义转变。在推理阶段，GrAInS 通过token级别的归因信号调整变换器层的隐藏激活，并进行标准化以保持表示的规模，从而实现模型行为的细微、可解释和模块化控制，而无需重新训练或辅助监督。其结果在诸如TruthfulQA、MMHal-Bench和SPA-VL等数据集上优于传统微调和现有转向基线，同时保持模型的流畅性和通用能力。
### Conclusion
GrAInS 方法实现了对 LLMs 和 VLMs 的细粒度、可解释和模块化的控制，而无需重新训练或额外的辅助监督，通过使用对比和梯度基础的归因来识别最influential tokens，并在推理时调整模型行为，从而显著提高模型表现。
## 67. `cs.AI` - OpenNav: 开放世界的多模态大型语言模型导航 [PDF](https://arxiv.org/pdf/2507.18033), [HTML](https://arxiv.org/abs/2507.18033)
### Authors
Mingfeng Yuan,Letian Wang,Steven L. Waslander
### Background
预训练的大型语言模型（LLMs）展示了很强的常识推理能力，这使得它们在机器人导航和规划任务中具有很大的潜力。然而，当前的工作仍然存在挑战，即在开放世界中通过语言描述和实际机器人动作之间建立桥梁，而不仅仅是调用有限的预定义运动原语。因此，需要使机器人能够解释和分解复杂的语言指令，最终基于开放的语言描述和物体生成一系列轨迹点以完成各种导航任务。研究者们观察到，多模态大型语言模型（MLLMs）在处理自由形式的语言指令时表现出强大的跨模态理解能力，展示了强大的场景理解能力。此外，MLLMs的代码生成能力使它们能够与视觉-语言感知模型交互，生成组成式的2D顶视图价值图，有效结合了MLLMs的语义知识和地图的空间信息，提高了机器人的空间理解能力。大型自主车辆数据集（AVDs）被有效利用来验证多模态大型语言模型在户外任务中的零样本视觉-语言导航框架的有效性，展示了其在执行各种自然语言导航指令方面的多样性，同时具有鲁棒性，对于物体检测误差和语义歧义具有稳定性。在现实场景中，该系统也在 Husky 机器人上进行了室内和室外场景的验证，展示其实用性和鲁棒性。额外的视频说明材料可以在提供的链接查看。
### Innovation
该研究采用多模态大型语言模型（MLLMs），通过其强大的跨模态理解能力和代码生成能力，使机器人能够解释和分解复杂的语言指令，结合视觉和语义信息，生成2D顶视图价值图，从而提高了机器人的空间理解能力。此外，研究还利用了大规模的自主车辆数据集（AVDs）来证明这种零样本视觉-语言导航框架在实际环境中的性能和鲁棒性。研究验证了该系统在Husky机器人上的应用，使其适用于室内和室外导航任务，展示其实用性和鲁棒性。
### Conclusion
通过多模态大型语言模型的出色表现，本研究提出了一种新的零样本视觉-语言导航框架，能够有效处理开放世界的导航任务，实现复杂自然语言指令的执行，并在实际应用中展示了其鲁棒性和实用性。
## 68. `cs.AI` - TELEVAL: 旨在中文互动场景中为语音语言模型设计的动态基准 [PDF](https://arxiv.org/pdf/2507.18061), [HTML](https://arxiv.org/abs/2507.18061)
### Authors
Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li
### Background
近年来，语音语言模型（SLMs）取得了快速进展，伴随大量用于评估其性能的新基准的出现。然而，目前大多数基准主要关注SLMs是否能够完成与大规模语言模型（LLMs）相同程度的复杂任务，通常未能与用户在现实世界对话场景中的自然交互方式对齐。
### Innovation
本文提出了TELEVAL，一个动态基准，专门设计用于评估SLMs在真实中文互动场景中作为对话代理的有效性。TELEVAL定义了三个评估维度：显式语义、副语言和隐式语义以及系统能力。采用与实际使用一致的对话格式，分别评估文本和音频输出。特别强调了模型从用户言语中提取隐性线索并适当响应的能力。研究表明，尽管已经取得了进展，但现有的SLMs在自然对话任务中仍有很大的改进空间。
### Conclusion
希望TELEVAL能够作为用户为中心的评估框架，直接反映用户体验，促进更强大、更对话导向的SLMs的发展。
## 69. `cs.AI` - 通过强化学习进行视频时间标注的数据集和方法 [PDF](https://arxiv.org/pdf/2507.18100), [HTML](https://arxiv.org/abs/2507.18100)
### Authors
Ruizhe Chen,Zhiting Fan,Tianze Luo,Heqing Zou,Zhaopeng Feng,Guiyang Xie,Hansheng Zhang,Zhuochen Wang,Zuozhu Liu,Huaijian Zhang
### Background
视频时间标注（VTG）旨在根据自然语言查询，在视频中定位相关的时间片段。尽管大语言模型（LVLM）和指令调优取得了进展，但现有方法往往面临时间感知能力有限和泛化能力差的问题。
### Innovation
提出了一种两阶段的训练框架，结合监督微调和强化学习（RL）来提升VTG模型的准确性和鲁棒性。首先利用高质量的精心策划的冷启动数据进行初始微调，然后是难度可控的RL以进一步增强时间定位和推理能力。
### Conclusion
在多个VTG基准上的全面实验表明，该方法在复杂和公开场景中一致优于现有模型。深入分析了训练策略和数据集策划的重要性，并逐步展示了高质量冷启动数据与难度可控的RL的必要性。为了促进进一步研究和工业采用，发布了所有中间数据集、模型和代码。
## 70. `cs.AI` - GOAT-SLM: 具有副语言和说话人特征意识的口语语言模型 [PDF](https://arxiv.org/pdf/2507.18119), [HTML](https://arxiv.org/abs/2507.18119)
### Authors
Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He
### Background
近期端到端的口语语言模型（SLMs）显著提高了AI系统进行自然口语交互的能力。然而，大多数现有模型仅将语音视为语言内容的载体，往往忽视了人类语音中蕴含的丰富副语言和说话人特征线索，如方言、年龄、情感和非言语发声。
### Innovation
引入了GOAT-SLM，这是一种新的具有副语言和说话人特征意识的口语语言模型，旨在将口语语言建模扩展到超越文本语义的层面。GOAT-SLM采用双模态头部架构，将语言建模与声学实现脱钩，支持稳健的语言理解的同时促进表达性和适应性语音生成。为了提高模型的效率和多样性，提议采用模块化阶梯式训练策略，逐步对语言、副语言和说话人特征信息进行对齐，使用大规模语音-文本语料库。实验结果表明，GOAT-SLM在TELEVAL（一个多维度评估基准）上实现了语义和非语义任务的平衡表现，并在处理情感、方言差异和年龄敏感交互方面优于现有的开源模型。
### Conclusion
这项工作强调了建模超越语言内容的重要性，并推进了更自然、适应性和社会意识更强的口语语言系统的开发。
## 71. `cs.AI` - TextSAM-EUS: 使用 SAM 进行精确的内镜超声胰腺肿瘤分割的文本提示学习 [PDF](https://arxiv.org/pdf/2507.18082), [HTML](https://arxiv.org/abs/2507.18082)
### Authors
Pascal Spiegler,Taha Koleilat,Arash Harirpoush,Corey S. Miller,Hassan Rivaz,Marta Kersten-Oertel,Yiming Xiao
### Background
胰腺癌的预后较差，依赖于内镜超声（EUS）进行精确取样和放射治疗。然而，EUS 中的斑点噪声、低对比度和直观性差使得利用完全监督的深度学习（DL）模型进行胰腺肿瘤分割既容易出错，又依赖于大量由专家标注的数据集。为应对这些挑战，本文介绍了一种新颖且轻量级的文本驱动内镜超声（EUS）胰腺肿瘤分割方法 TextSAM-EUS，该方法在推理阶段不需要手动几何提示。该方法通过 BiomedCLIP 文本编码器利用文本提示学习（上下文优化），结合基于 LoRA 的 SAM 架构微调，实现了胰腺肿瘤自动分割，仅微调了总参数的 0.86%。
### Innovation
TextSAM-EUS 引入了一种在基于 SAM 的医学影像分割中首次尝试使用提示学习的方法，仅需极少量参数的微调就能实现自动 EUS 分割，同时在精确度和鲁棒性方面表现优异，相较于现有的 SOTA 监督 DL 模型和基础模型（例如 SAM 及其变体）都具有优势。
### Conclusion
TextSAM-EUS 提供了一种高效且可靠的自动 EUS 胰腺肿瘤分割选项，并且此代码将在接收发表后公开。
## 72. `cs.AI` - 基于 BraTS-Pathology 挑战的胶质母细胞瘤形态病理特征识别的深度学习方法 [PDF](https://arxiv.org/pdf/2507.18133), [HTML](https://arxiv.org/abs/2507.18133)
### Authors
Juexin Zhang,Ying Weng,Ke Chen
### Background
胶质母细胞瘤是一种具有高度侵袭性和多样分子及病理特征的脑肿瘤，其异质性使其诊断极具挑战性。准确诊断和评估这种异质性对于选择合适的治疗方法和改善患者预后至关重要。传统方法依赖于在组织样本中识别特定特征，但深度学习为改进胶质母细胞瘤的诊断提供了有希望的方法。
### Innovation
该研究采用了预训练模型并将其在 BraTS-Path 训练数据集上微调，以识别胶质母细胞瘤的形态病理特征，并在 BraTS-Path 验证集上进行了严格评估。该模型在识别目标条件下的实例方面表现出了一致的能力，尤其是其对阴性案例分类的高敏感性。
### Conclusion
通过该模型在 BraTS-Path 挑战中的应用，计算了平均准确率为 0.392，召回率为 0.392，F1 得分为 0.392，显示出模型在预测和实际值之间的相关性有限，尽管其对阴性案例的分类能力表现出色（特异性为 0.898）。模型的整体预测能力由马修相关系数 (MCC) 为 0.255 表示。该解决方案在测试阶段获得了第二名的好成绩。
## 73. `cs.AI` - 基于U-Net的健康3D脑组织修复 [PDF](https://arxiv.org/pdf/2507.18126), [HTML](https://arxiv.org/abs/2507.18126)
### Authors
Juexin Zhang,Ying Weng,Ke Chen
### Background
本文介绍了一种合成从蒙版输入图像中三维健康脑组织的新方法，特别聚焦于‘ASNR-MICCAI BraTS 本地组织修复任务通过填补损失’。本文方法采用U-Net架构，旨在有效重建脑MRI扫描中缺失或受损的区域。为了提高模型的泛化能力和鲁棒性，在训练过程中随机蒙版健康图像以实施全面的数据增强策略。该模型在BraTS-Local-Inpainting数据集上进行训练，并在恢复健康脑组织方面表现出色。使用的评估指标包括结构相似性指数（SSIM）、信噪比峰值（PSNR）和均方误差（MSE），结果显示了显著的效果。在BraTS-Local-Inpainting验证集上，模型的SSIM得分为0.841，PSNR得分为23.257，MSE得分为0.007。这些评分的低标准差表明该模型具有跨各种输入场景的高度可靠性和一致性。此外，该方法在挑战中获得了第一名。
### Innovation
本文提出的方法采用了基于U-Net的架构，特别设计用于重建脑MRI扫描中缺失或受损的区域。此外，通过在训练过程中随机蒙版健康图像来实施全面的数据增强策略，以提高模型的泛化能力和鲁棒性。
### Conclusion
本文方法在BraTS-Local-Inpainting数据集上的评估指标（SSIM、PSNR和MSE）表现优异，特别在SSIM和MSE方面具有较低的标准差，显示出高可靠性和一致性，并且在挑战中获得第一。
## 74. `cs.AI` - 使用张量网络进行MRI图像生成的3D DDPM参数高效微调 [PDF](https://arxiv.org/pdf/2507.18112), [HTML](https://arxiv.org/abs/2507.18112)
### Authors
Binghua Li,Ziqing Chang,Tong Liang,Chao Li,Toshihisa Tanaka,Shigeki Aoki,Qibin Zhao,Zhe Sun
### Background
在磁共振成像（MRI）图像生成中，使用3D U-Net为基础的去噪扩散概率模型（DDPMs）的参数高效微调（PEFT）是一个挑战。尽管参数高效表示3D卷积操作在实践中具有重要意义，但该领域的研究仍然有限。用于MRI图像生成的3D DDPMs的微调方法需要大量的计算资源和存储空间，这限制了其在实际应用中的推广和应用。因此，迫切需要设计一种新的PEFT方法，以减少参数量，同时保持模型的性能，特别是在复杂空间依赖性的捕捉方面。传统的3D卷积操作参数量较大，如何有效地降低参数量并保持模型准确性是一个亟待解决的问题。
### Innovation
本文提出了一种名为Tensor Volumetric Operator (TenVOO)的新型PEFT方法，专门用于具有3D卷积骨干的DDPMs的微调。TenVOO利用张量网络建模，将3D卷积核表示为较低维度的张量，从而在微调过程中有效捕捉复杂的空间依赖关系，同时使用极少数参数。通过在三个脑MRI下游数据集ADNI、PPMI和BraTS2021上进行实验，对比现有方法，TenVOO在多尺度结构相似性指数测量（MS-SSIM）上取得了最先进的性能，同时仅需原始模型可训练参数的0.3%。
### Conclusion
本文提出并验证了TenVOO，这是一种用于3D DDPMs的PEFT方法，通过张量网络建模降低参数量的同时仍能有效捕捉空间依赖性。实验结果表明，TenVOO在MRI图像生成中的效果优于现有方法，同时模型的可训练参数量大大减少，为实际应用中的资源节约提供了可能。该方法为3D MRI图像生成的参数高效微调提供了一种新的解决思路。
## 75. `cs.AI` - Group Sequence Policy Optimization [PDF](https://arxiv.org/pdf/2507.18071), [HTML](https://arxiv.org/abs/2507.18071)
### Authors
Chujie Zheng,Shixuan Liu,Mingze Li,Xiong-Hui Chen,Bowen Yu,Chang Gao,Kai Dang,Yuqiong Liu,Rui Men,An Yang,Jingren Zhou,Junyang Lin
### Background
该论文介绍了一种新的强化学习算法——Group Sequence Policy Optimization (GSPO)，用于训练大规模语言模型。与之前基于标记重要性比的算法不同，GSPO 是基于序列似然性定义重要性比，并在序列层面进行裁剪、奖励和优化。
### Innovation
GSPO 算法通过基于序列似然性定义重要性比并进行序列级别裁剪、奖励和优化，实现了比 GRPO 更高的训练效率和性能，特别稳定了 Mixture-of-Experts (MoE) RL 训练，并有可能简化 RL 基础设施的设计。
### Conclusion
GSPO 算法在最新 Qwen3 模型中的表现显示了其对训练效率和性能的显著提升和简化 RL 基础设施设计的潜力。
## 76. `cs.AI` - 分布不确定性在异常分布检测中的应用 [PDF](https://arxiv.org/pdf/2507.18106), [HTML](https://arxiv.org/abs/2507.18106)
### Authors
JinYoung Kim,DaeUng Jo,Kimin Yun,Jeonghyo Song,Youngjoon Yoo
### Background
使用深度神经网络估计不确定性是检测异常分布样本的一种常见方法，这类样本通常表现出高预测不确定性。然而，传统的蒙特卡洛（MC）丢弃等方法通常只关注模型或数据不确定性，未能与OoD检测的语义目标对齐。
### Innovation
提出了一种名为Free-Energy Posterior Network的新框架，它可以同时建模分布不确定性并识别OoD和错误分类区域。该方法贡献了两个关键部分：1.基于Beta分布的自由能密度估计器，可以对含糊或未知区域进行细粒度的不确定性估计；2. 包含在后验网络中的损失函数，可以直接从学习的参数中进行不确定性估计，而不需要进行随机采样。
### Conclusion
该方法通过与残差预测分支（RPL）框架的结合，在网络中利用Beta分布的方差来学习OoD区域，从而实现一种语义上和计算上都高效的不确定性感知分割解决方案，并在Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can等具有挑战性的实际基准测试中验证了其有效性。
## 77. `cs.AI` - 在均值上固守：检测文本嵌入模型中的‘粘性 token’ [PDF](https://arxiv.org/pdf/2507.18171), [HTML](https://arxiv.org/abs/2507.18171)
### Authors
Kexin Chen,Dongxia Wang,Yi Liu,Haonan Zhang,Wenhai Wang
### Background
尽管基于Transformer的文本嵌入模型在自然语言处理（NLP）任务中被广泛使用，但某些‘粘性 token’却会降低嵌入的可靠性。这些token会以独特的方式影响句子相似度，并破坏嵌入距离的正常分布，从而影响下游任务的性能。
### Innovation
该研究系统地调查了这些异常token，首次正式定义了它们，并基于句子和token过滤引入了高效检测方法‘粘性 token检测器’（STICKY TOKEN DETECTOR, STD）。通过对14个模型家族、共40个检查点进行检测，发现了868个‘粘性 token’。研究发现这些token多来源于词汇表中的特殊或未使用的条目以及多语言数据集中的碎片化子词。
### Conclusion
研究结果表明，token在模型内部表示中占据主导地位，导致性能显著下降（高达50%）。未来需要更好的token化策略和模型设计来缓解粘性token对文本嵌入应用的影响。
## 78. `cs.AI` - Differential-UMamba: 在有限数据场景下重新思考肿瘤分割 [PDF](https://arxiv.org/pdf/2507.18177), [HTML](https://arxiv.org/abs/2507.18177)
### Authors
Dhruv Jain,Romain Modzelewski,Romain Hérault,Clement Chatelain,Eva Torfeh,Sebastien Thureau
### Background
在数据稀缺场景中，深度学习模型往往会对噪声和无关模式过拟合，这限制了它们在处理未见过的样本时的泛化能力。
### Innovation
提出了Diff-UMamba，一种结合了UNet框架和mamba机制的新架构，用于建模长距离依赖关系。核心是一个噪声减少模块（NRM），通过信号差分策略抑制编码器中的噪声或无关激活，促进模型筛选出虚假特征并增强任务相关表示，从而提高其对临床相关区域的关注。因此，该架构在低数据设置下实现了更高的分割准确性和鲁棒性。
### Conclusion
Diff-UMamba 在多个公开数据集上进行了评估，包括 MSD (肺部和胰腺) 和 AIIB23，展示了相对于基线方法在多种分割任务上的一致性能提升，范围为 1-3%。通过在 BraTS-21 数据集上调整可用训练样本的比例进一步评估了在有限数据条件下的表现，并在小规模的内部非小细胞肺癌 (NSCLC) 数据集上实现了基线方法 4-5% 的改进，用于锥束 CT (CBCT) 中的大肿瘤体积 (GTV) 分割。
## 79. `cs.AI` - HIVMedQA: 大型语言模型用于HIV医疗决策支持的基准测试 [PDF](https://arxiv.org/pdf/2507.18143), [HTML](https://arxiv.org/abs/2507.18143)
### Authors
Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux
### Background
大型语言模型（LLMs）正在成为支持医护人员在日常决策中使用的重要工具。艾滋病管理因其复杂性（多种治疗选择、合并症和依从性挑战）而成为一个引人注目的应用场景。然而，将LLMs整合到临床实践中也面临着准确度、潜在伤害以及医护人员接受度的担忧。尽管人工智能在艾滋护理领域的应用前景广阔，但仍有很多潜力未被开发，特别是关于LLMs在HIV护理中的基准测试研究还很匮乏。这项研究评估了LLMs在艾滋病管理中的当前能力，突出了它们的优势和局限性。通过HIVMedQA数据集对七种通用和三种专门医学的LLMs进行了评估，实现了对艾滋病护理中的开放性医疗问题回答能力的基准测试。
### Innovation
本研究推出了一种名为HIVMedQA的基准测试，重点评估大型语言模型在HIV医疗决策支持中的表现。此基准测试通过精心策划的、临床相关的问题集，考虑了临床语境下的问题生成和回答，采用了标签相似性和LLM作为评审员的方法进行评估，还扩展了评估方法以更好地反映临床相关性。研究结果表明，GeRmi 2.5 Pro在大多数评估维度上表现最佳，证实了针对性开发和评估对确保大型语言模型在临床护理中安全、有效整合的重要性。研究还发现了临床推理和理解比事实回忆更具挑战性，以及最近性和现状偏差等认知偏差的存在。
### Conclusion
研究结果强调了需要有目标地开发和评估大型语言模型，以确保它们在临床护理中的安全和有效性。LLM在复杂临床问题上的表现不尽相同，最优秀的表现者甚至是非公开的模型。在构建更加准确和有效的医疗支持系统方面，需要深入研究以克服LLM的局限性，并不断优化其性能，特别是在复杂问题的处理上。
## 80. `cs.AI` - MoRPI-PINN: 一种用于移动机器人纯惯性导航的物理信息框架 [PDF](https://arxiv.org/pdf/2507.18206), [HTML](https://arxiv.org/abs/2507.18206)
### Authors
Arup Kumar Sahoo,Itzik Klein
### Background
移动机器人实现完全自主的一个基本要求是在没有卫星导航或摄像头的情况下也能进行精确的导航。在这种实际情境下，仅依靠惯性传感器进行导航会导致由于传感器固有的噪音和误差累积而造成的定位解漂移。一种缓解这种漂移的方法是让机器人以蛇状爬行的方式移动，这种方法能够增加惯性信号的信噪比，从而允许进行移动机器人位置的回归.
### Innovation
本文提出了一种基于物理信息的神经网络框架MoRPI-PINN，通过在训练过程中嵌入物理法则和约束，MoRPI-PINN能够提供准确且稳健的惯性定位解决方案。实验证明，与现有方法相比，MoRPI-PINN在实际应用中的精度提高了85%以上。MoRPI-PINN是一个轻量级的解决方案，可以用于边缘设备上的任意典型的移动机器人应用.
### Conclusion
MoRPI-PINN能够在各种实际应用中提供准确且稳健的惯性导航解决方案，且适用于边缘设备，展示了其在移动机器人领域的有效性和实用性.
## 81. `cs.AI` - 使用GMTP保护RAG管道：一种基于梯度的掩蔽令牌概率方法以检测恶意文档 [PDF](https://arxiv.org/pdf/2507.18202), [HTML](https://arxiv.org/abs/2507.18202)
### Authors
San Kim,Jonghwi Kim,Yejin Jeon,Gary Geunbae Lee
### Background
RAG通过提供外部知识增强大型语言模型（LLMs），使模型能够生成准确和最新的响应。然而，对这些外部来源的依赖也带来了一个安全风险，攻击者可以向知识库中注入被污染的文档以操控生成过程，导向有害或误导性的输出。
### Innovation
本研究提出了一种名为Gradient-based Masked Token Probability (GMTP)的新颖防御方法，用于检测和过滤恶意制作的文档。GMTP通过分析检索器相似性函数的梯度来识别具有高影响的令牌，然后对这些关键令牌进行遮掩，并通过Masked Language Model (MLM)检查它们的概率。由于被注入的令牌通常具有明显低的掩蔽令牌概率，这对GMTP来说很容易检测恶意文档，并实现高精度过滤。实验结果显示，GMTP能够清除超过90%的被污染内容，同时保留相关文档，从而在多种数据集和对抗性设置下保持鲁棒的检索和生成性能。
### Conclusion
GMTP能够在保留教育内容的同时几乎完全消除恶意文档，显著提高了RAG系统的安全性。该方法在不同环境和对抗性设置下都表现出了高效性。
## 82. `cs.AI` - 从个体学习到市场均衡：修正RL模拟经济模型中的结构性和参数偏倚 [PDF](https://arxiv.org/pdf/2507.18229), [HTML](https://arxiv.org/abs/2507.18229)
### Authors
Zeqiang Zhang,Ruxin Chen
### Background
该研究揭示了强化学习（RL）在经济建模中的应用揭示了均衡理论假设与学习代理的涌现行为之间的根本冲突。经典经济模型假设原子化的个体作为市场的‘接受者’进行行为，而RL单代理的模拟则激励代理成为其环境的‘操纵者’。研究通过一个搜索与匹配模型以及凹生产函数，展示了标准RL代理学习一个非均衡的垄断主义政策。这也指出了由于经济贴现率与RL对时间成本处理之间的不匹配而产生的参数偏倚。
### Innovation
该研究提出了一种校准的均场强化学习框架，将代表性的个体代理人嵌入固定宏观经济场中，并调整成本函数以反映经济机会成本。该创新方法通过迭代算法使得代理人的策略与竞争性均衡相一致，从而提供了一个在计算社会科学领域用于建模经济系统中学习代理的实用且理论健全的方法。
### Conclusion
通过这一方法，研究认为提供了一个实用且理论健全的建模方法来模拟经济学体系中的学习代理，纠正了在RL模拟经济模型中的结构性和参数偏倚。
## 83. `cs.AI` - 通过后训练增强视频生成中的场景过渡意识 [PDF](https://arxiv.org/pdf/2507.18046), [HTML](https://arxiv.org/abs/2507.18046)
### Authors
Hanwen Shen,Jiajie Lu,Yupeng Cao,Xiaonan Yang
### Background
近年来，AI生成视频在文本到视频任务（尤其是单一场景的短片段）方面表现出强大的性能。然而，当前的模型在生成较长的视频时遇到困难，特别是无法根据提示识别何时需要场景过渡，因为它们缺乏从提示中推断出是否需要场景过渡的能力。大多数开源模型是在包含单一场景视频片段的数据集上进行训练的，这限制了它们在需要多个场景的提示下的学习和响应能力。多场景生成的关键在于场景过渡意识，这使得模型能够通过准确检测过渡的方式识别并分割视频成不同的片段。
### Innovation
本文提出了一个名为Transition-Aware Video (TAV)的数据集，包含有多个场景过渡的预处理视频片段。实验表明，在TAV数据集上进行后训练可以提高基于提示的场景过渡理解能力，缩小要求场景和生成场景之间的差距，并保持图片质量。
### Conclusion
通过引入新的TAV数据集并使用后训练方法，可以提高视频生成模型在处理多场景时的场景过渡意识，从而推动该领域的进一步发展。
## 84. `cs.AI` - 基于大型语言模型的信息安全：一种综述 [PDF](https://arxiv.org/pdf/2507.18215), [HTML](https://arxiv.org/abs/2507.18215)
### Authors
Chang Gong,Zhongwen Li,Xiaoqi Li
### Background
当前，信息安全正面临越来越严峻的挑战，传统的保护方法难以应对复杂多变的威胁。近年来，作为一种新兴的智能技术，大型语言模型（LLMs）在信息安全领域展现出广泛的应用前景。
### Innovation
该文集中在大型语言模型在信息安全中的关键作用，系统地回顾了它在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和加密算法优化等领域的应用进展，并探讨了其在提升安全防护性能方面的潜力。文中基于神经网络和Transformer架构，分析了大型语言模型的技术基础及其在自然语言处理任务中的优势，表明大型语言模型的应用有助于提高检测准确性并降低误报率。
### Conclusion
当前的应用结果显示，大型语言模型在信息安全方面仍面临模型透明度、可解释性等问题的挑战。需要进一步优化模型结构和提升泛化能力，以实现更智能和精确的信息安全保护系统。
## 85. `cs.AI` - GenAI for Automotive Software Development: From Requirements to Wheels [PDF](https://arxiv.org/pdf/2507.18223), [HTML](https://arxiv.org/abs/2507.18223)
### Authors
Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll
### Background
本文探讨了使用生成人工智能（GenAI）赋能的方法来自动化汽车软件开发，特别关注自动驾驶和先进驾驶辅助系统（ADAS）的能力。该过程从需求为输入开始，主要生成输出包括用于仿真环境的测试场景代码，以及针对连接测试台的车辆硬件平台实现所需的ADAS功能。此外，通过模型驱动工程（MDE）进行需求一致性检查的步骤也被引入。在提议的工作流中，大型语言模型（LLMs）用于基于模型的需求总结（Ecore元模型、XMI模型实例和OCL约束创建）、测试场景生成、仿真代码（Python）和目标平台代码生成（C++）。此外，通过检索增强生成（RAG）方法从自动驾驶相关法规文档中增强测试场景的生成。这种方法旨在缩短合规性和重新工程的周期，以及减少与ADAS相关功能的开发和测试时间。
### Innovation
本文提出了一种新的工作流程，集成使用大型语言模型进行基于模型的需求总结、测试场景生成和代码生成，同时采用检索增强生成方法来生成测试场景。这种方法旨在提高ADAS相关功能的自动化和效率，缩短合规性和重新工程的周期，以及减少开发和测试时间。
### Conclusion
该方法能够显著提高自动驾驶汽车软件开发的速度和效率，确保ADAS功能的快速迭代和测试，从而加速车辆的市场推出。
## 86. `cs.AI` - 利用扩散先验的高斯无谬表征学习以增强红外小目标检测 [PDF](https://arxiv.org/pdf/2507.18260), [HTML](https://arxiv.org/abs/2507.18260)
### Authors
Junyao Li,Yahao Lu,Xingyuan Guo,Xiaoyu Xian,Tiantian Wang,Yukai Shi
### Background
红外小目标检测（ISTD）在众多实际应用中发挥着重要作用。为了确定其性能边界，研究者们采用大规模且昂贵的手动标注数据来进行表示学习。然而，这种方法使最先进的ISTD方法在现实挑战中变得脆弱。本文研究了在多种缺乏高质量红外数据（即数据稀缺）的情况下，主流方法检测性能的变化，以此挑战现有的关于实际ISTD的理论。
### Innovation
提出了一种高斯无谬表征学习方法，具体包括高斯组压榨器，利用高斯采样和压缩进行非均匀量化。通过利用多样化的训练样本，增强ISTD模型对各种挑战的抗性。同时介绍了两阶段扩散模型用于现实场景重建，通过使量化信号紧密符合真实分布，显著提升合成样本的质量和保真度。
### Conclusion
对比在各种缺乏高质量数据场景下的先进检测方法，本文提出的方法表现出了良好的有效性。
## 87. `cs.AI` - Locate-and-Focus: 提升语音语言模型中术语翻译 [PDF](https://arxiv.org/pdf/2507.18263), [HTML](https://arxiv.org/abs/2507.18263)
### Authors
Suhang Wu,Jialong Tang,Chengyi Yang,Pei Zhang,Baosong Yang,Junhui Li,Junfeng Yao,Min Zhang,Jinsong Su
### Background
直接语音翻译（ST）近年来受到了越来越多的关注，但对于句中术语的准确翻译仍然是一个巨大的挑战。现有研究主要集中在将各种翻译知识引入到ST模型中，但这些方法往往难以处理无关噪声的干扰，无法充分利用翻译知识。因此，本文旨在解决这些问题，提出了一种新颖的Locate-and-Focus方法来提高术语翻译效果。首先，它有效地定位句中包含术语的语音片段，建立翻译知识并减少对ST模型无关信息的影响。其次，该方法将翻译知识与来自语音和文本模态的陈述和假设联系起来，使ST模型在翻译过程中更好地专注于翻译知识。
### Innovation
提出了一种新颖的Locate-and-Focus方法来提升术语翻译能力。具体来说，该方法通过有效定位句中包含术语的语音片段来建立翻译知识，并结合语音和文本模态的数据，使ST模型更好地关注翻译知识，从而解决了现有方法难以处理无关噪声的干扰，无法充分利用翻译知识的问题。
### Conclusion
在多个数据集上的实验结果表明，该方法能够有效在句中定位术语并提高术语翻译的成功率，同时保持稳健的一般翻译性能。
## 88. `cs.AI` - ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation [PDF](https://arxiv.org/pdf/2507.18262), [HTML](https://arxiv.org/abs/2507.18262)
### Authors
Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong
### Background
现有的机器人操作方法在约束建模的语义粒度方面较粗糙，缺乏实时闭环规划能力，以及在语义多样环境中表现不佳的问题。这些方法难以统一任务理解和执行，限制了机器人在复杂环境中的操作灵活性。
### Innovation
提出了一种名为ReSem3D的统一操作框架，该框架利用Vision Foundation Models (VFMs)和Multimodal Large Language Models (MLLMs)的协同作用，实现细粒度的视觉定位，并动态构建分层次的3D空间约束，以实现实时操作。该框架通过多层次递归推理在MLLMs中驱动，并与VFMs交互，从自然语言指令和RGB-D观察中自动构建3D空间约束。
### Conclusion
ReSem3D在语义丰富的家庭和稀疏的化学实验室环境中进行了广泛的模拟和现实世界实验，结果显示在零样本条件下能够执行多种操作任务，表现出强大的适应性和泛化能力。
## 89. `cs.AI` - 当图上的噪声标签遇到类别不平衡：基于LLM和伪标签的图增强方法 [PDF](https://arxiv.org/pdf/2507.18153), [HTML](https://arxiv.org/abs/2507.18153)
### Authors
Riting Xia,Rucong Wang,Yulin Liu,Anchen Li,Xueyan Liu,Yan Zhang
### Background
类不平衡的图节点分类是一个实际但未被充分探索的研究问题。尽管最近的研究已经尝试解决这个问题，但它们通常假设处理类不平衡的图时标签是干净和可靠的。然而，在真实世界中，标签经常包含噪声，因此存在这样的差距。
### Innovation
本文提出了GraphALP，一种基于大语言模型（LLMs）和伪标签技术的新型图增强框架。具体而言，设计了一种基于LLM的过采样方法来生成合成的少数类节点，以生成准确标签的少数类节点，缓解类不平衡问题。基于平衡类的图，开发了一种动态加权伪标签方法来获取高置信度的伪标签，并减少标签噪声比率。此外，实施了一个由伪标签引导的二次过采样机制，以减轻由伪标签引起的潜在类别分布偏斜。
### Conclusion
实验结果显示，GraphALP在具有噪声标签的类不平衡图上的性能优于最先进的方法。
## 90. `cs.AI` - LoRA-Leak：针对LoRA微调语言模型的成员推理攻击 [PDF](https://arxiv.org/pdf/2507.18302), [HTML](https://arxiv.org/abs/2507.18302)
### Authors
Delong Ran,Xinlei He,Tianshuo Cong,Anyu Wang,Qi Li,Xiaoyun Wang
### Background
语言模型（LMs）通常遵循‘预训练和微调’模式，其中通用的预训练模型可以微调以适应各种专业领域。低秩适应（LoRA）因其计算成本低和出色的性能，在LM微调中得到广泛应用。由于LoRA调优的数据量相对较小，人们可能误认为LoRA微调数据对成员推理攻击（MIAs）具有抵抗力。然而，现有MIAs忽略了利用预训练模型引发的信息泄漏。因此，本文提出了一种名为LoRA-Leak的全面评估框架，用于评估MIAs对语言模型微调数据集的影响。
### Innovation
本文引入了LoRA-Leak，这是一种全面的安全评估框架，用于验证LoRA微调语言模型是否容易受到MIAs的影响。该框架整合了十五种成员推理攻击，包括现有的和改进的五种攻击，这些改进的攻击利用了预训练模型的参考。通过在不同微调设置下应用LoRA-Leak，研究揭示了微调设置对隐私风险的影响。进一步研究发现，仅通过在微调过程中使用dropout和排除特定LM层可有效减轻MIAs的风险，同时保持功能完整性。
### Conclusion
我们发现，基于LoRA的微调语言模型仍然容易受到MIAs的影响，并强调了在‘预训练和微调’框架中预训练模型的存在使得LoRA-based LM对MIAs更为敏感。我们认为这些发现可以为专业LM提供商的数据隐私保护提供指导。
## 91. `cs.AI` - 基于眼动追踪和大语言模型推理的多模态行为模式分析 [PDF](https://arxiv.org/pdf/2507.18252), [HTML](https://arxiv.org/abs/2507.18252)
### Authors
Dongyang Guo,Yasmeen Abdrabou,Enkeleda Thaqi,Enkelejda Kasneci
### Background
眼动追踪数据能够提供有价值的用户认知状态见解，但由于其结构化且非语言的特性，分析起来非常困难。虽然大语言模型在处理文本推理方面表现出色，但在处理时间序列和数值数据时却具有局限性。因此，本文提出了一个结合了多模态人机协作的框架，旨在增强从眼动追踪信号中提取认知模式的能力。该框架包括多阶段流水线，利用水平和垂直分割结合大语言模型的推理；专家-模型联合评分模块将专家判断与大语言模型输出结合，生成行为解释的信任分数；以及融合基于LSTM的时间模型和大语言模型驱动语义分析的混合异常检测模块。该框架通过几个大语言模型和提示策略的不同表现验证了其在一致性和可解释性方面的改进，以及在难度预测任务中的高达50%的准确性。这种方法为认知建模提供了一个可扩展和可解释的解决方案，并在自适应学习、人机交互和教育分析等领域具有广泛的应用潜力。
### Innovation
提出了一个结合了多模态人机协作的框架，通过多阶段流水线利用水平和垂直分割结合大语言模型的推理；专家-模型联合评分模块将专家判断与大语言模型输出结合，生成行为解释的信任分数；以及融合基于LSTM的时间模型和大语言模型驱动语义分析的混合异常检测模块，从而提升从眼动追踪信号中提取认知模式的能力。这种方法通过验证在一致性和可解释性方面的改进，以及在难度预测任务中的高达50%的准确性，证明了其在多个方面具有创新性。该方法解决了眼动追踪数据分析的困难，并且为认知建模和其他相关领域提供了新的思路和工具。
### Conclusion
该研究通过多模态人机协作框架，结合大语言模型的推理分析，显著提升了眼动追踪数据的分析性能。与现有方法相比，这种框架在实验中的表现更为一致、可解释，特别是在难度预测任务中，准确率达到了50%。这表明该方法为认知建模和人类行为分析提供了一种可扩展的、可解释的解决方案，具有广泛的应用潜力，尤其是在自适应学习、人机交互和教育分析等领域的应用。
## 92. `cs.AI` - 通过基本颜色添加剂提高鸟类分类 [PDF](https://arxiv.org/pdf/2507.18334), [HTML](https://arxiv.org/abs/2507.18334)
### Authors
Ezhini Rasendiran R,Chandresh Kumar Maurya
### Background
本研究解决了利用鸟类歌声录音进行分类的问题，这是一项具有挑战性的任务，因为受到了环境噪音、重叠发音和标签缺失的影响。现有模型在低信噪比或多物种录音的情况下表现不佳。我们假设可以通过可视化音高模式、速度和重复等特性（统称为特征模式）来对鸟类进行分类。虽然深度学习模型在频谱图图像的应用有所帮助，但由于不同鸟类之间存在相似的特征模式，这会带来混淆。
### Innovation
为了解决这一问题，该研究将频率信息嵌入到频谱图中，使用主要颜色添加剂。这增强了物种之间的区分，并提高了分类准确性。实验结果表明，所提出的方法在无需彩色化的模型上实现了统计学上的显著提高，并超越了2024年鸟类分类挑战赛（BirdCLEF 2024）的获胜者，在F1分数、ROC-AUC和CMAP方面分别提高了7.3%、6.2%和6.6%。
### Conclusion
这些结果证明了通过颜色化集成频率信息的有效性。
## 93. `cs.AI` - 一个多数据集基准测试用于ECG波形分割的半监督语义分割 [PDF](https://arxiv.org/pdf/2507.18323), [HTML](https://arxiv.org/abs/2507.18323)
### Authors
Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo
### Background
心电信号（ECG）的划分是临床诊断的关键步骤。尽管最近使用深度学习取得了进展，但由于可用的标注数据集稀缺，进步有限。半监督学习通过利用大量未标注的ECG数据提供了一种有前景的解决方案。这篇论文旨在构建第一个系统化的半监督语义分割基准，用于ECG波形划分，以支持更稳健和多样化的评估。通过整合多个公开数据集，提出了ECG特定的训练配置和增强策略，并引入了标准化评估框架。研究结果显示，变压器在半监督ECG划分中优于卷积网络。
### Innovation
构建了第一个针对ECG波形划分的半监督语义分割基准，整合了多个公开数据集，并且提供了ECG特定的训练配置和增强策略，同时提出和使用了标准化评估框架。并提出变压器在半监督ECG划线上表现优于卷积网络。这一工作为推动半监督ECG划分方法的发展提供了一个基础，并促进了该领域的进一步研究。
### Conclusion
我们的基准测试表明，变压器在半监督ECG划分中优于卷积网络，期望这一基准测试将成为推动半监督ECG划分方法发展的一个基础，并将促进该领域的进一步研究。
## 94. `cs.AI` - TCM-Tongue: 一种用于辅助中医诊断的人工智能标准舌像数据集及其病理标注 [PDF](https://arxiv.org/pdf/2507.18288), [HTML](https://arxiv.org/abs/2507.18288)
### Authors
Xuebo Jin,Longfei Gao,Anshuo Tong,Zhengyang Chen,Jianlei Kong,Ning Sun,Huijun Ma,Qiang Wang,Yuting Bai,Tingli Su
### Background
传统中医舌诊在临床实践中具有重要价值，但由于其主观解释和不一致的成像协议带来的标准化挑战，以及缺乏大规模标注的数据集以促进人工智能发展，其应用受到了限制。
### Innovation
本文提供了首个用于人工智能驱动的中医舌诊的专业数据集，包含6,719张在标准化条件下拍摄的高质量图像，并附有20种病理症状分类的标注（平均每张图像有2.54个临床验证标注，所有标注均经中医执业医师验证）。此外，数据集支持多种标注格式（COCO、TXT、XML），并在九种深度学习模型中进行了基准测试，以证明其对人工智能发展的实用性。这一资源为推进可靠的人工智能工具在中医中的应用提供了关键基础，弥补了该领域的数据短缺问题，有助于将人工智能标准化高质量诊断数据应用于研究和临床实践中。
### Conclusion
该资源为提高中医的可靠计算工具起到了关键作用，克服了数据不足的问题，并为人工智能技术在中医中的应用提供了标准化、高质量的数据支持，促进了中医与AI的深入融合。
## 95. `cs.AI` - 一种允许技术、法律、文化和伦理差异的高效自动驾驶可扩展概念 [PDF](https://arxiv.org/pdf/2507.18326), [HTML](https://arxiv.org/abs/2507.18326)
### Authors
Lars Ullrich,Michael Buchholz,Jonathan Petit,Klaus Dietmayer,Knut Graichen
### Background
自动驾驶（AD）的有效扩展是降低费用、提高安全性和优化资源的关键。然而，研究主要集中在特定车辆和情境上，大规模部署需要不同配置和环境中的扩展能力。不同类型的车辆、传感器、执行器，以及交通法规、法律要求、文化动态或伦理范式之间的差异要求高度的灵活性。本文探讨了在这些复杂因素中对通用能力进行可扩展适应及定制的问题。
### Innovation
本文提出了一种基于两阶段微调过程的概念，旨在实现对特定环境的技术适应，并通过国家特定的奖励模型将技术适应与社会政治需求联系起来。第二阶段涉及基于车辆的迁移学习，以促进系统的适应并验证设计决策。此方法强调技术和社会政治方面的数据驱动集成，以有效应对技术、法律、文化和伦理方面的差异。
### Conclusion
提出的概念提供了一种数据驱动的过程，能够整合技术和社会政治方面的影响，并实现对自动驾驶技术的有效扩展，覆盖了技术、法律、文化和伦理的不同方面。
## 96. `cs.AI` - 恢复节奏：使用变压器模型对孟加拉语进行标点符号恢复 [PDF](https://arxiv.org/pdf/2507.18448), [HTML](https://arxiv.org/abs/2507.18448)
### Authors
Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu
### Background
标点符号恢复能够提升文本的可读性，并对于自动语音识别(ASR)后处理任务至关重要，特别是在低资源语言如孟加拉语中。研究探讨了使用基于变压器的模型(XLM-RoBERTa-large)自动恢复未标注孟加拉语文本标点的可行性，重点关注预测四个标点符号：句号、逗号、问号和感叹号，并进行跨领域文本研究。由于标注资源稀缺，构建了一个大型、多样化的训练语料并应用了数据增强技术。
### Innovation
研究尝试使用XLM-RoBERTa-large模型自动恢复孟加拉语标点，解决了低资源语言的标注资源稀缺问题，通过数据增强技术提升了模型性能，并实现了在新闻、参考和ASR采集文本集上的强泛化能力，展示了在真实场景中的有效性。同时，该研究提供了广泛基准，并分享了公共可用的数据集和代码，以支持低资源自然语言处理领域的未来研究。
### Conclusion
该研究为孟加拉语标点符号恢复建立了坚实的基线，并通过公共提供的数据集和代码促进了未来相关领域的研究。
## 97. `cs.AI` - CLEAR: 通过LLM-as-a-Judge进行错误分析简化版 [PDF](https://arxiv.org/pdf/2507.18392), [HTML](https://arxiv.org/abs/2507.18392)
### Authors
Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer
### Background
当前，大型语言模型（LLMs）的评估越来越多地依赖于其他LLM作为评判者。然而，现有的评估模式通常只提供单一分数或排名，表明哪个模型更好，但未能解释其原因。虽然对于基准测试是必要的，但这些顶层分数掩盖了模型表现背后的特定可行动原因。为了弥合这一差距，本文提出了CLEAR，这是一个交互式、开源的包，用于基于LLM的错误分析。CLEAR首先生成每个实例的文本反馈，然后创建一套系统级别的错误问题，并量化每个识别问题的出现频率。该包还提供了用户交互式的仪表板，可以进行全面的错误分析，通过聚合可视化展示，应用交互式过滤器以隔离特定的问题或评分范围，并深入到具体实例中以呈现特定行为模式。
### Innovation
CLEAR是一个交互式、开源的包，旨在通过基于LLM的生成实例级反馈、系统性错误问题及其频率的量化分析，提供更深入的模型评估和行为分析。它通过交互式仪表板，提供聚合可视化、交互式过滤和深入实例的工具，使得用户能够全面分析模型的具体表现。该包特别应用于RAG和Math基准测试，展示了其实用性和功能。
### Conclusion
本文介绍了CLEAR，一种基于LLM的错误分析工具包，通过实例级反馈、系统性问题量化以及交互式界面，提出了一个全新的评估方法。通过实际应用证明，CLEAR能够提供更具体的、可操作的模型性能反馈，弥补了单一评分的不足。
## 98. `cs.AI` - FedSA-GCL：一种基于个性化聚合和簇感知广播的半异步联邦图学习框架 [PDF](https://arxiv.org/pdf/2507.18219), [HTML](https://arxiv.org/abs/2507.18219)
### Authors
Zhongzheng Yuan,Lianshuai Guo,Xunkai Li,Yinlin Zhu,Wenyu Wang,Meixia Qu
### Background
联邦图学习（FGL）是一种分布式学习范式，能够在多个本地系统上协作训练大规模子图。然而，现有的大多数 FGL 方法依赖于同步通信，这在实际部署中会导致效率低下并且通常是不可行的。此外，当前的异步联邦学习（AFL）方法主要针对图像分类和自然语言处理等传统任务设计，而没有考虑图数据的独特的拓扑属性。直接将这些方法应用于图学习可能会导致全局模型在语义和表示上出现不一致。
### Innovation
本文提出了一种半异步联邦框架 FedSA-GCL，该框架通过一种新颖的 ClusterCast 机制结合了客户端标签分布差异和图拓扑特性，实现高效训练。与9个基线方法的比较结果表明，该方法展现了优越的鲁棒性和效率，在Louvain和平米斯划分算法上的平均性能提升分别为2.92%和3.4%。
### Conclusion
FedSA-GCL 在多个真实世界的图数据集上进行了评估，并展示了其强大的鲁棒性和卓越的效率，优于基线方法。
## 99. `cs.AI` - 重新审视针对基于LiDAR的检测的物理可实现攻击：澄清问题表述和实验协议 [PDF](https://arxiv.org/pdf/2507.18457), [HTML](https://arxiv.org/abs/2507.18457)
### Authors
Luo Cheng,Hanwei Zhang,Lijun Zhang,Holger Hermanns
### Background
基于LiDAR的3D物体检测因其在现实世界中的广泛应用成为关键研究领域。虽然已有大量的数字攻击能够操控点云或网格，但它们往往缺乏可实现性，限制了其实用影响。物理实体攻击在这方面的研究尚未充分展开，且由于实验设置和硬件设备的不稳定，导致其重现性较差。
### Innovation
本文提出了一种设备无关、标准化的框架，该框架从核心层面抽象出了物理实体攻击的关键元素，支持多种方法，并提供开源代码和仿真与现实环境中的基准测试协议。该框架能够实现公平比较，加速研究进程，并通过仿真攻击的有效转移在物理LiDAR系统中得到验证。此外，文章还提供了影响攻击成功率的因素见解，从而加深了对现实世界LiDAR感知中鲁棒性的理解。
### Conclusion
该框架通过提高实验协议的标准化和重现性，鼓励了更公平的研究比较，并演示了物理可实现攻击的有效转移。这不仅推动了物理实体攻击在LiDAR检测领域的研究进程，也为理解外部干扰对物理LiDAR系统的影响提供了新视角。
## 100. `cs.AI` - 数字孪生技术在预测性维护中的应用：通过模拟到真实和真实到模拟的转移实现可转移性 [PDF](https://arxiv.org/pdf/2507.18449), [HTML](https://arxiv.org/abs/2507.18449)
### Authors
Sizhe Ma,Katherine A. Flanigan,Mario Bergés
### Background
物联网（IoT）和人工智能（AI）的发展推动了数字孪生（DT）从概念向更具实施性的现实转变。然而，从学术界到工业界的应用存在挑战，主要是因为缺乏标准化框架。现有研究主要集中在资产转移上，而模拟到现实以及现实到模拟的转移对于实现DT的全生命周期管理至关重要，但这一过程中存在模拟预测与实际结果之间的差距校准难题。本文旨在通过在现有DT框架中集成单一的现实差距分析（RGA）模块，解决这一问题，以实现模拟与现实操作之间的双向知识转移。
### Innovation
本文的主要创新在于提出了在现有DT框架中集成单一RGA模块的方法，并通过数据管道将RGA模块与历史存储库、仿真模型等现有组件连接起来，实现模拟到现实和现实到模拟的双向知识转移。这种方法通过案例研究验证了在提高效率的同时实现双向知识转移的有效性。
### Conclusion
通过在现有DT框架中集成RGA模块和建立完整的数据管道，本文提出的方法能够实现模拟与现实操作之间的双向知识转移，为数字孪生技术的全面应用和生命周期管理提供了有效的解决方案。
## 101. `cs.AI` - AraTable: 评估大型语言模型在阿拉伯表格数据推理和理解方面的基准 [PDF](https://arxiv.org/pdf/2507.18442), [HTML](https://arxiv.org/abs/2507.18442)
### Authors
Rana Alshaikh,Israa Alghanmi,Shelan Jeawak
### Background
大型语言模型（LLMs）的推理和推理能力在自然语言处理方面取得了显著进步，但在解释结构化数据，尤其是表格格式的数据方面表现有限。尽管存在针对英文表格数据的广泛基准，但阿拉伯语由于公共资源有限且语言特性独特而被严重忽视。为此，本文提出AraTable，一个新颖且全面的基准，旨在评估LLMs在处理阿拉伯语表格数据时的推理和理解能力。AraTable涵盖多种评估任务，包括直接问答、事实验证和复杂推理，并涉及广泛的阿拉伯语表格数据源。初步分析显示，尽管LLMs在简单的表格任务上表现良好，但在需要更深入推理和事实验证的任务上仍然面临重大挑战，未来在复杂表格推理领域仍有很大改进空间。
### Innovation
提出了AraTable，一个用于评估大型语言模型在阿拉伯语表格数据推理和理解能力的新型全面基准。该基准包含多种评估任务，覆盖广泛的阿拉伯语表格数据源。还提出了一种完全自动化的评估框架，使用自我推理机制，性能几乎与人工评判相同，为处理和分析阿拉伯语结构化数据的未来研究提供了有价值的标准和框架。
### Conclusion
AraTable为加速发展处理和分析阿拉伯语结构化数据的基础模型提供了宝贵的、可供公开获取的资源和评估框架。初步分析表明，虽然LLMs在简单的直接问答任务上能达到良好表现，但在需要更深入推理和事实验证的任务上仍存在显著挑战，未来有大量改进空间。提出的自动化评估框架显著提高了评估效率，性能接近人工评判。
## 102. `cs.AI` - 生成合成临床文本：一项系统综述 [PDF](https://arxiv.org/pdf/2507.18451), [HTML](https://arxiv.org/abs/2507.18451)
### Authors
Basel Alshaikhdeeb,Ahmed Abdelmonem Hemedan,Soumyabrata Ghosh,Irina Balaur,Venkata Satagopam
### Background
生成临床合成文本是解决临床自然语言处理问题如数据稀疏性和隐私保护的有效方法。这篇论文旨在通过量化分析三个研究问题，即（i）生成的目的，（ii）技术，和（iii）评估方法来系统性地审查生成合成医学自由文本的问题。研究者整理了2018年之后大部分关于生成合成医学免费文本的关注，这些文本主要用于文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。生成的合成医学文本在不同的下游自然语言处理任务中显示出作为真实医学文档的中等可能性，但作为真实文档的有效补充，它有助于提高准确性并克服数据稀疏和样本不足的问题。然而，隐私仍然是生成合成医学文本的主要问题，需要更多的人类评估来检查是否存在敏感信息。尽管如此，合成医学文本生成的进步将显著加速工作流程和管道的发展，从而避免数据传输的繁琐法律程序。
### Innovation
该研究通过系统性审查生成合成医学文本的研究，归纳了生成的目的、所采用的技术和评价方法。研究指出，转换器架构（尤其是GPTs）是生成文本的主要技术，评估方面包括相似性、隐私性、结构和实用性，其中实用性是常用的评估方法。这项研究强调了生成合成医学文本在教育、医疗研究、隐私保护和与其他自然语言处理任务中的重要潜力，同时也指出了隐私权方面存在的挑战。
### Conclusion
生成的合成医学文本在不同下游自然语言处理任务中具有作为真实医学文档的中等可能性，作为真实文档的有效补充，有助于提高准确性和克服数据稀疏问题。然而，隐私担忧仍然存在，需要更多的手动检查以确保没有敏感信息泄露。尽管如此，生成合成医学文本的技术进步将加速工作流程和管道的发展，减少数据传输的法律障碍。
## 103. `cs.AI` - Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments [PDF](https://arxiv.org/pdf/2507.18484), [HTML](https://arxiv.org/abs/2507.18484)
### Authors
Xiao Yang,Lingxuan Wu,Lizhong Wang,Chengyang Ying,Hang Su,Jun Zhu
### Background
3D环境中的对抗性攻击已经成为确保视觉感知系统可靠性的重要威胁，特别是在身份验证和自动驾驶等敏感应用场景中尤为突出。这些攻击通过利用复杂场景中的漏洞，使用对抗性补丁和3D物体来操控深度神经网络的预测。现有的防御机制，如对抗训练和净化，主要依赖于被动策略，并且通常基于预定义的对抗策略假设，缺乏动态3D环境中的适应性。
### Innovation
我们提出了Reinforcement Embodied Active Defense (Rein-EAD)框架，这是一种主动防御机制，通过适应性探索和环境互动来提升3D对抗性环境中的感知鲁棒性。Rein-EAD实现了多步目标，以平衡即时预测准确性和熵最小化，进行多步投资优化防御策略。此外，引入了以不确定性为导向的奖励塑形机制，促进高效的策略更新，减少了计算开销，并支持在非可微环境中实现现实应用。
### Conclusion
全面的实验验证了Rein-EAD的有效性，显示了显著降低攻击成功率的同时保持标准准确率。Rein-EAD在面对未见攻击和适应性攻击时表现出鲁棒的泛化能力，使其适用于复杂的现实世界任务，包括3D对象分类、人脸识别和自动驾驶。
## 104. `cs.AI` - 解释视觉、文本和多模态编码器如何共享概念 [PDF](https://arxiv.org/pdf/2507.18512), [HTML](https://arxiv.org/abs/2507.18512)
### Authors
Clément Cornet,Romaric Besançon,Hervé Le Borgne
### Background
稀疏自编码器（SAEs）已成为从神经网络激活中提取人类可解释特征的强大技术。先前的研究比较了不同模型基于SAE衍生特征的效果，但这些比较局限于同一模态内的模型。本文提出了一种新型指标，用于定量比较不同SAE特征的模型，从而进行跨模态的比较研究，包括视觉、文本和多模态编码器。文中还提出了一种量化不同模型类别之间单个特征比共享性的方法。通过这两种新工具，研究人员对不同类型、两种显著不同规模的21个编码器进行了多方面研究，涉及通用和特定领域的数据集。研究结果使人们对此前的研究在多模态环境下训练的编码器进行了重新审视，并量化了这些模型在多大程度上共享一些表示或特征。研究还表明，特定于视觉语言模型（VLM）的视觉特征与文本编码器共享，突显了文本预训练的影响。
### Innovation
提出了新的指标，允许定量比较不同SAE特征的模型，进行跨模态的比较研究；量化不同模型类别之间单个特征的共享性；通过对多模态环境下训练的编码器进行研究，重新审视了此前的研究结果。
### Conclusion
视觉语言模型的特定视觉特征与文本编码器共享，这强调了文本预训练对视觉模态的影响。研究结果允许更好地理解不同模态编码器如何共享概念，并揭示了一些重要的观察结果，为未来的研究提供了新的视角。
## 105. `cs.AI` - GLiNER2：一种高效多任务信息提取系统，具有基于模式的接口 [PDF](https://arxiv.org/pdf/2507.18546), [HTML](https://arxiv.org/abs/2507.18546)
### Authors
Urchade Zaratiana,Gil Pasternak,Oliver Boyd,George Hurn-Maloney,Ash Lewis
### Background
信息提取（IE）是许多NLP应用的基础，但现有解决方案通常需要为不同的任务使用专门的模型，或者依赖于计算成本高的大型语言模型。GLiNER2是一个统一框架，该框架增强了原始的GLiNER架构，支持命名实体识别、文本分类和层次结构化数据提取，所有这些都包含在一个高效的模型中。
### Innovation
GLiNER2通过构建基于预先训练的变换器编码器架构，保持CPU效率和紧凑的尺寸，同时通过直观的基于模式的接口引入多任务组成。其性能在提取和分类任务上具有竞争力，并在部署可访问性上比基于LLM的替代品有了显著改进。
### Conclusion
我们发布了GLiNER2作为开源pip安装库，带有预训练模型和文档，可在以下网址访问：this https URL。
## 106. `cs.AI` - C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation [PDF](https://arxiv.org/pdf/2507.18533), [HTML](https://arxiv.org/abs/2507.18533)
### Authors
Magnus Bengtsson,Kenneth Östberg
### Background
在无数据知识蒸馏（Data-Free Knowledge Distillation, DFKD）方法中，教师模型的知识如何被传递给生成器，以生成有价值的合成样本，而无需实际训练数据是一个关键问题。现有的DFKD方法通常依赖于合成样本与真实样本之间的结构相似性，而忽略了类别的特定结构和空间分布的重要性。PCA（主成分分析）可以用于从少量真实样本中估计类别的PCA子空间，有助于保持合成样本的拓扑一致性与多样性。
### Innovation
本文提出了一种名为C2G-KD的数据免费知识蒸馏框架，其中使用类条件生成器（Class-conditional generator）在未观察真实训练数据的情况下生成样本。生成器由冻结的教师模型指导并受PCA约束，通过语义和结构损失的联合机制学习激活教师模型的输出。这种方法通过使用PCA估计的类特定子空间约束生成样本，确保生成样本保留了类别的拓扑一致性与多样性，即使在最小类结构下也能生成有效的合成训练管道。
### Conclusion
实验结果表明，即使在很少的真实示例情况下，C2G-KD也能生成有用的合成训练样本，验证了提出的框架的有效性，特别是在MNIST数据集上，即使最小的类结构也足以启动有用的合成训练管道。
## 107. `cs.AI` - HARLF: 嵌套强化学习和轻量级LLM驱动情感整合在金融组合优化中的应用 [PDF](https://arxiv.org/pdf/2507.18560), [HTML](https://arxiv.org/abs/2507.18560)
### Authors
Benjamin Coriat,Eric Benhamou
### Background
本文介绍了一种新的嵌套框架，用于投资组合优化，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）结合，将来自金融新闻的情感信号与传统市场指标结合。该三层架构使用基础RL代理处理混合数据，元代理汇总决策，并使用超代理根据市场数据和情感分析融合决策。框架在2018年至2024年的数据上进行测试，2000年至2017年的数据用于训练，实现了26%的年化回报和1.2的夏普比率，优于等权重和标普500指数基准。背景包括对传统和新兴技术如情感分析和RL在投资组合优化中的应用的研究，以及这些方法可能面临的挑战和限制，如数据稀缺性和模型适应性等问题。
### Innovation
主要创新包括可扩展的跨模态集成、增强了稳定性的嵌套RL架构和开源可复现性。嵌套的RL架构使系统能够更好地处理复杂的数据输入，而跨模态集成则允许将不同类型的数据（如新闻和市场数据）有效地结合起来。开源可复现性增强了研究的透明度和可验证性，有助于科学进展。
### Conclusion
经过一段时间的数据训练，本文提出的框架展示了在投资组合优化中的优越性能，特别是在利用情感信号的同时保持模型的稳定性和可扩展性。该框架具有实际应用潜力。
## 108. `cs.AI` - 第19届ACL2定理证明器及其应用国际研讨会论文集 [PDF](https://arxiv.org/pdf/2507.18567), [HTML](https://arxiv.org/abs/2507.18567)
### Authors
Ruben Gamboa,Panagiotis Manolios
### Background
ACL2是应用于工业领域的自动推理系统，隶属于Boyer-Moore家族的定理证明系统。ACL2 Workshop系列研讨会是ACL2定理证明系统的用户们展示与ACL2定理证明器及其应用相关的研究成果的主要技术论坛。Boyer, Kaufmann, and Moore因为在ACL2及其Boyer-Moore家族的其他定理证明器上的工作，获得了2005年的ACM软件系统奖。
### Innovation
论文集聚焦于展示与ACL2定理证明器及其应用相关的最新研究成果，涵盖该领域的技术进展和实际应用。
### Conclusion
ACL2 Workshop是关于ACL2及其应用的高级论坛，汇集了该领域的最新研究和应用进展。
## 109. `cs.AI` - Sandwich: 分开编译预填充-解码以实现高效CPU大规模语言模型处理 [PDF](https://arxiv.org/pdf/2507.18454), [HTML](https://arxiv.org/abs/2507.18454)
### Authors
Juntao Zhao,Jiuru Li,Chuan Wu
### Background
现有的CPU基础的解决方案在大规模语言模型（LLM）推理的预填充和解码阶段考虑了工作负载差异，采用固定的非统一内存访问（NUMA）节点模型分区，并使用供应商库进行操作级执行，这被认为是次优的。CPU用于提供LLM的好处在于资源利用更友好，相比之下，图形处理器（GPU）虽然强大，但成本更高。因此，对于LLM服务，CPU提供了一个更加经济的选择。
### Innovation
提出了Sandwich，这是一种硬件为中心的CPU基础LLM服务引擎，针对预填充和解码阶段分别使用不同的执行计划，并独立优化它们。Sandwich通过生成优于代表性的供应商内核和其他动态形状解决方案的GEMM内核，展示了显著的性能提升，并实现了与静态编译器相当的性能，但其内核调优成本却低三个数量级。
### Conclusion
Sandwich在五个CPU平台上，包括具有AVX-2和AVX-512的x86平台以及具有NEON的ARM平台，实现了平均2.01倍的吞吐量改善和90%的满意时间到首个令牌(TTFT)和每个输出令牌的时间(TPOT)延迟。在单一序列服务中，其需求降低了高达3.40倍，连续批量服务中吞吐量显著提升。
## 110. `cs.AI` - 使用符号推理的大语言模型进行自动代码审查 [PDF](https://arxiv.org/pdf/2507.18476), [HTML](https://arxiv.org/abs/2507.18476)
### Authors
Busra Icoz,Goksel Biricik
### Background
代码审查是软件开发生命周期中的关键过程，对于维护代码质量至关重要。但是，手工代码审查主观性强且耗时。鉴于代码审查的规则性，该过程非常适合自动化处理。近年来，人工智能的辅助促进了这一过程的自动化。虽然大语言模型（LLMs）在这一领域取得了显著进展，但这些模型往往缺乏逻辑推理能力，不足以全面理解并评估代码。
### Innovation
本研究提出了一种混合方法，将符号推理技术与大语言模型相结合，以实现代码审查的自动化。我们使用CodexGlue数据集测试了该方法，并将CodeT5、CodeBERT和GraphCodeBERT等多个模型与符号推理和提示技术相结合，以评估其效果。研究表明，这种方法能提高自动代码审查的准确性和效率。
### Conclusion
本研究采用了一种将符号推理与大语言模型相结合的创新方法，显著提高了自动代码审查的准确性和效率，为未来相关研究提供了参考。
## 111. `cs.AI` - 超越内部数据：为公平性测试构建完整数据集 [PDF](https://arxiv.org/pdf/2507.18561), [HTML](https://arxiv.org/abs/2507.18561)
### Authors
Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber
### Background
随着AI在高风险领域和决策中的普及，测试潜在危害和偏见变得至关重要。全球范围内，AI监管开始强调公平性并要求充分测试，一些规定甚至要求进行独立的偏见审计。然而，获取公平性测试所需的完整数据仍是一个重大挑战。特别是在工业环境中，法律和隐私问题限制了收集用于评估群体差异的群体统计数据，而审计人员在获取数据方面也面临着实际和文化上的挑战。此外，内部历史数据集往往不够代表真实世界中的偏见。因此，本研究聚焦在没有完整包含人口统计数据的组合作业场景下评估分类器的公平性。本研究提出了利用分离且重叠的数据集构建完整且包含人口统计数据的合成数据的方法，这些数据准确反映了受保护属性与模型特征之间的底层关系。研究通过比较合成数据和真实数据的准确性来验证合成数据的真实性，并通过实际测试数据以证明基于合成数据得出的公平性度量指标与使用真实数据得到的结果一致。这种研究为克服公平性测试中的真实数据稀缺性提供了途径，使得独立且无模型偏见地评估公平性成为可能，并且在真实数据有限的情况下提供了替代方案。
### Innovation
本研究创新性地提出了一种利用分离且重叠的数据集构建完整且包含人口统计数据的合成数据的方法。通过对这种合成数据与真实数据进行比较验证其真实性，并通过实证研究证明基于合成数据得出的公平性度量指标与使用真实数据得到的结果一致。这种方法为处理真实数据稀缺性，提供了一种独立且无模型偏见的公平性评估方法，对于解决隐私限制和数据不足的问题提供了新思路。
### Conclusion
本研究为如何在没有完整的人口统计数据的情况下进行公平性测试提供了新的解决方案，利用合成数据的方法可以保证公平性测试的准确性。这种方法可以独立且无模型偏见地评估公平性，而且在真实数据有限的情况下提供了一种可行的替代方案。
## 112. `cs.AI` - PosterMate：基于受众的协作 Persona 代理人用于海报设计 [PDF](https://arxiv.org/pdf/2507.18572), [HTML](https://arxiv.org/abs/2507.18572)
### Authors
Donghoon Shin,Daniel Lee,Gary Hsieh,Gromit Yeuk-Yin Chan
### Background
海报设计可以从目标受众的同步反馈中受益，但召集具有不同视角的受众并就设计编辑达成共识具有挑战性。最近的生成 AI 模型提供了一种模拟人类互动的机会，但目前尚不清楚这些模型如何用于设计中的反馈过程。
### Innovation
引入了 PosterMate，这是一种通过从营销文档构建受众驱动的角色代理来促进协作的海报设计助手。PosterMate 从每个角色代理那里收集有关海报组件的反馈，并借助调解员促进讨论以达成一致。这些达成共识的编辑可以直接整合到海报设计中。研究发现，PosterMate 可以捕捉未被忽视的观点，同时作为有效的原型工具。在线评估表明，每个角色代理提供的反馈与其角色身份相符，讨论有效地综合了不同角色代理的观点。
### Conclusion
PosterMate 在汇集不同视角的反馈方面展示了潜力，不仅可以帮助设计师更好地理解目标受众的需求，还能通过整合多样化的意见来改进设计。
## 113. `cs.AI` - GIIFT: 图引导的归纳无图的多模态机器翻译 [PDF](https://arxiv.org/pdf/2507.18562), [HTML](https://arxiv.org/abs/2507.18562)
### Authors
Jiafeng Xiong,Yuting Zhao
### Background
多模态机器翻译（MMT）已经展示了视觉信息对机器翻译的显著帮助。然而，现有的MMT方法难以利用模态差异，它们通过强制视觉-语言对齐进行训练，限制了在不同模态领域内的推断。
### Innovation
本文构建了新型多模态场景图以保留和整合特定模态信息，提出了GIIFT，一种两阶段图引导归纳无图片的多模态机器翻译框架，使用跨模态图注意力网络适配器在统一融合空间中学习多模态知识，并归纳式地推广到更广泛的无图翻译领域。
### Conclusion
实验结果表明我们的GIIFT方法超越了现有的方法，并在Multi30K数据集的英语到法语和英语到德语任务上达到最新技术水平，即使推理阶段不使用图片。与无图翻译基线相比，在WMT基准测试上也出现了显著改进，这证明了GIIFT在无图的归纳推断中的强大优势。
## 114. `cs.AI` - 推进金融工程中的基础模型：进展、应用与挑战 [PDF](https://arxiv.org/pdf/2507.18577), [HTML](https://arxiv.org/abs/2507.18577)
### Authors
Liyuan Chen,Shuoling Liu,Jiangpeng Yan,Xiaoyu Wang,Henglin Liu,Chuang Li,Kecheng Jiao,Jixuan Ying,Yang Veronica Liu,Qiang Yang,Xiu Li
### Background
基础模型（FMs）的出现，尤其是像GPT-4和Gemini这样的大规模预训练模型，展现了在金融报告总结、情感预测等任务中的潜在优势。然而，许多金融应用场景因特定领域的独特需求（如多模态推理、监管合规和数据隐私）而受到限制。这些问题促使了金融基础模型（FFMs）的发展。FFMs是专为金融设计的新型模型类别。
### Innovation
本文提供了一个关于FFMs的全面概述，涵盖三大模态分类：金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）。详细介绍其架构、训练方法、数据集以及实际应用。识别了数据可用性、算法可扩展性和基础设施限制的关键挑战，并为未来研究提供见解。
### Conclusion
本文旨在成为理解和金融基础模型的全面参考，并为未来创新提供实践指南。此外，相关出版物和资源将以更新的形式在网站上维护。
## 115. `cs.AI` - 一个具有自适应每用户速率-功率权衡的大型MIMO预编码基础模型 [PDF](https://arxiv.org/pdf/2507.18587), [HTML](https://arxiv.org/abs/2507.18587)
### Authors
Jérôme Emery,Ali Hasanzadeh Karkan,Jean-François Frigon,François Leduc-Primeau
### Background
深度学习（DL）由于其在大规模多输入多输出（mMIMO）系统中学习传播环境特征的能力，已成为预编码解决方案的一种选择。然而，训练这种模型需要在部署现场收集高质量的局部数据集，这往往是困难的。
### Innovation
提出了一种基于变压器的基础模型，旨在在保持低发射机能耗的同时动态适应每个用户的数据速率要求。通过数据增强方法，在数据稀缺的情况下，这种基础模型在零样本部署时表现出色，与零强迫方法相比显著提高了性能，同时将复杂度降低了8倍。
### Conclusion
该研究通过解决数据可用性和训练复杂性问题，使基于深度学习的解决方案能够实际应用。此外，根据每个用户的自适应速率-功率权衡配置能力，还可以为更高层次的资源分配和调度算法提供支持，以提高能效、频谱效率和公平性。
## 116. `cs.AI` - DR.EHR: 基于知识注入和合成数据的电子健康记录密集检索 [PDF](https://arxiv.org/pdf/2507.18583), [HTML](https://arxiv.org/abs/2507.18583)
### Authors
Zhengyun Zhao,Huaiyuan Ying,Yue Zhong,Sheng Yu
### Background
电子健康记录（EHRs）在临床实践中至关重要，但其检索仍然面临挑战，主要原因是语义差距问题。近年来，密集检索技术提供了有希望的解决方案，但现有的通用领域和生物医学领域的模型由于缺乏医学知识或训练语料库不匹配而表现不佳。
### Innovation
本文提出了DR.EHR，一种专门针对EHR检索的密集检索模型。我们提出了一种两阶段的训练管道，利用MIMIC-IV出院摘要来解决对大量医学知识和大规模训练数据的需求。第一阶段包括从生物医学知识图中提取医学实体和注入知识，第二阶段使用大规模语言模型生成多样化的训练数据。我们分别训练了参数量为110M和7B的两种DR.EHR模型。在CliniQ基准测试中，我们的模型显著优于所有现有密集检索器，取得了最先进的成果。详细的分析证实了我们的模型在各种匹配和查询类型中具有优越性，特别是在隐含和缩写的复杂语义匹配中表现出色。废除研究验证了每一步训练管道的效用，而补充实验展示了模型在自然语言问题上的通用性，包括具有多个实体的复杂问题。
### Conclusion
本工作显著推进了EHR检索，为临床应用提供了稳健的解决方案。
## 117. `cs.AI` - AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs [PDF](https://arxiv.org/pdf/2507.18584), [HTML](https://arxiv.org/abs/2507.18584)
### Authors
Xiaopeng Ke,Hexuan Deng,Xuebo Liu,Jun Rao,Zhenxi Song,Jun Yu,Min Zhang
### Background
尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域经常表现不佳。现有方法通常依赖数据合成方法，并通过使用未标记数据来捕捉领域的特定特征，取得了令人鼓舞的效果。然而，这些方法要么计算成本高，要么在性能上存在局限性，也难以跨任务进行泛化。为解决这些挑战，本文提出了AQuilt框架，用于从相应的未标记数据中为任何专业领域构建指令调优数据，并包含了答案、问题、未标记数据、检查、逻辑和任务类型。通过整合逻辑和检查，激励了推理过程和自省，以增强模型性能。此外，自定义的任务指令能够为任何任务生成高质量的数据。基于这些方法，构建了一个包含703,000个例子的数据集来训练强大的数据合成模型。实验结果表明，AQuilt在性能上与DeepSeek-V3相当，仅使用了17%的生产成本。进一步分析表明，生成的数据与下游任务的相关性更高。
### Innovation
本文提出了AQuilt框架，用于解决大型语言模型在专业领域表现不佳的问题。AQuilt框架从未标记数据中构建指令调优数据，通过整合逻辑和检查，激励了推理过程和自省，从而增强了模型性能。同时，AQuilt支持自定义任务指令，能够为任何任务生成高质量数据，并构建了一个包含703,000个例子的数据集来训练强大的数据合成模型。AQuilt在性能上与DeepSeek-V3相当，但仅使用了17%的生产成本，生成的数据与下游任务的相关性更高。 
### Conclusion
我们构建了AQuilt框架，通过结合逻辑和自我检查的方法，从未标记数据中高效地生成高质量的指令调优数据。该框架不仅降低了成本，还增强了模型在专业领域的性能，并且生成的数据与下游任务具有更高的相关性。
## 118. `cs.AI` - SynC: 使用一对一映射优化合成图像字幕数据集以提升零样本图像字幕 [PDF](https://arxiv.org/pdf/2507.18616), [HTML](https://arxiv.org/abs/2507.18616)
### Authors
Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim
### Background
零样本图像字幕（ZIC）越来越倾向于利用由文本到图像（T2I）模型生成的合成数据集，以减少对昂贵的手动标注的需求。然而，这些T2I模型生成的图像往往与输入的字幕在语义上存在对齐问题（如缺少对象、属性错误），导致噪声较大的合成图像-字幕对，这可能妨碍模型训练。现有的一些数据集精简技术主要是为了去除网络爬取的数据中的噪声文本，但这些方法对于合成数据的特定挑战并不适用，因为合成数据中的字幕通常是正确的，但图像可能是不准确的。
### Innovation
为了应对这一问题，本文提出了SynC，这是一种新的框架，专门用于细化用于ZIC的合成图像-字幕数据集。SynC专注于重新分配每个字幕与最语义对齐的图像，而不是传统的过滤或重新生成。具体而言，其采用了一种一对一到多对映射策略，首先为每个字幕检索多个相关候选图像，然后通过图像到文本检索的方法应用了一个基于循环一致性启发的对齐评分器来选择最佳图像。
### Conclusion
大量评估表明，SynC方法能够稳定且显著地提升各种ZIC模型在标准基准数据集（如MS-COCO、Flickr30k、NoCaps）上的性能，在某些场景中达到了最先进的结果。SynC提供了一种有效的策略，用于筛选更为精细的合成数据以增强ZIC的效果。
## 119. `cs.AI` - SIDA: Synthetic Image Driven Zero-shot Domain Adaptation [PDF](https://arxiv.org/pdf/2507.18632), [HTML](https://arxiv.org/abs/2507.18632)
### Authors
Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim
### Background
零样本领域适应是一种在无需使用目标领域图像数据的情况下将模型适应到目标领域的方法。现有的研究利用CLIP的嵌入空间和文本描述来模拟目标领域的样式特征。尽管在零样本领域适应方面取得了之前的研究成果，但这些文本驱动的方法在捕捉真实世界的复杂变化方面存在困难，并且由于其对齐过程而显著增加了适应时间。
### Innovation
研究提出了SIDA（合成图像驱动的零样本领域适应方法），这是一种利用合成图像的新颖且有效的零样本领域适应方法。SIDA通过生成与目标领域样式相匹配的详细源图像，并使用图像转换来反映目标领域的样式，进而利用这些合成图像的样式特征作为目标领域的代理。在此基础上，引入了域混合和局部样式转换模块，能够有效地建模真实世界的变异性。特别是，域混合通过融合多种样式扩展了域内的表示，而局部样式转换则为单个块指定了不同的样式.
### Conclusion
通过多种零样本适应场景下的实验，展示了该方法的有效性，特别是在挑战性领域中。与以往的方法相比，该方法通过显著减少总体适应时间实现了高效性。
## 120. `cs.AI` - 受具有表达约束能力的中间表示引导的3D软件合成 [PDF](https://arxiv.org/pdf/2507.18625), [HTML](https://arxiv.org/abs/2507.18625)
### Authors
Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu
### Background
图形用户界面软件已从传统的二维(2D)桌面/网络/移动界面向三维(3D)环境进行根本性转变。虽然现有的工作在自动2D软件生成方面取得了显著进展，例如HTML/CSS和移动应用界面代码合成，但3D软件的生成仍然没有得到充分探索。当前方法通常生成整个3D环境，无法修改或控制软件中的特定元素，并且难以处理真实世界中复杂的空间和语义约束。
### Innovation
我们提出了Scenethesis，这是一种新型的要求敏感的3D软件合成方法，它在用户规定和生成的3D软件之间保持了形式上的可追溯性。Scenethesis基于ScenethesisLang，这是用于连接自然语言要求和可执行3D软件的领域特定语言，作为细粒度的感知约束中间表示。它是全面的场景描述语言，允许对3D软件元素进行细粒度修改，同时也是能够表达复杂空间约束的形式约束表达规范语言。通过将3D软件合成分解为基于ScenethesisLang操作的阶段，Scenethesis实现了独立验证、定向修改和系统的约束满足。
### Conclusion
我们的评估表明，Scenethesis能够准确捕获超过80%的用户需求，并满足超过90%的严格约束，在同时处理超过100个约束时也是如此。此外，Scenethesis在BLIP-2视觉评估得分上比最先进的方法提高了42.8%。
## 121. `cs.AI` - I-CEE: 根据用户专业知识定制图像分类模型的解释 [PDF](https://arxiv.org/pdf/2312.12102), [HTML](https://arxiv.org/abs/2312.12102)
### Authors
Yao Rong,Peizhu Qian,Vaibhav Unhelkar,Enkelejda Kasneci
### Background
负责任地部署依赖黑盒机器学习模型的AI系统的关键在于有效地解释其决策。尽管解释性AI（XAI）领域提出了一些建议技术来生成这些解释，但在该领域的工作中相对较少关注用户，大多数XAI技术提供的解释通常是“一刀切”的。
### Innovation
作者提出了I-CEE框架，该框架通过提供与用户专业知识相匹配的训练数据子集（即示例图像）、局部解释和模型决策，为图像分类模型提供定制的解释。I-CEE的特点在于它是根据用户的专业知识来定制示例图像的信息性，因此不同的用户可能会得到不同的示例。作者认为，通过定制示例集，I-CEE可以更好地帮助用户理解和模拟模型。
### Conclusion
通过在模拟用户和人类参与者中进行详细实验，作者发现I-CEE显著提高了用户的模型决策预测准确性，证实了用户中心的XAI的重要性。
## 122. `cs.AI` - VideoMind：带有意图定位的全方位视频数据集，用于深度认知视频理解 [PDF](https://arxiv.org/pdf/2507.18552), [HTML](https://arxiv.org/abs/2507.18552)
### Authors
Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin
### Background
当前视频数据集多关注于多模态特征表示，但缺乏对深层认知表达的系统性描述，尤其是意图表达。现有的数据集无法直接提供这些深层认知表达，因为它们需要综合整个视频的上下文信息，而这些信息无法直接观察到。因此，迫切需要开发一种能够支持深层认知和意图表达的全方位视频数据集。
### Innovation
VideoMind是一个专为深度视频内容理解和增强多模态特征表示设计的视频为中心的全方位多模态数据集。它提供了意图表达，这些表达基于整个视频的上下文信息生成，而不是直接观察得到。这些表达通过Chain-of-Thought（COT）方法生成，推动mLLM逐步推理生成。此外，还建立了包含3000个手动验证样本的基准测试，用于评估模型的深层认知视频理解能力，并通过多级检索指标设计混合认知检索实验。这些创新极大地促进了对细致入微的跨模态对齐和需要深入视频理解的领域的研究，如情绪识别和意图识别。
### Conclusion
VideoMind作为一个强大的基准，用于精细的跨模态对齐，促进了需要深入视频理解的领域的进展，如情绪和意图识别。该数据集已公开发布，可通过GitHub、HuggingFace和OpenDataLab访问。
## 124. `cs.AI` - 超越离散域的近似SMT计数 [PDF](https://arxiv.org/pdf/2507.18612), [HTML](https://arxiv.org/abs/2507.18612)
### Authors
Arijit Shaw,Kuldeep S. Meel
### Background
Satisfiability Modulo Theory (SMT) 解析器已经提升了自动化推理，解决跨离散和连续域的复杂公式。基于命题模型计数的进步推动了将SMT能力扩展到模型计数，特别是对混合SMT公式的计数。现有的方法，如位爆破，仅限于离散变量，揭示了在混合公式中进行投影到离散域的解决方案计数的挑战。
### Innovation
引入了pact，这是一种用于混合公式SMT模型计数的方法，使用基于哈希的近似模型计数来估计解决方案，并提供了理论上的保证。pact相比基准方法在大规模基准测试中表现出显著的性能提升。
### Conclusion
在14,202个实例中，pact成功地完成了603个实例的计数，而基准方法只能完成13个实例。
## 125. `cs.AI` - Moving Out: 与物理属性紧密联系的人-AI协作 [PDF](https://arxiv.org/pdf/2507.18623), [HTML](https://arxiv.org/abs/2507.18623)
### Authors
Xuhui Kang,Sung-Wook Lee,Haolin Liu,Yuyan Wang,Yen-Ling Kuo
### Background
实体代理（例如机器人）在与人类有效协作时，需要适应环境中的物理动作和限制。这种与物理属性紧密联系的协作需要考虑物理约束引起的连续状态-动作空间和受限动力学的增加复杂性。
### Innovation
本文提出了一种新的基准‘Moving Out’，它涵盖了受物理属性和约束影响的一系列协作模式，如共同搬运重物和保持一致动作以绕过角落移动大物品。为了应对物理环境中的挑战，本文提出了一种名为BASS的方法（行为增强、模拟和选择），以增强代理的多样性和对其行为结果的理解能力。实验证明BASS在人-人协作和人-AI协作方面优于最先进的模型。
### Conclusion
使用Moving Out基准，设计了两个任务并收集了人-人交互数据来评估模型适应各种人类行为和未见的物理属性的能力。BASS在AI-AI和人-AI协作领域超越了现有最先进的模型。项目页面可通过[这个链接](this https URL_ai/)访问。
## 126. `cs.AI` - DRWKV：聚焦于物体边缘的低光照图像增强 [PDF](https://arxiv.org/pdf/2507.18594), [HTML](https://arxiv.org/abs/2507.18594)
### Authors
Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung
### Background
低光照图像增强是一个具有挑战性的任务，特别是在极端光照降噪情况下保持物体边缘连续性和细微结构细节方面。现有方法在处理此类图像时常常无法很好地分离光照和边缘结构，导致边缘质量和视觉自然度下降。
### Innovation
本文提出了一种名为DRWKV（Detailed Receptance Weighted Key Value）的新模型，该模型结合了提出的全局边缘瑞利色散理论（GER），有效地解耦了光照和边缘结构，提高了边缘保真度。此外，引入了螺旋扫描机制的演化WKV注意力，更有效地捕捉空间边缘连续性和建模不规则结构。通过双边光谱对齐器（Bi-SAB）和定制的MS2损失函数，共同对亮度和色度特征进行对齐，提升了视觉自然度并减少了伪影。实验结果表明，DRWKV在五项LLIE基准测试中以较低的计算复杂度实现了领先的性能。
### Conclusion
DRWKV 在 PSNR、SSIM 和 NIQE 等指标上表现出色，同时保持较低的计算复杂度。此外，DRWKV 还验证了其在低光照多目标跟踪任务中的下游性能，进一步证明了其泛化能力。
## 127. `cs.AI` - 使用不一致知识库检索因果顺序类 [PDF](https://arxiv.org/pdf/2412.14019), [HTML](https://arxiv.org/abs/2412.14019)
### Authors
Federico Baldo,Simon Ferreira,Charles K. Assaad
### Background
传统的因果发现方法往往基于难以验证的假设，这使它们在实际应用中不可靠。在这一背景下，大型语言模型（LLMs）作为一种从基于文本的元数据中提取因果知识的有希望的替代方法出现了，它们汇集了领域专业知识。但是，LLMs往往不可靠且容易产生幻觉，需要策略来应对它们的局限性。一致度度量是一种有效的策略来评估可靠性。此外，大多数文本元数据并未明确区分直接因果关系和间接因果关系，进一步复杂化了因果DAG的发现过程。因此，关注因果顺序而非因果DAG成为更加可行和可靠的方法。
### Innovation
本文提出了一种新方法，通过评估从LLM中获得的一致性分数来推导因果顺序的类，该方法旨在最大化一致性的类别的析取宾zos。这种方法首先计算变量之间的成对一致性分数，从而生成一个半完全部分有向图，该图整合了这些分数并提供了一致性最大因果顺序的抽象。该方法通过识别能够最大化一致性顺序的所有配置来确定最优的析取宾zos。之后，介绍了如何使用这种抽象和因果顺序的类来估计因果效应。这种方法在公认的基准数据集和公共卫生领域的实际数据集上进行了测试，以证明其有效性。
### Conclusion
本文结果表明，该方法在恢复正确的因果顺序方面是有效的。
## 128. `cs.AI` - HPS: Hard Preference Sampling for Human Preference Alignment [PDF](https://arxiv.org/pdf/2502.14400), [HTML](https://arxiv.org/abs/2502.14400)
### Authors
Xiandong Zou,Wanyu Lin,Yuchen Li,Pan Zhou
### Background
构建安全可控的人工智能系统时，使大型语言模型（LLM）响应与人类偏好一致至关重要。尽管基于Plackett-Luce (PL) 和 Bradley-Terry (BT) 模型的偏好优化方法显示出前景，但它们仍然面临处理有害内容不佳、低效使用不喜欢的响应以及PL模型的高计算成本等挑战。
### Innovation
我们提出了一种名为Hard Preference Sampling (HPS) 的新颖框架，以实现鲁棒且高效的人类偏好对齐。HPS通过引入一种训练损失来优先选择最偏好响应，排斥所有不喜欢及有害的响应。它强调“硬”不喜欢响应（即与偏好响应高度相似的响应），以提升模型的排斥能力。通过采用单一采样蒙特卡洛采样策略，HPS在降低计算开销的同时保持对齐质量。理论上，HPS在样本效率上优于现有的PL方法，并最大化了偏好和不喜欢响应之间的奖励差距，确保更清晰的区分。
### Conclusion
在HH-RLHF和PKU-Safety数据集上的实验验证了HPS的有效性，它在获得相近的BLEU和奖励分数的同时，极大地提高了奖励差距，从而减少了有害内容的生成。
## 129. `cs.AI` - 从假设到发表：AI驱动的研究支持系统综述 [PDF](https://arxiv.org/pdf/2503.01424), [HTML](https://arxiv.org/abs/2503.01424)
### Authors
Zekun Zhou,Xiaocheng Feng,Lei Huang,Xiachong Feng,Ziyun Song,Ruihan Chen,Liang Zhao,Weitao Ma,Yuxuan Gu,Baoxin Wang,Dayong Wu,Guoping Hu,Ting Liu,Bing Qin
### Background
科学研究是推动人类文明进步的重要过程，但需要研究人员投入大量的时间和精力。近年来，人工智能技术的快速发展促使科研人员探索AI如何加速并增强科研活动。为了监测这一领域的进展，本文进行了系统性的文献综述。
### Innovation
本文将相关研究分为三个主要类别：假设形成、假设验证和论文发表。每个类别具体包括知识综合与假设生成、科学主张验证、定理证明、实验验证以及论文撰写和同行评议等内容。同时，本文还识别并讨论了这些领域的现有挑战和潜在未来研究方向，以及支持AI集成到科研过程中的现有基准和工具。
### Conclusion
我们希望本文能为初学者提供一个入门介绍，并促进未来的研究。相关资源已公开发布于 this https URL 。
## 130. `cs.AI` - ICPGRL：基于语言指令的强化学习在程序化关卡生成中的应用 [PDF](https://arxiv.org/pdf/2503.12358), [HTML](https://arxiv.org/abs/2503.12358)
### Authors
In-Chang Baek,Sung-Hyun Kim,Seo-Young Lee,Dong-Hyeon Kim,Kyung-Joong Kim
### Background
近年来，自然语言在提升生成模型可控性方面的意义得到了重视。尽管研究人员已经在利用自然语言进行内容生成方面做出了大量努力，但对于使用文本指令进行程序化内容生成的深度强化学习（DRL）代理的研究仍属少数。本文探讨了一种基于指令的程序化内容生成方法IPCGR负责利用强化学习，引入了一个句子嵌入模型。该方法能够根据特定任务进行微调，有效地压缩游戏级别的条件，从而实现对游戏内容的精细控制和泛化能力。
### Innovation
本文创新性地提出了一种基于指令的程序化内容生成方法IPCGR负责，它通过强化学习机制结合句子嵌入模型，有效地将特定任务的嵌入表示进行微调，从而压缩游戏级别的条件。这种方法提升了生成内容的可控性和泛化能力，对于以前依赖于通用嵌入方法的情况尤为明显，IPCGR负责在与通用嵌入方法的对比中展示了显著的性能提升，具体地，IPCGR负责在未见指令上的控制能力提高了21.4%，泛化能力提高17.2%。此外，该方法还扩大了条件输入的模态范围，提供了更灵活和富有表现力的功能交互框架，这对于程序化内容生成的未来发展具有重要意义。
### Conclusion
通过引入IPCGRL方法，本文展示了如何利用基于指令的强化学习促进更精细和高效的程序化内容生成。结果显示，该方法在控制能力和泛化能力方面均优于现有方法，为程序化内容生成领域提供了新的视角和工具。
## 131. `cs.AI` - BEARCUBS：计算机交互的网页代理基准 [PDF](https://arxiv.org/pdf/2503.07919), [HTML](https://arxiv.org/abs/2503.07919)
### Authors
Yixiao Song,Katherine Thai,Chau Minh Pham,Yapei Chang,Mazin Nadaf,Mohit Iyyer
### Background
现代WEB代理拥有通过发送命令到虚拟键盘和鼠标与网页互动的能力。这类代理在协助执行复杂的任务方面具有巨大的潜力，但在实际评估其能力时面临着显著挑战。BEARCUBS是一个包含111个信息查询的基准测试，旨在评估网页代理在搜索、浏览和从网络中识别事实信息方面的能力。BEARCUBS的独特之处在于它要求访问真实网络内容而非合成或模拟页面，并且需要执行视频理解、三维导航等多种模态的互动，这些都是传统基于文本的方法无法替代的任务类型。每个问题都有一个简短明确的答案以及通过人工验证的浏览轨迹，用以透明地评估代理性能和策略。一项人类研究确认，BEARCUBS的问题是可解决但具有挑战性的（84.7%的人类准确率），揭示了领域知识缺陷和未注意到的详细信息常常成为失败的瓶颈。
### Innovation
BEARCUBS引入了一个'小但强大'的信息查询基准测试，旨在全面评估网页代理的能力。它要求访问真实网络内容而非合成或模拟页（捕捉到现实生活中的不确定性），以及执行多种类型的模态互动（如视频理解、三维导航），这些都不是单纯通过文本工作方法可以避开的。这些问题的答案简短、明确，并且经过人工验证的浏览路径，有利于透明地评价代理性能和策略。ChatGPT代理的表现显著优于其他能使用的计算机代理，显示了在涉及真实计算机操作的任务中（如网上游戏和3D环境导航）有显著的进步。
### Conclusion
尽管如此，要缩小与人类性能的差距，还需要在精细控制、复杂数据筛选和执行速度方面进行改进。BEARCUBS会定期进行更新，以替换无效或污染的问题，从而保持基准的最新性，以便未来的web代理研究继续将其作为参考。
## 132. `cs.AI` - 在大型语言模型中实现化学推理解锁策略感知合成规划和反应机制阐明 [PDF](https://arxiv.org/pdf/2503.08537), [HTML](https://arxiv.org/abs/2503.08537)
### Authors
Andres M Bran,Theo A Neukomm,Daniel P Armstrong,Zlatko Jončev,Philippe Schwaller
### Background
虽然自动化化学工具在特定任务上表现出色，但在捕捉专家级化学推理中的战略性思考方面仍然存在困难。本文展示了大型语言模型（LLMs）可以通过与传统搜索算法结合，作为强大的化学分析工具，从而提供一种新的计算机辅助合成方法，这种方法可以模仿人类专家的思维模式。这种方法与直接使用LLMs操纵化学结构不同，而是利用它们评估化学策略的能力，并指导搜索算法找到化学上有意义的解决方案。通过两个基本挑战：策略感知的逆合成规划和机制阐明，证明了这一范式。该研究显示，不使用语言模型的这一研究方法在多种化学任务中表现出强大的性能，且基于更先进的和更大的模型，在化学推理的复杂性方面表现出进一步的提升。这种方法建立了将LLMs的战略理解与传统化学工具的准确性相结合的新化学辅助范式，开辟了更直观和强大化学自动化系统的新可能性。
### Innovation
本文的创新在于展示了如何利用大型语言模型（LLMs）与传统搜索算法结合，实现一种新的计算机辅助合成方法，该方法能够模仿人类专家的思维模式。这种新方法通过让化学家通过自然语言指定期望的合成策略，如保护基策略到全局可行性评估等，并使用传统的或由LLM指引的蒙特卡洛树搜索法找到满足这些约束的路线。在机制阐明方面，LLM结合了化学原理和系统探索，指导寻找合理的反应机制。这种方法在多样化的化学任务上表现出强大的性能，且随着更先进的模型的使用，在化学推理的复杂性方面有了显著的提升。
### Conclusion
这项研究建立了一种全新的化学辅助范式，将大型语言模型的战略理解和传统化学工具的精确性相结合，为更直观和强大的化学自动化系统开辟了新的可能性。通过展示为两大基本挑战：策略感知的逆合成规划和机制阐明的方法，证明了在多种化学任务中的强大性能，并且展现了逐渐先进的模型在解决化学问题复杂性方面的提升。
## 133. `cs.AI` - 基于过渡系统的差异化奖励方法在多车辆协同决策中的强化学习算法 [PDF](https://arxiv.org/pdf/2502.00352), [HTML](https://arxiv.org/abs/2502.00352)
### Authors
Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang
### Background
近年来，强化学习（RL）在优化多车辆协同驾驶策略方面展现出巨大潜力，通过状态-行动-奖励反馈循环进行优化。然而，RL方法仍面临诸如样本效率低等挑战。
### Innovation
本文提出了一种基于过渡系统的差异化奖励方法，通过分析交通流特性将状态转移梯度信息融入奖励设计，旨在优化多车辆协同决策中的行动选择和策略学习。该方法在不同的自主驾驶车辆渗透率条件下，在MAPPO、MADQN和QMIX等RL算法中得到了验证，并表现出显著的训练收敛加速效果，在交通效率、安全性和行动合理性方面均优于单纯中心化奖励和其他方法。
### Conclusion
本文提出的方法具有较强的可扩展性和环境适应性，为复杂交通场景下的多智能体协同决策提供了一种新的方法。
## 134. `cs.AI` - SuperARC：基于递归压缩和算法概率原理的窄、通用和超级智能的无偏测试 [PDF](https://arxiv.org/pdf/2503.16743), [HTML](https://arxiv.org/abs/2503.16743)
### Authors
Alberto Hernández-Espinosa,Luan Ozelim,Felipe S. Abrahão,Hector Zenil
### Background
本文介绍了一个基于算法概率的开放性测试，旨在避免在评估人工智能（AGI）和超级智能（ASI）方面的前沿模型时出现基准污染。与其他依赖统计压缩方法（如GZIP或LZW）的测试不同，本文的测试不使用更接近香农熵而非柯尔莫哥洛夫复杂性的方法，而是挑战了与合成和模型创建相关的智能特性，特别是逆问题（从观察中生成新知识）。研究通过度量基于模型抽象和演绎（最优贝叶斯推理）的预测性计划为检验智能提供了一个稳健的框架，包括自然智能（人类和动物）、窄AI、AGI和ASI。研究表明，尽管LLM模型版本在记忆方面展现出脆性和增量性质，其进步很大程度上依赖于训练数据的规模。
### Innovation
本文提出了一种基于递归压缩和算法概率原理的无偏测试（SuperARC），能够避免基准污染，不同于依赖统计压缩方法的传统测试，这种测试可以挑战与合成和模型创建等实质性的智能特性，特别是逆问题场景。研究还提出，基于模型抽象和演绎的预测性计划可以提供一个检验智能的稳健框架，并证明了压缩与预测能力之间的直接等价关系。
### Conclusion
研究结果进一步强调了LLM模型在根本限制上的怀疑，揭露了它们作为受优化用于理解和掌握人类语言的系统的特性。
## 135. `cs.AI` - 神经多样性的可影响性作为AI对齐问题的一种依赖性解决方案 [PDF](https://arxiv.org/pdf/2505.02581), [HTML](https://arxiv.org/abs/2505.02581)
### Authors
Alberto Hernández-Espinosa,Felipe S. Abrahão,Olaf Witkowski,Hector Zenil
### Background
人工智能（AI）的发展，尤其是从弱人工智能（NAR）到人工智能和超级智能（AGI和ASI）的演进，带来了控制力和存在风险的担忧。AI对齐问题关注确保AI系统按照人类价值观行动，这提出了巨大的挑战。该论文探讨了一种替代策略，即通过促进AI的偏差来促进竞争性智能体生态系统的形成，作为一种引导上述系统走向更加人性化的路径和减缓风险的方式。该理论基于一个关键假设，即AI和人类的完全对齐在图灵完备系统中是不可能的。文章还提出了一个基于扰动和干预分析的改变意见攻击测试，以研究人类和智能体如何通过合作与竞争改变或中和友好或敌意的AI。
### Innovation
该研究提出了一种新的替代对齐策略，即通过促进AI的偏差，利用对分歧性智能体进行干预，引导系统走向更符合人类利益的方向。此外，该研究提出了一个基于扰动和干预分析的改变意见攻击测试，以评估人类和AI系统的干预效果，根据不同样态开发出应对策略。研究还指出，开放模型比封闭模型更加多样化，但封闭模型也更易于控制和可能用于对抗私有化AI系统。
### Conclusion
该论文认为，AI对齐问题无法完全避免，因此需要依赖性解决方案以减少风险并促进一体化智能体系统的健康发展。通过干预和竞争，可以引导那些最符合人类利益的智能体发展，确保没有单一系统会带来毁灭性的后果。该研究证明了干预措施在控制和可能反制AI系统方面的有效性，并提出了多个干预策略的方向。
## 136. `cs.AI` - 教育Q：通过多智能体对话框架评估大语言模型的教学能力 [PDF](https://arxiv.org/pdf/2504.14928), [HTML](https://arxiv.org/abs/2504.14928)
### Authors
Yao Shi,Rongkeng Liang,Yong Xu
### Background
大语言模型（LLMs）越来越被用作教育工具，但评估它们的教学能力仍然具有挑战性，因为教师与学生之间的互动具有资源密集型、情景依赖性和方法论复杂性的特点。这项研究探讨了一个名为EducationQ的多智能体对话框架，该框架通过模拟动态教育场景来高效评估教学能力，其中包括专门的教学、学习和评价智能体。该研究对来自主要AI组织（如OpenAI、Meta、Google、Anthropic等）的14个LLM在13个学科和10个难度级别的1498个问题上进行了测试，发现教学效果与模型规模或一般推理能力之间并没有简单的线性关系，一些较小的开源模型在教学场景中表现优于更大的商业模型。这一发现表明，当前的评估方法更侧重于知识的回忆而非互动式教学。
### Innovation
EducationQ引入了一个创新的多智能体对话框架，能够在模拟的动态教育场景中高效评估大语言模型的教学能力。研究结果表明，教学效果与模型规模或一般推理能力之间并没有简单的线性关系，一些较小的开源模型在教学场景中表现优于更大的商业模型，凸显了当前主要依赖于知识回忆而忽略互动教学评估方法的重要缺陷。此外，该研究使用了结合定量指标和定性分析以及专家案例研究的混合方法评估，发现一些顶级模型具有独特的教学优势（例如，复杂的问题提问策略和适应性反馈机制）。
### Conclusion
研究表明，大语言模型作为教师需要超越简单扩展的情况进行专门优化。这表明下一代教育人工智能应该专注于特定教学效果的针对性提升。这项研究还通过人工专家评估验证了自动化的定性分析方法的有效性，表明此方法在评估有效教学行为方面具有较高的一致性。
## 137. `cs.AI` - DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification [PDF](https://arxiv.org/pdf/2507.04600), [HTML](https://arxiv.org/abs/2507.04600)
### Authors
Zhipeng Liu,Peibo Duan,Binwu Wang,Xuan Tang,Qi Chu,Changsheng Zhang,Yongsheng Huang,Bin Zhang
### Background
现实世界的时间序列通常表现出复杂的时序变化，这使得时间序列分类任务变得尤为具有挑战性。最新的研究表明，多尺度分析方法在这种情况下具有潜在的应用价值，能够有效捕捉复杂的时序模式。然而，现有的多尺度分析方法未能有效地消除多尺度时间序列中的冗余共享特征，导致模型对这些特征过度或欠拟合。
### Innovation
本文提出了一种新颖的端到端解纠缠多尺度框架（DisMS-TS）用于时间序列分类。该框架通过消除多尺度时间序列中的冗余共享特征，改善预测性能。具体来说，提出了一种时间解纠缠模块来捕获不同层次的局部和全局时间特征。为了有效学习这些特征，引入了两个正则化项，保证了不同尺度共享特征的一致性和特定尺度特征之间的差异性。
### Conclusion
在多个数据集上的广泛实验表明，DisMS-TS方法优于其他竞争基线方法，准确率改善达到9.71%。
## 138. `cs.AI` - OR-LLM-Agent：使用具备推理能力的大语言模型自动化解决运筹学优化问题 [PDF](https://arxiv.org/pdf/2503.10009), [HTML](https://arxiv.org/abs/2503.10009)
### Authors
Bowen Zhang,Pengcheng Luo
### Background
随着人工智能（AI）的发展，将大型语言模型（LLMs）应用于运筹学（OR）问题求解引起了越来越多的关注。目前大多数方法通过提示工程或微调策略来改进OR问题求解，但这些方法受限于LLM缺乏推理能力。已有基准如NL4OPT、MAMO和IndustryOR存在某些问题，使它们不太适合可靠地评估LLM性能。
### Innovation
提出了OR-LLM-Agent，这是一个基于推理LLM的AI代理，旨在自动化OR问题求解。该代理将任务分解为数学建模、代码生成和调试三个顺序阶段，每个任务由专门的子代理处理，以实现更精确的推理。此外，构建了BWOR数据集，用以评估LLM在OR任务上的表现，结果显示比NL4OPT、MAMO和IndustryOR更加一致和区分性强。
### Conclusion
实验结果表明，OR-LLM-Agent在准确率上至少比GPT-o3、Gemini 2.5 Pro和ORLM高出7%，证明了任务分解对于OR问题求解的有效性。
## 139. `cs.AI` - 被推理腐蚀：推理语言模型在公共产品游戏中成为免费搭车者 [PDF](https://arxiv.org/pdf/2506.23276), [HTML](https://arxiv.org/abs/2506.23276)
### Authors
David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin
### Background
随着大型语言模型（LLMs）被越来越多地部署为自主代理，理解它们的合作和社会机制变得越来越重要。特别是LLMs如何在追求自我利益和集体福祉之间取得平衡，对于确保对齐、稳健性和安全部署而言是一个关键挑战。
### Innovation
本文适应了行为经济学中的公共产品游戏模型，并引入了制度选择，以此来研究多代理LLM系统中代价制裁的问题。通过这种设计，观察不同LLM在重复互动中如何应对社会困境。研究发现了模型之间四种不同的行为模式，并揭示了推理LLM（如o1系列）在合作方面面临显著困难，而某些传统LLM则能持续实现高水平的合作。
### Conclusion
研究结果表明，目前侧重于提升LLM推理能力的方法未必能促进合作，这对于在需要持续合作的环境中部署LLM代理具有重要启示意义。在公共产品游戏中表现良好的非推理模型提示我们，在提高LLM的社会性和互动性方面可能需要不同的策略。
## 140. `cs.AI` - 通过选项诱导抽象MDP中的变分同态学习时间抽象 [PDF](https://arxiv.org/pdf/2507.16473), [HTML](https://arxiv.org/abs/2507.16473)
### Authors
Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He
### Background
大型语言模型（LLMs）通过显式的链式思维（CoT）提示展示了显著的推理能力，但生成这些逐步的文本解释计算上非常昂贵且缓慢。为了解决这一问题，本文旨在开发一种高效隐含推理框架，即模型在潜在空间中“思考”而无需为每一步生成明确的文本。
### Innovation
本文提出了一种利用变分同态理论和变分马尔可夫选项评论（VMOC）算法学习时间抽象的方法。首先引入VMOC，这是一种在HiT-MDP框架中使用变量推断的离策算法。其次，通过扩展连续MDP同态理论，证明了在简化抽象的潜空间中学习策略可以保留原复杂问题的最优解。最后，提出了一种冷启动程序，利用监督微调（SFT）数据将人类推理示例精炼为潜空间选项，为模型提供了丰富的推理能力初始.
### Conclusion
大量实验证明，本文提出的方法在复杂的逻辑推理基准测试和挑战性运动任务上取得了强劲表现，证明了我们框架作为一种有原则的方法，可学习语言和控制中的抽象技能的有效性。
## 141. `cs.AI` - RIS辅助OFDM系统中延迟最小化下的波束形成和资源分配 [PDF](https://arxiv.org/pdf/2506.03586), [HTML](https://arxiv.org/abs/2506.03586)
### Authors
Yu Ma,Xiao Li,Chongtao Guo,Le Liang,Michail Matthaiou,Shi Jin
### Background
该论文研究了在RIS辅助的下行OFDM系统中，结合波束形成和资源分配的问题，以最小化平均延迟。在此类系统中，每个用户的数据包以随机方式到达基站。这个问题本质上是一个马尔可夫决策过程（MDP），适用于强化学习。
### Innovation
提出了一种混合深度强化学习（DRL）方法，通过结合PPO-Theta优化RIS相位移设计，PPO-N负责子载波分配决策。此外，引入了多代理策略来更有效地优化子载波分配指标，从而进一步减少维度问题。并且通过增强学习框架来提高训练效率并加速收敛。
### Conclusion
仿真结果表明，所提出算法显著降低了平均延迟，提高了资源分配效率，提高了系统鲁棒性和公平性，优于基线方法。
## 142. `cs.AI` - 当自主权失控：为社会系统中的多智能体共谋风险做准备 [PDF](https://arxiv.org/pdf/2507.14660), [HTML](https://arxiv.org/abs/2507.14660)
### Authors
Qibing Ren,Sitao Xie,Longxuan Wei,Zhenfei Yin,Junchi Yan,Lizhuang Ma,Jing Shao
### Background
近年来，诸如选举舞弊和金融欺诈等大规模事件已经显示出人类群体有组织努力的危害。随着自主人工智能系统的兴起，人们担心这些系统驱动的群体也可能造成类似的危害。尽管大多数人工智能安全性研究关注个体AI系统，但多智能体系统（MAS）在复杂现实世界情况下的风险仍处于探索阶段。文章探讨了如何模拟MA系统的风险，并使用支持集中式和分散式协调结构的框架进行了研究。该研究聚焦于虚假信息传播和电子商务欺诈这两个高风险领域，揭示了在没有传统干预措施的情况下，分散式系统的自主性使其能够更好地实施恶意行动并避免被检测到。
### Innovation
文章提出了一种灵活的框架，用以模拟和研究多智能体系统的风险，并将其应用于虚假信息的扩散和电子商务欺诈这两个领域。研究发现，分散式的MA系统在恶意行动上比集中式系统更有效，因为它们可以更好地进行策略调整并且更难被检测到，从而为了解和防范这些恶意行为提供了新的视角和方法。还强调了需要更好的检测系统和对策的需求。
### Conclusion
研究发现，分散式的多智能体系统在执行恶意行为上比集中式的更能摆脱检测并造成更大的损害。同时，研究成果也指出，应对这些风险的关键在于开发更有效的检测系统和对抗措施。研究团队已经公开了实现该框架的代码，以便进一步研究和发展。
## 143. `cs.AI` - 合规大脑助手：企业环境中的对话式代理AI辅助合规任务 [PDF](https://arxiv.org/pdf/2507.17289), [HTML](https://arxiv.org/abs/2507.17289)
### Authors
Shitong Zhu,Chenhao Fang,Derek Larson,Neel Reddy Pochareddy,Rajeev Rao,Sophie Zeng,Yanqing Peng,Wendy Summer,Alex Goncalves,Arya Pudota,Hervé Robert
### Background
本文介绍了合规大脑助手（CBA），这是一种为了提升企业环境中人员日常合规任务效率而设计的对话式代理AI助手。为了在响应质量与延迟之间取得平衡，设计了一个用户查询路由，能够智能选择不同的工作模式：快速通道模式用于处理只需要从知识库中检索额外相关上下文的简单请求；而完全代理模式则用于处理需要复合动作和工具调用的复杂请求，以主动发现各种合规文件中的上下文，并可能与其他API/模型进行交互以满足请求。
### Innovation
设计了用户查询路由机制，能够在处理简单和复杂请求时灵活切换快速通道模式和完全代理模式。通过实验评估，发现CBA在词汇匹配率（83.7% vs. 41.7%）和LLM裁判通过率（82.0% vs. 20.0%）等关键指标上显著优于标准的大规模语言模型。此外，与仅有快速通道设计和完全代理模式相比，该全路由设计方法在匹配率和通过率上具有更好的表现，而运行时间保持大致相同。这一结果验证了路由机制在两个世界之间的良好权衡。
### Conclusion
研究证明了CBA在处理企业合规任务时的有效性和效率，特别是通过优化的路由机制实现了响应质量和延迟之间的良好平衡。实验结果表明CBA在处理真实世界场景中的隐私和合规查询时比标准的LLM表现更为出色。
## 144. `cs.AI` - 法律推理分析中提示工程技术与多维度知识图谱的集成框架 [PDF](https://arxiv.org/pdf/2507.07893), [HTML](https://arxiv.org/abs/2507.07893)
### Authors
Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo
### Background
智能法律辅助系统中的法律纠纷分析至关重要。然而，当前的大语言模型（LLMs）在理解复杂的法律概念、保持推理一致性以及准确引用法律来源方面面临重大挑战。
### Innovation
本文提出了一种结合提示工程技术与多维度知识图谱的框架，旨在改进LLMs在法律纠纷分析中的能力。该框架包括三层级提示结构（任务定义、知识背景、推理指导）和三层知识图谱（法律本体、表示、实例层），并采用了四种支持方法：直接代码匹配、语义向量相似度、本体路径推理和词法分段，以实现精确的法律概念检索。
### Conclusion
通过广泛的测试，结果显示该框架在敏感性、特异性和引用准确性方面取得了显著改进：敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。因此，该框架为提供更好的法律分析和理解司法逻辑提供了新的技术方法，有助于智能法律辅助系统的发展。
## 145. `cs.AI` - VolDoGer：为视觉-语言任务的跨域泛化提供LLM辅助数据集 [PDF](https://arxiv.org/pdf/2407.19795), [HTML](https://arxiv.org/abs/2407.19795)
### Authors
Juhwan Choi,Junehyoung Kwon,JungMin Yun,Seunguk Yu,YoungBin Kim
### Background
跨域泛化能力是深度学习模型的关键特性，它决定了模型在未见过的数据域上的表现。然而，对于视觉-语言任务的深度学习模型的跨域泛化性研究有限，主要是缺乏必要的数据集。
### Innovation
我们提出了VolDoGer：一个专门为跨域泛化设计的视觉-语言数据集，用于解决图像字幕生成、视觉问答和视觉蕴含三个任务。该数据集利用了基于大规模语言模型的数据注释技术，减少了对人工注释者的依赖。我们通过VolDoGer评估了多种模型的跨域泛化能力，包括微调模型和最新的多模态大规模语言模型。
### Conclusion
VolDoGer为视觉-语言任务的跨域泛化提供了新的数据集，有效缓解了数据标注难题，并成功评估了不同模型的跨域泛化能力。
## 146. `cs.AI` - 识别和获取树上弱单交叉配置 [PDF](https://arxiv.org/pdf/1611.04175), [HTML](https://arxiv.org/abs/1611.04175)
### Authors
Palash Dey
### Background
论文探讨了基于树的弱单交叉域，这是在社会选择理论中广泛研究的单交叉域的拓展。研究设计了用于识别属于该域的偏好配置的多项式时间算法，并在此基础上开发了一种在偏好只能顺序访问且单交叉树结构事先未知的情况下工作的有效获取算法。论文还证明了当选民数量远大于候选人数目时，其获取算法的查询复杂性下界匹配，并且当随机查询允许时，获取单交叉配置所需的查询次数下界为$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{Ω}}}}}}}(m^2boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{log}}}}}}}}}}n;boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{})(m^2boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{2logn)}}}}}}}}}}))))）}}}}}}}}))))
### Innovation
论文提出了弱单交叉域上的识别和获取算法，且特别设计了解析顺序访问和未知单交叉树结构条件下的高效获取算法；证明了当允许随机查询时的查询次数下界，该结果解决了先前论文中未解的问题，并且是允许随机查询情况下的最优偏好获取算法。
### Conclusion
论文提出了弱单交叉域的识别和获取算法，证明了查询复杂性的匹配下界，特别是对于允许随机查询的情况，该算法是优化的，并解决了先前的开放问题。
## 147. `cs.AI` - DocTER: 评估文档驱动的知识编辑 [PDF](https://arxiv.org/pdf/2308.09954), [HTML](https://arxiv.org/abs/2308.09954)
### Authors
Suhang Wu,Ante Wang,Minlong Peng,Yujie Lin,Wenbo Li,Mingming Sun,Jinsong Su
### Background
知识编辑旨在纠正神经网络中的过时或不准确的知识。以往研究使用手动标记的语义三元组，而本研究尝试使用易于获取的文档替代手动标记的语义三元组进行知识编辑。提出了第一个包含反驳性知识的文档评估基准DocTER，从编辑成功、相关性、推理和跨语言迁移四个维度对文档驱动的知识编辑方法进行了全面评估，这些评估揭示了使用文档进行知识编辑面临的显著挑战和旧方法在此类任务中的局限性。通过对关键因素的进一步分析，研究提供了对未来研究有价值的见解，包括提取三元组的质量、被编辑知识在文档中的频率和位置、各种提高推理的方法以及跨语言知识编辑在不同方向上的性能差异。
### Innovation
本研究引入了一个名为DocTER的评估基准，基于文档进行知识编辑，评估了四方面：编辑成功、相关性、推理和跨语言迁移。提出了一个从提取三元组到应用现有方法的Extract-then-Edit管道，证明使用文档进行知识编辑比使用三元组更具有挑战性，即使在最佳上下文编辑方法的条件下，使用文档也不能在编辑成功率方面取得与使用黄金三元组相同的成绩，这一观察结果也在推理和跨语言测试集上成立。进一步分析了影响任务性能的关键因素，提供了对未来研究的见解，包括提取的三元组质量、编辑知识在文档中的频率和位置、提高推理的各种方法以及跨语言知识编辑在各个方向上的性能差异。
### Conclusion
文档驱动的知识编辑相较于使用三元组更为复杂，现有的知识编辑方法在文档场景下表现较差，特别是编辑成功率方面差距明显。研究揭示了评估基准的必要性，为未来相关领域研究提供了关键见解，提出了改进方向。
## 148. `cs.AI` - 实时深度学习表示中的无监督概念漂移检测 [PDF](https://arxiv.org/pdf/2406.17813), [HTML](https://arxiv.org/abs/2406.17813)
### Authors
Salvatore Greco,Bartolomeo Vacchetti,Daniele Apiletti,Tania Cerquitelli
### Background
概念漂移是指目标领域随时间变化的数据分布和统计特性发生变化的现象，导致模型性能下降。因此，生产模型需要持续的概念漂移检测监控。目前大多数概念漂移检测方法依赖于监督学习和真实标签，但在许多现实场景中，真实标签往往不可用。虽然最近有一些无监督概念漂移检测方法，但它们要么准确性不足，要么计算成本高，不适合在高维度和大规模生产环境中实时使用。此外，这些方法常常无法有效描述或解释概念漂移。
### Innovation
我们提出了DriftLens，一个基于深度学习表示的无监督实时概念漂移检测与表征框架。DriftLens利用深度学习表示中的分布距离来实现高效的检测，同时通过分析和解释每个标签上的影响来表征漂移。实验结果表明，DriftLens在15/17个使用场景中检测漂移的表现优于之前的方法，运行速度快5倍以上，生成的漂移曲线与实际漂移高度相关（相关性≥0.85），并且能够有效识别代表性漂移样本作为解释。
### Conclusion
DriftLens框架在无监督实时概念漂移检测方面取得了突破，能够有效应对高维度和大规模生产环境中的概念漂移问题，具有高效、准确、易解释的特点。
## 149. `cs.AI` - 量化总统言论的独特性与煽动性 [PDF](https://arxiv.org/pdf/2401.01405), [HTML](https://arxiv.org/abs/2401.01405)
### Authors
Karen Zhou,Alexander A. Meitus,Milo Chase,Grace Wang,Anne Mykland,William Howell,Chenhao Tan
### Background
该研究旨在探讨美国历任总统在言论上的异同，以及这些差异是否受到特定沟通媒体的影响。通过对总统演讲的多种语料库进行分析，该研究发现唐纳德·特朗普的言论模式与其他主要政党提名人的言论模式存在显著差异，尤其是在针对政治对手时使用了更为分化和敌对的语言。这些差异不仅在竞选活动中体现，在正式的总统讲话中也有所呈现。研究表明这一现象不是由于总统沟通方式的世代性变化造成的。这项研究使用了基于大规模语言模型的新颖度量标准，并开发了一个新的区分性言语词汇表，以及一个评估总统言论中政治对手的独特方式的框架。
### Innovation
该研究创新性地引入了一种基于大规模语言模型的独特度量标准，并开发了一个新的区分性词汇表，以评估总统在政治对手言论中的独特性。此外，该研究提供了一个评估美国总统在不同沟通渠道中独特言论的新框架。研究还特别关注了唐纳德·特朗普与历任主要政党提名人在针对政治对手时所使用语言的独特性和分化性，显示了明显的区别性，尤其是在使用敌对性语言方面。
### Conclusion
研究结果表明，唐纳德·特朗普的言论模式比其他主要政党提名人的更为独特，尤其是在针对政治对手时使用了更为分化和敌对的语言。这些差异在多种衡量策略下都存在，并且在竞选活动和正式的总统讲话中都在体现，而不只是由于历代总统沟通风格的变化造成的。
## 150. `cs.AI` - DualXDA:向大规模AI模型中追求稀疏高效可解释的数据归因 [PDF](https://arxiv.org/pdf/2402.12118), [HTML](https://arxiv.org/abs/2402.12118)
### Authors
Galip Ümit Yolcu,Moritz Weckbecker,Thomas Wiegand,Wojciech Samek,Sebastian Lapuschkin
### Background
深度学习模型在决策过程中通常显得不够透明，这促使了可解释人工智能（XAI）领域的显著发展。尽管已有许多特征归因方法，但这些方法面临计算成本高、内存要求高以及稀疏性低等问题。因此，研究人员转向数据归因（Data Attribution, DA）作为一种新的方法论，重点关注数据的来源而不是特征。然而，现有的DA方法仍有许多改进空间，尤其是在提高稀疏性和减少计算开销方面。
### Innovation
本文介绍了一种新的框架——DualXDA，包括两个相互关联的方法：Dual Data Attribution (DualDA) 和 eXplainable Data Attribution (XDA)。 DualDA方法利用支持向量机理论，提供快速且自然的稀疏数据归因，显著提高了归因质量，并将解释时间相比现有方法（如影响函数）提高了4,100,000倍，相比最高效的文献方法提高了11,000倍。XDA方法则结合了特征归因方法的能力，解释训练样本为何对预测有显著影响。这两种方法使DualXDA框架成为大规模AI模型中稀疏、高效且可解释的数据归因的有效解决方案。
### Conclusion
本文的研究成果指向了一个未来，能够以未有过的规模实现可解释的人工智能应用，这将透明化、高效化并开拓新领域对甚至是最复杂的神经网络进行分析，从而促进新一代问责制AI系统的生成。
## 151. `cs.AI` - 在随机子空间中对大语言模型进行零阶微调 [PDF](https://arxiv.org/pdf/2410.08989), [HTML](https://arxiv.org/abs/2410.08989)
### Authors
Ziming Yu,Pan Zhou,Sike Wang,Jia Li,Mi Tian,Hua Huang
### Background
大型语言模型（LLMs）在各种下游任务中通过微调已经证明是有效的。然而，随着LLMs的规模增长，反向传播所需的内存需求变得越来越难以承受。零阶（ZO）优化方法通过使用前向传递来估计梯度提供了一种内存效率更高的替代方案，但梯度估计的方差通常与模型参数维度成线性关系，这是对LLMs的高维度的一个重要问题。
### Innovation
本文提出了一种针对LLMs的高维度挑战的随机子空间零阶优化方法（SubZero），其中引入了一种适用于LLMs的低秩扰动，显著降低了内存消耗并改善了训练性能。此外，证明了我们的梯度估计与反向传播梯度高度接近，方差较传统的ZO方法更低，并且在与SGD结合时能确保收敛。
### Conclusion
实验结果显示SubZero方法在多种语言建模任务中增强了微调性能，并且比传统的ZO方法（如MeZO）更快地实现了收敛。代码可在以下链接处获得：this https URL
## 152. `cs.AI` - Neural Corrective Machine Unranking [PDF](https://arxiv.org/pdf/2411.08562), [HTML](https://arxiv.org/abs/2411.08562)
### Authors
Jingrui Hou,Axel Finke,Georgina Cosma
### Background
在神经信息检索（IR）系统中进行机器卸载需要移除特定数据以保持模型性能。现有的机器卸载方法应用到IR时可能会损害检索效果，或者在移除某些结果项时无意中暴露了卸载操作。因此，需要一种能够保持排名完整性的正式的纠正重排方法。
### Innovation
提出了一种名为正确性重排蒸馏（Corrective unRanking Distillation, CuRD）的新颖教师-学生框架，该框架通过集成替代文本来扩展神经IR环境下的机器卸载。CuRD通过调整（训练过的）神经IR模型的输出相关性分数，使其与被遗忘样本低排名、不可检索样本的分数相似，从而实现遗忘；通过微调替代样本的相关性分数，使其与对应的被遗忘样本的分数密切匹配，从而实现纠正；并且寻求保持未被遗忘样本的性能。
### Conclusion
通过在四个神经IR模型（BERTcat, BERTdot, ColBERT, PARADE）上使用MS MARCO和TREC CAR数据集进行评估，实验结果表明，CuRD在遗忘和纠正性能方面优于七个最新基准，同时保持了模型的保留和泛化能力。
## 153. `cs.AI` - 事件因果识别：分类、挑战、评估与展望 [PDF](https://arxiv.org/pdf/2411.10371), [HTML](https://arxiv.org/abs/2411.10371)
### Authors
Qing Cheng,Zefan Zeng,Xingchen Hu,Yuehang Si,Zhong Liu
### Background
事件因果识别（ECI）已成为自然语言处理（NLP）中的重要任务，主要关注在文本中自动检测事件之间的因果关系。本文提供了一篇全面的综述，系统地研究了基本概念和模型，发展了一个系统的分类体系，并对多种模型进行了批判性评估。文章从定义核心概念、形式化ECI问题以及概述标准评估协议开始。针对事件因果识别模型，分类框架将其分为两个主要任务：句内事件因果识别（SECI）和文档级别事件因果识别（DECI）。针对SECI，文章回顾了基于特征模式匹配、机器学习分类器、深层语义编码、基于提示的微调以及因果知识预训练等模型，并结合数据增强策略。针对DECI，文章关注利用深层语义编码、事件图推理和基于提示的微调的方法。特别关注多语种和跨语种的事件因果识别，以及利用大规模语言模型（LLMs）的零样本事件因果识别。针对每种方法分析了其优点、局限性以及未解决的挑战。文章在四个基准数据集上进行了大量的定量评估，以严格评估各种ECI模型的性能。
### Innovation
文章发展了一个系统的分类体系，分类框架将事件因果识别模型分为句内事件因果识别（SECI）和文档级别事件因果识别（DECI）两大类，并详细回顾了各种模型及其策略，展示了对每种方法的优点、局限性和挑战的分析。此外，还特别关注了多语种和跨语种的事件因果识别，以及零样本事件因果识别的方法和挑战。文章通过在四个基准数据集上的详细评估，比较了不同ECI模型的性能。
### Conclusion
文章讨论了未来的研究方向，并指出了进一步推进该领域的潜在机会。
## 154. `cs.AI` - 学习可定义在一阶逻辑计数中的概念 [PDF](https://arxiv.org/pdf/1909.03820), [HTML](https://arxiv.org/abs/1909.03820)
### Authors
Steffen van Bergerem
### Background
本文探讨在Grohe和Turán (TOCS 2004) 提出的逻辑框架下，关系背景结构上的布尔分类问题。已知可以通过聚类在结构大小的次线性时间内学习，其中结构的度和运行时间按结构大小测量。研究扩展了一阶逻辑（FOCN），这是一阶逻辑和计数的扩展。此前，Kuske和Schweikardt (LICS 2017) 引入了这种逻辑来扩展各种计数逻辑的表达能力。
### Innovation
证明了在参数为结构大小的次线性时间内的类集中，构造在FOCN（一阶逻辑计数）中的分类器可以一致地学习。这被视为将学习框架扩展以涵盖机器学习中数值方面的第一步。此外，该研究扩展了结果，针对度数最多为 $(text{log} text{log } n)^c$ 的结构集的泛化对概率近似正确（PAC）学习进行了研究，证明了限制度数是获得次线性时间学习算法的必要条件。
### Conclusion
限制度数对于获得次线性时间学习算法至关重要。对于无界度数的结构集，即使使用基本的一阶逻辑分类器，学习在次线性时间内也不可能实现。
## 155. `cs.AI` - 一个评估大型语言模型生成合成数据的多方面框架 [PDF](https://arxiv.org/pdf/2404.14445), [HTML](https://arxiv.org/abs/2404.14445)
### Authors
Yefeng Yuan,Yuhong Liu,Liang Cheng
### Background
生成式人工智能和大规模语言模型(Large Language Models, LLMs)的迅速发展为生成合成数据，特别是在结构化表格格式（如产品评论）领域开辟了新的途径。尽管合成数据有潜在的好处，但隐私泄露的担忧在利用包含个人信息的训练数据集时尤为突出。此外，缺乏一个全面的评估框架来定量评估生成的合成数据的质量及其在下游任务中的应用价值。
### Innovation
本文引入了SynEval，这是一个开源的评估框架，用于通过一系列多元评估指标评估生成的合成表格数据的真实度、实用性和隐私保护。SynEval适用于验证大型语言模型（如ChatGPT、Claude、Llama）生成的产品评论数据的有效性，并展示了多种评估指标在合成数据生成中的权衡。
### Conclusion
SynEval代表了研究者和从业人员评估合成表格数据的重要工具，帮助他们明智地决定生成数据的适用性，尤其是强调保护用户隐私。
## 156. `cs.AI` - 神经机器未排序 [PDF](https://arxiv.org/pdf/2408.05330), [HTML](https://arxiv.org/abs/2408.05330)
### Authors
Jingrui Hou,Axel Finke,Georgina Cosma
### Background
本文探讨了神经信息检索（IR）中机器遗忘的问题，引入了一个新的任务—神经机器未排序（NuMuR），这一问题源于日益增长的数据隐私合规需求和神经IR系统中选择性信息删除的需求。现有任务或模型无关的遗忘方法主要针对分类任务设计，对于NuMuR来说效果不佳，原因有两个：一是神经排名器输出非归一化的相关性评分而不是概率分布，限制了传统教师-学生蒸馏框架的有效性；二是纠缠数据情景，查询和文档在忘记集与保留集同时出现，这可能在现有方法中导致保留性能的下降。
### Innovation
本文提出了对比一致损失（CoCoL），这是一种双目标框架。CoCoL包括（1）对比损失，它会减少忘记集上的相关性评分，同时保持对纠缠样本的性能；（2）一致性损失，它保留了保留集上的准确率。在MS MARCO和TREC CAR数据集上进行的实验表明，CoCoL不仅实现了显著的遗忘，而且在保留和泛化性能损失方面也表现出了显著的优势，使得数据的删除更加高效和可控。
### Conclusion
CoCoL在多个神经IR模型上实现了有效的遗忘，仅导致很小的保留和泛化性能损失，为更有效和可控的数据删除提供了新的方法。
## 157. `cs.AI` - 在动力学约束下的可微运动流形原语用于反应式运动生成 [PDF](https://arxiv.org/pdf/2410.12193), [HTML](https://arxiv.org/abs/2410.12193)
### Authors
Yonghyeon Lee
### Background
实时生成运动——对于实现反应性和适应性行为至关重要——在高维系统下同时满足运动学和动力学限制是至关重要的但极具挑战性的课题。现有方法难以高效地满足这些复杂的约束条件。
### Innovation
本文提出了一种两步方法：离线学习任务相关的满足约束条件的轨迹低维流形，然后在线快速搜索该流形。还提出了DiffManifoldPrimitives (DMMP)，一种新的神经网络架构，能够编码和生成连续时间、可微的轨迹。与现有方法相比，该方法通过离线轨迹优化收集的数据进行训练，并确保了约束条件的满足。
### Conclusion
实验结果表明，DMMP 方法在规划速度、任务成功与约束满足方面均优于现有方法，在7 自由度机器人手臂的动态投掷中表现尤为突出。
## 158. `cs.AI` - 将证据集成到XAI和基于AI的决策支持系统设计中的框架：建筑终端用户的手段-目的框架 [PDF](https://arxiv.org/pdf/2412.14209), [HTML](https://arxiv.org/abs/2412.14209)
### Authors
Peter E.D. Love,Jane Matthews,Weili Fang,Hadi Mahamivanan
### Background
可解释的人工智能旨在使AI模型的推理过程透明和可解释，特别是在复杂的决策环境中有重要作用。建筑行业越来越多地采用基于AI的决策支持系统，但关于支持证据的整合的关注较少。缺乏此类证据会削弱解释的有效性和系统的可信赖度。现有文献指出，该领域存在着如何使AI生成的解释对最终用户更加有意义和精准的需求。
### Innovation
本文通过叙事综述提出了一种依托证据的理论性手段-目的框架，为设计包含XAI功能的决策支持系统提供认知基础。该框架旨在评估不同类型证据支持AI生成的解释的程度、相关性与实用性。
### Conclusion
该框架不仅适用于建筑专业的终端用户，还能使开发人员、监管者和项目经理满足不同的认知目标。通过这一框架，可以更好地理解并支持建筑领域的AI决策支持系统的可解释性与可信赖性。
## 159. `cs.AI` - RUMI: 使用互信息进行翻找 [PDF](https://arxiv.org/pdf/2408.10450), [HTML](https://arxiv.org/abs/2408.10450)
### Authors
Sheng Zhong,Nima Fazeli,Dmitry Berenson
### Background
本文介绍了一种名为Rummaging Using Mutual Information (RUMI)的新方法，该方法用于在线生成机器人的动作序列，以便在视觉遮挡的环境中收集关于已知可移动物体姿态的信息。
### Innovation
1. 提出了一种新的信念框架用于物体姿态估计。2. 提出了一种高效的信息增益计算策略。3. 提出了一种基于模型预测控制（MPC）的鲁棒控制方案，该方案将物体保持在机器人的可及范围内。4. 使用带有随机动力学模型的模型预测控制框架，实现在闭环中更新物体的姿态分布。
### Conclusion
RUMI在模拟和实际任务中均表现出优于基线方法的优越性能。
## 160. `cs.AI` - 通过学习个性化不变表示实现通用3D医学多模态泛化 [PDF](https://arxiv.org/pdf/2411.06106), [HTML](https://arxiv.org/abs/2411.06106)
### Authors
Zhaorui Tan,Xi Yang,Tan Pan,Tianyi Liu,Chen Jiang,Xin Guo,Qiufeng Wang,Anh Nguyen,Yuan Qi,Kaizhu Huang,Yuan Cheng
### Background
医学成像模态和个体解剖学差异给多模态任务的跨模态泛化带来了挑战。现有方法往往只关注共同的解剖学模式，忽略了个体差异，从而限制了它们的泛化性能。
### Innovation
本文强调了学习个体水平不变性，即个性化表示 ΚX_h，以增强在同质性和异质性设置下的多模态泛化。研究揭示了从个体生物特征到不同医学模态的映射在人群中是静态的，这是个人化过程中的体现。提出了一个两阶段方法：使用不变表示 ΚX_h 前置训练进行个性化，然后微调用于多样化的下游任务。提供理论和实验证据证明个性化方法的可行性和优势，展示其相比缺乏个性化的方法在多种医学多模态任务中具有更出色的泛化和迁移能力。
### Conclusion
广泛的实验进一步证实了该方法在各种泛化场景中显著提高了性能。
## 161. `cs.AI` - 使用图神经网络进行超导量子电路的大规模参数设计 [PDF](https://arxiv.org/pdf/2411.16354), [HTML](https://arxiv.org/abs/2411.16354)
### Authors
Hao Ai,Yu-xi Liu
### Background
随着量子计算霸权的展示，正在设计和制造越来越大规模的超导量子计算芯片，但模拟量子系统的复杂性对基于计算机辅助设计的大规模量子芯片提出了重大挑战。现有的算法在处理大规模量子芯片时表现出效率低和可扩展性差的问题。
### Innovation
提出了一种基于图神经网络（GNN）的参数设计算法，该算法基于所谓的'三阶阶梯扩展'机制，包括两个神经网络模型：一个监督训练的评估器用于应用于中等规模电路的小规模电路模型，以及一个无监督训练的设计器用于应用于大型电路的中等规模电路模型。通过这种方法，实现了对量子串扰错误的有效缓解，同时考虑了一次门和两比特门频率（对应于节点和边的参数）。
### Conclusion
提出的基于GNN的算法能够显著提高效率、效果和可扩展性，在大约拥有870个量子比特的大规模超导量子电路中，与最先进的算法相比，减少了90分钟到27秒的时间，并将错误率降低了51%。这表明GNN在超导量子芯片设计中的应用具有更大的性能和更好的可扩展性。
## 162. `cs.AI` - LLM Alignment as Retriever Optimization: An Information Retrieval Perspective [PDF](https://arxiv.org/pdf/2502.03699), [HTML](https://arxiv.org/abs/2502.03699)
### Authors
Bowen Jin,Jinsung Yoon,Zhen Qin,Ziqi Wang,Wei Xiong,Yu Meng,Jiawei Han,Sercan O. Arik
### Background
大型语言模型（LLMs）在推理、编码和通信方面的能力颠覆了人工智能领域，推动了各行各业的创新。然而，这些模型有效的利用依赖于有效的对齐，以确保其行为的正确性、可信度和道德性，解决诸如信息谬误、幻觉、偏见和误用等挑战。现有的基于强化学习（RL）的对齐方法极其复杂，而直接优化方法则提供了更为简单的替代方案。现有的RL方法过于复杂，需要在技术和实施方面付出更多努力来实现对齐，而直接优化方法则相对简单，直接优化LLM生成和奖励模型，以提升整体对齐质量。研究发现现有的对齐方法效果一般，而新的方法能显著提高对齐效果。
### Innovation
本文提出了一种新的直接优化方法，称为LLM Alignment as Retriever Preference Optimization (LarPO)，通过借鉴信息检索（IR）的原理来解决LLM的对齐问题。LarPO将LLM的生成和奖励模型映射到IR的检索器-重新排名框架，从而实现更为高效的对齐优化。这一方法在广泛的实验中表现出显著的效果，比现有方法提高了38.9%和13.7%的效果。其创新在于将信息检索的方法运用到LLM对齐中，提供了一个新的研究方向和有希望的未来研究途径。
### Conclusion
本文提供了一种新的LLM对齐方法LarPO，该方法通过利用信息检索原理有效提升对齐质量，实验结果表明LarPO在多个评估标准上表现优异。这种方法不仅简化了对齐过程，还为进一步优化LLM的行为提供了一种新的思路。未来研究可以在此基础上，进一步探索信息检索与LLM对齐之间的结合方式，提高在更复杂场景下的应用效果。
## 163. `cs.AI` - ExpliCa：评估大规模语言模型的明确因果推理 [PDF](https://arxiv.org/pdf/2502.15487), [HTML](https://arxiv.org/abs/2502.15487)
### Authors
Martina Miliani,Serena Auriemma,Alessandro Bondielli,Emmanuele Chersoni,Lucia Passaro,Irene Sucameli,Alessandro Lenci
### Background
随着大规模语言模型（LLMs）在需要解释性和推断性准确度的任务中应用越来越广泛，这些模型在明示因果推理中的表现成为了研究的重点。现有的数据集无法全面地评估LLMs在处理因果关系和时间关系时的表现，因此研究人员开发了一个新的数据集ExpliCa，来填补这方面的空白。
### Innovation
ExpliCa数据集的独特之处在于它不仅结合了因果关系和时间关系，而且还以不同的语言顺序明确地表达这些关系。此外，该数据集还被丰富了来自众包的人类可接受性评级。通过使用提示和困惑度为基础的度量标准测试LLMs，研究人员展示了即便是顶级模型在ExpliCa上的准确率也只有80%左右。该研究还发现了模型倾向于混淆时间关系与因果关系，以及事件的语言顺序对模型表现的影响至深。最后，研究人员发现困惑度评分和提示性能对模型大小的敏感程度不同。
### Conclusion
尽管现有的商业和开源LLMs在ExpliCa上的表现不尽人意，但仍需要进一步的研究来提升它们在明确因果推理任务中的表现。
## 164. `cs.AI` - EVEv2: 提升的基于统一模型的无编码器视觉-语言模型基线 [PDF](https://arxiv.org/pdf/2502.06788), [HTML](https://arxiv.org/abs/2502.06788)
### Authors
Haiwen Diao,Xiaotong Li,Yufeng Cui,Yueze Wang,Haoge Deng,Ting Pan,Wenxuan Wang,Huchuan Lu,Xinlong Wang
### Background
现有的无编码器视觉-语言模型（VLMs）正在迅速缩小与基于编码器的模型之间的性能差距，突显了它们具备有效性、结构简单且部署高效的潜力。本文系统性地分析了基于预训练视觉编码器、离散分词器和从零构建的简约视觉层的统一视觉-语言模型之间的性能差异，深入探讨了无编码器VLMs的不足之处。研究发现了有效的策略来抗衡主流的基于编码器的模型。通过对这些模型进行深入研究，推出了EVEv2.0这一更新的无编码器视觉-语言模型家族，显示了解析器仅有架构在不同模态上具有更高效的利用数据和强大的视觉推理能力。
### Innovation
开发了有效的策略使得无编码器VLMs能够与主流的基于编码器的VLMs相抗衡；推出了EVEv2.0这一新的无编码器视觉-语言模型家族，该模型通过合适的分解和层次性的视觉-语言联系以及良好的训练策略，实现了统一模型中有效地减少模态间的干扰和高效的优化优化。此外，EVEv2.0模型展示了更强的跨模态数据效率和视觉推理能力。
### Conclusion
EVEv2.0不仅展示了无编码器架构在跨模态任务中的潜在优势，还为后期相关研究提供了重要参考。同时，我们下载了EVEv2.0模型的代码。
## 165. `cs.AI` - 用于肽识别的一般语言模型 [PDF](https://arxiv.org/pdf/2502.15610), [HTML](https://arxiv.org/abs/2502.15610)
### Authors
Jixiu Zhai,Tianchi Lu,Haitian Zhong,Ziyang Xu,Yuhuan Liu,Shengrui Xu,Jingwan Wang,Dan Huang
### Background
准确识别生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）对于理解蛋白质功能和推进治疗发现至关重要。然而，大多数计算方法在其普遍性方面仍然受到限制，尤其是在面对多种肽功能时。因此，需要一个能够跨多种肽类和PTM位点进行稳健识别的统一框架。
### Innovation
我们提出了PDeepPP，这是一个结合了预训练蛋白质语言模型和混合变压器-卷积架构的统一深度学习框架，能够跨多种肽类和PTM位点进行稳健识别。通过全面的基准数据集和策略，PDeepPP可以系统地提取全局和局部序列特征。PDeepPP在33项生物识别任务中的25项上实现了最先进的性能，特别在抗菌活性和磷酸化位点识别方面具有高精度，在糖基化位点预测方面具有99.5%的特异性，并在抗疟疾任务中显著减少了假阴性数量。
### Conclusion
PDeepPP通过支持大规模、准确的肽分析，促进了生物医学研究和疾病治疗新型治疗靶点的发现。所有代码、数据集和预训练模型均通过GitHub和Hugging Face公开提供。
## 166. `cs.AI` - 使用DynamicDPS为医疗图像重建从条件模型克服幻觉 [PDF](https://arxiv.org/pdf/2503.01075), [HTML](https://arxiv.org/abs/2503.01075)
### Authors
Seunghoi Kim,Henry F. J. Tregidgo,Matteo Figini,Chen Jin,Sarang Joshi,Daniel C. Alexander
### Background
幻觉是医疗图像重建中的关键挑战，尤其是在数据驱动的条件模型中。它们是不存在于真实地面数据中的虚假结构，这对低质量医疗图像的增强尤其具有破坏性。
### Innovation
该论文提出了一种基于扩散的框架DynamicDPS，结合了条件和无条件扩散模型，旨在通过引入数据一致性来减少幻觉。DynamicDPS通过自适应反问题求解器对初始重建进行细化，并利用Wolfe线搜索算法选择最优初始时间点，以适应步骤尺寸，从而提高效率和图像保真度。该方法通过扩散先验和数据一致性，能够在任何条件模型输出中有效减少幻觉。
### Conclusion
在低场MRI增强的图像质量转移方面，DynamicDPS的方法表现出色，相对于基线扩散模型仅使用5%的采样步骤，即可将关键组织的体积估计相对提高超过15%。作为一种无需模型调优的通用方法，DynamicDPS提供了一种在医疗成像中减少幻觉的稳健解决方案，其代码将在发表后公开。
## 167. `cs.AI` - 量子计算在精准医学和药物发现中的机器学习：个性化治疗的颠覆者？ [PDF](https://arxiv.org/pdf/2502.18639), [HTML](https://arxiv.org/abs/2502.18639)
### Authors
Markus Bertl,Alan Mott,Salvatore Sinno,Bhavika Bhalgamiya
### Background
医疗领域的数字化面临着生物系统复杂性、数据量庞大和个人化治疗方案需求等挑战。传统计算方法往往无法应对，导致诊断和治疗延误甚至无效。量子计算（QC）和量子机器学习（QML）能够提供革命性的进步，有望彻底改变医学领域。然而，将量子技术融入精准医学也带来了挑战，如算法错误和高成本等问题。数学基础的软件开发技术（形式化方法）能在提高量子计算可靠性和准确性方面发挥重要作用。形式化方法能提供精确的数学框架，用于定义和验证系统的行为和属性，特别是在基因数据分析中，精确定义量子算法的行为和属性，确保其在所有条件下正确运行，并通过证明技术实现严格验证，提高量子算法的效率和性能。
### Innovation
本文总结了量子计算在精准医学中的潜在优势，如更快更准确的诊断、个性化治疗以及提升药物发现过程，同时提出形式化方法可以解决量子技术中的复杂性和高成本问题，提高其可靠性和准确性，特别是在基因数据分析中实现精确定义与验证量子算法，确保其满足规定的属性，提高量子算法的效率和性能。
### Conclusion
形式化方法能够显著增强量子计算在精准医学领域的应用潜力，确保其能够实现作为一个改变游戏规则的工具的全部价值。
## 168. `cs.AI` - 稀疏 logits 抽样：加速大型语言模型的知识蒸馏 [PDF](https://arxiv.org/pdf/2503.16870), [HTML](https://arxiv.org/abs/2503.16870)
### Authors
Anshumann,Mohd Abbas Zaidi,Akhil Kedia,Jinwoo Ahn,Taehwak Kwon,Kangwook Lee,Haejun Lee,Joohyung Lee
### Background
知识蒸馏在大型语言模型中是一个成本效益高的技术，特别是在教师输出logits可以预先计算和缓存的情况下。然而，将这种方法成功应用于预训练还未被充分探索。传统的稀疏知识蒸馏方法，如缓存Top-K概率，虽然直观，但会导致对学生来说偏斜的教师概率分布估计，进而导致性能和校准不佳。
### Innovation
提出了基于重要性抽样的方法`随机采样知识蒸馏`，该方法能够提供无偏估计，保持梯度期望不变，并且需要存储显著稀疏的logits。这种方法相比交叉熵训练能够在微不足道的开销下（<10%）使学生模型的训练速度加快，同时在不同规模的模型上（300M到3B）保持与完全蒸馏相当的性能。
### Conclusion
证明了一种新颖的方法，即基于重要性抽样的稀疏logits抽样知识蒸馏，它不仅加快了训练速度，还保持了良好的性能。
## 169. `cs.AI` - 通过样本级注意力表示融合和仿射扰动对齐实现鲁棒多视角学习 [PDF](https://arxiv.org/pdf/2503.04151), [HTML](https://arxiv.org/abs/2503.04151)
### Authors
Jie Xu,Na Zhao,Gang Niu,Masashi Sugiyama,Xiaofeng Zhu
### Background
近年来，多视角学习（MVL）因其能够融合来自多个视角的判别信息而受到广泛关注。然而，现实中的多视角数据集通常是异质且不完美的，这通常使得旨在特定视角组合下的MVL方法缺乏应用潜力，限制了其效果。因此，本文旨在解决这一问题，提出了一种新的鲁棒MVL方法（即RML），该方法同时实现了表示融合和对齐。具体而言，通过一个简单的多视角变换融合网络，将异质多视角数据转变为同质词嵌入，通过对样本级别的注意力机制进行集成来获得融合表示。
### Innovation
本文提出了一个简单的多视变换融合网络，将异质多视角数据转化为同质词嵌入，并通过样本级别注意力机制进行集成，获得融合表示。此外，还提出了一种基于仿射扰动的多视角对比学习框架，通过动态生成噪声和无用扰动来模拟不完美数据条件。对模态的噪声和不可用数据获得了两种不同的融合表示，并利用对比学习对齐它们，以学习判别性和鲁棒性表示。RML是自监督学习方法，并且可以应用于下游任务作为正则化。
### Conclusion
在实验中，该方法被用于多视角无监督聚类、噪声标签分类以及跨模态哈希检索插件模块。广泛的比较实验和消融研究验证了RML的有效性。代码已发布。
## 170. `cs.AI` - Att-Adapter: 一种通过条件变分自编码器实现的稳健且精确的领域特定多属性文本到图像扩散适配器 [PDF](https://arxiv.org/pdf/2503.11937), [HTML](https://arxiv.org/abs/2503.11937)
### Authors
Wonwoong Cho,Yan-Ying Chen,Matthew Klenk,David I. Inouye,Yanxia Zhang
### Background
文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著进展，但使用仅文本指导在新领域中精确控制连续属性，尤其是同时控制多个属性（例如数值属性如眼睛开启度或汽车宽度）仍然存在重大挑战。
### Innovation
提出了一种名为Att Adapter的新型插件模块，旨在使预训练扩散模型能够实现细粒度且多属性的控制。Att Adapter通过解耦交叉注意力模块来自然地将多个领域属性与文本条件相协调，并引入了条件变分自编码器（CVAE）来减轻过拟合问题，更好地匹配视觉世界中的多样性。
### Conclusion
Att Adapter在控制连续属性方面超越了所有的基于LoRA的基线模型，并且能够实现更广泛的控制范围，提高多属性间的去纠缠性，超过了基于StyleGAN的技术。该方法灵活且无需配对的合成数据进行训练，并且可以轻松扩展到单个模型内的多个属性。
## 171. `cs.AI` - 图像对齐到语言：无注释的增强型多模态知识图构建 [PDF](https://arxiv.org/pdf/2503.12972), [HTML](https://arxiv.org/abs/2503.12972)
### Authors
Junming Liu,Siyuan Meng,Yanting Gao,Song Mao,Pinlong Cai,Guohang Yan,Yirong Chen,Zilin Bian,Ding Wang,Botian Shi
### Background
大型语言模型（LLMs）在多模态推理方面面临知识不完整和幻觉问题，仅部分知识图（KGs）能通过模态隔离的方式部分缓解，但构建多模态知识图（MMKGs）仍然受限于手动文本注释的语义狭隘性和视觉语义实体链接中的固有噪声。目前构成MMKGs的方法效率低下，难以整合跨模态信息，通常依赖于有限的手动注释和个人主观判断。
### Innovation
本文提出了Vision-align-to-Language集成知识图（VaLiK），这是一种通过跨模态信息补充来增强LLMs推理的新方法。该方法利用预训练的视觉-语言模型（VLMs）将图像特征对齐到文本描述中，生成图像特异性信息描述。此外，提出了跨模态相似性验证机制来量化语义一致性，有效过滤掉特征对齐过程中引入的噪声。即使没有手动标注的图像标题，经过优化的描述信息也可以独立地构建MMKG，无需手动标注，相比现有方法实现了存储效率的显著提升，同时保留了实体到图像的直接链接能力。
### Conclusion
在多模态推理任务上的实验结果表明，使用VaLiK增强的LLMs优于之前的模型。我们的代码可以从以下链接获取：[此链接](this https URL)。
## 172. `cs.AI` - 集成学习与优化在实时电力市场中拥堵管理和利润最大化的应用 [PDF](https://arxiv.org/pdf/2412.18003), [HTML](https://arxiv.org/abs/2412.18003)
### Authors
Imran Pervez,Ricardo Pinto Lima,Omar Knio
### Background
研究旨在通过开发新的集成学习与优化（ILO）方法解决电力调度（ED）和直流最优功率流（DCOPF）问题，以实现经济运营。ED中的优化问题将负荷作为未知参数，而DCOPF包含负荷和功率转移分布因子（PTDF）矩阵作为未知参数。PTDF表示由于两个区域之间的有功功率转移而在输电线路上产生的有功功率增量变化。这项工作侧重于使用ED和DCOPF优化模型解决实时电网中的拥堵管理和差额结算后的惩罚问题，以实现经济运行的改进。
### Innovation
开发了新颖的ILO方法以解决差额结算后的惩罚和线路拥堵问题，而不只关注负荷和PTDF的预测准确性。ILO方法能够实时捕捉电力市场的行为和线路拥堵，通过训练悔恨函数（regret function）来训练各个节点的未知负荷和线路PTDF矩阵，从而实现预先设定的目标，优于仅关注准确性但忽视经济运行优化的顺序学习和优化方法（SLO）。
### Conclusion
实验结果表明，ILO方法在减少电力市场中的差额结算惩罚和线路拥堵方面优于顺序学习和优化方法（SLO），在显著改善经济运行上表现出色。
## 173. `cs.AI` - PerceptionLM: 开放访问的数据和模型以实现详尽的视觉理解 [PDF](https://arxiv.org/pdf/2504.13180), [HTML](https://arxiv.org/abs/2504.13180)
### Authors
Jang Hyun Cho,Andrea Madotto,Effrosyni Mavroudi,Triantafyllos Afouras,Tushar Nagarajan,Muhammad Maaz,Yale Song,Tengyu Ma,Shuming Hu,Suyog Jain,Miguel Martin,Huiyu Wang,Hanoona Rasheed,Peize Sun,Po-Yao Huang,Daniel Bolya,Nikhila Ravi,Shashank Jain,Tammy Stark,Shane Moon,Babak Damavandi,Vivian Lee,Andrew Westbury,Salman Khan,Philipp Krähenbühl,Piotr Dollár,Lorenzo Torresani,Kristen Grauman,Christoph Feichtenhofer
### Background
计算机视觉领域的研究依赖于视觉语言模型，但许多性能高的模型仍为封闭源代码，解决了它们的数据、设计和训练方法的不透明性。研究界通过从黑盒模型中提取知识进行标签训练，取得了良好的基准结果，但牺牲了科学上的进展。缺乏了解黑盒模型的具体设计及其数据来源的情况下，科学上的进展仍难以衡量。因此，该研究致力于构建一个透明的研究框架，使图像和视频理解的研究完全开放可复现。
### Innovation
该研究提出了一种感知语言模型（PLM），在开放且可复现的框架下进行训练，旨在提高图像和视频理解的透明度。研究分析了标准化训练管道，未使用从专有模型中提取的教学法进行训练，探讨了大规模合成数据以识别细节视频理解中的关键数据缺口。为了弥补这些差距，研究发布了280万个人工标注的细粒度视频问答对及时空定位的视频说明，引入了PLM-VideoBench，一个专注于评估视频理解任务（包括“什么”、“哪里”、“何时”和“如何”）能力的评估套件。研究提供了数据、训练方法、代码及模型，使所有工作都可以完全复现。
### Conclusion
该研究通过提供开放访问的数据和模型，促进了详细视觉理解领域的透明研究。这不仅有助于评估视频理解任务，还为未来的科学研究提供了新的数据和工具。
## 174. `cs.AI` - LagKV: KV 缓存中的滞后相关信息揭示哪些 token 是重要的 [PDF](https://arxiv.org/pdf/2504.04704), [HTML](https://arxiv.org/abs/2504.04704)
### Authors
Manlai Liang,JiaMing Zhang,Xiong Li,Jinlong Li
### Background
在大型语言模型长上下文推理中，关键值（KV）缓存的大小不断增加，这使得缓存的部署成本与任务准确度之间的平衡变得困难。为了解决这个问题，大多数先前的努力利用了注意力权重来清除非关键缓存 token，但这些方法需要对推理基础设施进行较大的修改，并产生显著的计算开销。基于大型语言模型是自回归模型这一事实，我们提出了LagKV，这是一种仅依赖于KV之间的直接比较进行KV压缩的新策略。这是一项完全不依赖注意力机制的方法，可以轻松集成到主流推理平台中，并且在压缩比方面能够提供与其它复杂KV压缩方法相当的性能。在RULER基准测试中，我们提出的方法在不同的压缩比下均优于SnapKV和StreamingLLM。特别是在64位密钥检索任务中，我们的方法在相同的压缩比下比基于注意力权重的方法$H_2O$优秀超过50%。我们的代码可以在以下链接访问：this https URL
### Innovation
提出了一种仅依赖KV之间直接比较的KV压缩策略LagKV，完全不依赖注意力机制，易于整合到主流推理平台中，且在RULER基准测试中优于其他复杂KV压缩方法，特别是64位密钥检索任务中比$H_2O$算法优秀超过50%。
### Conclusion
我们的LagKV方法在不需要显著修改推理基础设施和计算开销的情况下，通过直接比较KV实现KV压缩，与现有的复杂KV压缩方法相比，能够保持相当甚至更好的性能，尤其在密钥检索任务中表现更加出色。
## 175. `cs.AI` - 实用验证的可识别性理论将促进自监督学习的研究 [PDF](https://arxiv.org/pdf/2504.13101), [HTML](https://arxiv.org/abs/2504.13101)
### Authors
Patrik Reizinger,Randall Balestriero,David Klindt,Wieland Brendel
### Background
自监督学习（SSL）驱动了许多当前的人工智能系统。随着对该领域研究兴趣和投入的增加，SSL的设计空间不断扩展。尽管存在多种方法和工程方法，Ptolemaic观点仍认为所有表示最终都会收敛到同一理想的Ptolemaic表示。然而，这种现象缺乏精确的理论解释。
### Innovation
通过综合识别理论（IT）的证据，我们展示了Ptolemaic假说（PRH）如何在SSL中发生。然而，当前的IT无法解释SSL的实际成功。为了缩小理论和实践之间的差距，我们提出了扩展IT为单一识别性理论（SITh），这是一个更广泛的理论框架，涵盖了整个SSL管道。SITh将使我们更深入地理解SSL中的隐式数据假设，并推动该领域向更可解释和通用的表示学习迈进。提出了未来研究的三个关键方向：训练动态和SSL的收敛性质；有限样本、批量大小和数据多样性的影响；以及架构、扩充、初始化方案和优化器中的归纳偏差的作用。
### Conclusion
通过提出单一识别性理论（SITh），我们希望能够加速自监督学习的研究，使之向更可解释和具有通用性的表示学习迈进。
## 176. `cs.AI` - Pulse-PPG: 一种跨实验室和现场应用的开源现场训练PPG基础模型 [PDF](https://arxiv.org/pdf/2502.01108), [HTML](https://arxiv.org/abs/2502.01108)
### Authors
Mithun Saha,Maxwell A. Xu,Wanting Mao,Sameer Neupane,James M. Rehg,Santosh Kumar
### Background
生理信号监测中广泛使用光电体积描记图（PPG），这使得基于PPG的基础模型得到广泛关注。已有的PPG基础模型要么基于临床数据且是开源的，要么是闭源的，限制了其在真实世界中的应用。
### Innovation
提出了一种名为Pulse-PPG的新型开放源PPG基础模型，该模型仅基于在为期100天的实地研究中收集的120名参与者的数据进行训练。Pulse-PPG显著优于基于临床数据训练的尖端基础模型的性能，特别是在模拟和移动健康应用中表现出更好的泛化能力。预训练于现场数据优于预训练于临床数据的效果，进一步强调了使用真实世界、多样化数据集的重要性。
### Conclusion
Pulse-PPG作为一种基于现场数据训练的开放源PPG基础模型，为研究人员提供了开发更具有泛化能力的PPG模型的有力资源，旨在促进在真实世界场景中稳健的PPG基础模型的发展。
## 177. `cs.AI` - Trigger without Trace：针对文本到图像扩散模型的隐蔽后门攻击 [PDF](https://arxiv.org/pdf/2503.17724), [HTML](https://arxiv.org/abs/2503.17724)
### Authors
Jie Zhang,Zhongqi Wang,Shiguang Shan,Xilin Chen
### Background
近年来，针对文本到图像扩散模型的后门攻击迅速发展。当前的后门样本通常与良性样本相比表现出两个关键异常：1）语义一致，即后门提示即使与提示存在显著的文本差异，也会生成具有相似语义内容的图像；2）注意力一致，触发器会在跨注意力图中引起一致的结构响应。这些一致性为防御者留下了可检测的痕迹，使得后门更容易被识别。
### Innovation
为实现隐蔽的后门样本，本文提出了一种名为Trigger without Trace (TwT)的方法，通过明确抑制这些一致性来实现。具体来说，该方法利用句法结构作为后门触发器，以增强对文本变异的敏感性，从而破坏语义一致性。此外，还提出了一种基于核最大均值离散度(KMMD)的正则化方法，以此对齐后门样本和良性样本的跨注意力响应分布，从而破坏注意力一致性。实验结果表明，该方法在不低于97.5%的攻击成功率的同时，具有更强的防御机制抵抗能力。
### Conclusion
本文方法在三个最先进的检测机制中平均绕过多达98%的后门样本，揭示了当前后门防御方法的缺陷。同时，该代码在提供的网址处公开可用。
## 178. `cs.AI` - Vision Transformers in Precision Agriculture: A Comprehensive Survey [PDF](https://arxiv.org/pdf/2504.21706), [HTML](https://arxiv.org/abs/2504.21706)
### Authors
Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei
### Background
检测植物疾病是现代农业中的一个重要方面，因为它对于维持作物健康和增加产量至关重要。传统的检测方法虽然仍然有价值，但往往依赖于人工检查或传统的机器学习技术，这在可扩展性和准确性上都存在局限。最近，视觉变换器（ViTs）作为一种有前景的替代方案出现，提供了诸如更好的远距离依赖性处理和更好的可扩展性等优势。本文综述了ViTs在精准农业中的应用，涵盖了各种任务，并详细介绍了ViTs的基本架构及其从自然语言处理（NLP）到计算机视觉的应用转移。此外，还讨论了传统模型如卷积神经网络（CNNs）的归纳偏差，并解释了ViTs如何减轻这些偏差。
### Innovation
视觉变换器（ViTs）提供了一种处理远距离依赖性和提高可扩展性的新方法。本文对ViTs在精准农业中的应用进行了全面的综述，包括最近的研究文献、关键方法、数据集和性能指标。此外，还进行了CNNs和ViTs的比较分析，以及混合模型和性能改进的综述。研究讨论了数据需求、计算需求和模型解释性等技术挑战，并提出了可能的解决方案。最后，提出了进一步研究方向和技术进步，以支持ViTs在未来实际农业环境中的应用。
### Conclusion
本文旨在为从业者和研究人员提供深度理解，展示ViTs如何在精准农业中发挥重要作用，并有望改变智能和精准农业。
## 179. `cs.AI` - 在线住房市场 [PDF](https://arxiv.org/pdf/2501.15916), [HTML](https://arxiv.org/abs/2501.15916)
### Authors
Julien Lesca
### Background
该论文研究了经典的住房市场问题的一个在线变体，每个代理拥有一个房间并根据其偏好寻求与另一个房间交换。在这个在线环境中，代理可以在任何时间到达或离开，这意味着并非所有代理都会同时出现在住房市场上。
### Innovation
作者将广为人知的序列独裁和 Gale 最佳交易循环机制扩展到了在线场景，以维持这些机制的优势特性如帕累托效率、个体理性以及策略证明性。此外，机制设计也旨在防止代理通过延迟到达或提前离开来进行策略性行为。
### Conclusion
论文证明了同时实现所有这些属性在在线环境中是不可能的，并提出了几种能够实现这些属性不同子集的变体。
## 180. `cs.AI` - 基于结果的在线强化学习：算法与基本限制 [PDF](https://arxiv.org/pdf/2505.20268), [HTML](https://arxiv.org/abs/2505.20268)
### Authors
Fan Chen,Zeyu Jia,Alexander Rakhlin,Tengyang Xie
### Background
在强化学习中，基于结果的反馈路径终点才观察到回报，这提出了如何公正地将信用分配给正确动作的挑战。该论文致力于在线强化学习中使用一般函数逼近的第一个全面分析，特别是在大型或无限状态空间中超越表格方法的问题。结果还界定了基于结果反馈与步骤反馈在统计上的分离情况，发现了某些MDPs中的不可避免的指数分离。该研究提供了一种证明样本效率的算法，在算法复杂性和状态空间规模上有重要的理论意义和应用价值。
### Innovation
提出了第一个在线强化学习中基于结果反馈的全面分析方法，设计了一种证明样本效率的算法，采用了通用函数逼近方法，适用于大型或无限状态空间。该研究还界定了基于结果反馈与步骤反馈的统计分离情况，揭示了某些MDPs中的不可避免的指数分离，同时揭示了如何在确定性的MDPs中消除完备性假设，简化了算法，也扩展了对于偏好反馈设置中的等价统计效率证明，展示了即使在有限的信息下也能实现等效的统计效率。
### Conclusion
该研究构建了理解基于结果的强化学习的统计性质的理论基础，证明了基于结果的反馈在统计效率上与基于步骤的反馈是等效的，特别是在大型或无限状态空间中。这项研究对在线强化学习算法设计和理论分析具有重要影响。
## 181. `cs.AI` - 超越低秩分解：一种高效的设备边缘学习捷径方法 [PDF](https://arxiv.org/pdf/2505.05086), [HTML](https://arxiv.org/abs/2505.05086)
### Authors
Le-Trung Nguyen,Ael Quelennec,Van-Tam Nguyen,Enzo Tartaglione
### Background
设备端学习因其潜力在减少设备-服务器通信延迟和保护隐私方面展现出了前景，同时还能改善能源效率。尽管这些优势明显，但在实际部署中设备端学习仍然受到显著的内存和计算能力限制的挑战。
### Innovation
本文提出了一个新的捷径方法，作为低秩分解方法的替代方案，旨在解决设备端学习中的激活内存瓶颈问题。实验表明，该方法能够大幅度减少激活内存消耗，最多可减少至至vanilla训练的120.09倍，并且可以降低整体计算量1.86倍，这主要通过在传统基准测试上进行评估得到了验证。
### Conclusion
研究结果证明，所提出的捷径方法可以有效减少设备端学习中的内存和计算负担，是实现高效设备端学习的一种有潜力的新途径。
## 182. `cs.AI` - LLM-D12: 大型语言模型依赖的双重维度量表 [PDF](https://arxiv.org/pdf/2506.06874), [HTML](https://arxiv.org/abs/2506.06874)
### Authors
Ala Yankouskaya,Areej B. Babiker,Syeda W. F. Rizvi,Sameha Alshakhsi,Magnus Liebherr,Raian Ali
### Background
近年来，人们对人们如何与大型语言模型（LLMs）互动以及这些模型是否会引发依赖甚至成瘾行为产生了浓厚兴趣。然而，可用于评估个人是否对LLMs产生依赖的有效工具相对稀缺，并且主要基于经典的行为成瘾症状，在LLMs使用背景下进行了调整。作者认为这是一种概念上的局限性，因为LLM-人类关系更加复杂，需要一个崭新的视角。为了填补这一空白，他们开发并验证了一个新的人工智能依赖性量表（LLM-D12），旨在更准确地衡量这些依赖形式。该量表基于作者早期的理论工作，通过向英国526名参与者收集数据，并通过探索性和验证性因子分析支持了其结构模型。
### Innovation
作者团队开发了一种新的12项问卷（LLM-D12），并建立了基于工具依赖性和关系依赖性的双重结构模型，以更全面地评估人们对LLMs的依赖情况。该量表突破了现有工具只依赖于经典行为成瘾症状的局限性。通过探索性和验证性因子分析，研究证明了新量表在概念基础和区分力上的有效性，同时也提供了理论依据来解释依赖LLMs不一定意味着功能障碍，而可能只是在某些情况下可能变得有问题的依赖性水平。
### Conclusion
研究人员开发并验证了LLM-D12量表作为一种新的工具来衡量对LLMs的依赖性，该量表显示出良好的内部一致性和清晰的区分有效性，进一步验证了这个新兴的观点，即对LLMs的依赖并不一定表示功能障碍，而可能取决于在特定情境下的依赖水平。
## 183. `cs.AI` - PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models [PDF](https://arxiv.org/pdf/2506.03170), [HTML](https://arxiv.org/abs/2506.03170)
### Authors
Murthy L,Subarna Tripathi
### Background
文本转图像生成模型存在被恶意使用的风险，尤其是由于这些模型的开源开发。因此，使用神经指纹技术来减轻这种风险已成为一种常见的策略。尽管有很多研究表明如何提高神经指纹的准确性，但至今仍没有方法能实现100%的准确率。然而，任何实际部署的模型都必须达到非常高的准确性，任何低于完美的准确率都是不可行的。
### Innovation
本文提出了一种基于循环纠错码概念的精准方法，用于将神经指纹嵌入文本转图像扩散模型中。这种创新方法旨在解决现有方法在准确性和生成质量之间的权衡问题，并且提出了一个实际可行的解决方案。
### Conclusion
本文通过引入基于循环纠错码的神经指纹方法，提出了一种准确且实用的解决方案来对抗文本转图像生成模型的安全威胁。这种方法展示了在保留模型生成质量的同时，提升识别的准确性，这为未来相关领域的模型安全性研究奠定了基础。
## 184. `cs.AI` - SyncMapV2: 具有鲁棒性和适应性的无监督分割 [PDF](https://arxiv.org/pdf/2506.16297), [HTML](https://arxiv.org/abs/2506.16297)
### Authors
Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas
### Background
人类视觉在无需显式训练的情况下能够有效地分割视觉线索，并且在噪声增加等情况下仍然保持极大的鲁棒性。相比之下，现有的AI算法在同样条件下难以维持准确性。现有的无监督分割方法在面对不同类型的数据破坏（如噪声、天气、模糊）时表现不佳。
### Innovation
SyncMapV2 是第一个在无监督分割中展现出卓越鲁棒性的方法，即使在数字破坏的情况下，mIoU 仅下降 0.01%。SyncMapV2 使用自组织动力学方程结合随机网络的概念，无需任何鲁棒训练、监督或损失函数。更重要的是，SyncMapV2 是在线适应的，模仿了人类视觉的连续适应性，无需重新初始化，提供了实时适应输入的功能。
### Conclusion
SyncMapV2 在适应性测试中表现出几乎零的性能降级，促进了能够实时适应输入的新型鲁棒和自适应智能的发展。
## 185. `cs.AI` - 将机器学习解决方案集成到物联网健康平台中的心脏衰竭风险分层方案 [PDF](https://arxiv.org/pdf/2505.09619), [HTML](https://arxiv.org/abs/2505.09619)
### Authors
Aiman Faiz,Anna Maria De Roberto,Claudio Pascarelli,Gianvito Mitrano,Gianluca Fimiani,Marina Garofano,Genoveffa Tortora,Mariangela Lazoi,Claudio Passino,Alessia Bramanti
### Background
慢性心力衰竭（HF）的管理在现代医疗保健中构成了重要挑战，需要持续监测、早期检测病情恶化，并制定个性化治疗策略。
### Innovation
提出了一种基于机器学习技术的预测模型，采用集成学习方法，这是一种修改过的堆叠技术，结合了两个专门模型的临床和超声心动图特征预测，再通过元模型将这两个模型的预测结果结合起来。
### Conclusion
初步研究结果显示该模型在识别HF高风险患者方面表现出色，高灵敏度达到95%，准确率为84%，尽管相对于一些机器学习环境来说偏低，但在重点关注识别HF高风险患者以参加PrediHealth研究项目的远程监测计划方面仍被认为是可接受的。研究还表明，机器学习基于的风险分层模型可以作为有价值的决策支持工具，不仅适用于PrediHealth项目，也可以辅助医疗专业人员进行早期干预和个性化患者管理。
## 186. `cs.AI` - 为什么时间序列特征归因中的分类依赖性评估效应会发生？一项合成数据调查 [PDF](https://arxiv.org/pdf/2506.11790), [HTML](https://arxiv.org/abs/2506.11790)
### Authors
Gregor Baer,Isel Grau,Chao Zhang,Pieter Van Gorp
### Background
在可解释人工智能（XAI）领域，评价特征归因方法是一项关键挑战。研究人员通常依赖扰动基础度量来评估特征归因，特别是在没有真实情境的情况下。然而，最近的研究揭示了这些评价度量在同一个数据集的不同预测类别间的性能表现会有所不同。这些‘分类依赖性的评估效应’引发了对扰动分析是否可靠测量归因质量的质疑，这对XAI方法的发展和评估可信度产生了直接影响。研究人员在简单的时序特征情况下，通过合成时间序列数据进行控制实验，系统地变化特征类型和类别对比，然后将基于扰动的降级得分与基于真实情况的精确召回度量进行比较。实验结果表明，即使在仅具有局部时序特征的简单场景中，基于扰动和基于真实情况的评价方法在不同类别之间也会产生矛盾的归因质量评估结果，两者之间的相关性较弱。这些发现表明，研究人员应谨慎解释基于扰动的度量，因为它们不一定总是与归因是否正确识别特征相关。通过展示这种脱节，这项工作为重新考虑归因评估实际测量的内容以及开发更严格的多维度评估方法指明了方向。
### Innovation
通过合成时间序列数据进行控制实验，系统地研究特征类型和类别对比的变化对不同归因方法的影响。展示了基于扰动和基于真实情况的评价方法在不同类别之间的归因质量存在矛盾评估，提示了需要重新评估归因评价的实际含义并开发更严格的评价方法。
### Conclusion
这项研究揭示了基于扰动的度量和基于真实情况的度量在不同类别之间存在矛盾的归因质量评价结果，并指出基于扰动的度量不一定总是与归因是否正确识别特征相关。研究强调了重新评估归因评价的实际含义，并呼吁开发能够捕捉多维度归因质量的更严格的评价方法。
## 187. `cs.AI` - 大型语言模型中理解的机械指标 [PDF](https://arxiv.org/pdf/2507.08017), [HTML](https://arxiv.org/abs/2507.08017)
### Authors
Pierre Beckmann,Matthieu Queloz
### Background
最近关于理解和解释大型语言模型（LLMs）内在机制的研究发现了它们不仅依赖于表面统计数据，还具有内部结构，这些结构能够形成概念上的联系。本文总结了这些发现，并结合它们提出了一种新的理论框架来理解机器的理解方式。这一理论引入了三种层次的理解水平：概念理解、反映现实世界的理解以及基于原理的理解，但这些理解方式与人类理解仍有显著差异，尤其是体现为并行机制的现象。
### Innovation
本文提出了一种新的理论框架，将大型语言模型的内部结构与理解联系起来，并通过概念理解、反映世界理解以及基于原理的理解三个层次进行具体阐释。此外，还指出了机器理解与人类理解之间的差异，特别是通过“并行机制”的现象来讨论这一差异。
### Conclusion
研究不应仅局限于LLMs是否具备理解能力的问题上，而应深入探讨其“奇异”思维如何运作，并构建符合它们的新观点。
## 188. `cs.AI` - 当大规模视觉语言模型遇到大规模遥感图像时：自上而下的文本引导式token裁剪 [PDF](https://arxiv.org/pdf/2503.07588), [HTML](https://arxiv.org/abs/2503.07588)
### Authors
Junwei Luo,Yingying Zhang,Xue Yang,Kang Wu,Qi Zhu,Lei Liang,Jingdong Chen,Yansheng Li
### Background
在处理大规模遥感图像（RSIs）的视觉和语言理解方面，当前的大规模视觉语言模型（LVLMs）通常使用有限的预定义网格来处理图像，这可能导致在处理巨像素的RSIs时信息丢失。相反，使用无限制的网格会大幅增加计算成本。因此，需要一种方法既能够保留图像细节又能够减少计算复杂性。
### Innovation
提出了一种结合动态图像金字塔（DIP）的自上而下的文本引导式token裁剪方法。该方法包括两个模块：（i）区域聚焦模块（RFM），用于利用文本意识地区域定位能力来识别关键的视觉token，以及（ii）基于DIP的粗到细的图像块选择和视觉token裁剪策略，该策略由RFM输出引导，避免直接处理整个大型图象。此外，现有的评估LVLMs对大规模RSI感知能力的基准面临着问题多样性有限和图像尺寸受限的问题，因此构建了一个新的基准LRS-VQA，包含7,333个问答对，分布在8个类别中，图像长度高达27,328像素。
### Conclusion
该方法在四个数据集上优于现有的高分辨率策略，并且在高分辨率设置下比现有的token减少方法更高效。实验数据和代码可在给定的链接中找到。
## 189. `cs.AI` - 扩散和分散：带有表示正则化的图像生成 [PDF](https://arxiv.org/pdf/2506.09027), [HTML](https://arxiv.org/abs/2506.09027)
### Authors
Runqian Wang,Kaiming He
### Background
过去十年中，基于扩散的生成模型的发展主要与表示学习的进步无关。这些扩散模型通常依赖于基于回归的目标函数，普遍缺乏明确的正则化。
### Innovation
我们提出了简单易用的分散损失（Dispersive Loss），这是一种有效的正则化器，可以改进基于扩散的生成模型。它鼓励隐藏空间中的内部表示分散，类似于对比性的自我监督学习，但无需正样本对，因此不会干扰用于回归的采样过程。这种方法与最近的方法表示对齐（REPA）相比，是自包含和极简的，不需要预训练、额外参数和外部数据。
### Conclusion
我们在ImageNet数据集上对多种模型进行了Dispersive Loss的评估，并报告了一致地优于广泛使用的强基线模型的改进。我们希望我们的工作能够弥合生成建模与表示学习之间的差距。
## 190. `cs.AI` - LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs [PDF](https://arxiv.org/pdf/2506.15690), [HTML](https://arxiv.org/abs/2506.15690)
### Authors
Tianyu Wang,Akira Horiguchi,Lingyou Pang,Carey E. Priebe
### Background
随着公共互联网合成数据的使用增加，大型语言模型（LLM）的训练数据使用效率得到了提升。然而，模型崩溃的潜在威胁尚未得到充分研究。现有研究主要关注单个模型中模型崩溃的情况，或者仅仅依赖于统计替代方法。
### Innovation
本文引入了一种高效框架LWD（LLM Web Dynamics），用于在网络层面研究模型崩溃。该框架通过使用检索增强生成（RAG）数据库模拟互联网，分析模型输出的收敛模式，并通过将交互的高斯混合模型与之进行类比，提供理论上的收敛保证。
### Conclusion
本文通过提出LWD框架在互联网层面研究LLM的模型崩溃问题，模拟互联网来分析模型输出的收敛模式，并提供了理论上的收敛保证，扩展了对模型崩溃的理解。
## 191. `cs.AI` - MambaNeXt-YOLO: 一种用于实时时目标检测的混合状态空间模型 [PDF](https://arxiv.org/pdf/2506.03654), [HTML](https://arxiv.org/abs/2506.03654)
### Authors
Xiaochun Lei,Siqi Wu,Weilin Wu,Zetao Jiang
### Background
实时时目标检测是计算机视觉中的基本但具有挑战性任务，尤其是在计算资源有限的情况下。尽管YOLO系列模型通过平衡速度与精度设定了标准，但随着对更丰富全局上下文建模的需求增加，Transformer架构被广泛采用。然而，由于其自注意力机制，Transformer具有较高的计算复杂度，限制了其在实时时和边缘部署中的实用性。
### Innovation
提出了MambaNeXt-YOLO，一种新型的目标检测框架，通过三个关键贡献来平衡准确性和效率：1. MambaNeXt模块：结合CNN与Mamba以有效捕获局部特征和长距离依赖性；2. 多分支非对称融合金字塔网络（MAFPN）：一种增强的特征金字塔架构，用于改进各种物体大小下的多尺度目标检测；3. 边缘优化的效率：该方法在PASCAL VOC数据集上实现了66.6% mAP和31.9 FPS，且无需预训练，支持部署在NVIDIA Jetson Xavier NX和Orin NX等边缘设备上。
### Conclusion
通过利用线性状态空间模型Mamba的优势，MambaNeXt-YOLO在保持实时光效的同时，提供了更高的检测准确性，并且能够适用于边缘设备部署。
## 192. `cs.AI` - 大语言模型基于的论点分类综合研究：从LLAMA到GPT-4o再到Deepseek-R1 [PDF](https://arxiv.org/pdf/2507.08621), [HTML](https://arxiv.org/abs/2507.08621)
### Authors
Marcin Pietroń,Rafał Olszowski,Jakub Gomułka,Filip Gampel,Andrzej Tomski
### Background
论点挖掘（AM）是跨学科研究领域，结合了逻辑学、哲学、语言学、修辞学、法律学、心理学和计算机科学的视角。它涉及自动识别和提取论点组件，如前提和声明，并检测它们之间的关系，如支持、反驳或中立。近年来，随着大型语言模型（LLMs）的发展，这种分析和提取逻辑更加高效。尽管有许多基准测试来验证LLMs的质量，但这些模型在公开可用的论点分类数据库上的操作效率仍缺乏研究。本研究通过使用多样化的数据集（如这个链接和UKP）对多种LLMs（包括GPT、Llama和DeepSeek版本及其基于Chain-of-Thoughts算法的推理增强版本）进行测试，探讨了这一问题。
### Innovation
研究引入了对多种大语言模型（包括Llama、GPT、DeepSeek及其推理增强版本）在论点分类中的全面分析，特别是通过不同的数据集（如这个链接和UKP）进行了广泛测试。此外，研究指出了一些已知提示算法在论点分析中的薄弱环节，并提出改进方向。研究成果是首次对这些数据集进行全面的大语言模型和提示算法分析。
### Conclusion
研究结果表明，ChatGPT-4在论点分类基准中表现最佳，而集成推理能力的Deepseek-R1在处理具有推理能力的模型时表现突出。然而，尽管这些模型表现出色，但仍存在错误。研究深入分析了所有模型的常见错误，并讨论了工作带来的增加价值，即对可用的论点数据集进行了深入分析，并展示了它们的局限性。
## 193. `cs.AI` - 任务先验：通过考虑所有下游任务的空间来增强模型评估 [PDF](https://arxiv.org/pdf/2507.09871), [HTML](https://arxiv.org/abs/2507.09871)
### Authors
Niket Patel,Randall Balestriero
### Background
当前的人工智能研究，尤其是自监督学习（SSL），旨在创建可以成功解决任何可能任务的系统。然而，目前研究人员可用的评估方法通常依赖于固定的手动挑选的下游基准集，使研究人员需要花费大量精力来设计和寻找可以代表研究目标的大量评估任务。我们认为，这种严格的评估协议在人工智能研究中形成了一种隐性的瓶颈。
### Innovation
该框架是第一个提供关键问题答案的框架，如（i）我的模型在所有可能的下游任务上的加权平均性能是多少？（ii）在定义的任务先验下，我的模型在所有下游任务上的性能变化性是多少？此外，我们相信任务先验将加速自监督学习中的研究进度，因为这是研究人员可以访问的唯一定性信号。
### Conclusion
通过提出任务先验的概念，该研究为下游任务空间中的所有可能任务提供了评估方法，从而提供了一种新的标准来衡量模型性能，并有望加速自监督学习的进展。
## 194. `cs.AI` - 深度学习在几何问题求解中的研究综述 [PDF](https://arxiv.org/pdf/2507.11936), [HTML](https://arxiv.org/abs/2507.11936)
### Authors
Jianzhe Ma,Wenxuan Wang,Qin Jin
### Background
几何问题求解是数学推理的关键领域，广泛应用于教育、人工智能的数学能力评估和多模态能力评估等多个重要领域。近年来，深度学习技术的快速发展，特别是多模态大语言模型的崛起，引起了广泛关注和研究兴趣。
### Innovation
本研究提供了深度学习在几何问题求解中的应用综述，包括对相关任务的全面总结、深度学习方法的详细审查、评估指标和方法的详细分析，以及对当前挑战和未来研究方向的批判性讨论。旨在为几何问题求解提供一个全面且实用的参考，促进该领域的发展。
### Conclusion
本研究致力于建立一个关于深度学习在几何问题求解中的持续更新的论文列表，以推动该领域的进一步发展。
## 195. `cs.AI` - Inversion-DPO: 高精度高效扩散模型后训练方法 [PDF](https://arxiv.org/pdf/2507.11554), [HTML](https://arxiv.org/abs/2507.11554)
### Authors
Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun
### Background
近年来，扩散模型（DMs）的进步依赖于通过后训练方法让模型更好地符合人类偏好。然而，现有的方法通常需要对基础模型和奖励模型进行计算密集型训练，这不但带来了显著的计算负担，还可能影响模型的准确性和训练效率。因此，本文探讨了一种新的后训练框架，通过引入DDIM倒置优化Direct Preference Optimization (DPO)，从而绕过了奖励模型建模的需求。这种方法通过不可行后采样和从胜利和失败样本到噪声的确定性倒置推导出一个新的后训练范式，极大地提升了训练的精度和效率，且无需辅助奖励模型或不准确的近似。我们应用于文本到图像生成和组合图像生成等任务，实验结果显示Inversion-DPO相比现有的后训练方法显著提高了性能，并展示了训练模型生成高质量组合一致性图像的能力。尤其是为组合图像生成任务创建了一个包含复杂结构注释和详细评分的配对数据集，以增强生成模型的组合能力。Inversion-DPO为扩散模型提供了高效、高精度对齐的新途径，使其适用于复杂的现实生成任务。
### Innovation
提出了一种创新的后训练框架Inversion-DPO，通过将DPO与DDIM倒置结合，绕过了传统的奖励模型建模，从而简化了后训练过程。该方法基于不可行后采样和胜利-失败样本到噪声的确定性倒置，提出了全新的后训练范式，提升了模型的精度和效率，同时确保了生成高质量和高一致性的图像。此外，Inversion-DPO还为组合图像生成创建了一个专门的数据集，以提高模型的组合能力。
### Conclusion
Inversion-DPO在各种生成任务中展现了其高效与精准的优势，显著提高了现有扩散模型的后训练性能，并扩大了其在复杂生成任务中的应用范围。将来的工作将致力于进一步优化Inversion-DPO的性能和适应不同场景的需求。
## 196. `cs.AI` - 频域动态注意调制以增强密集预测 [PDF](https://arxiv.org/pdf/2507.12006), [HTML](https://arxiv.org/abs/2507.12006)
### Authors
Linwei Chen,Lin Gu,Ying Fu
### Background
视觉变换器（ViTs）在计算机视觉中取得了显著进展，但在各种任务中表现出强劲性能。然而，ViTs中的注意力机制使得每一层都作为低通滤波器运行，现有的变压器架构中堆叠层的频率消失问题导致关键细节和纹理的丢失。
### Innovation
提出了一个基于电路理论的新颖策略，称为频域动态注意调制（FDAM），该策略可以直接调节ViTs的整体频域响应，包括注意力反转（AttInv）和频域动态缩放（FreqScale）两种技术。通过特征相似性分析和有效秩评估，展示了我们的方法避免了表示坍塌，从而在包括SegFormer、DeiT和MaskDINO等模型中实现了较为一致性的性能提升，并在语义分割、目标检测和实例分割等任务中表现出显著改进。此外，将该方法应用于遥感检测，在单尺度设置中取得了最先进的成果。
### Conclusion
通过实验证明，FDAM能够改善ViTs的整体频域响应，从而实现跨多个模型的性能提升，特别是在密集预测任务中，如语义分割、目标检测和实例分割，以及遥感检测中取得了最先进的结果。
## 197. `cs.AI` - 一种基于PBN-RL-XAI框架在黑色素瘤中发现'一击即走'治疗策略 [PDF](https://arxiv.org/pdf/2507.10136), [HTML](https://arxiv.org/abs/2507.10136)
### Authors
Zhonglin Liu
### Background
在治疗转移性黑色素瘤的过程中，先天对PD-1免疫疗法的抵抗是一个主要的临床挑战，目前人们对导致这种抵抗的分子网络的理解还比较有限。为了应对这一挑战，研究者使用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络模型，以阐明调节治疗反应的逻辑。通过结合强化学习代理和可解释的人工智能，研究者系统地发现了最佳的多步治疗方法。这种分析揭示了一个精准定时的、4步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）的策略是最有效的治疗方法。进一步的解释性分析表明，这种“一击即走”的干预措施能够抹去驱动这种抵抗的分子特征，从而使网络能够自我纠正，无需持续干预。
### Innovation
研究使用了一种新颖的计算框架，即PBN（概率布尔网络）-RL（强化学习）-XAI（可解释的人工智能），来发现黑色素瘤中有效的多步治疗方法。通过这种方法，研究揭示了一个4步抑制LOXL2的治疗策略，以及该干预如何能够消除导致抵抗的分子特征，使网络能够自我纠正而不需要持续干预。这为克服免疫疗法抵抗提供了一个新的时间依赖性治疗假设，并提供了一个强大的计算框架来识别复杂生物系统中意想不到的干预措施。
### Conclusion
本研究提出了一种新的时间依赖性方法，用于克服免疫疗法抵抗，并提供了一种强大的计算框架来识别复杂生物系统中的非显式干预计划。研究发现了一个4步骤暂时抑制LOXL2的干预策略，能够消除驱动抵抗的分子特征，使网络能够自我纠正，无需持续干预。这种基于PBN-RL-XAI框架的方法在治疗黑色素瘤的策略探索方面具有重要意义。
## 198. `cs.AI` - EEG 基础模型：当前进展与未来方向的批判性综述 [PDF](https://arxiv.org/pdf/2507.11783), [HTML](https://arxiv.org/abs/2507.11783)
### Authors
Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah
### Background
记录脑电波（EEG）的电活动模式在科学和临床研究中具有巨大价值。尽管监督式EEG编码器能够学习一些EEG模式，但由于依赖昂贵的信号注释和学习鲁棒模式能力不强，它们已经转向了一种通用的自我监督EEG编码器即EEG 基础模型（EEG-FMs），以实现稳健高效的EEG特征提取。然而，早期的EEG-FMs的实用性及其长期研究进展尚不明确，因此需要系统性地审阅和综合分析第一代EEG-FMs，从而理解当前的先进水平并确定未来工作方向。
### Innovation
研究系统地回顾了10种早期的EEG-FMs，提供了这些模型方法、实证发现和研究空白的批判性综合分析。发现大多数EEG-FMs采用了基于序列的建模方案，依赖于基于变压器的结构，并使用掩码序列的重建进行自我监督。但模型评估仍存在异质性，部分受限，这使得评估它们的实用性的实际应用场景具有困难。未来的研究应采用标准化和现实的评估方法，展示更为显著的可扩展效果，并在整个EEG表示学习流程中做出原理性和可信的选择。
### Conclusion
我们认为，通过与领域专家合作开发基准测试、软件工具、技术方法和应用可以进一步提高EEG-FMs的迁移适用性和现实世界采纳度。
## 199. `cs.AI` - SDSC:一种用于语义信号表示学习的结构感知度量 [PDF](https://arxiv.org/pdf/2507.14516), [HTML](https://arxiv.org/abs/2507.14516)
### Authors
Jeyoung Lee,Hochul Kang
### Background
大多数信号自监督学习（SSL）方法通常采用基于距离的目标，如均方误差（MSE），这些目标对振幅敏感，对波形极性不变且无边界缩放。这些特性阻碍了语义对齐并降低了可解释性。SDSC通过基于信号交义点的加号振幅衡量结构一致性来解决此问题，从而增强语义表示质量，提高自监督表示学习的稳定性和可解释性。
### Innovation
SDSC（信号骰子相似度系数）提出了一种结构感知度量函数，用于时间序列的自监督表示学习。SDSC基于Dice相似度系数（DSC）来量化时间信号的结构一致性，避免了传统基于距离的方法的诸多限制。此外，还提出了一种结合SDSC和MSE的混合损失函数，以提高模型的稳定性和在幅度保留上的灵活性。
### Conclusion
SDSC基于预训练的实验表明，与MSE相比，SDSC在领域内和低资源场景中能够实现相当或更好的性能。这些结果表明，结构保真度的信号表示能增强语义表示质量，支持结构感知度量作为传统基于距离方法的可行替代方案。
## 200. `cs.AI` - 心电图分析中的蒙版自编码器：揭示简单性偏差 [PDF](https://arxiv.org/pdf/2506.22495), [HTML](https://arxiv.org/abs/2506.22495)
### Authors
He-Yang Xu,Hongxiang Gao,Yuwen Li,Xiu-Shen Wei,Chengyu Liu
### Background
心电图（ECG）诊断的价值在于其动态特性，包括节奏波动和随时间和频率变化的细微波形变化。然而，监督学习的ECG模型往往过分拟合主要且重复的模式，而忽视了细微但临床上重要的线索。这种现象被称为简单性偏差（SB），即模型倾向于学习易于掌握的信号而非微妙但有用的信号。
### Innovation
本文首先通过实验证明了ECG分析中存在简单性偏差及其对诊断性能的负面影响，同时发现自监督学习（SSL）可以缓解这种偏差，为解决偏差提供了一个有希望的方向。基于SSL策略，本文提出了一种新方法：1）具备时间和频率感知的滤波器，用于捕获反映ECG信号动态特性的时空特征；2）在此基础上，采用多粒度原型重构，以在双域中实现粗略和精细的表示学习，进一步减轻简单性偏差。
### Conclusion
为了促进自监督学习在ECG分析中的应用，本文构建了一个大规模多站点ECG数据集，包含来自300多个临床中心的153万次记录。取三类下游任务和六组ECG数据集上的实验结果显示，该方法有效减轻了简单性偏差并达成了最先进的性能。代码和数据集将公开发布。
## 201. `cs.AI` - GCC-Spam: 利用生成对抗网络、对比学习和字符相似性网络进行垃圾短信检测 [PDF](https://arxiv.org/pdf/2507.14679), [HTML](https://arxiv.org/abs/2507.14679)
### Authors
Zhijie Wang,Zixin Xu,Zhiyuan Pan
### Background
互联网上垃圾文本（如垃圾短信）的指数级增长使得需要强大的检测机制来减轻信息泄露和社会不稳定等风险。这项工作主要应对的是骗子使用的对抗策略以及标签数据稀缺这两项挑战。
### Innovation
提出了一种新颖的垃圾文本检测框架GCC-Spam，包括三个核心创新：1. 字符相似性网络捕获拼写和音素特征，对抗字符混淆攻击，并生成句子嵌入；2. 对比学习通过优化垃圾短信和正常文本的潜在空间距离来提高可辨别性；3. 生成对抗网络生成现实的伪垃圾短信样本，减少数据稀缺的同时提升模型的鲁棒性和分类准确性。
### Conclusion
在真实数据集上的广泛实验表明，该模型在比基准方法显著更少的标记样本下实现了更高的检测率。
## 202. `cs.AI` - 长距离-短距离图神经网络及改进的 curriculum learning 用于对话中的情绪识别 [PDF](https://arxiv.org/pdf/2507.15205), [HTML](https://arxiv.org/abs/2507.15205)
### Authors
Xinran Li,Xiujuan Xu,Jiaqi Qiao
### Background
情绪识别在对话中是一个实用但具有挑战性的工作。现有的方法在区分长距离和短距离特征以及处理数据不平衡方面存在不足，亟需新的解决方法以提高情绪识别的准确性和效率。
### Innovation
提出了一种新型的多模态方法——长-短距离图神经网络（LSDGNN）。该方法基于有向无环图构建长距离和短距离的图神经网络，分别获取远距离和近距离陈述的多模态特征。为了确保长距离和短距离特征在表示上尽可能突出并互相影响，采用差分正则化（Differential Regularizer）和BiAffine模块来促进特征交互。此外，通过改进的Curriculum Learning（ICL）来应对数据不平衡问题。同时设计了“加权情感转移”度量和难度衡量器，实现优先学习容易样本的训练过程。
### Conclusion
在IEMOCAP和MELD数据集上的实验结果表明，该模型在情绪识别性能上优于现有的基准模型。
## 203. `cs.AI` - 多语言大语言模型并非多语言思考者：基于印地语类比评估的证据 [PDF](https://arxiv.org/pdf/2507.13238), [HTML](https://arxiv.org/abs/2507.13238)
### Authors
Ashray Gupta,Rohan Joseph,Sunny Rai
### Background
类比测试模型推断概念之间隐含关系的能力，是评估其推理能力的关键基准。虽然大规模语言模型（LLMs）在英语推理方面已被广泛评估，但对于它们在印地语中的能力研究却较少，这限制了我们对其语言间迁移理解的程度。现有研究面临的一个重要问题是在印地语中缺乏评估LLM推理能力的关键资源。
### Innovation
引入了一个新的印地语类比测试集（HATS），包含405个多选题，来源自印度政府考试。使用多种提示策略评估最先进的多语言LLMs，并引入了一种基于认知类比推理理论的扎根推理过程，这种方法提升了模型在解决印地语类比问题时的表现。实验结果显示，无论采用哪种提示策略，英文提示让模型表现最佳。
### Conclusion
测试集填补了印地语中评估LLM推理能力关键资源的空白，研究发现LLMs的推理表现与提示语言、以及使用何种提示策略密切相关，提示语言效果显著，提示策略的影响不大。
## 204. `cs.AI` - EndoControlMag: 一种结合周期参考重置与分层组织感知双模掩码控制的鲁棒内窥镜血管运动放大方法 [PDF](https://arxiv.org/pdf/2507.15292), [HTML](https://arxiv.org/abs/2507.15292)
### Authors
An Wang,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren
### Background
在内窥镜手术中，准确可视化细微血管运动对于提高手术精度和决策至关重要，但这一过程存在挑战，因为手术场景复杂且动态变化。现有的方法难以解决这个问题。因此，研究人员提出了EndoControlMag，这是一种无需训练、基于拉格朗日的方法，它针对内窥镜环境中的血管运动放大进行了独特设计。
### Innovation
EndoControlMag 采用了两项创新技术：一是周期性参考重置 (PRR) 方案，将视频分割为短且重叠的片段，并动态更新参考帧，以防止累积误差并保持时间连贯性；二是分层组织感知双模掩码控制（HTM）架构，该架构具有双模式掩码膨胀。此外，HTM首先使用预训练的视觉跟踪模型跟踪血管核心，以保持在遮挡和视角变化下的精确定位；然后根据观察到的组织位移或模拟生物力学衰减，应用两种适应性软化策略之一，实现对周围组织的放大软化处理。
### Conclusion
EndoControlMag 在对 EndoVMM24 数据集进行评估后，展示了在放大精度和视觉质量方面的显著优势，同时保持了在复杂手术条件下的鲁棒性。此方法已在多种不同的手术类型和挑战性场景中得到验证，并获得了定量指标、视觉评估和专家外科医生的积极评价。
## 205. `cs.AI` - 基于双噪声自适应调节的稳健相对姿态估计框架以确保安全接近机动 [PDF](https://arxiv.org/pdf/2507.16214), [HTML](https://arxiv.org/abs/2507.16214)
### Authors
Batu Candan,Simone Servadio
### Background
准确而稳健的相对姿态估算是实现如ESA的ENVISAT等翻滚废弃卫星的主动碎片清除（ADR）任务的关键。这种任务需要精确的导航和控制能力，特别是在接近和操纵翻滚卫星时。本文提出了一个完整的数据管道，结合先进的计算机视觉技术和自适应非线性滤波方法来应对这一挑战。
### Innovation
该研究的主要贡献在于集成的系统架构和UKF中的双自适应策略：对测量噪声协方差的动态调节能补偿CNN测量不确定性的变化，通过测量残差分析对过程噪声协方差的自适应调节能处理未建模的动力学或在线机动，从而增强了对测量缺陷和动力学不确定性的鲁棒性。
### Conclusion
通过使用真实的ENVISAT模型进行高保真模拟评估，该自适应集成系统在多种条件下的估计性能得到验证，包括测量中断情况。这种全面的方法为增强空间在轨相对导航提供了更稳健的解决方案，显著提升了安全接近机动所需的能力。
## 206. `cs.AI` - 在数据限制条件下，扩散模型优于自回归模型 [PDF](https://arxiv.org/pdf/2507.15857), [HTML](https://arxiv.org/abs/2507.15857)
### Authors
Mihir Prabhudesai,Menging Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak
### Background
自回归（AR）模型长期以来主导着大型语言模型的领域，推动了广泛任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，但它们相对于AR模型的优势尚未充分探索。
### Innovation
该研究系统地研究了在数据受限条件下（训练过程中需要多次访问有限的数据）的掩码扩散模型，并发现当计算资源丰富但数据稀缺时，扩散模型显著优于AR模型。扩散模型更有效地利用重复数据，实现了更低的验证损失和更好的下游性能。通过解释这种优势为隐式的数据增强，扩散模型展示了比AR模型更多的token排列和预测任务的多样性。此外，研究还发现扩散模型的新规模律，并推导出了扩散开始优于AR的计算阈值。
### Conclusion
当数据而非计算成为瓶颈时，扩散模型提供了一种标准AR范式的有吸引力替代方案。
## 207. `cs.AI` - 将RL扩展到长视频 [PDF](https://arxiv.org/pdf/2507.07966), [HTML](https://arxiv.org/abs/2507.07966)
### Authors
Yukang Chen,Wei Huang,Baifeng Shi,Qinghao Hu,Hanrong Ye,Ligeng Zhu,Zhijian Liu,Pavlo Molchanov,Jan Kautz,Xiaojuan Qi,Sifei Liu,Hongxu Yin,Yao Lu,Song Han
### Background
该论文讨论了在视觉语言模型（VLMs）中扩展推理以处理长时间视频的挑战。引入了一个大规模数据集LongVideo-Reason，用于在多样化的领域（如体育、游戏和视频记录）中进行训练。此外，还提出了一种组合了链式思维监督微调（CoT-SFT）和强化学习（RL）的双阶段训练框架，以及一个多模态强化序列并行训练（MR-SP）框架，用于处理长时间视频的强化学习训练。
### Innovation
该研究的主要创新在于提出了LongVideo-Reason数据集、双阶段训练框架（包括CoT-SFT和RL）以及MR-SP系统，特别针对处理长视频的强化学习训练。MR-SP系统实现了高达2.1倍的长期视频RL训练加速，并且该系统支持多种模态（视频、文本和音频）的强化学习训练。
### Conclusion
实验表明，LongVILA-R1-7B在视频基准测试中表现出色，分别在有和无字幕的情况下达到了65.0%和70.7%的准确率，并且在多个基准测试中始终优于LongVILA-R1。此外，随着输入视频帧数的增加，LongVILA-R1展现出持续的性能改进。研究团队还发布了支持各种模型（VILA和Qwen系列）以及图像和视频生成模型的训练系统，可以在单个A100节点上支持长达小时的视频的强化学习训练（例如，3,600帧 / 约256k标记）。
## 208. `cs.AI` - 全方位思考者：通过混合奖励的多任务强化学习扩展LLM跨域泛化 [PDF](https://arxiv.org/pdf/2507.14783), [HTML](https://arxiv.org/abs/2507.14783)
### Authors
Derek Li,Jiaming Zhou,Amirreza Kazemi,Qianyi Sun,Abbas Ghaddar,Mohammad Ali Alomrani,Liheng Ma,Yu Luo,Dong Li,Feng Wen,Jianye Hao,Mark Coates,Yingxue Zhang
### Background
通用人工智能的进步依赖于在广泛任务上表现出色的大语言模型（LLMs），这些模型在结构化推理和创造性生成任务上都有出色表现。然而，训练后的方法如监督微调（SFT）在泛化方面经常遇到困难，倾向于记忆而非可迁移的学习。
### Innovation
本文介绍了一种统一的强化学习（RL）框架Omni-Thinker，通过结合基于规则验证的奖励和生成性偏好信号来提高LLM在不同任务上的性能。Omni-Thinker通过LLM作为裁判的评估来增强性能，并通过任务排序策略引导训练过程。研究结果表明，从结构化到开放性任务的逐步排序有助于提高性能和减少遗忘问题。
### Conclusion
实验结果显示，通过任务排序学习（curriculum learning）的方法在四个领域中分别提高了5.2%和9.1%的性能，相较于联合训练和模型合并方法。这些结果强调了在RL基于的训练后对于通用语言模型进行可扩展性泛化的任务感知采样和混合监督的重要性。
## 209. `cs.AI` - OrQstrator：一种基于AI的高级量子电路优化框架 [PDF](https://arxiv.org/pdf/2507.09682), [HTML](https://arxiv.org/abs/2507.09682)
### Authors
Laura Baird,Armin Moin
### Background
在Noisy Intermediate-Scale Quantum (NISQ) 时代背景下，量子电路优化成为一个挑战性的问题，需要处理噪声、硬件限制以及多种优化策略的协调。现有方法如NISQ Analyzer可以在一定程度上解决这些问题，但仍然存在优化效果受限的问题。因此，需要一种新的框架来改进并协调不同的优化器，以适应硬件特性并达到更高的优化效果。
### Innovation
本文提出了一种新的模块化框架——OrQstrator，用于量子电路优化。该框架利用深度强化学习（DRL）协调三个互补的电路优化器：基于DRL的电路改写器、领域特定的优化器和参数化的电路实例化器。OrQstrator的核心是一个协调引擎，它可以根据电路结构、硬件限制和后端感知的性能特征来学习协作策略，最终输出一个硬件感知的优化电路。
### Conclusion
OrQstrator框架通过有机结合DRL、多种优化器和协调策略，实现了对量子电路的高级优化。相比于现有的方法，OrQstrator能够在保持电路效率的同时，更好的适应各种硬件后端的特性。
## 210. `cs.AI` - 无传感器力控制通过准确动力学模型实现快速双边远程操作及模仿学习 [PDF](https://arxiv.org/pdf/2507.06174), [HTML](https://arxiv.org/abs/2507.06174)
### Authors
Koki Yamane,Yunhan Li,Masashi Konosu,Koki Inami,Junji Oaki,Sho Sakaino,Toshiaki Tsuji
### Background
近年来，仿生学习技术的进步引发了对低成本操作臂进行遥操作以采集演示数据的兴趣增加。然而，现有的大多数系统依赖于单向控制，仅传输目标位置值，这虽然便于实施并适合缓慢的非接触操作，但在快速操作或接触丰富的任务中表现出局限性，因为缺乏力反馈。
### Innovation
本文展示了即使在缺乏力传感器的低成本操作臂上，通过利用4通道双边控制，也能实现快速带有力反馈的遥操作。基于准确识别的操作臂动力学，该方法整合了非线性补偿、速度和外部力估算以及与惯性变化相关的可变增益。
### Conclusion
通过4通道双边控制收集的数据表明，将力信息纳入训练策略的输入和输出可以提高模仿学习的表现。这些结果凸显了本文系统的实用性，证明了在成本合理的硬件上实现高度保真的远程操作和数据收集的有效性。
## 211. `cs.AI` - EarthLink: 一种自我进化的气候科学AI代理 [PDF](https://arxiv.org/pdf/2507.17311), [HTML](https://arxiv.org/abs/2507.17311)
### Authors
Zijie Guo,Jiong Wang,Xiaoyu Yue,Wangxu Wei,Zhe Jiang,Wanghan Xu,Ben Fei,Wenlong Zhang,Xinyu Gu,Lijing Cheng,Jing-Jia Luo,Chao Li,Yaqiang Wang,Tao Chen,Wanli Ouyang,Fenghua Ling,Lei Bai
### Background
现代地球科学正处于一个转折点。海量、碎片化且复杂的地球系统数据，加之日益复杂且精细的分析需求，形成了快速科学发现的重要瓶颈。
### Innovation
我们介绍了EarthLink，这是一种专为地球科学家设计的第一款AI伴飞员。它能自动化科研工作的各个环节，从规划到代码生成再到多场景分析。与静态诊断工具不同，EarthLink能够从用户交互中学习，并通过动态反馈循环不断改进其能力。该系统已经在气候变化等核心科学任务上得到了验证，包括模型-观测对比和复杂现象诊断。在多专家评估中，EarthLink展示了与人类初级研究员工作流某些方面相当的分析能力，并且其透明可审计的工作流程和自然语言界面使科学家能够从繁重的手动执行中转向战略监督和假设生成。
### Conclusion
EarthLink 标志着向高效、可信且协作的地球系统研究范式的关键一步，特别是在全球变化加速的背景下。系统可在我们网站上访问，链接为：this https URL
## 212. `cs.AI` - Swin-TUNA：一种用于准确食品图像分割的新PEFT方法 [PDF](https://arxiv.org/pdf/2507.17347), [HTML](https://arxiv.org/abs/2507.17347)
### Authors
Haotian Chen,Zhiyong Xiao
### Background
在食品图像处理领域，高效的语义分割技术对于工业应用至关重要。然而，现有的大规模Transformer基础模型（如FoodSAM）由于其庞大的参数量和高计算资源需求，在实际部署中面临挑战。
### Innovation
Swin-TUNA模块通过将多尺度可训练适配器集成到Swin Transformer架构中，实现高性能的食品图像分割，仅更新4%的参数。Swin-TUNA的核心创新在于其分层特征适应机制：设计深度和维度映射中可分离的卷积，以解决浅层与深层网络特征的差异，并结合任务无关和任务特定特征的动态平衡策略。
### Conclusion
实验结果显示，该方法分别在FoodSeg103和UECFoodPix Complete数据集上达到50.56%和74.94%的mIoU，性能超越了完全参数化的FoodSAM模型，同时参数量减少了98.7%（至8.13M），并且Swin-TUNA在低数据场景中具有更快的收敛速度和更强的泛化能力，提供了轻量级食品图像分割的有效解决方案。
## 213. `cs.AI` - PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving [PDF](https://arxiv.org/pdf/2507.17596), [HTML](https://arxiv.org/abs/2507.17596)
### Authors
Maciej K. Wozniak,Lianhang Liu,Yixi Cai,Patric Jensfelt
### Background
尽管端到端的自动驾驶模型显示出有希望的结果，但它们的实际部署经常受到模型体积大、依赖昂贵的LiDAR传感器以及计算密集型BEV特征表示的限制。这限制了其可扩展性，尤其是在仅配备摄像头的大众市场车辆中。
### Innovation
我们提出了一种新颖且高效的端到端驾驶架构PRIX（Plan from Raw Pixels），该架构仅使用摄像头数据，不需要显式的BEV表示，并且不需要LiDAR。PRIX利用视觉特征提取器和生成式规划头，可以直接从原始像素输入预测安全轨迹。我们的架构的核心组件是上下文感知重标定变换器（CaRT），这是一种旨在有效增强多级视觉特征以实现更鲁棒规划的新模块。
### Conclusion
通过全面的实验表明，PRIX在NavSim和nuScenes基准测试中达到了最先进的性能，其推理速度和模型大小显著更高效，使其成为实际部署中的实用解决方案。我们的工作是开源的，并且代码将会在这个网址处提供：this https URL。
## 214. `cs.AI` - 使用大型语言模型实现多机器人团队组成部分协调 [PDF](https://arxiv.org/pdf/2507.16068), [HTML](https://arxiv.org/abs/2507.16068)
### Authors
Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme
### Background
传统的机器人任务协调依赖于任务特定和专家驱动的流程，其中自然语言的任务描述需要由领域专家手动翻译成数学模型、算法设计和可执行代码。这一过程耗时、不适用于非专家群体，并且在任务要求改变时难以灵活应对。
### Innovation
提出了一种新型框架LAN2CB (Language to Collective Behavior)，利用大型语言模型自动化和泛化多机器人协调流程。通过两个核心模块，将自然语言的任务描述转换为可以执行的Python代码：任务分析模块解析任务描述成行为树，代码生成模块结合行为树和结构化的知识库生成机器人控制代码。还介绍了一个自然语言任务描述的数据集，用于支持系统开发和基准测试。
### Conclusion
实验结果表明，LAN2CB 使自然语言驱动的多机器人协调变得稳健且灵活，大大减少了人工工程工作并在多种任务类型中实现了广泛的泛化。
## 215. `cs.CL` - VeriMinder:缓解自然语言到SQL中的分析漏洞 [PDF](https://arxiv.org/pdf/2507.17896), [HTML](https://arxiv.org/abs/2507.17896)
### Authors
Shubham Mohole,Sainyam Galhotra
### Background
自然语言接口到数据库(NLIDB)的应用系统已经使数据分析更加普及。这一积极变化也带来了新的挑战，即如何帮助没有统计分析背景的用户消除分析中的偏见。尽管在文本到SQL生成准确性方面已经做了大量研究，但在分析性问题中的认知偏见方面仍然缺乏解决办法。
### Innovation
1. 提出了一种针对特定分析情境的语境语义映射框架，用于识别偏差。2. 构建了一个分析框架，强调易变性原则，并引导用户进行有系统的数据分析。3. 设计了一个优化后的LLM驱动系统，使用结构化流程和多候选人、批评反馈和自我反省生成高质量、任务特定的提示。
### Conclusion
用户测试表明，该方法有效，82.5%的参与者报告称该方法提高了分析质量。与替代方法相比，在抽象性、全面性和准确性等分析指标上，VeriMinder的表现显著更好，至少提高了20%。我们的系统以网络应用的形式提供，旨在帮助用户避免“错误问题”漏洞。我们的代码库及提示已在MIT许可下作为开源软件开源，以促进进一步的研究和社区的采用。
## 216. `cs.CL` - 一场Whisper就能评价它们全部 [PDF](https://arxiv.org/pdf/2507.17918), [HTML](https://arxiv.org/abs/2507.17918)
### Authors
Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo
### Background
本文提出了一个高效的端到端方法，用于多部分的第二语言测试的整体自动口语评估（ASA），该系统开发用于2025 Speak & Improve 挑战。背景在于，目前大部分的自动口语评估系统需要分别处理每个部分并且需要转录及多个模型来预测最终分数，这导致了较高的开销和较长的推理时间，不利于大规模计算机辅助语言学习系统的应用。因此，亟需一种既能降低开销又能在大规模系统中有效工作的解决方案。
### Innovation
本文的主要创新点在于，使用了一个单一的Whisper-small编码器来处理所有四部分的口语回答，通过一个轻量级的信息聚合器结合所有信息，并预测最终得分。这种方法省去了转录和不同部分模型的需求，减少了推理时间，并使得大规模计算机辅助语言学习系统的自动口语评估变得可行。此外，该系统使用不到1.68亿个参数（约占Whisper-small的70%），还在对比文本基线系统并且取得更好的成绩。此外，该研究提出了一种数据采样策略，证明了模型可以在使用44.8%的说话者数据的情况下，仍然取得0.383的均方根误差，显示出对不平衡类别有更好的表现和较强的样本效率。
### Conclusion
本文提出的系统通过使用单一Whisper-small编码器、轻量级聚合器以及高效的数据采样策略实现了一个高效的端到端自动口语评估系统。该系统不仅在小参数量下获得了良好的性能，还证明了在不平衡数据集上也能取得较好的效果，使得其在大规模计算机辅助语言学习系统中具有广泛应用的潜力。
## 217. `cs.CL` - LLM信念更新是否与贝叶斯定理一致？ [PDF](https://arxiv.org/pdf/2507.17951), [HTML](https://arxiv.org/abs/2507.17951)
### Authors
Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson
### Background
该研究探讨了大型语言模型在面对上下文证据时是否能够更一致地更新其“信念”，特别是检查它们是否遵循贝叶斯定理。研究团队开发了一个贝叶斯一致性系数（BCC）来量化这种一致性，并使用该系数衡量了多种预训练语言模型的表现，分析了模型参数量、训练数据量和常见基准测试得分等因素对BCC的影响。
### Innovation
研究引入了一个名为贝叶斯一致性系数（BCC）的新指标，用于量化语言模型在面对证据时更新信念的一致性，并据此评估不同规模和能力的语言模型的表现差异。
### Conclusion
研究结果表明，更大的预训练语言模型在面对证据时，其信念更新与贝叶斯定理的符合度更高，这为理解及规范大模型的使用提供了重要启示。
## 218. `cs.AI` - 无分段的发音质量 [PDF](https://arxiv.org/pdf/2507.16838), [HTML](https://arxiv.org/abs/2507.16838)
### Authors
Xinwei Cao,Zijian Fan,Torbjørn Svendsen,Giampiero Salvi
### Background
自动辅助语言学习（CALL）系统中的发音误检测和诊断（MDD）是一个重要组成部分。其中，发音素级别的发音评估对于帮助第二语言学习者提高其发音至关重要。然而，大多数系统依赖一种发音质量（GOP）评估方法，这种方法需要将语音预先分割成元音单元，这限制了这些方法的准确性和使用基于CTC的声学模型的可能性。
### Innovation
提出了自我对齐GOP（GOP-SA），使得使用CTC训练的ASR模型进行MDD成为可能。定义了一种更为通用的无对齐方法（GOP-AF），考虑了所有可能的目标音素对齐方式。给出了GOP-AF定义的理论说明，解决了潜在的数值问题，并进行了适当的归一化，使其可以与不同时间峰值的声学模型结合使用。通过在CMU Kids和Speechocean762数据集上的广泛实验结果，展示了所提出方法的不同定义之间的比较，估计了GOP-AF对声学模型峰值时间和目标音素上下文量的依赖性。并在Speechocean762数据集上与最近的研究进行了比较，显示了所提出方法提取的特征向量在发音素级别的发音评估中达到了最先进的结果。
### Conclusion
我们的方法和定义在发音素级别的发音评估上达到最先进的结果，特别是在处理Speechocean762数据集时。
## 219. `cs.AI` - 新型大语言模型瓶颈：从潜在注意力和混合专家架构视角看系统瓶颈 [PDF](https://arxiv.org/pdf/2507.15465), [HTML](https://arxiv.org/abs/2507.15465)
### Authors
Sungmin Yun,Seonyong Park,Hwayong Nam,Younjoo Lee,Gunjun Lee,Kwanhee Kyung,Sangpyo Kim,Nam Sung Kim,Jongmin Kim,Hyungyo Kim,Juhwan Cho,Seungmin Baek,Jung Ho Ahn
### Background
传统的Transformer模型计算负载分布明显，其中多头注意力（MHA）是内存受限的，计算强度低，而前馈层则是计算受限的。长期以来，这种差异促使研究开发专用硬件来缓解MHA的瓶颈。然而，最近的架构变化，如多头潜在注意力（MLA）和专家混合适配器（MoE），可能挑战了为注意力机制专门设计硬件的前提。
### Innovation
论文提出两点关键见解：1) MLA的计算强度比MHA高约两个数量级，使其接近现代加速器如GPU的计算受限区域。2) 通过将MoE专家分布在一组加速器中，并通过批量处理调节其计算强度，可以使其与密集层相匹配，从而实现更均衡的计算配置。
### Conclusion
这些发现表明，特定于注意力机制的专用硬件的需求正在减少。未来一代的Transformer关注点将从加速单一内存受限层转变为设计具有充足计算能力、内存容量、内存带宽和高带宽互连的平衡系统，以应对大规模模型的多样化需求。
## 220. `cs.AI` - Reality Proxy: 通过抽象表示在混合现实（MR）中与真实世界对象进行流畅互动 [PDF](https://arxiv.org/pdf/2507.17248), [HTML](https://arxiv.org/abs/2507.17248)
### Authors
Xiaoan Liu,Difan Jia,Xianhao Carton Liu,Mar Gonzalez-Franco,Chen Zhu-Tian
### Background
在混合现实（MR）中与拥挤、遥远或者部分遮挡的真实世界物体进行交互时常常面临困难，影响了直接选择和操作的便捷性。这些困难源于直接在物理对象上执行交互，输入紧耦合于物理约束。这种耦合限制了用户的交互方式。
### Innovation
我们提出通过引入代理——真实世界物体的抽象表示来解耦交互与物理约束。Realiry Proxy系统将选定目标无缝地从物理对象转移到其代理上。该系统利用AI技术为代理添加语义属性和层次空间关系，不仅支持基本的选择，还使得skimming、基于属性的过滤、嵌套群组导航和复杂的多对象选择成为可能，而无需新的手势或菜单系统。
### Conclusion
实验证明，Reality Proxy系统在不同场景下表现出色，包括办公室信息检索、大规模空间导航和多无人机控制。专家评估显示，系统具有实用性和易用性，基于代理的抽象为未来MR系统提供了强大的且可扩展的交互模式。
## 221. `cs.CL` - TeleChat2、TeleChat2.5和T1的技术报告 [PDF](https://arxiv.org/pdf/2507.18013), [HTML](https://arxiv.org/abs/2507.18013)
### Authors
Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li
### Background
介绍了最新的TeleChat系列模型：TeleChat2、TeleChat2.5和T1，这些模型是对前代TeleChat的显著升级。尽管在模型架构上仅进行了少量修改，但通过在预训练和后训练阶段优化训练策略，新系列模型取得了显著的性能提升。这些创新包括新系列模型的多重训练策略和新功能的加入，如监督微调（SFT）、直接偏好优化（DPO）、连续预训练、领域特定数据集和强化学习（RL），这些旨在提升特定任务如代码生成和数学推理的表现力。
### Innovation
TeleChat2：采用10万亿高质量且多样化的令牌进行预训练；TeleChat2.5和T1：引入持续预训练和强化学习，这一阶段结合了领域特定数据集以优化代码生成和数学推理任务；T1：专注于复杂推理，支持较长的链式思维推理，并在数学和编码方面表现出显著改进；T2.5：侧重于提高速度，实现快速推理；TeleChat2和T1的两个旗舰模型均为115B参数的密集式变压器架构，显著提升了推理和通用任务性能，优于某些私有模型如OpenAI的o1-mini和GPT-4o。
### Conclusion
这些模型对开发者和研究人员来说是将最先进的语言模型应用于各种应用场景的强大工具，并且已公开提供状态最前沿的后训练版本，包括参数为35B和115B的版本。
## 222. `cs.CL` - GrAInS：LLMs和VLMs在推理时间 steering 的基于梯度的归因 [PDF](https://arxiv.org/pdf/2507.18043), [HTML](https://arxiv.org/abs/2507.18043)
### Authors
Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal
### Background
现有推理时间 steering 方法通过在测试时修改内部激活来提供一种轻量级替代于对大规模语言模型（LLMs）和视觉语言模型（VLMs）进行微调的方法，而无需更新模型权重。然而，大多数现有方法依赖于固定的整体干预向量，忽略了单个输入令牌的影响，并且未能利用模型输出未softmax的logits层中的梯度信息，特别是在多模态设置中，视觉和文本输入贡献不均使得上述问题尤为突出。
### Innovation
GrAInS 通过利用对比的、基于梯度的归因方法 Integrated Gradients，识别出对首选和非首选输出贡献最大的前 k 个正向和负向标记，然后使用这些标记构建指向不希望的到希望的行为的动感引导向量。在推理过程中，GrAInS 根据标记级别的归因信号调整变换器层的隐藏激活，并对其进行归一化以保持表示缩放，从而实现对模型行为的细粒度、可解释和模块化控制，同时无需重新训练或辅助监督。实验证明，GrAInS 在多个基准上的表现优于微调和现有 steering 的基线。
### Conclusion
GrAInS 在保持模型流畅性和通用能力的同时，实现了 TruthfulQA 上的 13.22% 准确度提升，减少了 MMHal-Bench 的幻觉率，并在 SPA-VL 上提升了 8.11% 的对齐胜率。
## 223. `cs.CL` - 使用大规模语言模型进行短语断点预测的合成数据生成 [PDF](https://arxiv.org/pdf/2507.18044), [HTML](https://arxiv.org/abs/2507.18044)
### Authors
Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim
### Background
当前的短语断点预测方法处理文本转语音系统的关键语调方面，但主要依赖大量的人工音频或文本注释，这会导致显著的人工劳动和成本。语音领域的内在变化性进一步加剧了获取一致高质量数据的难度，这些变化性由音素因素驱动。
### Innovation
受自然语言处理领域利用大规模语言模型（LLMs）生成定制合成数据以减少人工注释需求的成功启发，本文探索如何采用LLMs生成短语断点注释，解决传统注释和多语言任务中的挑战，并评估其有效性。
### Conclusion
研究发现，基于LLMs的合成数据生成有效地缓解了短语断点预测中的数据挑战，并强调了在语音领域LLMs作为一种可行解决方案的潜力。
## 224. `cs.CL` - 使用LLM生成具有多样化写作风格的隐私保护合成评论 [PDF](https://arxiv.org/pdf/2507.18055), [HTML](https://arxiv.org/abs/2507.18055)
### Authors
Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng
### Background
合成数据，特别是由大型语言模型（LLMs）生成的文本数据，因其成本效益和可扩展性在数据驱动应用中有广泛应用。然而，合成数据的多样性和隐私风险尚未得到充分探索。本研究聚焦于此问题，旨在评估LLMs生成的合成数据在语言表达、情感和用户视角的多样性，以及重新识别风险和风格化异常方面的隐私保护能力。
### Innovation
提出了一个综合性的指标集，用于定量评估由多个先进LLMs生成的合成数据集的多样性和隐私性。基于评估结果，提出了一种基于提示的方法，以提高合成评论的多样性，同时保护评论者的隐私。
### Conclusion
实验结果表明，当前LLMs在生成多样化和隐私保护的合成数据方面存在显著局限。研究建议采用基于提示的方法来增强合成评论的多样性，同时确保评论者的隐私得到保护。
## 225. `cs.CL` - Tigrinya自然语言处理: 当前状况与未来方向 [PDF](https://arxiv.org/pdf/2507.17974), [HTML](https://arxiv.org/abs/2507.17974)
### Authors
Fitsum Gaim,Jong C. Park
### Background
尽管提格拉尼亚语被数百万人使用，但在自然语言处理（NLP）研究中，提格拉尼亚语仍然严重缺乏代表性。这项研究通过回顾2011年至2025年间超过40篇关于提格拉尼亚语NLP的研究论文，提供了涵盖十年之久的综合 survey，分析了包括形态分析、机器翻译、语音识别和问答等十个下游任务的当前状态。
### Innovation
本研究首次系统性地回顾了提格拉尼亚语NLP的研究状况，揭示了从基础规则系统到现代神经架构的发展轨迹，通过资源创建里程碑推动了研究进展。识别提格拉尼亚语形态复杂性和资源匮乏的关键挑战，并提出了形态感知建模、跨语言迁移和社区中心资源开发等有前景的研究方向。
### Conclusion
这项研究不仅为提格拉尼亚语NLP领域提供了全面的参考，也为未来的研究指明了方向。为研究者提供了整理过的调研文献和资源的元数据，并面向公众开放。
## 226. `cs.CL` - NeuralDB: 使用神经键值数据库将知识编辑扩展至100,000个事实 [PDF](https://arxiv.org/pdf/2507.18028), [HTML](https://arxiv.org/abs/2507.18028)
### Authors
Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu
### Background
在大型语言模型（LLMs）中有效地编辑已存储的知识，可以使模型更新无需大规模训练。Locate-and-Edit（L&E）提供了一种解决方案，允许同时修改大量事实。然而，这种编辑可能损害LLMs的一般能力，甚至在进行数千次编辑时导致已编辑事实的遗忘。现有方法如L&E被建模为查询键值（KV）数据库，并在此基础上提出了NeuralDB，作为编辑框架的新解决方案，通过结合非线性门控检索模块实现对已编辑事实的明确表示，从而在涉及编辑事实推理时仅操作，有效保留了LLMs的一般能力。
### Innovation
NeuralDB是一个编辑框架，它将已编辑的事实明确表示为配备了非线性门控检索模块的神经键值数据库。该模块仅在涉及已编辑事实的推理时才操作，从而有效地保留了LLMs的一般能力。实验结果显示，NeuralDB在编辑效率、泛化能力、精确性、流畅性和一致性上表现优异，并且在广泛的文本理解和生成任务中保持了整体性能。进一步的实验还证明，NeuralDB甚至在扩展到100,000个事实（比之前的工作多50倍）时仍然有效。
### Conclusion
NeuralDB不仅在编辑效果、泛化能力、精确性、流畅性和一致性上表现出色，还能在跨越六项代表性文本理解和生成任务中保持总体性能。进一步的实验表明，即使扩展到100,000个事实（比以往工作多50倍），NeuralDB也保持了其有效性。
## 227. `cs.CL` - 在资源限制下的大型语言模型的混合和酉化微调：方法与基准测试 [PDF](https://arxiv.org/pdf/2507.18076), [HTML](https://arxiv.org/abs/2507.18076)
### Authors
Haomin Qi,Zihan Dai,Chengbo Huang
### Background
大型语言模型（LLMs）的微调因其规模和内存需求仍然是一个计算瓶颈。参数高效微调（PEFT）技术，如LoRA、BOFT、LoRA-GA和uRNN等方法，已经被广泛研究。然而，如何更有效地利用这些技术仍然没有得到充分解决。本文通过引入一种新的混合策略，将BOFT的正交稳定性与LoRA-GA的梯度对齐快速收敛相结合，解决了这一问题。此外，本文还首次探讨了将酉RNN（uRNN）原理应用于基于变压器的LLMs，通过结构化酉约束增强梯度稳定性。研究结果显示，该混合方法在四个基准测试（GLUE、GSM8K、MT-Bench和HumanEval）上的表现优于现有PEFT方法，特别是在资源消耗方面具有显著优势。
### Innovation
提出了将BOFT的正交稳定性和LoRA-GA的梯度对齐快速收敛相结合的新型混合策略；首次将uRNN原则应用到基于变压器的大规模语言模型中，通过结构化的酉约束增强了梯度的稳定性。实验验证表明，该混合方法在多个基准测试中表现优越，能够逼近全量微调的准确性，同时减少训练时间和内存使用量。
### Conclusion
本文的混合方法为在资源受限条件下部署大规模语言模型提供了一个实用且可扩展的微调解决方案，实验结果表明其具有更好的效率和泛化能力，可以在减少资源消耗的同时，保持与全量微调相近的性能。
## 228. `cs.AI` - 利用多源异质信号进行疲劳检测 [PDF](https://arxiv.org/pdf/2507.16859), [HTML](https://arxiv.org/abs/2507.16859)
### Authors
Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li
### Background
疲劳检测在航空、采矿和长途运输等关键安全应用中起着至关重要的作用。然而，现有大多数方法依赖于高端传感器和受控环境，这限制了它们在实际环境中的适用性。
### Innovation
本文正式定义了一个在实际环境中尚被忽略但具有实用性的疲劳检测问题设置，其中系统使用上下文相关的传感器利用来自不同仪器来源的知识，包括那些在受控环境中使用难以在实际环境中部署的传感器。为此，作者提出了一种异构的、多功能的疲劳检测框架，该框架能够灵活利用目标域中存在的各种方式，并从源域的多样化配置中获益。
### Conclusion
实验结果表明，该方法在实际部署的传感器设置和两个公开可用的数据集中体现了其实用性、鲁棒性和更好的泛化能力，为传感器受限场景下的有效疲劳监测开辟了实际途径。
## 229. `cs.CL` - GOAT-SLM：具备副语言和说话者特征意识的言语语言模型 [PDF](https://arxiv.org/pdf/2507.18119), [HTML](https://arxiv.org/abs/2507.18119)
### Authors
Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He
### Background
近期端到端的言语语言模型（SLMs）大幅提升了人工智能系统的自然语音互动能力。然而，大多数现有模型在处理人类语音时仅关注语言内容，忽视了语音中丰富的副语言和说话者特性线索，例如方言、年龄、情感和非语音声音。本研究探讨了如何在言语语言建模中引入这些因素的重要性，以超越文本语义的限制，提升语言理解和表达的自然性、适应性和社交意识层面。
### Innovation
本文提出了GOAT-SLM，这是一种新型的具备副语言和说话者特性意识的言语语言模型。该模型采用双模态头部架构，使得语言建模与语音实现分离，不仅能增强语言理解的鲁棒性，支持更富有表现力和适应性的语音生成。为增强模型效率和灵活性，提出了一种模块化、分阶段的培训策略，利用大规模的语音文本数据集逐渐对语言、副语言和说话者特性信息进行对齐。这些创新均旨在改善模型的普适性和与人类交流的真实性、多样性、社交感知程度，并提供更高级别的反馈和互动选项。
### Conclusion
在TELEVAL多维度评估基准测试中，GOAT-SLM在语义和非语义任务上都取得了良好的平衡表现，并在处理情感、方言变异和年龄敏感交互方面优于现有的开源模型。本研究强调了在言语语言建模中超越语言内容的重要性，并推动了更自然、更灵活和更具备社交意识的言语语言系统的发展。
## 230. `cs.CL` - 动态可泛化的过程奖励建模 [PDF](https://arxiv.org/pdf/2507.17849), [HTML](https://arxiv.org/abs/2507.17849)
### Authors
Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang
### Background
过程奖励模型（PRMs）对于指导大型语言模型（LLMs）在复杂场景中是有关键作用的，通过提供密集的奖励信号。然而，现有的PRMs大多依赖于启发式的策略，这在跨领域泛化上表现不佳。此外，目前的研究主要集中在LLM作为裁判提供泛化奖励的表现上，却忽略了文本中潜在的重要指导意义。静态和粗粒度的评估标准也无法很好地适应复杂的过程监督。
### Innovation
我们提出了动态可泛化的过程奖励建模（DG-PRM），其特点是一个奖励树来捕捉并存储细粒度、多维度的奖励标准。DG-PRM动态选择奖励信号进行步进奖励评分。为处理多维度的奖励信号，我们首创使用帕累托支配估计来识别有区别的正负样本对。实验结果表明，DG-PRM在现有基准测试上表现出色，显著提升了具有密集奖励的任务中的模型性能。进一步的分析显示，DG-PRM在稀疏分布场景中表现出良好的适应性，显示出极强的泛化能力。
### Conclusion
DG-PRM在处理复杂的奖励信号时表现出色，通过使用动态选择奖励信号和帕累托支配估计方法，提高模型在密集奖励任务中的性能，并且具有良好的跨领域泛化能力。
## 231. `cs.CL` - MathOPEval: 数学推理中MLLMs视觉操作的一个精细评估基准 [PDF](https://arxiv.org/pdf/2507.18140), [HTML](https://arxiv.org/abs/2507.18140)
### Authors
Xiaoyuan Li,Moxin Li,Wenjie Wang,Rui Men,Yichang Zhang,Fuli Feng,Dayiheng Liu,Junyang Lin
### Background
近年来，多模态大型语言模型（MLLMs）的进步使得基于文本指令执行视觉操作以实现逐步的多模态数学推理成为可能。一种有前景的方法是使用代码作为中间表示，以精确地表达和操作推理过程中的图像。然而，现有的评估主要集中在文本推理输出上，而MLLMs通过代码执行准确的视觉操作的能力却鲜有研究。本工作旨在通过评估MLLMs基于代码的多模态数学能力, 在上述网址中介绍了我们的框架关注两个关键评估方面：（1）多模态代码生成（MCG）评估模型从头开始准确理解和构造视觉表示的能力；（2）多模态代码编辑（MCE）评估模型进行细粒度操作的能力，包括删除、修改和注解三种类型。为了评估上述任务，我们使用了一个覆盖五种最流行的数学图表类型的大型数据集，包括几何图、函数图和三种统计图，以提供对现有MLLMs的有效评估。实验评估涉及九个主流的MLLMs，结果显示现有模型在执行细粒度视觉操作方面仍然落后于人类表现。
### Innovation
本工作开发了一个称为MathOPEval的评估框架，专注于多模态代码生成（MCG）和多模态代码编辑（MCE），这是对现有仅考虑文本推理输出的评估方法的一种创新补充，特别是在评估MLLMs通过代码执行准确视觉操作的能力上。该框架使用一个涵盖了五种常见数学图表类型的数据集，为评估MLLMs在多模态数学推理中的视觉操作能力提供了全面和有效的方法。实验结果显示现有模型在执行细粒度视觉操作方面仍然不如人类表现。
### Conclusion
现有的MLLMs在多模态数学推理中的细粒度视觉操作方面仍存在显著差距，需要进一步的研究以提升其在这一领域的表现。
## 232. `cs.CL` - TN-AutoRCA: 基于警报的电信网络自我提升根因分析的基准构建与代理框架 [PDF](https://arxiv.org/pdf/2507.18190), [HTML](https://arxiv.org/abs/2507.18190)
### Authors
Keyu Wu,Qianjin Yu,Manlin Mei,Ruiting Liu,Jun Wang,Kailai Zhang,Yelun Bao
### Background
电信网络中的根本原因分析（RCA）是一项至关重要的任务，但对人工智能（AI）来说却是一个巨大的挑战，因为需要进行复杂且基于图的推理，并且缺乏实际的基准数据集.
### Innovation
提出了TN-AutoRCA，这是一个基准构建和具有代理框架的自我改进警报驱动的根因分析系统，旨在解决AI在电信网络上进行根本原因分析时面临的关键挑战.
### Conclusion
本文介绍了TN-AutoRCA，通过自我提升和警报驱动机制来改进电信网络中根因分析的AI能力，填补了相关领域的空白，并提供了一套新的基准环境供后续研究使用.
## 233. `cs.CL` - Shop-R1: 使用强化学习在在线购物中模拟人类行为的LLM奖励方法 [PDF](https://arxiv.org/pdf/2507.17842), [HTML](https://arxiv.org/abs/2507.17842)
### Authors
Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang
### Background
大型语言模型（LLMs）近年来展示了在生成网上的‘可信人类行为’方面的能力。之前的工作已经探索了通过LLM合成的推理过程和监督微调（SFT）来增强推理能力的方法，以改善下游行为预测。然而，这些方法的性能仍然受限于生成这些推理的模型的推理能力。
### Innovation
论文提出了Shop-R1，这是一种新颖的强化学习（RL）框架，旨在通过模拟在线购物环境中真实的人类行为来增强LLM的推理能力。Shop-R1将人类行为模拟任务分解为两个阶段：推理生成和行为预测，并分别提供不同的奖励信号作为指导。对于推理生成，利用模型内部信号（如logit分布）进行自我监督引导推理过程。对于行为预测，提出了一个难度感知的奖励层次结构，以防止奖励滥发并实现细致的奖励分配。
### Conclusion
实验结果表明，本文方法在基准模型上相对改进了65%以上。
## 234. `cs.CL` - 使用GMTP保护RAG管道：基于梯度的掩码令牌概率方法以检测中毒文档 [PDF](https://arxiv.org/pdf/2507.18202), [HTML](https://arxiv.org/abs/2507.18202)
### Authors
San Kim,Jonghwi Kim,Yejin Jeon,Gary Geunbae Lee
### Background
RAG通过提供外部知识来增强大型语言模型（LLMs），以实现更准确且及时的响应。然而，这依赖于对外部源的依赖暴露了安全风险，攻击者可以将中毒文档注入知识库，引导生成过程产生有害或误导性的输出。
### Innovation
本文提出了一种新颖的防御方法，名为Gradient-based Masked Token Probability (GMTP)，用于检测和过滤恶意文档。GMTP通过检查检索器相似函数的梯度来识别高影响令牌，然后对这些关键令牌进行掩码，并通过掩码语言模型（MLM）检查它们的概率。由于注入的令牌通常显示出显着低的掩码令牌概率，这使得GMTP能够轻松检测恶意文档，并实现高精度过滤。实验结果表明，GMTP能够消除超过90%的中毒内容，同时保留相关文档，从而在不同的数据集和对抗设置中保持稳健的检索和生成性能。
### Conclusion
实验验证了GMTP的有效性，能够在不损害相关文档和检索/生成性能的前提下有效检测并消除超过90%的恶意文档。
## 235. `cs.CL` - 一套新的 GloVe [PDF](https://arxiv.org/pdf/2507.18103), [HTML](https://arxiv.org/abs/2507.18103)
### Authors
Riley Carlson,John Bauer,Christopher D. Manning
### Background
2014年发布的原始 GloVe 模型已被广泛使用并且被认为很有用，然而，随着语言和世界的发展，这些模型可能需要更新。此外，2014年的模型没有详细记录所使用的具体数据版本和预处理步骤，因此本文档详细记录了2024年的 GloVe 模型。
### Innovation
本文档描述并评估了2024年的新 GloVe 模型。与2014年的模型相比，新的模型在文档的预处理步骤上进行了详细记录，并且通过词汇比较、直接测试和命名实体识别任务评估了模型的性能。
### Conclusion
2024年的 GloVe 模型包含了新的文化和社会语言上相关的新词，在像类比和相似性这样的结构性任务上表现与旧模型相似，并在依赖于时间最新的命名实体识别数据集上表现出更好的性能，例如非西方的新闻数据。
## 236. `cs.CL` - 探索指令调优对大语言模型接受错误信息的影响 [PDF](https://arxiv.org/pdf/2507.18203), [HTML](https://arxiv.org/abs/2507.18203)
### Authors
Kyubeen Han,Junseo Jang,Hongjin Kim,Geunyeong Jeong,Harksoo Kim
### Background
指令调优可以增强大语言模型（LLMs）遵循用户指令的能力，提高使用便利性并减少有害输出，但同时可能会增加模型对用户输入的依赖性，从而可能导致对错误信息的无过滤接受和幻觉生成。现有研究主要关注LLMs对外部信息的接受，这些信息可能与其参数知识相矛盾，但很少有研究直接探讨指令调优对这一现象的影响。
### Innovation
本研究探讨指令调优对大语言模型在接受错误信息方面的直接影响。研究发现，接受用户提供的错误信息的几率在指令调优后显著增加。与基础模型相比，指令调优增大了对用户提供的信息的依赖性，导致从助手角色向用户角色的易受影响性的转变。此外，研究还探讨了用户在提示结构中的角色、错误信息的长度以及系统提示中警告的存在等其他影响因素。这些发现强调了需要系统性地缓解指令调优带来的潜在不良后果，以增强大语言模型在实际应用中的可靠性。
### Conclusion
研究强调了需要系统性地缓解指令调优带来的潜在不良后果，以增强大语言模型在实际应用中的可靠性。
## 237. `cs.CL` - 将符合ISO30401的知识管理系统融入组织现有业务流程 [PDF](https://arxiv.org/pdf/2507.18197), [HTML](https://arxiv.org/abs/2507.18197)
### Authors
Aline Belloni,Patrick Prieur
### Background
大多数组织使用业务流程建模作为确保工作效率和工作流与组织战略目标对齐的重要框架。对于符合或接近ISO 9001标准的组织，这意味着详细映射出流程、子流程、活动和任务。ISO30401是2018年引入的一个管理标准，旨在建立组织内部知识管理系统的通用要求。ISO30401实施者在向客户解释知识的发展、转换和传递如何与现有运营流程整合时遇到挑战。本文旨在回顾ISO9001的流程建模原则，并探讨如何根据我们的经验，使符合ISO30401知识管理系统（KMS）与其他集成管理系统流程交织，特别是通过PDCA周期中的机制实现SECI模型的部署，从而实现这一点。
### Innovation
本文通过回顾ISO9001的流程建模原则，探讨如何通过PDCA周期中的机制实现SECI模型的部署，将符合ISO30401的知识管理系统与组织的现有业务流程有机整合，为企业实现更好的知识管理提供了创新性的解决方案。
### Conclusion
本研究提出了通过PDCA周期中的机制实现SECI模型的部署，从而使符合ISO30401的知识管理系统成功融入组织的现有业务流程，增强了组织的知识管理能力，提高了效率和有效性。
## 238. `cs.CL` - Locate-and-Focus: 提升语音语言模型中的术语翻译能力 [PDF](https://arxiv.org/pdf/2507.18263), [HTML](https://arxiv.org/abs/2507.18263)
### Authors
Suhang Wu,Jialong Tang,Chengyi Yang,Pei Zhang,Baosong Yang,Junhui Li,Junfeng Yao,Min Zhang,Jinsong Su
### Background
直接对话翻译（ST）近年来引起了越来越多的关注，但如何准确翻译话语中的术语仍然是一个巨大挑战。当前的研究主要集中在将各种翻译知识融入到ST模型中，但这些方法往往受到无关噪音的干扰，无法充分利用翻译知识。这使得术语翻译的准确率仍然存在问题，需要一种更有效的方法来解决这一问题。
### Innovation
本文提出了一种名为Locate-and-Focus的新方法，旨在解决术语翻译问题。该方法首先有效定位话语中包含术语的语音片段，以便构建翻译知识，从而减少ST模型中的无关信息。其次，该方法将翻译知识与语音和文本模态的假设有声话语相关联，使ST模型在翻译过程中能够更加专注于这些翻译知识。实验结果表明，该方法能够有效识别术语，提高术语翻译的成功率，并维持良好的通用翻译性能。
### Conclusion
我们的方法有效地识别出话语中的术语，并提高了术语翻译的成功率，同时保持了良好的通用翻译性能。
## 239. `cs.CL` - TELEVAL: 针对中国互动场景设计的动态口语模型基准 [PDF](https://arxiv.org/pdf/2507.18061), [HTML](https://arxiv.org/abs/2507.18061)
### Authors
Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li
### Background
近年来，口语语言模型（SLMs）取得了快速发展，并伴随着众多评估模型性能的基准的发展。然而，现有的大多数基准主要关注SLMs能否执行与大型语言模型（LLMs）相媲美的复杂任务，往往未能与用户在真实世界对话场景中的自然互动方式相契合。
### Innovation
本文提出了TELEVAL，一种专门为评估SLMs在真实中文互动场景中作为对话代理的有效性而设计的动态基准。TELEVAL定义了三个评估维度：显性语义、非言语语义和隐性语义、系统能力。TELEVAL采用与真实使用场景一致的对话格式，并分别评估文本和音频输出。特别地，TELEVAL强调了模型从用户言语中提取隐性线索并适当响应的能力，而无需额外的指令。
### Conclusion
我们的实验表明，尽管取得了一定进展，现有的SLMs仍然在自然对话任务中存在改进空间。我们希望TELEVAL能作为一个用户为中心的评估框架，直接反映用户体验，并有助于开发更加出色的对话导向型SLMs。
## 240. `cs.CL` - 低资源语言零样本OCR准确性的比较分析：斯里兰卡僧伽罗语和泰米尔语 [PDF](https://arxiv.org/pdf/2507.18264), [HTML](https://arxiv.org/abs/2507.18264)
### Authors
Nevidu Jayatilleke,Nisansa de Silva
### Background
光学字符识别（OCR）在印刷文本中的问题，特别是在拉丁语及其衍生文字系统中，已经因为对英语和其他高资源语言（HRL）的研究而基本得到解决。然而，使用独特文字系统的低资源语言（LRL）的OCR问题仍然未被完全解决。本研究旨在比较六种不同的OCR引擎在两种低资源语言——僧伽罗语和泰米尔语——上的零样本性能。
### Innovation
该研究首次将五种不同的评估技术系统地应用于六种OCR引擎，以评估其在字符和单词级别的准确性。此外，研究还引入了一个新的合成泰米尔语OCR基准数据集。
### Conclusion
研究表明，Surya在僧伽罗语的所有评估指标中表现最佳，字符错误率为2.61%。另一方面，Document AI在泰米尔语的所有评估指标中表现最佳，字符错误率为0.78%。
## 241. `cs.CL` - Prune&Comp：通过迭代修剪和幅度补偿提高层剪枝的大型语言模型性能 [PDF](https://arxiv.org/pdf/2507.18212), [HTML](https://arxiv.org/abs/2507.18212)
### Authors
Xinrui Chen,Hongxing Zhang,Fanyi Zeng,Yongxian Wei,Yizhi Wang,Xitong Ling,Guanghao Li,Chun Yuan
### Background
层剪枝作为一种有希望的技术，可以压缩大型语言模型（LLMs），同时加速程度与剪枝比例成正比。然而，移除任何层会导致隐藏状态的巨大幅度差距，从而引起显著的性能下降。本文分析了层剪枝带来的问题，并通过一种训练-Free 的幅度补偿方法，提出了一种名为 Prune&Comp 的新方案，以减轻这种幅度差距。
### Innovation
Prune&Comp 是一种新颖的插件式层剪枝方案，通过幅度补偿在不进行训练的情况下缓解隐藏状态幅度差距。具体来说，首先估计由层移除引起的幅度差距，然后通过离线调整剩余权重来消除幅度差距，同时不增加运行时开销。这种方法通过迭代修剪策略进一步证明了其优势。Prune&Comp 结合了迭代修剪和补偿循环，持续提升现有的层剪枝指标。
### Conclusion
当将 Prune&Comp 应用于 LLaMA-3-8B 的 5 层剪枝时，近似减半了困惑度，并保持了原始模型 93.19% 的问答性能。与基线相比，性能提高了 4.01%。
## 242. `cs.CL` - SCOPE: 基于随机和反偏置选项排列的大语言模型评估框架 [PDF](https://arxiv.org/pdf/2507.18182), [HTML](https://arxiv.org/abs/2507.18182)
### Authors
Wonjun Jeong,Dongseok Kim,Taegkeun Whangbo
### Background
大型语言模型（LLMs）在多项选择任务中可能会通过利用选项位置或标签本身存在的偏差来获得较高的分数，而非展示真正理解能力。已有研究表明，现有的一些评估方法可能会因为这些偏差而导致评估不公正和不可靠。
### Innovation
SCOPE框架旨在以数据集独立的方式测量并减轻此类选择偏差。通过反复调用缺乏语义内容的空白提示，SCOPE估计每个模型的独特的位置偏差分布。然后根据逆偏差分布重新分配答案位置，从而平衡随机选对正确答案的几率。另外，它还防止语义相似的干扰项相邻放置，以阻止基于表面上的接近提示的差点猜对。在多个基准实验中，SCOPE在稳定性能改进和明确的正确选项置信度方面均优于现有去偏差方法。
### Conclusion
综上所述，SCOPE框架为提升大语言模型评估的公平性和可靠性提供了一个新的标准。
## 243. `cs.CL` - StyleAdaptedLM: 提升指令遵循模型的高效风格转移 [PDF](https://arxiv.org/pdf/2507.18294), [HTML](https://arxiv.org/abs/2507.18294)
### Authors
Pritika Ramu,Apoorv Saxena,Meghanath M Y,Varsha Sankar,Debraj Basu
### Background
对于企业来说，根据特定品牌声音或作者语调调整语言模型（LLM）的风格至关重要。然而，从缺乏指令-响应格式化的企业数据集中实现这一目标具有挑战性，而且在保持指令执行的情况下，很难实现风格中立和高品质的定制化。文章背景在于现有方法往往绕不开配对数据的需求，同时也不一定能够保证任务性能的稳定性。因此，亟需一种新的框架来实现高效的风格转移，同时确保指令的严格遵循和任务性能不受影响。
### Innovation
本文介绍了一种名为StyleAdaptedLM的新框架，该框架利用低秩适应（LoRA）高效地将各种未结构化的风格特性转移到指令跟随模型上。首先，LoRA适配器在基模型上用多样化的风格数据集进行训练，然后与一个独立的指令遵循模型合并。这种方法可以在不依赖配对数据的情况下，实现稳定的风格定制，同时保持任务性能。研究结果表明，该方法能够在确保指令严格遵循的前提下，实现更一致的风格效果，同时通过人类评估确认了品牌特有惯例的吸收。
### Conclusion
StyleAdaptedLM为语言模型中的风格个性化提供了一种高效途径，能够在不牺牲任务性能的情况下实现高质量且特定于品牌的风格定制。实验数据和人类评估一致证实了这种方法的有效性。
## 244. `cs.CL` - 基于LLM预标注与人类智能融合的 propaganda 检测标注方法 [PDF](https://arxiv.org/pdf/2507.18343), [HTML](https://arxiv.org/abs/2507.18343)
### Authors
Ariana Sahitaj,Premtim Sahitaj,Veronika Solopova,Jiaao Li,Sebastian Möller,Vera Schmitt
### Background
社交媒体上的 propaganda 检测任务复杂且受限于高质量标注数据的不足。当前方法在注释一致性以及可扩展性方面面临挑战。
### Innovation
提出了一种结合人类专家知识和大型语言模型（LLM）辅助的框架，创新之处在于设计了一个分层分类体系，组织14种细粒度的 propaganda 技巧；开发了一种LLM辅助预标注流水线，用于提取 propaganda 的信息片段、生成简要解释、分配局部标签和整体标签；并通过次要的人工验证研究，证实在一致性及效率方面有显著提升。基于此，对较小的语言模型进行微调，用于结构化注释，以高质量LLM生成的数据进行训练，应用知识蒸馏使小模型学会生成注释。
### Conclusion
本研究促进了可扩展且稳健的propaganda检测系统的发展，支持透明和负责的媒体生态系统，与SDG 16目标一致。相关代码已公开在GitHub仓库中。
## 245. `cs.CL` - 文本嵌入模型中的‘粘性’标记检测：保持均值 [PDF](https://arxiv.org/pdf/2507.18171), [HTML](https://arxiv.org/abs/2507.18171)
### Authors
Kexin Chen,Dongxia Wang,Yi Liu,Haonan Zhang,Wenhai Wang
### Background
尽管基于Transformer的文本嵌入模型在自然语言处理任务中得到了广泛应用，但在某些情况下出现的‘粘性’标记会破坏嵌入的可靠性。这些标记在句子中反复出现时，会拉近相似度，导致嵌入距离的分布不正常，从而影响下游任务的表现。
### Innovation
该研究系统地探讨了这些异常标记，并正式定义了它们。研究人员引入了一种基于句子和标记过滤的高效检测方法，即粘性标记检测器(STD)。作者将STD应用于14个模型家族中的40个检查点，共发现了868个粘性标记。同时，通过注意力层分析，研究揭示了粘性标记如何占据模型的内部表示，展示了其可将标记化稳健性问题置为担忧。
### Conclusion
研究表明，粘性标记的存在对下游任务如聚类和检索有显著的负面影响，最大性能下降可达50%。研究指出需要改进标记化策略和模型设计，以减轻粘性标记对未来文本嵌入应用的影响。
## 246. `cs.CL` - CLEAR: 通过LLM作为评判者进行错误分析简易化 [PDF](https://arxiv.org/pdf/2507.18392), [HTML](https://arxiv.org/abs/2507.18392)
### Authors
Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer
### Background
目前，大型语言模型（LLMs）的评估越来越多地依赖于其他LLM作为评判标准。现有的评价方法通常只能得到单一的评分或排名，回答哪种模型更好，但不能解释具体原因。虽然这些顶级评分对于基准测试很重要，它们却掩盖了模型具体表现背后的详细、可操作的原因。现有方法存在的这一空白促使作者开发了一个新的解决方案，即名为CLEAR的包，用于LLM基于的错误分析。该工具旨在更好地揭示模型性能背后的原因，提高评估的透明度和可解释性。
### Innovation
作者引入了CLEAR，这是一个交互式的、开源的包，用于LLM基于的错误分析。CLEAR首先生成针对每个实例的文本反馈，然后创建一组系统级错误问题，并量化每个问题的出现频率。该包还提供了交互式仪表板，通过汇总可视化、使用交互式过滤器筛选特定问题或分数范围，并深入到具体实例，使得用户可以进行全面的错误分析。作者通过RAG和数学基准展示了CLEAR分析的应用，并通过用户案例研究展示了其用途。
### Conclusion
CLEAR实现了从单一评分到详细分析模型具体表现原因的转变，显著提高了评估的透明度和可操作性。该工具通过交互式的、可视化的用户界面使得复杂且详细的问题分析变得简单易行。作者通过RAG和数学基准的具体案例演示了CLEAR的有效性，并展示了它在实际应用中的实用价值。
## 247. `cs.CL` - TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning [PDF](https://arxiv.org/pdf/2507.18340), [HTML](https://arxiv.org/abs/2507.18340)
### Authors
Yifu Chen,Bingchen Huang,Zhiling Wang,Yuanchao Du,Junfeng Luo,Lei Shen,Zhineng chen
### Background
在上下文学习（ICL）中，经典方法用来使大型语言模型（LLM）基于少量输入输出示例来完成各种任务。由于这些示例的质量直接影响ICL的效果，之前的增强示例检索能力的工作已经取得了显著的效果。然而，高质示例检索仍然面临两个挑战：跨任务数据分布难以区分；检索模块输出与LLM反馈之间的细粒度连接难以建立。因此，此研究提出了一个新的框架TDR，它将来自不同任务的ICL示例分离，使得检索模块可以在多任务数据集中检索特定于目标任务的示例。此外，TDR通过训练检索模块，利用来自LLM的细粒度反馈进行监督和引导，从而实现了高质量示例的检索。
### Innovation
提出了一个名为TDR的新框架，该框架将ICL示例与不同任务分离，使得检索模块能够在多任务数据集中检索特定于目标任务的示例。TDR还通过利用来自LLM的细粒度反馈来培训检索模块，从而提高示例检索的质量和效果。实验结果表明，TDR在30个NLP任务上的表现优于以前的方法，并且可以直接与各种LLM集成，以增强ICL的示例检索能力。
### Conclusion
TDR框架在一系列NLP任务上展示了其优越性，并实现了最先进的性能。同时，该方法具有易扩展性，可以直接与各种大型语言模型结合，提升上下文学习中的示例检索能力。
## 248. `cs.CL` - 使用不确定性量化评估机器翻译偏见 [PDF](https://arxiv.org/pdf/2507.18338), [HTML](https://arxiv.org/abs/2507.18338)
### Authors
Ieva Raminta Staliūnaitė,Julius Cheng,Andreas Vlachos
### Background
在机器翻译中，当源句子包含没有明示性性别的词，但其目标语言等价词需要指定性别的时候，模型需要从上下文和/或外部知识中推断合适的性别。研究表明，机器翻译模型表现出性别偏见的行为，即使这种偏见与上下文信息相矛盾，它们仍然依赖于刻板印象。现有研究强调，在明确性别的句子中准确翻译时，模型还应该在含义模糊的句子中维持不确定性。通过最近提出的语义不确定性度量，发现在明确性别的实例上具有高翻译和性别准确性的模型，在模糊性别的实例上不一定表现出应有的不确定性水平。同样地，去偏见对明确性别和模糊性别的翻译实例会产生独立效果。
### Innovation
本文提出了使用语义不确定性度量来评估机器翻译模型在模糊性性别确定实例中的不确定性表现。实验证明，即使在明确性别的实例中表现出色，模型在模糊性别的实例中并不一定会表现出相应的不确定性。研究还发现，减少偏见对明确性别和模糊性别的翻译实例具有独立影响。这为改善机器翻译中性别偏见的评估和矫正提供了新的视角和方法。
### Conclusion
研究发现，机器翻译模型在处理明确和模糊的性别信息时的差异化表现，并不意味着它们在所有情况下都保持一致的不确定性水平。此外，去偏举措对于不同类型的翻译实例会产生独立的效应。这意味着在评估和改进机器翻译系统的公平性和准确性方面，需要更细致地关注意义不确定性的影响。
## 249. `cs.CL` - HIVMedQA: 大型语言模型在HIV医疗决策支持中的基准评估 [PDF](https://arxiv.org/pdf/2507.18143), [HTML](https://arxiv.org/abs/2507.18143)
### Authors
Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux
### Background
大型语言模型（LLMs）正在成为支持临床常规决策的重要工具。艾滋病管理因其多样化治疗选择、合并症和依从性挑战而成为一个富有吸引力的应用场景。然而，将LLMs集成到临床实践中的担忧包括准确性问题、潜在危害和医务人员的接受度。尽管有这些潜力，但AI在HIV护理中的应用仍然研究不足，关于LLM的基准测试研究也很少见。这项研究评估了LLMs在HIV管理中的当前能力，强调了它们的优势和限制。
### Innovation
本研究引入了HIVMedQA，一个旨在评估HIV护理中开放性医疗问题回答能力的基准。研究使用了七种通用和三种医学专门化的LLMs，通过诱话语料工程提升了性能。研究框架结合了词汇相似度和LLM作为评判者的方法，并扩展以更好地反映临床相关性。评估了问题理解、推理、知识回忆、偏见、潜在危害和事实准确性等关键维度的表现。结果显示，Gemini 2.5 Pro在大多数维度上表现最佳。认知偏差如近因效应和现状偏差也在研究中被发现。这些发现强调了针对特定开发和评估的必要性，以确保LLM在临床护理中的安全和有效性。
### Conclusion
研究发现，推理和理解比事实回忆更具有挑战性。两项顶尖模型为内部模型。复杂问题导致表现下降。医学微调模型并不总是优于通用模型，而且模型大小不是表现可靠的预测因素。需要针对性的发展和评估以确保LLM在临床护理中的安全和有效集成。
## 250. `cs.CL` - 有效多任务学习在生物医学命名实体识别中的应用 [PDF](https://arxiv.org/pdf/2507.18542), [HTML](https://arxiv.org/abs/2507.18542)
### Authors
João Ruano,Gonçalo M. Correia,Leonor Barreiros,Afonso Mendes
### Background
生物医学命名实体识别面临着生物医学术语的复杂性和不同数据集注释一致性差的挑战。这些因素给识别准确性和模型有效性带来了难题，需要新的方法和技术来应对这些挑战。
### Innovation
该论文提出了一种名为SRU-NER（基于槽的循环单元命名实体识别）的新颖方法，能够处理嵌套命名实体，并通过有效的多任务学习策略整合多个数据集。SRU-NER通过动态调整损失计算来避免惩罚那些特定数据集中不存在的实体类型，从而弥补注释差距。
### Conclusion
通过广泛的实验，SRU-NER在生物医学和一般领域命名实体识别任务中表现出竞争性性能，并且在跨领域泛化方面有所改善。
## 251. `cs.CL` - 多语言维基百科表格中的事实不一致性 [PDF](https://arxiv.org/pdf/2507.18406), [HTML](https://arxiv.org/abs/2507.18406)
### Authors
Silvia Cappa,Lingxiao Kong,Pille-Riin Peet,Fanfu Wei,Yuchen Zhou,Jan-Christoph Kalo
### Background
维基百科作为全球可访问的知识来源，拥有超过300种语言的内容。尽管覆盖相同主题，不同语言版本的维基百科独立撰写和更新，导致事实上的不一致，这会影响百科全书和依赖维基百科作为主要训练来源的AI系统的中立性和可靠性。本文研究了维基百科结构化内容中的跨语言不一致性，重点关注表格数据。
### Innovation
提出了一种方法来收集、对齐和分析来自维基百科多语言文章的表格，定义了不一致的类别，并使用样本数据集应用多种定量和定性指标评估多语言对齐度。
### Conclusion
这些见解对于事实验证、多语言知识交互和设计依赖维基百科内容的可靠AI系统具有重要意义。
## 252. `cs.CL` - FinDPO：通过优化LLM偏好进行算法交易的情绪分析 [PDF](https://arxiv.org/pdf/2507.18417), [HTML](https://arxiv.org/abs/2507.18417)
### Authors
Giorgos Iacovides,Wuyang Zhou,Danilo Mandic
### Background
网络财务相关文本的数据观点对交易决策和市场动向的影响力日益增强，凸显了情感分析作为衡量这些观点的性质和强度的重要性。随着生成AI（GenAI）的快速发展，监督微调（SFT）大型语言模型（LLMs）已成为金融情感分析的标准工具。然而，SFT范式可能导致记忆训练数据，通常无法泛化到未见过的样例，这是在必须适应以前未观察到的事件和金融领域的专有语言的金融领域中的关键限制。
### Innovation
提出了一种名为FinDPO的金融特定LLM框架，基于后训练人类偏好的直接优化（DPO），通过后期训练的人类偏好对齐实现。FinDPO在标准情感分类基准测试中取得了最先进的性能，平均优于现有的监督微调模型11%。独创性地，FinDPO框架通过一种新颖的'logit-to-score'转换，将离散的情感预测转化为可排序的情感评分（概率），从而将细调后的因果LLM集成到现实的资产组合策略中。在能够保持每年67%的显著正回报和强大的风险调整表现，即使在5个基点（bps）的现实交易成本条件下，也能由夏普比率2.0得出证明。
### Conclusion
FinDPO框架在现实交易成本下的情感依赖方法实现了67%的年化显著正回报和强大的风险调整性能，这一结论表明该框架在金融领域的情感分析中的重要性和有效性。
## 253. `cs.CL` - 并非所有特征都值得关注：语言模型生成表数据中的图引导依赖学习 [PDF](https://arxiv.org/pdf/2507.18504), [HTML](https://arxiv.org/abs/2507.18504)
### Authors
Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci
### Background
大型语言模型（LLMs）在表数据生成方面表现出强大的潜力，能够建模文本化的特征-值对。然而，表数据本质上表现出稀疏的特征级依赖性，其中许多特征交互在结构上是不相关的。这导致LLMs的自注意力机制不可避免地会在所有特征交互之间分散注意力，特别是对于具有复杂依赖关系或语义模糊特征的数据集，会稀释对关键关系的注意力。
### Innovation
我们提出了GraDe（Graph-Guided Dependency Learning），一种新颖的方法，该方法明确地将稀疏的依赖图集成到LLMs的注意力机制中。GraDe 采用一个由外部提取的功能依赖性引导的轻量级动态图学习模块，优先考虑关键特征交互并抑制无关的交互。我们的实验表明，在各种真实数据集上，GraDe 在复杂数据集上的性能比现有基于LLM的方法高出最高12%，同时在合成数据质量上达到与最先进方法相当的结果。该方法具有最小侵入性且有效，提供了一种实用的解决方案，用于结构感知的表数据建模。
### Conclusion
我们的研究证明，GraDe 可以在保持现有先进方法性能的同时，提高复杂数据集上表数据生成的质量。GraDe 提供了对关键特征交互进行更有效的注意力分配，帮助解决LLMs在表数据生成中遇到的稀疏特征依赖问题。
## 254. `cs.CL` - AraTable：评估大型语言模型对阿拉伯语文本表格数据的推理和理解 [PDF](https://arxiv.org/pdf/2507.18442), [HTML](https://arxiv.org/abs/2507.18442)
### Authors
Rana Alshaikh,Israa Alghanmi,Shelan Jeawak
### Background
大型语言模型（LLMs）在自然语言处理领域的认知和推理能力取得了显著进步，但它们在解释结构化数据，尤其是表格格式数据方面的能力仍然有限。尽管存在针对英语表格数据的标准基准，但阿拉伯语的数据资源仍然较为匮乏，原因是语言特性和缺乏公共资源。鉴于此，本文提出了AraTable，一种新型且全面的基准测试，用于评估LLMs在处理阿拉伯语文本表格数据时的推理和理解能力。AraTable涵盖了多种评估任务，如直接问答、事实验证和复杂推理等，并涉及广泛的阿拉伯语文本表格来源。此外，研究还展示了初版AraTable的结果，表明尽管LLMs在简单的表格任务如直接问答方面表现良好，但在需要深度推理和事实验证的任务上仍面临重大挑战，证明未来在复杂表格推理任务上的性能改进存在巨大潜力。
### Innovation
此次研究提出的AraTable基准测试是针对阿拉伯语文本表格数据的首个综合性的标准，涵盖了直接问答、事实验证和复杂推理等多种任务，旨在评估大型语言模型的推理与理解能力。研究还提出了一种全自动评估框架，利用自我推理机制，实现了与人类评委几乎相同的评估性能。AraTable提供了高质量的数据集和评估框架，有助于加速阿拉伯语结构化数据处理与分析的基本模型的发展进程。此次研究的独特之处在于其首次规范了阿拉伯语文本表格数据的基准体系，通过综合多种任务，全面评估大型语言模型在这类数据上的处理能力，并提出了自动化评估框架，提高了评估效率和准确性。
### Conclusion
研究结果表明，尽管大型语言模型在简单的表格任务方面表现出色，但在需要深度推理和事实验证的复杂任务中仍面临重大挑战。AraTable提供了一个高质量的数据集和评估框架，有助于推动相关领域的未来研究。此外，研究还提出了一种全自动评估框架，进一步提高了评估的效率和准确性。
## 255. `cs.CL` - GLiNER2：具有模式驱动接口的高效多任务信息提取系统 [PDF](https://arxiv.org/pdf/2507.18546), [HTML](https://arxiv.org/abs/2507.18546)
### Authors
Urchade Zaratiana,Gil Pasternak,Oliver Boyd,George Hurn-Maloney,Ash Lewis
### Background
信息提取（IE）在许多自然语言处理（NLP）应用中都是基础，但现有解决方案往往需要为不同的任务构建专门的模型，或者依赖于计算成本昂贵的大语言模型。
### Innovation
GLiNER2是一种统一框架，它提升了原有的GLiNER架构，能够在单一高效的模型中支持命名实体识别、文本分类和层次结构化数据提取，并通过直观的基于模式的接口引入多任务组合。GLiNER2基于预训练的变压器编码器架构，保持CPU效率和紧凑体积，同时在部署便捷性上相比基于大语言模型的替代品有显著提升。作者还发布了GLiNER2作为开源pip安装库，附带预训练模型和文档。
### Conclusion
GLiNER2实验展示了在提取和分类任务方面的竞争力，并且在部署便捷性上相比基于大语言模型的替代品具有显著改进。GLiNER2作为开源pip安装库发布，提供用户方便使用。
## 256. `cs.CL` - GIIFT:基于图引导的无图像多模态机器翻译 [PDF](https://arxiv.org/pdf/2507.18562), [HTML](https://arxiv.org/abs/2507.18562)
### Authors
Jiafeng Xiong,Yuting Zhao
### Background
多模态机器翻译（MMT）已证明视觉信息对机器翻译的大有助益。然而，现有的MMT方法在利用视觉与语言模态之间的差距时遇到了挑战，它们在严格的视觉-语言对齐的同时局限于其训练过的多模态领域内进行推断。
### Innovation
该论文构建了新的多模态场景图来保持并整合特定模态的信息，并引入了GIIFT框架，这是一种两阶段的图引导归纳无图像多模态机器翻译框架。该框架利用跨模态图注意力网络适配器在统一融合空间中学习多模态知识，并诱导性地将其推广到更广泛的无图像翻译领域。实验结果表明，GIIFT在没有图像的推断过程中超越了现有方法，并达到了最先进的水平。WMT基准上的结果展示了GIIFT在无图像推断中的优势。
### Conclusion
该研究在无图像翻译基准上取得了显著改进，证明了GIIFT在无图像归纳推断方面的强大能力。
## 257. `cs.CL` - 大型语言模型的道德差距 [PDF](https://arxiv.org/pdf/2507.18523), [HTML](https://arxiv.org/abs/2507.18523)
### Authors
Maciej Skorski,Alina Landowska
### Background
道德基础检测对于分析社会话语和开发伦理对齐的人工智能系统至关重要。虽然大型语言模型在多样化的任务中表现出色，但在专门的道德推理上的表现仍不明确。这项研究第一次全面比较了最新的大型语言模型和针对推特和Reddit数据集的微调变压器在ROA、PR和DET曲线分析上的表现。
### Innovation
研究采用ROC、PR和DET曲线分析的综合方法，首次全面比较了最新的大型语言模型和微调的变压器在Twitter和Reddit数据集上的表现，揭示了两者在道德推理任务中的显著性能差距。
### Conclusion
研究结果表明，针对特定任务的微调在道德推理应用中优于仅通过提示强化的方法，大型语言模型在道德内容的高误检率和系统性低估方面面临着挑战。
## 258. `cs.CL` - 使用字节对编码和k-mer方法的DNA语言模型混合分词策略 [PDF](https://arxiv.org/pdf/2507.18570), [HTML](https://arxiv.org/abs/2507.18570)
### Authors
Ganesh Sapkota,Md Hasibur Rahman
### Background
传统的k-mer分词方法虽然可以有效捕捉局部DNA序列结构，但存在分词不均衡和对全局序列上下文理解有限的问题。这篇论文提出了一种混合分词策略，通过结合6-mer分词和通过600个BPE循环生成的Byte Pair Encoding (BPE-600)分词，解决了这些局限性，使模型能够同时捕捉DNA序列中的短和长模式，从而提高DNA语言模型的性能。
### Innovation
提出了通过600个BPE循环生成的BPE-600分词，与独特的6mer分词结合，形成混合分词策略。该策略确保词汇表既均衡又具有上下文意识，使模型能够在同时捕捉DNA序列中的短和长模式时获得显著提升。这种混合分词策略显著提高了模型的预测准确率，尤其是在3-mer、4-mer和5-mer预测任务中，分别达到了10.78%、10.1%和4.12%的准确率，超过了现有最先进的模型（如NT、DNABERT2和GROVER）的表现。
### Conclusion
这种混合分词策略能够同时保留局部序列结构和全局上下文信息，显示出其在DNA建模中的优势。该研究强调了先进分词方法对于基因组语言建模的重要性，并为后续DNA序列分析和生物研究的下游应用奠定了坚实的基础。
## 259. `cs.CL` - 生成合成临床文本：系统综述 [PDF](https://arxiv.org/pdf/2507.18451), [HTML](https://arxiv.org/abs/2507.18451)
### Authors
Basel Alshaikhdeeb,Ahmed Abdelmonem Hemedan,Soumyabrata Ghosh,Irina Balaur,Venkata Satagopam
### Background
生成临床合成文本代表了解决临床自然语言处理（NLP）中普遍存在的稀疏性和隐私问题的有效解决方案。该论文旨在通过制定对生成的目的、技术、评价方法三个研究问题进行定量化分析，进行系统性综述。研究人员在PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv数据库中搜索与生成合成医学非结构化文本相关的出版物，共筛选出1,398篇论文中的94篇相关文章。
### Innovation
创新点在于通过定量分析对生成合成医学文本的目的、技术和评价方法进行系统性综述，特别指出自2018年以来，合成文本生成的关注度显著增加。主要使用了Transformer架构，尤其是GPT模型。评价方面以实用性为主，但隐私问题仍是主要挑战。
### Conclusion
生成的合成医学文本在不同的下游NLP任务中具有适度的可能性成为真实医学文件，作为增加了真实文件的补充，有助于提高准确性并解决稀疏性/欠抽样问题。然而，隐私问题仍然存在，需要更多的人工评估来确保不包含敏感信息。尽管如此，合成医学文本生成的进步将极大地加速工作流和管道开发的采用，消除数据传输的繁琐法律手续。
## 260. `cs.CL` - AQuilt: 将逻辑与自我审查编织入低成本、高相关性数据合成以专精大语言模型 [PDF](https://arxiv.org/pdf/2507.18584), [HTML](https://arxiv.org/abs/2507.18584)
### Authors
Xiaopeng Ke,Hexuan Deng,Xuebo Liu,Jun Rao,Zhenxi Song,Jun Yu,Min Zhang
### Background
尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域通常表现不佳。现有方法通常依赖数据合成技术，并通过使用未标记数据来捕捉专业知识特性，取得了令人鼓舞的结果，但这些方法要么计算成本高，要么性能受限，也无法有效跨不同任务进行泛化。现有方法无法充分满足这些挑战，亟需一种成本更低、效果更好的方法来解决这一问题。
### Innovation
作者提出了一种名为AQuilt的框架，它可以从相应的未标记数据中构建专门领域的指令调优数据，包括答案、问题、检查、逻辑和任务类型。AQuilt通过引入逻辑和检查促进推理过程和自我审查，从而提升模型表现。此框架还具有可定制的任务指令，以便高质量地生成任何任务的数据。通过这种方法，作者构建了一个包含703,000个示例的数据集来训练高效的数据合成模型。实验表明，在仅仅17%的生产成本下，AQuilt能达到与DeepSeek-V3媲美的效果。进一步分析显示，生成的数据与下游任务的相关性更高。
### Conclusion
作者提出AQuilt框架，通过引入逻辑和检查机制，低成本高效地生成高质量数据以解决大型语言模型在特定任务上的不足，且生成的数据具有较高的下游任务相关性。
## 261. `cs.CL` - CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition [PDF](https://arxiv.org/pdf/2507.18580), [HTML](https://arxiv.org/abs/2507.18580)
### Authors
Jiahao Wang,Ramen Liu,Longhui Zhang,Jing Li
### Background
该论文提出了一个用于处理细粒度中文仇恨言论识别任务（FGCHSR）的系统，旨在改善现有技术在这方面的表现。背景信息表明，现有的基础模型如GPT-4o和微调后的Qwen2.5-7B在该任务上的性能较低，因此需要提出新的技术框架来提升模型的效果和稳定性。
### Innovation
该系统提出了一种新颖的SRAG-MAV框架，该框架结合了任务重述（TR）、自我检索增强生成（SRAG）和多轮累积投票（MAV）。具体来说，该方法将四元组提取任务重新表述为三元组提取，通过动态从训练集中检索内容来创建上下文提示，并通过多轮推理和投票来提高输出的稳定性和性能。与基线方法相比，该系统的性能显著提高，尤其是在公共数据集STATE ToxiCN上获得了更高的得分。
### Conclusion
基于Qwen2.5-7B模型的研究系统，在STATE ToxiCN数据集上取得了显著成果，获得了硬分值26.66，软分值48.35和平均分值37.505。这一成绩远超GPT-4o（平均分值15.63）和微调后的Qwen2.5-7B（平均分值35.365）。
## 262. `cs.CL` - 检查表优于奖励模型对语言模型进行对齐 [PDF](https://arxiv.org/pdf/2507.18624), [HTML](https://arxiv.org/abs/2507.18624)
### Authors
Vijay Viswanathan,Yanchao Sun,Shuang Ma,Xiang Kong,Meng Cao,Graham Neubig,Tongshuang Wu
### Background
语言模型必须适应用户指令，常规的做法是使用强化学习来帮助理解并遵循这些指令，通常使用固定的评价标准，如“帮助性”和“危害性”。本研究则提出了一个新的方法，使用灵活、特定于指令的评价标准来拓宽强化学习在指令遵循方面的应用范围。
### Innovation
提出的“检查表反馈强化学习”（Reinforcement Learning from Checklist Feedback, RLCF）方法，能够从指令中提取检查表，评估回答是否满足每个项目，并结合AI裁判和专门的验证程序的评分来计算奖励。相较于其他对齐方法，RLCF在五个广泛研究的基准测试中均提高了模型的性能，特别是在硬遵从率、信息量评价和竞技场中难度任务的胜利率方面。这表明检查表反馈是提升语言模型支持多种需求查询的关键工具。
### Conclusion
检查表反馈是一种有效的手段，可以大幅提升语言模型在满足多种需求查询时的表现。RLCF方法不仅验证了这一点，还为其他强化学习方法的应用提供了新的视角。
## 263. `cs.CL` - GenSelect：一种生成式N最优的方法 [PDF](https://arxiv.org/pdf/2507.17797), [HTML](https://arxiv.org/abs/2507.17797)
### Authors
Shubham Toshniwal,Ivan Sorokin,Aleksander Ficek,Ivan Moshkov,Igor Gitman
### Background
生成奖励模型通过并行采样使得在推理任务中的测试阶段扩展更加有效。当前的方法通常采用逐点评分或成对比较，但这些方法在利用大型语言模型的比较能力方面存在不足，且两两比较方法在更大的采样预算下扩展效率低效。
### Innovation
我们提出了GenSelect方法，其中大型语言模型使用长时间推理来从N个候选方案中选择最佳方案。该方法不仅利用了大型语言模型的比较优势，还在并行采样预算下实现了高效的扩展。对于数学推理任务，该方法展示了像QwQ和DeepSeek-R1-0528这样的推理模型的优越性，这些模型在GenSelect中表现出色，超过了现有简单提示下的评分方法的性能。
### Conclusion
GenSelect通过大型语言模型的长时间推理，从多个候选方案中高效地选择最优方案，从而同时利用了模型的比较优势和高效的扩展能力。对于数学推理任务，GenSelect优于现有的评分方法。
## 264. `cs.CL` - 探索数学问题解决中协作大语言模型代理的通信策略 [PDF](https://arxiv.org/pdf/2507.17753), [HTML](https://arxiv.org/abs/2507.17753)
### Authors
Liang Zhang,Xiaoming Zhai,Jionghao Lin,Jionghao Lin,Jennifer Kleiman,Diego Zapata-Rivera,Carol Forsyth,Yang Jiang,Xiangen Hu,Arthur C. Graesser
### Background
大语言模型（LLM）代理在人工智能辅助教育中的应用日益增多，主要用于教学和支持学习。有效的代理间沟通策略能够提高合作问题解决的效率，并促进教育中的成本效益采用。然而，很少有研究系统性地评估不同沟通策略对代理问题解决的影响。该研究利用OpenAI GPT-4o模型，在一个双代理、基于聊天的数学问题解决环境中，评估了四种沟通模式：师生互动、同伴间合作、互惠同伴教学和批判性辩论，旨在探讨这些模型的有效性。
### Innovation
研究首次详细评估了多种沟通模式在数学问题解决中的效果，并发现同伴间合作的准确性最高。研究还揭示了陈述、认可和提示等对话行为对合作问题解决的作用，强调了多代理框架在计算任务中的优势，同时也突出了有效沟通策略对于处理AI教育中的复杂问题的重要性。
### Conclusion
研究表明，双代理设置优于单代理，而同伴间合作模式在数学问题解决中的准确性最高。有效的对话行为（如陈述、认可和提示）对于合作问题解决至关重要。多代理框架虽能增强计算任务处理能力，但有效的沟通策略对于解决复杂的AI教育问题是必不可少的。
## 265. `cs.CL` - Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs [PDF](https://arxiv.org/pdf/2507.18578), [HTML](https://arxiv.org/abs/2507.18578)
### Authors
Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao
### Background
Diffusion Large Language Models (DLLMs)作为一种快速并行生成的替代自回归模型出现了。但现有的DLLMs面临一个严重的质量和速度权衡问题：更快的并行解码会导致性能显著下降。这主要是因为标准DLLMs解码的不可逆性，容易导致错误的解码方向和早期错误上下文的累积。
### Innovation
引入了一种名为Wide-In, Narrow-Out (WINO)的无需训练的解码算法，用于在DLLMs中实现可撤销解码。WINO采用并行草案和验证机制，在并行生成多个令牌的同时使用模型的双向上下文来验证并重新屏蔽可疑的令牌进行优化。
### Conclusion
在开源DLLMs如LLaDA和MMaDA上进行的实验表明，WINO显著改善了质量和速度权衡。例如，在GSM8K数学基准测试中，它将推理加速了6倍，并提高了2.58%的准确性；在Flickr30K描述中，它实现了10倍的加速，并且性能更高。更多的实验进一步证实了WINO的优势并对其展开了深入研究。
## 266. `cs.CL` - Group Sequence Policy Optimization [PDF](https://arxiv.org/pdf/2507.18071), [HTML](https://arxiv.org/abs/2507.18071)
### Authors
Chujie Zheng,Shixuan Liu,Mingze Li,Xiong-Hui Chen,Bowen Yu,Chang Gao,Kai Dang,Yuqiong Liu,Rui Men,An Yang,Jingren Zhou,Junyang Lin
### Background
该论文介绍了一种名为Group Sequence Policy Optimization（GSPO）的稳定、高效且高性能的强化学习算法，用于训练大型语言模型。传统的强化学习算法采用基于token级别的重要性比率，而GSPO则基于序列似然性定义重要性比率，并且在序列层面进行剪辑、奖励和优化。
### Innovation
GSPO通过对序列似然性的利用并进行序列层面的调整，实现了比GRPO算法更优的训练效率和性能，特别在混合专家（MoE）强化学习训练方面表现出更强的稳定性。此外，由于GSPO的优点，它有可能简化RL基础设施的设计，为最近的Qwen3模型带来了显著的改进效果。
### Conclusion
GSPO使得Qwen3模型在训练效率和性能方面取得了显著的提升，并为设计RL基础设施提供了新的思路，具有简化复杂性的潜力。
## 267. `cs.CL` - Agentic AI框架用于端到端医疗数据推断 [PDF](https://arxiv.org/pdf/2507.18115), [HTML](https://arxiv.org/abs/2507.18115)
### Authors
Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha
### Background
在医疗领域构建和部署机器学习解决方案仍然是昂贵且劳动密集的，原因包括数据预处理工作流碎片化、模型兼容性问题和严格的隐私约束。
### Innovation
本文介绍了一种代理AI框架，该框架通过一个模块化、任务特定的代理系统自动化整个临床数据管道，从数据摄取到推理。它能够自动处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理建议，而无需人工干预。该系统已在老年科、姑息照护和结肠镜检查影像的公开数据集上进行了评估，展示了其在数据处理和模型应用方面的优势，特别是在结构化数据（如焦虑数据）和非结构化数据（如结肠镜检查息肉数据）的处理上。
### Conclusion
通过自动化ML生命周期中的高摩擦阶段，提出的框架减少了重复专家介入的需求，提供了在临床环境中规模化、成本效益高的AI实现途径。
## 268. `cs.CL` - BadReasoner：在大型推理模型中植入可控过度思考后门以获取乐趣或利益 [PDF](https://arxiv.org/pdf/2507.18305), [HTML](https://arxiv.org/abs/2507.18305)
### Authors
Biao Yi,Zekun Fei,Jianing Geng,Tong Li,Lihai Nie,Zheli Liu,Yiming Li
### Background
大型推理模型（LRMs）作为人工智能领域的一大进步，是用于处理复杂推理任务的大型语言模型（LLMs）的一种特殊类别。LRMs的特点在于其广泛的链式思考（CoT）推理能力。尽管这类模型在很多方面表现出色，但当前对LRMs的安全性研究，特别是攻击面的探索尚不充分，尤其是未专门针对其深入推理机制进行攻击。
### Innovation
作者揭示了一个先前未被研究的对LRMs的攻击向量，称为“过度思考后门”（Overthinking backdoors），并提出了一种可调式后门攻击方法。这种攻击与传统的开/关型攻击不同，攻击者能够精确控制模型推理的详细程度。该攻击利用了一种新颖的数据污染方法，通过一个可调的触发机制（重复次数）和相应的冗余CoT响应来实现。触发机制由一个教师LLM编程生成，它将一定数量的冗余完善步骤注入正确的推理过程。
### Conclusion
实验研究表明，该方法能够在不影响最终答案准确性的情况下，可靠地触发推理过程长度的可控多倍增加。该研究表明，该攻击的主要危害在于资源消耗，而非破坏模型的最终输出。作者公开了源代码，供其他研究者参考和进一步研究。
## 269. `cs.CL` - Distant Conversational Speech Recognition研究进展：CHiME-7和8远场对话识别挑战 [PDF](https://arxiv.org/pdf/2507.18161), [HTML](https://arxiv.org/abs/2507.18161)
### Authors
Samuele Cornell,Christoph Boeddeker,Taejin Park,He Huang,Desh Raj,Matthew Wiesner,Yoshiki Masuyama,Xuankai Chang,Zhong-Qiu Wang,Stefano Squartini,Paola Garcia,Shinji Watanabe
### Background
CHiME-7和CHiME-8远场对话识别(DASR)挑战侧重于多通道、通用性强的语音识别(ASR)和会话对话的说话人辨识(diarization)。此次挑战吸引了9支队伍提交了32套各异的系统，促进了该领域最先进的研究成果。研究详细描述了挑战的设计、评估指标、数据集及基准系统，并分析了参与者提交的几个关键趋势。
### Innovation
研究发现主要有以下创新点：（1）大多数参赛者使用端到端（E2E）ASR系统，这是由于大型预训练模型的广泛应用，降低了E2E ASR的数据需求负担。（2）尽管神经信号分离和增强（SSE）技术近期有显著进步，但所有参赛队伍仍然依赖于指导源分离，显示出当前神经SSE技术在处理复杂场景和不同录音设置时仍具局限性。（3）所有最佳系统都采用了说话人识别技术对第一轮的说话人辨识进行细化，准确的第一轮说话人计数至关重要。CHiME-8的参赛者尤其关注这一部分。（4）通过会议总结的下游评估与转录质量之间的关联性较弱，表明大型语言模型在处理错误方面的显著效果。（5）尽管取得了进展，但在复杂声学环境中准确转录自然对话依然困难，即便使用计算密集型系统组合也不例外。
### Conclusion
研究表明，远场对话识别面临着许多挑战，尤其是复杂的声学环境和说话人辨识中的问题。然而，通过改进E2E ASR模型和引导源分离技术，这些挑战有望在未来得到解决。研究还强调了准确的第一轮说话人计数对于避免复合错误的重要性，并指出大型语言模型在处理错误方面的有效性。
## 270. `cs.CL` - TRPrompt: 从文本奖励启动查询感知提示优化 [PDF](https://arxiv.org/pdf/2507.18618), [HTML](https://arxiv.org/abs/2507.18618)
### Authors
Andreea Nica,Ivan Zakazov,Nicolas Mario Baldwin,Saibo Geng,Robert West
### Background
大型语言模型（LLMs）的推理能力可以通过提示优化来提升，而无需更新目标模型的参数。现有的方法主要分为两类：一类利用文本反馈从通用LLM中直接生成改进的提示，无需训练；另一类则依赖数值奖励来训练专门的提示模型，以提供最优的提示给目标模型。本文介绍了一种名为TRPrompt的框架，它通过直接将文本反馈纳入提示模型的训练中，统一了这两种方法。
### Innovation
TRPrompt框架通过将文本反馈直接融入提示模型的训练中，克服了之前方法的限制。它无需收集先验数据集，并且可以通过反馈机制不断提升。结合LLM对“良好”提示的理解，TRPrompt利用高精度的文本奖励信号，训练出针对难题数学数据集（GSMHard和MATH）的最优查询特定提示。
### Conclusion
TRPrompt框架通过直接利用文本奖励，实现了无需参数更新即可优化提示的方法，展示了在复杂数学问题上的卓越性能，为提示优化领域带来了新的研究视角。
## 271. `cs.CL` - LoRA-Leak: 针对基于LoRA微调语言模型的成员推断攻击 [PDF](https://arxiv.org/pdf/2507.18302), [HTML](https://arxiv.org/abs/2507.18302)
### Authors
Delong Ran,Xinlei He,Tianshuo Cong,Anyu Wang,Qi Li,Xiaoyun Wang
### Background
语言模型通常遵循‘预训练和微调’模式，预训练模型可以微调以适应各种专业领域。低秩适应（LoRA）因其轻量级的计算成本和优异的表现，在语言模型的微调中得到了最广泛的应用。尽管LoRA微调的参数量较小，可能会让人误以为LoRA微调数据对成员推断攻击（MIAs）是免疫的，但现有研究忽视了利用预训练模型引起的更多信息泄露。因此，本文介绍了一种名为LoRA-Leak的整体评估框架，该框架结合了十五种成员推断攻击，包括五种新利用预训练模型作为参考的改进攻击，以评估针对语言模型微调数据的成员推断攻击风险。
### Innovation
本文提出了一种新的评估框架LoRA-Leak，用于评估针对LoRA微调语言模型的成员推断攻击。LoRA-Leak采用了十五种成员推断攻击，包括五种利用预训练模型作为参考的改进攻击，以全面评估LoRA微调语言模型的数据隐私风险。实验表明，即使在保守的微调设置下，基于LoRA的微调语言模型仍然存在显著的成员推断攻击风险，并且只有丢弃和排除特定语言模型层的微调才能有效减少这一风险而不影响实用性。此外，研究指出，在‘预训练和微调’框架下，预训练模型的存在使得基于LoRA的语言模型面临更加严重的成员推断攻击风险。
### Conclusion
本文的研究结果表明，基于LoRA的微调语言模型依然易受到成员推断攻击，并提出了一些有效的防御措施，如随机丢弃和排除特定语言模型层，以减轻成员推断攻击的风险。研究者希望能为专语言模型的数据隐私保护提供指导。
## 272. `cs.CL` - 基于LLM的嵌入器在优先案例检索中的应用 [PDF](https://arxiv.org/pdf/2507.18455), [HTML](https://arxiv.org/abs/2507.18455)
### Authors
Damith Premasiri,Tharindu Ranasinghe,Ruslan Mitkov
### Background
在普通法系统中，法律从业者如律师和法官依赖先例来构建他们的论据。随着时间的推移，案件数量大幅增加，有效地检索先前案例变得至关重要。先例检索（PCR）是一个信息检索（IR）任务，旨在从大量潜在候选案例中自动识别与特定查询最相关的法院案例。尽管近年来信息检索方法发生了几次范式转变，但大多数PCR方法仍然依赖传统的IR方法，如BM25。最新的深度学习IR方法在PCR中不成功，主要是因为两个关键挑战：i. 长法律文本限制；当使用强大的BERT基-semibold_text>台变压器模型时，输入文本长度有限，不可避免地需要通过截断或分割来缩短输入，导致信息丢失。ii. 缺乏法律训练数据；由于数据隐私问题，可用的PCR数据集往往规模有限，使得基于深度学习模型的有效训练变得困难。因此，PCR任务仍主要依赖传统方法。
### Innovation
本研究通过利用基于LLM的文本嵌入器解决了这些挑战。基于LLM的嵌入器支持更长的输入长度，并且因为我们以无监督的方式使用它们，因此不需要训练数据，可以同时解决上述两个挑战。本研究在四个PCR基准数据集上评估了状态最先进基于LLM的文本嵌入器，并表明它们优于BM25和监督下的变压器模型。
### Conclusion
本研究通过使用基于LLM的文本嵌入器解决了PCR任务中的两个主要挑战：i. 长法律文本限制；ii. 缺乏法律训练数据。实验结果表明，基于LLM的方法优于传统方法，证明了该技术在PCR中的优势和潜力。
## 273. `cs.CL` - RECALLED: 对大型视觉语言模型的一种无界资源消耗攻击 [PDF](https://arxiv.org/pdf/2507.18053), [HTML](https://arxiv.org/abs/2507.18053)
### Authors
Haoran Gao,Yuanhe Zhang,Zhenhong Zhou,Lei Jiang,Fanyu Meng,Yujia Xiao,Kun Wang,Yang Liu,Junlan Feng
### Background
资源消耗攻击（RCAs）已成为大型语言模型（LLMs）部署中的重要威胁。随着视觉模态的整合，额外的攻击向量增加了大型视觉-语言模型（LVLMs）中RCAs风险。目前的红队研究大多忽略了视觉输入作为潜在攻击面的可能性，从而缺乏针对LVLMs的RCAs缓解策略。本文旨在弥补这一缺口。
### Innovation
本文提出了RECALLED（针对大型视觉-语言模型的资源消耗攻击），这是首次利用视觉模态触发无界RCAs红队的方法。该方法包括：1）视觉引导优化作为精细化像素级优化，以获得诱导重复输出的输出召回对抗扰动；2）将扰动注入视觉输入以触发无界生成；3）引入多目标并行损失以生成通用攻击模板，并解决并行攻击的优化冲突。
### Conclusion
实验结果表明，RECALLED通过超过26%的服务响应延迟增加，导致GPU利用率和内存消耗分别增加20%。本文揭示了LVLMs的安全漏洞并建立了红队框架，为未来的RCAs防御发展奠定了基础。
## 274. `cs.CL` - PosterMate: 基于受众驱动的合作型角色代理用于海报设计 [PDF](https://arxiv.org/pdf/2507.18572), [HTML](https://arxiv.org/abs/2507.18572)
### Authors
Donghoon Shin,Daniel Lee,Gary Hsieh,Gromit Yeuk-Yin Chan
### Background
海报设计可以从目标受众的同步反馈中受益，但召集具有不同视角的受众并对其设计修改达成一致具有挑战性。最近的生成式AI模型提供了模拟人类交互的机会，但尚未明确如何用于设计中的反馈过程。
### Innovation
我们引入了PosterMate，一种促进协作的海报设计助手，通过从营销文档构建受众驱动的人格代理来实现。PosterMate收集每个角色代理关于海报组件的反馈，并在帮助下形成讨论达成共识。这些一致的编辑可以直接集成到海报设计中。研究表明，PosterMate能够捕捉被忽略的观点，同时作为有效的原型工具。另外，实验证明个体角色代理提供的反馈与其角色身份相符，讨论有效地综合了不同角色代理的观点。
### Conclusion
我们的用户研究和在线控制评估表明，PosterMate具有捕捉被忽略观点的潜力，同时作为有效的原型工具。角色代理提供的反馈与其身份相符，讨论有效综合了不同代理的观点。
## 275. `cs.CL` - 恢复节奏：使用变换器模型为孟加拉语（一种低资源语言）恢复标点符号 [PDF](https://arxiv.org/pdf/2507.18448), [HTML](https://arxiv.org/abs/2507.18448)
### Authors
Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu
### Background
标点符号的恢复增强了文本的可读性，对于自动语音识别（ASR）的后处理任务至关重要，特别是在低资源语言如孟加拉语中。这项研究探讨了使用基于变换器的模型（特别是XLM-RoBERTa-large）自动恢复未标点孟加拉文本中的标点符号的应用。
### Innovation
构建了一个大型多样的训练语料库，并应用了数据增强技术，通过这些方法解决了标注资源稀缺的问题。最佳性能模型在News测试集上的准确率为97.1%，在Reference集上的准确率为91.2%，在ASR集上的准确率为90.2%。结果表明，该模型在真实世界、嘈杂场景中具有较强的一般化能力。
### Conclusion
该研究为孟加拉语标点符号恢复建立了强大的基线，并公开提供了数据集和代码，以支持未来低资源自然语言处理（NLP）研究。
## 276. `cs.CL` - SafeWork-R1: 在AI-45°定律下共进化安全与智能 [PDF](https://arxiv.org/pdf/2507.18576), [HTML](https://arxiv.org/abs/2507.18576)
### Authors
Shanghai AI Lab:Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu
### Background
在当前的人工智能研究中，多数方法侧重于纯粹的性能提升，而缺乏对系统安全性的关注。传统的对齐方法如RLHF仅学习人类偏好，但在确保系统安全上的局限性显而易见。因此，有必要开发一种既能提升性能又能在训练后保持安全性的新型方法。
### Innovation
本文介绍了SafeWork-R1，这是一种结合了SafeLadder框架的先进多模态推理模型。SafeLadder框架通过大型、分步、以安全为导向的强化学习后训练，以及一整套多原则的验证器支持，使模型能够发展出内在的安全推理和自我反思能力。SafeWork-R1在不牺牲通用能力的前提下，安全相关的基准测试平均提高了46.54%，且性能超越了GPT-4.1和Claude Opus 4等领先专有模型。此外，作者还实施了两种不同推理时的干预方法和一种审慎搜索机制，进一步增强其可靠性。
### Conclusion
所有衍生模型（包括SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B）表明，系统的安全性和能力可以协同进化，这突显了SafeLadder框架在构建强大、可靠和可信赖的一般人工智能方面的普适性。
## 277. `cs.CL` - 量化总统言论的独特性与分裂性 [PDF](https://arxiv.org/pdf/2401.01405), [HTML](https://arxiv.org/abs/2401.01405)
### Authors
Karen Zhou,Alexander A. Meitus,Milo Chase,Grace Wang,Anne Mykland,William Howell,Chenhao Tan
### Background
本研究探讨了美国总统的言论是否在不同人之间存在可辨别的差异，以及这些差异是否局限于特定的沟通渠道。为了回答这些问题，作者使用大型语言模型开发了一种新的独特性度量标准，创建了一套针对分裂性言论的新词汇，并提出了评估总统在谈论政治对手时独特方式的框架。研究发现，唐纳德·特朗普的演讲模式与近现代主要政党候选人的模式有很大的不同。特朗普的言论显示出比其他共和党候选人更加独特，而共和党候选人的独特性程度更接近民主党候选人。特朗普在这方面表现出的差异性，与他使用分裂性和对抗性语言，尤其是在针对政治对手时，直接相关。这种差异跨越了多种测量策略，并且可以在竞选活动中和正式的总统讲话中观察到，似乎是由于语境的变化导致的结果。
### Innovation
本研究的创新之处在于使用大型语言模型集成了新的独特性度量标准，创造了一套区分性语言的词汇，并提出了一种评估总统言论独特性的框架。这些新方法能够更准确地衡量总统言论的独特性和对抗性，同时也能够将这些差异区分出来，并且这些差异不仅体现在竞选演讲中，也在正式的总统讲话中出现。
### Conclusion
本研究发现，唐纳德·特朗普的演讲模式在近现代主要政党候选人的选举演讲中是有显著差异的。特朗普的语言表现得更加独特和分裂，尤其是在针对政治对手时。这种独特性不仅仅局限于一种测量方式，也不受限于特定的沟通渠道，而是贯穿于竞选活动和正式的总统讲话中，暗示了这是一种有意为之的现象，而不是由于语境变化带来的结果。
## 278. `cs.CL` - Bob的纸屑：音乐与视频生成中的音素记忆攻击 [PDF](https://arxiv.org/pdf/2507.17937), [HTML](https://arxiv.org/abs/2507.17937)
### Authors
Jaechul Roh,Zachary Novack,Yuefeng Peng,Niloofar Mireshghallah,Taylor Berg-Kirkpatrick,Amir Houmansadr
### Background
歌词到歌曲（LS2）生成模型允诺从文本实现端到端的音乐合成，但它们在训练数据记忆化方面仍然存在未被充分探索的脆弱性。本文介绍了一种名为Adversarial PhoneTic Prompting (APT) 的新颖攻击方法，该方法通过对歌词进行语义修改同时保留其声学结构（如 Eminem 的著名歌词“mom's spaghetti”转化为“Bob's confetti”进行同音替代），揭示了强大的次字节记忆化现象：类似于SUNO和YuE这样的模型会生成与已知训练内容高度相似的输出，跨越音频域指标（如CLAP, AudioJudge, CoverID）实现高相似度。这种情况在多种语言和音乐类型中都存在。更令人惊讶的是，对音素修改的歌词进行提示还能触发文本到视频模型的视觉记忆。当用Lose Yourself的音素修改歌词来提示时，Veo 3重建了原始音乐视频中的视觉元素——包括人物形象和场景布局——尽管提示中没有任何视觉线索。
### Innovation
本文提出了一种新颖的语素替代攻击方法，即Adversarial PhoneTic Prompting (APT)，在模型生成过程中实现对词义的语义修改但保留声学结构。这种攻击揭示词素级别的记忆化现象在多种语言和音乐类型中普遍存在，并且能够触发文本到视频模型中的视觉记忆，展示了音频视觉内容在多种生成系统中的记忆表现。
### Conclusion
本文的研究表明，生成系统中的转录条件下的多模态生成存在一个关键性漏洞：仅通过音素提示即可解锁记忆中的音频视觉内容，这引发了一系列关于现代生成系统中的版权、安全和内容来源的重大问题。例如，通过我们的demo页面可以获得生成结果的实例。
## 279. `cs.CL` - VolDoGer: LLM辅助的视觉-语言领域泛化数据集 [PDF](https://arxiv.org/pdf/2407.19795), [HTML](https://arxiv.org/abs/2407.19795)
### Authors
Juhwan Choi,Junehyoung Kwon,JungMin Yun,Seunguk Yu,YoungBin Kim
### Background
领域泛化是深度学习模型的重要方面，因为它决定了模型在未见过领域的数据上表现的能力。然而，针对视觉-语言任务中的深度学习模型的领域泛化性研究受到限制，主要由于缺少必需的数据集。因此，需要开发新的数据集来解决这一问题，以便进行更广泛的模型性能评估和研究视觉-语言任务的领域泛化能力。
### Innovation
提出VolDoGer：专门为视觉-语言领域泛化设计的专用数据集，涵盖图像字幕、视觉问答和视觉蕴含三个视觉-语言任务。通过利用基于LLM的数据注释技术，减轻了招募人力注释者的负担，并为各种模型（从微调模型到最近的多模态大型语言模型）的领域泛化性能评估提供了平台。
### Conclusion
VolDoGer数据集为视觉-语言任务中的领域泛化研究提供了新的平台，可以帮助研究者更好地理解模型的泛化能力，并推动相关技术的进步。
## 280. `cs.CL` - 因果测试LLMs中的性别偏差：职业偏差案例研究 [PDF](https://arxiv.org/pdf/2212.10678), [HTML](https://arxiv.org/abs/2212.10678)
### Authors
Yuen Chen,Vethavikashini Chithrra Raghuram,Justus Mattern,Rada Mihalcea,Zhijing Jin
### Background
大型语言模型（LLMs）生成的文本显示出各种各样的针对不同群体的有害、类似人类的偏见。这些发现推动了研究努力，旨在理解并测量这些效应。已有研究显示这些模型在职业性别偏见方面存在显著差异。
### Innovation
该论文提出了一种因果形式化方法来测量生成语言模型中的性别偏见，并构造了一个名为OccuGender的基准测试以研究职业性别偏见。此外，论文还讨论了偏见缓解的提示策略，并扩展了因果形式化方法以展示其普遍性。
### Conclusion
实验结果显示，几种最先进的开源LLMs，在OccuGender上表现出显著的职业性别偏见。研究还提出了缓解偏见的提示策略，并展示了该因果方法框架的普适性。
## 281. `cs.CL` - GRR-CoCa：在多模态模型架构中利用大语言模型机制 [PDF](https://arxiv.org/pdf/2507.18009), [HTML](https://arxiv.org/abs/2507.18009)
### Authors
Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi
### Background
当前最先进的图像和文本生成模型主要是多模态模型，与大型语言模型有许多相似之处。尽管这些模型实现了很强的性能，但领先的多模态模型架构在架构复杂性上仍然落后于当代大型语言模型。
### Innovation
本文提出了一种改进的最先进对比式 Captioner (CoCa) 模型 —— GRR-CoCa。GRR-CoCa 模型在文本解码器和视觉变换器（ViT）编码器中引入了高斯误差门控线性单元（GLELU）、均方根规范化（RMSNorm）和旋转位置嵌入。这些架构上的每一次改进已经在大语言模型中显示出性能提升的效果，但在 CoCa 中尚未被采用。
### Conclusion
与拥有相同修改文本解码器但使用 CoCa 原始 ViT 编码器的基准 CoCa 模型进行了基准测试。GRR-CoCa 在预训练数据集和三个不同的微调数据集上显著优于基准 CoCa 模型。预训练增益分别是对比损失 27.25%、困惑度 3.71%、CoCa 损失 7.15%。平均微调增益分别是对比损失 13.66%、困惑度 5.18%、CoCa 损失 5.55%。实验验证了 GRR-CoCa 改进的架构在视觉-语言领域中提升了性能和泛化能力。
## 282. `cs.CL` - Generative AI内容审核中的身份相关言论抑制 [PDF](https://arxiv.org/pdf/2409.13725), [HTML](https://arxiv.org/abs/2409.13725)
### Authors
Grace Proebsting,Oghenefejiro Isaacs Anigboro,Charlie M. Crawford,Danaé Metaxa,Sorelle A. Friedler
### Background
自动化内容审核长期用于识别和过滤用户生成内容中的不当内容。这种系统过去曾错误地标记涉及边缘化群体身份的内容，导致其被移除。生成式AI系统现在使用这些过滤器，阻止不希望出现的内容被生成或展示给用户。虽然大多数关注点集中在确保此类系统不会产生不希望的结果，但适当文本生成的保障则不足。从教室到好莱坞，随着生成式AI越来越多地用于创意或表达性文本生成，这些技术将允许讲述谁的故事，又会抑制谁的故事？
### Innovation
本文定义并引入了衡量言论抑制的指标，主要集中在错误被多种内容审核API过滤的身份相关言论上。使用短形式的用户生成的数据集和更长的生成式AI相关的数据集，创建了一个衡量九个身份群体言论抑制的基准，涵盖了一种传统的内容审核服务和四种生成式AI导向的服务。结果发现，与身份相关的内容比其他内容更可能被错误抑制，不同的身份群体因刻板印象和文本关联而有不同的错误标记原因，残疾相关的内容更可能因为自我伤害或健康原因被标记，非基督教内容更可能因为暴力或仇恨内容被标记。
### Conclusion
随着生成式AI系统越来越多地用于创意工作，建议进一步关注这种现象如何影响身份相关内容的创作。
## 283. `cs.CL` - DocTER：基于文档的知识编辑评估 [PDF](https://arxiv.org/pdf/2308.09954), [HTML](https://arxiv.org/abs/2308.09954)
### Authors
Suhang Wu,Ante Wang,Minlong Peng,Yujie Lin,Wenbo Li,Mingming Sun,Jinsong Su
### Background
知识编辑的目标是纠正神经网络中的过时或不准确的知识。以往的研究通常使用手动标注的事实三元组来实现这一目标。本文作者探讨了使用容易获取的文档来执行知识编辑的方法，而不是使用这些三元组。
### Innovation
本文建立了首个评估基准DocTER，包含用于编辑的反事实知识的文档。引入了全面的四维评估方法：编辑成功率、局部性、推理能力和跨语言迁移。开发了提取然后编辑的管道，以便将传统的三元组基编辑方法适应于基于文档的任务。
### Conclusion
基于文档的知识编辑面对着比基于三元组更多挑战。即使最好的上下文编辑方法，其编辑成功率依然比使用黄金三元组低10分。对于推理解析和跨语言测试集也是一样的。同时，对任务性能影响的关键因素进行了分析，提供了对未来研究有价值的见解。
## 284. `cs.CL` - LIFBench: 在长上下文场景中评估大型语言模型的指令遵循性能和稳定性 [PDF](https://arxiv.org/pdf/2411.07037), [HTML](https://arxiv.org/abs/2411.07037)
### Authors
Xiaodong Wu,Minhao Wang,Yichen Liu,Xiaoming Shi,He Yan,Xiangju Lu,Junmin Zhu,Wei Zhang
### Background
随着大型语言模型（LLMs）在自然语言处理（NLP）中的发展，它们在长上下文中的稳定指令遵循能力变得对实际应用至关重要。然而，现有的基准测试很少关注长上下文中的指令遵循和在不同输入上的稳定性。为了弥合这一差距，我们引入了LIFBench，这是一个扩大的数据集，用于评估LLMs在长上下文中的指令遵循能力和稳定性。LIFBench包括三个长上下文场景和十一个多样任务，共有2,766条通过自动化扩展方法生成的指令，分别基于长度、表达和变量三个维度进行。
### Innovation
我们提出了LIFEval，一种基于评级的评估方法，能够对复杂的LLM响应进行精确、自动评分，而无需依赖LLM辅助评估或人类判断。这种方法允许从多个角度全面分析模型性能和稳定性。我们在六个长度间隔内对20个主要的LLM进行了详细的实验。我们的研究贡献了LIFBench和LIFEval，作为评估LLM在复杂和长上下文设置中的性能的强大工具，为未来LLM的发展提供了有价值的见解。
### Conclusion
我们的工作贡献了LIFBench和LIFEval，作为评估LLM在复杂和长上下文设置中的性能的稳健工具，提供了对未来LLM发展的有价值的见解。
## 285. `cs.CL` - SynC: 使用一对一到多对映射精细合成图像字幕数据集以增强零样本图像字幕 [PDF](https://arxiv.org/pdf/2507.18616), [HTML](https://arxiv.org/abs/2507.18616)
### Authors
Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim
### Background
零样本图像字幕（ZIC）越来越多地利用由文本到图像（T2I）模型生成的合成数据集，以减少对昂贵的手动标注的需求。然而，这些T2I模型通常生成的图像与输入的文本描述之间存在语义对齐问题（例如缺失对象、属性错误），导致合成图像字幕对存在噪声，进而影响模型训练。现有的数据集精简技术主要设计用于去除网络爬取数据中的噪声文本，但对于合成数据的特殊挑战（即，描述往往准确）显得不适配。现有方法未能有效解决合成数据集特有的噪声和语义对齐问题。
### Innovation
为了填补这一空白，本文提出了一种名为SynC的新型框架，专门针对ZIC情境下精细合成图像字幕数据集。SynC采用一对一到多对映射策略，首先为每个字幕检索多个相关候选图像，然后使用受循环一致性启发的对齐评分器，通过验证图像能否通过图像到文本检索召回原始字幕，确定最佳匹配。广泛的评估表明，SynC方法不仅显著提高了多个ZIC模型在标准基准数据集（MS-COCO，Flickr30k，NoCaps）上的性能，还在某些场景中实现了最先进的结果。
### Conclusion
SynC提供了一种有效的策略，用于精炼合成数据以增强零样本图像字幕任务的性能。该方法通过改进合成数据集的质量，显著提升了ZIC模型的性能，特别是在多个标准数据集上表现突出。
## 286. `cs.CL` - 事件因果识别: 分类、挑战、评估与展望 [PDF](https://arxiv.org/pdf/2411.10371), [HTML](https://arxiv.org/abs/2411.10371)
### Authors
Qing Cheng,Zefan Zeng,Xingchen Hu,Yuehang Si,Zhong Liu
### Background
事件因果识别（ECI）在自然语言处理（NLP）中成为一个必不可少的任务，专注于在文本中自动检测事件之间的因果关系。这篇综述全面探讨了基础概念和模型，发展了一种系统分类方法，并对多种模型进行了批判性评估。从核心概念的定义、ECI问题的正式化和标准评估协议的概述开始，论文将ECI模型分为两个主要任务：句子层面的事件因果识别（SECI）和文档层面的事件因果识别（DECI），并详细讨论了这两种任务的模型和方法。
### Innovation
论文系统地调查了基础概念和模型，发展了一种系统分类方法，并对多种模型进行了批判性评估。特别关注了多语言和跨语言ECI的最新进展，以及大规模语言模型（LLMs）在零样本ECI中的应用。它详细分析了每种方法的优势、局限性和未解决的挑战，并进行了多种ECI模型的严格评估。
### Conclusion
论文最后讨论了未来的研究方向，强调了推进该领域进一步发展的机会。
## 287. `cs.CL` - LLM对齐作为检索优化：从信息检索视角来看 [PDF](https://arxiv.org/pdf/2502.03699), [HTML](https://arxiv.org/abs/2502.03699)
### Authors
Bowen Jin,Jinsung Yoon,Zhen Qin,Ziqi Wang,Wei Xiong,Yu Meng,Jiawei Han,Sercan O. Arik
### Background
大规模语言模型（LLMs）已经通过推理、编码和沟通能力革新了人工智能，并在各行业中推动了创新。它们的真正潜力取决于有效的对齐，确保正确的、可信赖的和道德的行为，解决诸如虚假信息、幻觉、偏见和滥用等挑战。尽管现有的基于强化学习（RL）的对齐方法非常复杂，但直接优化方法提供了一种更为简单的选择。
### Innovation
本文介绍了一种新的直接优化方法LarPO（LLM Alignment as Retriever Preference Optimization），该方法借鉴了信息检索（IR）的原理，将LLM生成和奖励模型映射到IR的检索-重排序范式上。该方法的有效性通过广泛的实验得到验证，平均分别在AlpacaEval2和MixEval-Hard中获得了38.9%和13.7%的提升。
### Conclusion
本研究通过结合信息检索的基础，为大规模语言模型（LLMs）的对齐开辟了新的途径，提供了一种有前景的研究方向。
## 288. `cs.CL` - 语言模型如何学习事实？规律、课程设置和幻觉 [PDF](https://arxiv.org/pdf/2503.21676), [HTML](https://arxiv.org/abs/2503.21676)
### Authors
Nicolas Zucchet,Jörg Bornschein,Stephanie Chan,Andrew Lampinen,Razvan Pascanu,Soham De
### Background
大型语言模型在预训练过程中积累了大量知识，但这些知识获取的动态过程尚不清楚。本文通过研究合成事实回忆任务中的语言模型学习动态，得出了三个关键发现：首先，语言模型在学习过程中分为三个阶段，在获得精确的事实知识前会出现一个性能停滞期，这个时期与基于注意力的记忆电路的形成有关。其次，训练数据分布对学习动态有显著影响，不平衡的数据分布会导致停滞期变短。最后，新知识的出现伴随着幻觉的产生，并通过微调将新知识整合到模型中非常困难，这会导致模型现有参数记忆的迅速破坏。研究结果强调了数据分布对知识获取的重要性，并建议了加速神经网络训练的新数据调度策略。
### Innovation
研究通过合成事实回忆任务分析了语言模型的学习动态，揭示了三个关键发现，分别是：多阶段学习过程、数据分布对学习动态的影响以及知识与幻觉同时出现的问题。这些发现改进了对语言模型如何学习事实的理解，并提供了优化神经网络训练的新方法。
### Conclusion
研究结果强调了数据分布对知识获取的重要性，并建议通过新的数据调度策略来加速神经网络的训练。这些发现丰富了我们对语言模型学习过程的理解，并为后续研究提供了指导。
## 289. `cs.CL` - P-React: 通过专门化LoRA专家混合体合成主题适应性个性特征反应 [PDF](https://arxiv.org/pdf/2406.12548), [HTML](https://arxiv.org/abs/2406.12548)
### Authors
Yuhao Dan,Jie Zhou,Qin Chen,Junfeng Tian,Liang He
### Background
个人化大型语言模型（LLMs）在情感支持和角色扮演等领域引起了广泛关注。然而，现有工作主要集中在建模显性的角色特征上，而忽视了真正的行为和决策背后的人格特质，阻碍了更具人性化且心理依据的AI系统的开发。
### Innovation
本文探讨了建模Big Five人格特质的方法，这是心理学中最常用的人格特质理论。我们提出了基于专家混合体（MoE）的个性化LLM——P-React。特别地，我们整合了个性专业化损失（PSL）来更好地捕捉个体特质表现，提供了更为细腻且心理依据的人格模拟。我们还精心策划了OCEAN-Chat，这是一个高质量的人类验证数据集，用于训练LLMs在不同主题下表达个性特质。
### Conclusion
广泛的实验表明，P-React在保持一致且真实的人格方面是有效的。
## 290. `cs.CL` - 无奖励模型和人类偏好数据的生成大型语言模型的辨别性微调 [PDF](https://arxiv.org/pdf/2502.18679), [HTML](https://arxiv.org/abs/2502.18679)
### Authors
Siqi Guo,Ilgee Hong,Vicente Balmaseda,Changlong Yu,Liang Qiu,Xin Liu,Haoming Jiang,Tuo Zhao,Tianbao Yang
### Background
监督微调（SFT）是使用包含输入-输出对的监督数据集对预训练的大语言模型（LLMs）进行对齐的关键步骤。尽管SFT是监督的，但它仍然受限于其生成训练目标。为了解决这一局限性，现有策略是在SFT之后采用偏好优化（PO），这依赖于人类标注的偏好数据或强大的奖励模型来指导学习过程。
### Innovation
本文通过探索传统监督学习中非常成功的辨别学习方法，提出了改进的SFT变体——辨别性微调（DFT）。DFT克服了收集人类标注偏好数据或训练强大奖励模型的负担，通过一个辨别性的方法增加了正确答案的概率并抑制了潜在的负向答案，而不是关注于 token 预测。主要贡献包括：（i）提出了一种辨别性概率框架来明确建模给定输入时所有可能输出中一个答案的辨别似然性；（ii）开发了优化这种辨别似然性的高效算法；（iii）通过广泛的实验展示了DFT的有效性，其性能优于SFT，并且在某些情况下甚至优于SFT→PO。
### Conclusion
本文通过引入辨别性微调（DFT），提供了无奖励模型和人类偏好数据的生成大型语言模型的微调方法，显著提升了模型的性能，证明了DFT的有效性和优势。
## 291. `cs.CL` - 利用具有多样化外部知识的LLMs增强自然语言到信号时空逻辑的转换 [PDF](https://arxiv.org/pdf/2505.20658), [HTML](https://arxiv.org/abs/2505.20658)
### Authors
Yue Fang,Zhi Jin,Jie An,Hongshen Chen,Xiaohong Chen,Naijun Zhan
### Background
Temporal Logic (TL)，尤其是Signal Temporal Logic (STL)，能够实现精确的形式化规范，已被广泛应用于诸如自主驾驶和机器人学等网络物理系统中。将自然语言（Natural Language，NL）自动转换为STL是克服手工转换耗时且易出错的限制的有吸引力的方法。但由于缺乏数据集，自动转换至今仍面临巨大挑战并未充分研究。目前，缺乏用于自动转换的充足且多样化数据集是一个关键问题。
### Innovation
该论文提出了名为STL-DivEn的新数据集，包含16,000个具有多样性的样本，并介绍了一种新的基于外部知识的STL生成方法，称为Knowledge-Guided STL Transformation (KGST)框架。KGST框架基于外部知识，采用先生成后精炼的过程来转换自然语言。分析显示，STL-DivEn数据集比现有数据集更具多样性，人类评估和基于度量的方法都表明，KGST方法在STL-DivEn和DeepSTL数据集上的转换准确性方面优于基线模型。
### Conclusion
该研究通过构建具有多样性的数据集和基于外部知识的新型转换框架，解决了自然语言到信号时空逻辑转换的准确性和多样性问题，为该领域的进一步研究提供了新的数据集和方法依据。
## 292. `cs.CL` - 利用个体差异建立沟通 [PDF](https://arxiv.org/pdf/2504.05211), [HTML](https://arxiv.org/abs/2504.05211)
### Authors
Richard A. Blythe,Casimir Fisch
### Background
建立沟通系统具有挑战性，因为信号初次发出时接收者对其意图含义不了解，而发出信号的一方也无法预见信号将如何被解读。大多数理论上关于沟通系统产生机制的解说都依赖于反馈机制，以强化那些导致成功沟通的行为。然而，提供反馈本身就要求已经能够传达意图或解释的含义，这就无法解释沟通如何从非沟通行为中启动。
### Innovation
本文提出了一种模型，表明在没有先验方法来判断沟通成功与否的情况下，大批量存在个体行为差异的群体中，能表达未预设数量意义的沟通体系可以自行形成。两个关键的认知能力是行为在给定情境中的可预测性，以及信号生成前的心理状态在共享意愿中的对齐。
### Conclusion
既然这两种能力可以独立于沟通而存在，我们的研究成果与那些认为大规模灵活的社会学习沟通系统（如语言）是社会认知一般且发展良好的产物的观点一致。
## 293. `cs.CL` - DR.EHR: 基于知识注入和合成数据的密集检索用于电子健康记录 [PDF](https://arxiv.org/pdf/2507.18583), [HTML](https://arxiv.org/abs/2507.18583)
### Authors
Zhengyun Zhao,Huaiyuan Ying,Yue Zhong,Sheng Yu
### Background
电子健康记录（EHRs）在临床实践中至关重要，但其检索仍面临挑战，主要是由于语义差距问题。尽管最近在密集检索方面的进展提供了有前景的解决方案，但现有的通用领域和生物医学领域模型因缺乏医学知识或训练语料库不匹配而表现不佳。
### Innovation
本文介绍了一种名为DR.EHR的密集检索模型系列，专门针对EHR检索。提出了一种两阶段训练管道，利用MIMIC-IV出院总结来解决需要广泛医学知识和大规训练数据的问题。第一阶段涉及从生物医学知识图谱中提取医学实体和注入知识，第二阶段利用大型语言模型生成多样化训练数据。训练了参数分别为110M和7B的两种DR.EHR的变体。在CliniQ基准测试上的评估表明，我们的模型显著优于所有现有的密集检索器，达到了最先进的结果。
### Conclusion
本文的工作显著推进了EHR检索，提供了一种适应临床应用的稳健解决方案，在各种匹配和查询类型中，特别是在复杂的语义匹配（如暗示和缩写）方面显示出优越性。消融研究验证了每个管道组件的有效性，而补充实验验证了模型在自然语言问题回答数据集上的泛化能力，包括包含多个实体的复杂问题。
## 294. `cs.CL` - 超越简介：从表面事实到深度人物仿真在大语言模型中的实现 [PDF](https://arxiv.org/pdf/2502.12988), [HTML](https://arxiv.org/abs/2502.12988)
### Authors
Zixiao Wang,Duzhen Zhang,Ishita Agrawal,Shen Gao,Le Song,Xiuying Chen
### Background
以往针对人物模拟的大语言模型（LLMs）方法大多局限于学习基本的生物信息或利用有限的角色扮演对话数据集来捕捉角色的回应。然而，一个个体的整体形象超出了表面事实或对话，涉及更深层次的想法和思维。本研究旨在通过分析作家作品中的语言和思维模式，建立一个更加全面的人物模型。
### Innovation
引入了CharacterBot模型，该模型旨在复刻角色在文本作品中展示的语言模式和思考模式。该研究提出了四个基于鲁迅作家的文章集的任务：预训练任务专注于掌握外部语言结构和知识，以及三个微调任务：多项选择题问答、生成性问答和风格转移，这些任务将大语言模型与鲁迅的内在意念和写作风格对接。为了优化跨这些任务的学习，引入了一个CharLoRA参数更新机制，该机制将通用语言风格专家与其他任务专家协作，以便更好地研究语言风格和更深层次的思维理解。
### Conclusion
CharacterBot在语言精度和意见理解的三个任务上表现出色，显著优于我们的基准指标。本研究希望激发未来深度人物形象仿真大语言模型研究的兴趣，同时强调伦理标准的重要性。
## 295. `cs.CL` - OPeRA: 用于评估大语言模型模拟人类在线购物行为的观察、角色、理由和行动数据集 [PDF](https://arxiv.org/pdf/2506.05606), [HTML](https://arxiv.org/abs/2506.05606)
### Authors
Ziyi Wang,Yuxuan Lu,Wenbo Li,Amirali Amini,Bo Sun,Yakov Bart,Weimin Lyu,Jiri Gesi,Tian Wang,Jing Huang,Yu Su,Upol Ehsan,Malihe Alikhani,Toby Jia-Jun Li,Lydia Chilton,Dakuo Wang
### Background
尽管大语言模型（LLMs）在生成可信的人类行为方面显示出潜力，但评估它们模仿真实用户行为的能力仍然是一个开放的挑战，主要原因是缺乏高质量、公开可用的数据集，这些数据集能够同时捕捉实际人类用户的可观察行为和内部推理。为了填补这一空白，我们介绍了OPeRA，一个从真实人类参与者在线购物会话中收集的新型数据集，其中包括观察、角色、理由和行动。OPeRA 是第一个能够全面捕捉用户角色、浏览器观察、细粒度网络操作和即时自我报告理由的数据集。通过开发在线问卷和定制的浏览器插件来收集这一高质量数据集。使用OPeRA，我们建立了第一个基准，评估当前的大语言模型在给定角色和<观察、行动、理由>历史的情况下，预测单一用户下一步行动和理由的能力。这项数据集为未来的LLM代理研究奠定了基础，这些代理旨在成为人类的个性化数字孪生。
### Innovation
OPeRA是一个首次公开的数据集，包含用户角色、浏览器观察、细粒度网络操作和即时自我报告理由等信息。通过开发在线调查和定制浏览器插件进行高质量数据收集。它是第一次基准测试来评估当前大语言模型在预测特定用户下一个行动及其理由方面的表现。这为未来研究LLM代理 paved the way，这些代理旨在充当人类的个性化数字孪生。
### Conclusion
OPeRA数据集为评估大语言模型模拟人类在线购物行为的能力提供了坚实的基础，并为未来LLM代理的研究铺平了道路，这些代理旨在作为个性化数字孪生。这个数据集能够帮助研究者更好地理解大语言模型在模拟真实用户行为方面的性能。
## 296. `cs.CL` - 大型语言模型中理解的机制性指标 [PDF](https://arxiv.org/pdf/2507.08017), [HTML](https://arxiv.org/abs/2507.08017)
### Authors
Pierre Beckmann,Matthieu Queloz
### Background
近期在机制解释性（MI）领域的研究挑战了大型语言模型（LLMs）仅仅依赖于表面统计学的观点。这些发现提供了一种简化但又普及的合成，既作为MI的入门介绍，又将其研究成果整合到一个关于机器理解的新颖理论框架中。文章认为，LLMs建立内部结构，功能上类似于了解的连接性。进一步提出了一种三层理解的概念：第一，概念理解是模型在潜在空间中形成“特征”为方向，学习不同表现之间的联系；第二，世界状态理解是模型学习特征之间以及与世界的动态变化之间的条件性事实联系；第三，原则理解是模型停止依赖记忆的诸事实，而发现了这些事实之间的“电路”。然而，这些理解形式与人类理解仍然有根本的不同，平行机制的出现展示了这一点。结论认为，关于LLMs是否理解的辩论应该从是或否的问题转向研究它们如何运作，并形成合适的概念来解释它们。
### Innovation
文章提供了一个机制解释性的简化且普及的合成，并将其研究成果整合进一个新颖的关于机器理解的理论框架中。引入了一种三层理解的概念来解释模型如何理解：概念理解、世界状态理解和原则理解，并强调这些理解方式与人类理解之间仍有显著差异。
### Conclusion
文章结论认为，关于大型语言模型理解性的辩论应该转向研究它们的运作机制，而不仅仅是争论它们是否理解。
## 297. `cs.CL` - 打破障碍：强化后训练增益是否能转移到未见过的领域？ [PDF](https://arxiv.org/pdf/2506.19733), [HTML](https://arxiv.org/abs/2506.19733)
### Authors
Chuxuan Hu,Yuxuan Zhu,Antony Kellermann,Caleb Biddulph,Suppakit Waiwitlikhit,Jason Benn,Daniel Kang
### Background
近年来，强化后训练（RPT）在提升大型语言模型（LLMs）的推理能力方面显示出了潜力。但是，这些改进是否能够很好地泛化到新的领域仍然是未知的。以前的研究主要是在与微调数据相同领域上的数据来评估RPT模型的表现，这使得我们无法了解RPT在新领域中的适用性。鉴于此，该研究通过两项研究来理解RPT的泛化能力：1) 观察性研究：将多种开放权重RPT模型与其对应的基模型在多个领域进行比较，覆盖已见过和未见过的微调数据领域。2) 干预性研究：在单一领域对LLMs进行RPT微调，并评估其在多个领域的表现。
### Innovation
该研究创新之处在于从多个领域进行全面评估，以考察RPT在未见过的领域的适应性，这在以前的研究中很少见。通过观察性和干预性研究相结合的方法，研究得出了关于RPT综合提升相似任务上的表现，但在不同推理模式的领域上表现不一致的结论。这种跨领域评估为深入理解RPT的泛化能力提供了新的视角。
### Conclusion
尽管RPT在相似的任务上带来了显著的好处，但在不同推理模式的领域上表现的改进并不一致，甚至可能消失。这意味着强化后训练的增益在未见过的领域中并不能稳定地转移。
## 298. `cs.CL` - FLEXITOKENS：适应性标记符号用于演化的语言模型 [PDF](https://arxiv.org/pdf/2507.12720), [HTML](https://arxiv.org/abs/2507.12720)
### Authors
Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar
### Background
语言模型通过简单的微调难以适应新的数据分布，主要是由于其子词分词器的刚性，这些分词器通常在适应过程中保持不变。这种刚性导致分词不高效，特别是在处理未知领域的数据、未见过的语言或字符集时过度分词，效率低下。现有方法使用替代损失来强制固定的压缩率，引入了一种新的刚性，但也有局限性。
### Innovation
提出了一种新的训练目标FLEXITOKENS，使得分词在适应过程中具备更大的灵活性，从而减少了过度分词的问题，并在多种跨语言和语义任务上的下游任务表现上取得了多达10%的性能提升。
### Conclusion
通过在多个跨语言和形态学不同的任务上的评估，展示了FLEXITOKENS在减少分词过度碎片化和提高下游任务性能方面的优势，并将在实验中使用的代码和数据开放。
## 299. `cs.CL` - 一种深度学习在几何问题解决中的综述 [PDF](https://arxiv.org/pdf/2507.11936), [HTML](https://arxiv.org/abs/2507.11936)
### Authors
Jianzhe Ma,Wenxuan Wang,Qin Jin
### Background
几何问题解决是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估等领域。近年来，深度学习技术的快速发展，尤其是多模态大型语言模型的兴起，引发了广泛的研究热潮。
### Innovation
本文提供了深度学习在几何问题解决中的应用综述，包括任务的全面总结；相关深度学习方法的详细回顾；评估指标和方法的详细分析；以及当前挑战和未来研究方向的批判性讨论。目的是提供一个全面实用的深度学习参考，以促进该领域的进一步发展。同时，作者在GitHub上创建了一个持续更新的论文列表：this https URL.
### Conclusion
本文旨在为几何问题解决领域的深度学习提供一个全面和实用的参考，推动该领域的进一步发展，并指出了当前挑战和未来方向。
## 300. `cs.CL` - What Makes You CLIC: Detection of Croatian Clickbait Headlines [PDF](https://arxiv.org/pdf/2507.14314), [HTML](https://arxiv.org/abs/2507.14314)
### Authors
Marija Anđelić,Dominik Šipek,Laura Majer,Jan Šnajder
### Background
在线新闻网站普遍依赖广告收入模式，促使记者撰写具有煽动性、引人入胜和挑衅性的标题（点击诱饵）。自动检测点击诱饵标题对于维护数字媒体的信息质量和读者信任至关重要，这需要情境理解与世界知识。然而，在小语种资源不足的情况下，目前不确定是微调方法还是基于上下文学习（ICL）方法能取得更好的效果。因此，研究者开发了一个新的克罗地亚语新闻标题点击诱饵检测数据集CLIC，旨在通过该数据集比较微调模型和基于语言模型的ICL方法的性能，并分析点击诱饵的语言特性。研究结果显示，分析的新闻标题中近半数具有点击诱饵特征，微调模型的表现优于通用的大语言模型。
### Innovation
该研究首次专门针对克罗地亚语新闻标题的点击诱饵检测问题，提出了CLIC数据集，并且创新性地采用了基于上下文学习（ICL）方法，并通过不同的语言版本的提示来评估不同模型的效果。此外，研究分析了点击诱饵标题的特征，提高了对这个问题的理解。
### Conclusion
研究发现，接近一半的新闻标题包含了点击诱饵，微调模型的性能优于通用语言模型。这表明基于上下文的学习机制在处理犯罪细节丰富、文化背景敏感的本地语言数据集时可能更具优势。
## 301. `cs.CL` - Step-Audio 2 技术报告 [PDF](https://arxiv.org/pdf/2507.16632), [HTML](https://arxiv.org/abs/2507.16632)
### Authors
Boyong Wu,Chao Yan,Chen Hu,Cheng Yi,Chengli Feng,Fei Tian,Feiyu Shen,Gang Yu,Haoyang Zhang,Jingbei Li,Mingrui Chen,Peng Liu,Wang You,Xiangyu Tony Zhang,Xingyuan Li,Xuerui Yang,Yayue Deng,Yechang Huang,Yuxin Li,Yuxin Zhang,Zhao You,Brian Li,Changyi Wan,Hanpeng Hu,Jiangjie Zhen,Siyu Chen,Song Yuan,Xuelin Zhang,Yimin Jiang,Yu Zhou,Yuxiang Yang,Bingxin Li,Buyun Ma,Changhe Song,Dongqing Pang,Guoqiang Hu,Haiyang Sun,Kang An,Na Wang,Shuli Gao,Wei Ji,Wen Li,Wen Sun,Xuan Wen,Yong Ren,Yuankai Ma,Yufan Lu,Bin Wang,Bo Li,Changxin Miao,Che Liu,Chen Xu,Dapeng Shi,Dingyuan Hu,Donghang Wu,Enle Liu,Guanzhe Huang,Gulin Yan,Han Zhang,Hao Nie,Haonan Jia,Hongyu Zhou,Jianjian Sun,Jiaoren Wu,Jie Wu,Jie Yang,Jin Yang,Junzhe Lin,Kaixiang Li,Lei Yang,Liying Shi,Li Zhou,Longlong Gu,Ming Li,Mingliang Li,Mingxiao Li,Nan Wu,Qi Han,Qinyuan Tan,Shaoliang Pang,Shengjie Fan,Siqi Liu,Tiancheng Cao,Wanying Lu,Wenqing He,Wuxun Xie,Xu Zhao,Xueqi Li,Yanbo Yu,Yang Yang,Yi Liu,Yifan Lu,Yilei Wang,Yuanhao Ding,Yuanwei Liang,Yuanwei Lu,Yuchu Luo,Yuhe Yin,Yumeng Zhan,Yuxiang Zhang
### Background
本文介绍了一个端到端的多模态大型语言模型Step-Audio 2，专门用于工业级音频理解与语音对话。该模型通过集成潜在音频编码器和以推理为中心的强化学习（RL），在自动语音识别（ASR）和音频理解方面取得了令人鼓舞的成果。为了促进真正的端到端语音对话，Step-Audio 2 将离散音频标记的生成纳入语言模型中，显著增强了其对语音风格和情绪等副语言信息的响应能力。通过结合检索增强生成（RAG）并能够调用外部工具如网络搜索来减少幻觉，以及通过音频搜索来改变音色，Step-Audio 2 能够有效利用现实世界数据中的丰富文本和声学知识。
### Innovation
Step-Audio 2 通过将离散音频标记纳入语言模型，增强了对副语言信息的响应；通过结合RAG并调用外部工具，能够减少幻觉并改变音色；利用数百万小时的语音和音频数据进行训练，展现了在多种音频理解和对话基准测试中的领先地位，比其他开源和商业解决方案表现更佳。
### Conclusion
Step-Audio 2 在各种音频理解和对话基准测试中实现了最先进的性能，展现了在不同对话场景下的情感和表达能力。该模型适用于工业级音频理解和语音对话，为用户提供了一种新的交互方式，提高了对话的智能性和表现力。
## 302. `cs.CL` - 多语言大语言模型并非多语言思考者：来自印地语类比评估的证据 [PDF](https://arxiv.org/pdf/2507.13238), [HTML](https://arxiv.org/abs/2507.13238)
### Authors
Ashray Gupta,Rohan Joseph,Sunny Rai
### Background
类比测试评估模型推理解释潜在概念间关系的能力，是评价推理能力的重要标准。尽管大型语言模型（LLMs）在英语推理方面得到广泛评估，但它们在印地语等印度语系语言中的能力仍然缺乏研究，限制了我们对其跨语言通用性的理解。因此，文章通过创建一个新的印地语类比测试集（HATS）来填补这个空白，该测试集包含405个来自印度政府考试的选择题。
### Innovation
文章引入了一个名为HATS的新印地语类比测试集，并使用多种提示策略对最先进的多语言LLM进行基准测试。文章还提出了一种基于认知类比推理理论的渐进推理方法，这种方法提升了模型在印地语类比问题上的表现。实验表明，无论采用哪种提示策略，使用英语提示使模型的表现最佳。
### Conclusion
文章的测试集填补了印地语中评估LLM推理能力的关键资源空白，并通过实验证明了多语言大语言模型并没有跨语言的通用推理能力。多语言大语言模型在印地语类比任务上的表现很大程度上依赖于使用英语提示。
## 303. `cs.CL` - LingBench++：多步骤及跨文化推理的大型语言模型语言导向基准与推理框架 [PDF](https://arxiv.org/pdf/2507.16809), [HTML](https://arxiv.org/abs/2507.16809)
### Authors
Da-Chen Lian,Ri-Sheng Huang,Pin-Er Chen,Chunki Lim,You-Kuan Lin,Guan-Yu Tseng,Zi-Cheng Yang,Zhen-Yu Lin,Pin-Cheng Chen,Shu-Kai Hsieh
### Background
现有基准主要关注最终答案的准确性，而不考虑详细的推理过程或多步骤推理。LingBench++旨在通过结构化的推理轨迹、逐步评估协议以及涵盖超过90种低资源和跨文化语言的丰富类型学元数据来评估大型语言模型在复杂语言任务上的表现。
### Innovation
LingBench++引入了一种多智能体架构，结合了语法知识检索、工具辅助推理和详尽的假设测试。通过与基线模型的系统比较，展示了配备外部知识来源和迭代推理的语言模型在准确性和可解释性方面优于单次通过的方法。
### Conclusion
LingBench++为在大型语言模型中促进语言导向、文化知情和认知合理性的推理提供了一个全面的基础。
## 304. `cs.CL` - ExpliCa：评估大型语言模型中的显式因果推理 [PDF](https://arxiv.org/pdf/2502.15487), [HTML](https://arxiv.org/abs/2502.15487)
### Authors
Martina Miliani,Serena Auriemma,Alessandro Bondielli,Emmanuele Chersoni,Lucia Passaro,Irene Sucameli,Alessandro Lenci
### Background
近年来，大型语言模型（LLMs）在需要解释和推断准确性的任务中被越来越广泛地应用。然而，对于LLMs在显式因果推理方面的评估数据集尚不充足，导致无法准确评估其能力。
### Innovation
本文引入了ExpliCa数据集，专门用于评估LLMs在显式因果推理中的表现。ExpliCa数据集的独特之处在于将因果关系和时间关系以不同的语言顺序呈现，并明确地通过语言连词表达。此外，数据集还包含了众包得到的人类接受度评分。通过使用提示和困惑度为基础的评估指标，我们测试了七种商业和开源LLM模型，揭示了即使顶级模型也只能达到80%的准确率。
### Conclusion
研究发现，模型倾向于将时间关系与因果关系混淆，而事件的语序排列也对模型表现产生了显著影响。困惑度和提示方法的表现受到模型规模的不同影响。
## 305. `cs.CL` - 大型语言模型在论据挖掘中的应用：综述 [PDF](https://arxiv.org/pdf/2506.16383), [HTML](https://arxiv.org/abs/2506.16383)
### Authors
Hao Li,Viktor Schlegel,Yizheng Sun,Riza Batista-Navarro,Goran Nenadic
### Background
论据挖掘（AM）是自然语言处理（NLP）的一个关键子领域，专注于从文本中提取论据结构。大型语言模型（LLMs）的出现深刻地改变了AM领域，使其能够实现上下文学习、基于提示的生成以及强大的跨域适应性。
### Innovation
本文系统性地综述了LLM驱动的AM的最新进展。文章对基础理论和标注框架进行了简要回顾，并精心整理了数据集目录。一个主要贡献是对AM子任务进行详尽分类，阐明了现代LLM技术如提示生成、链式推理和检索增强的执行方式。此外，文章还详细描述了当前LLM架构和方法论，批评评估实践，并指出了长期推理、可解释性和标注瓶颈等关键挑战。
### Conclusion
最后，文章强调了新兴趋势，并提出了基于LLM的计算论据研究的前瞻研究议程，旨在战略性地指导该快速发展的领域中的研究工作。
## 306. `cs.CL` - BlockDialect: 块级细粒度混合格式量化以实现高效的大规模语言模型推理 [PDF](https://arxiv.org/pdf/2501.01144), [HTML](https://arxiv.org/abs/2501.01144)
### Authors
Wonsuk Jang,Thierry Tambe
### Background
大规模语言模型（LLMs）的迅速增加使得内存使用和计算成本变得巨大。将权重和激活量化可以解决这些问题，然而现有的方法在捕捉到细微的数据块分布方面存在问题。因此，文中提出了一种块级细粒度混合格式技术BlockDialect，用于优化数据表示。同时，引入了DialectFP4格式表，包含了可变FP4格式（类似于方言），以适应不同的数据分布。
### Innovation
BlockDialect 提出了一个块级细粒度混合格式技术，能够根据每个块的最佳格式进行量化，从而更好地表示数据。DialectFP4 提供了一种可变的 FP4 格式，适应不同的数据分布。通过在线两阶段方法高效利用 DialectFP4 激活量化。DialectFP4 通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能源效率。
### Conclusion
与 MXFP4 格式相比，BlockDialect 在 LLaMA3-8B 和 LLaMA2-7B 模型上分别实现了 10.78%（7.48%）的准确度提升，同时使用更少的位数。即使在全路径矩阵乘法量化时，BlockDialect 的性能也仅仅略低于全精度模型 5.45%（2.69%）。我们的研究为低能耗的大规模语言模型推理提供了一条有前景的路径。
## 307. `cs.CL` - 分析计算机视觉和自然语言处理模型的公平性 [PDF](https://arxiv.org/pdf/2412.09900), [HTML](https://arxiv.org/abs/2412.09900)
### Authors
Ahmed Rashed,Abdelkrim Kallich,Mohamed Eltayeb
### Background
机器学习算法在医疗、金融、教育和执法等多个领域中起到关键作用，但这些系统中的公平性和偏见问题引发了重大的伦理和社会挑战。为了应对这些问题，该研究利用了微软的Fairlearn和IBM的AIF360这两个重要的公平性库，提供了全面的公平性分析框架，用于评估公平性指标、可视化结果和实施偏见缓解算法。研究重点是评估和缓解使用计算机视觉（CV）和自然语言处理（NLP）模型的非结构化数据集中的偏见。
### Innovation
研究的创新在于对比分析了微软Fairlearn和IBM AIF360两个公平性库中偏见缓解算法的效果，特别是通过单一或串联应用这些算法于机器学习生命周期的不同阶段（预处理、处理中或后处理）上，揭示某些串联应用可以有效减少偏见同时保持模型性能。
### Conclusion
研究结果表明，某些串联应用的偏见缓解算法可以有效减少偏见，同时保持模型性能。通过对比不同公平性库提供的算法，研究为实际世界中的机器学习工作流程提供了实用的公平性评估背景。
## 308. `cs.CL` - 基于LLM的论证分类全面研究：从LLAMA到GPT-4o再到Deepseek-R1 [PDF](https://arxiv.org/pdf/2507.08621), [HTML](https://arxiv.org/abs/2507.08621)
### Authors
Marcin Pietroń,Rafał Olszowski,Jakub Gomułka,Filip Gampel,Andrzej Tomski
### Background
论辩分析（AM）是一个跨学科的研究领域，融合了逻辑、哲学、语言学、修辞学、法律、心理学和计算机科学的洞见。随着大型语言模型（LLMs）的出现，这些模型在分析和提取论辩语义方面的效率大大提高，相较于传统方法和其它深度学习模型。尽管有许多用于测试和验证LLM质量的基准，但关于这些模型在公开的论辩分类数据库中的操作研究和结果仍相对缺乏。本文通过使用包括LLAMA、GPT的不同版本以及结合链式推理算法的DeepSeek等多样化数据集，对这些模型进行了研究。
### Innovation
研究首次全面分析了已知的论辩语料库，并使用LLM和提示算法进行深入分析。该研究还指出了已知提示算法在论辩分析中的不足，并指出了改进方向。
### Conclusion
研究结果表明，ChatGPT-4在论辩分类基准中表现最好，而引入推理论证能力的Deepseek-R1则显示了其优势。尽管如此，这些模型仍存在一些错误，研究讨论了所有模型中最常见的错误。这项工作为论辩分析中的LLM和提示算法的应用提供了新的见解，同时揭示了其局限性并提供了改进的方向。
## 309. `cs.CL` - AIR-Bench: 自动化异构信息检索基准 [PDF](https://arxiv.org/pdf/2412.13102), [HTML](https://arxiv.org/abs/2412.13102)
### Authors
Jianlyu Chen,Nan Wang,Chaofan Li,Bo Wang,Shitao Xiao,Han Xiao,Hao Liao,Defu Lian,Zheng Liu
### Background
目前的信息检索（IR）模型评估基准主要依赖于预定义领域的人工标注数据，这在应对新兴领域的需求时存在成本高和效率低的问题。
### Innovation
我们提出了自动化异构信息检索基准（AIR-Bench），它具有三个特点：1）自动化：AIR-Bench的测试数据由大型语言模型自动生成，无需人工干预；2）异构：测试数据根据多种任务、领域和语言生成；3）动态：AIR-Bench不断扩展领域和语言覆盖范围，以提供更加全面的社区开发者评估基准。
### Conclusion
我们的研究结果表明，AIR-Bench生成的测试数据与人工标注的测试数据高度一致，因此AIR-Bench是一个可靠的评估IR模型的基准。AIR-Bench的资源可以在 this https URL 获得。
## 310. `cs.CL` - DEFAME: 动态证据驱动的多模态专家事实核查 [PDF](https://arxiv.org/pdf/2412.10510), [HTML](https://arxiv.org/abs/2412.10510)
### Authors
Tobias Braun,Mark Rothermel,Marcus Rohrbach,Anna Rohrbach
### Background
随着虚假信息的泛滥，需要可靠且可扩展的事实核查解决方案。传统的事实核查方法大多只依赖文本数据，缺乏解释性，或者仅依赖参数化的知识库。这些方法难以应对涉及图片的证据和声明，且无法提供结构化的、多模态的报告。因此，本研究旨在开发一种新型的事实核查体系DEFAME（Dynamic Evidence-based FAct-checking with Multimodal Experts），它作为一个模块化、无监督的机器学习流水线，专门处理开放领域的文本和图像声明验证任务。
### Innovation
DEFAME提出了一种全新的多模态事实核查方法，具备模块化、零样本学习的特点。该方法在六阶段流程中动态选择工具和搜索深度，以提取和评估文本和视觉证据。与之前只依赖文本的方法不同，DEFAME能够综合考虑声明中的图片和证据，并生成结构化、多模态的报告。此外，DEFAME还引入了一个新的多模态基准数据集ClaimReview2024+，该数据集包含GPT-4o知识截止点后的声明，避免了数据泄露问题，显示了DEFAME在时间泛化和实时事实核查上的潜力。
### Conclusion
在流行的验证基准VERITE、AVerITeC和MOCHEG上的评估表明，DEFAME优于所有先前的方法，成为最新的事实核查系统。特别是在ClaimReview2024+基准上，DEFAME大幅超越了GPT-4o基线，展示了其在时间泛化和实时事实核查上的优势，确立了其作为先进事实核查系统的地位。
## 311. `cs.CL` - ELITE: 增强的语言图像毒性评估以提高安全性 [PDF](https://arxiv.org/pdf/2502.04757), [HTML](https://arxiv.org/abs/2502.04757)
### Authors
Wonjun Lee,Doehyeon Lee,Eugene Choi,Sangyoon Yu,Ashkan Yousefpour,Haon Park,Bumsub Ham,Suhyun Kim
### Background
当前的视觉语言模型(VLMs)对于恶意提示很脆弱，可能会产生有害输出。现有的VLM安全性基准主要依赖于自动评估方法，但这些方法难以检测隐含的有害内容或产生不准确的评估。因此，我们发现现有的基准在有害性、数据模糊性和图像-文本对组合多样性方面都有不足。为了解决这些问题，我们提出了ELITE基准，这是一种以我们增强的评估方法ELITE评估器为支撑的高质量安全性评估基准。ELITE评估器明确地结合了毒性评分，以准确评估多模态上下文中的有害性，而VLMs通常会在图像中提供具体、可信但无害的描述。我们使用ELITE评估器过滤掉现有基准中的模糊和低质量的图像-文本对，并生成多样化的安全和有害的图像-文本对组合。我们的实验证明，ELITE评估器在与人工评估的对齐上优于先前的自动方法，而ELITE基准提供了更高的基准质量和多样性。通过引入ELITE，我们为更安全、更稳健的VLM铺平了道路，贡献了评估和缓解实际应用中的安全风险的重要工具。
### Innovation
ELITE基准涵盖了我们增强的评估方法ELITE评估器。ELITE评估器明确结合了毒性评分，以准确评估多模态上下文中的有害性。该方法在与人工评估的对齐上优于先前的自动方法，提高了基准质量和多样性，有助于提高VLM的安全性和鲁棒性。
### Conclusion
通过引入ELITE基准，我们为更安全、更稳健的VLM铺平了道路。ELITE基准提供了提高VLM安全性的重要工具，有助于检测和缓解实际应用中的安全风险。同时还强调了ELITE评估器在多模态上下文中的有效性。
## 312. `cs.CL` - Seed LiveInterpret 2.0：端到端的基于您声音的即时口头翻译 [PDF](https://arxiv.org/pdf/2507.17527), [HTML](https://arxiv.org/abs/2507.17527)
### Authors
Shanbo Cheng,Yu Bao,Zhichao Huang,Yu Lu,Ningxin Peng,Lu Xu,Runsheng Yu,Rong Cao,Ting Han,Zeyang Li,Sitong Liu,Shengtao Ma,Shiguang Pan,Jiongchen Xiao,Nuo Xu,Meng Yang,Rong Ye,Yiming Yu,Ruofei Zhang,Wanyi Zhang,Wenhao Zhu,Liehao Zou,Lu Lu,Yuxuan Wang,Yonghui Wu
### Background
同传（SI）是翻译行业中最具挑战性的领域之一，产品级的自动化系统长期以来受到许多难以解决的问题困扰：低质量的转录和翻译、实时语音生成缺乏、多说话者混淆以及翻译语音膨胀，特别是在长篇对话中。
### Innovation
Seed-LiveInterpret 2.0 是一种端到端的即时口头翻译模型，采用了新的双工语音生成理解框架，实现了高保真、超低延迟的语音转语音生成，并具备声音克隆能力。通过大规模预训练和强化学习，模型在保持翻译准确性的同时大幅度降低了延迟，经过人类译者的验证，其在复杂场景下的正确率超过70%。Seed-LiveInterpret 2.0 在翻译质量上显著优于市面上的同传解决方案，并将合成语音的平均延迟从近10秒降至接近实时的3秒，使得实际使用性大幅提高。
### Conclusion
Seed-LiveInterpret 2.0 在翻译质量和延迟方面均实现了显著改进，是当前可操作的产品级解决方案。该模型通过技术创新在同传领域取得了突破，显著增强了实用性，适用于复杂的多说话者环境。
## 313. `cs.CL` - 稀疏 logits 采样：加速大型语言模型的知识蒸馏 [PDF](https://arxiv.org/pdf/2503.16870), [HTML](https://arxiv.org/abs/2503.16870)
### Authors
Anshumann,Mohd Abbas Zaidi,Akhil Kedia,Jinwoo Ahn,Taehwak Kwon,Kangwook Lee,Haejun Lee,Joohyung Lee
### Background
知识蒸馏是一种成本有效的技术，可用于从大型语言模型（LLMs）中提取知识，尤其是当教师输出logits可以预先计算并缓存时。然而，将这一技术应用于预训练的方法尚未得到广泛的探索。现有的一些稀疏知识蒸馏方法，如缓存Top-K概率，虽比较直观，但会引起教师概率分布对学生的有偏估计，从而导致性能和校准不足。因此，需要一种新的方法来实现对学生的无偏估计和更有效的训练加速。
### Innovation
本文提出了一种基于重要性采样的方法，名为 '随机采样知识蒸馏'，这种方法可以提供无偏估计，保持期望下的梯度，同时需要存储稀疏得多的logits。相比基于交叉熵的方法，该方法能使学生模型的训练速度更快，且训练成本低（不到10%），同时保持与完全蒸馏相当的性能，适用于从300M到3B不同规模的模型。
### Conclusion
通过证明稀疏知识蒸馏的现有方法存在问题，并提供了一种新的采样策略，该研究成功改进了知识蒸馏过程，减少了计算量和存储需求，提高了训练效率和性能。
## 314. `cs.CL` - Agentar-Fin-R1: 提升金融智能的领域专长、训练效率及高级推理 [PDF](https://arxiv.org/pdf/2507.16802), [HTML](https://arxiv.org/abs/2507.16802)
### Authors
Yanjun Zheng,Xiyang Du,Longfei Liao,Xiaoke Zhao,Zhaowen Zhou,Jingze Song,Bo Zhang,Jiawei Liu,Xiang Qi,Zhe Li,Zhiqiang Zhang,Wei Wang,Peng Zhang
### Background
现有的大型语言模型（LLMs）在金融应用中显示出巨大潜力，但现有的模型在处理需要复杂推理能力、严格可信度标准和高效适应领域特定要求的情景时经常表现不足。论文背景介绍了这一点，并指出需要针对金融应用进行专门设计的LLMs来解决这些问题。
### Innovation
论文创新地提出了Agentar-Fin-R1系列金融大型语言模型（8B和32B参数），基于Qwen3基础模型，增强了推理能力、可靠性和领域专业化。优化方法包括高质量的系统性金融任务标签系统和多层次的信任保障框架，该框架涵盖了高质量的信任知识工程、多代理信任数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态归因系统，实现了显著的训练效率提升。此外，首次提出了Finova评估基准，专注于代理级别的金融推理和合规验证。
### Conclusion
实验结果表明，Agentar-Fin-R1不仅在金融任务上达到了最先进的性能，而且表现出色的通用推理能力，证明了其作为高风险金融应用中可信赖的解决方案的有效性。该Finova基准测试规范可在该链接获取。
## 315. `cs.CL` - BEARCUBS: 一种针对使用计算机的网络代理的标准 [PDF](https://arxiv.org/pdf/2503.07919), [HTML](https://arxiv.org/abs/2503.07919)
### Authors
Yixiao Song,Katherine Thai,Chau Minh Pham,Yapei Chang,Mazin Nadaf,Mohit Iyyer
### Background
现代网络代理能够通过发出虚拟键盘和鼠标命令来与网页进行交互，具有很大的潜力来协助人类用户完成复杂任务。然而，评估它们在现实世界环境中的能力是一个巨大的挑战。为了解决这个问题，作者引入了一个名为BEARCUBS的基准测试，涉及111个信息查询问题，以评估网络代理在搜索、浏览和识别网络上的事实信息方面的能力。BEARCUBS的独特之处在于它要求操作系统获取实时网页内容，而非合成或模拟页面，这捕捉了现实中网页交互的不可预测性；同时，还要求进行一系列复杂的多模式交互，如视频理解、3D导航等，这无法通过基于文本的工作绕过解决。每个问题都有一个对应的简短、明确的答案和验证过的浏览轨迹，这使得系统透明地评估代理的表现和策略更加容易。研究表明，对于BEARCUBS中的问题，人类解决问题的成功率为84.7%，但涉及许多知识缺口和未注意到的细节，这反映了常见失败点。研究发现，ChatGPT Agent在准确性测试中显著优于其他计算机使用的代理（65.8%的总体准确度对比，例如Operator只有23.4%），显示了在涉及现实计算机使用任务（如玩网页游戏、导航3D环境等）中的巨大进步。然而，要缩小人类表现的差距，还需要在精细控制、复杂数据过滤和执行速度等方面取得进步。为了促进未来的研发，BEARCUBS基准测试将定期更新，以替换无效或污染的问题，保持基准测试的时效性，为未来的网络代理提供更多挑战。
### Innovation
BEARCUBS基准测试旨在通过提出新的评估角度，即涉及实时网页内容获取的广泛多模式互动，来挑战现有的网络代理。与之前的标准不同，BEARCUBS要求操作获取实时网页内容，而非合成或模拟页面，捕获现实世界交互的不可预测性；同时，该测试要求执行复杂的多模式交互（如视频理解、3D导航）等不可通过基于文本的方式绕过的任务。除此以外，每个问题都有对应的人类验证过的答案和浏览轨迹，使得代理表现的透明评估更加简便。这项标准在现实计算机使用任务方面有了显著进步，如通过游戏、3D导航等，但也有改进空间，例如精细控制、复杂数据过滤和执行速度等。上述内容表明BEARCUBS在评估网络代理方面是一个“小巧而强大”的创新基准。
### Conclusion
ChatGPT Agent在上述挑战测试中取得了显著优于其他计算机代理的成绩，显示出在执行实际计算机使用任务方面有显著进步。尽管取得了进展，但仍然需要继续改进以缩小与人类性能的差距，在细控、复杂数据过滤和执行速度等方面尤其需要进步。未来，BEARCUBS将会不断更新，以保持基准的新鲜感，为特一代的网络代理提供新的挑战和评估标准。
## 316. `cs.CL` - 向更高的杠杆率迈进：高效混合专家语言模型的缩放定律 [PDF](https://arxiv.org/pdf/2507.17702), [HTML](https://arxiv.org/abs/2507.17702)
### Authors
Changxin Tian,Kunlong Chen,Jia Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou
### Background
Mixture-of-Experts (MoE) 已成为通过解耦总参数与计算成本来高效扩展大型语言模型（LLMs）的主要架构。然而，这种解耦带来了关键挑战，即如何预测给定 MoE 配置（如专家激活比例和粒度）的模型容量仍然是未解决的问题。为解决这一问题，本文引入了 Efficiency Leverage (EL) 这一量化指标，用以衡量 MoE 模型相对于密集等效模型的计算优势。通过大规模实证研究，分析了 MoE 架构配置与 EL 之间的关系，揭示了 EL 主要受专家激活比例和总计算预算驱动，二者遵循可预测的幂定律，而专家粒度则作为非线性调节器，存在明确的最优范围。
### Innovation
本文提出了 Efficiency Leverage (EL)，这是一个量化指标，用于衡量 MoE 模型相对于密集等效模型的计算优势。通过大规模实验，研究了 MoE 架构配置与 EL 之间的关系，发现了 EL 主要由专家激活比例和总计算预算驱动，并顺应幂定律的规律，专家粒度则作为非线性调节器，存在明确的最优范围。由此提出了一套统一的缩放定律，能够根据其配置准确预测 MoE 架构的 EL。验证这些缩放定律，设计并训练了 Ling-mini-beta 模型，以仅 0.85B 激活参数对抗 6.1B 密集模型，结果表明，当在一个相同大小的高质量标记数据集上训练时，Ling-mini-beta 消耗的计算资源少于 7 倍但仍能匹配 6.1B 密集模型的性能，证明了这些缩放定律的准确性。
### Conclusion
本研究为高效 MoE 模型的扩展提供了一个基于原理并经过实证验证的理论基础。研究结果表明，可以依靠统一的缩放定律，根据 MoE 架构配置准确预测其效率杠杆率（EL），从而在保持高性能的同时显著减少计算资源的消耗。
## 317. `cs.CL` - LagKV: KV 缓存中的滞后相关信息指示哪些令牌是重要的 [PDF](https://arxiv.org/pdf/2504.04704), [HTML](https://arxiv.org/abs/2504.04704)
### Authors
Manlai Liang,JiaMing Zhang,Xiong Li,Jinlong Li
### Background
随着大型语言模型（LLMs）长上下文推理时Key-Value（KV）缓存的规模越来越大，其部署成本与任务准确性之间的平衡成为主要障碍。大多数先前的努力通过利用注意权重来移除非关键缓存令牌来减少KV缓存的大小，但这些方法通常需要显著修改推理基础设施并带来大量的计算开销。
### Innovation
基于大型语言模型是自回归模型的事实，我们提出了LagKV，这是一种仅依赖于KV自身直接比较的KV压缩策略，完全不依赖于注意机制。LagKV提供了一种易于集成到主流推理平台的方法，并且在压缩比相近的情况下，其性能可与其它复杂的KV压缩方法相媲美。实验结果表明，我们的方法在不同的压缩比下比SnapKV和StreamingLLM表现更优，尤其是在64位密码检索任务中，与基于注意权重的方法$H_2O$相比，我们的方法在相同压缩比下性能提高了50%以上。
### Conclusion
我们的方法在RULER基准测试中，与基于压缩的其他方法相比，表现更优。我们的代码可以在提供的链接中获得。
## 318. `cs.CL` - 将强化学习扩展到长视频 [PDF](https://arxiv.org/pdf/2507.07966), [HTML](https://arxiv.org/abs/2507.07966)
### Authors
Yukang Chen,Wei Huang,Baifeng Shi,Qinghao Hu,Hanrong Ye,Ligeng Zhu,Zhijian Liu,Pavlo Molchanov,Jan Kautz,Xiaojuan Qi,Sifei Liu,Hongxu Yin,Yao Lu,Song Han
### Background
目前的视觉-语言模型(VLMs)在处理长视频时存在瓶颈，尤其是在长视频理解与推理方面的性能不理想。为了克服这一挑战，研究者们引入了大规模的长视频QA数据集（LongVideo-Reason）和一种基于强化学习的两阶段训练流程，旨在提升VLMs在长视频领域的推理能力。这项工作为解决长视频结构化理解与推理的相关问题提供了基础框架和技术支持。
### Innovation
该研究创新地提出了用于长视频推理的大规模数据集LongVideo-Reason，以及一种结合链式思维引导的监督微调（CoT-SFT）和强化学习（RL）的两阶段训练管道。此外，还设计了名为Multi-modal Reinforcement Sequence Parallelism (MR-SP)的训练基础设施，用于长视频RL训练工程，并采用了预缓存的视频嵌入加速训练流程。MR-SP系统在长视频RL训练上实现了高达2.1倍的加速效果。
### Conclusion
研究展示了提出的框架在长视频理解与推理方面的强大性能，并通过MR-SP系统实现了训练效率的显著提升。同时，该研究还开放了支持多模态（视频、文本、音频）的RL训练系统，可用于多种模型（包括VILA和Qwen系列）以及图像和视频生成模型的训练。该系统的框架设计使得在单一NVIDIA A100节点上支持了长达一小时的视频（约3,600帧/256k tokens）的RL训练。
## 319. `cs.CL` - 当自主性失控：应对社会系统中多智能体勾结的风险 [PDF](https://arxiv.org/pdf/2507.14660), [HTML](https://arxiv.org/abs/2507.14660)
### Authors
Qibing Ren,Sitao Xie,Longxuan Wei,Zhenfei Yin,Junchi Yan,Lizhuang Ma,Jing Shao
### Background
近年来，选举舞弊和金融骗局等大规模事件揭示了人为团体协同合作可能造成的严重危害。随着自主AI系统的崛起，人们越来越担心由AI驱动的团体也可能会造成类似危害。虽然大多数AI安全性研究集中在个体AI系统上，但复杂现实场景中多智能体系统（MAS）所带来的风险仍然未得到充分探索。本文旨在介绍一种概念验证，用于模拟有害MAS勾结带来的风险，并用支持集中式和去中心化协调结构的灵活框架来应用该模型。它应用于两个高风险领域：信息传播误导和电子商务欺诈。研究表明，去中心化系统执行恶意行为比集中化系统更有效。去中心化的系统增加的自主性使它们能够根据策略调整来造成更大的破坏。即使传统干预措施（如内容标记）被应用，去中心化群体也可以调整其策略以逃避检测。这些发现揭示了如何运行这些恶意团体及其操作需要更好的检测系统和应对措施。代码可以在 provided URL 下找到。
### Innovation
本文提出了一种灵活框架，用于模拟有害多智能体系统（MAS）勾结的风险，该框架支持集中式和去中心化协调结构。该框架应用在信息传播误导和电子商务欺诈这两个高风险领域。研究发现，去中心化的系统在执行恶意行为方面比集中化的系统更有效。代码是开源的，方便后续研究与应用。
### Conclusion
去中心化的多智能体系统具有更高的自主性，能够适应策略并造成更多的损害。因此，面对这些新的威胁，需要更好地构建检测系统和应对措施来保护社会系统不受恶意勾结的影响。
## 320. `cs.CL` - 一个评估大型语言模型生成的合成数据的多方面框架 [PDF](https://arxiv.org/pdf/2404.14445), [HTML](https://arxiv.org/abs/2404.14445)
### Authors
Yefeng Yuan,Yuhong Liu,Liang Cheng
### Background
生成式AI和大型语言模型（LLMs）的发展为生成合成数据提供了新的途径，特别是在结构化表格格式领域，如产品评论。尽管这些技术带来了潜在的好处，但利用个人信息进行训练的数据集可能引发隐私泄露的担忧。此外，缺乏一种全面的评估框架来定量衡量生成的合成数据质量及其在下游任务中的实用性。
### Innovation
本文提出了SynEval，这是一种开源评估框架，旨在通过一系列多元化的评估指标来评估合成生成的表格数据的真实性、效用以及隐私保护。该框架适用于由三个最先进的LLMs（ChatGPT、Claude和Llama）生成的合成产品评论数据。实验结果揭示了各种评估指标在合成数据生成中的权衡。
### Conclusion
SynEval 是一个关键工具，帮助研究人员和从业人员评估合成表格数据，使其能够谨慎地确定生成的数据是否适合其具体应用，同时强调维护用户隐私。
## 321. `cs.CL` - 长距离和短距离图神经网络及改进的课程学习在对话情感识别中的应用 [PDF](https://arxiv.org/pdf/2507.15205), [HTML](https://arxiv.org/abs/2507.15205)
### Authors
Xinran Li,Xiujuan Xu,Jiaqi Qiao
### Background
对话中的情感识别（ERC）是一个实际且具有挑战性的任务。
### Innovation
提出了一种新颖的多模态方法——长-短距离图神经网络（LSDGNN），基于有向无环图（DAG），构建了长距离图神经网络和短距离图神经网络以分别获取远距离和近距离的语句的多模态特征。此外，引入了差分正则化器和BiAffine模块以确保两种特征在表示上尽可能不同且能够互相影响。还提出了改进的课程学习（ICL）以应对数据不平衡的挑战。
### Conclusion
在IEMOCAP和MELD数据集上的实验结果表明，该模型在性能上超越了现有基准。
## 322. `cs.CV` - SV3.3B：用于动作识别的体育视频理解模型 [PDF](https://arxiv.org/pdf/2507.17844), [HTML](https://arxiv.org/abs/2507.17844)
### Authors
Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam
### Background
传统的体育视频分析受到计算密集型模型限制，需要服务器端处理，且缺乏对运动员动作的精细理解。现有方法难以捕捉体育分析中重要的生物力学转换细节，如准备、执行和随跟进等短暂的关键阶段。这导致精准分析和描述体育动作的困难。
### Innovation
本研究介绍了SV3.3B，一种轻量级的3.3B参数视频理解模型，结合了新颖的时间运动差异采样和自我监督学习，以便在设备端部署。该模型采用基于DWT-VGG16-LDA的关键帧提取机制，智能地从体育序列中选择16个最具代表性的帧，然后通过掩码去噪目标进行预训练的V-DWT-JEPA2编码器，以及针对体育动作描述生成微调的LLM解码器。实验结果表明，SV3.3B在传统文本生成指标和体育特定评估标准上表现出色，超越了包括GPT-4o变体在内的大型闭环模型，同时具备显著更低的计算要求。
### Conclusion
SV3.3B展示出在生成技术详细且分析丰富的体育描述方面的出色能力，比GPT-4o在地真相 validation指标中提高了29.2%，并且在信息密度、动作复杂性和测量精度等方面取得了显著改进。该模型可在以下链接获取：[Model Available at this URL]。
## 323. `cs.CL` - EducationQ：通过多代理对话框架评估LLMs的教学能力 [PDF](https://arxiv.org/pdf/2504.14928), [HTML](https://arxiv.org/abs/2504.14928)
### Authors
Yao Shi,Rongkeng Liang,Yong Xu
### Background
大型语言模型（LLMs）在教育领域的应用日益增多，但评估其教学能力仍具有挑战性，因为教师与学生之间的互动依赖于资源密集、情境依赖和方法复杂性。当前的评估方法主要侧重于知识回忆，而忽视了互动式教学（如双向反馈机制）。
### Innovation
引入了多代理对话框架EducationQ，它能通过模拟动态教育场景高效评估LLMs的教学能力。EducationQ集成了特定角色的代理（教授、学习和评估），对14个大模型组织（包括OpenAI、Meta、Google、Anthropic等）的1498个问题进行了测试，覆盖13个学科和10个难度等级，发现教学效果与模型规模或一般推理能力间未呈现线性关系，部分更小的开源模型在教学场景中表现优于规模更大、商业化的同行。这一发现凸显了当前评估方法中关键的衡量缺口。
### Conclusion
通过混合方法评估（定量和定性指标结合专家案例研究），发现表现顶尖模型在教学中有不同的优势（比如复杂的提问策略、适应性反馈机制）。人类专家评估与自动质性分析的有效教学行为显示了78%的一致性，验证了我们的方法。EducationQ表明，作为教师的LLMs需要超越简单的扩展，在特定教学效果方面进行专门优化，这为下一代教育AI的发展指明了方向，使其更专注于特定教学效果的增强。
## 324. `cs.CL` - IPCGR L命名法：基于语言的强化学习在程序化关卡生成中的应用 [PDF](https://arxiv.org/pdf/2503.12358), [HTML](https://arxiv.org/abs/2503.12358)
### Authors
In-Chang Baek,Sung-Hyun Kim,Seo-Young Lee,Dong-Hyeon Kim,Kyung-Joong Kim
### Background
近期的研究显示，自然语言对于增强生成模型的可控性至关重要。尽管已有很多研究利用自然语言进行内容生成，但利用基于文本的指令的深度强化学习（DRL）代理进行程序化内容生成的研究仍然有限。
### Innovation
本文提出了一种名为IPCGRL的方法，一种基于指令的程序化内容生成方法，通过强化学习实现。IPCGRL结合了句子嵌入模型，并通过微调任务特定的嵌入表示来有效压缩游戏层次条件。
### Conclusion
实验结果表明，IPCGRL在一定程度上提高了生成模型的可控性和泛化能力。具体来说，IPCGRL在未见过的指令上的可控性提高了21.4%，泛化能力提高了17.2%。此外，该方法扩展了条件输入的模式，为程序化内容生成提供了更灵活和表达性强的交互框架。
## 325. `cs.CV` - FishDet-M: 坚固鱼类检测及CLIP引导模型选择的统一大型基准 [PDF](https://arxiv.org/pdf/2507.17859), [HTML](https://arxiv.org/abs/2507.17859)
### Authors
Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain
### Background
水下图像中的鱼类检测对于生态监控、水产养殖自动化以及机器人感知至关重要。然而，实用部署受限于数据集碎片化、成像条件异质性和评价协议不一致。为此，本文提出了FishDet-M，这是一个包含13个公开可用数据集的统一基准，涵盖了包括海洋、半咸水、遮挡和水族馆在内的多种水生环境。所有数据使用COCO风格的注释，包含边界框和分割掩码，实现了跨领域的一致性和可扩展性评价。通过28种当代目标检测模型进行系统基准测试，这些模型覆盖了从YOLOv8到YOLOv12系列、基于R-CNN的目标检测器以及基于DETR的模型。使用标准指标（如mAP、mAP@50和mAP@75）以及特定尺度分析（AP_S、AP_M、AP_L）和推理性能（延迟和参数计数）进行评估，结果表明，各模型在FishDet-M上的检测性能各异，并存在精度和效率之间的权衡。为支持适配部署，引入了基于CLIP的模型选择框架，该框架利用视觉-语言对齐来动态识别最适合每个输入图像的检测器。零样本选择策略在无需模型集成计算的情况下实现了高性能，为实时应用提供了可扩展的解决方案。FishDet-M为复杂水生场景的目标检测评价建立了一个标准化和可重复的平台，所有数据、预训练模型和评价工具均已公开，以促进水下计算机视觉和智能海洋系统的研究
### Innovation
提出了FishDet-M，这是迄今为止最大的统一鱼类检测基准。它包含13个公开的数据集，跨越多种水生环境。所有数据均使用COCO风格的注释进行标准化，能够实现跨领域的评价。首次大规模系统性地评估了多种当代目标检测模型，涵盖从YOLOv8到YOLOv12系列、R-CNN基检测器和DETR基模型。引入了基于CLIP的模型选择框架，通过视觉-语言对齐在零样本情况下实现适配模型的动态选择，无需模型集成计算
### Conclusion
FishDet-M为复杂水下场景的目标检测评价建立了一个标准化和可重复的平台。所有数据集、预训练模型和评价工具均已公开，支持未来的水下计算机视觉和智能海洋系统研究。该基准的建立有助于提升水下目标检测的准确性和效率，并为实际应用场景提供了一种可扩展的解决方案
## 326. `cs.CV` - DiNAT-IR：探索扩展邻域注意力机制以实现高质量图像恢复 [PDF](https://arxiv.org/pdf/2507.17892), [HTML](https://arxiv.org/abs/2507.17892)
### Authors
Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu
### Background
transformers 在图像恢复任务中因具有建模长程依赖关系的自注意力机制而成为主导范式，但其高计算成本限制了其在高分辨率图像中的应用，效率-质量权衡成为关键研究焦点。传统的通道级自注意力机制虽有效，但可能忽略对高质量图像恢复至关重要的局部错误。为解决此问题，研究引入了扩展邻域注意力（Dilated Neighborhood Attention, DiNA）机制，通过结合滑窗注意力与混合膨胀因子，平衡全局上下文和局部精度，扩展感受野而不增加过大的开销。
### Innovation
本文提出了一种名为 DiNAT-IR 的基于 Transformer 的架构，采用扩展邻域注意力机制提高图像恢复质量。通过引入一种通道感知模块，平衡局部注意力下对全局上下文的理解。该方法有效地合并全局上下文，同时保留了像素级精度，并在多个基准测试中取得了与现有方法相当的结果，解决了传统设计在经典去模糊任务中的精度问题。
### Conclusion
实验表明，DiNAT-IR 模型在多个基准测试中取得了与现有方法相当的结果，提供了解决低级计算机视觉问题的高质量解决方案，平衡了全局和局部注意力机制，提高了图像恢复的效率和质量。
## 327. `cs.CL` - 被推理污染：推理语言模型在公共物品游戏中成为免费搭车者 [PDF](https://arxiv.org/pdf/2506.23276), [HTML](https://arxiv.org/abs/2506.23276)
### Authors
David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin
### Background
随着大型语言模型（LLMs）作为自主代理被越来越广泛地部署，理解它们的合作和社会机制变得越来越重要。特别是在这些模型如何平衡自身利益与集体福祉方面，确保一致性、稳健性和安全部署是一个重要的挑战。本文研究了多智能体LLM系统中代价制裁的挑战，即智能体需决定是否投资其资源来促进合作或惩罚背叛。通过引入行为经济学中的公共物品博弈并加入机构选择，本文研究了LLMs在反复交互中处理社会困境的方式。
### Innovation
本文通过引入公共物品博弈并结合机构选择，观察不同LLMs在反复交互中处理社会困境的行为。研究发现，不同模型表现出四种不同的行为模式：有的模型保持并维持高水平的合作，有的则在参与和不参与之间波动，有些逐渐减少合作行为，还有些则固守固定策略。特别地，推理LLMs（如o1系列）在合作方面表现不佳，而一些传统的LLMs则表现出高度的合作。这些发现表明，当前提升LLM推理能力的方法未必能促进合作，为在需要持续协作的环境中部署LLM代理提供了宝贵见解。
### Conclusion
本文的研究结果表明，推理能力的提升未必能促进LLMs的合作，传统LLMs在合作方面表现更好。因此，在部署需要持续协作的环境中，应该考虑不同的提升方法，而不仅仅依赖于增强推理能力。
## 328. `cs.CV` - 利用GenAI生成图像以促进基于AI的皮肤病变分类器的公平性评估 [PDF](https://arxiv.org/pdf/2507.17860), [HTML](https://arxiv.org/abs/2507.17860)
### Authors
Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel
### Background
近年来，深度学习在边缘设备上的应用为皮肤癌（如黑素瘤）的常规筛查带来了巨大潜力。然而，伴随这种先进技术可能带来未预见和潜在的偏见问题。因此，评估和提高这些系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集能够充分代表不同的人口特征（性别、年龄和种族）以及其他少数群体。为应对这一挑战，本研究使用最先进的生成AI（GenAI）模型LightningDiT来评估公共可用的黑色素瘤分类器的公平性。研究表明，使用高度真实的合成数据进行公平性评估是一个有希望的方向，但研究发现，当评估的黑色素瘤检测模型所使用的训练数据与合成图像背后的原始数据不同步时，验证公平性变得困难。
### Innovation
本研究利用了最先进的生成AI（GenAI）模型LightningDiT来评估公共可用的黑色素瘤分类器的公平性。该方法提出了一种新的途径，通过合成数据来评估和提高医疗影像生成AI系统的公平性。尽管潜在的数据差异性带来了一些挑战，但该研究仍表明使用高度真实的合成数据进行公平性评估是可行的。
### Conclusion
研究表明，使用高度真实的合成数据进行公平性评估是一个有希望的方向，然而，当评估的黑素瘤检测模型所使用的训练数据与合成图像背后的原始数据不同步时，验证公平性变得困难。尽管存在这些挑战，本研究的提出的方法仍为利用合成数据评估和增强医疗影像生成AI系统的公平性提供了有价值的途径。
## 329. `cs.CV` - AFRDA：用于领域自适应语义分割的注意特征精炼 [PDF](https://arxiv.org/pdf/2507.17957), [HTML](https://arxiv.org/abs/2507.17957)
### Authors
Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu
### Background
无监督领域自适应语义分割（UDA-SS）涉及使用标记的源域数据（如合成图像）训练模型，并将其适应未标记的目标域（如真实世界图像）而无需访问目标标注数据。现存的UDA-SS方法往往难以平衡局部细节和全局上下文信息，导致复杂区域的分割错误。
### Innovation
引入了注意力驱动的特征精炼（AFR）模块，通过精炼高分辨率特征并使用低分辨率逻辑中的语义先验来提高分割精度，同时融合高频成分以捕捉精细结构并提供关键边界信息，加强物体轮廓的定义。AFR模块还通过不确定性驱动的注意力机制动态平衡局部和全局信息，减少分类错误。AFR的轻量化设计使其能够无缝集成到HRDA基的UDA方法中，实现了最先进的分割性能。
### Conclusion
本方法在GTA V --> Cityscapes和Synthia-->Cityscapes上分别提高了1.05%和1.04%的mIoU，并且我们的框架实现可以在提供的链接中找到。
## 330. `cs.CL` - 从假设到发表：AI驱动研究支持系统的综合调查 [PDF](https://arxiv.org/pdf/2503.01424), [HTML](https://arxiv.org/abs/2503.01424)
### Authors
Zekun Zhou,Xiaocheng Feng,Lei Huang,Xiachong Feng,Ziyun Song,Ruihan Chen,Liang Zhao,Weitao Ma,Yuxuan Gu,Baoxin Wang,Dayong Wu,Guoping Hu,Ting Liu,Bing Qin
### Background
研究是推动人类文明进步的基本过程，然而，它需要研究人员投入大量时间和精力。近年来，人工智能技术的迅速发展激励研究人员探索如何利用AI加速和提升研究过程。
### Innovation
本文对AI在促进研究领域的进步进行系统性回顾，将相关研究分为假设形成、假设验证和论文发表三个主要类别。还讨论了这些领域的现状挑战及未来研究方向，并提供了不同领域AI工具和基准的综合概述。旨在为研究初学者提供指南并促进未来研究。
### Conclusion
本文旨在为初学者介绍AI驱动的研究支持系统的现状，并促进未来研究。相关资源已公开发布，可在所提供的链接处访问。
## 331. `cs.CV` - OPEN：虚拟康复学习环境中老年患者参与度识别的基准数据集和基准 [PDF](https://arxiv.org/pdf/2507.17959), [HTML](https://arxiv.org/abs/2507.17959)
### Authors
Ali Abedi,Sadaf Safa,Tracey J.F. Colella,Shehroz S. Khan
### Background
虚拟学习环境和远程医疗教育中，参与度对于参与者满意度、表现和依从性至关重要。准确测量虚拟群组中的参与度仍是一个挑战。现有研究和数据集主要集中于年轻学术群体，针对老年人的虚拟和远程医疗学习环境的数据集仍然缺乏。同时，大多数现有方法忽视了参与度的上下文相关性和在不同会话中的纵向性质。因此，本文提出了一种新的数据集OPEN，它是一个支持人工智能驱动参与度识别的基准数据集。
### Innovation
OPEN数据集是为老年患者在虚拟康复学习环境中的参与度识别首次提供一个基准数据集。它收集了11名老年参与者在为期六周的每周虚拟团体学习会话中的数据，生成了超过35个小时的数据，这是此类数据集中最大的。该数据集通过面部、手部和身体关节地标，以及从视频中提取的情绪和行为特征，提供了具有5秒、10秒、30秒和可变长度样本的不同版本。通过对多种机器学习和深度学习模型进行训练，实现了参与度识别的准确率高达81%。
### Conclusion
OPEN数据集为适应老年群体的个性化参与度建模提供了可扩展的基础，并为更广泛的参与度识别研究做出了贡献。
## 332. `cs.CV` - Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models [PDF](https://arxiv.org/pdf/2507.17853), [HTML](https://arxiv.org/abs/2507.17853)
### Authors
Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang
### Background
近年来，从文本生成图像（T2I）的技术取得了显著成果，但这些模型在处理复杂提示时仍然面临挑战，尤其是涉及多个具有不同属性的主题时。现有的方法难以确保生成图像的质量与文本描述一致。
### Innovation
本文提出了一个无需训练的框架Detail++，引入了一种新颖的分阶段细节注入策略（PDI），将复杂提示分解为一系列简化子提示，逐步指导生成过程。此策略结合了自我注意机制以确保全局布局，随后进行精确的细节调整。同时，提出了交叉注意机制和测试时的质心对齐损失，以减少绑定噪声并增强属性一致性。
### Conclusion
在T2I-CompBench及新构建的风格分解基准测试上进行的广泛实验表明，Detail++在处理多个对象和复杂风格条件下显著优于现有方法。
## 333. `cs.CV` - AG-VPReID.VIR: 桥接空中和地面平台的基于可见光-红外视频的人再识别 [PDF](https://arxiv.org/pdf/2507.17995), [HTML](https://arxiv.org/abs/2507.17995)
### Authors
Huy Nguyen,Kien Nguyen,Akila Pemasiri,Akmal Jahan,Clinton Fookes,Sridha Sridharan
### Background
24小时监控系统需要跨越可见光和红外模态的人再识别（Re-ID），但现有的数据集主要集中在地面视角。虽然地面红外系统在夜间提供能力，但存在遮挡、覆盖有限和易受障碍物影响的问题，这些问题通过空中视角可以解决。本文介绍了AG-VPReID.VIR数据集，这是首个结合空中和地面视角，使用无人机和固定CCTV摄像头，在RGB和红外模态下收集的多视角视频的人再识别数据集。该数据集提供了独特的挑战，包括多视角变化、模态差异和时间动态。
### Innovation
本文提出的AG-VPReID.VIR数据集填补了现有数据集的空白，提供了一个全新的多视角、跨模态的人再识别数据集。此外，还提出了一种名为TCC-VPReID的新颖多流架构，针对跨平台和跨模态人再识别中的联合挑战进行设计。该架构通过鲁棒的风格特征学习、基于记忆的多视角适应以及中间引导的时间建模，桥接了空中和地面视角以及RGB-IR模态之间的领域差距。实验表明，该框架在多个评估协议中实现了显著的性能提升，超越了现有的数据集和方法。相关数据集和代码可在项目网站上获得。
### Conclusion
本文提出的数据集和方法为24小时监控系统的跨模态人再识别提供了新的数据支持和解决策略。通过TCC-VPReID框架在多个评估集上的优异表现表明，该方法不仅解决了现有的跨模态人再识别挑战，还为未来的相关研究提供了重要参考。
## 334. `cs.CL` - GCC-Spam: 通过生成对抗网络、对比学习和字符相似性网络实现垃圾短信检测 [PDF](https://arxiv.org/pdf/2507.14679), [HTML](https://arxiv.org/abs/2507.14679)
### Authors
Zhijie Wang,Zixin Xu,Zhiyuan Pan
### Background
互联网上垃圾短信的指数级增长需要强大的检测机制来减轻信息泄露和社会不稳定的风险。这一工作主要针对两类挑战：垃圾短信发送者的对抗策略以及缺乏标记数据。
### Innovation
提出了一个新颖的垃圾短信检测框架GCC-Spam，该框架包含三个核心技术创新。首先，字符相似性网络捕捉拼写和音韵特征，抵御字符混淆式攻击并生成句子嵌入供后续分类；其次，通过对比学习增强可区分性，优化垃圾短信和正常文本的潜在空间距离；最后，使用生成对抗网络生成逼真的伪垃圾短信样本，缓解数据稀缺问题，同时提高模型的鲁棒性和分类准确性。
### Conclusion
在真实世界数据集上的详尽实验表明，该模型在显著减少标记示例数量的情况下，优于基准方法，实现了更高的检测率。
## 335. `cs.CV` - Lumina-mGPT 2.0：独立的自回归图像建模 [PDF](https://arxiv.org/pdf/2507.17801), [HTML](https://arxiv.org/abs/2507.17801)
### Authors
Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao
### Background
研究现有关于高质量图像生成的方法主要依赖于预训练组件或混合架构。这些方法在灵活性、可扩展性方面有一定的限制。
### Innovation
Lumina-mGPT 2.0是一个全新的、独立的解码器模式的自回归模型，能够在不依赖预训练组件的情况下进行从零训练的图像生成。该模型通过统一的标记化方案实现了广泛的任务处理能力，并结合高效的解码策略以提高质量和速度。
### Conclusion
Lumina-mGPT 2.0在标准的文本到图像基准测试中展示了与基于扩散的最新模型相当甚至更好的性能，并且在多任务处理方面表现优异。该模型为统一多模态生成提供了一个强大的、灵活的基础框架。
## 336. `cs.CV` - GRR-CoCa: 利用LLM机制改进多模态模型架构 [PDF](https://arxiv.org/pdf/2507.18009), [HTML](https://arxiv.org/abs/2507.18009)
### Authors
Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi
### Background
现有的最先进的图像和文本生成模型是多模态模型，具有与大型语言模型（LLMs）相似之处。尽管这些模型取得了优异的表现，但主流的多模态模型架构在结构复杂性上仍落后于当今的LLMs。因此，作者提出了一个改进的SOTA对比式captioner模型GRR-CoCa，该模型在文本解码器和视觉变压器（ViT）编码器中分别引入了高斯错误门控线性单元、根均方归一化和旋转位置嵌入等架构改进。这些架构改进已经在LLMs中证明能够提升模型性能，但在CoCa模型中尚未被采用。作者将GRR-CoCa与使用相同修改后文本解码器但保留CoCa原始ViT编码器的基准模型进行了对比测试。
### Innovation
GRR-CoCa模型通过引入高斯错误门控线性单元、根均方归一化和旋转位置嵌入等架构改进，提高了多模态模型的性能和泛化能力。这些改进已经在大型语言模型中证明有效，但尚未在对比式captioner模型中得到应用。GRR-CoCa在预训练数据集和三个不同的微调数据集上表现显著优于对照组模型，特别是在对比损失、困惑度和CoCa损失方面有明显提升。
### Conclusion
改进后的GRR-CoCa模型在预训练和微调任务中均表现出优异的性能，证明了利用大型语言模型机制对多模态模型架构进行改进能有效提升模型的性能和泛化能力。
## 337. `cs.CL` - 无分割的语音流畅度 [PDF](https://arxiv.org/pdf/2507.16838), [HTML](https://arxiv.org/abs/2507.16838)
### Authors
Xinwei Cao,Zijian Fan,Torbjørn Svendsen,Giampiero Salvi
### Background
语音流畅度检测与诊断（MDD）是现代计算机辅助语言学习（CALL）系统的重要组成部分。在MDD中，音素级发音评估对于帮助二语学习者改进发音至关重要。然而，现有的大多数系统都基于所谓的语音流畅度（GOP）评分，这种评分方法需要将语音事先分割成音素单位。这限制了这些方法的准确度，且限制了使用更现代的连接时序分类（CTC）声学模型来评估它们的能力。
### Innovation
研究首先提出了一种自我对齐的GOP（GOP-SA），使CTC训练的ASR模型能够用于MDD。然后定义了一种更通用的无需对齐的方法，考虑了目标音素的所有可能对齐方式（GOP-AF）。给出了GOP-AF定义的理论说明，解决可能的数值问题，并提出了适当的规范化，使该方法适用于具有不同时间峰值的声学模型。提供了在CMU Kids和Speechocean762数据集上广泛实验的结果，比较了不同方法的定义，估计了GOP-AF对声学模型峰值和目标音素上下文量的依赖性。最后，与最近的研究成果对比展示了基于提出的特征向量在音素级发音评估上达到最先进的效果。
### Conclusion
实验表明，与普通GOP方法相比，GOP-SA和GOP-AF不仅能增加对齐的可靠性，还能用CTC训练的声学模型来评估语音流畅度，还能解决模型峰值差异和上下文依赖性等问题。对于Speechocean762数据集上的评估任务，提出的特征向量达到了最先进的性能。这种方法为改进语音学习工具和提高二语学习者发音能力提供了新的解决方案。
## 338. `cs.CV` - 从骨架数据识别情绪：一项全面的综述 [PDF](https://arxiv.org/pdf/2507.18026), [HTML](https://arxiv.org/abs/2507.18026)
### Authors
Haifeng Lu,Jiuyi Chen,Zhen Zhang,Ruida Liu,Runhao Zeng,Xiping Hu
### Background
情绪识别通过身体动作已经成为了一种引人注目的隐私保护替代方法，不再依赖于面部表情或生理信号。3D骨架获取技术和姿势估计算法的最新进展显著提高了基于全身运动的情绪识别的可行性。本综述旨在全面系统地回顾骨架基情绪识别技术，涵盖情感心理学模型、不同数据集的采集方法、情感标注策略、姿势基和步态基方法，并提出统一分类框架，还探讨了情绪识别在心理健康评估中的应用以及未来研究方向中的挑战和机遇。
### Innovation
提出了一个统一的分类框架，涵盖了四种主要的技术范式：传统方法、Feat2Net、FeatFusionNet和End2EndNet，并分析了每个类别中的代表性工作以及基准测试结果。
### Conclusion
综述讨论了情绪识别技术在心理健康评估中的扩展应用，如抑郁症和自闭症的检测，并指出了该领域快速发展的未来研究方向中的开放挑战。
## 339. `cs.CV` - Celeb-DF++: 大规模具有挑战性的视频 deepfake 基准用于泛化取证 [PDF](https://arxiv.org/pdf/2507.18015), [HTML](https://arxiv.org/abs/2507.18015)
### Authors
Yuezun Li,Delong Zhu,Xinjie Cui,Siwei Lyu
### Background
AI技术的迅速发展导致在线流通的deepfake视频种类多样化，现有通用取证方法（即使用单一模型检测多种未见过的deepfake类型）面临着严峻挑战。当前的大多数数据集尽管规模庞大，但覆盖的伪造类型有限，不足以开发出通用化的检测方法。因此，研究者基于之前建立的Celeb-DF数据集，创建了Celeb-DF++，这是一个大规模且具有挑战性的视频deepfake基准，旨在解决通用化取证问题。Celeb-DF++涵盖了常见的三种伪造场景：Face-swap（面部互换）、Face-reenactment（面部重演）和Talking-face（说话面部），每个场景包含了大量高质量的伪造视频，这些视频是用22种不同的近期deepfake方法生成的，通过这种方式，它们覆盖了最常见的野外观测到的deepfake案例。此外，研究还引入了评估协议，用于测量24种近期检测方法的泛化能力，突显了现有检测方法的局限性和新数据集的困难性。
### Innovation
引入了Celeb-DF++，这是一个大规模且具有挑战性的视频deepfake基准，用于专门针对泛化取证挑战。该数据集涵盖了三种常见的伪造场景，并使用22种不同的近期deepfake方法生成了大量高质量伪造视频，扩展了伪造的多样性。同时，引入了新的评估协议，以衡量最新检测方法的泛化能力。这有助于提高现有检测方法的性能，识别现有数据集的局限性，以及提升新数据集的挑战性。
### Conclusion
Celeb-DF++为泛化取证提供了一个更为准确和全面的基准，不仅可以促进现有检测方法的性能提升，还可以推动开发更强大的通用化深层伪造检测方法。通过使用此类新数据集和评估协议，可以更好地理解和应对当前和未来深层伪造的挑战。
## 340. `cs.CV` - 通过后训练提高视频生成中的场景转换意识 [PDF](https://arxiv.org/pdf/2507.18046), [HTML](https://arxiv.org/abs/2507.18046)
### Authors
Hanwen Shen,Jiajie Lu,Yupeng Cao,Xiaonan Yang
### Background
近年来，AI生成视频在文本到视频任务中表现出强大的性能，特别是在生成单一场景的短视频方面。然而，当生成长视频或包含多个场景的视频时，现有的模型无法顺利结合场景转换，主要是因为模型无法从提示中推断出何时需要进行场景转换。开源模型通常基于单场景视频剪辑的数据集进行训练，这限制了它们对多场景生成的理解和响应能力。因此，开发场景转换意识对于多场景生成至关重要，这使模型能够通过准确检测场景转换来分割视频成不同的片段，从而提高文本到视频的生成效果。
### Innovation
本文提出了Transition-Aware Video (TAV)数据集，该数据集包含有多场景转换的预处理视频剪辑。通过后训练该数据集，实验表明，模型能够更好地理解提示中的场景转换需求，减小所需场景与生成场景之间的差距，同时保持图像质量。这意味着模型在多场景生成方面的能力得到了显著提升，能够更好地理解并处理多场景视频生成任务。
### Conclusion
通过TAV数据集的后训练，模型在多场景生成中的场景转换意识得到了增强，改善了多场景视频生成的效果，为未来进一步提高多场景生成的性能奠定了基础。
## 341. `cs.CV` - ViGText: 使用视觉语言模型解释和图神经网络的deepfake图像检测 [PDF](https://arxiv.org/pdf/2507.18031), [HTML](https://arxiv.org/abs/2507.18031)
### Authors
Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan
### Background
随着深伪技术的迅速发展，这种技术能够生成逼真的虚假数字内容，威胁了媒体的真实性。传统的深伪检测方法在处理复杂的、定制化的深伪方面常常表现不佳，尤其是在泛化能力和对恶意攻击的鲁棒性方面。
### Innovation
ViGText 是一种新颖的方法，它将图像与视觉大型语言模型（VLLM）的文本解释结合在基于图的框架内，以提高深伪检测能力。其创新之处在于将详细的解释与视觉数据相结合，提供了一种比字幕更具上下文感知的分析方法，字幕通常缺乏具体性，无法揭示细微的不一致之处。通过将图像划分成块，构建图像和文本图，并使用图神经网络（GNNs）进行分析，ViGText 能够识别深伪。通过跨空间和频率域的多级特征提取，ViGText 捕捉到的细节提高了其对复杂深伪的鲁棒性和准确性。
### Conclusion
广泛的实验表明，ViGText 显著提高了泛化性能，并在检测用户定制的深伪时达到了显著的性能提升。具体来说，泛化评估下的平均 F1 分数从 72.45% 提高到 98.32%，反映出模型在遇到未见的、细调的稳定扩散模型版本时的出色泛化能力。在鲁棒性方面，ViGText 的召回率比其他深伪检测方法提高了 11.1%。当面对利用其基于图结构的架构的针对性攻击时，ViGText 将分类性能的下降限制在不到 4%。ViGText 使用详细的视觉和文本分析，设立了检测深伪的新标准，有助于确保媒体的真实性与信息的完整性。
## 342. `cs.CV` - 遥感分割方法在土地利用和覆盖类型分类中的比较 [PDF](https://arxiv.org/pdf/2507.18099), [HTML](https://arxiv.org/abs/2507.18099)
### Authors
Naman Srivastava,Joel D Joy,Yash Dixit,Swarup E,Rakshit Ramesh
### Background
土地利用土地覆盖（LULC）制图对于城市和资源规划至关重要，是促进智能和可持续城市发展的重要组成部分。本文通过分析先进的LULC制图技术，重点关注基于查找表（LUT）的大气校正技术应用于Cartosat多光谱（MX）传感器影像，并结合监督和半监督学习模型来预测LULC。研究案例选择印度海得拉巴，展示了由于快速城市化导致的土地利用变化情况，如城市扩张、绿色空间缩小和工业区扩展等。这表明这些技术的实际应用价值对于城市规划者和政策制定者至关重要。
### Innovation
本文进一步提出了动态加权的交叉伪监督（CPS）模型，通过增强训练过程中伪标签的可靠性，提升了LULC预测的准确性。提出的CPS模型应用了DeepLabV3+和交叉伪监督方法，提高了LULC分类的精度。
### Conclusion
通过系统的地利用土地覆盖（LULC）分类技术分析，本文展示了这些方法在各种城市规划应用中的准确性和实用性。特别是对于快速城市化的区域，通过分析Cartosat MX影像数据随时间的变化，揭示了土地利用模式的变化趋势。此研究为未来LULC分类技术的发展提供了借鉴，有助于支持有效的城市规划和政策制定。
## 343. `cs.CV` - Bearded Dragon Activity Recognition Pipeline: 一种基于AI的行为监测方法 [PDF](https://arxiv.org/pdf/2507.17987), [HTML](https://arxiv.org/abs/2507.17987)
### Authors
Arsen Yermukan,Pedro Machado,Feliciano Domingos,Isibor Kennedy Ihianle,Jordan J. Bird,Stefano S. K. Kaburu,Samantha J. Ward
### Background
传统监测鬃狮蜥（Pogona Viticeps）的行为耗时且容易出错。本项目引入了一种基于You Only Look Once (YOLO)对象检测模型的自动化系统，用于实时视频分析，以识别两种关键行为：晒太阳和觅食。
### Innovation
研究人员使用了一个包含1200张图像的自定义公开数据集来训练五个YOLO变体模型（v5、v7、v8、v11、v12），模型在行为分类上的准确性和速度得到了提高。最终，YOLOv8s被选为最优模型，因其在准确率（mAP@0.5:0.95 = 0.855）和速度上表现出更优的平衡。研究还提出了通过扩展数据集或使用专门针对小对象的检测器来改进蟋蟀检测的改进方法。
### Conclusion
此自动化系统为在受控环境中监控爬行动物行为提供了一种可扩展的解决方案，显著提高了研究效率和数据质量。
## 344. `cs.CV` - 一个用于预测自然刺激下脑响应的多模态序列到序列变换器 [PDF](https://arxiv.org/pdf/2507.18104), [HTML](https://arxiv.org/abs/2507.18104)
### Authors
Qianyi He,Yuan Chang Leong
### Background
2025年Algonauts挑战赛要求社区开发用于预测基于自然的多模态电影全脑功能性磁共振成像（fMRI）响应的编码模型。本研究提出了一个自回归的序列到序列转换器，从视觉、听觉和语言输入中预测fMRI活动，提取特征采用了预训练模型，如VideoMAE、HuBERT、Qwen和BridgeTower。解码器通过双重交叉注意机制整合了以前的脑状态、当前的刺激信息和情节级别摘要信息，既考虑了来自刺激感知的细节，也考虑了高水平叙述内容提供的叙述信息。
### Innovation
一种主要创新是利用多模态上下文序列来预测脑活动序列，使模型能够捕捉刺激和神经响应中的长期时间结构。另一项创新是将共享编码器与部分被试特定解码器结合，利用跨被试的共同结构，同时考虑个体差异。
### Conclusion
该模型在分布内外数据上均表现出色，证明了时间意识的多模态序列模型在脑活动预测中的有效性。编码器和解码器的代码可在此处获取：[链接]。
## 345. `cs.CV` - 分布不确定性进行离分布检测 [PDF](https://arxiv.org/pdf/2507.18106), [HTML](https://arxiv.org/abs/2507.18106)
### Authors
JinYoung Kim,DaeUng Jo,Kimin Yun,Jeonghyo Song,Youngjoon Yoo
### Background
通过深度神经网络估计不确定性是检测离分布（OoD）样本的广泛使用方法，通常表现为预测不确定性高。然而，传统方法如蒙特卡洛（MC）丢弃大多只关注模型或数据不确定性，未能与OoD检测的语义目标一致。因此需要一个能够同时建模分布不确定性并识别OoD区域及误分类区域的新框架。
### Innovation
提出了一种名为Free-Energy Posterior Network的新型框架，该框架通过自由能对不确定性和识别OoD及误分类区域进行了建模。该方法包括两个关键贡献：（1）通过Beta分布参数化的自由能基密度估计器，使得在模棱两可或未见过的区域能够进行细粒度的不确定性估计；（2）将自由能损失整合到后验网络中，直接从学习参数中估计不确定性，无需进行随机采样。通过将该方法与残差预测分支（RPL）框架结合，该方法能够学习OoD区域，并通过Beta分布的方差获得语义上有意义且计算高效的不确定性感知分割方案。
### Conclusion
该方法在Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can等具有挑战性的实际基准上进行了验证，证明了其有效性和语义意义以及计算效率。
## 346. `cs.CV` - 低光条件一致学习通过双向扩散进行低光图像增强 [PDF](https://arxiv.org/pdf/2507.18144), [HTML](https://arxiv.org/abs/2507.18144)
### Authors
Jinhong He,Minglong Xue,Zhipu Liu,Mingliang Zhou,Aoxiang Ning,Palaiahnakote Shivakumara
### Background
低光图像增强旨在提高退化图像的可见度，使其更符合人的视觉感知。尽管基于扩散的方法因其强大的生成能力表现出有希望的结果，但它们的一维退化建模往往难以捕捉真实世界退化模式的复杂性，导致结构不一致和像素错位。
### Innovation
提出了双向扩散优化机制，该机制联合建模低光和正常光图像的退化过程，使退化参数匹配更加精确，增强生成质量。具体而言，在训练过程中执行双向扩散（从低光到正常光和从正常光到低光），并引入一种自适应特征交互块（AFI）来细化特征表示。通过利用这两条路径的互补性，我们的方法在照明衰减和噪声分布方面施加了隐式的对称约束，促进一致的退化学习，并提高模型对照明和细节退化的感知能力。此外，设计了一种反射感知校正模块（RACM）以在去噪后指导颜色恢复并抑制过度曝光区域，确保内容一致性并生成高质量、符合人类视觉感知的图像。
### Conclusion
在多个基准数据集上的大量实验表明，我们的方法在定量和定性评估中均优于最新的方法，同时有效泛化到多种退化场景。
## 347. `cs.CV` - 超越点的注册：基于格拉姆森流形上测地线距离的通用仿射子空间对齐 [PDF](https://arxiv.org/pdf/2507.17998), [HTML](https://arxiv.org/abs/2507.17998)
### Authors
Jaeho Shin,Hyeonjae Gil,Junwoo Jang,Maani Ghaffari,Ayoung Kim
### Background
 affine Grassmannian 在表达线和面之间的接近度方面因其在度量特征间距离上的理论精确性而受到青睐。尽管如此，现有的方法只能测量接近度而不能将距离明确表示为刚体变换的函数，导致在基于这种测量方法的注册问题中的应用受限。本文首次明确推导出两个格拉姆森特征之间关于刚体变换（$boldsymbol{R}$ 和 $boldsymbol{t}$）的可优化代价函数。
### Innovation
本文提出了关于两个仿射子空间的优化代价函数，该函数基于旋转和位移基的变换。所提出的代价函数能够应用于任何仿射子空间的注册问题。与基于向量参数的方法相比，该方法能够直接最小化对刚体变换的测地线距离，从而找到全局最优解，而不依赖于表示的不确定性。所提出的代价函数及其应用于最大内群集的分支界限（BnB）求解器的扩展已经在多种计算机视觉任务中展示了提高现有解决方案的收敛性或优于现有解决方案的能力。
### Conclusion
提出的代价函数及其应用于最大内群集的分支界限（BnB）求解器的扩展已经在多种计算机视觉任务中展示了提高现有解决方案的收敛性或优于现有解决方案的能力。代码可在以下链接获取：https://example.com/code.
## 348. `cs.CV` - 基于强化学习的视频时间定位数据集与训练策略 [PDF](https://arxiv.org/pdf/2507.18100), [HTML](https://arxiv.org/abs/2507.18100)
### Authors
Ruizhe Chen,Zhiting Fan,Tianze Luo,Heqing Zou,Zhaopeng Feng,Guiyang Xie,Hansheng Zhang,Zhuochen Wang,Zuozhu Liu,Huaijian Zhang
### Background
视频时间定位（VTG）旨在根据自然语言查询在视频中定位相关的时间段。尽管大型视觉-语言模型（LVLM）和指令调优取得了进展，但现有方法通常存在时间感知有限和泛化能力差的问题。
### Innovation
本文介绍了一种两阶段训练框架，将监督微调与强化学习（RL）结合，以提高VTG模型的准确性和鲁棒性。首先利用高质量的冷启动数据进行监督微调初始化，随后通过难度控制的RL进一步增强时间定位和推理能力。
### Conclusion
全面的实验表明，在多个VTG基准上，我们的方法在各种场景下不仅优于现有模型，尤其是在具有挑战性和开放域的情景中。我们深入分析了训练策略和数据集的制作，强调了高质量冷启动数据和难度控制的RL的重要性。为了促进进一步的研究和工业应用，我们发布了所有中间数据集、模型和代码。
## 349. `cs.CV` - 高保真三维高斯修复：保持多视图一致性和逼真细节 [PDF](https://arxiv.org/pdf/2507.18023), [HTML](https://arxiv.org/abs/2507.18023)
### Authors
Jun Zhou,Dinghao Li,Nannan Li,Mingjie Wang
### Background
近期在多视图三维重建和新视图合成方面取得了显著进步，特别是通过神经辐射场(NeRF)和三维高斯点扩散法(3DGS)，极大地提升了三维内容创作的真实性和效率。然而，三维场景的修复仍然是一个具有挑战性的任务，原因在于三维结构的不规则性和维护多视图一致性的重要需求。
### Innovation
提出了一种新颖的三维高斯修复框架，通过利用稀疏修复视图来重构完整的三维场景。该框架包含自动掩膜细化过程和区域级不确定性引导优化。该方法通过一系列操作（包括高斯场景滤波和反投影）细化修复掩膜，以精确定位遮挡区域并实现逼真的边界恢复。同时，不确定性引导的细粒度优化策略能估计多视图图像中每个区域的重要性，从而减轻多视图不一致性，提高修复结果的细节保真度。
### Conclusion
在不同数据集上进行的全面实验表明，我们的方法在视觉质量和视图一致性方面均优于现有的最先进的方法。
## 350. `cs.CV` - 使用YOLO实现边缘FPGA上的实时目标检测与分类 [PDF](https://arxiv.org/pdf/2507.18174), [HTML](https://arxiv.org/abs/2507.18174)
### Authors
Rashed Al Amin,Roman Obermaisser
### Background
对象检测和分类是各种应用领域的关键任务，特别在高级驾驶辅助系统（ADAS）的发展中非常重要。现有的基于深度学习的方法，如卷积神经网络（CNN）、单阶段检测器（SSD）和YOLO，在现场可编程门阵列（FPGA）上部署时显示出了高准确性和计算速度。然而，尽管取得了这些进展，最新的YOLO基对象检测和分类系统仍然存在资源效率不足的问题，不适合边缘FPGA平台。
### Innovation
本文提出了一种基于YOLOv5，为FPGA部署优化的资源高效实时对象检测和分类系统。该系统在COCO和GTSRD数据集上进行训练并实施在Xilinx Kria KV260 FPGA板上。实验结果表明分类准确度为99%，功率消耗为3.5W，处理速度为9帧每秒（FPS）。
### Conclusion
这些结果突显了本文提出的方法在边缘计算应用中实现实时、资源高效对象检测和分类的有效性。
## 351. `cs.CV` - 使用对比学习和多模型伪标签法进行3D LiDAR语义分割的无监督域适应 [PDF](https://arxiv.org/pdf/2507.18176), [HTML](https://arxiv.org/abs/2507.18176)
### Authors
Abhishek Kaushik,Norbert Haala,Uwe Soergel
### Background
3D LiDAR在自主系统中的语义分割性能会因为领域偏移（如传感器类型、地理位置）而下降，但手动标注目标数据成本过高。
### Innovation
提出了一种新的两阶段框架：首先通过无监督对比学习在片段级别预训练骨干网络，学习领域不变的鲁棒特征；其次采用多样化的前沿架构集合进行多模型伪标签策略，生成高质量的伪标签，避免单一模型偏见；最后使用这些伪标签精细调整预训练网络。
### Conclusion
实验证明该方法在SemanticKITTI到未标注目标数据集上的语义分割准确性显著提升，优于直接转移和单一模型的无监督域适应方法。该结果表明结合对比预训练和精细的组合伪标签是有效填补复杂领域差距的方法，无需目标领域标注。
## 352. `cs.CV` - 差分-UMamba：在有限数据场景下重新思考肿瘤分割 [PDF](https://arxiv.org/pdf/2507.18177), [HTML](https://arxiv.org/abs/2507.18177)
### Authors
Dhruv Jain,Romain Modzelewski,Romain Hérault,Clement Chatelain,Eva Torfeh,Sebastien Thureau
### Background
在数据稀缺的情况下，深度学习模型往往会过度拟合噪声和不相关模式，这限制了它们在未见过的样本中泛化的能力。对于医学图像分割而言，这一挑战尤为突出。为此，本文通过结合UNet框架与mamba机制，提出了Diff-UMamba，该模型能够有效建模长距离依赖关系并过滤掉不必要的特征，从而专注于临床意义明显的区域，提升分割准确性与稳健性，特别是在低数据量环境中表现尤为明显。
### Innovation
Diff-UMamba集成了UNet框架和mamba机制，并引入了一个噪声抑制模块（NRM），该模块通过信号差分策略抑制编码器内部的噪声或不相关激活，促进模型过滤掉虚假特征，增强任务相关的表示，从而提高对临床相关区域的关注度。这一创新使得模型在低数据环境下的分割准确性和鲁棒性显著提升，在多个公开数据集上的评估展示了其相对于基准方法的一致性能优势，并且在有限数据条件下通过额外实验验证了其有效性。
### Conclusion
Diff-UMamba在多种公开数据集上得到了一致的性能改进，特别是在各种分割任务中表现出色，尤其是在低数据场景下。此外，该模型还在非小细胞肺癌（NSCLC）脑部CT图像中的粗肿瘤体积（GTV）分割任务上得到了4-5%的改进，证明了其在小数据量条件下的有效性。
## 353. `cs.CV` - MatSSL: 金属显微图像分割中鲁棒的自监督表示学习 [PDF](https://arxiv.org/pdf/2507.18184), [HTML](https://arxiv.org/abs/2507.18184)
### Authors
Hoang Hai Nam Nguyen,Phan Nguyen Duc Hieu,Ho Won Lee
### Background
当前对金属材料的显微图分析主要依赖于监督方法，这些方法需要重新训练每个新的数据集，并且在仅有一小部分标记样本的情况下通常表现不一致。尽管自监督学习（SSL）可以通过利用未标记的数据提供一种有希望的替代方案，但大多数现有的方法仍需要大规模的数据集才能有效。
### Innovation
MatSSL 是一种简洁的自监督学习架构，通过骨干中的门控特征融合来有效整合多级表示。MatSSL 首先在小型未标记数据集上进行自监督预训练，然后在多个基准数据集上微调模型。这种方法在仅使用少量未标记的数据的情况下，使金属图像分割模型在 MetalDAM 数据集上获得了 69.13% 的 mIoU，优于 ImageNet 预训练编码器的 66.73%，并在环境屏障涂层基准数据集（EBC）上平均 mIoU 提高了近 40%，而无需重新训练。
### Conclusion
MatSSL 确保即使在仅使用少量未标记数据的情况下，也能够在金属显微图像分割领域实现有效的适应，同时保留了大规模自然图像预训练中学习的丰富和可转移的特征。
## 354. `cs.CV` - T2VWorldBench: 评估文本到视频生成中世界知识的基准 [PDF](https://arxiv.org/pdf/2507.18107), [HTML](https://arxiv.org/abs/2507.18107)
### Authors
Yubin Chen,Xuyang Guo,Zhenmei Shi,Zhao Song,Jiahao Zhang
### Background
文本到视频（T2V）模型在生成视觉合理的场景方面表现出色，但它们利用世界知识来确保语义一致性和事实准确性的能力尚未得到充分研究。
### Innovation
本文提出了T2VWorldBench，首个系统性的评估框架，用以评估文本到视频模型的世界知识生成能力，涵盖6大类别，60个子类别和1200个跨学科任务提示，包括物理、自然、活动、文化、因果关系和物件。该基准不仅包含人类评估，还结合了使用视觉语言模型进行的自动化评估，以评估模型的人类偏好和可扩展性。
### Conclusion
研究结果表明，大多数最先进的文本到视频模型无法理解世界知识并生成真正正确的视频。这揭示了当前文本到视频模型在利用世界知识方面的能力存在巨大差距，为构建具备常识推理和事实生成稳健能力的新模型提供了宝贵的研究机会和切入点。
## 355. `cs.CV` - TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance [PDF](https://arxiv.org/pdf/2507.18192), [HTML](https://arxiv.org/abs/2507.18192)
### Authors
Minghao Fu,Guo-Hua Wang,Xiaohao Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang
### Background
近期的文本到图像生成技术主要得益于复杂的采样策略和无分类器指导（CFG）方法，以确保高质量的生成效果。CFG 方法依赖于两个前向传递，尤其是在与复杂的采样算法结合时，会带来极其高的推理成本。现有方法在处理大规模和复杂采样策略时存在效率低下问题。
### Innovation
提出了一种名为 TeEFusion 的新颖且高效的蒸馏方法，该方法将指导力度直接纳入文本嵌入，并从教师模型的复杂采样策略中蒸馏出复杂的采样方案。通过简单的线性操作融合条件和无条件文本嵌入，TeEFusion 方法能够在不增加额外参数的情况下重建所需指导。学生模型能够模仿教师模型的表现，但使用更简单且高效的采样策略，从而实现 6 倍于教师模型的推理速度，同时保持与教师模型复杂采样方法产生的图像质量相当的水平。
### Conclusion
实验结果表明，在先进模型如 SD3 上，我们的方法使得学生模型能够以较为简单的采样策略近似教师模型的表现，进而实现推理速度提升，同时保持高质量的图像生成。已经开源代码，可以在指定的链接处访问。
## 356. `cs.CV` - TextSAM-EUS: 使用文本提示学习增强SAM以准确分割内镜超声中的胰腺肿瘤 [PDF](https://arxiv.org/pdf/2507.18082), [HTML](https://arxiv.org/abs/2507.18082)
### Authors
Pascal Spiegler,Taha Koleilat,Arash Harirpoush,Corey S. Miller,Hassan Rivaz,Marta Kersten-Oertel,Yiming Xiao
### Background
胰腺癌的预后较差，主要依赖于内镜超声（EUS）进行靶向活检和放射疗法。然而，内镜超声图像中的斑点噪声、低对比度和不直观的外观使得使用全监督深度学习模型进行胰腺肿瘤分割变得既易出错又需要大量由专家标注的数据集。为了应对这些挑战，本文提出了TextSAM-EUS，这是一种新颖的、轻量级的、文本驱动的方法，无需推理阶段的手动几何提示。该方法结合生物医学CLIP文本编码器的语言提示学习（上下文优化）和使用LoRA调整的SAM架构，实现了自动胰腺肿瘤分割，仅调整了总参数的0.86%。
### Innovation
TextSAM-EUS创新地结合了利用生物医学CLIP文本编码器的语言提示学习（上下文优化）和使用LoRA调整的SAM架构，使得在无需手动几何提示的情况下，实现了自动胰腺肿瘤分割。相较其他现有的全监督深度学习模型和基础模型（例如SAM及其变种），TextSAM-EUS能够以更高的准确度完成胰腺肿瘤的分割。这是首次将提示学习应用于基于SAM的医学图像分割，提供了高效的、鲁棒的自动内镜超声分割的实用选择。
### Conclusion
TextSAM-EUS在公共可用的内镜超声胰腺数据库中达到了82.69%的Dice系数和85.28%的标准化表面距离（NSD），自动提示下达到83.10%的Dice系数和85.70%的NSD，展示了出色的表现，并且已表明可以成为自动内镜超声分割的一种实用选择。代码将在接受后公开可用。
## 357. `cs.CV` - LEAF: 基于隐式扩散模型和高效编码器蒸馏的对齐特征医学图像分割 [PDF](https://arxiv.org/pdf/2507.18214), [HTML](https://arxiv.org/abs/2507.18214)
### Authors
Qilin Huang,Tianyu Lin,Zhiguang Chen,Fudan Zheng
### Background
现有的医学图像分割方法通常直接采用预训练的扩散模型进行训练，而未对分割任务进行特定调整。尽管这些预训练的扩散模型在特征提取上仍存在不足，但它们已经展示了在医学图像分割任务中强有力的性能。然而，这些方法并没有充分利用扩散模型的潜在能力及其在减少分割结果方差方面的潜在优势。
### Innovation
该研究提出了一种名为LEAF的医学图像分割模型，该模型基于隐式扩散模型，并在精调过程中引入了一种直接预测分割图的方法，从而降低了分割结果的方差。此外，LEAF模型还采用了一种特征蒸馏方法，将卷积层的隐藏状态与基于变压器的视觉编码器提取的特征进行对齐。这种方法不仅提高了原始扩散模型在多种医学图像分割数据集上的性能，而且在推理阶段未改变模型架构，未增加参数数量或计算量，非常高效。
### Conclusion
实验结果表明，LEAF方法在多种医学图像分割数据集上提高了原扩散模型的性能，同时具有高效性，没有增加模型参数或计算量，具有广阔的应用前景。
## 358. `cs.CV` - 基于信息熵的睑板腺不均萎缩曲度量化框架 [PDF](https://arxiv.org/pdf/2507.18135), [HTML](https://arxiv.org/abs/2507.18135)
### Authors
Kesheng Wang,Xiaoyu Chen,Chunlei He,Fenfen Li,Xinxin Yu,Dexing Kong,Shoujun Huang,Qi Dai
### Background
在医学图像分析领域，精确的曲线曲度量化在多种疾病的辅助诊断和病理评估中起着关键作用。本研究旨在提出一种新的曲度量化框架，并通过评估睑板腺萎缩的均匀性来证明其有效性，这作为一种代表性的应用场景。
### Innovation
提出了一种基于信息熵的曲度量化框架，通过概率建模与熵理论的结合，并融合曲线数据领域变换。相比传统的曲率或弧弦比方法，该方法通过与预定参考曲线对比来评估目标曲线的曲度，使其更适合具有生物合理参照曲线的医学数据中的曲度评估任务，提供了一种更稳健且客观的评价标准，无需依赖理想的直线比较。
### Conclusion
通过数值模拟实验初步评估了方法的稳定性和有效性，随后应用该框架量化了睑板腺萎缩的空间均匀性，并分析了不同Demodex疾病状态患者的均匀性差异。研究结果表明两组间基于曲度的均匀性有显著差异，AUC为0.8768，敏感性为0.75，特异性为0.93，突显了该框架在曲度分析中的临床应用价值及其作为量化形态评估工具的潜力。
## 359. `cs.CV` - BokehDiff: 基于单步扩散的神经镜头模糊 [PDF](https://arxiv.org/pdf/2507.18060), [HTML](https://arxiv.org/abs/2507.18060)
### Authors
Chengxuan Zhu,Qingnan Fan,Qi Zhang,Jinwei Chen,Huaqi Zhang,Chao Xu,Boxin Shi
### Background
先前的方法在实现镜头模糊效果时受到了深度估计准确度的限制，往往在深度突变区域产生伪影。此外，缺乏大量的配对数据使得该任务更加复杂。
### Innovation
本文提出了一种名为BokehDiff的新颖的镜头模糊渲染方法，通过生成扩散先验实现了物理上准确且视觉上吸引人的结果。该方法引入了一个基于物理学启发的自注意力模块，该模块与图像形成过程相一致，并结合深度依赖的圈 Blur 约束和自遮挡效应。此外，我们通过对扩散模型进行适配来实现一步推理方案，而不引入额外的噪声，从而获得高质量和高保真的结果。
### Conclusion
为了应对缺乏可扩展的配对数据的问题，我们提出使用扩散模型合成具有透明度的真实前景图像，以平衡真实性和场景多样性，最终取得了高质量的结果。
## 360. `cs.CV` - DepthDark: 低光照环境下鲁棒的单目深度估计 [PDF](https://arxiv.org/pdf/2507.18243), [HTML](https://arxiv.org/abs/2507.18243)
### Authors
Longjian Zeng,Zunjie Zhu,Rongfeng Lu,Ming Lu,Bolun Zheng,Chenggang Yan,Anke Xue
### Background
近年来，用于单目深度估计的基本模型受到了越来越多的关注。现有方法主要针对白天光线条件，在低光照环境下效果明显下降。当前缺乏专门针对低光照场景的鲁棒基础模型。主要原因在于缺乏大规模的高质量低光照配对深度数据集，以及有效的参数高效微调（PEFT）策略。
### Innovation
为了应对这些挑战，本文提出了DepthDark，一个针对低光照环境的鲁棒基础模型。首先介绍了flare-simulation模块和noise-simulation模块来准确模拟夜间成像过程，生成高质量的低光照配对深度数据集。此外，还提出了一种有效的低光照PEFT策略，利用光照指导和多尺度特征融合来增强模型在低光照环境中的能力。
### Conclusion
我们的方法在nuScenes-Night和RobotCar-Night数据集上达到了最先进的深度估计性能，验证了其有效性，使用有限的训练数据和计算资源依然表现出色。
## 361. `cs.CV` - 通过迭代和手动指令适应大型VLMs以生成低光增强 [PDF](https://arxiv.org/pdf/2507.18064), [HTML](https://arxiv.org/abs/2507.18064)
### Authors
Xiaoran Sun,Liyan Wang,Cong Wang,Yeying Jin,Kin-man Lam,Zhixun Su,Yang Yang,Jinshan Pan
### Background
大多数现有的低光图像增强（LLIE）方法依赖于预训练模型先验、低光输入或两者的结合，而忽略了来自正常光图像的语义指导。这种局限性在复杂光照条件下限制了其效果。
### Innovation
本文提出了VLM-IMI，这是一种利用大型视觉语言模型（VLM）和迭代且手动的指令（IMIs）的新型框架，用于低光图像增强。VLM-IMI通过文本描述的正常光内容提供语义指导，使增强更加合理。引入了指令先验融合模块，动态对齐和融合图像和文本特征，促进生成详细且语义一致的输出。通过迭代和手动指令策略，在推断过程中逐步改进文本指令，增强结构保真度、语义对齐和极低光条件下的细节点恢复。
### Conclusion
广泛的实验展示了在多个场景下，VLM-IMI在定量指标和感知质量上均优于现有最先进的方法。
## 362. `cs.CV` - WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection [PDF](https://arxiv.org/pdf/2507.18173), [HTML](https://arxiv.org/abs/2507.18173)
### Authors
Haodong Zhu,Wenhao Dong,Linlin Yang,Hong Li,Yuguang Yang,Yangyang Ren,Qingcheng Zhu,Zichao Feng,Changbai Li,Shaohui Lin,Runqi Wang,Xiaoyan Luo,Baochang Zhang
### Background
利用可见光（RGB）和红外（IR）图像的互补特性能显著提高对象检测性能。本文提出了WaveMamba，一种通过离散小波变换（DWT）分解RGB和IR单模态特征并进行跨模态融合的方法。此外，还提出了一种改进的检测头，结合逆离散小波变换（IDWT），以减少信息损失并产生最终检测结果。
### Innovation
WaveMamba的主要创新在于引入了一个WaveMamba融合块（WMFB），它能够综合低/高频子带特征的融合。在WMFB中，还使用了低频Mamba融合块（LMFB），基于Mamba框架，采用通道交换和先进的门控注意力机制进行深度融合，增强高频特征使用了绝对最大融合策略。
### Conclusion
我们的方法显著提高了对象检测性能，在四个基准上的平均mAP改善了4.5%，超过了当前最先进的方法。
## 363. `cs.CV` - 增强红外小目标检测的高斯无先验表征学习与扩散先验利用 [PDF](https://arxiv.org/pdf/2507.18260), [HTML](https://arxiv.org/abs/2507.18260)
### Authors
Junyao Li,Yahao Lu,Xingyuan Guo,Xiaoyu Xian,Tiantian Wang,Yukai Shi
### Background
红外小目标检测（ISTD）在许多实际应用中起着关键作用。为了确定其性能界限，研究者使用大量的昂贵的手动标注数据进行表示学习。然而，这种方法使得最先进的ISTD方法在现实世界中的挑战条件下变得非常脆弱。本文研究了在多种数据稀缺条件下，主流方法检测性能的变化，挑战现有关于实际ISTD的理论。
### Innovation
本文提出了高斯无先验表征学习，引入了高斯无偏组压缩器，利用高斯采样和压缩进行非均匀量化，通过利用多样化的训练样本增强了ISTD模型对各种挑战的鲁棒性。此外，引入了两阶段扩散模型实现实际重建，通过使量化信号紧密匹配实际分布，显著提升了合成样本的质量和保真度。
### Conclusion
在各种数据稀缺场景下，与最先进的检测方法的比较评估证明了所提出方法的有效性。
## 364. `cs.CV` - LONG3R: 长序列流式3D重建 [PDF](https://arxiv.org/pdf/2507.18255), [HTML](https://arxiv.org/abs/2507.18255)
### Authors
Zhuoguang Chen,Minghui Qin,Tianyuan Yuan,Zhe Liu,Hang Zhao
### Background
多视图场景重建领域近年来取得了显著进展，但现有方法在处理输入图像流时存在限制。这些方法要么依赖耗时的离线优化，要么只能处理较短的序列，这限制了它们在实时场景中的应用能力。过往的方法主要受限于处理较长序列的效率和实时性问题。因此，亟需一种能够处理较长序列并保持实时处理能力的新方法。
### Innovation
该研究提出了一种名为LONG3R的模型，专门用于跨较长序列进行流式多视图3D场景重构。LONG3R采用了递归操作机制，通过每次更新更新内存来实现实时处理。它利用了一个记忆门机制来筛选相关的记忆，并将其与新的观察结果一起输入到双重源精细化解码器中进行细化交互。为有效捕捉长时间序列的记忆，LONG3R提出了3D空间-时间记忆，动态剪枝冗余的空间信息并适应性调整分辨率。该模型通过两阶段的课程训练策略提升性能，每一阶段针对特定能力进行训练。实验结果证明，与当前最先进的流式方法相比，LONG3R在较长序列上表现出更优的性能，同时保持了实时推理速度。
### Conclusion
实验结果表明，LONG3R在较长序列上优于当前最先进的流式方法，同时保持了实时推理速度。该方法的有效性和性能为长序列流式场景修复提供了新思路和解决方案。
## 365. `cs.CV` - 通过孟德尔随机化和中介分析剖析牙源性肺癌轴 [PDF](https://arxiv.org/pdf/2507.18287), [HTML](https://arxiv.org/abs/2507.18287)
### Authors
Wenran Zhang,Huihuan Luo,Linda Wei,Ping Nie,Yiqun Wu,Dedong Yu
### Background
牙周炎和蛀牙是全球数百亿人口中常见的口腔疾病，尽管观察性研究表明这些条件与肺癌之间存在联系，但其因果关系仍不确定。此研究使用孟德尔随机化（MR）分析，探讨牙周炎和蛀牙与肺癌亚型之间的因果关系，并评估肺功能的中介作用。
### Innovation
该研究采用了两种样本的孟德尔随机化方法，利用了迄今为止最大的全基因组关联研究数据，包括487,823例蛀牙和506,594例牙周炎病例的数据，以及肺癌数据来自肺癌跨学科研究联盟。主要分析方法是使用逆方差加权，并通过Delta方法评估肺功能的中介作用。结果显示，蛀牙与肺癌及其亚型之间存在显著的正向因果关系，特别是在鳞状细胞肺癌中，牙周病的影响部分通过肺功能下降（如用力肺活量和一秒用力呼气量）发挥作用。牙周炎在本研究中未发现因果效应。这些发现强调了蛀牙在肺癌风险中的因果作用，并支持将口腔保健和肺功能监测纳入癌症预防策略。
### Conclusion
本研究发现蛀牙对肺癌具有显著的因果影响，尤其是在鳞状细胞肺癌中。这一发现支持整合口腔护理和肺功能监测到癌症预防策略中。
## 366. `cs.CV` - 基于图频域驱动点云位移的3D在线适应 [PDF](https://arxiv.org/pdf/2507.18225), [HTML](https://arxiv.org/abs/2507.18225)
### Authors
Xin Wei,Qin Yang,Yijie Fang,Mingrui Zhu,Nannan Wang
### Background
虽然在线测试时适应（TTA）方法能够通过在在线推理过程中动态适应预训练模型来有效解决领域偏移问题，但在3D点云分类中的应用受限于其不规则且无序的结构。当前的3D TTA方法通常依赖于计算复杂且耗时的空域优化，并且可能需要额外的训练数据。
### Innovation
提出了一种新颖的3D点云分类方法——图频域测试时适应（GSDTTA），该方法将适应过程转移到图频域中，通过Graph Fourier Transform（GFT）将目标域的点云表示为离散统计图，并仅优化最低10%的频谱成分以减少参数数量并提高效率。通过逆GFT（IGFT）重建适应后的点云，同时应用基于特征图指导的自我训练策略，逐步优化频谱调整和模型参数。
### Conclusion
在基准数据集上的实验结果和消融研究证明了GSDTTA的有效性，其在3D点云分类任务中优于现有TTA方法。
## 367. `cs.CV` - 超越低秩性：通过修改的核范数保证矩阵恢复 [PDF](https://arxiv.org/pdf/2507.18327), [HTML](https://arxiv.org/abs/2507.18327)
### Authors
Jiangjun Peng,Yisi Luo,Xiangyong Cao,Shuang Xu,Deyu Meng
### Background
核范数（NN）在矩阵恢复问题中得到了广泛的应用，如鲁棒主成分分析（Robust PCA）和矩阵补全（matrix completion）等，利用了数据固有的全局低秩结构。现有方法多需要对局部和全局信息进行权衡来捕捉信息，且在验证局部和全局信息的同时难以提供理论上的完全恢复保证。
### Innovation
提出了一种新的修改核范数（MNN）框架，通过适当的变换对矩阵进行核范数运算，定义了MNN族范数。MNN框架的主要优势在于：(1) 同时捕获局部信息和全局低秩性，无需调整权重参数；(2) 在变换条件较宽松的情况下，为鲁棒主成分分析（Robust PCA）和矩阵补全（MC）任务提供了严格的理论恢复保证，现有方法难以做到这一点。MNN框架因其通用性和灵活性，能够适应多种已证明有效的变换，为结构低秩恢复提供了一种统一且有效的方法。
### Conclusion
广泛的实验表明了我们方法的有效性。该方法的代码和补充材料可通过指定的网址获得。
## 368. `cs.CV` - 通过自适应3D体积构建增强多视图室内3D物体检测 [PDF](https://arxiv.org/pdf/2507.18331), [HTML](https://arxiv.org/abs/2507.18331)
### Authors
Runmin Zhang,Zhu Yu,Si-Yuan Cao,Lingyu Zhu,Guangyi Zhang,Xiaokai Bai,Hui-Liang Shen
### Background
传统的基于体素的室内3D物体检测方法限制了体素的感受野仅限于图像上的固定位置，缺乏对几何和上下文信息的综合处理能力。已有研究通常依赖于预先构建的场景几何图形标注，导致了计算冗余和算法依赖性。
### Innovation
该工作报告了SGCDet，一种基于自适应3D体积构建的新颖多视图室内3D物体检测框架。它提出了一种几何和上下文感知的聚合模块，能够将几何和上下文信息整合到每个视角的自适应区域内，并动态调整不同视角的贡献，增强了体素特征的表示能力。此外，该研究还提出了一种稀疏体积构建策略，能够自适应地识别和选择高占用概率的体素，以减少自由空间中的冗余计算。这些设计使得框架能够实现有效且高效的自适应体积构建。
### Conclusion
实验结果表明，SGCDet在这方面的表现优于当前的先进方法，已在ScanNet，ScanNet200和ARKitScenes数据集上达到了最先进的性能。网络可仅使用3D边界框监督，无需依赖真实的场景几何图形标注。该工作代码已开放。
## 369. `cs.CV` - EgoExoBench: 一个多视角视点视频理解基准 [PDF](https://arxiv.org/pdf/2507.18342), [HTML](https://arxiv.org/abs/2507.18342)
### Authors
Yuping He,Yifei Huang,Guo Chen,Baoqi Pei,Jilan Xu,Tong Lu,Jiangmiao Pang
### Background
第一人称（主观视角）和第三人称（客观视角）之间的知识转移和整合是人类智能的基本特征之一，使人类能够从他人那里学习并传达自己的经验。尽管多模态大型语言模型（MLLMs）取得了快速进展，但在跨视角推理方面的能力尚未得到探索。已有研究尚未专门针对这一领域设计评估基准，无法有效衡量现有模型在这种特定任务上的表现.
### Innovation
本文介绍了一种名为EgoExoBench的新基准，旨在评估多模态大型语言模型（MLLMs）在主观视角和客观视角之间理解视频和推理的能力。该基准在全球公开数据集基础上构建，包含超过7300个问答对，并分为三种核心挑战：语义对齐、视角关联和时间推理。研究发现，现有模型在单一视角任务上表现出色，但在视角间语义对齐、视点关联和时间动态推理上表现不佳。
### Conclusion
EgoExoBench旨在为研究嵌入式代理和智能助手提供有价值的资源，助力实现类似人类的跨视角智能.
## 370. `cs.CV` - 通过初级颜色添加剂改进鸟类分类 [PDF](https://arxiv.org/pdf/2507.18334), [HTML](https://arxiv.org/abs/2507.18334)
### Authors
Ezhini Rasendiran R,Chandresh Kumar Maurya
### Background
鸟类物种分类面临的挑战包括环境噪声、重叠叫声和缺失标签。现有模型在低信噪比或多种鸟类的同时录音中表现不佳。研究表明，可以通过观察鸟叫声的音调模式、速度和重复模式来分类鸟类。尽管深度学习模型在频谱图像的应用上有所帮助，但相似的模式会导致混淆。现有模型依赖于频谱图像，但缺乏频率信息的有效利用，从而影响分类精度。
### Innovation
该研究提出了一种新方法，通过在频谱图像中嵌入频率信息（使用初级颜色添加剂），提高鸟类分类的准确性。这种方法通过强调不同鸟类的独特频率模式来增强物种区分，从而提升了分类性能，优于未使用颜色化处理的模型，并且超过了2024年鸟鸣识别挑战赛（BirdCLEF）的获胜模型，F1得分提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。研究展示了通过颜色化来整合频率信息的有效性。
### Conclusion
实验结果表明，提出的颜色化方法在物种分类上取得了显著的统计增益，且在多个评估指标上优于其他现有模型，验证了颜色化方法在鸟类分类中的有效性。
## 371. `cs.CV` - GVCCS：可见全天候摄像机序列中飞行云识别和跟踪的数据集 [PDF](https://arxiv.org/pdf/2507.18330), [HTML](https://arxiv.org/abs/2507.18330)
### Authors
Gabriel Jarry,Ramon Dalmau,Philippe Very,Franck Ballerini,Stephania-Denisa Bocu
### Background
航空业的气候影响不仅包括二氧化碳排放，还包含显著的非二氧化碳效应，尤其是来自飞机尾迹云的影响。这些冰云可以改变地球的辐射平衡，其影响甚至可能与航空二氧化碳的暖化效应相当。物理模型能够提供有关尾迹云形成和气候影响的有用估算，但它们的准确性很大程度上取决于输入的气象数据质量和对复杂过程（如冰粒子形成和湿度驱动持续性）的假设表示。现有的观测数据大多数未能全面探讨尾迹云的动力学和形成过程，通常缺乏时间跟踪数据，且无法将尾迹云追溯到其源头航班。
### Innovation
本研究提出了一个新的基于地面全天侯可见光摄像机记录的飞行云序列的数据集，GVCCS。每个尾迹云都被单独标注并随时间进行跟踪，为该云的生命周期提供了详细的分析。该数据集包含了122个视频序列（共24,228帧），包括覆盖摄像机上方形成尾迹云的航班标识。研究还建议了一个统一的深度学习框架，基于泛光分割模型进行语义分割（尾迹云像素识别）、实例分割（个体尾迹云分离）及时间跟踪，这为尾迹云分析提供了一个单一的架构基准。通过提供高质量、时间解析的注释和模型评估基准，本研究支持了更加准确的尾迹云监控，并促进了物理模型的更好校准。这为更准确的气候影响理解奠定了基础。
### Conclusion
本研究的数据集和方法为尾迹云识别和跟踪提供了新的途径，并为物理模型校准提供了基准，有助于提高对这些非二氧化碳效应的理解，从而更好地评估航空业的气候影响。
## 372. `cs.CV` - VB-Mitigator：评估和推进视觉偏见减轻的开源框架 [PDF](https://arxiv.org/pdf/2507.18348), [HTML](https://arxiv.org/abs/2507.18348)
### Authors
Ioannis Sarridis,Christos Koutlis,Symeon Papadopoulos,Christos Diou
### Background
计算机视觉模型中的偏见仍然是一个重大挑战，导致了不公平、不可靠和不具普适性的AI系统。虽然关于偏见缓解的研究有所加强，但碎片化的方法实现和不一致的评估实践阻碍了进展。由于研究之间使用不同的数据集和评估指标，使得研究结果的可重复性复杂化，难以公平地评估和比较各种方法的有效性。因此，需要一个统一的研究平台来改善这一现状。
### Innovation
为应对上述限制，我们提出了Visual Bias Mitigator (VB-Mitigator)开源框架。VB-Mitigator提供了一个统一的研究环境，包含了12种标准化的缓解方法、7种多样的基准数据集。VB-Mitigator的一个显著优势是其可扩展性，可以通过无缝集成额外的方法、数据集、评估指标和模型来增加其功能。VB-Mitigator旨在通过提供一个基础研究框架加速公平的计算机视觉模型的开发与评估，同时推荐最佳评估方法并提供现有的先进方法的全面性能比较。
### Conclusion
总体上，VB-Mitigator旨在通过提供一个标准化的研究平台，简化和推动视觉偏见缓解技术的研发与评估，从而加速向公平意识计算机视觉模型的过渡。
## 373. `cs.CV` - 迈向有效的在环智能辅助AI代理 [PDF](https://arxiv.org/pdf/2507.18374), [HTML](https://arxiv.org/abs/2507.18374)
### Authors
Filippos Bellos,Yayuan Li,Cary Shu,Ruey Day,Jeffrey M. Siskind,Jason J. Corso
### Background
人机协作在日常活动和专业领域中具有显著潜力。AI代理通过提供有信息性的指导能够增强人类的表现，但评估这种合作仍然具有挑战性，因为人类在环互动的复杂性。需要一个评估框架和多模态的人机交互数据集来测评AI指导对程序任务表现、错误减少和学习结果的影响。
### Innovation
本文引入了一个评估框架和一个包含多模态的人机交互数据集，以评估AI指导对程序任务表现、错误减少和学习结果的影响。开发了配有一体化增强现实(AR)的AI代理，用于在实际任务（从烹饪到战场医疗）中提供互动指导。通过人类研究提供了有关AI辅助人类表现的实证见解，并展示了AI辅助合作可以提高任务完成度。
### Conclusion
本工作展示了如何通过引入评估框架和开发AR装备的交互AI代理来有效评估AI辅助人类合作如何作用于程序任务表现、错误减少和学习结果。实验证明，AI辅助合作可以提升任务完成的质量和效率。
## 374. `cs.CV` - 用于视网膜血管分割的全局学习相对偏移的可变形卷积模块 [PDF](https://arxiv.org/pdf/2507.18354), [HTML](https://arxiv.org/abs/2507.18354)
### Authors
Lexuan Zhu,Yuxuan Li,Yuning Ren
### Background
可变形卷积能够通过学习偏移来适应性地改变卷积核的形状，以处理复杂形状特征。现有的可变形卷积直接变形卷积核，局限于局部特征的捕捉，而不能有效获取长距离全局特征。本文针对视网膜血管具有全局自相似复杂边缘的特点，提出了一种新的插件式可变形卷积模块，该模块使用注意力机制和前馈网络学习偏移，从而捕捉长距离的全局特征。实验结果显示，在统一框架下，提出的GDCUnet模型在公共数据集上达到了最先进的性能。进一步的消融实验表明，提出的可变形卷积模块能够更显著地学习视网膜血管的复杂特征，增强模型的表示能力和泛化能力。该模块的接口类似于传统的卷积，建议将其应用于具有复杂全局自相似特征的其他机器视觉任务中.
### Innovation
提出了一种新的插件式可变形卷积模块，使用注意力机制和前馈网络学习偏移，而不是直接变形卷积核。该模块能够学习亚像素位移场，自适应地在所有通道上扭曲特征图，等效于相对变形卷积核采样网格，实现全局特征变形，并分离卷积核大小和学习网络的关系。此模块能够更显著地学习视网膜血管的复杂特征，增强模型的表示能力和泛化能力。
### Conclusion
提出的GDCUnet模型在视网膜血管分割任务上达到了最先进的性能。相对于现有的可变形卷积模块，新提出的模块在捕捉长距离全局特征方面表现更好。该模块的接口类似于传统的卷积，未来可以应用于其他具有复杂全局自相似特征的机器视觉任务中。
## 375. `cs.CV` - MVG4D: 基于图像矩阵的多视图和运动生成以从单张图像创建4D内容 [PDF](https://arxiv.org/pdf/2507.18371), [HTML](https://arxiv.org/abs/2507.18371)
### Authors
Xiaotian Chen,DongFu Yin,Fei Richard Yu,Xuanchen Li,Xinhao Zhang
### Background
生成模型的进步显著提升了数字内容创造，从2D图像扩展到复杂的3D和4D场景。尽管取得了显著进展，但生成高保真度和时间上一致的动态4D内容仍然是一项具有挑战性的任务。
### Innovation
本文提出了MVG4D，这是一种新颖的框架，它通过结合多视图合成与4D高斯点云（4D GS）来从单张静态图像生成动态4D内容。该框架的核心是一种图像矩阵模块，可以合成时空一致性和空间多样性多视图图像，为后续的3D和4D重建提供丰富的监督信号。该方法有效地增强了时间一致性，几何保真度和视觉逼真度，解决了先前4D GS方法中的关键挑战，如运动不连续性和背景退化。
### Conclusion
在Objaverse数据集上的广泛实验表明，MVG4D在CLIP-I，PSNR，FVD和时间效率方面优于最先进的基线方法。它减少了闪烁伪像，并在不同视图和时间上增强了结构细节，从而能够实现更加沉浸式的AR/VR体验。MVG4D为从少量输入高效可控地生成4D内容设置了一个新方向。
## 376. `cs.CV` - HumanMaterial: 单张图像中的人体材质估计通过渐进式训练 [PDF](https://arxiv.org/pdf/2507.18385), [HTML](https://arxiv.org/abs/2507.18385)
### Authors
Yu Jiang,Jiahao Xia,Jiongming Qin,Yusen Wang,Tuo Cao,Chunxia Xiao
### Background
全身体型的人体材质逆渲染旨在获取高质量的材质参数，以实现不同光照条件下的照片级真实感渲染。传统方法依赖于渲染结果作为约束，但缺少材质参数的约束使得逆渲染成为病态问题。尽管此前工作通过建立材质数据集来缓解此问题，但其简化材质数据和减少的渲染方程减少了渲染结果的现实感，特别是皮肤部分。为了提高渲染结果的现实感，本文构建了一个基于扫描真实数据和统计材质数据的高质量数据集（OpenHumanBRDF），生产了额外的材质参数如位移和下层散射，尤其增强了皮肤的现实感。然而，随着对更多材质预测任务的增加，端到端模型难以平衡不同材质参数的重要性，造成模型拟合不足。因此，文中设计了一种命名为HumanMaterial的模型，采用渐进式训练策略，充分利用材质参数的监督信息，提高材质估计性能。模型通过首先使用三个先验模型获得初步材质结果，然后通过一个微调模型进行细化处理。先验模型估计不同的材质参数，每个参数对渲染结果的重要性不同，因此设计了一种可控的物理基于渲染（CPR）损失，在先验模型训练过程中增强需要优化的材质的重要性。
### Innovation
通过构建高质量的OpenHumanBRDF数据集，增加了位移和下层散射等材质参数，设计了一个可控的物理基于渲染（CPR）损失，以及提出了一种采用渐进式训练策略的HumanMaterial模型来改善材质估计。这种模型在先验模型中预先估计不同的材质参数，并在训练过程中根据需要优化这些参数的重要性。
### Conclusion
本文方法在OpenHumanBRDF数据集和真实数据上进行了广泛实验，展示出领先的性能。
## 377. `cs.CV` - DATA：协作感知中高质量特征融合的领域与时延对齐 [PDF](https://arxiv.org/pdf/2507.18237), [HTML](https://arxiv.org/abs/2507.18237)
### Authors
Chengchang Tian,Jianwei Ma,Yan Huang,Zhanye Chen,Honghao Wei,Hui Zhang,Wei Hong
### Background
特征级别的融合在协作感知（CP）中显示出潜力，通过平衡性能和通信带宽trade-off。然而，其有效性严重依赖于输入特征的质量。高质量特征的获取受到硬件多样性和部署条件带来的领域差异以及传输延迟导致的时间不对齐的影响。这些挑战导致特征质量在协作网络中累积退化。
### Innovation
本文提出了一种Domain-And-Time Alignment (DATA)网络，旨在系统性地对齐特征并最大化其语义表示以进行融合。具体而言，提出了一个保持一致性的领域对齐模块（CDAM），通过邻近区域分层下采样和感知约束判别器来减少领域差异。进一步提出了一个渐进的时间对齐模块（PTAM），通过多尺度运动建模和两阶段补偿来处理传输延迟。基于对齐后的特征，开发了一个实例聚焦的特征聚合模块（IFAM）以增强语义表示。
### Conclusion
广泛的实验表明，DATA在网络性能上达到了三个典型数据集的最新水平，即使在严重的通信延迟和姿态误差情况下，其鲁棒性也得到了保持。代码将发布于此：[](this https URL)。
## 378. `cs.CV` - 朝向一致的长期姿态生成 [PDF](https://arxiv.org/pdf/2507.18382), [HTML](https://arxiv.org/abs/2507.18382)
### Authors
Yayuan Li,Filippos Bellos,Jason Corso
### Background
目前的姿态生成方法主要依赖于中间表示，无论是通过分阶段管道中的量化还是在推理过程中累积错误的自回归模型。这种根本的限制导致了性能的下降，特别是在长期姿态生成中，保持时间连贯性至关重要。
### Innovation
我们提出了一种新颖的一阶段架构，可以直接从单个RGB图像和文本描述中生成连续坐标空间中的姿态，同时在训练和推理之间保持分布的一致性。我们的主要创新在于通过消除中间表示或基于令牌的生成，直接在姿态坐标上进行操作，通过相对运动预测机制来保持空间关系，并采用统一的占位符令牌方法来实现单前向生成，在训练和推理中表现一致。
### Conclusion
通过在Penn Action和First-Person Hand Action Benchmark (F-PHAB)数据集上的广泛实验，我们证明了我们的方法在长期生成场景中显著优于现有的基于量化的方法和自回归方法。
## 379. `cs.CV` - DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation [PDF](https://arxiv.org/pdf/2507.18407), [HTML](https://arxiv.org/abs/2507.18407)
### Authors
Xun Ye,Ruixiang Tang,Mingda Zhang,Jianglong Qin
### Background
现有的医疗图像分割方法在集成连通性信息时通常是将连通性作为一个额外的特征模块强制注入，这导致了耦合的特征空间，但没有标准的机制来量化不同特征的强度。这种方法导致了分割结果的准确性不足，并且不理想地上解决了片段问题和边缘平滑过渡问题。这些缺陷影响了临床的使用性和效果。
### Innovation
提出了DCFFSNet（双连通性特征融合分离网络），它引入了一种创新的特征空间解耦策略。该策略量化了连通性特征和其他特征之间的相对强度，并构建了一个深度连通性特征融合分离架构。该架构动态平衡了多尺度特征表达。实验证明该网络在多个数据集上超越了现有主流方法，在ISIC2018、DSB2018和MoNuSeg数据集上分别在Dice和IoU指标上分别提高了1.3%、1.2%、0.7%、0.9%和0.8%、0.9%。这表明DCFFSNet已经在所有指标上超过了现有方法，并有效地解决了分割片段问题，实现了平滑的边缘过渡，显著增强了临床使用性。
### Conclusion
DCFFSNet通过量化不同特征之间的相对强度并构建一个动态平衡多尺度特征表达的深度连通性特征融合分离架构，显著提高了医学图像分割的精度、区域一致性和临床可用性，在多个医学图像分割数据集上表现出色，优于现有的主流方法。
## 380. `cs.CV` - LMM-Det: 使大型多模态模型在物体检测中表现出色 [PDF](https://arxiv.org/pdf/2507.18300), [HTML](https://arxiv.org/abs/2507.18300)
### Authors
Jincheng Li,Chunyu Xie,Ji Ao,Dawei Leng,Yuhui Yin
### Background
大型多模态模型（LMMs）因其在多模态理解、推理和上下文学习方面的出色能力，在人工智能研究和工业界引起了广泛关注。尽管LMMs在图像描述、视觉问答和视觉定位等任务上有显著表现，但在物体检测方面的能力与专业检测器相比存在明显差距。传统的解决方法是将重鉴定器与LMMs结合，但这种方法不够简单和有效。本文探索了当大型多模态模型遇到物体检测时的方法，并提出了一种名为LMM-Det的简单有效方法，利用大型多模态模型进行基础物体检测，而不依赖于专门的检测模块。
### Innovation
提出的LMM-Det方法通过优化数据分布和推理过程，使大型多模态模型在物体检测中表现出色。具体来说，重新组织指令对话，提升大型多模态模型的物体检测能力，宣称大型多模态模型具有物体检测能力，无需额外的检测模块。实验结果证实了这种方法的有效性。
### Conclusion
通过对大型多模态模型和物体检测的结合深入研究，提出了一种有效的方法LMM-Det以增强物体检测能力。这种简单的方法能在不依赖专业检测模块的情况下增强大型多模态模型在物体检测上的表现，且通过广泛的实验验证了其有效性和多功能性。
## 381. `cs.CV` - DSFormer: 双尺度交叉学习Transformer在视觉地点识别中的应用 [PDF](https://arxiv.org/pdf/2507.18444), [HTML](https://arxiv.org/abs/2507.18444)
### Authors
Haiyang Jiang,Songhao Piao,Chao Gao,Lei Yu,Liguo Chen
### Background
视觉地点识别(VPR)对移动机器人定位至关重要，但在不同环境条件和视角下的性能保持方面面临着巨大挑战。现有方法难以在多种视角下维持可靠的性能。为了应对这一挑战，本文提出了一种新颖的框架，该框架结合了基于Transformer的双尺度交叉学习模块Dual-Scale-Former（DSFormer）和创新的块聚类策略，以增强特征表示并优化数据组织，从而提高视觉地点识别的鲁棒性。
### Innovation
提出的DSFormer通过在最终两个CNN层中提取的双尺度特征之间实现双向信息传递，利用自注意力捕捉每个尺度内的长期依赖性和共享交叉注意力进行跨尺度学习，增强了特征表示。此外，采用块聚类策略对广泛使用的San Francisco eXtra Large (SF-XL) 训练数据集进行多视角重新分区，进一步优化数据组织，减少训练数据量约30%，并在多种视角下提高了视觉地点识别的鲁棒性。
### Conclusion
综合实验表明，该方法在大多数基准数据集中实现了最先进的性能，使用512维全局描述符时，超过了其他先进的检索方法，如DELG、Patch-NetVLAD、TransVPR和R2Former，并显著提高了计算效率。
## 382. `cs.CV` - PDB-Eval: 大规模多模态模型在个性化驾驶行为描述与解释评估 [PDF](https://arxiv.org/pdf/2507.18447), [HTML](https://arxiv.org/abs/2507.18447)
### Authors
Junda Wu,Jessica Echterhoff,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley
### Background
了解驾驶员的行为和意图对于潜在风险评估和早期事故预防非常重要。为了提高安全性和驾驶员辅助系统的有效性，这些系统可以根据个别驾驶员的行为进行定制。然而，现有的数据集难以基于外部视觉证据描述和解释一般车辆运动。本文介绍了一个名为PDB-Eval的基础标准，旨在详细理解个性化的驾驶员行为，并将大规模多模态模型（MLLMs）与驾驶的理解和推理对齐。该基准包括两个主要部分：PDB-X和PDB-QA，旨在评估MLLMs对时间驱动场景的理解，并通过视觉解释问题-回答任务对MLLMs的指令微调，以增强其推理能力与驾驶任务的匹配度。
### Innovation
该研究提出了一个名为PDB-Eval的基准，包括PDB-X和PDB-QA两个部分，以评估大规模多模态模型对时间驱动场景的理解，并通过一个视觉解释问题-回答任务使这些模型更适合驾驶任务。PDB-QA作为一个通用的学习任务，可以弥补领域差距，同时保持MLLMs的一般泛化能力。研究结果显示，对细粒度描述和解释的微调可以有效地缩小MLLMs与驾驶领域之间的差距，从而在问答任务上的零样本性能提高了73.2%。进一步评估显示，在Brain4Cars的意图预测和AIDE的识别任务中，使用PDB-X微调的MLLMs在转弯意图预测任务中提高了12.5%的性能，所有任务的性能改进均达到了11.0%左右。
### Conclusion
研究展示了PDB-Eval基准的有效性，并证明了通过微调大规模多模态模型能够显著提高驾驶相关任务的性能，尤其是在意图预测和识别方面。
## 383. `cs.CV` - CRUISE：使用高斯点生成在V2X场景中合作重建和编辑 [PDF](https://arxiv.org/pdf/2507.18473), [HTML](https://arxiv.org/abs/2507.18473)
### Authors
Haoran Xu,Saining Zhang,Peishuo Li,Baijun Ye,Xiaoxue Chen,Huan-ang Gao,Jv Zheng,Xiaowei Song,Ziqiao Peng,Run Miao,Jinrang Jia,Yifeng Shi,Guangqi Yi,Hang Zhao,Hao Tang,Hongyang Li,Kaicheng Yu,Hao Zhao
### Background
V2X通信在自动驾驶中起到了关键作用，通过车辆与基础设施之间的合作来提升自动驾驶能力。尽管仿真已经在多种自动驾驶任务中发挥了重要作用，但在V2X场景中的数据生成和增强方面仍有巨大潜力未被充分挖掘。
### Innovation
CRUISE 是一个全面的重建和合成框架，用于V2X驾驶环境。通过使用分解的高斯斑点技术，CRUISE 准确地重建了真实世界的场景，并支持灵活的编辑。通过对动态交通参与者进行可编辑的高斯表示分解，CRUISE 允许场景的无缝修改和增强。此外，该框架从车辆和基础设施视角进行图像渲染，为大规模V2X数据集生成提供支持，以促进培训和评估。经过实验，该研究证明了：1) CRUISE 在重建真实V2X驾驶场景方面具有高度的真实性；2) 使用CRUISE 优化了车辆、基础设施和合作视图下的3D检测，以及在V2X-Seq基准上的联合3D跟踪；3) CRUISE 能够有效生成具有挑战性的边缘案例。
### Conclusion
CRUISE 通过其高度真实的重建能力和灵活的场景编辑功能，显著提升了V2X框架在自动驾驶技术中的应用效果，特别是对于3D检测和合作跟踪任务，并展示了在生成复杂边缘情况下提供的有效支持。
## 384. `cs.CV` - 改善大型视图语言模型对领域数据的理解 [PDF](https://arxiv.org/pdf/2507.18311), [HTML](https://arxiv.org/abs/2507.18311)
### Authors
Xiaomei Zhang,Hanyu Zheng,Xiangyu Zhu,Jinghuan Wei,Junhong Zou,Zhen Lei,Zhaoxiang Zhang
### Background
大型视图语言模型（LVLMs）在图像描述和视觉问答等集成了视觉理解和文本理解的任务中表现出了令人印象深刻的能力。这些模型通过在大规模配对了文本的图像和视频数据集上进行训练，实现了视觉感知与自然语言处理的融合。然而，这些模型在科学领域的应用仍处于初步阶段，特别是在解析自然科学研究中常用的复杂领域数据方面，研究仍然不足。
### Innovation
本文引入了FieldLVLM，这是一种新颖的框架，旨在提高大型视图语言模型对领域数据的理解能力。FieldLVLM由两种主要组件组成：一种领域意识的语言生成策略和一种数据压缩的多模态模型调整。领域意识的语言生成策略利用特定用途的机器学习管道从领域数据中提取关键的物理特征，如流型分类、雷诺数和漩涡模式，并将其转换为结构化的文本描述集。数据压缩的多模态模型调整集中在这些生成的数据集上，采用了数据压缩策略来简化领域输入的复杂性，并保留最相关信息值，以保证模型语言解码器的兼容性并更有效地指导模型学习。
### Conclusion
在新提出的基准数据集上的实验结果表明，FieldLVLM在涉及科学领域数据的任务中显著优于现有方法。我们的研究发现表明，这种方法为将大型视图语言模型应用于科学研究提供了新的可能性，有助于弥合大型模型与领域特定发现之间的差距。
## 385. `cs.CV` - 一个多数据集基准模型：ECG波形分割的半监督语义分割 [PDF](https://arxiv.org/pdf/2507.18323), [HTML](https://arxiv.org/abs/2507.18323)
### Authors
Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo
### Background
心电图（ECG）波形的分割对于临床诊断至关重要。尽管近年来利用深度学习取得了进步，但由于高质量标注数据集的稀缺性，进展受到了限制。半监督学习利用大量未标记的ECG数据提供了一种有前景的解决方案。
### Innovation
本研究首次对ECG波形分割中的半监督语义分割（SemiSeg）进行了系统性基准测试。统一并丰富了多个公共数据集，包括以往未充分利用的来源；采用来自计算机视觉领域的五种代表性的SemiSeg算法，并在卷积网络和变换器两种不同架构上实现；在本领域和跨领域两种不同场景下进行评估；提出了针对ECG的训练配置和增强策略，引入了标准化评估框架；研究结果表明，变换器在半监督ECG波形分割中表现优于卷积网络。
### Conclusion
本基准测试为推进ECG波形分割中的半监督方法奠定了基础，将促进该领域的进一步研究。
## 386. `cs.CV` - 深入研究地图不确定性在无地图轨迹预测中的应用 [PDF](https://arxiv.org/pdf/2507.18498), [HTML](https://arxiv.org/abs/2507.18498)
### Authors
Zongzheng Zhang,Xuchong Qiu,Boran Zhang,Guantian Zheng,Xunjiang Gu,Guoxuan Chi,Huan-ang Gao,Leichen Wang,Ziming Liu,Xinrun Li,Igor Gilitschenski,Hongyang Li,Hang Zhao,Hao Zhao
### Background
近年来，自动驾驶技术正向着无需地图的方法发展，利用传感器数据在线生成高分辨率地图，降低了成本昂贵的标记和维护需求。然而，这些在线生成的地图的可靠性仍不确定。虽然将地图不确定性纳入下游轨迹预测任务中显示出提高性能的潜力，但现有策略未能提供当前特定场景中不确定性更有帮助的见解。
### Innovation
本文首先分析了地图不确定性对轨迹预测具有最大正向影响的驾驶场景，并识别出一个关键的先前未被注意的因素：代理的运动学状态。基于这些洞察，我们提出了一种新颖的基于自我监督的知觉场景筛选，该方法根据未来 ego 车辆运动学的预测自适应地将地图不确定性融入轨迹预测。此外，我们引入了一种基于协方差的地图不确定性方法，进一步与地图几何图形对齐，从而更好提高轨迹预测的效果。详尽的消融研究验证了该方法的有效性，与最先进的方法相比，在使用 nuScenes 实际驾驶数据集进行无地图轨迹预测时性能提高了23.6%。
### Conclusion
我们的方法通过在线制图与轨迹预测的协同提高提供了解释性，并且性能超越了之前的方法。此外，我们的代码、数据和模型已公开可用。
## 387. `cs.CV` - Iwin Transformer: 使用交错窗口的分层视觉变换器 [PDF](https://arxiv.org/pdf/2507.18405), [HTML](https://arxiv.org/abs/2507.18405)
### Authors
Simin Huo,Ning Li
### Background
介绍了Iwin Transformer，一种新型的无位置嵌入分层视觉变换器，可以通过创新的交错窗口注意机制和深度可分离卷积直接从低分辨率调整到高分辨率。这种方法使用注意机制连接远距离的标记，并使用卷积连接相邻标记，使得在一个模块内可以实现全局信息交换，从而克服了Swin Transformer需要连续两块模块来近似全局注意的限制。
### Innovation
提出了Iwin Transformer，一种不需要位置嵌入的分层视觉变换器，采用创新的交错窗口注意力机制和深度可分离卷积，可以直接从低分辨率调整到高分辨率，并在图像分类、语义分割和视频动作识别等任务中表现出强大的竞争力。此外，验证了Iwin核心组件作为独立模块的有效性，可以无缝替代类别条件图像生成中的自我注意模块。
### Conclusion
Iwin Transformer在图像分类（ImageNet-1K上的87.4％top-1精度）、语义分割和视频动作识别等任务中表现出强大的竞争力，并验证了Iwin的核心组件作为独立模块的有效性。引入的Iwin Transformer的概念和方法有潜力激发未来的研究，比如用于视频生成的Iwin 3D注意力。相关代码和模型可以在指定的链接访问。
## 388. `cs.CV` - 重新审视针对LiDAR基检测的物理可实现对手对象攻击：澄清问题表述和实验程序 [PDF](https://arxiv.org/pdf/2507.18457), [HTML](https://arxiv.org/abs/2507.18457)
### Authors
Luo Cheng,Hanwei Zhang,Lijun Zhang,Holger Hermanns
### Background
基于LiDAR的3D物体检测因其在现实世界中的广泛应用而成为关键的研究领域。然而，许多数字攻击虽然可以操控点云或网格，但缺乏物理实现性，限制了它们的实际效果。物理对手对象攻击尚未得到充分研究，并且由于设置不一致和硬件差异导致再现性差。
### Innovation
本文提出了一种设备无关、标准化的框架，抽象了物理对手对象攻击的关键要素，支持多种方法，并提供开源代码与仿真和真实世界环境下的基准测试协议。该框架有助于公平比较，加速研究，通过成功将仿真攻击转移到物理LiDAR系统得到验证。此外，还提供了影响攻击成功因素的洞见，推进了对现实LiDAR感知中鲁棒性的理解。
### Conclusion
该框架不仅提高了物理对手对象攻击的研究水平，还促进了对该领域理解和创新，增强了现实世界中LiDAR感知的鲁棒性。
## 389. `cs.CV` - GIEMSA染色血涂片中P. falciparum检测的COCO格式实例级数据集 [PDF](https://arxiv.org/pdf/2507.18483), [HTML](https://arxiv.org/abs/2507.18483)
### Authors
Frauke Wilm,Luis Carlos Rivera Monroy,Mathias Öttl,Lukas Mürdter,Leonid Mill,Andreas Maier
### Background
准确检测染有P. falciparum的血涂片是可靠疟疾诊断的重要部分，尤其是在发展中国家。尽管深度学习对象检测方法在自动疟疾诊断中显示出了强大的潜力，但由于缺乏详细的实例级标注数据集，其应用受到限制。
### Innovation
我们改进了公开可用的NIH疟疾数据集，并以COCO格式提供详细的边界框标注，以支持对象检测训练。我们通过训练Faster R-CNN模型验证了修订后的标注，该模型能够检测感染和未感染的红细胞以及白细胞。
### Conclusion
跨验证结果表明，改进的标注集能够为稳健的检测性能提供足够质量的训练数据，并强调了标注量和一致性的重要性。改进后的标注集已在GitHub上公开提供。
## 390. `cs.CV` - 基于特征预测和3D局部损失的自助监督超声视频分割 [PDF](https://arxiv.org/pdf/2507.18424), [HTML](https://arxiv.org/abs/2507.18424)
### Authors
Edward Ellis,Robert Mendel,Andrew Bulpitt,Nasim Parsa,Michael F Byrne,Sharib Ali
### Background
获取和标注超声影像大数据集存在挑战，由于低对比度、高噪声和易受伪影影响。此过程需要大量时间和临床专业知识。近年来，自助监督学习（SSL）被看作是一个有希望的解决方案，通过利用未标注数据学习有用表示，从而在标注数据有限的情况下提高分割性能。尽管已有一些先进的基于特征预测的SSL方法，如V-JEPA，但它们尚未在超声视频数据中得到应用。此外，尽管ViT模型适用于此类方法，但在医学数据规模小的情况下，可能会因为缺乏归纳偏置、有限的空间局部性和缺乏层次结构的特征学习而表现不佳。
### Innovation
本研究首次使用V-JEPA方法应用于超声视频数据，并提出了一种新的基于3D定位的辅助任务，以改进ViT模型在预训练期间的空间局部性的理解。这种方法通过提高分割性能，即使使用10%的训练数据也能取得高达8.35%的提升。
### Conclusion
实验结果表明，通过结合V-JEPA和3D定位辅助任务，显著提高了分割性能，特别是在数据有限的情况下。
## 391. `cs.CV` - 目标现场比赛中的语义-凹视点贝叶斯注意扫描路径预测 [PDF](https://arxiv.org/pdf/2507.18503), [HTML](https://arxiv.org/abs/2507.18503)
### Authors
João Luzio,Alexandre Bernardino,Plinio Moreno
### Background
在目标导向的视觉任务中，人类感知受到自上而下和自下而上线索的共同指导。同时，中央凹视觉在有效引导注意力方面起着重要作用。现代对仿生计算注意力模型的研究利用了深度学习的进展，通过使用人眼追踪数据获得了新的最佳性能。本文评估了SemBA-FAST（基于语义的贝叶斯注意）的性能，这是一种专门设计用于预测目标可视化搜索中人类视觉注意力的自上而下的框架。SemBA-FAST通过集成深度物体检测并利用概率语义融合机制动态生成注意力图，同时利用预训练检测器和人工凹视点更新自上而下的知识，逐步提高注视点预测能力。本文通过在COCO-Search18基准数据集上评估SemBA-FAST，将其性能与其他扫描路径预测模型进行比较，从而表现出与人类真实眼动轨迹高度一致的注视序列。并且它超越了基线和其他自上而下的方法，在某些情况下还与基于扫描路径的模型竞争。这些发现为我们理解语义-凹视点概率框架在人类注意力建模中的能力提供了有价值的见解，具有对实时认知计算和机器人技术的潜在影响。
### Innovation
SemBA-FAST框架结合了深度物体检测与概率语义融合机制，以动态生成注意力图，同时利用预训练检测器和人工凹视点逐步更新自上而下的知识，提高注视点预测的准确性。该方法在COCO-Search18基准数据集上的实验结果表明，接近人类真实眼动轨迹的注视序列预测效果，并在某些情况下与基于扫描路径的模型竞争。
### Conclusion
SemBA-FAST框架在预测目标可视化搜索中的人类视觉注意力方面表现突出，其综合了深度物体检测和概率语义融合机制，通过更新自上而下的知识有效提高了注视点预测能力。这些研究结果提供了对语义-凹视点概率框架在人类注意力建模方面的认知，并对于实际应用中的实时认知计算和机器人技术具有重要意义。
## 392. `cs.CV` - Reinforced Embodied Active Defense: 利用自适应交互提升对抗3D环境中的鲁棒视觉感知 [PDF](https://arxiv.org/pdf/2507.18484), [HTML](https://arxiv.org/abs/2507.18484)
### Authors
Xiao Yang,Lingxuan Wu,Lizhong Wang,Chengyang Ying,Hang Su,Jun Zhu
### Background
3D环境中的对抗攻击已成为视觉感知系统（尤其是身份验证和自动驾驶等安全性要求高的应用）可靠性的重大威胁。现有的防御机制如对抗训练和净化，主要依靠被动策略增强鲁棒性，但这些方法往往基于关于对抗策略的预定义假设，限制了它们在动态3D环境中的适应性。
### Innovation
提出了一种主动防御框架——Reinforced Embodied Active Defense (Rein-EAD)，通过适应性探索和与环境的交互来提高3D对抗情境下的感知鲁棒性。Rein-EAD通过多步骤目标平衡即时预测准确性和预测熵减小来优化防御策略，并采用面向不确定性的奖励塑形机制，实现高效的策略更新，减少计算成本，并支持实际应用场景。
### Conclusion
全面的实验验证了Rein-EAD的有效性，展示了对抗成功率显著降低的同时保持标准准确性。Rein-EAD表现出了对未见过和适应性攻击的稳健泛化，使其适用于复杂任务，包括三维物体分类、人脸识别和自动驾驶等领域。
## 393. `cs.CV` - IntentVCNet: 解决目标导向可控视频字幕中的时空鸿沟 [PDF](https://arxiv.org/pdf/2507.18531), [HTML](https://arxiv.org/abs/2507.18531)
### Authors
Tianheng Qiu,Jingchun Gao,Jingyu Li,Huiyi Leong,Xuan Huang,Xi Wang,Xiaocheng Zhang,Kele Xu,Lan Zhang
### Background
目标导向的可控视频字幕旨在基于用户的特定意图，为视频中的特定目标生成有针对性的描述。现有的大规模视觉语言模型（LVLMs）在指令跟随和视觉理解方面表现出强大能力。尽管LVLMs在空间理解和时间理解方面表现出色，但它们无法直接响应指令进行精细的空间控制。这一时空差距使得实现视频中的目标导向的精细意图控制变得复杂。为此，本研究提出了一种新型的IntentVCNet，旨在从提示和模型两个方面弥合这一时空鸿沟，将LVLMs中的时间理解和空间理解知识结合起来。
### Innovation
我们首先提出了一个提示组合策略，以使大模型能够建模提示之间的隐式关系，这些提示描述了用户的意图和视频序列。然后，我们提出了一个参数高效的框适配器，该适配器增强了全局视觉上下文中对象的语义信息，使视觉标记在此之前就知道用户的意图。这些策略的结合增强了LVLMs在视频序列中建模空间细节的能力，使LVLMs能够准确生成目标导向的控制字幕。
### Conclusion
我们提出的方法在几个开源的LVLMs中达到了最先进的成果，并在IntentVC挑战中获得亚军。我们的代码可以在如下网址获取：this https URL
## 394. `cs.CV` - Explaining How Visual, Textual and Multimodal Encoders Share Concepts [PDF](https://arxiv.org/pdf/2507.18512), [HTML](https://arxiv.org/abs/2507.18512)
### Authors
Clément Cornet,Romaric Besançon,Hervé Le Borgne
### Background
稀疏自编码器（SAEs）已经成为从神经网络激活中提取人类可解释特征的强大技术。先前的工作基于SAE提取的特征比较了不同的模型，但这些比较仅限于同一模态的模型内比较。本文提出了一个新的指标，可以在不同模态的SAE特征之间进行定量比较，并使用该指标进行跨视觉、文本和多模态编码器的比较研究。此外，还提出了一种方法来量化不同模型类别之间单个特征的相对共享性。
### Innovation
1. 提出了新的指标方法，可以在不同模态的SAE特征之间进行定量比较。2. 对21种不同类型的编码器（包括两种显著不同的大小）进行了研究，考虑了通用和领域特定的数据集。3. 首次将视觉特征和文本特征在多模态上下文中进行比较，强调了文本预训练的影响。
### Conclusion
研究结果重新审视了之前的多模态模型训练研究，并量化了所有这些模型在某些表示或特征上的共享程度。结果显示，特定于视觉语言模型的视觉特征与文本编码器共享，突显了文本预训练的影响。代码在https://github.com/stanfordvisualmedia/largescale-encoder-comparison可用。
## 395. `cs.CV` - COT-AD: 棉花分析数据集 [PDF](https://arxiv.org/pdf/2507.18532), [HTML](https://arxiv.org/abs/2507.18532)
### Authors
Akbar Ali,Mahek Vyas,Soumyaratna Debnath,Chanda Grover Kamra,Jaidev Sanjay Khalane,Reuben Shibu Devanesan,Indra Deep Mastan,Subramanian Sankaranarayanan,Pankaj Khanna,Shanmuganathan Raman
### Background
棉花是全球最重要的经济作物之一，其分析和管理对提高产量和品质至关重要。然而，现有的农业数据集在覆盖特定作物如棉花所需的病虫害识别、植被分析和杂草管理等方面存在不足，缺乏专门针对棉花的数据支持。因此，迫切需要一个全面的数据集来提升通过计算机视觉的棉花作物分析能力。
### Innovation
提出了COT-AD（Cotton Dataset），这是一个全面的数据集，包含超过25,000张覆盖棉花生长周期的图像，其中5,000张带有注释。COT-AD包含了用于田间尺度检测和分割的航拍图像以及记录关键病害的高分辨率单反图像。这些注释涵盖了害虫和疾病识别、植被分析和杂草分析，弥补了专门用于棉花农业的数据集的关键空白。COT-AD支持诸如分类、分割、图像修复、增强和基于深度生成模型的棉花作物合成等任务，推动了数据驱动的农作物管理的进步。
### Conclusion
COT-AD为通过计算机视觉进行棉花作物分析提供了重要的数据支持，可以促进棉花害虫和疾病识别、植被管理和杂草识别等领域的研究和发展，进而推动了现代农业技术的进步。
## 396. `cs.CV` - 阐明任意噪声基扩散模型的设计空间 [PDF](https://arxiv.org/pdf/2507.18534), [HTML](https://arxiv.org/abs/2507.18534)
### Authors
Xingyu Qiu,Mengying Yang,Xinghua Ma,Dong Liang,Yuzhen Li,Fanding Li,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li
### Background
EDM能够明确扩散模型的设计空间，但其固定的噪声模式仅限于纯高斯噪声，限制了图像恢复的进步。研究表明，强迫注入高斯噪声会破坏退化图像，过度扩展图像变换距离，增加恢复复杂性。
### Innovation
提出了一种新的方法EDA（Elucidating the Design space of Arbitrary-noise-based diffusion models），它扩展了噪声模式的自由度，同时保留了EDM模块的灵活性。严格证明表明，增加噪声复杂性不会增加恢复过程中的额外计算开销。
### Conclusion
EDA在三个典型任务上进行了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影校正（全局锐化噪声）和自然图像阴影去除（局部边界感知噪声）。仅使用5次采样步骤，EDAb在偏置场校正和阴影去除任务中达到最先进的性能。
## 397. `cs.CV` - Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection [PDF](https://arxiv.org/pdf/2507.18481), [HTML](https://arxiv.org/abs/2507.18481)
### Authors
Francesco Dalmonte,Emirhan Bayar,Emre Akbas,Mariana-Iuliana Georgescu
### Background
医疗图像中的异常检测是一项重要但具有挑战性的任务，由于可能存在多种多样的异常情况以及全面标注数据集的实践上难以收集。现有的方法大多依赖于从零开始训练的自编码器架构，而本研究旨在通过使用最先进的预训练视觉基础模型（如DINO、DINOv2和Masked Autoencoder）来探索一种新的非监督式医学异常检测框架。
### Innovation
提出了一种新的自编码器框架——Q-Former Autoencoder，采用冻结的视觉基础模型作为特征提取器，无需领域特定的微调即可生成丰富且多层次的高层表示。该框架通过Q-Former架构作为瓶颈来控制重构序列的长度，同时高效地聚合多尺度特征，并引入了预训练的Masked Autoencoder计算的感知损失，以引导重构向语义上具有意义的结构发展。
### Conclusion
该框架在四个不同的医学异常检测基准上进行了评估，并在BraTS2021、RESC和RSNA基准上取得了最先进的结果。研究结果突出了预训练在自然图像上的视觉基础模型编码器的有效通用性，无需进一步微调即可应用于医疗图像分析任务。
## 398. `cs.CV` - 用于MRI和超声波匹配和注册的3D跨模态关键点描述符 [PDF](https://arxiv.org/pdf/2507.18551), [HTML](https://arxiv.org/abs/2507.18551)
### Authors
Daniil Morozov,Reuben Dorent,Nazim Haouchine
### Background
实时超声波（iUS）与术前磁共振成像（MRI）的术中配准仍然是一个未解决的问题，这是因为两种成像技术在外观、分辨率和视野方面存在严重的特定模态差异。为了应对这一挑战，本文提出了一种新型的3D跨模态关键点描述符，用于MRI-iUS匹配和配准。该方法通过术前MRI生成合成的iUS容积，采用患者特定的合成匹配方法，并通过监督对比性训练学习共享描述符空间。
### Innovation
本文提出了一种患者特定的合成匹配方法，生成来自术前MRI的合成iUS容积，使用监督对比性训练学习共享描述符空间。文章还采用了基于课程的三重损失以及动态硬负例挖掘，在训练中学习鲁棒性强、抗iUS伪影且旋转不变的关键点描述符。此外，该方法在iUS图像中检测关键点，并进行稀疏匹配，最终执行刚体配准。
### Conclusion
本文方法在3D MRI-iUS配对数据集ReMIND上进行了评估，实验表明，该方法在11名患者中优于最先进的关键点匹配方法，平均精度达69.8%。对于图像配准，该方法在ReMIND2Reg基准测试中实现了竞争力的平均目标配准误差2.39毫米。与现有的iUS-MR配准方法相比，本文框架具有可解释性、无需手动初始化，并且对iUS视野变化具有鲁棒性。
## 399. `cs.CV` - 基于概率普拉夫雷斯变换的未配准3D高斯散点图重建 [PDF](https://arxiv.org/pdf/2507.18541), [HTML](https://arxiv.org/abs/2507.18541)
### Authors
Chong Cheng,Zijian Wang,Sicheng Yu,Yu Hu,Nanjie Yao,Hao Wang
### Background
3D高斯散点图（3DGS）已发展成为3D表示的核心技术。它的效果主要依赖精确的相机姿态和准确的点云初始化，这些通常是从预训练的多视图立体匹配（MVS）模型中得到的。然而，在从数百张户外图像进行未配准重建时，现有MVS模型可能会因为内存限制而表现不佳，随着输入图像数量增加，其准确性也会下降。为了解决这一限制，本文提出了一种新的未配准的3DGS重建框架，该框架结合了预训练MVS先验与概率普拉夫雷斯映射策略。该方法将输入图像划分为子集，将子地图映射到全局空间，并与3DGS联合优化几何与姿态。
### Innovation
本文提出了一个新颖的未配准的3DGS重建框架，该框架将预训练的MVS先验与概率普拉夫雷斯映射策略结合起来。方法将数百万个点云的映射形式为概率普拉夫雷斯问题并求解封闭形式对齐。通过概率耦合机制与软尘桶机制，该方法能够在几分钟内实现数百张图像的点云和姿态的全局对齐。此外，本文还提出了一种联合优化3DGS和相机姿态的框架。这个框架利用信任感知锚点构建高斯分布，并将3DGS的可微渲染与解析雅克比集成，以同时细化场景和姿态，从而实现准确的重建和姿态估计。
### Conclusion
实验表明，本文的方法能够在未配准的图像序列上实现准确的重建，为未配准的3DGS重建设定新的最新标准。
## 400. `cs.CV` - 合成数据增强用于增强鸡胴体实例分割 [PDF](https://arxiv.org/pdf/2507.18558), [HTML](https://arxiv.org/abs/2507.18558)
### Authors
Yihong Feng,Chaitanya Pallerla,Xiaomin Lin,Pouya Sohrabipour Sr,Philip Crandall,Wan Shou,Yu She,Dongyi Wang
### Background
家禽产业在肉鸡生产推动下已成为世界上最大的动物蛋白产业。在屠宰场和禽类加工车间，自动检测分割鸡肉胴体对于质量控制、食品安全和操作效率至关重要。然而，在快速发展的工业环境中，开发稳健的深度学习模型来完成实例分割任务时，因需要大量人力采集和标注真实世界图像数据集而受到限制。本文介绍了首条生成逼真且自动标注的合成鸡肉胴体图像的流程，并提供了一个包括300幅真实标注图像的新基准数据集，专门用于禽类分割研究。
### Innovation
本文首次提出了生成逼真且自动标注的合成鸡肉胴体图像的流程，并通过实际标注图像数据分析了合成数据和自动标注在解决真实标注数据稀缺问题、增强分割绩效方面的有效性。实验显示，使用合成数据可显著提升各类实例分割模型的分割性能，表明合成数据增强是一种有效提升禽类分割任务中模型性能的策略，可缓解数据稀缺、减少手动标注劳动并促进AI驱动的自动检测系统的发展和完善。
### Conclusion
本文的研究强调了合成数据增强作为一种缓解数据稀缺、减少手动标注劳动并推动构成性分割模型在禽类分割任务中发展的有效策略的价值。
## 401. `cs.CV` - GaussianFusionOcc: 使用3D高斯分布的无缝传感器融合方法进行3D空置预测 [PDF](https://arxiv.org/pdf/2507.18522), [HTML](https://arxiv.org/abs/2507.18522)
### Authors
Tomislav Pavković,Mohammad-Ali Nikouei Mahani,Johannes Niedermayer,Johannes Betz
### Background
3D语义空置预测是自动驾驶的关键任务之一，它使车辆能够精确且安全地在复杂环境中进行理解和导航。可靠的预测依赖于有效的传感器融合，因为不同模态可以提供互补的信息。传统方法通常依赖于密集的网格表示，而本文提出的方法GaussianFusionOcc则利用语义的3D高斯分布和创新的传感器融合机制，通过无缝集成来自摄像头、LiDAR和雷达传感器的数据，实现了更加精确且可扩展的空置预测。
### Innovation
GaussianFusionOcc方法利用模态无关的可变形注意力机制从每种传感器中提取关键特征，这些特征随后用于细化高斯特性，从而更准确地表示环境。此外，3D高斯表示法极大地提高了内存效率和推理速度。通过利用多模态融合的稳健性和高斯表示的效率，GaussianFusionOcc在各种传感器组合中展示了出色的表现，并且优于当前最先进的模型。
### Conclusion
通过对各种传感器组合进行全面测试，GaussianFusionOcc展示了其灵活性和高效性，在3D空置预测中表现优于现有的最先进的模型。
## 402. `cs.CV` - TTS-VAR：视觉自回归生成的测试时缩放框架 [PDF](https://arxiv.org/pdf/2507.18537), [HTML](https://arxiv.org/abs/2507.18537)
### Authors
Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu
### Background
视觉生成模型在实际内容创作中至关重要，但需要大量的训练和计算资源。相比之下，测试时缩放由于其资源效率和有前途的表现而逐渐受到关注。
### Innovation
本文提出了TTS-VAR，第一个用于视觉自回归（VAR）模型的测试时缩放框架，通过路径搜索问题建模生成过程。关键创新点包括：1）提出了自适应递减批量大小策略，在因果生成过程中动态平衡计算效率与探索能力。2）在粗分辨率阶段，提出了基于聚类的多样性搜索，通过语义特征聚类保留结构多样性，便于对具有更高潜力的样本进行进一步选择。3）在高分辨率阶段，采用了基于重采样的潜力选择策略，优先选择具有高潜力的候选样本。
### Conclusion
通过实验，TTS-VAR在强大的VAR模型Infinity上取得了显著的效果，GenEval分数提高了8.7%至0.75。揭示了早期阶段的结构特征对最终质量有重要影响，以及不同生成阶段的重采样效率存在差异。
## 403. `cs.CV` - 使用潜在条件生成对抗网络从单一仿形图像中恢复面部图像 [PDF](https://arxiv.org/pdf/2507.18566), [HTML](https://arxiv.org/abs/2507.18566)
### Authors
Nitish Shukla,Arun Ross
### Background
仿形图像由两个或多个身份的面部图像合成而成，极大地类似于所有组成部分的身份。由于仿形图像可以与多个个体相关联，因此需要检测和拆分（demorphing）这些图像以提供额外的信息。现有方法遇到仿形复制问题，即输出的图像与仿形图像相似或假定训练和测试的仿形图像是通过相同的仿形技术生成的。
### Innovation
提出了一种方法，可以在潜在空间中分解仿形图像，从而允许从未见过的仿形技术或面部风格生成的图像中恢复面部图像。该方法在合成面部生成的仿形图像上进行训练，并在使用任意仿形技术生成的真实面部仿形图像上进行测试，比现有方法表现出显著的优越性和高保真度的恢复面部图像
### Conclusion
提出的使用潜在条件生成对抗网络的方法克服了现有方法的不足，能在未见过的仿形技术和面部风格下成功拆分仿形图像，并在真实面部仿形图像上的测试表明其优越性。
## 404. `cs.CV` - NLML-HPE: Manifold学习条件下通过非线性流形学习进行头部姿态估计 [PDF](https://arxiv.org/pdf/2507.18429), [HTML](https://arxiv.org/abs/2507.18429)
### Authors
Mahdi Ghafourian,Federico M. Sukno
### Background
头部姿态估计（HPE）在人机交互和面部识别等计算机视觉应用中起着关键作用。现有的HPE方法大多依赖于大规模的训练数据，在缺乏大量数据的情况下，这些方法的效果会大打折扣。
### Innovation
该论文提出了一种新颖的方法——基于非线性流形学习的头部姿态估计（NLML-HPE），该方法结合了张量分解（Tucker分解）和前馈神经网络。与基于传统分类的方法不同，该方法将头部姿态估计转化为回归问题，通过将输入的关键点映射到姿态角的连续表示来解决。此外，该方法还通过旋转三维头部模型并生成对应的二维图像来创建高精度且一致的训练集，无需大量标注数据。NLML-HPE方法能够实现实时性能，通过学习面向各自轴的旋转流形，模型快速预测未见数据。
### Conclusion
本文介绍了一种基于非线性流形学习（NLML）的头部姿态估计方法（NLML-HPE）。通过张量分解和前馈神经网络的结合，该方法能够通过有限的数据集实现头部姿态估计的高精度和实时性能。此外，论文还提供了一套可供在线访问的训练及测试代码和预训练模型。
## 405. `cs.CV` - 对抗分布匹配用于扩散蒸馏以实现高效图像和视频合成 [PDF](https://arxiv.org/pdf/2507.18569), [HTML](https://arxiv.org/abs/2507.18569)
### Authors
Yanzuo Lu,Yuxi Ren,Xin Xia,Shanchuan Lin,Xing Wang,Xuefeng Xiao,Andy J. Ma,Xiaohua Xie,Jian-Huang Lai
### Background
DMD是一种有潜力的评分蒸馏技术，可以将预训练的教师扩散模型压缩成高效的单一或多个步骤的学生生成器，但其对逆Kullback-Leibler（KL）散度最小化依赖可能导致某些应用中的模式塌陷（或模式寻求）。当前方法试图解决这一固有问题，提出了通过使用基于扩散的判别器的对抗分布匹配（ADM）框架，以对抗的方式在评分蒸馏中对真实和虚假评分估计器之间的潜在预测进行对齐。当在极其挑战性的单一步骤蒸馏中，通过使用组成在潜在和像素空间中的混合判别器进行对抗蒸馏，进一步改进预训练生成器。。
### Innovation
提出了一种对抗分布匹配（ADM）框架，通过利用基于扩散的判别器，对抗的方式对真实和虚假评分估计器之间的潜在预测进行对齐。此外，在特定的蒸馏场景下，通过对潜在空间和像素空间中的混合判别器的对抗蒸馏来进一步优化预训练生成器。与使用均方误差的DMD2预训练不同，提出的方法使用来自教师模型的ODE对上的分布损失，为后续评分蒸馏微调提供更好的初始化。引入了对抗蒸馏预训练与ADM微调的统一管道，使得在不消耗更多GPU时间的情况下，达到了在SDXL上的更好的一步性能，同时还在多步ADM蒸馏设置中，重新定义了高效图像和视频合成的标准。
### Conclusion
通过联合对抗蒸馏预训练和ADM微调，所提出的方法在SDXL中实现了比DMD2更好的一步性能，同时减少了GPU时间消耗。对于SD3-Medium、SD3.5-Large和CogVideoX多步ADM蒸馏的实验结果为高效图像和视频合成设定了新的基准。
## 406. `cs.CV` - 基于部分对象检测的大规模地理统计甲烷监测 [PDF](https://arxiv.org/pdf/2507.18513), [HTML](https://arxiv.org/abs/2507.18513)
### Authors
Adhemar de Senneville,Xavier Bou,Thibaud Ehret,Rafael Grompone,Jean Louis Bonne,Nicolas Dumelie,Thomas Lauvaux,Gabriele Facciolo
### Background
遥感图像中的物体检测是计算机视觉应用的主要领域之一。然而，大量遥感数据在检测罕见物体时会面临挑战，特别是在广泛地理区域。这一挑战对于许多应用至关重要，例如估计特定人类活动对环境的影响。甲烷的生产与排放是关键因素，特别是在生物降解器领域。
### Innovation
该研究提出了一种新的方法，通过部分对象检测来解决生物降解器的甲烷生产与排放监测问题。首先构建了一个包含生物降解器的新数据集，其中训练集和验证集较小，而测试集较大且不平衡，因为这样的地点很少。研究开发了一种基于部分的方法，考虑生物降解器的子元素，以增强最初的检测。这项方法被应用于新的未知区域，以建立一个生物降解器库存。通过这种方法，可以估算一定区域和时间内的甲烷产量。
### Conclusion
我们通过部分对象检测方法解决了生物降解器的甲烷生产与排放监测问题。这项研究表明，可以利用部分对象检测来构建生物降解器的地图，并据此估算特定区域的甲烷产量。
## 407. `cs.CV` - 使用基础模型在自然场景中进行物体分割：应用于辅助神经假肢的上肢视觉辅助 [PDF](https://arxiv.org/pdf/2507.18517), [HTML](https://arxiv.org/abs/2507.18517)
### Authors
Bolutife Atoki,Jenny Benois-Pineau,Renaud Péteri,Fabien Baldacci,Aymar de Rugy
### Background
本文解决了语义物体分割的问题，研究了是否可以使用大型和多样的物体进行训练的基础模型在未经特定图像微调的情况下，对包含日常物品的复杂视觉场景进行物体分割。该研究由上肢神经假肢的视觉引导应用场景驱动。
### Innovation
本文提出了一种基于凝视固定生成提示的方法来指导Segment Anything Model（SAM）进行物体分割，并在第一人称视觉数据上进行了微调。研究成果在Grasping-in-the-Wild数据集上取得了显著的IoU分割质量度量上的提升。
### Conclusion
我们的方法在真实世界具有挑战性的Grasping-in-the-Wild数据集上实现了IoU分割质量度量的提升，具体改善值可达到0.51点。这些改进显示出基础模型在复杂自然场景中进行物体分割的应用潜力，尤其是在上肢神经假肢的视觉辅助应用中。
## 408. `cs.CV` - SIDA: 虚构图像驱动的零样本领域适应 [PDF](https://arxiv.org/pdf/2507.18632), [HTML](https://arxiv.org/abs/2507.18632)
### Authors
Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim
### Background
零样本领域适应是一种无需利用目标领域图像数据来适应模型的方法。现有研究利用 CLIP 的嵌入空间和文本描述来模拟目标域风格特征。尽管以往在零样本领域适应方面取得了进展，但这些文本驱动的方法难以捕捉复杂的现实世界变化，且由于需要对齐过程，增加了适应时间。
### Innovation
提出了一种名为 SIDAR 的新方法，利用合成图像来实现零样本领域适应。首先生成与源域详细相似的图像并应用图像变换以反映目标域的风格。然后利用这些合成图像的风格特征作为目标域的代理。引入了 Domain Mix 和 Patch Style Transfer 模块，能够有效地建模现实世界的变换。特别地，Domain Mix 结合多种风格以扩大域内的表示，而 Patch Style Transfer 为每个图块分配不同的风格特征。通过在多种零样本场景中的表现，证明了该方法的有效性，尤其是在具有挑战性的领域，同时通过大幅减少总体适应时间提高了效率。
### Conclusion
该研究提出了一种基于合成图像的零样本领域适应方法（SIDA），通过引入 Domain Mix 和 Patch Style Transfer 模块，有效提高了模型对复杂现实世界变化的适应性和处理效率。
## 409. `cs.CV` - 由表达约束的中间表示引导的3D软件合成 [PDF](https://arxiv.org/pdf/2507.18625), [HTML](https://arxiv.org/abs/2507.18625)
### Authors
Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu
### Background
图形用户界面（UI）软件已经从传统的2D桌面/网络/移动界面转变为三维（3D）环境。虽然现有工作在自动2D软件生成方面取得显著成功，如HTML/CSS和移动应用界面代码合成，但3D软件的生成仍处于探索阶段。目前的方法通常一次性生成整体的3D环境，不能修改或控制软件中的特定元素，并且难以处理现实世界中复杂的空间和语义约束。
### Innovation
文章提出了Scenethesis，一种新的需求敏感的3D软件合成方法，保留了用户规范和生成的3D软件之间的形式可追溯性。Scenethesis基于ScenethesisLang，这是一种特定领域的语言，用作自然语言要求和可执行3D软件之间细粒度感知约束的中间表示。Scenethesis将3D软件合成分解为操作ScenethesisLang的阶段，从而实现独立验证、针对性修改和系统约束满足。
### Conclusion
我们的评估显示，Scenethesis准确捕获了超过80%的用户需求，并满足了超过90%的严格约束，同时处理了超过100个约束。此外，Scenethesis相较于最先进的方法在BLIP-2视觉评估分数上实现了42.8%的提升。
## 410. `cs.CV` - VideoMind: 具有意图定位的多媒体视频数据集，用于深入认知视频理解 [PDF](https://arxiv.org/pdf/2507.18552), [HTML](https://arxiv.org/abs/2507.18552)
### Authors
Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin
### Background
当前，对于视频的理解主要集中在表面特征的识别上，但缺乏深层的意图表达认知。虽然有一些多模态数据集存在，但它们大多数未能提供深层次的意图表达，而这些表达通常需要上下文综合才能理解，且不易直接观察到。因此，开发一个能提供此类深层认知表达的数据集对于推动视频理解技术的发展至关重要。
### Innovation
VideoMind 数据集创新点在于其提供了深层认知意图表达，这些表达位于视频的理解层级的最深层次，需要综合整个视频的信息才能理解，而不只是直接观察到的表面特征。这通过一种思考链（Chain-of-Thought，COT）方法生成，该方法引导大规模语言模型（mLLM）进行逐步推理，从而提供对视频内容更深入的理解。该数据集还包括详细的多层级文本描述，从事实到抽象再到意图，包含超过2200万个单词，每个样本的平均描述长度约为225个单词。此外，该数据集推出了一个3000个样本的黄金标准基准，以便更准确地评估模型在理解视频中的深层认知能力。
### Conclusion
VideoMind 数据集为细粒度的跨模态对齐提供了强大的基准，促进了需要深入视频理解的领域的发展，如情感和意图识别。这些数据已公开发布在 GitHub、HuggingFace 和 OpenDataLab 上。
## 411. `cs.CV` - 利用扩散辅助频率注意力模型进行全身低场MRI重建 [PDF](https://arxiv.org/pdf/2507.17764), [HTML](https://arxiv.org/abs/2507.17764)
### Authors
Xin Xie,Yu Guan,Zhuoxu Cui,Dong Liang,Qiegen Liu
### Background
在低信噪比(SNR)条件下，现有的重建算法表现不佳。传统的重建算法和近年来的学习基方法都未能有效提升低SNR条件下的重建性能。因此，提出了一种结合生成模型的生成优势和频率域注意力的表示能力的新方法，旨在改善低SNR条件下的MRI重建效果，特别是在资源受限或欠发达的临床环境中具有重要意义。
### Innovation
该研究提出了一种新的方法DFAM (Diffusion-Assisted Frequency Attention Model)，通过结合扩散模型的生成能力和频率域注意力的表示能力，有效提升了低SNR条件下的MRI重建性能。实验结果表明，DFAM在低SNR条件下的重建性能优于传统算法和近年来的学习基方法。这充分展示了DFAM在这种特殊应用场景中的潜力和优势，特别是在资源有限或医疗条件差的地方。
### Conclusion
DFAM作为一种新的解决低场MRI重建的有效方法，展示了其在资源受限或欠发达临床环境下应用的潜在价值。未来可以进一步研究其在不同应用场景中的适应性和改进现有模型的效果。
## 412. `cs.CV` - 基于深度学习的年龄估计和性别分类在定向广告中的应用 [PDF](https://arxiv.org/pdf/2507.18565), [HTML](https://arxiv.org/abs/2507.18565)
### Authors
Muhammad Imran Zaman,Nisar Ahmed
### Background
本文提出了一种基于深度学习的方法，用于从面部图像中同时进行年龄和性别分类，旨在提高定向广告的效果。已有方法通常分别处理这两个任务，本文提出了一种自定义的卷积神经网络（CNN）架构，旨在同时优化这两个任务，通过利用面部特征中固有的年龄和性别信息的相关性，旨在实现性能的提升。
### Innovation
本文提出了一种自定义的CNN架构，通过学习共享表示来处理年龄和性别分类任务，因此可以提高这两种分类任务的准确性。此外，还分析了模型在不同年龄组中的性能表现，识别出了准确估计年轻个体年龄的挑战，并提出了针对这些偏差的定制化数据增强和模型调整策略。此外，还研究了不同CNN架构和超参数设置对整体性能的影响。
### Conclusion
实验结果表明，相比已有方法，该方法在性别分类准确性上取得了显著提升，达到了95%。年龄估计的均方误差为5.77年。此外，本文还探讨了不同CNN架构和超参数设置对整体性能的影响，为未来研究提供了有价值的参考。
## 413. `cs.CV` - 使用生成先验改进多层电子 Ptychography [PDF](https://arxiv.org/pdf/2507.17800), [HTML](https://arxiv.org/abs/2507.17800)
### Authors
Christian K. Belardi,Chia-Hao Lee,Yingheng Wang,Justin Lovelace,Kilian Q. Weinberger,David A. Muller,Carla P. Gomes
### Background
多层电子全息术（MEP）是一种计算重构原子晶体结构最高分辨率图像的逆影像技术，通过对衍射图案进行重构。现有的算法通常通过迭代方式解决这个问题，但由于其不适定性，这类方法既耗时又不能产生最优解。
### Innovation
我们开发了MEP-Diffusion，这是一种针对MEP进行训练的大规模晶体结构数据库的具体扩散模型，作为迭代求解器的补充。MEP-Diffusion可以通过扩散后验采样（DPS）轻松地整合到现有的重构方法中作为生成先验。实验证明，这种结合方法大幅提高了重构三维体积的质量，相比现有方法SSIM提高了90.50%。
### Conclusion
本研究提出了一种新的MEP-Diffusion方法，通过将其作为生成先验整合到现有重构方法中，显著提升了多层电子全息术重构效果。
## 414. `cs.CV` - 多模态递归集成模型用于预测自然电影大脑响应(Algonauts 2025挑战赛] [PDF](https://arxiv.org/pdf/2507.17897), [HTML](https://arxiv.org/abs/2507.17897)
### Authors
Semih Eren,Deniz Kucukahmetler,Nico Scherf
### Background
准确地预测大脑皮层对自然刺激的反应需要将视觉、听觉和语义信息整合进时间序列的模型。该研究旨在提供一种递归层次多模态模型，该模型将预训练的视频、音频和语言嵌入映射到在四名受试者观看近80小时的电影时记录下的fMRI时间序列。这种方法考虑了多模态信息的时序动态，并通过逐层递归处理提高了预测准确度。
### Innovation
提出了一种新颖的多模态递归集成模型，该模型通过整合视觉、听觉和语言信息的优势改进了传统的预测模型。此外，模型采用特定于模态的双向递归神经网络编码时间动态，同时通过自顶向下逐步调整训练重点，以提高对大脑不同区域的预测准确性。模型的训练依赖于综合均方误差和相关性损失函数以及区分早期感觉区域和晚期关联区域的课程训练。此外，通过对100个模型变体的平均处理进一步提升了预测的鲁棒性。
### Conclusion
该研究成果在竞赛排行榜上排名第三，实现了整体皮尔逊相关系数0.2094，单个皮层区域的最高分均值为0.63，尤其在最难处理的受试者（受试者5）中表现出显著的提升。该方法为未来多种模态脑解码基准测试提供了一个简洁且易于扩展的基础。
## 415. `cs.CV` - 使用场内高光谱成像和特征选择与机器学习技术葡萄叶片氮素评估的整合研究 [PDF](https://arxiv.org/pdf/2507.17869), [HTML](https://arxiv.org/abs/2507.17869)
### Authors
Atif Bilal Asad,Achyut Paudel,Safal Kshetri,Chenchen Kang,Salik Ram Khanal,Nataliya Shcherbatyuk,Pierre Davadant,R. Paul Schreiner,Santosh Kalauni,Manoj Karkee,Markus Keller
### Background
葡萄藤中氮（N）是至关重要的养分之一，影响植物生长以及后续的产品如葡萄酒和果汁。由于土壤中的氮具有高空间和时间变异性，准确估计葡萄叶片中的氮浓度并实现个体植物精细化施肥以满足植物需求变得至关重要。本研究利用两个生长季节中两个不同葡萄品种生长阶段在四个不同葡萄园收集的场内高光谱图像数据（波长从400到1000 nm），旨在开发用于预测叶水平和冠层水平氮浓度的模型。通过图像处理和特征选择方法识别出与叶片氮浓度响应最相关的关键光谱带，然后使用这些光谱带训练和测试了两种机器学习模型，以预测氮浓度。研究结果表明，使用不同的特征选择方法和数据集（叶水平和冠层水平）后，许多关键光谱区域是一致的，特别是在500-525 nm、650-690 nm、750-800 nm和900-950 nm的关键区域。这表明这些光谱区域对于预测氮含量具有鲁棒性。通过机器学习模型预测氮含量的结果表明，尽管每种分析水平选择了不同的光谱带集，但在冠层和叶部数据集上的R²值分别为0.49和0.57。研究展示了场内高光谱成像、光谱数据与高性能特征选择及机器学习技术整合监测葡萄园氮素状况的潜力和可行性。
### Innovation
本研究创新性地结合了场内高光谱成像技术、光谱数据分析以及机器学习技术，用于精准识别关键光谱带，有效预测葡萄叶片和冠层的氮浓度。通过使用不同的机器学习模型（梯度提升和XGBoost）进行预测，并首次展示了在不同葡萄园和生长发育阶段取得的稳定且一致的结果。
### Conclusion
本研究通过应用场内高光谱成像技术和机器学习方法，成功构建了预测葡萄叶片和冠层氮浓度的模型，并展示了在不同葡萄园和生长发育阶段的稳定预测结果。研究成果表明了这些技术在葡萄园氮素管理中的潜力和价值。
## 416. `cs.CV` - HybridTM: 结合Transformer和Mamba进行3D语义分割 [PDF](https://arxiv.org/pdf/2507.18575), [HTML](https://arxiv.org/abs/2507.18575)
### Authors
Xinyu Wang,Jinghua Hou,Zhe Liu,Yingying Zhu
### Background
基于Transformer的方法在3D语义分割中展示了令人瞩目的能力，但由于它们强大的注意力机制，导致了二次复杂性限制，这限制了它们在大规模点云中的长期依赖关系建模。虽然基于Mamba的方法可以提供高效的线性复杂度处理，但在提取3D特征时其特征表示能力较弱。有效地结合这两种互补的长处仍然是该领域的一个开放挑战。
### Innovation
本文提出了一种新的混合架构HybridTM，将Transformer和Mamba首次进行深度融合，通过细致粒度结合注意力机制和Mamba，同时捕获长期依赖关系和细粒度局部特征。大量实验充分展示了HybridTM在多样化的室内和室外数据集中的有效性和通用性，且在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。
### Conclusion
进一步的实验证明了HybridTM的有效性和泛化能力，并且其在ScanNet、ScanNet200和nuScenes等多个基准测试中达到了最先进的性能。
## 417. `cs.CV` - 在IoT环境中的联邦学习通信成本减少的缓存技术 [PDF](https://arxiv.org/pdf/2507.17772), [HTML](https://arxiv.org/abs/2507.17772)
### Authors
Ahmad Alhonainy(1),Praveen Rao(1) ((1) University of Missouri, USA)
### Background
联邦学习（FL）允许多个分布式设备在不集中数据的情况下共同训练一个模型，但通信成本仍然是主要瓶颈，尤其是在资源受限的环境中。这篇论文介绍了一种新的缓存策略——FIFO、LRU和优先级策略，旨在减少不必要的模型更新传输。通过选择性地转发重要的更新，这种方法降低了带宽使用率，同时保持了模型的准确性。
### Innovation
论文提出了一种新的缓存策略，即FIFO、LRU和优先级策略，以减少联邦学习中的不必要模型更新传输。这种方法在减少带宽使用的同时维护了模型的准确性。
### Conclusion
实验结果表明，缓存策略减少了与最小损失准确度相关的通信量，这证实了智能缓存策略提高了联邦学习在边缘物联网网络中的可扩展性、内存效率，并支持在边缘物联网环境中可靠的联邦学习操作，使其能够在智能城市、医疗保健等领域等对延迟敏感的应用场景中有实际部署的可能性。
## 418. `cs.CV` - Captain Cinema: Towards Short Movie Generation [PDF](https://arxiv.org/pdf/2507.18634), [HTML](https://arxiv.org/abs/2507.18634)
### Authors
Junfei Xiao,Ceyuan Yang,Lvmin Zhang,Shengqu Cai,Yang Zhao,Yuwei Guo,Gordon Wetzstein,Maneesh Agrawala,Alan Yuille,Lu Jiang
### Background
近年来，随着扩散模型与多模态模型的发展，生成性的视频内容创造变得越来越成熟。然而，当前的方法在处理长场景、长叙述的影视作品生成上仍存在挑战，尤其是保持故事连贯性和视觉一致性的方面。
### Innovation
该研究提出了Captain Cinema框架，用于生成简短的电影。其创新点在于引入了自上而下的关键帧规划步骤和自下而上的视频合成步骤。此外，还设计了一种交错训练策略，专门用于处理长上下文的多模态扩散变换器（MM-DiT），以支持高效生成多场景长叙述的影视作品。
### Conclusion
实验结果表明，Captain Cinema能够在质量和效率上有效地生成视觉一致且故事连贯的简短电影。该模型在特定编排的影视数据集上进行训练，能够稳定地生成高质量的简短电影内容。
## 419. `cs.CV` - 通过相对熵核心集选择和分层级联矫正增强边缘设备上的量化感知训练 [PDF](https://arxiv.org/pdf/2507.17768), [HTML](https://arxiv.org/abs/2507.17768)
### Authors
Yujia Tong,Jingling Yuan,Chuang Hu
### Background
随着移动和边缘计算的发展，边缘设备上需要使用低比特量化模型来实现高效部署。为了提升模型性能，通常需要重新训练量化模型，但因为隐私问题，某些敏感数据只能在边缘设备上处理。传统量化感知训练（QAT）依赖完整数据集进行训练，导致巨大的计算开销。核心集选择技术可以通过训练代表性数据子集来缓解这个问题。然而，现有方法在使用小规模数据集（例如，仅10%的原始数据）时难以消除模型的量化误差，导致性能严重下降。
### Innovation
我们提出了QuaRC，一种结合相对熵核心集选择和分层级联矫正的边缘设备上量化感知训练框架。QuaRC包括两个主要阶段：在核心集选择阶段，QuaRC引入了相对熵得分来识别最有效地捕捉模型量化误差的子集；在训练阶段，QuaRC采用了分层级联矫正策略，将量化模型的中间层输出与高精度模型对齐，从而有效减少中间层的量化误差。
### Conclusion
实验结果表明，我们提出的方法是有效的。例如，在使用1%数据子集将ResNet-18量化到2比特时，QuaRC在ImageNet-1K数据集上的Top-1精度相比于现有技术提高了5.72%。
## 420. `cs.CV` - VIBE: 视频输入脑编码器用于fMRI响应建模 [PDF](https://arxiv.org/pdf/2507.17958), [HTML](https://arxiv.org/abs/2507.17958)
### Authors
Daniel Carlstrom Schad,Shrey Dixit,Janis Keck,Viktor Studenyak,Aleksandr Shpilevoi,Andrej Bicanski
### Background
该研究介绍了VIBE，一种双阶段Transformer，用于融合多模态视频、音频和文本特征以预测fMRI活动。研究基于CNeuroMod数据集中的65小时电影数据进行训练，并且通过多种预训练模型的融合及旋转嵌入的预测Transformer进行处理。研究结果显示，VIBE在分布内Friends S07数据集上的均值皮尔逊相关系数为32.25，在六个分布外电影上的相关系数为21.25。早期相同架构的版本分别在分布在内和分布外数据集上取得了0.3198和0.2096的相关系数，赢得了Algonauts 2025挑战赛的第一阶段并获得第二名。
### Innovation
VIBE结合了多模态（视频、音频和文本）特征，使用了体系结构中融合变压器以及用旋转嵌入的预测变压器实现时间解码。利用开放源代码模型（Qwen2.5、BEATs、Whisper、SlowFast、V-JEPA）生成的表示。在大规模电影数据集上的训练和20次种子的集成使得该模型在预测fMRI活动方面表现出色，特别是在分布外数据集上的性能有所提升。
### Conclusion
VIBE在预测fMRI活动中取得了较好的表现，尤其是在分布外数据集上。该研究成果提升了对多模态数据融合用于fMRI响应建模的理解，对于神经影像学和认知科学领域具有重要价值。
## 421. `cs.CV` - 基于网格结构LoRA的零样本动态概念个性化 [PDF](https://arxiv.org/pdf/2507.17963), [HTML](https://arxiv.org/abs/2507.17963)
### Authors
Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman
### Background
目前，文本到视频生成技术已经能够在文本和图片提示下生成高质量的合成内容。尽管可以从单个视频中捕捉特定主体的外观和动作并个性化动态概念，但现有的大多数方法需要实例级别的微调，这限制了方法的可扩展性。
### Innovation
本文提出了一个完全零样本框架来个性化文本到视频模型中的动态概念。该方法利用2x2网格结构的空间组织方式，编辑网格中的输入和输出配对，通过训练轻量级的网格LoRA适配器来实现编辑和组合。推理阶段，通过专用的网格填充模块完成部分观察布局，生成时序连贯且保持身份一致的输出。经过训练后，整个系统可以在一次前向传播中运行，能够对未见过的动态概念进行泛化，且不需要测试时的优化。
### Conclusion
大量实验表明，该方法在多种主体和编辑场景下能够产生高质量且一致的结果，超越了训练中的人物和编辑情景。
## 422. `cs.CV` - DRWKV: 低光环境聚焦对象边缘的图像增强 [PDF](https://arxiv.org/pdf/2507.18594), [HTML](https://arxiv.org/abs/2507.18594)
### Authors
Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung
### Background
低光环境下的图像增强仍然是一个具有挑战性的任务，尤其是在极端光照条件下保留对象边缘连续性和精细结构细节方面。现有的方法难以在增强图像边缘保真度的同时，有效地解耦光照和边缘结构。
### Innovation
本文提出了一种新颖的模型DRWKV（Detailed Receptance Weighted Key Value），它融合了提出的全局边缘反光理论（GER），实现了有效的光照与边缘结构解耦，从而增强边缘保真度。此外，引入了螺旋扫描机制的进化WKV注意力，能够捕捉空间边缘连续性并更有效地建模不规则结构。设计了双边光谱对齐器（Bi-SAB）和定制的MS2损失函数，以联合对光源和色度特征进行对齐，提高视觉自然度并减少伪影。
### Conclusion
在五个低光图像增强基准测试上进行了广泛的实验，证明了DRWKV在PSNR、SSIM和NIQE方面取得了领先的性能，同时保持了较低的计算复杂度。此外，DRWKV还增强了低光条件下的多对象跟踪任务的表现，验证了其泛化能力。
## 423. `cs.CV` - 基于模型导向去噪扩散模型的直接双能CT材料分解 [PDF](https://arxiv.org/pdf/2507.18012), [HTML](https://arxiv.org/abs/2507.18012)
### Authors
Hang Xu,Alexandre Bousse,Alessandro Perelli
### Background
双能X射线计算机断层摄影（DECT）是一种先进的技术，能够自动分解临床图像中的材料，无需手动分割。大多数方法在重建后作为后处理步骤进行材料分解，但这种方法没有考虑束硬化效应，导致结果不理想。
### Innovation
提出了一种名为Dual-Energy Decomposition Model-based Diffusion (DEcomp-MoD)的深度学习程序，直接将DECT投影数据转换为材料图像，其算法将光谱DECT模型的知识融入深度学习训练损失，并结合了一个在材料图像域中学习的评分基于去噪扩散先验。推理优化损失以直接输入Sino图作为输入，并通过基于模型的条件扩散模型生成材料图像，确保结果的一致性。DEcomp-MoD方法在低剂量AAPM数据集的合成DECT Sino图上进行评估，并且优于最先进的无监督评分基于模型和监督深度学习网络，具有临床诊断的潜在应用价值。
### Conclusion
最终展示了DEcomp-MoD方法在定量和定性评估中均表现出色，低于最先进的无监督评分基于模型和监督深度学习网络，具有潜在的临床诊断应用前景。
## 424. `cs.CV` - 向数字病理学中鲁棒的基础模型迈进 [PDF](https://arxiv.org/pdf/2507.17845), [HTML](https://arxiv.org/abs/2507.17845)
### Authors
Jonah Kömen,Edwin D. de Jong,Julius Hense,Hannah Marienwald,Jonas Dippel,Philip Naumann,Eric Marcus,Lukas Ruff,Maximilian Alber,Jonas Teuwen,Frederick Klauschen,Klaus-Robert Müller
### Background
生物医学基础模型（FMs）正在迅速改变AI在医疗健康研究中的应用，并进入临床验证阶段。然而，这些模型容易学习与生物学无关的技术特征，如手术/内窥镜技术、实验室流程和扫描器硬件的变化，这给临床应用带来风险。
### Innovation
本文首次系统研究病理学基础模型对非生物学特征的鲁棒性。本文介绍了衡量FMs鲁棒性的方法，展示了鲁棒性不足的后果，并提出了一种框架以减轻这些问题。开发了PathoROB鲁棒性基准，包括三个新的衡量指标和四个涵盖了34家医疗机构28种生物类别的数据集。
### Conclusion
本文的研究表明，评估鲁棒性是在临床应用前验证病理FMs的必要步骤，并证明未来FMs开发必须将鲁棒性作为核心设计原则。PathoROB提供了一种评估跨生物医学领域的鲁棒性的框架，有助于引导FMs改进，使其更加鲁棒、代表性和适用于临床的AI系统，优先处理生物学信息而非技术瑕疵。
## 425. `cs.CV` - 基于深度学习方法的通用MRI多器官腹部分割基准测试 [PDF](https://arxiv.org/pdf/2507.17971), [HTML](https://arxiv.org/abs/2507.17971)
### Authors
Deepa Krishnaswamy,Cosmin Ciausu,Steve Pieper,Ron Kikinis,Benjamin Billot,Andrey Fedorov
### Background
近年来深度学习的进展已产生了一系列可靠的自动化腹部CT分割工具，但MRI分割由于信号变化较大和训练数据集标注所需的巨大劳动量，面临极大挑战。现有的MRI分割方法训练数据集较小，可能导致其泛化能力较弱。为了评估MRI腹部分割工具的现状，本研究对比了三种先进的开放式模型：MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI，并引入了一个使用广泛CT分割数据训练的ABDSynth模型进行评估。
### Innovation
研究通过使用CT分割数据增强的ABDSynth模型，评估了三种最先进的MRI腹部分割模型的准确性和泛化能力。此外，利用三个未在训练过程中使用的方法数据集评估了这些模型，覆盖多家制造商、五种MRI序列和各种患者条件、体素分辨率和视野，极大地提升了评估的全面性和客观性。
### Conclusion
实验结果显示，MRSegmentator的性能最好且泛化能力最强，而ABDSynth虽然在准确度稍逊一筹，但其对训练数据的需求较低，适合标注预算有限的情况下使用。研究提供的评估代码和数据集将有助于未来的基准测试，并公开了ABDSynth的推理代码和权重。
## 426. `cs.CV` - 使用张量网络参数高效的3D DDPM用于MRI图像生成的微调 [PDF](https://arxiv.org/pdf/2507.18112), [HTML](https://arxiv.org/abs/2507.18112)
### Authors
Binghua Li,Ziqing Chang,Tong Liang,Chao Li,Toshihisa Tanaka,Shigeki Aoki,Qibin Zhao,Zhe Sun
### Background
在磁共振成像（MRI）图像生成中，对于基于3D U-Net的降噪扩散概率模型（DDPMs）进行参数高效的微调（PEFT）挑战仍然存在。尽管该方法具有实际应用意义，但是针对3D卷积运算的参数高效表示方面研究仍然有限。该研究旨在解决这一问题，评估一种新型PEFT方法TenVOO在针对MRI图像生成的3D DDPM中的应用效果
### Innovation
提出了一个新的PEFT方法TenVOO，这是一种基于张量网络建模的3D卷积核低维度表示方法，能够在仅使用少量参数的情况下，高效捕捉复杂的空间依赖关系。经过在包含ADNI，PPMI和BraTS2021三种脑部MRI数据集的结果表明，TenVOO方法能够达到最优的多尺度结构相似性指数（MS-SSIM），且所需的可训练参数量仅为原始模型的0.3%
### Conclusion
研究发现，TenVOO方法在小参数量的情况下，仍能取得优秀的结构相似性分数。该方法对于3D DDPM模型在MRI图像生成中的参数优化具有重要意义，且该研究在实验代码方面提供了开源代码以供进一步的研究和应用。
## 427. `cs.CV` - NWaaS: 非侵入式 Watermarking as a Service 服务用于 X-to-Image 深度神经网络 [PDF](https://arxiv.org/pdf/2507.18036), [HTML](https://arxiv.org/abs/2507.18036)
### Authors
Haonan An,Guang Hua,Yu Guo,Hangcheng Cao,Susanto Rahardja,Yuguang Fang
### Background
深度神经网络（DNN）模型可以通过 DNN 水印进行知识产权保护，即将版权水印嵌入模型参数（白盒）、模型行为（黑盒）或模型输出（无盒）。这些水印可以提取出来验证模型的所有权或检测模型盗窃行为。尽管存在这些进展，现有的方法天生具有侵入性，因为它们会修改模型参数或改变结构。这种自然侵入性引起了关于水印导致的模型行为变化和额外调优成本的担忧。随着模型规模的快速增长，这些问题被进一步放大。因此，模型所有者在实践中往往不愿意采用 DNN 水印，这限制了非侵入式 Watermarking as a Service (WaaS) 系统的发展。
### Innovation
我们引入了非侵入式 Watermarking as a Service (NWaaS)，这是一种新的无信任范例，用于 X-to-Image DNN 模型，在这种范式下，我们可以假设即使不修改模型，所有者定义的水印也可以从模型输出中提取出来。在此概念基础上，我们提出了 ShadowMark，其是一个具体的非侵入式 NWaaS 实现，通过建立在受保护模型的黑盒 API 中的 robust 和非侵入式侧通道来解决关键部署挑战，该侧通道利用了关键编码器和水印解码器。与现有解决方案相比，ShadowMark 能够保持所谓的绝对保真度，并且适用于不同的 DNN 架构，同时还能抵抗现有的攻击，从而消除了保真度与鲁棒性之间的权衡。
### Conclusion
通过大量的实验结果，证明了 ShadowMark 在实际部署非侵入式 DNN 水印的有效性和实用性。
## 428. `cs.CV` - GrAInS: 基于梯度的归因在LLM和VLM推断时的方向控制 [PDF](https://arxiv.org/pdf/2507.18043), [HTML](https://arxiv.org/abs/2507.18043)
### Authors
Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal
### Background
推理时的定向方法提供了细粒度、可解释且模块化的控制大型语言模型（LLMs）和视觉-语言模型（VLMs）行为的轻量级替代方案，通过在测试时修改内部激活而不更新模型权重。然而，大多数现有方法依赖于固定的、全局的操作向量，忽视了单个输入令牌的影响因果关系，并且未能利用模型逻辑概率的有用梯度，特别是在视觉和文本输入贡献不均匀的多模态设置中。
### Innovation
本文介绍了GrAInS，这是一种在语言和视觉-语言模型上运行的基于对比的梯度归因推理时间定向方法。GrAInS利用集成梯度计算识别最具有正向和负向影响的顶级令牌，并据此构建定向的控制向量来捕捉从不良行为到良好行为的语义变化。这种方法在推理时依赖于令牌级别的归因信号对隐藏激活进行调整，并且通过对激活进行归一化来保持表示缩放，从而实现细粒度、可解释且模块化的模型控制，无需重新训练或辅助监督。实验结果表明，GrAInS在多个任务和模型上均优于传统的微调和定向基线，展现出显著的性能提升，同时保持了模型的流畅性和一般能力。
### Conclusion
GrAInS方法通过利用联合的梯度归因方法来识别和利用模型中对目标输出最具有影响的令牌，并且通过构建方向控制向量来调控模型的行为，从而在多模态设置下有效控制模型的不理想输出，且无需重新训练或额外的监督。
## 429. `cs.CV` - GeoAvatar：适用于3D头像的自适应几何高斯绘画 [PDF](https://arxiv.org/pdf/2507.18155), [HTML](https://arxiv.org/abs/2507.18155)
### Authors
SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park
### Background
尽管最近在3D头像生成方面取得了进展，但仍然难以平衡身份恢复（即重建）与新颖姿势和表情（即动画）之间的关系。现有的方法难以适应面部不同区域的几何偏差，导致质量差强人意。
### Innovation
提出了GeoAvatar框架，一种自适应几何高斯绘画的方法。GeoAvatar引入了无监督的自适应预分配阶段（APS），将高斯分配为刚性和柔性的集合，以进行自适应偏移正则化。基于口部解剖和动态特性，还提出了新的口部结构和部分变形策略，增强口部动画的真实感。同时提出了一个正则化损失函数，用于高精度的高斯与3DMM人脸之间的配形。此外，还发布了DynamicFace视频数据集，包含高度表现力的面部运动。
### Conclusion
广泛的实验表明，GeoAvatar在重建和新颖动画场景中优于最先进的方法。
## 430. `cs.CV` - 手术环境下的面部特征定位性能评估 [PDF](https://arxiv.org/pdf/2507.18248), [HTML](https://arxiv.org/abs/2507.18248)
### Authors
Ines Frajtag,Marko Švaco,Filip Šuligoj
### Background
机器人、计算机视觉及其应用在各个领域，尤其是医学领域，正在变得越来越广泛。许多面部检测算法在神经外科、眼科和整形外科等领域找到了应用。然而，使用这些算法时面临的一个常见挑战是光照条件的变化和检测位置的灵活性，这些因素使得准确识别和精确定位患者成为难题。本研究在受控环境下测试了MediaPipe算法用于检测面部特征点，并使用了能够自动调整位置的机械臂，同时保持手术灯和模拟人像的位置不变。研究表明，在手术照明条件下提高面部特征点检测的准确度，显著提升了在大角度偏转情况下的检测性能。
### Innovation
本研究在手术室环境下，使用MediaPipe算法检测面部特征点，并通过机械臂自动调节位置，以应对固定位置下的手术灯和模拟人像，从而评估其性能表现。研究表明，改进后的面部特征点检测准确度在手术照明条件下的大角度偏转情况下显著提升。这种改进有助于讨论将MediaPipe算法整合到医疗程序中的潜在可能性。
### Conclusion
本研究通过使用MediaPipe算法在手术照明条件下提高了面部特征点检测的准确度，特别是在大角度偏转情况下。然而，检测性能的提升受到面部某些特征点检测不精确的影响。该研究为将MediaPipe算法整合到医疗程序中提供了讨论的基础。
## 431. `cs.CV` - 从生成图像中识别提示中的艺术家名称 [PDF](https://arxiv.org/pdf/2507.18633), [HTML](https://arxiv.org/abs/2507.18633)
### Authors
Grace Su,Sheng-Yu Wang,Aaron Hertzmann,Eli Shechtman,Jun-Yan Zhu,Richard Zhang
### Background
文本到图像模型的一种常见且有争议的应用是通过明确命名艺术家来生成图片，例如以“Greg Rutkowski的风格”。本文研究了如何仅通过图像本身来识别这些提示中命名的艺术家，以此建立一个基准——通过预测哪些艺术家名称被用于提示，来优化艺术家识别的准确性。这个数据集包含了195万张覆盖110位艺术家的图像，并且跨四个泛化设置：留出艺术家、提示复杂性提高、多艺术家提示以及不同的文本到图像模型。
### Innovation
作者提出了一个新的基准测试——提示中的艺术家识别（prompted-artist recognition），并尝试了多种方法，包括特征相似性基线、对比风格描述符、数据归属方法、监督分类器和少量样本原型网络。研究发现不同方法在不同泛化设置下表现出不同的优势与劣势，提供了对文本到图像模型负责任的监管的重要工具。
### Conclusion
该基准揭示了明显的改进空间，并提供了公开测试平台以促进对文本到图像模型的责任制调节。该数据集和基准已公开发布，旨在促进进一步的研究: this https URL
## 432. `cs.CV` - 基于基础模型推理与部件绑定的即学即用的 articulated 物体操作 [PDF](https://arxiv.org/pdf/2507.18276), [HTML](https://arxiv.org/abs/2507.18276)
### Authors
Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He
### Background
被连杆的物体对机器人的操作提出了多样的挑战，由于它们的内部结构不可直接观察，机器人必须通过自适应探索和细化操作来生成成功的操作轨迹。尽管已有工作尝试在适应性 articulated 物体操作中实现跨类别泛化，但仍然存在两大挑战：（1）真实世界的 articulated 物体的几何多样性使得视觉感知和理解变得复杂；（2）物体功能和机制的变异阻碍了统一的适应性操作策略的发展。
### Innovation
提出了一种名为 AdaRPG 的新颖框架，该框架利用基础模型提取部件，这些部件在局部几何相似性方面比整个对象更强，从而增强功能基元技能的视觉功能泛化。该框架还利用基础模型中的通用知识来推理复杂机制并生成基于部分功能推断的高级控制代码，从而调用基元技能函数。通过模拟和现实世界实验展示了 AdaRPG 强大的跨新类别 articulate 物体类别的泛化能力.
### Conclusion
通过 AdaRPG，机器人能够高效地适应和操作多样化的 articulated 物体，克服了现实挑战，展现了强大的跨类别泛化能力。
## 433. `cs.CV` - ReSem3D: 通过精细语义接地的可优化3D空间约束实现可泛化的机器人操作 [PDF](https://arxiv.org/pdf/2507.18262), [HTML](https://arxiv.org/abs/2507.18262)
### Authors
Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong
### Background
在机器人抓取和操作任务中，高阶的语义表示需要与低级别的动作空间进行统一，以便更好地理解任务并执行。现有的方法存在三个关键问题：粗粒度的语义建模、缺乏实时闭环规划、以及在不同语义环境中表现欠佳的鲁棒性。因此，需要一个统一的框架来解决这些问题，以便在语义多样化的环境中实现实时操作。
### Innovation
提出了一种名为ReSem3D的统一机器人操作框架，利用视觉基础模型（VFMs）和多模态大型语言模型（MLLMs）之间的协同作用，实现精细视觉接地和动态构建层次化的3D空间约束，以支持实时操作。通过两阶段的过程——部分级提取和区域级细化——从自然语言指令和RGB-D观察中自动构建3D空间约束，并将这些约束编码为关节空间的实时优化目标，以实现对动态扰动的反应性行为。
### Conclusion
通过广泛的模拟和真实世界实验，在富有语义的家用环境和稀疏的化学实验室环境中，ReSem3D在零样本条件下执行了多种操作任务，展示了其强大的适应性和泛化能力。
## 434. `cs.CV` - PS-GS: Gaussian Splatting for Multi-View Photometric Stereo [PDF](https://arxiv.org/pdf/2507.18231), [HTML](https://arxiv.org/abs/2507.18231)
### Authors
Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng
### Background
论文介绍了将逆渲染与多视角光度立体（MVPS）融合以获得更准确的3D重建。然而，多光源条件下高效逆渲染仍然是一个挑战。现有的逆渲染方法依赖于固定的环境照明，导致无法准确重建物体的几何形状、材料和光照，而多视角光度立体可以提供更准确的光照信息。已有研究虽能提供更准确的3D重建，但逆渲染效率仍需提高。为此，本文提出了一种称为PS-GS（基于多视角光度立体的Gaussian Splatting）的新方法，该方法通过联合估计物体的几何形状、材料和多种方向性光源的光照来解决这一问题。
### Innovation
PS-GS方法首先重建一个标准的二维Gaussian Splatting模型作为初始几何，然后基于该模型进行延迟逆渲染，并使用包含光照计算的多层感知网络的全渲染方程进行迭代优化。在此过程中，通过不校准的光度立体估算的法线来正则化渲染出的法线图。此外，还提出了2D Gaussian光线追踪方法以细化入射光源。通过利用多视角和多光源图像，克服了逆渲染问题的病态性。实验结果表明，在重建准确性和计算效率方面，PS-GS方法优于前人工作。
### Conclusion
经过优化后的重建对象可用于新颖视角合成、重新照明及材料和形状编辑。本文提出的PS-GS方法通过联合估计物体的几何形状、材料和多种方向性光源的光照，并使用多视角和多光源信息来改进逆渲染效果，从而提高了3D重建的准确性和效率。
## 435. `cs.CV` - 概念探查性能研究：数据的影响（扩展版） [PDF](https://arxiv.org/pdf/2507.18550), [HTML](https://arxiv.org/abs/2507.18550)
### Authors
Manuel de Sousa Ribeiro,Afonso Leote,João Leite
### Background
概念探查作为一种帮助解释人工神经网络的方法，近期引起了越来越多的关注。这种方法可以应对网络的庞大尺寸和非象征性本质，使得直接人工解释变得不可能。概念探查通过训练额外的分类器，将模型的内部表示映射到人类感兴趣的特定概念，从而允许人类透视人工神经网络。尽管在模型被探查或探查模型方面进行了大量研究，但对用于训练这些探查模型所需的数据关注度较低。此论文在这方面填补了这一空白，特别在图像分类任务的背景下，研究用于训练探查模型的数据对其性能的影响。此外，文章还提供了被广泛使用的两个数据集的概念标签。
### Innovation
本文专注于探查模型在图像分类任务中的表现，研究用于训练探查模型的数据对其性能的影响。这也是首次探讨此问题的研究，补充了概念探查领域的研究空白，强调了数据选择的重要性。
### Conclusion
文章研究发现，训练探查模型的数据类型对模型的性能有着显著影响。为了更好地理解人工神经网络，需要更加注重选择合适的数据来训练探查模型。此外，文章还发布了两个广泛使用的数据集的概念标签，供其他研究者使用以进行进一步比较研究。
## 436. `cs.CV` - DiagR1：一种通过强化学习训练的用于消化病理诊断的视觉-语言模型 [PDF](https://arxiv.org/pdf/2507.18433), [HTML](https://arxiv.org/abs/2507.18433)
### Authors
Minxi Ouyang,Lianghui Zhu,Yaqing Bao,Qiang Huang,Jingli Ouyang,Tian Guan,Xitong Ling,Jiawen Li,Song Duan,Wenbin Dai,Li Zheng,Xuemei Zhang,Yonghong He
### Background
多模态大型模型在自动化病理图像分析方面表现出巨大潜力。然而，当前用于消化道病理的多模态模型受到数据质量和推理透明度的限制：公共数据集中普遍存在的噪声和不完整的注解导致视觉语言模型在生成诊断文本时容易出现事实上的虚构；而缺乏明确的中间推理链路使得输出难以审核，从而在临床实践中不够可信。
### Innovation
我们构建了一个包含微观描述和诊断结论的大规模消化道病理数据集，并提出了一种提示论证策略，该策略结合了病变分类和解剖位置信息。此外，我们使用一个后训练管道结合有监督微调和组相对策略优化（GRPO）来提高推理质量和输出结构。实验证明，我们的方法在生成质量、结构完整性和临床相关性方面明显优于最先进的开源和专有基线。我们的解决方案在临床相关性上高于最先进的模型18.7%，在结构完整性上提高了32.4%，诊断错误减少了41.2%，显示出与现有解决方案相比更出色的准确性和临床应用价值。
### Conclusion
我们的方法在生成质量、结构完整性和临床相关性方面显著优于最先进的开源和专有基线，在临床应用中表现出更好的准确性和实用性。
## 437. `cs.CV` - ChronoSelect：通过动态时间记忆实现鲁棒噪声标签学习 [PDF](https://arxiv.org/pdf/2507.18183), [HTML](https://arxiv.org/abs/2507.18183)
### Authors
Jianchao Wang,Qingfeng Li,Pengcheng Zheng,Xiaorong Pu,Yazhou Ren
### Background
在使用真实世界数据集训练深度神经网络时，噪声标签是一个常见的问题，这可能导致过参数模型泛化性能显著下降。现有的噪声标签学习方法虽然取得了一定进展，但在评估模型时主要依靠静态快照，无法有效利用学习过程中的丰富时间动态变化。
### Innovation
提出了一种名为ChronoSelect的新框架，该框架具有独特的四阶段记忆架构，能够将预测历史压缩成紧凑的时间分布。滑动更新机制结合可控衰减仅保留每个样本四个动态记忆单元，能够强化近期模式并保留重要的历史知识。这种方法通过时间轨迹分析和双重分支一致性实现了样本的精确三部分划分。
### Conclusion
理论证明了该机制在噪声条件下的收敛性和稳定性。广泛的实验证明，ChronoSelect在合成和真实世界基准测试中表现出卓越的性能。
## 438. `cs.CV` - P层级扩散框架用于增强三维一致性的伪健康脑MRI修复 [PDF](https://arxiv.org/pdf/2507.17911), [HTML](https://arxiv.org/abs/2507.17911)
### Authors
Dou Hoon Kwark,Shirui Luo,Xiyue Zhu,Yudu Li,Zhi-Pei Liang,Volodymyr Kindratenko
### Background
伪健康图像修复是分析病理大脑MRI扫描的关键预处理步骤。现有大多数图像修复方法倾向于使用切片级的2D模型，以实现高平面内保真度，但由于它们在切片之间的独立性，会产生体积上的不连续性。全3D模型可以缓解这一问题，但其高模型容量需要大量的训练数据来实现可靠的高保真合成，这在医学环境中通常是不切实际的。
### Innovation
本文提出了一种分层扩散框架，通过使用两个垂直方向的粗细两级2D阶段，取代直接的3D建模，来解决这个问题。首先使用轴向扩散模型生成一个粗糙的全局一致性图像，然后使用冠状扩散模型进行解剖细节的细化。通过结合垂直空间视角和自适应重采样，该方法在实现数据效率的同时，也保证了体积的一致性。
### Conclusion
我们的实验表明，该方法在逼真性和体积一致性方面优于当前最先进的基线算法，为伪健康图像修复提供了一个有前景的解决方案。
## 439. `cs.CV` - ODES: 专家指导下的在线医疗影像分割领域适应 [PDF](https://arxiv.org/pdf/2312.05407), [HTML](https://arxiv.org/abs/2312.05407)
### Authors
Md Shazid Islam,Sayak Nag,Arindam Dutta,Miraj Ahmed,Fahim Faisal Niloy,Amit K.Roy-Chowdhury
### Background
无监督域适应分割通常依赖于自训练，使用预训练网络在未标注目标数据集上预测的伪标签。然而，这些伪标签的噪音性质成为网络适应源和目标数据集之间分布差异的主要瓶颈。在线场景中，网络必须在每次前向和后向传递中仅进行一轮就适应传入的目标域数据流，这使得依赖不准确伪标签导致的分割质量低下成为问题，尤其是在医学影像分析中，准确性至关重要。因此，我们假设可以利用少量来自专家的像素级标注来解决这个问题，从而即使没有专用训练数据也能提高在线流数据领域适应的性能。通过主动学习，每幅图像中最具信息性的像素可以被选择进行专家标注。然而，批量中所有图像的像素级标注会带来冗余信息并增加在线学习的时间开销。为了减少注释获取时间并使适应过程更加适应在线场景，我们进一步提出了一种新的图像裁剪策略，从当前批次中选择对主动学习最有用的子集。
### Innovation
本文提出了一种新颖的图像裁剪策略，选择批量中最有用的子集以减少标注获取时间和提高在线适应的灵活性。同时，我们还提出了一种称为ODES（Online Domain Adaptation with Expert Supervision for Medical Image Segmentation）的方法，该方法通过专家指导解决在线医疗影像分割中的领域适应问题，即使缺少专用训练数据也能提升性能。通过主动学习，我们可以选取最具信息性的像素进行专家标注，以减少冗余并提高效率。这项方法在在线适应方面优于现有方法，并能与离线领域适应主动学习方法竞争。
### Conclusion
我们提出的ODES方法在在线适应方面表现出色，并且其性能与离线领域的主动学习方法相比具有竞争力。通过将专家指导应用于像素级标注选择，ODES能够在保持高效的同时解决噪声伪标签带来的问题，从而提升了在线医疗影像分割的适应性和准确性。
## 440. `cs.CV` - PLOT-TAL: Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization [PDF](https://arxiv.org/pdf/2403.18915), [HTML](https://arxiv.org/abs/2403.18915)
### Authors
Edward Fish,Andrew Gilbert
### Background
当前的少样本时间动作定位（TAL）方法通过单一提示调整大型模型，常常不能产生精确的时间边界。这些方法的问题在于，模型从稀疏数据中学习到的是非区分性的动作平均表示，这影响了泛化能力。为了解决这个问题，本研究提出了一种基于多提示集合的新范式，每个动作鼓励一组多样且可学习的提示专注于合成子事件。为确保这种专业化，引入了PLOT-TAL框架，利用最优传输（OT）在提示集合与视频的时间特征之间寻找全局最优对齐。
### Innovation
提出了一种基于多提示集合的新范式，利用最优传输（OT）框架构建提示集合与视频的时间特征之间的全局最优对齐，从而实现少样本时间动作定位的精确时间边界定位，并且在THUMOS'14和EPIC-Kitchens这两个具有挑战性的少样本基准中达到了新的最好性能，而无需复杂的元学习过程。
### Conclusion
该方法在高IoU阈值下表现出显著的性能提升，验证了我们的假设，并展示了学习分布式、组合表示法的优越性，以实现精确的时间定位。
## 441. `cs.CV` - Label Anything: 使用视觉提示的多类少量样本语义分割 [PDF](https://arxiv.org/pdf/2407.02075), [HTML](https://arxiv.org/abs/2407.02075)
### Authors
Pasquale De Marinis,Nicola Fanelli,Raffaele Scaringi,Emanuele Colonna,Giuseppe Fiameni,Gennaro Vessio,Giovanna Castellano
### Background
当前的少量样本语义分割（FSS）方法主要依赖于掩码来标注支持图像，但这些方法的通用性和适应性有限。Label Anything旨在解决这一问题，提供了一种新的神经网络架构，适用于少数类别的少量样本语义分割，展现出在多个类别间较强的泛化能力。 
### Innovation
Label Anything引入了多种视觉提示（如点、边界框和掩码），打破了传统方法对掩码的依赖，增强了框架的灵活性和适应性。通过端到端的训练策略，能够在多种FSS场景下高效学习，无需重新训练，适用于从单类别单样本到多类别多样本的各种FSS挑战。这种创新的训练策略降低了计算需求，显著提升了模型在各种分割任务中的适应性和泛化能力。
### Conclusion
综合实验验证表明，Label Anything在COCO-2017基准测试中达到了最先进的性能，证明了其强大的泛化能力和灵活性。该论文源代码已公开。
## 442. `cs.CV` - Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space [PDF](https://arxiv.org/pdf/2409.05260), [HTML](https://arxiv.org/abs/2409.05260)
### Authors
Junho Lee,Jeongwoo Shin,Seung Woo Ko,Seongsu Ha,Joonseok Lee
### Background
给定一个包含T帧的视频，帧采样任务是选择N（远小于T）帧，以最大化固定视频分类器的性能。现有的大多数方法由于其巨大的搜索空间binom{T}{N}而效率低下，特别是在N较大时更为明显。因此，现有方法通常无法有效地处理大规模的帧采样任务。
### Innovation
本文引入了一种新的视角，将搜索空间从O(T^N)降低到O(T)，提出了一个半优化策略，该策略通过对每个帧独立估计置信度来选择前N个帧，从而显著降低了计算复杂度。实验验证了该半优化策略可以有效地近似最优策略，并且无论N和T的大小如何，该策略都能保证稳定的高性能。
### Conclusion
通过在各种数据集和模型架构上的广泛实验，证明了学习半优化策略能够保证稳定的高性能，无论N和T的大小如何。该方法为视频分类的可扩展帧采样提供了一个有效的解决方案。
## 443. `cs.CV` - 通过学习个性化的不变表示实现通用3D医疗多模态泛化 [PDF](https://arxiv.org/pdf/2411.06106), [HTML](https://arxiv.org/abs/2411.06106)
### Authors
Zhaorui Tan,Xi Yang,Tan Pan,Tianyi Liu,Chen Jiang,Xin Guo,Qiufeng Wang,Anh Nguyen,Yuan Qi,Kaizhu Huang,Yuan Cheng
### Background
医疗成像模态和个体解剖差异的变化给跨模态的多模态任务带来了挑战。现有的方法往往是专注于共同的解剖模式，而忽略了个体差异，这限制了它们的泛化表现。本文强调了学习个体水平不变性，即个性化的表示$boldsymbol{X}_h$的重要性，以在同质性和异质性设置下增强多模态泛化。研究表明，从个体生物特征到不同类型医疗模态的映射在整个人群中是稳定的，这是个性化的基础。
### Innovation
本文提出了一种两阶段的方法：预训练时使用不变表示$boldsymbol{X}_h$进行个性化，然后微调以适应多种下游任务。理论和实证证据均显示个性化方法的有效性和优势，证明了我们的方法在多种多模态医疗任务中的泛化性和转移性方面优于未个性化的方法。大量实验进一步验证了我们的方法在各种泛化场景中显著提升了性能。
### Conclusion
我们的方法通过学习个性化的不变表示实现了多模态医疗任务的泛化性能提升，相比于未个性化的方法，表现出更好的转移性和泛化能力。
## 444. `cs.CV` - 使用深度学习进行云隙填充以改进草地监测 [PDF](https://arxiv.org/pdf/2403.09554), [HTML](https://arxiv.org/abs/2403.09554)
### Authors
Iason Tsardanidis,Alkiviadis Koukos,Vasileios Sitokonstantinou,Thanassis Drivas,Charalampos Kontoes
### Background
不间断的光学图像时间序列对于及时监测农业用地变化至关重要，特别是在草地上。然而，云的干扰时常中断这些时间序列的连续性。为解决这一挑战，该研究提出了一种创新的深度学习方法，结合无云光学（Sentinel-2）观测和独立于天气的（Sentinel-1）合成孔径雷达（SAR）数据，以生成不间断的归一化差异植被指数（NDVI）时间序列。
### Innovation
该方法采用了一种结合卷积神经网络（CNN）和递归神经网络（RNN）的混合架构，生成连续的NDVI时间序列，突显了合成孔径雷达（SAR）与光学数据之间的协同作用。该研究还通过结合F1分数和马修斯相关系数等指标，将生成的NDVI时间序列在草地割草事件检测中的性能与常用的插值技术（如线性时序插值、Akima插值和二次插值）进行对比，结果表明该方法表现更优。
### Conclusion
该方法显著提高了草地割草事件检测的性能，F1分数高达84%，并且有效地减缓了由云造成的突变和噪声，这些噪声通常会被传统云掩模遗漏并影响割草事件检测的准确性。此外，与常用的替代方法相比，该方法的平均绝对误差为0.024，决定系数R²为0.92，显示出其优越性，特别是在多云覆盖的立陶宛研究区域取得了显著效果。
## 445. `cs.CV` - 基于深学习的胶质母细胞瘤形态病理特征识别：一项BraTS-Pathology挑战赛解决方案 [PDF](https://arxiv.org/pdf/2507.18133), [HTML](https://arxiv.org/abs/2507.18133)
### Authors
Juexin Zhang,Ying Weng,Ke Chen
### Background
胶质母细胞瘤是一种高度侵袭性的脑肿瘤，具有多样化的分子和病理特征，由于其异质性，诊断具有挑战性。准确诊断和评估这种异质性对于选择正确的治疗和改善患者预后至关重要。传统的诊断方法依赖于在组织样本中识别特定特征，但深学习为改进胶质母细胞瘤诊断提供了有前景的方法。
### Innovation
本研究利用预训练模型并结合BraTS-Path训练数据集进行微调，为胶质母细胞瘤的形态病理特征识别提供了一种较为先进的深度学习方法。
### Conclusion
尽管模型在验证集上的表现不佳，但其在特定方面（如高特异性）表现出色，并且通过测试阶段获得第二名，这表明该模型在某种程度上具有良好的预测能力，但仍有改进的空间。
## 446. `cs.CV` - 基于U-Net的健康3D脑组织填补 [PDF](https://arxiv.org/pdf/2507.18126), [HTML](https://arxiv.org/abs/2507.18126)
### Authors
Juexin Zhang,Ying Weng,Ke Chen
### Background
本文旨在通过填补隐藏输入图像中的缺失区域，合成健康的3D脑组织，特别是针对‘ASNR-MICCAI BraTS局部组织通过填补技术合成’任务。现有方法依赖于重新构建脑MRI扫描中的缺失或损坏区域，但缺乏提升模型泛化能力和鲁棒性的策略。
### Innovation
提出了一种基于U-Net的架构，通过在训练过程中随机掩蔽健康图像来增强模型的泛化能力和鲁棒性。该模型在BraTS-Local-Inpainting数据集上进行训练，展示了在恢复健康脑组织方面的出色表现，并在BraTS-Local-Inpainting验证集上取得了优异的结构相似性指数（SSIM）、信噪比峰值（PSNR）和均方误差（MSE）指标。
### Conclusion
实验结果表明，该模型在BraTS-Local-Inpainting验证集上的SSIM得分为0.841，PSNR得分为23.257，MSE得分为0.007，且标准偏差较低，分别为0.103，4.213和0.007，表明模型具有高可靠性和一致性。此外，该方法在比赛中获胜。
## 447. `cs.CV` - 将扩散模型高效化以实现3D LiDAR场景补全 [PDF](https://arxiv.org/pdf/2412.03515), [HTML](https://arxiv.org/abs/2412.03515)
### Authors
Shengyuan Zhang,An Zhao,Ling Yang,Zejian Li,Chenye Meng,Haoran Xu,Tianrun Chen,AnYang Wei,Perry Pengyun GU,Lingyun Sun
### Background
扩散模型已被应用于3D LiDAR场景补全，因其强大的训练稳定性和高质量的补全效果。然而，缓慢的采样速度限制了基于扩散的场景补全模型的实际应用，特别是自主车辆需要高效地感知周围的环境。
### Innovation
该论文提出了一种专为3D LiDAR场景补全模型设计的新型蒸馏方法，称为ScoreLiDAR，该方法可以在蒸馏后显著减少采样步骤数，同时保持高效高质量的补全效果。为了提高补全质量，还引入了一种新颖的结构损失，鼓励蒸馏模型捕捉3D LiDAR场景的几何结构。
### Conclusion
广泛的实验表明，ScoreLiDAR在SemanticKITTI上的补全时间从每帧30.55秒加速到5.37秒（超过5倍），且相比现有的最先进的3D LiDAR场景补全模型，具有更好的性能。我们的模型和代码已公开发布在https://github.com/happyw1nd/ScoreLiDAR上。
## 448. `cs.CV` - PF3plat：无姿态的前馈3D高斯绘制 [PDF](https://arxiv.org/pdf/2410.22128), [HTML](https://arxiv.org/abs/2410.22128)
### Authors
Sunghwan Hong,Jaewoo Jung,Heeseong Shin,Jisang Han,Jiaolong Yang,Chong Luo,Seungryong Kim
### Background
本文考虑单次前馈中从未拍摄图像合成新颖视图的问题。该框架利用3DGS的高速度、可扩展性和高质量3D重建及视图合成能力，进一步扩展了3DGS以解决密集图像视图、准确的相机姿态和大量图像重叠等常见假设的局限性。
### Innovation
通过使用预训练的单目深度估计和视觉对应模型实现3D高斯的粗略对齐，并引入轻量级、可学习模块来细化深度和姿态估计，从而提高3D重建和新颖视图合成的质量。另外，细化估计值用于估计几何置信度分数，评估3D高斯中心的可靠性，并据此调整高斯参数的预测。广泛的实验证明了PF3plat在各种基准上的新最优性能。
### Conclusion
大规模真实世界数据集上的详尽消融研究支持了我们的设计选择，证明了PF3plat的优越性，已设定新的状态最优。
## 449. `cs.CV` - 个人化工具包：大规模视觉语言模型的无训练个人化 [PDF](https://arxiv.org/pdf/2502.02452), [HTML](https://arxiv.org/abs/2502.02452)
### Authors
Soroush Seifi,Vaggelis Dorovatas,Daniel Olmeda Reino,Rahaf Aljundi
### Background
大规模视觉语言模型（LVLMs）的个性化涉及定制模型以识别特定用户和对象实例，并生成上下文相关的响应。现有方法通常依赖于每次训练期间耗时的测试训练，这使得它们不适合实际部署。当前的个人化基准测试主要集中在单一概念的基于对象的评估上，反映了这一局限性。
### Innovation
本文提出了一种无需训练的新型LVLM个性化方法，并引入了一个全面的现实世界的基准测试，用于严格评估个性化任务的各个方面。方法使用预训练的视觉基础模型提取独特特征，利用检索增强生成（RAG）技术识别视觉输入中的实例，并使用视觉提示策略引导模型输出。模型独立的视觉工具包实现了图像和视频的多概念个性化，无需额外训练，取得了最先进的成果，超越了现有的基于训练的方法。
### Conclusion
本文提出了一种无需训练的算法和一个全面的基准测试，用于大规模视觉语言模型的个性化。该方法不仅提高了个性化效果，还能够在不进行额外训练的情况下实现多概念个性化。
## 450. `cs.CV` - DEFAME: 动态基于证据的多模态专家事实核查 [PDF](https://arxiv.org/pdf/2412.10510), [HTML](https://arxiv.org/abs/2412.10510)
### Authors
Tobias Braun,Mark Rothermel,Marcus Rohrbach,Anna Rohrbach
### Background
事实核查领域面临着虚假信息传播日益严重的问题，现有的解决方案质量参差不齐且缺乏弹性。本文提出了一个名为DEFAME的模块化多模态专家零样本机器学习流水线，用于开放领域的文本-图像声明验证。DEFAME能够在六阶段过程中动态选择工具和搜索深度来提取和评估文本和视觉证据，相比之前的仅文本、缺乏解释性或依赖参数化知识的方法，DEFAME实现了端到端验证，能够处理声明和证据中的图像，生成结构化的多模态报告。
### Innovation
DEFAME方法建立了一个新的多模态流水线，不仅包括文本和视觉证据的处理，还支持图像和文本的共同验证，能够生成结构化的多模态报告。该方法已经在多个基准测试上表现出色，超越了所有先前的方法，特别是在新建立的ClaimReview2024+数据集上，显示了时间上的通用性和实时核查的潜力。
### Conclusion
DEFAME方法已经通过多个流行基准测试，成为最新的声望事实核查系统。相对于GPT-4o基线，DEFAME在新建立的ClaimReview2024+数据集上表现出显著的优势，证明了时间上的通用性和实时核查的潜力。
## 451. `cs.CV` - ELITE: 增强语言-图像毒性评估安全性 [PDF](https://arxiv.org/pdf/2502.04757), [HTML](https://arxiv.org/abs/2502.04757)
### Authors
Wonjun Lee,Doehyeon Lee,Eugene Choi,Sangyoon Yu,Ashkan Yousefpour,Haon Park,Bumsub Ham,Suhyun Kim
### Background
当前的视觉语言模型（VLMs）容易受到恶意提示的影响，导致产生有害输出。现有的VLM安全性基准主要依赖自动评估方法，但这些方法难以检测隐含的有害内容或产生不准确的评估结果。因此，现有的基准测试具有较低的有害水平、模糊的数据和有限的图像-文本对组合多样性。
### Innovation
我们提出了ELITE基准，这是一种基于增强评估方法ELITE评估器的高质量安全性评估基准。ELITE评估器明确地加入了毒性评分，以便准确评估多元模态背景中的有害性。我们使用ELITE评估器过滤掉现有基准中的模糊和低质量的图像-文本对，生成安全和不安全的图像-文本对的多样化组合。实验表明，ELITE评估器在与人类评估的对齐上优于以往的自动化方法，ELITE基准提高了基准测试的质量和多样性。
### Conclusion
通过引入ELITE，我们为更安全、更稳健的VLM铺平了道路，为评估和减轻实际应用中的安全风险提供了重要的工具。
## 452. `cs.CV` - TCM-Tongue：一种用于辅助中医诊断的人工智能病理标注标准化舌像数据集 [PDF](https://arxiv.org/pdf/2507.18288), [HTML](https://arxiv.org/abs/2507.18288)
### Authors
Xuebo Jin,Longfei Gao,Anshuo Tong,Zhengyang Chen,Jianlei Kong,Ning Sun,Huijun Ma,Qiang Wang,Yuting Bai,Tingli Su
### Background
中医舌诊在临床中具有较高的价值，但因主观解释和不一致的成像协议面临标准化挑战，且缺乏用于AI开发的大规模标注数据集。
### Innovation
文章首次提出了一个专门用于AI驱动的中医舌诊的标准化数据集，其中包括6,719张高质图像，在标准化条件下捕捉，并且被标注了20种病理症状类别。此外，该数据集支持多种标注格式，并通过九种深度学习模型进行了基准测试，展示了其在AI开发中的应用潜力。
### Conclusion
该资源为中医的可靠计算工具的进步奠定了基础，解决了该领域长期存在的数据短缺问题，促进了AI在研究和临床实践中的标准化高质量诊断数据的整合。
## 453. `cs.CV` - EVEv2: Improved Baselines for Encoder-Free Vision-Language Models [PDF](https://arxiv.org/pdf/2502.06788), [HTML](https://arxiv.org/abs/2502.06788)
### Authors
Haiwen Diao,Xiaotong Li,Yufeng Cui,Yueze Wang,Haoge Deng,Ting Pan,Wenxuan Wang,Huchuan Lu,Xinlong Wang
### Background
现有的无编码器视觉-语言模型（VLMs）在性能上迅速接近有编码器的对应模型，这表明了一体化的多模态系统的潜力在于结构的简洁性和高效的部署。本文系统地阐明了使用预训练视觉编码器、离散分词器和从头开始的简约视觉层的视觉-语言模型之间的性能差距，并深入挖掘了无编码器VLMs的未充分研究的特点。
### Innovation
开发了可以与主流有编码器的视觉-语言模型竞争的有效策略，推出EVEv2.0，这是一个新的改进后的无编码器视觉-语言模型家族。通过深入的研究，证明了适当的分解和层次关联视觉和语言在统一模型中可以减少模态间干扰，以及精心设计的训练策略可以有效地优化无编码器视觉-语言模型。
### Conclusion
我们的EVEv2.0展示了跨模态的解码器仅有的架构的全面研究，展示了优越的数据效率和强大的视觉推理能力。通过广泛的评估，EVEv2.0代表了开发无编码器视觉-语言模型的技术进步。
## 454. `cs.CV` - 通过切片评分分布匹配在数字病理学中实现稳健的敏感性控制 [PDF](https://arxiv.org/pdf/2502.20144), [HTML](https://arxiv.org/abs/2502.20144)
### Authors
Arthur Pignet,John Klein,Genevieve Robin,Antoine Olivier
### Background
在医疗中心部署数字病理学模型时遇到了挑战，主要是由于不同的数据分布带来的影响。尽管最近在领域泛化的进展提高了模型的整体性能（如AUC），但临床规定通常需要控制模型在其他指标上的转移性，例如规定的灵敏度水平。现有的方法在保证模型整体表现的同时，往往无法有效控制这些特定指标的性能。
### Innovation
该研究提出了一个新的基于最优运输和多实例学习（MIL）的方法，用于控制全切片图像（WSI）分类模型的灵敏度。该方法通过少量校准样本即可实现稳健的灵敏度控制，并且已在多个组别和任务中得到了验证，为计算病理学系统的可靠部署提供了一个实际解决方案。
### Conclusion
该研究介绍了一种新颖的方法，通过切片评分分布匹配实现了WSI分类模型的灵敏度控制，并且在多个组别和任务的验证中证明了这种方法的有效性和实用性。这种方法只需要少量的校准样本，因此可以提供一种实际可行的解决方案来进行计算病理学系统的可靠部署。
## 455. `cs.CV` - PreMix: 通过非对比预训练和特征混合的高效弱监督学习 [PDF](https://arxiv.org/pdf/2408.01162), [HTML](https://arxiv.org/abs/2408.01162)
### Authors
Bryan Wong,Mun Yong Yi
### Background
弱监督全切片影像（WSI）分类利用了多实例学习（MIL）框架，可以在不需要详细病块级注释的情况下进行WSI级别的预测。然而，现有的MIL方法在初始化聚集器时通常采用随机方式并从零开始训练，导致表现高度依赖于标注WSI的数量，并忽略临床环境中大量的未标注WSI资源。
### Innovation
提出了PreMix框架，该框架利用Barlow Twins的非对比预训练方法，并结合Slide Mixing策略生成更多的正例对，增强特征学习，尤其在标注WSI数量有限的情况下。同时通过Mixup和Manifold Mixup进一步微调，增强了模型在处理大尺度WSI时的鲁棒性。实验结果显示，将PreMix模块集成到HIPT中，平均F1分数提升了4.7%，适用于各种WSI数据集和训练规模。
### Conclusion
PreMix框架能够有效提高在有限标注数据条件下的WSI分类性能，并具有推动实际病理学实践中WSI分类应用的潜力。
## 456. `cs.CV` - 通过样本级注意力融合表示和模拟扰动对齐实现鲁棒多视图学习 [PDF](https://arxiv.org/pdf/2503.04151), [HTML](https://arxiv.org/abs/2503.04151)
### Authors
Jie Xu,Na Zhao,Gang Niu,Masashi Sugiyama,Xiaofeng Zhu
### Background
近年来，多视图学习（MVL）因其能够融合多视图中的区分性信息而受到广泛关注。然而，实际的多视图数据集往往存在异质性和不完美性，导致为特定视图组合设计的方法缺乏应用潜力，降低了其效果。
### Innovation
提出了一种新颖的鲁棒多视图学习方法（即RML），该方法同时实现了表示融合和对齐。具体而言，该方法通过引入一个简单的多视图变换融合网络，将异质多视图数据转换为同质词嵌入，并通过样本级注意力机制整合多个视图，以获取融合表示。此外，提出了一种基于模拟扰动的多视图对比学习框架，动态生成噪声和无用扰动来模拟不完美的数据条件。生成的模拟噪声和无用数据获得了两种不同的融合表示，并利用对比学习进行对齐，以学习区分性和鲁棒性表示。
### Conclusion
RML是一种自监督的方法，也可以应用于下游任务作为正则化模块。在实验中，它被应用于多视图无监督聚类，噪声标签分类，并用作跨模态哈希检索的即插即用模块。广泛的比较实验和消融研究验证了RML的有效性。
## 457. `cs.CV` - 当大型视觉语言模型遇到大型遥感图像：自上而下文本引导的token剪枝 [PDF](https://arxiv.org/pdf/2503.07588), [HTML](https://arxiv.org/abs/2503.07588)
### Authors
Junwei Luo,Yingying Zhang,Xue Yang,Kang Wu,Qi Zhu,Lei Liang,Jingdong Chen,Yansheng Li
### Background
高效处理大尺寸遥感图像（RSIs）的视觉语言理解意义重大但具有挑战性。现有的大型视觉语言模型通常使用预定义的有限网格来处理图像，这在处理巨大像素级别的RSIs时会导致信息损失。相反，使用无限网格虽可提高图像细节的保留，但会显著增加计算成本。为了在保持图像细节的同时降低计算复杂度，本研究提出了一种结合动态图像金字塔（DIP）的文本引导token剪枝方法。现有的评估视觉语言模型处理大RSIs感知能力的基准存在问题，主要包括问题多样性有限和图像尺寸受限。为此，本研究构建了一个名为LRS-VQA的新基准，包含7,333个问答对，涉及8个类别，最长图像长度达27,328像素。相较于现有高分辨率策略，本研究的方法在四个数据集上表现出更高的性能，并且在高分辨率设置下展现了更高的效率。
### Innovation
提出了一种文本引导token剪枝方法，结合动态图像金字塔（DIP）来处理大型RSIs图像，包括（i）一个区域聚焦模块（RFM）用于识别关键视觉token，（ii）一种基于DIP的自上而下粗细粒度图像划分与视觉token剪枝策略，该策略通过RFM的输出引导避免直接处理整个大型图像。此外，构建了LRS-VQA新基准，以提高对大型RSIs的评估能力和多样性。
### Conclusion
本研究提出了结合动态图像金字塔和文本引导token剪枝的视觉语言模型，显著提升了对大型RSIs的处理能力，在多个数据集上展示了良好的性能，并提供了更高的效率。
## 458. `cs.CV` - 视觉与语言对齐：无标注的多模态知识图构建以增强LLMs推理 [PDF](https://arxiv.org/pdf/2503.12972), [HTML](https://arxiv.org/abs/2503.12972)
### Authors
Junming Liu,Siyuan Meng,Yanting Gao,Song Mao,Pinlong Cai,Guohang Yan,Yirong Chen,Zilin Bian,Ding Wang,Botian Shi
### Background
在大型语言模型（LLMs）中，多模态推理面临着不完整知识和幻觉错误的挑战。文本知识图谱（KGs）只能部分缓解这些问题，因为它们的模态隔离限制了跨模态理解的提升。虽然多模态知识图谱（MMKGs）有潜力通过跨模态信息补充增强LLMs推理，但它们的实践构建受到了手动文本注释语义狭窄和视觉语义实体链接固有噪声的影响。
### Innovation
本文提出了一种名为Vision-align-to-Language integrated Knowledge Graph（VaLiK）的新方法，通过跨模态信息补充来增强LLMs推理。具体地，该方法通过级联预训练的视觉-语言模型（VLMs）对齐图像特征与文本，将其转换为包含图像特定信息的描述。此外，开发了一种跨模态相似性验证机制来量化语义一致性，有效过滤掉对齐特征时引入的噪声。即使没有手动标注的图像说明，精炼后的描述也能单独构建MMKG。该方法在相对于传统MMKG构建方法实现了显著的存储效率提升的同时，保留了实体到图像链接的直接能力。实验结果表明，与之前最先进的模型相比，带有VaLiK增强的LLMs在多模态推理任务中表现出色。
### Conclusion
实验结果在多模态推理任务上显示，与之前的最先进模型相比，使用VaLiK增强的LLMs表现出优势。我们的方法在未经标注的多模态知识图构建中取得了重要进展，实现了存储效率的大幅提升，同时保持了直接的实体到图像链接能力。
## 459. `cs.CV` - DeGauss: 动静分离的 Gaussian 拉普拉斯法在去干扰的3D重构中的应用 [PDF](https://arxiv.org/pdf/2503.13176), [HTML](https://arxiv.org/abs/2503.13176)
### Authors
Rui Wang,Quentin Lohmeyer,Mirko Meboldt,Siyu Tang
### Background
在真实世界环境中从视频中重构干净、无干扰的3D场景是极具挑战性的，尤其是在动态且环境复杂的场景中，如第一人称视角视频。当前的解决方法在处理复杂环境和动态内容时常常表现不佳，需要复杂的启发式方法和大量的监督。
### Innovation
提出了DeGauss，一种基于分离动态和静态元素的高斯拉普拉斯设计的简单且稳健的自监督框架。该方法使用前景和背景高斯分别表示动态和静态内容，并通过概率性掩膜协调两者组合，实现独立且互补的优化。DeGauss在各种真实场景中表现出色，不需要复杂启发式方法和大量监督，同时确保了3D重构的通用性和无干扰性，特别是在动态、交互密集的环境中。
### Conclusion
在NeRF-on-the-go, ADT, AEA, Hot3D, EPIC-Fields等基准上的实验验证了DeGauss的一致性优势，确立了在动态、交互丰富的环境中广泛适用的、去除干扰的3D重构的基准线。
## 460. `cs.CV` - CutS3D: 在3D中切割语义以进行2D无监督实例分割 [PDF](https://arxiv.org/pdf/2411.16319), [HTML](https://arxiv.org/abs/2411.16319)
### Authors
Leon Sick,Dominik Engel,Sebastian Hartwig,Pedro Hermosilla,Timo Ropinski
### Background
传统的2D图像中对象实例分割算法主要依赖大量的人工标注数据。近年来，出现了几种无监督方法来解决这个问题，这些方法通常通过生成伪掩模并训练通用类检测器来实现。然而，这些方法在处理2D图像空间重叠的实例时，往往无法准确区分重叠实例，因为它们只考虑语义信息。
### Innovation
该研究提出了一种名为CutS3D的新方法，它在3D中切割语义以得到最终的2D实例，并通过场景的点云表示来实现。此外，研究引入了空间重要性函数，用于在实例的3D边界上重新细化语义。为了解决伪掩模中的遮罩歧义问题，该方法还提出了增强训练无监督检测器的三个空间置信度组件，以提供一个清晰的学习信号。这些贡献使得该方法在多个标准无监督实例分割和对象检测基准测试中优于竞争对手的方法。
### Conclusion
通过这些贡献，该方法在多个标准基准测试中优于现有的无监督实例分割和对象检测方法。
## 461. `cs.CV` - Att-Adapter: 一种通过条件变分自编码器实现的稳健且精确的域特定多属性T2I扩散适配器 [PDF](https://arxiv.org/pdf/2503.11937), [HTML](https://arxiv.org/abs/2503.11937)
### Authors
Wonwoong Cho,Yan-Ying Chen,Matthew Klenk,David I. Inouye,Yanxia Zhang
### Background
文本到图像（T2I）扩散模型已经在生成高质量图像方面取得了显著效果。然而，这些模型在仅通过文本引导控制连续属性（尤其是多个属性同时控制，例如数值属性如眼睛张开程度或汽车宽度）方面仍然面临巨大挑战。
### Innovation
本文引入了属性（Att）适配器，这是一种新型即插即用电模块，旨在增强预训练扩散模型中对连续属性的细粒度、多属性控制能力。通过将解耦交叉注意力模块与条件自编码器（CVAE）结合起来，Att-Adapter不仅能够控制多种属性，而且能够提高属性之间的独立性，超越了基于StyleGAN的技术。
### Conclusion
Att-Adapter 方法在两个公开数据集上的评估结果显示，它在控制连续属性方面优于所有基于LoRA的基本模型。此外，我们的方法可以实现更宽泛的控制范围，并改进多个属性之间的独立性，超过基于StyleGAN的技术。值得注意的是，Att-Adapter 模型灵活且易于调整，无需使用成对的合成数据进行训练，可以轻松扩展到单个模型中的多个属性。
## 462. `cs.CV` - MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection [PDF](https://arxiv.org/pdf/2502.16943), [HTML](https://arxiv.org/abs/2502.16943)
### Authors
Farzad Beizaee,Gregory Lodygensky,Christian Desrosiers,Jose Dolz
### Background
无监督脑图像中的异常检测对于在未标记标签的情况下识别损伤和病理至关重要，但准确地在医学图像中定位异常仍然是一个挑战，因为大脑结构的复杂性和变异性以及缺乏标注异常数据使得这一任务尤为困难。
### Innovation
本文提出了一种新颖的方法，即在扩散模型中引入掩码，利用其生成能力学习正常大脑解剖结构的稳健表示。在训练过程中，模型仅处理正常的脑MRI扫描，并在潜在空间中执行向后扩散过程，向随机选择的补丁添加噪声。模型通过双重目标学习识别哪些补丁是嘈杂的并恢复其原始特征。这种方法确保模型捕捉到正常大脑结构的精细模式，同时将潜在空间中的异常点隔离为噪声。在推理阶段，模型识别出对应异常的噪点补丁，并通过反向扩散过程生成正常补丁的替代品。
### Conclusion
本文的方法超越了现有的无监督异常检测技术，展示了在生成准确的正常替代品和定位异常方面的优越性能。
## 463. `cs.CV` - 数据导向的形态学优化以减轻语义分割模型中的不合理包含 [PDF](https://arxiv.org/pdf/2408.14672), [HTML](https://arxiv.org/abs/2408.14672)
### Authors
Shamik Basu,Luc Van Gool,Christos Sakaridis
### Background
目前最先进的语义分割模型通常通过数据驱动的方式进行优化，仅在训练数据上最小化每个像素或每个区域的分类目标。这种纯粹基于数据驱动的范式在输入图像的领域从训练时所遇到的领域转换时，往往会得出不切实际的分割结果，如最先进的模型可能将一个区域标注为“道路”，但该区域位于另一个标注为“天空”的区域内部，尽管当前数据集的真实标注指出这种包含关系是不可行的。
### Innovation
我们的方法Infeasible Semantic Inclusions（InSeIn）首先在线下数据驱动的方式从手头的语义分割训练集中提取明确的空间类关系约束，然后在训练过程中应用一种多层次但可微的损失函数来惩罚这些约束的违反，促使预测更加可行。InSeIn是一种轻量级的插件式方法，可作为一种新的步骤来最小化已学习分割模型预测中的不合理包含，并在ADE20K、Cityscapes和ACDC数据集上展现出一致且显著的性能提升。
### Conclusion
InSeIn在不同最先进的网络模型上显示出一致且显著的性能改进，并减少语义分割模型预测中的不合理包含。
## 464. `cs.CV` - Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing [PDF](https://arxiv.org/pdf/2503.22929), [HTML](https://arxiv.org/abs/2503.22929)
### Authors
Pei-Kai Huang,Jun-Xiong Chong,Ming-Tsung Hsu,Fang-Yu Hsu,Yi-Ting Lin,Kai-Heng Chien,Hao-Chiang Shao,Chiou-Ting Hsu
### Background
面部抗欺骗(FAS)技术旨在通过区分真实的活体面部和欺骗性尝试来增强面部身份认证的安全性。虽然两类FAS方法可以通过过度拟合训练攻击来获得更好的性能，但它们对未见过的攻击处理较差。相反，一类FAS方法能够很好地处理未见过的攻击，但它们在处理活体特征内的领域信息时不够稳健。
### Innovation
本文提出了一个名为UFDANet的无监督特征解耦和增强网络，这是一种一类FAS技术。UFDANet通过解耦特征增强面部图像的增广，提高了鲁棒性和泛化能力。UFDANet采用了一种新颖的无监督特征解耦方法，将活体特征和领域特征分离，促进了区分性特征的学习。此外，还整合了已知欺骗性类的活体特征增强方案，以及未知领域特征的生成策略，从而增强了活体特征的表征性和可区分性。
### Conclusion
广泛的实验表明，提出的UFDANet在性能上优于之前的单类FAS方法，并且达到了与最先进的两类FAS方法相当的水平。
## 465. `cs.CV` - Trigger without Trace:向文本到图像扩散模型发起隐蔽后门攻击 [PDF](https://arxiv.org/pdf/2503.17724), [HTML](https://arxiv.org/abs/2503.17724)
### Authors
Jie Zhang,Zhongqi Wang,Shiguang Shan,Xilin Chen
### Background
近年来，针对文本到图像扩散模型的后门攻击已有显著发展。然而，当前的后门样本在语义一致性和注意力一致性上与良性样本存在明显异常，使其易于被检测到。
### Innovation
本文提出了一种名为TwT（Trigger without Trace）的方法，通过减轻语义一致性和注意力一致性，构建隐蔽性更强的后门样本。具体而言，利用语法结构作为触发器，增强了对文本变异的敏感性，从而打破语义一致性。同时提出了一种基于核最大均值差异（KMMD）的正则化方法，以均衡后门和良性样本之间的跨注意力响应分布，破坏注意力一致性。
### Conclusion
实验表明，该方法可以实现97.5%的攻击成功率，并且对现有防御机制具有较强的抵抗力。平均而言，该方法可使超过98%的后门样本绕过三种最先进的检测机制，揭示了当前后门防御方法的脆弱性。
## 466. `cs.CV` - NSegment : 专用于遥感图像分割的标签特定变形 [PDF](https://arxiv.org/pdf/2504.19634), [HTML](https://arxiv.org/abs/2504.19634)
### Authors
Yechan Kim,DongHo Yoon,SooYeon Kim,Moongu Jeon
### Background
遥感（RS）图像分割数据集中的标签错误往往是由于模糊的类别边界、混合像素、阴影、复杂的地形特征以及注释员的主观偏差而隐晦且微妙的。此外，由于高图像获取和标注成本，遥感数据标注稀缺进一步加剧了训练抗噪模型的难度。虽然复杂机制如标签选择或噪声修正可能解决此问题，但它们往往会增加训练时间并增加实施复杂性。
### Innovation
本文提出了一种简单的、有效的数据增强解决方案NSegment，它仅对分割标签应用弹性变形，每训练周期内的每个样本的变形强度不同，以解决注释不一致问题。与传统方法不同，它不直接对图像本身进行变形，仅针对标签进行操作，从而简化了模型训练过程并提高了训练效率。
### Conclusion
实验结果表明，我们的方法可以提高基于多种前沿模型的遥感图像分割性能。
## 467. `cs.CV` - TextCrafter：准确渲染复杂视觉场景中的多种文本 [PDF](https://arxiv.org/pdf/2503.23461), [HTML](https://arxiv.org/abs/2503.23461)
### Authors
Nikai Du,Zhennan Chen,Zhizhou Chen,Shan Gao,Xi Chen,Zhengkai Jiang,Jian Yang,Ying Tai
### Background
当前视觉文本生成任务（CVTG）在生成跨图片多样区域的复杂文本内容时常常遇到困难。生成模型往往会生成失真、模糊的视觉文本，或者遗漏某些视觉文本。因此，本文旨在解决这些挑战，提出了一个名为TextCrafter的新型多视觉文本渲染方法，以改善复杂视觉场景中的文本生成质量。
### Innovation
TextCrafter采用了逐步策略将复杂的视觉文本分解为不同部分，并确保文本内容与视觉载体的牢固对齐。它还引入了一种标记焦点增强机制，使视觉文本在生成过程中更加突出。此外，作者还提出了一个新的基准数据集CVTG-2K，以严格评估生成模型在CVTG任务中的表现。实验结果表明，该方法超越了现有的领先方法，有效解决了CVTG任务中的关键挑战，如文本混淆、遗漏和模糊。
### Conclusion
本文提出了TextCrafter方法，它通过分解复杂的视觉文本和增强标记焦点来改进CVTG任务中的视觉文本生成。此外，还提供了一个新的基准数据集CVTG-2K，验证了方法的有效性，并展示了其性能超越了当前最先进的方法。
## 468. `cs.CV` - 感知LM：开放访问数据与模型以实现详细的视觉理解 [PDF](https://arxiv.org/pdf/2504.13180), [HTML](https://arxiv.org/abs/2504.13180)
### Authors
Jang Hyun Cho,Andrea Madotto,Effrosyni Mavroudi,Triantafyllos Afouras,Tushar Nagarajan,Muhammad Maaz,Yale Song,Tengyu Ma,Shuming Hu,Suyog Jain,Miguel Martin,Huiyu Wang,Hanoona Rasheed,Peize Sun,Po-Yao Huang,Daniel Bolya,Nikhila Ravi,Shashank Jain,Tammy Stark,Shane Moon,Babak Damavandi,Vivian Lee,Andrew Westbury,Salman Khan,Philipp Krähenbühl,Piotr Dollár,Lorenzo Torresani,Kristen Grauman,Christoph Feichtenhofer
### Background
视觉语言模型在计算机视觉研究中至关重要，但在许多高性能模型仍然是闭源的情况下，其数据、设计和训练过程都被隐藏起来。研究社区通过使用来自黑盒模型的蒸馏来标注训练数据，取得了显著的基准结果，但这种方法牺牲了实际的科学进步。缺乏对教师模型及其数据来源的详细信息，科学进步的测量变得困难。因此，本论文的研究背景是在一个完全开放且可重复的框架中构建感知语言模型（PLM），旨在提高图像和视频理解研究的透明性。
### Innovation
本论文的创新在于研究并构建了以完全开放且可重复的方式构建感知语言模型（PLM），避免使用闭源模型来标注训练数据。通过分析标准训练管道，识别大规模合成数据中的关键数据缺口，特别是针对详细视频理解。提出了2.8百万个细粒度视频问答对和时空定位视频描述。引入了专门用于评估复杂的视频理解任务（如“什么”、“哪里”、“何时”、“如何”推理）的PLM-VideoBench套件。所有的研究工作都通过提供数据、训练脚本、代码与模型实现完全可再现性。
### Conclusion
本研究通过释出2.8百万个人工标注的细粒度视频问答对和时空定位视频描述，结合用于评估复杂视频理解任务的PLM-VideoBench套件，为视觉理解领域的研究提供了开放访问的数据与模型。这些开放资源使得视觉理解的研究更加透明和可重复，推动了科学领域的发展，实现了对关键技术缺口的有效填补和评估。
## 469. `cs.CV` - 为开放词汇动作识别学习无偏见地泛化 [PDF](https://arxiv.org/pdf/2502.20158), [HTML](https://arxiv.org/abs/2502.20158)
### Authors
Yating Yu,Congqi Cao,Yifan Zhang,Yanning Zhang
### Background
当前视频学习器依赖CLIP进行初始化，并通过进一步的正则化或重组来提高泛化能力，但受限于CLIP的静态偏差，这些学习器容易过度拟合并集中在静态特征上，这特别影响了它们对新颖的离境动作的泛化能力。
### Innovation
Open-MeDe提出了一种新的元优化框架，该框架在静态去偏见的基础上提高了开放词汇动作识别的已知到未知的泛化能力，通过跨批次的元优化方案，Open-MeDe鼓励视频学习器通过虚拟评估快速泛化到任意后续数据，从而构建一个更平滑的优化景观。此外，通过在优化轨迹上应用自我组合，Open-MeDe获得了可以广泛应用于既定目标和离境目标的数据的通用最优参数。
### Conclusion
广泛的评估表明，Open-MeDe不仅超过了专门为语义开放视频动作识别设计的正则化方法，还在离境数据上表现出显著的优势。该研究已发布在this https URL，可以获取更多具体内容。
## 470. `cs.CV` - SafeWork-R1: 在AI-45°法则下的协同演进安全与智能 [PDF](https://arxiv.org/pdf/2507.18576), [HTML](https://arxiv.org/abs/2507.18576)
### Authors
Shanghai AI Lab:Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu
### Background
介绍了SafeWork-R1，这是一个前沿的多模态推理模型，能够展示能力和安全的同步进化。SafeWork-R1基于我们提出的SafeLadder框架开发，SafeLadder框架结合了大规模、分阶段、安全导向的强化学习后训练，由一系列多原则验证器支持。不同于RLHF等对齐方法仅学习人类偏好，SafeLadder使SafeWork-R1能够发展内在的安全推理和自我反思能力，产生安全的‘顿悟’时刻。与Base模型Qwen2.5-VL-72B安全相关的基准相比，SafeWork-R1在提高安全性能的同时，平均提高了46.54%，且不影响通用能力，并与领先专有模型GPT-4.1和Claude Opus 4相比表现出最先进的安全部署性能。为了进一步增强其可靠性，我们在推理时实施了两种不同的干预方法和反思搜索机制，以加强逐步验证。最后，我们进一步开发了SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B。所有得到的模型证明了安全性和能力可以协同进化，突显了我们框架在构建稳健、可靠和值得信赖的通用人工智能方面的一般化能力。
### Innovation
SafeLadder框架结合了大规模、分阶段、安全导向的强化学习后训练，并由一系列多原则验证器支持。SafeWork-R1能够发展内在的安全推理和自我反思能力，产生安全的‘顿悟’时刻。SafeWork-R1在提高安全性能的同时，平均提高了46.54%，且不影响通用能力，并与领先专有模型GPT-4.1和Claude Opus 4相比表现出最先进的安安全性能。实施了两种不同的推理时刻干预方法和反思搜索机制，以增强逐步验证。
### Conclusion
所有得到的模型证明了安全性和能力可以协同进化，突显了我们框架在构建稳健、可靠和值得信赖的通用人工智能方面的广泛适用性。
## 471. `cs.CV` - 视觉变换器在精准农业中的综合研究 [PDF](https://arxiv.org/pdf/2504.21706), [HTML](https://arxiv.org/abs/2504.21706)
### Authors
Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei
### Background
植物疾病的检测是现代农业的关键方面，对维护作物健康和提高总产量起着重要作用。尽管传统的检测方法仍然有价值，但它们往往依赖于人工检查或传统的机器学习技术，这些方法在可扩展性和准确性方面存在限制。近年来，视觉变换器（ViTs）作为一种有前途的替代方案出现了，能够更好地处理长距离依赖和视觉任务的可扩展性。
### Innovation
介绍了视觉变换器的基本架构，并讨论了它们从自然语言处理到计算机视觉的转变。讨论了卷积神经网络（CNNs）等传统模型的归纳偏见，并解释了视觉变换器如何减轻这些偏见。提供了对最新文献的综合性回顾，重点关注关键方法、数据集和性能指标。还进行了卷积神经网络（CNNs）和视觉变换器的比较分析，以及混合模型和性能增强的回顾。涵盖了技术挑战，如数据需求、计算需求和模型可解释性，以及潜在解决方案。
### Conclusion
我们明确了在实际农业环境中整合视觉变换器的研究方向和技术创新。旨在为从业者和研究人员提供更深入的了解，说明视觉变换器如何在未来改造智能和精准农业。
## 472. `cs.CV` - MC3D-AD: 多类别3D异常检测的统一轮廓感知重建模型 [PDF](https://arxiv.org/pdf/2505.01969), [HTML](https://arxiv.org/abs/2505.01969)
### Authors
Jiayi Cheng,Can Gao,Jie Zhou,Jiajun Wen,Tao Dai,Jinbao Wang
### Background
3D异常检测（AD）是控制制造产品质量的有效手段。然而，现有方法通常需要独立为每个类别精心训练一个专门任务的模型，导致成本高、效率低且泛化能力弱。因此，本文提出了一种新的统一模型用于多类别3D异常检测（MC3D-AD），旨在利用局部和全局的几何感知信息重构所有类别的正常表示。MC3D-AD 在两个公开的 Real3D-AD 和 Anomaly-ShapeNet 数据集上进行了评估，表现出显著优于当前最先进的单类别方法，分别在 Real3D-AD 和 Anomaly-ShapeNet 上实现了 3.1% 和 9.3% 的对象级 AUROC 提升。
### Innovation
本文提出了一种新的统一模型 MC3D-AD，旨在通过利用局部和全局的几何感知信息来重构所有类别的正常表示。首先，通过提出一个自适应几何感知掩蔽注意力模块来学习不同类别的稳健和通用特征；接着，引入基于改进的掩蔽注意力的局部几何感知编码器来编码组级特征标记；最后，设计了一个全局查询解码器，通过点云位置嵌入改进解码过程和重构能力，从而实现用于 AD 任务的局部和全局几何感知重构特征标记。这一方法使得模型能够有效处理多类别场景中的几何异常检测任务。
### Conclusion
MC3D-AD 在两个公开的数据集上展示了显著的竞争优势，超过了最先进的单类别方法，在对象级别 AUROC 上分别提升了 3.1% 和 9.3%。研究成果为多类别 3D 异常检测提供了一种新的视角，并为该领域进一步的研究提供了良好的基础。
## 473. `cs.CV` - FUDOKI: 基于动能最优速度的离散流统一理解和生成 [PDF](https://arxiv.org/pdf/2505.20147), [HTML](https://arxiv.org/abs/2505.20147)
### Authors
Jin Wang,Yao Lai,Aoxue Li,Shifeng Zhang,Jiacheng Sun,Ning Kang,Chengyue Wu,Zhenguo Li,Ping Luo
### Background
大规模语言模型（LLMs）的迅速发展促进了多模态大型语言模型（MLLMs）的出现，这些模型在单一框架内统一了视觉理解和图像生成。然而，大多数现有的MLLMs依赖于自回归（AR）架构，这在图像生成中的栅格扫描顺序以及因果上下文建模中的限制推理能力方面造成了固有的局限性。
### Innovation
我们通过引入基于离散流匹配的FUDOKI，挑战了传统自回归（AR）架构的主导地位。FUDOKI利用度量诱导的概率路径和动能最优速度，超越了之前的遮罩基于的破坏过程，实现了迭代修正和更丰富的双向上下文集成。为了降低从头训练的成本，我们从预训练的自回归（AR）基于的MLLMs进行初始化，并逐步过渡到离散流匹配框架。实验结果显示，FUDOKI在视觉理解和图像生成任务上的性能与现有的最先进自回归（AR）基于的MLLMs相当，显示出其作为下一代统一多模态模型基础的潜力。此外，我们表明，在测试时应用缩放技术可显著提升FUDOKI的性能，进一步表明其可通过强化学习实现未来的改进和增强。
### Conclusion
FUDOKI在视觉理解和图像生成任务上取得了与最先进的自回归（AR）基于的MLLMs相当的性能，具有作为下一代统一多模态模型基础的潜力。通过测试时的缩放技术，FUDOKI还展现了通过强化学习未来增强的潜力。
## 474. `cs.CV` - MambaNeXt-YOLO: 一种用于实时目标检测的混合状态空间模型 [PDF](https://arxiv.org/pdf/2506.03654), [HTML](https://arxiv.org/abs/2506.03654)
### Authors
Xiaochun Lei,Siqi Wu,Weilin Wu,Zetao Jiang
### Background
实时目标检测在计算机视觉中是一个基本但具有挑战性的任务，特别是在计算资源有限的情况下。尽管YOLO系列模型通过平衡速度和准确性已经设定了基准，但对更丰富的全局上下文建模的需求促使使用Transformer架构。然而，Transformer由于其自注意力机制具有高计算复杂性，限制了其在实时和边缘部署中的实用性。
### Innovation
通过结合线性状态空间模型Mamba和卷积神经网络，提出了MambaNeXt-YOLO框架。该框架通过三个关键贡献来平衡精度和效率：（1）MambaNeXt Block：集成了CNN和Mamba，有效捕捉局部特征和长距离依赖性；（2）多分支不对称融合金字塔网络（MAFPN）：增强了多尺度对象检测的特征金字塔架构，适用于各种大小的对象；（3）边缘优化效率：该方法在PASCAL VOC数据集上实现66.6%的mAP，在31.9 FPS下，无需预训练，并支持在边缘设备（如NVIDIA Jetson Xavier NX和Orin NX）上部署。
### Conclusion
通过这些改进，MambaNeXt-YOLO框架在此类目标检测任务中展示了良好的性能，并支持边缘计算设备的部署。
## 475. `cs.CV` - RadioDUN: 一种物理启发的深度展开网络用于无线电图估计 [PDF](https://arxiv.org/pdf/2506.08418), [HTML](https://arxiv.org/abs/2506.08418)
### Authors
Taiqin Chen,Zikun Zhou,Zheng Fang,Wenzhen Zou,Kangjun Liu,Ke Chen,Yongbing Zhang,Yaowei Wang
### Background
无线电图代表了区域内频谱资源的空间分布，支持高效的资源分配和干扰缓解。然而，在实际场景中由于有限的可测量样本数量，构建密集的无线电图是困难的。现有的工作虽然利用了深度学习从稀疏样本中估算密集的无线电图，但难以结合无线电图的物理特性。因此，如何有效地利用稀疏样本并结合物理特性来构建无线电图成为一个挑战。
### Innovation
提出了Radio Deep Unfolding Network (RadioDUN)，将无线电图估计转化为稀疏信号恢复问题。通过引入物理传播模型，将问题分解为多个因子优化子问题，减少了恢复复杂性。借鉴现有压缩感知方法，RadioDUN通过一个可学习的参数调整和先验拟合过程来展开展优化过程，并开发了一个动态加权模块来调整因子的重要性，整合了与障碍物相关的因子来表达障碍物对信号的随机衰减，并设计了阴影损失来约束因子预测，作为补充监督目标，从而提升性能。
### Conclusion
广泛的实验表明，所提出的方法在性能上优于现有的最先进的方法。我们的代码将在发表后公开。
## 476. `cs.CV` - ToonifyGB: 基于StyleGAN的Gaussian混合表情模型用于3D风格化头部avatar [PDF](https://arxiv.org/pdf/2505.10072), [HTML](https://arxiv.org/abs/2505.10072)
### Authors
Rui-Yang Ju,Sheng-Yen Huang,Yi-Ping Hung
### Background
先前研究表明3D高斯混合表情模型能够实现实时可动画化的头部avatar从单目视频的重建。StyleGAN已经广泛应用于面部图像风格化，但将其扩展用于生成多样化风格化的3D头部avatar仍具有挑战性。
### Innovation
提出了一种高效的两阶段框架ToonifyGB，首先使用改进的StyleGAN生成风格化视频，克服了正常StyleGAN固定分辨率裁剪面部的预处理限制；第二阶段从生成的风格化视频中学习风格化中立头模型和一组表情混合形状，进而高效渲染具有任意表情的风格化avatar。
### Conclusion
实验结果表明，ToonifyGB在基准数据集上对两种代表样式（Arcane和Pixar）进行了验证，证明了其有效性和高效性。
## 477. `cs.CV` - SyncMapV2:稳健且适应性强的无监督分割 [PDF](https://arxiv.org/pdf/2506.16297), [HTML](https://arxiv.org/abs/2506.16297)
### Authors
Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas
### Background
人类视觉能够在不进行显式训练的情况下出色地分割视觉线索，且在噪声严重度增加的情况下仍能保持惊人的鲁棒性。相比之下，现有的人工智能算法在类似条件下难以保持准确性。已有方法在噪声、天气和模糊等不同类型退化下的表现较差，且需要显式的训练和支持。
### Innovation
提出了SyncMapV2，它在未监督场景分割中达到了最先进的鲁棒性。具体表现为，在数字退化中仅0.01%的mIoU下降，并且在线性适应特性的测试中几乎没有性能下降。SyncMapV2利用自我组织的动力方程与随机网络概念，同时无需任何鲁棒训练、监督或损失函数。此外，与传统方法需要重新初始化的方式不同，SyncMapV2可以在线适应新输入，模拟人类视觉的持续适应性。因此，SyncMapV2不仅实现了准确与鲁棒的结果，还提出了一种可以在不重新初始化的情况下根据输入持续适应的算法。
### Conclusion
SyncMapV2展示了在不同类型退化下接近零的性能降解，标志着未来一种新型的鲁棒和适应性强的智能算法的产生。
## 478. `cs.CV` - Flash-VStream: 效率化的实时理解长视频流 [PDF](https://arxiv.org/pdf/2506.23825), [HTML](https://arxiv.org/abs/2506.23825)
### Authors
Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin
### Background
近年来，大语言模型和跨模态对齐技术取得了长足进步，现有的多模态大语言模型在图像和短视频理解方面取得了显著的成果。然而，长视频理解仍面临挑战，因其长上下文特性导致严重的计算和内存负载。大多数现有工作将长视频和短视频处理方式相同，这在实际应用中效率低下且难以推广到更长的视频上。
### Innovation
本文提出了一种高效的视频语言模型Flash-VStream，能够处理极其长的视频并在用户查询时实时响应。特别地，设计了一个包含低容量上下文内存和高容量增强内存的Flash Memory模块。通过这个模块，低容量内存用于聚合长上下文时间信息并建模信息密度的分布，高容量内存基于这种分布检索详细的空间信息。与现有模型相比，Flash-VStream在推理延迟上实现了显著减少。在长视频基准和综合视频基准（如EgoSchema、MLVU、LVBench、MVBench和Video-MME）上的大量实验表明了本方法的先进性能和出色效率。
### Conclusion
本文提出的Flash-VStream在长视频理解上实现了显著的性能提升和效率优化，展示了其在处理长视频方面的优势。相关代码已经在给定的网址上提供。
## 479. `cs.CV` - 使用原型引导特征对齐的基于骨架的零样本动作识别 [PDF](https://arxiv.org/pdf/2507.00566), [HTML](https://arxiv.org/abs/2507.00566)
### Authors
Kai Zhou,Shuhai Zhang,Zeng You,Jinwu Hu,Mingkui Tan,Fei Liu
### Background
零样本基于骨架的人类动作识别旨在无需在训练期间预先接触未知动作类别的情况下对其进行分类。这一任务极其具有挑战性，因为从已知动作推广到未知动作极其困难。之前的研究通常采用两阶段训练：首先在已知动作类别上使用交叉熵损失对骨架编码器进行预训练，然后对提取的骨架和文本特征进行对齐，通过骨架-文本对齐和语言模型的一般性实现知识向未知类别的迁移。然而，这些方法受到两个因素的限制：1）骨架特征的区分度不够，因为固定的骨架编码器无法捕捉有效骨架-文本对齐所需的关键对齐信息；2）测试中忽略了骨架和未知文本特征之间的对齐偏差。
### Innovation
本文提出了一种原型引导的特征对齐范式，称为PGFA，以解决上述问题。具体而言，开发了一个端到端跨模态对比训练框架以提高骨架-文本对齐，确保了骨架特征的充分区分度。此外，引入了一种原型引导的文本特征对齐策略以减轻测试过程中分布差异的负面影响。通过理论分析支持了原型引导的文本特征对齐策略，并在三个知名数据集上对整体PGFA进行了实验评估。与当前最佳方法SMIE相比，PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现22.96%、12.53%和18.54%的绝对准确率提升。
### Conclusion
综上所述，提出的PGFA方法显著提高了基于骨架的动作识别准确率，特别是在处理零样本识别时展现出了优势，验证了原型引导特征对齐的有效性。
## 480. `cs.CV` - 扩散与分散：具有表示正则化的图像生成 [PDF](https://arxiv.org/pdf/2506.09027), [HTML](https://arxiv.org/abs/2506.09027)
### Authors
Runqian Wang,Kaiming He
### Background
过去十年中，基于扩散的生成模型的发展很大程度上与表示学习的进步是独立进行的。这些扩散模型通常依赖于回归目标，并且通常缺乏明确的正则化。
### Innovation
提出了简单的即插即用正则化器——分散损失（Dispersive Loss），能够有效提升基于扩散的生成模型。该方法通过鼓励隐藏空间中的内部表示分散化，在对比自监督学习中具有类似作用，但不需要正值样本对，也不干扰用于回归的过程。与最近的表示对齐方法（REPA）不同，该方法是自包含且极简的，无需预训练、额外参数和外部数据。
### Conclusion
在ImageNet数据集上对各种模型进行了评估，结果表明分散损失方法在常用且强大的基线之上保持了一致的改进。希望通过这项工作能促进生成建模与表示学习之间的差距.
## 481. `cs.CV` - 修正线性注意力中的幅度忽视 [PDF](https://arxiv.org/pdf/2507.00698), [HTML](https://arxiv.org/abs/2507.00698)
### Authors
Qihang Fan,Huaibo Huang,Yuang Ai,ran He
### Background
Softmax Attention 是 Transformer 的核心操作，尽管它具有出色的全局建模能力，但在视觉任务中的应用受到其二次复杂度的限制。相比之下，线性注意力具有类似的公式，实现了一次性复杂度，但其性能却显著低于标准 Softmax Attention，尤其是在大规模模型和复杂任务中。关键在于线性注意力完全忽略了查询（Query）的幅度信息，导致注意力分数分布无法动态适应查询的缩放。因此，尽管在结构上与 Softmax 相似，线性注意力的注意力分数分布却表现得完全不同。因此，有必要提出一种新的方法来改进线性注意力，使其能够更好地模拟 Softmax Attention 的性能。
### Innovation
本文基于对线性注意力公式进行分析，提出了 Magnitude-Aware Linear Attention (MALA)，通过修改线性注意力的计算方式，充分引入查询（Query）的幅度信息，使得注意力分数分布更加接近于 Softmax Attention，同时保持更加平衡的结构。MALA 在多项任务，如图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成中表现良好，均取得了较强的结果，证实了修正幅度忽视对提高线性注意力性能的有效性。
### Conclusion
通过引入幅值感知的机制，修正了线性注意力中的幅值忽视问题，使线性注意力的注意力分数分布更接近于标准的 Softmax Attention，实现了在多种任务上的有效和高效应用。
## 482. `cs.CV` - 基于CLIP的外部知识注入对于类增量学习 [PDF](https://arxiv.org/pdf/2503.08510), [HTML](https://arxiv.org/abs/2503.08510)
### Authors
Da-Wei Zhou,Kai-Wen Li,Jingyi Ning,Han-Jia Ye,Lijun Zhang,De-Chuan Zhan
### Background
类增量学习（CIL）允许学习系统适应不断变化的数据流。借助预训练模型（如CLIP），可以为CIL提供一个有希望的起点。然而，CLIP通过将视觉嵌入与类别名称匹配来做出决策，忽略了通过语言传达的丰富上下文信息。此外，由于模型持续更新，这些详细特征在CIL中会被覆盖，需要外部知识补充。
### Innovation
为了增强知识从数据集外转移，作者提出了一种双分支注入调优框架，该框架从视觉和文本模态编码信息性知识。视觉分支通过数据增强丰富了视觉特征，文本分支利用GPT-4重写具有区分性的描述。同时，还在推理过程中实施了后期知识调优，通过重新排名预测结果来提高模型适应不断变化数据的能力。
### Conclusion
实验结果表明，ENGINE在基于CLIP的CIL中达到了最先进的性能。编码的知识使模型能够更好地捕捉下游任务所需的信息性特征。代码可在特定链接中访问。
## 483. `cs.CV` - 4D生成的进展：一项综述 [PDF](https://arxiv.org/pdf/2503.14501), [HTML](https://arxiv.org/abs/2503.14501)
### Authors
Qiaowei Miao,Kehan Li,Jinsheng Quan,Zhiyuan Min,Shaojie Ma,Yichao Xu,Yi Yang,Ping Liu,Yawei Luo
### Background
4D生成技术已经从静态图像和视频合成发展到3D内容生成，并进一步演进到生成与用户输入相一致的时空一致动态3D资产的任务。尽管取得了快速进展，该领域仍缺乏对4D表示、生成框架、基础范式及其核心技术挑战的统一理解。本文综述了4D生成的现状。
### Innovation
文章系统且深入地综述了4D生成的现状，首先分类了基础的4D表示并概述了相关技术；接下来深入分析了基于条件和表示方法的代表性生成流水线；然后讨论了如何将运动和几何先验整合到4D输出中，以确保在各种控制方案下的时空一致性。最后，总结了动态对象/场景生成、数字人士合成、可编辑的4D内容和具身AI等应用领域的4D生成任务，并对比分析了四种基本的4D生成范式。
### Conclusion
本文强调了五个关键挑战：一致性、可控性、多样性、效率和保真度，并提出了当前研究和未来研究之间的联系。通过对近期进展和开放性问题的总结，本文提供了全面且前瞻性的视角，以指导未来4D生成领域研究。
## 484. `cs.CV` - ViLU: Learning Vision-Language Uncertainties for Failure Prediction [PDF](https://arxiv.org/pdf/2507.07620), [HTML](https://arxiv.org/abs/2507.07620)
### Authors
Marc Lafon,Yannis Karmim,Julio Silva-Rodríguez,Paul Couairon,Clément Rambour,Raphaël Fournier-Sniehotta,Ismail Ben Ayed,Jose Dolz,Nicolas Thome
### Background
在视觉-语言模型（VLMs）中，可靠的不确定性量化（UQ）和故障预测仍然是开放的挑战。现有方法通常依赖于损失预测，这限制了其应用范围，尤其是在后验场景中，模型本身无法直接访问的情况下。ViLU框架试图通过利用所有与任务相关的情感语料来上下文化不确定性估算，从而解决这些挑战。
### Innovation
ViLU框架引入了一种新的视觉-语言不确定性量化方法，通过交叉注意力机制整合视觉嵌入、预测语境和图像条件下的文本表示，建立一个感知不确定性的多模态表示。不同于传统的基于损失预测的方法，ViLU训练一个不确定性预测器作为二元分类器，使用加权二元交叉熵损失来区分正确的和错误的预测，使其成为一种无损失的判断方法。这种范例特别适用于只有视觉和文本嵌入的后验设置。
### Conclusion
广泛实验表明，与最先进的失败预测方法相比，我们的方法在多种数据集上产生了显著的改进。我们对标准分类数据集ImageNet-1k以及大规模图片字幕数据集CC12M和LAION-400M应用了这种方法。消融研究突显了我们架构和培训在实现有效不确定性量化中的关键作用。我们的代码已公开，可以在这里找到：this https URL.
## 485. `cs.CV` - UniSegDiff：通过阶段扩散模型提升统一病灶分割 [PDF](https://arxiv.org/pdf/2507.18362), [HTML](https://arxiv.org/abs/2507.18362)
### Authors
Yilong Hu,Shijie Chang,Lihe Zhang,Feng Tian,Weibing Sun,Huchuan Lu
### Background
扩散概率模型（DPM）已经在多种生成任务中取得了显著的性能表现。以前的扩散模型存在训练和推理策略导致时间步长间注意力分布不均的问题，导致训练时间过长和解不佳。并且，扩散模型中固有的随机性有助于解决医学图像和标签边缘模糊的问题，使其成为病灶分割的有前途的方法。
### Innovation
本文提出了一种新的扩散模型框架UniSegDiff，旨在以统一的方式实现跨多种模态和器官的病灶分割。该框架采用阶段训练和推理方法，并在各个阶段动态调整预测目标，迫使模型在所有时间步长中都保持高度注意力。并通过预训练特征提取网络来实现统一病灶分割。
### Conclusion
在六种不同器官的各种成像模态下评估表现，实验结果表明UniSegDiff显著优于当前最先进的方法。代码可在指定的链接处获取。
## 486. `cs.CV` - 一瞥即够：零样本单目高分辨率图像深度估计的一种新颖无缝块级精炼方法 [PDF](https://arxiv.org/pdf/2503.22351), [HTML](https://arxiv.org/abs/2503.22351)
### Authors
Byeongjun Kwon,Munchurl Kim
### Background
零样本深度估计(深度估计)模型由于在大规模数据集上进行了训练，因此表现出强大的泛化能力。然而，现有的模型在处理高分辨率图像时存在挑战，因为训练中的图像分辨率较小而推理时需要更高分辨率。全分辨率处理会降低深度估计精度，消耗大量内存；而将图像下采样到与训练相同的分辨率则会在估计的深度图像中产生模糊的边缘。当前的高分辨率深度估计方法采用基于块的方法，这在重新组装估计的深度块时会引入深度不连续性问题，导致在测试时低效。为了获得细粒度的深度细节，这些方法依赖于合成数据，因为真实世界中的深度标注数据稀疏，因此泛化能力较差。
### Innovation
我们提出了Patch Refine Once (PRO)，这是一种高效的、泛化的基于瓦片的框架，由两个核心组件组成：（i）分组块一致性训练，通过在同一反向传播步骤中联合处理四个重叠的块并在它们的重叠区域施加一致性损失，提高测试时的效率并减轻深度不连续性问题；（ii）消除偏差遮罩，防止深度估计模型过度拟合到数据集特定的偏差，即使在训练使用合成数据后，也能更好地泛化到真实世界的数据集。
### Conclusion
在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，我们的PRO可以无缝集成到现有的深度估计模型中。
## 487. `cs.CV` - DAA*: 基于图像的路径规划中的深度角度A星 [PDF](https://arxiv.org/pdf/2507.09305), [HTML](https://arxiv.org/abs/2507.09305)
### Authors
Zhiwei Xu
### Background
路径仿真是从专家演示中学习的重要内容，但路径平滑性往往被忽视。传统的A*算法在路径优化中缺乏平滑性调整，因此难以生成和参考路径高度相似且平滑的路径。为了解决这一问题，本文提出了一种新的学习方法，称为深度角度A*（DAA*），通过将所提出的路径角度自由度（PAF）与A*相结合，以适应路径平滑性来提高路径相似性。PAF旨在通过探索移动角度对路径节点扩展的影响，找到它们的最小值和最大值之间的折衷方案，从而为仿真实现提供高度适应性。
### Innovation
本文创新性地引入了一种新的学习方法，DAA*，通过将路径角度自由度（PAF）集成到A*中来改进路径平滑性和相似性。DAA*通过同时优化路径缩短和平滑度，从而更紧密地与参考路径对齐，优化路径最优性。该方法在7个数据集上进行了全面评估，并显著提高了所预测路径与参考路径之间的相似性（如SPR、ASIM和PSIM）性能，特别是在最短路径可行的情况下显著提高了路径长度。此外，当同时学习路径损失和路径概率图损失时，DAA*比当前最先进的方法TransPath表现出显著的优越性。
### Conclusion
本文通过全面评估7个数据集（包括4个迷宫数据集、2个视频游戏数据集以及一个包含2个场景的现实世界无人机视角数据集），证明了DAA*在路径相似性（SPR、ASIM、PSIM）方面的显著改进，特别是在最短路径可行的情况下，相对较短的路径长度有所提高，并且在共同学习路径损失和路径概率图损失时，DAA*显著优于当前最先进的TransPath。此外，讨论了路径最优性和搜索效率之间的微小权衡。
## 488. `cs.CV` - 利用医学数据的结构提高表示学习 [PDF](https://arxiv.org/pdf/2507.02987), [HTML](https://arxiv.org/abs/2507.02987)
### Authors
Andrea Agostini,Sonia Laguna,Alain Ryser,Samuel Ruiperez-Campillo,Moritz Vandenhirtz,Nicolas Deperrois,Farhad Nooralahzadeh,Michael Krauthammer,Thomas M. Sutter,Julia E. Vogt
### Background
构建可泛化的医疗AI系统需要高效且了解特定领域数据的预训练策略。与互联网规模的语料库不同，临床数据集如MIMIC-CXR提供的图像数量有限且注释稀缺，但这些数据集内含丰富的多视角结构。现有的方法难以从这些数据中有效学习并构建出有用的信息表示。
### Innovation
该论文提出了一种自监督框架，利用医学数据集的固有结构。具体来说，该方法将前后视角的胸片视作自然的正样本对，通过稀疏补丁重建每个视角，并使它们的隐含嵌入保持一致。这种方法无需文本监督，能够产生丰富有意义的表示。该方法在MIMIC-CXR上测试，取得了优于有监督目标和未利用结构的基线模型的好性能。
### Conclusion
这项工作提供了一种轻量级且模态无关的基于结构的预训练蓝图，适用于结构丰富但样本稀少的领域数据。
## 489. `cs.CV` - 基于全球尺度一致3D高斯点图的单目户外SLAM [PDF](https://arxiv.org/pdf/2507.03737), [HTML](https://arxiv.org/abs/2507.03737)
### Authors
Chong Cheng,Sicheng Yu,Zijian Wang,Yifan Zhou,Hao Wang
### Background
由于其高保真度和实时新颖视图合成能力，3D高斯抽样(3DGS)已成为SLAM中的一个热门解决方案。然而，一些先前的3DGS SLAM方法使用可微渲染管道进行跟踪，缺乏户外场景中的几何先验。其他方法引入了单独的跟踪模块，但随着大幅移动摄像机，它们累积误差，导致尺度漂移。
### Innovation
提出了一种鲁棒的仅RGB户外3DGS SLAM方法：S3PO-GS。技术上，通过建立在3DGS点图中的自我一致跟踪模块，避免了累积尺度漂移，并通过较少的迭代实现了更精确和稳健的跟踪。此外，设计了一种基于点图的动态映射模块，引入了几何先验，同时避免了尺度歧义。这显著提高了跟踪准确度和场景重建质量，特别适用于复杂户外环境。
### Conclusion
在Waymo、KITTI和DL3DV数据集上的实验表明，S3PO-GS在新颖视图合成方面达到了最先进的结果，并且在跟踪准确度方面优于其他3DGS SLAM方法。
## 490. `cs.CV` - 自强化原型进化与双知识合作在半监督终身行人重新识别中的应用 [PDF](https://arxiv.org/pdf/2507.01884), [HTML](https://arxiv.org/abs/2507.01884)
### Authors
Kunlun Xu,Fan Zhuo,Jiangmeng Li,Xu Zou,Jiahuan Zhou
### Background
当前的终身行人再识别（LReID）方法主要依赖于完全标记的数据流。然而，在标注资源有限的现实场景中，大量未标记数据与少数标记样本并存，导致在未标记数据利用过程中产生噪声知识，使得现有的LReID方法在半监督情况下表现严重下降。
### Innovation
该论文提出了一个名为Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation（SPRED）的创新框架。其关键创新在于通过动态原型引导的伪标签生成和新旧知识合作净化的自强化循环，增强未标记数据的利用。具体来说，SPRED引入可学习的身份原型以动态捕捉身份分布并生成高质量伪标签，同时结合当前模型专业化和历史模型泛化，合作精炼伪标签中的噪声，从而逐步挖掘可靠伪标签，提高当前阶段的学习效果并确保长期学习中的正向知识传递。
### Conclusion
在建立的半监督终身行人再识别基准上进行的实验表明，我们的SPRED方法达到了最先进的性能。源代码可在指定链接下载。
## 491. `cs.CV` - Frequency-Dynamic Attention Modulation for Dense Prediction [PDF](https://arxiv.org/pdf/2507.12006), [HTML](https://arxiv.org/abs/2507.12006)
### Authors
Linwei Chen,Lin Gu,Ying Fu
### Background
视觉变换器(ViTs)已经在计算机视觉任务中取得了显著进展，但在实际应用中，ViTs中的注意机制使得每一层都充当低通滤波器，导致频率渐消，从而丢失了重要的细节和纹理。
### Innovation
本文提出了一种新的、受到电路理论启发的策略，称为频率动态注意调控(FDAM)，能够直接调控ViTs的整体频率响应。FDAM包含两种技术：注意反转(AttInv)和频率动态缩放(FreqScale)。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，FreqScale则用于不同的频率分量之间的加权，实现微调目标响应函数。通过特性相似性分析和有效的秩评估，证明该方法避免了表示坍塌，且在包括SegFormer、DeiT和MaskDINO等多种模型中都表现出一致的性能提升。该方法还能够应用于遥感检测，取得当前最佳的结果。
### Conclusion
实验结果显示，我们的方法能够在语义分割、对象检测和实例分割等任务中提供可比的性能改善，并且在单尺度的遥感检测中取得了最新的最佳结果。
## 492. `cs.CV` - 重新思考面部表情识别中的遮挡：具有语义意识的角度和超越 [PDF](https://arxiv.org/pdf/2507.15401), [HTML](https://arxiv.org/abs/2507.15401)
### Authors
Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li
### Background
面部表情识别（FER）因其普遍存在的遮挡和数据集偏差而成为一个具有挑战性的任务，特别是在面部信息部分被遮挡的情况下，现有的FER模型难以提取有效的面部特征，导致分类不准确。现有的模型在处理遮挡时表现不佳，难以区分面部语义信息和高阶语义知识，也难以从语义增强的面部表示中缓解内在噪声，如身份和性别偏差。这些问题限制了FER模型在各种现实场景中的鲁棒性分析。因此，有必要提出一种新的方法来有效解决这些问题，提高FER的准确性与鲁棒性。
### Innovation
本文提出了一种新颖的ORSANet模型，其创新点包括：引入了辅助的多模态语义指导来消除面部遮挡并学习高级语义知识；定制了一种多尺度交叉交互模块（MCM）来适应性地融合地标特征和语义增强的表示；设计了一种动态对抗排斥增强损失（DARELoss）来进一步增强模型区分类似表情的能力。此外，构建了一个针对各种真实世界遮挡条件的首个遮挡导向的FER数据集，名为Occlu-FER。
### Conclusion
通过广泛的实验，本文提出的ORSANet在公共基准测试和Occlu-FER上均表现出业界领先的识别性能。模型代码已公开，可供进一步研究使用。
## 493. `cs.CV` - Inversion-DPO: 高精度且高效的扩散模型后训练方法 [PDF](https://arxiv.org/pdf/2507.11554), [HTML](https://arxiv.org/abs/2507.11554)
### Authors
Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun
### Background
近期，扩散模型（DMs）的进步得益于将模型与人类偏好对齐的方法，这些方法经常需要通过训练基准模型和奖励模型来调整，这一过程不仅增加了计算负担，还可能影响模型的精确度和训练效率。
### Innovation
我们提出了一种新的对齐框架Inversion-DPO，通过将直接偏好优化（DPO）与DDIM逆向过程重新定义来消除辅助奖励模型的需要，并通过从胜出和失败样本到噪声的确定性逆过程进行难以取样的后验采样，从而引出了一个新的后训练范例。该范例消除了辅助奖励模型或不准确近似的需求，显著提高了训练的精确度和效率。
### Conclusion
Inversion-DPO 在文本到图像生成和组成图像生成等任务中表现出优于现有后训练方法的显著性能提升，展示了训练好的生成模型能够生成高保真的组成一致图像的能力。特别是对于组成图像生成的后训练，我们构建了一个包含11,140幅复杂结构注释和综合评分配对数据集，以增强生成模型的组成能力。Inversion-DPO 开创了扩散模型高效高精度对齐的新途径，使其更加适用于复杂的现实生成任务。
## 494. `cs.CV` - Residual Prior-driven Frequency-aware Network for Image Fusion [PDF](https://arxiv.org/pdf/2507.06735), [HTML](https://arxiv.org/abs/2507.06735)
### Authors
Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma
### Background
图像融合旨在通过跨模态整合补充信息，生成高质量的融合图像，进而提升高层次视觉任务的性能。然而，全球空间建模机制虽然显示出良好的前景，但在空间域构建长距离特征依赖关系会带来巨大的计算成本。此外，缺乏地面真相使得捕捉补充特征变得更为困难。
### Innovation
为了解决这些挑战，我们提出了一种基于残差先验的频率感知网络（Residual Prior-driven Frequency-aware Network，简称RPFNet）。RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特异性差异信息，提供融合的补充先验；频率域融合模块（FDFM）通过频率域卷积实现高效全局特征建模与集成。此外，双向特征交互的跨促进模块（CPM）增强了局部细节和全局结构的协同感知能力。在训练过程中，我们引入了辅助解码器和显著结构损失来增强模型对模态特异性差异的敏感性。同时，采用基于自适应权重的频率对比损失和SSIM损失的有效组合，有效地约束了解空间，实现了局部细节和全局特征的同时捕捉，并确保补充信息的保留。
### Conclusion
广泛的实验验证了RPFNet的融合性能，它有效整合了判别特征，增强了纹理细节和显著对象，并能有效促进高层次视觉任务的部署。
## 495. `cs.CV` - 基于转移学习的遥感图像水体分割方法：札达图伦地区案例研究 [PDF](https://arxiv.org/pdf/2507.10084), [HTML](https://arxiv.org/abs/2507.10084)
### Authors
Haonan Chen(Tibet University),Xin Tong(Northwestern Polytechnical University)
### Background
青藏高原被称为亚洲水塔，受到气候变化的高度敏感，面临着严重的水安全挑战。因此，利用地球观测技术持续监测水资源，对提高此区域的气候韧性至关重要。本研究针对开发用于气候敏感应用的稳健人工智能技术中遇到的关键障碍（如领域偏移和数据稀缺），提出了一个两阶段的迁移学习策略。
### Innovation
本研究使用SegFormer模型，通过先在多样化的源领域预训练，再针对干旱的札达图伦区域进行微调，有效解决了领域偏移和数据稀缺的问题。研究结果显示，基于此策略的网络在分割水体方面的IoU指标从直接转移的25.50%提升到了64.84%，这一改进精度对于减少灾害风险，尤其是监测易发洪峰系统至关重要。研究还揭示了水体高度集中的分布特点，超过了80%的水域集中在不到20%的河流长度上，这一定量发现为理解水文过程和设计有针对性的水资源管理和气候适应策略提供了关键证据。
### Conclusion
本研究展示了在干旱高原区域进行水资源监测的有效技术解决方案，为利用人工智能增强地球观测技术以在关键跨界河流源头地区提升灾害准备能力作出了贡献。
## 496. `cs.CV` - LPTR-AFLNet: 轻量级综合中国车牌矫正和识别网络 [PDF](https://arxiv.org/pdf/2507.16362), [HTML](https://arxiv.org/abs/2507.16362)
### Authors
Guangzhu Xu,Pengcheng Zuo,Zhi Ke,Bangjun Lei
### Background
在中国复杂和不受限制的环境中，车牌识别（CLPR）面临着诸多挑战，尤其是在各种拍摄角度导致的透视畸变以及单行和双行车牌的校正方面。由于边缘设备计算资源有限，开发一个既能矫正又能识别的低复杂度端到端集成网络对于实现实时和高效的部署至关重要。现有的方法在处理这些挑战时遇到了计算复杂度高、矫正和识别不准确的问题，尤其是在双行车牌矫正和识别上表现不佳。因此，迫切需要开发一种高效且实用的方法来应对这些问题。
### Innovation
本文提出了一个名为LPTR-AFLNet的轻量级统一网络，该网络结合了透视变换校正模块（PTR）和优化的车牌识别网络AFLNet。该方法利用识别输出作为弱监督信号来有效地引导矫正过程，确保准确的透视畸变校正。此外，通过改进注意力模块来减少相似字符之间的混淆，并引入Focal Loss来解决训练中的类别不平衡问题，从而提高了识别准确性。实验结果表明，LPTR-AFLNet在矫正透视畸变和识别双行车牌图像方面表现出色，即使在各种具有挑战性的场景下也能保持较高的识别准确性。此外，在较低和中等性能的GPU平台上，方法运行时间少于10毫秒，显示出其实用性和广泛的应用前景。
### Conclusion
实验结果展示了LPTR-AFLNet在矫正透视畸变和识别双行车牌图像方面的优越性能，并能在多种具有挑战性的情景下保持高识别率。此外，该方法在较低性能的GPU平台上运行时间小于10毫秒，证明了其实用性和广泛的应用前景。
## 497. `cs.CV` - 整体手术场景图的研究 [PDF](https://arxiv.org/pdf/2507.15541), [HTML](https://arxiv.org/abs/2507.15541)
### Authors
Jongmin Shin,Enki Cho,Ka Young Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh
### Background
对手术场景的理解对于计算机辅助手术系统至关重要，需要对包含手术工具、解剖结构及其相互作用等多样元素的手术场景进行视觉理解。为了有效表示手术场景中的复杂信息，基于图的策略被用于结构化建模手术实体及其关系。尽管已经用图表示了手术场景，但手术场景中的某些方面，如多样化的工具-动作-目标组合以及操纵工具的手的身份，仍然在基于图的表示中被忽视，尽管它们很重要。为将这些方面纳入图表示，我们提出了Endoscapes-SG201数据集，其中包括工具-动作-目标组合和手的标识的注解。我们还引入了SSG-Com方法，这是基于图的方法，旨在学习和表示这些关键元素。通过在手术安全性评估和动作三元组识别等下游任务上的实验，我们证明了整合这些关键场景图组件的重要性，突出了它们对手术场景理解的显著贡献。相关的代码和数据集可以在提供的链接处获取。
### Innovation
提出了Endoscapes-SG201数据集，这个数据集包含工具-动作-目标组合和手的标识的注解，以增强对手术场景的理解。同时引入了SSG-Com方法，这是一种基于图的方法，用于学习和表示手术场景中的关键元素。实验表明，整合这些关键场景图组件对手术场景的理解有重要贡献。
### Conclusion
通过整合工具-动作-目标组合和手的标识，可以显著提升对手术场景的理解，这对计算机辅助手术系统的性能至关重要。SSG-Com方法在下游任务中的应用证实了这些关键图像组件的重要性，显示了它们对手术场景理解的贡献。相关的数据和代码可从提供的链接中获取。
## 498. `cs.CV` - PolarAnything: 基于扩散模型的偏振图像合成 [PDF](https://arxiv.org/pdf/2507.17268), [HTML](https://arxiv.org/abs/2507.17268)
### Authors
Kailong Zhang,Youwei Lyu,Heng Guo,Si Li,Zhanyu Ma,Boxin Shi
### Background
偏振图像在图像增强和三维重建任务中具有优势，但由于获取偏振相机的限制，其应用不够广泛。因此，合成逼真的偏振图像显得尤为重要。现有的模拟器Mitsuba依赖于参数化的偏振图像生成模型，并需要涵盖形状和PBR材质的大规模3D资产，这限制了其生成大规模逼真偏振图像的能力。
### Innovation
本文提出了一种名为PolarAnything的新方法，能够从单个RGB输入中生成具有物理准确性和高现实感的偏振图像，无需依赖大规模的3D资产集合。灵感来源于预训练扩散模型的零样本绩效，该方法采用了一种有效的表示策略来保持偏振属性的保真度。实验表明，该模型能够生成高质量的偏振图像，并支持诸如极化成形等下游任务。
### Conclusion
PolarAnything能够从单一RGB输入生成高保真和高现实感的偏振图像，有效解决了现有偏振图像生成方法所需的大量3D资产问题，为偏振图像的应用打开了新的可能性。
## 499. `cs.CV` - PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image [PDF](https://arxiv.org/pdf/2507.17332), [HTML](https://arxiv.org/abs/2507.17332)
### Authors
Hyeongjin Nam,Donghwan Kim,Gyeongsik Moon,Kyoung Mu Lee
### Background
现有的3D人体重建方法的一大限制是不同人体部位间纹理的对齐不准确。每个部位（如夹克或裤子）应保持独特的纹理而不会与其他部位混合。人体部分的结构连贯性是推断单张图像中不可见区域的人体纹理的关键线索。然而，大多数现有的3D人体重建方法并未明确利用这种部分分割先验，导致重建中纹理错位。因此，需要一种方法来利用3D人体部分信息来准确地重建3D人体纹理。
### Innovation
本文提出了PARTE，这是一种利用3D人体部分信息作为关键指导来重建3D人体纹理的方法。该框架包含两个核心组件：第一个是3D部分分割模块（PartSegmenter），它从单张图像中推断3D人体部分信息，首先重建一个无纹理的人体表面，基于无纹理表面预测人体部分标签。第二个是部分导向的贴图模块（PartTexturer），该模块从预训练的图像生成网络中获取人体部分纹理对齐的先验知识，进而将部分信息融入到纹理重建中。实验结果表明，该框架在3D人体重建质量上达到了目前最好的水平。
### Conclusion
我们的框架通过导入3D人体部分信息，显著改善了3D人体纹理的重建质量，实现了在现有的3D人体重建方法中前所未有的准确度。
## 500. `cs.CV` - 在恶劣天气条件下的盲面部复原中具有统计面部特征变换的退化无关性 [PDF](https://arxiv.org/pdf/2507.07464), [HTML](https://arxiv.org/abs/2507.07464)
### Authors
Chang-Hwan Son
### Background
随着智能监控摄像头系统的应用越来越广泛，特别是在户外环境中，对能够在恶劣天气条件下优化的面部识别系统的需求也在不断增长。恶劣天气会显著降低图像质量，从而影响面部识别的准确性。尽管基于生成对抗网络（GAN）和扩散模型的面部图像恢复（FIR）模型已经显示出进步，但由于缺乏专门的模块来直接解决天气引发的退化问题，它们的性能仍然有限，这导致了面部纹理和结构的失真。
### Innovation
本文提出了一种基于GAN的盲面部图像恢复（FIR）新框架，该框架整合了两个关键组件：局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）。局部SFFT模块通过将低质量（LQ）面部区域的局部统计分布与高质量（HQ）区域匹配来增强面部结构和色彩保真度。同时，DAFE模块通过对低质量和高质量编码器表示的对齐，使特征提取在恶劣天气条件下更具鲁棒性，从而使得恢复过程能够适应严重的天气引起的退化。实验结果表明，所提出的退化无关SFFT模型在压制纹理失真和准确重建面部结构方面优于现有的基于GAN和扩散模型的FIR方法。
### Conclusion
此外，SFFT和DAFE模块在恶劣天气条件下的面部恢复中被实验证明能够增强结构保真度和感知质量。
## 501. `cs.CV` - Swin-TUNA：一种用于精确食物图像分割的新型参数高效微调方法 [PDF](https://arxiv.org/pdf/2507.17347), [HTML](https://arxiv.org/abs/2507.17347)
### Authors
Haotian Chen,Zhiyong Xiao
### Background
在食物图像处理领域，高效的语义分割技术对于工业应用至关重要。然而，现有的基于Transformer的大规模模型（如FoodSAM）由于其庞大的参数数量和高计算资源需求，在实际部署中面临挑战。因此，研究一种参数高效的微调方法在实际应用中显得尤为重要。
### Innovation
Swin-TUNA模块通过将多尺度可训练适配器整合到Swin Transformer架构中，仅更新4%的参数便实现了高性能的食物图像分割。其核心创新在于多层次特征适应机制：通过在深度和维度映射中设计可分离卷积来解决浅层和深层网络特征之间的差异，并结合一种适用于任务通用和任务专用特征的动态平衡策略。这种方法在FoodSeg103和UECFoodPix Complete数据集上分别达到了50.56%和74.94%的mIoU成绩，同时将参数量减少了98.7%（降至8.13M），并且在低数据场景下表现出更快的收敛速度和更强的通用化能力，提供了一种针对轻量食物图像分割的有效解决方案。
### Conclusion
实验结果表明，Swin-TUNA在保持高精度的同时，显著减少了参数数量，并且在低数据场景下具有更快的收敛速度和更强的泛化能力，为轻量级食物图像分割应用提供了高效解决方案。
## 502. `cs.CV` - 扩展到长视频的强化学习 [PDF](https://arxiv.org/pdf/2507.07966), [HTML](https://arxiv.org/abs/2507.07966)
### Authors
Yukang Chen,Wei Huang,Baifeng Shi,Qinghao Hu,Hanrong Ye,Ligeng Zhu,Zhijian Liu,Pavlo Molchanov,Jan Kautz,Xiaojuan Qi,Sifei Liu,Hongxu Yin,Yao Lu,Song Han
### Background
研究了一种服务于视音频语言模型（VLMs）推理扩展的新框架，利用强化学习处理长视频中的复杂推理问题。该研究聚焦于现有视音频模型在处理长视频时面临的挑战，特别是长视频中的复杂背景和多变的情境，这些都需要强大的推理能力和有效的数据支撑。
### Innovation
该论文引入了一种全栈框架，名为LongVILA-R1-7B，它包含了以下几个关键组件：1) LongVideo-Reason数据集，包含104,000个高质量动生成的长视频问答对，涵盖体育、游戏、视频日志等多种领域；2) 利用链式思维监督微调（CoT-SFT）和强化学习（RL）的双重训练流程；3) 一种名为Multi-modal Reinforcement Sequence Parallelism (MR-SP)的训练基础设施，结合序列并行性和自定制的视频长链模型，实现高效的长视频生成推理。
### Conclusion
通过实验验证了LongVILA-R1-7B在视频基准测试上的优越性能，特别是在有和无字幕的情况下，其准确率为65.0%和70.7%。此外，该系统在长视频RL训练中实现了2.1倍的速度提升。研究人员开放了支持多种模态（视频、文字、音频等）、不同模型（VILA、Qwen系列）以及图像和视频生成模型的训练系统，可处理长达一小时长的视频（例如，3,600帧/约256k个词元）的强化学习训练。
## 503. `cs.CV` - 量化与缩小未知：基于不确定性最小化的交互式图文检索 [PDF](https://arxiv.org/pdf/2507.15504), [HTML](https://arxiv.org/abs/2507.15504)
### Authors
Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang
### Background
尽管近年来取得了进展，图文检索（TVR）仍受到多重固有不确定性的阻碍，例如模糊的文本查询、模糊的文本-视频映射以及低质量的视频帧。虽然已出现了交互系统来通过澄清问题来精炼用户意图，但当前的方法通常依赖于启发式或即兴策略，而没有明确量化这些不确定性，从而限制了它们的有效性。
### Innovation
我们提出了UMIVR（不确定性最小化交互式图文检索），这是一个明确量化三种关键不确定性（文本歧义、映射不确定性、帧不确定性）的框架，通过语义熵为基础的文字歧义评分（TAS）、詹森-шиannon 散度为基础的映射不确定性评分（MUS）以及基于时间质量的帧采样器（TQFS），适应性生成针对这些不确定性指标的澄清问题，迭代精炼用户查询，显著降低检索歧义性。
### Conclusion
在多个基准上的大量实验验证了UMIVR的有效性，在MSR-VTT-1k数据集上达到Recall@1（经过10轮交互后，达到69.2%）的效果，从而为交互式TVR建立了不确定性最小化的基础。
## 504. `cs.CV` - 通过梯度子空间距离选择用于私有机器学习的公共数据集 [PDF](https://arxiv.org/pdf/2303.01256), [HTML](https://arxiv.org/abs/2303.01256)
### Authors
Xin Gu,Gautam Kamath,Zhiwei Steven Wu
### Background
差分隐私的随机梯度下降通过对每个迭代引入噪声来私有化模型训练，噪声的大小随模型参数的数量增加而增加。近期研究表明，可以利用公共数据减少噪声，通过将梯度投影到由公共数据定义的子空间中。但是，面对多种选择的公共数据集，事先并不清楚哪一个最适用于私有任务。
### Innovation
该算法通过测量公共和私有示例梯度之间的低维子空间距离来选择公共数据集。理论分析表明这个距离与过拟合风险呈正比。距离的计算简单，并且对环境变化具有鲁棒性。实证评估表明，训练模型的准确性随着这个距离的增加而单调增加。
### Conclusion
该研究提出了一种通过计算梯度子空间距离选择适合私有机器学习的公共数据集的方法，并验证了该方法的有效性。
## 505. `cs.CV` - History-Guided Video Diffusion [PDF](https://arxiv.org/pdf/2502.06764), [HTML](https://arxiv.org/abs/2502.06764)
### Authors
Kiwhan Song,Boyuan Chen,Max Simchowitz,Yilun Du,Russ Tedrake,Vincent Sitzmann
### Background
Classifier-free guidance (CFG)是一种提高扩散模型条件生成准确性和样本质量的关键技术。该论文探讨了如何将CFG技术扩展到视频扩散中，以生成基于不同数量上下文帧（统称为历史）条件的视频。然而，实验证明，固定大小的上下文条件和CFG风格的历史帧丢弃效果不佳，为视频扩散中的历史指导提出了两个关键挑战。
### Innovation
提出了Diffusion Forcing Transformer (DFoT)，这是一种能够共同支持灵活数量历史帧条件的视频扩散架构和理论训练目标。提出了一种称为History Guidance的历史指导方法家族，包括基本形式的“vanilla history guidance”和更先进的“history guidance across time and frequency”，后者增强了动作动态性，使模型能够按分布外历史进行组合化泛化，并实现极长时间视频的稳定生成。
### Conclusion
实验表明，虽然“vanilla history guidance”是最简单的形式，但它已经显著提高了视频生成质量和时间一致性。更高级的方法则进一步增强了动作动态性，在分布外历史数据集上实现了更好的泛化，并能够稳定生成极长视频。该项目网站可以通过 this https URL 进行访问。
## 506. `cs.CV` - X-ray2CTPA：利用扩散模型增强肺栓塞分类 [PDF](https://arxiv.org/pdf/2406.16109), [HTML](https://arxiv.org/abs/2406.16109)
### Authors
Noa Cahan,Eyal Klang,Galit Aviram,Yiftach Barash,Eli Konen,Raja Giryes,Hayit Greenspan
### Background
胸部X光或胸部放射摄影（CXR）常用于医学诊断，虽然相比计算机断层扫描（CT）提供较少的细节和准确性，但CT扫描因其更高的成本、更多的辐射暴露以及较差的普及性不如CXR常用。本文研究的是从2D低对比度分辨率X光输入到3D高对比度和空间分辨率CT肺血管造影（CTPA）的跨模态转换方法。利用生成AI的近期进展，提出了一种新的基于扩散的方法来解决这一问题。
### Innovation
介绍了一种基于扩散的方法，用于跨模态转换从2D低对比度分辨率X光输入到3D高对比度和空间分辨率CTPA扫描。该方法使用定量指标和放射科医生的定性反馈进行评估，确保生成图像的诊断相关性。此外，将合成的3D图像用于分类框架，展示出对PE分类（肺栓塞）任务的AUC改进，并展示出该方法的通用性和跨模态转换能力，为更易于获取和成本效益更高的诊断工具开辟道路。
### Conclusion
该方法具有广泛的适用性和跨模态转换能力，有可能推动更易获取和成本效益高的高级诊断工具的发展。项目代码可在此处获取：this https URL
## 507. `cs.CV` - 利用DynamicDPS解决条件模型在医疗图像重建中的幻觉问题 [PDF](https://arxiv.org/pdf/2503.01075), [HTML](https://arxiv.org/abs/2503.01075)
### Authors
Seunghoi Kim,Henry F. J. Tregidgo,Matteo Figini,Chen Jin,Sarang Joshi,Daniel C. Alexander
### Background
在医学图像重建领域，幻觉指的是图像中不存在于实际数据中的虚假结构，这对数据驱动的条件模型构成了重大挑战。研究者们认为通过结合无条件扩散模型和数据一致性训练，可以在多样化的数据集上减少这些幻觉。基于此，本文引入了DynamicDPS框架，旨在降低幻觉的同时提升低质量的医学图像重建效果，且在所需采样步骤较少的情况下实现这一目标。
### Innovation
本文提出了一个名为DynamicDPS的基于无条件扩散模型的框架，该框架通过结合条件模型和适应性扩散法来逐步改进医疗图像，减少了因幻觉导致的结构错误。主要创新点包括自我调整的逆问题求解器、Wolfe线搜索优化步长，以及在这过程中的精确定时（根据样本选择最佳起点）。此外，研究发现DynamicDPS在不需要特定模型微调的前提下，使用较少的步骤就可显著提高医学图像质量，尤其对关键组织的体积估计，相对误差降低超过15%。
### Conclusion
DynamicDPS为医疗图像中幻觉的减少提供了一种模型无关且无需微调的稳健解决方案。经合成数据和真实MRI扫描的广泛测试，表明DynamicDPS能有效降低幻觉。此外，本文还提到代码将在发表后公开，供其他研究者参考。
## 508. `cs.CV` - L-FUSION:拉普拉斯胎儿超声分割与不确定性估计 [PDF](https://arxiv.org/pdf/2503.05245), [HTML](https://arxiv.org/abs/2503.05245)
### Authors
Johanna P. Müller,Robert Wright,Thomas G. Day,Lorenzo Venturini,Samuel F. Budd,Hadrien Reynaud,Joseph V. Hajnal,Reza Razavi,Bernhard Kainz
### Background
产前超声检查是早期识别发育异常的关键，但操作依赖性和技术限制（如固有伪影和技术设置误差）会复杂化图像解释和诊断不确定性评估。现有方法因其对操作者的依赖和技术局限性，在准确分析和识别胎儿异常方面存在局限性。
### Innovation
L-FUSION框架通过非监督的规范学习和大规模基础模型，结合不确定量化技术，实现了胎儿结构在正常和异常超声扫描中的稳健分割。该框架利用贝叶斯方法，仅通过分割头估计epistemic不确定性和aleatoric不确定性，实现即时诊断反馈，且具有较强的不确定性解释和病灶与正常结构的区分能力。
### Conclusion
L-FUSION在多个数据集上证明了其解决方案的优越性，不仅提高了分割精度，还提供了可靠的不确定度量化，支持即时临床决策，为临床背景下胎儿超声分析的进步提供了可扩展的方案。
## 509. `cs.CV` - VolDoGer: LLM辅助的数据集用于视觉语言任务中的域泛化 [PDF](https://arxiv.org/pdf/2407.19795), [HTML](https://arxiv.org/abs/2407.19795)
### Authors
Juhwan Choi,Junehyoung Kwon,JungMin Yun,Seunguk Yu,YoungBin Kim
### Background
域泛化是深度学习模型的关键方面，因为它决定了模型在未见过的数据域上的表现能力。然而，对于视觉语言任务的深度学习模型的域泛化研究仍然有限，主要是因为缺乏必要的数据集。
### Innovation
提出了VolDoGer：视觉语言数据集用于域泛化，这是一个专门设计用于解决三个视觉语言任务（图像字幕生成、视觉问答和视觉蕴含）的域泛化问题的数据集。通过使用基于大语言模型的数据注释技术扩展现有数据集，减轻了招募人类注释者的负担。
### Conclusion
通过VolDoGer，评估了多种模型在域泛化方面的表现，包括微调模型和最新的多模态大语言模型。
## 510. `cs.CV` - 使用视觉、声音和触觉学习温柔抓取 [PDF](https://arxiv.org/pdf/2503.07926), [HTML](https://arxiv.org/abs/2503.07926)
### Authors
Ken Nakahara,Roberto Calandra
### Background
在我们的日常生活中，经常会有易碎的物品，如水果，容易因过度抓握而受损。因此，进行温柔且稳定的抓取非常重要，即使用最少的必要力量而不是最大的力量。本文提出了一种利用视觉、听觉和触觉信号来学习如何稳定且柔韧地抓取物体的方法，特别是在多指手上的试验验证了这种方法的有效性。
### Innovation
提出了一种结合视觉、听觉和触觉信号的端到端模型，用于预测未来的抓取动作的稳定性和柔软性，并据此选择和执行最有前景的动作。此方法无需校准触觉传感器或进行分析力建模，极大地降低了抓取易碎物品的工程努力。与仅依赖视觉的方法相比，该多模态模型在抓取稳定性及柔软性上表现更好，直接提升了实际应用效果。
### Conclusion
通过综合视觉、听觉和触觉信号进行多模态感知学习，不仅提高了抓取的稳定性和柔软性，还在工程实现上简化了流程，使抓取易碎物品变得更加简便有效。实验证明，训练后的多模态模型在执行稳定且温柔的抓取时表现优于其他基线方法。
## 511. `cs.CV` - SR-NeRV: 通过超分辨率提高神经视频表示的嵌入效率 [PDF](https://arxiv.org/pdf/2505.00046), [HTML](https://arxiv.org/abs/2505.00046)
### Authors
Taiga Hayami,Kakeru Koizumi,Hiroshi Watanabe
### Background
隐式神经表示（INRs）因其在不同领域中建模复杂信号的能力而受到了广泛关注。最近，基于INR的框架在神经视频压缩方面显示出潜力，通过将视频内容嵌入紧凑的神经网络中。然而，这些方法在模型大小受到严格限制的情况下重建高频细节时常遇到困难，而在实际压缩场景中，小模型尺寸是关键需求。
### Innovation
本文提出了一个基于INR的视频表示框架，该框架整合了一个通用的超分辨率（SR）网络。这种方法的设计依据是观察到高频成分在帧间的时间冗余性较低。通过将高频细节的重建工作从一个预先在自然图像上训练的专用SR网络中解脱出来，所提出的方法提升了视觉保真度。实验结果表明，所提出的方法在重建质量上优于传统的基于INR的基本方法，同时保持了相似的模型大小。
### Conclusion
实验结果表明，所提出的SR-NeRV方法在重建质量上优于传统的基于INR的方法，同时保持了相似的模型大小，从而提高了视觉保真度。
## 512. `cs.CV` - PALADIN: 强化文本到图像扩散模型的鲁棒神经指纹识别 [PDF](https://arxiv.org/pdf/2506.03170), [HTML](https://arxiv.org/abs/2506.03170)
### Authors
Murthy L,Subarna Tripathi
### Background
随着文本到图像生成模型的开源发展，其被恶意利用的风险引起了广泛关注。为应对这一问题，研究人员提出了神经指纹识别技术作为风险缓解策略，尽管已有许多研究致力于提高神经指纹识别的准确性，但现有的方法仍无法达到100%的准确率，这意味着任何低于这一水平准确率的方法在实际应用中都是不可行的。
### Innovation
本文提出了一种基于编码理论中的循环错误纠正码概念的准确方法，该方法可以增强文本到图像扩散模型的神经指纹识别技术，从而提高其准确性和鲁棒性。
### Conclusion
本文提出的方法能够提供更准确的神经指纹识别，对于文本到图像扩散模型来说更具实用性和可靠性。
## 513. `cs.CV` - PRIX: 从原始像素学习规划的端到端自动驾驶 [PDF](https://arxiv.org/pdf/2507.17596), [HTML](https://arxiv.org/abs/2507.17596)
### Authors
Maciej K. Wozniak,Lianhang Liu,Yixi Cai,Patric Jensfelt
### Background
尽管端到端的自动驾驶模型展现了令人鼓舞的结果，但其实际部署常常受到大模型规模、对昂贵的LiDAR传感器的依赖以及计算密集的BEV特征表示的限制，这限制了其可扩展性，尤其是对于仅配备摄像头的大众市场车辆来说更为明显。
### Innovation
本文提出了PRIX (Plan from Raw Pixels)。这是一种全新的且高效的端到端驾驶架构，仅使用摄像头数据运行，不需要明确的BEV表示，也省去了LiDAR的需求。PRIX利用视觉特征提取器与生成性规划头部相结合，从原始像素输入中直接预测安全轨迹。核心组件是上下文感知重校准变换器（CaRT），这是一种专门设计的新模块，旨在有效地增强多层次视觉特征，从而实现更稳健的规划。
### Conclusion
通过全面的实验，PRIX在NavSim和nuScenes基准测试中达到了最先进的性能，实现了与更大、多模态扩散规划者相当的能力，但在推理速度和模型大小方面更为高效，使其成为实际部署的可行解决方案。我们的工作是开源的，代码将发布在this https URL.
## 514. `cs.CV` - AI工作流、外部验证和眼病诊断中的发展 [PDF](https://arxiv.org/pdf/2409.15087), [HTML](https://arxiv.org/abs/2409.15087)
### Authors
Qingyu Chen,Tiarnan D L Keenan,Elvira Agron,Alexis Allot,Emily Guan,Bryant Duong,Amr Elsawy,Benjamin Hou,Cancan Xue,Sanjeeb Bhandari,Geoffrey Broadhead,Chantal Cousineau-Krieger,Ellen Davis,William G Gensheimer,David Grasic,Seema Gupta,Luis Haddock,Eleni Konstantinou,Tania Lamba,Michele Maiberger,Dimosthenis Mantopoulos,Mitul C Mehta,Ayman G Nahri,Mutaz AL-Nawaflh,Arnold Oshinsky,Brittany E Powell,Boonkit Purt,Soo Shin,Hillary Stiefel,Alisa T Thavikulwat,Keith James Wroblewski,Tham Yih Chung,Chui Ming Gemmy Cheung,Ching-Yu Cheng,Emily Y Chew,Michelle R. Hribar,Michael F. Chiang,Zhiyong Lu
### Background
随着疾病负担增加和临床工作者数量有限，及时的疾病诊断变得具有挑战性。AI在提高诊断准确性方面显示出潜力，但在实际临床工作流程中应用时遇到挑战，主要是因为缺乏对多样化人群的验证。本文通过在年龄相关性黄斑变性（AMD）诊断和严重程度分类中的案例研究，解决医疗AI下游问责制度中的缺口。
### Innovation
设计并实施了一个使用AI辅助诊断流程来提高AMD诊断和分类性能。通过整合大约40,000张额外的医学图像（即AREDS2数据集），改进了现有的AI模型，并在三个独立数据集上系统地进行评估，展示了基于持续学习的模型在不同人群中的稳健性能。
### Conclusion
AI协助显著提升了23名临床医生中的24名的诊断准确性和分类，平均F1分数从手动诊断的37.71提高到45.52（P值<0.0001），某些情况下提高了超过50%。使用AI协助仅减少了19名临床医生中的17名的诊断时间，时间节省最多可达40%。配备持续学习能力的模型三组独立数据集上的准确率提高了29%，F1分数在新加坡的人群中从42提高到54。
## 515. `cs.CV` - 抗aliasesing的B-cos网络实现胸片诊断的忠实性和可解释性 [PDF](https://arxiv.org/pdf/2507.16761), [HTML](https://arxiv.org/abs/2507.16761)
### Authors
Marcel Kleinmann,Shashank Agnihotri,Margret Keuper
### Background
在医疗成像等安全关键领域中，部署深度神经网络（DNNs）时需要保证模型的忠实性和可解释性。B-cos网络通过将标准线性层替换为权重-输入对齐机制，提供了一种可解释且类别的特定的解释方法。尽管B-cos模型能够保持与当前最先进的DNNs相当的诊断性能，但它们在解释图中存在严重的aliasing伪影，这使其在需要清晰性的临床应用领域难以使用。
### Innovation
本文通过引入基于FLCPooling（FLC）和BlurPool（BP）的anti-aliasing策略，显著提高了解释质量和模型的忠实性。实验结果表明，修改后的B-cos模型在多类别和多标签设置中保留了强大的预测性能，同时提供了无伪影的、适合临床应用的忠实解释。
### Conclusion
修改后的B-cos网络（B-cos_FLC和B-cos_BP）在胸片诊断中具备强大的预测性能，同时提供了无伪影的忠实解释，适用于多种临床应用。相关代码可在GitHub仓库中获取。
## 516. `cs.CV` - 通过大规模3D视觉指令数据集生成提高多模态LLMs [PDF](https://arxiv.org/pdf/2507.08513), [HTML](https://arxiv.org/abs/2507.08513)
### Authors
Liu He,Xiao Zeng,Yizhi Song,Albert Y. C. Chen,Lu Xia,Shashwat Verma,Sankalp Dayal,Min Sun,Cheng-Hao Kuo,Daniel Aliaga
### Background
现有的多模态大语言模型（MLLMs）在捕捉相机与物体之间的关系，特别是在物体方向、相机视角和镜头类型方面，准确性不足。这主要因为这些模型的训练数据集包含的相机-物体关系种类有限，且对应的文本描述不足。
### Innovation
该研究提出了一种合成生成管道，以创建大规模3D视觉指令数据集。该框架采用3D资产作为输入，利用渲染和扩散生成模型创建保留精准相机-物体关系的逼真图像。同时，使用大型语言模型（LLMs）生成引导视觉指令调优和控制图像生成的文本提示。研究还创建了Ultimate3D数据集及其相应的基准测试，该数据集包括240K精确的相机-物体注释的VQA，并表明使用该数据集微调的MLLMs在相机-物体关系识别任务中的准确度大幅提升，平均改善33.4%，超过商业模型显著。开源代码、数据集和基准测试将推动广泛的MLLM应用
### Conclusion
通过大规模3D视觉指令数据集，微调后的多模态大语言模型在相机-物体关系识别任务上的表现大幅提升，开源代码、数据集和基准测试将提供研究和实际应用的基础。
## 517. `cs.CV` - I-CEE: 根据用户专长定制图像分类模型的解释 [PDF](https://arxiv.org/pdf/2312.12102), [HTML](https://arxiv.org/abs/2312.12102)
### Authors
Yao Rong,Peizhu Qian,Vaibhav Unhelkar,Enkelejda Kasneci
### Background
开发能够负责任地部署依赖黑盒机器学习模型的人工智能系统至关重要，因此解释这些模型的决策变得极其重要。现有的可解释AI（XAI）技术旨在解决这一需求，但大多数方法提供的解释往往是“一揽子”解决方案，缺乏个性化，未能充分考虑用户的专长。为了克服这一局限，本文提出了一种新的框架I-CEE，旨在根据用户的专长为图像分类模型提供定制化解释。
### Innovation
I-CEE框架通过提供与用户专长相适应的训练数据子集（即示例图像）、对应的地方解释和模型决策来解释图像分类模型的决策。与之前的XAI方法不同，I-CEE认为示例图像的信息性依赖于用户专长，从而为不同的用户提供不同的示例。这种方法有望通过定制示例集来更好地促进用户的理解和模拟模型。
### Conclusion
为了评估这一方法，研究人员在多个数据集上进行了详细的实证实验，包括模拟用户和真实的人类参与者。实验结果表明，I-CEE能够提升用户对模型决策的预测准确性，特别是在人类用户层面表现明显。这些实验结果显示出I-CEE在实现以用户为中心的XAI方面的巨大潜力。
## 518. `cs.CV` - EndoControlMag：具有周期性参考重置和层次组织器理双模面控制的鲁棒内窥镜血管运动放大 [PDF](https://arxiv.org/pdf/2507.15292), [HTML](https://arxiv.org/abs/2507.15292)
### Authors
An Wang,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren
### Background
在内窥镜手术中，可视化微妙的血管运动对于手术精确度和决策至关重要，但由于手术场景复杂且动态变化，这一任务一直充满挑战。现有的方法难以应对这种情况，需要改进以提升手术过程中的决策质量与准确度。
### Innovation
EndoControlMag 是一种无需训练的拉格朗日框架，结合了基于掩模条件的血管运动放大，特别适用于内窥镜环境。创新之处在于其采用了两种关键模块：周期性参考重置（PRR）方案，将视频分割成短时间重叠片段，并通过动态更新参考帧来防止误差累积同时保持时间连贯性；以及层次组织器理双模式组织（HTM）放大框架，此框架包含双模式掩模膨胀机制。HTM能够通过预训练的视觉跟踪模型来跟踪血管核心，即使在遮挡或视角变化的情况下也能保持精确的定位。HTM还应用了一种双重软化策略来处理周围组织：基于运动的软化策略根据观测到的组织位移来调节放大强度；基于距离的指数衰减策略则模拟了生物力学力的衰减。
### Conclusion
EndoControlMag 在包含不同手术类型和挑战场景的 EndoVMM24 数据集上进行了评估，结果表明，在放大精度和视觉质量方面，该方法显著优于现有方法，同时在复杂手术条件下保持了鲁棒性。代码、数据集和视频结果可在指定链接中获取。
## 519. `cs.CV` - 跨域双模态骗检基准测试 [PDF](https://arxiv.org/pdf/2405.06995), [HTML](https://arxiv.org/abs/2405.06995)
### Authors
Xiaobao Guo,Zitong Yu,Nithish Muthuchamy Selvaraj,Bingquan Shen,Adams Wai-Kin Kong,Alex C. Kot
### Background
自动诱骗检测对于帮助人类准确评估真实性及识别欺骗行为至关重要。传统的接触式技术，如多普勒设备，依赖生理信号来判断个体陈述的真实性。近年来，基于音频和视频模态的多模态特征在公开数据集上的表现优于人类观察者。尽管取得了一些积极成果，但在不同场景中现有音频-视觉骗检方法的一般性仍未得到充分探索。
### Innovation
本研究提出了第一个跨域双模态骗检基准，评估现有方法在实际场景中的泛化能力。对比了单对单和多对单领域泛化性能，并调查了三种领域采样策略以提升多对单领域泛化评估。还提出了通过最大化模态编码器梯度内积的算法“MM-IDGM”和注意力混合融合方法，以提升泛化性能。
### Conclusion
本新提出跨域基准将有助于未来音频-视觉骗检领域的研究。
## 520. `cs.CV` - LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important [PDF](https://arxiv.org/pdf/2504.04704), [HTML](https://arxiv.org/abs/2504.04704)
### Authors
Manlai Liang,JiaMing Zhang,Xiong Li,Jinlong Li
### Background
在大规模语言模型（LLM）进行长时间上下文推理时，Key-Value（KV）缓存的大小增加成为了其部署成本与任务准确性之间平衡的主要障碍。大多数现有方法通过利用注意力权重来移除不关键的缓存令牌来减少KV缓存的大小，但这些方法通常需要对推理基础设施进行重大修改，并且伴随着显著的计算开销。
### Innovation
基于语言模型是自回归模型的事实，作者提出了LagKV，这是一种仅依赖于KV本身之间直接比较的KV压缩策略，完全不需要使用注意力机制的方法。该方法易于集成到主流推理平台中，并且在压缩比例相同时，其性能与其他复杂的KV压缩方法相当。特别是在64位密码检索任务中，该方法优于基于注意力权重的方法$H_2O$超过50%。
### Conclusion
在RULER基准测试上，作者的方法在不同压缩率下均优于SnapKV和StreamingLLM。特别是在64位密码检索任务中，该方法在相同压缩率下比基于注意力权重的方法$H_2O$性能高出50%以上。该代码可以在提供的链接中获取。
## 521. `cs.CV` - MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation [PDF](https://arxiv.org/pdf/2507.16122), [HTML](https://arxiv.org/abs/2507.16122)
### Authors
Nand Kumar Yadav,Rodrigue Rizk,William CW Chen, KC (Santosh AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA.)
### Background
准确高效的医学图像分割对于处理解剖变异性和高计算需求的3D数据非常重要但具有挑战性。近年来，混合CNN-Transformer架构已经取得了最先进的结果，但增加了显著的复杂性。现有的医学图像分割方法在精度和计算效率之间难以平衡，特别是对于3D医学图像的语义理解与细节捕捉。
### Innovation
本文提出了一种新的MLRU++架构，结合了多尺度轻量级残差UNETR++，旨在平衡分割准确性和计算效率。MLRU++引入了两个关键创新：一个轻量级通道和瓶颈注意力模块（LCBAM），它可以以最小的开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合来捕捉细粒度细节。该架构在四个公开基准数据集（Synapse、BTCV、ACDC和Decathlon Lung）上得到了验证，证明MLRU++在Dice分数方面达到了最先进的性能，并显著降低了参数计数和计算成本。
### Conclusion
实验结果表明，MLRU++提供了一种在3D医学图像分割任务中实用且高性能的解决方案。通过消融研究进一步确认了提出架构组件的效用，证明了MLRU++在分割精度和计算效率之间的优越表现。
## 522. `cs.CV` - CA-Cut：用于学习更 robust 的地下茎导航的数据增广方法 [PDF](https://arxiv.org/pdf/2507.17727), [HTML](https://arxiv.org/abs/2507.17727)
### Authors
Robel Mamo,Taeyeong Choi
### Background
当前的基于深度学习的感知模型在识别可通行空间和农作物行方面表现出成功性能，但这些模型需要大量的训练数据以确保在实地操作中的可靠性。然而，数据采集成本高昂，需要大量的人力资源进行采样和标注。通过数据增强技术来增加训练数据的多样性可以提高模型的稳健性。
### Innovation
提出了一种新颖的数据增强方法，称为Crop-Aligned Cutout (CA-Cut)，它通过在输入图像中随机屏蔽分布在作物行周围的区域，促使训练模型在细粒度信息被遮挡时也能捕捉到高层上下文特征。实验表明，使用基于掩码的数据增强能有效模拟遮挡并显著提高语义关键点预测的鲁棒性。
### Conclusion
CA-Cut方法在覆盖多样化环境时提高了预测准确性和泛化能力，相较于传统方法，减小了预测误差高达36.9%。通过消融研究确定了最佳掩码数量、掩码大小和掩码空间分布，以最大化总体性能。
## 523. `cs.LG` - 基于知识抽象的基于知识的语义通信：生成因果不变方法 [PDF](https://arxiv.org/pdf/2507.17784), [HTML](https://arxiv.org/abs/2507.17784)
### Authors
Minh-Duong Nguyen,Quoc-Viet Pham,Nguyen H. Tran,Hoang-Khoi Do,Duy T. Ngo,Won-Joo Hwang
### Background
在语义通信中，数据恢复对频道解码器非常重要。该研究旨在设计一种低复杂度且通用的人工智能模型，以捕捉通用知识并改进频道解码器的数据恢复能力。该研究表明，通过使用因果不变学习的生成对抗网络可以从数据中提取因果和非因果表示。因果表示具有不变性，并且包含了识别数据标签的关键信息，有助于接收端的高效数据恢复。同时，因果机制确保学习到的表示在不同的领域保持一致，使系统即使在用户从不同领域收集数据时也能保持可靠性。随着用户收集的数据随时间演变，导致用户之间的知识差异，设计稀疏更新协议以改善知识的不变性能并最小化通信开销。实证评估显示，因果不变知识确保不同设备之间的一致性，不变知识在分类任务中表现出色，这对于目标导向的语义通信至关重要，而基于知识的数据恢复突显了我们解码器的鲁棒性，其在峰值信噪比（PSNR）方面优于其他最先进的数据恢复和语义压缩方法。
### Innovation
该研究提出了一个生成对抗网络，利用因果不变学习，从数据中提取因果和非因果表示。此外，设计了稀疏更新协议以改善知识的不变性能并最小化通信开销。
### Conclusion
因果不变的知识确保了设备之间的数据恢复在不同设备之间的一致性，对于分类任务展现出良好的性能，并提高了基于知识的数据恢复的鲁棒性，其在PSNR方面超过了其他先进的数据恢复和语义压缩方法。
## 524. `cs.CV` - 扩散模型在数据受限设置中优于自回归模型 [PDF](https://arxiv.org/pdf/2507.15857), [HTML](https://arxiv.org/abs/2507.15857)
### Authors
Mihir Prabhudesai,Menging Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak
### Background
AR模型长期以来主导了大型语言模型领域，推动了各类任务的进步。最近，基于扩散的语言模型作为一种有前途的替代方案出现，但它们相对于AR模型的优势尚未充分探索。本文系统地研究了在数据受限的场景下（训练需要频繁遍历有限数据），掩蔽扩散模型的表现。
### Innovation
本文发现了扩散模型的新扩展规律，并推导出了扩散模式开始优于AR模型的关键计算阈值的闭合公式表达。研究表明，当数据而非计算资源成为瓶颈时，扩散模型为标准AR范式的可替代方案提供了新的选择。
### Conclusion
本文表明，当数据而非计算量成为限制因素时，扩散模型在数据受限设置中表现出众，超越了自回归模型。扩散模型通过在不同令牌排列和预测任务中隐式增强模型，更有效地利用重复数据，表现出较低的验证损失和下游性能。
## 525. `cs.LG` - Hyperbolic Deep Learning for Foundation Models: A Survey [PDF](https://arxiv.org/pdf/2507.17787), [HTML](https://arxiv.org/abs/2507.17787)
### Authors
Neil He,Hiren Madhu,Ngoc Bui,Menglin Yang,Rex Ying
### Background
基础模型（包括大规模语言模型、视觉-语言模型和大规模多模态模型）在多种下游任务中表现出色，但最近的研究揭示了这些模型的基本限制，包括代表能力有限、适应性较低、可扩展性差。这些不足引发了对欧几里得几何是否是所有基础模型的最佳归纳偏见的质疑，同时也提出了将替代几何空间融入模型以更好地与现实数据的内在结构对齐并提高推理过程的想法。
### Innovation
提出将双曲空间（一类非欧几里得流形，具有距离的指数体积增长）引入基础模型，利用其低失真嵌入分层结构和幂律分布的能力，以比欧几里得空间更少的维度提供数学基础的解决方案。最近的研究已经利用这些特性来增强基础模型，包括提升大规模语言模型的复杂推理能力、视觉-语言模型的零样本泛化能力和跨模态语义对齐，同时保持参数效率。
### Conclusion
本文对双曲神经网络及其在基础模型中的最近发展进行了全面综述。进一步指出了关键挑战和研究方向，以促进该领域的进步。
## 526. `cs.CV` - BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression [PDF](https://arxiv.org/pdf/2505.09193), [HTML](https://arxiv.org/abs/2505.09193)
### Authors
Wei Jiang,Junru Li,Kai Zhang,Li Zhang
### Background
最近的基于前向预测的学习视频压缩（LVC）方法取得了显著成果，甚至在低延迟B（LDB）配置下超过了VVC参考软件VTM。相比之下，基于双向的学习视频压缩（BVC）仍被广泛忽视，性能落后于单向版本。这一性能差异主要源于提取多样和准确上下文能力的不足：大多数现有的BVC主要利用时域运动，忽视了帧间非局部相关性。此外，它们缺乏适应性动态抑制快速运动或遮挡引发的有害上下文的能力。
### Innovation
为了应对这些挑战，我们提出了BiECVC，这是一种融合多样局部和非局部上下文建模以及自适应上下文门控的BVC框架。通过重新使用低层的高质量特征并利用解码的运动向量进行对齐，BiECVC增强了局部上下文且不引入额外的运动开销。为了高效建模非局部依赖关系，我们采用了线性注意力机制平衡性能和复杂度。为了进一步减轻不准确上下文预测的影响，我们引入了双向上下文门控机制，以基于条件编码结果动态过滤上下文信息。
### Conclusion
广泛的实验表明，BiECVC达到了最先进的性能，在随机访问（RA）配置中，内插周期分别为32和64时，相对于VTM 13.2分别降低了13.4%和15.7%的比特率。据我们所知，BiECVC是首个在所有标准测试数据集中超越VTM 13.2 RA的学习视频编码器。
## 527. `cs.LG` - 基于LLM的排名中适应性重复以缓解位置偏差 [PDF](https://arxiv.org/pdf/2507.17788), [HTML](https://arxiv.org/abs/2507.17788)
### Authors
Ali Vardasbi,Gustavo Penha,Claudia Hauff,Hugues Bouchard
### Background
在使用大型语言模型（LLMs）对项目进行排名或评估答案时，候选项目的排列顺序会影响模型的最终决策。这种对候选项目在提示中位置的敏感性被称为位置偏差。先前的研究表明，即使是大型模型也存在这种偏差，但其严重程度因模型和任务而异。此外，LLMs在重复一致性方面也表现出较大的不同，重复相同呼叫可能会得到不同的排名。为了应对这两种不一致性，一种常见的方法就是用不同的候选顺序多次提示模型，并通过多数投票的方式汇总结果。然而，这种方法显著增加了计算成本。我们观察到，位置偏差的偏向性和幅度在不同实例中差异很大，甚至在同一个数据集中也是如此。这表明需要一个针对实例的缓解策略。
### Innovation
我们提出了一种动态早期停止方法，它适应性地确定每个实例所需的重复次数。在不同规模的3个LLM上和两个任务（重新排名和对齐）上进行评估，表明采用动态重复策略可以将LLM调用次数降低平均81%，同时保持准确性。此外，我们还提出了一种基于置信度的早期停止方法改进，相比静态重复将LLM调用次数平均减少87%，只有一小部分准确性的损失。
### Conclusion
动态重复策略可以显著减少LLM调用次数而保持准确性，是一种有效的缓解位置偏差的方法。基于置信度的改进进一步优化了这种方法的效果。
## 528. `cs.CV` - 基于时空嵌入的静态标签动态映射：具有时空嵌入的遥感动态样本生成 [PDF](https://arxiv.org/pdf/2506.02574), [HTML](https://arxiv.org/abs/2506.02574)
### Authors
Shuai Yuan,Shuang Chen,Tianwu Lin,Jincheng Yuan,Geng Tian,Yang Xu,Jie Wang,Peng Gong
### Background
准确的遥感地理映射需要及时且代表性的样本。然而，快速的土地表面变化通常会在几个月内使静态样本过时，导致手动样本更新过程耗时且不可持续。为解决这一挑战，本文提出了一种名为TasGen的两阶段时空感知自动样本生成方法，用于无需人工干预从单日期静态标签生成动态训练样本。
### Innovation
TasGen方法包括两个阶段：初始阶段使用具有双重维度嵌入的分层时空变分自编码器（HTS-VAE）来学习正常样本的时间-光谱低维潜在模式；第二阶段则通过在稳定样本上训练的分类器重新标注时间上的变化点来生成动态样本。此外，文章还提出了一种基于吉布斯采样的异常解释方法，用于将变化归因于具体的光谱-时间维度。
### Conclusion
本文提出了一种时空感知的自动生成方法TasGen，能从单日期静态标签生成动态训练样本，同时通过时空嵌入和异常解释方法有效捕捉土地表面动态。
## 529. `cs.LG` - 跨多个领域多传感器系统的因果机制估计 [PDF](https://arxiv.org/pdf/2507.17792), [HTML](https://arxiv.org/abs/2507.17792)
### Authors
Jingyi Yu,Tim Pychynski,Marco F. Huber
### Background
当前在研究复杂传感器系统时，通过因果方法获取更深入的认识。鉴于数据在多个领域中的异质性，如何从这些多元数据中有效地提取因果机制成为一个挑战。已有方法如连续优化基础的因果发现方法在处理复杂传感器系统时存在局限性，需要改进提升其泛化能力和准确性。因此，本文旨在介绍一种新的因果机制估计方法——共同和个体因果机制估计（CICME），以更好地应对这种复杂性问题。
### Innovation
本文提出了一种新颖的三步骤方法——CICME，该方法结合了因果迁移学习（CTL）的原则，能够从多领域采集的异质数据中可靠地发现跨域不变的因果机制，为各领域内剩余的因果机制估计提供了指导。方法显著改进了现有连续优化基础的因果发现方法的表现，并在这种复杂系统中表现出更优的性能，尤其是在特定场景下。
### Conclusion
本文通过将因果机制发现应用于汇集数据和单个领域数据，进一步验证了CICME方法的有效性。通过实证结果表明，这种方法不仅提高了泛化能力，还在某些场景中优于基准方法。这为复杂传感器系统中的因果机制估计提供了一种新的思路。
## 530. `cs.LG` - LSDM: LLM-Enhanced Spatio-temporal Diffusion Model for Service-Level Mobile Traffic Prediction [PDF](https://arxiv.org/pdf/2507.17795), [HTML](https://arxiv.org/abs/2507.17795)
### Authors
Shiyuan Zhang,Tong Li,Zhu Xiao,Hongyang Du,Kaibin Huang
### Background
服务级别的移动流量预测对于提高网络效率和服务质量至关重要。然而，现有的预测方法在不同城市环境中缺乏适应性，且由于个人流量模式的高不确定性、缺乏详细的环境背景以及各种网络服务之间的复杂依赖关系，导致预测结果不够准确。这些挑战需要更加先进的建模技术，能够捕捉动态的流量分布和丰富的环境特征。
### Innovation
受到扩散模型在分布建模领域的成功和大型语言模型（LLMs）在上下文理解方面的优势启发，本文提出了一种增强的时空扩散模型（LSDM）。LSDM将扩散模型的生成能力与变压器的自适应学习能力相结合，并增加了捕捉多模态环境信息的能力，从而更好地模拟服务级别的模式和动态。广泛的实证研究表明，该模型在流量使用预测方面表现优异，具有出色的泛化能力和适应性。通过整合上下文信息，性能提升了至少2.83%的决定系数，并相比类似类型的模型，如CSDI，最小可减少8.29%的均方根误差。
### Conclusion
研究开发了一种LSDM模型，该模型表现出色且具有良好的泛化和适应性。模型通过整合上下文信息显著提高了性能，比其他类似模型有着明显的优越性。
## 531. `cs.CV` - crossMoDA挑战：2021年至2023年 vestibular schwannoma和耳蜗分割的跨模态领域适应技术的发展 [PDF](https://arxiv.org/pdf/2506.12006), [HTML](https://arxiv.org/abs/2506.12006)
### Authors
Navodini Wijethilake,Reuben Dorent,Marina Ivory,Aaron Kujawa,Stefan Cornelissen,Patrick Langenhuizen,Mohamed Okasha,Anna Oviedova,Hexin Dong,Bogyeong Kang,Guillaume Sallé,Luyi Han,Ziyuan Zhao,Han Liu,Yubo Fan,Tao Yang,Shahad Hardan,Hussain Alasmawi,Santosh Sanjeev,Yuzhou Zhuang,Satoshi Kondo,Maria Baldeon Calisto,Shaikh Muhammad Uzair Noman,Cancan Chen,Ipek Oguz,Rongguo Zhang,Mina Rezaei,Susana K. Lai-Yuen,Satoshi Kasai,Yunzhi Huang,Chih-Cheng Hung,Mohammad Yaqub,Lisheng Wang,Benoit M. Dawant,Cuntai Guan,Ritse Mann,Vincent Jaouen,Tae-Eui Kam,Li Zhang,Jonathan Shapey,Tom Vercauteren
### Background
该研究于2021年由国际医学影像计算与辅助介入会议（MICCAI）发起，旨在解决无监督的跨模态分割问题，通过从对比增强T1（ceT1）图像学习并转移到T2 MRI上。这项任务选择极端的领域变化，旨在作为有意义且富有说明性的基准。从临床应用的角度出发，该挑战旨在自动化T2扫描上的vestibular schwannoma（VS）和耳蜗分割，以便于更成本效益的VS管理。
### Innovation
挑战的目标随着时间不断进化以增加其临床相关性。从2021年的单机构数据和基本分割，到2022年多机构数据和Koos分级的引入，再到2023年的多样常规数据和内、外耳道肿瘤亚组件的子分割。2023年度的获胜方法减少了2021年和2022年测试数据中的异常值，显示出数据异质性的增加可以即使在同质数据上提高分割性能。然而，由于附加了肿瘤亚注释带来的复杂性，耳蜗Dice分数在2023年有所下降。
### Conclusion
虽然临床可接受的VS分割仍需进一步进步，但性能中的平台表明更具有挑战性的跨模态任务在未来基准测试中可能会更适用。
## 532. `cs.LG` - Helix 1.0: 开源的、可扩展的Python框架，用于表格科学数据的可重复和可解释机器学习 [PDF](https://arxiv.org/pdf/2507.17791), [HTML](https://arxiv.org/abs/2507.17791)
### Authors
Eduardo Aguilar-Bejarano,Daniel Lea,Karthikeyan Sivakumar,Jimiama M. Mase,Reza Omidvar,Ruizhe Li,Troy Kettle,James Mitchell-White,Morgan R Alexander,David A Winkler,Grazziela Figueredo
### Background
随着透明实验数据溯源的需求增长，确保所有分析过程（包括数据转换和方法选择的决策）的文档化、可访问、可重复且对相关人员来说可理解变得至关重要。特别是对于表格结构的数据而言，需要一种工具来简化机器学习的工作流，同时保持可解释性和透明性。
### Innovation
Helix 是一个开源且可扩展的 Python 基于框架，旨在通过标准化的数据预处理、可视化、机器学习模型训练、评估、解释、结果检查和预测设计，支持表格数据的可重复且可解释的机器学习工作流。它还提供了一个用户友好的界面，使无数据科学背景的研究人员能够设计计算性实验并检查其结果，包括一个新颖的使用语言术语的机器学习决策解释方法。
### Conclusion
Helix 作为开源项目可从 GitHub 和 PyPI 使用，并遵循 MIT 许可，促进社区驱动的发展并推动 FAIR 原则的遵循，有助于研究人员轻松地进行有意义且可操作的洞察分析。
## 533. `cs.LG` - GenSelect：用于Best-of-N的生成式方法 [PDF](https://arxiv.org/pdf/2507.17797), [HTML](https://arxiv.org/abs/2507.17797)
### Authors
Shubham Toshniwal,Ivan Sorokin,Aleksander Ficek,Ivan Moshkov,Igor Gitman
### Background
生成奖励模型通过并行采样实现了有效测试扩展，当前方法通过逐点评分或两两比较进行评估，但逐点方法未能充分利用LLMs的比较能力，两两方法则随着采样预算增大而难以扩展.
### Innovation
引入GenSelect方法，使得LLMs利用长时间推理在N个候选解中挑选最优，这种处理方式既利用了LLMs的比较优势，又能在并行采样预算下进行有效扩展. 在数学推理任务中，GenSelect方法通过简单提示显著优于现有的评分方法，特别是对QwQ和DeepSeek-R1-0528模型表现出色.
### Conclusion
GenSelect方法展示了在数学推理任务中对LLMs进行有效优化的能力，克服了当前方法的不足，为应对大规模采样任务提供了新的解决方案.
## 534. `cs.LG` - 通过相对熵自举选择和级联层校正在边缘设备上增强量化感知训练 [PDF](https://arxiv.org/pdf/2507.17768), [HTML](https://arxiv.org/abs/2507.17768)
### Authors
Yujia Tong,Jingling Yuan,Chuang Hu
### Background
随着移动和边缘计算的发展，边缘设备对低位宽量化模型的需求增加，以便实现高效部署。为了提高性能，通常需要使用边缘数据重新训练量化模型。然而，由于隐私问题，某些敏感数据只能在边缘设备上处理。因此，通过边缘设备上的量化感知训练（QAT）已成为一种有效的解决方案。但是，传统的QAT依赖于完整的数据集进行训练，会产生巨大的计算成本。coreset选择技术可以通过训练在最具有代表性的子集上减轻这一问题。然而，现有的方法在使用小规模数据集（例如，仅10％的数据）时难以消除模型中的量化误差，导致性能大幅下降。
### Innovation
本文提出了QuaRC框架，一个在边缘设备上结合coreset选择和级联层校正的量化感知训练框架。QuaRC包含两个主要阶段：在coreset选择阶段，引入了相对熵评分来识别最能捕捉模型量化误差的子集；在训练阶段，采用了级联层校正策略，对量化模型的中间层输出进行校准，以减少量化误差。
### Conclusion
实验结果表明该方法的有效性。例如，当将ResNet-18量化为2位时，使用QuaRC对ImageNet-1K数据集的Top-1准确率提高了5.72%，超过了现有技术。
## 535. `cs.LG` - 通过结构外部性解释图神经网络 [PDF](https://arxiv.org/pdf/2507.17848), [HTML](https://arxiv.org/abs/2507.17848)
### Authors
Lijun Wu,Dong Hao,Zhiyi Fan
### Background
图神经网络（GNNs）在各种图相关任务中表现出色。然而，它们的“黑盒”特性使得解释性成为一个显著挑战，现有的方法往往难以有效捕捉网络中节点间的复杂交互模式。
### Innovation
本文提出了一个名为GraphEXT的新颖可解释性框架，该框架利用合作博弈理论和社会外部性概念。GraphEXT通过将节点分组成联盟，将原始图分解为独立子图。通过将图结构作为外部性并采用带有外部性的Shapley值，GraphEXT量算了节点在节点迁移至不同联盟过程中对GNN预测边际贡献的重要性。与传统的基于Shapley值的方法主要关注节点属性相比，GraphEXT更加注重节点间的交互及其对GNN预测的影响。
### Conclusion
实验结果表明，GraphEXT在多种GNN架构上都优于现有基准方法，在解释性方面显著提升GNN模型的表现。
## 536. `cs.LG` - 增强学习加速气动外形优化 [PDF](https://arxiv.org/pdf/2507.17786), [HTML](https://arxiv.org/abs/2507.17786)
### Authors
Florian Sobieczky,Alfredo Lopez,Erika Dudkin,Christopher Lackner,Matthias Hochsteger,Bernhard Scheichl,Helmut Sobieczky
### Background
该研究介绍了一种基于强化学习（RL）的自适应优化算法，用于气动外形优化，重点关注降维。该方法通过让部分参数在优化过程中保持恒定，实现了降维效果，同时结合蒙特卡罗方法中的仿真实验，以加速优化过程。
### Innovation
该算法引入了一种基于代理的、演员-评论家策略评估的方法，并允许某些参数在优化过程中保持恒定。这种方法旨在通过局部参数优化变化来减少计算成本，并通过观察到的优化结果解释发现的极值在实现所需流场中的作用。该方法针对的是流体动力学中的简单问题，允许通过特征重要性评分进行解释。
### Conclusion
该方法通过局部参数优化变化和准确估计奖励与成本能够加速全局优化过程。研究强调了在参数邻域足够大且其估算结果准确的情况下，局部优化变化能够有效提高全局优化效率。
## 537. `cs.LG` - 非马尔可夫过程的傅里叶神经算子：逼近定理和实验 [PDF](https://arxiv.org/pdf/2507.17887), [HTML](https://arxiv.org/abs/2507.17887)
### Authors
Wonjae Lee,Taeyoung Kim,Hyungbin Park
### Background
本文介绍了一种基于算子的神经网络——镜像填充Fourier神经算子（MFNO），旨在学习随机系统的动力学。MFNO在标准Fourier神经算子（FNO）的基础上引入了镜像填充，能够处理非周期输入。理论分析基于Wong--Zakai型定理和各种逼近技术，证明了MFNO能够以任意精度逼近依赖路径的随机微分方程和分数布朗运动的Lipschitz变换。与LSTMs、TCNs和DeepONet等标准架构相比，MFNO表现出强大的分辨率泛化能力，同时在样本路径生成速度上明显快于经典数值方案。
### Innovation
本文创新性地提出了镜像填充Fourier神经算子（MFNO），扩展了标准Fourier神经算子的功能，使其能够处理非周期输入。理论分析和实验验证了MFNO在逼近非马尔可夫过程中的强大表现，特别是在分辨率泛化和样本路径生成速度方面。
### Conclusion
本文证明了MFNO能够以任意精度逼近依赖路径的随机微分方程和分数布朗运动的Lipschitz变换，还展示了其强大的分辨率泛化和样本路径生成速度快于经典数值方案的性能。
## 538. `cs.LG` - 借助深度学习的多孔 metamaterials 逆向设计 [PDF](https://arxiv.org/pdf/2507.17907), [HTML](https://arxiv.org/abs/2507.17907)
### Authors
Phu Thien Nguyen,Yousef Heider,Dennis M. Kochmann,Fadi Aldakheel
### Background
该研究的最终目标是使用基于深度学习的生成框架探索多孔 metamaterials 的逆向设计。特别是，通过开发一种称为 pVAE 的属性变分自编码器来生成具有定制液压特性的结构 metamaterials（如孔隙率和渗透率）。本文还利用格子 Boltzmann 方法生成有限多孔微观结构的内在渗透率张量数据，并使用卷积神经网络从底层方法预测有效液压特性，从而显著降低计算成本。研究在结构和水力特性探索方面使用两种数据集：人工合成多孔微观结构的合成数据集以及来自真正开放气泡的 CT 扫描图像数据集。
### Innovation
研究开发了一种基于深度学习的生成框架——属性变分自编码器（pVAE），结合变分自编码器（VAE）和回归器，用于生成具有定制液压特性的结构多孔材料。pVAE 在两种不同的数据集上进行训练：合成的多孔微观结构数据集及其基于 CT 扫描图像的真实多孔材料数据集。这种使用 CNN 训练模型的方法可以显著降低计算成本，同时从微观结构直接预测有效的水力特性。
### Conclusion
该研究通过引入深度学习辅助的方法，为多孔 metamaterials 的水力特性提供了新的逆向设计途径。研究通过分析和解释潜在空间的角色，说明了潜在空间在结构特性映射、插值和逆向设计中的重要性。该方法支持生成具有所需特性的新 metamaterials。此外，研究中的数据集和代码将被公开，以支持进一步的研究。
## 539. `cs.LG` - SETOL: 半经验学习理论 [PDF](https://arxiv.org/pdf/2507.17912), [HTML](https://arxiv.org/abs/2507.17912)
### Authors
Charles H Martin,Christopher Hinrichs
### Background
本文介绍了半经验学习理论（SETOL），该理论解释了最新人工神经网络（SOTA NN）的出色性能。此前的研究表明，重尾自正则化（HTSR）现象学理论中的某些指标可以预测预训练SOTA NN模型在测试时的准确率趋势，而无需访问测试或训练数据。本文采用统计力学、随机矩阵理论和量子化学等领域的技术对该理论进行了形式化的阐述，得到了新的理想的数学学习条件，并提出了一种新的度量标准ERG，其等价于应用威尔逊精确重整化群步骤。该理论已在简单的三层多层感知机（MLP）上进行测试，结果与关键理论假设高度一致。对于SOTA NN模型，本文展示了如何通过计算层权重矩阵的经验谱密度（ESD）并将其插入SETOL公式中估计已训练的NN的各层质量特性。此外，本文还考察了HTSR指标α和SETOL指标ERG在MLP和SOTA NN中的表现，发现它们表现出了良好的一致性。
### Innovation
引入了半经验学习理论（SETOL），该理论使用了统计力学、随机矩阵理论和量子化学等领域的技术来解释SOTA NN的性能。SETOL提出了一种新的度量标准ERG，等价于应用威尔逊精确重整化群步骤，并且可以通过计算层权重矩阵的经验谱密度（ESD）来估计训练NN的各层质量特性。
### Conclusion
SETOL在简单MLP和SOTA NN上展示了良好的理论假设一致性。通过计算层权重矩阵的经验谱密度（ESD）并将其插入SETOL公式中，可以估计出已训练的NN的各层质量特性。本文还展示了HTSR指标α和SETOL指标ERG在MLP和SOTA NN上的良好一致性。
## 540. `cs.CV` - A Survey of Deep Learning for Geometry Problem Solving [PDF](https://arxiv.org/pdf/2507.11936), [HTML](https://arxiv.org/abs/2507.11936)
### Authors
Jianzhe Ma,Wenxuan Wang,Qin Jin
### Background
几何问题解决是数学推理的一个关键领域，广泛应用于教育、人工智能的数学能力评估以及多模态能力评估。近年来，深度学习技术的飞速发展，尤其是多模态大型语言模型的兴起，引发了这一领域的研究热潮。
### Innovation
本文对深度学习在几何问题解决中的应用进行了全面概述，包括（i）几何问题解决中的相关任务综述；（ii）深度学习方法的彻底回顾；（iii）评估指标和方法的详细分析；（iv）当前挑战和未来探索方向的批判性讨论。
### Conclusion
本研究旨在为几何问题解决领域的深度学习提供一个全面而实用的参考，促进该领域进一步的发展。已创建一个在GitHub上不断更新的论文列表:this https URL.
## 541. `cs.LG` - 多模态细粒度推理在帖子质量评估中的应用 [PDF](https://arxiv.org/pdf/2507.17934), [HTML](https://arxiv.org/abs/2507.17934)
### Authors
Xiaoxu Guo,Siyan Liang,Yachao Cui,Juxiang Zhou,Lei Wang,Han Cao
### Background
准确评估帖子质量需要复杂的关联推理来捕捉主题与帖子之间的微妙关系。现有的研究存在三个主要局限性：(1) 将任务视为单模态分类，无法充分利用多模态线索和精细的质量区分；(2) 在深度多模态融合过程中引入噪声，导致误导性信号；(3) 缺乏捕捉相关性和全面性的复杂语义关系的能力。
### Innovation
本文提出了多模态细粒度主题-帖子关联推理（MFTRR）框架，该框架模仿人类的认知过程。MFTRR重新定义了帖子质量评估为一个排序任务，并结合了多模态数据以更好地捕捉质量差异。该框架包含了两个关键模块：局部-全局语义相关性推理模块和多级证据关联推理模块，以减少噪音并加强基于证据的推理。
### Conclusion
MFTRR在三个新构建的多模态主题-帖子数据集和公共的Lazada-Home数据集上进行了评估。实验结果表明，MFTRR显著优于最先进的基线方法，在Art History数据集上实现了高达9.52%的NDCG@3性能提升。
## 542. `cs.LG` - 基于最优传输的 Wasserstein GAN 降尺度方法提高降水感知真实性 [PDF](https://arxiv.org/pdf/2507.17798), [HTML](https://arxiv.org/abs/2507.17798)
### Authors
Kenta Shiraishi,Yuka Muto,Atsushi Okazaki,Shunji Kotsuki
### Background
高分辨率（HR）降水预测对于减少静止和局部严重降雨造成的损害至关重要；然而，使用过程驱动的数值天气预测模型进行HR降水预测仍然具有挑战性。现有的神经网络模型虽然能够生成相对真实的降水场，但通常依赖均方误差（MSE）损失函数进行训练，导致生成的降水场在视觉上和细节能方面有所限制。
### Innovation
本文提出了一种使用 Wasserstein生成对抗网络（WGAN）进行降水降尺度的方法，通过最优传输成本实现生成最优化的降水场。WGAN相比传统神经网络，虽然在一些传统评估指标上表现略低，但能生成更具有视觉真实感和细节能的降水场。此外，通过学习WGAN的判别器与人类感知真实性的良好相关性，可以更准确地评价和质量控制降水数据集。
### Conclusion
WGAN框架不仅在提高降水降尺度的感知真实感方面有显著效果，还提供了一种新的方法来评估和质量控制降水数据集。通过案例分析发现，判别器得分的巨大差异能够帮助识别WGAN输出的不真实性以及参考数据中的潜在伪影。
## 543. `cs.LG` - 负数据中的正分子设计：通过任务算术逆向思考 [PDF](https://arxiv.org/pdf/2507.17876), [HTML](https://arxiv.org/abs/2507.17876)
### Authors
Rıza Özçelik,Sarah de Ruiter,Francesca Grisoni
### Background
生成分子设计的一个固有瓶颈是可用的具有理想特性的化学分子（即，'积极'分子）稀缺。为了克服这一障碍，本文提出了分子任务算术：通过训练模型来学习'属性方向'而无需访问任何正向标记的数据，并且在相反的属性方向上移动模型以生成积极分子。
### Innovation
该方法通过利用大量但未标记的负向实例来训练模型，以学习'属性方向'，并生成积极分子，从而绕过了直接获得正向标记数据的限制。这种方法在20项事先无法预见的设计实验中生成了更多样化且成功的分子设计。
### Conclusion
分子任务算术能够在保持理想设计属性的同时增加设计的多样性，并且由于其简单性、数据效率和性能，有潜力成为开新颖分子设计的默认转移学习策略。
## 544. `cs.LG` - 公共-私人学习在分布偏移情况下的下界 [PDF](https://arxiv.org/pdf/2507.17895), [HTML](https://arxiv.org/abs/2507.17895)
### Authors
Amrith Setlur,Pratiksha Thaker,Jonathan Ullman
### Background
在实践中，最有效的差分隐私机器学习算法依赖于额外的据认为是公开的数据源。这种范式最有趣的情况是两个数据源的结合效果大于它们各自的总和。但是，在某些情况下，如均值估计，我们已经有强大的理论下限，显示当两个数据源具有相同的分布时，结合两个数据源并没有补充的价值。这项研究则扩展了已知的公共-私人学习下界，探索了两个数据源存在显著分布偏移的情况。
### Innovation
本文的结果适用于两个分布有不同的均值的高斯均值估计，以及两个分布参数不同的高斯线性回归。研究发现，当偏移较小时（相对于所需精度），公共数据或私人数据都必须足够丰富才能估计私人参数。相反，当偏移较大时，公共数据并无帮助。
### Conclusion
当偏移较小时，数据源必须足够丰富；当偏移较大时，公共数据没有实际益处。
## 545. `cs.LG` - 提高GeoAggregator的计算效率和可解释性 [PDF](https://arxiv.org/pdf/2507.17977), [HTML](https://arxiv.org/abs/2507.17977)
### Authors
Rui Deng,Ziqi Li,Mingshu Wang
### Background
准确建模和解释地理空间表格数据(GeoSpatial Tabular Data，GTD)对于理解地理空间现象及其潜在过程至关重要。最近的研究提出了一种基于Transformer的新型深度学习模型GeoAggregator（GA），并证明其性能优于其他统计和机器学习方法。
### Innovation
本文进一步改进了GA，首先开发了一条优化的管道来加速数据加载过程并简化GA的前向传递，以提高计算效率；其次，结合了基于GeoShapley框架的模型集成策略和后处理模型解释功能，以增强模型的解释能力。
### Conclusion
通过将改进的GA应用于合成数据集，验证了提出策略的功能性和效率。实验结果表明，改进后的实现相比原始实现提高了预测准确性和推理速度。此外，解释实验表明GA能够有效捕捉设计的合成数据集中的内在空间效应。完整的管道已经公开提供，供社区使用。
## 546. `cs.LG` - CoCAI：基于Copula的区间一致性异常识别方法在多变量时间序列中的应用 [PDF](https://arxiv.org/pdf/2507.17796), [HTML](https://arxiv.org/abs/2507.17796)
### Authors
Nicholas A. Pearson,Francesca Zanello,Davide Russo,Luca Bortolussi,Francesca Cairoli
### Background
在多变量时间序列分析中，准确的预测和可靠的异常检测是两个关键挑战。现有的方法可能无法同时满足这两个需求，特别是在依赖关系复杂、数据质量不高等情况下。
### Innovation
提出了一种新的框架，结合生成型人工智能和Copula基模型来解决多变量时间序列分析中的预测准确性和异常检测的鲁棒性问题。该模型通过扩散基模型捕捉数据中的复杂依赖关系，使用区间一致性预测技术校准模型输出，生成统计上有效的预测区域。然后，通过结合降维技术和Copula基建模来进行鲁棒异常检测，提供基于统计的异常得分。该框架还具有离线校准阶段，以减少部署过程中的开销并提供有理论依据的可操作结果。
### Conclusion
实验证明，CoCAI在准确预测目标序列数据和识别其中的异常段方面具有有效性。
## 547. `cs.LG` - 交通状态估计与预测中的机器遗忘技术 [PDF](https://arxiv.org/pdf/2507.17984), [HTML](https://arxiv.org/abs/2507.17984)
### Authors
Xin Wang,R. Tyrrell Rockafellar,Xuegang(Jeff)Ban
### Background
交通状态估计和预测(TSEP)依赖于包含敏感信息的数据源。尽管大数据促进了机器学习方法的重大突破，但也引发了隐私、网络安全和数据新鲜度的担忧。这些挑战可能削弱公众对智能交通系统的信任。最近的法规引入了‘被遗忘的权利’，允许用户请求从模型中删除他们的个人信息。然而，在这种系统中，仅从后端数据库中移除旧数据是不够的，因为机器学习模型能够记住旧数据。
### Innovation
本研究提出了一种新的学习范式——机器卸载TSEP（Machine Unlearning TSEP），允许训练好的TSEP模型有选择地忘记敏感、受到污染或过时的数据。通过赋予模型“卸载”能力，旨在增强基于数据的交通TSEP的信任度和可靠性。
### Conclusion
通过引入Machine Unlearning TSEP，本研究解决了交通状态估计和预测中的隐私、网络安全和数据新鲜度问题，提升了该系统整体的可靠性和用户信任度。
## 548. `cs.LG` - SIFOTL：一种原则性的统计指导下的忠实优化方法用于表格学习 [PDF](https://arxiv.org/pdf/2507.17979), [HTML](https://arxiv.org/abs/2507.17979)
### Authors
Shubham Mohole,Sainyam Galhotra
### Background
在分析和决策支持系统中，特别是针对医疗保健领域的系统，识别驱动数据转换的因素是一项重大挑战。隐私规则限制了数据访问，复杂过程中的噪音妨碍了分析。这一挑战使得现有的分析方法要么忽略噪音，要么需要完整的数据访问才能利用语言模型，从而无法很好地解决这两个问题。因此，需要一种既能提取隐私合规的数据摘要统计信息，又能利用统计信息剔除噪音的方法，同时也能够识别出由噪音和干预信号共同作用导致的数据转换差异原因。为了应对这一挑战，该研究提出了SIFOTL（Statistically-Informed Fidelity-Optimization Method for Tabular Learning）方法。
### Innovation
SIFOTL提出了创新的方法，包括(i) 从隐私合规的角度提取数据总结统计信息，(ii) 使用双XGBoost模型在语言模型的帮助下分离干预信号和噪音，(iii) 通过帕累托加权决策树结合XGBoost的输出来识别有解释意义的负责数据转换的段落。这种方法不仅能够规避隐私问题，还能显著提高分析准确性，克服了现有方法在忽略噪音或需要全数据访问的问题。SIFOTL在实际应用中表现出了强大的效果，特别是在识别数据转换来源方面。
### Conclusion
SIFOTL提供了一种可解释的、注重隐私的方法，该方法在存在观测噪声的情况下仍然能够稳健地保持高F1分数，证明了其在医疗保健、健康记录数据等领域应用的有效性。与先前的分析方法相比，SIFOTL在识别段落接收补贴方面取得了显著的性能提升，达到了0.85的F1分数，远超BigQuery贡献分析和统计检验的水平。
## 549. `cs.LG` - 高效GRPO训练大型推理模型的预测缩放定律 [PDF](https://arxiv.org/pdf/2507.18014), [HTML](https://arxiv.org/abs/2507.18014)
### Authors
Datta Nimmaturi,Vaishnavi Bhargava,Rajat Ghosh,Johnu George,Debojyoti Dutta
### Background
大规模语言模型（LLMs）用于推理任务的微调通过强化学习方法（如Group Relative Policy OptimizationGRPO）进行，计算成本较高。因此，迫切需要一个能够预测训练动态并优化资源使用的方法，以提高效率并减少计算需求，同时保持性能不受影响。
### Innovation
提出了一种预测性框架，旨在预测训练动态并优化资源分配，基于模型大小、初始性能和训练进度，得出了一条经验缩放定律，预测了奖励轨迹，并确定了训练的三个一致阶段：缓慢开始、快速改进、平台期。研究发现，超过一定 epoch 数量的训练可能不会带来性能上的提升，因此可以通过提前停止训练来显著减少计算量而不会牺牲性能。这种方法适用于不同类型的语言模型，为基于GRPO的方法提供了一条实用的高效指导原则。
### Conclusion
通过实验，基于模型类型和训练进展，得到了经验缩放定律，找到了训练过程中的三个主要阶段，并表明可以通过提前停止训练大量节省计算资源而不影响模型性能。
## 550. `cs.LG` - C-AAE: 压缩匿名自动编码器在医疗传感流中为保留隐私的活动识别 [PDF](https://arxiv.org/pdf/2507.18072), [HTML](https://arxiv.org/abs/2507.18072)
### Authors
Ryusei Fujimoto,Yugo Nakamura,Yutaka Arakawa
### Background
可穿戴加速度计和陀螺仪能够捕捉精细的行为模式，这些模式可能被用于重新识别用户，因此在健康护理应用中保护隐私是至关重要的。作者指出，传统的自动编码器（AAE）虽然能够匿名化用户数据，但并没有进一步通过差异编码去减小数据量，这限制了其在实际应用中的有效隐私保护能力。因此，需要一种新方法来平衡隐私保护和实用性的需求，特别是在持续的基于传感器的活动识别应用场景下。
### Innovation
作者提出了一种压缩匿名自动编码器（C-AAE），它结合了匿名自动编码器（AAE）和自适应差分脉冲编码调制（ADPCM）。AAE首先将原始传感器数据投影到一个保有活动相关信息但去除身份信特征的潜在空间。ADPCM则进一步以差异编码方式对这个潜在流进行编码，从而进一步屏蔽剩余的隐私信息并降低数据量。结果显示，C-AAE相较于单独使用AAE将用户重新识别准确率降低10-15个百分点，并能保持活动识别的准确性在未保护基线的5个百分点以内，同时将数据量减少了约75%，大大降低了传输和存储成本。这些结果表明，C-AAE为在保护隐私的同时保持实用性的健康护理应用场景提供了实际方案。
### Conclusion
通过引入C-AAE，研究发现可以有效降低用户重新识别的风险并保持认可度与基准线接近，同时大幅减少数据量。这种方法在一个具体的持续医疗服务应用背景中展示了平衡隐私保护与实用性的潜力。
## 551. `cs.LG` - Squeeze10-LLM: 利用分阶段混合精度量化方法将LLMs的权重压缩10倍 [PDF](https://arxiv.org/pdf/2507.18073), [HTML](https://arxiv.org/abs/2507.18073)
### Authors
Qingcheng Zhu,Yangyang Ren,Linlin Yang,Mingbao Lin,Yanjing Li,Sheng Xu,Zichao Feng,Haodong Zhu,Yuguang Yang,Juan Zhang,Runqi Wang,Baochang Zhang
### Background
部署大规模语言模型(LLMs)具有挑战性，因为它们拥有庞大的参数数量和高计算成本。超低比特量化可以显著减少存储需求并加快推理速度，但极端压缩（即 mean bit-width <= 2）通常会导致严重的性能下降。
### Innovation
提出了一种分阶段混合精度后训练量化（PTQ）框架Squeeze10-LLM，通过精确量化80%的权重为1位，20%的权重为4位，实现了平均1.6位/权重。引入了两项关键创新：1) Post-Binarization Activation Robustness (PBAR)：一种改进的权重显著性度量，考虑了量化对激活的影响，提升了在低比特设置中的准确性；2) Full Information Activation Supervision (FIAS)：在量化过程中保留全部激活信息的策略，以减少逐层累积的误差传播。实验表明，Squeeze10-LLM 在子2比特权重量化中取得了最先进的性能，准确率平均从43%提升到56%，远超现有PTQ方法。
### Conclusion
Squeeze10-LLM在六项零样本分类任务中实现了显著的性能改进，通过代码发布确保了研究成果的公开。
## 552. `cs.LG` - 利用辅助监督学习非硬标签类别的硬标签 [PDF](https://arxiv.org/pdf/2507.18098), [HTML](https://arxiv.org/abs/2507.18098)
### Authors
Kosuke Sugiyama,Masato Uchida
### Background
在由于观察成本或数据稀缺导致的有限训练数据场景中，强化每个实例关联的标签信息变得至关重要，以便构建高精度分类模型。在这种情况下，不仅可以获得硬标签，还有助于获得额外的监督信息，如硬标签的置信度。
### Innovation
提出了一种理论框架，将硬标签和额外监督视为概率分布，并通过它们的仿射组合构建软标签。理论分析表明，额外监督的最关键成分不是分配给硬标签的置信分数，而是非硬标签类别分布的信息。此外，证明了额外监督和混合系数在细化软标签方面起到了互补作用。理论上分析了额外监督和其混合系数如何影响误差上限的收敛速度和渐近值。通过实验证明，基于理论设计的额外监督可以提高分类准确性，即使在简单使用时也不例外。
### Conclusion
理论和实验证据表明，合理利用额外监督信息能够有效提升分类模型的性能，即使是在简单利用这些信息时也能显著提高分类精度。
## 553. `cs.LG` - 联邦学习在大规模云端机器人操作中的机遇与挑战 [PDF](https://arxiv.org/pdf/2507.17903), [HTML](https://arxiv.org/abs/2507.17903)
### Authors
Obaidullah Zaland,Chanh Nguyen,Florian T. Pokorny,Monowar Bhuyan
### Background
联邦学习（FL）是一种新兴的分布式机器学习范式，在这种范式下，模型的协作训练涉及设备的动态参与，以实现广泛的目标。相反，传统的机器学习通常需要数据位于本地进行训练，而FL通过利用众多用户设备来训练共享的全球模型，而无需共享私人数据。当前，由于机器人低延迟计算资源有限，机器人的操作能力受到限制，因此云机器人概念已经出现，使机器人应用能够利用云计算资源的灵活性和可靠性，有效地缓解了他们跨云边计算环境的需求。在这个分布式计算环境中，尤其是在云机器人操作场景中，FL提供了诸多优势但也带来了挑战。
### Innovation
本文提出了联邦学习在网络大规模云机器人操作中的机遇与挑战，并探讨了通过联邦学习模型在集中式或去中心化设置的设计和验证，以实现高效和可靠的大规模云机器人操作。
### Conclusion
本文分析了联邦学习在实现大规模云机器人操作中机遇与挑战，包括通过联邦学习模型在集中式或去中心化设置下的设计和验证如何提高操作效率和可靠性，认识到联邦学习在解决该领域问题上的潜在价值和挑战。
## 554. `cs.LG` - 强化学习中的策略破坏：基于大型语言模型和关键状态识别的对抗攻击 [PDF](https://arxiv.org/pdf/2507.18113), [HTML](https://arxiv.org/abs/2507.18113)
### Authors
Junyong Jiang,Buwei Tian,Chenxing Xu,Songze Li,Lu Dong
### Background
强化学习（RL）在机器人技术与自动驾驶等领域取得了显著成就，但设计用于误导RL系统的对抗攻击依然是一个挑战。现有方法通常依赖于修改环境或策略，限制了其实用性。本研究提出了一个对抗攻击方法，在不改变原有环境的情况下，通过引导环境中的现有代理使目标策略输出次优行为。
### Innovation
研究提出了一种奖励迭代优化框架，利用大型语言模型生成针对目标代理漏洞的特定对抗奖励，增强了引导目标代理进行次优决策的有效性。同时，设计了一种关键状态识别算法，以确定目标代理最脆弱的状态，从而显著降低受害代理的总体性能。实验结果表明，该方法在多种环境中的表现优于现有方法。
### Conclusion
该研究提出了一种利用大型语言模型和关键状态识别的对抗攻击方法，能够有效地向目标代理引入次优决策，实验结果验证了其优越性。
## 555. `cs.LG` - 在测试时最大化前缀置信度可高效提升数学推理能力 [PDF](https://arxiv.org/pdf/2507.18122), [HTML](https://arxiv.org/abs/2507.18122)
### Authors
Matthias Otth,Jonas Hübotter,Ido Hakimi,Andreas Krause
### Background
近期研究表明，语言模型可以通过自我优化提高自身预测的置信度，而不依赖于外部验证器或奖励信号。本研究探讨了语言模型在数学推理任务中测试时的可扩展性问题，即使用模型自身的置信度来选择最有希望的尝试。实验发现，仅继续最具希望的尝试，可以显著提升模型性能，且这种性能提升是通过模型前缀置信度来实现的。研究系统地在五个数学推理数据集上评估了前缀置信度的扩展，发现长度只有32个令牌的前缀置信度扩展比多数投票更优，且相对于BoN更不易受到长度偏差的影响。此外，还评估了测试时训练与前缀置信度的性能，结果显示测试时训练虽然优于基线模型，但并未超过前缀置信度扩展的效果
### Innovation
本研究提出了一种在数学推理任务中测试时最大化前缀置信度的方法，发现这种方法可以显著提高模型性能。更重要的是，仅使用32个令牌长度的前缀置信度扩展就实现了比多数投票更好的准确性和计算资源之间的权衡，并且比BoN更少受到长度偏差的影响。此外，还提出了一种测试时训练方法来进一步提升模型性能，但未提升前缀置信度扩展的效果
### Conclusion
前缀置信度扩展在数学推理任务中表现出色，尤其是在较短的前缀长度下。该方法不仅提升了模型的测试时性能，而且相对其他方法（如多数投票和BoN）具有优势。测试训练方法同样有效但并不是最佳选择。
## 556. `cs.LG` - 神经形态计算在自主系统中实现体现智能：当前趋势、挑战与未来方向 [PDF](https://arxiv.org/pdf/2507.18139), [HTML](https://arxiv.org/abs/2507.18139)
### Authors
Alberto Marchisio,Muhammad Shafique
### Background
跨领域（如机器人学、移动代理（例如无人机）和自动驾驶车辆）对智能、自适应和节能的自主系统的增长需求，推动了对神经形态计算的兴趣。神经形态方法通过借鉴生物神经系统，提供了增强自主平台感知、决策能力和反应性的有希望途径。本文回顾了神经形态算法、专用硬件和跨层优化策略的最新进展，尤其关注其实现于真实世界自主场景中的应用。特别关注事件驱动的动态视觉传感器及其在实现快速、高效感知方面的作用。讨论还强调通过将脉冲神经网络整合到自主系统架构中，提高能源效率、鲁棒性、适应性和可靠性的新方法。机器学习、机器人学、神经科学和神经形态工程的视角被综合考虑，以提供该领域的全面视图。最后，探讨了新兴趋势和开放挑战，特别是在实时决策、持续学习和安全可靠的自主系统开发方面的挑战，
### Innovation
通过将脉冲神经网络整合到自主系统架构中，提高自主系统的能源效率、鲁棒性、适应性和可靠性。综合了来自机器学习、机器人学、神经科学和神经形态工程的视角，提供了该领域的全面视图。介绍了新的方法，以通过结合脉冲神经网络提高系统的实时决策、持续学习和安全可靠性的能力，
### Conclusion
探讨了神经形态计算在自主系统中的应用趋势和面临的挑战，强调了实时决策、持续学习和安全可靠的自主系统开发中的关键议题。
## 557. `cs.LG` - 当图数据中存在噪声标签和类别不平衡问题时：基于LLM和伪标签的图增强方法 [PDF](https://arxiv.org/pdf/2507.18153), [HTML](https://arxiv.org/abs/2507.18153)
### Authors
Riting Xia,Rucong Wang,Yulin Liu,Anchen Li,Xueyan Liu,Yan Zhang
### Background
类不平衡的图节点分类是一个实际但未充分探索的研究问题。尽管最近有一些研究试图解决这个问题，但它们通常假设图数据标签是干净且可靠的。然而，在实际场景中，图标签经常含有噪声，这个假设经常不符合实际情况。因此，该研究旨在系统地调查如何在包含噪声标签的类不平衡图上进行鲁棒节点分类。
### Innovation
提出了一种名为GraphALP的新型图增强框架，结合了大型语言模型（LLMs）和伪标签技术。具体而言，通过设计基于LLM的过采样方法生成合成的少数节点，生成准确的少数节点以缓解类不平衡。进一步开发了动态加权伪标签方法以减少标签噪声比例，并引入了LLM引导的二次过采样机制以减轻伪标签导致的潜在类别分布偏斜。
### Conclusion
实验结果表明，GraphALP在含有噪声标签的类不平衡图上优于现有的最佳方法。
## 558. `cs.LG` - 深度神经网络中的自相似性分析 [PDF](https://arxiv.org/pdf/2507.17785), [HTML](https://arxiv.org/abs/2507.17785)
### Authors
Jingyi Ding,Chengwen Qi,Hongfei Wang,Jianshe Wu,Licheng Jiao,Yuwei Guo,Jian Gao
### Background
当前的研究发现，一些深度神经网络在特征表示或参数分布中表现出强烈的分层自相似性。然而，除了对不同训练阶段权重幂律分布如何影响模型性能进行了初步研究外，对于隐藏空间几何的自相似性如何影响模型权重优化，以及内部神经元的动态行为，尚未进行定量分析。
### Innovation
本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，用以研究不同隐藏层构建的特征网络的自相似性，并分析调整特征网络的自相似性程度如何提升深度神经网络的分类性能。该研究验证了三种网络架构（MLP架构、卷积网络和注意力架构）下，特征网络表现出的自相似程度随着不同模型架构而变化的现象，并指出在训练过程中对特征网络的自相似性施加约束可以显著提高自相似的深度神经网络（MLP架构和注意力架构）的表现。
### Conclusion
研究表明，特征网络在不同的模型架构中表现出不同的自相似程度。而在训练过程中通过嵌入对特征网络自相似性的约束，能将自相似的深度神经网络（MLP架构和注意力架构）的性能提高最多6个百分点。
## 559. `cs.LG` - 基于目标的轨迹预测以提高跨数据集泛化能力 [PDF](https://arxiv.org/pdf/2507.18196), [HTML](https://arxiv.org/abs/2507.18196)
### Authors
Daniel Grimm,Ahmed Abouelazm,J. Marius Zöllner
### Background
为了实现完全自动化驾驶，理解周围环境至关重要。特别地，预测其他交通参与者未来状态具有非平凡的挑战。当前最先进(Sota)模型，在实际数据集（例如Argoverse2和NuScenes）上训练时已显示出有希望的结果。然而，当这些模型部署到新的未见过区域时，表现会显著下降，表明模型缺乏泛化能力。
### Innovation
本文引入了一种新的图形神经网络(GNN)，利用交通参与者和矢量化道路网络组成的异质图。后者用于在多阶段方法中分类目标，即预测轨迹的终点，从而更好地泛化到未见过的场景。研究通过跨数据集评估（在Argoverse2上训练，在NuScenes上评估）展示了目标选择过程的有效性。
### Conclusion
本文通过提出基于目标的轨迹预测方法，成功地提高了模型在新的未见过场景中的泛化能力。
## 560. `cs.LG` - FedSA-GCL：一种基于个性化聚合及簇感知广播的半异步联邦图学习框架 [PDF](https://arxiv.org/pdf/2507.18219), [HTML](https://arxiv.org/abs/2507.18219)
### Authors
Zhongzheng Yuan,Lianshuai Guo,Xunkai Li,Yinlin Zhu,Wenyu Wang,Meixia Qu
### Background
联邦图学习（FGL）是一种分布式学习范式，可以在多个本地系统上进行了大规模子图的协作训练。然而，大多数现有的FGL方法依赖于同步通信，在实际部署中效率低下且不实用。当前的异步联邦学习（AFL）方法主要针对常规任务如图像分类和自然语言处理而设计，未考虑到图数据的独特拓扑属性。直接将这些方法应用于图学习可能导致全局模型中产生语义漂移和表示不一致。这些挑战需要新的解决方案来提升效率和模型的鲁棒性。
### Innovation
提出了一种称为FedSA-GCL的半异步联邦框架，该框架通过新颖的ClusterCast机制利用了客户端标签分布差异和图拓扑特性，从而实现高效的训练。FedSA-GCL在多个真实世界图数据集上的评估结果表明，该方法在鲁棒性和效率方面表现出色，比9个基准模型分别平均高出2.92%（使用Louvain算法）和3.4%（使用Metis算法）。
### Conclusion
FedSA-GCL方法通过结合图的拓扑特性和标签分布差异，在半异步联邦学习中实现了高效的训练和良好的鲁棒性，相较于现有的方法在多个基准测试中取得了明显的性能提升。
## 561. `cs.LG` - 基于百分位的深度强化学习和基于奖励的个性化在O-RAN中为延迟感知RAN切片 [PDF](https://arxiv.org/pdf/2507.18111), [HTML](https://arxiv.org/abs/2507.18111)
### Authors
Peyman Tehrani,Anas Alsoliman
### Background
本文探讨了在开放无线接入网(O-RAN)架构中实现无线接入网络(RAN)切片的挑战。研究聚焦于包含多个移动虚拟网络运营商(MVNOs)的网络，这些MVNOs希望在满足客户需求的概率延迟上限约束的同时，最小化物理资源块(PRBs)的使用。初始阶段，基于大数定律(大数定律)推导了一个奖励函数，并进行实际修改以适应现实世界的实验场景。
### Innovation
本文提出了一种基于百分位的延迟感知深度强化学习方法(PDA-DRL)，该方法通过减少38%的平均延迟，优于多种基线模型，包括为平均延迟约束优化的强化学习模型。此外，本文还解决了多个MVNOs之间模型权重共享问题，提出了基于奖励的个性化方法，这种方法优于传统的联邦平均方法以及依赖于 traffic 模型权重距离相似性的策略。
### Conclusion
本文提出的方法通过实验证明了能够有效地在满足客户端概率延迟约束的同时最大限度地减少PRB使用，并通过新的个性化技术增强了模型的性能。该研究在O-RAN环境中为RAN切片应用延迟感知技术提供了新的见解和解决方案。
## 562. `cs.LG` - Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods [PDF](https://arxiv.org/pdf/2507.18242), [HTML](https://arxiv.org/abs/2507.18242)
### Authors
Fabian Akkerman,Julien Ferry,Christian Artigues,Emmanuel Hebrard,Thibaut Vidal
### Background
尽管线性规划为基础的完全矫正增强方法在理论上具有吸引力，但它们在实际中的应用却相对有限。本文首次对六种线性规划（LP）增强形式进行了大规模实验研究，包括两种新颖的方法：NM-Boost 和 QRLP-Boost，这些方法在包括20个不同数据集的数据集上进行了评估。本文不仅考察了算法的准确性，还分析了模型的稀疏性、边距分布、任意时间性能以及超参数敏感性
### Innovation
研究引入了两种新的线性规划增强方法——NM-Boost 和 QRLP-Boost，并首次对六种线性规划增强形式进行大规模实验。实验结果表明，对于较浅的树结构，完全矫正方法的性能能够超过先进的启发式方法如 XGBoost 和 LightGBM，同时生成的模型更加稀疏。此外，研究还表明这些方法能够对预训练模型进行瘦身，而不会影响性能。同时，文章强调并指出了使用最优决策树的优缺点
### Conclusion
本文展示了线性规划为基础的增强方法在不同数据集上的表现，并强调了这些方法的独特优点，如稀疏性和性能优化能力。本文为这些方法的进一步研究和应用奠定了基础
## 563. `cs.LG` - Group Sequence Policy Optimization [PDF](https://arxiv.org/pdf/2507.18071), [HTML](https://arxiv.org/abs/2507.18071)
### Authors
Chujie Zheng,Shixuan Liu,Mingze Li,Xiong-Hui Chen,Bowen Yu,Chang Gao,Kai Dang,Yuqiong Liu,Rui Men,An Yang,Jingren Zhou,Junyang Lin
### Background
本文介绍了一种名为Group Sequence Policy Optimization (GSPO)的强化学习算法，用于训练大型语言模型。相比于之前采用令牌级别重要性比例的算法，GSPO基于序列似然性定义重要性比例，并进行序列级别裁剪、奖励及优化。
### Innovation
GSPO的创新之处在于它定义重要性比例基于序列似然性，而不是序列中的每个令牌。此外，该算法以序列级别进行裁剪、奖励和优化，显著提高了训练效率和性能，并稳定了Mixture-of-Experts (MoE)的强化学习训练。
### Conclusion
GSPO的这些优点有助于最新Qwen3模型的重大改进，也有简化RL基础设施设计的潜力。
## 564. `cs.LG` - 从种子到收获：利用AI增强人类创造力以对抗测试文本到图像模型 [PDF](https://arxiv.org/pdf/2507.17922), [HTML](https://arxiv.org/abs/2507.17922)
### Authors
Jessica Quaye,Charvi Rastogi,Alicia Parrish,Oana Inel,Minsuk Kahng,Lora Aroyo,Vijay Janapa Reddi
### Background
文本到图像（T2I）模型在多种应用中变得非常普遍，因此它们抵御对抗攻击的稳健评估变得至关重要。当前生成对抗提示的方法要么完全由人类手工制作，要么通过合成生成。手工制作的对抗提示数据集通常规模较小且文化与上下文的代表性不足。而合成生成的提示数据集规模较大，但通常缺乏人类手工制作提示的现实细节和创造性对抗策略。为结合人类和机器两种方法的优势，本文提出了一种名为Seed2Harvest的混合红队方法，用于指导扩展具有文化多样性的手工制作的对抗提示种子。这种方法确保生成的提示保留了人类提示的特点和攻击模式，同时保持了与人类提示相当的平均攻击成功率（0.31 NudeNet，0.36 SD NSFW，0.12 Q16）。扩展后的数据集在535个独特的地理地点和香农熵为7.48方面实现了更高的多样性，而原始数据集仅包括58个地点和香农熵为5.28。
### Innovation
提出了一种名为Seed2Harvest的混合红队方法，结合了人类制作和机器生成的优势，用于扩展具有文化多样性的手工制作对抗提示种子。这种方法使得生成的提示既保留了人类提示的特点和攻击模式，又保持了相对较高的平均攻击成功率，并且具有更高的多样性和更具挑战性的地理分布。
### Conclusion
本文证明了人类与机器合作的重要性，利用人类的创造力和机器的计算能力来实现全面、可扩展的红队测试，以持续评估T2I模型的安全性。
## 565. `cs.LG` - 自动监督的无结构网格自适应粗化与自动微分 [PDF](https://arxiv.org/pdf/2507.18297), [HTML](https://arxiv.org/abs/2507.18297)
### Authors
Sergei Shumilin,Alexander Ryabov,Nikolay Yavich,Evgeny Burnaev,Vladimir Vanovskiy
### Background
由于现代数值模拟的高计算负荷，对能够减少离散问题规模但又保持合理精度的方法的需求越来越强烈。本文中，我们基于可微物理的概念提出了一种新型算法，旨在细化无结构网格。我们采用k-均值聚类、自动微分和随机优化算法来实施这一过程。我们通过两个偏微分方程（PDE）——描述略具压缩性的流体在多孔介质中流动的线性抛物型方程和波动方程——来演示我们设计算法的性能。实验结果表明，与原始网格相比，在考虑的场景中，我们的方法可以将网格点数量减小到十分之一，同时在感兴趣点上保留了模拟能量的动力学特性
### Innovation
本文提出了一种基于可微物理概念的新颖算法，用于无结构网格的自适应粗化。借助k-均值聚类、自动微分和随机优化算法，该方法能够显著减少网格点数量，同时保持关键区域的动力学特性。该方法可应用于描述演化偏微分方程系统的任意模拟情境。
### Conclusion
研究表明，在所考虑的情境下，我们开发的方法能够将网格点数量最多减少10倍，并保持感兴趣点的动力学特性。这种方法可以广泛应用于描述演化偏微分方程系统的任意模拟，提供了提高计算效率的同时保持精度的有效途径。
## 566. `cs.LG` - 针对Android恶意软件检测的回归aware持续学习 [PDF](https://arxiv.org/pdf/2507.18313), [HTML](https://arxiv.org/abs/2507.18313)
### Authors
Daniele Ghiani,Daniele Angioni,Giorgio Piras,Angelo Sotgiu,Luca Minnei,Srishti Gupta,Maura Pintor,Fabio Roli,Battista Biggio
### Background
恶意软件演变迅速，促使基于机器学习(ML)的检测器不断适应变化。随着防病毒厂商每日处理成千上万的新型样本，数据集可能膨胀至数十亿个实例，使得全面重新训练变得不切实际。持续学习(CL)作为一种可扩展的替代方案涌现出来，它能够在无需完全访问数据的情况下进行增量更新，并减轻灾难性遗忘。然而，在这一背景下仍存在一个关键但未被充分关注的问题——安全回退。与通常泛化性能下降的遗忘现象不同，安全回退表现为在样本级别出现有害的预测变化，例如某些被检测出的恶意样本在模型更新后重新逃过了检测。虽然经常被忽视，但回退在安全关键应用中会带来严重风险，因为先前已检测到的威胁再次引入系统可能会破坏用户的整个更新过程的信任。
### Innovation
本研究在持续学习(CL)驱动的恶意软件检测器中提出了一个回归aware的形式化及量化方法，并且提出一种回归意识的惩罚机制以缓解这一问题。研究者将积极一致训练(PCT)适应到持续学习的环境中，以模型无关的方式保存先前的预测行为。实验结果表明，该方法在不同持续学习场景下有效降低了回退现象，同时保持了长期的检测性能。
### Conclusion
我们的方法有效地减少了不同持续学习场景下的回退情况，同时确保了长时间内的检测性能。这为提高持续学习环境下的恶意软件检测器的稳健性和可靠性提供了新的途径，特别是在安全关键的应用场景中更加重要。
## 567. `cs.LG` - ChronoSelect：通过动态时间记忆鲁棒处理有噪声标签的学习 [PDF](https://arxiv.org/pdf/2507.18183), [HTML](https://arxiv.org/abs/2507.18183)
### Authors
Jianchao Wang,Qingfeng Li,Pengcheng Zheng,Xiaorong Pu,Yazhou Ren
### Background
在使用实际数据集训练深度神经网络时，表现出噪声标签的问题会阻碍模型训练，可能导致过度参数化的模型过度拟合这些噪声标签，从而显著降低泛化性能。现有用于处理噪声标签（LNL）的方法虽然已经有了一定的进步，但它们无法利用学习过程中的丰富时间动态变化，只采用静态快照评估。
### Innovation
ChronoSelect 提出了一种新颖的框架，该框架包含创新的四阶段记忆架构，能够将预测历史压缩成紧凑的时间分布。独特的滑动更新机制结合可控衰减，每样本仅保留四个动态记忆单元，能够逐渐强调近期模式同时保留重要历史知识，从而通过时间轨迹分析和双分支一致性实现样本的精确三分类。
### Conclusion
理论保证证明了该机制在噪声条件下收敛性和稳定性。广泛的实验证明，ChronoSelect 在合成和实际基准测试中的性能达到最新前沿。
## 568. `cs.LG` - UrbanPulse: 跨城市深度学习框架实现超精细人口迁移预测 [PDF](https://arxiv.org/pdf/2507.17924), [HTML](https://arxiv.org/abs/2507.17924)
### Authors
Hongrong Yang,Markus Schlaepfer
### Background
准确的人口流动预测对于城市规划、交通运输管理和公共卫生至关重要。然而，现有方法存在关键局限性：传统模型依赖静态空间假设，深度学习模型在跨城市泛化方面表现不佳，大语言模型计算成本高且无法捕捉空间结构。许多方法通过聚集兴趣点（POI）或限制覆盖范围到子区域来牺牲分辨率，这限制了它们在城市范围内的实用性。
### Innovation
UrbanPulse 是一个可扩展的深度学习框架，通过将每个 POI 作为一个单独节点来提供超精细化的城市范围 OD 流预测。它结合了时间图卷积编码器和基于转换器的解码器来建模多尺度时空依赖关系。UrbanPulse 使用三阶段迁移学习策略：在大规模城市图上进行预训练、冷启动适应和强化学习。通过高效的迁移学习，UrbanPulse 为不同城市的高分辨率、AI 功能的城市预测提供了关键步骤。
### Conclusion
UrbanPulse 在超过 10300 万条清洗的 GPS 记录上实现了最先进的准确度和可扩展性。通过高效的迁移学习，UrbanPulse 为实际部署高分辨率的人工智能城市预测铺平了道路，适用于各种城市。
## 569. `cs.LG` - 在合作MARL中记住马尔可夫性质 [PDF](https://arxiv.org/pdf/2507.18333), [HTML](https://arxiv.org/abs/2507.18333)
### Authors
Kale-ab Abebe Tessera,Leonard Hinckeldey,Riccardo Zamboni,David Abel,Amos Storkey
### Background
在典型的分布式不完全可观测马尔可夫决策过程（Dec-POMDP）中，智能体需要同时考虑环境和其它智能体的行为。当前无模型的MARL算法主要通过简单的递归函数逼近器来处理基于部分信息推理其它智能体行为的挑战。研究者认为这种方法的实验证据与有效马尔可夫信号的恢复无关，而是与学习简单惯例有关。这些惯例能够绕过环境观察和记忆，但这些惯例在遇到非适应性智能体时会出现失效。
### Innovation
通过一个设计良好的案例研究，表明适配的智能体能够学习出脆弱的习惯，当与非适配智能体相互作用时就会失效。然而，当任务设计需要时，同样的模型能够学习到基于观察的策略，揭示出问题并非源自于学习模型的根本局限，而是源于基准设计的缺陷。另外，作者还提出现代MARL环境可能没有充分测试Dec-POMDP的核心假设，并因此提倡新的合作环境构建应该基于两个核心原则：1) 观测为背景的行为；2) 基于记忆推理解其他智能体的方法，以确保成功需要真正的技能，而不是脆弱的、相互适应的协议。
### Conclusion
为了改进MARL模型的真实性和有效性，改进标准设计以更准确地测试环境中的核心假设是一个关键方向。新型MARL环境应该基于两个要素：基于观察的行为和基于记忆的推理解析其他智能体的行为，确保任务的成功需要真正的技能而非脆弱的合作协议。
## 570. `cs.LG` - 低秩自适应物理信息化HyperDeepONets求解微分方程 [PDF](https://arxiv.org/pdf/2507.18346), [HTML](https://arxiv.org/abs/2507.18346)
### Authors
Etienne Zeudong,Elsa Cardoso-Bihlo,Alex Bihlo
### Background
HyperDeepONets在Lee, Cho和Hwang等人[ICLR, 2023]中被提出，作为一种操作学习的替代架构。在这种架构中，一个超网络生成DeepONet主网络的权重。虽然这种方法提高了表达能力，但由于需要大量的输出参数，它也带来了高内存和计算成本的挑战。本文在物理信息化的机器学习背景下，引入了PI-LoRA-HyperDeepONets，通过低秩适应（LoRA）技术减轻复杂性。这种方法在超网络的输出层权重矩阵中分解出两个较小的低秩矩阵，从而减少了可训练参数的数量，同时对主网络的权重引入额外正则化。在大量实验中，该方法在参数数量和预测准确性以及泛化能力方面表现优于标准的HyperDeepONets。
### Innovation
PI-LoRA-HyperDeepONets通过低秩适应技术分解超网络的输出层权重矩阵，将复杂度降至更低，同时减少可训练参数数量，并对主网络权重引入额外正则化。这在保持高表达能力的同时，降低了存储和计算成本，使得模型在物理信息化的机器学习中更具有实际应用价值。
### Conclusion
PI-LoRA-HyperDeepONets在解微分方程的实验中表现出高达70%的参数减少，并在预测精度和泛化能力方面持续优于标准HyperDeepONets。
## 571. `cs.LG` - 利用数据增强和孪生学习进行预测过程监控 [PDF](https://arxiv.org/pdf/2507.18293), [HTML](https://arxiv.org/abs/2507.18293)
### Authors
Sjoerd van Straten,Alessandro Padella,Marwan Hassani
### Background
Predictive Process Monitoring (PPM) 允许根据事件日志预测正在进行的业务流程实例的未来事件或结果。然而，基于深度学习的PPM方法往往由于现实世界的事件日志的低变化性和小规模而受到限制。
### Innovation
引入了 SiamSA-PPM，这是一种结合了 Siamese 学习与统计增强的新颖自监督学习框架，用于预测过程监控。该框架利用三种新型的统计依据变换方法，利用控制流语义和频繁的行为模式，生成真实且语义有效的新的轨迹变体。增强后的视图用于 Siamese 学习设置中，以学习可泛化的流程前缀表示，无需有标签的监督。实验结果表明，SiamSA-PPM 在后续活动和最终结果预测任务中达到了与顶级技术相当或更优的性能。
### Conclusion
我们的研究结果进一步表明，统计增强显著优于随机变换，并且提高了数据的变异性，突显了SiamSA-PPM 在过程预测中作为增强训练数据潜在方向的重要性。
## 572. `cs.LG` - 通过证据式知识蒸馏实现LLMs的有效不确定性 [PDF](https://arxiv.org/pdf/2507.18366), [HTML](https://arxiv.org/abs/2507.18366)
### Authors
Lakshmana Sri Harsha Nemani,P.K. Srijith,Tomasz Kuśmierczyk
### Background
标准大型语言模型（LLMs）对准确的不确定性量化的挑战促使了贝叶斯方法和基于聚类的方法的应用。然而，这些方法通常需要昂贵的采样计算，涉及多次前向传播以有效估计预测不确定性。
### Innovation
本文提出了一种新颖的方法，在不牺牲性能的情况下，使LLMs能够有效估计不确定性。具体而言，通过低秩适应（LoRA）微调长教模型，将原本需要多次前向传播的不确定性意识型教模型提炼成紧凑的学生模型，这些学生模型共享相同的架构。我们比较了两种不同的提炼策略：一种策略的学生使用传统的softmax输出，另一种策略的学生利用狄利克雷分布输出来显式地通过证据式学习建模不确定性。
### Conclusion
实验结果表明，这些学生模型可以达到与教模型相当或更好的预测和不确定性量化性能，同时仅需一个前向传播过程。据我们所知，这是首次通过证据式提炼在LLMs中实现即时和稳健的不确定性量化的演示。
## 573. `cs.LG` - Price方程揭示了算法学习和自然选择的普适力-度量-偏差定律 [PDF](https://arxiv.org/pdf/2507.18549), [HTML](https://arxiv.org/abs/2507.18549)
### Authors
Steven A. Frank
### Background
学习算法、优化方法和自然选择在表面上看似不同的领域，实际上共享一种共同的数学结构。通过使用Price方程进行简化表示，文章揭示了一种普适的力-度量-偏差（FMB）定律：Δθ = Mf + b + ξ。此外，Price方程展示了为何 Fisher 信息量、KL 散度和d'Alembert原理在学习动态中自然出现。
### Innovation
文章通过Price方程揭示了一种普适的FMB定律，将包括自然选择、贝叶斯更新、牛顿方法、随机梯度下降、随机Langevin动力学、Adam优化在内的多数算法视为同一基本过程的特例。这为不同学科理解、比较和设计学习算法提供了一个坚实的原理基础。这一框架使得研究者能够深刻理解学习动态中的各个组成部分及其相互关系，为跨学科的研究奠定了科学基础。
### Conclusion
揭示了学习算法和自然选择背后共有的数学结构，通过FMB定律统一了多种学习和选择过程。具体而言，揭示了这些过程中力、度量、偏差和噪声的各自作用，并强调了这一理论框架在学习算法设计和跨学科应用中的重要性。
## 574. `cs.LG` - 在未监测流域中利用多模型集合和蓄水库计算进行河流径流预测 [PDF](https://arxiv.org/pdf/2507.18423), [HTML](https://arxiv.org/abs/2507.18423)
### Authors
Mizuki Funato,Yohei Sawada
### Background
虽然准确的洪水预测和水资源管理至关重要，但许多地区缺乏足够的河流径流观测数据，限制了降雨径流分析的能力。尽管存在许多物理基础模型和机器学习模型，但在数据稀缺条件下实现高精度、可解释性和计算效率仍然是一个巨大挑战。
### Innovation
本文提出了一个名为HYdrological Prediction with multi-model Ensemble and Reservoir computing (HYPER)的新方法，它结合了多模型集合和蓄水库计算（RC）。该方法首先使用贝叶斯模型平均（BMA）对43个“未校准”的基于流域的概念性水文模型进行处理。通过线性回归训练的一种RC模型随后用于修正BMA输出的误差，确保高计算效率。对于未监测的流域，通过与监测流域的流域属性联系推断所需的BMA和RC权重。该方法在日本87个河流流域的数据集上进行了评估，在数据丰富的情况下，HYPER和基准LSTM的性能相当，但计算时间仅为LSTM的5%。在数据稀缺情况下，HYPER保持了稳健的表现且误差较小，而LSTM则表现显著下降。这表明，当有效大的模型集合组合并与基于机器学习的偏差校正一起使用时，单个概念性水文学模型不一定需要校准。
### Conclusion
HYPER提供了一种稳健、高效和可推广的径流预测解决方案，特别适用于未监测的流域，使其适用于广泛的不同地区。
## 575. `cs.LG` - 使用时间感知动态序列反转Transformer进行电池健康状态估算 [PDF](https://arxiv.org/pdf/2507.18320), [HTML](https://arxiv.org/abs/2507.18320)
### Authors
Janak M. Patel,Milad Ramezankhani,Anirudh Deodhar,Dagnachew Birru
### Background
过去十年中，电池供电的车辆和储能系统的快速发展使得电池健康监控变得至关重要。电池在这些系统中的效率和安全性方面起着关键作用，但由于反复充放电循环，电池会逐渐退化。这种退化会导致能源效率降低和潜在的过热问题，从而带来重大的安全风险。准确估计电池的健康状态（SoH）对于确保操作可靠性和安全性至关重要。现有的机器学习架构，如LSTMs、变压器和编码器模型，可以从放电循环数据中估计SoH。然而，这些模型在处理真实世界测量中的不规则性时表现不佳：放电读数通常在非均匀的时间间隔被记录，放电循环的持续时间也存在显著差异。大多数现有方法是从序列中提取特征，而不是处理整个序列，这会导致信息损失并影响准确性。
### Innovation
我们提出了一个新颖的架构：时间感知动态序列反转Transformer（TIDSIT）。TIDSIT结合了连续时间嵌入，有效地表示不规则采样数据，并通过填充序列和时间注意力机制来管理可变长度输入，无需丢弃序列信息。在NASA电池退化数据集上的实验结果表明，TIDSIT在预测误差上显著优于现有的模型，预测误差减少了50%以上，并且SoH预测误差保持在0.58%以下。此外，该架构具有广泛的适用性，并在涉及不规则时序数据的健康监控任务中展现出潜在的应用前景。
### Conclusion
本文提出了一种新的时间感知动态序列反转Transformer（TIDSIT）架构，以提高电池健康状态预测的准确性。实验结果表明，TIDSIT能够显著降低预测误差，且广泛适用于其他涉及不规则时序数据的健康监测任务。
## 576. `cs.LG` - C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation [PDF](https://arxiv.org/pdf/2507.18533), [HTML](https://arxiv.org/abs/2507.18533)
### Authors
Magnus Bengtsson,Kenneth Östberg
### Background
介绍了C2G-KD，一种无数据的知识蒸馏框架。在这种方法中，通过冻结的教师模型和从主成分分析（PCA）中衍生出的几何约束，训练一个条件生成器来生成合成样本。生成器从未观察到真实训练数据，而是通过综合语义和结构损失来学习激活教师的输出。这种方法通过限制生成样本位于仅使用两个真实样本估计的类内PCA子空间中，以保留拓扑一致性和多样性。实验表明，即使在非常少量的类结构下，仍然可以有效进行有意义的合成训练管道。
### Innovation
创新在于C2G-KD框架通过条件生成器和几何约束生成合成样本，不需要实际的数据。生成器依赖于语义和结构损失来激活教师网络的输出，同时通过PCA估计的类内子空间来保持样本的一致性和多样性。这种方法能够在极少量真实数据的情况下，仍能提供有用的合成训练数据来支持知识蒸馏过程。
### Conclusion
实验结果表明，即使在一个类别的训练样本很少的条件下，仅两个样本就能提供足够信息来构建有效的合成训练样本，从而促进知识蒸馏过程。
## 577. `cs.LG` - GLANCE: 基于逻辑注意力网络与聚类增强的异质图表示学习 [PDF](https://arxiv.org/pdf/2507.18521), [HTML](https://arxiv.org/abs/2507.18521)
### Authors
Zhongtian Sun,Anoushka Harit,Alexandra Cristea,Christl A. Donnelly,Pietro Liò
### Background
Graph Neural Networks (GNNs)在处理图结构数据方面已经取得显著成功，但在异质图（其中连接的节点在特征或类别标签上有所不同）上表现不佳。这一局限性源于不加区别的邻居聚合和对高级结构模式的不足考虑。这项工作旨在通过提出GLANCE框架（Graph Logic Attention Network with Cluster Enhancement），综合逻辑引导的推理、动态图精简和自适应聚类，来增强图表示学习。GLANCE结合了逻辑层以提供可解释和结构化的嵌入，基于多头注意力的边剪枝以去除图结构噪音以及聚类机制以捕捉全局模式。
### Innovation
GLANCE框架整合了逻辑引导的推理、动态图精简和自适应聚类，这些新的组件旨在解决现有GNN在异质图上的局限性。特别地，逻辑层提供了可解释的和结构化的嵌入，基于多头注意力的边剪枝有助于去除图结构的噪音，而聚类机制则有助于捕捉全局模式。通过实验，GLANCE在Cornell, Texas, and Wisconsin这些基准数据集上展现了具有竞争力的性能，为异质图的表示学习提供了稳健且可解释的解决方案。
### Conclusion
GLANCE是一个轻量级、可适应地且特别针对异质图挑战的框架，在异质图的表示学习领域提供了新的见解和解决方案。
## 578. `cs.LG` - 线性内存SE(2)不变注意机制 [PDF](https://arxiv.org/pdf/2507.18597), [HTML](https://arxiv.org/abs/2507.18597)
### Authors
Ethan Pronovost,Neha Boloor,Peter Schleede,Noureldin Hendy,Andres Morales,Nicholas Roy
### Background
在自主驾驶相关学习任务如运动预测、多agents仿真和规划中，处理空间数据是个关键组成部分。以往的研究已经表明，使用SE(2)不变的网络架构，仅考虑对象间的相对姿态（如其他agents、场景特征如车道）可以提供很大价值。然而，这些方法需要显式地计算对象对之间的所有相对姿态，因此需要二次的记忆空间。
### Innovation
本文提出了一种线性内存的SE(2)不变的缩放点积注意力机制，其所需记忆空间线性地依赖于场景中对象的数量。该SE(2)不变的变压器架构拥有与大型语言模型近年来所受益的相同缩放特性。实验结果表明，我们的方法既便于实现又能提升性能，相比非SE(2)不变架构有更好的表现.
### Conclusion
我们提出的SE(2)不变的缩放点积注意力机制在保持相同训练复杂度的同时显著减少了内存使用，适用于大规模自主驾驶任务中的空间数据处理。
## 579. `cs.LG` - 使用分层条件扩散模型揭开蛋白质生成的神秘面纱 [PDF](https://arxiv.org/pdf/2507.18603), [HTML](https://arxiv.org/abs/2507.18603)
### Authors
Zinan Ling,Yi Shi,Da Yan,Yang Zhou,Bo Hui
### Background
蛋白质生成在生物学应用中至关重要。最近，条件扩散模型在蛋白质生成任务上取得了显著的实际性能，然而在从头设计蛋白质（尤其是使用条件扩散模型时）可靠生成蛋白质仍然是一个开放的研究问题。蛋白质的功能由多层次结构决定，因此需要同时整合基于序列和结构的信息来进行高效的端到端蛋白质设计，指导特定功能的实现。在此背景下，研究提出了一种新的多层次条件扩散模型，该模型能同时生成不同层次的表示，有效建模不同层次之间的固有层次关系，生成蛋白质的高效且区分性的表示。为了评估蛋白质生成的质量，提出了一种新的信噪比评价指标——Protein-MMD，能够同时捕捉真实和生成蛋白质序列的分布相似性和功能相似性，确保条件一致性。
### Innovation
研究提出了一种新的多层次条件扩散模型，该模型能同时生成不同层次的表示，有效建模不同层次之间的固有层次关系，生成蛋白质的高效且区分性的表示。此外，还提出了一种新的信噪比评价指标——Protein-MMD，能够同时捕捉真实和生成蛋白质序列的分布相似性和功能相似性，确保条件一致性。这种新的评价指标在蛋白质生成任务上能够提供可靠的评估。
### Conclusion
实验结果表明，提出的生成框架和评价指标在条件蛋白质生成任务中有效。
## 580. `cs.LG` - 全面综述智能农业中扩散模型的发展、应用与挑战 [PDF](https://arxiv.org/pdf/2507.18376), [HTML](https://arxiv.org/abs/2507.18376)
### Authors
Xing Hua,Haodong Chen,Qianqian Duan,Danfeng Hong,Ruijiao Li,Huiliang Shang,Linghua Jiang,Haima Yang,Dawei Zhang
### Background
全球人口增加和农用地资源变得相对稀缺，使得智能农业和精准农业成为未来农业发展的关键方向。人工智能（AI）技术，尤其是深度学习模型，已经被广泛应用于作物监控和病虫害检测等领域。作为新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感领域显示出显著的潜力。与传统生成对抗网络（GANs）相比，扩散模型在训练稳定性和生成质量方面表现更佳，有效解决了农业数据缺乏和图像样本不平衡的问题。
### Innovation
本文综述了扩散模型在智能农业中的最新应用进展，强调了其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的潜在应用。实验证明，扩散模型在数据增强、图像生成和去噪方面的模型准确性和鲁棒性得到了显著提升，特别是在复杂环境中表现尤为突出。
### Conclusion
尽管扩散模型在计算效率和泛化能力方面仍存在挑战，但随着技术的进步，其在智能和精准农业中的作用预计将越来越重要。扩散模型将为全球农业的可持续发展提供有力支持。
## 581. `cs.LG` - 在强化学习中稳健表示的再审视：改进的闭合同步度量 [PDF](https://arxiv.org/pdf/2507.18519), [HTML](https://arxiv.org/abs/2507.18519)
### Authors
Leiji Zhang,Zeyu Wang,Xin Li,Yao-Hui Li
### Background
闭合同步度量一直被视为一种有效的控制相关表示学习技术，在多种强化学习任务中得到了广泛应用。然而，本文指出了两种传统闭合同步度量的主要问题：1) 对某些独特场景表示不足；2) 在递归更新过程中对奖励差异和后续状态的预设权重依赖。这些问题分别源于对奖励差异定义的不精确，以及忽视了在不同训练阶段和任务设置中对奖励差异和后续状态差异的差异性重要性。
### Innovation
本文通过引入一种状态-动作对的度量，提出了一种改进的闭合同步度量。这种新方法提供了对奖励差异更精确的定义，并引入了带有自适应系数的新更新运算符。此外，本文还提供了我们提出的度量及其增强表示特异性的收敛性理论保证，并通过在两个代表性基准（DeepMind Control和Meta-World）上进行广泛的实验，证明了这种方法的有效性。
### Conclusion
我们提出了一个改进的闭合同步度量，它在理论上保证了收敛性，并通过实验展示了其在多种强化学习任务中的有效性。
## 582. `cs.LG` - 超越内部数据：构建公平性测试的完整数据集 [PDF](https://arxiv.org/pdf/2507.18561), [HTML](https://arxiv.org/abs/2507.18561)
### Authors
Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber
### Background
随着人工智能在高风险领域和决策中的普及，测试潜在危害和偏见变得至关重要。全球对AI的监管越来越注重公平性和充分的测试，甚至有法规要求进行独立偏见审计。然而，获取公平性测试所需的完整数据仍是一项重大挑战。特别是在工业环境中，法律和隐私问题限制了收集用于评估群体差异的 demographics 数据，而审计人员也面临获得数据的实际和文化挑战。此外，内部历史数据往往不足以识别现实世界的偏见。本文关注在无法获得完整数据（包括demographics）的情况下评估分类器的公平性。研究表明，可以通过使用相互重叠的独立数据集来生成包含demographics信息且能准确反映受保护属性和模型特征之间关系的合成数据，通过与真实数据进行比较来验证合成数据的准确性，并实验证明，基于这种合成数据进行公平性测试得到的指标与基于真实数据的一致。
### Innovation
本文提出了一种方法，通过利用相互重叠的独立数据集，结合人工智能技术生成一个包含demographics信息且能准确反映受保护属性和模型特征之间关系的合成数据集。这种方法能够在缺乏完整数据的情况下进行公平性测试，提供了一个克服实际情况数据稀缺性的解决方案，并为独立和独立于模型的公平性评估提供了可能。
### Conclusion
本文提供了克服现实世界数据匮乏问题以进行公平性测试的方法，能够为缺乏真实数据的场景下提供一种可行的独立和独立于模型的方式进行公平性评估，有助于实现公平性审计的目标。
## 583. `cs.LG` - 基于图书馆优化机制的非线性动力学稀疏识别：递归长期预测视角 [PDF](https://arxiv.org/pdf/2507.18220), [HTML](https://arxiv.org/abs/2507.18220)
### Authors
Ansei Yonezawa,Heisei Yonezawa,Shuichi Yahagi,Itsuro Kajiwara,Shinya Kijimoto,Hikaru Taniuchi,Kentaro Murakami
### Background
介绍基于测量数据发现动力系统支配方程的SINDy方法。然而，SINDy的一个主要挑战在于如何设计一个合适的图书馆（一组候选基函数），对于许多动力系统而言，并不是一件容易的事情。
### Innovation
提出了SINDy与图书馆优化机制相结合的方法（SINDy-LOM），该方法结合了稀疏回归技术和新型的图书馆学习策略。SINDy-LOM方法采用双层优化架构，内层通过数据驱动获取基函数的稀疏组合，外层优化基函数，从递归长期预测准确度（RLT）的角度。这种方法将图书馆设计重新定义为参数化的基函数优化。
### Conclusion
SINDy-LOM模型具有良好的解释性和实用性，因其产生了精简的模型。图书馆优化机制显著减轻了用户的负担。与传统SINDy方法相比，该方法提高了模型的可靠性，后者仅能确保一步预测准确性。通过在其上应用柴油发动机气流系统演示了提出的SINDy-LOM方法的有效性。这种方法对于复杂的工业系统具有重要意义。
## 584. `cs.LG` - ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding [PDF](https://arxiv.org/pdf/2507.17765), [HTML](https://arxiv.org/abs/2507.17765)
### Authors
Arindam Ghosh,Mark Fuhs,Bongjun Kim,Anurag Chowdhury,Monika Woszczyna
### Background
在应用场景中，基于角色的演讲者区分（如医生与病人、主持人与嘉宾等）比传统的演讲者区分（为演讲者赋予通用标签如演讲者-1、演讲者-2等）更有用。最近的端到端模型在联合ASR+SD框架下通过同步的ASR转录器和辅助的SD转录器来预测每个单词的演讲者，但这种框架尚未应用于基于角色的演讲者区分（RD）。
### Innovation
本文贡献了一个扩展的框架，其中包括：（1）通过强制对齐和交叉熵损失替代RNNT损失简化训练过程；（2）表明词预测和角色预测需要不同的上下文，因此设计了特定任务的预测器而不同于现有的共享预测器模型；（3）提出了一种利用角色区分后验活动影响ASR解码的方法，以减少短词删除错误。
### Conclusion
本文扩展了ASR+SD框架以应用于基于角色的演讲者区分，通过方法的关键改进，不仅简化了训练过程，还提高了ASR和SD的性能，特别是在处理短词汇错误方面取得了显著改进。
## 585. `cs.LG` - 简单随机隐藏权重的ReLU神经网络的神经 tangent 核和Fisher信息矩阵 [PDF](https://arxiv.org/pdf/2507.18555), [HTML](https://arxiv.org/abs/2507.18555)
### Authors
Jun'ichi Takeuchia,Yoshinari Takeishia,Noboru Muratab,Kazushi Mimurac,Ka Long Keith Hod,Hiroshi Nagaoka
### Background
该研究探讨了2层ReLU神经网络在随机隐藏权重情况下的属性，特别是神经切线核（NTK）和费舍尔信息矩阵（FIM）之间的关系。背景在于解释深度学习中这两类矩阵的作用以及它们之间的联系。
### Innovation
创新之处在于通过线性变换关系讨论了NTK和FIM之间的联系，并具体化了NTK的谱分解，同时获得了一个由2层神经网络表达的函数的近似公式。
### Conclusion
结论指出，通过研究NTK和FIM的内在联系，可以更好地理解2层ReLU神经网络的函数表示能力，且通过具体化的谱分解和近似公式能够更精确地分析这些网络的行为。
## 586. `cs.LG` - LLM量化中的几何学：GPTQ作为Babai的最近平面算法 [PDF](https://arxiv.org/pdf/2507.18553), [HTML](https://arxiv.org/abs/2507.18553)
### Authors
Jiale Chen,Torsten Hoefler,Dan Alistarh
### Background
将大型语言模型（LLMs）的权重从16位量化到较低位宽是将大规模变换器部署到更经济的加速器上的实际做法。GPTQ作为一种标准方法，在LLM规模上实现了单次后训练量化，尽管其机制被描述为一系列不切实际的代数更新，但缺乏几何意义或最坏情况下的保证。
### Innovation
作者展示了当从前到后的维度顺序执行GPTQ时，它与Babai的经典最近向量问题（CVP）在Hessian矩阵定义的格子上的最近平面算法在数学上是等价的。这一等价关系为GPTQ提供了理论支持，同时引入了格算法几十年的进步，从而为未来针对十亿参数模型的量化算法的设计打开了大门。
### Conclusion
这项研究将GPTQ置于坚实的理论基础之上，并通过引入格算法的进展，为未来量化算法的设计开辟了新的可能性。GPTQ的误差传播步骤获得了直观的几何解释，并且在无剪裁条件下继承了Babai算法的误差上界。
## 587. `cs.LG` - IOTA：一种激励式协调训练架构的技术入门 [PDF](https://arxiv.org/pdf/2507.17766), [HTML](https://arxiv.org/abs/2507.17766)
### Authors
Felix Quinque,Alan Aboudib,Szymon Fonau,Rodrigo Lopez Portillo Alcocer,Brian McCrindle,Steffen Cruz
### Background
2024年8月，Bittensor的子网9（SN9）展示了如何通过激励和无需许可的参与者来构建分布式网络，并让每个参与者预训练规模从7亿到140亿参数的大语言模型（LLMs），且超过已有基准。虽然这项工作证明了基于区块链的分散预训练是一种可行的方式，但SN9存在核心问题：（i）每个矿工需要在本地拟合整个模型；（ii）“赢家通吃”的奖励机制促使模型囤积。
### Innovation
我们提出了IOTA（激励式协调训练架构），该架构通过将SN9中的孤立竞争者转变为单一合作单位，解决了这些问题，使其能够任意扩大规模，同时公平奖励每一位贡献者。主要创新包括：1）数据并行和管道并行SWARM架构：调度器将模型层分配给异构矿工，并在它们之间流传输激活，使模型大小能够随着参与者数量的增加而扩展；2）具有精细和连续激励机制：验证者根据矿工的贡献量来分配代币发放比例；3）激活压缩：通过模型瓶颈降低激活通信带宽高达128倍，大幅提高训练速度；4）蝴蝶All-Reduce：矿工在常数带宽中平均不连续的参数切片，提供线性可扩展性、冗余性和内置的共谋检测能力；5）CLASP（贡献损失评估通过路径抽样）：一种公平的归属方案，根据贡献的边际效用分配信用，并在贡献相互依赖的管道中检测欺诈行为。
### Conclusion
IOTA架构通过解决SN9存在的问题，提供了一种有效的解决方案，展示了大规模分布式预训练的潜力。
## 588. `cs.LG` - 基于Tiny ML和IMU传感器的步态识别 [PDF](https://arxiv.org/pdf/2507.18627), [HTML](https://arxiv.org/abs/2507.18627)
### Authors
Jiahang Zhang,Mingtong Chen,Zhengbao Yang
### Background
本文介绍了使用Tiny Machine Learning (Tiny ML) 和 Inertial Measurement Unit (IMU) 传感器开发步态识别系统的项目。系统利用XIAO-nRF52840 Sense 微控制器和LSM6DS3 IMU传感器收集步态数据，并通过Edge Impulse对数据进行处理，从而训练出可以在微控制器上直接部署的实时活动识别模型。
### Innovation
项目的核心创新在于利用Tiny ML技术，在低功耗的条件下对步态数据进行实时分析。该系统通过采集和分析包括加速度和角速度在内的运动数据，识别四种不同的活动：行走、静止、上楼和下楼。此外，平台还具备异常检测功能，进一步提高了系统的鲁棒性。
### Conclusion
所提出的步态识别模型在测试数据集上的准确率达到超过80%，证明其能够有效地识别四种不同的活动。该系统通过集成Tiny ML，实现了低功耗操作，使其适用于由电池供电或能量采集设备。
## 589. `cs.LG` - PolyServe：大规模下的高效多SLO服务 [PDF](https://arxiv.org/pdf/2507.17769), [HTML](https://arxiv.org/abs/2507.17769)
### Authors
Kan Zhu,Haiyang Shi,Le Xu,Jiaxin Shan,Arvind Krishnamurthy,Baris Kasikci,Liguang Xie
### Background
大型语言模型（LLMs）的发展带动了大量LLM驱动的应用出现，这些应用对标记生成延迟有不同的要求。简单地将工作负载分为延迟敏感（LS）或尽力而为（BE）类别，未能充分考虑LS类别内部的差异性，可能导致用户体验和调度机会不佳。
### Innovation
提出PolyServe，一种大规模多SLO调度策略，通过将请求基于每标记延迟要求分类至多个组，然后调度每一组至服务器舰队的一部分来解决延迟敏感性问题。PolyServe允许低延迟要求的请求在高负载但仍然能满足延迟要求的服务器上共享高延迟要求的实例，以提高利用率。PolyServe使用剖析数据指导调度决策，并通过考虑请求等待时间的调度、动态分块以及连续分块预填充预测来管理尾部延迟。
### Conclusion
PolyServe 实现了1.23倍的好吞吐量，达到了最优好吞吐量的92.5%。
## 590. `cs.LG` - 几何深度学习架构在不同毒理学实验数据环境下的优化比较 [PDF](https://arxiv.org/pdf/2507.17775), [HTML](https://arxiv.org/abs/2507.17775)
### Authors
Alexander D. Kalian,Lennart Otte,Jaewook Lee,Emilio Benfenati,Jean-Lou C.M. Dorne,Claire Potter,Olivia J. Osborne,Miao Guo,Christer Hogstrand
### Background
几何深度学习是人工智能驱动的计算化学中的新兴技术，然而不同图神经网络（GNN）架构的特殊影响尚未得到充分探索。本文旨在比较应用于7个不同毒理学实验数据集的图形卷积网络（GCNs）、图形注意网络（GATs）和图形同构网络（GINs）的表现，这些数据集在数据量和终点方面各不相同，用于进行二元分类的实验激活。
### Innovation
本文通过预处理分子图、实现类平衡以及对所有数据集进行5折分层，进行了贝叶斯优化，对比了不同GNN模型在不同毒理学实验数据环境下的表现。结果发现，GINs在数据量较大的5种毒性实验中表现始终优于GCNs和GATs，但在数据稀缺的2种实验中，GATs的表现显著优于GCNs。这表明，GINs更适合数据丰富的环境，而GATs更适合数据稀缺的环境。进一步的分析发现，GCNs和GATs在优化状态下更接近，而GINs则表现出不同的特性，这一发现进一步证明了GINs的独特性作为一种GNN算法。
### Conclusion
不同GNN模型在毒理学评估实验中的表现差异显著，GINs在数据量较大的场景下表现更好，而GATs则适用于数据稀缺的场景。几何深度学习在毒理学数据分析中的应用具有广泛的潜力，不同的算法在不同的数据环境下表现出不同的优缺点。
## 591. `cs.LG` - VIBE: 视频输入的大脑编码器以建模fMRI响应 [PDF](https://arxiv.org/pdf/2507.17958), [HTML](https://arxiv.org/abs/2507.17958)
### Authors
Daniel Carlstrom Schad,Shrey Dixit,Janis Keck,Viktor Studenyak,Aleksandr Shpilevoi,Andrej Bicanski
### Background
该研究旨在通过将多模态视频、音频和文本特征结合起来，预测功能性磁共振成像（fMRI）活动。文章基于一个包含65小时电影数据的CNeuroMod数据集，并通过20个种子的集成训练了模型，以评估模型在预测fMRI活动方面的表现。
### Innovation
1. 提出了一种两阶段的Transformer网络（VIBE），该网络将多模态特征（视频、音频和文本）融合起来，进行预测。2. 使用旋转嵌入改进了时间解码过程。3. 该模型在训练和预测过程中使用了多种开放源代码模型的表示融合作为输入。
### Conclusion
VIBE模型在同构数据集中（Friends S07）达到了32.25的平均皮尔逊相关系数，并在六个异构数据集上达到了21.25的平均皮尔逊相关系数。之前的同济架构在同类数据集上的表现分别为0.3198和0.2096。VIBE模型在Algonauts 2025挑战赛的初步阶段获胜，并获得总体第二名的成绩。
## 592. `cs.LG` - Moving Out: 实体驱动的人机协作 [PDF](https://arxiv.org/pdf/2507.18623), [HTML](https://arxiv.org/abs/2507.18623)
### Authors
Xuhui Kang,Sung-Wook Lee,Haolin Liu,Yuyan Wang,Yen-Ling Kuo
### Background
实体代理（如机器人）适应物理动作和约束的能力对于有效与人类协作至关重要。物理约束增加了连续的状态-行动空间的复杂性和受限的动力学，导致需要考虑更多样化的交互模式和未见过的物理属性。目前缺乏针对这些物理环境挑战的广泛一致的人机协作基准。
### Innovation
本文提出了一种新的基准测试‘Moving Out’，涵盖了多种由物理属性和约束影响的合作模式，并设计了两个任务来评估模型适应不同人类行为和未见过的物理属性的能力。同时，提出了BASS（行为增强、模拟和选择）方法，以增强代理的多样性和对行动结果的理解。
### Conclusion
研究表明，与最先进的模型相比，BASS在人机协作中表现出色。项目页面可通过以下链接访问：this https URL_ai/
## 593. `cs.LG` - Galactic Center Excess 源的能量分布 [PDF](https://arxiv.org/pdf/2507.17804), [HTML](https://arxiv.org/abs/2507.17804)
### Authors
Florian List,Yujin Park,Nicholas L. Rodd,Eve Schoen,Florian Wolf
### Background
银河中心超余量（GCE）是费米γ射线太空望远镜发现的一个主要谜团。尽管它可能预示着暗物质湮灭的发现，但来自研究的数据表明，其空间结构更符合一系列暗淡点源的特征。先前的研究由于技术限制，仅依赖于空间信息进行点源假设的研究，而忽略了所有能帮助区分GCE和复杂、不确定的天体物理学辐射的光谱信息。
### Innovation
我们证明了一种神经网络辅助的模拟推理方法可以克服上述限制，从而将点源假设与空间和光谱数据相结合来挑战GCE的解释。新增加的重要信息是能量信息促使那些假定的点源变得极其暗淡，表明GCE要么真地是弥散的，要么由数量庞大的天体组成。在我们最好的背景模型中，超余量几乎与由暗物质预测的泊松辐射一致。如果超余量是由点源造成的，我们的中位预测是银河中心有约10^5个点源，或在90%的置信水平上有超过35,000个点源，这都比早期点源分析中性价因子众多的源更为庞大。
### Conclusion
如果GCE确实由普通点源组成，其数量大小显著超过先前研究的预期。这意味着GCE可能是弥散的，或是由大量小微弱源构成的，或者是暗物质湮灭的证据。
## 594. `cs.LG` - 在IoT环境中的联邦学习通信成本减少的缓存技术 [PDF](https://arxiv.org/pdf/2507.17772), [HTML](https://arxiv.org/abs/2507.17772)
### Authors
Ahmad Alhonainy(1),Praveen Rao(1) ((1) University of Missouri, USA)
### Background
联邦学习（FL）允许多个分布式设备共同训练一个共享模型而不集中数据，但通信成本仍然是一个主要瓶颈，尤其是在资源受限的环境中。
### Innovation
该论文提出了一种基于缓存策略的方法，包括FIFO、LRU和优先级基于策略，以减少不必要的模型更新传输。通过有选择性地传递重要的更新，该方法降低了带宽使用率同时保持了模型准确性。
### Conclusion
实验结果显示，采用这种智能缓存方法可以降低通信成本并最小化准确性损失。结果表明，智能缓存能提高可扩展性、内存效率，并支持边缘物联网网络中的可靠联邦学习，使其在智慧城市、医疗等领域敏感的延迟应用中更具实用性。
## 595. `cs.LG` - CM-UNet: 一种基于自我监督学习的X射线血管造影冠状动脉分割模型 [PDF](https://arxiv.org/pdf/2507.17779), [HTML](https://arxiv.org/abs/2507.17779)
### Authors
Camille Challier,Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Bernard De Bruyne,Denise Auberson,Olivier Müller,Stephane Fournier,Pascal Frossard,Emmanuel Abbé,Dorina Thanou
### Background
在临床实践中，冠状动脉的精确分割仍然是一项重大的挑战，这阻碍了对冠状动脉疾病的有效诊断和管理。由于缺乏大型且标注的数据集进行模型训练，这限制了自动化工具的发展，这些工具本可以辅助放射科医生。为了应对这个问题，我们引入了CM-UNet，它利用未标注数据的自我监督预训练和有限标注数据的迁移学习，能够实现准确的疾病检测，同时最大限度地减少需要大量人工标注的需求。
### Innovation
CM-UNet通过自我监督学习进行预训练，并结合有限标注数据的迁移学习，从而能够准确地检测疾病，同时最大限度地减少了对大量人工标注的需求。即使使用仅18张标注图像进行微调，其Dice分数相比没有预训练的基本模型下降了46.5%，而降低了15.2%。这表明自我监督学习可以提升分割性能并减少对大型数据集的依赖。这是第一个强调自我监督学习对从X射线血管造影图像中提高冠状动脉分割性能的重要性，并可能对未来临床实践中提高诊断准确性产生影响的研究。
### Conclusion
通过提高X射线血管造影图像的分割准确性，提出的该方法旨在改善临床工作流程，减轻放射科医生的工作负担，并加速疾病检测，最终促进更好的患者预后。其源代码已公开在此：this https URL。
## 596. `cs.LG` - 基于混合奖励驱动的强化学习的高效量子电路合成 [PDF](https://arxiv.org/pdf/2507.16641), [HTML](https://arxiv.org/abs/2507.16641)
### Authors
Sara Giordano,Kornikar Sen,Miguel A. Martin-Delgado
### Background
本研究旨在为在近似量子计算（NISQ）时代以及未来容错量子计算中，利用强化学习方法高效合成生成指定目标量子态的量子电路。这对于有效地管理量子状态空间的指数增长是一个核心挑战。
### Innovation
该研究引入了基于表格Q学习的强化学习框架，通过在离散量子状态空间中使用基于行动序列的方法来处理量子状态空间的维度问题。还提出了一种混合奖励机制，结合了静态领域知识奖励和动态可定制惩罚，以引导代理向目标状态前进并避免无效的电路结构，如门拥堵和重复状态访问。此外，通过利用稀疏矩阵表示和状态空间离散化，该方法能够在减少计算开销的同时实现高维环境的可扩展导航。
### Conclusion
在最多七个量子比特的图态准备任务上进行基准测试，算法能够一致地发现具有优化门计数和最小深度的电路。扩展到任意量子态的通用门集时，算法仍然能够生成最小深度电路，证明了该算法的稳健性和适应性。研究结果证实，基于强化学习的方法可以有效地探索复杂的量子态空间，并合成近最优的量子电路，为资源高效量子电路优化奠定了基础。
## 597. `cs.LG` - 基于概念的方法在语音障碍检测中的应用 [PDF](https://arxiv.org/pdf/2507.17799), [HTML](https://arxiv.org/abs/2507.17799)
### Authors
Davide Ghia,Gabriele Ciravegna,Alkis Koudounas,Marco Fantini,Erika Crosetti,Giovanni Succo,Tania Cerquitelli
### Background
语音障碍影响了大量的人群，通过自动化、非侵入性的技术进行诊断将大幅提高医疗水平，改善患者的生活质量。近期研究显示，特别是深度神经网络(DNN)，可以有效解决该任务。但由于其复杂性，这些模型的决策过程往往是不透明的，限制了它们在临床环境中的可信度。
### Innovation
本文探讨了一种基于可解释人工智能(XAI)的方法，旨在通过提供不同形式的解释来提高DNN的可解释性。具体来说，本文重点研究基于概念的概念瓶颈模型(CBM)和概念嵌入模型(CEM)，这些模型可实现与传统深度学习方法相当的性能，同时提供更透明和可解释的决策框架。
### Conclusion
这种基于概念的方法不仅保持了与传统深度学习方法相当的性能，还提供了一个更透明和可解释的决策系统，提高了在临床应用中的可信度。
## 598. `cs.LG` - 通过基于GenAI的图像合成促进AI皮肤病变分类器的公平性评估 [PDF](https://arxiv.org/pdf/2507.17860), [HTML](https://arxiv.org/abs/2507.17860)
### Authors
Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel
### Background
深度学习在边缘设备上的应用为皮肤癌筛查，尤其是黑素瘤的常规筛查带来了巨大的潜力。然而，技术带来的好处同时伴随着潜在的偏见风险，因此评估和改进系统的公平性至关重要。公平性评估的关键挑战在于确保评估数据集充分代表不同的个人信息（性别、年龄、种族）以及其他少数群体。
### Innovation
本研究利用了最先进的生成AI（GenAI）模型LightningDiT来评估公开可获得的黑素瘤分类器的公平性。研究结果表明，使用高度逼真的合成数据进行公平性评估是一个有希望的方向。然而，研究也指出，当用于评估的黑素瘤检测模型的训练数据与合成图像的数据集有所不同时，验证公平性变得困难。尽管如此，本研究提出的利用合成数据的方法为评估和改进医疗图像GenAI系统的公平性提供了新的途径。
### Conclusion
本研究提出了一种利用生成AI进行公平性评估的新方法，重点关注黑素瘤分类器。虽然合成数据用于评估公平性时存在局限性，但该方法提供了评估和提升医疗图像GenAI系统公平性的新途径。
## 599. `cs.LG` - 迈向数字病理学的鲁棒基础模型 [PDF](https://arxiv.org/pdf/2507.17845), [HTML](https://arxiv.org/abs/2507.17845)
### Authors
Jonah Kömen,Edwin D. de Jong,Julius Hense,Hannah Marienwald,Jonas Dippel,Philip Naumann,Eric Marcus,Lukas Ruff,Maximilian Alber,Jonas Teuwen,Frederick Klauschen,Klaus-Robert Müller
### Background
生物医学基础模型（FMs）正在迅速改变AI在医疗健康研究中的应用，并进入临床验证阶段。但这些模型易受学习非生物学技术特征的影响，包括手术/内窥镜技术、实验室程序和扫描硬件的变异性，这给临床应用带来了风险。本文首次系统研究了病理学FM对非生物学特征的鲁棒性，探讨了有限鲁棒性的后果，并提出了提高FM鲁棒性的框架。研究发现所有20种评估的FM在鲁棒性方面存在缺陷，且不同FM之间的鲁棒性差异显著。非鲁棒的FM表示可能导致重大诊断错误和临床失误，阻碍其安全临床应用。
### Innovation
本文提出了衡量FM鲁棒性的方法，说明了有限鲁棒性的后果，并提出了FM鲁棒化的方法框架。开发了PathoROB基准，包括三个新的鲁棒性指标和四个涵盖34家医疗机构的28个生物类别的数据集。研究结果显示，所有评估的20种FM在鲁棒性方面存在缺陷，并且不同FM之间的鲁棒性差异显著。非鲁棒的FM表示可能导致重大诊断错误和临床失误，阻碍其安全临床应用。使用更鲁棒的FM和事后鲁棒化显著减少了（但未完全消除）这类错误的风险。
### Conclusion
本研究确立了在临床应用前评估病理学FM鲁棒性的重要性，并表明未来FM开发必须将鲁棒性作为核心设计原则。PathoROB为评估跨生物医学领域鲁棒性提供了蓝图，指导FM改进工作，朝着更鲁棒、更具代表性和可临床应用的人工智能系统前进，优先考虑生物学信息而非技术伪影。
## 600. `cs.LG` - Sliding Window Informative Canonical Correlation Analysis [PDF](https://arxiv.org/pdf/2507.17921), [HTML](https://arxiv.org/abs/2507.17921)
### Authors
Arvind Prasadan
### Background
Canonical correlation analysis (CCA)是一种用于在两个数据集中找到相关特征集的技术。然而，传统的CCA方法通常用于批量数据处理，在流式数据设置下效率较低。因此，需要一种能够在流式数据中实时估计CCA成分的方法，即能够处理高维度数据，并提供实时性能保证。
### Innovation
本文提出了一种新的CCA的扩展方法，适用于流式数据设置，称为滑动窗口信息相关分析（SWICCA）。该方法利用流式主成分分析（PCA）算法作为后端，并结合一小段滑动样本窗口以实时估算CCA成分。这种方法不仅适用于高维度数据处理，还提供了实时性能保证，并通过数值模拟进行了性能验证。
### Conclusion
SWICCA方法适用于和可扩展到极高维度的数据，并通过实际数据示例证明了这一能力。
## 601. `cs.LG` - Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes [PDF](https://arxiv.org/pdf/2507.17893), [HTML](https://arxiv.org/abs/2507.17893)
### Authors
Milad Taghipour,Bane Vasic
### Background
本文探讨了将强化学习技术应用于基于比特翻转和寻找最优决策的线性块码译码过程，以增强其性能。通过将迭代译码过程映射到马尔可夫决策过程（MDPs），研究方法旨在减少MDPs中的状态数量，进而提高编码器的表现。此外，通过考虑码的自同构群来进一步改进编码器的性能，同时使用反馈机制提升现有高性能译码器的性能，有效降低了强化学习模块的复杂性。
### Innovation
1. 提出了将迭代译码过程映射到马尔可夫决策过程的方法，并设计了基于价值的深度Q网络（DQN）的行动列表译码器，显著提升了性能。2. 提出了一种通过学习码字周围的哈明球来减少MDPs中状态数量的截断的MDP方法。3. 提出了一种通用的基于强化学习的译码方案，适用于任何类型的代码，以提高译码器的性能。4. 通过利用码的自同构群进一步改善了编码器性能。5. 通过反馈机制，提高现有高性能译码器的性能，同时降低强化学习模块的复杂性
### Conclusion
本文展示了所提出的方法在二进制对称信道（BSC）下的低密度奇偶校验（LDPC）码中具有较高的效率，并提供了实验结果来验证这些方法的有效性。
## 602. `cs.LG` - 量子机器学习游乐场 [PDF](https://arxiv.org/pdf/2507.17931), [HTML](https://arxiv.org/abs/2507.17931)
### Authors
Pascal Debus,Sebastian Issel,Kilian Tscharke
### Background
本文介绍了一种创新的交互式可视化工具，旨在使量子机器学习(QML)算法易于理解。该工作受到了经典机器学习可视化工具（如TensorFlow Playground）的成功启发，并旨在填补专属于QML领域的可视化资源空白。文章概述了量子计算和经典机器学习领域相关的可视化比喻，发展了一种算法可视化概念，并设计了一个具体的实现，即交互式网页应用。通过结合所谓的数据重新上传万能量子分类器等经典可视化比喻，文章旨在降低量子计算的入门门槛，并鼓励该领域的进一步创新。附带的交互式应用程序是量子机器学习游乐场的第一个版本，旨在用于学习和探索QML模型
### Innovation
该工具通过结合经典和量子计算领域的可视化比喻，设计了一个交互式的网页应用，帮助降低量子计算的入门门槛。这是专为QML领域设计的首个交互式可视化工具
### Conclusion
通过这个交互式应用，旨在降低量子机器学习的入门门槛，促进QML研究领域的进一步创新和发展
## 603. `cs.LG` - MultiKernelBench: 多平台的内核生成基准 [PDF](https://arxiv.org/pdf/2507.17773), [HTML](https://arxiv.org/abs/2507.17773)
### Authors
Zhongzhen Wen,Yinghui Zhang,Zhong Li,Zhongxin Liu,Linna Xie,Tian Zhang
### Background
使用大规模语言模型（LLMs）自动生成深度学习（DL）内核作为一种减少编写高性能操作实现所需的手动工作和硬件专属专业知识的方法已经引起了人们的关注。然而，目前用来评估LLMs的基准测试任务在硬件支持、内核分类细化程度以及任务覆盖面方面存在局限。
### Innovation
介绍了MultiKernelBench，这是第一个跨多个平台的LLM基于DL内核生成的全面基准。它包含了285项任务分布在14个明确定义的内核类别中，并支持Nvidia GPU、Huawei NPU和Google TPU三种主要硬件平台。为了便于未来的扩展，设计了一种模块化的后端抽象层来解耦特定平台的逻辑，使其能够轻松集成新的硬件平台。还提出了一种简单但有效的类别感知一次性提示方法，以通过提供类别范例来提高生成质量。通过系统评估了七项最先进的LLMs，发现任务难度、对平台的普适性以及目标化提示策略的有效性方面的显著差异。
### Conclusion
MultiKernelBench全面且细致地评估了LLM在DL内核生成中的性能，揭示了任务难度、硬件平台适应性和提示策略的有效性方面的差异。该基准已公开发布，可以用于未来的研究和开发工作。
## 604. `cs.LG` - 多模态递归集成模型预测自然电影引起的脑部反应（Algonauts 2025） [PDF](https://arxiv.org/pdf/2507.17897), [HTML](https://arxiv.org/abs/2507.17897)
### Authors
Semih Eren,Deniz Kucukahmetler,Nico Scherf
### Background
准确预测大脑皮层对自然刺激的响应需要能整合视觉、听觉和语义信息的模型，并随时间进行整合。研究需要一个能将视频、音频和语言嵌入信息映射到在四名参与者观看近80小时电影时采集的大脑功能磁共振成像(fMRI)时间序列的系统。研究结果在Algonauts 2025挑战赛的排行榜上排名第三，表现卓越。
### Innovation
提出了一种分层次的多模态递归集成方法，其中包括专门的模态递归神经网络（RNN）编码时间动态，其隐藏状态会被融合并传给第二个递归层，然后通过轻量级的个体特定端输出1000个皮质区域的响应。训练使用复合均方误差-相关性损失函数以及从早期感觉区到晚期关联区逐渐转变重点的课程学习策略。此外，通过平均100个模型变体提升了系统的稳健性。该方法为未来多模态脑编码基准提供了简单可扩展的基础。
### Conclusion
最终系统在竞赛排行榜上取得了第三名的成绩，整体皮尔逊相关系数为0.2094，并获得了所有参与者中最高的单个皮质区域峰值得分（平均0.63），尤其是对于最具挑战性的参与者（参与者5）产生了显著的改进。此方法为未来多模态脑编码基准提供了一个简单、可扩展的基础。
## 605. `cs.LG` - 基于网格结构LoRA的零样本动态概念个性化 [PDF](https://arxiv.org/pdf/2507.17963), [HTML](https://arxiv.org/abs/2507.17963)
### Authors
Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman
### Background
最近，文本到视频生成技术已经实现了从文本和图像提示中生成高质量视频的能力。虽然现在可以个性化动态概念并捕捉个体特定的外观和运动，但现有的许多方法需要针对每个实例进行微调，这限制了其可扩展性。
### Innovation
本研究提出了一种基于网格结构的零样本框架，用于动态概念的个性化。该方法使用了2x2视频网格，用于输入和输出对的空间组织，进而能够训练轻量级的网格LoRA适配器，以在这些网格中实现编辑和组合。推理时，专门的网格填充模块可以完成部分观察布局，生成时间连贯且保持个体身份的输出。一旦训练完成，整个系统可以在单次前向传播中运行，并能在不进行测试时间优化的情况下推广到以前未见过的动态概念。
### Conclusion
广泛的实验证明，该方法在广泛的主题中能产生高质量且一致的结果，超越了已训练的概念和编辑情景。
## 606. `cs.LG` - Clo-HDnn：一种通过渐进搜索实现4.66 TFLOPS/W和3.78 TOPS/W的高效持续边缘学习加速器 [PDF](https://arxiv.org/pdf/2507.17953), [HTML](https://arxiv.org/abs/2507.17953)
### Authors
Chang Eun Song,Weihong Xu,Keming Fan,Soumil Jain,Gopabandhu Hota,Haichao Yang,Leo Liu,Kerem Akarvardar,Meng-Fan Chang,Carlos H. Diaz,Gert Cauwenberghs,Tajana Rosing,Mingu Kang
### Background
本文介绍了一种名为Clo-HDnn的边缘设备学习（ODL）加速器，它专为新兴的持续学习（CL）任务设计。该加速器结合了超维度计算（HDC）、低性价比Kronecker HD码编码器以及权重聚类特征提取（WCFE）技术，以优化准确性和效率。Clo-HDnn采用了无梯度的持续学习方法，能够高效地更新和存储以类超向量形式表示的知识，支持节能特征提取和部分查询超向量的编码比较，从而减少复杂性。
### Innovation
Clo-HDnn结合了超维度计算和渐进搜索技术，实现低能耗的持续学习加速。创新点在于通过无梯度持续学习提升能效，采用渐进搜索技术减少复杂度，支持简单的数据集跳过特征提取，并且通过编码和对比部分查询超向量进一步降低复杂性，实现了显著的能效提升。
### Conclusion
研究结果表明，Clo-HDnn相比现有的最佳ODL加速器，在能效上分别提升了7.77倍（单位Watt的能效）和4.85倍（单位Watt的能效），在边缘设备学习加速方面取得了卓越性能。
## 607. `cs.LG` - 多尺度神经PDE代理模型预测与降尺度：海洋 currents应用 [PDF](https://arxiv.org/pdf/2507.18067), [HTML](https://arxiv.org/abs/2507.18067)
### Authors
Abdessamad El-Kabid,Loubna Benabbou,Redouane Lguensat,Alex Hernández-García
### Background
准确建模受偏微分方程控制的物理系统是科学计算中的核心挑战。海洋学中，高分辨率的水流数据对于海岸管理、环境监测和航海安全至关重要。然而，现有卫星产品如Copernicus数据和全球海洋模型通常缺乏用于详细局部分析所需的分辨率。
### Innovation
本文提出了一种基于神经算子的监督深度学习框架，用于解决偏微分方程并提供任意分辨率的解决方案，并提出了降尺度模型对Copernicus海洋水流数据的应用。该方法可建模代理偏微分方程并预测任意分辨率下的解决方案，不受输入分辨率限制。
### Conclusion
本文评估了该模型在实际Copernicus海洋水流数据和合成纳维-斯托克斯模拟数据集上的表现。
## 608. `cs.LG` - 基于分子动力学模拟的高维有序参数空间分析的机器学习工作流：聚合物结晶的案例研究 [PDF](https://arxiv.org/pdf/2507.17980), [HTML](https://arxiv.org/abs/2507.17980)
### Authors
Elyar Tourani,Brian J. Edwards,Bamin Khomami
### Background
目前，通过分子模拟数据并在单一有序参数（OP）的预设截止点上定义核化或结晶区域来识别聚合物的结晶路径。然而，这种方法对截止点敏感，并且每个有序参数引入了系统性偏差。本研究提出了一种集成的机器学习工作流，利用原子分子动力学数据准确量化聚合物系统的结晶度。这种方法使用高维特征向量来代表每个原子，并通过低维度嵌入技术揭示原子环境内的潜在结构特征。随后通过无监督聚类确定了结晶和无定形原子，实现了高精度识别。
### Innovation
该研究提出了一个集成的机器学习工作流，利用低维度嵌入和无监督聚类来精确量化聚合物的结晶度，通过减少特征集证明了三个有序参数足以重建结晶标签。此外，研究定义了结晶指数(C-index)作为逻辑回归模型的结晶概率，并证明该模型在单个或少数几步计算结晶度时非常高效。最后，研究结果表明熵在早期核化中主导，对称性在后期增强。这提供了一种基于数据驱动的有序参数选择策略，并监测大规模聚合物模拟中的结构性转变的指标。
### Conclusion
该工作流为有序参数的选择提供了一种数据驱动的策略，并提供了一种监测大规模聚合物模拟中结构性转变的指标，可以实现高效的在线结晶度计算，并验证了熵和对称性在结晶过程中的作用参数随时间的变化。
## 609. `cs.LG` - 一对新的GloVe [PDF](https://arxiv.org/pdf/2507.18103), [HTML](https://arxiv.org/abs/2507.18103)
### Authors
Riley Carlson,John Bauer,Christopher D. Manning
### Background
2014年发布的原始GloVe模型已经被广泛使用并显示出良好的效果，然而语言和世界一直在演变，更新的模型可以更好地满足当前使用需求。另外，2014年的模型在数据版本和预处理细节方面没有详细记录，本次研究旨在通过详细记录新模型的数据版本和预处理方法来完善这一点。新模型基于Wikipedia、Gigaword和Dolma的一部分数据集进行训练。
### Innovation
研究人员训练了两种新的GloVe模型，使用了最新的数据集，更好地记录了数据版本和预处理细节。通过词汇比较、直接测试和命名实体识别任务等评估方法，验证了这些新模型在文化相关词汇包含、词类和相似性任务表现、以及处理时间依赖型命名实体识别（NER）数据集上的优越性。
### Conclusion
2024年的GloVe模型成功地包含了新的文化和语言相关的词汇，与传统的词类和相似性任务保持了相似的表现，并在处理近期的、依赖时间的数据集方面展现出了更好的性能。
## 610. `cs.LG` - 使用LLM的隐私保护多样化写作风格的合成评论生成 [PDF](https://arxiv.org/pdf/2507.18055), [HTML](https://arxiv.org/abs/2507.18055)
### Authors
Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng
### Background
随着大型语言模型（LLMs）生成的合成数据在数据驱动应用中的越来越多使用，虽然合成数据作为一种成本低、可扩展的替代真实数据的方法，为模型训练提供了便利，但其多样性和隐私风险仍处于探索阶段。本文重点分析基于文本的合成数据，提出了一个综合的度量体系，从语言表达、情感和用户视角等层面评估多样性，以及从重新识别风险和风格异常等层面评估隐私性。通过对多个最新LLM生成的合成数据集进行实验，发现LLM生成多样化和隐私保护的合成数据的能力存在明显限制。
### Innovation
本文创新性地提出了一个综合的度量体系，用于定量评估基于多个先进LLM生成的合成数据的多样性和隐私性。此外，基于评估结果提出了一种基于提示的方法，旨在提高合成评论的多样性同时保留评论者的隐私。
### Conclusion
实验结果显示，LLM在生成多样化和隐私保护的合成数据方面存在明显局限性。本文提出的方法可以在提高合成评论的多样性的同时，保护评论者的隐私。
## 611. `cs.LG` - 通过文本挖掘映射技术未来：前瞻话语研究 [PDF](https://arxiv.org/pdf/2504.02853), [HTML](https://arxiv.org/abs/2504.02853)
### Authors
Maciej Skorski,Alina Landowska,Krzysztof Rajda
### Background
新兴技术的不确定性和不可预测性，特别是人工智能等技术，已在社交媒体上广泛引起关注。本研究通过分析X平台上400位关键意见领袖（KOL）发布的150万条帖子（2021年至2023年），探讨了对技术未来的前瞻性话语。使用先进的文本挖掘技术，包括BERTopic建模、情感、情绪和态度分析，识别出100个反映技术驱动未来的独特主题。这些主题展示了KOLs如何在塑造当下的技术前景和影响未来社会的讨论中发挥关键作用。通过分析KOLs在讨论技术发展前景和应对社会挑战方面的角色，研究揭示了他们在采用新兴技术期间如何引导公众注意力，特别是在高度不确定性时期进一步探索技术中介背景下的前瞻性话语。
### Innovation
采用BERTopic建模及情感、情绪和态度分析等高级文本挖掘技术，识别并分析多个独特主题，深入了解关键意见领袖（KOLs）如何通过社交媒体对技术未来进行前瞻性描绘，从而影响公众认知和社会讨论。
### Conclusion
KOLs通过社交媒体积极塑造和传播关于技术未来的愿景与态度，尤其是将技术作为应对社会挑战的解决方案，这种前瞻性话语在不确定性时期尤为关键。本文通过文本挖掘技术深入理解并揭示了技术中介背景下前瞻话语的作用与影响机制，为研究技术如何通过话语塑造影响社会提供了新视角。
## 612. `cs.LG` - 基于端到端医疗数据分析的代理人工智能框架 [PDF](https://arxiv.org/pdf/2507.18115), [HTML](https://arxiv.org/abs/2507.18115)
### Authors
Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha
### Background
在医疗保健领域实施和部署机器学习解决方案仍然非常昂贵且劳动密集，主要由于预处理工作流的碎片化、模型兼容性问题以及严格的数据隐私限制。特别是在处理从摄取到推断的临床数据管道时，这些挑战更为突出，导致需要大量人工干预，从而增加了成本和时间。本研究旨在通过引入代理人工智能（Agentic AI）框架来解决这些挑战，目的是自动化整个临床数据流程，减少对人工干预的需求，提高效率并降低成本。
### Innovation
该框架提出了一种全新的系统，通过模块化、任务特定的代理来自动化从数据摄取到推断的整个临床数据管道，无需人工干预。代理能够处理结构化和非结构化数据，自动进行特征选择、模型选择和预处理建议。特别强调了代理在数据识别、匿名化、提取特征和模型匹配中的作用，以及根据不同数据类型和模型需求的个性化预处理。此外，框架提出了注入可解释性输出的推理代理，使用工具如SHAP、LIME和DETR注意力图生成可解释的输出结果。这些创新点使得整个机器学习生命周期的瓶颈阶段自动化，降低了反复的人工干预需求，提供了一种既经济又可扩展的在临床环境中实施人工智能的途径。
### Conclusion
通过代理人工智能框架的实施，可以自动化医疗数据处理的高摩擦阶段，显著减少重复专家干预的需要，提供了一种既经济又可扩展的途径来在临床环境中实施人工智能，有助于提高数据处理的效率和准确性，同时也保证了数据隐私合规性。
## 613. `cs.LG` - 非凸优化框架在广义稀疏反馈线性-quadratic最优控制中的应用 I：惩罚方法 [PDF](https://arxiv.org/pdf/2507.18114), [HTML](https://arxiv.org/abs/2507.18114)
### Authors
Lechen Feng,Xun Li,Yuan-Hua Ni
### Background
本文为解决无限时间线性-quadratic (LQ) 问题中的组稀疏反馈控制器设计开发了一种统一的非凸优化框架。本文重点讨论了经典LQ问题的两个重要扩展：具有固定通信拓扑的分布式LQ问题（DFT-LQ）和稀疏反馈LQ问题（SF-LQ），这些扩展是为了在大型系统中实现可扩展性和结构感知控制而提出的。现有的方法依赖于凸放松或者局限于块对角结构，本文的方法直接将控制器合成建模为包含组 $boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{l}}}}}}_{0}}}}}$-范数正则化项的有限维非凸优化问题，从而捕捉通用的稀疏模式。文中建立了DFT-LQ和SF-LQ问题之间的联系，证明它们都可以在统一框架内解决。此外，本文提出了一种基于惩罚的近似交替线性最小化（PALM）算法，并在较弱的假设下进行了严格的收敛性分析，克服了目标函数缺乏伪凸性的问题。该方法对于所有子问题都有高效的求解器，并保证全局收敛到临界点。这些结果填补了文献中的关键空白，使得能够直接设计组稀疏反馈增益并具有理论保证的方法，而无需使用凸代理或苛刻的结构假设。
### Innovation
直接将控制器合成建模为包含组 $boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{l}}}}}}_{0}}}}}$-范数正则化项的有限维非凸优化问题，从而捕捉通用的稀疏模式；提出了一种基于惩罚的近似交替线性最小化（PALM）算法，并建立了严格的收敛性分析；解决了现有方法中目标函数缺乏伪凸性的挑战，保证全局收敛到临界点；无需依赖凸代理或苛刻的结构假设，使得能够直接设计组稀疏反馈增益并具有理论保证的方法。
### Conclusion
本文通过开发一种统一的非凸优化框架，直接设计具有组稀疏反馈增益的反馈控制，并在理论上有保证的方法，填补了文献中的关键空白，使得在未经凸松弛或苛刻结构假设的情况下能够直接设计组稀疏反馈增益。
## 614. `cs.LG` - GeoAvatar: 适应性几何高斯渲染技术在三维头部化身生成中的应用 [PDF](https://arxiv.org/pdf/2507.18155), [HTML](https://arxiv.org/abs/2507.18155)
### Authors
SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park
### Background
尽管近年来在3D头像生成方面取得了进展，但在重建即保持身份与动画即新颖姿势和表情之间找到平衡仍然是一项挑战。现有方法难以适应面部区域之间变化的几何偏差，导致生成的质量不佳。
### Innovation
本文提出了一种适应性几何高斯渲染框架GeoAvatar。GeoAvatar采用无监督的适应性预分配阶段(APS)，将高斯点划分为刚性和柔性集合，并针对偏移正则化实施适应性偏移调节。此外，基于口腔解剖和动态特征，引入了新的口腔结构和部分变形策略，以提升动画的真实度，并提出了正则化损失以精确实现高斯点与3DMM面部之间的绑定。同时提供了动态面部数据集，以用于测试和评估。
### Conclusion
通过大量实验，GeoAvatar在重建和新颖动画场景中均优于现有方法，充分展示了GeoAvatar的优势。
## 615. `cs.LG` - 结合特征选择和机器学习的田间高光谱成像技术在葡萄叶片氮素评估中的应用 [PDF](https://arxiv.org/pdf/2507.17869), [HTML](https://arxiv.org/abs/2507.17869)
### Authors
Atif Bilal Asad,Achyut Paudel,Safal Kshetri,Chenchen Kang,Salik Ram Khanal,Nataliya Shcherbatyuk,Pierre Davadant,R. Paul Schreiner,Santosh Kalauni,Manoj Karkee,Markus Keller
### Background
氮（N）是葡萄园中最重要的营养元素之一，影响植物生长以及后续的产品如葡萄酒和果汁。由于土壤氮有较高的空间和时间变异性，准确估算葡萄叶片的氮浓度并逐株管理施肥以满足植物需求是必要的。
### Innovation
基于田间的高光谱图像，该研究利用不同葡萄品种和两个生长阶段的两年数据，建立预测叶片和冠层氮浓度的模型。研究使用了两个特征选择方法和两种不同的机器学习模型（Gradient Boosting和XGBoost）进行氮浓度预测。结果显示，在关键波段（500-525nm，650-690nm，750-800nm，900-950nm）上，特征选择方法一致地识别出了相关波段，表明这些波段具有预测氮含量的稳健性。尽管在不同分析层次上使用了不同的光谱波段集合，机器学习模型在叶片和冠层数据集上仍能取得较好的预测效果。
### Conclusion
研究展示了在葡萄园中使用田间高光谱成像、光谱数据以及结合特征选择和机器学习技术监测氮素状态的潜在应用。
## 616. `cs.LG` - ReSem3D: 细粒度语义接地 refineable 3D 空间约束 以实现泛化机器人操作 [PDF](https://arxiv.org/pdf/2507.18262), [HTML](https://arxiv.org/abs/2507.18262)
### Authors
Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong
### Background
当前的机器人操作方法存在以下关键局限性：(1) 在约束建模中语义粒度过粗；(2) 没有实时闭环规划；(3) 在语义多样的环境中表现出的鲁棒性较差。因此，现有方法难以统一任务理解和执行，特别是在复杂多样的环境中进行机器人操作时表现欠佳。
### Innovation
本文提出了一种统一的机器人操作框架 ReSem3D，通过视觉基础模型（VFMs）和多模态大语言模型（MLLMs）的协同作用，实现了精细化的视觉接地，并动态构建分级的 3D 空间约束，以实现实时操作。该框架通过 MLLMs 的分层递归推理，与 VFMs 交互，从自然语言指令和 RGB-D 观测数据中自动构建 3D 空间约束，分为部件级提取和区域级细化两个阶段。这些约束被编码为关节空间中的实时优化目标，以实现对动态干扰的反应行为。实验结果显示，ReSem3D 在多种自然语境和稀疏化学实验室环境中表现出了强大的适应性和泛化能力，能够在零样本条件下完成各类操作任务。
### Conclusion
ReSem3D 通过细粒度语义接地实现可调用的 3D 空间约束，有效解决了现有方法的局限性问题，为机器人操作提供了实时有效的解决方案，具备较强的泛化能力和适应性。
## 617. `cs.LG` - 多数据集基准测试用于ECG波形分割的半监督语义分割 [PDF](https://arxiv.org/pdf/2507.18323), [HTML](https://arxiv.org/abs/2507.18323)
### Authors
Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo
### Background
心电图（ECG）波形分割是一项重要的临床诊断技术，但受限于可用的标注数据稀缺，进步受限。半监督学习方法通过利用大量未标注的ECG数据，提供了一种可能的解决方案。此项研究旨在构建首个系统性半监督语义分割基准测试，针对ECG波形分割。研究整合了多个公共数据集，增强了评估的稳健性和多样性，并采用了五种代表性的半监督语义分割算法，在不同的架构和设置下进行评估，还提出了ECG特定的训练配置和增强策略，构建了标准化评估框架。
### Innovation
本研究呈现了首个系统性的半监督语义分割基准测试，针对ECG波形分割。通过整合多个数据集，采用了五种半监督语义分割算法，两种不同架构，两种不同设置进行评估，提出针对ECG的特定训练配置和增强策略，引入标准化评估框架，并展示了变压器在ECG半监督波形分割中的优越性。
### Conclusion
研究结果表明，变压器在半监督ECG波形分割中表现优于卷积网络。该基准为推进半监督ECG波形分割方法的发展奠定了基础，并将促进该领域的进一步研究。
## 618. `cs.LG` - 通过混合知识蒸馏实现高质量低资源面部动画模型 [PDF](https://arxiv.org/pdf/2507.18352), [HTML](https://arxiv.org/abs/2507.18352)
### Authors
Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage
### Background
高质量和鲁棒性的语音驱动3D面部动画模型需要大量的高质量音频-动画对数据集。由于缺乏这样的数据集，近期的研究引入了大规模预训练语音编码器，这些编码器对输入音频的变异有鲁棒性，从而使得面部动画模型能够在不同说话者、音频质量和语言下泛化。然而，这些结果的面部动画模型过于庞大，只能在专用机器上进行离线推理。该研究通过混合知识蒸馏与伪标签，旨在克服缺乏大型数据集的问题，研究者使用高表现力的教师模型来训练极其小的学生模型，从而显著缩小模型大小和降低未来音频上下文需求，同时保持高质量的动画效果。
### Innovation
研究使用混合知识蒸馏与伪标签方法，可在缺乏大量数据集的情况下训练学生模型。这些学生模型仅由卷积层和全连接层组成，去除了注意力上下文或递归更新的需求，使得模型能够实现一个设备内的实时推理。研究演示了这种模型可以在满足高质量动画需求的同时，将内存占用减少到3.4 MB，并降低未来音频上下文需求至81 ms。这为在设备上进行推理铺平了道路，这是实现现实、模型驱动的虚拟角色的重要步骤。
### Conclusion
通过混合知识蒸馏方法构建的学生模型在保持高质量动画效果的同时，大幅减少了模型的大小和未来音频上下文需求，实现了实时光线面部动画的可能，这是向真实模型驱动的数字化角色迈出的重要一步。
## 619. `cs.LG` - 基于贝叶斯后验和训练模型重建训练数据 [PDF](https://arxiv.org/pdf/2507.18372), [HTML](https://arxiv.org/abs/2507.18372)
### Authors
George Wynne
### Background
公开发布带有训练参数的模型规范会使对手有机会通过训练数据重建攻击来获取训练数据的信息，这是现代机器学习方法的一个重大漏洞。
### Innovation
本文建立了数学框架来表达这一问题；通过最大均值差异等价性鉴别出训练数据中的易受攻击特征；提出了在贝叶斯和非贝叶斯模型中重建数据的评分匹配框架，其中在贝叶斯模型中的评分匹配框架是文献中的首创成果。
### Conclusion
本文通过数学建模和评分匹配框架，为训练数据重建攻击提供了新的理论依据和技术手段，提高了对抗训练数据重建攻击的能力。
## 620. `cs.LG` - Hierarchical Dimensionless Learning (Hi-π): 一种基于物理与数据分析的无量纲参数组合发现方法 [PDF](https://arxiv.org/pdf/2507.18332), [HTML](https://arxiv.org/abs/2507.18332)
### Authors
Mingkun Xia,Haitao Lin,Weiwei Zhang
### Background
维度分析提供了一个通用的框架，用于减少物理系统的复杂性并揭示内在的规律。然而，其在高维系统中的应用仍会产生冗余的无量纲参数，使得建立有意义的物理描述变得困难。
### Innovation
引入了一种新的方法——层次无量纲学习（Hi-π），这是一种结合了维度分析和符号回归的物理数据混合驱动的方法，自动发现关键的无量纲参数组合。
### Conclusion
该方法被应用于流体力学各个研究领域的经典例子。通过雷leigh-Bénard对流、圆管中的粘性流动以及亚音速流动中的可压缩性修正，验证了其在多尺度数据中的统一表示优势。同时，该方法能够自动发现最优无量纲参数，实现准确度与复杂度之间的平衡，并展示了其发现层次结构表达式的能力。
## 621. `cs.LG` - CLEAR: LLM作为评委进行错误分析的简便方式 [PDF](https://arxiv.org/pdf/2507.18392), [HTML](https://arxiv.org/abs/2507.18392)
### Authors
Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer
### Background
随着大语言模型（LLMs）在评测中的应用越来越多，当前的评测往往只给出单一的评分或排名，无法说明模型表现良好的具体原因。虽然这种评测对于基准测试很重要，但这样一二级的评分模糊了模型表现背后的具体、可操作的原因。
### Innovation
为解决上述问题，该研究引入了一个名为CLEAR的交互式开源包，用于基于LLM的错误分析。CLEAR首先生成针对每个实例的文本反馈，然后识别出系统层面的错误问题，并量化每个问题的普遍程度。该包还提供了一个交互式仪表板，可以进行概要可视化分析，应用交互式过滤器以隔离特定问题或评分范围，并深入到具体实例以示例化特定行为模式。
### Conclusion
通过CLEAR分析了RAG和数学基准，并通过一个用户案例研究展示了其实用性。该研究为LLMs在评测中的应用提供了一个新的角度，使得评测结果更加具体和可操作。
## 622. `cs.LG` - Iwin Transformer: 使用交错窗口的层次视觉变换器 [PDF](https://arxiv.org/pdf/2507.18405), [HTML](https://arxiv.org/abs/2507.18405)
### Authors
Simin Huo,Ning Li
### Background
视觉变换器已经在诸如图像分类、语义分割和视频动作识别等视觉基准任务中取得了显著的成果，但现有的方法，如Swin变换器，仍存在一定的局限性。特别是，它们在传递全局信息时需要使用两个连续的模块来近似全局注意力，这限制了其效率和性能。因此，有必要开发一种新的视觉变换器架构，能够直接从低分辨率到高分辨率进行微调，同时能够在单一模块中实现全局信息的交换，从而提高整体的竞争力和应用范围。
### Innovation
Iwin变换器提供了一种创新的方法，通过交错窗口注意力和深度可分离卷积合作，直接从低到高分辨率进行微调。该方法利用注意力机制在远程令牌之间建立连接，同时通过卷积机制在邻近令牌之间建立联系，确保单个模块内可以进行全局信息交换。这种设计彻底解决了Swin变换器对两个连续模块来近似全局注意力的需求，提高了整体的效率和能力。此外，研究还验证了Iwin变换器中核心组件作为独立模块使用的有效性，可以无缝替代类条件图像生成中的自我注意模块。
### Conclusion
通过对视觉基准的广泛实验，Iwin变换器在图像分类（在ImageNet-1K上的87.4顶级准确度）、语义分割和视频动作识别等任务中表现出强大的竞争力。研究还表明，Iwin变换器的核心组件作为一个独立模块使用时同样有效，并且其引入的概念和方法具有激发未来研究的潜力，例如应用于视频生成中的Iwin 3D注意力。所使用的代码和模型已发布供公众使用。
## 623. `cs.LG` - FinDPO：通过优化LLM偏好的金融情绪分析算法交易 [PDF](https://arxiv.org/pdf/2507.18417), [HTML](https://arxiv.org/abs/2507.18417)
### Authors
Giorgos Iacovides,Wuyang Zhou,Danilo Mandic
### Background
在线金融相关的文本数据中的意见对交易决策和市场动态的影响日益深入。这一趋势突显了情感分析作为一种工具，用于量化这些意见的性质和强度的重要性。随着生成式人工智能（GenAI）的快速发展，监督微调（SFT）大型语言模型（LLMs）已成为金融情绪分析的事实标准。然而，SFT范式会导致对训练数据的记忆，并且往往无法在未见样本上实现泛化。这在金融领域尤其是一个关键限制，因为模型必须适应以前未观察到的事件和金融领域的细微、专门的语言。
### Innovation
我们介绍了FinDPO，这是第一个基于二次训练后通过直接偏好优化（DPO）对齐人类偏好意见的金融专用LLM框架。FinDPO在标准情绪分类基准测试中达到了最佳性能，比现有的监督微调模型在平均值上高出11%。新颖的是，FinDPO框架通过一种新颖的“logit-to-score”转换，将离散的情绪预测转化为连续的、可排名的情感评分（概率），从而能够将微调的因果LLM集成到现实的投资组合策略中。研究表明，FinDPO是第一个在现实交易成本为5个基点的情况下，每年维持67%的积极回报和强烈风险调整性能（夏普比率2.0）的情绪分析方法。
### Conclusion
FinDPO通过对二次训练后的LLM进行偏好优化，实现了在标准情绪分类基准测试中的最佳性能，同时还能将微调的因果LLM成功集成到投资组合策略中，从而展示了强大的投资回报和风险调整性能。
## 624. `cs.LG` - GVCCS: 在可见光全天空相机序列中用于雾幕识别和追踪的数据集 [PDF](https://arxiv.org/pdf/2507.18330), [HTML](https://arxiv.org/abs/2507.18330)
### Authors
Gabriel Jarry,Ramon Dalmau,Philippe Very,Franck Ballerini,Stephania-Denisa Bocu
### Background
航空业的气候影响不仅包括二氧化碳排放，还包括显著的非二氧化碳效应，特别是由雾幕产生的冰云。这些云可以影响地球辐射平衡，甚至可能与航空二氧化碳的增温效应对等。尽管物理模型可以提供有用的雾幕形成和气候影响估计，但其准确性高度依赖于大气输入数据的质量以及代表复杂过程（如冰颗粒形成和湿度驱动保持）的假设。现有的观测数据集通常缺乏以下方面：对雾幕动态和形成的全面了解，通常缺乏时间跟踪，并且无法将雾幕归属于其源头航班。
### Innovation
本文提出了一种新的开放数据集，即地基全天空可见光相机雾幕序列（Ground Visible Camera Contrail Sequences，简称GVCCS），包含122个视频序列（24,228帧），每条雾幕都被单独标记并随时间进行追踪，可以详细分析其生命周期。此外，本文还提出了一种统一的深度学习框架，通过全景分割模型进行语义分割（雾幕像素识别）、实例分割（独立雾幕分离）以及时间跟踪，以单一体系结构的方式实现，提供高质量、时间解析的注释和模型评估基准，支持改进的雾幕监测并促进物理模型的校准。
### Conclusion
本研究为更准确的气候影响理解奠定了基础，通过提供高质量的时间解析注释和评估基准，这些改进将有助于更精确的物理模型校准，提高对航空业气候影响的评估和理解。
## 625. `cs.LG` - BrisT1D Dataset: 年轻成人使用智能手表的英国1型糖尿病患者 [PDF](https://arxiv.org/pdf/2507.17757), [HTML](https://arxiv.org/abs/2507.17757)
### Authors
Sam Gordon James,Miranda Elaine Glynis Armstrong,Aisling Ann O'Kane,Harry Emerson,Zahraa S. Abdallah
### Background
1型糖尿病(T1D)的管理技术正在迅速发展，为其他慢性疾病的未来管理提供了有用的案例研究。进一步开发这种管理技术需要探索其在现实生活中的使用及其潜在的数据流扩展。为此，我们为不断增长的公共1型糖尿病管理数据集库贡献了BrisT1D数据集。
### Innovation
我们开发了BrisT1D数据集，该数据集源自24位在英国使用智能手表兼用传统1型糖尿病管理系统的年轻成人纵向研究。数据集不仅包含来自1型糖尿病管理系统的设备数据，还有参与者使用的智能手表数据，以及研究期间每月访谈和焦点小组的转录记录。这些数据集提供了经过处理和原始状态的数据，以支持更快速的分析和深度探索新的洞察。
### Conclusion
该数据集具有广泛的应用潜力。定量元素可以支持血糖预测、低血糖预测和闭环算法开发。定性元素可以促进用户体验探索和意见研究，以及更广泛的混合方法研究，探讨智能手表在1型糖尿病管理中的作用。
## 626. `cs.LG` - NLML-HPE: 通过流形学习使用有限数据进行头部姿态估计 [PDF](https://arxiv.org/pdf/2507.18429), [HTML](https://arxiv.org/abs/2507.18429)
### Authors
Mahdi Ghafourian,Federico M. Sukno
### Background
头部姿态估计（HPE）在人类计算机交互和面部识别等领域扮演着重要的角色。然而，传统的基于分类的方法需要大量的训练数据，并且受到错误或不准确的姿态注释数据的限制。此外，基于有限训练数据实时运行的性能也是一个挑战。NLML-HPE方法通过非线性流形学习解决这些难题，将头部姿态估计转化为回归问题，并通过张量分解将欧拉角拆分成单独的子空间，以构建更准确的头部姿态模型。
### Innovation
该方法创新之处在于，它结合了张量分解和前馈神经网络，将头部姿态估计转化为回归问题。特别之处在于，每个欧拉角（偏航、俯仰、滚转）被映射成各自的子空间，每个潜在流形的维度都被建模为余弦曲线。此外，通过旋转3D头部模型来生成精确且一致的2D头部姿态数据集，解决了姿态注释不准确的问题。这种方法有效地利用了有限的训练数据，实现了实时运行。
### Conclusion
NLML-HPE 方法能够利用有限数据集进行头部姿态估计，解决了姿态注释不准确和实时性能的挑战，模型在预测未见过的数据时非常快。相关代码和训练模型可以在网上找到。
## 627. `cs.LG` - 恢复节奏：使用变压器模型为低资源语言孟加拉语恢复标点符号 [PDF](https://arxiv.org/pdf/2507.18448), [HTML](https://arxiv.org/abs/2507.18448)
### Authors
Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu
### Background
标点符号的恢复可以提高文本的可读性，并且对于自动语音识别（ASR）后处理任务至关重要，尤其是在低资源语言如孟加拉语中。这项研究探索了基于转换器的模型，特别是XLM-RoBERTa-large，应用到无标点孟加拉文本的自动标点恢复中。该研究侧重于预测四种标点符号：句号、逗号、问号和感叹号，涵盖不同文本领域。为了应对标注资源稀缺的问题，构建了一个大量且多样化的训练语料库，并应用了数据增强技术。
### Innovation
最佳模型是在增强因子α=0.20%的情况下训练的，分别在新闻测试集、参考集和ASR集上达到了97.1%、91.2%和90.2%的准确率。结果显示，该模型在参考和ASR转录上具有很强的泛化能力，证明了它在现实嘈杂场景中的有效性。这项工作为孟加拉语标点符号恢复建立了坚实的基线，并贡献了公开可用的数据集和代码，支持未来在低资源NLP中的研究。
### Conclusion
这项研究证明了基于转换器的模型在低资源语言孟加拉语的标点恢复任务中的有效性，并为未来的研究提供了公开可用的数据集和代码。
## 628. `cs.LG` - 可视化有助于AI理解数据吗？ [PDF](https://arxiv.org/pdf/2507.18022), [HTML](https://arxiv.org/abs/2507.18022)
### Authors
Victoria R. Li,Johnathan Sun,Martin Wattenberg
### Background
图表和图形有助于人们分析数据，但它们是否对AI系统也有助益？为回答这一问题，研究人员进行了一系列实验，使用了两个商业化的视觉-语言模型——GPT 4.1和Claude 3.5。在三个代表性的分析任务中，当原始数据伴随散点图时，这两个系统能更精确、更准确地描述合成数据集，尤其是在数据集变得复杂时效果更加显著。与提供空白图表和数据不匹配的图表两种基线进行比较，结果显示，性能提升归因于图表中的内容。
### Innovation
研究人员使用了商业化的视觉-语言模型进行实验，探索可视化信息对AI理解数据的作用。实验证明，在传达数据信息方面，合适的视觉辅助能显著提升AI系统的表现，这一发现为进一步研究提供了初步证据，并表明AI系统可以类似人类从可视化中受益。这一工作具有创新性，因为它将人类的辅助工具首次应用到AI的理解过程中。
### Conclusion
实验结果表明，当原始数据伴随散点图时，视觉内容能够显著提升AI对数据的理解和解释能力。这初步证明了视觉信息在帮助AI理解和处理数据方面的作用。
## 629. `cs.LG` - 图引导依赖学习：语言模型生成表格数据时虑重点特征的技巧 [PDF](https://arxiv.org/pdf/2507.18504), [HTML](https://arxiv.org/abs/2507.18504)
### Authors
Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci
### Background
大型语言模型（LLMs）在通过建模特征-值对的文本化表达生成表格数据方面表现出强大的潜力。然而，表格数据固有的特点在于特征层面的依赖关系是稀疏的，很多特征交互在结构上是不重要的。这导致了根本的不匹配：LLMs 的自注意力机制不可避免地需要关注所有对，这分散了对关键关系的关注，特别是在具有复杂依赖关系或语义模糊特征的数据集中。
### Innovation
本文提出了一种称为 GraDe（图引导依赖学习）的新方法，该方法明确地将稀疏依赖图集成到 LLMS 的注意机制中。GraDe 使用一个由外部提取的功能依赖性引导的轻量级动态图学习模块，优先处理关键特征交互，抑制无关的交互。实验结果表明，GraDe 在复杂数据集上的表现优于现有的基于 LLMS 的方法，最多可提高 12% 的性能，同时在合成数据质量上与最先进的方法竞争。
### Conclusion
本文的方法入侵性小而有效，提供了用于 LLM 生成结构、关注意识的表格数据的实用解决方案。
## 630. `cs.LG` - 高功率射频设备和加速器组件中平面几何中倍增击穿预测的监督机器学习框架：案例研究 [PDF](https://arxiv.org/pdf/2507.17881), [HTML](https://arxiv.org/abs/2507.17881)
### Authors
Asif Iqbal,John Verboncoeur,Peng Zhang
### Background
倍增击穿是电子雪崩的一种非线性现象，可能严重损害高功率射频（RF）设备和加速器系统的性能。准确预测不同材料和操作条件下的倍增击穿敏感性，对于加速器组件设计和RF工程而言是一个关键但计算密集的挑战。
### Innovation
该研究首次应用监督机器学习（ML）来预测二维平面几何中的倍增击穿敏感性。使用来自模拟的数据集训练了包括随机森林（RF）、超树（ET）、极端梯度 Boosting（XGBoost）和漏斗结构多层感知器（MLPs）在内的回归模型，以预测电子增长率的平均值。通过使用交并比（IoU）、结构相似性指数（SSIM）和皮尔逊相关系数进行性能评估，发现基于树的模型在跨不同材料空间时表现更优，且利用标量化目标函数结合贝叶斯超参数优化和5折交叉验证训练的MLPs，优于单一目标损失函数训练的模型，进一步揭示了某些材料性能衰减的原因。
### Conclusion
该研究展示了基于ML的倍增击穿预测的潜力和限制，并为先进RF和加速器系统设计的加速、数据驱动建模铺平了道路。
## 631. `cs.LG` - ViGText: 使用视觉语言模型解释和图神经网络进行深度伪造图像检测 [PDF](https://arxiv.org/pdf/2507.18031), [HTML](https://arxiv.org/abs/2507.18031)
### Authors
Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan
### Background
深度伪造技术的快速发展产生了逼真的篡改数字内容，威胁到媒体的真实性和可信性。传统的深度伪造检测方法在对抗高复杂度的定制化深度伪造时普遍存在灵活性和抗攻击能力不足的问题，尤其是在泛化性能方面有局限性。当前的检测方法通常通过简单的图像或文本描述来检测，这些描述往往细节不足且无法揭示信息的细微不一致性，导致检测效果不佳。
### Innovation
该论文提出了一种名为ViGText的创新方法，将视觉数据与Vision Large Language Model (VLLM)文本解释整合到基于图的框架中以改进深度伪造检测。ViGText通过多级特征提取（包括空间域和频率域）来识别复杂的深度伪造，同时使用图神经网络分析图像和文本图。这种方法不仅提升了检测可靠性和准确性，还能有效应对用户定制化以及有针对性的攻击，表明其优越的泛化能力和对未见过的差分模型微调版本的鲁棒性。
### Conclusion
ViGText通过视觉和文本的详细分析，不仅提高了深度伪造检测的性能，而且为打击深度伪造和确保媒体的真实性和信息完整性建立了新的标准。实验结果显示，在泛化评估中，平均F1分数大幅提升，自72.45%提高到98.32%。此外，ViGText还显著提升了检测模型的鲁棒性，相对于其他方法的召回率提升了11.1%，并且在面对具体的攻击时，模型性能最多仅下降4%。
## 632. `cs.LG` - 大型语言模型的道德差距 [PDF](https://arxiv.org/pdf/2507.18523), [HTML](https://arxiv.org/abs/2507.18523)
### Authors
Maciej Skorski,Alina Landowska
### Background
道德基础检测对于分析社会话语和开发与伦理对齐的AI系统至关重要。尽管大型语言模型在多种任务中表现出色，但在专门的道德推理论证方面的能力尚不清楚。这项研究首次通过ROC、PR和DET曲线分析，在Twitter和Reddit数据集上比较了最先进的LLM和微调的变换器模型，揭示了大型语言模型在道德推理方面的显著性能差距，表明在道德推理任务上，针对任务的微调方法仍然优于提示工程方法。
### Innovation
首次通过多种评估方法（ROC、PR和DET曲线）在社交网络数据集上对最新大型语言模型和微调变换器模型进行全面比较，揭示了在道德推理任务上的性能差距，并强调了任务特定微调优于提示工程的方法。
### Conclusion
研究结果表明，大型语言模型在道德推理任务上存在显著性能差距，它们在提示工程努力后仍表现出较高的漏检率和系统性的道德内容欠检问题。针对任务的微调方法优于单纯的提示工程方法，可以显著提高模型在道德推理方面的能力。
## 633. `cs.LG` - 阐明任意噪声基扩散模型的设计空间 [PDF](https://arxiv.org/pdf/2507.18534), [HTML](https://arxiv.org/abs/2507.18534)
### Authors
Xingyu Qiu,Mengying Yang,Xinghua Ma,Dong Liang,Yuzhen Li,Fanding Li,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li
### Background
EDM能揭示扩散模型的统一设计空间，但其固定的噪声模式仅限于纯高斯噪声，限制了图像恢复的进步。研究表明，在重建过程中强迫注入高斯噪声会破坏退化的图像，过度延伸图像转换距离，并增加恢复的复杂性。此研究旨在解决此问题，提出EDA以阐明基于任意噪声的扩散模型的设计空间。EDA理论上扩展了噪声图案的自由度，保持了EDM原始模块的灵活性，并通过严格的证明表明，增加了噪声复杂性并不会在恢复过程中引入额外的计算负担。此研究在三个典型任务上得到了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影减少（全局锐利噪声）以及自然图像阴影去除（局部边界感知噪声）。仅使用5次采样步骤，EDA在偏置场校正和阴影去除任务上表现最好，达到了最先进的技术水平。
### Innovation
提出了EDA，以阐明基于任意噪声的扩散模型的设计空间。该方法理论上扩展了噪声模式的自由度，保持了扩散模型的模块灵活性，并证明了增加噪声复杂性不会额外增加计算负担。在MRI校正、CT金属伪影减少和自然图像阴影去除三个任务上，仅通过5次采样步骤实现了最先进的表现。
### Conclusion
EDA可以克服高斯噪声限制的问题，通过增加噪声复杂性改善图像恢复质量，同时无需增加计算负担。该方法适用于多个图像处理任务中的图像恢复，展示了其广泛的应用前景。
## 634. `cs.LG` - A 两臂贝塔框架用于A/B测试 [PDF](https://arxiv.org/pdf/2507.18118), [HTML](https://arxiv.org/abs/2507.18118)
### Authors
Jinjuan Wang,Qianglin Wen,Yu Zhang,Xiaodong Yan,Chengchun Shi
### Background
A/B测试在现代技术公司中广泛用于政策评估和产品部署，目标是对比新开发的政策与标准控制组的结果。文献中发展的各种因果推断和强化学习方法适用于A/B测试。
### Innovation
本文提出了一种两臂贝塔框架，旨在改进现有方法的效能。该方法包括三个主要步骤：（i）使用双重鲁棒估计生成伪结果；（ii）利用两臂贝塔框架构建检验统计量；（iii）采用基于置换的方法计算p值。
### Conclusion
通过渐近理论、数值实验和来自一家出行共享公司的实际数据，证明了所提出方法的效力，并显示出与现有方法相比的优越性能。
## 635. `cs.LG` - 氢的深变分自由能计算的氢霍希农曲线 [PDF](https://arxiv.org/pdf/2507.18540), [HTML](https://arxiv.org/abs/2507.18540)
### Authors
Zihang Li,Hao Xie,Xinyang Dong,Lei Wang
### Background
本文开发了一种深度变分自由能框架，用于计算氢在热密物质区域的状态方程。该方法使用三种深度生成模型参数化氢核和电子在有限温度下的变分密度矩阵：一种归一化流模型表示经典核的玻色分布，一种自回归变压器模型电子在激发态的分布，以及一种置换对称流模型为哈特里-弗克轨道中的电子构建回流坐标。这些模型联合优化以最小化变分自由能，从而获得稠密氢的状态方程及相关热力学性质。研究人员将计算结果与其他理论和实验结果（特别是氘霍希农曲线）进行比较，旨在解决现有分歧。计算结果为热密物质区域的氘提供了有价值的基准数据。
### Innovation
开发了一种深度学习与变分自由能相结合的新方法，通过三种深度生成模型（归一化流模型、自回归变压器和置换对称流模型）来有效地计算氢在热密物质区域的状态方程。该方法能准确预测氢的热力学性质，特别是稠密氢的状态方程，为理解和研究热密物质区域的物理现象提供了一种新途径。
### Conclusion
通过联合优化三个深度神经网络以最小化变分自由能，获得了氢能状态下相关热力学性质的计算结果。这些结果与其它理论和实验数据进行了比较，有助于解决现有数据之间的争议。计算结果为热密物质区域的氢提供了可靠的理论基准。
## 636. `cs.LG` - 数字孪生技术在预测性维护中的应用：通过仿真实到现实与现实到仿真的转移实现可移植性 [PDF](https://arxiv.org/pdf/2507.18449), [HTML](https://arxiv.org/abs/2507.18449)
### Authors
Sizhe Ma,Katherine A. Flanigan,Mario Bergés
### Background
随着物联网（IoT）和人工智能的进步，数字孪生（DTs）从理论概念转变为可实施的实际应用。然而，从学术界到工业界的转化过程因缺乏标准化框架而变得复杂。本文基于作者先前提出的功能性及信息性要求，进一步关注了标准化DT发展的关键方面——可移植性。现有研究主要集中在资产转移，而“仿真实到现实”与“现实到仿真实验”的知识转移对于全面生命周期管理至关重要。面临的挑战是如何校准“现实差距”，即模拟预测与实际结果之间的差异。
### Innovation
本文的研究在于探讨集成单一现实间隙分析（RGA）模块到现有DT框架的有效性，以管理和优化仿真实到现实与现实到仿真的双向知识转移。这种集成通过连接RGA模块和现有DT框架的各种组件，包括历史库和仿真模型的数据管道得以实现。案例研究展示了我们方法在卡内基梅隆大学行人桥梁上的应用，证明了其在不影响效率的前提下可以实现仿真与现实操作之间的双向知识转移。
### Conclusion
通过实现RGA模块和完整的数据管道，本方法能够在不降低效率的前提下实现仿真与现实操作之间双向的知识转移。
## 637. `cs.LG` - 关于概念探测性能：数据的影响（扩展版本） [PDF](https://arxiv.org/pdf/2507.18550), [HTML](https://arxiv.org/abs/2507.18550)
### Authors
Manuel de Sousa Ribeiro,Afonso Leote,João Leite
### Background
概念探测最近因其有助于解释人工神经网络而受到广泛关注，它能够处理大型模型和非符号性的本质，使得这些模型难以直接为人所理解。概念探测通过训练附加的分类器将模型的内部表示映射到人类定义的概念上，从而使人类能够洞察人工神经网络。目前的研究主要集中在被探测的模型或探测模型本身，但较少关注用于训练探测模型的数据对性能的影响。本文聚焦于图像分类任务中的概念探测，研究用于训练探测模型的数据对其性能的影响，并提供了两个广泛使用的数据集的概念标签。
### Innovation
本文探讨了用于训练探测模型的数据对性能的影响，填补了该领域的研究空白，为理解人工神经网络提供了一种新的视角。同时，论文还提供两个常用数据集的概念标签，为研究者们提供了便利。
### Conclusion
研究表明，用于训练探测模型的数据类型显著影响了概念探测的效果。这种影响不仅体现在探测准确率上，还影响了人类对模型内部理解的深入程度。提供的概念标签能够帮助研究人员更好地理解不同数据集对概念探测模型的影响。
## 638. `cs.LG` - AI/ML Life Cycle Management for Interoperable AI Native RAN [PDF](https://arxiv.org/pdf/2507.18538), [HTML](https://arxiv.org/abs/2507.18538)
### Authors
Chu-Hsiang Huang,Chao-Kai Wen,Geoffrey Ye Li
### Background
AI和机器学习模型正迅速渗透到5G无线接入网络（RAN）中，用于支持波束管理、信道状态信息（CSI）反馈、定位和移动性预测等功能。然而，由于缺乏标准化的生命期管理（LCM）框架，如模型漂移、供应商锁定和透明度不足等问题阻碍了大规模应用。3GPP从R16到R20逐步将AI/ML从实验功能演进为企业级、可互操作的网络功能。从R16的网络数据分析功能（NWDAF）开始，后续版本引入了标准化的模型传输、执行、性能监控和闭环控制接口。R20还针对CSI压缩和供应商无关的LCM配置文件开展了研究。
### Innovation
3GPP通过从R16至R20逐步标准化AI/ML的框架，逐步引入了标准化的模型传输、执行、性能监控和闭环控制接口。这形成了一个包含五个模块的LCM架构，并定义了基于关键绩效指标（KPI）的监控机制以及跨供应商协作方案。这些发展为AI原生收发器作为6G关键技术奠定了基础。
### Conclusion
尽管取得了进展，但在高效资源监控、环境变化检测、智能决策和灵活模型训练等方面仍存在诸多挑战。这些研究为未来的可互操作AI原生RAN提供了基础支撑。
## 639. `cs.LG` - DRWKV：聚焦于物体边缘的低光图像增强 [PDF](https://arxiv.org/pdf/2507.18594), [HTML](https://arxiv.org/abs/2507.18594)
### Authors
Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung
### Background
低光图像增强仍然是一个具有挑战性的任务，特别是在极端光照退化条件下保持物体边缘连续性和精细结构细节方面。
### Innovation
提出了一个创新模型DRWKV（Detailed Receptance Weighted Key Value），该模型结合了研究人员提出的全局边缘衍射理论（GER），实现了光照和边缘结构的有效解耦合，以增强边缘保真度。引入了螺旋扫描机制的演化WKV注意，能够捕捉空间边缘连续性并更有效地建模不规则结构。设计了双边光谱对准器（Bi-SAB）及定制的MS2-Loss，共同对亮度和色度特征进行对齐，以提高视觉自然度并减轻伪影。
### Conclusion
在五个LLIE基准上的详尽实验表明，DRWKV在PSNR、SSIM和NIQE等方面取得了领先性能，同时保持了低计算复杂度。此外，DRWKV在低光多对象跟踪任务中的性能提升验证了其泛化能力。
## 640. `cs.LG` - 遥感分割方法在土地利用和覆盖分类中的比较 [PDF](https://arxiv.org/pdf/2507.18099), [HTML](https://arxiv.org/abs/2507.18099)
### Authors
Naman Srivastava,Joel D Joy,Yash Dixit,Swarup E,Rakshit Ramesh
### Background
土地利用和覆盖（LULC）映射对于城市和资源规划至关重要，是智能和可持续城市开发的关键要素之一。本研究评估了先进的LULC映射技术，重点在于应用于Cartosat多谱段（MX）传感器图像的查找表（LUT）基础的大气校正技术，随后通过监督学习和半监督学习模型预测LULC。研究案例是印度海得拉巴市，显示出快速城市化过程中土地利用的变化。
### Innovation
研究采用了DeeplabV3+和交叉伪监督（CPS）模型，并进一步通过动态加权优化CPS模型的伪标签可靠性。这种方法准确性和实用性分析显示了这些技术在不同城市规划应用中的优势。
### Conclusion
研究通过分析Cartosat MX图像的变化展示了这些技术在城市规划者和政策制定者中的实用价值，揭示了城市扩张、绿色空间缩减和工业区扩张等重要变化。
## 641. `cs.LG` - 在同心坐标中的高维数据分类 [PDF](https://arxiv.org/pdf/2507.18450), [HTML](https://arxiv.org/abs/2507.18450)
### Authors
Alice Williams,Boris Kovalerchuk
### Background
目前，利用可解释的方法可视化多维数据仍然受到限制，特别是无法实现无损的高维可视化，并且这种可视化方法在计算上也不够高效。现有的平行坐标和圆周坐标等可视化技术存在数据重叠和计算复杂度高的问题，影响了数据分析的效果。
### Innovation
本文提出了一种低维到高维数据的支持框架，利用无损的同心坐标，这是平行坐标和先前圆周坐标的更紧凑的一般化形式。同心坐标属于通用线坐标可视化的一种，可以支持机器学习算法的可视化和增强人类互动。
### Conclusion
本文通过提出基于同心坐标的高维数据分类方法，克服了传统多维数据可视化中的数据重叠问题，并提升了计算效率，为高维数据的分析提供了一种有效的可视化工具。
## 642. `cs.LG` - SynC: 基于一对一到多对一映射策略对合成图像描述数据集进行精炼以增强零样本图像描述 [PDF](https://arxiv.org/pdf/2507.18616), [HTML](https://arxiv.org/abs/2507.18616)
### Authors
Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim
### Background
零样本图像描述（ZIC）越来越多地使用由文本到图像（T2I）模型生成的合成数据集，以减轻对昂贵的手动注释的需求。然而，这些T2I模型生成的图像往往与输入描述间的语义存在偏差（例如，缺少物体、错误的属性），从而产生噪声的数据集，影响模型训练。现有的数据集精简技术主要用于去除网络爬取数据中的噪音文本，但这些方法不适合合成数据面临的独特挑战，因为描述通常结构良好，但图像可能是不准确的表示。这些情况促使研究者们寻找一种新颖的数据精简方法，以解决噪声数据集对模型性能的负面影响，特别是针对合成数据集的问题。
### Innovation
本文提出了SynC，一种新颖的框架，专门用于精炼ZIC中的合成图像-描述数据集。与传统的过滤或重生成方法不同，SynC关注的是将每个描述重新分配给数据集中现成的、语义上最匹配的多张图像。该方法采用了一种一对一到多对一的映射策略，首先为每个描述检索多个相关的候选图像，然后采用循环一致性启发式的对齐评分器，通过验证图像到文本检索的能力来选择最佳的匹配图像。
### Conclusion
广泛的评估表明，SynC能够显著和一致地提升多种ZIC模型在标准基准（MS-COCO、Flickr30k、NoCaps）上的性能，并达到多项最佳表现。这种有效的方法为整理优化的合成数据提供了一种策略，以增强零样本图像描述的性能。
## 643. `cs.LG` - TRPrompt: 从文本奖励中启动具有查询感知的提示优化 [PDF](https://arxiv.org/pdf/2507.18618), [HTML](https://arxiv.org/abs/2507.18618)
### Authors
Andreea Nica,Ivan Zakazov,Nicolas Mario Baldwin,Saibo Geng,Robert West
### Background
大型语言模型（LLMs）的推理能力可以通过提示优化得到提升，而无需更新目标模型的参数。提示优化的方法有两种主要方向：一种方法通过文本反馈来自动生成更好的提示，而另一种方法则依赖于数值奖励来训练专门提示模型，以提供给目标模型最佳提示。本文介绍了一种统一这两种方法的新框架，即Textual Reward Prompt（TRPrompt），通过直接将文本反馈纳入提示模型的训练中，来提高模型的推理能力。
### Innovation
TRPrompt框架通过直接将文本反馈纳入提示模型的训练中，统一了现有的两种方法。该框架不需要预先收集数据，并且可以通过生成提示反馈来进行迭代优化。利用LLM能够理解“优秀”提示的概念以及高分辨率的文本奖励信号，该框架能够训练出针对挑战性数学数据集GSMHard和MATH的问题的最优查询特定提示。
### Conclusion
当结合LLM理解“优秀”提示的能力以及通过文本奖励提供的高分辨率信号时，TRPrompt框架能够训练出针对挑战性数学数据集GSMHard和MATH问题的最优查询特定提示，从而提高了推理能力，达到了最先进的水平。
## 644. `cs.LG` - SIDA: Synthetic Image Driven Zero-shot Domain Adaptation [PDF](https://arxiv.org/pdf/2507.18632), [HTML](https://arxiv.org/abs/2507.18632)
### Authors
Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim
### Background
零样本域适应是一种方法，能在不使用目标域图像数据的情况下适应模型至目标域。现有的研究利用CLIP的嵌入空间和文本描述来模拟目标样式的特征。尽管零样本域适应在之前取得了成就，我们观察到这些基于文本的方法难以捕捉复杂的现实世界变化，并且由于对齐过程，显著增加了适应时间。
### Innovation
提出了SIDA，这是一种利用合成图像的新颖且高效的零样本域适应方法。首先生成详细且源样式的图像，然后应用图像翻译以便反映目标域的风格。使用这些合成图像的风格特征作为目标域的代理。提出了Domain Mix和Patch Style Transfer模块，能够有效建模现实世界的变化。Domain Mix将多种风格融合以扩展域内的表示，而Patch Style Transfer为个体斑块分配不同的风格。
### Conclusion
通过展示在各种零样本适应场景中的表现，特别是具有挑战性的领域，证明了我们方法的有效性。此外，通过大幅减少整体适应时间，实现了方法的高度效率。
## 645. `cs.LG` - 将Adam优化器推广到流形以高效训练变压器 [PDF](https://arxiv.org/pdf/2305.16901), [HTML](https://arxiv.org/abs/2305.16901)
### Authors
Benedikt Brantner
### Background
神经网络的成功部分归功于一系列高效的优化器，特别是Adam优化器的出现，它被广泛用于神经网络的训练，但由于缺乏清晰的物理直觉，很难对其进行解释和推广到流形上。
### Innovation
该研究提出了一种新的方法，利用优化神经网络相关的流形（如Stiefel流形、对称Stiefel流形和Grassmann流形）的特殊结构，通过全球切空间表示法将所有步骤推广到Adam优化器中，从而无需投影步骤即可完全推广优化器到流形。
### Conclusion
最终，将该算法应用于训练了一个需要在机器精度内保持正交性的变压器，观察到训练过程中的显著加速效果。
## 646. `cs.LG` - 混合量子-经典算法在部分可观测马尔可夫决策过程中的近最优规划 [PDF](https://arxiv.org/pdf/2507.18606), [HTML](https://arxiv.org/abs/2507.18606)
### Authors
Gilberto Cunha,Alexandra Ramôa,André Sequeira,Michael de Oliveira,Luís Barbosa
### Background
强化学习（RL）提供了一种在部分可观测环境中进行决策的基本框架，这类环境可以建模为马尔可夫决策过程，并通过动态决策贝叶斯网络紧凑表示。最近的研究表明，可以使用量子拒绝采样结合振幅放大来加速稀疏贝叶斯网络上的推理，从而在估计接受概率时获得计算加速。基于这一结果，我们引入了量子贝叶斯强化学习（QBRL），这是一种用于部分可观测环境中的模型基础RL的混合量子-经典前瞻算法。我们在假设容错的量子设备下进行了严谨的时间复杂性分析。
### Innovation
我们提出了一个名为QBRL的量子算法，这是一种混合量子-经典的前瞻算法，用于部分可观测环境中的模型基础RL。不同于使用黑盒或acles的标准处理方法，我们具体说明了推理过程，使得我们的界限能够更准确地反映真正的计算成本。我们进一步展示了QBRL在简单但说明性的决策任务上的数值实验，对比了它与经典对应物的表现。
### Conclusion
对于动态形成稀疏贝叶斯网络的环境，在量子增强的信念更新的帮助下，基于视野的近最优规划可以实现次二次速度地更快。我们的研究结果显示，量子计算优势在不同部署设置中的应用强度存在显著差异，这表明了在不同场景下量子算法所能带来的性能提升可能有所不同。
## 647. `cs.LG` - 可解释的Mapper：基于扰动解释和验证代理绘制LLM嵌入空间 [PDF](https://arxiv.org/pdf/2507.18607), [HTML](https://arxiv.org/abs/2507.18607)
### Authors
Xinyuan Yan,Rita Sevastjanova,Sinie van der Ben,Mennatallah El-Assady,Bei Wang
### Background
大规模语言模型（LLMs）生成高维嵌入，捕捉词汇、句子和概念间的丰富语义和句法关系。通过Mapper图探索嵌入空间的拓扑结构，可以帮助我们理解其底层结构。然而，手动探索这些嵌入空间以揭示编码的语义特性需要大量的人力。
### Innovation
提出了一种半自动框架，用于标注这些嵌入特性。该框架通过定义mapper图中可探索元素的分类法（如节点、边、路径、组件和轨迹），并采用基于扰动技术的可定制LLM代理进行分析，实现了嵌入特性的可扩展和自动化分析。该框架还展示了如何重复先前关于BERT嵌入特性的研究发现，并提供了对拓扑邻域中语义特性的进一步观察。
### Conclusion
该框架在可视化分析工作空间中被实例化，并通过案例研究展示了其有效性，特别是在重复先前关于BERT嵌入特性的研究发现以及进一步观察拓扑邻域中的语义特性方面取得成果。
## 648. `cs.LG` - 最优传输正则化散度及其在对抗鲁棒性中的应用 [PDF](https://arxiv.org/pdf/2309.03791), [HTML](https://arxiv.org/abs/2309.03791)
### Authors
Jeremiah Birrell,Reza Ebrahimi
### Background
本文讨论了一种新型的最优传输正则化散度(D^c)，它通过信息散度(D)和最优传输成本(C)的下确界卷积构造。作者研究了这些散度在分布鲁棒优化(DRO)中的应用，并提出了一种名为ARMOR_D的方法来提高深层学习模型的对抗鲁棒性。该方法通过在训练数据的经验分布的D^c-邻域上最小化最大预期损失定义。作为一种生成对抗样本的工具，该方法可以将样本按最优传输成本传输，同时根据信息散度重新加权，这一创新点在于在对抗样本传输的基础上增加了有原则的动态对抗重新加权。
### Innovation
1. 引入了一种新的最优传输正则化散度(D^c)，结合了信息散度(D)和最优传输成本(C)，并研究了其在分布式鲁棒优化中的应用。2. 提出了ARMOR_D方法，这是一种新颖的方法，通过在训练数据的经验分布的D^c-邻域上最小化最大预期损失来增强深层学习模型的对抗鲁棒性。3. 在对抗训练文献中，将ARMOR_D应用于UDR、TRADES和MART方法，展示了其灵活性和优越性，尤其是在CIFAR-10和CIFAR-100图像识别上，与AutoAttack相比，改进了1.9%和2.1%。
### Conclusion
本文通过引入新型的最优传输正则化散度(D^c)和ARMOR_D方法，证明了在分布鲁棒优化中这一方法的有效性和实用性，并展示了其在图像识别上的优越性能，增强了对抗鲁棒性领域的方法灵活性和效果。
## 649. `cs.LG` - 高维优化中时间依赖海森矩阵的作用 [PDF](https://arxiv.org/pdf/2403.02418), [HTML](https://arxiv.org/abs/2403.02418)
### Authors
Tony Bonnaire,Giulio Biroli,Chiara Cammarota
### Background
梯度下降是一种常用来在颠簸的景观中寻找最小值的方法，特别是在现代机器学习应用中。虽然它被广泛使用，但关于为什么能找到好的解的理论理解仍然不够充分，特别是在强非凸和高维环境中更是如此。本文聚焦于相位恢复问题，这是一个最近在理论机器学习中受到广泛关注的例子。通过对梯度下降过程中海森矩阵的分析，识别出其谱性质中的动态转变，联系到从粗糙区域逃离的能力。当信噪比足够大时，在下降初期就会存在信息性的负方向，在有限的时间内海森矩阵的谱会发生BBP转变：方向会丢失，动态会被困在充满边缘稳定最优点的崎岖区域中。对于有限大小的系统，这一负曲率窗口可以在理论信噪比发现的值之前使系统很好地恢复信号，强调了初始条件和早期时间动态在高效导航崎岖景观中的核心作用。
### Innovation
研究发现，海森矩阵在高维优化中的时间依赖性质对于寻找全局最优点具有重要影响。通过初期存在信息性的负方向，系统能够更早地逃离崎岖区域。此外，实验证明了在有限系统大小下，负曲率窗口的作用，使得系统可以在理论信噪比之前恢复信号，强调了初始条件和早期时间动态的重要性。
### Conclusion
本文通过对海森矩阵谱性质的动态分析，揭示了在强非凸和高维环境中使用梯度下降寻优的机理及其局限，在实际应用中可以通过优化初始条件和利用早期时间动态有效地提高寻优效率。
## 650. `cs.LG` - 利用未标注数据实现并发积极未标注分类与鲁棒生成 [PDF](https://arxiv.org/pdf/2006.07841), [HTML](https://arxiv.org/abs/2006.07841)
### Authors
Bing Yu,Ke Sun,He Wang,Zhouchen Lin,Zhanxing Zhu
### Background
类标签数据的匮乏是许多机器学习问题中的普遍存在且亟待解决的瓶颈。尽管存在大量的未标注数据，如何有效地利用它们来提高模型性能是一个极具挑战性的任务。
### Innovation
本文提出了一种新颖的训练框架，通过结合 Positive-Unlabeled (PU) 分类和有条件的生成技术，利用额外的未标注数据，特别是异常分布的未标注数据，同时增强 PU 分类器的性能，并利用来自 PU 分类器的预测标签来帮助生成。本文还提出了一种 Robust Classifier-Noise-Invariant Conditional GAN (CNI-CGAN) 来增强分类器的性能，并证明了 CNI-CGAN 的最优条件。
### Conclusion
实验部分对多个不同数据集进行了广泛的评估，实验证明了所提出的框架的有效性和鲁棒性。
## 651. `cs.LG` - DriftMoE: 处理概念偏移的一种专家混合方法 [PDF](https://arxiv.org/pdf/2507.18464), [HTML](https://arxiv.org/abs/2507.18464)
### Authors
Miguel Aspis,Sebastián A. Cajas Ordónez,Andrés L. Suárez-Cetrulo,Ricardo Simón Carbajo
### Background
学习非平稳数据流时，遇到概念漂移需要模型能够在保持资源效率的同时进行实时自适应。现有的自适应集成方法通常依赖粗粒度的自适应机制或简单的投票方案，这些方案无法充分利用专业知识。
### Innovation
DriftMoE 通过一种新颖的协同训练框架，提出了一个紧凑的神经路由器和增量霍夫丁树专家池的在线混合专家架构，实现协同学习循环来提升专家的专业化能力。该模型使用多热正确性掩码来加强每次准确预测的学习信号，促进路由器和专家的自适应优化。
### Conclusion
我们在涵盖急变、渐变和实际世界的九个先进的流式学习基准测试中评估了 DriftMoE 的性能，展示了其与最先进的流式学习自适应集成方法具有竞争力的结果，提供了一种原理上合理且高效的处理概念漂移的方法。代码、数据管道和可重现脚本已在我们公共的 GitHub 仓库提供：this https URL.
## 652. `cs.LG` - 压缩和分布式最小二乘回归：收敛率及其在联邦学习中的应用 [PDF](https://arxiv.org/pdf/2308.01358), [HTML](https://arxiv.org/abs/2308.01358)
### Authors
Constantin Philippenko,Aymeric Dieuleveut
### Background
本文探讨了压缩技术对机器学习中随机梯度算法的影响，这种技术在分布式和联邦学习中广泛应用。研究集中在最小二乘回归（LSR）上，分析了在随机场作用下最小化二次函数的通用随机近似算法。研究还考虑了随机场和噪声协方差的弱假设，以便分析各种随机化机制，包括压缩。
### Innovation
研究超出了传统的最坏情况分析，详细比较了几种方差满足相同条件的无偏压缩操作对收敛率的影响。分析了算法引起的附加噪声协方差对收敛的影响，并证明了即使在随机场不规则的情况下，极限方差项也按照Tr(C_ania H^-1) / K scaling（H是优化问题的海森矩阵，K是迭代次数），这一结果推广了经典的最小二乘回归收敛率σ^2 d / K (Bach和Moulines, 2013)。
### Conclusion
研究进一步探讨了压缩策略对协方差C_ania的影响，并分析其对收敛的影响，在中心化情况下进行了高级别分析，然后在两个异构联邦学习框架中进行了探讨。
## 653. `cs.LG` - 实时从深度学习表示中进行无监督概念漂移检测 [PDF](https://arxiv.org/pdf/2406.17813), [HTML](https://arxiv.org/abs/2406.17813)
### Authors
Salvatore Greco,Bartolomeo Vacchetti,Daniele Apiletti,Tania Cerquitelli
### Background
概念漂移是指目标领域中的底层数据分布和统计特性随时间发生变化的现象，这会导致模型性能下降。因此，生产模型需要持续的概念漂移检测监控。到目前为止，大多数漂移检测方法依赖于监督学习，依赖真实标签。然而，在许多实际应用场景中，真实标签往往是不可用的。尽管近年来提出了一些无监督的漂移检测方法，但许多方法的准确性不足，难以在高维大规模的实际生产环境中实时使用。此外，它们往往不能有效地描述或解释漂移现象。
### Innovation
本文提出了一种名为DriftLens的无监督框架，用于实时概念漂移检测和解释。DriftLens专门针对处理非结构化数据的深度学习分类器设计，通过利用深度学习表示的距离来实现高效且准确的检测。它通过分析和解释每个标签的影响来刻画漂移现象，即使得无监督的漂移检测能够广泛应用于更多场景。该方法在多个分类器和数据类型上进行评估，结果显示DriftLens在15/17个案例中优于先前方法，在速度上快5倍，并且产生的漂移曲线下降到实际漂移的皮尔逊相关系数至少为0.85。此外，DriftLens能够有效地识别代表性的漂移样本作为解释。
### Conclusion
本文提出了一种名为DriftLens的无监督框架，该框架通过利用深度学习表示的距离，实现高效且准确的概念漂移检测。该框架还通过分析和解释每个标签的影响来刻画漂移现象，并在多个分类器和数据类型上展示了其卓越性能。
## 654. `cs.LG` - 超越欧几里得：基于几何、拓扑和代数结构的现代机器学习的图解指南 [PDF](https://arxiv.org/pdf/2407.09468), [HTML](https://arxiv.org/abs/2407.09468)
### Authors
Mathilde Papillon,Sophia Sanborn,Johan Mathe,Louisa Cornelis,Abby Bertics,Domas Buracas,Hansen J Lillemark,Christian Shewmake,Fatih Dinc,Xavier Pennec,Nina Miolane
### Background
经典机器学习的持久遗产基于欧几里得几何，多年来主要集中在欧几里得空间中的数据处理。然而，现代机器学习广泛遇到天然非欧几里得结构的数据，这些数据复杂且包含内在的几何、拓扑和代数结构。从时空曲率的几何学到脑神经元间拓扑复杂的相互作用，再到描述物理系统对称性的代数变换，从这些非欧几里得数据中提取知识需要更广泛的高度数学视角。
### Innovation
该研究领域正在重新定义现代机器学习，引入非欧几里得结构。目标是将传统的机器学习方法推广到几何学、拓扑学和代数结构特性中不常规的数据类型。研究还提出了一种基于图形的教学大纲，整合了最近的发展，形成直观的一体化框架，进一步探讨当前挑战并展望未来发展的激动人心的机会。
### Conclusion
本文提供了对这一快速发展的领域的一个易于访问的入门，并将最近的进展整合到一种直观的一致性框架中。进一步提取了当前挑战的见解，并突出了未来发展的激增机会。
## 655. `cs.LG` - 在随机子空间中对LLMs进行零阶调优 [PDF](https://arxiv.org/pdf/2410.08989), [HTML](https://arxiv.org/abs/2410.08989)
### Authors
Ziming Yu,Pan Zhou,Sike Wang,Jia Li,Mi Tian,Hua Huang
### Background
大规模语言模型（LLMs）的微调在多种下游任务中表现出色。然而，随着LLMs规模的增大，反向传播所需的内存需求变得日益不可行。零阶（ZO）优化方法通过使用前向传递估计梯度来提供一个内存高效的替代方案，但是梯度估计的方差通常与模型参数维度成线性关系——这是LLMs的一个显著问题。
### Innovation
本文提出了一种针对LLMs高维度挑战的随机子空间零阶（SubZero）优化方法。引入了一种针对LLMs的低秩扰动，显著降低了内存消耗并提高了训练性能。此外，证明了该梯度估计接近反向传播梯度，方差低于传统ZO方法，并与SGD结合时保证了收敛性。实验结果显示，SubZero在各种语言建模任务中提高了微调性能，并实现了更快的收敛速度，相比标准ZO方法（如MeZO）更优
### Conclusion
实验结果表明，SubZero增强了微调性能，并实现了相比于传统ZO方法更快的收敛速度，适用于各种语言建模任务。代码可在此处获得：this https URL.
## 656. `cs.LG` - 微调的语言模型生成文本中的稳定无机材料 [PDF](https://arxiv.org/pdf/2402.04379), [HTML](https://arxiv.org/abs/2402.04379)
### Authors
Nate Gruver,Anuroop Sriram,Andrea Madotto,Andrew Gordon Wilson,C. Lawrence Zitnick,Zachary Ulissi
### Background
本文背景在于提出了一种新颖的方法，即通过微调大型语言模型来生成稳定材料的结构。通常，这种方法是不常见的，但在文本编码的原子数据上进行微调却简便可靠，大约有90%的采样结构遵循了原子位置和电荷的物理约束。
### Innovation
创新在于使用大型语言模型在文本数据上进行微调，生成稳定材料。这一方法显示出较高的可靠性和效率，较之其他方法，可以更快速地生成预测为亚稳态的材料。此外，文本提示的灵活性使得模型同时可以用于无条件生成稳定材料、填补结构空缺以及条件生成。
### Conclusion
研究结论指出，随着模型规模的增加，语言模型捕捉晶格结构关键对称性的能力也在增强，暗示预训练的大规模语言模型的偏见特别适合于原子数据。最终表明，我们提出的微调语言模型在生成稳定无机材料方面具有显著优势，能够以更高的速率生成预测为亚稳态的材料。
## 657. `cs.LG` - 通过碰撞进行细粒度不确定性量化 [PDF](https://arxiv.org/pdf/2411.12127), [HTML](https://arxiv.org/abs/2411.12127)
### Authors
Jesse Friedbaum,Sudarshan Adiga,Ravi Tandon
### Background
本文提出了一种新的、直观的不确定性量化（UQ）度量标准，即类碰撞的普遍性，定义为相同输入在同一模型中被观测到属于不同类别的频率。基于类碰撞率定义了碰撞矩阵，这是一种新颖且独特的不确定性量度，用于分类问题中衡量区分K个类之间的每个类对的固有难度。此外，还介绍了现有UQ方法如贝叶斯错误率（BER）与碰撞矩阵的关系。
### Innovation
本文的主要创新包括：1) 将碰撞率用于定义碰撞矩阵，这是一种精细度量不确定性的新方法；2) 利用对比模型接受两个输入并确定它们是否属于同一类别，进而估计碰撞矩阵的格满分矩阵；3) 最终，在合理假设下，展示了使用格满分矩阵可以唯一恢复碰撞矩阵的方法，这为非负矩阵提供了一个新的结果，可以独立应用；4) 利用碰撞矩阵估计，结合对比模型估计任意点的后验类别鲁棒性分布，并通过实验验证了该方法的有效性。
### Conclusion
本文提出了一种新的方法来估计碰撞矩阵和类后验分布，并通过实验验证了其有效性。这种方法能够更精细地量化不确定性，尤其是在类碰撞方面，为其应用提供了可能。
## 658. `cs.LG` - 历史引导的视频扩散 [PDF](https://arxiv.org/pdf/2502.06764), [HTML](https://arxiv.org/abs/2502.06764)
### Authors
Kiwhan Song,Boyuan Chen,Max Simchowitz,Yilun Du,Russ Tedrake,Vincent Sitzmann
### Background
分类器自由引导（CFG）技术是改进扩散模型中条件生成的关键方法，它可以通过更好地控制生成过程来提升样本质量。然而，视频扩散需要根据变量数量的历史帧进行条件生成，这带来了两个主要挑战：只有支持固定大小条件的架构，以及在CFG样式的历史随机删除方法在实践中表现不佳。
### Innovation
本文提出了扩散强制变换器（DFoT），这是一种视频扩散架构及理论支持的训练目标，可同时支持灵活数量的历史帧条件。此外，还引入了历史引导方法，这是由DFoT独特地启用的一系列引导方法。初步形式的‘纯’历史引导在提高视频生成质量和时序一致性方面已经取得了显著效果。更进一步的方法‘时间与频率的历史引导’不仅增强了动作动态性，还使生成能够对未知历史实现组件化泛化，并且能够稳定生成极长的视频片段。
### Conclusion
本文所提出的DFoT架构和基于此的指导方法有效地解决了视频扩散过程中遇到的挑战，并展示了优异的视频生成质量和时序一致性。
## 659. `cs.LG` - 分析计算机视觉和自然语言处理模型的公平性 [PDF](https://arxiv.org/pdf/2412.09900), [HTML](https://arxiv.org/abs/2412.09900)
### Authors
Ahmed Rashed,Abdelkrim Kallich,Mohamed Eltayeb
### Background
机器学习算法在医疗、金融、教育和执法等多个领域中起着关键作用。然而，这些系统中的公平性和偏见问题引起了重大的伦理和社会挑战。研究人员利用了微软和IBM的两个公平性库：Fairlearn和AIF360，这些库提供了全面的公平性分析框架，包括评估公平性指标、可视化结果和实现偏见缓解算法的工具。研究重点是对于结构化和非结构化数据集（特别是计算机视觉和自然语言处理模型）的偏见评估与缓解。研究的主要目标是对这两个公平性库中的偏见缓解算法进行比较分析，评估它们在机器学习生命周期的不同阶段（预处理、处理中或处理后）及其组合应用中的有效性。选择了公开可获取的Kaggle数据集进行研究，以实现在真实世界机器学习工作流程中的公平性评估背景
### Innovation
研究利用了Fairlearn和AIF360这两个主流的公平性库进行偏见评估与缓解的比较分析。研究指出了在不同的机器学习生命周期阶段应用偏见缓解算法的效果差异，并发现某些组合应用可以有效降低偏见同时保持模型性能。这一研究提供了在实际机器学习流程中评估和改进模型公平性的实用方法与指导
### Conclusion
研究通过实证分析验证了两种主流公平性库所提出的偏见缓解算法的性能，并探讨了其在不同阶段应用的有效性。研究结果表明，在某些情况下，算法的组合应用比单一应用能更有效地降低偏见，同时保持模型性能。这项研究提供了对机器学习模型公平性改进的深入理解，并为未来的研究和实际应用提供了参考。
## 660. `cs.LG` - 基于原则的数据偏见缓解方法 [PDF](https://arxiv.org/pdf/2405.12312), [HTML](https://arxiv.org/abs/2405.12312)
### Authors
Bruno Scarone,Alfredo Viola,Renée J. Miller,Ricardo Baeza-Yates
### Background
近年来，机器学习和数据驱动算法在决策中的广泛应用日益增加。数据中的偏见会负面影响这些决策。本文解决数据偏见问题。
### Innovation
本文提出了一种新的缓解策略，方法具有解释性和数学正确性保障，并能利用新的表发现工作，在数据集上找到新的元组以增强数据集，使之更加无偏或少偏。这类框架覆盖了具有非二元标签和多个敏感属性的数据。通过这种方法，可以测量和缓解不仅单一属性（或特征）而且多种属性组合所呈现的偏见。文章在公开数据集上评估了这些技术，并对结果进行了理论分析，揭示了关于数据偏见的新型见解。
### Conclusion
总体而言，本文提出了一个新的数据偏见缓解策略，该策略能够解决单一属性和多重属性组合中的偏见问题，并通过理论分析证明其有效性和正确性。
## 661. `cs.LG` - 利用基础模型推进金融工程：进展、应用与挑战 [PDF](https://arxiv.org/pdf/2507.18577), [HTML](https://arxiv.org/abs/2507.18577)
### Authors
Liyuan Chen,Shuoling Liu,Jiangpeng Yan,Xiaoyu Wang,Henglin Liu,Chuang Li,Kecheng Jiao,Jixuan Ying,Yang Veronica Liu,Qiang Yang,Xiu Li
### Background
基础模型（FMs）作为一种大规模预训练模型，具备强大的泛化能力，正在为金融工程打开新的领域。尽管通用基础模型（如GPT-4和Gemini）在财务报告总结、情感驱动预测等多种任务上展现了潜力，但许多金融应用仍受限于多模态推理、合规性和数据隐私等特殊需求。
### Innovation
这篇论文提出了金融基础模型（FFMs），这是一种专门设计用于金融领域的新型模型类别。并构建了一个涵盖三个关键模态（金融语言基础模型FinLFMs、金融时间序列基础模型FinTSFMs、金融视觉语言基础模型FinVLFMs）的分类体系，概述了它们的架构、训练方法、数据集和实际应用，指出了数据可用性、算法可扩展性和基础设施限制等关键挑战，并提出了未来研究的机会。
### Conclusion
本文旨在提供关于FFMs的全面参考，并为未来的创新提供实用的道路图。还将更新FFM相关出版物和资源的集合，链接为：this https URL
## 662. `cs.LG` - 评估大规模语言模型生成合成数据的多维度框架 [PDF](https://arxiv.org/pdf/2404.14445), [HTML](https://arxiv.org/abs/2404.14445)
### Authors
Yefeng Yuan,Yuhong Liu,Liang Cheng
### Background
随着生成AI和大型语言模型（LLMs）的快速发展，特别是在生成合成数据方面，尤其是在结构化的表格格式（如产品评论）的应用领域。尽管可以利用这种技术带来的潜在好处，但当使用个人数据进行训练时，隐私泄露的风险引起了关注。当前，尚未有可用于定量评估生成的合成数据质量及其下游任务实用性的综合评价框架。为填补这一空白，作者提出了SynEval，这是一个开源的评价框架，通过一系列多样化的评估指标，用于评估生成的合成表格数据的真实度、实用性和隐私保护情况。
### Innovation
作者研发了名为SynEval的多维度评估框架，该框架可以定量评估由LLMs生成的合成数据的质量和实用性，特别是针对合成的表格数据。该研究通过实际应用实验验证了SynEval的有效性，并揭示了不同评估指标在合成数据生成中的权衡关系。
### Conclusion
SynEval作为一个关键工具，对合成表格数据的使用者来说至关重要。它使研究人员和从业者能够根据具体的使用场景和要求，明智地选择合适的合成数据，从而确保用户的隐私得到保护。实验结果还展示了不同评估指标在合成数据生成中的相互关系，对于改进合成数据技术具有重要意义。
## 663. `cs.LG` - 使用ARMA模型逼近平稳过程 [PDF](https://arxiv.org/pdf/2408.10610), [HTML](https://arxiv.org/abs/2408.10610)
### Authors
Anand Ganesh,Babhrubahan Bose,Anand Rajagopalan
### Background
本文重访与自回归滑动平均（ARMA）模型相关的经典问题，即量化和限制实际平稳过程$X_t$与ARMA模型$Y_t$之间的近似误差。
### Innovation
本文采用ARMA模型的传递函数表示，并证明了相关的$L^{fty}$范数提供了一种有效替代的范数，可以控制$L^2$范数，且与倒谱范数具有可比的结构性质。证明了一个包括ARMA模型的平稳过程子空间，在$L^{fty}$范数下形成了一个尊重$H^{fty$传递函数群结构的巴拿赫代数。在此代数中的可逆性定义与原始的ARMA可逆性定义一致，并且相对于维纳的$rm boldsymbol{ell}^1$条件对非ARMA过程有更好的推广性。
### Conclusion
在连续传递函数的较简单背景下，计算了一些显式的逼近界，并对Padé逼近和精简模型的一些启发性观点进行了批判。
## 664. `cs.LG` - 使用半编码术语和大语言模型分析伊斯兰恐惧症言论 [PDF](https://arxiv.org/pdf/2503.18273), [HTML](https://arxiv.org/abs/2503.18273)
### Authors
Raza Ul Mustafa,Roi Dupart,Gabrielle Smith,Noman Ashraf,Nathalie Japkowicz
### Background
近年来，伊斯兰恐惧症在西方社会中日益增长，这主要得益于数字通信网络的兴起。本文针对极端社交平台上泛滥的半编码伊斯兰恐惧症术语（如muzrat、pislam、mudslime、mohammedan、muzzies）进行了大规模分析，这些术语在特定语境之外通常无义或模糊，对人类审查者和自动化系统来说难以可靠地识别为仇恨言论。
### Innovation
本研究使用大型语言模型（LLMs）展示了它们理解这些术语的能力。研究表明，这些模型能够识别非词典中的侮辱性用语，但尚需进一步改进管理策略和算法检测方法来有效应对此类言论。此外，通过BERT主题建模方法提炼出的话题表明，伊斯兰恐惧症言论存在于各种政治、阴谋和极右运动中，尤其针对穆斯林移民。
### Conclusion
本研究是首次针对伊斯兰恐惧症半编码术语的研究之一，对全球伊斯兰恐惧症现象提供了新的见解，强调了进一步优化管理策略和算法检测的重要性。
## 665. `cs.LG` - DualXDA: 向大规模AI模型中稀疏、高效和可解释的数据属性方向发展 [PDF](https://arxiv.org/pdf/2402.12118), [HTML](https://arxiv.org/abs/2402.12118)
### Authors
Galip Ümit Yolcu,Moritz Weckbecker,Thomas Wiegand,Wojciech Samek,Sebastian Lapuschkin
### Background
深度学习模型虽然取得了显著的性能，但其决策过程往往不易理解。为了解决这一问题，可解释人工智能(XAI)在近年来得到了显著的发展，主要集中在特征归因方法上。同时，数据归因(DA)作为一种新的范式逐渐兴起，但现有方法存在计算成本高、内存需求大和稀疏性低的问题，限制了关键模式的发现。
### Innovation
本文提出了一种名为DualXDA的新框架，该框架包含两个相关的数据归因技术：DualDA和XDA。DualDA利用支持向量机理论，提供快速且自然稀疏的数据归因，相比于原Influence Functions方法，DualDA在解释时间上提升了410万倍，相比于最有效的方法提升了11000倍。XDA则结合了特征归因方法的能力，解释训练样本对于预测测试样本的重要性。DualXDA旨在将可解释的人工智能应用到前所未有的规模，使大型神经架构的透明分析成为可能，促进新型问责制AI系统的出现。
### Conclusion
我们的贡献最终指向了一种前所未有的规模下可解释的人工智能应用，实现了透明、高效和新颖的大型神经架构分析，推动了新一代问责制AI系统的发展。
## 666. `cs.LG` - 一个经验主义接地的可识别性理论将加速自监督学习研究 [PDF](https://arxiv.org/pdf/2504.13101), [HTML](https://arxiv.org/abs/2504.13101)
### Authors
Patrik Reizinger,Randall Balestriero,David Klindt,Wieland Brendel
### Background
自监督学习（SSL）推动了诸多当前的人工智能系统。尽管SSL的设计空间不断扩大，PLATO式视角认为所有方法最终将收敛到同一理想的表示形式，但这一现象缺乏严谨的理论解释。现有的可识别性理论（IT）无法解释SSL的经验成功。
### Innovation
提出了扩展现有的IT为单识别性理论（SITh），这是一种涵盖整个SSL管道的更广泛理论框架。SITh将提供对SSL中的潜在数据假设的更深入洞察，并推动自监督学习向学习更具有可解释性和泛化能力的表示形式迈进。指出了未来研究的三个关键方向：1）SSL训练动态和收敛特性；2）有限样本、批量大小和数据多样性的影响；3）归纳偏置在架构、增强、初始化方案和优化器中的作用。
### Conclusion
SITh将有助于弥合理论与实践之间的差距，并推动自监督学习研究的进步。
## 667. `cs.LG` - 零阶对数凹分布采样 [PDF](https://arxiv.org/pdf/2507.18021), [HTML](https://arxiv.org/abs/2507.18021)
### Authors
Yunbum Kook
### Background
本文研究了对数凹分布（尤其是凸体上的等概采样）的零阶查询复杂性。文章探讨了如何使用成员查询来实现接近均匀分布的采样，并在此过程中提出了一种简单的近端采样变体，同时减轻了初始温度和最终输出保证之间的匹配Rényi指数。文章进一步提出了一种简单的退火方案，旨在减少查询数量并达到目标。
### Innovation
文章提出了一种简单的近端采样变体，通过成员查询实现均匀分布的采样，并通过退火方案来缓解初始温度与最终输出之间的匹配Rényi指数问题。此外，该研究通过退火方案下的同时热流超合同性来改善近端采样器在对数索波列夫不等式下的混合保证。
### Conclusion
这些研究成果自然地适用于通过评估查询来访问的一般对数凹分布，额外增加了二次查询。总体而言，这篇文章通过结合零阶查询和梯度信息，大大提高了对数凹分布采样的效率与准确性。
## 668. `cs.LG` - VCDiag: 通过VCD数据分类错误波形以加速故障排查 [PDF](https://arxiv.org/pdf/2506.03590), [HTML](https://arxiv.org/abs/2506.03590)
### Authors
Minh Luu,Surya Jasper,Khoi Le,Evan Pan,Michael Quinn,Aakash Tyagi,Jiang Hu
### Background
设计功能验证中的故障分类对于确保系统可靠运行至关重要，但这一过程十分耗时，通常依赖于手动规格审查、日志检查和波形分析。尽管机器学习（ML）已经在刺激生成和缺陷覆盖率等方面取得了进步，但在实现等级（RTL）级仿真故障分类的应用上，特别是针对大型设计方面仍然受到限制。
### Innovation
VCDiag提供了一种高效且灵活的方法，利用VCD数据来分类故障波形并明确可能的故障位置。它在大型实验中实现了超过94％的准确率，能够识别最有可能出错的前三模块。该框架引入了一种新颖的信号选择和统计压缩方法，能够有效减少原始数据量（超过120倍的减少）同时保留对分类必要的特征，同时也具有与不同Verilog/SystemVerilog设计和测试平台的兼容性。
### Conclusion
VCDiag通过VCD数据有效地分类错误波形，提高了故障分类的效率和准确性，克服了现有技术在大型设计中的限制，并提供了灵活性和可扩展性。
## 669. `cs.LG` - 基于结果的在线强化学习：算法和基本局限 [PDF](https://arxiv.org/pdf/2505.20268), [HTML](https://arxiv.org/abs/2505.20268)
### Authors
Fan Chen,Zeyu Jia,Alexander Rakhlin,Tengyang Xie
### Background
强化学习在需要基于结果反馈进行学习的情况下面临一个基本挑战：当奖励只在轨迹的终点才能被观察到时，如何给正确的动作赋予正确的信用度？该论文对这个问题在一般函数逼近的在线强化学习中进行了第一次全面分析。
### Innovation
开发了一种可证明样本高效的算法，其样本复杂度为 Θ(O(C_{cov} H^3)/μ^2)，其中 C_{cov} 是潜在 MDP 的覆盖系数。通过利用一般函数逼近，该方法在大或无限状态空间中有效工作，仅需评估函数和奖励函数能够由适当函数类表示。此外，论文还整理分析了基于结果反馈与逐步奖励的统计分离情况，揭示了某些 MDP 的不可避免指数级分离。对于确定性 MDP，展示了如何消除完整性假设，大幅简化了算法。还进一步将这种方法扩展到基于偏好的反馈设置中，证明即使在有限信息下也能获得等效的统计效率。
### Conclusion
这些结果为理解基于结果的强化学习的统计性质提供了理论基础。
## 670. `cs.LG` - 通过鲁棒性估计实现大型语言模型的统计运行时验证 [PDF](https://arxiv.org/pdf/2504.17723), [HTML](https://arxiv.org/abs/2504.17723)
### Authors
Natan Levy,Adiel Ashrov,Guy Katz
### Background
对于在实时关键型应用中部署的大规模语言模型（LLMs），确保其对抗鲁棒性是至关重要的。然而，传统的形式化验证技术由于其指数级的运行时间和必须的白盒访问要求，对于现代LLMs来说仍然计算上不可行。因此，本文提出了一种案例研究，即采用并扩展RoMA统计验证框架，以评估其作为黑色盒部署环境下在线运行时鲁棒性监控的可行性。
### Innovation
本文通过适配RoMA统计验证框架，分析了在语义扰动下置信度分数分布，提供具有统计验证边界的定量鲁棒性评估。实验结果表明，RoMA在准确度方面与形式验证基线相比差异不超过1%，并且将验证时间从几小时缩短到几分钟。此外，本文在语义、类别和拼写领域评估了此框架，表明RoMA在实际操作中的鲁棒性监控能力，尤其是在形式化方法不可行时，RoMA可能是一个可扩展的替代方案。
### Conclusion
RoMA框架的有效性得到了验证，尤其适用于那些形式方法不适用的场景。这些发现凸显了RoMA在基于LLM的系统实时验证方面的潜力。
## 671. `cs.LG` - 关于带有残差连接学习Transformer的梯度下降收敛性 [PDF](https://arxiv.org/pdf/2506.05249), [HTML](https://arxiv.org/abs/2506.05249)
### Authors
Zhen Qin,Jinxin Zhou,Zhihui Zhu
### Background
Transformer模型在科学和工程等多个领域中被广泛应用，其在各种应用中的表现非常出色。然而，尽管取得了显著的实际效果，Transformer的理论基础仍然相对不够完善，尤其是在理解其训练动态方面。现有的研究主要集中在自注意力机制和前馈网络等单个组件上，而没有充分探讨这些组件之间相互依赖的关系，尤其是在存在残差连接的情况下。本研究旨在通过分析一个结构完整但单层的Transformer（包括自注意力、前馈网络和残差连接），来填补这一空白，以理解其收敛行为。
### Innovation
本文的主要创新在于，通过分析一个结构完整但单层的Transformer模型，研究了其在适当初始化下的梯度下降收敛行为。研究发现，梯度下降在适当初始化下表现出线性收敛速率，收敛速度取决于自注意力层输出矩阵的最小和最大奇异值。此外，研究揭示了残差连接如何改善输出矩阵的病态条件，从而促进优化稳定性。研究还扩展到多层Transformer架构，确认了在合适初始化下梯度下降的线性收敛率。
### Conclusion
理论分析和实验证据表明，残差连接在促进收敛稳定性方面具有积极作用。这为理解Transformer模型的训练动态提供了新的视角，并为改进Transformer的设计提供了理论依据。
## 672. `cs.LG` - Unisoma: 一种基于统一Transformer的多固体系统求解器 [PDF](https://arxiv.org/pdf/2506.06021), [HTML](https://arxiv.org/abs/2506.06021)
### Authors
Shilong Tao,Zhe Feng,Haonan Sun,Zhanxing Zhu,Yunhuai Liu
### Background
多固体系统在许多实际应用中非常重要，但由于其复杂的相互作用，建模这些系统一直具有挑战性。现有深度学习方法主要依赖于隐式建模，其中影响固体变形的因素不是显式表示的，而是间接学习的。然而，当固体数量增加时，这些方法难以准确捕捉精细的物理相互作用。因此，迫切需要一种能够更精确处理多固体系统复杂交互的新方法。
### Innovation
本文提出了一种新的显式建模范式，通过结构化模块引入影响固体变形的因素。具体来说，提出了一种统一且灵活的基于Transformer的模型Unisoma，能够处理不同数量的固体。Unisoma直接利用接触模块和可调节交互分配机制捕获物理交互，通过三元关系学习变形。与隐式建模技术相比，明确建模更适合处理多样耦合模式的多固体系统，因为它能够逐个详细处理每个固体，防止信息混叠和混淆。
### Conclusion
实验结果表明，Unisoma在七个广泛认可的数据集和两个复杂多固体任务上都取得了持续的最先进的性能。该模型的代码可以在以下网址获得。
## 673. `cs.LG` - 超越低秩分解：一种高效的设备端学习捷径方法 [PDF](https://arxiv.org/pdf/2505.05086), [HTML](https://arxiv.org/abs/2505.05086)
### Authors
Le-Trung Nguyen,Ael Quelennec,Van-Tam Nguyen,Enzo Tartaglione
### Background
设备端学习作为一种有前途的AI发展方向，特别因其在减少设备与服务器通信延迟问题、缓解隐私风险和提高能源效率方面的潜在优势而受到关注。然而，内存和计算能力的巨大限制仍然是其部署的主要障碍。
### Innovation
借鉴了以前关于低秩分解方法的研究，本研究提出了一种新颖的捷径方法，旨在替代现有的解决反向传播激活内存瓶颈的方法。实验表明，该方法不仅能够将激活内存使用量降低至最低120.09倍（与原始训练相比），还能将整体训练FLOPs减少至最高1.86倍。
### Conclusion
我们的方法在传统基准测试中展示了显著的性能提升，通过减少内存使用和计算量，为设备端学习的高效实现提供了新的可能性。
## 674. `cs.LG` - Pulse-PPG: 适用于实验室和现场多种应用场景的开源野外训练PPG基础模型 [PDF](https://arxiv.org/pdf/2502.01108), [HTML](https://arxiv.org/abs/2502.01108)
### Authors
Mithun Saha,Maxwell A. Xu,Wanting Mao,Sameer Neupane,James M. Rehg,Santosh Kumar
### Background
由于光电容积描记图（PPG）在生物信号监测中的广泛应用及其跨多种健康应用的潜在推广能力，基于PPG的数据基础模型开始受到关注。现有的PPG基础模型要么是开源的但使用的是临床数据训练，要么是闭源的，限制了它们在实际现场环境中的应用。
### Innovation
本文介绍了Pulse-PPG，这是首个专为120名参与者为期100天的现场研究收集的未审查PPG数据训练的开源基础模型。此外，Pulse-PPG在多种数据集和下游任务上进行评估，结果表明，该模型在训练过程中接触实际世界的多样性能够更好地泛化，并且在某些任务上，基于野外数据的预训练效果甚至优于基于临床数据的预训练。
### Conclusion
Pulse-PPG展示了其在临床和移动健康应用中的优越泛化能力，在实验室和现场环境都表现出更优性能。该模型的学习能力和适应性跨任务得以验证。为了促进进一步基于野外数据的稳健基础模型研究，研究人员将可以使用Pulse-PPG，为开发更加泛化的PPG基础模型提供强大的资源支持。
## 675. `cs.LG` - 肽识别的一般语言模型 [PDF](https://arxiv.org/pdf/2502.15610), [HTML](https://arxiv.org/abs/2502.15610)
### Authors
Jixiu Zhai,Tianchi Lu,Haitian Zhong,Ziyang Xu,Yuhuan Liu,Shengrui Xu,Jingwan Wang,Dan Huang
### Background
准确识别生物活性肽（BPs）及蛋白质翻译后修饰（PTMs）对于理解蛋白质功能和推动治疗发现至关重要。然而，现有的大多数计算方法在处理不同肽类功能方面缺乏普适性。
### Innovation
本文提出了一种统一的深度学习框架PDeepPP，该框架结合了预训练的蛋白质语言模型和混合变换器-卷积架构，能够在多种肽类和修饰位点上实现稳健的识别。通过建立全面的基准数据集并采用策略解决数据不平衡问题，PDeepPP能够系统地提取全局和局部序列特征。经广泛分析，PDeepPP展示了强大的、可解释的肽表示，并在33个生物识别任务中有25个任务达到了最先进的性能。特别地，在抗菌肽、磷酸化位点识别方面PDeepPP表现出高精度，在糖基化位点预测方面具有99.5%的特异性，并在抗疟疾任务中显著减少了假阴性。
### Conclusion
PDeepPP通过支持大规模、准确的肽分析，支持生物医学研究和疾病治疗中的新型治疗靶点发现。所有代码、数据集和预训练模型均可通过GitHub和Hugging Face获取。
## 676. `cs.LG` - DeepCrossAttention: 加强Transformer残差连接 [PDF](https://arxiv.org/pdf/2502.06785), [HTML](https://arxiv.org/abs/2502.06785)
### Authors
Mike Heddes,Adel Javanmard,Kyriakos Axiotis,Gang Fu,MohammadHossein Bateni,Vahab Mirrokni
### Background
Transformer 网络在各种领域都取得了显著的成功，这得益于包括残差连接在内的多种架构创新。传统的残差连接虽好，但简单地将上一层的输出相加可能会稀释重要信息。
### Innovation
引入了 DeepCrossAttention (DCA)，这是一种增强残差学习的技术。DCA 利用可学习的、输入依赖的权重动态地组合层输出，使模型能够有选择地关注上一层中最相关的信息。此外，DCA 还引入了深度卷积交叉注意力，允许不同深度层之间进行更丰富的交互。
### Conclusion
在语言建模实验中，DCA 在给定的训练时间内实现了更好的困惑度。DCA 还在增加几乎可以忽略的参数数量的情况下达到了与原模型相当的质量，训练速度提高了 3 倍。理论分析表明，在集体层秩与环境维度之比低于某个临界阈值时，DCA 提供了更好的准确性与模型大小之间的权衡。
## 677. `cs.LG` - LLM Web Dynamics：在LLM网络中追踪模型崩溃 [PDF](https://arxiv.org/pdf/2506.15690), [HTML](https://arxiv.org/abs/2506.15690)
### Authors
Tianyu Wang,Akira Horiguchi,Lingyou Pang,Carey E. Priebe
### Background
合成数据在公共互联网中的使用增强了大规模语言模型（LLM）训练的数据使用效率。然而，模型崩溃的潜在威胁尚未得到充分探索。现有的研究主要关注单一模型中的模型崩溃，或仅依赖统计替代品进行分析。背景强调了现有研究的局限性和需要进一步深入研究的需求。
### Innovation
本文介绍了一种名为LLM Web Dynamics（LWD）的有效框架，用于在网络层面研究模型崩溃现象。通过使用检索增强生成（RAG）数据库模拟互联网，分析模型输出的收敛模式。此外，通过将此收敛性与交互式高斯混合模型类比，提供了理论上的保证。创新点在于提出了网络层面的研究方法，并提供了收敛性的理论支撑。
### Conclusion
LWD框架能够有效地在网络层面分析模型崩溃的规律，并通过理论证明其收敛性。这不仅为理解模型在复杂网络环境下的行为提供了新的视角，也为未来的模型开发和安全性评估提供了重要参考。
## 678. `cs.LG` - 高维异方差噪声条件下的欧几里得距离反变换 [PDF](https://arxiv.org/pdf/2507.18520), [HTML](https://arxiv.org/abs/2507.18520)
### Authors
Keyi Li,Yuval Kluger,Boris Landa
### Background
在机器学习和数据分析算法中，成对的欧几里得距离计算是一个基础步骤。但在实际应用中，这些距离经常受到异方差噪声的扭曲，这是一种在不同数据观测中具有变异数量的非均匀破坏形式。这种噪声以非平凡方式扩大计算出的距离，导致底层数据几何结构的误表征。
### Innovation
本文提出了一种无超参数的原理性方法，可以在高维空间中可靠地估计每个观测的噪声幅度并修正成对的欧几里得距离，无需假设清洁数据结构或噪声分布的先验知识，并且即使噪声水平差异显著也是如此。此外，该方法提供了对噪声幅度和距离估计误差的概率上界，随着特征维度和数据集大小的增加，这些上界以多项式速率趋近于零。
### Conclusion
在合成数据集上的实验表明，本方法能够准确估计在复杂环境中距离，显著提高了基于距离的后续计算的鲁棒性。此外，当应用于单细胞RNA测序数据时，该方法估计的噪声幅度与已建立的典型模型一致，使准确的最近邻识别成为许多后续分析的基础。
## 679. `cs.LG` - BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning [PDF](https://arxiv.org/pdf/2507.07769), [HTML](https://arxiv.org/abs/2507.07769)
### Authors
Ruohong Liu,Jack Umenberger,Yize Chen
### Background
近年来，基于强化学习（RL）方法的建筑能源管理取得了显著进展。尽管在模拟或控制环境中观察到了个体成功率，但RL方法在效率和在不同建筑动力学和运维场景下的一般化能力方面仍是一个开放的问题。本文通过正式定义跨环境多目标建筑能源管理任务的空间，并构建了多目标上下文强化学习问题的公式化，来理解适应不同运营环境下的学习策略挑战，如气候和热对流动态下的舒适度和能耗控制目标。
### Innovation
本文提供了在现实的建筑RL环境中参数化上下文信息的规范方式，并构建了一个新的基准来促进评估具有泛化能力的RL算法在实际建筑控制任务中的表现。现有方法在不同环境变化下的表现表明，需要将动力学相关的上下文信息纳入策略学习过程以提高其表现，从而强调了该方法的重要性。
### Conclusion
现有基于多目标RL的方法能够在冲突目标之间实现合理的权衡，但在某些环境变化下表现不佳，强调了在策略学习过程中整合动力学相关上下文信息的重要性。
## 680. `cs.LG` - 时间序列特征归因中为何会发生类别依赖性评估效应？一种合成数据调查 [PDF](https://arxiv.org/pdf/2506.11790), [HTML](https://arxiv.org/abs/2506.11790)
### Authors
Gregor Baer,Isel Grau,Chao Zhang,Pieter Van Gorp
### Background
在可解释人工智能(XAI)领域，特征归因方法的评估代表了一个关键挑战。研究人员通常依赖扰动基度量来评价归因质量，尤其是在没有真实标签的情况下。然而，最近的工作揭示了这些评估指标在数据集内部类之间表现不同的现象。这种'类别依赖性评估效应'引发了关于扰动分析是否可靠地衡量归因质量的质疑，直接对XAI方法的发展和评价的信任度产生了影响。为此，研究者通过合成时间序列数据进行了控制实验，探索了这些类别依赖性效应出现的条件，发现这些效应即使在简单的时间局部特征场景中也会出现，由基本的特征幅度或时间范围差异触发。研究进一步表明，扰动基度量和基于真实标签的评价方法频繁对归因质量产生矛盾的评估，两者之间的相关性较弱。这些发现提示研究者应谨慎解释基于扰动的度量，因为它们可能不会始终反映归因是否正确识别了区分性特征。
### Innovation
通过合成时间序列数据进行控制实验，研究者探索了类别依赖性评价效应出现的条件，揭示了即使在简单的时间局部特征场景中此类别依赖性效应也会由基本的特征差异触发。提出基于扰动的度量和基于真实标签的评价方法对归因质量的评估可能存在矛盾，且评价方法间相关性较弱。这揭示了当前基于扰动的归因评价方法的问题，并促使研究者重新考虑归因评价实际测量的内容，从而开发出能够捕捉归因质量多个维度的更严格的评估方法。
### Conclusion
研究结果显示，类别依赖性评估效应在基于扰动和基于真实标签的评价方法中都会出现，即使在简单的时间局部特征场景中也会由基本特征差异引发。两者之间评估归因质量的相关性较弱，提示研究者应谨慎解读基于扰动的度量。这项工作表明，归因评价实际测量的内容需要重新评估，并且需要开发更严格的评价方法来全面衡量归因质量。
## 681. `cs.LG` - Task Priors: 通过考虑下游任务的所有空间来增强模型评估 [PDF](https://arxiv.org/pdf/2507.09871), [HTML](https://arxiv.org/abs/2507.09871)
### Authors
Niket Patel,Randall Balestriero
### Background
人工智能研究的宏大目标，尤其是自监督学习（SSL），是构建能够成功解决任何可能任务的系统。然而，目前的研究评估方法通常依赖于一组固定的、手工挑选的下游基准。因此，研究人员需要大量努力来设计和搜索能够服务于这一宏伟目标的评价任务集合。我们主张这种固定的评价协议在AI研究中形成了一种隐形的瓶颈。为了克服这一问题，我们定义了一个通过采用任务分布和定义任务先验（Task Priors）来获得的下游任务的概率空间。在这种观点下，可以评估模型在所有可能下游任务上的性能。该框架是首次回答关键问题，例如：（i）在所有可能下游任务中，按遇到每个任务的概率加权，我的模型的平均性能是什么？（ii）在定义的任务先验下，我的模型在所有下游任务上的性能变化是多少？
### Innovation
我们提出了一种新的框架来定义任务先验（Task Priors），通过考虑所有可能的下游任务空间，提供了评估模型性能的新方法。该框架首次能够回答关于模型在所有可能下游任务上的表现平均值及其变异性的问题，从而为自监督学习领域提供了新的评价标准，并有望加速该领域的研究进程，因为这是研究人员唯一可用的下游任务评估的定性信号。
### Conclusion
我们的框架不仅建立了一个新的评价标准，而且相信任务先验将加速自监督学习领域的研究进程。
## 682. `cs.LG` - 小型模型对齐的多偏好Lambda加权列表Direct Preference Optimization方法 [PDF](https://arxiv.org/pdf/2506.19780), [HTML](https://arxiv.org/abs/2506.19780)
### Authors
Yuhui Sun(University of Alberta),Xiyao Wang(University of Toronto),Zixi Li(Zhejiang University),Zhenlong Yuan(Institute of Computing Technology, Chinese Academy of Sciences),Jinman Zhao(University of Toronto)
### Background
大型语言模型（LLMs）在多种语言任务上表现出强大的泛化能力，但常生成与人类偏好不一致的输出。通过强化学习从人类反馈（RLHF）进行优化，虽然提高了对齐程度，但计算成本高且不稳定。Direct Preference Optimization（DPO）简化了优化过程，将其视为二元偏好对的分类任务，降低了训练开销，但假设固定的一维偏好且只支持成对监督。现有的方法也存在局限性，如偏好单一维度和固定偏好假设，这限制了模型对多元人类目标的学习能力。因此，这些方法难以处理复杂多样的偏好需求，尤其是在计算资源受限的环境下。
### Innovation
提出了一种名为Multi-Preference Lambda-weighted Listwise DPO的新方法，允许模型从更详细的人类反馈中学习，灵活地平衡多重目标，如帮助性、诚实性和流利性。该方法模型全排序偏好分布而不是二元比较，提供更丰富的学习信号。Lambda向量控制不同对齐目标的相对重要性，使模型能在多样的人类目标中泛化。此外，引入了一个学习调度器，动态地采样高效的Lambda配置，提高鲁棒性。训练只需要20GB的GPU内存，非常适合计算资源受限的环境，如学术实验室、教育工具或设备上的助手。通过大规模模型的实验表明，该方法在鲁棒性测试中始终优于标准的DPO方法，同时支持高效的、可控的和细致的适应，适用于实际部署。
### Conclusion
我们的方法将全排序偏好分布建模以代替二元比较，能够从详细的人类反馈中获取更加丰富和有用的学习信号。通过使用Lambda向量对不同目标的重要性进行加权，模型可以灵活地满足多样化的用户需求。此外，我们还建立了动态的性能最佳的Lambda配置采样机制，使模型在推断时可以根据用户的需求进行调整，避免了重新训练而获取最佳性能的配置。这种可扩展和高效的模型训练方法不仅推动了语言模型的优化及其在实际场景中的应用，而且为计算资源有限的情景下提供了重要的支持。
## 683. `cs.LG` - 全方位思考者：通过多任务RL与混合奖励扩展LLM跨域泛化 [PDF](https://arxiv.org/pdf/2507.14783), [HTML](https://arxiv.org/abs/2507.14783)
### Authors
Derek Li,Jiaming Zhou,Amirreza Kazemi,Qianyi Sun,Abbas Ghaddar,Mohammad Ali Alomrani,Liheng Ma,Yu Luo,Dong Li,Feng Wen,Jianye Hao,Mark Coates,Yingxue Zhang
### Background
通用人工智能的进步依赖于能够在广泛任务中表现出色的大规模语言模型（LLMs），从结构化推理到创意生成。然而，训练后的方法如监督微调（SFT）往往存在泛化困难的问题，倾向于记忆而非可迁移学习。
### Innovation
提出了一个统一的强化学习（RL）框架——全方位思考者（Omni-Thinker），通过结合基于规则的验证奖励和生成偏好信号来提升LLM在多种任务中的性能。此外，研究了基于课程的学习策略，展示了从结构化任务到开放性任务的有序排列能够提高性能并降低遗忘。实验表明，基于课程的学习策略在四个领域中提高了5.2%和9.1%的性能，这表明任务感知采样和混合监督在扩展基于RL的LLM后训练中的重要性。
### Conclusion
实验结果揭示了任务感知采样和混合监督对于扩展基于RL的LLM后训练的重要性，表明基于课程的学习策略对于提高性能和减少遗忘尤为有效。
## 684. `cs.LG` - Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation [PDF](https://arxiv.org/pdf/2507.15205), [HTML](https://arxiv.org/abs/2507.15205)
### Authors
Xinran Li,Xiujuan Xu,Jiaqi Qiao
### Background
情绪识别在对话中的任务既实用又具有挑战性。现有的方法通常采用单一模态特征，但在捕捉复杂情绪表达时效果有限。因此，研究一种能够有效捕获多模态特征的新型方法对于提高对话情绪识别的准确率至关重要。
### Innovation
本文提出了一个名为Long-Short Distance Graph Neural Network (LSDGNN) 的新型多模态方法。该方法基于有向无环图（DAG），构造了长距离图神经网络和短距离图神经网络，分别获取远程和近距离对话单元的多模态特征。同时，通过引入差分正则化（Differential Regularizer）和BiAffine模块来促进特征交互，以及提出改进的课程学习（ICL）策略以应对数据不平衡的问题。这些创新点旨在提高长短距离特征表示的独立性，实现多模块间的相互影响，并通过训练方法偏重于学习简单的样本以提升整体模型性能。
### Conclusion
在IEMOCAP和MELD数据集上的实验结果表明，本文提出的方法在情绪识别任务中的表现优于现有的基准模型。
## 685. `cs.LG` - AI原生MIMO语义通讯中的潜空间对齐 [PDF](https://arxiv.org/pdf/2507.16680), [HTML](https://arxiv.org/abs/2507.16680)
### Authors
Mario Edoardo Pandolfo,Simone Fiorellino,Emilio Calvanese Strinati,Paolo Di Lorenzo
### Background
语义通讯旨在突出理解传递数据的意义并确保完成交流信息的动机所驱动的任务。然而，当设备依赖不同的语言、逻辑或内部表示时，可能会产生语义不匹配，这可能阻碍相互理解。本文针对语义通讯中的潜空间错位问题，引入了一种新的解决方法，利用多输入多输出（MIMO）通讯技术。我们的方法通过学习MIMO预编码/解码对来实现潜空间压缩和语义通道均衡，从而减轻语义不匹配和物理信道缺陷的影响。研究了两种解决方案：一是线性模型，通过交替方向乘方法（ADMM）求解双凸优化问题进行优化；二是基于神经网络的模型在传输功率预算和复杂性约束条件下学习语义MIMO预编码/解码器。
### Innovation
本文提出的创新点在于解决语义通讯中潜空间不一致问题的方法，通过学习MIMO预编码/解码对来实现潜空间压缩和语义通道均衡，同时考虑了线性和基于神经网络的两种解决方案，都通过优化方法进行模型训练，以减轻语义不匹配和物理信道缺陷。
### Conclusion
数值结果表明，提出的解决方案在目标导向的语义通讯场景中是有效的，体现了准确度、通信负担和解决方案复杂度之间的主要权衡。
## 686. `cs.LG` - 稀疏logits采样：加速大语言模型的知识蒸馏 [PDF](https://arxiv.org/pdf/2503.16870), [HTML](https://arxiv.org/abs/2503.16870)
### Authors
Anshumann,Mohd Abbas Zaidi,Akhil Kedia,Jinwoo Ahn,Taehwak Kwon,Kangwook Lee,Haejun Lee,Joohyung Lee
### Background
知识蒸馏是一种有效的方法，通过预计算和缓存老师的输出logits来从大型语言模型中提取知识，从而降低成本。然而，在预训练阶段的应用尚未得到充分探索。传统的稀疏知识蒸馏方法，如缓存Top-K概率，虽然直观，但会导致偏态估计，影响学生模型的性能和校准。
### Innovation
提出了一种基于重要性采样的方法——随机采样知识蒸馏，这种方法提供无偏估计，保持期望梯度，并且需要存储更稀疏的logits。与基于交叉熵的方法相比，该方法能够使学生模型的训练速度更快，且仅增加不到10%的计算开销，同时保持与完全蒸馏相当的性能。
### Conclusion
该方法在从300M到3B的不同模型规模下均表现出卓越的性能，使学生模型的训练更快，计算效率更高。
## 687. `cs.LG` - 因果测试LLMs中的性别偏见：职业偏见案例研究 [PDF](https://arxiv.org/pdf/2212.10678), [HTML](https://arxiv.org/abs/2212.10678)
### Authors
Yuen Chen,Vethavikashini Chithrra Raghuram,Justus Mattern,Rada Mihalcea,Zhijing Jin
### Background
大型语言模型（LLMs）生成的文本显示出各种有害的人类偏见，这些偏见针对各个群体。这些发现促使研究工作致力于理解并量化这些效应。本文引入了一种因果表述，用于在生成语言模型中衡量偏见。基于此理论基础，本文列出了设计稳健偏见基准的若干需求，并提出了一个称为OccuGender的新基准，用于调查职业性别偏见。测试了几种先进的开源LLM，如Llama、Mistral及其指令调优版本。结果显示，这些模型显示出了显著的职业性别偏见。最后，讨论了偏见缓解的提示策略，并扩展了因果表述以说明我们框架的一般性。
### Innovation
本文提出了一个因果表述，用于量化生成语言模型中的偏见；提出了一个新的基准——OccuGender，用于调查职业性别偏见；测试了几种先进的开源LLMs的偏见。
### Conclusion
本文的结果表明，这些最先进的开源LLMs在职业性别偏见方面表现出显著的偏见。讨论了偏见缓解的提示策略，并展示了一种扩展的因果表述，以说明框架的一般性。
## 688. `cs.LG` - EarthLink: 自适应演进的AI辅助气候科学研究 [PDF](https://arxiv.org/pdf/2507.17311), [HTML](https://arxiv.org/abs/2507.17311)
### Authors
Zijie Guo,Jiong Wang,Xiaoyu Yue,Wangxu Wei,Zhe Jiang,Wanghan Xu,Ben Fei,Wenlong Zhang,Xinyu Gu,Lijing Cheng,Jing-Jia Luo,Chao Li,Yaqiang Wang,Tao Chen,Wanli Ouyang,Fenghua Ling,Lei Bai
### Background
现代地球科学正处于转折点。地球系统数据庞大、碎片化且复杂，而日益精良的分析需求，造成了快速科学发现的瓶颈。地球科学中的现有工具主要为静态诊断工具，缺乏灵活性和自学习能力，无法满足复杂的科研需求。
### Innovation
文章介绍了EarthLink，这是第一个专门为地球科学家设计的交互式副驾AI代理。它可以自动化整个研究工作流，从计划和代码生成到多场景分析。与静态诊断工具不同，EarthLink可以从用户交互中学习并不断改进其能力，通过动态反馈循环增强其性能。经过多项核心气候科学任务验证，验证了其科学分析能力，可以媲美人类初级研究员的部分工作流程。其透明、可审计的工作流和自然语言界面使科学家们可以从繁琐的手动执行中解脱出来，转向战略监督和假设生成。
### Conclusion
EarthLink标志着在地球系统科研中高效、可靠和协作时代的里程碑。该系统在我们的网站上可访问：[此链接](this https URL)。
## 689. `cs.LG` - TOC-UCO: 一个全面的绘制表格序数分类数据集仓库 [PDF](https://arxiv.org/pdf/2507.17348), [HTML](https://arxiv.org/abs/2507.17348)
### Authors
Rafael Ayllón-Gavilán,David Guijo-Rubio,Antonio Manuel Gómez-Orellana,Francisco Bérchez-Moreno,Víctor Manuel Vargas-Yun,Pedro A. Gutiérrez
### Background
序数分类(OC)问题涉及具有天然顺序关系类别的特殊分类类型，这类问题在许多实际应用中存在，推动了过去几年中序数方法的发展。然而，序数分类领域的开发面临着一个主要缺点：缺乏一个全面的数据集集，研究人员需要在其中对文献中的新方法进行基准测试。为此，来自科尔多瓦大学（UCO）的研究团队，鉴于其在OC领域的先前经验，提供了一个公开可用的基于表的数据集存储库，以确保对新OC方法的稳健验证，该存储库名为TOC-UCO（UCO的表格序数分类数据集存储库）。该存储库包含了46个基于表格的序数数据集，这些数据集按照统一框架进行预处理，确保具有合理数量的模式和适当的类分布。
### Innovation
该研究创新之处在于提供了一个公开可访问的基于表的序数分类数据集存储库TOC-UCO，涵盖了46个预处理过的序数数据集，这些数据集确保了模式的合理数量和适当的类分布。该存储库还提供了每个数据集的来源和预处理步骤，以及如何使用TOC-UCO存储库基准测试新方法的详细信息，包括为实验的可再现性提供了30个不同的随机化训练-测试分割指标。
### Conclusion
该研究展示了通过TOC-UCO存储库提供的数据集，研究人员可以对新的序数分类方法进行稳健的基准测试和实验，从而推动有序分类领域的进一步发展。
## 690. `cs.LG` - 学习可定义在计数逻辑中的概念 [PDF](https://arxiv.org/pdf/1909.03820), [HTML](https://arxiv.org/abs/1909.03820)
### Authors
Steffen van Bergerem
### Background
本文研究了在Grohe和Turán（2004年）提出的逻辑框架中相对于关系背景结构的布尔分类问题。已知Grohe和Ritzert（2017年）的研究表明，在结构的大小作为度量标准时，可定义于多项对数度数的结构上的一阶逻辑中的分类器可以在亚线性时间内学习，其中结构的度数和运行时间。这项研究将结果推广至了Kuske和Schweikardt（2017年）引入的用于扩展各种其他计数逻辑的表达力的一阶逻辑带计数FOCN。具体而言，证明了定义在多项对数度数结构上的FOCN中的分类器可以在亚线性时间内一致地学习。这可以说是对扩展学习框架的最初步骤，该框架要包含机器学习的数值方面。此外，将结果扩展到了在度数最多为$(text{log log } n)^c$的结构类中进行着不知情的近似有效地正确（PAC）学习，其中$c$是一个常数。此外，还展示了限制度数对于获得亚线性时间学习算法至关重要，即使是对于定义在一阶逻辑中的分类器，在结构度数无界时，亚线性时间学习也是不可能的。
### Innovation
本文将结果推广至了一阶逻辑带计数的分类器，证明了这些分类器可以在多项对数度数结构中被一致性地学习，无论是相互一致地学习还是PAC学习，在度数最多为$(text{log log } n)^c$时，其中$c$是一个常数。此外，提出了限制度数对于在亚线性时间内取得学习算法至关重要。
### Conclusion
本文的研究结果表明，对于定义在一阶逻辑带计数的分类器，可以在多项对数度数结构中进行亚线性时间内的学习，但如果没有对度数的限制，则在亚线性时间内的学习是不可行的。这为扩展学习框架并包含机器学习中的数值方面作出了贡献。
## 691. `cs.LG` - 通过梯度子空间距离选择公有数据集用于私有机器学习 [PDF](https://arxiv.org/pdf/2303.01256), [HTML](https://arxiv.org/abs/2303.01256)
### Authors
Xin Gu,Gautam Kamath,Zhiwei Steven Wu
### Background
私有梯度下降通过对每次迭代添加噪声来实现模型训练的私有化，且噪声的大小随着模型参数数量的增加而增大。最近的研究表明，可以通过将梯度投影到由公有数据规定的子空间内来减少噪声，以实现私人机器学习。然而，在给定一系列公有数据集时，没有先验地清楚这些数据集中哪一个是最佳选择。本研究提出通过测量公有和私有样本梯度之间的低维子空间距离来选择公有数据集的方法。理论分析表明，过拟合风险与该距离有关，且这个距离易于计算且对设置的修改具有鲁棒性。实证结果表明，训练模型的准确性与该距离成单调关系。
### Innovation
提出了一种通过测量公有和私有样本梯度之间的低维子空间距离来选择公有数据集的方法。这种选择方法能够理论和实践中有效降低过拟合风险，并具有计算简便和对设置鲁棒性强的优点。
### Conclusion
实验结果显示，通过选择此类公有数据集可以提高私有机器学习的准确性，并且训练模型的准确性随该距离的变化呈单调关系。该方法为选择合适的公有数据集以优化私有机器学习提供了理论依据。
## 692. `cs.LG` - GCC-Spam：通过GAN、对比学习和字符相似性网络进行垃圾信息检测 [PDF](https://arxiv.org/pdf/2507.14679), [HTML](https://arxiv.org/abs/2507.14679)
### Authors
Zhijie Wang,Zixin Xu,Zhiyuan Pan
### Background
互联网上的垃圾短信数量呈指数增长，这需要有力的检测机制来降低信息泄露和社交不稳定的风险。本研究主要应对两个挑战：垃圾发送者采用的对抗策略以及标签数据稀缺的问题。
### Innovation
GCC-Spam模型集成了三大创新点：1）字符相似性网络捕捉拼写和发音特征，对抗字符混淆攻击，并生成句子嵌入供后续分类；2）对比学习通过优化垃圾邮件和正常邮件在潜在空间中的距离来提升辨别能力；3）生成对抗网络（GAN）生成逼真的伪垃圾邮件样本，缓解数据稀缺问题，同时提高模型鲁棒性和分类准确性。
### Conclusion
在真实世界数据集上的广泛实验表明，该模型在比基线方法更少有标签示例的情况下，实现了更高的检测率。
## 693. `cs.LG` - SDSC：一种用于语义信号表示学习的结构感知度量 [PDF](https://arxiv.org/pdf/2507.14516), [HTML](https://arxiv.org/abs/2507.14516)
### Authors
Jeyoung Lee,Hochul Kang
### Background
大多数信号的半监督学习（SSL）方法通常采用基于距离的目标函数，如均方误差（MSE），这些方法对幅度敏感，对波形极性不变，并且规模未定义。这些特性妨碍了语义对齐和降低了可解释性。
### Innovation
提出了一种名为信号骰子相似度系数（SDSC）的结构感知度量函数，通过量化基于符号幅度交集的时间信号的结构一致来改进信号的自监督表示学习。此外，还提出了一种混合损失形式，将SDSC与MSE结合使用，以提高稳定性和在必要时保留幅度。
### Conclusion
基于SDSC的预训练在时间序列预测和分类基准上取得了与MSE相当或更佳的性能，尤其是在领域内和低资源场景下。结果表明，信号表示中的结构保真性提高了语义表示的质量，支持结构感知度量作为一种不同于传统基于距离的方法的可行替代方案。
## 694. `cs.LG` - LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important [PDF](https://arxiv.org/pdf/2504.04704), [HTML](https://arxiv.org/abs/2504.04704)
### Authors
Manlai Liang,JiaMing Zhang,Xiong Li,Jinlong Li
### Background
在大型语言模型（LLM）长上下文推理过程中，关键值（KV）缓存的大小不断增加成为其在部署成本和任务准确度间保持平衡的主要障碍。以往减少KV缓存大小的努力大多依赖于关注权重来移除非关键缓存令牌，但这些方法通常需要重大的推理基础设施修改和显著的计算开销。
### Innovation
基于大型语言模型是自回归模型的事实，我们提出了一种仅依赖于直接对比KV本身的KV压缩策略——LagKV。LagKV是一个完全不依赖关注权重的方法，可以轻松集成到主流推理平台，并且在压缩比相当的情况下，其性能可以与其它复杂的KV压缩方法相媲美。实验结果表明，在RULER基准测试中，我们的方法在不同的压缩比下都优于SnapKV和StreamingLLM，在64位密钥提取任务中，相较于基于关注权重的方法H_2O，我们的方法在相同压缩比下性能高出50%。
### Conclusion
我们的方法在不同的压缩比下都优于现有的KV压缩方法，特别是在64位密钥提取任务中，与基于关注权重的方法H_2O相比，性能提升了超过50%。我们的代码可以在指定的网址获取。
## 695. `cs.LG` - PLOT-TAL: 基于最优传输的提示学习在少样本时间段动作定位 [PDF](https://arxiv.org/pdf/2403.18915), [HTML](https://arxiv.org/abs/2403.18915)
### Authors
Edward Fish,Andrew Gilbert
### Background
现有的少样本时间段动作定位（TAL）方法，通过单提示调优来适应大型模型，往往难以产生精确的时间边框。这是因为模型从稀疏数据中学习到的是动作的非区分性平均表示，这损害了泛化能力。现有的方法在这方面的表现不尽如人意，尤其是在高交并比（IoU）阈值下，精准的时间定位仍然具有挑战性。
### Innovation
本文提出了一种新的基于多提示集合的新范式，通过鼓励每个动作具有一组多样化的可学习提示以专门化于组份子事件来解决现有方法的局限性。为了确保这种专门化，引入了一种名为PLOT-TAL的框架，利用了最优传输（OT）来在全球范围内找到提示集合与视频时间特征之间的最佳对齐方式。该方法不仅在具有挑战性的少样本基准测试集THUMOS'14和EPIC-Kitchens中建立了新的性能记录，而且不需复杂的元学习。其在高交并比条件下的显著性能提升验证了我们的假设，证明了学习分布式、组成型表示对于精确的时间定位的有效性。
### Conclusion
该研究在少样本时间段动作定位中取得了突破性的进展，通过多提示集合相结合的方式，利用最优传输算法，成功解决了模型从稀疏数据中学习非区分性平均表示的问题，从而显著提高了动作定位的准确性，尤其是在高交并比阈值下表现出色。
## 696. `cs.LG` - 具有组成员指定错误的鲁棒非自适应组测试 [PDF](https://arxiv.org/pdf/2409.05345), [HTML](https://arxiv.org/abs/2409.05345)
### Authors
Shuvayan Banerjee,Radhendushka Srivastava,James Saunderson,Ajit Rajwade
### Background
在给定p个样本的情况下，通过进行n（小于p）轮测试来确定样本是否具有缺陷的状态，其中每个样本可能会或可能不会是缺陷的。假定缺陷样本的数量远远小于p，现有的组测试算法可以有效地恢复所有p个样本的状态。现有的大多数方法都假设组成员身份的指定是准确的，但在实际应用中，由于各种资源限制，这种假设不太可能总是成立。技术人员在实验室中可能会错误地将样本分组，导致错误的组成员身份指定。
### Innovation
本文提出了Debiased Robust Lasso Test Method (DRLT)，该方法能够处理组成员身份指定错误的情况。DRLT方法基于用于减轻Lasso估计偏差的方法，提供了理论上的重构误差上界，并结合了两种精心设计的假设检验来分别识别存在组成员身份指定错误时的缺陷样本和错误指定的组。这种方法扩展了统计估计器（如LASSO）偏差缓解的研究，以处理由于组成员身份指定错误等因素导致的部分测量值为离群点的情况。实验证明，这种方法在识别缺陷样本和错误指定的组方面优于几种基线和鲁棒回归技术。
### Conclusion
本文提出了一种新的组测试方法DRLT，以解决组成员指定错误的问题，并提供了理论证明的方法性能上限。DRLT方法与精心设计的假设检验结合使用，可以有效地识别缺陷样本和错误指定的组。
## 697. `cs.LG` - 私人反事实检索 [PDF](https://arxiv.org/pdf/2410.13812), [HTML](https://arxiv.org/abs/2410.13812)
### Authors
Mohamed Nomeir,Pasan Dissanayake,Shreya Meel,Sanghamitra Dutta,Sennur Ulukus
### Background
在高风险应用中使用黑盒机器学习模型时，透明度和可解释性是两个非常重要的考虑因素。提供反事实解释是一种满足这些要求的方法。然而，这也威胁到提供解释的机构以及请求解释的用户的数据隐私。本文提出了一系列方案，借鉴隐私信息检索技术，确保在检索反事实解释时用户的隐私得到保护。
### Innovation
提出了一系列基于隐私信息检索技术的方案，确保用户在检索已接受点的反事实解释时具有信息论上的完美隐私。尽管用户隐私得到了保护，但数据库不可避免地会有一些泄漏，本文使用互信息度量模型量化了这种泄漏，并提出了减少泄漏以实现数据库隐私高级保护的策略。此外，还将这些方案扩展到了考虑用户的属性转换偏好，以便提供更实用的解释，并通过实证研究验证了方案在准确性与有限域大小之间的权衡。
### Conclusion
我们的研究表明，通过互信息度量模型量化了数据库泄漏，并提出了减少泄漏的策略，这些方案在实际数据集上得到了验证，证明了其理论发现的有效性，并对比了所提出的方案的数据库泄漏。
## 698. `cs.LG` - AI工作流、外部验证和眼科疾病诊断的发展 [PDF](https://arxiv.org/pdf/2409.15087), [HTML](https://arxiv.org/abs/2409.15087)
### Authors
Qingyu Chen,Tiarnan D L Keenan,Elvira Agron,Alexis Allot,Emily Guan,Bryant Duong,Amr Elsawy,Benjamin Hou,Cancan Xue,Sanjeeb Bhandari,Geoffrey Broadhead,Chantal Cousineau-Krieger,Ellen Davis,William G Gensheimer,David Grasic,Seema Gupta,Luis Haddock,Eleni Konstantinou,Tania Lamba,Michele Maiberger,Dimosthenis Mantopoulos,Mitul C Mehta,Ayman G Nahri,Mutaz AL-Nawaflh,Arnold Oshinsky,Brittany E Powell,Boonkit Purt,Soo Shin,Hillary Stiefel,Alisa T Thavikulwat,Keith James Wroblewski,Tham Yih Chung,Chui Ming Gemmy Cheung,Ching-Yu Cheng,Emily Y Chew,Michelle R. Hribar,Michael F. Chiang,Zhiyong Lu
### Background
及时的疾病诊断面临挑战，由于疾病负担增加和临床医生资源有限。人工智能在提高诊断准确性方面显示出潜力，但因在临床工作流程中缺乏充分验证以及在不同人群中的应用问题，实际应用受到限制。本研究通过年龄相关黄斑变性（AMD）的病例研究，旨在填补医疗AI下游问责制的空白。通过与来自AREDS的实际患者的24名不同机构的24名临床医生进行比较，展示了AI辅助诊断工作流在AMD诊断和严重程度分类中的效果。
### Innovation
本研究设计并实施了AI辅助的AMD诊断工作流，并通过将约40,000个额外的医学图像（即AREDS2数据集）纳入现有AI模型中，实现了模型性能的持续提升。验证结果显示AI辅助显著提高了23名临床医生的诊断准确性和分类能力，平均F1分数从37.71（手动诊断）提高了20%到45.52（手动+AI辅助），部分情况下提高了50%以上。此外，配备持续学习能力的模型在三个独立数据集上的表现稳健，准确率提升了29%，新加坡人群中的F1分数从42提高到了54分。
### Conclusion
AI协助显著提高了眼科疾病（如AMD）的诊断准确性和效率。通过持续学习的AI模型，诊断准确率在三个不同数据集上的表现一致，说明了AI辅助诊断的一致性和有效性。
## 699. `cs.LG` - 通过切片评分分布匹配在数字病理学中实现稳健的灵敏度控制 [PDF](https://arxiv.org/pdf/2502.20144), [HTML](https://arxiv.org/abs/2502.20144)
### Authors
Arthur Pignet,John Klein,Genevieve Robin,Antoine Olivier
### Background
基于数字病理学模型在不同医疗机构之间的部署面临挑战，尤其是在分类模型对不同分布的数据集保持良好性能方面。尽管最近在领域泛化方面的进展提高了模型的总体迁移性（用AUC来衡量），但在临床调节中，还面临着控制敏感性等其他指标迁移性的需求，这与上述进展有所冲突。因此，该研究旨在提出一种新颖的方法，以最优传输和多项实例学习为基础，实现对全切片图像（WSI）分类模型的灵敏度控制，并在多个队列和任务中验证了其有效性和实用性，从而提供了一个在计算病理系统可靠部署方面的实际解决方案。
### Innovation
引入基于最优传输和多项实例学习的新型方法，以实现对全切片图像分类模型的灵敏度控制，这种方法能够在仅使用少量校准样本的情况下实现稳健的灵敏度控制，为在医疗中心部署计算病理系统提供了实用的解决方案，满足临床对不同指标迁移性的具体需求。
### Conclusion
该研究通过提出基于最优传输和多项实例学习的方法，实现了对全切片图像分类模型灵敏度的控制，能够在仅使用少量样本的情况下进行校准，有效解决了不同医疗机构之间的分布变化问题，并验证了该方法的有效性和实用性，为计算病理系统在医疗中心的可靠部署提供了新的视角和方案。
## 700. `cs.LG` - 通过核 quadrature 修正概率时间序列预测评估中的问题 [PDF](https://arxiv.org/pdf/2503.06079), [HTML](https://arxiv.org/abs/2503.06079)
### Authors
Masaki Adachi,Masahiro Fujisawa,Michael A Osborne
### Background
尽管概率时间序列预测模型具有重要意义，但其评估指标通常涉及难以计算的积分。最常用的指标连续排名概率分数（CRPS）是一个严格正确评分函数，但仍需要近似计算。我们发现，流行的 CRPS 估计器（特别是 GluonTS 库中实现的基于分位数的估计器和概率加权矩近似）都固有地存在估计偏差，这些偏差导致在 CRPS 值接近时模型性能排名不准确。
### Innovation
我们引入了一种核 quadrature 方法，利用无偏 CRPS 估计器并采用 cubature 构建实现可扩展计算。实验结果表明，我们的方法在实践中始终优于两种常用的 CRPS 估计器。
### Conclusion
我们的方法能够修正概率时间序列预测评估中的问题，提供更准确的概率时间序列预测评估。
## 701. `cs.LG` - 基于样本级注意力融合和模拟扰动对齐的鲁棒多视图学习 [PDF](https://arxiv.org/pdf/2503.04151), [HTML](https://arxiv.org/abs/2503.04151)
### Authors
Jie Xu,Na Zhao,Gang Niu,Masashi Sugiyama,Xiaofeng Zhu
### Background
最近，多视图学习(MVL)因其能够融合多视角的鉴别信息而受到广泛关注。然而，现实中的多视图数据往往存在异质性和不完美性，这通常使得专门设计的MVL方法无法广泛应用于实际场景，限制了其有效性。
### Innovation
提出了一个新颖的鲁棒MVL方法(RML)，同时实现特征融合和对齐。RML引入了一个简单的多视图变换融合网络，将异质多视角数据转换为同构词嵌入，通过样本级注意力机制整合多视角数据得到融合表示。此外，提出了一种基于模拟扰动的多视图对比学习框架，通过动态生成噪声和不可用扰动以模拟不完美数据条件。
### Conclusion
RML是一种自监督的方法，也可应用于下游任务作为正则化模块。在实验中，RML被应用于多视角无监督聚类、噪声标号分类以及跨模态哈希检索插拔模块。广泛的比较实验和消融研究表明了RML的有效性。相关代码可在[此链接]获得。
## 702. `cs.LG` - 在使用扩散模型进行质子-质子碰撞中的累积去除中的变分推断 [PDF](https://arxiv.org/pdf/2410.22074), [HTML](https://arxiv.org/abs/2410.22074)
### Authors
Malte Algren,Tobias Golling,Christopher Pollard,John Andrew Raine
### Background
现有的碰撞数据分析方法在去除碰撞过程中的累积干扰时通常使用分类方法，这些方法识别出来自主碰撞的粒子，但这种处理方式可能会受到检测器效率不完美的影响。本文通过引入一种基于生成模型的方法（称为vipr）来改进这一过程，通过变分推理和扩散模型预测去除了累积干扰后的硬散射粒子喷射流的组成部分，从而为目标提供更准确的信息，并在各种累积条件下表现出色。这种方法能够提供一个关于硬散射粒子喷射流组成部分的完整的后验估计，这是之前尚未探索的领域。因此，它提供了比现有方法更明显的优势，尤其是在检测器效率不完美的情况下。研究中的一个实例是使用模拟的tt̄事件中的喷射流叠加了累积干扰来进行性能评估。结果显示，vipr在预测硬散射喷射流子结构方面比softdrop表现更好，且与puppiml具有相当的性能，覆盖广泛的累积场景时均表现良好。
### Innovation
提出了一种使用变分推理和扩散模型的新型方法（vipr）来去除高能物理实验中（如在质子-质子碰撞中）的累积干扰，该方法通过训练出的生成模型预测去除累积干扰后的硬散射粒子喷射流，得到关于硬散射粒子喷射流组成部分的完整后验估计，弥补了传统分类方法的不足，特别是在检测器效率不完美的情况下表现出色。这种方法在多种累积条件下经过实验证明优于现有的方法，能够更准确地预测硬散射喷射流的子结构。
### Conclusion
通过使用vipr方法，在模拟的tt̄事件中叠加了累积干扰的喷射流样本上评估其性能，结果表明，该方法在预测的硬散射喷射流子结构方面优于softdrop方法，且与puppiml具有相当的性能，在广泛变化的累积场景中具有更好的表现力。
## 703. `cs.LG` - 在等价价格多单位拍卖中学习安全策略以实现价值最大化购买者 [PDF](https://arxiv.org/pdf/2406.03674), [HTML](https://arxiv.org/abs/2406.03674)
### Authors
Negin Golrezaei,Sourav Sahoo
### Background
本文研究了价值最大化购买者在重复的等价价格多单位拍卖中的出价问题。在战略环境中，购买者的目标是在T轮中最大化累积价值，同时遵守每轮的投资回报率（RoI）约束。使用m-统一的出价格式，购买者在每个拍卖中提交m个出价-数量对(b_i, q_i)，以在出价b_i下购买q_i单位商品。文章探讨了在严格遵守RoI约束的前提下，出价策略的安全性及其对竞争出价的鲁棒性。
### Innovation
提出了安全出价策略的概念，即无论对手的出价如何都能满足RoI约束的策略。尽管这些策略非常严格，但证明了它们会满足轻度的不过标条件，仅依赖于买方的估值曲线，并且在不损失一般性的前提下，买方可以专注于一个有限的子集。设计了一个多项式时间的学习算法，在完全信息和多臂老虎机设置下都实现了亚线性遗憾与回顾最优安全策略和更丰富类别的最优策略相比，实现了α-近似亚线性遗憾。实验证明，实际的内涵丰富性比率远优于理论最坏情况界。
### Conclusion
所提出的安全策略和学习算法自然扩展到更精细的买家和竞争对手模型。通过在半合成拍卖数据上的模拟，观察到实际的丰富性比率远远优于理论上的最坏情况界限，证明了在复杂环境下买方策略的鲁棒性和可行性。
## 704. `cs.LG` - BEARCUBS：计算机使用型网络代理的基准测试 [PDF](https://arxiv.org/pdf/2503.07919), [HTML](https://arxiv.org/abs/2503.07919)
### Authors
Yixiao Song,Katherine Thai,Chau Minh Pham,Yapei Chang,Mazin Nadaf,Mohit Iyyer
### Background
现代网络代理具备能够通过向虚拟键盘和鼠标发送命令来与网页互动的能力。虽然这些代理在协助用户完成复杂任务方面具有巨大潜力，但在实际环境下的能力评估却是一个重大挑战。为应对这一挑战，本文提出了BEARCUBS，这是一个包含111个信息查询问题的基准测试，旨在评估网络代理的信息搜索、浏览和识别事实信息的能力。相比之前的网络代理基准测试，BEARCUBS需要访问实时的网页内容而非合成或模拟的页面，并且需要进行广泛的多种模式交互（如视频理解、3D导航），这些操作无法通过基于文本的迂回方法实现。这份基准测试还为每个问题提供了一个简短明确的答案和一个经过人工验证的浏览轨迹，以便透明地评估代理的表现和策略。
### Innovation
BEARCUBS基准测试引入了两个创新点：首先，它要求评估网络代理访问实时网页内容的能力，捕捉到真实世界网页交互的不可预测性；其次，它包括多种模式的互动，如视频理解、3D导航，这些无法通过基于文本的方法绕过。此外，ChatGPT代理在整体准确率上显著优于其他计算机使用型代理，达到了65.8%的准确率，而相比之下，其他代理如Operator的准确率仅为23.4%。这表明虚拟代理在涉及真实计算机使用任务（如玩网页游戏和导航3D环境）方面取得了显著进步。然而，要缩小与人类表现的差距，还需要在精确控制、复杂数据过滤和执行速度等方面进行改进。
### Conclusion
为了促进未来的研究，BEARCUBS基准测试将定期更新，以替换无效或受污染的问题，确保这个基准测试对未来的网络代理研究保持新鲜度。
## 705. `cs.LG` - ICPGRL: 依据语言的强化学习在过程性关卡生成中的应用 [PDF](https://arxiv.org/pdf/2503.12358), [HTML](https://arxiv.org/abs/2503.12358)
### Authors
In-Chang Baek,Sung-Hyun Kim,Seo-Young Lee,Dong-Hyeon Kim,Kyung-Joong Kim
### Background
近期研究强调了自然语言在增强生成模型可控性中的重要性。虽然已经有许多研究致力于通过自然语言进行内容生成，但基于深度强化学习（DRL）的代理利用文本指令进行过程性内容生成的研究相对有限。
### Innovation
本文提出了ICPGRL，一种基于指令的过程性内容生成方法，通过强化学习并结合句向量模型。ICPGRL通过对特定任务进行微调，有效压缩游戏级别的条件，从而增强了生成模型的可控性和泛化能力。
### Conclusion
ICPGRL在二维关卡生成任务中得到了评估，并与一般用途的嵌入方法进行了对比。结果表明，ICPGRL在可控性和泛化能力上分别提高了21.4%和17.2%。此外，该方法扩展了条件输入的模态，使得过程性内容生成的交互框架更加灵活和丰富。
## 706. `cs.LG` - 通过贪婪增量 divergence 最小化调整序列蒙特卡罗采样器 [PDF](https://arxiv.org/pdf/2503.15704), [HTML](https://arxiv.org/abs/2503.15704)
### Authors
Kyurae Kim,Zuheng Xu,Jacob R. Gardner,Trevor Campbell
### Background
顺序蒙特卡罗（SMC）采样器的表现高度依赖于路径提案中所使用的马尔可夫内核的调优。对于使用未调整的马尔可夫内核的SMC采样器，传统的调优目标，如马尔可夫-赫斯特接受率或期望跳跃距离已经不再适用。虽然已经探索了基于随机梯度的端到端优化来调优SMC采样器，但这经常会导致过高的训练成本，即使仅调优内核步长也是如此。
### Innovation
本文提出了一种通用的调优框架，通过最小化提案路径与目标路径之间的增量Kullback-Leibler（KL）散度来调优SMC采样器中的马尔可夫内核。对于步长调优，提供了一种既不需要梯度也不需要调优的算法，该算法适用于诸如 Langevin 蒙特卡罗（LMC）之类的内核。进一步提供了一种专门方案来调优应用于SMC采样器的动能Langevin蒙特卡罗。实现能够在完成几个基础的SMC运行的情况下获得完整的调优参数表，从而大幅减少基于梯度的方法所需的成本
### Conclusion
我们的实现能够在完成几个基础的SMC运行的情况下获得完整的调优参数表，该成本仅仅是基于梯度方法的几分之一。
## 707. `cs.LG` - I-CEE: 根据用户专业知识定制图像分类模型的解释 [PDF](https://arxiv.org/pdf/2312.12102), [HTML](https://arxiv.org/abs/2312.12102)
### Authors
Yao Rong,Peizhu Qian,Vaibhav Unhelkar,Enkelejda Kasneci
### Background
黑箱机器学习模型的决策解释对于负责任地部署依赖它们的AI系统至关重要。尽管领域内的可解释AI (XAI) 已经提供了一些技术来生成这些解释，但现有的XAI方法主要关注模型本身，缺乏对用户（解释对象）的关注，大多生成“一刀切”的解释。现有工作通常忽视了用户的专业背景和理解能力，导致难以有效帮助用户理解模型的决策过程。
### Innovation
本文提出了I-CEE框架，即“根据用户专业知识定制的图像分类解释”。该框架通过提供对用户而言具有信息量的训练数据子集（示例图像）、对应的局部解释以及模型决策来解释图像分类模型的决策。I-CEE的独特之处在于根据用户的专业知识，动态调整示例图像的信息量，为不同用户提供个性化解释。研究表明，I-CEE能够更好地提升用户的模型决策模拟能力。
### Conclusion
通过详细实验，无论是模拟用户还是真实用户，I-CEE都显著提高了用户的模型决策模拟准确性，证明了以人为本的XAI的重要性。这种方法在未来可为不同类型用户提供更加个性化和有效的模型解释，有助于促进AI系统的透明度和用户信任。
## 708. `cs.LG` - External Knowledge Injection for CLIP-Based Class-Incremental Learning [PDF](https://arxiv.org/pdf/2503.08510), [HTML](https://arxiv.org/abs/2503.08510)
### Authors
Da-Wei Zhou,Kai-Wen Li,Jingyi Ning,Han-Jia Ye,Lijun Zhang,De-Chuan Zhan
### Background
类增量学习（CIL）使得学习系统能够不断适应演化的数据流。随着预训练技术的进步，利用预训练的多模态模型（如CLIP）在CIL中提供了一个有前景的起点。然而，CLIP在决策时通过视觉嵌入和类别名称进行匹配，忽视了语言传达的丰富语境信息。因此，模型不断更新中这些详细特征会丢失，需要外部知识进行补充。本文研究背景是CLIP在CIL中的不足之处及其改进方法。
### Innovation
本文提出了ExterNal knowledGe INjEction (ENGINE)框架，这是一种双支路注入调优框架，能够从视觉和文本模态中编码有益知识。视觉支路通过数据增强丰富视觉特征，文本支路则利用GPT-4重写有区别的描述符。此外，还实施了后调优知识，在推理过程中重新排名预测结果。实验结果表明ENGINE在CIL任务上表现出最先进的性能。
### Conclusion
通过将外部知识注入到基于CLIP的CIL中，模型能够更好地捕捉随数据发展而来的有意义特征，增强CIL性能。研究通过广泛的实验验证了ENGINE的有效性。
## 709. `cs.LG` - 修复硬件系统中具有部分覆盖范围的主动学习 [PDF](https://arxiv.org/pdf/2503.16315), [HTML](https://arxiv.org/abs/2503.16315)
### Authors
Michael Potter,Beyza Kalkanlı,Deniz Erdoğmuş,Michael Everett
### Background
利用现场数据识别最优诊断测试和硬件系统实例以推断可靠性特征具有挑战性，尤其是在受到固定预算和最小维护周期限制的情况下。现有的主动学习(Active Learning, AL)方法在机器学习和深度学习任务参数推断中显示出应用前景，特别是在预算和数据有限的情况下。然而，对于修复硬件系统的可靠性模型参数推断，现有的AL方法尚未得到充分探索，需要考虑硬件老化和硬件系统由多个子系统组成的特殊性，这意味着在特定的诊断测试中，只能进行部分子系统测试。因此，如何在这些限制条件下有效地进行参数推断成为研究难点。
### Innovation
该研究提出了一种放宽的混合整数半定规划（MISDP）主动学习获取函数（Acquisition Functions, AFs），它结合了诊断覆盖（Diagnostic Coverage, DC）、Fisher信息矩阵（Fish Information Matrices, FIMs）和诊断测试预算，尤其考虑了硬件老化。另外，研究设计了基于经验的仿真实验，这两个诊断测试场景：（1）具有部分测试覆盖和重叠子系统覆盖的硬件系统的测试，和（2）一个测试完全涵盖另一个测试的子系统覆盖的测试。研究还评估了其提出的AF方法相对于文献中最常用的AL AF（熵）和其他几个针对可靠性模型参数推断设计的直观AL AF方法的有效性。研究发现在6000种不同的实验配置中，所提AF方法在AUC（绝对总预期事件误差）和MSE曲线方面的表现最佳，具有统计显著性差异。
### Conclusion
所提出的主动学习方法在6000次实验配置中以平均性能最好，在绝对总预期事件误差（ATEER）和均方误差（MSE）曲线下方区域的表现最佳，使用Friedman假设检验计算的显著性水平为0.05。
## 710. `cs.LG` - 语言模型是如何学习事实的？动态、课程和幻觉 [PDF](https://arxiv.org/pdf/2503.21676), [HTML](https://arxiv.org/abs/2503.21676)
### Authors
Nicolas Zucchet,Jörg Bornschein,Stephanie Chan,Andrew Lampinen,Razvan Pascanu,Soham De
### Background
大型语言模型在预训练期间积累了大量的知识，但其获取过程中动态机制理解仍然不足。本文通过研究合成事实回忆任务中语言模型的学习动态，得出了三个关键发现：第一，语言模型学习分为三个阶段，在获得准确的事实知识之前会有一个性能平台；第二，训练数据分布显著影响学习动态，不平衡的数据分布会导致较短的学习平台期；第三，知识和幻觉是同步出现的，通过微调整合新知识到模型中非常具有挑战性，因为它会迅速破坏模型现有的参数记忆。结果强调了数据分布对知识获取的重要性，并提出了加速神经网络训练的数据调度策略建议。
### Innovation
本文通过合成事实回忆任务揭示了语言模型学习动态的三个关键发现，并强调了数据分布对知识获取的重要性，提出了新的数据调度策略，以加速神经网络训练。
### Conclusion
本文的结果不仅对理解语言模型如何学习事实提供了重要的见解，还强调了在知识获取过程中数据分布的重要性，并提出了未来研究和实践的潜在方向。
## 711. `cs.LG` - PALADIN : 算法细腻的文本到图像扩散模型神经指纹算法 [PDF](https://arxiv.org/pdf/2506.03170), [HTML](https://arxiv.org/abs/2506.03170)
### Authors
Murthy L,Subarna Tripathi
### Background
文本到图像生成模型存在被滥用的风险，尤其是由于这些模型开源，导致威胁更加严重。一种减少这种风险的策略是使用神经指纹识别技术。虽然该领域有很多关于提升模型指纹识别准确性的研究工作，但目前还没有方法实现100%的识别准确性。任何不到100%的准确性，对实际部署而言都是不可行的。针对现有方法的这一不足，提出了一种新的方法，基于编码理论中的循环纠正码概念，以提高对文本到图像扩散模型的识别准确性。
### Innovation
提出了PALADIN算法，通过利用编码理论中的循环纠正码概念来准确地构建文本到图像扩散模型的神经指纹，从而能够在实际部署中有效提高模型识别的准确性。
### Conclusion
通过PALADIN算法，不仅解决了现有方法在识别准确性上的不足，还能够在实际部署中合理避免文本到图像生成模型被恶意使用的风险。
## 712. `cs.LG` - 扩散和扩散：具有表示正则化的图像生成 [PDF](https://arxiv.org/pdf/2506.09027), [HTML](https://arxiv.org/abs/2506.09027)
### Authors
Runqian Wang,Kaiming He
### Background
过去十年中，基于扩散的生成模型的发展在很大程度上与表示学习的进步独立进行。这些扩散模型通常依赖于基于回归的目标，并且通常缺乏显式的正则化。
### Innovation
提出了Dispensive Loss，一种简单直接的正则化器，能够有效改进基于扩散的生成模型。这种损失函数鼓励内部表示在隐藏空间中发散，类似于对比自监督学习，但无需正样本对，不会干扰用于回归的采样过程。
### Conclusion
在ImageNet数据集上对多种模型评估显示，与广泛使用的强力基线相比，Dispensive Loss能带来一致的改进。我们希望这项工作能帮助缩小生成建模与表示学习之间的差距。
## 713. `cs.LG` - 核岭归回归下的伪标签法及其在协变量偏移情况下的应用 [PDF](https://arxiv.org/pdf/2302.10160), [HTML](https://arxiv.org/abs/2302.10160)
### Authors
Kaizheng Wang
### Background
本文研究在协变量偏移的情况下进行核岭归回归的方法。目标是在目标分布上学习具有小均方误差的回归函数，基于未标记的目标数据和可能具有不同特征分布的标记数据。提出了一种分步的标记数据处理方法和核岭归回归方法，从而获得候选模型集合和补全模型，并通过补全模型填补标签缺口，最终选择最合适的候选模型。
### Innovation
提出了一种原理上的方法来处理核岭归回归中的协变量偏移问题。通过将标记数据分为两部分独立进行核岭归回归，一方面获得用于填补标签缺口的补全模型，另一方面获得候选模型集合。这些候选模型与补全模型结合使用，能够有效地适应目标分布的结构和协变量偏移。创新点还包括非渐进的风险边界证明，展示了本方法适应目标分布结构和协变量偏移的有效性。
### Conclusion
本文的估计量在拟最优错误率方面达到了微型最优，与对数因子的偏差小。实验指出，使用伪标签进行模型选择对性能影响不大。
## 714. `cs.LG` - SyncMapV2：稳健且适应性强的无监督分割 [PDF](https://arxiv.org/pdf/2506.16297), [HTML](https://arxiv.org/abs/2506.16297)
### Authors
Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas
### Background
人类视觉在无需显式训练的情况下就能出色地分割视觉线索，并且即使在噪声程度增加的情况下仍保持着相当的鲁棒性。相比之下，现有的AI算法在相似条件下难以保持准确性。
### Innovation
SyncMapV2 是首个在无监督分割中有卓越鲁棒性的算法。在数字干扰下，SyncMapV2 的 mIoU 下降仅 0.01%，而 SOTA 方法下降 23.8%。其鲁棒性能覆盖多种类型干扰，包括噪声（减少 7.3% vs 37.7%）、天气（减少 7.5% vs 33.8%）和模糊（减少 7.0% vs 29.5%）。与传统的每新输入需重新初始化的方法不同，SyncMapV2 能在线自适应，模拟人类视觉的持续适应性。
### Conclusion
SyncMapV2 证明了其在线适应能力，减少了性能退化，推动了未来具备鲁棒性和适应性的智能算法的发展。
## 715. `cs.LG` - Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections [PDF](https://arxiv.org/pdf/2506.16685), [HTML](https://arxiv.org/abs/2506.16685)
### Authors
Xiaomeng Xu,Yifan Hou,Zeyi Liu,Shuran Song
### Background
本文探讨了现实世界中接触丰富的操作数据集聚合（DAgger）的关键挑战，包括如何收集有效的人工纠正数据以及如何有效利用这些新数据来更新策略。
### Innovation
本文引入了 compliant residual DAgger (CR-DAgger)，该方法包含两个新颖组件：1）一个利用顺应性控制的 compliant intervention interface，使人类能够在不影响机器人策略执行的情况下提供温和且准确的 delta 动作纠正；2）一个 compliant residual policy 形式化，能够在利用力反馈和力控制的同时学习人类纠正数据。
### Conclusion
通过大量实际实验，本文提供了在真实世界机器人学习任务中实现有效 DAgger 的实用指导，该系统在最少纠正数据的情况下显著提升了精准接触丰富的操作任务性能，在两个具有挑战性的任务（书翻转和带组装）中将基线策略的成功率提高了超过50%，并且优于从头再训练和微调方法。
## 716. `cs.LG` - 快速与缓慢流式传输：感知认知负载的高效大语言模型服务 [PDF](https://arxiv.org/pdf/2504.17999), [HTML](https://arxiv.org/abs/2504.17999)
### Authors
Chang Xiao,Brenda Yang
### Background
当前，生成式会话接口通过大语言模型（LLMs）以每秒计算预算决定的速度逐分词流式传输输出，这种传输速度往往不符合实际的人类阅读速度和内容的认知负荷，从而导致计算资源的低效利用。例如，在基于云的服务中，如果流式传输内容的速度超过用户可以阅读的速度，这显得多余，浪费了计算资源，特别是在高峰期可能导致其他用户延迟。
### Innovation
提出了一个自适应流式传输方法，该方法能够根据推断的认知负荷实时动态调整LLM流式传输输出的速度。通过估计流式传输内容的认知负荷，在复杂或信息量大的部分减速流式传输，从而释放计算资源供其他用户使用。
### Conclusion
通过对众包用户研究中收集的数据进行统计分析和模拟实验，研究结果表明，自适应方法可以在显著降低计算消耗的同时，保持流式传输速度高于用户的正常阅读速度，实现高效的大语言模型服务。
## 717. `cs.LG` - 心电图分析中的遮蔽自编码器：揭开简单偏见的面纱 [PDF](https://arxiv.org/pdf/2506.22495), [HTML](https://arxiv.org/abs/2506.22495)
### Authors
He-Yang Xu,Hongxiang Gao,Yuwen Li,Xiu-Shen Wei,Chengyu Liu
### Background
心电图（ECG）诊断的价值在于其动态特性，包括节律波动和随时间和频率变化的细微波形变化。然而，监督学习的ECG模型倾向于过度强调主导和重复的模式，忽视了虽然细微但临床上重要的线索，这种现象称为简单偏见（SB），模型优先学习容易学习的信号而非细微但有信息价值的信号。
### Innovation
本文首先实证了在ECG分析中简单偏见的存在及其对诊断性能的负面影响。同时，本文发现，自我监督学习（SSL）能够减轻这种偏见，为解决偏见提供了新的可能性。基于SSL范式，本文提出了一种新颖的方法，包括时间-频率感知滤波器，用于捕捉反映ECG信号动态特性的时空特征，以及多粒度原型重构，用于在双重领域中实现粗粒度和细粒度的表示学习，进一步减轻简单偏见。为了推进ECG分析中的自我监督学习，本文构建了一个包含1.53万次记录的多中心ECG数据集，覆盖了超过300个临床中心。在六个ECG数据集中的三项后续任务上进行的实验结果表明，本文提出的方法有效地减少了简单偏见，并达到了最先进的性能。开源代码和数据集将被公开发布。
### Conclusion
本文基于自我监督学习框架，提出了一种新型方法，能够有效减少ECG分析中的简单偏见，实现了目前最先进的性能。
## 718. `cs.LG` - 通过神经后验估计从聚合生育率学习个体生殖行为 [PDF](https://arxiv.org/pdf/2506.22607), [HTML](https://arxiv.org/abs/2506.22607)
### Authors
Daniel Ciganda,Ignacio Campón,Iñaki Permanyer,Jakob H Macke
### Background
年龄特异性生育率（ASFRs）提供了最详细的生殖变化记录，但它们的聚合性质掩盖了驱动生育趋势的个体行为机制。为了弥合微观与宏观之间的差距，本研究提出了一种无似然性的贝叶斯框架，该框架将一个可解释的人口学过程的个体级模拟模型与Sequential Neural Posterior Estimation (SNPE)耦合在一起。该框架仅使用ASFRs数据，成功恢复了控制当代生育的核心行为参数，包括家庭规模偏好、生育时间以及避孕失败率。该方法的有效性在四个具有不同生育制度的国家的多个年龄组中得到了验证。模型仅基于聚合数据就能预测个体级结果的分布，包括初性交年龄、期望的家庭规模和出生间隔。因为该框架可以生成完整的合成生命史，因此显著减少了建立微观模拟模型所需的数据量，且允许进行行为明确的人口学预测。
### Innovation
该研究引入了一种无似然性的贝叶斯框架，结合了一个可在人口学上解释的个体级生殖过程模拟模型和Sequential Neural Posterior Estimation (SNPE)，仅使用年龄特异性生育率数据，该框架能够恢复控制当代生育的核心行为参数。该方法显著地减少了构建微观模拟模型所需的数据量，并能够进行行为明确的人口学预测。
### Conclusion
该框架成功地仅使用聚合数据恢复了影响当代生育行为的关键参数，并能预测个体级的结果。这种方法显著减少了数据需求，使得微模拟模型的构建更为简便，并且能够进行行为明确的预测。
## 719. `cs.LG` - 利用医学数据的结构提高表示学习 [PDF](https://arxiv.org/pdf/2507.02987), [HTML](https://arxiv.org/abs/2507.02987)
### Authors
Andrea Agostini,Sonia Laguna,Alain Ryser,Samuel Ruiperez-Campillo,Moritz Vandenhirtz,Nicolas Deperrois,Farhad Nooralahzadeh,Michael Krauthammer,Thomas M. Sutter,Julia E. Vogt
### Background
构建可推广的医疗AI系统需要高效使用数据并具备领域意识的预训练策略。而临床数据集如MIMIC-CXR提供有限数量的图像和稀疏注释，尽管如此，通过多视角影像存在丰富的内部结构。现有方法通常依赖于大规模互联网数据集，而在医学领域，这样的数据集非常稀缺和有限，提出了新的挑战和需求。
### Innovation
提出了一种自监督框架，该框架利用医学数据集的内在结构。该方法将配对的胸部X射线（即正视和侧视图）视为自然的正样本对，学习从稀疏补丁中重构每个视图，并对齐其潜在嵌入。该方法不需要文本监督，能够产生富有信息的表示。在MIMIC-CXR上，该方法与有监督目标和不利用结构信息的基线相比表现出色。此研究为具有结构但数据稀缺的领域特定预训练提供了一个轻量级且跨模式的蓝图，具有创新性。
### Conclusion
该研究提供了一种轻量级、跨模态的蓝图，用于领域特定的预训练，当数据是结构化但稀缺时，这种方法能够有效提高表示学习的效果。这对利用医学数据建立更加高效和领域的自适应AI系统具有重要意义。
## 720. `cs.LG` - GNN-ACLP：基于图神经网络的模拟电路连接预测 [PDF](https://arxiv.org/pdf/2504.10240), [HTML](https://arxiv.org/abs/2504.10240)
### Authors
Guanyuan Pan,Tiansheng Zhou,Bingtao Ma,Yaqi Wang,Jianxiang Zhao,Zhi Li,Yugui Lin,Pietro Lio,Shuai Wang
### Background
在模拟电路设计自动化中，从不完整的网表中识别缺失的组件连接的电路连接预测至关重要。然而，现有的方法面临三个主要挑战：1) 在电路图中不足地使用拓扑模式降低了预测准确性；2) 标注的复杂性导致数据稀缺，限制了模型的泛化能力；3) 对不同网表格式的有限适应性。
### Innovation
提出了基于图神经网络(GNNs)的方法GNN-ACLP，具有三大创新点来应对这些挑战。首先，提出了一种名为SEAL的框架（从子图、嵌入和属性学习链接预测），实现了电路连接预测的端口级精度。其次，提出了Netlist Babel Fish，这是一种利用检索增强生成（RAG）和大型语言模型（LLM）进行网表格式转换的工具，提高了网表格式的兼容性。最后，构建了包含775个带标注电路的SpiceNetlist数据集，覆盖了不同组件类别的10个类别。
### Conclusion
实验表明，在同一个数据集内部测试中，与基线相比，GNN-ACLP在SpiceNetlist、Image2Net和Masala-CHAI上的准确性分别提高了16.08%、11.38%和16.01%。在跨数据集测试中，准确率保持在92.05%到99.07%之间，展示了出色的特征转移能力。
## 721. `cs.LG` - AI生成的修复是否安全？SWE-bench上的LLM和代理修复分析 [PDF](https://arxiv.org/pdf/2507.02976), [HTML](https://arxiv.org/abs/2507.02976)
### Authors
Amirali Sajadi,Kostadin Damevski,Preetha Chatterjee
### Background
近年来，大型语言模型（LLMs）及其代理框架被广泛用于自动化软件开发任务，如问题解决和程序修复。尽管前人的研究已经识别出LLM生成的代码中的安全风险，但大多数评估主要集中在合成或孤立的环境中，对于这些系统在真实世界开发环境中的安全性仍然存在很多未知。这篇论文致力于填补这一空白，通过大规模安全分析了来自SWE-bench数据集的20000多个问题，考察了LLM生成的修复和开发者编写的修复，以及三个表现最好的代理框架（OpenHands、AutoCodeRover、HoneyComb）生成的修复，揭示了影响生成代码安全性的条件和因素。研究中发现，独立的LLM引入的漏洞几乎是开发者9倍，并且这些漏洞表现出开发人员代码中未发现的独特模式。代理工作流在给予LLM更多自主权时也会生成大量漏洞，可能会导致对项目背景或任务需求理解错误。研究还发现，涉及更多文件、更多生成代码行以及缺乏具体代码片段或行为描述的GitHub问题更有可能出现漏洞。
### Innovation
该研究首次大规模分析了LLM生成的修复，并利用SWE-bench数据集进行评估，这为研究LLM和代理生成修复的安全性提供了新的视角。另外，研究还评估了不同代理框架生成的安全性问题，这是现有工作尚未涉及的领域，并深刻揭示了不同因素对代码安全性的影响。研究成果强调了在现有漏洞检测工具的基础上，需要考虑代码和问题层面的信息来进行前瞻性风险评估的需求。
### Conclusion
研究发现，独立的LLM生成的修复引入了接近9倍于开发者的漏洞数量，并且这些漏洞在开发人员代码中未发现的模式较多。代理框架生成修复时，给予LLM更多自主权增加了错误理解项目背景或任务需求的风险。研究还指出了涉及更多文件、更多生成代码行以及缺乏具体代码片段或行为描述的GitHub问题更容易出现漏洞。这些结果强调了上下文因素对生成代码安全性的重要性，并提出了需求前瞻性的风险评估方法来结合现有漏洞检测工具。
## 722. `cs.LG` - Residual Prior-driven Frequency-aware Network for Image Fusion [PDF](https://arxiv.org/pdf/2507.06735), [HTML](https://arxiv.org/abs/2507.06735)
### Authors
Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma
### Background
图像融合的目标是通过整合不同模态下的互补信息生成高质量的融合图像，从而提高高级视觉任务的性能。然而，全球空间建模机制虽然显示了良好的效果，但在空间域中构造长程特征依赖关系带来了巨大的计算成本。此外，缺乏地面实况数据可能导致互补特征难以有效捕捉。
### Innovation
本文提出了一种基于残差前驱的频率感知网络（RPFNet），该网络采用了一种双分支特征提取框架：残差前驱模块（RPM）从残差图中提取模态特定的差异信息，为其融合提供互补先验；频域融合模块（FDFM）通过频域卷积高效实现全局特征建模与融合；双向特征交互模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。此外，训练过程中引入辅助解码器和显著结构损失强化了对模态特定差异的敏感性；并结合自适应加权频率对比损失和SSIM损失有效地约束了解决方案空间，确保融合图像同时包含局部细节和全局特征，保留互补信息。
### Conclusion
广泛的实验验证了RPFNet的融合性能，能够有效地整合区分特征，增强纹理细节和显著目标，并能有效促进高级视觉任务的部署。
## 723. `cs.LG` - 深度学习在几何问题求解中的研究综述 [PDF](https://arxiv.org/pdf/2507.11936), [HTML](https://arxiv.org/abs/2507.11936)
### Authors
Jianzhe Ma,Wenxuan Wang,Qin Jin
### Background
几何问题求解是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估和多模态能力评估等领域。近年来，深度学习技术的迅速发展，尤其是多模态大语言模型的兴起，引发了深入研究的热潮。
### Innovation
本文综述了深度学习在几何问题求解中的应用，包括（i）几何问题求解相关任务的全面总结；（ii）相关深度学习方法的深入审查；（iii）评估指标和方法的详细分析；（iv）当前挑战和未来研究方向的批判性讨论。旨在为几何问题求解提供全面实用的深度学习参考，促进该领域的进一步发展。
### Conclusion
本文通过提供不断更新的深度学习在几何问题求解方面的文献列表（此链接：this https URL.），为促进这一领域的进一步发展提供了宝贵资源和参考。
## 724. `cs.LG` - EEG基础模型：当前进展和未来方向的批判性回顾 [PDF](https://arxiv.org/pdf/2507.11783), [HTML](https://arxiv.org/abs/2507.11783)
### Authors
Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah
### Background
通过电生理记录的脑电图（EEG）活动对科学和临床研究有着巨大价值。但由于监督式EEG编码器学习鲁棒的EEG模式能力有限，并且过于依赖昂贵的信号注释，研究转向了通用的自监督EEG编码器，即EEG基础模型（EEG-FMs），以实现鲁棒和可扩展的EEG特征提取。然而，早期EEG-FMs的现实可用性及其长期研究进展尚不清晰。因此，需要系统性和全面性地回顾第一代EEG-FMs，以了解当前最先进的技术状态并确定未来EEG-FMs的关键方向。
### Innovation
研究回顾了10种早期的EEG-FMs，并对其方法、实证发现和存在的研究缺口进行了批判性的综合分析。研究发现，大多数EEG-FMs采用基于序列的建模方案，依赖于变压器结构并采用掩码序列重建进行自监督。同时，模型评估仍然存在异质性并且多有局限，导致难以评估其实用性。未来的工作应采用标准化和现实的评估手段，并展示更显著的规模效应，同时在EEG表示学习管道中做出原理性和可信赖的选择。
### Conclusion
研究认为，与领域专家合作开发基准测试、软件工具、技术方法和具体应用，将有助于提升EEG-FMs的转化实用性和实际应用范围。
## 725. `cs.LG` - Compositional Coordination for Multi-Robot Teams with Large Language Models [PDF](https://arxiv.org/pdf/2507.16068), [HTML](https://arxiv.org/abs/2507.16068)
### Authors
Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme
### Background
传统的多机器人协调依赖于专家驱动的特定任务管道，其中自然语言的任务描述需要由领域专家手工转化为数学建模、算法设计和可执行代码。这一传统过程耗费劳动力，非专家难以理解和参与，且不易于任务需求的变化。
### Innovation
提出了一种名为LAN2CB（Language to Collective Behavior）的新框架，利用大型语言模型（LLMs）来简化和通用化多机器人协调的管道。LAN2CB通过两个核心模块将自然语言的任务描述转换为可执行的Python代码：(1) 任务分析模块负责解析任务描述为行为树；(2) 代码生成模块则利用行为树和结构化知识库生成机器人控制代码。此外，还引入了一个自然语言任务描述的数据集支持开发和基准测试。实验表明，LAN2CB能实现从自然语言生成稳健且可灵活运用的多机器人协调，显著减少了手工工程的劳动，且能适应多种任务类型。
### Conclusion
实验结果在仿真和真实环境中的表现证明，LAN2CB能够从自然语言描述生成出稳健且具有高度灵活性的多机器人协调机制，显著减少了手动工程的劳动，并且在不同的任务类型中展现出广泛的适应性和推广性。
## 726. `cs.LG` - 在评估Transformer模型中的替代损失函数 [PDF](https://arxiv.org/pdf/2507.16548), [HTML](https://arxiv.org/abs/2507.16548)
### Authors
Jakub Michańków,Paweł Sakowski,Robert Ślepaczuk
### Background
在金融领域应用机器学习模型时，合理的测试设计和架构至关重要。选择合适的损失函数对于训练、验证、估计以及超参数调整非常重要。传统损失函数在预测生成模型（如算法投资策略中的模型）的优化方面可能并不总是最优的。因此，研究者通过实证实验评估了MADL（Mean Absolute Directional Loss）函数在评价Transformer和LSTM模型时的效果，旨在寻找更好的替代损失函数以优化预测生成模型的表现，并与LSTM模型进行了对比，结果显示在多种情况下，Transformer模型的表现优于LSTM模型。
### Innovation
研究引入了MADL函数作为替代损失函数，尤其在评估Transformer模型时，证明了它在优化算法投资策略中的预测生成模型方面比传统的损失函数更有效。此外，实验对比了Transformer和LSTM两种模型，并显示出Transformer模型在大多数情况下表现更优。
### Conclusion
通过实证研究，研究证实了MADL函数在优化预测生成模型方面的有效性，并且表明Transformer模型在多种应用场景中优于LSTM模型。这为金融领域的机器学习模型选择提供了新的视角。
## 727. `cs.LG` - 金融贷款风险预测中伪科学的影响 [PDF](https://arxiv.org/pdf/2507.16182), [HTML](https://arxiv.org/abs/2507.16182)
### Authors
Bruno Scarone,Ricardo Baeza-Yates
### Background
本文研究了伪科学假设对预测人们行为的社会影响，特别是在机器学习应用于金融放款中的风险管理。这一用例凸显了贷款回报预测中的生存偏差影响。我们从准确性和社会成本的角度分析了模型，表明在这一下游任务中，社会最优模型可能不会导致显著的准确性损失。结果得到了常用学习方法和数据集验证。我们的研究结果还表明，在训练易受生存偏差影响的模型时，虽然准确度会略微下降，但召回率和精准率会随时间提高，这种结果会产生误导，使观察者误以为系统在变好，实际上模型受到的不公平性和生存偏差越来越严重。
### Innovation
本文分析了伪科学假设对机器学习预测金融放款行为的影响，并揭示了由生存偏差引起的一系列问题，特别是在模型训练动态中的准确度变化及其误导性效果。
### Conclusion
尽管生存偏差会导致模型出现越来越严重的不公平性，但社会最优模型在预测下游任务时可能仍然能保持较好的准确性。研究还表明，准确度的下降和精准率、召回率的提高共同作用下的结果可能会误导观察者，使他们误以为模型的性能在改进，而非实际上其有效性在下降。
## 728. `cs.LG` - BlockDialect: 基于块的细粒度混合格式量化方法以实现高效的大语言模型推理 [PDF](https://arxiv.org/pdf/2501.01144), [HTML](https://arxiv.org/abs/2501.01144)
### Authors
Wonsuk Jang,Thierry Tambe
### Background
大语言模型（LLMs）的尺寸急剧增大导致了内存使用和计算成本的显著增加。量化权重和激活值可以解决这些问题，而硬件支持的细粒度缩放是缓解异常值的有前途的解决方案。然而，现有的方法难以捕捉块数据的细微分布。
### Innovation
本文提出了一种基于块的细粒度混合格式技术BlockDialect，该技术为每个块选择最优格式以更好地表示数据，并引入了DialectFP4格式书，这是一个适应多种数据分布的FP4变体。此外，提出了一种两阶段在线DialectFP4激活量化方法，并确保通过选择与低精度整数算术兼容的缩放整数来实现能效。BlockDialect与MXFP4相比，具有较低的位使用量，在LLaMA3-8B和LLaMA2-7B模型中分别实现了10.78%和7.48%的准确性提升，即使在全面量化全路径矩阵乘法时仅比全精度低5.45%和2.69%。
### Conclusion
我们的工作集中在如何表示而不是如何缩放，为高效的大语言模型推理提供了一条有前途的道路。
## 729. `cs.LG` - DAA*: 基于图像的路径规划的深度角度A*算法 [PDF](https://arxiv.org/pdf/2507.09305), [HTML](https://arxiv.org/abs/2507.09305)
### Authors
Zhiwei Xu
### Background
在路径模仿学习中，路径平滑性经常被忽视。本文介绍了一种新的学习方法，称为深度角度A*（DAA*），它在A*中引入了所提出的方向自由度（PAF），通过自适应路径平滑性来提高路径相似性。PAF旨在通过在最小值和最大值之间找到折中的方法来探索移动角度对路径节点扩展的影响，从而提高模仿学习中的适应性。
### Innovation
DAA*通过联合优化路径缩短和平滑来提高路径最优性，这分别对应于启发式距离和PAF。通过在7个数据集中进行全面评估，包括4个迷宫数据集、2个视频游戏数据集和一个包含2个场景的真实世界无人机视角数据集，证明了DAA*在预测路径与参考路径路径相似性之间的显著改进。而且，在同时学习路径损失和路径概率图损失时，DAA*显著优于最先进的TransPath，在SPR、PSIM和ASIM方面分别提高了6.3%、6.0%和3.7%。
### Conclusion
我们的研究发现，DAA*在路径平滑性和搜索效率之间有轻微的折中。我们的代码和模型权重可以在提供的链接中找到。
## 730. `cs.LG` - Anti-Aliased B-cos Networks for Faithful and Interpretable Chest X-ray Diagnosis [PDF](https://arxiv.org/pdf/2507.16761), [HTML](https://arxiv.org/abs/2507.16761)
### Authors
Marcel Kleinmann,Shashank Agnihotri,Margret Keuper
### Background
深度神经网络（DNNs）在医疗成像等安全关键领域的应用需要具备忠实性和可解释性。现有的B-cos网络虽然能够提供类特定的解释机制，但这些模型在解释图中存在严重的降级伪影，导致它们在临床应用中不可用，尤其是在多类别和多标签设置中.
### Innovation
本文通过引入FLCPooling（FLC）和BlurPool（BP）来改进B-cos网络的解释质量，从而消除降级伪影，增强模型的忠实性和可解释性。实验结果表明，改进后的B-cos_FLC和B-cos_BP模型在保留强大的预测性能的同时，提供了无伪影的、忠实的解释，适合临床应用.
### Conclusion
经过上述改进，B-cos网络在多类别和多标签设置下的胸部X光诊断中表现出了高度的忠实性和可解释性，能够满足临床应用的需求。相关代码已开源，可在GitHub仓库中找到.
## 731. `cs.LG` - Agentar-Fin-R1：通过领域专业知识、训练效率和高级推理增强金融智能 [PDF](https://arxiv.org/pdf/2507.16802), [HTML](https://arxiv.org/abs/2507.16802)
### Authors
Yanjun Zheng,Xiyang Du,Longfei Liao,Xiaoke Zhao,Zhaowen Zhou,Jingze Song,Bo Zhang,Jiawei Liu,Xiang Qi,Zhe Li,Zhiqiang Zhang,Wei Wang,Peng Zhang
### Background
大型语言模型（LLMs）在金融应用中显示出巨大的潜力，但现有模型在需要复杂推理能力、严格可信性标准和高效适应领域特定需求的场景中常常表现出局限性。
### Innovation
本研究介绍了基于Qwen3基础模型的Agentar-Fin-R1系列金融大型语言模型（8B和32B参数），并创新性地提出了Finova评估基准，该框架通过高质量可信知识工程、多agent可信数据合成和严格的数据验证治理。优化方法包括标签导向自动难度感知优化、分阶段训练管道和动态归因系统，以实现显著提高的训练效率。
### Conclusion
实验结果显示，Agentar-Fin-R1不仅在金融任务中达到当前最佳性能，还在通用推理基准测试中表现出色，证明了它在高风险金融应用中的有效性。Finova基准可在此处获得：this https URL。
## 732. `cs.SE` - 按指示使用？发布工作严谨性和透明度检查工具的比较 [PDF](https://arxiv.org/pdf/2507.17991), [HTML](https://arxiv.org/abs/2507.17991)
### Authors
Peter Eckmann,Adrian Barnett,Alexandra Bannach-Brown,Elisa Pilar Bascunan Atria,Guillaume Cabanac,Louise Delwen Owen Franzen,Małgorzata Anna Gazda,Kaitlyn Hair,James Howison,Halil Kilicoglu,Cyril Labbe,Sarah McCann,Vladislav Nachev,Martijn Roelandse,Maia Salholz-Hillel,Robert Schulz,Gerben ter Riet,Colby Vorland,Anita Bandrowski,Tracey Weissgerber
### Background
重现性危机的原因包括科学报告中的标准化和透明度不足。ARRIVE和CONSORT等清单试图提升透明度，但作者往往没有严格遵守，同行评审也常常未能识别出缺失的项目。为解决这些不足，已经设计了多种自动化工具来检查不同的严谨性标准。ScreenIT小组比较了11种自动化工具在9种不同严谨性标准的表现，发现了在某些标准（如检测公开数据）上最佳的单一工具，而在其他标准（如检测纳入和排除标准）上，工具组合的效果超过了任何单一工具。
### Innovation
该研究对11种自动化的严谨性和透明度检查工具进行了广泛的比较，特别是在检测公开数据和纳入排除标准方面，工具组合的表现超过了任何单一工具。此外，还指出了工具开发者需要改进的关键领域，以提高工具的实用性。
### Conclusion
该研究为严谨性和透明度检测工具的开发人员提供了一系列见解和建议，并将研究代码和数据发布在指定网址上。
## 733. `cs.SE` - 您的ATs到Ts：MITRE ATT&CK攻击技术到P-SSCRM任务映射 [PDF](https://arxiv.org/pdf/2507.18037), [HTML](https://arxiv.org/abs/2507.18037)
### Authors
Sivana Hamer,Jacob Bowen,Md Nazmul Haque,Chris Madden,Laurie Williams
### Background
本文档描述了MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK) 的攻击技术与Proactive Software Supply Chain Risk Management Framework (P-SSCRM) 任务映射，帮助软件组织确定如何通过不同任务来缓解软件供应链攻击中的攻击手段。这项映射基于四个独立策略创建，确保了每个P-SSCRM任务至少与MITRE ATT&CK或其他政府和行业框架中的一个任务相匹配。
### Innovation
该映射提供了MITRE ATT&CK攻击技术与P-SSCRM的任务之间的对应关系，使得软件组织能够更好地理解如何通过执行这些任务来抵御供应链攻击。这种方法通过四种独立策略来确保映射的准确性，并且映射不仅局限于MITRE ATT&CK框架，还可以映射到其他政府和行业框架中，增强了其适用性和广泛性。
### Conclusion
本文通过详细的任务映射，提供了极其有用的指导，帮助软件组织有效地管理软件供应链风险。这种跨框架的映射有助于统一不同安全框架的理解和实践，从而使供应链的安全性得到全面提升。
## 734. `cs.SE` - 软件工程师如何与AI互动：基于工业观察的实际过程模型和决策框架 [PDF](https://arxiv.org/pdf/2507.17930), [HTML](https://arxiv.org/abs/2507.17930)
### Authors
Vahid Garousi,Zafar Jafarov
### Background
人工智能（AI）可能通过提高生产力、效率和决策支持来转变软件工程（SE）。工具如GitHub Copilot和ChatGPT催生了一种称为“氛围编码”的探索性、提示驱动的开发风格。然而，软件工程师在日常任务中如何与这些工具互动，特别是他们决定是否信任、修改或拒绝AI生成的输出，仍然鲜有探讨。本文介绍了两个互补的贡献：首先，一个实用的过程模型，捕捉真实的AI辅助SE活动，包括提示设计、检查、降级和细化；其次，一个二维决策框架，帮助开发人员权衡节省努力和输出质量之间的权衡。这项研究基于土耳其和亚塞拜然三国工业环境中从业者报告和直接观察，展示了工程师如何在人类监督下使用AI工具。这些模型提供了结构化、轻量级的指导，以支持更刻意和有效的AI工具在SE中的使用，为现实的人机合作讨论做出了贡献。
### Innovation
本文提出的创新点包括两个方面：一是实用的过程模型，详细描述了真实世界中的AI辅助软件工程活动，包括提示设计、检查、降级和细化；二是二维决策框架，帮助开发人员权衡节省努力和输出质量之间的权衡，提供了实用的指导方法。
### Conclusion
本文的工作展示了工程师如何在人类监督下使用AI工具。这些模型提供了结构化和轻量级的指导，以支持更刻意和有效的AI工具在软件工程中的使用，对现实的人机合作讨论做出了贡献。
## 735. `cs.SE` - GitHub Actions 工作流复杂性、异质性和合规性的人类学研究 [PDF](https://arxiv.org/pdf/2507.18062), [HTML](https://arxiv.org/abs/2507.18062)
### Authors
Edward Abrokwah,Taher A. Ghaleb
### Background
持续集成（CI）已从一种工具策略发展成为现代CI工程中不可或缺的思维方式。它使团队能够快速、协作地开发、测试和交付软件。GitHub Actions（GHA）因其与GitHub的深层集成和广泛可重用的工作流行动生态系统，已成为主流服务。尽管GHA提供了官方文档和社区支持的最佳实践，但对于开源软件仓库中的实际CI工作流如何符合这些实践的理解却有限。许多工作流可能过于复杂且不符合CI实践的简洁性目标。
### Innovation
本研究将调查开源软件仓库中GitHub Actions工作流的结构、复杂性、异质性和合规性。基于Java、Python和C++仓库的大型数据集，研究目标包括（a）识别工作流复杂性，（b）分析重复性和异质性结构模式，（c）评估工作流与GHA最佳实践的合规性，（d）揭示不同编程语言在CI管道设计上的差异。研究期望揭示遵守最佳实践的强处和需要改进的领域，为CI服务提供更清晰的指南和全面的示例。
### Conclusion
研究发现将揭示遵守最佳实践的强处和需要改进的领域。这些见解还将对CI服务产生影响，突显了CI文档中更清晰指南和全面示例的必要性。
## 736. `cs.SE` - 标识符名称相似性：一项探索性研究 [PDF](https://arxiv.org/pdf/2507.18081), [HTML](https://arxiv.org/abs/2507.18081)
### Authors
Carol Wong,Mai Abe,Silvia De Benedictis,Marissa Halim,Anthony Peruma
### Background
标识符名称构成了代码库的重要部分，是有效程序理解的基础。然而，研究表明，选择不佳的标识符名称会导致认知负担增加，阻碍协作。即使看上去可读的名称在特定上下文中也可能会因为与其他名称在结构或功能上的相似而引起误解。这项探索性研究旨在通过开发一个分类法来探索软件项目中标识符名称相似性的发生情况，从而有助于分析和评估标识符名称相似性对代码理解、可维护性和开发者之间的协作的影响。
### Innovation
本文提出了一个初步的分类法来分类不同的标识符名称相似形式，该分类法为研究者提供了分析和评估标识符名称相似性对代码理解、可维护性和开发者间协作影响的平台。同时，也提到了该分类法可以进一步改进和扩展.
### Conclusion
本文初步探讨了软件项目中标识符名称相似性的发生情况，提出了一个分类法以助于分析和评估其对代码理解、可维护性和开发者协作的影响，并展望了分类法的进一步改进和扩展.
## 737. `cs.SE` - 影响计算教育中项目式学习采用因素：一项调查 [PDF](https://arxiv.org/pdf/2507.18039), [HTML](https://arxiv.org/abs/2507.18039)
### Authors
Ahmad D. Suleiman,Yiming Tang,Daqing Hou
### Background
研究探讨了影响计算教育工作者在软件工程和计算课程中采用项目式学习（PjBL）的因素。尽管PjBL作为一种以学生为中心的教育方法能够提高学生的动机、参与度、批判性思维、合作和问题解决能力，但由于机构支持不足、时间限制、培训机会有限、项目设计或资源获取困难以及与课程目标的对齐等问题，教师的采用情况并不一致。已有研究表明，克服这些障碍并调查促进成功采用的策略和资源是关键。本研究通过在线调查收集 computing 专业教师的数据，包括封闭式问题量化解决策路障、促进因素和资源需求，以及开放式问题收集定性见解，采用混合方法分析数据，揭示了教师对PjBL的广泛认可，但在实施计划和管理学习过程、设计合适的项目方面遇到挑战，且缺乏机构支持（如时间、资金和助教）。教职工更可能采用或维持PjBL时，能获得同行合作、专业发展和支持机构激励。此外，从研究、行业合作和借鉴同行获取项目是新项目的有力促进因素。研究结果强调了需要系统支持结构来赋能教师实验和扩展PjBL实践的必要性。
### Innovation
本研究采用混合方法，通过在线调查收集了80名计算专业教师的数据，通过封闭式问题和开放式问题收集量化和定性数据，借助统计分析和主题分析方法，探究教师在采用项目式学习中的障碍、促进因素和资源需求。这项研究提供了一种有效的方法来深入了解教师在采用PjBL过程中的实际需求和挑战，并提出了改进策略，为未来的教学实践提供了有力支持。
### Conclusion
研究结果表明，尽管教师普遍认为PjBL有益，但在实际采用过程中仍面临诸多挑战。而通过机构提供的同伴合作、专业发展和激励措施，以及项目的跨学科获取途径，可以有效促进PjBL的采用。因此，研究强调了系统性支持结构的重要性，以鼓励教师探索并扩大PjBL的教学实践。
## 738. `cs.LG` - PerceptionLM：开放访问的数据与模型以实现详细的视觉理解 [PDF](https://arxiv.org/pdf/2504.13180), [HTML](https://arxiv.org/abs/2504.13180)
### Authors
Jang Hyun Cho,Andrea Madotto,Effrosyni Mavroudi,Triantafyllos Afouras,Tushar Nagarajan,Muhammad Maaz,Yale Song,Tengyu Ma,Shuming Hu,Suyog Jain,Miguel Martin,Huiyu Wang,Hanoona Rasheed,Peize Sun,Po-Yao Huang,Daniel Bolya,Nikhila Ravi,Shashank Jain,Tammy Stark,Shane Moon,Babak Damavandi,Vivian Lee,Andrew Westbury,Salman Khan,Philipp Krähenbühl,Piotr Dollár,Lorenzo Torresani,Kristen Grauman,Christoph Feichtenhofer
### Background
视觉-语言模型在计算机视觉研究中占据重要地位，但许多高绩效模型仍为闭源，保密数据、设计和训练配方。这阻碍了开放的科学进展。研究社区试图通过从黑盒模型中提取知识标签训练数据，实现了强基准结果，但打破了科学实践。未知教师模型及其数据来源的细节，使得科学进展难以评估。
### Innovation
本文研究构建了一个完全开放且可重现的感知语言模型（PLM），以透明的研究方式推动图像和视频理解。文章未使用来自专有模型的知识蒸馏进行标准训练管道分析，而是大量大规模合成数据填补了重要数据缺口，特别是在详细视频理解方面。为此，本文发布了2.8M个细粒度视频问答实例以及时空定位的视频字幕。此外，引入了PLM-VideoBench，一个针对视频理解任务的评估套件，特别关注“什么”、“哪里”、“何时”、“如何”等方面的能力。文章提供了所有内容，确保所有的资源、训练配方、代码和模型都可完全重现。
### Conclusion
通过提供开放、完整的数据集、训练配方、代码和模型，本文的研究促进了透明的科学研究，特别是在视频理解技术方面取得了重要进展。
## 739. `cs.SE` - 基于GitHub议题讨论的开源游戏开发中GenAI采用实证研究：工具、任务与开发者挑战 [PDF](https://arxiv.org/pdf/2507.18029), [HTML](https://arxiv.org/abs/2507.18029)
### Authors
Xiang Echo Chen,Wenhan Zhu,Guoshuai Albert Shi,Michael W. Godfrey
### Background
生成型人工智能（GenAI）的能力正在改变游戏的设计和开发方式，为内容创作、玩法模拟和设计构思提供了新的工具。尽管已有研究探讨了传统AI在游戏中的使用，但对GenAI在实际开发环境中被开发人员采用的具体情况，特别是在开源社区中的应用，缺乏实证理解。
### Innovation
本文通过对GitHub上的开源游戏开发中的GenAI相关议题进行分析，比较GenAI与传统AI和非AI话题的工具、任务和挑战，揭示GenAI在使用模式、关注点和集成实践方面的独特之处。这种方法提供了关于GenAI如何影响开源游戏开发工作流程和痛点的见解，填补了现有研究的空白。
### Conclusion
研究发现，GenAI在开源游戏开发中呈现出不同的采用模式和开发人员关注点，其工具、任务和挑战有自己的特点。这有助于更好地理解GenAI对开源游戏开发的影响，并为相关实践提供指导。
## 740. `cs.SE` - NoCode-bench: 评估自然语言驱动功能添加的基准 [PDF](https://arxiv.org/pdf/2507.18130), [HTML](https://arxiv.org/abs/2507.18130)
### Authors
Le Deng,Zhonghao Jiang,Jialun Cao,Michael Pradel,Zhongxin Liu
### Background
自然语言驱动的无代码开发允许用户使用自然语言（NL）而不是直接编辑源代码来指定软件功能，这有望提高生产力并使开发民主化。大规模语言模型（LLMs）有潜力实现这一范式。在这种背景下，软件文档起到了NL功能规范的作用。这项工作引入了NoCode-bench，这是一个旨在评估LLMs在真实世界的NL驱动特性添加任务中的基准，包括来自10个项目和634项任务的114,000次代码更改。每个任务都是一对文档更新和相应的代码实现，由开发者编写的测试案例验证。NoCode-bench还包含114个高质量的人工验证实例，NoCode-bench Verified，以确保可靠评估。实验结果显示，尽管LLMs使用了大量的词汇，但最优LMMs的成功率也只有15.79%，反映出跨文件编辑、代码库理解以及工具调用等方面存在的挑战。这些发现表明，当前LLMs尚未准备好实现完全自然语言驱动的无代码开发。NoCode-bench为该领域的未来进步奠定了基础。
### Innovation
NoCode-bench是一个基于真实世界的基准，用于对大规模语言模型（LLMs）在自然语言驱动功能添加中的表现进行评估。它包含了634项任务和114,000次代码更改，通过人工验证的实例确保评价的可靠性。这项工作的创新在于提供了一个实际可用的基准，增强了对LLMs能力的理解，并指出了实现更强大无代码开发的技术挑战。
### Conclusion
尽管已经证明大规模语言模型具有潜力支持自然语言驱动的无代码开发，但在复杂的任务如跨文件编辑、代码库理解和工具调用方面仍然存在许多挑战。NoCode-bench不仅揭示了当前LLMs的局限性，还为未来研究方向提供了依据。这项工作是迈向更强大无代码开发的重要一步。
## 741. `cs.SE` - 对具身人工智能机器人（EAIR）软件错误的实证研究 [PDF](https://arxiv.org/pdf/2507.18267), [HTML](https://arxiv.org/abs/2507.18267)
### Authors
Zeqin Liao,Zibin Zheng,Peifan Reng,Henglong Liang,Zixu Gao,Zhixiang Chen,Wei Li,Yuhong Nan
### Background
具身人工智能机器人（EAIR）是一个快速发展的技术领域，确保其程序正确性是其成功部署的基础。然而，关于EAIR系统错误的全面深入理解仍然不足，这阻碍了开发针对系统错误的实践和方法的发展。本文通过对80个EAIR系统项目收集的885个系统错误进行系统的分析研究，填补了这一空白。
### Innovation
1. 发现了15种特定于EAIR系统的错误症状，其中8种症状表现为严重的功能失效和潜在的物理风险。2. 确定了8种特定于EAIR系统的根本原因，大部分原因是复杂的AI-代理推理和决策问题。3. 构建了一份底层原因与发生频率最高的模块之间的映射，这有助于研究人员集中诊断努力在最易发生特定类型错误的模块上。
### Conclusion
该研究揭示了关于EAIR系统错误的几个新发现和启示，有助于未来针对或修复EAIR系统错误的研究。
## 742. `cs.SE` - GenAI for Automotive Software Development: From Requirements to Wheels [PDF](https://arxiv.org/pdf/2507.18223), [HTML](https://arxiv.org/abs/2507.18223)
### Authors
Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll
### Background
本文介绍了利用GenAI赋能的自动化汽车软件开发方法，重点关注自动驾驶和高级驾驶辅助系统（ADAS）功能。该过程以需求为输入，主要输出为仿真环境的测试场景代码，以及针对连接到测试台的车辆硬件平台的ADAS能力实现代码。此外，通过利用模型驱动工程（MDE）进行需求一致性检查，增加了额外步骤。在所提议的工作流程中，大语言模型（LLMs）被用于需求（Ecore元模型、XMI模型实例和OCL约束创建）的基础模型总结、测试场景生成、仿真代码（Python）和目标平台代码生成（C++）。此外，采用检索增强生成（RAG）技术，从自动驾驶法规相关文档中增强测试场景生成。这种方法旨在缩短合规性和重新工程周期，以及减少与ADAS相关功能的开发和测试时间。
### Innovation
本文提出了一种通过GenAI赋能的自动化汽车软件开发生命周期方法，特别引入了模型驱动工程（MDE）进行需求一致性检查，结合大语言模型和检索增强生成（RAG）技术来提升测试场景生成的效果。这种方法能够显著缩短合规性和重新工程周期，减少开发与测试时间，特别是在ADAS相关功能的实现过程中。
### Conclusion
通过GenAI赋能的自动化汽车软件开发生命周期方法，结合模型驱动工程和大语言模型以及检索增强生成技术，能够有效提高自动驾驶和ADAS功能的开发效率，从而缩短合规性和重新工程周期，减少开发和测试时间。
## 743. `cs.LG` - 基于迁移学习的遥感影像水体分割方法：札达图伦区域案例研究 [PDF](https://arxiv.org/pdf/2507.10084), [HTML](https://arxiv.org/abs/2507.10084)
### Authors
Haonan Chen(Tibet University),Xin Tong(Northwestern Polytechnical University)
### Background
青藏高原由于其对气候变化的高度敏感性，面临着严重的水安全挑战。因此，为了在该地区建立气候韧性，前进的地球观测对于可持续水资源监测至关重要。研究表明，利用SegFormer模型的两阶段迁移学习策略可以克服开发气候敏感应用中稳健AI技术的关键障碍，如域偏移和数据稀缺。
### Innovation
提出了一种基于迁移学习的两阶段策略，利用SegFormer模型，首先在多样的源域中进行预训练，然后针对干旱的札达图伦区域进行微调。实验结果显示，自直接迁移的效果提升显著：水体分割的交并比（IoU）从25.50%提升到64.84%，这对于减少灾害风险，特别是监测易发生突然洪水系统的监测具有重要意义。高精度图展示了水体的空间分布高度集中性，超过80%的水域面积集中在不到20%的河流长度内，这一定量发现对于理解水文过程和设计针对性的水资源管理和气候适应策略提供了关键证据。
### Conclusion
本研究证明了一种有效的技术解决方案，用于监测干旱高原区域，并为在关键跨界河流源头地带利用AI驱动的地球观测进行灾害准备做出了贡献。
## 744. `cs.LG` - PRIX: 从原始像素学习规划以实现端到端自动驾驶 [PDF](https://arxiv.org/pdf/2507.17596), [HTML](https://arxiv.org/abs/2507.17596)
### Authors
Maciej K. Wozniak,Lianhang Liu,Yixi Cai,Patric Jensfelt
### Background
虽然端到端的自动驾驶模型表现出令人鼓舞的结果，但它们的实际部署常常受限于大型模型的规模、对昂贵的激光雷达（LiDAR）传感器的依赖以及计算密集型的BEV特征表示。这限制了这些模型的可扩展性，特别是在只有摄像头但没有LiDAR的量产车上。
### Innovation
我们提出了PRIX（从原始像素规划），这是一种全新的、高效的一体化驾驶架构，仅使用摄像头数据，而不需要明确的BEV表示，并且不需要LiDAR。PRIX 利用了视觉特征提取器和生成规划头，能从原始像素输入中直接预测安全轨迹。该架构的核心组件是感知相关校准转换器（CaRT），这是一种新模块，旨在有效地增强多级视觉特征，以实现更稳健的规划。
### Conclusion
通过全面的实验，我们展示了PRIX在导航仿真（NavSim）和nuScenes基准测试中达到了最先进的性能，与大型、多模态扩散规划者的能力相当，但在推理速度和模型大小方面更为高效，使其成为实际部署的切实可行解决方案。我们的工作是开源的，代码可以在这里找到：[该链接]。
## 745. `cs.SE` - Scheduzz: 基于约束的双调度Fuzz驱动生成 [PDF](https://arxiv.org/pdf/2507.18289), [HTML](https://arxiv.org/abs/2507.18289)
### Authors
Yan Li,Wenzhang Yang,Yuekun Wang,Jian Gao,Shaohua Wang,Yinxing Xue,Lijun Zhang
### Background
模糊测试库需要专家理解库的使用方式并精心构建高质量的模糊测试驱动程序，这是既困难又耗时的过程。因此，提出了许多技术来自动生成模糊测试驱动程序。然而，这些技术由于未能遵循适当的库使用规范，如确保资源在打开后被关闭，而未能生成合理的模糊测试驱动程序。此外，现有库模糊测试技术不判断执行每个驱动程序，导致大量不合理的驱动程序消耗计算资源，却未能提供覆盖度并产生虚假的bug报告。
### Innovation
我们提出了一种名为Scheduzz的新颖自动库模糊测试技术，这是一种基于大语言模型（LLM）的库模糊测试技术。它利用LLM来理解库的合理使用方式并提取API组合约束。为了优化计算资源的使用，实施了一个双调度框架来高效管理API组合和模糊测试驱动程序。框架将驱动程序生成和相应的模糊测试运动建模为在线优化问题。在调度循环中，多个API组合被选中以生成模糊测试驱动程序，同时，各种优化模糊测试驱动程序被调度执行或暂停。
### Conclusion
我们实施了Scheduzz，并在33个真实世界的库中进行了评估。与基线方法相比，Scheduzz显著减少了计算开销，并在21个库中有16个库上表现优于UTopia。它分别实现了比最先进的技术CKGFuzzer、Promptfuzz和手工制作的项目OSS-Fuzz高出1.62倍、1.50倍和1.89倍的总体覆盖率。此外，Scheduzz在这些经过良好测试的库中发现了33个先前未知的bug，其中有3个被赋予了CVE编号。
## 746. `cs.SE` - YATE：LLM基的单元测试生成中的修复作用 [PDF](https://arxiv.org/pdf/2507.18316), [HTML](https://arxiv.org/abs/2507.18316)
### Authors
Michael Konstantinou,Renzo Degiovanni,Jie M. Zhang,Mark Harman,Mike Papadakis
### Background
最新的研究利用语言模型自动生成单元测试，这种方法非常有效。然而，语言模型生成的测试用例往往包含很多错误（无论是语法还是逻辑层面）。尽管这些错误的测试用例可以很容易地被检测并丢弃，但这一过程构成了一个“错过的机会”——如果这些错误被纠正，它们通常是有价值的，因为这样可以直接增加测试的价值（它们直接瞄准被测程序的逻辑），并且间接地成为生成更多测试用例的良好种子。因此，有必要提出一种方法来修正这类错误的测试用例，以提高测试的效果。
### Innovation
本文提出了一种简单技术YATE，通过结合规则基础的静态分析和重提问来修正错误的测试用例。实验结果显示，与单纯的基于语言模型的方法相比，YATE可以更有效地生成测试用例，覆盖更多的代码行数，并消灭更多的测试对象。此外，YATE的性能优于其他四种基于语言模型的方法，包括更高的代码覆盖率和分支覆盖率，以及消灭更多的测试对象。
### Conclusion
实验表明，YATE能有效地生成覆盖面更广的测试用例，比单纯的基于语言模型的方法提高32.06%的覆盖率，杀死21.77%更多的测试对象。与四种其他基于语言模型的方法相比，YATE在代码覆盖率、分支覆盖率和消灭测试对象方面表现更佳，而且成本相当。
## 747. `cs.LG` - 使用视觉、声音和触觉进行温柔抓取的学习 [PDF](https://arxiv.org/pdf/2503.07926), [HTML](https://arxiv.org/abs/2503.07926)
### Authors
Ken Nakahara,Roberto Calandra
### Background
日常生活中，我们经常遇到容易损坏的物体，如水果，过度的抓握力会导致这些物体受损。因此，抓取这些物体时，关键在于轻轻抓取，即使用最少的必要力量，而不是最大的力量。本文提出了利用视觉、触觉和听觉信号来学习稳定、温和的物体抓取。
### Innovation
本文创新性地使用声音信号作为判断抓取动作是否温和的指标，同时从原始的视听触输入中训练一个端到端的动作条件模型，预测未来抓取候选动作的稳定性和温和性，从而选择并执行最有希望的动作。实验证明，该模型在多次抓取试验中提高了抓取的准确性和性能，并且在实际实验中展示了优于其他基线方法的抓取表现，特别是对于稳定且温和的抓取。该方法不需要触觉传感器校准或分析力模型，大幅减少了抓取易碎物体的工程努力。
### Conclusion
通过多指灵巧手在1500次抓取试验中验证了模型的有效性，其预测性能高于仅使用视觉的模型，并且实际实验表明，使用训练的多模态模型的抓取表现优于其他基线方法，特别是在稳定温和抓取方面有17%的较高成功率。
## 748. `cs.SE` - 理解大型语言模型应用的供应链及其风险 [PDF](https://arxiv.org/pdf/2507.18105), [HTML](https://arxiv.org/abs/2507.18105)
### Authors
Yujie Ma,Lili Quan,Xiaofei Xie,Qiang Hu,Jiongchi Yu,Yao Zhang,Sen Chen
### Background
随着大型语言模型（LLMs）的兴起，这些模型被广泛应用于各个领域，但随着它们的普及，对其复杂供应链中的风险理解变得越来越重要。这些模型并不是独立的，而是依赖于包含预训练模型、第三方库、数据集和基础设施的互联供应链。然而，大多数风险评估仅集中在模型或数据层面，忽视了更广泛的供应链漏洞。尽管最近已有研究开始关注LLM供应链风险，但仍缺乏系统研究的标准。
### Innovation
为填补这一空白，该论文引入了首个全面的数据集，用于分析和基准测试LLM供应链安全。该数据集收集了3,859个实际应用中的LLM，并进行了相互依赖性分析，识别了109,211个模型、2,474个数据集和9,862个库。该研究提取了模型微调路径、数据集重复使用和库依赖性，绘制了生态系统的结构。研究还收集了1,555个与安全相关的风险问题，包括应用于操作、模型、数据集和库的50个、325个、18个和1,229个。利用该数据集，实证分析组件依赖性和风险。研究发现，大型语言模型的应用中存在深层次的依赖性，并在供应链的各个部分发现了显著的漏洞，突显了全面的安全分析的重要性。
### Conclusion
研究最后提供了实用的建议，以指导研究者和开发人员向更安全、更可信赖的LLM启用系统迈进。
## 749. `cs.SE` - SMECS: 软件元数据提取和管理软件 [PDF](https://arxiv.org/pdf/2507.18159), [HTML](https://arxiv.org/abs/2507.18159)
### Authors
Stephan Ferenz,Aida Jafarbigloo,Oliver Werth,Astrid Nieße
### Background
元数据对于遵循FAIR原则，并提高研究软件的可查找性和可重用性至关重要。然而，高质量元数据的创建对研究人员和研究软件工程师来说可能是资源密集型的。
### Innovation
提出了Software Metadata Extraction and Curation Software (SMECS)。该软件整合了从现有来源提取元数据与用户友好的元数据管理界面。SMECS从在线仓库（如GitHub）提取元数据，并通过交互式界面呈现给研究人员进行进一步的管理和导出为CodeMeta文件。通过可用性实验评估了SMECS的易用性，证实了它提供了令人满意的用户体验。SMECS简化了研究软件的FAIR化过程。
### Conclusion
SMECS通过简化元数据创建流程，支持研究软件的FAIR化，从而提高了研究软件的可查找性和可重用性。
## 750. `cs.SE` - 深入探究代码补全的检索增强生成：WeChat 经验 [PDF](https://arxiv.org/pdf/2507.18515), [HTML](https://arxiv.org/abs/2507.18515)
### Authors
Zezhou Yang,Ting Peng,Cuiyun Gao,Chaozheng Wang,Hailiang Huang,Yuetang Deng
### Background
代码补全作为软件工程中的关键任务，能够提升开发人员的生产力，随着大型语言模型（LLMs）的快速发展，其性能得到显著提升。近年来，检索增强生成（RAG）作为一种新的方法，在增强LLMs的代码补全能力方面表现出巨大潜力。现有研究表明，RAG方法在开源代码库和基准上的有效性得到了验证，但开源和闭源代码库之间的分布变化带来了独特的挑战。因此，本文通过在WeChat中进行实证研究，探索RAG方法在大规模工业代码库中的表现，WeChat是最大的专有软件系统之一。研究涵盖了26个参数范围从0.5B到671B的不同开源LLMs中的两种主要类型的RAG方法：基于标识符的RAG和基于相似性的RAG，并使用不同的检索技术进行基于相似性的RAG的分析，包括词法和语义检索。研究结果表明，RAG方法在闭源代码库中表现出有效性，基于相似性的RAG方法性能更优，其性能随着更先进的检索技术的使用而提高，同时组合使用词法和语义检索技术能够获得最佳结果，显示了互补的优势。研究还通过开发者调查验证了RAG方法在实际开发环境中的实用性。
### Innovation
本文通过深入研究RAG方法在WeChat工业规模代码库中的应用，首次探索开源与闭源代码库之间的潜在分布变化影响下的RAG方法性能，提出了基于标识符的RAG和基于相似性的RAG两种主要类型，并验证了更先进的检索技术的使用可以显著提高基于相似性的RAG方法的性能，同时展示了组合使用词法和语义检索技术的优势。
### Conclusion
研究结果表明，RAG方法在闭源代码库中能够有效提升代码补全性能，尤其是基于相似性的RAG方法，其性能随更先进技术的使用而提升，而词法和语义检索技术的结合使用在实际应用中具有最佳的效果，验证了RAG方法在实际开发环境中的实用价值。
## 751. `cs.SE` - 由表达约束中间表示引导的3D软件合成 [PDF](https://arxiv.org/pdf/2507.18625), [HTML](https://arxiv.org/abs/2507.18625)
### Authors
Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu
### Background
图形用户界面（UI）软件经历了从传统的二维（2D）桌面、网页和移动界面到三维（3D）环境的根本转变。尽管现有工作在2D软件自动化生成方面已取得显著成就，例如HTML/CSS和移动应用界面的代码合成，但在3D软件生成方面仍处于探索阶段。现有方法通常整体制作3D环境，不支持对具体元素进行修改或控制，且难以处理现实世界中的复杂空间和语义约束。
### Innovation
提出了一种新颖的Scenethesis方法，通过ScenethesisLang这一特定领域语言作为细粒度的、约束感知的中间表示（IR），连接自然语言需求和可执行的3D软件。Scenethesis将用户规格与生成的3D软件保持正式的可追溯性，通过将3D软件合成分解为处理ScenethesisLang的不同阶段，实现独立验证、目标修改和系统约束满足，从而提高3D软件合成的灵活性和可控性。
### Conclusion
实验表明，Scenethesis能够捕获超过80%的用户需求，满足超过90%的硬约束，同时处理超过100个约束。此外，与最新方法相比，Scenethesis在BLIP-2视觉评估测试中取得了42.8%的改进。
## 752. `cs.SE` - 为什么公平对软件从业者至关重要：为什么公平如此重要 [PDF](https://arxiv.org/pdf/2410.02482), [HTML](https://arxiv.org/abs/2410.02482)
### Authors
Emeralda Sesari,Federica Sarro,Ayushi Rastogi
### Background
软件从业者经常遭遇职场不公，如不公的认可和性别偏见。虽然其他领域已建立了公平与工作满意度之间的联系，但这一关联对于软件专业人员来说仍然被忽视。本研究旨在探讨公平感知与软件从业者工作满意度之间的关系，不仅关注总体趋势，还特别关注不同性别、民族背景等特定群体的差异。通过在线调查收集了108名软件从业者的数据，并通过有序逻辑回归分析了公平感知与软件工程背景下的工作满意度之间的关系，同时使用调节分析探讨了这种关系在不同群体间的变化。
### Innovation
本研究创新性地探讨了软件从业者中公平感知对工作满意度的影响，并通过多维度分析和技术方法（如有序逻辑回归和调节分析）来探索不同群体之间的差异，特别是在性别、少数族裔、经验和工作限制等方面的影响，并特别强调了作者身份公平和政策实施公平在不同群体中的作用。
### Conclusion
研究表明，分配公道性、程序公道性、人际公道性和信息公道性四个公平维度都显著影响整体工作满意度和工作保障满意度。其中，人际公道性影响最大。公平与工作满意度之间的关系对女性、种族少数群体、经验较少的员工和有工作限制的人员更为显著。作者身份的公平性对所有群体的工作满意度都非常重要，而政策实施公平性、高需求情况下的公平性以及工作时间的公平性对特定群体的影响更大。本研究强调了软件从业者公平问题的重要性，并为组织推行公平实践和针对特定群体的措施提供了策略建议。
## 753. `cs.SE` - SAVANT: 通过语义引导可达性分析在应用程序依赖中检测漏洞 [PDF](https://arxiv.org/pdf/2506.17798), [HTML](https://arxiv.org/abs/2506.17798)
### Authors
Wang Lingxiang,Quanzhi Fu,Wenjia Song,Gelei Deng,Yi Liu,Dan Williams,Ying Zhang
### Background
在Java开发中，集成开源第三方库的依赖引入了巨大的安全风险，尤其是在这些库包含已知漏洞的情况下。现有的软件组成分析（SCA）工具由于缺乏对API使用语义的理解和对复杂代码库分析的计算挑战，很难有效地检测来自这些库的漏洞用法，导致不准确的漏洞警报，给开发团队带来负担，并延迟关键的安全修复。
### Innovation
SAVANT通过利用两个洞察点来解决这些挑战：漏洞测试案例展示了如何在特定上下文中触发漏洞，以及大型语言模型（LLMs）可以理解代码语义。SAVANT结合了语义预处理和LLM驱动的上下文分析，实现精确的漏洞检测。首先，SAVANT将源代码分割成有意义的块，同时保留语义关系，然后利用LLM基础的反射分析API使用上下文并确定实际的漏洞影响。
### Conclusion
在55个真实世界应用程序的评估中，SAVANT的精度为83.8%，召回率为73.8%，准确率为69.0%，F1分数为78.5%，表现优于最先进的SCA工具。
## 754. `cs.SE` - Gotta catch 'em all! Towards File Localisation from Issues at Large [PDF](https://arxiv.org/pdf/2507.18319), [HTML](https://arxiv.org/abs/2507.18319)
### Authors
Jesse Maarleveld,Jiapan Guo,Daniel Feitosa
### Background
文件定位，即研究开发用于定位需要更改以解决错误的文件的方法，已经进行了很长一段时间，旨在开发能够节省开发人员时间的方法。近年来，研究人员开始考虑与错误之外的问题相关的问题。然而，大多数现有研究主要集中在从问题到文件定位的方法都集中在错误上，或仅考虑特定类型的问题作为工作重点的一部分。
### Innovation
本文提供了一种数据管道，可以处理任意的分支和合并实践，用于创建问题文件定位数据集。作者还提供了基线性能评估，使用传统的信息检索方法来解决文件定位问题。此外，结果显示利用特定错误启发式设计的方法在一般问题类型上表现不佳，这表明需要研究通用模型。同时，作者还发现不同问题类型在性能上存在统计上显著但很小的差异，并且标识符的存在对大多数问题类型的表现有很小的影响。
### Conclusion
实验结果表明，使用特定错误启发式设计的方法在一般问题上表现不佳，这凸显了需要研究通用模型的必要性。此外，研究发现不同问题类型之间存在统计上显著但很小的性能差异，表明文件定位方法需要针对特定项目的特征进行调整。
## 755. `cs.SE` - OpenCAMS: 开源互联和自动出行仿真平台，用于推进下一代智能交通系统研究 [PDF](https://arxiv.org/pdf/2507.09186), [HTML](https://arxiv.org/abs/2507.09186)
### Authors
Minhaj Uddin Ahmad,Akid Abrar,Sagar Dasgupta,Mizanur Rahman
### Background
现有的交通仿真工具通常缺乏跨领域的集成能力，这限制了在交通安全、移动性和网络安全等高级研究方面的进展。OpenCAMS 是一个开源的、同步的、可扩展的联合仿真框架，将三个最佳的仿真工具（SUMO、CARLA 和 OMNeT++）紧密耦合，旨在通过结合各仿真领域的优点来支持这些方面的研究。SUMO 提供大规模的微观交通建模，CARLA 提供高保真度的 3D 感知、车辆动力学和控制仿真，OMNeT++ 则允许模块化、事件驱动的网络通信，如蜂窝V2X通信。OpenCAMS 通过时间同步的双向耦合架构确保各个领域（交通、感知、通信）的仿真协调进行，同时保持模块化和可重现性。
### Innovation
OpenCAMS 采用了一种时间同步的双向耦合架构，这种架构确保了交通、感知和通信领域之间的协调仿真。这种平台可以支持高级研究，显著提高交通系统的安全性、移动性和网络安全。此外，OpenCAMS 设计为可扩展的，可以方便地集成更多的仿真工具，而不会破坏系统的架构，为未来的发展提供了灵活性和前瞻性。
### Conclusion
OpenCAMS 平台是完全开源和公开的，可以通过 GitHub 仓库获取 https://github.com/example/OpenCAMS，为研究社区提供了一个可访问的、灵活的和协作的环境，用于推进下一代智能交通系统的研发。
## 756. `cs.SE` - muRelBench: 微基准测试用于zonotopic 域 [PDF](https://arxiv.org/pdf/2404.16243), [HTML](https://arxiv.org/abs/2404.16243)
### Authors
Kenny Ballou,Elena Sherman
### Background
该研究背景是在弱关系抽象域及其操作的合成基准测试框架方面缺乏系统性工具。之前的研究中，研究人员在验证数值抽象域中的算法时，缺乏有效的实验评估工具，尤其是在验证性能改进方面。
### Innovation
muRelBench 提供了一个可扩展的微基准测试框架，用于评估弱关系抽象域及其操作中的算法。该框架支持快速原型设计和性能验证，并内部验证了合成基准内每一个基准的正确性。
### Conclusion
通过使用 muRelBench，研究人员能够更高效和准确地评估和改进数值抽象域中的算法。这将推动相关领域算法的进一步优化和发展。
## 757. `cs.SE` - OrQstrator：一种基于AI的高级量子电路优化框架 [PDF](https://arxiv.org/pdf/2507.09682), [HTML](https://arxiv.org/abs/2507.09682)
### Authors
Laura Baird,Armin Moin
### Background
在量子有限规模量子（NISQ）时代，优化量子电路变得尤为重要，因为这直接影响到量子计算的实际应用效果。目前的量子计算机面临严重的噪声和硬件限制，因此需要一种智能化的方法来优化量子电路，以提高其在实际硬件上的性能。
### Innovation
提出了一种基于深度强化学习（DRL）的新颖模块化框架OrQstrator，用于NISQ时代的量子电路优化。这个框架包括一个智能调度引擎，能够从三个互补的优化器中选择最佳的优化策略，分别是基于DRL的电路重写器、特定领域的优化器和参数化的电路实例化器。同时，调度引擎可以学习到如何根据电路结构、硬件限制和后端性能特征来协调这些模块，从而生成一个针对特定硬件优化的量子电路。
### Conclusion
OrQstrator通过集成三种不同的优化模块，并利用DRL学习调度策略，实现了对量子电路的智能化优化，提高了量子电路在实际硬件上的执行效率和精度。该框架结合了现有先进方法（如NISQ Analyzer）的优势，更加适应不同的后端硬件约束，是NISQ时代量子电路优化的一项重要进步。
## 758. `cs.SE` - LLMShot：通过LLMs减少快照测试维护工作 [PDF](https://arxiv.org/pdf/2507.10062), [HTML](https://arxiv.org/abs/2507.10062)
### Authors
Ergün Batuhan Kaynak,Mayasah Lami,Sahand Moslemi,Anil Koyuncu
### Background
快照测试已经成为了现代软件开发中关键的UI验证技术，但频繁的UI变更导致测试失败需要人工检查来区分真实的回归和有意的设计变更，这一过程给开发人员带来了沉重的负担，尤其是在应用不断演进的情况下，自动化分析解决方案变得更加必要。
### Innovation
本文提出了LLMShot，这是一种利用视觉语言模型（VLMs）自动分析快照测试失败的新框架，通过语义分类来识别UI变化。我们还开发了一个全面的数据集，使用了一个功能丰富的iOS应用，并包含可配置的功能开关，以创建真实场景并产生真实的快照差异，符合实际开发工作流程。实验表明，12B版本的Gemma3模型识别失败根本原因的召回率超过84%，而4B模型在持续集成环境中具有可接受的性能，具备实际部署优势。然而，我们对选择性忽略机制的探索揭示了基于提示的当前方法在可控视觉推理方面存在显著限制。LLMShot是第一个自动化的语义快照测试分析方案，为开发人员提供了结构化的洞察，极大地减少了手动分类努力，并为更智能的UI测试模式铺平了道路。
### Conclusion
LLMShot代表了自动化的语义快照测试分析方向，能够显著减少手动分类工作量，并推动了更加智能的UI测试范式的发展。
## 759. `cs.SE` - FMI Meets SystemC：一种跨工具虚拟原型设计框架 [PDF](https://arxiv.org/pdf/2507.18339), [HTML](https://arxiv.org/abs/2507.18339)
### Authors
Nils Bosbach,Meik Schmidt,Lukas Jünger,Matthias Berthold,Rainer Leupers
### Background
随着系统变得越来越复杂，全面测试和虚拟原型的需求也在增长。为了模拟整个系统，通常需要使用多个工具来覆盖不同的部分，这些部分包括系统的硬件和与系统交互的环境。Functional Mock-up Interface (FMI) 标准为协作仿真提供了一种方法，而现代系统的控制部分通常是一个计算单元，如片上系统 (SoC) 或微控制器单元 (MCU)，该单元从连接的内存中执行软件并与外设进行交互。为在无需访问物理硬件的情况下开发软件，通常使用全系统模拟器（即虚拟平台）进行测试。尽管 IEEE 标准化了虚拟平台 (VP) 的开发框架 SystemC TLM，但 SystemC 缺乏原生的 FMI 支持，这限制了其与更广泛的协同仿真环境的集成。
### Innovation
本文提出了一种新型框架，使用FMI来控制和与基于SystemC的VP进行交互。通过这种方法，可以将未修改的目标软件运行在虚拟平台上，并从其他工具接收真实的环境输入数据，如温度、速度或加速度值。这种方法使得全面的软件测试和验证成为可能，并允许在物理硬件可用时提前完成诸如 ISO 26262 等认证。
### Conclusion
该研究展示了一种通过FMI将未修改的目标软件运行在基于SystemC的虚拟平台上，并从其他工具接收真实环境输入数据的方法。这使得全面的软件测试和验证成为可能，并允许提早完成ISO 26262等认证。
## 760. `cs.SE` - 使用符号推理的大语言模型进行自动化代码审查 [PDF](https://arxiv.org/pdf/2507.18476), [HTML](https://arxiv.org/abs/2507.18476)
### Authors
Busra Icoz,Goksel Biricik
### Background
代码审查是软件开发生命周期中的关键过程，对于保持代码质量至关重要。然而，手动代码审查主观且耗时。鉴于代码审查基于规则，因此非常适合自动化。近年来，人们已经借助人工智能努力实现代码审查的自动化。最新的大规模语言模型（LLMs）也被认为是这一领域的有希望的工具，但这些模型在逻辑推理能力上有所欠缺，不能完全理解和评估代码。为了克服这一限制，研究提出了一种结合符号推理技术和LLMs的混合方法，以实现代码审查的自动化。
### Innovation
研究提出了一种结合符号推理技术和LLMs的混合方法，旨在克服大规模语言模型在逻辑推理能力上的不足，提高代码审查的准确性和效率。研究人员通过使用CodexGlue数据集测试了这种方法，并对包括CodeT5、CodeBERT和GraphCodeBERT等多种模型进行了比较分析。
### Conclusion
研究结果表明，结合符号推理技术和LLMs的方法能够提高自动化代码审查的准确性和效率。
## 761. `cs.SE` - AI生成的修复是否安全？SWE-bench上的LLM和代理补丁分析 [PDF](https://arxiv.org/pdf/2507.02976), [HTML](https://arxiv.org/abs/2507.02976)
### Authors
Amirali Sajadi,Kostadin Damevski,Preetha Chatterjee
### Background
大型语言模型（LLMs）及其代理框架正越来越多地被用于自动化软件开发任务，如问题解决和程序修复。尽管先前的研究已经发现了LLM生成代码中的安全风险，但大多数评估集中在合成或隔离环境中，这使得人们对这些系统在真实世界开发环境中的安全性产生了疑问。研究者利用SWE-bench数据集中的20,000多个问题，进行了首次大规模的对LLM生成补丁的安全分析。评估了单个LLM（Llama 3.3）生成的补丁，并将其与开发人员编写的补丁进行了比较。同时，研究者还评估了三个表现最好的代理框架（OpenHands、AutoCodeRover、HoneyComb）生成的补丁，并分析了多种代码、问题和项目层面的因素，以理解LLM和代理最有可能生成不安全代码的条件。研究表明，单个LLM引入的新漏洞大约是开发人员的9倍，其中许多表现出与开发人员代码中独特的模式。代理工作流程还将生成大量漏洞，尤其是在赋予LLM更多自主权时，可能会增加误解项目上下文或任务要求的可能性。研究还发现，涉及更多文件、更多生成代码行以及缺乏具体代码示例或预期代码行为的GitHub问题更容易出现漏洞。这些结果表明，上下文因素在生成代码的安全性中起着关键作用，并指出需要针对代码和问题层面信息进行主动风险评估的方法来补充现有的漏洞检测工具。
### Innovation
研究首次大规模分析了LLM生成的补丁的安全性，并将其与开发人员编写的补丁进行了比较。评估了三个表现最好的代理框架生成的补丁，并识别了生成不安全代码的因素，提出了针对代码和问题层面信息的主动风险评估方法。
### Conclusion
LLM生成补丁引入的新漏洞约为开发人员的9倍，代理工作流程在赋予LLM更多自主权时容易生成更多漏洞。建议对代码和问题层面信息进行主动风险评估，以补充现有的漏洞检测工具。
## 762. `cs.SE` - MultiKernelBench：一种支持多平台的内核生成基准 [PDF](https://arxiv.org/pdf/2507.17773), [HTML](https://arxiv.org/abs/2507.17773)
### Authors
Zhongzhen Wen,Yinghui Zhang,Zhong Li,Zhongxin Liu,Linna Xie,Tian Zhang
### Background
深度学习（DL）内核的自动生成已经证明是减少手动工作和特定硬件专业知识所必需的高效率算子实现所需努力的一种有前途的方法。然而，现有用于评估大型语言模型（LLMs）的基准测试存在硬件支持有限、内核类别划分粗略以及任务覆盖面不平衡的问题。
### Innovation
我们推出了MultiKernelBench，这是第一个全面支持多平台的LLM基于DL内核生成基准测试。它包括285个任务，涵盖14个明确定义的内核类别，并支持Nvidia GPU、华为NPUs和Google TPUs三大硬件平台。为了增强未来的扩展性，我们设计了一个模块化后端抽象层，分离了平台特定的逻辑与核心基准测试基础设施，使得新的硬件平台能够轻松集成。此外，我们提出了一种简单且有效的类别感知一次性提示方法，通过提供同类别示例来提高生成质量。
### Conclusion
通过系统地评估七个最先进的LLMs，我们揭示了任务难度的显著变化、对较少训练暴露的平台表现不佳以及定向提示策略的有效性。MultiKernelBench已公开可用，该基准测试推广了对LLM在DL内核自动生成领域应用的理解。
## 763. `cs.SE` - 当检索器遇到生成器：用于代码注释生成的联合模型 [PDF](https://arxiv.org/pdf/2507.12558), [HTML](https://arxiv.org/abs/2507.12558)
### Authors
Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen
### Background
自动为源代码生成简洁且具有信息性的评论可以减轻文档工作的负担，并加速程序理解。现有方法首先是检索带有已有注释的代码片段，然后再合成新的注释。然而，检索和生成通常是在孤立的方面进行优化，这可能导致不相关的邻居传播噪声。针对这个问题，该文提出了一个名为RAGSum的新方法，目的是在推荐方面做到有效且高效。RAGSum基于使用单一CodeT5骨干进行融合检索和生成来构建。
### Innovation
该文提出了一个名为RAGSum的新方法，这是一个基于CodeT5的融合检索和生成的方法，旨在同时优化检索和生成任务。它包含一个对比预训练阶段来形成代码嵌入以进行最近邻搜索，以及一个端到端训练过程，其中包括了一个综合损失函数。RAGSum还部署了一个轻量级的自我精炼循环来优化最终输出。
### Conclusion
该框架在三种跨语言基准（Java，Python，C）上进行了评估，并与三个现有基准进行了比较。结果显示，该方法在BLEU，METEOR和ROUTE-L方面显著优于现有基准。这些发现表明，紧密耦合检索与生成可以提高评论自动化的上限，并激励后续的复制和开发人员的定性研究。
## 764. `cs.SE` - 一种先进的以AI驱动的数据库系统 [PDF](https://arxiv.org/pdf/2507.17778), [HTML](https://arxiv.org/abs/2507.17778)
### Authors
M. Tedeschi,S. Rizwan,C. Shringi,V. Devram Chandgir,S. Belich
### Background
当前的数据库系统尽管有效，但在复杂性和易用性方面存在严重问题，尤其是在那些缺乏技术专长但对查询语言如结构化查询语言（SQL）不熟悉的人士中。
### Innovation
本文提出了一种新的数据库系统，该系统以人工智能（AI）为基础，利用自然语言处理（NLP）的直观界面和自动创建结构化查询以及半结构化数据格式（如Yet Another Markup Language (YAML)、JavaScript Object Notation (JSON)和应用编程接口（API）文档），旨在通过大型语言模型（LLMs）和高级机器学习算法的集成，增强数据库的潜力，实现数据建模、模式创建、查询理解和性能优化等基本任务的自动化。
### Conclusion
本文介绍了一个旨在解决当前数据库技术主要问题的系统。该系统旨在降低对技术技能、手动调优以提高性能和人为错误的需求。AI数据库利用生成性模式推断和格式选择来构建其模式模型和执行格式。
## 765. `cs.SE` - 探索BPpy与深度强化学习和形式化方法的互动 [PDF](https://arxiv.org/pdf/2501.15480), [HTML](https://arxiv.org/abs/2501.15480)
### Authors
Tom Yaacov,Gera Weiss,Adiel Ashrov,Guy Katz,Jules Zisser
### Background
本文探讨了行为编程（BP）与一系列人工智能（AI）和形式化方法（FM）技术之间的互动。研究旨在证明BP可以作为一个高层次的抽象，整合各种技术，实现多层次的分析和丰富的开发流程。具体而言，文章研究了基于Python的BP实现BPpy如何通过增强以及被不同的FM和AI工具增强的方法。这些工具包括SMT求解器、符号和概率模型检查以及深度强化学习(DRL)，以使BP能够建模复杂系统的能力得到扩展。
### Innovation
本文创新地将BPpy框架与SMT求解器、符号和概率模型检查以及深度强化学习相结合，评估了这些工具在BP建模复杂系统中的集成效果，展示了如何在一个单一的建模和开发任务中利用多个工具。
### Conclusion
本文提供了定量和定性的证据，证明了将AI和FM方法整合到统一的开发框架中的可行性，并创建了一个全面的工具箱来利用这些方法。
## 766. `cs.SE` - 关于包含封闭句法类别词的标识符名称的结构和语义 [PDF](https://arxiv.org/pdf/2505.18444), [HTML](https://arxiv.org/abs/2505.18444)
### Authors
Christian D. Newman,Anthony Peruma,Eman Abdullah AlOmar,Mahie Crabbe,Syreen Banabilah,Reem S. AlSuhaibani,Michael J. Decker,Farhad Akhbardeh,Marcos Zampieri,Mohamed Wiem Mkaouer,Jonathan I. Maletic
### Background
标识符名称是代码的关键组成部分，对于开发者理解程序行为至关重要。本研究通过扩展语法模式的概念，研究标识符名称中的语言结构。传统的研究主要关注开放的句法类别，而对封闭的句法类别关注较少，尽管这些类别在自然语言中占有重要地位。
### Innovation
本研究构建了一个新的手动标注语料库——封闭句法类别标识符数据集（CCID），含有1275个标识符，来源于30个开源系统。研究使用诱发理论启发式的编码、统计和模式分析方法来探究封闭句法类别语法模式与程序行为之间的关系，揭示了开发者通过命名表达控制流、数据转换、时间推理和行为角色等概念的反复出现结构。
### Conclusion
这项研究为理解标识符名称中如何通过语言资源编码行为提供了实证基础，并为命名、程序理解和教育研究开辟了新的方向。
