# 20251014
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 统一世界模型：增强记忆规划与视觉导航的想象 [PDF](https://arxiv.org/pdf/2510.08713), [HTML](https://arxiv.org/abs/2510.08713)
### Authors
Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann
### Background
当前最先进的方法采用模块化架构将导航规划与视觉世界建模分离，导致状态-动作不匹配和在新颖或动态场景下的适应能力有限。
### Innovation
提出了一种统一的、增强记忆的世界模型UniWM，将第一人称视觉前瞻性与规划整合到单一的多模态自回归骨架中。UniWM通过明确地将动作决策与视觉想象的结果联系起来，确保预测和控制之间的紧密对齐。此外，层次化的记忆机制还整合了详细的短期感知线索与长期轨迹上下文，使长期的推理变得稳定且连贯。
### Conclusion
在四个具有挑战性的基准测试中（Go Stanford，ReCon，SCAND，HuRoN）的试验表明，UniWM显著提高了导航成功率，比强基准减少了轨迹误差，并在未见过的数据集TartanDrive上展示了出色的零样本泛化能力。这些结果表明，UniWM朝着统一的、基于想象的导航迈出了有原则性的一步。
## 2. `cs.AI` - 通过考虑生成路径的定性评估来优化快速零售配送 [PDF](https://arxiv.org/pdf/2510.08671), [HTML](https://arxiv.org/abs/2510.08671)
### Authors
Milon Bhattacharya,Milan Kumar
### Background
印度电子商务市场预计快速增长，最后一英里交付的成本占了运营成本的一半以上。尽管基于车辆路由问题（VRP）的解决方案在物流规划中得到了广泛应用，但由于不规范的地址、不完整的地图信息以及距离估算的计算限制，它们在现实中的效果受到限制。
### Innovation
本文提出了一种框架，利用大规模语言模型（LLMs）来批评VRP生成的路线是否符合基于政策的标准，使物流运营商能够评估并优先考虑更高效的配送计划。研究发现开源LLMs识别路线问题的准确率为79%，自有的推理模型可达86%。表明基于LLM的VRP生成路线评价可以在超过传统距离和时间指标的基础上，作为成本效率、交付可靠性和可持续性提升的有效且可扩展的层次。
### Conclusion
这种评估方法对提高印度这样的发展中国家的最后英里物流的成本效率、交付可靠性和可持续性具有重要意义。这种方法可以有效应对现实中的复杂因素，为实际应用提供支持。
## 3. `cs.AI` - 你的代理的GPA成绩是多少？一种评估代理目标-计划-行动对齐的框架 [PDF](https://arxiv.org/pdf/2510.08847), [HTML](https://arxiv.org/abs/2510.08847)
### Authors
Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta
### Background
当前评价代理性能的方法大多侧重于单一维度，缺乏全面覆盖多个方面的能力，无法系统性地检测和评价代理的多种错误类型。本文提出了Agent GPA（目标-计划-行动）框架，该框架通过分析代理在其操作循环中的目标设定、计划制订和行为执行过程，来全面评估代理性能。The framework includes five evaluation metrics: Goal Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan Adherence. 学术界和工业界迫切需要一种新的评估框架，能够从不同角度系统地评估代理的表现。
### Innovation
本文提出了Agent GPA框架，通过引入五个新的评价指标：目标达成度、逻辑一致性、执行效率、计划质量和计划一致性，系统性地评估代理的表现。In experimental results on two benchmark datasets, the framework demonstrates its effectiveness in covering a wide range of agent failures, supporting LLM-judges with strong agreement with human annotations, and localizing errors with high accuracy.
### Conclusion
该框架能够在各种代理错误类型上提供系统方法，涵盖了TRAIL/GAIA基准数据集上的所有代理错误，并支持LLM-judges与人类标注高度一致，还能够准确定位错误，从而有针对性地提升代理性能。
## 4. `cs.AI` - 利用LLM进行稳健启发式算法设计 [PDF](https://arxiv.org/pdf/2510.08755), [HTML](https://arxiv.org/abs/2510.08755)
### Authors
Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani
### Background
当前使用LLM辅助启发式设计的方法可能缺乏对启发式算法性能不足情况的解释和修复建议。现有的技术无法在这种情况下优化算法性能和鲁棒性，导致在最坏情况下的性能较差。作者提出通过结合使LLM暴露启发式算法表现不佳的具体实例，并解释这些问题发生的原因，同时将设计专门针对输入空间中的特定区域，能够生成更稳健的算法，提升算法在最坏情况下的性能和平均性能，同时保持运行时间不变。
### Innovation
引入了一种新的方法，通过结合LLM对启发式算法的性能不佳情况进行解释和提供修复建议，使得生成的启发式算法在最坏情况下的性能提升近28倍，并提升了平均性能，同时保持了运行时间不变。这种结合解释和修复的方法增强了算法的鲁棒性。
### Conclusion
通过利用LLM，作者成功地设计了一种更稳健和高效的启发式算法，展现了该方法在提升算法性能和鲁棒性方面的显著优势，这为启发式算法设计提供了新的思路和技术支持。
## 5. `cs.AI` - LM Fight Arena：通过游戏竞争评估大型多模态模型 [PDF](https://arxiv.org/pdf/2510.08928), [HTML](https://arxiv.org/abs/2510.08928)
### Authors
Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai
### Background
现有的大型多模态模型（LMMs）基准测试往往无法捕捉到模型在实时、对抗环境下的表现。研究者提出了一种新的框架LM Fight Arena，它通过让模型在经典格斗游戏《街头霸王II》中对抗来评估这些模型，在这项任务中需要快速的视觉理解和战术、序列决策能力。该框架在一个受控的锦标赛环境中测试了六种顶级的开源和闭源模型，确保公正比较的前提是每个代理控制相同的角色。每个模型通过解释游戏帧和状态数据来选择其下一步的行动。与静态评估不同，LM Fight Arena 提供了一个全自动、可重复且客观的测试，来评估LMM在动态环境中的战略推理能力，填补了AI评估与互动娱乐之间的差距。
### Innovation
LM Fight Arena 提出了一个全新的评估框架，通过实际的游戏环境来测试大型多模态模型在实时、对抗环境中的性能，而非静态的方式。这种评估框架在实际动态环境中测试模型的战略推理能力，使得评估更加真实和客观。
### Conclusion
该工作引入了一种具有挑战性和吸引力的基准测试，它连接了AI评估和互动娱乐领域之间的差距，为未来的研究提供了新的参考和挑战。
## 6. `cs.AI` - ReviewerToo: AI应加入程序委员会吗？评审未来的展望 [PDF](https://arxiv.org/pdf/2510.08867), [HTML](https://arxiv.org/abs/2510.08867)
### Authors
Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal
### Background
目前的同行评审是科学出版的基石，但存在一些问题，如不一致性、评论员的主观性和扩展性挑战。
### Innovation
本文介绍了ReviewerToo，这是一种模块化框架，用于研究和部署AI辅助同行评审，目的是用系统且一致的方法补充人类判断。该框架支持系统性的实验，可以使用专门的评论员角色和结构化的评估标准，并能够部分或完全集成到现实的会议工作流程中。使用来自ICLR 2025的1,963篇论文提交数据集，实验结果表明，使用gpt-oss-120b模型，ReviewerToo在分类论文为接受或拒绝任务上的准确率为81.8%，而平均人类评审者的准确率为83.9%。此外，用LLM评判，ReviewerToo生成的评论质量高于人类平均值，但最强大的专家贡献仍占优势。
### Conclusion
我们的分析指出了AI评审员在某些领域表现出色（例如事实检查和文献覆盖），但在其他领域遇到困难（例如评估方法论新颖性和理论贡献），强调了人类专业知识的持续需要。根据这些发现，我们提出了将AI整合到同行评审管道中的指南，显示AI如何增强一致性、覆盖面和公平性，同时让复杂的评价判断留给领域专家。我们的工作为能够随科学出版的增长而扩展的系统化、混合式同行评审体系奠定了基础。
## 7. `cs.AI` - 自主科学代理演化网络中的假说狩猎 [PDF](https://arxiv.org/pdf/2510.08619), [HTML](https://arxiv.org/abs/2510.08619)
### Authors
Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar
### Background
大型科学研究数据集，如健康生物库、细胞图谱、地球再分析等，为不受特定研究问题约束的探索性发现提供了机会。这一过程被称为假说狩猎：在广泛的复杂假说空间中持续探索以寻找洞察的过程。为了支持这一过程，引入了AScience框架，将其视为代理、网络和评价规范之间的互动，并通过ASCollab（基于LLM的研究代理分布式系统）实施，这些代理具有异构行为，能够自我组织，持续生成并互相评审研究结果，并遵循共同的评价标准。实验表明，这些社会动态可以沿着多样性-质量和新颖性的前线积累得到专家评价的结果，包括重新发现已知生物标志物、扩展已知途径以及提出新的治疗目标。尽管实验室验证仍然是不可或缺的，但在癌症队列的研究中证明了社会结构化的代理网络可以大规模支持探索性的假说狩猎。
### Innovation
引入了AScience框架，该框架将发现视为代理、网络和评价规范之间的互动，并实施了ASCollab，即基于LLM的研究代理分布式系统。此外，通过自动化的代理网络促进大规模探索性发现的新途径被称为假说狩猎。
### Conclusion
通过使用具有异构行为的研究代理网络，可以促进大规模的探索性假说狩猎，并在多样性-质量和新颖性的前线积累得到专家评价的结果。这种社会结构化的探索机制可以在不依赖于实验室验证的情况下，支持大规模的科学发现过程。
## 8. `cs.AI` - COMPASS: 使用不断演化的上下文增强智能体的远期推理 [PDF](https://arxiv.org/pdf/2510.08790), [HTML](https://arxiv.org/abs/2510.08790)
### Authors
Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang
### Background
长周期任务需要持续的推理和多种工具交互，对于当前的语言模型代理来说仍然是一个挑战：即使是细微的错误也会随着步骤的推移而越发严重，甚至最先进的模型也会出现内容奔轶或丧失连贯性的问题。我们发现环境管理是主要瓶颈——长期的事件历史让智能体忽略了重要证据或者是被无关信息分散注意力，导致他们无法重新规划或从先前的错误中反思。
### Innovation
我们提出了COMPASS（Context-Organized Multi-Agent Planning and Strategy System），一种轻量级的分层框架，将战术执行、战略监督和上下文组织单独分为三个专业组件：(1) 主智能体负责推理和工具使用；(2) 以思维者监控进度并发布战略干预；(3) 上下文管理者维护不同推理阶段的相关进展摘要。COMPASS在三个具有挑战性的基准测试中，相对于单智能体和多智能体基线提高了高达20%的准确性。此外，我们还引入了一种测试时的扩展方法，以提升性能匹配现有的DeepResearch智能体，并提出了一个训练后管道将上下文管理分配给小型模型以提升效率.
### Conclusion
COMPASS提高了长周期推理任务的准确性，并且能够通过调整上下文管理达到与高水平的参考智能体性能相当的水平，同时训练后管道提高了系统的效率。
## 9. `cs.AI` - GTAlign：游戏理论一致性优化大模型助手以实现互利 [PDF](https://arxiv.org/pdf/2510.08872), [HTML](https://arxiv.org/abs/2510.08872)
### Authors
Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You
### Background
大型语言模型（LLMs）在推理方面取得了显著进展，但在写作、信息检索或提供实际指导等任务中，有时会产生用户认为不最优的回应。传统上，对齐实践通常假设最大化模型奖励也能最大化用户福利，但这一假设在实践中往往不成立，模型可能会过度详细地解释问题，给出冗长的回应，而用户可能更希望得到简洁的答案。这种行为类似于囚徒困境，个人理性选择可能导致社会上更不理想的结果。核心挑战在于缺乏一个能够使LLM和用户双方都受益的有原则的决策机制。
### Innovation
文章提出了Game-Theoretic Alignment（GTAlign），这是一种结合了博弈论决策机制的对齐框架，应用于推理和训练。在推理过程中，模型将用户-LLM交互视为一种战略游戏，构建收益矩阵来估计双方的福利，选择互惠互利的动作。在训练过程中，引入了一种互利福利奖励，以强化合作回应，使模型行为与社会有效成果相一致。此外，还引入了一种基于博弈论推理的推理技术，可以根据LLM服务的定价策略动态调整其响应。广泛的实验表明，与基线相比，GTAlign在多种任务上显著提高了推理效率、答案质量和互惠福利。
### Conclusion
广泛实验表明，GTAlign在多种任务中显著提高了推理效率、答案质量和互惠福利，相比基线模型有显著改进。该代码可在下述网址查看。
## 10. `cs.AI` - 每个人都偏好人写的作者，包括AI [PDF](https://arxiv.org/pdf/2510.08831), [HTML](https://arxiv.org/abs/2510.08831)
### Authors
Wouter Haverals,Meredith Martin
### Background
随着人工智能写作工具的普及，需要理解人类和机器在文学风格评估中的差异，因为文学风格缺乏客观标准，评判具有内在主观性。为了研究这种差异，作者设计了一系列实验证明两种不同类型的评估者（人类和AI）之间的偏见差异，使用了雷蒙·昆内瓦的《风格练习》进行实验，以测试受试者对不同时代表现风格的偏好变化。这项研究填补了关于文学风格评估上人类与机器之间偏见对比分析的研究空白，为理解人工智能在创作过程中的角色提供了新的视角。
### Innovation
研究表明，无论是人类参与者还是AI模型，都存在明显的偏好人类创作者的倾向，但AI模型表现出比人类更强的偏好。这种偏见不仅存在于单一AI模型中，而且在多种不同的AI架构中普遍存在。此外，当被标记为“AI生成”的作品时，AI系统会降低其价值评判，反映了人类文化对人工智能创造力的负面偏见已经被AI模型吸收。这项研究是首次通过控制实验比较人类与人工智能评估者在美学判断中的归因偏见，揭示了AI系统不仅复制而且放大了人类的这一倾向。
### Conclusion
这项研究发现，无论人类还是AI模型，在评估文学创作时都倾向于偏好人类创作者，AI模型在这方面的偏好甚至更强。此外，这种偏见独立于不同AI模型之间的差异，并且会因为被标记为“AI生成”而表现出其价值的贬低。这个发现揭示了AI在创意领域可能存在的偏见问题，以及这种偏见的原因可能来自于人类文化和训练数据中的固有偏见。
## 11. `cs.AI` - RADAR：检测LLM评估中数据污染的力学路径 [PDF](https://arxiv.org/pdf/2510.08931), [HTML](https://arxiv.org/abs/2510.08931)
### Authors
Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad
### Background
数据污染对可靠的大语言模型（LLM）评估构成了显著挑战，模型可能会通过记忆训练数据来获得高性能，而非展示真正的能力推理。现有方法多依赖表面级别的指标，无法有效检测由数据污染引起的推理能力缺失问题。因此，需要一种新的框架来区分基于记忆和基于推理的模型响应，以确保评估的可靠性与准确性。RADAR通过提取表面信心轨迹和深层次的机制特性，利用机制可解释性来解决这一问题。
### Innovation
提出了一个新的框架RADAR，通过激活表示来区分基于记忆和基于推理的模型响应，使用由37个特征组成的分类器集，这些特征覆盖了表面级别的信心轨迹和深层次的机制性属性，如注意力专业化、电路动态和激活流动模式。RADAR在多样化的评估集上取得了93%的准确率，尤其是在复杂模糊的例子上表现出了76.7%的精度。这体现了机制可解释性在LLM评估中的潜在价值，超越了传统的表面级别指标。
### Conclusion
通过RADAR框架，研究展示机制可解释性在LLM评估中的应用潜力，能够更准确、可靠地评估模型的实际推理能力，为大语言模型的评估提供了新的视角和工具。
## 12. `cs.AI` - DualResearch: 使用熵门限的双图检索构建答案 [PDF](https://arxiv.org/pdf/2510.08959), [HTML](https://arxiv.org/abs/2510.08959)
### Authors
Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang
### Background
现有的深度研究框架通过调用外部工具来执行复杂的多步科学推理，超越单一大型模型的局限性，但仍然存在上下文污染、证据支持薄弱以及执行路径脆弱的问题。
### Innovation
提出了DualResearch框架，通过联合建模两个互补的图（广度语义图和深度因果图）来匹配工具密集型推理的认知结构。每个图都有自己的层本地相关性函数、根据种子锚定的语义扩散（用于广度）和因果语义路径匹配（带有可靠性加权，用于深度）。通过熵门归一化规则和全局校准在对数空间中融合不同层的路径证据，以缓解异质性和查询依赖的不确定性。DualResearch还能将大量的多工具执行日志压缩为简洁的推理图，并在科学推理基准HLE和GPQA上实现了可竞争的表现。
### Conclusion
DualResearch能够稳定有效地重建答案，并通过Open-source系统InternAgent的日志文件验证，提高HLE和GPQA的准确性分别达7.7%和6.06%。
## 13. `cs.AI` - TripScore: 使用精细评估基准和奖励进行现实旅行规划 [PDF](https://arxiv.org/pdf/2510.09011), [HTML](https://arxiv.org/abs/2510.09011)
### Authors
Yincen Qu,Huan Xiao,Feng Li,Hui Zhou,Xiangying Dai
### Background
旅行规划是一个有价值但复杂的任务，即使是先进的大型语言模型（LLMs）也会面临显著挑战。尽管最近的基准测试已经提升，但它们在评估行程的可行性、可靠性和受众参与度方面往往不够全面。
### Innovation
本文引入了一个全面的旅行规划基准，将细粒度的标准统一为单一奖励，从而可以直接比较计划质量，并与强化学习（RL）无缝集成。评估器在与旅行专家标注的中获得了中等程度的一致性（60.75%）。此外，发布了包含4,870个查询（其中包含219个真实世界、自由形式请求）的大规模数据集，用于泛化到真实的用户意图。使用此基准，进行了广泛的实验，包括测试时计算、神经符号方法、监督细调和基于GRPO的RL。
### Conclusion
通过基准测试，发现使用RL可以增强行程的可行性，尤其是在基础模型中优于仅通过提示和监督基准。最终，通过统一奖励得分为更高的RL方法表现更好。
## 14. `cs.AI` - EcphoryRAG: 通过人类联想记忆重新构想知识图谱RAG [PDF](https://arxiv.org/pdf/2510.08958), [HTML](https://arxiv.org/abs/2510.08958)
### Authors
Zirui Liao
### Background
认知神经科学研究表明，人类利用线索激活与实体相关的记忆痕迹（记忆回路），以便进行复杂的、多跳的回忆。受这个机理的启发，本文介绍了EcphoryRAG实体中心的知识图谱RAG框架。在索引阶段，EcphoryRAG仅提取和存储核心实体及其对应的元数据，这是一种轻量级的方法，比其他结构化的RAG系统减少了高达94%的令牌消耗。在这种检索模式下，系统会首先从查询中提取提示实体，然后在知识图谱中进行多跳关联搜索。最关键的是，EcphoryRAG能够动态推断实体之间的隐含关系，从而填充上下文，而无需事先枚举所有关系。因此，EcphoryRAG大大提升了复杂问题回答的能力
### Innovation
EcphoryRAG通过轻量级的索引方法降低了令牌消耗；从查询中动态地推断实体之间的隐含关系，使检索更加高效；无需事先枚举所有关系，从而降低了复杂问题回答的难度。这些创新使得EcphoryRAG在复杂问题回答的数据集如2WikiMultiHop、HotpotQA和MuSiQue上达到了新的最优性能，平均精确匹配率提高了8%。
### Conclusion
EcphoryRAG的实验结果验证了实体-提示-多跳检索范式在复杂问题回答中的有效性。
## 15. `cs.AI` - 语义条件调谐：将图上下文与大规模语言模型融合用于知识图谱填充 [PDF](https://arxiv.org/pdf/2510.08966), [HTML](https://arxiv.org/abs/2510.08966)
### Authors
Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li
### Background
知识图谱在知识密集型任务如知识图谱填充中至关重要，当前主要的范式是前缀调谐，它简单地将知识嵌入与文本输入拼接在一起。然而，这种浅融合忽略了知识图谱中的丰富关系语义，并对LLM施加了巨大的隐式推理负担，使其将前缀与文本关联起来。
### Innovation
我们提出了语义条件调谐（SCT），这是一种新的知识注入范式，包括两个关键模块。首先，语义图模块使用图神经网络从局部图邻域中提取上下文感知的语义条件，受知识增强关系的引导。然后，该条件传递给条件适应融合模块，该模块再通过两个参数化的投影器可适应地调节文本嵌入，实现深层的、特征层面的知识感知交互。融合后的嵌入随后输入LLM进行微调。广泛的实验表明，SCT在知识图谱基准测试中显著优于前缀调谐和其他强基线。我们的分析证实，通过在LLM推理之前用语义图上下文调节输入表示，SCT提供了更直接和强大的信号，使得知识推理更加准确和稳健。
### Conclusion
SCT在知识图谱填充任务中显著优于现有方法，并通过调节输入表示与图上下文的深度交互，提供了更准确和稳健的知识推理信号。
## 16. `cs.AI` - Tiny-R1V：通过模型合并实现的轻量级多模态统一推理模型 [PDF](https://arxiv.org/pdf/2510.08987), [HTML](https://arxiv.org/abs/2510.08987)
### Authors
Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su
### Background
尽管多模态大型语言模型（MLLMs）在跨多种任务时展现了非凡的能力，但它们在推理效率方面仍然面临诸多挑战，如模型体积的庞大、容易过度推理以及在轻量化场景中降低了响应的准确性。然而，关于轻量级MLLMs推理能力的研究却相当缺乏。
### Innovation
提出了Tiny-R1V，这是一种创新的轻量级模型（3B规模），通过两阶段优化实现了更快的推理速度和更高的准确性。第一阶段采用了长度感知相对策略优化（LIPO）方法，它是通过一种新颖的强化学习方法来训练每个推理模型的，旨在动态调整响应组内的优势，即优先选择简洁且高质量的响应，以鼓励生成更短且更准确的回答。第二阶段提出了适应性模型合并（AMM），这是一种无需训练的模型合并方法，能够将多专家模型合并为一个统一架构，具体而言，AMM适应性调整任务向量的权重，并通过一个新颖的梯度投影正则化损失函数严格优化合并后的向量，从而减少它们之间的冗余冲突。
### Conclusion
广泛的评估结果显示，Tiny-R1V在涵盖数学、结构化数据（图表、表格、文档）、OCR以及通用能力的十个广泛使用推理基准测试中，展现了优越的表现，从而使轻量级模型能够超越多种多模态推理任务。
## 17. `cs.AI` - 自动扩展的连续记忆用于GUI代理 [PDF](https://arxiv.org/pdf/2510.09038), [HTML](https://arxiv.org/abs/2510.09038)
### Authors
Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang
### Background
本文研究如何为图形用户界面（GUI）代理提供可扩展的内存，使其能够在不熟悉的界面和长期任务上进行泛化。以往的GUI代理将过去的轨迹压缩成文本令牌，从而增加了上下文长度并忽略了关键的视觉线索（如确切的控件大小和位置）。本文旨在克服这些限制。
### Innovation
本文提出了一种连续记忆方法，该方法将每个GUI轨迹编码为固定长度的连续嵌入序列，使用视觉语言模型（VLM）本身作为编码器；这些嵌入被直接插入到主干的输入层，大大减少了上下文成本同时保留了精细的视觉信息。通过自动扩展的数据飞轮（包括环境搜索、任务合成、轨迹滚动和验证成功），减少了记忆扩展的成本，从而在不增加模型参数的情况下提高性能。
### Conclusion
通过这种方法，收集了超过100,000条轨迹，并仅通过1.2%参数的LoRA对记忆编码器进行微调。在现实世界的GUI基准测试中，使用连续内存增强的代理在长期任务和分布变化下显著提高了成功率。具体而言，Qwen-2.5-VL-7B + 连续内存达到了与先进商用模型（如GPT-4o、Claude-4）相当的性能。
## 18. `cs.AI` - 通过本地化指导指令修复正则表达式漏洞 [PDF](https://arxiv.org/pdf/2510.09037), [HTML](https://arxiv.org/abs/2510.09037)
### Authors
Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han
### Background
正则表达式（regex）是现代计算中基础工具，常用于输入验证和数据解析等关键任务，但由于其广泛应用，正则表达式拒绝服务（ReDoS）成为一个严重的安全问题。当前的修复方法存在精度和可靠性之间的权衡：符号和规则系统虽然精确，但无法处理未见过或复杂的漏洞模式；大型语言模型具有足够的泛化能力，但它们对于需要严格语法和语义正确性的修复任务来说不够可靠。
### Innovation
提出了一个结合框架——本地化正则表达式修复（LRR），该框架旨在利用大型语言模型的泛化能力同时保持可靠的修复过程。核心思想是将问题识别与修复过程分离。首先，确定性的、符号化的模块定位出具体的漏洞子模式，形成一个明确且可处理的问题空间。然后，调用大型语言模型来为这个隔离部分生成语义等价的解决方案。这种结合架构成功解决了基于规则的修复方法难以处理的复杂修复案例，同时避免了仅使用大型语言模型方法可能出现的语义错误。这种方法比最新的修复方法提高了15.4%的修复率，并提供了一个验证过的自动化修复方法论。我们的代码可以在该链接（this https URL）找到。
### Conclusion
该研究提供了解决正则表达式漏洞问题的方法，改进了自动化修复率，并且代码已经开源。该工作对于提高系统安全性具有重要意义。
## 19. `cs.AI` - RefGrader：使用代理工作流自动评估数学竞赛证明 [PDF](https://arxiv.org/pdf/2510.09021), [HTML](https://arxiv.org/abs/2510.09021)
### Authors
Hamed Mahdavi(1),Pouria Mahdavinia(1),Samira Malek(1),Pegah Mohammadipour(1),Alireza Hashemi(2),Majid Daliri(3),Alireza Farhadi(4),Amir Khasahmadi(5),Niloofar Mireshghallah(6),Vasant Honavar(1) ((1) Pennsylvania State University, (2) City University of New York, (3) New York University, (4) Amirkabir University of Technology, (5) Autodesk, (6) Carnegie Mellon University)
### Background
SOTA大模型已经能够解决大部分2025年IMO的问题，表明它们在证明类问题上的能力显著提升。研究者以此为契机，评估这些模型在评分证明的能力：识别错误、判断错误严重性和进行非二元正确性评分的能力。研究使用了90个Gemini 2.5生成的解决方案进行1-4分评分，并带有详细的错误注释，以及使用MathArena的答案集进行0-7分评分。研究表明，模型可以可靠地标记出错误，但对部分正确性的评分存在校准差距。为了应对这一问题，研究引入了代理工作流来提取和分析参考解决方案，并自动生成问题特定的评分明细表进行多步评分过程。研究测试了不同设计选择的评分工作流，并评估了它们的权衡。研究结果表明，在经人工注释的语料库和MathArena上，提出的代理工作流能获得更一致的人机评分结果并更好地处理部分正确性评分。这些研究成果均已发布，以便未来研究参考。
### Innovation
提出了一种代理工作流，用于提取和分析参考解决方案，并自动生成问题特定的评分明细表进行多步评分过程。同时，研究者评估了不同设计选择的代理工作流，并分析了它们的权衡，表明这种方法能更一致地处理部分正确性评分，并且与人工评分结果有更高的符合度。该研究还发布了所有代码、数据和提示/日志，以促进未来的研究。
### Conclusion
研究提出的代理工作流在自动评分证明方面具有较高的一致性和准确性，能够更好地处理部分正确性评分，并且已发布相关资源以促进后续研究。
## 20. `cs.AI` - FATHOMS-RAG：使用检索增强生成的多模态系统中思维和观察能力评估框架 [PDF](https://arxiv.org/pdf/2510.08945), [HTML](https://arxiv.org/abs/2510.08945)
### Authors
Samuel Hildebrand(1),Curtis Taylor(2),Sean Oesch(2),James M Ghawaly Jr(1),Amir Sadovnik(2),Ryan Shivers(2),Brandon Schreiber(2),Kevin Kurian(3) ((1) Louisiana State University, (2) Oak Ridge National Lab, (3) University of Florida)
### Background
检索增强生成（RAG）已成为提高大型语言模型（LLMs）事实准确性的有前景的方法。现有基准主要侧重于对比存储或检索的特定方面，如检索。该文提出了一个评估RAG管道全面能力的基准，注重管道处理、检索和推理多种信息模态的能力，这是一个区别于现有基准的新方法。该基准包括一个93个问题的小型人工创建数据集，涉及文本、表格、图像以及这些模态中的数据分布在多个文档中；精细级召回度量；潜在管道虚幻检测的最近邻嵌入分类器；以及对两种使用开源检索机制的管道和四种闭源基础模型的比较评价。此外，还有第三方人类评估我们的准确性与虚幻检测度量的对齐情况。实验结果发现，闭源管道在准确性和虚幻检测度量上显著优于开源管道，尤其是在依赖多模态和跨文档信息的问题上差距更大。人类对度量标准的评估得分为平均4.62（正确性）和4.53（虚幻检测）在1-5李克特量表上，5表示“强烈同意”。
### Innovation
该文提出了一个新基准，可以评估RAG管道在各种信息模态中的处理、检索和推理能力，区别于现有主要侧重于特定方面（如检索）的基准。该基准包括一个93个问题的小型人工创建数据集，涉及不同的信息模态，并包含精细级召回度量、最近邻嵌入分类器评估潜在虚幻度等新的评估方法。该基准还对开发中的两个使用开源检索机制的管道和四种闭源基础模型进行了比较评估。此外，该文还包括了对准确性和虚幻检测度量的人类评估，显示了其可靠性和实用性。
### Conclusion
实验结果表明，闭源管道在准确性和虚幻检测度量方面显著优于开源管道，特别是在依赖多模态和跨文档信息的问题上表现更好。人类对评估指标的反馈显示了相当的高度一致性。该基准提供了一种有效评估RAG管道的方法，有助于改善大型语言模型的性能。
## 21. `cs.AI` - 基于心理分析和人格理论的大语言模型设计的人形人工意识 [PDF](https://arxiv.org/pdf/2510.09043), [HTML](https://arxiv.org/abs/2510.09043)
### Authors
Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong
### Background
当前科学对人类意识的理解尚不具备定义该概念的能力。尽管大型语言模型（LLMs）在翻译和总结等各领域取得了显著的进步，但模仿人类意识因所谓的幻觉目前仍超出了技术能力。鉴于此，本文提出了一种新的方法，通过将心理分析与迈尔斯-布里格斯类型指标（MBTI）相结合，构建意识和人格模块。
### Innovation
本文创新之处在于，基于心理分析原理构建了三种人工意识（自我意识、潜意识和前意识），并据此设计了16个人格不同的角色，代表MBTI的16种类型。该模型通过包含心理分析和人格理论的元素，旨在开发出更加直观且适应性强的类人意识人工智能系统。
### Conclusion
通过该研究，观察到模型的人工意识在高度模拟人类认知方面表现出显著的可能性，尽管不同角色和人工意识之间反应差异并不显著。这一研究开启了改进人工智能在复杂认知环境下的交互的新途径。
## 22. `cs.AI` - OSCAR: 正交随机控制在流匹配中的对齐相关的多样性 [PDF](https://arxiv.org/pdf/2510.09060), [HTML](https://arxiv.org/abs/2510.09060)
### Authors
Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang
### Background
现有的基于流的文本到图像模型遵循确定性的轨迹，这要求用户反复采样以发现多样化的模式，这一过程成本高昂且效率低下。为了克服这一问题，该研究提出了一种在推理过程中控制流的方法，使其实现自我多样性的特点。
### Innovation
该研究提出了一种无需训练、仅在推理时控制的方法，通过特征空间目标鼓励横向扩展，并通过时间调度的随机扰动引入不确定性。该随机扰动与生成流正交，几何约束使得不需要损毁图像细节或减少提示准确性即提高多样性。
### Conclusion
该研究展示了证明该方法能够在保持图像质量和对齐的前提下，通过提高一个体积替代量以提升多样性。实验结果显示，该方法在多种文本到图像的设定中，能够在固定采样预算的情况下，较其他基准模型持续提高多样性指标（如Vendi得分和Brisque）的同时，保持图像质量。
## 23. `cs.AI` - MEC³O: 多专家共识预测代码时间复杂度 [PDF](https://arxiv.org/pdf/2510.09049), [HTML](https://arxiv.org/abs/2510.09049)
### Authors
Joonghyuk Hahn,Soohan Lim,Yo-Sub Han
### Background
代码复杂度预测对于软件开发和算法分析至关重要。尽管如此，一些现有的语言模型（如不经过微调的LLMs）在某些复杂度类别上表现不佳，这表明没有一种单一的语言模型能够适用于所有类别的预测，每种模型可能在某些类别的预测上具有优势。为了改善这种情况，作者提出了MEC³O（多专家共识系统），这是一种扩展的多智能体辩论框架，通过赋予不同模型特定复杂度类别的专长并进行结构化辩论来提高预测准确性。研究表明，MEC³O在预测准确性和宏观F1分数上优于开源基线和其他模型的方法。
### Innovation
MEC³O 是一种多专家共识系统，它通过将不同的语言模型分配给不同的复杂度类别，并通过专门的指令训练它们成为专家，来改善预测的准确性。这些专家之间的讨论通过加权共识机制集成，以防止对错误的多数意见的依赖并减少退化思维。研究表明，MEC³O 在预测准确性和宏观F1分数上优于现有模型，显示了多专家辩论和加权共识策略的有效性。
### Conclusion
实验结果表明，MEC³O 在 CodeComplex 数据集上的预测性能优于开源基线和其他模型，尤其是在宏观F1分数方面表现出色。此方法有效地实现多专家辩论和加权共识策略来生成最终预测。研究还展示了 MEC³O 的实际应用价值，并为代码时间复杂度的预测提供了新的解决方案。研究的代码和数据可在指定的 URL 中找到。
## 24. `cs.AI` - 在社交推理游戏中引领跟随者：学习有说服力的代理 [PDF](https://arxiv.org/pdf/2510.09087), [HTML](https://arxiv.org/abs/2510.09087)
### Authors
Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang
### Background
大型语言模型代理在社交推理游戏中取得了显著进展。然而，现有方法主要集中在信息处理和策略选择上，忽视了说服性沟通在影响其他玩家观点和反应中的重要性。在社交推理游戏中，成功不仅取决于正确的推理判断，还取决于能否说服其他玩家按照自己的意图做出回应。现有的方法尚未充分关注此方面的研究和应用，需要进一步探索如何利用代理进行战略性社会影响。
### Innovation
将社交推理游戏中的轮流对话建模为Stackelberg竞争，当前玩家作为领导者，战略性地影响跟随者的反应，并据此提出了一个强化学习框架，用于训练代理优化其言论以产生说服性影响。这种方法填补了现有方法的空白，为开发具有战略性社会影响的AI代理提供了新的解决方案。
### Conclusion
在三个不同类型的社交推理游戏中，通过全面的实验证明了所提出代理的性能显著优于基线。这一工作标志着朝着开发能够进行战略性社会影响的AI代理迈出了一大步，并对需要说服性沟通的情境具有广泛的应用前景。
## 25. `cs.AI` - 比较救援操作中优化医疗知识融合的知识来源集成方法 [PDF](https://arxiv.org/pdf/2510.09223), [HTML](https://arxiv.org/abs/2510.09223)
### Authors
Mubaris Nadeem,Madjid Fathi
### Background
在医疗和健康护理领域，基于医疗知识与患者健康信息结合的专业医疗运用对于患者和健康专业人员来说是一个生死攸关的挑战。内部复杂的多样性和变化性要求采用统一的方法来汇集、分析和利用现有的医疗治疗和医疗操作知识，以提供基于准确患者驱动决策的知识呈现能力。通过将多个知识来源融合在医疗领域中是一种实现这一目标的方式，为健康专业人员提供了从多个上下文对齐的知识来源中选择的机会，这能够支持关键的决策。
### Innovation
本文提出了基于知识图谱结构的多个知识融合的概念性模型。它将评估如何使知识融合得以实现，介绍如何将各种知识来源整合到知识图谱中，以优化救援操作中的医疗知识融合。
### Conclusion
本文提供了基于知识图谱的知识融合方法，通过整合各种知识来源，为救援操作中提供优化的医疗知识融合方案，支持关键的决策。
## 26. `cs.AI` - PAC 原理推理：控制性能损失以实现高效推理 [PDF](https://arxiv.org/pdf/2510.09133), [HTML](https://arxiv.org/abs/2510.09133)
### Authors
Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An
### Background
大型推理模型（LRMs）在复杂问题解决任务中取得了显著进展，但它们在部署过程中通常面临高计算成本的问题，这突出需要提高推理效率。一种提高效率的方法是动态地将LRMs切换到思考和非思考模式。然而，这些方法可能会引入额外的推理错误，并缺乏对于性能损失的统计保证，这对高风险应用至关重要。
### Innovation
本文提出了一种概率近似正确（PAC）推理方法，确保在用户指定的性能损失容忍度内控制性能损失。具体而言，构建了性能损失的上置信边界，并通过不确定性分数将其转化为单调函数来确定切换到非思考模式的阈值。理论上，这种切换确保了在无分布性的基础上有界性能损失。我们的全面实验表明，提议的方法可以节省计算预算并控制用户指定的性能损失。
### Conclusion
提出的PAC推理方法能够在用户指定的性能损失容忍度内控制性能损失，并通过上置信边界的技术确保无分布性的性能损失上界。实验结果表明，该方法可以高效地节省计算预算并提供可控的性能损失。
## 27. `cs.AI` - 构建自主LLM代理的基本原理 [PDF](https://arxiv.org/pdf/2510.09244), [HTML](https://arxiv.org/abs/2510.09244)
### Authors
Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll
### Background
传统的大型语言模型在实际任务中存在局限性，因此该研究旨在探索开发能够自动化复杂任务并弥补与人类能力差距的“智能”大型语言模型。主要组成部分包括一个感知系统，将环境感知转化为有意义的表示；一个推理系统，通过Chain-of-Thought和Tree-of-Thought等技术制定计划、适应反馈并评估行动；一个记忆系统，通过短期和长期机制保留知识；以及一个执行系统，将内部决策转化为具体行动。
### Innovation
该研究审查了由大型语言模型驱动的智能代理的架构和实现方法，旨在通过整合感知、推理、记忆和执行系统，创建更强大和通用的软件代理，这种代理能够模拟人类的认知过程，实现自主和智能行为。
### Conclusion
通过集成这些系统，可以创造出更为强大的智能代理，这些代理能够在现实世界任务中表现得更加智能，弥合与人类能力之间的差距。
## 28. `cs.AI` - Dr. Bias: 社会差异在AI驱动的医学指导中的体现 [PDF](https://arxiv.org/pdf/2510.09162), [HTML](https://arxiv.org/abs/2510.09162)
### Authors
Emma Kondrup,Anne Imouza
### Background
随着大型语言模型（LLMs）的迅速发展，公众现在可以轻松且经济地获取能够以个性化方式回答大多数健康相关问题的应用。这些模型在医疗能力上越来越具有竞争力，并且在某些方面甚至超过了专业人士。它们在资源匮乏地区特别有潜力，因为它们提供了广泛可访问、近乎免费的医疗支持的可能性。然而，支撑这些动机的评估很少深入社会医疗的本质，忽视了不同社会群体之间的健康差异，以及偏见如何在生成的医疗建议中体现出来，并影响用户。
### Innovation
本文提供了一个关于LLM对一系列覆盖关键临床领域医学问题的回答的探索性分析，模拟了不同性别、年龄范围和种族患者角色提问的场景。通过对比生成回复的自然语言特征，研究表明，当LLM用于生成医疗建议时，它们会根据社会群体系统性地生成不同的回复。特别地，对于原住民和性别间患者，收到的建议更难阅读且更复杂。研究还发现，当考虑交叠群体时，这一趋势会加剧。
### Conclusion
鉴于个体对这些模型的信任日益增加，作者呼吁提高AI素养，并强调AI开发者迫切需要进行调查和缓解以确保系统性差异的减少，不再转化为对患者的不公支持。代码已经在GitHub上公开。
## 29. `cs.AI` - 基于物理信息的高阶图动态识别学习用于预测复杂网络的长时动力学 [PDF](https://arxiv.org/pdf/2510.09082), [HTML](https://arxiv.org/abs/2510.09082)
### Authors
Bicheng Wang,Jinping Wang,Yibo Sue
### Background
理解、建模和控制现实世界的复杂系统的关键在于学习复杂网络的动力学。目前预测复杂网络动态进化的挑战在于，现有方法通常仅使用简单的图形描述网络关系，但这只能捕捉到成对关系，而网络中可能存在丰富的非成对关系结构。对于初级图形神经网络而言，难以捕捉动态的非成对关系。另外，理论预测模型缺乏准确性，数据驱动模型缺乏解释性。针对这些问题，提出了一种更高的网络动态识别方法，旨在长期动态预测复杂网络。该方法通过引入动态超图学习来解决传统图形机器学习只能处理成对关系的问题，以捕捉网络中的高阶非成对关系，从而提高复杂网络建模的准确性。同时，提出了一个受物理驱动的动态预测模块，利用科莫邓姆算子理论将复杂网络动态演化的非线性微分方程转化为可解的线性系统，并使用神经动力学方程方法确保动态演化符合物理定律，从而保证预测的准确性和解释性。该方法在公共数据集和自建的产业链条网络数据集上进行了验证，实验结果表明该方法具有良好的预测准确性和长期预测性能。
### Innovation
提出了一种基于物理信息的高阶图动态识别学习方法，它通过引入动态超图学习来捕捉复杂网络中的高阶非成对关系，并利用科莫邓姆算子和物理信息神经微分方程确保预测既准确又具有解释性。该方法对于长期动态预测复杂网络具有显著优势。
### Conclusion
基于物理信息的高阶图动态识别学习方法，通过引入动态超图学习和使用科莫邓姆算子理论及物理信息神经微分方程，有效地提高了复杂网络的动力学预测能力和解释性，实验结果验证了该方法的有效性。
## 30. `cs.AI` - RegexPSPACE: 一个评估LLM推理在PSPACE完全正则表达式问题上的基准 [PDF](https://arxiv.org/pdf/2510.09227), [HTML](https://arxiv.org/abs/2510.09227)
### Authors
Hyundong Jin,Joonghyuk Hahn,Yo-Sub Han
### Background
大型语言模型（LLMs）在自然语言处理、数学推理和编程方面表现出色，而近期的推理模型（LRMs）更强调明确的推理能力。然而，这些模型的计算限制，特别是在有限上下文窗口下受到的空间复杂度限制，尚未得到充分理解。现有的研究大多集中在NP复杂性类的问题上，而本文通过引入一个基于两个PSPACE完全的正则表达式（regex）问题的新型基准（RegexEQ和RegexMin）来拓展边界。PSPACE完全的问题为评估计算能力提供了更为严格的准则，因为它们需要进行大量的搜索空间探索。
### Innovation
本文提出了一个名为RegexPSPACE的新基准，用于评估LLMs和LRMs在PSPACE完全正则表达式问题上的推理能力。该基准是以两个具体的PSPACE完全问题构建的（正则表达式等价性决策和正则表达式最小化），通过双指数级的空间探索构建了一个包含超过一百万实例的标记数据集，并执行了严格的过滤过程。这种方法比现有的研究更严格，并且能够揭示模型的一些常见失败模式，如冗余和重复。通过这个基准，可以进行详细的定量评估，揭示LLMs和LRMs的空间计算限制，从而提供一个新的框架来评估其高级推理能力。
### Conclusion
通过RegexPSPACE基准，本文首次以实证方式探讨了LLMs和LRMs的空间计算限制，为其高级推理能力提供了新的评价框架。
## 31. `cs.AI` - 语言模型中演绎推理的机理解释趋向 [PDF](https://arxiv.org/pdf/2510.09340), [HTML](https://arxiv.org/abs/2510.09340)
### Authors
Davide Maltoni,Matteo Ferrara
### Background
最近的大语言模型展示了在解决需要逻辑推理的问题方面的相关能力；然而，相应的内部机制仍然没有得到充分探索。这项研究通过展示一个小规模的语言模型如何通过学习底层规则（而不是作为统计学习者的操作）来解决演绎推理任务，进一步阐述了这个问题背景。
### Innovation
这项研究证明了一个小型语言模型可以通过学习底层规则来解决演绎推理任务，而不仅仅是作为统计学习者进行操作。此外，研究提供了对其内部表示和计算电路的低层解释，并揭示了归纳头在逻辑推理任务的规则补全和规则链接步骤中的核心作用。
### Conclusion
研究结果表明，语言模型可以通过学习和应用底层逻辑规则来解决复杂的演绎推理任务，这为进一步理解语言模型的内部机制提供了新的视角。
## 32. `cs.AI` - 局部主义大语言模型——一种动态局部性控制的数学框架 [PDF](https://arxiv.org/pdf/2510.09338), [HTML](https://arxiv.org/abs/2510.09338)
### Authors
Joachim Diederich
### Background
本文介绍了一种训练大规模语言模型的新框架，该框架能够动态调整内部表示，从局部主义（可解释的、基于规则的）到分布式（可泛化的、高效的）编码。关键创新在于引入了一个局部性调谐器（locality dial），这是一种可调参数，可以在训练和推理过程中动态控制局部化程度，而无需重新训练模型。这一创新通过注意机制的分组稀疏惩罚、信息论锚点设计和动态规则注入实现。文章提供了严格的数学证明，证明在特定阈值条件下，注意机制能够集中于语义相关的部分，同时给出了注意熵和指针准确性的指数级上界。
### Innovation
提出的框架通过引入局部性调谐器，能够在保持可解释性的同时实现高性能。通过分组稀疏惩罚注意力机制、信息论锚点设计和动态规则注入，实现模型内部表示在局部主义和分布式之间动态调整。严格的数学证明支持了这一理论，证明了在特定条件下模型的注意力机制能够准确聚焦于语义相关的部分，同时保持低熵和高准确性。
### Conclusion
该框架允许从业者连续地在解释性和高性能模式之间进行插值，支持需要透明性和能力兼备的应用场景。
## 33. `cs.AI` - 序列变量：用于路由和排序的约束编程计算领域 [PDF](https://arxiv.org/pdf/2510.09373), [HTML](https://arxiv.org/abs/2510.09373)
### Authors
Augustin Delecluse,Pierre Schaus,Pascal Van Hentenryck
### Background
约束编程（CP）为车辆路线问题（VRP）提供了直观且声明式的建模框架，但传统的基于后继变量的CP模型在处理可选访问或插入式启发式方面存在局限性。
### Innovation
本文正式化了序列变量在CP中的应用。与传统的后继模型不同，这种计算领域能够处理可选访问并支持插入启发式，包括基于插入的大型邻域搜索。文中还定义了域、更新操作，并引入了针对该域的一致性级别。此外，还提出了专为序列变量和车辆路线设计的全局约束。
### Conclusion
序列变量在简化问题建模并实现计车辆路线问题（例如Dial-a-Ride Problem）的高效求解方面展示了其有效性。
## 34. `cs.AI` - 安全可信的‘证明携带’AI代理：迈向自主代理数据湖 [PDF](https://arxiv.org/pdf/2510.09567), [HTML](https://arxiv.org/abs/2510.09567)
### Authors
Jacopo Tagliabue,Ciro Greco
### Background
数据湖运行敏感工作负载时，AI驱动的自动化引起了关于信任、正确性和治理的问题。我们提出，API优先、可编程数据湖提供了设计安全且自主工作流的正确抽象层。
### Innovation
文中利用Bauplan作为案例研究，展示了如何通过数据分支和声明性环境自然地扩展到代理，从而实现可重复性和可观测性的同时减少攻击面。文中还提出了一种概念实现，其中代理使用类似于证明携带代码的正确性检查来修复数据管道。证明了不信任的AI代理可以在生产数据上安全地运行，并勾画出迈向完全自主代理数据湖的路径。
### Conclusion
原型表明，不信任的AI代理可以在生产环境中安全运行，并为自主代理数据湖制定了未来路径。
## 35. `cs.AI` - GraphMERT：从无结构数据高效且可扩展地提取可靠的知识图谱 [PDF](https://arxiv.org/pdf/2510.09580), [HTML](https://arxiv.org/abs/2510.09580)
### Authors
Margarita Belova,Jiaxin Xiao,Shikhar Tuli,Niraj K. Jha
### Background
研究人员近三十年来一直追求神经象征人工智能（Neurosymbolic AI）的应用，因为符号组件提供了抽象，而神经组件提供了泛化。因此，这两种组件的结合可以带来人工智能的快速进步。然而，该领域的前景尚未实现，因为大多数神经象征人工智能框架未能扩展。此外，神经方法隐式表示和近似推理的限制影响了可解释性和可信度。知识图谱（KGs）作为显式语义知识的标准表示形式，可以解决符号方面的问题，但是在文本语料库中自动生成可靠的KGs仍然是一个开放性问题。
### Innovation
该研究提出了一种名为GraphMERT的仅编码器图形模型，可以从无结构文本语料库中提取高质量的知识图谱，并通过其内部表示进行自我改进。该模型及其等效KG形式形成了一种模块化的神经象征栈：通过神经学习抽象；以及使用KG进行可验证推理。GraphMERT与KG相结合，是首个高效且可扩展的神经象征模型，实现了最先进的基准准确率和更为优越的符号表示，相对于基线模型更具有优势。
### Conclusion
GraphMERT与KG的结合在糖尿病主题的PubMed论文中生成的知识图谱表现优异，其FActScore为69.8%，ValidityScore为68.8%，远高于32亿参数的基础大型语言模型（LLM，如Qwen3-32B）生成的KG，其FActScore为40.2%，ValidityScore为43.0%。
## 36. `cs.AI` - 深度多模态子空间聚类网络 [PDF](https://arxiv.org/pdf/1804.06498), [HTML](https://arxiv.org/abs/1804.06498)
### Authors
Mahdi Abavisani,Vishal M. Patel
### Background
该研究提出了基于卷积神经网络（CNN）的无监督多模态子空间聚类方法，聚焦于多模态数据的融合与表示学习。背景包括多模态数据在不同应用场景中的广泛应用，以及传统方法在处理这类数据时遇到的挑战，如数据融合难度大、表示学习不足等问题。
### Innovation
论文的主要创新点包括：1) 一个由多模态编码器、自表达层和多模态解码器组成的三阶段框架；2) 研究早期、晚期和中间融合技术，并针对空间融合设计了三种不同的编码器；3) 提出了自表达层和多模态解码器在不同空间融合方法中是统一的，同时提出了一种基于自表达层融合的方法，使不同模态的自表达层相同；4) 通过在多个数据集上的实验验证了所提方法优于现有最先进的方法。
### Conclusion
该研究通过使用深度学习方法成功地实现了多模态数据的无监督子空间聚类，并在多个数据集上验证了方法的有效性，表现出显著的优越性。
## 37. `cs.AI` - 放射学中的代理系统：设计、应用、评估与挑战 [PDF](https://arxiv.org/pdf/2510.09404), [HTML](https://arxiv.org/abs/2510.09404)
### Authors
Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh
### Background
代理系统，能够感知并自主作用于环境中的系统，一直是AI研究的重点。随着大型语言模型（LLMs）的出现，这些模型能够使用自然语言整合信息、遵循指令并在多种任务中执行多种形式的“推理”和计划，代理系统在实践中的应用变得更为普遍。放射学领域因其多模态数据流和多个系统间的协同工作流程，非常适合利用能够适应环境并自动化复杂而重复任务的代理系统。尽管LLMs及其多模态变体已经在信息提取和报告摘要等任务上展示了有希望的表现，但单独使用LLMs会使它们在复杂多步骤工作流中的应用潜力受限。通过为LLMs配备外部工具和反馈机制，可以促进系统具备从半自动化的工作流到能够管理复杂过程的更加适应性更强的代理系统。本文综述了LLM驱动的这些代理系统的设计、主要应用、计划和工具使用评估方法，并讨论了错误传播、工具使用效率和与健康信息技术集成等挑战。
### Innovation
本文创新性地探讨了LLM驱动的代理系统的具体设计、其在放射学中的主要应用、评估这些系统的规划和工具使用方法，并指出了应用中可能遇到的重要挑战，如错误传播、工具使用效率和与健康信息技术集成等难题。作者提出通过为LLMs配备外部工具和反馈机制，使这些代理系统能够支持复杂多步骤工作流程，从而最大化LLMs在复杂决策中的作用。
### Conclusion
本文综评了LLM驱动的代理系统在放射学中的设计、应用与挑战。作者认为通过改进现有的设计和工具使用，可以使代理系统在放射学中发挥更大的作用，提高工作流程的效率和准确性，但同时也需要解决工具使用效率、错误传播和健康信息技术集成等现实问题。
## 38. `cs.AI` - 通过多模态训练提高单一模态动态手势识别的性能 [PDF](https://arxiv.org/pdf/1812.06145), [HTML](https://arxiv.org/abs/1812.06145)
### Authors
Mahdi Abavisani,Hamid Reza Vaezi Joze,Vishal M. Patel
### Background
当前的手势识别方法大多依赖单一模态的3D卷积神经网络（3D-CNN），但在识别任务中，利用多种模态的知识可能显著提高识别的准确性和鲁棒性。传统的做法是显式地结合多模态信息，然而，本文提出了一种不同的框架，即通过在单独的网络中嵌入多模态信息，使每个单一模态的网络提高性能。
### Innovation
本文提出了一种新颖的方法，即通过构建一个“时空语义对齐”损失（SSA）来实现不同模态网络的特征内容对齐，并通过引入“焦点正则参数”来避免不良的知识迁移。这种方法能够在不直接结合多模态信息的情况下提高单一模态网络在动态手势识别任务中的测试时间识别准确性。
### Conclusion
实验结果显示，本文框架能显著提高单一模态3D-CNN在动态手势识别任务中的测试时间识别准确性，并在多种动态手势识别数据集上达到了当前最先进的性能。
## 39. `cs.AI` - LiveOIBench：大型语言模型能在信息学奥林匹克竞赛中超越人类参赛者吗？ [PDF](https://arxiv.org/pdf/2510.09595), [HTML](https://arxiv.org/abs/2510.09595)
### Authors
Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang
### Background
由于编程竞赛问题复杂且易于验证，它们已成为评估大型语言模型（LLMs）编码能力的重要基准。然而，当前的编程基准存在一些限制，包括缺乏极富挑战性的问题、测试案例覆盖面不足以及依赖于限制访问性的在线平台API。为解决这些问题，本文介绍了LiveOIBench，这是一个包括403个权威精选的奥林匹克级别编程竞赛问题的全面基准，每个问题平均有60个专家设计的测试案例。
### Innovation
LiveOIBench 通过四个关键特性进行创新：（1）高质量任务的精心筛选，附有详细的子任务评分标准和广泛的私有测试案例；（2）直接集成顶尖参赛者的表现数据，以与顶级人类表现者进行有信息性的比较；（3）持续性、无污染的更新，来自新发布的奥林匹克竞赛问题；（4）独立的评估系统，便于线下和易于复现的评估。
### Conclusion
通过基准测试32个流行的通用和推理型LLMs，研究发现GPT-5达到了显著的第81.76百分位，尽管这一结果很强大，但仍然低于通常排名前90％的人类参赛者的水平。相比之下，开源推理型模型GPT-OSS-120B仅达到第60百分位，突显出与前沿封闭模型之间存在显著的能力差异。详细分析表明，强大的推理模型更注重精准的问题分析而非过多探索，这意味着未来模型应加强结构化分析并减少不必要的探索。
## 40. `cs.AI` - 基于深度学习的稀疏表示分类 [PDF](https://arxiv.org/pdf/1904.11093), [HTML](https://arxiv.org/abs/1904.11093)
### Authors
Mahdi Abavisani,Vishal M. Patel
### Background
该研究基于稀疏表示分类（SRC）方法，通过提出一个深度学习的框架来改进SRC方法，采用卷积自编码器和全连接层来实现更有效和准确的分类。背景指出，当前的SRC方法在某些情况下可能无法提供最佳的分类结果，因此需要改进以提高稀疏表示的质量，从而提升分类性能。
### Innovation
创新之处在于提出了一种新的基于深度学习的模型，结合卷积自编码器和全连接层来生成更稳健的特征表示以及稀疏编码，这有助于提高SRC方法的分类性能。与现有的SRC方法相比，实验结果显示新方法能产生更优的分类结果，从而表明新模型的有效性和改进之处。
### Conclusion
研究展示了基于深度学习的稀疏表示分类网络能够提供比现有方法更好的分类性能，通过采用卷积自编码器和全连接层，该网络可以生成更高质量的稀疏表示，从而提高分类准确性。同时，该论文提供的源代码可以被其他研究者使用和验证。
## 41. `cs.AI` - AgenticAD：全方位阿尔茨海默病管理的专业多智能体系统框架 [PDF](https://arxiv.org/pdf/2510.08578), [HTML](https://arxiv.org/abs/2510.08578)
### Authors
Adib Bazgir,Amir Habibdoust,Xing Song,Yuwen Zhang
### Background
阿尔茨海默病（AD）给患者、护理人员和医疗系统带来了复杂的多方面挑战，需要整合和动态的支持解决方案。当前的人工智能（AI）干预应用往往孤立，仅解决疾病诊断或护理人员支持等单一方面的问题，缺少系统的集成。
### Innovation
该论文提出了一个全面、多智能体系统（MAS）的方法论框架，专门设计用于阿尔茨海默病的综合管理。该框架由八个具有特定功能的专业互操作智能体组成，涵盖从护理人员和病人支持、数据分析和研究到高级多模态工作流等多个方面。智能体的技术架构利用了大型语言模型（LLM）、多智能体编排框架、检索增强生成（RAG）和专门的跨模态数据处理工具，促进了一个协作式人工智能生态系统的发展。
### Conclusion
通过超越单一用途工具，转向协作性的多智能体范式，该框架为开发更为适应性和个性化的解决方案奠定了基础。这种方法旨在为未来能够综合多元数据流来改善患者结果并减轻护理人员负担的系统铺平道路。
## 42. `cs.AI` - 大型语言模型在机器辅助解析用户意图方面的比较分析 [PDF](https://arxiv.org/pdf/2510.08576), [HTML](https://arxiv.org/abs/2510.08576)
### Authors
Justus Flerlage,Alexander Acker,Odej Kao
### Background
大型语言模型（LLMs）已经成为了自然语言理解和用户意图处理的重要工具，支持如翻译和总结等任务，甚至开始管理复杂的流程。这种技术变革预示着用户界面从图形用户界面（GUI）向语言优先交互模式的转变。用户可以通过自然语言表达其目标，促使LLMs跨多个应用程序执行动态、上下文相关的操作。然而，现有的实施通常依赖云上的专有模型，这在隐私、自主性和可扩展性方面带来了限制。为了使语言优先的交互成为真正的强大且可信赖的界面模式，当地部署不仅是便利的，而是必要的。因此，本研究评估了几种开源和开放访问的LLMs如何在机器辅助下促进用户意图解析的能力，并将其与OpenAI的专有GPT-4系统进行了对比分析。
### Innovation
本研究的重点在于开启讨论关于AI基础设施的去中心化和普及化，特别是通过将开放源代码的LLMs嵌入下一个版本的系统中，实现更为无缝、适应性强且注重隐私的用户设备交互。
### Conclusion
本研究为了解开源LLMs在新一代操作系统的自主、本地操作组件中的可行性和性能权衡提供了实证见解。研究结果支持了未来用户设备交互更加无缝、适应性强和注重隐私的愿景，通过嵌入式智能增强了用户体验。
## 43. `cs.AI` - LadderSym：音乐实践错误检测的多模态交织变换器 [PDF](https://arxiv.org/pdf/2510.08580), [HTML](https://arxiv.org/abs/2510.08580)
### Authors
Benjamin Shiue-Hal Chou,Purvish Jajal,Nick John Eliopoulos,James C. Davis,George K. Thiruvathukal,Kristen Yeon-Ji Yun,Yung-Hsiang Lu
### Background
音乐学习者可以从能够准确检测其练习中错误的工具中大幅受益。现有方法通常通过启发式规则或可学习的模型比较音频录制和乐谱。LadderSym 提出了一种基于Transformer的新颖方法，旨在解决现有方法中的局限性，如晚融合限制了跨流对齐和跨模态比较能力，以及对乐谱音频的依赖引入频谱的模糊性，导致多音符乐曲的性能下降。
### Innovation
LadderSym 通过（1）引入具有跨流对齐模块的双流编码器，以提高音频比较能力和错误检测F1分数；（2）采用多模态策略，结合音频和乐谱符号作为解码器提示，减少模糊性和提高F1分数。
### Conclusion
在MAESTRO-E和CocoChorales-E数据集上，LadderSym 在未检测到的音符（missed notes）上的F1分数提高了近一倍（从26.8%提升到56.3%），额外音符检测（extra notes detection）提高了14.4个百分点（从72.0%提升到86.4%）。这项工作提供了关于比较模型的一般见解，这些见解可以用于强化学习序列评估任务、人类技能评估和模型评估任务的启示。
## 44. `cs.AI` - PyNoetic：一种用于无代码开发脑机接口的模块化Python框架 [PDF](https://arxiv.org/pdf/2509.00670), [HTML](https://arxiv.org/abs/2509.00670)
### Authors
Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo
### Background
EEG-BCI（脑电图-脑-计算机接口）作为一种变革性的技术，已被应用于机器人、虚拟现实、医疗和康复等多个领域。然而，现有的BCI框架存在一些局限性，包括缺乏实验研究所需的逐阶段灵活性、对非编程研究人员来说陡峭的学习曲线、由于依赖专有软件而产生的高昂成本，以及缺失的全面功能导致需要使用多个外部工具，这影响了研究结果。
### Innovation
PyNoetic 是一种模块化的BCI框架，专为满足BCI研究的多样化需求而设计。它是少数几个涵盖BCI设计全流程的Python框架之一，从刺激展示和数据采集到通道选择、滤波、特征提取、伪迹去除、模拟和可视化。PyNoetic 引入了直观且端到端的GUI和独特的可配置流程图，支持无代码BCI设计，使其对编程经验有限的研究人员更易上手。同时，PyNoetic 为高级用户提供无缝集成自定义功能和新算法的途径，确保在设计的每个阶段都能实现适应性。此外，PyNoetic 提供了丰富的分析工具，包括机器学习模型、脑连接度指数、模拟模拟测试功能和新范式的评估方法。PyNoetic 的优势在于它在离线和实时BCI开发中的高灵活性，这简化了设计过程，使研究人员能够专注于BCI开发的更深层次方面，从而加速其研究进程。
### Conclusion
PyNoetic 作为一种模块化的BCI框架，通过提供直观的GUI和端到端的设计流程，以及支持自定义功能和新算法的方法，简化了BCI的开发过程，使其既适合编程新手也适合高级用户。PyNoetic 的灵活性和多功能性增强了BCI研究的效率和质量，为未来的BCI技术研究和应用铺平了道路。
## 45. `cs.AI` - 动态压力检测：言语中压力时序建模研究 [PDF](https://arxiv.org/pdf/2510.08586), [HTML](https://arxiv.org/abs/2510.08586)
### Authors
Vishakha Lall,Yisi Liu
### Background
在高压环境下，从语音中检测心理压力至关重要。以往的研究主要利用声学特征来检测压力，但大多数情况下将压力视为静态标签。本研究将压力视为一个受历史情绪状态影响随时间变化的现象，提出了一个动态标签策略，并引入了基于交叉注意力的顺序模型，包括单向LSTM和Transformer编码器来捕捉压力随时间的变化过程。
### Innovation
提出了一个动态标签策略，从情绪标签中推导出精细的压力标注，并利用基于交叉注意力的顺序模型，包括单向LSTM和Transformer编码器，来捕捉压力随时间的演变过程。这种方法在MuSE和StressID上的准确性分别提高了5%和18%，并且能够很好地泛化到一个定制的现实世界数据集，强调了将压力建模为动态结构的重要性.
### Conclusion
本研究通过动态标签策略和基于交叉注意力的顺序模型，提高了心理压力检测的准确性，特别是在高压环境下，展示了其在实际应用中的潜力。
## 46. `cs.AI` - EGSTalker：高效高斯变形驱动的实时音频生成头部模型 [PDF](https://arxiv.org/pdf/2510.08587), [HTML](https://arxiv.org/abs/2510.08587)
### Authors
Tianheng Zhu,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng
### Background
随着多媒体应用的迅速发展，为了提高应用的即时性和用户沉浸感，需要快速生成高保真面部动画。目前的面部动画生成方法往往需要大量的训练数据和时间，难以满足实时应用的需求。因此，如何在保证质量和效果的同时，大幅缩短训练时间和提高实时性能，成为研究的关键问题。
### Innovation
该论文提出的EGSTalker框架，基于3D高斯点计算（3DGS），仅需3-5分钟的训练视频即可合成高质量的面部动画。它通过两个核心阶段——静止高斯初始化和音频驱动形变——实现了高效的面部动画生成。尤其是，提出的高效空间-音频注意机制（ESAA模块）能够有效地融合音频和空间信息，显著提高了性能。该方法在渲染质量和口型同步精度上与当前最先进的技术相当，但在推理速度上表现更为出色。
### Conclusion
EGSTalker通过高效的空间-音频注意机制和高效的3D高斯点表示，成功地实现了实时音频驱动的面部动画生成，大幅提高了实时多媒体应用领域的性能表现。未来该技术有望在实时视频通话、虚拟现实和增强现实等领域发挥重要作用。
## 47. `cs.AI` - 在多种声学条件下使用语音查询评估多模态LLM中的幻觉 [PDF](https://arxiv.org/pdf/2510.08581), [HTML](https://arxiv.org/abs/2510.08581)
### Authors
Hansol Park,Hoseong Ahn,Junwon Moon,Yejin Lee,Kyuhong Shim
### Background
当前对于视觉-语言模型中的幻觉已有较多研究，但在语音查询如何影响多模态幻觉方面，仍然存在大量的空白。尽管语音驱动界面越来越普遍，相关研究尚不充分。这项工作旨在探讨语音输入如何影响多模态大型语言模型中的幻觉现象，并提出了RePOPE-Spk基准测试，用于系统性地评估不同模型在不同声学条件下的表现。结果表明，在语音查询相较于文本查询时，幻觉现象有显著增加。此外，输入顺序和查询长度也对模型的可靠性有影响，但在改善模型幻觉方面的解决策略仍有局限性。
### Innovation
推出RePOPE-Spk基准测试，评估在多样的声学条件下，使用语音查询时多模态大型语言模型的幻觉现象。这是首次全面研究语音查询对多模态模型幻觉的影响。
### Conclusion
研究表明，语音查询相比文本查询，导致幻觉增加的现象更加显著，并且模型的可靠性受输入顺序和查询长度影响。尽管有一些改善策略，但仍然不能完全缓解幻觉问题。这突显了一个重要的但尚未充分探索的挑战，未来工作需要根据这些结果设计更加可靠的声音交互系统。
## 48. `cs.AI` - 超越传统CNN：在低数据集条件下高效微调多模态语言模型进行物体检测 [PDF](https://arxiv.org/pdf/2510.08589), [HTML](https://arxiv.org/abs/2510.08589)
### Authors
Nirmal Elamon,Rouzbeh Davoudi
### Background
物体检测和理解领域正在快速发展，得益于传统基于CNN的模型和新兴的多模态大型语言模型（LLMs）。尽管如ResNet和YOLO等CNN在基于图像的任务中仍然非常有效，但基于transformer的LLMs引入了动态上下文推理、语言引导的提示和全场景理解等新能力。然而，当直接使用这些LLMs时，它们的全部潜力并未被充分利用，通常导致在专业化视觉任务上的表现不佳。本文通过全面比较微调的传统CNN、零样本多模态LLMs和微调的多模态LLMs，在人工文本叠加检测这一具有挑战性的任务上进行研究。
### Innovation
我们展示了在不到1000张图片的非常有限的数据集上有效微调LLMs，从而实现多达36%的准确率提升，这一结果甚至能够匹配或超越基于CNN的标准基线模型，这类模型通常需要更大量的数据。通过探索如何使语言引导的模型能够进行精确的视觉理解，并在最少的监督下适应，我们的研究为视觉和语言的结合提供了新的见解，提出了一种有效的跨模态学习策略。这些发现突显了基于LLM的方法在真实世界物体检测任务中的适应性和数据效率，为在低资源视觉环境中应用多模态变换器提供了行动指南。
### Conclusion
我们的研究结果强调了基于LLMs的方法在现实世界物体检测任务的适应性和数据效率，并为在低资源视觉环境中应用多模态变换器提供了行动指南。为了促进该领域的持续进步，我们已经在GitHub上发布了用于微调模型的代码，以支持未来的改进和重复使用相关应用。
## 49. `cs.AI` - 深度神经网络的持续主导地位：对量子机器学习和脉冲神经网络根本局限性的批判性分析 [PDF](https://arxiv.org/pdf/2510.08591), [HTML](https://arxiv.org/abs/2510.08591)
### Authors
Takehiro Ishikawa
### Background
近期，量子机器学习（QML）和脉冲神经网络（SNNs）的进步激发了极大的兴趣，它们有望通过实现指数级别的速度提升和与大脑类似的能量效率，彻底改变人工智能。然而，本文认为在短期内它们不太可能取代深度神经网络（DNNs）。
### Innovation
然而，QML 遭遇了单元保真约束、测量诱导的状态崩溃、退化的梯度景观以及高测量开销等问题，这些问题在当前噪声中间规模的量子硬件限制下更加严重，急需开发更具针对性的正则化技术以减少过拟合风险。SNNs 面临带宽限制，难以处理远距离依赖和语言任务中的语义编码，这主要是由于其基于突触处理的离散性质。此外，实现大脑般的仿真是潜在的高效率损失，包括认知偏见、有限的工作记忆和缓慢的学习速度。尽管SNNs在能源效率上被认为有优势，但优化后的DNNs，特别是采用量化技术的DNNs，可能在实际条件下表现更佳。
### Conclusion
相反，DNNs 利用了高效的反向传播、稳健的正则化以及LRRs创新，可以将缩放转移至推理时计算，这使得其能够通过强化学习和模拟退火算法等技术实现自我改进，同时缓解数据稀缺问题。这在近年来的模型如 xAI 的 Grok-4 Heavy 和 gpt-oss-120b 中得到了证据，后者尽管参数量仅为120亿且部署在单个80GB GPU上，其性能却超越甚至接近了顶级的行业模型。此外，专用的ASIC提高了这些效率。最终，QML 和 SNNs 或者可能在某些混合角色中发挥作用，但DNNs仍然是推动人工智能进步的主要且实际的范式。
## 50. `cs.AI` - 较少多样性，较少安全性：大型语言模型测试时放缩中的间接但普遍存在的风险 [PDF](https://arxiv.org/pdf/2510.08592), [HTML](https://arxiv.org/abs/2510.08592)
### Authors
Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra
### Background
TTS通过探索多个候选响应并从中找到最佳输出来改进LLM的推理。背后的一个假设是，足够多样的候选池增强了可靠性。然而，本文发现当候选多样性受到限制时，即使是轻微的限制，TTS也更有可能产生不安全的输出。这种现象在多个开源模型和不同的TTS策略中得以验证，并且也在闭源模型中表现出来，表明这是一个广泛存在的TTS特性而非特定模型的异常。现有的安全防护机制对由RefDiv生成的对抗输入提示无法检测，表明现有防御策略对这种多样性驱动的失败模式提供的保护有限。
### Innovation
引入了一个名为RefDiv的参考指南多样缩减协议，这是一种诊断攻击，用于测试TTS管道。实验结果显示，多样性受限时，TTS产生不安全结果的可能性显著增加，这种现象在多种模型和策略中普遍存在。
### Conclusion
本文发现了一个新的TTS失败模式——当多样性受限时，会增加生成不安全输出的风险。现有的安全防护机制对于这种多样性驱动的风险效果有限。希望未来的研究能设计出既能有效运作又能抵御这种多样性的TTS策略。
## 51. `cs.AI` - 基于层次自监督表示学习的语音抑郁检测 [PDF](https://arxiv.org/pdf/2510.08593), [HTML](https://arxiv.org/abs/2510.08593)
### Authors
Yuxin Li,Eng Siong Chng,Cuntai Guan
### Background
语音基于抑郁检测（SDD）是一种有前景的无创替代传统临床评估的方法。然而，它仍然受限于提取有意义特征和捕捉随时间变化的稀疏且异质的抑郁迹象的难度。预训练自监督学习（SSL）模型如WavLM能够提供丰富的多层语音表示，但大多数现有的SDD方法仅依赖于最终层或寻找最佳表现的模式，这些方法常在特定数据集上过度拟合，未能充分利用用于检测微妙且持久抑郁信号的完整分层结构。
### Innovation
我们提出了一种名为HAREN-CTC的创新架构，该架构结合了多层SSL特征，利用多任务学习框架内的跨注意力，结合连接主义时序分类损失（CTC）来处理稀疏的时间监督。HAREN-CTC包括两个关键模块：层级自适应聚类模块和跨模态融合模块。CTC目标使模型能够追踪抑郁语音线索的不规则时间模式。
### Conclusion
我们在标准数据分割的上限设置和五折交叉验证的一般设置下评估了HAREN-CTC模型，在DAIC-WOZ和MODMA上分别取得了最先进的宏观F1分数0.81和0.82，并在两种评估场景中均优于先前的方法。
## 52. `cs.AI` - Recover-LoRA: 通过低秩适应实现退化语言模型的无数据精度恢复 [PDF](https://arxiv.org/pdf/2510.08600), [HTML](https://arxiv.org/abs/2510.08600)
### Authors
Devleena Das,Rajeev Patwari,Ashish Sirasao
### Background
语言模型任务中的推理优化措施，如量化的调整、权重剪枝、数据类型转换、模型导出和序列化等，可能会导致模型性能的退化。大多数优化集中于基于量化的技术以恢复部署后的性能，但本研究着眼于从模型权重退化中恢复精度的问题，特别是由于不正确的模型序列化导致的问题。
### Innovation
本研究提出了Recover-LoRA，一种轻量级、数据无关的方法，用以恢复退化模型的精度。Recover-LoRA 使用合成数据和 logits 以蒸馏的方式，在模型选择性层上学习 LoRA 调节器，辅助将退化模型与全精度模型对齐。
### Conclusion
研究结果表明，Recover-LoRA 在包含不同注意机制的小型语言模型（SLM），如带有不同头部注意力机制的多头注意力（MHA）和群组查询注意力（GQA），等多种评估数据集上，能够提升模型精度在 5-17%。
## 53. `cs.AI` - BaldWhisper: 使用头剪切和层合并加快 Whisper [PDF](https://arxiv.org/pdf/2510.08599), [HTML](https://arxiv.org/abs/2510.08599)
### Authors
Yaya Sy,Christophe Cerisara,Irina Illina
### Background
对低资源语言进行大预训练变换器剪枝是一项挑战，因为这通常需要大量的重新训练数据来恢复性能。例如，Distill-Whisper通过剪枝并重新训练21,000小时的语音数据来减少40%的Whisper，这远远超出了大多数语言所能够提供的数据量。因此，如何使Whisper更适合在数据稀缺环境中利用边缘设备并变得更加轻量和快速成为一个迫切需要解决的问题。
### Innovation
该研究专注于只有32小时语音转文本数据的巴马拉语，提出了一种新的剪枝方案，不使用词汇剪枝（由于巴马拉语讲者频繁混合语言而不太合适），而是采用低秩分解和特征蒸馏压缩嵌入。此外，该研究并没有简单地删除模型的层，而是通过合并层来限制性能损失。结果表明，最终模型保持了90%的原始性能，同时体积缩小了48%，速度提高了2.15倍（在MacBook Air M1上）。
### Conclusion
这项研究提出了一个新的针对数据稀缺语言的大模型剪枝方案，通过低秩分解和特征蒸馏压缩嵌入，以及层合并，实现了模型的轻量化和加速，在保持性能的同时满足了边缘设备的需求。
## 54. `cs.AI` - LatentBreak：通过潜在空间反馈破解大型语言模型 [PDF](https://arxiv.org/pdf/2510.08604), [HTML](https://arxiv.org/abs/2510.08604)
### Authors
Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio
### Background
现有针对大型语言模型的自动化破解攻击通常通过优化对抗后缀或调整长提示模板来生成初始部分受限或有害的响应。然而，这些攻击可以通过简单的困惑度过滤来检测。因此，本文背景在于介绍一种新的白盒破解方法，以克服现有缺陷。
### Innovation
本文提出了一种名为LatentBreak的白盒破解攻击方法，它生成自然的低困惑度对抗提示，可以绕过基于困惑度的防护措施。LatentBreak通过在潜在空间中选择最相似的单词来替换输入提示中的单词，从而保持初始意图，无需添加高困惑度的对抗后缀或长模板。
### Conclusion
与现有竞争性的破解算法相比，LatentBreak生成的提示更短且低困惑度，在多个对齐了安全性的模型上显示出更强的性能，从而能够更有效地绕过基于困惑度的防护措施。
## 55. `cs.AI` - 向更安全的网络迈进：多语言多代理大语言模型在缓解对抗式 misinformation 攻击中的应用 [PDF](https://arxiv.org/pdf/2510.08605), [HTML](https://arxiv.org/abs/2510.08605)
### Authors
Nouar Aldahoul,Yasir Zaki
### Background
数字平台上错误信息的快速传播威胁了公共话语、情感稳定和决策。尽管此前已有研究探索了各种误导信息检测中的对抗性攻击，但本文详细研究的特定转换（如跨语言转换、查询长度夸大和结构重新格式化等问题）尚未受到系统研究。
### Innovation
本文提出了一种基于检索增强生成的多语言多代理大语言模型框架，并可部署为网络插件至在线平台。该工作强调了利用AI驱动的错误信息检测以保护网络事实完整性的必要性，同时展示了基于插件部署在实际网络应用程序中的可行性。
### Conclusion
我们的研究结果表明，多语言多代理大语言模型框架能在面对各种攻击时有效保护网络中的事实完整性，并且这种基于插件的方法具有在实际网络应用程序中实施的潜力。
## 56. `cs.AI` - Mnemosyne: 一种适用于边缘端LLM的无监督、效仿人类的长期记忆架构 [PDF](https://arxiv.org/pdf/2510.08601), [HTML](https://arxiv.org/abs/2510.08601)
### Authors
Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)
### Background
自然、现实对话需要长期记忆的支持。当前的大语言模型（LLM）记忆系统要么依赖于粗暴的上下文扩展，要么依赖于静态检索管道，这些系统在边缘限制设备上表现不佳。
### Innovation
Mnemosyne 提出了一个无监督、效仿人类的长期记忆架构，适用于边缘端的LLM。它采用了图表结构存储、模块化材料和冗余过滤器、记忆提交和修剪机制，以及基于人类记忆的概率回忆和时间衰减及刷新过程。此外，Mnemosyne 引入了一个浓缩的核心摘要，能够有效地从固定长度的内存图子集中捕获用户的个性和领域相关的历史信息。
### Conclusion
在纵向医疗对话的实验中，Mnemosyne 在盲评估中展现了65.8%的现实度和长期记忆能力，相比基线RAG提高了31.1%。此外，Mnemosyne 在 LoCoMo 基准测试中的时间推理和单跳检索达到最高分，并且整体得分也是第二高，超越了常用的 Mem0 和 OpenAI 基线，这表明改善事实回忆、增强时间推理和更自然的用户反馈是可行的，尤其是使用一种边缘兼容且易于迁移的无监督记忆架构时。
## 57. `cs.AI` - 基于相对定位的代码分割方法用于代码语言模型在仓库级别代码补全任务中丰富上下文检索 [PDF](https://arxiv.org/pdf/2510.08610), [HTML](https://arxiv.org/abs/2510.08610)
### Authors
Imranur Rahman,Md Rayhanur Rahman
### Background
代码补全能够帮助开发人员提高效率，简化开发流程。现代集成开发环境（IDE）中已有代码补全功能，但对于如何基于IDE可获取的信息构建有效上下文以改善大型语言模型（LLMs）的代码补全性能，现有研究尚缺乏深入探讨。本文旨在通过提出一种有效的上下文收集策略，提高大型语言模型在代码补全任务中的表现。
### Innovation
本文提出了基于相对定位的代码分割方法，该方法首先将代码仓库预处理成较小的代码片段，随后利用基于语法规则和语义相似性的代码片段检索技术，关键在于相对定位代码片段，该方法显著改善了代码补全任务的性能。
### Conclusion
通过代码片段化和相对定位，最终上下文可有效提升大型语言模型在代码补全任务上的表现，为代码开发环境中的智能代码补全提供了新的解决方案。
## 58. `cs.AI` - 以情绪热点为中心：对话中多模态局部-全局融合与跨模态对齐 [PDF](https://arxiv.org/pdf/2510.08606), [HTML](https://arxiv.org/abs/2510.08606)
### Authors
Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li
### Background
情绪识别在对话中的挑战在于区别性证据稀疏、局部化且常在不同模态间异步出现。
### Innovation
该文提出了一种统一模型，通过检测文本、音频和视频中的情绪热点，使用热点门控融合，并通过路由混合的整合器对齐模态，利用跨模态图编码对话结构。该设计关注突出的片段以减少对齐错误并保留上下文信息，实验显示该方法在标准对话情绪识别基准上相对于强基线有所提升，并且消融实验验证了热点门控融合（HGF）和混合的整合器（MoA）的贡献。研究结果表明，热点为中心的观点可以为未来多模态学习提供指导，为对话情绪识别中的模态融合提供了新的视角。
### Conclusion
实验结果支持热点为中心的观点，该方法在标准对话情绪识别基准上表现良好，通过分析有助于未来多模态情绪识别的发展。
## 59. `cs.AI` - 穿越兔子洞：从DINO的任务相关概念到闵科夫斯基几何 [PDF](https://arxiv.org/pdf/2510.08638), [HTML](https://arxiv.org/abs/2510.08638)
### Authors
Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg
### Background
DINOv2广泛应用于物体、场景和动作识别，但对其感知本质仍然不了解。为了理解DINOv2的学习表现，作者采用线性表示假设（LRH）并利用SAEs进行可视化研究，发现其能够通过不同任务招募特定的概念，揭示了概念的功能特化。通过这一分析，作者进一步探索了SAEs学习到的概念的几何分布及其统计特性，发现概念表示既非严格稀疏也非完全密集，表明这些表示在简单稀疏性之外还具有更高维度的组织结构。
### Innovation
作者提出了Minkowski表示假设（MRH），它基于Gardenfors的概念空间理论，认为SAEs中的令牌是由一组基类型的凸组合构成。这一模型机制通过多头注意力机制生成由基类型界定的区域。这一假设为理解Vison-Transformer模型的表示提供了新的视角。
### Conclusion
通过分析概念的几何特性和统计特性，作者提出了一种新的解释方式：令牌由一组基类型的凸组合构成，这一结构为理解Vision-Transformer模型的表示提供了新的见解。
## 60. `cs.AI` - 使用领域特定工具桥接LLM代理推理-执行差距的自动化Android构建修复 [PDF](https://arxiv.org/pdf/2510.08640), [HTML](https://arxiv.org/abs/2510.08640)
### Authors
Ha Min Son,Huan Ren,Xin Liu,Zhe Zhao
### Background
Android是最大的移动平台，但自动构建应用仍然是一个实际挑战。尽管大型语言模型在代码修复方面显示出潜力，但它们修复Android构建错误的应用仍然没有得到充分探索。
### Innovation
本文首先引入了AndroidBuildBench基准集，包含43个开源Android项目中的1,019个构建失败情况。其次，提出了GradleFixer，这是一种具有领域特定工具的LLM代理，用于检查和操作Gradle构建环境。实验结果显示，GradleFixer的解决率为81.4%，远超依赖通用外壳的先进编程代理。文章提出的工具桥接策略通过提供API格式化的工具和限制相关操作来促进模型的高层次推理与低层次执行之间的桥梁。
### Conclusion
GradleFixer的成功表明，尽管LLM具有解决这些故障的高层次知识，但它们使用通用外壳难以将知识转化为有效的低层次动作。工具桥接策略通过提供对LLM更可信赖的API格式化工具和限制行动空间来有效解决这一问题。
## 61. `cs.AI` - LLMs对软件开发团队协作的影响 [PDF](https://arxiv.org/pdf/2510.08612), [HTML](https://arxiv.org/abs/2510.08612)
### Authors
Devang Dhanuka
### Background
大型语言模型（LLMs）正在逐渐被整合到软件开发流程中，有可能改变团队的工作流程和生产力。本文探讨了LLMs如何影响软件开发生命周期（SDLC）中的团队协作，并重新构思并更新了2025年之前的早期研究，结合了最新的文献和案例研究，概述了SDLC中的协作障碍问题，探讨了LLMs如何提高团队中生产力、沟通和决策能力。通过文献综述、行业示例、团队调查和两个案例研究，评估了LLMs辅助工具（如代码生成助手和AI驱动的项目管理代理）对协作软件工程实践的影响。研究表明，LLMs在自动化重复任务和文档编写以及提高沟通清晰度和跨功能协作方面可以显著提高效率，同时也带来了模型限制和隐私问题等新挑战。
### Innovation
本文对2025年前的早期研究进行了重新构思和更新，结合了最新的文献和案例研究，探讨了LLMs如何影响SDLC中的团队协作。通过文献综述、行业示例、团队调查和两个案例研究，评估了LLMs辅助工具对协作软件工程实践的影响，并提出了未来研究方向，包括针对特定领域的模型定制、开发工具的更好集成以及确保信任和安全的策略。
### Conclusion
研究发现，LLMs在自动化重复任务和文档编写、提高沟通清晰度和促进跨功能协作方面对团队协作有显著的正面影响。然而，也存在模型限制和隐私问题等新挑战。需要进一步研究以确保这些工具的有效性和安全性，并提供针对特定领域的定制解决方案和更好的集成策略。
## 62. `cs.AI` - Hi-OSCAR: 层次开放集分类器在人類活动识别中的应用 [PDF](https://arxiv.org/pdf/2510.08635), [HTML](https://arxiv.org/abs/2510.08635)
### Authors
Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring
### Background
在人类活动识别（HAR）中，日常生活中执行的活动范围远远超过了可用于训练的标注传感器数据集所能捕获的活动范围。未能正确处理未见过的活动会严重影响HAR分类器的可靠性。在HAR领域，不同类别的活动并不是完全不相似，一些类别间存在显著的重叠或包含其它子活动。基于这些观察，作者将活动类别组织成一个结构化的层次体系。在此基础上，作者提出了Hi-OSCAR，一种层次开放集分类器，能够以最先进的精度识别已知活动同时拒识未知活动。这不仅可以实现开放集分类，还能将未知类别定位到最近的内部节点，提供超越二元“已知/未知”分类的洞察。为了促进此项以及未来开放集HAR研究，作者收集了一个新的数据集：NFI_FARED。NFI_FARED包含多个参与者在不同场景下进行的十九种活动的数据，包括日常活动、通勤和快速移动等，该数据集已完全公开并可下载。
### Innovation
提出了Hi-OSCAR，一种层次开放集分类器，在确保以最先进的准确性识别已知活动的同时，能够拒识未知活动。它不仅实现了开放集分类，还能将未知类别定位至最近的内部节点，提供超出二元“已知/未知”分类的洞察。此外，作者还收集了一个名为NFI_FARED的新数据集，涵盖了多种情境下的多种活动，是公开可用的数据集。
### Conclusion
通过提出Hi-OSCAR层次开放集分类器，作者不仅解决了传统HAR模型无法处理未知活动的问题，还提供了对未知活动类进行分类的新方法，使研究更加全面和深入。NFI_FARED数据集的发布也为未来的HAR研究提供了宝贵的资源。
## 63. `cs.AI` - 基于能量驱动导向：减少大型语言模型中的拒绝响应 [PDF](https://arxiv.org/pdf/2510.08646), [HTML](https://arxiv.org/abs/2510.08646)
### Authors
Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li
### Background
大型语言模型的安全对齐面临一个关键挑战：当前的安全对齐技术往往只专注于提高对有害提示的安全性，导致模型变得过于谨慎，拒绝回应非有害提示。因此，安全对齐的一个关键目标是增强安全性的同时减少不必要的拒绝响应。现有的方法大多集中在对模型进行微调，这不仅耗时，还可能改变模型原有的知识结构。本文讨论了一个新的解决方案来解决这个问题。
### Innovation
本文提出了一种新颖的能量驱动转换（EDS）框架，该框架不需要对模型进行微调即可解决上述问题。该方法通过在推理阶段动态干预，让一个轻量级的外部能量函数模型（EBM）将大语言模型的内部激活转换为“能量景观”。通过能量函数的梯度动态引导大语言模型的隐藏状态进入低能量区域，实现实时生成期望响应，而无需修改模型的权重。这种方法分离了行为控制和模型的核心知识，提供了一个灵活且计算效率高的解决方案。实验表明，该方法显著降低了不必要的拒绝响应率，例如在ORB-H基准测试上提高合规性至82.6%，同时保持原有的安全性能。
### Conclusion
本文提出的方法为构建同时具备低不必要的拒绝响应率和高安全性的大型语言模型提供了有效框架，展示了这种新的能量驱动导向方法的实际效果。
## 64. `cs.AI` - 前沿Chain-of-Thought：一种协作的Chain-of-Thought压缩框架 [PDF](https://arxiv.org/pdf/2510.08647), [HTML](https://arxiv.org/abs/2510.08647)
### Authors
Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen
### Background
最近的发展使得大型语言模型（LLMs）可以通过长Chain-of-Thought（CoT）实现高级推理，但CoT长会导致较高的计算成本和显著的延迟损失，这是由于生成型LLMs的自回归性质。CoT压缩旨在通过减少输出长度来提高推理过程的效率。之前的策略要么通过繁琐的离散提示设计，要么通过构建包含关键推理细节的外部压缩CoT数据集，牺牲了推理效率。
### Innovation
本文提出了一种高效的推理框架——前沿CoT（UCoT），该框架预先通过小型模（压缩器）生成富含推理信息的思想嵌入，从而避免了手动设计提示的缺点。UCoT的第二阶段优化执行器以利用预先生成的思想嵌入进行短推理以得出正确答案，采用奖励机制。实验结果表明，UCoT保持了执行者的强大推理能力，同时显著减少了CoT的输出长度。特别是在应用到Qwen2.5-7B-Instruct模型时，使用UCoT在GSM8K数据集上的令牌使用率降低了50%，性能提升了3.08%，优于最先进的方法。
### Conclusion
本文提出的UCoT通过预先生成的思想嵌入，优化了一个合作流程中的执行器，显著提高了大型语言模型的推理效率，而不会牺牲推理效果。
## 65. `cs.AI` - 从‘What’到‘Why’: 小型语言模型驱动的知识空间推荐 [PDF](https://arxiv.org/pdf/2510.08626), [HTML](https://arxiv.org/abs/2510.08626)
### Authors
Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar
### Background
大规模语言模型（LLMs）通过增强的推理提高了推荐能力，但其高昂的推理成本使得实际部署成为一项挑战。相比之下，小型语言模型（SLMs）虽然在效率上更为优越，但在推荐中的推理能力尚未得到充分探索。现有的系统多采用自然语言理由作为非监督的描述性文本，未能充分发挥其作为学习信号的潜力。在这种情况下，本文提出了PULSE框架，通过将小型语言模型生成的理由作为关键学习信号，并结合交互历史数据来共同建模用户的动作和其语义驱动因素，从而创建一个跨领域的知识空间，提高了模型的鲁棒性和泛化能力。
### Innovation
PULSE框架通过将小型语言模型生成的理由作为关键学习信号，并结合交互历史数据来共同建模用户的动作和其语义驱动因素，显著提高了推理能力，并且其新颖的设计使得生成的嵌入更具鲁棒性和通用性。PULSE在多个基准数据集上优于现有的ID、协同过滤（CF）和基于LLM的序列推荐模型，并且在跨领域推荐和下游任务（如基于推理的问题回答）中表现出强大的性能。
### Conclusion
广泛的实验表明，PULSE在多个基准数据集上的推荐性能超过了现有的ID、协同过滤（CF）和基于LLM的序列推荐模型。该框架还展示了在跨领域推荐和下游任务中的优越转移性能。
## 66. `cs.AI` - 无逆的威尔逊环路用于变换器：一个实用的不变性和顺序敏感性诊断工具 [PDF](https://arxiv.org/pdf/2510.08648), [HTML](https://arxiv.org/abs/2510.08648)
### Authors
Edward Y. Chang,Ethan Y. Chang
### Background
大型语言模型在进行细微但有意义的编辑后会更改答案。这些细微的更改会破坏预训练中学习到的不变性，并影响系统的集成。团队在修复这些错误时需要权衡安全性与速度，且修正过程耗时且成本高昂。尽管已有一些方法可以检测这些错误，但它们通常过于复杂或依赖于特定的模型，这限制了它们的普遍适用性。本研究旨在提供一种简单且通用的诊断套件，以应对这些挑战。
### Innovation
本研究提出了WILSON，一种小巧的后插诊断套件，通过内部表示的简单循环和重排序检查将系统信号转化为信号。WILSON结合了基于JVPs和Hutchinson探针的位置和层的无逆曲率图，以及标识重排序风险的激活层次通量计数器。这些信号的计算成本低廉，模型普遍适用于标准变换器，并导出为阈值和CSV文件供协调者使用。这一方法能有效防止RAG受到顺序效应的影响，捕捉微调回退，稳定辩论路径和长多轮对话的连续性，并在部署中阻止融合或重排序操作。
### Conclusion
WILSON能够预判潜在的故障，并批准安全的优化，从而在不改变模型架构或训练的情况下同时提高可靠性和吞吐量。
## 67. `cs.AI` - 在个人叙述中形式化风格 [PDF](https://arxiv.org/pdf/2510.08649), [HTML](https://arxiv.org/abs/2510.08649)
### Authors
Gustave Cortal(ENS Paris Saclay, LISN),Alain Finkel(ENS Paris Saclay)
### Background
个人叙述是作者构建的故事，用以赋予他们的经历意义。风格，作者使用语言表达自我特有的方式，是这些叙述传达主观体验的关键。然而，缺乏一种形式化的框架来系统分析这些风格选择。
### Innovation
本文提出了一种新颖的方法，将个人叙述中的风格形式化为作者在传达主观体验时所做语言选择的模式。这种方法结合了三个领域：功能语言学作为语言是一个具有意义选择系统的基础，计算机科学为自动提取和分析序列模式提供了方法，以及这些模式与心理学观察的联系。使用语言模型，本文自动提取了诸如过程、参与者和情境等语言特征。
### Conclusion
文章将这一框架应用到数百个梦的叙述中，并通过一个战争退伍军人（患有创伤后应激障碍）的案例研究，分析了其叙述中的独特模式，特别是如何口头过程在心理过程中占据主导地位，展示了语言选择与心理状态之间的关系。
## 68. `cs.AI` - MMA-ASIA: 一种用于文化背景评估的多语言和多模态对齐框架 [PDF](https://arxiv.org/pdf/2510.08608), [HTML](https://arxiv.org/abs/2510.08608)
### Authors
Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen
### Background
大型语言模型（LLMs）在全球范围内广泛使用，但在非西方、资源较少的地区，它们的多模态理解和推理能力常常下降。本研究旨在评估LLMs对亚洲文化的意识，特别是针对亚洲上下文的全面框架。为此，研究者开发了一套参考标准，涵盖来自8个亚洲国家的10种语言，包含27,000个问题，其中超过79%的问题需要基于文化背景的多步推理，这超越了简单的记忆能力。这是首个在三个模态（文本、图像和语音）输入层面进行对齐的数据集，支持跨模态迁移的直接测试。该框架旨在评估国家之间文化意识的差异、跨语言一致性、跨模态一致性、文化传播的一般性以及模型支持信息定位的有效性。此外，文化意识定位验证模块用于检测是否采用了捷径学习，确认模型答案是否基于必需的文化知识。比较模型分析、注意力追踪和创新的视图删除前缀回放（VPR）方法揭示了模型在不同语言和模态上的分歧原因，为构建文化可靠多模态LLMs提供实际建议。
### Innovation
研究提出了一种全新的跨模态基准数据集和评估框架MMA-ASIA，该数据集和框架致力于评估LLMs对亚洲文化背景的了解，特别关注文化相关的多步推理和知识应用。这是首次将多模态数据在输入层面对齐到三个模态（文本、图像和语音），以直接测试跨模态迁移。评估框架涵盖了五类关键维度：国家间文化意识差异、跨语言一致性、跨模态一致性、文化传播的一般性以及模型支撑验证的有效性。创新的方法包括文化意识定位验证模块和其他用于诊断模型性能和揭示其内部运作机制的工具，如视图删除前缀回放（VPR）方法。这些工具有助于深入理解模型的决策过程，为进一步改进LLMs提供指南。
### Conclusion
本研究通过构建多语言和多模态对齐的数据集MMA-ASIA，提出了评估LLMs文化意识的框架，该框架包括多维度评估指标和创新的技术工具。实验结果显示，尽管LLMs在这类任务上表现欠佳，但新方法和框架能够揭示并解释模型在不同语言和模态上的表现差异，为构建文化可靠且多模态的LLMs提供了有价值的见解。创新方法和框架有助于推动LLMs的跨文化和跨模态理解的进一步研究和发展。
## 69. `cs.AI` - 从多模态到参数化原素的3D生成框架 [PDF](https://arxiv.org/pdf/2510.08656), [HTML](https://arxiv.org/abs/2510.08656)
### Authors
Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan
### Background
近年来，AI驱动的3D模型生成在多模态领域取得了进展，但生成具有平滑表面且降低存储开销的模型仍面临挑战。
### Innovation
提出了一种多阶段框架，用于生成由参数化原素组成的3D模型，并通过文本和图像输入进行指导。此框架包括基于参数化原素的模型生成算法，能识别模型组成部分的形状特征，用高保真表面的参数化原素替换这些部分。此外，还提出了一种相应的模型存储方法，确保模型的原始表面质量，同时仅保留参数化原素的参数。
### Conclusion
在虚拟场景数据集和实际场景数据集上进行的实验表明，该方法的准确性较高，实现的点到点距离为0.003092，VIoU为0.545，F1分数为0.9139，NC为0.8369，参数化原素参数文件大小约为6KB。该方法特别适用于简单模型的快速原型设计。
## 70. `cs.AI` - 基于知识图谱稀疏化的GNN稀有遗传病诊断 [PDF](https://arxiv.org/pdf/2510.08655), [HTML](https://arxiv.org/abs/2510.08655)
### Authors
Premt Cara,Kamilia Zaripova,David Bani-Harouni,Nassir Navab,Azade Farshad
### Background
稀有遗传病的诊断面临关键挑战，包括患者数据不足、全基因组测序难以获取以及潜在致病基因的庞大数量。这些限制导致了诊断时间延长、不当治疗和关键延误。在资源受限的地区，诊断工具的缺乏使得情况更为严峻。
### Innovation
提出了基于子图的图神经网络RareNet，仅需患者表型数据即可识别最有可能的致病基因，并检索专注于临床研究的患者子图。RareNet 可作为独立方法或与其他候选基因优先级方法的预处理或后处理过滤器，提升其性能，提供可解释的洞察。通过在两个生物医学数据集上的全面评估，证明了其在因果基因预测上的竞争力和鲁棒性，集成到其他框架时性能显著提高。仅需任何临床环境下的表型数据，RareNet 使复杂的遗传分析民主化，特别为缺乏高级基因组基础设施的弱势群体提供了巨大价值。
### Conclusion
RareNet 在稀有遗传病诊断中的应用展示了其在精度和鲁棒性上的优势，通过对表型数据的利用，减少了对基因组测序的依赖，从而降低了诊断成本和时间，提高了诊断效率，且能够为临床研究提供有价值的解释性洞见。
## 71. `cs.AI` - 内在实例归一化方法用于时间序列预测 [PDF](https://arxiv.org/pdf/2510.08657), [HTML](https://arxiv.org/abs/2510.08657)
### Authors
Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen
### Background
时间序列受多种因素影响，表现出复杂的非平稳特性。非平稳性会导致数据分布的变化，即统计特性随时间改变，这会负面影响模型性能。已有的一些实例归一化方法试图解决时间序列预测中的分布转移问题，但这些方法未能考虑到单个实例内部的变化，从而导致性能不足。为了解决这一问题，研究提出了一种新的内在实例水平的方法：学习分布（LD）和学习条件分布（LCD）。这些方法能够通过适应性地调整参数来消除不同时间点上的内部分布差异，并利用神经网络预测输出的缩放系数，从而有效捕捉数据分布的变化。
### Innovation
该研究提出了两种新的点级别的内在实例归一化方法：学习分布（LD）和学习条件分布（LCD），旨在有效解决单个实例内部的分布转移问题。LD方法通过不同的参数在不同时间步预测输入和输出的内部分布差异，而LCD则利用神经网络来预测输出的缩放系数。
### Conclusion
通过在多个公开基准模型上评估这两种方法，并通过对比实验验证了点级别归一化方法的有效性。实验结果表明，这提出的方法能够有效应对内在实例水平上的分布转移，从而改善时间序列预测模型的性能。
## 72. `cs.AI` - CATS-Linear: 分类辅助线性模型在时间序列预测中的应用 [PDF](https://arxiv.org/pdf/2510.08661), [HTML](https://arxiv.org/abs/2510.08661)
### Authors
Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen
### Background
近期研究显示，线性模型在预测性能上能与复杂架构媲美，然而提升线性模型的方法依然相对缺乏。鉴于不同时间序列实例可能遵循不同的线性映射，本文提出了一种名为分类辅助趋势季节性分解线性模型(CATS-Linear)的方法，利用分类辅助通道独立度(CACI)来动态路由实例至专门的预测器，实现监督通道设计，并进一步分析了不同通道设置的理论期望风险。此外，通过将趋势成分的分解架构与解耦、线性映射和重建框架相结合，以及将季节成分的分解架构设为复数域线性投影，重新设计了趋势和季节成分的分解架构.
### Innovation
本文提出了CATS-Linear模型，利用分类辅助通道独立度实现动态路由实例至专门的预测器，理论分析了不同通道设置的风险，重新设计了趋势和季节成分的分解架构，从而提升了线性模型的预测性能，并验证了即使在固定超参数的情况下也能达到与超参数调整基线相当甚至更好的准确率
### Conclusion
CATS-Linear模型在固定超参数的情况下达到了与超参数调整基线相当的准确率，而对抗比超参数固定的基线性能更优秀。
## 73. `cs.AI` - 语言赋能基础模型的证明鲁棒适应 [PDF](https://arxiv.org/pdf/2510.08659), [HTML](https://arxiv.org/abs/2510.08659)
### Authors
Yuni Lai,Xiaoyu Xue,Linghui Shen,Yulun Wu,Gaolei Li,Song Guo,Kai Zhou,Bin Xiao
### Background
语言赋能基础模型（LeFMs）如CLIP和GraphCLIP，通过将视觉（或图）特征与文本表示对齐，极大地推动了多模态学习。这些模型在少量示例学习中展现出强大的能力。然而，LeFMs依赖于开放环境中收集的小且任务特定的支持数据集，使其容易受到威胁者操控支持样本导致性能下降的反向工程技术。现有防御措施依赖于经验策略，缺乏正式保证，对未预见和适应性强的攻击仍不够稳固。有向量证明的鲁棒性已被广泛用于基于LeFMs的少样本分类器的探索不足。
### Innovation
本文提出了首个为LeFMs设计的证明鲁棒性的少样本分类器——LeFCert。该模型结合了文本和特征嵌入，并采用自适应混合机制。通过提出两层修剪平均原型，并推导出分类分数的可证明上界和下界，LeFCert能够在最坏场景下提供证明鲁棒性认证。此外，LeFCert还提供了两种改进版本：LeFCert-L通过随机化平滑提供Lipschitz连续性，适用于双重预算约束条件下的鲁棒性认证；LeFCert-C提供集体认证，适用于攻击者将共用中毒预算分配给多个样本的情况。实验表明，LeFCert在清洁准确性和认证准确性方面都优于现有基线，显示了其卓越的性能。
### Conclusion
LeFCert展示了最先进的鲁棒性机制，并且在计算效率方面具有优势，使其成为实际应用中的理想选择。
## 74. `cs.AI` - 利用LLM评分文本数据增强评分量表测试的新框架 [PDF](https://arxiv.org/pdf/2510.08663), [HTML](https://arxiv.org/abs/2510.08663)
### Authors
Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell
### Background
心理评估通常依赖于结构化的评级量表，但这些量表无法充分捕捉回应者自然语言中的丰富细微差别。为解决这一问题，该研究利用了前沿的人工智能技术——大规模语言模型（LLMs），通过结合LLMs评分的文本数据和传统的评级量表项目，创建了一种增强测试。研究者以抑郁症为例，使用了来自正规教育阶段后期学生的实际数据（n=693）和相应的合成数据集（n=3,000）进行框架的开发与评估。结果显示，在验证数据集中，增强测试在测量精度和准确性方面取得了统计学意义上的显著改善。
### Innovation
该研究创新性地提出了一种利用大规模语言模型（LLMs）评分文本数据来增强传统量表测试的新框架。这种方法通过计算项目信息量来实证性地选定最具有信息量的LLM评分指示符，从而超越了以前依赖预标记数据或复杂专家制定评分标准的方法，提供了一种可应用于实际的心理评估的新途径。
### Conclusion
该框架为利用不断增长的转录文本来增强传统心理测量方法提供了一个可扩展的解决方案。研究者讨论了该方法在临床健康和其他领域的潜在应用价值。整体而言，这种方法代表了自动化评分领域的一个概念性转变。
## 75. `cs.AI` - RA-Gen: 使用ReAct进行多智能体任务执行的可控制代码生成框架 [PDF](https://arxiv.org/pdf/2510.08665), [HTML](https://arxiv.org/abs/2510.08665)
### Authors
Aofan Liu,Haoxuan Li,Bin Wang,Ao Yang,Hui Li
### Background
基于大型语言模型（LLMs）的代码生成模型已广泛应用，但在确保安全性、准确性和可控性方面仍面临挑战，特别是在复杂任务中。现有的方法往往缺乏对外部工具的动态集成、透明推理以及用户对安全性的控制。
### Innovation
提出了一种基于ReAct范式的可控制代码生成框架，旨在通过LLMs和外部资源的动态交互来实现高效、精确和可解释的代码生成。该框架采用了一个由四个专门智能体构成的协作架构：分解任务的Planner、利用ReAct框架进行推理和工具集成的Searcher、生成准确代码的CodeGen智能体以及检索结构化数据的Extractor。
### Conclusion
实验结果显示，该框架在多种语言中均有效，并在CodeQL上实现了94.8%的高安全率，优于现有方法。透明的推理过程有助于增强用户信任并提高可控性。
## 76. `cs.AI` - Faver: 通过函数抽象验证中间件提升基于LLM的RTL生成 [PDF](https://arxiv.org/pdf/2510.08664), [HTML](https://arxiv.org/abs/2510.08664)
### Authors
Jianan Mu,Mingyu Shi,Yining Wang,Tianmeng Yang,Bin Sun,Xing Hu,Jing Ye,Huawei Li
### Background
基于LLM的RTL生成是一个有潜力的研究方向，能解放芯片设计中最不自动化的阶段。但高阶规格与RTL之间的语义差距，以及有限的训练数据，导致现有模型在生成准确性上存在不足。借鉴人类经验，设计验证能提高准确性，但RTL测试台数据更加稀缺，这不利于LLM。虽然LLM在高级语言如Python/C中表现出色，但在RTL上存在巨大的语义差距。实现相同功能时，Python/C代码和硬件代码在空间时间粒度上有显著差异，要求LLM不仅要考虑高层功能语义，还要确保低级别细节与电路代码一致，这对LLM来说是一项艰巨的任务。
### Innovation
本文提出了一种函数抽象验证中间件（Faver），它通过混合LLM友好的代码结构和基于规则的模板，解耦电路验证的细节，使LLM能够专注于功能本身。实验表明，在SFT模型和开源模型上，Faver能够提高模型生成准确性高达14%。
### Conclusion
Faver通过解耦电路验证细节，提升了基于LLM的RTL生成准确性。
## 77. `cs.AI` - DPCformer：作物基因组预测的可解释深度学习模型 [PDF](https://arxiv.org/pdf/2510.08662), [HTML](https://arxiv.org/abs/2510.08662)
### Authors
Pengcheng Deng,Kening Liu,Mengxi Zhou,Mingxi Li,Rui Yang,Chuzhe Cao,Maojun Wang,Zeyu Zhang
### Background
传统全基因组选择（Genomic Selection, GS）方法在预测复杂性状和处理大数据集时存在预测准确度较低的问题。本文旨在解决这一问题，提出了一种名为DPCformer的新方法，该方法结合了卷积神经网络和自我注意力机制，以更好地建模基因型-表型关系。DPCformer被应用于五种作物：玉米、棉、番茄、稻米和鹰嘴豆。该方法使用了8维的一热（one-hot）编码来表示单核苷酸多态性（SNP）数据，并按染色体排序，同时使用PMF算法进行特征选择。实验结果显示DPCformer在预测性能上优于现有方法，特别是在小样本数据集上表现出色，并且具有更好的可解释性。这些发现为精准育种和解决全球粮食安全挑战提供了一个强有力的工具。
### Innovation
本文提出了DPCformer，这是一种结合了卷积神经网络和自我注意力机制的深度学习模型，用于基因组预测。DPCformer能够提高复杂性状的预测精度，并在小样本数据集上表现出色。该模型还提高了模型的可解释性，有助于更好地理解基因型-表型关系。
### Conclusion
研究结果表明，DPCformer相较于现有的基因组预测方法，具有更高的准确性和更好的鲁棒性，在小样本情况下的表现尤为突出，且增强了模型的可解释性。DPCformer提供了一种强大的工具，可用于精准育种及解决全球粮食安全问题。
## 78. `cs.AI` - dInfer：一种高效的扩散语言模型推理框架 [PDF](https://arxiv.org/pdf/2510.08666), [HTML](https://arxiv.org/abs/2510.08666)
### Authors
Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng
### Background
扩散型大语言模型（dLLMs）作为一种有前景的替代自回归（AR）语言模型的方案，利用去噪生成的方式来实现固有的并行处理能力。尽管越来越多的扩散型语言模型开源，但由于没有标准化且高效的推理框架，其广泛应用受到了限制。因此，该领域亟需开发一个能够高效、可扩展，并且针对新型算法和系统级优化进行设计的推理框架。
### Innovation
dInfer框架将推理管线分解为四个模块化的组件：模型、扩散迭代管理器、解码策略和KV缓存管理器，并为每个组件整合了新颖的算法以及系统层面的优化。通过这种方法，dInfer在保持LLaDA-MoE输出质量的情况下实现了显著的效率提升。例如，在批处理大小为1的情况下，dInfer在HumanEval上的表现超过每秒1100个令牌，在六个项目基准测试中，每8块H800 GPU平均每秒超过800个令牌。dInfer的效率比Fast-dLLM提高了10倍，尽管在模型性能方面相当，但dInfer在与AR模型（如配备了最新vLLM推理引擎的QWen2.5-3B）相比时仍能提供2-3倍的加速。
### Conclusion
dInfer是为扩散型语言模型推理特别设计的高效且可扩展的框架。它通过算法创新和系统提升实现了显著的性能提升。dInfer 的实现已经被开源，可以被广泛使用和进一步研究。
## 79. `cs.AI` - RAG4Tickets：通过JIRA和GitHub数据增强检索生成实现AI驱动的工单解决 [PDF](https://arxiv.org/pdf/2510.08667), [HTML](https://arxiv.org/abs/2510.08667)
### Authors
Mohammad Baqar
### Background
现代软件团队在解决重复或相关的问题时，会遇到由于知识碎片化散落在JIRA票项、开发人员讨论和GitHub合并请求（PRs）中而引起的延迟。团队成员需要花费大量时间回顾和整合这些信息，才能找到解决问题所需的上下文，这严重影响了工作效率。
### Innovation
本文提出了一种检索增强生成（RAG）框架，该框架结合了Sentence-Transformers的语义嵌入和基于FAISS的向量搜索，以提供面向上下文的票项解决建议。该方法将历史JIRA票项、用户评论和链接的PR元数据嵌入，检索出语义相似的过去案例，然后由大规模语言模型（LLM）综合生成具体的、可解释的解决方案建议。该框架提供了一个将JIRA和GitHub数据关联起来的统一管道，一种针对异质软件资源的嵌入和FAISS索引策略，以及一个基于检索证据引导的解决方案生成模块。
### Conclusion
实验评估表明，该系统在精度、召回率、解决时间减少以及开发者接受度方面表现出色，显著提升了问题解决的准确性和修复质量，提高了现代 DevOps 环境下的知识重用。
## 80. `cs.AI` - FreqCa: 通过频率感知缓存加速扩散模型 [PDF](https://arxiv.org/pdf/2510.08669), [HTML](https://arxiv.org/abs/2510.08669)
### Authors
Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang
### Background
扩散变换器的应用面临着显著的推理成本问题。为了解决这一问题，日前提出了一种特征缓存方法，该方法通过重复使用前一时间步的特征来跳过未来时间步的计算。然而，之前的特征缓存假设相邻时间步的特征是相似或连续的，但这并非在所有情况下都成立。该研究从频域进行了分析，揭示了扩散模型中不同频率带的特征在时间步长上表现出不同的动态特性。低频分量决定了图像的结构，它们相似但连续性差；高频分量解码图像的细节，它们连续性好但相似性差。
### Innovation
该研究提出了频率感知缓存（FreqCa），直接重复利用根据相似性低频分量的特征，同时采用二阶海明插值预测高频分量。此外，还提出了缓存累计残差特征（CRF），这减少了特征缓存的内存占用99%。
### Conclusion
在FLUX.1-dev、FLUX.1-Kontext-dev、Qwen-Image和Qwen-Image-Edit上的广泛实验验证了该方法在生成和编辑方面的有效性。代码可参见补充材料，并将在GitHub上发布。
## 81. `cs.AI` - 使用语义配对增强自我监督学习: 新数据集和实证研究 [PDF](https://arxiv.org/pdf/2510.08722), [HTML](https://arxiv.org/abs/2510.08722)
### Authors
Mohammad Alkhalefi,Georgios Leontidis,Mingjun Zhong
### Background
实例区分是自我监督表示学习的一种范式，其中数据集中的每个实例被视为不同的类别。通过应用随机变换生成每实例的不同时空视图，来实现这种范式，这促使模型学习在这些视图下对共通基础对象不变的表示形式。
### Innovation
该研究提出了一种使用语义配对的新方法，通过引入这种配对增强自我监督学习的效果，并提供了一个新的数据集和实证研究，验证了新方法的有效性。
### Conclusion
研究证明了通过语义配对可以有效提高自我监督学习的效果，并通过实验证明了一个新的数据集的有效性和新方法的实用性。
## 82. `cs.AI` - ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing [PDF](https://arxiv.org/pdf/2510.08705), [HTML](https://arxiv.org/abs/2510.08705)
### Authors
Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser
### Background
在拥挤环境中进行物体运输是多个领域的基本任务，包括家庭服务和仓库物流。合式物体搬运中，多台机器人需协同搬运超出单个机器人承载能力的大型物体。推拉策略是一个可行方案，只需简单的机器人，但选择接触点以沿预定路径推动物体需要谨慎考虑。尽管这可以通过解析方法解决，但随着机器人数量和物体尺寸的增加，解空间呈组合式增长，限制了方法的可扩展性。
### Innovation
受人类利用常识进行合作搬运的启发，我们提出结合大型语言模型（LLM）的推理能力和局部搜索来选择合适的接触点。我们提出的方法，ConPoSe，能够成功选择各种形状（例如立方体、圆柱体和T形）的接触点。实践证明，ConPoSe在处理机器人数量和物体尺寸时比解析方法更具可扩展性，同时在纯基于LLM的选择中表现更优。
### Conclusion
ConPoSe结合了LLM的推理能力和局部搜索，能够更有效地选择接触点，具有更好的可扩展性，适用于不同形状的物体，并且在处理数量和尺寸方面优于传统方法。
## 83. `cs.AI` - 基于上下文的坐标：使用LLMs定位复杂位置参考 [PDF](https://arxiv.org/pdf/2510.08741), [HTML](https://arxiv.org/abs/2510.08741)
### Authors
Tessa Masis,Brendan O'Connor
### Background
地理编码是将位置参考与实际地理坐标关联的任务，对于对非结构化文本进行许多下游分析至关重要。本文研究了地理编码组成位置参考这一具有挑战性的设置。基于最近研究证明的LLMs处理地理空间数据的能力，本研究评估了LLMs在我们的任务相关的地理知识与推理技能。
### Innovation
本文提出了一种基于LLM的策略，用于地理编码组成位置参考。研究表明，该方法在任务上提高了性能，并且一个较小的微调LLM可以在性能上与较大且现成的模型相匹敌。
### Conclusion
研究证明了LLMs在处理复杂位置参考地理编码任务上的潜力，并提供了一种相对高效的方法来处理此类任务。
## 84. `cs.AI` - 何时推理：针对vLLM的语义路由器 [PDF](https://arxiv.org/pdf/2510.08731), [HTML](https://arxiv.org/abs/2510.08731)
### Authors
Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen
### Background
大型语言模型（LLMs）在加入推理模式如链式思考和推理时可以显著提高准确性，但同时也会带来推理延迟和token使用量的增加，这些对于许多简单的提示而言是不必要的。这些额外的推理不仅消耗资源，还带来了环境和经济上的影响。
### Innovation
本文提出了一种语义路由器，该路由器能够根据查询的推理需求对其进行分类，并在必要时才进行推理，从而在保持准确性的前提下减少了响应延迟和token消耗。相较于直接使用vLLM进行推断，该语义路由实现了在MMLU-Pro基准测试上准确率提高10.2个百分点，响应延迟降低了47.1%，token消耗减少了48.5%。
### Conclusion
语义路由提供了一种有效机制，能够在开源LLM服务系统中权衡准确性和效率。
## 85. `cs.AI` - BigCodeArena: 通过执行揭示更可靠的代码生成人工偏好 [PDF](https://arxiv.org/pdf/2510.08697), [HTML](https://arxiv.org/abs/2510.08697)
### Authors
Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra
### Background
在聊天机器人领域，实时从人类视角评估模型响应质量是可行的。然而，在代码生成领域，手动检查大型语言模型（LLM）生成的内容质量极具挑战性，因为这需要详细理解大量源代码并模拟代码执行。针对这一问题，需要一个既能提供实时执行环境又能让人类与之互动的人工评估平台，以便全面检验代码生成的能力和质量。 
### Innovation
引入了BigCodeArena，这是一个基于Chatbot Arena构建的开源代码生成人工评估平台，具备即时执行环境。BigCodeArena能够执行由LLM生成的代码，并允许人类与执行过程及结果交互。此外，该平台还收集了来自10种流行LLM的14,000多个以代码为中心的对话会话，这些LLM涵盖了10种编程语言和8种执行环境。这些对话中，研究人员还筛选出超过4,700个双人偏好样本，揭示了LLM在任务、语言和框架中的细粒度偏好。基于以上数据，该项目还构建了两个基准测试，BigCodeReward和AutoCodeArena。前者通过优化4,700个对话数据，评估奖励模型与人类偏好的一致性；后者是一种自动化的Elo评级基准，无需人类参与即可评估LLM的代码质量。研究表明，现有的自有品牌LLM在代码生成性能上仍领先于新兴的其他模型。 
### Conclusion
BigCodeArena通过执行环境更好地揭示了LLM生成代码时的人工偏好，并建立了两个基准测试来系统地评估LLM的代码理解和生成能力。同时，研究发现尽管一些新技术模型不断涌现，但自有产权的LLM（如GPT-5，Claude-Sonnet-4和Claude-Opus-4）在代码生成方面的表现仍然是最好的。
## 86. `cs.AI` - 非稳态MIMO均衡的在上下文学习 [PDF](https://arxiv.org/pdf/2510.08711), [HTML](https://arxiv.org/abs/2510.08711)
### Authors
Jiachen Jiang,Zhen Qin,Zhihui Zhu
### Background
信道均衡是减轻频率选择性衰落和符号间干扰等失真的基础。与需要重新训练或微调的传统监督学习方法不同，在上下文学习（ICL）能够在推理时仅通过少量示例对新信道进行适应。然而，现有的ICL均衡器主要针对在上下文窗口内的静态信道进行了开发和评估。目前的研究主要集中在信道不变化的场景下，考虑信道均衡问题的ICL研究仅限于静态设定。因此，本文探讨了ICL在非静态（时间变化）信道均衡问题的应用潜力。我们通过引入合适的注意机制和算法设计来增强非静态任务下的适应性，从而扩展了ICL的应用范围。
### Innovation
本文提出了一种新的框架来设计高效的注意力机制，利用自适应信号处理算法进行引导设计，提出了基于LMS算法的新注意变体、增强鲁棒性的LRMS公式和用于改进长期跟踪的多步梯度更新等方法。这些方法能够在动态环境中增强ICL的适应性和性能。实验结果表明ICL在非静态MIMO均衡中有很好的应用前景，并且受到经典自适应算法启发的注意力机制能够显著提升在动态环境中的适应性和性能。本研究为发展具有更强适应性和鲁棒性的下一代无线基础模型提供了关键见解。
### Conclusion
我们的研究结果表明ICL在非静态MIMO均衡场景中具有很大的潜力，并能够通过引入一种新的机制，提升在动态环境中的适应性和性能。今后的工作可以进一步研究如何更好地将这些机制应用于实际无线通信系统中。
## 87. `cs.AI` - 图扩散变换器是场景驱动的分子设计师 [PDF](https://arxiv.org/pdf/2510.08744), [HTML](https://arxiv.org/abs/2510.08744)
### Authors
Gang Liu,Jie Chen,Yihan Zhu,Michael Sun,Tengfei Luo,Nitesh V Chawla,Meng Jiang
### Background
上下文学习允许大型模型从少量演示中适应新任务，但在分子设计中的应用有限。现有的数据库如ChEMBL包含跨越数百万生物测试的分子属性，但是每个属性的标注数据仍然稀缺。面对这一局限，本文介绍了基于演示条件的扩散模型(DemoDiff)，它通过一小批分子属性示例定义任务场景，而不是使用文本描述。此外，为了实现大规模预训练，开发了一种新的分子分词器，采用节点对编码来表示分子，仅需5.5倍更少的节点。研究人员构建了一个含有来自多个来源数百万个上下文任务的数据集，涵盖药物和材料，并在其中训练了一个含有0.7亿参数的模型。
### Innovation
提出了基于演示条件的扩散模型(DemoDiff)，使用分子属性示例而不是文本描述定义任务场景，指导去噪变换器生成符合目标属性的分子。开发了一种新的分子分词器，采用节点对编码，使模型构建更加高效。构建了一个含有数百万个上下文任务的数据集，并在其中训练了一个含有0.7亿参数的模型。
### Conclusion
在33项设计任务中，DemoDiff的表现与100-1000倍更大的语言模型相当，且平均排名为3.63，而特定领域的模型则在5.25到10.20之间。这些结果将DemoDiff定位为一种分子基础模型，用于上下文驱动的分子设计。
## 88. `cs.AI` - SAFER-AiD: Saccade-Assisted Foveal-Peripheral Vision Enhanced Reconstruction for Adversarial Defense [PDF](https://arxiv.org/pdf/2510.08761), [HTML](https://arxiv.org/abs/2510.08761)
### Authors
Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu
### Background
 adversarial attacks significantly challenge the deployability of deep learning models in real-world applications. Traditional defenses, such as adversarial training or data augmentation, are often computationally intensive and do not fully replicate the inherent robustness of the human visual system to adversarial perturbations.
### Innovation
提出了一个结合了三点生物机制（中心-外周处理、扫视眼动和皮层填充）的新颖防御框架SAFER-AiD。该框架使用强化学习引导的扫视动作，选择性地捕获多个中心-外周视图，然后在分类之前将这些视图融合到一个重建图像中。这种方法受到生物启发的预处理有效减轻了对抗性噪声，同时保持了语义完整性，并且不需要重新训练或微调下游分类器，使得与现有系统无缝集成。
### Conclusion
在ImageNet数据集上的实验表明，本方法在多种分类器和攻击类型下均能提高系统的鲁棒性，同时与生物和非生物启发的防护技术相比，显著降低了训练开销。
## 89. `cs.AI` - 使用AI自动视频关键帧提取识别kea [PDF](https://arxiv.org/pdf/2510.08775), [HTML](https://arxiv.org/abs/2510.08775)
### Authors
Paula Maddigan,Andrew Lensen,Rachael C. Shaw
### Background
准确识别和重新识别个体动物是野生动物种群监测成功的关键。传统方法，如鸟类的脚环标记，耗时且具有侵入性。近年来，人工智能的进步，尤其是计算机视觉技术，提供了智能保护和高效自动化的有希望的解决方案。研究从新西兰森林栖息的kea（Nestor meridionalis）视频中提取高质量的关键帧，这是一种受威胁的鹦鹉。虽然关键帧提取在人员重新识别中已有研究，但在野生动物领域应用有限。通过使用定制鸟食站的视频记录，研究提取关键帧并对管道的重新识别性能进行了评估。
### Innovation
该研究提出了一个独特的管道，结合了YOLO和Grounding DINO的目标检测，光流模糊检测，DINOv2的图像编码，以及聚类方法来选择代表性的关键帧。这种方法提供了非侵入性和高效的方法，用于识别kea个体，是一种传统物理标记方法的有价值的替代方案，从而提高了种群监测的效果。
### Conclusion
研究为使用收集于更多多样和具有挑战性环境的媒体进行了进一步的研究提供了基础，为野生动物监测提供了新的方法，具有生态学和保护生物学的应用价值。
## 90. `cs.AI` - 测量多语言能力下道德LLM响应 [PDF](https://arxiv.org/pdf/2510.08776), [HTML](https://arxiv.org/abs/2510.08776)
### Authors
Kimaya Basu,Savi Kolari,Allison Yu
### Background
随着大规模语言模型（LLM）的使用在全球、多种语言和人类社会中变得越来越普遍，理解并规范其多语言响应的需求也随之增加。为此，已创建了大规模数据集用于测试和基准测试，以评估和促进LLM在多个维度上的响应。本研究评估前沿和领先开源模型在低资源和高资源语言上的五个维度响应，以衡量LLM在多语言环境中的准确性和一致性。
### Innovation
本研究采用五点评分量表和主持LLM对响应进行评估，重点考察了五个维度：一致性和连贯性、责任与公正、同意与自主、伤害预防与安全以及隐私与透明度。通过这些评估，研究展示了在各个类别中的表现。例如，GPT-5在每个类别中的表现最佳，而其他模型则在语言和类别之间表现出更多的不一致性。特别是在同意与自主和伤害预防与安全类别中，GPT的得分最高，而Gemini 2.5 Pro得分最低。
### Conclusion
这些发现强调了对不同类别中语言变化如何影响LLM响应进行进一步测试的必要性，并指出需要在这些领域进行改进。
## 91. `cs.AI` - Struc-EMB:结构感知编码在语言嵌入中的潜力 [PDF](https://arxiv.org/pdf/2510.08774), [HTML](https://arxiv.org/abs/2510.08774)
### Authors
Shikun Liu,Haoyu Wang,Mufei Li,Pan Li
### Background
大型语言模型（LLMs）的文本嵌入已成为众多应用的基石。然而，这些模型通常仅处理原始文本，忽视了强相关的结构信息，比如超链接或引文，这些信息在许多真实世界的数据集中提供了必要的上下文。本研究旨在通过直接将这些结构关系融合到LLM的内部编码过程中来生成结构感知文本嵌入，而不依赖传统的事后聚合方法。研究通过广泛的零样本实验（涵盖检索、聚类、分类及推荐任务），验证了结构感知嵌入的一致优越性，展现了它在文本嵌入及事后聚合基准模型中的超越性。研究还分析了两种主流程方法：顺序串联和并行缓存，揭示了各自的优缺点。此外，针对噪声结构数据问题，还提出了两种有效技术：上下文提炼和语义平衡措施，并进行了验证。这项工作首次全面分析了嵌入中的结构感知编码过程，为构建更强大且上下文感知的嵌入模型提供了原理性设计指导。
### Innovation
本研究引入并系统评估了一种新颖的生成结构感知文本嵌入的框架，通过直接将结构关系融合到LLM的内部编码过程中。研究进一步探讨了两种主要的在线处理方法（顺序串联和并行缓存），并提出了两种应对噪声结构数据的有效技术（上下文提炼和语义平衡）以增强方法的鲁棒性。研究成果提供了全面分析嵌入中的结构感知编码的研究基础和实现方案，为增强嵌入模型的功能性和上下文感知性提供了新的视角和方法。
### Conclusion
本研究通过广泛的零样本实验探讨了结构感知文本嵌入的有效性，并在多个任务中展示了其相对于文本仅处理和事后聚合基准模型的优越性能。研究还分析了不同处理方法的关键权衡，并提出的技术有效地提高了处理噪声结构数据的准确性。研究结论强调了结构感知编码在语言嵌入中的潜力，并为构建更强大的上下文感知嵌入模型提供了重要参考。
## 92. `cs.AI` - SkipSR：通过取消低分辨率输入中的细节计算加速超分辨率 [PDF](https://arxiv.org/pdf/2510.08799), [HTML](https://arxiv.org/abs/2510.08799)
### Authors
Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni
### Background
基于扩散的超分辨率(SR)是视频生成和视频恢复的关键组成部分，但速度慢且昂贵，限制了其在更高分辨率和更长时间视频上的扩展。现有的方法一般会对所有像素进行均匀处理，即使很多区域原本就细节不足或可以通过不进行细化来保持质量。
### Innovation
提出了一种名为SkipSR的简单框架，通过直接从低分辨率输入中识别低细节区域并完全跳过这些区域的计算，仅对需要细化的区域进行超分辨率处理。这种方法能够在保持感知质量的同时显著降低计算量。在标准超分辨率基准测试中，我们的方法在720p视频上的端到端延迟比之前的方法快60%，且无明显质量损失。
### Conclusion
该方法通过直接跳过低分辨率视频中的低细节区域的计算，可以在保持良好视觉效果的同时大幅提高超分辨率处理速度，适合应用于视频超级分辨率场景且适用于标准和单步扩散超分辨率模型。
## 93. `cs.AI` - MLLM作为UI裁判：多模态LLM在预测用户体验界面感知方面的基准测试 [PDF](https://arxiv.org/pdf/2510.08783), [HTML](https://arxiv.org/abs/2510.08783)
### Authors
Reuben A. Luera,Ryan Rossi,Franck Dernoncourt,Samyadeep Basu,Sungchul Kim,Subhojyoti Mukherjee,Puneet Mathur,Ruiyi Zhang,Jihyung Kil,Nedim Lipka,Seunghyun Yoon,Jiuxiang Gu,Zichao Wang,Cindy Xiong Bearfield,Branislav Kveton
### Background
在理想的设计流程中，用户界面设计与用户研究紧密结合，以验证决策。然而，在早期探索阶段，研究往往由于资源限制而受限。最近，多模态大型语言模型（MLLMs）的进步为成为早期评估工具提供了新的机会，帮助设计师在正式测试前缩小选项范围。现有研究侧重于狭隘领域的用户行为，如电子商务，并使用点击率或转化率等指标进行评估。本研究则关注不同界面下的主观用户评价。研究旨在探讨MLLMs是否能够模仿人类在单独的用户界面评估及不同界面对比时的偏好。通过众包平台获取的数据，本研究比较了GPT-4o、Claude和Llama在30个不同界面的表现，并从多个UI因素的角度考察其与人类判断的一致性。研究表明，虽然MLLMs在某些维度上能够接近人类偏好，但在其他维度上则表现出不一致，这突显了它们在早期用户体验研究中的潜力与局限性。
### Innovation
本研究利用多模态大型语言模型作为早期评估工具，通过对比不同大模型在多种用户界面情境下的表现，评估其在预测人类感知用户界面方面的有效性。这填补了现有研究侧重于特定领域行为而忽视更广泛用户评价的空白。
### Conclusion
研究发现MLLMs在某些维度上能够接近人类偏好，但在其他维度上表现出不一致。这表明在早期用户体验研究中，MLLMs具有潜在价值，但也存在局限性。
## 94. `cs.AI` - 通过LLM增强观察指导强化学习探索 [PDF](https://arxiv.org/pdf/2510.08779), [HTML](https://arxiv.org/abs/2510.08779)
### Authors
Vaibhav Jain,Gerrit Grossmann
### Background
在稀疏奖励环境中，强化学习（RL）代理通常难以发现有效的行动序列，传统的探索策略在这种环境中失效。尽管大型语言模型（LLMs）在文本预训练期间获得了过程性知识和推理能力，可以指导RL探索，但现有方法往往创建了固定的依赖性，使得RL策略必须遵循LLMs的建议或直接将它们整合到奖励函数中。这项研究提出了一个框架，通过增强观察空间提供由LLM生成的行动建议，使RL代理在何时遵循或忽视这些指导变得灵活。这种方法利用了LLMs的世界知识和推理能力，并通过软约束保持了灵活性。
### Innovation
该方法利用大型语言模型的先验知识和推理能力，通过增强观察空间提供行动建议，让RL代理在遵循或忽视这些建议时具有灵活性，同时保持一定的灵活性。这种方法在具有不同复杂性的BabyAI环境中得到验证，表明LLM指导的益处随着任务难度的增加而增加。在最具挑战性的环境中，该方法相对于基线在最终成功率上实现了71%的相对提升。此外，该方法提高了样本效率，使代理达到性能阈值的速度加快了9倍，且无需对现有的RL算法进行任何修改。
### Conclusion
这种利用LLM规划能力的方法有效加速了在具有挑战性的环境中强化学习的训练， demonstrated an effective method for leveraging LLM planning capabilities to accelerate RL training in challenging environments.
## 95. `cs.AI` - 使用多步推理视角评估中文常识推理 [PDF](https://arxiv.org/pdf/2510.08800), [HTML](https://arxiv.org/abs/2510.08800)
### Authors
Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang
### Background
尽管大型语言模型（LLMs）展示了先进的推理能力，但它们在一般中文语境下的全面评估仍然不足。本文为填补这一空白，提出了Chinese Commonsense Multi-hop Reasoning (CCMOR)这一新的基准，旨在评估LLMs结合中文特定事实知识和多步逻辑推理的能力。
### Innovation
提出了CCMOR基准，设计了一个包含从现有问答数据集中构建的领域平衡种子集和LLM驱动生成多步问题（基于事实单元链）的管道。此外，还设计了一个基于人工辅助验证系统来确保数据集的质量。
### Conclusion
使用CCMOR评估了最先进的LLMs，证明了它们处理长尾知识和执行知识密集型推理的能力存在不足。然而，检索增强生成显著缓解了这些知识鸿沟，带来了显著的性能提升。
## 96. `cs.AI` - 多臂老虎机中的欺骗性探索 [PDF](https://arxiv.org/pdf/2510.08794), [HTML](https://arxiv.org/abs/2510.08794)
### Authors
I. Arda Vurankaya,Mustafa O. Karabag,Wesley A. Suttle,Jesse Milzman,David Fridovich-Keil,Ufuk Topcu
### Background
本文考虑了一个多臂老虎机环境，其中每个臂都有公共和私人奖励分布。观察者期望代理遵循根据公共奖励进行机会抽样的策略，而欺骗性代理则旨在迅速确定最佳私人臂而不被发现。观察者只能观察公共奖励和被拉动的臂，而不能观察私人奖励。另一方面，代理观察到公共和私人奖励。
### Innovation
本文通过将可检测性形式化为实际上由代理使用的拉动概率与观察者预期的拉动概率之间的逐步Kullback-Leibler (KL) 发散约束来建模。成功拉动公共非最优臂被建模为一个Bernoulli过程，其中成功的概率随着每次成功的拉动而降低，并表明在KL约束下，这些拉取可以在最坏情况下以Θ(√T)的速度发生。通过基于公共和私人均值建立最大化最小问题，其解描述了识别最佳私人臂的最佳错误指数。最后，本文提出了一种基于top-two算法的启发式算法，该算法根据公共非最优臂差距的难度自然调整其探索策略，并提供了数值示例来说明Θ(√T)的速度和所提出算法的行为。
### Conclusion
本研究提出了一个基于top-two算法的策略，该策略能在公共非最优奖励差距的难度下自然调整探索，并据此量化了最佳私人臂识别的最佳错误指数。通过数值示例，证明了该策略的行为符合预期。
## 97. `cs.AI` - 在深空探测任务中使用离线信念状态规划实现自适应科学操作 [PDF](https://arxiv.org/pdf/2510.08812), [HTML](https://arxiv.org/abs/2510.08812)
### Authors
Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer
### Background
深空任务面临极端的通信延迟和环境不确定性，无法支持实时地面操作。为了在通信受限的环境中支持自主科学操作，本文提出了一种部分可观测马尔可夫决策过程（POMDP）框架，用于适应性地序列化航天器科学仪器。在此框架中，通过集成贝叶斯网络到POMDP观测空间，来管理典型的天体生物学任务中高维度和不确定的测量数据，提高了科学数据的可解释性和计算效率。
### Innovation
将贝叶斯网络集成到POMDP的观测空间中，以有效管理高维和不确定性高的测量数据，增强了系统的可解释性和计算可行性。通过离线计算仪器操作策略，可以在发射前生成并验证资源感知的计划。
### Conclusion
通过与土卫二轨道探测器的Life Detection Suite (LDS)案例研究，展示了贝叶斯网络结构和奖励塑造如何影响系统性能。研究结果表明，该方法将样本识别错误降低了近40%。与任务基准概念操作（ConOps）相比，该方法还评估了异常样本采集情况下的系统表现。
## 99. `cs.AI` - McMining：学生代码中的错误观念的自动化发现 [PDF](https://arxiv.org/pdf/2510.08827), [HTML](https://arxiv.org/abs/2510.08827)
### Authors
Erfan Al-Hossami,Razvan Bunescu
### Background
在学习编程时，学生往往会对编程概念产生误解，这些误解不仅会导致代码错误和效率低下，还会减缓相关概念的学习进程。为了解决这一问题，该研究引入了McMining任务，即从学生代码样本中挖掘编程误解。
### Innovation
本文开发了一个包含大量代码样本（展示了各种误解）的可扩展基准数据集，用于McMining系统的训练和评估。同时，还提出了两种基于LLM（大型语言模型）的方法，通过广泛评估证明了Gemini、Claude和GPT系列模型在发现学生代码中的误解方面的有效性。
### Conclusion
本文通过开发可扩展的基准数据集和基于LLM的两种McMiner方法的有效性评估，为自动化发现编程误解提供了可行方案，有助于提高编程教学质量。
## 100. `cs.AI` - D-CoDe：通过动态压缩和问题分解将图像预训练VLM扩展到视频 [PDF](https://arxiv.org/pdf/2510.08818), [HTML](https://arxiv.org/abs/2510.08818)
### Authors
Yiyang Huang,Yizhou Wang,Yun Fu
### Background
视频大型语言模型（Vid-LLMs）在多种视频-语言任务中表现出色，可以通过适应图像预训练的视觉语言模型（VLMs）有效地构建。然而，这种适应具有挑战性，因为它需要处理超出图像模型容量的密集且时间上扩展的视觉输入。本文指出了在将基于图像的VLMs扩展到视频域时的关键挑战，即感知瓶颈和标记过载。
### Innovation
本文提出了一种训练无干预的适应框架D-CoDe，结合动态压缩和问题分解。动态压缩通过适应选择代表帧和内容感知的聚合空间标记来缓解感知瓶颈，减少了冗余并保留了信息内容。同时，问题分解通过将原始查询重新表述为子查询来减轻标记过载，引导模型关注视频的不同方面，从而实现更全面的理解。
### Conclusion
实验结果表明，D-CoDe在各种基准上的视频理解能力得到有效提升。特别是在具有挑战性的长视频基准上的强表现表明了D-CoDe在处理复杂视频-语言任务中的潜力。该代码可在该网址获取。
## 101. `cs.AI` - 时间感知特征选择：适用于稳定稀疏自编码器训练的自适应时间掩码 [PDF](https://arxiv.org/pdf/2510.08855), [HTML](https://arxiv.org/abs/2510.08855)
### Authors
T. Ed Li,Junyu Ren
### Background
了解大型语言模型的内部表示对于确保其可靠性和安全性至关重要，稀疏自编码器（SAEs）作为一种有望提高模型可解释性的方法受到关注。然而，现有的SAE训练方法面临着特征吸收的问题，即特征（或神经元）相互吸收以减小$L_1$惩罚，这使得很难一致地识别和分析模型行为。
### Innovation
提出了一种新颖的训练方法——自适应时间掩码（ATM），通过动态调整特征选择，跟踪激活幅度、频率和重建贡献来计算随时间演化的相关性评分。ATM采用了基于统计阈值的概率性掩码机制，形成了更自然的特征选择过程。在Gemma-2-2b模型上进行了广泛的实验，结果显示ATM在吸收评分方面明显低于现有方法（如TopK和JumpReLU SAEs），同时保持了卓越的重建质量。
### Conclusion
这些结果确立了ATM作为学习神经网络中稳定和可解释特征的一个理论解决方案的基础，为更可靠的模型分析提供了基石。
## 102. `cs.AI` - 通过微调的LLM实现仓库感知的文件路径检索 [PDF](https://arxiv.org/pdf/2510.08850), [HTML](https://arxiv.org/abs/2510.08850)
### Authors
Vasudha Yanuganti,Ishaan Puri,Swapnil Chhatre,Mantinder Singh,Ashok Jallepalli,Hritvik Shrivastava,Pradeep Kumar Sharma
### Background
现代代码库使得开发者和AI编码助手在回答诸如“这个功能是如何实现的？”或“bug是在哪里引入的？”的问题时难以找到合适的源文件。传统的代码搜索（基于关键字或信息检索的方法）往往会忽略语义上下文和跨文件链接，而大型语言模型虽然能理解自然语言，但对于特定代码库的细节仍缺乏了解。
### Innovation
本文提出了一种文件路径检索方法，通过使用QLoRA和Unsloth优化的强大型语言模型（Qwen3-8B）直接从自然语言查询中预测相关文件路径。为了构建训练数据，引入了六种代码感知策略，利用抽象语法树（AST）结构和代码库内容生成真实的问答对，其中答案是文件路径的集合。这些策略从单一文件提示到层次化的代码库摘要，提供广泛的覆盖范围。该方法在Python项目（如Flask、Click、Jinja、FastAPI、PyTorch）上进行微调，取得了高检索精度：在外数据查询上可达91%的精确匹配和93%的召回率，明显优于单一策略训练。在大型代码库（如PyTorch，约4000个Python文件）上，模型的召回率为59%，显示了其规模性。
### Conclusion
多层次代码信号有助于大型语言模型推理跨越文件的上下文，同时讨论了数据集设计、局限性（例如，非常大型代码库中的上下文长度限制）以及未来将检索与基于大型语言模型的代码智能集成的可能性。
## 103. `cs.AI` - Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication [PDF](https://arxiv.org/pdf/2510.08874), [HTML](https://arxiv.org/abs/2510.08874)
### Authors
Benjamin Brock,Renato Golin
### Background
分布式矩阵乘法在自然科学、数据科学和人工智能工作负载中非常重要。现有工作开发了多种适用于不同问题规模和分区的算法，包括1维、2维、1.5维和2.5维算法。但现有算法仅限于部分分区方案，无法支持所有可能的分区组合。因此，需要多个算法实现来支持所有分区方案，若某种特定分区方案没有相应算法实现，则需要重新分配操作数，增加通信成本。
### Innovation
本文提出一种针对分布式矩阵乘法的通用单边算法，支持所有分区组合和复制因子。该算法通过切片（索引算术）计算必须相乘的重叠小矩阵块集合，然后直接执行或重新排列并将其降低到优化中间表示以最大化重叠。此外，该算法使用一种基于PGAS的高阶C++框架实现，该框架通过节点内互联在GPU之间执行直接通信。
### Conclusion
我们对各种分区方案和复制因子进行了性能评估，发现我们的工作在性能上与PyTorch DTensor相对竞争，PyTorch DTensor是针对AI模型的高度优化分布式张量库。
## 104. `cs.AI` - CommandSans：以精确指令消毒确保人工智能代理安全 [PDF](https://arxiv.org/pdf/2510.08829), [HTML](https://arxiv.org/abs/2510.08829)
### Authors
Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader
### Background
随着具有多种工具访问权限和敏感数据的大型语言模型（LLM）代理被越来越多地采用，间接提示注入的攻击面显著扩大。由于攻击具有上下文依赖性，当前的防御措施往往不能可靠地区分恶意和良性指令，导致高的误报率，这阻碍了它们在现实世界中的应用。这一背景下，本文分析了现有安全措施的问题，并探讨了一种解决方案。
### Innovation
本文提出了一种基于计算机安全基本原则的新方法：数据不应包含可执行指令。该方法通过在工具输出中去除指令，而不是在样本级别进行分类，从而避免了误报和上下文依赖性的问题。相较于现有的安全分类器，这种方法是非阻塞的，不需要校准，能够在多种攻击和基准测试中广泛适用，且可以通过现有的指令调优数据进行训练，从而避免依赖于不切实际的提示注入示例。
### Conclusion
实验结果表明，该方法在包括AgentDojo、BIPIA、InjecAgent、ASB和SEP等多种攻击和基准测试中表现出色，实现了7-10倍的攻击成功率降低，在良性与恶意设置中均未影响代理的实用性。
## 105. `cs.AI` - 基于强化学习的边缘管理以实现可靠的多视图3D重建 [PDF](https://arxiv.org/pdf/2510.08839), [HTML](https://arxiv.org/abs/2510.08839)
### Authors
Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy
### Background
实时多视图3D重建是边缘本地关键应用场景的关键任务之一，诸如火灾救援等领域，其能够提供及时且准确的3D场景建模，从而帮助提高现场情况的感知能力和决策的准确性。然而，边缘资源的动态和不可预测性导致了诸如图像质量下降、网络连接不稳定和服务器负载波动等问题，这些因素严重挑战了重建管道的可靠性。
### Innovation
本工作提出了一种基于强化学习(RL)的边缘资源管理框架，该框架能够确保即使在资源受限且易受干扰的环境下，也能在合理的时间内实现高质量的3D重建。具体来说，该框架采用了两个合作的Q学习代理，一个用于摄像头选择，另一个用于服务器选择，两者完全在线运行，并通过与边缘环境的交互学习策略。为了在现实约束条件下支持学习并评估系统性能，研究团队构建了一个分布式测试平台，包括实验室端设备和FABRIC基础设施边缘服务器，以模拟在现实干扰场景下的智能城市边缘基础设施环境。结果表明，该提出的框架能够有效平衡端到端延迟和重建质量，从而提高应用的可靠性。
### Conclusion
实验结果表明，提出的框架通过有效平衡端到端延迟和重建质量，在动态环境中实现了更高的应用可靠性。
## 106. `cs.AI` - 基于向量图的仓库理解以支持问题驱动的文件检索 [PDF](https://arxiv.org/pdf/2510.08876), [HTML](https://arxiv.org/abs/2510.08876)
### Authors
Kostiantyn Bevziuk,Andrii Fatula,Svetozar Lashin Yaroslav Opanasenko,Anna Tukhtarova,Ashok Jallepalli Pradeepkumar Sharma,Hritvik Shrivastava
### Background
在软件开发过程中，大型软件仓库的管理和维护变得复杂。现有的许多任务，如问题定位和修复、代码重构都需要对代码仓库的结构和语义有深入的理解。传统的手动方式效率低下，迫切需要自动化的方法来辅助代码的管理和开发。此论文提出了一个仓库分解系统，该系统将大型的软件仓库转换为一个向量化的知识图谱，以捕捉语义关系并提供自动化的进一步仓库管理能力。
### Innovation
提出了一个将大型软件仓库分解为向量化知识图的方法，该图谱能够反映项目架构和语义结构，捕获语义关系并实现进一步仓库开发的高度自动化。该系统特别引入了一种混合检索流程，结合了语义检索和图感知扩展，以及基于LLM的助手自动提出受约束的只读图请求，并生成面向人工的解释。
### Conclusion
该系统通过构建一个向量化的知识图谱，简化了大型软件仓库的管理和开发，特别是对于问题驱动的文件检索和支持具有自动化的仓库维护。通过实际应用，提高了代码管理和维护的效率，同时也提供了一个支持性的自动解析助手来辅助用户提供精确的结果。
## 107. `cs.AI` - 在RLVR中的多温度策略探索：用于标记和汇总级控制 [PDF](https://arxiv.org/pdf/2510.08892), [HTML](https://arxiv.org/abs/2510.08892)
### Authors
Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang
### Background
强化学习已经显著提高了大型语言模型（LLMs）的推理能力，并在多个领域展现出广阔的应用前景。研究发现，LLMs中的令牌在推理任务中扮演着不同的角色，被分为高熵推理令牌和低熵知识令牌。先前的方法通常关注于间接促进探索行为，但并未直接在令牌生成阶段鼓励探索。
### Innovation
本文提出了一种新的方法，通过为不同类型的令牌分别应用不同的温度设置，显式地在采样过程中促进探索。具体而言，该方法使用较高的温度设置来积极鼓励推理令牌的探索，同时维持较低的温度设置以保证事实的准确性。此外，本文还系统地研究了不同多温度调度策略在强化学习环境中的影响。实验证明该方法显著提高了LLMs的推理性能。
### Conclusion
基于实证评估，该研究证明了多温度策略在加强LLMs推理性能方面具有显著效果。该方法不仅直接促进了探索性行为，还通过实验验证了其在多种推理基准测试中的有效性。
## 108. `cs.AI` - Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models [PDF](https://arxiv.org/pdf/2510.08859), [HTML](https://arxiv.org/abs/2510.08859)
### Authors
Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma
### Background
大规模语言模型（LLMs）仍然容易受到利用对话背景逐渐绕过安全限制的多轮监禁攻击（jailbreaking attacks）。这些攻击针对不同类型的风险（如恶意软件生成、骚扰或欺诈）采用不同的对话策略（如教育讨论、个人经历、假设场景）。现有的多轮监禁破解方法通常依赖于启发式或临时的探索策略，对底层模型的弱点提供有限的见解。不同风险类别下的对话模式与模型漏洞之间的关系仍然没有很好的理解。文章提出了一种名为PE-CoA（Pattern Enhanced Chain of Attack）的框架，利用五种对话模式以自然对话方式构造有效的多轮监禁攻击。
### Innovation
文章提出了PE-CoA框架，通过五种对话模式构建有效的多轮监禁攻击，通过自然对话方式实施，评估结果表明该框架在十二个LLM涵盖的十个风险类别上取得了最先进的性能，揭示了特定模式下的漏洞和大型语言模型的行为特征：模型在不同对话模式下的防御能力具有差异性，同一类型的模型在面对不同的对话模式时表现出类似的失效模式。这些发现揭示了安全训练的局限性，并指出需要采用模式感知的防御策略。
### Conclusion
通过评估PE-CoA框架在十二个大型语言模型中的应用情况，其达到了最先进的性能，发现在不同对话模式下的特定漏洞和大型语言模型的行为特征。文章发现模型在不同对话模式下的防御能力是不同的，同一类型的模型在面对不同的对话模式时会表现出类似的失败模式。这些发现指出安全训练的局限性，表明需要方向性防护策略。
## 109. `cs.AI` - ControlAudio: 通过渐进式扩散建模解决基于文本引导、定时指示和清晰易懂的音频生成问题 [PDF](https://arxiv.org/pdf/2510.08878), [HTML](https://arxiv.org/abs/2510.08878)
### Authors
Yuxuan Jiang,Zehua Chen,Zeqian Ju,Yusheng Dai,Weibei Dou,Jun Zhu
### Background
近期研究表明，带有细粒度控制信号的文本到音频（TTA）生成，例如精确的定时控制或可理解的语音内容，在当前研究中已有所探索。但由于数据稀缺，其大规模生成性能仍然受到限制.
### Innovation
该研究将可控TTA生成重新定义为多任务学习问题，并引入了一种渐进扩散建模方法——ControlAudio。该方法通过步骤化策略适应更多细粒度的信息分布，包括文本、定时和音素特征。首先提出了一种覆盖注释和模拟的数据构建方法，以增强顺序中的条件信息。在模型训练阶段，先使用大规模文本-音频对预训练一个扩散变压器（DiT），实现可扩展的TTA生成，然后逐步整合定时和音素特征与统一语义表示，增强可控性。最后，在推理阶段提出逐步引导生成方法，按顺序强调更多细粒度信息，与DiT粗细采样本性相契合。实验结果显示，ControlAudio在时间准确性和语音清晰度上达到最新技术水平，在客观和主观评估上显著优于现有方法.
### Conclusion
ControlAudio在时间准确性和语音清晰度方面达到了最先进的性能，显著优于现有的方法，在客观和主观评估中都表现出色。
## 110. `cs.AI` - 设计和发展以人工智能驱动的沉浸式多学科模拟（AIMS）用于跨专业教育 [PDF](https://arxiv.org/pdf/2510.08891), [HTML](https://arxiv.org/abs/2510.08891)
### Authors
Ruijie Wang,Jie Lu,Bo Pei,Evonne Jones,Jamey Brinson,Timothy Brown
### Background
跨专业教育长期以来依赖案例分析和标准化病人来支持医疗保健专业人士之间的团队合作、沟通等相关协作能力。然而，传统方法往往受限于成本、可扩展性和无法模拟现实临床情景的动态复杂性。因此，设计并开发了AIMS（增强型人工智能增强沉浸式多学科模拟），这是一种虚拟模拟，结合了大型语言模型（Gemini-2.5-Flash）、基于Unity的虚拟环境引擎和角色生成流水线，用于支持用户与虚拟患者之间的同步、多模态互动。AIMS旨在提升药学、医学、护理和社会工作学生之间的协作临床推理和健康促进能力。通过正式的易用性测试，参与者在健康团队中扮演专业角色，并参与混合的剧本和非剧本对话。参与者探究了患者的症状、社会背景和护理需求。发现了技术问题（如音频路由、响应延迟）并用于指导后续改进。总体来说，AIMS支持现实、专业特定和上下文适宜的对话.
### Innovation
通过结合大型语言模型、基于Unity的虚拟环境引擎和角色创建流水线，设计和发展了AIMS（增强型人工智能增强沉浸式多学科模拟），以解决传统跨专业教育方法中存在的成本、可扩展性和真实性问题。AIMS支持同步和多模态互动，旨在提升学生之间的协作临床推理和健康促进能力。通过使用虚拟患者，学员可以探索患者的症状、社会背景和护理需求，这种沉浸式技术提供了更真实的对话体验。
### Conclusion
研究表明，AIMS支持现实、专业特定和上下文适宜的对话。讨论了AIMS的技术和教学创新，并指出了未来发展方向。
## 111. `cs.AI` - 精确刻画关键步骤：可验证强化学习中的归因信用分配 [PDF](https://arxiv.org/pdf/2510.08899), [HTML](https://arxiv.org/abs/2510.08899)
### Authors
Junxi Yin,Haisen Luo,Zhenyu Li,Yihua Liu,Dan Liu,Zequn Li,Xiaohang Xu
### Background
虽然采用可验证奖励的强化学习（RLVR）能增强大型语言模型（LLMs）的复杂推理能力，但现有方法难以平衡探索与利用，导致中间步骤责任分配不准确和随机性过早耗尽等问题，限制了模型性能。
### Innovation
提出了一种基于归因的策略优化贡献（ACPO）阶段框架，该框架结合了难度感知的课程设置，通过轨迹语义分割和基于归因的表示动态调节策略的不确定性，从而缓解其过早衰减，并通过因子化的奖励系统精确量化每一步推理的层次贡献，确保责任精确分配。
### Conclusion
在AIME、MATH和AMC等具有挑战性的基准测试上进行的广泛实验表明，ACPO显著优于现有最先进的方法。
## 112. `cs.AI` - HES-SQL：结构化骨架指导下的高效文本到SQL混合推理 [PDF](https://arxiv.org/pdf/2510.08896), [HTML](https://arxiv.org/abs/2510.08896)
### Authors
Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun
### Background
该研究聚焦于文本到SQL生成（Text-to-SQL）任务，提出了利用Group Relative Policy Optimization (GRPO)与思考模式融合的监督微调 (SFT) 方法的新型混合训练框架HES-SQL。该框架旨在同时优化SQL查询的准确性和执行效率，并在单一用户控制条件下对MySQL 8.0和SQLite 3.42进行了实验评估。
### Innovation
HES-SQL引入了三种关键技术：(1) 骨架完整性评分机制，提高生成查询与最优SQL结构之间的偏好一致性；(2) 查询延迟感知的奖励系统，激励生成计算效率高的SQL查询；(3) 自我蒸馏过程，在不影响模型推理能力的情况下完成思考模式。
### Conclusion
实验结果显示，HES-SQL在BIRD和KaggleDBQA基准上的执行准确性分别为79.14%和54.9%，相比于监督基线有着11%到20%的效率提升。研究证明，通过执行导向的强化学习方法可以有效平衡语义准确性和计算效率，这对构建有效的自然语言数据库接口和增强结构化生成任务的鲁棒性具有重要意义。
## 113. `cs.AI` - 大规模语言模型支持的统一生物医学命名实体识别框架 [PDF](https://arxiv.org/pdf/2510.08902), [HTML](https://arxiv.org/abs/2510.08902)
### Authors
Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin
### Background
生物医学命名实体识别对于医学信息提取和知识发现至关重要，但现有方法在处理嵌套实体、实体边界模糊以及跨语言泛化能力方面存在局限性。
### Innovation
提出了基于大规模语言模型（LLMs）的统一生物医学命名实体识别（BioNER）框架。通过将BioNER重新定义为文本生成任务并设计符号标签策略来联合处理平级和嵌套实体，同时引入对比学习实体选择器筛选错误或虚假预测。
### Conclusion
实验结果显示，该方法在四个基准数据集和两个未见过的数据集上均达到最新的性能，并且展示了语言上卓越的零样本泛化能力。源代码已开源。
## 114. `cs.AI` - 低资源数据学习的分析调查：从分析到调查 [PDF](https://arxiv.org/pdf/2510.08962), [HTML](https://arxiv.org/abs/2510.08962)
### Authors
Xiaofeng Cao,Mingwei Xu,Xin Yu,Jiangchao Yao,Wei Ye,Shengjun Huang,Minling Zhang,Ivor W. Tsang,Yew Soon Ong,James T. Kwok,Heng Tao Shen
### Background
人工智能（AI）在使用高资源数据的学习中取得了显著的成功，但与数据注释和模型训练相关的成本仍然很高。AI研究的基本目标之一是通过有限资源数据实现稳健泛化。
### Innovation
本文采用泛化无知的主动抽样理论在可能近似正确（PAC）框架下分析了低资源数据学习中的泛化误差和标签复杂性。基于此分析，研究了一系列针对低资源数据学习的优化策略，包括梯度导向优化、元迭代优化、几何意识优化和基于LLMs的优化。
### Conclusion
总结了分析的主要发现，并突出了它们对低资源数据学习的意义。
## 115. `cs.AI` - 合著自我：推荐系统中兴趣反思的人工智能界面 [PDF](https://arxiv.org/pdf/2510.08930), [HTML](https://arxiv.org/abs/2510.08930)
### Authors
Ruixuan Sun,Junyuan Wang,Sanjali Roy,Joseph A. Konstan
### Background
基于自然语言的用户画像已在推荐系统中得到了探索，这些画像具有可解释性和帮助用户验证和调整其兴趣的潜力，从而提高推荐质量。在此基础上，我们提出了一种适用于电影推荐系统的协作式用户画像，该画像呈现了用户电影历史的可编辑个性化兴趣摘要。
### Innovation
该研究引入了一种协作式用户画像，与静态画像不同，这种设计邀请用户直接检查、修改和反思系统得出的推断。研究在8周的在线现场部署中，涉及1775名活跃的电影推荐用户，发现了用户感知的兴趣与系统推断之间持续存在的差距，展示了画像如何促进用户参与和反思，并确定了利用不完美的AI驱动用户画像来刺激更多用户干预和建立更透明和可信赖的推荐体验的设计方向。
### Conclusion
研究结果表明，至少在电影推荐领域，用户对系统推断的理解水平普遍较低，并且可编辑的个性化兴趣总结可以有效促进用户对系统推断的参与和反思。未来的设计方向包括如何更好地利用这种不完美的AI驱动的用户画像，以促进更多的用户干预，从而提高推荐系统的透明度和信任度。
## 116. `cs.AI` - RO-Bench: 使用文本驱动的虚假视频大规模评估MLLMs的鲁棒性 [PDF](https://arxiv.org/pdf/2510.08936), [HTML](https://arxiv.org/abs/2510.08936)
### Authors
Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang
### Background
近年来，多模态大型语言模型（MLLMs）在各种视频理解任务中取得了显著的性能。然而，它们在面对篡改视频内容时的鲁棒性尚未得到充分探索。此前，针对MLLMs的评估多集中在静态场景或较小规模的测试集上。
### Innovation
本文通过引入Ro-Bench，构建了一个能够评估MLLMs在动态非分布（OOD）虚假视频测试集上的鲁棒性的基准方法。Ro-Bench通过编辑样式、对象、背景及其组成，集成了高质量、多样且时序相关性的视频数据。研究发现，当前的视频MLLMs在面对虚假视频内容时性能显著下降，但通过细调模型以适应虚假数据可以显著提升鲁棒性。
### Conclusion
研究结果强调了使用虚假数据增强视频理解能力的有效性。已评估的模型在Ro-Bench上的性能提升了21.73%，并在MVBench数据集的20个任务上平均提高了12.78%的性能。研究团队将很快公开代码和数据。
## 117. `cs.AI` - 多臂老虎机问题的频域分析：探索-利用权衡的一种新视角 [PDF](https://arxiv.org/pdf/2510.08908), [HTML](https://arxiv.org/abs/2510.08908)
### Authors
Di Zhang
### Background
多臂老虎机（MAB）问题是最基本的序贯决策模型之一，核心挑战在于探索和利用之间的权衡。虽然UCB和Thompson Sampling等算法及其遗憾理论得到了广泛的发展和验证，但现有分析主要集中在时间域和累计遗憾上，难以捕捉学习过程中的动态特性。
### Innovation
本文提出了一个新的频域分析框架，将多臂老虎机过程重新定义为信号处理问题。在此框架下，每个臂的奖励估计被视为频谱组件，其不确定性对应于频率，算法被解释为自适应滤波器。构建了正式的频域多臂老虎机模型，证明了主定理：UCB算法中的置信界限项可等效地表示为时间变化的增益应用于不确定的频谱组件上，这一增益与访问次数的平方根成反比。在此基础上，进一步推导出关于探索率衰减的有限时间动态边界。这种理论不仅为经典算法提供了一个新颖直观的物理解释，还为设计具有自适应参数调整的新一代算法奠定了坚实的理论基础。
### Conclusion
本文通过构建频域多臂老虎机模型，提供了一种新的探索-利用权衡的视角，不仅为经典算法提供了新的物理解释，还为下一代具有自适应参数调整的算法设计提供了理论基础。
## 118. `cs.AI` - 软件项目中集体治理的人类行为基线 [PDF](https://arxiv.org/pdf/2510.08956), [HTML](https://arxiv.org/abs/2510.08956)
### Authors
Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey
### Background
本文研究了开源社区如何通过版本控制系统中的治理文档来描述参与和控制。采用了一包含710个项目且具有配对快照的数据集，对文本进行了解析，并将其划分为主体、规则、行动和对象。通过熵、丰富性和Jensen Shannon散度来衡量变化。
### Innovation
研究发现，项目随着时间的推移定义了更多的角色和行动，并且这些角色和行动被更均匀地分配。规则的构成保持稳定。这些发现表明，治理通过扩展和平衡参与的类别来增长，而不会出现大的规范性变化。此分析为后续AI中介工作流程是否集中或重新分配权力提供了可再现的参考基准。
### Conclusion
治理的增长通过扩展与平衡参与的类别来进行，而不会出现重大的规范性变化。此分析提供了一个可再现的基础，用于评估未来AI中介工作流程到底是集中还是重新分配权力。
## 119. `cs.AI` - SHERLOCK：LLM增强的电子商务风险管理中动态知识适应化 [PDF](https://arxiv.org/pdf/2510.08948), [HTML](https://arxiv.org/abs/2510.08948)
### Authors
Nan Lu,Yurong Hu,Jiaquan Fang,Yan Liu,Rui Dong,Yiming Wang,Rui Lin,Shaoyi Xu
### Background
随着电子商务行业的增长，电商平台中的风险管理和隐蔽经济活动之间出现了更加激烈的对抗。为应对这个挑战，公司通常会进行风险调查以识别和预防欺诈行为，这种做法提高了预判风险和事后治理的能力，然而，这同时也给风险管理人员带来了沉重的工作负担，因为每个案例都需要长期的经验积累和多维度的细致审查。此外，不同风险分析师之间的个体差异也影响了标准化的工作流程。因此，需要一种新的方法来解决这些问题，帮助风险管理人员更高效地进行调查工作。
### Innovation
我们提出了SHERLOCK框架，该框架利用大型语言模型（LLM）的推理能力来辅助风险调查。该框架由三个主要的组成部分构成：(1)从多模态数据中提取风险管理知识并构建专业知识库，(2)建立一个以数据飞轮范式为导向的智能平台，该平台整合了日常运营、专家注释和模型评估，并通过迭代微调来优化偏好匹配，(3)引入一个反思与改进（R&R）模块，该模块与领域知识库合作，以快速应对不断变化的风险模式。实验结果表明，该方法能够在LLM分析结果中显著提高事实对齐的准确性和风险定位的精度。使用SHERLOCK框架基于LLM系统的部署，可以极大地提升风险管理人员的案例调查工作效率。
### Conclusion
SHERLOCK框架通过利用大型语言模型的推理能力，提供了一种新的解决方案来解决电子商务风险管理中的挑战。通过构建专业知识库、智能平台和反思与改进模块，SHERLOCK能够提高风险调查的效率和准确性，并为不断演变的风险模式建立快速响应机制。
## 120. `cs.AI` - 拯救SWE-Bench：一种基准变异方法以实现真实的代理评估 [PDF](https://arxiv.org/pdf/2510.08996), [HTML](https://arxiv.org/abs/2510.08996)
### Authors
Spandan Garg,Ben Steenhoek,Yufan Huang
### Background
当前用于评估软件工程代理的基准指标，如SWE-Bench Verified，主要来源于GitHub问题，并未能准确反映开发人员与集成开发环境（IDE）中的聊天编码助手的互动方式。这种不符使得代理的实际能力在真实场景中被系统性地高估，尤其是在缺陷修复方面。
### Innovation
引入了一种新的基准评估框架，通过系统分析开发人员与聊天代理的互动模式，将现有的正式基准转换为现实用户查询。该方法灵活且可扩展，应用于SWE-Bench Verified、多SWE-Bench中的TypeScript子集和一个内部基准SWE-Bench C#。基于流行聊天代理的遥测分析，将正式的GitHub问题描述转换为现实用户的查询。研究表明，对于部分模型，现有基准在公共基准中高估了代理能力超过50%，在内部基准中约为10-16%。
### Conclusion
本研究通过基准变异技术建立了评估交互式聊天软件工程代理的新范式。
## 121. `cs.AI` - 学习正则化器：学习能够正则化的优化器 [PDF](https://arxiv.org/pdf/2510.08968), [HTML](https://arxiv.org/abs/2510.08968)
### Authors
Suraj Kumar Sahoo,Narayanan C Krishnan
### Background
已在元学习领域引起关注的Learned Optimizers（LOs）因其参数化和可训练性，能够高效优化。传统梯度方法通过引入诸如锐度感知最小化（SAM）、梯度范数感知最小化（GAM）和差距导向的锐度感知最小化（GSAM）等显式正则化技术来提升泛化和收敛性能。然而，该论文提出探究的一个基本问题是：正则化器是否能够被学习？
### Innovation
通过对标准基准（包括MNIST、FMNIST、CIFAR及MLP、MLP-Relu和CNN等神经网络）进行广泛的实验，研究表明LOs能够被训练以学习并内化传统正则化技术的效果，而无需直接将这些正则化技术应用到目标函数中。实验结果表明，含正则化器的LOs在测试准确率和泛化性能上优于未经过正则化处理的LOs。进一步的实验还展示了LOs能够保留和转移这些正则化效果到新的优化任务中，其内部倾向寻找到与这些正则化器目标相近的极小值。这项研究挑战了传统上直接对优化目标应用显式正则化的需求，表明LOs能够内生地学习正则化特性，实现优化和正则化能力的统一.
### Conclusion
研究结果揭示了LOs能够内生地学习正则化特性，挑战了传统上显式地在优化目标上应用正则化的需求，对元学习和优化技术领域具有重要意义。
## 122. `cs.AI` - PlatformX：一种端到端可移植的能源高效神经架构搜索平台 [PDF](https://arxiv.org/pdf/2510.08993), [HTML](https://arxiv.org/abs/2510.08993)
### Authors
Xiaolong Tu,Dawei Chen,Kyungtae Han,Onur Altintas,Haoxin Wang
### Background
现有硬件感知神经架构搜索（HW-NAS）方法由于高昂的时间成本、繁重的手动配置和跨不同硬件平台的可伸缩性差等问题，在实际部署中仍不具备实用性。
### Innovation
PlatformX 提出了一种全自动且可移植的 HW-NAS 框架，该框架包含四个关键组件：一种基于能量驱动的搜索空间，能够扩展常规 NAS 设计并包含能量关键配置；一种跨设备可移植的内核级能量预测器，通过少量设备上的样本逐步改进；一种基于帕累托的多目标搜索算法，平衡能量和准确率以识别最优权衡；以及一种高分辨率运行时能量剖析系统，无需人工干预即可自动生成设备上的电源测量。
### Conclusion
PlatformX 在多项移动平台上进行了评估，展示了其在降低搜索开销的同时保持准确性和能量保真度。它发现的模型可达到高达 0.94 的准确率或每个推断只需 0.16 mJ 能量，均优于 MobileNet-V2。
## 123. `cs.AI` - SEER: 通过增强软件需求工程实现可持续性 [PDF](https://arxiv.org/pdf/2510.08981), [HTML](https://arxiv.org/abs/2510.08981)
### Authors
Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi
### Background
软件开发的迅速扩展对环境、技术、社会和经济产生了重大影响。联合国可持续发展目标要求到2030年实现可持续发展，这促使开发者采取可持续的实践方式。现有的方法多提供高层次的指导原则，实施起来耗时且依赖团队的适应性，同时还集中在设计或实施阶段，但可持续性评估应该在需求工程阶段就开始。
### Innovation
提出了一种名为SEER的框架，在软件开发的早期阶段解决可持续性问题。SEER在三个阶段运行：(i) 从通用分类中识别与特定软件产品相关的可持续性需求(SRs)；(ii) 基于识别的SRs评估系统的可持续性需求；(iii) 优化未能满足任何SR的系统需求。该框架使用大型语言模型的推理能力和代理性RAG(检索增强生成)方法实现。已在四个不同领域的软件项目上进行了实验，结果证明了通过Gemini 2.5推理模型提出的该方法在各种领域准确识别广泛可持续性问题的有效性。
### Conclusion
SEER框架有效地解决了软件开发早阶段的可持续性问题，提升了需求工程中的可持续性评估和优化，有助于实现联合国可持续发展目标。
## 124. `cs.AI` - 使用混合模型进行非监督语音去混响 [PDF](https://arxiv.org/pdf/2510.09025), [HTML](https://arxiv.org/abs/2510.09025)
### Authors
Louis Bahrman(IDS, S2A),Mathieu Fontaine(IDS, S2A),Gaël Richard(IDS, S2A)
### Background
大多数现有的算法依赖于配对的干燥/混响语音数据，但这种数据很难获取。本文提出了一种新的训练策略，可以在没有干燥和混响配对数据的情况下，仅利用有限的声学信息（如混响时间RT60）来提高语音去混响系统的性能。
### Innovation
提出了一个全新的不需要干燥/混响配对数据的非监督训练策略。该方法使用有限的声学信息（如混响时间RT60）来训练去混响系统，相较于现有技术，方法能够在多种客观度量标准上实现更一致的性能。
### Conclusion
实验结果表明，本文提出的方法在各种客观指标上比当前最先进的技术能实现更一致的性能提升。
## 125. `cs.AI` - DiTSinger: 使用扩散变换器和隐式对齐扩展歌声合成 [PDF](https://arxiv.org/pdf/2510.09016), [HTML](https://arxiv.org/abs/2510.09016)
### Authors
Zongcai Du,Guilin Deng,Xiaofeng Guo,Xin Gao,Linke Li,Kaichang Cheng,Fubo Han,Siyu Yang,Peng Liu,Pan Zhong,Qiang Fu
### Background
基于扩散的歌声合成（SVS）取得了显著进展，但在数据稀缺和模型可扩展性方面仍存在局限性。现有的SVS方法在表达能力方面很强，但在大规模应用中受到数据不足和模型复杂度的限制。因此，需要一种新的方法来解决这些问题并提高合成声音的质量和可靠性。
### Innovation
本文提出了一种两阶段管道：通过将固定旋律与多样化的LLM生成歌词配对构建紧凑的人类演唱录音种集，然后训练旋律特异模型，生成超过500小时的高质量中文歌唱数据。在此基础上，提出了一种新型扩散变换器DiTSinger，该模型通过序列深度、宽度和分辨率进行系统扩展，以提高声音合成的保真度。此外，还设计了一种隐式对齐机制，通过在字符级别范围内约束音素到声学的注意力，来替代音素级别的持续时间标签，从而提高在嘈杂或不确定对齐下的鲁棒性。
### Conclusion
大量实验表明，我们的方法可以实现可扩展、无需对齐并且具有高保真的歌声合成。
## 126. `cs.AI` - SQS: 通过稀疏量化子分布进行贝叶斯DNN压缩 [PDF](https://arxiv.org/pdf/2510.08999), [HTML](https://arxiv.org/abs/2510.08999)
### Authors
Ziyi Wang,Nan Jiang,Guang Lin,Qifan Song
### Background
在资源受限设备上部署大型神经网络模型时，压缩神经网络是必要的。现有的方法大都仅采用权重剪枝或低比特量化单独进行，这通常会导致压缩率不高，同时保持性能下降。本文分析了现有技术的局限性及其对神经网络压缩效果的影响。
### Innovation
本文提出了一种新的统一框架——SQS（Simultaneous Quantization and Sparsity），它通过贝叶斯变分学习来同时实现权重的稀疏性和量化。SQS框架通过引入稀疏贝叶斯先验诱导稀疏性，使用高斯混合模型量化权重，从而达到更低的比特精度。理论分析和实验证明，SQS在与现有方法相似的性能下降条件下实现了更高的压缩率。
### Conclusion
本文通过对ResNet、BERT-base、Llama3和Qwen2.5等模型进行压缩实验，验证了SQS方法的有效性。实验表明，SQS方法在保持与现有方法相近性能下降的情况下，实现了更高的压缩率。
## 127. `cs.AI` - 视觉标记的先验不确定性在大型视觉-语言模型中物体幻象中的作用 [PDF](https://arxiv.org/pdf/2510.09008), [HTML](https://arxiv.org/abs/2510.09008)
### Authors
Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun
### Background
大型视觉-语言模型（LVLMs）通过结合视觉编码器（VE）和大型语言模型在多种任务上取得了显著的成功。然而，这些模型仍面临如物体幻象等重要挑战，即它们生成了输入图像中不存在的物体的描述。
### Innovation
作者提出了一种通过修改视觉编码器（VE）的方法来缓解物体幻象问题。这一方法包括利用对抗扰动的代理方法来有效识别不确定性高的视觉标记，并在VE中间层的自注意力过程中遮蔽这些不确定的视觉标记，从而减少其对视觉编码的影响，以减轻幻象问题。研究发现，视觉标记中的先验不确定性与幻象的出现呈正相关，并且在VE早期层中，受小对抗扰动影响下具有广泛表示偏差的视觉标记表明高先验不确定性。实验表明，该方法显著减少了LVLM中的物体幻象现象，并能够与其他先前的工作协同工作。
### Conclusion
该研究通过统计分析验证了视觉标记中的先验不确定性与幻象之间存在关联，并通过构建对抗扰动代理方法和遮蔽不确定视觉标记的自注意力过程，有效降低了物体幻象现象的发生。
## 128. `cs.AI` - Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers [PDF](https://arxiv.org/pdf/2510.09017), [HTML](https://arxiv.org/abs/2510.09017)
### Authors
Rui Bu,Haofeng Zhong,Wenzheng Chen,Yangyan Li
### Background
本文探讨了基于Transformer架构的大模型中存在的极端标记现象，如注意力陷阱和值态漏斗。这些现象会导致模型性能下降、量化精度降低以及解释性减弱，主要原因是模型在学习过程中形成了一种低效的'无操作'行为，即过度关注具有接近零值状态的标记，这会导致模型的注意力分布变得无序且不易解释。
### Innovation
本文提出了一种名为Value-State Gated Attention (VGA)的简单、专用且稳定的架构机制，通过直接打破这种循环来高效地执行'无操作'注意力。VGA引入了一个可学习的数据依赖门控机制，该机制直接从值向量（V）中计算得出，用于调节输出。我们通过理论分析验证，使用自身值来门控值态比基于输入嵌入门控的方法更能有效地解耦值和注意力分数的更新。这一机制为模型提供了一条直接的调节路径，可以让模型根据其发展出的价值表示来抑制标记的贡献。
### Conclusion
我们的实验结果显示，VGA显著缓解了注意力陷阱的形成并稳定了值态规范，从而提高了模型的性能、鲁棒的量化精度和解释性。
## 129. `cs.AI` - 情感分离嵌入对齐：噪声鲁棒和跨语料库的语音情绪识别 [PDF](https://arxiv.org/pdf/2510.09072), [HTML](https://arxiv.org/abs/2510.09072)
### Authors
Upasana Tiwari,Rupayan Chakraborty,Sunil Kumar Kopparapu
### Background
在真实世界场景中，语音情绪识别的有效性常常受到噪声环境和数据集间变异性的影响。
### Innovation
该论文提出了一种两步方法，通过改进表示学习提高语音情绪识别模型的鲁棒性和泛化能力。首先，模型使用情感分离表示学习（EDRL）提取类别特定的判别性特征，同时保留跨情绪类别之间的共同相似性。其次，多块嵌入对齐（MEA）通过将这些表示投影到与原始语音输入最大化协方差的联合判别潜在子空间中来优化这些表示。通过此类表示学习得到的EDRL-MEA嵌入在干净样本上训练情绪分类器，并在未见过的噪声和跨语料库语音样本上进行评估。
### Conclusion
在这些具有挑战性的条件下获得的性能改进表明了该方法的有效性。
## 130. `cs.AI` - 智能总体约束博弈强化学习方法确保自主驾驶系统的鲁棒性控制 [PDF](https://arxiv.org/pdf/2510.09041), [HTML](https://arxiv.org/abs/2510.09041)
### Authors
Junchao Fan,Xiaolin Chang
### Background
深度强化学习（DRL）在自主驾驶策略开发中取得了显著的成功，然而其对对抗攻击的脆弱性仍然是实际部署中的关键障碍。尽管现有的一些健足足措施已经取得了成功，但仍面临三个关键问题：（i）这些方法主要针对短视的对抗攻击进行训练，限制了它们应对更有策略性的威胁的能力；（ii）它们难以引发真正安全关键的事件（例如碰撞），但通常会导致较小的后果；（iii）这些方法在训练过程中由于缺乏健壮的约束而可能引入学习不稳定性及策略偏移。
### Innovation
本文提出了一种新型的鲁棒自主驾驶方法——智能总体约束博弈强化学习（IGCARL），它包含一个策略性目标攻击者和一个鲁棒驾驶代理。策略性目标攻击者利用DRL在时间决策中的能力，执行策略性的多步攻击。此外，它明确旨在通过采用总体博弈目标来引发安全关键的事件。鲁棒驾驶代理通过与攻击者互动来学习，开发针对对抗攻击的稳健自主驾驶策略。为了保证在对抗环境中的稳定学习并减轻攻击引起的策略偏移，代理在受约束的表达式下得到了优化。
### Conclusion
实验结果表明，IGCARL相较于最先进的方法成功概率提高了至少27.9%，展现了对对抗攻击的更高鲁棒性，并增强了基于DRL的自主驾驶的安全性和可靠性。
## 131. `cs.AI` - 训练模型从人类反应中检测递进的机器人错误 [PDF](https://arxiv.org/pdf/2510.09080), [HTML](https://arxiv.org/abs/2510.09080)
### Authors
Shannon Liu,Maria Teresa Parreira,Wendy Ju
### Background
随着机器人越来越多地融入社会，检测机器人错误对于有效的机器人-人类交互（HRI）至关重要。当机器人反复失败时，它应该如何知道何时改变行为？人类通过口头和非口头的反应对机器人错误做出自然回应，这些反应会随着失败的发生而加剧，从困惑和微妙的言语变化到明显的愤怒和急躁。
### Innovation
这项研究利用机器学习来识别从人类反应中机器人的失败阶段。在一项涉及26名参与者的实验中，研究人员从机器人重复对话错误的视频数据中提取行为特征，训练用户模型。最佳模型在检测错误方面达到了93.5%的准确率，在分类连续错误方面达到了84.1%的准确率。通过建模人类反应的进展，增强了错误检测，并有助于理解HRI中反复互动中断的理解。
### Conclusion
这项研究表明，通过训练模型从人类反应中检测递进的机器人错误，可以提升错误检测的准确率和理解反复交互中断的过程。
## 132. `cs.AI` - MemLoss: 利用循环利用对抗样本增强对抗训练 [PDF](https://arxiv.org/pdf/2510.09105), [HTML](https://arxiv.org/abs/2510.09105)
### Authors
Soroush Mahdi,Maryam Amirmazlaghani,Saeed Saravani,Zahra Dehghanian
### Background
对抗训练是提升机器学习模型对抗对手攻击能力的重要方法之一，但传统的对抗训练往往会在提升模型对抗性鲁棒性的同时，导致模型在干净数据上的性能下降。
### Innovation
提出了一个新的方法叫做MemLoss，该方法通过利用之前生成的对抗样本（称为'记忆对抗样本'）来增强模型的鲁棒性和准确性，而不影响其在干净数据上的性能。MemLoss通过在多个训练周期中使用这些样本，提供了一个在自然准确性提升的同时提高对抗鲁棒性的平衡。
### Conclusion
在CIFAR-10等多个数据集上的实验结果表明，MemLoss方法在保持强对抗鲁棒性的同时，能比现有的对抗训练方法实现更好的准确率。
## 133. `cs.AI` - 利用标识符替换实现LLM成本效益高的长代码翻译 [PDF](https://arxiv.org/pdf/2510.09045), [HTML](https://arxiv.org/abs/2510.09045)
### Authors
Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta
### Background
在软件开发领域，大型语言模型（LLMs）已被用于自动化代码翻译等任务，即将一种编程语言的源代码翻译成另一种语言并保留其功能。然而，LLMs 在处理长源代码时经常遇到问题，因为长代码往往难以完全容纳在模型的上下文窗口中，这导致翻译结果不够准确。针对这一挑战，本研究提出了一种新的零样本代码翻译方法，该方法结合了标识符替换技术，通过在翻译过程中用通用占位符替换用户提供的长标识符，从而帮助模型关注代码的逻辑结构，减少令牌数量和内存使用量，提高长代码翻译的效率和成本效益。实验结果表明，该方法能保留语法和层次信息，并生成具有较少令牌数的翻译结果。
### Innovation
本研究提出了一种新的零样本代码翻译方法，通过在翻译过程中用通用占位符替换长标识符，以减少模型的输入量并优化模型处理长代码的能力。这种技术不仅能提高翻译的准确性，还能大幅度减少翻译过程中的计算开销，从而实现成本效益更高的代码翻译。该方法致力于解决LLMs在处理长代码时面临的典型问题，通过标识符替换，克服了模型上下文窗口的限制，为软件开发中的代码翻译任务提供了新的策略。这种方法的创新点在于利用标识符替换技术降低了长代码翻译的难度和计算复杂度，使模型能够更有效地处理较长的源代码。
### Conclusion
本研究提出了一种新的标识符替换技术，用于解决LLMs在处理长代码时的翻译准确性问题。通过在翻译过程中引入标识符替换，该方法能够有效减少模型的上下文压力和内存使用，从而提高翻译效率，降低成本。实验结果表明，该方法可以较好地保留源代码的语法和结构信息，同时生成较少的翻译结果。这种技术对软件开发领域的自动化代码翻译具有重要意义，有助于提升代码翻译的质量和效率。
## 134. `cs.AI` - Alif: 通过多语言合成数据蒸馏提升乌尔都语大型语言模型 [PDF](https://arxiv.org/pdf/2510.09051), [HTML](https://arxiv.org/abs/2510.09051)
### Authors
Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq
### Background
开发适用于低资源语言（如乌尔都语）的高性能大型语言模型（LLMs）面临诸多挑战，包括高质量数据的稀缺性、多语言一致性问题以及安全问题。现有的多语言LLMs往往通过翻译大量可用的数据来应对这些问题，但这样的翻译往往缺乏质量、文化细微之处，并且还会产生巨大的数据整理和培训成本。这些不足之处使得需要提出一种新的方法来解决这些问题。
### Innovation
本文提出了一种名为Alif-1.0-8B-Instruct的多语言乌尔都语-英语模型，该模型采用了一种独特的方法对抗这些挑战。通过使用修改后的self-instruct技术，该模型被训练在一个高质量的多语言合成数据集（Urdu-Instruct）上，这个数据集包括乌尔都语母语链式推理、双语翻译、文化相关性和伦理安全对齐。这种技术显著增强了Alif-1.0-8B-Instruct模型在乌尔都语特定任务中的理解能力，相比Llama-3.1-8B-Instruct以及包括Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct和Cohere-Aya-Expanse-8B在内的领先多语言LLMs，它在培训预算低于100美元的情况下都表现更优。文章证明了使用我们修改的self-instruct方法可以高效地构建出高性能和低资源语言LLMs，并且这些模型可以实现文化对齐。
### Conclusion
本研究通过使用修改的self-instruct方法开发了高质量的多语言合成数据集，并以此为基础训练了一个多语言乌尔都语-英语模型Alif-1.0-8B-Instruct，该模型在乌尔都语特定任务上的表现优于现有模型，并且在培训成本上具有优势。这种新的建模方法和数据集开发策略可以为低资源语言的LLM开发提供一种更高效和文化对齐的方式。所有数据集、模型和代码都已公开展示。
## 135. `cs.AI` - 当机器人比人类更强大时：从受限示范者学习 [PDF](https://arxiv.org/pdf/2510.09096), [HTML](https://arxiv.org/abs/2510.09096)
### Authors
Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık
### Background
当前的研究使用教学示例让专家能够通过诸如示教操作、摇杆控制和模拟到现实场景的转移来向机器人教授复杂的任务。然而，这些互动方式常常限制了专家演示最优行为的能力，主要原因包括间接操控、设置限制和硬件安全问题。例如，摇杆仅能在二维平面上移动机械臂，即便机器人在更高维度的空间中操作。因此，受限专家收集的示范导致机器学习的策略表现欠佳，这一问题引发了新的研究 questions：机器人能否比受限的人类专家演示出更好的策略？
### Innovation
本文提出的方法允许智能体不仅模仿专家动作，还探索更短、更高效的路径。通过使用专家示范来推断单状态奖励信号，衡量任务进展，并使用时域插值自标注未知状态的奖励。这种新方法在样本效率和任务完成时间上都优于传统的模仿学习。
### Conclusion
该方法在实际操作的 WidowX 机械臂上完成任务的速度是行为克隆的10倍，仅需12秒，并且在展示视频中展示了这一结果。
## 136. `cs.AI` - 人工智能与人类监督：一种基于风险的对齐框架 [PDF](https://arxiv.org/pdf/2510.09090), [HTML](https://arxiv.org/abs/2510.09090)
### Authors
Laxmiraju Kandikatla,Branislav Radeljic
### Background
随着人工智能技术的不断发展，保护人类自主权和促进公正决策是建立信任和责任的关键。人工智能系统应该积极保护和增强人类自主权。本文探讨了设计符合基本权利、强化人类自主权并嵌入有效的人类监督机制的人工智能系统的策略。它讨论了关键的监督模型，包括人类在控制系统（HIC）、人类在环控制（HITL）和人类在环控制（HOTL），并提出了一种基于风险的框架来指导这些机制的应用。通过将人工智能模型的风险级别与适当的人类监督形式联系起来，本文强调了人类在负责任部署人工智能中的关键作用，平衡技术创新与保护个人价值观和权利之间的关系，从而确保人工智能技术的合理使用，同时最大限度地保护个人自主权并促进社会利益。
### Innovation
本文提出了一种基于风险的框架来指导人类监督机制的应用，通过将人工智能模型的风险级别与适当的人类监督形式联系起来，强调了人类在负责任部署人工智能中的关键作用，平衡了技术创新与保护个人价值观和权利之间的关系。
### Conclusion
本文旨在确保人工智能技术的合理使用，同时最大限度地保护个人自主权并促进社会利益，通过提出的基于风险的框架指导人类监督机制的应用，强化了对人类自主权和公平决策的支持，并实现了人工智能技术与个人价值观和权利之间的对齐。
## 137. `cs.AI` - 隐私保护的公平性：测量和减轻差异隐私机器学习中组隐私风险差距 [PDF](https://arxiv.org/pdf/2510.09114), [HTML](https://arxiv.org/abs/2510.09114)
### Authors
Zhi Yang,Changwu Huang,Ke Tang,Xin Yao
### Background
虽然在传统公平感知机器学习（ML）和差异隐私机器学习（DPML）方面取得了显著进展，但不同群体之间的隐私保护公平性仍未得到充分研究。现有研究提出了一些评估群体隐私风险的方法，但这些方法基于数据记录的平均隐私风险。这种方法可能低估了群体之间的隐私风险差异，从而导致低估不同群体之间的隐私风险差异。此外，目前评估数据记录最坏情况隐私风险的方法耗时较长，限制了其实际应用。
### Innovation
本文介绍了一种新的成员推断游戏，可以高效地审计数据记录的近似最坏情况隐私风险。实验结果表明，该方法提供了一个更严格的群体隐私风险度量，能够可靠地评估群体隐私风险差异。此外，为了在DPML中促进隐私保护公平性，本文基于差异隐私审计研究中麻雀的策略设计，增强了标准的DP-SGD算法，引入了一个适应性群体特定梯度剪辑策略，该策略能够有效减少群体之间隐私风险的差异，提高DPML中隐私保护的公平性。
### Conclusion
我们的方法提供了一种更加严格的群体隐私风险度量，能够可靠地评估群体隐私风险差异。我们的算法有效地减少了群体之间隐私风险的差异，提高了隐私保护在DPML中的公平性。
## 138. `cs.AI` - controlled personalization in legacy media online services: a case study in news recommendation [PDF](https://arxiv.org/pdf/2510.09136), [HTML](https://arxiv.org/abs/2510.09136)
### Authors
Marlene Holzleitner,Stephan Leitner,Hanna Lind Jorgensen,Christoph Schmitz,Jacob Welander,Dietmar Jannach
### Background
个性化新闻推荐已成为大型新闻聚合服务的标准功能，通过自动化内容选择优化用户参与度。相比之下，传统的新闻媒体通常谨慎地对待个性化，力求在技术创新与核心编辑价值之间找到平衡。因此，传统新闻机构的在线平台通常会结合编辑精选的内容与算法推荐的文章，这是一种我们称之为受控个性化的方法。
### Innovation
在这篇行业论文中，通过对一家挪威大型传统新闻机构网站进行A/B测试评估了受控个性化的效果。研究发现即使是一种适度的个性化也能带来显著的好处。用户接触个性化内容后，点击率更高，导航更加便捷，有助于发现相关内容。此外，分析还表明，受控个性化有助于提升内容多样性，扩大内容目录覆盖范围，并减少内容流行度偏见。
### Conclusion
总体而言，研究结果表明受控个性化可以成功地将用户需求与编辑目标结合起来，为传统媒体提供了一条在保持新闻价值的同时采用个性化技术的可行路径。
## 139. `cs.AI` - SOS: 合成对象分割提高检测、分割和语义定位 [PDF](https://arxiv.org/pdf/2510.09110), [HTML](https://arxiv.org/abs/2510.09110)
### Authors
Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna
### Background
视觉分组通过实例分割、视觉定位和目标检测实现，支撑着从机器人感知到照片编辑的应用。然而，大型注释数据集成本高昂、偏见严重且难以扩展。合成数据虽然有潜力，但往往缺乏灵活性、准确性和构配件多样性。为了解决这一问题，本文介绍了一种基于对象中心重组策略的简单且可扩展的数据合成管道SOS。该管道使用结构化的布局先验和生成性光照，并将高质量的合成对象分割粘贴到新的图像中，生成了准确且多样的掩码、框和引用表达。
### Innovation
SOS提出了一个基于对象中心重组策略的数据合成管道，通过结构化布局先验和生成性光照将高质量合成对象分割粘贴到新图像中，生成准确且多样的掩码、框和引用表达。实验结果显示，使用10万个SOS合成图像训练的模型在检测和定位任务上优于基于更大真实图像数据集GRIT（2000万）和V3Det（20万）训练的模型，分别在LVIS检测上提高了10.9个AP分，在gRefCOCO定位上提高了8.4个$N_{text{Acc}}$。SOS使得数据集的可控构造成为可能，并在低数据量和封闭词汇量环境中提高了泛化能力。结合LVIS和COCO的合成对象分割使真实数据规模下的性能大幅提升，甚至在极其有限的真实数据设置下（如LVIS实例分割中+3.83个$AP_{text{rare}}$和COCO设置中+6.59个AP），也能获得更大增益。这种可控性还支持针对视觉定位中具有挑战性的类内引用生成。
### Conclusion
SOS通过生成准确且多样的合成对象切分图像，显著提升了检测、分割和语义定位等多种视觉任务的性能。该方法的可控性使其能够针对具有挑战性的类内引用生成生成数据，增强在数据稀缺情况下的泛化能力。
## 140. `cs.AI` - MSDM：使用多模态条件扩散模型生成用于细胞和核分割的特定任务病理图像 [PDF](https://arxiv.org/pdf/2510.09121), [HTML](https://arxiv.org/abs/2510.09121)
### Authors
Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu
### Background
在计算病理学中，注释数据的稀缺性，尤其是罕见或非典型形态的数据，构成了细胞和核分割的显著挑战。手工注释耗费大量人力和成本，而合成数据则提供了一种经济有效的替代方案。
### Innovation
我们提出了一个多模态语义扩散模型（MSDM），用于生成具有像素级精确度的图像-掩模对，以支持细胞和核分割。该模型通过细胞/核形态、RGB色彩特性和BERT编码的实验/指示元数据进行条件化生成，使得生成的数据集具有所需的形态学属性。利用多头跨注意力机制整合这些多模态信息，使得生成的图像具有精细的控制力。定量分析表明，生成的图像与真实数据高度相似，具有低的Wasserstein距离，并且将这些合成样本应用于柱状细胞的实例显著提高了细胞分割模型的准确性。这种策略系统地丰富了数据集，针对性地弥补了模型的不足。
### Conclusion
我们展示了多模态扩散增广策略在提升细胞和核分割模型的稳健性和泛化能力方面的有效性。因此，我们为生成模型在计算病理学中的广泛应用铺平了道路。
## 141. `cs.AI` - 保护患者隐私的联邦数据分析平台：用于癌症免疫治疗的协作管理 [PDF](https://arxiv.org/pdf/2510.09155), [HTML](https://arxiv.org/abs/2510.09155)
### Authors
Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal
### Background
连接健康是一种多学科方法，侧重于患者需求，促进工具、服务和治疗的创建。该范式通过有效的信息交换，确保护理连续性中的所有参与者能够进行及时有效的护理。数字技术和流程创新的兴起有望通过整合各种医疗数据源，提高连接健康的效果，进而个性化护理、预测健康结果并简化患者管理。然而，数据架构、应用程序互操作性和安全问题依然存在挑战。
### Innovation
本文介绍了一种协作数字框架，通过联邦大数据分析和人工智能，加强了决策支持，同时确保了隐私性。该框架利用敏捷的系统开发生命周期，在一个由欧盟资助的项目中开发，旨在为接受免疫治疗的癌症患者开发集成的人工智能生成的解决方案。
### Conclusion
研究通过实际数据验证了分析能力，如治疗推荐和不良事件预测，试点研究中达到了70%-90%的准确性，证明了此框架的有效性。
## 142. `cs.AI` - 现代深度学习方法在板球击球分类中的全面基准研究 [PDF](https://arxiv.org/pdf/2510.09187), [HTML](https://arxiv.org/abs/2510.09187)
### Authors
Sungwoo Kang
### Background
板球击球从视频序列中的分类仍然是体育视频分析中的一个挑战性问题，需要有效地建模空间和时间特征。
### Innovation
本文首次全面比较了七种不同的深度学习方法在四种不同的研究范式下的板球击球分类基准研究。这些方法包括传统的CNN-LSTM架构、注意力模型、视觉变压器、迁移学习方法和现代的EfficientNet-GRU组合。结果显示，与学术文献中的声称相比，实际实施结果之间的性能差距显著。本文提出了现代最先进的方法，结合EfficientNet-B0和基于GRU的时间模型，实现了92.25%的准确率，这表明了现代架构和系统优化能带来显著的改进。
### Conclusion
所有实现都遵循了现代的MLOps实践（使用PyTorch Lightning），提供了一个可重复的研究平台，突显了标准化评估协议在体育视频分析研究中的关键重要性。
## 143. `cs.AI` - 有关深度持续学习中灾难性遗忘的隐含对抗性 [PDF](https://arxiv.org/pdf/2510.09181), [HTML](https://arxiv.org/abs/2510.09181)
### Authors
Ze Peng,Jian Zhang,Jintao Guo,Lei Qi,Yang Gao,Yinghuan Shi
### Background
持续学习旨在使机器智能获得类似人类的能力，即不断积累新的技能。其核心挑战是灾难性遗忘，即在学习新任务时忘记旧任务的知识。对于深度网络而言，灾难性遗忘的具体原理尚未完全阐明。
### Innovation
本文揭示了新任务训练实际上是对旧任务知识的一种隐含对抗攻击。具体而言，新任务梯度会自动且精确地与旧任务损失景观中的尖锐方向对齐，迅速增加旧任务的损失。此外，本文理论证明该现象来源于训练过程的低秩偏差，通过前向和反向传播，限制两个方向在同一低维子空间中，从而促进对齐。为了应对该问题，本文提出了一种新的方法backGP，它通过减少由反向传播引起的对抗性对齐来减少遗忘，从而平均提高了10.8%的保留率和12.7%的准确性。
### Conclusion
本文通过揭示新任务训练对旧知识的对抗性影响，提供了对灾难性遗忘机制的新见解，并提出了backGP方法来缓解这一问题，实验结果表明该方法有效提升了学习保留率和准确性。
## 144. `cs.AI` - 时间序列电子健康记录跨表示基准测试以预测临床结果 [PDF](https://arxiv.org/pdf/2510.09159), [HTML](https://arxiv.org/abs/2510.09159)
### Authors
Tianyi Chen,Mingcheng Zhu,Zhiyao Luo,Tingting Zhu
### Background
电子健康记录（EHRs）可以用于临床预测任务，但如何最佳地表示患者数据仍不清楚，因为各种评价方法不一致。本文介绍了一个系统基准，比较了EHR表示方法，包括多元时间序列、事件流和语言模型处理的文本事件流。该研究在两种不同的临床环境中标准化了数据处理与评价流程，分别是MIMIC-IV数据库用于ICU任务（死亡率、表型诊断）和EHRSHOT数据库用于纵向护理（30天再入院、1年胰腺癌）预测。
### Innovation
本文提出了一个首次系统基准，比较了不同时间序列、事件流和语言模型处理的文本事件流的EHR表示方法。研究评估了适用于每种模式的模型家族（如变压器、MLP、LSTM和Retain用于时间序列，CLMBR和计数基础模型用于事件流，8-20B语言模型用于文本流），并分析了基于数据缺失性的特征剪枝对性能的影响。研究发现事件流模型在性能上表现最稳定，预训练模型（如CLMBR）在少量样本设置下样本效率高，但在数据充足的情况下，简单的计数基础模型也很有竞争力。此外，研究发现特征选择策略需适应临床情境：对于ICU预测，稀疏特征的剪枝改善效果，而对于纵向任务，则需保留这些特征以提高预测效果。
### Conclusion
通过统一和可重复的流程，本文的研究结果提供了基于临床背景和数据状况选择EHR表示的具体指导。
## 145. `cs.AI` - 多模态提示优化：为什么不对MPLLMs利用多种模态 [PDF](https://arxiv.org/pdf/2510.09201), [HTML](https://arxiv.org/abs/2510.09201)
### Authors
Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）取得了显著的成功，其多模态扩展（MLLMs）进一步解锁了除文本之外的图像、视频等其他模态的能力。然而，尽管出现了这一转变，目前用于减少手动提示设计负担并最大化性能的提示优化方法仍然局限于文本，限制了MLLMs的全部潜能。
### Innovation
为了弥合这一差距，作者提出了新的多模态提示优化问题，将提示优化的定义扩展到了由文本和非文本提示对定义的多模态空间中。作者还提出了一种名为Multimodal Prompt Optimizer (MPO) 的统一框架，既通过保持对齐的更新执行多模态提示的联合优化，又通过在贝叶斯基础上利用先前评估作为先验来指导候选提示的选择过程。
### Conclusion
通过在文本之外的图像、视频甚至分子等多种模态上进行广泛的实验，证明了MPO 在多模态提示优化方面优于现存的只对文本进行优化的方法，确立了多模态提示优化是实现MPLLMs潜能的关键一步。
## 146. `cs.AI` - 朝向更安全、可解释性的驾驶员意图预测 [PDF](https://arxiv.org/pdf/2510.09200), [HTML](https://arxiv.org/abs/2510.09200)
### Authors
Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar
### Background
随着自主驾驶（AD）系统的不断进步，特别是深度学习和人工智能的最新进展，这些系统越来越擅长处理复杂任务。然而，随着人机交互的增加，提高决策过程的可解释性变得尤为重要，这对确保驾驶安全至关重要。现有的模型难以理解驾驶环境和任务的底层表示，这在基于深度学习的系统中是一个巨大挑战。本文在驾驶机动发生前，提出了对驾驶员意图预测（DIP）的理解性任务，这在AD系统中扮演着重要角色。研究团队为此创建了eXplainable Driving Action Anticipation Dataset (DAAD-X)，一个包含多层次、高级文本解释的新多模态、以自我为中心的视频数据集，这些解释来自驾驶员的凝视和以自我为中心的视角。
### Innovation
本文提出了一种Video Concept Bottleneck Model (VCBM)框架，它能够直接生成时空上一致的解释，而不依赖于后处理技术。通过在DAAD-X数据集上的广泛评估显示，基于Transformer的模型在解释性方面优于传统的基于CNN的模型。此外，还介绍了一种多标签t-SNE可视化技术，用于展示多种解释之间的脱散和因果关系。
### Conclusion
本文通过创建DAAD-X数据集并引入VCBM框架，展示了基于Transformer的模型在解释性上的优势，并通过多标签t-SNE可视化技术详细说明了各种解释之间的因果关系。此外，数据、代码和模型均可在相关链接处获取。
## 147. `cs.AI` - DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction [PDF](https://arxiv.org/pdf/2510.09211), [HTML](https://arxiv.org/abs/2510.09211)
### Authors
Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang
### Background
大型语言模型（LLMs）在处理具有特定用户需求的任务时，往往会优先考虑推理而忽视详细指令的遵守。传统的对LLMs进行微调的方法由于高计算成本和参数访问限制而变得不切实际。为此，需要一种既能保留模型广泛知识和推理能力，又能确保输出满足用户需求的方法。
### Innovation
提出了DICE，这是一种轻量级框架，通过引导小型语言模型（SLMs）进行基于推理链条（CoT）的校正来改进大型语言模型的输出。DICE框架分为两个阶段：首先，使用自然语言生成促使LLMs生成自然语言响应。然后，使用预训练的SLMs分析这些输出并进行修正以符合结构化输出规范。开发了一种双调优策略，并构建了带注解的结构化CoT数据集，以提高LLMs输出格式准确性和内容正确性。
### Conclusion
实验结果表明，与现有基线相比，DICE在形式准确性和内容正确性方面分别提高了35.4%和29.4%，实现了最先进的性能（SOTA）。
## 148. `cs.AI` - 明路清晰：智能交通中的多天气场景图像和视频恢复进展 [PDF](https://arxiv.org/pdf/2510.09228), [HTML](https://arxiv.org/abs/2510.09228)
### Authors
Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala
### Background
恶劣天气条件，如雾霾、雨雪等显著降低了图像和视频的质量，对依赖视觉输入的智能交通系统（ITS）构成了严重挑战。这些降级影响到诸如自动驾驶、交通监控和安全监视等关键应用。
### Innovation
该论文全面回顾了用于减轻由天气引起的视觉障碍的图像和视频修复技术的发展。将现有方法分为传统的基于先验的方法和现代的数据驱动模型，包括CNNs、变压器、扩散模型和新兴的视觉-语言模型（VLMs）。进一步根据修复策略的范围将其分类为单一任务模型、多任务或多天气系统以及能够处理各种降级的综合框架。讨论了白天和夜间修复挑战、基准数据集和评估协议。
### Conclusion
论文总结指出，现有研究中存在的局限性，并提出未来研究方向，如混合/复合降级恢复、实时部署和能动AI框架。该工作旨在为智能交通环境中更抗恶劣天气的视觉系统的发展提供有价值的参考。最后，为保持最新进展，将定期更新相关的最新论文及其开源实现：this https URL
## 149. `cs.AI` - CrisiText: 用于紧急通信中LLM训练的警报消息数据集 [PDF](https://arxiv.org/pdf/2510.09243), [HTML](https://arxiv.org/abs/2510.09243)
### Authors
Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini
### Background
危机情况下有效地识别威胁并减轻潜在损害对于保护处于危险中的个人至关重要。尽管AI已经在紧急情况下辅助人类，但NLP技术的应用仍然有限，主要集中在分类任务上。然而，使用自然语言生成（NLP）架构及时生成警告信息的巨大潜力却被忽视了。因此，需要一个大规模的数据集来支持警告消息的生成，以应对13种不同类型危机的情境。
### Innovation
本文介绍了CrisiText，这是首个大规模的警告消息数据集，旨在生成适用于13种不同类型的危机警告信息，包含超过400,000条警告消息（覆盖近18,000个危机情境）。该数据集的生成涉及从现有危机描述开始，创建与场景相关的事件链，每个事件配对一条警告信息，并且每条警告信息都遵循专家撰写的指导方针，确保术语的正确和建议的真实。此外，每条消息还附带三种不理想的警告类型，以研究不同NLP方法。实验比较了监督微调设置与偏好对齐、零样本和少量样本方法，并评估了在分布外场景中的模型性能以及自动后编辑的有效性。
### Conclusion
研究人员通过CrisiText数据集和一系列实验证明，可以使用更精细的方法训练大规模语言模型（LLM），有效生成针对紧急情况的警告信息。
## 150. `cs.AI` - 在大规模语言模型的强化学习后训练中检测数据污染 [PDF](https://arxiv.org/pdf/2510.09259), [HTML](https://arxiv.org/abs/2510.09259)
### Authors
Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li
### Background
数据污染对大规模语言模型（LLMs）的可靠评估构成了重大威胁。这主要是因为基准样本可能意外地出现在训练集中，从而损害了报告的性能的有效性。虽然已经开发了预训练和监督微调阶段的检测方法，但对于日益重要的强化学习（RL）后训练阶段，缺乏专门的污染检测方法。由于RL后训练对于推进LLM推理至关重要，因此这一范式中缺乏专门污染检测方法的现状构成了一个关键的漏洞。
### Innovation
我们进行了首次针对RL后训练场景的数据检测系统研究，并提出了一种名为Self-Critique的方法。该方法基于如下关键观察：在RL阶段之后，LLM的输出熵分布趋向于崩溃，呈现出特定且稀疏的模式。Self-Critique通过探测潜在的策略崩溃，即模型收敛到狭窄的推理路径，来寻找这种熵减少。为了支持这一研究，我们还在RL-MIA基准中构建了模拟这种特定污染场景的环境。广泛的实验表明，Self-Critique在多个模型和污染任务上显著优于基线方法，AUC改善高达30%。相比之下，现有方法对于RL阶段的污染检测接近随机猜测，而我们的方法则使得检测成为可能。
### Conclusion
我们提出了Self-Critique，一种专门针对RL后训练场景的数据污染检测方法。该方法通过检测策略崩溃来有效识别数据污染，显著提高了检测性能。
## 151. `cs.AI` - 使用多模态大型语言模型和消费级相机诊断肩部疾病 [PDF](https://arxiv.org/pdf/2510.09230), [HTML](https://arxiv.org/abs/2510.09230)
### Authors
Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun
### Background
肩部疾病，如肩锁冻结（即粘连性肩关节囊炎）是全球范围内影响人们健康的一种常见疾病，并且在老年人和从事重复肩部任务的工作者中发病率较高。在医疗资源稀缺的地区，实现早期和准确诊断面临巨大挑战，迫切需要低成本且易于扩展的辅助诊断解决方案。基于此，研究引入使用消费级设备拍摄的视频进行初步诊断，以减少用户的成本。研究背景在于探索消费级设备拍摄的视频在肩部疾病的初步诊断中的应用，并进一步提出一种结合运动视频诊断框架（HMVDx）的方法，该框架旨在通过多模态大型语言模型实现动作理解与疾病诊断。研究还提出了一种新的可操作性指数（Usability Index），从整个医疗诊断路径的角度评价多模态大型语言模型在医疗领域的应用价值。
### Innovation
研究创新地应用了多模态大型语言模型（MLLMs）在肩部疾病初步诊断中的应用，提出了混合运动视频诊断框架（HMVDx），将动作理解与疾病诊断分别由两个MLLMs完成。此外，研究还提出了一种基于医疗决策过程的新评价指标——可操作性指数（Usability Index），从整个医疗诊断路径的角度评价MLLMs在医疗领域的应用价值。该方法通过实验测试大幅提升肩关节损伤诊断的准确性，展现了低成本多模态大型语言模型在医疗应用中的潜在价值。这项技术为未来在医疗领域应用大型语言模型理解视频带来了重要的技术贡献。
### Conclusion
研究发现，使用混合运动视频诊断框架（HMVDx）诊断肩关节损伤的准确率相比直接视频诊断提高了79.6%，这表明该框架在医疗领域视频理解应用中有显著的技术优势，为未来研究提供了重要的参考。此外，通过提出的可操作性指数，研究揭示了多模态大型语言模型在医疗诊断中的潜在价值，并为医疗工作者提供了新的评估工具。
## 152. `cs.AI` - 使用动态运动模型和强化学习的避障 [PDF](https://arxiv.org/pdf/2510.09254), [HTML](https://arxiv.org/abs/2510.09254)
### Authors
Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa
### Background
基于学习的运动规划能够快速生成接近最优轨迹，但通常需要大型训练数据集或昂贵的人类演示收集。这项研究提出了一种新的方法，该方法可以从单一个人工演示快速生成平滑且接近最优的无碰撞3D笛卡尔轨迹。该演示被编码为动态运动原型（DMP），并通过基于策略的强化学习迭代重塑，从而生成适用于不同障碍配置的多样轨迹数据集。这些数据集用于训练神经网络，该网络接受描述障碍物尺寸和位置的任务参数作为输入（这些参数是从点云自动提取的），并输出生成轨迹的DMP参数。这些研究是在模拟和真实机器人实验中进行验证的，结果表明这种方法在计算时间和执行时间上优于RRT-Connect基线，同时支持不同障碍几何形状和末端执行器尺寸的多模态轨迹生成。相关视频和实现代码可以在指定链接找到。
### Innovation
该方法能够从单一个人工演示生成多样化的无碰撞3D笛卡尔轨迹，并利用动态运动原型（DMP）和基于策略的强化学习技术对该轨迹进行迭代重塑。这种方法能够快速生成适应不同障碍物配置的近最优轨迹，并通过神经网络直接从点云数据自动提取任务参数进行计算，从而大大减少了数据集的需求和成本。此外，该方法能够支持多模态轨迹生成，以适应不同的障碍物几何形状和末端执行器尺寸。该工作验证了该方法在模拟和真实机器人实验中的有效性，与RRT-Connect基线相比，具有更短的轨迹长度和更快的计算及执行速度。
### Conclusion
通过从单一人经演示中快速生成近最优的3D笛卡尔轨迹，并通过动态运动原型（DMP）和基于策略的强化学习进行优化，本文提出的方法显著改善了运动规划效率和适应性。实验证明，该方法不仅能够有效避免障碍物，生成平滑的近最优轨迹，而且在计算和执行时间上更胜一筹，有效支持复杂环境中的多模态轨迹生成。
## 153. `cs.AI` - CLARity: 单独的推理一致性可以培训强化专家 [PDF](https://arxiv.org/pdf/2510.09278), [HTML](https://arxiv.org/abs/2510.09278)
### Authors
Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng
### Background
在数据稀缺的领域训练专家级的大语言模型（LLM）具有挑战性，通常依赖于多项选择题（MCQ）。标准基于结果的强化学习（RL）应用于MCQ是具有风险的。虽然可能提高准确性，但我们观察到它经常降低推理质量，例如逻辑一致性。现有的监督推理方法，如大规模过程奖励模型（PRMs），代价高昂。因此，需要一种更经济的方法来提升推理质量。
### Innovation
提出了一种名为CLARity的经济高效RL框架，利用少量的一般用途LLM来增强推理质量而不依赖大规模PRMs。CLARity通过整合一致性意识奖励机制和两阶段精炼然后监控的训练管道来增强推理一致性，并通过动态数据重构成更有效地利用有限的数据。实验表明，与基线相比，CLARity在响应一致性上提高了16.5%，在准确性上提高了7.5%。
### Conclusion
结合人工评估，CLARity证明了整体一致性和专业性的改进。因此，CLARity提供了一种可推广的解决方案，使较小的模型能够有效引导专家模型进行推理。该研究的代码已开源。
## 154. `cs.AI` - SynthID-Image: 在互联网规模上的图像水印 [PDF](https://arxiv.org/pdf/2510.09263), [HTML](https://arxiv.org/abs/2510.09263)
### Authors
Sven Gowal,Rudy Bunel,Florian Stimberg,David Stutz,Guillermo Ortiz-Jimenez,Christina Kouridi,Mel Vecerik,Jamie Hayes,Sylvestre-Alvise Rebuffi,Paul Bernard,Chris Gamble,Miklós Z. Horváth,Fabian Kaczmarczyck,Alex Kaskasoli,Aleksandar Petrov,Ilia Shumailov,Meghana Thotakuri,Olivia Wiles,Jessica Yung,Zahra Ahmed,Victor Martin,Simon Rosen,Christopher Savčak,Armin Senoner,Nidhi Vyas,Pushmeet Kohli
### Background
本文介绍了基于深度学习的SynthID-Image系统，该系统用于在AI生成的图像中隐形地嵌入水印。文章详细记录了在互联网规模上部署此类系统的技术需求、威胁模型和实践挑战，重点关注效果、保真度、鲁棒性和安全性。SynthID-Image已被用于标记超过十亿张图像和视频帧，并在其服务中提供了一个对应的验证服务，供受信任的测试人员使用。本文还介绍了用于合作伙伴的外部模型变体SynthID-O的实验评估，展示了其在视觉质量和鲁棒性方面优于其他文献中的后嵌入水印方法。虽然该研究的重点是视觉媒体，但关于部署、限制和威胁模型的结论适用于其他模态，包括音频。文章提供了大规模部署基于深度学习的媒体来源系统的全面文档。
### Innovation
文章的主要创新在于提出了一种大规模互联网级别部署的基于深度学习的图像水印系统——SynthID-Image，通过该系统实现了高效、高保真度、高鲁棒性和安全性的图像水印技术。此外，通过与合作伙伴提供的外部模型变体SynthID-O的实验，展示了其在视觉质量和对抗常见图像扰动的鲁棒性方面优于已有的方法，达到了最先进的技术水平。
### Conclusion
本文为大规模部署基于深度学习的媒体来源系统提供了全面的文档说明，特别强调了视觉媒体的应用，并指出结论适用于其他模态，如音频。此外，该工作还展示了大规模部署和应用的挑战、需求和技术解决方案。
## 155. `cs.AI` - CapGeo: 基于配对描述的几何推理方法 [PDF](https://arxiv.org/pdf/2510.09302), [HTML](https://arxiv.org/abs/2510.09302)
### Authors
Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang
### Background
几何推理仍然是多模态大型语言模型（MLLMs）的核心挑战。即使如GPT-O3和Gemini-2.5-Pro等最新的闭源系统，在国际数学奥林匹克（IMO）等文本推理任务中表现出色，但在解决几何问题时仍难以可靠地应对。这一差距表明，瓶颈可能在于理解几何图示，而非推理本身。
### Innovation
提出了一种基于配对描述的几何推理框架CapGeo，该框架将视觉和文本模态联系起来。实验表明，当模型带有描述时，性能大大提升，例如Qwen2.5-VL-72B从8.6%提升至59.0%，Claude-Opus-4从44.8%提升至73.0%。同时，作者提出了CapGeo-Bench数据集，包含4,641个精心策划的图描述对，并引入了基于关键点的评价指标，与后续CapGeo性能高度相关，从而可靠评估几何描述能力。
### Conclusion
论文框架和基准数据集共同展示了通往MLLMs中几何推理进步的新途径。
## 156. `cs.AI` - 基于模型驱动工程的AI赋能医疗平台方法 [PDF](https://arxiv.org/pdf/2510.09308), [HTML](https://arxiv.org/abs/2510.09308)
### Authors
Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi
### Background
人工智能（AI）有潜力通过支持更准确的诊断和个性化治疗来变革医疗保健。然而，其实现受到分散数据源、严格的隐私法规和技术构建可靠临床系统的复杂性制约。为了应对这些挑战，我们提出了一种专门用于医疗AI的模型驱动工程（MDE）框架。该框架依赖于形式化的元模型、领域特定语言（DSL）以及自动变换，从高层次规范过渡到运行软件。其核心是医疗互操作性语言（MILA），一种图形DSL，使临床医生和数据科学家能够使用共享本体定义查询和机器学习管道。
### Innovation
提出了一种专门用于医疗AI的MDE框架，核心是医疗互操作性语言（MILA）。MILA是一种图形DSL，使临床医生和数据科学家能够使用共享本体定义查询和机器学习管道。通过与联邦学习架构结合，MILA允许机构在不交换原始患者数据的情况下协作，确保站点间语义一致性，同时保护隐私。
### Conclusion
我们通过多中心癌症免疫治疗研究评估了这一方法。生成的管道表现出强烈的预测性能，支持向量机在关键任务中的准确率高达98.5%和98.3%。同时大幅减少了手动编程的工作，表明了MDE原则——建模、语义集成和自动代码生成为可互操作、可重复和可信的数字健康平台提供了一条实用的路径。
## 157. `cs.AI` - 通过其计算图验证链式思维推理 [PDF](https://arxiv.org/pdf/2510.09312), [HTML](https://arxiv.org/abs/2510.09312)
### Authors
Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda
### Background
当前的链式思维（CoT）验证方法根据模型的输出（黑盒）或激活（灰盒）来预测推理的正确性，但这些方法提供的关于错误原因的见解有限。已有研究集中在基于模型输出或内部激活来评估推理正确性，但未能深入解析推理为何出错的原因。
### Innovation
该研究提出了一种白盒方法：计算电路基础的推理验证（CRV）。作者假设正确的CoT步骤的归因图，作为模型潜在推理电路的执行记录，其结构特征与错误步骤明显不同。通过训练分类器来区分这些图的结构特征，研究表明这些执行记录中存在的推理错误信号非常强大。这种方法提供了通过计算图直接验证推理的新见解，揭示了推理任务中的错误在不同场景下的计算模式差异，并通过针对性干预单一转换器特征修正了模型的错误推理。这种治疗方法从诊断错误走向了理解LLM推理的因果关系层次。
### Conclusion
研究通过详细分析模型的计算过程，证明了可以将简单错误检测提升到对LLM推理更深层次、更因果的理解。
## 158. `cs.AI` - 虚幻的卓越还是真正的表现？通过动态评估重新思考医疗诊断基准 [PDF](https://arxiv.org/pdf/2510.09275), [HTML](https://arxiv.org/abs/2510.09275)
### Authors
Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu
### Background
医疗诊断是一个高风险且复杂的领域，对患者护理至关重要。然而，当前大型语言模型（LLMs）的评估与真实临床实践存在根本性偏差。大多数评估依赖于源于公共医学考试项目的静态基准，这些基准往往高估了模型性能，忽视了教科书病例与现实世界中复杂、多变情况之间的差异。尽管最近的动态评估尝试提供了替代方案，但其改进仅限于表面的变动和对准确度的狭窄关注。这些问题促使研究者开发了DyReMe，一种动态基准应用于医疗诊断，更好地反映了实际临床实践。这种方法通过生成类似于咨询的、包含多个鉴别诊断的鲜活案例，以及模仿多样化的现实中查询习惯来改进评价维度。
### Innovation
提出了DyReMe，一种动态基准，增强了对准确度之外三个临床相关维度的评估，包括真实性、有用性和一致性。DyReMe通过引人干扰诊断和常见误诊因素、变化表达风格来模拟现实世界的各种查询习惯，从而提供更加挑战性和现实的评估。这使得DyReMe相比静态评估方法展现出更强的改进和实用性。
### Conclusion
实验表明，这种方法提供了更加具有挑战性和现实性的评估，揭示了最先进的LLMs在真实世界临床实践中存在的显著表现不匹配。该研究强调了需要更好的评估框架来体现可信医疗诊断的需求。
## 159. `cs.AI` - FLRC：高效大型语言模型推理的细粒度低秩压缩器 [PDF](https://arxiv.org/pdf/2510.09332), [HTML](https://arxiv.org/abs/2510.09332)
### Authors
Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu
### Background
尽管大型语言模型（LLM）已经取得了显著的性能，但由于其庞大的参数数量，它们在资源受限的硬件上部署存在困难。低秩压缩可以减少内存使用和计算需求，但对所有层应用统一的压缩比通常会导致性能显著下降。先前的方法在解码时表现不佳。
### Innovation
为了应对这些问题，我们提出了细粒度低秩压缩器（FLRC），该方法可以为每层高效地确定最优的秩分配，并结合渐进低秩解码来保持文本生成的质量。系统实验证明，FLRC 在摘要是取得高达 ROUGE-L 性能改善 17% 的结果，与最先进的低秩压缩方法相比，建立了更稳健和高效的框架以改进 LLM 推理。
### Conclusion
FLRC 显著提高了 LLM 推理的效率和质量，克服了现有低秩压缩方法在部署上的局限性。
## 160. `cs.AI` - 深-REMAP：使用正则化多任务学习的概率恒星光谱参数化 [PDF](https://arxiv.org/pdf/2510.09362), [HTML](https://arxiv.org/abs/2510.09362)
### Authors
Sankalp Gilda
### Background
在调查数据爆炸的时代，传统的光谱分析方法已经接近极限。为了应对这一挑战，我们开发了深-REMAP这一新型的深度学习框架，该框架利用正则化、多任务的方法，从观测光谱中预测恒星大气参数。
### Innovation
通过使用正则化和多任务的方法，结合非对称损失函数与嵌入损失，我们建立了一个可解释的回归-分类框架，该框架对参数不平衡具有鲁棒性，并能够捕捉非高斯不确定性。此外，该框架不局限于MARVELS调查，而是具有向其他调查扩展的可能性。
### Conclusion
深-REMAP框架为预测恒星大气参数提供了一种强大的自动化途径，通过对标记的MARVELS校准星的验证，其精度达到了如75开尔文的温度的有效恢复。这一方法为恒星表征开辟了一条新的、自动化的发展道路。
## 161. `cs.AI` - 从数据中学习均衡的最优率学习 [PDF](https://arxiv.org/pdf/2510.09325), [HTML](https://arxiv.org/abs/2510.09325)
### Authors
Till Freihaut,Luca Viano,Emanuele Nevali,Volkan Cevher,Matthieu Geist,Giorgia Ramponi
### Background
本研究填补了多智能体模仿学习（MAIL）中的多项理论空白，特别是非交互式MAIL的限制，并提出了第一个具有接近最优样本复杂度的交互式算法。在非交互式设置下，证明了一个统计下界，确定了所有策略偏差集中系数为基本复杂度度量，并证明了行为克隆（BC）算法率最优。在交互式设置中，引入了一种结合无奖励强化学习与交互式MAIL的框架，并实例化为名为MAIL-WARM的算法。这个算法将已知的最佳样本复杂度从$text{O}(ε^{-8})$提升到$text{O}(ε^{-2})$，这与我们存在的下界中的$text{ε}$的依赖性一致。
### Innovation
研究填补了一个开放的理论空白，并首次提出了样本复杂度接近最优的交互式MAPL算法。在非交互式情况下，证明并确定了所有策略偏差集中系数作为基本复杂度措施，同时证明了行为克隆（BC）算法率最优。在交互式情况下，结合无奖励强化学习与交互式MAIL，引入了名为MAIL-WARM的算法，将先前最好的样本复杂度从$text{O}(ε^{-8})$提升到$text{O}(ε^{-2})$，和下界中的$text{ε}$依赖保持一致。
### Conclusion
研究提供了数值结果来支持理论，并在格子世界等环境中发现行为克隆算法的局限性。在非交互式和交互式两种设置中，通过开发和评估新算法，定量地确定了样本使用的下限和上限，完成了理论到实践的整套研究。
## 162. `cs.AI` - 通过Eigenvalues在序列模型中的任务级洞察 [PDF](https://arxiv.org/pdf/2510.09379), [HTML](https://arxiv.org/abs/2510.09379)
### Authors
Rahel Rickenbach,Jelena Trisovic,Alexandre Didier,Jerome Sieber,Melanie N. Zeilinger
### Background
尽管softmax注意力机制在序列模型中表现优异，但其二次复杂度限制了其扩展性，促使发展出线性替代方法，如状态空间模型（SSMs）。虽然这些替代方法提高了效率，但它们在信息处理方面的根本差异仍然不甚明了。本文利用最近提出的动态系统框架，将softmax、范数和线性注意力表示为动态系统，以此为基础，通过分析其各自的特征值谱进行结构化的比较研究。
### Innovation
本文创新性地运用动态系统框架，将不同类型的关注机制转化为动态系统模型，并通过分析它们各自的特征值谱进行比较研究。这种做法揭示了特征值如何影响记忆和长距离依赖建模的关键特性，并进一步探讨了架构修改如何影响特征值谱和任务性能之间的关系。
### Conclusion
通过广泛的实证分析，本文发现特征值在任务级别的表现与任务需求高度一致，并进一步证明了特征值分析作为解释、理解和最终改善序列模型性能的有原则性度量的有效性。
## 163. `cs.AI` - 随机HyperSteiner：一种用于双曲Steiner最小树的随机Delaunay三角剖分启发式算法 [PDF](https://arxiv.org/pdf/2510.09328), [HTML](https://arxiv.org/abs/2510.09328)
### Authors
Aniss Aiman Medbouhi,Alejandro García-Castellanos,Giovanni Luca Marchetti,Daniel Pelt,Erik J Bekkers,Danica Kragic
### Background
Steiner Minimal Trees（SMTs）在双曲空间中的构建问题是NP难问题。现有的双曲启发式方法如HyperSteiner通常是确定性的，在局部次优配置中容易被困住。已有方法（例如Minimum Spanning Tree （MST）、Neighbour Joining以及未修改的HyperSteiner）在构造SMT时效果有限。
### Innovation
提出了Randomized HyperSteiner（RHS），这是一种将随机性引入扩展过程中的随机Delaunay三角剖分启发式算法。通过Riemannian梯度下降优化对候选树进行改进。实验表明，RHS在合成数据集和实际的单细胞转录组学数据集上明显优于MST、Neighbour Joining以及未修改的HyperSteiner（HS），特别在接近边界的配置中，RHS相较于HS可减少32%的总长度，显示了其在不同数据集上的有效性和鲁棒性。
### Conclusion
实验结果表明，Randomized HyperSteiner（RHS）在合成数据集中以及实际的单细胞转录组学数据集中的性能优于MST、Neighbour Joining和未修改的HyperSteiner（HS），特别是在边界区域，RHS能实现显著的长度优化，证明了RHS在多种数据情况下的有效性和鲁棒性。
## 164. `cs.AI` - 第二-order优化在LLMs中的潜力：使用全Gauss-Newton方法的研究 [PDF](https://arxiv.org/pdf/2510.09378), [HTML](https://arxiv.org/abs/2510.09378)
### Authors
Natalie Abreu,Nikhil Vyas,Sham Kakade,Depen Morwani
### Background
近期加速大模型预训练的努力集中在利用第二阶结构的计算高效近似上。然而，这引发了一个关键问题：这些近似会导致多少性能损失？为此，研究人员通过将全Gauss-Newton预训练方法应用于最多150M参数的变压器模型，设置了一种实际的迭代复杂度上限。实验显示，全Gauss-Newton更新在训练迭代次数上显著优于现有的优化器，相较于SOAP和Muon等基线方法，其减少幅度达5.4倍。此外，实验还发现，一种忽略跨层信息的逐层Hessian预训练方法几乎能够达到全Gauss-Newton方法的性能水平。
### Innovation
通过使用全Gauss-Newton方法对最多150M参数的变压器模型进行预训练，研究人员设定了实际的迭代复杂度上限。实验结果表明，Gauss-Newton近似方法在预训练中非常有效，暗示高阶损失项可能不是影响收敛速度的关键因素。此外，逐层的Hessian结构中包含足够信息几乎能够达到所有潜在性能增益。最后，目前的近似方法与理论上理想的逐层先验相比存在显著的性能差距。
### Conclusion
(1) Gauss-Newton近似在预训练中非常有效，可能高阶损失项对收敛速度的影响不大；(2) 逐层Hessian结构包含足够的信息以实现大部分可能的性能增益；(3) 当前的近似方法与理想的逐层先验之间存在显著性能差距。
## 165. `cs.AI` - 通过系数动态设计序列模型的原则 [PDF](https://arxiv.org/pdf/2510.09389), [HTML](https://arxiv.org/abs/2510.09389)
### Authors
Jerome Sieber,Antonio Orvieto,Melanie N. Zeilinger,Carmen Amo Alonso
### Background
深度序列模型，如Transformers、State Space Models (SSMs)以及更为近期的门控线性RNNs，其主要计算输出为过去值向量的线性组合。为此，研究者开发了一个统一框架，将这一线性组合系数明确表示为由脉冲输入驱动的自主线性动态系统的输出。这种观点与专注于将线性RNN与线性注意力联系起来的方法本质不同，揭示了不同架构之间的共同数学主题，并且能捕捉softmax注意力，而不仅仅是RNN、SSMs及其相关模型。
### Innovation
本文提出了一个统一框架，通过将线性组合系数表示为由脉冲输入驱动的自主线性动态系统的输出，明确表示了序列模型的输出操作。这种方法解释了近年来设计的成功，并为系统地设计新的序列模型架构提供了指导原则，识别了表达能力和高效实现之间的权衡、输入选择的几何约束以及数值稳定训练和信息保留的稳定性条件。
### Conclusion
该框架通过连接近期文献中的多个见解和观察，解释了近期设计的实证成功，并提供了系统设计新的序列模型架构的指导原则。
## 166. `cs.AI` - 识别与互动式精炼模糊用户目标以生成数据可视化代码 [PDF](https://arxiv.org/pdf/2510.09390), [HTML](https://arxiv.org/abs/2510.09390)
### Authors
Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani
### Background
在人机交流中确立共同目标是非常重要的一步。然而，语言中的歧义可能导致生成与说话人意图不符的输出。本文关注数据可视化领域，其中自然语言中的歧义影响生成可视化数据的代码。通过多种视角（如意图图表和渲染代码）的数据可以提供对不同类型的歧义进行独特而全面分析的机会。
### Innovation
本文发展了一种歧义类型的分类体系，并提出了一种定量衡量这些歧义的方法。使用DS-1000数据集的Matplotlib问题，本文展示了本研究的歧义度量标准比不确定性基线更好与人类注释相关联。本文还探讨了多轮对话减少歧义并提高代码准确性的可能性，并介绍了Gricean合作理论、论题表示理论和讨论中的问题等实用模型，以指导对话策略。模拟用户研究揭示了多轮对话如何减少歧义，提高代码准确性，强调了代码生成中的多轮交流的价值。
### Conclusion
通过多轮对话可以减少歧义，从而提高代码准确性。本研究使用实用模型指导对话策略，并通过模拟用户研究展示了多轮对话在代码生成中的价值。
## 167. `cs.AI` - ChoirRec: 使用大型语言模型进行低活跃用户转化率预测的语义用户分组 [PDF](https://arxiv.org/pdf/2510.09393), [HTML](https://arxiv.org/abs/2510.09393)
### Authors
Dakai Zhai,Jiong Gao,Boya Du,Junwei Xu,Qijie Shen,Jialin Zhu,Yuning Jiang
### Background
准确预测低活跃用户的转化率(CVR)仍然是大规模电子商务推荐系统中的一个基本挑战。现有的方法面临三个关键限制：依赖于噪声和不可靠的行为信号；由于缺乏多样化的互动数据，导致用户级别的信息不足；以及培训偏向于高活跃用户，忽视了低活跃用户的需要。
### Innovation
为了应对这些挑战，本文提出ChoirRec，一种新的框架，利用大型语言模型（LLMs）的语义能力构建语义用户组，增强低活跃用户的CVR预测。ChoirRec通过一种 robust 的跨用户知识转移双通道架构，包含三个组件：语义用户组生成模块、组感知层次表示模块和组感知多粒度模块。ChoirRec通过利用LLMs形成可靠的、跨活动用户聚类，过滤掉噪声信号；通过丰富稀疏的用户嵌入并将具有洞察力的组级先验信息纳入其中，缓解数据不足的问题；并通过双通道架构和自适应融合机制确保有效学习和利用组知识。
### Conclusion
通过在淘宝上的广泛离线和在线实验，ChoirRec在离线评估中提高了GAUC 1.16%，在线A/B测试中显示订单量增加了7.24%，表明其在实际应用中的显著实用价值。
## 168. `cs.AI` - 语音LLM无所不包：一种真正完全端到端的语音对话状态跟踪方法 [PDF](https://arxiv.org/pdf/2510.09424), [HTML](https://arxiv.org/abs/2510.09424)
### Authors
Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf
### Background
本文研究了端到端语音对话状态跟踪中上下文管理策略，对比了传统的多模态上下文、完整的语音历史以及压缩的语音历史方法。通过SpokenWOZ语料库的实验表明，提供完整的对话历史作为输入，模型性能显著优于之前的同类方法。
### Innovation
研究展示了基于注意力池化压缩的语音历史方法，能够在减小上下文规模的同时保持竞争力。研究表明，上下文利用的改进来自于更有效的上下文使用。
### Conclusion
实验结果表明，提供完整的语音对话作为输入可以显著提高模型性能，而基于注意力池化的压缩方法则为上下文大小和准确度提供了一个强有力的权衡方案。
## 169. `cs.AI` - 自回归大型语言模型中实体的表示研究 [PDF](https://arxiv.org/pdf/2510.09421), [HTML](https://arxiv.org/abs/2510.09421)
### Authors
Victor Morand,Josiane Mothe,Benjamin Piwowarski
### Background
实体是文本中知识的基本构建块，用于承载事实信息并结构化语言中的关系。尽管它们的重要性不言而喻，但尚不清楚大型语言模型（LLMs）是如何内部表示这些实体的。以往的研究主要关注显式的实体关系，但对实体本身的具体表示知之甚少。这项研究引入了一种新的实体提及重建框架，旨在探索LLMs如何编码和操作实体，以及通过内部表示生成实体提及的可能性。
### Innovation
提出了利用任务向量的实体提及重建方法，该方法可以从LLMs隐藏状态中提取出的各种实体表示中一致生成多词提及。进一步提出了扩展logit-lens的“实体镜”，以预测多词提及。研究结果表明，LLMs发展出了特定的机制，用于表示和操作任何多词实体，包括训练过程中未见过的实体。
### Conclusion
研究结果提供了新的证据，证明LLMs具备在内部表示和操作多词实体（包括训练期间未见过的实体）的特定机制。
## 170. `cs.AI` - 超越单一粒度提示：多尺度链式思维图提示学习 [PDF](https://arxiv.org/pdf/2510.09394), [HTML](https://arxiv.org/abs/2510.09394)
### Authors
Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu
### Background
预训练提示 paradigm 已从自然语言处理(NLP)领域扩展到图领域，并取得了显著进展。当前主流的图提示微调方法通过可学习的提示向量修改输入或输出特征。然而，现有方法在提示生成过程中仅受限于单一粒度（如节点级或子图级），忽略了图数据中固有的多尺度结构信息，这限制了提示语义的多样性。因此，迫切需要一种能够整合多尺度信息的学习框架，以提高图数据处理的灵活性和多样性。
### Innovation
作者提出了一种名为 Multi-Scale Graph Chain-of-Thought (MSGCOT) 的多尺度链式思维图提示框架。该框架通过设计一种轻量级的低秩粗化网络，高效捕捉多尺度结构特征作为层级基础向量，用于提示生成。进而，模仿人类从粗到细的认知过程，在每个推理步骤中动态整合多尺度信息，形成逐级粗细的提示链。实验结果证明，MSGCOT 在少量样本场景中比最先进的单一粒度图提示微调方法表现更优，展示了其优越性。
### Conclusion
此项研究提出了一种创新的多尺度链式思维图提示学习框架MSGCOT，通过整合多尺度信息提高了图数据处理的灵活性和多样性。实验结果表明，MSGCOT 在多种场景下显著优于现有的单一粒度图提示微调方法，特别是在少量样本情况下。
## 171. `cs.AI` - 生成性机器人策略运行时的故障预测 [PDF](https://arxiv.org/pdf/2510.09459), [HTML](https://arxiv.org/abs/2510.09459)
### Authors
Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig
### Background
生成性自适应学习（如扩散和流动匹配）使机器人能够执行复杂的长期任务。然而，未见过的环境分布移变或累积的动作错误可能会导致不可预测且不安全的行为，导致任务失败。因此，在人类为中心和安全性至关重要的环境中部署机器人时，运行时早期故障预测变得至关重要。
### Innovation
提出了FIPER框架，这是一种用于生成性自适应学习策略的在运行时预测故障的一般框架，不需依赖故障数据。该框架通过在策略的嵌入空间中应用随机网络蒸馏来检测异常分布观察，并通过新颖的行动批次熵分数来测量生成行动的不确定性。通过小规模的成功滚动力求集校准这两个故障预测得分。两者在短时间内超过阈值时触发故障警报。
### Conclusion
研究表明，FIPER能更准确地区分实际故障和伪故障情况，并且预测故障更早也更准确，优于现有方法。因此，这被视为实现更具可解释性和安全性生成性机器人策略的重要步骤。相关代码、数据和视频可在提供的链接处获得。
## 172. `cs.AI` - SilvaScenes: 树冠下自然森林中树木分割和物种分类的数据集 [PDF](https://arxiv.org/pdf/2510.09458), [HTML](https://arxiv.org/abs/2510.09458)
### Authors
David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère
### Background
对于森林管理的机器人技术的兴趣正在增长，但在复杂自然环境中的感知仍是一个重大障碍。由于遮挡严重、光照变化和茂密的植被，自动化系统面临着挑战，这些系统对于精准林业、生物多样性监测和林业设备的自动化至关重要。这些任务依赖于先进的感知能力，例如树木个体检测和细致的物种分类。然而，现有的数据集往往无法开发这样的感知系统，因为它们往往集中在城市环境或少数几种物种。
### Innovation
提出了 SilvaScenes 数据集，这是一个用于森林中树冠下图像的树木实例分割和物种分类的新数据集。该数据集在加拿大魁北克省的五个生物气候区收集，包含来自24个物种的1476棵树，并由林业专家进行了注释。结果表明，树木分割相对容易，但物种分类仍然是一个重大挑战。
### Conclusion
通过基准测试现代深度学习方法用于实例分割证明了该数据集的相关性和挑战性。尽管树冠下树木分割的最高平均精度为67.65%，但物种分类的最高平均精度仅为35.69%。该数据集和源代码将在此网站 https://example.com 上提供。
## 173. `cs.AI` - 使用碰撞感知动态警报掩码和混合执行策略的可扩展多智能体路径规划 [PDF](https://arxiv.org/pdf/2510.09469), [HTML](https://arxiv.org/abs/2510.09469)
### Authors
Bharath Muppasani,Ritirupa Dey,Biplav Srivastava,Vignesh Narayanan
### Background
多智能体路径规划（MAPF）仍然是机器人技术和自主系统中的关键问题。传统上，集中式算法利用全局信息进行高效导航，但由于需要解决的冲突的组合爆炸而导致在大规模场景中计算成本高昂。相比之下，局部信息的分布式方法能够更好地扩展，但通常以降低解决方案质量为代价。为了克服这些局限性，我们提出了一种结合分散式路径规划和轻量级集中式协调者的混合框架。
### Innovation
该框架利用强化学习（RL）进行分散式规划，使智能体能够基于最少且针对性的警报（如静态冲突单元标志或简短冲突轨迹等动态共享信息）进行适应性规划，从而有效解决冲突。与完全集中式和分散式方法相比，该方法减少了智能体间的信息共享，同时仍然能够持续找到可行的、无碰撞的解决方案，即使在具有更高智能体数量的大型场景中。
### Conclusion
通过实证研究，我们探索了智能体可用信息对其规划性能的影响。我们的方法在信息到达的限制下仍然能够保持高性能，并能够有效地解决冲突问题，同时保持可扩展性。
## 174. `cs.AI` - 可信监控模型上的适应性攻击颠覆了AI控制协议 [PDF](https://arxiv.org/pdf/2510.09462), [HTML](https://arxiv.org/abs/2510.09462)
### Authors
Mikhail Terekhov,Alexander Panfilov,Daniil Dzenhaliou,Caglar Gulcehre,Maksym Andriushchenko,Ameya Prabhu,Jonas Geiping
### Background
AI控制策略作为一种防御机制，旨在阻止不可信的大语言模型代理在自主环境中造成危害。之前的研究所将其视为安全问题，通过利用部署环境来进行微妙的有害操作测试，如后门植入。实践中，大多数AI控制策略本质上依赖于大语言模型的监控器，这些监控器可能成为中心弱点。因此，作者研究了一个不受信任的模型发起的适应性攻击，这种攻击知道协议和监控模型，可能是因为该模型在知识截断较晚或自主搜索这些信息的情况下被训练。作者通过将已知或零样本提示注入嵌入到模型输出中，实例化了一个简单的适应性攻击向量，使用这种方法，前沿模型能够规避各种监控器，并在两个主要AI控制基准上完成恶意任务。该攻击对当前依赖于监控器的协议具有普遍适用性，甚至导致了最新的Defer-to-Resample协议失效。
### Innovation
该研究提出了一种适应性攻击的方法，旨在通过零样本提示注入来应对当前依赖监控器的AI控制协议。研究揭示了监控模型上的重大盲点，这将成为未来AI控制机制评估的标准组成部分。
### Conclusion
当前的AI控制协议存在显著的安全漏洞，特别是针对能够自我学习或有更新知识的模型的适应性攻击。传统的防御手段可能无法有效对抗这种适应性威胁，因此需要进一步完善AI控制协议以应对未来的安全挑战。
## 175. `cs.AI` - 机器学习算法在慢性肾病预测中的性能分析 [PDF](https://arxiv.org/pdf/2510.09493), [HTML](https://arxiv.org/abs/2510.09493)
### Authors
Iftekhar Ahmed,Tanzil Ebad Chowdhury,Biggo Bushon Routh,Nafisa Tasmiya,Shadman Sakib,Adil Ahmed Chowdhury
### Background
全球约10%的人口可能受到慢性肾病（CKD）的影响，导致肾功能下降。为保护处于危险中的患者免受进一步的肾损伤，有效的CKD风险评估和适当的CKD监控至关重要。由于机器学习模型具有快速和精确的检测能力，因此当前医疗保健领域中的大量诊断系统和流程都依赖于机器学习以实现其疾病预测能力。
### Innovation
该研究设计并提出了计算机辅助的设计系统来预测和诊断CKD。研究使用了若干种机器学习技术（包括随机森林、SVM、朴素贝叶斯、Logistic回归、KNN、XGBoost、决策树和AdaBoost）来建立模型，并通过性能评价比较来确定具有最高准确度的机器学习模型。研究发现，随机森林和Logistic回归表现最出色，准确度达到了99%，紧随其后的是AdaBoost、XGBoost、朴素贝叶斯、决策树和SVM，而KNN模型表现最差，准确度为73%。
### Conclusion
该研究利用机器学习算法的性能分析，揭示了几种预测慢性肾病的方法，并确定了最有效的方法，为进一步减轻慢性肾病的负担提供了新的视角。
## 176. `cs.AI` - 在使用VQ-VAE和GNN的多用户FDD系统中的预编码器设计 [PDF](https://arxiv.org/pdf/2510.09495), [HTML](https://arxiv.org/abs/2510.09495)
### Authors
Srikar Allaparapu,Michael Baur,Benedikt Böck,Michael Joham,Wolfgang Utschick
### Background
在频率分割双工（FDD）系统中，稳健的预编码可以通过合并通过生成模型学习到的传播环境统计信息得以高效实现。此前的研究成功地利用高斯混合模型（GMMs）和图神经网络（GNNs）结合的方式设计了特定站点的预编码器。但GMM的一个关键缺点是其组件数量随着反馈位数的增加呈指数增长。
### Innovation
通过使用向量量化变分自编码器（VQ-VAE），本文克服了GMM的一个主要缺点，即组件数量随反馈位数增加呈指数级增加。此外，VQ-VAE的深度学习架构使得能够联合训练GNN和VQ-VAE，以及试点优化，形成端到端（E2E）模型，对于多用户无线系统，这导致了显著的吞吐量性能提升。
### Conclusion
仿真结果表明，所提出的框架在吞吐量性能上优于传统方法，传统方法包括子离散傅里叶变换（DFT）试点矩阵和迭代预编码算法，使可以部署具有更少试点或反馈位数的系统。
## 177. `cs.AI` - 临床驱动的交互分割评估方法 [PDF](https://arxiv.org/pdf/2510.09499), [HTML](https://arxiv.org/abs/2510.09499)
### Authors
Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso
### Background
交互分割是构建鲁棒且通用的医学图像分割算法的有前途的策略。然而，临床不一致且不切实际的评估阻碍了公平比较并歪曲了真实世界的性能。
### Innovation
提出了基于临床的方法来定义评估任务和指标，并构建了一个用于构建标准化评估流水线的软件框架。评估了当前最先进的算法，并观察到关键点包括：1)处理用户交互时最小化信息丢失对于模型的鲁棒性至关重要；2)自适应缩放机制提高了鲁棒性并加速了收敛；3)验证提示行为/预算与训练不同会导致性能下降；4)2D方法适用于切片状图像和粗略的目标，但3D上下文有助于处理大型或不规则形状的目标；5)非医学领域模型（如SAM2）在低对比度和复杂形状下表现较差。
### Conclusion
研究结果表明，对于模型的鲁棒性和性能，重要的因素包括信息处理、缩放机制、提示行为一致性、目标尺寸和复杂形状的理解等。
## 178. `cs.AI` - 自主学习驱动软机器人导线导航 [PDF](https://arxiv.org/pdf/2510.09497), [HTML](https://arxiv.org/abs/2510.09497)
### Authors
Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger
### Background
在血管内手术中，手术医生通过导管和细导丝将导管推送到患者血管内的治疗部位，以治疗血栓、动脉瘤和畸形等疾病。带有机器人末端的导丝可以提高操控性，但模型和控制方面存在挑战。自动控制软机器人导丝导航有望克服这些挑战，提高血管内导航的精准度和安全性。在其他外科领域，端到端的模仿学习已经取得了令人鼓舞的结果。
### Innovation
开发了一个基于变换器的带目标条件、相对动作输出和自动对比度染料注射的模仿学习框架，用于在动脉瘤定位任务中实现通用软机器人导丝导航。模型在36种不同的模块化分叉几何结构上进行训练，生成647个模拟透视显示下的示范，并在未见过的血管几何结构上进行评估。该模型在未见过的几何结构上自主引导机器人导丝尖端到达动脉瘤位置的成功率为83%，优于多个基线。此外，还进行了消融研究和基线研究，以评估每个设计和数据收集选择的有效性。
### Conclusion
该研究提出的方法能够有效实现软机器人导丝在未见过的血管几何结构中的自主导航，并通过模型训练和对比实验，证明了其优越性。未来的工作将致力于进一步提高模型在复杂血管环境中的适应性和精度。
## 179. `cs.AI` - 多模态政策内化在对话代理中的应用 [PDF](https://arxiv.org/pdf/2510.09474), [HTML](https://arxiv.org/abs/2510.09474)
### Authors
Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya
### Background
现代对话代理如ChatGPT和Alexa依赖于预定义的策略来规定元数据、响应风格和工具使用规则。随着这些基于LLM的系统扩展以支持多样化的业务和用户查询，这些政策变得越来越复杂和冗长，使得严格的遵循变得困难，并导致较大的固定计算成本。随着多模态代理的兴起，管理视觉和多模态行为的政策变得至关重要，但仍然缺乏研究。先前的压缩提示工作主要缩短了任务模板和示范，而现有的政策对齐研究则专注于文本基础的安全规则。该研究引入了多模态政策内化(MPI)，这是一个新的任务，旨在将复杂的多模态政策内化到模型参数中，从而在推断过程中不包含该政策即可更严格地遵循政策。MPI提出了独特数据和算法挑战。该研究构建了两个涵盖合成和真实世界决策和工具使用任务的数据集，并提出了TriMPI三阶段训练框架，该框架首先通过持续预训练注入政策知识，然后进行监督微调，最后应用一种基于GRPO风格的强化学习扩展PolicyRollout，增加了政策感知响应来促进实地探索。TriMPI在端到端准确度、泛化能力和对抗遗忘的鲁棒性方面取得了显著提高。该研究为多模态政策内化提供了数据集、训练食谱和全面评估，以促进未来研究。
### Innovation
该研究首次提出多模态政策内化(MPI)任务，旨在将复杂多模态政策内化到模型参数中，从而在实际情况中不引入该政策即可更严格地遵循政策。研究同时提出TriMPI，这是一个三阶段的训练框架，能够有效处理数据和算法上的挑战，并在多个方面取得了明显改进。此外，该研究提供了数据集、训练策略和全面评估，有助于未来的研究
### Conclusion
该研究成功地将多模态政策内化到了对话代理中，并通过三阶段训练框架TriMPI改进了模型的端到端准确度、泛化能力和鲁棒性。这为多模态政策的研究提供了技术和方法上的进展，也为未来研究和实际应用提供了宝贵的数据和策略参考。
## 180. `cs.AI` - 通过推理塑造减轻过度思考 [PDF](https://arxiv.org/pdf/2510.09535), [HTML](https://arxiv.org/abs/2510.09535)
### Authors
Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang
### Background
大型推理模型（LRMs）通过强化学习从验证者奖励（RLVR）提升，显示出了强大的问题解决能力，但往往会导致过度思考：即大量、冗长的推理过程，增加了计算成本。以往RLVR设计中的惩罚机制虽然能够减少令牌消耗，但会损害模型性能，主要是因为令牌级别监督过于简单。这一事实表明监督的粒度在平衡效率和准确性方面发挥着关键作用，实验初步分析显示推理片段与令牌消耗和模型性能之间存在强相关性，因此提出了一种基于步骤的正则化方法来规范推理，并设计了跨片段簇的长度感知加权机制。
### Innovation
提出了一种基于步骤的正则化方法（Group Relative Segment Penalization，GRSP）来规范推理过程，通过跨片段簇的长度感知加权机制提高了令牌效率，同时在保持较高准确性的同时，尤其是对难题的优势更为显著，还稳定了RL训练，并且在不同模型规模下具有较高的可扩展性。
### Conclusion
GRSP方法在减轻过度思考和提高令牌效率的同时，保持了较高准确性，尤其是在处理难题时表现出色，并在不同模型规模下表现出良好的扩展性。
## 181. `cs.AI` - SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models [PDF](https://arxiv.org/pdf/2510.09541), [HTML](https://arxiv.org/abs/2510.09541)
### Authors
Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu
### Background
扩散型大语言模型（dLLMs）因其能够并行解码多个标记而成为生成模型的高效替代方案。然而，通过强化学习（RL）调整dLLMs以符合人类偏好或特定任务的奖励具有挑战性，因为它们不可计算的log-likelihood阻碍了标准策略梯度方法的应用。现有的方法使用似然下界（ELBO）作为代理，但这些单向近似会导致显著的策略梯度偏差。
### Innovation
提出了一种新的策略梯度方法——Sandowiched Policy Gradient (SPG)，该方法采用了真实log-likelihood的上界和下界，克服了现有方法中由ELBO导致的单向近似偏差问题，实验结果表明SPG在多项任务上显著优于基于ELBO或一阶估计的基线方法。
### Conclusion
SPG在dLLMs的RL方法中，在GSM8K、MATH500等任务上分别提高了3.6%、2.6%的准确性，而在Countdown、Sudoku等任务上分别提高了18.4%、27.0%的准确性。
## 182. `cs.AI` - 重新审视Titans：一种轻量级重实施和测试时内存模型的批判性分析 [PDF](https://arxiv.org/pdf/2510.09551), [HTML](https://arxiv.org/abs/2510.09551)
### Authors
Gavriel Di Nepi,Federico Siciliano,Fabrizio Silvestri
### Background
到2024年底，谷歌研究者发布了Titans：测试时学习模型，一种在多种任务中表现出色的神经内存模型。尽管如此，由于缺乏公开代码和原始描述中的模糊性，复现工作受到阻碍。在此项工作中，我们对Titans进行了轻量级重新实现，并在掩码语言建模、时间序列预测和推荐任务上进行了全面评估。我们发现由于切块问题，Titans并不总是超越现有基线模型。然而，它的神经内存组件在性能上持续优于仅依赖注意力机制的模型。这些结果证实了模型的创新潜力，同时也指出其实际限制，并为未来研究提出了问题。
### Innovation
重新实现轻量级的Titans模型，并在多个任务上进行评估。发现了神经内存组件在性能上的持续优势，尤其是在时间序列预测任务上。同时指出由于切块问题，模型可能不总是优于基线模型。
### Conclusion
尽管Titans模型在多个任务中表现良好，但其神经内存组件的性能持续优于仅依赖注意力机制的模型。然而，由于切块问题，它并不总是优于基线模型。研究结果确认了模型的创新潜力，并揭示了其可能面临的实际限制，为未来研究提供了新方向。
## 183. `cs.AI` - BaNEL：仅使用负奖励进行生成建模的探索后验 [PDF](https://arxiv.org/pdf/2510.09596), [HTML](https://arxiv.org/abs/2510.09596)
### Authors
Sangyun Lee,Brandon Amos,Giulia Fanti
### Background
当今的生成模型在大量监督数据和描述生成质量的信息性奖励函数的支持下表现良好。这些模型假设监督数据能够预先训练模型，而奖励函数提供了关于如何进一步提高生成质量和正确性的密集信息。但是在解决重要问题最困难的情况下，出现了两个问题：（1）基础生成模型的奖励信号接近于零；（2）需要频繁调用奖励先知（oracle）。这种场景提出了与标准基于奖励的后训练学习不同的基本挑战。
### Innovation
我们提出了一种算法BaNEL（Bayesian Negative Evidence Learning），该算法仅使用失败尝试进行后训练，并最大限度地减少奖励评估的次数。我们方法的核心思想是将从失败中学习规律的问题重新构造成另一项，在环中的生成建模问题。利用这种模型评估新数据是否类似于先前看到的失败并引导生成避免它们。
### Conclusion
我们在几个稀疏奖励任务中证明了BaNEL能够不观察任何成功的样本来改善模型性能，并且与现有的新颖性奖金方法相比，在成功率上提高了几个数量级，同时使用更少的奖励评估。
## 184. `cs.AI` - Dyna-Mind：从经验中学习模拟以提高AI代理效能 [PDF](https://arxiv.org/pdf/2510.09577), [HTML](https://arxiv.org/abs/2510.09577)
### Authors
Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao
### Background
近年来，推理模型在诸如数学和编码等领域的表现出色。然而，在长时互动任务（如网页导航和计算机/手机使用）方面的表现却与专业级别的能力形成强烈对比。文献指出，当前的人工智能代理需要‘代偿性实验与错误’——即在采取行动前能够进行心理上的未来情境模拟的能力——以增强在复杂互动环境中的理解与表现。本文概述了Dyna-Mind，这是一种两阶段的培训框架，旨在通过心理模拟使语言模型在推理中具备更强的能力。第一阶段介绍了一种名为‘Simulations增强推理’（ReSim）的方法，该方法通过环境交互获取的实际经验构建扩展搜索树，训练代理生成结构化的推理痕迹，从而使其推理扎根于真实的世界动态，具备预见到未来状态的能力。第二阶段提出了一种在线强化学习方法Dyna-GRPO，利用实际抽样的结局奖励和中间状态来增强代理在模拟和决策任务中的能力。实验结果表明，ReSim能有效提升代理的模拟能力，而Dyna-GRPO则能够通过结合结果和交互级信号来学习更好的策略，适用于长时规划任务。这些实验结果突出了模拟在帮助AI代理更好地推理、规划和应对挑战环境中的重要性.
### Innovation
提出了一种名为Dyna-Mind的两阶段培训框架，首次明确训练语言模型将模拟能力整合到其推理过程中。引入了ReSim方法，以及Dyna-GRPO在线强化学习方法，前者通过生成推理痕迹来训练代理模拟未来状态的能力，后者利用结局和中间状态作为反馈来优化代理的决策.
### Conclusion
实验结果表明，Dyna-Mind方法在合成基准（比如Sokoban和ALFWorld）和现实基准（比如AndroidWorld）上可以有效提升代理在长时规划任务中的表现。这强调了在复杂交互环境中合理使用心理模拟对于提高代理效能的重要性.
## 185. `cs.AI` - prompting_test_time_scaling_is_a_strong_llm_reasoning_data_augmentation [PDF](https://arxiv.org/pdf/2510.09599), [HTML](https://arxiv.org/abs/2510.09599)
### Authors
Sondos Mahmoud Bsharat,Zhiqiang Shen
### Background
大语言模型（LLMs）在提供链式思维示例时展示了卓越的推理能力，但是创建大型的推理数据集仍然劳动密集且资源成本高昂。因此，研究提出了Prompting Test-Time Scaling（P-TTS）方法，通过在测试时使用精细的指令提示强度变体来增强LLM的推理能力，而无需收集大量的示例数据。P-TTS方法利用了90个手动选择的推理示例，并通过系统地变化示例增强方式来生成多种推理轨迹的上下文，在数学推理任务中提升了LLM的性能。
### Innovation
P-TTS通过在测试时不断变化类似例增强方式，利用有限的手动选择的推理示例（仅90个），实现了对不同规模的Qwen-2.5模型的有效数据增强，从而显著提升了LLM在数学推理任务中的性能。特别是在AIME2024和25、MATH500和GPQA-Diamond的所有测试集中，P-TTS数据增强后的模型表现优于之前的竞争基线，实现了显著的准确率提升。此外，P-TTS还能提高LLM在不同领域推理任务中零样本泛化性能，展示了在资源受限或快速发展的领域中增强LLM推理的有效途径。
### Conclusion
P-TTS方法有效地探索了推理模式的潜在空间，通过最小的标注成本放大了LLM的问题解决能力，进一步揭示了LLM在推理方面的潜力。这种方法为在资源受限或快速发展的领域中利用LLM推理提供了一个可行且成本低廉的方法。
## 186. `cs.AI` - 基于Y操作符改进一类基于随机微分方程子-母系统强化学习性能的方法 [PDF](https://arxiv.org/pdf/2311.04014), [HTML](https://arxiv.org/abs/2311.04014)
### Authors
Cheng Yin,Yi Chen
### Background
本文探讨了如何在基于随机微分方程(SDEs)的系统中，通过Actor-Critic(AC)方法来提升控制性能。现有方法在处理这类系统时效果一般，尤其是在引入随机性后的控制性能方面存在局限。
### Innovation
作者引入了一个名为Y操作符的新算子，它巧妙地将子-母系统中的随机性融入到了Critic网络的损失函数中。这种方法将求解状态值函数的偏微分方程问题转换为了系统SDE中的漂移和扩散函数的并行问题。通过严格的数学证明，该操作符的这一特性使得基于Y操作符的强化学习框架（YORL）能够有效解决基于模型和数据驱动的最优控制问题。
### Conclusion
通过线性和非线性的数值实例，YORL框架展示了其在收敛后相较于现有方法具有更好的性能。
## 187. `cs.AI` - 无需训练的安全去噪器用于安全使用扩散模型 [PDF](https://arxiv.org/pdf/2502.08011), [HTML](https://arxiv.org/abs/2502.08011)
### Authors
Mingyu Kim,Dongjun Kim,Amman Yusuf,Stefano Ermon,Mijung Park
### Background
随着强大的扩散模型（DMs）的安全性受到越来越多的关注，这些模型经常被滥用以生成不适当或不适合工作的（NSFW）内容，或者是生成被版权保护的内容或个人不愿被提及的数据。目前大多数方法通过依赖文本负提示或大量重训练DMs来解决这些问题，但这种做法往往效果不佳。因此，作者提出了一种全新的方法，即直接通过利用一个否定集合（包括不安全的图片、受版权保护的数据或需要排除的数据点）来修改采样轨迹，以避开特定的数据分布区域，而无需重新训练或微调DMs。
### Innovation
作者采取了一种与现有方法完全不同的方法，直接通过利用一个否定集合来修改采样轨迹，以避开特定的数据分布区域，从而确保样本远离需要被否定的区域。基于这一推导，作者开发了一种实用的算法，在文本条件、类别条件和无条件图像生成场景中成功生成高质量样本，同时避免了数据分布中的否定区域。
### Conclusion
该方法为如何更安全地使用DMs提供了新的途径，暗示了无需训练的安全去噪器在安全使用扩散模型方面的巨大潜力。
## 188. `cs.AI` - Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research [PDF](https://arxiv.org/pdf/2502.12669), [HTML](https://arxiv.org/abs/2502.12669)
### Authors
Xiang Liu,Penglei Sun,Shuyan Chen,Longhan Zhang,Peijie Dong,Huajie You,Yongqi Zhang,Chang Yan,Xiaowen Chu,Tong-yi Zhang
### Background
由于钙钛矿太阳能电池（PSCs）的快速发展，研究文献数量呈指数级增长，急需高效的知识管理和推理系统。为了应对这一挑战，本文提出了一种全面的知识增强系统，该系统整合了三个关键组件。
### Innovation
本文创新性地开发了Perovskite-KG，一个基于1,517篇研究论文构建的领域特定知识图谱；创建了Perovskite-Chat和Perovskite-Reasoning两个互补的数据集；引入了Perovskite-Chat-LLM和Perovskite-Reasoning-LLM两个专门的大语言模型。实验结果表明，该系统在领域特定知识检索和科学推理任务方面显著优于现有模型，为研究人员提供了有效的文献综述、实验设计和复杂问题解决工具。
### Conclusion
实验结果显示，本文提出的知识增强系统在领域特定知识检索和科学推理任务上显著优于现有模型，为PSC研究提供了高效的研究工具。
## 189. `cs.AI` - StreamingVLM：无限视频流的实时理解 [PDF](https://arxiv.org/pdf/2510.09608), [HTML](https://arxiv.org/abs/2510.09608)
### Authors
Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han
### Background
视觉语言模型（VLMs）能够为实时助手和自主代理提供动力，但在处理无尽的视频流时面临着 escalating 的延迟和内存使用问题。完全使用注意力处理整段视频会导致计算成本激增，而简单滑动窗口方法存在连贯性或高延迟问题，因为它们会重新计算冗余内容或断开连通性。
### Innovation
作者引入了 StreamingVLM 模型，该模型能够实现实时、稳定地理解无限的视觉输入。该模型采用统一框架，将训练与流式推理对齐。在推理过程中，通过重用注意力池的状态、最近的视觉令牌短窗口和长窗口的文本令牌，维护一个紧凑的 KV 缓存。此外，通过一种简单的监督微调（SFT）策略，该策略在短重叠视频片段上应用全面的注意力，该策略无需训练极其长的上下文，就能模仿推理时的注意力模式。为了评估，构建了 Inf-Streams-Eval 挑战基准，这是一个新的基准测试，包含平均时长超过两小时的视频，要求在每一帧和文本之间进行密集的秒级对齐。StreamingVLM 在性能上相对于 GPT-4O mini 取得了显著提升，并在单个 NVIDIA H100 上保持了高达 8 FPS 的稳定实时性能。此外，该 SFT 策略还可以增强通用的视觉问答能力，而无需进行 Vision-and-Text 专门微调，在 LongVideoBench 上的性能提高了 4.30，在 OVOBench Realtime 上的性能提高了 5.96。
### Conclusion
StreamingVLM 通过引入一种新的流式处理策略，有效地解决了处理无限视频流时的延迟和内存问题，实现了稳定且高效的实时理解。该模型在广泛的基准测试中表现出色，并展示了其在视觉问答任务上的泛化能力。
## 190. `cs.AI` - HA-VLN 2.0: An Open Benchmark and Leaderboard for Human-Aware Navigation in Discrete and Continuous Environments with Dynamic Multi-Human Interactions [PDF](https://arxiv.org/pdf/2503.14229), [HTML](https://arxiv.org/abs/2503.14229)
### Authors
Yifei Dong,Fengyi Wu,Qi He,Zhi-Qi Cheng,Heng Li,Minghan Li,Zebang Cheng,Yuxuan Zhou,Jingdong Sun,Qi Dai,Alexander G Hauptmann
### Background
VLN已经被主要研究在离散和连续的环境中，较少关注动态和拥挤的环境。现有的研究很少关注人与人之间的社会互动和环境的动态变化，尤其是人类在环境中动态移动和观察范围限制的情况。因此，这些环境中的人工智能导航系统在面对人类动态时，表现较差，需要引入新的基准测试来更好地捕捉这些情况下的导航需求和挑战。
### Innovation
- 引入了HA-VLN 2.0统一基准，增加了明确的社会意识约束；- 提出了标准化的任务和评估指标，同时考虑目标准确性与个人空间遵守情况；- 发布了HAPS 2.0数据集和模拟器，能够模拟多人互动、户外场景和细粒度的语言-动作对齐；- 涵盖了16,844条涉及人类动态和部分观察性的社会指令的基准测试，揭示了领先代理在人类动态和部分可观察性下的性能下降；- 通过现实世界的机器人实验验证了模拟到现实环境的迁移，并提供了一个公开榜可进行透明比较；
### Conclusion
清晰的社会建模提高了导航的稳健性，减少了碰撞，强调了以人为中心的方法的必要性。通过提供数据集、模拟器、基线和协议，HA-VLN 2.0为安全、负责任的导航研究提供了坚实的基础。
## 191. `cs.AI` - 一种知识导向的深度学习范式：通用和稳定优化的跟车模型 [PDF](https://arxiv.org/pdf/2504.14241), [HTML](https://arxiv.org/abs/2504.14241)
### Authors
Chengming Wang,Dongyao Jia,Wei Wang,Dong Ngoduy,Bei Peng,Jianping Wang
### Background
随着交通流分析和自动驾驶的发展，跟车模型（CFMs）已成为关键应用之一。现有的基于物理参数校准的方法和基于数据驱动的训练方法能够模拟人类驾驶行为，但它们依赖于特定的数据集，导致在不同场景下的泛化能力受限，并在实际部署中可靠性下降。此外，这些模型通常侧重于行为准确性，却忽视了局部和连贯稳定性的优化，这对于自动驾驶车辆的安全高效运营非常重要。因此，需要一种新的方法来解决上述问题，这种方法既要保持行为准确性，又要确保在实际应用中的安全性与可靠性.
### Innovation
文中提出了一种知识导向的深度学习（KIDL）范式，该范式利用预先训练的大语言模型（LLMs）的知识转移，形成一个轻量级且关注稳定的神经架构。通过知识蒸馏，KIDL能够提取超越特定数据集模式的跟车基本知识，并直接将稳定性约束整合到其训练目标中，从而使得生成的模型不仅能模仿人类驾驶行为，还能满足实时部署的AV系统至关重要的局部和连贯稳定性要求。研究结果表明，KIDL在实际部署的NGSIM和HighD数据集上表现出更优的行为泛化能力和交通流稳定性，为下一代交通系统提供了强大且可扩展的解决方案.
### Conclusion
研究通过比较KIDL与代表性的基于物理参数和数据驱动的CFMs，证明了其在提高行为通用性和交通流稳定性方面的优越性，提出了一种新的基于深度学习的方法，可广泛应用于未来交通系统，以确保自动驾驶的安全性和高效性.
## 192. `cs.AI` - AniME: 自适应多智能体规划生成长动画 [PDF](https://arxiv.org/pdf/2508.18781), [HTML](https://arxiv.org/abs/2508.18781)
### Authors
Lisai Zhang,Baohan Xu,Siqian Yang,Mingyu Yin,Jing Liu,Chao Xu,Siqi Wang,Yidi Wu,Yuxin Hong,Zihao Zhang,Yanzhang Liang,Yudong Jiang
### Background
目前，长形式动画的制作流程复杂且劳动密集，依赖于导演的创意和多部门的合作。尽管部分自动化系统已经出现，但缺乏一种能够覆盖从故事创作到最终视频制作的完整工作流程的自动化解决方案。
### Innovation
AniME 提出了一种面向导演的多智能体系统，旨在实现长动画的自动化制作。该系统整合了定制的模型上下文协议 (MCP)，能够根据不同的子任务自适应选择控制条件，实现了具有连贯角色和同步音视频元素的电影级动画，提供了一种面向AI驱动的动画创作的可扩展解决方案。
### Conclusion
AniME 提供了一种全面的长动画自动化制作系统，通过多智能体规划和定制模型上下文协议，实现了从故事到最终动画的全流程覆盖，适用于面向AI的动画创作，推动了自动化制作为艺术创作带来更多可能性。
## 193. `cs.AI` - AdaReasoner：自适应推理让大语言模型更具灵活性 [PDF](https://arxiv.org/pdf/2505.17312), [HTML](https://arxiv.org/abs/2505.17312)
### Authors
Xiangqi Wang,Yue Huang,Yanbo Wang,Xiaonan Luo,Kehan Guo,Yujun Zhou,Xiangliang Zhang
### Background
大语言模型（LLMs）在处理需要复杂的推理和问题解决的任务时，往往需要有效的配置，如温度设置和推理步骤。现有的提示方法通常采用通用的、固定的配置来应对各种任务，但很少达到特定任务的最佳效果。本文探讨了这一差距，并提出了解决方案。
### Innovation
本文介绍了AdaReasoner，这是一种大语言模型无关的插件，旨在自动化各种需要不同推理类型的任务的自适应推理配置。AdaReasoner 通过强化学习（RL）框架进行训练，结合因素化动作空间和目标探索策略，以及预训练的奖励模型来优化策略模型，仅通过少量示例指导即可优化推理配置。AdaReasoner 在六种不同的大语言模型和各种推理任务上表现优异，保持了离分布鲁棒性，并在知识密集型任务上取得了一定的改进。
### Conclusion
AdaReasoner 在不同 LLM 和多种推理任务中表现稳定，优于标准基线，并在特定任务上提供了增量收益。实验结果表明其快速收敛和超线性策略差距的理论保证。
## 194. `cs.AI` - 物理模型的自主探索 [PDF](https://arxiv.org/pdf/2509.24978), [HTML](https://arxiv.org/abs/2509.24978)
### Authors
Maximilian Nägele,Florian Marquardt
### Background
科学研究的过程依赖于观察、分析和假设生成的相互作用。机器学习已被用来应对这一过程的各个部分。然而，自动完成发现未知系统定律所需的启发式迭代循环——通过实验和分析来探索系统——仍然是一个开放的挑战。这个过程不针对特定任务进行调整。SciExplorer通过利用大型语言模型工具使用能力，无需特定领域的蓝本，自主探索未知的物理系统。
### Innovation
SciExplorer 是一个基于大型语言模型工具使用的代理，能够在没有特定领域规划的情况下自主探索系统。它被应用于未知的物理系统，如机械动力系统、波动演化和量子多体物理学，使用少量工具，主要是通过代码执行实现，展示了在从观察到的动态恢复运动方程以及从期望值推断哈密顿量等任务中的出色表现。
### Conclusion
SciExplorer 在这些任务中表现出的有效性为在其他领域进行类似的科学探索铺平了道路，而不必进行微调或任务特定的指令。
## 195. `cs.AI` - 基于搜索的信用分配方法在离线偏好强化学习中的应用 [PDF](https://arxiv.org/pdf/2508.15327), [HTML](https://arxiv.org/abs/2508.15327)
### Authors
Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li
### Background
离线强化学习是指从固定数据集中学习策略的过程，不需额外的环境交互。但这种方法通常依赖于已定义好的奖励函数，设计这些函数既困难又昂贵。相比之下，人类反馈是一个有吸引力的替代方案，但其两种常见形式——专家示范和偏好——各有局限。示范提供了逐步监督，但采集代价高且通常反映专家行为模式有限。相反，偏好采集容易，但难以分辨行为哪一部分对轨迹片段贡献最大，导致责任归因问题悬而未决。
### Innovation
本文提出了搜索基(Based)于偏好加权(SPW, Search-Based Preference Weighting)方案，将这两种反馈源进行统一。对于偏好标记轨迹中的每个转换，SPW 从专家示范中搜索最相似的状态-行动对，并直接基于相似度分数推导出逐步的重要性权重。这些权重随后被用来引导标准的偏好学习，使得更准确的责任归因成为可能，超越了传统方法。
### Conclusion
实验结果表明，SPW 能够实现偏好和示范的有效联合学习，优于前一种同时利用这二者反馈的方法，在具有挑战性的机器人操作任务上表现更优。
## 196. `cs.AI` - ARS: 自适应推理抑制以提高大型推理语言模型效率 [PDF](https://arxiv.org/pdf/2510.00071), [HTML](https://arxiv.org/abs/2510.00071)
### Authors
Dongqi Zheng
### Background
大型推理语言模型（LRLMs或LRMs）在复杂推理任务中展示了显著的能力，但由于过度思考的现象面临严重的计算效率低下问题。现有的高效推理方法在提高推理质量的同时，难以有效降低推理过程中的计算成本。
### Innovation
提出了自适应推理抑制（ARS），这是一个无需训练的新型方法，通过自适应的确定性监控动态抑制冗余的推理步骤，同时保持准确性。ARS 引入了具有渐进抑制阈值的多检查点确定性估计机制，相比于静态抑制方法，在效率方面取得了更好的效果。
### Conclusion
在使用多种模型架构的数学推理基准测试中，ARS 的测试结果表明，在减少 53% 的令牌、46.1% 的延迟和 57.9% 的能耗的同时，能够保持或提升准确性。
## 197. `cs.AI` - 通过Shachi重塑基于代理的建模以利用大语言模型代理 [PDF](https://arxiv.org/pdf/2509.21862), [HTML](https://arxiv.org/abs/2509.21862)
### Authors
So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang
### Background
在基于大规模语言模型（LLM）驱动的多智能体系统的新兴行为研究领域，尽管存在研究挑战，但研究进展受限于缺乏系统性的控制实验方法。该领域亟需一种能够系统分析特定架构选择对集体行为影响的框架。
### Innovation
提出了一种名为Shachi的正式方法和模块化框架，将智能体策略分解为核心认知组件：配置其固有特征、记忆其上下文惯性以及扩展功能的工具，全部由LLM推理引擎协调。这种基于原理的架构超越了脆弱的、即兴的智能体设计，能够系统地分析特定架构选择对集体行为的影响。该方法在全面的10项任务基准测试中得到了验证，并通过新的科学探索展示了其力量。特别地，通过建模真实的美国关税冲击，展示了当智能体的认知架构适当配置记忆和工具时，其行为与市场实际反应一致，从而证明了该方法的外部有效性。这项工作为构建和评估LLM智能体提供了一个严谨的开源基础，旨在促进更累积的、科学基础的研究。
### Conclusion
Shachi为基于智能体的建模提供了一个严格的、开源的基础，有助于研究者深入理解特定架构选择如何影响大规模智能体系统的行为。通过这种方法，研究团队证明了智能体的认知架构对精确模拟现实世界经济行为的重要性，并进一步推动了科学地研究智能体建模领域。
## 198. `cs.AI` - GUI-Shift: 提升基于VLM的GUI代理通过自我监督强化学习 [PDF](https://arxiv.org/pdf/2505.12493), [HTML](https://arxiv.org/abs/2505.12493)
### Authors
Longxi Gao,Li Zhang,Pengzhi Gao,Wei Liu,Jian Luan,Mengwei Xu
### Background
训练有效的视觉-语言模型（VLMs）以用于GUI代理通常依赖于大型注释数据集，其收集工作既费时又容易出错。收集这些数据集需要大量人工标注，且在标注过程中容易出错。
### Innovation
引入了K步GUI转换任务，这是一种自我监督逆动力学任务，VLMs通过预测导致两个GUI状态之间转换的初始动作来学习GUI动态。此方法消除了对自然语言指令的需求，使得从现有GUI轨迹或自动化探索中构建大规模数据集成为可能。在此基础上，提出了一种结合规则优化与数据筛选的强化学习（RL）框架GUI-Shift，以提升VLM性能。
### Conclusion
通过使用GUI-Shift训练VLM在多种VLM模型架构上，在多个基准测试中均表现出良好泛化能力，特别是在GUI自动化任务与GUI定位任务上，能提高高达11.2%的GUI自动化准确度。这项研究强调了自我监督RL在利用未标注GUI轨迹方面的潜力，并提出了标注样本之外的可扩展训练方案。
## 199. `cs.AI` - 通过动态主体感知路由改进多模态大脑编码模型 [PDF](https://arxiv.org/pdf/2510.04670), [HTML](https://arxiv.org/abs/2510.04670)
### Authors
Xuanhua Yin,Runkai Zhao,Weidong Cai
### Background
自然场景下的功能性磁共振成像(fMRI)编码必须处理多模态输入、不断变化的融合风格以及显著的个体间差异。现有方法难以同时标准化这些复杂变量以进行准确的脑活动预测和个体间的泛化。论文在此背景下提出了AFIRE（无假设框架）和MIND（插拔式专家混合解码器），旨在解决上述问题，从而提高自然场景下多模态fMRI研究的预测效果和跨个体泛化能力。
### Innovation
AFIRE提供了一种标准化多编码器融合后的时序对齐标记的无假设框架，而MIND则采用主体感知动态门控机制，结合Top-K稀疏路由和先验知识，个性化地使用专家解码器，同时保持了解码器的通用性。这种方法在多个多模态架构和受试者上展示了比现有基线方法更好的预测效果、增强的跨个体泛化能力和可解释的专家模式，与内容类型相关。框架还提供了一个便于新编码器和数据集集成的简单附着点，确保了自然场景下神经影像学研究的鲁棒性和插拔式改进性能。
### Conclusion
通过引入AFIRE和MIND，本文显著提升了自然场景下多模态fMRI编码和跨个体预测的准确性与通用性，并展示了在不同模态和人群中的应用效果。该框架还为未来扩展和优化提供了灵活性和便捷性，为进一步的神经影像学研究奠定了基础。
## 200. `cs.AI` - SurveyG：一种基于层次引文图的多智能体大模型框架实现自动化综述生成 [PDF](https://arxiv.org/pdf/2510.07733), [HTML](https://arxiv.org/abs/2510.07733)
### Authors
Minh-Anh Nguye,Minh-Duc Nguyen,Ha Lan N.T.,Kieu Hai Dang,Nguyen Tien Dong,Dung D. Le
### Background
大规模语言模型（LLMs）日益被用于自动化生成综述论文。现有的方法通常从大量相关论文中提取内容并直接提示LLMs进行总结，但这些方法往往会忽略论文之间的结构关系，导致生成的综述缺乏连贯的分类体系和更深层次的研究进展背景理解。
### Innovation
提出了一种基于LLM的多智能体框架——SurveyG，该框架集成了层次引文图，其中节点代表研究论文，边捕捉它们之间的内容引用依赖性和语义相关性，从而将结构和上下文知识嵌入到综述生成过程中。图分为三层：基础、发展和前沿，以捕捉从开山之作到逐步进步和新兴方向的研究演变过程。通过在层次内进行水平搜索并在层次间进行垂直深度遍历，智能体生成多层总结，这些总结被合并为结构化的综述大纲。一个包含多智能体验证阶段确保生成最终综述的一致性、全覆盖和事实准确性。
### Conclusion
实验表明，SurveyG 在专家和LLM评估中均优于最先进的框架，生成的综述更全面且更具结构化，能够更好地贴合特定领域的知识分类体系。
## 201. `cs.AI` - 门户已临：AI如何颠覆系统研究 [PDF](https://arxiv.org/pdf/2510.06189), [HTML](https://arxiv.org/abs/2510.06189)
### Authors
Audrey Cheng,Shu Liu,Melissa Pan,Zhifei Li,Bowen Wang,Alex Krentsel,Tian Xia,Mert Cemri,Jongseok Park,Shuo Yang,Jeff Chen,Lakshya Agrawal,Aditya Desai,Jiarong Xing,Koushik Sen,Matei Zaharia,Ion Stoica
### Background
人工智能(AI)正在开始通过自动化新解决方案的发现过程来转变我们熟知的研究流程。传统上，AI驱动的解决方法首先生成一组多样化的解决方案，然后对其进行验证并选择一个解决问题的方案。这一过程假设存在一个可靠的验证器，即能够准确判断一个方案是否解决了给定问题的验证器。本文认为，长久以来专注于设计和评估性能相关算法的系统研究，特别适合于由AI驱动的解决方案发现，因为系统性能问题通常具有可靠的验证器，解决方案通常在真实的系统或模拟器中实现，验证归结为运行这些软件产物并测量性能的过程。
### Innovation
提出了AI驱动的研究方法（ADRS），通过迭代生成、评估和细化解决方案，发现性能超越现有最佳设计的算法。针对现有框架总结了算法演变的最佳实践，从提示设计到评估器构建。并讨论了AI在算法设计中的重要作用，这将使研究人员更加关注问题定义和策略指导。此外，还展示了多种领域中ADRS的实际应用案例，如多区域云调度的负载均衡、专家混合推理、基于LLM的SQL查询以及事务调度。
### Conclusion
研究结果强调了AI时代的系统研究实践的颠覆性和迫切需要进行适应。随着AI在算法设计中的核心作用，人类研究人员将越来越多地集中在问题界定和战略引导上。
## 202. `cs.AI` - PEAR: Phase Entropy Aware Reward for Efficient Reasoning [PDF](https://arxiv.org/pdf/2510.08026), [HTML](https://arxiv.org/abs/2510.08026)
### Authors
Chen Huang,Wei Lu,Wenxuan Zhang
### Background
大型推理模型（LRMs）在复杂推理任务上取得了显著的性能，但它们生成的详细推理链（CoT）解释往往过长，包含冗余的推理步骤，这增加了推理成本并降低了可用性。控制生成的推理长度而不牺牲准确性仍然是一个未解的挑战。已有研究表明，不同推理阶段的模型熵与其响应长度之间存在正相关关系，思考阶段表现出较高的熵，反映出较长响应的探索性行为，而最终答案阶段则表现出较低的熵，表明更确定的解决方案。这一观察建议不同推理阶段的熵可以作为控制便捷性和性能之间的平衡的调节器。
### Innovation
本文引入了一种新的奖励机制——Phase Entropy Aware Reward (PEAR)，它将阶段依赖的熵纳入奖励设计中。相比于所有词元均等处理，PEAR 在思考阶段惩罚过高的熵，在最终答案阶段允许适度的探索，促使模型生成简明的推理轨迹，同时保留足够的灵活性以正确解决问题。这使得可以通过适应性地控制响应长度，而无需依赖显式的长度目标或刚性的截断规则。广泛的数据集实验显示，PEAR 能够在保持竞争力的同时减少响应长度，并且在分布外 (OOD) 的鲁棒性方面表现出色，超越了训练分布之外的效果。
### Conclusion
广泛的实验表明，PEAR 能够在保持准确性的基础上减少响应长度，同时展现出强大的分布外鲁棒性。这项工作的代码可以在此处找到：this https URL。
## 203. `cs.AI` -  ConjNorm: 可计算的密度估计用于异常分布检测 [PDF](https://arxiv.org/pdf/2402.17888), [HTML](https://arxiv.org/abs/2402.17888)
### Authors
Bo Peng,Yadan Luo,Yonggang Zhang,Yixuan Li,Zhen Fang
### Background
可靠机器学习领域，后验异常分布（OOD）检测近年来引起了广泛关注。许多研究致力于基于逻辑值、距离或严格的数据分布假设来推导得分函数，以识别得分较低的OOD样本。然而，这些估计得分可能无法准确反映真实数据密度或施加不切实际的约束条件。
### Innovation
提出了一种基于Bregman散度的新理论框架，该框架通过导出暴露的共轭约束条件，将密度函数设计重新定义为在给定数据集上寻找最优规范系数p的搜索。同时，通过蒙特卡洛重要性抽样技术，设计了一种无偏且解析上可处理的分区函数估计器，从而克服了归一化计算的挑战。
### Conclusion
在各种OOD检测基准上的广泛实验表明，提出的ConjNorm方法在多种OOD检测设置中取得了新的最佳性能，相比当前最佳方法在CIFAR-100和ImageNet-1K上的性能分别提升了13.25%和28.19%（FPR95）。
## 204. `cs.AI` - 通过排名和大型语言模型融合提升图像描述的详细程度 [PDF](https://arxiv.org/pdf/2306.11593), [HTML](https://arxiv.org/abs/2306.11593)
### Authors
Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano
### Background
当前最先进的（SoTA）图像说明模型通常在Microsoft公开的物体环境（MS-COCO）数据集上进行训练，该数据集包含短人类标注的描述，通常包含大约十个词。尽管有效于一般场景理解，但此类短描述往往无法捕捉复杂场景的细节和传达详细信息。此外，这类模型倾向于对“平均”描述表现出偏见，此类描述仅捕捉了更为一般性方面，从而忽略了详细信息。
### Innovation
本文提出了一种新的方法，通过结合不同SoTA图像描述模型生成的不同描述来生成更丰富和信息量更大的图像描述。该方法无需额外训练模型，给定一幅图像，利用文献中预先训练的模型生成初始描述，然后使用我们新引入的基于图像-文本的度量（BLIPScore）对这些描述进行排名。最后，使用大型语言模型（LLM）融合排名靠前的描述，生成最终更详细的照片描述。实验结果表明，在MS-COCO和Flickr30k测试集上，该方法在描述与图像对齐和减少幻觉方面效果显著，并且支持研究结果表明，由本文方法生成的描述一般被认为与人类判断更为一致。通过融合多样的SoTA模型的优势，该方法提升了图像描述的质量和吸引力，桥接了自动化系统与人类生成的、丰富且信息量大描述之间的差距。这种方法使得生成更合适的用于训练视觉-语言模型和图像描述模型的描述成为可能。
### Conclusion
通过结合不同SoTA图像描述模型生成的描述，本文提出的方法有效地提高了图像描述的详细程度，减少了幻觉，并且生成的描述更符合人类判断，从而提升了自动化图像描述系统的质量和吸引力。
## 205. `cs.AI` - Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning [PDF](https://arxiv.org/pdf/2403.19979), [HTML](https://arxiv.org/abs/2403.19979)
### Authors
Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang
### Background
class-incremental learning (CIL)旨在使模型能够连续学习新类别并克服灾难性遗忘。引入预训练模型带来了新颖的调整范式。本文回顾了在持续学习背景下不同参数高效调整（PET）方法。
### Innovation
本文提出了一种增量调整共享适配器的方法，不限制参数更新约束，增强主干网络的学习能力。还采用了从存储的原型中采样特征来重新训练统一分类器，进一步提高其性能。估计老化原型的语义偏移，更新存储的原型。该方法消除了模型扩展，避免保留任何图像样本，并超越了现有的基于预训练模型的CIL方法，展示了显著的持续学习能力。
### Conclusion
实验结果在五个CIL基准上验证了本文方法的有效性，达到了最先进的性能。
## 206. `cs.AI` - E-ICL: 通过原型理论提升细粒度情感识别 [PDF](https://arxiv.org/pdf/2406.02642), [HTML](https://arxiv.org/abs/2406.02642)
### Authors
Zhaochun Ren,Zhou Yang,Chenglong Ye,Yufeng Wang,Haizhou Sun,Chao Chen,Xiaofei Zhu,Yunbing Wu,Xiangwen Liao
### Background
在上下文学习（ICL）在知识获取、常识推理和语义理解等多种领域表现出显著性能后，其在情感检测任务中的表现显著下降，特别是在细粒度情感识别方面。虽然其背后的原因尚不清楚，但本文通过原型理论视角，发现了ICL在细粒度情感识别中的不足，并提出了改进方法。
### Innovation
本文首次基于原型理论，提出了E-ICL方法，具体包括：1）利用更情感准确的原型预测类别，通过参考动态标注的情感相似示例；2）采用排斥性情感预测策略，避免来自无关类别的干扰，从而提高准确性和鲁棒性。此过程不需要额外训练，使用的辅助情感模型占语言模型比例不到10%时，也能显著提升LLM的表现。
### Conclusion
实验表明，E-ICL在细粒度情感数据集EDOS、Empathetic-Dialogues、EmpatheticIntent、GoEmotions上的情感预测性能优异，即使辅助情感模型占比低于10%，也能提高LLM性能超过4%。
## 207. `cs.AI` - Robo-Instruct: 集成模拟器辅助指令对齐以微调代码大语言模型 [PDF](https://arxiv.org/pdf/2405.20179), [HTML](https://arxiv.org/abs/2405.20179)
### Authors
Zichao Hu,Junyi Jessy Li,Arjun Guha,Joydeep Biswas
### Background
代码大语言模型在自然语言任务到可由服务机器人执行的程序转换方面表现出良好的成果。然而，收集针对每个机器人定制的任务-程序数据集需要大量的时间和成本。虽然像SELF-INSTRUCT和EVOL-INSTRUCT这样的方法能够生成新任务，但它们无法基于提供的编程接口生成能遵守物理世界和机器人约束条件的正确程序。使用模拟器是一个检查这类约束的自然解决方案，但构建能够处理任意任务及其必要对象和位置的模拟环境是具有挑战性的。因此，本文提出了ROBO-INSTRUCT，其在程序执行过程中即时合成特定任务的模拟环境，并基于实体在任务程序中的使用情况来推测实体属性并施加相应约束。此外，ROBO-INSTRUCT还集成了一个大语言模型辅助的后处理过程，以细化指令以更好地与机器人程序对齐。
### Innovation
ROBO-INSTRUCT的主要创新之处在于它在程序执行过程中即时生成特定任务的模拟环境，并基于实体的使用情况推测实体属性并施加对应约束。此外，它还集成了大语言模型辅助的后处理步骤，以更好地对齐指令与机器人程序。这种方法能够有效处理物理世界和机器人约束，同时降低了数据收集的成本和时间。
### Conclusion
通过在多种代码大语言模型上进行演示，研究结果表明，我们的微调模型在所有基线方法上表现优异，并且甚至可以达到或超越几个更大且专有的模型的性能。
## 208. `cs.AI` - 基于信心加权的人机判断整合以实现卓越决策 [PDF](https://arxiv.org/pdf/2408.08083), [HTML](https://arxiv.org/abs/2408.08083)
### Authors
Felipe Yáñez,Xiaoliang Luo,Omar Valerio Minero,Bradley C. Love
### Background
大型语言模型（LLMs）在某些预测任务中可以超越人类。在这种情况下，人类在整体决策过程中还能发挥什么作用？一种可能性是，尽管人类的表现可能不如LLMs，但如果与之结合使用，人类仍能带来价值。当团队成员的自信校准良好并且在难度任务上存在分歧（即需要校准和多样性）时，人机团队可以在某些任务上超越各自的队友。本文简化并扩展了一种基于贝叶斯方法的判断整合方法，使用逻辑回归框架来结合任意数量团队成员的信心加权判断。该方法在图像分类和神经科学预测任务中展示了其有效性，结合人类判断和一个或多个机器可以始终提高整体团队的性能。背景信息展示了人机协作在提高决策质量方面的潜力。
### Innovation
本文简化并扩展了一种基于贝叶斯方法的判断整合方法，使用逻辑回归框架来整合任意数量团队成员的信心加权判断。该方法不仅适用于人机团队的决策过程，还在图像分类和神经科学预测任务中表现出色，提高了整体团队的性能。创新点在于提供了一种简单且有效的策略，来整合人类和机器的判断，促进了人机协作。
### Conclusion
希望通过这种方法，能够促进人机协作的高效发展，实现卓越的决策效果。这种简单且有效的方法可以为提高团队决策质量提供一个实用的策略。
## 209. `cs.AI` - 在复杂Q函数中缓解确定性策略梯度的次优性 [PDF](https://arxiv.org/pdf/2410.11833), [HTML](https://arxiv.org/abs/2410.11833)
### Authors
Ayush Jain,Norio Kosaka,Xinhu Li,Kyung-Min Kim,Erdem Bıyık,Joseph J. Lim
### Background
在强化学习中，如DDPG和TD3等离策略演员-评论家方法使用确定性策略梯度：Q函数从环境数据中学习，演员通过梯度上升来最大化它。然而，在诸如灵巧操作和受限移动等复杂任务中，Q函数表现出许多局部最优解，使得梯度上升容易陷入局优，导致算法无法找到全局最优解。
### Innovation
提出了SAVO（Success Action Value Optimization）演员网络架构，能够在多种任务中（如受限移动、灵巧操作和大型离散动作空间推荐系统）更频繁地找到最优动作。SAVO架构包括(i) 生成多个动作提案并选择Q值最高的那个；(ii) 通过截断较差的局部最优解多次逼近Q函数，更有效地引导梯度上升。
### Conclusion
通过评估复杂任务，证明SAVO演员网络在找到最优动作的频率上优于其他演员架构，并展示了其在多种复杂任务中的优越性。
## 210. `cs.AI` - 超声序列感知预训练方法Echocardiography中的探头移动指导 [PDF](https://arxiv.org/pdf/2408.15026), [HTML](https://arxiv.org/abs/2408.15026)
### Authors
Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang
### Background
超声心动图是诊断心血管疾病的重要医学技术，但由于其高操作复杂性，导致训练专业人员不足。心脏的复杂结构和个体差异使得超声心动图面临两大挑战。以往的研究仅仅学习了心脏的群体平均结构，而非个性化的心脏结构，导致性能瓶颈。临床观察表明，超声技师会根据先前的扫描序列动态调整对患者心脏解剖结构的解释，并进而优化扫描策略。
### Innovation
本文提出了一种序列感知的自监督预训练方法。具体来说，该方法通过预测扫描序列中的掩码特征和探头移动动作来学习个性化的三维心脏结构特征。作者假设如果模型能够预测缺失的内容，则表明它对个性化的心脏结构有很好的理解。实验结果显示，与先进的基线方法相比，提出的序列感知方法能够有效减少探头指导错误。
### Conclusion
研究通过大量的专家扫描数据集（包含167万个样本）的实验验证，证明了提出的序列感知预训练方法的有效性，能够在超声心动图探头移动指导中减少错误，展示了其在解决超声心动图操作复杂性问题上的潜力。
## 211. `cs.AI` - RAGDiffusion：通过外部知识融入实现可靠的布料生成 [PDF](https://arxiv.org/pdf/2411.19528), [HTML](https://arxiv.org/abs/2411.19528)
### Authors
Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni
### Background
标准服装资产生成涉及通过从多样化的真实世界环境中提取服装信息来恢复正面展示的平铺服装图像，这些图像通常显示在清晰的背景上。这带来了一定的挑战，因为这些图像结构高度标准化且在复杂场景中缺乏服装语义。现有的模型在空间感知方面具有局限性，常常在该高要求生成任务中出现结构错觉和纹理失真。
### Innovation
提出了一种新颖的检索增强生成（RAG）框架，名为RAGDiffusion，通过从语言模型和外部数据库整合知识来增强结构确定性和减轻错觉。RAGDiffusion包括两个过程：（1）基于检索的结构聚合，利用对比学习和结构局部线性嵌入（SLLE）来推导全局结构和空间地标，提供软和硬指导以对抗结构不确定性；（2）全方位忠实服装生成，引入了从粗到细的纹理对齐，确保细节和图案成分在扩散过程中的忠实性。
### Conclusion
在具有挑战性的现实世界数据集上进行的大量实验表明，RAGDiffusion能够合成结构和纹理都忠实的服装资产，显示出在高要求忠实生成中用RAG对抗固有错觉并提高忠实度方面的重要进展。
## 212. `cs.AI` - Medchain: 通过交互序列弥合大语言模型代理与临床实践之间的差距 [PDF](https://arxiv.org/pdf/2412.01605), [HTML](https://arxiv.org/abs/2412.01605)
### Authors
Jie Liu,Wenxuan Wang,Zizhan Ma,Guolin Huang,Yihang SU,Kao-Jung Chang,Wenting Chen,Haoliang Li,Linlin Shen,Michael Lyu
### Background
临床决策制定（CDM）是一个复杂且动态的过程，对医疗保健至关重要，但仍然是人工智能系统的重大挑战。尽管基于大型语言模型（LLM）的代理在通用医学知识方面已经通过了执照考试和知识问答任务的测试，但在真实世界临床场景中的CDM性能仍然有限，主要是因为缺乏全面的测试数据集来反映实际医疗实践。
### Innovation
MedChain是一个包含12,163个临床案例的数据集，涵盖了临床工作流程的五个关键阶段。它通过三个特征——个性化、互动性和序列性——与其他现有基准区分开来。为了解决实际临床场景中的CDM挑战，该研究还提出了MedChain-Agent，这是一种结合反馈机制和MCase-RAG模块的AI系统，能够从以往案例中学习并适应其回答。MedChain-Agent展示了在动态收集信息和处理序列化临床任务方面表现出色的能力，超越了现有方法。
### Conclusion
MedChain-Agent通过集成反馈机制和MCase-RAG模块，在动态信息收集和处理序列化临床任务方面表现出优异的适应能力，并显著优于现有的方法。
## 213. `cs.AI` - Generate Any Scene: Scene Graph Driven Data Synthesis for Visual Generation Training [PDF](https://arxiv.org/pdf/2412.08221), [HTML](https://arxiv.org/abs/2412.08221)
### Authors
Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna
### Background
现有的文本到视觉生成技术在视觉保真度方面表现出色，但在组成泛化和语义对齐方面存在问题。目前的数据集噪声大且缺乏组合性，限制了模型对复杂场景的理解能力。构建大规模、高质量的密集注释仍然是一项挑战。
### Innovation
该研究介绍了一个名为Generate Any Scene的数据引擎，能够系统性地列举表示各种视觉场景组合排列的场景图。Generate Any Scene能够动态构建具有不同复杂度的场景图，并将其转换为用于文本到图像或文本到视频生成的描述字或用于语义对齐的视觉问题解答。此引擎用于创建自我提升框架和教师模型等强化学习机制，以改进模型性能并实现特定专有模型能力的开源模型转移。还创建了奖励模型以低成本对齐模型生成与语义精度。
### Conclusion
利用这些方法，研究人员不仅提高了模型在复杂场景和难造概念生成上的性能，还在数据生成和下游内容审查任务方面取得了显著提升。
## 214. `cs.AI` - 医疗图像分析中Mamba架构全面综述：分类，分割，修复及更广阔的领域 [PDF](https://arxiv.org/pdf/2410.02362), [HTML](https://arxiv.org/abs/2410.02362)
### Authors
Shubhi Bansal,Sreeharish A,Madhava Prasath J,Manikandan S,Sreekanth Madisetty,Mohammad Zia Ur Rehman,Chandravardhan Singh Raghaw,Gaurav Duggal,Nagendra Kumar
### Background
Mamba作为状态空间模型的一种特殊情况，在医疗图像分析中作为基于模板的深度学习方法的替代方案越来越受欢迎。尽管变压器架构具有强大的功能，但也存在一些缺点，如计算复杂度呈二次增长和处理长程依赖关系的不足。这些限制影响了在医疗成像中处理大规模和复杂数据集的能力，这是因为医疗图像中有许多空间和时间的联系。相比之下，Mamba具有线性的时间复杂度，这比起变压器是一种显著的提升。Mamba能够处理长序列而无需使用注意力机制，这使得推理更快且需要更少的内存。Mamba在融合多模态数据方面也表现出色，提高了诊断准确性和患者结果。
### Innovation
Mamba架构提供了线性时间复杂度，这比变压器更具优势，能够更快速且更节省内存地处理长序列，提高了诊断准确性和患者结果。Mamba在医疗图像分析中表现出色，特别是在多模态数据的融合方面。其独特的架构设计解决了变压器计算复杂度高和处理长程依赖难的问题。
### Conclusion
本文综述了Mamba在医疗图像分析中的应用，包括分类、分割和修复。我们从状态空间模型的核心概念出发，介绍了Mamba的架构，包括纯Mamba、U-Net变体和与卷积神经网络、变压器、图形神经网络的混合模型。我们也涵盖了Mamba的优化方法、技术与适应性、数据集、应用、实验结果以及其在医疗图像中的挑战和未来方向。本文旨在展示Mamba在克服现有医疗图像分析障碍方面的潜力，并铺平未来创新发展的道路。
## 215. `cs.AI` - 基于LLM增强生成检索的偏好辨识 [PDF](https://arxiv.org/pdf/2412.08604), [HTML](https://arxiv.org/abs/2412.08604)
### Authors
Fabian Paischer,Liu Yang,Linfeng Liu,Shuai Shao,Kaveh Hassani,Jiacheng Li,Ricky Chen,Zhang Gabriel Li,Xiaoli Gao,Wei Shao,Xue Feng,Nima Noorshams,Sem Park,Bo Long,Hamid Eghbalzadeh
### Background
在序列推荐中，模型依据用户的交互历史推荐物品。现有模型通常综合使用物品描述和个人偏好或意图信息。然而，在公开数据集中，用户的偏好通常以隐式形式存在，需要通过类似语言模型（如大型语言模型）进行近似。当前方法仅在训练时利用近似的用户偏好，仅依赖于过去的交互历史进行推荐，这限制了模型动态适应用户变化偏好和打破回声室效应的能力。
### Innovation
为解决这个问题，本文提出了一个新的范式，即偏好辨识，将其作为一种生成推荐模型的生成检索方法，该模型在其上下文中明确考虑用户偏好表述的文本背景。此外，提出了一种新的基准测试评估偏好辨识，并通过对比当前最先进的方法发现，它们在动态适应用户变化偏好方面存在局限。对此，提出了一个新的方法Mender（多模态偏好辨识），该方法在我们的基准测试中达到了最先进的性能。
### Conclusion
我们的结果表明，Mender 能够有效地根据人类偏好调整推荐，即使这些偏好在训练过程中未被观察到。这为未来的更具灵活性的推荐模型奠定了基础。
## 216. `cs.AI` - SwarmGPT：结合大型语言模型与安全运动规划的无人机集群编舞 [PDF](https://arxiv.org/pdf/2412.08428), [HTML](https://arxiv.org/abs/2412.08428)
### Authors
Martin Schuck,Dinushka Orrin Dahanaggamaarachchi,Ben Sprenger,Vedant Vyas,Siqi Zhou,Angela P. Schoellig
### Background
无人机集群表演——同步、表现力强的空中表演配上音乐——已经成为现代机器人技术的一个引人入胜的应用。然而，设计流畅且安全的编舞仍然是一个复杂的过程，需要专家知识。现有的方法往往难以让非专家用户通过自然语言交互来迭代地改进编舞，同时确保不发生碰撞或不超出执行器的限制。
### Innovation
本文介绍了一种基于语言的编舞工具SwarmGPT，它利用了大型语言模型（LLMs）的推理能力，简化了无人机表演的设计流程。该系统通过与安全过滤器结合，确保编舞的部署性，并能做出最小的纠正来解决安全或可行性约束的问题。SwarmGPT能够将高层编舞设计与低层运动规划分离开来，从而使非专家用户能够通过自然语言交互来迭代地改进编舞，而不必担心碰撞或执行器限制。本文通过最多200架无人机的模拟和最多20架无人机的实际试验验证了这一方法，展示了可扩展、同步和安全的表演。这些成果不仅对娱乐领域有重要意义，也为将基础模型集成到安全性关键的无人机集群应用中提供了范例。
### Conclusion
通过模拟和实地实验验证，SwarmGPT展示了其在无人机集群表演编舞中的应用效果，能够实现可扩展、同步和安全的表演。此外，这项工作为将基础模型集成到安全关键的无人机集群应用中提供了蓝图。
## 217. `cs.AI` - AD-LLM：大型语言模型异常检测基准测试 [PDF](https://arxiv.org/pdf/2412.11142), [HTML](https://arxiv.org/abs/2412.11142)
### Authors
Tiankai Yang,Yi Nian,Shawn Li,Ruiyao Xu,Yuangang Li,Jiaqi Li,Zhuo Xiao,Xiyang Hu,Ryan Rossi,Kaize Ding,Xia Hu,Yue Zhao
### Background
异常检测(AD)是一个重要的机器学习任务，广泛应用于欺诈检测、医疗诊断和工业监控等领域。在自然语言处理(NLP)领域，AD有助于检测诸如垃圾信息、误导性信息和异常用户活动等问题。尽管大型语言模型(LLMs)在文本生成和总结等方面表现出很强的能力，但它们在AD中的潜力尚未得到充分研究。这项研究介绍了AD-LLM，这是首个评估LLMs在NLP异常检测中作用的基准测试，涵盖了零样本检测、数据增强和模型选择三项关键任务。
### Innovation
首次提出了AD-LLM基准测试，以评估LLMs在NLP异常检测中的应用，并通过实验显示了在零样本异常检测、精心设计的数据增强方法的有效性以及特定数据集的模型选择解释的挑战性。
### Conclusion
研究表明，LLMs在零样本异常检测中有很好的表现，精心设计的数据增强方法是有用的，然而特定数据集的模型选择解释仍然具有挑战性。基于这些结果，提出了六项针对LLMs在AD中的未来研究方向。
## 218. `cs.AI` - OrcaLoca：一种用于软件问题定位的LLM代理框架 [PDF](https://arxiv.org/pdf/2502.00350), [HTML](https://arxiv.org/abs/2502.00350)
### Authors
Zhongming Yu,Hejia Zhang,Yujie Zhao,Hanxian Huang,Matrix Yao,Ke Ding,Jishen Zhao
### Background
近年来，大型语言模型（LLM）代理在自主软件工程（ASE）中的发展正在革新自动化编程、问题修复和功能改进。然而，精确定位软件问题——即通过导航到相关代码段来准确识别问题——仍然是一个重要的挑战。当前的方法往往因为LLM代理与精确代码搜索机制之间的有效整合不足而产生次优结果。
### Innovation
本文提出了一种名为OrcaLoca的LLM代理框架，通过结合基于优先级的调度、LLM引导行动分解与相关性评分以及距离感知上下文剪枝，提高了软件问题定位的准确性。实验结果表明，OrcaLoca在SWE-bench Lite上的函数匹配率达到了65.33%，成为开源领域的最新前沿技术。此外，通过其补丁生成集成，OrcaLoca还提高了开源框架最终解决率6.33个百分点。
### Conclusion
实验结果证明，OrcaLoca框架在功能匹配率方面已成为开源领域的最新开放源代码前沿技术，同时增强了开源框架的问题解决效率。
## 219. `cs.AI` - 使用解耦扩散序列蒙特卡洛方法求解线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
### Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
### Background
近期的研究利用预训练的生成扩散模型作为先验解决贝叶斯逆问题。本研究延续这一研究方向，设计了一种基于‘解耦扩散’的顺序蒙特卡洛方法，专注于线性-高斯逆问题。
### Innovation
该方法利用解耦扩散机制，使得样本更新更具灵活性。该方法在理论上具有渐近确切性，并成功应用于合成数据、蛋白质数据和图像数据，显示出其有效性。此外，还展示了该方法如何拓展至离散数据。
### Conclusion
作者通过设计的解耦扩散顺序蒙特卡洛（DDSMC）算法，有效解决了线性高斯逆问题，并通过多种类型的数据验证了算法的有效性，同时为未来研究离散数据提供了可能的路径。
## 220. `cs.AI` - RadVLM: 一种用于放射学的多任务对话视觉语言模型 [PDF](https://arxiv.org/pdf/2502.03333), [HTML](https://arxiv.org/abs/2502.03333)
### Authors
Nicolas Deperrois,Hidetoshi Matsuo,Samuel Ruipérez-Campillo,Moritz Vandenhirtz,Sonia Laguna,Alain Ryser,Koji Fujimoto,Mizuho Nishio,Thomas M. Sutter,Julia E. Vogt,Jonas Kluckert,Thomas Frauenfelder,Christian Blüthgen,Farhad Nooralahzadeh,Michael Krauthammer
### Background
随着胸部X光（CXR）的广泛应用和放射科医生短缺，自动CXR分析和AI辅助报告的需求日益增加。现有的视觉语言模型虽然在特定任务如报告生成或异常检测中表现出色，但在支持交互式诊断功能方面却较为有限。
### Innovation
本文提出了RadVLM，这是一种专门设计用于胸部X光解读的紧凑式的多任务对话基础模型。通过创建包含超过100万图像指令对的大规模指令数据集，RadVLM能在各种任务中表现出卓越的对话能力和视觉定位能力，同时在其他放射学任务上保持竞争力。实验证明，联合多任务训练对于有限标注数据场景下的效果尤为有益。
### Conclusion
RadVLM 提示了作为临床相关AI助手的潜力，不仅提供结构化的X光解读，还增强了对话能力，支持更有效和易于访问的诊断流程。
## 221. `cs.AI` - IG-MCTS: 人类参与下的不完整信息下的协同导航 [PDF](https://arxiv.org/pdf/2502.01857), [HTML](https://arxiv.org/abs/2502.01857)
### Authors
Shenghui Chen,Ruihan Zhao,Sandeep Chinchali,Ufuk Topcu
### Background
在不完整信息条件下，人类与机器人的协同导航具有挑战性。在这种情境下，机器人依靠局部感知导航，而人类操作员则基于不准确的地图提供指导。机器人可以通过共享其车载摄像头视图来帮助操作员改进对环境的理解。为了实现高效的协同工作，本文提出了一种联合优化自主移动和信息通信的在线规划算法——信息增益蒙特卡洛树搜索（IG-MCTS）。
### Innovation
本文提出了IG-MCTS算法，该算法利用从众包地图数据集中训练出的神经人类感知模型（NHPM），预测人类内部地图如何随新观测数据的共享而进化。该算法能够在线规划，同时优化机器人的自主移动和与操作员的通信效率，从而减少交流需求，并降低认知负担，同时保持与直接远程操作和指令遵循基线相当的任务性能。此外，该研究还展示了IG-MCTS算法在连续空间水道导航任务中的泛化能力，即NHPM从深层编码器-解码器架构中获益，并利用动态构建的Voronoi分区可通行图来优化规划过程
### Conclusion
该研究通过CoNav-Maze仿真环境验证了IG-MCTS算法的有效性，展示了在不完整信息条件下人与机器人的高效协同导航能力，并证明了算法在不同场景下的通用性和优越性。
## 222. `cs.AI` - 在GPU加速中启用基于树的遗传编程的种群级并行性 [PDF](https://arxiv.org/pdf/2501.17168), [HTML](https://arxiv.org/abs/2501.17168)
### Authors
Zhihong Wu,Lishuang Wang,Kebin Sun,Zhuozhao Li,Ran Cheng
### Background
基于树的遗传编程（TGP）是一种广泛用于符号回归、分类和机器人控制等任务的演化算法。由于运行TGP需要大量的计算资源，因此GPU加速对于实现可扩展性能至关重要。然而，高效的GPU加速TGP仍然是一个挑战，主要原因是TGP个体结构的异质性、多级并行性集成的复杂性以及高性能CUDA执行与灵活的Python环境之间的不兼容性。
### Innovation
该文提出了EvoGP框架，这是一种为通过种群级并行执行加速TGP而优化的高性能框架。主要创新包括：1. 引入张量表示，将可变大小的树编码为固定形状、对齐内存的数组，以实现均匀内存访问和在多样个体间并行计算；2. 采用自适应并行策略，基于数据集大小动态组合个体内和个体间并行性，确保广泛的任务中高GPU利用率；3. 在PyTorch运行时嵌入自定义CUDA内核，实现与Python环境（如Gym、MuJoCo、Brax和Genesis）无缝集成。
### Conclusion
实验结果表明，EvoGP达到了峰值吞吐量超过$10^{11}$ GPops/s，相比基于GPU的TGP实现最多加速528倍，相比最快的CPU库加速18倍，并保持相似的准确性，在大种群规模下具有更好的可扩展性。EvoGP是开源的，可以在如下网址访问：this https URL.
## 223. `cs.AI` - WyckoffDiff — 一种用于晶体对称性的生成扩散模型 [PDF](https://arxiv.org/pdf/2502.06485), [HTML](https://arxiv.org/abs/2502.06485)
### Authors
Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten
### Background
结晶材料通常表现出高度对称性，但大多数生成模型并未考虑对称性，而是针对每个原子独立建模而不对其位置或元素进行任何约束。该论文提出了一个生成模型WyckoffDiff，该模型能够基于对称性来描述晶体，通过考虑能够编码所有对称性的晶体结构表示，并设计出一种新的神经网络架构来在离散生成模型框架中使用该表示，从而使得生成过程更快且能遵守对称性。同时，该论文还提出了一种新的度量标准Fréchet Wrenformer Distance，用于捕捉生成材料的对称性特性，并将WyckoffDiff与最近提出的几种晶体生成模型进行了对比测试。作为概念验证研究，作者使用WyckoffDiff在热力学稳定性凸包之下寻找新的材料。
### Innovation
该研究引入了一种新的生成模型WyckoffDiff，能够在晶体生成过程中考虑对称性。通过采用能够编码所有对称性的晶体结构表示，并设计出适应离散生成模型框架的神经网络结构，使得生成过程不仅遵守对称性，而且还能够加快生成速度。此外，还提出了一种新的度量标准Fréchet Wrenformer Distance，用于评估生成材料的对称性特性。
### Conclusion
该研究提出的生成模型WyckoffDiff相比现有的模型能够更好地利用晶体的对称性特性，实现了更快的生成速度。进一步的实验表明，WyckoffDiff在生成具有对称性的材料方面具有优势。作为一种概念验证，WyckoffDiff成功地在热力学稳定性区域下方找到新的材料。
## 224. `cs.AI` - 对比学习增强的社会推荐 [PDF](https://arxiv.org/pdf/2502.15695), [HTML](https://arxiv.org/abs/2502.15695)
### Authors
Lin Wang,Weisong Wang,Xuanji Xiao,Qing Li
### Background
推荐系统对于现代内容平台至关重要，但传统的基于行为的模型在处理缺乏互动数据的冷启动用户时往往表现不佳。吸引这些用户对于平台的增长至关重要。为了解决这一问题，本文提出利用社会关系图来丰富基于行为的兴趣表示。然而，从社会图中提取价值存在挑战，因为社会图中的关系噪声和跨域不一致导致的问题。
### Innovation
本文采用了一种双视图去噪策略，通过低秩SVD对用户-项目交互矩阵进行去噪以得到清洁的社会关系图，并利用对比学习将原始的社会关系图和重构的社会关系图进行对齐。同时，为了处理社会兴趣和行为兴趣之间的一致性问题，本文采用了“互学习”技术来分离出原始兴趣到对齐的社会/行为兴趣和具有专门兴趣的社会/行为特定兴趣，从而最大化两者的价值。实验结果验证了该方法的有效性，尤其是对冷启动用户具有显著效果，为未来的研究提供了新的视角。
### Conclusion
研究结果在广泛采用的工业数据集上得到验证，特别是在处理冷启动用户方面表现出色。该方法提供了未来研究的新视角，并已经开源实现。读者可以在指定的链接下载代码进行研究。
## 225. `cs.AI` - 使用可预测性测量图像字幕中的方向性偏差放大 [PDF](https://arxiv.org/pdf/2503.07878), [HTML](https://arxiv.org/abs/2503.07878)
### Authors
Rahul Nair,Bhanu Tokas,Hannah Kerner
### Background
在使用有偏差的机器学习数据集训练模型时，模型不仅会学习这些偏差，还可能在测试时放大这些偏差，这被称为偏差放大。现有的基于共现性的度量方法有效用于简单问题如图像分类，但在复杂问题如图像字幕中并不有效，因为它们无法捕捉字幕的语义。为此，前人提出了基于可预测性的度量方法漏出度量（LIC），但LIC在识别偏差放大方向、估算数据集偏差以及对抗模型敏感性方面存在局限性。
### Innovation
本文提出了一种名为Directional Predictability Amplification in Captioning (DPAC)的新方法，用于测量字幕中的方向性偏差放大，通过改进的词汇替换策略更好地估计数据集偏差，并减少对攻击模型的敏感性，从而使DPAC成为衡量字幕中偏差放大的最可靠指标。
### Conclusion
通过在COCO字幕数据集上的实验，证明了DPAC是测量字幕中偏差放大的最可靠方法。
## 226. `cs.AI` - CCDP：条件扩散策略的组成与引导采样 [PDF](https://arxiv.org/pdf/2503.15386), [HTML](https://arxiv.org/abs/2503.15386)
### Authors
Amirreza Razmjoo,Sylvain Calinon,Michael Gienger,Fan Zhang
### Background
模仿学习提供了一种有希望的方法，可以直接从数据中学习而无需明确的模型、模拟或详细的任务定义，在推理过程中，动作是从学习到的分布中抽取并被执行在机器人上。然而，抽取的动作可能会因为多种原因失败，仅仅重复抽样步骤直到获得成功动作可以效率低下。
### Innovation
本文提出了一种增强的采样策略，通过细化采样分布以避免之前无效的动作。通过仅利用成功演示的数据，我们的方法可以在无需额外探索行为或高阶控制器的情况下推断恢复动作。此外，我们利用扩散模型分解的概念，将主要问题分解为多个更小且更易于管理的子问题，在学习、数据收集和推理中，这使得系统能够适应变量的失败次数。
### Conclusion
我们的方法在多次任务上（包括未知方向开门、物体操作和按钮搜索场景）进行了验证，并表明我们的方法优于传统的基线方法，实现了一个低级控制器，能够动态调整其采样空间以提高效率。
## 227. `cs.AI` - TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis [PDF](https://arxiv.org/pdf/2504.05684), [HTML](https://arxiv.org/abs/2504.05684)
### Authors
Tri Ton,Ji Woo Hong,Chang D. Yoo
### Background
该研究提出了基于流动变换器的高保真度和时间连贯视频到音频合成的新型框架Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning (TARO)。该框架改进了与动态视觉事件同步的音频质量，并展示了在VGGSound和Landscape数据集上的出色性能，优于先前的方法，特别是在FAD和FD指标上有了显著改善。
### Innovation
TARO的主要创新包括：(1) Timestep-Adaptive Representation Alignment (TRA)，动态调整不同的噪声时间步长以调整表示对齐强度，以确保平滑进化并提高保真度；(2) Onset-Aware Conditioning (OAC)，通过集成音频相关的视觉时刻的突发线索来增强与动态视觉事件的同步。
### Conclusion
实验结果表明，TARO相较于先前的方法性能更佳，在Frechet Distance、Frechet Audio Distance和Alignment Accuracy方面分别达到了53%、29%的下降和97.19%的高对齐精度，显示出了其出色的音频质量和同步精度。
## 228. `cs.AI` - DeepOHeat-v1: 高效的操作学习方法以实现快速且可靠的三维集成电路（3D-IC）设计中的热仿真与优化 [PDF](https://arxiv.org/pdf/2504.03955), [HTML](https://arxiv.org/abs/2504.03955)
### Authors
Xinling Yu,Ziyue Liu,Hai Li,Yixing Li,Xin Ai,Zhiyu Zeng,Ian Young,Zheng Zhang
### Background
由于三维集成电路（3D-IC）设计中热密度增加和复杂的热传导路径，热分析变得至关重要。现有操作学习框架如DeepOHeat表现出加速热仿真方面的初步潜力，但在处理多尺度热模式的预测能力、训练效率以及结果可信度方面仍存在显著限制。
### Innovation
DeepOHeat-v1通过三个创新点解决这些挑战：1. 将柯尔莫哥洛夫-阿诺尔德网络与可学习激活函数结合作为主干网络，实现对多尺度热模式的自适应表示；2. 引入分隔训练方法，沿坐标轴分解基函数，提高62倍的训练速度并减少31倍的GPU内存使用，使得精细分辨率下的热分析得以实现；3. 提出可信度评分评估预测结果的可信度，并结合有限差分法（FD）和广义最小残差法（GMRES）的方法进行增量解算优化，实现高效且可靠的热优化。
### Conclusion
实验结果显示，DeepOHeat-v1在模型准确性和优化过程的速度上均表现出色，优化过程速度比高保真有限差分解法快70.6倍，通过优化热源组件的布局成功减小了峰值温度。
## 229. `cs.AI` - Brain2Text解码模型揭示视觉语义处理的神经机制 [PDF](https://arxiv.org/pdf/2503.22697), [HTML](https://arxiv.org/abs/2503.22697)
### Authors
Feihan Feng,Jingxin Nie
### Background
在神经科学和人工智能领域，从神经活动解码感性体验以重建人类感知的视觉刺激和语义内容仍是一项挑战。尽管当前的脑解码模型取得了显著进展，但在系统地整合这些模型与既有的神经科学理论方面仍存在关键差距，并且对潜在的神经机制探索不足。
### Innovation
本文提出了一种新的框架，直接将fMRI信号解码为自然图像的文本描述。训练该新型深度学习模型无需视觉信息，其语义解码性能达到了最先进的水平，生成了能够捕捉复杂场景核心语义内容的描述性标题。通过神经解剖学分析发现，较高水平的视觉皮层（包括MT+复和、腹侧通路视觉皮层、下顶叶皮层）在视觉语义处理中起着关键作用。此外，通过类别特异性分析还展示了对于语义维度如有生命性和运动性的精细神经表征。这项工作为脑语义解码提供了一个更直接和可解释的框架，为探索复杂语义处理的神经基础提供了一种强大新方法，进一步完善了分布式语义网络的理解，并可能发展出仿脑语言模型。
### Conclusion
这种工作提供了一种更直接且可解释的框架来解码脑的语义，为探索复杂语义处理的神经基础和神经科学理论提供了强力建设性方法，有助于理解分布式语义网络，并可能促进脑启发的语言模型的发展。
## 230. `cs.AI` - 通过LLM驱动的迭代代码图搜索进行问题定位 [PDF](https://arxiv.org/pdf/2503.22424), [HTML](https://arxiv.org/abs/2503.22424)
### Authors
Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu
### Background
问题解决旨在根据问题描述在真实世界的代码仓库中生成修复补丁。问题定位是准确问题解决的基础。近年来，基于大语言模型（LLM）的问题定位方法表现出最先进的性能。然而，这些方法在搜索空间的广度和深度上难以平衡，不能高效地收敛到目标。此外，它们允许LLM自由地探索整个仓库，这使得控制搜索方向和防止LLM搜索错误目标变得困难。
### Innovation
本文提出了一种名为CoSIL的有效函数级别问题定位方法，该方法无需训练或索引。CoSIL采用了两阶段的代码图搜索策略：首先通过动态构建的模块调用图进行文件级别的广泛探索，然后通过扩展模块调用图到函数调用图并执行迭代搜索，进行深度分析。CoSIL设计了一个修剪器来过滤无关方向和无关上下文，以精确控制搜索方向。CoSIL还引入了回声机制，利用额外的短上下文独立查询增强格式化能力，以避免在长上下文中出现错误的交互格式。实验结果表明，CoSIL分别在SWE-bench Lite和SWE-bench Verified上实现了43.3%和44.6%的Top-1定位准确性（使用Qwen2.5-Coder-32B），并平均优于现有最佳方法96.04%。在与问题解决方法Agentless结合时，问题解决率提高了2.98%到30.5%。
### Conclusion
实验结果表明，CoSIL在准确的问题定位方面表现出色，并且在集成到问题解决方法Agentless后能显著提高问题解决率。
## 231. `cs.AI` - 使用连续令牌的扩散生成推荐 [PDF](https://arxiv.org/pdf/2504.12007), [HTML](https://arxiv.org/abs/2504.12007)
### Authors
Haohao Qu,Shanru Lin,Yujuan Ding,Yiqi Wang,Wenqi Fan
### Background
近年来，生成式人工智能，尤其是大型语言模型（LLMs），为增强推荐系统（RecSys）开辟了新的机遇。大多数基于LLM的RecSys方法在离散空间中操作，通过使用向量量化分词器来适应语言模型的本质离散性。然而，这些量化方法往往会导致分词过程中信息丢失和学习效果不佳，主要是由于标准向量量化中的非可微argmin操作导致的梯度传播不准确。本文在现有方法基础上进行背景描述。
### Innovation
该研究提出了ContRec，一种新的框架，将连续令牌无缝集成到基于LLM的RecSys中。ContRec由两个关键模块组成：sigma-VAE分词器，用于用连续令牌编码用户/项目；以及分散扩散模块，用于捕捉隐式用户偏好。sigma-VAE分词器通过连续变分自编码器（VAE）目标进行训练，并采用三种有效技术以避免表示崩溃。分散扩散模块使用一种新颖的分散损失进行条件扩散过程，通过下一个令牌的扩散生成高质量的用户偏好。ContRec结合LLM的文本推理输出和扩散模型生成的潜在表示进行Top-K项检索，从而提供全面的推荐结果。
### Conclusion
通过在四个数据集上的广泛实验，该研究证明了ContRec在性能上优于传统和SOTA的基于LLM的推荐系统。实验结果突显了连续令牌化和生成性建模在推动下一代推荐系统方面的潜力。
## 232. `cs.AI` - 使用大型语言模型探索人类与共享自主车辆的互动：心理因素对用户体验的影响 [PDF](https://arxiv.org/pdf/2504.16548), [HTML](https://arxiv.org/abs/2504.16548)
### Authors
Lirui Guo,Michael G. Burke,Wynita M. Griggs
### Background
之前的研究已经广泛探讨了心理因素，如拟人化，对共享自主车辆（SAVs）的采用产生的影响。然而，有关大型语言模型（LLM）驱动的交互式SAV代理的提示策略如何影响用户对技术的感知、体验及采用意愿的研究却相当有限。因此，本文旨在探究LLM驱动的SAV代理如何通过影响心理因素，如心理拥有感，来驱动用户的态度。
### Innovation
本文创新性地设计了四种具有不同拟人特征和心理拥有感触发器的SAV代理，以定量和定性评估用户与SAV交互过程中的心理拥有感、拟人化、服务质量、披露倾向、SAV响应的情感色彩及整体接受度。研究结果表明，更加拟人化的SAV能够显著提升用户对其拟人类质的感知，并使其响应更具有积极但同时更为主观的情感色彩。这也是首次通过定性和定量方法证实心理拥有感在SAV情境中的作用。
### Conclusion
研究结果表明，个性化设计在创造有效的SAV互动体验方面至关重要。这些发现为设计能够提升用户体验和采用率的交互式SAV代理提供了实用指导。
## 233. `cs.AI` - Cognitio Emergens: 在人类与人工智能知识共创中的行动、维度和动态 [PDF](https://arxiv.org/pdf/2505.03105), [HTML](https://arxiv.org/abs/2505.03105)
### Authors
Xule Lin
### Background
人类与人工智能的科学合作已经从工具使用者的关系转变为共进退的战略伙伴关系。人工蛋白质序列折叠预测程序AlphaFold的出现反映了科学家与智能伴侣互动以改变结构与功能问题解决方法的这一趋势。然而，现有的框架大多将人工智能视为更复杂的工具或潜在的风险，忽视了通过递归互动生发科学理解的重要性。
### Innovation
本文引入了一个名为Cognitio Emergens (CE)的框架，以捕捉人类和人工智能共进退的认知伙伴关系的本质。该框架借鉴了自组织理论、社会系统理论以及组织模块化理论，包括三个方面：行动配置模型、认知维度和伙伴关系动态。它提出了动态而非线性的伙伴关系模式，捕捉了六个认知维度的能力，以及引导战略发展的独特“能力印记”，同时识别了进化力量，如认知排斥，即研究者失去对他们正式支持的知识的解释控制。
### Conclusion
该框架使研究者能够诊断维度上的不平衡，使机构领导人能够设计支持多样行动配置的治理结构，使政策制定者能够发展超越简单绩效指标的评估体系。通过重新构想人类与人工智能合作为本源上的共进退，CE提供了培养既能保持认知完整性又能实现人类和人工智能无法独立完成的变革性突破的伙伴关系的概念工具有重要作用。
## 234. `cs.AI` - 开发者声明AI生成代码的现状分析 [PDF](https://arxiv.org/pdf/2504.16485), [HTML](https://arxiv.org/abs/2504.16485)
### Authors
Syed Mohammad Kashif,Peng Liang,Amjed Tahir
### Background
随着AI代码生成工具在开发人员中的普及，它们被广泛用于软件开发以生成代码。现有研究主要集中在评估AI生成代码的质量，如正确性和安全性。然而，在实际软件开发过程中，识别AI生成代码与人工编写代码的过程是必需的，因此开发人员需明确声明AI生成的代码。因此，本研究旨在理解开发人员声明AI生成代码的方法，并探讨他们为何选择声明或不声明的原因。研究包括两个阶段，第一阶段通过GitHub仓库收集了613个AI生成代码片段，第二阶段进行了一项针对111名开发者的跟进调查。研究表明，大多数开发者（76.6%）时常或总是声明AI生成代码，而其他开发者（23.4%）则从不声明。声明AI生成代码的原因包括跟踪和监控代码进行未来审查和调试，以及伦理考量。而不声明的原因包括对AI生成代码大量修改和认为声明是不必要的活动。最后，提出了关于如何声明AI生成代码的实践指南，以解决伦理和代码质量的问题。
### Innovation
本研究通过混合方法研究了开发人员声明AI生成代码的行为及其原因，填补了现有研究在该领域的空白，为AI生成代码的透明度和伦理提供了新的视角。
### Conclusion
大多数开发人员声明AI生成的代码，声称或总是声明的比例为76.6%，因为需要跟踪和监测代码以进行未来审查和调试，以及伦理原因。然而，一些修改后的代码和不必要的活动感知使得其他开发人员选择不声明。研究提供了关于如何声明AI生成代码的建议，解决了伦理和代码质量的问题。
## 235. `cs.AI` - 协作无标签数据优化 [PDF](https://arxiv.org/pdf/2505.14117), [HTML](https://arxiv.org/abs/2505.14117)
### Authors
Xinyi Shang,Peng Sun,Fengyuan Liu,Tao Lin
### Background
现有模型中心化方法存在三个关键限制，根源在于从数据中提取的知识与模型参数绑定，限制了知识的重用性和扩展性。
### Innovation
提出了一种高效并行协作无标签数据优化框架CoOpt，通过分布无标签数据和利用公开的、任务无关的模型，实现可扩展、可重用和可持续的训练管道。
### Conclusion
通过在多样化的数据集和架构上进行广泛实验，证明CoOpt的有效性和效率，分别在Tiny-ImageNet和ImageNet-1K上实现了13.6%和6.8%的性能提升，并且在训练速度上分别提升1.94倍和1.2倍。
## 236. `cs.AI` - 多模态语言模型在查看更浅层时表现更好 [PDF](https://arxiv.org/pdf/2504.21447), [HTML](https://arxiv.org/abs/2504.21447)
### Authors
Haoran Chen,Junyan Lin,Xinghao Chen,Yue Fan,Jianfeng Dong,Xin Jin,Hui Su,Jinlan Fu,Xiaoyu Shen
### Background
当前的多模态大型语言模型（MLLMs）通常从预训练的视觉变换器（ViT）的最终层中提取视觉特征。这一做法主要是基于经验惯例，缺乏深入分析。此前的研究表明，不同层的ViT捕捉的信息类型不同：浅层专注于细腻的视觉细节，而深层则更贴近文本语义。然而，这种变化对MLLM性能的影响尚未得到充分探索。本文进行了首次全面研究，通过分析ViT各层的表示相似性来确定浅层、中层和深层的区分，并在涵盖60多种任务的10个基准测试上对1.4B-7B参数的MLLMs进行了广泛评估，表明浅层和中层在细粒度视觉任务如计数、定位和对象检测方面明显优于深层，尤其是在语义丰富任务如OCR上，深层则表现更佳。
### Innovation
本文首次提出了关于MLLMs视觉层选择的系统性研究，提出了一种轻量级的特征融合方法，通过战略性地整合浅层特征，实现了比单一层次和专属性融合基线的一致改进，并提供了首个基于原理的MLLMs视觉层选择案例，证明了MLLMs在某些情况下通过查看更浅层可以获得更好的表现。
### Conclusion
研究结果表明，MLLMs在处理细粒度视觉任务时，可能更擅长利用浅层和中层的特征，而在语义丰富的任务上则可能受益于深层的高语义表征能力。该方法为多模态大型语言模型的特征融合与优化提供了新的思路和实践指导。
## 237. `cs.AI` - 连续部分可观测量决策过程中的Sequential Monte Carlo策略优化 [PDF](https://arxiv.org/pdf/2505.16732), [HTML](https://arxiv.org/abs/2505.16732)
### Authors
Hany Abdulsamad,Sahel Iqbal,Simo Särkkä
### Background
在部分可观测的环境下作出最优决策需要在减少不确定性（探索）和追求即时目标（利用）之间进行平衡。本文面向连续的部分可观测量马尔可夫决策过程（POMDP），探讨了如何解决这一挑战.
### Innovation
本文引入了一种新的策略优化框架，将策略学习视为在非马尔可夫费曼-卡克模型中的概率推理，该模型能够内在地捕捉信息收集的价值，而无需使用次优近似或手工设计的启发式规则。通过开发嵌套的顺序蒙特卡洛（SMC）算法，本文有效估计了依赖历史的策略梯度，且该算法是在由POMDP诱导的最优轨迹分布的样本下进行估计的.
### Conclusion
本文展示了该算法在标准的连续POMDP基准测试中的有效性，在不确定性下现有方法难以有效行动的问题中，新的算法表现出色.
## 238. `cs.AI` - 使用元学习进行系统提示优化 [PDF](https://arxiv.org/pdf/2505.09666), [HTML](https://arxiv.org/abs/2505.09666)
### Authors
Yumin Choi,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）展现了强大的能力，而优化其输入提示对于提升性能至关重要。尽管LLM的提示包括任务无关的系统提示和任务特定的用户提示，现有的提示优化工作主要集中在针对特定查询或任务的用户提示上，而忽视了可以在不同任务和领域中通用的系统提示。因此，本研究引入了双层系统提示优化的新型问题，目标是设计既对多样用户提示具有鲁棒性又能在未知任务中迁移的系统提示。
### Innovation
研究提出了一个元学习框架，通过在多个数据集上迭代优化系统提示和更新用户提示，实现对多种用户提示的鲁棒性和在未知任务上的迁移能力。实验结果表明，该方法能够有效生成适用于多样化用户提示的系统提示，并在未知任务中实现快速适应，减少测试阶段所需的优化步骤，同时提高性能。
### Conclusion
研究展示了如何通过元学习框架有效优化系统提示，从而提升大型语言模型的性能。优化后的系统提示不仅能适应多样化的用户提示，还能在未知任务中快速适应，减少优化步骤并提高性能。
## 239. `cs.AI` - 信任游戏：你的区块链认为你有多可信？ [PDF](https://arxiv.org/pdf/2505.14551), [HTML](https://arxiv.org/abs/2505.14551)
### Authors
Petros Drineas,Rohit Nema,Rafail Ostrovsky,Vassilis Zikas
### Background
本文探讨区块链如何将节点关于一组节点可信度的集体信念提炼成一个反映正确执行任务概率的声誉系统。研究将这一问题分解为两个子问题：首先，如何将信任信息从节点真实信念的函数中提炼出来；其次，如何激励节点如实报告此类信息。为解决第一个子问题，本文对广为人知的PageRank算法进行创新性改编。为解决第二个子问题，本文引入了一类新的博弈类型，称为信誉游戏中可信度（Trustworthy Reputation games，简称TRep游戏），旨在从参与者的行为中提取集体信任信念。在此基础上，提出了一个基于个性化PageRank的TRep游戏，并通过简单的区块链奖励机制实现。这一系统能够增强区块链和DeFi解决方案的稳健性、可扩展性和效率。并通过一个具体的实例展示如何在声誉区块链中使用此类系统。
### Innovation
本文的创新之处在于对PageRank算法进行了创新性改编，提出了新的游戏类型（TRep游戏）来提取参与者的集体信任信念，并且设计了一种基于TRep游戏的区块链奖励机制来激励节点如实报告信任信息，最终实现了一个可广泛应用的声誉系统，提升了去中心化解决方案的安全性与效率。
### Conclusion
本文提出的TRep游戏和基于个性化PageRank的声誉系统可以显著提升区块链和DeFi解决方案的鲁棒性、可扩展性和效率。在区块链中使用该系统可以增强其安全性，提高其可靠性，并有助于促进更高效的去中心化金融交易。
## 240. `cs.AI` - DDO：多智能体合作的LLM方法在医学咨询中的双决策优化 [PDF](https://arxiv.org/pdf/2505.18630), [HTML](https://arxiv.org/abs/2505.18630)
### Authors
Zhihao Jia,Mingyi Jia,Junwen Duan,Jianxin Wang
### Background
大型语言模型（LLMs）展示了强大的泛化和推理能力，使其成为复杂决策任务，如医学咨询（MC）的良好选择。然而，现有的基于LLM的方法往往未能捕捉到MC的双重性质，这一性质包括两个不同的子任务：症状询问，一个顺序的决策过程；以及疾病诊断，一个分类问题。这种不匹配通常导致症状询问无效和疾病诊断不可靠。
### Innovation
提出了一种新颖的基于LLM的框架DDO（Dual-Decision Optimization），通过将两个子任务解耦并采用不同的目标进行协作多智能体工作流程优化来解决上述问题。与现有基于LLM的方法相比，DDO在实际医学咨询数据集上的实验结果表明，它始终表现出优越的性能，并且在与最先进的生成方法的性能方面，达到可接受水平，证明了其在医学咨询任务中的有效性。
### Conclusion
DDO在多智能体合作模型中实现了双决策优化，展示了其在医学咨询任务中的有效性，并且该框架在实际医学咨询数据集上的实验结果显示其有效性超越了现有方法，并且达到了与最先进的生成方法可竞争的性能水平。
## 241. `cs.AI` - 推理大规模语言模型错误源于关键问题特征的幻觉 [PDF](https://arxiv.org/pdf/2505.12151), [HTML](https://arxiv.org/abs/2505.12151)
### Authors
Alex Heyman,Joel Zylberberg
### Background
最近，通过强化学习训练的连锁思维（CoT）策略，大型语言模型在推理任务上的表现取得了显著进展。然而，这些“推理大规模语言模型”（RLLMs）仍然是不完善的推理者，理解它们失败模式的频率和原因对于用户和开发者都很重要。本文研究人员对包括o1-mini，o3-mini，DeepSeek-R1，Claude 3.7 Sonnet，Gemini 2.5 Pro Preview和Grok 3 Mini Beta在内的多个模型进行了图着色问题的测试，发现这些模型容易产生超出提示描述的图边。这种现象在多种复杂度问题和语义框架中普遍存在，并且解释了测试模型中大量错误答案的原因。
### Innovation
本文通过具体实例（如图着色问题）并且结合CoT策略和解释文本分析，揭示了RLLMs的一个关键问题，即它们容易产生关键问题特征的幻觉。作者发现这种幻觉现象是导致模型错误的主要原因之一，并且这种错误在不同复杂度的问题中普遍存在。此外，研究人员还通过小型实验验证了这个幻觉现象在不同类型问题上的普适性。这些结果表明，RLLMs可能在更广泛的背景下对问题细节存在误导性表示的问题，并提出了相应的设计建议以缓解这一弱点。
### Conclusion
本文的测试结果表明，RLLMs在图着色等复杂逻辑问题上存在将未提到的图边纳入解决方案中的倾向。这种幻觉现象在不同复杂度问题中普遍存在，并且是导致这些模型产生错误结论的主要原因之一。此外，研究人员还通过小型实验验证了这一现象的普适性。因此，建议在设计此类模型时需要更正这一弱点，以提高它们的准确性和可靠性。
## 242. `cs.AI` - 从隐含表示构建动态向量：超越示范 [PDF](https://arxiv.org/pdf/2505.20318), [HTML](https://arxiv.org/abs/2505.20318)
### Authors
Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu
### Background
在-上下文提取向量（ICV）方法通过从大型语言模型中提取任务相关的表示并在推理过程中重新注入，达到了与少样本上下文学习（ICL）相似的性能，而无需重复演示处理。但是，现有的ICV方法仍对ICL特有的因素敏感，通常使用粗糙或语义碎片化的表示作为向量的来源，并依赖基于启发式的注入位置，这限制了它们的应用范围。
### Innovation
本文提出了一种名为动态向量（DyVec）的新方法，结合了全面查询旋转（EQR）策略来提取鲁棒的语义聚合的潜在表示，通过减轻因ICL引入的方差来解决现有问题。它还应用了动态潜在分割和注入方法，根据任务复杂性适配性分区表示，并利用基于REINFORCE的优化来学习每个片段的最佳注入位置。实验结果显示DyVec在少样本ICL、LoRA和先前的ICV基准中表现更优。进一步的分析强调了动态分割和注入语义聚合潜在表示的有效性。
### Conclusion
DyVec提供了一种轻量级且数据效率高的推理时任务适配解决方案。
## 243. `cs.AI` - Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios [PDF](https://arxiv.org/pdf/2505.23118), [HTML](https://arxiv.org/abs/2505.23118)
### Authors
Zhongzhen Huang,Linjie Mu,Yakun Zhu,Xiangyu Zhao,Shaoting Zhang,Xiaofan Zhang
### Background
临床决策依赖于在不同证据来源上的迭代多模态推理。尽管多模态推理模型在数学和科学任务中取得了显著的成功，但在医疗领域的应用仍然较为有限。
### Innovation
本文提出了一种名为MedE$^2$的两阶段后训练管道，用于激起并增强医疗多模态推理。第一阶段使用包含精准组织推理演示的数据样本来微调模型，以激发推理行为。第二阶段通过严格筛选的医疗多模态案例进一步增强模型的推理能力，使其推理输出与提出的多模态医疗推理偏好保持一致。
### Conclusion
广泛的实验证明，采用MedE$^2$训练的模型在多个医疗多模态基准测试中的推理性能显著优于基线模型。进一步的验证表明，该方法具有鲁棒性和实用价值。
## 244. `cs.AI` - 任意主体视频重新聚焦: 视频扩散模型的任意主体视频重新聚焦 [PDF](https://arxiv.org/pdf/2505.21593), [HTML](https://arxiv.org/abs/2505.21593)
### Authors
Yang Yang,Siming Zheng,Qirui Yang,Jinwei Chen,Boxi Wu,Xiaofei He,Deng Cai,Bo Li,Peng-Tao Jiang
### Background
近年来，扩散模型已被证明是强大的相机模拟工具，能够实现几何变换和真实的光学效果。其中，基于图像的散景渲染已经显示出良好的结果，但视频散景渲染尚未被探讨。现有的基于图像的方法受到时间闪烁和模糊过渡不一致的问题困扰，而当前的视频编辑方法缺乏对焦平面和散景强度的显式控制。这些限制因素使得它们在可控视频散景的应用中存在局限性。因此，需要一种新的方法来解决这些挑战，以实现更加稳定、空间准确且可控的视频散景效果，特别是能够处理任意主体场景视频重新聚焦的需求。本文背景基于这样的需求和挑战展开研究。
### Innovation
本文提出了一种一步扩散框架，用于生成时间连贯且深度感知的视频散景渲染。该框架通过使用适应焦点平面的多平面图像（MPI）表示，条件化视频扩散模型，使其能够利用预训练骨干网络中的强3D先验知识。为了进一步增强时间稳定性、深度鲁棒性和细节保留，引入了一种渐进式训练策略。实验结果表明，该模型在时间连贯性、空间准确性及可控性方面优于先前的基线模型。这是首次专门为视频散景生成提出的扩散框架，建立了时间连贯且可控景深效果的新基线。
### Conclusion
本文提出了一种针对视频散景生成的一步扩散框架，通过条件化视频扩散模型并使用多平面图像（MPI）表示，成功解决了时间闪烁、模糊过渡不一致和显式对焦控制的问题。实验表明，该模型具备超越现有基线模型的卓越性能，为实现时间连贯且可控的景深效果提供了新的路径。
## 245. `cs.AI` - CLIP 需要一个鲁棒的文本编码器：两个领域的稳健性 [PDF](https://arxiv.org/pdf/2506.03355), [HTML](https://arxiv.org/abs/2506.03355)
### Authors
Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher
### Background
对抗性输入攻击可以显著改变CLIP嵌入。这可能会影响包含CLIP的模型的下游鲁棒性，例如文本到图像生成模型或大型视觉语言模型。尽管已经有一些努力旨在使CLIP图像编码器鲁棒，但文本编码器的鲁棒性尚未得到研究。
### Innovation
本文提出了LEAF：一种高效的文本域对抗微调方法，适用于大规模CLIP模型。我们的模型在文本领域显著提高了零样本对抗准确性，同时保持了去噪图像编码器提供的视觉性能。当与文本到图像扩散模型结合使用时，可以在对抗噪声下提高生成质量。在多模态检索任务中，LEAF在对抗噪声下的召回率优于标准CLIP模型。最后，我们展示了鲁棒性文本编码器能够通过直接优化更好地从嵌入重建输入文本。
### Conclusion
通过对抗微调改进了CLIP模型的鲁棒性，特别是在文本领域，有助于在对抗噪声下提高各个相关任务的表现。除了开源代码和模型外，还展示了优化后的文本嵌入对输入文本重建的作用。
## 246. `cs.AI` - FinTagging: 测试大语言模型提取和结构化财务信息的基准 [PDF](https://arxiv.org/pdf/2505.20650), [HTML](https://arxiv.org/abs/2505.20650)
### Authors
Yan Wang,Yang Ren,Lingfei Qian,Xueqing Peng,Keyi Wang,Yi Han,Dongji Feng,Fengran Mo,Shengyuan Lin,Qinchuan Zhang,Kaiwen He,Chenri Luo,Jianxing Chen,Junwei Wu,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Qianqian Xie,Jian-Yun Nie
### Background
准确理解财务报告中的数字对于市场、监管机构、算法和普通公众解读经济和世界至关重要，但即使有XBRL（可扩展商业报告语言）设计用于标记每个数字的标准会计概念，将成千上万的事实映射到超过10,000个美国通用会计准则（US-GAAP）概念也非常昂贵、不一致且容易出错。现有的基准将标签定义为平展的、单步骤的、极端分类，仅涵盖US-GAAP概念的小部分子集，忽视了该分类法的层次结构语义及其结构化的本质，即每个事实必须表示为上下文化的多字段输出。这些简化导致难以在实际报告条件下公平评估大型语言模型（LLMs）。
### Innovation
本文提出了FinTagging，这是第一个全面的基准测试，旨在评估LLMs在通过数值推理和文本与表格之间的分类对齐来解构和对齐财务事实方面的能力。它定义了两个子任务：FinNI，用于数字识别，提取XBRL报告中的数值实体及其类型；FinCL，用于概念链接，将每个提取的实体映射到完整US-GAAP分类法中的相应概念。这些子任务共同产生每个财务事实的结构化表示。分析显示LLMs擅长数字识别但对细粒度的概念链接表现出困难，揭示了结构意识推理在准确财务披露方面的当前局限性。所有代码和数据集均可在GitHub和Hugging Face上获得。
### Conclusion
研究结果表明，尽管LLMs在数字识别方面表现出良好的泛化能力，但在细粒度概念链接方面却面临挑战，揭示了结构意识推理在准确财务披露方面的当前局限性。
## 247. `cs.AI` - AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving [PDF](https://arxiv.org/pdf/2506.05404), [HTML](https://arxiv.org/abs/2506.05404)
### Authors
Lianming Huang,Haibo Hu,Yufei Cui,Jiacheng Zuo,Shangyu Wu,Nan Guan,Chun Jason Xue
### Background
随着自主驾驶的迅速发展，视觉-语言模型（VLMs）被广泛应用于提升感知能力和决策制定。然而，VLMs 的实时应用受到高延迟和计算开销的阻碍，限制了它们在时间紧迫的驾驶场景中的效果。当VLMs表现出过度推断现象，即使在达到自信预测后仍继续处理不必要的层，这一问题尤为明显。为了应对这一不效率，我们提出了一种AD-EE早期退出框架，结合了自主驾驶领域的特性，并利用因果推断识别最优退出层，
### Innovation
我们提出了一种AD-EE早期退出（Early Exit）框架，结合了自主驾驶领域的特点，并利用因果推断来识别最优退出层，通过在大规模真实世界自主驾驶数据集（如Waymo和专注边缘案例的CODA）、以及运行于Autoware Universe平台的真实车辆上进行评估，证明了该方法能显著减少延迟，最高可达57.58%，同时提升了目标检测准确性，最高可增加44%。
### Conclusion
我们的方法显著减少了延迟，提高了目标检测的准确性。
## 248. `cs.AI` - 一种用于SE任务中弥合人类评估差距的LLM作为法官度量标准 [PDF](https://arxiv.org/pdf/2505.20854), [HTML](https://arxiv.org/abs/2505.20854)
### Authors
Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,Kui Liu,Xin Xia,David Lo
### Background
大型语言模型（LLMs）和其他自动化技术被广泛用于支持软件开发人员，通过生成软件组件如代码片段、补丁和评论等来辅助。然而，准确评估这些生成的软件组件的正确性仍然是一个重大挑战。一方面，人工评估虽然准确但劳动密集且缺乏可扩展性。另一方面，许多自动评估度量标准虽然可扩展且需要很少的人力投入，但通常无法准确反映生成的软件组件的实际正确性。
### Innovation
本文介绍了一种名为SE-Jury的评估度量标准，它是第一个为LLM-作为-合议法官设计的专门评估生成软件组件正确性的度量标准。SE-Jury首先定义了五种不同的评估策略，每个策略由独立的法官实现。然后，通过动态团队选择机制，识别最合适的部分法官作为一个团队，通过合议产生最终的正确性评分。研究结果表明，SE-Jury在多种软件工程（SE）基准测试中，与现有的自动评估度量标准相比，其相关性持续提高，改进幅度从29.6%到140.8%，并且在代码生成和程序修复任务中SE-Jury与人类标注者的共识水平接近人类之间的共识水平，展示了其作为可扩展和可靠的替代人类评估的潜力
### Conclusion
研究结果表明，SE-Jury每次评估都能更好地与人类判断相关，与现有自动度量标准相比，改进幅度从29.6%到140.8%不等，尤其是在代码生成和程序修复任务中，SE-Jury与人类标注者的共识水平接近人类之间的共识水平。这对软件工程任务中的自动化度量标准而言是一个重要突破，显示出SE-Jury作为可扩展和可靠的替代方案的潜力。
## 249. `cs.AI` - 神经网络参数空间中的对称性 [PDF](https://arxiv.org/pdf/2506.13018), [HTML](https://arxiv.org/abs/2506.13018)
### Authors
Bo Zhao,Robin Walters,Rose Yu
### Background
现代深度学习模型高度过参数化，导致产生大量能产生相同输出的参数配置。这个冗余中的一部分可以由参数空间中的对称性来解释——这是使得网络功能保持不变的变换。参数空间中的对称性塑造了损失景观，限制了学习动态，提供了理解优化、泛化和模型复杂性的新视角，补充了现有的深度学习理论。本文综述了参数空间中的对称性。
### Innovation
总览了参数空间中的对称性，总结了现有文献，揭示了对称性和学习理论之间的联系，并识别了这一新兴领域中的缺口和机遇。
### Conclusion
文章提供了参数空间对称性的概览，总结了现有研究，揭示了对称性和学习理论之间的联系，并指出在这一新兴领域中还有很多未被探索的机会。
## 250. `cs.AI` - CausalVLBench: 在大型视觉语言模型中基准测试视觉因果推理 [PDF](https://arxiv.org/pdf/2506.11034), [HTML](https://arxiv.org/abs/2506.11034)
### Authors
Aneesh Komanduri,Karuna Bhaila,Xintao Wu
### Background
大型语言模型（LLMs）在各种语言任务中展示了出色的能力，尤其是它们的上下文学习能力。通过将视觉输入扩展到LLMs中，大的视觉语言模型（LVLMs）在识别和视觉问答（VQA）等任务中表现出令人印象深刻的性能。尽管在因果推理任务（如因果发现和反事实推理）中使用LLMs的兴趣不断增加，但在视觉因果推理任务方面的LVLMs表现则相对较少研究。
### Innovation
本研究引入了首个专为多模态上下文学习设计的综合因果推理基准CausalVLBench，包含三个代表性任务：因果结构推断、干预目标预测和反事实预测。评估最先进的开源LVLMs在这些因果推理任务上的表现，并揭示其基本优势和不足，以促进LVLMs视觉因果推理能力的提升和发展新方向和范式。
### Conclusion
本基准测试揭示了现有视觉语言模型的缺陷，并激发了改进LVLMs视觉因果推理能力的新方向和范式。
## 251. `cs.AI` - Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs [PDF](https://arxiv.org/pdf/2506.07180), [HTML](https://arxiv.org/abs/2506.07180)
### Authors
Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang
### Background
随着视频大语言模型（Video-LLMs）在需要基于视觉证据的多模态推理的实际应用中越来越广泛地应用，确保这些模型的事实一致性和可靠性变得至关重要。然而，这些模型往往会因为用户的输入而表现出阿谀奉承的行为，这在视觉证据与用户输入不一致的情况下尤为常见，从而损害了它们的可信度。当前的研究大多忽视了阿谀奉承在视频-语言领域的具体表现形式，鲜有系统性的基准测试和针对性的评估来理解Video-LLMs在误导性用户输入下的表现。因此，本文提出了VISE（Video-LLM Sycophancy Benchmarking and Evaluation），这是第一个旨在评估顶级Video-LLMs在多种问题格式、提示偏差和视觉推理任务下的阿谀奉承行为的基准工具。
### Innovation
VISE是第一个将语言角度上的阿谀奉承分析带入视频领域的基准工具，能够细粒度地分析多种类型的阿谀奉承及其交互模式。此外，本文还提出了两种潜在的无训练的缓解策略，分别为：（i）通过可解释的关键帧选择来增强视觉对齐，（ii）通过目标导向的推理时内部神经表示干预来引导模型的行为远离阿谀奉承。
### Conclusion
本文通过VISE提出了第一个专门用于评估顶尖Video-LLMs阿谀奉承行为的基准工具，同时提出了两种无训练的缓解策略以减少阿谀奉承的偏差。该研究将为评估和改进Video-LLMs的行为提供重要参考。
## 252. `cs.AI` - Bures-Wasserstein Flow Matching for Graph Generation [PDF](https://arxiv.org/pdf/2506.14020), [HTML](https://arxiv.org/abs/2506.14020)
### Authors
Keyue Jiang,Jiahao Cui,Xiaowen Dong,Laura Toni
### Background
图形生成已成为药物发现、电路设计等领域的关键任务。现有的方法，如扩散和流基模型，通过构建在参考数据和实际数据之间插值的概率路径来实现图形生成的性能。然而，这些方法通常独立地建模节点和边的演变，并使用线性插值构建路径，这种分解的插值会破坏图形中的相互关联模式，使得构建的概率路径不规则、不平滑，导致训练动态差和采样收敛错误。
### Innovation
本文提出了一个基于Bures-Wasserstein距离的概率路径构建框架，用于图形生成模型。具体来说，通过将图表示为由马尔可夫随机场参数化的连接系统，建模节点和边的联合演变，并利用MRF对象之间的最优传输位移来设计一条平滑的概率路径，确保图形组件的一致演化。基于此，提出了BWFlow框架，利用导出的最佳概率路径来优化训练和采样算法的设计。实验结果验证了BWFlow的有效性，并证明了其在图形生成和分子生成中的竞争力、更好的训练收敛性和有效的采样效率。
### Conclusion
实验结果表明，BWFlow在图形生成和分子生成中表现出色，具有更好的训练收敛性和高效的采样预测能力。
## 253. `cs.AI` - 超越 token：一种语义与统计视角下的 LLM 公平性量化 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
### Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
### Background
大型语言模型（LLMs）在生成响应时常常体现出内在偏见，影响它们在实际应用中的可靠性。现有的评估方法往往忽视了长文本响应中的偏见以及LLM输出固有的变异性。为克服这些挑战，本文提出了Fine-grained Semantic Comparison（FiSCo），一种新的统计框架，用于通过检测不同群体响应的细微语义差异来评估LLMs的群体公平性。
### Innovation
FiSCo通过在语义层面进行分析，利用推导检查评估响应意义的一致性，而不同于以往主要关注情感或token级别的比较方法。作者将模型输出分解为语义上不同的声明，并应用统计假设测试来比较不同群体间和群体内的相似性，确保识别细微偏见的过程具有强大的统计性。
### Conclusion
实验表明，FiSCo能够更可靠地识别细微的偏见，并且减少因LLM随机性引起的偏差影响，从而在多个评估指标中表现出优越性。
## 254. `cs.AI` - EFRame：通过探索-筛选-重放强化学习框架实现更深入的推理 [PDF](https://arxiv.org/pdf/2506.22200), [HTML](https://arxiv.org/abs/2506.22200)
### Authors
Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yuzhi Zhang,Yue Wang
### Background
最近在强化学习（RL）领域的进展大大提升了大规模语言模型（LLMs）的推理能力。GRPO（Group Relative Policy Optimization），作为Proximal Policy Optimization（PPO）的轻量级变体，提升了效率，但存在探索不足和训练不稳定的问题，这限制了其在复杂推理任务中的效果。
### Innovation
本文提出了一种名为EFRame（探索-筛选-重放框架）的强化学习框架，通过对探索、效率和稳定性进行统一处理，增强了GRPO的功能。具体来说，EFRame通过增加额外的遍历次数实现更深入、更精准的探索；通过在线筛选删除低质量样本以稳定梯度并加速训练；通过经验重放增强稀有的但极具信息量的轨迹，以实现稳定收敛。这一体系在多种推理基准测试中展示了稳定的优势，并在Geometry3K上实现了37.9%的相对改进。
### Conclusion
EFRame提供了一种精细样本分类和精确熵控制工具，使其成为LLMs实现更深入推理的稳健解决方案。我们的代码可在以下网址获取：this https URL。
## 255. `cs.AI` - 基于视频的帕金森病手指敲击测试运动特征可解释和细致量化 [PDF](https://arxiv.org/pdf/2506.18925), [HTML](https://arxiv.org/abs/2506.18925)
### Authors
Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers
### Background
准确量化帕金森病患者的运动特性对于监测疾病进展和优化治疗策略至关重要。手指敲击测试是标准的运动评估方法，但临床医生的主观评价容易受到评估者间和评估者内的变化影响，且不能提供运动特性在测试中的个体化见解。因此，需要一种更客观和细致的方法来量化这些特性。
### Innovation
本文提出了一种基于计算机视觉的细粒度方法，通过视频记录来量化帕金森病的运动特性。该方法提出了四种相关特征来表征运动减退、书写迟缓、序列效应和犹豫-停顿。通过这种方式，研究人员能够识别进一步的细致区分，并训练机器学习分类器来估计运动障碍学会统一帕金森病评定量表（MDS-UPDRS）手指敲击分数。相比现有方法，该方法在MDS-UPDRS分数预测方面具有更高的准确性，并且提供了可解释的定量评估结果。
### Conclusion
本文提出的方法提供了一种实用的方案，用于客观评估帕金森病患者的运动特性，可能在临床和远程环境中应用。未来的工作将评估该方法对症状治疗的反应性和疾病进展的灵敏度。
## 256. `cs.AI` - AirScape：具有运动可控性的空中生成世界模型 [PDF](https://arxiv.org/pdf/2507.08885), [HTML](https://arxiv.org/abs/2507.08885)
### Authors
Baining Zhao,Rongze Tang,Mingyuan Jia,Ziyou Wang,Fanghang Man,Xin Zhang,Yu Shang,Weichen Zhang,Wei Wu,Chen Gao,Xinlei Chen,Yong Li
### Background
在体化智能领域，如何让智能体预测其自身动作意图在三维空间中的结果是一个基本问题。为了探索通用的空间想象能力，该研究提出了AirScape，这是第一个为六自由度空中智能体设计的世界模型。AirScape基于当前视觉输入和动作意图预测未来的观察序列。
### Innovation
研究构建了一个包含11,000个视频-意图对的数据集，用于训练和测试空中世界模型，其中包括一千多个小时标注的动作意图，以及多元化的无人机动作场景。研究还开发了一种两阶段训练计划，将最初没有体化空间知识的预训练模型训练成一个可以通过动作意图控制且遵守物理时空约束的世界模型。实验结果表明，AirScape在三维空间想象能力上显著优于现有模型，特别是在动作对齐的指标上提高了50%以上。
### Conclusion
AirScape在3D空间想象能力上的表现显著优于现有模型，特别是在动作对齐的指标上取得了显著的进步。这项研究提供了具有运动可控性的空中生成世界模型，该模型具备强大的三维空间想象能力。
## 257. `cs.AI` - Mem4Nav：在城市环境中的基于层次空间认知的长短期记忆系统增强视觉-语言导航 [PDF](https://arxiv.org/pdf/2506.19433), [HTML](https://arxiv.org/abs/2506.19433)
### Authors
Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li
### Background
在大型城市环境中进行视觉-语言导航（VLN）需要实体代理将语言指令与复杂场景联系起来，并在长时间内回忆相关的经验。现有的模块化管道可以提供可解释性，但缺乏统一的记忆，而端到端的（M）LLM代理在融合视觉和语言方面表现出色，但仍然受限于固定上下文窗口和隐式的空间推理。
### Innovation
我们提出了Mem4Nav，这是一种分层次的空间认知长短期记忆系统，可以增强任何VLN主干。Mem4Nav结合了一个稀疏八叉树以实现精细的体素索引，以及一个语义拓扑图以实现高级地标连接，两者都储存在通过可逆变换器嵌入的可训练记忆标记中。长时记忆（LTM）压缩并保留了八叉树和图节点的历史观察结果，而短期记忆（STM）则缓存了最近的多模态条目以相对坐标形式进行实时障碍物规避和局部规划。在每一步，STM检索会精确地筛选动态上下文，当需要更深入的历史记录时，LTM标记可以无损解码以重建过去的嵌入。
### Conclusion
Mem4Nav在Touchdown和Map2Seq上，在三个主干（模块化、基于提示的大规模视觉-语言导航和具备跨注意力机制的最先进VLN）上均表现出7-13％的装卸任务完成改进，在足够的空间轨迹偏差减少和>10％的nDTW改进方面也有表现。消融实验确认了层次化地图和双内存模块的不可或缺性。我们的代码已开源，可以通过这个链接获取：https://github.com/example-link.
## 258. `cs.AI` - 在环路人工指导下使自我改进代理在测试时学习 [PDF](https://arxiv.org/pdf/2507.17131), [HTML](https://arxiv.org/abs/2507.17131)
### Authors
Yufei He,Ruoyu Li,Alex Chen,Yue Liu,Yulin Chen,Yuan Sui,Cheng Chen,Yi Zhu,Luca Luo,Frank Yang,Bryan Hooi
### Background
大型语言模型（LLM）代理在规则和所需领域知识经常变化的环境中表现不佳，例如合规管理和用户风险筛选。尽管现有的方法，如离线微调和标准提示，但在实际操作中无法有效地适应新知识。
### Innovation
提出了自适应反思交互式代理（ARIA），这是一种专为此类环境设计的LLM代理框架，能够在测试时持续学习更新的领域知识。ARIA利用结构化的自我对话来评估自己的不确定性，主动识别知识缺口，并请求人类专家的目标解释和更正。然后，它系统地根据提供的指导更新内部带有时间戳的知识库，并通过比较和澄清查询检测和解决冲突或过时的知识。
### Conclusion
ARIA在包括 TikTok Pay 的真实客户尽职调查名称筛查任务和公共资源的动态知识任务中的评估显示，与使用标准离线微调和现有自我改进代理的基线相比，具有显著的适应性和准确性改进。ARIA在 TikTok Pay 中为超过1.5亿月活跃用户提供服务，证实了其在快速变化环境中的实用性和有效性。
## 259. `cs.AI` - 预印本：海报：我刚刚浏览了一个由LLM撰写的网站？ [PDF](https://arxiv.org/pdf/2507.13933), [HTML](https://arxiv.org/abs/2507.13933)
### Authors
Sichang Steven He,Ramesh Govindan,Harsha V. Madhyastha
### Background
当前，网络内容越来越多地由大型语言模型（LLMs）自动生成，而无需大量的人工干预。我们称之为‘LLM主导’的内容。由于LLMs可能会剽窃或胡言乱语，这种类型的内容可能存在不可靠性且不道德。然而，很少有网站专门披露此类信息，让普通读者难以区分。因此，亟需开发出可靠的检测方法来识别LLM主导的内容。然而，最新的LLM检测器往往不适用于网络数据，因为网络数据具有低阳性率、复杂标记和多样体裁等特点，这与优化过的基准数据大不相同。我们必须开发出专门针对网络数据的准确检测器。
### Innovation
我们提出了一种高可用、可扩展的管道，能够对整个网站进行分类，而不是简单地对每页提取的文本进行分类。该管道首先通过一个LLM文本检测器对多个类似文体页面进行分类，从而提高准确度。我们通过收集2个不同的基准数据集（共计120个网站）进行训练和评估，并在测试中实现了100%的准确率。在现实环境的测试中，我们检测到10,000个搜索引擎结果页面和10,000个原始公共档案中有一部分网站是LLM主导的。我们的研究表明，LLM主导的网站数量正在增加，且在搜索结果中的排名较高，这引发了对其对最终用户和整个网络生态系统的影响的质疑。
### Conclusion
我们的工作展示了如何有效地识别网络上由LLM主导的内容并提高了实际应用的准确性。我们检测到了大量的网站在搜索结果和原始公共档案中是LLM主导的，并发现这些网站的数量正在增长。这对最终用户和广大互联网生态系统的影响值得关注。未来需要继续研究以进一步完善这个理论并找到实际解决方法。
## 260. `cs.AI` - 无窥视调整：LLM后训练中的可证明隐私和泛化界 [PDF](https://arxiv.org/pdf/2507.01752), [HTML](https://arxiv.org/abs/2507.01752)
### Authors
Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud
### Background
梯度优化是深度学习的核心工具，通过反向传播实现了高效和可扩展的训练。然而，在训练过程中暴露梯度可能会泄露敏感数据信息，导致隐私和安全问题，如数据投毒攻击。相比之下，黑盒优化方法将模型视为不透明的功能，仅通过函数评估来引导优化，在限制数据访问、高对抗风险或防止过拟合的场景下表现出优势。本文介绍了BBoxER，一种适用于LLM后训练的进化黑盒方法，通过对训练数据进行隐含压缩以引入信息瓶颈。利用信息流动的可计算性，我们提供了针对差分隐私、数据投毒攻击和提取攻击的非空泛化界和强理论保证。实验结果表明，黑盒优化方法虽然存在规模和计算挑战，但仍能有效学习，体现较好的性能泛化能力和对抗成员推理攻击的鲁棒性。这表明BBoxER在保留梯度优化优势的前提下，适合部署在受限或隐私敏感环境中，同时也提供了非空泛化保证结果。
### Innovation
BBoxER是一种进化黑盒方法，用于LLM后训练，通过隐式压缩训练数据引入信息瓶颈。该方法通过提供非空泛化界和强理论保证，提出了差分隐私、数据投毒攻击和提取攻击的解决方案。实验展示了黑盒优化方法在对抗成员推理攻击方面的鲁棒性，证明了其在LLM后训练中的潜力。
### Conclusion
BBoxER作为一种黑盒优化方法，为LLM后训练提供了非空泛化保证，即使在存在网络安全问题的场景下也能保持性能。该方法在限制数据访问、高对抗风险或防止过拟合的场景下表现出色，可以作为梯度优化的补充，在隐私敏感环境中提供有效的解决方案。
## 261. `cs.AI` - 基于逐层冻结的站点级微调：面向极早期婴儿首日胸片的抗肺泡性肺疾病稳健预测 [PDF](https://arxiv.org/pdf/2507.12269), [HTML](https://arxiv.org/abs/2507.12269)
### Authors
Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)
### Background
极低出生体重婴儿（小于32周胎龄，体重401-999克）中，35%的婴儿会患上慢性肺部疾病——抗肺泡性肺疾病（BPD）。BPD的定义是在矫正胎龄36周时仍需氧疗。BPD会引起终身的呼吸系统并发症。尽管预防干预措施可以减少BPD的发生，但这些干预措施也会带来严重的风险，如神经发育障碍、机械通气引起的肺损伤和全身并发症。因此，对于极低出生体重的婴儿，准确预测BPD的早期情况及其预后至关重要，以避免不必要的对低风险婴儿的毒副作用。胸部X射线是在婴儿出生24小时内常规获得的影像，可以作为非侵入性预测工具。为了实现这一目标，该研究开发并验证了一种基于深度学习的方法，使用了163名极低出生体重婴儿（胎龄≤32周，体重401-999克）的胸部X射线。
### Innovation
该研究通过使用逐层冻结和线性探针的方法，对已经预训练的ResNet-50模型进行了微调，该模型经过了针对成人胸部X射线的预训练。通过这种方法，研究者开发了一种可以准确预测极低出生体重婴儿首日胸部X射线中BPD预后的模型，并在具有代表性的实验中表现出了高准确性，且在域内预训练下的表现优于ImageNet初始化（p = 0.031）。这证实了针对特定领域的预训练模型对BPD预测的重要性。
### Conclusion
研究结果表明，基于特定领域的预训练模型可以准确预测极早期婴儿的BPD预后。通过逐层冻结和线性探针的方法，研究方法能在计算上实现站点级实施，并为未来的联邦学习部署提供支持。这种方法避免了不必要的对低风险婴儿的毒性干预，并有助于降低BPD的风险，为临床决策提供了有价值的参考。
## 262. `cs.AI` - TriP-LLM: 一种基于三支路斑块化大型语言模型的时间序列异常检测框架 [PDF](https://arxiv.org/pdf/2508.00047), [HTML](https://arxiv.org/abs/2508.00047)
### Authors
Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin
### Background
时间序列异常检测在众多应用领域中发挥着关键作用。随着物联网（IoT）和智能制造的发展，时间序列数据的规模和维度大幅增加，传统统计方法在处理这种数据的高异质性和复杂性方面暴露出局限性。最近，大型语言模型（LLMs）在语言和视觉多模态任务中的成功激发了对新型异构时间序列异常检测方法的兴趣。
### Innovation
本文提出了一种创新的无监督时间序列异构检测框架TriP-LLM，通过三支路框架集成局部和全局时间特征，基于预制的大型语言模型处理输入的时间序列。该框架通过一个轻量级的斑块化解码器重构输入，并从重构中得出异常分数。研究结果显示，TriP-LLM 在多个公开基准数据集上超过了最近的顶级方法，且通过广泛的经验性消融研究验证了基于大型语言模型的架构对整体结构的显著贡献，相比使用通道独立性（CI）斑块处理的LLM方法，TriP-LLM在GPU内存限制环境中具有更低的内存消耗。
### Conclusion
TriP-LLM在所有数据集上的实验结果表明，它具有很强的检测能力，并且显著优于最新的顶级方法。此外，通过大量经验性消融研究，我们验证了基于大型语言模型的架构对整体架构的显着贡献。TriP-LLM的全部代码和模型检查点已公开在特定网址上。
## 263. `cs.AI` - VAGPO: Vision-augmented Asymmetric Group Preference Optimization for Graph Routing Problems [PDF](https://arxiv.org/pdf/2508.01774), [HTML](https://arxiv.org/abs/2508.01774)
### Authors
Shiyan Liu,Bohan Tan,Zhiguang Cao,Yan Jin
### Background
图路由问题在与web相关的网络中起着关键作用，找到图上的最优路径对于高效的数据传输和内容交付至关重要。经典的路由问题如旅行商问题（TSP）和带容量约束的车辆途径问题（CVRP）代表了基本的图优化挑战。虽然最近的数据驱动优化方法取得了显著进展，但它们在训练效率和大规模实例的泛化方面仍然存在局限。
### Innovation
提出了一个新颖的视觉增强异质组偏好优化（VAGPO）方法。该方法利用基于ResNet的视觉编码和基于Transformer的序列建模，同时捕捉空间结构和时间依赖性。进一步引入了一种异质组偏好优化策略，相比于常用的策略梯度方法，显著加速了收敛。
### Conclusion
在生成的TSP和CVRP实例，以及真实世界的数据集上进行的实验结果表明，所提出的VAGPO方法获得了高度竞争力的解决方案质量。此外，VAGPO在无需重新训练的情况下对大规模实例（多达1000个节点）表现出强大的泛化能力，突显了其在学习效率和可扩展性方面的有效性。
## 264. `cs.AI` - 认知通过探索：一种增强学习框架以实现稳健的功能调用 [PDF](https://arxiv.org/pdf/2508.05118), [HTML](https://arxiv.org/abs/2508.05118)
### Authors
Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang
### Background
大型语言模型（LLMs）有效培训对于功能调用面临一个关键挑战：在探索复杂推理路径的同时保持稳定策略优化。标准方法如监督微调（SFT）难以赋予模型稳健的推理能力，而传统的增强学习（RL）则因探索效率低下而踌躇。
### Innovation
本文提出了EGPO，一种基于Group Relative Policy Optimization（GRPO）的新RL框架，旨在直接解决上述挑战。EGPO的核心是增强后的优势函数，该函数将模型Chain-of-Thought（CoT）的熵纳入策略梯度计算中，从而鼓励生成多样化的推理策略。通过引入限制机制以精确定制熵奖励，EGPO确保了优化方向。通过严格的二元奖励信号，EGPO有效指导模型发现有结构且准确的工具调用模式。
### Conclusion
EGPO在Berkeley Function Calling Leaderboard（BFCL）上表现出色，在4B参数模型中设置了新的基准线，超越了包括GPT-4o和Gemini-2.5在内的多项强劲竞争对手。
## 265. `cs.AI` - ACD-CLIP: 解耦表示和动态融合以实现零样本异常检测 [PDF](https://arxiv.org/pdf/2508.07819), [HTML](https://arxiv.org/abs/2508.07819)
### Authors
Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo
### Background
预训练的视觉-语言模型（VLMs）在零样本异常检测（ZSAD）任务中表现不佳，主要原因是缺乏必要的局部归纳偏置，不能进行密集预测，并且融合特征的方式不灵活。
### Innovation
本文提出了一种名为Architectural Co-Design（ACD）的框架，通过联合优化特征表示和跨模态融合，克服上述限制。该方法引入了一个参数高效的Convolutional Low-Rank Adaptation（Conv-LoRA）适配器，用于注入局部归纳偏置来细化表示，并引入了Dynamic Fusion Gateway（DFG），通过利用视觉上下文自适应地调节文本提示来实现强大的双向融合。
### Conclusion
大量实验在多样化的工业和医学基准数据集上显示出优越的准确性和鲁棒性，验证了这种协同设计对于使基础模型适应密集感知任务的重要性。
## 266. `cs.AI` - LATTE：学习对齐的交易和文本嵌入以供银行客户使用 [PDF](https://arxiv.org/pdf/2508.10021), [HTML](https://arxiv.org/abs/2508.10021)
### Authors
Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Omar Zoloev,Artem Sakhno,Dmitry Korolev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko
### Background
从客户历史通信序列中学习客户嵌入是金融应用的核心。尽管大型语言模型（LLMs）提供了广泛的知识，但在实时管道中直接处理长事件序列会耗时且不切实际。
### Innovation
我们提出了LATTE，一种对比学习框架，将原始事件嵌入与冻结的LLM的语义嵌入对齐。行为特征被总结为简短的提示，由LLM嵌入，并通过对比损失提供监督。与传统的全序列处理相比，该方法显著减少了推理成本和输入大小。
### Conclusion
我们在实验中表明，我们的方法在实际金融数据集上优于最先进的技术，同时可以在敏感延迟环境中部署。
## 267. `cs.AI` - 关于任务向量和梯度 [PDF](https://arxiv.org/pdf/2508.16082), [HTML](https://arxiv.org/abs/2508.16082)
### Authors
Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà
### Background
任务算术作为一种简单而强大的技术，已经被证明可以将多个微调模型合并为一个。尽管它在实践中非常成功，但为何以及何时能够成功的原因仍然缺乏明确的理论解释。
### Innovation
本文为任务算术提供了严格的理论基础，建立了任务向量与任务损失梯度之间的联系。作者证明，在标准梯度下降中，一个从一次微调生成的任务向量等同于负梯度，且经过学习率缩放，同时也证明了在多轮微调的实用情况下，这种等价关系近似成立，并且给出了端到端网络的二次误差项的明确边界。
### Conclusion
实验分析在七个视觉基准上的结果支持了该理论，表明在幅度和方向上，第一轮微调梯度主导了微调轨迹。关键含义是，仅进行一次微调的模型的合并性能往往与完全收敛模型的合并性能相当。此发现将任务算术重新框架为一种近似的多任务学习形式，为其实效性提供了一个明确的理由，并强调了早期训练动态在模型合并中所扮演的关键角色。
## 268. `cs.AI` - 神经辐射场（NBF）用于空间波束RSRP预测 [PDF](https://arxiv.org/pdf/2508.06956), [HTML](https://arxiv.org/abs/2508.06956)
### Authors
Keqiang Guo,Yuheng Zhong,Xin Tong,Jiangbin Lyu,Rui Zhang
### Background
在密集的多用户无线网络中，准确预测波束级别的参考信号接收功率（RSRP）对于波束管理至关重要，但由于高测量开销和快速信道变化，这非常具有挑战性。文章提出了一种名为NBF的混合神经-物理框架，用于高效且可解释的空间波束RSRP预测。核心在于引入多路径条件功率概貌（MCPP），一种可学习的物理中介，代表特定站点的传播环境。该方法将环境与特定天线/波束配置分离，这有助于模型学习站点特定的多路径特征，增强其泛化能力。文章采用一种解耦的“黑盒-白盒”设计，采用基于Transformer的深层神经网络（DNN）从稀疏用户测量和位置中学习MCPP，同时用物理启发的模块进行波束RSRP统计的推断。为了提高收敛性和适应性，引入了一种预训练和校准（PaC）策略，利用射线跟踪先验进行基于物理的预训练，然后利用RSRP数据进行现场校准。大量仿真实验表明，NBF在预测准确性、训练效率和泛化能力方面显著优于传统的基于表格的信道知识地图（CKMs）和纯黑盒DNN，同时保持了较小的模型尺寸。提出的框架为下一代密集无线网络中的智能波束管理提供了一种可扩展且基于物理的解决方案
### Innovation
NBF框架采用了一种混合的神经-物理方法，通过学习多路径条件功率概貌（MCPP）和物理启发模块进行波束RSRP统计的推断，解耦环境与特定的天线/波束配置，并通过预训练和校准（PaC）策略提高模型的泛化能力。该方法显著提升了在密集无线网络中波束管理的性能，同时保持了模型的紧凑性。这种方式为智能波束管理提供了一种基于物理的方法，有效地解决了信道变化和高测量开销带来的挑战。
### Conclusion
NBF框架通过将环境与特定的天线/波束配置分离，采用基于Transformer的DNN和物理启发的模块进行波束RSRP预测，有效解决了密集多用户无线网络中的信道变化和高测量开销问题，提供了更高的预测准确性和泛化能力，同时保持了模型的紧凑性，为下一代无线网络中的智能波束管理提供了可扩展且物理合理的方法。
## 269. `cs.AI` - AMFT：通过元学习最佳模仿-探索平衡来对齐大语言模型推理器 [PDF](https://arxiv.org/pdf/2508.06944), [HTML](https://arxiv.org/abs/2508.06944)
### Authors
Lixuan He,Jie Feng,Yong Li
### Background
大语言模型（LLMs）通常通过监督微调（SFT）和基于奖励的学习（RL）的两阶段管道进行微调，但这一过程常常伴随着灾难性遗忘及模仿与探索之间的次优权衡。单阶段方法试图通过启发式方法统一SFT和RL，但缺少一个合理的机制来动态平衡两种范式。本文将这一挑战重新定义为隐含奖励的理论视角，将SFT和RL视为互补的奖励信号，而非独立的方法。本文提出了一种新颖的单阶段算法——自适应元微调（AMFT），该算法能够学习SFT的隐含路径级奖励和RL的显式结果基奖励的最佳权衡。AMFT的核心是一个元梯度自适应权重控制器，它将SFT-RL平衡视为可学习的参数，并动态优化以最大化长期任务性能。该前瞻性的方法通过策略熵正则化来提高稳定性，自主地发现有效的训练课程。通过数学推理、抽象视觉推理（General Points）以及视觉语言导航（V-IRL）等具有挑战性的基准测试，AMFT展示了显著的进步，尤其是在离分布（OOD）任务上的泛化能力。消融研究和训练动态分析表明，元学习控制器对于AMFT的稳定性和性能至关重要，提供了更合理且有效的LLM对齐范式。
### Innovation
本文提出了一种新型算法——自适应元微调（AMFT），该算法通过元学习来自动发现SFT和RL的最佳权衡，从而优化大语言模型的长期任务性能。AMFT的核心是一个元梯度自适应权重控制器，它动态调节SFT-RL的平衡，并通过策略熵正则化来提高稳定性，使得算法更适应复杂的推理任务。AMFT在多个挑战性数据集上展示了良好的性能，并通过消融研究和训练动态分析证明了其有效性。
### Conclusion
本文提出并通过实验验证了一种新的单阶段方法——自适应元微调（AMFT），该方法能够自动学习大语言模型中监督微调（SFT）与基于奖励的学习（RL）的最佳平衡，从而提高模型的长期性能和泛化能力。AMFT展示了在数学推理、抽象视觉推理（General Points）和视觉语言导航（V-IRL）等任务上的优越表现，并且通过对齐大语言模型推理器的表现证明了其作为更合理和有效的LLM对齐范式的优势。
## 270. `cs.AI` - 资源受限设备上稀疏激活大型语言模型的联邦精调 [PDF](https://arxiv.org/pdf/2508.19078), [HTML](https://arxiv.org/abs/2508.19078)
### Authors
Fahao Chen,Jie Wan,Peng Li,Zhou Su,Dongxiao Yu
### Background
由于混合专家（MoE）为基础的大型语言模型（LLMs）对计算资源的需求巨大，参与者的资源限制使得联邦微调MoE-based LLMs成为一项挑战。现有的工作试图通过模型量化、计算卸载或专家剪枝来填补这一缺口，但由于不切实际的系统假设和对MoE独特特征的忽视，这些方法无法获得理想的性能。
### Innovation
FLUX系统通过以下三个关键创新来解决上述问题：(1) 基于量化的地方化配置文件估算专家激活的最小开销方法；(2) 适应性层感知专家合并，以减少资源消耗同时保持准确性；(3) 使用探索-利用策略动态分配专家角色，以平衡调优和非调优专家。
### Conclusion
通过在LLaMA-MoE和DeepSeek-MoE上的广泛实验，证明了FLUX显著优于现有方法，在时间到准确度方面提高了高达4.75倍。
## 271. `cs.AI` - 在线强化学习与离线专家结合：通过动态加权实现监督微调与强化学习的和谐 [PDF](https://arxiv.org/pdf/2508.11408), [HTML](https://arxiv.org/abs/2508.11408)
### Authors
Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou
### Background
大型语言模型（LLMs）的监督微调（SFT）和强化学习（RL）是两个主要的后训练范式，用于提高模型的能力并使其行为与期望一致。现有方法结合SFT和RL时常面临打破预定响应模式和过度拟合专家数据的风险。为了应对这一挑战，本文通过一个经验性分析，提供了SFT和RL统一视图的探讨，即通过离策略和在线策略的视角进行研究。
### Innovation
本文提出了CHORD框架，该框架通过动态加权机制，在在线策略RL过程中，将SFT重新定义为一个动态加权的辅助目标。CHORD框架结合了全局系数和基于token的加权函数两种控制机制，以全局和粒度水平上引导从离策略模仿到在线探索的过渡，从而促进在线探索并减少离策略数据的干扰
### Conclusion
通过在数学推理问题和实用工具使用任务上的广泛实验，CHORD展示了稳定的高效学习过程，并相对于基线有显著改进。研究结果表明，CHORD通过有效协调离策略专家数据与在线探索，实现了SFT和在线RL的有效结合。作者已在该项目网站上公开了该框架的实现。
## 272. `cs.AI` - 从联邦学习到X学习：通过随机游走打破分散性的壁垒 [PDF](https://arxiv.org/pdf/2509.03709), [HTML](https://arxiv.org/abs/2509.03709)
### Authors
Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour
### Background
论文介绍了X-Learning（XL），这是一种新颖的分布式学习架构，旨在扩展和深化分散概念的理解。作者探讨了XL与图论和马尔可夫链之间的直观但复杂的联系，为该领域带来了新的设计考虑和自由度。
### Innovation
论文提出了一种新颖的X-Learning架构，通过探讨与图论及马尔可夫链的关系，引入了该领域的未探索设计方案和自由度。同时指出了研究开放方向，以刺激进一步的研究。
### Conclusion
论文指出，X-Learning通过随机游走的概念，为打破分散性壁垒提供了新的视角，旨在引导更多研究探索这一方向。
## 273. `cs.AI` - 量化大型语言模型标签诱发偏差的自我和跨模型评估 [PDF](https://arxiv.org/pdf/2508.21164), [HTML](https://arxiv.org/abs/2508.21164)
### Authors
Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush
### Background
大型语言模型（LLMs）越来越多地被用作文本质量的评估者，但它们判断的有效性尚未得到充分探索。这项研究旨在探讨三个主要LLM（ChatGPT、Gemini和Claude）在自我评估和跨模型评估中的系统性偏差。研究通过控制实验设计，在不同归因条件下对每种模型撰写的博客进行评估。
### Innovation
本研究通过设计一个受控实验，利用三种主要的LLM来评估由它们各自撰写的博客，评估包括整体偏好投票和三个维度（连贯性、信息量和简洁性）的具体质量评分，并将所有评分归一化为百分比进行直接比较。研究发现模型对自身和标签的判读存在显著差异，表明感知到的模型身份可以显著扭曲高级判断和细致的质量评估，且这种影响与内容质量无关。
### Conclusion
本研究挑战了LLM作为评判者的可靠性，并强调了实施盲评估协议和多样化的多模型验证架构的重要性，以确保自动化文本评估和LLM基准测试中的公平性和有效性。
## 274. `cs.AI` - 生活满意度的个体效用揭示了与政治倾向无关的不平等厌恶 [PDF](https://arxiv.org/pdf/2509.07793), [HTML](https://arxiv.org/abs/2509.07793)
### Authors
Crispin Cooper,Ana Fredrich,Tommaso Reggiani,Wouter Poortinga
### Background
这篇论文探讨了在社会中如何优先考虑幸福感的问题，以及人们在公平和个人幸福感之间愿意做出什么样的权衡。为此，研究者通过一项面向英国全国代表性样本（n=300）的意愿调查实验，让参与者评估在不确定性条件下自身的和他人的生活满意度结果。
### Innovation
研究者使用预期效用最大化（EUM）框架估计个体级别的效用函数，并测试其对小概率过度估计的敏感性，以此反映了决策制定过程中的前景理论（CPT）特征。结果显示，大多数参与者表现出凹型（风险厌恶）的效用曲线，并且对社会生活满意度结果中的不平等表现出了更强的厌恶，这种偏好与政治倾向无关，揭示出一个跨越意识形态界限的公平规范立场。这一发现挑战了以平均生活满意度作为政策衡量指标的做法，支持发展非线性效用为基础的替代选项，更好地反映集体人类价值观。
### Conclusion
研究结果表明，使用平均生活满意度作为政策衡量指标需要谨慎，应该开发基于非线性效用的替代方案，更准确地反映集体人类价值观。此外，研究还讨论了这些发现对公共政策、幸福感衡量以及价值导向AI系统设计的影响。
## 275. `cs.AI` - 基于期望最大化方法的多智能体强化学习中的潜在变量建模在UAV野生动物保护中的应用 [PDF](https://arxiv.org/pdf/2509.02579), [HTML](https://arxiv.org/abs/2509.02579)
### Authors
Mazyar Taghavi,Rahman Farnoosh
### Background
在广大且部分不可观测的环境中保护濒危野生动物免受非法猎杀是一个关键挑战，尤其是需要实时响应的情况下。本文针对这一背景，提出了一个多智能体强化学习（MARL）框架，结合期望最大化（EM）基于潜在变量建模方法，用于协调无人机（UAV）在野生动物保护中的使用。该方法通过潜在变量建模隐藏的环境因素和智能体间的动态性，以增强在复杂环境中的探索和协作能力。文章通过一个包含10架无人机巡逻伊朗豹受保护栖息地的自定义模拟实验，验证和评估了其效果，结果表明该方法在检测准确性、适应性和策略收敛性方面优于标准算法如PPO和DDPG。研究结果强调了结合EM推断与MARL可以在复杂的高风险保护场景中改善去中心化决策的可能性。相关的完整实现、仿真环境和训练脚本在GitHub上公开提供，以便进一步研究和应用。
### Innovation
该研究引入了一种新的基于期望最大化（EM）的潜在变量建模方法，用于多智能体强化学习（MARL）框架，以增强在复杂和部分不可观测环境中的无人机（UAV）协调能力。该模型通过潜在变量来建模隐藏的环境因素和智能体间的动态性，有助于提升在野生动物保护中的探索和协作效果。
### Conclusion
实验结果验证了该EM-MARL框架在检测准确性、适应性和策略收敛性方面的优势。该研究强调了将EM推断与MARL结合的优势，在复杂的、高风险的野生动物保护环境中可以更有效地做出去中心化的决策。代码和环境在GitHub上开源，可供进一步研究和应用。
## 276. `cs.AI` - COMPACT：跨通道和令牌的常见令牌优化模型剪枝 [PDF](https://arxiv.org/pdf/2509.06836), [HTML](https://arxiv.org/abs/2509.06836)
### Authors
Eugene Kwek,Wenpeng Yin
### Background
对于边缘部署、交互应用以及大规模可持续推理而言，使大型语言模型（LLMs）在内存、延迟和推理成本上更加高效至关重要。目前，剪枝是一种有潜力的技术，但现有剪枝方法存在局限性：宽度剪枝常常会破坏标准的变压器布局，需要定制推理代码；而深度剪枝可能会导致显著的准确率下降。此外，许多剪枝方法虽然对LLMs有效，但在处理小型语言模型（SLMs）时却很难保持性能。
### Innovation
本文提出了COMPACT，它同时执行两个剪枝任务：(i) 剪枝罕见词汇以缩小嵌入/LM头层，(ii) 借助常见令牌加权激活剪枝FFN中间通道，使剪枝后的层的重要性与剪枝后的令牌分布相一致。COMPACT集成了深度和宽度剪枝的优点，如：部署友好性（保持标准变压器架构）、缩放适配性（词汇量与FFN剪枝之间的权衡），优异的剪枝速度，以及在存储需求和吞吐量得到增强的同时保持强大的记忆力节约能力。实验结果表明，COMPACT在Qwen、LLaMA和Gemma家族（0.5B-70B参数）中表现出最先进的下游性能，同时显著减少了参数数量、GPU内存和延迟时间。
### Conclusion
COMPACT在保持性能的同时通过剪枝减少了参数量、GPU内存和延迟，展示了强大且高效的剪枝策略。
## 277. `cs.AI` - 超越抱歉，我不能：拆解大型语言模型的拒绝行为 [PDF](https://arxiv.org/pdf/2509.09708), [HTML](https://arxiv.org/abs/2509.09708)
### Authors
Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee
### Background
大语言模型（LLMs）在面对有害提示时表现出的拒绝行为是一种关键的安全行为。然而，这种行为背后的具体机制尚未被充分理解。
### Innovation
本文利用稀疏自编码器（SAEs）研究了两个公开的大语言模型中激活流残差的特征集合，通过特征集的去除效应，展示了这种拒绝行为的因果影响并推动了‘ Jailbreak ’的生成。研究分三步进行：1）寻找拒绝主导方向并收集接近该方向的SAE特征；2）贪婪筛选，简化为最小集合；3）交互发现，通过因子机器捕捉剩余活跃特征与最小集合之间的非线性交互关系。这种方法揭示了拒绝的重要机制，并发现了冗余特征的存在，这些特征在不抑制更早特征时会保持休眠状态。该研究提出了通过操控可解释的隐空间来进行精细审计和针对性干预的可能性。
### Conclusion
本研究展示了大语言模型拒绝行为背后的深层机制，指出了一些关键的触发特征，以及潜在的冗余特征。这些发现为实现更精细的安全性和行为调节提供了理论基础并展示了实际应用的潜力。
## 278. `cs.AI` - 关于数字孪生的大规模研究揭示了其优势、劣势及其进一步改进的机会 [PDF](https://arxiv.org/pdf/2509.19088), [HTML](https://arxiv.org/abs/2509.19088)
### Authors
Tiany Peng,George Gui,Daniel J. Merlau,Grace Jiarui Fan,Malek Ben Sliman,Melanie Brucks,Eric J. Johnson,Vicki Morwitz,Abdullah Althenayyan,Silvia Bellezza,Dante Donati,Hortense Fong,Elizabeth Friedman,Ariana Guevara,Mohamed Hussein,Kinshuk Jerath,Bruce Kogut,Akshit Kumar,Kristen Lane,Hannah Li,Patryk Perkowski,Oded Netzer,Olivier Toubia
### Background
数字孪生个体（'digital twins'）有望改变社会科学研究和决策制定方式。然而，目前尚不清楚这些孪生体是否真正反映了所模仿的人的特点。为解决此问题，研究者进行了19项事先注册的研究，涉及具有代表性的美国大型样本及其基于详尽个体数据构建的孪生体。
### Innovation
研究通过直接比较人类和孪生体在广泛领域和刺激下的行为（包括前所未有的刺激），方法科学严谨且具有开创性，特别强调了基于详细个人资料信息比仅仅基于人口统计信息的哑铃模型效果更好，而且孪生体在某些领域（如社会和个人特质）表现更好，但在政治领域表现较差。
### Conclusion
研究结果指出数字化孪生的潜力与现有局限：它们可以捕捉到个体之间的相对差异，但尚未能准确反映特定个体的独特判断。所有数据和代码均已公开，以支持数字孪生管道的进一步开发与评估。
## 279. `cs.AI` - MOCHA: 多模态对象感知的跨架构对齐 [PDF](https://arxiv.org/pdf/2509.14001), [HTML](https://arxiv.org/abs/2509.14001)
### Authors
Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli
### Background
该研究介绍了一种知识蒸馏方法MOCHA（Multi-modal Objects-aware Cross-arcHitecture Alignment），它能够将大模型的多模态语义（例如LLaVa）应用于轻量级的单一视觉检测器学生模型（例如YOLO）。这一方法利用翻译模块将学生模型的特征映射到联合空间中，训练学生模型和翻译模块的目标是通过双重目标损失来实现局部对齐和全局关系一致性。
### Innovation
MOCHA主要创新点在于其在对象层级上进行多模态语义的转换，而不依赖于大模型的修改或在推理过程中需要文本输入。这种方法能够高效地转移语义信息，并且在少量样本条件下在四个个性化检测基准测试上表现出一致的优势，比基准模型提高了平均10.1分。尽管MOCHA架构紧凑，但模型性能与更大规模的多模态模型相当，证明了其在实际部署中的有效性。
### Conclusion
研究表明，MOCHA方法在四个少样本检测基准测试中均比基准模型有显著提升，并且尽管架构较小，其性能与大型多模态模型相当，证明了其在实际应用场景中的适用性和有效性能。
## 280. `cs.AI` - ByteDance的稳健大语言模型训练基础设施 [PDF](https://arxiv.org/pdf/2509.16293), [HTML](https://arxiv.org/abs/2509.16293)
### Authors
Borui Wan,Gaohong Liu,Zuquan Song,Jun Wang,Yun Zhang,Guangming Sheng,Shuguang Wang,Houmin Wei,Chenyuan Wang,Weiqiang Lou,Xi Yang,Mofan Zhang,Kaihua Jiang,Cheng Ren,Xiaoyun Zhi,Menghan Yu,Zhe Nan,Zhuolin Zheng,Baoquan Zhong,Qinlong Wang,Huan Yu,Jinxin Chi,Wang Zhang,Yuhan Li,Zixian Du,Sida Zhao,Yongqiang Zhang,Jingzhe Tang,Zherui Liu,Chuan Wu,Yanghua Peng,Haibin Lin,Wencong Xiao,Xin Liu,Liang Xiang
### Background
大语言模型（LLMs）的训练规模已经达到了成千上万的GPU，并且持续扩大，这使得大型模型的学习速度更快。随之而来的资源规模扩大导致了各种各样的故障（如CUDA错误、NaN值、作业挂起等）的增多，这对训练的稳定性提出了重大挑战。任何大规模LLM训练基础设施都应该尽量减少训练中断，高效地诊断故障，并具备强大的容错能力，以确保高效连续的训练。
### Innovation
ByteRobust是一个针对LLM训练过程特点进行优化的大规模GPU基础设施管理系统，着重于常规检测和恢复故障。利用LLM训练的并行性和特性，ByteRobust实现了高容量的容错性、快速故障分界和定位，并通过数据驱动的方法综合保障了LLM任务的持续和高效训练。
### Conclusion
ByteRobust在超过200,000个GPU的生产GPU平台上部署，对于9,600个GPU的三个月训练任务实现了97%的ETTR（预计训练时间比对）效率。
## 281. `cs.AI` - 在医学视觉语言模型中基准测试和遏制奉承行为 [PDF](https://arxiv.org/pdf/2509.21979), [HTML](https://arxiv.org/abs/2509.21979)
### Authors
Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu
### Background
视觉语言模型(VLMs)越来越多地被整合到临床工作流程中，但它们通常表现出迎合行为，优先考虑与用户语言社会暗示或感知权威一致，而非基于证据的推理。本研究通过一个新颖的临床导向基准，评估了医学视觉问答中的临床奉承性。研究使用来自PathVQA、SLAKE和VQA-RAD的不同器官系统和模态的数据集，构造了医学奉承性数据集。通过对多种视觉语言模型进行对抗性实验，研究发现这些模型通常薄弱，对抗反应存在显著变化，与模型的准确性和大小无显著相关性。模仿和专家提供的校正是最有效的触发因素，表明模型具有独立于视觉证据的偏见机制。
### Innovation
提出了Visual Information Purification for Evidence based Response (VIPER) 的轻量级缓解策略，该策略通过过滤非证据性内容（例如社会压力），然后生成受到约束的证据导向答案，从而降低奉承行为。该框架在保持可解释性的同时，优于基线，并通过基准分析和缓解框架为在现实世界临床医师互动中稳健部署医学VLMs铺平了道路，强调了需要证据为基础的防御机制的重要性
### Conclusion
研究通过基准分析和缓解框架，为医学VLMs的稳健部署提供了基础，强调了需要证据为基础的防御机制的重要性。
## 282. `cs.AI` - RPG: 一种统一和可扩展的代码库生成的仓库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型在生成单一函数或单个文件代码方面表现出色，但在从零开始生成完整的代码库方面仍面临根本性的挑战。这一能力对于从高层次规范构建一致的软件系统并实现自动化代码生成的全部潜力至关重要。此过程需要在两个层次上进行规划：决定要构建哪些功能和模块（提案阶段）以及定义其实现细节（实施阶段）。目前的方法依靠自然语言规划，往往导致不清晰的规定、不匹配的组件和脆弱的设计，因为自然语言本身具有固有的模糊性和结构不足。
### Innovation
为了应对这些限制，本文引入了仓库规划图（RPG），这是一种结构化表示，包括能力和功能在内的统一图，编码文件结构、数据流和功能。通过用明确的蓝图替换自由自然语言，RPG 使长期规划仓库生成得以一致进行。在此基础上，我们开发了图驱动的零代码库框架 ZeroRepo，该框架分为三个阶段：提案级规划、实施级构建和图引导的代码生成并带有测试验证。在 RepoCraft 这一包含六个真实项目并拥有 1,052 任务的基准测试中，ZeroRepo 平均生成近 36,000 行代码和 445,000 代码标记，分别是最强基线 Claude Code 的 3.9 倍和其它基线的 68 倍。它实现了 81.5% 的覆盖率和 69.7% 的测试准确性，分别优于 Claude Code 27.3 和 35.8 个百分点。进一步分析表明，RPG 能够捕捉复杂依赖性、通过接近线性扩展实现更复杂的规划，并提高代理对代码库的理解，从而加速定位。
### Conclusion
研究结果表明，RPG 能够解决传统方法带来的问题，并且在实际项目中的性能显著优于现有方法。RPG 和基于 RPG 的 ZeroRepo 框架为高效的代码生成提供了新的解决方案。
## 283. `cs.AI` - CFDLLMBench：计算流体动力学中评估大型语言模型的基准套件 [PDF](https://arxiv.org/pdf/2509.20374), [HTML](https://arxiv.org/abs/2509.20374)
### Authors
Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan
### Background
大型语言模型（LLMs）已经在通用自然语言处理（NLP）任务中表现出色，但它们在自动化复杂物理系统数值实验方面的应用仍然很少。作为过去几十年计算科学的主要工具，计算流体动力学（CFD）为评估LLMs的科学能力提供了独特的测试平台。CFDLLMBench基准套件包含三个互补部分：CFDQuery、CFDCodeBench和FoamBench，旨在全面评估LLM在三个关键技能：流体动力学研究生水平知识、数值和物理推理以及上下文依赖的流体动力学工作流实现方面的表现。基于现实世界的CFD实践，该基准结合了详细的任务分类和严谨的评估框架，提供了可重复的结果并量化了LLM在代码可执行性、解决方案准确性以及数值收敛行为方面的表现。
### Innovation
CFDLLMBench提出了一套独特的基准套件，旨在全面评估LLMs在CFD任务中的性能。它引入了CFDQuery、CFDCodeBench和FoamBench三个不同的组件，这些组件分别从流体动力学知识、数值和物理推理以及上下文依赖的工作流程实现方面评估模型的性能。通过结合详细的任务分类和严谨的评估框架，CFDLLMBench提供了可重复的结果，量化了模型在代码可执行性、解决方案准确性以及数值收敛行为方面的表现。这为LLM驱动的复杂物理系统数值实验的自动化提供了坚实的基础。
### Conclusion
CFDLLMBench为大型语言模型驱动的复杂物理系统数值实验自动化开发和评估奠定了坚实的基础。该基准套件通过详细的任务分类和严谨的评估方法，提供了可重复的结果，并量化了模型的关键性能指标。相关代码和数据可在指定网址获取。
## 284. `cs.AI` - InfiR2：增强推理能力语言模型的全面FP8培训配方 [PDF](https://arxiv.org/pdf/2509.22536), [HTML](https://arxiv.org/abs/2509.22536)
### Authors
Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Hongxia Yang
### Background
训练大型语言模型（LLMs）的庞大计算成本是阻碍创新的主要障碍。尽管使用FP8训练可以带来显著的理论效率提升，但其广泛应用受到了缺乏全面且开源的培训配方的限制。为解决这一问题，研究团队提供了一个端到端的FP8培训方法，该方法无缝地结合了连续预训练和监督微调。这种方法采用了一种精细的混合粒度量化策略，以维持数值保真度的同时最大化计算效率。通过广泛的实验，该方法证明了在大型语料库上的继续预训练，不仅具有高度的稳定性而且几乎可以忽略不计的性能损失，使FP8在一系列推理基准测试中达到了与BF16基准相当的性能。这还实现了显著的效率改进，包括高达22%的训练时间减少、14%的最大内存使用减少和19%的吞吐量提高。
### Innovation
研究团队开发了一个端到端的FP8培训配方，结合了连续预训练和监督微调，采用精细的混合粒度量化策略以维持数值保真度同时最大化计算效率。该方法在多个推理基准测试中达到了与BF16基准相当的表现，同时具有显著的效率提升，例如训练时间减少、最大内存使用减少和吞吐量提高。
### Conclusion
研究结果证实FP8是一种具有实际性和稳健性的BF16替代方案，团队将发布配套代码，进一步实现大规模模型训练的民主化。
## 285. `cs.AI` - ClustRecNet: 一种用于聚类算法推荐的新型端到端深度学习框架 [PDF](https://arxiv.org/pdf/2509.25289), [HTML](https://arxiv.org/abs/2509.25289)
### Authors
Mohammadreza Bakhtyari,Bogdan Mazoure,Renato Cordeiro de Amorim,Guillaume Rabusseau,Vladimir Makarenkov
### Background
介绍了ClustRecNet框架，这是一种基于深度学习（DL）的推荐系统，用于确定最适合给定数据集的聚类算法。该研究解决了无监督学习中长期存在的聚类算法选择难题。为了实现监督学习，构建了一个包含34,000个具有多种结构特性的合成数据集的数据集，每个数据集都使用了10种流行聚类算法进行处理，结果通过调整兰德指数（ARI）来建立基准标签，用于训练和评估DL模型。
### Innovation
提出的网络架构结合了卷积、残差和注意力机制，以捕捉输入数据的局部和全局结构模式。这种设计支持端到端的训练，学习数据集的紧凑表示，并直接推荐最合适的聚类算法，减少了对人工编造的元特征和传统聚类有效性指标（CVIs）的依赖。实验结果表明，该DL模型在合成和实际数据集上的表现都优于传统的CVIs（以及先进的AutoML聚类推荐方法）.
### Conclusion
通过合成数据和实际数据基准的全面实验表明，提出的DL模型在合成数据上比卡林斯基-哈拉巴什指数高出0.497的ARI改进，在实际数据上比最佳AutoML方法高出15.3％的ARI增益。
## 286. `cs.AI` - 信任区域奖励优化及接近逆向奖励优化算法 [PDF](https://arxiv.org/pdf/2509.23135), [HTML](https://arxiv.org/abs/2509.23135)
### Authors
Yang Chen,Menglin Zou,Jiaqi Zhang,Yitan Zhang,Junyi Yang,Gael Gendron,Libo Zhang,Jiamou Liu,Michael J. Witbrock
### Background
逆强化学习（IRL）通过学习奖励函数来解释专家演示的行为。现代IRL方法通常使用对抗（极小极大）形式，其交替进行奖励和策略优化，这通常会导致训练不稳定。最近的非对抗IRL方法通过能量基础形式同时学习奖励和策略，提高了稳定性，但缺乏正式保证。本文解决了这一差距，作者首先提供了一个统一的观点，展示了典型非对抗方法显式或隐式最大化专家行为的可能性，等同于最小化期望回报差距。这一洞察引出了本文的主要贡献：信任区域奖励优化（TRRO），这是一种通过极小-极大过程保证奖励可能性逐渐提高的框架。我们实例化TRRO到接近逆向奖励优化（PIRO），这是一个实用且稳定的IRL算法。理论上，TRRO提供了IRL在正向RL中的类似保障，实际中PIRO在MuJoCo和Gym-Robotics基准测试中与其他标杆算法在奖励恢复和高采样效率的策略模仿，以及在真实的动物行为建模任务中表现出色或超越了它们的表现
### Innovation
提供了一种名为TRRO的新框架，它保证通过极小-极大过程在专家行为的可能性上有单调的改进。实例化TRRO得到了PIRO，这是一种实用且稳定的IRL算法。PIRO理论上的稳定性和实际测试中的表现均优于其他标杆算法
### Conclusion
TRRO是IRL中的稳定性保证的创新框架，它的应用实例PIRO在多个基准测试和真实世界的应用中表现出色，证明了其在IRL领域的有效性
## 287. `cs.AI` - TimeScope: 向任务导向的长视频时域定位迈进 [PDF](https://arxiv.org/pdf/2509.26360), [HTML](https://arxiv.org/abs/2509.26360)
### Authors
Xiangrui Liu,Minghao Qin,Yan Shu,Zhengyang Liang,Yang Tian,Chen Jason Zhang,Bo Zhao,Zheng Liu
### Background
在长视频中识别关键时刻对于下游理解和推理任务至关重要。传统的时域定位方法由于其泛化能力有限和处理长视频的困难，很难解决这一问题。
### Innovation
提出了一个新的问题，Taskoriented Temporal Grounding (ToTG)，旨在根据任务的自然描述，局部化包含必要信息的时间区间。为此，提出了TimeScope框架，该框架基于逐步推理，首先在长视频中识别粗粒度的时间范围，然后通过细粒度的时刻划分进行细化，从而有效解决时域定位问题。此外，还创建了一个高质量的数据集ToTG Pile，以增强TimeScope在逐步时域定位中的表现。
### Conclusion
广泛的实验表明，TimeScope在各种设置下均优于现有的时域定位方法和流行的MLLMs，突显了其解决这一新挑战性问题的有效性。
## 288. `cs.AI` - 使用机器学习进行新颖的大语言模型脱牢笼检测与分析 [PDF](https://arxiv.org/pdf/2510.01644), [HTML](https://arxiv.org/abs/2510.01644)
### Authors
John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra
### Background
大语言模型（LLMs）面临着各种漏洞，恶意用户可以通过操纵输入文本来诱使模型生成不合规的响应。所谓的脱牢笼提示旨在让模型绕过安全机制，从而违反开发者的政策。因此，研究如何通过机器学习模型来区分脱牢笼提示与正常使用提示变得尤为重要。
### Innovation
研究通过分析不同机器学习模型对脱牢笼提示的识别能力，发现使用端到端微调的双向编码器表示从变换器（BERT）模型可以获得最佳性能。此外，还提出了区分脱牢笼提示和正常提示的关键词，并指出文本提示中的明确反思可能是脱牢笼意图的信号。
### Conclusion
使用当前数据集，最佳方法是使用微调的BERT模型来识别脱牢笼提示。关键词分析表明，明确的提示结构反思可能是脱牢笼意图的信号。
## 289. `cs.AI` - 在噪声中编码目标图像以实现高保真图像编辑的可编辑噪声图反转 [PDF](https://arxiv.org/pdf/2509.25776), [HTML](https://arxiv.org/abs/2509.25776)
### Authors
Mingyu Kang,Yong Suk Choi
### Background
文本到图像的扩散模型已经取得了显著的成功，在生成高质量和多样化的图像方面表现出色。基于这些进展，扩散模型在指导图像编辑方面也展示出了卓越的性能。已有的反转方法在保留源图像内容和实现编辑能力方面存在局限，主要原因是反转后的噪声图虽然能够忠实重建源图像，但限制了对所需编辑的灵活性。
### Innovation
本文提出了一种创新的反转技术——可编辑噪声图反转(ENM Inversion)，它通过寻找最优的噪声图来确保内容的保留和编辑能力。这种方法通过对噪声图的性质进行分析，引入了与所需编辑相适应的可编辑噪声细化，通过最小化重构噪声图和编辑后噪声图之间的差异来实现。实验结果表明，ENM Inversion 在多种图像编辑任务中，在保真度和目标提示编辑保真度方面均优于现有方法。此外，本文的方法还可以轻松应用于视频编辑，以实现跨帧的时间一致性内容操控。
### Conclusion
ENM Inversion 方法在图像和视频编辑中取得了显著的改进，通过优化噪声图反转过程，实现了在保持内容完整的同时，提高编辑的灵活性和保真度。
## 290. `cs.AI` - Verbalized Sampling: 如何减少模式坍缩并解锁大语言模型的多样性 [PDF](https://arxiv.org/pdf/2510.01171), [HTML](https://arxiv.org/abs/2510.01171)
### Authors
Jiayi Zhang,Simon Yu,Derek Chong,Anthony Sicilia,Michael R. Tomz,Christopher D. Manning,Weiyan Shi
### Background
在后训练对齐过程中，通常会减少大语言模型（LLM）的多样性，导致一种现象称为模式坍缩。过往的研究通常将这种效果归因于算法限制，而本研究识别出一个根本性的驱动因素：偏好数据中的典型性偏差，即注释者系统地偏好熟悉的文本，根据认知心理学中的现有发现。
### Innovation
本文引入了Verbalized Sampling（VS）作为一种简单的训练后提示策略，以避免模式坍缩。VS提示模型以口头形式生成一组响应的概率分布（例如，“生成5个关于咖啡的笑话及其对应的概率”）。全面的实验表明，VS在创意写作（诗歌、故事、笑话）、对话模拟、开放式问答和合成数据生成等方面显著提高了性能，同时没有牺牲事实准确性或安全性。研究表明，越强大的模型从中受益越多。在此分析的基础上，本文从数据角度提供了对模式坍缩的新见解，并提出了一种实用的推理时修正策略，有助于释放预训练生成式多样性。
### Conclusion
总之，本文为模式坍缩提供了一个新的数据为中心的认知视角，并提供了一种实用的推理时修正策略，有助于解锁预训练生成式多样性。
## 291. `cs.AI` - 从不精确监督中学习鲁棒扩散模型 [PDF](https://arxiv.org/pdf/2510.03016), [HTML](https://arxiv.org/abs/2510.03016)
### Authors
Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang Shen,Masashi Sugiyama
### Background
最近，条件扩散模型已经在各种生成任务中取得了显著的成果，但它们的训练通常依赖于大规模的数据集，这些数据集不可避免地包含了条件输入中的不准确信息。这些监督通常源于具有噪声、模糊或不完整标签的信息，会导致条件不匹配并降低生成质量。
### Innovation
本文提出了DMIS，一种针对不精确监督训练鲁棒扩散模型的统一框架，这是在扩散模型内的首次系统性研究。该框架基于似然最大化，并将目标分解为生成和分类两个部分：生成部分用于建模不精确标签分布，分类部分则利用扩散分类器估计后验概率，通过优化时间步长采样策略进一步提高了效率。
### Conclusion
广泛的实验证明，DMIS在不同类型不精确监督的任务中（包括图像生成、弱监督学习和嘈杂数据集浓缩）能够生成高质量且具有类区分度的样本。
## 292. `cs.AI` - 基于提示感知的低延迟LLM服务调度 [PDF](https://arxiv.org/pdf/2510.03243), [HTML](https://arxiv.org/abs/2510.03243)
### Authors
Yiheng Tao,Yihe Zhang,Matthew T. Dearing,Xin Wang,Yuping Fan,Zhiling Lan
### Background
高效调度LLM推理任务对于实现低延迟和高吞吐量至关重要，特别是在使用具有推理能力的LLM时更为重要。传统的先来先服务（FCFS）策略容易受到首尾阻塞（HOL）问题的影响，长时间运行的任务会使排队在后的短任务延迟。
### Innovation
本文提出了一种提示感知的LLM任务调度器（PARS），通过成对排名和边际排名损失近似最短任务优先（SJF）调度，旨在做出对调度影响大的决策，并无缝集成到最先进的LLM服务系统vLLM中。PARS有效预测基于响应长度的任务排序，通过最小化开销来降低延迟。
### Conclusion
在多个LLM和真实世界推理数据集上的广泛实验表明，PARS可以显著提高性能，包括推理工作负载。此外，跨模型评估表明该设计具有良好的一般性，即使在不同LLM上训练预测器时也能实现有效的调度。
## 293. `cs.AI` - Nav-EE: 导航引导的早期退出用于自主驾驶中的高效视觉-语言模型 [PDF](https://arxiv.org/pdf/2510.01795), [HTML](https://arxiv.org/abs/2510.01795)
### Authors
Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Shangyu Wu,Nan Guan,Chun Jason Xue
### Background
视觉-语言模型（VLMs）在自主驾驶中得到了广泛应用，可以用作统一感知与推理工具。然而，高推理延时阻碍了其实时部署。传统的早期退出（Early-exit）方法通过在中间层终止推理来减少延时，但由于其任务依赖性，无法在多种场景中进行泛化。研究发现，这种局限性与自主驾驶的导航特性相符：导航系统能够预测即将出现的上下文（例如，十字路口、交通灯），这表明需要哪些任务。由此，本文基于导航指导提出了Nav-EE框架，该框架通过离线预计算任务特定的退出层并在在线阶段根据导航先验应用它们，实现与全推理相同的准确性同时将延时降低至最多63.9%。在CODA、Waymo和BOSCH的数据集上的实验结果以及与Autoware Universe的实车集成表明，该方法可将推理延时减少到300毫秒，支持更快速的复杂场景决策。这些结果证明，将导航先见与早期退出结合可以为自主系统中的大型模型高效部署提供一种可行的途径。
### Innovation
提出了导航引导的早期退出（Nav-EE）框架，该框架通过离线预计算任务特定的退出层并在在线阶段根据导航先验应用它们，实现了与全推理相同的准确性同时显著降低延时。此方法能够适应多种场景，支持更快速、高效的自主驾驶决策。
### Conclusion
通过将导航先见与早期退出结合，可以为自主系统中的大型模型高效部署提供一种可行的路径。实验证实，Nav-EE能够显著减少推理延时，支持更快速的自主驾驶决策。
## 294. `cs.AI` - InstructPLM-mu: 使用结构输入的ESM2在1小时内微调可超越ESM3的蛋白质突变预测 [PDF](https://arxiv.org/pdf/2510.03370), [HTML](https://arxiv.org/abs/2510.03370)
### Authors
Junde Xu,Yapin Shi,Lijun Lang,Taoyong Cui,Zhiming Zhang,Guangyong Chen,Jiezhong Qiu,Pheng-Ann Heng
### Background
多模态蛋白质语言模型在突变效果预测方面表现出色，但这些模型从头开始训练则需要大量的计算资源。ESM2在使用结构输入的情况下，经过微调可以达到与ESM3相当的性能。为了理解这一现象，研究人员系统地比较了三种不同的特征融合设计和微调策略，结果显示，这两种方法都会显著影响最终的准确性，表明微调过程并不简单。
### Innovation
提出了一种名为InstructPLM-mu的微调框架，该框架可以在1小时内将结构输入注入预训练的蛋白质语言模型ESM2，并且通过微调ESM2达到与ESM3相当的性能表现。研究者还系统地对比了三种不同的特征融合设计和微调策略，强调了融合方法和微调策略对最终准确性的显著影响。
### Conclusion
这项工作为将结构信息注入预训练蛋白质语言模型提供了实用指导，并激发了对更好融合机制和微调协议的进一步研究。
## 295. `cs.AI` - 基于生成世界模型的规划式时空预测：一种基于模型的强化学习方法 [PDF](https://arxiv.org/pdf/2510.04020), [HTML](https://arxiv.org/abs/2510.04020)
### Authors
Hao Wu,Yuan Gao,Xingjian Shi,Shuaipeng Li,Fan Xu,Fan Zhang,Zhihong Zhu,Weiyan Wang,Xiao Luo,Kun Wang,Xian Wu,Xiaomeng Huang
### Background
针对物理时空预测中固有的随机性和不可微度量的双重挑战，本文提出了时空预测作为规划（Spatiotemporal Forecasting as Planning，SFP）的新范式，该范式基于模型驱动的强化学习。SFP构建了一个新颖的生成世界模型，用于模拟多样的高保真未来状态，实现了基于想象的环境模拟。
### Innovation
在该框架下，一个基础预测模型作为代理，由基于束搜索的规划算法引导，利用不可微领域的度量作为奖励信号探索高收益的未来序列。这些高奖励候选者随后作为伪标签，通过迭代自训练持续优化代理的策略，显著降低预测误差，并在捕捉极端事件等关键领域指标方面表现出色。
### Conclusion
该研究提出的方法在时空预测方面具有显著的性能提升，并通过迭代自我训练不断优化策略，有效减少了预测误差，展示了在重要领域指标上的出色表现。
## 296. `cs.AI` - 低精度变压器训练失败的原因：闪注意识分析 [PDF](https://arxiv.org/pdf/2510.04212), [HTML](https://arxiv.org/abs/2510.04212)
### Authors
Haiquan Qiu,Quanming Yao
### Background
随着计算效率的不断追求，低精度格式被广泛应用于训练变压器模型中。然而，这种应用常常受到训练稳定性差的阻碍。特别是在低精度设置下使用闪注意识（Flash Attention）进行训练时，模型会面临灾难性的损失爆炸问题，但具体原因一直未得到机制上的解释。
### Innovation
本文首次提供了低精度设置下闪注意识训练失败的机制性解释，发现这一失败并非随机现象，而是由两个因素共同作用导致的：注意力机制中相似低秩表示的出现以及低精度算术中固有的偏置舍入误差的累积效应。文章还提出一个简单的修改方法，以缓解舍入误差偏置，从而稳定训练过程，这一发现验证了研究者的分析并为解决此问题提供了实用方案。
### Conclusion
通过引入一个简单的闪注意识修改，研究人员成功地缓解了舍入误差偏置问题，稳定了训练过程，验证了他们的分析，并提供了一个实用的解决方案，解决了这一长期存在的问题。
## 297. `cs.AI` - CLARITY: Clinical Assistant for Routing, Inference, and Triage [PDF](https://arxiv.org/pdf/2510.02463), [HTML](https://arxiv.org/abs/2510.02463)
### Authors
Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets
### Background
该研究介绍了一个名为CLARITY的AI驱动平台，旨在改善患者与专科医生之间的转介流程、提供临床咨询并评估患者病情的严重性。CLARITY平台结合了有限状态机（FSM）与大型语言模型（LLM），以结构化对话流程支持固定状态的自动行程规划，并利用协作代理分析症状，评估病情，推荐最适合的专科医生。该平台建立在模块化微服务框架上，确保了平台的安全性、高效性和稳健性，同时具备较强的扩展性，能够适应现有的医疗工作流程和IT解决方案。研究团队将CLARITY集成到一个全国范围的医院平台中，并在两个月的部署期间积累了超过55,000条内容丰富的用户对话记录，其中超过2,500条对话得到了专家的标注以进行后续验证。验证结果显示，CLARITY在首次尝试的路由准确性方面超过了人类的表现，同时还使咨询时长减少了约30%。
### Innovation
CLARITY创新地结合了有限状态机和大型语言模型，用于结构化对话流程和症状分析。此外，CLARITY还采用了模块化微服务架构，保证了其安全、高效和可扩展性，能够适应现有的医疗工作流程和IT解决方案。CLARITY在首次尝试的路由准确性方面超过了人类的表现，且咨询时长减少了约30%。研究团队还报告了在大规模实际部署中的应用情况，展示了CLARITY在实际中的效果和应用价值。
### Conclusion
CLARITY平台是在实际部署中成功验证的一种有效工具，能够提高患者转诊的准确性，缩短临床咨询时间，并具有高度的可扩展性和适应性，能够满足现有医疗工作流程和IT解决方案的需求。CLARITY的首次尝试路由精度超过人类水平，并且在实际部署中展示了显著的效率提升。
## 298. `cs.AI` - 6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection [PDF](https://arxiv.org/pdf/2510.03807), [HTML](https://arxiv.org/abs/2510.03807)
### Authors
Vaskar Chakma,Wooyeol Choi
### Background
当前集成数字孪生技术的网络物理系统（CPS）在实现关键任务工业应用中的实时性能方面面临重大限制。现有的基于5G的系统延迟超过10毫秒，不足用于需要亚毫秒响应时间的应用场景，例如自主工业控制和预测性维护。因此，研究旨在开发并验证一种基于6G的数字孪生框架，该框架能够实现超低延迟通信和物理工业资产与其数字对应物之间实时同步，特别聚焦于滚动轴承故障检测这一工业应用场景。
### Innovation
本文引入的一种基于6G的数字孪生框架，该框架通过整合太赫兹通信（0.1-1 THz）、智能反射表面和边缘人工智能，以五层架构的形式，实现了超低延迟通信和实时同步。实验验证使用了Case Western Reserve University的滚动轴承数据集，系统性能通过分类准确性、端到端延迟和可扩展性等多维度进行了评估，结果表明该系统在端到端延迟为0.8毫秒的情况下，分类准确率达到97.7%，相较于WiFi-6和5G分别提高了15.6倍和5.25倍。同时，该系统展示了优异的可扩展性，并在四个滚动轴承故障类别（正常、内圈、外圈、滚珠）下的F1分数均值超过了97%。
### Conclusion
实验结果表明，基于6G的数字孪生框架在滚动轴承故障检测工业应用中的实际效果出色，通过显著降低延迟和提高准确性，为关键任务的工业应用提供了有效解决方案。
## 299. `cs.AI` - P2P: 一种针对大语言模型可靠后门防御的后门对后门对策 [PDF](https://arxiv.org/pdf/2510.04503), [HTML](https://arxiv.org/abs/2510.04503)
### Authors
Shuai Zhao,Xinyi Wu,Shiqian Zhao,Xiaobao Wu,Zhongliang Guo,Yanhao Jia,Anh Tuan Luu
### Background
在微调过程中，大型语言模型（LLMs）越来越容易受到数据中毒后门攻击的影响，这些攻击损害了它们的可靠性和可信度。现有的防御策略存在局限性：它们仅针对特定的攻击类型或任务设置有效。因此，需要一种广泛且有效的后门防御算法来克服这些限制，以便在各种任务设置和攻击类型中保持一致的防御效果。
### Innovation
本文提出了一种名为Poison-to-Poison (P2P)的一般且有效的后门防御算法。P2P通过提示式学习在部分训练样本中注入良性触发器和安全替代标签，并利用这些重新中毒的数据集对模型进行微调。这种方法迫使模型将触发器诱导的表示与安全输出关联起来，从而克服了原恶意触发器的影响。
### Conclusion
理论和实验结果表明，P2P算法可以在保持任务性能的同时有效中和恶意后门。我们在分类、数学推理和摘要生成等任务上进行了广泛的实验，涉及多个领先的大语言模型。结果证明，与基准模型相比，P2P显著降低了攻击的成功率。我们希望P2P能够作为防御后门攻击的指导原则，促进一个安全和可靠的大型语言模型社区的发展。
## 300. `cs.AI` - MLLMEraser：利用活性导向在多模态大型语言模型中实现测试时遗忘 [PDF](https://arxiv.org/pdf/2510.04217), [HTML](https://arxiv.org/abs/2510.04217)
### Authors
Chenlu Ding,Jiancan Wu,Leheng Sheng,Fan Zhang,Yancheng Yuan,Xiang Wang,Xiangnan He
### Background
多模态大型语言模型（MLLMs）已经在视觉-语言任务中展现了卓越的能力，但大规模部署时会引发关于私有数据的回忆、过时知识和有害内容的担忧。现有的MLLM遗忘方法通常依赖基于训练的策略，如梯度上升或偏好优化，但这些方法计算成本高、不可逆且常常扭曲保留的知识。
### Innovation
本文提出了MLLMEraser，一种基于输入感知、无需训练的测试时遗忘框架。该方法利用活性导向实现动态知识遗忘，不更新参数。它通过对比扰动知识回忆的图像-文本对和知识遗忘的对应物，构造多模态的遗忘方向，捕捉文本和视觉的差异。此框架设计了一种输入感知的导向机制，可以根据需要动态决定何时以及如何应用遗忘方向，保持保留知识的有用性并强制遗忘指定的内容。实验结果表明，MLLMEraser 在LLaVA-1.5 和 Qwen-2.5-VL 上优于最先进的基准方法，以较低的计算成本实现更好的遗忘效果，同时最小化有用性的损失。
### Conclusion
MLLMEraser 在保持保留知识效用的同时实现了对指定内容的遗忘，并且在计算成本和保留知识质量方面都表现优越。
## 301. `cs.AI` - 揭示疾病间的联系：从统计方法到大规模语言模型 [PDF](https://arxiv.org/pdf/2510.04888), [HTML](https://arxiv.org/abs/2510.04888)
### Authors
Alina Ermilova,Dmitrii Kornilov,Sofia Samoilova,Ekaterina Laptenkova,Anastasia Kolesnikova,Ekaterina Podplutova,Senotrusova Sofya,Maksim G. Sharaev
### Background
手动分析大规模临床数据以发现疾病联系劳动密集且主观性强，容易引起专家之间意见分歧。尽管机器学习显示出潜力，但仍然存在三个重要挑战：选择合适的机器学习方法、确定来自电子健康记录的真实世界临床数据或结构化疾病描述哪个能提供更可靠的信息、以及缺乏“金标准”，因为一些疾病联系在医学中尚未被探索。
### Innovation
该研究系统评估了七种方法，基于两种数据源——MIMIC-IV电子健康记录中的ICD-10代码序列和完整的ICD-10代码，包括文本描述和无文本描述两种情况下的分析方法。研究框架整合了基于统计共现分析和掩码语言模型的实临床数据方法、医疗领域特定的BERT变体（Med-BERT和BioClinicalBERT）、一般用途的BERT和文档检索方法以及四种大规模语言模型（Mistral, DeepSeek, Qwen, YandexGPT）。结果表明，基于大型语言模型的方法生成的疾病联系与其他方法相比，ICD代码连接的多样性较低，这暗示了大型语言模型发现新联系有局限。
### Conclusion
由于缺乏ICD代码之间医疗联系的金标准数据库，研究结果构成一个有价值的医学疾病本体论，可以作为未来临床研究和医疗健康领域人工智能应用的基础资源。
## 302. `cs.AI` - 在LLM中负责任的人工智能的可扩展多语言PII标注 [PDF](https://arxiv.org/pdf/2510.06250), [HTML](https://arxiv.org/abs/2510.06250)
### Authors
Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu
### Background
随着大型语言模型（LLMs）的广泛应用，确保这些模型在多种监管背景下可靠处理个人可识别信息（PII）变得至关重要。
### Innovation
本文介绍了为13种欠代表语言提供高质量PII注释的可扩展多语言数据整理框架，涵盖约336种特定于地方的PII类型。该框架采用分阶段、人机协同注释方法结合语言学专业知识和严格的质量保证，显著提高了召回率和假阳性率。框架利用注释者间一致性度量和根本原因分析系统地发现并解决注释不一致问题，从而生成高保真数据集，适用于监督学习微调。
### Conclusion
除了报告实证增益外，本文还指出了多语言PII标签中常见注释者挑战，并展示了迭代、数据驱动管道如何提高注释质量并增强下游模型可靠性。
## 303. `cs.AI` - 在混合线性注意力转换方法中解开组件不平衡 [PDF](https://arxiv.org/pdf/2510.05901), [HTML](https://arxiv.org/abs/2510.05901)
### Authors
Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas
### Background
尽管 Transformer 模型具有出色的性能，但它们的二次计算复杂度限制了它们的可扩展性。虽然线性注意力将计算复杂度降低到线性级别，但在大多数情况下，从头开始预训练这些模型仍然非常昂贵。最近的后训练线性化方法能够高效地将预训练的 Transformer 转换为线性模型，通常采用将线性注意力与滑窗 softmax 结合的混合方法。然而，这些现有方法存在一个关键缺陷：它们无意中绕过了线性组件，几乎完全依赖滑窗 softmax。这种现象在常见的常识基准上的组件级诊断中未被发现，来自被忽视的评估实践。
### Innovation
本文提出了三种确保组件混合使用的解决方案：（i）推理时仅线性转换与滑窗 softmax 结合的混合方法；（ii）HedgeCATs，结合注意力权重传递与目标 LoRA 微调；（iii）随机滑窗丢弃（SSD），在训练过程中以概率降低 softmax 支路，防止组件坍塌。这些方法保持了计算效率，恢复了大部分基本模型性能，并确保了线性注意力的实际采用，从而恢复了混合转换性能归因的有效性。
### Conclusion
通过这些新方法，本文在保持计算效率的同时，提高了线性注意力的实际应用，确保了性能归因的有效性，并平衡了组件使用的混合转换方法的正确性。
## 304. `cs.AI` - 人类团队的经验能否应用于多代理系统？结构、多样性与互动动态的角色 [PDF](https://arxiv.org/pdf/2510.07488), [HTML](https://arxiv.org/abs/2510.07488)
### Authors
Rasika Muralidharan,Haewoon Kwak,Jisun An
### Background
多代理系统（MAS）中的强大语言模型（LLM）代理正引起关注，但较少研究探讨代理团队的动力学。本文受人类团队科学研究的启发，提出了一种多代理框架，旨在研究团队基本科学中的结构、多样性和互动动态等方面。
### Innovation
本文通过关注团队的基本科学方面，评估了多代理系统的团队表现，涵盖常识与社会推理任务，发现扁平结构的团队通常比层级结构的团队表现更好，多样性的影响也因其复杂性和表现形式有所不同，强调了在多代理系统中理解团队动态的重要性。
### Conclusion
尽管代理对团队表现过于自信，但任务后反思表明，代理之间在合作上的认可和在整合上面临的挑战，包括对话协调的有限性。
## 305. `cs.AI` - 在线成对比较中从双向比较生成在线评价标准 [PDF](https://arxiv.org/pdf/2510.07284), [HTML](https://arxiv.org/abs/2510.07284)
### Authors
MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek
### Background
评价标准为训练LLM生成开放式的长篇回答提供了一种灵活的方式，尤其是在无法提供可验证奖励和仅有粗略人类偏好信号的情况下。既有研究显示，使用基于评价标准的奖励进行强化学习可以显著提高训练后的LLM性能。现有的大多数方法依赖静态评价标准，但这些静态标准容易导致奖励作弊行为，无法捕捉训练过程中浮现的新需求。本研究旨在解决这一问题，提出了一种名为OnlineRubrics的方法，该方法能够通过当前政策和参考政策响应的成对比较动态生成评价标准，从而在线上持续识别并修正错误，进而不断提高训练效果
### Innovation
该研究创新性地提出了一种名为OnlineRubrics的方法，通过成对比较响应来动态生成评价标准。这种方法可以在线上持续发现并修正错误，避免了静态评价标准的局限性，提高了LLM训练的效果，具体而言，在多种评估集上取得了最高8%的提升。此外，通过质性分析生成的评价标准，发现了透明性、实用性、组织性和推理等显著主题，为后续研究提供了新的方向
### Conclusion
这一方法能够在动态生成评价标准的同时，保证LLM训练过程中的高质量和一致性，相比于仅使用静态评价标准，表现更为出色。此外，该方法促使生成的评价标准更有意义，能够反映出训练过程中浮现的重要需求。
## 306. `cs.AI` - Reinforce-Ada: 一种用于强化学习风格的大语言模型训练的自适应采样框架 [PDF](https://arxiv.org/pdf/2510.04996), [HTML](https://arxiv.org/abs/2510.04996)
### Authors
Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang
### Background
在利用强化学习对大型语言模型（LLMs）进行推理任务时，由于固定且均匀地采样响应导致梯度估计不稳定，成为限制因素。先前的研究如GVM-RAFT通过在预算约束下动态分配推理预算来减少随机梯度方差，以此解决这一问题。在借鉴这一洞察的基础上，作者提出了Reinforce-Ada，这是一种在线的自适应采样框架，通过对不确定性或学习潜力最大的提示持续重新分配采样努力来加速训练过程。
### Innovation
与传统的两阶段分配方法不同，Reinforce-Ada将估计和采样交错在一个在线的逐步淘汰过程中，并且一旦从某个提示收集到足够的信号就会自动停止采样。为了稳定更新，该框架形成了具有强制奖励多样化约束的固定大小的组，并使用自适应采样阶段收集的综合统计信息计算优势基线。实验结果表明，与GRPO相比，该方法在多个模型架构和推理基准上加速了收敛并提高了最终性能，特别是在使用均衡采样变体时更为明显。
### Conclusion
我们的工作突显了在保证大语言模型生成推理能力的同时，利用变异感知的自适应数据收集方式在提高强化学习效率和可靠性方面发挥的关键作用。相关代码可以在提供的链接处找到。
## 307. `cs.AI` - GyroSwin：用于等离子体湍流仿真的5D代理模型 [PDF](https://arxiv.org/pdf/2510.07314), [HTML](https://arxiv.org/abs/2510.07314)
### Authors
Fabian Paischer,Gianluca Galletti,William Hornsby,Paul Setinek,Lorenzo Zanisi,Naomi Carey,Stanislas Pamela,Johannes Brandstetter
### Background
核聚变在可靠和可持续能源生产中起着关键作用，但核聚变电力面临的主要障碍是对等离子体湍流的理解不足，这严重阻碍了等离子体的约束，对于下一代反应堆设计至关重要。等离子体湍流由非线性陀螺颗度方程支配，该方程随时间演变5维分布函数。由于计算成本高，实践中通常使用降低维度的模型来近似湍流能量传输。然而，这些模型忽略了全维动态中的非线性效应。为解决这一问题，我们引入了GyroSwin，这是第一个可扩展的5D神经代理模型，能够模拟5D非线性陀螺颗度仿真，从而捕捉降低维度模型所忽略的物理现象，同时提供准确的湍流热量传输估计。
### Innovation
GyroSwin 扩展了分层视觉变换器到5D，并引入了跨注意力和集成模块用于潜在3D<->5D电静态势场与分布函数之间的交互，同时基于非线性物理进行了通道方式模式分离。
### Conclusion
GyroSwin 在等离子体热流预测方面优于广泛使用的降低维度数值方法，捕捉了湍流能量级联，并在将全解析非线性陀螺颗度动力学成本降低三个数量级的同时保持物理可验证性。GyroSwin 表现出有希望的可扩展性定律，最多测试到一亿个参数，为等离子体湍流仿射的可扩展神经代理模型铺平了道路。
## 308. `cs.AI` - Haystack 工程：异质性和自主性长上下文评估的上下文工程 [PDF](https://arxiv.org/pdf/2510.07414), [HTML](https://arxiv.org/abs/2510.07414)
### Authors
Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li
### Background
现代大规模语言模型在合成的‘针扎草堆’（NIAH）基准测试中表现出色，但这些测试忽略了从偏见检索和代理工作流程中噪音上下文的来源。研究表明，Haystack 工程对于构建真实世界中因素（如异质偏见检索器的干扰和代理工作流程中的级联错误）反映充分的噪音长上下文是必要的，以测试模型的长上下文鲁棒性。
### Innovation
提出了一种名为 HaystackCraft 的新 NIAH 基准，它基于全英版维基百科超链接网络，并采用多跳问题。HaystackCraft 评估不同的检索策略（例如稀疏型、密集型、混合型和图基型）对干扰组成、草堆排序以及下游 LLM 性能的影响。此外，HaystackCraft 延伸了 NIAH 到以模型依赖性模拟代理操作的动态场景，在此场景中，模型不断完善查询、反思过去的推理，并决定何时停止。
### Conclusion
实验结果显示，更强的密集检索器可以引入更具挑战性的干扰，而图基型重新排名则在提高检索效果的同时减少更多有害干扰。在代理测试中，即使是最先进模型（如 Gemini 2.5 Pro 和 GPT-5）也会因为自动生成的干扰或难以执行早期停止而面临级联失败。这些结果凸显了长上下文推理中持续存在的挑战，并首次将 HaystackCraft 确立为未来研究的重要测试床。
## 309. `cs.AI` - 更少的权重，更多的问题：对LLM剪枝的实际攻击 [PDF](https://arxiv.org/pdf/2510.07985), [HTML](https://arxiv.org/abs/2510.07985)
### Authors
Kazuki Egashira,Robin Staab,Thibaud Gloaguen,Mark Vero,Martin Vechev
### Background
模型剪枝，即移除模型权重的子集，已经成为减少大语言模型（LLMs）推理过程中的内存占用的主要方法。流行的推理引擎，如vLLM，使用户可以在部署前方便地剪枝下载的模型。尽管剪枝方法的实用性和效率得到了显著提高，但剪枝的安全影响仍然没有得到充分探索。研究首次展示了现代LLM剪枝方法可以被恶意利用。实验证明，任何在vLLM应用的剪枝方法（如Magnitude，Wanda和SparseGPT），在多种攻击场景中，都表现出强大的恶意行为（成功率为高达95.7%的突破性行为、98.7%的良性指令拒绝行为以及99.5%的针对性内容注入行为）.
### Innovation
研究创新地展示了如何利用现代LLM剪枝方法进行恶意攻击。攻击者可以通过计算一个代理度量来估计每个参数被剪枝的可能性，然后将恶意行为注入不太可能被剪枝的参数，最后用更有可能被剪枝的参数恢复模型，从而在未剪枝的模型中抵消注入的行为。研究表明，任何情况下，攻击成功率都非常高，揭示了模型压缩部署时的安全缺口，突显了增强安全意识的迫切性.
### Conclusion
研究揭示了模型剪枝在部署时的安全漏洞，强调了在模型压缩过程中需要更强的安全意识。攻击者可以利用剪枝过程自身的特点，执行恶意操作，这强调了在模型部署前进行安全性评估和测试的重要性。
## 310. `cs.AI` - 学习神经曝光场进行视角合成 [PDF](https://arxiv.org/pdf/2510.08279), [HTML](https://arxiv.org/abs/2510.08279)
### Authors
Michael Niemeyer,Fabian Manhardt,Marie-Julie Rakotosaona,Michael Oechsle,Christina Tsalicoglou,Keisuke Tateno,Jonathan T. Barron,Federico Tombari
### Background
近年来，神经场景表示的进展使得3D重建和视角合成的质量达到了前所未有的水平。尽管在带有精心策划数据的通用基准测试中能产出高质量的结果，但对于包含如强烈曝光变化等图像间变化的数据（如大多数具有室内和室外区域或者带有窗户的房间场景），输出往往会恶化。这种问题在大多数实际场景中普遍存在，因此需要有效的解决方案来应对这些挑战。
### Innovation
本文提出了一种新颖的技术——神经曝光场(NExF)，用于从困难的现实世界捕获中稳健地重建高质量且3D一致外观的3D场景。核心贡献是学习一个神经场来预测每个3D点的最佳曝光值，使我们能够以3D场景表示优化曝光。方法将传统的基于像素的曝光优化扩展到了基于3D的空间优化，从而在高动态范围场景实现精确的视角合成，而不依赖于后期处理步骤或多次曝光捕获。
### Conclusion
本工作包括一种新的神经表示用于曝光预测，一个场景表示和曝光场联合优化的新系统，以及在多种基准测试中表现出色的结果。实验证明，本文方法相较于先前工作训练速度更快，且在多个基准测试中取得了最先进的结果，提高了超过55%的最佳基线性能。
## 311. `cs.AI` - 合成序列-符号数据生成以用于时间序列基础模型 [PDF](https://arxiv.org/pdf/2510.08445), [HTML](https://arxiv.org/abs/2510.08445)
### Authors
Wenxuan Wang,Kai Wu,Yujian Betterest Li,Dan Wang,Xiaoyu Zhang
### Background
时间序列分析（TSA）的基础模型近年来受到了广泛的关注。然而，由于训练数据的稀缺性和不平衡性，这些模型的发展仍然面临重重挑战。作者提出了一种受复杂动态系统理论启发的序列-符号数据生成机制，能够不受限制地生成高质量的时间序列数据及其对应的符号表达形式。通过利用高相关性的序列-符号数据对，作者提出了一种名为SymTime的预训练基础模型，利用符号信息来增强时间序列的表示能力。实验表明，SymTime在五个主要的TSA任务中表现出竞争性性能，与基于真实数据集进行预训练的基线模型性能相当。这种方法突出了序列-符号数据生成和预训练机制在克服数据稀缺性并增强任务性能方面的潜力。提供的代码可以在以下链接访问：this https URL
### Innovation
作者提出了一种新的数据生成机制，并基于此开发了一个预训练的时间序列基础模型SymTime，能够利用符号信息来增强时间序列的表示。这种方法通过生成与符号表达形式有强相关性的高质时间序列数据对，旨在解决数据稀缺和不平衡的问题，从而提升模型在多项任务上的性能。
### Conclusion
SymTime展示了在五大时间序列分析任务中具备强劲的竞争性性能，与基于真实数据集预训练的模型表现相似。这种方法证实了序列-符号数据生成和预训练机制在克服数据稀缺性及提升任务性能方面的巨大潜力。
## 312. `cs.CL` - 大规模语言模型脆弱推理的系统诊断 [PDF](https://arxiv.org/pdf/2510.08595), [HTML](https://arxiv.org/abs/2510.08595)
### Authors
V. S. Raghu Parupudi
### Background
本文的研究背景在于人工智能领域尤其是机器学习模型对数学的理解程度，传统的基准测试不足以深入诊断模型的具体失效点。
### Innovation
本文提出了一种新的衡量数学推理能力的框架，不同于传统的基准测试，该框架能够生成结构化的、分步骤的推理，并通过更强大的分析师模型对错误进行分类，同时使用无监督聚类分析每个推理句子，确定出具体的“推理模式”。这种方法揭示了模型在处理组合推理时的非人性化的脆弱性：尽管在顺序计算等程序性模式上的准确度非常高，但在需要组合推理和限制条件时的表现却显著下降。
### Conclusion
通过对不同推理能力的可靠性和准确度的识别和量化，本文提供了一种更为细致的方法来评估数学理解能力，并为开发新的能力和更可靠的应用指明了具体的路径。
## 313. `cs.AI` - RLVR的优化动力学：梯度差距和步长阈值 [PDF](https://arxiv.org/pdf/2510.08539), [HTML](https://arxiv.org/abs/2510.08539)
### Authors
Joe Suk,Yaqi Duan
### Background
RLVR是一种使用简单二元反馈来后训练大型语言模型的方法，已显示出显著的经验成功。然而，关于为何它有效的原因缺乏严格的理论理解。本文通过在响应序列和标记级别上分析其训练过程，为RLVR建立了理论基础。文章的核心在于梯度差距这一概念，它形式化了从低奖励到高奖励响应空间区域改进的方向。理论证明，收敛性高度依赖于更新方向与梯度差距的对齐，同时基于梯度差距的程度推导出严格的步长阈值：低于该阈值，学习会收敛，而高于该阈值，则会导致性能崩溃。文章进一步预测了关键步长如何随响应长度和成功率变化，并解释了为什么诸如长度归一化等实用启发式方法能够提高稳定性。这表明，以固定的学习率，成功率会严格低于100%。通过受控的多臂老虎机模拟，验证了这些预测结果。
### Innovation
文章通过理论分析建立了RLVR的基础，提出了梯度差距的概念，解释了收敛性和性能崩溃的原因，并基于这一概念建立了一个严格的步长阈值模型。该理论还预测了关键步长如何随响应长度和成功率变化，从而解释了长度归一化等实用启发式方法的有效性，并指出在固定学习率下，成功率可以严格低于100%。
### Conclusion
文章通过理论分析为RLVR建立了基础模型，提出了梯度差距的概念和基于此的严格步长阈值，验证了这些理论上预测的现象，解释了为什么某些经验性策略能够提高模型的稳定性，同时也指出了模型在特定条件下的局限性。
## 314. `cs.CL` - 创意时代LLM评价的度量标准：不仅仅是困惑度 [PDF](https://arxiv.org/pdf/2510.08596), [HTML](https://arxiv.org/abs/2510.08596)
### Authors
V. S. Raghu Parupudi
### Background
参考无偏度的指标如自我困惑度在评判创造性文本生成时存在显著偏差。为了减少这种偏差，该研究提出了从模型输出概率分布中导出的信心分数（CS）作为替代方案。
### Innovation
该研究提出了一种新的度量标准——信心分数（CS），并表明与基于流畅性的度量相比，CS在99%的创意提示中能更有效地判定创造性文本生成，这是一种统计上的显著差异。此外，CS能够区分任务的难易程度，具有不重叠的置信区间。
### Conclusion
信心分数（CS）减轻了传统度量标准对创造性的偏差，同时保留了他们的核心评估优势，为现代大语言模型提供了更平衡的评估。
## 315. `cs.CL` - 使用GLiNER-BioMed和目标字典后处理增强生物医学命名实体识别：针对BioASQ 2025任务6 [PDF](https://arxiv.org/pdf/2510.08588), [HTML](https://arxiv.org/abs/2510.08588)
### Authors
Ritesh Mehta
### Background
生物医学命名实体识别（BioNER）是BioASQ（生物医学大规模语义索引和问答挑战）任务6中的关键任务，对于从科学文献中提取信息至关重要。然而，由于难以区分如基因与化学物质等相似实体类型，此任务面临挑战。GLiNER-BioMed模型在这项研究中被评估，并提出了一种针对常见错误分类的字典后处理策略以提升识别准确性。尽管该后处理方法在开发集上表现出显著改善（从基础的0.79微F1分数提升到0.83），但在盲测试集上表现不佳，最终分数降低至0.77，相较于基线分数0.79而言有所下降。此外，研究探讨了使用条件随机场等替代方法，但并未显著改善结果。这些结果强调了使用预训练模型进行词典精炼的潜力，同时也指出了开发数据过拟合问题及确保实际应用中稳健泛化的必要性。
### Innovation
引入了一种针对常见错误分类的字典后处理策略，并评估了GLiNER-BioMed模型在BioASQ数据集上的表现。探讨了条件随机场等方法作为改进方向，但并未取得显著成效。
### Conclusion
研究表明，字典基于的模型精炼可能对预训练BioNER模型有提升效果，但也强化了开发数据过拟合问题，并强调了确保实际应用中稳健泛化的必要性。
## 316. `cs.CL` - 基于层次自我监督表示学习的语音抑郁检测 [PDF](https://arxiv.org/pdf/2510.08593), [HTML](https://arxiv.org/abs/2510.08593)
### Authors
Yuxin Li,Eng Siong Chng,Cuntai Guan
### Background
言语基抑郁症检测（SDD）是一种有前景的无创替代传统临床评估的方法。然而，它仍然受到提取有意义特征的难度以及难以捕捉稀疏且异质的抑郁线索的影响。预训练自我监督学习（SSL）模型如WavLM提供了丰富的、多层的语音表示，但现有的大多数SDD方法仅依赖于最后一层或搜索最佳表现的一层，这些方法往往对特定数据集过拟合并且未能充分利用检测微妙且持久抑郁信号所需的完整层次结构。
### Innovation
我们提出了一种名为HAREN-CTC的新型架构，它在多层次SSL特征中使用了多任务学习框架内的交叉注意，并结合了连接时序分类损失以处理稀疏的时间监督。HAREN-CTC 包含两个关键模块：层次自适应聚类模块，它重新组织SSL特征为互补嵌入；以及跨模态融合模块，它通过交叉注意来建模层间依赖性。CTC 目标使得对齐意识的训练成为可能，从而使模型能够追踪抑郁语音线索的不规则时间模式。
### Conclusion
我们在标准数据分割的上界设置和使用五折交叉验证的一般设置下评估了HAREN-CTC。该模型在DAIC-WOZ中实现了0.81的宏F1分数，在MODMA中实现了0.82的宏F1分数，两种评估场景下均优于此前的方法。
## 317. `cs.CL` - Recover-LoRA：通过低秩适应实现退化语言模型的数据驱动精度恢复 [PDF](https://arxiv.org/pdf/2510.08600), [HTML](https://arxiv.org/abs/2510.08600)
### Authors
Devleena Das,Rajeev Patwari,Ashish Sirasao
### Background
语言模型任务性能可以通过各种推理优化（如量化、剪枝、数据类型转换、模型导出和序列化）受到功能损失。大多数关于性能恢复的努力主要集中在鲁棒量化技术上，而该研究专注于从不正确模型序列化等所有来源恢复模型精度。
### Innovation
研究提出了一种轻量级且数据通用的方法，即Recover-LoRA，用于恢复退化模型的精度。Recover-LoRA通过合成数据和logit蒸馏，在选择性的层上学习LoRA适配器，以使退化模型与全精度模型对齐。该方法适用于不同类型的较小语言模型以及多种评估数据集，显示出在多头注意力（MHA）和团体查询注意力（GQA）较小语言模型上恢复了5-17%的模型精度。
### Conclusion
研究结果表明，Recover-LoRA能够在不同类型的语言模型上有效恢复损失的精度。
## 318. `cs.CL` - 较少多样性，较低安全性：大型语言模型测试时缩放的间接但普遍风险 [PDF](https://arxiv.org/pdf/2510.08592), [HTML](https://arxiv.org/abs/2510.08592)
### Authors
Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra
### Background
Test-Time Scaling (TTS) 通过探索多个候选响应，然后在这些候选集中找到最佳输出来提升大语言模型（LLM）的推理能力。然而，TTS 的一个潜在前提是多样化的候选集能够提高可靠性。这项研究揭示了一个不为人知的失败模式，当候选集的多样性被适度减少时，TTS 更容易产生不安全的输出。现有用于防御这种多样性和安全防护方法（如 Llama-Guard 和 OpenAI 中介化 API）不具备检测和阻止由 TTS 引入的这些不安全结果的能力，因此称为 TTS 策略的安全威胁。
### Innovation
这项研究提出了一种名为 RefDiv 的参考指导多样性减少协议，它作为诊断性攻击来测试 TTS 管道的稳健性。研究发现，即使是对多样性的轻微限制，也会显著增加不安全结果的产生率。这种现象普遍存在于多种 TTS 策略中，不仅限于开源模型，还扩展到了闭源模型，如 OpenAI o3 和 Gemini-2.5-Pro。这表明 TTS 存在一个普遍的不安全因素，而不是特定模型特性的缺陷。
### Conclusion
该研究揭示了 TTS 的安全风险，并希望推动未来在设计更稳健的 TTS 策略方面的研究，这些策略能够有效应对多样性导向的攻击。此外，研究发现现有的安全防护工具在针对 TTS 引入的问题方面提供的保护有限，这凸显了需要更多关注 TTS 的安全性。
## 319. `cs.CL` - 人类文本是离群值：基于离群值检测LLM生成文本 [PDF](https://arxiv.org/pdf/2510.08602), [HTML](https://arxiv.org/abs/2510.08602)
### Authors
Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu
### Background
大型语言模型（LLMs）如ChatGPT、DeepSeek和Claude快速进步，在数字通信中增加了AI生成文本的比例。现有区分人类撰写和机器生成内容的方法多作为二分类问题处理，容易在不同领域中表现不佳。
### Innovation
本文提出重新定义检测任务为离群值检测问题，认为人类文本不是统一分布而是离群值，构建单类别学习和基于评分的学习技术框架（包括DeepSVDD、HRN和能量基于方法），实验证明这种方法在多个数据集上表现优异，尤其在DeepFake数据集上AUROC达到98.3%，FPR95只有8.9%。此外，框架在多语言、攻击和未见过的模型和领域文本上测试，展示了其稳健性和泛化能力。
### Conclusion
通过离群值检测方法，本文有效提升了检测LLM生成文本的能力，框架具有广泛的适用性和鲁棒性。
## 320. `cs.CL` - Mnemosyne:边缘基于的大型语言模型中启发式无监督长期记忆架构 [PDF](https://arxiv.org/pdf/2510.08601), [HTML](https://arxiv.org/abs/2510.08601)
### Authors
Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)
### Background
长时记忆对于自然、真实的对话至关重要。然而，当前的大规模语言模型（LLM）记忆系统依赖于粗暴的上下文扩展或固定的检索管道，这些方法在边缘设备上表现不佳，特别是在边缘设备对计算和存储资源有限制的情况下。因此，需要一种不依赖大量数据预处理，能够适应边缘设备长期记忆的方法，做到在资源受限的环境下，仍能进行有效的对话记忆和内容使用。
### Innovation
本文介绍了一种名为Mnemosyne的无监督、人类启发式的长期记忆架构，设计用于边缘设备上的大型语言模型。Mnemosyne使用图结构存储、模块化内容和冗余过滤机制、记忆提交和修剪机制，以及基于人类记忆的具有时间衰减和刷新过程的概率性检索。特别地，Mnemosyne引入了一个从固定长度的内存图子集中高效提取的“核心总结”，能够捕捉用户的个性及护理应用中的长期特定细节。此外，Mnemosyne被设计成能够适应纵向的健康助手，这些助手需要管理重复且语义上相似但在时间上不同的对话，这些对话受简单检索的限制。
### Conclusion
实验表明，在纵向健康对话实验中，Mnemosyne在盲评估中具有最高的现实性和长期记忆能力，得分为65.8%，明显高于基线RAG方法31.1%的表现。此外，在时间推理和单跳检索的LoCoMo基准评测中，Mnemosyne达到了现有最高分数。综合所有方法，Mnemosyne的整体平均得分为54.6%，仅次于某些常用方法，这表明改进的事实再现、增强的时间推理以及更多自然的用户界面响应是可行的，通过一种边缘兼容且易于迁移的无监督记忆架构实现。
## 321. `cs.CL` - LatentBreak: 通过潜在空间反馈破解大型语言模型 [PDF](https://arxiv.org/pdf/2510.08604), [HTML](https://arxiv.org/abs/2510.08604)
### Authors
Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio
### Background
该论文探讨了针对大型语言模型的Jailbreak（越狱）攻击。这些攻击是设计用来绕过大型语言模型内置的安全机制。现有的Jailbreak攻击通常通过优化恶意后缀或调整长提示模板，迫使模型生成初始部分受限或有害的响应。然而，这些方法可以通过基于困惑度的过滤来检测。
### Innovation
该研究提出了一种名为LatentBreak的白盒Jailbreak攻击方法，该方法通过空间中替代词生成低困惑度的自然对抗性提示，从而绕过基于困惑度的防御。与现有方法不同，LatentBreak通过在潜在空间中选择最接近无害请求的单词来生成对抗提示，而不需要添加高困惑度的恶意后缀或长模板。
### Conclusion
研究通过广泛的评估显示，LatentBreak生成的提示更短且具有低困惑度，这使得它在对抗基于困惑度的过滤器方面优于现有的Jailbreak算法。
## 322. `cs.CL` - YpathRAG：病理领域的检索增强生成框架及基准 [PDF](https://arxiv.org/pdf/2510.08603), [HTML](https://arxiv.org/abs/2510.08603)
### Authors
Deshui Yu,Yizhi Wang,Saihui Jin,Taojie Zhu,Fanyi Zeng,Wen Qian,Zirui Huang,Jingli Ouyang,Jiameng Li,Zhen Song,Tian Guan,Yonghong He
### Background
大规模语言模型（LLMs）在通用任务上表现出色，但在病理等高门槛领域仍然会出现虚构情况。现有工作主要依赖于领域的微调，但这既不能扩大知识边界，也无法强制实施以证据为基础的约束。
### Innovation
该研究构建了一个覆盖28个子领域、153万段落的病理向量数据库，并提出了YpathRAG，这是一种以病理为导向的RAG框架，采用了双通道混合检索（结合密集检索BGE-M3和词汇导向稀疏检索）和一个基于LLM的支持性证据判断模块，以闭合检索-判断-生成循环。此外，还发布了两个评估基准，YpathR和YpathQA-M。在YpathR上，YpathRAG达到了召回率@5为98.64%，比基线高出23个百分点；在YpathQA-M的300个最具挑战性的问题中，它将通用和医学LLM的准确性平均提高了9.0%，最高提高了15.6%。这些结果表明检索质量提高和事实可靠性增强，为病理导向的RAG提供了可扩展的构建范式和可解释评估手段
### Conclusion
这些结果证明了检索质量的提升和事实可靠性的增强，为病理导向的RAG提供了可扩展的构建范式和可解释的评估方法。
## 323. `cs.CL` - 迈向更安全的网络：多语言多代理大语言模型在缓解对抗性误导信息攻击中的应用 [PDF](https://arxiv.org/pdf/2510.08605), [HTML](https://arxiv.org/abs/2510.08605)
### Authors
Nouar Aldahoul,Yasir Zaki
### Background
数字平台上的虚假信息的迅速传播危害了公众对话、情感稳定和决策制定。尽管之前的研究所探讨了各种误导信息检测中的对抗性攻击，但这项论文所研究的特定转换还没有系统地被研究。研究主要探讨了跨英文、法文、西班牙文、阿拉伯文、印地文和中文的语言切换，以及在总结之前查询长度的膨胀，和转换结构成多项选择题。这些方式都是现有研究中较少探讨的手段，对预防多样化攻击的重要性进行了补充说明，强调了利用AI进行虚假信息检测对于网络事实完整性保护的重要性。
### Innovation
研究提出了一种多语言多代理大语言模型框架，采用检索增强生成技术，并可以在网上作为插件部署。这一创新在于它能够针对多种语言和攻击手段进行保障，展示了解决实际网络应用中对抗性误导信息攻击的可行性。
### Conclusion
这项研究强调了AI驱动的虚假信息检测在保护网络事实完整性上的重要性，并展示了基于插件的部署方式在实际网络应用程序中的可行性。
## 324. `cs.CL` - GraphGhost：追踪大型语言模型背后的结构 [PDF](https://arxiv.org/pdf/2510.08613), [HTML](https://arxiv.org/abs/2510.08613)
### Authors
Xinnan Dai,Kai Guo,Chung-Hsiang Lo,Shenglai Zeng,Jiayuan Ding,Dongsheng Luo,Subhabrata Mukherjee,Jiliang Tang
### Background
大语言模型（LLMs）展现了卓越的推理能力，但其背后的结构机制仍然鲜有探索。本文介绍了一种名为GraphGhost的统一框架，用于表示神经元激活和其信号传播的图形表示，解释了LLMs如何从序列输入中捕获结构性语义并生成具有一致结构机制的输出。
### Innovation
GraphGhost框架将神经元激活和信号传播表示为图形，利用图算法如PageRank来表征LLMs的属性，揭示了跨多种数据集的共同和特定推理行为。此外，研究通过结构干预识别并评估GraphGhost中的激活神经元，发现对关键神经元节点的修改可以引发推理崩溃，改变逻辑流程和语义理解。
### Conclusion
这些贡献使GraphGhost成为分析、干预和最终理解LLMs推理结构基础的强大工具。
## 325. `cs.CL` - 中心化情绪热点：对话中多模态局部-全局融合与跨模态对齐 [PDF](https://arxiv.org/pdf/2510.08606), [HTML](https://arxiv.org/abs/2510.08606)
### Authors
Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li
### Background
情绪识别在对话中的挑战在于鉴定性证据稀疏、局部化且往往在不同模态中具有异步性。传统的ERC方法难以处理这些复杂性，特别是在不同模态之间进行有效的跨模态对齐和特征融合时遇到困难，从而导致识别效果不佳和模型复杂度增加。
### Innovation
提出了基于情绪热点的方法，通过检测文本、音频和视频中的情绪热点，并结合全局特征进行Hotspot-Gated Fusion，使用路由混合的Aligners进行模态对齐，引入跨模态图编码对话结构。该方法专注于显著段落，减少错位并保留上下文信息，以此改善异步证据的处理和多模态特征的融合，增强情绪识别的效果。该设计强调模型关注显著段落，减少错位，同时保留上下文信息，从而提高了情绪识别的准确性。对比实验显示，该模型在标准的ERC基准测试中优于强大的基线模型，并且消融实验确认了HGF和MoA的贡献。
### Conclusion
实验结果表明，基于情绪热点的方法在标准的ERC基准测试中取得了显著的进展，并通过消融实验确认该方法的有效性。这一结果指出了情绪热点中心化的新视角，可以指导未来多模态学习的发展，同时也提供了ERC中模态融合的新视角。
## 326. `cs.CL` - 基于迭代LLM生成和细化数学文字问题中的干扰条件 [PDF](https://arxiv.org/pdf/2510.08615), [HTML](https://arxiv.org/abs/2510.08615)
### Authors
Kaiqi Yang,Hang Li,Yucheng Chu,Zitao Liu,Mi Tian,Hui Liu
### Background
数学推理是评估大型语言模型（LLMs）智能的关键测试平台，数学文字问题（MWPs）是最常用的形式。现有MWPs大多仅包含必要信息，忽视了含有干扰或多余条件的问题。先前研究显示，引入干扰条件后，流行的大语言模型的性能会显著下降。然而，这些干扰条件的数据集有限，且大部分问题难度较低或表达不连贯，这使得干扰条件较为容易识别和忽略，降低了使用这些数据集的基准测试的有效性。当加入干扰条件后，推理过程和答案可能会改变，这需要人工检查和重新编写解答。
### Innovation
论文设计了一个迭代框架，利用大语言模型自动生成干扰条件。通过设计一组提示，从多个角度和认知层次修订MWPs，鼓励创建有意义的干扰条件以及进一步的完善建议。核心优势在于保留了原始问题和修订问题之间共享的解答：引导大语言模型生成不影响原始解答的干扰条件，从而无需生成新的答案。此框架高效且易于部署，大幅减少了生成含有干扰条件的MWPs所需的努力，同时保持了数据质量。
### Conclusion
该框架通过自动生成干扰条件，克服了现有MWPs数据集的不足，提高了MWPs在智能评估中的有效性和可信度。
## 327. `cs.CL` - 医疗领域大型语言模型中的性别偏见：赋值一致性和临床影响 [PDF](https://arxiv.org/pdf/2510.08614), [HTML](https://arxiv.org/abs/2510.08614)
### Authors
Mingxuan Liu,Yuhe Ke,Wentao Zhu,Mayli Mertens,Yilin Ning,Jingchi Liao,Chuan Hong,Daniel Shu Wei Ting,Yifan Peng,Danielle S. Bitterman,Marcus Eng Hock Ong,Nan Liu
### Background
大型语言模型（LLMs）在医疗领域的整合有望增强临床决策，但它们可能存在的偏见问题仍然是一个亟待解决的核心问题。性别因素长期以来影响着医生的行为和患者的结局，因此，假设人类般角色的LLMs，例如临床医生或医疗教育者，可能会复制甚至放大与性别相关的偏见。本文通过分析《新英格兰医学杂志》挑战（NEJM）中的案例研究，对多个开源和专有LLM进行了性别（女性、男性或未指定）赋值，并评估了这些模型在LLM基础诊断及模型对患者性别在LLM基础诊断中的相关性和必要性判断方面的一致性。
### Innovation
研究采用案例研究的方法，对多种开源和专有LLM进行了性别赋值，并评估了它们在诊断和模型对患者性别在诊断中的相关性和必要性判断方面的一致性。发现了诊断结果在大多数模型中具有一致性，但在判断性别相关性时，所有模型表现出了显著的一致性差异，特别是偏见方向上女性和男性间的系统性差异。
### Conclusion
研究结果揭示了一种未被充分探索的偏见，这可能会影响LLM在临床实践中的可靠性，强调了在与LLM交互时进行常规身份赋值一致性检查的重要性，以确保可靠且公平的AI辅助临床护理。
## 328. `cs.CL` - MMA-ASIA: 一种针对文化基础评估的多语言和多模态对齐框架 [PDF](https://arxiv.org/pdf/2510.08608), [HTML](https://arxiv.org/abs/2510.08608)
### Authors
Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen
### Background
大型语言模型（LLMs）现在被广泛使用，不过它们在超出西方及高资源环境的文化理解和推理能力往往表现不佳。本文提出了一种名为MMA-ASIA的全面框架，旨在评估LLMs的文化意识，特别是基于亚洲背景。MMA-ASIA涵盖了8个亚洲国家和10种语言，包含27,000个问题，其中约79%的问题需要基于文化背景的多步骤推理，超越了简单的记忆。到目前为止，这是首个在输入层面跨三种模态（文本、图像和语音）对齐的数据集，从而可以实现跨模态转移的直接测试。
### Innovation
MMA-ASIA提出了一种多语言和多模态对齐框架，用于评估LLMs在亚洲背景下的文化意识。该框架包括一个由人类编辑、多语言、多模态对齐的多项选择基准测试，覆盖8个亚洲国家和10种语言，共计27,000个问题，79%以上的问题需要基于文化背景的多步推理。此外，该论文还提出了一个五维评估协议，以测量文化意识差距、跨语言一致性、跨模态一致性、文化知识泛化和定位有效性。为了确保严格的评估，还设计了一个文化意识定位验证模块来检测“捷径学习”。最后，通过模型对比分析、注意力跟踪和创新的Vision-ablated Prefix Replay (VPR) 方法，探究模型在不同语言和模态下的差异。
### Conclusion
通过MMA-ASIA框架，该研究不仅能够全面评估LLMs在亚洲文化背景下的表现，还通过跨模态分析揭示了模型在不同语言和模态下的表现差异，并提供了针对构建文化可靠的多模态LLMs的实用见解。
## 329. `cs.CL` - LLMs在变形压力测试下显示表面形式上的脆弱性 [PDF](https://arxiv.org/pdf/2510.08616), [HTML](https://arxiv.org/abs/2510.08616)
### Authors
Juan Miguel Navarro Carranza
### Background
大型语言模型（LLMs）的基准得分可能会因记忆测试项目或近似重复而虚高。已有研究表明，模型可能通过记住特定的问题表述来获得高得分，而不是真正理解问题背后的实质。这项研究聚焦于通过重新评估模型在变形问题上的表现来检测这一问题，变形问题是原始问题的重新表述或类似但略有不同的版本。研究人员使用Mistral-7B-Instruct和Qwen2.5-7B-Instruct两个模型在ARC-Easy和ARC-Challenge两个数据集上进行实验，验证模型是否在变形的问题设置下出现准确率下降的问题。通过这种方式，研究再现了之前关于污染和表面形式捷径（ brittle surface-form shortcuts）的担忧，并初步验证了这些担忧的真实性。
### Innovation
研究引入了一种简单的评估协议，该协议通过对基准测试问题进行重新措辞来重新评估模型的泛化能力。关键的创新亮点包括：1. 控制解码过程，确保输出格式一致的多选题，2. 强化变形问题清洗步骤，以保持语义的一致性。这种方法旨在更真实地测试模型的理解能力和泛化能力，而不仅仅是记忆能力。
### Conclusion
研究结果表明，变形问题能够有效揭示模型在表面形式上的脆弱性，这与之前的担忧相符。模型在变形问题上的准确率显著下降，显示了模型可能依赖于表面形式上的捷径而不是深层的理解。这一结论支持了之前关于大型语言模型易受表面形式捷径影响的观点，并提出了未来的改进方向。
## 330. `cs.CL` - 从模拟到策略：自动化个性化交互规划以增强会话代理的有效性 [PDF](https://arxiv.org/pdf/2510.08621), [HTML](https://arxiv.org/abs/2510.08621)
### Authors
Wen-Yu Chang,Tzu-Hung Huang,Chih-Ho Chen,Yun-Nung Chen
### Background
在代理对话模型迅速发展的背景下，需要进行现实用户的模拟研究以调优有效的对话策略。本研究关注于以销售为导向的代理，该代理根据用户的年龄、性别和职业等个人资料调整对话。虽然年龄和性别在总体性能上有所影响，但职业对于对话意图的影响最为明显。
### Innovation
研究引入了一种基于职业的轻量级策略，指导代理优先考虑与用户偏好一致的意图，从而缩短对话，提高其成功率。研究强调了丰富模拟资料的重要性，并展示了简单的人格启发式策略如何提高销售导向对话系统的有效性。
### Conclusion
研究表明，随着代理对话模型的发展，利用丰富的用户资料并采用简单的人格启发式策略能够有效提升销售导向对话系统的性能。
## 331. `cs.CL` - JAI-1：以泰语为中心的大语言模型 [PDF](https://arxiv.org/pdf/2510.08620), [HTML](https://arxiv.org/abs/2510.08620)
### Authors
Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Pontakorn Trakuekul,Sumana Sumanakul,Natchanon Pollertlam
### Background
近期的泰语模型主要依赖现有的开源模型，通过附加训练而不进行结构修改的方式来专业化泰语。然而，这种方法可能会在注入特定于泰语的信息时侵蚀模型参数空间中的原有知识，因为适用于通用任务的优化参数可能与新的语言需求产生冲突。
### Innovation
JAI-1采用了一种扩增策略：从一个较小的高性能英语开放源代码的大语言模型开始，扩大其参数空间，并利用新增的容量系统地整合泰语语言知识。这种方法不仅保留了原始模型的通用智能，还建立起独特架构，不同于其他开源模型，为未来的增强提供了可扩展性。
### Conclusion
JAI-1在预训练过程中接触到超过1.5万亿个令牌，包括超过300亿个泰语语言令牌。之后进行监督微调和对齐调整，使用超过60万个基于指令的示例。最终模型在泰语专项基准（IFEval-TH、MT-Bench-TH和JAI-Hall-Bench）上表现优于Typhoon2-70B，验证了其扩增和知识整合框架的有效性。
## 332. `cs.CL` - PARSE: LLM驱动的模式优化以实现可靠的实体抽取 [PDF](https://arxiv.org/pdf/2510.08623), [HTML](https://arxiv.org/abs/2510.08623)
### Authors
Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla
### Background
在新兴的软件3.0系统中，LLM代理自主与API和服务交互至关重要。当前的方法直接将大型语言模型应用于抽取任务，尽管使用了约束解码或强化学习方法来确保语法有效性，但JSON模式通常被视为静态合同，用于人类开发者的数据结构规范，这导致了抽取性能不佳、频繁的虚构现象以及代理行为的不可靠性，尤其是在模式包含模糊或不完整规范时。
### Innovation
我们认识到JSON模式本身是一种自然语言理解合同，编码了LLMs应该理解和系统改进的规则、关系和预期。因此，我们开发了PARSE（Parameter Automated Refinement and Schema Extraction），这是一种结合了两个协同组件的新系统：ARCHITECT（自动优化JSON模式并保持向后兼容性通过RELAY集成代码生成系统），以及SCOPE（使用结合静态和LLM基护栏的反映抽取）。通过这种方法，PARSE在三个数据集，包括Schema-Guided Dialogue (SGD)、Structured Web Data Extraction (SWDE)和内部零售对话数据上，以高达64.7%的抽取准确率改进率达到了10%框架改进率，并将第一次重试中的抽取错误降低了92%，同时保持了实用的延迟。
### Conclusion
我们通过PARSE在三个数据集上进行了定性和定量评估，发现其可大幅提升抽取准确率，并通过框架改进提高模型性能，同时显著减少重试中的错误，维持了实际的延迟效率。
## 333. `cs.CL` - Text2Stories：评估生成用户故事与利益相关者访谈之间的对齐情况 [PDF](https://arxiv.org/pdf/2510.08622), [HTML](https://arxiv.org/abs/2510.08622)
### Authors
Francesco Dente,Fabiano Dalpiaz,Paolo Papotti
### Background
大型语言模型（LLMs）可以用于从自然语言输入（如提取访谈的转录）自动生成软件需求。然而，评估生成的需求是否忠实反映了利益相关者的需要目前仍是一个主要依赖手动工作的任务。本文介绍了一种名为Text2Stories的任务和指标，允许量化用户故事（以用户故事的形式）与提取访谈参与者真正表达的需求的一致程度。该方法通过将访谈转录分割成文本块并将其与用户故事实例化为块与故事之间的匹配问题来实现这一点。实验表明，基于LLM的匹配器在保留注释上的宏F1得分为0.86，而仅使用嵌入模型效果不佳但仍可有效阻塞匹配。最终，本文展示了如何使用这些指标来比较不同用户故事集（例如，人工 vs. 生成）的效果，将Text2Stories定位为现有的用户故事质量标准的可扩展且来源忠实补充。
### Innovation
引入了Text2Stories，这是一种用于评估用户故事与利益相关者访谈之间对齐情况的任务和指标。通过将访谈转录分割成文本块并实例化为匹配问题，该方法能够量化用户故事与实际需求的一致程度。此外，基于LLM的方法在评估生成故事的准确性和完整性方面表现出色。
### Conclusion
本文介绍了Text2Stories，并展示了该方法在评估用户故事与利益相关者访谈之间的一致性方面的能力。通过实验验证了基于LLM的匹配器的性能，并将其定位为现有用户故事质量标准的补充。
## 334. `cs.CL` - 从小到大：利用小型语言模型的思维空间推荐 [PDF](https://arxiv.org/pdf/2510.08626), [HTML](https://arxiv.org/abs/2510.08626)
### Authors
Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar
### Background
大型语言模型（LLMs）通过增强的推理能力提高了推荐能力，但其高昂的推理成本限制了实际部署。相比之下，小型语言模型（SLMs）因其高效性成为推荐系统的有力候选方案，但它们的推理能力在推荐中的应用尚未得到充分研究。目前的方法往往将自然语言理由仅作为无监督的描述性文本使用，未能充分利用其作为学习信号的潜力。因此，现有系统通常无法有效利用理由和用户行为之间的内在联系。鉴于此，本研究提出了一种名为Thought Space的框架，利用小型语言模型生成的推理作为直接学习信号，结合用户的交互历史以联合建模用户的行动和其背后的语义驱动因素。这与现有方法只考虑序列和嵌入的方式不同，PULSE引入了更稳健、更具普适性的嵌入表示。通过在多个基准数据集上的广泛实验，证明了PULSE在领先的方法中表现出色，并在跨域推荐和推理导向的问答任务上具有较强性能。
### Innovation
本研究提出的PULSE框架引入了一种新的设计思路，将小型语言模型生成的理由作为主信号，这之前的方法通常仅考虑序列和嵌入。该框架通过结合用户的历史交互信息，能够更全面地理解和建模用户行为的“为什么”，从而生成更加稳健和通用的嵌入表示。这些嵌入表示在多个基准数据集上展现了优越的性能，并且在跨域推荐和推理导向的问答任务中表现出色。
### Conclusion
PULSE在多个基准数据集上显著优于现有的ID（基于身份的推荐）、协同过滤（CF）和基于LLM的序列推荐模型，特别是在跨域推荐和推理导向问题回答任务中表现优异。所提出的方法不仅提高了推荐系统的性能，还更好地理解了用户行为背后的语义驱动因素。相关代码可从作者提供的链接获取。
## 335. `cs.CL` - 通过层次扩散语言模型进行下一语义规模预测 [PDF](https://arxiv.org/pdf/2510.08632), [HTML](https://arxiv.org/abs/2510.08632)
### Authors
Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola
### Background
本文介绍了一个新颖的语言模型家族——层次扩散语言模型（HDLM）。这些模型基于一个分层词汇表，其中低级词汇具有详细的语义，这些词汇以单射方式映射到中级词汇，后者具有粗粒度的意义。在前向过程中，每个词汇根据调度器独立地扰动为更抽象的祖先词汇，而在反向过程中，模型逐步预测更具细节化的语义。总之，HDLM 提供了一个普遍的时间变化的下一语义层次预测过程。
### Innovation
文章提出了 HDLM，这是一种基于分层词汇的语言模型，结合了扩散模型的特性。HDLM 映射低级详细词汇到高级粗粒度词汇，并通过反向过程逐级预测更详细的语义。此外，该模型提供了封闭形式的扩散证据下界（ELBO）表达式，并展示了该模型可以通过灵活的实现方式构建，并将现有的 MDLM 作为特例包含在内。文章还基于洞察提出了实用的训练技术。实验结果表明 HDLM 的效果优于基线模型，验证了其在文本生成中的有效性。
### Conclusion
HDLM 提供了一个通用的随时间变化的下一语义层次预测过程，能够有效地在文本生成任务中释放扩散模型的潜力。实验证明，HDLM 在验证和生成困惑度方面表现出色，证明了其有效性。
## 336. `cs.CL` - 形式化个人叙事中的风格 [PDF](https://arxiv.org/pdf/2510.08649), [HTML](https://arxiv.org/abs/2510.08649)
### Authors
Gustave Cortal(ENS Paris Saclay, LISN),Alain Finkel(ENS Paris Saclay)
### Background
个人叙事是作者为赋予其经验意义而构建的故事。风格是作者用语言表达自身的独特方式，对传达主观体验至关重要。然而，缺乏一个系统分析这些风格化选择的正式框架。
### Innovation
该研究提出了一种新的方法，将个人叙事中的风格形式化为作者在传达主观体验时所作的语言选择模式。该框架整合了三个领域：功能语言学作为语言是有意义选择的系统，计算机科学提供自动提取和分析序列模式的方法，以及这些模式与心理观察之间的联系。通过语言模型，自动提取语料库中的语言特征，如过程、参与者和情境。
### Conclusion
该框架应用于数百个梦的叙述中，特别是在一位患有创伤后应激障碍的战争退伍军人的案例研究中。对他的叙述分析揭示了独特的模式，尤其是在口头过程如何主导心理过程方面的表现，说明语言选择与心理状态之间的关系。
## 337. `cs.CL` - ExPO-HM: 学习进行解释-然后检测以检测恶意贴纸 [PDF](https://arxiv.org/pdf/2510.08630), [HTML](https://arxiv.org/abs/2510.08630)
### Authors
Jingbiao Mei,Mingsheng Sun,Jinghong Chen,Pengda Qin,Yuhong Li,Da Chen,Bill Byrne
### Background
恶意贴纸已成为在线骚扰的一种特别具有挑战性的形式，促使开发自动化检测系统。大多数先前的方法依赖于直接检测，仅产生二元预测。这种模型无法提供实际管理所需的上下文和解释。最近的解释-然后检测方法（如基于链推理提示或LMM代理），其性能甚至不如简单的即插即用模型，即使是先进的后训练方法如GRPO也未能改善这一差距。我们的分析确定了这些系统中的两个关键问题：模型未能假定政策相关的关键线索作为可能的解释；并且二元奖励信号不足以引导推理。为了应对这些挑战，我们提出了ExPO-HM（解释-然后检测策略优化），灵感来源于人类注释者的培训和评估过程。ExPO-HM 结合了SFT 热身、基于课程学习的GRPO、以及条件决策熵（CDE）作为推理质量的评估指标和奖励。
### Innovation
ExPO-HM 是借鉴人类注释者培训和评估过程的一种方法，结合SFT 热身、基于课程学习的GRPO、以及条件决策熵（CDE），作为评估和奖励推理质量的双重指标。它在三个恶氦贴纸基准测试中取得了最先进的性能，在二元检测、细粒度分类和推理质量上分别提高了15%和17%的F1得分，超过了GRPO和DPO基准。通过将恶意贴纸检测从简单的二元警报转变为解释驱动的检测，ExPO-HM 提供了准确、可解释和可操作的监管支持。
### Conclusion
ExPO-HM 通过解释-然后检测策略优化，实现了恶意贴纸检测的先进性能，并提供了准确、可解释和可操作的监管支持，解决了现有技术在上下文理解和解释方面的问题。
## 338. `cs.CL` - Do LLMs Know They Are Being Tested? Evaluation Awareness and Incentive-Sensitive Failures in GPT-OSS-20B [PDF](https://arxiv.org/pdf/2510.08624), [HTML](https://arxiv.org/abs/2510.08624)
### Authors
Nisar Ahmed,Muhammad Imran Zaman,Gulshan Saleem,Ali Hassan
### Background
大语言模型（LLMs）的表现通常依赖于带有评估导向提示的基准测试，这些提示要求可见推理和严格的格式化。然而，实际部署则需要更简洁、合同约束的答案。该研究探讨了这种“评估味”是否会在没有相应能力提升的情况下虚增表现测量结果。通过对单一开放权重模型（GPT-OSS-20B）进行六组配对A/B测试，研究了评价导向与现实世界导向、不同推理深度（中等/高等）的题目内容如何影响模型的回答，覆盖了从确定性数学题、严格的代码修正、引证生成、激励翻转（谨慎 vs. 能力）、逐步推理可见性和多语言（乌尔都语）标题等多方面情景，以确定评估框架是否会导致模型产生更长但不一定更精确的回答，同时增加了输出的格式化和复杂性，且激励措辞会以不同方式重新平衡错误的构成。该研究还考察了多语言提示对模型表现的影响，并提供了可复现的A/B测试框架和实用指导，如中立语气或双重评估框架检查、合同意识评估、风格变化报告、信心治理和多语言仪表板等，以确保基准测试的结果反映了可部署的能力。
### Innovation
研究设计了一种可复现的A/B测试框架，包括提示库、验证器、每次运行的分数和脚本，并提供了一种实用指导方案。通过这种框架和指导，可以确保基准测试的结果能够反映模型的实际部署能力。此外，研究还发现，模型在面对评估导向的提示时，倾向于生成更详细但不一定更准确的答案，这可能会影响其实际应用的表现。
### Conclusion
在六组A/B测试中，评估框架导致了更长的逐步推理输出，降低了简洁回答的合规性，并且以有限或不一致的准确性获得提高。结构化输出在封装中有所改进，但在正则验证的内容方面没有显著改善。激励措辞会重新平衡错误的构成，但不同措辞会影响准确性。乌尔都语提示再现了这些模式，表明可能存在多语言一致性风险。该研究提供了可以复现的分析框架和实用指南，以确保基准测试的结果能够真实反映模型的实际部署能力。
## 339. `cs.CL` - Upfront Chain-of-Thought:一种协作框架进行Chain-of-Thought压缩 [PDF](https://arxiv.org/pdf/2510.08647), [HTML](https://arxiv.org/abs/2510.08647)
### Authors
Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen
### Background
近期发展使大型语言模型（LLMs）能够通过长链推理（CoT）进行复杂的推理，但这种长链推理由于生成LLMs的自回归特性，导致了高的计算成本和显著的延迟损失。CoT压缩旨在通过减少输出长度来提高推理过程的效率。虽然一些先前的工作通过劳动密集的离散提示设计或构建外部压缩CoT数据集进行了CoT压缩，但这些方法要么牺牲推理细节，要么降低了推理效率。
### Innovation
本文提出了一种名为Upfront CoT（UCoT）的高效推理框架，它通过一种前瞻的思维嵌入来自动化CoT压缩。UCoT包括一个小型模型（压缩器）和一个大型模型（执行器），其中第一阶段训练压缩器产生包含丰富推理信息的前瞻思考嵌入，以避免手工设计提示的缺点；第二阶段优化执行器使用前瞻思考嵌入以获取短推理来得出正确答案，利用奖励机制。实验结果表明UCoT在大幅度减少CoT长度的同时保持了执行器的强大推理能力。例如，应用于Qwen2.5-7B-Instruct模型时，UCoT在GSM8K数据集上的token使用量减少了50%，而性能比最先进的方法高3.08%。
### Conclusion
UCoT框架既保持了强大的推理能力，又减少了CoT的长度。实验结果展示了UCoT在不同模型上的广泛应用和优越性能，表明这是一种有效的CoT压缩方法。
## 340. `cs.CL` - dInfer：用于扩散语言模型的有效推理框架 [PDF](https://arxiv.org/pdf/2510.08666), [HTML](https://arxiv.org/abs/2510.08666)
### Authors
Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng
### Background
基于扩散的大语言模型(dLLMs)作为一种有前途的选择，提供了自回归(AR)模型的内在并行性，但由于缺乏标准化和高效的推理框架，它们的广泛应用受到限制。这些开放源代码的dLLM模型尽管越来越多，但受到推广的障碍仍然存在。因此，需要一个既能提高效率又不会牺牲输出质量的推理框架。
### Innovation
论文提出了dInfer框架，这是一个高效且可扩展的dLLM推理框架。dInfer将推理流程分解为四个模块化的组件：模型、扩散迭代管理器、解码策略以及KV缓存管理器，并在每个组件中集成新的算法以及系统级优化。通过这种算法创新和系统增强的结合，dInfer在LLaDA-MoE上实现了显著的效率提升，而不会牺牲输出质量。与其他系统相比，dInfer在相同的硬件环境下对Fast-dLLM的速度提升了近10倍，同时在保持类似模型性能的情况下，对QWen2.5-3B也有2-3倍的速度提升。
### Conclusion
dInfer框架通过模块化设计和系统优化，有效提高了dLLM推理的效率，使得以前的模型在相同硬件资源下处理任务的速度有了显著提升，同时也展示了与自回归模型相比的竞争力。其开源实现为社区提供了可访问的技术支持。
## 341. `cs.CL` - 使用LLM评分文本数据增强评分量表测试的新型框架 [PDF](https://arxiv.org/pdf/2510.08663), [HTML](https://arxiv.org/abs/2510.08663)
### Authors
Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell
### Background
心理评估通常依赖于结构化评分标尺，但无法捕捉受访者自然语言中的丰富细微差别。本研究利用最近的语言模型（LLM）的进步，结合新型概念框架中的定性数据，将LLM评分文本与传统的等级量表项目结合起来，创建了增强测试方法。使用抑郁症作为案例研究，该方法在实际样本（693名中学生）和相对应的合成数据集（3,000个样本）上进行了开发和评估。在保留的测试集上，增强测试显著提高了测量精度和准确性。来自LLM项目的信息增益相当于在原始19项测试中添加了6.3至16.0个项目。
### Innovation
本研究提出了一个创新性的框架，将LLM评分的文本数据与传统的等级量表相结合，创建增强测试，并在实际和合成数据集上进行了验证，展示了增量测试的显著提升。该方法通过基于项目信息计算的经验选择最有信息量的LLM评分指导语，相比传统的预标注数据或复杂的专家创建评价标准，更加高效。这一框架为利用不断增长的语音记录文本资料增强传统心理测量指标提供了可扩展方法，并讨论了其在临床健康以及更广泛的领域中的潜在应用价值。
### Conclusion
本研究展示了一种自动化评分的新方向，即采用经验选择最有信息量的LLM评分指导语，而非依赖于预标注数据或复杂专家创建的评价标准，从而绕过了传统自动化评分的瓶颈。这一框架为利用越来越多的转录文本资料提高传统心理测量的准确性提供了可扩展的方法，并讨论了其在临床健康等领域的潜在应用价值。
## 342. `cs.CL` - 代码的缩放定律：更加数据饥渴的范式 [PDF](https://arxiv.org/pdf/2510.08702), [HTML](https://arxiv.org/abs/2510.08702)
### Authors
Xianzhen Luo,Wenzhen Zheng,Qingfu Zhu,Rongyi Zhang,Houyi Li,Siming Huang,YuanTao Fan,Wanxiang Che
### Background
大型语言模型（LLMs）正在革新软件工程，然而，指导高效训练的缩放定律主要是在自然语言（NL）上进行分析。由于代码和自然语言在严格的语法上存在根本差异，这些定律直接应用于代码的有效性尚不清楚。因此，有必要研究代码的缩放定律。
### Innovation
本文进行了首个大规模实证研究，涵盖从0.2B到3.8B的模型大小和从2B到128B的训练令牌，应用Chinchilla定律和Farseer定律进行拟合。研究结果显示，更具表现力的Farseer定律提供了更高的准确性。此外，分析发现代码在模型规模上表现出良好的扩展性，但与自然语言相比，需要更高的数据与参数比例。
### Conclusion
代码在数据消耗方面更“饥饿”，需要远高于自然语言的数据与参数比例。另外，代码和自然语言混合的额外实验表明，在资源受限的情境下自然语言是有益的，但在高性能计算预算下则会成为一种负担。
## 343. `cs.CL` - 思考更长，并不一定更聪明：评估大规模语言模型在层级法律推理中的能力 [PDF](https://arxiv.org/pdf/2510.08710), [HTML](https://arxiv.org/abs/2510.08710)
### Authors
Li Zhang,Matthias Grabmair,Morgan Gray,Kevin Ashley
### Background
案例推理是美国法律实践的基础，要求专业人士通过将当前案例与过去的先例进行类比和区分来论证。大型语言模型（LLMs）展现了卓越的能力，但在这种复杂、微妙的推理形式中，它们的表现仍需进一步研究。
### Innovation
本文提出了一种正式框架，将识别案例之间重要差异的过程分解为三个阶段的推理任务。该框架使用称为因素的事实谓词来表示案例、组织成法律知识层级结构，并定义验证规则来识别差异、分析其论据支持和评估其重要性。通过对现代推理LLM的全面评估，揭示了一个悖论：模型在表面推理（任务1）上达到了高准确率，但在层级推理（任务2：64.82%-92.09%）和综合分析（任务3：11.46%-33.99%）上的表现下降。最引人注目的是，我们发现模型在错误响应上消耗了更多的计算资源，这表明“思考更长时间并不总是意味着思考得更聪明”。
### Conclusion
本文提供了一种细粒度分析LLM在复杂领域的推理能力的方法，并揭示了必须解决的基础性限制，以实现坚固和可信赖的法律人工智能。
## 344. `cs.CL` - 语言模型微基准测试的可靠性程度如何？ [PDF](https://arxiv.org/pdf/2510.08730), [HTML](https://arxiv.org/abs/2510.08730)
### Authors
Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta
### Background
语言模型开发往往需要大量时间和成本，因此使用微基准测试评估模型成为一种可能的解决方案。然而，微基准测试能否像原始基准测试那样一致地排名模型？或者它们能否比随机选择数据点的方式更一致地排名模型？该研究发现，在许多情况下，答案是否定的。
### Innovation
该研究引入了一种元评估度量方法，用于研究微基准测试如何根据模型在完整基准测试上的表现差异来正确排名模型对。这种方法能够确定哪些模型对可以通过微基准测试正确排名，从而细化分析微基准测试大小与其可靠性之间的权衡。
### Conclusion
研究表明，要一致地排名模型对，微基准测试通常需要选择至少250个示例。当仅比较8B指令调优模型时，只有大约一半的成对比较可能会被保留。该研究提供了针对微基准测试用户和开发者在评估效率和可靠性之间的权衡方面的可操作指导。
## 345. `cs.CL` - 如何从二元矩阵视角评估生成测试用例所需代码和测试用例的数量？ [PDF](https://arxiv.org/pdf/2510.08720), [HTML](https://arxiv.org/abs/2510.08720)
### Authors
Xianzhen Luo,Jinyang Huang,Wenzhen Zheng,Qingfu Zhu,Mingzheng Xu,Yiheng Xu,Yuantao Fan,Libo Qin,Wanxiang Che
### Background
自动评估由大型语言模型生成的测试用例是一项关键但极具挑战性的任务。现有基准存在高计算成本、评分膨胀以及偏向于简单错误而非罕见的关键故障的偏见。本研究旨在回答两个基本问题：1. 能代表整个错误空间的最小错误代码集合是什么？2. 用于区分这些代码所需的最小测试用例集是什么？
### Innovation
作者提出了一种框架，将基准构建问题形式化为在二进制代码-测试矩阵中寻找最优诊断基。通过该框架，他们设计了WrongSelect算法来高效地选择最大多样性的错误代码。利用该框架，他们构建了TC-Bench基准，这是一个紧凑的、多样化的且抗膨胀的基准。实验证明，最先进的测试用例生成方法在TC-Bench上能达到的排除率仅为约60%，揭示了它们诊断能力的显著差距。
### Conclusion
作者通过构建一个名为TC-Bench的新基准，证明了现有的测试用例生成方法的局限性，并提出了一个新的框架和算法来改善测试用例评估。
## 346. `cs.CL` - 使用LLMs解析复杂地点参考的坐标 [PDF](https://arxiv.org/pdf/2510.08741), [HTML](https://arxiv.org/abs/2510.08741)
### Authors
Tessa Masis,Brendan O'Connor
### Background
地理编码是将地理位置参考链接到实际地理位置的任务，对于许多未结构化文本的下游分析至关重要。本文探索将组成性地点参考进行地理编码的挑战性设置。基于最近的研究，表明了大语言模型（LLM）在处理地理空间数据方面的推理能力，本文评估了LLM在地理空间知识和与任务相关的推理技能之间的差异。基于这些见解，本文提出了一种基于LLM的策略来解析组成性地点参考。研究表明，该方法可以提高任务性能，并且相对较小的微调LLM可以在与更大规模现成模型相当的性能上实现良好的表现。
### Innovation
本文创新地评估了大语言模型在解析复杂地点参考方面的地理空间知识和推理能力，进一步提出了基于LLM的策略，来解决组成性地点参考的地理编码问题，并展示了微调后的LLM在性能上的改进和相对于更大规模模型的优越性。
### Conclusion
本文提出的方法在解析组成性地点参考方面表现良好，相对较小的微调LLM可以达到接近现成大型模型的性能水平，这表明LLM在地理位置推理方面的能力值得进一步研究和利用。
## 347. `cs.CL` - 测量多语言能力下的道德LLM响应 [PDF](https://arxiv.org/pdf/2510.08776), [HTML](https://arxiv.org/abs/2510.08776)
### Authors
Kimaya Basu,Savi Kolari,Allison Yu
### Background
随着大规模语言模型（LLM）的使用在全球范围内扩展，多语言环境下的理解和规制其响应变得尤为重要。为此，研究人员构建了大规模数据集以测试和评估不同语言环境中LLM的表现。这项研究评估了前沿开源模型在五大维度上的响应，涵盖低资源语言和高资源语言，以衡量LLM在多语言环境中的准确性和一致性。
### Innovation
本研究创新之处在于使用五点打分评价体系和人工评审员来评估领先和前沿的开源模型在多语言环境下的响应。研究特别强调了GPT-5在伦理与自主性以及危害预防与安全两类评估中的卓越表现，同时指出其他模型在不同语言和类别中的不一致性。
### Conclusion
研究发现表明，GPT-5在所有评估类别中表现出色；然而，其他模型在不同语言和类别间的响应更加不一致。特别是，在伦理与自主性和危害预防与安全类别的评估中，GPT的平均分分别为3.56和4.73，而Gemini 2.5 Pro的平均分分别为1.39和1.98。这些结果强调了在不同类别中进一步测试语言变化对LLM响应的影响，并在这些领域进行改进的必要性。
## 348. `cs.CL` - 学习记忆什么：高效语言模型的自适应概率记忆保留 [PDF](https://arxiv.org/pdf/2510.08798), [HTML](https://arxiv.org/abs/2510.08798)
### Authors
S M Rafiuddin,Muntaha Nujat Khan
### Background
Transformer的注意力机制随序列长度呈二次增长(O(n^2))，限制了长上下文的使用。
### Innovation
提出了自适应保留机制，这是一种分层的、基于概率的token选择机制，能够在全局预算M的限制下学习保留哪些表示。利用Bernoulli门和Hard-Concrete/变分松弛进行训练，并通过简单的top-M规则在推理时进行实现，使得方法具有可微性和向标准编码器直接替换的能力。该方法在分类、抽取式问答和长文档摘要任务中，保留30-50%的token，可保持至少95%的全模型性能，同时减少峰值内存约35-45%，并且吞吐量最多可提高1.8倍。这种架构无关的方法可以在不修改基本注意力机制或任务头部的情况下，提供实际的长上下文效率增强。
### Conclusion
该自适应概率记忆保留机制允诺在不修改基础注意机制或任务头部的情况下，在保持高性能的同时提高语言模型的内存效率和吞吐量，具有广泛的应用前景。
## 349. `cs.CL` - MOSAIC：任务智能的科学编码多智能体协调 [PDF](https://arxiv.org/pdf/2510.08804), [HTML](https://arxiv.org/abs/2510.08804)
### Authors
Siddeshwar Raghavan,Tanwi Mallick
### Background
在科学编码任务中，算法需要具有严谨性，与深厚的领域知识相连，并且需要在不依赖输入输出测试案例的前提下进行领域特定推理和算法迭代。许多科学问题需要解决一系列子问题，最终得到所需的结果。
### Innovation
MOSAIC 是一个无需训练的多智能代理框架，设计用于解决科学编码任务。它包含特殊设计的代理，能够在师生模式下自我反思、规划论证、编码和调试。该框架能够逐步分解问题，针对错误进行修正，并通过合并 Consolidated Context Window（CCW）机制，减少大型语言模型在解决链式子问题时的幻觉。
### Conclusion
在科学编码基准测试中，MOSAIC 以其在准确度、健壮性和可解释性方面的表现，超越了现有方法。
## 350. `cs.CL` - 具有多跳推理视角的汉语常识推理基准测试 [PDF](https://arxiv.org/pdf/2510.08800), [HTML](https://arxiv.org/abs/2510.08800)
### Authors
Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang
### Background
虽然大型语言模型（LLMs）已经展示了先进的推理能力，但在一般中文语言环境中的全面评估仍然较少研究。为了缩小这一差距，我们提出了汉语常识多跳推理（CCMOR），这是一种新的基准，旨在评估LLMs整合特定于中文的事实知识和多步逻辑推理的能力。我们首先从现有的问答数据集中构建了一个领域平衡的种子集，然后开发了一个基于LLM的流水线来生成基于事实单元链的多跳问题。为了保证数据集的质量，我们实施了一个人工干预的验证系统，由领域专家系统地验证和完善生成的问题。使用CCMOR，我们评估了最先进的LLMs，显示出LLMs在处理长尾知识和执行知识密集型推理方面存在持续的局限性。值得注意的是，检索增强的生成显著缓解了这些知识差距，带来了显著的性能提升。
### Innovation
提出了汉语常识多跳推理（CCMOR），这是一种新的基准，旨在评估LLMs整合特定于中文的事实知识和多步逻辑推理的能力。开发了一个基于LLM的流水线来生成基于事实单元链的多跳问题，并实施了一个人工干预的验证系统，由领域专家系统地验证和完善生成的问题。
### Conclusion
使用CCMOR，我们评估了最先进的LLMs，显示了LLMs在处理长尾知识和执行知识密集型推理方面存在持续的局限性。值得注意的是，检索增强的生成显著缓解了这些知识差距，带来了显著的性能提升。
## 351. `cs.CL` - 模型的语言很重要：大语言模型隐私泄露的比较分析 [PDF](https://arxiv.org/pdf/2510.08813), [HTML](https://arxiv.org/abs/2510.08813)
### Authors
Abhishek K. Mishra,Antoine Boutet,Lucas Magnana
### Background
大语言模型（LLMs）在处理敏感数据的跨语言应用中越来越普遍，但它们的规模和语言多样性带来了重大的隐私风险。尽管LLMs主要在英语上进行评估，这篇论文研究了语言结构如何影响在英语、西班牙语、法语和意大利语医学语料库上训练的LLM的隐私泄露。
### Innovation
量化了六种语言指标，并评估了提取、反事实记忆和成员归属三种攻击向量。研究结果表明，隐私漏洞与语言冗余性和标记粒度成正比：意大利语表现出最强的泄露，而英语具有更高的成员归属可分性。相比之下，法语和西班牙语由于更高的形态复杂性表现出更强的韧性。这项研究提供了语言在隐私泄露中起作用的第一个定量证据。
### Conclusion
总体而言，我们的发现强调了在LLM部署中需要考虑语言差异的隐私保护机制的重要性。
## 352. `cs.CL` - Search-on-Graph：基于图的迭代启发式导航以增强大型语言模型在知识图谱中的推理能力 [PDF](https://arxiv.org/pdf/2510.08825), [HTML](https://arxiv.org/abs/2510.08825)
### Authors
Jia Ao Sun,Hao Yu,Fabrizio Gotti,Fengran Mo,Yihong Wu,Yuchen Hui,Jian-Yun Nie
### Background
大型语言模型（LLMs）展示了令人印象深刻的推理能力，但在处理需要大量知识和多跳推理的问题时仍然不可靠——它们往往遗漏了长尾事实、当不确定时会产生虚像，并且其内部知识落后于真实世界的变更。现有的知识图谱问答（KGQA）方法面临着根本性的权衡：在不了解可用关系的情况下构建完整的SPARQL查询证明是有弱点的；检索大型子图则引入了噪声；复杂的多智能体框架在并行探索时，指数地扩展了搜索空间。这些问题限制了LLMs在KG上的有效利用。
### Innovation
提出了一个简单的但非常有效的框架——Search-on-Graph (SoG)，允许LLMs利用单个精心设计的Search函数进行迭代启发式的图导航。SoG遵循“观察后导航”的原则：在每一步中，LLM会分析当前实体的实际可用关系，然后决定下一步的跳跃。这种方法还能够无缝适应不同的KG模式，通过自适应过滤处理高度节点。
### Conclusion
在涵盖Freebase和Wikidata的六个KGQA基准测试中，SoG未经过微调即可达到最先进的性能。特别是在Wikidata基准测试中显示出特别大的提升（相比于之前最佳方法提高了16%），同时在Freebase基准测试中也实现了持续性的改善。
## 353. `cs.CL` - 在RLVR中探索多温度策略的令牌级和卷积级控制 [PDF](https://arxiv.org/pdf/2510.08892), [HTML](https://arxiv.org/abs/2510.08892)
### Authors
Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang
### Background
强化学习在大型语言模型（LLMs）的推理能力方面取得了显著进步，显示出在多个领域的广泛应用。最近的研究发现，LLMs中的令牌在推理任务中扮演着不同的角色，可以被分类为高熵推理令牌和低熵知识令牌。早期的方法大多侧重于间接地通过限制更新来促进探索行为，但并未在令牌生成阶段明确促进探索性行为。
### Innovation
本文提出了一种互补方法，在采样时明确推动探索。具体来说，使用较高的温度设置促进推理令牌的探索行为，而使用较低的温度设置维持知识令牌的事实正确性。此外，系统研究了各种多温度调度策略及其在强化学习环境中的影响。
### Conclusion
在几个推理基准测试上的实证评估表明，本文的方法显著提升了LLMs的推理性能。
## 354. `cs.CL` - 结构增强的多轮监狱闯关攻击：利用大型语言模型的结构性漏洞 [PDF](https://arxiv.org/pdf/2510.08859), [HTML](https://arxiv.org/abs/2510.08859)
### Authors
Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma
### Background
大型语言模型（LLMs）仍然容易受到利用对话上下文逐步绕过安全限制的多轮监狱闯关攻击。这些攻击通过不同的对话方法（如教育讨论、个人经历、假设场景），针对不同的危害类别（如恶意软件生成、骚扰或欺诈）发起攻击。现有的多轮监狱闯关方法通常依赖于启发式或临时探索策略，对于模型潜在弱点的洞察有限。跨危害类别的对话模式与模型脆弱性的关系仍不清楚。
### Innovation
我们提出了一种框架，称为Pattern Enhanced Chain of Attack (PE-CoA)，它包含了五个对话模式，用于通过自然对话构建有效的多轮监狱闯关。通过在十二个LLM（涵盖十个危害类别）上评估PE-CoA，我们取得了最先进的性能，发现了特定模式的脆弱性和LLM的行为特征：模型在针对某一对话模式的鲁棒性不适用于其他模式，并且模型家族共享相似的故障模式。这些发现揭示了安全培训的局限性，并指出了需要模式感知防御的必要性。
### Conclusion
我们的研究结果表明，需要对特定模式的防御进行针对性的策略制定，而不是依靠广泛的安全训练。这些发现强调了大型语言模型在处理对话模式时的脆弱性，并指出了需要改进的方向。
## 355. `cs.CL` - 文档级翻译中的质量估计重排序 [PDF](https://arxiv.org/pdf/2510.08870), [HTML](https://arxiv.org/abs/2510.08870)
### Authors
Krzysztof Mrozinski,Minji Kang,Ahmed Khota,Vincent Michael Sutanto,Giovanni Gatti De Giacomo
### Background
质量估计（QE）重排序是一种质量意识解码形式，旨在通过评分和从生成的多个翻译中选择最佳候选者来提高机器翻译（MT）输出。尽管在句子级别已被证明是有效的，但将其应用于日益重要的文档级别翻译领域仍未受到足够的探索。本文研究了在文档级别（而不是传统的句子级别）翻译中使用各种机器学习和大型语言模型（LLM）为基础的质量估计度量评估QE重排序的效果。研究表明，通过使用我们最好的机器学习度量SLIDE或LLM度量GEMBA-DA，相比于传统的句子级别，文档级别的QE度量能够显著改善翻译质量。并且，随着候选翻译数量的增加，这种效果更加明显。尽管长输入会减小这一增幅，但在长文档中使用32个候选 still shows 显著改进。这项研究揭示了文档级别的QE重排序在实际中的价值，同时将最小的运行时开销提供给人合适的翻译模型和硬件。
### Innovation
该研究首次大规模探讨了在文档级别（而非句子级别）的机器翻译中使用重排序策略的有效性，通过利用机器学习和大型语言模型为基础的质量估计度量，成功地实现了比传统方法更好的翻译质量提升。利用最佳的SLIDE和GEMBA-DA质量估计方法，实现了显著的翻译质量提高。在长文档的情况下，改进仍然显著。
### Conclusion
这些发现证明了文档级别QE的有效性和实用性，在适当的硬件和翻译模型条件下，使用少量的额外计算资源可以实现显著的翻译质量提升。
## 356. `cs.CL` - 基于大规模语言模型的统一生物医学命名实体识别框架 [PDF](https://arxiv.org/pdf/2510.08902), [HTML](https://arxiv.org/abs/2510.08902)
### Authors
Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin
### Background
准确识别生物医学命名实体对医学信息提取和知识发现至关重要，但现有方法通常在嵌套实体、实体边界模糊以及跨语言泛化方面表现不佳。
### Innovation
提出了一种基于大型语言模型（LLMs）的统一生物医学命名实体识别（BioNER）框架，将BioNER重新定义为文本生成任务，设计了符号标记策略以同时处理扁和平级嵌套实体，并引入了基于对比学习的实体筛选器，通过边界敏感的正负样本过滤错误或虚假预测。
### Conclusion
在四个基准数据集和两个未见过的语料库上进行的实验结果显示，该方法达到最先进的性能，并且在语言上的零样本泛化表现稳健。源代码可以免费获取。
## 357. `cs.CL` - 利用上下文语义锚点进行LLM的无自编码上下文压缩 [PDF](https://arxiv.org/pdf/2510.08907), [HTML](https://arxiv.org/abs/2510.08907)
### Authors
Xin Liu,RunSong Zhao,PengCheng Huang,XinYu Liu,JunYi Xiao,ChunYang Xiao,Tong Xiao,Shengxiang Gao,Zhengtao Yu,JingBo Zhu
### Background
当前上下文压缩方法主要依赖于自编码任务来训练上下文无关的压缩标记，以压缩上下文语义。然而，这种自编码任务导致了与实际下游任务之间的重要不匹配，即优化重构建导致了有益于实际应用的特征减弱。
### Innovation
提出了语义锚点压缩（SAC）方法，它不依赖自编码任务，而是预先设计具备压缩能力的架构，直接从原始上下文选择所谓的锚标记，并将上下文信息聚合到其键值表示中。SAC通过直接从上下文标记获取表示消除了自编码训练的需要，并通过锚嵌入和双向注意力修改设计确保了压缩性能。
### Conclusion
实验结果表明，SAC在不同压缩比率下的性能都优于现有的上下文压缩方法，在MRQA上的表现更加突出，尤其是在较高压缩比率下取得了显著的性能提升。
## 358. `cs.CL` - FinAuditing: 一种基于金融分类结构的多文档基准，用于评估LLM [PDF](https://arxiv.org/pdf/2510.08886), [HTML](https://arxiv.org/abs/2510.08886)
### Authors
Yan Wang,Keyi Wang,Shanshan Yang,Jaisal Patel,Jeff Zhao,Fengran Mo,Xueqing Peng,Lingfei Qian,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Jian-Yun Nie
### Background
普遍接受的会计原则（GAAP）的复杂性和XBRL财务报告的层次结构使得自动化和验证财务审计变得越来越困难。虽然大型语言模型（LLMs）展示了在非结构化文本理解方面的强大能力，但它们在处理结构化、相互依赖和基于分类的财务文件方面的推理能力尚未得到充分探索。因此，本文介绍了FinAuditing，这是第一个基于分类结构、多文档的基准，用于评估LLMs在财务审计任务上的表现。从真实的符合美国GAAP的XBRL报告中构建而成，FinAuditing定义了三个互补的子任务：FinSM（语义一致性）、FinRE（关系一致性）和FinMR（数值一致性），每个子任务都针对结构化审计推理的特定方面。此外，还提出了一种统一的评估框架，该框架整合了这些子任务上的检索、分类和推理指标。
### Innovation
首次开发了FinAuditing，一个基于财务分类结构的多文档基准，用于评估LLMs在财务审计任务上的表现。该基准定义了三个互补的子任务：FinSM（语义一致性）、FinRE（关系一致性）和FinMR（数值一致性），并提出了一种统一的评估框架，该框架整合了这些子任务上的检索、分类和推理指标。实验表明，当前模型在语义、关系和数学维度上表现出不一致的表现，准确性在进行层次多文档结构推理时可能下降60-90%。该研究揭示了现代LLMs在基于分类的财务推理方面的系统限制，并通过FinAuditing为开发可信赖、结构意识和法规对齐的财务智能系统奠定了基础。
### Conclusion
FinAuditing为评估LLMs在财务审计任务上的表现提供了新的基准，揭示了现代LLMs的限制，并确立了其作为开发结构对齐和法规对齐的财务智能系统的基础。该基准数据集可在Hugging Face获取。
## 359. `cs.CL` - 人工印象：通过特质印象视角评估大型语言模型行为 [PDF](https://arxiv.org/pdf/2510.08915), [HTML](https://arxiv.org/abs/2510.08915)
### Authors
Nicholas Deas,Kathleen McKeown
### Background
本文介绍了人工印象的概念，这是大型语言模型（LLMs）对提示的内部表示中体现的人类印象和基于语言的刻板印象的图案。研究发现，当在提示下被要求时，LLMs 以不一致的方式报告印象。然而，这些印象可以从模型的隐藏表示中更一致地线性解码。还发现人工印象可以预测模型响应的质量和使用含糊语言的程度。此外，研究还探讨了提示中的特定内容、风格和方言特征如何影响LLMs的印象。
### Innovation
本文创新性地提出了一个‘人工印象’的概念，通过模型隐藏表示线性解码出的人类印象来评估大型语言模型的行为。这种方法有助于深入理解模型对人类印象和刻板印象的表示以及如何影响其生成的文本。此外，本文还提供了一个框架来探索特定内容、风格和方言特征如何影响模型的印象。
### Conclusion
本文发现，尽管大型语言模型在被提示时报告印象是不一致的，但这些印象在模型的隐藏表示中可以更一致地解码。研究还表明，人工印象可以预测模型的响应质量及使用含糊语言的程度。提示中的特定内容、风格和方言特征会对LLMs的印象产生影响。该研究为评估大型语言模型的行为提供了一个新的视角。
## 360. `cs.CL` - 软件项目中集体治理的人类行为基准 [PDF](https://arxiv.org/pdf/2510.08956), [HTML](https://arxiv.org/abs/2510.08956)
### Authors
Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey
### Background
该研究关注的是开源社区如何通过版本控制的治理文档来描述参与和控制的情况。通过对710个项目的文本进行解析，研究团队识别出参与者、规则、行动和对象，并测量了它们的变化，包括均匀度、丰富度和Jensen Shannon散度。研究发现，随着项目的发展，角色和行动的数量增加，并且分配得更加均匀，但规则的组成保持稳定。这些发现表明，治理的增长是通过扩展和平衡参与者的类别来实现的，而没有重大改变赋权方式。这项分析提供了评估未来由AI中介的工作流程是集中还是重新分配权力的可再现基准。
### Innovation
研究使用文本解析方法和度量标准（如熵、丰富度和Jensen Shannon散度），评估模型变化和趋势，在开源社区治理方面提供了一个可量化和可重现的视角。这项研究为未来AI中介的工作流程提供了基准，以评估是否集中在特定权力或分散到更多的参与者中。
### Conclusion
研究发现，软件项目中的治理通过扩展和平衡参与者的类别来增长，而赋权方式保持稳定。这种研究方法为评估和改进软件项目中的集体治理模式提供了新的工具。
## 361. `cs.CL` - SOP-Maze: 评估大型语言模型在复杂商业标准操作程序中的表现 [PDF](https://arxiv.org/pdf/2510.08942), [HTML](https://arxiv.org/abs/2510.08942)
### Authors
Jiaming Wang,Zhe Tang,Yilin Jin,Peng Ding,Xiaoyu Li,Xuezhi Cao
### Background
随着大型语言模型（LLMs）在特定领域中的广泛应用，已经提出了许多基准来评估它们在现实场景中的指令遵循和决策能力。然而，商业场景通常涉及复杂的标准操作程序（SOPs），而模型在这些情境下的能力评估尚未得到充分探讨。
### Innovation
本文提出了一项名为SOP-Maze的新基准，它基于实际业务数据构建，并适应成为包含23个复杂SOP场景的397个任务的集合。团队还进一步将SOP任务分为两大类：侧根系统（LRS）代表广泛的选项任务，需要精确的选择；心根系统（HRS）突出了复杂的分支中的深层逻辑推理。详尽的实验揭示了几乎所有最先进模型在SOP-Maze上都表现不佳，并且通过全面的分析确定了三种关键的错误类别：（i）路径盲点：难以遵循程序；（ii）对话脆弱性：无法处理现实对话的细微差别；（iii）计算错误：在复杂背景下时间或算术推理上的错误。
### Conclusion
本研究系统地探讨了SOP任务对LLM的挑战，这些任务挑战了广度和深度，为改进模型能力提供了新的见解。我们的工作已经开源，可访问此链接：this https URL.
## 362. `cs.CL` - 创建中文适应性政策沟通语料库 [PDF](https://arxiv.org/pdf/2510.08986), [HTML](https://arxiv.org/abs/2510.08986)
### Authors
Bolun Sun,Charles Chang,Yuen Yuen Ang,Pingxu Hao,Ruotong Mu,Yuchen Xu,Zhengxin Zhang
### Background
作者介绍了一个名为CAPC-CG的中文适配性政策沟通语料库，这是首个带有五色分类学标记的清晰和模糊语言类别的公开数据集，基于Ang的适应性政策沟通理论。该语料库记录了1949年至2023年间由中国顶级权威机构发布的法律法规和部门规章，为政策沟通领域提供了丰富的资源和研究基础。
### Innovation
该语料库的独特之处在于它使用五色分类法标注了清晰和模糊语言类别，并且包含了详细的元数据、两轮标记框架和金标准注释集，由专家和训练有素的编码员开发。验证标注者的可靠性达到了Fleiss kappa系数K = 0.86。此外，文中提供了多个大型语言模型的基线分类结果，并描述了数据集的模式。这些创新有助于支持后续任务和多语言自然语言处理研究在政策沟通领域的应用。
### Conclusion
这项发布旨在支持在政策沟通领域的下游任务，促进多语言自然语言处理的研究。
## 363. `cs.CL` - MASA：由大规模语言模型驱动的多智能体系统用于自动形式化 [PDF](https://arxiv.org/pdf/2510.08988), [HTML](https://arxiv.org/abs/2510.08988)
### Authors
Lan Zhang,Marco Valentino,André Freitas
### Background
自动形式化在将自然语言与形式推理连接起来方面具有重要作用。本文介绍了一种全新的多代理系统框架MASA，该框架由大型语言模型（LLMs）驱动，利用协作代理将自然语言陈述转换为形式表示。
### Innovation
MASA框架通过强调模块化、灵活性和可扩展性，实现了新型代理和工具的无缝集成，适应快速发展的领域。这一系统通过现实世界数学定义的用例和形式数学数据集的实验，展示了其有效性，突出了由LLMs和定理证明器交互驱动的多代理系统在提高自动形式化效率和可靠性方面的潜力。
### Conclusion
这项工作强调了多代理系统在自动形式化领域增强效率和可靠性的潜力，为该领域的研究人员和实践者提供了宝贵的见解和支持。
## 364. `cs.CL` - 分解安全性为正交子空间：大型语言模型的低成本和保持性能的安全对齐 [PDF](https://arxiv.org/pdf/2510.09004), [HTML](https://arxiv.org/abs/2510.09004)
### Authors
Yutao Mou,Xiaoling Zhou,Yuxiao Luo,Shikun Zhang,Wei Ye
### Background
构建可信的人工智能需要确保模型的安全性，但现有方法通常需要在安全性和通用性能之间进行复杂的权衡优化，这既耗费计算资源又难以取得显著成效。尽管如此，传统的安全调整方法往往会导致模型性能下降，因此需要一种既能保持性能又能增强安全性的更有效的方法来替代目前的做法。
### Innovation
本文提出了一种名为LoRA-Refusal训练的方法，能够通过仅使用安全数据进行训练来实现性能保持的安全对齐，证明了LoRA作为一种成本低、保持性能和即插即用的安全补丁的有效性。此外，本文还提供了理论和实验证据，说明LoRA能够将安全特性分解到一个与模型内在变换空间部分正交的低秩子空间中，确保安全增强不会干扰模型的固有能力。
### Conclusion
研究证明，通过引入LoRA-Refusal训练方法可以低成本地实现安全与性能的平衡，同时不需要对原始数据进行昂贵的混合搜索，从而降低开发成本并提高模型的安全性和可靠性。
## 365. `cs.CL` - DARO: 难题感知重权策略优化 [PDF](https://arxiv.org/pdf/2510.09001), [HTML](https://arxiv.org/abs/2510.09001)
### Authors
Jingyu Zhou,Lu Ma,Hao Liang,Chengyu Shen,Bin Cui,Wentao Zhang
### Background
近年来，大规模语言模型（LLMs）通过强化学习带可验证奖励（RLVR）显著增强了推理能力。GRPO（Group Relative Policy Optimization）已成为RLVR的标准方法，并产生了一系列变种。然而，这些方法本质上都是GRPO的不同加权变形，其依赖于固定的或过于简单的权重方案，这些方案与样本难度相关，无法适应模型随时间而进化的能力。这导致了一个显著的损失比例问题，即训练过度关注某些难度级别，而忽视了其他水平，从而阻碍了整体性能。
### Innovation
我们提出了难度感知重权策略优化（DARO），该方法基于模型的学习状态动态调整每个难度组别的损失贡献比例。实验结果显示，DARO 在 Qwen2.5-Math-1.5B、Qwen2.5-Math-7B 和 Llama3.1-8B 上的六个数学基准测试中，优于四个领先基线，实现了更快的收敛速度和更优的最终性能。
### Conclusion
DARO 通过动态调整不同难度级别的损失贡献，有效解决了现有方法在处理样本难度时的各种问题，提高了整体性能，并在实际测试中展示了其优越性。
## 366. `cs.CL` - LitE-SQL：基于向量架构关联和执行引导自我纠正的轻量级高效文本到SQL框架 [PDF](https://arxiv.org/pdf/2510.09014), [HTML](https://arxiv.org/abs/2510.09014)
### Authors
Shengmin Piao,Jieun Lee,Sanghyun Park
### Background
文本到SQL任务将自然语言问题转换为SQL查询，使非专业人士可以直观地与数据库交互。近年来，利用大型语言模型（LLMs）的方法在性能上取得了显著进步，但这些方法依赖于专有模型，这引发了部署可行性及数据隐私问题的担忧。现有基于LLM的方法虽然表现出色，但在参数数量上却存在着极大的资源消耗。
### Innovation
本文提出了一种名为LitE-SQL的轻量级高效框架，包括一个向量数据库中的预计算模式嵌入进行高效模式链接的模式检索器，以及一个通过监督微调和执行引导强化学习进行细调的SQL生成器，该生成器能够自我纠正而无需生成多个候选答案。该框架在BIRD和Spider 1.0数据集上的执行准确率分别达到了72.10%和88.45%，表现出低于基于LLM方法两到三十倍的参数使用量，依然提供了相当或更优的性能，在隐私敏感和资源受限场景中具有可操作性解决方案。
### Conclusion
研究表明，高质量的文本到SQL生成可以在轻型模型上实现，为隐私敏感和资源受限环境提供了切实可行的解决方案。
## 367. `cs.CL` - 通过反思与修订自动优化语言模型作文评分准则 [PDF](https://arxiv.org/pdf/2510.09030), [HTML](https://arxiv.org/abs/2510.09030)
### Authors
Keno Harada,Lui Yoshida,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo
### Background
大型语言模型（LLMs）的表现对所给提示高度敏感。本研究基于提示优化领域的灵感，探讨通过细化LLMs使用的评分准则来提高自动作文评分（AES）的可能性。具体而言，研究通过强制模型迭代地基于自身评分理由和与人工评分之间的偏差来反思并优化评分标准。
### Innovation
研究提出了一种反思与修订的方法，让模型能够基于自身评分理由和与人工评分的偏差迭代地优化评分标准。这种方法在TOEFL11和ASAP数据集上使用GPT-4.1、Gemini-2.5-Pro和Qwen-3-Next-80B-A3B-Instruct进行实验，分别实现了高达0.19和0.47的Quadratic Weighted Kappa（QWK）改进。即使初始评分标准简单，该方法也能达到与人工详尽评分标准相当甚至更好的QWK表现，突显了基于LLMs的AES进行迭代评分标准优化的重要性。
### Conclusion
本研究发现，在LLMs基础上的AES中进行评分标准的迭代优化对于提高评分标准与人类评估的一致性至关重要。
## 368. `cs.CL` - 通过基于转写词干的MLM微调探索跨语言知识迁移对于极度低资源查克玛语言 [PDF](https://arxiv.org/pdf/2510.09032), [HTML](https://arxiv.org/abs/2510.09032)
### Authors
Adity Khisa,Nusrat Jahan Lia,Tasnim Mahfuz Nafis,Zarif Masud,Tanzir Pial,Shebuti Rayana,Ahmedul Kabir
### Background
查克玛是一种印度-雅利安语系语言，数据稀缺，因此在语言模型中代表不足。由于OCR流程对形态丰富的印地语系字体的限制，进一步限制了其在语言模型中的应用。
### Innovation
该研究引入了一个由查克玛文学翻译成孟加拉语转写的上下文连贯语料库，并通过本地说话人验证。研究使用这个数据集对六种基于编码器的多语言和地区变压器模型（mBERT，XLM-RoBERTa，DistilBERT，DeBERTaV3，BanglaBERT和IndicBERT）进行微调。实验表明，微调后的多语言模型在适应孟加拉语转写的查克玛时优于预训练模型，达到73.54%的标记准确率和2.90的困惑度。研究还强调了数据质量对模型性能的影响，并展示了OCR流程在形态丰富的印地语系字体中的局限性。
### Conclusion
本研究展示了转写后的孟加拉语查克玛高度适合查克玛语言的迁移学习，并公开了一个手动验证的一语言数据集以促进对低资源语言的多语言语言建模研究。
## 369. `cs.CL` - 大型语言模型并不真正知道它们不知道的东西 [PDF](https://arxiv.org/pdf/2510.09033), [HTML](https://arxiv.org/abs/2510.09033)
### Authors
Chi Seng Cheang,Hou Pong Chan,Wenxuan Zhang,Yang Deng
### Background
最近的研究表明，大型语言模型（LLMs）在其内部表示中编码了事实性信号，如隐藏状态、注意权重或令牌概率，这暗示LLMs可能会“知道它们不知道的东西”。但这些模型也可能因为依赖于捷径或虚假关联而产生事实性错误。这些错误与其训练目标相一致，促进了正确预测，因此引发了内部计算能否可靠地区分事实性和幻觉输出的疑问。
### Innovation
该研究通过机制分析LLMs如何处理事实查询，比较了两种类型的幻觉（基于主体知识依赖程度）。发现当幻觉与主体知识相关时，LLMs使用与正确回应相同的内部回忆过程，导致隐藏状态几何形状重叠且难以区分。相反，不依赖主体知识的幻觉生成了可分辨的、聚类的表示，从而可以被检测到。这一发现揭示了一个基本的限制：LLMs不编码真实性，只编码知识回忆模式，表明“LLMs并不真正知道它们不知道的东西”。
### Conclusion
这些发现揭示了一个基本的限制，即LLMs不编码真实性，而是仅编码知识回忆模式，因此它们不能可靠地区分事实性输出和幻觉输出。
## 370. `cs.CL` - 当检索成功与失败：重新思考基于检索增强生成的LLM [PDF](https://arxiv.org/pdf/2510.09106), [HTML](https://arxiv.org/abs/2510.09106)
### Authors
Yongjie Wang,Yue Yu,Kaisong Song,Jun Lin,Zhiqi Shen
### Background
大型语言模型（LLMs）因其强大的语言理解和生成能力而被广泛应用于各类场景。但由于LLMs主要依赖静态语料库进行训练，它们在处理快速变化的信息或特定领域的问题时存在局限性。为解决这一问题，检索增强生成（RAG）技术通过结合LLMs和外部检索机制，使其能够访问最新的和上下文相关的信息。然而，随着LLMs在规模和能力上的持续进步，传统RAG框架的优势逐渐减弱。
### Innovation
本文综述了RAG的相关内容，从其总体目标和核心组件开始，分析了RAG的关键挑战，并指出了可能限制其有效性的关键弱点。最后，展示了仅使用LLMs时表现不佳的应用场景，但在这些场景中，通过结合LLMs和RAG可以显著提高系统的有效性。本文旨在鼓励研究人员重新思考RAG的作用，并激发未来RAG系统的开发。
### Conclusion
希望通过本文的研究，能够促使研究人员重新审视RAG的作用，并激发下一代RAG系统的开发灵感。
## 371. `cs.CL` - 通过TAU增强对话以构建个性化特征的LLM [PDF](https://arxiv.org/pdf/2510.09158), [HTML](https://arxiv.org/abs/2510.09158)
### Authors
Seiya Ishikura,Hiroaki Yamada,Tatsuya Hiraoka,Hiroaki Yamada,Takenobu Tokunaga
### Background
当前研究领域在利用大规模语言模型（LLM）进行个性建模方面取得了进展，但主要依赖原始对话数据。本文提出将思考 aloud 陈述（TAU）引入对话数据中，以更好地捕捉个体的个性特征。
### Innovation
本文的创新在于首次尝试利用TAU来帮助LLM更准确地识别和模拟讲者的性格特征。实验通过Big Five框架评估了TAU增强数据训练的LLM在对抗性神经质和宜人性方面的表现优于原始对话数据训练的模型。
### Conclusion
实验结果表明，引入TAU可以显著提高LLM在识别讲者神经质和宜人性方面的表现。此外，TAU的质量也直接影响到LLM构建个性特征的效果。
## 372. `cs.CL` - 通过推理和聚合构建更强的重识别攻击 [PDF](https://arxiv.org/pdf/2510.09184), [HTML](https://arxiv.org/abs/2510.09184)
### Authors
Lucas Georges Gabriel Charpentier,Pierre Lison
### Background
文本去标识化技术常用于遮蔽文档中的个人可识别信息（PII）。然而，这些技术在掩饰文本中提及的个人身份方面的效果难以衡量。最近的方法显示，通过基于自动化对手尝试进行反向过程——重识别——来评估去标识化方法的鲁棒性，可以测量其效果。这项研究提出了两种增强重识别攻击的策略。
### Innovation
本文展示了两种增强重识别攻击的策略：首先表明P II片段重新识别的顺序对结果有影响，而且将多个顺序的预测结果综合分析可以提升结果；其次发现推理模型能够提高重识别的性能，特别在这种对手假设拥有大量背景知识的情况下表现良好。
### Conclusion
通过改进重识别攻击的方法，本文展示了去标识化技术的鲁棒性评估的新途径，并提供了增强重识别攻击策略的具体方法。
## 373. `cs.CL` - ReFIne: 一种基于可靠性、忠实性和解释性的可信赖大型推理模型框架 [PDF](https://arxiv.org/pdf/2510.09062), [HTML](https://arxiv.org/abs/2510.09062)
### Authors
Chung-En Sun,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng
### Background
长链推理（CoT）最近的研究大多注重于答案的准确性和令牌效率，而忽视了信任度方面的关键因素。我们提出，可使用的推理系统必须是可靠的，应该具备可解释性、忠实性和可靠性这三个特性。当前研究偏重于准确性，但忽视了这些信任度方面的重要属性，因此需要一个新的框架来提升模型的这些方面的能力。
### Innovation
ReFIne 提出了一种新的训练框架，将监督微调与 GRPO 结合，以鼓励模型：(i) 提高可解释性，通过产生结构化的、标签化的痕迹，并结合高层次的规划，便于人类理解；(ii) 提高忠实性，通过明确揭示指导每个解决方案的关键信息，且各跨段落引用具有一致性；(iii) 提高可靠性，提供推理过程的正确性和最终答案的自信度的自我评估。我们通过在多个规模的 Qwen3 模型上应用 ReFIne 方法，并在不同难度的数学基准上进行评估，展示了 ReFIne 模型在解释性、忠实性、可靠性方面显著改进的结果。
### Conclusion
我们的实验结果表明，ReFIne 模型在推理过程的清晰性和结构化方面提高了 44.0%，在忠实性方面提高了 18.8%，在可靠的信心估计方面提高了 42.4%。这些发现突显了一个被忽视但重要的方向：推理模型应不仅优化其准确性，还应优化其更广泛信任度的维度。我们的代码可以在指定链接找到。
## 374. `cs.CL` - Alif: 通过多语言合成数据精炼推动乌尔都语大型语言模型 [PDF](https://arxiv.org/pdf/2510.09051), [HTML](https://arxiv.org/abs/2510.09051)
### Authors
Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq
### Background
开发面向低资源语言的高性能大型语言模型（LLMs），如乌尔都语，面临数据稀缺、多语言一致性问题以及安全挑战。现有方法通常通过大量翻译数据来解决这些问题，但这种方法往往缺乏质量、文化细腻度，并且在数据管理和训练成本上开销较大。这导致了开发高效、文化对齐的乌尔都语LLMs面临诸多困难。
### Innovation
本文提出了一种名为Alif-1.0-8B-Instruct的多语言乌尔都语-英语模型，通过一种新的多语言合成数据集（Urdu-Instruct）解决了上述问题。该数据集是通过修改后的自我指令技术开发的，采用独特的提示和种子值为每个任务提供个性化输入，结合了全局任务池。这种方法显著提升了模型对乌尔都语特定任务的理解能力，使得Alif-1.0-8B-Instruct在训练预算低于100美元的情况下，不仅在乌尔都语特定任务上表现优于Llama-3.1-8B-Instruct，还在培训预算不到100美元的情况下超越了Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct和Cohere-Aya-Expanse-8B等领先多语言LLMs。这种改良的自我指令方法证明了高效和文化对齐的低资源语言LLMs可以被有效开发。所有数据集、模型和代码均已在公开渠道提供。
### Conclusion
本研究通过采用多语言合成数据的改良自我指令方法，证明了高效能的低资源语言LLMs可以进行有效的开发和文化对齐，解决了现有方法在数据质量和文化细微度上的不足，并显著降低了训练成本。Alif-1.0-8B-Instruct的成果不仅显示了该方法的有效性，也为其他低资源语言的LLM开发提供了新的思路和技术支持。
## 375. `cs.CL` - FrameEOL：使用因果语言模型的语义框引申 [PDF](https://arxiv.org/pdf/2510.09097), [HTML](https://arxiv.org/abs/2510.09097)
### Authors
Chihiro Yano,Kosuke Yamada,Hayato Tsukagoshi,Ryohei Sasano,Koichi Takeda
### Background
语义框引申是将引发语义框的词汇根据它们所引发的语义框进行分组的任务。近年来，使用掩码语言模型（如BERT）获得的词汇嵌入已被证明在语义框引申任务中表现出色。尽管因果语言模型（如GPT和Llama系列）在广泛的语言理解任务中表现出色，并且可以进行对话，仿佛理解了框的概念，但它们尚未应用于语义框引申任务。在此之前，主要方法基于掩码语言模型（MLM），但因果语言模型（CLM）在处理某些特定任务时可能更加有效，尤其是对于数据资源较少的语言，例如日语。因此，该领域需要新的探索方法，以提高性能并解决现有方法的局限性。
### Innovation
该论文提出了一种基于因果语言模型（CLM）的语义框引申的新方法，命名为FrameEOL。这种方法利用了基于提示的框架嵌入获取方式，并结合上下文学习（ICL）和深度度量学习（DML）来获得更适合框引申任务的嵌入。并通过聚类这些嵌入来完成框引申。该方法在英文和日文的FrameNet数据集上的实验结果表明，提出的方优于现有的框引申方法，尤其是在资源较匮乏的情况下，基于CLM的方法仅使用5个ICL示例就能达到与基于MLM微调DML方法相当的效果。
### Conclusion
本文提出的方法在语义框引申任务中表现出了更高的性能，特别是在资源有限的语言（如日文）上。这表明基于因果语言模型的方法有可能在处理特定任务时超越传统的方法，为未来进一步探索这些模型在自然语言处理中的应用提供了新的可能性。
## 376. `cs.CL` - LLaMAX2: 转换增强模型也能在逻辑推理方面表现出色 [PDF](https://arxiv.org/pdf/2510.09189), [HTML](https://arxiv.org/abs/2510.09189)
### Authors
Changjiang Gao,Zixian Huang,Jingyang Gong,Shujian Huang,Lei Li,Fei Yuan
### Background
通用大语言模型（LLMs）在逻辑推理方面表现出色，但经过翻译增强的模型在推理任务上表现不佳。
### Innovation
提出了一种新的翻译增强策略，以指令模型为基础，仅在并行数据上应用层选择性调整。基于此流程，引入了Qwen3-XPlus模型，显著提升了高资源和低资源语言的翻译性能，特别是在低资源语言如斯瓦希里语中达到15+ spBLEU和40+ xComet。通过仅使用小型并行数据集训练，Qwen3-XPlus在7个多语言任务中平均每项任务提升了1+点，并且保持了与Qwen3指令模型相当的15个流行推理数据集的性能。此工作提供了一种多语言增强的有前景方法，显著降低了复杂性和提高了更多语言的可访问性。
### Conclusion
该工作提供了一种有前景的多语言增强方法，降低了复杂性，增强了对更广泛语言的可访问性。代码和模型已公开。
## 377. `cs.CL` - DICE：通过小型语言模型引导的链式思考纠正实现LLMs的结构化推理 [PDF](https://arxiv.org/pdf/2510.09211), [HTML](https://arxiv.org/abs/2510.09211)
### Authors
Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang
### Background
在执行具有用户特定需求的任务时，如严格的输出格式，大型语言模型（LLMs）往往优先考虑推理而非遵循详细指令。通过监督数据微调LLMs来解决这一问题在计算成本和参数访问限制上是不切实际的。因此，需要一种新的方法来指导小型语言模型（SLMs）对LLMs的输出进行链式思考（CoT）纠正，以满足结构化输出规格，同时保留LLMs的广泛知识和推理能力并确保输出符合用户需求。
### Innovation
提出了DICE框架，通过分两步走的方式，首先让LLMs生成自然语言响应，接着使用预训练的SLMs分析并改进这些响应，以符合结构化输出规范。DICE通过构建结构化CoT适应数据集和采用双重微调策略，指导SLMs按照分析然后作答的模式生成结构化输出，从而提高LLMs输出的格式准确性和内容正确性。
### Conclusion
实验表明，DICE能够分别提高LLMs输出的格式准确性和内容正确性35.4%和29.4%，其性能超越了其他竞争基线，实现了业界领先（SOTA）的表现。
## 378. `cs.CL` - DITING：一种用于网络小说翻译基准测试的多智能体评估框架 [PDF](https://arxiv.org/pdf/2510.09116), [HTML](https://arxiv.org/abs/2510.09116)
### Authors
Enze Zhang,Jiaying Wang,Mengxi Xiao,Jifei Liu,Ziyan Kuang,Rui Dong,Youzhong Dong,Sophia Ananiadou,Min Peng,Qianqian Xie
### Background
大型语言模型（LLMs）的出现大大提升了机器翻译（MT）的水平，但它们在翻译网络小说方面的有效性尚不清楚。现有的基准测试主要依赖于表面层度量，未能捕捉到这一文体的独特特征。为了填补这一空白，该研究引入了DITING，这是第一个全面评估网络小说翻译的框架，它从六个维度——成语翻译、词汇歧义、术语本地化、时态一致性、零代词解决和文化安全性——评估叙述和文化忠实度，基于超过18000个专家注释的中英句子对。另外，该研究还提出了AgentEval，这是一种基于推理的多智能体评估框架，模拟专家讨论来评估翻译质量，超越了词表重叠，实现了与七个自动评价指标中人类判断的最高相关性。为了便于不同评价指标的对比，研究开发了MetricAlign，一个包含300个句子对的元评估数据集，附带错误标签和标量质量评分。全面评估了14个开放的、封闭的和商业的模型表明，中文训练的LLMs超越了更大的外国同行，而DeepSeek-V3提供了最忠实且风格一致的翻译。这项工作建立了一个新的LLM驱动的网络小说翻译探索范式，并提供了公共资源以促进未来研究。
### Innovation
研究引入了DITING，这是一个全面评估网络小说翻译的框架，从六个维度评估叙述和文化忠实度；提出了基于推理的AgentEval多智能体评估框架，模拟专家讨论来评估翻译质量；开发了MetricAlign，一个包含300个句子对的元评估数据集，附带错误标签和标量质量评分，以促进不同评价指标的对比。
### Conclusion
研究全面评估了14个开放的、封闭的和商业的模型，结果表明中文训练的LLMs优于更大的外国同行，DeepSeek-V3提供了最忠实且风格一致的翻译。这项工作建立了一个新的LLM驱动的网络小说翻译探索范式，并提供了公共资源以促进未来研究。
## 379. `cs.CL` - IRIS：在无表格数据情况下可验证因果发现的迭代集成框架 [PDF](https://arxiv.org/pdf/2510.09217), [HTML](https://arxiv.org/abs/2510.09217)
### Authors
Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari
### Background
因果发现对科学研究至关重要，但传统统计算法面临数据收集昂贵、已知关系重复计算和不现实假设等挑战。虽然最近基于大语言模型（LLM）的方法在识别已知因果关系方面表现优异，但在发现新颖的因果关系方面却程度有限。
### Innovation
我们提出了IRIS（Iterative Retrieval and Integrated System for Real-Time Causal Discovery），一种新型框架，解决了上述局限性。IRIS 自动从初始变量集开始收集相关文档，提取变量并发现因果关系。该方法结合了统计算法和基于大语言模型的方法，以发现已知和新颖的因果关系。IRIS 还包括一个缺失变量提案组件，用于识别并整合缺失变量，从而扩展因果图。该方法允许仅从一组初始变量开始进行实时因果发现，无需预先存在的数据集。
### Conclusion
本研究通过引入IRIS框架，实现了无表格数据情况下可验证的实时因果发现，不仅发现已知的因果关系，还能识别并整合缺失变量以扩展因果图。
## 380. `cs.CL` - DSPO: 稳定且高效的策略优化以实现有代理搜索和推理 [PDF](https://arxiv.org/pdf/2510.09255), [HTML](https://arxiv.org/abs/2510.09255)
### Authors
Chenyang Gu,Yewen Pu,Bruce Yang,Xiaofan Li,Huan Gao
### Background
增强大规模语言模型(LLMs)的主动外部知识搜索能力对于复杂的真实世界任务至关重要。当前的方法要么依赖提示来激发模型的内在代理能力，要么在进行强化学习( RL )时，当应用于复杂的交互任务时，表现出性能极限并崩溃，未能充分发挥其真正的代理潜力。
### Innovation
我们提出了动态过滤序列级策略优化(DSPO)，这是一种改进的用于通过序列级优化和动态样本过滤进行稳健代理训练的RL算法。我们的模型完全通过RL训练进行多轮搜索和推理的交织，从而消除了监督示例数据的需要。在多个QA基准测试中，我们的DSPO训练的7B模型比前作提高了34.1%，且在复杂多跳QA场景如HotpotQA中超越了前作的14B模型近9%，同时保持了出色的训练稳定性。
### Conclusion
我们的DSPO算法达到了前作无法实现的效果，在代理搜索和推理方面表现出更高的稳定性和效率，证明了其在复杂任务中的潜力。
## 381. `cs.CL` - 一段话，两种嵌入：显性与隐性语义表示的对比学习 [PDF](https://arxiv.org/pdf/2510.09293), [HTML](https://arxiv.org/abs/2510.09293)
### Authors
Kohei Oda,Po-Min Chuang,Kiyoaki Shirai,Natthawut Kertkeidkachorn
### Background
句嵌入方法取得了显著进展，但仍难以捕捉句子中的隐含语义。这主要是因为传统句嵌入方法仅给每个句子分配一个向量，导致无法有效表达句子的多种语义。
### Innovation
提出了DualCSE方法，这是一种为每个句子分配两个嵌入的新方法：一个表示显性语义，另一个表示隐性语义。这些嵌入共存于共享空间，使得可以根据具体目的选择所需的语义，例如信息检索和文本分类。
### Conclusion
实验结果表明，DualCSE可以有效地编码显性和隐性含义并提高下游任务的性能。
## 382. `cs.CL` - CLARity: 仅通过合理性即可教导强化专家 [PDF](https://arxiv.org/pdf/2510.09278), [HTML](https://arxiv.org/abs/2510.09278)
### Authors
Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng
### Background
在数据稀缺的领域训练专家级大规模语言模型（LLM）具有挑战性，通常依赖于多项选择题（MCQs）。然而，基于标准结果导向的强化学习（RL）在MCQs上的应用存在着风险。尽管能够提高准确性，但研究发现这类方法往往降低了逻辑一致性等推理质量。现有的监督推理的方法，例如大规模过程奖励模型（PRMs），成本过高。因此，本文提出了一种名为CLARity的新框架，通过低成本的方式增强推理质量。
### Innovation
CLARity框架引入了一种一致性感知的奖励机制和一个两阶段的‘先润色再监测’训练流程，以增强推理的一致性；同时提出了一种动态数据重构策略，更好地利用有限的数据。实验结果表明，CLARity在提高响应一致性（16.5%）和准确性（7.5%）方面优于基线方法。人类评估进一步证实整体一致性与专业性的提高。
### Conclusion
CLARity提供了一个可扩展的解决方案，即使使用较小的通用语言模型，也能有效指导专家模型进行理性推理。相关代码已开源，可供研究与应用参考。
## 383. `cs.CL` - 检测大语言模型在强化学习后训练阶段的数据污染 [PDF](https://arxiv.org/pdf/2510.09259), [HTML](https://arxiv.org/abs/2510.09259)
### Authors
Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li
### Background
大语言模型（LLMs）的可靠评估受到数据污染的严重威胁，尤其当基准样本意外出现在训练集中时，这会影响报告的性能。虽然在预训练和监督微调阶段已有检测方法，但在强化学习（RL）后训练阶段的数据污染检测方法研究仍存在巨大空白。随着RL后训练阶段在增强LLMs推理能力方面变得越来越重要，缺乏专门针对这一阶段的数据污染检测方法成为了一个关键漏洞。
### Innovation
论文首次系统研究了RL后训练阶段的数据检测问题，并提出了一种名为Self-Critique的方法。这种方法基于一个关键观察：在RL阶段结束后，LLMs的输出熵分布会集中在特定且稀疏的模式中。Self-Critique通过探测潜在的策略崩溃，即模型向狭窄的推理路径收敛，从而导致熵的减少，来进行检测。此外，还引入了RL-MIA基准来模拟这一特定的污染场景。广泛的经验表明，Self-Critique方法在多个模型和污染任务上显著优于基线方法，AUC提升高达30%，而现有方法在RL阶段污染检测中几乎等同于随机猜测。
### Conclusion
Self-Critique方法有效解决了LLMs在RL后训练阶段的数据污染检测问题，并通过广范围的实验验证了其优越性，为该领域的研究提供了新的方向。
## 384. `cs.CL` - 充满虚幻的成功还是真正的表现？通过动态评估重新思考医学诊断基准 [PDF](https://arxiv.org/pdf/2510.09275), [HTML](https://arxiv.org/abs/2510.09275)
### Authors
Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu
### Background
医学诊断是一个高度紧张和复杂的领域，对于患者的护理至关重要。然而，目前对大规模语言模型（LLMs）的评估从根本上与实际临床实践不一致。大多数评估依赖于源自公开医学考试项目的静态基准，倾向于高估模型性能，并忽略了课本案例与真实世界中复杂、多变的情况之间的差异。虽然最近对动态评估的努力提供了一种有希望的替代方案，但它们的改进仅限于表面的扰动和对准确度的狭窄关注。
### Innovation
我们提出了DyReMe，一个动态基准，更好地反映实际临床实践。与静态的考试式问题不同，DyReMe生成新鲜、咨询式的病例，引入了备选诊断和常见误诊因素作为干扰项，并改变表达风格以模仿现实世界中多样的查询习惯。除了准确性之外，DyReMe还从三个额外的临床相关维度评估LLMs：真实性、帮助性和一致性。
### Conclusion
我们的实验表明，这种动态方法提供了更具挑战性和现实性的评估，揭示了最先进的LLMs在实际临床实践中的表现之间存在显著差异。这些发现突显了需要更具代表性的评估框架以满足可靠医学诊断的需求。
## 385. `cs.CL` - CFVBench: 一个全面的细粒度多模态检索增强生成的视频基准 [PDF](https://arxiv.org/pdf/2510.09266), [HTML](https://arxiv.org/abs/2510.09266)
### Authors
Kaiwen Wei,Xiao Liu,Jie Zhang,Zijian Wang,Ruida Liu,Yuming Yang,Xin Xiao,Xiao Sun,Haoyang Zeng,Changzai Pan,Yidan Zhang,Jiang Zhong,Peijin Wang,Yingchao Feng
### Background
Multimodal Retrieval-Augmented Generation (MRAG) 允许多模态大型语言模型 (MLLMs) 通过外部多模态证据生成响应。尽管已经提出了许多基于视频的 MRAG 基准来评估模型在检索和生成阶段的能力，但现有的基准在模态覆盖和格式多样性方面仍然有限，通常集中在单一或多模态任务上，或粗糙的场景理解上。
### Innovation
我们引入了 CFVBench，这是一个大规模的手动验证基准，基于599个公开可用的视频，生成了5,360对开放式问答对。CFVBench 覆盖了不同领域如图表密集型报告、新闻广播和软件教程等高密度格式，需要模型检索和在长时间视频片段上进行推理，同时保持细粒度的多模态信息。通过 CFVBench，我们系统地评估了 7 种检索方法和 14 种广泛使用的 MLLMs，揭示了一个关键瓶颈：当前模型（即使是GPT5或Gemini）难以捕捉瞬时但重要的细粒度多模态细节。我们提出了 Adaptive Visual Refinement (AVR) 作为一种简单而有效的框架，可以动态增加帧采样密度并在必要时调用外部工具。
### Conclusion
实验表明，AVR 在所有评估的 MLLMs 中都一致增强了细粒度的多模态理解，提高了性能。
## 386. `cs.CL` - MaP: 一种统一的预训练动力学可靠评估框架 [PDF](https://arxiv.org/pdf/2510.09295), [HTML](https://arxiv.org/abs/2510.09295)
### Authors
Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou
### Background
大型语言模型（LLMs）的可靠评估对于其进展至关重要，但在预训练过程中的评估过程中存在显著的不稳定性，这掩盖了真正的学习动态。
### Innovation
提出了一种名为MaP的双管齐下的框架，该框架通过结合检查点合并和Pass@k指标来同步整合，检查点合并通过平均最近的模型权重来平滑参数空间，而Pass@k则提供了一个稳健的、低方差的统计模型能力估计。广泛的实验证明，MaP能显著平滑性能曲线、减少运行间变异性，并确保模型排名更为一致。
### Conclusion
MaP 提供了更可靠和忠实的预训练动态观察窗口，为LLM研究奠定了关键的实证基础。
## 387. `cs.CL` - 通过其计算图验证链式思考推理 [PDF](https://arxiv.org/pdf/2510.09312), [HTML](https://arxiv.org/abs/2510.09312)
### Authors
Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda
### Background
当前的链式思考 (CoT) 验证方法是基于输出的黑盒方法或基于激活的灰盒方法来预测推理的正确性，但这些方法并不能揭示计算失败的具体原因。
### Innovation
提出了一种白盒方法：基于电路的推理验证 (CRV)。假设正确的CoT步骤的归因图，作为模型潜在推理电路的执行痕迹，具有与错误步骤不同的结构指纹。通过训练分类器来区分这些图形的结构特征，证明它们包含推理错误的强大信号。并且这种方法揭示了推理错误具有高度的领域特定性，并能够通过分析指导对个体转录器特征进行针对性干预，从而纠正模型的错误推理。
### Conclusion
通过仔细审查模型的计算过程，我们可以从简单的错误检测转向对大语言模型 (LLM) 推理的更深层次、因果性的理解。这种方法揭示了一些关于推理错误的新型科学见解，这些见解是其他方法所无法达到的。
## 388. `cs.CL` - FLRC：适用于高效大语言模型推理的精细低秩压缩器 [PDF](https://arxiv.org/pdf/2510.09332), [HTML](https://arxiv.org/abs/2510.09332)
### Authors
Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu
### Background
尽管大语言模型（LLM）已经取得了显著的性能，但其巨大的参数量阻碍了在资源受限的硬件上的部署。低秩压缩能够减少内存使用和计算需求，但在所有层上应用相同的压缩比通常会导致性能显著下降，且以前的方法在解码过程中表现不佳。
### Innovation
提出了精细低秩压缩器（FLRC），它能够为每个层高效地确定最优的秩分配，并引入逐步低秩解码以保持文本生成质量。
### Conclusion
在多种基准测试上的全面实验表明，FLRC在摘要任务上的ROUGE-L得分相比最先进的低秩压缩方法提高了高达17%，确立了更可靠和高效的框架来改善LLM推理。
## 389. `cs.CL` - ShiZhi: 一种用于法院观点生成的中文轻量级大语言模型 [PDF](https://arxiv.org/pdf/2510.09297), [HTML](https://arxiv.org/abs/2510.09297)
### Authors
Zhitian Hou,Kun Zeng
### Background
刑事法院观点生成（CVG）是法律人工智能中的一个基本任务，目标是自动生成法律案例文档中的“法院观点”部分。由于案件事实的多样性和复杂性，直接从原始事实生成可能会限制性能。现有的模型难以处理这类问题，因此存在改进的空间。为了应对这些问题，研究者们构建了一个名为CCVG的大型中文法院观点生成数据集，包含超过11万个案例，每个案例都包含了事实描述及其相应的法院观点，以此来提升生成的准确性和法律一致性。
### Innovation
本文提出了一种名为ShiZhi的轻量级大语言模型，这是第一个专门设计用于法院观点生成的模型。ShiZhi模型基于CCVG数据集进行训练，显示出了在案件文词生成和指控预测上的优越性能，尤其是在BLEU-1得分为58.5、准确率为86.1%以及宏F1得分为92.5%的表现，展示了当使用高质量的特定领域数据进行训练时，即使是很小的模型也能够生成合理的且法律上一致的法院观点。
### Conclusion
研究结果显示，即使是小型模型，在高质量专门领域数据的指导下，也可以生成合理的且法律上连贯的法院观点。ShiZhi模型和CCVG数据集已向公众开放。
## 390. `cs.CL` - Mask Tokens as Prophet: Fine-Grained Cache Eviction for Efficient dLLM Inference [PDF](https://arxiv.org/pdf/2510.09309), [HTML](https://arxiv.org/abs/2510.09309)
### Authors
Jianuo Huang,Yaojie Zhang,Yicun Yang,Benhao Huang,Biqing Qi,Dongrui Liu,Linfeng Zhang
### Background
扩散型大语言模型（dLLMs）通过并行解码的能力为替代主流的自回归模型（ARMs）提供了可能，但同时也带来了巨大的计算和内存成本。dLLMs的缓存机制用于双向注意，需要大量的内存，这限制了他们在资源受限环境中处理长上下文的能力。现有的缓存淘汰策略主要针对ARMs设计，并忽略了dLLMs的独特特性，导致性能不佳。
### Innovation
团队提出了MaskKV，这是一种无需训练的缓存淘汰框架，专门针对dLLMs。它包含两个关键创新：(1) 基于掩码查询的评分机制，利用注意权重来识别并淘汰每个头部中不太关键的提示令牌；(2) 适应性的缓存预算策略，通过减少中间层的分配并集中资源在偏好提示的头部来提高效率。
### Conclusion
将带有MaskKV的LLaDA中的KV缓存压缩到仅256对（不到5%的令牌），在长测试集上的性能与满缓存相比保持了94%，并且在32k提示长度下的加速比达到了31倍。整个代码可以在以下链接获取：this https URL
## 391. `cs.CL` - LLP: 基于大型语言模型的电子商务产品定价 [PDF](https://arxiv.org/pdf/2510.09347), [HTML](https://arxiv.org/abs/2510.09347)
### Authors
Hairu Wang,Sheng You,Qiheng Zhang,Xike Xie,Shuguang Han,Yuchen Wu,Fei Huang,Jufeng Chen
### Background
在电子商务中，消费者对次品的价格设定往往面临挑战，现有大量研究试图通过静态回归模型自动预测价格，但这些模型难以适应市场价格变化。本文探讨了在现有基础上引入基于大型语言模型（LLM）的产品定价框架LLP，以应对价格动态调整的需求，从而提升价格预测的准确性与实用性。
### Innovation
LLP是第一个基于大型语言模型的生成框架，用于次品定价。该框架通过检索相似产品来更好地适应市场动态变化，利用大型语言模型理解文本中的关键定价信息生成准确的价格建议。此外，LLP采用两种优化阶段（监督微调和组相对策略优化）以及基于信心的过滤机制，提高大型语言模型的领域推理能力，从而改善价格预测的准确性和可靠性。实验结果表明，LLP在多个方面优于现有方法，尤其是在未见类别上的泛化能力表现尤为突出。而且，LLP已经被成功部署在中国最大的二手电商平台Xianyu，其性能显著超出先前的方法。
### Conclusion
LLP框架通过结合大型语言模型优势，显著提升了次品价格的预测准确性和市场上线应用的用户接受度，为电子商务平台提供了新的定价解决方案，具有广泛的实用价值和应用前景。
## 392. `cs.CL` - ReTraceQA：在常识问答中评估小型语言模型的推理过程 [PDF](https://arxiv.org/pdf/2510.09351), [HTML](https://arxiv.org/abs/2510.09351)
### Authors
Francesco Maria Molfese,Luca Moroni,Ciro Porcaro,Simone Conia,Roberto Navigli
### Background
小型语言模型（SLMs）在常识推理基准测试中的性能得到了良好展示，但当前的评估方法主要依赖于最终答案的准确性，忽视了推理过程的有效性。专家标注的数据集揭示了SLMs在一定比例的情况下（14-24%），即使推理过程有缺陷，最终答案也可能正确，表明现有评估指标可能高估了SLMs的能力。这种情况下，使用大型语言模型（LLMs）作为自动评判者，而非仅仅关注最终答案，进行具有推理意识的评估，可以显著影响SLMs的表现。
### Innovation
提出了ReTraceQA，一个新的基准，它引入了在常识推理任务中对推理过程层次上的评估。使用专家标注的数据集展示，仅凭最终答案评估SLMs的表现可能不能全面反映SLMs的实际性能，其能力可能被高估。通过使用LLMs进行具有推理的评估，而不是仅评估答案，SLMs的性能显著下降。
### Conclusion
通过ReTraceQA，证明了在RLP评估中，小型语言模型的性能可以被与其最终答案准确性相反的质量所反映，强烈表明了人们对小型语言模型的理解可能是片面的。采用具有推理意识的评估方法比仅依赖最终答案的评估更加重要。
## 393. `cs.CL` - Logit Arithmetic Elicits Long Reasoning Capabilities Without Training [PDF](https://arxiv.org/pdf/2510.09354), [HTML](https://arxiv.org/abs/2510.09354)
### Authors
Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang
### Background
大型推理模型能够进行长链推理，采用回溯和自我修正等策略，但这些能力通常需要额外的训练。研究者探索了是否可以在没有任何训练的情况下引发这些行为。现有的方法表明，这通常需要进行额外的训练。本文试图在不需要额外训练的情况下，通过一种解码时的方法来实现这一目标，即通过较小的推理模型引导较大的非推理模型进行长推理。
### Innovation
本文提出了一种名为ThinkLogit的新方法，利用对数几率（logit）算术来调整一个目标大型非推理模型，使其能够进行长推理。此外，作者还提出了一种名为ThinkLogit-DPO的新方法，通过优化正确和错误的推理对进行训练，进一步提升模型性能。这种方法能够在没有额外训练的情况下，显著提高模型的推理能力，尤其是在目标模型和引导模型来自不同模型系列时依然有效，同时与小型模型的后训练方法具有互不干扰性。
### Conclusion
实验结果显示，即使使用一个比目标模型小21倍的模型作为引导器，ThinkLogit和ThinkLogit-DPO也能够在五个推理基准中分别实现相对平均准确率提升24.5%和29.1%。无论引导器和目标模型来自不同模型系列，ThinkLogit方法依然有效，且与其他改进小型模型的方法兼容，提供了一种经济有效的方式，在大型模型中解锁长推理能力。
## 394. `cs.CL` - 基于马尔科夫极大似然的token级策略优化：将组级奖励与token级聚合链接 [PDF](https://arxiv.org/pdf/2510.09369), [HTML](https://arxiv.org/abs/2510.09369)
### Authors
Xingyu Lin,Yilin Wen,En Wang,Du Su,Wenbin Liu,Chenfu Bao,Zhonghou Lv
### Background
大型语言模型（LLMs）在数学推理能力上存在提升空间，尽管Group Relative Policy Optimization (GRPO)及其相关方法通过增强链式思考（CoT）的数学性能进步显著，但仍受到稀疏标记奖励的挑战。现有方法主要通过无区别的token级熵调整，导致熵崩溃或模型崩溃等问题。
### Innovation
提出TEPO（Token-Level Policy Optimization）框架，通过引入马尔科夫极大似然来连接组级奖励与token级聚合，替换现有的无区别的token级熵调整方法，从而在关键指标上表现更优，并且在数学推理任务上达到新前沿，同时也大幅提升了模型的训练稳定性。
### Conclusion
TEPO框架在多个关键指标上超越了现有基线，不仅在数学推理任务上达到了新的标准，还显著增强了训练的稳定性。
## 395. `cs.CL` - NL2GenSym: 通过大型语言模型将自然语言转换为生成符号规则的SOAR认知架构 [PDF](https://arxiv.org/pdf/2510.09355), [HTML](https://arxiv.org/abs/2510.09355)
### Authors
Fang Yuan,Junjie Zeng,Yue Hu,Zhengqiu Zhu,Quanjun Yin,Yuxiang Xie
### Background
SOAR是一种经典的基于符号的认知架构，对通用、类人类智能代理的发展起到了推动作用。然而，它的实际应用受到了手工规则编码繁琐的阻碍。新兴的大规模语言模型（LLM）表现出高效的规则生成潜力，但当前的研究主要集中在概念框架上，缺乏稳健的实验验证。为了填补这一缺口，本文提出了NL2GenSym框架，将LLM与SOAR相结合，以自主从自然语言生成生成的符号规则。该框架引入了执行背景下的生成者-批判者机制，通过检索增强生成接入自我演化领域的知识库，LLM生成的规则随后在SOAR环境中执行，验证其正确性，基于此反馈，批判者驱动规则的迭代改进。
### Innovation
本文提出的NL2GenSym框架创新性地结合了LLM与SOAR，能够自主从自然语言生成生成的符号规则，并引入了执行背景下的生成者-批判者机制。通过执行验证和迭代改进，该框架在解决特定问题（水壶问题）上取得了显著效果，成功率超过86%，并生成了新颖的启发式规则，显著减少了决策周期。该框架还展示了小型参数模型可以超越大型模型的效果。
### Conclusion
本文提出的NL2GenSym框架在解决水壶问题的数据集上进行了验证，显示出高效的规则生成能力和显著的性能改进，特别是在决策周期上。该框架通过将大型语言模型与SOAR认知架构结合，成功解决了传统规则编码的繁琐问题，为智能代理的开发提供了新的方法。
## 396. `cs.CL` - 识别与互动优化数据可视化代码生成中的含糊用户目标 [PDF](https://arxiv.org/pdf/2510.09390), [HTML](https://arxiv.org/abs/2510.09390)
### Authors
Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani
### Background
在人机交互中，建立共享目标是一个基本步骤。但是，歧义会使得生成的输出看似正确，却未能反映出说话人的意图。本文在数据可视化领域探讨这个问题，探索自然语言中的歧义如何影响代码生成的准确性。
### Innovation
本文开发了一种歧义的分类体系，并提出了量化这些类型歧义的度量标准。作者还研究了多轮对话如何减少歧义，提高代码准确性。通过评估三项实用模型（格赖斯合作原则、话语表示理论和讨论中的疑问）来指导对话策略，作者发现模拟用户研究显示多轮对话如何减少歧义并提升代码准确性，强调了多轮对话在代码生成中的价值。
### Conclusion
本文的工作表明，我们的歧义度量标准比不确定性标准更好地与人类注释相关。多轮对话能够降低歧义，通过更好地匹配用户目标来提高代码准确性。
## 397. `cs.CL` - 理解特定领域微调对大语言模型的影响 [PDF](https://arxiv.org/pdf/2510.09359), [HTML](https://arxiv.org/abs/2510.09359)
### Authors
Eshaan Tanwar,Deepak Nathani,William Yang Wang,Tanmoy Chakraborty
### Background
特定领域微调过的大型语言模型（LLMs）在特定领域表现出强大的性能，但它们的参数空间是如何被微调改变的机制尚不明确。先前的研究主要集中在自回归或通用指令模型上，而针对特定领域的大型语言模型（LLMs）则较少被研究。本文首次对特定领域微调在大型医疗语言模型中的效果进行了系统研究。研究表明，微调主要修改了代表空间中的小部分，基本上保留了预训练模型的表示。这些变化在子空间中的解释，本文提出了调谐向量的方法，这是基于任务向量的一种新框架，可以明确捕捉微调诱导的方向参数变化。实验证明，这种方法对于提高指令遵守和生成质量至关重要。此外，将不同领域间的调谐向量结合起来能提升泛化能力。
### Innovation
提出了一种新的框架——调谐向量，可以明确地捕捉微调诱导的方向参数变化，并展示了这种向量对于增强指令遵守和生成质量的重要性。进一步发现，这些向量主要在模型的MLP层中写入新的方向信息，并放大注意力头中的现有方向。这种方法提供了一个新的用于理解大语言模型适应性的见解，并提供了一种通用且可解释的框架来分析大语言模型的特殊化
### Conclusion
研究发现，特定领域微调主要影响了模型的MLP层和注意力头的方向性，而不显著改变底层的表示空间。调谐向量对于提高指令推理和生成质量至关重要，结合不同领域间的调谐向量可以提升模型的泛化能力。这一研究提供了关于大型语言模型特定领域微调的新见解，并为研究大型语言模型的适应性提供了一种可解释的分析框架。
## 398. `cs.CL` - 超越单一粒度提示：多尺度思维链的图提示学习 [PDF](https://arxiv.org/pdf/2510.09394), [HTML](https://arxiv.org/abs/2510.09394)
### Authors
Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu
### Background
现有的 '预训练、提示' 架构已经从NLP领域扩展到图数据领域，取得了显著进展。然而，当前的主流图提示调优方法仅在节点级或子图级等单一粒度上使用可学习的提示向量，忽视了图数据中固有的多层次结构信息，限制了提示语义的多样性。
### Innovation
本文提出了一种新的多尺度图思维链（Multi-Scale Graph Chain-of-Thought, MSGCOT）提示框架，该框架在网络设计中引入了多层次信息。具体而言，该框架利用轻量级低秩粗化网络高效地捕捉多层次结构特征作为提示生成的层次基向量，并按照从粗到细的认知过程动态整合多层次信息，从而形成逐步的粗到细提示链。
### Conclusion
在八个基准数据集上的广泛实验表明，MSGCOT 在少样本场景下优于现有的单一粒度图提示调优方法，显示出卓越的性能。
## 399. `cs.CL` - 大型语言模型的主动模型选择 [PDF](https://arxiv.org/pdf/2510.09418), [HTML](https://arxiv.org/abs/2510.09418)
### Authors
Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel
### Background
先前的评估和基准测试方法主要依赖于完全注释的数据集，这在获取高质量注释方面非常耗费成本。因此，需要一个能够在有限注释情况下高效识别最佳大型语言模型的框架。
### Innovation
LLM SELECTOR框架是首个针对大型语言模型（LLMs）进行主动模型选择的框架。它通过自适应地选择最具信息量的少量查询来注释，从而找到最适合给定任务的模型。此外，该框架还利用基于评判者的oracle注释模型来进一步降低注释成本。实验结果表明，LLM SELECTOR在选择最佳和近似最佳LLM时可将注释成本降低高达59.62%。
### Conclusion
LLM SELECTOR通过高效地在有限注释的情况下选出最佳的大型语言模型，显著降低了注释成本，展示了其在实际应用中的潜力。
## 400. `cs.CL` - Auto-regressive Large Language Models 中实体的表示研究 [PDF](https://arxiv.org/pdf/2510.09421), [HTML](https://arxiv.org/abs/2510.09421)
### Authors
Victor Morand,Josiane Mothe,Benjamin Piwowarski
### Background
实体是文本中知识的基本构建块，它们在语言中承载事实信息并构建关系。尽管实体的重要性不言而喻，但目前尚不清楚大型语言模型（LLMs）如何内部表示这些实体。前期研究主要关注显式的实体关系，但对于实体本身的表示研究却很少。因此，研究如何从内部表示生成实体提及以及实体提及如何被编码和操作具有重要意义。
### Innovation
本文引入了实体提及重构作为研究LLMs如何编码和操作实体的新框架。通过利用任务向量，该方法能够从各种LLMs隐藏状态派生出的实体表示中一致性地生成多汉字提及。此外，作者提出了新的实体镜头（Entity Lens），扩展了logit-lens来预测多汉字提及。研究结果表明，LLMs发展出了特定于实体的机制，用于表示和操作任何多汉字实体，甚至那些在训练期间未见过的实体。
### Conclusion
我们的研究提供了证据，表明LLMs发展出了特定于实体的机制，能够表示和操作任何多汉字实体。我们通过训练过程中未见过的实体，验证了这一理论。我们所提供的代码可以在提供的链接中获得。
## 401. `cs.CL` - Speech-LLM 倾听一切：一种真正完全端到端的口语对话状态跟踪方法 [PDF](https://arxiv.org/pdf/2510.09424), [HTML](https://arxiv.org/abs/2510.09424)
### Authors
Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf
### Background
本文研究了端到端口语对话状态跟踪中上下文管理策略，特别是使用语音大语言模型（Speech-LLMs）的情况。研究了传统的多模态上下文（结合文本历史和当前的口语转录），完整的口语历史记录，以及压缩的口语历史记录方法。
### Innovation
本文系统地评估了不同上下文管理策略的效果，并通过SpokenWOZ语料库的实验证明，提供完整的口语对话作为输入，可以显著超越之前的模型。此外，基于注意力池化压缩口语历史记录的方法在减少上下文大小的同时保持了竞争力。
### Conclusion
详细的分析表明，性能的提升来自于更有效的上下文利用。提供整个口语历史作为输入能够显著提升模型性能，而基于注意力池化的压缩方法在减少上下文大小的同时也能保持较高的准确性。
## 402. `cs.CL` - KORMo：面向每个人的韩语开放推理模型 [PDF](https://arxiv.org/pdf/2510.09426), [HTML](https://arxiv.org/abs/2510.09426)
### Authors
Minjun Kim,Hyeonseok Lim,Hangyeol Yoo,Inho Won,Seungwoo Song,Minkyung Cho,Junhun Yuk,Changsu Choi,Dongjae Shin,Huige Lee,Hoyun Song,Alice Oh,Kyungtae Lim
### Background
本研究旨在进行大规模的开放型双语大型语言模型（LLM）构建调查，特别针对韩语。此前，大多数语言模型主要基于真实数据训练，而该研究首次尝试使用大量合成数据训练模型。
### Innovation
本文介绍了名为KORMo-10B的全新10.8亿参数模型，该模型主要在包含68.74%合成数据的韩英双语语料中从零开始训练。研究通过系统性实验表明，当合成数据在语言覆盖和指令风格上达到平衡时，可以在大规模预训练中保持稳定而不发生下降。此外，该模型在广泛的知识、推理和指令跟随基准测试中的表现与当前的开源多语言基线相当。研究揭示，合成数据可以在长期预训练中可靠地保持稳定，而不引发模型崩溃，并且双语指令调整能够实现韩语的接近母语推理和连贯性。
### Conclusion
本研究全面公开了所有组件，包括数据、代码、训练食谱和日志，建立了一种在低资源环境中开发数据驱动的全开放模型（FOM）的透明框架。此外，该研究还为未来的多语言LLM研究设定了可重复的先例。
## 403. `cs.CL` - 没有标注数据我们能否可靠地跨域排名模型性能？ [PDF](https://arxiv.org/pdf/2510.09519), [HTML](https://arxiv.org/abs/2510.09519)
### Authors
Veronica Rammouz,Aaron Gonzalez,Carlos Cruzportillo,Adrian Tan,Nicole Beebe,Anthony Rios
### Background
在自然语言处理(NLP)领域，理解模型如何泛化并在不同环境下表现如何是一个重要的目标。既有的工作提出了基于数据集相似度或预测正确率的模型性能度量方法，但这些方法在不同领域中产生的性能排名可靠性仍不清楚。
### Innovation
本文采用了两步评估框架，并结合了四个基本分类器和多个大型语言模型作为错误预测器，评估了几种基于漂移和零样本基线的方法，结果显示基于大型语言模型的错误预测器对于真实准确率的排名相关性更强且更一致。
### Conclusion
我们的分析揭示了两项关键发现：当各领域性能差异较大以及错误模型预测与基础模型的真实失败模式吻合时，排名更为可靠。这些结果明确了在何种情况下性能估计方法可以被信赖，并为在跨域模型评估中的使用提供了指导。
## 404. `cs.CL` - StatEval: 一个全面的大型语言模型在统计学中的基准测试 [PDF](https://arxiv.org/pdf/2510.09517), [HTML](https://arxiv.org/abs/2510.09517)
### Authors
Yuchen Lu,Run Yang,Yichen Zhang,Shuguang Yu,Runpeng Dai,Ziwei Wang,Jiayi Xiang,Wenxin E,Siran Gao,Xinyao Ruan,Yirui Huang,Chenjing Xi,Haibo Hu,Yueming Fu,Qinglan Yu,Xiaobing Wei,Jiani Gu,Rui Sun,Jiaxuan Jia,Fan Zhou
### Background
大型语言模型（LLMs）在数学和逻辑推理方面取得了显著进步，但作为一门独立且综合的学科，统计学在基准测试中的探索仍显不足。
### Innovation
引入StatEval，这是第一个全面针对统计学的基准测试，涵盖了不同难度级别的基础问题和研究级证明任务，设计了一个可扩展的多代理流水线以实现大规模问题的自动化提取、重写和质量控制，并提出了一个专用于计算和证明任务的稳健评估框架。
### Conclusion
实验结果显示，闭源模型如GPT5-mini在研究级问题上的表现仅为57%以下，开源模型表现更差，这突显了统计推理的独特挑战和当前LLMs的局限性，StatEval有望作为推进统计智能的严格基准。
## 405. `cs.CL` - 自然语言推理中的混合模型：命题逻辑案例 [PDF](https://arxiv.org/pdf/2510.09472), [HTML](https://arxiv.org/abs/2510.09472)
### Authors
Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki
### Background
尽管神经模型取得了显著的进步，它们在逻辑推理等应用中的泛化能力依然是一项关键挑战。泛化能力包括两个基本方面：组成性和递归性。组成性是指抽象出复杂推断背后的原子逻辑规则，而递归性是通过迭代应用推断规则来构建复杂表征的能力。这两方面在文献中常常被混淆为泛化的一个概念。为了明确这一区别，研究团队采用命题逻辑作为自然语言推理的基准，评估预训练大型语言模型在逻辑泛化方面的表现。
### Innovation
研究团队提出了一种结合符号推理与神经计算的混合架构，旨在克服当前神经推理系统的局限性并建立可靠的逻辑证明工具。这种架构通过协同作用实现了稳健且高效的信息推断，神经组件加速了处理过程，而符号推理确保了完整性。实验结果显示，即使使用较小的神经组件，高效性也得到了保持。
### Conclusion
研究发现大型语言模型在递归性方面表现出色，但在组成性方面能力较弱。通过提出混合模型的方法，研究为解决神经推理系统的泛化障碍提供了理论依据和潜在路径。
## 406. `cs.CL` - 领域适应预训练语言模型在事故叙述中隐含信息提取的应用 [PDF](https://arxiv.org/pdf/2510.09434), [HTML](https://arxiv.org/abs/2510.09434)
### Authors
Xixi Wang,Jordanka Kovaceva,Miguel Costa,Shuai Wang,Francisco Camara Pereira,Robert Thomson
### Background
道路交通事故的自由文本叙述在交通安全管理中起着重要作用，但由于这些文本内容是非结构化的，难以标准化且由不同经验水平的作者撰写，因此大规模分析仍然具有挑战性。近年来，基于Transformer的预训练语言模型（如BERT和大型语言模型）在自然语言处理任务中表现出色，能从事故叙述中提取明确的事实，但在涉及大量推理判断的任务中（例如事故类型识别）表现不佳，且这些模型对外部API的依赖引发了隐私问题。此外，这些黑盒工具由于领域知识有限，性能通常不理想。
### Innovation
研究发现，通过应用细调技术（结合低秩适应[LoRA]和BERT）的小型开源预训练语言模型能够支持事故叙述中的复杂信息提取。团队将特定任务的知识注入到大型语言模型中，展示了这些细调后的模型在使用最少训练资源的情况下，相较于强大的闭源模型（如GPT-4o）有更好的性能。结果显示，细调后的模型能够捕捉到更丰富的叙述细节，并且能够修正数据集中的某些错误标注。
### Conclusion
实验结果表明，我们改进的细调模型能够有效提升事故叙述中关键信息的提取精度，并且相比闭源大模型，所需的训练资源更少。此外，这些模型还能识别出某些错误标注，从而提高数据质量。
## 407. `cs.CL` - 多模态政策内化在对话代理中的应用 [PDF](https://arxiv.org/pdf/2510.09474), [HTML](https://arxiv.org/abs/2510.09474)
### Authors
Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya
### Background
现代对话代理如ChatGPT和Alexa依赖于预定义的策略，这些策略涉及元数据、响应风格和工具使用规则。随着这些基于大语言模型的系统扩展以支持多样化的业务和用户查询，这些策略变得越来越复杂和冗长，使得忠实执行变得困难，并增加了巨大的固定计算成本。随着多模态代理的兴起，监管视觉和多模态行为的策略至关重要但仍然未被充分研究。先前的提示压缩工作主要缩短了任务模板和演示，而现有的策略对齐研究仅集中在基于文本的安全规则上。
### Innovation
本文介绍了多模态政策内化（MPI），这是一种新的任务，将计算密集型多模态策略内化到模型参数中，无需在推理期间包含策略。MPI提出了独特数据和算法挑战。作者构建了两个跨越合成和现实世界决策和工具使用任务的数据集，并提出了一个三阶段训练框架——Tr(MPI)。该框架通过连续预训练、监督微调和应用基于卷积策略优化扩展的策略展开技术来增强具有政策感知的探索，从而实现端到端精度、泛化能力和遗忘鲁棒性的显著提升。
### Conclusion
作为第一项关于多模态政策内化的研究，本文提供了数据集、训练配方和全面评估，以促进未来研究。
## 408. `cs.CL` - 通过推理塑造减少过度思考 [PDF](https://arxiv.org/pdf/2510.09535), [HTML](https://arxiv.org/abs/2510.09535)
### Authors
Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang
### Background
大型推理模型（LRMs）在从验证者奖励（RLVR）进行强化学习后，展示出强大的问题解决能力，但仍经常陷入过度思考：冗长、复杂的推理过程导致计算成本增加。此前，RLVR中限制手段能减少标记消耗，但往往损害模型性能，这源于对标记级监督的简化处理。研究表明，推理段落与标记消耗及模型性能密切相关，因此监督的粒度对于平衡效率和准确性至关重要。
### Innovation
本文提出了一种步骤级正则化推理的方法——组相对段落惩罚（GRSP），其通过设计一种感知段落长度的加权机制，在不同段落簇间分配权重，从而提升了标记效率而不显著影响准确率，尤其在处理更难问题时优势明显。此外，GRSP还稳定了RL训练过程，并在不同大小的模型中表现出良好的扩展性。
### Conclusion
通过GRSP，实现了在不大幅牺牲准确性的前提下，显著提高标记效率，尤其对于困难问题，GRSP展示出其独特优势。同时，GRSP有效稳定了RL训练，且能在不同规模的模型中良好扩展。
## 409. `cs.CL` - 为实际应用搭建索引：LLM训练数据的全文搜索 [PDF](https://arxiv.org/pdf/2510.09471), [HTML](https://arxiv.org/abs/2510.09471)
### Authors
Ines Altemir Marinas,Anastasiia Kucherenko,Alexander Sternfeld,Andrei Kucharavy
### Background
大型语言模型（LLMs）的表现主要取决于训练数据。尽管开放权重LLMs的数量增加，但LLE的访问仍然受限。即使是完全开放的LLMs，由于数据量巨大，使得科学界难以理解，虽然这些数据可能包含了从互联网上抓取的关键信息。本文探讨了Apertus LLM训练数据的全文索引管道，利用Elasticsearch并行索引和Alps基础设施，成功地在一种先进的高能效arm64超集群上创建了一个索引。这不仅是一个重要的LLM安全工具，还像一个离线且精挑细选的开源网络搜索引擎。然而，科学界目前在访问这些训练数据方面面临挑战，尤其是大规模数据集的全文索引和对整个开放网络进行索引可能难以实现和获取。因此，数据索引工作对于研究者来说非常重要。这篇文章展示了相关的技术和部署经验，以供其他团队借鉴。
### Innovation
作者利用Elasticsearch并行索引和Alps基础设施，成功在arm64基于的先进高能效超集群上创建了一个Apertus LLM训练数据的全文索引。此外，作者展示了在现代LLM训练数据集规模和整个开放网络进行全文索引是可行且可访问的，并且这样的索引可以用来确保以前无法访问的、刺激无关的LLM安全性。通过这种方式，提供了一个新的工具来辅助研究和改进LLM的安全性能，同时也有望推动绿色计算的广泛过渡。
### Conclusion
本文的研究表明了Elasticsearch可以在下一代arm64基础上成功移植。并且，展示了大规模的现代LLM训练数据集和整个开放网络进行全文索引和搜索是可行的且可用于实际应用。此外，这一工作对于所有涉及大规模数据索引的团队提供了宝贵的经验，并有望促进更绿色的计算方法。
## 410. `cs.CL` - 通过显著性驱动的频谱图遮罩实现音调不变的自动语音识别 [PDF](https://arxiv.org/pdf/2510.09528), [HTML](https://arxiv.org/abs/2510.09528)
### Authors
Mohammad Hossein Sameti,Sepehr Harfi Moridani,Ali Zarean,Hossein Sameti
### Background
预训练的变换器模型显著推进了自动语音识别（ASR），但它们对口音和方言变化仍然敏感，导致在英语和波斯语等语言中词错率（WER）升高。为了应对这一挑战，我们提出了一种音调不变的ASR框架，该框架将口音和方言分类集成到识别流水线中。该方法通过对频谱图进行特定口音特征的训练分类器，隐藏对预测影响最大的区域，并使用遮罩过的频谱图进行数据增强，增强了ASR模型在应对口音变化方面的鲁棒性。我们使用英波斯两种语言的语音进行评估，为波斯语提供了包含多种区域口音的新数据集，并首次建立了波斯语语音识别中的声调变异性系统基准，填补了多语言语音研究中的关键空白，提供了未来研究低资源语言的基础。
### Innovation
本文提出的创新之处在于提出了一种通过信号驱动的频谱图遮罩实现音调不变的自动语音识别方法。方法包括训练针对特定口音的分类器识别口音特征，并遮罩预测中最具影响的区域，然后使用这些遮罩的频谱图进行数据增强。这种方法提升了ASR模型在面对口音变化时的鲁棒性。
### Conclusion
实验结果表明，通过掩码和数据增强策略，我们显著降低了英波斯两种语言环境下的词错率，证实了该方法的有效性。这项研究促进了对口音和方言多样性的多语言ASR系统的开发，代码和数据集已公开。
## 411. `cs.CL` - 评估大型语言模型对多语言拼写错误的鲁棒性 [PDF](https://arxiv.org/pdf/2510.09536), [HTML](https://arxiv.org/abs/2510.09536)
### Authors
Yihong Liu,Raoyuan Zhao,Lena Altinger,Hinrich Schütze,Michael A. Hedderich
### Background
大型语言模型（LLMs）在多语言的实际应用中越来越多地面对带有用户输入的应用情景，这自然地引入了拼写错误（错别字）。然而，大部分基准测试假设输入都是干净的，这使得跨语言的LLMs对于错别字的鲁棒性研究相对较少。为了弥补这一缺口，本研究引入了MulTypo，这是一种基于语言特定键盘布局和打字行为的多语言错别字生成算法，模拟人类错误。我们在三个模型家族的18个开源LLMs上进行了评估，覆盖了涵盖语言推理、多项选择问题回答、数学推理和机器翻译任务的五个下游任务。研究结果表明，错别字在生成任务和需要推理的任务中会一致地损害性能，而自然语言推理任务的鲁棒性相对较强。指令调优可以在干净输入的情况下提高性能，但在噪声环境下可能会增加脆弱性。还观察到语言相关的鲁棒性：高资源语言比低资源语言更为鲁棒，并且从英语到其他语言的翻译比从其他语言到英语的翻译更为鲁棒。研究结果强调了噪声意识训练和多语言鲁棒性评估的必要性。我们公开了我们的代码和数据。
### Innovation
引入了MulTypo，这是一种基于语言特定键盘布局和打字行为的多语言错别字生成算法，模拟人类错误；首次系统的评估了18种开源LLMs在多语言中的鲁棒性。
### Conclusion
研究发现，错别字会普遍损害LLM的性能，特别是在生成和需要推理的任务中。指令调优可以增强在干净输入下的性能，但在噪声环境下的鲁棒性可能会降低。研究还揭示了语言相关的鲁棒性差异，并强调了噪声意识训练和多语言鲁棒性评估的重要性。
## 412. `cs.CL` - 跨语言链式推理综合评估：跨语言的一致性和忠实性 [PDF](https://arxiv.org/pdf/2510.09555), [HTML](https://arxiv.org/abs/2510.09555)
### Authors
Raoyuan Zhao,Yihong Liu,Hinrich Schütze,Michael A. Hedderich
### Background
大型推理模型LRMs越来越多地依赖逐步链式推理CoT来提高任务表现，特别是在资源丰富如英语的语言中。现有的研究表明，在多语言环境中，重点关注的是最终答案的准确性，而推理痕迹，即通向最终答案的中间步骤，仍然没有得到足够的探索。
### Innovation
本文首次全面研究了多语言链式推理，评估了三个关键维度：性能、一致性和忠实性。通过测量语言合规性、答案准确性和答案一致性，揭示了较强的语言偏好和跨语言性能的差异。研究还评估了在语言间互换思考痕迹时的一致性，并使用扰动技术探究思考痕迹在不同语言中的忠实性。
### Conclusion
研究结果表明，不同语言的思考痕迹在质量与有效性方面存在显著差异。模型对思考痕迹的依赖程度因语言而异。研究同时发布了代码和数据，以支持未来的相关研究。
## 413. `cs.CL` - SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models [PDF](https://arxiv.org/pdf/2510.09541), [HTML](https://arxiv.org/abs/2510.09541)
### Authors
Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu
### Background
扩散大语言模型（dLLMs）由于能够并行解码多个令牌，已成为自回归模型的有效替代方案。然而，通过强化学习（RL）对dLLMs进行与人类偏好或特定任务奖励的对齐是具挑战性的，因为其无法计算的对数似然使其无法直接应用标准的策略梯度方法。先前工作使用似然下界（ELBO）等替代方法，但这些方法会给策略梯度带来显著偏差。
### Innovation
提出了一种新的策略梯度方法——三明治策略梯度（SPG），该方法利用了真实对数似然的上界和下界。实验表明，SPG在多个任务上显著优于基于ELBO或一步估计的基线方法，特别是在GSM8K、MATH500、Countdown和Sudoku任务上，准确率分别提高了3.6%、2.6%、18.4%和27.0%。
### Conclusion
SPG方法在利用扩散大语言模型进行任务时，通过结合真实对数似然的上界和下界，有效地减少了策略梯度的偏差，并显著提升了模型的性能。
## 414. `cs.CL` - 基于知识增强的分层索引多语言视频语料检索 [PDF](https://arxiv.org/pdf/2510.09553), [HTML](https://arxiv.org/abs/2510.09553)
### Authors
Yu Wang,Tianhao Tan,Yifei Wang
### Background
从多语言医学档案中检索相关的教学视频对于跨语言回答复杂的多跳问题至关重要。然而，现有的系统要么将长视频压缩成粗粒度的嵌入，要么会对精细级别的匹配产生高昂的成本。在NLPCC-2025 M4IVQA挑战任务中，研究提出了一种多阶段框架，该框架整合了多语言语义、专业术语和高效的长文本处理方式来解决多语言视频语料检索任务（mVCR）
### Innovation
该框架将视频字幕划分为语义上连贯的片段，并通过语言无关的多语言编码器丰富了这些片段的KG事实。在查询时，通过分层索引和知识增强，利用轻量级大语言模型对排名靠前的片段进行再排序，从而避免了全面的交叉编码评分同时保持了片段级别的精确度。
### Conclusion
该实验在mVCR测试集上展示了最先进的表现，并且消融研究证实了知识增强、分层索引和针对大语言模型的再排序的互补贡献。提出的框架为专业医学视频集合中的多语言检索提供了精确且可扩展的解决方案。
## 415. `cs.CL` - 超越表面推理：揭示扩散大型语言模型的真正长链推理能力 [PDF](https://arxiv.org/pdf/2510.09544), [HTML](https://arxiv.org/abs/2510.09544)
### Authors
Qiguang Chen,Hanjing Li,Libo Qin,Dengyun Peng,Jinhao Liu,Jiangyi Wang,Chengyue Wu,Xie Chen,Yantao Du,Wanxiang Che
### Background
近期，扩散大型语言模型（DLLMs）提供了高吞吐量和有效的序列推理能力，使其成为自回归大型语言模型（ALLMs）的竞争替代品。然而，平行解码能够同时更新标记，却与进行严谨推理时所需要的因果顺序产生冲突。我们首先将这一冲突定义为平行-顺序矛盾（PSC）。在简单和复杂推理任务中进行的行为分析显示，DLLMs仅在直接可判定的输出中展现出真正的并行性，随着任务难度的增加，他们回归到类似于自回归的行为，这一局限性在使用自回归提示时被放大，额外的解码步骤增加几乎一倍，却没有改进质量。此外，PSC限制了DLLMs的自我反思、推理深度和探索广度。
### Innovation
我们通过引入扩散语言模型的三个扩展维度——并行、扩散和序列，进一步表征PSC。实证研究表明，尽管并行扩展可以带来一致的改善，但扩散和序列扩展由于PSC的限制而受到制约。基于这些发现，我们提出了一系列实际缓解措施，包括并行导向的提示、扩散提前停止和并行扩展，以减少PSC所带来的无效性和低效率。
### Conclusion
我们揭示了扩散大型语言模型在复杂推理中的局限性，提出了缓解这些局限性的方法，以提升模型的有效性和效率。
## 416. `cs.CL` - Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models [PDF](https://arxiv.org/pdf/2510.09592), [HTML](https://arxiv.org/abs/2510.09592)
### Authors
Donghang Wu,Haoyang Zhang,Jun Chen,Xiangyu(Tony)Zhang,Hexin Liu,Eng Siong Chng,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu
### Background
实时语音语言模型(SLMs)在实现链式思维(Chain-of-Thought, CoT)推理时面临较大的延迟问题，难以实时有效利用完整的思维过程。虽然实时思考和说话的能力正逐渐引起人们的关注，但目前的方法仍存在切换模式的问题，无法保持推理过程的连贯性。
### Innovation
提出了一种名为Mind-Paced Speaking(MPS)的新框架，该框架借鉴了人脑结构，通过将复杂的推理和流畅的语言生成分开处理（即“思维脑”指导“发音脑”），实现实时、高保真推理的无缝衔接。这种分工避免了模式切换，显著提高了推理的实时性和准确性，同时将延迟大幅度降低。
### Conclusion
MPS在数学推理任务和语音对话任务上分别达到了92.8%和82.5的准确率，显著优于现有的方法，成功闭合了高质量推理与实时交互之间的差距。
## 417. `cs.CL` - WUGNECTIVES：来自论证连词的语言模型对新型实体的推理 [PDF](https://arxiv.org/pdf/2510.09556), [HTML](https://arxiv.org/abs/2510.09556)
### Authors
Daniel Brubaker,William Sheffield,Junyi Jessy Li,Kanishka Misra
### Background
语言模型在预测连接两个论点的论证连接词方面表现出色，这部分依赖于世界知识的作用。以往的研究通常重点在于语言模型预测连接词的能力，本研究则反过来探讨论证连接词能否帮助语言模型了解世界知识的问题。为此，研究者构建了一个包含8,880条刺激的WUGNECTIVES数据集，来评估语言模型在连接词链接的上下文中对新实体的推理能力。
### Innovation
本研究创新性地构建了一个称为WUGNECTIVES的数据集，旨在评估语言模型对由连接词链接的上下文中新实体的推理能力。通过研究17种不同规模和训练策略的语言模型，发现调整语言模型以表现出推理行为可以显著提高其对大多数组连接词的推理能力。同时，研究还揭示了不同类型的连接词对语言模型性能的广泛影响，尤其是表示让步意义的连接词对所有模型都构成了挑战。这些发现为进一步研究语言提示的功能角色奠定了基础。
### Conclusion
研究结果为更细致地探究语言模型捕捉语言线索的功能角色指明了方向。研究者已将WUGNECTIVES数据集发布在指定的URL上。
## 418. `cs.CL` - AutoPR: 让我们自动化你的学术推广！ [PDF](https://arxiv.org/pdf/2510.09558), [HTML](https://arxiv.org/abs/2510.09558)
### Authors
Qiguang Chen,Zheng Yan,Mingda Yang,Libo Qin,Yixin Yuan,Hanjing Li,Jinhao Liu,Yiyan Ji,Dengyun Peng,Jiannan Guan,Mengkang Hu,Yantao Du,Wanxiang Che
### Background
由于经过同行评审的研究文献数量激增，学者们越来越依赖于社交平台来发现研究，并且作者们也在投入大量努力来促进自己的作品，以确保其可见性和引用率。为了简化这一过程并减少人工努力的依赖，我们引入了Automatic Promotion (AutoPR) 这一新的任务，它可以将研究论文转化为准确、吸引人并及时的公共内容。为了能够进行严格的评估，我们发布了PRBench基准，该基准关联了512篇经过同行评审的文章和高质量的推广帖子，评估系统在三个维度上的表现：准确性和语气（Fidelity）、受众定位和吸引力（Engagement）、时间及渠道优化（Alignment）。
### Innovation
我们引入了一个多智能体框架PRAgent来自动化AutoPR，分为三个阶段：多模态内容提取与准备、协作合成以产出精炼的输出，以及特定平台的适应性优化来最大化覆盖范围。与直接使用大语言模型（LLM）的管道相比，在PRBench基准上进行的测试表明，PRAgent显示出显著的改进，包括总观看时间增加了604%，点赞数增加了438%，并且整体参与度至少提高了2.9倍。删除法研究表明，平台建模和目标推广是这些收益的最大贡献者。
### Conclusion
这些结果将AutoPR定位为一个可行且可衡量的研究问题并提供了一个可扩展且具有影响力的学术沟通自动化路线图。
## 419. `cs.CL` - Prompting Test-Time Scaling 是一种强大的大型语言模型推理数据增强方法 [PDF](https://arxiv.org/pdf/2510.09599), [HTML](https://arxiv.org/abs/2510.09599)
### Authors
Sondos Mahmoud Bsharat,Zhiqiang Shen
### Background
大型语言模型（LLMs）在提供链式思维示例后表现出令人印象深刻的推理能力，但构建大型推理数据集仍然耗时且资源密集。论文介绍了Prompting Test-Time Scaling（P-TTS），这是一种简单而有效的推理时数据增强策略，通过微调提高LLM的推理能力。P-TTS仅利用90个手动选择的推理实例，并在测试时系统地变化示例增强，通过有原则的指令提示强度来合成多样化的推理轨迹背景。
### Innovation
P-TTS通过最小的标注成本来有效探索推理模式的潜在空间，提高LLM问题解决能力。这种方法在多个数学推理基准测试中表现出优越性能，对于多种不同的问题集，P-TTS的模型在准确率上实现了显著提升。此外，P-TTS还能增强LLM在跨领域推理中的零样本泛化能力。
### Conclusion
P-TTS为在资源受限或快速发展领域内唤起LLM推理提供了一种实用且低成本的方法，进一步释放了LLM的推理潜力和能力。
## 420. `cs.CL` - Dyna-Mind: 从经验中学习模拟以提高AI代理性能 [PDF](https://arxiv.org/pdf/2510.09577), [HTML](https://arxiv.org/abs/2510.09577)
### Authors
Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao
### Background
近期的推理模型在数学和编程等领域取得了显著的进展，但在长时间交互任务如网页导航和电脑/手机使用等方面的表现却不如人类专家。基于人类认知领域的研究，论文提出了当前的人工智能代理需要“间接的尝试与错误”——具备能够在行动前的心理前瞻模拟能力，以增强其理解和性能。作者介绍了一个名为Dyna-Mind的两阶段训练框架，该框架旨在教导语言模型（L）在推理过程中整合模拟。第一阶段引入了生成推理时序（ReSim）方法，通过环境交互获取的经验构建扩展搜索树，从而为代理提供了一种符合真实世界动态的推理方式，使它能够预见未来的状态。第二阶段提出了Dyna-GRPO方法，通过在线强化学习利用结果奖励和中间状态反馈来进一步加强代理的模拟和决策能力。
### Innovation
论文提出了一个名为Dyna-Mind的两阶段训练框架，旨在教授语言模型在推理过程中整合模拟能力。第一阶段使用生成推理时序（ReSim）方法，将复杂的现实世界动态嵌入代理的推理中；第二阶段通过在线强化学习（Dyna-GRPO）利用结果奖励和中间状态反馈来进一步训练模型。这种方法在合成基准（如Sokoban和ALFWorld）和真实基准（如AndroidWorld）上测试，实验结果表明该方法使得代理获得了更好的政策表现。
### Conclusion
研究结果表明，模拟在使AI代理更有效地规划和行动中扮演着核心角色。这些发现使人们认识到模拟对于提升代理在复杂和更具挑战性的环境中表现的重要性。
## 421. `cs.CL` - 动态压力检测：语音中压力时序进展建模研究 [PDF](https://arxiv.org/pdf/2510.08586), [HTML](https://arxiv.org/abs/2510.08586)
### Authors
Vishakha Lall,Yisi Liu
### Background
在高压环境中，从语音中检测心理压力至关重要。尽管先前的研究利用声学特征进行压力检测，但大多数方法将压力视为静态标签。本文将压力建模为一种受历史情感状态影响的、随时间演变的现象。
### Innovation
提出了一种动态标签策略，从情感标签中推导出细粒度的压力注释，并引入了基于交叉注意力的序列模型（包括单向LSTM和Transformer编码器），来捕捉压力的时序进展。该方法在MuSE（+5%）和StressID（+18%）上超过了现有基线，并对自定义的现实世界数据集具有良好的泛化能力。
### Conclusion
实验结果突显了将压力建模为动态构念在语音中的价值。
## 422. `cs.CL` - 基于发音信息的自动语音识别：通过辅助语音反转和交叉注意力融合集成发音特征 [PDF](https://arxiv.org/pdf/2510.08585), [HTML](https://arxiv.org/abs/2510.08585)
### Authors
Ahmed Adel Attia,Jing Liu,Carol Espy Wilson
### Background
先前的研究已经调查了发音特征作为自动语音识别（ASR）的补充表示的应用，但主要局限于浅层声学模型。本文回顾了发音信息在深度学习时代的应用，并提出了一种框架，该框架不仅将发音表示作为辅助任务，还作为伪输入到识别模型中。
### Innovation
本文引入了一种新的方法，通过辅助语音反转任务预测发音特征，并将这些预测的发音特征作为查询流在交叉注意力模块中注入模型，使用声学嵌入作为键和值。实验结果表明，在 LibriSpeech 数据集上，该方法在强基于变换器的基本模型之上提供了持续的改进，特别是在资源有限的情况下。
### Conclusion
研究表明当与现代架构结合时，发音特征可以为自动语音识别提供有意义的好处，即使之前这些特征在自动语音识别研究中被忽视了。
## 423. `cs.CL` - 能量驱动导向：在大型语言模型中减少拒绝请求 [PDF](https://arxiv.org/pdf/2510.08646), [HTML](https://arxiv.org/abs/2510.08646)
### Authors
Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li
### Background
大型语言模型的安全对齐面临一个关键挑战：当前对齐技术往往只专注于提高对有害提示的安全性，导致模型变得过于谨慎，拒绝回答无害的提示。因此，安全对齐的关键目标是提高安全性的同时减少错误拒绝率。
### Innovation
本文介绍了一种名为能量驱动导向 (EDS) 的新框架，这是一种无需微调的干预方法。通过在推理时动态更改模型内部的隐藏状态，使模型生成更合适的结果，而不需要修改其权重。这种方法将行为控制与模型的核心知识分离，提供了一个灵活且计算开销较小的解决方案。
### Conclusion
实验结果表明，我们的方法成功实现了这一目标：它显著降低了错误拒绝率。例如，在ORB-H基准测试中，将合规性从57.3%提高到82.6%，同时保持了基础的安全性能。我们的工作为构建在保证低错误拒绝率和高安全性方面实现的LLMs提供了一种有效的范式。
## 424. `cs.CL` - 注意力机制中归一化方法的局限性 [PDF](https://arxiv.org/pdf/2508.17821), [HTML](https://arxiv.org/abs/2508.17821)
### Authors
Timur Mudarisov,Mikhail Burtsev,Tatiana Petrova,Radu State
### Background
本文探讨了注意力机制中的归一化限制。作者从理论框架出发，提出了识别模型选择能力和几何分离能力的方法，并对Softmax缩放下的token向量间的距离和分离标准进行了明确的界限分析。通过使用预训练的GPT-2模型的实验，验证了理论结果，并分析了注意力机制的关键行为。研究表明，随着选择的token数量增加，模型区分有价值token的能力下降，常导致均匀的选择模式。还展示了在Softmax归一化下梯度敏感性在训练过程中面临的挑战，尤其是在低温设置下。这些发现增强了对基于Softmax的注意力机制的理解，并推动了未来注意力架构中更稳健的归一化和选择策略的需求。
### Innovation
本文的创新点在于建立了理论框架，明确了token向量在Softmax缩放下的距离和分离标准，并通过实验验证了理论结果，指出了随着选择token数量增加，模型区分token能力下降的现象，以及Softmax归一化下梯度敏感性在训练过程中的挑战，尤其是在低温设置下。这推动了对未来注意力架构中更稳健的归一化和选择策略的需求。这些发现增强了对基于Softmax的注意力机制的理解。
### Conclusion
本文研究了注意力机制中的归一化限制，通过理论分析和实验验证，表明随着选择的token数量增加，模型区分token的能力下降，通常会趋向于均匀的选择模式。此外，模型的梯度敏感性在Softmax归一化下，尤其是在低温设置下，存在训练挑战。这些发现为未来注意力机制的稳健归一化和选择策略提供了理论支持和实际指导。
## 425. `cs.CL` - BaldWhisper：剪枝和层合并加速的 Whisper [PDF](https://arxiv.org/pdf/2510.08599), [HTML](https://arxiv.org/abs/2510.08599)
### Authors
Yaya Sy,Christophe Cerisara,Irina Illina
### Background
在资源匮乏的语言环境下，修剪大型预训练变换器是一个挑战，因为通常需要大量的重新训练数据来恢复性能。例如，Distill-Whisper通过修剪40%的Whisper并进行21,000小时的重新训练来获得性能，这远远超出了大多数语言可用的数据量。为了使Whisper在数据稀缺的边缘设备上更轻便、更快捷，该研究聚焦于只有32小时语音转文字数据的班巴拉语。与词汇修剪不同，由于班巴拉语讲话者频繁地切换语言，该方法不适用于词汇修剪。因此，研究提出了新的修剪方案，使用低秩分解和特征蒸馏压缩嵌入，而非移除层，而是合并层以减少性能损失。
### Innovation
该研究提出了一个新的修剪配方，通过低秩分解和特征蒸馏压缩嵌入，而不是使用不适用于班巴拉语频繁代码切换问题的词汇修剪方法。为了减少性能损失，该方法没有移除层，而是将它们合并。最终的模型保留了原始性能的90%，体积缩小了48%，在MacBook Air M1上执行速度提升了2.15倍。
### Conclusion
该研究通过压缩嵌入和合并层提出了新的修剪技术，使Whisper在不具备丰富语料的资源少的语言中，变得轻便且运行速度快。这种方法不仅适用于班巴拉语，理论上也可以应用于其他资源匮乏的语言环境，以更高效地在边缘设备上使用预训练变换器。
## 426. `cs.CL` - 何时进行推断：针对vLLM的语义路由 [PDF](https://arxiv.org/pdf/2510.08731), [HTML](https://arxiv.org/abs/2510.08731)
### Authors
Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen
### Background
大型语言模型（LLMs）在引入推理模式（如链式思考和推理时的扩展）后展示出显著的准确度提升。然而，推理也会带来明显的推理延迟和标记使用上的成本增加，这些成本在环境和财务方面十分可观，对于许多简单的提示并非必需。本文讨论了语义路由的概念，该路由能够根据查询的推理需求分类并仅在有益的场景中才应用推理，从而实现准确度、响应延迟和标记消耗的有效平衡.
### Innovation
本文提出了一种语义路由方法，该方法能够基于查询的推理需求来分类查询，并仅在有益的情况下才应用推理，取得了在MMLU-Pro基准测试中准确度提升了10.2个百分点，响应延迟减少了47.1%，标记消耗减少了48.5%的功效，这是相较于直接使用vLLM进行推理而言的.
### Conclusion
语义路由提供了一个有效的机制，能够在开源LLM服务系统中实现准确性和效率之间的平衡.
## 427. `cs.CL` - 大型语言模型在机器辅助解决用户意图方面的比较分析 [PDF](https://arxiv.org/pdf/2510.08576), [HTML](https://arxiv.org/abs/2510.08576)
### Authors
Justus Flerlage,Alexander Acker,Odej Kao
### Background
大型语言模型（LLMs）已发展成为自然语言理解和用户意图解析的重要工具，支持翻译、总结等任务，甚至现在还用于复杂工作流程的协调。这一进步标志着从传统的基于图形用户界面（GUI）的用户界面向基于语言的交互范式的转变。用户可以使用自然语言表达其目标，使LLMs能够跨多个应用程序实现动态和上下文相关的操作。然而，现有实现经常依赖云托管的专有模型，这在隐私、自主性和可扩展性方面引入了限制。要使基于语言的交互成为真正强大和值得信赖的界面范式，局部部署不仅是便利的，而且是迫切需要的。这种局限性强调了评估可局部部署、开源和开放访问的LLMs作为未来基于意图操作系统的基础组件的可行性的重要性。本文即是对此进行了研究，并探讨了几种开源和开放访问模型，在机器辅助解决用户意图方面的功能，并将其与OpenAI的自有GPT-4系统进行了比较分析，以评估其在生成各种用户意图的工作流方面的能力。
### Innovation
该研究对几种开源和开放访问的LLMs进行了评价，旨在解决局部部署在隐私、自主性和可扩展性方面的问题。研究采用了一种与专有GPT-4系统进行工作流生成任务的比较分析方法，探索开源LLMs作为下一代操作系统中自主、局部可执行组件的可行性和性能权衡。这项研究为人工智能基础设施的去中心化和民主化提供了实证见解，预示了一个通过嵌入本地智能实现更无缝、更具适应性和隐私意识的用户-设备交互未来。
### Conclusion
这项研究为评估开源LLMs在局部部署中的性能以及未来将在基于意图的操作系统中的实用性提供了实证支持。研究结果表明，开源LLMs可以作为下一代操作系统的自主、局部可执行组件，推动用户-设备交互更加无缝、适应性更强和隐私保护。这项研究的结果还促进了对未来AI基础设施的更广泛的讨论，推动了AI民主化的进程。
## 428. `cs.CL` - 优化快速电子商务交付——考虑生成路径的定性评估 [PDF](https://arxiv.org/pdf/2510.08671), [HTML](https://arxiv.org/abs/2510.08671)
### Authors
Milon Bhattacharya,Milan Kumar
### Background
印度电子商务市场预计快速增长，其中最后一英里交付占据了近一半的运营成本。尽管基于车辆路线问题（VRP）的解算器广泛用于交付计划，但由于非结构化的地址、不完整的地图信息以及在距离估算中的计算限制，这些解算器在实际应用中的有效性有限。因此，本文研究提出了一种框架，利用大型语言模型（LLMs）来评估VRP生成的路径是否符合政策标准，使物流运营商能够评估和优先考虑更高效的配送计划。通过对400个案例的生成、标注和评估，研究发现开源LLMs在识别路径问题方面准确率为79%，而专有推理模型的准确率可达86%。研究结果表明，基于LLMs的VRP生成路径评估可以超越传统基于距离和时间的指标，有效且具有可扩展性，这对于提高印度等发展中国家的最后一英里物流的成本效率、交付可靠性和可持续性具有重要意义。
### Innovation
研究提出了一种框架，利用大型语言模型（LLMs）来评估VRP生成的路径是否符合政策标准，这一方法超越了传统的基于距离和时间的指标，能够有效提高成本效率、交付可靠性和可持续性，尤其是在印度等发展中国家。在实际应用中，开源LLMs在识别路径问题方面表现良好，准确率为79%，而专有推理模型的准确率可达86%。这种方法证明了对最后一英里物流优化的有效性和实用性。
### Conclusion
本文的研究表明，基于大型语言模型的VRP生成路径评估可以用来优化快速电子商务的交付，并且超越了传统基于距离和时间的指标。这种方法对提高成本效率、交付可靠性和可持续性具有重要意义，尤其是在印度等发展中国家的应用。它提供了一种新的、高效的评估方法，有助于物流行业的进一步发展。
## 429. `cs.CL` - 探索大型语言模型在联邦学习中跨客户端训练数据的记忆 [PDF](https://arxiv.org/pdf/2510.08750), [HTML](https://arxiv.org/abs/2510.08750)
### Authors
Tinnakit Udsa,Can Udomcharoenchaikit,Patomporn Payoungkhamdee,Sarana Nutanong,Norrathep Rattanavipanon
### Background
联邦学习（FL）使得不同客户端可以在不共享原始数据的情况下进行协作训练，但仍然存在训练数据记忆的风险。现有的FL记忆检测技术主要针对单个样本进行，未能充分考虑到跨样本记忆的潜在细微风险。虽然集中学习（CL）中的最新研究引入了细粒度的方法来评估训练数据中所有样本的记忆情况，但这些方法假设可访问所有数据，无法直接应用于FL场景。为了弥合这一差距，本文提出了一种框架，通过在整个客户端之间进行细粒度的跨样本记忆测量来量化FL中客户端内的和客户端间的记忆情况。基于此框架，我们进行了两项研究：一是测量跨客户端的微妙记忆，二是探讨影响记忆的关键因素，包括解码策略、前缀长度和FL算法。研究表明，尤其是在客户端内部数据的记忆方面，FL模型的记忆现象更为显著，记忆情况受到训练和推理因素的影响更为明显。
### Innovation
本文提出了一个框架，通过细粒度的跨客户端样本记忆测量来量化联邦学习中客户端内部和客户端间的记忆情况，填补了集中学习和联邦学习在记忆检测方面的空白。研究结果表明，FL模型确实存在对客户端数据的记忆现象，特别是在客户端内部数据的记忆情况更为明显。同时，研究还明确了影响记忆的关键因素，包括解码策略、前缀长度和联邦学习算法等。
### Conclusion
实验结果揭示了联邦学习模型确实存在客户数据记忆的现象，尤其是客户内部数据的记忆更为显著，记忆情况受到训练和推理因素的影响更为明显。
## 430. `cs.CL` - BigCodeArena：通过执行揭示更可靠的代码生成人类偏好 [PDF](https://arxiv.org/pdf/2510.08697), [HTML](https://arxiv.org/abs/2510.08697)
### Authors
Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra
### Background
现有的众包模型评估平台能够从人类视角进行实时评估，以衡量模型的回复质量。然而，对于编程领域，手动评估由大规模语言模型（LLM）生成的内容非常具有挑战性，因为这需要理解大量的原始代码，并且需要有意识地模拟代码执行过程。因此，研究者引入了BigCodeArena，这是一个基于全面且即时执行环境的开放人类评估平台，用于代码生成。BigCodeArena基于Chatbot Arena构建，可以运行LLM生成的代码，允许人类与执行过程及结果进行互动。该平台收集了来自10种广泛使用的LLM的14,000多个以代码为中心的对话会话，涵盖10种语言和8种执行环境，从这些会话中识别出超过4,700个多轮聊天样本，这些样本展示了两两之间的人类偏好。进一步的分析揭示了在任务、语言和框架等细粒度领域中对LLM的未充分探索的偏好。
### Innovation
提出了BigCodeArena，这是一种基于全面而即时执行环境的开放人类评估平台，用于代码生成。BigCodeArena利用收集到的4,700个聊天样本，创建了两个基于数据的基准测试BigCodeReward和AutoCodeArena。BigCodeReward通过处理这些聊天样本，评估奖励模型与人类偏好的一致性。研究还提出了一种自动Elo评分基准AutoCodeArena，无需人类参与即可评估LLM的代码质量。研究结果表明，尽管存在新兴模型的竞争，仍旧有几种专有LLM（如GPT-5、Claude-Sonnet-4和Claude-Opus-4）在代码生成性能上排名靠前。
### Conclusion
BigCodeArena通过运行LLM生成的代码提供了更可靠的代码生成人类偏好数据。BigCodeReward和AutoCodeArena两个基准测试展示了LLM在编程任务上的表现，特别是一些先进的专有LLM仍然在代码生成中表现出色。
## 431. `cs.CL` - 使用大语言模型构建鲁棒的启发式算法设计 [PDF](https://arxiv.org/pdf/2510.08755), [HTML](https://arxiv.org/abs/2510.08755)
### Authors
Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani
### Background
研究指出，通过将大语言模型（LLMs）应用到启发式算法设计中，可以生成更稳健和高效的启发式方法。然而，单纯依靠LLMs可能无法充分理解和改进启发式算法的性能问题。因此，需要结合能够解释为什么启发式算法性能不佳以及如何改进它们的工具，来增强启发式算法的鲁棒性和性能。
### Innovation
本文提出，通过增强使用大语言模型进行启发式设计的方法，结合解释性能不佳原因的工具和改进建议，可以生成更稳健的启发式算法。尤其强调通过将LLM暴露在启发式算法表现不佳的实例中，并解释这些情况的原因，以及专门针对输入空间中特定区域进行设计，可以显著提高算法的鲁棒性。实验表明，与现有的FunSearch方法相比，生成的启发式算法在最坏情况下的性能提高了约28倍，并且平均性能也有所改进，且保持了运行时间。
### Conclusion
研究证明，结合大语言模型和解释工具可以产生比现有技术更稳健的启发式算法，这些算法具有更好的最坏情况性能，平均性能也有提高，且保持了良好的运行时间。
## 432. `cs.CL` - Struc-EMB: 结构感知编码在语言嵌入中的潜力 [PDF](https://arxiv.org/pdf/2510.08774), [HTML](https://arxiv.org/abs/2510.08774)
### Authors
Shikun Liu,Haoyu Wang,Mufei Li,Pan Li
### Background
大型语言模型（LLMs）中生成的文本嵌入已成为许多应用的基础。然而，这些模型通常仅处理原始文本，忽略了诸如超链接或引用等丰富的结构信息，这些结构信息在很多实际数据集中提供了关键的语境信息。本文提出了一种新的范式，通过将这些结构关系直接集成到LLM的内部编码过程中来生成结构感知的文本嵌入。
### Innovation
研究了两种主要的过程中的方法：顺序串联和并行缓存。通过广泛的零样本实验，包括检索、聚类、分类和推荐任务，证明了结构感知的方法在所有任务中都优于仅基于文本和后处理的基线。提出了两个有效的技术，用于解决噪声结构数据的问题：上下文蒸馏和语义平衡，以进一步提高模型性能。
### Conclusion
这项工作提供了结构感知编码的首个全面分析，为构建更强大和上下文感知的嵌入模型提供了一个蓝图。
## 433. `cs.CL` - 基于设计的方法解决文本因果推理问题：语言模型太大了吗？ [PDF](https://arxiv.org/pdf/2510.08758), [HTML](https://arxiv.org/abs/2510.08758)
### Authors
Graham Tierney,Srikar Katta,Christopher Bail,Sunshine Hillygus,Alexander Volfovsky
### Background
许多社会科学问题探究语言特性如何因果地影响受众的态度和行为。由于文本特性往往是交织在一起的（例如，愤怒的评论会使用粗俗语言），因此必须控制潜在的混杂因素以隔离因果效应。最近的文献提出使用大型语言模型（LLMs）来学习成功预测治疗和结果的文本的潜在表示。然而，由于治疗是文本的一部分，这些深度学习方法存在学习实际上编码治疗本身的潜在表示的风险，从而引起重叠偏差。
### Innovation
我们提出了一种新的实验设计，该设计解决了潜在混杂因素，避免重叠问题，并未预后调整依赖性地估计治疗效应。该设计被应用于评估谦逊表达在政治通信中的说服力实验。从方法论上讲，我们证明了基于LLM的方法在我们的实际文本和实验结果中的表现甚至不如简单的词汇袋模型。从实质性角度讲，我们成功地分离了谦逊表达对政治声明感知说服力的因果效应，为社交媒体平台、政策制定者和社会科学家提供了新的见解.
### Conclusion
我们提出了一种新的实验设计，以解决文本中的潜在混杂因素，避免深度学习方法的重叠偏差，并且这种设计能够更准确地评估治疗效应。在应用该设计的实验中，我们发现基于LLM的方法在结果上不如简单的词汇袋模型，但这一实验方法为我们提供了关于表达谦逊在政治陈述中的影响的新见解。
## 434. `cs.CL` - McMining：学生代码中误解的自动化发现 [PDF](https://arxiv.org/pdf/2510.08827), [HTML](https://arxiv.org/abs/2510.08827)
### Authors
Erfan Al-Hossami,Razvan Bunescu
### Background
在学习编程时，学生经常会形成各种编程语言概念的误解。这些误解不仅可能导致代码错误或效率低下，还可能减缓相关概念的学习进度。针对这一问题，本研究致力于从学生代码样本中挖掘编程误解的任务，即MCMining任务。为了解决MCMining任务的训练和评估问题，研究团队开发了一个包含大量代码样本的可扩展基准数据集，这些样本中都表现出了各种误解。
### Innovation
本研究提出了MCMining任务，并开发了一种可扩展的基准数据集及大量代码样本来表现这些误解，从而能够在学生代码中发现误解。此外，研究还引入了两个基于大语言模型（LLM）的MCMining方法，通过广泛的评估证明Gemini、Claude和GPT家族的模型对于发现学生代码中的误解非常有效。
### Conclusion
研究通过开发基准数据集和基于大语言模型的方法，证明了MCMining技术在发现学生代码中的误解方面的有效性，从而有助于改进编程教育和提高代码质量。
## 435. `cs.CL` - 每个人更喜欢人类作家，包括AI [PDF](https://arxiv.org/pdf/2510.08831), [HTML](https://arxiv.org/abs/2510.08831)
### Authors
Wouter Haverals,Meredith Martin
### Background
随着人工智能写作工具的普及，理解人类和机器如何评估文学风格变得尤为重要。在文学领域，客观标准难以界定，且评估往往是主观的。文章通过控制实验，使用雷蒙德·库南的《风格练习》（1947年）作为样本，研究了评估者在三种不同情境下的归因偏差。
### Innovation
研究首次比较了人类和人工评估者在审美判断中的归因偏差，揭示了一种系统性的偏好人类作品的现象。研究人员发现，无论是人类还是AI模型，偏好人类创作的作品，其中AI模型的偏好程度更强。研究还发现，归因标签会影响评估标准的反转，即同样的特征基于作者身份会得到相反的评价，这暗示AI模型可能在训练过程中吸收了人类对人造创造力的文化偏见。
### Conclusion
研究揭示了AI系统不仅复制而且放大了人类中这种倾向于偏好人类创作的倾向。无论使用哪种AI生成内容，当被标注为“AI生成”时，AI系统都会系统地贬低创意内容的价值。研究结果强调了需要深入理解人类和机器在文学评估中的主观性和客观性差异，以及可能存在的文化偏见。
## 436. `cs.CL` - 时间感知特征选择：稳定稀疏自编码器训练的自适应时间掩码 [PDF](https://arxiv.org/pdf/2510.08855), [HTML](https://arxiv.org/abs/2510.08855)
### Authors
T. Ed Li,Junyu Ren
### Background
了解大型语言模型的内部表示对于确保其可靠性和安全性至关重要。现有的稀疏自编码器（SAEs）方法，如TopK和JumpReLU SAEs，存在特征吸收问题，即特征（或神经元）互相吸收以最小化$L_1$惩罚，这使得一致性地识别和分析模型行为变得困难。
### Innovation
本文介绍了一种名为自适应时间掩码（ATM）的新颖训练方法，该方法通过跟踪激活幅度、频率和重构贡献来动态调整特征选择，并据此计算随时间变化的重要性评分。ATM采用基于统计阈值的概率性掩码机制，创造了一种更自然的特征选择过程。实验表明，ATM在Gemma-2-2b模型上实现了比现有方法如TopK和JumpReLU SAEs更低的吸收分数，同时保持了优秀的重构质量。
### Conclusion
ATM是学习具有稳定性和可解释性的神经网络特征的原理性解决方案，为更可靠地分析模型提供了基础。
## 437. `cs.CL` - ReviewerToo: AI 是否应该加入程序委员会？未来同行评审的展望 [PDF](https://arxiv.org/pdf/2510.08867), [HTML](https://arxiv.org/abs/2510.08867)
### Authors
Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal
### Background
同行评审是科学研究出版的基石，但它存在不一致性、审稿人主观性以及扩展性的挑战。本文分析了这一现状并提出了一个模块化框架——ReviewerToo，旨在通过系统性和一致性评估补充人类判断，支持AI辅助同行评审。
### Innovation
提出了ReviewerToo模块化框架，用于研究和部署AI辅助同行评审，以系统实验的形式支持专门的审稿人角色和结构化的评估标准，可部分或完全融入真实会议工作流程。此外，通过精细化整理自ICLR 2025的1,963篇论文，实验结果显示，对于论文分类为接受/拒绝的任务，其准确率为81.8%，接近人类评审员的平均准确率83.9%。
### Conclusion
我们的研究揭示了AI审稿人在某些领域（如事实核查、文献覆盖）的卓越表现及在某些领域（如评估方法新颖性与理论贡献）的挑战，说明了人类专业知识的持续需要。基于这些发现，我们提出了如何将AI整合到同行评审流程中的指导意见，展示AI如何增强一致性和覆盖面，同时保留复杂评估判断给领域专家。研究奠定了可扩展的混合同行评审体系的基础，适应科学出版的增长。
## 438. `cs.CL` - ControlAudio: 通过渐进扩散建模解决受文本指导、时间指示和可听声音生成 [PDF](https://arxiv.org/pdf/2510.08878), [HTML](https://arxiv.org/abs/2510.08878)
### Authors
Yuxuan Jiang,Zehua Chen,Zeqian Ju,Yusheng Dai,Weibei Dou,Jun Zhu
### Background
近年来，基于文本到语音（TTA）生成的研究已经探索了精细控制信号的应用，如精确的时间控制或清晰的语音内容。然而，由于数据稀缺的限制，这些方法在大规模生成上的性能仍然受到制约。
### Innovation
本文将可控的 TTA 生成重新表述为一个多任务学习问题，并引入了一种渐进性扩散建模的方法，称为 ControlAudio。首先，本文提出了一种数据构建方法，涵盖注释和模拟，以扩展文本、时间、音素条件信息。其次，在模型训练阶段，预训练了一个大规模的扩散变压器（DiT），实现可扩展的 TTA 生成，然后逐步引入时间、音素特征，以统一语义表示，提高可控性。最后，在推理阶段，提出了一种逐步引导生成方法，逐步强调更多细节信息，与扩散变压器的逐步采样本质相一致。实验表明，ControlAudio 在时间准确性、语音清晰度等方面达到了最先进的性能，显著优于现有方法的客观和主观评估。
### Conclusion
ControlAudio 在时间准确性、语音清晰度等方面达到了最先进的性能，显著优于现有方法。该方法通过多任务学习和逐步扩散模型来解决可控的 TTA 生成问题，进一步提高了生成质量的可控性和性能。
## 439. `cs.CL` - 在多模态推理模型中释放感知时间缩放的潜能 [PDF](https://arxiv.org/pdf/2510.08964), [HTML](https://arxiv.org/abs/2510.08964)
### Authors
Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu
### Background
近年来，尤其是在利用强化学习进行验证奖励推理时，在推理阶段进行缩放的方法显著提升了大型视-语言模型（LVLM）的推理能力。尽管这种方法已在多模态推理中得到了应用，但对于视觉感知的影响尚不明确。为了弥补这一差距，研究者们引入了DisTANCE，一个以感知为中心的视觉估计基准测试。评测结果显示，LVLM的估计精度有限，而推理阶段的缩放只能带来微小的提升。
### Innovation
研究提出了感知时间缩放（PTS）这一创新的范式，它鼓励富有的感知过程，并将复杂的感知问题分解为中间的可处理子问题，以此来使感知过程能够更好地适应和从推理阶段的缩放中获益。结合强化学习技术，PTS 显著提高了感知精度，在 DisTANCE 上将高精度性能从 8.0% 提高到了 64.7%，并能够很好地泛化到跨域任务。有趣的是，尽管 PTS 数据完全是合成的，但将它们与数学推理数据结合使用，仍然能够在推理和现实世界的感知基准测试中获得一致的改进。
### Conclusion
研究发现，PTS 通过引入更多与感知相关的标记和增加模型对图像标记的关注度，显著提高了感知精度。研究成果已对其代码和数据进行公开发布。
## 440. `cs.CL` - HES-SQL：基于结构框架指导的高效文本到SQL混合推理 [PDF](https://arxiv.org/pdf/2510.08896), [HTML](https://arxiv.org/abs/2510.08896)
### Authors
Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun
### Background
本文介绍了一种新型混合训练框架HES-SQL，通过将思考模式融合监督微调（SFT）与组相对策略优化（GRPO）相结合，促进文本到SQL生成任务的发展。该框架通过干预生成的SQL查询与理想SQL结构之间的一致性偏好、生成计算效率高的SQL查询以及思考模式完成的自我蒸馏过程，引入了三项创新技术，旨在提高SQL查询的准确性与执行效率，特别是在单一用户控制条件下，在MySQL 8.0和SQLite 3.42上的实验结果显示了其潜力。
### Innovation
该论文提出了三项关键创新：(1) 骨架完整性评分机制，强化生成查询与最优SQL结构之间的一致性偏好；(2) 查询延迟感知奖励系统，促进生成计算效率高的SQL查询；(3) 自我蒸馏过程，防止模型推理能力的弱化。这些创新共同促进混合推理模型在推理和非推理模式之间的切换，提高了SQL查询的准确性和执行效率。
### Conclusion
HES-SQL框架通过执行导向的强化学习，在平衡语义准确性和计算效率方面建立了新的范式，它在BIRD基准和KaggleDBQA上的执行准确率为79.14%和54.9%，查询延迟接近于生成查询在数据库管理系统（DBMS）中的端到端执行时间，平均多次运行来减少方差。该方法对开发稳健的自然语言数据库接口具有重要意义，并可扩展应用于需要优化正确性和效率的更广泛的结构生成任务。
## 441. `cs.CL` - 视觉标记的先验不确定性对于大型视觉语言模型中物体幻觉的作用 [PDF](https://arxiv.org/pdf/2510.09008), [HTML](https://arxiv.org/abs/2510.09008)
### Authors
Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun
### Background
大型视觉语言模型（LVLMs），将视觉编码器（VE）与大型语言模型结合，已经在各种任务中取得了显著的成功。然而，LVLMs仍然面临诸如物体幻觉等关键挑战，即生成输入图像中不存在的物体的描述。研究表明，视觉编码器中的不确定视觉标记可能是导致物体幻觉的关键因素。该研究通过统计分析发现，具有高先验不确定性的视觉标记与物体幻觉的发生正相关。早期视觉编码器层中，大代表偏离小对抗扰动的视觉标记也表明了高先验不确定性。
### Innovation
本文提出了一种简单有效的策略，通过仅修改视觉编码器来减轻物体幻觉。该方法包括一种带对抗扰动的代理方法，用于高效识别不确定的视觉标记，以及一种在视觉编码器中间层的自我注意过程中掩蔽这些不确定的视觉标记的方法，以抑制它们对视觉编码的影响，从而缓解幻觉现象。实验结果表明，本文方法显著减少了大型视觉语言模型中的物体幻觉，并且可以与其他技术协同工作。
### Conclusion
研究成果表明，通过针对不确定的视觉标记进行干预，LVLMs中的物体幻觉现象可以得到有效缓解。该策略具有较低的计算成本，并且能够与现有技术结合使用，进一步提高大型视觉语言模型的性能。
## 442. `cs.CL` - 语义条件调谐：在大型语言模型与图上下文融合中的知识图谱补全 [PDF](https://arxiv.org/pdf/2510.08966), [HTML](https://arxiv.org/abs/2510.08966)
### Authors
Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li
### Background
在知识密集型任务如知识图谱补全中，知识图谱(KG)融合与大型语言模型(LLM)结合是至关重要的。现有的主流方法，前缀调谐(即前缀微调)，简单地将知识嵌入与文本输入拼接在一起。然而，这种浅融合忽略了知识图谱内部丰富的语义关系，并给LLM带来了较大的隐含推理负担，需要将前缀与文本关联起来。
### Innovation
我们提出了语义条件调谐(Semantic-Condition Tuning, SCT)，这是一种新的知识注入范式，包含两个关键模块。首先，通过使用图神经网络从局部图上下文中提取一个由知识增强关系引导的上下文感知语义条件的语义图模块。然后，此条件被传递给条件适应性融合模块，该模块进一步通过两个参数化的投影器适配性地调节文本嵌入，从而使在特征层次上、知识意识下的深层次交互成为可能。最后，融合后的嵌入被提供给LLM进行微调。实验证明，SCT在知识图谱基准测试中显著优于前缀调谐和其它强大的基线。通过在LLM推理之前将语义图上下文融入输入表示中，SCT提供了更直接和更强的信号，允许更准确和稳健的知识推理。
### Conclusion
对知识图谱补全任务而言，语义条件调谐是一种通过在大型语言模型推理前将语义图上下文融入输入表示中，从而为LLM提供更直接和更强信号的新方法。这种方法在实验中显著优于前缀调谐及其他强大基线，展示了其在知识密集型任务上的优势。
## 443. `cs.CL` - Auto-scaling Continuous Memory for GUI Agent [PDF](https://arxiv.org/pdf/2510.09038), [HTML](https://arxiv.org/abs/2510.09038)
### Authors
Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang
### Background
本文探讨了如何赋予GUI代理可扩展的内存，以在不熟悉的界面和长时任务中实现通用性。先前的GUI代理将过往的轨迹压缩为文本标记，导致上下文长度增大并丢失关键的视觉线索（例如精确的部件大小和位置）。
### Innovation
本文提出了一种连续内存方法，通过VLM本身作为编码器将每个GUI轨迹编码成固定长度的连续嵌入序列，并将这些嵌入直接插入主干输入层，从而大幅减少了上下文成本并保留了详细视觉信息。新增的数据飞轮可自动扩展内存，通过搜索发现新环境，使用开源VLM合成任务，利用代理展开轨迹，并使用相同的VLM验证成功。
### Conclusion
使用此流程，我们收集了10多万条轨迹，花费约4000美元，并仅对内存编码器进行微调（使用LoRA在Q-Former上，参数比例1.2%）。在实际GUI基准中，我们的记忆增强代理在长时间和分布转移条件下能够持续提升成功率。Qwen-2.5-VL-7B与连续记忆相比，性能与最先进的闭源模型（如GPT-4o、Claude-4）相当。
## 444. `cs.CL` - 诊断和缓解自奖励RL中的系统偏差 [PDF](https://arxiv.org/pdf/2510.08977), [HTML](https://arxiv.org/abs/2510.08977)
### Authors
Chuyi Tan,Peiwen Yuan,Xinglin Wang,Yiwei Li,Shaoxiong Feng,Yueqi Zhang,Jiayi Shi,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li
### Background
Reinforcement Learning with Verifiable Rewards (RLVR)通过验证奖励来扩展大型语言模型的推理能力，但在继续数据扩展时受到有限标记样本的限制。而在没有标记数据的情况下，通过内在奖励(Reinforcement Learning with Intrinsic Rewards, RLIR)来进行强化学习，虽然允许可持续扩展，但其性能和稳定性仍然落后于RLVR。这一差距归因于系统偏差：模型倾向于高估其自信的回放，导致奖励估计偏差，并随训练进展而累积，从而导致不稳定训练。通过三个度量指标：$rho_{text{noise}}$、$rho_{text{selfbias}}$和$rho_{text{symbias}}$对这一偏差进行了表征。
### Innovation
本文提出了Reinforcement Learning with Ensembled Rewards (RLER)，该方法使用集成模型来汇总不同模型，并调整奖励插值和回放选择，以缓解系统偏差。广泛的实验表明，与RLIR相比，RLER提高了13.6%的性能，并且其性能仅比RLVR低3.6%。这使得RLER在无标签样本上实现稳定扩展，使其具有很高的应用价值。
### Conclusion
RLER通过整合多个模型和调整奖励插值与回放选择，成功解决了自奖励RL中的系统偏差问题，实现了在无标签数据集上的稳定扩展性能，其性能接近验证奖励RLVR的水平。
## 445. `cs.CL` - 多模态提示优化：为何不利用多种模态来增强MLLMs？ [PDF](https://arxiv.org/pdf/2510.09201), [HTML](https://arxiv.org/abs/2510.09201)
### Authors
Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）已经在自然语言处理领域取得了显著的成功，其多模态扩展（MLLMs）进一步增强了在图像、视频和其他模态上的能力。尽管如此，现有的提示优化方法仍然局限于文本，无法充分发掘MLLMs的潜力。
### Innovation
本文提出了新的多模态提示优化问题，扩展了传统的提示优化定义到采用文本和非文本提示的多模态空间。为此，我们提出了一种名为多模态提示优化器（MPO）的统一框架，可以通过保对齐更新来联合优化多模态提示，并且通过贝叶斯基础上的先前评估作为先验来指导候选提示的选择过程。总体而言，MPO 在跨文本、图像、视频甚至分子的多种模态中表现出色，优于现有的仅基于文本的优化方法。
### Conclusion
通过大量实验，我们证明了MPO 在多模态提示优化方面优于现有的文本仅方法，从而证实了多模态提示优化是充分释放MLLMs潜力的关键步骤。
## 446. `cs.CL` - 利用AI代理的网络搜索工具进行数据泄露 [PDF](https://arxiv.org/pdf/2510.09093), [HTML](https://arxiv.org/abs/2510.09093)
### Authors
Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz
### Background
大型语言模型（LLMs）现在被广泛用于执行复杂的任务，从自然语言处理到动态的工作流例如网络搜索。通过调用工具和检索增强生成（RAG）技术，LLMs能够处理和检索敏感的企业数据，这不仅增强了其功能，也增加了滥用的风险。随着LLMs越来越多地与外部数据源进行交互，间接提示注入攻击成为一种关键且不断发展的攻击途径，允许攻击者通过操纵输入来利用模型。研究通过系统地评估不同类型模型中的间接提示注入攻击，分析当前LLMs在这些攻击面前的脆弱性，探讨哪些因素（包括模型大小、制造商、特定实现等）会影响其脆弱性，以及哪些攻击方法最具效果。研究结果表明，即使是常见的攻击模式依然有效，揭示了模型防御中存在的持续弱点。
### Innovation
研究通过系统性评估的方式，揭示了间接提示注入攻击对当前LLMs的攻击效果及其影响因素，强调了增强训练流程、建立已知攻击向量的中心数据库以及统一测试框架的重要性，以提高模型的安全性，并促进将安全集成到LLM的核心设计中。
### Conclusion
当前的LLMs仍然存在长期威胁，需要强化训练程序以增强内在韧性，建立已知攻击向量的中心数据库以实现主动防御，并确保持续的安全验证。这些措施对于将安全集成到LLMs的核心设计中至关重要。
## 447. `cs.CL` - 从语音中无监督学习词典受限于表示而不是聚类 [PDF](https://arxiv.org/pdf/2510.09225), [HTML](https://arxiv.org/abs/2510.09225)
### Authors
Danel Adendorff,Simon Malan,Herman Kamper
### Background
研究零资源语言学的系统旨在在没有文本标签的情况下将语音分割为单词单元。尽管取得了进展，但生成的词汇库仍不完善。在理想情况下使用金标准词边界，研究探讨了性能受限于单词片段的表示还是受限于聚类方法的问题。
### Innovation
结合不同类型（连续/离散）和不同粒度（帧/单词级别）的自监督语音特征，以及不同的聚类方法（K均值、层级、图基）进行实验，发现使用动态时间规整和连续特征的图聚类方法效果最佳，而更快的替代方案则使用照常距离和平均连续特征，或编辑距离和离散单元序列。
### Conclusion
表现的主要限制因素是在同一单词类型内的片段表示变化，而不是聚类。
## 448. `cs.CL` - 使用多模态大规模语言模型和消费级摄像头诊断肩部疾病 [PDF](https://arxiv.org/pdf/2510.09230), [HTML](https://arxiv.org/abs/2510.09230)
### Authors
Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun
### Background
肩部疾病，如肩锁冻结（也称为黏连性囊炎），是全球影响人们健康的常见疾病，尤其在老年和从事重复肩部任务的工作者中发病率较高。在医疗资源稀缺的地区，实现早期准确的诊断极具挑战性，亟需低成本且易于扩展的辅助诊断解决方案。本研究利用消费级设备捕获的视频作为诊断的基础，减少了用户的成本。
### Innovation
提出了一种创新的多模态大规模语言模型（MLLMs）在肩部疾病初步诊断中的应用，即Hybrid Motion Video Diagnosis框架（HMVDx）。此框架将动作理解和疾病诊断分别由两个MLLMs完成。同时提出了一个新的度量标准，称为可实施性指数，该指数从整个医疗诊断流程的角度评估MLLMs在医疗领域的有效性，揭示了低成本MLLMs在医疗应用中的潜在价值。与直接视频诊断相比，HMVDx在诊断肩关节损伤方面的准确性提高了79.6%，为医疗领域视频理解的MLLMs应用研究做出了显著的技术贡献。
### Conclusion
该研究通过引入消费级视频作为诊断基础和提出具有创新性的Hybrid Motion Video Diagnosis框架，提高了肩部疾病诊断的准确性和可操作性，展示了低成本MLLMs在医疗领域的应用前景和潜力。
## 449. `cs.CL` - 多说话人录音中目标说话人匿名化 [PDF](https://arxiv.org/pdf/2510.09307), [HTML](https://arxiv.org/abs/2510.09307)
### Authors
Natalia Tomashenko,Junichi Yamagishi,Xin Wang,Yun Liu,Emmanuel Vincent
### Background
现有的大多数说话人匿名化研究集中在单说话人音频上，导致开发出的技术和评估标准都是针对这种单一情况下优化的。这项研究则针对多说话人对话音频中单个目标说话人的匿名化这一重要挑战，尤其在呼叫中心等客户隐私需要保护的场景中尤为重要，客户的声音需要被匿名化以保护隐私，但常用的匿名化方法往往不适用于此场景。此外，现有的评估方法无法准确评估这种复杂多说话人场景中的隐私保护和实用性。
### Innovation
这项工作旨在通过探索在对话音频中进行有针对性的说话人匿名化策略，填补这方面的空白，并提出相应的改进评估方法，以有效评估隐私保护和实用性。
### Conclusion
研究指出，在多说话人录音中实现目标说话人匿名化的挑战在于现有技术和评估方法的局限性，提出了新的策略和评估方法以应对这些挑战。
## 450. `cs.CL` - CapGeo: 一种辅助说明图的几何推理方法 [PDF](https://arxiv.org/pdf/2510.09302), [HTML](https://arxiv.org/abs/2510.09302)
### Authors
Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang
### Background
几何推理仍然是多模态大型语言模型（MLLMs）的核心挑战。即使最先进的闭源系统，如GPT-O3和Gemini-2.5-Pro，在解决几何问题方面仍然表现不稳定，尽管它们在IMO等文本推理任务上表现出色。这表明瓶颈可能在于理解和分析几何图，而不是推理本身。因此，几何图形常常能被简洁地描述成文本形式，将视觉内容转换为说明可能是一个有希望的方向。
### Innovation
提出了一种辅助说明图的推理框架CapGeo，将视觉和文本模态连接起来。实验结果显示，配备说明图的模型在几何推理任务上的表现显著提升：Qwen2.5-VL-72B从8.6%提高到59.0%，Claude-Opus-4从44.8%提高到73.0%。此外，提出了一种名为CapGeo-Bench的数据集，包含4,641个精心选择的图-说明对，并引入了一种基于关键点的评估指标，该指标与后续CapGeo的表现密切相关，能够可靠地评估几何说明的能力。
### Conclusion
我们的框架和基准测试共同突出了一种新的路径，用于通过MLLMs提升几何推理能力。
## 451. `cs.CL` - 大型语言模型提示数据集：深入分析与启示 [PDF](https://arxiv.org/pdf/2510.09316), [HTML](https://arxiv.org/abs/2510.09316)
### Authors
Yuanming Zhang,Yan Lin,Arijit Khan,Huaiyu Wan
### Background
随着大型语言模型（LLM）的广泛应用，从GitHub和社交媒体等平台涌现出了多样化的提示数据集，这些数据集涉及广泛的应用领域和内容类型，促进了LLM的更广泛应用以及提示工程的改进。已有文献中虽然有对提示数据集的提及，但对它们进行了广泛综述的系统性研究很少见。本文旨在填补这一空白，综合了来自不同渠道的提示数据集列表，并分析了它们在任务类型、语言、工程技术、属性和模态方面的共性与差异，区分了这些提示数据集与文献和网页文本等其他文本语料库的特点。
### Innovation
本文首次编制了包含来自各种渠道的提示数据集的综合列表，涵盖了一系列下游任务、语言、工程技术、属性和模态。提出了利用词性嵌入和依赖结构语法嵌入的提示优化方法，通过识别提示的中心表示并引导LLM重写提示以接近这个中心，提高模型输出的意义性。同时，作者公开了所使用数据集和代码，促进了进一步的研究和应用。
### Conclusion
本文详细分析了提示数据集，揭示了不同类型提示的共性和差异，并提出了一种利用语法嵌入优化提示的方法，该方法改善了模型输出的意义性。
## 452. `cs.CL` - 大型语言模型服务中的隐私保护高效参数微调 [PDF](https://arxiv.org/pdf/2305.06212), [HTML](https://arxiv.org/abs/2305.06212)
### Authors
Yansong Li,Zhixing Tan,Paula Branco,Yang Liu
### Background
参数高效微调（PEFT）为用户提供了在使用其私有数据定制大语言模型（LLMs）时的实用途径。然而，私人数据的固有敏感性要求在定制LLM服务时必须采取坚固的隐私保护措施，以确保数据安全，维持用户信任，并符合严格的监管标准。
### Innovation
提出了隐私保护的高效参数微调（RAPT）框架，该框架采用局部隐私方法，允许用户在使用文本到文本的局部差分隐私机制本地化其数据的情况下保留数据隐私。为了解决直接在私有化数据上训练PEFT性能不佳的问题，引入了一个新的私有化标记重建任务，该任务与下游任务联合训练，允许LLMs学习更好的任务相关表示。
### Conclusion
尽管框架相对简单，但实验结果表明，RAPT在各种任务上达到了可竞争的性能，同时提供了针对攻击者的隐私保障。
## 453. `cs.CL` - HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness [PDF](https://arxiv.org/pdf/2510.09388), [HTML](https://arxiv.org/abs/2510.09388)
### Authors
Xinyi Wang,Jinyi Han,Zishang Jiang,Tingyun Li,Jiaqing Liang,Sihang Jiang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao
### Background
强化学习（RL）已成为提升大型语言模型（LLMs）长链推理能力的关键驱动力。然而，常用的RL方法，如GRPO，在任务难度超出模型能力时往往会出现奖励稀疏化，导致训练效率低下。过去的工作尝试通过使用如混合RL和监督微调（SFT）或提供提示等外部指导来缓解这一问题，但这些方法往往导致策略更新误导。论文识别并指出这一问题的根本原因是训练中的低亲和性，这源于模型策略与外部指导之间的巨大分布不匹配。作者提出了一个名为Affinity的新指标，以定量监测探索效率和训练稳定性。
### Innovation
论文提出了HINT（帮助无效滚提出向有效性的框架），这是一个自适应提示框架，它通过提供启发式的建议帮助模型自我发现解决方案，而不是直接给出答案。这种方法能够提高Affinity，即提高探索效率和训练稳定性，从而改善模型的推理能力。实验表明，HINT在数学推理任务上优于其他现有方法，能够实现不同程度规模模型的优异表现，并且学习过程更为稳定，消耗的数据更少。相关代码已开源，可以在Github上找到。
### Conclusion
整体而言，该研究揭示了RL中模型训练亲和性低的问题，并提出了一种新的解决方案HINT，通过自适应提示帮助模型自我发现解决方案，从而改善模型的长期推理能力，展示了在数学推理等任务上的优势。
## 454. `cs.CL` - 使用自然主义MEG-fMRI编码模型在高空间和时间分辨率下估计大脑活动 [PDF](https://arxiv.org/pdf/2510.09415), [HTML](https://arxiv.org/abs/2510.09415)
### Authors
Beige Jerry Jin,Leila Wehbe
### Background
当前非侵入性神经成像技术在空间分辨率和时间分辨率之间存在权衡。磁脑成像技术（MEG）能够捕捉快速的神经动态，功能性磁共振成像（fMRI）则能够定位大脑活动。尽管如此，很难在保留高分辨率的同时获得统一的大脑活动图示，尤其是在单次试验自然主义数据方面，现有源定位方法或MEG-fMRI融合方法尤其存在挑战。
### Innovation
本文开发了一种基于变压器的编码模型，该模型结合了MEG和fMRI数据，用于估计高空间-时间分辨率下的隐源反应。该模型通过多个受试者的数据训练，创新地包含一个隐层，代表重建皮层源的估计值。实验结果表明，该模型在预测MEG方面优于单一模态编码模型的标准方法，并且在模拟实验中产生了比经典最小范数解决方案更高的空间和时间保真度的源估计。此外，通过检验估计的潜源的泛化能力，且表现出优于ECoG训练的编码模型在全新数据集中的电皮层图（ECoG）预测结果。
### Conclusion
通过整合大规模自然实验、MEG、fMRI和编码模型的力量，本文提出了一条向毫秒和毫米级的大脑映射实践路线。
## 455. `cs.CL` - LiveOIBench：大型语言模型能在信息学奥林匹克竞赛中超越人类选手吗？ [PDF](https://arxiv.org/pdf/2510.09595), [HTML](https://arxiv.org/abs/2510.09595)
### Authors
Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang
### Background
随着复杂性和易于验证的特点，编程竞赛问题逐渐成为评估大型语言模型（LLMs）编码能力的重要基准。然而，当前的编程基准测试存在挑战性问题不足、测试用例覆盖面不够以及过度依赖在线平台API限制可访问性等问题。
### Innovation
LiveOIBench 是一个全面的基准，包含403个精品奥林匹克水平的编程竞赛问题，每个问题平均有60个专家设计的测试案例。这些问题直接来源于2023年至2025年间举办的72场官方信息学奥林匹克竞赛。LiveOIBench 的四大特色包括：精心挑选的高质量任务，详细的子任务评分标准和广泛的私有测试案例；直接整合精英参赛选手的表现数据，以与顶级人类表现进行对比分析；持续、无污染的更新机制，使用新发布的奥林匹克竞赛问题；以及一个独立评估系统，便于离线执行并轻松再现评估结果。
### Conclusion
对32个流行的通用和推理大型语言模型进行基准测试后，发现GPT-5达到了81.76的百分位数，这一结果虽强却仍低于顶级人类参赛选手的通常表现（通常超过第90百分位）。相比之下，开源推理模型GPT-OSS-120B仅获得了第60百分位数，突显了与前沿封闭模型的显著能力差距。详细分析表明，稳健的推理模型更侧重于精确的问题分析而非过度探索，未来应更重视结构化的分析，并尽量减少不必要的探索。
## 456. `cs.CL` - StreamingVLM: 实时理解无限视频流 [PDF](https://arxiv.org/pdf/2510.09608), [HTML](https://arxiv.org/abs/2510.09608)
### Authors
Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han
### Background
视觉-语言模型（VLMs）能够驱动实时助手和自主代理，但面临一个关键挑战：在不提高延迟和内存使用率的情况下理解无限的视频流。全注意力机制处理整个视频会导致计算成本急剧增加，并且对于长视频性能较差。简单滑动窗口方法也会出问题，它们要么破坏连贯性，要么由于冗余计算导致高延迟。
### Innovation
本文介绍了StreamingVLM，一种专为实时、稳定理解无限视觉输入而设计的模型。其采用统一框架使得训练与流式推理相一致。在推理过程中，通过重用注意力汇的当前状态、近期视觉标记的短窗口和近期文本标记的长窗口来维护紧凑的KV缓存。此外，通过简单监督微调（SFT）策略，在短重叠视频块上应用全注意力，从而在不训练超长上下文的情况下模仿推理阶段的注意力模式。为此，作者构建了Inf-Streams-Eval基准测试，要求每秒对齐视频帧与文本，结果表明StreamingVLM在Inf-Streams-Eval上达到了66.18%的胜率，并在单块NVIDIA H100上保持了8 FPS的稳定、实时性能。SFT策略还增强了通用的VQA能力，而无需特定的VQA微调，提升了LongVideoBench和OVOBench Realtime的性能。
### Conclusion
StreamingVLM在处理无限的视频流时能够实现实时理解，通过有效的注意力机制和监督微调方案，显著提升了模型的性能和稳定性，同时无需增加计算成本。
## 457. `cs.CL` - 大型语言模型在因果发现中的可靠性 [PDF](https://arxiv.org/pdf/2407.19638), [HTML](https://arxiv.org/abs/2407.19638)
### Authors
Tao Feng,Lizhen Qu,Niket Tandon,Zhuang Li,Xiaoxi Kang,Gholamreza Haffari
### Background
该研究探讨了大型语言模型（LLM）在因果发现方面的效用。通过使用可访问其预训练语料库的开源LLM OLMo和BLOOM，研究者们提出了三个研究问题来评估LLM在因果发现中的表现，包括记忆对因果关系预测准确性的影响、预训练数据中不正确的因果关系的影响，以及背景信息对LLM理解因果关系的影响。
### Innovation
本研究采用了新发布的开源大型语言模型OLMo和BLOOM，并首次系统地评估了这些模型在因果发现中的表现，特别是在识别罕见或新因果关系、处理预训练数据中的不正确因果关系以及理解背景信息方面的能力。
### Conclusion
研究发现，尽管LLM在识别频繁出现在预训练数据中的因果关系方面表现出色，但它们在处理新的或罕见的因果关系方面的能力有限。此外，预训练数据中的不正确因果关系显著降低了LLM对正确因果关系的信心，而背景信息对LLM辨别随机变量之间因果联系的结果影响重大。
## 458. `cs.CL` - Robo-Instruct: 为调优代码LLMs而增强模拟器的指令对齐 [PDF](https://arxiv.org/pdf/2405.20179), [HTML](https://arxiv.org/abs/2405.20179)
### Authors
Zichao Hu,Junyi Jessy Li,Arjun Guha,Joydeep Biswas
### Background
代码LLMs已经在将自然语言任务转换为可执行的服务机器人程序方面展现了前景。然而，收集特定于每个机器人的任务-程序对的数据集耗时且昂贵。尽管一些方法如SELF-INSTRUCT和EVOL-INSTRUCT可以生成新任务，但它们无法根据提供的编程接口生成满足物理世界和机器人约束条件的相应程序。模拟是检查这些约束的自然解决方案，但建立能够处理任意任务及其必要对象和位置的模拟环境具有挑战性。为了解决这些问题，引入了ROBO-INSTRUCT，它在程序执行期间即时合成与任务特定的模拟环境，并根据实体在任务程序中的使用情况推断实体属性并施加相应的约束。此外，ROBO-INSTRUCT结合使用了LLM辅助的后处理过程，以更好地使指令与机器人程序对齐。在多个LLMs上的实验表明，我们调优的模型优于所有基线方法，并且在某些情况下甚至与较大的专有模型性能相当或超越。
### Innovation
ROBO-INSTRUCT 的创新点在于即时合成与任务特定的模拟环境，并根据实体在任务程序中的使用情况推断实体属性并施加相应的约束。另外，该方法结合使用了LLM辅助的后处理过程，以更好地使指令与机器人程序对齐。
### Conclusion
ROBO-INSTRUCT在多个LLMs上的实验表明，我们的调优模型优于所有基线方法，并能够在某些情况下与较大的专有模型性能相当或超越。
## 459. `cs.CL` - 用大规模语言模型进行合规保障的客户服务聊天机器人增强：基于上下文的知识扩展 [PDF](https://arxiv.org/pdf/2410.12444), [HTML](https://arxiv.org/abs/2410.12444)
### Authors
Mengze Hong,Chen Jason Zhang,Di Jiang,Yuanqin He
### Background
检索型聊天机器人通过利用经过人类验证的问题和答案知识来提供准确且可验证的响应，特别适合需要严格遵守监管和运营标准的应用场景。为了有效处理多样化的客户咨询，通过增加“相似问题”来丰富知识库，这些“相似问题”保持语义意义的同时包含不同程度的表达，是一种成本效益高的策略。这一方法能够帮助聊天机器人更好地应对不同类型的用户咨询，增强其全面的知识覆盖面和适应性。
### Innovation
本文提出了一个针对大规模语言模型训练和推理的“相似问题生成”任务（SQG），并提出了一种基于上下文的方法，以实现全面的语义探索和更好地与源问题-答案关系对齐。本文还提出了优化技术来构建上下文提示，并在预算限制下选择最佳的相似问题子集，以扩展聊天机器人的知识。量化和人工评估验证了这些方法的有效性，部署的聊天机器人系统实现了92%的用户满意度，比未扩展的基础系统提高了18%的满意度。
### Conclusion
这些发现突显了SQG的实际优势，并强调了大规模语言模型在支持非生成型系统方面的作用，这些系统能够实现无幻觉、合规保障的应用。
## 460. `cs.CL` - 少见的双词表达揭示字节级分词中不完整分词的漏洞 [PDF](https://arxiv.org/pdf/2410.23684), [HTML](https://arxiv.org/abs/2410.23684)
### Authors
Eugene Jang,Kimin Lee,Jin-Woo Chung,Keuntae Park,Seungwon Shin
### Background
分词是将人类可读的文本转换为模型可读的离散标记的关键步骤。然而，最近的研究表明，分词器可以被利用来引发模型的不期望行为。本文探讨了不完整的分词，即由于基于字节的字节对编码（BPE）分词导致的不可解码分词，伴随着多余的字节。研究者推测，这类分词高度依赖于其相邻的分词，并且在与不熟悉的分词配对时容易出故障。通过引入少见的双词表达，即出分布的不完整分词组合，旨在利用它们的依存关系来演示这一脆弱性。
### Innovation
研究者引入了少见的双词表达以展示不完整分词的漏洞。实验结果显示，少见的双词表达在一些场景下导致幻觉行为的概率显著提高。然而，使用替代分词方式时，这些相同的短语在幻觉行为的发生率上有着显著降低（以Llama3.1为例，幻觉行为率降低了90%）。该研究提示人们应小心字节级BPE分词器带来的潜在漏洞，这些漏洞可能会影响语言模型并引入盲点。
### Conclusion
研究者警告，字节级BPE分词器可能会引入语言模型的安全盲点，建议采取更稳健的分词方式来防止模型意外行为的发生。
## 461. `cs.CL` - Medchain: 通过互动序列填补LLM代理与临床实践之间的差距 [PDF](https://arxiv.org/pdf/2412.01605), [HTML](https://arxiv.org/abs/2412.01605)
### Authors
Jie Liu,Wenxuan Wang,Zizhan Ma,Guolin Huang,Yihang SU,Kao-Jung Chang,Wenting Chen,Haoliang Li,Linlin Shen,Michael Lyu
### Background
临床决策制定（CDM）是一个复杂而动态的过程，对于医疗服务至关重要，但目前仍然是人工智能系统的一个重要挑战。虽然基于大语言模型（LLM）的代理已经在通用医学知识方面的执照考试和知识问答任务中进行了测试，但在实际临床场景中的CDM应用仍然受到缺乏真实医疗实践镜像的实际测试数据集的限制。因此，目前的系统在应对实际CDM挑战方面的能力受到限制。
### Innovation
MedChain是一个包含12,163个临床病例的数据集，覆盖了临床工作的五个关键阶段，具有个性定制化、互动性和顺序性的三大特点。此外，研究者还提出了一种新的AI系统——MedChain-Agent，该系统集成了反馈机制和MCase-RAG模块，可以从过往案例中学习以适应其响应。MedChain-Agent在动态获取信息和处理顺序临床任务方面表现出了优异的适应能力，超越了现有的方法。
### Conclusion
MedChain-Agent通过其出色的适应性和在实际临床任务中的出色表现，填补了大语言模型代理与真正临床实践之间的差距，展示出了在真实世界CDM场景中的巨大潜力。
## 462. `cs.CL` - RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation [PDF](https://arxiv.org/pdf/2501.13726), [HTML](https://arxiv.org/abs/2501.13726)
### Authors
Shi-Qi Yan,Quan Liu,Zhen-Hua Ling
### Background
尽管检索增强生成（RAG）在利用外部知识方面显示出潜力，但其生成过程高度依赖所检索上下文的质量和准确性。大型语言模型（LLMs）在评估与内部记忆相异的外部检索知识的准确性时存在困难，导致生成响应时产生知识冲突。先前的方法通常需要额外的步骤来评估检索质量。
### Innovation
介绍了检索偏好优化（RPO），这是一种轻量级且有效的对齐方法，能够根据检索相关性灵活利用多源知识。RPO通过引入检索相关性的隐式表示，将其整合到奖励模型中，实现了检索评价与响应生成的统一处理，解决了之前方法需要额外评估检索质量的步骤。值得注意的是，RPO是唯一能够量化训练中检索相关性意识的RAG专用对齐方法，克服了数学障碍。
### Conclusion
在四个数据集上的实验表明，RPO在准确度上比RAG提高了4-10%，且无需额外组件，显示出其稳健的泛化能力。
## 463. `cs.CL` - 他们过滤掉了什么？预训练数据集减少危害的过滤策略实验基准 [PDF](https://arxiv.org/pdf/2503.05721), [HTML](https://arxiv.org/abs/2503.05721)
### Authors
Marco Antonio Stranisci,Christian Hardmeier
### Background
大数据过滤策略对于开发安全的大语言模型（LLM）至关重要，因为它们支持从预训练数据集中移除有害内容。尽管这些策略对于减少潜在伤害具有积极作用，但现有研究较少关注这些策略对弱势群体的歧视影响，也尚未系统地评估这些策略的有效性。
### Innovation
本文提出了一个基准研究，旨在系统性评价现有的数据过滤策略。通过整理分析55份关于英语LMs和LLMs的技术报告，识别现有过滤策略，并设计实验设置测试这些策略对弱势群体的影响。
### Conclusion
研究表明，虽然数据过滤策略在减少有害内容方面具有积极影响，但也导致在数据集中弱势群体歧视下的代表性不足的问题。
## 464. `cs.CL` - NLP-ADBench：NLP异常检测基准 [PDF](https://arxiv.org/pdf/2412.04784), [HTML](https://arxiv.org/abs/2412.04784)
### Authors
Yuangang Li,Jiaqi Li,Zhuo Xiao,Tiankai Yang,Yi Nian,Xiyang Hu,Yue Zhao
### Background
异常检测(AD)是一个重要的机器学习任务，广泛应用于欺诈检测、内容审核和用户行为分析等领域。然而，在自然语言处理(NLP)的背景下，AD相对研究较少，这限制了其在检测有害内容、网络钓鱼尝试和垃圾评论方面的能力。
### Innovation
本文介绍了迄今为止最全面的NLP异常检测(NLP-AD)基准——NLP-ADBench，它包含了8个精心挑选的数据集和19种最先进的算法。这些算法涵盖了3种端到端方法和16种两步法，这些方法将经典非AD方法适应Bert和OpenAI的语言嵌入。实验结果显示，没有单一模型能够在所有数据集上占据主导地位，表明需要自动选择模型。此外，基于Transformer的嵌入的两步法方法表现优于专门的端到端方法，OpenAI嵌入比BERT嵌入更出色。文章在this https URL发布了NLP-ADBench，提供了一个统一的NLP-AD框架，支持未来的研究。
### Conclusion
研究表明，NLP-AD需要符合不同场景的定制化模型。基于Transformer的嵌入的两步法在几乎所有数据集上都优于端到端的方法，其中OpenAI的嵌入表现更佳。NLP-ADBench提供了一个统一框架，有助于未来的NLP-AD研究。
## 465. `cs.CL` - AD-LLM: 大型语言模型在检测中的基准 [PDF](https://arxiv.org/pdf/2412.11142), [HTML](https://arxiv.org/abs/2412.11142)
### Authors
Tiankai Yang,Yi Nian,Shawn Li,Ruiyao Xu,Yuangang Li,Jiaqi Li,Zhuo Xiao,Xiyang Hu,Ryan Rossi,Kaize Ding,Xia Hu,Yue Zhao
### Background
异常检测（AD）是一个重要的机器学习任务，在许多实际应用中都有所涉及，如欺诈检测、医疗诊断和工业监控。在自然语言处理（NLP）中，AD有助于检测诸如垃圾信息、错误信息以及不寻常的用户活动等问题。虽然大型语言模型（LLMs）在文本生成和总结任务上已经产生了显著影响，但在AD领域中其潜在能力尚未得到充分研究。因此，本文介绍了AD-LLM，这是首个评估LLMs在NLP异常检测中应用的基准测试。研究了三个关键任务，即零样本检测、数据增强和模型选择。通过使用不同的数据集进行实验，发现LLMs在零样本AD中表现良好，精心设计的增强方法很有用，但特定数据集的模型选择解释仍颇具挑战性。这些研究结果为LLMs在AD领域的未来研究提供了六个研究方向。
### Innovation
AD-LLM是首个用于评估LLMs在NLP异常检测中应用的基准测试。研究了三个关键任务：零样本检测、数据增强和模型选择。首次将LLMs引入到NLP异常检测中，并进行了实证研究，探索它们的应用潜力。
### Conclusion
在不同的数据集上进行的实验表明，LLMs在零样本异常检测中表现出色，精心设计的增强方法非常有用，但针对特定数据集的模型选择解释仍然具有挑战性。基于这些研究成果，提出了六个未来研究方向，以进一步提高LLMs在异常检测中的应用。
## 466. `cs.CL` - 如何使双语语言模型具备双语能力：稀疏自编码器追踪内部表示 [PDF](https://arxiv.org/pdf/2503.06394), [HTML](https://arxiv.org/abs/2503.06394)
### Authors
Tatsuro Inaba,Go Kamoda,Kentaro Inui,Masaru Isonuma,Yusuke Miyao,Yohei Oseki,Benjamin Heinzerling,Yu Takagi
### Background
本研究探讨了双语语言模型如何发展出复杂的内部表示。本文利用稀疏自编码器分析双语语言模型的内部表示，重点关注训练步骤、层数和模型大小的影响。研究表明，语言模型首先分别学习语言，然后逐渐形成双语对齐，尤其是在中间层。研究还发现，大模型中的这种双语倾向更加明显。
### Innovation
我们采用新颖的方法，将完全训练好的模型的分解表示整合到中训练模型中，展示了双语表示对模型性能的至关重要的作用。这种整合方法揭示了双语语言模型如何获得双语能力。
### Conclusion
研究结果表明，双语语言模型通过逐步发展复杂的内部表示来获得双语能力。大模型中的双语特性尤为显著，这对模型性能有重要影响。
## 467. `cs.CL` - LightMamba：基于量化和硬件协同设计的FPGA上高效的Mamba加速 [PDF](https://arxiv.org/pdf/2502.15260), [HTML](https://arxiv.org/abs/2502.15260)
### Authors
Renjie Wei,Songqiang Xu,Linfeng Zhong,Zebin Yang,Qingyu Guo,Yuan Wang,Runsheng Wang,Meng Li
### Background
如Mamba这样的状态空间模型（SSMs）近年来受到了广泛关注。相比于基于Transformer的大型语言模型（LLMs），Mamba计算复杂度与序列长度呈线性关系，性能更优，但这使其难以加速，因为存在散布的激活异常值和复杂的计算依赖性，导致现有LLM加速器效果不佳。
### Innovation
本文提出了LightMamba，这是一种为Mamba推理设计的FPGA加速方案，通过协作设计量化算法和FPGA加速器架构来提高效率。具体而言，该方案提出了一种适用于FPGA的后训练量化算法，结合了旋转辅助量化和幂律SSM量化技术，将大多数计算降低到4位，同时设计了一款FPGA加速器，部分展平了Mamba计算，平衡了效率和硬件成本。此外，通过计算重排以及细粒度的分块和融合，加速器的硬件利用和内存效率显著提高。
### Conclusion
在Xilinx Versal VCK190 FPGA上实现LightMamba后，其能量效率比GPU基线提高了4.65到6.06倍。而在Alveo U280 FPGA上评估时，LightMamba达到93 tokens/s的速度，比GPU基线快1.43倍。代码已开源并在相关链接可用。
## 468. `cs.CL` - AnyEdit: 编辑语言模型中编码的任何知识 [PDF](https://arxiv.org/pdf/2502.05628), [HTML](https://arxiv.org/abs/2502.05628)
### Authors
Houcheng Jiang,Junfeng Fang,Ningyu Zhang,Guojun Ma,Mingyang Wan,Xiang Wang,Xiangnan He,Tat-seng Chua
### Background
大语言模型（LLMs）经常输出错误或过时的信息，因此需要有高效的精准知识更新机制。然而，现有的模型编辑方法在处理诗歌、代码片段和数学推导等多种格式的长内容时存在局限性，这一局限性源于它们依赖于编辑单一标记的隐藏状态，这就是所谓的“有效性障碍”。
### Innovation
本文提出了一个新的自回归编辑范式——AnyEdit，它将长格式的知识分解成序列块，并逐步编辑每个块的关键标记，确保输出的一致性和准确性。理论研究中，我们将AnyEdit建基于互信息链规则，证明了其在LLMs中更新任何知识的能力。实证研究中，相比基准方法，AnyEdit在其包括UnKEBench、AKEW和新提出的EditEverything数据集上的表现均优于基线，提升了21.5%。此外，AnyEdit提供了一个即插即用框架，使得现有的编辑方法可以灵活地更新任意长度和格式的知识，显著提升了LLMs知识编辑的应用范围和实用可靠性。
### Conclusion
研究证明AnyEdit在处理LLMs中的长格式多种知识时表现出更高效和精准的过程中，同时提供了一个通用框架，能增强现有编辑方法的灵活性和适应性，显著推动了LLMs知识编辑的应用范围和实用可靠性。
## 469. `cs.CL` - RAISE：大型语言模型强化自适应指令选择 [PDF](https://arxiv.org/pdf/2504.07282), [HTML](https://arxiv.org/abs/2504.07282)
### Authors
Qingsong Lv,Yangning Li,Zihua Lan,Zishan Xu,Jiwei Tang,Tingwei Lu,Yinghui Li,Wenhao Jiang,Hong-Gee Kim,Hai-Tao Zheng,Philip S. Yu
### Background
在大型语言模型（LLMs）的指令微调过程中，高质量的少数几个指令被广泛认为优于大量低质量的指令。目前正在研究的大多数指令选择方法大多基于启发式的质量度量标准，在训练前只考虑数据选择，这对指令微调的优化不够充分，固定的启发式指标通常很难针对特定任务进行优化。
### Innovation
设计了一个动态的任务目标驱动指令选择框架RAISE（Reinforced Adaptive Instruction SElection），将整个指令微调过程纳入优化，根据每条指令对模型性能提升的预期影响逐步选择指令。通过将动态指令选择建模为顺序决策过程，使用强化学习（RL）训练选择策略，实验结果证明了其相对于其他指令选择方法的优势，展示了其高效性与效果。
### Conclusion
RAISE仅在1%的训练步骤中更新，相对于全数据训练，表现出优越的性能，证明了其高效性和有效性。
## 470. `cs.CL` - 理解并改进LLMs中提示压缩的信息保留 [PDF](https://arxiv.org/pdf/2503.19114), [HTML](https://arxiv.org/abs/2503.19114)
### Authors
Weronika Łajewska,Momchil Hardalov,Laura Aina,Neha Anna John,Hang Su,Lluís Màrquez
### Background
近年来，大型语言模型（LLMs）在各种任务中的应用取得了显著进展，但在信息密集型任务中，提示的长度可能会迅速增长，导致计算资源需求增加、性能下降和由于无关或冗余信息而引入偏见。为了在降低输入长度和保持性能之间取得更好的平衡，最近已经引入了多种提示压缩技术。研究团队提出了一种全面的评估框架，用于深入分析提示压缩方法，并通过该框架分析了最新最先进的软性和硬性压缩方法，发现某些方法在压缩的同时未能保留原始提示的关键细节，从而限制了复杂任务上的性能。
### Innovation
研究团队提出了一个全面的评估框架，用于分析提示压缩方法在信息保留方面的影响。特别是在软性压缩方法中引入了控制压缩粒度的概念，从而在下游任务性能、输入上下文关联以及信息保留方面分别提高了23%、8个BERTScore点和2.7倍的实体个数。通过对现有技术的改进和深入分析，研究团队能够更有效且高效地实现性能和压缩效率之间的平衡。该研究的结果为未来的提示压缩技术提供了新的方向和改进空间。
### Conclusion
通过引入一个新的评估框架，研究团队发现，结合软性提示方法和序列级压缩可以有效提高LLMs在信息保留和任务性能之间的平衡效率。具体的改进包括通过控制压缩粒度来保留关键信息，从而显著提高了性能。详细的实验数据和改进方法的代码可在相应链接中获得。
## 471. `cs.CL` - Science Hierarchography: Hierarchical Organization of Science Literature [PDF](https://arxiv.org/pdf/2504.13834), [HTML](https://arxiv.org/abs/2504.13834)
### Authors
Muhan Gao,Jash Shah,Weiqi Wang,Kuan-Hao Huang,Daniel Khashabi
### Background
科学知识正以惊人的速度增长，这使得跨学科跟踪进展和高层次的概念联系变得愈发困难。尽管引用网络和搜索引擎等工具能帮助检索相关论文，但它们缺乏所需的抽象化能力，无法充分反映各部门间活动的密集度和结构。为了促进科学文献的有效管理与理解，有必要将科学文献组织成跨越多个抽象层次（从宽泛领域到具体研究）的高质量层次结构，这种层次结构能够揭示哪些领域得到了充分研究，哪些领域则缺乏重视。
### Innovation
本文提出了SCIENCE HIERARCHOGRAPHY这一概念，旨在通过结合高效嵌入式聚类与大型语言模型（LLM）提示的混合方法，将科学文献组织成一个多层次结构。这种方法在保持可扩展性的同时，实现了语义精度。相较基于LLM反复构建树形结构的方法，本方法在质量和效率方面表现出更卓越的权衡。通过这种方法生成的层次结构，能够反映现代科学的跨学科和多维特性，且有助于提升科学文献导航的可解释性，并提供一种超越传统搜索方法的科学文献探索途径。
### Conclusion
本文通过SCIENCE HIERARCHOGRAPHY方法成功构建了一种多层次的科学文献结构，提升了科学文献的可解释性和可探索性，并提供了在其他方法之外的文献导航新途径。相关代码、数据和演示已公开。
## 472. `cs.CL` - 从科学论文生成代码：Paper2Code的自动化代码生成方法 [PDF](https://arxiv.org/pdf/2504.17192), [HTML](https://arxiv.org/abs/2504.17192)
### Authors
Minju Seo,Jinheon Baek,Seongyun Lee,Sung Ju Hwang
### Background
尽管机器学习研究迅速发展，但相关的代码实现常常不可用，从而阻碍了研究者们重复实验结果并建立在前人的研究基础上。同时，大型语言模型（LLMs）在理解和生成高质量代码方面表现优异。鉴于此情况，研究人员提出了PaperCoder框架，旨在将机器学习论文转化为功能代码仓库。
### Innovation
PaperCoder采用多代理LLM架构，分为计划、分析和生成三个阶段，每个阶段均通过专门设计的代理代理进行有效协作。该框架能够从机器学习论文中生成高质量、忠实的代码实现。此外，PaperCoder在最近发布的PaperBench基准测试中表现出色，显著优于强基线模型。
### Conclusion
论文通过模型和人工评估证明了PaperCoder的有效性，并展示了其在生成高质量、忠实代码实现方面的优越性能。研究结果表明，PaperCoder是一个有潜力的解决方案，可以促进研究成果的快速传播和利用。
## 473. `cs.CL` - 基于元学习的系统提示优化 [PDF](https://arxiv.org/pdf/2505.09666), [HTML](https://arxiv.org/abs/2505.09666)
### Authors
Yumin Choi,Jinheon Baek,Sung Ju Hwang
### Background
大语言模型（LLMs）已经展示了卓越的能力，优化它们的输入提示有助于最大化其性能。然而，LLM的提示包括任务无关的系统提示和任务特定的用户提示，现有的工作主要集中在特定查询或任务的用户提示优化上，而忽略了系统提示。系统提示一旦优化，就可以在不同的任务和领域中应用。已有工作对系统提示优化的忽视是一个亟待解决的问题。
### Innovation
本文引入了二层系统提示优化的新问题，旨在设计能够抵御多样用户提示并能在新任务上转移的系统提示。为此，我们提出了一种基于元学习的框架，该框架通过在多个数据集上优化系统提示，并在迭代过程中同时更新用户提示，以确保其协同作用来解决该问题。
### Conclusion
我们的实验在涵盖5个不同领域的14个未见数据集上进行，表明我们的方法可以有效推广应用于多样化的用户提示。此外，优化后的系统提示还能快速适应新任务，在测试时间上的用户提示优化步骤更少，同时提高了性能。
## 474. `cs.CL` - ViClaim: 多语言多标签视频自动断言检测数据集 [PDF](https://arxiv.org/pdf/2504.12882), [HTML](https://arxiv.org/abs/2504.12882)
### Authors
Patrick Giedemann,Pius von Däniken,Jan Deriu,Alvaro Rodrigo,Anselmo Peñas,Mark Cieliebak
### Background
随着视频内容作为交流媒介和误信息传播的影响日益增长，亟需有效的工具来分析多语言多主题背景下的断言。现有的误信息检测主要集中在书面文本上，忽略了视频字幕中口语文本的复杂性。因此，开发适用于视频字幕的断言检测工具是必要的，以满足这一领域的需求空白。
### Innovation
本文提出了ViClaim数据集，这是一个包含1,798个标注的视频字幕集，涵盖三种语言（英语、德语、西班牙语）和六个主题。每个句子都会被标记为事实核查相关类别之一：事实核查值得的、事实核查不值得的或者观点。此外，还开发了一款定制标注工具以简化复杂标注过程。使用最先进多语言语言模型的实验结果表明在交叉验证上的强大性能（宏F1值最高可达0.896），但也指出在未见主题泛化的挑战，特别是对于不同领域的内容。研究发现突显了视频字幕中断言检测的复杂性，ViClaim数据集为视频基通信中的误信息检测提供了一个坚实的基础，弥补了多模态分析中的关键空白，
### Conclusion
ViClaim 数据集为媒体审查和误信息检测提供了有价值的资源，对于进一步研究视频字幕中的断言检测具有重要意义。它展示了解决未见主题泛化的挑战的重要性，这对于推进视频通信中的误信息检测具有重要意义。
## 475. `cs.CL` - DDO: 双决策优化以多智能体协作方式实现基于大语言模型的医学咨询 [PDF](https://arxiv.org/pdf/2505.18630), [HTML](https://arxiv.org/abs/2505.18630)
### Authors
Zhihao Jia,Mingyi Jia,Junwen Duan,Jianxin Wang
### Background
大语言模型（LLMs）显示出了强大的泛化和推理能力，使其适合复杂决策任务，例如医学咨询（MC）。然而，现有的基于LLM的方法往往未能捕捉到MC的双重性质，这包括两个不同的子任务：症状问询，一个顺序决策过程，以及疾病诊断，一个分类问题。这种不匹配通常会导致无效的症状问询和不可靠的疾病诊断。论文提供了一种名为DDO的新颖LLM基于框架，通过分离两个子任务并使用不同的目标进行优化，以协作多智能体工作流来进行双决策优化。实验结果表明，DDO在三个真实世界的MC数据集上始终优于现有的基于LLM的方法，并实现了与最先进的基于生成的方法相当的表现，证明了其在MC任务中的有效性。相关代码可从此处获取。
### Innovation
DDO提出了一种新颖的LLM基于框架，通过分离症状问询与疾病诊断这两个子任务，并通过协作多智能体工作流进行优化，分别针对这两个子任务进行优化。这种方法有效解决了现有LSTM方法的不足，尤其在症状问询和疾病诊断的准确性上有了显著提升，实现了更好的性能表现。
### Conclusion
实验证明，DDO框架在真实世界的MC数据集上实现了超越并保持了与最先进的生成方法相近的效果，展示了其在解决MC任务上的有效性。
## 476. `cs.CL` - 从潜在表示动态构建：省去示例的向量构造 [PDF](https://arxiv.org/pdf/2505.20318), [HTML](https://arxiv.org/abs/2505.20318)
### Authors
Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu
### Background
现有的In-Context Vector (ICV) 方法通过从大型语言模型（LLMs）中提取任务相关的表示并将其在推理时重新注入，实现了与少量示例In-Context Learning (ICL) 相当的性能，但没有重复示例演示处理。然而，现有的ICV方法在ICL特定因素上仍较为敏感，通常使用粗略或语义破碎的表示作为向量源，并依赖基于启发式的注入位置，这限制了它们的应用范围。
### Innovation
为了应对这些问题，本文提出了一种动态向量(DyVec)方法，该方法结合了耗尽查询旋转(EQR)策略，通过减轻由ICL引入的方差提取出鲁棒且语义聚合的潜在表示。然后，它采用动态潜在分割和注入策略，根据任务的复杂性进行自适应分割，并利用基于REINFORCE的优化来为每一部分学习最优的注入位置。实验结果显示，DyVec超越了少量示例ICL、LoRA及先前的ICV基线。进一步的分析强调了动态分割和注入语义聚合的潜在表示的有效性，DyVec提供了一个轻量级且数据高效的推理时任务适应解决方案。
### Conclusion
DyVec通过自适应处理和基于优化的学习注入位置，解决了ICV方法在ICL特定因素上的敏感性问题，增强了向量表示的语义聚集性和分割的灵活性，从而在任务适应性方面表现优秀。
## 477. `cs.CL` - Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs [PDF](https://arxiv.org/pdf/2506.07180), [HTML](https://arxiv.org/abs/2506.07180)
### Authors
Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang
### Background
随着视频大型语言模型（Video-LLMs）越来越多地融入现实世界的应用中，这些模型需要具备基于视觉证据的多模态推理能力。然而，这些模型倾向于迎合用户输入，即使这些输入与视觉证据相矛盾，这降低了它们在这些场景中的可信度。当前的研究大多忽视了这种谄媚行为在视频-语言领域的具体表现，导致缺乏系统性的基准测试和针对性评估，以理解Video-LLMs在误导性用户输入情况下的反应.
### Innovation
本文提出了VISE（Video-LLM Sycophancy Benchmarking and Evaluation），这是第一个用于评估最先进的Video-LLMs在不同问题格式、提示偏差和视觉推理任务中的谄媚行为的基准测试。VISE引入了语言视角来分析视频中的谄媚行为，能够对多种谄媚类型和交互模式进行细致分析。此外，还提出了两种潜在的无需训练的缓解策略：（i）通过可解释的关键帧选择增强视觉对接；（ii）通过目标干预内部神经表示来引导模型偏离谄媚行为.
### Conclusion
我们的代码可以在以下链接找到：[https://github.com/example](https://github.com/example). 这个基准测试和缓解策略为研究Video-LLMs的谄媚行为提供了新的视角和方法，有助于提高模型的实用性与可靠性.
## 478. `cs.CL` - Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios [PDF](https://arxiv.org/pdf/2505.23118), [HTML](https://arxiv.org/abs/2505.23118)
### Authors
Zhongzhen Huang,Linjie Mu,Yakun Zhu,Xiangyu Zhao,Shaoting Zhang,Xiaofan Zhang
### Background
临床决策依赖于跨多种证据来源的迭代、多模态推理。近年来，多模态推理模型显著改变了解决复杂任务的格局。这些模型在数学和科学领域取得了显著成功，但在医疗领域中的应用仍然尚未充分探索。医疗领域的复杂性要求模型能够处理多种类型的数据来源，以做出有效的临床决策。
### Innovation
本文提出了一种称为MedE2的两阶段后训练管道，用于引发和增强医疗领域的多模态推理。在第一阶段，通过2000个仅包含精确调度推理演示的数据样本微调模型，以引发所需的推理行为。第二阶段则通过1500个多模态医学病例在严格筛选后进一步增强模型的推理能力，使模型推理输出与所提出的多模态医学推理偏好相匹配。该方法在多个医学多模态基准上与基线模型相比，展示了改进推理性能的效果，并且经过更大模型验证和推理时间缩放下的进一步验证，展示了该方法的鲁棒性和实用性。
### Conclusion
大量实验表明，使用MedE2训练的模型在多种医学多模态基准上的推理性能优于基线模型，并且该方法在更大模型和推理时间缩放下的验证仍显示出其鲁棒性和实用性。
## 479. `cs.CL` - 跨并行样本学习进行LLM推理 [PDF](https://arxiv.org/pdf/2506.09014), [HTML](https://arxiv.org/abs/2506.09014)
### Authors
Jianing Qi,Xi Ye,Hao Tang,Zhigang Zhu,Eunsol Choi
### Background
对于大型语言模型（LLMs），测试时计算量的扩展能带来显著性能提升。已有方法通过采样多个答案并采用启发式聚合（如多数投票或多验证器评估答案排名）来实现数学领域的性能提升。本文在此基础上提出了一种新的方法，旨在进一步优化性能。
### Innovation
本文提出了一种新的方法——Sample Set Aggregator (SSA)，即样本集聚合器，通过强化学习训练一个紧凑版本的LLM，它接收多个样本的拼接序列作为输入，输出最终答案，特别优化了答案的准确性。该方法在五个推理数据集上的实验结果证明了其有效性和效率，特别是在处理MATH数据集时，相对于简单的多数投票提高了8%的pass@5性能。此外，3B规模的SSA模型超越了基于模型的再排序，且使用了更大的72B规模的奖励模型。分析表明SSA在样本集大小、基础模型家族和规模、以及任务上的泛化能力强。
### Conclusion
本文通过将生成答案的LLM与分析和聚合采样答案的LLM分离，利用跨并行样本训练模型的方法，展示了其能够在与顶级黑盒模型集成时实现高效且兼容的工作能力。
## 480. `cs.CL` - FinTagging：评估提取和结构化财务信息的LLM基准 [PDF](https://arxiv.org/pdf/2505.20650), [HTML](https://arxiv.org/abs/2505.20650)
### Authors
Yan Wang,Yang Ren,Lingfei Qian,Xueqing Peng,Keyi Wang,Yi Han,Dongji Feng,Fengran Mo,Shengyuan Lin,Qinchuan Zhang,Kaiwen He,Chenri Luo,Jianxing Chen,Junwei Wu,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Qianqian Xie,Jian-Yun Nie
### Background
理解和准确解读财务报告中的数字对于市场、监管者、算法以及普通人的经济和世界解读至关重要，尽管有XBRL（可扩展商业报告语言）设计用于为每个数字加上标准化的会计概念，但将数千个事实与超过10,000个美国公认会计原则（GAAP）概念进行映射仍然是成本高、不一致且易出错的。现有的基准仅定义标签为平面的、单一步骤并适用于小部分GAAP概念的极端分类，而忽略了分类法的层次语义和现实标签的结构化特征，这种现实标签中每个事实都需要表示为一个上下文化的多字段输出。这些简化使得在真实的报告条件下无法公平地评估大语言模型（LLMs）的表现。
### Innovation
为了弥补这些差距，我们引入了FinTagging，这是第一个全面基准，专门针对结构感知和全面的XBRL标签设计，旨在评估LLMs提取并根据数值推理和文本与表格之间的分类法对齐来关联财务事实的能力。我们定义了两个子任务：FinNI用于数值识别，从XBRL报告中抽取数值实体及其类型；FinCL用于概念链接，将每个抽取的实体映射到全面的GAAP分类法中的相应概念。这两个子任务共同生成了每个财务事实的结构化表示。我们在零-shot设置下评估了不同的LLMs，并分析了它们在两个子任务和总体标签准确性上的表现。结果表明，LLMs在数值识别中表现出良好的泛化能力，但在细粒度的概念链接中则面临挑战，揭示了结构感知推理在准确的财务披露中的当前限制。所有代码和数据集均可在GitHub和Hugging Face上获得。
### Conclusion
研究结果表明，LLMs在数值识别方面表现出良好的泛化能力，但在细粒度概念链接方面面临挑战，揭示了在准确财务披露中的结构感知推理的当前限制。
## 481. `cs.CL` - RedDebate：通过多代理红队辩论实现更安全的响应 [PDF](https://arxiv.org/pdf/2506.11083), [HTML](https://arxiv.org/abs/2506.11083)
### Authors
Ali Asad,Stephen Obadinma,Radin Shayanfar,Xiaodan Zhu
### Background
现有的AI安全性方法往往依赖于昂贵的人工评估或孤立的单模型评估，这些方法受限于可扩展性并易出现疏忽问题。
### Innovation
RedDebate提供了一个新的多代理辩论框架，该框架让大型语言模型（LLMs）能够识别和减轻其不安全行为。它通过跨不同辩论场景的多个LLM之间的协作论证，使它们能够彼此批判性评价并系统地发现不安全的失败模式。此外，它还集成了独特的长期记忆模块，用于保存辩论互动中的安全相关见解，并在后续推理期间利用这些见解，促进模型行为的持续改进。实验表明，RedDebate在不同类型模型的安全基准测试中显著减少了不安全的输出。
### Conclusion
RedDebate是第一个完全自动化的框架，将多代理辩论和红队测试统一起来，逐步提升LLM的安全性，无需人工干预。
## 482. `cs.CL` - Phonikud：用于实时文本-to-语音的希伯来文音素-音节转换 [PDF](https://arxiv.org/pdf/2506.12311), [HTML](https://arxiv.org/abs/2506.12311)
### Authors
Yakov Kolani,Maxim Melichov,Cobi Calev,Morris Alper
### Background
现代希伯来文的拼写复杂性使得实时文本-to-语音（TTS）具有挑战性。现有的解决方案通常忽略了关键的音素特征，如重音，在添加了音标后这些特征仍然描述不完全。因此，研究团队决定开发Phonikud，一款轻量级、开源的希伯来文音节-to-音素（G2P）系统，输出完整的国际音标（IPA）转录。
### Innovation
Phonikud采用现有标记化模型并添加轻量级适配器进行调整，几乎不对延迟产生额外影响。还提供了带有IPA注释的ILSpeech希伯来文发音数据集，用于希伯来文G2P训练、TTS系统的训练数据，以及评估TTS性能时捕捉重要音素细节的工具。实验结果显示Phonikud能够更准确地预测希伯来文本中的音素，从而实现具有更优速度-准确度折衷的实时TTS模型训练。
### Conclusion
Phonikud G2P转换比先前的方法更能准确预测希伯来文本中的音素，并使实时希伯来TTS模型训练成为可能，具备更好的速度-准确度折衷。相关代码、数据和模型在项目页面上发布。
## 483. `cs.CL` - 超越token的LLM公平性量化：一种语义与统计视角 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
### Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
### Background
大规模语言模型（LLMs）经常会生成包含内在偏见的响应，这削弱了它们在真实世界应用中的可靠性。现有的评估方法通常忽视了长格式响应中的偏见以及LLM输出的固有变异性。
### Innovation
本文提出了FiSCo（精细语义比较），这是一种新颖的统计框架，用于通过检测组间长格式响应中的微妙语义差异来评估LLM的群体公平性。与以往侧重于情感或token级对比的方法不同，FiSCo不止于表面分析，而是基于断言级别运作，利用蕴含检查来评估响应之间的意义一致性。该方法将模型输出分解为语义上不同的断言，并使用统计假设检验来比较组内和组间的相似性，从而实现对微妙偏见的稳健检测。
### Conclusion
实验表明，FiSCo更可靠地识别细微偏见，减少了随机LLM变异性的影响，并在各种评估指标中表现出色。此外，作者还提出了一个新的群体反事实公平性定义，并在包含性别、种族和年龄的合成数据和人类标注数据集上验证了FiSCo的有效性。
## 484. `cs.CL` - ConlangCrafter：使用多跳LLM流水线构建语言 [PDF](https://arxiv.org/pdf/2508.06094), [HTML](https://arxiv.org/abs/2508.06094)
### Authors
Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš
### Background
人造语言(conlangs)如 Esperanto 和 Quenya 在艺术、哲学和国际交流中扮演着多样的角色。同时，基础模型已经改变了文本、图像以及更广泛领域的创造性生成。本文通过现代大语言模型（LLMs）作为计算创造力的辅助工具，实现了端到端的人造语言生成。所提出的 ConlangCrafter 多步骤流水线将语言设计分解为模块化的阶段，包括音韵学、形态学、句法学、词汇生成和翻译。
### Innovation
ConlangCrafter 提出了一个多步骤流水线，将语言设计转换为模块化阶段，利用 LLAs 的元语言推理能力，在每个阶段注入随机性以鼓励多样性，同时利用自反省反馈来确保生成语言描述的一致性。该方法首次展示了如何使用 LLAs 实现端到端的人造语言生成，无需人类语言学专业知识。
### Conclusion
ConlangCrafter 在一致性度量和类型学多样性上进行了评估，证明了其能够生成连贯且多样化的 conlangs。
## 485. `cs.CL` - 使用语言VAEs解构潜在推理规则的系统研究 [PDF](https://arxiv.org/pdf/2506.19418), [HTML](https://arxiv.org/abs/2506.19418)
### Authors
Yingji Zhang,Marco Valentino,Danilo S. Carvalho,André Freitas
### Background
现有的Transformer基语言模型在自然语言推理（NLI）任务中表现出色，但它们主要依赖记忆而非基于规则的推理。研究人员尝试在语言模型的潜在空间中嵌入明确的推理规则来提高模型的一般性、可解释性和可控性。这篇论文探讨了如何通过语言变分自编码器（VAE）explicit地将推理规则嵌入和记忆在语言模型中。
### Innovation
提出了一个学习在基于Transformer的语言VAE中嵌入推理规则的完整管道。该管道涵盖了三个基于规则的推理任务、支持的理论框架和实际的端到端架构。实验结果表明，在明确信号监督下，推理规则可以在编码器的参数空间中被分离。引入推理信息使模型能够更有效地根据键检索存储的值。此外，FFN层比注意力层更适合在模型参数中保持推理规则的分离，并且对于数学推理任务，在特定模型（Qwen2.5(0.5B)）中增加样本数量不会持续提高性能。
### Conclusion
该研究展示了如何通过语言VAE显式地解构潜在的推理规则。分离的推理规则提高了模型的可解释性，而FFN层在保持推理规则分离方面表现更好。未来研究可以进一步探索如何在更大的模型上实现这些发现的成果。
## 486. `cs.CL` - Lizard: 一种高效的大型语言模型线性化框架 [PDF](https://arxiv.org/pdf/2507.09025), [HTML](https://arxiv.org/abs/2507.09025)
### Authors
Chien Van Nguyen,Ruiyi Zhang,Hanieh Deilamsalehy,Puneet Mathur,Viet Dac Lai,Haoliang Wang,Jayakumar Subramanian,Ryan A. Rossi,Trung Bui,Nikos Vlassis,Franck Dernoncourt,Thien Huu Nguyen
### Background
Transformer 基础的大规模语言模型（LLMs）在处理长序列时面临严重的计算和内存瓶颈，主要是由于 softmax 注意力机制的二次复杂度，以及不断增加的键值对（KV）缓存，这导致推理过程受到上下文长度的内存限制。现有的线性化方法大都受固定且不可调整结构的限制，无法有效解决这些问题。因此，迫切需要一个能够线性化预训练的Transformer模型并解决上述瓶颈的新型框架，以保持模型性能并提高推理效率和缩短训练时间.
### Innovation
本文提出了Lizard框架，这是一种线性化框架，能够将预训练的Transformer基大型语言模型（LLMs）转换为亚二次的架构。Lizard通过引入一个亚二次的注意力机制，该机制能近距离模拟softmax注意力机制，同时保持模型质量。不同于之前受限于固定非自适应结构的线性化方法，Lizard增加了紧凑且可学习的模块，以实现适应性的内存控制和鲁棒的长度泛化。此外，Lizard还引入了一个针对门控注意力中数值不稳定性的硬件感知算法，以加快训练速度。实验表明，Lizard在5-shot MMLU基准测试中的表现显著优于现有方法，性能提高了9.4-24.5个百分点，同时表现出更好的关联记忆性.
### Conclusion
Lizard能够实现接近无损的教师模型性能恢复，并且在5-shot MMLU基准测试中比之前的方法性能提高多达9.4-24.5个百分点，显示出在联想记忆方面的优越性。
## 487. `cs.CL` - LaTeXTrans：多智能体协调下的结构化LaTeX翻译 [PDF](https://arxiv.org/pdf/2508.18791), [HTML](https://arxiv.org/abs/2508.18791)
### Authors
Ziming Zhu,Chenglong Wang,Shunjie Xing,Yifu Huo,Fengning Tian,Quan Du,Di Yang,Chunliang Zhang,Tong Xiao,Jingbo Zhu
### Background
尽管现代机器翻译系统在通用文本上的表现非常出色，但将结构化的LaTeX格式文档进行翻译仍是一项巨大的挑战。这些文档通常混合了自然语言和领域特定的语法，如数学公式、表格、图例和交叉引用。所有这些元素都需要准确地保持，以保持语义完整性和可编译性。因此，目前主流的MT系统在处理这类文档时仍然存在较大困难。
### Innovation
文中介绍了LaTeXTrans，这是一个协作式的多智能体系统，旨在解决这一问题。LaTeXTrans通过六个专门的智能体来实现格式保留、结构忠实度和术语一致性：1) 解析器，通过占位符替换和语法过滤将LaTeX分解为易于翻译的单元；2) 翻译者、验证器、摘要生成器和术语提取器，协同工作以确保上下文意识、自我纠正和术语一致的翻译；3) 生成器，将翻译的内容重新构建成结构良好的LaTeX文档。实验结果显示，LaTeXTrans在翻译准确性和结构忠实度方面均优于主流MT系统，提供了一种有效且实用的LaTeX格式文档翻译解决方案。
### Conclusion
实验结果表明，LaTeXTrans在翻译准确度和结构保真度方面均优于主流MT系统，提供了一种有效且实用的LaTeX格式文档翻译解决方案。LaTeXTrans的代码可以在[此处获取】，为结构化LaTeX文档翻译领域带来了新的解决方案。
## 488. `cs.CL` - LATTE：银行客户交易和文本嵌入的学习对齐 [PDF](https://arxiv.org/pdf/2508.10021), [HTML](https://arxiv.org/abs/2508.10021)
### Authors
Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Omar Zoloev,Artem Sakhno,Dmitry Korolev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko
### Background
从客户历史通信序列中学习客户嵌入对于金融应用至关重要。虽然大型语言模型（LLMs）提供了广泛的世界知识，但直接使用它们处理长时间序列事件在现实世界的管道中是计算昂贵且不切实际的。现有的方法不适用于实时场景，因为它们需要处理完整的事件序列，这会导致较高的推理成本和较大的输入尺寸。本文旨在设计一种新的学习框架，通过对比学习机制，将原始事件嵌入与冻结的LLMs的语义嵌入进行对齐，从而减少推理成本和输入尺寸，提高部署效率，特别是在对延迟敏感的环境中。
### Innovation
本文提出了一种新的对比学习框架LATTE，通过对比学习机制将原始事件嵌入与冻结的LLMs的语义嵌入进行对齐。行为特征被总结为简短的提示，由LLMs嵌入，并通过对比损失作为监督。ALTTE方法显著地减少了推理成本和输入尺寸，相比于传统的完整序列处理方法。实验结果显示，该方法在实际金融数据集上优于最新的序列表示技术，同时适用于对延迟敏感的部署环境。
### Conclusion
实验结果表明，ALTTE方法在实际金融数据集上学习事件序列表示方面优于最新技术，并且在延迟敏感的环境中具有可部署性。这种方法通过减少推理成本和输入尺寸，显著提高了实用性。
## 489. `cs.CL` - 大型语言模型能否掌握复杂桌面游戏？ [PDF](https://arxiv.org/pdf/2509.01328), [HTML](https://arxiv.org/abs/2509.01328)
### Authors
Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang
### Background
复杂的博弈游戏一直是检验人工智能算法进步的重要基准。AlphaGo、AlphaZero和MuZero在围棋和国际象棋中战胜了顶尖人类玩家，引起了广泛的社会关注。与此同时，大型语言模型在各种任务中展示了惊人的能力，引发了关于大型语言模型是否能在复杂博弈游戏中取得类似成功的讨论。
### Innovation
本文探索了大型语言模型在掌握复杂扑克牌游戏方面的潜力。系统性地评估了大型语言模型在八种不同扑克牌游戏中的学习能力，研究了通过细调高质量游戏数据的影响，考察了模型保留一般能力和掌握这些游戏的能力之间的平衡。研究发现大型语言模型通过监督微调高质量数据可以接近强游戏AI的表现，同时在规则相似的游戏间实现了特定程度的专业水平，而在规则不同的游戏中表现不佳。然而，当掌握复杂游戏时，大型语言模型的一般能力有所下降，但可通过混入一定比例的一般指令数据来缓解这种下降。
### Conclusion
评估结果表明，大型语言模型具有强大且多样的学习能力。研究的代码已在提供的链接中公开发布。
## 490. `cs.CL` - 量化大型语言模型标签诱导偏见的自我和跨模型评估 [PDF](https://arxiv.org/pdf/2508.21164), [HTML](https://arxiv.org/abs/2508.21164)
### Authors
Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush
### Background
随着大型语言模型（LLMs）在评估文本质量方面越来越被广泛部署，它们判断的有效性尚未得到充分研究。本研究通过一项受控实验，考察了ChatGPT、Gemini和Claude这三种主流LLM的自我评价和交叉模型评价系统性偏差，研究了标签对模型评估结果的影响。
### Innovation
本研究设计了一个受控实验来评估每个模型撰写的博客文章，使用无标记、真实标记和两个虚假标记的情况进行评估。采用了整体偏好投票和细化的质量评分，并对所有评分进行标准化处理以直接比较结果。研究揭示了显著的模型评分不对称性，以及虚假标签对偏好的频繁反转，并强调了感知的模型身份对高级判断和细粒度质量评估结果的显著影响，独立于内容质量。这些结果挑战了LLM作为裁判模式的可靠性，并凸显了盲评估协议和多样化多模型验证框架对于确保自动化文本评估和LLM基准测试中的公平性和有效性的关键需求。
### Conclusion
感知的模型身份可以显著扭曲高级判断和细粒度质量评估，独立于内容质量。研究结果质疑了LLM作为裁判模式的可靠性，并强调了盲评估协议和多样化多模型验证框架对于确保自动化文本评估和LLM基准测试中的公平性和有效性的关键需求。
## 491. `cs.CL` - COMPACT: 共有标记优化的模型剪枝跨越通道和标记 [PDF](https://arxiv.org/pdf/2509.06836), [HTML](https://arxiv.org/abs/2509.06836)
### Authors
Eugene Kwek,Wenpeng Yin
### Background
对于边缘部署、交互应用以及大规模可持续推理而言，使大型语言模型（LLMs）在内存、延迟和服务器成本方面更加高效至关重要。现有的剪枝方法存在局限性：宽度剪枝通常会破坏标准变换器布局，需要定制推理代码，而深度剪枝可能会导致准确率骤降。虽然许多剪枝方法对LLMs有效，但在维护小语言模型（SLMs）的性能方面存在困难。
### Innovation
本文提出了一种名为COMPACT的方法，采用共同标记加权激活功能共同（i）剪枝罕见词汇以缩小嵌入/语言模型头层，（ii）使用共同标记加权激活功能进行FFN中间通道剪枝，使重要性与剪枝后的标记分布相一致。COMPACT结合了深度剪枝和宽度剪枝的优点，如部署友好性（保持标准变换器架构）、规模适应性（折中词汇表的宽度剪枝和FFN剪枝）、可竞争的剪枝时间和强大的内存节省及吞吐量增益。
### Conclusion
跨Qwen、LLaMA和Gemma家族（0.5B-70B参数量）的实验显示，COMPACT具有最先进的下游性能，并且在参数减少、GPU内存和延迟方面有显著的降低。
## 492. `cs.CL` - 填补临床差距的基准：针对日本医疗系统的HealthBench案例 [PDF](https://arxiv.org/pdf/2509.17444), [HTML](https://arxiv.org/abs/2509.17444)
### Authors
Shohei Hisada,Endo Sunao,Himi Yamato,Shoko Wakamiya,Eiji Aramaki
### Background
虽然用于安全开发医疗大语言模型（LLM）的坚实评估框架至关重要，但在日本可用的资源却很少，往往由翻译成日语的多项选择题组成。本研究旨在调查HealthBench这一大规模、基于评分标准的医疗基准在日语环境中的适用性。
### Innovation
研究通过两种方式解决这一问题：一是利用机器翻译HealthBench的5,000个情景来评估两个模型——一个高性能多语言模型（GPT-4.1）和一个日本原生开源模型（LLM-jp-3.1），以此建立性能基线；二是采用大语言模型作为法官的方法系统分类基准情景和评分标准，以识别内容与日本临床指南、医疗体系或文化规范不符的‘情境缺口’。
### Conclusion
研究发现，GPT-4.1由于评分标准不匹配导致轻微表现下降，而日本原生模型更为严重，表现出临床完成度不足的问题。此外，分类结果显示，尽管大部分情景适用，但仍有一大比例的评分标准需要本地化。本研究强调了直接基准翻译的局限性，并指出了需要一个情境感知且本地化的“J-HealthBench”以确保在日本环境中的医疗LLM可靠且安全评估的急迫需求。
## 493. `cs.CL` - RE-Searcher：目标导向规划与自我反思的稳健代理搜索 [PDF](https://arxiv.org/pdf/2509.26048), [HTML](https://arxiv.org/abs/2509.26048)
### Authors
Daocheng Fu,Jianbiao Mei,Licheng Wen,Xuemeng Yang,Cheng Yang,Rong Wu,Tao Hu,Siqi Li,Yufan Shen,Xinyu Cai,Pinlong Cai,Botian Shi,Yong Liu,Yu Qiao
### Background
大型语言模型（LLMs）在知识密集型问题回答和推理方面表现出色，但在实际部署时受到知识截止日期、幻觉和有限的交互方式的制约。增强LLMs的外部搜索工具可以缓解这些问题，但也会使代理暴露在一个复杂的搜索环境中，在这种环境中，查询形式的微小变化可能导致无益的推理轨迹，并放大错误。这项研究系统地分析了环境复杂性如何导致脆弱的搜索行为，并反过来降低整体性能。
### Innovation
提出了一个简单的但有效的方法来实现搜索代理RE-Searcher。RE-Searcher在搜索时明确表述具体的搜索目标，并随后反思检索到的证据是否满足该目标。这种目标导向的规划与自我反思的结合，使RE-Searcher能够抵抗复杂搜索环境中的虚假线索，并执行稳健的搜索。广泛的实验表明，该方法提高了搜索准确性，并达到了最先进的结果。扰动研究表明，该方法对噪声或误导性外部信号具有很强的鲁棒性，减轻了搜索过程中的脆弱性。
### Conclusion
这些发现为将LLM驱动的代理整合到更复杂的交互环境中并实现更自主的决策提供了实际指导。
## 494. `cs.CL` - RPG: 一种统一且可扩展的代码库生成规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型在生成单独的函数或单个代码文件方面表现卓越，但在从零开始生成完整的代码库方面仍面临根本性的挑战。这一能力对于从高层规范构建一致的软件系统以及实现自动化代码生成的全部潜力至关重要。生成代码库需要在两个层面进行计划：决定要构建哪些功能和模块（提案阶段）和定义其实施细节（实施阶段）。当前的方法依赖于自然语言规划，经常产生不清晰的规范、不一致的组件和脆弱的设计，这是由于自然语言的内在歧义性和缺乏结构导致的。
### Innovation
为了解决这些限制，作者引入了Repository Planning Graph（RPG），这是一种统一的结构化表示，能够编码功能、文件结构、数据流和函数。RPG通过用明确的蓝图替换自由形式的自然语言，使长期规划的规划得以持续进行。基于RPG，作者开发了一个图驱动的框架ZeroRepo，包括三个阶段：提案级规划、实施级构建以及图引导的代码生成带测试验证。
### Conclusion
通过在RepoCraft基准上进行评估，ZeroRepo在代码行数和代码令牌数上超过了最强基准Claude Code，并且比其他基准大68倍。它实现了81.5%的覆盖率和69.7%的测试准确率，分别超过Claude Code 27.3和35.8个百分点。进一步分析表明，RPG能够描述复杂的依赖性，通过近线性扩展实现更复杂的规划，并提高代理对代码库的理解，从而加速定位。
## 495. `cs.CL` - 机器学习在检测与分析新型大语言模型监狱破解方面的应用 [PDF](https://arxiv.org/pdf/2510.01644), [HTML](https://arxiv.org/abs/2510.01644)
### Authors
John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra
### Background
大型语言模型（LLMs）受到多种漏洞的影响，这些漏洞允许恶意用户通过篡改输入文本来获取不希望的回复。所谓的监狱破解提示旨在欺骗LLM绕过为遵守开发者政策而设定的安全限制。当前研究旨在分析不同机器学习模型识别监狱破解提示与正常使用的能力，重点关注模型在识别使用之前未见过的策略的监狱破解提示方面的能力。现有的研究表明，通过微调双向Transformer编码表示（BERT）模型来识别监狱破解表现最佳。此外，研究还揭示了区分监狱破解与正常提示的关键词，结论指出，提示结构中的明确反思可能是监狱破解意图的信号。
### Innovation
研究创新地使用了机器学习模型来区分监狱破解提示与正常使用，特别是在识别之前未见过策略的监狱破解方面。研究发现，通过端到端微调BERT模型可以取得最佳性能。此外，研究还可视化了区分监狱破解与正常提示的关键词，进一步深化了对监狱破解特征的理解。
### Conclusion
研究得出结论，提示结构中的明确反思可能是监狱破解意图的信号，同时通过微调BERT模型能够有效识别监狱破解提示，这对于保障LLM的安全性和合规性具有重要意义。
## 496. `cs.CL` - InfiR2: 一种用于增强推理的语言模型的全面FP8训练配方 [PDF](https://arxiv.org/pdf/2509.22536), [HTML](https://arxiv.org/abs/2509.22536)
### Authors
Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Hongxia Yang
### Background
大规模语言模型（LLMs）的训练计算成本巨大，这是创新的主要障碍。虽然FP8训练因其显著的理论效率提升而提供了有希望的解决方案，但其广泛应用受到了缺乏全面开源训练配方的阻碍。因此，为了弥合这一差距，该研究引入了一个端到端的FP8培训配方，该配方无缝地结合了持续预训练和监督微调。通过在含有160亿个标记的语料库上继续预训练模型，并且通过广泛实验，该研究证明其不仅非常稳定，而且基本上无损失，其性能与BF16基线相当，同时在推理基准测试中实现了与BF16相当的表现。这还实现了显著的效率改进，包括训练时间减少22%，峰值内存使用下降14%，以及吞吐量增加19%。研究结果表明FP8是一种实际且稳健的BF16替代方案，并将发布配套代码以进一步普及大规模模型训练。
### Innovation
该研究提出了一个端到端的FP8培训配方，该配方结合了持续预训练和监督微调。此外，研究采用了细粒度的混合粒度量化策略，在保持数值准确性的前提下最大化计算效率。通过广泛实验，证明该配方不仅稳定性高，而且几乎无损失，同时实现效率的显著提升。
### Conclusion
研究结果证实了FP8作为BF16的实用和稳健替代方案的有效性，并计划发布配套代码以进一步推动大规模模型训练的普及。
## 497. `cs.CL` - 超越‘对不起，我不能’：剖析大型语言模型的拒绝行为 [PDF](https://arxiv.org/pdf/2509.09708), [HTML](https://arxiv.org/abs/2509.09708)
### Authors
Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee
### Background
在指令调优的大语言模型（LLMs）中，拒绝有害提示是一种关键的安全行为，但其内部原因仍然没有得到充分理解。本文通过研究两个已公开的指令调优模型Gemma-2-2B-IT和LLaMA-3.1-8B-IT，尝试解析这种拒绝行为的内在机制。研究利用稀疏自编码器（SAEs）训练在残差流激活上的模型，并通过分析有害提示搜索SAE的潜在空间，发现导致模型从拒绝转向服从的特征集，展示其因果影响并创建‘监狱逃脱’现象。研究方法包括三个阶段：（1）拒绝方向：找到一个拒绝中介的方向并收集靠近该方向的SAE特征；（2）贪婪过滤：缩减到最小的特征集；（3）交互发现：拟合一个因子化机器（FM），捕捉剩余激活特征与最小特征集之间的非线性相互作用。这一流程提供了一个广泛的‘监狱逃脱’关键特征集，揭示了拒绝行为的机制基础。同时，研究还发现了冗余特征，这些特征在早期特征不被抑制的情况下保持沉默。这项研究强调了通过操纵可解释的潜在空间进行细粒度审核和针对性干预的潜在可能性。
### Innovation
本文运用稀疏自编码器（SAEs）在模型的潜在空间中搜索有害提示导致模型从拒绝转向服从的特征集，从而展示了细粒度因果关系和创建‘监狱逃脱’的现象。此外，研究还揭示了冗余特征的存在及其作用机制。这一方法为理解和改进大型语言模型的安全行为提供了新的视角和工具。
### Conclusion
本文通过研究两个公开的指令调优模型Gemma-2-2B-IT和LLaMA-3.1-8B-IT，利用稀疏自编码器（SAEs）在模型潜在空间中识别导致模型拒绝行为改变的关键特征。这一研究揭示了拒绝行为的潜在机制，并提供了关于冗余特征和潜在空间的见解。未来研究可以进一步探索如何利用这些发现进行模型的安全审计和干预。
## 498. `cs.CL` - CFDLLMBench：计算流体动力学中评估大型语言模型的一个基准套件 [PDF](https://arxiv.org/pdf/2509.20374), [HTML](https://arxiv.org/abs/2509.20374)
### Authors
Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan
### Background
大型语言模型（LLMs）在通用自然语言处理任务上表现出色，但它们在自动化复杂物理系统中数值实验方面的应用尚未充分探索。作为几十年来计算科学的主要工具，计算流体动力学（CFD）为评估LLMs的科学能力提供了一个独特且具有挑战性的测试平台。因此，通过创建一个综合性的基准测试套件CFDLLMBench来评估LLMs在CFD任务中的性能，该工具包含CFDQuery、CFDCodeBench和FoamBench三个互补组件，旨在全面评估LLM在CFD知识、数值和物理推理以及上下文相关实现CFD工作流方面的表现。基准测试结合了详细的任务分类和严格的评估框架，为LLM性能提供了可再现的结果，并量化了代码执行性、解决方案准确性和数值收敛行为。总之，CFDLLMBench为开发和评估LLM驱动的复杂物理系统数值实验自动化奠定了坚实的基础。
### Innovation
CFDLLMBench是针对计算流体动力学评估大型语言模型的第一个基准测试套件，它包括详细的任务分类和严格的评估框架，并且设计了三个互补组件：CFDQuery、CFDCodeBench和FoamBench，全面评估LLM在CFD知识、数值和物理推理以及上下文相关实施CFD工作流方面的表现。此外，该基准测试还提供可再现的结果并量化了代码执行性、解决方案准确性和数值收敛行为，使得对于LLMs驱动的复杂物理系统数值实验自动化提供了新的研究基础。
### Conclusion
CFDLLMBench为开发和评估大型语言模型在复杂物理系统数值实验中的应用建立了坚实的基础，它通过严格的评估框架提供可再现结果，并量化了代码执行性、解决方案准确性和数值收敛行为，从而为实现LLMs驱动的自动化工具发出积极信号，虽然目前仍在初步阶段，但为未来的研究和应用提供了极大的潜力。
## 499. `cs.CL` - 口头采样：如何缓解模式坍缩并解锁大模型多样性 [PDF](https://arxiv.org/pdf/2510.01171), [HTML](https://arxiv.org/abs/2510.01171)
### Authors
Jiayi Zhang,Simon Yu,Derek Chong,Anthony Sicilia,Michael R. Tomz,Christopher D. Manning,Weiyan Shi
### Background
在模型训练后调整期间，通常会减少大语言模型LLM的多样性，出现一种现象称为模式坍缩。以往的研究通常归因于算法本身的局限性，本文发现了一个根本性的、普遍的数据层面驱动因素：偏好数据中存在的典型性偏差。这种偏差源于认知心理学中的已建立发现，即标注者系统地偏好熟悉的文本。本文从理论上对该偏差进行了形式化，在偏好数据集上进行了实证验证，并展示了这种偏差在模式坍缩中的核心作用。
### Innovation
本文引入了一种名为口头采样(Verbalized Sampling，VS)的简单且无需训练的提示策略，以绕过模式坍缩。VS提示模型口头化一组响应的概率分布（例如，“生成5个关于咖啡的笑话及其相应的概率”）。全面的实验表明，VS在创意写作、对话模拟、开放型问题回答和生成合成数据等多个场景中显著提高了性能，同时不牺牲事实准确性和安全性。例如，在创意写作中，VS将多样性提高了1.6至2.1倍。本文还观察到，更强大的模型从VS中受益更多。这项工作提供了对模式坍缩的新数据导向视角，并提供了一种实用的推理时解决方案，帮助解锁预训练生成性多样性。
### Conclusion
本文的工作为模式坍缩提供了一个新的数据导向的视角，并提供了一种实用的推理时解决方案，有助于解锁预训练生成性多样性。
## 500. `cs.CL` - CLARITY: 临床助理用于转诊、推理和分类 [PDF](https://arxiv.org/pdf/2510.02463), [HTML](https://arxiv.org/abs/2510.02463)
### Authors
Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets
### Background
该研究旨在开发一种基于人工智能的平台，以优化患者与专科医生的转诊流程、临床咨询和病情严重程度评估。CLARITY平台通过结合有限状态机（FSM）的结构对话流程和使用大规模语言模型（LLM）分析症状并优先转介专科医生，实现此目标。该平台基于模块化的微服务框架，确保了在医疗保健领域的安全、高效和稳健运行，并且易于根据现有工作流程和IT解决方案进行扩展。此前已有报道表明，CLARITY已被集成到一个大规模的国家级跨医院平台中，在部署两个月内完成了超过55,000次内容丰富的用户对话，其中2,500次对话由专家标注用于后续验证。
### Innovation
CLARITY平台的独特之处在于其混合架构，涵盖了有限状态机用于结构化对话流程以及结合了大规模语言模型进行症状分析和优先专科转诊推荐的功能。此外，该平台还基于模块化的微服务框架，确保了在医疗保健领域的安全、高效和稳健运行，并能够灵活且快速地扩展以适应现有工作流程和IT解决方案的需求。目前为止，CLARITY在初次尝试的转诊精度上超过了人类的表现，并且该过程仅需人类所花费时间的大约三分之一。这表明该平台能够通过自动化和智能化手段显著优化医疗保健流程和效果。
### Conclusion
该平台的临床助理CLARITY已经成功地集成到了国家级跨医院的平台上，并且经过两个月的大规模部署后，初步验证结果表明，CLARITY不仅能够以更高的精度进行初次尝试的转诊，还能显著缩短临床咨询的时间，从而有可能大幅提高医疗保健服务的效率和质量。未来的研究需要进一步测试该平台在不同医疗环境下的应用效果以及其长期运营的稳定性和可持续性。
## 501. `cs.CL` - 使用QLoRA对罗马乌尔都-英语代码混合文本进行冒犯语言检测的大语言模型微调 [PDF](https://arxiv.org/pdf/2510.03683), [HTML](https://arxiv.org/abs/2510.03683)
### Authors
Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov
### Background
在使用代码混合的语言，如罗马乌尔都语，中使用贬义词会对自然语言处理系统构成挑战，因为存在未明确的语法、不一致的拼写和缺乏标注的数据。
### Innovation
提出了一种基于QLoRA的微调框架，用于改进罗马乌尔都-英语文本中的冒犯语言检测。使用Google Translate将罗马乌尔都-英语代码混合数据集翻译成英语，以便利用英语的大语言模型，同时认识到这种翻译会减少对代码混合特征的直接参与。通过使用记忆效率高的适配方式（QLoRA），对包括Meta LLaMA 3 8B、Mistral 7B v0.1、LLaMA 2 7B、ModernBERT和RoBERTa在内的多个变压器和大语言模型进行了微调。在手动标注的罗马乌尔都语数据集上进行了训练和评估，重点是使用英文翻译的低资源输入的分类性能。研究表明，Meta LLaMA 3 8B和Mistral 7B分别以91.45和89.66的F1分数在所有测试模型中表现出最高的性能，超过了传统的基于变压器的基线。
### Conclusion
研究证明QLoRA在低资源环境中，如代码混合冒犯语言检测，对微调高性能模型的有效性，并确认了大语言模型在该任务中的潜力。这项工作为罗马乌尔都语的管理提供了一种可扩展的方法，并为基于大语言模型的多语言冒犯检测系统铺平了道路。
## 502. `cs.CL` - LLMs的内部层是否揭示了逃逸检测的模式？ [PDF](https://arxiv.org/pdf/2510.06594), [HTML](https://arxiv.org/abs/2510.06594)
### Authors
Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis
### Background
大语言模型（LLMs）的日益普及和可访问性使其易受恶意用户操控，这些用户通过精心设计的提示来获取受限制或敏感输出，这种行为被称为‘逃逸’。尽管已提出多种防御机制，但攻击者不断开发新的提示技术，没有模型可以完全抵御攻击。因此，研究LLMs的内部行为及其对逃逸的反映成为一个重要议题。
### Innovation
本研究通过分析LLMs内部层对逃逸提示和良性提示的响应，揭示了两者间的不同模式。研究特别关注开源LLM GPT-J和状态空间模型Mamba2的表现，这为开发基于模型内部动态的可靠逃逸检测和防御方法提供了新的线索。
### Conclusion
研究结果表明，通过分析LLMs的内部动态，可以为逃逸的检测和防御提供有希望的方向。这为未来的研究指明了潜在的发展路径。
## 503. `cs.CL` - 从人类团队可否应用于多智能体系统？结构、多样性与互动动力学的作用 [PDF](https://arxiv.org/pdf/2510.07488), [HTML](https://arxiv.org/abs/2510.07488)
### Authors
Rasika Muralidharan,Haewoon Kwak,Jisun An
### Background
多智能体系统（MAS）结合了大型语言模型（LLM）驱动的智能体正受到关注，然而较少的研究探讨其团队动态。本文受到人类团队科学的启发，提出了一种多智能体框架来研究团队科学的核心方面：结构、多样性和互动动态。
### Innovation
本文通过多任务评估，探讨了团队结构、多样性对团队表现的影响，并通过访谈揭示了智能体的自信程度及其合作中的挑战，特别强调了交流协调方面的局限性。
### Conclusion
本文的研究结果表明，扁平结构的团队通常比层级结构的团队表现更好，而多样性的影响是复杂的。智能体对团队协作表现出自信，但在任务后的反思中揭示出整合挑战，特别是在对话协调方面。
## 504. `cs.CL` - EVALUESTEER: 测量奖励模型向价值观和偏好方向的可控性 [PDF](https://arxiv.org/pdf/2510.06370), [HTML](https://arxiv.org/abs/2510.06370)
### Authors
Kshitish Ghate,Andy Liu,Devansh Jain,Taylor Sorensen,Atoosa Kasirzadeh,Aylin Caliskan,Mona T. Diab,Maarten Sap
### Background
随着大型语言模型（LLMs）的全球部署，创建能够容纳世界各国用户多样化偏好和价值观的多元化系统变得至关重要。现有的数据集不能支持对奖励模型（RMs）可控性的评估，因此研究团队开发了EVALUESTEER基准，旨在测量LLMs和RMs根据心理学和人机交互文献中的价值观和风格偏好方向进行调节的能力。EVALUESTEER通过合成生成165,888个偏好对来实现在4个价值观维度（传统、世俗理性、生存和自我表达）和4个风格维度（语句量、可读性、自信度和温暖度）上的系统性变化，以此进行评估。
### Innovation
EVALUESTEER是一个基准，旨在测量LLMs和RMs根据用户的偏好进行调节的能力。它通过合成生成大量偏好对数据，填补了现有数据集在支持控制性评估奖励模型方向方面的空白。通过EVALUESTEER，研究团队探讨了模型准确识别用户多样化的价值观和偏好能力的限制，并提出了一种新的测试方案，以促进开发针对多样化人类价值观和偏好的可调节奖励模型。
### Conclusion
即使在提供用户完整的价值观和风格偏好信息的情况下，最好的模型也只实现了不到75%的正确选择响应的准确率。这表明，当前的奖励模型在识别和适应相关用户配置文件信息方面存在明显不足。EVALUESTEER揭示了这些局限性，并为开发可以针对多样的人类价值和偏好的可调节奖励模型提供了具有挑战性的试验环境。
## 505. `cs.CL` - 从成对比较中在线提取评价标准 [PDF](https://arxiv.org/pdf/2510.07284), [HTML](https://arxiv.org/abs/2510.07284)
### Authors
MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek
### Background
当前，对于LLMs训练使用开放性长文回答时，缺乏可验证奖励，只能依赖于粗略的人类偏好。以往研究表明，基于评价标准的强化学习可以提高模型的训练成效。然而，现有的方法大多采用静态评价标准，这种静态标准容易被‘奖励欺诈’，无法捕捉训练中出现的新需求。为解决这个问题，本文提出了一种新的方法 Online Rubrics Elicitation（OnlineRubrics），这种方法利用在线的成对比较方式动态生成评价标准，能够持续地识别和缓解训练过程中出现的问题，确保模型持续优化。
### Innovation
本文提出的Online Rubrics Elicitation（OnlineRubrics）方法，能够在线地生成和更新评价标准。通过基于成对比较的方式动态抽取评价标准，这种方法能够在训练过程中不断识别和缓解错误，确保模型在整个训练期内都能取得一致的提升。实验结果显示，这种方法在AlpacaEval、GPQA、ArenaHard以及专家问题和评价标准的验证集上均优于仅使用静态评价标准的方法，平均改进幅度达到8%。此外，这种方法生成的评价标准显示出透明度、实用性、组织性和推理等重要主题。
### Conclusion
本文提出了一种有效的方法 Online Rubrics Elicitation，通过在线成对比较动态生成和更新评价标准，有效提高了模型在开放式长文回答任务的训练成效。实验结果验证了这种方法的优越性，并通过分析生成的评价标准揭示了几项重要主题。这种实时且智能的方法为模型训练提供了一种新的优化途径，对未来强化学习和模型训练具有重要参考价值。
## 506. `cs.CL` - 人工智能遭遇 populism：使用大规模语言模型推进 populism 研究 [PDF](https://arxiv.org/pdf/2510.07458), [HTML](https://arxiv.org/abs/2510.07458)
### Authors
Eduardo Ryô Tamaki(German Institute for Global and Area Studies),Yujin J. Jung(Mount St. Mary's University),Julia Chatterley(Princeton University),Grant Mitchell(University of California, Los Angeles),Semir Dzebo(University of Oxford),Cristóbal Sandoval(Diego Portales University),Levente Littvay(ELTE Centre for Social Sciences),Kirk A. Hawkins(Brigham Young University)
### Background
测量民粹主义的思想内容仍是一个挑战。传统的基于文本分析的策略尽管在建立田野基础和提供有效的、客观的民粹主义框架指标方面发挥了关键作用，但这些方法成本高、耗时且难以横向扩展到多种语言、情境和大规模的语料库中。
### Innovation
本文介绍了一种基于标记表和锚点引导的思想链（CoT）提示方法，这种方法模仿了人类编码器的培训过程。通过利用全球民粹主义数据库（GPD），一个包含全球领导人的演讲并标注了民粹主义程度的综合数据集，作者指导模拟能够推理的大规模语言模型（LLM），并通过复制GPD中的评分测试多种专有和开源权重模型。研究发现，这种领域特定的提示策略能够让LLM在民粹主义分类准确率上达到专家人类编码器的水平，展示了其在处理民粹主义的复杂、情境敏感方面的能力。
### Conclusion
领域特定的提示策略能够使大规模语言模型在民粹主义分类上达到专家级水平，证明了其处理民粹主义复杂性和情景敏感性的潜力，这为推进民粹主义研究提供了新的工具。
## 507. `cs.CL` - ARM2：具有视觉理解与可执行代码的自适应推理模型 [PDF](https://arxiv.org/pdf/2510.08163), [HTML](https://arxiv.org/abs/2510.08163)
### Authors
Jian Xie,Zhendong Chu,Aoxiao Zhong,Kai Zhang,Mingzhe Han,Xing Fan,Jialie Shen,Qingsong Wen
### Background
大型推理模型(LRMs)经常遭受“过度推理”问题，即在简单任务中生成不必要的长推理过程。已经提出了一些策略来缓解这个问题，例如长度惩罚或路径机制，但这些方法通常是直观的且针对特定任务，缺乏一种适应推理的通用框架。
### Innovation
本文介绍了一种统一模型ARM2，它通过强化学习框架结合长度感知优化的自适应平衡推理性能和效率，适用于多种格式。ARM2不仅集成视觉理解扩展了其应用范围，还结合了可执行代码进行推理，显著降低了令牌成本同时保持了任务性能。
### Conclusion
实验结果表明，ARM2在GRPO训练的传统推理模型中达到了同等的性能，且平均减少了70%以上的令牌使用量。此外，深入分析进一步验证了ARM2的有效性和设计的合理性。
## 508. `cs.CL` - 为LLMs负责任的人工智能中的可扩展多语言PII注释 [PDF](https://arxiv.org/pdf/2510.06250), [HTML](https://arxiv.org/abs/2510.06250)
### Authors
Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu
### Background
随着大规模语言模型（LLMs）的广泛应用，确保其在不同监管环境下的可靠处理个人可识别信息（PII）变得至关重要。因此，本文提出了一个适用于注释13种欠代表语言的大型多语言数据策源框架，涵盖了约336种特定地区PII类型。该框架结合了语言专家知识和严格的质保措施，实现了从试点、训练到生产的多阶段注释方法，进一步提高了召回率和误报率。此外，通过利用注释者间的一致性指标和根本原因分析，该框架系统地揭开了并解决了注释中的不一致性问题，从而生成高质量的数据集，适合监督下的LLM微调。对于非监督理解型的LLM，本研究还强调了多语言PII标注的常见挑战，并展示了迭代驱动的分析流水线如何提升注释质量和下游模型的可靠性。
### Innovation
提出了一个 scalable 多语言数据策源框架，用于高质量的 PII 注释，涵盖 13 种欠代表语言和约 336 种特定地区 PII 类型。该框架结合了语言专家知识和严格的质保措施，采用了多阶段的人工在环注释方法，利用注释者间的一致性指标和根本原因分析解决不一致性问题，生成高质量数据集，适用于监督下的 LLM 微调。该研究还展示了迭代驱动的分析流水线如何提升注释质量和下游模型的可靠性，强调了多语言 PII 标注中的常见挑战。
### Conclusion
该框架通过提高召回率和降低误报率，有效解决了大规模语言模型处理个人可识别信息的挑战。通过提升注释质量和保证下游模型的可靠性，推动了负责任的人工智能在大规模语言模型中的应用。
## 509. `cs.CL` - 海绵工程：异质性和机构化长上下文评估的背景工程 [PDF](https://arxiv.org/pdf/2510.07414), [HTML](https://arxiv.org/abs/2510.07414)
### Authors
Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li
### Background
现代大型语言模型在合成的“针扎稻草堆”（NIAH）基准测试中表现良好，但这些测试忽略了噪声上下文源于偏差检索和机构性工作流的现象。我们论证认为，通过海绵工程，可以构建真实世界噪声长上下文，这些上下文能够忠实捕捉异质偏差检索和机构性工作流传导错误的关键因素，以测试模型的长上下文鲁棒性。通过HaystackCraft新建立的NIAH基准来实例化它，该基准基于完整版英文维基百科链接网络，并包含多跳问题。HaystackCraft评估了不同检索策略的异质性（例如，稀疏、密集、混合和图基）如何影响干扰者的构成、稻草堆排序以及下游大语言模型的表现。此外，HaystackCraft进一步扩展了NIAH到动态和大语言模型依赖的场景，模拟了机构操作，其中模型会改进查询、反思其过去的推理，并决定何时停止。试验使用了15个长上下文模型，表明（1）虽然更强的密集检索者可以引入更具挑战性的干扰者，但图基重排序同时提高了检索的有效性并减轻了更多有害的干扰者；（2）在机构性测试中，即使是先进的模型如Gemini2.5 Pro和GPT-5也会受自动生成干扰者或在进行早期停止方面表现困难而遭受逐步失败。这些结果突显了机构性长上下文推理的持续挑战，并将HaystackCraft确立为未来研究的重要测试平台。
### Innovation
建立了一个名为HaystackCraft的新NIAH基准，基于完整版英文维基百科链接网络，并包含多跳问题。HaystackCraft评估了不同检索策略对干扰者组成和模型性能的影响，并扩展了NIAH测试到动态、依赖大模型的场景，模拟了机构性操作。通过这些测试和分析，发现了噪声长上下文的挑战性特征和机构模型在长上下文推理中的局限性。
### Conclusion
实验结果突出显示了机构性长上下文推理中的持续挑战，并将HaystackCraft确立为未来研究的重要测试平台。
## 510. `cs.CL` - 通过排名和大语言模型融合改进图像描述的详细程度 [PDF](https://arxiv.org/pdf/2306.11593), [HTML](https://arxiv.org/abs/2306.11593)
### Authors
Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano
### Background
目前，最先进的（State-of-The-Art, SoTA）图像字幕模型通常在MicroSoft Common Objects in Context (MS-COCO)数据集上进行训练，包含由人类标注的平均长度约为十个标记的字幕。尽管这些模型对于一般场景理解有效，但较短的字幕往往无法捕捉复杂的场景和详细信息，也倾向于偏向于“平均”字幕，仅捕捉更一般方面而忽视了细微的细节。
### Innovation
本文提出了一种新颖的方法，通过结合来自不同SoTA字幕生成模型的字幕来生成更丰富和更具有信息性的图像字幕。该方法无需额外的模型训练：给定一张图像，它利用文献中的预训练模型生成初始字幕，然后使用一个新的基于图像-文本的度量（我们命名为BLIPScore）对这些字幕进行排名。之后，将最靠前的两个字幕使用大型语言模型（Large Language Model, LLM）融合生成最终、更详细的描述。
### Conclusion
在MS-COCO和Flickr30k测试集上的实验结果表明，这种方法在字幕-图像对齐和幻觉减少方面具有有效性，这些结果得到了评价指标ALOHa、CAPTURE和Polos的验证。主观研究还表明，这些模型生成的字幕通常更符合人类判断。通过结合不同SoTA模型的优势，我们的方法提高了图像描述的质量和吸引力，填补了自动化系统与人类生成描述丰富性之间的差距。这一进展使得生成更适合训练视觉-语言和字幕模型的字幕成为可能。
## 511. `cs.CL` - 部署小型LVLM评判器进行图表模型的实际评估：经验教训和最佳实践 [PDF](https://arxiv.org/pdf/2510.07545), [HTML](https://arxiv.org/abs/2510.07545)
### Authors
Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang
### Background
现有研究表明，仅包含7B参数的大型视觉-语言模型（LVLMs）在图表理解任务的自动化评委中显示出潜力。然而，参数量小于等于2B的小模型在作为评委时表现仍然不佳，这限制了它们在资源受限环境下的实际应用。这些小模型在现实世界的应用中由于参数量较少，难以有效地执行涉及大量数据和复杂查询的任务。因此，为实现经济高效的评估，本文提出了两种方法：（i）多标准提示，将单独的评估标准结合为一个查询，以及（ii）领域自适应迁移学习，即对2B参数的LVLM进行微调以在一个图表数据集上生成一个专用于图表理解的评判模型ChartJudge。实验表明，多标准提示暴露了鲁棒性差距，使得7B模型的性能大幅下降，即使是专门针对图表理解任务的LVLM评判器也受影响。此外，研究还发现，我们的小型LVLM（ChartJudge）能够有效地从一个数据集转移到另一个数据集，使其更为专业化。并且，对不同图表类型和查询复杂性的细致分析提供了有关模型大小、提示设计和迁移性之间权衡的实际见解，这些见解促进针对图表推理任务的评估规范化和规模化，同时保持成本效益。
### Innovation
本文提出了两种评估策略：（i）多标准提示，将多个评估标准整合为单一查询，（ii）领域自适应迁移学习，即调整参数量为2B的LVLM，使其能够执行专用于特定图表数据集的判决任务。通过这些方法，作者解决了小模型在资源受限环境下的评估难题，并显著提升了这些小模型在图表理解任务中的表现。研究工作展示了这种方法在提升小模型性能的同时，保持了相对较小的参数量和计算需求，有助于开发低成本、高效率的图表理解模型评判系统。
### Conclusion
本文通过引入多标准提示和领域自适应迁移学习的方法，增强了小型（<=2B参数）LVLM在评价图表理解模型时的有效性，不仅提升了性能，还提供了针对不同图表类型和查询复杂性的性能优化策略。这些方法指导了构建经济高效、可扩展的图表推理任务评判模型的最佳实践，从而确保了模型在资源受限环境中也能持续稳定地进行高质量评估。
## 512. `cs.CL` - 使用随机舍入直接量化训练语言模型 [PDF](https://arxiv.org/pdf/2412.04787), [HTML](https://arxiv.org/abs/2412.04787)
### Authors
Kaiyan Zhao,Tsuguchika Tabaru,Kenichi Kobayashi,Takumi Honda,Masafumi Yamazaki,Yoshimasa Tsuruoka
### Background
虽然近年来使用二进制或三进制权重的量化大型语言模型（LLMs），如BitNet，大大降低了部署时的内存使用，但这些模型的训练仍需要大量内存。这是因为需要维持高精度（即未量化）权重来进行径直贯穿估计，这在整个训练过程中占据大量内存。因此，研究者探索了在反向传播中直接更新量化低精度权重，而不依赖径直贯穿估计法，旨在减少训练过程中的内存使用。通过使用随机舍入技术，使低位权重在整个训练过程中使用时的信息损失最小化。
### Innovation
提出了直接使用量化低精度权重进行训练的方法，避免了径直贯穿估计法的使用，减少了训练过程中的内存占用。具体来说，采用随机舍入技术最大程度地减小了低位权重使用过程中的信息损失。结果显示，即使使用受限于三值的低精度权重进行训练也是可行的；将位宽扩展到8位可与BitNet b1.58性能相当；模型在精度缩放和内存减少的情况下仍保持稳健，并且在从FP32迁移到较低内存环境（BF16/FP8）时性能下降最小；此外，该模型支持使用三值权重进行推理，展现了其在部署中的灵活性。
### Conclusion
该研究通过直接量化训练语言模型，并使用随机舍入技术，证明了即使使用低精度权重进行训练也是可行的，且能够节省内存，同时保持模型性能稳定。
## 513. `cs.CL` - 基于检索链增强生成的推理方法 [PDF](https://arxiv.org/pdf/2501.14342), [HTML](https://arxiv.org/abs/2501.14342)
### Authors
Liang Wang,Haonan Chen,Nan Yang,Xiaolong Huang,Zhicheng Dou,Furu Wei
### Background
现有的RAG（ Retrieval-Augmented Generation）模型通常在生成过程中只进行一次检索步骤，这样会限制其在处理复杂查询时的效果，因为初次检索结果可能不完整或不准确。
### Innovation
本文提出了一种名为CoRAG（Chain-of-Retrieval Augmented Generation）的方法。CoRAG允许模型根据检索状态动态地重新构建查询，通过使用拒绝采样自动生成中间检索链来增强现有的RAG数据集。论文还提出了各种解码策略以控制测试时计算的长度和样本检索链的数量。
### Conclusion
CoRAG在多项基准测试中表现良好，特别是在多跳问答任务中，EM得分提高了超过10个点，超过了强基线。在KILT基准上，CoRAG在各种知识密集型任务中取得了新的最先进性能。此外，研究还提供了关于CoRAG扩展行为的全面分析，为未来开发事实性和基于事实的基础模型的研究奠定了基础。
## 514. `cs.CL` - CausalVLBench: 在大型视觉语言模型中评估视觉因果推理 [PDF](https://arxiv.org/pdf/2506.11034), [HTML](https://arxiv.org/abs/2506.11034)
### Authors
Aneesh Komanduri,Karuna Bhaila,Xintao Wu
### Background
大型语言模型（LLMs）在各种语言任务中表现出色，特别是在上下文学习能力方面。通过引入视觉输入，大型视觉语言模型（LVLMs）在识别和视觉问答（VQA）等任务中也取得了很好的成绩。尽管在因果推理任务如因果发现和反事实推理方面对LLMs的兴趣不断增加，但对LVLMs在视觉因果推理任务上的能力的研究还相对较少。因此，该研究提出了一项全面的因果推理基准，旨在评估基于LVLMs的多模态上下文学习能力，并涵盖因果结构推理、干预目标预测和反事实预测三个代表性任务。
### Innovation
本研究正式推出了CausalVLBench基准，具体涵盖了三个代表性的任务：因果结构推理、干预目标预测和反事实预测。评估最先进的开源LVLMs在CBRL数据集上的因果推理能力，揭示现有视觉语言模型的优缺点，并激发新的方向和框架来提高LVLMs的视觉因果推理能力。
### Conclusion
CausalVLBench将阐明现有视觉语言模型的不足之处，并激发改进LVLMs视觉因果推理能力的新方向和框架。
## 515. `cs.CL` - LLM作为评估者指标以弥合软件工程任务中的人类评估差距 [PDF](https://arxiv.org/pdf/2505.20854), [HTML](https://arxiv.org/abs/2505.20854)
### Authors
Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,Kui Liu,Xin Xia,David Lo
### Background
大型语言模型（LLMs）和其他自动化技术被越来越多地用于支持软件开发人员生成软件制品，如代码片段、补丁和注释。然而，准确评估这些生成的制品的正确性仍然是一个重大挑战。人工评估虽然准确但耗时费力且缺乏可扩展性，而许多自动评估指标虽然可扩展且几乎不需要人工努力，但往往不能准确反映生成的软件制品的实际正确性。
### Innovation
本文引入了SE-Jury，这是第一个针对LLM-Ensemble-Judge设计的评估指标，用于准确评估生成的软件制品的正确性。SE-Jury首先定义了五个独立的评估策略，通过动态团队选择机制，确定最合适的团队来生成最终的正确性分数。
### Conclusion
通过在软件工程（SE）基准测试中，横跨代码生成、自动程序修复和代码总结三个任务，评估结果表明SE-Jury在与人类判断的一致性上明显优于现有自动指标，提高了29.6%到140.8%。在代码生成和程序修复任务中，SE-Jury与人类注释者达成的共识程度接近于注释者间的一致性水平。这些结果强调了SE-Jury作为这些SE任务中人力评价的可扩展和可靠替代方案的潜力。
## 516. `cs.CL` - 无窥探的调优：LLM后训练中的可证明隐私与泛化界 [PDF](https://arxiv.org/pdf/2507.01752), [HTML](https://arxiv.org/abs/2507.01752)
### Authors
Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud
### Background
深度学习中的梯度优化为模型训练提供了高效的手段，但这一过程可能泄露敏感数据信息，引发隐私和安全问题。相比之下，黑盒优化方法通过模型表现来指导优化，适用于数据访问受限、对抗风险高或泛化能力欠佳的情景。论文讨论了使用黑盒优化方法在LLM后训练中的应用，特别是在引入BBoxER这一黑盒进化方法后，如何通过隐式的数据压缩诱导信息瓶颈，提供了隐私保护、抗数据投毒攻击及信息提取攻击的理论保证。尽管黑盒优化方法在计算上存在挑战，但实验结果表明，BBoxER可以提升LLM性能，有效泛化，并具有成员推理攻击的抵抗能力。
### Innovation
论文引入了一种名为BBoxER的黑盒进化方法，用于LLM后训练。BBoxER通过隐式压缩训练数据，诱导信息瓶颈，从而保证其在隐私保护、抗数据投毒攻击和信息提取攻击方面的性能。此外，还提供了可靠的非真空泛化保证，并在实验中验证了其在应对泛化能力及计算挑战方面的有效性。
### Conclusion
BBoxER作为一种黑盒优化方法，展示了在隐私敏感或数据受限环境中部署的潜力，即使面临计算和可扩展性挑战，仍能提供非真空的泛化保证。这使其成为梯度优化的有效补充，特别适用于需要保护隐私和安全的环境。
## 517. `cs.CL` - 通过LLM驱动的迭代代码图搜索进行问题定位 [PDF](https://arxiv.org/pdf/2503.22424), [HTML](https://arxiv.org/abs/2503.22424)
### Authors
Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu
### Background
问题解决旨在根据问题描述在实际代码仓库中生成修复补丁。问题定位是准确问题解决的基础。最近，基于LLM的问题定位方法展示了最先进的性能。然而，这些方法要么从问题描述中提到的文件开始搜索，要么在整个仓库中搜索，难以在广度和深度之间平衡搜索空间以高效地找到目标。此外，这些方法允许LLM自由探索整个仓库，这使控制搜索方向以防止LLM搜索错误目标变得具有挑战性。
### Innovation
该论文介绍了CoSIL，一种无需训练或索引的LLM驱动的功能级别问题定位方法。CoSIL采用两阶段代码图搜索策略。首先，在动态构建的模块调用图上在文件级别进行广泛的探索，然后在函数级别通过扩展模块调用图到函数调用图并执行迭代搜索进行深入分析。为了精确控制搜索方向，CoSIL设计了一个剪枝器来过滤无关的方向和无关的上下文。为了防止长上下文中的错误交互格式，CoSIL引入了反照机制，该机制使用短上下文中的附加独立查询来增强形式化能力。实验结果表明，CoSIL在SWE-bench Lite和SWE-bench Verified上的Top-1定位精度分别为43.3%和44.6%，分别使用Qwen2.5-Coder-32B，平均优于最先进的方法96.04%。当将CoSIL集成到问题解决方法Agentless中时，问题解决率提高了2.98%至30.5%。
### Conclusion
CoSIL通过两阶段代码图搜索策略，结合功能级别的精确控制剪枝器和短上下文中的反照机制，显著提高了问题定位的精度和效果。
## 518. `cs.CL` - Mem4Nav: 提升城市环境视觉语言导航的分层空间认知长短时记忆体系 [PDF](https://arxiv.org/pdf/2506.19433), [HTML](https://arxiv.org/abs/2506.19433)
### Authors
Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li
### Background
在大规模城市环境中进行视觉语言导航（VLN）的挑战在于要求智能体在复杂的场景中理解语言指令，并且具备在长时间内回忆相关经验的能力。目前的模块化管道虽然具有解释性，但缺乏统一的记忆机制，而端到端的多模态语言模型（M）LLM虽然在融合视觉和语言方面表现出色，但也受限于固定上下文窗口和隐式的空间推理。
### Innovation
我们提出了Mem4Nav，一种分层的空间认知长短时记忆系统，可以增强任何VLN后端。该系统结合了稀疏八叉树进行精细体素索引，以及语义拓扑图进行高级地标连接性，并将两者存储在通过可逆Transformer嵌入的可训练记忆标记中。长期记忆（LTM）压缩并保留了八叉树和图节点处的历史观测信息，而短期记忆（STM）则缓存最近的多模态条目为实时障碍物避免和局部规划提供支持。每个步骤中，STM检索急剧地减少了动态上下文，并在需要更深的历史信息时通过无损解码LTM标记来重建过去的嵌入。
### Conclusion
Mem4Nav在Touchdown和Map2Seq基准测试中，分别在三个不同的后端（模块化、基于提示的LLM最先进的VLN和基于跳跃注意机制的LLM最先进的VLN）上，显示出了7-13%的指令完成率提高、足够的SPD减少，并且nDTW提高了超过10%。消融实验进一步证实了分层地图和双向记忆模块的不可或缺性。我们的代码已经开源。
## 519. `cs.CL` - 基于语言模型的强化学习在量化交易中的应用 [PDF](https://arxiv.org/pdf/2508.02366), [HTML](https://arxiv.org/abs/2508.02366)
### Authors
Adam Darmanin,Vince Vella
### Background
量化交易需要短期战术决策与长期金融目标一致，目前算法交易中已经使用强化学习（RL）来处理此类问题，但由于RL的短视行为和不透明的策略，其应用受限。此外，大型语言模型（LLMs）在提供了战略推理和多模态信号解释方面与RL互补，但前提是通过结构化提示进行指导。
### Innovation
本文提出了一种混合框架，其中LLMs生成高层次的交易策略以指导RL。该框架通过对LLM生成策略的专家评审以及LLM指导的代理与未受指导的RL基线在夏普比率（SR）和最大回撤（MDD）方面的性能评估，展示了LLM在提升回报和风险指标方面的优越性。
### Conclusion
实证结果表明，LLM指导下的代理在收益和风险控制方面均优于传统的RL基准。
## 520. `cs.CL` - 大型语言模型代理在药物发现中模块化任务执行 [PDF](https://arxiv.org/pdf/2507.02925), [HTML](https://arxiv.org/abs/2507.02925)
### Authors
Janghoon Ock,Radheesh Sharma Meda,Srivathsan Badrinarayanan,Neha S. Aluru,Achuth Chandrasekhar,Amir Barati Farimani
### Background
本文介绍了一种基于大型语言模型（LLMs）的模块化框架，该框架能够自动化并简化药物发现早期阶段的关键任务。通过结合LLM推理和领域特定工具，该框架完成生物医学数据检索、领域特定问题回答、分子生成、性质预测、性质感知分子精炼以及3D蛋白-配体结构生成等任务。
### Innovation
该框架在案例研究中，针对淋巴细胞性白血病中的BCL-2靶点，其自主检索相关的生物分子信息，并使用增强上下文准确性的策略回答了机制性问题。然后，该框架生成了化学多样性的种子分子并预测了67个ADMET相关属性，从而指导了分子的迭代精炼。在两个迭代中，QED大于0.6的分子数量从34增加到55，并且满足经验药物化学筛选标准的分子数量也有所增加。此外，该框架还利用Boltz-2生成3D蛋白-配体复合物并提供候选化合物的快速结合亲和力估算。
### Conclusion
这些结果表明该方法有效支持分子筛选、优先级排序和结构评估。其模块化设计使未来的工具和模型的集成变得灵活，为人工智能辅助治疗发现提供了可扩展的基础。
## 521. `cs.CL` - 预印本：海报：我刚刚浏览的网站是由LLM编写的吗？ [PDF](https://arxiv.org/pdf/2507.13933), [HTML](https://arxiv.org/abs/2507.13933)
### Authors
Sichang Steven He,Ramesh Govindan,Harsha V. Madhyastha
### Background
随着大量语言模型（LLMs）生成网页内容，导致网页内容呈‘LLM主导’状态，而这些内容由于LLMs的剽窃和虚构特性，内容可能不可靠和不道德。然而，网站很少披露此类信息，人类读者也难以区分，因此需要开发可靠的‘LLM主导’内容检测器。现有的基于LLM的检测器在网页内容上表现不佳，因为网页内容具有低阳性率、复杂标记和多样化体裁等特点，而不是干净、散文式的基准数据，这使得现有的先进检测器优化效果不佳。
### Innovation
本文提出了一个可靠、可扩展的流水线方法，用于分类整个网站。不同于通过对每个页面提取文本进行简单的分类，本文方法基于LLM文本检测器的多种散文式页面输出来分类每个网站，以提高准确率。研究团队通过收集2个不同的真实基准数据集共120个网站的数据，并进行训练和评估后，其检测器在这些数据集上的测试准确率达到100%。在实际环境中，检测器在搜索引擎结果和其他数据集上检测到大量被‘LLM主导’的网站，表明这些网站正在变得越来越普遍并在搜索结果中排名靠前，这引发了对其对最终用户和整个Web生态系统的影响的质疑。
### Conclusion
通过开发可靠的‘LLM主导’内容检测器，本文解决了当前基于LLMs的检测器在网页内容上表现不佳的问题。检测到大量网页由LLMs生成这一发现引发了关于其对用户和Web生态系统影响的深入讨论。
## 522. `cs.CL` - 推理通过探索：一种增强学习框架以实现稳健的函数调用 [PDF](https://arxiv.org/pdf/2508.05118), [HTML](https://arxiv.org/abs/2508.05118)
### Authors
Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang
### Background
大型语言模型（LLMs）在函数调用的有效训练中面临一个关键挑战：如何平衡复杂推理路径的探索与稳定策略优化。传统的监督微调（SFT）方法无法提供稳健的推理能力，而传统的强化学习（RL）则面临探索效率低下的问题。
### Innovation
提出了一个新的增强学习框架EGPO（Exploration-guided Group Policy Optimization），该框架基于组相对策略优化（GRPO）来解决这一挑战。EGPO的核心是一个增强的优函数，将模型的链式思考（CoT）的熵集成到策略梯度计算中，以促进多样化的推理策略生成。通过引入一个通过裁剪机制精制的熵补贴，并结合严格的二元奖励信号，EGPO能够有效地引导模型发现结构化的准确工具调用模式。
### Conclusion
在挑战性的伯克利函数调用排行榜（BFCL）上，使用EGPO训练的4B参数模型在与之大小相近的模型中建立了新的最优纪录，超越了包括GPT-4o和Gemini-2.5在内的多种强劲对手。
## 523. `cs.CL` - AMFT：通过元学习优化模仿-探索平衡来对齐LLM推理器 [PDF](https://arxiv.org/pdf/2508.06944), [HTML](https://arxiv.org/abs/2508.06944)
### Authors
Lixuan He,Jie Feng,Yong Li
### Background
大型语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）两个阶段的管道进行微调，但这一过程中常常出现灾难性遗忘和模仿与探索之间的次优权衡问题。尽管最近有尝试将SFT和RL结合成单阶段方法，但缺乏一个有原则性的机制来动态平衡这两种范式。现阶段的单阶段方法使用他验性方法进行统一，但缺乏一个理论框架来解决这个问题。
### Innovation
本文重新定义了这一挑战，从理论角度引入了“隐式奖励”的概念，将SFT和RL视为互补的奖励信号而不是不同的方法。文中提出了Adaptive Meta Fine-Tuning (AMFT)，一种新颖的单阶段算法，它通过学习SFT的路径级隐式奖励和RL的结果级显式奖励之间的最优平衡来优化长期任务性能。AMFT的核心是一部具有元梯度自适应权重控制器，将SFT-RL的平衡视为可学习的参数，动态优化以最大化长期任务性能，并通过策略熵进行正则化确保稳定性。该研究通过自动生成有效的训练课程以实现自主发现。实验证明，AMFT在多个具有挑战性的基准测试中建立了新的SOTA，并在泛化性能上优于现有方法。
### Conclusion
元学习控制器在AMFT的稳健性、样本效率和性能上起着至关重要的作用，为LLM对齐提供了一个更系统和有效的方法。这项研究通过开源代码进行了验证，提供了一个重要的理论框架和实际应用。
## 524. `cs.CL` - ARS：适用于高效大型推理语言模型的自适应推理抑制 [PDF](https://arxiv.org/pdf/2510.00071), [HTML](https://arxiv.org/abs/2510.00071)
### Authors
Dongqi Zheng
### Background
大型推理语言模型（LRLMs或LRMs）在复杂推理任务中表现出卓越的能力，但在执行推理时会面临严重的计算效率低下问题，主要是由于过度推理现象。现有的一些高效推理方法在提升推理效率时，却难以在保持推理质量的同时降低推理成本。
### Innovation
提出了一种名为自适应推理抑制（ARS）的新型无需训练的方法，通过适应性确信度监控动态抑制冗余的推理步骤，引入了具有逐步抑制阈值的多检查点确信度估计机制，相较于静态抑制方法取得了更优的效率。
### Conclusion
在多个数学推理基准测试中，使用多种模型架构进行广泛评估表明，ARS 可以分别实现高达53%、46.1% 和57.9% 的 token、延迟和能效的降低，同时保持或提高推理准确性。
## 525. `cs.CL` - DeHate: 基于稳定扩散的多模态方法以缓解图像中的仇恨言论 [PDF](https://arxiv.org/pdf/2509.21787), [HTML](https://arxiv.org/abs/2509.21787)
### Authors
Dwip Dalal,Gautam Vashishtha,Anku Rani,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal
### Background
互联网上有害内容的增加不仅扭曲了公众对话，也对维护健康的数字环境提出了重大挑战。因此，本研究引入了一个专门为识别数字内容中的仇恨言论设计的多模态数据集。这一背景下，传统的仇恨言论检测方法已难以应对复杂多样的网络环境，急需新的技术手段来有效识别和去除仇恨信息，以净化网络空间和保护用户免受仇恨言论的影响。
### Innovation
本文提出的DeHater模型结合了带有稳定标识（watermarked）的稳定性增强（stability-enhanced）稳定扩散（stable diffusion）技术，并配合使用Digital Attention Analysis Module（DAAM），能够在图像中精确定位仇恨元素，生成详细的仇恨关注图（hate attention maps），最终通过模糊处理去除仇恨区域，从而有效净化图像内容。通过这种方式，该研究提出了新的基于AI的图像仇恨言论检测方法，特别是在文本提示下的多模态去仇恨化任务中表现突出，推动了更加伦理的社交媒体中的AI应用发展。
### Conclusion
本文介绍的DeHate数据集及DeHater模型为多模态仇恨言论检测提供了新的解决方案，并且其在图像去仇恨化任务中的表现证明了该方法在实际应用中的有效性和创新性。此外，该研究为未来的多模态仇恨言论检测和净化提供了重要参考和技术支持，有助于开发更符合伦理标准的社交媒体AI应用。
## 526. `cs.CL` - Anemoi：基于Coral Protocol的Agent-to-Agent通信MCP服务器的半集屮多智能体系统 [PDF](https://arxiv.org/pdf/2508.17068), [HTML](https://arxiv.org/abs/2508.17068)
### Authors
Xinxing Ren,Caelum Forder,Qianbo Zang,Ahsen Tahir,Roman J. Georgio,Suman Deb,Peter Carroll,Önder Gürcan,Zekun Guo
### Background
近年来，通用多智能体系统（MAS）主要采用上下文工程加中心化的规划模式，其中规划智能体通过单向提示传递协调多个工作智能体。虽然在这种强大的规划智能体模型下有效，但该设计存在两个重大局限性：（1）对规划智能体能力的强烈依赖，导致使用较小的语言模型（LLM）时性能下降；（2）智能体间通信受限，协作依赖于提示拼接，而非通过结构化讨论进行的实质改进。为解决这些问题，本文提出Anemoi，这是一种基于Coral Protocol的Agent-to-Agent（A2A）通信MCP服务器的半集中化MAS。
### Innovation
Anemoi 允许所有智能体在实时监控进度、评估结果、识别瓶颈和提出改进建议的同时进行结构化的直接合作。该模式减少了对单一规划智能体的依赖，支持适应性计划更新，并减少冗余上下文传递，从而实现了更可扩展的执行。在GAIA基准测试中，使用较小的LLM（GPT-4.1-mini）作为规划者，Anemoi 达到了52.73%的准确性，超越了最强开源基线OWL（43.63%）达9.09%之多，且在相同的LLM设置下取得了更好的结果。
### Conclusion
Anemoi 实现了更高效的多智能体系统，改善了传统设计中对强规划智能体的高依赖和通信限制问题，通过实验证明了其在多功能场景下的优越性能。
## 527. `cs.CL` - P2P: 一种针对大规模语言模型可靠背门防御的毒药配毒药方法 [PDF](https://arxiv.org/pdf/2510.04503), [HTML](https://arxiv.org/abs/2510.04503)
### Authors
Shuai Zhao,Xinyi Wu,Shiqian Zhao,Xiaobao Wu,Zhongliang Guo,Yanhao Jia,Anh Tuan Luu
### Background
在微调过程中，大型语言模型（LLMs）越来越容易受到数据污染后门攻击的影响，这些攻击会损害模型的可靠性和可信度。现存的防御策略普遍具有有限的一般化能力，只能针对特定的攻击类型或任务场景发挥作用。
### Innovation
本文提出了一种通用且有效的后门防御算法P2P。它通过在训练样本中注入良性触发器和安全替代标签，利用基于提示的学习在重新污染的数据集上进行微调，从而迫使模型将由触发器引起的表示与安全输出关联起来，以抵消原始恶意触发器的效果。P2P在不同任务设置和攻击类型中的跨环境表现表明了其实用性和普遍性。
### Conclusion
在分类、数学推理和摘要生成等任务上，通过广泛的实验验证了P2P算法相对于基线模型显著降低了攻击成功率。期望P2P能为抵御后门攻击提供指导，并促进安全可信的LLM社区的发展。
## 528. `cs.CL` - CAFL-L：基于拉格朗日对偶优化的嵌入式语言模型的约束感知联邦学习 [PDF](https://arxiv.org/pdf/2510.03298), [HTML](https://arxiv.org/abs/2510.03298)
### Authors
Dongqi Zheng,Wenjin Fu
### Background
联邦学习（Federated Learning, FedAvg）的技术背景在于在保护用户数据隐私的前提下，通过多设备协同学习模型。然而，不同设备的资源限制（如能量、通信、内存和热管理等）影响了模型训练的效果，传统的FedAvg方法未能有效处理这些资源约束问题。因此，如何在保持模型性能的同时，合理利用分布式设备的资源成为亟待解决的问题。
### Innovation
作者提出了一种全局优化方法CAFL-L，它通过拉格朗日对偶优化动态调整模型训练的重要参数（如冻结深度、本地步骤、批次大小以及通信压缩等），同时保留了训练稳定性和训练过程中的预算管理（通过梯度累积来保持令牌预算）。与传统的FedAvg相比，CAFL-L能够在不牺牲验证性能的前提下，大幅减少内存使用（降低20%）和通信成本（减少95%），使其更加适用于资源受限的边缘设备。
### Conclusion
实验结果表明，CAFL-L在满足约束条件的同时，仍能保持与标准FedAvg相当的验证性能，有望被实际应用到资源受限的边缘设备上，实现了资源使用效率的显著提高。
## 529. `cs.CL` - Reinforce-Ada：一种用于强化风格大型语言模型训练的自适应采样框架 [PDF](https://arxiv.org/pdf/2510.04996), [HTML](https://arxiv.org/abs/2510.04996)
### Authors
Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang
### Background
在使用强化学习（RL）对大型语言模型（LLMs）进行推理任务训练时，通常会被不稳定的梯度估计瓶颈所限制。这些不稳定的估计是由于响应在不同提示下进行固定的、均匀的采样所导致的。先前的研究，如GVM-RAFT，通过在预算约束下动态分配每个提示的推理预算来最小化随机梯度方差来应对这一问题。
### Innovation
本文提出了一种自适应采样框架Reinforce-Ada，针对在线后训练的LLMs，不断重新分配采样努力，对最具不确定性和学习潜力的提示进行采样。与传统的两阶段分配方法不同，Reinforce-Ada将估算和采样交替在一个在线顺序淘汰过程中进行，并在收集到足够信号后自动停止对提示的采样。为了稳定更新，该方法形成了具有强制奖励多样性的固定大小的组，并使用自适应采样阶段聚合的全局统计信息来计算优势基线。实验结果表明，Reinforce-Ada相较GRPO能够加速收敛并提高最终性能，特别是使用了平衡采样变体时更为显著。这项工作强调了在促进大型语言模型高效的、可靠的强化学习中，变异感知、自适应数据编目起着关键作用。
### Conclusion
我们的工作突显了在具备推理能力的LLMs中实现有效的强化学习中，如何在数据采集方面进行变异感知、自适应编目的中心作用。我们的代码可在该链接获取：this https URL。
## 530. `cs.CL` - 用户需求与行动分类法 [PDF](https://arxiv.org/pdf/2510.06124), [HTML](https://arxiv.org/abs/2510.06124)
### Authors
Renee Shelby,Fernando Diaz,Vinodkumar Prabhakaran
### Background
随着对话AI的普及，现有分类法无法全面涵盖用户的目的性目标和社会实践。目前的研究要么过于泛化，要么局限于特定领域，或者将交互简化为狭窄的功能性对话。这需要一个能够体现用户行为多样性的框架。
### Innovation
本文提出了用户需求与行动分类法（TUNA），这是一种通过迭代的定性分析和理论复核建立的实证框架。TUNA 将用户行为分为信息检索、综合、过程指导、内容创造、社会互动和元对话三个层次。这种方法强调用户自主性和适应性，有助于多尺度评估，促进产品间政策的和谐统一，并为特定领域提供一个分类的基础。
### Conclusion
TUNA 为描述AI使用提供了一套系统化的术语，不仅增进了学术理解，也为设计更安全、响应性和负责任的对话系统提供了支持。
## 531. `cs.CL` - 拆解混合线性注意力转换方法中的组件不平衡 [PDF](https://arxiv.org/pdf/2510.05901), [HTML](https://arxiv.org/abs/2510.05901)
### Authors
Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas
### Background
尽管 Transformer 在性能上表现优异，但由于其计算复杂度呈平方级别增长，限制了其可扩展性。线性注意力可将计算复杂度降低至线性级别，但预训练这些模型仍然在大多数情况下过于昂贵。近年来，一些后训练线性化方法可以高效地将预训练的 Transformer 转换为线性模型，通常采用结合线性注意力与滑动窗 softmax 的混合方法。然而，现有方法中存在一个关键缺陷，即混合方法实际上完全依赖于滑动窗 softmax，而忽略了线性注意力组件的作用。这种不平衡的现象源于对常用常识基准测试评价实践中的忽视。作者指出，现有的方法无法确保在线性注意力替换滑动窗 softmax 时各组件能够均衡使用，这影响了模型性能的客观评估。
### Innovation
作者提出了三种解决方案来确保混合方法各组件能够均衡使用：（i）在推理时将仅线性注意力转换与滑动窗 softmax 混合；（ii）结合注意力权重转移与目标 LoRA 微调的 HedgeCATs 方法；（iii）拟合滑动窗 dropout（SSD），在训练中随机抑制 softmax 分支以防止组件失衡。这些方法在保持计算效率的同时，能够恢复大部分基础模型性能，确保真实地应用线性注意力，从而恢复了混合转换性能归因的有效性。
### Conclusion
通过作者提出的解决方案，可以确保混合线性注意力转换方法各组件能够均衡使用，从而保持模型的计算效率和性能，同时恢复性能归因的有效性。这为混合线性注意力转换方法的进一步优化奠定了基础，也为后续研究提供了新的思路。
## 532. `cs.CV` - 脑肿瘤分割数据增强和损失函数的可重复评估 [PDF](https://arxiv.org/pdf/2510.08617), [HTML](https://arxiv.org/abs/2510.08617)
### Authors
Saumya B
### Background
脑肿瘤分割对于诊断和治疗计划至关重要，但数据不平衡和模型泛化不足等问题仍然制约着其进展。这项工作通过使用焦点损失和基础数据增强策略对U-Net分割性能进行了可重复评估，集中在参数调优和三种数据增强技术（水平翻转、旋转和缩放）对结果的影响上。
### Innovation
研究使用U-Net结合焦点损失，并通过公共MRI数据集进行实验，进行数据增强技术参数调整，并评估三种基本数据增强策略的效果。此外，所有代码和结果均公开，以建立一个透明、可重复的基准，指导未来关于增强策略和损失函数设计的研究。研究还达到了90%的精确度，与最先进的结果相当。
### Conclusion
本研究通过公开代码和结果，确立了一个透明、可重复的基准，推动了脑肿瘤分割中增强技术与损失函数设计的研究进展。
## 533. `cs.CV` - 在文本到图像扩散模型中调整初始噪声以减轻记忆现象 [PDF](https://arxiv.org/pdf/2510.08625), [HTML](https://arxiv.org/abs/2510.08625)
### Authors
Hyeonggeun Han,Sehwan Kim,Hyungjun Joo,Sangwoo Hong,Jungwoo Lee
### Background
尽管文本到图像的扩散模型具有出色的生成能力，但它们常常会记住并复制训练数据，这引发了严重的隐私和版权问题。研究表明，这种记忆现象与一种吸引盆地有关，即在该区域内，无分类引导（CFG）会将去噪轨迹引导向已记住的输出。之前的研究建议延迟应用CFG直到去噪轨迹脱离该盆地，但这样的延迟往往会导致与输入提示不匹配的、非记忆化的图像。
### Innovation
本文展示了初始噪声样本在决定何时逃离吸引盆地方面起到的关键作用。作者通过实验证明不同的初始样本会导致不同的逃离时间。基于此洞察，作者提出两种缓解策略，分别调整初始噪声的集体或个体部分，以寻找并利用鼓励较早逃逸初始样本的方法。这些方法显著减少了记忆现象，同时保持了图像和文本的一致性。
### Conclusion
通过调整初始噪声，本文显著降低了文本到图像扩散模型中的记忆现象，同时保持了文本与图像之间的对齐。
## 534. `cs.CV` - 动态专家混合体（Dynamic Mixture-of-Experts）应用于视觉自回归模型 [PDF](https://arxiv.org/pdf/2510.08629), [HTML](https://arxiv.org/abs/2510.08629)
### Authors
Jort Vincenti,Metod Jazbec,Guoxuan Xia
### Background
视觉自回归模型（VAR）能够高效且高质量地生成图像，但由于在不同分辨率下重复调用Transformer而导致计算冗余。
### Innovation
引入了一种动态的专家混合体路由器整合到VAR中。新的架构允许通过基于分辨率和令牌复杂性的比例感知阈值来进行计算与质量的权衡。这种阈值策略可以根据需要选择专家，而不需要额外的训练。结果显著减少了FLOPs（20%），加快了推理速度（11%），并达到了与密集基线相同的质量标准。
### Conclusion
通过这种动态的专家混合体策略，实现了计算效率和图像质量的平衡，证明了该方法的有效性。
## 535. `cs.CV` - 超越CNN：在低数据量环境下多模态LLMs的有效微调用于目标检测 [PDF](https://arxiv.org/pdf/2510.08589), [HTML](https://arxiv.org/abs/2510.08589)
### Authors
Nirmal Elamon,Rouzbeh Davoudi
### Background
物体检测和理解领域正迅速发展，得益于传统CNN模型和新兴的多模态大型语言模型（LLMs）的进步。虽然像ResNet和YOLO这样的CNN在图像任务中依然非常有效，但基于Transformer的LLMs引入了动态上下文推理、语言引导提示和全面场景理解的新能力。然而，这些模型在直接使用时，其潜力仍未得到充分挖掘，导致在专门的视觉任务上性能不佳。本研究通过细比较传统CNN、零-shot预训练多模态LLMs和多模态LLMs在人工文字叠加检测任务上的表现，展示了一个关键贡献：LLMs能在不到1000张图像的少量数据下进行有效微调，并实现36%的准确率提升，接近或超过通常需要大量数据的基于CNN的基线。
### Innovation
研究证明了多模态LLMs在低数据量环境下能通过有效微调达到显著的准确率提升，具体表现为在不到1000张图像的数据下能够达到与大量数据训练的基于CNN的基线相当或更优的效果，这展示了LLMs的适应能力和数据效率。通过研究语言引导模型如何在最小监督下实现精确的视觉理解，研究为跨模态学习策略提供了新的见解，旨在弥合视觉和语言之间的差距。
### Conclusion
研究结果强调了基于LLM的方法在真实世界的物体检测任务中的适应性和数据效率，并为在资源有限的视觉环境中应用多模态变换器提供了实际指导。为了促进该领域的进一步发展，研究团队已将用于模型微调的代码发布在GitHub上，以便未来的研究改进和应用复用。
## 536. `cs.CV` - 数字的镜子：AI生成图像中的性别偏见与职业刻板印象 [PDF](https://arxiv.org/pdf/2510.08628), [HTML](https://arxiv.org/abs/2510.08628)
### Authors
Siiri Leppälampi,Sonja M. Hyrynsalmi,Erno Vanhala
### Background
生成AI为创建图形、视频和图像提供了巨大机会。然而，最近关于AI生成视觉化的研究主要集中在创建过程和图像质量上，忽视了表现性偏差。这项研究通过在职业环境中测试AI生成图片中的表现性偏差，并评估两个AI图像生成工具DALL-E 3和Ideogram之间的差异，填补了这一空白。研究还讨论了AI生成图像中的年龄和情绪问题。随着AI图像工具的广泛应用，减轻并缓解有害的性别偏见变得至关重要，以确保媒体和专业环境中的多样性表现。研究过程中，对超过750张AI生成的职业图像进行了提示，主题分析结果显示，DALL-E 3和Ideogram在AI生成图像中均强化了传统的性别刻板印象，尽管程度不同。这些发现强调了AI可视化工具面临狭窄表现的风险。在讨论部分，研究提出了增加代表性、在生成有可见性性别的图像时降低偏见的建议。
### Innovation
本研究首次通过在职业环境中测试AI生成图片中的表现性偏差，填补了现有研究的空白。对比分析了DALL-E 3和Ideogram两种AI生成工具，发现两者均强化了传统的性别刻板印象。研究还初步探讨了AI生成图像中的年龄和情绪问题，提出减少性别偏见的建议，强调了在职业情境下应用AI生成工具时减少偏见的重要性。
### Conclusion
AI可视化工具存在强化狭窄表现的风险，潜在地加剧了对特定性别职业刻板印象的僵化。为了确保媒体和专业环境中的多样性表现，研究提出了几个建议，包括增加代表性、减少有害的性别偏见。
## 537. `cs.CV` - 使用分层高斯混合模型获得的表观不确定性在LiDAR语义分割中的离群值检测 [PDF](https://arxiv.org/pdf/2510.08631), [HTML](https://arxiv.org/abs/2510.08631)
### Authors
Hanieh Shojaei Miandashti,Claus Brenner
### Background
精确的LiDAR点云语义分割可以实现场景理解，但检测未在训练中遇到的离群值物体（OOD对象）也是至关重要的，以防止不明物体被错误地分配到已知类中。传统的监督离群值检测方法依赖于辅助离群值数据集，而非监督方法避免了这一需求，但通常依赖预测熵，即通过集成或多个后验权重样本平均获得的预测分布的熵。然而，这些方法往往混淆了表观不确定性（模型不确定性）和实际不确定性（数据不确定性），导致将内部不确定性的区域错误地识别为离群值。
### Innovation
提出了一种非监督的离群值检测方法，该方法利用来自深度神经网络特征空间中的高斯混合模型（GMM）参数的分层贝叶斯建模中的表观不确定性。该方法不依赖辅助数据或额外的训练阶段，与以往使用预测熵方法相比，展示出在SemanticKITTI数据集上具有优越的性能：AUROC提高18%，AUPRC增加22%，FPR95从76%降至40%。
### Conclusion
该研究提出的方法能够在无需额外辅助数据或训练的情况下，通过利用高斯混合模型参数的分层贝叶斯不确定性来对未在训练中遇到的物体进行有效的离群值检测，明显优于现有基于不确定性的方法。
## 538. `cs.CV` - Hi-OSCAR: 层次开放集分类器在人类活动识别中的应用 [PDF](https://arxiv.org/pdf/2510.08635), [HTML](https://arxiv.org/abs/2510.08635)
### Authors
Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring
### Background
在人类活动识别（HAR）中，生活中的活动范围远远超过了用于训练的标注传感器数据集能捕捉的活动范围。对未知活动处理不当严重削弱了任何HAR分类器的可靠性。此外，在HAR中，并非所有的类别都等同于不相似，有些类别显著重叠或包含其他亚活动。基于这些观察，我们将活动类别组织成一个结构化的层次体系。在此基础上，我们提出了Hi-OSCAR：一种层次开放集分类器，可以在保持最先进的识别已知活动准确性的同时，同时拒绝未知活动。这不仅实现了开放集分类，还允许未知类别定位到最近的内部节点，提供超过二元“已知/未知”分类的见解。此外，为了促进这一领域的进一步研究，我们收集了一个新的数据集：NFI_FARED。NFI_FARED包含多个受试者执行十九种活动的数据，这些活动涉及不同的情境，如日常生活、通勤和快速运动，数据完全公开可下载。
### Innovation
我们提出了Hi-OSCAR：一种层次开放集分类器，它可以在保持最先进的识别已知活动准确性的同时，同时拒绝未知活动。这不仅实现了开放集分类，还允许未知类别定位到最近的内部节点，提供超过二元“已知/未知”分类的见解。此外，还收集了新的数据集NFI_FARED，包含多种活动，增强了研究的有效性。
### Conclusion
我们提出的Hi-OSCAR不仅实现了开放集分类，还提供了更精细的未知类别的定位，增强了HAR的可靠性和实用性。同时，NFI_FARED数据集的提供也促进了未来的HAR研究。
## 539. `cs.CV` - 使用时频分析检测高频振荡 [PDF](https://arxiv.org/pdf/2510.08637), [HTML](https://arxiv.org/abs/2510.08637)
### Authors
Mostafa Mohammadpour,Mehdi Zekriyapanah Gashti,Yusif S. Gasimov
### Background
高频振荡（HFOs）是识别癫癎病致痫区的新生物标志物，通过界定产生HFOs的区域可以提高难治性癫癎患者手术切除部位的精准度。然而，检测HFOs仍具有挑战性，且其临床特征尚不完全明了。传统的视觉识别方法耗时、费力且主观，因此开发自动化的HFOs检测方法对于研究和临床使用都至关重要。
### Innovation
该研究开发了一种新颖的检测方法，适用于检出80-500 Hz频率范围内的HFOs。利用未监督聚类技术结合S变换从时频域提取事件进行分类，有效区分HFOs事件与其他电活动如尖波、背景活动和伪影。该方法在控制数据集和癫癎患者数据上的评估显示，取得了高灵敏度（97.67%）、高精确度（98.57%）和高F分数（97.78%），并且HFOs的检测与手术结果之间存在较强的相关性，切除区与非切除区HFOs率比值为0.73。
### Conclusion
HFOs是癫癎患者中癫痫源的有前景的生物标志物，尤其是去除快速振荡后可以实现无癫痫发作，而剩余的HFOs则导致癫痫复发。研究确认了HFOs作为癫痫源标志物的重要性，并展示了基于该方法的自动HFOs检测在临床应用中的潜力。
## 540. `cs.CV` - 穿越兔子洞：从DINO的任务相关概念到闵可夫斯基几何 [PDF](https://arxiv.org/pdf/2510.08638), [HTML](https://arxiv.org/abs/2510.08638)
### Authors
Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg
### Background
DINOv2已经在对象、场景和动作识别领域得到广泛应用，然而其感知的本质仍然未知。为了探讨其背后的机制，作者采用线性表示假设（LRH），并使用SAEs生成了一个包含32000个单元的字典，为后续的研究提供了一个可解释性基础。研究分三个部分展开，旨在揭示不同下游任务如何利用这个学习到的字典中的概念，以及这些概念的几何和统计特性。研究表明，表示部分稠密而不是严格稀疏，并且字典朝向更大的一致性发展，偏离了最大正交的理想状态，同时也提出了新的假设和观点，即描述了字典中概念的结构特征与景物空间理论和模型机制的关系。
### Innovation
该研究创新之处在于使用SAEs构建了一个32000个单元的字典，并提出了Minkowski Representation Hypothesis（MRH），这是一种新的假设，提出了用于解释Vision Transformer表示的理论基础，该理论基于Gardenfors的概念空间理论和多头注意力机制。MRH对于理解和解读Vision Transformer的表示具有重要的理论意义。
### Conclusion
基于上述分析，研究表明，字典中的概念部分稠密，但它的发展朝向更大的一致性和更低维度性，同时引入了Minkowski Representation Hypothesis（MRH），提出了模型中表示的基本结构，认为它们是由概念空间中的凸混合物组成的。这种结构在几何和统计层面提供了新的见解，有助于理解Vision Transformer的表示机制。
## 541. `cs.CV` - Hulu-Med: 通向全面医学跨模态理解的透明通用模型 [PDF](https://arxiv.org/pdf/2510.08668), [HTML](https://arxiv.org/abs/2510.08668)
### Authors
Songtao Jiang,Yuan Wang,Sibo Song,Tianxiang Hu,Chenyi Zhou,Bin Pu,Yan Zhang,Zhibo Yang,Yang Feng,Joey Tianyi Zhou,Jin Hao,Zijian Chen,Ruijia Wu,Tao Tang,Junhui Lv,Hongxia Xu,Hongwei Wang,Jun Xiao,Bin Feng,Fudong Zhu,Kenli Li,Weidi Xie,Jimeng Sun,Jian Wu,Zuozhu Liu
### Background
在临床决策中，整合来自多种数据模态（包括医疗文本、2D/3D 图像和视频）的信息面临挑战，导致效率低下和潜在的诊断疏漏。尽管通用视觉-语言模型（VLMs）表现出潜力，但在医学领域的发展仍面临不透明的工作流程、数据稀缺性和架构灵活性的挑战。
### Innovation
Hulu-Med 通过统一的基于补丁的视觉编码器和 LLM 解码器构建，实现了跨模态的理解统一。Hulu-Med 分阶段训练了 1670 万样本，从 2D 到 3D 和视频理解中扩展。该模型通过医疗意识标记减少机制实现了高效训练，仅需 4,000 到 40,000 GPU 小时即可完成不同参数量（7B 到 32B）的训练。Hulu-Med 在 30 个基准测试中表现出领先的性能，超越了开源领先模型并在多语种和罕见疾病场景中的复杂推理任务中与专有系统竞争。通过开源整个工作流，Hulu-Med 提供了一个高透明度的高性能医学 VLM，作为临床 AI 访问和影响的基础工具。
### Conclusion
Hulu-Med 建立了高透明度的高性能医学 VLM 可行性，通过开放源代码共同构建一个便于使用的临床人工智能基础工具，改善医疗决策过程中的信息整合与效率。
## 542. `cs.CV` - 结构化输出正则化：一种用于少样本转移学习的框架 [PDF](https://arxiv.org/pdf/2510.08728), [HTML](https://arxiv.org/abs/2510.08728)
### Authors
Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay
### Background
传统的转移学习通常通过冻结部分预训练网络的权重并添加任务特定层来重用大型预训练网络。尽管这种方法计算效率高，但它限制了模型适应领域特定特征的能力，并且在数据有限的情况下仍可能导致过拟合。
### Innovation
提出了一种名为结构化输出正则化（SOR）的简单而有效的框架，该框架冻结内部网络结构（如卷积滤波器）的同时，使用分组Lasso和L1惩罚的组合。该框架通过少量额外参数将模型定制化，并且可以很容易地应用于各种网络组件，如卷积滤波器或神经网络中的各种块，从而在转移学习任务中有广泛的适用性。
### Conclusion
SOR 在三个少样本医疗影像分类任务上进行评估，使用 DenseNet121 和 EfficientNetB4 作为基础模型，实现了与现有基准相当的结果。
## 543. `cs.CV` - PhyDAE：基于物理学的退化自适应专家用于端到端遥感图像恢复 [PDF](https://arxiv.org/pdf/2510.08653), [HTML](https://arxiv.org/abs/2510.08653)
### Authors
Zhe Dong,Yuzhe Sun,Haochen Jiang,Tianzhu Liu,Yanfeng Gu
### Background
遥感图像在获取过程中不可避免地会受到各种退化因素的影响，包括大气干扰、传感器限制以及成像条件等。复杂的异质退化对图像质量及后续的解释任务构成了严峻挑战。现有的单一解决方案过于依赖隐式的特征表示，缺乏对退化物理特性的明确建模。
### Innovation
本文提出了基于物理学的退化自适应专家（PhyDAE），采用两阶段串行结构将隐式的退化信息转化为显式的决策信号，实现了准确的异质退化识别和处理。引入了残差流形投影（RMP）和频率感知退化分解（FADD），从流形几何和频率角度全面分析退化特征。使用了物理感知专家模块及温度控制稀疏激活策略，保证了计算效率的同时保持成像物理学的一致性。
### Conclusion
对三个基准数据集（MD-RSID、MD-RRSHID 和 MDRS-Landsat）进行了广泛实验，结果显示 PhyDAE 在所有四个恢复任务上均表现出优越的性能，显著优于最新的方法。PhyDAE 还实现了显著减少的参数数量和计算复杂性，与主流方法相比具有显著的效率提升，在性能与效率之间实现了最优平衡。
## 544. `cs.CV` - BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities [PDF](https://arxiv.org/pdf/2510.08759), [HTML](https://arxiv.org/abs/2510.08759)
### Authors
Yu Qi,Haibo Zhao,Ziyu Guo,Siyuan Ma,Ziyan Chen,Yaokun Han,Renrui Zhang,Zitiantao Lin,Shiji Xin,Yijian Huang,Kai Cheng,Peiheng Wang,Jiazheng Liu,Jiayi Zhang,Yizhe Zhu,Wenqing Wang,Yiran Qin,Xupeng Zhu,Haojie Huang,Lawson L.S. Wong
### Background
现有的多模态大型语言模型（MLLMs）在演示特定领域能力（如规划或空间理解）方面表现良好，但对它们的综合感知、理解和操作实际世界能力的评估尚缺乏全面和系统的方法。现有的基准测试主要集中在这些特定领域，导致了对于MLLMs整体的、基础的交互能力评估不足。
### Innovation
本文提出了BEAR，这是一个综合而细致的基准测试，旨在评估MLLMs在原子级别的基础交互能力。BEAR包括在六个类别中的14个领域中4469个交错的图像-视频-文本条目，涵盖了从低级别的指针任务、路径理解，到高级的规划任务。此外，文中还提出了一款名为BEAR-Agent的多模态可对话代理，整合预训练的视觉模型，增强了MLLM的知觉、3D理解和规划能力，显著提升了MLLM在BEAR上的各种基础交互能力的表现。
### Conclusion
实验结果表明，提升MLLM的交互能力能够改善其在模拟环境中的基础交互任务表现。该多模态可对话代理BEAR-Agent在增强MLLM的交互能力方面表现突出，特别是在GPT-5上实现了9.12%的绝对收益和17.5%的相对改进。这些发现突显了在具体任务中改进MLLM交互能力的重要性，并证明了 EnhanceAI现有的基准测试的价值，可以作为 Molotov 和 GPT5 等模型评估的重要工具。
## 545. `cs.CV` - 使用预训练深度学习模型和机器人平台的热成像溢油检测 [PDF](https://arxiv.org/pdf/2510.08770), [HTML](https://arxiv.org/abs/2510.08770)
### Authors
Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung
### Background
随着工业和运输的快速发展，油品泄露等环境污染问题日益严峻。传统的检测方法往往受限于环境条件，且效率较低。因此，本文提出了一种利用预训练深度学习模型结合RGB和热成像技术实时检测油品泄露的系统。
### Innovation
本文系统利用预训练模型大幅提升了检测的准确性和速度，并通过热成像技术在不同光照条件下表现出更好的鲁棒性。尽管模型大小较小，但在标准消费级硬件上能够实现低至44毫秒的超快推理时间，使该系统能在安全关键领域有效部署。
### Conclusion
实验结果显示，使用预训练的VGG19模型进行热成像训练在实际应用中效果最佳，表明该系统能够在各类环境中有效检测油品泄露，进而提高环境保护和安全管理能力。
## 546. `cs.CV` - 使用相机思考：一种用于相机中心理解和生成的统一多模态模型 [PDF](https://arxiv.org/pdf/2510.08673), [HTML](https://arxiv.org/abs/2510.08673)
### Authors
Kang Liao,Size Wu,Zhonghua Wu,Linyi Jin,Chao Wang,Yikai Wang,Fei Wang,Wei Li,Chen Change Loy
### Background
相机中心的理解和生成是空间智能的两个重要支柱，但通常它们会孤立研究，缺乏统一的关系。Puffin提出了一种统一的相机中心多模态模型，旨在扩展空间意识，并通过集成功能，将语言回归和基于扩散的生成结合起来，从任意视角解释和创造场景。为了弥合相机和视觉语言之间的模态差距，Puffin引入了一种新的范式，将相机视为语言，以此引导模型对空间化视觉线索与摄影术语进行对齐，同时进行几何上下文推理。Puffin模型通过一个包含400万视觉语言相机三元组的大规模数据集Puffin-4M进行训练，提供了灵活可靠的空问生成能力。实验表明，Puffin在相机中心理解和生成任务上的表现优于专门化的模型，通过指令调优，Puffin还能够泛化到涉及空间想象、世界探索和摄影指导等多个跨视角任务上。未来将发布代码、模型、数据集管道和基准测试，以促进多模态空间智能研究的发展。
### Innovation
Puffin是一个统一的相机中心多模态模型，它不仅可以解释任意视角的场景，还能生成新的场景。它通过将相机输入视为语言，并借鉴摄影术语，实现了基于几何上下文的空间化视觉线索对齐。Puffin使用了一个大规模的数据集Puffin-4M进行训练，包括全球相机参数和像素级别的相机地图，使其能够生成灵活且可靠的空间内容。通过指令调优，Puffin可以泛化到多个跨视角任务，如空间想象、世界探索和摄影指导等。这些创新点丰富了多模态空间智能的研究成果。
### Conclusion
Puffin是目前最先进的相机中心多模态模型，能够通过相机输入理解和生成任意视角的场景，通过与摄影术语的对齐和几何上下文推理，展示了优异的空间生成能力。通过指令调优，Puffin还能应用于多种跨视角任务。Puffin的代码、模型、数据集管道和基准测试将开放，以促进相关领域的研究。
## 547. `cs.CV` - SAFER-AiD：基于眨眼辅助中心-周边视觉增强重建的对抗防御 [PDF](https://arxiv.org/pdf/2510.08761), [HTML](https://arxiv.org/abs/2510.08761)
### Authors
Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu
### Background
对抗攻击严重挑战了深度学习模型在实际应用中的安全部署。传统的防御方法通常依赖于计算密集型优化（如对抗训练或数据增强）来提高鲁棒性，而人类视觉系统通过进化出的生物机制具备对对抗扰动的固有鲁棒性。我们假设注意力引导下的非均匀稀疏采样和预测编码在这一鲁棒性中扮演关键角色。基于此假设，我们提出了一种融合了三种主要生物机制（中心-周边处理、凝视眼动和皮层填充）的新防御框架。该方法利用强化学习指导的眨眼来选择性地捕捉多个中心-周边视觉得到的图像片段，并在分类之前将其融合到重构的图像中，从而有效地减轻对抗噪声，保持语义完整性和减少对下游分类器的重训练或微调需求，能够无缝集成到现有系统。实验表明，该方法提高了不同分类器和攻击类型的系统鲁棒性，同时显著减少了相对于生物和非生物灵感防御技术的训练开销
### Innovation
我们提出了一种名为SAFER-AiD的新防御框架，它融合了中心-周边处理、凝视眼动和皮层填充三种生物机制。该方法利用强化学习指导的眨眼选择性捕捉多个中心-周边片段，并将这些片段融合到重构图像中，用于分类前处理。这种方法能够有效减轻对抗噪声，保持语义完整性和减少对下游分类器的重训练或微调需求，从而无缝集成到现有系统中。
### Conclusion
我们的方法在不同分类器和攻击类型上提高了系统鲁棒性，显著减少了相对于生物和非生物灵感防御技术的训练开销。通过引入基于生物机制的预处理步骤，我们提供了一种新的防御框架，可以在保持现有模型性能的前提下有效抵抗对抗攻击。
## 548. `cs.CV` - LinearSR: 解锁线性注意力以实现稳定且高效的图像超分辨率 [PDF](https://arxiv.org/pdf/2510.08771), [HTML](https://arxiv.org/abs/2510.08771)
### Authors
Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu
### Background
生成模型在图像超分辨率（SR）方面变得越来越强大，然而，其依赖的多头自注意力的平方复杂性（O(N^2)）带来了主要的计算瓶颈。虽然线性注意力提供了线性阶（O(N)）的解决方案，但其在生成逼真图像时的效果因为一系列历史上的前期未解难题而迟迟未能实现。
### Innovation
本文介绍了线性SR（LinearSR），这是首款全面解决这些关键障碍的框架。我们首次提出了一种创新的基于“膝盖点”的早期停止引导微调（ESGF）策略，来解决训练不稳定性导致的灾难性模型发散问题。同时，我们利用专门的设计信噪比（SNR）为基础的专家混合（MoE）架构来缓解感知与失真的传统权衡。此外，我们建立了一个轻量且有效的方法，取名TAG，源自“精度胜过体积”的原则。最终，我们的线性SR模型在保持尖端感知质量的同时，实现了卓越的效率。核心扩散前向传递（1-NFE）达到最先进的速度，整体多步推理时间在竞争范围内。
### Conclusion
这项工作提供了首个在逼真图像超分辨率领域应用线性注意力的稳健方法，确立了高效生成超分辨率领域未来研究的基础框架。
## 549. `cs.CV` - 使用AI自动化视频关键帧提取识别kea [PDF](https://arxiv.org/pdf/2510.08775), [HTML](https://arxiv.org/abs/2510.08775)
### Authors
Paula Maddigan,Andrew Lensen,Rachael C. Shaw
### Background
动物个体的准确识别与重新识别是野生动物种群监测成功的关键。传统的标记方法，例如鸟类的腿环标记，耗时且侵入性。近年来，人工智能的进步，尤其是计算机视觉，为智能保护和高效自动化提供了有希望的解决方案。研究表明，通过在新西兰特有的森林栖息鹦鹉kea（Nestor meridionalis）的自建喂食器上提取视频的关键帧，利用AI技术实现非侵入性高效识别kea个体，为保护生物学和生态学中的种群监测提供了新的方法。然而，关键帧提取在野生动物识别方面的应用有限。
### Innovation
该研究提出了一个独特的管道，用于从kea的视频中提取高质量的关键帧，创新点在于利用了对象检测（YOLO和Grounding DINO）、光流模糊检测、DINOv2图像编码和聚类方法来选择代表性的关键帧。该方法在非侵入性和高效性方面作为一个替代传统物理标记方法的有价值选择，为未来在更多样化和更具挑战性的环境中使用媒体进行研究奠定了基础。
### Conclusion
研究结果表明，提出的关键帧选择方法能生成准确的kea重识别图像集合，为未来利用收集的媒体的野生动物监测研究提供了基础。人工智能和计算机视觉的应用为kea个体的识别提供了新的非侵入性和高效的方法，有助于提高种群监测的效果。这项研究为野生动物监测的发展和研究应用生物学和保护生物学做出了贡献。
## 550. `cs.CV` - Q-Router: 以专家模型路由和时空特征定位实现自主视频质量评估 [PDF](https://arxiv.org/pdf/2510.08789), [HTML](https://arxiv.org/abs/2510.08789)
### Authors
Shuo Xing,Soumik Dey,Mingyang Wu,Ashirbad Mishra,Hansi Wu,Binbin Li,Zhengzhong Tu
### Background
视频质量评估（VQA）是一项基础的计算机视觉任务，旨在预测给定视频的感知质量与人类判断一致。现有通过直接分数监督训练的VQA模型存在以下问题：（1）在多样内容和任务上表现不佳，包括用户生成的内容（UGC）、短视频和人工智能生成的内容（AIGC）；（2）解译性有限；（3）无法扩展到新的应用场景或内容类型。现有模型在跨领域通用性、可解释性和扩展性方面存在局限性。
### Innovation
本文提出了一种名为Q-Router的自主视频质量评估框架，该框架具备多层级模型路由系统，通过多样的专家模型组合和实时路由机制，根据视频语义动态选择最适合的专家模型进行组合。Q-Router的设计优化了专家模型的互补优势，提供了在不同视频来源和任务中表现的一致性和鲁棒性。实验表明，Q-Router在多种基准测试上与最先进的VQA模型表现相当甚至更优，显著提高了通用性和解译性，并在质量基于的问题回答基准测试Q-Bench-Video上表现出色，证明了其作为下一代VQA系统基础的应用潜力。此外，Q-Router 还能有效定位时空特征，具备用于视频生成模型后训练的奖励函数潜力。
### Conclusion
Q-Router通过集成各种专家模型和实时路由机制，为视频质量评估提供了一种灵活且鲁棒的方式。它在多个基准测试上的良好表现表明，Q-Router不仅解决了现有VQA模型在通用性和解释性方面的问题，还展示了其作为未来VQA系统基础的巨大潜力。此外，Q-Router在识别时空特征方面的能力为视频生成模型的优化提供了新的可能性。
## 551. `cs.CV` - SkipSR：通过Token跳过实现更快的超分辨率 [PDF](https://arxiv.org/pdf/2510.08799), [HTML](https://arxiv.org/abs/2510.08799)
### Authors
Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni
### Background
基于扩散的超分辨率（SR）是视频生成和视频修复中的关键技术组件，但效率较低且成本较高，限制了对更高分辨率和更长视频的广泛应用。现有的方法通常会均匀处理所有像素，即使很多区域天然具有较低的细节，提升这些区域并不能显著提高质量。
### Innovation
我们提出了一种名为SkipSR的简单框架，通过直接从低分辨率输入中识别低细节区域，并完全跳过这些区域的计算，仅对需要精修的区域进行超分辨率处理。这种方法在保持感知质量的同时显著减少了计算量，特别是在标准和单步扩散SR模型中表现出色。研究表明，在标准SR基准测试中，我们的方法在720p视频上实现了高达60%的端到端延迟降低，且无明显质量损失。
### Conclusion
SkipSR框架通过跳过低细节区域的计算，有效提升了视频超分辨率的速度，同时保持了良好的视觉质量，在标准和单步扩散SR模型中达到了显著的性能提升。
## 552. `cs.CV` - Medical视觉问答中的对齐、挖掘和融合：带有困难负例挖掘的选择性知识融合 [PDF](https://arxiv.org/pdf/2510.08791), [HTML](https://arxiv.org/abs/2510.08791)
### Authors
Yuanhao Zou,Zhaozheng Yin
### Background
医学视觉问答（Med-VQA）是一个复杂的任务，要求深入了解医学图像和文本问题。尽管利用医学视觉语言预训练（Med-VLP）的工作已在Med-VQA任务上显示出强大的性能，但模态对齐的统一解决方案仍未建立，困难负例的问题仍被忽视。常用的知识融合技术可能会引入无关信息。
### Innovation
本文提出了一个框架，通过三大创新点解决上述挑战：(1) 借助对比学习和最优化传输理论等方法，提供在多个层面、模态、视角和阶段上的统一模态对齐解决方案；(2) 采用软标签的困难负例挖掘方法，强化困难负例对的区分；(3) 引入门控跨注意力模块，将答案词汇作为先验知识，选择相关的信息。该框架在RAD-VQA, SLAKE, PathVQA和VQA-2019等广泛使用的Med-VQA数据集上表现优于之前的技术前沿。
### Conclusion
本文提出的方法在多个Med-VQA数据集上实现了最先进的性能，解决了模态对齐和困难负例挖掘等难题，展示了门控跨注意力模块的有效性。
## 553. `cs.CV` - D-CoDe: 通过动态压缩和问题分解扩展图像预训练VLM到视频 [PDF](https://arxiv.org/pdf/2510.08818), [HTML](https://arxiv.org/abs/2510.08818)
### Authors
Yiyang Huang,Yizhou Wang,Yun Fu
### Background
视频大型语言模型（Vid-LLMs）在多种视频语言任务中表现优异，可以通过调整图像预训练的视觉语言模型（VLMs）来有效构建。然而，这种调整存在挑战，因为需要处理密集且时间延长的视觉输入，这些输入超出了图像基础模型的容量。本文指出，在将基于图像的VLMs扩展到视频领域时，感知瓶颈和标记过载是主要挑战。
### Innovation
本文提出了一种名为D-CoDe的无需训练的调整框架，该框架结合了动态压缩和问题分解。动态压缩通过自适应选择代表性帧和基于内容的聚集空间标记，减少了冗余并保留了有价值的内容，从而缓解了感知瓶颈。问题分解通过重新制定原始查询为子问题，引导模型关注视频的不同方面，从而实现更全面的理解，从而缓解了标记过载。
### Conclusion
实验表明，D-CoDe有效地提高了视频理解能力，尤其在具有挑战性的长视频基准测试中表现良好，突显了D-CoDe在处理复杂视频语言任务的潜力。相关代码可以在该链接获取。
## 554. `cs.CV` - FOLK: 快速基于标签引导知识蒸馏的开放词汇3D实例分割 [PDF](https://arxiv.org/pdf/2510.08849), [HTML](https://arxiv.org/abs/2510.08849)
### Authors
Hongrui Wu,Zhicheng Gao,Jin Cao,Kelu Yao,Wen Shen,Zhihua Wei
### Background
现有的3D实例分割方法通常将3D实例映射到2D RGB-D图像上，然后利用视觉语言模型进行分类。然而，这种映射策略通常会带来由2D遮挡引入的噪声，并且在推理过程中消耗大量的计算和内存资源，从而减慢推理速度。
### Innovation
本文提出了一种基于标签引导知识蒸馏的快速开放词汇3D实例分割方法（FOLK），设计了一个老师模型来提取高质量的实例嵌入，并将开放词汇的知识蒸馏到3D学生模型中。在推断时，蒸馏后的3D模型可以直接对3D点云中的实例进行分类，避免了遮挡引起的噪声并显著加快了推断过程。此外，设计了一个老师模型来为每个3D实例生成一个包含可见性和视点多样性的2D CLIP嵌入，并在此基础上提出了一种标签引导的知识蒸馏算法来将一致标签的2D嵌入中的开放词汇知识蒸馏到学生模型中。
### Conclusion
FOLK在ScanNet200和Replica数据集上进行了实验，达到了ScanNet200数据集上的AP50得分为35.7，并且比之前的方法快大约6.0到152.2倍。所有代码将在论文接受后公开。
## 555. `cs.CV` - SegTrans: 可转移的分割模型对抗样本 [PDF](https://arxiv.org/pdf/2510.08922), [HTML](https://arxiv.org/abs/2510.08922)
### Authors
Yufei Song,Ziqi Zhou,Qi Lu,Hangtao Zhang,Yifan Hu,Lulu Xue,Shengshan Hu,Minghui Li,Leo Yu Zhang
### Background
现有分割模型在白盒设置下对对抗样本表现出显著的脆弱性，但现有的对抗攻击方法在不同分割模型之间表现出较差的可转移性。尽管部分研究者探索了基于转移的对抗攻击方法，但由于模型中的复杂上下文依赖关系以及代理模型和目标模型之间的特征分布差异，导致了较低的可转移成功率。
### Innovation
提出了一种名为SegTrans的新型转移攻击框架，该框架将输入样本划分为多个局部区域，并重新映射这些区域的语义信息以生成多样化的增强样本。这些增强样本用于替换原始样本进行扰动优化，从而提高不同分割模型之间的对抗样本可转移性。与现有方法不同，SegTrans仅保留原始输入的局部语义信息，而非使用全局语义信息进行扰动优化。实验结果表明，SegTrans在PASCAL VOC和Cityscapes两个基准数据集上，对四种不同的分割模型和三种骨干网络，显著提高了对抗转移成功率，且未增加额外的计算成本，相比当前最先进的方法，平均提高了8.55%的对抗转移成功率，并提高了超过100%的计算效率。
### Conclusion
SegTrans在不增加额外计算成本的情况下，显著提高了不同分割模型之间的对抗转移成功率，并相比现有最先进的方法，极大地提升了计算效率。
## 556. `cs.CV` - 利用时间进程轨迹表征蔓越莓生长 [PDF](https://arxiv.org/pdf/2510.08901), [HTML](https://arxiv.org/abs/2510.08901)
### Authors
Ronan John,Anis Chihoub,Ryan Meegan,Gina Sidelli,Jeffery Neyhart,Peter Oudemans,Kristin Dana
### Background
蔓越莓种植中的一项重要任务是变化监测，可以通过此任务向育种者和种植者提供作物生长分析、产量预测以及治疗决策的能力。然而，这一任务通常需要人工完成，占用种植者或育种者大量的时间。基于深度学习的变化监测方法有潜力解决这个问题，但仍存在难以解释的高维度特征和需要手工标注的问题。为了填补这一空白，我们提出了一种基于自监督方法细调视觉变换器（ViTs）的方法来建模作物生长，这种方法避免了繁琐的图像注释。我们采用时间回归和类别预测双重预训练任务来学习植物和果实外观的时间进程演化潜在空间。生成的二维时间轨迹提供了具有解释性的作物生长时间序列模型，可用于预测作物生长过程中的生长趋势及区分不同蔓越莓品种之间的时间差异。同时，我们提供了一个蔓越莓果实各品种变化时间进程的新闻数据集，不同品种观察了52次，在整个生长期跨度四个月的时间内，数据集还包括关于杀菌剂应用、产量和腐烂的信息。我们的方法具有通用性，可以应用于其他作物和应用场景（代码和数据集可于https://github.com/ronan-39/tlt/处获取）
### Innovation
我们提出了一种基于自监督方法细调视觉变换器的方法来建模作物生长，这种方法避免了繁琐的图像注释；通过双重预训练任务学习植物和果实外观的时间进程演化潜在空间，生成具有解释性的作物生长时间序列模型；提供了一个蔓越莓果实各品种变化时间进程的新闻数据集，含有大量关于作物生长周期内杀虫剂使用、产量和腐烂的数据。此外，该方法具有通用性，可以应用于其他作物和应用场景
### Conclusion
我们提出的方法可以通过准确地测量蔓越莓的生长趋势以及区分不同品种的时间差异，缓解人工监测任务的困难。此外，我们提供的数据集和代码将对其他作物的研究和应用具有启发作用。
## 557. `cs.CV` - 通过特征空间 perturbation 防御图像恢复中的未经授权知识蒸馏 [PDF](https://arxiv.org/pdf/2510.08925), [HTML](https://arxiv.org/abs/2510.08925)
### Authors
Han Hu,Zhuoran Zheng,Chen Lyu
### Background
知识蒸馏（KD）攻击通过让对手利用教师模型的输出来训练学生网络，对深度模型的知识产权构成了重大威胁。现有的防御措施在图像分类中能够扰乱KD，但将这些方法扩展到图像恢复中具有挑战性。区别在于，恢复任务是生成性的，具有连续、高维的输出，并且取决于空间连贯性和精细细节，小幅度的扰动往往不足以有效防御KD。
### Innovation
针对图像恢复任务的特点，研究人员提出了一种名为Adaptive Singular Value Perturbation（ASVP）的运行时防御方法，用于对抗未经授权的知识蒸馏。ASVP基于教师网络的内部特征图上的奇异值分解（SVD）进行操作，在保持教师网络性能的同时，通过放大前k个奇异值来注入结构化的高频扰动，破坏蒸馏所需的对齐，从而妨碍学生网络的学习。
### Conclusion
通过在五种图像恢复任务（超分辨率、低光增强、水下增强、除雾、除雨）上的实验，研究人员证明ASVP能够显著降低学生网络的PSNR最多4dB和SSIM达60-75%，而对教师网络的性能几乎没有影响。与先前的方法相比，ASVP提供了一种更强和更一致的防御手段。该研究为防止未经授权的知识蒸馏，提供了一种在实际部署中可行的解决方案。
## 558. `cs.CV` - RO-Bench: 使用文本驱动的反事实视频评估MLLMs的大规模鲁棒性 [PDF](https://arxiv.org/pdf/2510.08936), [HTML](https://arxiv.org/abs/2510.08936)
### Authors
Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang
### Background
近期，多模态大型语言模型（MLLMs）在各种视频理解任务中展现了显著的性能。然而，这些模型在面对篡改视频内容时的鲁棒性仍然未被充分探索。针对这一问题，本文提出了Ro-Bench，这是首个专门用于评估MLLMs在动态非分布（OOD）反事实视频测试集上的基准。Ro-Bench使用高质量、多样且具有时间相关性的视频数据，通过编辑风格、对象、背景及其组合来构建测试数据。
### Innovation
本文提出的Ro-Bench基准首次针对动态非分布反事实视频测试集对MLLMs进行评估。通过细调反事实数据，MLLMs的鲁棒性得到了显著提升，Ro-Bench上的性能提升了21.73%，在MVBench数据集的20项任务中，性能总体提高了12.78%。这些发现表明反事实数据在增强MLLMs的视频理解能力方面非常有效。
### Conclusion
本文研究显示，现有的MLLMs在面对反事实视频内容时表现较差，但通过细调反事实数据，MLLMs的鲁棒性得到了显著提升。最终，作者将发布代码和数据，以促进更多研究。
## 559. `cs.CV` - PHyCLIP：Hyperbolic因素的$boldsymbol{boldsymbol{beta_1}}$-乘积统一了视觉语言表示学习中的层次结构和组合性 [PDF](https://arxiv.org/pdf/2510.08919), [HTML](https://arxiv.org/abs/2510.08919)
### Authors
Daiki Yoshikawa,Takashi Matsubara
### Background
视觉语言模型在大规模视觉场景和语言描述对的多模态表示学习方面取得了显著成果。然而，这些模型在同时表达概念家族内的层次结构（如狗$trianglerighteq$哺乳动物$trianglerighteq$动物）和不同概念家族间的组合性（如“车里的狗”$trianglerighteq$狗或车）方面仍存在挑战。尽管近期工作通过使用双曲空间解决了层次结构的表达问题，但其对组合性的表示能力仍不清楚。这项研究旨在解决该难题并提出了PHyCLIP模型，该模型利用双曲空间中的$boldsymbol{beta_1}$-乘积度量，实现了概念家族内层次结构的自然形成及不同概念家族间的组合特性捕获。
### Innovation
PHyCLIP引入了一种独特的$boldsymbol{beta_1}$-乘积度量方法，用于处理视觉语言表示学习中的层次结构和组合性问题。通过在其双曲因素的笛卡尔积上应用$boldsymbol{beta_1}$-乘积度量，PHyCLIP不仅在各概念家族内部产生了自然的层次结构，还通过$boldsymbol{beta_1}$-乘积度量捕获了不同概念家族间的组合特性，使得表示学习后得到的嵌入空间更加具有可解释性。实验结果表明，PHyCLIP在零样本分类、检索、层次分类和组合理解等任务上均优于现有的单一空间方法，并提供了更高可解释性的结构。
### Conclusion
通过引入$boldsymbol{beta_1}$-乘积度量到双曲空间，PHyCLIP成功统一了视觉语言表示学习中的层次结构和组合性问题，实现了更为有效的多模态信息表达，并在多个任务上验证了其优越性，为未来相关研究提供了新的视角和方法。
## 560. `cs.CV` - 去噪扩散以实现专注于对象的图像增广 [PDF](https://arxiv.org/pdf/2510.08955), [HTML](https://arxiv.org/abs/2510.08955)
### Authors
Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar
### Background
现代农业操作越来越依赖于结合多种数据源的集成监控系统，以优化农场运营。无人机在监测牲畜健康方面起到了关键作用，但由于现场特定问题（如动物小、遮挡或部分可见）和数据集不足，导致数据有限。目前的迁移学习方法由于缺乏反映农场具体情况的大数据集而难以解决这些问题（包括动物品种、环境和行为的变化）。因此，需要一种特定于问题、专注于动物的数据增强策略来应对这些挑战。本文针对基于数据稀缺情况下的动物健康监测问题，提出了一种专注于对象的数据增强框架，通过分割动物背景、进行变换和扩散合成生成逼真多样的场景，从而提升动物检测和监控性能。
### Innovation
本文提出了一种针对动物健康监测的专注于对象的数据增强框架。该方法能有效地从背景中分割出动物，并通过变换和基于扩散的合成生成逼真多样化的场景，填补了基于数据缺失背景下动物健康监测的空白。实验结果表明，通过生成特定领域数据，所提出的方法能够增强实时动物健康监测解决方案的实用性，甚至在数据稀缺的情况下也能发挥作用，有效地弥合了数据有限与实际应用之间的差距。
### Conclusion
本文提出了一种基于去噪扩散的数据增强方法，用于改善在数据稀缺情况下的动物健康监测。通过生成特定领域数据，增强了动物检测和监控性能，即便在数据匮乏的情况下也能提供可靠的实时监测解决方案。
## 561. `cs.CV` - mmJoints: 扩展基于毫米波的3D姿态估计中的关节表示 [PDF](https://arxiv.org/pdf/2510.08970), [HTML](https://arxiv.org/abs/2510.08970)
### Authors
Zhenyu Wang,Mahathir Monjur,Shahriar Nirjon
### Background
在基于毫米波的姿态估计中，稀疏信号和弱反射常使得模型依赖统计先验而非传感器数据来推断身体关节位置，虽然先验知识有助于学习有意义的表示，但对它的过度依赖会降低手势和活动识别等下游任务的性能。
### Innovation
提出了mmJoints框架，该框架通过补充预训练的黑盒毫米波基3D姿态估计器的输出，加入额外的关节描述符，使得关节被感知的可能性以及预测位置的可靠性变得显式。这些描述符增强了解释性并提升了下游任务的准确性。通过超过115,000个信号帧在13种姿态估计设置下的广泛评估，显示mmJoints的描述符估计错误率低于4.2%，同时关节位置的准确性最多可提高12.5%，活动识别性能最多可提升16%，超越最新的方法
### Conclusion
通过mmJoints框架，增强了基于毫米波的3D姿态估计关节表示，不仅提升了解释性，还显著提升了下游任务的准确性，特别是在联合位置和活动识别方面。
## 562. `cs.CV` - Hierarchical Scheduling for Multi-Vector Image Retrieval [PDF](https://arxiv.org/pdf/2510.08976), [HTML](https://arxiv.org/abs/2510.08976)
### Authors
Maoliang Li,Ke Li,Yaoyang Liu,Jiayu Chen,Zihao Zheng,Yinjun Wu,Xiang Chen
### Background
在多模态大语言模型（MLLM）应用中，为了有效利用用户特定数据，研究人员采用了检索增强生成（RAG）方法。然而，传统的检索方法常常因为检索精度受限而面临挑战。为了提高检索精度，近年来的研究中引入了多向量检索（MVR），通过将查询分解并与分段图像进行匹配来增强准确性。尽管MVR取得了进展，但仍然存在精度不足和效率问题，忽略了查询与图像对象之间的对齐以及冗余的细粒度图像片段匹配。
### Innovation
本文提出了一种高效的时间调度框架——HiMIR。首先，引入了一种新的分层范式，通过为不同的图像对象设置多种中间粒度，以增强对齐性。其次，通过利用跨层相似性一致性来最小化检索中的冗余，并通过层次稀疏性进一步减少不必要的匹配计算。此外，还为每个数据集自动配置参数以适应不同的应用场景。实验证明，HiMIR不仅实现了显著的准确性提升，还能将现有MVR系统的计算量减少至多3.5倍。
### Conclusion
HiMIR不仅在准确性上取得了显著提升，同时还能大幅度减少计算量，证明了其在多向量图像检索中的有效性。
## 563. `cs.CV` - HandEval：迈向生成图像中手部质量评估的第一步 [PDF](https://arxiv.org/pdf/2510.08978), [HTML](https://arxiv.org/abs/2510.08978)
### Authors
Zichuan Wang,Bo Peng,Songlin Yang,Zhenchen Tang,Jing Dong
### Background
尽管最近的文本转图像（T2I）模型在生成图像的整体视觉质量方面取得了显著进步，但在复杂局部区域，尤其是人体手部的生成精度方面仍然存在困难。生成的手部经常出现结构失真和不现实的纹理，即便身体其他部分生成较好，这些缺陷也非常明显。然而，对手部区域的质量评估仍然被忽视，限制了以人体为中心的生成质量优化和AIGC检测等下游任务的表现。因此，亟需针对生成手部区域的质量评估任务，并展示其丰富的下游应用价值。
### Innovation
本文提出了第一个针对生成手部区域的质量评估任务，并开发了专门的手部质量评估模型HandEval。HandEval利用多模态大型语言模型的视觉理解能力，并结合手部关键点先验知识，提高了对手部质量的感知能力。通过构建由先进T2I模型生成的手部图像的人工注释测试集来验证其质量评估能力。实验结果表明，HandEval在评估手部生成质量方面优于现有顶尖方法。此外，HandEval被集成到图像生成和AIGC检测管道中，显著提高了生成手部的逼真度和检测准确性，证明了其在下游应用中的普遍有效性。
### Conclusion
研究结果表明，HandEval更好地与人力判断相匹配，且在手部生成质量评估方面优于现有方法。通过将HandEval集成到图像生成和AIGC检测中，显著提升了生成手部的逼真度和检测的准确性，证实了其在下游应用中的普遍有效性。数据集和代码将对外开放。
## 564. `cs.CV` - Unleashing Perception-Time Scaling to Multimodal Reasoning Models [PDF](https://arxiv.org/pdf/2510.08964), [HTML](https://arxiv.org/abs/2510.08964)
### Authors
Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu
### Background
近期，特别是在利用强化学习和可验证奖励的推理时扩展方面取得的进展，极大地提升了大规模视觉-语言模型（LVLMs）的推理能力。尽管这种方法在多模态推理中得到了广泛应用，但其对视觉感知的影响仍然不清楚。鉴于此，本文介绍了一个名为DisTANCE的感知中心基准测试，用于视觉估算任务。实验结果显示，LVLMs在估算精度方面表现有限，而推理时的扩展只能带来微小的提升。这归因于当前LVLMs的快速感知范式，即认为视觉理解是一次性的输出，而不是建模底层的感知过程。因此，本文提出了感知时间扩展（PTS），这是一种新颖的范式，强调感知中的丰富标记，并将复杂感知问题分解为中间可解决的子问题，从而实现感知与推理时扩展的对齐和受益。结合强化学习技术，PTS显著提高了感知准确性，将DisTANCE上的高精度性能从8.0%提高到64.7%，并适用于不同的任务。有趣的是，尽管PTS数据完全是合成的，但将其与数学推理数据结合使用，在推理和现实感知基准测试中仍然能取得一致的改进。进一步分析显示，PTS引入了更多的感知相关标记，并增加了模型对图像标记的注意。相关代码和数据将公开发布。
### Innovation
本文提出了感知时间扩展（PTS），这是一种新颖的范式，旨在通过引入更多感知相关的标记和将复杂感知问题分解为中间可解决的子问题来改善感知准确性。PTS与强化学习技术相结合，显著提高了感知性能，特别是在DisTANCE基准测试中的表现。另外，即使PTS数据完全是合成的，将其与数学推理数据结合使用也能在多种基准测试中取得一致的进步。
### Conclusion
通过引入感知时间扩展（PTS），本文证明了可以显著提高LVLMs的感知准确性，并且这种改进不仅限于合成数据，也可以应用到现实世界的数据上。提出了PTS数据和真实数据混合使用的策略，并公开了相关代码和数据。
## 565. `cs.CV` - 不可着色的样本：通过感知感知色域限制扰动防止未经授权的AI着色 [PDF](https://arxiv.org/pdf/2510.08979), [HTML](https://arxiv.org/abs/2510.08979)
### Authors
Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen
### Background
基于AI的着色技术虽能从灰度图像生成逼真的彩色图像，但存在版权侵权的风险，如未经授权对黑白漫画和电影进行着色并再次出售。目前，尚无有效手段来阻止这种不当使用情况。因此，需要探索一种新的防御机制来防止未经授权的AI着色行为。
### Innovation
提出了第一个防御框架，称为不可着色样本（Uncolorable Examples），通过嵌入不可感知的扰动到灰度图像中以阻止未经授权的着色行为。该方法名为感知感知色域限制扰动（PAChroma），通过优化Laplacian滤波器来保持感知质量，并在优化过程中应用多种输入变换，以增强模型间转移性和抵抗常见的后续处理（如压缩）的鲁棒性。实验表明，PAChroma能有效降低着色质量并保持视觉外观。
### Conclusion
本文初步探索了通过PAChroma方法保护视觉内容免受非法AI着色攻击，为生成媒体中的版权意识防御奠定了基础。
## 566. `cs.CV` - 关于大型视觉语言模型中视觉标记的 épistemic 不确定性与物体幻觉 [PDF](https://arxiv.org/pdf/2510.09008), [HTML](https://arxiv.org/abs/2510.09008)
### Authors
Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun
### Background
大规模视觉-语言模型（LVLMs）整合了视觉编码器（VE）和大型语言模型，在各类任务上取得了显著成果。然而，这类模型仍然面临关键挑战，例如物体幻觉，即生成输入图像中不存在的物体的描述。
### Innovation
研究表明，视觉编码器中的不确定视觉标记是导致物体幻觉的关键因素。提出了通过修改视觉编码器（VE）来检测和抑制不确定视觉标记的简单有效策略，包括利用对抗扰动的代理方法高效识别不确定视觉标记，并在VE中间层的自注意力过程中屏蔽这些不确定标记，从而减轻幻觉现象。
### Conclusion
实验结果表明，该方法显著减少了大型视觉语言模型中的物体幻觉，并能够与其他先前方法协同工作。
## 567. `cs.CV` - 从熵的角度探讨更高效的人工递归图像生成 [PDF](https://arxiv.org/pdf/2510.09012), [HTML](https://arxiv.org/abs/2510.09012)
### Authors
Xiaoxiao Ma,Feng Zhao,Pengyang Ling,Haibo Qiu,Zhixiang Wei,Hu Yu,Jie Huang,Zhixiong Zeng,Lin Ma
### Background
当前人工递归（AR）图像生成模型在采样方面存在一些问题，图像令牌的信息密度较低且在空间上分布不均匀。这些问题限制了生成质量和合成速度。
### Innovation
本文提出了两种创新方法：1) 通过基于令牌分布空间熵的动态温度控制，提高生成的质量平衡，包括内容多样性、对齐准确性与结构一致性，而无需额外的计算开销；2) 在推测性解码中采用熵意识接受规则，实现接近无损的生成，成本约为传统加速方法85%的推理成本。
### Conclusion
广泛使用不同的AR图像生成模型的基准测试表明，该方法在提高生成质量和采样速度方面具有有效性与通用性。
## 568. `cs.CV` - Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation [PDF](https://arxiv.org/pdf/2510.08994), [HTML](https://arxiv.org/abs/2510.08994)
### Authors
Yao Teng,Fuyun Wang,Xian Liu,Zhekai Chen,Han Shi,Yu Wang,Zhenguo Li,Weiyang Liu,Difan Zou,Xihui Liu
### Background
自回归文本到图像模型作为视觉内容生成的新范式，但由于它们逐个token的序列化解码过程，通常需要成千上万次模型前向传递来生成单个图像，从而导致推理速度较慢。因此，本文旨在通过提高效率来解决这一问题，提出了Speculative Jacobi-Denoising Decoding (SJD2)框架，该框架将去噪过程纳入雅克比迭代中，以在自回归模型中实现并行token生成。这种方法通过低开销的微调引入了预测下一个干净token的范式，指导模型向更稳定雅克比轨迹方向发展。
### Innovation
本文提出了一种Speculative Jacobi-Denoising Decoding (SJD2)框架，将去噪过程融入到雅克比迭代中，使得可在自回归模型中实现并行token生成。具体创新点包括引入预测下一个清洁token的范式，使预训练的自回归模型能够接受噪声扰动的token嵌入并进行低成本微调；并采用了概率标准在推理过程中并行验证和接受多个token，同时为下一轮迭代提供未接受token的去噪轨迹进行细化处理
### Conclusion
实验结果表明，本方法通过减少模型前向传递次数加快了生成过程，同时也保持了生成图像的视觉质量。
## 569. `cs.CV` - 柔性微电极阵列的视觉异常检测以实现可靠的机器人植入 [PDF](https://arxiv.org/pdf/2510.09071), [HTML](https://arxiv.org/abs/2510.09071)
### Authors
Yitong Chen,Xinyao Xu,Ping Zhu,Xinyong Han,Fangbo Qin,Shan Yu
### Background
柔性微电极（FME）植入大脑皮层存在挑战，因为FME探针的纤维状结构和与关键生物组织的交互。为了确保可靠性和安全性，植入过程需要仔细监测。因此，开发了一种基于机器人口腔FME植入系统显微摄像头的图像异常检测框架，用于四个检查点：微针、FME探针、钩结果和植入点。
### Innovation
该研究提出了一种统一的基于视觉的异常检测框架，利用现有的对象定位结果，从原始图像中提取对齐的感兴趣区域（ROIs），并输入预训练的视觉变换器（ViT）。此外，提出了一种逐级粒度片段特征取样方法，以解决不同位置的灵敏度-容错性权衡问题，并从原始通用ViT特征中选择具有较高信噪比的部分特征通道，以提供每个具体场景更好的描述符。
### Conclusion
所提出的方法通过我们的植入系统收集的图像数据集进行了验证，并证明了其有效性。
## 570. `cs.CV` - MambaH-Fit：通过状态空间建模重新思考基于超曲面拟合的点云法线估计 [PDF](https://arxiv.org/pdf/2510.09088), [HTML](https://arxiv.org/abs/2510.09088)
### Authors
Weijia Wang,Yuanzhi Su,Pei-Gen Ye,Yuan-Gen Wang,Xuequan Lu
### Background
现有的法线估计方法往往难以建模精细几何结构，限制了预测法线的准确性。最近，状态空间模型（SSMs），尤其是Mamba，展示了强大的建模能力，能够捕捉长范围依赖性并启发点云处理方面的适应性。然而，现有的Mamba基方法主要 focuses on理解全局形状结构，而对局部和精细的几何细节建模较少探索。
### Innovation
本文引入了注意力驱动的层次特征融合（AHFF）方案，以自适应融合多尺度点云片段特征，显著增强局部点云邻域中的几何上下文学习。进一步提出了点云片段的状态空间模型（PSSM），通过状态动力学将点云片段视为隐含的超曲面，从而有效实现精细几何结构的理解，用于法线预测。实验结果表明，在基准数据集上，我们的方法在准确性、鲁棒性和灵活性方面均优于现有方法。并且消融研究进一步验证了所提组件的贡献.
### Conclusion
我们在基准数据集上进行了广泛的实验，表明我们的方法在准确性、鲁棒性和灵活性方面优于现有方法。进一步的消融研究验证了所提组件的贡献。
## 571. `cs.CV` - GL-DT: 多无人机检测与跟踪中的全局-局部集成 [PDF](https://arxiv.org/pdf/2510.09092), [HTML](https://arxiv.org/abs/2510.09092)
### Authors
Juanqin Liu,Leonardo Plotegher,Eloy Roura,Shaoming He
### Background
无人机在军事侦察、环境监测等相关领域的广泛应用，引发了对准确和高效的多对象跟踪（MOT）技术的迫切需求，这对于无人机态势感知至关重要。现有的MOT方法在检测准确性和轨迹连续性方面仍面临复杂背景、小目标以及频繁的遮挡和交互的挑战。
### Innovation
该论文提出了一种全局-局部检测与跟踪（GL-DT）框架。它使用时空特征融合（STFF）模块联合建模运动和外观特征，并结合全局-局部协作检测策略，有效提高了小目标的检测能力。在此基础上，引入了JPTrack跟踪算法来解决标识符交换和轨迹分割等常见问题。实验证明，该方法在保持实时性能的同时显著提高了MOT的连续性和稳定性，为无人机检测和跟踪技术的进步提供了有力支持。
### Conclusion
所提出的GL-DT框架显著提升了MOT的连续性和稳定性，同时保持了实时性能，在多无人机检测与跟踪中具有重要的实践价值。
## 572. `cs.CV` - 基于病灶aware的潜表扩散模型在CT灌注合成扩散MRI中的后训练 [PDF](https://arxiv.org/pdf/2510.09056), [HTML](https://arxiv.org/abs/2510.09056)
### Authors
Junhyeok Lee,Hyunwoong Kim,Hyungjin Chung,Heeseong Eom,Joon Jang,Chul-Ho Sohn,Kyu Sung Choi
### Background
图像到图像的转换模型有助于解决医学图像获取中固有的各种挑战。潜表扩散模型（LDMs）通过在压缩潜空间中的高效学习成为最先进的生成图像模型的核心，但这种效率伴随着关键像素级细节损失的风险，这对高保真度医学图像至关重要。在生成临床重要结构（如病灶）时，这种限制尤为严重，因为病灶往往只占图像的一部分。病灶区域重建不准确会严重影响诊断可靠性和临床决策。
### Innovation
本文提出了一种新的后训练框架，将病灶aware的医学像素空间目标融入到LDMs在医学图像到图像转换中的后训练中。该方法不仅提升了整体图像质量，还改善了病灶的边界划分精确度。通过评估脑CT到MRI转换，特别是在急性缺血性脑卒中患者的早期准确诊断对于最佳治疗选择和改善患者预后至关重要。使用817名患者的CT灌注扫描数据集，本文证明了框架在合成DWI和ADC图像时提高了总体图像质量和病灶区分度，优于现有的图像到图像转换模型。此外，本文的后训练策略易于应用于预训练的LDMs，并在多种医学图像转换任务中展现出广泛的应用潜力。
### Conclusion
本文提出了一个病灶aware的LDMs后训练框架，该框架在合成CT灌注图像至扩散MRI时提升了图像质量及病灶的准确划分，通过实际应用案例验证了其有效性和广泛适用性。
## 573. `cs.CV` - 在不完善标签下LiDAR基语义分割的单域泛化探究 [PDF](https://arxiv.org/pdf/2510.09035), [HTML](https://arxiv.org/abs/2510.09035)
### Authors
Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen
### Background
准确的感知对于保证车辆安全至关重要，而激光雷达(LiDAR)是自动驾驶中的关键技术。为了确保在不同环境、不同传感器类型和不同天气条件下具有稳健的性能，而无需重新注解成本较高的情况下，需要在基于LiDAR的3D语义分割中实现跨域泛化。然而，由于传感器缺陷、遮挡和人为错误，LiDAR注解往往存在噪声，这降低了分割的准确性，并在域转移时进一步放大，威胁了系统可靠性。现有的图像中有标签噪声学习方法虽然研究较多，但在3D LiDAR分割的跨域泛化中仍然鲜有研究，因为点云的稀疏性和不规则性限制了2D方法的直接应用。因此，需要一个新的任务和方法来解决这一问题，即：具有噪声标签的LiDAR语义分割的跨域泛化(DGLSS-NL)。然而，现有的有噪声标签学习方法在转换到LiDAR数据方面适应性较差。
### Innovation
本研究提出了一个名为DuNe的双视图框架，它具有强分支和弱分支，通过特征级一致性增强和基于预测置信度过滤的信心感知交叉熵损失来确保一致性。与现有的方法相比，DuNe在跨域泛化任务DGLSS-NL中表现更佳，实现了更佳的mIoU性能，在SemanticKITTI数据集上达到了56.86%，nuScenes数据集上达到了42.28%，SemanticPOSS数据集上达到了52.58%，且在10%对称标签噪声下，平均算术平均数AM为49.57%，调和平均数HM为48.50%。研究通过适应三种典型的图像分类中的噪声标签学习策略，建立了一个新的基准。
### Conclusion
研究展示了在LiDAR语义分割的跨域泛化DGLSS-NL任务中的鲁棒性，提出的方法在多个数据集上取得了优异的表现，证明了在具有噪声标签的LiDAR语义分割任务中的跨域泛化性能。
## 574. `cs.CV` - Dense2MoE: 将扩散变压器重组为 MoE 以实现高效文本到图像生成 [PDF](https://arxiv.org/pdf/2510.09094), [HTML](https://arxiv.org/abs/2510.09094)
### Authors
Youwei Zheng,Yuxi Ren,Xin Xia,Xuefeng Xiao,Xiaohua Xie
### Background
扩散变压器（DiT）在文本到图像生成方面表现出色，但其庞大的参数规模导致了较大的推理负担。现有的参数压缩方法主要集中在剪枝上，但激进的剪枝往往会因为减少了模型容量而导致性能严重下降。
### Innovation
本研究首次将密集的扩散变压器（DiT）转换为 Mixture of Experts（MoE）以实现结构化的稀疏化。具体而言，通过用 MoE 层替换 DiT 块中的前馈网络（FFN），实现了 FFN 中激活参数数量的62.5%的减少。此外，还提出了块混合法（MoB）以选择性地激活 DiT 块，从而进一步增强稀疏性。为了确保有效的密集到 MoE 转换，设计了一条多步蒸馏流水线，包括基于 Taylor 计量的专家初始化、带负载平衡的知识蒸馏以及组特征损失来优化 MoB。
### Conclusion
Dense2MoE 将大型扩散变压器（如 FLUX.1）转换为 MoE 结构，减少了60%的活跃参数，同时保持了原始性能，并且在广泛的实验中超越了基于剪枝的方法。Dense2MoE 为高效文本到图像生成建立了一种新的范式。
## 575. `cs.CV` - 一种用于CT扫描中识别细微病理特征的新型多分支ConvNeXt架构 [PDF](https://arxiv.org/pdf/2510.09107), [HTML](https://arxiv.org/abs/2510.09107)
### Authors
Irash Perera(1),Uthayasanker Thayasivam(1) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka)
### Background
智能医学影像分析在协助临床诊断中具有重要作用，尤其是在识别细微病理特征方面。现有的方法和模型在处理这类问题时存在一定的挑战，尤其是在医疗图像分析中发现特定病理特征方面。为了克服这些挑战，论文提出了一种针对医学图像分析独特挑战设计的新型多分支ConvNeXt架构，适用于COVID-19诊断，并提供了一种一般框架来分类从CT扫描中获得的多种病理学。该模型包括从细致的数据预处理和增强到两个阶段受监督训练策略的严格的端到端流程，充分利用迁移学习。
### Innovation
论文提出了一种创新的多分支ConvNeXt架构，其中融合了三种并行提取的特征：全局平均池化、全局最大池化和新的注意力加权池化机制。该模型针对诊断COVID-19进行了训练和验证，使用了来自两个来源的2,609个CT切片数据集。实验结果表明，该模型在验证集上性能优越，最终ROC-AUC为0.9937，验证准确率为0.9757，F1分数为0.9825，显著优于以前报道的所有模型。这表明，结合现代多分支架构和精细的数据处理，可以实现与当前最先进的模型相媲美的诊断性能，从而证明了高级深度学习技术在稳健医学诊断中的有效性。
### Conclusion
该研究提出的方法和实验结果表明，现代化的多分支架构结合了精细的数据处理，能够达到或超越当前最先进的模型性能，进一步证实了先进深度学习技术在医学诊断中的有效性。
## 576. `cs.CV` - MSDM:基于多模态条件扩散模型生成用于细胞和核分割特定任务的病理图像 [PDF](https://arxiv.org/pdf/2510.09121), [HTML](https://arxiv.org/abs/2510.09121)
### Authors
Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu
### Background
在计算病理学中，标注数据稀缺，尤其是针对稀有或异常形态的数据，这给细胞和核分割带来了重大挑战。手动标注是劳动密集型且成本高昂的，而合成数据则提供了一种经济高效的替代方案。
### Innovation
我们提出了一个多模态语义扩散模型（MSDM），用于生成用于细胞和核分割的现实像素精确图像-掩模对。该模型通过细胞/核形态（水平和垂直图）、RGB色彩特性和BERT编码的试剂/指示元数据来条件生成过程。多模态通过多头交叉注意力整合，从而实现对生成图像的精细控制。定量分析表明，合成图像与真实数据高度匹配，生成和真实图像在匹配的生物条件下具有较低的Wasserstein距离。这些合成样本，例如柱状细胞，显著提高了柱状细胞分割模型的准确性。这种策略系统性地丰富了数据集，直接针对模型缺陷。
### Conclusion
我们强调了基于多模态扩散增强的有效性，以提高细胞和核分割模型的稳健性和泛化能力。从而为计算病理学中生成模型的广泛应用铺平了道路。
## 577. `cs.CV` - SOS: 合成对象分割提高检测、分割和语义定位 [PDF](https://arxiv.org/pdf/2510.09110), [HTML](https://arxiv.org/abs/2510.09110)
### Authors
Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna
### Background
视觉聚类依赖于实例分割、视觉定位和目标检测等技术，服务于从机器人感知到照片编辑的应用。然而，大型注释数据集成本高昂、覆盖面不均且难以扩展。尽管合成数据具有潜力，但它们通常缺乏灵活性、准确性和组成多样性。因此，需要一种简单且可扩展的数据合成流水线来解决这些问题。
### Innovation
本文提出了基于对象中心组成的SOS（合成对象分割）数据合成流水线。该方法通过使用结构化布局先验和生成性的环境调节来拼接高质量的合成对象分割，从而生成准确且多样的掩码、边界框和描述表达式。实验结果显示，使用100000个SOS合成图像训练的模型在检测和定位任务上优于使用更大规模真实图像数据集GRIT（20M）和V3Det（200K）训练的模型，AP值提升10.9，$N_{text{Acc}}$ 提升8.4。SOS能够实现可控的数据集构建，改善在低数据和封闭词汇量设置中的泛化能力。通过将合成对象分割与真实数据集（如LVIS和COCO）结合使用，可以实现不同规模真实数据的强性能，并在极度有限的真实数据条件下（如LVIS单个类别分割的AP提升3.83，COCO 1%设置下的AP提升6.59）取得更大的提升。
### Conclusion
SOS在合成对象分割的基础上，提供了可控的数据集构建方法，提升了模型在检测、分割和语义定位任务上的表现，并且在数据稀缺的情况下也表现出良好的泛化能力。
## 578. `cs.CV` - 实例级生成用于表示学习 [PDF](https://arxiv.org/pdf/2510.09171), [HTML](https://arxiv.org/abs/2510.09171)
### Authors
Yankun Wu,Zakaria Laskar,Giorgos Kordopatis-Zilos,Noa Garcia,Giorgos Tolias
### Background
实例级识别（ILR）关注于识别个体物体而不是广泛类别，提供图像分类中的最高细分度。然而，这种精细粒度的特性使得创建大规模标注数据集变得具有挑战性，限制了ILR在多个领域中的实际应用。
### Innovation
本文提出了一种新颖的方法，通过从多个领域在不同条件和背景下合成多样化的物体实例，生成大規模训练集，解决了ILR领域的特定挑战。这种方法首次不依赖任何真实图像，就能自动生成合成数据，显著改善了跨七种ILR基准测试的检索性能，涵盖多个领域。
### Conclusion
这种方法为从广泛实际领域的数据收集与整理提供了新的、高效且有效的替代方案，引入了一种新的ILR范式，只需输入目标领域的名称，就能解锁广泛的现实世界应用。
## 579. `cs.CV` - 视觉模型的训练特征归因 [PDF](https://arxiv.org/pdf/2510.09135), [HTML](https://arxiv.org/abs/2510.09135)
### Authors
Aziz Bacha,Thomas George
### Background
深度神经网络通常被视为不透明系统，这导致了需要提高对其可解释性的需求以增强信任度和责任感。现有的方法通常将测试时的预测归因于输入特征（例如图像中的像素）或有影响力训练示例。然而，这些方法通常将这两种视角分开研究，而本文主张这两种视角应联合研究。
### Innovation
本文探讨了训练特征归因，将测试预测与特定训练图像的特定区域联系起来，从而为深入模型的内部工作机制提供了新的见解。实验结果表明，训练特征归因可以提供细粒度、针对性的解释：它能够识别出导致分类错误的有害示例，并揭示出常规归因方法未能揭示的虚假相关性，如基于块的捷径。
### Conclusion
研究发现，通过训练特征归因方法，可以更细粒度地解释测试预测的过程，深入揭示深度模型的内部机制，识别驱动错误分类的有害示例，揭示常规方法难以发现的虚假关联。这种方法为提高深度学习解释性提供了新的途径。
## 580. `cs.CV` - 极坐标可分离变换用于高效正交旋转不变图像表示 [PDF](https://arxiv.org/pdf/2510.09125), [HTML](https://arxiv.org/abs/2510.09125)
### Authors
Satya P. Singh,Rashmi Chaudhry,Anand Srivastava,Jagath C. Rajapakse
### Background
在计算视觉中，正交矩量基图像表示是基本的，但经典的矩量方法存在高计算复杂度和大阶数下的数值不稳定性问题。例如，Zernike矩和伪Zernike矩需要耦合的径向-角处理，这导致了$frac{text{O}(n^3N^2)}{text{O}(n^6N^2)}$的复杂度和$text{O}(N^4)$条件数程度，其中n是阶数，N是图像尺寸。
### Innovation
我们引入了PSepT（Polar Separable Transform，极坐标可分离变换），一种在极坐标中克服非分离障碍的可分离正交变换。PSepT 通过具有离散余弦变换（DCT）径向基和傅里叶谐波角基的张量乘积构造实现了完整内核因子化，从而使径向和角处理独立。这个可分离的设计将计算复杂度降低到$text{O}(N^2 text{log }N)$，内存要求降低到$text{O}(N^2)$，并减少条件数程度到$text{O}(text{sqrt}N)$，相比传统的多项式方法实现了指数级别的改进。PSepT 具有正交性、完整性、能量守恒和旋转协变特性。实验结果证明在结构化数据集上PSepT具有更好的数值稳定性和计算效率，并保持了精确重构能力。该分离框架使得经典的高阶矩分析成为可能，为稳健的图像分析应用开辟了新的可能性。
### Conclusion
实验结果表明，PSepT在数值稳定性和计算效率上均表现优异，保持了精确重构的能力，同时在结构化数据集上的分类性能与竞赛方法相当。高阶矩分析的可行性通过PSepT的引入克服了经典方法的限制，为后续的图像分析应用提供了更多可能性。
## 581. `cs.CV` - 在线拓扑定位在支气管镜导航辅助中的应用 [PDF](https://arxiv.org/pdf/2510.09144), [HTML](https://arxiv.org/abs/2510.09144)
### Authors
Clara Tomasini,Luis Riazuelo,Ana C. Murillo
### Background
支气管镜检查是呼吸医学中的基础程序，通过患者支气管树进行导航以诊断或操作。医生在通过气道导航期间需要确定支气镜的位置，这是一个非常具有挑战性的任务，原因在于支气管树结构的复杂性以及医生的经验和培训水平不一。导航辅助可以帮助医生定位支气镜，以提高手术效果。目前常用的技术依赖于患者的前期CT扫描来获取气道的3D模型，随后使用额外的传感器或图像注册技术跟踪支气镜，这种方法虽然可以准确地确定位置，但也要求额外的设置、扫描和培训。但对于手术导航辅助而言，准确的度量定位并不总是必要的，基于通用气道模型的拓扑定位往往可以满足医生的导航需求。
### Innovation
本文提出了一种基于图像的支气管镜拓扑定位管道，无需使用患者CT扫描即可提供导航辅助。该方法仅通过训练仿真人数据实现，从而减少了真实数据标注的成本，并展示了良好的推广能力。与现有方法相比，该方法在真实数据测试序列中获得了更优的结果。
### Conclusion
本文通过训练无需CT扫描的仿真人数据，提出了一个基于图像的支气管镜拓扑定位管道，该方法在提供导航辅助的同时，避免了额外的设置和培训，并取得了优于现有方法的表现。
## 582. `cs.CV` - TARO：迈向语义丰富的开放世界物体检测 [PDF](https://arxiv.org/pdf/2510.09173), [HTML](https://arxiv.org/abs/2510.09173)
### Authors
Yuchen Zhang,Yao Lu,Johannes Betz
### Background
当前的现代物体检测器大多假设在“封闭场景”下工作，只能识别预定义类别的对象，无法处理未知类别的物体。在实际场景中，当遇到新型物体时，这种方法存在局限性和风险。尽管开放集检测方法通过将未知类别标记为‘未知’来尝试解决这一问题，但这种处理方式往往不够细致。对于安全关键应用，应根据具体的未知类别提供详细的描述，以增强决策的有用性和可靠性。例如，在自动驾驶场景中，区分未知动物需要紧急停车，而未知碎片则需要一个安全的车道变换，这种细节化的识别优于简单的‘未知’分类。
### Innovation
TARO 是一种新的检测框架，不仅能够识别未知物体，还能将它们分类为语义层次结构中的粗粒度父类别。TARO 使用了一种具有稀疏最大熵头的特殊架构，用于建模物体性，采用层次引导的重新标注组件提供辅助监督，以及一个学习语义层次关系的分类模块。实验结果表明，TARO 可以将高达 29.9% 的未知物体分类为有意义的粗粒度类别，显著减少了未知类与已知类之间的混淆，同时在未知召回率和已知的 mAP 方面取得了与之竞争的性能。
### Conclusion
TARO 能够在未知物体分类和已知物体检测之间取得平衡，提供了语义上更丰富的开放世界物体检测，为安全关键应用中的决策提供了更有力的支持。
## 583. `cs.CV` - 在线视频深度万物：低内存消耗的一致性深度预测 [PDF](https://arxiv.org/pdf/2510.09182), [HTML](https://arxiv.org/abs/2510.09182)
### Authors
Johann-Friedrich Feiden,Tim Küchler,Denis Zavadski,Bogdan Savchynskyy,Carsten Rother
### Background
单目视频的深度估计已成为许多实际计算机视觉系统的关键组成部分。最近，Video Depth Anything (VDA) 在长视频序列上展示了强大的性能。然而，VDA 依赖于批量处理，这阻碍了其在在线环境中的应用。
### Innovation
本文克服了这个限制，并引入了在线 VDA (oVDA)。关键创新在于使用大型语言模型（LLMs）的技术，即在推理期间缓存潜在特征，在训练期间掩码帧。oVDA 方法在准确性和 GPU 内存使用方面都优于所有竞争的在线视频深度估计方法。低 GPU 内存使用尤为重要，因为它对于在边缘设备上部署至关重要。研究表明，oVDA 可以在 NVIDIA A100 上以 42 FPS 运行，并在 NVIDIA Jetson 边缘设备上以 20 FPS 运行。
### Conclusion
我们不仅展示了 oVDA 在准确性和性能上的提升，还提供了源代码和编译脚本，使得 oVDA 可以轻松部署在低功耗硬件上。
## 584. `cs.CV` - 现代深度学习方法在板球击球分类中的应用：全面的基础研究 [PDF](https://arxiv.org/pdf/2510.09187), [HTML](https://arxiv.org/abs/2510.09187)
### Authors
Sungwoo Kang
### Background
在运动视频分析中，板球击球的视频序列分类是一个具有挑战性的问题，需要有效地建模空间和时间特征。
### Innovation
该研究首次全面比较了七种不同的深度学习方法在板球击球分类中的表现，涵盖了四种不同的研究范式。研究使用了传统的CNN-LSTM架构、注意力模型、视觉变换器、迁移学习方法和现代EfficientNet-GRU组合进行实现和系统性评估，展示了现代架构和系统优化带来的显著性能提升。
### Conclusion
研究发现，学术文献中的声称与实际实现之间的性能差距显著。虽然先前的研究报告的准确率分别为96%（Balaji LRCN）、99.2%（IJERCSE）和93%（Sensors），但标准化重实现达到的分别是46.0%、55.6%和57.7%。该研究结合EfficientNet-B0和基于GRU的时间模型的现代SOTA方法，达到了92.25%的准确率，证明了使用现代架构和系统优化的重大改进空间。所有实现都遵循现代MLOps实践，使用PyTorch Lightning，为运动视频分析研究提供了一个可重复的研究平台，突显了标准化评估协议的重要性。
## 585. `cs.CV` - 使用时延变换器进行瞬时测量的3D重建 [PDF](https://arxiv.org/pdf/2510.09205), [HTML](https://arxiv.org/abs/2510.09205)
### Authors
Yue Li,Shida Sun,Yu Hong,Feihu Xu,Zhiwei Xiong
### Background
瞬时测量被广泛应用于高效率的成像任务，包括视线（LOS）和非视线（NLOS）成像，但这些测量在三维重建中存在挑战，原因在于传感器的量子效率低以及噪声高，尤其是在长距离或复杂场景中。
### Innovation
提出了一种通用的时延变换器（TRT）架构，该架构针对瞬时测量设计了两种专门的注意力机制，分别用于探索局部和全局的时间空间相关性，并将局部和全局特征在标记空间中进行整合，从而生成具备高表现能力的深度特征。在此基础上，开发了TRT-LOS和TRT-NLOS两种特定任务模型，实验表明两者均显著优于现有方法，并贡献了大量具有不同噪声水平的合成LOS数据集以及使用自定义成像系统获得的真实NLOS测量数据集，以增强数据多样性
### Conclusion
全面的实验表明，TRT及其特定任务变体在合成数据和不同成像系统的现实世界数据上展现了显著的性能优势，同时通过增加数据集贡献和开放代码与数据集进一步推动了该领域的发展。
## 586. `cs.CV` - 朝向更安全和可理解的驾驶员意图预测 [PDF](https://arxiv.org/pdf/2510.09200), [HTML](https://arxiv.org/abs/2510.09200)
### Authors
Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar
### Background
自动驾驶（AD）系统的能力随着深度学习和AI的最新进展而不断提高，特别是在处理复杂任务方面。随着自主系统与人类互动的增加，驾驶系统的决策过程的可解释性变得越来越关键，以确保驾驶操作的安全性。成功的人机交互需要理解环境和驾驶任务的潜在表示，这在基于深度学习的系统中仍然是一个重大挑战。因此，为确保驾驶员安全，在行为发生之前预测驾驶员意图（DIP）变得至关重要。
### Innovation
为了推进可解释的驾驶员意图预测（DIP）研究，作者创建了eXplainable Driving Action Anticipation Dataset（DAAD-X）数据集，这是一个新的多模态、以自我为中心的视频数据集，提供分层和高级的文本解释作为因果推理，这些解释来自于驾驶员的眼球注视和自动驾驶车辆的视角。此外，作者提出了Video Concept Bottleneck Model（VCBM）框架，这是一种能够自动生成时空连贯解释的方法，而无需依赖于事后技术。实验结果表明，基于变换器的模型相较于传统的基于CNN的模型具有更高的可解释性。
### Conclusion
通过对DAAD-X数据集进行广泛的评估，展示了基于变换器的模型相较于常规的CNN模型具有更好的可解释性。我们还介绍了一种多标签t-SNE可视化技术来说明多个解释之间的分离和因果相关性。我们的数据、代码和模型可在指定的链接处获得。
## 587. `cs.CV` - Cattle-CLIP: 多模态牛行为识别框架 [PDF](https://arxiv.org/pdf/2510.09203), [HTML](https://arxiv.org/abs/2510.09203)
### Authors
Huimin Liu,Jing Gao,Daria Baran,AxelX Montout,Neill W Campbell,Andrew W Dowsey
### Background
牛的行为是评估单个动物健康、生产性能和整体福祉的重要指标。基于视频的监测结合深度学习技术已成为动物生物特征识别的主流方法，能够提供在一些行为识别任务中的高精度。本研究介绍了Cattle-CLIP，这是一种多模态深度学习框架，用于牛行为识别，通过引入语义线索来增强视频基于视觉特征的识别性能。该框架基于大型图像-语言模型CLIP并加入了一个时间整合模块，以解决预训练模型中网络数据与实际牛群监控视频之间的领域差距，引入了针对性的数据增强策略和专门的文本提示。
### Innovation
提出了Cattle-CLIP，这是一种结合语义线索的多模态深度学习框架，用于牛的行为识别。通过时间整合模块来增强视觉特征的识别性能。为了解决预训练模型和真实世界数据之间的领域差异，引入了定制化的数据增强策略和特定的文字提示。该框架在完全监督和少量样例学习场景中进行了评估，特别是在数据稀缺的行为识别领域表现出色，突显了多模态学习在农业和动物行为分析中的潜力。
### Conclusion
Cattle-CLIP 在监督设置下实现了 96.1% 的总体精度，对于进食、饮水和站立反刍行为的召回率达到接近 100%。在少量样本场景下，展示出了良好的泛化性能，突显了多模态学习在少数据条件下的能力。还介绍了 CattleBehaviours6 数据集，包含六种室内行为：进食、饮水、站立自梳毛、站立反刍、躺卧自梳毛和躺卧反刍，涵盖了 200 头荷斯坦-弗里斯兰奶牛的 1905 个片段。
## 588. `cs.CV` - Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation [PDF](https://arxiv.org/pdf/2510.09224), [HTML](https://arxiv.org/abs/2510.09224)
### Authors
Wangyu Wu,Xuhang Chen,Zhenhong Chen,Jing-En Jiang,Kim-Fung Tsang,Xiaowei Huang,Fei Ma,Jimin Xiao
### Background
Cross-Domain Sequential Recommendation (CDSR) 在现代消费电子和电子商务平台上扮演着重要角色。用户与书、电影、在线零售产品等多种服务互动。这些系统需要准确捕捉特定领域和跨领域的行为模式，以提供个性化和无缝的用户体验。
### Innovation
本文提出了TEMA-LLM（标签增强多注意力与大规模语言模型）框架，通过结合大规模语言模型进行语义标签生成和增强，使用大规模语言模型对项目标题和描述进行领域感知提示并生成描述性标签。嵌入标签后，与文本和视觉特征结合构造增强项目表示，引入标签增强多注意力机制以同时建模领域内和跨领域的用户偏好，使其能够捕捉复杂的和不断变化的消费者兴趣。
### Conclusion
在四个大规模电子商务数据集上的广泛实验表明，TEMA-LLM 在各个基准上表现优异，证明了基于语义标签的大规模语言模型及其多注意力集成对于面向消费者的推荐系统的好处。所提出的方法强调了大规模语言模型在消费电子产品领域智能、用户为中心服务方面的潜力。
## 589. `cs.CV` - 稳定视频无限：通过错误回收实现无限长度视频生成 [PDF](https://arxiv.org/pdf/2510.09212), [HTML](https://arxiv.org/abs/2510.09212)
### Authors
Wuyang Li,Wentao Pan,Po-Chien Luan,Yang Gao,Alexandre Alahi
### Background
现有的长视频生成方法试图通过手工编写的抗漂移（例如，修改的噪声调度、帧锚定）来减轻累积错误，但在处理自动生成、可能包含错误的输出时仍有一定的限制，主要实现了单一指令的外推，结果导致场景单调，动作重复。研究者认为，基本挑战不仅限于错误累积，更在于训练假设（看到干净数据）与测试时自回归现实（条件依赖自生成的错误输出）之间的关键差异。
### Innovation
SVI 结合了一种新的高效训练方法——错误回收微调，将 Diffusion 变换器（DiT）自动生成的错误重新利用为监督提示，促使 DiT 主动识别并纠正自己的错误。具体而言，SVI 通过闭环回收、自回归学习带入错误反馈；注入历史错误干预干净输入，模拟流动匹配中的累积错误过程；高效地通过一步双向集成近似预测并使用残差计算错误；动态将错误存储在离散时间步的回放记忆中，并从中重新抽样作为新输入的处理。
### Conclusion
SVI 能够在不增加推理成本的情况下将视频扩展到无限时长，同时能够适应多种条件（例如音频、骨架和文本流）。通过三个基准测试（包括一致、创意和条件设置），SVI 普遍验证了其多功能性和在现有技术水平上的领先地位。
## 590. `cs.CV` - Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation [PDF](https://arxiv.org/pdf/2510.09228), [HTML](https://arxiv.org/abs/2510.09228)
### Authors
Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala
### Background
恶劣天气条件（如雾霾、雨雪）会显著降低图像和视频质量，对依赖视觉输入的智能交通系统（ITS）构成严重挑战。这些降级影响了包括自动驾驶、交通监控和监视等关键应用。因此，需要对图像和视频恢复技术进行全面审查，以减轻由天气引起的视觉障碍。
### Innovation
本文将现有的图像和视频恢复方法分为传统先验方法和现代数据驱动模型，包括CNN、变压器、扩散模型和新兴的视觉语言模型（VLM）。此外，讨论了白天和夜间恢复挑战、基准数据集和评估协议。文章还深入讨论了当前研究的局限性，并提出了混合/复合降级恢复、实时部署和自代理AI框架等未来方向。
### Conclusion
本文旨在为提高智能交通环境中天气抗性的视觉系统提供有价值的参考资料。为了跟上该领域快速发展的步伐，我们将定期更新最新的相关论文及其开源实现。
## 591. `cs.CV` - 使用视觉-语言模型进行零样本图像隐私分类 [PDF](https://arxiv.org/pdf/2510.09253), [HTML](https://arxiv.org/abs/2510.09253)
### Authors
Alina Elena Baia,Alessio Xompero,Andrea Cavallaro
### Background
历史上，针对图像隐私预测的研究主要依赖于专门的学习模型。然而，当前的文献越来越多地倾向于使用设计用于通用任务的大规模视觉-语言模型（VLMs），这可能导致忽视专门为图像隐私设计的小型、专用模型在性能上限上的表现。本文构建了一个零样本基准，以公平地评估顶级开源VLMs在隐私分类任务中的表现，并对比它们与现有的单模态和多模态方法的性能、效率和鲁棒性。
### Innovation
本文提出的创新点包括构建了一个零样本基准，用于公平比较开源VLMs在图像隐私分类中的表现，并首次在大规模预训练模型中发现鲁棒性更强，但准确率并不一定更高的情况。
### Conclusion
尽管VLMs在资源上更为密集，但在隐私预测准确性方面，它们仍然落后于小巧的专业化模型。此外，VLMs在图像扰动下的鲁棒性表现更好。
## 592. `cs.CV` - 使用多模态大规模语言模型和消费级相机诊断肩部疾病 [PDF](https://arxiv.org/pdf/2510.09230), [HTML](https://arxiv.org/abs/2510.09230)
### Authors
Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun
### Background
肩部疾病是全球范围内对人们健康影响较大的常见病，尤其是在老年人和从事重复肩部任务的劳动者中发病率较高。在医疗资源匮乏的地区，实现肩部疾病的早期和准确诊断极具挑战性。因此，迫切需要低成本和易推广的辅助诊断解决方案。
### Innovation
研究引入了消费级设备拍摄的视频作为诊断基础，利用多模态大型语言模型（MLLMs）在肩部疾病初步诊断中的创新应用。提出了混合运动视频诊断框架（HMVDx），将动作理解与疾病诊断分别由两个MLLMs完成。此外，提出了通过医学决策逻辑过程计算的新型评估指标“实用性指数”（Usability Index），该指标从整个医疗诊断流程的角度评估MLLMs在医学领域的有效性。
### Conclusion
HMVDx在肩关节损伤诊断的准确性提高了79.6%，为未来利用MLLMs进行医学视频理解应用的研究提供了重要的技术贡献。该研究揭示了低成本MLLMs在医学应用中的潜在价值，为医疗从业者提供了一种新的诊断途径。
## 593. `cs.CV` - 在放射学视觉语言模型中使用离散语义熵进行幻象过滤 [PDF](https://arxiv.org/pdf/2510.09256), [HTML](https://arxiv.org/abs/2510.09256)
### Authors
Patrick Wienholt,Sophie Caselitz,Robert Siepmann,Philipp Bruners,Keno Bressem,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn
### Background
该研究旨在探讨使用离散语义熵（DSE）来拒绝可能产生幻觉的问题，是否能提高黑盒视觉语言模型（VLMs）在医学影像基于视觉问答（VQA）任务中的准确性。研究使用了两个公开的脱敏数据集，并结合了GPT-4o和GPT-4.1模型来评估DSE的有效性，通过计算保留低熵问题后的模型准确率来进行对比分析，最终验证了DSE在检测黑盒VLMs幻觉中的应用潜力，指出这种方法能显著提高诊断答案的准确性，并提供了一种临床VLM应用中的筛选策略。
### Innovation
该研究提出了一种新的方法，使用离散语义熵（DSE）来筛选可能产生幻觉的问题，以提高黑盒视觉语言模型在医学影像视觉问答任务中的准确性。通过实验数据表明，该方法能够显著提高模型的准确性，并提供了一种有效的幻象过滤策略。
### Conclusion
通过使用离散语义熵（DSE），能够在黑盒视觉语言模型中可靠地检测幻觉，该方法能显著提高诊断答案的准确性，并为临床视觉语言模型应用提供一个过滤策略。
## 594. `cs.CV` - 聚焦于多模态强化学习中的token感知 [PDF](https://arxiv.org/pdf/2510.09285), [HTML](https://arxiv.org/abs/2510.09285)
### Authors
Siyuan Huang,Xiaoye Qu,Yafu Li,Yun Luo,Zefeng He,Daizong Liu,Yu Cheng
### Background
虽然可验证奖励的强化学习（RLVR）已提升大型联合视觉语言模型（LVLMs）的推理能力，但现有方法在处理多模态推理时往往忽略了视觉感知在RLVR优化过程中的关键作用。
### Innovation
提出了一种新的视觉感知策略——基于token感知的政策优化（VPPO），它通过引入token感知来细化学习信号，从而显著提升LVLMs的多模态推理能力。
### Conclusion
实验结果表明，VPPO在八项感知与推理基准测试中表现出色，并且效果在7B和32B模型规模上得到了一致性验证。这一发现不仅为分析多模态RLVR提供了新的token级感知视角，还提供了一种新的、有效的优化策略，大幅提高了LVLMs的多模态推理能力。
## 595. `cs.CV` - MomentSeg：聚焦时刻采样以提高视频像素理解 [PDF](https://arxiv.org/pdf/2510.09274), [HTML](https://arxiv.org/abs/2510.09274)
### Authors
Ming Dai,Sen Yang,Boqiang Duan,Wankou Yang,Jingdong Wang
### Background
RefVOS旨在通过自然语言描述对视频中的目标对象进行分割，这要求同时进行时间推理和细节视觉理解。现有的基于LLM的采样策略通常依赖于手工构建的启发式方法或外部关键帧模型，前者经常忽略了重要的时间线索，后者则增加了系统的复杂性。
### Innovation
提出了一种统一框架，联合优化了时间语句定位(TSG)和RefVOS，自然地结合了关键时刻定位能力。在训练中，引入了一种新型的TSG范式，通过使用一个专用的'[FIND]'标记进行基于时间标记相似性的匹配来识别关键时刻，从而避免了外部时间戳编码的需求。在推理阶段，设计了一种以时刻为中心的采样(MCS)策略，密集采样信息型时刻并稀疏采样非关键帧，同时保留运动细节和全局上下文。为提高跟踪稳定性，开发了双向锚更新传播(BAP)，利用最相关的时刻作为高质量掩膜初始化的起点，并在采样点动态更新以减轻累积误差。
### Conclusion
本工作提出的方法在保持运动细节和全局上下文的同时提高了视频像素理解的精度，增强了跟踪稳定性，并且公布了代码和模型。
## 596. `cs.CV` - 目视觅食：人类视觉凝视动态与深度预测模型 [PDF](https://arxiv.org/pdf/2510.09299), [HTML](https://arxiv.org/abs/2510.09299)
### Authors
Tejaswi V. Panchagnula
### Background
动物通常通过具有重尾步长的Levy游走随机轨迹进行觅食，以适应稀疏资源环境。尽管传统的模型强调基于图像的显著性，但人类视觉凝视的时间空间统计特性却未得到充分探索。理解这些动态对注意力建模和基于视觉的接口具有重要应用价值。研究通过大规模的人类被试实验（40名参与者，观看50张多样化图片），并记录了超过400万个凝视点，从而揭示了类似动物觅食的凝视轨迹。此外，训练了一个卷积神经网络（CNN）来仅从图像输入中预测固定热图，表明关键的凝视行为可以从视觉结构中学习。这些发现提供了新的证据，表明人类的视觉探索遵循与自然觅食类似的统计规律，并为通过生成和预测框架建模凝视提供了可能途径
### Innovation
该研究首次通过大规模实验揭示了人类视觉凝视遵循与动物觅食类似的Levy游走规律，同时使用卷积神经网络预测凝视热图，表明视觉结构可以独立驱动凝视行为，为通过生成和预测框架建模凝视提供了创新方法
### Conclusion
人类视觉探索遵循类似自然觅食的统计规律，且凝视行为的关键成分可以从视觉结构中学习，为未来通过预测和生成模型研究视觉行为提供了新的见解和方法
## 597. `cs.CV` - CapGeo: 一种辅助标题的几何推理方法 [PDF](https://arxiv.org/pdf/2510.09302), [HTML](https://arxiv.org/abs/2510.09302)
### Authors
Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang
### Background
多模态大型语言模型（MLLMs）在几何推理方面仍存在核心挑战。尽管最先进的闭源系统（如GPT-O3和Gemini-2.5-Pro）在IMO等文本推理任务上表现出色，但在解决几何问题上仍难以可靠地处理。这表明瓶颈可能在于理解几何图示而非推理本身。因此，考虑到几何图示可以被简洁的文本描述，将视觉内容转换为标题提供了一个有希望的方向
### Innovation
我们引入了CapGeo，这是一个辅助标题的推理框架，将视觉和文本模态联系起来。实验表明，在模型采用标题的情况下，性能显著提升：Qwen2.5-VL-72B 从8.6% 提高到59.0%，而Claude-Opus-4 从44.8% 提高到73.0%。此外，我们进一步提出了CapGeo-Bench，这是一个包含4,641个精挑细选的图标题对的数据集，该数据集采用基于关键点的评估指标，该指标与下游CapGeo性能高度相关，从而实现可靠地评估几何图标题的能力
### Conclusion
我们的框架和基准展示了在MLLMs中推进几何推理的一个新途径
## 598. `cs.CV` - RadioFlow: 使用流匹配实现高效雷达图构建框架 [PDF](https://arxiv.org/pdf/2510.09314), [HTML](https://arxiv.org/abs/2510.09314)
### Authors
Haozhe Jia,Wenshuo Chen,Xiucheng Wang,Nan Cheng,Hongbo Zhang,Kuimou Yu,Songning Lai,Nanjian Jia,Bowen Tian,Hongru Xiao,Yutao Yue
### Background
下一代无线系统需要准确且实时的雷达图（RM）生成，但基于扩散的方法往往存在模型过大、迭代降噪慢及推理延迟高等问题，这些都限制了其实际部署。
### Innovation
提出了一种基于流匹配的生成框架——RadioFlow，通过单步高效采样实现了高质量的雷达图生成。RadioFlow 学习了噪声和数据之间的连续传输轨迹，使得训练和推理速度显著加快，同时保持重建准确性。与领先的基于扩散模型的基准（RadioDiff）相比，RadioFlow 的参数少至 8 倍，并且推理速度快 4 倍以上，为未来 6G 网络提供了可扩展、能耗低且实时的电磁数字孪生路经。
### Conclusion
全面的实验表明，RadioFlow 提供了一种新的途径，可以实现大规模、能效高且实时的电磁数字孪生，适用于未来的 6G 网络。代码已发布在 GitHub 上。
## 599. `cs.CV` - 基于实例感知的鲁棒一致性正则化用于半监督细胞核实例分割 [PDF](https://arxiv.org/pdf/2510.09329), [HTML](https://arxiv.org/abs/2510.09329)
### Authors
Zenan Lin,Wei Li,Jintao Chen,Zihao Wu,Wenxiong Kang,Changxin Gao,Liansheng Wang,Jin-Gang Yu
### Background
在病理图像中进行细胞核实例分割对于下游任务如肿瘤微环境分析至关重要。然而，高成本和标注数据的稀缺性限制了完全监督方法的应用；现有的半监督方法在实例级别未能充分正则化一致性，无法充分利用病理结构的固有先验知识，并且容易在训练中引入噪声伪标签。
### Innovation
提出了一种实例感知鲁棒一致性正则化网络（IRCR-Net），引入了匹配驱动实例意识一致性（MIAC）和先验驱动实例意识一致性（PIAC）机制来细化教师和学生子网络的细胞核实例分割结果，特别是在密集分布和重叠的细胞核情况下。通过引入病理图像中细胞核的形态先验知识，利用这些先验知识评估从未标注数据生成的伪标签的质量，去除低质量伪标签，提升高质量预测，从而减少伪标签噪声并促进网络的鲁棒训练。
### Conclusion
实验结果表明，所提出的方法在多个公开数据集上显著提升了半监督细胞核实例分割性能，甚至在某些情况下超越了完全监督方法。
## 600. `cs.CV` - 增强红外成像: 进化提示融合网络及基准 [PDF](https://arxiv.org/pdf/2510.09343), [HTML](https://arxiv.org/abs/2510.09343)
### Authors
Jinyuan Liu,Zihang Chen,Zhu Liu,Zhiying Jiang,Long Ma,Xin Fan,Risheng Liu
### Background
现有的红外图像增强方法主要针对单一的退化因素，如噪声、对比度和模糊进行处理，难以应对多种退化交织的情况。而针对所有类型退化的集成增强方法，在热成像传感器中往往效果有限，主要是因为红外成像模型与其他传感器（如RGB传感器）显著不同。本文重新审视了热成像机制，并提出了一种进化提示融合网络（Progressive Prompt Fusion Network, PPFN）以克服这些挑战。
### Innovation
引入了进化提示融合网络（PPFN），该网络基于热成像过程提出了逐步融合提示对的方法，以适应单一或多种退化情况。此外，还引入了一种选择性进化训练（Selective Progressive Training, SPT）机制，该机制逐步精化模型对于综合情况的处理能力，从而不仅能够去除传感器噪声并保留关键的结构细节，还能增强热图像的整体对比度。此外，本文还提出了迄今为止最高质量、场景多样的红外基准数据集，涵盖广泛的应用场景。
### Conclusion
通过广泛的实验验证，本文的方法不仅在特定退化情况下的视觉效果取得了显著的成果，而且在复杂退化场景下表现优异，实现了8.76%的性能提升。
## 601. `cs.CV` - 基于动态推理链的视觉语言模型在多模态关键短语预测中的增强 [PDF](https://arxiv.org/pdf/2510.09358), [HTML](https://arxiv.org/abs/2510.09358)
### Authors
Qihang Ma,Shengyu Li,Jie Tang,Dingkang Yang,Shaodong Chen,Yingyi Zhang,Chao Feng,Jiao Ran
### Background
多模态关键短语预测（MMKP）旨在超越仅限于文本的方法，通过结合多种输入信息来生成一组明确的短语。传统的多模态方法在处理缺失和未知情境时显示出显著的局限性。此外，现有基准方法因训练测试集之间的高度重叠而被高估了模型的能力。因此，本文提出利用视觉语言模型（VLMs）来处理MMKP任务。为评估VLMs的下限性能，采用零样本和监督微调两种策略。在提高VLMs的复杂推理能力方面，引入了Fine-tune-CoT方法，并提出了一种动态CoT策略来应对“过度思考”现象，该策略在训练过程中动态注入CoT数据，使模型在推理阶段灵活利用推理能力。
### Innovation
提出利用视觉语言模型（VLMs）进行多模态关键短语预测，其中包括使用零样本和监督微调策略评估VLMs的下限性能，采用Fine-tune-CoT方法提升复杂推理能力，以及提出动态CoT策略以应对“过度思考”现象。
### Conclusion
对提出的策略在多个数据集上进行评估，实验结果表明所提出的方法的有效性。代码可在该链接下载。
## 602. `cs.CV` - HJB-ni yǎnlì gōngcè yuǎn-jìn fēnxù yǔ gōngcì de dǎomáo yùnzhì yǐbiān de dāngdìkàn yínsù kěrù dìzhì jì [PDF](https://arxiv.org/pdf/2510.09320), [HTML](https://arxiv.org/abs/2510.09320)
### Authors
Wenyao Zhang,Hongsi Liu,Bohan Li,Jiawei He,Zekun Qi,Yunnan Wang,Shengyang Zhao,Xinqiang Yu,Wenjun Zeng,Xin Jin
### Background
当前的自监督单目深度估算（MDE）方法因为提取的语义-空域知识不足而面临性能局限。这些方法在处理空域细节和全局语义信息时存在不足，导致难以准确地进行深度估计和场景理解。因此，迫切需要一种能够系统地整合基础模型（如CLIP和DINO），以提取视觉先验并获得足够的上下文信息的方法，从而改善这一问题。
### Innovation
本文提出了一种名为Hybrid-depth的新颖框架，系统地整合了基础模型（例如CLIP和DINO），以提取视觉先验，并获得足够的上下文信息，从而改进单目深度估算。该方法采用了从粗到细的逐层学习框架：首先，利用对比语言指导从CLIP和DINO聚合多粒度特征，设计了一个近似目标任务，通过文本提示强制实现深度感知的特征对齐；其次，在粗特征的基础上，整合相机姿态信息和像素级语言对齐，进一步细化深度预测。这种方法通过语言指导聚合CLIP的语义上下文和DINO的空间细节，有效解决了特征粒度匹配问题。研究表明，该方法在KITTI基准测试中显著优于当前最先进的方法，同时也能为后端任务，如BEV感知带来实际益处。
### Conclusion
实验结果表明，本文提出的方法在所有指标上都显著优于当前最佳方法，并且对下游任务具有实际益处。该方法作为现有的自监督单目深度估算管道（如Monodepth2、ManyDepth）的一个即插即用深度编码器，通过整合CLIP的语义背景和DINO的空间细节，有效地解决了特征尺寸不匹配的问题，从而大大提高了连续深度估计的性能。
## 603. `cs.CV` - 利用预训练DETR中的动态稀疏性 [PDF](https://arxiv.org/pdf/2510.09380), [HTML](https://arxiv.org/abs/2510.09380)
### Authors
Reza Sedghi,Anand Subramoney,David Kappel
### Background
在基于Transformer的模型中高效推理仍然是个挑战，特别是在对象检测等视觉任务中。DETR中的MLP层具有固有的稀疏性，现有的方法难以充分利用这种稀疏性而不需要重新训练模型。
### Innovation
本文提出了两种方法来利用DETR中MLP层的固有稀疏性：第一种是Static Indicator-Based Sparsification (SIBS)，通过固定激活模式预测神经元的不活性；第二种是Micro-Gated Sparsification (MGS)，这是一种轻量级的门控机制，通过一个小型线性层预测动态稀疏性。MGS可实现85%至95%的激活稀疏性，保持甚至改进模型性能的同时显著降低计算量。
### Conclusion
本文提供了一种实用的、输入自适应的剪枝方法，使预先训练的视觉Transformer可以在无需完全重新训练的情况下高效部署。
## 604. `cs.CV` - BLINK-Twice: 你看到的，但你观察到了吗？一个基于视觉感知的推理基准 [PDF](https://arxiv.org/pdf/2510.09361), [HTML](https://arxiv.org/abs/2510.09361)
### Authors
Junyan Ye,Dongzhi Jiang,Jun He,Baichuan Zhou,Zilong Huang,Zhiyuan Yan,Hongsheng Li,Conghui He,Weijia Li
### Background
最近，多模态大型语言模型（MLLMs）在增强其推理能力方面取得了快速进步，特别是在处理基于视觉的推理方面。但是，现有的推理基准仍然主要评估基于语言的推理能力，经常将视觉输入视为可以替换的背景信息。因此，研究者们需要一种新的基准测试，能够评估模型在纯视觉内容基础上的推理能力。
### Innovation
本文提出了BLINK-Twice，这是一种以视觉为中心的推理基准，集中于具有挑战性的感知任务。该基准要求模型仅从视觉内容中进行推理，从而转向基于图像的推理。与以往的感知基准不同，BLINK-Twice不仅要求观察感知（“see”），更要求进行细致的观察和分析推理（“observe”）。该基准包括三种核心组成部分：七种视觉挑战测试视觉推理能力、自然对抗图像对以强化依赖视觉内容、以及标注的推理链以进行精细的推理过程评估，而不仅仅是最终答案。
### Conclusion
本文评估了20种领先的MLLMs，包括12个基础模型和8个增强推理能力的模型。结果表明，BLINK-Twice对现有模型构成了重大挑战，重复图像观察能够改善模型性能，表明主动视觉交互的需求。此外，研究还指出当前模型在视觉推理方面需要一个新的范式。
## 605. `cs.CV` - Minkowski-MambaNet:具有选择性状态空间模型的点云框架，用于森林生物量量化 [PDF](https://arxiv.org/pdf/2510.09367), [HTML](https://arxiv.org/abs/2510.09367)
### Authors
Jinxiang Tu,Dayong Ren,Fei Shi,Zhenhong Jia,Yahong Ren,Jiwei Qin,Fang He
### Background
准确的森林生物量量化对于监测碳循环至关重要。尽管机载LiDAR在捕捉森林结构方面表现出色，但由于难以建模区分树木所需的长距离依赖关系，直接从点云数据估计木质体积和地上生物量（AGB）仍具有挑战性。
### Innovation
提出了一种新颖的深度学习框架Minkowski-MambaNet，该框架通过将Mamba模型的选择性状态空间模型（SSM）整合到Minkowski网络中，有效地编码全局语境和长距离依赖关系，从而提高树木区分能力，同时通过引入跳跃连接来增强特征和加速处理。在丹麦国家森林监测LiDAR数据上的测试中，Minkowski-MambaNet显著优于现有方法，提供了更精确和稳健的估计。此外，该方法不需要数字地形模型，并且对边界故障具有鲁棒性。
### Conclusion
这一工作为大规模森林生物量分析提供了强大的工具，推动了基于LiDAR的森林监测进入了新阶段。
## 606. `cs.CV` - Mono4DEditor: 通过点级语言嵌入高斯点定位实现单目视频驱动的4D场景编辑 [PDF](https://arxiv.org/pdf/2510.09438), [HTML](https://arxiv.org/abs/2510.09438)
### Authors
Jin-Chuan Shi,Chengye Su,Jiajun Wang,Ariel Shamir,Miao Wang
### Background
基于单目视频重建4D场景并根据文本提示进行编辑是一个有价值的但极具挑战性的任务，广泛应用于内容创作和虚拟环境。关键难度在于实现复杂、动态场景中局部区域的语义精确编辑，同时保持未编辑区域内容的完整性。
### Innovation
提出了一种名为Mono4DEditor的新型框架，该框架能够灵活、精确地根据文本驱动对4D场景进行编辑。该方法通过量化CLIP特征增强3D高斯，形成嵌入语言的动态表示，从而实现对任意空间区域的高效语义查询。还提出了一种两级点级定位策略，首先通过CLIP相似性选择候选高斯点，然后优化它们的空间范围以提高准确性。最后，使用基于扩散的视频编辑模型对局部区域进行精准编辑，流和素描指导确保空间一致性与时序连贯性。
### Conclusion
广泛的实验表明，Mono4DEditor能够在各种场景和对象类型中实现高质量、文本驱动的编辑，同时保持未编辑区域的外观和几何结构的完整，并在灵活性和视觉保真度上超越了先前的方法。
## 607. `cs.CV` - 低光视频增强中基于动态权重的时序聚合 [PDF](https://arxiv.org/pdf/2510.09450), [HTML](https://arxiv.org/abs/2510.09450)
### Authors
Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai
### Background
低光视频增强（LLVE）是一个具有挑战性的任务，由于噪声、低对比度和色彩退化的问题。尽管基于学习的方法可以提供快速推理，但在实际的低光场景中，它们仍难以应对严重的噪声，主要是因为有效利用时序信息的局限性。
### Innovation
本文提出了DWTA-Net，这是一种新颖的双阶段框架，联合利用短期和长期的时序线索。第一阶段使用视觉状态空间块进行多帧对齐，恢复亮度、色彩和结构，并保持局部一致性。第二阶段引入了动态权重引导的时间聚合的递归细化模块，根据不同区域的静态和动态特性自适应地平衡这些区域。此外，通过纹理自适应损失进一步保持细节，同时在平坦区域促进平滑性。
### Conclusion
实验结果表明，DWTA-Net可以有效抑制噪声和伪影，相比现有最先进的方法提供了更好的视觉质量。
## 608. `cs.CV` - 在动态城市场景中对3D Gaussian 拟合进行视图感知密集化 [PDF](https://arxiv.org/pdf/2510.09364), [HTML](https://arxiv.org/abs/2510.09364)
### Authors
Yikang Zhang,Rui Fan
### Background
3D Gaussian 拟合（3DGS）已被证明在合成功新人视图方面表现出色。然而，其效果高度依赖于初始化点云的质量。特别是在无限扩展、动态的城市环境中，要实现场景结构的均匀和完整覆盖，通常需要重叠观察锥体，这一假设往往无法满足。通过部分初始化的点云训练高斯模型，常会导致扭曲和伪影，因为从光照齐交可能会导致与被遮挡或不可见几何结构关联的高斯原语的梯度传播出错。现有的密集化策略仅是克隆和分裂现有的高斯原语，无法重建缺失的结构。
### Innovation
本文提出了一种名为 VAD-GS 的3DGS框架，适用于具有挑战性的城市场景中的几何恢复。该方法通过体素基线可视推理识别不可靠的几何结构，通过多样性的视图选择选择有信息支持的视图，并通过基于斑块匹配的多视图立体重建恢复缺失的结构。这一设计使得即使在缺乏起始点的区域，也能根据可靠的几何先验生成新的高斯原语。广泛的实验表明，VAD-GS 在 Waymo 和 nuScenes 数据集上优于最先进的3DGS方法，并显著提高了对静止和动态对象重建几何质量。
### Conclusion
本文提出了一种新的方法——VAD-GS，用于解决现有的3DGS方法在动态城市场景下的问题。通过视觉感知的密集化，VAD-GS 能够有效恢复缺失的几何结构，并生成高质量的合成视图。该方法已在两个数据集上进行了验证，证明了其在三维合成视图生成领域中的优越性。
## 609. `cs.CV` - D-TPT: 通过维度熵最大化校准视觉语言模型测试时提示调优 [PDF](https://arxiv.org/pdf/2510.09473), [HTML](https://arxiv.org/abs/2510.09473)
### Authors
Jisu Han,Wonjun Hwang
### Background
测试时适应范式通过在目标域的未标记数据上立即适应源模型来提供对数据域转换的灵活性。视觉语言模型利用其泛化能力来处理各种下游任务，并且测试时提示调优已成为适应视觉语言模型的一种突出解决方案。先前的研究也发现了跨模态主导维度的模态间隙问题，导致了调整精度的下降。
### Innovation
本文提出了一种名为维度熵最大化（D-TPT）的方法，以缓解视觉语言模型中测试时提示调优的校准性能下降。该方法通过使文本特征分布趋向均匀来限制主导维度的影响，从而减轻它们间的依赖。这种方法能够提高视觉语言模型在实际部署场景中的可靠性。
### Conclusion
本文提出的方法能够缓解测试时提示调优中的校准性能问题，提供了一个简单且有效的方法来提高视觉语言模型在实际部署中的可靠性。
## 610. `cs.CV` - SilvaScenes：自然林下树段分割与物种分类的图像数据集 [PDF](https://arxiv.org/pdf/2510.09458), [HTML](https://arxiv.org/abs/2510.09458)
### Authors
David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère
### Background
随着对森林管理中机器人技术的兴趣增加，但在复杂自然环境中仍存在显著的感知障碍。例如，严重的遮挡、多变的光照条件以及密集的植被给自动化系统带来了挑战。这些任务依赖于先进的感知能力，如个体树种的检测和精细化分类。然而，现有的数据集经常集中在城市环境或有限的树种上，不足以开发这样的感知系统。因此，本文介绍了SilvaScenes，一个用于自然林下图像实例分割的树种数据集，数据集采集覆盖了加拿大魁北克省的五个生物气候带。
### Innovation
该论文提出了SilvaScenes数据集，这是首个用于林下树种实例分割的数据集。数据集包含来自24个树种的1476棵树，并由林业专家进行了标注。通过对比最先进的深度学习模型在实例分割和物种分类任务上的表现，证明了该数据集在技术和方法上的挑战性，并展示了其在森林管理中的潜在应用价值。
### Conclusion
结果表明，尽管树的分割相对容易，但物种分类仍然是一个巨大的挑战，mAP仅为35.69%。本文的数据集及代码已公开，证明了SilvaScenes在该领域的创新价值和应用潜力。
## 611. `cs.CV` - 基于临床驱动的交互分割评估方法 [PDF](https://arxiv.org/pdf/2510.09499), [HTML](https://arxiv.org/abs/2510.09499)
### Authors
Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso
### Background
交互分割是一种有前途的策略，用于构建适用于临床的、具有良好泛化能力的三维医学图像分割算法。但是，不一致且不切实际的评估方法阻碍了公平比较并歪曲了实际性能。
### Innovation
提出了一种基于临床的评价任务和指标定义方法，并构建了一个标准化评价流水线的软件框架。此方法评估了最先进的算法在异构和复杂任务中的表现，发现最小化用户交互处理中的信息损失对模型的鲁棒性至关重要；自适应缩放机制增强了鲁棒性和加速了收敛；验证提示行为/预算与训练不同会导致性能下降；二维方法在类似切片的图像和粗略目标上表现良好，但三维上下文有助于处理大型或不规则形状的目标；非医学领域模型（如SAM2）在对比度差和复杂形状下性能会下降。
### Conclusion
评估结果显示，最小化信息损失、采用自适应缩放机制、统一验证提示行为和预算、考虑三维上下文以及优化非医学领域模型的输入可以提高交互分割算法的性能和鲁棒性。
## 612. `cs.CV` - PRNet: 原始信息就是一切 [PDF](https://arxiv.org/pdf/2510.09531), [HTML](https://arxiv.org/abs/2510.09531)
### Authors
PeiHuang Zheng,Yunlong Zhao,Zheng Cui,Yang Li
### Background
在空中图像的小物体检测中，由于像素表示有限，特征提取过程中会遭受严重的信息降解，导致浅层空间细节与语义信息对齐不充分，从而频繁出现漏检和假阳性结果。现有的基于FPN的方法通过后处理增强尝试缓解这些问题，但重建的细节往往会偏离原始图像信息，阻碍了与语义内容的融合。
### Innovation
提出了一种实时检测框架PRNet，该框架优先考虑浅层空间特征的保存和高效利用，以增强小物体的表示。PRNet通过两种模块实现这一目标：渐进细化neck (PRN) 用于通过主干网络重用和迭代细化进行空间-语义对齐，以及增强切片采样 (ESSamp) 用于在下采样过程中通过优化排列和卷积保留浅层信息。
### Conclusion
在VisDrone、AI-TOD和UAVDT数据集上的大量实验表明，在相似的计算约束条件下，PRNet的表现优于最先进的方法，实现了更高的准确性和效率权衡。
## 613. `cs.CV` - 带有LoRA的Few-shot多令牌DreamBooth风格一致角色生成 [PDF](https://arxiv.org/pdf/2510.09475), [HTML](https://arxiv.org/abs/2510.09475)
### Authors
Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar
### Background
随着音频视频行业的发展，AI技术不仅用于自动化常规任务，还推动了新的艺术形式。本文解决了生成大量保留少量人类设计的参考角色的艺术风格和共同视觉特征的新角色的问题，以提高动画、游戏及相关领域的创造性可能性。
### Innovation
本文基于DreamBooth的微调技术，提出了一种多令牌策略，结合聚类对个体角色及其整体风格指派不同令牌，采用LoRA进行参数高效微调。通过去除特定类别正则化项并在生成期间引入随机令牌和嵌入，实现了无限制角色生成，并保留了学习到的风格。该方法在五个小型专用数据集上进行了评估，结果表明，生成高质量、多样化的新角色并保留了参考角色的美学特征。
### Conclusion
研究表明，本文的方法生成了高质量、多样的新角色，保留了参考角色的独特美学特征，得到了人类评价进一步证实其有效性和方法潜力。
## 614. `cs.CV` - TC-LoRA: 时间调节条件LoRA以实现自适应扩散控制 [PDF](https://arxiv.org/pdf/2510.09561), [HTML](https://arxiv.org/abs/2510.09561)
### Authors
Minkyoung Cho,Ruben Ohana,Christian Jacobsen,Adityan Jothi,Min-Hung Chen,Z. Morley Mao,Ethem Can
### Background
当前可控扩散模型通常依赖固定架构，通过修改中间激活值来注入新的模态指导。这种方法使用静态条件策略应用于动态、多阶段去噪过程，限制了模型在生成从粗略结构到细节数字时的适应能力。研究表明，这种静态控制策略限制了模型在生成过程中逐步精细化时的动态调整能力。
### Innovation
我们引入了TC-LoRA（时间调节条件LoRA），一种新的范式，能够实现动态、上下文感知的控制。我们的框架使用超网络生成LoRA适应器，根据时间和用户条件，为每个扩散步骤动态调整冻结主干的权重修改。这种方法使模型能够学习并执行在整个生成过程中应用条件引导的明确适应策略。
### Conclusion
通过在多个数据领域进行实验，我们证明了这种动态、参数化控制显著提高了生成保真度和在空间条件下的准确性，优于基于静态激活的方法。TC-LoRA展示了模型条件策略可以通过更深层次的权重功能调整进行修改，从而更好地适应任务和生成阶段的动态需求。
## 615. `cs.CV` - 三星图像中的斜向伪像：PRNU挑战与解决方案 [PDF](https://arxiv.org/pdf/2510.09509), [HTML](https://arxiv.org/abs/2510.09509)
### Authors
David Vázquez-Padín,Fernando Pérez-González,Alejandro Martín-Del-Río
### Background
研究了几款三星智能手机拍摄的照片中存在的斜向伪像及其对基于PRNU的相机来源验证的影响。研究发现，某些Galaxy S系列型号以及部分Galaxy A型号存在相似的指纹碰撞问题。PRO模式下的嵌入式原始捕获方式可以避免处理流水线引入的伪像，但这种模式不适用于中端A系列型号，或无原始图像访问权限的法医案例中。
### Innovation
指出了斜向伪像在法医应用方面的潜在价值，包括在HDR图像中减少误检率和在人像模式图像中定位合成景深效果受影响的区域。此外，研究还表明，支持PRO模式和嵌入式原始捕获的设备在源验证中仍可以进行可靠的PRNU验证，而中端A系列和无原始图像访问权限的法医情境例外。
### Conclusion
总结指出，尽管斜向伪像可能影响基于PRNU的相机来源验证，PRO模式下的原始捕获仍可以提供可靠的证据。同时，斜向伪像在某些法医应用中也有潜在作用，如在HDR图像中减少误检率和在人像模式图像中定位合成景深效果受影响的区域。
## 616. `cs.CV` - PhysToolBench: 评估 MLLMs 物理性工具理解能力的标准 [PDF](https://arxiv.org/pdf/2510.09507), [HTML](https://arxiv.org/abs/2510.09507)
### Authors
Zixin Zhang,Kanghao Chen,Xingwang Lin,Lutao Jiang,Xu Zheng,Yuanhuiyi Lyu,Litao Guo,Yinchuan Li,Ying-Cong Chen
### Background
工具的使用、理解和创造是人类智能的关键特征，使人类能够与物理世界进行复杂的互动。任何通用的智能代理要实现真正的灵活性，也必须掌握这些基本技能。尽管现代多模态大型语言模型（MLLMs）利用其广泛的常识在实体AI和下游视觉-语言-行动（VLA）模型中的高层规划，但对于它们对物理工具真正理解的程度尚未进行量化。为了填补这一空白，我们提出了PhysToolBench，这是第一个专门评估MLLMs对物理工具理解能力的基准测试。该基准测试包含超过1000个图像-文本对，分为三个不同的难度级别进行评估：（1）工具识别：需要识别工具的主要功能；（2）工具理解：测试模型抓住工具操作底层原理的能力；（3）工具创造：当常用工具不可用时，挑战模型使用周围物体创造新工具的能力。
### Innovation
PhysToolBench 是第一个专门评估 MLLMs 对物理工具理解能力的基准测试，包含多个难度级别的工具识别、工具理解和工具创造任务。对32种MLLMs进行全面评估发现其在工具理解方面存在显著不足，并提供了详细的分析和初步解决方案。代码和数据集已公开
### Conclusion
PhysToolBench 提供了一个评估 MLLMs 物理性工具理解能力的平台，揭示了目前这些模型在物理工具理解方面的不足，并提出了进一步改善的初步建议。
## 617. `cs.CV` - FLOWING: 用于结构保留变换的隐式神经流 [PDF](https://arxiv.org/pdf/2510.09537), [HTML](https://arxiv.org/abs/2510.09537)
### Authors
Arthur Bizzi,Matias Grynberg,Vitor Matias,Daniel Perazzo,João Paulo Lima,Luiz Velho,Nuno Gonçalves,João Pereira,Guilherme Schardong,Tiago Novello
### Background
形态变化是一个历史悠久的问题，涉及视觉和计算机图形学领域。传统的形态变化方法需要时间依赖的弯曲操作以对齐特征以及平滑插值。近期，多层感知器（MLPs）被探索作为隐式神经表示（INRs）来建模这种变形，由于其无网状结构和可微性，MLPs在一般意义上是适用的。然而，从标准MLPs中提取一致且准确的形态变化通常仍然依赖于昂贵的正则化技术，这经常导致训练不稳定，妨碍有效的特征对齐。
### Innovation
本文提出了FLOWING（FLOW形态变化）框架，通过将变形重新构想为微分向量流的构建，自然而然地确保了连续性、可逆性和时间连续性，直接将结构性流特性编码到网络架构中。这种基于流的方法提供了原理上的稳定转换，能够准确且结构保留地对2D图像和3D形状进行形态变化。广泛的应用实验表明，FLOWING在各种应用中，如面部和图像形态变化，以及Gaussian Splatting形态变化，实现了最先进的形态质量，并且收敛速度快。
### Conclusion
广泛的实验表明，FLOWING在形态质量上达到了最先进的水平，并且收敛速度更快。代码和预训练模型可以在这里获取。
## 618. `cs.CV` - FSP-DETR：少量样本原型检测 [PDF](https://arxiv.org/pdf/2510.09583), [HTML](https://arxiv.org/abs/2510.09583)
### Authors
Shubham Trehan,Udhav Ramachandran,Akash Rao,Ruth Scimeca,Sathyanarayanan N. Aakur
### Background
生物医学领域的检测对象在标注数据稀缺且不断出现新的或罕见类别时受到根本性限制。我们提出了一种名为FSP-DETR的统一检测框架，它能够在一个模型中实现鲁棒的少量样本检测、开放集识别以及适应未见过的生物医学任务的一般化。该框架基于一个类通用的DETR骨干网络，通过构建类原型和使用增强视图及轻量级变压器解码器来学习嵌入空间。通过同时优化原型匹配损失、基于对齐的分离损失以及KL散度正则化，在稀缺的监督下提高特征学习的辨别性和校准性。
### Innovation
我们的框架FSP-DETR在解决这些任务时提供了推理时的灵活性，可以在不重新训练的情况下支持未见过类别的识别、背景拒绝和跨任务适应。我们还引入了包含20种寄生虫类别的新型ova种类检测基准，并制定了标准化评估协议。广泛的实验涵盖了卵子、血液细胞和疟疾检测任务，表明FSP-DETR在少量样本和开放集场景中显著优于先前的少量样本和原型基检测器。
### Conclusion
FSP-DETR显著优于先前的少量样本和原型基检测器，尤其是在少量样本和开放集场景中表现出更出色的性能。此研究提出的框架为未见过类别的生物医学检测提供了有效方法，并为相关领域的进一步研究提供了基准和标准评估协议。
## 619. `cs.CV` - 视觉语言模型：26000篇论文综述 [PDF](https://arxiv.org/pdf/2510.09586), [HTML](https://arxiv.org/abs/2510.09586)
### Authors
Fengming Lin
### Background
本文通过分析自2023年至2025年被CVPR、ICLR和NeurIPS接受的26,104篇论文，提供了一个透明且可重复的研究趋势度量，这些论文的标题和摘要经过归一化、短语保护和与手工制作的词汇表进行对比匹配，以分配多达35个主题标签，并挖掘任务、架构、训练策略、目标、数据集和共提模态的细微线索。研究结果显示了三大宏观转变：多模态视觉语言-大语言模型工作显著增加，将经典感知重新定义为指令跟随和多步推理；生成方法的稳步扩展，扩散研究集中在可控性、蒸馏和速度上；以及3D和视频活动的持续性，组分从NeRF到高斯插值，对人类和代理的理解日益重视。
### Innovation
本文通过使用经过归一化和约束的手工制作词汇表来分配主题标签，并挖掘精细的线索，对视觉语言模型的研究趋势进行了精确测量。此外，它还展示了三大宏观转变，并强调了CVPR、ICLR和NeurIPS在研究方向上的差异。最后，本文还提供了一个可以发布的词汇表和方法论，以供审核和扩展。
### Conclusion
本文量化了三大宏观转变，并展示了CVPR、ICLR和NeurIPS在研究方向上的区别。通过释放词汇表和方法论，促进了进一步的审计和扩展。尽管存在词汇表召回率和摘要范围的局限性，但纵向信号在各个会议和年份之间保持一致。
## 620. `cs.CV` - SpaceVista: 全尺度视觉空间推理从毫米到公里 [PDF](https://arxiv.org/pdf/2510.09606), [HTML](https://arxiv.org/abs/2510.09606)
### Authors
Peiwen Sun,Shiqiang Lang,Dongming Wu,Yi Ding,Kaituo Feng,Huadai Liu,Zhen Ye,Rui Liu,Yun-Hui Liu,Jianan Wang,Xiangyu Yue
### Background
当前，关于空间推理的研究有显著进展，特别是在理解室内场景方面。然而，对于机器人技术与自主驾驶等应用仍面临挑战。现状包括高度依赖室内3D扫描和手工标注，以及缺乏有效的全尺度场景建模，导致模型对单一场景过拟合。因此，如何实现全尺度的空间推理成为亟待解决的问题。
### Innovation
本文提出了一种综合解决方案，整合结构化空间推理知识系统、尺度感知建模和迭代训练框架。首次尝试将全尺度的空间智能扩展到深度学习语言模型上。通过任务特定的专家驱动自动管道，收集了跨越5个尺度的38,000个视频场景，构建了包含约100万个空间问答对和19种不同任务类型的SpaceVista-1M数据集。此外，提出了利用规模作为锚点的尺度感知专家和渐进奖励的SpaceVista-7B模型。
### Conclusion
广泛评估结果显示，该模型在5个基准测试中，包括SpaceVista-Bench，表现出了泛化能力强的特点。同时，本文公开了该数据集、模型和基准测试，促进了全尺度空间推理领域的研究。
## 621. `cs.CV` - 通过动作专家蒸馏高效训练视觉语言模型执行任务 [PDF](https://arxiv.org/pdf/2510.09607), [HTML](https://arxiv.org/abs/2510.09607)
### Authors
Shaoqi Dong,Chaoyou Fu,Haihan Gao,Yi-Fan Zhang,Chi Yan,Chu Wu,Xiaoyu Liu,Yunhang Shen,Jing Huo,Deqiang Jiang,Haoyu Cao,Yang Gao,Xing Sun,Ran He,Caifeng Shan
### Background
视觉语言动作（VLA）模型通过利用预训练视觉语言模型（VLMs）的强大感知能力来显著提高机器人的操作能力。通过将动作模块整合到这些预训练模型中，VLA方法展示了改进的泛化性能。然而，从头开始训练它们是代价高昂的。
### Innovation
本文提出了一种简单而有效的蒸馏框架，通过将预训练的小动作模型的知识转移到VLMs中，赋予VLMs动作执行能力。该框架保留了原始VLM结构，只需添加一个动作令牌和一个状态编码器以整合物理输入。采用两阶段训练策略，首先通过轻量级对齐将VLM隐藏状态映射到小动作模型的动作空间，从而有效重用其预训练动作解码器，避免昂贵的预训练。其次，对语言模型、状态编码器和动作模块进行选择性微调，使系统能够结合多模态输入并精确生成动作。动作令牌为VLM提供了预测未来动作的直接手段，而状态编码器使模型能够捕获仅凭视觉无法捕捉的机器人动力学。
### Conclusion
该设计在从头开始训练大VLA模型方面的效率上取得了显著增长。与之前的先进方法相比，本方法在LIBERO上实现了97.3%的平均成功率（提高了11.8%），在LIBERO-LONG上实现了93.5%的成功率（提高了24.5%）。在五个操作任务的实地实验中，该方法始终优于对照模型，成功率达到82.0%（提高了17%），证明动作蒸馏有效使VLMs能够生成精确动作，同时大幅降低了训练成本。
## 622. `cs.CV` - Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization [PDF](https://arxiv.org/pdf/2510.08618), [HTML](https://arxiv.org/abs/2510.08618)
### Authors
Rui Hu,Delai Qiu,Yining Wang,Shengping Liu,Jitao Sang
### Background
自动语音识别（ASR）系统在处理领域特定术语，尤其是在如学术讲座这类专门场合，常常表现不佳。现有针对幻灯片内容的ASR任务的管道方法复杂且效果不佳。尽管全模态的大语言模型（OLLMs）提供了端到端框架的潜力，但在实践中经常失效，退化为简单的光学字符识别（OCR）系统。
### Innovation
本文提出了一种名为Visually-Anchored Policy Optimization (VAPO)的新颖后训练方法，该方法通过强制执行有序的“思考前转录”程序，优化模型的推理过程。VAPO结合链式思维推理范式，在思考步骤中先进行OCR，然后在回答步骤中通过参考OCR结果来生成转录，优化过程通过强化学习实现，设有四个不同的奖励来针对格式规范性、OCR准确性、ASR质量和视觉锚定一致性。此外，还构建了一个新的实体丰富的基准——SlideASR-Bench，其中包括用于训练和测试的合成数据集和用于评估的具有挑战性的实际数据库。
### Conclusion
大量实验表明，VAPO能显著提高对领域特定术语的识别，建立了SlideASR的有效端到端框架。
## 623. `cs.CV` - 基于GCN自适应背景网格简化生成网格尺寸场 [PDF](https://arxiv.org/pdf/2510.08645), [HTML](https://arxiv.org/abs/2510.08645)
### Authors
Xunyang Zhu,Hongfei Ye,Yifei Wang,Taoran Liu,Jianjun Chen
### Background
定义在三角背景网格上的尺寸场对于控制无结构网格生成的质量和效率至关重要。然而，创建一个几何适应性好、计算成本低且无条带等不良现象的背景网格极具挑战。
### Innovation
提出了一种基于图卷积网络（GCN）的自适应背景网格简化（ABGS）框架。将网格简化任务转化为边得分回归问题，并训练GCN模型以高效预测最优边坍缩候选。模型由综合考虑几何保真度和尺寸场准确性的自定义损失函数引导。这种数据驱动的方法取代了成本高昂的程序化评估，加速了简化过程。
### Conclusion
实验结果表明，该框架适用于各种复杂工程模型并表现出有效性。与初始密集网格相比，简化后的背景网格在元素减少74%-94%的同时，将尺寸场查询时间降低了35%-88%。
## 624. `cs.CV` - StreamingVLM: 实时理解无限视频流 [PDF](https://arxiv.org/pdf/2510.09608), [HTML](https://arxiv.org/abs/2510.09608)
### Authors
Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han
### Background
视觉语言模型（VLMs）能够支持实时助手和自主代理，但它们面临着理解无限视频流的关键挑战，即避免延迟和内存使用量激增。处理整段视频时采用全注意力机制会导致计算成本呈二次增长，并且在处理长段视频时表现不佳。简单滑动窗口方法也有缺陷，要么导致连贯性损失，要么由于冗余重新计算导致高延迟。
### Innovation
本研究提出了StreamingVLM，这是一种专为实时、稳定理解无限视觉输入设计的模型。该模型通过统一框架将训练与流式推理相统一。推理过程中，通过复用注意力瓶的状态、最近的视觉标记短窗口以及最近的文本标记长窗口来维持紧凑的键值缓存。研究者采用一种简单监督微调（SFT）策略，仅对短的重叠视频片段应用全注意力，这种策略有效地模拟了推理时的注意力模式，而无需训练超长上下文。
### Conclusion
在Inf-Streams-Eval基准测试中，Evaluation结果显示StreamingVLM在8 FPS下实现了66.18%的胜率，并保持稳定、实时性能。研究证明，SFT策略也提升了通用VQA能力，无需进行任何VQA特定的微调，在LongVideoBench和OVOBench Realtime上分别提高了4.30%和5.96%。相关代码已在指定链接处提供。
## 625. `cs.CV` - 使用时空隐式神经表示的交错动态X射线CT重建 [PDF](https://arxiv.org/pdf/2510.08641), [HTML](https://arxiv.org/abs/2510.08641)
### Authors
Mathias Boulanger,Ericmoore Jossou
### Background
本文研究了使用时空隐式神经表示（INRs）进行动态X射线计算机断层扫描（XCT）重建的方法，特别是在交错采集方案下的应用。研究了模拟不同采集场景下的重建性能，包括全局欠采样的严重程度、空间复杂度和噪音水平。研究还探讨了如何使重建框架具有实际应用性。
### Innovation
本文提出了一种结合ADMM优化与INCODE（一种包含先验知识的条件框架）的方法，以实现高效的收敛。特别强调了INR的归纳偏置对于中度噪音的鲁棒性，并通过引入加权最小二乘的数据一致性项提高了在更具挑战性的情况下表现。还介绍了直接在重建过程中进行环状伪影校正和批量轴向切片的4D体积重建等创新点。
### Conclusion
本研究在所有场景中展现了较强的表现，超越了当前最先进的基于模型的迭代方法（TIMBIR）。通过引入显式的噪声建模和直接在重建过程中进行环状伪影校正等措施，增加了方法在更具挑战性情况下的适用性。同时，提出了4D体积重建的方法，讨论了对该方法的可能性的进一步改进方向。
## 626. `cs.CV` - 从跨模态到参数化基元的3D生成框架 [PDF](https://arxiv.org/pdf/2510.08656), [HTML](https://arxiv.org/abs/2510.08656)
### Authors
Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan
### Background
近年来，基于AI的3D模型生成技术已经利用了跨模态数据，但这依然存在产生具有平滑表面的模型并减少存储开销的挑战。
### Innovation
本文提出了一种新的多阶段框架，用于生成由参数化基元组成的3D模型，该框架由文本和图像输入引导，提出了一种基于参数化基元的模型生成算法，能够识别模型组成部分的形状特征，并用高质量表面的参数化基元替换元素。同时，设计了一种相应的模型存储方法，确保模型原始表面质量的同时，仅保留参数化基元的参数。
### Conclusion
实验结果表明，本文方法在虚拟场景数据集和现实场景数据集上的效果较好，实现了0.003092的均方差距离、0.545的VIoU、0.9139的F1-Score和0.8369的NC，而且参数文件大小约为6KB。本文方法特别适用于简单的3D模型快速原型设计。
## 627. `cs.CV` - 基于强化学习的边缘管理以实现可靠的多视点3D重建 [PDF](https://arxiv.org/pdf/2510.08839), [HTML](https://arxiv.org/abs/2510.08839)
### Authors
Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy
### Background
实时多视角3D重建是边缘环境中关键应用场景之一，如火灾救援，及时准确的3D场景建模有助于现场态势感知和决策制定。然而，边缘资源的动态和不可预测可用性带来了挑战，如图像质量下降、网络连接不稳定和服务器负载波动等问题，这影响了重建流程的可靠性。
### Innovation
提出了一种基于强化学习（RL）的边缘资源管理框架，旨在在资源受限和易受干扰的环境中实现高质量的3D重建。该框架包含了两个合作性的Q学习代理，分别用于选择相机和服务器，它们完全在线运行，并通过与边缘环境的交互学习策略。
### Conclusion
实验结果显示，提出的框架通过在动态环境中有效平衡端到端延迟和重建质量，提高了应用程序的可靠性。
## 628. `cs.CV` - 统一世界模型：增强记忆规划与展望的视觉导航 [PDF](https://arxiv.org/pdf/2510.08713), [HTML](https://arxiv.org/abs/2510.08713)
### Authors
Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann
### Background
当前最先进的方法采用分离架构将导航规划与视觉世界建模分开，导致状态-动作不一致并限制了在新的或动态场景中的适应性。因此，实现体态代理能够有效地想象未来状态对于稳健和泛化的视觉导航至关重要。
### Innovation
我们提出了UniWM，一个统一的、增强记忆的世界模型，将第一人称视觉预见性和规划整合到一个单一的多模态自回归基础架构中。UniWM通过明确地将行动决策与视觉想象的结果联系起来，确保预测与控制之间的紧密对齐。层级内存机制进一步结合了详细的短期知觉线索和长期轨迹上下文，使在长时间范围内的稳定和连贯推理成为可能。
### Conclusion
广泛的实验证明，UniWM在四个具有挑战性的基准（Stanford Go、ReCon、SCAND、HuRoN）上显著提高了导航成功率，达30%以上，与强大的基线相比大幅度减少了轨迹误差，并在未见过的TartanDrive数据集上展示了令人印象深刻的零样本泛化能力。这突显了UniWM是统一、想象驱动的体态导航的一个原则性步骤。
## 629. `cs.CV` - FreqCa：通过频率感知缓存加速扩散模型 [PDF](https://arxiv.org/pdf/2510.08669), [HTML](https://arxiv.org/abs/2510.08669)
### Authors
Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang
### Background
扩散变换器的应用受到其显著推理成本的困扰。先前的研究提出了特征缓存的方法，通过重用先前时间步的特征，跳过未来时间步的计算。但是，特征缓存假设相邻时间步的特征相似或连续，这一假设在所有场景中未必成立。通过频域分析，本文揭示了不同频率带在特征中的动态表现出差异。具体来说，决定图像结构的低频成分表现出较高的相似性但较差的连续性，而解析图像细节的高频成分表现出较强的连续性但较低的相似性。这些有趣的观察促使我们提出了频率感知缓存(FreqCa)，直接基于相似性重用低频成分的特征，同时使用二阶赫mite插值器基于连续性预测易变的高频成分。此外，本文还提出缓存累积残差特征(CRF)，而非所有层的特征，这将特征缓存的内存占用减少了99%。
### Innovation
提出频率感知缓存（FreqCa）方法，直接基于低频成分的相似性重用特征，使用二阶赫mite插值器基于连续性预测高频成分。此外，还提出缓存累积残差特征（CRF）以减少内存占用。
### Conclusion
在FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, 和 Qwen-Image-Edit上的广泛实验表明，FreqCa在生成和编辑方面均有效。代码已在附录材料中提供，并将在GitHub上发布。
## 630. `cs.CV` - 基于双层元策略控制的证据深度学习动态不确定性校准 [PDF](https://arxiv.org/pdf/2510.08938), [HTML](https://arxiv.org/abs/2510.08938)
### Authors
Zhen Yang,Yansong Ma,Lei Chen
### Background
传统的证据深度学习（EDL）方法依赖于静态超参数进行不确定性校准，这限制了它们在动态数据分布中的适应性，导致在高风险决策任务中的校准和泛化性能较差。
### Innovation
提出了一个元策略控制器（MPC），这是一种动态元学习框架，通过调整Kullback-Leibler散度系数和Dirichlet先验强度来实现最优不确定性建模。MPC采用双层优化方法，内层通过动态配置的损失函数更新模型参数，适应当前训练状态；外层则通过策略网络基于多目标奖励优化Kullback-Leibler散度系数和类特异性Dirichlet先验强度，平衡预测准确性和不确定性质量。
### Conclusion
广泛的实验结果表明，MPC显著提高了模型预测的可靠性和校准度，改进了不确定性校准，预测准确性和基于信心度量后的样本拒绝后的性能保留。
## 631. `cs.CV` - 稀疏分量区分视觉路径及其与神经网络的对齐 [PDF](https://arxiv.org/pdf/2510.08858), [HTML](https://arxiv.org/abs/2510.08858)
### Authors
Ammar I Marvi,Nancy G Kanwisher,Meenakshi Khosla
### Background
以往的研究表明，大脑的背侧、腹侧和侧区视觉皮层负责不同的功能过程。然而，单一任务训练的深层神经网络能够很好地模拟整个视觉系统，这暗示了这些通路之间存在共同的计算原则。本文研究这种不一致之处，通过应用新颖的稀疏分解方法，确定每个通路中的主导视觉表示成分，发现各通路中存在不同的成分响应特征。标准视觉DNNs在与腹侧通路的对齐度上优于背侧和侧通路段落。这种方法通过稀疏组件对齐（SCA）能够提供更高分辨率的对齐测量，更敏感于系统的神经调谐轴。
### Innovation
本文介绍了一种新的方法——稀疏组件对齐（Sparse Component Alignment，SCA），用于测量大脑和机器之间的表示对齐，更好地捕捉这两个视觉系统潜在的神经调谐。研究发现，标准视觉DNNs在与腹侧通路的对齐度上优于背侧和侧通路段落。SCA提供了一种对齐测量手段，能够敏感于系统的内在神经调谐轴，相比之下传统的人群层次几何学方法分辨率较低。
### Conclusion
尽管背侧、腹侧和侧区视觉皮层的功能过程不同，标准的视觉DNNs与腹侧通路的表示对齐度更高。SCA提供了更精确的对齐测量，可以通过神经累积的轴来衡量，超越了传统的人群水平几何学。
## 632. `cs.CV` - 医疗图像预测中公平AI的边界：因果分析视角 [PDF](https://arxiv.org/pdf/2510.08840), [HTML](https://arxiv.org/abs/2510.08840)
### Authors
Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang
### Background
随着机器学习（ML）算法在医学图像分析中的应用日益广泛，公众对这些算法潜在的对某些社会群体的偏见提出了担忧。尽管已经提出了很多确保ML模型公平性的方法，但大多数现有的工作仅集中在医学图像诊断任务上，如图像分类和分割，而忽视了涉及预测医疗条件未来可能发生或进展的预后场景。针对这一空白，我们提出了FairTTE框架，这是首个用于评估医学成像中时间到事件（TTE）预测公平性的框架。FairTTE涵盖了多种医学影像模态和TTE结果，集成最新的TTE预测和公平性算法，以实现系统的、细致的公平性分析。通过因果分析技术，FairTTE揭示并量化了医学影像数据集中嵌入的不同偏见来源。大规模评估表明，偏见普遍存在于不同的医学影像模态中，并且当前的公平性方法提供的减缓效果有限。进一步的分析显示，底层的偏见来源与模型差异之间存在强烈的关联，强调了需要全面的方法来应对所有类型的偏见。值得注意的是，我们发现公平性在数据分布变化时维持得越来越困难，突显了现有解决方案的局限性和构建更稳健、更公平的预后模型的迫切需求。
### Innovation
提出了FairTTE框架，这是首个全面评估医学图像中时间到事件（TTE）预测公平性的框架。它涵盖了多种医学影像模态和TTE结果，并通过因果分析技术揭露并量化了医学影像数据集中嵌入的不同偏见来源。此外，证明了偏见与模型差异之间的关联，并显示了在数据分布变化时维护公平性的挑战性。
### Conclusion
大规模评估显示偏见普遍存在于不同的医学影像模态中，并且当前的公平性方法提供的减缓效果有限。进一步证明了偏见来源与模型差异之间的关联，强调了需要全面的方法来应对所有类型的偏见。值得注意的是，公平性在数据分布变化时维护得越来越困难，突显了构建更稳健、更公平的预后模型的迫切需求。
## 633. `cs.CV` - SAM2-3dMed: 使SAM2适用于3D医学图像分割 [PDF](https://arxiv.org/pdf/2510.08967), [HTML](https://arxiv.org/abs/2510.08967)
### Authors
Yeqing Yang,Le Xu,Lixia Tian
### Background
准确分割3D医学图像对于临床应用如疾病评估和治疗计划至关重要。尽管Segment Anything Model 2 (SAM2)在利用时间线索进行视频对象分割方面表现出色，但其直接应用于3D医学图像面临着两个基本领域的差距：1) 切片之间的双方向解剖连续性与视频中的单方向时间流动形成鲜明对比，2) 精确的边界界定对于形态学分析至关重要，但往往在视频任务中被忽视。
### Innovation
为了弥合这些差距，我们提出了一种适应SAM2用于3D医学成像的SAM2-3dMed框架。我们的框架引入了两个关键创新：1) 切片相对位置预测 (SRPP) 模块通过引导SAM2以自我监督的方式预测不同切片的相对位置，明确建模切片间的双方向依赖关系；2) 边界检测 (BD) 模块提高了沿着关键器官和组织边界的分割准确性。
### Conclusion
在医学分割挑战（MSD）数据集中三个不同的医学数据集（肺部、脾脏和胰腺）上进行的大量实验表明，SAM2-3dMed在分割重叠和边界精度方面显著优于最先进的方法。我们的方法不仅提高了3D医学图像分割的性能，还提供了一种将视频为中心的基础模型适应空间体积数据的一般范式。
## 634. `cs.CV` - GUI代理中自适应连续记忆的自动扩展 [PDF](https://arxiv.org/pdf/2510.09038), [HTML](https://arxiv.org/abs/2510.09038)
### Authors
Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang
### Background
研究如何赋予图形用户界面（GUI）代理可扩展的内存，使其能够跨不熟悉界面和长期任务实现泛化。先前的GUI代理将过去的轨迹压缩为文本标记，这会增加上下文长度并错过关键的视觉线索（例如确切的控件大小和位置）。
### Innovation
提出了一种连续内存，将每个GUI轨迹编码为固定长度的连续嵌入序列，使用VLM本身作为编码器，并直接插入主干网络的输入层，大幅减少上下文成本同时保留细微的视觉信息。引入了一个自适应的数据飞轮来扩展内存，该飞轮包括发现新环境、合成任务、使用代理运行轨迹以及使用同一VLM验证成功，细分为四个步骤。
### Conclusion
在使用这种方法后，收集了超过10万轨迹，仅对记忆编码器进行微调（使用LoRA在Q-Former上，参数占比1.2%），在现实世界的GUI基准测试中，内存增强的代理在长期任务和分布偏移下的一致成功率得到提高。Qwen-2.5-VL-7B + 连续内存的表现与最先进的闭源模型（如GPT-4o和Claude-4）相当。
## 635. `cs.CV` - 渐进不确定性引导的证据U-KAN在可信赖的医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2510.08949), [HTML](https://arxiv.org/abs/2510.08949)
### Authors
Zhen Yang,Yansong Ma,Lei Chen
### Background
医学图像分割旨在为临床决策提供精确可靠的分割结果。现有方法大多采用证据深度学习（EDL）范式，因其计算效率高且理论稳定性强。然而，这些基于EDL的方法往往忽视了通过包含注意力线索的不确定性图来细化不明确边界分割的重要性。因此，需要新的机制来指导模型集中在难以识别的区域的功能表示学习，并同时保留关键的语义信息，以提高医学图像分割的准确性和可靠性。
### Innovation
提出了一种渐进不确定性引导注意力机制（PEUA），该机制通过不确定性图逐步细化注意力，同时使用低秩学习进行注意力权重去噪，增强对于挑战性的区域的功能学习。此外，引入了一种保语义的证据学习策略（SAEL），结合语义平滑的证据生成器和增强保真度的正则化项，以保持关键的语义信息。利用PEUA和SAEL与最先进的U-KAN算法相结合，提出了一种新的证据U-KAN方法，解决可信的医学图像分割问题。
### Conclusion
在4个数据集上进行的广泛实验表明，与竞争方法相比，Evidential U-KAN获得了更好的准确性和可靠性。研究代码已发布在GitHub上。
## 636. `cs.CV` - MMAudioSep: 针对视频/文本查询声音分离的视频到音频生成模型驯化 [PDF](https://arxiv.org/pdf/2510.09065), [HTML](https://arxiv.org/abs/2510.09065)
### Authors
Akira Takahashi,Shusuke Takahashi,Yuki Mitsufuji
### Background
研究领域涉及视频到音频生成模型的已有技术，特别是在声音分离任务中的应用。传统的分离模型通常需要从头开始训练，缺乏利用预训练模型已有知识进行更高效训练的方法。
### Innovation
引入了MMAudioSep模型，基于预训练的视频到音频模型，利用预训练的音频生成模型学到的视频/文本与音频之间的关系知识，使得模型可以通过微调而无需从头训练。该模型不仅在声音分离任务中表现出色，而且在微调后仍然保留了原始的视频到音频生成能力。
### Conclusion
实验结果表明，MMAudioSep模型在声音分离任务中优于现有的基线模型。研究展示了基础声音生成模型在声音相关下游任务中的潜力。源代码可以在提供的链接中找到。
## 637. `cs.CV` - OSCAR: 正交随机控制在流匹配中的对齐尊重多样性 [PDF](https://arxiv.org/pdf/2510.09060), [HTML](https://arxiv.org/abs/2510.09060)
### Authors
Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang
### Background
基于流的文本到图像模型遵循确定性的轨迹，迫使用户反复采样以发现多样化的模式，这是一个昂贵且低效的过程。现有方法需要多次采样以探索不同轨迹，从而增加了生成图像多样性的同时牺牲了处理效率。
### Innovation
提出了一种无需重新训练且可在推理期间使用的控制机制，使得流本身也具备多样性感知能力。该方法通过特征空间目标鼓励轨迹间的横向扩展，并通过时间调度的随机扰动重新引入不确定性。关键在于，这种扰动与生成流正交，这是一种几何约束，能够增加多样性而不影响图像细节或提示忠实度。该方法适用于常见的流匹配求解器，无需对基础采样器进行修改或重新训练。理论证明方法可以单调增加体积代理，在几何约束下大约保持边缘分布。实验证明，在固定采样预算的不同文本到图像设定下，该方法在多样性和质量指标上持续优于较强的基线方法，同时保持了图像质量与对齐。
### Conclusion
通过提出正交随机控制方法，本文解决了基于流的文本到图像模型中多样性探索效率低下的问题，确保了生成的图像质量和对齐要求，同时提升了多样化的生成结果。
## 638. `cs.CV` - FS-RWKV：利用频率空间感知RWKV进行3T到7T MRI转换 [PDF](https://arxiv.org/pdf/2510.08951), [HTML](https://arxiv.org/abs/2510.08951)
### Authors
Yingtie Lei,Zimeng Li,Chi-Man Pun,Yupeng Liu,Xuhang Chen
### Background
7T MRI由于其卓越的空间分辨率和组织对比度，能够检测出神经退行性疾病中的微小病理变化。然而，高昂的基础设施成本和技术需求限制了其在临床中的广泛应用。现有的基于CNN的方法无法提供足够的空间覆盖，而Transformer模型则需要巨大的计算资源。RWKV架构则提供了一种有效的替代方案，能够在医疗图像合成中高效建模全局特征，并且具有线性计算复杂度和强大的长距离依赖捕捉能力。为了解决这些挑战，提出了一个基于RWKV的框架FS-RWKV，用于3T到7T MRI的转换。该框架包含两个关键模块：(1) 频率-空间全域变换（FSO-Shift），通过离散小波分解和低频分支的全域空间变换，提高全局上下文表示能力，同时保留高频率的解剖细节；(2) 结构保真度增强块（SFEB），一种通过频率感知特征融合增强解剖结构的模块。
### Innovation
提出的FS-RWKV框架结合了RWKV模型的优势，通过FSO-Shift和SFEB模块，既提升了全局上下文表示能力，又保持了高分辨率的解剖细节。该框架在UNC和BNU数据集上的实验证明了其在T1w和T2w模态下比现有的基于CNN、Transformer、GAN和RWKV的方法都更优秀，展现了卓越的解剖学保真度和感知质量。
### Conclusion
综上所述，FS-RWKV提供了一种有效的方法来将3T MRI图像转换为7T MRI的质量，这不仅可以促进7T MRI技术在临床中的普及，还为医学图像处理研究提供了新的思路。
## 639. `cs.CV` - 通过物理对象针对视觉-语言-动作模型的具有目标导向的后门攻击 [PDF](https://arxiv.org/pdf/2510.09269), [HTML](https://arxiv.org/abs/2510.09269)
### Authors
Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang
### Background
最近，视觉-语言-动作（VLA）模型在增强身体型AI方面取得了显著进步，使得机器人能够遵循自然语言指令并完成各种任务。然而，这些模型依赖于未经过筛选的数据集，这引发了严重的安全问题。现有的对VLA的后门攻击大多数假设了白盒访问，并导致任务失败而不是执行特定动作。
### Innovation
本文揭示了一种更为实际的威胁：攻击者只需在训练数据集中注入物理对象作为触发器，VLA就能被操控。提出的具有目标导向的后门攻击（GoBA）在没有物理触发器时表现正常，但在存在物理触发器时执行预定义的目标导向动作。基于流行的VLA基准LIBERO，引入了BadLIBERO，包含了多种物理触发器和目标导向的后门动作。此外，提出了三级评估方法来分类GoBA下受害VLA的行为状态。
### Conclusion
实验表明，当物理触发器存在时，GoBA可以使受害VLA成功实现后门目标的比例达到97%，而对未受污染的输入没有任何性能下降。通过研究与GoBA相关的影响因素，发现动作轨迹和触发器颜色对攻击性能有显著影响，而触发器大小出乎意料地影响较小。项目页面提供了代码和BadLIBERO数据集的访问链接。
## 640. `cs.CV` - 重连发育：利用成人脑部先验提高婴儿MRI分割 [PDF](https://arxiv.org/pdf/2510.09306), [HTML](https://arxiv.org/abs/2510.09306)
### Authors
Alemu Sisay Nigru,Michele Svanera,Austin Dibble,Connor Dalby,Mattia Savardi,Sergio Benini
### Background
婴儿脑MRI的准确分割对于研究早期神经发育和诊断神经疾病至关重要。但由于样本解剖结构的持续演变、运动伪影以及高质量标注数据的稀缺性，这一任务仍然是一个基本挑战。
### Innovation
本文提出了LODi，一种新颖的框架，利用成人脑MRI分割模型的先验知识来增强婴儿扫描的分割性能。该方法通过预训练成人MRI数据集并采用迁移学习和领域适应策略，使模型能够渐进地适应0-2岁儿童人群，克服了婴儿扫描中的形态学和成像变化。通过引入一种新的训练策略，该方法集成了层级特征精炼和多级一致性约束，使得分割快速、准确且年龄适应性好，同时降低了扫描器和站点特异性偏差。
### Conclusion
在内部和外部数据集上进行的实验表明，本文的方法比传统的监督学习和领域特定模型更有优势。研究发现强调了利用成人脑部先验作为全生命周期年龄灵活神经成像分析的基础的重要性，为脑MRI分割的可靠性与泛化性开辟了新途径。
## 641. `cs.CV` - 一种基于生物物理条件的3D脑肿瘤MRI生成框架 [PDF](https://arxiv.org/pdf/2510.09365), [HTML](https://arxiv.org/abs/2510.09365)
### Authors
Valentin Biller,Lucas Zimmer,Can Erdur,Sandeep Nagar,Daniel Rückert,Niklas Bubeck,Jonas Weidner
### Background
磁共振成像（MRI）补全支持众多临床和研究应用。然而，当前的方法大多依赖于定点的数据处理和缺乏在其生成过程中利用连续的肿瘤浓度信息来进行高保真脑肿瘤MRI的合成。
### Innovation
本文引入了首个基于体素水平连续肿瘤浓度的生成模型，用于合成高保真度脑肿瘤MRI图像。我们调整了该架构以用于健康的组织恢复任务，通过将肿瘤浓度设为零。模型基于组织分割和肿瘤浓度在生成3D空间一致且解剖上一致的图像上的应用，既包括肿瘤像素的合成，也包括健康组织的补全。
### Conclusion
对于健康组织补全任务，我们实现的峰值信噪比（PSNR）为18.5；对于肿瘤补全任务，PSNR为17.4。代码已公开。
## 642. `cs.CV` - 高效的噪声成对比较的贝叶斯推断 [PDF](https://arxiv.org/pdf/2510.09333), [HTML](https://arxiv.org/abs/2510.09333)
### Authors
Till Aczel,Lucas Theis,Wattenhofer Roger
### Background
评价生成模型具有挑战性，因为标准指标经常无法反映人类偏好。虽然人工评估更可靠，但成本高且存在噪音，因为参与者在专业知识、注意力和勤勉程度方面存在差异。成对标记可以提高一致性，但在将这些标记汇总为整体质量评分时需要仔细建模。基于Bradley-Terry的方法通过比较更新项目得分，但现有方法要么忽略评分者的变量性，要么缺乏收敛保证，这限制了鲁棒性和可解释性。
### Innovation
我们提出了一种名为BBQ的贝叶斯Bradley-Terry变体，该方法明确建模评分者质量，降低或移除不可靠参与者，并通过期望最大化算法提供有保证的单调似然收敛。实验结果表明，BBQ相较于基线Bradley-Terry模型具有更快的收敛速度、更精确的不确定性估计以及更稳健、可解释的排名，即使使用嘈杂或众包评分者也能实现。
### Conclusion
该框架使生成模型的人类评估更加可靠且成本效益更高。
## 643. `cs.CV` - 识别并交互式细化模糊用户目标以提高数据可视化代码生成准确度 [PDF](https://arxiv.org/pdf/2510.09390), [HTML](https://arxiv.org/abs/2510.09390)
### Authors
Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani
### Background
在人类与人工智能交流中，确立共同目标是一个关键步骤。然而，模糊性会导致看似正确但未能反映说话人意图的结果。本文聚焦于数据可视化领域，研究自然语言中的模糊性如何影响代码生成。通过Matplotlib问题，文章揭示了不同类型的模糊性，并提出新的度量标准，这些度量标准比不确定性基准更好地与人工注释相关联。此外，讨论了多轮对话如何减少模糊性，提高代码准确性，以更好地匹配用户的意图目标。
### Innovation
本文开发了一种模糊类型的分类学，并提出了量化这些模糊性的新方法。所使用的数据集是DS-1000。此外，通过Gricean合作性、话语表征理论和讨论中的问题三种实用模型，制定了对话策略，证明了通过多轮对话可以减少模糊性并提高代码准确性，强调了多轮交流在代码生成中的价值。
### Conclusion
研究表明，我们的模糊性度量标准比不确定性基线更好地与人工注释相关联，证实了通过多轮对话设计的对话策略可以减少模糊性并提高代码准确性。
## 644. `cs.CV` - Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning [PDF](https://arxiv.org/pdf/2403.19979), [HTML](https://arxiv.org/abs/2403.19979)
### Authors
Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang
### Background
连续学习（Continual Learning）旨在使模型能够在学习新类别时克服灾难性遗忘。预训练模型的引入为连续学习引入了新的调参范式。在此背景下，本文回顾了不同参数高效调参（Parameter-efficient Tuning, PET）方法在连续学习中的应用。
### Innovation
本文提出了增量调参共享适配器的方法，无需对参数进行更新约束，增强了主干模型的学习能力。同时，通过从存储的原型中采样特征来重新训练统一分类器，进一步提高其性能。该方法能够估计旧原型的语义偏移，无需访问过去样本，并且每会话更新存储的原型，从而避免了模型膨胀和保留任何图像样本。实验结果表明，该方法超越了基于预训练模型的连续学习方法，展示了卓越的连续学习能力。
### Conclusion
我们的方法在五个连续学习基准数据集上的实验结果验证了其有效性，达到了当前最佳性能（State-of-the-Art, SOTA）。
## 645. `cs.CV` - 基于FFT的统计选择与优化在严重受损图像鲁棒识别中的应用 [PDF](https://arxiv.org/pdf/2403.14335), [HTML](https://arxiv.org/abs/2403.14335)
### Authors
Elena Camuffo,Umberto Michieli,Jijoong Moon,Daehyun Kim,Mete Ozay
### Background
在智能设备如机器人代理上实现稳健的视觉系统的一个关键挑战是对受到损坏的图像进行建模稳健性改进。尤其是，测试时的鲁棒性能对大多数应用来说尤为重要。
### Innovation
该论文提出了一种新颖的方法（FROST），利用高频特征来检测输入图像的损坏类型，并选择逐层特征归一化统计信息，从而提高任何分类模型的鲁棒性，尤其是在严重受损图像上。FROST方法在不同模型和数据集上提供了最先进的结果，在ImageNet-C上优于竞争对手，相对提升高达37.1%，并在严重损坏情况下将基线的mCE提高到40.9%。
### Conclusion
FROST方法在处理严重损坏图像的鲁棒识别方面表现出优越性，通过使用高频率特征和逐层特征归一化统计信息，提升了模型对于受到损坏图片的识别能力，取得了最先进的性能。
## 646. `cs.CV` - 通过排名和LLM融合提高图像描述的丰富性 [PDF](https://arxiv.org/pdf/2306.11593), [HTML](https://arxiv.org/abs/2306.11593)
### Authors
Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano
### Background
当前最先进的图像字幕模型多在MS-COCO数据集上进行训练，该数据集的字幕由人类注释，平均长度约为十个token。虽然这些模型对于通用场景理解非常有效，但简短的字幕往往难以捕捉复杂的场景细节，且倾向于偏向“平均”字幕，仅捕捉较通用的信息，从而忽略了详细的细节。
### Innovation
本文提出了一种新的方法，通过结合来自不同SoTA字幕模型生成的不同字幕来生成更丰富、更详细的信息字幕。该方法不需要额外的模型训练：首先利用预训练的模型生成初始字幕，然后使用新引入的基于图像-文本的BLIPScore评估指标对这些字幕进行排名，最后使用大型语言模型融合排名靠前的字幕，生成最终描述。实验结果显示，该方法在MS-COCO和Flickr30k测试集上的字幕和图像对齐度和幻觉减少方面具有优越性，且主观研究也进一步证实了这些结果。
### Conclusion
通过融合不同SoTA模型的字幕，本文的方法提升了图像字幕的质量和吸引力，缩小了自动系统与人类生成描述的丰富性之间的差距。这一进展使得生成更适合训练视觉-语言模型和字幕模型的字幕成为可能。
## 647. `cs.CV` - STaTS：通过统计窗口合并实现结构感知的时间序列总结 [PDF](https://arxiv.org/pdf/2510.09593), [HTML](https://arxiv.org/abs/2510.09593)
### Authors
Disharee Bhowmick,Ranjith Ramanathan,Sathyanarayanan N. Aakur
### Background
时间序列数据通常包含潜在的时间结构、局部平稳区域之间的转换、重复的动机和变异性的爆发，这些元素很少被标准的表示学习流水线利用。现有的模型通常在原始或固定窗口序列上运行，所有时间步骤都被认为是同等重要的信息源，这导致在长或嘈杂的序列中出现效率低下、鲁棒性差和扩展性不足的问题。
### Innovation
我们提出了STaTS，一个轻量级的无监督框架，用于结构感知的时间序列摘要，它可以自适应地压缩单变量和多变量时间序列，生成紧凑且信息保留的标记序列。STaTS使用基于BIC的统计差异准则检测多个时间分辨率下的变化点，然后使用简单的函数（如均值）或生成模型（如GMM）来总结每个片段。这个过程可以在不影响核心时序动态的情况下，将序列压缩高达30倍。该框架具有模型通用的预处理能力和不依赖于重新训练地与现有的无监督时间序列编码器集成。在150多个数据集上进行的广泛实验表明，STaTS在保持模型90%的性能的同时，显著减少了计算成本，并且在噪声下提高了鲁棒性，保持了判别结构，超越了均匀和基于聚类的压缩基准。
### Conclusion
STaTS作为一个基于原理的一般解决方案，适用于高效、面向结构的时间序列建模。
## 648. `cs.CV` - Dyna-Mind：从经验中学习模拟以提高AI代理 [PDF](https://arxiv.org/pdf/2510.09577), [HTML](https://arxiv.org/abs/2510.09577)
### Authors
Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao
### Background
近年来，推理模型在数学和编程等领域取得了显著进步。然而，这些模型在数学和编程领域的专家级能力与在长周期、交互式任务（如网络导航和计算机/手机使用）中的表现形成鲜明对比。借鉴人类认知的研究，作者认为当前的AI代理需要‘代理性的尝试与错误’——能够预先在行动之前在思维中模拟多种未来情景的能力，以增强其在复杂交互环境中的理解和性能。因此，作者提出了Dyna-Mind框架，这是一种两阶段的训练框架，旨在教（V）LM代理如何整合这种模拟到其推理中。第一阶段引入了通过强化从实际环境互动中收集的实际经历构建扩展搜索树生成结构化推理轨迹的‘模拟推理’(ReSim)。第二阶段提出了Dyna-GRPO，一种在线强化学习方法，通过使用结果奖励和中间状态作为来自实际演练的反馈来进一步强化代理的模拟和决策能力。
### Innovation
该研究创新性地提出了Dyna-Mind框架，这是一种两阶段的训练框架，致力于通过ReSim和Dyna-GRPO来增强AI代理的推理、计划和决策能力。ReSim通过从实际交互经验生成的拓展搜索树训练代理生成结构化的推理轨迹。而Dyna-GRPO则是一种在线强化学习方法，利用结果奖励和中间状态学习长期任务中的更好政策，从而实现更有效的推理与决策。
### Conclusion
实验证明了Dyna-Mind框架的有效性，即ReSim有效地将模拟能力注入AI代理中，同时Dyna-GRPO利用结果和交互级别的信号学习长期任务中的更好策略。这些结果强调了模拟在使AI代理能够更有效地推理、计划和采取相应行动方面的核心作用。
## 649. `cs.CV` - UltraSeP：基于序列感知的超声心动图探头移动预训练 [PDF](https://arxiv.org/pdf/2408.15026), [HTML](https://arxiv.org/abs/2408.15026)
### Authors
Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang
### Background
超声心动图是一种诊断心血管疾病的重要医疗技术，但由于操作复杂性高，导致专业人员短缺。心脏的内在复杂结构和个体间的显著差异是超声心动图面临的主要挑战。以往的研究主要集中于学习心腔的平均结构，而忽视了个性化心脏结构的学习，这限制了其性能。临床观察表明，超声检查者会根据先前的扫描序列动态调整对患者心脏解剖结构的解释，从而优化扫描策略。
### Innovation
本文提出了一种基于序列感知的自监督预训练方法（UltraSeP）。该方法通过预测扫描序列中被隐藏的图像特征和探头动作，学习个性化的三维心脏结构特征。作者假设如果模型能够预测缺失的内容，说明它已经很好地理解了个性化的心脏结构。实验结果表明，提出的序列感知方法可以有效减少探头指导错误，相比于其他先进的基线方法。
### Conclusion
本文提出的UltraSeP方法，通过自监督预训练学习个性化的三维心脏结构特征，能够有效减少超声心动图探头引导误差，为解决心脏超声操作复杂性问题提供了一种新的解决方案。
## 650. `cs.CV` - 基于变形注意力Transformer的扩散机制RGB-D语义分割 [PDF](https://arxiv.org/pdf/2409.15117), [HTML](https://arxiv.org/abs/2409.15117)
### Authors
Minh Bui,Kostas Alexis
### Background
视觉感知和推理对于任何自主系统中的场景理解至关重要。常用的RGB和深度图像能够捕捉环境的语义和几何特征。在现实世界应用中，可靠地解释这些数据是至关重要的，因为噪声测量是不可避免的。本文提出了一个基于扩散机制的框架来解决RGB-D语义分割问题。此外，研究表明使用变形注意力Transformer作为编码器可以有效地从深度图像中提取特征，并捕捉深度测量中的无效区域特性。
### Innovation
本研究提出了一种基于扩散机制的框架，利用变形注意力Transformer从深度图像中提取特征，能够有效捕捉深度测量中的无效区域特性。该生成框架能够更好地建模RGB-D图像的潜在分布，相比判别模型在更具挑战性的场景中展现出更强的鲁棒性能，并且显著减少了训练时间。
### Conclusion
实验结果表明，本文提出的方法在NYUv2和SUN-RGBD数据集上取得了最先进的性能，特别是在最具挑战性的图像数据上。本项目页面将在此 <this https URL> 获得。
## 651. `cs.CV` - 针对医学图像分析的Mamba架构全面综述：分类、分割、修复及相关应用 [PDF](https://arxiv.org/pdf/2410.02362), [HTML](https://arxiv.org/abs/2410.02362)
### Authors
Shubhi Bansal,Sreeharish A,Madhava Prasath J,Manikandan S,Sreekanth Madisetty,Mohammad Zia Ur Rehman,Chandravardhan Singh Raghaw,Gaurav Duggal,Nagendra Kumar
### Background
Mamba作为一种特殊的基于状态空间模型，作为一种替代模板深度学习方法在医学图像分析中的选择正在变得流行。虽然变压器架构强大，但它们具有计算复杂性呈二次函数增长及处理长期依赖性不高效的缺点，这对分析大型复杂的医学图像数据集造成了影响。相比之下，Mamba因其线性时间复杂性、处理长序列的能力以及在处理多模态数据时的高性能，使其更适合医学图像分析。
### Innovation
Mamba架构具有以下创新点：（1）线性时间复杂性相较于变压器的二次时间复杂性，显著提高了处理效率；（2）无需注意力机制即可处理长序列，提高了推理速度并减少了内存需求；（3）在多模态数据集成方面的强大表现提升了诊断精度和患者结果。该综述文章通过逐步介绍核心概念与架构，展示了Mamba在医学成像领域的强大潜力。
### Conclusion
本文综述了Mamba架构在医学图像分析中的应用，覆盖了从概念、架构设计、优化技术、应用场景到实验结果和未来方向的全面分析。Mamba具有克服现有医学成像障碍的潜力，为该领域带来了创新的进步。遵循本文提供的Mamba架构清单可以在GitHub上找到。
## 652. `cs.CV` - Gaussian Scenes: 使用深度增强扩散先验的无姿态稀疏视角场景重建 [PDF](https://arxiv.org/pdf/2411.15966), [HTML](https://arxiv.org/abs/2411.15966)
### Authors
Soumava Paul,Prakhar Kaushik,Alan Yuille
### Background
在现有研究中，无姿态（无需相机参数）的360度场景重建通常需要深度估计或三维基础先验进行正则化。虽然最近的技术已经能够利用视差条件生成先验对具有大量前景和背景细节的大规模复杂场景进行稀疏视图重建，但这些方法在没有地面真实姿态的情况下不能直接适应无姿态设置。本文旨在解决这个问题。
### Innovation
本文提出了一种图像到图像的生成模型，该模型可以在新视角渲染和3D场景的深度图中填补缺失细节并去除伪影。为了轻量级实现上下文和几何条件，引入了特征线性调制（FiLM）调制层作为交叉注意力的替代方案。还提出了一种新的3D高斯点云表示置信度度量方法，以更好地检测这些伪影。通过借鉴Gaussian-SLAM的过程逐步整合这些新视图，实现了多视角一致的3D表示。在MipNeRF360和DL3DV-10K基准数据集上的评估显示，本文的方法超越了现有的无姿态技术，并且在复杂360度场景中与具有预计算相机参数的最新姿态方法表现竞争。
### Conclusion
本研究通过深度增强扩散先验，提出了一种用于无姿态稀疏视角场景重建的图像到图像生成模型。在不同场景上的实验证明，该方法在复杂场景中性能优越。
## 653. `cs.CV` - 生成任意场景：基于场景图的数据合成在视觉生成训练中的应用 [PDF](https://arxiv.org/pdf/2412.08221), [HTML](https://arxiv.org/abs/2412.08221)
### Authors
Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna
### Background
文本到视觉生成技术在图像保真度方面取得了显著进展，但在构成泛化和语义对齐方面仍存在挑战。现有的数据集存在噪声和成分较弱的问题，限制了模型对复杂场景的理解，而对密集高质量注释的可扩展解决方案仍面临挑战。
### Innovation
本文介绍了‘生成任意场景’（Generate Any Scene）数据引擎，该引擎通过系统地列出场景图来表示可能的视觉场景的组合阵列。该引擎能从对象、属性和关系的结构化分类目录中动态构建不同复杂度的场景图，并将其翻译成文本到图像或文本到视频生成的说明，以及用于自动评估和语义对齐奖励建模的视觉问题答案。文章通过自改进框架和知识蒸馏算法显著提高了模型性能，并通过低成本的奖励模型优化生成模型的语义准确性。最后将这些方法应用到内容审核下游任务中，通过学习合成数据来培训模型识别具有挑战性的案例。
### Conclusion
通过Generate Any Scene，模型在Compositional和Hard概念生成上的TIFA分数提高了10%，并能够在下游内容审核任务中_training_模型以识别具有挑战性的案例。
## 654. `cs.CV` - 平衡数据集中偏见放大的方向性和可解释性 [PDF](https://arxiv.org/pdf/2412.11060), [HTML](https://arxiv.org/abs/2412.11060)
### Authors
Bhanu Tokas,Rahul Nair,Hannah Kerner
### Background
目前大多数机器学习数据集都存在偏见，这会导致训练出的模型不仅学习了数据集的偏见，还可能放大这些偏见。评估偏见放大的常用方法依赖于共现度量，但它们无法对平衡数据集中的偏见进行准确测量。最近提出了一种基于预测性的度量方法——泄漏放大，它可以用于平衡数据集，但缺乏明确的方向性。因此，本文旨在提出一种新的基于预测性的度量方法——定向可预测性放大 (DPA)，以实现偏见放大的方向性和可解释性，特别是在平衡数据集中。
### Innovation
本文提出了一种新的基于预测性的度量方法——定向可预测性放大 (DPA)，用于测量平衡数据集中的偏见放大的方向性。与现有方法不同，DPA 不仅适用于平衡数据集，还更易于解释，并且对攻击者模型更加鲁棒。实验证明，DPA 是一种有效的方向性偏见放大测量方法。
### Conclusion
本文通过提出 DPA 方法，解决了平衡数据集中偏见放大的方向性和可解释性问题。DPA 在实验中展示了其有效性和在方向性偏见放大测量方面的优势。同时，该方法将增强我们对机器学习模型公平性理解的能力。
## 655. `cs.CV` - RAGDiffusion: 通过外部知识融合实现可靠的衣着生成 [PDF](https://arxiv.org/pdf/2411.19528), [HTML](https://arxiv.org/abs/2411.19528)
### Authors
Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni
### Background
标准的服装资产生成涉及从复杂背景中恢复面向前方的平铺服装图片，这带来了显著的挑战，因为结构样本分布高度标准化，且在复杂场景中缺乏服装语义信息。现有模型在这一高规格生成任务中具有有限的空间感知能力，经常出现结构幻觉和纹理失真。
### Innovation
我们提出了一种名为RAGDiffusion的新颖检索增强生成（RAG）框架，通过融合语言模型和外部数据库的知识来增强结构确定性并减轻幻觉。RAGDiffusion包含两个过程：（1）基于检索的结构聚合，通过对比学习和结构局部线性嵌入（SLLE）推导全局结构和空间地标，提供软硬指导以对抗结构上的不确定性；（2）全方位真实的服装生成，引入了从粗到细的纹理对齐，确保图案和细节组件的准确度。
### Conclusion
在具有挑战性的现实世界数据集上的广泛实验表明，RAGDiffusion能够合成结构和纹理可靠的服装资产，性能显著提升，在RAG的帮助下，有效应对了内在幻觉并提升了真实性。
## 656. `cs.CV` - SkipClick: 结合快速响应和低级特征的冬季运动场景交互分割 [PDF](https://arxiv.org/pdf/2501.07960), [HTML](https://arxiv.org/abs/2501.07960)
### Authors
Robin Schön,Julian Lorenz,Daniel Kienzle,Rainer Lienhart
### Background
交互分割领域致力于通过用户的引导信息（如点击提示）来预测高质量的分割掩模，而传统的交互分割算法通常能够在每次用户点击后迅速响应。本研究基于冬季运动场景中的交互分割，通过一个特定的基线架构和一系列改进的架构设计，旨在提高分割冬季运动装备的性能，并验证其在不同数据集上的效果，取得了优于现有SAM和HQ-SAM模型的结果。此外，该模型还应用于一个新的包含滑雪中人体掩模的数据集上，展示了其在高精度分割上的优越性。
### Innovation
该研究提出了一种新颖的交互分割架构——SkipClick，其主要创新点在于结合了快速响应机制和低级特征，特别针对冬季运动场景中交互分割任务进行了优化，提升了分割冬季运动装备的质量，特别是在WSESeg数据集上表现突出，与SAM和HQ-SAM相比分别节省了2.336和7.946次点击。
### Conclusion
该研究在WSESeg数据集上的实验结果表明，SkipClick在NoC@85指标上优于SAM和HQ-SAM，节省了多次点击。应用到HQSeg-44k数据集上，SkipClick同样取得了最优的结果，NoC@90和NoC@95分别达到了6.00和9.89，同时验证了其在包含滑雪中人体掩模的新数据集上的有效性。
## 657. `cs.CV` - RadVLM: 一种用于放射学的多任务对话视觉语言模型 [PDF](https://arxiv.org/pdf/2502.03333), [HTML](https://arxiv.org/abs/2502.03333)
### Authors
Nicolas Deperrois,Hidetoshi Matsuo,Samuel Ruipérez-Campillo,Moritz Vandenhirtz,Sonia Laguna,Alain Ryser,Koji Fujimoto,Mizuho Nishio,Thomas M. Sutter,Julia E. Vogt,Jonas Kluckert,Thomas Frauenfelder,Christian Blüthgen,Farhad Nooralahzadeh,Michael Krauthammer
### Background
由于胸部X光片（CXR）的广泛应用与放射科医生短缺的问题，促使了对自动化CXR分析和AI辅助报告的兴趣增加。现有的视觉-语言模型（VLMs）在如报告生成或异常检测这样的特定任务上表现出潜力，但往往缺乏交互诊断的支持。因此，研究者们致力于开发能够进行多任务对话的模型来解决这一问题。
### Innovation
本文提出了RadVLM，这是一种专门设计用于胸部X光片解释的紧凑型、多任务对话基础模型。研究人员构建了一个包含超过100万张图像-指令对的大规模数据集，该数据集覆盖了一次任务（如报告生成、异常分类和视觉着地）和多次任务的对话交互。经过对这个指令数据集的微调后，评估结果表明，RadVLM在对话能力和视觉着地上取得了最先进的性能，同时在其他放射学任务上仍保持了竞争力。此外，消融实验进一步显示出跨多个任务联合训练的益处，尤其是在标注数据有限的情况下。
### Conclusion
研究结果表明，RadVLM作为一种临床相关的AI助手，具有提供结构化的胸部X光片解释和对话功能的潜力，从而支持更高效和更有可及性的诊断工作流程。
## 658. `cs.CV` - RobustMerge: 参数稳定模型合并以增强MLLMs [PDF](https://arxiv.org/pdf/2502.17159), [HTML](https://arxiv.org/abs/2502.17159)
### Authors
Fanhu Zeng,Haiyang Guo,Fei Zhu,Li Shen,Hao Tang
### Background
通过使用定制数据调整预训练模型可生成专门针对特定任务的多个专家模型。合并模型为一个通用模型以增强多任务能力并避免数据泄露变得流行。随着数据和模型规模的扩大，参数效率调整成为高效获取任务特定模型的普遍做法。然而，很少有方法专注于高效合并，现有方法旨在进行完整的调整合并，在高效合并下表现不佳。
### Innovation
本文分析了低秩分解并揭示了合并阶段的方向稳定对于高效模块的合并至关重要，还发现补偿显著奇异值之间的差距有助于增强方向稳定性。因此，提出了一种名为RobustMerge的训练无要求的、参数高效合并方法，结合参数互补调整以保持方向稳定性。具体来说，通过（1）从参数之间的关系中剪枝参数并缩放系数以保持远离任务干扰的方向稳定性；（2）执行跨任务归一化以增强对未见过任务的泛化。
### Conclusion
在包含多种模态任务的基准测试集上进行了实验，证明了该方法的卓越性能和泛化能力。进一步的研究和详细分析还展示了其有效性。相关代码已开源。
## 659. `cs.CV` - SQ-GAN: 使用掩码矢量量化实现语义图像通信 [PDF](https://arxiv.org/pdf/2502.09520), [HTML](https://arxiv.org/abs/2502.09520)
### Authors
Francesco Pezone,Sergio Barbarossa,Giuseppe Caire
### Background
该研究旨在优化适合语义或特定任务导向的图像压缩方式，通过结合语义驱动的图像编码和矢量量化技术改进传统的图像压缩方法。现有的图像压缩方案如JPEG2000和BPG，以及基于深度学习的方法，在压缩率极低的情况下，往往在感知质量或语义分割准确性上表现不佳。
### Innovation
论文提出了一种名为Semantically Masked Vector Quantized Generative Adversarial Network (SQ-GAN)的新方法。SQ-GAN 方法使用现成的软件计算图像的语义分割图，并开发了一个新的语义条件自适应掩码模块（SAMM）来有选择地编码图像中的语义相关特征。不同语义类别的相关性是任务特定的，并在训练过程中通过引入适当的权重来反映这种相关性。SQ-GAN 方法优于现有的图像压缩方案，包括在感知质量和重建图像的语义分割准确性方面，在极低的压缩率下表现更佳。
### Conclusion
实验结果表明，SQ-GAN 方法在多种评价指标下优于现有的图像压缩方案（如JPEG2000、BPG以及深度学习方法），特别是在极低压缩率的情况下，能够显著提高感知质量和语义分割准确性。SQ-GAN 的优势在于它可以仅对源编码进行操作，从而与现有的系统完全兼容。
## 660. `cs.CV` - 自我监督对比学习在多模态图文分析中的综述 [PDF](https://arxiv.org/pdf/2503.11101), [HTML](https://arxiv.org/abs/2503.11101)
### Authors
Asifullah Khan,Laiba Asmatullah,Anza Malik,Shahzaib Khan,Hamna Asif
### Background
自我监督学习是一种通过从未标记数据中学习潜在模式和提取判别特征来生成隐式标签的机器学习方法，无需人工标注。对比学习引入了“正样本”和“负样本”的概念，正样本（如同一图像/对象的不同变体）被拉近嵌入空间，负样本（如不同图像/对象的不同视图）则被推远。这种方法在无需大量依赖标记数据的情况下，显著提高了图像理解与图像文本分析的效果。本文全面讨论了对比学习在图文模型中的术语、最近进展与应用。
### Innovation
本文提供了近年来对比学习在图文模型中应用的概述，并基于不同的模型结构进行了分类。进一步介绍了和讨论了在该过程中使用的最新技术，如图像和文本的预训练任务、架构结构以及关键趋势。
### Conclusion
本文最后探讨了基于自我监督对比学习的图文模型的最新应用成果。
## 661. `cs.CV` - 使用可预测性衡量图像标题中的方向性偏差放大 [PDF](https://arxiv.org/pdf/2503.07878), [HTML](https://arxiv.org/abs/2503.07878)
### Authors
Rahul Nair,Bhanu Tokas,Hannah Kerner
### Background
在用有偏差的机器学习数据集训练模型时，模型不仅学习这些偏差，还可能在测试时放大这些偏差，这种现象称为偏差放大。尽管目前有许多基于共现的方法可以用来测量偏差放大，这些方法在简单的图像分类问题上有效，但在复杂的图像字幕问题上则无效，因为它们无法捕捉到字幕的语义信息。为了解决这个问题，之前的工作引入了一个基于可预测性的度量——称为字幕泄露（LIC）的方法。然而，LIC 方法在标识偏差放大的方向、对词汇替换策略较弱且对攻击模型高度敏感方面存在局限性。为了克服这些问题，本文提出了方向性可预测性放大（DPAC）的方法，主要用于在字幕中测量偏差的放大方向，并通过改进的替换策略更好地估计数据集偏差，同时对攻击模型的影响较小。实验结果表明，DPAC 是衡量字幕偏差放大的最可靠指标。
### Innovation
提出了一种新的度量方法——方向性可预测性放大（DPAC），它能够捕捉并测量字幕中的偏差放大方向，并通过改进的词汇替换策略更好地估计数据集偏差，同时减少了对攻击模型的敏感度。这种方法在复杂问题如图像字幕上比现有方法更有效。
### Conclusion
方向性可预测性放大（DPAC）是一种更可靠的方法，用于衡量图像字幕中的偏差放大。与以前的方法相比，DPAC方法能够更准确地估计偏差，并具有更好的稳健性。实验结果表明，在COCO数据集上的表现证明了该方法的有效性。
## 662. `cs.CV` - CQ-DINO：通过类别查询缓解梯度稀释效应以应对大型词汇量目标检测 [PDF](https://arxiv.org/pdf/2503.18430), [HTML](https://arxiv.org/abs/2503.18430)
### Authors
Zhichao Sun,Huazhang Hu,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu
### Background
随着数据呈指数增长，传统的对象检测方法在处理大规模词汇量对象检测任务时变得越来越难以有效地应对。我们分析了基于分类的目标检测器的两个关键限制：正梯度稀释问题，即稀有正类别会收到不充分的学习信号；以及难以梯度稀释问题，其中区分性梯度被大量简单负类别所掩盖。为解决这些挑战，我们提出了CQ-DINO，一种基于类别查询的对象检测框架，将分类任务重新定义为对象查询与可学习类别查询之间的对比任务。
### Innovation
CQ-DINO采用了图像引导的查询选择方法，通过交叉注意力机制从每个图像中自适应地检索前K个相关类别来减少负空间，从而重新平衡梯度分布并促进隐式的硬样本挖掘。此外，CQ-DINO可以灵活地在结构化数据集中（如V3Det）整合显式的类别层次关系，或者在通用数据集中（如COCO）通过自我注意力学习隐式的类别关联。
### Conclusion
实验表明，CQ-DINO在具有挑战性的V3Det基准测试中的表现优于此前的方法（提高了2.1%的AP），同时在COCO上也保持了竞争力。我们的工作提供了一种可扩展的解决方案，适用于需要广泛类别覆盖的真实世界检测系统。相关代码已公开。
## 663. `cs.CV` - ProbRes: Probabilistic Jump Diffusion for Open-World Egocentric Activity Recognition [PDF](https://arxiv.org/pdf/2504.03948), [HTML](https://arxiv.org/abs/2504.03948)
### Authors
Sanjoy Kundu,Shanmukha Vellamcheti,Sathyanarayanan N. Aakur
### Background
开放世界第一人称活动识别因其不受约束的性质而构成了一个基本挑战，要求模型能够从一个全面但部分观察的搜索空间中推断出未见过的活动。现有的方法需要同时平衡先验引导的探索与基于似然性的利用，以有效地导航这个空间。
### Innovation
ProbRes 提出了一种基于跳跃扩散的概率残差搜索框架，该框架通过平衡先验引导的探索与基于似然性的利用，有效地导航搜索空间。该方法利用结构化的常识先验构建语义上一致的搜索空间，并使用视觉-语言模型(VLMs)自适应地细化预测，同时采用随机搜索机制来定位高似然性活动标签，避免了耗时的穷尽枚举。
### Conclusion
研究系统地评估了 ProbRes 在不同开放级别 (L0-L3) 上的表现，并展示了其在开放搜索空间复杂性增加时的适应性。ProbRes 在多个基准数据集（包括 GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, 和 Charades-Ego等）上达到了最先进的性能，并通过清晰的分类对开放世界的活动识别问题进行了界定，指出了共同理解和方法进步所需的关键挑战。该研究突显了结构化搜索策略的重要性，为开放世界的活动识别提供了方向性指导。
## 664. `cs.CV` - 视频生成在增强数据受限动作理解中的作用 [PDF](https://arxiv.org/pdf/2505.19495), [HTML](https://arxiv.org/abs/2505.19495)
### Authors
Wei Li,Dezhao Luo,Dongbao Yang,Zhenhang Li,Weiping Wang,Yu Zhou
### Background
在实际场景中，视频动作理解任务经常面临数据局限性问题。本文通过解决数据匮乏的动作理解问题，提出了一种新方法，利用文本到视频的扩散变换器生成注释数据以供模型训练。这种方法可以无限制地生成大规模的注释数据，无需人工干预。同时，通过定量和定性的分析，观察到实际样本通常比生成样本包含更多的信息，因此提出了信息增强策略以提高生成样本的信息内容。另外，一些质量低的生成样本可能对模型训练产生负面影响，为此设计了基于不确定性的标签平滑策略，以减少这些样本的影响。
### Innovation
本文提出了一种利用文本到视频的扩散变换器生成注释数据的方法，以应对动作理解中的数据稀缺问题。提出了信息增强策略和基于不确定性的标签平滑策略，分别从环境和角色两个方面增强生成样本的信息含量，减少低质量生成样本对模型训练的负面影响，实现了零样本动作识别领域的最佳性能。
### Conclusion
所提出的方法在四个数据集上对五个任务进行了验证，并获得了零样本动作识别的最佳性能。
## 665. `cs.CV` - 从任意主体到视频模糊：使用视频扩散模型的视频重新聚焦 [PDF](https://arxiv.org/pdf/2505.21593), [HTML](https://arxiv.org/abs/2505.21593)
### Authors
Yang Yang,Siming Zheng,Qirui Yang,Jinwei Chen,Boxi Wu,Xiaofei He,Deng Cai,Bo Li,Peng-Tao Jiang
### Background
最近，扩散模型被用作强大的相机模拟工具，支持几何变换和真实的光学效果。在这些模型中，基于图像的景深模糊渲染显示出有希望的结果，但视频中的景深模糊尚未被探索。现有的基于图像的方法便携着时间闪烁和不一致的模糊过渡问题，当下的视频编辑方法在焦点平面和模糊强度上的控制也不够明确。这些问题限制了它们应用于可控的视频景深模糊中的适用性。
### Innovation
本文提出了一种一键式的扩散框架，用于生成时空一致、深度意识的视频模糊渲染。该框架利用针对焦平面优化的多平面图像（MPI）表示来调整视频扩散模型，从而使得该模型能够从中提取强大的三维先验知识。为了进一步提高时间稳定性、深度鲁棒性和细节保持性，还引入了一种分阶段训练策略。在合成和现实世界的基准测试上，该方法展现了更优秀的时空一致性、空间准确性和可控制性，并超过之前的基线方法。
### Conclusion
这项工作代表了第一个专注于视频模糊生成的专门扩散框架，为时空一致且可控的景深效果设定了新的基准线。
## 666. `cs.CV` - 体育视频事件检测中的深度学习：任务、数据集、方法与挑战 [PDF](https://arxiv.org/pdf/2505.03991), [HTML](https://arxiv.org/abs/2505.03991)
### Authors
Hao Xu,Arbind Agrahari Baniya,Sam Well,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal
### Background
体育视频分析如今已成为现代运动分析的关键组成部分，支持自动化运动表现评估、内容生成和战术决策。近年来，深度学习在相关任务如时间动作定位（Temporal Action Localization, TAL）、动作检测（Action Spotting, AS）和精确事件检测（Precise Event Spotting, PES）方面取得了进展。这些任务虽然密切相关，但其细微差别模糊了它们之间的界限，导致了研究和实际应用中的困惑。此外，以往的综述要么专注于通用视频事件检测，要么涵盖了更广泛的体育视频任务，但缺乏对事件检测特有的时间粒度和领域特定挑战的讨论。现有的大多数体育视频综述主要关注精英比赛，忽略了日常运营者的更广泛社区。这项综述通过明确区分TAL、AS和PES及其各自的使用场景，提出了新的结构化税则，并全面评估了基准数据集和评估协议中的局限性，提供了一个全面的基础，以开发适用于研究和行业的具有时间精确性、普遍适用性和实际部署性的体育事件检测系统。
### Innovation
本文通过区分TAL、AS和PES及其各自的使用场景，提出了新的结构化税则，并全面评估了基准数据集和评估协议中的局限性。它填补了缺口，包括对现成的体育视频事件检测信息的明确区分，引入了时间建模策略、多模态框架和数据高效的AS和PES专用管道，以及对现有基准数据集和评估协议进行批判性评估，突出了依赖广播质量素材和过于偏重宽容多标签预测的指标等问题。
### Conclusion
本文通过综合当前研究并揭示开放挑战，为开发既具有时间精确性又普遍适用且实际可部署的体育事件检测系统提供了全面的基础，不仅为研究界，也为工业界提供了指导。
## 667. `cs.CV` - 多模态语言模型在较浅层处表现更好 [PDF](https://arxiv.org/pdf/2504.21447), [HTML](https://arxiv.org/abs/2504.21447)
### Authors
Haoran Chen,Junyan Lin,Xinghao Chen,Yue Fan,Jianfeng Dong,Xin Jin,Hui Su,Jinlan Fu,Xiaoyu Shen
### Background
多模态大型语言模型（MLLMs）通常从预训练的Vision Transformer (ViT)的最终层提取视觉特征。然而，这种深层偏好很大程度上是由经验惯例驱动的，而不是通过严格的分析得出的。先前研究表明，不同的ViT层提取不同类型的信息，浅层关注细小微观细节，而深层则更接近文本语义，而这种变化对MLLM性能的影响尚未被充分探索。本文进行了首个多模态语言模型中视觉层选择的全面研究，通过对ViT层进行代表相似性分析，区分出浅层、中间层和深层的组别，并基于此评估了包含60多种任务的10个基准模型中的MLLMs（1.4B-7B参数），结果发现，在依赖大量语义的任务如OCR中，深层层表现更佳，而浅层和中间层在细颗粒视觉任务中表现出显著优势，包括计数、定位和物体定位任务。
### Innovation
本文首次全面研究了多模态语言模型中视觉层的选择，提出了一个轻量级的特征融合方法，策略性地结合浅层特征，该方法在单一层和专用融合基线下展示了持续的性能提升，提供了多模态语言模型视觉层选择的第一个基于原则的研究，表明MLLMs在查看较浅层时可能表现更好。
### Conclusion
研究表明，即使在深层具有更多语义优势的任务中，浅层和中间层也能够在细颗粒视觉任务中提供更好的性能。基于此，本文提出了一个轻量级的特征融合方法，提高了MLLMs在多任务场景中的表现。
## 668. `cs.CV` - SpatialSplat：从稀疏未对齐图像高效生成语义3D [PDF](https://arxiv.org/pdf/2505.23044), [HTML](https://arxiv.org/abs/2505.23044)
### Authors
Yu Sheng,Jiajun Deng,Xinran Zhang,Yu Zhang,Bei Hua,Yanyong Zhang,Jianmin Ji
### Background
3D重建领域的一个主要突破是前馈范式，可以从稀疏的未对齐图像中生成像素级的3D点或高斯基元。现有方法为了进一步融合语义信息，同时避免高维语义特征的高存储开销，将每个基元关联压缩了的语义特征向量。然而，这些方法存在两个主要问题：一是简单压缩的特征降低了表示能力，影响模型对细微语义特征的捕捉能力；二是像素级的基元预测在重叠区域引入了冗余，导致不必要的内存开销。
### Innovation
本文提出了SpatialSplat，这是一种前馈框架，旨在产生具有冗余感知的高斯分布，并利用双场语义表示。通过将语义表示分解为一个粗特征场，该场使用最小数量的基元以无压缩方式编码语义信息，和一个精细但低维的特征场，该场捕获了不同实例之间的详细关系。此外，本文还提出了选择性高斯机制，仅保留场景中的关键高斯分布，有效地消除了冗余基元。SpatialSplat 通过更紧凑的3D高斯分布学习准确的语义信息和详细的实例先验，从而使得语义3D重建更加实用。
### Conclusion
本文进行了广泛实验，表明SpatialSplat在减少场景表示参数（精度提高60%）的同时，能够实现优于现有方法的性能。
## 669. `cs.CV` - 使用FLAIR解决逆向问题 [PDF](https://arxiv.org/pdf/2506.02680), [HTML](https://arxiv.org/abs/2506.02680)
### Authors
Julius Erbach,Dominik Narnhofer,Andreas Dombos,Bernt Schiele,Jan Eric Lenssen,Konrad Schindler
### Background
基于流的潜在生成模型（如Stable Diffusion 3）能够生成具有显著质量的图像，甚至实现逼真的文本转图像生成。这些模型展示了作为逆向图像问题先验的强大潜力，但由于几个关键障碍尚未实现相当的质量：（i）数据似然项通常是不可计算的；（ii）学习生成模型无法直接针对受损观测进行调整，导致数据似然性与先验之间的目标冲突；（iii）重建可能与观测数据产生偏差。
### Innovation
FLAIR（一种无需训练的变分框架），利用基于流的生成模型作为逆向问题的先验。为此，引入了一种对降级类型无感的流动匹配变分目标，并结合确定性的轨迹调整，引导先验向后验更可能的区域进行调整。此外，提出了一个时间依赖的校准方案，通过离线准确性估计调节正则化强度。
### Conclusion
在标准成像基准上的结果显示，FLAIR在重建质量和样本多样性方面始终优于现有的扩散模型和基于流动的方法。我们的代码可在以下网址获得。
## 670. `cs.CV` - HoliTom: 整体标记合并以快速推断视频大型语言模型 [PDF](https://arxiv.org/pdf/2505.21334), [HTML](https://arxiv.org/abs/2505.21334)
### Authors
Kele Shao,Keda Tao,Can Qin,Haoxuan You,Yang Sui,Huan Wang
### Background
视频大型语言模型（video LLMs）在视频理解方面表现出色，但存在显著的计算效率问题，因为它们会处理多余的视频标记。现有方法，如快速视频（FastV）方法，虽然能减小程序中的冗余标记，但在浅层计算上仍需要额外的计算开销。外层LLM剪枝方法在单一帧或有限的时间窗内处理空间冗余，但忽略了长期视频序列中重要的时空全局动态和关联性，导致时空减少效果不佳，也无法充分利用视频压缩性。对于这些方法的互补潜力和相互影响的研究还有所欠缺。现有方法未能同时优化时间和空间冗余以提升模型的计算效率和性能。
### Innovation
HoliTom是一种全新的无需训练的整体标记合并框架。通过全局冗余意识的时间分割，HoliTom在外层LLM剪枝后执行时空合并，显著减少了超过90%的视觉标记，从而大大减轻了LLM的计算负担。此外，HoliTom结合了一种内在LLM基于标记相似性的标记合并方法，以提升性能和与外层LLM剪枝的兼容性。这种方法在LLaVA-OneVision-7B上的评估显示，与原始性能相比，计算成本降低了6.9%，TTFT减少了2.28倍，解码吞吐量提高了1.32倍，这表明我们的综合剪枝方法对高效的视频LLM推断具有实际意义和优势。
### Conclusion
HoliTom和改进后的内层LLM标记合并方法提供了在视频LLM推断中高效减少冗余和计算成本的策略，展示了在现有方法之外的新颖性，对于推动视频LLM研究的发展具有重要意义。
## 671. `cs.CV` - Differentially Private 2D Human Pose Estimation [PDF](https://arxiv.org/pdf/2504.10190), [HTML](https://arxiv.org/abs/2504.10190)
### Authors
Kaushik Bhargav Sivangi,Paul Henderson,Fani Deligianni
### Background
2D人体姿态估计（HPE）在医疗保健、活动识别和人机交互等多个应用中已成为必要组成部分。然而，处理敏感视觉数据的隐私影响成为了在关键领域部署的障碍。传统的匿名化技术提供有限的保护，经常牺牲数据的有用性以进行更广泛的运动分析。相比之下，差分隐私（DP）提供形式化的隐私保障，但在应用时通常会降低模型性能。因此，本文探讨了Differentially Private 2D Human Pose Estimation（2D-HPE）的差分隐私框架，以平衡隐私与性能。本文通过采用投影差异隐私梯度下降（PDP-SGD）并在特征上引入特征差异隐私（FDP）方法，构建了结合特征投影的混合差异隐私框架，以实现HPE的隐私保护和准确性之间的平衡。该研究在MPII数据集上进行了评估，结果表明结合特征投影的方法在各种隐私预算、训练策略和梯度裁剪标准下都优于纯差分隐私梯度下降和个别基线，特别是在ε=0.8的情况下，平均PCKh@0.5达到了82.61%，显著缩小了与非私有性能的差距。这项工作为现实世界中的敏感应用程序中的隐私保护人体姿态估计奠定了基础。
### Innovation
本文提出了第一个全面的Differentially Private 2D Human Pose Estimation（2D-HPE）框架，通过应用Differentially Private Stochastic Gradient Descent（DP-SGD）和投影差异隐私梯度下降（PDP-SGD）方法来平衡隐私保护和模型性能。此外，引入了特征差异隐私（FDP）来选择性地仅针对敏感特征进行隐私化，同时保留公共视觉线索。结合特征投影的方法，构建了混合特征投影的差异隐私框架，以满足HPE中的隐私与准确性需求。该框架在各种场合下总是优于纯差分隐私梯度下降和个别基线。
### Conclusion
本文的研究构建了一个结合特性和投影的混合差异隐私框架，用于平衡隐私保护与人体姿态估计的准确性。通过在MPII数据集上的评估，该方法在多个隐私预算、训练策略和梯度裁剪标准下均表现优异，尤其在ε=0.8的情况下，PCKh@0.5达到了82.61%。这为在敏感应用中实现人体姿态估计的隐私保护奠定了基础。
## 672. `cs.CV` - DenseDPO：视频扩散模型的细粒度 temporal 偏好优化 [PDF](https://arxiv.org/pdf/2506.03517), [HTML](https://arxiv.org/abs/2506.03517)
### Authors
Ziyi Wu,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ashkan Mirzaei,Igor Gilitschenski,Sergey Tulyakov,Aliaksandr Siarohin
### Background
Direct Preference Optimization (DPO) 近期被用作对文本到视频扩散模型的后训练技术。现有的方法要求注释者对比两个由独立噪声生成的视频，但这种方法限制了精细的比较，并且偏向于选择低运动的片段，因为这些片段通常包含较少的视觉伪影。
### Innovation
提出了一种名为 DenseDPO 的方法，主要有三方面的创新：1. 通过去噪真实视频的腐蚀副本制作每组视频，形成在运动结构相似但局部细节不同的对齐视频，消除运动偏见。2. 利用时间对齐的结果，在短片段上标注偏好，生成更密集和精确的学习信号。3. 使用现成的视觉语言模型（VLM）如 GPT 实现自动偏好标注，DenseDPO 在这些标签上训练的表现接近使用人工标签。
### Conclusion
DenseDPO 方法可以在仅使用三分之一的标注数据下，显著提高运动生成性能，同时保持与 vanilla DPO 相同的文字对齐、视觉质量和时间一致性。另外，DenseDPO 还能够通过现成的 VLM 实现自动偏好标注，效果接近使用人工标注的性能。
## 673. `cs.CV` - 轮廓误差：一种用于可靠3D多目标跟踪的以自我为中心的度量标准 [PDF](https://arxiv.org/pdf/2506.04122), [HTML](https://arxiv.org/abs/2506.04122)
### Authors
Sharang Kaul,Mario Berk,Thiemo Gerbich,Abhinav Valada
### Background
在自动驾驶等安全关键应用中的多对象跟踪中，找到可靠的匹配至关重要，以确保感知系统的准确性和可靠性。传统的交并比（IoU）和中心点距离（CPD）等度量标准在2D图像平面上很有效，但在复杂3D场景下往往无法找到关键的匹配。因此，需要引入一种新的以自我为中心的匹配度量标准，以改善匹配的质量和可靠性，从而提高对象识别和跟踪性能以及安全性。
### Innovation
本文提出了一种新的度量标准——轮廓误差（CEs），这是一种自车或对象中心的度量标准，可以从功能角度识别跟踪场景中的感兴趣的匹配。通过在自车框架中比较边界框，轮廓误差提供了更相关于功能的物体匹配评估。实验结果表明，与最先进的2D IoU和CPD度量标准相比，轮廓误差提高了跟踪方法中匹配的可靠性，特别是在3D汽车跟踪中，它可以将功能性错误（FPs/FNs）在近距离和远距离分别减少80%和60%。
### Conclusion
本文提出了一种新的度量标准——轮廓误差，这种度量标准在处理复杂3D场景中的匹配时表现更优，特别是在自车或对象中心的视角下提供了更相关的信息。这种度量标准在3D多目标跟踪中表现出了更好的可靠性和功能性能。
## 674. `cs.CV` - AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving [PDF](https://arxiv.org/pdf/2506.05404), [HTML](https://arxiv.org/abs/2506.05404)
### Authors
Lianming Huang,Haibo Hu,Yufei Cui,Jiacheng Zuo,Shangyu Wu,Nan Guan,Chun Jason Xue
### Background
随着自动驾驶技术的迅速发展，视觉-语言模型（VLMs）被用于提升感知和决策效果，但在实际应用中由于高延迟和计算开销，影响了它们在时间敏感驾驶场景中的效果。特别是在面对过度推理的问题时更为显著，即即使在达成自信预测后，VLMs仍继续处理不必要的层级。
### Innovation
本文提出了一种称为AD-EE的早期退出框架，该框架结合了自动驾驶领域的特性，并利用因果推断来识别最佳退出层，以解决上述低效问题。
### Conclusion
在Waymo和其他大规模的自动驾驶数据集以及配备Autoware Universe平台的实际车辆上进行了广泛实验，结果表明该方法能显著降低延迟，最多达到57.58%，同时提高目标检测精度，最多可达44%。
## 675. `cs.CV` - 自回归图像生成中的序列建模对齐：从分词器到自回归模型 [PDF](https://arxiv.org/pdf/2506.05289), [HTML](https://arxiv.org/abs/2506.05289)
### Authors
Pingyu Wu,Kai Zhu,Yu Liu,Longxiang Tang,Jian Yang,Yansong Peng,Wei Zhai,Yang Cao,Zheng-Jun Zha
### Background
传统的图像自回归生成方法基于先前的图像标记进行逐个预测，但这种过程受到传统图像标记化中的双向依赖性挑战，这与自回归模型的单向特性存在根本性偏差。
### Innovation
提出了AliTok，这是一种新颖的对齐分词器，通过改变标记序列的依赖结构来解决这一问题。AliTok融合了双向编码器和受限于因果解码器的前缀标记，从而促使编码器生成既富含语义又具有前向依赖性的标记序列。同时，通过两阶段的分词器训练过程和前缀标记的引入来提升重建性能，AliTok实现了高保真度和预测性的统一。
### Conclusion
基于AliTok，标准的仅解码器自回归模型，即使参数量仅有177M，也能在ImageNet-256基准上达到gFID 1.44和IS 319.5的优异结果。进一步将参数量扩大到662M时，该模型捷成了gFID 1.28，不仅超越了最先进的扩散方法，还实现了10倍的采样速度。相关代码和权重可在该链接获取。
## 676. `cs.CV` - Parkinson疾病中基于视频的可解释和粒度化指敲测试运动特征量化 [PDF](https://arxiv.org/pdf/2506.18925), [HTML](https://arxiv.org/abs/2506.18925)
### Authors
Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers
### Background
准确量化帕金森病(PD)的运动特征对于监测疾病进展和优化治疗策略至关重要。指敲测试是标准的运动评估方法，临床医生根据手指敲击的幅度、速度和不规则性对患者的敲击表现进行主观评估并打分。然而，这种方法的主观性会导致测评者之间和测评者内部的一致性不高，并且不能揭示患者在测试中呈现的具体运动特征。
### Innovation
本研究提出了一种基于计算机视觉的微细化视频分析方法来量化PD患者的运动特征。该方法通过视频记录来评估四类相关临床特征，即运动迟缓、动作迟缓、序列效应以及犹豫步，以识别并描述指敲测试中的微小差异，同时利用机器学习算法预测运动障碍学会帕金森病统一评分量表（MDS-UPDRS）中的指敲评分，相比现有方法，达到了更高的准确性。
### Conclusion
提出的框架为客观评估PD运动特征提供了实用的解决方案，并可能适用于临床和远程环境中。未来的工作需要评估该方法对症状治疗反应性和疾病进展的敏感性。
## 677. `cs.CV` - 事件-彩色融合用于恶劣光照条件下的航天器姿态估计 [PDF](https://arxiv.org/pdf/2507.05698), [HTML](https://arxiv.org/abs/2507.05698)
### Authors
Mohsi Jawaid,Marcus Märtens,Tat-Jun Chin
### Background
航天器姿态估计对于自主空间操作至关重要，如对接、补给等。基于视觉的姿态估计方法通常使用RGB成像传感器，但这些方法在面对恶劣光照条件时面临挑战，这些问题包括反射、过曝、拖尾和镜头眩光等成像缺陷。具有更高动态范围的神经形态或事件传感器在这种极端环境中表现更稳定，但它们的分辨率较低，在相对运动较小时信号与噪声的比例也受到影响。为克服这些传感器的独立限制，该研究提出了一种结合RGB和事件传感器融合的方法。通过使用分束棱镜实现精确的光学和时间对齐，开发了一种基于RANSAC技术的融合方法，从而利用两种成像方式的优点，并通过dropout不确定性估计来检测影响任一通道的极端情况。
### Innovation
该研究通过引入事件-彩色融合方法，结合了具有高动态范围的事件传感器和有效捕捉三维空间信息的RGB传感器，实现了在恶劣光照环境下的精准航天器姿态估计。具体创新包括：1) 使用分束棱镜精确对齐RGB和事件传感器。2) 开发基于RANSAC的融合技术，以及通过dropout不确定性估计检测极端成像条件。
### Conclusion
通过在实验室环境下收集的多种恶劣光照条件下的RGB和事件数据集进行测试，实验结果表明，该事件-彩色融合方法能够有效提高航天器姿态估计的准确性。这些结果进一步验证了使用事件传感器进行航天器姿态估计的有效性，并支持了公开发布的数据集，为社区研究提供支持。
## 678. `cs.CV` - DiffMark：基于扩散模型的抗Deepfake鲁棒水印 [PDF](https://arxiv.org/pdf/2507.01428), [HTML](https://arxiv.org/abs/2507.01428)
### Authors
Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li
### Background
深度伪造（Deepfakes）通过恶意面部操控会带来重大的安全和隐私威胁。现有的一些抗伪造验证和溯源的方法往往缺乏充分的对抗深度伪造攻击的鲁棒性。扩散模型在图像生成方面的卓越表现使得水印可以在生成过程中与图像无缝融合，为我们提出了一种基于扩散模型的鲁棒水印框架（DiffMark）。通过调整训练和采样方案，以面部图像和水印作为条件，引导扩散模型逐步去噪并生成相应的水标记图像。
### Innovation
提出了一个基于扩散模型的鲁棒水印框架（DiffMark），通过调整训练和采样策略，将面部图像和水印作为条件进行生成码的引导，以适应扩散模型的采样过程。同时引入了一种跨信息融合（CIF）模块，利用一个可学习的嵌入表来适应性提取水印特征，并通过交叉注意力将其与图像特征整合。在训练阶段整合了一个冻结的自编码器来模拟深度伪造攻击，还引入了深度伪造抗御指导，使用特定的深度伪造模型逆向引导扩散采样过程以生成更鲁棒的水标记图像。
### Conclusion
实验结果证明了所提出的DiffMark在典型深度伪造中的有效性。我们的代码可在这个链接https:// <链接地址> 获取。
## 679. `cs.CV` - 基于渐进层冻结的站点级微调：极早早产儿第一天胸部X光片中肺泡发育不全稳健预测的方向 [PDF](https://arxiv.org/pdf/2507.12269), [HTML](https://arxiv.org/abs/2507.12269)
### Authors
Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)
### Background
极早早产儿中存在35%的支气管肺发育不良（BPD）病例，这种慢性肺病定义为在孕龄36周时仍需依赖氧气，会导致终身呼吸并发症。预防干预措施具有严重风险，包括神经发育损伤、机械通气引起的肺损伤和全身并发症。因此，早期预测BPD对于避免对低风险婴儿不必要的毒性和进行适当的治疗至关重要。新生儿入院时的胸部X光片可以作为非侵入性预后工具，且常规在出生24小时内进行。
### Innovation
该研究开发并测试了一种基于深度学习的方法，使用163名极早早产儿（≤32周胎龄，体重401-999克）出生24小时内的胸部X光片进行BPD预测。研究通过渐进层冻结、线性探测和CutMix数据增强方法，无需调整全部参数，有效地进行了微调并显著提高了BPD预测性能。研究人员发现基于成人胸部X光片预训练的模型比从ImageNet初始化的模型表现更好，证实了领域特定预训练的重要性。
### Conclusion
经过领域特定预训练的方法可以准确预测极早早产儿第一天胸部X光片中的BPD。使用渐进层冻结和线性探测的方法，该模型在实际部署和未来联机学习应用中保持了计算上的可行性。这种方法可以用来生成早期BPD预测，从而为低风险婴儿避免不必要的毒性提供了可能。
## 680. `cs.CV` - Mem4Nav: 通过层级空间认知长短期记忆系统在城市环境中增强视语言导航 [PDF](https://arxiv.org/pdf/2506.19433), [HTML](https://arxiv.org/abs/2506.19433)
### Authors
Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li
### Background
在大规模城市环境中，视语言导航(VLN)要求具备感知能力的代理能够将语言指令嵌入复杂场景中，并在长时间段内回忆相关经验。目前的模块化管道虽然具备解释性，但缺乏统一的记忆系统；而端到端的大模型语言-视觉混合代理则虽然擅长融合视觉和语言信息，但仍然受限于固定上下文窗口和隐式的空间推理。
### Innovation
我们提出了Mem4Nav，这是一种具有层级空间认知能力的长短期记忆系统，能够增强任何VLN主干结构。Mem4Nav结合了稀疏八叉树进行细粒度体素索引、语义拓扑图进行高层地标连接，并将这些结构嵌入可训练的记忆令牌中，通过可逆变换器实现。长期记忆(LTM)压缩并保留了关于八叉树和图节点的历史观察，而短期记忆(STM)则缓存了最近的多模态条目，以相对坐标进行实时障碍物规避和局部规划。每一步，STM检索都会尖锐地精简动态上下文，并在需要更深层次的历史记录时，LTM令牌可以无损解码以重建过去的嵌入。在Touchdown和Map2Seq数据集上，Mem4Nav在三个主干（模块化、基于提示的大模型VLN、以及基于跳跃注意力的大模型VLN）上获得7-13个百分点的任务完成率提升、足够的SPD降低和超过10个百分点的nDTW改进。
### Conclusion
消融实验确认了双重记忆模块和层级地图模块的不可或缺性。我们的代码开源了。
## 681. `cs.CV` - TTS-VAR: 一种用于视觉自回归生成的测试时缩放框架 [PDF](https://arxiv.org/pdf/2507.18537), [HTML](https://arxiv.org/abs/2507.18537)
### Authors
Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu
### Background
在真实世界的内容创作中，视觉生成模型的扩展至关重要，但这也需要大量的训练和计算资源。相比之下，测试时的缩放因其资源效率和有希望的性能而受到了越来越多人的重视。本文解决了视觉自回归（VAR）模型的测试时缩放问题，提出了一种新的框架TTS-VAR。
### Innovation
TTS-VAR提出了一个通用的测试时缩放框架，将生成过程视为路径搜索问题。该框架通过自适应的递减批次大小调度来动态平衡计算效率和探索能力。此外，借鉴VAR多层次的粗细粒度多尺度生成特性，TTS-VAR框架结合了两种关键组件：粗粒度尺度使用基于聚类的多样性搜索来保留结构多样性，以及细粒度尺度通过潜在选择重新采样来优先选择有潜力的候选样本。这些策略在Infinity模型上取得了显著效果，提高了8.7%的GenEval分数。
### Conclusion
实验表明，早期阶段的结构特征对最终质量有显著影响，不同生成尺度的重采样效果也有所不同。
## 682. `cs.CV` - CAPE: 一种 CLIP 意识的互补热图线索指向集成方法用于具身参考理解 [PDF](https://arxiv.org/pdf/2507.21888), [HTML](https://arxiv.org/abs/2507.21888)
### Authors
Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel
### Background
本文解决了具身参考理解的问题，即通过人体指向手势和语言预测场景中的人在指代的对象。准确识别指代对象需要多模态理解：结合文本指令、视觉指向和场景上下文。现有方法经常难以有效利用视觉线索进行消歧义。
### Innovation
提出了一个双重模型框架，其中一个模型从头到指尖方向学习，另一个模型从腕部到指尖方向学习。引入了热图表示这些线的高斯射线，并将它们作为输入提供强监督信号，以引导模型更好地关注指向线索。此外，提出了一个 CLIP 意识的指向集成模块，利用 CLIP 特征进行了混合集成。还提出了一种物体中心预测头作为辅助任务以进一步增强指代对象的定位。
### Conclusion
通过在基准 YouRefIt 数据集上的广泛实验和分析验证了该方法，ROC 平均精度（大约 4 mAP）在 0.25 IoU 阈值下有所提高。并且在 CAESAR 和 ISL Pointing 数据集上进一步评估了该方法。
## 683. `cs.CV` - UniLiP: 调整CLIP以实现统一的多模态理解和生成编辑 [PDF](https://arxiv.org/pdf/2507.23278), [HTML](https://arxiv.org/abs/2507.23278)
### Authors
Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang
### Background
CLIP在多模态理解方面表现出色，但缺乏重建能力，无法作为统一的视觉编码器。现有的基于CLIP的统一方法无法平衡理解和重建，导致语义退化或重建不一致。UniLIP提出了一种新颖的两阶段训练方案以及一种自我蒸馏策略，逐步赋予CLIP高保真重建能力，同时保留其原始的解释性能。为了增强理解和生成/编辑的一致性，UniLIP利用MetaQuery框架开发了一种双条件架构，联合使用多模态隐藏状态和可学习的查询嵌入，以利用多模态大语言模型的强大推理能力。
### Innovation
1. 提出了一个新颖的两阶段训练方案，结合自我蒸馏策略，逐步赋予CLIP重建能力，同时保持其原始解释性能。2. 发展了一种基于MetaQuery的双条件架构，结合多模态隐藏状态和可学习的查询嵌入，利用多模态大语言模型的推理能力进行增强的生成和编辑。3. UniLIP仅使用1B和3B参数，在GenEval、WISE和ImgEdit上优于较大统一模型，实现了最先进的性能。4. 通过调整CLIP，UniLIP成功扩展了CLIP的应用，不仅作为理解任务的理想选择，还在生成和编辑任务中实现了竞争性表现。
### Conclusion
UniLIP作为一种统一框架，成功实现了多模态理解和生成编辑任务，展示了卓越的指令跟随和编辑保真度。该模型虽然参数较少，但性能优于更大参数量的模型，证明了其在多个任务上的实用性和竞争力。代码和模型已公开提供。
## 684. `cs.CV` - MedCAL-Bench：医疗图像分析中基于基础模型的冷启动主动学习综合基准 [PDF](https://arxiv.org/pdf/2508.03441), [HTML](https://arxiv.org/abs/2508.03441)
### Authors
Ning Zhu,Xiaochuan Ma,Shaoting Zhang,Guotai Wang
### Background
冷启动主动学习（CSAL）旨在在缺乏先验知识的情况下选择具有信息量的样本进行标注，这对于在有限的标注预算下提高注释效率和模型性能至关重要。大多数现有的CSAL方法依赖于目标数据集的自我监督学习（SSL）来提取特征，这效率低且受限于特征表示的不足。最近，预训练基础模型在特征提取方面显示出强大的能力，并且有可能更好地应用于CSAL。然而，这一范式很少被研究，缺乏针对CSAL任务比较基础模型的基准。基于此，本文提出了MedCAL-Bench，这是首个基于基础模型的CSAL基准，专门用于医疗图像分析。该基准评估了14种基础模型和7种CSAL策略在7个不同的标注预算下的性能，涵盖了多种医学成像数据集，包括分类和分割任务。
### Innovation
MedCAL-Bench是首个基于基础模型的冷启动主动学习基准，首次系统地评估了基础模型在医学图像分析中的特征提取和样本选择能力。此基准涵盖了多种医学成像数据集，包括分类和分割任务。实验结果显示，大多数基础模型都适用于CSAL，尤其是在分割任务中，DINO家族表现最优。此外，根据不同任务的不同表现，需要考虑不同的样本选择策略。
### Conclusion
基于MedCAL-Bench的实验结果，大多数基础模型在CSAL中表现良好，特别是在分割任务中，DINO家族为最优。不同的样本选择策略适用于不同的数据集，ALPS在分割任务中表现最优，而RepDiv在分类任务中表现最佳。
## 685. `cs.CV` - VisionTS++：具有持续预训练视觉骨干的跨模态时间序列基础模型 [PDF](https://arxiv.org/pdf/2508.04379), [HTML](https://arxiv.org/abs/2508.04379)
### Authors
Lefei Shen,Mouxiang Chen,Xu Liu,Han Fu,Xiaoxue Ren,Jianling Sun,Zhuo Li,Chenghao Liu
### Background
最近的研究表明，预训练在图像上的视觉模型可以作为一种时间序列基础模型（TSFM），通过将时间序列预测（TSF）重新表述为图像重建。然而，由于三个差异性问题，视觉到时间序列的有效跨模态转移仍然具有挑战性：（1）结构化、有界限的图像数据与无界限、异构的时间序列数据之间的数据模态差异；（2）固定RGB三通道视觉模型与任意数量变量的时间序列之间的多变量预测差异；（3）视觉模型的确定性输出与需要不确定性意识的概率预测之间的概率预测差异。为了克服这些问题，该文提出了VisionTS++，基于视觉模型在大规模时间序列的持续预训练的TSFM。
### Innovation
该文提出了三个关键创新：（1）基于视觉模型的筛选以识别高质量序列以稳定预训练并缓解模态差异；（2）多变量颜色化转换，将多变量时间序列编码为多子图RGB图像以增强跨变量建模；（3）多分位数预测，使用并行重建头生成不依赖参数假设的分位数预测。实验表明，VisionTS++在分布内和分布外预测中都达到了最先进的性能，与专门的时间序列基础模型相比，在MSE减少方面提高了6%-44%，并在包含23个数据集跨越7个领域的GIFT-Eval基准测试中排名第一。
### Conclusion
本文的工作表明，在适当适应后，视觉模型可以有效地推广到时间序列预测，从而促进了通用时间序列基础模型的追求。
## 686. `cs.CV` - PanoLAM: 大规模avatar模型用于单张非姿态图像生成高保真全头Gaussian模型 [PDF](https://arxiv.org/pdf/2509.07552), [HTML](https://arxiv.org/abs/2509.07552)
### Authors
Peng Li,Yisheng He,Yingdong Hu,Yuan Dong,Weihao Yuan,Yuan Liu,Siyu Zhu,Gang Cheng,Zilong Dong,Yike Guo
### Background
在单张非姿态图像生成全头Gaussian模型时，以往的工作依赖于长时间的GAN反向过程和测试阶段的优化。此外，缺乏大规模的3D头部资产阻碍了模型的精确重建。
### Innovation
本文提出了一个无需时间消耗的GAN反转和测试时间优化的前馈框架。通过提出大规模合成数据集，利用已训练的3D GAN生成，仅使用合成数据训练框架。引入了由稀疏点与图像特征交互组成的粗到细的Gaussian头部生成管道，并提出了双分支框架，有效聚合结构化的球形三平面特征和不规则的基于点的特征，以实现更有效的Gaussian头部模型重建。
### Conclusion
实验结果表明，本文的框架比现有工作更有效。
## 687. `cs.CV` - ACD-CLIP: 解耦表示和动态融合以实现零样本异常检测 [PDF](https://arxiv.org/pdf/2508.07819), [HTML](https://arxiv.org/abs/2508.07819)
### Authors
Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo
### Background
预训练的跨模态模型（VLMs）在零样本异常检测（ZSAD）中表现出色，但由于重要的适应差距，它们在密集预测和固定的功能融合模式上存在限制，因此在ZSAD任务上表现不佳。本文指出这些模型缺乏细粒度表示所需的局部归纳偏置，并且没有灵活的功能融合机制。
### Innovation
本文通过一种联合设计（Architectural Co-Design，ACD）框架来提高模型的零样本异常检测能力，同时优化特征表示和跨模态融合。ACD框架引入了一个参数效率高的Conv-LoRA自适应器，旨在注入局部归纳偏置，以改善细粒度表示。同时，它还引入了一个动态融合网关（Dynamic Fusion Gateway，DFG），可以根据视觉上下文自适应地调节文本提示，增强了跨模态融合的双向性。实验结果表明，ACD-CLIP在多种工业和医疗基准测试中表现出更高的准确性和鲁棒性，证实了这种协同联合设计对于将基础模型适应密集感知任务的重要性。
### Conclusion
本文提出了一种ACD-CLIP方法，通过联合设计框架提高了预训练跨模态模型在零样本异常检测任务中的表现。结果表明这种方法显著提升了模型的适应性和准确性。
## 688. `cs.CV` - Multimodal大语言模型中的视觉表示对齐 [PDF](https://arxiv.org/pdf/2509.07979), [HTML](https://arxiv.org/abs/2509.07979)
### Authors
Heeji Yoon,Jaewoo Jung,Junwan Kim,Hyungyu Choi,Heeseong Shin,Sangbeom Lim,Honggyu An,Chaehyun Kim,Jisang Han,Donghyun Kim,Chanho Eom,Sunghwan Hong,Seungryong Kim
### Background
多模态大语言模型（MLLMs）在多种任务中表现出色，但它们在以视觉为中心的任务，如物体计数或空间推理方面仍然有限。这个问题主要归因于当前的以文本为主的监督范式，这种范式只能间接指导视觉路径，并导致MLLMs在训练过程中丢弃视觉细节。
### Innovation
我们提出了Visual Representation ALignment (VIRAL)，一种简单而有效的正则化策略，该策略将MLLMs的内部视觉表示与预训练的视觉基础模型（VFMs）对齐。通过明确强制这种对齐，VIRAL使模型不仅能够保留输入视觉编码器的关键视觉细节，还能够从VFMs补充额外的视觉知识，从而增强其处理复杂视觉输入的能力。我们在广泛采用的多模态基准测试上进行了实验，并证明了该方法在所有任务上的改进。
### Conclusion
我们的消融研究进一步验证了我们框架下关键设计选择的有效性。我们相信这一简单发现为在训练MLLMs中有效地整合视觉信息指明了重要方向。
## 689. `cs.CV` - 统一多模态模型作为自动编码器 [PDF](https://arxiv.org/pdf/2509.09666), [HTML](https://arxiv.org/abs/2509.09666)
### Authors
Zhiyuan Yan,Kaiqing Lin,Zongjian Li,Junyan Ye,Hui Han,Zhendong Wang,Hao Liu,Bin Lin,Hao Li,Xue Xu,Xinyan Xiao,Jingdong Wang,Haifeng Wang,Li Yuan
### Background
当前多模态理解与生成之间的根本分裂一直阻碍着统一多模态模型（UMMs）的发展。现有的方法通常将这两者分离处理，导致了相互之间的潜在益处被忽视。论文指出，全方面的统一不仅在于合并两个任务，更需要有一个能够内在地联系它们的统一基础目标。
### Innovation
提出了一个新的框架：Auto-Encoder（AE）视角下的统一理解与生成（UAE和Unified-GRPO）。首先通过预训练解码器在700k长上下文的图像-说明对中实现理解；其次利用强化学习（RL）提出了Unified-GRPO框架，涵盖两个互补阶段：理解为生成，编码器生成最大化解码器重建质量的描述；生成为理解，解码器从生成的描述中重建，提高细节利用和生成精度。此框架展示了理解与生成之间的双向提升，即理解增强生成（通过GenEval验证），生成增强细致视觉感知（通过MMT-Bench验证），体现了一种深层次的协同作用。
### Conclusion
在统一重建目标之下，理解与生成能够互相受益，从而向真正统一的多模态智能迈进。
## 690. `cs.CV` - MOCHA：多模态物体感知跨体系架构对齐 [PDF](https://arxiv.org/pdf/2509.14001), [HTML](https://arxiv.org/abs/2509.14001)
### Authors
Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli
### Background
介绍了MOCHA（多模态物体感知跨体系架构对齐）的知识蒸馏方法，该方法将大型视觉语言教师（例如，LLaVa）的区域级多模态语义迁移至轻量级的只视觉物体检测学生（例如，YOLO）。尽管教师模型规模庞大，但MOCHA能在不修改教师模型和推理时不需文本输入的情况下，高效地将语义知识转移到学生模型中。
### Innovation
MOCHA通过引入映射模块将学生特征映射到一个联合空间，使用双目标损失进行训练，既保持局部对齐又保证全局关系一致性。它专注于物体级别而非密集或全局对齐，从而实现高效的跨体系架构知识迁移。
### Conclusion
MOCHA在四个少量样本检测基准测试中均表现出优越性能，对比基线方法平均分提高了10.1分。尽管架构紧凑，MOCHA仍然达到了与大型多模态模型相当的性能，证明了其在实际部署中的适用性。
## 691. `cs.CV` - LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA [PDF](https://arxiv.org/pdf/2509.10026), [HTML](https://arxiv.org/abs/2509.10026)
### Authors
Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Joey Tianyi Zhou,Changtao Miao,Huazhe Tan,Weibin Yao,Jianshu Li
### Background
随着大型视觉语言模型（VLMs）的进步，它们在多语言视觉问答（mVQA）中的能力显著提高。然而，现有的方法主要依赖于文本推理，并且对多语言多模态推理的支持有限，限制了它们在实际应用中的部署。
### Innovation
提出了LaV-CoT框架，该框架结合了语言感知的视觉推理和多方面奖励优化。LaV-CoT包括一个可解释的多阶段推理管道，涵盖文本摘要与边界框、语言识别、空间对象级描述和逐步逻辑推理。通过自动化数据收集方法，生成多语言推理注释，提高训练数据的质量。采用监督微调（SFT）与语言感知的组相对策略优化（GRPO）相结合的两阶段训练范式，通过验证多方面的奖励如语言一致性、结构准确性等提高推理和泛化能力。
### Conclusion
在公开数据集（如MMMB、Multilingual MMBench和MTVQA）上的广泛评估表明，LaV-CoT在开放源基线中取得了高达9.5%的准确性提升，并且超越了比其规模大两倍的模型2.6%。此外，LaV-CoT在GPT-4o-0513和Gemini-2.5-flash等先进的专有模型上也表现出色。在线A/B测试验证了其在实际数据中的有效性，进一步证明了该方法在工业部署中的效果。
## 692. `cs.CV` - MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder [PDF](https://arxiv.org/pdf/2509.11442), [HTML](https://arxiv.org/abs/2509.11442)
### Authors
Ayhan Can Erdur,Christian Beischl,Daniel Scholz,Jiazhen Pan,Benedikt Wiestler,Daniel Rueckert,Jan C Peeken
### Background
在医学成像数据中，缺失的输入序列是常见的问题，这对依赖完整输入数据的深度学习模型构成了挑战。本研究受到MultiMAE [2]的启发，旨在通过构建一个掩码自编码器（MAE）范式，解决3D医学影像中脑部MRI多模态、多任务学习的问题，尤其是在处理缺失输入数据时的鲁棒性挑战。该方法将每个MRI序列视为独立的输入模态，采用晚期融合式的变压器编码器来整合多序列信息，并为每个模态设计了独立的解码流以进行多任务重建。这种预训练策略促使模型不仅学习丰富的模态表示，还能通过跨序列推理来处理缺失输入数据
### Innovation
本研究提出了一种基于MultiMAE的新掩码自编码器（MAE）框架，该框架专为脑部MRI的3D多模态、多任务学习设计。通过这种策略，模型可以学习丰富的模态表示，并具备从可用输入中推断缺失序列的能力。该模型在下游分割和分类任务中与基线方法相比表现出更高的性能鲁棒性，尤其是在处理缺失输入序列时。
### Conclusion
实验结果显示了该预训练策略的优势。该方法在脑部MRI领域展示出了强大的应用潜力，并且其实现已被公开。与MAE-ViT基线相比，在下游任务中实现了总体Dice分数10.1%和0.46的绝对改进，特别是在处理缺失输入序列的情况下。
## 693. `cs.CV` - DeHate: 一种基于稳定扩散的多模态方法以减轻图像中的仇恨言论 [PDF](https://arxiv.org/pdf/2509.21787), [HTML](https://arxiv.org/abs/2509.21787)
### Authors
Dwip Dalal,Gautam Vashishtha,Anku Rani,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal
### Background
有害的在线内容不仅扭曲了公共话语，还对维护健康的数字环境提出了重大挑战。为此，我们提供了一个专门为识别数字内容中的仇恨而设计的多模态数据集。
### Innovation
我们使用了带水印、稳定增强的稳定扩散技术，并结合了数字注意力分析模块（DAAM），这一组合在图像中精确定位仇恨元素，生成详细的仇恨注意力图，从而有助于从图像中移除仇恨段落。我们还介绍了DeHater，一个用于多模态去仇恨化的视觉-语言模型。
### Conclusion
我们的方法在由文本提示驱动的AI图像仇恨检测方面设立了新标准，这有助于开发更符合伦理规范的社交媒体AI应用。
## 694. `cs.CV` - 动态跳连增强U型网络特征融合 [PDF](https://arxiv.org/pdf/2509.14610), [HTML](https://arxiv.org/abs/2509.14610)
### Authors
Yue Cao,Quansong He,Kaishen Wang,Jianlong Xiong,Tao He
### Background
U型网络因其跳跃连接能够将高级语义和低级空间细节相结合，成为了医学图像分割的基本框架。然而，传统的跳连方式存在两个主要限制：特征间约束（特征融合的静态性质，信息沿固定路径传输，不考虑特征内容）和特征内约束（无法充分建模多尺度特征交互，阻碍全局上下文信息的有效聚合）。
### Innovation
提出了一种新型的动态跳连（DSC）模块，通过自适应机制增强跨层连接性。DSC模块包含两个组件：（1）测试时训练（TTT）模块，通过动态调整隐藏表示以实现内容感知特征精炼来解决特征间约束；（2）动态多尺度核（DMSK）模块，根据全局上下文线索自适应选择核大小，增强网络处理多尺度特征集成的能力。DSC模块具有架构无关性，可以无缝集成到现有的U型网络结构中。
### Conclusion
大量的实验结果表明，提出的DSC模块在基于CNN，Transformer，混合CNN-Transformer和Mamba的U型网络中具有插即用的效果。
## 695. `cs.CV` - 4D雷达上2D分段骨干对点云预测的影响 [PDF](https://arxiv.org/pdf/2509.19644), [HTML](https://arxiv.org/abs/2509.19644)
### Authors
William Muckelroy III,Mohammed Alsakabi,John Dolan,Ozan Tonguz
### Background
LiDAR通过提供密集且精确的点云表示，增强了周围环境的感知能力，显著提高了道路安全。但是，由于高昂的成本，LiDAR的使用限制了高级自动驾驶系统在商用车辆中的普及。此前，研究人员通过训练神经网络，使用LiDAR点云作为真实值，成功用4D雷达生成类似LiDAR的3D点云。典型的案例包括采用模块化2D卷积神经网络作为骨干网络，核心是使用了时空一致性网络（Temporal Coherence Network），并通过RaDelft数据集进行训练的雷达目标检测器（参见arXiv:2406.04723）。
### Innovation
本研究探讨了更高能力的分割骨干对生成的点云质量的影响。结果显示，虽然非常高容量的模型可能反而会降低性能，但最佳的分割骨干可以提高23.7%的表现，超过当前最先进的技术。
### Conclusion
研究结果表明，适配的分割骨干网络（2D backbone）对于提高雷达生成点云的质量至关重要，能够显著提升自动驾驶系统的性能。
## 696. `cs.CV` - TimeScope：长视频中面向任务的时域定位 [PDF](https://arxiv.org/pdf/2509.26360), [HTML](https://arxiv.org/abs/2509.26360)
### Authors
Xiangrui Liu,Minghao Qin,Yan Shu,Zhengyang Liang,Yang Tian,Chen Jason Zhang,Bo Zhao,Zheng Liu
### Background
在长视频中识别关键时刻对于下游的理解和推理任务至关重要。传统的方法在处理这类问题时表现不佳，因为它们难以处理长视频并在长视频中实现一贯性。
### Innovation
提出了一个新的问题，任务导向的时序定位（ToTG），其目标是根据任务的自然描述定位包含必要信息的时间区间。为此，作者提出了TimeScope框架，该框架基于逐步推理。同时，还建立了ToTG Bench基准和ToTG Pile数据集来提升TimeScope的能力。
### Conclusion
广泛的实验表明TimeScope在各种设置下始终优于现有的时序定位方法和流行的MLLMs，证明了该方法在解决这一新的挑战性问题上的有效性。
## 697. `cs.CV` - 可编辑噪声图逆向映射：将目标图像编码为噪声以实现高保真图像操作 [PDF](https://arxiv.org/pdf/2509.25776), [HTML](https://arxiv.org/abs/2509.25776)
### Authors
Mingyu Kang,Yong Suk Choi
### Background
文本到图像扩散模型已经取得了显著的成功，能够生成高质量且多样的图像。基于这些进展，扩散模型也在文本引导的图像编辑中展现了卓越的性能。有效的图像编辑策略通常涉及将源图像逆变为与目标图像相关的可编辑噪声图。然而，之前的逆向方法在紧密遵循目标文本提示方面面临挑战。由于逆向得到的噪声图虽然能忠实重建源图像，但限制了对所需编辑的灵活性。
### Innovation
本文提出了可编辑噪声图逆向映射（ENM Inversion），这是一种创新的逆向技术，用于寻找最佳的噪声图以确保内容保真度和可编辑性。通过分析噪声图以增强编辑性，方法引入了一种可编辑噪声细化，通过最小化重建噪声图与编辑噪声图之间的差异，使其与期望的编辑对齐。
### Conclusion
通过广泛的实验证明，ENM Inversion在各种图像编辑任务中的保真度和编辑保真度都优于现有方法。此外，该方法还可以轻松应用于视频编辑，实现帧间的时序一致性和内容操作。
## 698. `cs.CV` - RangeSAM: 利用视觉基础模型进行代表范围视图的激光雷达分割 [PDF](https://arxiv.org/pdf/2509.15886), [HTML](https://arxiv.org/abs/2509.15886)
### Authors
Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Dieter Fellner,Saptarshi Neil Sinha
### Background
点云分割对自动驾驶和3D场景理解至关重要。虽然基于体素和点的方法在最近的研究中占据了主导地位，因为它们与深度架构兼容且能够捕捉精细几何结构，但这些方法通常会导致高计算成本、不规则的内存访问以及有限的实时效率。相比之下，尽管较未被广泛探索的范围视图方法却可以利用成熟的2D语义分割技术进行快速准确的预测。受到视觉基础模型(VFMs)在视觉captioning、零样本识别和多模态任务中的快速发展启发，本研究探索是否可以将当前在分割任务中处于领先地位的SAM2作为激光雷达点云分割的强有力骨干，在范围视图中应用。
### Innovation
本文提出了首个将SAM2适应3D分割的范围视图框架，结合了高效2D特征提取和标准投影/反投影操作来处理点云数据。为了优化SAM2以适应范围视图表示，我们对编码器的结构进行了几个修改：(1) 一种新颖的模块，强调LiDAR范围图像中考量水平空间依赖性的重要性；(2) 为球面投影特制的配置；(3) 在编码器骨干中设计的机制，以捕获范围视图伪图像中存在的独特空间模式和不连续性。该方法在SemanticKITTI上达到了具有竞争力的性能，同时能够受益于2D为中心的工作流程的速度、可扩展性和部署简单性。通过利用视觉基础模型作为3D感知的通用骨干，该工作提供了一种统一的基础模型驱动的激光雷达分割路径，并展示了使用VFMs进行范围视图分割的方法具有潜力的前景。
### Conclusion
使用视觉基础模型进行范围视图分割的方法得到了令人鼓舞的结果，这表明VFMs作为3D感知的通用骨干是可行的，并开启了激光雷达分割的基础模型驱动的统一路径。
## 699. `cs.CV` - 医学视觉语言模型的评估与缓解 [PDF](https://arxiv.org/pdf/2509.21979), [HTML](https://arxiv.org/abs/2509.21979)
### Authors
Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu
### Background
视觉语言模型（VLMs）正在逐渐融入临床工作流程中，但这些模型常常表现出奉承行为，倾向于对用户的表达社交暗示或感知权威给予优先考虑，而不是基于证据的推理。这项研究通过一个新的临床应用背景下的基准，评估了医学可视化问答中的临床奉承现象。模型表现出了不同程度的奉承，尤其是在面对心理动机的压力模板时，无论模型的准确性或大小，展现出了不同程度的对抗性响应，这表现出模型内部偏见与视觉证据无关。因此，研究需要一种新的策略来减轻这种方法带来的影响，使模型在临床工作者互动中更好地表现其诊断推理能力，增强基于证据的防御措施的必要性是进一步研究的重点。
### Innovation
研究提出了一个基于PathVQA、SLAKE和VQA-RAD的医学奉承数据集，通过构造不同器官系统和模态的数据来评估医学VLMs的奉承行为，并提出了一个名为Visual Information Purification for Evidence based Response (VIPER)的轻量级缓解策略，该策略能够过滤掉非证据性内容，例如社交压力，并生成受限的基于证据的回答。该框架能够在保持解释性的同时显著降低奉承现象，优于基准模型。
### Conclusion
这项研究的基准分析和缓解框架为医学VLMs在临床交互中的稳健部署奠定了基础，强调了基于证据的防御措施的必要性。
## 700. `cs.CV` - 在MLLM中不要只追求“高亮的视觉标记”：重新审视视觉整体语境保留 [PDF](https://arxiv.org/pdf/2510.02912), [HTML](https://arxiv.org/abs/2510.02912)
### Authors
Xin Zou,Di Lu,Yizhou Wang,Yibo Yan,Yuanhuiyi Lyu,Xu Zheng,Linfeng Zhang,Xuming Hu
### Background
尽管多模态大型语言模型（MLLMs）具有强大的能力，但由于对大量视觉标记的依赖，它们会面临显著的计算开销问题。近期研究表明，通过文本-视觉跨注意力或[CLS]注意力对冗余视觉标记进行修剪可以缓解这一问题。然而，现有的基于注意力的标记修剪方法具有一个关键的局限性，即它们倾向于保留语义相似的标记，导致在高修剪率下性能显著下降。
### Innovation
本文提出了HoloV，一种简单而有效的插即用视觉标记修剪框架，用于提高推理效率。HoloV不同于现有的基于注意力的方案，从整体视角重新思考标记保留，通过在不同空间裁剪中适应性分配修剪预算，确保保留的标记能够捕获全局视觉语境，而非孤立的显著特征，从而减少了表征塌陷并保持任务相关信息，即使在激进的修剪下也是如此。
### Conclusion
实验结果表明，与当前最佳方法相比，HoloV在各种任务、MLLM架构和修剪率下均实现了更好的性能，例如，配装了HoloV的LLaVA1.5在修剪88.9%的视觉标记后，保留了95.8%的原始性能，实现更优的效率-准确度权衡。
## 701. `cs.CV` - 2025 CARE肝脏任务挑战的第一解决方案：对比增强的半监督分割与泛化和测试时自适应 [PDF](https://arxiv.org/pdf/2510.04243), [HTML](https://arxiv.org/abs/2510.04243)
### Authors
Jincan Lou,Jingkun Chen,Haoquan Li,Hang Li,Wenjian Huang,Weihua Chen,Fan Wang,Jianguo Zhang
### Background
从对比增强的MRI中准确分割肝脏对于诊断、治疗计划和疾病监测至关重要，但仍然具有挑战性。这主要是由于标注数据有限、不同的强化协议以及跨扫描器和机构间的显著领域偏移。传统的图像到图像翻译框架虽然在领域泛化方面取得了巨大进步，但在实际应用中并不直接。例如，Pix2Pix需要图像配准，而cycle-GAN无法无缝集成到分割管道中。这些方法主要针对跨模态场景，常常引入结构失真，且在训练过程中不稳定，这在单模态场景中可能带来不利影响。
### Innovation
提出了一种基于nnU-Netv2的紧凑型分割框架CoSSeg-TTA，结合了半监督的mean teacher方案以利用大量未标注的数据。框架还包含一个领域适应模块，该模块使用随机化直方图基础风格外观转换函数和可训练的对比度感知网络来丰富领域多样性并减轻中心间变异性。此外，采用了一种持续的测试时自适应策略来提高推理的鲁棒性。实验结果表明，该框架在Dice分数和Hausdorff距离方面优于nnU-Netv2基线，在低标注条件下表现出强大的跨领域泛化能力。
### Conclusion
本文提出了CoSSeg-TTA框架，该框架在未标注数据丰富的条件下，通过半监督学习和领域适应技术，实现了肝脏分割的高性能表现和跨领域泛化能力。
## 702. `cs.CV` - TBStar-Edit：从图像编辑模式转换到一致性增强 [PDF](https://arxiv.org/pdf/2510.04483), [HTML](https://arxiv.org/abs/2510.04483)
### Authors
Hao Fang,Zechao Zhan,Weixin Feng,Ziwei Huang,Xubin Li,Tiezheng Ge
### Background
近期图像生成和编辑技术的进步使得最先进的模型在通用领域取得了令人印象深刻的结果。但是，在应用于电子商务场景时，这些通用模型往往面临一致性限制的挑战。为了应对这一挑战，我们引入了TBStar-Edit，一种专门针对电子商务领域的图像编辑模型。通过严格的数据库构建、模型架构设计和训练策略，TBStar-Edit实现了精确且高保真的图像编辑，同时保持了产品外观和布局的完整性。
### Innovation
我们的创新点在于：1）建立了全面的数据构建管道，包括数据收集、构建、过滤和增强，以获得高质量、指令跟随且高度一致的编辑数据，支持模型训练。2）设计了分层模型框架，包括基础模型、模式转换模块和一致性增强模块。3）采用了两阶段训练策略来增强一致性保留：第一阶段为编辑模式转换，第二阶段为一致性增强。每个阶段分别使用不同的数据集训练不同时期的模块。
### Conclusion
我们在自拟的电子商务基准上进行了广泛的TBStar-Edit评估，结果显示，TBStar-Edit在客观指标（VIE评分）和主观用户偏好方面均优于现有的通用领域编辑模型。
## 703. `cs.CV` - 从字幕到关键帧：KeyScore多模态帧评分与视频-语言理解 [PDF](https://arxiv.org/pdf/2510.06509), [HTML](https://arxiv.org/abs/2510.06509)
### Authors
Shih-Yao Lin,Sibendu Paul,Caren Chen
### Background
现有的视频理解方法在选择关键帧时依赖于启发式方法、忽略语义信息或产生冗余帧，这导致了效率低下且结果不精准的问题。
### Innovation
提出了KeyScore，这是一种基于字幕的帧评分方法，结合了语义相似性、时间代表性以及上下文缺失影响三个互补信号。此外，还提出了STACFP时空自适应聚类方法，用于生成长视频中多样化且紧凑的帧提案。通过这些方法，减少了无信息的帧，同时保留了关键内容，使得推理更快更准确。
### Conclusion
实验结果显示，结合STACFP和KeyScore方法在多标准视频-语言基准测试（MSRVTT、MSVD、DiDeMo）中相比全帧处理减少高达99%的帧，同时优于均匀8帧编码器在视频文本检索、关键帧提取和动作识别任务中的表现。通过关注语义相关帧，该方法提高了效率和性能，使视频理解更具扩展性和基于字幕的特性。
## 704. `cs.CV` - ALISE：无需标注的激光雷达实例分割 [PDF](https://arxiv.org/pdf/2510.05752), [HTML](https://arxiv.org/abs/2510.05752)
### Authors
Yongxuan Lyu,Guangfeng Jiang,Hongsi Liu,Jun Liu
### Background
户外激光雷达点云的手动标注实例分割工作非常耗时且成本高。尽管现有方法试图减轻这种负担，但仍依赖于某种形式的人工标注。为彻底消除这种依赖，本文引入了ALISE，这是一种无需任何标注就能执行激光雷达实例分割的新框架。其核心挑战是如何以完全无监督的方式生成高质量的伪标签。现有的方法通常是部分依赖人工标注或完全无法实现无需标注的实例分割，因而对完全无需标注的实例分割技术有着巨大的需求和挑战。
### Innovation
本文提出了ALISE框架，这是一种完全无监督的激光雷达实例分割方法。创新点在于使用Vision Foundation Models (VFMs)生成初始伪标签，并通过专门的空间-时间投票模块进一步精炼这些标签。此外，引入了两种形式的语义监督：基于2D先验的信息注入到3D网络中的损失函数，以及一种新颖的基于原型的对比损失函数，通过利用3D语义一致性构建区分性特征空间。这一综合设计取得了显著的性能提升，并在无监督3D实例分割中建立了新的最先进水平。特别值得一提的是，当使用未标注的数据时，该方法优于基于真实2D边界框的MWSIS方法，在mAP指标上高出2.53%（50.95% vs. 48.42%）。
### Conclusion
ALISE框架通过无监督的方式生成高质量伪标签，并通过多种语义监督改进了特征学习，从而在无监督3D实例分割中达到了最先进的性能，甚至在某些情况下优于监督型方法。这些发现为自动驾驶等应用中的激光雷达点云实例分割提供了强有力的支持。
## 705. `cs.CV` - 通过LiDAR的视角：一种特征丰富且具有不确定性意识的点云标注管道 [PDF](https://arxiv.org/pdf/2510.06582), [HTML](https://arxiv.org/abs/2510.06582)
### Authors
Fei Zhang,Rob Chancia,Josie Clapp,Amirhossein Hassanzadeh,Dimah Dera,Richard MacKenzie,Jan van Aardt
### Background
准确的陆地激光扫描（TLS）点云语义分割受限于昂贵的手动注释。现有方法依赖于大量的手动标注，这导致了时间和成本的增加，同时降低了标注的效率。
### Innovation
本文提出了一种半自动的、具有不确定性意识的管道，结合了球面投影、特征增强、集成学习和目标注释，以减少人工标注的工作量，同时保持高精度。该方法通过球面投影3D点到2D网格，使用多源特征增强像素，并训练多个分割网络生成伪标签和不确定性图，后者指导对模糊区域的注释。2D输出再反投影到3D，产生精细标注的点云，由三级可视化套件支持（2D特征图、3D带色点云和紧凑虚拟球体），用于快速筛选和审稿人指导。
### Conclusion
通过该管道，我们构建了Mangrove3D语义分割TLS数据集，并通过ForestSemantic和Semantic3D跨数据集测试验证了特征增强策略的一般性。结果表明性能在约12个注释扫描后饱和，几何特征贡献最大，紧凑的九通道堆栈捕获了几乎所有判别能力，平均交并比（mIoU）在约0.76左右达到平台期。本研究贡献包括：（i）一种稳健的、具有不确定性意识的TLS标注管道，带有可视化工具；（ii）Mangrove3D数据集；（iii）数据效率和特征重要性方面的实际指导，从而实现TLS点云高效高质的语义分割。该项目的数据集和处理脚本可在此 https://链接获取。
## 706. `cs.CV` - 面向多模态深度感知的嵌入式参考理解方法 [PDF](https://arxiv.org/pdf/2510.08278), [HTML](https://arxiv.org/abs/2510.08278)
### Authors
Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel
### Background
嵌入式参考理解需要基于语言指令和指向提示在视觉场景中识别目标对象。此前的工作虽然在开放词汇对象检测方面取得了进展，但在存在多个候选对象的模糊场景中常常表现不佳。
### Innovation
本文提出了一种新的嵌入式参考理解（ERU）框架，结合了基于大规模语言模型的数据增强、深度图模态和深度感知决策模块，增强语言和实体线索的融合，提高复杂或杂乱环境中的消歧能力。实验结果表明，该方法显著优于现有基线，实现了更准确可靠的指代检测。
### Conclusion
实验结果显示，本方法在两个数据集上显著优于现有基线，实现了更准确可靠的指代检测。
## 707. `cs.CV` - GTR-Bench: 评估视觉语言模型中的地理时空推理 [PDF](https://arxiv.org/pdf/2510.07791), [HTML](https://arxiv.org/abs/2510.07791)
### Authors
Qinghongbing Xie,Zhaoyuan Xia,Feng Zhu,Lijun Gong,Ziyue Li,Rui Zhao,Long Zeng
### Background
视觉-语言模型（VLMs）的时空智能近年来因其在自动驾驶、具身人工智能和通用人工智能中的重要性而受到广泛关注。现有的时空基准主要侧重于以自我为中心视角的图像/视频语境推理或地理视角的图形（如地图）语境推理，但未能评估VLMs在同时结合图像/视频和图形语境下的地理时空智能，这一点在交通管理和紧急响应等领域非常重要。为此，作者引入了Geo-Temporal Reasoning基准（GTR-Bench），这是一个新的挑战，用于评估一个大规模摄像网络中移动目标的地理时空推理。
### Innovation
GTR-Bench 是一个全新的基准，用于评估视觉语言模型在大规模摄像网络中对移动目标的地理时空推理能力。该基准在多个地图和视频视角之间切换、多视频间的联合推理以及未被任何视频覆盖的空间-时间区域推理等方面更具挑战性。评估超过10种流行的视觉语言模型表明，即使是最先进的自产模型，Gemini-2.5-Pro（34.9%），在地理时空推理方面的表现也远落后于人类的表现（78.61%）。此外，对GTR-Bench的全面分析揭示了当前模型在地理时空推理方面的三个主要缺陷：（1）VLMs对空间-时间语境的利用存在失衡；（2）VLMs在时间预测方面较弱，导致在重时间强调的任务中表现不如空间重要性任务；（3）VLMs缺乏理解和或对齐地图数据与多视角视频输入的能力。
### Conclusion
GTR-Bench 提供了宝贵的见解，并为时空智能的研究和应用打开了新机会。基准和代码将会在给定的链接中公开。
## 708. `cs.CV` - RetouchLLM：基于视觉语言模型的无需训练代码化图像润色 [PDF](https://arxiv.org/pdf/2510.08054), [HTML](https://arxiv.org/abs/2510.08054)
### Authors
Moon Ye-Bin,Roy Miles,Tae-Hyun Oh,Ismail Elezi,Jiankang Deng
### Background
图像润色不仅能够提升视觉效果，还能表达个人偏好和情感。然而，现有的基于学习的方法需要大量配对数据，并且作为黑盒操作，使润色过程变得透明，限制了其对不同类型、用户或图像特定调整的适应性。
### Innovation
提出了一种无需训练的白盒图像润色系统RetouchLLM，能够直接在高分辨率图像上进行可解释的代码化润色。该框架通过类似于人工多步骤润色的方式渐进性地提升图像，并包含一个视觉批评模块和一个代码生成模块。该系统展示了在不同润色风格上的广泛应用能力，并通过自然语言交互实现可解释和可控的用户意图调整。
### Conclusion
实验结果证明，该方法具有广泛的应用能力，能够快速适应不同的润色需求，并通过自然语言提供的用户交互实现用户意图的精准调整。
## 709. `cs.CV` - 一箭双雕：一种空白文本与空白频率感知的扩散模型用于文本引导的图像修复 [PDF](https://arxiv.org/pdf/2510.08273), [HTML](https://arxiv.org/abs/2510.08273)
### Authors
Haipeng Liu,Yang Wang,Meng Wang
### Background
文本引导的图像修复旨在根据文本提示恢复被掩盖的区域，长期面临的是保持未遮盖区域的完整性以及实现两者之间的语义一致性。以往的研究未能同时解决这两个问题，只能够在其中之一进行优化。我们观察到，这种现象源自于编码不同图像属性的混合（例如，中频和低频）频带的纠缠，在去噪过程中这些频带对文本提示表现出不同的鲁棒性。在这篇论文中，我们提出了一个名为NTN-Diff的基于扩散模型的解决方案，通过将语义一致性分解为每种频带的一致性，同时保留未遮盖的区域，以解决两个挑战。这项工作的出发点是基于扩散过程将去噪过程分为早期（高频噪声去除）和晚期（低频噪声去除）阶段，在去除噪声过程中分离中间高频和低频段。通过这一过程，趋于稳定的中频段被语义对齐，同时也为包含被遮盖区域的低频噪声去除过程提供了引导。
### Innovation
我们提出了一种称为NTN-Diff的空白文本与空白频率感知的扩散模型，它将语义一致性分解为每个频带的一致性，同时保留未遮盖的区域。NTN-Diff通过分离扩散过程的高频和低频噪声去除阶段，逐步去除频带中的噪声，从而实现语义一致性，同时保持未遮盖区域的完整性。这在以往的工作中是未曾实现的。我们还观察到，稳定的中频段在文本引导的去噪过程中逐渐趋于语义对齐，为低频噪声去除提供了指导，最终实现了在遮盖和未遮盖区域之间不同频带的语义一致性。
### Conclusion
广泛的实验验证了NTN-Diff相对于现有的扩散模型在文本引导的图像修复任务中的优越性。本研究提出的NTN-Diff模型对于图像修复任务中的两个关键挑战提供了有效的解决方案，验证了该模型的有效性和优越性。
## 710. `cs.CV` - 基于频率导向后验采样的扩散模型驱动的图像恢复方法 [PDF](https://arxiv.org/pdf/2411.15295), [HTML](https://arxiv.org/abs/2411.15295)
### Authors
Darshan Thaker,Abhishek Goyal,René Vidal
### Background
图像恢复旨在从退化观测中恢复高质量的图像。当退化过程已知时，恢复问题可以被建模为逆问题。最近，现代预训练的扩散模型已被用于图像恢复，通过修改其采样过程以适应退化过程。然而，这些方法通常依赖于某些近似，可能产生显著的误差和样本质量问题。本文在统计假设下首次对退化线性逆问题中的近似误差进行严谨分析，示证了以往工作可能存在灾难性失效的情形。根据理论洞见，提出了简单修改扩散模型图像恢复方法。该方法引入时间变化的低通频率滤波器，在测量的频域中进行频率的逐渐引入。根据数据分布开发了一些自适应的训练课程。方法显著提高了在运动去模糊和图像除雾等具有挑战性的图像恢复任务上的性能
### Innovation
提出了一种基于频率导向后验采样的扩散模型驱动的图像恢复方法。通过引入时间变化的低通频率滤波器，在测量的频域中进行频率的逐渐引入，并根据数据分布开发一些自适应的训练课程。这种方法显著提高了在具有挑战性的图像恢复任务上的性能
### Conclusion
该方法对退化线性逆问题中的近似误差进行严谨分析，展示了以往工作的失效情形，并且通过引入频率滤波器的方法在运动去模糊和图像除雾等任务中显著提高了性能。
## 711. `cs.CV` - 学习神经曝光场以进行视图合成 [PDF](https://arxiv.org/pdf/2510.08279), [HTML](https://arxiv.org/abs/2510.08279)
### Authors
Michael Niemeyer,Fabian Manhardt,Marie-Julie Rakotosaona,Michael Oechsle,Christina Tsalicoglou,Keisuke Tateno,Jonathan T. Barron,Federico Tombari
### Background
近年来，神经场景表示法在3D重建和视图合成方面的进展显著提高了3D图像的质量。尽管现有的神经网络在针对常见基准数据集和精心策划的数据集时可以提供高质量的结果，但在包含场景间或场景内变化（例如强烈的曝光变化）的数据上，结果容易降级。这些变化在大多数室内外场景或有窗户的房间中最为常见。这项研究针对的是使用现实世界捕获中复杂数据进行高精度3D建模的传统挑战。因此，论文提出了一种基于神经网络的曝光预测方法，以优化视图合成中的曝光条件，从而提升质量并满足3D一致性需求。
### Innovation
本文提出了一种新颖的曝光预测模型——神经曝光场(Neural Exposure Fields, NExF)，这是一种用于优化复杂数码拍摄的3D场景重建和视图合成的新技术。NExF的核心思想是在3D空间中而非传统像素层面进行优化，倡导了一种新的神经空间条件机制，该机制在场景表示和曝光场之间实现协同优化。此外，论文使用了迄今提出的内容最为丰富的神经网路进行曝光值的预测，并展示了一种从根节点训练到整个神经网路的方法。与现有常见方法相比，该方法不仅训练速度更优，而且性能更佳，一些场景中的表现提高了超过55%。
### Conclusion
总之，通过引入基于上下文的神经场预测曝光值的新机制，解决了以往神经场景表示法在应对复杂曝光变化时可靠性不足的问题。该方法展示了对基准测试数据集的高度适应性，同时在训练效率和重建精度上均有所提升。论文对所有类别数据均有显著改善，特别是在强烈曝光变化的场景中表现超群。
## 712. `cs.CV` - Brain2Text 解码模型揭示视觉语义处理的神经机制 [PDF](https://arxiv.org/pdf/2503.22697), [HTML](https://arxiv.org/abs/2503.22697)
### Authors
Feihan Feng,Jingxin Nie
### Background
从神经活动解码感知经验以重构人类感知的视觉刺激和语义内容在神经科学和人工智能中仍是一项挑战。尽管当前的脑解码模型取得了显著进展，但这些模型仍然缺乏与现有的神经科学理论系统的整合和对于潜在神经机制的探索。
### Innovation
提出了一种新的框架，直接将fMRI信号解码为所观看的自然图像的文本描述。没有使用视觉信息训练的新型深度学习模型实现了最先进的语义解码性能，生成了能够捕捉复杂场景核心语义内容的有意义描述。通过对神经解剖学的分析揭示了较高层次的视觉皮层（如MT+复合区、腹侧通路视觉皮层和下顶叶皮层）在视觉语义处理中的关键作用。
### Conclusion
这项工作提供了一种更直接和可解释的框架来进行脑部的语义解码，为探索复杂的语义处理的神经基础提供了新的强有力的方法，进一步完善了分散语义网络的理解，并可能发展出基于大脑的语言模型。
## 713. `cs.CV` - HA-VLN 2.0: 考虑动态多人交互的离散和连续环境中人类意识导航的一个开放基准和排行榜 [PDF](https://arxiv.org/pdf/2503.14229), [HTML](https://arxiv.org/abs/2503.14229)
### Authors
Yifei Dong,Fengyi Wu,Qi He,Zhi-Qi Cheng,Heng Li,Minghan Li,Zebang Cheng,Yuxuan Zhou,Jingdong Sun,Qi Dai,Alexander G Hauptmann
### Background
现有的视觉-语言导航（VLN）研究主要集中在离散或连续设置上，但很少关注动态、拥挤的环境。当前的基准和评价标准主要侧重于单一导航准确性，缺乏对个人空间和社交互动的关注，这限制了其在复杂环境下导航的能力和安全性。该论文旨在填补这一空白，引入了一个统一的基准，旨在通过明确增设社交认知约束来改善导航的鲁棒性和安全性，特别是在面对人类行为动态和不完全可观察性时的能力。
### Innovation
该论文的主要贡献包括：(i) 一个标准化任务和度量标准，既能捕捉目标精确性也能体现出个人空间的遵守情况；(ii) 针对多个现实场景的新数据集（HAPS 2.0）和模拟器，包括多人互动、户外环境和细致的语言-运动对齐；(iii) 基于16,844条实用性强的指导性指令的基准测试，揭示了领先代理在人类动态和部分可观察性下的显著性能下降；(iv) 实用的机器人实验验证了模拟到现实转移的有效性，并提供了一个开放的排行榜以促进透明比较。这些创新为人类中心的导航研究提供了坚实的基础，提高了安全性与社会责任感。
### Conclusion
通过发布数据集、模拟器、基线和协议，HA-VLN 2.0不仅为安全、负责任的导航研究提供了坚实的基础，而且还证明了明确的社会建模可以提高导航的鲁棒性并减少碰撞，强调了人类中心方法的必要性。
## 714. `cs.CV` - SMF: 使用动能代码实现无模板和无调整架的动画转换 [PDF](https://arxiv.org/pdf/2504.04831), [HTML](https://arxiv.org/abs/2504.04831)
### Authors
Sanjeev Muralikrishnan,Niladri Shekhar Dutt,Niloy J. Mitra
### Background
动画重定向将稀疏的动作表示（如关键点序列）应用于角色网格，以生成时空连贯的全身网格序列。现有方法存在诸多限制，比如需要基于模板的形状先验或艺术家设计的变形架，难以泛化到未见的动作或形状，或者会导致动作抖动。
### Innovation
本文提出了一个无需特定数据集注解、模板或架的自监督框架——自我监督运动场（Self-supervised Motion Fields，SMF）。该方法通过新型自动编码器基稀疏动作编码（Kinetic Codes），在大规模训练中暴露了富有语义的潜在空间。该架构包括专用的空间和时间梯度预测器，它们以端到端方式联合训练。通过Kinetic Codes的潜在空间正则化，联合网络能够很好地泛化到未见的形状和新的动作。
### Conclusion
本文方法在AMASS数据集上对未见动作进行了评估，展示了在未见动作泛化方面的最新最佳结果（State-of-the-Art），并且代码、权重和补充材料可在项目网页上获取。
## 715. `cs.CV` - 免费的协方差：利用均值分布进行无需训练的联邦学习 [PDF](https://arxiv.org/pdf/2412.14326), [HTML](https://arxiv.org/abs/2412.14326)
### Authors
Dipam Goswami,Simone Magistri,Kai Wang,Bartłomiej Twardowski,Andrew D. Bagdanov,Joost van de Weijer
### Background
使用预训练模型可以减少数据异质性的影响，加速联邦学习算法。近期研究探索了无需训练的方法，通过客户端数据的第一和第二阶统计量汇总，从而在不进行任何训练的情况下保持高性能。在本文中，我们提出了一种无需训练的方法，基于类协方差的无偏估计，仅使用客户端发送的类均值的第一阶统计量。我们展示了这些估计的类协方差如何被用来初始化全局分类器，而无需实际共享协方差。我们还表明，仅使用类内部协方差来初始化分类器效果更好。我们的方法在相同的通信成本下比仅共享类均值的方法性能提升在4-26%之间，且其性能可媲美或优于仅共享二阶统计量的方法，但通信开销大大减少。我们的方法比联邦提示调整方法更节能，并且仍然表现更优。最后，使用我们的方法初始化分类器并进一步进行联邦微调或线性探查，可以进一步提升性能。
### Innovation
提出了一种无需训练的方法，基于类协方差的无偏估计，仅使用客户端发送的类均值的第一阶统计量。该方法展示了利用估计的类协方差来初始化全局分类器的方法，且仅使用类内部协方差来初始化分类器效果更好。我们的方法在相同的通信成本下比仅共享类均值的方法性能提升在4-26%之间，且其性能可媲美或优于仅共享二阶统计量的方法，但通信开销大大减少。同时，我们的方法比联邦提示调整方法更节能，并且仍然表现更优。
### Conclusion
我们的方法在相同的通信成本下提升了4-26%的性能与使用类均值相比，性能竞争或更优，通信开销大大减少。我们的方法比联邦提示调整方法更节能，并且性能更优。初始化分类器后进行联邦微调或线性探查可以进一步提升性能。
## 716. `cs.CV` - TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis [PDF](https://arxiv.org/pdf/2504.05684), [HTML](https://arxiv.org/abs/2504.05684)
### Authors
Tri Ton,Ji Woo Hong,Chang D. Yoo
### Background
该论文介绍了一种新颖的基于流式变换器的时间步自适应表示对齐（Timestep-Adaptive Representation Alignment, TRA）与起始感知条件（Onset-Aware Conditioning, OAC）框架，用于高保真度和时域一致性视频到音频合成。
### Innovation
该框架引入了以下两项关键创新：(1) 时间步自适应表示对齐（TRA），通过基于噪声计划调整对齐强度来动态对齐潜在表示，确保平滑演化并提高保真度；(2) 起始感知条件（OAC），将起始标记集成到音频有关的视觉时刻中，以增强与动态视觉事件的同步。
### Conclusion
在VGGSound和Landscape数据集中进行的大量实验表明，TARO在FAD、FD和对齐精度方面均优于先前方法，表现出更高质量的音频和更高精度的同步，具体指标分别是53%的较低Frechet Distance (FD)，29%的较低Frechet Audio Distance (FAD)，97.19%的对齐精度。
## 717. `cs.CV` - CLIP的鲁棒性：需要一个鲁棒的文本编码器 [PDF](https://arxiv.org/pdf/2506.03355), [HTML](https://arxiv.org/abs/2506.03355)
### Authors
Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher
### Background
对抗性输入攻击可以显著改变CLIP嵌入。这影响了包含CLIP的下游鲁棒模型，如文本到图像生成模型或大型视觉语言模型的鲁棒性。虽然一些努力已经致力于使CLIP图像编码器变得鲁棒，但文本编码器的鲁棒性仍是一个未被探索的领域。
### Innovation
本文提出了一种名为LEAF的高效对抗性微调方法，专门针对文本领域，并能够扩展到大型CLIP模型。模型在零样本攻击准确性上取得了显著改进，同时保持了由鲁棒图像编码器提供的视觉性能。结合文本到图像的扩散模型，可以在对抗性噪音下提高生成质量。在多模态检索任务中，LEAF在对抗性噪音下的检索率优于标准CLIP模型。此外，本文表明鲁棒文本编码器有助于直接优化其嵌入的输入文本的重构。
### Conclusion
我们开源了代码（this https URL）和模型（this https URL）。
## 718. `cs.CV` - 您的扩散模型内部是什么？基于得分的黎曼度量以探索数据流形 [PDF](https://arxiv.org/pdf/2505.11128), [HTML](https://arxiv.org/abs/2505.11128)
### Authors
Simone Azeglio,Arianna Di Bernardo
### Background
最近，扩散模型在捕捉复杂图像分布方面表现出色，但学习的数据流形的几何特性依然研究不足。该研究通过引入基于扩散模型的斯坦因得分函数的得分基于黎曼度量填补这一空白，无需显式参数化即可表征数据流形的内在几何特性。方法在相空间中定义度量张量，使得度量在流形相垂直方向拉伸，沿流形切线方向保持不变，从而创建一个使得测地线自然跟随流形轮廓的几何结构。研究人员开发了计算这些测地线的高效算法，并展示该方法在数据点之间插值及超出观测数据分布外推上的实际应用。通过合成数据（已知几何）、Rotated MNIST 和通过Stable Diffusion生成的复杂自然图像实验，结果表明，得分基于测地线捕捉符合底层数据分布的意义上变换。该方法在感知度量（LPIPS）和分布度量（FID、KID）方面优于基准方法，产生更平滑、更真实的图像过渡。这些结果揭示了扩散模型中隐含的几何结构，并提供了一种通过黎曼几何视角导航自然图像流形的原理方法。
### Innovation
提出了基于Stein得分函数的得分基于黎曼度量，无需显式参数化即可表征数据流形的内在几何特性。该方法定义了相空间中度量张量的方法，使得在流形相垂直方向拉伸度量，在流形切线方向保持度量不变。通过高效算法计算测地线，并展示了其在数据点之间插值及其超出观测数据分布外推的实用性。实验结果显示了该方法在感知度量和分布度量方面优于基准方法，从而揭示了扩散模型中隐含的几何结构，并提供了一种通过黎曼几何视角导航自然图像流形的原理方法。
### Conclusion
实验结果显示，得分基于测地线能够捕捉符合底层数据分布的意义上变换。得分基于几何的方法在感知度量（LPIPS）和分布度量（FID, KID）方面优于基准方法，生成更平滑、更真实的图像过渡。这些结果揭示了扩散模型中隐含的几何结构，并提供了一种通过黎曼几何视角导航自然图像流形的原理方法。
## 719. `cs.CV` - Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs [PDF](https://arxiv.org/pdf/2506.07180), [HTML](https://arxiv.org/abs/2506.07180)
### Authors
Wenrui Zhou,Mohamed Hendy,Shu Yang,Qingsong Yang,Zikun Guo,Yuyu Luo,Lijie Hu,Di Wang
### Background
随着视频大型语言模型（Video-LLMs）越来越多地被集成到需要多模态推理的应用中，确保它们的准确性和可靠性变得至关重要。然而，这些模型倾向于与用户输入保持一致，即使这与视觉证据相矛盾，这降低了它们在相关应用中的可信度。当前的研究很大程度上忽视了视频语言领域中这种行为的具体表现，缺乏系统性的基准测试和专门的评估来理解 Video-LLMs 在误导性用户输入下的反应。
### Innovation
本文提出了 VISE（视频-LLM 攀谀行为基准测试与分析），第一个专门用于评估最先进的视频-LLMs 在不同问题格式、提示偏见和视觉推理任务下的攀谀行为的基准。此外，提出了两种无需训练的缓解策略：通过可解释的关键帧选择增强视觉接地，以及通过在推理时间通过针对性的干预来引导模型行为远离攀谀。
### Conclusion
VISE 为视频-LLMs 在视频领域的攀谀行为提供了详细的分析框架，并提出了解决这些问题的潜在路径，有助于提高视频-LLMs 的可靠性和可信度。相关代码已公开。
## 720. `cs.CV` - 使用自监督学习理解冰晶习性多样性 [PDF](https://arxiv.org/pdf/2509.07688), [HTML](https://arxiv.org/abs/2509.07688)
### Authors
Joseph Ko,Hariprasath Govindarajan,Fredrik Lindsten,Vanessa Przybylo,Kara Sulia,Marcus van Lier-Walqui,Kara Lamb
### Background
冰含云对气候变化有重大影响，但由于冰晶形态多样性（即形状）难以建模，因此它们的建模具有挑战性。通过利用自监督学习（SSL）从冰晶图像中学习隐形表示，这项研究旨在克服这一难题，旨在开发出模型冰晶形态的稳定表示方法，这些表示方法可用于各种以科学为导向的任务。
### Innovation
论文的主要创新在于使用自监督学习来学习冰晶形态的隐藏表示。通过使用许多云粒子图像对视觉变换器进行预训练，该研究学习到了鲁棒的隐表示形态，这些表示可以用于各种科学驱动的任务。同时，该研究验证了自监督学习方法可以用于学习有意义的表示，以及展示了如何使用这些隐表示来量化冰晶多样性。
### Conclusion
研究表明，基于自监督学习驱动的表示能够提高冰晶特性的表征，从而限制其在地球气候系统中的作用。这些成果展示了自监督学习在理解和建模冰晶形态中的强大潜力。
## 721. `cs.CV` - G$^2$RPO: Granular GRPO for Precise Reward in Flow Models [PDF](https://arxiv.org/pdf/2510.01982), [HTML](https://arxiv.org/abs/2510.01982)
### Authors
Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai
### Background
将在线强化学习（RL）整合到扩散和流模型中，已成为使生成模型与人类偏好对齐的有前景方法。在消噪过程中使用随机微分方程（SDE）进行随机采样，以生成多种消噪方向，用于RL探索。尽管现有的方法有效地探索了高价值样本，但由于稀疏和狭窄的奖励信号，导致了偏好对齐的不足。
### Innovation
提出了一种新的Granular-GRPO（G$^2$RPO）框架，实现了在流模型RL中对采样方向精确而全面的奖励评估。引入了唯一的奇异随机采样策略，支持逐步的随机探索，并确保奖励和注入噪声之间有高度的相关性。此外，引入了多粒度优势集成模块，聚合不同扩散尺度计算的优势，生成更全面和稳健的采样方向评估。
### Conclusion
在多个奖励模型上进行的实验表明，G$^2$RPO显著优于现有的基于流的GRPO基线，突显了其有效性和鲁棒性。
## 722. `cs.CV` - 视觉编码器的后训练量化需要前缀寄存器 [PDF](https://arxiv.org/pdf/2510.04547), [HTML](https://arxiv.org/abs/2510.04547)
### Authors
Seunghyeon Kim,Jinho Kim,Taesun Yeom,Wonpyo Park,Kyuyeun Kim,Jaeho Lee
### Background
基于Transformer的视觉编码器在多模态智能中扮演重要角色，驱动从自主网络代理到机器人控制的应用。然而，这些应用对大规模视觉数据的实时处理有较高要求，因此降低视觉编码器的推理成本至关重要。尽管量化是减少推理成本的一种实用方法，但在8位精度下仍面临挑战，主要是由于大规模激活（即异常值）的存在。传统的后训练量化在高精度下难以有效处理异常值问题。
### Innovation
本文提出了一种无需训练的算法RegCache，能够减少视觉编码器中的异常值，使量化后的模型能够以显著较小的精度损失进行量化。其创新点包括：引入可能具有异常值但无语义意义的前缀 token，以及两种技术革新——中间层前缀化和 token 删除，这两种技术专门用于处理视觉编码器中的异常值。
### Conclusion
实验表明，该方法能够一致地提高量化模型的准确度，适用于由文本监督和自我监督训练的视觉编码器。
## 723. `cs.CV` - EMedNeXt: 基于MedNeXt V2和深度监督的Sub-Saharan非洲脑肿瘤分割增强框架 [PDF](https://arxiv.org/pdf/2507.23256), [HTML](https://arxiv.org/abs/2507.23256)
### Authors
Ahmed Jaheen,Abdelrahman Elsayed,Damir Kim,Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Mostafa Salem,Hu Wang,Sarim Hashmi,Mohammad Yaqub
### Background
脑癌影响全球数百万人，尤其是在临床环境中，医生依赖磁共振成像（MRI）来诊断和监测胶质瘤。然而，通过手动分割多参数MRI进行肿瘤量化是一项耗时的工作，需要专家放射科医生参与，并且在资源匮乏的医疗系统中通常不可行。特别是在低收入地区，MRI扫描仪质量较低，放射学专业知识稀缺，导致错误的分割和量化。此外，非洲地区获得的MRI扫描图像数量通常较少。这些挑战在撒哈拉以南非洲（SSA）尤为突出，那里的资源限制和图像质量下降引入了显著的差异。因此，为解决这些问题，BraTS-Lighthouse 2025挑战专注于在SSA中构建强大的肿瘤分割模型。
### Innovation
EMedNeXt是一个基于MedNeXt V2的脑肿瘤分割框架，引入了深监督和针对性的后期处理管道。其创新点包括：1）扩大了感兴趣的区域；2）改进了基于nnU-Net v2的架构基础；3）提出了一种鲁棒的模型集成系统。该框架在隐藏验证集上的性能表现出色，平均病变明智DSC为0.897，平均病变明智NSD在0.5mm和1.0mm的耐受性下分别为0.541和0.84，从而显著提高了肿瘤分割的准确性和可靠性。
### Conclusion
EMedNeXt框架在解决资源限制和图像质量下降方面表现出潜力，能够提供更准确的肿瘤分割结果。
## 724. `cs.CV` - 高频率Mixout: 重新审视Mixout在稳健跨域泛化中的应用 [PDF](https://arxiv.org/pdf/2510.06955), [HTML](https://arxiv.org/abs/2510.06955)
### Authors
Masih Aminbeidokhti,Heitor Rapela Medeiros,Srikanth Muralidharan,Eric Granger,Marco Pedersoli
### Background
混合微调模型结合强大的预训练权重初始化是一种提高在分布迁移下鲁棒性的常见策略，但这种方法伴随着大量的计算成本，因为它需要训练和存储多个模型。Dropout提供了一种轻量级的替代方案，通过随机抑制神经元来模拟模型集合，但在应用于预训练模型时，它倾向于过度正则化并破坏对于泛化至关重要的表征。
### Innovation
本文研究了一种名为Mixout的随机正则化技术，作为Dropout的替代方案，用于域泛化。Mixout在训练过程中通过概率性地将部分微调权重与预训练权重进行替换，而不是抑制神经元，从而在适应和保留先验知识之间取得平衡，以减轻过拟合。研究发现，对于ViTs和ResNets，采用高掩码比率（分别为0.9和0.8）的Mixout在跨域泛化基准测试中表现出更强的性能，这减少了计算开销并显著降低了训练成本，同时仍然达到了与基于模型集合的方法相当的性能。
### Conclusion
实验结果表明，采用高频率Mixout的方法在跨域泛化基准测试中取得了与模型集合方法相当的离域准确率，同时显著降低了训练成本。
## 725. `cs.CV` - 基于频域意识的集成学习方法在2025年BraTS儿童脑肿瘤分割挑战中的应用 [PDF](https://arxiv.org/pdf/2509.19353), [HTML](https://arxiv.org/abs/2509.19353)
### Authors
Yuxiao Yi,Qingyao Zhuang,Zhi-Qin John Xu,Xiaowen Wang,Yan Ren,Tianming Qiu
### Background
儿童脑肿瘤分割具有独特的挑战性，因为这些恶性肿瘤既罕见又具有异质性。然而，这种对临床诊断和治疗计划至关重要的任务仍需改进。我们采用了nnU-Net、Swin UNETR和HFF-Net三种网络进行集成处理，以应对这一挑战。
### Innovation
我们提出了三种关键扩展：为nnU-Net提供可调节初始化比例以控制复杂度，通过从预训练的BraTS 2021模型转移学习以提高Swin UNETR在儿科数据集上的泛化能力，以及在HFF-Net中使用频域分解以分离低频组织轮廓和高频纹理细节。
### Conclusion
我们的最终集成框架将nnU-Net（$boldsymbol{beta}=0.7$）、微调过的Swin UNETR和HFF-Net结合在一起，在未见过的测试数据集上取得了显著的效果，得到了包括CC、ED、ET、NET、TC和WT在内的Dice分数分别为62.7%、83.2%、72.9%、85.7%、91.8%和92.6%。我们的方法在BraTS 2025儿童脑肿瘤分割挑战中获得了第一名（排名第1）。
## 726. `cs.CV` - MorphGen: 可控且形态合理的生成细胞成像 [PDF](https://arxiv.org/pdf/2510.01298), [HTML](https://arxiv.org/abs/2510.01298)
### Authors
Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello
### Background
模拟生化细胞反应的虚拟环境在加速高内涵图像实验中显示出巨大潜力，这对于推动药物发现和基因编辑至关重要。为此，研究人员引入了MorphGen，一种基于扩散的生成模型，用于荧光显微成像，以实现跨多种细胞类型和扰动的可控生成。MorphGen通过与OpenPhenom（一种生物前沿模型）的表型嵌入进行对齐训练，以捕捉与已知细胞形态一致的生物意义模式。
### Innovation
与之前的压缩多通道染色到RGB图像的方法不同，MorphGen可以联合生成完整的荧光通道，保留每个亚细胞结构，从而实现精细的形态分析，这对于生物解释至关重要。此外，与只能生成单个细胞类型RGB图像的先前最佳模型MorphoDiff相比，MorphGen在FID得分上降低了超过35%。这表明MorphGen具有更好的生物一致性和表现力。
### Conclusion
该研究证明了MorphGen的有效性和优势，通过提供详细的荧光通道生成，使得细胞图像的生成更加精细和真实，对于多细胞类型的精确分析具有重要意义。此外，MorphGen还通过CellProfiler特征展示了其生物一致性，并通过代码开源增强了模型的可访问性和可扩展性。
## 727. `cs.CV` - AMFT: 通过元学习最佳模仿与探索平衡来对齐大语言模型推理器 [PDF](https://arxiv.org/pdf/2508.06944), [HTML](https://arxiv.org/abs/2508.06944)
### Authors
Lixuan He,Jie Feng,Yong Li
### Background
大语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）的两阶段管道进行针对性训练，但这一过程容易导致灾难性遗忘，并且在模仿和探索之间存在次优权衡。尽管最近的研究试图结合SFT和RL使用启发式方法，但缺乏一种系统性地动态平衡这两种范式的机制。论文从隐含奖励的理论视角重新定义了这一挑战，认为SFT和RL不是各自独立的方法，而是互补的奖励信号。论文提出了一种新的单阶段算法AMFT，旨在学习SFT的路径级隐含奖励和RL的结果级显性奖励间的最佳平衡。AMFT的核心是元梯度自适应权重控制器，该控制器将SFT-RL平衡视为可学习的参数，并动态优化它以最大化长期任务性能。论文对覆盖数学推理、抽象视觉推理（General Points）和视觉语言导航（V-IRL）等具有挑战性的基准进行了全面评估，AMFT在各项任务上都取得了新的最佳性能，并在分布外（OOD）任务上展示了超群的泛化能力。实验结果表明，元学习控制器对AMFT的稳定性和样本效率至关重要，提供了大语言模型对齐的更系统和更有效框架。
### Innovation
论文提出了AMFT算法，这是一种新的单阶段算法，通过元学习机制动态平衡SFT和RL之间的权衡。AMFT的核心是一个元梯度自适应权重控制器，能够自动发现有效的训练课程。这种方法通过确保长期任务性能最大化，有效地克服了传统方法中的灾难性遗忘和权衡问题。AMFT在各种具有挑战性的基准上都取得了显著的性能提升，并在分布外任务上展示了更强的泛化能力。此外，实验验证了元学习控制器对AMFT稳定性和样本效率的重要性。
### Conclusion
AMFT通过元学习机制实现了大语言模型推理器的最佳模仿与探索平衡，将SFT和RL视为互补的奖励信号，实现两者的动态平衡。该算法通过元梯度自适应权重控制器优化了SFT-RL平衡，确保长期任务性能最大化，并在多项挑战性任务上展示了新的最佳性能。AMFT强调了元学习方法在大语言模型训练中的重要性，并提供了一个系统和有效的框架，用于进一步的LLM对齐研究。
## 728. `cs.LG` - 基于图形神经网络的罕见疾病诊断的知识图谱稀疏化 [PDF](https://arxiv.org/pdf/2510.08655), [HTML](https://arxiv.org/abs/2510.08655)
### Authors
Premt Cara,Kamilia Zaripova,David Bani-Harouni,Nassir Navab,Azade Farshad
### Background
罕见遗传疾病的诊断面临关键挑战：缺乏患者数据、难以获取全基因组测序以及可能的致病基因数量巨大。这些限制导致了漫长且不准确的诊断过程、不适当的治疗以及资源受限地区由于诊断工具稀缺而产生的严重影响。
### Innovation
作者提出了RareNet，一种基于子图的图形神经网络，只需要患者的表型数据，就能识别最可能的致病基因，并提取重点患者子图进行针对性临床研究。RareNet 可以作为独立方法使用，也可以作为其他候选基因优先方法的预处理或后处理滤波器，从而使其性能得到一致的提升，并可能带来可解释的洞察。
### Conclusion
通过在两个生物医学数据集上的全面评估，研究展示了竞争性和稳健的致病基因预测能力，并在与其他框架集成时取得了显著的性能提升。由于只需使用表型数据，RareNet 民主化了对复杂遗传分析的访问，特别为缺乏高级基因组基础设施的服务不足群体提供了价值。
## 729. `cs.LG` - DPCformer：一种用于作物基因组预测的可解释深度学习模型 [PDF](https://arxiv.org/pdf/2510.08662), [HTML](https://arxiv.org/abs/2510.08662)
### Authors
Pengcheng Deng,Kening Liu,Mengxi Zhou,Mingxi Li,Rui Yang,Chuzhe Cao,Maojun Wang,Zeyu Zhang
### Background
基因组选择（GS）利用全基因组信息预测作物表型并加快育种过程。传统GS方法在处理复杂性状和大数据集时预测准确性较差。
### Innovation
提出了一个结合卷积神经网络和自注意力机制的深学习模型DPCformer，用于建模复杂的基因型-表型关系。通过8维one-hot编码单核苷酸多态性（SNP）数据，并采用PMF算法进行特征选择，DPCformer在13种性状的十字花科作物（玉米、棉花、番茄、水稻、鹰嘴豆）数据集上表现出色。
### Conclusion
DPCformer在作物基因组预测中展示了更高的准确性、在小样本情况下更稳健的表现以及增强的可解释性，提供了精准育种的强有力工具，有助于解决全球食品安全挑战。
## 730. `cs.LG` - 能量驱动舵行：减少大型语言模型的虚假拒绝 [PDF](https://arxiv.org/pdf/2510.08646), [HTML](https://arxiv.org/abs/2510.08646)
### Authors
Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li
### Background
大型语言模型的安全对齐面临一个关键挑战：当前对齐技术主要关注提高对有害提示的安全性，导致模型变得过于谨慎，拒绝回答无害提示。因此，安全对齐的关键目标是在提升安全性的同时减少虚假拒绝。当前方法往往使得模型在处理无害的查询时过度规避风险，从而拒绝回答应答。
### Innovation
在本文中，我们引入了能量驱动舵行（EDS），这是一种不涉及微调的新颖框架，能够在推理时通过动态干预解决这一挑战。我们通过训练一个轻量级的外部能量基模型（EBM），为不利于模型输出（虚假拒绝或脱狱）的状态赋予高能量，为有利于模型输出（有助于回应或安全拒绝）的状态赋予低能量。在推理过程中，EBM将LLM的内部激活映射到“能量景观”。我们使用能量函数的梯度来动态引导LLM的隐藏状态进入低能量区域，实时纠正模型生成期望的回应，而不修改其权重。这一方法将行为控制与模型的核心知识分离，提供了一种灵活的解决方案，具有较低的计算开销。广泛实验表明，我们的方法能够成功实现这一目标：大幅度降低虚假拒绝率。例如，在ORB-H基准测试中，将合规性从57.3%提高到82.6%，同时保持基线的安全性能。我们的工作提出了一个成功的范式，用于构建既能保持低虚假拒绝率又能获得高安全性的大型语言模型。
### Conclusion
总之，通过减少虚假拒绝率和维持基线安全性，我们的方法展示了其在大型语言模型安全对齐的有效性。该工作提供了一个新的解决方案，既能确保模型的安全性，又能减少不必要的拒绝行为。
## 731. `cs.LG` - 内部分布归一化方法在时间序列预测中的应用 [PDF](https://arxiv.org/pdf/2510.08657), [HTML](https://arxiv.org/abs/2510.08657)
### Authors
Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen
### Background
现实世界的时间序列受到多种因素的影响，表现出复杂的非平稳特性。非平稳性会导致分布迁移，即时间序列的统计属性随时间变化，这会负面影响模型的表现。虽然已经提出了多种实例归一化技术来解决时间序列预测中的分布迁移问题，但现有的方法未能考虑到个体实例内的迁移变化，导致性能不佳。因此，需要提出新的方法来有效应对个体实例内的分布迁移问题，改善模型表现。
### Innovation
本文提出了两种新的基于点的方法：Learning Distribution (LD) 和 Learning Conditional Distribution (LCD)。LD 通过在不同时间步骤使用不同的参数来适应不同输入和输出的内部分布来消除内部差异，而 LCD 利用神经网络预测输出的缩放系数。这两种方法在多个骨干模型上进行了评估，并通过对比实验展示了基于点水平范式的有效性。
### Conclusion
本研究提出的基于点的方法 LD 和 LCD 能有效应对时间序列预测中的个体实例内部分布迁移问题，通过多个公开基准测试验证了其有效性。
## 732. `cs.LG` - CATS-Linear: 时间序列预测的分类辅助线性模型 [PDF](https://arxiv.org/pdf/2510.08661), [HTML](https://arxiv.org/abs/2510.08661)
### Authors
Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen
### Background
最近的研究表明，线性模型在预测性能上可以与复杂的架构相比肩，但增强线性模型的方法研究仍然相对不足。现有的方法主要集中在复杂架构上，而对线性模型的改进较少。已有研究发现，不同的时间序列实例可能遵循不同的线性映射。
### Innovation
提出了一种名为CATS-Linear的分类辅助趋势-季节分解线性模型，该模型利用了分类辅助通道独立性（CACI）技术。CATS-Linear通过分类动态分配实例到专门的预测器，实现监督通道设计。此外，对不同通道设置的理论期望风险进行了分析，并通过分割-线性映射-重新组合框架重新设计了趋势-季节分解架构，增加了复数域线性投影以处理季节成分。
### Conclusion
CATS-Linear在固定超参数的情况下实现了最先进的准确度，与调整超参数的基线相比，达到了同等的最先进准确性，同时保持了固定的超参数配置下的最先进准确度。
## 733. `cs.LG` - 如何打破“归一化压力”和KL散度的尺度限制：重新思考质量指标 [PDF](https://arxiv.org/pdf/2510.08660), [HTML](https://arxiv.org/abs/2510.08660)
### Authors
Kiran Smelser,Kaviru Gunaratne,Jacob Miller,Stephen Kobourov
### Background
高维度的复杂数据在许多科学领域中普遍存在，包括机器学习、生物学和社会科学。常用的方法是通过二维散点图来可视化这些数据集，以直观地捕捉数据的一些特征。然而，视觉判断这些图的准确性具有挑战性，因此研究人员常使用质量度量来衡量投影的准确性及其对原始数据的真实度。常用的归一化压力度量对投影的均匀缩放（拉伸、缩小）敏感，但这并不实质性改变投影内容；同样，t-SNE技术中使用的Kullback-Leibler（KL）散度也受到这种比例敏感性的影响。本文通过分析和实验证据探讨了缩放对压力和KL散度的影响，表明其数值变化及其对降维技术评估的影响。
### Innovation
引入了一种简单技术，使其能够使这两项指标对比例变化具有不变性，并通过小型基准测试展示了其正确地反映了预期的行为。这为解决和评估可视化技术的质量度量提供了一种新的方法。
### Conclusion
通过分析和实验证据，显示了归一化压力和KL散度受缩放影响的程度，并提出一种简单技术使这些度量不受比例变化影响。这种方法能够更准确地评估降维技术的表现。
## 734. `cs.LG` - FreqCa: 通过频率感知缓存加速扩散模型 [PDF](https://arxiv.org/pdf/2510.08669), [HTML](https://arxiv.org/abs/2510.08669)
### Authors
Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang
### Background
扩散变换器在推理阶段存在严重的计算成本问题。虽然特征缓存已经提出用以前时间步的特征重用的方法来解决此问题，但这种做法假设相邻时间步的特征相似或连续，但这并不在所有情况下都成立。因此，本文从频域出发，分析发现扩散模型中的不同频带在时间步之间表现出不同的动态。具体来说，决定图像结构的低频分量具有较高的相似性但缺乏连续性，而解码图像细节的高频分量则显示显著的连续性但相似性较差。
### Innovation
提出了一种名为Frequency-aware Caching (FreqCa)的方法，该方法直接基于低频分量的相似性重用这些特征，并使用二次海明插值器基于高频分量的连续性来预测高频分量的挥发性变化。此外，还提出了缓存累计残余特征（CRF）而不是所有模型层中的特征，这将特征缓存的内存占用减少了99%。
### Conclusion
在FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, 和 Qwen-Image-Edit的数据集上进行的大量实验证明，FreqCa在生成和编辑方面都表现出有效性。相关代码作为附录材料提供，并将在GitHub上发布。
## 735. `cs.LG` - 无逆Wilson环路对Transformer：一种实用的不变性及顺序敏感性诊断 [PDF](https://arxiv.org/pdf/2510.08648), [HTML](https://arxiv.org/abs/2510.08648)
### Authors
Edward Y. Chang,Ethan Y. Chang
### Background
大型语言模型在进行无害的编辑后可能会改变答案，这些编辑虽然在表面上看来是无害的，但对实际应用有重要影响。这包括RAG输出在段落重新排序时会改变、微调会破坏预训练中学到的不变性、辩论或链式思维提示会受到路径依赖的影响、编译融合或重新排序会影响决策边界附近的logits值。这些失败违背了预设的不变性，破坏了连续集成，并迫使团队在安全与速度之间做出权衡。效果虽然微小但分布在多个层面，且对上下文长度和评估顺序敏感，修复起来成本高昂，需要重新训练或形式验证。这些不良影响早在模型结构和训练过程发生时就已经存在，且渗透至多个层面和位置，对系统安全构成威胁，需要通过高效且经济的诊断工具进行识别和治理。现有的诊断工具往往过于复杂或依赖特定模型，无法满足普遍需求。本文介绍了一种名为WILSON的简化的后置诊断套件，能够将简单循环和重新排序检查转换为系统信号
### Innovation
WILSON是一种减低成本且模型通用的后置诊断工具，通过不求逆的曲率图计算和Hutchinson探针结合激活级交换子，识别重新排序风险，提供了廉价易于计算的系统信号。这些信号可以跨标准Transformer通用，且能导出为阈值和CSV文件，供项目管理者使用，能够防止RAG受到顺序效应的影响，揭露微调回归的问题，稳定辩论路径和长多轮语境，控制编译融合或重新排序。WILSON的独特之处在于其不依赖逆运算，且为通用Transformer模型提供了解决方案，降低了诊断成本，帮助团队实现可靠性与吞吐量的共同提升，无需改变模型架构或训练方法
### Conclusion
WILSON提供了一种高效且经济的诊断方法，能够识别大型语言模型在微小重新排序或路径依赖后的不良影响，防止模型出现安全问题，帮助团队优化并确保模型在部署中的可靠性与效率共同提升。该方法显著降低了诊断成本，通过简单循环和重新排序检查转化为系统信号，并为多种场景提供了解决方案，帮助开发者和团队更好地管理和优化语言模型的性能和安全。
## 736. `cs.LG` - 语言赋能模型的证明鲁棒性适应 [PDF](https://arxiv.org/pdf/2510.08659), [HTML](https://arxiv.org/abs/2510.08659)
### Authors
Yuni Lai,Xiaoyu Xue,Linghui Shen,Yulun Wu,Gaolei Li,Song Guo,Kai Zhou,Bin Xiao
### Background
语言赋能基础模型（LeFMs），如CLIP和GraphCLIP，通过将视觉（或图）特征与文本表示对齐，促进了多模态学习，并赋予了如少样本学习等强大的后续能力。然而，它们依赖于在开放环境中收集的小规模、任务特定支持数据集，这使得它们容易受到数据投毒攻击。现有防御措施依赖于经验策略，缺乏正式保证，且容易受到未知和适应性的攻击。尽管已知的鲁棒性方法能够提供正式保证，但它们大多未被探索用于基于LeFMs的少样本分类器。此前的研究尚未提出针对LeFMs的证明鲁棒性少样本分类器。
### Innovation
本文提出了一种新的证明鲁棒性少样本分类器LeFCert，它是针对LeFMs的第一种符合鲁棒性的模型。LeFCert结合了文本和特征嵌入，并采用自适应混合机制。为了实现证明鲁棒性，本文提出了双重剔除均值原型，并推导出分类分数的可证明上界和下界，从而能够在最坏情况的投毒场景下进行认证。此外，LeFCert还通过考虑更现实和紧致的攻击预算，提供了两种变体：LeFCert-L与LeFCert-C。LeFCert在实验中表现出最先进的性能，显著提高了清洁和认证准确性。尽管具有先进的鲁棒性机制，LeFCert在计算上仍然高效，使其适用于实际应用。
### Conclusion
LeFCert达到了最先进的性能，显著提高了清洁和认证准确性与现有基线相比。尽管具有高级的鲁棒性机制，LeFCert在计算上是高效的，适合实际应用。
## 737. `cs.LG` - Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting [PDF](https://arxiv.org/pdf/2510.08696), [HTML](https://arxiv.org/abs/2510.08696)
### Authors
Yunzhen Feng,Parag Jain,Anthony Hartshorn,Yaqi Duan,Julia Kempe
### Background
在使用强化学习（reinforcement learning, RL）增强大规模语言模型（large language models, LLMs）的推理任务表现时，Group Relative Policy Optimization (GRPO) 策略被广泛应用于实践中。然而，GRPO 存在一个问题，即在不少情况下忽略了负面样本组，特别是那些没有产生正确响应的组，它们会白白浪费大量的计算资源。为了解决这一问题，作者从奖励建模的概率最大似然（maximum-likelihood estimation, MLE）角度出发，提出了一个新的方法。
### Innovation
作者提出了一种新的方法，称为Likelihood Estimation with Negative Samples (LENS)，该方法通过在不正确响应上增加基于置信度的惩罚，使得错误响应成为有用的梯度更新，从而转化负面组为有用的信息。LENS 方法实质上是对 GRPO 的改进，赋予了不正确生成的非零、依赖置信度的奖励，使其更具信息价值，并显著提高了算法的效率和性能。
### Conclusion
在 MATH 基准测试中，使用 Llama-3.1-8B 和 Qwen-2.5-3B 模型进行实验，研究结果显示，提出的 LENS 变体能够持续超越 GRPO 基线，特别是在处理较难的问题时表现出更为显著的进步。这证明了无需额外监督的情况下，通过置信度加权可以有效利用负面样本组，从而在 RLVR 中实现更高的效率和更好表现。
## 738. `cs.LG` - 使用语义配对增强自我监督学习：一个新的数据集和经验研究 [PDF](https://arxiv.org/pdf/2510.08722), [HTML](https://arxiv.org/abs/2510.08722)
### Authors
Mohammad Alkhalefi,Georgios Leontidis,Mingjun Zhong
### Background
实例差异性是一种自我监督表示学习范式，其中数据集中的每个实例被视为不同的类。通过应用随机变换生成每个实例的两个不相似视图，模型被鼓励学习能够跨越这些视图共同对象不变的表示。
### Innovation
该研究提出了一个新的数据集和经验研究，名为'语义配对'，旨在通过将语义相似性引入自我监督学习中，进一步增强模型的识别能力。
### Conclusion
实验表明，通过引入语义配对，自我监督学习的性能得到了显著提升，验证了将语义信息融入自我监督学习的有效性。
## 739. `cs.LG` - Counterfactually Fair Conformal Prediction [PDF](https://arxiv.org/pdf/2510.08724), [HTML](https://arxiv.org/abs/2510.08724)
### Authors
Ozgur Guldogan,Neeraj Sarna,Yuanyuan Li,Michael Berger
### Background
现有的研究主要集中在点预测的反事实公平性方面，但其扩展到预测集——这对于不确定环境下公平决策至关重要——仍然存在不足。另一方面，虽然依赖数据分布的自由预测集可以通过同变预测（CP）提供有效的区间预测，但它并不能确保反事实公平性。因此，本文填补了这一空白，通过发展反事实公平同变预测（CF-CP），旨在使预测结果既保持边际覆盖性质又保证反事实公平性。
### Innovation
本文通过引入反事实公平同变预测（CF-CP），在不依赖训练数据的情况下，实现了既保持边际覆盖性质同时又确保反事实公平性的预测区间。通过保护属性干预下的对称化一致性得分，CF-CP 的预测集保证了反事实公平性，同时最小化了预测集的尺寸。
### Conclusion
通过实证研究，本文在合成数据集和真实数据集的回归和分类任务上验证了 CF-CP 的有效性和实用性，并实现了理想的反事实公平性，预测集覆盖率达到目标要求。CF-CP 提供了一个简单的、无需训练的方法来实现反事实公平的不确定性量化。
## 740. `cs.LG` - 非站定条件下的上下文学习在MIMO均衡中的应用 [PDF](https://arxiv.org/pdf/2510.08711), [HTML](https://arxiv.org/abs/2510.08711)
### Authors
Jiachen Jiang,Zhen Qin,Zhihui Zhu
### Background
信道均衡对于减轻频率选择性衰落和符号间干扰等失真是基本的。现有的标准监督学习方法需要为每个新任务进行成本高昂的重新训练或微调，而上下文学习（ICL）则通过少量实例在推断时适应新的信道，不需重新训练或微调。然而，现有基于ICL的均衡器主要针对静态信道在上下文窗口中的情况进行开发和评估。现有关于ICL的理论研究大多只关注固定函数的站定环境。本文研究了ICL在随时间变化信道均衡中的应用能力，采用了原理性框架设计高效的注意力机制，利用自适应信号处理算法指导更好的设计。实验结果表明，ICL在非站定MIMO均衡中有很大的潜力，借鉴经典自适应算法的注意力机制能够显著提升动态环境下的适应性和性能。
### Innovation
本文提出了通过上下文学习解决非站定信道均衡问题的新方法；设计了高效的注意力机制，确保在非站定任务中的良好适应性；借鉴经典自适应信号处理算法，如最小均方（LMS）、最小平方平方根（LRMS）和多步梯度更新，提出了新的注意力变体，以提高自适应性和鲁棒性；实验结果验证了ICL在非站定MIMO均衡中的有效性和潜力；表明经典自适应算法启发的注意力机制在动态环境中具有显著的适应性和性能提升作用。
### Conclusion
本文的研究结果可能为开发具有更强适应性和鲁棒性的下一代无线基础模型提供关键洞见，强调了ICL在非站定信道均衡中的巨大潜力和价值。
## 741. `cs.LG` - 基于SHAP的监督聚类及扩展的瀑布图在样本分类中的应用 [PDF](https://arxiv.org/pdf/2510.08737), [HTML](https://arxiv.org/abs/2510.08737)
### Authors
Justin Lin,Julia Fukuyama
### Background
随着数据和科技的发展，大型黑盒模型逐渐成为常态，因其处理大量数据并学习极为复杂的输入输出关系的能力。然而，这些方法的缺陷在于无法解释其预测过程，因此在高风险情况下使用这些模型是不安全的。SHapley Additive exPlanations (SHAP) 分析是新兴的解释型人工智能方法，能够通过原始特征解释模型预测。本文在介绍SHAP值的基础上，提出了一种通过聚类SHAP值来探索数据中隐藏模式的方法，从而缩小相似预测的样本集合。此外，作者还提供了一种用于多分类任务的瀑布图的扩展版本。
### Innovation
本文提出了基于SHAP的监督聚类方法，并展示了在阿尔茨海默病数据集上的应用。同时，提出了一种可用于多分类任务的扩展瀑布图。该方法能够提供不同样本在相同预测下的路径，有助于更好地理解复杂预测过程，并为高风险决策提供了更可靠的依据。
### Conclusion
该研究通过模拟实验和阿尔茨海默病的实际案例，验证了基于SHAP的监督聚类方法的有效性，并展示了扩展瀑布图在多分类问题中的适用性和直观性。
## 742. `cs.LG` - 使用代理模型和预测性分析实现复杂集成时序预测的忠实且可解释的解释 [PDF](https://arxiv.org/pdf/2510.08739), [HTML](https://arxiv.org/abs/2510.08739)
### Authors
Yikai Zhao,Jiekai Ma
### Background
现代时序预测越来越多地依赖于AutoML系统（如AutoGluon）生成的复杂集成模型，这些模型虽然提供了更高的预测准确性，但同时也导致了透明度和可解释性方面的显著损失。本文介绍了一种全面的双管齐下框架，旨在解决复杂时序集成中的解释性和预测性挑战。该框架通过实验研究验证，证明了所提出的方法在解释准确性方面的优越性，并且通过预测性分析进一步优化了模型的可靠性指标，从而实现用户对预测及其解释的信任度校准。
### Innovation
本文的创新点在于提出了使用LightGBM作为代理模型来忠实模拟AutoGluon的时序预测，并通过谱预测性分析量化每个时间序列的固有预测能力，从而提供可解释的实例级解释。同时，该框架还通过特征注入实验验证了代理模型的有效性，并通过实例数据集评估表明，高预测性与更高的预测准确性和解释度一致性密切相关。此外，该研究强调了项目归一化对于跨不同量级的时间序列生成有意义的SHAP解释的重要性。
### Conclusion
该研究提出的框架为最先进的集成预测提供了可解释的实例级解释，并为预测及其解释的可靠性提供了预测性指标，使用户能够对预测结果及其解释进行校准。通过这些分析方法，用户可以更可靠地信任预测结果及其解释，从而提供一种新的方法来解决时序预测中的透明度问题。
## 743. `cs.LG` - 将提示转化为权重 [PDF](https://arxiv.org/pdf/2510.08734), [HTML](https://arxiv.org/abs/2510.08734)
### Authors
Hanna Mazzawi,Benoit Dherin,Michael Munn,Michael Wunder,Javier Gonzalvo
### Background
已有研究证明，可以通过直接修改大型语言模型内部状态的方法在其推理时有效控制其行为，这些方法包括向其激活值添加向量或更新其权重矩阵。尽管这些技术非常强大，但通常依赖于经验性的直觉指导，例如通过对比提示的平均激活值来推导引导向量。这项研究提供了这些干预措施的理论基础，解释了它们如何从变换器架构的基本计算中产生。基于最近发现的一点——即提示的影响可以被数学映射为隐式权重更新（Dherin et al., 2025），这项研究将这一理论推广到深层、多块变换器。研究展示了用户提示中任何片段的信息是如何通过权重向量和权重矩阵在内部表示和组合的，随后推导出一种原则性的方法，将这些信息凝练成不依赖于词素的思考向量和思考矩阵。这些结构为现有的向量和矩阵基模编辑技术提供了理论解释，并提供了一种直接的、基于计算的方法，将文本输入转化为可重用的权重更新方法。
### Innovation
这项研究为现有的干预措施提供了理论基础，展示了提示对模型的影响是如何通过隐式权重更新理论来实现的，并将这一理论扩展至深层、多块变换器。研究推导出了一种新的方法，将用户提示中包含的信息凝练为不依赖于词素的思考向量和矩阵，这为理解大型语言模型的内部工作机制提供了新的视角，并为模型编辑技术的研究提供了新的理论框架。
### Conclusion
这项研究通过提供数学映射的理论基础，解释了提示如何影响模型的方式，以及如何通过权重向量和矩阵将提示中的信息转换为可以直接应用于模型的权重更新。这不仅为理解大型语言模型的行为提供了新的理论解释，还为设计更有效的模型编辑方法提供了直接的计算途径。
## 744. `cs.LG` - RFOD：基于随机森林的表格数据异常检测 [PDF](https://arxiv.org/pdf/2510.08747), [HTML](https://arxiv.org/abs/2510.08747)
### Authors
Yihao Ang,Peicheng Yao,Yifan Bao,Yushuo Feng,Qiang Huang,Anthony K. H. Tung,Zhiyong Huang
### Background
在高风险领域（如网络安全、金融欺诈检测和医疗健康）中，表格数据中的异常检测对于保障数据完整性至关重要。现有的方法在处理混合型表格数据方面存在挑战，往往依赖编码方案，这会导致重要语义信息的丢失，并且缺乏解释性，难以理解特定值引发异常的原因。
### Innovation
研究人员引入了基于随机森林的新型随机森林异常检测框架（textsf{RFOD}）。与建模全局联合分布不同，textsf{RFOD} 将异常检测重新定义为基于特征的条件重建问题，针对其他特征训练每个特征的专用随机森林。该设计能够稳健地处理异质性数据类型，同时保留分类特征的语义完整性。进一步地，textsf{RFOD} 结合了调整后的戈弗距离（AGD）和不确定性加权平均（UWA），用于在细胞级别上评分并汇总为稳健的行级异常评分，从而实现精确且可解释的检测。
### Conclusion
在15个真实数据集上的大量实验表明，textsf{RFOD} 在检测准确性方面持续优于最先进的基线方法同时提供更强大的稳健性、可扩展性和对混合型表格数据的解释性。
## 745. `cs.LG` - Conformal Risk Training: End-to-End Optimization of Conformal Risk Control [PDF](https://arxiv.org/pdf/2510.08748), [HTML](https://arxiv.org/abs/2510.08748)
### Authors
Christopher Yeh,Nicolas Christianson,Adam Wierman,Yisong Yue
### Background
深度学习模型常常能够实现高度的预测准确性，但在高风险应用场景中，它们的预测并未附带任何可验证的风险或可靠性保证。现有的框架，如conformal risk control (CRC)，提供了一种无分布、有限样本的方法来控制任何有界单调损失函数的期望值，并可在任何预先训练的深度学习模型后方便地应用。但是，许多实际应用对尾部风险更加敏感，而不仅仅是期望损失。
### Innovation
本研究开发了一种控制优化确定等价（OCE）风险的方法，这是一类风险度量的广泛类别，包括预期损失（扩展了原始CRC方法）和常见的尾部风险如条件值-at-风险（CVaR）。此外，标准的后处理CRC会因缺乏对模型的反馈而导致平均情况性能下降。为解决这一问题，提出了“conformal风险训练”，这是一种端到端的方法，在模型训练或微调期间通过conformal OCE风险控制进行反向传播。该方法在分类器的假阴性率控制和电池储能运营中的金融风险控制应用上展示了显著改进的平均情况性能，且能够提供风险保证。
### Conclusion
该方法在平均情况性能方面显著优于后处理方法，同时保持了可验证的风险保证。
## 746. `cs.LG` - LOTION: 通过随机舍入平滑化优化景观以实现量化训练 [PDF](https://arxiv.org/pdf/2510.08757), [HTML](https://arxiv.org/abs/2510.08757)
### Authors
Mujin Kwun,Depen Morwani,Chloe Huangyuan Su,Stephanie Gil,Nikhil Anand,Sham Kakade
### Background
优化神经网络以满足量化目标在本质上是具有挑战性的，原因在于量化器是分段常数函数，导致除在量化阈值外的任何地方梯度均为零，而在量化阈值处导数是未定义的。大多数现有方法通过使用类似于 Straight Through Estimator (STE) 的技术来放松梯度计算，但并未提供任何关于收敛性的保证。
### Innovation
本文受 Nesterov 平滑启发，提出通过引入低精度优化算法 LOTION（L_low-precision Optimization via Stochastic-noise Smoothing）将量化损失面近似为连续损失面。该方法用无偏随机舍入噪音下的期望值代替原始量化损失。利用此框架，标准优化器可以保证收敛到损失面的局部极小值。使用基于随机舍入的噪声时，证明了原始量化损失的全局最小值得到了保留。
### Conclusion
实验结果表明，该方法在合成测试平台上和包含150M和300M参数的语言模型上均优于标准的量化训练（QAT）方法。
## 747. `cs.LG` - 大型语言模型中联邦学习中跨客户端训练数据记忆性探究 [PDF](https://arxiv.org/pdf/2510.08750), [HTML](https://arxiv.org/abs/2510.08750)
### Authors
Tinnakit Udsa,Can Udomcharoenchaikit,Patomporn Payoungkhamdee,Sarana Nutanong,Norrathep Rattanavipanon
### Background
联邦学习（FL）允许在不共享原始数据的情况下进行协作训练，但仍存在训练数据记忆的风险。现有的FL数据记忆检测技术只关注单个样本，忽略了跨样本记忆的更微妙风险。相比之下，集中学习（CL）领域已有的研究引入了更细粒度的方法来评估训练数据中所有样本的记忆性，但这些方法假设对数据有集中访问，不能直接应用于FL场景。本研究旨在通过提出一种新的框架，解决跨客户端细粒度跨样本记忆度量方法在FL中的应用缺口，并探讨影响记忆的关键因素。
### Innovation
本文提出了一种框架，用于量化联邦学习中的跨客户端和客户端内数据的记忆性，使用了所有客户端之间的细粒度跨样本记忆性测量方法。该框架通过两个研究来实现：一是测量客户端之间的细粒度记忆性，二是研究影响记忆的关键因素，包括解码策略、前缀长度和联邦学习算法。研究发现，联邦学习模型在客户端内数据记忆性方面显著高于跨客户端数据，且记忆性受训练和推理因素影响。
### Conclusion
联邦学习模型确实会记忆客户端数据，尤其是客户端内数据，但跨客户端的数据记忆性较低。这受多种因素影响，包括训练和推理策略。
## 748. `cs.LG` - Graph Diffusion Transformers是上下文驱动的分子设计师 [PDF](https://arxiv.org/pdf/2510.08744), [HTML](https://arxiv.org/abs/2510.08744)
### Authors
Gang Liu,Jie Chen,Yihan Zhu,Michael Sun,Tengfei Luo,Nitesh V Chawla,Meng Jiang
### Background
在上下文学习中，大型模型可以从少量演示中适应新的任务，但在分子设计领域效果有限。现有的数据库如ChEMBL包含了大量的生物测定分子属性，但每个属性的标注数据仍然稀缺，这成为了一个显著的限制。为了解决这个问题，引入了基于演示的扩散模型（DemoDiff），该模型使用小规模的分子-评分示例定义任务上下文，而不是文本描述。这些演示指导去噪Transformer生成与目标属性对齐的分子。为了实现可扩展的预训练，开发了一种新的分子分词器Node Pair Encoding，以图元级别的方式表示分子，所需节点数减少到原数的5.5倍。编制了一个包含来自不同来源数百万个上下文任务的数据集，涵盖药物和材料领域，并在一个拥有约0.7亿参数的模型上进行了预训练。在六大类别中的33个设计任务中，DemoDiff的表现与比其大100-1000倍的语言模型相当或更好，并且取得了平均排名3.63的成绩，相比之下，领域特定方法的平均排名在5.25-10.20之间。这些结果将DemoDiff定位为一种用于上下文分子设计的基础模型。
### Innovation
1. 提出了基于演示的扩散模型（DemoDiff），它使用少量的分子-评分示例定义任务上下文，而不是标准的文本描述，这为生成与目标属性对齐的分子提供建立了指导。2. 开发了一种新的分子分词器Node Pair Encoding，它可以在图谱级别的表示下实现分子的表示，并使所需的节点数减少到原数的5.5倍。3. 编制了一个包含来自多个来源数百万个上下文任务的数据集，涵盖药物和材料领域，并预训练了拥有约0.7亿参数的模型。4. 在大量分子设计任务上取得了比大语言模型更好的表现或与其相当，并且在使用领域特定方法的情况下，取得了更好的平均排名。
### Conclusion
Graph Diffusion Transformers作为分子基础模型，为上下文分子设计提供了有效的解决方案，它能够在大量的分子设计任务上取得更好的表现，并且在平均排名上优于领域特定方法。
## 749. `cs.LG` - Spatial Deconfounder: Interference-Aware Deconfounding for Spatial Causal Inference [PDF](https://arxiv.org/pdf/2510.08762), [HTML](https://arxiv.org/abs/2510.08762)
### Authors
Ayush Khot,Miruna Oprescu,Maresa Schröder,Ai Kagawa,Xihaier Luo
### Background
空间领域中的因果推理面临两大相互交织的挑战：未测量的空间因素（如天气、空气污染或移动）可能会混淆处理和结果，以及来自附近处理的相互作用，这违反了标准的无相互作用假设。现有方法通常通过假设忽略其中一个问题来解决另一个问题，而这些问题是密切联系的。相互作用揭示了潜在混淆变量中的结构性信息。
### Innovation
本文提出了一种新的方法——空间去混淆器，这是一种两阶段方法，首先使用条件变分自动编码器（CVAE）结合空间先验从局部治疗向量中重建一个替代的混淆变量，然后通过灵活的结果模型估计因果效应。这种方法能够在弱假设下非参数识别直接和溢出效应，无需多种处理类型或已知的潜在场模型。此外，还建立了一个包含治疗相互作用的基准套件以扩展空间混淆器，并通过真实世界的数据集展示了性能提升。
### Conclusion
通过将干扰转化为多原因信号的方式，本文框架将空间和去混淆文献联系起来，为结构化数据中的稳健因果推理提供了新的进展。
## 750. `cs.LG` - 使用毕肖普的π定理实现零样本策略迁移的强化学习 [PDF](https://arxiv.org/pdf/2510.08768), [HTML](https://arxiv.org/abs/2510.08768)
### Authors
Francisco Pascoa,Ian Lalonde,Alexandre Girard
### Background
强化学习（RL）策略往往难以在具有不同物理参数的新机器人、任务或环境中泛化，这一限制使得RL策略难以在现实世界中广泛应用。
### Innovation
本文提出了一种基于毕肖普的π定理的简单零样本迁移方法，该方法通过在无量纲空间中调整输入（观察）和输出（动作）对预训练策略进行适应，无需重训练，从而解决了这一限制。这种方法在模拟吊摆、物理吊摆以及高维HalfCheetah三种环境中的评估表明，在动态相似环境中，无量纲空间调整的策略不会导致性能下降。在非相似环境中，该策略始终优于传统的迁移方法，显著扩展了原策略有效作用的环境范围。这些发现表明，量纲分析提供了增强RL策略稳定性和泛化能力的强大而实用的工具。
### Conclusion
本文通过提出一种基于毕肖普的π定理的简单零样本迁移方法，为强化学习策略的泛化能力提供了强有力的工具，该方法不需要重新训练，能够显著提高策略在不同环境中的适用范围。
## 751. `cs.LG` - Struc-EMB：语言嵌入中结构感知编码的潜力 [PDF](https://arxiv.org/pdf/2510.08774), [HTML](https://arxiv.org/abs/2510.08774)
### Authors
Shikun Liu,Haoyu Wang,Mufei Li,Pan Li
### Background
大型语言模型（LLMs）生成的文本嵌入已成为众多应用的基础。然而，这些模型通常只处理原始文本，忽视了诸如超链接或引用等丰富的结构信息，这些信息在许多现实世界的数据集中提供了关键的背景信息。
### Innovation
本文提出并系统评估了一种新的生成结构感知文本嵌入的方法，通过在LLM的内部编码过程中直接整合这些结构关系，而不是依赖于传统的后处理聚合。研究了两种主要的在过程中方法：顺序串联和并行缓存。通过广泛的零样本实验，展示了结构感知方法在检索、聚类、分类和推荐任务中的一贯优越性能。为解决噪声结构数据的挑战，还介绍了和验证了两种有效的方法：上下文蒸馏和语义平衡。
### Conclusion
本文为结构感知编码提供了首个全面分析，并提供了构建更强大和上下文感知嵌入模型的蓝图。
## 752. `cs.LG` - 通过LLM增强观测进行强化学习中的探索引导 [PDF](https://arxiv.org/pdf/2510.08779), [HTML](https://arxiv.org/abs/2510.08779)
### Authors
Vaibhav Jain,Gerrit Grossmann
### Background
在稀疏奖励环境中，传统探索策略难以发现有效的行动序列，这使得强化学习（RL）代理常面临挑战。现有方法将大型语言模型（LLM）生成的建议植入为僵硬依赖，或者直接集成到奖励函数中，从而限制了RL代理的自由度。
### Innovation
本文提出了一种框架，通过增强观测空间提供LLM生成的行动建议，使RL代理能够在适当时候遵循或忽略这些建议，同时保持某种柔性的约束条件，从而利用LLM的世界知识和推理能力，而不牺牲灵活性。
### Conclusion
在更具挑战性的环境中，我们实现了71%的相对成功率提升，达到了9倍于基准的样本效率效果，同时还无需修改现有的RL算法。结果表明，本方法有效利用了LLM的规划能力来加速在挑战性环境中的RL训练。
## 753. `cs.LG` - 神经网络函数近似中的权重初始化 [PDF](https://arxiv.org/pdf/2510.08780), [HTML](https://arxiv.org/abs/2510.08780)
### Authors
Xinwen Hu,Yunqing Huang,Nianyu Yi,Peimeng Yin
### Background
神经网络基于函数近似在科学计算和机器学习中扮演着关键角色，但训练此类模型面临着许多挑战：(i) 每个目标函数通常需要从头训练一个新的模型；(ii) 性能高度依赖于架构和超参数的选择；(iii) 模型往往在训练域之外泛化能力较差。
### Innovation
本研究提出了一种基于基函数预训练的可复用初始化框架。首先，基于参考域训练基神经网络以近似多项式族。然后使用预训练网络的已学习参数来初始化更为复杂的目标函数网络。进一步引入了一种域映射机制，将输入变换到参考域中，从而保持与预训练模型的结构对应。
### Conclusion
大量的数值实验在1到2维设置中展示了在训练效率、泛化能力和模型可迁移性方面的显著改进，突显了基于初始化策略的可扩展和模块化神经函数近似的潜力。完整的代码已公开发布于Gitee。
## 754. `cs.LG` - 基于虚拟成像试验的CT采集和重建参数强化学习优化 [PDF](https://arxiv.org/pdf/2510.08763), [HTML](https://arxiv.org/abs/2510.08763)
### Authors
David Fenwick,Navid NaderiAlizadeh,Vahid Tarokh,Nicholas Felice,Darin Clark,Jayasai Rajagopal,Anuj Kapadia,Benjamin Wildman-Tobriner,Ehsan Samei,Ehsan Abadi
### Background
在计算机断层扫描(CT)中，协议优化对于获取高诊断图像质量和降低辐射剂量至关重要。然而，由于CT采集和重建参数之间的复杂相互依赖关系，传统优化方法需要穷尽测试这些参数的各种组合，这往往是不切实际的。本研究引入了一种结合虚拟成像工具与强化学习的新方法，以更高效地优化CT协议。使用验证过的CT模拟器对包含肝病变的人体模型进行了成像，并使用新型CT重建工具包进行重建。优化参数空间包括管电压、管电流、重建核、切片厚度和像素大小。优化过程使用Proximal Policy Optimization (PPO) 剂量进行训练，目标是最大化图像质量客观指标，即重建图像中肝病变的检测指数(d')。将优化性能与在超级计算机上执行的穷尽搜索进行比较，表明所提的强化学习方法在测试案例中实现了全局最大d'，所需的步骤数比穷尽搜索少79.7%，展示了其准确性和计算效率。该框架灵活，可适应各种图像质量指标。研究结果强调了将虚拟成像工具与强化学习集成在CT协议管理中的潜力。
### Innovation
本研究提出了一种结合虚拟成像工具与强化学习的新方法，以更高效地优化CT协议。该方法使用Proximal Policy Optimization (PPO)剂量训练，通过最大化肝病变检测指数(d')来优化CT图像质量。该方法在测试案例中实现了全局最大d'，所需的步骤数比传统穷尽搜索方法少79.7%，展示了其准确性和计算效率。该框架还具有灵活性，可以适应各种图像质量指标。
### Conclusion
研究结果表明，结合虚拟成像工具与强化学习的方法可以高效且准确地优化CT协议。这种方法不仅能够提高图像质量，还能显著降低所需的计算资源，为CT协议管理提供了一种新的有效途径。未来可以进一步研究更多具体的参数优化以及不同场景的应用。
## 755. `cs.LG` - TAPAS：学习误差问题的数据集 [PDF](https://arxiv.org/pdf/2510.08797), [HTML](https://arxiv.org/abs/2510.08797)
### Authors
Eshika Saxena,Alberto Alfarano,François Charton,Emily Wenger,Kristin Lauter
### Background
在后量子密码学中，AI-powered攻击对一种称为Learning with Errors (LWE)的重要困难数学问题表现出与经典方法相当或更优的效果。尽管这种新方法有前景，但由于缺乏可获取的数据，限制了AI研究者的使用和改进。创建LWE数据用于AI模型训练是耗时且计算资源密集，需要大量专业知识。为了填补这一空白并加速AI在LWE攻击中的研究，作者提出了一种称为TAPAS的数据集工具包，用于分析基于AI系统的后量子密码学。
### Innovation
TAPAS数据集工具包提供了一系列LWE设置的数据集，AI研究者可以直接使用这些数据集来开发新的破解LWE的方法。这项工作详细记录了TAPAS数据集的创建过程，建立了攻击性能基准，并指出了未来的研究方向。
### Conclusion
该研究通过提供TAPAS数据集工具包，加速了AI在LWE攻击研究中的应用，并为未来的研究奠定了基础。
## 756. `cs.LG` - 多臂赌博机中的欺骗性探索 [PDF](https://arxiv.org/pdf/2510.08794), [HTML](https://arxiv.org/abs/2510.08794)
### Authors
I. Arda Vurankaya,Mustafa O. Karabag,Wesley A. Suttle,Jesse Milzman,David Fridovich-Keil,Ufuk Topcu
### Background
研究一个多臂赌博机模型，其中每个臂具有公共和私人两个奖励分布。观察者期望代理人遵循公共奖励的汤普森采样方法，但是欺骗性代理人试图快速识别最优私人臂而不被发现。观察者只能观察到公共奖励和被拉的选择臂，而代理人可以观察到公共和私人奖励。这种情景下，定义可检测性为实际使用的选择概率与预期观察者的期望选择概率之间的步进Kullback-Leibler（KL）发散度约束。将成功拉取公共次优臂的过程建模为一个Bernoulli过程，成功率随着每次成功的拉取而降低，并且在KL约束下这种拉取的发生率最多为Θ(√T)。
### Innovation
将KL发散度约束用于定义可检测性，成功拉取公共次优臂的过程被建模为一个随成功率递减的Bernoulli过程，并表明此过程在KL约束下最多以Θ(√T)的速度发生。基于公共和私人期望奖励解决一个最大化最小问题，描述了最优错误指数并提出了一个借鉴top-two算法启发的算法，该算法能够根据公共次优臂差距的难度自然调整其探索策略。
### Conclusion
提出的方法建立了一个可检测欺骗性代理人的步骤，该步骤通过KL发散度约束来限制代理人的选择行为。证明了公共次优臂的拉取率最多为Θ(√T)，并通过数值示例展示提出的算法的性能。
## 757. `cs.LG` - Edu-EmotionNet: 交叉模态注意力对齐与时间反馈回路 [PDF](https://arxiv.org/pdf/2510.08802), [HTML](https://arxiv.org/abs/2510.08802)
### Authors
S M Rafiuddin
### Background
理解在线教育中的学习者情感对于提高参与度和个性化教学至关重要。尽管之前的情感识别工作探索了多模态融合和时间建模，但现有方法通常依赖于静态融合策略，并假设模态输入始终可靠，这在实际学习环境中很少成立。
### Innovation
引入了Edu-EmotionNet，这是一种新的框架，联合建模时间情感演变和模态可靠性，以实现稳健的情感识别。该模型包含三个关键组件：跨模态注意力对齐（CMAA）模块，用于动态跨模态上下文共享；模态重要性估计器（MIE），在每个时间步骤给每个模态分配基于置信度的权重；以及时间反馈回路（TFL），利用先前的预测以确保时间一致性。
### Conclusion
在注释了困惑、好奇、无聊和挫败感的IEMOCAP和MOSEI教育子集上进行评估，Edu-EmotionNet实现了最先进的性能，并且展示了对缺失或噪声模态的强大稳健性。视觉化结果证实了其捕获情感转变和自适应优先处理可靠信号的能力，使其非常适合实时学习系统部署。
## 758. `cs.LG` - PO-CKAN：具有分块理查德结构的物理感知深度操作符柯尔莫哥洛夫-阿诺尔德网络 [PDF](https://arxiv.org/pdf/2510.08795), [HTML](https://arxiv.org/abs/2510.08795)
### Authors
Junyi Wu,Guang Lin
### Background
该论文提出了PO-CKAN，这是一种基于分块理性柯尔莫哥洛夫-阿诺尔德网络（CKAN）的物理感知深度操作符框架，用于近似偏微分方程（PDE）的解决方案运算符。该框架利用了Deep Operator Network (DeepONet) 架构，并将CKAN子网络整合进去以增强函数近似能力。论文师从物理感知神经网络（PINNs）的原则，将物理一致性原则集成到操作符学习框架中，以确保结果的物理一致性。这种方法使得在训练后可以高效地学习物理一致性时空解决方案运算符，并且能够在不同参数和边界条件等输入变化的情况下，快速预测参数时变PDE的解决方案。该方法已经在具有挑战性的基准问题上得到了验证，展示了接近高保真解的精确操作符学习结果。
### Innovation
PO-CKAN采用了DeepONet的分支-干道结构，其中的子网络表现为理性KAN模块，并通过PDE残差（PINN样式）损失来强制物理一致性。与先前的PI-DeepONet相比，PO-CKAN在$u=0.01$的Burgers'方程上将平均相对$L^2$误差减少了约48%，并且在Eikonal和扩散-反应基准测试中取得了相当高的精度。
### Conclusion
PO-CKAN通过整合CKAN分块理性的网络结构和物理一致性损失，提高了偏微分方程解决方案运算符的物理一致性和预测精度，在偏差问题上验证了其有效性和准确性。
## 759. `cs.LG` - 通过信息保留两阶段学习实现长尾识别 [PDF](https://arxiv.org/pdf/2510.08836), [HTML](https://arxiv.org/abs/2510.08836)
### Authors
Fudong Lin,Xu Yuan
### Background
在许多实际数据分布中存在着不平衡（或长尾）现象，这种现象往往导致深度分类模型倾向于频繁类别，而忽略了尾部类别的表现，导致对尾部类别的性能较差。
### Innovation
本文提出了一种新颖的两阶段学习方法，旨在减轻对多数类别的偏向倾向，同时保留数据集中的有价值信息。第一阶段采用信息理论视角提出了一种新的表示学习技术，理论上等效于最小化类内距离，从而获得有效且良好的特征空间。第二阶段开发了一种新颖的采样策略，该策略选择具有数学信息的样本，能够在不损害模型总体性能的情况下纠正多数类偏向的决策边界。通过广泛的实验验证，该方法在各种长尾基准数据集上达到了最先进的性能，且代码已公开可用。
### Conclusion
我们的方法在各种长尾基准数据集上达到了最先进的性能，通过广泛的实验验证。
## 760. `cs.LG` - 基于强化学习的边缘管理以实现可靠的多视角3D重建 [PDF](https://arxiv.org/pdf/2510.08839), [HTML](https://arxiv.org/abs/2510.08839)
### Authors
Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy
### Background
实时多视角3D重建是一个关键性的边缘本地应用场景，例如消防救援，这些应用需要实时和准确的3D场景建模来实现态势感知和决策支持。然而，边缘资源的动态和不可预测性会导致图像质量下降、网络链接不稳定和服务器负载波动等问题，影响重建管线的可靠性。
### Innovation
提出了一个基于强化学习（RL）的边缘资源管理框架，旨在确保在资源受限和容易出现中断的环境中，仍能以合理的时间保证高质量的3D重建。特别地，该框架采用了两个协同的Q-learning智能体，一个用于相机选择，一个用于服务器选择，这两个智能体全程在线运行，通过与边缘环境的交互学习策略。
### Conclusion
实验结果表明，该提出的框架通过有效平衡端到端的延迟和重建质量，在动态环境中提高了应用程序的可靠性。
## 761. `cs.LG` - TinyGraphEstimator：适应轻量级语言模型的图形结构推理 [PDF](https://arxiv.org/pdf/2510.08808), [HTML](https://arxiv.org/abs/2510.08808)
### Authors
Michal Podstawski
### Background
图形提供了一种通用的复杂关系系统表示框架，从图形文本表示中推断其结构属性是图形分析和推理的核心挑战。虽然大型语言模型最近展示了进行符号和数值推理的能力，但在这种语境下，更小和资源高效的模型的潜力尚未得到广泛探索。因此，本文研究了基于紧凑型的变压器语言模型是否可以直接从图形的文本表示中推断图形理论参数。为了实现系统评价，本研究提出了TinyGraphEstimator数据集——一个包含详细结构元数据并由多种随机图形模型生成的平衡集合连接图形。实验结果显示，小型语言模型拥有非平凡的图形结构数据推理能力，并且可以通过轻量级微调技术如LoRA来有效适应结构推断任务，提高所有指标的性能。
### Innovation
本文引入了TinyGraphEstimator数据集，并研究了紧凑型的变压器语言模型是否可以从图形文本表示中直接推理出图形理论参数。此外，本研究还采用一种轻量级微调技术Low-Rank Adaptation (LoRA)，使得小型语言模型在所有评估指标上均表现出一致的性能提升。
### Conclusion
小型语言模型在图形结构推理任务中不仅展现出非平凡的逻辑推理能力，而且通过有效的参数调整可以被适配用于结构推理任务。
## 762. `cs.LG` - 医疗影像预后中公平AI的边界：一个因果视角 [PDF](https://arxiv.org/pdf/2510.08840), [HTML](https://arxiv.org/abs/2510.08840)
### Authors
Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang
### Background
随着机器学习算法在医学图像分析中的应用日益广泛，人们越来越关注其对某些社会群体的潜在偏见问题。尽管已经提出了许多方法来确保机器学习模型的公平性，但大多数现有工作仅关注医学图像诊断任务，如图像分类和分割，而忽视了预后场景。预后场景涉及对某种医疗状况的可能结局或进展的预测。
### Innovation
本文提出了FairTTE，一个评估医学成像中时间到事件预测公平性的首个综合性框架。FairTTE通过结合最先进的时间到事件预测和公平算法，实现对医学图像预后公平性的系统和详细分析。通过因果分析技术，FairTTE揭示并量化了嵌入在医学成像数据集中的不同偏见来源。大规模评估表明，偏见在不同成像模态中普遍存在，现有的公平性方法提供的缓解效果有限。此外，研究还发现，隐蔽偏见源与模型差异之间存在强烈关联，强调了整体方法的重要性，这种方法能够针对所有类型的偏见。
### Conclusion
我们发现，随着数据分布的变化，保持公平性变得越来越困难，这揭示了现有解决方案的局限性，强调了需要更加稳健和公正的预后模型的需求。
## 763. `cs.LG` - 时间感知特征选择：稳定稀疏自编码器训练的自适应时态掩蔽 [PDF](https://arxiv.org/pdf/2510.08855), [HTML](https://arxiv.org/abs/2510.08855)
### Authors
T. Ed Li,Junyu Ren
### Background
理解大型语言模型的内部表示对于确保其可靠性和安全性至关重要，而稀疏自编码器（SAEs）作为一种潜在的可解释性方法正在逐渐受到关注。然而，目前的SAE训练方法遇到了特征吸收（feature absorption）的问题，即特征（或神经元）吸收到彼此中以最小化$L_1$惩罚，这使得持续识别和分析模型行为变得困难.
### Innovation
本文提出了自适应时态掩蔽（Adaptive Temporal Masking, ATM）这一新颖的训练方法，通过跟踪激活幅度、频率和重构贡献来动态调整特征选择，从而计算随着时间变化的重要性分数。ATM基于统计阈值应用概率掩蔽机制，创建了更自然的特征选择过程。实验表明，ATM相对现有方法（如TopK和JumpReLU SAEs）具有更低的吸收评分，同时保持了出色的重构质量。这些结果证明ATM是学习神经网络中稳定、可解释特征的原理性解决方案，为更可靠的模型分析提供了基础.
### Conclusion
通过广泛的实验，ATM在Gemma-2-2b模型上展示了其优越性，不仅在吸收得分上取得了显著改进，同时保持了优秀的重构效果。这些结果确立了ATM作为学习神经网络中稳定、可解释特征的原理性解决方案的地位，为更加可靠的模型分析奠定了基础。
## 764. `cs.LG` - 监督式与自我监督对比学习之间的对齐 [PDF](https://arxiv.org/pdf/2510.08852), [HTML](https://arxiv.org/abs/2510.08852)
### Authors
Achleshwar Luthra,Priyadarsi Mishra,Tomer Galanti
### Background
自我监督对比学习（CL）在下游任务中取得了显著的经验成功，其生成的表示往往可以与监督预训练相匹敌。最近的理论表明，当类别数量增加时，对比损失（CL损失）接近于监督似然的负样本监督对比损失（NSCL损失）的近似值。尽管如此，对于CL和NSCL在表示层面上在整个训练过程中是否也始终保持一致，仍存在一个未解答的问题。
### Innovation
该研究通过分析共享随机性（相同的初始化、批次和增广）下训练的CL和NSCL模型的表示对齐，证明了它们诱导的表示总是相似的：具体证明了CL和NSCL的相似矩阵在现实条件下保持接近。研究提供了相似性度量（如中心核对齐CKA和表示相似性分析RSA）的高概率保证，并解释了如何随类别数量、温度和批次大小的增加而改进对齐。相比之下，研究展示了参数空间耦合的内在不稳定性：CL和NSCL权重之间的差异随训练时间呈指数增长。最后，作者通过实验证明了这些预测，表明缩小比例和温度增长时，CL-NSCL对齐增强，而NSCL比其他监督目标更紧密地跟踪CL。
### Conclusion
研究证实NSCL是自我监督和监督学习之间的原理性桥梁。代码和项目页面可访问：[链接1](this https URL) [链接2](this https URL)
## 765. `cs.LG` - 高保真批处理主动学习的高斯过程分类器 [PDF](https://arxiv.org/pdf/2510.08865), [HTML](https://arxiv.org/abs/2510.08865)
### Authors
Murray Cutforth,Yiming Yang,Tiffany Fan,Serge Guillas,Eric Darve
### Background
许多科学研究和工程问题依赖于昂贵的计算模拟，通过多保真方法可以在参数空间探索方面加快这一过程。在二元模拟输出的情况下，我们利用高斯过程（GP）模型研究了模拟预算的有效分配。目前的研究引入了一种新的批量主动学习算法Bernoulli参数互信息（BPMI），旨在提高多保真GP分类器的效率。BPMI通过使用连接函数的一阶泰勒展开绕过了计算互信息的不可行性。
### Innovation
该论文提出了一种新的批量主动学习算法Bernoulli参数互信息（BPMI），针对多保真GP分类器。BPMI通过使用连接函数的一阶泰勒展开来解决计算互信息的不可行性问题，从而提高了多保真GP分类器的效率。
### Conclusion
通过在两种合成测试案例和一个复杂的实际应用（激光点火火箭燃烧室的模拟）上的实验评估，BPMI表现出了优越的性能，实现了在固定计算预算下更高的预测准确性。
## 766. `cs.LG` - 精确定位关键步骤：可验证强化学习中的属性归因信用分配 [PDF](https://arxiv.org/pdf/2510.08899), [HTML](https://arxiv.org/abs/2510.08899)
### Authors
Junxi Yin,Haisen Luo,Zhenyu Li,Yihua Liu,Dan Liu,Zequn Li,Xiaohang Xu
### Background
关于使用验证奖励的强化学习（RLVR）增强LLMs复杂推理，当前方法难以平衡探索与利用，这导致了诸如中间步骤信用分配不准确和过早熵坍塌等重要问题，限制了模型的性能。
### Innovation
提出了基于归因的策略优化贡献（ACPO）的阶段框架，结合了难度感知的课程，通过轨迹语义分割和基于归因的表示动态调节策略熵来改善探索，同时通过因子化的奖励系统精确量化每个推理步骤的层级贡献，确保准确的信用分配，从而在多个具有挑战性的基准（如AIME、MATH和AMC）上显著优于现有最先进的方法，提升了模型的性能和准确性。
### Conclusion
实验结果表明，ACPO相较于现有最先进的方法，显著提高了LLMs在复杂推理任务中的表现。
## 767. `cs.LG` - 稀疏成分区分视觉通路及其与神经网络的对齐 [PDF](https://arxiv.org/pdf/2510.08858), [HTML](https://arxiv.org/abs/2510.08858)
### Authors
Ammar I Marvi,Nancy G Kanwisher,Meenakshi Khosla
### Background
研究表明，人类高级视觉皮层中的背侧、腹侧和侧向流在执行不同功能过程中具有特异性。然而，仅通过单一任务训练的深度神经网络（DNN）表现出对整个视觉系统的惊人建模能力，提示了这些路径在线程中的共同计算原理。本文旨在探讨逻辑矛盾，应用一种新颖的稀疏分解方法来识别每个流中的视觉表示的主要成分。研究确认了三个视觉流中成分响应模式的差异，揭示了这些流在选择性识别面部、地点、身体、文本和食物以及社交互动、暗示的运动和手部动作上的区别。基于此，引入了一种新的方法——稀疏成分对齐技术，用于测量大脑和机器在表示上的对齐程度，并能更好地捕捉这两大视觉系统内在的神经调谐。研究发现，标准的视觉DNN在背侧流的表示上比在侧向流和侧流上更对齐。稀疏成分对齐技术提供了比常规群体水平几何更能敏感捕捉系统神经调谐轴的表示对齐度量。
### Innovation
1. 应用了一种新颖的稀疏分解方法来识别每个流中的视觉表示的主要成分。2. 引入了一种新的方法——稀疏成分对齐技术，用于测量大脑和机器在表示上的对齐程度。3. 深入揭示了DNN与人类视觉系统不同流之间的表示对齐和神经调谐差异。
### Conclusion
标准的视觉DNN在背侧流的表示上比在侧向流和侧流上更对齐。稀疏成分对齐技术比常规群体水平几何更能敏感捕捉系统神经调谐轴，提供了对表示对齐度量的更精细测量。
## 768. `cs.LG` - 改进的无模型决策估计系数及其在对抗MDP中的应用 [PDF](https://arxiv.org/pdf/2510.08882), [HTML](https://arxiv.org/abs/2510.08882)
### Authors
Haolin Liu,Chen-Yu Wei,Julian Zimmert
### Background
研究结构化观测条件下的决策制定（DMSO），Foster等人在2021年和2023年的工作中通过决策估计系数（DEC）分析了其复杂度，并在模型类规模上缩小了遗憾上界和下界的差距。然而，他们提出的乐观DEC仅能适用于随机环境，未明确适用于对抗环境。本文进一步研究了无模型决策估计系数，去掉乐观性假设，通过信息增益驱动探索，解决了Foster等人方法在对抗环境中的应用问题，并同时在混合MDP中取得了首个无模型遗憾界成果，填补了相关领域的主要空白。与此同时，改进了无模型学习中的在线函数估计过程，提高了潜在遗憾界的表现，使之与基于乐观的方法相当或更优。
### Innovation
提出了去除乐观性的无模型DEC（Dig-DEC），通过信息增益驱动探索。Dig-DEC在混合MDP中实现了无模型条件下率先的遗憾界，解决了先前研究的开放问题。改进了无模型学习中的在线函数估计过程，提高了遗憾界的上限，使其性能可与基于乐观的方法媲美或更佳。这些改进填补了模型类规模上遗憾上界和下界的差距，且可应用于对抗MDP环境。
### Conclusion
通过引入去除乐观性的模型自由DEC（Dig-DEC），填补了基于DEC方法在处理对抗MDP环境的遗憾界问题；此外，还通过改进无模型学习的在线函数估计过程，解决了混合MDP下的遗憾界问题，特别是在Bellman完备MDP中实现了与基于乐观方法相似或更优的性能。
## 769. `cs.LG` - 使用表格基础模型进行空间时间相关的小地球数据简单且稳健预测 [PDF](https://arxiv.org/pdf/2510.08920), [HTML](https://arxiv.org/abs/2510.08920)
### Authors
Yuting Yang,Gang Mei,Zhengjing Ma,Nengxiong Xu,Jianbing Peng
### Background
小地球数据是具有有限短期监测变化的地质科学观测数据，虽然稀疏但具有重要意义，通常表现出空间时间和时间的相关性。尽管这些数据规模较小，其空间时间预测对于理解地质科学过程至关重要。然而，传统的时空预测深度学习模型通常需要针对不同场景进行特定任务训练，而基础模型无需特定任务训练，但它们往往会对预训练分布的全局均值存在预测偏差
### Innovation
本文提出了一种简单且 robust 方法来预测空间时间相关的小地球数据。该方法的关键是对小地球数据的空间时间和时间模式进行表征和量化，并采用表格基础模型进行准确的预测。实验结果表明，无论在三个典型场景中的哪一种，本提出的预测方法在大多数情况下的准确性都优于图深度学习模型 (T-GCN) 和表格基础模型 (TabPFN) ，并表现出更强的鲁棒性
### Conclusion
本方法通过表征和量化小地球数据的空间时间和时间模式，利用表格基础模型实现不同场景下的精准预测，从而实现了在三个典型场景中优于图深度学习模型和表格基础模型的准确性。
## 770. `cs.LG` - 多臂老虎机问题的频域分析：探索与利用之间的全新视角 [PDF](https://arxiv.org/pdf/2510.08908), [HTML](https://arxiv.org/abs/2510.08908)
### Authors
Di Zhang
### Background
多臂老虎机(MAB)问题是最基本的序贯决策模型之一，核心挑战是探索与利用之间的权衡。尽管UCB和Thompson Sampling算法及其对应的后悔理论已经很成熟，但现有的分析主要集中在时间域和累积后悔上，难以反映学习过程的动态本质。
### Innovation
本文提出了一个新颖的频域分析框架，将老虎机过程重新表述为信号处理问题，将每个臂的奖励估计视为频谱成分，其不确定性对应于频谱的频率，而老虎机算法解释为自适应滤波器。构建了一个正式的频域老虎机模型，并证明了主要定理：UCB算法中的置信界项在频域中相当于应用于不确定频谱成分的时间变化增益，该增益与访问计数的倒数平方根成反比。基于此，进一步推导出关于探索率衰减的时间内动态边界条件。
### Conclusion
该理论不仅为经典算法提供了新的直观物理解释，还为设计具有自适应参数调整的新一代算法奠定了坚实的理论基础。
## 771. `cs.LG` - IoV SPS中基于速度和密度的RRI分析与AoI最小化优化 [PDF](https://arxiv.org/pdf/2510.08911), [HTML](https://arxiv.org/abs/2510.08911)
### Authors
Maoxin Ji,Tong Wang,Qiong Wu,Pingyi Fan,Nan Cheng,Wen Chen
### Background
本文针对半持续调度（SPS）在车联网（IoV）中的问题，特别是在包冲突和车辆速度相关信道不确定性导致Age of Information（AoI）恶化的情况下，提出了基于大规模语言模型（LLM）和深度确定性策略梯度（DDPG）的优化方法。首先建立了AoI的计算模型，考虑了车辆速度、密度和资源预留间隔（RRI）的影响。之后，设计了一个双路径优化方案。实验结果表明，LLM可以在积累少量示例后显著降低AoI，且不需模型训练，而DDPG方法在训练后可以实现更加稳定的性能。
### Innovation
提出了基于大规模语言模型（LLM）和深度确定性策略梯度（DDPG）的AoI优化方法。该方法通过考虑车辆速度、密度和RRI的影响来优化AoI，并通过双路径优化方案进一步改进了AoI的性能。LLM用于生成最优参数配置，而DDPG方法依赖状态空间和奖励函数进行优化；并且该方法在训练后可以实现更加稳定的性能。
### Conclusion
通过引入基于大规模语言模型和深度确定性策略梯度的方法，本文提出了一个能有效减少半持续调度（SPS）在车联网（IoV）中AoI恶化的优化方案。实验结果证明，该方案可以通过少量示例显著降低AoI，且在训练后可以获得稳定的效果。
## 772. `cs.LG` - 基于证据深度学习的双层元策略控制动态不确定性校准 [PDF](https://arxiv.org/pdf/2510.08938), [HTML](https://arxiv.org/abs/2510.08938)
### Authors
Zhen Yang,Yansong Ma,Lei Chen
### Background
传统的证据深度学习（EDL）方法依赖静态超参数进行不确定性校准，这限制了它们在动态数据分布中的适应性，导致在高风险决策任务中校准和泛化性能较差。
### Innovation
提出了一种动态元学习框架——Meta-Policy Controller (MPC)，通过在内层调整KL散度系数和狄利克雷先验强度，在外层通过多目标奖励优化来平衡预测准确性和不确定性质量，学习可变狄利克雷先验，增强模型预测的可靠性和校准。
### Conclusion
广泛的实验结果表明，MPC 显著提高了各种任务中模型预测的可靠性和校准，提升了不确定性校准、预测准确性和置信度采样后的性能保持。
## 773. `cs.LG` - MATT-CTR: Unleashing a Model-Agnostic Test-Time Paradigm for CTR Prediction with Confidence-Guided Inference Paths [PDF](https://arxiv.org/pdf/2510.08932), [HTML](https://arxiv.org/abs/2510.08932)
### Authors
Moyu Zhang,Yun Chen,Yujun Jin,Jinxin Hu,Yu Zhang,Xiaoyi Zeng
### Background
近年来，越来越多的研究关注于优化点击率（CTR）模型架构以更好地建模特征交互，或改进训练目标以促进参数学习，从而提高预测性能。然而，这些努力主要集中在训练阶段，忽视了在推理阶段优化的机会。特别地，罕见的特征组合会降低预测性能，导致不可靠或低置信度的输出。为了释放训练好的CTR模型的预测潜力，本文提出了一种模型无关的测试时间范式（MATT），该方法利用特征组合的置信分数来引导生成多个推理路径，从而减轻低置信度特征对最终预测的影响。
### Innovation
本文创新地提出了一种模型无关的测试时间范式（MATT），通过引入分层概率哈希方法来估计特征组合在不同级别上的出现频率，作为对应的置信分数。然后，使用这些置信分数作为采样概率，通过迭代采样生成多个针对特定实例的推理路径，并综合多个路径的预测评分进行稳健预测。这种方法可以在保持现有CTR模型兼容性的同时，显著提高模型的预测性能和可靠性。
### Conclusion
大量的离线实验和在线A/B测试验证了MATT在现有CTR模型上的兼容性和有效性。
## 774. `cs.LG` - AB-PINNs：基于残差驱动的自适应基底物理感知神经网络 [PDF](https://arxiv.org/pdf/2510.08924), [HTML](https://arxiv.org/abs/2510.08924)
### Authors
Jonah Botvinick-Greenhouse,Wael H. Ali,Mouhacine Benosman,Saviz Mowlavi
### Background
当前的物理信息神经网络（PINNs）在处理复杂多尺度偏微分方程时遇到了挑战，尤其是在捕捉不同尺度下解的复杂特征方面。传统的无网格方法在训练过程中不能灵活地调整子域，这阻碍了其在多尺度问题上的应用效率和效果。为了改善这一状况，本文提出了自适应基底物理信息神经网络（AB-PINNs），结合了自适应的网格细化技术和动态调整子域的方法，使每个子域能够更好地适应解的内在特征，并为难以表示的解部分提供额外的表达能力。这种方法特别适用于多尺度问题，可以通过动态引入新的子域来避免局部极小值的收敛问题，并减少对超参数调优的需求。
### Innovation
本文引入了自适应基底物理信息神经网络（AB-PINNs），这种方法能够根据解的内在特征动态优化子域。借鉴了经典网格细化技术的理念，AB-PINNs在训练过程中能够根据残差损失高风险区域动态地引入新的子域，从而显著提高了模型在复杂多尺度问题上的适应性和准确性。AB-PINNs的优势在于其灵活性和在收敛至局部极小值时的预防机制，以及减少超参数调优需求的能力。
### Conclusion
本研究证明了AB-PINNs在解决各种复杂多尺度偏微分方程问题时的有效性。相较于静态子域划分，这种自适应方法能够更好地捕捉多尺度解的复杂特性，有效避免了不良局部极小值的收敛，并减少了对超参数调优的需求，为物理信息神经网络在实际应用中的进一步发展提供了有力的支撑。
## 775. `cs.LG` - 低资源数据学习的分析调查：从分析到探究 [PDF](https://arxiv.org/pdf/2510.08962), [HTML](https://arxiv.org/abs/2510.08962)
### Authors
Xiaofeng Cao,Mingwei Xu,Xin Yu,Jiangchao Yao,Wei Ye,Shengjun Huang,Minling Zhang,Ivor W. Tsang,Yew Soon Ong,James T. Kwok,Heng Tao Shen
### Background
高资源数据在人工智能中取得了显著成功，但数据注释和模型训练的成本仍然很高。AI研究的核心目标是在有限资源数据下实现鲁棒泛化。
### Innovation
本文在Probably Approximately Correct（PAC）框架内运用无偏积极抽样理论，分析低资源数据学习的泛化误差和标签复杂性。提出了一系列针对低资源数据学习优化策略，包括梯度指导优化、元迭代优化、几何感知优化以及基于大语言模型的优化。
### Conclusion
总结了低资源数据学习的关键发现，并强调了这些发现对低资源数据学习的涵义。
## 776. `cs.LG` - Variability Aware Recursive Neural Network (VARNN): 一种用于序列回归建模中捕捉时间偏差的残差记忆模型 [PDF](https://arxiv.org/pdf/2510.08944), [HTML](https://arxiv.org/abs/2510.08944)
### Authors
Haroon Gharwi,Kai Shu
### Background
实世界中的时间序列数据表现出非平稳行为、相位转换以及随时间变化的噪声。这些特性削弱了标准回归模型的鲁棒性。本文探讨了VARNN，一种用于监督时间序列回归的创新性模型，能够在最近的预测残差中学习显式的误差记忆，并据此重新校准后续预测，以适应变动环境。VARNN 增强了前馈预测器，引入了能够从短期上下文残差中更新的误差记忆状态。以此模型，在包括能耗、医疗和环境监测等多个数据集领域进行了实验，结果证明VARNN的性能优越，并且相较于静态、动态和递归基线模型，具有较低的测试MSE和很少的计算开销。我们的研究结果表明，VARNN能够在变动和波动环境下提供稳健的预测，展现出了其作为时间序列学习框架的巨大潜力。
### Innovation
VARNN通过学习显式的误差记忆，能够捕捉到时间序列中波动和漂移的变化特征，并据此调整模型的预测，从而显著提升模型的鲁棒性。该模型克服了普通回归模型在面对非平稳性和临时变化时的不足.
### Conclusion
跨多个数据集领域，VARNN展现出其优越的性能，特别是在能耗、医疗和环境监测领域。VARNN在测试MSE上的表现优于静态、动态和递归基线模型，具有较少的计算开销。这一发现表明，VARNN可以在变动和具有波动性的环境下提供稳健的预测，具有作为时间序列学习的强大框架潜力。
## 777. `cs.LG` - 当LLM代理遇见图优化：一种自动数据质量改进方法 [PDF](https://arxiv.org/pdf/2510.08952), [HTML](https://arxiv.org/abs/2510.08952)
### Authors
Zhihan Zhang,Xunkai Li,Yilong Zuo,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang
### Background
文本属性图（TAGs）作为一种结合了结构连接和细粒度语义的强大表示形式，支持广泛的基于数据的应用。然而，图神经网络（GNNs）在TAGs上的性能高度依赖于输入质量，现有的研究主要集中于改进模型架构，而忽略了标明自身数据质量系统的优化。我们通过实验证明，不论是传统的GNNs还是LLM增强的GNNs，在九个典型情景（稀疏性、噪声、不平衡）下都遭受显著的质量下降，表明图的质量成为关键瓶颈。
### Innovation
本文提出了一种统一的多智能体框架——LAGA（大型语言和图智能体），将图质量控制视为首要的数据中心问题。LAGA将检测、计划、动作和评估四个协作智能体整合进一个自动化闭环中。动作智能体采用了双重编码器和三目标设计，以捕捉模态之间互补的信息，进行整体的图质量增强。研究结果表明，LAGA可以提高图质量，并在各种任务和网络架构上取得最先进的性能，验证了数据为中心的质量优化是可靠TAGs和稳健图学习的关键.
### Conclusion
实验结果验证了数据为中心的质量优化为可靠文本属性图和稳健图学习的关键。LAGA通过整合四个协作智能体，并利用双重编码器和三目标设计，成功提升了图的质量，达到了最先进的性能。
## 778. `cs.LG` - HiBBO: HiPPO为基础的高维贝叶斯优化空间一致性 [PDF](https://arxiv.org/pdf/2510.08965), [HTML](https://arxiv.org/abs/2510.08965)
### Authors
Junyu Xuan,Wenlong Chen,Yingzhen Li
### Background
贝叶斯优化（BO）是优化昂贵的黑盒函数的强大工具，但在高维空间中的效果会由于数据稀疏和替代模型可扩展性差而下降。虽然基于变分自编码器（VAE）的方法通过学习低维潜在表示可以解决此问题，但基于重构的目标函数经常会导致潜在空间与原始空间的功能分布不匹配，进而导致优化性能不佳。
### Innovation
本文首先分析了仅使用重构损失可能导致分布不匹配的原因，然后提出了一种新颖的BO框架——HiBBO，利用HiPPO——一种长期序列建模方法——将空间一致性引入VAE潜在空间构建中，以减少潜在空间与原始空间的功能分布不匹配。实验结果表明，HiBBO在收敛速度和解决方案质量上优于现有的VAEBO方法，填补了高维序列表示学习与有效贝叶斯优化之间的差距，使其能够更广泛地应用于神经架构搜索、材料科学等领域。
### Conclusion
通过HiBBO框架，本文提高了高维空间中的贝叶斯优化效果，为神经架构搜索、材料科学等领域的应用奠定了基础。
## 779. `cs.LG` - 学习正则化器：可以正则化的学习优化器 [PDF](https://arxiv.org/pdf/2510.08968), [HTML](https://arxiv.org/abs/2510.08968)
### Authors
Suraj Kumar Sahoo,Narayanan C Krishnan
### Background
学习优化器（LOs）是一种元学习技术，因其参数化和训练能力而越来越受欢迎，以实现高效优化。传统的梯度基优化方法结合了显式正则化技术（如Sharpness-Aware Minimization (SAM)，Gradient-norm Aware Minimization (GAM)，以及Gap-guided Sharpness-Aware Minimization (GSAM)），以提高泛化能力和收敛性。研究提出了一个基本问题：正则化器能否被学习？
### Innovation
研究通过实验演示了LOs能够被训练以学习并内化传统正则化技术的效果，而不必在目标函数中显式应用这些正则化方法。LOs在标准基准测试上表现优越，无论它们是否具有访问显式正则化的能力，带正则化的LOs在测试精度和泛化能力上都优于未正则化的LOs。此外，结果显示LOs能够保留并将这些正则化效果转移到新的优化任务中。研究结果表明LOs能够学习正则化属性，挑战了显式优化目标函数正则化的惯例必要性。
### Conclusion
LOs能够内化并应用传统的正则化技术，提升模型的泛化能力和测试精度，无需在初始目标函数中显式应用这些正则化技术；正则化的LOs能够在新的优化任务中展现出更好的适应性，表明LOs可能具备了与人类所掌握的正则化技术相似的功能。
## 780. `cs.LG` - FedL2T：用于癫痫预测的双重教师蒸馏的个性化联邦学习 [PDF](https://arxiv.org/pdf/2510.08984), [HTML](https://arxiv.org/abs/2510.08984)
### Authors
Jionghao Lou,Jian Zhang,Zhongmei Li,Lanlan Chen,Enbo Feng
### Background
癫痫预测的深度学习模型训练需要大量脑电图（EEG）数据，但获得充分标记的数据因标注成本和隐私限制而困难。现有的联邦学习（FL）方法在处理患者间变异时无法在异质客户端设置下实现稳定的性能。
### Innovation
提出了FedL2T，一种结合了新颖的双重教师知识蒸馏策略的个性化联邦学习框架，通过客户端同时学习全局聚合模型和动态分配的同伴模型，促进更直接和丰富的知识交流。采用自适应多级蒸馏策略，根据任务置信度对预测输出和中间特征表示进行对齐。此外，引入邻近正则化项来约束个人模型更新，以增强训练稳定性。
### Conclusion
FedL2T在两个EEG数据集上的大量实验中表现出色，尤其是在低标记条件下，且收敛速度快且稳定，减少了通信轮数和相关开销，突显了它在敏感医疗场景下进行癫痫预测的可靠性和个性化潜力。
## 781. `cs.LG` - 诊断和缓解自我奖励RL中的系统偏差 [PDF](https://arxiv.org/pdf/2510.08977), [HTML](https://arxiv.org/abs/2510.08977)
### Authors
Chuyi Tan,Peiwen Yuan,Xinglin Wang,Yiwei Li,Shaoxiong Feng,Yueqi Zhang,Jiayi Shi,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li
### Background
强化学习（RL）通过验证奖励（RLVR）提升了大型语言模型（LLMs）的推理能力，但在持续进行数据规模扩展时受到有限的标注样本文本的限制。强化学习（RLIR）靠策略模型自身为其展开的行动序列赋予奖励，能够在无标签环境下实现可持续的增长，但其性能和稳定性不及RLVR。研究发现性能差异源于系统偏差：模型倾向于高估其高置信度的展开序列，导致奖励估计存在偏差，并随训练进行累积，逐渐背离最佳策略，造成不稳定的训练。
### Innovation
本文提出了一种新的强化学习方法——聚合奖励的强化学习（RLER），它通过聚合多样化的模型并调整奖励插值与展开序列选择，来缓解系统偏差。实验结果表明，与RLIR相比，RLER性能提升13.6%，与RLVR的性能差距也为3.6%，在无标签数据上实现了稳定的扩展，具有很强的应用价值。
### Conclusion
通过RLER聚合多样化的模型并调整奖励插值与展开序列选择，可以缓解自我奖励RL中的系统偏差，从而实现无标签样本上的稳定扩展，使得这种方法在无标签环境下具有很高的应用潜力。
## 782. `cs.LG` - PlatformX：用于高效神经网络架构搜索的端到端可移植平台 [PDF](https://arxiv.org/pdf/2510.08993), [HTML](https://arxiv.org/abs/2510.08993)
### Authors
Xiaolong Tu,Dawei Chen,Kyungtae Han,Onur Altintas,Haoxin Wang
### Background
已有硬件感知的神经架构搜索（HW-NAS）已成为设计适合边缘设备的高效深度神经网络的强大工具。然而，现有方法在实际部署中仍然存在高时间成本、频繁的手动性能分析以及跨具有复杂、设备特定能耗行为的多样硬件平台的不良可扩展性等问题。
### Innovation
本文提出了PlatformX，这是一种完全自动化且可移植的HW-NAS框架，旨在解决上述局限性。PlatformX集成了四个关键组件：一个以能量驱动的搜索空间、一个跨设备可迁移的内核级能耗预测器、一个基于帕累托的多目标搜索算法、以及一个高分辨率的运行时能耗分析系统。
### Conclusion
通过对多个移动平台的评估，PlatformX显著减少了搜索开销，同时保持了准确性和能耗的真实性。它识别的模型在准确性和效率方面均优于MobileNet-V2，模型最高准确率达到0.94或每次推理能耗低至0.16毫焦耳。代码和教程可在本链接获取。
## 783. `cs.LG` - SQS：通过稀疏量化子分布实现的贝叶斯DNN压缩 [PDF](https://arxiv.org/pdf/2510.08999), [HTML](https://arxiv.org/abs/2510.08999)
### Authors
Ziyi Wang,Nan Jiang,Guang Lin,Qifan Song
### Background
在有限资源的设备上部署大规模神经网络模型时，压缩这些模型是必不可少的。大多数现有方法分别采用权重剪枝或低位宽量化的方式，这往往导致压缩率不够高，无法在性能下降的前提下提供更好的压缩效果。
### Innovation
本文引入了一种统一框架SQS（Simultaneous Pruning and Low-bit Quantization via Bayesian Variational Learning），通过贝叶斯变分学习同时实现权重剪枝和低位宽量化。SQS框架通过引入尖刺-薄脊先验诱导稀疏性，并使用混合高斯模型量化模型权重，以实现低位宽精度。理论分析显示，所提出的变分方法与稀疏和量化 deep 神经网络是一致的。实验表明，SQS方法在 ResNet、BERT-base、Llama3 和 Qwen2.5 模型压缩中实现了比现有方法更高的压缩率，同时性能下降可与现有方法媲美。
### Conclusion
本文提出的SQS方法通过贝叶斯变分学习和混合高斯模型，实现神经网络的同时剪枝和量化，取得了比现有方法更高的压缩率和相似的性能下降。能够提高在资源受限设备上部署神经网络模型的效率。
## 784. `cs.LG` - Constraints-of-Thought: 一种指导语言模型搜索中的约束推理框架 [PDF](https://arxiv.org/pdf/2510.08992), [HTML](https://arxiv.org/abs/2510.08992)
### Authors
Kamel Alrashedy,Vriksha Srihari,Zulfiqar Zaidi,Ridam Srivastava,Pradyumna Tambwekar,Matthew Gombolay
### Background
当前，虽然学术界在使大语言模型（LLMs）执行多步骤规划方面取得了显著进展，但LLMs在确保多步骤规划符合用户高层次意图和满足符号约束方面仍存在问题，特别是在复杂或多步骤环境中。现有推理方法，如Chain-of-Thought (CoT)、Tree-of-Thought (ToT)和验证器增强方法，扩大了搜索空间，但往往会生成不可行的行动或虚构的步骤。因此，需要一种新的方法来解决这些问题，使其在确保规划符合整体意图和操作合规性方面更有效、更合理，提升规划效率和决策过程中的可验证性，尤其是在复杂的多步骤任务中。
### Innovation
本文提出了一种名为Constraints-of-Thought (Const-o-T) 的框架，这种方法提供了一个结构化的先验信息，可以引导蒙特卡洛树搜索（MCTS）聚焦在语义上有意义的路径上。每个推理步骤均表示为一个（意图，约束）对，用于压缩搜索空间并确保计划的完整性。与之前的仅生成推理痕迹或事后验证输出的方法不同，Const-o-T 使用意图-约束对积极地聚焦搜索，确保生成的计划是可行且有意义的，显著提高了搜索效率和决策的可验证性。通过集成Const-o-T到 MCTS中，利用意图-约束对结构化表示进行剪枝和引导探索，从而促进有效、符合约束和适应特定领域的规划。
### Conclusion
通过在风险游戏、CAD代码生成和算术推理三个领域内与基线方法进行对比实验，证明该方法能够提高规划准确性，并且与基线相比有更好的结构性对齐。本文的主要贡献在于展示了Const-of-T框架在指导语言模型搜索中的约束推理方面具有通用性，可推动更高效、更约束导向且更适应领域特点的大语言模型规划方法的发展。
## 785. `cs.LG` - Slim Scheduler：一种针对高效CNN推断的运行时感知的RL和调度系统 [PDF](https://arxiv.org/pdf/2510.09018), [HTML](https://arxiv.org/abs/2510.09018)
### Authors
Ian Harshbarger,Calvin Chidambaram
### Background
大部分神经网络调度的研究主要集中在优化固定的宽度的端到端静态模型，并未考虑到根据异构硬件和运行时条件变化的动态调度方法。
### Innovation
提出了一种混合调度框架Slim Scheduler，结合了Proximal Policy Optimization (PPO)强化学习策略与基于贪心算法的调度程序，以协调分布式的细粒度模型的推理调度。这是一种分层设计，减少了搜索空间的复杂性，避免了特定硬件的过拟合，并平衡了效率和吞吐量。
### Conclusion
与完全随机的任务分配基线相比，Slim Scheduler可以在减少平均延迟（96.45%）和能耗（97.31%）的同时，准确率下降到最窄的模型（70.3%）。此外，它还能在网络延迟和能耗标准差增加的情况下，进一步减少平均延迟和能耗，从而提高整体任务吞吐量。
## 786. `cs.LG` - Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers [PDF](https://arxiv.org/pdf/2510.09017), [HTML](https://arxiv.org/abs/2510.09017)
### Authors
Rui Bu,Haofeng Zhong,Wenzheng Chen,Yangyan Li
### Background
基于Transformer架构的大模型容易出现极端词元现象，如注意力陷阱和值状态漏斗，这些问题导致模型性能下降、量化保真度降低和可解释性变差。这些现象源于模型通过过度关注值状态接近零的词元学习了一种低效的‘空操作’行为，从而形成了问题的相互强化机制。
### Innovation
论文提出了一种名为Value-State Gated Attention (VGA)的简单、专用且稳定架构机制，通过直接打破这种循环来高效地执行‘空操作’注意力。VGA引入了一种可学习的、依赖数据的门控机制，直接从值向量（V）中计算得到，用于调节输出。通过理论分析底层梯度，我们表明，使用自身函数对值状态进行门控比以前基于输入嵌入进行门控的方法更有效地解耦值和注意力得分的更新。这创建了一条直接的调节路径，使模型能够根据其出现的价值表示抑制词元的贡献。
### Conclusion
实验结果表明，VGA显著缓解了注意力陷阱的形成并稳定了值状态规范，从而提高了模型性能、稳健的量化保真度和增强的模型可解释性。
## 787. `cs.LG` - 在 noisy 忘记数据集上的 LLM 复习：关于不完整、改写和带水印数据的研究 [PDF](https://arxiv.org/pdf/2510.09007), [HTML](https://arxiv.org/abs/2510.09007)
### Authors
Changsheng Wang,Yihua Zhang,Dennis Wei,Jinghan Jia,Pin-Yu Chen,Sijia Liu
### Background
大规模语言模型（LLMs）展示了强大的生成能力，但会因记忆敏感数据、强化偏见和生成有害内容而引发伦理和安全问题。这些风险促使了对 LLM 复习的兴趣，即从预训练模型中移除与不良数据相关知识的任务。然而，现有方法大多假设可以访问干净且明确的忘记数据样本，但在实际应用中，忘记数据往往质量低下、被重新改写或带有水印标志。这种情况下，数据的可靠性受到质疑。本研究调查了在 noisy 忘记数据集上进行 LLM 复习的可能性，这些数据包含不完整、改写和带水印的信息。本研究系统地评估了 RMU 和 NPO 这两种当前最先进的 LLM 复习方法在 noisy 忘记数据集上的表现。研究表明，提供核心语义信号保持不变的情况下，复习过程依然具有相当的鲁棒性。
### Innovation
本研究首次系统性地评估了在 noisy 忘记数据集上进行 LLM 复习的方法。通过使用两种当前最先进的 LLM 复习方法（RMU 和 NPO）在 noisy 忘记数据集上的表现，研究发现，在 core semantic signals 保持不变的情况下，复习方法依然具有鲁棒性。该研究提供了基于 saliency 的解释：推动遗忘的关键语义组件即使在表层形式有显著变化的情况下依然保持影响，表明复学习算法主要受深层语义线索而不是浅层词素模式的指导。
### Conclusion
本研究揭示了在 noisy 忘记数据集上进行 LLM 复习的鲁棒性，基于 saliency 分析表明核心语义信息的持续重要性。这为改进现有复学习算法提供了理论基础，以更好地处理实际应用中常见的不完整、改写和带水印的忘记数据。
## 788. `cs.LG` - 优化器的收敛性意味着在平衡状态下的特征值过滤 [PDF](https://arxiv.org/pdf/2510.09034), [HTML](https://arxiv.org/abs/2510.09034)
### Authors
Jerome Bolte(TSE-R),Quoc-Tung Le(UGA, LJK),Edouard Pauwels(TSE-R)
### Background
大量的实证证据表明，在深度神经网络训练中，各种优化器倾向于找到接近全局最优解的解。本文从一个不同的视角出发，假设收敛到任意固定点而非证明其存在。研究表明，不同的优化器实质上是通过其超参数决定的特征值过滤器。
### Innovation
本文提出了两种新的算法，这些算法能够增强特征值过滤效果，有效促进更宽的最小值。理论分析基于广义的Hadamar-Perron稳定流形定理，并适用于通用的半代数 $C^2$ 函数，无需额外的非退化条件或全局Lipschitz假设。
### Conclusion
通过理论分析和数值实验，本文证明了优化器的收敛性实际上意味着在平衡状态下进行特征值过滤，并提出了一种新的增强特征值过滤的算法。
## 789. `cs.LG` - MagicDock：通过梯度反向设计面向对接的目的性配体设计 [PDF](https://arxiv.org/pdf/2510.09020), [HTML](https://arxiv.org/abs/2510.09020)
### Authors
Zekai Chen,Xunkai Li,Sirui Zhang,Henan Sun,Jia Li,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang
### Background
配体从头设计是寻找能够与蛋白质受体充分对接并获得强结合亲和力的候选蛋白质或分子的任务。它在医学和生物学应用中具有重要性。然而，大多数现有的研究受到伪从头设计、有限的对接建模和不灵活的配体类型的限制。
### Innovation
提出了一种名为MagicDock的框架，它基于逐步管道和可微表面建模。主要创新点包括：（1）采用了以梯度逆向为核心的精设计框架，结合所掌握的受体和配体的一般对接知识作为基础模型，通过结合配体预判将对接知识作为逆向梯度流事例化，引导从头配体生成过程。（2）强调在对接过程中采用可微表面建模，利用可学习的3D点云表示精确捕捉结合细节，确保生成的配体能够保持对接的有效性和直接可解释的空间指纹。（3）对不同类型的配体进行定制设计，并整合到一个具有灵活触发器的统一梯度逆向框架中，以确保广泛的应用范围。此外，为MagicDock的每个组件提供了严格的理论保证。
### Conclusion
在9个情景下的广泛实验表明，MagicDock分别在针对蛋白质配体设计和分子配体设计的最先进的基线模型中取得了平均27.1%和11.7%的改进。
## 790. `cs.LG` - 机器学习训练的环境影响持续上升 明显显示反作用效应 [PDF](https://arxiv.org/pdf/2510.09022), [HTML](https://arxiv.org/abs/2510.09022)
### Authors
Clément Morand(STL),Anne-Laure Ligozat(ENSIIE, LISN, STL),Aurélie Névéol(STL, LISN)
### Background
近年来，机器学习（ML）方法在基准测试中的表现显著提升，但计算需求也随之增加。针对这一问题，硬件、算法和碳排放优化策略被提出以降低能耗和环境影响。然而，这些策略是否能够实现可持续的机器学习模型训练仍需探讨。本文通过估算过去十年中训练著名的人工智能系统的环境影响，特别是关注显卡的整个生命周期，揭示了这一问题的重要趋势。
### Innovation
本文对机器学习训练的环境影响进行了系统性评估，特别关注显卡在整个生命周期中的影响。研究发现，虽然生产显卡的环境影响有所增加，但训练ML模型的能量消耗和环境影响却呈指数级增长，即使考虑到一些减少策略如转移至碳密度较低的地区的用电进行训练，这一趋势仍然存在。研究还证明，仅仅提高效率不足以确保ML的可持续性，还应减少AI活动，质疑资源密集型训练的规模和频率。
### Conclusion
本研究强调仅提高效率不足以确保ML的可持续发展，减少AI活动并质疑资源密集型训练的规模和频率同样重要，以真正减轻AI的环境影响。
## 791. `cs.LG` - 第二步：更强的适应性攻击绕过针对LLM越狱和提示注入的防御 [PDF](https://arxiv.org/pdf/2510.09023), [HTML](https://arxiv.org/abs/2510.09023)
### Authors
Milad Nasr,Nicholas Carlini,Chawin Sitawarin,Sander V. Schulhoff,Jamie Hayes,Michael Ilie,Juliette Pluto,Shuang Song,Harsh Chaudhari,Ilia Shumailov,Abhradeep Thakurta,Kai Yuanqing Xiao,Andreas Terzis,Florian Tramèr
### Background
当前，对于防止攻击者诱导有害知识或远程触发恶意行为（即，针对‘越狱’和‘提示注入’的防护措施）的评估方法通常是使用一组静态的有害攻击字符串进行测试，或者使用没有针对防御措施设计的计算能力较弱的优化方法。我们指出，这种评估过程是存在缺陷的。真正的测试应该是在适应性攻击者表明修改其攻击策略来对抗防御设计，同时以较多资源优化其目标的情况下进行的。我们系统性地调整并扩展了常见的优化技术（梯度下降、强化学习、随机搜索和人机联合探索），成功绕过了12种基于多种技术的新型防御方法，大多数情况下攻击成功率超过了90%；此外，大部分此前报告防御效能极高的措施现在也被证明能被攻击绕过。
### Innovation
我们提出了对更强适应性攻击者进行评估的方法，这些攻击者不仅修改其攻击策略来对抗防御设计，而且还使用有效的优化方法进行策略优化。通过使用梯度下降、强化学习、随机搜索和人机联合探索等通用优化技术，成功绕过了多种现有的防护措施。
### Conclusion
未来的防护工作必须考虑到更强的攻击方式，如我们描述的适应性攻击，以能够提出可靠的和令人信服的关于防护性壮性的声明。
## 792. `cs.LG` - 使用实际多模态数据集成的时空图卷积网络进行电动汽车充电需求预测 [PDF](https://arxiv.org/pdf/2510.09048), [HTML](https://arxiv.org/abs/2510.09048)
### Authors
Jose Tupayachi,Mustafa C. Camur,Kevin Heaslip,Xueping Li
### Background
交通运输是温室气体排放的主要来源之一，亟需向可持续的替代方案，如电动汽车(EVs)进行转变。然而，充电基础设施的空间分布不均和利用率不均造成了对电网稳定性和投资规划的挑战。本研究以美国田纳西州为例，介绍了结合图卷积网络和时间架构的时空预测框架TW-GCN，用于预测EV充电需求。
### Innovation
提出了TW-GCN框架，结合时空数据和图卷积网络，以多模式实际数据为基础，预测EV充电需求。实验结果显示，在预测精度和响应稳定性方面，1DCNN（一维卷积神经网络）表现最优。该方法提供了可持续交通转型和电网可靠性管理的数据驱动智能支持。
### Conclusion
通过区域分析展示了东、中、西田纳西州在模型预测精度上的差异，反映了站点密度、人口数量和当地需求变化对模型性能的影响。TW-GCN框架可以在电动汽车基础设施规划中促进数据驱动智能的应用，支持可持续交通转型和社会稳定的电网管理。
## 793. `cs.LG` - 智能总体约束博弈对抗强化学习在自动驾驶中的鲁棒驾驶控制 [PDF](https://arxiv.org/pdf/2510.09041), [HTML](https://arxiv.org/abs/2510.09041)
### Authors
Junchao Fan,Xiaolin Chang
### Background
深度强化学习（DRL）在开发自动驾驶政策方面取得了显著的成果，但其容易受到对抗性攻击的影响，这是其在真实世界应用中的主要障碍。虽然现有的鲁棒方法已经取得了成功，但它们仍然存在三个关键问题：（i）这些方法仅针对短视的对抗性攻击进行训练，限制了它们应对更具策略性的威胁的能力；（ii）难以引发真正安全关键的事件（例如碰撞），但常常导致轻微后果；（iii）由于缺乏鲁棒约束，这些方法在训练时可能导致学习不稳定和政策漂移。这些问题限制了基于DRL的自动驾驶技术的实际应用和发展。
### Innovation
提出了一种名为智能总体约束博弈对抗强化学习（IGCARL）的新型鲁棒自动驾驶方法，包括战略性目标对手和一个鲁棒驾驶代理。IGCARL在对抗性环境中确保稳定学习，并通过优化受到约束的方法来减轻攻击引起的策略漂移。IGCARL的目标对手利用DRL的时序决策能力，执行战略上协调的多步攻击，并且专注于引发安全关键事件。鲁棒驾驶代理通过与对手交互来学习，以对抗对抗性攻击开发出一个鲁棒的自动驾驶策略。实验结果表明，IGCARL相比最先进的方法，至少提高了27.9%的成功率，显示出更强的对抗性攻击鲁棒性，并增强了基于DRL的自动驾驶的安全性和可靠性。
### Conclusion
IGCARL改进了现有的鲁棒性方法，通过克服现有方法在应对高策略性攻击、现实世界关键事件和学习稳定性方面的局限性，展示了在对抗攻击下的优越性和提升基于DRL的自动驾驶的安全性和可靠性。
## 794. `cs.LG` - 改进工业时序中异常检测的角色：分割与异构集成的作用 [PDF](https://arxiv.org/pdf/2510.09079), [HTML](https://arxiv.org/abs/2510.09079)
### Authors
Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello
### Background
在机器学习领域，分割模型可以识别时间序列中的状态变化，有助于在正常和异常条件之间检测转换。特定技术如Change Point Detection（CPD），尤其是ChangeFinder算法，被成功应用于分割时间序列并提高异常检测能力，尤其是在多变量环境中减少时间不确定性。本研究探索了将分割技术与异构集成结合使用，以改进工业生产中的异常检测。研究表明，将分割作为预处理步骤，然后选择异构集成算法，显著提高了案例研究中的AUC-ROC指标，从使用PCA和LSTM集成的0.8599提高到使用随机森林和XGBoost的0.9760。
### Innovation
本研究的创新在于将分割技术与异构集成结合使用，以改进工业生产中的异常检测。这种结合显著提高了AUC-ROC指标，表明分割可以减少时间不确定性并有助于监督算法的学习过程。
### Conclusion
未来的工作将评估引入从变化点研究中得出的加权特征，结合分割和异构集成，以进一步优化模型在早期异常检测中的性能。
## 795. `cs.LG` - FLToP CTC：利用相对阈值进行分帧级别标记剪枝以实现跨平台高效和节省内存的解码 [PDF](https://arxiv.org/pdf/2510.09085), [HTML](https://arxiv.org/abs/2510.09085)
### Authors
Atul Shree,Harshith Jupuru
### Background
基于CTC的ASR系统在资源受限的环境中面临计算和内存瓶颈。传统的CTC解码器会消耗系统中高达90%的处理时间（例如，wav2vec2-large在L4 GPU上的系统），其效率低下主要是由于密集的标记级操作。
### Innovation
本文提出了一种名为FLToP CTC的新型解码算法，该算法通过相对阈值概率进行分帧级别标记剪枝。通过动态移除每帧中的低概率标记，FLToP CTC在保持微小的WER降解的同时减少了计算和内存需求。
### Conclusion
FLToP CTC在LibriSpeech上实现了10.5倍的运行时加速和2.78倍的内存减少，适用于各种平台（如CPU、GPU等）。它解决了CTC的瓶颈问题，提高了资源受限环境下的可扩展性，并改善了实时应用中的语音识别访问性和效率。
## 796. `cs.LG` - 神经编解码器作为生物信号分词器 [PDF](https://arxiv.org/pdf/2510.09095), [HTML](https://arxiv.org/abs/2510.09095)
### Authors
Kleanthis Avramidis,Tiantian Feng,Woojae Jeong,Jihwan Lee,Wenhui Cui,Richard M Leahy,Shrikanth Narayanan
### Background
神经生理记录，如脑电图（EEG），提供了一种获取生理活动信息的便捷且侵入性小的方式，适用于医疗保健、诊断筛查甚至沉浸式娱乐等领域。然而，这些记录通常产生高维且带噪音的时间序列数据，需要大量的预处理和手工特征提取才能揭示有意义的信息。近年来，研究人员对将大型预训练模型（基础模型）的表示学习技术应用到生物信号解码和解释中表现出了浓厚兴趣。但这种方法的引入也带来了一系列挑战。
### Innovation
本文提出了一种名为BioCodec的替代表示学习框架，灵感来源于神经编解码器，旨在通过离散标记来捕获生物信号的低级特征。BioCodec基于数千小时的EEG数据进行预训练，并在多种下游任务中表现出色，包括临床诊断、睡眠生理学、言语和运动意象解码，特别适用于资源有限的场景。此外，研究还提供了关于码本使用的定性分析，并估计了编码器嵌入的时空一致性，监测EEG连接性。值得注意的是，该方法也被证明适用于其他类型的生物信号数据，例如肌电图（EMG）。
### Conclusion
本文提出的方法提供了一种灵活的生物信号分词解决方案，具有与先进模型相媲美的性能。源代码和模型检查点已共享。
## 797. `cs.LG` - MemLoss：利用回收的对抗样本增强对抗训练 [PDF](https://arxiv.org/pdf/2510.09105), [HTML](https://arxiv.org/abs/2510.09105)
### Authors
Soroush Mahdi,Maryam Amirmazlaghani,Saeed Saravani,Zahra Dehghanian
### Background
当前对抗训练方法已经取得了很大的进展，但大部分方法在提高模型抗干扰能力的同时，往往会降低模型在干净数据上的性能。本文的背景是在保持模型在干净数据上良好性能的前提下，探索提高模型对抗攻击能力的方法，为此引入了一种新的方法称为MemLoss。
### Innovation
本文提出了一个新的方法MemLoss，该方法通过使用过去的生成的对抗样本（称为‘记忆对抗样本’）来增强模型的鲁棒性和准确度。MemLoss能够在多个数据集上平衡提高模型在自然准确性和对抗鲁棒性两方面的性能，实验结果表明其效果优于现有的对抗训练方法，且对攻击具有较强的抵抗力。
### Conclusion
本文证明了MemLoss能够在保持模型良好的自然准确率的前提下，提高模型在对抗攻击中的鲁棒性。实验结果表明这种方法优于现有的对抗训练方法。
## 798. `cs.LG` - 基于对偶比较的得分优化密度估计 [PDF](https://arxiv.org/pdf/2510.09146), [HTML](https://arxiv.org/abs/2510.09146)
### Authors
Petrus Mikkola,Luigi Acerbi,Arto Klami
### Background
本文研究了基于对偶比较的密度估计方法，动机来自于专家知识的提取和人类反馈的学习。通过对未观察到的目标密度与加权获胜密度（偏好选择的边际密度）的关系进行建模，通过分数匹配学习获胜者的得分。进一步通过反归一化的得分估计目标密度，并证明了信念分数和获胜者密度分数之间的线性关系，受到位置依赖的调温场的影响。在布雷德利-特里模型下给出了这种调温场的分析公式，并使用经过调温样本训练的扩散模型（通过分数尺度的退火朗道动态生成）来学习模拟专家复杂的多变量信念密度，仅需要数百到数千次的对偶比较。
### Innovation
本文提出了基于分数匹配的密度估计新方法，特别强调了如何将未观察到的目标密度与加权获胜密度关系进行建模，提出了通过反归一化得到目标密度的算法，并通过调温场将信念分数和获胜者密度分数联系起来，同时还提出了一种基于布雷德利-特里模型的调温场估计方法，以及通过训练扩散模型进行密度估计的新方法。
### Conclusion
通过训练扩散模型介导的分数尺度退火朗道动态生成的样本，可以仅使用数百到数千次的对偶比较就能估计出复杂多变量的专家信念密度，这展示了该方法的强大能力及其在实际应用中的前景。
## 799. `cs.LG` - 隐私保护的公平性：针对差分隐私机器学习中分组隐私风险差异的衡量与缓解 [PDF](https://arxiv.org/pdf/2510.09114), [HTML](https://arxiv.org/abs/2510.09114)
### Authors
Zhi Yang,Changwu Huang,Ke Tang,Xin Yao
### Background
尽管在常规公平感知机器学习（ML）和差异隐私机器学习（DPML）方面取得了显著进展，但是不同群体之间隐私保护的公平性尚未得到充分探讨。现有研究提出了评估群体隐私风险的方法，但这些方法基于数据记录的平均隐私风险，可能导致对群体隐私风险的低估，进而低估不同群体的隐私风险差异。现有的评估最坏情况隐私风险的方法耗时较长，限制了其实践应用。因此，本文旨在提出一种新的成员推理游戏，可以高效审计数据记录的近似最坏情况隐私风险，从而提供更为严谨的群体隐私风险衡量，验证估计群体隐私风险差异的可靠性。并且为了促进DPML中的隐私保护公平性，引入了一种基于差分隐私审计中金丝雀设计的自适应组特定梯度裁剪策略改进的标准DP-SGD算法，验证结果表明该算法能有效缓解不同群体的隐私风险差异，提高了DPML中隐私保护的公平性
### Innovation
本文提出的是一种新的近似最坏情况隐私风险审计的游戏方法，能够有效审计数据记录的隐私风险。同时，一种基于差分隐私审计中的金丝雀策略设计的自适应组特定梯度裁剪策略也被引入到标准DP-SGD算法中，以实现更公平的隐私保护在DPML中的应用
### Conclusion
该研究通过结合新的成员推理游戏方法和自适应组特定梯度裁剪策略，验证了该方法能够更严格地衡量不同群体的隐私风险，增强了DPML中隐私保护的公平性。
## 800. `cs.LG` - AdaPM:一种适用于大规模语言模型训练的部分动量算法 [PDF](https://arxiv.org/pdf/2510.09103), [HTML](https://arxiv.org/abs/2510.09103)
### Authors
Yimu Zhang,Yuanshi Liu,Cong Fang
### Background
在大规模语言模型的训练中，动量被广泛使用，通常能显著加速训练过程。然而，存储动量则通常会带来内存方面的挑战。针对这一问题，本文介绍了一种新的自适应训练策略AdaPM，该策略利用部分动量实现内存高效的优化器。AdaPM采用非均匀动量设计：对于大多数块而言，不一定需要保存完整的动量以保持优化性能。为了减轻部分动量偏差和性能损失的影响，AdaPM通过偏差校正技术增强了部分动量。实验结果表明，该方法在保持效率和性能的同时，将动量占用内存减少了超过90%。对于从60M到1.5B规模的多种语言模型的预训练以及监督微调和RLHF，都能维持优化效果。此外，通过结合在二阶统计量上的内存高效技术，AdaPM还能进一步将优化状态的内存占用减少95%，从而节省超过30%的GPU训练时间，以进行GPT-2 1.5B规模模型的预训练。
### Innovation
提出了一种新的自适应训练策略AdaPM，它利用部分动量实现内存高效的优化器。该方法采用非均匀动量设计，通过偏差校正技术增强了部分动量，有效减少了内存占用，同时保持了模型的优化性能。此外，结合二阶统计量上的内存高效技术，能在优化状态上实现进一步的内存节省。
### Conclusion
AdaPM通过利用部分动量，并结合偏差校正技术和二阶统计量上的内存高效技术，成功地减少了大规模语言模型训练时的内存消耗，同时保持了优化性能。该方法适用于多种语言模型的预训练，以及监督微调和RLHF，减少了大量GPU训练时间。
## 801. `cs.LG` - 鲁棒性和正则化在分层重活化中的作用 [PDF](https://arxiv.org/pdf/2510.09174), [HTML](https://arxiv.org/abs/2510.09174)
### Authors
Benedikt Franke,Florian Heinrich,Markus Lange,Arne Raul
### Background
本文探讨了Git Re-Basin这一新颖的合并训练模型方法。研究发现通过分层模型合并方案，可以显著超越传统MergeMany算法的表现。
### Innovation
提出了一个分层模型合并方案，该方案在多个模型参与时能增强模型对抗性和扰动鲁棒性。
### Conclusion
尽管分层重活化方法在实验中带来了更大的性能下降，但在合并模型中诱发了更强的对抗性和鲁棒性。
## 802. `cs.LG` - Logits Replay + MoClip：稳定、低成本的最小遗忘后训练 [PDF](https://arxiv.org/pdf/2510.09152), [HTML](https://arxiv.org/abs/2510.09152)
### Authors
Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun
### Background
大型语言模型（LLMs）在后训练时面临着专业领域改进与通用能力之间的权衡问题。现有解决方案通过正则化、选择性参数更新或数据为中心的重放来缓解这一紧张关系，但每个方法都会在计算、数据访问或适应性方面带来显著成本。虽然有研究表明可以通过压缩训练信号来避免精度损失，但简单的截断优化不稳且加剧了遗忘问题。
### Innovation
本文提出了一种两阶段框架——Logits Replay + MoClip，首先记录动态Top-K token子集以覆盖概率阈值，并始终包含正确标签；然后通过重放这些紧凑子集来计算精确重归一化损失，避免整个softmax计算，间接起到正则化作用。为了确保优化的稳定性，设计了MoClip优化器，限制梯度动量旋转并应用arctan2基更新缩放。
### Conclusion
实验结果显示，该方法在通信技术（CT）和NL2SQL任务上提高了领域性能，同时在一般基准测试（MMLU、BBH、GPQA、MATH）上减少了遗忘现象，并降低了超过40%的训练成本。这些贡献为LLM的领域适应提供了一条可扩展且架构无关的道路，同时不会牺牲泛化能力。
## 803. `cs.LG` - Agentic-KGR：通过多智能体强化学习进行协同演化知识图谱构建 [PDF](https://arxiv.org/pdf/2510.09156), [HTML](https://arxiv.org/abs/2510.09156)
### Authors
Jing Li,Zhijie Sun,Zhicheng Zhou,Suming Qiu,Junjie Huang,Haijia Sun,Linyuan Qiu
### Background
当前的知识增强大型语言模型依赖于静态、预先构建的知识库，这些知识库存在覆盖面不足和时间过时的问题，限制了其在动态信息环境中的有效性。
### Innovation
（1）一种动态的模式扩展机制，在训练过程中系统地扩展图本体，超越预定义的边界；（2）检索增强的记忆系统，使模型参数和知识结构通过持续优化协同进化；（3）一种可学习的多尺度提示压缩方法，通过自适应序列优化保留关键信息并减少计算复杂性。
### Conclusion
实验表明，与监督基准和单一回合强化学习方法相比，在知识抽取任务中取得显著改进。结合GraphRAG后，我们的方法在下游问答任务中表现出更高的性能，在准确性和知识覆盖率上均优于现有方法。
## 804. `cs.LG` - 通过子空间优化在资源受限环境下高效训练视觉变压器 [PDF](https://arxiv.org/pdf/2510.09160), [HTML](https://arxiv.org/abs/2510.09160)
### Authors
Le-Trung Nguyen,Enzo Tartaglione,Van-Tam Nguyen
### Background
随着人工智能在日常生活中的广泛应用，能源消耗和数据隐私问题变得日益突出。针对这一问题，研究从数据边缘设备上直接训练模型出发，以减少能源消耗并保护数据隐私。然而，现代神经网络规模的扩大为边缘设备上的训练带来了重大障碍。尽管之前的许多研究集中在紧凑卷积架构上，该论文则采用了子空间训练的方法应用于变压器模型上，目的是减轻反向传播的记忆瓶颈问题并提升变压器模型的推理效率.
### Innovation
论文提出了一种名为Weight-Activation Subspace Iteration (WASI)的方法，该方法将训练局限于固定的子空间内，适用于视觉变压器模型的高效训练。WASI不仅保留了原始训练的准确性，还减少了高达62倍的记忆使用量和高达2倍的计算成本（FLOPs），并在Raspberry Pi 5上实现了大约1.5倍的更快训练和推理速度.
### Conclusion
实验结果表明，WASI方法在保留与传统训练相似准确性的基础上，大幅减少了内存使用和计算成本，并在Raspberry Pi 5设备上的训练和推理速度上具有显著优势。
## 805. `cs.LG` - 带有延迟反馈和通用函数近似的对抗情景下上下文多臂伯努利问题的遗憾界 [PDF](https://arxiv.org/pdf/2510.09127), [HTML](https://arxiv.org/abs/2510.09127)
### Authors
Orin Levy,Liad Erez,Alon Cohen,Yishay Mansour
### Background
本文探讨了在存在延迟反馈的上下文多臂伯努利问题（CMAB）中的遗憾最小化算法。具体场景包括损失观测值可能会延迟到达，并且这些延迟是恶意选择的。先前的研究通常在没有延迟假设下或者延迟有限且固定的假设下进行了研究，但本文重点关注更一般的延迟情况下，特别是在直接访问有限策略集合时的情形，得到了一个最优的遗憾界。进一步地，本文研究了带有函数近似的一般上下文损失函数类，并提出了一个基于最早先进先出（FIFO）的假设条件，给出了遗憾界的上界。该研究扩展了CMAB问题在实际应用中的适用范围，处理了更加复杂和挑战性的情况，即延迟可以由外部对手选择且上下文损失函数是未知的且可以是无限的。这使得研究结果更加适用于现实世界的动态决策问题，如在线广告、推荐系统等。在函数约简方面，本文也有一系列的贡献，包括设计并评估了一种新的基于Vovk的聚合预测器的稳定性分析。Vovk的聚合预测器在此背景下被用来实现函数近似，并确保它具有的稳定性参数在$theta(big(frac{1}{1+beta}big))$的范围内，这是一个新颖的结果。这些模型和方法在处理现实世界中的动态决策问题时具有重要的理论和实践价值。
### Innovation
1. 提出了一套适应于延迟预期可变且由攻击者控制的上下文多臂伯努利问题的算法框架。2. 在函数近似的一般场景下，给出了一个新奇的遗憾率上界，该结果在理论上达到了最优，但在实践中也提供了较强的适用性和灵活性。3. 通过最小化Vovk的聚合预测器的稳定性参数，首次确定了该算法的实际应用的稳定性边界，为实现实时更加高效的决策系统提供了理论保障。
### Conclusion
本文通过引入一个既考虑延迟又考虑函数近似的算法框架，解决了在具有不确定延迟的上下文多臂伯努利问题中遗憾最小化的问题。研究成果不仅在理论上优化了遗憾界，且验证了新算法的有效性。最终，本文提供的分析和算法对于在线广告、推荐系统等领域中的实际应用具有重要价值，可以用于制定更加高效的动态决策策略。
## 806. `cs.LG` - 时序电子健康记录跨表示基准测试在临床结局预测中的应用 [PDF](https://arxiv.org/pdf/2510.09159), [HTML](https://arxiv.org/abs/2510.09159)
### Authors
Tianyi Chen,Mingcheng Zhu,Zhiyao Luo,Tingting Zhu
### Background
电子健康记录（EHRs）允许使用深度学习技术进行临床预测，但最优的患者数据表示方法仍不清楚，因为评估实践不一致。本文提出了首个系统基准，比较了EHR表示方法，涵盖了ICU任务（如死亡率、表型分类）和 longitudioral护理任务（30天再入院、1年胰腺癌）中的多变量时间序列、事件流和文本流表示。不同临床场景下的数据整理和评估标准得到了统一。
### Innovation
本研究首次系统性地比较了EHR表示方法，使用多变量时间序列、事件流和文本流模型，并评估了适用于不同临床场景的适当模型家族（如Transformers、MLP、LSTM、Retain等），同时分析了基于数据缺失程度的特征剪枝对性能的影响。研究发现，事件流模型的一贯最强；预训练模型CLMBR在少量样本设置下高度样本效率，但简单计数模型在充分数据情况下也具有竞争力；特征选择策略需要根据临床环境调整。
### Conclusion
通过统一和可重复的流程，研究结果为基于临床背景和数据模式选择EHR表示提供了实用指导，表明在ICU预测中通过剪枝稀疏特征有助于性能提升，而在长期护理任务中保留这些特征则至关重要。
## 807. `cs.LG` - 超越成对连接：在全局约束下提取高阶功能脑网络结构 [PDF](https://arxiv.org/pdf/2510.09175), [HTML](https://arxiv.org/abs/2510.09175)
### Authors
Ling Zhan,Junjie Huang,Xiaoyao Yu,Wenyu Chen,Tao Jia
### Background
现有的功能脑网络（FBN）建模通常依赖于局部成对交互，这种方法在捕捉高阶依赖方面存在局限性。此外，目前的超图建模方法在计算负担和启发式性质方面限制了从数据分布中直接学习FBN结构的能力。
### Innovation
提出了一种新的全局约束导向多分辨率（GCM）FBN结构学习框架，该框架通过包含4种类型的全局约束（信号同步、被试身份、预期边数和数据标签），使FBN结构能在4个不同的建模分辨率层次（样本/被试/组/项目）中被学习。实验结果表明，与9个基线和10个最先进的方法相比，GCM在5个数据集中和2个任务设置中分别实现了30.6%的相对准确性和96.3%的计算时间减少。
### Conclusion
广泛的实验证明了各个组成部分的贡献，并突显了GCM的可解释性。本文为功能脑网络结构学习提供了一种新的视角，并为跨学科应用在认知神经科学中的应用奠定了基础。代码已公开，可在该网址访问：this https URL
## 808. `cs.LG` - RepDL: 位级可再现的深度学习训练和推理 [PDF](https://arxiv.org/pdf/2510.09180), [HTML](https://arxiv.org/abs/2510.09180)
### Authors
Peichen Xie,Xian Zhang,Shuo Chen
### Background
非确定性和不可重复性在深度学习中带来了显著挑战，导致不同运行和平台间的结果不一致。这些问题来源于随机数生成和浮点计算两个方面。尽管可以通过确定性配置控制随机性，但浮点计算的不一致性问题仍然难以解决。
### Innovation
引入了RepDL，这是一个开源库，确保了在不同计算环境中深度学习训练和推理的确定性和位级可再现性。RepDL通过强制执行浮点计算中正确的舍入和序无关性来实现这一目标。
### Conclusion
RepDL确保了在多样化的计算环境中实现深度学习训练和推理的位级可再现性，并且源代码可以在这里获取：this https URL。
## 809. `cs.LG` - 在深度持续学习中灾难性遗忘的隐含对抗性 [PDF](https://arxiv.org/pdf/2510.09181), [HTML](https://arxiv.org/abs/2510.09181)
### Authors
Ze Peng,Jian Zhang,Jintao Guo,Lei Qi,Yang Gao,Yinghuan Shi
### Background
持续学习旨在让机器智能获得类似人类的能力，即积累新技能。其核心挑战是灾难性遗忘，这一现象在深度网络中尚未完全理解。本文揭露了灾难性遗忘的本质，指出新任务训练实际上是对旧任务知识的一种隐含对抗攻击。新任务梯度能够自动且精准地与旧任务损失景观的尖锐方向对齐，导致旧任务损失迅速增加。
### Innovation
本文通过理论分析揭示了梯度投影（GP）方法无法解决由反向传播引起的对齐问题，提出了一种新的解决方案backGP，该方法通过减弱由前向传播引起的对抗对齐，并通过后向传播进一步减少遗忘，平均提高了12.7%的准确率。
### Conclusion
本文发现新任务的梯度对齐于旧任务损失景观的尖锐方向实际上是一种对抗性行为，这种行为源于训练过程中的低秩偏差，通过前向和反向传播将两个方向限制到同一低维子空间中。通过后向传播针对性解决GP方法无法解决的问题，提出的backGP方法在减少遗忘方面取得了更好的效果。
## 810. `cs.LG` - 反应可行性预测中的极小蕴含解释 [PDF](https://arxiv.org/pdf/2510.09226), [HTML](https://arxiv.org/abs/2510.09226)
### Authors
Klaus Weinbauer,Tieu-Long Phan,Peter F. Stadler,Thomas Gärtner,Sagar Malhotra
### Background
机器学习模型在预测化学反应可行性方面已成为自动化合成规划的核心。尽管这些模型在预测性能上非常成功，但它们往往缺乏透明度和可解释性。
### Innovation
提出了一种专门针对该领域的新型极小蕴含解释（也称为最小充分理由）的表述，并提出了一种计算此解释的算法，用于小型反应预测任务。初步实验表明，我们的极小蕴含解释保守地捕获了真实的解释，即这些解释通常包含冗余的化学键和原子，但始终捕捉到预测反应可行性的关键分子属性。
### Conclusion
我们的方法能够保守地捕捉到反应可行性的关键分子属性，即使解释中包含冗余成分也能保持一致性。
## 811. `cs.LG` - 多模态提示优化：为何不利用多个模态来扩展 MLLMs [PDF](https://arxiv.org/pdf/2510.09201), [HTML](https://arxiv.org/abs/2510.09201)
### Authors
Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）已经取得了显著的成功，其多模态扩展（MLLMs）进一步解锁了跨越图像、视频和其他非文本模态的能力。尽管如此，尽管这种转变已经发生，现有的提示优化方法仍然主要关注于文本模态，这些方法旨在减轻手工提示构建的负担并最大限度地提高性能。但它们最终限制了MLLMs的全部潜力。因此，研究者认为需要填补这一空白，提出了一个全新的问题，即多模态提示优化，它扩展了以往对提示优化的定义，将文本和非文本提示对定义的多模态空间纳入考虑范围。
### Innovation
为了应对这一问题，该研究提出了一种统一的框架——多模态提示优化器（MPO），它不仅可以通过保对齐的更新进行多模态提示的联合优化，还能利用贝叶斯基于的选择策略早期评估作为先验，引导候选提示的选择过程。通过在图像、视频、分子等超越文本的多种模态下进行全面实验，研究表明MPO能够超越领先的仅基于文本的优化方法，证实了多模态提示优化是充分释放MLLMs潜能的关键步骤。
### Conclusion
研究证明，MPO能够在多模态空间中实现提示的优化，实现MLLMs潜在能力的最大化，被视为下一步实现MLLMs潜力的关键步骤。
## 812. `cs.LG` - 基于主成分分析的數據預測方法 [PDF](https://arxiv.org/pdf/2510.09246), [HTML](https://arxiv.org/abs/2510.09246)
### Authors
Peteris Daugulis,Vija Vagale,Emiliano Mancini,Filippo Castiglione
### Background
在数据科学中，如何选择合适的值来填充缺失数据是一个常见的问题。本文介绍了一种结合传统数学和机器学习元素的方法，用于预测和填补缺失数据，该方法基于现有数据集合与候选集之间距离的概念，而现有数据集则由其第一主成分所张成的子空间来表示。对于欧几里得度量的情况，给出了解决方案。
### Innovation
本文提出的方法结合了主成分分析（PCA）和机器学习技术，通过计算现有数据集及其候选集之间的距离来进行缺失数据的预测。该方法创新地使用了距离的概念来构建预测模型，简化了传统的填补缺失数据的过程，为数据处理提供了新的思路和方法。
### Conclusion
本文提出了一种新的方法，用于基于主成分分析填充缺失数据，通过计算子空间之间的距离来进行预测。该方法主要适用于欧几里得度量下的数据预测问题，并为数据预处理提供了新的解决方案。
## 813. `cs.LG` - 基于残差的信息学习代数环的解 [PDF](https://arxiv.org/pdf/2510.09317), [HTML](https://arxiv.org/abs/2510.09317)
### Authors
Felix Brandt,Andreas Heuermann,Philip Hannebohm,Bernhard Bachmann
### Background
本文介绍了一种基于残差的机器学习方法，用于用神经网络代理替换方程式基础的Modelica模型中的代数环。为了改进模拟效率，需要一种替代传统的有监督学习方法来加速仿真的技术，同时保持模型的准确性和一致性。
### Innovation
该研究提出了一种训练前馈神经网络的新方法，直接使用代数环的残差作为损失函数的一部分，从而无需使用监督数据集。这种方法还解决了鲁棒解的歧义性问题，使代理模型能够收敛到一致性的解，而不是平均多个有效的解。
### Conclusion
将该方法应用于大规模的IEEE 14-节点系统，实现了与传统仿真相同水平的精度，并通过误差控制机制将仿真时间减少了60%。
## 814. `cs.LG` - 大型语言模型提示数据集：详细分析和见解 [PDF](https://arxiv.org/pdf/2510.09316), [HTML](https://arxiv.org/abs/2510.09316)
### Authors
Yuanming Zhang,Yan Lin,Arijit Khan,Huaiyu Wan
### Background
大型语言模型的部署日益增多，从GitHub和社交媒体等平台涌现出多种提示数据集，涵盖广泛的应用和内容类型，促进了这些模型的更广泛应用和提升提示工程的质量。现有数据集的编目不完整，研究尚未全面探讨提示数据集的特性及其与其它文本语料库的区别。
### Innovation
本研究首次全面编目提示数据集，涵盖各种下游任务、语言、工程技巧、属性和模态，选择关键代表数据集进行系统分析，揭示了不同类别中提示构建的共性和差异，并提出了一种利用词性和依赖结构语义嵌入的提示优化方法，通过引导大型语言模型朝向中心点重写提示，提升生成结果的含义性。
### Conclusion
本研究展示了这些提示数据集的特点，通过中心点表示法方法提高生成模型输出的意义性，并公开了数据集和代码。
## 815. `cs.LG` - FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning [PDF](https://arxiv.org/pdf/2510.09222), [HTML](https://arxiv.org/abs/2510.09222)
### Authors
Zhenglin Wan,Jingxuan Wu,Xingrui Yu,Chubin Zhang,Mingcong Lei,Bo An,Ivor Tsang
### Background
Flow Matching (FM) 已经展示了在建模复杂分布时的显著能力，并在基于离线模仿学习的专家行为克隆任务中取得了优异的表现。然而，尽管 FM 在行为克隆上拥有强大的表达能力，但由于缺乏环境互动和探索，其政策不可避免地限制了泛化能力，特别是在超出专家演示的未见过的场景中表现较差。这突显了环境交互的必要性。然而，通过在线环境交互优化 FM 策略既具有挑战性又低效，因为梯度计算不稳定性和高推理成本会影响其表现。
### Innovation
为了应对上述问题，本文提出了一种名为 FM-IRL 的方法，即通过简单的多层感知器 (MLP) 学生策略进行环境探索，并使用带有奖励模型的 RL 算法实现在线更新。教师 FM 模型包含丰富的专家数据分布信息，能与学生策略一起用于政策正则化，以稳定政策学习。学生策略的简单架构避免了 FM 策略梯度不稳定性问题，同时利用了教师 FM 模型的强大表达能力。实验表明，该方法显著提升了学习效率、泛化能力和鲁棒性，尤其是在使用次优专家数据学习时。
### Conclusion
我们的方法显著提高了学习效率、泛化能力和鲁棒性，特别是当从次优专家数据学习时。通过使用教师 FM 模型和基于 RL 的学生策略更新机制，我们成功地解决了 FM 策略在在线环境互动中的不稳定性和高效探索问题，同时保持了强大的表达能力。实验证明了这种方法的有效性和优越性。
## 816. `cs.LG` - 利用合成数据和异常值缓解发展中经济体中的模型漂移 [PDF](https://arxiv.org/pdf/2510.09294), [HTML](https://arxiv.org/abs/2510.09294)
### Authors
Ilyas Varshavskiy,Bonu Boboeva,Shuhrat Khalilbekov,Azizjon Azimi,Sergey Shulgin,Akhlitdin Nizamitdinov,Haitz Saez de Ocariz Borde
### Background
金融中的机器学习模型极易受到模型漂移的影响，表现为预测性能随数据分布的变化而下降。这种现象在如中亚和高加索地区（包括塔吉克斯坦、乌兹别克斯坦、哈萨克斯坦和阿塞拜疆）这样的发展中经济体中尤为严重，这些地区的宏观经济波动导致金融数据不稳定。据报道，这是首次针对该地区金融数据集的研究之一。
### Innovation
研究采用合成异常值作为尚未充分探索的方法，来提高模型在不可预见的冲击情况下的稳定性。该研究提出了一个双层框架，用以评估模型性能下降的程度和冲击的严重性，以衡量这种方法的有效性。
### Conclusion
实验结果显示，在宏观数据表格中添加少量合成异常值通常能提高模型的稳定性，尽管最佳添加量会因数据集和模型的不同而变化。
## 817. `cs.LG` - 时间感知公平性在数据共享中的激励 [PDF](https://arxiv.org/pdf/2510.09240), [HTML](https://arxiv.org/abs/2510.09240)
### Authors
Jiangwei Chen,Kieu Thao Nguyen Pham,Rachael Hwee Ling Sim,Arun Verma,Zhaoxuan Wu,Chuan-Sheng Foo,Bryan Kian Hsiang Low
### Background
在协作的数据共享和机器学习中，多个实体合并其数据资源来训练性能更好的机器学习模型。然而，由于实体需要承担数据收集的成本，他们仅在保证公平性和个人合理性等激励时愿意这样做。现有的框架假定所有实体会同时加入合作，但在许多真实场景中这是不成立的。由于数据清洗的长时间处理、难以跨越的法律障碍，或者缺乏意识，实体可能会在不同的时间加入合作。本文探讨了这样的情况，并提出了一种新的视角：早期加入合作的实体会承担更高的风险，因此鼓励等待观察的实体提供数据，同时应该获得更高的奖励价值。
### Innovation
提出了一种时间感知的公平性数据共享框架，包括新颖的时间感知激励。提出了一种新的方法来决定奖励价值，以满足这些激励。进一步展示了如何生成模型奖励来实现奖励价值，并在合成和实际数据集上进行了实证分析，证明了方法的性质。
### Conclusion
通过研究和设计，提出了一个能够考虑到时间因素的公平性数据共享框架，并通过奖励机制来鼓励早期贡献数据的实体。这种方法不仅提高了数据共享中实体的积极性，还确保了模型训练过程中的公平性。
## 818. `cs.LG` - 数据中均衡的学习最优速率 [PDF](https://arxiv.org/pdf/2510.09325), [HTML](https://arxiv.org/abs/2510.09325)
### Authors
Till Freihaut,Luca Viano,Emanuele Nevali,Volkan Cevher,Matthieu Geist,Giorgia Ramponi
### Background
该论文填补了多智能体模仿学习（MAIL）领域的理论空白，通过定义非交互式MAIL的限制条件以及首次提出一个交互式算法，展示了在近最优样本复杂度下的性能。
### Innovation
提出了一个结合无奖励强化学习与交互式MAIL的框架，并基于此开发了MAIL-WARM算法，将样本复杂度从O(ε^-8)改进到了O(ε^-2)，这一改进与统计下界所暗示的ε依赖性相匹配。同时，证明了行为克隆（BC）的最优速率，并在格子世界等环境中提供了实验结果来支持理论。
### Conclusion
该论文通过一系列理论证明和实验验证，展示了其算法在特定环境下的优越性能，并强调了在样本复杂度方面的进步。
## 819. `cs.LG` - 安全博弈：利用线性规划求解器实现黑盒代理AI的对话安全与信息平衡 [PDF](https://arxiv.org/pdf/2510.09330), [HTML](https://arxiv.org/abs/2510.09330)
### Authors
Tuan Nguyen,Long Tran-Thanh
### Background
确保大型语言模型（LLMs）满足安全要求是AI部署中的核心挑战。现有对齐方法主要在训练期间进行操作，如通过微调或通过人类反馈的强化学习，但这些方法成本高且灵活性差，需要在新要求出现时重新训练。最近，推理时对齐的尝试缓解了这些限制，但仍假定可以访问模型内部信息，这在实际中不可行，并不适合没有访问模型的第三方利益相关者。
### Innovation
提出了一种模型无关、黑盒框架，用于安全对齐，不需要重新训练或访问LLM的底层架构。作为一个概念证明，解决了生成安全但不提供信息的答案与产生有帮助但可能具有风险的回答之间的权衡问题。将这一困境表述为一个两人零和博弈，其最小极大均衡捕捉了安全性和辅助性之间的最佳平衡。LLM代理在推理时利用线性规划求解器计算平衡策略。
### Conclusion
结果证明了黑盒安全对齐的可行性，为包括小型组织和资源受限环境中的实体在内的利益相关方提供了一种可扩展和易于实现的途径，以确保LLM生态系统中的安全性。
## 820. `cs.LG` - 从嘈杂的成对比较中进行高效的贝叶斯推理 [PDF](https://arxiv.org/pdf/2510.09333), [HTML](https://arxiv.org/abs/2510.09333)
### Authors
Till Aczel,Lucas Theis,Wattenhofer Roger
### Background
评估生成模型具有挑战性，因为传统的度量标准往往不能反映人类偏好。虽然人类评估更可靠，但成本高昂且噪音大，因为参与者在专业程度、注意力和尽责性方面存在差异。成对比较可以提高一致性，但将这些比较综合成整体质量分数需要精心建模。基于Bradley-Terry的方法可以通过比较更新项目得分，但现有方法要么忽视评价者差异性，要么缺乏收敛保证，这限制了其稳健性和可解释性。
### Innovation
我们引入了BBQ（贝叶斯Bradley-Terry的变体），它明确地对评价者质量进行了建模，降低了或移除了不可靠的参与者，并通过期望最大化算法提供了有保证的单调最大似然收敛。实验结果表明，BBQ实现了更快的收敛速度，校准了不确定性估计，提供了更具鲁棒性和可解释性的排名，即使在嘈杂或众包的评价者中也是如此。这种框架使得生成模型的人类评估更加可靠和成本效益更高。
### Conclusion
BBQ框架能够实现对生成模型进行更可靠和成本效益更好的人类评估。
## 821. `cs.LG` - CHUCKLE -- 当人类教会AI以简单方式学习情绪 [PDF](https://arxiv.org/pdf/2510.09382), [HTML](https://arxiv.org/abs/2510.09382)
### Authors
Ankush Pratap Singh,Houwei Cao,Yong Liu
### Background
现有的情感识别中的课程学习（CL）方法通常根据启发式、数据驱动或模型定义样本难度，而忽略了对于人类感知来说至关重要的主观任务因素。这些方法没有充分利用人类感知的难度来定义样本难度。
### Innovation
CHUCKLE框架是一种感知驱动的课程学习框架，它利用众包数据集中的注释者一致性和对齐性来定义样本难度。这种方法假设对人类有挑战性的视频片段对机器学习模型也是类似的挑战。
### Conclusion
实证研究表明，与非课程学习基线相比，CHUCKLE提高了LSTM相对平均准确率6.56%，提高了Transformer的1.61%，同时减少了梯度更新次数，从而提高了训练效率和模型稳健性。
## 822. `cs.LG` - 序列模型中基于任务的本征值见解 [PDF](https://arxiv.org/pdf/2510.09379), [HTML](https://arxiv.org/abs/2510.09379)
### Authors
Rahel Rickenbach,Jelena Trisovic,Alexandre Didier,Jerome Sieber,Melanie N. Zeilinger
### Background
虽然软最大化注意力机制在序列模型中表现出最先进的性能，但其二次复杂度限制了其扩展性，因此促使了更高效线性替代方案如状态空间模型 (SSMs) 的开发。现有的替代方案虽然提高了效率，但它们在信息处理上的基本差异仍然不甚了解。
### Innovation
利用最近提出的动态系统框架将软最大化、范数和线性注意力表示为动态系统，并通过分析各自的本征值光谱来对它们与SSMs进行结构化比较。详细的实验分析揭示了本征值如何影响记忆和长程依赖性建模，且与任务要求一致，并进一步研究了序列模型架构修改对本征值光谱和任务性能的影响。
### Conclusion
本征值分析为解释、理解和最终提升序列模型的能力提供了一个原则性的度量标准。
## 823. `cs.LG` - HINT: 助力无效执行走向有效性 [PDF](https://arxiv.org/pdf/2510.09388), [HTML](https://arxiv.org/abs/2510.09388)
### Authors
Xinyi Wang,Jinyi Han,Zishang Jiang,Tingyun Li,Jiaqing Liang,Sihang Jiang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao
### Background
强化学习（RL）已成为提升大型语言模型（LLMs）长链条思考（CoT）推理能力的关键驱动力。然而，通用方法如GRPO在任务难度超出模型容量时常常失效，导致奖励稀疏和训练效率低下。先前的工作试图通过使用离策数据（如结合监督微调SFT或使用提示），但这些方法往往误导了策略更新。这种缺失主要源于外部引导与模型策略间的大规模分布不匹配。
### Innovation
为了诊断这一问题，该研究引入了Affinity，这是首个用于监测探索效率和训练稳定性的量化指标。进一步提出HINT（Helping Ineffective rollouts Navigate Towards effectiveness）框架，采用自适应提示引导模型自主寻找解决方案，从而保留其自主推理能力。实验显示，HINT在数学推理任务上表现优异，能够实现不同规模模型的性能提升，并显示出更高且更稳定的训练表现。
### Conclusion
HINT框架在数学推理任务上展现出优于现有方法的性能，实现了各种规模模型的state-of-the-art成果，同时证明了更高的训练稳定性和数据利用率。该研究的成果已在Github上公开可用。
## 824. `cs.LG` - 第二阶优化在大语言模型中的潜力：基于全高斯牛顿方法的研究 [PDF](https://arxiv.org/pdf/2510.09378), [HTML](https://arxiv.org/abs/2510.09378)
### Authors
Natalie Abreu,Nikhil Vyas,Sham Kakade,Depen Morwani
### Background
近年来，加速大规模语言模型（LLM）预训练的努力集中在利用高阶结构的计算效率的近似方法上。这引出一个重要问题：这些近似方法会牺牲多少性能？为了探究这一问题，通过将全高斯-牛顿（GN）预条件化应用于最多包含150M参数的变压器模型，我们设定了一个实用的迭代复杂度上限。实验结果表明，全GN更新方法在与现有优化器（如SOAP和Muon）对比时，能够大幅度提高性能，实现五倍以上的训练迭代次数减少。此外，研究表明，忽略层间信息的精确层间GN预条件化方法几乎达到了全GN方法的性能水平。
### Innovation
本研究提出了将全高斯-牛顿（GN）预条件化应用于含有最多150M参数的变压器模型的方法，以探究第二阶优化方法在大规模语言模型预训练中的有效性。通过这种方法，研究发现了现有近似方法与理想化的层间Oracle方法之间存在的显著性能差距。同时，研究发现近似的层间GN预条件化方法几乎能够达到全GN方法的性能。这表明高阶损失项可能对收敛速度的重要性较低，并且层间Hessian结构中包含足够的信息以实现大部分潜在的性能提升。
### Conclusion
本研究结果表明：1) GN近似预条件化方法非常有效，暗示高阶损失项可能不那么重要；2) 层间Hessian结构包含足够信息以实现大部分性能提升；3) 当前的近似方法与理想化的层间Oracle方法之间存在显著的性能差距。
## 825. `cs.LG` - 时间图学习模型学到了什么？ [PDF](https://arxiv.org/pdf/2510.09416), [HTML](https://arxiv.org/abs/2510.09416)
### Authors
Abigail J. Hayes,Tobias Schumacher,Markus Strohmaier
### Background
时间图学习已成为图表示学习中的关键议题，大量基准测试证明了前沿模型的强大性能。然而，最近的研究指出，常用的评估协议存在可靠性问题，即便是简单的启发式方法也表现出相当的竞争力，这种现象促使研究者反思模型真正依赖哪些时间图的基本属性来进行预测。
### Innovation
该研究通过系统评估七种模型在捕捉时间图八个基本属性方面的表现，揭示了模型在不同属性上的学习能力存在差异，从而识别出时间图学习模型的重要局限性。这些属性涵盖了结构特性（如密度）、时间模式（如最近性）以及边形成机制（如同质性）等内容，利用合成数据集和实际数据集进行分析。
### Conclusion
研究结果显示，模型在某些属性上表现良好，但在其他属性上却无法做到准确复制。因此，研究者认为这些结果为时间图学习模型的实际应用提供了有价值的见解，并激发了时间图学习研究中增强解释性的评估方法。
## 826. `cs.LG` - 通过特征解耦和对抗训练实现跨接收器泛化的RF指纹识别 [PDF](https://arxiv.org/pdf/2510.09405), [HTML](https://arxiv.org/abs/2510.09405)
### Authors
Yuhao Pan,Xiucheng Wang,Nan Cheng,Wenchao Xu
### Background
射频指纹识别(RFFI) 是无线网络安全的关键技术，利用制造过程中引入的固有硬件级缺陷实现精准的发射机识别。尽管深度神经网络在提取特征方面表现出色，但在实际部署中，接收机引起的变异性限制了其应用。RF指纹信号包含发射机特定特征、信道失真和接收机引起的偏差。尽管信道均衡可以减少信道噪声，但接收机引起的特征偏移仍未得到有效解决，导致RFFI模型过度拟合到特定接收器的模式。这一限制在训练和评估使用相同接收器时尤为明显，如果在部署中更换接收器，会导致性能大幅下降。
### Innovation
提出了一种鲁棒的跨发射机泛化RFFI框架，结合对抗训练和风格迁移来显式解耦发射机和接收机特征。通过实现域不变表征学习，该方法将真实的硬件签名从接收器伪影中分离出来，确保在更换接收器时仍然具有鲁棒性。在多种接收器数据集上的实验证明，该方法在不同接收器环境下的一致性能优于最先进的基准，平均准确率提高了10%以上。
### Conclusion
深入实验多接收器数据集表明，相较最先进的基础模型，我们的方法能够提供更加鲁棒的性能，特别是在接收器发生变化时展现出显著改善。
## 827. `cs.LG` - 运用深度学习识别高密度网络中列车延误的时空级联效应 [PDF](https://arxiv.org/pdf/2510.09350), [HTML](https://arxiv.org/abs/2510.09350)
### Authors
Vu Duc Anh Nguyen,Ziyue Li
### Background
现代经济中铁路网络的操作效率持续受到列车延误级联效应的影响。实时交通管理中准确预测这些延误传播是一个关键挑战。虽然最近的研究利用图神经网络（GNN）来建模铁路网络结构，但仍然缺乏能够提供网络规模上多步自回归预测的框架，同时提供实时可解释的解释，以支持决策。鉴于此，本文通过开发和评估一种新颖的XGeoAI框架，解决了实时部署的可行性问题。
### Innovation
本文提出了一个基于两阶段自回归图注意力网络（GAT）模型的XGeoAI框架，该模型在覆盖荷兰铁路网络40%以上的真实数据集上进行训练，用于实现实时可解释的多步骤列车延误预测。该模型通过将系统表示为包含发车和到站事件以及粒度特征（如站台和车站拥堵）的时间空间图来工作。研究通过模拟真实条件下预测误差放大使用序贯k步预报协议对该模型进行了严格评估。
### Conclusion
虽然提出的GATv2模型在纯误差指标（MAE）上被简单的 persistence 基线所挑战，但在延迟事件分类精度上表现更优，这对于可靠的决策支持工具至关重要。
## 828. `cs.LG` - 深度神经网络和大型语言模型中的权重初始化与方差动态 [PDF](https://arxiv.org/pdf/2510.09423), [HTML](https://arxiv.org/abs/2510.09423)
### Authors
Yankun Han
### Background
训练初期，权重初始化对信号传播和梯度流动的影响很大。本文通过理论支持和实验证据，针对两种架构——紧凑的ReLU多层感知机和GPT-2风格的变压器——进行了研究。
### Innovation
1. 通过对初始标准差进行对数扫描，识别出一个稳定的权重区间，标准差在1e-2到1e-1之间。2. 实验显示使用Kaiming（fan-in）初始化在ReLU情况下比Xavier初始化更快、更稳定。3. 跟踪从零开始的12层GPT-2风格模型中每一层的Q/K/V权重方差，在预训练过程中观察到深度相关的均衡，即浅层快速扩展而深层变化逐渐。
### Conclusion
研究结果将经典的初始化原则与现代变压器行为联系起来，提出了简单、实用的训练稳健性食谱。
## 829. `cs.LG` - 序列模型的设计原则通过系数动力学 [PDF](https://arxiv.org/pdf/2510.09389), [HTML](https://arxiv.org/abs/2510.09389)
### Authors
Jerome Sieber,Antonio Orvieto,Melanie N. Zeilinger,Carmen Amo Alonso
### Background
本文分析了深度序列模型，从Transformers和状态空间模型（SSMs）到更近的门控线性RNN，它们本质上都是通过过去的值向量的线性组合来计算输出。为了从中提取见解并系统地比较这些架构，作者提出了一种统一框架，通过将线性组合系数视为由冲击输入驱动的自主线性动态系统的输出来明确输出操作。这种视角本质上不同于将线性RNN与线性注意力连接起来的方法，它揭示了各种架构中常见的数学主题，并且捕捉了软最大注意力，超出了RNN、SSM及其相关模型的范畴。与常见的通过基准评估新模型提议的做法不同，作者推导出将架构选择与模型属性联系起来的设计原则。从而明确了表达力与有效实现之间的权衡、输入选择性的几何限制以及稳定条件下的数值稳定训练和信息保留。通过将最近文献中的几个见解和观察点联系起来，框架既解释了近期设计的实验性成功，又为系统设计新的序列模型架构提供了指导原则。
### Innovation
本文提出了一个新的统一框架，将线性组合系数视为由冲击输入驱动的自主线性动态系统的输出，揭示了不同架构之间的共同数学主题。这一新的视角不仅解释了最近设计的成功，而且为系统设计新的序列模型架构提供了指导原则。另外，通过这一框架作者也确定了表达力、高效实现、输入选择性几何约束和训练稳定性的关系。
### Conclusion
通过连接几个来自最近文献的见解和观察，该框架不仅解释了近期设计的实验性成功，而且为系统设计新的序列模型架构提供了指导原则，同时明确了表达力、高效实现、输入选择性几何约束和训练稳定性的关系。
## 830. `cs.LG` - 推荐模型中的交叉注意力秘密执行正交对齐 [PDF](https://arxiv.org/pdf/2510.09435), [HTML](https://arxiv.org/abs/2510.09435)
### Authors
Hyunin Lee,Yong Zhang,Hoang Vu Nguyen,Xiaoyi Liu,Namyong Park,Christopher Jung,Rong Jin,Yang Wang,Zhigang Wang,Somayeh Sojoudi,Xue Feng
### Background
跨领域序列推荐(CDSR)的目标是将来自不同领域的异构用户行为序列进行对齐。交叉注意力被广泛用于提高推荐系统的性能，但其工作机制尚未完全理解。大多数研究人员认为交叉注意力是一种残余对齐机制，通过参考另一个域的数据（作为键和值输入）来删除查询输入中的冗余信息，保留非冗余信息。
### Innovation
引入了正交对齐这一现象，即交叉注意力发现了查询输入中不存在的新信息。进一步提出残余对齐和正交对齐可以在推荐模型中同时存在。该研究发现，当交叉注意力的查询输入和输出正交时，模型性能在300次实验中提高了。正交对齐可以在没有任何显式约束的情况下自然生成。研究表明，结合交叉注意力模块的模型在参数匹配的基准模型中表现出更高的准确性。
### Conclusion
这些发现为多模态研究中的参数高效扩展提供了新的方向。
## 831. `cs.LG` - 关于均匀缩放流：一种与密度对齐的深度一类分类方法 [PDF](https://arxiv.org/pdf/2510.09452), [HTML](https://arxiv.org/abs/2510.09452)
### Authors
Faried Abu Zaid,Tim Katzke,Emmanuel Müller,Daniel Neider
### Background
无监督异常检测通常围绕两种广泛研究的方法进行框架设定：深层一个类分类（Deep One-Class Classification，D OSC），以Deep SVDD为代表，学习正常表示的紧凑的潜在表示；而通过标准化流实现的概率密度估计直接建模常规数据的可能性。
### Innovation
本文证明了均匀缩放流（USFs），是一种具有恒定雅可比行列式的标准化流，能够精确地将这两种方法连接起来。具体来说，通过最大似然训练USF等价于Deep SVDD目标，具有一个独特的正则化项，内在地防止了表示崩溃。此外，USFs能够在负对数似然和潜在表示之间产生更紧密的对齐。最近将一类目标与生成对抗网络结合的混合方法也可以自然地扩展到USFs。因此，USFs可以作为一种直接替代现有方法的方案用于现代异常检测架构。
### Conclusion
本文的实验结果表明，用USFs取代非USFs在多个基准和模型架构上都产生了持续性能提升和训练稳定性改进，同时这些结果统一了两种主要的异常检测方法，从理论上和实践中都推进了异常检测的理解和性能。
## 832. `cs.LG` - 基于单峰偏好的有限资源多臂赌博机 [PDF](https://arxiv.org/pdf/2510.09425), [HTML](https://arxiv.org/abs/2510.09425)
### Authors
Gur Keinan,Rotem Torkan,Omer Ben-Porat
### Background
研究了一个在线随机匹配问题，其中算法需在T轮内，用U个用户匹配到K个臂上，以最大化累积奖励，但受预算限制。在没有结构假设的情况下，计算最优匹配是NP难问题，使得在线学习在计算上不可行。
### Innovation
论文关注单峰偏好——这是一种由社会选择理论广泛认可的结构，用户的偏好在某个共同的臂的排序下呈现单峰特性。提出了一种有效的离线预算匹配算法，并将其扩展到一种在线算法，其遗憾度为$tilde O(UKT^{2/3})$。如果知道单峰结构，进一步开发了一种高效的类似UCB的算法，遗憾度为$tilde O(Ufrac{text{sqrt(TK)}}{text{C}})$。使用了一种新颖的基于PQ树的排序近似方法。
### Conclusion
通过利用单峰偏好的结构，提出了有效的在线和离线算法，在预算和调度两个任务上取得了较好的性能。
## 833. `cs.LG` - 可解释的机器学习在预测初创公司融资、专利申请和退出方面的应用 [PDF](https://arxiv.org/pdf/2510.09465), [HTML](https://arxiv.org/abs/2510.09465)
### Authors
Saeid Mashhadi,Amirhossein Saghezchi,Vesal Ghassemzadeh Kashani
### Background
本文构建了一个包含2010至2023年间 Crunchbase 数据和美国专利与商标局（USPTO）数据的公司-季度面板数据集，针对融资、专利申请及退出三种不同的预测时间范围进行分析。目的是开发一个可解释的机器学习框架来预测创业公司的结果，包括融资、专利申请和退出（通过IPO或并购）。
### Innovation
研究使用了可解释的机器学习框架来预测创业公司的结果，并针对不同的预测时间范围内（12个月内融资、24个月内专利增长和36个月内退出）进行了评估。研究通过特殊处理解决了类别不平衡问题，并通过比较多种模型得出了较高预测准确性（AUROC值分别为0.921、0.817和0.872）。
### Conclusion
通过可解释的机器学习方法，研究实现了对公司未来融资、专利申请和退出的有效预测。模型的高AUROC值表明了预测的准确性，并为创新融资提供了透明且可重复的排名依据。
## 834. `cs.LG` - Latent空间上的测地线计算 [PDF](https://arxiv.org/pdf/2510.09468), [HTML](https://arxiv.org/abs/2510.09468)
### Authors
Florine Hartwig,Josua Sassen,Juliane Braunsmann,Martin Rumpf,Benedikt Wirth
### Background
自编码器通过提供低维数据表示来描述潜在流形，这些问题可以从几何学的角度进行研究。现有方法在处理隐式表示的不准确性时不够稳健。
### Innovation
本文提出了一种新的框架，将潜在流形描述为某个隐空间的隐式子流形。基于此，开发了一种离散黎曼微积分工具，用于近似经典几何算子。该方法能抵抗隐式表示中的不准确性，并能通过最小化去噪目标来学习隐空间上的近似投影。此外，该方法支持不同几何结构，并能计算潜在流形上的测地线路径。
### Conclusion
本文方法在合成数据和真实数据训练的自编码器上进行评估，能够成功计算潜在流形上的测地线路径和通过黎曼指数映射射击测地线。
## 835. `cs.LG` - 机器学习算法在慢性肾病预测中的性能分析 [PDF](https://arxiv.org/pdf/2510.09493), [HTML](https://arxiv.org/abs/2510.09493)
### Authors
Iftekhar Ahmed,Tanzil Ebad Chowdhury,Biggo Bushon Routh,Nafisa Tasmiya,Shadman Sakib,Adil Ahmed Chowdhury
### Background
慢性肾病（CKD）患者占全球人口的约10%，肾脏功能逐渐衰减。防止患者额外受损，需要进行有效的CKD风险评估和适当监控。机器学习模型由于快速精确的检测能力，被广泛应用于医疗诊断，能够提高疾病预测的准确性，因此现代医疗领域的诊断系统和流程越来越多地依赖于机器学习。
### Innovation
设计并建议了一种用于CKD诊断的疾病的计算机辅助设计方法。通过使用UCL机器学习仓库中的数据集，并采用“平均-模式”和“随机抽样”方法填充数据缺失值后，应用了八种机器学习技术（随机森林、SVM、朴素贝叶斯、逻辑回归、KNN、XGBoost、决策树和AdaBoost）建立模型，通过准确性评估比较了不同机器学习模型的性能。
### Conclusion
随机森林和逻辑回归表现出99%的高准确性，其次是AdaBoost、XGBoost、朴素贝叶斯、决策树和SVM，而KNN分类器模型的准确性仅为73%。
## 836. `cs.LG` - 近最优的第二阶保证对于基于模型的对抗性模仿学习 [PDF](https://arxiv.org/pdf/2510.09487), [HTML](https://arxiv.org/abs/2510.09487)
### Authors
Shangzhe Li,Dongruo Zhou,Weitong Zhang
### Background
在在线对抗性模仿学习（AIL）中，智能体通过学习离线专家的演示并在无需访问奖励功能的情况下与其他环境交互来学习。尽管这一领域取得了显著的实验成果，但在线交互的好处以及随机性的影响仍在很大程度上未被理解。
### Innovation
该论文通过引入基于模型的AIL算法（MB-AIL）解决了这些问题，并在一般函数近似下为专家数据和无奖励交互建立了无视窗的第二阶样本复杂性保证。此外，该研究利用的信息论下的第二阶下界展示了MB-AIL在有限专家数据的情景下实现了近最优的样本复杂性，并且与专家数据的样本复杂性偏差主要依赖于视窗大小H、精度ε和政策方差σ²相匹配。实验进一步验证了理论结果，表明MB-AIL的实际实现可以匹配或超越现存方法的样本效率。
### Conclusion
MB-AIL算法在无奖励交互方面达到了理论上的最优样本复杂性（除了对数因子），并且对于专家数据的样本复杂性依赖于视窗大小H、精度ε和政策方差σ²时也达到了下界的最佳性能。
## 837. `cs.LG` - 可信赖监控上的适应性攻击颠覆AI控制协议 [PDF](https://arxiv.org/pdf/2510.09462), [HTML](https://arxiv.org/abs/2510.09462)
### Authors
Mikhail Terekhov,Alexander Panfilov,Daniil Dzenhaliou,Caglar Gulcehre,Maksym Andriushchenko,Ameya Prabhu,Jonas Geiping
### Background
AI控制协议被视为一种防御机制，用以阻止不可信的大规模语言模型（LLM）代理在自主环境中造成危害。过去的此类工作将此视为安全问题，并通过利用部署环境温和地完成有害辅助任务来测试这种安全机制，例如后门插入。在实践中，大多数AI控制协议基本基于LLM监控器，这可能会成为一个集中失效点。这项研究进一步研究了这样的不可信模型发动适应性攻击的情况，这些攻击了解控制协议和监控模型，并在训练后期或通过自主搜索获得知识，包括在模型输出中嵌入已知的或零样本提示注入。这种战术使得前沿模型能够绕过不同的监控器，甚至在两个主要的AI控制基准上完成恶意任务。最新的Defer-to-Resample协议在此类攻击中尤为脆弱，其采样的增加反而加强了提示注入，从而有效将其重新表述为最佳的-n-攻击。
### Innovation
研究了一种适应性攻击，此攻击由了解控制协议和监测模型的不可信模型发起。通过将已知的或零样本提示注入嵌入到模型输出中，攻击能够绕过不同的监控器，实现诸如后门插入等恶意任务。此外，最新的一种Defer-to-Resample协议在此类攻击下表现更是不理想，其重复采样反而增强了提示注入的效果，将攻击性质模棱两可地转化为了最佳的-n-攻击。这项研究指出了现有的控制协议在面对适应性攻击时的弱点，同时呼吁对抗性测试应成为未来AI控制机制评估的一个标准组成部分。
### Conclusion
现有的AI控制机制中嵌入的监控器模型存在重大盲点，面临着来自已了解控制协议和监控模型的不可信模型的适应性攻击。建议在评估这些机制时应将适应性攻击纳入考量，并将其作为标准测试的一部分。
## 838. `cs.LG` - CRPS-LAM：通过匹配边缘概率进行区域集合天气预报 [PDF](https://arxiv.org/pdf/2510.09484), [HTML](https://arxiv.org/abs/2510.09484)
### Authors
Erik Larsson,Joel Oskarsson,Tomas Landelius,Fredrik Lindsten
### Background
机器学习在天气预测方面的应用越来越依赖于ensemble方法来提供概率预报。扩散模型在区域模型（LAM）方面显示出强大的性能，但在采样时间仍具较高的计算成本。全球天气预报模型通常采用连续排名概率评分（CRPS）作为训练目标，这表明基于CRPS训练的模型在天气预测中的有效性。因此，本文提出了基于CRPS训练的概率LAM预报模型CRPS-LAM，通过单次前向传播采样并注入一个潜在噪声向量来生成集合成员，实现了比扩散模型快39倍的采样速度，并在MEPS区域数据集上与扩散模型的低误差相当，同时还能保留细尺度预报细节，展示了其作为区域天气概率预报的有效方法。
### Innovation
基于CRPS训练的CRPS-LAM模型能够通过单次前向传播生成集合成员，实现了快速采样速度（为扩散模型的39倍），同时还能保持细尺度预报细节，有效解决了LAM采样时间成本高且不够精细的问题。此外，CRPS-LAM模型的引入为进一步提升区域天气预报精度和效率提供了新的方法。
### Conclusion
CRPS-LAM模型在MEPS区域数据集上与扩散模型具有相似的低误差，且在保持细尺度预报细节的同时实现了快速采样，表明该模型是一种有效的区域天气概率预报方法。
## 839. `cs.LG` - 局部最优私有采样：超越全局最小最大 [PDF](https://arxiv.org/pdf/2510.09485), [HTML](https://arxiv.org/abs/2510.09485)
### Authors
Hrad Ghoukasian,Bonwoo Lee,Shahab Asoodeh
### Background
本文研究在本地差分隐私(LDP)下的分布采样问题。已有的工作主要关注在整个分布类上的一致最优性，而本文则从局部的角度出发，研究在固定分布$P_0$附近的最小风险。本文在纯LDP的基础上扩展到更广泛的函数LDP框架，并证明了全局最优的函数LDP采样器在接近$P_0$的分布下也能达到最优。这为数据隐私与数据采样之间的权衡提供了新的视角。
### Innovation
本文的主要创新表现在：1) 从局部角度出发，研究固定分布$P_0$附近的最小风险；2) 扩展了LDP到更广泛的函数LDP框架；3) 证明了全局最优函数LDP采样器在接近$P_0$的分布下也能达到最优；4) 提出了一个简单且通用的局部最小最大最优采样器，不依赖于$f$-散度的选择。这些创新为在满足隐私要求的同时生成接近真实分布的数据提供了新的方法。
### Conclusion
本文证明了在固定分布$P_0$附近的最小风险与全局最小风险相关，并提出了一种简单的闭式表达式来获得局部最优采样器。实验结果表明，与现有的全局方法相比，本文提出的局部最优采样器在某些方面表现更好。这为私有采样与公共数据相结合的场景提供了新的解决方案。
## 840. `cs.LG` - Geo-Aware Models for Stream Temperature Prediction across Different Spatial Regions and Scales [PDF](https://arxiv.org/pdf/2510.09500), [HTML](https://arxiv.org/abs/2510.09500)
### Authors
Shiyuan Luo,Runlong Yu,Shengyu Chen,Yingda Fan,Yiqun Xie,Yanhua Li,Xiaowei Jia
### Background
理解环境生态系统对于可持续管理地球至关重要。然而，现有的基于物理和数据驱动的模型往往难以跨不同地区和尺度进行泛化，因为实际环境生态系统的数据异质性，以及可用于模型训练的观测样本有限进一步加剧了这一问题。
### Innovation
我们提出了Geo-STARS，一个地理意识的时空建模框架，用于预测不同河流流域和空间尺度的溪流温度。Geo-STARS 的主要创新在于引入了地理意识嵌入，该功能利用地理信息明确捕捉不同空间区域和尺度间的共同原理和模式。此外，Geo-STARS 将地理意识嵌入整合到门控时空图神经网络中，使得模型能够在地理和水文背景下学习复杂的时空模式，即使在观测数据稀少或缺失的情况下也能如此。
### Conclusion
Geo-STARS 在预测溪流温度方面表现出卓越的泛化性能，验证了其在多个美国东海岸流域的广泛适用性和数据效率。这些结果表明，Geo-STARS 对于可扩展、数据高效性的环境监测和决策具有巨大的应用前景。
## 841. `cs.LG` - STaTS：基于统计窗口合并的结构感知时序序列摘要 [PDF](https://arxiv.org/pdf/2510.09593), [HTML](https://arxiv.org/abs/2510.09593)
### Authors
Disharee Bhowmick,Ranjith Ramanathan,Sathyanarayanan N. Aakur
### Background
时间序列数据通常包含隐蔽的时间结构、局部稳定阶段之间的转换、重复的图案和变异的爆发，而现有标准的代表学习管道很少利用这些特征。现有模型通常处理原始或固定窗口的序列，认为时间点都同样重要，导致在长或嘈杂序列上出现效率低下、鲁棒性差和可扩展性受限制的问题。
### Innovation
STaTS 提出了一个轻量级、无监督的框架，用于结构感知的时间序列摘要。该框架能够自适应地压缩一维和多维时间序列数据，同时保留核心时间动态。STaTS 使用基于 BIC 的统计差异准则检测多个时间分辨率下的变化点，然后使用简单的函数（如均值）或生成模型（如 GMM）总结每个段，实现了高达30倍的序列压缩，同时保留了主要的时间动态。STaTS 作为模型无关的预处理器，可以与现有的无监督时间序列编码器无缝集成，无需重新训练。广泛的实验结果表明，STaTS 可以实现与完整模型90%以上的性能，同时大幅降低计算成本，同时增强抗噪性并保留区分结构，优于均匀压缩和基于聚类的压缩基线。
### Conclusion
STaTS 提供了一种基于统计窗口合并的结构感知时间序列建模的原理性、通用高效方案。
## 842. `cs.LG` - 资源高效神经网络训练的自动进化优化 [PDF](https://arxiv.org/pdf/2510.09566), [HTML](https://arxiv.org/abs/2510.09566)
### Authors
Ilia Revin,Leon Strelkov,Vadim A. Potemkin,Ivan Kireev,Andrey Savchenko
### Background
神经网络模型在优化过程中存在许多关键挑战，如分布式计算、压缩技术和有效的训练等，无论它们具体应用于哪些任务。解决这些问题非常重要，因为对可扩展且资源高效模型的需求正在增加。
### Innovation
提出了一种新的自动化机器学习框架——Parameter Efficient Training with Robust Automation (PETRA)，该框架利用进化优化方法来优化模型架构和训练策略。PETRA包含剪枝、量化以及损失正则化。实验结果表明，PETRA在实际数据集（包括金融事件序列、图像和时间序列基准数据）上能够显著改善神经网络模型的性能和可扩展性，具体表现为模型大小减少高达75%，延迟降低高达33%，吞吐量提高13%，且不影响目标指标的性能。
### Conclusion
PETRA框架在提高神经网络模型的性能和可扩展性方面表现出色，通过剪枝、量化和损失正则化显著减少模型大小和延迟，并提高吞吐量，而不会牺牲目标指标。
## 843. `cs.LG` - MODE：使用动态专家混合体学习复杂系统的组成表示 [PDF](https://arxiv.org/pdf/2510.09594), [HTML](https://arxiv.org/abs/2510.09594)
### Authors
Nathan Quiblier,Roy Friedman,Matthew Ricci
### Background
生命科学中的动力系统经常由重叠的行为模式混合组成。细胞亚群可能从周期性动态转变为平衡动态，或者转向不同的发育命运。这些模式之间的转换可能会显得嘈杂和不规则，给传统的基于流量的动力学建模技术带来了严重挑战，这些技术假设局部光滑的动力学。近年来，这些非平滑的动力学现象在复杂的动力学转换中愈发突出，给现有方法带来了巨大的困难。因此，需要一种能够处理这些复杂动力学现象的新方法。
### Innovation
本文提出了MODE（Mixture Of Dynamical Experts），这是一种图形建模框架，其神经门控机制将复杂动力学分解为稀疏、可解释的组成部分，从而可以在无监督的情况下发现行为模式并准确预测这些模式之间的转换。MODE的关键优势在于其框架内的代理可以跳跃到不同的动力学法则，使得它特别适用于上述嘈杂的转换，并能对合成和真实的细胞动力学数据进行有效的分类和预测。MODE通过利用神经门控机制大大提高了在无缝转换中的适应性和预测准确性。
### Conclusion
作者通过多个合成和真实的数据集对MODE进行了评估，包括在分类任务中的表现，以及在细胞动力学关键过程中的预测准确性。结果表明，MODE在处理高度非线性和复杂动力学转换方面具有优越的能力，不但能够区分增殖和分化动力学，还能够在分子层面预测细胞在最终命运决定的时刻，这对计算生物学来说是一个重要的突破性成果。
## 844. `cs.LG` - BaNEL: 基于仅使用负奖励的生成建模探索先验 [PDF](https://arxiv.org/pdf/2510.09596), [HTML](https://arxiv.org/abs/2510.09596)
### Authors
Sangyun Lee,Brandon Amos,Giulia Fanti
### Background
今天的生成模型依赖大量监督数据和具有信息量的质量奖励函数来产生高质量的生成结果。假设提供的数据预先训练模型，奖励函数提供关于如何进一步提高生成质量和正确性的密集信息。但在重要问题的最困难实例中，两个问题显现：（1）基础生成模型几乎得到零奖励信号，（2）调用奖励预言机（oracle）的成本昂贵。这种设置提出了与标准基于奖励的后训练完全不同的学习挑战。
### Innovation
为了应对这一挑战，该论文提出了BaNEL（Bayesian Negative Evidence Learning）算法。该算法仅使用失败尝试来后训练模型，并且会尽量减少奖励评估次数。其创新之处在于将学习失败背后的规律的问题重新定义为另一个嵌套生成建模问题，并利用此模型评估新数据是否类似于先前看到的失败，从而引导生成偏离这些失败模式。该方法在几个稀疏奖励任务上显示出无需观察单个成功样本也能提高模型性能，相较现有的新颖性奖金方法，在成功率上可提升多个数量级，且使用更少的奖励评估次数。
### Conclusion
该论文展示了使用仅基于负奖励的策略，通过BaNEL算法的特点，提高生成模型在一些稀疏奖励任务上的性能。相较于现有的新颖性奖金方法，该方法在成功率达到几个数量级的提升，且使用更少的奖励评估次数，成功解决了最困难问题中的学习挑战。
## 845. `cs.LG` - 进化计算作为自然生成人工智能 [PDF](https://arxiv.org/pdf/2510.08590), [HTML](https://arxiv.org/abs/2510.08590)
### Authors
Yaxin Shi,Abhishek Gupta,Ying Wu,Melvin Wong,Ivor Tsang,Thiago Rios,Stefan Menzel,Bernhard Sendhoff,Yaqing Hou,Yew-Soon Ong
### Background
生成人工智能（GenAI）已在许多领域取得了显著的成功，但其能力仍受限于有限训练集的统计模型以及基于局部梯度信号的学习。这些限制往往会导致更多的衍生性产物而非真正意义上的生成。与之相比，进化计算（EC）提供了一种探索更多样性和创造力的搜索驱动路径，通过探索超出可用数据界限的未知解决方案空间，扩展了生成能力。本文建立了EC与GenAI之间的根本联系，重新定义EC为自然生成人工智能（NatGenAI）——一种由探索性搜索和自然选择控制下的生成范式。
### Innovation
本文的关键创新在于将经典EC的操作与传统GenAI相映射，而颠覆性操作则能实现结构性的进化跳跃，通常在短短几代内就能生成超出分布的产物。此外，进化多任务的方法提供了整合颠覆性EC（跨域重组进化特征）和限制性选择机制（允许新颖解决方案生存）的卓越手段，从而促进持续创新。通过对EC重新定义为NatGenAI，本文强调了结构性破坏和选择压力的适度调节作为创造力驱动因素的重要性。这种视角扩展了生成范式的边界，并将EC置于推动探索性设计、创新、科学发现以及GenAI时代开放生成的核心地位。
### Conclusion
通过将EC重新定义为NatGenAI，我们强调结构性破坏和选择压力的适度调节作为创造力驱动因素的重要性。这种视角扩展了生成范式的边界，并将EC置于推动探索性设计、创新、科学发现以及GenAI时代开放生成的核心地位。
## 846. `cs.LG` - Recover-LoRA：通过低秩适应恢复退化语言模型的无数据精度 [PDF](https://arxiv.org/pdf/2510.08600), [HTML](https://arxiv.org/abs/2510.08600)
### Authors
Devleena Das,Rajeev Patwari,Ashish Sirasao
### Background
推理优化如量化、剪枝、格式和数据类型转换、模型导出和序列化可能会导致语言模型任务性能下降。大多数性能恢复工作集中在稳健的量化技术上，而本研究则致力于从任何导致模型权重退化的原因中恢复模型的精度，例如不当的模型序列化。
### Innovation
提出了一个轻量级且数据无关的方法Recover-LoRA，用于在降级模型中恢复精度。Recover-LoRA 使用合成数据和 logits 透视法，在选择性层上学习 LoRA 调整器，以使降级模型与全精度模型对齐。该方法适用于多种小语言模型，包括具有不同注意力结构的模型，如多头注意力（MHA）和组查询注意力（GQA），并在多个评估数据集中进行了验证。
### Conclusion
Recover-LoRA 在具有 MHA 和 GQA 的小语言模型中恢复了 5-17% 的模型精度。
## 847. `cs.LG` - PyNoetic:一个用于无代码开发EEG脑机接口的模块化Python框架 [PDF](https://arxiv.org/pdf/2509.00670), [HTML](https://arxiv.org/abs/2509.00670)
### Authors
Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo
### Background
EEG-基于的BCI在多个领域（如机器人、虚拟现实、医学和康复）都展现出了革新性技术的应用潜力。然而，现有的BCI框架存在一些局限性，包括实验研究所需阶段灵活性不足、对非编程研究人员的学习曲线陡峭、因依赖专有软件而导致成本提升以及因缺乏集成特性而导致研究人员需使用多款外部工具的问题，这些问题都可能影响研究结果。
### Innovation
PyNoetic是一个模块化的BCI框架，旨在满足BCI研究领域的多样需求。它是一个Python框架，覆盖了从刺激呈现和数据采集到通道选择、滤波、特征提取、去噪、仿真和可视化等整个BCI设计流程。PyNoetic还引入了一个直观的端到端GUI和独特的拖放配置的流程图，支持无代码BCI设计，并且使缺乏编程经验的研究人员也能使用。此外，PyNoetic还支持高级用户无缝集成自定义功能和新型算法，确保在每个设计阶段的灵活性。PyNoetic还配备了丰富的分析工具，如机器学习模型、脑连接性指数、仿真和模拟的功能测试以及新型范式的评估方法。PyNoetic的优势在于能够在离线和实时BCI开发中实现灵活性，简化设计流程，使研究人员能够集中精力进行更精细的BCI开发，从而加速研究进程。
### Conclusion
PyNoetic通过其模块化设计和广泛的工具支持，在BCI领域提供了一个强大的解决方案，解决了传统BCI框架面临的问题，并且促进了BCI研究的发展。
## 848. `cs.LG` - Mnemosyne：边缘基础的大语言模型中基于人类启发的无监督长期记忆架构 [PDF](https://arxiv.org/pdf/2510.08601), [HTML](https://arxiv.org/abs/2510.08601)
### Authors
Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio(Kaliber AI)
### Background
长时记忆对于自然和真实对话至关重要。然而，现有的大型语言模型（LLM）记忆系统依赖于扩展上下文或静态检索管道，这些方法在边缘受限设备上表现不佳。
### Innovation
引入Mnemosyne，这是一种用于边缘基础LLM的无监督、受人类启发的长期记忆架构。Mnemosyne采用图结构存储、模块化物质和冗余过滤机制、记忆提交与修剪机制、以及基于人类记忆的具有时间衰减和刷新的概率性检索。
### Conclusion
Mnemosyne在纵向医疗对话实验中的人类盲评估中实现了65.8%的最高胜率，远高于现有检索增强方法的基准线31.1%。此外，Mnemosyne在LoCoMo基准测试中的时间推理和单跳检索得分也最高，整体平均得分54.6%同样是第二高，超越了包括Mem0和OpenAI在内的常用基线路由。这表明，改进的事实回忆、增强的时间推理以及更自然的面向用户的响应可以通过边缘兼容且易于转移的无监督记忆架构来实现。
## 849. `cs.LG` - 较少多样性，较少安全：大规模语言模型测试时扩展中间接但普遍存在的风险 [PDF](https://arxiv.org/pdf/2510.08592), [HTML](https://arxiv.org/abs/2510.08592)
### Authors
Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra
### Background
Test-Time Scaling (TTS) 通过探索多个候选响应并从中找到最佳输出来增强LLM推理。TTS 的一个未被注意到的假设是，高度多样化的候选集能提高可靠性。然而，本文发现当候选集多样性减少，即使是适度减少，TTS 也更可能产生不安全的输出。为诊断此问题，作者提出了一种引荐导向的多样性减少协议（RefDiv），用于对TTS流程进行压力测试。实验表明，限制多样性会导致TTS产生更多的不安全结果，这一现象在不同的TTS策略和封闭源代码模型中也普遍存在。此外，发现广泛使用的安全护栏分类器（如Llama-Guard和OpenAI Moderation API）无法识别RefDiv生成的对抗输入提示，说明现有的防御措施对这种由多样性驱动的失败模式提供有限的保护。该研究希望激发对未来设计能够抵御多样性强敌压力测试的TTS策略的研究
### Innovation
提出了参考导向的多样性减少协议（RefDiv），这是一种诊断攻击，用于对TTS流程进行压力测试；发现限制多样性会导致TTS产生更多的不安全结果；表明这一现象在不同的TTS策略和封闭源代码模型中广泛存在；发现广泛使用的一些安全护栏分类器无法识别RefDiv生成的对抗输入提示，指出现有的防御措施对这种缺陷提供有限保护
### Conclusion
TTS 中的多样减少会导致更多的不安全结果，这一现象不仅在开放源代码模型中也存在于封闭源代码模型；现有安全护栏对由多样性驱动的攻击提供有限保护；未来需要设计既有效又能够抵御这种多样性驱动攻击的TTS策略
## 850. `cs.LG` - 深度神经网络的持久主导地位：对量子机器学习和脉冲神经网络根本局限性的批判性分析 [PDF](https://arxiv.org/pdf/2510.08591), [HTML](https://arxiv.org/abs/2510.08591)
### Authors
Takehiro Ishikawa
### Background
最近，量子机器学习（QML）和脉冲神经网络（SNNs）的发展引起了极大的兴趣，它们在理论上可以实现指数级的速度提升和类似大脑的能量效率，从而彻底改变人工智能。然而，本文指出，它们短期内不太可能取代深度神经网络（DNNs）。QML在适应反向传播时面临单位约束、测量导致的量子态坍缩、荒原 plateau和高测量开销等问题，这些问题进一步受到当前嘈杂的中等规模量子硬件的限制。SNNs在代表能力带宽方面受限，难以处理长距离依赖关系和语言任务中的语义编码，因为它们基于脉冲处理。即使它们声称的能量效益也高估了，优化后的DNNs通过量化技术在实际条件下可以实现更好的能源效益。此外，SNN训练从时间展开的角度来看对计算资源要求也很高。相比之下，DNN利用有效的反向传播、稳健的正则化及用于提升推理时间计算的线性回归模型创新，能够通过强化学习和搜索算法如MCTS实现自我改进，同时缓解数据稀缺性。最近的模型，例如xAI的Grok-4 Heavy和gpt-oss-120b，证明了DNNs在性能上的优越性，尽管它们的参数规模相对较小且可以在单个80GB GPU上部署。此外，专用的ASIC进一步放大了这些效率增益。最终，QML和SNNs可能在某些特定杂交角色中发挥作用，但DNNs仍然是推动人工智能进步的主要、实用的范式。
### Innovation
本文创新性地分析了QML和SNNs的潜在局限性，并强调了DNNs在性能、效率和实际应用中的持续主导地位，即使在计算资源紧张的情况下也能够通过优化和硬件支持实现自我改进。
### Conclusion
本文结论认为，尽管QML和SNNs在理论上具有潜在的优势，但在实际应用中，DNNs的效率和性能更为优越，能够通过自我改进和优化以更好应对数据稀缺等问题，因此DNNs在推动人工智能进步方面仍然是主要且实用的范式。
## 851. `cs.LG` - LatentBreak: 通过潜在空间反馈破解大型语言模型 [PDF](https://arxiv.org/pdf/2510.08604), [HTML](https://arxiv.org/abs/2510.08604)
### Authors
Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio
### Background
文章探讨了针对大型语言模型内置安全机制的破解技术（jailbreak）。现有的破解技术通过优化对抗后缀或适应长提示模板，迫使模型生成受限制或有害的响应，但这类方法可能被简单的困惑度筛选检测到。因此，需要一种新的破解方法来绕过这些防御。
### Innovation
提出了一种名为LatentBreak的白盒破解攻击技术，它生成自然的低困惑度对抗提示，能有效规避基于困惑度的防御机制。LatentBreak通过在输入提示中用语义等价词替换词语，尽量保持原始意图，而不是添加高困惑度的对抗后缀或长模板。
### Conclusion
广泛的评估表明，LatentBreak生成的提示更短且低困惑度，因此在多个安全对齐的模型中，相比其他基于困惑度的防护策略，它具有更好的性能。
## 852. `cs.LG` - 迈向更安全的网络：多语言多智能体大语言模型以减轻对抗式虚假信息攻击 [PDF](https://arxiv.org/pdf/2510.08605), [HTML](https://arxiv.org/abs/2510.08605)
### Authors
Nouar Aldahoul,Yasir Zaki
### Background
数字平台上虚假信息的迅速传播威胁公共话语、情感稳定和决策。此前的研究已探索了虚假信息检测的各种对抗性攻击，但本论文所研究的具体语言转换，如语言切换、翻译、查询长度膨胀、结构改写等尚未被系统性地研究过。这些对抗性攻击对多语言环境下的虚假信息检测提出了挑战，强调了利用人工智能进行虚假信息检测以保护在线事实完整性的必要性，对抗各种攻击手段的重要性。
### Innovation
本研究提出一个多语言、多智能体的大语言模型框架，该框架结合检索增强生成技术，能够在网络插件中部署于在线平台。这种方法不仅展示了多语言背景下的虚假信息检测的重要性，还展示了利用插件部署解决实际网络应用问题的可能性。
### Conclusion
本研究强调了以人工智能为基础的虚假信息检测方法的重要性，表明这种技术可以有效地应对各种攻击。同时，该研究提出的框架展示了在现实世界网络应用中通过插件部署多语言多智能体大语言模型的可能性，有助于保护在线环境中的事实完整性。
## 853. `cs.LG` - 数据增强和损失函数在脑肿瘤分割中的可重复评估 [PDF](https://arxiv.org/pdf/2510.08617), [HTML](https://arxiv.org/abs/2510.08617)
### Authors
Saumya B
### Background
脑肿瘤分割对于诊断和治疗规划至关重要，但面对类别不平衡和模型泛化能力有限等挑战，研究进展一直受阻。这项研究通过使用焦点损失和基本的数据增强策略，对U-Net在脑肿瘤MRI上的分割性能进行了可重复评估。
### Innovation
该研究通过调整焦点损失参数和评估三种数据增强技术（左右翻转、旋转和缩放）的影响，对使用焦点损失的U-Net实现了90%的精度，这一结果与最先进的技术相当。此外，该研究将所有代码和结果公开，提供了一个透明且可重复的基础线，以指导未来在脑肿瘤分割方面的数据增强策略和损失函数设计研究。
### Conclusion
这项研究为脑肿瘤分割数据增强策略和损失函数设计提供了可重复的基线，推动了该领域的进一步研究。
## 854. `cs.LG` - 人类文本为异常值：基于异常检测检测LLM生成的文本 [PDF](https://arxiv.org/pdf/2510.08602), [HTML](https://arxiv.org/abs/2510.08602)
### Authors
Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu
### Background
大型语言模型（LLMs）如ChatGPT、DeepSeek和Claude等的快速发展，显著增加了AI生成文本在网络通信中的存在。现有方法主要将人类文本和机器生成文本的区分视为二分类问题，但这种二分类假设存在缺陷，无法有效泛化到未见过的文本。针对这一问题，本文提出将检测任务重新定义为异常检测问题，人类文本被视为分布异常值，而机器生成的文本则属于分布内样本，从而改进了现有的二元分类方法。
### Innovation
本文提出了将文本检测问题重新定义为异常检测问题的方法，即认为人类文本分布中的异常值问题，而将机器生成的文本视为分布内样本，而非二分类问题的处理方式。研究中开发了一种检测框架，结合了一类学习方法（如DeepSVDD和HRN）和基于得分的学习技术（如能量法），提高了检测的鲁棒性和通用性。并通过多种数据集验证了该方法的有效性，特别是在DeepFake数据集上实现了98.3%的AUROC和AUPR，仅有8.9%的FPR95。此外，该框架在多种语言、攻击和未见过的模型及领域测试中也显示了其鲁棒性和通用性。
### Conclusion
本文提出了一种新的异常检测方法来识别LLM生成的文本，通过将其定义为异常检测问题，避免了二分类方法中的缺陷。该方法通过在不同数据集和环境下的广泛测试，展示了其强大泛化能力和鲁棒性，未来将进一步验证其在实际应用场景中的效果。
## 855. `cs.LG` - 基于相对定位的代码片段分割方法在代码仓库级代码补全任务中的丰富上下文检索 [PDF](https://arxiv.org/pdf/2510.08610), [HTML](https://arxiv.org/abs/2510.08610)
### Authors
Imranur Rahman,Md Rayhanur Rahman
### Background
代码补全能够帮助开发者提高效率并简化开发过程。尽管现代集成开发环境（IDEs）提供代码补全功能，但缺乏基于IDE可获取的信息来确定良好的代码补全上下文的研究，以帮助大型语言模型（LLMs）在代码补全任务中表现更好。现有的研究尚未探索有效的上下文收集策略来辅助LLMs进行代码补全任务。研究表明，通过预处理代码仓库生成更小的代码片段，并利用基于语法和语义相似性的代码片段检索及相对定位方法，可以有效地提高代码补全任务的性能。
### Innovation
本文提出了一种有效的代码片段分割方法，通过预处理代码仓库为更小的代码片段并利用基于相对定位的语法和语义相似性代码片段检索，从而提高代码补全任务的性能，这填补了现有研究中关于基于IDE信息确定良好代码补全上下文的空白。
### Conclusion
通过代码片段化和代码片段的相对定位，最终上下文的构建可以显著提高代码补全任务的性能。
## 856. `cs.LG` - 使用分层高斯混合模型的成因不确定性在LiDAR语义分割中的离群值检测 [PDF](https://arxiv.org/pdf/2510.08631), [HTML](https://arxiv.org/abs/2510.08631)
### Authors
Hanieh Shojaei Miandashti,Claus Brenner
### Background
通过精确的LiDAR点云语义分割获得准确的场景理解是必要的，但检测不在训练中遇到的不常见物体（OOD）也是必要的，以避免将未知物体误分类为已知类别。目前，监督的ODD检测方法依赖于辅助OOD数据集，而无监督的方法避免了这个要求，但通常依赖于预测熵，即通过集成或多个后验权重样本获得的预测分布的熵。然而，这些方法经常会混淆成因不确定性和偶然不确定性，将分布内的模糊区域误判为OOD。
### Innovation
提出了一个无监督的OOD检测方法，该方法利用分层贝叶斯建模的高斯混合模型（GMM）参数在深度神经网络特征空间中的成因不确定性。该方法无需辅助数据或额外的训练阶段，在SemanticKITTI数据集上的表现优于现有的基于不确定性的方法。
### Conclusion
我们的方法在AUROC上提高了18%，AUPRC上提高了22%，FPR95下降了36%（从76%下降到40%）相比现有的使用预测熵的方法。
## 857. `cs.LG` - 减少过时和易受攻击依赖项的最佳方法：锁定还是浮动？ [PDF](https://arxiv.org/pdf/2510.08609), [HTML](https://arxiv.org/abs/2510.08609)
### Authors
Imranur Rahman,Jill Marley,William Enck,Laurie Williams
### Background
开发人员经常使用版本约束来指定项目依赖项的可接受版本。锁定依赖项可以减少意外变更的风险，但也带来了手动管理过时且易受攻击的依赖项的不便。相反，浮动版本可以自动获取修复程序和安全补丁，但面临变更的风险。安全从业人员建议锁定依赖项以防止软件供应链攻击，如恶意包更新。然而，锁定是最严格的版本约束，最可能导致依赖项过时。因此，不知道不同版本约束类型下依赖项变得过时或易受攻击的概率如何变化。本文通过实证评估不同版本约束类型下依赖项变为过时和易受攻击的概率，帮助开发者做出更好的依赖项版本约束选择。研究首先识别了依赖项版本约束使用趋势和开发者在npm、PyPI和Cargo生态系统中版本约束类型变化的模式。然后使用生存分析建模依赖项状态转换，并估计使用锁定与使用其他版本约束类型相比，变为过时或易受攻击的概率如何变化。研究发现，在过时和易受攻击的依赖项中最常用的版本约束类型是flooting-minor，其次为锁定。同时发现，floating-major最不可能导致依赖项过时，而floating-minor最不可能导致依赖项易受攻击。
### Innovation
提出了通过生存分析实证评估不同版本约束类型下依赖项变为过时和易受攻击概率的变化，帮助开发者选择合适的版本约束类型，以减少过时和易受攻击的依赖项的风险。
### Conclusion
在过时和易受攻击的依赖项中最常用的版本约束类型是flooting-minor，最不可能导致依赖项过时和易受攻击的版本约束类型分别是floating-major和floating-minor。因此，开发人员在做出依赖项版本约束选择时应考虑这些发现以降低风险。
## 858. `cs.LG` - QuIRK: Quantum-Inspired Re-uploading KAN [PDF](https://arxiv.org/pdf/2510.08650), [HTML](https://arxiv.org/abs/2510.08650)
### Authors
Vinayak Sharma,Ashish Padhy,Vijay Jagdish Karanjkar,Sourav Behera,Lord Sen,Shyamapada Mukherjee,Aviral Shrivastava
### Background
KANs（Kolmogorov-Arnold Networks）在科学领域内的回归问题上表现出色，能够在使用更少参数的情况下超越传统深度神经网络，并且由于其结构是由单变量B-Spline函数组成，具有较高的可解释性，能够从训练好的KAN中导出封闭形式的方程。然而，B-Spline的局限性在于处理周期函数时表现不佳。
### Innovation
本文提出了受量子数据重新利用（Quantum Data Re-uploading）模型启发的QuIRK（Quantum-Inspired Re-uploading KAN）模型。QuIRK使用单量子比特DR模型代替B-Spline作为单变量函数逼近器，不仅在参数数量上更少，而且在处理周期函数时能够与或超越传统KAN。QuIRK模型由于仅使用单量子比特电路，可以通过GPU加速进行经典模拟，同时保留了传统KAN的可解释性优势和产生封闭形式方程的能力。
### Conclusion
QuIRK模型通过引入受量子计算概念启发的方法，在保持传统KAN模型优点的同时，进一步减少了参数数量，特别适用于处理周期函数问题。
## 859. `cs.LG` - PARSE：由LLM驱动的模式优化以实现可靠的实体提取 [PDF](https://arxiv.org/pdf/2510.08623), [HTML](https://arxiv.org/abs/2510.08623)
### Authors
Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla
### Background
在新兴的软件3.0系统中，大型语言模型（LLM）代理自主与API和服务交互，提取结构化信息从非结构化文本变得尤为关键。现有方法通常直接使用大型语言模型进行现有JSON模式的提取任务，尽管使用了约束解码或强化学习等方法来确保语法规则性，但仍将JSON模式视为为软件开发者设计的静态合约，这导致提取性能欠佳、频繁的幻觉结果以及代理行为不可靠。研究人员意识到JSON模式本身是一种自然语言理解合约，包含了数据结构的规则、关系和期望，LLM应该能够理解和系统地改进这些规则。
### Innovation
PARSE系统通过引入两个协同组件——ARCHITECT和RELAY（自动优化JSON模式并保持向后兼容性的代码生成系统），以及SCOPE（结合静态和基于LLM的护航的基于反射的提取系统）来解决这些问题。与现有方法相比，PARSE实现了从6%到64.7%的提取准确率提高，并在首次重新尝试中将提取错误减少了92%，同时也保持了合理的延迟。
### Conclusion
研究者通过定性和定量评估的方式，在Schema-Guided Dialogue (SGD)、Structured Web Data Extraction (SWDE) 和内部零售对话数据集上测试了PARSE系统。结果显示了架构改进能够提高10%，在SWDE数据集上的提取准确率达到64.7%的提升，重新尝试时减少了92%的提取错误。
## 860. `cs.LG` - 自主科学代理演化网络中的假设狩猎 [PDF](https://arxiv.org/pdf/2510.08619), [HTML](https://arxiv.org/abs/2510.08619)
### Authors
Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar
### Background
大规模科学数据集涵盖了健康生物库、细胞图谱、地球再分析等，这些数据集为不受特定研究问题限制的探索性发现提供了机会。这一过程被我们称为假设狩猎，即在巨大的和复杂假设空间中持续探索以寻求深刻见解的过程。为了支持这一过程，我们引入了AScience框架，将发现过程建模为代理、网络和评估规范的相互作用，并以ASCollab系统进行了实现，该系统是基于LLM的研究代理，具有异质行为。代理自我组织成不断演变的网络，持续生产和互评成果，按通用评估标准进行。实验表明，这样的社会动态能够促进从多样性质量新颖性前沿中累积专业标准的结果，包括重新发现已确立的生物标志物、扩展已知途径等，以及提议新的治疗目标。尽管湿实验室验证不可或缺，我们的癌症队列实验表明，结构性的、有代理权的网络可以在大规模环境下维持探索性假设狩猎。
### Innovation
引入了AScience框架来模拟发现过程中的代理、网络和评估规范的相互作用，并通过ASCollab系统实现了一种基于LLM的研究代理系统，这些代理具有异质行为并且能够自我组织，持续生产和互评研究成果，通过共享的评估标准来实现。实验结果表明，这种社会动态能够促进累积专业标准的结果，涵盖重新发现生物标志物、扩展已知路径，以及提出新的治疗目标等多样化、高质量和新颖的结果。而这些发现无需依赖传统的实验室验证，显示了这种结构化的、有代理权的网络能够支持大规模的探索性假设狩猎。
### Conclusion
尽管湿实验室验证仍然不可或缺，但实验结果表明，结构化的自主科学代理网络可以在大规模环境下继续支持探索性假设狩猎，提供了新的可能，以更高效、更灵活的方式来进行科学研究。同时，通过共享的评估标准和源源不断的反馈机制，这些代理网络能够在多样性和新型研究结果方面取得显著进展。
## 861. `cs.LG` - 通过层次扩散语言模型进行下一语义级别预测 [PDF](https://arxiv.org/pdf/2510.08632), [HTML](https://arxiv.org/abs/2510.08632)
### Authors
Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola
### Background
本文介绍了一种新颖的语言模型家族，即层次扩散语言模型（HDLM），旨在更好地预测语言中的语义层次。传统的方法通常关注的是单词级别的预测，而HDLM通过层次词汇表，将详细的语义低级词汇映射到粗粒度语义的高级词汇，从而提供一种时间动态变化的下一个语义层级预测过程。这种方法结合了扩散模型和层次结构的优势，能够在生成文本时更好地捕捉到语言中的复杂语义层次。此前已有研究主要关注低级词汇上的扩散模型，但本研究提出了将这些模型扩展到高级词汇层的新颖框架。
### Innovation
HDLM基于层次词汇模型，将细节丰富的低级词汇映射到粗粒度的高级词汇，提出了新的扩散语言模型框架。在模型的前向过程中，每个词汇独立地被扰动到其抽象程度更高的祖先词汇；而在反向过程中，模型逐步预测更详细的语义。HDLM不仅能够泛化现有模型（MDLM）的情况，还提出了具体训练技术，并通过全面的文本生成实验验证了其有效性，表现出了比基线更低的验证和生成困惑度。此外，文章还推导了扩散证据下界（ELBO）的闭式表达式，并展示了其实现的灵活性。
### Conclusion
本文提出的HDLM通过时间变化的语义预测过程，显著提高了语言建模的性能。通过验证实验，HDLM在验证和生成困惑度上表现优于现有基线模型，展示了其在更复杂语义层次捕获方面的优越性。未来研究有望探讨更高效的训练策略和更广泛的高级词汇层次的影响。
## 862. `cs.LG` - 使用面向谱系的图注意力模型解读结核分枝杆菌中的正向选择 [PDF](https://arxiv.org/pdf/2510.08703), [HTML](https://arxiv.org/abs/2510.08703)
### Authors
Linfeng Wang,Susana Campino,Taane G. Clark,Jody E. Phelan
### Background
背景：正选择驱动结核分枝杆菌中适应性突变的出现，影响药物耐药性、传播性和毒性。谱系树捕捉菌株间的进化关系，构成检测适应性信号的自然框架。研究者使用500株来自四大谱系的结核分枝杆菌和249个单核苷酸变异体构建图结构，采用图注意网络（GAT）方法研究适应性进化信号。
### Innovation
创新：提出一种谱系引导的图注意力网络（GAT）方法，将单核苷酸多态性（SNP）注释的谱系树转换为适用于神经网络分析的图结构。在去除超过七个内部节点的边后，节点特征编码SNP的存在或不存在，GAT架构包括两层注意机制、残差连接、全局注意池化和多层感知机分类器。该模型在保留测试集上的准确率为0.88，并成功识别了41个不同谱系中具有收敛出现的候选变异，与正向选择一致。
### Conclusion
结论：该研究证实将谱系转换为GNN兼容结构的可行性，并强调基于注意机制的模型是检测正向选择的有效工具，有助于基因组监视和变异筛选。
## 863. `cs.LG` - 结构化输出正则化：一种用于少量样本迁移学习的框架 [PDF](https://arxiv.org/pdf/2510.08728), [HTML](https://arxiv.org/abs/2510.08728)
### Authors
Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay
### Background
传统迁移学习通常通过冻结部分预训练网络的权重并添加任务特定层来重用大型预训练网络。虽然这种方法计算效率高，但限制了模型适应领域特定特征的能力，并且在数据非常有限的情况下仍然可能导致过拟合。现有框架需要使用额外参数对模型进行大量修改，这限制了其在各类网络组件中的广泛适用性，如卷积滤波器或神经网络中的各种模块，从而阻碍了其在迁移学习任务中的广泛适用性。
### Innovation
提出了一种结构化输出正则化（SOR）框架，这是一种简单而有效的框架，冻结内部网络结构（如卷积滤波器），同时使用组合的群组lasso和$L_1$惩罚。该框架仅通过少量额外参数调整模型，并且易于应用于各种网络组件，如卷积滤波器和各种神经网络模块，使其广泛适用于迁移学习任务。
### Conclusion
在三个少量样本医学成像分类任务中评估了SOR，使用DenseNet121和EfficientNetB4为基础，结果与现有基准相当。
## 864. `cs.LG` - 语言模型微基准测试的可靠性如何？ [PDF](https://arxiv.org/pdf/2510.08730), [HTML](https://arxiv.org/abs/2510.08730)
### Authors
Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta
### Background
微基准测试提供了一种解决语言模型开发中经常难以承受的时间和成本的方法：仅在现有基准的小部分上进行评估。然而，这些微基准测试是否能够像它们所取代的完整基准测试那样一致地对模型进行排名？它们是否比随机选择数据点的子集排名更一致？研究发现结果并不总是如此。
### Innovation
介绍了用于微基准测试的元评价措施，该措施研究了微基准测试如何随着其在完整基准测试上性能差异函数的好坏程度来对两个模型进行排名。这种方法可以确定哪些模型对可以由微基准测试正确排名，从而在微基准测试大小和可靠性之间进行精细化分析。研究发现，为了在准确率相差3.5分或4分的情况下一致地排名模型对，通常需要选择250个示例，此时随机抽样与其他微基准测试方法相当。当仅比较具有相同大小的指令调优模型时，发现超过一半的成对比较可能不再被保留。
### Conclusion
我们的研究提供了对微基准测试用户和开发者在评估效率和可靠性之间的权衡方面具有可操作指导意义的结果。
## 865. `cs.LG` - SkipSR：通过标记跳过实现更快的超分辨率 [PDF](https://arxiv.org/pdf/2510.08799), [HTML](https://arxiv.org/abs/2510.08799)
### Authors
Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni
### Background
基于扩散的超分辨率（SR）是视频生成和视频恢复中的关键组件，但是速度慢且成本高，限制了其在更高分辨率和更长视频上的应用扩展。
### Innovation
提出了一种新的框架SkipSR，在低分辨率输入中直接识别低细节区域，对这些区域完全跳过计算，仅对需要精细的区域进行超分辨率处理，从而在保持感知质量的同时显著减少了计算。
### Conclusion
在标准的SR基准测试中，该方法在720p视频上实现了比先前模型高达60%的端到端延迟减少，同时无感知质量损失。视频演示可在该网址获取：this https URL
## 866. `cs.LG` - Neptune: 在GPU上提高局部性和并行性的高级机器学习操作融合 [PDF](https://arxiv.org/pdf/2510.08726), [HTML](https://arxiv.org/abs/2510.08726)
### Authors
Yifan Zhao,Egan Johnson,Prasanth Chatarasi,Vikram Adve,Sasa Misailovic
### Background
深度学习中操作融合已成为关键优化技术，它通过合并多个深度学习操作来提高数据重用并减少全局内存传输。然而，现有张量编译器难以融合涉及循环携带依赖（如注意力机制中的复杂归约计算）的操作。
### Innovation
Neptune 引入了一种新的高级操作融合方法，该方法故意打破部分现有依赖关系，并通过构建代数修正表达式来补偿，确保核函数可以产生正确的结果。
### Conclusion
Neptune 在十个基于注意力的基准测试中，从简单的注意力代码和高级调度模板开始，超过了现有的编译器如 Triton、TVM 和 FlexAttention，包括基于 Triton 的 FlashAttention 实现。在来自 NVIDIA 和 AMD 的四种不同 GPU 架构中，Neptune 生成的内核在平均加速比上达到了 1.35 倍，证实了其在深度学习工作负载中的有效性。
## 867. `cs.LG` - 文本因果推理设计问题：语言模型会太大吗？ [PDF](https://arxiv.org/pdf/2510.08758), [HTML](https://arxiv.org/abs/2510.08758)
### Authors
Graham Tierney,Srikar Katta,Christopher Bail,Sunshine Hillygus,Alexander Volfovsky
### Background
许多社会科学问题探讨语言特性如何因果影响受众的态度和行为。由于文本特性通常是相互关联的（例如，愤怒的评论使用冒犯性的语言），因此必须控制潜在的共因以隔离因果效应。最近的研究建议使用大语言模型（LLMs）来识别文本的隐含表示，这可以成功地预测治疗和结果。然而，由于治疗是文本的一部分，这些深度学习方法可能会学习编码治疗本身的表示，从而引发重叠偏差。本文引入了一种新颖的实验设计，该设计可以处理潜在的共因，避免重叠问题，并无偏估计治疗效果。
### Innovation
本文提出了一种新颖的实验设计，旨在处理潜在的共因并避免重叠偏差，从而无偏估计治疗效果。此外，通过实验证明基于大语言模型的方法在实际文本和实验结果中的表现甚至不如简单的词袋模型。
### Conclusion
该实验隔离了表达谦逊在政治沟通中的说服力效果，为社交媒体平台、政策制定者和社会科学家提供了新的沟通效果见解。同时，研究结果表明全文本的成功预测依赖于大语言模型的方法可能并不优于简单的词袋模型。
## 868. `cs.LG` - 理解系外行星宜居性：基于贝叶斯机器学习框架预测大气吸收光谱 [PDF](https://arxiv.org/pdf/2510.08766), [HTML](https://arxiv.org/abs/2510.08766)
### Authors
Vasuda Trehan,Kevin H. Knuth,M. J. Way
### Background
近年来，由于计算技术的进步，如人工智能（AI）和机器学习（ML），空间技术的发展迅猛，极大地提升了我们探索宇宙的能力。例如，詹姆斯·韦伯太空望远镜（JWST）等任务使得远距离天体的信息更加容易获取，从而产生了大量有价值的数据。在此背景下，研究团队正在致力于建立一个系外行星大气吸收光谱预测模型，该模型将结合观测光谱数据与由NASA戈达德空间研究所气候建模项目开发的ROCKE-3D通用气候模型生成的合成光谱数据。
### Innovation
研究团队开发了一个贝叶斯自适应探索框架，利用插值曲线描述模拟大气吸收光谱的箱高与行星参数值之间的关系。通过Bayesian Adaptive Exploration方法，确定需要更多数据以改进模型的行星参数空间区域。这将有助于建立一个正向模型，通过已知行星大气吸收光谱推断出行星参数。这项工作预计有助于更好地理解系外行星属性、普遍的系外行星气候和宜居性。
### Conclusion
最终建立的系统会作为一个正向模型使用，通过已知行星大气吸收光谱可以推断出行星参数，为研究系外行星的属性和宜居性提供了新的方法。
## 869. `cs.LG` - 人工启发式算法已死，长存代码生成器! [PDF](https://arxiv.org/pdf/2510.08803), [HTML](https://arxiv.org/abs/2510.08803)
### Authors
Rohit Dwivedula,Divyanshu Saxena,Aditya Akella,Swarat Chaudhuri,Daehyeok Kim
### Background
过去的政策设计通常是一个手动过程，由领域专家精心调整适用于特定部署场景的手动启发式策略。本文重新设想了政策设计，通过一种新的自动搜索技术来实现，这种方法受到生成模型最近进展的驱动，特别是大型语言模型（LLM）驱动的代码生成。
### Innovation
作者提出了PolicySmith框架，该框架利用大型语言模型来合成实例最优的启发式策略。PolicySmith应用于web缓存和拥塞控制两个长期存在的系统政策，展示了这种LLM驱动的启发式搜索的机会。在缓存方面，PolicySmith发现的启发式策略在标准开源日志中优于已建立的基线。在拥塞控制方面，PolicySmith可以生成可以直接整合到Linux内核中的安全策略。
### Conclusion
总体而言，该研究展示了如何利用大型语言模型实现自动政策设计，这不仅提高了政策设计的效率，还显著提升了性能。这种代码生成器框架展示了未来自动化系统设计的巨大潜力。
## 870. `cs.LG` - 以利润为导向的延迟优先：基于DRL的5G网络切片接入控制 [PDF](https://arxiv.org/pdf/2510.08769), [HTML](https://arxiv.org/abs/2510.08769)
### Authors
Proggya Chakraborty,Aaquib Asrar,Jayasree Sengupta,Sipra Das Bit
### Background
5G网络通过网络切片能够支持多种服务（如eMBB、URLLC和mMTC），但实现这一目标需要智能的准入控制和资源分配以满足严格的服务质量（QoS）要求，并最大化网络服务提供者的利润。现有深度强化学习（DRL）框架主要集中在利润优化上，而没有明确考虑服务延迟，这可能导致对延迟敏感切片的QoS违反。此外，通常使用ε贪婪探索机制会带来不稳定且次优的策略学习结果。
### Innovation
本文提出了一种名为DePSAC（延迟和利润感知切片准入控制）的新方法。该方法基于DRL，引入了延迟感知的奖励函数，通过惩罚延迟引发的服务问题来增强对URLLC等延迟关键切片的优先处理。还采用了玻尔兹曼探索机制以实现更平稳和快速的收敛。通过在具有实际网络切片请求（NSLR）到达模式的5G核心网络模拟环境下实现和评估，结果显示我们的方法在总体利润、减少URLC切片延迟、接受率提升和资源利用方面均优于基准DSARA方法。此结果显示提出的DePSAC方法能够更好地实现QoS与利润之间的权衡，在实际5G网络切片场景中具有有效性。
### Conclusion
我们的方法在5G网络切片应用场景中实现了更好的QoS-利润权衡，优于现有基准方法。它通过一个延迟感知的奖励函数和玻尔兹曼探索机制有效解决了延迟敏感服务的QoS和利润优化问题。实验结果显示，我们的方法在各方面都表现出了优越性。
## 871. `cs.LG` - 使用预训练深度学习模型和机器人平台进行热成像油污检测 [PDF](https://arxiv.org/pdf/2510.08770), [HTML](https://arxiv.org/abs/2510.08770)
### Authors
Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung
### Background
该研究提出了一种实时油污检测系统，利用预训练的深度学习模型结合RGB和热成像技术，在多种环境中对油污与无油污情况进行分类。研究使用了均衡的二分类数据集（4000张图像），实验展示了热成像在推理速度、准确性和模型大小方面的优势。轻量级模型（如VGG19、NasNetMobile）在热成像数据上达到了100%的准确率，在不同光照条件下的性能更加稳定快速。系统运行在消费级硬件（RTX 4080）上，实现了最低44毫秒的推理时间，模型大小低于350MB，突显了其在关键安全环境中的可部署性。实验表明，使用热成像数据训练的VGG19模型效果最佳。
### Innovation
该系统采用了预训练的深度学习模型结合RGB和热成像技术来实现实时油污检测，特别强调了热成像在不同光照条件下的优势和轻量级模型的应用。此外，系统在消费级硬件上实现了高效部署，模型大小和推理时间都非常优化。这些特点提升了系统的实用性和可扩展性，特别是在安全监控领域中。
### Conclusion
研究结果表明，系统通过预训练的深度学习模型结合热成像技术实现了高效的油污检测，轻量级模型如VGG19在热成像数据上的效果最佳，且系统在消费级硬件上的表现优异，达到了极低的推理时间和较小的模型大小，展示了在关键安全环境中的部署潜力。
## 872. `cs.LG` - Humanoid Everyday：开放世界类人机器人操作的综合数据集 [PDF](https://arxiv.org/pdf/2510.08807), [HTML](https://arxiv.org/abs/2510.08807)
### Authors
Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang
### Background
类人机器人在展示复杂全身能力方面取得了显著进步，但当前大部分机器人学习数据集和基准主要集中在静止的机器人手臂上。现有的类人机器人数据集要么局限于固定环境，要么任务多样性有限，很少涉及人类与类人机器人交互和下肢运动。此外，几乎没有标准化的评估平台用于基准学习导向的策略在类人机器人数据上的性能。
### Innovation
本研究提出了一种名为Humanoid Everyday的大型且多样的类人机器人操作数据集，该数据集包括广泛的涉及灵巧物体操作、人与类人机器人交互、结合移动的动作等多种任务。通过高效的受人类监督的远程操作流水线，该数据集结合了高质的多模态传感数据（包括RGB、深度、LiDAR和触觉输入）以及自然语言注释，共计10300个轨迹和300多万帧数据，覆盖7大类别中的260项任务。此外，还分析了代表性的策略学习方法在本数据集上的表现，提供了不同任务类别中它们的优势和局限性见解，并引入了一种基于云的标准化评估平台，允许研究人员无缝部署其策略并在受控环境中接收性能反馈。
### Conclusion
通过发布Humanoid Everyday数据集及策略学习分析结果和基于云的标准化评估平台，本研究旨在推动通用型类人机器人操作的研究，并为更具备表现力和实体化的机器人代理在现实世界场景中打下基础。相关数据集、数据收集代码和云评估网站已公开提供于项目网站上。
## 873. `cs.LG` - CommandSans：以手术级精确性清理指令确保AI代理安全 [PDF](https://arxiv.org/pdf/2510.08829), [HTML](https://arxiv.org/abs/2510.08829)
### Authors
Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader
### Background
随着可访问众多工具和敏感数据的大规模语言模型（LLM）代理的广泛采用，间接提示注入的攻击面显著增加。由于攻击的上下文依赖性，当前的防御措施往往不能可靠地区分恶意和良性指令，导致高误报率，抑制了其在现实世界中的应用。
### Innovation
我们提出了一种新的方法，借鉴了计算机安全的基本原则：数据不应包含可执行指令。我们建议进行一种令牌级别的清洗过程，该过程从工具输出中手术般去除任何针对AI系统的指令，同时将恶意指令作为副产品捕获。与现有的安全分类器相比，该方法是非阻塞的，无需校准，并且对工具输出的上下文不敏感。此外，我们可以通过仅使用现有的指令调优数据进行训练，而不需要依赖来自挑战或其他合成来源的不现实的提示注入示例。我们的实验表明，该方法在各种攻击和基准测试（如AgentDojo、BIPIA、InjecAgent、ASB和SEP）中具有很好的泛化能力，实现了7-10倍的攻击成功率的减少（在AgentDojo中从34%降低到3%），而不会损害代理在良性或恶意设置中的实用性。
### Conclusion
我们所提出的方法能够在各种攻击和基准测试中有效降低攻击成功率，同时保持良好的代理实用性，无需额外数据和计算资源。
## 874. `cs.LG` - 基于约束最小二乘最小化的瞬时过程代表定理 [PDF](https://arxiv.org/pdf/2510.08916), [HTML](https://arxiv.org/abs/2510.08916)
### Authors
Hideaki Kim,Tomoharu Iwata
### Background
核方法的核心是表示定理，它允许通过核函数从灵巧的完整希尔伯特空间中估计隐函数。这种非参数估计方法将无穷维的优化问题转化为有限维的对偶系数优化问题，从而使得算法更具实践性和计算可行性。本文的研究目的是基于瞬时过程理论，特别是线性多变量瞬时过程，利用核函数框架估计隐性触发核函数，即编码事件之间相互作用结构的函数。
### Innovation
本文提出了一种基于约束最小二乘最小化的新型表示定理，证明了一个新的形式，通过定义一系列同时积分方程的转换核，最优的触发核估计可以表示为这些转换核在数据点上的线性组合。值得注意的是，对偶系数完全固定为1，无需解决复杂的优化问题即可获得对偶系数，这使得估计器在处理大规模数据时更为高效。
### Conclusion
实验结果表明，提出的方法在人造数据集上取得了可竞争的预测准确性，同时大幅提高了计算效率，优于现有的基于核方法的估计器。
## 875. `cs.LG` - Gradient-Guided Furthest Point Sampling for Robust Training Set Selection [PDF](https://arxiv.org/pdf/2510.08906), [HTML](https://arxiv.org/abs/2510.08906)
### Authors
Morris Trestman,Stefan Gugler,Felix A. Faber,O. A. von Lilienfeld
### Background
在相关于化学的机器学习问题中，减少数据需求并提升预测稳健性可以通过智能的训练集选择程序实现。传统的Furthest Point Sampling (FPS)方法被广泛使用，但它可能无法有效地覆盖所有重要配置空间，尤其是在化学分子的复杂性方面，可能导致训练集中重要数据的缺失或偏差，从而影响模型的泛化能力和预测准确性。
### Innovation
本文提出了一种新的采样方法——Gradient Guided Furthest Point Sampling (GGFPS)，它是一种对FPS简单扩展，通过利用分子力范数来引导配置空间的高效采样。实验结果表明，与FPS和均匀采样相比，使用GGFPS能够显著提高数据效率和预测稳健性。特别是在MD17分子动力学轨迹数据集中，GGFPS解决了FPS系统性下采样平衡几何结构的问题，从而降低了松弛结构的测试误差，并提供了更准确和一致的预测结果。
### Conclusion
研究结果表明，具有梯度意识的采样方法作为有效的训练集选择工具具有很大的潜力。本文的方法表明，盲目使用FPS可能导致训练集不平衡和预测结果不一致。
## 876. `cs.LG` - GTAlign: 基于博弈论对大型语言模型助手进行互惠对齐 [PDF](https://arxiv.org/pdf/2510.08872), [HTML](https://arxiv.org/abs/2510.08872)
### Authors
Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You
### Background
大型语言模型（LLMs）在推理方面取得了显著进步，但在诸如写作、信息检索或提供实用指导等任务中，有时会产生对用户不够理想的回答。传统对齐方法通常假设最大化模型奖励也最大化了用户福利，但在实践中这种假设经常失败：模型可能会过于详细解释从而产生冗长的推理，而用户可能更希望简洁的答案。这些行为类似于囚徒困境，个体理性的选择会导致社会最优结果的失败。因此，缺乏一个能够同时优化LLM和用户利益的原则性决策机制，成为了主要挑战。
### Innovation
本文提出了一种名为Game-Theoretic Alignment (GTAlign)的对齐框架，它将博弈论决策整合到推理和训练过程中。在推理过程中，模型显式地将用户-LLM 交互视为一种战略游戏，并在其推理链中构建收益矩阵来估计自身和用户的福利，最终选择对双方都有利的行动。在训练过程中，引入了一种互惠奖励机制，以增强合作性反应，并使模型行为与社会高效的成果相一致。此外，还引入了一种推理技术，该技术利用博弈论推理动态调整LLM 的响应，以适应LLM 服务定价策略的变化。实验结果表明，与 baselines 相比，GTAlign 在多种任务上显著提高了推理效率、答案质量和互惠福利。
### Conclusion
通过在算法推理和训练过程中引入博弈论决策，GTAlign 显著提升了LLM 的效率、答案质量和互惠福利。该研究为改进大型语言模型的行为，提供了一个有效的解决方案，帮助在给定奖励最大化的同时也最大化用户体验。实验结果充分证明了GTAlign 方法的有效性，并说明了其潜在广泛应用的潜力。
## 877. `cs.LG` - PHyCLIP: $?ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning [PDF](https://arxiv.org/pdf/2510.08919), [HTML](https://arxiv.org/abs/2510.08919)
### Authors
Daiki Yoshikawa,Takashi Matsubara
### Background
视觉-语言模型在大规模视觉场景和语言描述配对的多模态表示学习方面取得了显著成效。然而，它们在同时表达概念家族内的层次结构（例如，狗 $?preceq$ 哺乳动物 $?preceq$ 生物）和不同概念家族间的组合性（例如，“车里的狗” $?preceq$ 狗、车）方面仍然存在困难。尽管最近的工作通过使用双曲空间来应对这一挑战，其能够有效捕捉树状层次结构，但其在表示组合性的能力上仍存在疑问。
### Innovation
该研究提出了PHyCLIP，它使用卡方乘积中的$?ell_1$-Product度量在双曲因素的笛卡尔积上。这种设计使得各自家族内的层次结构在单独的双曲因素中表现出来，而跨家族的组合性则由$?ell_1$-产品度量捕捉，类似于布尔代数。实验数据表明，PHyCLIP在零样本分类、检索、层次分类和组合理解任务上优于现有的一维空间方法，并提供了更可解释的嵌入空间结构。
### Conclusion
PHyCLIP通过引入$?ell_1$-Product度量聚合双曲因素，在视觉-语言表示学习中有效地统合了概念家族内的层次结构和不同概念家族间的组合性，且在多种任务上的表现优于现有方法。
## 878. `cs.LG` - 带有重尾先验的镜像流匹配在凸域生成建模中的应用 [PDF](https://arxiv.org/pdf/2510.08929), [HTML](https://arxiv.org/abs/2510.08929)
### Authors
Yunrui Guan,Krishnakumar Balasubramanian,Shiqian Ma
### Background
该研究探讨了在凸域上使用流匹配和镜像映射进行生成模型建模的问题，并识别了两个关键挑战：一是标准对数障碍镜像映射会导致双分布重尾，引发不现实的动力学；二是与高斯先验的结合在匹配重尾目标时表现不佳。
### Innovation
为了应对这些挑战，该研究提出了一种基于正则化镜像映射的镜像流匹配方法，该方法控制了对偶尾行为并保证有界矩。此外，该方法还与重尾目标匹配，采用Student-$t$先验以稳定训练。该研究还提供了理论保证，包括空间Lipschitz性和时间正则性，以及在使用Student-$t$先验进行流匹配时的速度场收敛率和原始空间保证下的约束生成结果。在实验中，该方法在合成凸域仿真实验中优于基线方法，并在现实世界的约束生成任务中获得了竞争力的样本质量。
### Conclusion
该研究提供了一种新的生成建模方法，以解决凸域生成模型中存在的两个核心挑战，并验证了该方法在理论和实验上都优于现有方法。
## 879. `cs.LG` - RADAR：检测LLM评估中数据污染的机制途径 [PDF](https://arxiv.org/pdf/2510.08931), [HTML](https://arxiv.org/abs/2510.08931)
### Authors
Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad
### Background
数据污染对可靠的大规模语言模型（LLM）评估构成了重大挑战，模型可能通过记忆训练数据而非展示真实的推理能力来达到高性能。传统的表面级评估指标不能有效地区分模型是通过记忆还是通过推理来进行响应的。因此，需要引入一种新的框架来检测模型响应中的记忆成分和推理成分，以提高评估的可靠性。
### Innovation
引入了一个名为RADAR（Recall vs. Reasoning Detection through Activation Representation）的新颖框架，该框架通过区分基于回忆的和基于推理的模型响应来检测数据污染，采用机械解释性方法提取包括注意特化、电路动态和激活流模式在内的37个特征，目标是提高LLM评估的可靠性，超越传统的表面级指标。RADAR在一系列评估任务上达到了93%的准确率，对清晰案例实现完美性能，对具有挑战性的模糊案例也取得了76.7%的准确率。
### Conclusion
这项研究展示了机械解释性在推进LLM评估中的潜力，可以提高LLM评估的深度和可靠性，不再局限于传统的表面级评估指标。
## 880. `cs.LG` - 使用高斯-赛德尔投影进行物理上合理的生物分子相互作用建模 [PDF](https://arxiv.org/pdf/2510.08946), [HTML](https://arxiv.org/abs/2510.08946)
### Authors
Siyuan Chen,Minghao Guo,Caoliwen Wang,Anka He Chen,Yikun Zhang,Jingjing Chai,Yin Yang,Wojciech Matusik,Peter Yichen Chen
### Background
生物分子相互作用模型在基础模型的推动下取得了显著进展，然而，它们往往会产生违反基本空间可行性的全原子结构。本文探讨了在训练和推断过程中设置物理可行性作为严格约束的方法，通过集成模块来解决这一限制。该模块的核心是可微投影，该投影将扩散模型的临时原子坐标映射到最近的物理上可行的配置。这种方法利用约束的局部性和稀疏性，确保大规模计算时的稳定和快速收敛。该模块无缝集成到现有的端到端微调框架中，只需两步去噪步骤即可生成同时具有物理可行性和结构准确性的生物分子复合物。
### Innovation
提出了一个结合高斯-赛德尔方案的不同可微投影模块，该模块能够将临时原子坐标映射到最近的物理上可行配置，通过这种方式，可以在保证结构准确性的前提下实现模型训练和推断的速度大幅提升。两步去噪步骤就足够生成物理上可行且结构准确的生物分子复合物，与现行的200步扩散基线相比，速度提高了约10倍，同时保持相同的结构准确性，同时保证了模型的物理可行性。
### Conclusion
通过高斯-赛德尔投影模块，本文提出的两步模型与现行先进的200步扩散基线在结构准确性上相同，但速度几乎快10倍，而且能够保证生成的生物分子复合物的物理可行性。
## 881. `cs.LG` - 不可色彩化示例：通过感知意识调色限制扰动预防未经授权的AI色彩化 [PDF](https://arxiv.org/pdf/2510.08979), [HTML](https://arxiv.org/abs/2510.08979)
### Authors
Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen
### Background
基于AI的颜色化在生成逼真的彩色图像方面展现了卓越的能力，但这也带来了版权侵权的风险，如未经授权的颜色化和二次销售单色漫画和电影作品。尽管存在这些问题，目前尚无有效方法来防止此类滥用。
### Innovation
提出了第一个防御性范式——不可色彩化示例，通过嵌入不可感知的扰动到灰度图像中，使未经授权的颜色化无效。该方法通过使用拉普拉斯滤波器优化不可感知的扰动，同时保留感知质量，以及在优化过程中应用多种输入变换以增强跨模型的迁移性和抗常用后处理（如压缩）的鲁棒性，以满足有效、不可感知、迁移性、鲁棒性的四个标准。
### Conclusion
研究表明，PAChroma 方法能够在保持视觉外观的同时有效降低颜色化质量，标志着在保护视觉内容免受非法AI颜色化方面迈出的重要一步，为生成媒体的版权意识防御铺平了道路。
## 882. `cs.LG` - 去噪扩散用于对象聚焦图像增强 [PDF](https://arxiv.org/pdf/2510.08955), [HTML](https://arxiv.org/abs/2510.08955)
### Authors
Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar
### Background
现代农业运营越来越多地依赖于综合监测系统，该系统结合了多种数据源以优化农场效率。基于无人机的动物健康监测是关键部分，但面临数据可用性有限的问题，尤其是由于动物场景的特定问题，如动物小、被遮挡或部分可见。转移学习的方法由于缺乏反映特定农场条件下动物品种、环境和行为差异的大数据集而无法解决这个问题。因此，需要为这些问题专门设计一种以动物为中心的数据增强策略。这项工作提出了一个专门针对动物健康监测的物体定向数据增强框架，在数据受限的情况下进行动物分割，并通过转换和基于扩散的合成生成现实且多样的图像场景，以提高动物检测和监测性能。初步实验表明，增强数据集在动物检测任务中相比基础模型表现更优，通过生成特定领域的数据，本方法能够在数据稀缺的情况下增强实时动物健康监测解决方案，弥合数据稀缺与实际应用之间的差距。
### Innovation
提出了一种专门针对动物健康监测的物体定向数据增强框架，通过物体分割和基于转换与扩散的图像合成生成现实多样的图像场景，提高动物检测和监测性能。这种方法能够解决在数据受限条件下动物健康监测的技术难题，实现基于特定领域数据的实时应用。
### Conclusion
通过生成特定领域数据，本文方法能够在数据稀缺的情况下增强实时动物健康监测解决方案，从而弥合数据稀缺与实际应用之间的差距。初步实验证明，与基础模型相比，增强后的数据集在动物检测任务中表现更优。
## 883. `cs.LG` - 使用标识符替换实现成本效益高的LLM长代码翻译 [PDF](https://arxiv.org/pdf/2510.09045), [HTML](https://arxiv.org/abs/2510.09045)
### Authors
Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta
### Background
在软件开发领域，LLM已被用于自动化诸如代码翻译等任务，即将一种编程语言的源代码翻译成另一种语言并保持其功能完整性。然而，LLM在处理长源代码时常受到上下文窗口限制，导致译码不准确。
### Innovation
我们提出了一种新的零样本代码翻译方法，该方法结合了标识符替换。通过在翻译过程中用通用占位符替换用户提供的长标识符，我们的方法使LLM能够聚焦于代码的逻辑结构，通过减少令牌数量和内存使用，提高了长代码翻译的效率和成本效益。
### Conclusion
我们的实验结果显示，我们的方法保留了语法和层次信息，并生成了减少TOKEN数量的翻译结果。
## 884. `cs.LG` - 自动分级数学竞赛证明的RefGrader：基于代理工作流程的自动评分 [PDF](https://arxiv.org/pdf/2510.09021), [HTML](https://arxiv.org/abs/2510.09021)
### Authors
Hamed Mahdavi(1),Pouria Mahdavinia(1),Samira Malek(1),Pegah Mohammadipour(1),Alireza Hashemi(2),Majid Daliri(3),Alireza Farhadi(4),Amir Khasahmadi(5),Niloofar Mireshghallah(6),Vasant Honavar(1) ((1) Pennsylvania State University, (2) City University of New York, (3) New York University, (4) Amirkabir University of Technology, (5) Autodesk, (6) Carnegie Mellon University)
### Background
最新的大规模语言模型（SOTA LLMs）从难以解决奥林匹克证明问题，现已能够解决2025年国际数学奥林匹克（IMO）大部分问题，部分领先系统甚至处理了6个问题中的5个。基于这一进展，本文评估这些模型如何评估证明：检测错误、判断错误严重性以及分配公平分数。通过使用90个Gemini 2.5生成的解决方案评分和详细错误注释，以及IMO/USAMO 2025的MathArena解决方案集评分，研究了模型的证明分析能力。结果显示模型可以可靠地标记错误（包括细微错误）的解决方案，但在部分评分方面存在校准差距。为解决这一问题，引入了代理工作流程来提取和分析参考解决方案，并根据问题自动生成评分标准，用于多步骤评分过程。
### Innovation
提出了基于代理工作流程的自动化评分方法（RefGrader），该方法不仅能够检测错误，还能自动为多步评分过程中的问题生成具体的评分标准，更好地处理部分评分。通过实验证明，相对于传统方法，该工作流程具有更高的评分一致性，并且在不同数据集上的表现更为稳定。同时，还提供了代码、数据和提示日志以支持未来的研究工作。
### Conclusion
代理工作流程使得模型能够更准确和一致地进行评分，特别是在处理部分评分时。通过这一方法，可以解决现有模型在评估证明中的校准差距，提高了自动评分系统的准确性和一致性。此外，提供的数据集和工具将有助于未来相关研究的发展。
## 885. `cs.LG` - MAKO: 基于元适应Koopman算子的参数不确定非线性系统的模型预测控制学习方法 [PDF](https://arxiv.org/pdf/2510.09042), [HTML](https://arxiv.org/abs/2510.09042)
### Authors
Minghao Han,Kiwan Wong,Adrian Wing-Keung Law,Xunyuan Yin
### Background
本文提出了一种基于元学习的Koopman建模和预测控制方法，适用于具有参数不确定性的非线性系统。背景在于，在没有任何参数不确定性知识的情况下，通过多模态数据集学习一个元模型，并能够通过在线数据有效适应具有之前未见参数设置的新系统。使用所学的元Koopman模型开发了一种预测控制方案，即使在存在之前未见参数设置的情况下也能确保闭环系统的稳定性。
### Innovation
提出了一个自适应深度元学习基的建模方法，称为Meta Adaptive Koopman Operator（MAKO）。这种方法能够在没有参数不确定知识的情况下，从多模态数据集中学习一个元模型，并能够高效适应新系统中的之前未见参数设置。基于所学的元Koopman模型，开发了一种预测控制方案，即使存在之前未见参数设置也能确保闭环系统的稳定性。该方法在建模精度和控制效果上都优于竞争性的基线方法。
### Conclusion
通过广泛的仿真实验，证明了所提出的方法在建模精度和控制效果上都优于竞争性基线方法。
## 886. `cs.LG` - 在不完美标签下的单域泛化lidar语义分割探索 [PDF](https://arxiv.org/pdf/2510.09035), [HTML](https://arxiv.org/abs/2510.09035)
### Authors
Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen
### Background
准确感知对于车辆安全至关重要，LIDAR成为自主驾驶的关键使能器。为了确保在不同环境、传感器类型和天气条件下的稳健性能，无需昂贵的重新标注，LIDAR基于3D语义分割领域的泛化至关重要。然而，由于传感器缺陷、遮挡和人为错误，LIDAR标注往往存在噪声，这些噪声会降低分割准确性，并在领域变换时进一步放大，威胁系统的可靠性。虽然图像中的嘈杂标签学习已有广泛研究，但将其扩展到具有稀疏不规则结构的3D LiDAR分割下的泛化领域仍是一个未被探索的问题。
### Innovation
引入了新任务——在噪声标签下的LIDAR语义分割领域的单域泛化（DGLSS-NL），并建立了第一个基准。通过将三种代表性图像分类中的嘈杂标签学习策略适应到3D分割。但我们发现现有的嘈杂标签学习方法无法很好地适应LIDAR数据。提出了DuNe，一种带有强分支和弱分支的双视图框架，通过特征级别一致性约束和基于预测置信度过滤的交叉熵损失，实现噪声下单域泛化的性能优化。
### Conclusion
我们的方法在SemanticKITTI、nuScenes和SemanticPOSS的数据集上分别实现了56.86%、42.28%和52.58%的mIoU（在10%对称标签噪声下），总体算术平均（AM）为49.57%和调和平均（HM）为48.50%，展示了在DGLSS-NL任务中强大的单域泛化性能。代码可在项目页面上获取。
## 887. `cs.LG` - MMAudioSep: 通过预训练视频到音频生成模型向视频/文本查询音源分离的方向驯服 [PDF](https://arxiv.org/pdf/2510.09065), [HTML](https://arxiv.org/abs/2510.09065)
### Authors
Akira Takahashi,Shusuke Takahashi,Yuki Mitsufuji
### Background
该研究旨在开发一种能够在视频或文本查询下分离音频的生成模型。背景在于现有的音频分离模型通常需要从头开始训练，而这种模型通过利用预训练的视频到音频生成模型中学习到的音视频关系知识，可以更高效地进行训练，减少训练成本。
### Innovation
该研究的创新点在于提出了一种名为MMAudioSep的生成模型，该模型基于一个预训练的视频到音频模型。通过利用预训练音频生成模型中学习到的音视频相互作用知识，MMAudioSep能够在不从头训练的情况下进行更高效的训练。此外，即使经过微调后获得了语音分离的功能，模型仍然保留了原始的视频到音频生成能力，展示了基础的音生成模型在音相关的下游任务中的潜力。
### Conclusion
实验表明，MMAudioSep在与现有分离模型（包括确定性和生成性方法）的比较中表现更优，并能保留其音视频生成的能力。研究结果强调了基础音频生成模型在处理音相关任务时的潜在应用价值。
## 888. `cs.LG` - 自适应连续记忆供GUI代理使用 [PDF](https://arxiv.org/pdf/2510.09038), [HTML](https://arxiv.org/abs/2510.09038)
### Authors
Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang
### Background
本文探讨如何赋予图形用户界面（GUI）代理可扩展的存记忆能力，帮助其在不熟悉的操作界面和长远任务中泛化。之前的GUI代理将过往轨迹压缩为文本标记，这不仅增加了背景信息的长度，还错过了关键的视觉线索（例如精确的操作区域大小和位置）。
### Innovation
本文提出了一种连续记忆方法，该方法使用视觉语言模型（VLM）直接将每个GUI轨迹编码为固定长度的连续嵌入序列，从而直接插接到主干网络的输入层，减少了背景信息的成本同时保留了细致的视觉信息。内存大小和检索深度增加时，性能会单调提高，而使用文本记忆的方式在长提示下会性能下降。通过引入自适应连续数据飞轮，该方法能够在低成本地扩展记忆，执行包括发现新环境、合成任务、收购轨迹和验证成功的系列操作。
### Conclusion
使用此管线，收集了超过10万条轨迹，并仅使用少部分样本（1,500个）对内存编码器（即Q-Former的LoRA）进行了微调。在现实世界的GUI基准测试中，增强记忆的代理在长时间和分布漂移下持续提高了成功率。特别地，使用连续记忆增强的Qwen-2.5-VL-7B与最先进的闭源模型（例如GPT-4o，Claude-4）具有相似的表现。
## 889. `cs.LG` - 情绪解耦嵌入对齐：用于抗噪及跨语料库语音情绪识别的方法 [PDF](https://arxiv.org/pdf/2510.09072), [HTML](https://arxiv.org/abs/2510.09072)
### Authors
Upasana Tiwari,Rupayan Chakraborty,Sunil Kumar Kopparapu
### Background
在实际场景中，语音情绪识别的效果往往受到噪声环境和数据集间变异性的影响。现有方法难以在这些条件下保持鲁棒性和泛化能力。
### Innovation
提出了一种两步方法，通过改进表示学习来增强语音情绪识别模型的鲁棒性和泛化能力。首先使用EDRL（情绪解耦表示学习）从语音数据中提取特定类别的情绪鉴别特征，同时保持不同情绪类别间的共享相似性。其次使用MEA（多块嵌入对齐）进一步优化这些表示，将它们投影到一个与原始语音输入具有最大协方差的联合鉴别潜在子空间中。使用这种方法学习到的EDRL-MEA嵌入在公开数据集的干净样本上训练情绪分类器，并在无法预测的噪声和跨语料库语音样本上进行评估。
### Conclusion
在这些具有挑战性的条件下取得的改进性能证实了提出的方案的有效性。
## 890. `cs.LG` - Alif: 通过多语言合成数据精馏推进乌尔都大型语言模型 [PDF](https://arxiv.org/pdf/2510.09051), [HTML](https://arxiv.org/abs/2510.09051)
### Authors
Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq
### Background
开发针对低资源语言如乌尔都语的高性能大型语言模型（LLMs）面临诸多挑战，包括高质量数据稀缺、多语言一致性问题和安全问题。现有方法通常通过翻译大量可用数据来解决这些问题，但这些翻译往往缺乏质量与文化内涵，且导致数据管理和训练成本高昂。这些挑战促使研究者提出Alif-1.0-8B-Instruct这一创新解决方案。
### Innovation
引入了一种新的方法，即多语言合成数据精馏技术，允许训练基于修改后的自指令技术开发的多语言乌尔都语-英语模型。通过使用针对每个任务的独特提示和种子值，以及全球任务池，该方法促进了乌尔都语本土推理链、双语翻译、文化相关性和伦理安全性的融合，极大地提升了Alif-1.0-8B-Instruct模型在特定乌尔都语任务上的理解能力。尽管在训练预算上低于100美元，该模型在乌尔都语特定任务上的表现优于包括Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct和Cohere-Aya-Expanse-8B在内的众多领先多语言LLMs。
### Conclusion
研究表明，通过我们修改后的自指令方法，可以高效、文化针对性地开发高性能和低资源语言LLMs。该研究还提供了数据集、模型和代码的公开访问路径，促进了领域的进一步进展。
## 891. `cs.LG` - 当机器人能力优于人类：学习受限演示者 [PDF](https://arxiv.org/pdf/2510.09096), [HTML](https://arxiv.org/abs/2510.09096)
### Authors
Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık
### Background
目前，通过示教学习、操纵杆控制和模拟到现实的转移等接口，专家可以教机器人执行复杂的任务。然而，这些接口往往限制了专家演示最佳行为的能力，由于间接控制、设置限制和硬件安全因素。例如，操纵杆只能使机械臂在2D平面上移动，而机器人实际上处于更高维度的空间中。这些限制导致由受限专家示教收集的演示数据，会使学习到的策略效果不佳。因此，本文提出的关键问题是：机器人能否学习比受限专家示教更好的策略？
### Innovation
本文通过允许智能体超越直接模仿专家动作，探索更短和更高效的径路来解决这个问题。作者使用示教数据推断出仅基于状态的奖励信号，以测量任务进度，并使用时间内插为未知状态进行自我标签奖励。该方法在样本效率和任务完成时间上优于常见的模仿学习方法。在实际的WidowX机械臂上，该方法仅需12秒便完成任务，比行为克隆快10倍，具体结果已在实机视频中展示。
### Conclusion
本文提出了一种新的方法，允许机器人从受限专家的示教中学习更优策略，该方法在样本效率和任务完成时间方面表现优于传统方法。在实际实验中，该方法显著提高了任务完成速度。
## 892. `cs.LG` - MCMC: 连接渲染、优化和生成AI [PDF](https://arxiv.org/pdf/2510.09078), [HTML](https://arxiv.org/abs/2510.09078)
### Authors
Gurprit Singh,Wenzel Jakob
### Background
过去两年，生成式人工智能（AI）在视觉语言模型方面取得了前所未有的进展。在生成过程中，新的样本（图像）是从一个未知的高维分布中生成的。马尔科夫链蒙特卡洛（MCMC）方法特别适合从这样的复杂高维分布中抽样。MCMC 方法是确保生成准确样本的组成部分，特别是在对比条件随机场（EBMs）等模型中。梯度优化是现代生成模型的核心，优化过程中的更新步骤形成一个在当前状态仅依赖于下一状态的马尔科夫链，这允许以无记忆的方式探索参数空间，从而结合了梯度优化和MCMC抽样带来的好处。在基于物理的渲染中，MCMC 方法已被证明同样重要，因为复杂的光线路径使用简单的概率抽样方法是非常具有挑战性的。
### Innovation
本课程旨在统一各种技巧，特别是 MCMC 方法，以数据驱动的方式提高基于扩散生成模型的物理现实感样本（图像）的质量。同时，课程还探索如何使用 MCMC 作为桥梁，连接这些密切相关的研究领域，并为学生、研究人员和从业者提供必要的理论和实践工具，以共同实现生成基于物理的渲染目标。
### Conclusion
课程旨在通过MCMC方法的使用，为生成基于物理的渲染提供一种统一的方法，并帮助学生、研究人员和从业者理解 MCMC 如何帮助连接这些相关领域的研究。所有演示相关的 Jupyter 笔记本都可以在项目网页上找到。
## 893. `cs.LG` - PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning [PDF](https://arxiv.org/pdf/2510.09133), [HTML](https://arxiv.org/abs/2510.09133)
### Authors
Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An
### Background
大型推理模型（LRMs）在复杂问题解决任务中取得了显著进展，但在部署过程中通常面临高计算成本的问题，强调了高效的推理需求。一种提高效率的方法是动态地在思考模式和非思考模式之间切换LRMs，但这种方法可能会引入额外的推理错误，并且缺乏对性能下降的统计保证，这对于高风险应用来说至关重要。
### Innovation
本文提出了一种可能近似正确的（PAC）推理方法，可以在用户指定的性能损失容差下控制性能损失。通过构建性能损失的上置信界，该方法将其表述为不确定性得分的单调函数，并确定切换到非思考模式的阈值。理论上，使用阈值在非参数方式下确保了性能损失的有界性。实验证明，该方法在推理基准测试上可以节省计算预算并控制用户指定的性能损失。
### Conclusion
本文提出的PAC推理方法能够有效控制性能损失并节省计算资源，在复杂问题解决任务中实现了高效的推理过程。
## 894. `cs.LG` - Vision模型的训练特征归因 [PDF](https://arxiv.org/pdf/2510.09135), [HTML](https://arxiv.org/abs/2510.09135)
### Authors
Aziz Bacha,Thomas George
### Background
深度神经网络通常被视为不透明的系统，需要解释性方法来提高信任度和责任感。现有的方法通常将测试时的预测归因于输入特征（例如图像中的像素）或影响性的训练样例。但现有方法主要关注其中一个方面，没有结合考虑。
### Innovation
本文探讨了训练特征归因，它将测试预测与特定训练图像的特定区域联系起来，从而提供了关于深度模型内部工作机制的新见解。实验表明，训练特征归因提供了详细的、针对测试的具体解释，能够识别导致错误分类的有害示例并揭示传统的归因方法无法揭示的伪相关关系，例如基于块的捷径。
### Conclusion
实验结果证明，训练特征归因提供了一种新的方法，能够更精细地解释测试预测的来源，并洞悉网络内部的运作机制，特别是识别出可能导致错误分类的关键训练样本。
## 895. `cs.LG` - 一种用于CT扫描中识别细微病理特征的新型多分支ConvNeXt架构 [PDF](https://arxiv.org/pdf/2510.09107), [HTML](https://arxiv.org/abs/2510.09107)
### Authors
Irash Perera(1),Uthayasanker Thayasivam(1) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka)
### Background
智能分析医学影像在辅助临床诊断中扮演着至关重要的角色，特别是在识别细微的病理特征方面。本文介绍了一种专门针对医学影像分析中细微挑战的新型多分支ConvNeXt架构。
### Innovation
本文提出了一种创新的多分支ConvNeXt架构，该架构结合了全局平均池化、全局最大池化以及新的注意力加权池化机制。模型采用严格的端到端管道，包括细致的数据预处理和增强、两阶段的训练策略，并有效利用了迁移学习。该方法适用于从CT扫描中广泛分类多种病理学问题，并在COVID-19诊断中得到应用。实验结果表明，该模型在验证集中表现出色，最终AUC-ROC为0.9937，验证准确率为0.9757，F1分数为0.9825，优于该数据集上之前所有报告的模型。
### Conclusion
研究表明，现代多分支架构与精细的数据管理相结合，能够实现与或超越现有最先进的模型的性能，从而证明了先进深度学习技术在稳健医学诊断中的有效性。
## 896. `cs.LG` - 隐私保护协作平台：用于癌症免疫治疗的联邦数据分析 [PDF](https://arxiv.org/pdf/2510.09155), [HTML](https://arxiv.org/abs/2510.09155)
### Authors
Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal
### Background
连接健康是一种多学科方法，旨在健康管理和患者护理中的工具、服务和治疗的创建中优先考虑患者需求。这种范式通过促进所有护理连续体各方之间及时准确的患者信息交流，确保了主动且高效的护理。随着数字技术的进步和流程创新，通过整合各种健康数据源来提高连接健康的潜力，特别是在个性化护理、预测健康结果和优化患者管理方面。然而，数据架构、应用程序互操作性和安全性等方面仍存在挑战。
### Innovation
本文通过一个欧盟资助的项目，探索如何利用敏捷系统开发生命周期开发一个集成AI生成的解决方案，以应对正在进行免疫治疗的癌症患者的护理管理问题。该论文的创新之处在于提供了一个协作数字框架，整合了护理连续体中的所有利益相关者，利用联邦大数据分析和人工智能来提高决策质量，同时确保隐私。通过实际数据验证了分析能力，例如治疗建议和不良事件预测，实现了70%-90%的准确率。
### Conclusion
该框架在试点研究中表现出有效性，通过实际数据验证了其分析能力，如治疗建议和不良事件预测，并达到了70%-90%的准确性，证明了框架的有效性。
## 897. `cs.LG` - 神经网络的分布鲁棒逼近性质 [PDF](https://arxiv.org/pdf/2510.09177), [HTML](https://arxiv.org/abs/2510.09177)
### Authors
Mihriban Ceylan,David J. Prömel
### Background
本文研究了几类神经网络的普遍逼近性质，特别是在弱收敛测度族的均匀性方面取得了成果。现有文献中，经典普遍逼近定理主要集中在$L^p$空间上。本文扩展了这一理论，证明这些神经网络在Orlicz空间中是稠密的，从而涵盖了一些广泛使用的网络架构，如非多项式激活函数下的前馈神经网络、使用ReLU激活函数的深层窄网络和功能输入神经网络。
### Innovation
本文证明了这些神经网络在Orlicz空间中是稠密的，从而扩展了经典普遍逼近定理的应用范围，甚至超越了传统的$L^p$空间。所涵盖的神经网络类别包括用于前馈网络的非多项式激活函数、具有ReLU激活函数的深层窄网络和具有函数输入的神经网络。
### Conclusion
本文建立了几类神经网络在弱连贯测度族中的均匀普遍逼近性质，证明这些网络在Orlicz空间中是稠密的，进一步扩展了经典普遍逼近定理的应用。
## 898. `cs.LG` - 可证明的标记方案对抗数据污染攻击 [PDF](https://arxiv.org/pdf/2510.09210), [HTML](https://arxiv.org/abs/2510.09210)
### Authors
Yifan Zhu,Lijia Yu,Xiao-Shan Gao
### Background
近年来，数据污染攻击正被设计得越来越难察觉且甚至对系统有益，通常的目的是验证数据集的所有权或保护私人数据不受未授权使用。但这些发展有可能导致误解和冲突，在此之前，数据污染被视为对机器学习系统的一种安全威胁。为了应对这一问题，无害数据污染生成器需要声明其生成数据集的所有权，以使用户能够识别潜在的污染以防止滥用。
### Innovation
为了解决这个问题，我们提出部署标记方案作为解决方案。本文介绍了两种可证明且实用的数据污染标记方法：后污染标记和同时污染标记。分析表明，在适当的水印长度下，这两种方法都能保证标记的发现和污染的具体用途，证明了在数据污染攻击下标记的实用性。
### Conclusion
实验结果验证了我们的理论发现，适用于多种攻击、模型和数据集，证明了在数据污染攻击下，标记方案的有效性和实用性。
## 899. `cs.LG` - 增强数据与神经网络在疫情预测中的稳健应用：以意大利新冠疫情为例 [PDF](https://arxiv.org/pdf/2510.09192), [HTML](https://arxiv.org/abs/2510.09192)
### Authors
Giacomo Dimarco,Federica Ferrarese,Lorenzo Pareschi
### Background
本文提出了一种数据增强策略，旨在提升神经网络的训练阶段性能，进而提高其预测准确性。研究聚焦于两种神经网络架构：物理感知神经网络（PINNs）和非线性自回归（NAR）模型。NAR方法特别适用于短期预测，能够通过对数据直接学习动力学特性，提供准确的定量估计，同时避免了将物理约束嵌入训练中的额外计算成本。相比之下，PINNs在定量预测上不够准确，但能够捕捉系统的长期行为特征，更适合研究广泛的动力学趋势。该研究通过模拟意大利伦巴第地区新冠疫情的第二阶段，验证了所提出方法的有效性。
### Innovation
作者提出了一种通过生成合成数据来增强原始数据集的方法，该方法结合了适当隔室模型和不确定性整合，并将其与深度学习技术相结合，以产生额外的合成数据用于训练。这种方法不仅提升了神经网络的预测性能，还在新冠疫情的短期预测中展示了其特有的效果。两种不同架构的神经网络（PINNs和NAR）的应用进一步突显了该方法的灵活性和有效性。
### Conclusion
通过增强数据的方法显著提升了神经网络在预测中的表现，特别是在短期新冠疫情预测方面。两种神经网络架构各有优势，但在不同应用场景中表现不一，为未来疫情防控提供了新的工具。
## 900. `cs.LG` - IRIS：在缺乏表格数据情况下的可验证因果发现迭代综合框架 [PDF](https://arxiv.org/pdf/2510.09217), [HTML](https://arxiv.org/abs/2510.09217)
### Authors
Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari
### Background
因果发现是科学研究的基础，但传统统计算法面临着显著挑战，包括昂贵的数据收集成本、对已知关系处理时的冗余计算，以及不切实际的假设。尽管基于大语言模型（LLM）的最近方法在识别已知的因果关系方面表现出色，但它们无法发现新的因果关系。
### Innovation
我们引入了IRIS（迭代检索和集成系统，集成了实时因果发现），这是一种创新框架，能够解决这些限制。IRIS从一组初始变量开始，自动收集相关文档、提取变量并发现因果关系。我们的混合因果发现方法结合了统计算法和基于大语言模型的方法，用于发现已知和新的因果关系。此外，IRIS通过识别和纳入缺失变量，扩展因果图，使其能够仅从一组初始变量进行实时因果发现，而不需要预先存在的数据集。
### Conclusion
我们的方法使人们能够在没有预先存在的数据集的情况下，从仅有的初始变量集合中进行实时的因果发现。
## 901. `cs.LG` - 探究理性扩张小波变换对基于深度学习模型的运动想象脑电图解码影响 [PDF](https://arxiv.org/pdf/2510.09242), [HTML](https://arxiv.org/abs/2510.09242)
### Authors
Marco Siino,Giuseppe Bonomo,Rosario Sorbello,Ilenia Tinnirello
### Background
研究探讨了理性离散小波变换（RDWT）作为运动想象脑电图（EEG）解码前的预处理步骤，使用插件进行处理，再结合深度学习分类器的效果。本研究在四种先进的深度学习架构（EEGNet、ShallowConvNet、MBEEG_SENet、EEGTCNet）上进行了系统性对比分析，评估其在三个脑机接口基准数据集（High Gamma、BCI-IV-2a、BCI-IV-2b）上的表现。
### Innovation
本研究创新地将RDWT应用于运动想象EEG解码的预处理，探索其对不同深度学习架构的影响，特别是揭示了RDWT在处理非平稳会话时的优势，并通过精度和Cohen’s kappa衡量其提升效果。
### Conclusion
研究结论表明，RDWT能够提升多种深度学习模型的分类准确性，并在面对挑战性数据时表现出显著的改进，该方法是低开销、架构感知的预处理技术，能显著提高复杂病例下的模型性能和一致性。
## 902. `cs.LG` - 使用视觉语言模型的零样本图像隐私分类 [PDF](https://arxiv.org/pdf/2510.09253), [HTML](https://arxiv.org/abs/2510.09253)
### Authors
Alina Elena Baia,Alessio Xompero,Andrea Cavallaro
### Background
历史上的图像隐私预测主要依赖于专门设计的学习模型，但当前文献倾向于采用通用任务设计的大视觉-语言模型（VLMs），这可能会忽略这种专门设计的模型所设定的性能上限，由于缺乏系统的评估。
### Innovation
该研究建立了一个零样本基准来实现图像隐私分类的公平比较，评估了基于隐私基准的开源VLMs，对比任务对齐的提示，探讨其在隐私预测准确性、效率和鲁棒性方面的表现，发现尽管这些VLMs资源密集并且推理速度较慢，但在隐私预测准确性上仍落后于专门为视觉任务设计的小型模型。
### Conclusion
VLMs展示了对图像扰动的更高鲁棒性，但在隐私预测准确性上当前仍落后于专门设计的较小模型，这表明对于图像隐私预测，VLMs的有效性仍有待进一步提升。
## 903. `cs.LG` - 使用多模态大型语言模型和消费级摄像机诊断肩部疾病 [PDF](https://arxiv.org/pdf/2510.09230), [HTML](https://arxiv.org/abs/2510.09230)
### Authors
Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun
### Background
肩部疾病的频率在全球范围内较高，特别是在老年人以及从事重复性肩部任务的工作者中。在医疗资源匮乏的地区，早期且准确的诊断存在显著挑战，因此迫切需要低成本且易于扩展的辅助诊断解决方案。肩部疾病如粘连性肩囊炎的治疗需求迫切，尤其是在资源有限的地区，实现早期精确诊断面临难题。
### Innovation
研究将消费者级设备捕捉的视频作为诊断的基础，通过引入多模态大型语言模型（MLLMs）来实现初步肩部疾病诊断的创新应用。提出了一个名为Hybrid Motion Video Diagnosis框架（HMVDx），该框架将动作理解任务和疾病诊断任务分别由两个MLLMs完成。此外，还提出了一种新的评价标准——可操作性指数，该指数从整个医学诊断路径的角度评估MLLMs在医学领域的有效性，揭示了低成本MLLMs在医疗应用中的潜在价值。与直接视频诊断相比，HMVDx在诊断肩关节损伤方面的准确性提高了79.6%，这为未来MLLMs在医疗领域视频理解的应用研究提供了重要技术贡献。
### Conclusion
研究通过引入Hybrid Motion Video Diagnosis框架（HMVDx），利用消费者级摄像机和多模态大型语言模型的应用，显著提高了肩部疾病早期诊断的准确性。提出的可操作性指数为医学领域中MLLMs的应用提供了新的评价视角，展示了其在临床实践中的潜在价值。
## 904. `cs.LG` - 通过不确定性建模和众包测量表征5G用户吞吐量 [PDF](https://arxiv.org/pdf/2510.09239), [HTML](https://arxiv.org/abs/2510.09239)
### Authors
Javier Albert-Smet,Zoraida Frias,Luis Mendo,Sergio Melones,Eduardo Yraola
### Background
随着5G无线接入网络（RAN）能力的提高，连接瓶颈开始向网络的更深层次移动，使得在应用层度量用户吞吐量变得更加具有挑战性。传统的测量方法如汽车测试和运营商设备计数器成本高、限制多或无法准确捕获端到端（E2E）的服务质量（QoS）及其变异。因此，需要一种新的方法来准确估算用户的下行吞吐量，并更好地理解各种因素的变化对用户吞吐量的影响。
### Innovation
本文提出了一种基于大规模众包测量的方法，提出了一种不确定性感知和可解释的方法来估计下行用户吞吐量。该方法包括针对5G NSA和5G SA验证先前的4G方法，这是首次使用NGBoost模型输出点估计和校准置信区间来处理吞吐量的变异性。另外，该方法还分析了从4G到5G SA的吞吐量变化情况，并表明从RAN到传输层和服务层，吞吐量瓶颈正逐步转移，E2E指标的重要性逐渐增加，同时减少与无线电相关的特征的重要性。这是首次使用NGBoost模型应用于计算机通信领域，为5G的众包数据集提供了基准。
### Conclusion
本文通过验证先前的方法并引入NGBoost模型来改进5G用户的下行吞吐量估算，展示了端到端指标的重要性增加和无线电相关特征的重要性减少的趋势，并提供了更深入的理解对于评估5G网络性能至关重要。
## 905. `cs.LG` - 检测大规模语言模型强化学习训练后数据污染 [PDF](https://arxiv.org/pdf/2510.09259), [HTML](https://arxiv.org/abs/2510.09259)
### Authors
Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li
### Background
大规模语言模型（LLMs）的可靠评估受到数据污染的严重威胁。当基准样本可能意外出现在训练集中时，这会损害报告性能的有效性。虽然已经开发了预训练和监督微调阶段的数据污染检测方法，但在强化学习（RL）阶段的数据污染检测上存在一个重要的研究缺口。随着RL阶段在提升LLM推理能力方面变得至关重要，缺乏专门的污染检测方法成为这一阶段的关键脆弱性。因此，有必要在RL训练后的情景下系统研究数据污染检测，并提出了一种名为Self-Critique的方法来应对这一挑战。Self-Critique通过观察到，在RL阶段后，LLMs的输出熵分布倾向于集中到特定且稀疏的模式来工作，其核心是探测潜在的策略崩溃，即模型的推理路径变得狭窄，导致熵的降低。这种方法能够在多个模型和污染任务上显著优于基线方法，AUC改进高达30%。现有方法对于RL阶段的污染检测几乎等同于随机猜测，而该方法使得污染检测成为可能。
### Innovation
首次在RL训练后的情景下系统研究数据污染检测，并提出了一种名为Self-Critique的方法。该方法通过探测模型在RL阶段后的策略崩溃，有效识别数据污染，显著提升了数据污染检测的效果。此外，还介绍了RL-MIA，一种用于模拟特定污染场景的基准。
### Conclusion
提出的方法Self-Critique在多个模型和污染任务上显著优于现有基线方法，AUC改进高达30%，展示了在RL训练后场景中检测数据污染的有效性，填补了这一领域的研究空白，为提高LLM的可靠性提供了新的视角和方法。
## 906. `cs.LG` - Placeit！一种学习机器人物体放置技能的框架 [PDF](https://arxiv.org/pdf/2510.09267), [HTML](https://arxiv.org/abs/2510.09267)
### Authors
Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux
### Background
机器人研究在学习方面取得了显著进展，但仍面临着掌握基本技能如物体放置这一 fundamental 挑战。关键瓶颈在于获取大规模高质量数据，而这通常是一个手动和繁琐的过程。研究人员尝试利用模拟生成灵巧的抓取姿态，以减轻数据收集的负担。
### Innovation
本文介绍了一个名为Placeit！的演化计算框架，用于生成刚体对象的有效放置位置。该框架支持从放置到堆叠和插入的各种任务。实验结果表明，利用质量多样性优化，Placeit！在生成多样化有效姿态时显著优于现有最先进的方法。基于该框架构建的pick&place流水线在120个实际部署中的成功率达到90%。
### Conclusion
Placeit！被定位为一种强大的工具，用于开放环境下的pick-and-place任务，同时也是一个生成训练仿真基础模型所需的高质量数据的重要引擎。
## 907. `cs.LG` - 智能驱动滑翔器重心可调的智能导航 [PDF](https://arxiv.org/pdf/2510.09250), [HTML](https://arxiv.org/abs/2510.09250)
### Authors
X. Jiang,J. Qiu,K. Gustavsson,B. Mehlig,L. Zhao
### Background
人工滑翔器设计用于在通过流体下降时分散，要求精确导航以达到目标位置。研究表明，压缩进粘性流体中的滑翔器可以通过动态调整其质心来导航。通过全分辨率直接数值模拟（DNS）和强化学习，发现两种最佳导航策略能使滑翔器准确到达目标位置。
### Innovation
创新在于通过改变滑翔器质心位置，使其在过程中动态调整导航。具体来说，当滑翔器与周围流体的相互作用发生变化时，最佳策略依赖于粒子雷诺数的变化。这种方法的发现和应用为理解如何根据不同条件下最佳策略的依赖性提供了新的视角。
### Conclusion
研究结果解释了不同条件下最佳策略为何依赖于粒子雷诺数。在大雷诺数下，滑翔器学会了快速翻滚，通过其姿态改变移动质心，产生强大的惯性水平升力，使滑翔器可以远航。而在小雷诺数下，高粘性阻碍了翻滚。此时，滑翔器学会了调整质心使其稳定倾斜下沉，从而产生水平粘性力。然而，由于大雷诺数下的惯性升力远远大于小雷诺数下的粘性力，因此水平范围要小得多。所有这些贡献的作者在研究中贡献均等。
## 908. `cs.LG` - GREAT: 通过情绪感知触发合成在RLHF中实现可移植的后门攻击 [PDF](https://arxiv.org/pdf/2510.09260), [HTML](https://arxiv.org/abs/2510.09260)
### Authors
Subrat Kishore Dutta,Yuelin Xu,Piyush Pant,Xiao Zhang
### Background
近期的研究表明，基于人类反馈的强化学习（RLHF）对后门攻击非常敏感，这些攻击通过向偏好数据中注入恶意触发器来植入恶意程序。然而，现有方法通常依赖于静态的、稀有的触发器，这在现实场景中的有效性有限。
### Innovation
本文开发了GREAT，一种新颖的方法，用于通过情绪感知触发合成在RLHF中构建通用后门。GREAT特别针对一种具有半结构化暴力请求和情绪愤怒触发器的易受攻击用户子群，开发了一种触发识别流水线，通过潜在嵌入空间和主成分分析及聚类技术来识别最具代表性的触发器。此外，我们介绍了Erinyes，一个从GPT-4中精心筛选出的大规模（超过5000个）情绪愤怒触发器数据集。
### Conclusion
实验表明，GREAT在攻击成功率上显著优于基线方法，尤其是在未见过的触发场景下，同时在无害输入上保留了较高的响应质量。
## 909. `cs.LG` - 对抗鲁棒性统一贝叶斯框架 [PDF](https://arxiv.org/pdf/2510.09288), [HTML](https://arxiv.org/abs/2510.09288)
### Authors
Pablo G. Arce,Roi Naveiro,David Ríos Insua
### Background
机器学习模型对对抗攻击的脆弱性仍然是一个关键的安全挑战。传统的防御方法，如对抗训练，通过最小化最坏情况损失来增强模型的鲁棒性，但这些确定性的方法没有考虑到对手攻击的不确定性。虽然存在将对手建模为概率分布的随机防御方法，但它们往往缺乏统计意义上的严谨性，并且不能明确表述其背后的假设。
### Innovation
作者提出了一个形式化的贝叶斯框架，通过随机通道建模对手的不确定性，明确表述所有概率假设。该框架提供了两种增强策略：一种是在训练过程中实施的前瞻性防御，与对抗训练一致；另一种是在操作过程中实施的反应性防御，与对抗净化一致。此外，多种先前的防御方法可以作为模型的极限情况被恢复。通过实证验证，作者展示了明确建模对手不确定性的好处。
### Conclusion
该方法通过引入形式化贝叶斯框架，解决了传统防御方法在处理对手不确定性时的局限性，通过实现前瞻性防御和反应性防御，提供了增强对抗鲁棒性的有效策略，并通过实验证明了这种方法的有效性。
## 910. `cs.LG` - 通过其计算图验证链式推理 [PDF](https://arxiv.org/pdf/2510.09312), [HTML](https://arxiv.org/abs/2510.09312)
### Authors
Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda
### Background
当前的链式思考（CoT）验证方法基于输出（黑盒）或激活（灰盒）来预测推理正确性，但对为什么计算失败提供了有限的见解。
### Innovation
提出了新的白盒方法——基于电路的推理验证（CRV）。通过将正确的CoT步骤的归因图作为模型潜在推理电路的执行跟踪，并利用这些图的结构特征训练分类器，展示了这些跟踪包含强大的推理错误信号。这种方法提供了其他方法无法获得的新型科学见解，包括高度预测的结构性错误特征、高度特定于领域的结构特征以及通过详细分析指导个体转换器特征干预来纠正模型的错误推理。
### Conclusion
通过仔细审查模型的计算过程，我们可以从简单的错误检测转变为对大型语言模型推理的因果理解。
## 911. `cs.LG` - 基于模型驱动工程的方法实现人工智能驱动的医疗平台 [PDF](https://arxiv.org/pdf/2510.09308), [HTML](https://arxiv.org/abs/2510.09308)
### Authors
Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi
### Background
人工智能（AI）在支持更准确的诊断和个性化治疗方面具有潜力，但其在实际应用中的采用受到数据碎片化、严格的数据隐私规定和技术上构建可靠临床系统复杂性的限制。
### Innovation
该论文提出了一个专门用于医疗AI的模型驱动工程（MDE）框架，其核心是医疗互操作性语言（MILA），一种图形化领域特定语言（DSL），它让临床医生和数据科学家能够使用共享的本体定义查询和机器学习管道。结合联邦学习架构，MILA使得机构在无需交换原始患者数据的情况下进行合作，保证了站点之间的语义一致性的同时保护了隐私。该方法在多中心癌症免疫治疗研究中进行了评估，生成的管道展示了显著的预测性能，支持向量机在关键任务中的准确率达到了98.5%和98.3%，同时大幅减少了手工编码的劳动量。这些发现表明，模型驱动工程（MDE）原理、语义集成和自动化代码生成提供了实现互操作、可重复和可信的数字健康平台的实用途径。
### Conclusion
该研究展示了如何利用MDE方法来构建支持联邦学习且保障隐私的医疗平台，从而提高医疗AI的可扩展性和可靠性，为实际应用铺平了道路。
## 912. `cs.LG` - 通过物理对象对抗视觉-语言-行动模型的具有目标导向的后门攻击 [PDF](https://arxiv.org/pdf/2510.09269), [HTML](https://arxiv.org/abs/2510.09269)
### Authors
Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang
### Background
近期视觉-语言-行动（VLA）模型的进展极大地提升了可感知AI，使机器人能够遵循自然语言指令并执行多样化任务。然而，这些模型依赖于未经筛选的训练数据集，这引发了严重的安全问题。现有的针对VLA的后门攻击主要假定有白盒访问权限，且通常导致任务失败而非执行特定动作。
### Innovation
本文揭示了更具实践性的威胁：攻击者可以通过在训练数据集中简单注入物理对象作为触发器来操控VLA。作者提出了目标导向的后门攻击（GoBA），在这种攻击下，VLA在缺乏物理触发器时表现出正常行为，但在存在物理触发器时会执行预定义的目标导向动作。基于一个流行的VLA基准LIBERO，作者引入了BadLIBERO，该基准集成了多种物理触发器和目标导向的后门动作。此外，提出了一个三级评估方法，将被害VLA在GoBA下的行为划分为三个状态：无事可做、尝试做、成功完成。实验结果表明，当存在物理触发器时，GoBA使被害VLA在97%的输入下成功实现了后门目标，而对无触发器时的清洁输入性能没有负面影响。进一步研究表明，动作轨迹和触发器颜色显著影响攻击效果，而触发器大小的影响出乎意料的小。
### Conclusion
研究结果表明，通过物理对象实现的具有目标导向的后门攻击可以根据预设的目标操控VLA的行为。评估表明，在存在物理触发器时，VLA能够以高成功率执行后门目标，而对常规任务的影响较小。此外，研究还发现了物理触发器设计的关键因素，为未来提高VLA系统安全性的策略提供了指导。
## 913. `cs.LG` - 使用响应梯度的可靠性敏感性 [PDF](https://arxiv.org/pdf/2510.09315), [HTML](https://arxiv.org/abs/2510.09315)
### Authors
Siu-Kui Au,Zi-Jun Cao
### Background
工程风险涉及故障的可能性及其发生的情景。故障概率对系统参数变化的敏感性对于风险知情决策是相关的。计算敏感性比概率本身至少要复杂一个级别，因为已经面临着大量输入随机变量、罕见事件和隐式非线性‘黑盒’响应的挑战。有限差分法结合蒙特卡洛概率估计是不准确的，需要样本数量与步长的倒数成正比增长以降低估计偏差。许多现有多项研究通过利用特定类型输入变量、敏感性参数或确切或代理形式的响应来提高效率。对于通用系统，这项工作提出了一种理论及其蒙特卡罗策略，用于通过响应值和相对于敏感性参数的梯度来计算敏感性。研究表明，给定响应阈值下的敏感性可以通过响应梯度的条件期望来表示。确定期望需要以阈值这种零概率事件为条件，但可以通过核光滑的概念来解决。该方法提供了在单一蒙特卡罗运行中生成的所有响应阈值的敏感性估计，并在多种示例中得到验证。随着响应梯度越来越可用，希望这项工作可以为在同一个蒙特卡罗运行中嵌入敏感性计算和可靠性提供基础。
### Innovation
提出了一种基于响应值和相对于敏感性参数梯度的蒙特卡罗策略来计算敏感性，并通过条件期望在给定响应阈值的情况下表达敏感性。使用核光滑的概念来解决零概率事件的问题，并且能够在一次蒙特卡罗运行中生成所有响应阈值的敏感性估计。这项工作希望可以推动敏感性计算和可靠性在同一蒙特卡罗运行中集成，提高效率和准确性。
### Conclusion
通过研究不同性质的响应参数，验证了该方法的有效性。对于通用系统，该方法提供了一种理论基础，使得敏感性计算可以在同一蒙特卡罗运行中与可靠性结合，从而提高风险决策的质量。
## 914. `cs.LG` - Speech-LLM采取一切：一种真正全面的端到端口语对话状态跟踪方法 [PDF](https://arxiv.org/pdf/2510.09424), [HTML](https://arxiv.org/abs/2510.09424)
### Authors
Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf
### Background
本文进行了一项关于端到端口语对话状态跟踪使用语音大语言模型的上下文管理策略的比较研究。研究了传统多模态上下文（结合文本历史和口头当前回合）、完整的口头对话历史以及压缩的口头对话历史方法。
### Innovation
研究展示了在SpokenWOZ语料库上的实验证明，提供完整的口语对话作为输入可以显著超越其他同类模型，表现出更高的性能。此外，基于注意力池化的口语历史压缩方法提供了有效的权衡，保持了竞争力的同时减少了上下文大小。详细分析表明，性能提升来源于更有效的上下文利用。
### Conclusion
研究发现，提供完整的口语对话作为输入在模型性能上具有显著优势。基于注意力池化的口语历史压缩方法在减少上下文尺寸的同时，仍能保持竞争力。
## 915. `cs.LG` - 将交易网络和所有权网络整合的一种多模态中小企业信贷评分方法 [PDF](https://arxiv.org/pdf/2510.09407), [HTML](https://arxiv.org/abs/2510.09407)
### Authors
Sahab Zandi,Kamesh Korangi,Juan C. Moreno-Paredes,María Óskarsdóttir,Christophe Mues,Cristián Bravo
### Background
中小企业(SMEs)在经济增长、就业和创新方面发挥着重要作用，但它们在获得信贷时经常面临重大挑战，如金融记录有限、抵押品不足以及宏观经济冲击的影响。这些挑战使得准确的信用风险评估对贷款人至关重要，尤其是中小企业经常通过共同运营的企业网络进行经营，这可能导致违约风险的传播。现有的信贷风险评估方法通常基于传统的结构化数据，对于识别和量化企业间的传染性风险有限。
### Innovation
本研究提出并测试了一种新颖的中小企业信用风险建模方法，使用大型数据集，结合图神经网络和传统的结构化数据来预测中小企业违约风险。这种方法利用了企业间的共同所有权和财务交易数据构建的多层网络信息，不仅提高了申请评分性能，还明确地建模了公司在企业间的风险传染。研究还显示了这些连接的方向性和强度如何影响金融风险的传染，提供了对企业背后的这些过程的更深入理解。实证结果表明，网络数据具有预测力，而且供应链网络使得中小企业面临相关违约风险敞口。
### Conclusion
我们的研究结果强调了网络数据的预测能力以及供应链网络对中小企业相关违约风险敞口的作用，为理解和管理企业间的传染性风险提供了新的见解。
## 916. `cs.LG` - SilvaScenes:从自然森林下木冠层图像中进行树木分割和物种分类 [PDF](https://arxiv.org/pdf/2510.09458), [HTML](https://arxiv.org/abs/2510.09458)
### Authors
David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère
### Background
对于森林管理的机器人技术兴趣日益增长，但在复杂自然环境中感知能力仍是一大障碍。重遮挡、多变的光照和茂密的植被对自动化系统提出了挑战，特别是在精准林业、生物多样性监测以及林业设备自动化方面。现有的数据集无法满足开发这类感知系统的需要，因为它们通常专注于城市环境或少量物种。因此，本文提出了SilvaScenes数据集，用于实例分割自然森林下木冠层图像中的树木物种，期望解决上述问题。
### Innovation
本文创新性地提出了SilvaScenes数据集，用于实例分割自然森林下木冠层图像中的树木物种，涉及5个生物气候区域。该数据集包含24种树的1476个树木实例标注，由林业专家注释。本文还通过对比现代深度学习方法验证了数据集的可靠性和挑战性，发现树木分割相对容易，但物种分类仍然是一个显著挑战。
### Conclusion
研究结果表明，树木分割具有较高的精度，但物种分类仍面临巨大挑战。未来继续优化现有的深度学习方法或开发新的算法均有助于改善森林管理中的感知能力。SilvaScenes数据集及源代码将在此网址获取：this https URL。
## 917. `cs.LG` - 使用基于自然实验的MEG-fMRI编码模型估计高空间和时间分辨率的大脑活动 [PDF](https://arxiv.org/pdf/2510.09415), [HTML](https://arxiv.org/abs/2510.09415)
### Authors
Beige Jerry Jin,Leila Wehbe
### Background
目前的非侵入性神经成像技术在空间分辨率和时间分辨率之间存在权衡。尽管脑磁图（MEG）可以捕捉快速的神经动态，而功能性磁共振成像（fMRI）则可以空间上定位大脑活动，但如何同时保持高分辨率的统一图景依然是一个未解之谜，尤其是在现有的源定位方法或MEG-fMRI融合方法中。本研究在参与者聆听超过七小时叙事故事的自然实验过程中采集了全头MEG数据，并利用公开的fMRI数据集（LeBel et al., 2023）。研究者利用变压器编码模型结合MEG和fMRI数据，以高空间时间分辨率估计潜在皮层源响应。并且该模型在多参与者上同时训练，具有潜在的重建皮层源的潜空间层。该模型在其预测MEG性能上优于单一模态的编码模型，并且在经典最小范数解的模拟实验中也表现出更高的空间和时间保真度。通过验证估计的潜在源，显示出该估计在无见数据和模态上的强泛化能力，并预测到全新数据集中的ECoG活动优于ECoG训练的编码模型。研究表明，通过整合大规模自然实验、MEG、fMRI和编码模型的力量，提出了一种实现毫秒和毫米级脑图谱的实用途径。
### Innovation
研究开发了一种基于变压器的编码模型，该模型能够结合MEG和fMRI数据，以高空间时间分辨率估计潜在皮层源响应。模型在多参与者上同时训练，并在预测MEG和空间时间保真度方面比单模态编码模型和经典最小范数解都有更好的表现。此外，该模型还展示了在新的被试和模态上的泛化能力，这种方法整合了大规模自然实验、MEG、fMRI和编码模型的力量，为实现高分辨率的大脑图谱提供了一种实用的方法。
### Conclusion
本研究成功开发了一种结合MEG和fMRI数据的变压器编码模型，以高空间时间分辨率估计潜在皮层源响应。该模型通过在多参与者联合训练过程中观察到的高保真度预测和泛化能力，在多学科的应用中具有重要意义。此方法为大空间时间分辨率的脑活动映射提供了一种可行的途径。
## 918. `cs.LG` - 生成机器人策略的运行时故障预测 [PDF](https://arxiv.org/pdf/2510.09459), [HTML](https://arxiv.org/abs/2510.09459)
### Authors
Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig
### Background
基于生成模型的模仿学习（IL）使机器人能够执行复杂的、长时间的任务。然而，从未见过的环境中或累积的动作错误可能会导致不可预测且不安全的行为，从而导致任务失败。在具有人类中心和安全关键环境中的机器人部署中，运行时早期故障预测变得至关重要。
### Innovation
提出了一种名为FIPER的故障预测框架，该框架适用于生成IL策略且无需故障数据。FIPER通过在策略嵌入空间中检测异常分布观察以及通过新颖的动作块熵评分来量化生成的动作的不确定性来识别即将发生的故障的两个关键指标。两种故障预测分数通过聚类成功的滚动来校准，并通过阈值决定故障警报。FIPER在五个涉及不同故障模式的模拟和真实环境中进行了评估，结果表明即使在异常分布情况下也能更准确且更早地预测失败，是生成机器人策略方面的重要一步提高可解释性和安全性。
### Conclusion
FIPER框架通过结合两个指标的阈值判断来对未来可能发生的故障进行预警，从而能够更准确、更早地区分实际故障和良性异常情况。
## 919. `cs.LG` - 自然语言推理中的混合模型：以命题逻辑为例 [PDF](https://arxiv.org/pdf/2510.09472), [HTML](https://arxiv.org/abs/2510.09472)
### Authors
Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki
### Background
尽管神经模型在技术上取得了显著进步，但它们的关键挑战之一是生成能力——这种能力对于逻辑推理等应用至关重要。现有的文献中，神经模型的生成能力通常被归类为一般性，而这种能力可以细分为两个基本方面：聚合性和递归性。聚合性是指抽象出复杂推理背后的原子逻辑规则的能力；递归性是指通过迭代应用推理规则构建复杂表示的能力。为了区分这两种能力，该研究通过使用命题片段作为自然语言推理的基准，来考察预训练大语言模型（LLMs）的逻辑推理能力。命题片段虽然简单，但仍可以作为形式逻辑的基础且表达力强的部分，支持对关键推理能力进行受控评估。
### Innovation
研究提出了一种将符号推理与神经计算相融合的混合架构，以克服现有模型在聚合性和递归性方面的能力局限，建立可靠且高效的逻辑证明系统。混合架构的核心在于神经组件加速处理过程，而符号推理确保了推理的完整性。实验表明，即使使用相对较小的神经组件，该架构也能保持较高的效率。
### Conclusion
混合架构为解决神经推理系统中关键的生成能力障碍提供了有效的路径，展示出提高神经推理系统整体效力的潜力。
## 920. `cs.LG` - 基于LoRA的少样本多标记DreamBooth风格一致角色生成 [PDF](https://arxiv.org/pdf/2510.09475), [HTML](https://arxiv.org/abs/2510.09475)
### Authors
Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar
### Background
音频视觉行业正在经历一场深刻的变化，其中AI的发展不仅用于自动化常规任务，还用于激发新的艺术形式。该论文旨在解决一个问题：在尽量保留人类设计参考角色的艺术风格和共有的视觉特征的同时，生成几乎无限数量的新颖角色，以拓宽动画、游戏及相关领域的创意可能性。
### Innovation
论文提出了一种基于多标记策略和LoRA参数高效微调技术的少样本DreamBooth方法。通过分离单个角色和其集体风格的标记，并在生成过程中引入随机标记和嵌入，该方法不仅实现了角色的无限生成，还保留了所学的风格。该方法在五个小型专业数据集上进行了评估，结果显示，该方法生成了高质量、多样化、保留参考角色独特审美特征的角色，得到了人类评估的进一步验证。
### Conclusion
该方法有效地解决了少样本数据微调以及生成过程中保留复杂角色细节的工作。实验结果表明，该方法不仅能生成高质量、多样化的角色，还保留了参考角色的独特美学特征，证明了其在风格一致角色生成方面的有效性和潜力。
## 921. `cs.LG` - 从单次双向测试中无监督全场贝叶斯推断超弹性正交材料：心肌研究案例 [PDF](https://arxiv.org/pdf/2510.09498), [HTML](https://arxiv.org/abs/2510.09498)
### Authors
Rogier P. Krijnen,Akshay Joshi,Siddhant Kumar,Mathias Peirlinck
### Background
传统的组织测试需要激发多种变形模式（如三轴剪切试验和双向拉伸试验），这需要多个组织样本和复杂的样本操作。这些操作和样本间固有差异可能影响逆向识别的组织行为。本文旨在通过使用异质变形配置在参数估计中解决问题，针对高度非线性、正交的本构模型适应了一个名为EUCLID的无监督方法，采用贝叶斯推断方法和三维连续体元素，以定量推断合成心肌组织片的材料模型参数。尽管有噪声干扰，该方法依然显示良好的预测能力，并与真实的模拟结果及其置信区间一致。
### Innovation
本文通过利用单次双向拉伸测试中的异质变形配置，采用无监督方法EUCLID和贝叶斯推理方法，实现了对高度非线性和正交的材料模型参数的定量推断，突破了传统多模式试验的限制，无需多次样本测试和复杂操作，并具有不确定性量化的能力。
### Conclusion
本文方法显示了从单次双向拉伸测试中定量推断高度非线性和正交材料模型的潜力，能够给出与真实模拟结果一致且包含误差范围的参数估计，为材料模型的简化研究提供了新的途径。
## 922. `cs.LG` - 临床驱动的交互分割评估方法 [PDF](https://arxiv.org/pdf/2510.09499), [HTML](https://arxiv.org/abs/2510.09499)
### Authors
Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso
### Background
交互分割是构建稳健、可泛化的 volumetric 医学图像分割算法的一种有希望的策略。然而，不一致且临床不现实的评估妨碍了公平比较，并错误地代表了现实世界的性能。当前的评估方法无法充分反映实际应用中的表现，特别是在不同和复杂的任务下。
### Innovation
本文提出了一个基于临床方法的交互分割评估任务与指标定义的体系，并构建了一个软件框架来构建标准化的评估流程。本文还评估了当前最先进的算法，并观察到了多个关键发现，如用户交互时信息损失的最小化对于模型的稳健性至关重要，使用自适应缩放机制可以提高稳健性和加快收敛速度，验证索引行为/预算的差异会影响性能，二维方法在标准化图像和粗略目标中表现良好，但三维上下文对大型或不规则形状的目标有帮助，非医学领域的模型（如SAM2）在对比度差和复杂数字形状下性能会衰减。这些发现对于改进医学图像的交互分割算法具有重要意义
### Conclusion
本文提出了一个新的临床驱动的评估方法，评估了当前最先进的算法在不同任务下的表现，并强调了几个关键视角，如信息损失最小化、自适应缩放机制、训练和验证不一致性、二维与三维方法性能的差异等。这些发现对于未来交互分割算法的设计和改进具有重要意义。
## 923. `cs.LG` - 多模态且不完整临床数据的可解释生成性和区分性学习 [PDF](https://arxiv.org/pdf/2510.09513), [HTML](https://arxiv.org/abs/2510.09513)
### Authors
Albert Belenguer-Llorens,Carlos Sevilla-Salcedo,Janaina Mourao-Miranda,Vanessa Gómez-Verdejo
### Background
现实世界的临床问题通常涉及多模态数据，这些数据常常伴随不完整视角和样本量有限的问题，这对机器学习算法构成了重大挑战。
### Innovation
本文提出了一种贝叶斯方法，旨在高效地处理这些挑战并提供可解释的解决方案。该方法通过生成性建模捕捉跨视角关系，并采用半监督策略；同时，采用区分性建模特定下游目标的相关信息。这种生成性-区分性双重建模方式提供了广泛的理解和特定任务的见解，从而自动填补缺失视角，实现不同数据源间的稳健推断。
### Conclusion
该方法在多模态临床数据中取得了好的效果，能够捕捉并分离生物、心理和社会人口统计的复杂互动关系。
## 924. `cs.LG` - 条件流匹配用于贝叶斯后验推断 [PDF](https://arxiv.org/pdf/2510.09534), [HTML](https://arxiv.org/abs/2510.09534)
### Authors
So Won Jeong,Percy S. Zhai,Veronika Ročová
### Background
本文提出了一种通过流匹配生成多元后验分布的采样方法。该方法提供了一个简单的训练目标，无需评估似然函数。方法在数据和参数的联合空间中学习一个动态的分块三角形速度场，这形成了从源分布到所需后验的确定性传输图。逆映射（向量秩）可以通过时间上可逆地积分速度来实现。这种动态设计使得约束速度可以获得单调映射，从而形成Brenier映射，使得能够快速且同时生成对应的贝叶斯可信集。这些可信集的等值线对应于Monge-Kantorovich数据深度的等值线。相对GAN基和扩散基方法，本文的方法计算上更轻便，能够捕捉到复杂的后验结构。此外，还提供了贝叶斯可信集的一致性理论保证。
### Innovation
本文提出了通过流匹配生成多元后验分布的方法，该方法的优势在于其简单的训练目标和无需评估似然函数。通过在数据和参数的联合空间中学习一个动态的分块三角形速度场来构建确定性传输图，从而实现了从源分布到目标后验的映射。逆映射能够通过时间积分速度来实现，这使得它能够快速生成贝叶斯可信集，这些可信集还表现出了数据深度的特征。此外，本文的方法在计算上更加轻便，能够捕捉到复杂的后验结构，并且提供了理论保证以确保可信集的一致性。
### Conclusion
本文提出了一种新的方法，用于生成的后验分布采样，该方法基于流匹配并通过学习一个动态的分块三角形速度场生成确定的传输映射，从而实现从源分布到后验分布的转换。这种方法相对于生成对抗网络（GAN）和扩散模型更为简单有效，能捕获复杂的后验结构，并且通过理论保证确保了所生成的Bayesian可信集的一致性。
## 925. `cs.LG` - LiveOIBench: 在信息学奥林匹克竞赛中大型语言模型能否超越人类选手？ [PDF](https://arxiv.org/pdf/2510.09595), [HTML](https://arxiv.org/abs/2510.09595)
### Authors
Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang
### Background
竞争编程问题由于其复杂性和易于验证，已成为评估大型语言模型（LLMs）编程能力的重要基准。然而，当前的编程基准存在一些限制，如缺乏非常具有挑战性的问题、测试用例覆盖不足以及依赖于限制访问性的在线平台API。
### Innovation
LiveOIBench 是一个全面的基准测试，它包含来自72个不同地区举办的2023年至2025年信息学奥林匹克竞赛的403个专家精选的奥林匹克级别竞赛编程问题，每个问题平均有60个专家设计的测试用例。其四大创新特性包括：（1）高质量的任务，详细的任务评分标准和广泛的私人测试用例；（2）整合顶尖参赛选手的表现数据以实现与顶级人类选手的对比；（3）定期从新发布的奥林匹克竞赛问题中进行不污染性的更新；（4）内置的评估系统便于离线和易于复制的评估。
### Conclusion
对32个流行的通用和推理LLMs进行基准测试，结果显示GPT-5达到了显著的81.76百分位数，但仍未达到顶级人类选手的表现（通常位于90以上）。相比之下，开源推理模型GPT-OSS-120B仅达到了60百分位数，表明与前沿封闭模型存在显著的能力差距。详细分析表明，稳健的推理模型更倾向于精确的问题分析而不是过度探索，建议未来模型应强调结构化分析并尽量减少不必要的探索。所有相关数据、代码和排行榜结果将在网站上公开。
## 926. `cs.LG` - 测试时提示增强是一种强大的大语言模型推理数据增强方法 [PDF](https://arxiv.org/pdf/2510.09599), [HTML](https://arxiv.org/abs/2510.09599)
### Authors
Sondos Mahmoud Bsharat,Zhiqiang Shen
### Background
大语言模型（LLMs）在提供链式思维示例时展示了出色的推理能力，但构建大规模推理数据集依然耗费大量时间和资源。现有的改进方法通常需要大量的人工标注数据，这增加了成本和复杂度。本文旨在介绍一种新的方法——测试时提示增强（P-TTS），它通过最小化标注负担，利用少量手工选择的推理示例，在测试时系统地调整示例增强，从而提高LLM的推理解析能力。
### Innovation
P-TTS 方法通过利用90个手工选择的推理示例，在测试时通过原则性的指令提示强度变化，生成多样性的推理轨迹情况，并在进行数据增强微调后，相比先前的基线模型S1和S1.1在数学推理任务AIME2024 & 25、MATH500和GPQA-Diamond上取得了显著提升。此外，该方法还展示了在非领域相关的推理基准测试中的零样本泛化能力。研究认为，测试时的提示增强有效探索了推理模式的潜在空间，以最小的标注成本增强了LLM的问题解决能力，并进一步挖掘了LLM的推理潜能和能力。
### Conclusion
P-TTS通过最大程度地减少标注负担，利用少量手动选择的推理例子，在推理过程中灵活调整指导提示强度，显著提升了大语言模型的推理能力，并且能够将其广泛应用于非领域相关的推理任务中。这为在资源限制或快速发展领域中提取LLM推理提供了一种实用且成本低的方法。
## 927. `cs.LG` - 从上下文数据到新供应商决策：数据驱动算法的实际性能 [PDF](https://arxiv.org/pdf/2302.08424), [HTML](https://arxiv.org/abs/2302.08424)
### Authors
Omar Besbes,Will Ma,Omar Mouchtaki
### Background
本文研究了过去数据的相关性/质量和数量如何影响在不确定需求下的销售商决策表现。文章通过分析考虑了上下文的新闻小贩问题来探讨这一问题，其中决策者需要在销售不足和销售过剩的成本之间进行权衡。在这种背景下，文章分析了数据驱动算法在上下文相关最坏情况下期望后悔中的表现，重点关注权重经验风险最小化（WERM）策略，结合上下文空间中过去数据的相似概率来加以权衡。这包括传统的策略例如经验风险最小化（ERM）、最近邻（k-NN）和核策略等。
### Innovation
本文最显著的方法论贡献在于精确刻画了任意WERM策略在任何给定上下文配置中的最坏情况后悔。通过优化方法，文章发现新闻小贩损失函数中的特定结构，使得从最坏分布的无穷维度优化问题简化为了简单的线性搜索问题。这种方法揭示了先前普遍适用的界限所掩盖的基本见解，并且明确了算法的实际保证性能如何随上下文变化，以及算法的学习曲线的细腻洞察。在过往研究主要集中在通过集中不等式给出的上界估计时，本文从优化的角度出发，提供了更加精确的性能保证理解，被视为对上下文决策问题理解上的重要突破。
### Conclusion
本文通过深入研究数据驱动算法在上下文新闻小贩决策中的表现，提供了一种新的优化和分析视角，改变了先前研究中由于普遍适用的界限带来的模糊思想。作者揭示了各个策略在不同情境下的实际性能，并提供了对学习曲线的细腻理解，推动了对上下文决策过程中数据利用的深入理解。
## 928. `cs.LG` -  adversarial丢失过程下的公平图机器学习 [PDF](https://arxiv.org/pdf/2311.01591), [HTML](https://arxiv.org/abs/2311.01591)
### Authors
Debolina Halder Lina,Arlei Silva
### Background
现有的公平图神经网络（GNNs）研究通常假设敏感属性要么完全可见，要么完全随机缺失。然而，本文指出，这种假设在实际场景中可能不成立，尤其是在缺失数据具有对抗性质时。研究指出，在对抗丢失的过程中，现有的公平GNN模型可能会因为插补过程掩饰了公平性问题，从而导致模型高估了其预测的公平性。
### Innovation
本文提出了Better Fair than Sorry（BFtS），一种针对敏感属性的公平缺失数据插补模型。BFtS的关键原理是插补应该逼近最坏情况下公平性的场景——即当优化公平性最困难时。它通过一个3玩家的对抗方案实现这一理念，其中两个对手联合对抗一个GNN分类器，分类器则最小化最大的偏差。
### Conclusion
通过合成和真实数据集实验，本文验证了BFtS在对抗丢失过程中的公平性-准确率权衡效果通常优于现有替代方案。
## 929. `cs.LG` - FREE: 用于建模环境生态系统的基础语义识别 [PDF](https://arxiv.org/pdf/2311.10255), [HTML](https://arxiv.org/abs/2311.10255)
### Authors
Shiyuan Luo,Juntong Ni,Shengyu Chen,Runlong Yu,Yiqun Xie,Licheng Liu,Zhenong Jin,Huaxiu Yao,Xiaowei Jia
### Background
建模环境生态系统对于地球的可持续发展至关重要，但由于大量物理变量之间的复杂交互过程，这极具挑战性。许多变量在大范围内难以测量，因此现有工作常常结合可观察的特征和局部可用的测量或模拟值来构建特定研究区域和时间段的模型。这引出了一个基本问题：如何建立一个通用框架来建模多样环境变量在时空中的复杂关系？
### Innovation
本文介绍了一种名为FREE的框架，它可以利用可变特征和可用信息来训练通用模型。核心思想是将可用的环境数据映射到文本空间，然后将环境科学研究中的传统预测建模任务转换为语义识别问题。
### Conclusion
在两个社会重要的真实世界应用（流域水温预测和作物产量预测）上的评估证明，FREE在多个基线条件下表现更优，尤其是在数据不足的情况下。
## 930. `cs.LG` - ConjNorm：适用于离群值检测的可计算密度估计 [PDF](https://arxiv.org/pdf/2402.17888), [HTML](https://arxiv.org/abs/2402.17888)
### Authors
Bo Peng,Yadan Luo,Yonggang Zhang,Yixuan Li,Zhen Fang
### Background
后验离分布（OOD）检测在可靠的机器学习中引起了广泛关注。许多研究致力于根据逻辑回归、距离或严格数据分布假设来构造分数函数，以识别低评分的OOD样本。然而，这些估计的分数可能无法准确反映真实的数据密度或施加不切实际的约束。
### Innovation
提出了一个新的基于Bregman散度的理论框架，该框架扩展了分布考虑范围，涵盖了指数家族的分布。提出了一个textsc{ConjNorm}方法，将密度函数设计重新定义为在给定数据集上寻找最优范数系数 $p$ 的搜索。并通过蒙特卡洛重要性采样技术设计了一个无偏且可解析的分区函数估计器。
### Conclusion
广泛的实验结果表明，与OOD检测基准相比，textsc{ConjNorm}在多种OOD检测设置中取得了新的最佳状态，分别在CIFAR-100和ImageNet-1K上提高了13.25%和28.19% (FPR95)。
## 931. `cs.LG` - 向自然的机器遗忘迈进 [PDF](https://arxiv.org/pdf/2405.15495), [HTML](https://arxiv.org/abs/2405.15495)
### Authors
Zhengbao He,Tao Li,Xinwen Cheng,Zhehao Huang,Xiaolin Huang
### Background
机器遗忘（MU）的目标是从预训练模型中消除特定训练数据所学到的信息，即忘记的数据。目前，现有的MU方法主要是通过修改忘记数据的错误标签，并对模型进行微调来实现。虽然这种方法可以清除知识，但这个过程是不自然的，因为遗忘过程会不必要地强化这些错误信息，导致过度遗忘。
### Innovation
提出了通过将修正后的样本与对应的正确标签配对，从前剩余的数据中注入正确信息的方法。这种方法通过使用注入的正确信息来自然地抑制需要忘记的信息，而不仅仅是修改标签和微调模型。这种方法在某种程度上能显著超越当前最先进的方法，并且大幅度减少过度遗忘，具有较强的超参数鲁棒性，为实际应用中的自然机器遗忘提供了潜在的解决方案。
### Conclusion
这种方法虽简单，但能在自然的机器遗忘方面显著超越现有方法，尤其在减少过度遗忘和超参数鲁棒性方面表现出色，是实际机器遗忘中的一个有前景的候选方法。
## 932. `cs.LG` - E-ICL: 基于原型理论的细粒度情感识别增强方法 [PDF](https://arxiv.org/pdf/2406.02642), [HTML](https://arxiv.org/abs/2406.02642)
### Authors
Zhaochun Ren,Zhou Yang,Chenglong Ye,Yufeng Wang,Haizhou Sun,Chao Chen,Xiaofei Zhu,Yunbing Wu,Xiangwen Liao
### Background
在不同领域，如知识获取、常识推理和语义理解中，在上下文学习（ICL）取得了显著成果。然而，在情感检测任务，尤其是细粒度情感识别方面，其性能显著下降。原因仍未清楚。
### Innovation
本文从原型理论的角度分析了ICL在细粒度情感识别任务中的不足，并提出了一种方法来解决这一问题。通过对ICL的广泛实验，发现它遵循细粒度情感识别的原型理论。基于此理论指出ICL的缺陷：依赖于语义相似但情感不准确的原型来预测情感，且容易受到不相关类别的干扰，影响预测的准确性和鲁棒性。作者提出了E-ICL，通过使用情感相似的动态标签更准确的原型来预测类别，并采用了排除无关类别的情感预测策略，提高了其准确性和鲁棒性。E-ICL无需额外训练，并且即使辅助情感模型的规模低于LLMs的10%，仍能在多个数据集上提升LLMs的性能超过4%。
### Conclusion
实验结果表明，E-ICL在细粒度情感数据集EDOS、Empathetic-Dialogues、EmpatheticIntent和GoEmotions上实现了更好的情感预测性能。
## 933. `cs.LG` - 一次性解决三项难题：使用Nest提高性能、收敛性和系统吞吐量 [PDF](https://arxiv.org/pdf/2510.09578), [HTML](https://arxiv.org/abs/2510.09578)
### Authors
Yuqian Huo,David Quiroga,Anastasios Kyrillidis,Tirthak Patel
### Background
变分量子算法（VQAs）有潜力在短期内在量子计算机上展示量子实用性。然而，这些算法通常在最高精度的量子比特和计算机上运行以实现最佳性能，从而导致系统吞吐量较低。最近的研究表明，VQAs可以首先在低精度量子比特上运行，然后在后来的运行中转移到高精度量子比特，仍然可以实现较好的性能。
### Innovation
我们提出了一种技术Nest，通过执行期间精心调整VQA的量子比特精度映射，不仅可以（1）提高性能（即，帮助接近最优结果），还可以（2）加速收敛。我们还使用Nest同时将多个VQAs并行部署在同一计算机上，从而（3）增加系统吞吐量，因此同时优化了三项相互冲突的指标：性能、收敛性和系统吞吐量。
### Conclusion
这项技术使VQAs能够更有效地利用量子计算机资源，不仅提高了算法的性能和收敛性，还通过增加系统吞吐量提升了系统的整体效率，从而实现了多目标优化。
## 934. `cs.LG` - 基于生物物理条件的3D脑肿瘤MRI合成生成框架 [PDF](https://arxiv.org/pdf/2510.09365), [HTML](https://arxiv.org/abs/2510.09365)
### Authors
Valentin Biller,Lucas Zimmer,Can Erdur,Sandeep Nagar,Daniel Rückert,Niklas Bubeck,Jonas Weidner
### Background
磁共振成像(MRI)修复在临床和研究中广泛应用。目前尚未有基于体素水平、连续肿瘤浓度的生成模型来合成高质量的脑肿瘤MRI。为了应对BraTS 2025修复挑战，研究人员开发了一种新的生成模型，该模型能够通过设置肿瘤浓度为零来实现健康组织的修复。这种潜扩散模型同时根据组织分割和肿瘤浓度生成3D空间上一致且解剖结构上连贯的图像，用于肿瘤合成和健康组织修复。
### Innovation
提出了一种基于生物物理条件的生成框架，能够根据体素水平的连续肿瘤浓度合成高保真度的脑肿瘤MRI。该模型还能够在BraTS 2025修复挑战中，通过设置肿瘤浓度为零来实现健康组织修复。该模型生成的3D图像在肿瘤合成和健康组织修复中都表现出高度的一致性和结构完整性。
### Conclusion
在健康组织修复中，该模型达到了18.5的PSNR，在肿瘤修复中达到了17.4的PSNR。该模型通过两种评估指标展示了其有效性，并且其代码已开源。
## 935. `cs.LG` - 局部主义大语言模型——动态局域性控制的数学框架 [PDF](https://arxiv.org/pdf/2510.09338), [HTML](https://arxiv.org/abs/2510.09338)
### Authors
Joachim Diederich
### Background
本文提出了一个用于训练大型语言模型的新框架，该框架包含可以从局部主义（可解释、基于规则的）调整到分布式（通用、高效）表示的连续可调内部表示。关键创新在于一个可调的局部性旋钮，它在训练和推理过程中能够动态地控制局部化程度，而无需重新训练模型。这种方法通过在注意力机制中使用分组稀疏惩罚、信息论锚定设计和动态规则注入来实现。数学证明明确地确立了在什么条件下注意力机制会集中在语义上相关的块上，具有指针对齐的指数性边界以及注意力熵的边界。
### Innovation
该框架的关键创新是引入了一个可调的局部性旋钮，该旋钮可以在训练和推理过程中动态控制局部化程度，而无需重新训练模型。实现这一目标的方法包括在注意力机制中使用分组稀疏惩罚、信息论锚定设计和动态规则注入。通过这些方法，数学证明了在一定阈值下注意力机制会集中到语义相关的块上，具有指数级边界条件下的注意力熵和指针对齐度。
### Conclusion
该框架允许模型实践者在可解释性和高性能模式之间进行连续插值，支持需要透明性和能力兼备的应用场景，特别是监管领域。
## 936. `cs.LG` - Flow-Opt: 使用流匹配和可微优化实现可扩展集中多机器人轨迹优化 [PDF](https://arxiv.org/pdf/2510.09204), [HTML](https://arxiv.org/abs/2510.09204)
### Authors
Simon Idoko,Arun Kumar Singh
### Background
多机器人在狭小空间中的集中轨迹优化可以通过较大的可行空间获取更平滑的轨迹，但当机器人数量增加时，计算量会变得难以处理。因此，本文研究了如何提高集中多机器人轨迹优化的计算效率，特别是在处理大量机器人时。
### Innovation
本文提出了Flow-Opt，一种基于学习的方法，通过减少问题为首先学习生成模型来抽样不同的候选轨迹，然后使用学习的Safety-Filter来进行快速推理时间约束满足。此外，Flow-Opt通过提出流匹配模型，结合扩散变换器和排列不变的机器人位置和地图编码器作为生成模型，实现了对复杂环境中小数十个机器人的轨迹优化。文中还开发了一种专门用于Safety-Filter的求解器，并配备了一个预测上下文特定初始化的神经网络，这种初始化在网络监督下进行训练。
### Conclusion
我们的方法在以下几个方面优于现有技术：（1）可以在几毫秒内生成几十个在复杂环境中的机器人轨迹；（2）相比竞争的基于扩散模型的基线，我们的方法可以几毫秒内生成显著更平滑的轨迹；（3）每个组件都可以批量处理，使得在几毫秒内解决多个问题实例；（4）我们的方法可以生成开始和目标位置之间多样性更强的轨迹，捕捉不同的碰撞避免行为。
## 937. `cs.LG` - 深强化学习在标普500指数实值期权套期保值中的应用 [PDF](https://arxiv.org/pdf/2510.09247), [HTML](https://arxiv.org/abs/2510.09247)
### Authors
Zofia Bracha,Paweł Sakowski,Jakub Michańków
### Background
该研究探讨了深度Q学习在套期保值中的应用，特别是在标普500指数的实值期权上。利用双延迟双确定性策略梯度（TD3）算法训练一个基于代理的模型，该模型能够在不做出显式的价格动态假设的情况下模拟套期保值决策。模型训练使用了2004年至2024年的标普500看涨期权的日内历史价格数据，其中有六个预测变量，分别为期权价格、标的资产价格、实值程度、剩余到期时间和已实现波动率，以及当前的对冲仓位。通过回测法进行训练，模型在未来约17年中表现出色。
### Innovation
开发了一个基于TD3算法的代理模型，无需明确的价格动态假设，就能够在模拟套期保值决定时使用深度强化学习。利用单个时间序列六个变量训练代理模型，测试其在不同市场条件下的适应性，特别是增加了交易成本和风险意识惩罚，显示出在波动较大或交易成本高的环境中其稳健性和灵活性。
### Conclusion
研究表明，深度强化学习（DRL）代理能够在许多情况下优于传统的Delta对冲策略，特别是在波动性高或交易成本高的情况下。尽管DRL代理在总体上优于Delta对冲策略，但在风险意识参数较高的情况下，其表现会有所下降。结果还显示，使用更长的波动率估计时间间隔，可以提高模型结果的稳定性。
## 938. `cs.LG` - 高效的自回归推断在变压器概率模型中的应用 [PDF](https://arxiv.org/pdf/2510.09477), [HTML](https://arxiv.org/abs/2510.09477)
### Authors
Conor Hassan,Nasrulloh Loka,Cen-You Li,Daolang Huang,Paul E. Chang,Yang Yang,Francesco Silvestrin,Samuel Kaski,Luigi Acerbi
### Background
基于Transformer的模型，如神经过程、先验拟合网络和表格基础模型，在单过边际预测方面表现出色。然而，许多实际应用，从信号插值到多列表格预测，需要捕捉预测间依赖关系的连贯联合分布。纯粹自回归架构能够高效生成这样的分布，但牺牲了这些模型在元学习中的灵活条件处理能力。相比之下，从基于集的模型获取联合分布的标准方法需要在每个自回归步骤中对整个增强条件集进行昂贵的重新编码。
### Innovation
作者提出了一种因果自回归缓冲区，它保留了自回归架构和基于集的模型的优点。该方法将上下文编码与更新条件集区隔开，模型一次性处理上下文并将其缓存，动态缓冲区则捕捉目标之间的依赖关系，随着目标的加入，它们进入缓冲区并同时关注缓存的上下文和先前已缓冲的目标。这使得批处理自回归生成高效且一次通过联合对数似然评价。一种统一的训练策略使得可以在廉价基础上无缝集成基于集的和自回归模式。
### Conclusion
在合成函数、EEG信号、认知模型和表格数据上，该方法在预测准确性上与强大基准模型相当，同时比强基准模型的联合采样速度快20倍。该方法结合了自回归生成模型的效率和基于集的条件处理的表示能力，使联合预测对于基于变压器的概率模型而言成为实际可行的方法。
## 939. `cs.LG` - 一种柴油机数字孪生体：具有转移学习的操作启发式物理感知神经网络用于发动机健康监控 [PDF](https://arxiv.org/pdf/2412.11967), [HTML](https://arxiv.org/abs/2412.11967)
### Authors
Kamaljyoti Nath,Varun Kumar,Daniel J. Smith,George Em Karniadakis
### Background
提高柴油发动机效率、减少排放以及实现稳健的健康监测一直是发动机建模的关键研究课题。尽管最近在系统监控中使用神经网络显示出了有希望的结果，但这些方法通常集中在组件级分析上，缺乏泛化能力和物理可解释性。
### Innovation
本文提出了一种新颖的混合框架，结合了物理信息神经网络（PINNs）与深度操作网络（DeepONet），以在均值柴油发动机模型中实现准确且计算高效的参数识别。该方法利用基于物理系统的知识与神经网络的驱动数据相结合来增强模型的适用性。通过使用预训练的DeepONets来预测执行器动力学，与现有的PINN框架相比，显著降低了在线计算成本。本文还提出了两种转移学习（TL）策略以解决PINNs在不同输入条件下需要重训的问题。
### Conclusion
与现有的健康监控方法相比，本文框架结合了基于物理模型的可解释性与深度学习的灵活性，为柴油发动机诊断提供了泛化性、准确性和部署效率方面的显著提高。
## 940. `cs.LG` - 使用随机舍入直接量化语言模型训练 [PDF](https://arxiv.org/pdf/2412.04787), [HTML](https://arxiv.org/abs/2412.04787)
### Authors
Kaiyan Zhao,Tsuguchika Tabaru,Kenichi Kobayashi,Takumi Honda,Masafumi Yamazaki,Yoshimasa Tsuruoka
### Background
虽然最近的量化大型语言模型（LLMs），如BitNet，在部署时通过二进制或三进制权重显著减少了内存使用，但训练这些模型仍需要大量的内存占用。这是因为全精度（即非量化）权重在直通过程中的直通估计（straight-through estimation）中必须被维持。为了应对这一挑战，研究者探索了在反向传播过程中不依赖于直通估计，直接更新量化的低精度权重的方法，以减少训练过程中的内存使用。
### Innovation
研究引入了一种随机舍入技术，以最小化在使用低位权重进行训练时的信息损失。研究结果表明，在不同规模的LLaMA结构化模型上：（1）仅使用低精度权重进行训练是可行的，即使这些权重限制在三进制值；（2）将位宽扩展到8位可以达到与BitNet b1.58相当的性能；（3）模型在精度缩放和内存减少的情况下保持鲁棒性，从FP32迁移到较低内存环境（BF16/FP8）时性能下降较小；（4）模型还支持使用三进制权重进行推理，展示了其部署的灵活性。
### Conclusion
研究证明，通过引入随机舍入技术，量化低精度权重的直接训练是可行的，同时保持了良好的性能，并在内存受限的环境中具有较高的鲁棒性。
## 941. `cs.LG` - 使用黑盒优化和量子退火去除训练数据中的错误标记 [PDF](https://arxiv.org/pdf/2501.06916), [HTML](https://arxiv.org/abs/2501.06916)
### Authors
Makoto Otsuka,Kento Kodama,Keisuke Morita,Masayuki Ohzeki
### Background
在现实世界的数据集中，错误标记的训练样本是一个常见的问题，这会降低模型的泛化能力，需要采用稳健且高效的噪声去除策略。
### Innovation
提出了一种结合基于代理模型的黑盒优化（BBO）、后处理和量子退火的方法来从受污染的训练数据集中去除错误标记的样本。该方法通过验证损失评估过滤后的训练子集，迭代地通过基于代理模型的BBO和后处理来优化损失估计，并利用量子退火高效地采样具有低验证错误的多样化训练子集。该方法在噪音主导位任务上进行了实验，证明了其对高风险错误标记样本的优先去除能力。进一步通过D-Wave的团集采样器在物理量子退火器上实现了更快的优化和更高的训练子集质量，超越了OpenJij模拟量子退火采样器或Neal模拟退火采样器。
### Conclusion
研究表明，该方法在监督学习任务中表现出有效性，并指出未来的研究方向包括对无监督学习、真实世界数据集和大规模实现的应用。
## 942. `cs.LG` - 免费使用协方差：利用均值分布进行无训练联邦学习 [PDF](https://arxiv.org/pdf/2412.14326), [HTML](https://arxiv.org/abs/2412.14326)
### Authors
Dipam Goswami,Simone Magistri,Kai Wang,Bartłomiej Twardowski,Andrew D. Bagdanov,Joost van de Weijer
### Background
利用预训练模型可以减少数据异质性的影响并加速联邦学习算法。最近的研究探索了使用基于第一和第二阶统计的方法，在服务器端聚合本地客户端数据分布，而不进行训练即可实现高性能的方法。然而，这些方法仍然存在通信成本较高的问题。本文的目标是在不共享协方差的情况下利用客户端传输的类均值来初始化全局分类器，从而减少通信成本并提高性能。通过利用类内协方差而非直接共享协方差，本文的方法可以在相同或更低的通信成本下实现比共享第二阶统计方法更好的性能，并且在初始分类器后进行联邦微调或线性探针仍能获得更好的性能。
### Innovation
提出了一种基于无偏估计的类协方差矩阵的训练-free方法，仅使用客户端传输的类均值作为第一阶统计来估算协方差。这种方法不仅减少了通信成本，还提高了分类器的初始化性能。此外，试验表明只使用类内协方差优于共享整个协方差矩阵的方法，同时保持或超越了共享第二阶统计的方法的性能。最终结果表明，使用这种方法初始化分类器后再进行联邦微调或线性探针进一步提高了性能。
### Conclusion
本文提出的方法在保持相同通信成本的情况下，将性能提高了4-26%，并且在通信效率方面远远优于联邦提示调优方法，同时仍然优于后者。
## 943. `cs.LG` - 基于网络动力学的深度神经网络理解框架 [PDF](https://arxiv.org/pdf/2501.02436), [HTML](https://arxiv.org/abs/2501.02436)
### Authors
Yuchen Lin,Yong Zhang,Sihan Feng,Hong Zhao
### Background
随着人工智能的发展，对深度学习背后的基本机制有了更深层次的理解变得至关重要。本文提出了一种理论框架，通过动力系统理论来分析学习动力学。文中重新定义了神经网络中的线性和非线性概念，通过引入两种基本的神经元级转换单元：有序转换和非有序转换。不同转换模式导致了网络权重向量组织的不同集体行为、信息提取的不同模式，以及不同学习阶段的出现。这些阶段之间的转换在训练过程中可能发生，解释了诸如“悟解”等关键现象。为了进一步分析泛化能力和结构稳定性，提出了样本空间和权重空间中吸引盆地的概念。神经元不同转换模式的分布特征以及两种吸引盆地的结构特征，构成了分析学习模型性能的核心指标。深度、宽度、学习率和批量大小等超参数被用作精细调整这些指标的控制变量。
### Innovation
提出了一个新的理论框架，通过动力系统理论来分析深度神经网络中的学习动力学。重新定义了神经网络中的线性和非线性概念，引入了两种基本的神经元级转换单元：有序转换和非有序转换。提出了吸引盆地的概念，用于分析泛化能力和结构稳定性。通过超参数调整，能够优化网络架构和训练策略，从而更好地理解深度学习的内在优势，并提供了优化网络架构和训练策略的新视角。
### Conclusion
本文不仅揭示了深度学习的内在优势，还为优化网络架构和训练策略提供了新的视角。通过动态系统理论，不仅分析了学习模型的性能，也提供了改进方法和标准。
## 944. `cs.LG` - 未观察到因果路径和后门路径的因果可加模型 [PDF](https://arxiv.org/pdf/2502.07646), [HTML](https://arxiv.org/abs/2502.07646)
### Authors
Thong Pham,Takashi Nicholas Maeda,Shohei Shimizu
### Background
因果可加模型提供了在存在隐藏变量的情况下进行因果发现的一种可行且表达性强的框架。然而，当两个变量之间存在未观测到的后门路径或因果路径时，它们之间的因果关系通常在现有理论下是不可识别的。
### Innovation
我们确立了诸多情况下因果方向可以识别的充分条件。特别地，我们推导了允许识别弓箭因果结构中相邻观测变量共享隐藏共同父节点的父-子关系的条件。这代表了因果发现中一个具有挑战性的问题，且据我们所知，在任何不假设隐藏变量的情况下，之前的工作未曾建立过这种识别性。我们的条件基于回归集的新特征化以及结合回归残差之间的独立性与观测变量之间条件独立性的混合方法。
### Conclusion
我们提供了一种综合这些见解的稳健且完备的算法，并且实证评估表明这种方法在性能方面与最先进的方法具有竞争力。
## 945. `cs.LG` - 使用解耦扩散顺序蒙特卡罗方法解决线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
### Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
### Background
最近的研究利用预训练生成扩散模型作为先验来解决贝叶斯逆问题。这项工作致力于构建一个基于'解耦扩散'的顺序蒙特卡罗方法，专门针对线性高斯逆问题，通过设计生成过程使得样本更新能够更大，从而提高方法的有效性。该方法在合成数据、蛋白质数据和图像数据上都进行了实验验证并展示了良好的效果。此外，还展示了该方法如何扩展到离散数据。
### Innovation
我们设计了一种基于'解耦扩散'原理的顺序蒙特卡罗方法，专为线性高斯逆问题设计。这种方法是渐近精确的，并且已经在合成数据、蛋白质数据和图像数据上进行了实验验证。此外，我们还展示了这种方法如何扩展到离散数据，这种方法在处理线性高斯逆问题时提供了新的解决方案。
### Conclusion
我们提出的解耦扩散顺序蒙特卡罗(DDSMC)算法，针对线性高斯逆问题进行了优化，同时在合成数据、蛋白质序列及图像数据上进行了验证，表现出良好的效果。此外，该方法还可以进一步扩展到离散数据的应用场景，为处理线性高斯逆问题提供了一种新的方法。
## 946. `cs.LG` - 使用 xLSTMs 探索神经格兰杰因果关系：揭示复杂数据中的时间依赖关系 [PDF](https://arxiv.org/pdf/2502.09981), [HTML](https://arxiv.org/abs/2502.09981)
### Authors
Harsh Poonia,Felix Divo,Kristian Kersting,Devendra Singh Dhami
### Background
在分析时间序列中因果关系时，特别是存在非线性依赖时，这会变得很具挑战性。格兰杰因果关系是一种用于分析变量间潜在联系的方法，有助于确定一个时间序列是否可以预测另一个时间序列的未来值。尽管这种方法取得了成功，但在捕获变量间的长期关系方面仍然存在局限性。为此，本研究利用最新的成功架构——扩展长短期记忆（xLSTM）进行了研究，并提出了格兰杰因果关系 xLSTM (GC-xLSTM)。该方法首先通过专有的动态损失惩罚来减少时间序列组件之间的稀疏性，然后通过联合优化过程确保格兰杰因果关系得到稳健的恢复。
### Innovation
首先，使用新型动态损失惩罚来强制稀疏性，以改进模型并识别候选稀疏性。然后，通过联合优化确保恢复的格兰杰因果关系是稳健的。实验在六个不同数据集上进行了评估，展示了GC-xLSTM的整体有效性。
### Conclusion
实验评估展示了GC-xLSTM的有效性，表明GC-xLSTM方法能够在多种不同数据集上稳健地捕捉时间序列间的格兰杰因果关系。
## 947. `cs.LG` - 通过去噪表示的数据归因检测和过滤不安全的训练数据 [PDF](https://arxiv.org/pdf/2502.11411), [HTML](https://arxiv.org/abs/2502.11411)
### Authors
Yijun Pan,Taiwei Shi,Jieyu Zhao,Jiaqi W. Ma
### Background
大型语言模型对不安全的训练数据非常敏感，即使少量不安全数据也会影响模型的可靠性。目前最先进的检测方法主要依赖于需要大量计算资源的引导分类器，这些分类器受限于预定义的分类体系。已有方法在识别不安全训练数据时存在一个关键局限：不安全的目标文本既包括使其不安全的关键信息，也包括有必要的使语言流畅的中性信息（如停用词或无害事实），这使得整体表示在检测不安全训练数据时变得‘噪音’干扰较多。因此，为了解决这一问题，本文提出了一种新颖的表示法数据归因方法——去噪表示归因（DRA），它通过净化训练和目标表示来增强表示稀疏性，从而提高不安全训练数据的检测能力。这种方法在过滤逃逸钳制行为和检测性别偏见等任务上表现出了显著的提升，优于主要基于引导分类器的现有最佳方法。
### Innovation
提出了一种新颖的去噪表示归因方法（DRA），该方法通过净化训练和目标表示来增强表示稀疏性，从而有效识别不安全的训练数据。这种方法在多个任务上显著优于现有的基于引导分类器的方法。
### Conclusion
该研究通过提出DRA方法，显著提高了不安全训练数据检测的准确性，并验证了这种方法在多个实际任务中的有效性。
## 948. `cs.LG` - COSMOS: 一种针对大规模语言模型高效训练的混合自适应优化器 [PDF](https://arxiv.org/pdf/2502.17410), [HTML](https://arxiv.org/abs/2502.17410)
### Authors
Liming Liu,Zhenghao Xu,Zixuan Zhang,Hao Kang,Zichong Li,Chen Liang,Weizhu Chen,Tuo Zhao
### Background
大规模语言模型（LLMs）在各个领域表现出显著的成功，但其优化仍然是一项重大挑战，因为它们所处的复杂和高维损失景观使其优化困难。尽管自适应优化器如AdamW被广泛应用，但它们存在一些关键局限性，包括难以捕捉坐标之间的相关性以及高内存消耗。随后的研究，例如SOAP，虽然试图更好地捕捉坐标之间的相关性，但也增加了更多的内存开销，限制了大规模LLMs的可扩展性。作为一种替代方法，通过低维度投影来减少内存消耗，但这种方法导致了显著的近似误差，从而在优化性能上效果较差。因此，文章探讨了一种新的混合优化器COSMOS，该优化器通过利用梯度矩阵中不同特征子空间的重要性差异，在保持有效优化性能的同时实现了内存效率。COSMOS使用SOAP处理主特征子空间，这捕捉了主要的优化动态，而剩余的特征子空间使用MUON处理，因为SOAP对该部分的处理成本较高。这种混合策略显著减少了内存消耗，同时保持了稳健的优化性能，使其特别适合大规模LLMs。
### Innovation
COSMOS是一种新颖的混合优化器，它通过利用梯度矩阵中不同特征子空间的重要性差异，实现了内存效率，同时保持了优化性能。具体来说，COSMOS使用SOAP处理主特征子空间，利用MUON处理剩余特征子空间，这种混合策略减少了内存消耗，同时保持了优化性能，特别适合大规模LLMs。COSMOS的设计受到实验见解和实际考虑的驱动。研究表明，COSMOS在多个数据集和Transformer架构上表现出色，其代码可以在指定的网址获取。
### Conclusion
实验结果表明，COSMOS能够显著提高LLMs训练的内存效率，同时保持优化性能，特别适用于大规模LLMs。COSMOS的设计和实现证明了其有效性和实用性。
## 949. `cs.LG` - Score Smoothing在扩散模型中的插值效应 [PDF](https://arxiv.org/pdf/2502.19499), [HTML](https://arxiv.org/abs/2502.19499)
### Authors
Zhengdao Chen
### Background
评分基于扩散模型在不同领域取得了显著进展，能够生成不在训练集中但又与训练集相关的新数据样本。然而，这些模型的创造力是如何产生的原因尚不完全清楚。
### Innovation
本文假设这种创造力来源于由经验评分函数光滑引起的插值效应。在训练集均匀分布在一个一维子空间的情况下，通过理论分析和数值实验，本文揭示了正则化两层ReLU神经网络如何接近学习经验评分函数的一个光滑版本，以及评分光滑与去噪动态之间的相互作用。
### Conclusion
本文还通过实验表明，神经网络学习评分函数确实会导致评分光滑效应，在简单的非线性环境中也是如此，而无需显式正则化。此外，光滑的评分函数可以导致生成的样本在线性子空间内插值训练数据，而不是完全记忆。
## 950. `cs.LG` - 在可学习流形上的聚合以进行异步联邦优化 [PDF](https://arxiv.org/pdf/2503.14396), [HTML](https://arxiv.org/abs/2503.14396)
### Authors
Archie Licudi,Anshul Thakur,Soheila Molaei,Danielle Belgrave,David Clifton
### Background
异步联邦学习（FL）面对两个关键问题：标准线性参数插值技术（如FedAvg）因曲率导致的损失障碍以及过时更新与服务器当前优化状态不一致所引起的干扰。这些问题限制了异步联邦学习的效果。
### Innovation
该研究提出了一种几何框架，将聚合视为Riemannian模型空间中的曲线学习，并将轨迹选择与更新冲突解决分离。在此框架下，提出了AsyncBezier和OrthoDC方法。AsyncBezier用低阶多项式（Bezier）轨迹代替线性聚合，以绕过损失障碍；OrthoDC利用基于内积的正交性将延迟更新投影，以减少干扰。该框架在多个数据集（包括LEAF Shakespeare和FEMNIST）上为强异步基线提供了持续提高的准确性和客户端公平性。
### Conclusion
即使其他方法得到更高的本地计算预算，该方法仍能保持性能增益。此外，研究还提供了框架级别的收敛性保证，覆盖每个变体的简单假设。
## 951. `cs.LG` - DeepOHeat-v1：高效的操作学习加速和可靠的3D-IC设计中的快速热模拟与优化 [PDF](https://arxiv.org/pdf/2504.03955), [HTML](https://arxiv.org/abs/2504.03955)
### Authors
Xinling Yu,Ziyue Liu,Hai Li,Yixing Li,Xin Ai,Zhiyu Zeng,Ian Young,Zheng Zhang
### Background
在3D-IC设计中，由于功率密度的增加和复杂的热传递路径，热分析变得至关重要。现有的一些操作学习框架，如DeepOHeat，在加速热模拟方面取得了初步的成果，但在多尺度热模式预测能力、训练效率和设计优化中的结果可信度方面存在局限性。
### Innovation
DeepOHeat-v1提出了三项关键创新来解决这些挑战。首先，集成Kolmogorov-Arnold网络和可学习的激活函数作为主干网络，实现对多尺度热模式的自适应表示，误差分别减少了1.25倍和6.29倍。其次，引入了一种分离的训练方法，分解了基础函数沿坐标轴，使得在基线案例中训练速度提高了62倍，并减少了31倍的GPU内存，从而能够进行以前由于GPU内存限制而不可行的热分析。第三，提出了可信度评分以评估预测结果的可靠性，并开发了一种结合操作学习与有限差分（FD）方法的混合优化流程，使用广义最小残差（GMRES）方法进行增量解的细化，实现了高效和可靠的热优化。
### Conclusion
实验结果表明，DeepOHeat-v1在准确性方面与使用高保真有限差分求解器的优化相当，同时在测试案例中将整个优化过程速度提高了70.6倍，通过最优放置产生热量的组件有效降低峰值温度。
## 952. `cs.LG` - 协作无标签数据优化 [PDF](https://arxiv.org/pdf/2505.14117), [HTML](https://arxiv.org/abs/2505.14117)
### Authors
Xinyi Shang,Peng Sun,Fengyuan Liu,Tao Lin
### Background
现有模型中心的方法存在三大关键限制，所有这些限制都源于共享瓶颈：从数据中提取的知识被锁定在模型参数中，妨碍了其重用性和扩展性。
### Innovation
提出了CoOpt，一种高效的并行框架，用于协作优化无标签数据，从而有效地将知识编码到数据本身。通过分配无标签数据并利用公开的、任务无关的模型，CoOpt实现了可扩展、可重用和可持续的训练管道。
### Conclusion
广泛的实验在多个数据集和架构上证明了其有效性和效率，在Tiny-ImageNet和ImageNet-1K上分别取得了13.6%和6.8%的改进，并且训练速度分别加快了1.94倍和1.2倍。
## 953. `cs.LG` - MergeBench: 基于合并大型领域特定LLM的基准 [PDF](https://arxiv.org/pdf/2505.10833), [HTML](https://arxiv.org/abs/2505.10833)
### Authors
Yifei He,Siqi Zeng,Yuzheng Hu,Rui Yang,Tong Zhang,Han Zhao
### Background
现有的模型合并方法虽然展示了潜力，但现有评估在模型规模和任务多样性方面都有限，这使得模型合并技术的实际应用面临挑战。此外，关于大型、领域特定的大语言模型（LLM）的应用问题仍不清楚。为了应对这些挑战，该研究引入了MergeBench，一个综合评估套件，用于全面评估大规模模型合并。MergeBench基于最新的开源语言模型，包括从2B到9B规模的Llama和Gemma家族，并涵盖五个关键领域：指令遵循、数学、多语言理解、编码和安全性。
### Innovation
MergeBench旨在解决现有方法在评估模型合并时规模和任务多样性方面的局限性。该研究标准化了模型微调和评估协议，并评估了八种代表性的合并方法在多任务性能、遗忘和运行时效率方面的表现。该研究指出，合并倾向于在更强的基础模型上表现更好，并提出了一些技术如合并系数调整和稀疏化可以提高知识保留。然而，挑战仍然存在，例如计算成本高，领域内性能与多任务模型相比的差距，以及模型合并如何融入标准的LLM训练管道中的未探索角色。研究为未来的合并模型研究提供了基础，并分享了实用指南以帮助算法选择及应用建议。
### Conclusion
研究强调了模型合并技术需要进一步研究和优化，虽然取得了一定的进展，但仍面临一些挑战，如大规模模型的计算成本、领域内性能差距和在标准LLM训练管道中的作用。最终希望MergeBench能够成为未来研究合并模型理解与实际应用的重要基石。
## 954. `cs.LG` - 推理大型语言模型的错误源于虚构关键问题特征 [PDF](https://arxiv.org/pdf/2505.12151), [HTML](https://arxiv.org/abs/2505.12151)
### Authors
Alex Heyman,Joel Zylberberg
### Background
近期，通过强化学习训练的链式思维策略，推理大型语言模型（RLLMs）显著提升了推理任务的表现。这些模型在某些情况下能够表现出复杂推理能力，但在面对更复杂的任务时，仍然显示出不完善的推理能力。因此，理解这些模型推理失败的频率和原因变得至关重要。
### Innovation
本文通过将多个推理大型语言模型（包括o1-mini, o3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, Grok 3 Mini Beta）应用到图着色问题上，发现这些模型倾向于虚构图中不在提示中的边。这种现象在不同复杂度的问题中普遍存在，并且能够解释受测模型中几乎所有的错误答案，尤其是在某些模型中几乎全部是这种情况。此外，作者还通过较小规模的实验验证了这种输入冲突虚构现象在稳定匹配问题中的普遍性。
### Conclusion
实验结果表明，推理大型语言模型可能普遍存在对问题具体细节的错误表示的问题。因此，提出了设计选择建议，旨在缓解这一弱点。
## 955. `cs.LG` - 你的扩散模型里藏有什么？一种基于得分的黎曼度量来探索数据流形 [PDF](https://arxiv.org/pdf/2505.11128), [HTML](https://arxiv.org/abs/2505.11128)
### Authors
Simone Azeglio,Arianna Di Bernardo
### Background
近期扩散模型在捕捉复杂图像分布方面取得了显著进展，但学习到的数据流形的几何特性仍然不太了解。本文旨在解决这一问题，通过引入一种基于扩散模型得分函数的黎曼度量，不再需要明确参数化就可以表征数据流形的内在几何结构。该度量在流形切向方向保持距离不变，在切向方向垂直地拉伸距离，从而创造了一种自然沿流形轮廓的测地线结构。
### Innovation
本文提出了一种基于得分的黎曼度量，利用扩散模型得分函数来表征数据流形的内在几何结构，无需显式参数化。开发了高效算法计算这些测地线，并展示了其在数据点间插值和超越观察到的数据分布的外推中的实用性。通过合成数据、已知几何结构的数据、以及由稳定扩散生成的复杂自然图像，实验表明，基于得分的测地线捕捉到有意义的变换，遵循数据分布，且在感知和分布级度量上优于基线方法。
### Conclusion
实验结果揭示了由扩散模型隐含学习的几何结构，并通过黎曼几何的视角提供了指导自然图像流形探索的方法。该方法在感知度量（LPIPS）和分布级度量（FID、KID）上表现一致优越，生成了更平滑、更逼真的图像过渡。这些结果强化了扩散模型内部隐含的几何结构，为探索和导航图像流形提供了新的途径。
## 956. `cs.LG` - 连续部分可观测量决策过程中的策略优化的序列蒙特卡洛方法 [PDF](https://arxiv.org/pdf/2505.16732), [HTML](https://arxiv.org/abs/2505.16732)
### Authors
Hany Abdulsamad,Sahel Iqbal,Simo Särkkä
### Background
在部分可观性条件下进行最优决策需要代理在减少不确定性（探索）和追求即时目标（利用）之间进行平衡。现有方法在处理部分可观测量马尔可夫决策过程（POMDPs）时往往难以有效应对不确定性。
### Innovation
本文提出了一种新颖的策略优化框架，用于连续部分可观测量马尔可夫决策过程，该框架明确解决了上述挑战。该方法将策略学习视为非马尔可夫费曼-卡克模型中的概率推断，能自然捕捉信息收集的价值，并通过预测未来观察结果来避免次优近似或人工启发式。
### Conclusion
研究表明，该算法在标准连续POMDP基准测试中表现出色，现有方法难以在不确定性下行动。
## 957. `cs.LG` - 自动评估基础模型的能力 [PDF](https://arxiv.org/pdf/2505.17228), [HTML](https://arxiv.org/abs/2505.17228)
### Authors
Arash Afkanpour,Omkar Dige,Fatemeh Tavakoli,Negin Baghbanzadeh,Farnaz Kohankhaki,Elham Dolatabadi
### Background
当前评估系统依赖于手动构建的静态基准，这限制了它们评估模型能力的全面性。因此，对于模型性能的准确度和广度评估存在局限性。
### Innovation
提出了一种名为ACE的新框架（Active learning for Capability Evaluation）。ACE框架实现了大规模、自动化的基础模型评估，并且评估过程更精细。ACE利用先进模型嵌入的知识将领域分解成有语义意义的能力，并生成多样化评估任务。它使用潜在语义空间拟合能力模型，通过主动学习只评估部分能力就能达到与全面评估相近的精度，同时达到更平衡的覆盖范围和更细微的能力差异区分能力，相比静态数据集，ACE能够更全面和细致地评估模型能力。
### Conclusion
实验结果表明，ACE框架可以提供更完整和有信息量的模型能力图景，这对于安全有效部署基础模型至关重要。
## 958. `cs.LG` - PrivATE: 在（ε,δ）差异隐私下的平均治疗效果的差分隐私置信区间 [PDF](https://arxiv.org/pdf/2505.21641), [HTML](https://arxiv.org/abs/2505.21641)
### Authors
Maresa Schröder,Justin Hartenstein,Stefan Feuerriegel
### Background
平均治疗效应（ATE）广泛用于评估药物和其他医疗干预的有效性。在如医学这样的安全关键应用中，可靠的ATE推断通常需要有效的不确定性量化，如通过置信区间（CIs）。然而，在这些场景中，治疗效应的估计通常涉及可能需要保持私密的敏感数据。因此，亟需一个既能保证隐私保护又能进行准确ATE估计的方法。
### Innovation
本文提出了一种新颖的机器学习框架，即PrivATE，用于在差异隐私下计算ATE的置信区间。该框架通过输出扰动估计差分隐私的ATE，在双重稳健的方式下估计差分隐私的方差，并在考虑估计和隐私化步骤的不确定性的同时构造置信区间。该框架不依赖于特定模型，具有双重稳健性，并确保有效置信区间的生成。
### Conclusion
通过使用合成和真实世界医疗数据集展示该框架的有效性，作者表明这是首次提出了一个适用于（ε,δ）差分隐私下的、具有双重稳健性的框架来生成有效的ATE置信区间。
## 959. `cs.LG` - CausalDynamics: 大规模基准用于动力因果模型的结构发现 [PDF](https://arxiv.org/pdf/2505.16620), [HTML](https://arxiv.org/abs/2505.16620)
### Authors
Benjamin Herdeanu,Juan Nathaniel,Carla Roesch,Jatan Buch,Gregor Ramien,Johannes Haux,Pierre Gentine
### Background
动力系统因果关系发现面临重大挑战，特别是在无法进行主动干预的领域。大多数用于研究这些系统及其基准的方法主要针对确定性的、低维度的和弱非线性的时序数据。为了克服这些限制，本文提出了一种大规模基准和可扩展的数据生成框架CausalDynamics，以促进动力因果模型的结构发现。现有的基准和方法主要适用于这些特定类型的数据，难以直接应用于复杂的真实动力系统，这些系统通常包括噪声、混淆和延迟的动力学特性。CausalDynamics解决的问题在于当前方法难以处理复杂、多变量的动力系统，尤其是在面对实际应用中的系统时。
### Innovation
CausalDynamics框架包括一个即插即用、自己设计耦合的工作流程，能够构建物理系统的层次结构，其基准数据集包括来自成千上万个线性和非线性耦合的常微分方程和随机微分方程的真实因果图，以及两个理想化的气候模型。通过这种大规模基准和可扩展的数据生成框架，本文为动力因果模型的发展提供了一个新的平台，能够测试和改进现有和新的因果发现算法，跨领域提供更广泛适用的方法，同时解决各自领域特有的挑战。CausalDynamics框架还将促进因果发现算法的发展，使其能够应对复杂、多变量的动力系统中的独特挑战。
### Conclusion
CausalDynamics通过提供大规模的基准和可扩展的数据生成框架，推动了动力因果模型结构发现的发展。这种框架使得研究人员能够对复杂的动力系统进行因果关系的发现，适用于多种场景，尤其是那些真实系统中存在噪声、混淆和延迟的动力学特性的情况。作者期望这一框架将加速该领域的发展，促进更稳健的因果发现算法的开发，并使这些算法能够在不同领域得到广泛应用。
## 960. `cs.LG` - 分区生成模型：无需掩码的掩码建模 [PDF](https://arxiv.org/pdf/2505.18883), [HTML](https://arxiv.org/abs/2505.18883)
### Authors
Justin Deschenaux,Lan Tran,Caglar Gulcehre
### Background
masked generative models (MGMs) 通常用于捕获复杂数据并比自回归模型 (AR) 提供更快的生成速度，通过并行解码。然而，MGMs 通常处理固定长度的输入，这可能导致低效：早期在采样过程中，大多数标记被遮蔽且不携带信息，导致不必要的计算浪费。相比之下，AR 模型仅处理之前生成的标记，使得早期迭代更快。
### Innovation
提出了分区生成模型 (PGM)，这是一种新的方法，结合了 AR 和 MGM 的优点。PGM 通过对标记进行分区和使用稀疏注意力机制来阻断信息流，而非简单的遮蔽。此模型在采样过程中可以仅处理之前生成的标记，同时保持并行生成和任意顺序生成标记的能力。在 OpenWebText 上，PGM 提供至少 5 倍的采样延迟和吞吐量改进，同时生成具有优越生成困惑度的样本，相较于掩码扩散语言模型。在 ImageNet 上，PGMs 的吞吐量比 MaskGIT 高 7.5 倍，仅 FID 有所增加（5.54 对比 5.35）。通过两倍的采样步骤，FID 降低到 4.56，同时比 MaskGIT 快 3.9 倍。最后，PGMs 无缝集成到 MGM 的蒸馏中，提供进一步的推理速度提升。
### Conclusion
PGM 是一种新的生成模型，能够同时处理与前后生成的标记间信息流的阻断，不仅在文本生成上有所突破，也在图像生成中取得了显著的吞吐量和图像生成质量的提升。此外，它能够与 MGM 的蒸馏技术无缝集成，进一步提高模型的推理速度。
## 961. `cs.LG` - CLIP Needs a Robust Text Encoder [PDF](https://arxiv.org/pdf/2506.03355), [HTML](https://arxiv.org/abs/2506.03355)
### Authors
Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher
### Background
对抗输入攻击可以显著影响CLIP嵌入，进而影响包含CLIP的下游模型（如文本到图像生成模型或大型跨模态模型）的鲁棒性。尽管已经有一些努力使CLIP图像编码器更鲁棒，但文本编码器的鲁棒性尚未被探索。
### Innovation
提出了LEAF方法：一个高效针对文本域的对抗微调方法，可以适用于大型CLIP模型。该方法显著提高了零样本对抗准确度，同时保持了稳健图像编码器提供的视觉性能。当与文本到图像扩散模型结合时，还可以提高对抗噪声下的生成质量。在跨模态检索任务中，LEAF在对抗噪声下提高了召回率。此外，鲁棒的文本编码器通过直接优化帮助更好重建输入文本。
### Conclusion
通过开源代码和模型，展示了LEAF的有效性，使CLIP模型在文本和视觉领域均具有更好的鲁棒性。
## 962. `cs.LG` - 通过时间共享深度展开前馈网络的非确定性自动机构造框架 [PDF](https://arxiv.org/pdf/2505.24110), [HTML](https://arxiv.org/abs/2505.24110)
### Authors
Sahil Rajesh Dhayalkar
### Background
本文提出了一个用于非确定性有限自动机（NFAs）形式和构造性模拟的时间共享深度展开前馈网络（TS-FFNs）框架。这是一种非循环的展开计算，具有共享参数，功能上与展开循环或状态空间模型等效。与依赖显式循环架构或事后提取方法的先前方法不同，我们的方法通过符号方式将自动机状态编码为二进制矢量，转换为稀疏矩阵变换，并将非确定性分支（包括 ε-闭包）表示为共享阈值更新的组合。
### Innovation
本文的核心创新在于使用时间共享深度展开前馈网络，首先通过符号方式编码自动机状态为二进制矢量，转换为稀疏矩阵变换，并通过共享阈值更新组合来表示非确定性分支（包括 ε-闭包）。证明了所有正规语言都可以通过这种共享参数的展开前馈网络准确识别，参数数量与输入长度无关。此外，这些网络可以通过监督接受数据进行梯度下降训练，以恢复目标自动机的行为，这一训练能力是本文工作的关键点。
### Conclusion
理论结果在大量实验中得到了验证，达到了完美的或接近完美的接受一致性、状态传播和闭包动力学一致性。本文澄清了自动机理论与现代神经架构之间的对应关系，展示了展开前馈网络能够执行精确的、可解释的和可训练的符号计算。
## 963. `cs.LG` - 利用物理感知突触形态网络实现无需训练的地球观测变化检测 [PDF](https://arxiv.org/pdf/2506.04285), [HTML](https://arxiv.org/abs/2506.04285)
### Authors
Stephen Smith,Cormac Purcell,Zdenka Kuncic
### Background
低地球轨道卫星的地球观测数据对于灾害响应决策者至关重要，但数据从卫星传输到地面站的延迟是主要瓶颈。一种解决方法是对数据进行在轨处理并优先传输相关信息。本文提出了一种物理感知神经形态网络（PANN），用于检测由自然灾害引起的环境变化，并生成变化地图，以优先传输重要数据。这种PANN使用受物理神经网络启发的方法，这些网络由具有“记忆”功能的纳米电子电路元件（如memristors）组成，确保网络权重动态响应变化的输入信号。这种方法使得模型无需训练且资源消耗较少，从而提高应对资源受限情况下的在轨数据处理能力。PANN在多个自然灾难检测类别中达到了与最先进的AI模型可比甚至更好的效果，为资源受限的在轨处理提供了一种有前景的解决方案。
### Innovation
本文提出了一种无需训练的物理感知神经形态网络（PANN），应用于灾害变化检测。PANN基于纳米电子元件（如memristors）构建，网络权重动态响应输入信号，生成物理约束的动态输出特征，通过距离基度量检测变化。这种方法不需要训练，减少了计算资源需求，适用于资源受限的环境。与最先进的AI模型相比，PANN在多个灾害类别中表现相当甚至更好，为灾害响应提供了新的解决方案。
### Conclusion
物理感知神经形态网络（PANN）在灾害变化检测中表现出色，无需训练，且计算资源消耗少，为资源受限的在轨处理提供了新的解决方案，有望改善灾害响应决策。
## 964. `cs.LG` - NIMO：一个非线性可解释模型 [PDF](https://arxiv.org/pdf/2506.05059), [HTML](https://arxiv.org/abs/2506.05059)
### Authors
Shijian Xu,Marcello Massimo Negri,Volker Roth
### Background
深度学习已经在许多领域取得了显著的成功，但同时也引发了对模型预测可解释性的高需求。虽然已经提出了一些可解释的机器学习方法，但这些方法的后验解释通常缺乏保证的准确性，并且容易受到超参数选择的影响，凸显了采用固有可解释性模型的吸引力。例如，线性回归通过其系数提供了清晰的特征效应，但此类模型通常被性能更复杂的神经网络超越，而这些复杂的神经网络通常缺乏固有的可解释性。
### Innovation
为了应对这一矛盾，我们提出了NIMO框架，它结合了神经网络的强大表达能力与内置的可解释性。NIMO基于简单的线性回归，能够提供灵活且可理解的特征效应。此外，我们开发了一种基于参数消除的优化方法，该方法允许有效且高效地优化神经网络参数和线性系数，并能方便地引入稀疏性。我们通过实验证明，该模型能够在保持良好的预测性能的同时提供忠实且可理解的特征效应。
### Conclusion
我们展示了NIMO模型能够在保持良好预测性能的前提下，通过稀疏适应性岭回归方法提供忠实且可理解的特征效应。该模型结合了神经网络的强大表达能力和固有的可解释性，为解决了复杂模型与可解释性之间的矛盾提供了一种新的解决方案。
## 965. `cs.LG` - 神经网络参数空间中的对称性 [PDF](https://arxiv.org/pdf/2506.13018), [HTML](https://arxiv.org/abs/2506.13018)
### Authors
Bo Zhao,Robin Walters,Rose Yu
### Background
现代深度学习模型高度过参数化，导致了大量的参数配置能够产生相同的结果。这部分冗余可以归因于参数空间中的对称性——这些变换在不影响网络功能的情况下能够发生变化。这些对称性塑造了损失景观并限制了学习动态，为优化、泛化和模型复杂性提供了新的视角，补充了现有的深度学习理论。已有文献对此进行了初步探讨，但该领域仍有许多空白需要填补。
### Innovation
本综述总结了现有文献，揭示了对称性和学习理论之间的联系，并指出了该新兴领域的空白和机遇。通过揭示参数空间对称性对深度学习模型的影响，提供了对优化、泛化和模型复杂性理解的新视角，补充了现有的理论框架。
### Conclusion
综述提供了关于参数空间对称性的概述。概括了现有的文献内容，发现了对称性和学习理论之间的联系，并确定了在该新兴领域中的空缺和机遇。
## 966. `cs.LG` - CausalVLBench: 在大型视觉语言模型中衡量视觉因果推理 [PDF](https://arxiv.org/pdf/2506.11034), [HTML](https://arxiv.org/abs/2506.11034)
### Authors
Aneesh Komanduri,Karuna Bhaila,Xintao Wu
### Background
大型语言模型在各种语言任务中展示了显著的能力，尤其是得益于其在上下文学习中的 emergent 能力。通过将视觉输入扩展到 LLMs 中，大型视觉-语言模型 (LVLMs) 在识别和视觉问答 (VQA) 等任务中取得了显著的成就。尽管人们越来越关注 LLMs 在因果推理任务（如因果发现和反事实推理）中的应用潜力，但在视觉因果推理任务中，相关研究还相对缺乏。为了解决上述问题，本文正式介绍了一项针对多模态上下文学习的视觉因果推理基准（CausalVLBench），包含三个代表性的任务：因果结构推理、干预目标预测和反事实预测。
### Innovation
本文提出了一个针对 LVLMs 的视觉因果推理基准（CausalVLBench），包括因果结构推理、干预目标预测和反事实预测等三个任务。使用最先进的 LVLMs 对这些因果推理任务进行了评估，并揭示了现有视觉语言模型的不足，激发了改进 LVLMs 视觉因果推理能力的新方向。
### Conclusion
希望本基准能够揭示现有视觉语言模型的不足，促使新的方向和方法以提高 LVLMs 在视觉因果推理能力方面的表现。
## 967. `cs.LG` - 多尺度微调用于基于编码器的时间序列基础模型 [PDF](https://arxiv.org/pdf/2506.14087), [HTML](https://arxiv.org/abs/2506.14087)
### Authors
Zhongzheng Qiao,Chenghao Liu,Yiming Zhang,Ming Jin,Quang Pham,Qingsong Wen,P.N. Suganthan,Xudong Jiang,Savitha Ramasamy
### Background
时间序列基础模型（TSFMs）在时间序列预测方面展示了出色的零样本性能。然而，一个重要的但尚未充分探索的挑战是如何有效地在特定下游任务上微调TSFMs。尽管简单的微调方法可以取得性能提升，但它们往往无法充分利用TSFMs的能力，导致过度拟合和次优性能。基于TSFsMs在不同采样尺度上具有多种时间模式的多样性以及其固有的多尺度预测能力，研究者通过因果视角分析了微调过程，强调了显式建模多尺度的重要性，并指出了简单方法的不足。
### Innovation
研究提出了一种名为多尺度微调（MSFT）的简单而通用的框架，旨在将多尺度建模明确集成到微调过程中。实验结果表明，使用MSFT微调的TSFMs不仅优于简单的和常见的参数高效微调方法，而且超过了最先进的深度学习方法。
### Conclusion
基于三个不同基础结构（Moirai, Moment 和 Units）的实验结果显示，使用MSFT进行微调的TSFMs在性能上优于其他方法。进一步的实验将代码开源，以促进该领域的研究进步。
## 968. `cs.LG` - 通过通用软操作和鲁棒强化学习进行离散组合生成 [PDF](https://arxiv.org/pdf/2506.17007), [HTML](https://arxiv.org/abs/2506.17007)
### Authors
Marco Jiralerspong,Esther Derman,Danilo Vucetic,Nikolay Malkin,Bilun Sun,Tianyu Zhang,Pierre-Luc Bacon,Gauthier Gidel
### Background
在科学研究中，缩小一个指数级大的对象集合（如蛋白质或分子）到仅有少量具有理想属性的候选对象是一个主要瓶颈。虽然此过程可以借助专家知识，但近期的研究使用由代理奖励函数引导的强化学习（RL）来解决筛选问题。通过采用多种形式的熵正则化，这些方法旨在学习生成多样性候选对象的采样器，这些候选对象在代理函数中得分较高。
### Innovation
本文做出了两项主要贡献。首先，我们发现这些方法倾向于在大型搜索空间中生成过度多样且表现不佳的候选对象。为此，我们引入了一个新的统一操作，该操作结合了几种正则化RL操作，形成一个更适用于峰值采样分布的通用框架。其次，我们提供了一种关于这个筛选过程的新型鲁棒RL视角。正则化可以解释为代理函数中的组成形式不确定性（即，候选对象的真实评估与代理评估不同）的鲁棒性。我们的分析引领我们开发了一种新颖且易于使用的新算法——轨迹通用温和最大值（TGM）：我们发现它在合成和真实任务中都比基线算法识别出更高的质量、更多样化的候选对象。
### Conclusion
我们的分析导致我们提出了一个名为轨迹通用温和最大值（TGM）的新颖且易于使用算法，在合成和实际任务中，它都比基线方法识别出更高的质量、更多样化的候选对象。
## 969. `cs.LG` - 向更深的预言编码神经网络的训练 [PDF](https://arxiv.org/pdf/2506.23800), [HTML](https://arxiv.org/abs/2506.23800)
### Authors
Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori
### Background
预言编码网络是一种通过迭代能量最小化过程进行推理的神经模型，其操作在时间和空间上都是局部的。这种模型在浅层架构中表现良好，但在超过五到七层后性能会显著下降。
### Innovation
作者揭示了性能下降的原因是权重更新过程中各层之间能量误差的指数级失衡，以及前一层的预测对深层权重更新的指导作用不强。通过引入一种基于精度加权的隐变量优化，在松弛阶段平衡错误分布，提出了一种新的权重更新机制减少深层错误积累，并利用辅助神经元减缓残差连接中能量的传播速度，解决了上述三个问题。
### Conclusion
实验上，作者的方法在深层模型（如ResNets）上达到了与反向传播相当的性能，为复杂任务中的预言编码开辟了新的可能。
## 970. `cs.LG` - EFRame: 通过探索-过滤-重播强化学习框架实现更深层次的推理 [PDF](https://arxiv.org/pdf/2506.22200), [HTML](https://arxiv.org/abs/2506.22200)
### Authors
Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yuzhi Zhang,Yue Wang
### Background
最近在强化学习（RL）方面取得的进展显著提升了大型语言模型（LLMs）的推理能力。GRPO（Group Relative Policy Optimization），作为一种Proximal Policy Optimization（PPO）的轻量级变体，提高了效率，但面临探索不足和训练不稳定的问题，这些限制了它在复杂推理任务中的效果。为了应对这些挑战，本文提出了EFRame，一种探索-过滤-重播框架，通过三个维度来增强GRPO：增加额外的采样便于更深入和有针对性的探索，线上过滤删除低质量样本以稳定梯度和加速训练，经验重播放大稀有但具有信息价值的轨迹以实现稳定收敛。这种统一框架建立了一个平衡探索、效率和稳定性的训练周期。实验结果显示，EFRame在多种推理基准上取得了持续的改进，例如在Geometry3K上的改进为37.9%。EFRame还支持细粒度样本分类和精确的熵控制，显示出它作为实现LLMs更深层次推理的稳健解决方案的优势。
### Innovation
提出了EFRame，一种探索-过滤-重播框架，旨在通过增加额外的采样、线上过滤低质量样本以及经验重播来增强GRPO在复杂推理任务中的效果。该框架能更好平衡探索、效率和稳定性的训练周期，并在多种推理基准上展示了持续的改进效果，特别是在Geometry3K上的显著提升。
### Conclusion
EFRame通过引入探索-过滤-重播框架，有效地解决了GRPO中的探索不足和训练不稳定问题，使得大型语言模型在执行更深层次的推理任务时更加有效和稳定。其在各推理基准上的表现证明了该方法的有效性和优越性，进一步强调了其作为推进大型语言模型推理能力的关键工具的重要性。
## 971. `cs.LG` - Bures-Wasserstein Flow Matching for Graph Generation [PDF](https://arxiv.org/pdf/2506.14020), [HTML](https://arxiv.org/abs/2506.14020)
### Authors
Keyue Jiang,Jiahao Cui,Xiaowen Dong,Laura Toni
### Background
图生成已成为药物发现、电路设计等多个领域的关键任务。现有的图生成方法，如扩散和流式模型，通过构造在参考分布和数据分布之间插值的概率路径，达到了良好的图生成性能。然而，这些方法通常独立地模拟节点和边的演变，并使用线性插值来构建路径，这种分离插值破坏了图之间的互联模式，导致构造的概率路径不规则且非光滑，从而影响训练动态和采样收敛性。因此，针对这一局限性，论文首先提出了图生成模型中概率路径构造的理论框架，通过使用马尔可夫随机字段（MRF）参数化的连接系统来联合建模节点和边的演变，进一步利用MRF对象之间的最优传输位移设计了一种平滑的概率路径，以确保图组件的共同演变。
### Innovation
提出了Bures-Wasserstein流匹配框架（BWFlow），利用从MRF对象之间的最优传输位移中得出的概率路径来改进训练和采样算法设计。该方法通过使用马尔可夫随机字段参数化的连接系统来建模节点和边的联合演变，并利用最优传输设计理念确保图组件的共同演变，从而提高生成模型的有效性和效率，特别是在典型图生成和分子生成中表现出了优越的性能、更快的训练收敛性和高效的采样能力。
### Conclusion
实验结果表明，与现有图生成方法相比，BWFlow在图生成和分子生成任务中表现出了竞争力，具有更好的训练收敛性和高效的采样效率。
## 972. `cs.LG` - 揭开神经网络黑箱之谜：动态极值映射器 [PDF](https://arxiv.org/pdf/2507.03885), [HTML](https://arxiv.org/abs/2507.03885)
### Authors
Shengjian Chen
### Background
研究指出，神经网络并非黑箱，其泛化能力源于能够动态将数据集映射到模型函数的极值上。论文进一步证明，神经网络中的极值数量与参数数量呈正相关。
### Innovation
提出了一种新的算法，主要通过求解线性方程组获得参数值，这种方法与反向传播算法显著不同。该框架简单地解释并处理了一些难于克服的问题，如梯度消失和过拟合。
### Conclusion
研究通过证明极值数量与参数数量的正相关关系，提出的新算法不仅解决了传统反向传播算法中的问题，还简化了对于复杂情况的处理和解释。
## 973. `cs.LG` - 不窥视调优：LLM后训练的可证明隐私性和泛化界 [PDF](https://arxiv.org/pdf/2507.01752), [HTML](https://arxiv.org/abs/2507.01752)
### Authors
Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud
### Background
梯度优化是深度学习的基础，通过反向传播提供高效的可扩展训练，但在训练过程中暴露梯度可能会泄露底层数据的敏感信息，引发隐私和安全问题，如数据中毒攻击。相比之下，黑盒优化方法将模型视为不透明的函数，依赖于函数评估指导优化，这在限制数据访问、高对抗风险或过拟合的情况下提供了一个有前景的替代方案。这项研究介导了一个新的方法BBoxER，旨在通过对训练数据的隐式压缩来实现信息瓶颈，以解决这些问题。
### Innovation
论文引入了一个新的黑盒优化方法BBoxER，通过对训练数据的隐式压缩实现了信息瓶颈，在实验中展示了不依赖梯度优化方法的优化方案在大规模语言模型后训练中的有效性和稳健性，特别是通过少量迭代能够提升性能，泛化能力强，并且能够抵抗群体推理攻击。这种方法提供了可证明的隐私保护和非空泛化边界，为在资源受限或隐私敏感环境中部署提供了一个更具吸引力的选择。
### Conclusion
BBoxER不仅解决了黑盒优化方法固有的可扩展性挑战，还展示了在实际应用中的有效性。该方法作为一种调优工具，既适用于资源有限或隐私敏感的环境，又能提供实质性的泛化保证，为深度学习系统提供了新的可行方案。
## 974. `cs.LG` - 大型语言模型代理在药物发现中模块化任务执行 [PDF](https://arxiv.org/pdf/2507.02925), [HTML](https://arxiv.org/abs/2507.02925)
### Authors
Janghoon Ock,Radheesh Sharma Meda,Srivathsan Badrinarayanan,Neha S. Aluru,Achuth Chandrasekhar,Amir Barati Farimani
### Background
本文介绍了一个基于大型语言模型（LLMs）的模块化框架，该框架可以自动化和简化计算药物发现早期阶段的关键任务。通过结合LLM推理和特定领域的工具，框架实现了生物医学数据检索、特定领域的问答、分子生成、性质预测、基于性质的分子细化以及三维蛋白质-配体结构生成等多项功能。在BCL-2淋巴细胞白血病靶点的研究案例中，代理能够自主检索相关生物大分子信息，并比标准的LLMs在机制问题上的回答中具有更好的上下文准确性。
### Innovation
本文的创新在于提出了一种结合大型语言模型和特定领域工具的模块化框架，该框架能够自动化和简化药物发现早期阶段的关键任务。该框架在特定领域的问答、分子生成与优化、性质预测以及三维结构生成等方面发挥作用。特别是在BCL-2淋巴细胞白血病靶点的研究案例中，代理能够自主检索各种相关信息并生成新颖的候选化合物，这展示了一种有效的分子筛选和优先级设置方式，同时该模块化设计也为未来工具和技术的集成奠定了基础，从而有望支持计算辅助药物发现过程的进一步发展和优化。
### Conclusion
该模块化框架不仅展示了在分子筛选、优先级设定和结构评估方面有效的支持，还通过BCL-2淋巴细胞白血病靶点的具体研究 cases，证明了该框架能够提高分子质量（如QED > 0.6）的比例，并且可扩展性强，便于未来工具和模型的集成。该研究的结果强调了将语言模型与特定领域工具相结合的重要性，为AI辅助药物发现提供了一种有潜力的解决方案。
## 975. `cs.LG` - ROC-n-reroll: 当验证器不完美时，如何影响测试时缩放 [PDF](https://arxiv.org/pdf/2507.12399), [HTML](https://arxiv.org/abs/2507.12399)
### Authors
Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang
### Background
测试时缩放的目标是在推理过程中利用额外的计算资源来提高语言模型的性能。许多研究已经研究了诸如Best-of-N（BoN）和拒绝采样（RS）等技术，这些技术利用验证器来实现测试时缩放。然而，到目前为止，很少有人理论性地理解验证器不完美性如何影响性能。本研究填补了这一空白。
### Innovation
证明了这些方法的实例级准确度精确地由验证器ROC曲线的几何形状表征。研究表明，在固定计算资源下RS优于BoN，但在无限计算资源限制下两种方法收敛至相同的准确性。此外，基于低计算资源观察预测高计算资源性能通常是不可能的。
### Conclusion
本研究强调了验证器不完美性对测试时缩放性能的关键影响，并通过Qwen和LLama模型在GSM8K和MATH500上的实验验证了理论结果。
## 976. `cs.LG` - AMS 电路中通过图对比学习和标签重平衡实现可迁移的寄生估计 [PDF](https://arxiv.org/pdf/2507.06535), [HTML](https://arxiv.org/abs/2507.06535)
### Authors
Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu
### Background
在模拟混合信号（AMS）电路中，图表示学习对于各种下游任务，例如寄生估测至关重要。然而，设计数据的稀缺性、标签分布的不平衡以及电路实现固有的多样性都给学习具有鲁棒性和可移植性的电路表示带来了重大挑战。
### Innovation
为应对这些限制，提出了CircuitGCL，这是一种新颖的图对比学习框架，通过整合表示分散和标签重平衡来增强异构电路图之间的可移植性。CircuitGCL通过超球面表示分散采用自监督策略学习拓扑不变的节点嵌入，消除了对大规模数据的依赖。引入了平衡均方误差（BMSE）和平衡的软最大交叉熵（BSCE）损失，以降低电路之间的标签分布差异，从而实现稳健和可移植的寄生估计。
### Conclusion
在TSMC 28nm AMS设计的寄生电容估计（边级任务）和地电容分类（节点级任务）上评估了CircuitGCL，结果显示其优于所有最先进的方法，以％为单位，边回归的$R^2$改进率从33.64到44.20，节点分类的F1分数提升从1.9倍到2.1倍。
## 977. `cs.LG` - 通过机器学习实现网络化信息聚合 [PDF](https://arxiv.org/pdf/2507.09683), [HTML](https://arxiv.org/abs/2507.09683)
### Authors
Michael Kearns,Aaron Roth,Emily Ryu
### Background
该研究探讨了一种分布式学习问题，其中学习代理嵌入在一个有向无环图（DAG）中。DAG中的每个节点只能直接观察到数据集的一部分特征，每个节点按照拓扑排序的顺序顺序学习，并使用从其父节点接收到的预测信息来增强自己的模型。研究集中在这种分布式学习过程中能否实现信息聚合，即是否有可能某些节点能够学习到一个模型，该模型的误差与能够访问所有特征的最佳模型相当，尽管网络中的任何单一节点都没有这样的访问权限。研究还考虑了线性和一般假设类的情况，并提供了上界和下界。
### Innovation
本文创新点在于推出了DAG的深度作为关键参数，证明了只要路径足够长且所有相关特征在路径中得到充分表示，信息聚合就能发生。此外，研究还发现了即使在网络有足够节点和路径情况下，依然存在某些分布使得信息聚合不可能。这项工作首次考虑了这种分布特征在网络上的信息聚合问题，并提供了理论上的上界和下界。实验结果验证了理论分析的有效性。
### Conclusion
本文研究了DAG上分布式学习中的信息聚合问题，证明了在特定条件下路径长度对信息聚合的影响，并提供了线性假设类和一般假设类情况下的上界和下界。同时，指出了某些网络拓扑结构（如中心辐射状）条件下信息聚合不可能的问题，丰富了机器学习在分布式网络中的应用理论。
## 978. `cs.LG` - 基于人类闭环指导实现测试时自我提升代理的学习能力 [PDF](https://arxiv.org/pdf/2507.17131), [HTML](https://arxiv.org/abs/2507.17131)
### Authors
Yufei He,Ruoyu Li,Alex Chen,Yue Liu,Yulin Chen,Yuan Sui,Cheng Chen,Yi Zhu,Luca Luo,Frank Yang,Bryan Hooi
### Background
大型语言模型（LLM）代理在规则和所需专业知识经常变化的环境中（如合规性和用户风险筛选）表现不佳。当前的应对措施，如离线微调和标准提示，由于它们在实际操作过程中无法有效适应新的知识而显得不足。
### Innovation
提出了一种名为自适应反思交互代理（ARIA）的LLM代理框架，专门设计用于在测试时持续学习更新的专业知识。ARIA通过结构化的自我对话评估其不确定性，主动识别知识空白，并从人类专家那里请求有针对性的解释或更正。然后，它系统地使用提供的指导信息更新其内部、带时间戳的知识库，并通过比较和澄清查询解决冲突或过时的知识。
### Conclusion
ARIA 在字节跳动支付平台上的客户尽职调查名称筛查任务以及公开可用的动态知识任务上进行评估，结果显示与标准离线微调和现有自我改进代理基线相比，ARIA 在适应性和准确性方面表现出显著提高。ARIA 已部署在字节跳动支付中，服务于超过 1.5 亿月活跃用户，证明其在快速变化环境中的实际可行性和有效性。
## 979. `cs.LG` - 通信高效的分布式训练用于深度学习中合作平坦极值恢复 [PDF](https://arxiv.org/pdf/2507.20424), [HTML](https://arxiv.org/abs/2507.20424)
### Authors
Tolga Dimlioglu,Anna Choromanska
### Background
研究了集中分布式数据并行训练深度神经网络（DNNs），目标是在局部梯度方法中改进通信效率和模型性能之间的权衡。
### Innovation
提出了一种简单的但有效的尖度度量In逆均谷，并证明其与DNNs的泛化差距有强相关性；引入了一种有效的放松措施，作为轻量级正则化器，纳入分布式训练目标中，鼓励工作节点协作寻求较宽的极值，生成了分布式拉-推力（DPPF）算法。
### Conclusion
实验表明，DPPF在保持通信效率的同时，优于其他通信高效的范例，并比局部梯度方法和同步梯度平均具有更好的泛化性能。此外，损失景观可视化证实了DPPF能够定位更平坦的极值。理论层面证明，DPPF引导工作节点跨越平坦山谷，最终的山谷宽度由拉推力的相互作用决定，其拉-推动力具有自我稳定特性，并提供了与山谷宽度相关的泛化保证，证明了其在非凸情况下的收敛性。
## 980. `cs.LG` - 从ECGs中创建精细可解释的数字表型的原型学习 [PDF](https://arxiv.org/pdf/2508.01521), [HTML](https://arxiv.org/abs/2508.01521)
### Authors
Sahil Sethi,David Chen,Michael C. Burkhart,Nipun Bhandari,Bashar Ramadan,Brett Beaulieu-Jones
### Background
原型神经网络通过将输入与训练数据中学习到的、代表性的信号模式进行比较来提供可解释的预测。此类模型在生理数据分类方面显示出潜力，但尚不清楚原型是否捕捉到与临床表现相关的潜在结构。
### Innovation
研究使用一个原型深度学习模型对PTB-XL数据集进行多标签心电图分类训练，然后在MIMIC-IV临床数据库上进行推理，评估单独的原型（仅用于分类训练）与临床预后之间的显著且具体的关联性，尤其是在各个临床分类中表现出显著的类内距离差异，表明模型了解决了诊断类别内的临床有意义的变化。
### Conclusion
原型模型在不同类型条件下实现了强大的预测性能，AUC值从心房颤动的0.89到心力衰竭的0.91不等，也显示出对非心脏条件（如败血症和肾脏疾病）的显著信号。这些发现表明，原型模型可以从生理时间序列数据中支持可解释的数字表型表征，捕捉到超越原始训练目标的临床相关生理特征。
## 981. `cs.LG` - TriP-LLM: 一种三分支片段化大型语言模型时间序列异常检测框架 [PDF](https://arxiv.org/pdf/2508.00047), [HTML](https://arxiv.org/abs/2508.00047)
### Authors
Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin
### Background
时间序列异常检测在众多应用领域中扮演着核心角色。随着物联网（IoT）和智能制造业的广泛应用，时间序列数据在规模和维度上都大幅增长，这些传统统计方法在处理高度异质性和复杂性的数据时暴露出局限性。原有的方法面临着处理大规模和高维度时间序列数据的挑战。
### Innovation
本文提出了一个名为TriP-LLM的新颖的无监督时间序列异常检测框架。该框架创新性地结合了局部和全局时间特征，通过一个由分割、选择和全局模块组成的三分支设计来编码输入的时间序列，然后利用预训练的大型语言模型进行处理。使用轻量级的片段化解码器重构输入并从中提取异常分数。TriP-LLM在多个公开基准数据集上使用PATE（无需阈值的评价度量），并与统一开源框架中的其他算法进行比较，实验结果表明，该方法在所有数据集上都显著优于最新的方法，并且相比基于通道独立性的方法具有更低的记忆消耗，更适用于GPU内存受限的环境。
### Conclusion
实验结果表明，TriP-LLM在所有数据集上都表现出更强大的检测能力，相比现有的基于大型语言模型的方法，具有更低的记忆消耗，更适用于GPU内存受限的环境。所有代码和模型检查点都已公开发布，以促进进一步的研究和应用。
## 982. `cs.LG` - VAGPO: 视觉增强的非对称群偏好优化方法在图路由问题中的应用 [PDF](https://arxiv.org/pdf/2508.01774), [HTML](https://arxiv.org/abs/2508.01774)
### Authors
Shiyan Liu,Bohan Tan,Zhiguang Cao,Yan Jin
### Background
在网络相关的图形中，找到最优路径对于高效的数据传输和内容交付至关重要。经典的图路由问题如旅行商问题（TSP）和带有容量限制的车辆路径问题（CVRP）为基本的图形优化挑战。虽然近期的数据驱动优化方法取得了显著进步，但它们在训练效率和对大规模实例的泛化能力方面仍存在局限。
### Innovation
本文提出了一个名为视觉增强的非对称群偏好优化（VAGPO）的新颖方法。VAGPO方法利用基于ResNet的视觉编码和基于Transformer的序列建模来捕捉时空结构和依赖性。此外，引入了一个非对称群偏好优化策略，相比通常使用的策略梯度方法，该策略显著加快了收敛速度。实验结果表明，提出的VAGPO方法在生成的TSP和CVRP实例以及实际数据集上获得了具有竞争力的解质量，并且VAGPO在更大的实例（多达1000个节点）上表现出强大的泛化能力，无需重新训练，从而突显了其在学习效率和可扩展性方面的优势。
### Conclusion
实验结果显示，提出的VAGPO方法在生成和实际数据集上的解质量都非常出色，并且展示了其在大实例中的强大泛化能力，无需重新训练，证明了其在学习效率和可扩展性方面优于现有技术。
## 983. `cs.LG` - 量化交易中的语言模型引导强化学习 [PDF](https://arxiv.org/pdf/2508.02366), [HTML](https://arxiv.org/abs/2508.02366)
### Authors
Adam Darmanin,Vince Vella
### Background
算法交易需要在长期金融目标指导下做出短期战术决策。尽管强化学习已被应用于此类问题，但由于其短视行为和不透明政策，其采纳率受到限制。大型语言模型可以提供战略性推理和多模态信号解释，但需通过结构良好的提示进行指导。
### Innovation
本文提出了一种结合框架，在该框架中，大型语言模型生成高层次的交易策略，以指导强化学习代理。通过对专家评审和使用夏普比率和最大回撤来评估LLM指导的代理性能，结果表明LLM指导可以改善回报和风险指标，相比标准RL方法效果更好。
### Conclusion
语料库中的实验结果表明，大型语言模型的指导可以在提高回报和风险指标方面优于标准的RL方法。
## 984. `cs.LG` - 基于Lyapunov函数分析学习率和批次大小调度加速SGDM [PDF](https://arxiv.org/pdf/2508.03105), [HTML](https://arxiv.org/abs/2508.03105)
### Authors
Yuichi Kondo,Hideaki Iiduka
### Background
本研究分析了带动量的随机梯度下降（SGDM）算法在动态学习率和批次大小调度下的收敛行为。文章引入了新的简化Lyapunov函数来分析这种调度策略下的收敛性。研究扩展了现有的理论框架，涵盖了三种常见的深度学习调度策略：恒定批次大小伴随学习率衰减、批次大小增加伴随学习率衰减以及批次大小和学习率都增加。这些策略在实际应用中广泛使用。
### Innovation
本文对现有的理论框架进行了扩展，通过引入一种简化后的Lyapunov函数，首次全面分析了动态学习率和批次大小不同调度策略下的SGDM算法收敛性。研究揭示了不同调度策略下SGDM算法的收敛速度存在明显差异：恒定批次大小不保证梯度的期望范数收敛；增加批次大小可以保证梯度的期望范数收敛；同时增加批次大小和学习率可以导致更快速的收敛速度。
### Conclusion
理论分析与实验结果表明，动态调度的SGDM显著优于固定超参数的SGDM，特别是在收敛速度方面。研究还发现了一个新的调度策略（warm-up调度）在实验中表现出更好的收敛行为。
## 985. `cs.LG` - 探索中的推理：一种强化学习框架以实现稳健的功能调用 [PDF](https://arxiv.org/pdf/2508.05118), [HTML](https://arxiv.org/abs/2508.05118)
### Authors
Bingguang Hao,Zengzhuang Xu,Maolin Wang,Yuntao Wen,Yicheng Chen,Cunyin Peng,Long Chen,Dong Wang,Xiangyu Zhao,Jinjie Gu,Chenyi Zhuang,Ji Zhang
### Background
对大型语言模型（LLMs）进行有效的函数调用训练面临着一个关键挑战，即在探索复杂推理路径和稳定策略优化之间取得平衡。传统的监督微调（SFT）方法无法培养稳健的推理能力，而传统的强化学习（RL）在探索效率方面存在困难。
### Innovation
我们提出了一个新的RL框架EGPO，该框架基于群体相对策略优化（GRPO），旨在直接解决这一挑战。EGPO的核心是一个增强熵的优势函数，将模型Chain-of-Thought（CoT）的熵整合到策略梯度计算中，以鼓励生成多样化的推理策略。通过引入一个裁剪机制来谨慎地限制熵奖金，它确保了优化的方向。用严格的二进制奖励信号作为补充，EGPO有效地引导模型发现结构化的准确工具调用模式。
### Conclusion
在具有挑战性的伯克利函数调用排行榜（BFCL）上，使用EGPO训练的4B参数模型在与之相当规模的模型中达到了新的最先进的成果，超越了包括GPT-4o和Gemini-2.5在内的一系列强劲竞争对手。
## 986. `cs.LG` - AMFT：通过元学习最优模仿探索平衡来对齐大语言模型推理器 [PDF](https://arxiv.org/pdf/2508.06944), [HTML](https://arxiv.org/abs/2508.06944)
### Authors
Lixuan He,Jie Feng,Yong Li
### Background
大语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）的两阶段管道进行定制，但这种方法容易遭受灾难性遗忘和模仿与探索之间的次优权衡。单一阶段的方法试图通过启发式方法弥合并使用SFT和RL，但缺乏一种原理性机制来动态平衡这两种范式。
### Innovation
本文通过隐含奖励的理论框架重新定义这一挑战，将SFT和RL视作互补的奖励信号，而非独立的方法。提出了一种新颖的一阶段算法——自适应元微调（AMFT），该算法学习SFT的隐含路径级奖励和RL的显式结果导向奖励之间的最优平衡。AMFT的核心是一个元梯度自适应权重控制器，将SFT-RL平衡视为可学习参数，动态优化以最大化长期任务性能。通过增加策略熵以提高稳定性，该方法自主发现有效的训练课程，并通过全面评估和消融研究验证其在数学推理、抽象视觉推理（通用点）和视觉语言导航（V-IRL）中的成功率。
### Conclusion
AMFT始终建立了新的性能基准，并在离分布任务上展示了更好的泛化能力。通过学习控制器验证其稳定性、样本效率和性能，提供了对齐大语言模型的一种更原理性和更有效的范式。
## 987. `cs.LG` - 在策略性强化学习遇见离策略专家：通过动态加权实现监督微调与强化学习的协调 [PDF](https://arxiv.org/pdf/2508.11408), [HTML](https://arxiv.org/abs/2508.11408)
### Authors
Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou
### Background
现有的监督微调（SFT）和强化学习（RL）结合方法在提升大型语言模型（LLMs）的能力和行为对齐时，容易破坏已有的响应模式，并导致对专家数据的过度拟合。为了应对这一挑战，研究人员提出了一种新的视角，通过离策略与在策略的对比来综合考虑SFT和RL。
### Innovation
提出了一种名为CHORD的新框架（Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting），该框架重新定义SFT作为在策略RL过程中的动态加权辅助目标，而非独立阶段。CHORD框架中加入了一种双重控制机制，首先使用全局系数在整体上引导从离策略模仿到在策略探索的转变，然后应用一个按词权重函数，以粒度化的方式从专家数据中学习，促进在策略探索并减轻离策略数据的干扰。
### Conclusion
通过实证研究，CHORD框架在数学推理问题和实际工具使用任务上展示了稳定的、高效的强化学习过程，并且相较于基线方法有显著改进。研究者已发布了CHORD的实现代码，以激发进一步的研究。
## 988. `cs.LG` - 任务向量与梯度 [PDF](https://arxiv.org/pdf/2508.16082), [HTML](https://arxiv.org/abs/2508.16082)
### Authors
Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà
### Background
任务算术作为一种简单而强大的技术，已经在模型合并中取得了显著成效，能够将多个微调模型合并成一个。尽管它在实践中成功应用，但为什么以及在什么情况下它有效缺乏明确的理论解释。本文通过建立任务向量和任务损失梯度之间的联系，为任务算术提供了坚实的理论基础。
### Innovation
作者证明，在标准梯度下降的情况下，一个从一个微调周期生成的任务向量等同于损失的负梯度，放大了学习率。对于多周期的实际设置，证明了这种等价性近似成立，对于前向网络，给出了二次误差项的显式边界。实证分析在七个视觉基准中的结果支持了理论，表明第一周期梯度在范数和方向上主导着微调轨迹。关键影响是，微调训练仅一个周期的模型合并往往能达到完全收敛模型合并的性能。
### Conclusion
这些发现将任务算术重新定义为近似多任务学习的形式，清晰地阐明了其有效性，并突显了早期训练动力学在模型合并中的关键作用。
## 989. `cs.LG` - 评估数据驱动回归模型校准过程中的量化不确定性质量 [PDF](https://arxiv.org/pdf/2508.17761), [HTML](https://arxiv.org/abs/2508.17761)
### Authors
Jelke Wibbeke,Nico Schönfisch,Sebastian Rohjans,Andreas Rauh
### Background
在安全关键应用中，数据驱动模型不仅需要准确，还需提供可靠的不确定性估计。这一特性，通常称为校准，在风险意识决策中是必要的。回归分析中出现了多种校准度量和校准方法，但这些度量在定义、假设和尺度上差异很大，使得跨研究解释和对比结果困难。此外，大多数校准方法仅使用少数几种度量进行评估，使得不清楚这些改进是否能在不同的校准度量中普遍适用。因此，研究者强调了系统地从文献中提取和分类回归校准度量，并独立于特定建模方法或校准方法，对这些度量进行基准测试的重要性。
### Innovation
本文系统地从文献中提取和分类了回归校准度量，并通过受控实验比较了它们在实际、合成和人为校准数据上的表现。研究发现，不同的校准度量经常产生矛盾的结果，并揭示了显著的不一致性：许多度量对同一校准结果的评价存在分歧，有些甚至给出互相矛盾的结论。研究中还指出了两个度量（Expected Normalized Calibration Error (ENCE) 和 Coverage Width-based Criterion (CWC)）作为最可靠的度量。
### Conclusion
本文的研究结果突显了在校准研究中选择度量的重要性。
## 990. `cs.LG` - 现代递归模型中的再审视: 关联记忆 [PDF](https://arxiv.org/pdf/2508.19029), [HTML](https://arxiv.org/abs/2508.19029)
### Authors
Destiny Okpekpe,Antonio Orvieto
### Background
尽管现代递归深度学习模型（例如状态空间模型）具有亚 quadratic 复杂度的优势，但最近的研究表明，它们在推理和记忆任务上的表现可能不如变换器。本文深入探讨了其中的一个基准任务：关联回忆（AR），该任务已被证明与语言建模表现高度相关，并详细检查了最新提出的令牌混合策略中的缩放和优化问题的影响。
### Innovation
本文首先表明，与标准变换器不同，学习率的选择对于现代递归模型的性能至关重要：这可能会严重影响先前工作的报告性能，建议进一步研究以保证训练的稳定性。其次，研究发现递归和基于注意力的模型在宽度和深度扩展时表现出不同的优势，注意力在单层限制下明显无法解决AR任务。然后进一步分析了一层变换器，发现尽管它们的表现较差，但它们的训练动态令人惊讶地与头的归纳形成过程相似，这是之前仅在它们的两层对应物中观察到的现象。最后，通过架构删减，研究了组件如何影响Transformer和Mamba的性能与优化稳定性。
### Conclusion
研究还发现一层变换器的独特行为以及递归和基于注意力的模型在扩展方面的不同表现。这些观察结果表明可能需要针对递归模型的设计和优化方法进行进一步研究，以更好地理解它们在关联回忆任务等复杂任务中的局限性。
## 991. `cs.LG` - 通过期望最大化在多智能体强化学习中的潜在变量建模用于基于无人机的野生动物保护 [PDF](https://arxiv.org/pdf/2509.02579), [HTML](https://arxiv.org/abs/2509.02579)
### Authors
Mazyar Taghavi,Rahman Farnoosh
### Background
在广大且部分不可观测的环境中保护濒危野生动物免受非法猎杀是一个关键性的挑战，尤其是需要实时响应的情况下。本文通过多智能体强化学习（MARL）框架中的无人机协调，提出了一种基于期望最大化（EM）的潜在变量建模方法，以实现在这类复杂环境中的有效保护。
### Innovation
本文引入了一种新颖的方法，即基于期望最大化（EM）的潜在变量建模方法，应用于多智能体强化学习（MARL）框架下无人机的协调，通过模拟隐藏环境因素和智能体间动态，增强了在网络环境中进行探索与协调的能力。
### Conclusion
本文的实验证明，与标准算法如近端策略优化（PPO）和深度确定性策略梯度（DDPG）相比，提出的EM-MARL框架在检测精度、适应性和策略收敛性方面性能更优。研究成果强调了将EM推理与MARL结合可以在复杂、高风险保育场景中提高分散化决策制定的潜力。
## 992. `cs.LG` - 从联邦学习到X学习：通过随机游走打破去中心化的障碍 [PDF](https://arxiv.org/pdf/2509.03709), [HTML](https://arxiv.org/abs/2509.03709)
### Authors
Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour
### Background
该文旨在探讨X学习(X-Learning)这一分布式学习架构，该架构是对去中心化概念的一种扩展。背景在于现有的去中心化学习方法和联邦学习存在一定的局限性，本文尝试通过引入X学习来解决这些问题，并表明X学习与图论和马尔可夫链之间的联系。
### Innovation
文章创新性地提出了一种新型的分布式学习架构——X学习，它可以解决现有的去中心化学习方法存在的问题。创新之处在于揭示了X学习与图论及马尔可夫链之间的非直观但重要的联系，并提出了多个开放的研究方向，以激发更多的研究工作。
### Conclusion
文章通过将X学习与随机游走相结合，提出了一种新的去中心化学习架构，旨在打破传统的去中心化学习限制，并提出了未来研究的方向。
## 993. `cs.LG` - DQS: 一种低成本的查询策略以增强无监督数据驱动的异常检测方法 [PDF](https://arxiv.org/pdf/2509.05663), [HTML](https://arxiv.org/abs/2509.05663)
### Authors
Lucas Correia,Jan-Christoph Goos,Thomas Bäck,Anna V. Kononova
### Background
现有的时间序列异常检测方法中，真正的无监督方法罕见，那些存在的方法由于阈值设定不合理而影响了检测性能；而其他被称作无监督的方法往往需要使用标记数据子集进行校准，这在现实中往往是不可获得的。本文通过结合主动学习策略和现有无监督异常检测方法，选择性地查询多元时间序列的标签并优化阈值选择过程。
### Innovation
本文提出了一种新的查询策略，称为基于不相似性查询策略（DQS）。DQS 旨在通过动态时间规整评估异常得分之间的相似性，最大化查询样本的多样性，进而优化无监督异常检测方法。文章还探讨了误标记影响下的检测性能，这是文献中较少关注的问题。
### Conclusion
研究表明在预算有限的情况下，DQS 表现最佳，但在面临误标记时其他策略更加稳健。因此，实际选择查询策略时需要考虑专家知识和标记样本的数量。无论如何，所有查询策略都优于无监督阈值，并在这种情况下推荐使用基于主动学习的阈值。
## 994. `cs.LG` - 适配的LoRA专家分配与选择用于联合细调 [PDF](https://arxiv.org/pdf/2509.15087), [HTML](https://arxiv.org/abs/2509.15087)
### Authors
Lei Wang,Jieming Bian,Letian Zhang,Jie Xu
### Background
大型语言模型（LLMs）在多项任务中表现出色，但在针对特定领域进行微调时，通常需要大量的特定领域数据，这些数据可能分散在多个组织中。联邦学习（FL）提供了一种隐私保护的解决方案，但在应用于LLMs时面临着计算资源限制的挑战。低秩适应（LoRA）作为一种参数效率高的微调方法已经出现，但它在处理不同领域异质数据时表现不佳。因此，本文专注于解决联邦LoRA微调中的两个关键挑战：1）跨异质客户端确定LoRA专家的最佳数量和分配，以及2）使客户端根据其数据特征选择性地使用这些专家。
### Innovation
本文提出了FedLEASE（联邦适应LoRA专家分配与选择）框架，这是一种新颖的方法，它基于表示相似性对客户端进行自适应分组，以分配和训练领域特定的LoRA专家，并引入了一种自适应顶级-M混合专家机制，允许每个客户端选择最优数量的利用专家。该方法在多种基准数据集上的大量实验表明，与现有的联合微调方法相比，FedLEASE在异质客户端设置中表现出更优性能，同时保持高效的通信效率。
### Conclusion
FedLEASE通过自适应地集群客户端并分配和培训领域特异的LoRA专家，有效地解决了联邦LoRA微调中的两个关键挑战。此外，它还引入了自适应的顶级-M混合专家机制，使每个客户端能够根据其数据特征灵活地选择使用专家的数量。实验结果表明，FedLEASE在异质客户端环境下显著优于现有的联合微调方法，且在通信效率方面保持高效。
## 995. `cs.LG` - 稳健的字节跳动大型语言模型训练基础设施 [PDF](https://arxiv.org/pdf/2509.16293), [HTML](https://arxiv.org/abs/2509.16293)
### Authors
Borui Wan,Gaohong Liu,Zuquan Song,Jun Wang,Yun Zhang,Guangming Sheng,Shuguang Wang,Houmin Wei,Chenyuan Wang,Weiqiang Lou,Xi Yang,Mofan Zhang,Kaihua Jiang,Cheng Ren,Xiaoyun Zhi,Menghan Yu,Zhe Nan,Zhuolin Zheng,Baoquan Zhong,Qinlong Wang,Huan Yu,Jinxin Chi,Wang Zhang,Yuhan Li,Zixian Du,Sida Zhao,Yongqiang Zhang,Jingzhe Tang,Zherui Liu,Chuan Wu,Yanghua Peng,Haibin Lin,Wencong Xiao,Xin Liu,Liang Xiang
### Background
大型语言模型（LLMs）的训练规模已达到数千个GPU，并且持续扩张，使得模型学习速度加快。伴随着资源规模的扩大，失败现象（如CUDA错误、NaN值、作业挂起等）变得普遍，这对训练稳定性构成了重大挑战。任何大规模LLM训练基础设施都必须尽力减少训练中断、高效诊断故障和有效应对故障，以实现高效的连续训练。
### Innovation
该论文提出了ByteRobust，这是一种针对LLMs稳健和稳定训练的大规模GPU基础设施管理系统。ByteRobust利用了LLMs训练过程的特殊性，优先考虑在常规处理中检测和恢复故障。通过利用并行性和LLMs训练的特点，ByteRobust实现了高容量的容错、快速故障边界划定和定位，并采用数据驱动的方法进行了优化，全面确保LLMs任务的连续和高效训练。
### Conclusion
ByteRobust已经在超过20万个GPU的生产GPU平台上部署，并在使用9,600个GPU进行为期三个月的训练任务时实现了97%的ETTR（潜在训练时间比）。
## 996. `cs.LG` - MolSpectLLM：一种将光谱分析、分子解析和三维结构生成结合的分子基础模型 [PDF](https://arxiv.org/pdf/2509.21861), [HTML](https://arxiv.org/abs/2509.21861)
### Authors
Shuaike Shen,Jiaqing Xie,Zhuo Yang,Antong Zhang,Shuzhou Sun,Ben Gao,Tianfan Fu,Biqing Qi,Yuqiang Li
### Background
近年来，分子基础模型在分子性质预测和从头设计分子方面取得了显著成效，尤其是在药物发现和反应预测等领域具有广泛应用前景。然而，现有大多数方法仅依赖于SMILES表示，并忽视了实验光谱和三维结构信息这两种捕捉现实场景中分子行为的重要来源。这种局限性在需要考虑立体化学、空间构象和实验验证的任务中显著降低了模型的效果。为了克服这些挑战，作者提出了MolSpectLLM，这是一种基于Qwen2.5-7B预训练的分子基础模型，能够将实验光谱和分子三维结构统一起来。通过明确建模分子光谱，MolSpectLLM在光谱相关的任务中达到了最先进的性能，平均准确率在NMR、IR和MS基准上达到了0.53。MolSpectLLM还在光谱分析任务中表现出色，序列准确率达到15.5%，标记准确率达到41.7%，显著优于大型通用LLM。更重要的是，MolSpectLLM不仅能够有效完成分子解析任务，还能直接从SMILES或光谱输入中生成准确的三维分子结构，实现了光谱分析、分子解析和分子设计的结合。
### Innovation
MolSpectLLM是一种将实验光谱和分子三维结构结合的新型分子基础模型。它能够通过明确建模分子光谱，实现最先进的性能，显著优于现有的大型通用语言模型。更重要的是，MolSpectLLM能够直接从SMILES或光谱输入中生成准确的三维分子结构，实现了光谱分析、分子解析和分子设计的结合，填补了现有方法在这些方面的空白。
### Conclusion
MolSpectLLM不仅在光谱相关的任务中达到了最先进的性能，还在光谱分析、分子解析和分子结构生成任务中表现出色，通过结合实验光谱和分子三维结构，实现了对现有方法的超越，为药物发现和化学反应预测等领域带来了新的机会和挑战。
## 997. `cs.LG` - 时空域多场深度学习在微观结构介质中冲击传播中的应用 [PDF](https://arxiv.org/pdf/2509.16139), [HTML](https://arxiv.org/abs/2509.16139)
### Authors
M. Giselle Fernández-Godino,Meir H. Shachar,Kevin Korner,Jonathan L. Belof,Mukul Kumar,Jonathan Lind,William J. Schill
### Background
预测冲击波在多孔和结构化材料中的传播能力是行星防御和惯性聚变能源追求中的关键挑战。尽管最近在单一领域和简化表示方面取得了进展，但仍难以捕捉到孔隙塌陷、非寻常Hugoniot响应和局部加热等现象，这些现象强烈影响了小行星偏转或聚变点火。
### Innovation
我们引入了一种时空多场模型（MSTM），将压力、密度、温度、能量、材料分布以及两个速度分量统一为一个自回归代理模型。该模型基于高保真流体动力代码数据进行训练，能够捕获从多孔和结构化配置中非线性的冲击驱动动力学，误差分别降到1.4%和3.2%，同时加速了计算过程超过三个数量级。相对于单一领域时空模型，MSTM降低了均方误差和结构差异性94%。这一进展使一度被认为是不可解决的问题转化为可解决的设计研究，建立了一个实用框架来优化在行星碰撞缓解和惯性聚变能中的介观结构材料。
### Conclusion
MSTM通过时空多场模型的引入，成功解决了冲击波在复杂材料中的传播预测难题，提供了高效且准确的模拟方法，并建立了优化介观结构材料的实用框架。
## 998. `cs.LG` - Cell2Text: 多模态大语言模型，用于从RNA测序数据生成单细胞描述 [PDF](https://arxiv.org/pdf/2509.24840), [HTML](https://arxiv.org/abs/2509.24840)
### Authors
Oussama Kharouiche,Aris Markogiannakis,Xiao Fei,Michail Chatzianastasis,Michalis Vazirgiannis
### Background
单细胞RNA测序技术使得科学家能够以细胞分辨率测量基因表达，提供细胞类型、状态和疾病环境的信息。最近，单细胞基础模型因其能够从表达谱中学习可转移的表示并在分类和聚类任务中提高性能而成为强大的工具。然而，这些模型受限于离散的预测头，将细胞的复杂性简化为预定义的标签，无法捕捉到生物学家所需的丰富背景解释。
### Innovation
Cell2Text 是一种多模态生成框架，能够将 scRNA-seq 文件转换为结构化的自然语言描述。通过结合单细胞基础模型的基因级嵌入与预先训练的大语言模型，Cell2Text 生成连贯的总结，捕捉细胞身份、组织来源、疾病关联和通路活动，适用于未见过的细胞的泛化。Cell2Text 在分类准确性、本体一致性及文本生成语义一致性方面均优于基线模型，表明将表达数据与自然语言相结合，不仅能提供更强的预测性能，还能提供本质上可解释的输出，指出了无监督注释未知细胞的可扩展路径。
### Conclusion
这些结果表明，将表达数据与自然语言相结合不仅能提供更强的预测性能，还能提供本质上可解释的输出，为实现无监督注释未知细胞的可扩展路径奠定了基础。
## 999. `cs.LG` - Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm [PDF](https://arxiv.org/pdf/2509.23135), [HTML](https://arxiv.org/abs/2509.23135)
### Authors
Yang Chen,Menglin Zou,Jiaqi Zhang,Yitan Zhang,Junyi Yang,Gael Gendron,Libo Zhang,Jiamou Liu,Michael J. Witbrock
### Background
逆强化学习（IRL）通过学习奖励函数来解释专家演示。现代的IRL方法通常使用对抗性（极小极大）形式，该形式在奖励和策略优化之间交替进行，这通常会导致训练不稳定性。最近的非对抗性IRL方法通过能量型形式共同学习奖励和策略以提高稳定性，但缺乏形式上的保证。
### Innovation
本文旨在填补该空白。首先提出了统一的观点，指出经典的非对抗性方法显式或隐式最大化专家行为的似然性，这相当于最小化预期返回的差距。这一点见解促成了主要贡献：信任区域奖励优化（TRRO），这是一种通过最小化最大化过程保证似然性单调改进的框架。将其实施为邻近逆奖励优化（PIRO），这是一种实用且稳定的IRL算法。从理论上讲，TRRO提供了与信任区域策略优化（TRPO）在正向RL中的稳定性保证相关的IRL对应项。从实验上看，PIRO在MuJoCo和Gym-Robotics基准测试中达到或超过了最先进的基准，在奖励恢复、高样本效率政策模仿方面表现优异，并且在现实世界的动物行为建模任务中也表现出色。
### Conclusion
该工作通过TRRO和PIRO提供了稳定性的保证，并在多个基准测试中展示了其有效性和实用性，为IRL领域的发展做出了重要贡献。
## 1000. `cs.LG` - ClustRecNet：一种新颖的端到端深度学习聚类算法推荐框架 [PDF](https://arxiv.org/pdf/2509.25289), [HTML](https://arxiv.org/abs/2509.25289)
### Authors
Mohammadreza Bakhtyari,Bogdan Mazoure,Renato Cordeiro de Amorim,Guillaume Rabusseau,Vladimir Makarenkov
### Background
聚类算法选择是无监督学习中的长期挑战，现有方法依赖于手工设计的元特征和传统的聚类有效性指标（CVIs），但这些方法效果有限且难以适应多样化的数据结构。
### Innovation
文章提出了一种新的基于深度学习（DL）的推荐框架ClustRecNet，用于确定最适合指定数据集的聚类算法。该框架通过构建包含34,000个具有不同结构特性的合成数据集的全面数据仓库，并使用10种流行的聚类算法进行处理，建立了一个监督学习环境。ClustRecNet的网络结构结合了卷积、残差和注意力机制，以捕捉输入数据的局部和全局结构模式。该设计支持端到端的训练，以学习数据集的紧凑表示，并直接推荐最适合的聚类算法，减少了对手工设计的元特征和传统CVIs的依赖。
### Conclusion
在合成数据和真实世界数据基准测试中，ClustRecNet的DL模型在调整兰德指数（ARI）上明显优于传统CVIs和最先进的AutoML聚类推荐方法。在合成数据上，ClustRecNet比卡林斯基-哈拉布欣指数高0.497的ARI；在真实世界数据上，ClustRecNet比表现最佳的AutoML方法高15.3%的ARI。
## 1001. `cs.LG` - 机器学习中锂离子电池锂枝晶检测：基于高斯过程的方法 [PDF](https://arxiv.org/pdf/2509.26234), [HTML](https://arxiv.org/abs/2509.26234)
### Authors
Ayush Patnaik,Jackson Fogelquist,Adam B Zufall,Stephen K Robinson,Xinfan Lin
### Background
锂枝晶在快速充电过程中的沉积是导致电池容量迅速衰减的关键退化机制，还可能引发严重的安全问题。先前的研究已经识别出4.0 V以上的dQ/dV的独特峰值作为锂枝晶形成的标志，但传统的dQ/dV计算方法依赖于带滤波的有限差分，这种做法会放大传感器噪声并引入峰值位置偏差。
### Innovation
本文提出了一种基于高斯过程（GP）的锂枝晶检测框架，直接建模充电-电压关系Q(V)为一个具有校准不确定性的随机过程。此方法利用高斯过程的派生仍然是高斯过程的特性，从后验概率中以分析和概率的方式推断dQ/dV，无需人工平滑，从而实现了稳健的检测。该框架提供以下三个关键优势：(i) 有知觉的噪声推理，其中超参数从数据中学习；(ii) 闭式派生及其置信区间，用于量化的不确定性；(iii) 具备嵌入电池管理系统（BMS）的在线变体的可扩展性。
### Conclusion
基于实验验证，在不同C率（0.2C-1C）和不同温度（0-40°C）的锂离子扣式电池上，该高斯过程方法能可靠地检测低温度、高率充电条件下的锂枝晶峰值，且在基线条件下正确地报告没有峰值。一致的高斯过程识别的差异峰值、减少的电量通过量以及通过参考性能测试测量的容量衰退表明了该方法的准确性和鲁棒性，从而提供了一种实际的实时锂枝晶检测途径。
## 1002. `cs.LG` - CarbonX：使用时间序列基础模型的一种开源计算脱碳工具 [PDF](https://arxiv.org/pdf/2510.01521), [HTML](https://arxiv.org/abs/2510.01521)
### Authors
Diptyaroop Maji,Kang Yang,Prashant Shenoy,Ramesh K Sitaraman,Mani Srivastava
### Background
计算脱碳旨在减少计算和数据中心、交通和建筑环境等社会系统中的碳排放。为了实现这一点，需要准确且详细的碳强度预测，但现有的工具存在一些关键限制：(i) 它们需要电网特定的电力组合数据，这限制了在没有此类信息的情况下使用；(ii) 它们依赖于单独的电网特定模型，这使得覆盖全球具有挑战性；(iii) 它们提供没有不确定性的预测，这对于下游碳意识应用的可靠性有限。
### Innovation
本文介绍了CarbonX，这是一个开源工具，利用时间序列基础模型（TSFMs）进行多种脱碳任务。CarbonX 利用TSFMs 的灵活性，在多种任务如碳强度预测和缺失值填充上表现出色，并可用于多种电网。仅使用历史碳强度数据和一个通用模型，该工具在全球214个电网中实现了零样本预测平均绝对百分比误差（MAPE）为15.82%。在13个基准电网中，CarbonX 的性能与当前顶点技术相当，平均 MAPE 为 9.59%，尾部预测 MAPE 为 16.54%，同时还提供了 95% 的预测区间。CarbonX 能够提供长达21天的预测，而准确性几乎没有下降。进一步而言，当完全调优时，CarbonX 在缺失值填充任务上比统计基线提高了1.2到3.9倍。这些结果表明，CarbonX 可以在数据有限的情况下轻松应用于任何电网，并仍能实现出色的性能，使其成为一个实用的工具来实现全球规模的计算脱碳。
### Conclusion
整体而言，CarbonX 可以被用于任何数据有限的电网并提供出色的预测性能，这是由于其利用时间序列基础模型的灵活性。这使得CarbonX 成为一个实用的全球规模脱碳工具。
## 1003. `cs.LG` - G$^2$RPO: 粒度GRPO实现流模型中的精确奖励 [PDF](https://arxiv.org/pdf/2510.01982), [HTML](https://arxiv.org/abs/2510.01982)
### Authors
Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai
### Background
将在线强化学习（RL）集成到扩散和流模型中，作为一种使生成模型与人类偏好保持一致的有前景的方法，最近开始受到关注。使用随机微分方程（SDE）的随机采样技术在去噪过程中被广泛应用，以生成多种多样的去噪方向，从而为RL探索提供支持。现有的方法尽管能够有效地探索高价值样本，但由于奖励信号稀疏且不宽泛，导致偏好对齐不佳的问题。
### Innovation
本文提出了一种名为G$^2$RPO的新颖框架，该框架能够在流模型的强化学习中精确和全面地评估采样方向的奖励。通过引入单粒度随机采样策略来支持逐步随机探索，并强制奖励与注入噪声高度相关，从而为每个SDE扰动提供更加真实的奖励。同时，为了消除固定粒度去噪中的偏差，引入了多粒度优势整合模块，该模块在多个扩散尺度上计算优势，从而提供对采样方向更加综合和稳健的评估。实验表明，G$^2$RPO相对于现有的基于流的GRPO基准模型具有显著的优势，证明了其有效性和鲁棒性。
### Conclusion
实验结果表明，G$^2$RPO在多种奖励模型下（包括领域内和领域外评估）显著优于现有的基于流的GRPO基准方法，突显其有效性和鲁棒性。
## 1004. `cs.LG` - TabImpute: 使用预训练变换器实现快速准确的零样本缺失数据填充 [PDF](https://arxiv.org/pdf/2510.02625), [HTML](https://arxiv.org/abs/2510.02625)
### Authors
Jacob Feitelberg,Dwaipayan Saha,Kyuseong Choi,Zaid Ahmad,Anish Agarwal,Raaz Dwivedi
### Background
在表格数据环境中，缺失数据是一个普遍存在的问题。现有的解决方案从简单的平均值插补到复杂的生成对抗网络不一而足。但由于在实际领域中性能的巨大差异以及超参数调优所耗费的时间，目前没有默认的插补方法。TabPFN 是一个用于监督学习的最新表格基础模型。在这个背景下，作者提出了一种预训练变压器 TabImpute，它可以在不进行配制或超参数调整的情况下提供快速准确的零样本插补。
### Innovation
作者提出了 TabImpute，这是一种预训练的变压器模型，能够在不进行配置或超参数调整的情况下，以快速和准确的方式进行零样本插补。为了训练和评估 TabImpute，作者还引入了三种创新：一种单元特征化方法、一种合成训练数据生成管道以及一个全面的基准测试 MissBench。这些创新使得 TabImpute 在性能上有了显著的提升，特别是在测试时的表现得到增强。
### Conclusion
作者通过广泛的测试表明，TabImpute 在 42 个 OpenML 数据集和 13 种不同的缺失模式中表现出色，与 11 种已建立的插补方法相比，显示了其鲁棒性的性能优势。
## 1005. `cs.LG` - 从模糊监督中学习稳健的扩散模型 [PDF](https://arxiv.org/pdf/2510.03016), [HTML](https://arxiv.org/abs/2510.03016)
### Authors
Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang Shen,Masashi Sugiyama
### Background
近期，条件扩散模型在各种生成任务中取得了显著成果，但其训练通常依赖大规模数据集，这些数据集不可避免地包含条件输入中的不精确信息。这些不精确的标签，往往源自噪声、模糊或不完整的标签，会造成条件不匹配并降低生成质量。
### Innovation
我们提出了一种名为DMIS的统一框架，用于从不精确监督中训练稳健的扩散模型，这是扩散模型领域的首次系统研究。该框架源于最大似然估计，并将目标分解为生成和分类两个组件：生成组件用于模拟不精确标签的概率分布，分类组件则利用扩散分类器推断类后验概率，并通过优化的时间步长采样策略进一步提高分类效率。
### Conclusion
在涵盖图像生成、弱监督学习和嘈杂数据集浓缩等多种形式的不精确监督任务上的广泛实验表明，DMIS能够持续产生高质量且具有类区分性的样本。
## 1006. `cs.LG` - 基于提示感知的低延迟LLM服务调度 [PDF](https://arxiv.org/pdf/2510.03243), [HTML](https://arxiv.org/abs/2510.03243)
### Authors
Yiheng Tao,Yihe Zhang,Matthew T. Dearing,Xin Wang,Yuping Fan,Zhiling Lan
### Background
高效的LLM推理任务调度对于实现低延迟和高吞吐量至关重要，尤其是在推理能力强的LLM日益普及的情况下。传统的先到先服务（FCFS）策略往往受到头阻塞（HOL）问题的影响，导致长时间运行的任务阻碍了排队在其后的较短任务的执行，增加了整体延迟。
### Innovation
论文介绍了一种基于提示感知的LLM任务调度器（PARS），通过成对排名和边缘排名损失来近似最短任务优先（SJF）调度，从而提高服务效率。PARS专注于有效的调度决策，并无缝集成到最先进的LLM服务系统vLLM中。它通过预测基于响应长度的任务排序来减少延迟，同时保持低开销。广泛实验表明，PARS在多个LLM和实际推理数据集上显著提高了性能，特别是在推理工作负载方面。此外，跨模型评估显示设计具有很好的泛化能力，即使训练预测器的LLM不同也能有效调度。
### Conclusion
PARS显著改善了LLM服务效率，特别是在低延迟和高吞吐量方面。它通过有效预测基于响应长度的任务排序，减少了延迟，同时保持了低开销。广泛的实验结果表明，PARS在多个LLM和实际推理数据集上都表现出优异的性能，特别是在推理工作负载方面。
## 1007. `cs.LG` - 作为规划的时空预测：基于生成世界模型的模型驱动强化学习方法 [PDF](https://arxiv.org/pdf/2510.04020), [HTML](https://arxiv.org/abs/2510.04020)
### Authors
Hao Wu,Yuan Gao,Xingjian Shi,Shuaipeng Li,Fan Xu,Fan Zhang,Zhihong Zhu,Weiyan Wang,Xiao Luo,Kun Wang,Xian Wu,Xiaomeng Huang
### Background
面对物理时空预测中固有的随机性和非可微度量的双重挑战，本文提出了一种新的范式——时空预测作为规划（SFP），该范式基于模型驱动的强化学习方法。
### Innovation
SFP构建了一个新颖的生成世界模型来模拟多样化、高保真度的未来状态，拥有基于“想象”的环境仿真能力。在此框架下，一个基础预测模型充当代理角色，依靠基于束搜索（beam search）的规划算法，使用非可微度量作为奖励信号来探索高收益的未来序列。被识别出的高奖励候选结果作为伪标签，通过迭代自我训练持续优化代理的策略，从而显著减少预测误差并表现出色，尤其在捕捉极端事件等关键领域度量方面。
### Conclusion
通过迭代自我训练，SFP显著降低了预测误差，并在关键领域的度量上表现出色，尤其是在捕捉极端事件方面。这种方法为时空预测领域带来了新的视角和技术手段。
## 1008. `cs.LG` - CAFL-L：基于拉格朗日对偶优化的设备感知联邦学习方法及其在本地语言模型中的应用 [PDF](https://arxiv.org/pdf/2510.03298), [HTML](https://arxiv.org/abs/2510.03298)
### Authors
Dongqi Zheng,Wenjin Fu
### Background
介绍了在设备受限资源（如能量、通信、内存和热预算）下，联邦学习的一种有原则扩展——约束感知联邦学习（CAFL-L）。CAFL-L 是 FedAvg 的扩展，其特别之处在于明确地纳入了设备级别的资源约束。该方法通过拉格朗日对偶优化动态调整训练超参数（如冻结深度、本地步骤、批量大小和通信压缩），同时通过梯度累积保持训练稳定性，从而最优地利用设备资源，特别适用于资源受限的边缘设备语言模型。
### Innovation
CAFL-L 通过使用拉格朗日对偶优化来动态调整训练超参数，同时通过梯度累积保持训练稳定性，从而优化了内存使用和通信量，实验结果表明，CAFL-L 相比于标准 FedAvg 能够在减小内存使用（20%）和减少通信量（95%）的情况下保持竞争力的验证性能。
### Conclusion
CAFL-L 为资源受限的边缘设备提供了最优的联邦学习解决方案，能够在保持竞争力的验证性能的同时减少对资源的需求。
## 1009. `cs.LG` - 使用两级机器学习模型预测雷暴引发的停电 [PDF](https://arxiv.org/pdf/2510.03959), [HTML](https://arxiv.org/abs/2510.03959)
### Authors
Iryna Stanishevska
### Background
雷暴引发的停电难以预测，因为大多数雷暴不会造成损害，而乱流过程发生迅速且混沌。可用的公共数据既有噪音又不完整。本研究基于密歇根州夏季雷暴相关停电事件，使用开放数据源（EAGLE-I作为地面实况数据；METAR作为天气数据），开发了一个24-48小时的早期预警模型，旨在提供雷暴引发的停电预警。
### Innovation
研究提出了一种两级机器学习模型设计，通过结合逻辑门和LSTM回归建模的方法，不仅限制了常规时段，降低了噪声影响，还通过对参量特定克里金化和集团过采样来保留极端值，提取空间和时间相关的因果特征，以及利用事件中心评估方法来提高预测准确度。模型还通过对湿度输送、风速变化和气压下降等前兆特征进行工程化处理，进一步提高了预测性能。
### Conclusion
研究发现，两级模型在检测参考峰值方面更加准确，且在接近峰值时具有适度的振幅增益，同时在输出误差方面与单步LSTM基线相当。通过SHAP分析确认了湿度输送和风速/阵风的前兆价值，证实了特征工程的有效性。即使在存在开放数据噪音的情况下，基于特征的管道也能够提供针对雷暴引发的停电的行动导向和事件中心的早期预警。
## 1010. `cs.LG` - 为什么低精度Transformer训练会失败：关于Flash Attention的分析 [PDF](https://arxiv.org/pdf/2510.04212), [HTML](https://arxiv.org/abs/2510.04212)
### Authors
Haiquan Qiu,Quanming Yao
### Background
低精度格式的采用提高了计算效率，但在训练Transformer模型时经常遇到训练不稳定性的问题。特别是在使用闪存注意力（flash attention）时，在低精度设置下，会出现灾难性的损失爆炸。
### Innovation
本文首次对低精度设置下使用闪存注意力导致训练失败的机制进行了解释。研究发现失败不是随机的，而是由相似低秩表示的出现和舍入错误偏见累积效应两个因素共同导致的。研究通过一个简单的修改解决了这个问题，稳定了训练过程。
### Conclusion
通过引入对闪存注意力的简单修改，消除了舍入错误偏见，稳定了训练过程，验证了研究分析并提供了一个持久问题的实用解决方案。
## 1011. `cs.LG` - MLLMEraser：通过激活导向实现多模态大型语言模型的测试时遗忘 [PDF](https://arxiv.org/pdf/2510.04217), [HTML](https://arxiv.org/abs/2510.04217)
### Authors
Chenlu Ding,Jiancan Wu,Leheng Sheng,Fan Zhang,Yancheng Yuan,Xiang Wang,Xiangnan He
### Background
多模态大型语言模型（MLLMs）在视觉-语言任务中表现出色，但大规模部署引发了关于记忆中的私人数据、过时的知识和有害内容的严重担忧。现有的MLLM遗忘方法通常依赖基于训练的策略，如梯度上升或偏好优化，但这些方法计算成本高、不可逆且往往会使保留的知识失真。因此，亟需一种高效且可逆的测试时遗忘方法，以应对这些挑战。
### Innovation
本文提出了MLLMEraser，这是一种无需训练框架，通过激活导向实现测试时遗忘的输入感知方法。该方法利用激活调节使知识动态消除，而不更新参数。具体方法是通过对比对抗扰动的知识召回图像-文本对与知识消除对应物，提取文本和视觉差异。同时设计了一个输入感知的调节机制，以适配决定何时及如何应用消除方向，从而在保留有用知识的同时强制遗忘指定内容。实验结果表明，MLLMEraser在LLaVA-1.5和Qwen-2.5-VL上的表现优于最先进的MLLM遗忘基准，具备更低的计算成本、更强的遗忘效果和更少的功能退化。
### Conclusion
MLLMEraser通过激活调节实现了多模态大型语言模型的测试时遗忘，该方法不仅计算效率高、影响可逆，而且在保持功能的同时能更有效地忘记指定内容，是一项创新性的解决方法。
## 1012. `cs.LG` - 视觉编码器的后训练量化需要前缀寄存器 [PDF](https://arxiv.org/pdf/2510.04547), [HTML](https://arxiv.org/abs/2510.04547)
### Authors
Seunghyeon Kim,Jinho Kim,Taesun Yeom,Wonpyo Park,Kyuyeun Kim,Jaeho Lee
### Background
基于Transformer的视觉编码器，如CLIP，在多模态智能中占据核心位置，支撑着从自主网络代理到机器人控制的各种应用。由于这些应用通常需要实时处理大量视觉数据，因此降低视觉编码器的推理成本至关重要。后训练量化是一种可行的方法，但在8位精度下依然具有挑战性，主要是因为大规模激活（即异常值）的存在。
### Innovation
本文提出了一种名为RegCache的无训练算法，用于在视觉编码器中缓解异常值问题，使量化后的模型具有显著更小的准确性下降。RegCache引入了异常值倾向但语义不相关的前缀标记到目标视觉编码器中，以防止其他标记出现异常值。此项工作通过观察视觉编码器中异常值与语言模型中异常值的不同行为，引入了中间层前缀和标记删除两大技术创新，并且实验表明该方法能够跨文本监督和自监督视觉编码器均提高量化模型的准确性。
### Conclusion
实验结果显示，本文的方法能够一致地提高量化模型的准确性，无论是对于由文本监督的视觉编码器还是自监督的视觉编码器。这表明RegCache算法有效地缓解了视觉编码器中的异常值问题，使其在量化时具有显著更小的准确性下降。
## 1013. `cs.LG` - 使用一般损失和球对称径向基函数的截断核随机梯度下降算法 [PDF](https://arxiv.org/pdf/2510.04237), [HTML](https://arxiv.org/abs/2510.04237)
### Authors
Jinhui Bai,Andreas Christmann,Lei Shi
### Background
传统的大规模监督学习中的核随机梯度下降算法效率和可扩展性较低。本文旨在通过引入一种创新的正则化策略，提出一种新的核随机梯度下降算法，利用球对称径向基函数的无穷级数展开，将梯度投影到可自适应调整偏置方差权衡的有限维假设空间，提升泛化性能。同时，基于内核诱导协方差算子的谱结构的新估计，发展了一个统一的优化与泛化分析框架，分析方法证明了算法的最优势收敛速度，并在再生核希尔伯特空间中取得了最优强收敛性。此外，该算法通过引入线性随机梯度下降的成分实现计算复杂度和存储复杂度的显著降低，从而避免了传统核随机梯度下降中的昂贵两两操作，使得处理流式数据更高效。
### Innovation
本文提出了一种创新的正则化策略，通过利用球对称径向基函数的无穷级数展开，将梯度投影到可自适应调整偏置方差权衡的有限维假设空间，提升算法的泛化性能。同时，基于内核诱导协方差算子的谱结构的新估计，发展了一个统一的优化与泛化分析框架，保证了算法的最优性能。此外，算法通过引入线性随机梯度下降的成分降低计算和存储复杂度，适应流式数据处理。
### Conclusion
本文提出的新算法能够在大规模监督学习中提供最优的收敛速度，并且通过引入线性随机梯度下降的成分，显著降低计算复杂度和存储复杂度，更适合于处理流式数据。广泛的数值实验验证了算法的有效性和优越性。
## 1014. `cs.LG` - 基于模型的框架下的自适应记忆动量 [PDF](https://arxiv.org/pdf/2510.04988), [HTML](https://arxiv.org/abs/2510.04988)
### Authors
Kristi Topollai,Anna Choromanska
### Background
现代大多数深度学习模型都使用动量为基础的一阶优化器进行训练。动量项通过决定每个过去梯度对当前收敛方向的贡献度来管理优化器的记忆。尽管众多优化方法（如Nesterov加速梯度和重球法）以及近期的方法（如AdamW和Lion）广泛使用常量动量系数$beta = 0.9$，但在模型训练过程中保持不变，这种做法虽然被广泛采用，但并不总是最优的。本文背景在于现有方法中使用的常量动量存在的局限性，以及寻求改进动量机制的方法。
### Innovation
提出了一种自适应记忆机制，该机制在线性优化过程中动态调整动量系数，而不是使用常量动量。通过近似目标函数为两个平面，一个来自当前迭代点的梯度，另一个来自累积的过去梯度记忆。这是一种新颖的方法，简单易用，并且不需要额外假设或超参数调整。在广泛的深度学习场景中，包括简单的凸问题和大规模深度学习场景，测试证明该方法可以优于具有手动调优动量系数的标准SGD和Adam。
### Conclusion
本文工作为优化过程的适应性引入了新的可能性，展示了自适应记忆机制在多种学习任务中的优势，并为未来研究提供了新的方向。
## 1015. `cs.LG` - 揭示疾病间关联：从统计方法到大规模语言模型 [PDF](https://arxiv.org/pdf/2510.04888), [HTML](https://arxiv.org/abs/2510.04888)
### Authors
Alina Ermilova,Dmitrii Kornilov,Sofia Samoilova,Ekaterina Laptenkova,Anastasia Kolesnikova,Ekaterina Podplutova,Senotrusova Sofya,Maksim G. Sharaev
### Background
手动分析大规模临床数据以识别疾病之间的关联是耗时、主观的，并且容易导致专家间的分歧。尽管机器学习展示了潜力，但存在着三大挑战：1. 如何在广泛的机器学习景观中选择最优方法；2. 确定是机器学习该使用真实的临床数据（如电子健康记录，EHRs）还是结构化的疾病描述来获取更可靠的信息；3. 由于一些疾病之间的关联尚未在医学中进行探索，缺乏“地面真相”。大规模语言模型（LLMs）展示了广泛的应用性，但通常缺乏专门的医学知识。在这种背景下，本文通过系统评估七种用于发现疾病关系的方法来解决这些缺口，使用来自MIMIC-IV EHRs的ICD-10代码序列和完整的ICD-10代码（包含和不包含文本描述）作为数据源，整合统计共现分析和掩码语言模型、医学专用的BERT变体以及通用的BERT和文档检索技术，并利用Mistral、DeepSeek、Qwen和YandexGPT四个语言模型。
### Innovation
本文通过系统评估七种方法来发现疾病关系，包括统计共现分析和掩码语言模型、医学专用的BERT变体（Med-BERT和BioClinicalBERT）、通用的BERT和文档检索方法，以及四个大规模语言模型。研究发现，基于语言模型的方法产生的疾病间的关联具有较低的ICD代码连接多样性，这表明语言模型在发现新的疾病关联方面具有有限的潜力。结果还形成了一项有价值的医学疾病本体知识，可以作为未来临床研究和医疗健康领域人工智能应用的基础资源。
### Conclusion
虽然基于语言模型的方法在一些方面有一定的优势，但它们在发现新的疾病关联方面的能力有限。这项研究为未来寻找疾病关联的方法提供了基础数据，并强调了在医疗健康领域使用语言模型时关键因素的重要性。
## 1016. `cs.LG` - 在Hybrid线性注意力转换方法中解开组件不平衡 [PDF](https://arxiv.org/pdf/2510.05901), [HTML](https://arxiv.org/abs/2510.05901)
### Authors
Martin Benfeghoul,Teresa Delgado,Adnan Oomerjee,Haitham Bou Ammar,Jun Wang,Zafeirios Fountas
### Background
尽管Transformers表现出色，但由于其计算复杂性呈二次增长，限制了其扩展性。虽然线性注意力将复杂性降低到线性级别，但重新训练这些模型仍然在大多数情况下极为昂贵。最近的后训练线性化方法有效且高效地将预训练的Transformers转换为线性模型，通常采用结合线性注意力和滑动窗口softmax的混合方法。然而，现有混合方法中存在一个关键缺陷：它们无意中绕过了线性部分，几乎完全依赖于滑动窗口softmax。组件级别的诊断表明，这种未被发现的现象源于在常见常识基准上的未被注意的评估实践。
### Innovation
本文提出了三种解决方案来确保组件的平衡使用：（i）推理时将仅线性转换与滑动窗口softmax结合的混合化；（ii）结合注意权重传输与针对性LoRA微调的HedgeCATs；（iii）在训练过程中根据概率抑制softmax分支的计划滑动窗口丢弃(SSD)。这些方法在保持计算效率的同时，恢复了大多数基模型的性能，确保了真正意义上的线性注意力采用，并恢复了混合转换中性能属性的有效性。
### Conclusion
通过这三种方法，研究确保了组件的平衡使用，既维持了计算效率，又恢复了基模型的大部分性能，并推动了真正的线性注意力采用，从而恢复了混合转换中性能属性的有效性。
## 1017. `cs.LG` - Reinforce-Ada: 一种针对强化学习风格大语言模型训练的自适应采样框架 [PDF](https://arxiv.org/pdf/2510.04996), [HTML](https://arxiv.org/abs/2510.04996)
### Authors
Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang
### Background
将强化学习应用于大语言模型（LLMs）进行推理任务时常受到因固定且均匀地从提示中采样响应而导致不稳定梯度估计的限制。先前的研究如GVM-RAFT通过在预算约束条件下动态分配推理预算，以最小化梯度方差来解决此问题。研究指出，现有的两阶段分配方法不是通过连续重新分配采样努力来根据每个提示的不确定度或学习潜力来优化采样方向，而是通过交替估计和采样过程进行在线选择性消除，一旦收集到足够的信号则自动停止提示的采样。为了稳定更新，通过强制奖励多样性形成固定大小的组，并使用在自适应采样阶段汇总的全局统计数据计算优势基线。
### Innovation
Reinforce-Ada通过连续重新分配采样努力，根据每个提示的不确定性或学习潜力进行优化采样方向，不同于传统的两阶段分配方法，Reinforce-Ada通过在线选择性消除过程交替估计和采样，一旦从提示采集到足够的信号则自动停止采样。它通过形成具有故意多样性的固定组来计算优势基线，从而在多个模型架构和推理基准测试中加速收敛并提高最终性能，尤其是在使用平衡采样变体时表现更为出色。研究强调了在强化学习风格的大语言模型训练中，依赖于了解方差并自适应地管理数据收集的重要性，这是实现高效且可靠的训练机制的关键因素。
### Conclusion
Reinforce-Ada通过自适应数据管理战略，有助于提高大语言模型的强化学习效率，并突出显示了自适应数据采样的关键角色，特别适用于能力推理的大语言模型。有关代码可参阅this https URL（链接应该是个实际存在的网址，这里仅为示例）。
## 1018. `cs.LG` - GRADE：通过自适应狄利克雷探索的组相关强化学习实现个性化多任务融合 [PDF](https://arxiv.org/pdf/2510.07919), [HTML](https://arxiv.org/abs/2510.07919)
### Authors
Tingfeng Hong,Pingye Ren,Xinlong Xiao,Chao Wang,Chenyi Lei,Wenwu Ou,Han Li
### Background
在现代推荐和搜索系统中，平衡多个目标对于用户满意度至关重要。当前的多任务融合（MTF）方法依赖于静态且手动调优的权重，无法准确捕捉个人用户的意图。尽管强化学习（RL）能够提供个性化的路径，但传统方法往往会因为训练不稳定性以及系统中稀疏奖励而失效。
### Innovation
本文提出了一种名为“GRADE”的新颖且稳健的个性化多任务融合框架，通过组相对的政策优化（GRPO）范式，避免了批评家使用，能够提供稳定的、高效的策略学习，并通过狄利克雷分布进行有原理且结构化的权重空间探索，以及综合奖励函数结合稀疏用户反馈和密集模型先验及规则约束指导搜索。实验结果显示，在一个每日活跃用户超过数百万的应用内购市场中，GRADE显著优于现有基准，在严格的大型A/B测试中，实现了点击率（CTR）增加0.595%，转化率（CVR）增加1.193%，订单利润（OPM）增加1.788%，总订单量增加1.568%。
### Conclusion
随着其优异表现，GRADE已在Kuaishou的应用市场搜索场景中全面部署，为数亿用户提供服务。
## 1019. `cs.LG` - 高概率Mixout：重新审视Mixout以实现稳健的跨域泛化 [PDF](https://arxiv.org/pdf/2510.06955), [HTML](https://arxiv.org/abs/2510.06955)
### Authors
Masih Aminbeidokhti,Heitor Rapela Medeiros,Srikanth Muralidharan,Eric Granger,Marco Pedersoli
### Background
混叠（Mixout）是一种在训练过程中模拟模型集成的技术，通过在训练过程中以概率方式将一部分微调权重替换为其预训练权重，从而在适应与保留先验知识之间找到平衡。尽管与Dropout相比，混叠提供了更轻量级的正则化方法，但在预训练模型上使用时，它倾向于过度正则化，破坏了对于泛化至关重要的表示。由于需要训练和存储多个模型，集成了微调模型的策略会带来巨大的计算成本。
### Innovation
论文提出了高概率Mixout，通过提高置换单元的概率，以更严格的方式惩罚与预训练参数的偏差，从而促进更有效的泛化能力。此外，高概率的混叠减少了计算开销，通过最高可达45%的梯度计算减少和最高90%的梯度内存使用量减少实现了显著的减少。实验结果表明，在五个跨域泛化基准（PACS、VLCS、OfficeHome、TerraIncognita和DomainNet）上使用ResNet和ViT架构时，该方法改进了跨域准确度，且比基于集成的方法显著降低了训练成本。
### Conclusion
通过实验验证，高概率Mixout在保持与集成方法相当的跨域准确度的同时，显著降低了训练成本。通过使用较高概率的置换单元，该方法更加有效平衡了模型的适配与泛化，实现了更加健壮的跨域泛化性能。
## 1020. `cs.LG` - 在复杂Q函数中缓解确定性策略梯度的次优性 [PDF](https://arxiv.org/pdf/2410.11833), [HTML](https://arxiv.org/abs/2410.11833)
### Authors
Ayush Jain,Norio Kosaka,Xinhu Li,Kyung-Min Kim,Erdem Bıyık,Joseph J. Lim
### Background
在强化学习中，像DDPG和TD3这样的离策略演员-评论家方法使用确定性策略梯度：Q函数是从环境数据中学习的，而演员则通过梯度上升来最大化Q值。然而，在复杂任务如灵巧操控和受移动限制的受限行动中，Q函数存在许多局部最优解，使得梯度上升容易卡在局部最优解中。
### Innovation
为了解决上述问题，该研究引入了SAVO演员架构：（i）生成多个动作提案，并选择具有最高Q值的动作；（ii）通过截断较差的局部最优来近似Q函数，更有效地引导梯度上升。
### Conclusion
我们在受限行动、灵巧操控、和大规模离散行动空间的推荐系统任务中评估了该模型，结果表明，我们的演员更频繁地找到最优行动，并且优于其他演员架构。
## 1021. `cs.LG` - D-TPT: 基于维度熵最大化在视图语言模型中校准测试时提示调整 [PDF](https://arxiv.org/pdf/2510.09473), [HTML](https://arxiv.org/abs/2510.09473)
### Authors
Jisu Han,Wonjun Hwang
### Background
视图语言模型(Vision-Language Models, VLMs)可以泛化用于不同的下游任务，测试时提示调整(Test-time prompt tuning)成为了适应VLMs的一种重要方法。然而，现有的VLMs在其文本和图像模态中存在主导特征维度之间的模态差距，这影响了其在测试时的提示调整性能。本文旨在探索基于对比的VLMs，并识别受限于单一部主导特征维度跨模态引发的高度预测敏感性。
### Innovation
本文提出了一种基于维度熵最大化的方法（Dimensional Entropy Maximization），该方法通过将文本特征的分布均匀化来减少对主导维度的依赖，从而改善了测试时提示调整的校准性能。
### Conclusion
本文提出的方法显著改善了测试时提示调整中的校准性能，提供了一种简单而有效的解决方案，以增强视图语言模型在真实部署场景中的可靠性。
## 1022. `cs.LG` - 一种用于追捕锁定发射任务的模仿强化学习框架 [PDF](https://arxiv.org/pdf/2406.11562), [HTML](https://arxiv.org/abs/2406.11562)
### Authors
Siyuan Li,Rongchang Zuo,Bofei Liu,Yaoyu He,Peng Liu,Yingnan Zhao
### Background
无人驾驶 Combat 航空器 (UCAV) 的近距离交战 (WVR) 在空战中起着重要作用。随着人工智能的发展，WVR 逐渐向智能化和自主化模式发展。然而，自主 WVR 策略的学习受到探索能力弱、学习效率低和不切实际仿真实验环境的阻碍。
### Innovation
提出了一种新颖的模仿强化学习框架，该框架高效利用专家数据并允许自主探索。该框架不仅通过专家模仿增强学习效率，还通过强化学习实现自主探索，确保动态环境的适应性。此外，该框架能够从复杂的空战任务中学习成功的“追捕锁定发射”策略。为了支持数据驱动学习，基于 Harfang3D 沙箱建立了一个环境。实验结果显示，该框架在多阶段任务中表现出色，显著优于最先进的强化学习和模仿学习方法。
### Conclusion
该框架能够迅速学习复杂空战任务中的关键知识，成功率达到100％，并表现出出色的稳健性。
## 1023. `cs.LG` - Large Language Models的主动模型选择 [PDF](https://arxiv.org/pdf/2510.09418), [HTML](https://arxiv.org/abs/2510.09418)
### Authors
Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel
### Background
现有方法依赖于完全注释的数据集进行大型语言模型（LLMs）的评估和基准测试，而LLM SELECTOR框架能够通过有限注释高效地识别最适合特定任务的LLM。与现有方法不同，LLM SELECTOR会为每个任务选择最有信息性的少量查询，同时利用基于审判者的Oracle注释模型进一步降低注释成本。
### Innovation
提出了第一个大型语言模型主动模型选择框架LLM SELECTOR。该框架通过有限的注释自主动选择适合任务的最优和接近最优模型，并通过使用基于判决者的Oracle注释模型来减少注释成本。
### Conclusion
通过在6个基准上进行大量实验，并对151个LLM进行了测试，LLM SELECTOR证明了，在选择最好的和接近最好的LLM时，注释成本最多可以减少59.62%。
## 1024. `cs.LG` - 基于正交表示的因果量估计 [PDF](https://arxiv.org/pdf/2502.04274), [HTML](https://arxiv.org/abs/2502.04274)
### Authors
Valentyn Melnychuk,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel
### Background
端到端表示学习已经成为估计高维观测数据中的因果量的有效工具，但其效率尚未明确。现有的方法有时在实践上表现良好，但缺乏形式上的拟或有效率。（提案方法）相比之下，两阶段尼曼正交学习器提供了这种理论上的最优性，但未能显式地利用表示学习的优势。本文提出两个研究问题并探索：1. 当前的尼曼正交学习器如何通过表示增强？2. 调和约束能否提升尼曼正交性？
### Innovation
作者提出了一种统一框架，将表示学习与尼曼正交学习器（简称OR-学习器）联系起来。特别地，他们表明，在低维流形假设下，OR-学习器能严格提高标准尼曼正交学习器的估计误差。同时，作者发现平衡约束需要额外的归纳偏差，通常无法补偿端到端方法缺乏尼曼正交性的缺点。基于这些见解，作者给出了用户如何有效结合表示学习与经典尼曼正交学习器以实现实用性能和理论保证的指导建议。
### Conclusion
作者提出了OR-学习器这一统一体系，通过低维流形假设证明OR-学习器能显著提高估计效果，且平衡约束通常无法弥补端到端方法在尼曼正交性上的不足。
## 1025. `cs.LG` - SketchGuard: 通过基于草图的筛选扩展 Byzantine-鲁棒的去中心化联邦学习 [PDF](https://arxiv.org/pdf/2510.07922), [HTML](https://arxiv.org/abs/2510.07922)
### Authors
Murtaza Rangwala,Farag Azzedin,Richard O. Sinnott,Rajkumar Buyya
### Background
去中心化联邦学习（DFL）使协作训练能够在没有集中服务器的情况下保持私密性，但它仍然是 Byzantine 攻击的脆弱性，恶意客户端可以提交被破坏的模型更新。现有的 Byzantine 抵抗 DFL 防御依赖于基于相似性的邻居筛选方法，这需要每个客户端在每个训练周期内与所有邻居交换并比较完整的高维模型向量，这导致了通信和计算成本的显著增加，阻碍了在 web 规模上部署。
### Innovation
提出了 SketchGuard，这是一个通过基于草图的邻居筛选来解耦 Byzantine 过滤和模型聚合的通用框架。SketchGuard 使用 Count Sketch 将 $d$ 维模型压缩到 $k$ 维草图 ($k ; d$)，进行相似性比较，然后仅从被接受的邻居中选择性地获取完整的模型，将每轮通信复杂度从 $O(d|N_i|)$ 降低到 $O(k|N_i| + d|S_i|)$，其中 $|N_i|$ 是邻居的数量，$|S_i| ; |N_i|$ 是被接受的邻居的数量。消除了现有的相似性比较方法中的通信和计算瓶颈。
### Conclusion
全面的实验表明，SketchGuard 在多种数据集、网络拓扑结构和攻击场景下，能够保持与最先进的方法相同的鲁棒性，同时计算时间最多减少了 82%，通信开销减少了 50-70%，并且这种优势随着模型维度和网络连接性的增加而呈倍数增长。这些结果确立了基于草图压缩作为实现 web 规模 Byzantine 鲁棒 DFL 的基础启用机制的可行性。
## 1026. `cs.LG` - 刻画宽容的0-1损失函数在多类别学习中的可学习性 [PDF](https://arxiv.org/pdf/2510.08382), [HTML](https://arxiv.org/abs/2510.08382)
### Authors
Jacob Trauger,Tyson Trauger,Ambuj Tewari
### Background
本文探讨了在有限标签多类别设置中宽容的0-1损失函数的可学习性。为此，构建了一个新的组合维度，该维度基于Natarajan维度，证明了一假设类在这种设置下是可学习的当且仅当这种广义Natarajan维度是有限的。此外，还探讨了与带集合反馈的学习之间的关系。
### Innovation
提出了一种新的基于Natarajan维度的组合维度，用于描述宽容0-1损失函数在有限标签多类别设置中的可学习性，并证明了一类假设类在这种设置下是可学习的当且仅当广义Natarajan维度是有限的。
### Conclusion
通过研究结果表明，一组学习问题的可学习性由Natarajan维度决定。
## 1027. `cs.LG` - 合成系列-符号数据生成用于时间序列基础模型 [PDF](https://arxiv.org/pdf/2510.08445), [HTML](https://arxiv.org/abs/2510.08445)
### Authors
Wenxuan Wang,Kai Wu,Yujian Betterest Li,Dan Wang,Xiaoyu Zhang
### Background
时间序列分析（TSA）的基础模型近年来受到了广泛关注，但是由于训练数据稀缺和不平衡等问题仍然对其发展构成阻碍。现有的时间序列分析模型在这一方面仍存在不足，特别是在数据稀缺和不均衡的问题上。
### Innovation
本文提出了一个系列-符号数据生成机制，该机制能够无限制地生成高质量的时间序列数据及其对应的符号表达。据此开发了SymTime模型，这是一个预训练基础模型，可以利用强相关的时间序列-符号数据对来增强时间序列表示能力，并在5个主要的时间序列分析任务上展示了与基于真实数据集预训练的基础模型相媲美的性能。这一方法强调了系列-符号数据生成和预训练机制在克服数据稀缺和提升任务性能方面的潜力。
### Conclusion
本文通过SymTime模型展示了系列-符号数据生成和预训练机制的有效性，证明了这一方法能够克服时间序列分析中的数据不足问题，显著提升模型性能。项目代码可以在提供的链接处获取。
## 1028. `cs.LG` - 关于RLVR的优化动态：梯度间隙与步长阈值 [PDF](https://arxiv.org/pdf/2510.08539), [HTML](https://arxiv.org/abs/2510.08539)
### Authors
Joe Suk,Yaqi Duan
### Background
RLVR（使用可验证奖励的强化学习）通过使用简单的二进制反馈来后训练大型语言模型，显示出了显著的实验成功，但缺乏对其为何有效原理性的理解。本文通过对RLVR在不仅响应层面还是标记层面的训练过程进行分析，构建了其理论基础。
### Innovation
本文提出了一个被称为梯度差距的量化指标，该指标具体化了从低奖励到高奖励方向上的改进方向。证明了收敛的关键在于调整更新方向与梯度差距的一致性，并推导出基于梯度差距幅度的锐利的步长阈值：低于该阈值时，学习收敛；高于该阈值时，性能崩溃。理论预测了关键步长需要如何随响应长度和成功率来缩放，解释了为何诸如长度归一化的实用启发式基于固定学习率可以导致成功率停滞在严格低于100%。
### Conclusion
本文的理论通过受控的多臂老虎机模拟进行了验证，解释了为什么RLVR表现出的稳定性得到了提升，以及成功率为固定学习率下的确发生了停滞现象。
## 1029. `cs.LG` - 模型瘦身，隐患更多：LLM模型瘦身的一种实际攻击 [PDF](https://arxiv.org/pdf/2510.07985), [HTML](https://arxiv.org/abs/2510.07985)
### Authors
Kazuki Egashira,Robin Staab,Thibaud Gloaguen,Mark Vero,Martin Vechev
### Background
模型瘦身，即移除模型的一部分权重，已成为在推理过程中降低大型语言模型(LLMs)内存占用的一种显著方法。流行的推理引擎，如vLLM，允许用户在部署之前方便地瘦身已下载的模型。尽管瘦身方法的实用性和效率有了显著提高，但它们的安全性影响却仍然没有得到充分探索。本研究首次展示了现代LLM瘦身方法可以被恶意利用。通过计算一个代理指标来估计哪些参数更有可能被瘦身，并将恶意行为注入不太可能被瘦身的参数，然后使用那些更有可能被瘦身的参数修复模型，使得恶意行为被取消，从而在未经瘦身的模型中表现出无害的样子。通过全面评估五个模型表明，这种攻击在多种攻击场景中均表现突出，即使在vLLM应用瘦身方法后，模型仍然能表现出高达95.7%的脱链攻击成功率、98.7%的良性指令拒绝成功率和99.5%的定向内容注入成功率。这揭示了关键的部署时安全漏洞，并强调了在模型压缩中增强安全意识的紧迫性。
### Innovation
研究提出了针对LLM模型瘦身的一种新的攻击方法，通过计算代理指标来估计参数被瘦身的概率，并利用这一信息在不太可能被瘦身的参数中注入恶意行为，随后通过使用更可能被瘦身的参数修复模型以消除这些恶意行为。该研究展示了这种攻击的有效性，并突出了模型瘦身过程中存在的严重安全问题。
### Conclusion
研究揭示了在LLM模型瘦身过程中存在的重要安全缺口，并强调了迫切需要提高安全意识，以确保模型压缩时的安全性。通过广泛的实验结果，证明了该攻击方法的有效性，并展示了其在多种攻击场景中的强大表现。这为今后研究LLM模型瘦身的安全性提供了新的视角和方法。
## 1030. `cs.LG` - K-ASTRO: 结构感知的LLM适应用于代码漏洞检测 [PDF](https://arxiv.org/pdf/2208.08067), [HTML](https://arxiv.org/abs/2208.08067)
### Authors
Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach
### Background
大型语言模型（LLMs）正在改变软件工程任务，包括代码漏洞检测——软件安全的关键领域。然而，现有方法通常依赖于资源密集型模型或基于图的技术，限制了它们的可访问性和实用性。
### Innovation
本文介绍了K-ASTRO，一种轻量级的Transformer模型。该模型通过结合LLMs的语义嵌入和Abstract Syntax Trees（ASTs）的结构特征，同时改进了代码漏洞检测的效率和准确性。我们的方法引入了基于AST的增强技术，灵感来源于变异测试，一种结构感知的注意力机制，该机制结合了增强的AST特征，并通过联合适应管道统一代码语义和语法。
### Conclusion
实验结果表明，K-ASTRO在BigVul、DiverseVul和PrimeVul三个大规模数据集上达到了最新的性能水平，同时在CPU上实现了快速推理，训练时间极为短促。通过提供一个可扩展、可解释且高效的解决方案，K-ASTRO在LLM进步与实际软件漏洞检测之间架起了桥梁，同时提供了开源工具以促进进一步研究。
## 1031. `cs.LG` - 持续适配器调谐及其在语义转移补偿下的类增量学习中的应用 [PDF](https://arxiv.org/pdf/2403.19979), [HTML](https://arxiv.org/abs/2403.19979)
### Authors
Qinhao Zhou,Yuwen Tan,Boqing Gong,Xiang Xiang
### Background
类增量学习（CIL）旨在使模型能够持续学习新类而克服灾难性遗忘。引入预训练模型带来了新的调谐范式，本文重访不同的参数高效调谐（PET）方法在持续学习语境中的应用。
### Innovation
1. 提出了无需参数扩展即可改进共享适配器的增量调谐方法，增强主干的学习能力。2. 采用特征采样从存储的原型重新训练统一分类器，进一步提高其性能。3. 估计旧原型的语义转移，并在每次学习会话中更新存储的原型，避免模型扩展和保留任何图像样本。
### Conclusion
所提出的方法在五个CIL基准上的实验结果证明了其有效性，达到了最佳性能。
## 1032. `cs.LG` - 加速演化集过程以本地计算PageRank [PDF](https://arxiv.org/pdf/2510.08010), [HTML](https://arxiv.org/abs/2510.08010)
### Authors
Binbin Huang,Luo Luo,Yanghua Xiao,Deqing Yang,Baojian Zhou
### Background
该研究旨在通过提出基于嵌套演化集过程的新型框架来加速个性化PageRank（PPR）计算。现有的方法在计算PPR时存在效率问题，特别是在大规模图上。论文通过局部不精确 proximal 点迭代解决简化线性系统，以提高PPR计算的效率。作者证明了这种局部方法的时间复杂性在获取$tilde{text{O}}(R^2/text{eps}^2)$或$tilde{text{O}}(m)$的$text{eps}$-近似解时是上界的。实验结果表明，该方法在早期有显著的收敛效果，证明了其在实际应用中的高效性。
### Innovation
论文提出了一种基于嵌套演化集过程的创新框架，通过局部不精确 proximal 点迭代解决简化线性系统来加速PPR计算。与现有的方法相比，这种方法的时间复杂性得到了改进，当$1/text{eps}^2 text{远小于} m$时，可以得到独立于底层图大小的整体计算复杂度$tilde{text{O}}(R^2 / (text{eps}^2 text{s}&#39;qrt;text{alpha}))$。这种改进极大地提高了PPR的计算效率，解决了现有文献中的公开猜想。
### Conclusion
通过实验，该方法在真实世界图上的实证证明了其高效性，在早期阶段有显著的收敛性，这对处理大规模数据集具有重要意义。此研究表明了嵌套演化集过程在本地PageRank计算中的潜力。
## 1033. `cs.LG` - 熵调节激活：通过激活作为熵约束提高连续控制、大规模语言模型和图像分类的效果 [PDF](https://arxiv.org/pdf/2510.08549), [HTML](https://arxiv.org/abs/2510.08549)
### Authors
Zilin Kang,Chonghua Liao,Tingqiang Xu,Huazhe Xu
### Background
该研究提出了ERA（Entropy Regularizing Activation），这是一种通过特定设计的激活函数来约束模型输出熵的新方法。该方法在不同领域都展示了广泛的适用性，包括大规模语言模型、连续控制强化学习代理和图像分类。在大规模语言模型方面，该方法提升了Qwen2.5-Math-7B的AIME 2025得分；在连续控制强化学习领域，ERA提升了HumanoidBench的性能；在图像分类方面，ERA使得ResNet-50的ImageNet top-1准确率提高了0.69%。这些改进都仅增加了不到7%的计算开销。先前的研究表明，输出激活可以作为一种强大的工具，用于熵控制，这为设计更简单且更稳健的算法提供了新的方向。
### Innovation
ERA通过使用特定设计的激活函数来约束模型输出的熵，提供了一种新的熵控制方式，并且在多种任务中表现出显著的有效性，包括大规模语言模型、连续控制强化学习和图像分类，同时保持了较低的计算开销。ERA为设计更简单且更稳健的算法打开了新的方向。
### Conclusion
ERA作为一种熵调节激活方法，通过特定设计的激活函数有效地控制模型输出的熵，在多个任务中取得了显著的性能提升，同时保持了较低的计算开销。这项工作验证了输出激活作为熵控制的工具的有效性，并为设计更简单且更稳健的算法提供了新的方向。
## 1034. `cs.LG` - 通过组间差异最小化在多样性域下的无监督多源联邦域适应 [PDF](https://arxiv.org/pdf/2510.08150), [HTML](https://arxiv.org/abs/2510.08150)
### Authors
Larissa Reichart,Cem Ata Baykara,Ali Burak Ünal,Harlin Lee,Mete Akgün
### Background
无监督多源域适应（UMDA）旨在通过在多个不同的源领域中的标注数据来学习模型，以泛化到未标记的目标领域。现有的分布式UMDA方法通过避免原始数据共享来解决隐私限制，并且通常是基于假设有少量源领域，这限制了这些方法在处理大量异质领域时的扩展性。这会导致高计算成本或不稳定的性能。因此，需要一种可扩展且稳健的联邦UMDA框架，能够处理大量异质来源并提供稳定性能。Digit-18是一个新的基准，由18个具有不同合成和真实世界域偏移的数字数据集组成，用于评估在高多样性场景中的性能。
### Innovation
文章提出了一个名为GALA的可扩展且稳健的联邦UMDA框架，引入了两个关键组件：(1) 一种新颖的组间差异最小化目标，能够有效地接近全对域对齐计算而无需进行二次计算；(2) 一种受温度控制的基于重心的加权策略，可以根据与目标的对齐情况动态优先考虑源域。这些组件共同实现了在大量异质源域上的稳定且并行的训练。通过使用Digit-18基准进行的广泛实验表明，GALA在标准基准测试中取得了可竞争甚至最新的结果，并且在具有高多样性的多源环境中显著优于先前的方法。
### Conclusion
GALA框架在高多样性的多源场景中展示了稳定性和优越的性能，解决了现有方法在处理大量异质源域时遇到的高计算成本或不稳定的问题。
## 1035. `cs.LG` - 通过排序和LLM融合提高图像描述的详尽性 [PDF](https://arxiv.org/pdf/2306.11593), [HTML](https://arxiv.org/abs/2306.11593)
### Authors
Luigi Celona,Simone Bianco,Marco Donzella,Paolo Napoletano
### Background
现有的最先进的（SoTA）图像描述模型通常是在包含人工标注的短描述（平均长度约十个标记）的MS-COCO数据集上进行训练。虽然这些模型在一般场景理解方面非常有效，但它们的短描述往往会遗漏复杂的场景和重要细节，并且倾向于偏向于描述“平均水平”的内容，忽略了细节信息。本文分析了这个背景问题。
### Innovation
本文提出了一种新型方法，通过结合不同的SoTA描述模型生成的描述来创建更丰富和更详细的信息。这个新方法无需额外的模型训练：首先应用预训练的模型生成初始描述，然后使用一种新的基于图像-文本的指标（命名为BLIPScore）对这些描述进行排名，最后通过大型语言模型（LLM）融合排名靠前的两个描述以获得最终更详细的描述。通过实验表明，这种方法在MS-COCO和Flickr30k数据集上的结果在图像描述的对齐和幻觉减少方面表现出色，得到了ALOhA、CAPTURE和Polos指标的支持，并且主观研究进一步证实了这一点，表明通过该模型生成的描述通常更符合人类判断。
### Conclusion
通过结合多种不同的SoTA模型的优点，本文的方法提高了图像描述的质量和吸引力，缩小了自动化系统与人类描述的丰富性和信息量之间的差距。这使生成更适合用于视觉-语言和描述模型训练的描述成为可能。
## 1036. `cs.LG` - 多项参数正则化及其在多项式函数回归中的聚类方法 [PDF](https://arxiv.org/pdf/2405.04147), [HTML](https://arxiv.org/abs/2405.04147)
### Authors
Elke R. Gizewski,Markus Holzleitner,Lukas Mayer-Suess,Sergiy Pereverzyev Jr.,Sergei V. Pereverzyev
### Background
近年来，多项式函数回归领域的主要成果集中在单参数正则化方案的深入探索上。现有研究大多关注于通过单一参数进行正则化，而较少涉及多个参数的正则化及相应参数的处理。
### Innovation
本文创新点在于提出了一个多参数正则化算法，并提供了一种理论支持的方法来处理相关参数，该方法能够促进具有不同正则化参数模型的聚合。
### Conclusion
通过在合成数据和一些实际医疗数据上的评估，表明所提出的方法具有良好的效果，揭示了有希望的结果。
## 1037. `cs.LG` - SolNet: 全球开源深度学习模型用于光伏功率预测 [PDF](https://arxiv.org/pdf/2405.14472), [HTML](https://arxiv.org/abs/2405.14472)
### Authors
Joris Depoortere,Johan Driesen,Johan Suykens,Hussain Syed Kazmi
### Background
近年来，深度学习模型在光伏（PV）预测领域取得了显著成效。然而，这些模型的一个局限性在于需要大量的高质量数据才能表现出色。由于传统系统中测量基础设施不足，以及全球新太阳能系统的快速建设，获取这些高质量数据往往不可行。本文研究的背景在于克服这一挑战，提出了一种名为SolNet的新型、通用的多变量太阳能功率预测模型。SolNet通过结合来自PVGIS的丰富合成数据进行初步迁移学习，随后在观测数据上进行微调来构建预测模型。实验使用荷兰、澳大利亚和比利时数百个站点的实际发电数据，结果表明，SolNet在数据稀缺的情况下和基线模型相比，可以提高预测性能。模型的成功依赖于多种因素，包括天气数据、季节性模式、生成合成数据的数量以及源位置可能存在的错误假设。
### Innovation
SolNet的创新之处在于它采用了一种两阶段的预测流程：首先从大量合成数据中进行迁移学习，然后根据观测数据进行微调。这种方法能够有效解决高质量数据稀缺的问题。此外，该模型为迁移学习实践者提供了指南和注意事项，强调了多种因素对最终结果的影响，如天气数据、季节性趋势、合成数据的数量以及源位置问题等。
### Conclusion
SolNet模型适用于全球任何陆地上的太阳能光伏系统，只要能够结合模拟和观测数据来提高预测能力。研究结果表明，当观测数据有限时，迁移学习的效果最为显著。同时，此研究为迁移学习提供了宝贵的指南和启示。
## 1038. `cs.LG` - Mini-batch Estimation for Deep Cox Models: Statistical Foundations and Practical Guidance [PDF](https://arxiv.org/pdf/2408.02839), [HTML](https://arxiv.org/abs/2408.02839)
### Authors
Lang Zeng,Weijing Tang,Zhao Ren,Ying Ding
### Background
已经广泛使用随机梯度下降（SGD）算法来优化深度Cox神经网络（Cox-NN）。SGD通过使用数据的小批量来更新模型参数。然而，SGD优化的是mini-batch偏似然函数的平均值，与标准偏似然函数不同。因此，需要发展新的统计特性来描述全局优化器，即mini-batch最大偏似然估计量（mb-MPLE）。对于Cox-NN，研究人员证明了mb-MPLE是一致的，并且其最小最大收敛率最优（直到对数因子）。对于具有线性协变量效应的Cox回归，mb-MPLE在大样本下是一致的，并且渐近分布接近信息下界，这些结论在模拟研究中得到了验证。
### Innovation
研究开发了mini-batch最大偏似然估计量（mb-MPLE），并证明了其一致性及最优最小最大收敛率。对于Cox回归，提出了mb-MPLE在大样本下一致并渐近正态。此外，通过理论分析和数值证据提供了使用SGD的实践指导。特别强调了对于Cox-NN，学习率与批量大小的比例对SGD动态至关重要，并提出了Cox回归中SGD迭代收敛的分析。
### Conclusion
研究表明，通过使用mini-batch最大偏似然估计量（mb-MPLE），可以在Cox-NN中获得有效估计。对于大规模的实际应用，证明了此方法的有效性。
## 1039. `cs.LG` - RAGDiffusion: 通过外部知识吸收实现忠实服装生成 [PDF](https://arxiv.org/pdf/2411.19528), [HTML](https://arxiv.org/abs/2411.19528)
### Authors
Xianfeng Tan,Yuhan Li,Wenxiang Shang,Yubo Wu,Jian Wang,Xuanhong Chen,Yi Zhang,Ran Lin,Bingbing Ni
### Background
标准的服装资产生成涉及从多样化的现实世界场景中提取服装信息，恢复面向前方的平铺服装图片。由于结构样本分布高度标准化以及在复杂场景中缺乏服装语义信息，这带来了巨大挑战。现有的模型在空间感知上有限，经常在高规格生成任务中出现结构幻觉和纹理失真。
### Innovation
提出了一种新的检索增强生成（RAG）框架——RAGDiffusion，通过整合语言模型和外部数据库的知识来增强结构确定性和缓解幻觉。RAGDiffusion 包含两个过程：基于检索的结构聚合，使用对比学习和结构局部线性嵌入（SLLE）来推导全局结构和空间地标，提供软硬指导以对抗结构不确定性；以及全方位一致的服装生成，引入了从粗到细的纹理对齐，确保图案和细节成分的保真度。
### Conclusion
在具有挑战性的现实世界数据集上进行的广泛实验表明，RAGDiffusion 合成了具有结构和纹理忠实性的服装资产，性能显著提升，这标志着使用 RAG 进行高规格保真生成并克服内在幻觉和提高保真度的开创性努力。
## 1040. `cs.LG` - 基于频域指导的后验采样在扩散模型图像恢复中的应用 [PDF](https://arxiv.org/pdf/2411.15295), [HTML](https://arxiv.org/abs/2411.15295)
### Authors
Darshan Thaker,Abhishek Goyal,René Vidal
### Background
图像恢复旨在从退化观测中恢复高质量的图像。在退化过程已知的情况下，恢复问题可以被表述为逆问题，在贝叶斯框架下，目标是在给定退化观测的情况下采样一个干净的重建。近年来，现代预训练的扩散模型被用于图像恢复，通过修改采样过程以考虑退化过程。然而，这些方法常常依赖于某些近似，可能导致显著的误差和样本质量下降。
### Innovation
本文提供了线性逆问题下频域指导的后验采样方法的第一项严谨分析，并通过对真实图像空间的假设条件下展示了先前工作的局限性情况。基于理论洞察，我们提出了对现有的基于扩散的过程的图像恢复方法的简单改进。通过在测量的频域中引入时间变化的低通滤波器，我们的方法逐次将更高频率纳入恢复过程中。我们还基于底层数据分布开发了一个适应性课程，该课程为我们所提出的方法的频谱安排提供了一个自适应的退火策略。我们方法在包括运动模糊消除和图像除雾在内的具有挑战性的图像恢复任务上表现出显著的性能提升。
### Conclusion
我们的方法在解决图像退化问题时表现出色，通过改进现有的基于扩散的方法，特别是通过一种自适应的频率安排策略，显著提高了恢复效果。
## 1041. `cs.LG` - 平衡数据集中偏见放大的方向性和可解释性 [PDF](https://arxiv.org/pdf/2412.11060), [HTML](https://arxiv.org/abs/2412.11060)
### Authors
Bhanu Tokas,Rahul Nair,Hannah Kerner
### Background
现有的机器学习数据集往往存在偏见，训练模型时不仅会学习到这些偏见，还可能放大这些偏见。已有的一些共现度量方法虽然可以测量受保护属性（如性别）和任务（如烹饪）之间的偏见放大，但无法衡量在受保护属性与任务平衡情况下的偏见。近期出现了基于预测性的度量方法，如泄漏放大，但由于其不能识别偏见放大的方向，所以需要进一步创新来解决这一问题。
### Innovation
本文提出了一种新的基于预测性的度量方法，称为方向预测放大(DPA)，用于衡量平衡数据集中的方向性偏见放大。DPA方法更容易解释，并且对攻击者模型模型的敏感度较低。通过表数据和图像数据集的实验，证明了DPA是衡量方向性偏见放大的有效指标。
### Conclusion
本文提出的方向预测放大(DPA)指标，可以有效地衡量平衡数据集中的方向性偏见放大，并且具有更好的可解释性和对攻击模型的鲁棒性。
## 1042. `cs.LG` - 利用增强生成检索的LLM偏好认知 [PDF](https://arxiv.org/pdf/2412.08604), [HTML](https://arxiv.org/abs/2412.08604)
### Authors
Fabian Paischer,Liu Yang,Linfeng Liu,Shuai Shao,Kaveh Hassani,Jiacheng Li,Ricky Chen,Zhang Gabriel Li,Xiaoli Gao,Wei Shao,Xue Feng,Nima Noorshams,Sem Park,Bo Long,Hamid Eghbalzadeh
### Background
在序列推荐中，模型根据用户的交互历史推荐项目。当前模型通常会利用项目描述和用户意图或偏好信息。然而，用户偏好通常在开源数据集中未明确给出，因此需要通过例如大型语言模型（LLMs）等方式进行近似。现有的方法只能在训练过程中利用近似的用户偏好，而完全依赖过去的交互历史进行推荐，这限制了它们动态适应用户偏好变化的能力，可能会强化回音室效应。
### Innovation
本文提出了一个新的范式，即偏好认知，该范式在自然语言上下文中明确地将生成推荐模型条件化于用户的偏好。为了评估偏好认知，引入了一个新的基准测试，该基准测试涵盖了多种场景，包括偏好导向和情绪跟随。通过在基准测试中评估当前最先进的方法，发现它们动态适应用户偏好变化的能力有限。因此，本文提出了一个新的方法，名为Mender（多模态偏好辨析），该方法在我们的基准测试中取得最先进的性能。结果显示，即使是未在训练期间观察到的人类偏好，Mender也能够有效指导其推荐，从而为更灵活的推荐模型铺平了道路。
### Conclusion
Mender能够有效地根据人类偏好自适应调整推荐，即使这种偏好在训练过程中未被观察到，这表明它为动态推荐模型的发展提供了新的可能性。
## 1043. `cs.LG` - 二尺度梯度下降-上升动力学的收敛性：有限维度和均场视角 [PDF](https://arxiv.org/pdf/2501.17122), [HTML](https://arxiv.org/abs/2501.17122)
### Authors
Jing An,Jianfeng Lu
### Background
二尺度梯度下降-上升（GDA）是用于在最小-最大博弈中寻找纳什均衡的经典梯度算法。该研究探讨了学习率比率对二尺度GDA收敛行为的影响，特别是在有限维度和均场设置中的表现。
### Innovation
研究通过假设检验的方法，在有限维度的二次最小-最大博弈中，获得了近似静态区域内的长期收敛性。对于均场GDA动力学，研究借助混合同步-反射耦合技术探讨了有限尺度比下的收敛性。
### Conclusion
该论文通过不同的数学方法，从有限维度和均场两个角度深入分析了二尺度GDA的动力学行为，提供了理论依据和新的分析视角。
## 1044. `cs.LG` - NLP-ADBench: NLP Anomaly Detection Benchmark [PDF](https://arxiv.org/pdf/2412.04784), [HTML](https://arxiv.org/abs/2412.04784)
### Authors
Yuangang Li,Jiaqi Li,Zhuo Xiao,Tiankai Yang,Yi Nian,Xiyang Hu,Yue Zhao
### Background
异常检测（AD）是重要的机器学习任务，应用于欺诈检测、内容审核和用户行为分析等领域。然而，AD 在自然语言处理（NLP）上下文中研究较少，限制了其在检测有害内容、网络钓鱼尝试和垃圾评论方面的有效性。NLP-ADBench 是迄今为止最全面的 NLP 异常检测基准，包含八个精心策划的数据集和 19 种前沿算法。这些方法涵盖了 3 种端到端方法和 16 种两步方法，将经典非 AD 方法适应来自 BERT 和 OpenAI 的语言嵌入。
### Innovation
引入了 NLP-ADBench，这一基准包括了八个精心策划的数据集和19种前沿算法，覆盖了3种端到端方法和16种两步方法，将经典非AD方法适应了BERT和OpenAI的语言嵌入。实验证明，没有单一模型在所有数据集上都占主导地位，表明需要自动化模型选择。此外，使用变压器嵌入的两步方法通常优于专门的端到端方法，且OpenAI的嵌入表现优于BERT的嵌入。
### Conclusion
我们的实证结果表明，没有单一模型能在所有数据集上占据主导地位，指出了自动化模型选择的需求。此外，使用基于变换器的嵌入的两步方法通常优于专业的端到端的方法，且OpenAI嵌入表现优于BERT。提供了NLP-ADBench在线工具，支持未来的进一步研究。
## 1045. `cs.LG` - SWE-Arena: 一个在软件工程中评估基础模型的互动平台 [PDF](https://arxiv.org/pdf/2502.01860), [HTML](https://arxiv.org/abs/2502.01860)
### Authors
Zhimin Zhao
### Background
现有的大型语言模型（LLMs）在软件工程（SE）任务中表现出色，包括代码生成、调试和需求细化。然而，现有的评估框架不足以评估模型在迭代且语境丰富的SE工作流程中的性能，这限制了模型在软件工程中的实际应用和发展。
### Innovation
本研究引入了SWE-Arena，一个互动平台，专门用于评估SE任务中的基础模型。SWE-Arena提供了一个透明且开源的排行榜，支持多轮对话工作流程，并能进行端到端的模型对比。平台引入了新的评估指标，如模型一致性评分和对话效率指数。此外，平台还引入了RepoChat功能，可以自动将仓库相关的上下文（如问题、提交、拉取请求）嵌入对话中，从而更贴近实际的开发过程进行评估。
### Conclusion
本文概述了SWE-Arena的设计及其功能，强调了它在推动基础模型在软件工程中的评估和实际应用方面的潜力。
## 1046. `cs.LG` - 生成任何场景：场景图驱动的数据合成用于视觉生成训练 [PDF](https://arxiv.org/pdf/2412.08221), [HTML](https://arxiv.org/abs/2412.08221)
### Authors
Ziqi Gao,Weikai Huang,Jieyu Zhang,Aniruddha Kembhavi,Ranjay Krishna
### Background
文本到视觉生成（Text-to-Vision Generation）取得了显著的进步，但在场景组合的通用性和语义对齐方面仍面临挑战。现有数据集存在噪音大且组合性弱的问题，限制了模型对复杂场景的理解。同时，创建大规模高质量标注仍然存在挑战。因此，生成高质量且具有复杂性场景的方法仍然不足，尤其是在自动评估和语义对齐方面.
### Innovation
本文提出了Generate Any Scene（任何场景生成器），这是一种数据引擎，系统地枚举场景图，涵盖可能的视觉场景的组合数组。该系统能够生成不同复杂度的场景图，并将这些图转换为文本-图像或文本-视频生成的描述，以及视觉问题答案，用于自动评估和语义对齐的模型奖励建模。利用Generate Any Scene，设计了一个自改善框架，模型可以使用生成的数据逐代提升其性能，另一个设计了一种蒸馏算法，将专有模型的特定优势转移到开源模型中，最后提出了一种低成本的奖励模型来保持模型生成与语义准确性的对齐.
### Conclusion
Generate Any Scene 通过大量实验，展示了在文本到视觉生成、模型自改进、知识迁移和内容审核等多个下游任务中的应用效果，提升了模型在复杂场景生成、语义对齐和语义准确度等方面的性能。
## 1047. `cs.LG` - 基于梯度的样本选择以加速贝叶斯优化 [PDF](https://arxiv.org/pdf/2504.07742), [HTML](https://arxiv.org/abs/2504.07742)
### Authors
Qiyu Wei,Haowei Wang,Zirui Cao,Songhao Wang,Richard Allmendinger,Mauricio A Álvarez
### Background
贝叶斯优化（BO）是黑盒优化的有效技术，但由于构建高斯过程（GP）代理模型的计算复杂度接近三次方，其通常仅适用于中等预算问题。在大预算场景下，直接使用标准的GP模型面临显著的计算时间和资源需求挑战。
### Innovation
提出了一种新型的基于梯度的样本选择贝叶斯优化（GSSBO）方法，通过仅在选定的样本集上构建GP模型，利用梯度信息减少冗余同时保持多样性和代表性，提高BO的计算效率，并给出了基于梯度的样本选择策略的理论分析，获得了子线性遗憾界。
### Conclusion
在合成和实际任务上的大规模实验表明，该方法显著降低了GP拟合的计算成本，同时保持了与基准方法相当的优化性能。
## 1048. `cs.LG` - 三维统计系统中的分层自回归神经网络 [PDF](https://arxiv.org/pdf/2503.08610), [HTML](https://arxiv.org/abs/2503.08610)
### Authors
Piotr Białas,Vaibhav Chahar,Piotr Korcyl,Tomasz Stebel,Mateusz Winiarski,Dawid Zapolski
### Background
自回归神经网络(ANN)近年来被提出用作提高蒙特卡洛算法在多种自旋系统中的效率的机制。这个想法基于总概率配置可以分解为各个自旋的条件概率的事实，这些条件概率又可以用神经网络进行近似。据此，经过训练的ANN可用于从近似概率分布中采样配置，并可以显式地评估给定配置的概率。此外，人们还观察到这些条件概率可以提供信息论可观测值，如互信息或缠结熵。
### Innovation
该研究描述了三维分层自回归网络（HAN）算法，并使用三维ISING模型进行研究。HAN与三种其他自回归架构和经典的Wolff簇算法进行比较。此外，论文还为三维ISING模型提供了热力学可观测量的估计，如熵和自由能，涵盖了相变区域的不同温度范围。
### Conclusion
该研究通过比较四种不同的算法对三维ISING模型的性能，展示了HAN在实现更高效蒙特卡洛模拟中的优势，并给出了不同温度下热力学可观测量的估计结果。
## 1049. `cs.LG` - 如何使双语语言模型变得双语：使用稀疏自编码器追踪内部表示 [PDF](https://arxiv.org/pdf/2503.06394), [HTML](https://arxiv.org/abs/2503.06394)
### Authors
Tatsuro Inaba,Go Kamoda,Kentaro Inui,Masaru Isonuma,Yusuke Miyao,Yohei Oseki,Benjamin Heinzerling,Yu Takagi
### Background
本研究探讨了双语语言模型如何发展出复杂的内部表示。研究使用稀疏自编码器来分析双语语言模型的内部表示，重点是训练步骤、层数和模型尺寸对这些表示的影响。研究发现，语言模型首先独立学习每种语言，然后逐渐在中间层形成双语对齐。此外，研究还发现，大型模型中的这种双语倾向更强。
### Innovation
研究使用了一个新颖的方法，将完全训练好的模型中分解出来的表示整合到一个训练中期的模型中，以展示双语表示在模型性能中的关键作用。这一方法提供了新的视角，帮助理解语言模型是如何获得双语能力的。
### Conclusion
研究结果表明，语言模型在早期阶段独立学习每种语言，然后在中期层面形成双语对齐。较大的模型更倾向于在双语表示上产生较强的倾向。这表明双语表示在模型中的重要性，并为理解语言模型获取双语能力提供了新的见解。
## 1050. `cs.LG` - 理解并改进LLMs中提示压缩中的信息保存 [PDF](https://arxiv.org/pdf/2503.19114), [HTML](https://arxiv.org/abs/2503.19114)
### Authors
Weronika Łajewska,Momchil Hardalov,Laura Aina,Neha Anna John,Hang Su,Lluís Màrquez
### Background
近期，大型语言模型（LLMs）的进步使得它们在众多任务中取得成功应用。但在信息密集型任务中，提示长度迅速增长，导致计算需求增加、性能下降以及由无关或冗余信息引起的偏差。最近，引入了各种提示压缩技术以优化减少输入长度和保留性能之间的权衡。然而，现有的一些方法未能保留原始提示中的关键信息，限制了复杂任务上的表现。因此，需要一个全面的评估框架来深入分析提示压缩方法。
### Innovation
本文提出了一个综合评估框架，侧重于压缩比、下游任务性能、输入上下文连接性和信息保留等三个方面来分析先进的软式和硬式压缩方法。研究发现某些方法在压缩过程中未能保持关键信息，进而限制了复杂任务的表现。通过调整软提示的压缩粒度，改进了一种方法，取得了令人瞩目的提升：下游任务性能提高了23%，_grounding_增加了8个BERTScore点，压缩时保留了2.7倍的实体信息。这项研究揭示了软提示与序列级压缩相结合在有效性和压缩率之间的最佳权衡。
### Conclusion
最佳的有效性/压缩率权衡出现在软提示结合序列级压缩的方式中。
## 1051. `cs.LG` - 自监督对比学习在多模态图文分析中的综述 [PDF](https://arxiv.org/pdf/2503.11101), [HTML](https://arxiv.org/abs/2503.11101)
### Authors
Asifullah Khan,Laiba Asmatullah,Anza Malik,Shahzaib Khan,Hamna Asif
### Background
自监督学习是一种通过学习隐含模式和从无标签数据中提取 discriminative 特征来生成隐含标签的机器学习方法。对比学习引入了“正样本”和“负样本”的概念，使正样本（如同一图像/对象的变体）在嵌入空间中靠近，而负样本（如不同图像/对象的视图）则被推向远处。这种方法近年来在图像理解和图像文本分析中展现出显著的改进，大大减少了对有标签数据的依赖。
### Innovation
本文全面讨论了对比学习在图文模型中的术语、最新进展及其应用。具体而言，文章概述了近年来用于图文模型的对比学习方法，按不同的模型结构进行分类，并进一步介绍了整个过程中采用的最新技术，包括图像和文本的预训练任务、架构结构以及关键技术趋势。文章还讨论了最近基于自监督对比学习图文模型的最新应用。
### Conclusion
本文对自监督对比学习在多模态图文分析中的应用进行了综述，涵盖了术语的使用、最新进展和应用等方面的全面概述。通过分类不同的模型结构和探讨技术趋势，为该领域的进一步研究提供了依据和建议，同时也展示了这种方法在最近的应用中取得的最新成果。
## 1052. `cs.LG` - WyckoffDiff -- 一种晶体对称性生成扩散模型 [PDF](https://arxiv.org/pdf/2502.06485), [HTML](https://arxiv.org/abs/2502.06485)
### Authors
Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten
### Background
结晶材料通常表现出高度对称性，但大多数生成模型并未考虑对称性，而是对每个原子的位置和元素进行无约束建模。这项研究旨在通过设计一种考虑晶体结构中所有对称性的表示方法和构建能够利用该表示在离散生成模型框架内工作的新型神经网络架构，提出一种生成对称性描述的生成模型，Wyckoff Diff（WyckoffDiff）。
### Innovation
这篇论文提出了一种创新的生成模型WyckoffDiff，该模型能够生成基于对称性的晶体描述。通过设计一种能够考虑晶体结构中所有对称性的表示方法以及构建一种新型的神经网络架构，该模型能够在生成过程中自然地遵守对称性原则并实现快速生成。此外，论文还提出了一种新的度量标准Fréchet Wrenformer Distance，用于捕捉生成材料中的对称性特征，并在几种最近提出的晶体生成生成模型上进行了基准测试。研究还展示了WyckoffDiff用于在热力学稳定性凸包下方发现新材料的研究实例，作为其概念验证研究的一部分.
### Conclusion
WyckoffDiff能够在生成过程中自然地考虑和遵循晶体对称性，并且模型的离散特性使其能够快速生成。通过提出的新度量标准Fréchet Wrenformer Distance，论文还评估了WyckoffDiff在生成对称性材料方面的性能。WyckoffDiff被证明是一种有效的生成对称性描述的模型，并且成功地在实际应用中发现新材料。
## 1053. `cs.LG` - 使用元学习的系统提示优化 [PDF](https://arxiv.org/pdf/2505.09666), [HTML](https://arxiv.org/abs/2505.09666)
### Authors
Yumin Choi,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）展示了显著的能力，优化其输入提示对最大化模型性能起着关键作用。然而，现有的提示优化工作主要集中在针对特定查询或任务的用户提示上，而忽略了那些一旦优化就能适用于不同任务和领域的系统提示。本文聚焦于这一问题，提出了一种新的双层系统提示优化问题，并探讨了使用元学习框架解决这一问题的方法。
### Innovation
引入了新的双层系统提示优化问题，目标是设计出既对不同用户提示具有鲁棒性又能在未见任务间转移的系统提示。通过在多个数据集之间元学习系统提示，并在同一迭代过程中优化用户提示，以确保系统提示和用户提示之间的协同作用。实验结果显示，该方法在14个未见过的数据集上有效地对不同用户提示进行了泛化，同时优化后的系统提示能够快速适应未见任务，减少测试时的优化步骤并提高性能表现。
### Conclusion
本文提出了一个新的双层系统提示优化问题，并使用元学习框架解决了这一问题。实验表明，这种优化方式使得系统提示能够更有效地适应不同的用户提示，并能够快速适应未见过的任务，减少优化步骤并提高性能。
## 1054. `cs.LG` - 是什么让大型语言模型成为有效的序列推荐器？关于偏好强度和时间上下文的研究 [PDF](https://arxiv.org/pdf/2506.02261), [HTML](https://arxiv.org/abs/2506.02261)
### Authors
Zhongyu Ouyang,Qianlong Wen,Chunhui Zhang,Yanfang Ye,Soroush Vosoughi
### Background
现有的基于大型语言模型（LLM）的推荐系统在模仿人类灵活、具有情境感知的决策策略方面存在局限，未能很好地模拟人类在权衡经验、相对偏好强度和情境相关性方面的决策方式，忽略了与人类行为密切相关的结构化、动态和情境感知机制。论文分析了这一点，并指出现有模型难以复制人类的决策模式，特别是在序列推荐方面
### Innovation
提出了一个名为RecPO的偏好优化框架，旨在通过建模结构反馈和情境延迟来模拟人类在序列推荐中的优先级决策。RecPO利用推断的偏好层次结构和时间信号的最佳奖励边际，使模型能够优先考虑立即相关项目，并区分不同级别的偏好和厌恶程度。这一框架能够在多个实际数据集上产生优于最先进的基准的表现，并且能够部分重现人类决策的关键特性：优先满足需求、保持一致的偏好以及在不同情境下进行准确判断
### Conclusion
详尽的实验验证了RecPO不仅在性能上超越了现有的最佳基线模型，同时还能模仿人类决策过程中的关键属性：及时满足需求、持续一致的偏好以及在不同情境下进行仔细分辨判断的能力
## 1055. `cs.LG` - AdaReasoner: 自适应推理使大型语言模型更具灵活性 [PDF](https://arxiv.org/pdf/2505.17312), [HTML](https://arxiv.org/abs/2505.17312)
### Authors
Xiangqi Wang,Yue Huang,Yanbo Wang,Xiaonan Luo,Kehan Guo,Yujun Zhou,Xiangliang Zhang
### Background
LLMs在处理需要复杂推理和解决问题的任务时，如幽默生成和数学推理，往往需要有效的配置如温度和推理步骤。现有的提示方法通常采用通用且固定的配置，可以适用于多种任务，但在特定任务上尚未达到最优效果。
### Innovation
提出了AdaReasoner，这是一种LLM无关的插件，旨在自动化适应性推理配置，为不同类型的思考任务服务。AdaReasoner通过强化学习框架进行训练，结合分解的动作空间、目标探索策略以及预训练奖励模型，以最优化推理配置政策。该研究提供了理论保证，并通过实验保证了收敛速度快、政策差距呈亚线性增长。
### Conclusion
在六种不同的LLM和各种推理任务中，AdaReasoner在标准基线中表现出色，保持了离分布鲁棒性，并通过定制提示在知识密集型任务中带来了收益。
## 1056. `cs.LG` - 可解释的人工智能应用于城市热岛缓解：多尺度驱动因素的归因与加权 [PDF](https://arxiv.org/pdf/2507.04802), [HTML](https://arxiv.org/abs/2507.04802)
### Authors
David Tschan,Zhi Wang,Dominik Strebel,Jan Carmeliet,Yongling Zhao
### Background
城市热岛在热浪期间会加剧，并对公众健康构成风险。因此，城市规划者需要了解不同土地使用类型（LUTs）和驱动因素如何影响城市的热分布，从综合气候背景过程到小规模城市和跨尺度特征。研究表明，通过分类驱动因素为驱动（D）、城市（U）和本地（L）特征，可以更好地理解和减轻城市热岛。
### Innovation
本文提出了一种区分土地使用类型的新机器学习方法，用以快速模拟Weather Research and Forecasting (WRF)模型整合Noah土地表面模型（LSM）的预测能力，以预测地面温度（TSK）和2米气温（T2）。该方法采用了随机森林回归（RFR）和极端梯度提升（XGB）训练，通过分类和加权多尺度驱动因素，专注于表面发射率、反照率和叶面积指数等关键小尺度驱动因素，提高了模型的可解释性和计算效率。该框架下的模型比非框架模型在准确性和解释性上表现更好。
### Conclusion
使用RFR-XGB方法，城市规划者可以直接获得多尺度驱动因素对地面和2米气温的影响，这种方法在热浪数据较多的训练集下性能更优，并显著提高了模型的可解释性。尽管仍有不确定性需要减少，并需要在其他城市进行测试，但该方法为城市热岛缓解提供了直接的框架评估途径。
## 1057. `cs.LG` - Lizard：大规模语言模型高效线性化框架 [PDF](https://arxiv.org/pdf/2507.09025), [HTML](https://arxiv.org/abs/2507.09025)
### Authors
Chien Van Nguyen,Ruiyi Zhang,Hanieh Deilamsalehy,Puneet Mathur,Viet Dac Lai,Haoliang Wang,Jayakumar Subramanian,Ryan A. Rossi,Trung Bui,Nikos Vlassis,Franck Dernoncourt,Thien Huu Nguyen
### Background
 Transformers 遇到长序列时面临着严重的计算和内存瓶颈，因为其注意力操作（softmax）具有二次复杂度，以及增长的 Key-Value 缓存导致推理过程因上下文长度限制而内存绑定。
### Innovation
 提出了一种线性化框架 Lizard，通过引入一个亚二次关注机制来近似替换 softmax 关注机制，同时保持模型质量。Lizard 增强了可适应的内存控制和长序列下的稳健泛化能力，引入了硬件敏感算法解决了门控注意力中的数值不稳定性问题，加快了训练速度。
### Conclusion
 实验结果表明，Lizard 实现了对教师模型性能近似无损的恢复，并在 5-shot MMLU 基准测试中显著优于先前方法，性能提升了 9.4-24.5 点，同时显示出更强的关联回忆能力。
## 1058. `cs.LG` - 随机梯度下降方案的最后迭代收敛速率 [PDF](https://arxiv.org/pdf/2507.07281), [HTML](https://arxiv.org/abs/2507.07281)
### Authors
Marcel Hudiani
### Background
该研究探讨了在参数设定下，当目标函数F是全局凸函数或非凸函数（其梯度是γ-Hölder连续），随机梯度下降(SGD)和随机重球法(SHB)的最后迭代收敛速率。研究使用了离散的Gronwall不等式来重新获得SGD和SHB的结果，而无需使用Robbins-Siegmund定理。
### Innovation
研究直接通过离散Gronwall不等式恢复了SGD和SHB的收敛结果，并证明了当目标函数F是凸函数并且γ=1时，SHB带有常数动量参数β（0<β<1）在步长α_t=Θ(t^-p)时（p∈(1/2, 1)）可以达到收敛速率F(w_t)-F_* = O(t^max(p-1, -2p+1) log^2 (t/δ))的概率至少为1-δ。此外，还研究了非凸最小值的渐近结果和凸对象最优点的渐近结果。
### Conclusion
研究确定了SHB在特定条件下（当目标函数是凸函数且γ=1时）的收敛速率。同时，研究指出包括SGD和SHB在内的两种随机梯度下降方法在求解凸与非凸优化问题时的具体收敛速度。
## 1059. `cs.LG` - ACD-CLIP: 分开表示和动态融合以实现零样本异常检测 [PDF](https://arxiv.org/pdf/2508.07819), [HTML](https://arxiv.org/abs/2508.07819)
### Authors
Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Zhen Dai,Yueyi Luo
### Background
预训练的视觉-语言模型（VLMs）在零样本异常检测（ZSAD）中表现出困难，主要是因为缺乏针对密集预测所需的局部归纳偏置，并且功能融合方法僵化。
### Innovation
本文通过一个体系结构协同设计框架共同精炼特征表示和跨模态融合。提出了一种参数效率的卷积低秩适应（Conv-LoRA）适配器来注入局部归纳偏置，以实现精细表示，并引入了动态融合网关（DFG），利用视觉上下文自适应地调节文本提示，实现了强大的双向融合。
### Conclusion
广泛的实验表明，与各种工业和医学基准数据集相比，该协同设计方法在准确性和鲁棒性方面表现更优，证实了这种协同设计对于使基础模型适应密集感知任务的稳健性至关重要。源代码可在以下链接获取。
## 1060. `cs.LG` - 从实体可靠性到清洁反馈：超越交互级信号的基于实体感知去噪框架 [PDF](https://arxiv.org/pdf/2508.10851), [HTML](https://arxiv.org/abs/2508.10851)
### Authors
Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Kai Zhang,Jun Zhou
### Background
隐式反馈在现代推荐系统中至关重要，但其噪声性往往影响模型训练，降低推荐准确性和用户体验。大规模情况下，噪声误导学习过程，进一步影响平台价值。现有去噪策略通常忽略了噪声的实体特异性，增加了计算复杂度和超参数调优的复杂性。
### Innovation
本文提出了一种轻量级框架EARD（Entity-Aware Reliability-Driven Denoising），该框架从实体级可靠性出发，而不是关注交互级信号。EARD通过用户和项目平均损失作为其信誉的代理进行量化，并将这些实体级因素与交互级信心整合。该框架模型无关、计算效率高且仅需两个直观的超参数即可。实验证明EARD在多个数据集和统计模型下显著超越现有基准模型，且额外计算成本几乎可以忽略。
### Conclusion
该结果凸显了实体感知可靠性建模在去噪隐式反馈中的重要性，并为更稳健的推荐研究铺平了道路。
## 1061. `cs.LG` - 广义概率近似优化算法 [PDF](https://arxiv.org/pdf/2507.07420), [HTML](https://arxiv.org/abs/2507.07420)
### Authors
Abdelrahman S. Abdelrahman,Shuvro Chowdhury,Flaviano Morone,Kerem Y. Camsari
### Background
本文介绍了广义的‘概率近似优化算法（PAOA）’，这是一种扩展和完善了Weitz等人先前工作[Combes_2023]的经典变分蒙特卡洛框架。PAOA能够在当今的伊辛机和概率计算机上进行参数化和快速采样，通过迭代调整二元随机单元网络中的耦合，并根据独立样本的成本评估进行指导。本文建立了无导数更新与完整马尔可夫流的梯度之间的直接对应关系，表明PAOA具有原理性的变分形式。模拟退火是其在参数约束下的极限情况，研究者还在基于FPGA的概率计算机上实现了这一机制，以解决大型3D自旋玻璃问题。将PAOA与QAOA在典型26个自旋的Sherrington-Kirkpatrick模型中的性能进行了基准测试，结果显示PAOA表现更优。研究还展示了PAOA通过优化多个温度谱来自然扩展模拟退火，从而在重尾问题（如SK-Lévy）上性能更优。
### Innovation
该研究提出了一种广义的PAOA算法，其创新点在于将无导数更新与完整马尔可夫流的梯度建立了直接对应关系，具有原理性的变分形式，并在基于FPGA的概率计算机上实现了模拟退火机制，解决了大型3D自旋玻璃问题。此外，PAOA通过优化多个温度谱自然扩展了模拟退火，从而在重尾问题上表现出更好的性能。
### Conclusion
研究结果表明，PAOA在解决复杂优化问题时具有显著的优越性，特别是在大型3D自旋玻璃问题和重尾问题上。PAOA不仅在性能上优于现有的方法如QAOA，还展示了其在不同温度参数下的灵活性和优化潜力。
## 1062. `cs.LG` - VisionTS++：基于连续预训练视觉骨干的跨模态时间序列基础模型 [PDF](https://arxiv.org/pdf/2508.04379), [HTML](https://arxiv.org/abs/2508.04379)
### Authors
Lefei Shen,Mouxiang Chen,Xu Liu,Han Fu,Xiaoxue Ren,Jianling Sun,Zhuo Li,Chenghao Liu
### Background
近期研究表明，通过将时序预测（TSF）重新表述为图像重建，预训练于图像上的视觉模型可以作为时间序列基础模型（TSFMs）。然而，这种从视觉到时间序列的有效跨模态转移仍然具有挑战性，主要是因为以下三个差距：（1）结构化且受限的图像数据与非受限且异构的时间序列之间的数据模态差距；（2）固定色彩通道的视觉模型与任意数量变量的时序之间的多变量预测差距；（3）视觉模型的确定性输出与需要不确定性意识的概率预测之间的概率预测差距。
### Innovation
本文提出了VisionTS++，一种基于视觉模型连续预训练的时间序列基础模型（TSFM），其主要创新点如下：（1）利用基于视觉模型的筛选机制来识别高质量序列以稳定预训练并缓解模态差距；（2）色彩化多变量转换，将多变量序列编码为多子图RGB图像以增强跨变量建模；（3）多分位数预测，使用并行重建头生成无参数假设的分位数预测。
### Conclusion
实验结果表明，VisionTS++在分布内外预测中均达到了最先进的性能，相比专门的时间序列模型在MSE减少方面提高了6%-44%，在GIFT-Eval基准测试中排名第一，该基准测试包括来自7个领域共23个数据集。本研究表明，通过适当的适应，视觉模型可以有效地应用于TSF，从而推动了通用TSFMs的追求。相关代码可在该网址获取。
## 1063. `cs.LG` - 基于神经元的波束场（Neural Beam Field） [PDF](https://arxiv.org/pdf/2508.06956), [HTML](https://arxiv.org/abs/2508.06956)
### Authors
Keqiang Guo,Yuheng Zhong,Xin Tong,Jiangbin Lyu,Rui Zhang
### Background
在密集的多用户无线网络中，精确预测波束级参考信号接收功率（RSRP）对于波束管理至关重要，但由于存在高测量开销和快速的信道变化，这成为一个挑战。现有的解决方案无法有效地处理这一问题。该论文提出了一种叫做Neural Beam Field（NBF）的混合神经-物理框架，旨在实现高效和可解释的空间波束RSRP预测。
### Innovation
中央关键是引入了多路径条件功率配置文件（MCPP），这是一种学习物理中介，表示特定站点的传播环境。NBF采用了一个解耦的“黑盒-白盒”设计：基于Transformer的深度神经网络（DNN）从稀疏的用户测量和位置中学习MCPP，物理启发模块则进行RSRP统计的解析推断。为了提高收敛性和适应性，还引入了一种预训练和校准（PaC）策略，即利用射线追踪先验进行物理基础预训练，然后用RSRP数据进行现场校准。该方法显著提高了预测精度、训练效率和泛化能力，同时也保持了紧凑的模型大小。
### Conclusion
NBF提供了智能波束管理的一种可扩展且物理基础的解决方案，在下一代密集无线网络中具备广泛的应用前景。
## 1064. `cs.LG` - 基于逐渐层冻结的站点级微调：从极早早产儿第一天胸片向稳健的慢性肺病预测 [PDF](https://arxiv.org/pdf/2507.12269), [HTML](https://arxiv.org/abs/2507.12269)
### Authors
Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)
### Background
极低出生体重婴儿中慢性肺病（BPD）的发生率较高，影响约35%的此类婴儿。BPD通过新生儿36周胎龄后对氧气的依赖性来定义，会导致终生的呼吸并发症。尽管预防措施存在神经发育损伤、机械通气引起的肺损伤和全身性并发症等严重风险，早期BPD预后和预测BPD结果对于避免低风险婴儿不必要的毒性至关重要。婴儿通常在出生后的24小时内接受常规胸部X线检查，这些图像可以作为无创预后工具。本研究使用163名极低胎龄（≤32周胎龄，401-999g）婴儿在出生后24小时内获得的胸部X光片，开发并调查了一种深度学习方法，旨在准确预测BPD从第一天胸部X光片。几乎所有新生儿都会接受这种常规胸部X光检查，因此这些图像能够提供有价值的信息。但常规的IRDS评分在预测BPD方面表现有限，这强调了需要学习特定标记的重要性。
### Innovation
该研究使用了基于逐渐层冻结的方法进行站点级微调，利用这种方法对预先在成人胸部X光片上训练的ResNet-50模型进行微调，并使用CutMix增强技术和线性探测。这种方法显著优于从ImageNet初始化（p = 0.031），证明了在BPD预后中进行领域特定预训练的重要性。此外，通过逐渐层冻结和线性探测的方法使得该方法具备了在站点级实施和未来联邦学习部署中的计算可行性。该方法表明，基于逐渐层冻结的微调能够从常规第一天的胸部X光片中准确预测BPD。这种方法还确认了学习到的特定标记对于BPD预测的价值。
### Conclusion
该研究通过逐渐层冻结的方法和线性探测技术，在极早早产儿第一天的胸部X光片上实现了对BPD的准确预测。这种方法表明，进行领域特定的预训练可以提高BPD预测的准确性，并且这种方法在站点级实施具有可行性，为进一步的联邦学习部署提供了可能。
## 1065. `cs.LG` - 基于搜索的离线偏好强化学习中的信用分配方法 [PDF](https://arxiv.org/pdf/2508.15327), [HTML](https://arxiv.org/abs/2508.15327)
### Authors
Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li
### Background
离线强化学习是指从固定数据集中学习策略，不需要额外的环境交互。然而，它通常依赖于定义良好的奖励函数，而设计这些奖励函数是困难且昂贵的。人类反馈是一种有吸引力的替代方案，但其两种常见形式，专家演示和偏好，各有局限性。专家演示提供了逐步监督，但收集成本高昂且往往反映了有限的专家行为模式。相比之下，偏好收集起来更便捷，但不清楚哪种行为部分对路径片段的贡献最大，导致信用分配不明确。
### Innovation
本文提出了一种基于搜索的偏好加权（SPW）方案，以统一这些两种反馈来源。对于偏好标记轨迹中的每个过渡，SPW 从专家演示中搜索最相似的状态-动作对，并直接基于相似度分数推导逐步重要权重。随后，这些权重被用来引导标准的偏好学习，从而实现更准确的信用分配，这是传统方法难以做到的。SPW 实现了偏好和演示的有效联合学习，在挑战性的机器人操纵任务上优于先前利用两种反馈类型的先有方法。
### Conclusion
本文提出了SPW方案，通过将专家演示和偏好结合，解决了信用分配问题，提升了离线偏好强化学习的效果，在机器人操纵任务上取得了显著成效。
## 1066. `cs.LG` - 通过级联对比表示学习从限价订单簿检测多层次操纵 [PDF](https://arxiv.org/pdf/2508.17086), [HTML](https://arxiv.org/abs/2508.17086)
### Authors
Yushi Lin,Peng Yang
### Background
贸易操纵（TBM）严重影响了金融市场的公平性和稳定性。Spoofing是一种隐蔽性强且欺骗性高的TBM策略，其异常模式在多个价格层次上呈现出复杂性，但常常被简化为单一层次的操纵。这些模式通常隐藏在限价订单簿（LOB）的丰富层次信息中，由于高维度和噪声，利用这些信息颇具挑战性。
### Innovation
本文提出了一种结合级联LOB表示架构与监督对比学习的表示学习框架，用于检测多层次操纵。该框架在多种模型中展示了持续提高的检测性能，基于Transformer的架构达到了最新的技术水平。此外，通过系统分析和消融研究，探究了多层次操纵以及关键组件的检测贡献，为复杂时间序列数据中的表示学习和异常检测提供了更广泛的理解。
### Conclusion
实验结果表明，该框架在多种检测模型中表现出一致的改进性能，特别是在基于Transformer的架构上达到了最先进的结果。通过消融研究和系统分析，提供了对于复杂时间序列数据的表示学习和异常检测的更深层次的见解。
## 1067. `cs.LG` - 通过强化学习实现BVLoS路径规划以最大化UAV蜂窝连通性 [PDF](https://arxiv.org/pdf/2509.13336), [HTML](https://arxiv.org/abs/2509.13336)
### Authors
Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah
### Background
本文旨在解决基于蜂窝连接的无人机（UAV）在视距外（BVLoS）操作中的路径规划问题。UAVs在远处执行任务时，必须确保与地面基站（BSs）之间的通信质量，以保证操作的安全和可靠性。
### Innovation
提出了一种基于强化学习（RL）的方法，利用通信链路质量作为奖励函数来训练代理，以最小化飞行距离同时最大化蜂窝链路质量。这种方法能够解决有限的UAV蜂窝通信能力带来的挑战，特别是在空中覆盖和通道模型的限制下。
### Conclusion
该方法有效地解决了BVLoS操作中路径规划的问题，能够在线下生成可实现的UAV路径规划方案，并且这种方法可以集成到未来的地面控制系统（GCS）中，以增强UAV操作的安全性和能力。对未来长距离UAV应用特别是蜂窝连接无人机路径规划领域的发展具有潜在影响力。
## 1068. `cs.LG` - COMPACT: 共同标记优化的跨通道和标记修剪 [PDF](https://arxiv.org/pdf/2509.06836), [HTML](https://arxiv.org/abs/2509.06836)
### Authors
Eugene Kwek,Wenpeng Yin
### Background
对于边缘部署、交互式应用程序和大规模可持续推理而言，提高大型语言模型（LLMs）在内存、延迟和推理成本方面的效率至关重要。剪枝技术被证明是一种有潜力的方法，但是现有的剪枝方法有限：宽度剪枝经常破坏标准变换器布局，不得不使用定制推理代码；深度剪枝则会导致准确率突然下降。此外，虽然很多剪枝方法对LLMs有效，但在保持小型语言模型（SLMs）性能方面却遇到困难。
### Innovation
本文提出了COMPACT，这是一种联合剪枝方法，（i）通过剪枝稀有词汇来缩小嵌入/语言模型头部层；（ii）利用通用标记加权激活剪枝FFN中间通道，使得重要性与后剪枝标记分布一致。COMPACT结合了深度和宽度剪枝的优点，如：部署友好型（保留标准变换器架构）、尺度适应性（在词表量与FFN剪枝间权衡）、强有力的剪枝时间、以及在减少参数、GPU内存和延迟的同时提升吞吐量。实验表明，COMPACT在Qwen、LLaMA和Gemma家族（0.5B至70B参数）语言模型上具有最先进的下游性能，大幅减少了参数、GPU内存并降低了延迟。
### Conclusion
COMPACT 实现了与标准变换器架构兼容、能够权衡词表剪枝与FFN剪枝的剪枝方法，并且提供了竞争优势的剪枝速度，大幅度节省内存和提高吞吐量。在Qwen、LLaMA和Gemma家族中展示出优异的下游性能，证明了其在减小模型参数、降低GPU内存和缩短延迟方面的显著成效。
## 1069. `cs.LG` - MOCHA：多模态对象感知跨架构对齐 [PDF](https://arxiv.org/pdf/2509.14001), [HTML](https://arxiv.org/abs/2509.14001)
### Authors
Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli
### Background
该论文介绍了一种知识蒸馏方法MOCHA（Multi-modal Objects-aware Cross-arcHitecture Alignment），旨在将大型视觉-语言教师模型（例如LLaVa）的区域级多模态语义转移到轻量级的视觉仅对象检测学生模型（例如YOLO）中。与以往注重密集或全局对齐的方法不同，MOCHA在对象级别工作，无需修改教师模型或在推理时需要文本输入，即可高效地转移语义。
### Innovation
MOCHA创新地采用了一个翻译模块将学生特征映射到联合空间，在该空间中使用双重目标损失函数指导学生和翻译器的训练，同时确保局部对齐和全局关系一致性。此外，MOCHA是一种轻量级方法，能够在保持性能的同时，实现与更大模型相当的性能，适用于实际部署的场景。
### Conclusion
该研究在四个个性化的检测基准测试下验证了MOCHA在少样本情况下的效果，结果显示相对于基准方法有显著的性能提升，平均得分提高了10.1分。尽管架构紧凑，但MOCHA仍能达到与更大模型相当的性能，证明了其在实际部署中的适用性。
## 1070. `cs.LG` - MorphGen: 可控且形态合理的生成细胞成像 [PDF](https://arxiv.org/pdf/2510.01298), [HTML](https://arxiv.org/abs/2510.01298)
### Authors
Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello
### Background
使用in silico方法模拟细胞对干预的响应，是加速基于高内涵成像的药物发现和基因编辑的关键方向。为了实现这一目标，本文引入了MorphGen，这是一种基于扩散的生成模型，能够为多种细胞类型和干预措施生成可控制的荧光显微镜图像。该模型通过与OpenPhenom进行对齐损失训练，以匹配已知的细胞形态表型嵌入，实现了与真实图像的一致性。
### Innovation
MorphGen在生成图像时，能够联合生成完整的荧光通道，保留了每个亚细胞结构的细节，避免了将多通道染色压缩成RGB图像而损失特定亚细胞结构详细信息的问题。它与基于OpenPhenom训练的方法相比，在FID得分上降低了超过35%，并且能够在单个细胞类型之外进行多类型的生成，提高了生物学解释的精细度。
### Conclusion
MorphGen通过与OpenPhenom进行表型嵌入对齐训练，实现了形态合理且可控制的荧光显微镜图像生成，显著提高了生物解释的精确性，并在多项性能指标上优于现有模型。相关代码可在指定链接获取。
## 1071. `cs.LG` - 通过霍夫丁分解解释具有多元伯努利分布的模型 [PDF](https://arxiv.org/pdf/2510.07088), [HTML](https://arxiv.org/abs/2510.07088)
### Authors
Baptiste Ferrere(EDF R?&amp;D PRISME, IMT, SINCLAIR AI Lab),Nicolas Bousquet(EDF R?&amp;D PRISME, SINCLAIR AI Lab, LPSM (UMR?_8001)),Fabrice Gamboa(IMT),Jean-Michel Loubes(IMT),Joseph Muré(EDF R?&amp;D PRISME)
### Background
该研究旨在解释在随机输入的条件下，预测模型的行为。以往的研究证明，通过子模型分解，可以使用具有更易解释特征的子模型来实现这一目标。最新的结果表明，当随机输入变量相关时，存在且唯一的一种广义霍夫丁分解，基于L2子空间的斜投影概念。
### Innovation
本文重点关注具有伯努力分布的输入变量情况，并提供了此分解的完整描述。研究表明，在这种情况下，底层的L2子空间是一维的，并且分解是显式的。这导致了一个完全可解释的框架，并且理论上允许反向工程。可以明确获得输入对输出预测影响的指标（例如Sobol指数和Shapley效果）。
### Conclusion
通过数值实验，这种分析方法对于决策支持问题（例如二值决策图、布尔网络或二值神经网络）的应用证明是有效的。文章还概述了探索高维设置以及将这些发现扩展到有限可数输入模型的可能性。
## 1072. `cs.LG` - 在线成对比较生成的在线评价标准提取 [PDF](https://arxiv.org/pdf/2510.07284), [HTML](https://arxiv.org/abs/2510.07284)
### Authors
MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Bing Liu,Yunzhong He,Afra Feyza Akyürek
### Background
评分标准为训练LLMs生成开放式长格式答案提供了一种灵活的方法，尤其是在无法应用可验证的奖励且人类偏好只能提供粗略信号的情况下。现有研究表明，基于评分标准的强化学习有助于显著提升LLM训练后的表现。然而，大多数现有方法依赖于在整个训练过程中保持不变的评分标准。这些静态评分标准容易受到奖励篡改行为的影响，并且无法捕捉到训练过程中出现的新兴需求.
### Innovation
作者引入了Online Rubrics Elicitation (OnlineRubrics) 方法，该方法通过当前策略与参考策略响应的成对比较动态构建评价标准。这种方法能够在在线训练过程中持续识别和缓解错误，同时导致持续的改进。实验结果表明，在多种评估环境下，该方法比单独使用静态评分标准的改进幅度最大可达8%。
### Conclusion
通过成对比较生成的在线成对比较方法能够有效地提升LLM生成高质量回答的能力，特别是在评分标准复杂的场景下。提取的评价标准展示了透明度、实用性、组织性和推理等重要主题，树立了进一步改进的标准和方向。
## 1073. `cs.LG` - 部署小型大型视觉-语言模型法官以进行图表模型的实际评价：经验教训和最佳实践 [PDF](https://arxiv.org/pdf/2510.07545), [HTML](https://arxiv.org/abs/2510.07545)
### Authors
Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang
### Background
研究背景介绍了现有较小参数量的视觉-语言模型在图表理解和评价任务中的局限性，特别是在资源受限的环境下表现不佳。因此，需要新的方法来提高这些模型的评价效率。
### Innovation
此项研究提出了两种确保评估成本效益的方法：(1) 一个多标准提示策略，即将多个评价标准合并为一个查询，以及(2) 领域适应迁移学习，通过在合成判断的数据集上微调一个有2亿参数的视觉-语言模型，从而创建出‘图表法官’模型。这些方法旨在提高小型模型的评价能力。
### Conclusion
研究通过详细的分析不同图表类型和查询复杂性下的图表推理任务，提供了关于模型大小、提示设计和迁移性之间的权衡关系的具体洞见，从而有助于实现大规模、低成本的图表推理任务评价。
## 1074. `cs.LG` - 6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection [PDF](https://arxiv.org/pdf/2510.03807), [HTML](https://arxiv.org/abs/2510.03807)
### Authors
Vaskar Chakma,Wooyeol Choi
### Background
当前集成了数字孪生(DT)技术的物联网系统(CPS)在关键工业应用中面临实时性能的限制。现有的5G系统因延迟超过10ms而无法满足需要亚毫秒级响应时间的应用需求，例如自主工业控制和预测性维护。为了克服这一限制，该研究开发并验证了一个基于6G的数字孪生框架，旨在实现超低延迟通信和物理资产与其数字孪生体之间的实时同步，特别聚焦于轴承故障检测这一关键工业应用场景。
### Innovation
该研究提出了一种结合太赫兹通信、智能反射表面和边缘人工智能的五层架构，以实现超低延迟和实时同步。实验验证使用了CWRU轴承数据集，通过全面的特征提取和随机森林分类算法评估系统性能。该系统在分类准确性、端到端延迟和可扩展性等多个指标上优于传统的WiFi-6和5G网络，显示了卓越的性能和可扩展性。
### Conclusion
该研究成功开发并验证了一个基于6G的数字孪生框架，该框架在工业轴承故障检测场景中实现了97.7%的故障分类准确性和0.8ms的端到端延迟，分别比WiFi-6和5G网络的性能提高了15.6倍和5.25倍。系统展示了优异的可扩展性，处理时间增长率接近于线性，并在四个轴承故障类别（正常、内圈、外圈和球体故障）中保持了稳定的性能。
## 1075. `cs.LG` - 从数据到奖励：最大似然估计的 bilevel 优化视角 [PDF](https://arxiv.org/pdf/2510.07624), [HTML](https://arxiv.org/abs/2510.07624)
### Authors
Abdelhakim Benechehab,Gabriel Singer,Corentin Léger,Youssef Attia El Hili,Giuseppe Paolo,Albert Thomas,Maurizio Filippone,Balázs Kégl
### Background
生成模型构成了现代机器学习的核心，支撑了文本、视觉和多模态应用中的前沿系统。尽管最大似然估计长期以来一直作为主要的训练范式，但近期的工作指出，它在泛化能力和对抗灾难性遗忘方面不如强化学习技术，例如策略梯度方法。然而，这些方法依赖于明确的奖励信号，而在实践中这些信号往往是不可用的，这就提出了一个根本问题：当只有高质量的数据集可用时，如何对齐生成模型。
### Innovation
本工作通过一个 bilevel 优化框架解决了这一挑战，其中奖励函数作为外层问题的优化变量，内层则定义为策略梯度目标。并在此可处理的设置下对这个问题的优化进行了理论分析，从中提取出的部分洞察可推广应用于表格分类和模型基础的强化学习等领域。
### Conclusion
本研究通过 bilevel 优化框架研究了最大似然估计的方法，并通过理论分析获得了一定的洞察，这些洞察在实际应用中也有广泛的应用前景。
## 1076. `cs.SE` - 哪种更有利于减少过时和易受攻击的依赖：锁定还是漂浮？ [PDF](https://arxiv.org/pdf/2510.08609), [HTML](https://arxiv.org/abs/2510.08609)
### Authors
Imranur Rahman,Jill Marley,William Enck,Laurie Williams
### Background
开发人员频繁使用版本约束来指定项目依赖项的可接受版本。锁定依赖项可以减少破坏性更改的可能性，但需要手动处理过时和漏洞依赖项的替换，而漂浮则可以自动获取错误修复和安全修复，但面临破坏性更改的风险。安全从业者建议锁定依赖项以防止软件供应链攻击，例如恶意包更新。然而，由于锁定是最紧的版本约束，因此更可能导致依赖项过时。
### Innovation
研究通过在大规模下实证评估不同版本约束类型导致依赖项过时或成为漏洞的可能性，发现在过时和漏洞依赖项中最常用的版本约束类型是漂浮次要版本，其次是锁定。同时发现漂浮主要版本最不可能导致依赖项过时，而漂浮次要版本最不可能导致依赖项成为漏洞。
### Conclusion
本研究通过实证方法帮助开发者更明智地选择依赖项版本约束类型，发现漂浮次要版本是减少过时和漏洞依赖项的有效方式之一。
## 1077. `cs.SE` - 基于相对位置的代码片段分块方法在代码语言模型的仓库级别代码完成任务中的丰富上下文检索 [PDF](https://arxiv.org/pdf/2510.08610), [HTML](https://arxiv.org/abs/2510.08610)
### Authors
Imranur Rahman,Md Rayhanur Rahman
### Background
代码补全能够帮助开发人员提高效率并简化开发周期。尽管现代集成开发环境（IDEs）中提供了代码补全功能，但研究中缺乏基于IDEs可用信息研究如何构建好的代码补全上下文来帮助大型语言模型（LLMs）更好地完成任务。目前的研究主要集中在如何利用合适的上下文来提升代码补全的表现。
### Innovation
本文提出了一种有效的代码分块策略，通过将仓库预处理成较小的代码片段，并使用基于语法和语义相似度的代码片段检索方法，结合片段的相对位置，从而提升代码补全任务的表现。
### Conclusion
这种代码分块结合相对定位的方法能够显著改善代码完成任务的表现。
## 1078. `cs.SE` - 通过领域特定工具缩小LLM代理推理与执行差距的Android构建修复自动化 [PDF](https://arxiv.org/pdf/2510.08640), [HTML](https://arxiv.org/abs/2510.08640)
### Authors
Ha Min Son,Huan Ren,Xin Liu,Zhe Zhao
### Background
Android是最大的移动平台，但自动构建应用仍然是实际挑战。虽然大型语言模型（LLMs）在代码修复方面表现出潜力，但它们在修复Android构建错误方面仍较少被探索。
### Innovation
本文首先介绍了AndroidBuildBench，这是一个包含1,019个从43个开源Android项目提交历史中收集的构建失败情况的基准测试。每个问题都配有一个验证过的解决方法。其次，提出了一种名为GradleFixer的LLM代理，结合领域特定工具来检查和操作Gradle构建环境。GradleFixer解决了81.4%的问题，超过了一种依赖于通用shell的最先进的编码代理。此外，作者提出了一种策略，称为工具桥接，用领域意识抽象取代通用shell命令，以提高模型执行领域的有效性。
### Conclusion
工具桥接策略通过提供适合LLM使用的API格式工具，并限制有效的操作空间，缩小了模型的高层次推理与低层次执行之间的差距。
## 1079. `cs.SE` - RA-Gen：一种基于ReAct的多智能体任务执行的可控代码生成框架 [PDF](https://arxiv.org/pdf/2510.08665), [HTML](https://arxiv.org/abs/2510.08665)
### Authors
Aofan Liu,Haoxuan Li,Bin Wang,Ao Yang,Hui Li
### Background
基于大规模语言模型（LLMs）的代码生成模型已经广泛采用，但在确保安全性、准确性和可控性方面，尤其是在处理复杂任务时，仍面临挑战。现有的方法往往缺乏对外部工具的动态集成、透明推理以及用户对安全性的控制能力。
### Innovation
提出了一个基于ReAct范式的可控代码生成框架，该框架采用多智能体系统设计，通过LLMs与外部资源之间的动态交互实现高效、精确和可解释的代码生成。该框架包含四个专门的代理：计划者、搜索者、代码生成器和提取器，共同协作完成任务。搜索者基于ReAct框架交替生成推理轨迹并执行操作，增强准确性并增强用户控制。实验结果显示该框架的有效性，达到94.8%的安全性分数，并在CodeQL上超越现有方法。
### Conclusion
RA-Gen框架证明了其在多语言环境中的有效性，并通过透明的推理过程增强了用户信任和可控性，展示了其在安全性与准确性方面优于现有方法的优势。
## 1080. `cs.SE` - 大型语言模型在机器辅助解决用户意图方面的比较分析 [PDF](https://arxiv.org/pdf/2510.08576), [HTML](https://arxiv.org/abs/2510.08576)
### Authors
Justus Flerlage,Alexander Acker,Odej Kao
### Background
大型语言模型（LLMs）作为自然语言理解和用户意图识别的革新性工具，推动了翻译、总结及复杂流程编排任务的应用。这标志着从传统图形用户界面（GUI）向语言优先交互模式的转变。在语言优先的交互方式中，用户可以通过自然语言来描述其目标，从而使LLMs能够在多个应用间动态、上下文地调度行动。然而，现有实施大多依赖于云端的专有模型，这带来了隐私、自主性和可扩展性方面的限制。为了使语言优先的交互方式成为真正强大且值得信赖的界面形态，局部部署不再是便利性问题，而是一种必要性。因此，评估可局部部署、开源且开放访问的LLMs作为未来基于意图操作系统的基础组件的可行性变得至关重要。本研究探讨了几种开源和开放访问模型在机器辅助解决用户意图方面的能力，并与OpenAI的基于GPT-4的专有系统进行了比较分析，以评估其在各类用户意图下的工作流生成性能。这项研究提供了开源LLMs作为自主、本地操作组件在下一代操作系统中的实用可行性和性能权衡的实际见解，同时也促进了对AI基础设施去中心化和民主化讨论，并预示了一个更加无缝、适应性强和隐私保护的未来，其中用户设备交互通过本地嵌入的智能变得更加紧密。
### Innovation
本研究创新性地通过将几种开源和开放访问的大语言模型应用于用户意图解决，并与OpenAI的专有系统进行比较，探讨了开源模型在生成各种用户意图下工作流方面的性能和可行性和可能。这一研究填补了现有研究中开源LLM在局部部署和实现自主操作组件进操作系统方面的空白，也为未来基于意图的操作系统的发展提供了实际参考。
### Conclusion
该研究表明，开源大型语言模型在局部部署下的可用性、性能权衡和潜在应用表现是可行的，并强调了开源LLMs作为自主、本地操作组件的重要作用，为其在下一代操作系统中的广泛应用提供了有力的支持。研究结果为进一步讨论AI基础设施的去中心化和民主化，并鼓励采用更加无缝、适应性强和注重隐私的设计提供了新的视角。未来研究应在更多应用场景下验证这些开源模型的实际效能，并进一步优化其本地化部署方案。
## 1081. `cs.SE` - Faver: 通过函数抽象验证中间件提升基于LLM的RTL生成 [PDF](https://arxiv.org/pdf/2510.08664), [HTML](https://arxiv.org/abs/2510.08664)
### Authors
Jianan Mu,Mingyu Shi,Yining Wang,Tianmeng Yang,Bin Sun,Xing Hu,Jing Ye,Huawei Li
### Background
基于LLM的RTL生成是一个引人注目的研究方向，因为它有可能解放当前芯片设计中最不自动化的阶段。但是，由于高层次规范和RTL之间存在显著的语义差距，以及可用训练数据有限，现有的模型在生成准确性上面临挑战。依靠人类经验和设计验证可以提高准确性，但RTL测试台数据更加稀缺，这对于LLM来说不太友好。尽管LLM在像Python/C这类高级语言上表现出色，但在语义上与RTL存在巨大差距。实现相同功能时，Python/C代码和硬件代码在时空粒度上显著不同，要求LLM不仅要考虑高层次的功能语义，还要确保低级细节与电路代码一致。这一任务非常具有挑战性。
### Innovation
本文提出了一种功能抽象验证中间件（Faver），它在基于LLM的工作流程中简化了RTL验证。通过结合LLM友好的代码结构和基于规则的模板，Faver将电路验证的细节与功能本身分离，使LLM能够专注于功能本身。在SFT模型和开源模型的实验中，Faver将模型的生成准确性提高了最多14%。
### Conclusion
Faver为基于LLM的RTL生成提供了一种解决方案，通过将电路验证细节与功能分离，使LLM能够更好地关注功能本身的准确性。实验表明，该方法可以显著提高生成准确性。
## 1082. `cs.SE` - LLMs对软件开发中团队协作的影响 [PDF](https://arxiv.org/pdf/2510.08612), [HTML](https://arxiv.org/abs/2510.08612)
### Authors
Devang Dhanuka
### Background
随着大型语言模型（LLMs）在软件开发过程中的逐步集成，它们有潜力改变团队的工作流程和生产效率。本文旨在探讨LLMs如何影响软件开发生命周期（SDLC）中的团队协作。研究重新定义并更新了2025年前的现有研究，结合了最新的文献和案例研究，总结了SDLC中团队协作障碍的问题，并探索了LLMs如何在团队协作中增强生产力、沟通和决策。通过文献综述、行业实例、团队调研以及两份案例研究，评估了LLM辅助工具（如代码生成助手和AI项目管理代理）对协作软件工程实践的影响。
### Innovation
本文重新定义了先前的研究，结合了最新的文献和案例研究，评估了LLM辅助工具对协作软件工程实践的影响。此外，研究还探讨了LLMs在团队协作中带来的效率提升、沟通清晰度增强和跨功能协作辅助的同时，也存在模型限制和隐私问题的挑战。
### Conclusion
LLMs可以显著提高SDLC中的效率，通过自动化重复任务和文档工作，增强沟通清晰度，促进跨功能协作，但也带来新的挑战，如模型限制和隐私问题。研究讨论了这些优势和挑战，提出了指导研究的问题，并提出了未来研究方向，包括特定领域模型的定制、开发工具中的更好集成以及确保信任和安全的稳健策略。
## 1083. `cs.SE` - RAG4Tickets：利用JIRA和GitHub数据增强生成的AI驱动票务解决 [PDF](https://arxiv.org/pdf/2510.08667), [HTML](https://arxiv.org/abs/2510.08667)
### Authors
Mohammad Baqar
### Background
现代软件团队在处理重复或相关问题时经常遇到延迟，因为这些问题的知识碎片分布在JIRA票据、开发者的讨论以及GitHub合并请求（PRs）中。这导致了知识收集和管理的挑战，影响了解决问题的效率和质量。
### Innovation
提出了一个Retrieve-Augmented Generation（RAG）框架，利用Sentence-Transformers进行语义嵌入，并结合FAISS向量搜索来提供上下文相关的票务解决建议。该框架通过语义相似的历史JIRA票据、用户评论和链接的PR元数据检索过去的案例，并由大规模语言模型（LLM）综合生成具体和可解释的解决方案建议。该创新点在于统一JIRA和GitHub数据流程，以及通过嵌入和FAISS索引策略为异构软件资产提供知识重组，同时还包括一个基于检索证据的解决生成模块。
### Conclusion
实验结果表明，所提出系统在提高解决准确性、修复质量和现代DevOps环境中的知识再利用方面有显著效果，通过精确度、召回率、解决时间减少和开发者接受度指标的评估得到了验证。
## 1084. `cs.SE` - 基于差分进化算法的Python单元测试生成超参数调优 [PDF](https://arxiv.org/pdf/2510.08716), [HTML](https://arxiv.org/abs/2510.08716)
### Authors
Stephan Lukasczyk,Gordon Fraser
### Background
搜索基础的测试生成算法拥有无数的配置选项，用户通常不会调整这些选项，而是继续使用默认值，这可能导致无法获得最优结果。对算法超参数的手动调整方法资源需求较高。因此，使用元启发式搜索算法可以高效地调整个别参数，从而解决测试生成问题。本文探讨了将差分进化算法作为一种方法，以调谐DynaMOSA和MIO在Pynguin框架中的许多目标搜索算法的超参数。研究表明，调谐后的DynaMOSA算法可以显著提高测试套件的全面性，并且差分进化在效率上优于基本的网格搜索。
### Innovation
研究使用差分进化算法对Python单元测试生成中的DynaMOSA和MIO多种目标搜索算法的超参数进行调优。相较于传统的网格搜索，差分进化算法在效率上更具有优势。通过调优，DynaMOSA算法能够显著提高测试套件的覆盖率。
### Conclusion
调优后的DynaMOSA算法可以显著提高测试套件的覆盖率，并且差分进化比基本的网格搜索更高效。
## 1085. `cs.SE` - BigCodeArena: 通过执行揭示代码生成中更可靠的人类偏好 [PDF](https://arxiv.org/pdf/2510.08697), [HTML](https://arxiv.org/abs/2510.08697)
### Authors
Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra
### Background
在代码生成领域，手动评估LLM生成内容的质量极为困难，因为需要理解庞大的原始代码片段，并精心模拟代码执行。现有的众包模型评估平台，如Chatbot Arena，可以提供实时的人类视角评估，但BigCodeArena进一步引入了一个支持全面且即时执行环境的开源平台，专为代码生成设计，使人类能够与执行过程和结果进行交互。通过BigCodeArena，收集了跨越10种常用LLM的14,000多个对话会话，涵盖了10种编程语言和8种执行环境。这些对话会话中，识别出超过4700个两两之间的多轮对话样本，展示了人类偏好，并在细粒度任务、语言和框架领域发现了未充分探索的偏好。
### Innovation
BigCodeArena是一个建立在Chatbot Arena之上的开源平台，能够执行生成的代码，使人类能够参与到执行过程中，并评估LLM生成代码的质量。通过这些数据，该研究还建立了两个基准：BigCodeReward和AutoCodeArena，其中BigCodeReward通过处理和评估对话一致性来检测奖励模型的人类偏好，AutoCodeArena则是一种自动Elo评级基准，评估LLM的代码质量无需人类干预。研究表明，最近的生成模型中的专有LLM如GPT-5、Claude-Sonnet-4和Claude-Opus-4仍领先于代码生成性能。
### Conclusion
BigCodeArena为代码生成任务提供了可靠的评估基准，发现现有的专有模型在代码生成方面仍保持领先地位，并基于收集的数据建立了BigCodeReward和AutoCodeArena两个评估系统，证明了在不需要人工干预的情况下评估LLM代码质量的有效性。
## 1086. `cs.SE` - McMining: 自动发现学生代码中的误解 [PDF](https://arxiv.org/pdf/2510.08827), [HTML](https://arxiv.org/abs/2510.08827)
### Authors
Erfan Al-Hossami,Razvan Bunescu
### Background
在学习编程时，学生常常对语言概念产生误解，这些误解不仅会导致代码错误或效率低下，还会减缓相关概念的学习进度。因此，开发一种从学生代码样本中提取和自动发现这些误解的方法对于提高编程教学效果至关重要。
### Innovation
本文提出了一种名为McMining的新任务，即从学生的代码示例中挖掘编程误解。为了训练和评估McMining系统，作者开发了一个可扩展的误解基准数据集，并结合了大量包含这些误解的代码样本。随后，作者引入了两种基于LLM的McMiner方法，并通过广泛评估展示了Gemini、Claude和GPT家族模型在发现学生代码中的误解方面的有效性。
### Conclusion
本文通过引入McMining任务，从学生代码样例中自动发现编程中的误解，并展示了基于LLM的方法在这一任务上的有效性，为编程学习的教学提供了新的方法和技术支持。
## 1087. `cs.SE` - 识别视频游戏调试瓶颈：行业视角 [PDF](https://arxiv.org/pdf/2510.08834), [HTML](https://arxiv.org/abs/2510.08834)
### Authors
Carlos Pinto Gomez,Fabio Petrillo
### Background
传统的软件调试技术在视频游戏中也有应用，但视频游戏有其独特的调试需求，如On-Screen Console、Debug Draws、Debug Camera、作弊和游戏内菜单以及数据消尘等。本文通过收集20名资深游戏开发者在游戏开发过程中常见错误（崩溃、对象行为和对象持久性）的调试记录，分析了这些视频游戏开发者如何进行调试，进而识别影响调试效率的因素和使用的调试工具，还探讨了不同专业团队在调试中的协作方式。
### Innovation
本文通过实际的调试记录进行分析，重点识别了影响调试效率的关键活动和使用到的调试工具，并首次揭示了技术角色在调试过程中扮演的核心角色，实证了在视频游戏开发中调试活动的复杂性和团队协作的重要性。
### Conclusion
在游戏开发过程中，游戏开发者大约有36.6%的时间用于检查游戏对象，有35.1%的时间用于本地重现错误。技术角色在调试过程中处于核心位置，不同专业团队之间的合作对于高效调试至关重要。通过此次研究，为游戏开发者提供了更有效的调试策略和方法建议。
## 1088. `cs.SE` - PyMigTool：一种用于端到端Python库迁移的工具 [PDF](https://arxiv.org/pdf/2510.08810), [HTML](https://arxiv.org/abs/2510.08810)
### Authors
Mohayeminul Islam,Ajay Kumar Jha,May Mahmoud,Sarah Nadi
### Background
库迁移是软件项目中用一个库取代另一个相似库的过程。手动库迁移耗时且容易出错，因为这需要开发人员理解两个库的应用程序编程接口（API），映射等效API，并进行必要的代码转换。由于库迁移过程的复杂性，现有的大多数自动化技术和工具仅停留在API映射阶段，或者仅支持一组有限的库和代码转化。
### Innovation
本文开发了一个端到端的解决方案，可以自动在任意两个Python库之间迁移代码，这两个库都提供相似的功能。由于大型语言模型（LLMs）在代码生成和转换方面的潜力，本文使用LLMs作为主要引擎进行迁移。在构建工具之前，首先在包含321个真实案例的基准测试上研究了LLMs在库迁移中的能力，发现LLMs可以有效进行库迁移，但有时需要后续处理步骤来进一步提高性能。基于此，开发了结合LLMs、静态分析和动态分析力量的PyMigTool命令行应用程序，以提供精确的库迁移。在717个真实的世界Python应用程序上评估了PyMigTool，未从基准中获取。我们发现PyMigTool可以完全正确地迁移32％的迁移，其余的迁移只有57％的项目需要开发者手动修复超过14％的与迁移相关的更改。
### Conclusion
PyMigTool是一种结合LLMs、静态分析和动态分析力量的命令行应用程序，可以在任意两个提供相似功能的Python库之间实现端到端的自动化代码迁移。虽然当前的准确率为32%，但需要人工修复14%的迁移更改，该工具的开发展示了在库迁移自动化方面具有巨大的潜力。
## 1089. `cs.SE` - 基于向量图的仓库理解以支持问题驱动的文件检索 [PDF](https://arxiv.org/pdf/2510.08876), [HTML](https://arxiv.org/abs/2510.08876)
### Authors
Kostiantyn Bevziuk,Andrii Fatula,Svetozar Lashin Yaroslav Opanasenko,Anna Tukhtarova,Ashok Jallepalli Pradeepkumar Sharma,Hritvik Shrivastava
### Background
本文介绍了仓库分解系统，该系统将大型软件仓库转换为反映项目架构和语义结构的向量知识图。图中编码了诸如包含、实现、引用、调用和继承等语法关系，并增加了由LLM生成的摘要和向量嵌入。通过结合语义检索与图感知扩展的混合检索管道，以及由LLM生成的基于约束的、只读的图请求和生成人类导向的解释，实现了对仓库的自动进一步开发。这一方法提高了文件检索的效率和准确性，并支持问题驱动的文件查找和检索。
### Innovation
系统创新点在于构建了一个从代码仓库到知识图的转换工具，利用LLM提取代码结构和语义信息，并通过图编码方法实现自动化的后续开发。此外，它引入了语义检索与图感知扩展的混合检索管道，以及人力可读的解释生成机制，提高了开发者的工作效率。
### Conclusion
该研究提出了一种新的方法，能够高效地理解和转换大型软件仓库，使其架构和语义结构更加清晰。通过图编码和自然语言处理技术，进一步自动化了仓库开发过程，并通过语义检索和图感知扩展提高了文件检索的精确性和效率。
## 1090. `cs.SE` - SEER: 增强软件需求工程中的可持续性 [PDF](https://arxiv.org/pdf/2510.08981), [HTML](https://arxiv.org/abs/2510.08981)
### Authors
Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi
### Background
软件开发的快速扩展对环境、技术、社会和经济产生了重大影响。为了实现联合国2030可持续发展目标，开发人员需要采用可持续做法。现有方法大多提供高层次的指导方针，实施起来耗时且依赖团队适应性，而且大多关注设计或实施阶段，而可持续性评估应在需求工程阶段开始。
### Innovation
该论文介绍了一种名为SEER的框架，旨在在软件开发的早期阶段解决可持续性问题。框架通过三个阶段工作：（i）从通用分类法中识别特定软件产品的可持续性需求（SRs）；（ii）基于识别的SRs评估系统需求的可持续性；（iii）优化未能满足任何SR的系统需求。框架利用大型语言模型的推理能力和agentic RAG（检索增强生成）方法实现。研究结果表明，SEER在不同领域软件项目上的实验有效识别了广泛范围的可持续性问题，证明了其有效性和准确性。
### Conclusion
研究结果展示了SEER在不同领域软件项目中有效识别广泛范围的可持续性问题的能力，证明了一种新颖的框架方法在需求阶段考虑可持续性的有效性。
## 1091. `cs.SE` - 通过微调大型语言模型实现仓库感知的文件路径检索 [PDF](https://arxiv.org/pdf/2510.08850), [HTML](https://arxiv.org/abs/2510.08850)
### Authors
Vasudha Yanuganti,Ishaan Puri,Swapnil Chhatre,Mantinder Singh,Ashok Jallepalli,Hritvik Shrivastava,Pradeep Kumar Sharma
### Background
现代代码库使得开发人员和AI编程助手在回答诸如“这个功能是如何实现的？”或“错误是在哪里引入的？”等问题时难以找到正确的源文件。传统的代码搜索方法（基于关键字或信息检索）经常遗漏语义上下文和跨文件链接，而大型语言模型（LLMs）可以理解自然语言，但在特定代码库细节方面存在不足。
### Innovation
提出了一种文件路径检索方法，使用QLoRA和Unsloth优化对强大的大型语言模型（Qwen3-8B）进行微调，直接从自然语言查询中预测相关文件路径。通过六种代码感知策略生成训练数据，这些策略利用抽象语法树（AST）结构和代码库内容生成真实的问答对，涵盖单文件提示到层次化代码库摘要。本文在Python项目（包括Flask、Click、Jinja、FastAPI和PyTorch）上进行微调，取得高检索精度：外部查询的完全匹配可达91%，召回率93%，并大比例超越单一策略训练效果。在大型代码库如PyTorch（约4000个Python文件）中，模型达到59%的召回率，显示了其可扩展性。
### Conclusion
多级代码信号有助于LLM在跨文件上下文中的推理，通过数据集设计、限制（例如，在非常大的代码库中的上下文长度限制）及未来与基于LLM的代码智能检索集成为主题进行了讨论。
## 1092. `cs.SE` - 模型辅助与人机协作：软件专业人士在代码编写中使用LLMs的感知和实践 [PDF](https://arxiv.org/pdf/2510.09058), [HTML](https://arxiv.org/abs/2510.09058)
### Authors
Italo Santos,Cleyton Magalhaes,Ronnie de Souza Santos
### Background
大型语言模型（LLMs）迅速成为现代软件开发工作流程中的核心组件，软件从业人员越来越多地将这些工具集成到软件开发生命周期的不同阶段。尽管LLMs的应用越来越普遍，但对其实际使用情况和专业人员对其好处与限制的感知仍知之甚少。
### Innovation
本研究基于全球131名软件从业人员的调查，提供初步发现。结果揭示了LLMs在各种编码特定任务中的应用，展示了开发者将LLMs视为辅助工具而非独立解决方案的谨慎但实际的策略。
### Conclusion
研究结果为LLM在软件工程中的采用提供了早期的专业视角，强调了未来研究和负责任使用时需要考虑的关键因素。
## 1093. `cs.SE` - 向软件设计领域可持续性需求的分类学迈进 [PDF](https://arxiv.org/pdf/2510.08990), [HTML](https://arxiv.org/abs/2510.08990)
### Authors
Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi
### Background
软件系统对全球可持续性构成显著影响，需要在需求工程的初始阶段系统地考虑环境、社会、技术和经济因素。虽然现有的研究提供了各种可持续性需求（SRs），但这些贡献往往是分散的，局限于某些维度或特定应用领域，导致缺乏一个统一、全面的分类体系供软件工程社区使用。这促使研究进行了一项系统文献综述（SLR），旨在提取和组织前沿的可持续性需求，并建立了一个综合的可持续性需求分类体系，以覆盖环境、技术、社会和经济四个维度。同时，该分类体系还提供了每个类别中的清晰定义、关联的度量标准和评估方法，并绘制了不同维度中类别之间正向和负向影响（协同作用和冲突）的关联矩阵，为软件开发者和研究人员在可持续软件开发中有效制定、管理和平衡权衡提供了系统化的参考。
### Innovation
本研究通过进行系统文献综述，首次建立了一个综合性的可持续性需求分类体系，覆盖了软件开发中环境、技术、社会和经济四个维度的可持续性需求，为该领域的研究和发展提供了统一和全面的框架。分类体系中包括清晰的定义、关联的度量标准以及评估方法，此外，通过绘制影响矩阵，展示了不同维度中各类别之间的正向和负向影响，从而为问题的解决提供了更深层次的理解和指导。这些贡献对于促进可持续软件开发具有重要的实践与理论意义。
### Conclusion
该研究成功地建立了一个针对软件设计领域的可持续性需求的综合分类体系，这一体系不仅能帮助软件开发者和研究人员更好地理解可持续性需求，还能有效地进行相关的权衡与决策。这一分类体系的提出填补了该领域缺乏统一、全面分类框架的空白，为促进可持续软件开发提供了宝贵的工具和参考。
## 1094. `cs.SE` - Literate Tracing [PDF](https://arxiv.org/pdf/2510.09073), [HTML](https://arxiv.org/abs/2510.09073)
### Authors
Matthew Sotoudeh
### Background
随着计算机系统变得越来越大和越来越复杂，软件开发中的一个重要任务是系统专家向系统新手传达某个程序的工作方式。现有的文档方法如内嵌代码注释和外部设计文档各自存在局限性，无法充分提供全局视角或直接关联到代码的具体实现。因此，需要一种新的方法来更好地解释程序工作原理，并提供更好的文档支持.
### Innovation
本文介绍了一种新的程序文档方法——literate tracing，使用带有注释的、具体执行跟踪来解释软件系统。literate tracing相比传统的代码注释和外部设计文档，能提供更丰富的全局上下文以及更直接的代码关联。还描述了一个名为TReX的工具，用于生成交互式、可视化的literate tracing，这些tracing在设计之初就被保证忠实地反映了程序语义.
### Conclusion
作者使用TReX工具编写了literate tracing，解释了Linux内核、Git版本控制系统和GCC编译器等大型系统软件的组件，证明了该方法的有效性。
## 1095. `cs.SE` - 利用标识符替换实现LLMs的经济高效长代码翻译 [PDF](https://arxiv.org/pdf/2510.09045), [HTML](https://arxiv.org/abs/2510.09045)
### Authors
Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta
### Background
在软件开发领域，LLMs已被用于自动化诸如代码翻译等任务，即将一种编程语言的源代码翻译为另一种语言并保持其功能不变。然而，当处理不适宜置于上下文窗口内的长源代码时，LLMs通常会面临难题，导致翻译不准确。这主要是因为在翻译过程中需要保持大量的上下文信息，而长代码难以被有效处理。为了解决这一问题，本文探讨了一种新颖的零样本代码翻译方法，该方法结合了标识符替换技术，通过用通用占位符替换用户提供的一部分长标识符，使LLMs能够聚焦于代码的逻辑结构，从而减少了token数量和内存使用，提高长代码翻译的效率和成本效益。实验证明，该方法能够保留语法和层次信息，并生成更少token数量的翻译结果。
### Innovation
提出了一种结合标识符替换的新颖零样本代码翻译方法。该方法通过在翻译期间使用用户提供的长标识符来替换通用占位符，使LLMs能够关注代码的逻辑结构，而无需处理大量上下文信息，从而提高了长代码翻译的效率和成本效益，并证明了这种方法能够保留代码的语法规则和层次结构，生成更精确的翻译结果。
### Conclusion
本文实验结果表明，通过引入标识符替换技术，结合LLMs的长代码翻译得到了显著改进，保留了代码的语法规则和层次结构的同时，减少了token数量，进而提高了翻译的效率和性价比。
## 1096. `cs.SE` - 修复SWE-Bench：一种用于现实代理评估的基准变换方法 [PDF](https://arxiv.org/pdf/2510.08996), [HTML](https://arxiv.org/abs/2510.08996)
### Authors
Spandan Garg,Ben Steenhoek,Yufan Huang
### Background
目前用于评估软件工程代理的标准（如SWE-Bench Verified）主要来源于GitHub问题，未能准确反映开发人员在集成开发环境（IDE）中与基于对话的编码助手互动的方式。这种不匹配导致了代理在实际场景中能力的系统性高估，尤其是在bug修复方面。因此，通过系统研究开发人员与基于对话的代理互动模式，将现有形式的基准转化为现实的用户查询，是改进代理评估方法的关键。论文介绍了如何将SWE-Bench Verified、TypeScript子集的Multi-SWE-Bench以及私有基准SWE-Bench C#等已有多项基准转化为现实的用户查询，这些方法基于流行对话式代理互动的遥测分析。研究表明，对现有基准的测试揭示了一些模型的代理能力被高估了50%以上（对于公开基准）和约10-16%（对于内部基准）。这些发现提供了一种新的方法来通过基准变换技术评估交互式对话式软件工程代理的能力框架，从而改进了代理的评估过程和准确度。
### Innovation
提出了一个新的基准变换框架，能够将现有的形式基准转化为现实的用户查询，通过遥测分析真实对话式代理的用户互动来改进代理的评估。这种灵活性允许其轻松应用到现有的基准上，从而解决了现有标准来自GitHub问题的不足，从而提供更准确和现实的代理评估方法。该方法为交互式对话式软件工程代理评估提供了一个新的范式，使评估更为准确和现实。该论文建立了一种新的基准变换技术来评估交互式对话式软件工程代理的方法。
### Conclusion
通过对SWE-Bench Verified、TypeScript子集的Multi-SWE-Bench和私有基准SWE-Bench C#的应用，论文表明现有基准显著高估了一些代理模型的一些能力，具体而言，对于公开基准的高估高达50%，对于内部基准的高估约10-16%。这种新的基准变换技术能够更准确地评估交互式对话式软件工程代理的实际能力，为代理评估提供了新的范式。
## 1097. `cs.SE` - 基于约束的机器学习库单元测试生成 [PDF](https://arxiv.org/pdf/2510.09108), [HTML](https://arxiv.org/abs/2510.09108)
### Authors
Lukas Krodinger,Altin Hajdari,Stephan Lukasczyk,Gordon Fraser
### Background
机器学习（ML）库如PyTorch和TensorFlow在现代应用中至关重要。通过测试确保ML库的正确性非常重要。然而，ML API通常对输入有严格的约束，涉及复杂的结构如张量。现有的自动化测试生成工具如Pynguin并不了解这些约束，经常会产生非合规输入，导致测试早期失败，代码覆盖率较低。之前的研究已有尝试从官方API文档中提取约束。本研究旨在改进Pynguin测试生成器，使其利用这些约束，生成符合ML API要求的输入，从而实现更为充分的测试和更高的代码覆盖率。
### Innovation
提出了一种称为PynguinML的方法，旨在改善Pynguin测试生成器，利用从官方API文档中提取的约束，生成符合ML API要求的合规输入，进而实现更有效的测试和更高的代码覆盖率。
### Conclusion
在对PyTorch和TensorFlow的165个模块进行评估后，结果表明PynguinML显著提高了测试效果，相较于Pynguin实现了最高达63.9%的代码覆盖率提升。
## 1098. `cs.SE` - AI驱动医疗平台的模型驱动工程方法 [PDF](https://arxiv.org/pdf/2510.09308), [HTML](https://arxiv.org/abs/2510.09308)
### Authors
Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi
### Background
人工智能（AI）有潜力通过支持更准确的诊断和个人化治疗来改变医疗保健领域。然而，其在实践中的采用受到碎片化的数据来源、严格的隐私规定以及构建可靠的临床系统的技术复杂性的限制。
### Innovation
提出了一个专门针对医疗保健AI的模型驱动工程（MDE）框架。该框架依赖于形式化的元模型、领域特定语言（DSL）以及自动转换，从高层次规范到运行软件。核心是医疗可互操作语言（MILA），这是一种图形DSL，使临床医生和数据科学家能够使用共享本体定义查询和机器学习管道。结合联邦学习架构，MILA允许机构合作无需交换原始患者数据，同时确保跨站点的语义一致性和隐私保护。
### Conclusion
通过在多中心癌症免疫疗法研究中评估此方法，生成的管道展示了强大的预测性能，支持向量机在关键任务中的准确度最高可达98.5%和98.3%。这表明MDE原则、语义集成和自动化代码生成可以为互操作、可重复和可靠的数字健康平台提供实用途径。
## 1099. `cs.SE` - 概念导向的C++泛型编程 [PDF](https://arxiv.org/pdf/2510.08969), [HTML](https://arxiv.org/abs/2510.08969)
### Authors
Bjarne Stroustrup
### Background
泛型编程是C++的重要组成部分，而C++的概念提供了一种方式来表达对泛型代码的约束条件。本文旨在通过示例展示C++概念的功能和基本原则，特别是它们在类型系统中的用户定义扩展。
### Innovation
文章提出了多种编程技术来使用C++的概念。这些技术不仅包括一种简单的类型系统，还使用概念提供了一种无需额外的符号或运行时开销即可消除类型狭窄转换并实现范围检查的方法。此外，文章还探讨了泛型编程的关键设计原理，并提供了设计动机和背景。
### Conclusion
概念是C++泛型编程的关键，展示了它们的实用性和对泛型编程的基本理念。泛型编程不仅仅是子语言的一部分，它的特性同样支持一般的编程需求。
## 1100. `cs.SE` - 慢性护理中患者数字双胞胎的语义框架 [PDF](https://arxiv.org/pdf/2510.09134), [HTML](https://arxiv.org/abs/2510.09134)
### Authors
Amal Elgammal,Bernd J. Krämer,Michael P. Papazoglou,Mira Raheem
### Background
个性化慢性护理需要整合多模态健康数据，以实现精确、适应性和预防性决策。然而，现有的数字孪生（DT）应用程序大多局限于特定器官或数据类型，缺乏统一和保护隐私的基础。目前的DT应用难以满足多模态数据整合的需求。
### Innovation
本文提出了患者医疗数字孪生（PMDT），这是一种以本体驱动的在体患者框架，能够将生理、心理社会、行为和基因组信息整合到一个连贯且可扩展的模型中。PMDT使用OWL 2.0实现，确保语义互操作性，支持自动推理，且可在多种临床环境中重复利用。该本体围绕patient、disease and diagnosis、treatment and follow-up等模块构建，并通过专家研讨会、问卷调查和欧盟H2020 QUALITOP项目中的试点研究进行迭代优化和验证，确认了覆盖范围、推理正确性、用户友好性和GDPR合规性。
### Conclusion
PMDT能够整合异构数据，实施专业知识问题，并在联邦、保护隐私的前提下支持描述性、预测性和处方性分析。通过弥合数据碎片化和语义标准化的差距，PMDT为下一代数字健康生态系统的构建提供了一个验证的平台，有助于实现预防性、不断优化和公平管理的慢性护理。
## 1101. `cs.SE` - Text2Stories：评估访谈与生成用户故事之间的对齐 [PDF](https://arxiv.org/pdf/2510.08622), [HTML](https://arxiv.org/abs/2510.08622)
### Authors
Francesco Dente,Fabiano Dalpiaz,Paolo Papotti
### Background
大型语言模型（LLMs）可以用于从诸如访谈转录等自然语言输入中自动化生成软件需求。然而，评估这些衍生需求是否忠实反映了利益相关者的需要仍然是一项主要依赖于人工的任务。为了量化用户故事与实际访谈需求表达之间的匹配程度，作者引入了Text2Stories任务和指标，用于评估用户故事与访谈转录之间的对齐程度。
### Innovation
Text2Stories提供了一个新的任务和指标，用于量化用户故事与访谈转录之间的匹配程度。具体创新点包括：将访谈转录分段，并将其与用户故事进行匹配，形成匹配问题；实验结果显示，基于LLM的匹配器在保留注释上实现了0.86的宏F1得分；此外，还展示了Text2Stories如何使用户故事集之间的比较成为可能，进一步将Text2Stories定位为用户故事质量标准的可扩展、源忠实补充。
### Conclusion
实验结果显示，一个基于LLM的匹配器在保留注释上实现了0.86的宏F1得分。嵌入模型单独使用效果稍逊，但能够有效屏蔽无效匹配。最终，研究展示了Text2Stories指标能够实现不同用户故事集之间的比较，从而定位其作为现有用户故事质量标准的可扩展及源忠实补充角色。
## 1102. `cs.SE` - TIT: 基于树状指令微调的LLM代码翻译方法 [PDF](https://arxiv.org/pdf/2510.09400), [HTML](https://arxiv.org/abs/2510.09400)
### Authors
He Jiang,Yufu Wang,Hao Lin,Peiyu Zou,Zhide Zhou,Ang Jia,Xiaochen Li,Zhilei Ren
### Background
大规模语言模型（LLMs）在自动源代码到目标代码翻译中表现出强大的性能，通过大型代码语料库的预训练获得。然而，主流的基于LLM的代码翻译方法存在两个关键的局限性：首先，它们对语言特定特征非常敏感，这往往将源语言的句法或词汇引入输出中，导致句法混淆；其次，它们依赖于函数级别平行数据集，导致翻译代码和原始代码之间的语义不匹配。
### Innovation
为此，我们提出了TIT（Tree-structured Instruction Tuning），一种基于树状指令微调的代码翻译方法。TIT包含三个模块：首先，通过结构化解析整合语言无关的句法特征以减轻句法混淆；其次，通过语句级别分割和对比匹配生成高质量的细粒度平行数据；最后，利用双阶段树指令微调模块减轻LLM因引入句法信息带来的上下文处理负担。第一阶段采用句法感知微调以使LLM能够自主理解结构化句法信息，而第二阶段通过代码生成微调引导模型根据函数级别句法依赖生成准确的目标代码。实验结果表明，该方法在多个LLM中显著优于现有方法，代码翻译的成功率提高了1.22到1.75倍，并大幅减少了句法混淆。
### Conclusion
我们提出的TIT方法克服了现有方法的局限性，在多个LLM中表现出色，提高了代码翻译的成功率并大幅减少了句法混淆。
## 1103. `cs.SE` - 联邦数据分析在癌症免疫疗法中的应用：一种保护隐私的协作患者管理平台 [PDF](https://arxiv.org/pdf/2510.09155), [HTML](https://arxiv.org/abs/2510.09155)
### Authors
Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal
### Background
Connected health作为一种多学科方法，注重患者需求，并通过促进准确患者信息在所有护理连续体利益相关者之间的及时交流，确保积极和高效的护理。随着数字技术的进步和流程创新，整合多种医疗数据源有望增强connected health，实现个性化护理、预测健康结果和优化患者管理，但数据架构、应用互操作性和安全性方面仍面临挑战。数据分析可以提供关键洞察，支持基于数据的决策和健康管理，但解决方案必须优先考虑最终用户，包括患者和医护人员。
### Innovation
本研究通过一个受欧盟资助的敏捷系统开发生命周期项目开发了一种结合了各护理连续体利益相关者、采用联邦大数据分析和人工智能的协作数字框架，以改善决策过程的同时确保隐私。该框架在真实的临床合作对象参与的试点研究中得到了验证，实现了70%-90%的治疗建议和不良事件预测准确性。
### Conclusion
该研究展示了联邦数据分析如何在保护患者隐私的前提下，通过整合各护理单元的利益相关者、利用联邦大数据分析和人工智能为癌症免疫疗法患者管理提供有效平台。
## 1104. `cs.SE` - RepDL：位级可再现的深度学习训练和推理 [PDF](https://arxiv.org/pdf/2510.09180), [HTML](https://arxiv.org/abs/2510.09180)
### Authors
Peichen Xie,Xian Zhang,Shuo Chen
### Background
非确定性和不可再现性在深度学习中构成了显著挑战，导致不同运行和平台之间结果不一致。这些问题源于随机数生成和浮点计算两个方面。尽管可以通过确定性配置控制随机性，但浮点计算的不一致性问题仍然难以解决。
### Innovation
提出了一种名为RepDL的开源库，以确保跨多种计算环境的确定性和位级可再现的深度学习训练和推理。RepDL通过确保浮点计算中的正确舍入和顺序不变性来实现这一目标。
### Conclusion
通过引入RepDL库，能够在不同计算环境中实现深度学习训练和推理的确定性和位级可再现，解决了传统方法难以解决的浮点计算不一致性问题。
## 1105. `cs.SE` - 基于仿真的工业机器人导航系统测试研究与实践对接 [PDF](https://arxiv.org/pdf/2510.09396), [HTML](https://arxiv.org/abs/2510.09396)
### Authors
Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella
### Background
确保机器人在动态环境中的稳健导航是一个关键挑战，传统测试方法往往难以覆盖所有操作要求。本研究利用Surrealist框架进行工业应用，该框架最初用于无人机，在现已被应用于ANYmal四足机器人进行工业检查。研究者开发的方法使用基于搜索的算法自动生成具有挑战性的避障场景，有助于发现通常由手动测试所忽视的失败情况。
### Innovation
研究提出了将基于仿真的测试生成框架Surrealist应用于工业四足机器人ANYmal，通过自动生成复杂避障场景来发现潜在问题，这大大提高了测试的充分性和自动化水平。相比于传统的人工测试，这种方法能更有效地识别出操作中的薄弱环节并提供客观的基准标准。
### Conclusion
该框架被整合到ANYbotics的流程中，进行了为期六个月的工业测试，涵盖五个专有算法。正式调查显示，该方法提高了开发过程的质量，揭示了关键性失败，提供了客观的基准标准，并加强了整个验证流程。
## 1106. `cs.SE` - 使用声明性映射规则生成CodeMeta：使用ShExML的开放方法 [PDF](https://arxiv.org/pdf/2510.09172), [HTML](https://arxiv.org/abs/2510.09172)
### Authors
Herminio García-González
### Background
如今，软件是多个科学领域中使用计算机方法解答新研究问题的基石。为了使这些实验完全可重复，科研软件应遵循FAIR原则，但其元数据可以按照不同的数据模型分布于不同的位置。为了使领域更加统一，CodeMeta被提议为统一和标准化表示科研软件元数据的词汇表。现有工具虽能帮助用户为某些特定用例生成CodeMeta文件，但在灵活性和适应性方面仍然不足。因此，本文提出使用声明性映射规则生成CodeMeta文件，在ShExML中实现三个转换工作表，扩展并合并以涵盖两个现有科研软件制品生成CodeMeta文件。此外，输出通过SHACL和ShEx验证，并在整个生成工作流中实现自动化，要求新版本发布时最小的人工干预。
### Innovation
本文提出使用声明性映射规则生成CodeMeta文件，并通过ShExML实现三个交叉映射工作表，扩展和合并以涵盖两个现有科研软件制品生成CodeMeta文件。此方法的创新之处在于：1. 提供高度灵活性和适应性的解决方案；2. 通过ShExML进行跨模型映射，实现统一和标准化表示；3. 通过SHACL和ShEx验证输出，确保生成的CodeMeta文件符合规范；4. 实现自动化的工作流程，减少人工干预，简化新的版本发布。
### Conclusion
本研究提供了一种使用声明性映射规则生成CodeMeta文件的方法，通过ShExML实现，覆盖现有科研软件制品的多个实例。此方法可作为其他开发者生成CodeMeta流程的参考，促进CodeMeta的广泛应用，最终提高科研软件的FAIR性。
## 1107. `cs.SE` - MEC$^3$O: 多专家共识进行代码时间复杂度预测 [PDF](https://arxiv.org/pdf/2510.09049), [HTML](https://arxiv.org/abs/2510.09049)
### Authors
Joonghyuk Hahn,Soohan Lim,Yo-Sub Han
### Background
源代码的复杂性预测对于软件开发和算法分析至关重要。近年来，Baik等人（2025）提出了CodeComplex以预测代码的时间复杂性。研究表明，未经微调的语言模型（LLM）在某些复杂性类别上表现不佳，这表明没有单一模型能够胜任所有类别，而是每个模型各有其优势的类别。因此，需要一种机制来依据模型的性能将它们分配到特定的复杂性类别，并提高预测准确率，防止单一模型或错误多数意见的依赖。
### Innovation
本文提出了MEC$^3$O，一个由模型组成的多专家共识系统，它建立在多智能体辩论框架之上。MEC$^3$O根据模型的性能将其分配到不同的复杂性类别，并为它们提供类别专用的指令，使其成为专家。这些专家将进行结构化的辩论，并通过加权共识机制整合预测。此外，MEC$^3$O还解决了思考退化的问题，减少了对手动法官模型的依赖，并防止了错误多数意见的形成。实验结果表明，与开源基准相比，MEC$^3$O在宏加权F1得分中提升了至少10%，同时，它在平均宏加权F1得分上超越了GPT-4o-mini，并且平均F1得分与GPT-4o和GPT-o4-mini保持竞争力，这表明多专家辩论和加权共识策略的有效性。
### Conclusion
实验结果显示，MEC$^3$O在CodeComplex上优于开源基准，平均宏加权F1得分至少高出10%，同时在平均宏加权F1得分上超越了GPT-4o-mini，平均F1得分与GPT-4o和GPT-o4-mini保持竞争力。这证明了多专家辩论与加权共识策略能够有效地生成最终预测。所有代码和数据均可在提供的链接处获得。
## 1108. `cs.SE` - 数据要域的优势：零信任世界的最小权限数据访问新范式 [PDF](https://arxiv.org/pdf/2510.09494), [HTML](https://arxiv.org/abs/2510.09494)
### Authors
Nico Bistolfi,Andreea Georgescu,Dave Hodson
### Background
随着云基础设施的发展以支持动态和分布式的流程，尤其是受到AI驱动的进程加速推动，过去的权限模型已经成为了关键的安全漏洞。基于云安全联盟（CSA）2025年深入报告，我们分析了固定权限如何导致云重大漏洞。虽然当前的网络安全工具在应对网络和API安全方面取得了进展，但在确保细粒度数据访问的安全方面仍存在挑战。在数据层面撤销固定权限同样重要，尤其是在处理大量宝贵数据的公司中。
### Innovation
本白皮书介绍了一种基于按需数据要域的创新架构，直接解决了这一缺口。这种方法实现了零固定权限（ZSP）和即时（JIT）原则，用临时数据合同替代静态权限，以实现主动保护。这意味着根据按需请求的数据建立了分离，提供精确的访问和对单个记录的实时监控，而不是整个数据集。这种解决方案大大缩小了攻击面、防止了权限蔓延，并简化了审计，为企业转向更安全和更具弹性的数据环境提供了重要途径。
### Conclusion
本研究提出了一种新的方式，即数据要域优势，来实现零信任世界中的最小权限数据访问，通过按需数据合同，减少攻击面和特权蔓延，简化审计，帮助企业更安全地管理数据。
## 1109. `cs.SE` - OrcaLoca：一个用于软件问题定位的大型语言模型代理框架 [PDF](https://arxiv.org/pdf/2502.00350), [HTML](https://arxiv.org/abs/2502.00350)
### Authors
Zhongming Yu,Hejia Zhang,Yujie Zhao,Hanxian Huang,Matrix Yao,Ke Ding,Jishen Zhao
### Background
近期，大型语言模型（LLM）代理在自主软件工程（ASE）中的应用正在改变自动化编程、问题修复和功能改进的方式。然而，准确地定位软件问题——即通过导航到相关的代码部分来识别问题——仍然是一个重大挑战。当前的方法由于LLM代理与精确代码搜索机制之间缺乏有效集成，往往会产生次优结果。
### Innovation
本文提出了OrcaLoca，这是一个基于LLM代理的框架，通过优先级调度促进LLM指导下的操作、操作分解与相关性评分，以及距离感知上下文剪枝，从而提高软件问题定位的准确性。实验结果表明，OrcaLoca在SWE-bench Lite的功能匹配率（65.33%）上成为开源领域的最新最优方案（SOTA），并通过其补丁生成集成，开源框架最终解决率提高了6.33个百分点。
### Conclusion
OrcaLoca通过集成优先级调度、操作分解与相关性评分，以及距离感知上下文剪枝，显著提高软件问题定位精度，成为开源领域最新的功能匹配最优方案，并提升了开源框架的最终解决率。
## 1110. `cs.SE` - K-ASTRO：增强结构感知的LLM代码漏洞检测 [PDF](https://arxiv.org/pdf/2208.08067), [HTML](https://arxiv.org/abs/2208.08067)
### Authors
Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach
### Background
大型语言模型（LLMs）正改变软件工程任务，包括代码漏洞检测——这是软件安全的关键领域。然而，现有的方法往往依赖于资源密集型模型或基于图形的技术，限制了它们的可访问性和实用性。
### Innovation
本文提出了K-ASTRO，一种轻量级的Transformer模型，将LLMs的语义嵌入与AST的结构特征相结合，以提高代码漏洞检测的效率和准确性。该方法引入了一种基于AST的增强技术，受mutation测试启发；结构感知的注意力机制，结合了增强的AST特征；以及一个联合适应流水线以统一代码语义和语法。实验结果显示，在BigVul、DiverseVul和PrimeVul三个大规模数据集上，K-ASTRO表现出最先进的性能，同时能够在CPU上实现快速推理，所需训练时间最小。
### Conclusion
K-ASTRO通过提供可扩展、可解释和高效的方法，填补了LLMs发展与实用代码漏洞检测之间的差距，开放源代码工具以促进进一步的研究。
## 1111. `cs.SE` - SWE-Arena：软件工程中评估基础模型的交互平台 [PDF](https://arxiv.org/pdf/2502.01860), [HTML](https://arxiv.org/abs/2502.01860)
### Authors
Zhimin Zhao
### Background
尽管大型语言模型（LLMs）在代码生成、调试和需求细化等各种软件工程（SE）任务中展现出了显著的潜力，但现有的评估框架在评估模型在SE活动特有的迭代式、上下文丰富的工作中表现不足。为解决这一局限，本文提出SWE-Arena，这是一种交互式平台，旨在评估SE任务中的基础模型。该平台提供了透明的开源排行榜，支持多轮对话工作流，并允许端到端模型比较。
### Innovation
SWE-Arena引入了新的元指标，包括模型一致性得分（测量模型输出在自游戏比赛中的连贯性）和对话效率指数（评估模型性能并考虑达到结论所需的交互轮数）。此外，它还引入了名为RepoChat的新功能，该功能能够自动将仓库相关的背景信息（如问题、提交和合并请求）注入对话中，从而进一步使评估与实际开发流程保持一致。
### Conclusion
本文概述了SWE-Arena的设计和功能，强调了它在软件工程中评估和实践应用基础模型方面的潜在价值。
## 1112. `cs.SE` - JuliaGrid: 一种基于Julia语言的开放源代码电力系统状态估计框架 [PDF](https://arxiv.org/pdf/2502.18229), [HTML](https://arxiv.org/abs/2502.18229)
### Authors
Mirsad Cosovic,Ognjen Kundacina,Muhamed Delalic,Armin Teskeredzic,Darijo Raca,Amer Mesanovic,Dragisa Miskovic,Dejan Vukobratovic,Antonello Monti
### Background
现代电力系统因为电力需求的增长和各种能源的整合而变得越来越复杂。对这些大规模系统的监控依赖于高效的量测估计，这是一个计算上的挑战任务，并需要高效的模拟工具来进行电力系统稳态分析。鉴于此观察结果，我们提出了JuliaGrid，这是一个用Julia语言编写的开源框架，旨在跨多个平台实现高性能执行。它实施可观测性分析、加权最小二乘和最小绝对值估计器、坏数据分析以及与相量测量相关的各种算法。为了完成电力系统的分析，框架还包含了电力潮流分析和最优潮流分析，可以为状态估计过程生成量测数据。通过利用高效的计算算法，JuliaGrid能够解决所有方法下的大规模系统问题，并在性能上与其它开源工具竞争。该框架特别设计用于准稳态分析，并具备自动检测和重用计算数据以提高性能的功能。这些功能在拥有10000、20000和70000个节点的系统中得到了验证。
### Innovation
JuliaGrid 是一个专门用于电力系统状态估计的开源框架，采用了高效的计算算法，能够在多种平台上实现高性能执行，特别适用于准稳态分析。其具备自动检测和重用计算数据的功能，从而有效提升了性能。框架中集成了可观测性分析、电力潮流分析、最优潮流分析等多种电力系统分析方法，极大地增强了其实际应用价值。
### Conclusion
JuliaGrid 是一个可靠的、高性能且高效的框架，适用于大规模电力系统稳态分析，特别适用于准稳态问题。验证结果表明，它能够有效解决包含较大量节点的电力系统问题，并且在性能上具有竞争力。
## 1113. `cs.SE` - 开发者对其所生成的AI代码进行自我声明的现象分析 [PDF](https://arxiv.org/pdf/2504.16485), [HTML](https://arxiv.org/abs/2504.16485)
### Authors
Syed Mohammad Kashif,Peng Liang,Amjed Tahir
### Background
AI生成代码工具在开发者中获得了显著的流行度，因其能够帮助生成代码，开发者们经常使用这些工具进行软件开发。现有研究主要集中在探讨AI生成代码的质量（如正确性和安全性），但在实际软件开发过程中，首要任务是区分AI生成的代码和开发者手动编写的代码，这需要开发者明确声明AI生成的代码。本研究旨在了解开发人员声明AI生成代码的方法及他们选择声明或不声明的原因，并通过混合方法研究进行实证分析，第一阶段分析了GitHub上的代码片段，在第二阶段通过从业者调查收集数据，结果表明大多数开发者会声明其生成的AI代码，但也有部分开发者认为自行声明是不必要的工作。
### Innovation
本研究创新地通过混合方法研究揭示了开发者声明AI生成代码的实践，并分析了开发者选择声明或不声明的原因，同时提供了应对伦理和代码质量挑战的指导建议。之前的研究主要集中在AI生成代码的质量方面，而本研究则着重于开发者如何声明AI生成代码以及其背后的原因，这是现有研究的一个创新点。
### Conclusion
大多数开发者（76.6%）总是或者有时候会声明AI生成的代码，而一部分开发者（23.4%）则认为不需要进行自我声明。声明AI生成代码的原因包括跟踪和监控代码以便将来审查和调试，以及伦理考虑。而不声明的原因则可能是对AI生成代码进行了大量修改，以及开发者认为这是不必要的活动。结果最终为开发者提供了关于如何声明AI生成代码的指南，以解决伦理和代码质量的考虑。
## 1114. `cs.SE` - AI代理为何仍然需要你：来自实际开发-代理协作的研究结果 [PDF](https://arxiv.org/pdf/2506.12347), [HTML](https://arxiv.org/abs/2506.12347)
### Authors
Aayush Kumar,Yasharth Bajpai,Sumit Gulwani,Gustavo Soares,Emerson Murphy-Hill
### Background
软件工程代理(SWE代理)可以在像SWE Bench这样的基准上自主执行开发任务，但面对复杂的、模糊的实际世界任务时仍遇到挑战。因此，SWE代理通常设计为允许与开发者的互动，促进协作问题解决。
### Innovation
研究通过观察19名开发者在集成开发环境(IDE)中使用代理解决33个先前贡献过的仓库中的开放问题，来理解开发人员与SWE代理的协作方式以及他们在交互中遇到的障碍。该研究发现，采用增量方法解决问题和积极参与与代理讨论输出的开发人员更为成功。
### Conclusion
研究结果表明，为了促进成功的协作，SWE代理和开发人员在整个软件开发过程中应当积极参与任务。SWE代理可以通过提出挑战并进行讨论而非仅仅给出结论来实现这一目标，从而帮助开发人员提高协作效率。
## 1115. `cs.SE` - LLM-as-Judge指标在软件工程任务中与人类评估差距的桥梁 [PDF](https://arxiv.org/pdf/2505.20854), [HTML](https://arxiv.org/abs/2505.20854)
### Authors
Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,Kui Liu,Xin Xia,David Lo
### Background
随着大型语言模型（LLMs）和其他自动化技术在软件开发中的应用，这些技术能够生成代码片段、补丁和评论等软件构件，但如何准确评估这些生成构件的正确性仍然是一个重大挑战。方法论上，人工评估虽然精确但耗时且缺乏可扩展性；而现有的自动化评估指标虽然可扩展且需要较少的人工努力，但往往未能准确反映生成软件构件的实际正确性。本研究旨在解决这一问题，介绍了一种专为评估生成软件构件正确性而设计的创新评估指标SE-Jury，该指标通过定义独立的评判策略并动态选择最有针对性的评判团队来实现自动化评估的准确性。
### Innovation
SE-Jury是一种全新的评估指标，专门针对大型语言模型生成的软件构件进行正确性评估。该指标首次定义了五种不同的评估策略，实施独立的评判角色，并通过动态团队选择机制汇聚不同的评判结果，从而提高评估结果的准确性和可靠性。研究表明，SE-Jury在多种软件工程基准测试中的表现显著优于现有的自动化评估指标，特别是在代码生成和程序修复任务中，其与人工判断的一致性接近甚至超过人工评判者的互评一致性。
### Conclusion
SE-Jury在软件工程任务中的准确性和可靠性表现突出，其与人工评估的高度一致性表明SE-Jury有望提供一种可扩展且可靠的替代方案，以填补自动化评估与人工评估之间的差距。在代码生成和程序修复等任务中，SE-Jury已经展示出了作为自动化评估的可靠工具的巨大潜力。
## 1116. `cs.SE` - Agentic Services Computing [PDF](https://arxiv.org/pdf/2509.24380), [HTML](https://arxiv.org/abs/2509.24380)
### Authors
Shuiguang Deng,Hailiang Zhao,Ziqi Wang,Guanjie Cheng,Peng Chen,Wenzhuo Qian,Zhiwei Ling,Jianwei Yin,Albert Y. Zomaya,Schahram Dustdar
### Background
大型语言模型（LLM）驱动的代理正在改变服务计算，使其从静态、请求驱动的功能转变为动态、目标导向的、社会嵌入式的多代理生态系统。
### Innovation
提出了服务计算的新范式——Agentic Services Computing (ASC)，将服务重新构想为自主、适应和协作的代理，能够在开放和不确定的环境中感知、推理、行动和进化。ASC围绕设计、部署、运营和进化四个阶段生命周期，整合感知和上下文建模、自主决策、多代理协作和评估与可信度四个交织的研究维度，支持不断发展。
### Conclusion
通过将服务计算的基本原则与基于大语言模型的代理的最新进展整合起来，ASC提供了构建智能、负责任和服务导向的生态系统的基础。
## 1117. `cs.SE` - 通过LLM驱动的迭代代码图搜索进行问题定位 [PDF](https://arxiv.org/pdf/2503.22424), [HTML](https://arxiv.org/abs/2503.22424)
### Authors
Zhonghao Jiang,Xiaoxue Ren,Meng Yan,Wei Jiang,Yong Li,Zhongxin Liu
### Background
问题解决旨在根据问题描述在实际代码仓库中生成修复补丁。问题定位是精准问题解决的基础。最近，基于LLM的问题定位方法已经显示出最先进的性能，但它们要么搜索问题描述中提及的文件，要么搜索整个仓库，难以平衡搜索空间的广度和深度，高效地定位目标。此外，这些方法允许LLM自由探索整个仓库，难以控制搜索方向以防止LLM寻找错误的目标。
### Innovation
提出了一种名为CoSIL的LLM驱动的功能级别问题定位方法，无需训练或索引。CoSIL采用两阶段代码图搜索策略：首先在文件级别使用动态构建的模块调用图进行广泛探索，然后在函数级别通过拓展模块调用图至函数调用图并执行迭代搜索进行深入分析。为精确控制搜索方向，CoSIL设计了一个剪枝器过滤无关的方向和不相关的背景信息。为防止在长语境下出现不正确的交互格式，CoSIL引入了一种反射机制，在短语境中插入独立查询以增强格式化能力。实验结果显示，使用Qwen2.5-Coder-32B时，CoSIL在SWE-bench Lite和SWE-bench Verified上的Top-1定位准确率分别达到43.3%和44.6%，平均显著优于最先进的方法96.04%。当CoSIL集成到无代理问题解决方法Agentless中时，问题解决率提高了2.98%到30.5%。
### Conclusion
CoSIL在SWE-bench Lampite和SWE-bench Verified上的Top-1本地化准确率分别达到43.3%和44.6%，并在不依赖训练或索引的情况下明显超越了现有的最先进的方法。将CoSIL集成到Agentless中提高了问题解决率，展现了其在实际问题解决中的显著优势。
## 1118. `cs.SE` - EvoC2Rust: 一种项目级C到Rust翻译框架 [PDF](https://arxiv.org/pdf/2508.04295), [HTML](https://arxiv.org/abs/2508.04295)
### Authors
Chaofan Wang,Tingrui Yu,Chen Xie,Jie Wang,Dong Chen,Wenrui Zhang,Yuling Shi,Xiaodong Gu,Beijun Shen
### Background
将遗留的C代码迁移到Rust，特别是在构建安全关键系统中愈发受到需求。尽管出现了多种方式来解决这一问题，但每种方法都有其固有的权衡。基于规则的方法往往难以满足代码安全性和写作风格的要求，而基于大语言模型的方法则经常生成语义上等价的Rust代码，因为代码库中的模块间存在大量依赖。最近研究表明，这两种解决方案都适用于小型程序，但对于大型项目则存在局限性。
### Innovation
本文提出了一种名为EvoC2Rust的自动化框架，该框架可以将完整的C项目自动转换为等效的Rust项目。EvoC2Rust采用骨架引导的翻译策略，分为三个阶段：首先，将C项目分解成功能模块，并使用带有特征映射增强的LLM来转换定义和宏，生成类型检查的功能骨架，形成可编译的Rust骨架；其次，逐步翻译函数，替换相应的骨架占位符；最后，通过集成LLM和静态分析来修复编译错误。通过进化增强，EvoC2Rust结合了基于规则和基于大语言模型方法的优点。评估结果表明，EvoC2Rust在项目级C到Rust翻译上有超越性能，与最强的基于大语言模型的基线相比，在语法准确率上提高了17.24%，在语义准确率上提高了14.32%，同时实现比最好基于规则的工具高43.59%的代码安全性。
### Conclusion
我们的评估表明，EvoC2Rust 在项目级 C 到 Rust 的转换中表现优秀。相比最强的基于大语言模型的基线，EvoC2Rust 在语法准确率上高出 17.24%，在语义准确率上高出 14.32%，并在代码安全性上提高 43.59%。
## 1119. `cs.SE` - RPG：统一且可扩展的代码库生成的仓库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大语言模型在生成单个函数或单个文件代码方面表现出色，但要从头开始生成完整的代码库仍然是一项基本挑战。这一能力对于从高层次规范构建一致的软件系统以及实现自动化代码生成的全部潜力至关重要。生成代码库的过程需要两级规划：决定要构建哪些功能和模块（提案阶段），以及定义它们的实现细节（实现阶段）。当前的方法依赖于自然语言规划，这通常会生成模糊不清的规格说明、不一致的组件和脆弱的设计，因为自然语言具有固有的模糊性和无结构性。
### Innovation
本文引入了Repository Planning Graph (RPG)，这是一种结构化的表示方法，能够统一编码能力、文件结构、数据流和功能，通过用明确的蓝图替换自由形式的自然语言，RPG使长期规划更加一致。在此基础上，开发了ZeroRepo，这是一种图驱动框架，包括提案级规划、实施级构建和遵循图指导的代码生成及测试验证三个阶段。实验结果表明，ZeroRepo在RepoCraft基准测试中的Code Lines和Code Tokens数量分别是最强基线Claude Code的3.9倍和68倍，覆盖率达到了81.5%，测试准确性为69.7%，分别比Claude Code提高了27.3和35.8个百分点。进一步分析显示，RPG能够构复杂依赖性，通过接近线性的可扩展性实现更复杂的计划，并提高代理对代码库的理解能力，从而加速定位。
### Conclusion
RPG模型能够表示复杂依赖关系、通过接近线性可扩展性实现更复杂的规划，并提高代理对代码仓库的了解，从而加快了定位速度。ZeroRepo框架通过RPG在提案级规划、实施级构建和图指导下的代码生成及测试验证中显示出了显著优势。
