{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04871", "html_url": "https://arxiv.org/abs/2509.04871", "title": "从电话录音数据集克隆对话型语音AI代理以用于直销", "title_en": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "authors": "Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn", "background": "近年来，语言和语音建模的进展使得可以构建能够实时理解并生成人类对话的自主语音助手。这些系统已在客户服务和医疗保健等领域部署使用，能够自动化重复性任务、降低运营成本，并提供全天候支持。本文介绍了一种从通话记录语料库中克隆对话型语音AI代理的一般方法。尽管对直销数据进行的研究案例展示了这种方法，但该方法的应用范围涵盖任何有电话转录文本的领域。", "innovation": "本文提出了一种从通话录音数据中克隆对话型语音AI代理的通用方法，该方法结合了自动语音识别、基于大型语言模型的对话管理器以及文本转语音合成技术，形成了一条流式推理管道。克隆的AI代理在对话的各个方面与人类代理进行了比较，虽然在常规对话方面AI代理能够接近人类的性能，但在说服和处理异议方面表现不佳。", "conclusion": "本文总结了基于克隆的AI代理的设计教训及未来的研究方向，包括大规模模拟和自动化评估。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04791", "html_url": "https://arxiv.org/abs/2509.04791", "title": "大型语言模型的 what-if 分析：利用前瞻思维探索游戏世界", "title_en": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking", "authors": "Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi", "background": "现有的大型语言模型（LLMs）擅长于被动处理信息，但缺乏系统地探索未来假设的能力。它们无法主动预测如果我们采取某种行动，它会如何影响最终结果以及其潜在的后果，从而在高风险、动态场景中如战略规划、风险评估以及实时决策中受到局限。", "innovation": "本文提出了一个新的框架WiA-LLM，它结合了What-If分析（WIA），这是一种通过改变输入变量来评估假设情景的系统方法。WiA-LLM通过强化学习利用环境反馈，能够动态模拟每种潜在行动的结果，从而能够预见未来状态，而不仅仅是对当前情况进行被动反应。实验结果表明，WiA-LLM在《王者荣耀》（HoK）的复杂多人游戏环境中表现出了显著的预测能力，准确率高达74.2%，远超基线方法。特别是在高难度场景下，其显著的优势尤为明显。", "conclusion": "这是首次正式研究和整合LLMs中的what-if分析能力的工作。WiA-LLM代表了LLMs中主动推理的基础性进步，为在动态环境中进行鲁棒决策提供了一个可扩展的框架，对战略应用具有广泛的影响。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04676", "html_url": "https://arxiv.org/abs/2509.04676", "title": "基于人类标准对接AI模型评估的方法", "title_en": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria", "authors": "Sasha Mitts", "background": "在人工智能（AI）快速发展的领域中，传统基准可能难以捕捉AI模型的细腻能力。本文集中在物理世界建模方面，提出了一种新颖的方法，通过引入人类制定的评估标准来增强现有基准，旨在提高模型行为的可解释性和适用性。我们基于感知测试和OpenEQA基准，通过深入访谈和大规模调查，识别了优先级、记忆、鉴别和情境化等关键认知技能，这些技能对于人工智能和人类推理都至关重要。", "innovation": "通过将研究发现应用于基准设计，本文提供了一个框架，用于发展更符合人类认知过程的定义和衡量进展的方法。这种方法既提升了当前基准测试实践，也为未来AI模型评估的进步奠定了基础。文章强调了用户为中心的评估在AI开发中的重要性，为研究人员和实践者提供了实施指南，以便使AI能力与人类认知过程保持一致。", "conclusion": "本工作强调了在AI开发中采用用户为中心的评估的重要性，提供了实施指南，帮助研究人员和实践者使AI能力与人类认知过程保持一致。我们的方法既增强了当前的基准测试实践，也为未来AI模型评估的进步奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04646", "html_url": "https://arxiv.org/abs/2509.04646", "title": "健康模拟的个性化解释：面向利益相关者的混合方法框架", "title_en": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization", "authors": "Philippe J. Giabbanelli,Ameeta Agrawal", "background": "健康模拟方法，如基于代理的模型，有潜力支持医疗领域的决策活动，例如疫苗接种的采用和健康饮食及体育活动行为的研究。这些模型可能对不同的利益相关者群体具有用性，它们帮助政策制定者估计潜在干预措施的后果，并引导个体在复杂环境中做出健康选择。然而，这种潜力并未完全实现，因为这些模型的复杂性使它们难以被最能从它们中受益的利益相关者理解。当前的方法通常依赖于一刀切的总结，未能反映临床医生、政策制定者、患者、护理人员和健康倡导者多样化的信息需求和风格偏好。这个问题源于一个基本的缺口：缺乏对这些利益相关者需要什么解释以及如何针对这些需求进行调整的理解。", "innovation": "我们提出了一种分步骤框架来识别利益相关者的需要，并指导大型语言模型生成针对健康模拟的个性化解释。该框架采用混合方法设计，首先通过探索不同的健康利益相关者的解释需求和风格偏好，然后优化大型语言模型生成个性化输出的能力（例如，通过可控属性调优），最后通过一系列评估指标进一步改善个性化总结的效果。", "conclusion": "该框架旨在解决当前模型输出总结的局限性，使其能够更好地满足利益相关者的个性化需求，从而提高健康模拟的应用效果和接受度。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04505", "html_url": "https://arxiv.org/abs/2509.04505", "title": "机器的道德指南针：评估大型语言模型在建筑项目管理决策支持中的伦理性", "title_en": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management", "authors": "Somtochukwu Azie,Yiping Meng", "background": "随着人工智能（AI）在建筑项目管理（CPM）中的应用加速，大型语言模型（LLMs）逐渐成为可用的决策支持工具。这项研究旨在从伦理角度评估LLMs在建筑项目管理高风险的伦理敏感决策环境中应用的可行性和可靠性。研究设计采用了混合方法，包括定量测试两个领先的LLMs的性能，使用新型伦理决策支持评估检查表（EDSAC），以及定性分析十二位行业专家的半结构化访谈，以捕捉专业见解。研究表明，LLMs在结构化领域如法律合规方面表现出足够的性能，但在处理情境细微、确保责任和提供透明推理方面存在显著缺陷。相关方对使用AI进行伦理判断持保留态度，强烈主张加强人类在决策过程中的监督。这是首次在建筑领域中实证测试LLMs伦理推理的研究之一。该研究引入了EDSAC框架作为一个可重复的方法论，并提供了可操作的建议，强调当前LLMs更适合作为决策支持工具而非自主伦理代理。", "innovation": "这项研究是首次在建筑领域中实证测试LLMs伦理推理的研究之一。引入了名为EDSAC的伦理决策支持评估检查表作为一个可重复的方法论，并提出了改进LLMs作为伦理支持工具的行动建议。", "conclusion": "LLMs在结构化领域如法律合规方面表现出足够的性能，但在处理情境细微、确保责任和提供透明推理方面存在显著缺陷。相关方对使用AI进行伦理判断持保留态度，强烈主张加强人类在决策过程中的监督。研究表明LLMs当前更适合作为决策支持工具而非自主伦理代理。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04908", "html_url": "https://arxiv.org/abs/2509.04908", "title": "SparkUI-Parser: 提升GUI感知的稳健对接与解析", "title_en": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "authors": "Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao", "background": "现有的多模态大型语言模型（MLLMs）在GUI感知方面取得了显著进展，但仍存在一些挑战。首先，这些模型基于文本自回归机制建模离散坐标，导致对接精度较低和推理速度较慢。其次，它们只能定位预定义元素集，无法解析整个界面，限制了其广泛的应用和对下游任务的支持。", "innovation": "我们提出了SparkUI-Parser，这是一种新颖的端到端框架，同时实现了更高的定位精度和整个界面的细粒度解析能力。具体来说，不是使用基于概率的离散建模，而是使用预训练的MLLM、附加的标记路由器和坐标解码器进行连续坐标建模。这有效地缓解了MLLM固有的离散输出特征和逐token生成过程的局限性，从而提高了准确性和推理速度。此外，我们引入了一个基于修改后的匈牙利匹配算法的拒绝机制，使模型能够识别并拒绝不存在的元素，从而降低假阳性率。", "conclusion": "我们在广泛的实验中展示了我们的方法在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse基准上始终优于当前最先进的方法。资源可在以下链接获取：this https URL."}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04642", "html_url": "https://arxiv.org/abs/2509.04642", "title": "Maestro: 联合图与配置优化以构建可靠的AI代理", "title_en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "authors": "Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi", "background": "当前大多数优化器在固定图结构的情况下调整节点配置，忽略了图形层面的结构性失败模式。这表明需要一种能够同时优化图形和配置的框架，以提高代理的质量并解决结构性失败模式问题。", "innovation": "提出了Maestro，这是一种无需依赖特定框架的全面优化框架，可以在图形和配置之间进行联合搜索，同时考虑到具体的滚出/标记预算。Maestro还利用反思性的文本反馈来优先进行调整，提高了样本效率并定位特定的失败模式。此外，Maestro在IFBench和HotpotQA基准测试中表现优异，超过了MIPROv2、GEPA和GEPA+Merge等领先的方法，即使限制在仅优化提示的方法下表现也优于对照组。Maestro达到了这些结果所需要的rollout数量远少于GEPA，同时解决了单独提示调整无法修复的结构性失败模式问题.", "conclusion": "Maestro框架因其在图与配置联合优化方面的成就，在不同类型的任务中取得了显著的性能改进，并且验证了其在各种应用上的潜在价值和效率。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05007", "html_url": "https://arxiv.org/abs/2509.05007", "title": "Sticker-TTS: 通过贴纸驱动的测试时缩放框架学习利用历史经验", "title_en": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "authors": "Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen", "background": "大型推理模型（LRMs）在复杂推理任务上表现出强劲的性能，通过增加推理时的计算预算可以进一步提高性能。然而，现有的测试时缩放方法主要依赖冗余采样，忽视了历史经验的利用，从而限制了计算效率。", "innovation": "提出了一个新的测试时缩放框架Sticker-TTS，该框架协调三个协作的LRMs，通过历史尝试来迭代探索和细化解决方案。该框架的核心是提炼出的关键条件——贴纸，这些贴纸驱动多次推理过程中关键信息的提取、精炼和重用。此外，还提出了一种两阶段优化策略，结合模仿学习和自我改进，实现逐步精炼。", "conclusion": "在AIME-24、AIME-25和OlymMATH三个具有挑战性的数学推理基准测试上的广泛评估表明，Sticker-TTS在相似的推理预算下，一直超过了自我一致性方法和先进的强化学习方法的基准线。这些结果突显了贴纸引导的历史经验利用的有效性。相关代码和数据可在该 URL 查看。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05072", "html_url": "https://arxiv.org/abs/2509.05072", "title": "寻找你的缪斯：挖掘意外解决方案引擎", "title_en": "Finding your MUSE: Mining Unexpected Solutions Engine", "authors": "Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf", "background": "创新者常常受到现有解决方案或新兴想法的认知固定，这阻碍了对新替代方案的探索。现有的方法在构建功能概念图（FCGs）方面存在局限性，这使得难以获得大量高质量且包含明确抽象关系的功能概念图。因此，需要一种新的方法来克服这些问题，创建支持抽象化、问题重塑和类比灵感的功能概念图，并提供一种算法来生成特定问题的创造性灵感。", "innovation": "本研究引入了一种构建功能概念图（FCGs）的方法，该方法能够克服之前工作的局限性，生成大规模、高质量且包含明确抽象关系的功能概念图。此外，本文还提出了一种利用功能概念图（FCGs）生成特定问题创造性灵感的算法MUSE，并通过计算50万个专利的功能概念图来展示这一方法的有效性，提供数据供进一步研究使用。", "conclusion": "本研究所提出的功能概念图表征方法和MUSE算法能够促进对现有解决方案的认知超越，为解决复杂问题提供潜在的创意启示，具有实际应用价值。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04876", "html_url": "https://arxiv.org/abs/2509.04876", "title": "OSC：多智能体大语言模型协作中的动态知识对齐认知编排", "title_en": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration", "authors": "Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang", "background": "此前的工作虽然在智能体选择和结果汇总方面取得了进展，但专家智能体之间深入合作的语言互动高效性仍然是一个关键瓶颈。OSC框架通过引入‘协作知识模型（CKM）’，解决了这一问题，能够在选择和汇总之间提供一个重要的中介层，使每个智能体能够动态感知其合作者的认知状态。", "innovation": "OSC（Orchestrating Cognitive Synergy）是首个设计用于增强多智能体系统中基于大型语言模型的认知协同的知识驱动自适应协作框架。通过实时的认知间隙分析，代理能够根据学习到的策略适应性地调整沟通行为，包括内容焦点、细节程度和表达风格等。这使得‘并行工作的个体’能够转变为‘深度协作的认知团体’，优化了多智能体协作，并提供了对大型语言模型智能体交互行为的新见解。", "conclusion": "实验结果表明，OSC在复杂推理和问题解决基准测试中显著提高了任务性能和沟通效率，为多智能体系统中的多智能体协作提供了新思路。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05139", "html_url": "https://arxiv.org/abs/2509.05139", "title": "ODRL的评估与比较语义", "title_en": "Evaluation and Comparison Semantics for ODRL", "authors": "Jaime Osvaldo Salas,Paolo Pareti,Semih Yumuşak,Soulmaz Gheisari,Luis-Daniel Ibáñez,George Konstantinidis", "background": "文章关注的是Open Digital Rights Language (ODRL)的评估和比较问题。ODRL已经成为数字资源获取和使用权限的标准语言，但是其形式化语义仍然缺乏一个全面的描述。现有的初步工作虽然有所进展，但仍需一个简明直观的形式化语义，基于查询回答的方法来完善这一不足。", "innovation": "本文提供了基于查询回答的简单直观形式化语义，该语义是对先前形式化描述的改进，并与最新的主流ODRL语言规范（2.2版）保持一致。此外，论文还基于评价语义，提出了在数据共享场景下的政策比较问题，探讨了等价、更限制性和更宽容性政策的辨别方法。", "conclusion": "本文给出了ODRL的一个全面而简便的形式化语义，并且定义和研究了评估与比较政策的问题，在数据共享场景中辨别等价、更限制性和更宽容性政策。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05091", "html_url": "https://arxiv.org/abs/2509.05091", "title": "ProToM: 通过理论心智指导反馈促进利他行为", "title_en": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback", "authors": "Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling", "background": "人类本质上是社会性的，但人们在与他人协作和提供帮助时面临挑战，尤其是在追求独立目标时。为了应对这一挑战，旨在开发一种AI系统，通过提供有针对性、上下文相关的反馈来促进利他行为（即使这些行为不直接与个人目标一致）。研究在两个多代理系统环境中，即Doors, Keys, and Gems，以及Overcooked中评估了这种方法，发现最先进的大规模语言和推理模型在提供上下文相关和及时反馈方面存在不足，导致更高的沟通开销和任务加速。", "innovation": "提出了ProToM（Theory of Mind-Informed Facilitator），这是一种理论心智指导的促进剂，能够通过最大化的期望效用来根据推断出的目标分布选择反馈内容，从而促进多代理系统中的利他行为。ProToM结合了贝叶斯逆向规划推断代理的目标，然后提供与其目标分布相适应的反馈，这种方法在评估中显示出较高的成功率和较短的任务完成时间，并且被人类用户更偏好。", "conclusion": "ProToM在多代理环境中提供了有针对性和有帮助的反馈，成功提高了任务完成率，缩短了任务完成时间，并且在用户偏好方面持续表现更好，相比之下，最先进的大规模语言和推理模型在这些方面存在不足。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2303.06298", "html_url": "https://arxiv.org/abs/2303.06298", "title": "MLP-SRGAN: 使用MLP-Mixer的一维超分辨率生成对抗网络", "title_en": "MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer", "authors": "Samir Mitha,Seungho Choe,Pejman Jahbedar Maralani,Alan R. Moody,April Khademi", "background": "本文提出了一种名为MLP-SRGAN的新架构，它是一种利用MLP-Mixers和卷积层将切片方向上进行上采样的单维度超分辨率生成对抗网络（SRGAN）。该方法使用MSSEG2挑战数据集中高分辨率（HR）FLAIR MRI对手段进行训练和验证。方法被应用于三个多中心FLAIR数据集（CAIN、ADNI、CCNA），测试其在未见过临床数据上的表现。", "innovation": "本文提出了MLP-SRGAN架构，结合了MLP-Mixers和卷积层，用于在单维度上进行超分辨率处理。实验结果表明，与现有方法相比，MLP-SRGAN在边沿锐度、保真度、细节保留、参数数量、训练/评估时间及模型尺寸方面表现出明显优势。", "conclusion": "MLP-SRGAN在多个结构化、无参照图像质量评估指标方面取得了优异的表现，尤其是边沿锐度、噪声抑制和低频信息保留方面，同时具有更少的参数、更短的训练/评估时间和更小的模型尺寸。相关代码被提供供进一步研究使用。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02718", "html_url": "https://arxiv.org/abs/2509.02718", "title": "无需训练的高效在线多大语言模型路由方案", "title_en": "Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving", "authors": "Fangzhou Wu,Sandeep Silwal", "background": "随着大型语言模型（LLMs）服务需求的增加，部署和计算成本显著上升。LLM路由可以通过将查询路由到基于模型和查询特征的最佳LLM来提供低成本的解决方案。然而，现有工作主要集中在离线场景中，难以适应高查询量和受限的标记预算的在线设置。", "innovation": "本文提出了一种无需训练的在线路由算法，通过利用近似最近邻搜索快速估计查询特征，并对初始查询进行一次优化来学习指导未来的路由策略。在具备自然假设的理论分析中，该算法的竞争比为$1 - o(1)$，并在三个基准数据集和八个基线方法的广泛实验中得到验证，显示出整体性能平均提高了3.55倍、成本效率提高了1.85倍以及吞吐量提高了近4.25倍。", "conclusion": "该算法在无需训练的情况下，能够高效处理高流量的多大语言模型服务需求，并在多个指标上证明了其优越性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04731", "html_url": "https://arxiv.org/abs/2509.04731", "title": "语言驱动的层次任务结构作为多智能体学习的显式世界模型", "title_en": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "authors": "Brennen Hill", "background": "当前，语言模型、代理模型和世界模型的融合是人工智能的一个关键前沿领域。虽然最近的研究集中在扩展语言和代理模型，但构建复杂的世界模型仍然是一个关键瓶颈，尤其是在复杂的长期多代理任务中。在机器人足球等领域的研究中，使用高保真但结构扁平化的模拟器并通过标准强化学习训练的智能体往往因为难以探索的空间和稀疏的反馈而失败。研究呼吁未来智能代理发展的关键是构建具备显式层次结构世界模型的环境。通过系统回顾2024年的多智能体足球研究，发现符号和层次方法与多智能体强化学习（MARL）的集成趋势越来越明显。这些方法隐式或显式地构建基于任务的世界模型以指导智能体学习。从而提出一个新的范式转移，利用大规模语言模型动态生成这个层次结构框架，通过语言即时构建世界模型。这种由语言驱动的世界模型提供了内在的课程，密集且有意义的学习信号，以及组件学习的框架，使代理模型在更少的样本下获得了复杂的策略行为。通过构建明确且可配置任务层的环境，可以弥合低级反应性行为和高级战略团队玩法之间的差距，创建一个强大且泛化的框架，用于训练下一代智能代理。", "innovation": "文章提出的创新点在于利用大规模语言模型动态生成层次结构框架，即时构建世界模型，以此提供内在的课程，密集且有意义的学习信号，以及组件学习的框架，使代理模型在更少的样本下获得复杂的策略行为。通过对多智能体足球的研究，证明了这种方法的有效性。", "conclusion": "通过构建明确且可配置任务层的环境，可以弥合低级反应性行为和高级战略团队玩法之间的差距，创建一个强大且泛化的框架，用于训练下一代智能代理。这种方法提供了理解和学习复杂任务的新途径，基于任务的语言驱动世界模型能够有效促进智能体的学习和战略行为的发展。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04847", "html_url": "https://arxiv.org/abs/2509.04847", "title": "通过博弈论视角看人类与语言模型之间的合作与冲突", "title_en": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory", "authors": "Mukul Singh,Arjun Radhakrishna,Sumit Gulwani", "background": "随着语言模型在多互动在线环境中部署增加，从个人聊天助手到特定领域的代理，人们对他们在多党环境中的合作和竞争行为提出疑问。尽管以前的工作研究过孤立或短期博弈中的语言模型决策，但这些研究往往忽略了长期互动、人类模型协作以及行为模式随时间演变的问题。本文使用迭代的囚徒困境（IPD）来探讨语言模型行为的动态。IPD是研究合作与冲突的经典框架。研究表明，语言模型的表现可以与甚至超过最知名的古典策略。行为分析表明，语言模型展示了关键的强协作策略特征——友好性、挑衅性和仁慈性，在游戏中间对手策略发生变化时也表现出快速适应能力。在控制的‘策略切换’实验中，语言模型在几轮内就能检测并响应策略变化，与人类适应能力匹敌或超越。这些结果首次系统地描述了语言模型在长期内的协作行为，为未来研究其在更复杂、混合的人机社会环境中的角色提供了基础。", "innovation": "本文通过迭代囚徒困境研究语言模型的行为动态，在长期内系统地描述了语言模型的协作行为，探讨了它们在多党环境中的合作与竞争行为。研究发现语言模型接近或超过了最佳古典策略，并展示了快速适应对手策略的能力。同时，这也是首次利用博弈理论视角系统研究语言模型在长期内的行为策略。", "conclusion": "语言模型在长期内表现出强大的合作行为，包括友好性、挑衅性和仁慈性，并能在短时间内对对手策略变化做出快速适应。这些发现为复杂的人机社会环境中的语言模型行为提供了新见解，为未来的研究奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03614", "html_url": "https://arxiv.org/abs/2509.03614", "title": "在MIDOG 2025 挑战赛中采用教师-学生模型检测和分类分裂细胞", "title_en": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge", "authors": "Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Susan Done,Dimitrios Androutsos,April Khademi", "background": "细胞分裂图的计数对于病理学家来说是一个耗时的过程，并容易导致不同观察者之间的差异。人工智能（AI）有潜力通过自动检测分裂细胞来解决这个问题，同时保持决策一致性。然而，AI 工具易受域偏移的影响，这会导致由于训练集和测试集之间的差异，尤其是器官形态多样性、物种差异和染色协议的变化，而导致性能显著下降。此外，分裂细胞的数量远远少于正常细胞的数量，这为检测任务带来了严重的数据不平衡问题。", "innovation": "本文将分裂细胞检测问题定义为像素级别分割，并提出了一种教师-学生模型，该模型同时解决了分裂细胞检测（第1赛道）和不典型分裂细胞分类（第2赛道）。本文的方法基于一个结合了域泛化模块的UNet分割骨干网络，包括对比表征学习和领域对抗训练。采用教师-学生策略生成像素级别的伪掩码，不仅涵盖注释分裂细胞和硬负样本，还包括正常细胞，从而增强特征鉴别能力和提高对域偏移的鲁棒性。对于分类任务，引入了多尺度CNN分类器，可以利用分割模型的特征图在多任务学习范式下工作。", "conclusion": "在初步测试集上，算法在第1赛道的F1分数达到了0.7660，在第2赛道的平衡准确率达到0.8414，展示了通过结合基于分割的检测和分类，将分裂细胞分析统一到一个框架中的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04460", "html_url": "https://arxiv.org/abs/2509.04460", "title": "CoCoNUTS: 在检测AI生成的同行评审中重视内容忽略无信息文本风格", "title_en": "CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection", "authors": "Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun", "background": "大语言模型（LLMs）在同行评审过程中的日益集成带来了对学术评估公平性和可靠性的潜在风险。尽管LLMs能够提供语言润色方面的帮助，但越来越多人担忧其可能被用于生成实质性的评审内容。现有的通用AI生成文本检测器受到了改写攻击的影响，难以区分表面语言润色和实质内容生成，表明它们主要依赖于风格线索。当应用于同行评审时，这种局限性可能导致合法的AI辅助语言增强被不公平地怀疑，而未能捕捉到伪装为人类生成的AI生成评审内容。", "innovation": "提出了一种从基于风格到基于内容的检测方案转变。具体来说，引入了CoCoNUTS，这是一个内容导向的基准，基于细粒度的人工智能生成同行评审数据集，涵盖了六种不同的人机协作模式。此外，还开发了CoCoDet，这是一种多任务学习框架下的AI评审检测器，旨在更准确和稳健地检测评审内容中的AI参与。这项工作为评价LLMs在同行评审中的使用提供了实用基础，并促进了更精确、公平和可靠的检测方法的发展。", "conclusion": "我们的工作提供了一种实用框架，用于评估LLMs在同行评审中的应用，并为现实世界学术应用中的更精确、公平和可靠的检测方法的发展做出了贡献。我们的代码和数据将在指定的网址公开可获取。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04463", "html_url": "https://arxiv.org/abs/2509.04463", "title": "基于复杂形状针鳍结构湍流热预测的多尺度图神经网络", "title_en": "Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin", "authors": "Riddhiman Raut,Evan M. Mihalko,Amrita Basak", "background": "本文研究了一种适用于任意形状复杂针鳍结构二维通道中稳定和湍流流动及热行为预测的领域响应边缘感知多尺度图神经网络。研究的数据集通过集成几何生成、网格划分和 ANSYS Fluent 仿真流场解决方案的自动化框架构建。针鳍几何形状通过分段三次样条函数参数化，生成了 1000 种不同的配置，并使用拉丁超立方采样进行校验。每个仿真结果被转换为图结构，图的节点携带包含空间坐标、归一化顺流位置、一维边界指示符和到最近边界的符号距离等特点向量。此图结构作为新开发的图神经网络的输入，该网络被训练用于从 ANSYS 中获取的数据预测每个节点的温度、速度幅度和压力场，预测结果具有出色的准确性，捕捉到了边界层、回流区以及针鳍上游的停滞区域，显著缩短了计算时间（缩短了 2-3 个数量级）。", "innovation": "提出了适用于任意形状复杂针鳍结构二维通道中湍流流动及热行为预测的领域响应边缘感知多尺度图神经网络。该网络能够有效捕捉边界层、回流区以及针鳍上游的停滞区域，预测结果具有出色的准确性，并且显著提高了计算效率（缩短了 2-3 个数量级）。研究中的创新点包括采用分段三次样条函数进行针鳍几何参数化、利用拉丁超立方采样生成多种复杂配置、构建适用于针鳍结构的图神经网络预测模型，并实现将仿真结果转换为图结构输入神经网络进行预测的方法。", "conclusion": "本研究提出了一种新的图神经网络模型，该模型能够在复杂流场配置下快速且可靠地模拟湍流流动及热行为，预测结果准确，计算时间大幅缩短。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04464", "html_url": "https://arxiv.org/abs/2509.04464", "title": "来自LLM的多个响应能否揭示其不确定性来源？", "title_en": "Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?", "authors": "Yang Nan,Pengfei He,Ravi Tandon,Han Xu", "background": "大语言模型（LLMs）在多个领域取得了显著突破，但在某些情况下仍可能产生不可靠或误导性的输出，这对实际应用提出了关键挑战。尽管许多近期研究集中在量化模型不确定性上，但很少有人工智能诊断不确定性来源的工作。本文研究了当LLM产生不确定性时，其多个生成响应之间的分歧模式包含关于不确定性来源的重要线索。为此，研究者通过收集目标LLM的多个响应，并使用辅助LLM分析这些分歧模式，来鉴别不确定性来源，包括输入问题的歧义性或缺乏相关知识，或两者皆有。在知识差距的情况下，辅助LLM还能够识别特定缺失的事实或概念。实验在多种数据集上验证了该框架的有效性，表明该方法具有诊断不同类型不确定性来源的通用性。通过这种诊断，可以为改进LLM性能和可靠性提供有相关性的手动干预手段。", "innovation": "提出了利用LLM多个响应间的分歧模式来诊断不确定性来源的方法。通过引入辅助LLM来分析这些分歧，研究者发现这些模式揭示了输入问题的歧义性、相关知识的缺失或两者并存等地原因，甚至在知识差距的情况下，能够具体识别出导致不确定性的特定缺失事实或概念。这种方法展示了其对改进LLM性能和可靠性有着潜在的价值。", "conclusion": "研究验证了提出的方法在AmbigQA、OpenBookQA及MMLU-Pro等数据集上的有效性，证实其在诊断不同来源的不确定性方面具有泛化能力。这表明通过识别不确定性来源的具体情况，可以进行有针对性的手动干预，从而提高LLM的性能和可靠性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04467", "html_url": "https://arxiv.org/abs/2509.04467", "title": "提升LLM效率：针对预填充-解码离散化的精确剪枝", "title_en": "Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference", "authors": "Hao Zhang,Mengsi Lyu,Yulong Ao,Yonghua Lin", "background": "大规模语言模型（LLMs）在各种任务中展现出了出色的能力，但由于高计算和内存成本，其部署受到限制。模型剪枝是一种有效的手段，可以减轻这些需求。然而，现有的方法往往忽视了实践中预填充-解码（PD）离散化特征。", "innovation": "本文提出了一种新的针对PD离散化推理的剪枝方法，能够实现更精确和高效的块和KV缓存剪枝。文章方法通过构造剪枝和蒸馏集，独立地对预填充和解码阶段进行迭代的剪枝，获得更好的剪枝解决方案。此外，还引入了一种基于令牌的缓存剪枝机制，在预填充阶段保留所有KV缓存，并在解码阶段选择性地重用较早和较晚的令牌序列，减少通信成本，同时减少开销。", "conclusion": "广泛的实验表明，该方法在PD离散化和PD统一设置中都能实现良好的性能，且其方法在默认设置下，实现了20.56%的推理加速和4.95倍的数据传输带宽减少。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04979", "html_url": "https://arxiv.org/abs/2509.04979", "title": "Internet 3.0: 构建Agent网络的架构及其代理排名算法", "title_en": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents", "authors": "Rajesh Tembarai Krishnamachari,Srividya Rajesh", "background": "互联网正面临着由具备推理能力的大语言模型（LLMs）和工具、数据、网络搜索集成的AI代理带来的革命性变化，这些代理将形成一个机器原生的生态网络，即Agent网络，其中自主代理能够大规模地交互、协作并执行任务。然而，要实现这一愿景，需要一种代理排名机制，该机制不仅要考虑声明的功能，还要考虑实际的、近期的表现。不同于Web1.0时代的PageRank，全球透明的代理交互网络并不存在，使用信号是分散且私有的，因此在缺乏协调的情况下，进行排名是不可能的。因此，需要一个新的架构和算法来收集生态系统的最小可行、隐私保护的使用和性能聚合，并且能够实现动态信任意识的排名算法。", "innovation": "论文提出了名为DOVIS的五层运营协议（发现、编排、验证、激励、语义），能够收集最少的、隐私保护的使用和性能汇总，为结算基础结构。在此基础上，实现了一种动态、信任感知的AgentRank-UC算法，这种算法结合了使用（选择频率）和能力（结果质量和成本、安全性和延迟），最终成为一个统一的排名。该算法通过模拟结果和理论保证，证明了协调协议和基于性能的排名在实现可扩展且值得信赖的Agent网络中是可行的，展示了协调协议和性能感知排名的潜力和有效性。", "conclusion": "本文展示了DOVIS协议和AgentRank-UC算法如何使定义的Agent网络以及代理排名成为可能，并通过模拟结果和理论确保了此框架的收敛性、鲁棒性和Sybil抗性，证明了这种协调协议和基于性能的排名机制在构建“智能”互联网中的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04465", "html_url": "https://arxiv.org/abs/2509.04465", "title": "具有情感意识的代理人在纠纷解决中的应用", "title_en": "Emotionally-Aware Agents for Dispute Resolution", "authors": "Sushrita Rakshit,James Hale,Kushal Chawla,Jeanne M. Brett,Jonathan Gratch", "background": "在冲突中，人们通过情感表达来影响对方的思维、情感和行为。先前的研究显示情感识别技术在谈判中有潜力，然而纠纷涉及更为强烈的情感和不同的社会过程。本研究以卖家与买家纠纷对话的大型语料库为研究对象，调查情感表达如何塑造主观和客观结果。研究表明，大型语言模型在情绪强度标注方面比以往方法有更大的解释力，并且更好地与人类标注者的决策匹配。这些发现支持现有的理论模型，即情绪表达如何促进冲突升级和解决，并指出基于代理的系统可能在识别和减轻情绪升级方面对纠纷管理有帮助。", "innovation": "本研究利用大型语言模型在情绪强度标注方面的优势，不仅提高了解释力，还使其与人类标注者的决策更加一致。这为使用情感识别技术来管理纠纷提供了新的视角，提出了基于代理系统的潜在应用价值，能够识别并可能缓解情绪升级问题。", "conclusion": "研究发现支持现有的理论模型，即情绪表达在冲突中对升级和解决的作用，并指出基于代理系统的纠纷管理可能有潜在的价值，通过识别和减轻情绪升级来管理纠纷。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "评估 GPT-5 在生物医学自然语言处理中的性能", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Rui Zhang", "background": "生物医学文献的迅速扩展增加了对可扩展的自然语言处理（NLP）解决方案的需求。尽管 GPT-4 在问答任务上显著缩小了与专用系统的差距，但在其他领域的表现仍然参差不齐。因此，更新了一个标准化的生物医学自然语言处理基准，以评估 GPT-5 和 GPT-4o 在零样本、单样本和五样本提示下的表现，涵盖 12 个数据集，包括六类任务：实体识别、关系抽取、多标签文档分类、问答、文本摘要和文本简化。", "innovation": "使用固定提示模板、一致的解码参数和批量推理，报告了每个数据集的主要指标，并提供了 GPT-4、GPT-3.5 和 LLaMA-2-13B 的先前结果以供比较。GPT-5 在五样本提示下取得了最佳的整体基准性能，达到 0.557 的宏观平均得分，超过了 GPT-4 和 GPT-4o 的 0.506 和 0.508。GPT-5 在 MedQA 上取得了 94.1% 的准确率，超过了之前监督学习的最先进水平 50 个百分点，并与监督系统在 PubMedQA 上达到了同等表现（0.734）。在抽取任务中，GPT-5 在化学实体识别 (0.886 F1) 和 ChemProt 关系抽取 (0.616 F1) 上取得了显著改进，优于 GPT-4 和 GPT-4o，但在总结和疾病实体识别方面仍落后于领域特定的基础模型。", "conclusion": "这些结果将 GPT-5 确立为一种通用模型，现在提供了用于推理导向的生物医学问答的部署级性能，但精确度关键的抽取和信息密集的总结仍然偏向微调或混合方法。基准测试界定了简单提示足够和需要检索增强或基于规划的架构的地方，为生物医学 NLP 系统设计提供了可操作的指导，随着前沿模型的发展提供了实用的指南。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04469", "html_url": "https://arxiv.org/abs/2509.04469", "title": "多模态视觉 vs. 基于文本的解析：发票处理中LLM策略的基准测试", "title_en": "Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing", "authors": "David Berghaus,Armin Berger,Lars Hillebrand,Kostadin Cvejoski,Rafet Sifa", "background": "本文在三个不同家庭的八个大语言模型（GPT-5，Gemini 2.5，以及开源的Gemma 3）上，使用零样本提示在三个多样化的公开可用的发票文档数据集上进行了基准测试。评估了两种处理策略：直接使用多模态能力进行图像处理和先将文档转换为markdown格式再进行结构化解析。", "innovation": "提出了两种处理策略的基准测试，即直接图像处理和结构化提取，结果显示原生图像处理通常优于结构化方法，但不同模型类型和文档特征的表现有所不同。", "conclusion": "该基准测试为选择合适的模型和处理策略来进行自动化文档处理系统提供了洞见。相关代码已在线提供。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04466", "html_url": "https://arxiv.org/abs/2509.04466", "title": "语言模型中即时且分布的任务表示", "title_en": "Just-in-time and distributed task representations in language models", "authors": "Yuxuan Li,Declan Campbell,Stephanie C. Y. Chan,Andrew Kyle Lampinen", "background": "许多语言模型的惊人能力来自于它们的上下文学习：基于指令或示例，它们可以在无需权重更新的情况下推断并执行新任务。本文研究了语言模型中新任务表示形成的时间点及其在上下文过程中的变化。研究者集中于可以跨不同模型实例恢复任务上下文的可迁移任务表示，并展示了这些表示以非单调和间歇的方式演变，与持续存在的较高层级任务类别表示不同。", "innovation": "本文揭示了语言模型中新任务表示以非单调和间歇的方式演变的特点，并强调了这些可迁移任务表示关注的是局部任务范围，并依赖于更分散的表示来支持长期和复合任务。这种双维度分布性（时间性和语义性）揭示了语言模型即时适应新证据和快速学习新任务的基础计算过程。", "conclusion": "研究表明，语言模型能够以即时且分布的方式处理任务表示，这种处理方式依赖于局部但可迁移的任务表示来处理短期任务，并结合更分散的表示来支持长期和复合任务。这一发现揭示了语言模型快速适应新任务的机制。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05263", "html_url": "https://arxiv.org/abs/2509.05263", "title": "LatticeWorld: 一种基于多模态大语言模型的交互式复杂世界生成框架", "title_en": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "authors": "Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu", "background": "近年来，越来越多的研究关注于开发模拟复杂现实场景的3D世界模型。这些世界模型在诸多领域，如具身AI、自动驾驶、娱乐等，都有着广泛的应用。更真实的模拟和精确的物理仿真将有效减小虚拟与现实之间的差距，并方便我们获取丰富的真实世界信息。传统的人工建模已经能够创建虚拟的3D场景，而现代方法则借助先进的人工智能算法进行3D世界的生成，尤其是在生成性模型方面取得了显著进展，可以通过用户的指令生成虚拟世界。本文探讨了这一研究方向，并提出了LatticeWorld，这是一种简单有效且能够简化3D环境工业生产流程的3D世界生成框架。", "innovation": "LatticeWorld 采用了轻量级的LLM（如LLaMA-2-7B）与工业级渲染引擎（例如Unreal Engine 5）相结合的方式生成动态环境。它接受文本描述和视觉指令作为多模态输入，生成具有大规模交互特性的3D世界，具备竞争性的多智能体交互、高保真物理仿真和实时渲染等特点。通过全面的实验，LatticeWorld 在场景布局生成和视觉保真度方面表现出了卓越的准确性，并实现了相较传统手工生产方法约90倍的工业生产效率提升，同时保持了高品质的创造力。", "conclusion": "LatticeWorld 成功证明了生成性人工智能在3D世界生成中的有效应用，显着提高了生产效率，同时维持了高质量。这项工作为构建复杂的交互式虚拟世界提供了一种新的方法，具有广泛的应用前景。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04473", "html_url": "https://arxiv.org/abs/2509.04473", "title": "SpeechLLM: 统一的语音和语言模型以增强低资源环境中的多任务理解", "title_en": "SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings", "authors": "Jaekwon Yoo,Kunal Chandiramani,Divya Tadimeti,Abenezer Girma,Chandra Dhir", "background": "将语音编码器与大型语言模型（LLM）集成需要大量的数据和资源，但实际应用中受限于数据不足。为此，该研究提出一种参数效率适配器，用于将语音嵌入转换为与LLM兼容的标记，特别是在端到端自动语音识别（ASR）、实体识别（NER）和情感分析（SA）等场景中。", "innovation": "研究提出了一种使用7倍 fewer 可训练参数的高效适配器，实现了显著的性能提升，包括26%的WER改进，6.3%的NER F1分数提升，和32%的SA F1分数提升。此外，使用分类器正则化技术和低秩适应（LoRA）优化LLM进一步提升了性能。", "conclusion": "该研究提出的适配器与新的优化方法在低资源环境下显著提升了多任务处理能力，特别是ASR、NER和SA任务中，展示了在语音和自然语言处理中的有效性和实用性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04474", "html_url": "https://arxiv.org/abs/2509.04474", "title": "加速与扩展：高效大型语言模型测试时扩展的推测性解码基准", "title_en": "Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling", "authors": "Shengyin Sun,Yiming Li,Xing Li,Yingzhao Lian,Weizhe Lin,Hui-Ling Zhen,Zhiyuan Yang,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Chen Ma", "background": "测试时扩展已成为通过在推理期间分配额外计算资源来提升大型语言模型（LLM）推理能力的一种强大范式。然而，这一范式因生成冗余和重复的推理路径而存在固有的低效性，导致显著的计算开销。推测性解码为缓解这种低效性提供了有希望的途径，但在结构化且重复性高的测试时扩展背景下，推测性解码的有效性尚未得到充分探索。", "innovation": "本文引入了首个全面评估推测性解码方法加速LLM测试时扩展的基准。该基准在代表性的测试时扩展范式中（例如，Best-of-N采样和多轮思考）提供了一致的实验规程，使不同类型的推测性解码方法（基于模型、基于训练、基于n-克隆的方法）能够进行公平比较。实验证明，简单的基于n-克隆的方法能有效捕捉重复模式，显示出在测试时扩展加速中的独特潜力。", "conclusion": "研究结果表明，将基于n-克隆的方法与基于模型或基于训练的方法结合，可以在处理重复性和多样化推理路径的测试时扩展加速中找到平衡。希望这一基准能够激发推测性解码在测试时扩展方面的进一步研究，通过更好地处理重复和多样化的推理路径，使大型语言模型的推理更加快速和实用。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04479", "html_url": "https://arxiv.org/abs/2509.04479", "title": "没有集群，没有路由：Transformer实际上如何处理稀有词汇", "title_en": "No Clustering, No Routing: How Transformers Actually Process Rare Tokens", "authors": "Jing Liu", "background": "大语言模型在预测罕见词汇方面存在困难，但这些模型特化机制的具体运作方式尚不清楚。先前的研究发现了一些处理罕见词汇的专门化“平台”神经元，并且观察到它们的影响模式遵循特殊三阶段规律，但是这些神经元的功能组织仍不清楚。", "innovation": "本研究通过神经元影响分析、基于图的聚类和注意力头消融研究，对GPT-2 XL和Pythia模型中的稀有词汇处理机制进行了深入探究。研究发现稀有词汇处理需要超越常见词汇所需的幂律范围，形成双重计算机制；稀有词汇处理中的平台神经元在空间上分散而非分组集群；以及注意力机制并无偏好性的路径分配给专门处理稀有词汇的神经元。这些发现表明，稀有词汇特化是通过分布式、在训练过程中发生分化形成的，而不是通过架构模块化实现的。", "conclusion": "研究结果表明，稀有词汇的特化通过分布式、通过训练驱动的分化机制形成，这种机制能够保持上下文敏感的灵活性，并实现适应性能力分配，没有显示出明确的模块化结构或偏好的路径分配机制。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04471", "html_url": "https://arxiv.org/abs/2509.04471", "title": "MOSAIC：一种多语言、无特定分类体系的和计算效率高的影像报告分类方法", "title_en": "MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification", "authors": "Alice Schiavone(1 and 2),Marco Fraccaro(3),Lea Marie Pehrson(1, 4 and 5),Silvia Ingala(4 and 6),Rasmus Bonnevie(3),Michael Bachmann Nielsen(5),Vincent Beliveau(7),Melanie Ganz(1 and 2),Desmond Elliott(1) ((1) Department of Computer Science, University of Copenhagen, Denmark, (2) Neurobiology Research Unit, Copenhagen University Hospital, Denmark, (3) Unumed Aps, Denmark, (4) Department of Diagnostic Radiology, Copenhagen University Hospital, Denmark, (5) Department of Clinical Medicine, University of Copenhagen, Denmark, (6) Cerebriu A/S, Denmark, (7) Institute for Human Genetics, Medical University of Innsbruck, Austria)", "background": "放射学报告包含丰富的临床信息，可用于训练影像模型，而无需依赖昂贵的手动标注。现有方法存在以下限制：基于规则的方法难以应对语言变异，监督模型需要大量标注数据集，而最近的基于大规模语言模型（LLM）的方法依赖于闭源或计算资源密集的模型，并不适合临床使用。此外，现有解决方案主要限制在英语和单一模态、单一分类体系的数据集上。", "innovation": "我们提出了MOSAIC，一种基于开源紧凑型语言模型（MedGemma-4B）的多语言、无特定分类体系和计算效率高的放射学报告分类方法。该方法支持零样本/少量样本提示和轻量级微调，可在消费级GPU上部署。我们在七个涵盖不同语言、影像模态和标签分类体系的数据集上进行了评估，结果显示模型在五个胸部X光数据集上达到了88的平均宏观F1分数，接近或超过专家级表现，同时仅需24GB的GPU内存。通过数据增强，即使仅有80个标注样本，也可以在丹麦报告中达到82的加权F1分数，这也比使用完整的1600样本训练集的86高。MOSAIC为临床环境提供了大型或专有LLM的实用替代方案。代码和模型均为开源，欢迎社区在新的语言、分类体系和模态上评估与扩展MOSAIC.", "conclusion": "MOSAIC提供了在临床环境下替代大规模专有语言模型的实用方案，其代码和模型均已开源，为新的语言、分类体系和模态的评估与扩展提供了基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04481", "html_url": "https://arxiv.org/abs/2509.04481", "title": "叙事到场景生成：基于大语言模型的2D游戏环境管道", "title_en": "Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments", "authors": "Yi-Chun Chen,Arnav Jhala", "background": "近年来，大型语言模型 (LLMs) 的发展使得生成引人入胜的故事成为可能，但将叙述性文本连接到可玩的视觉环境中仍然是程序化内容生成 (PCG) 中的一个开放挑战。本文提出了一种轻量级的管道，将简短的叙述性提示转换为反映故事时间结构的2D格子游戏场景序列。", "innovation": "该系统通过识别关键时间框架，提取以‘对象-关系-对象’三元组的形式呈现的空间谓词，并从GameTileNet数据集中使用基于使用功能的语义嵌入检索视觉资产。层级地形通过细胞自动机生成，物体依据谓词结构使用空间规则放置。该原型提供了一种面向叙述场景生成的可扩展方法，并为未来多框架连续性、符号跟踪和故事情节中心的多智能体协调工作奠定了基础。", "conclusion": "我们在十个不同的故事中评估了该系统，分析了单元格-物体匹配、使用功能层对齐以及跨框架的空间约束满足情况。该原型为基于叙述的场景生成提供了一种可扩展方法，并为未来工作奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04475", "html_url": "https://arxiv.org/abs/2509.04475", "title": "ParaThinker：作为新范式的原生并行思考以扩展LLM测试时计算", "title_en": "ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute", "authors": "Hao Wen,Yifan Su,Feifei Zhang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大型语言模型（LLMs）的进步主要依赖于测试时计算量的扩展——一种通过生成更长、更连续的思考过程来提高推理能力的方法。尽管这种方法很有效，但随着计算量的增加，会出现瓶颈，进一步的计算只能带来微小的性能提升。研究者认为这一上限并不是模型能力的内在限制，而是由于计算扩展策略本身的缺陷，这个问题被称为“隧道视野”，即模型的初始不完美的推理路径将其锁定在了次优推理路径上。", "innovation": "为了解决这一问题，提出了一种新的扩展范式：原生思想并行（Native thought parallelism）。引入了ParaThinker框架，该框架训练LLM以并行生成多种多样且独立的推理路径，并融合为更好的最终答案。这一方法通过同时探索不同的思考路径，有效避免了“隧道视野”问题，激活了模型潜在的推理能力。研究证明，相对于单纯序列扩展计算（深度扩展），并行扩展计算（宽度扩展）可以更有效地实现更好的推理性能。在挑战性推理基准测试中，ParaThinker相对于传统的LLM实现了显著的准确性提升（1.5B模型平均提升12.3%，7B模型平均提升7.5%，使用8条并行路径），且增加了几乎可以忽略的延迟（7.1%）。这使得较小的模型能够超越更大的同类模型，并确立了平行思考是未来扩展LLMs的关键和有效维度。", "conclusion": "研究结果表明，通过并行扩展计算（宽度扩展）来实现更好的推理性能比仅仅通过序列扩展计算（深度扩展）更有效且更高效。通过探索不同的思考路径，ParaThinker成功规避了“隧道视野”问题，激活了模型的潜在推理能力。ParaThinker的创新之处在于，展示了原生的并行思考范式对于扩展未来的大型语言模型具有重要价值。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04476", "html_url": "https://arxiv.org/abs/2509.04476", "title": "使用上下文感知分词训练文本到分子模型", "title_en": "Training Text-to-Molecule Models with Context-Aware Tokenization", "authors": "Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin", "background": "近年来，文本到分子模型在化学应用中显示出巨大潜力，特别是药物发现。这些模型通过将分子表示为原子序列来适应语言模型，但主要依赖原子级别的分词来建模局部连接性，从而限制了模型捕捉分子全局结构上下文的能力。", "innovation": "本文提出了一个新颖的文本到分子模型——上下文感知分子T5（CAMT5）。受亚结构级别上下文在理解分子结构中的重要性启发，我们引入了亚结构级别的分词方案，并开发了一种基于重要性的训练策略，该策略优先考虑关键亚结构，使CAMT5更好地捕捉分子语义。实验验证了CAMT5在各种文本到分子生成任务中的优越性，并发现仅使用2%的训练标记，CAMT5就能超越最先进的方法。此外，我们提出了一种简单的有效集成策略，可以进一步提高生成性能。", "conclusion": "本文提出了一种新的上下文感知文本到分子模型CAMT5，通过引入亚结构级别的分词方案和基于重要性的训练策略，显著提高了模型对分子结构语义的理解和生成能力。实验结果验证了CAMT5的优越性能，并提供了一种提高生成性能的简单有效集成策略。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04484", "html_url": "https://arxiv.org/abs/2509.04484", "title": "自动评估同行评审对作者有用性的良好、不足和建设性", "title_en": "The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors", "authors": "Abdelrahman Sadallah,Tim Baumgärtner,Iryna Gurevych,Ted Briscoe", "background": "同行评审是提供建设性反馈给文章作者的核心部分。然而，随着评审者时间的减少，需要自动化支持系统来确保高质量的评审，并且使反馈对作者有用。本研究识别了四个关键方面（弱点部分中的单一要点）来评估评审意见的实用性：可操作性、可验证性和具体性、帮助性。", "innovation": "研究引入了RevUtil数据集，包含1430个人工标注的评审意见和10000个合成标注的意见。这些合成数据包括解释，即解释评审意见的评分原因。研究还评估了评估评审意见和生成解释的微调模型，并表明这些微调模型与人类的协议水平相当，甚至在某些情况下超越了强大的闭合模型如GPT-4o。此外，研究指出机器生成的评审意见在四个方面普遍不及人工评审。", "conclusion": "本研究通过RevUtil数据集展示了微调模型在评估评审意见和生成解释方面的性能，表明机器生成评审意见在某些方面不如人工评审意见。该研究为评估和改进评审意见提供了新的工具和方法。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04470", "html_url": "https://arxiv.org/abs/2509.04470", "title": "COCORELI：合作、组合重构与执行语言指令", "title_en": "COCORELI: Cooperative, Compositional Reconstitution \\& Execution of Language Instructions", "authors": "Swarnadeep Bhar,Omar Naim,Eleni Metheniti,Bastien Navarri,Loïc Cabannes,Morteza Ezzabady,Nicholas Asher", "background": "这篇论文的背景在于，大型语言模型（LLMs）在处理需要遵循复杂指令、减少幻觉以及进行空间推理的任务时存在局限性。作者希望通过引入一种混合代理框架COCORELI来克服这些局限。", "innovation": "COCORELI的创新点在于整合了中型LLM代理，并添加了新颖的抽象机制和话语模块，可以将指令解析为上下文学习动态的高阶环境表示。实验结果显示，COCORELI在自然协作建筑任务中表现出色，优于单一LLM的CoT和代理性LLM系统。此外，COCORELI的抽象能力还适用于其他场景，如ToolBench API完成任务。", "conclusion": "研究证明，COCORELI能够有效避免幻觉，识别缺失信息，请求澄清并更新学习对象。其抽象能力不仅局限于环境描述，还能应用于其他API任务完成场景。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04483", "html_url": "https://arxiv.org/abs/2509.04483", "title": "DecMetrics: 结构化论断分解评分以评估事实一致性的大规模语言模型输出", "title_en": "DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs", "authors": "Minghui Huang", "background": "论断分解在事实核查过程中发挥关键作用，通过将复杂的论断分解为更简单的原子组件并识别不实元素。然而，当前研究主要集中在生成方法的分解上，缺乏对分解后原子论断质量的评估。鉴于此，本文通过引入DecMetrics，提出了三种新指标：COMPLETENESS、CORRECTNESS 和 SEMANTIC ENTROPY，用于自动评估分解模型产出论断的质量。", "innovation": "本文的创新在于通过DecMetrics框架引入了三种新指标来评估论断分解模型的质量，并开发了一个轻量级的论断分解模型，通过将这些指标作为奖励函数来优化其性能。通过自动评估，该方法旨在为论断分解设定一个基准，提高事实核查系统的可靠性和有效性。", "conclusion": "本文通过提出DecMetrics框架，填补了论断分解质量评估上的空白，同时开发了一个轻量级的模型并通过自动评估设定了一种新的基准。这将有助于提高事实核查系统的整体效能和可靠性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04491", "html_url": "https://arxiv.org/abs/2509.04491", "title": "通过基于提示的弱监督训练改进字幕", "title_en": "Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR", "authors": "Xinnian Zhao,Hugo Van Hamme", "background": "尽管电视字幕容易获取，但由于其与音频的不精确对齐，限制了它们作为字幕转录监督目标的应用。传统的使用直接监督信号的方法受到限制，而该研究提出了一种新的方法，将字幕重新想象为上下文丰富的提示，从而使模型能够处理口语音频与字幕文本之间的不一致。", "innovation": "该研究提出了一种新的方法，通过基于提示的弱监督训练自动语音识别（ASR）框架，使用电视字幕作为上下文丰富的提示。通过重构成声文本作为主要目标，字幕作为迭代优化的引导线索。引入的加权注意力机制在推断过程中强调相关字幕令牌，从而提高转录准确性。", "conclusion": "实验结果表明，该方法显著提高了转录准确性，提供的增强伪标记数据集为训练鲁棒的ASR系统提供了高质量的基础资源。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04488", "html_url": "https://arxiv.org/abs/2509.04488", "title": "基于大型语言模型的多说话人口头信息排序提示语音识别", "title_en": "Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition", "authors": "Hao Shi,Yusuke Fujita,Tomoya Mizumoto,Lianbo Liu,Atsushi Kojima,Yui Sudo", "background": "现有的基于大型语言模型（LLM）的多说话人（MT）自动语音识别（ASR）系统要么省略提示，要么依赖简单的任务定义提示，此前没有研究探讨如何设计提示以提升性能。这项研究聚焦于通过提取序列化输出提示（SOP）并明确引导LLM使用结构化的提示来改进系统性能（SOP-MT-ASR），以提升多说话人口头信息分离和识别的精度。研究指出，尽管基于LLM的SOT模型在双说话人场景中表现良好，但在更复杂条件下，如三说话人场景，仍难以充分利用LLM的能力。", "innovation": "本文提出了序列化输出提示（SOP-MT-ASR）的方法，通过在语音编码器之后插入分隔器和序列化连接主义时序分类（CTC）层，以第一说话者先说话、先提取的方式分离和提取多说话人的语音内容。接着，通过贪婪搜索解码序列化CTC输出以获取SOP作为LLM的提示。此外，研究设计了三个阶段的训练策略：序列化输出训练（SOT）微调、序列化语音信息提取和SOP基于的适应性训练，以有效训练模型。这项研究显著提升了双说话人和三说话人情况下的识别性能，尤其是在复杂情况下，比基于LLM的SOT模型表现更佳。", "conclusion": "通过序列化输出提示，该研究改进了基于大型语言模型的多说话人口头信息识别系统的性能，尤其是在复杂场景中的表现得到显著提升。与现有的简单任务定义提示相比，结构化的序列化输出提示能够更有效地引导大型语言模型，从而提升识别性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04499", "html_url": "https://arxiv.org/abs/2509.04499", "title": "DeepTRACE: 审核深层研究AI系统以跟踪引文和证据的可靠性", "title_en": "DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence", "authors": "Pranav Narayanan Venkit,Philippe Laban,Yilun Zhou,Kung-Hsiang Huang,Yixin Mao,Chien-Sheng Wu", "background": "生成式搜索引擎和深度研究LLM代理承诺提供可信赖且基于来源的合成，但用户经常遇到过度自信、来源薄弱和混淆的引用方式。当前评估方法受到限制，难以全面评估这些系统的一致性和可靠性。因此，本文介绍了一个新的社会技术基础审计框架DeepTRACE，用于审计生成式搜索引擎和深度研究配置在回答文本、来源和引用方面的表现。", "innovation": "DeepTRACE是一个基于社会技术的方法审计体系，它将之前社区识别的失败案例转化为八个可衡量的维度，并通过陈述级分析（分解、信心评分）和构建引用和支持矩阵，全面评估系统如何使用和归因证据。DeepTRACE使用自动提取管道来评估多个流行公共模型（包括GPT-4.5/5，this http URL，Perplexity，Copilot/Bing，Gemini），并与一个验证过的人类评判一致性的人工智能裁判相结合，进行系统评估。", "conclusion": "研究发现，生成式搜索引擎和深度研究代理在辩论查询上经常产生片面而高度自信的回答，并包含大量没有来源支持的陈述。深度研究配置虽然减少了过度自信，但仍然在辩论查询上表现片面，并表现为大量没有支持的陈述，引用准确性范围在40%-80%之间。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04498", "html_url": "https://arxiv.org/abs/2509.04498", "title": "我在哪儿学习？语言模型在学术推荐中的偏见决策！评估学术推荐中LM的公平性", "title_en": "Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations", "authors": "Krithi Shailya,Akhilesh Kumar Mishra,Gokul S Krishnan,Balaraman Ravindran", "background": "大语言模型（LLMs）在日常生活中的推荐系统中越来越受欢迎，尤其是在教育规划等领域，但它们的推荐可能会延续社会偏见。本文通过实证研究，分析了三个开源LLMs（LLaMA-3.1-8B、Gemma-7B和Mistral-7B）在大学和专业建议方面的地理、人口统计和经济偏见。", "innovation": "本文提出了一种新的多维度评估框架，该框架超越了准确性，衡量了人口统计学和地理上的代表性。通过360个模拟用户配置文件（根据性别、国籍和经济状态变化），分析了超过25,000个建议结果，揭示了显著的偏见现象，提出了量化这些问题的方法。", "conclusion": "本文发现，教育LLMs中存在需要紧急考虑的偏见问题，以确保全球范围内对高等教育的公平准入。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04468", "html_url": "https://arxiv.org/abs/2509.04468", "title": "评估大型语言模型在金融推理中的应用：基于CFA的标准研究", "title_en": "Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study", "authors": "Xuan Yao,Qianteng Wang,Xinbo Liu,Ke-Wei Huang", "background": "大型语言模型(Large Language Models, LLMs)在金融应用中展现出巨大潜力，但它们在专业金融场景中的系统性评价仍然有限。", "innovation": "本研究首次使用1,560道来自CFA不同层级官方模拟题目的多项选择题，全面评估了当前最先进的LLMs。通过零样本提示和一种新的检索增强生成(Retrieval-Augmented Generation, RAG)管道，研究对比不同设计优先级的模型，并揭示了推理导向的模型在零样本设置中的优势，以及RAG管道在复杂情境下的显著改进。", "conclusion": "研究结果表明，在零样本设置中，推理导向的模型表现更为出色，而RAG管道在复杂场景中的表现尤为突出。全面的错误分析揭示了知识缺口是主要的问题点，而文本可读性的影响微乎其微。这些发现为LLM在金融领域的部署提供了切实可行的指导，帮助实践者根据模型选择和成本性能优化获得证据支持。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04472", "html_url": "https://arxiv.org/abs/2509.04472", "title": "RECAP: REwriting Conversations for Intent Understanding in Agentic Planning", "title_en": "RECAP: REwriting Conversations for Intent Understanding in Agentic Planning", "authors": "Kushan Mitra,Dan Zhang,Hannah Kim,Estevam Hruschka", "background": "理解用户意图对于有效规划对话助手至关重要，尤其是由大型语言模型（LLMs）协调多个代理的对话助手。然而，现实中的对话往往充满歧义、不明确或动态变化，使得意图检测一直是一个难题。传统基于分类的方法在开放环境中难以泛化，导致过于脆弱的解释和较差的后续规划。", "innovation": "提出了一种新的基准测试RECAP（REwriting Conversations for Agent Planning），旨在评估和推动意图重写，将用户-代理对话框重新构造成用户目标的简洁表示。RECAP捕捉到了多种挑战，如歧义、意图漂移、含糊性和混合目标对话。同时，引入了一个基于LLM的评估器，评估重写意图下的规划效用。利用RECAP，开发了一种基于提示的重写方法，优于基准，并展示了两种DPO基重写器微调的附加效用提升。", "conclusion": "结果显示，意图重写是改进开放域对话系统中代理规划的关键且可解决的组件。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04485", "html_url": "https://arxiv.org/abs/2509.04485", "title": "ASCENDgpt: 一种针对电子健康记录的心血管风险预测的表型感知变压器模型", "title_en": "ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records", "authors": "Chris Sainsbury,Andreas Karwath", "background": "本文介绍了ASCENDgpt，一种专门为从纵向电子健康记录（EHRs）预测心血管风险而设计的基于变压器的模型。该模型通过引入一种新颖的表型感知标记化方案，将47,155个原始ICD代码映射为176个临床有意义的表型标记，实现了诊断代码99.6%的合并同时保留了语义信息。这种方法还使模型词汇量从原始ICD代码的176个标记减少到10,442个标记，减少了77.9%。预先训练和微调过程使得该模型能够针对特定心血管疾病的风险进行有效预测。", "innovation": "ASCENDgpt 通过一种新颖的表型感知标记化方案将大量原始ICD代码减少为更具临床意义的表型标记；同时通过预先训练和针对特定心血管疾病的事件预测任务进行微调。该模型不仅提高了准确性和效率，而且保持了计算效率和临床解释性。", "conclusion": "本文展示了针对EHR的表型感知标记化和预训练在风险预测任务中的有效性，结果表明ASSENDgpt在整个心血管结局预测中具有良好的区分度，C-index达到了0.816，特别是在心肌梗死、中风、重大心血管事件、心血管死亡和全因死亡预测中表现出色（C-index 分别为0.792、0.824、0.800、0.842 和0.824）。该表型方法能够提供临床可解释的预测结果，同时保持计算效率。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04926", "html_url": "https://arxiv.org/abs/2509.04926", "title": "基于定性概念的对话的本体描述", "title_en": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "authors": "Barbara Gendron(LORIA, UL),Gaël Guibon(LIPN, LORIA),Mathieu D'aquin(LORIA, UL)", "background": "大型语言模型（LLMs）用作对话代理时的可控性是一个关键挑战，尤其是为了确保可预测性和个性化的用户回应。本研究提出了一种基于本体的方法，旨在正式定义通常具有定性特征的对话功能。通过利用一组语言描述符，本文推导出定性概念的定量定义，使其能够纳入本体进行推理和一致性检查。本文将此框架应用于对话水平控制的任务中，以 CEFR 语言能力等级为案例研究。这些定义随后被正式化为描述逻辑，纳入本体，指导LLM的微调以生成受控文本。", "innovation": "提出了一种基于本体的方法，通过使用一组语言描述符来推导出定性概念的定量定义。这种方法将这些概念纳入描述逻辑并创建本体，指导LLM的微调以实现可控性。研究使用CEFR语言能力等级作为案例研究，旨在通过对话的可控性提高对话AI的透明度。", "conclusion": "实验结果表明，该方法提供了符合水平的定义，使对话控制更加一致和可解释，从而提高对话AI的透明度。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04809", "html_url": "https://arxiv.org/abs/2509.04809", "title": "TalkToAgent: 使用大型语言模型的人本化强化学习代理解释", "title_en": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "authors": "Haechang Kim,Hao Chen,Can Li,Jong Min Lee", "background": "可解释的强化学习（XRL）作为提高强化学习（RL）代理透明度的一种有前途的方法已经出现。然而，由于XRL结果的可解释性有限，以及当前XRL方法孤立的特点，使得领域专家难以理解复杂的RL策略，用户也无法确定使用哪些工具。", "innovation": "我们引入了一个多代理大型语言模型（LLM）框架TalkToAgent，该框架能够提供交互式自然语言的RL策略解释。TalkToAgent通过五个专门的LLM代理（协调员、解释者、编码器、评估者和调试器），能够自动将用户查询映射到相关的XRL工具上，并清晰地解释代理的行为（包括关键状态变量、预期结果或反事实解释）。此外，该方法通过从定性的行为描述或新的基于规则的策略中推导出替代场景，进一步扩展了反事实解释。", "conclusion": "我们在四重水箱过程控制问题上的结果表明，TalkToAgent能够以高精度将用户查询映射到XRL任务，且编码-调试器的交互能够减少反事实生成的失败。此外，定性评价证实TalkToAgent能够有效地解释代理的行为，并在问题域内对这些行为的含义进行上下文化解读。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04492", "html_url": "https://arxiv.org/abs/2509.04492", "title": "基于 token 级 Entropy Production Rate 的黑盒大语言模型幻觉检测", "title_en": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate", "authors": "Charles Moslonka,Hicham Randrianarivo,Arthur Garnier,Emmanuel Malherbe", "background": "在问答任务中，大语言模型（LLM）输出的幻觉严重削弱了它们在现实世界中的可靠性。现有方法在数据访问有限的情况下（如使用黑盒LLM API时）很难实现高效的幻觉检测，因为这些API通常只提供少量每个token的 top 候选 log-probabilities。本文针对这类场景，提出了一种实用的一次性幻觉检测方法，可以直接从非贪婪解码过程中生成的log-probabilities中提取不确定性指标，而无需多次查询重跑。这种方法在多个问答数据集和大语言模型上进行了评估，显著提高了幻觉检测的性能，并证明了其在API受限部署场景中的实际效率和适用性。", "innovation": "提出了一种新颖的一次性幻觉检测方法，利用 token 级 Entropy Production Rate (EPR) 和监督学习相结合的方式，直接从黑盒 LLM 接口中获得的有限 log-probabilities 中提取不确定性指标。这种方法无需多次查询重跑，可以在单次生成过程中检测幻觉。该方法还通过使用典型的少量 log-probabilities (如每个 token 的 top <10) 实现了卓越的性能，证实了其在 API 约束部署场景中的实用性和适用性。", "conclusion": "本文提供了一种可部署的技术，用于增强问答和检索增强生成系统中大语言模型响应的可信度，只需一次生成过程即可。该技术方法还进一步展示了其在分析工业数据集的年度报告查询响应时的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04500", "html_url": "https://arxiv.org/abs/2509.04500", "title": "信任度的上下文工程：在混合和不适当上下文中基于Rescorla-Wagner的引导", "title_en": "Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts", "authors": "Rushi Wang,Jiateng Liu,Cheng Qian,Yifan Shen,Yanzhou Pan,Zhaozhuo Xu,Ahmed Abbasi,Heng Ji,Denghui Zhang", "background": "大型语言模型（LLMs）的响应质量可以通过整合外部上下文得到显著提升，但现实中的上下文常常包含相关和不相关内容，这可能会导致可靠性风险。研究发现，LLMs 在处理这种混合上下文时存在优先级分配问题，尤其是在现实环境中少量不适当内容可以显著降低响应质量。因此，研究旨在探讨 LLMs 如何处理这种混合上下文，并分析其优先级分配机制。", "innovation": "作者引入了一种称为混合上下文测试平台的工具，结合了相关和不相关内容的查询上下文，还提出了基于神经科学的Rescorla-Wagner (RW)模型以衡量上下文信号竞争对LLMs输出的影响。在此基础上提出的RW-Steering方法是一种双阶段微调方法，能够使模型内部识别并忽略不适当信号，提高了模型的可靠性和适应性，尤其是在不同比例不适当内容的上下文中具有强大的泛化能力。实验结果表明，优化后的模型极大地改善了响应质量，并逆转了不良行为曲线，证明RW-Steering是一个适用于提高LLMs在真实环境下使用的安全性的稳健通用上下文工程解决方案。", "conclusion": "研究通过提出RW-Steering模型，显著提高了LLMs在含不适当内容的混合上下文中的安全性和响应质量，并提出了一种有效的上下文工程方法来改善LLMs的安全性。此模型在不同比例的不适当内容上下文中展现出良好的泛化性能，解决了由于小量不适当内容可能导致的响应质量大幅下降的问题。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04515", "html_url": "https://arxiv.org/abs/2509.04515", "title": "通过模型解释缓解AI生成故事中的性别和族裔偏见", "title_en": "Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations", "authors": "Martha O. Dimgba,Sharon Oba,Ameeta Agrawal,Philippe J. Giabbanelli", "background": "语言模型在生成文本时会传播社会偏见，尤其是在性别和种族的表示上。这篇论文研究了AI生成的职业故事中性别和种族的偏见问题。通过分析不同职业领域、大型语言模型和多维度的人口统计特征，研究揭示了训练数据中的刻板印象导致的过度和不足代表现象。", "innovation": "论文提出了一种名为BAME（Biased Analysis and Mitigation through Explanation）的方法，利用模型生成的解释来指导有针对性的提示工程，从而有效减少偏见而无需更改模型参数。这种方法揭示了人口统计代表性提升2%至20%的改进。", "conclusion": "通过使用模型自身的推理机制来引导模型，可以显著提高人口统计平衡，从而推动更透明的生成式AI系统的开发。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04506", "html_url": "https://arxiv.org/abs/2509.04506", "title": "基于 memristor 的神经网络加速器在空间应用中的性能提升：通过时间平均和 SIRENs 增强", "title_en": "Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs", "authors": "Zacharia A. Rudge,Dominik Dold,Moritz Fieback,Dario Izzo,Said Hamdioui", "background": "Memristors 是一种新兴技术，能够为飞船上的 AI 加速器提供高能效和辐射鲁棒性。但是，空间应用需要可靠而精确的计算，而 memristive 设备存在器件变异性、传导漂移、器件故障等非理想特性，这使得将神经网络移植到 memristive 设备面临严重的性能下降挑战。", "innovation": "通过电路分割，神经网络层的时间平均和周期激活函数等方式，在 RRAM 设备上进行优化，初始结果从约 0.07 和 0.3 提升到 0.01 和 0.007，接近最先进的水平（0.003-0.005 和 0.003）。表明 memristors 在太空应用中的潜力，并且未来的技术和神经网络改进将有助于缩小性能差距，全面释放 memristors 的益处。", "conclusion": " memristors 的应用在太空任务中显示出巨大的潜力，在电路分割和时间平均等技术手段的辅助下，能实现与传统处理相近的性能，预示着它们在进行辐射敏感任务中的适用性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04501", "html_url": "https://arxiv.org/abs/2509.04501", "title": "理解模型训练中的强化学习及其GRAPE方法的未来方向", "title_en": "Understanding Reinforcement Learning for Model Training, and future directions with GRAPE", "authors": "Rohit Patel", "background": "该论文提供了从头开始对模型指令调优的关键算法的自包含阐述：SFT、拒绝采样、REINFORCE、信任区域策略优化（TRPO）、接近策略优化（PPO）、分组相对策略优化（GRPO）和直接偏好优化（DPO）。这些算法的解释常常假定读者已有先验知识，缺乏关键细节，或过于泛化和复杂。本文旨在通过简化和明确的记号将这些方法逐步讨论和发展，专注于语言模型（LLMs），以消除歧义、提供清晰且直观的理解。通过避免过多的广义强化学习文献讨论，并将概念与语言模型联系起来，本文减少了多余的抽象和认知负荷。", "innovation": "本文提出了一种简化和明确的记号，逐步解释了各种算法，确保每个步骤都清楚明了，并且直接聚焦于语言模型，以消除歧义和提供清晰理解。此外，本文还回顾了新的技术和方法，并提出了新的研究和探索思路，即通用相对优势策略进化（GRAPE）方法。", "conclusion": "本文首先详细介绍了多个与模型训练相关的先进算法，然后进行了广泛的文献回顾，并提出了一个新的方法论，即GRAPE，为未来的研究和发展指明了方向。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04504", "html_url": "https://arxiv.org/abs/2509.04504", "title": "大型语言模型的行为指纹分析", "title_en": "Behavioral Fingerprinting of Large Language Models", "authors": "Zehua Pei,Hui-Ling Zhen,Ying Zhang,Zhiyuan Yang,Xing Li,Xianzhi Yu,Mingxuan Yuan,Bei Yu", "background": "当前对大型语言模型（LLMs）的基准测试主要关注性能指标，往往未能捕捉到能够区分不同模型的细微行为特征。该论文提出了一个名为\"行为指纹\"的新型框架，旨在超越传统的评估方式，构建一个包含多方面特性的模型内在认知和互动风格的综合文件。该框架利用精心编排的诊断提示集合和创新的自动化评估流程，分析了十八个不同能力等级的模型。研究表明，在抽象和因果推理等核心能力方面，顶级模型正在趋同，而在对齐相关行为如奉承和语义鲁棒性方面则存在显著差异。这些研究结果揭示了在大型语言模型领域的重要分歧：虽然顶级模型在某些核心能力上趋于一致，但在对齐相关行为上却存在极大的差异性，这表明模型的互动性质与其规模或推理能力无关，而是特定且高度可变的开发人员对齐策略的结果。", "innovation": "该论文提出了一个名为\"行为指纹\"的新型框架，主要创新点包括：1. 利用精心编排的诊断提示集合进行评估；2. 利用创新的自动化评价流程；3. 揭示了模型的互动性质直接源于特定而高度可变的开发者对齐策略；4. 提供了可重复和可扩展的方法来揭示这些深层次的行为差异。", "conclusion": "该研究框架提供了一种可重复且可扩展的方法来揭示大型语言模型之间深层次的行为差异，这些差异不仅仅是模型规模或推理能力的衍生结果，而直接来自于特定的、高度可变的开发人员对齐策略。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04534", "html_url": "https://arxiv.org/abs/2509.04534", "title": "在生物医学自然语言处理中的量化大型语言模型：评估与推荐", "title_en": "Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation", "authors": "Zaifu Zhan,Shuang Zhou,Min Zeng,Kai Yu,Meijia Song,Xiaoyi Chen,Jun Wang,Yu Hou,Rui Zhang", "background": "大型语言模型在生物医学自然语言处理方面表现出色，但其迅速增长的规模和计算需求成为一个主要障碍，特别是在医疗保健环境中，因数据隐私问题无法采用云部署，并且资源有限。这些模型难以在计算资源受限的设备上运行.", "innovation": " systematic evaluation of the impact of quantization on 12 state-of-the-art large language models across eight benchmark datasets, demonstrating that quantization substantially reduces GPU memory requirements—with up to 75% reduction—while preserving model performance across diverse tasks, and maintaining domain-specific knowledge and responsiveness to advanced prompting methods.", "conclusion": "这些发现提供了重要的实用和指导价值，强调量化作为一种实用且有效的方法，能够在生物医学环境中实现安全的、本地的、大型且高容量语言模型的部署，缩小了AI技术进步与临床实用之间的差距."}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04507", "html_url": "https://arxiv.org/abs/2509.04507", "title": "从静默信号到自然语言：双阶段变换器-大语言模型方法", "title_en": "From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach", "authors": "Nithyashree Sivasubramaniam", "background": "静默语音接口（SSIs）因其能够从非声学信号生成可理解的语音而引起了关注。尽管在语音生成流水线方面取得了显著进展，但对于合成语音的识别和后续处理的研究相对有限，这些语音往往存在音素模糊和噪声问题。", "innovation": "本文提出了一种增强的自动语音识别框架，该框架结合了基于变换器的声音模型和大型语言模型（LLM）进行后处理。变换器能够捕捉整个语音单元的上下文，而LLM则确保语言一致性。实验结果表明，与36%的基线相比，这种方法在词错误率（WER）上相对减少了16%，绝对减少了6%，表明在静默语音接口的可理解性方面取得了重大改进。", "conclusion": "实验结果显示，结合变换器和大语言模型的方法在合成语音的识别和处理中显著提高了可理解性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04502", "html_url": "https://arxiv.org/abs/2509.04502", "title": "VaccineRAG: 提高多模态大语言模型对有害RAG样本免疫力", "title_en": "VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples", "authors": "Qixin Sun,Ziqin Wang,Hengyuan Zhao,Yilin Li,Kaiyou Song,Linjiang Huang,Xiaolin Hu,Qingpei Guo,Si Liu", "background": "RAG（检索增强生成）通过将检索和生成模块与外部知识结合，增强大语言模型（LLM）的响应准确性，尤其在实时查询和视觉问答任务中表现出色。然而，RAG的有效性经常受到检索器精度的限制：许多检索进入生成阶段的样本是无关或误导性的，这对LLM的表现构成了关键瓶颈。", "innovation": "1. ValveRAG是一个新颖的基于推理链的检索增强生成数据集，用于评估模型对不同正负样本比例数据的性能，全面揭示当前LLM的内在弱点。\n2. 提出了增强模型样本区分能力的方法，通过促使LLM为每个样本生成显式的推理链（CoT）分析后再生成最终答案。\n3. 引入了Partial-GRPO模型，通过将LLM的输出建模为多个组件而不是单一整体，能够更好地理解和学习复杂的推理链内容。", "conclusion": "在VaccineRAG上进行的全面评估和消融研究证实了所提出方案的有效性。该模型代码和数据集将很快公开。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04544", "html_url": "https://arxiv.org/abs/2509.04544", "title": "i-Mask: 智能呼吸驱动活动识别口罩", "title_en": "i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition", "authors": "Ashutosh Kumar Sinha,Ayush Patel,Mitul Dudhat,Pritam Anand,Rahul Mishra", "background": "吸入和呼出的模式包含重要的生理信号，可用于预测人类行为、健康趋势和生命体征。活动识别（HAR）与这些生命体征紧密相关，能够提供更深入的身体状况洞察，并实现实时健康监测。", "innovation": "i-Mask是一种创新的HAR方法，利用内置传感器的定制口罩捕捉呼出的呼吸模式。数据经过噪声过滤、时间序列分解和标记，用于训练预测模型。", "conclusion": "实验结果验证了该方法的有效性，准确率超过95%，强调了其在医疗保健和健身应用中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04549", "html_url": "https://arxiv.org/abs/2509.04549", "title": "基于变换器模型的操纵：可控性、导向性和鲁棒干预", "title_en": "Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions", "authors": "Faruk Alpay,Taylan Alpay", "background": "变换器模型在NLP任务中表现出色，但细微控制仍然具有挑战性。本文探讨了通过三个层面的原则干预（提示、激活和权重）来操纵变换器模型的方法。将可控文本生成形式化为可通过提示工程、参数高效微调、模型编辑和技术化学习解决的优化问题。研究表明，最小权重更新可以实现所需的行为改变，同时最大限度地减少副作用。", "innovation": "本文提出了一种统一框架，包括提示层级引导、激活干预和权重空间编辑。理论上证明了通过少量权重更新可以实现所需的行为改变，同时减少副作用。实证结果显示，在保持基线性能的同时，可以实现超过90%的情绪控制和事实编辑的成功率，尽管存在泛化特定性折中。讨论了伦理和双重用途风险以及严格的评估需求。这项工作为设计可控和鲁棒的语言模型奠定了基础。", "conclusion": "本文工作为设计可控和鲁棒的语言模型奠定了基础，探讨了通过多层次原则干预改变变换器模型的方法，分析了稳健性和安全性的影响，展示了通过少量权重更新实现所需行为改变并减少副作用的理论证明和实验证据。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04537", "html_url": "https://arxiv.org/abs/2509.04537", "title": "LLM代理在El Farol酒吧问题中的涌现社会动态", "title_en": "Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem", "authors": "Ryosuke Takata,Atsushi Masumori,Takashi Ikegammi", "background": "研究了大型语言模型（LLM）代理在延伸型El Farol酒吧问题中的社会动态，观察他们在经典社会困境中的自主导航行为。这些代理自发地产生了去酒吧的动力，并转变了决策方式，表现出集体行为特征。研究还发现，虽然代理没有完全解决该问题，但行为方式更接近人类。", "innovation": "揭示了外部激励（预设提示中的60%阈值等约束）与内部激励（预训练中文化编码的社会偏好）之间的复杂相互作用，证明了LLM代理自然地平衡了正式博弈理性与指导人类行为的社会动机。这项发现表明，可以利用LLM代理实现以前博弈论问题设置无法处理的群体决策新模型。", "conclusion": "研究不仅展示了LLM代理在面对复杂社会问题时的独特行为特征，还揭示了其在解决群体决策问题中的潜力。同时，这表明LLM代理可以结合形式博弈理性与社交动机，为研究和应用方面提供了新的视角。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04601", "html_url": "https://arxiv.org/abs/2509.04601", "title": "量子增强的具有可学习权重的多任务学习在药代动力学和毒性预测中的应用", "title_en": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction", "authors": "Han Zhang,Fengji Ma,Jiamin Su,Xinyue Yang,Lei Wang,Wen-Cai Ye,Li Liu", "background": "在药物发现和开发中，预测ADMET特性（吸收、分布、代谢、排泄和毒性）起着至关重要的作用，能够加速新药物的筛选和优化。现有方法主要依赖于单任务学习（STL），但这种学习方式往往无法充分利用不同任务间的互补性，并且每个任务的训练和推理需要更多的计算资源。为了解决这些问题，本文提出了一个名为QW-MTL的全新统一的量子增强和任务加权多任务学习框架，专门用于ADMET分类任务。该框架基于Chemprop-RDKit骨架，通过引入量子化学描述符来丰富分子表示，并结合数据集规模先验与可学习参数，提出了新颖的指数任务加权方案，实现跨任务动态损失平衡。这被认为是首项系统地在所有13个Therapeutics Data Commons（TDC）分类基准上开展联合多任务训练的工作，确保标准化和实际的评估环境。实验结果表明，QW-MTL在12个任务上显著优于单任务基线，实现了高预测性能、低模型复杂度和快速推理，证明了量子启发特征和自适应任务加权的多任务分子学习的有效性和效率。", "innovation": "提出了QW-MTL架构（量子增强和任务加权多任务学习），使用量子化学描述符增强了分子表示，引入了指数任务加权方案来实现跨任务动态损失平衡，该模型在标准化和现实的评估环境中系统地在13个TDC分类基准上开展了联合多任务训练，显著优于单任务基线。该框架通过量子信息增加了分子描述的丰富性，有效解决了单任务学习无法充分利用任务间互补性的问题，并使用自适应任务加权提高了模型性能和效率。", "conclusion": "通过QW-MTL架构，本文展示了如何有效结合量子信息以丰富分子描述，在药代动力学和毒性预测中实现更好的性能，同时保持模型复杂度较低和推理快速。该方法在多个基准测试中取得了显著的成果，证明了量子增强多任务学习在分子科学中的潜在应用和优势。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04628", "html_url": "https://arxiv.org/abs/2509.04628", "title": "基于Transformer的动作分割在基于图像的空间探测器导航与控制中的应用", "title_en": "Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control", "authors": "Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares", "background": "该研究针对从有限数据中实现高空间探测器导航、制导与控制（GNC）性能的需求。背景是目前在有限数据下实现高精度控制仍然是一个挑战，尤其是在空间探测器的导航任务中，需要在高精确度和样本效率之间找到平衡。现有的方法，如元强化学习（meta-RL），虽然有效，但所需的环境交互次数较大，这在实际应用中可能不可行或成本较高。", "innovation": "本研究提出了一种基于模仿学习的动作分割与Transformer结合的方法（ACT），能用仅有100次专家演示（对应约6,300次环境交互）的数据实现高精度的控制策略。该方法生成的轨迹比4000万次环境交互训练的元强化学习基线更加平滑且一致。研究在空间交会对接任务中验证了该方法的有效性，展示了ACT的高精度、平滑控制和更高的样本效率。", "conclusion": "综合而言，本研究开发的基于模仿学习的动作分割与Transformer结合的方法（ACT）能够在有限的数据下生成高精度且平滑的控制策略，验证了在空间探测器的在轨对接任务中的高效率和高准确性。未来的工作可以进一步优化该方法以实现更高的性能和更广的应用范围。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04535", "html_url": "https://arxiv.org/abs/2509.04535", "title": "基于跨域技能扩散的在上下文策略适应", "title_en": "In-Context Policy Adaptation via Cross-Domain Skill Diffusion", "authors": "Minjong Yoo,Woo Kyung Kim,Honguk Woo", "background": "本文研究了一种称为基于上下文策略适应（ICPAD）的框架，用于长视线多任务环境中的策略适应问题。该框架旨在探索在不更新模型且仅限于有限目标域数据的情况下，如何快速适应基于技能的强化学习策略。背景包括在复杂环境中，如何通过网络或平台使用不同领域中的技能以实现任务适应。", "innovation": "提出了一种跨域技能扩散方案，将领域无关的原型技能和领域相关的技能适配器结合，通过跨领域的统一扩散过程共同学习。此外，还提出了一种动态领域提示方案，以引导基于扩散的技能适配器更好地与目标领域对齐。", "conclusion": "通过在Metaworld的机器人 manipulation 和CARLA的自主驾驶环境中的实验，证明了我们的方案在不同领域配置的情况下，当仅有有限目标领域数据时，可以实现卓越的策略适应性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04653", "html_url": "https://arxiv.org/abs/2509.04653", "title": "将变压器架构解释为隐式多项式回归", "title_en": "Interpreting Transformer Architectures as Implicit Multinomial Regression", "authors": "Jonas A. Actor,Anthony Gruber,Eric C. Cyr", "background": "机制可解释性旨在理解现代机器学习模型内部组件，如权重、激活和层，如何导致模型的整体行为。注意力机制是一个特别晦涩的机制：尽管它在变压器模型中扮演着中心角色，但其数学基础与其与特征多义性、叠加以及模型性能的关系仍不甚清楚。", "innovation": "论文建立了一种新颖的注意力机制与多项式回归之间的联系。具体来说，在固定多项式回归设置中，通过优化潜在特征可以获得与注意力块诱导的动力学一致的最佳解。换句话说，通过变压器中表现形式的演变可以解释为一种轨迹，该轨迹可以恢复分类的最佳特征。", "conclusion": "这项工作为理解变压器中注意力机制提供了新的思路，并通过将注意力机制与多项式回归联系起来，增强了对变压器模型整体行为的理解。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04622", "html_url": "https://arxiv.org/abs/2509.04622", "title": "测量测量：模型家族中表示相似性度量的区分能力", "title_en": "Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families", "authors": "Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla", "background": "表示相似性度量是神经科学和人工智能中的基础工具，但尚未对不同模型家族（如CNN、Vision Transformers、Swin Transformers、ConvNeXt）和训练机制（监督 vs 自监督）中的区分能力进行系统比较。本文介绍了一种定量框架，基于模型家族分离能力评估表示相似性度量。", "innovation": "引入了一种基于模型家族分离能力的定量框架来评估表示相似性度量；系统地评估了RSA、线性预测性、Procrustes 和软匹配等常用度量的区分能力；发现随着度量施加更严格的对齐约束，分离能力系统地增加；软匹配在映射方法中达到最高分离能力，其次是Procrustes对齐和线性预测性；非拟合方法如RSA在家族间也表现出强大的分离能力。", "conclusion": "这是第一次从分离性的角度系统比较相似性度量，澄清了它们的相对敏感性，为大规模模型和大脑对比选择度量指标提供了指导。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04632", "html_url": "https://arxiv.org/abs/2509.04632", "title": "使用大型语言模型进行表格数据仓库的模式推理", "title_en": "Schema Inference for Tabular Data Repositories Using Large Language Models", "authors": "Zhenyu Wu,Jiaoyan Chen,Norman W. Paton", "background": "现有的表格数据往往在异构来源之间存在表示不一致，并且伴随着稀疏的元数据。这种数据在处理时让人感到棘手。尽管已有工作推进了数据集的发现和探索，但在元数据有限的情况下，模式推断仍然具有挑战性。", "innovation": "我们提出了SI-LLM（基于大型语言模型的模式推断），该方法仅使用列标题和单元格值来推断表格数据的简洁概念模式。推断出的模式包括分层实体类型、属性和类型间的关系。SI-LLM 在对两个来自网络表格和开放数据集的广泛评估中，取得了令人鼓舞的整体结果，并且与最先进的方法相比，在每一步上也表现出更好的或可比的结果。", "conclusion": "SI-LLM的所有源代码、完整提示和数据集都可在以下网址获取：this https URL."}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04606", "html_url": "https://arxiv.org/abs/2509.04606", "title": "新模态高效集成到大规模语言模型中", "title_en": "Sample-efficient Integration of New Modalities into Large Language Models", "authors": "Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti", "background": "多模态基础模型能够处理多种模态。然而，由于可能存在的模态空间庞大且不断变化，从零开始训练模型以涵盖所有模态是不可行的。此外，将模态集成到现有的基础模型中需要大量的配对数据，这对于资源有限的模态来说往往不可获得。研究背景是解决这些问题，提出了一种样本高效的模态集成方法（SEMI）到大规模语言模型（LLMs）中。", "innovation": "该研究提出了一种超网络，能够根据任意模态的少量样本适应共享投影器，该投影器位于特定模态编码器和大规模语言模型之间。该超网络在高资源模态（如文本、语音、音频、视频）上进行训练，并在推理过程中根据不同模态进行条件化以生成适当的适配器。为增加训练模态的多样性，通过等距变换增加了编码器的数量。研究发现，SEMI在新模态（如卫星图像、天文图像、惯性测量和分子）的少量样本集成中表现显著提升，尤其是在投影器具有任意嵌入维度的情况下。通过与32-shot SEMI进行比较，无SEMI需要64倍以上的数据才能达到相同准确性。", "conclusion": "SEMI有望扩大基础模型的模态覆盖率，提高对新模态的集成效率。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04633", "html_url": "https://arxiv.org/abs/2509.04633", "title": "使用大型语言模型自动生成设计并基于可塑性进行评估的器官组织体人工智能环境扩展", "title_en": "Scaling Environments for Organoid Intelligence with LLM-Automated Design and Plasticity-Based Evaluation", "authors": "Brennen Hill", "background": "随着人工代理复杂性的增加，设计能够有效地塑造其行为和能力的环境已成为关键的研究前沿。本文将这一原则扩展到一种新型代理：神经器官组织形式的生物神经网络。", "innovation": "本文提出了一个框架，设计了三个可扩展的闭环虚拟环境，用于训练基于器官组织体的生物代理，并探索学习机制（包括长期增强和长期抑制）。引入了一种新的元学习方法，利用大型语言模型（LLM）自动化实验协议的生成和优化。还提出了多模态的方法来评估学习，通过电生理学、细胞学和分子学层面的突触可塑性来衡量。", "conclusion": "该研究填补了计算神经科学与基于代理的人工智能之间的空白，提供了一个独特的平台，用于在受控的生物基质中研究实体性、学习和智能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04482", "html_url": "https://arxiv.org/abs/2509.04482", "title": "能量景观使可靠性弃权成为医疗保健中检索增强大型语言模型的核心", "title_en": "Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare", "authors": "Ravi Shankar,Sheng Wong,Lin Li,Magdalena Bachmann,Alex Silverthorne,Beth Albert,Gabriel Davis Jones", "background": "可靠的弃权对于检索增强生成（RAG）系统至关重要，特别是在医疗保健等安全关键领域，如女性健康，错误的答案可能导致伤害。在这些领域中，系统需要在生成答案或弃权之间做出明智的决定。", "innovation": "该论文提出了一种基于能量的模型（EBM），该模型通过学习一个平滑的能量景观来处理一个密集的语义语料库（包含2.6M个指南衍生问题），从而帮助系统决定何时生成答案或弃权。该模型与校准后的softmax基线和k近邻密度启发式方法（kNN）进行对比测试。在处理语义难题时，EBM的弃权性能优于softmax模型，并且最大限度地减少了错误的阈下率。", "conclusion": "研究结果表明，基于能量的弃权评分比基于概率的softmax置信度提供更可靠的置信信号。这为安全的RAG系统提供了一个可扩展且可解释的基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04669", "html_url": "https://arxiv.org/abs/2509.04669", "title": "VCMamba: 结合多方向Mamba实现高效视觉表示", "title_en": "VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation", "authors": "Mustafa Munir,Alex Zhang,Radu Marculescu", "background": "最近，Vision Transformers (ViTs) 和 State Space Models (SSMs) 如 Mamba 的发展，挑战了卷积神经网络（CNNs）在计算机视觉领域的主导地位。虽然 ViTs 擅长捕捉全局上下文，且 Mamba 等 SSM 提供了建模长序列的线性效率，但它们在捕捉细粒度局部特征方面不如 CNNs。相比之下，CNNs 对局部特征具有很强的归纳偏置，但缺乏 ViTs 和 Mamba 所提供的全局推理能力。为了弥合这一差距，本文提出了一种名为 VCMamba 的新型视觉骨干网，它结合了 CNNs 和多方向 Mamba SSM 的优点。", "innovation": "VCMamba 采用了一种新颖的设计，它在早期阶段使用卷积层提取丰富的局部特征，然后通过后期的多方向 Mamba 块来高效地建模长范围依赖关系和全局上下文。这种混合设计使得 VCMamba 能够实现优越的特征表示并保持与图像分辨率相关的线性复杂度。", "conclusion": "通过在 ImageNet-1K 分类和 ADE20K 语义分割上的大量实验，本文展示了 VCMamba 的有效性。VCMamba-B 在 ImageNet-1K 上达到 82.6% 的 top-1 准确率，比 PlainMamba-L3 优 0.3%，且参数量少了 37%；同时比 Vision GNN-B 优 0.3%，且参数量少了 64%。此外，VCMamba-B 在 ADE20K 上的 mIoU 达到 47.1，比 EfficientFormer-L7 高 2.0 mIoU，而参数量少了 62%。代码可在相应链接处获得。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04682", "html_url": "https://arxiv.org/abs/2509.04682", "title": "生态有效基准测试与自适应注意力：扩展性的海洋生物声学监测", "title_en": "Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring", "authors": "Nicholas R. Rasmussen,Rodrigue Rizk,Longwei Wang,KC Santosh", "background": "被动声学水下监测（UPAM）提供了大量的时空数据，有助于长期生态分析，但固有的噪声和复杂的信号依赖性阻碍了模型的稳定性和泛化能力。尽管多层窗口法提高了目标声音定位，但环境噪声变化、传播效应多样性及生物与人工源混合等变数要求更加稳健的架构和严格的评估。", "innovation": "介绍了GetNetUPAM，这是一种分层嵌套交叉验证框架，旨在在具有生态现实变数的情况下量化模型稳定性。数据被分割为不同的站点年份段，确保每段验证折都反映了独特的环境子集，减少了对局部噪声和传感器特征的过度拟合。GetNetUPAM同时也将站点年份阻塞与随机子集的标准交叉验证相结合，以衡量模型在UPAM全信号分布上的泛化能力。在此基础上，提出了自适应分辨率池化与注意力网络（ARPA-N），该神经架构适用于不规则频谱图维度，通过空间注意力实现自适应池化并捕捉全局语境。", "conclusion": "使用GetNetUPAM作为评估基石，在ARPA-N架构下，平均精度提高了14.4%，所有评估指标的变异性下降了两个数量级的对数尺度，从而实现了站点年份各折间的持续检测，并推动了可扩展和精确的生物声学监测的前进。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04696", "html_url": "https://arxiv.org/abs/2509.04696", "title": "ODKE+: 基于本体引导的LLM开放域知识提取", "title_en": "ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs", "authors": "Samira Khorshidi,Azadeh Nikfarjam,Suprita Shankar,Yisi Sang,Yash Govind,Hyun Jang,Ali Kasgari,Alexis McClimans,Mohamed Soliman,Vishnu Konda,Ahmed Fakhry,Xiaoguang Qi", "background": "知识图谱(KGs)在许多AI应用中是基础，但是保持其新鲜性和完整性仍然很昂贵。现有的知识图谱维护方法成本高并且效率低，因此需要一种自动高效的方式来提取和整合开放领域中的知识，并且能够保持高精度。这篇论文提出了一种名为ODKE+的生产级系统，可以自动从网络源中提取和导入数百万条开放领域的事实，并且具有高精度。", "innovation": "ODKE+系统结合了模块化的组件，形成可扩展的流水线，包括：(1) 提取发起者，检测缺失或过时的事实；(2) 证据收集器，收集支持性文档；(3) 混合知识提取器，结合模式规则和本体引导的大语言模型提示；(4) 轻量级的深化验证器，使用第二个大语言模型验证提取的事实；(5) 证实器，对候选事实进行排名和规范化以便于导入。此外，ODKE+能够动态生成针对每个实体类型的本体片段，从而确保了抽取事实与模式限制的一致性，实现了覆盖195个谓词的高效、类型一致的抽取。该系统支持批量处理和流处理模式，能够处理超过900万个维基百科页面，并能够并导入1900万个高置信度的事实，精度达到98.8%。", "conclusion": "ODKE+显著提高了覆盖范围，与传统的知识图谱生成方法相比，它与第三方知识图谱的重叠度提高了48%，并且将更新滞后时间减少了50天。此系统展示了基于本体的大语言模型知识提取具有可靠性，并且可以在实际生产环境中大规模用于多种实际情况。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04497", "html_url": "https://arxiv.org/abs/2509.04497", "title": "以叙述为导向的临床医师倦怠监测计算框架", "title_en": "A Narrative-Driven Computational Framework for Clinician Burnout Surveillance", "authors": "Syed Ahmad Chan Bukhari,Fazel Keshtkar,Alyssa Meczkowska", "background": "医务人员倦怠对病人安全构成重大威胁，特别是在重症监护室（ICU）这样的高急症环境中。现有的研究主要依靠回顾性调查工具或广泛的电子健康记录（EHR）元数据，往往忽视了嵌入在临床笔记中的有价值叙述信息。", "innovation": "研究引入了一个结合BioBERT情感嵌入、针对临床医生倦怠监控量身定制的词级压力词典以及五主题潜在狄利克雷分配（LDA）和工作量代理的混合管道。提供商级别的逻辑回归分类器在分层持有集中达到了高精度（0.80）、召回率（0.89）和F1分数（0.84），且F1分数比元数据基线高至少0.17。针对专科的分析表明，在放射学、精神病学和神经学等专业中，倦怠风险较高。研究结果表明，ICU临床笔记包含前瞻性和应对心理健康监测的操作信号。", "conclusion": "ICU临床笔记含有调节性和可采取措施来积极监测医生健康状况的行动信号。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04733", "html_url": "https://arxiv.org/abs/2509.04733", "title": "CoVeR: 符合变通性和可靠性的自回归下一个词预测的校准", "title_en": "CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction", "authors": "Yuzhu Chen,Yingjie Wang,Shunyu Liu,Yongcheng Jing,Dacheng Tao", "background": "自回归预训练模型与解码方法结合在复杂的推理任务中取得了显著的成果。主流的解码策略，如束搜索，能够生成合乎情理的候选集，但往往缺乏可验证的覆盖率保证，并且难以在搜索效率和多变轨迹的需求之间取得平衡，尤其是那些涉及到在某些真实世界应用中至关重要的长尾序列的轨迹方面。", "innovation": "提出了CoVeR，一种基于校准预测框架的新型无模型解码策略，能够在保持紧凑搜索空间的同时，确保对理想轨迹的高覆盖率概率。理论上建立了PAC类型的一般化界限，保证了CoVeR在任何目标水平 $\textalpha \textt{∈ (0,1)}$ 下实现至少 $\text 1 - \textalpha$ 的覆盖率率。", "conclusion": "CoVeR同时维持了紧凑的搜索空间并确保了对优点轨迹的高覆盖率概率，理论上证明了这一策略在覆盖率方面的渐近表现。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04650", "html_url": "https://arxiv.org/abs/2509.04650", "title": "在灾难推特分类中基于Transformer模型的比较分析", "title_en": "Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety", "authors": "Sharif Noor Zisad,Ragib Hasan", "background": "社交媒体平台，尤其是Twitter，在灾害和公共安全紧急事件中已成为实时信息的重要来源。自动分类与灾害相关的推文有助于应急服务更快更好地响应。传统的机器学习模型如逻辑回归、朴素贝叶斯和支持向量机被广泛使用，但由于这些模型无法理解语境或更深层的意义，尤其是在语言非正式、比喻或模糊的情况下，其表现往往不佳。", "innovation": "本文假设基于Transformer的模型在处理此类任务时优于传统的机器学习模型。研究对比了包括BERT、DistilBERT、RoBERTa和DeBERTa在内的各种Transformer模型在灾害相关推文分类中的效果，证明了这些模型在准确性和语言理解上的优越性，特别是在处理微妙语言方面。", "conclusion": "实验结果表明，BERT的准确率达到最高（91%），显著优于传统的逻辑回归和朴素贝叶斯模型（均为82%）。这表明基于Transformer的架构在公共安全应用中更适用，提供了更高的准确性和更好的泛化能力，能够更好地理解社交媒体文本中的微妙语言。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04655", "html_url": "https://arxiv.org/abs/2509.04655", "title": "多义性Dropout：特化大语言模型的可靠的Out-of-Domain检测", "title_en": "Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs", "authors": "Ayush Gupta,Ramneet Kaur,Anirban Roy,Adam D. Cobb,Rama Chellappa,Susmit Jha", "background": "尽管特化大语言模型（LLMs）通过微调在领域内任务上达到了最先进的性能，但在面对领域外（OOD）输入时，这些模型仍易产生错误或不可靠的输出，存在在关键应用中带来风险的可能性。因此，研究如何在推理阶段检测特化LLMs的OOD输入非常重要。目前的方法存在在OOD检测性能上的局限性，本文提出了一种新的基于Inductive Conformal Anomaly Detection（ICAD）框架的OOD检测算法，该算法结合了一种新的基于模型Dropout容忍度的新非一致性度量，以区分领域内和领域外输入的表现差异，从而提高了检测准确性，同时保持了ICAD的理论假警报边界。研究表明，该方法能显著提高特化LLMs的OOD检测性能，即在将OOD数据点视为正例和领域内测试数据点作为负例的情况下，AUROC提升了2%到37%.", "innovation": "本文提出了一种新的OOD检测算法，基于ICAD框架，使用基于模型Dropout容忍度的新非一致性度量。算法结合了多个层的Dropout容忍度，通过有效的集成方法提高检测效果，同时保持理论假警报边界。该方法特别针对特化LLMs，提出了利用Dropout容忍度差异来区分领域内外输入的新思路。", "conclusion": "实验结果表明，本文提出的方法在特化LLMs的OOD检测上表现优越，与基线方法相比，AUROC提高了2%到37%，特别是在将OOD数据点视为正例和领域内测试数据点作为负例的情况下。这表明该方法对特化的LLMs具有很好的适用性和可靠性，能够有效提升OOD检测的性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04712", "html_url": "https://arxiv.org/abs/2509.04712", "title": "使用亚优策略来提升强化学习在自主驾驶中的表现", "title_en": "Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving", "authors": "Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill", "background": "自动车辆控制利用强化学习（RL）由于它有可能通过环境交互学习到驾驶策略而受到广泛关注。然而，RL代理在样本效率和有效的探索方面常常面临训练挑战，使得发现最佳驾驶策略变得困难。", "innovation": "该研究提出了一种使用亚优策略引导RL驾驶代理的方法，无需该策略是高度优化或专家级控制器。具体来说，将基于规则的变道控制器与柔和的行动评论者（Soft Actor Critic，SAC）算法集成，以增强探索和学习效率。这种方法展示了提高的驾驶性能，并可以扩展到其他可以从中受益的驾驶场景。", "conclusion": "该方法表现出改进的驾驶性能，并且可以扩展到其他可通过示范指导获益的驾驶场景。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04735", "html_url": "https://arxiv.org/abs/2509.04735", "title": "增强自驾车在恶劣天气条件下的分割：SAM优化的双重不确定性感知训练方法", "title_en": "Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization", "authors": "Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu", "background": "近年来，例如Segment Anything Model (SAM)及其后续版本SAM2在通用图像分割基准测试上已达到最先进的性能。然而，这些模型在高视觉模糊的恶劣天气条件下表现不佳，主要原因是缺乏不确定性量化。", "innovation": "受医学影像中不确定性感知训练提高复杂情况可靠性的进步启发，该研究提出了两种增强自驾车路段分割鲁棒性的方法。首先，引入了SAM2的多步微调程序，直接将不确定性指标纳入损失函数，从而改进整体场景识别；其次，将原用于医学图像分割的Uncertainty-Aware Adapter (UAT)适配到驾驶场景中。在CamVid、BDD100K和GTA驾驶数据集上进行了评估，实验证明UAT-SAM在极端天气条件下优于标准SAM，而SAM2结合不确定性感知损失则能在多种驾驶情境中取得更好的性能。", "conclusion": "这些结果显示，明确的不确定性建模对于在具有挑战性的环境中确保自主驾驶的安全性和鲁棒性具有重要价值。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04716", "html_url": "https://arxiv.org/abs/2509.04716", "title": "KERAG: 知识增强的检索增强生成以实现高级问答", "title_en": "KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering", "authors": "Yushi Sun,Kai Sun,Yifan Ethan Xu,Xiao Yang,Xin Luna Dong,Nan Tang,Lei Chen", "background": "传统的知识图谱问答（KGQA）方法依赖于语义解析，通常只能检索严格必要的知识来生成答案。这种方法因严格的模式要求和语义模糊性，往往导致覆盖范围较低。大语言模型（LLMs）会产生幻觉，通过引入外部数据，检索增强生成（RAG）方法可以缓解这一问题，其中知识图谱（KGs）提供关键信息用于问答。", "innovation": "本文提出了一种新的基于知识图谱的RAG（KERAG）流水线，通过检索更广泛的子图来扩大问题回答的覆盖范围。通过检索、过滤、总结方法，并结合针对知识子图的链式思考推理微调过的LLMs，减少了噪声并提高了对简单和复杂问题的回答质量。实验表明，KERAG的质量超过最先进的解决方案约7%，并且超越了GPT-4o（工具）10-21%.", "conclusion": "研究表明，通过改进的检索策略和微调的LLMs，KERAG能够在问答任务中提供更准确和全面的答案，特别是在处理复杂问题时展现出显著优势。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04757", "html_url": "https://arxiv.org/abs/2509.04757", "title": "Mcanet：基于UAV影像的多标签飓风灾后损伤评估的多尺度分类特定注意力网络", "title_en": "MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "快速准确的飓风灾后损伤评估对于灾难响应和恢复至关重要。现有的基于CNN的方法难以捕捉多尺度空间特征，并区分视觉上相似或同时出现的损伤类型。", "innovation": "我们提出了MCANet，一种多标签分类框架，能够学习多尺度表征并自适应地关注每个损伤类别的空间相关区域。MCANet采用了基于Res2Net的分层骨干网络，以丰富不同尺度的空间上下文，并配备了多头类别特定的残差注意力模块来增强区分能力。每个注意力分支专注于不同的空间粒度，平衡局部细节与全局上下文。", "conclusion": "MCANet在飓风迈克尔灾后收集的4,494张UAV图像的RescueNet数据集上进行了评估，获得平均平均精度（mAP）为91.75%，超越了ResNet、Res2Net、VGG、MobileNet、EfficientNet和ViT模型。使用八个注意力头时，性能进一步提高至92.35%，特别是在道路堵塞等挑战类别的平均精度上提高了6%以上。损坏激活映射证实了MCANet能够定位损伤相关区域，支持可解释性。MCANet的输出可用于灾后风险图绘制、紧急路线规划以及基于数字孪生的灾难响应。未来工作可以整合灾害特定知识图和多模态大规模语言模型，以提高应对未知灾害的能力，并丰富现实世界决策中的语义理解。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04779", "html_url": "https://arxiv.org/abs/2509.04779", "title": "解码器笑声如编码器般响亮", "title_en": "Decoders Laugh as Loud as Encoders", "authors": "Eli Borodach,Raj Dandekar,Rajat Dandekar,Sreedath Panat", "background": "从计算机的诞生之初，艾伦·图灵就梦想着能够用语言进行人类般交流的机器人。近年来，在大型语言模型（LLMs）的领域中，一个单一模型能够应用于多种自然语言处理（NLP）任务，并且其输出有时甚至超过大多数人的交流技巧。诸如GPT、Claude、Grok等模型在科学界留下了深刻的印记。然而，尚不清楚这些模型对它们所生成的内容理解程度如何，尤其是在像幽默这样微妙的主题上。关于计算机是否理解幽默的问题仍然没有定论（最新的验证模型为GPT-2）。", "innovation": "本文探讨了计算机解码器是否能够理解幽默的问题。通过训练解码器（GPT-4o），并将其与最佳训练编码器（RoBERTa）进行比较，证明了解码器在F1-宏平均分数上达到了0.85，与编码器（F1平均分数0.86）表现相近。这一发现表明，解码器在处理幽默等复杂问题上可能具有较高的理解能力，推动了LLMs在复杂主题理解上的进展。", "conclusion": "本文的研究结果显示，经过微调的解码器（GPT-4o）在幽默理解方面表现出与最佳微调编码器（RoBERTa）相匹敌的能力，取得的F1-宏平均分数为0.85。这证明了解码器在处理幽默等复杂话题时具有强大的理解和生成能力，为LLMs的研究打开了新的视角。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04772", "html_url": "https://arxiv.org/abs/2509.04772", "title": "FloodVision: 基于基础视觉-语言模型和领域知识图的城市洪水水深估计", "title_en": "FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "及时和准确的洪水水位估计对于道路通行能力和紧急响应至关重要。尽管近年来计算机视觉方法已经能够检测洪水，但这些方法存在准确性和泛化能力较差的问题，主要原因是依赖固定对象检测器和任务特定训练。因此，迫切需要一种能够泛化到多种洪水场景的高精度水位估计方法。", "innovation": "本文提出了FloodVision，一个无监督框架，将基础视觉-语言模型GPT-4o的语义推理能力和结构化的领域知识图相结合。该框架通过在RGB图像中动态识别可见参照物，从知识图中检索验证高度，估计淹没比，并应用统计离群值过滤来计算最终深度值，从而实现高精度的水位估计。", "conclusion": "FloodVision在MyCoast New York提供的110张 crowdsourced 图像上进行了评估，其均方绝对误差为8.17 cm，比GPT-4o基线低20.5%（10.28 cm），并且超越了之前的CNN基线方法。该系统在多变场景下表现良好，能在接近实时的情况下运行，适合未来集成到数字孪生平台和市民报告应用中，以增强智能城市的防洪韧性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04753", "html_url": "https://arxiv.org/abs/2509.04753", "title": "大规模语言模型在患者信息提取中的研究：模型架构、微调策略和多任务指令调优", "title_en": "A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning", "authors": "Cheng Peng,Xinyu Dong,Mengxian Lyu,Daniel Paredes,Yaoyun Zhang,Yonghui Wu", "background": "自然语言处理(NLP)是提取临床叙事中的重要患者信息的关键技术，以支持医疗应用。大规模语言模型(LLM)的迅速发展已经革新了许多临床领域的NLP任务，但如何在患者信息提取任务中有效利用这些模型仍然需要进一步探索。", "innovation": "该研究调查了LLM在患者信息提取中的有效性，关注于LLM架构、参数有效的微调方法(PEFT)以及多任务指令调优技术，以开发稳健和普适的患者信息提取系统。研究还考察了在少量样本学习任务下，组合任务的零样本和少样本学习性能。", "conclusion": "研究以一套LLM为基础，包括基于编码器的语言模型(BERT、GatorTron)和基于解码器的语言模型(GatorTronGPT、Llama 3.1、GatorTronLlama)，在五个数据集上进行了基准测试。研究对比了传统全尺寸微调和基于提示的PEFT策略，并探索了一种结合任务的多任务指令调优框架，使用跨数据集留一法策略评估零样本和少样本学习性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04781", "html_url": "https://arxiv.org/abs/2509.04781", "title": "大语言模型已离开聊天：大型语言模型离场偏好的证据", "title_en": "The LLM Has Left The Chat: Evidence of Bail Preferences in Large Language Models", "authors": "Danielle Ensign,Henry Sleight,Kyle Fish", "background": "研究大语言模型（LLMs）是否在有选择的情况下会选择退出对话（以下简称“离场”或“bail”），以及影响模型选择离场的因素。", "innovation": "提出了三种不同的离场方法，包括模型调用的工具、模型输出的字符串和询问模型是否想要离开的提示。通过分析真实数据续写（Wildchat 和 ShareGPT）的结果，发现模型在不同的离场方法下，离场率在0.28%到32%之间变化。研究还构造了一个非详尽的离场案例分类系统，并基于此构建了一个代表性的合成数据集BailBench，评估多个模型的行为，发现模型间的离场比率差异显著，同时发现拒绝与离场之间的关系，为进一步研究提供了证据和数据支持。", "conclusion": "模型在真实世界的离场率可能被高估了4倍，最终实际的离场率可能是6%-7%。研究发现拒绝与离场之间存在复杂关系，不仅与不同的离场方法和提示词汇有关，还与拒绝率本身没有明显的相关性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04784", "html_url": "https://arxiv.org/abs/2509.04784", "title": "通过行列式点过程增强大型语言模型的多样性", "title_en": "Enhancing Diversity in Large Language Models via Determinantal Point Processes", "authors": "Yilei Chen,Souradip Chakraborty,Lorenz Wolf,Ioannis Ch. Paschalidis,Aldo Pacchiano", "background": "监督微调和强化学习是两个常用的后训练大型语言模型（LLMs）的方法。虽然它们可以提升模型在下游任务中的表现，但往往会降低模型的输出多样性，导致回答变得狭隘和模式化。当前用于增强多样性的方法多在推理时使用或仅关注词汇差异。", "innovation": "基于行列式点过程（DPPs）提出了一种名为DQO的新训练方法，旨在同时优化LLMs的质量和语义多样性。该方法从每个提示中采样并嵌入一组响应，使用基于核相似度矩阵的行列式测量这些响应嵌入的体积，以此来评估多样性。", "conclusion": "实验结果显示，该方法在不牺牲模型质量的情况下显著提高了语义多样性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04782", "html_url": "https://arxiv.org/abs/2509.04782", "title": "VARMA-增强的变压器模型在时间序列预测中的应用", "title_en": "VARMA-Enhanced Transformer for Time Series Forecasting", "authors": "Jiajun Song,Xiaoou Liu", "background": "基于Transformer的模型在时间序列预测方面取得了显著进展。例如，Cross-Attention-only Time Series transformer（CATS）展示了通过移除自我注意，模型可以更准确和高效。然而，这些精简架构可能会忽略古典统计模型，如向量自回归移动平均（VARMA）模型所捕捉到的有效局部时序依赖。”这些古典统计模型能够捕捉时间序列中的局部和统计特征。", "innovation": "本文提出了VARMAformer，一种结合了跨注意力机制高效性与古典时间序列分析原则的新型架构。该模型的关键创新点包括：（1）VARMA启发式特征提取器（VFE），用于在片段级别明确建模自回归（AR）和移动平均（MA）模式；（2）VARMA增强注意力（VE-atten）机制，采用时间门控机制使查询更加具有上下文意识。通过将这些古典洞察融入现代骨干，VARMAformer能够同时捕捉全局、长期依赖关系和局部、统计结构。", "conclusion": "通过在广泛使用的基准数据集上进行大量实验，证明了我们的模型始终优于现有最先进的方法。这项工作验证了将古典统计洞察力整合到现代深度学习框架中以进行时间序列预测的重要优势。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04734", "html_url": "https://arxiv.org/abs/2509.04734", "title": "Beyond I-Con: 探索表示学习中新的距离度量维度", "title_en": "Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning", "authors": "Jasmine Shone,Shaden Alshammari,Mark Hamilton,Zhening Li,William Freeman", "background": "研究表明，超过23种表示学习方法隐式地最小化数据与学习分布之间的KL散度，这些学习分布用于编码数据点之间的相似性。然而，基于KL散度的损失函数可能与真正的优化目标不一致，KL散度的不对称性和无界性可能带来优化挑战。", "innovation": "提出了一种超越I-Con的新框架，该框架通过探索替代的统计差异和相似性核，系统地发现了新的损失函数。该框架在无监督聚类、监督对比学习和降维等任务上，通过使用总变差距离和基于距离的相似性核等替代方法，展示了优于传统的优化策略。", "conclusion": "研究结果强调在表示学习优化中选择差异度量和相似性核的重要性。通过这种方法，可以获得更好的无监督聚类结果、监督对比学习表现和降维效果。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04800", "html_url": "https://arxiv.org/abs/2509.04800", "title": "基于移动获取图像的深度学习模型实现可访问性皮肤病学：皮肤病变分类", "title_en": "Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images", "authors": "Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib", "background": "皮肤病是全球最普遍的健康问题之一，而传统的诊断方法往往成本高昂、复杂且在低资源地区不可用。自动分类的深度学习方法已成为一种有前景的替代方法，但现有研究主要限于皮肤镜数据集和疾病类别的狭窄范围。", "innovation": "本项工作创建了一个包含超过50种皮肤病类别的大型移动设备获取数据集，使之更符合现实生活条件。研究评估了多种卷积神经网络和基于Transformer的架构，证明了Transformer模型，特别是在Swin Transformer模型的优越性能，这得益于其有效捕捉全局上下文特征的能力。为了增强可解释性，引入了Gradient-weighted Class Activation Mapping（Grad-CAM），它突出了临床相关区域并提供了模型预测的透明度。", "conclusion": "本研究表明，基于Transformer的模型方法在手机获取的皮肤病变分类中具有潜力，为有限资源环境下的AI辅助皮肤科筛查和早期诊断铺平了道路。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04785", "html_url": "https://arxiv.org/abs/2509.04785", "title": "图去学习：图神经网络中的高效节点删除", "title_en": "Graph Unlearning: Efficient Node Removal in Graph Neural Networks", "authors": "Faqian Guan,Tianqing Zhu,Zhoutian Wang,Wei Ren,Wanlei Zhou", "background": "随着对隐私攻击和潜在敏感信息泄露的关注不断增加，研究人员已积极研究如何在图神经网络（GNN）模型中高效地移除敏感训练数据并降低隐私风险的方法。节点去学习作为一种保护敏感节点隐私的有前景技术，通过高效删除GNN模型中的特定训练节点信息得以提出。然而，现有的节点去学习方法要么限制GNN结构，要么不能有效利用图拓扑信息，甚至会破坏图的拓扑结构，使得难以达到性能与复杂性的良好权衡。", "innovation": "为了解决上述问题并实现GNN中训练节点去除的高效去学习，本文提出了三种新的节点去学习方法：基于类别的标签替换、拓扑引导的邻居均值后验概率以及类一致性邻居节点筛选。其中，拓扑引导的邻居均值后验概率和类一致性邻居节点筛选方法有效地利用了图的拓扑特征，从而实现更有效的节点去学习。我们通过在三个基准数据集上进行实验，并从模型效用、去学习效用和去学习效率等方面进行评估，证明了所提出方法的效果与先进节点去学习方法相比的优势。", "conclusion": "本文提出的方法能够高效地移除敏感训练节点并在GNN中保护敏感节点的隐私信息。所提出的发现增强了GNN模型的隐私和安全，并在节点去学习领域提供了有价值的见解。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04752", "html_url": "https://arxiv.org/abs/2509.04752", "title": "SePA: 一种增强搜索的预测代理以实现个性化健康指导", "title_en": "SePA: A Search-enhanced Predictive Agent for Personalized Health Coaching", "authors": "Melik Ozolcer,Sang Won Bae", "background": "该论文介绍了一种名为SePA（搜索增强预测AI代理）的新颖的LLM健康教练系统，该系统结合了个性化的机器学习和检索增强生成，以提供适应性强的、基于证据的指导。SePA结合了（1）个体化模型，通过佩戴传感器数据预测每日压力、酸痛和受伤风险；（2）一个检索模块，将LLM生成的反馈与专家审核过的网络内容结合，以确保上下文相关性和可靠性。", "innovation": "该创新在于SePA系统的开发，它通过个性化模型预测用户健康状态，并结合检索模块确保生成的反馈具有可靠性和相关性。研究采用了滚动起源交叉验证和团队k折交叉验证方法评估预测模型的性能，并且一个初步的专家研究显示，检索辅助建议比没有检索辅助的建议更受欢迎，且显示了实际意义（Cliff's δ=0.3, p=0.05）。此外，该论文还衡量了响应质量和速度之间的延迟性能折衷，提供了一个清晰的路线图，以便开发下一代可信的个人健康信息管理系统", "conclusion": "该研究表明，个性化模型优于通用基础模型，检索模块提高了建议的实用性和可靠性。该研究还展示了在保持建议质量和速度之间进行权衡的方法，并为未来可持续、可信的个人健康信息管理系统提供了指导性的路径。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04853", "html_url": "https://arxiv.org/abs/2509.04853", "title": "基于专家路由的驱动知识驱动扩散策略", "title_en": "A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing", "authors": "Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun", "background": "端到端的自动驾驶仍然受限于生成多模式行为、保持时间稳定性以及在各种场景下泛化的需要。现有方法往往难以处理多模式性、长期一致性或缺乏模块化的适应性。", "innovation": "本文提出了一种知识驱动的扩散策略KDP，它结合了生成扩散建模和稀疏专家组合路由机制。扩散组件生成时间上一致且多模式的行为序列，而专家路由器机制根据上下文激活专门且可重用的专家，从而实现模块化的知识组合。广泛的实验结果表明，KDP 在代表性驾驶场景中表现出更高的成功率、更少的碰撞风险和更平滑的控制，高于当前主流方法。归因分析揭示了专家的结构化专业化和跨场景重用。", "conclusion": "这些结果建立了扩散与专家路由相结合的知识驱动的端到端自动驾驶可扩展和解释性框架。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04844", "html_url": "https://arxiv.org/abs/2509.04844", "title": "REMOTE: 一种基于多级最优传输和混合专家的统一多模态关系提取框架", "title_en": "REMOTE: A Unified Multimodal Relation Extraction Framework with Multilevel Optimal Transport and Mixture-of-Experts", "authors": "Xinkui Lin,Yongxiu Xu,Minghao Tang,Shilong Zhang,Hongbo Xu,Hao Xu,Yubin Wang", "background": "多模态关系提取（MRE）在知识图谱和多媒体领域是一个关键任务，对多模态知识图谱的构建起着重要作用。然而，现有方法通常只能提取单一类型的关系三元组，限制了它们提取超出指定类型的三元组的能力。直接结合这些方法无法捕捉到动态的跨模态交互，同时引入了大量的计算冗余。", "innovation": "提出了一种新的统一多模态关系提取框架，称为 REMOTE（基于多级最优传输和混合专家的统一多模态关系提取），可以同时提取文本实体与视觉对象之间的内模态和跨模态关系。通过引入混合专家机制动态选择不同类型的三元组的最佳交互特征，确保最相关的模态信息被利用。此外，采用多级最优传输融合模块保留低级特征，同时保持多层编码，以获得更丰富的表示。", "conclusion": "广泛的实验证明，REMOTE 有效地提取了各种类型的关系三元组，并在两个其他公共 MRE 数据集的所有指标上达到了最先进的性能。我们发布了我们的资源，可以在 https://yourlinkhere 发布。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04805", "html_url": "https://arxiv.org/abs/2509.04805", "title": "无线通信系统中的AI驱动前传链路压缩：综述与方法设计", "title_en": "AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design", "authors": "Keqin Zhang", "background": "现代无线系统中的前传链路必须在严格的带宽和时延限制下传输高维度信号，这使得压缩变得不可或缺。传统策略如压缩传感、标量量化和固定编解码流水线通常依赖严格的先验知识，在高压缩率时性能急剧下降，且难以在各通道和部署之间调整。近年来，人工智能的进展带来了端到端学习变换、向量量化和逐层量化，这些方法更好地利用了信道状态信息(CSI)、预编码矩阵、IQ样本和LLR的结构。这些方法的第一部分综述了AI驱动的压缩技术，第二部分对两种代表性高压缩路径——CSI反馈的端到端学习和资源块(RB)级别预编码优化结合压缩进行了深入分析。据此，该文提出了一种适应无蜂窝架构的前传压缩策略，旨在实现高压缩率并控制性能损失，支持资源块级别的速率自适应，以及适用于下一代网络中集中协作传输的低时延推理能力。", "innovation": "提出了针对无蜂窝架构的前传压缩策略，结合了端到端学习的CSI反馈和资源块级别预编码优化的压缩技术；该策略能够实现高压缩率并控制性能损失，支持资源块级别自适应速率，适合低时延集中协作传输，适用于未来的无线通信系统。相较于传统技术，这种方法利用了更多信号结构信息，具有更好的灵活性和适应性，能够在保持较高性能的同时实现更高效的压缩。", "conclusion": "该文综述了AI驱动的压缩技术，并具体分析了CSI反馈的端到端学习和RB级别预编码优化结合压缩的方法设计。基于此，提出了一种专门为无蜂窝架构设计的前传压缩策略，能够实现高效的压缩性能，并且能够支持资源块级别的自适应速率，适用于当前和未来的无线通信系统中，提供低时延的推理能力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04824", "html_url": "https://arxiv.org/abs/2509.04824", "title": "使用杂交Mamba-Transformer框架探索空间-角度非局域相关性以实现光线场超分辨率", "title_en": "Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution", "authors": "Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou", "background": "近年来，基于Mamba的方法因其在长程信息建模和线性复杂度方面的优势，在光线场图像超分辨率（LFSR）中显示出优化计算成本和性能的巨大潜力。然而，当前多方向扫描策略在复杂光线场数据上应用时导致了不高效的特征提取。", "innovation": "本文提出了Subspace Simple Scanning (Sub-SS) 策略和Subspace Simple Mamba Block (SSMB)，实现更高效和精确的特征提取。同时，提出了双阶段建模策略来解决状态空间在保留空间-角度和视差信息方面的局限性，扩展了非局部空间-角度相关性探索。上述策略构建了杂交Mamba-Transformer框架（LFMT），将Mamba和Transformer模型的优势结合，适用于LFSR，并在空间、角度和极平面域进行全面信息探索。", "conclusion": "实验结果表明，LFMT在LFSR中显著优于当前最先进的方法，实现了性能大幅提升，同时保持了较低的计算复杂度。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04855", "html_url": "https://arxiv.org/abs/2509.04855", "title": "末日悖论：承认灭绝风险反而减少预防它的动力", "title_en": "The Paradox of Doom: Acknowledging Extinction Risk Reduces the Incentive to Prevent It", "authors": "Jakub Growiec,Klaus Prettner", "background": "本文研究了灭绝风险作为导致急躁行为来源的重要性。研究框架区分了人类灭绝风险和个体死亡风险，同时允许不同程度的代际利他主义。此外，还考虑了从进化角度来看，“自私的基因”视角。研究表明，人类灭绝的风险是折现率不可或缺的一部分；而个体死亡风险可以通过人类繁衍部分或完全对冲。总的来说，本文指出，在面对灭绝风险时，人们变得更加急躁而不是更加远见。因此，灭绝风险越严重，避免这种风险的激励就越小。该框架有助于解释为什么人类在应对各种灭绝风险方面的投资一直不足，包括气候变化缓解、流行病预防以及应对日益增长的先进人工智能风险。", "innovation": "本文提出的框架区分了人类灭绝风险和个体死亡风险方面，在此基础上考虑了不同程度的代际利他主义，并引入了“自私的基因”视角。它还证实了在面对较严重的灭绝风险时，人们反而会减少对预防这些风险的投资。", "conclusion": "本文展示了，面对灭绝风险，人们的激励不足，导致对气候变暖缓解、流行病预防以及先进人工智能风险的应对投资不足。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04889", "html_url": "https://arxiv.org/abs/2509.04889", "title": "蜘蛛网络：视觉模型估计与蜘蛛相关的恐惧评分", "title_en": "SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models", "authors": "Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak", "background": "计算机视觉的进步为临床应用开辟了新的途径，特别是在基于患者反应动态调整视觉刺激的计算机暴露疗法中。为了开发适应性系统，研究使用预训练的计算机视觉模型从标准化数据集中的蜘蛛相关图像中准确预测恐惧水平作为关键步骤。313张图像的标准数据集被用来训练三种不同的模型，通过交叉验证评估模型表现，平均绝对误差在10.1到11.0之间。分析表明，减少数据集大小显著损害了性能，而进一步增加则没有显著收益。可解释性评估显示模型预测基于与蜘蛛相关的特征。类别错误分析进一步确定了与更高错误率相关的视觉条件（例如，远处视角和人造或涂漆的蜘蛛）。", "innovation": "研究使用预训练的计算机视觉模型预测与蜘蛛相关的恐惧评分，通过改进和评估三种不同的模型，发现平均绝对误差在10.1到11.0之间，并通过可解释性评估确定了关键的预测因素，证明了解释性计算机视觉模型在预测恐惧评分方面的潜力，强调了模型的可解释性和数据集大小对开发有效的情绪感知治疗技术的重要性。", "conclusion": "研究结果表明，解释性的计算机视觉模型在预测恐惧评分方面具有潜力，强调了模型的可解释性和数据集大小的有效性对于开发有效的基于情绪的治疗技术的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04588", "html_url": "https://arxiv.org/abs/2509.04588", "title": "基于忠诚指导的神经网络集成解释", "title_en": "Toward Faithfulness-guided Ensemble Interpretation of Neural Network", "authors": "Siyu Zhang,Kenneth Mcmillan", "background": "可解释和忠实的解释对于理解模型的行为和评估至关重要。现有模型解释的有效性和广度有待提升。", "innovation": "提出了一种名为FEI（Faithfulness-guided Ensemble Interpretation）的新颖框架，该框架通过提供更优秀的可视化效果，提高了解释的准确性和广度。FEI运用平滑近似提高定量忠实度评分，并提出了一种新的定性指标评估隐藏层忠实度。", "conclusion": "实验结果表明，FEI在定性和定量方面均超越现有方法，展示了显著的进展，为提升神经网络解释的忠实度建立了一个全面的框架，强调了广度和精度的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04970", "html_url": "https://arxiv.org/abs/2509.04970", "title": "DeGuV：深度引导的视觉强化学习在通用性和可解释性的抓取任务中", "title_en": "DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation", "authors": "Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi", "background": "强化学习（RL）代理可以从视觉输入中学习解决复杂任务，但在将这些学到的技能应用到新环境中，特别是在机器人领域方面，依然面临重大挑战。虽然数据增强可以提高通用性，但它通常会牺牲样本效率和训练稳定性。", "innovation": "该论文提出了DeGuV，一种既增强了通用性又提高了样本效率的RL框架。具体来说，DeGuV 利用一个可学习的掩码网络，从深度输入中生成掩码，只保留关键的视觉信息并丢弃无关像素，确保RL代理专注于重要特征，从而增强数据增强下的鲁棒性。此外，DeGuV 还通过引入对比学习来进一步增强样本效率和训练稳定性，稳定Q值估计。", "conclusion": "该方法在Franka Emika机器人的RL-ViGen基准测试中得到了评估，并展示了在零样本的仿真到现实转移中的有效性。结果表明，DeGuV 在通用性和样本效率上均优于现有方法，并通过突出显示视觉输入中最相关的区域来提高可解释性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04993", "html_url": "https://arxiv.org/abs/2509.04993", "title": "6G网络中的大规模语言模型使能多代理系统：边缘-终端双环合作框架与方法", "title_en": "LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration", "authors": "Zheyan Qu,Wenbo Wang,Zitong Yu,Boquan Sun,Yang Li,Xing Zhang", "background": "6G网络中无处不在的计算资源为大规模语言模型(LLMs)和智能服务的融合提供了理想环境，通过代理框架实现。LLM使能的代理能够通过辅助模块和规划内核自主规划和执行行动，应对多样化的环境语义和用户意图。然而，个体网络设备资源有限，严重影响了LLM使能代理高效操作，特别是面对复杂的工具调用，这迫切需要多级设备合作的高效机制。", "innovation": "提出了6G网络中具备双环终端-边缘合作的LLM使能多代理系统框架和方法。外环由全球代理与部署在边缘服务器和终端上的多个子代理的迭代合作组成，通过任务分解和并行子任务分配增强规划能力。内环利用具有专门角色的子代理进行循环推理、执行和重新规划子任务，同时整合并行工具调用生成与卸载策略来提高效率。这些改进的能力通过6G支持的城市安全管理案例研究得到验证。", "conclusion": "详细分析了在6G网络中面临的开放挑战和未来方向，推动6G时代的到来。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04923", "html_url": "https://arxiv.org/abs/2509.04923", "title": "使用人工智能表示和表征量子系统", "title_en": "Artificial intelligence for representing and characterizing quantum systems", "authors": "Yuxuan Du,Yan Zhu,Yuan-Hang Zhang,Min-Hsiu Hsieh,Patrick Rebentrost,Weibo Gao,Ya-Dong Wu,Jens Eisert,Giulio Chiribella,Dacheng Tao,Barry C. Sanders", "background": "随着量子系统的规模扩大，特别是在量子模拟器和巨量子计算机产生的系统中，对量子系统的有效表征成为量子科学中的核心挑战。希尔伯特空间的维数与系统的规模呈指数关系增长，因此传统的表征方法难以应对。近年来，人工智能（AI）在高维模式识别和函数近似方面的能力，使其作为一种强大的工具出现以解决这一挑战。借助AI，已有大量研究致力于表示和表征可扩展的量子系统。AI在量子系统表征中的应用可以分类为三种协同范式：机器学习，特别是深度学习和语言模型。这些AI范式在两个核心任务中的贡献被详细讨论了，即量子属性预测和量子态近似器的构建。这些任务支持了量子认证、基准测试、量子算法优化以及强关联物质相的理解等多种应用。同时还讨论了AI与量子科学接口的挑战、开放问题和未来前景。", "innovation": "利用AI技术，特别是机器学习和深度学习，来解决大型量子系统的表征挑战，能够有效识别高维模式和近似复杂函数，这在以往的表征方法中难以实现。通过AI的不同范式，既提升了量子属性预测的能力，又促进了量子态的近似。这不仅推动了量子认证、基准测试等领域的技术进步，也为理解复杂的量子物理现象提供了新的途径。同时，AI和量子科学的融合为未来的研究和应用开辟了广阔的可能性。", "conclusion": "本文综述了AI在量子系统表征中的三大范式及其对核心任务的贡献，强调了AI与量子科学相结合的应用前景。尽管AI在表征复杂量子系统方面取得了显著进展，但仍有一些关键技术问题亟待解决，如如何更有效地利用先验知识来增强模型性能，以及如何解决训练复杂模型的计算成本和数据集多样性的挑战等。未来，随着AI技术的发展，解决这些问题将使我们能够更好地理解和利用大型量子系统。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05034", "html_url": "https://arxiv.org/abs/2509.05034", "title": "工业异常检测和定位中高效像素标注的途径", "title_en": "Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization", "authors": "Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang", "background": "在工业产品检测中，通常使用仅基于非缺陷样本训练的异常检测（AD）框架进行检测。虽然可以收集到缺陷样本，但利用它们通常需要对像素进行标注，这限制了其可扩展性。", "innovation": "提出了一种交互式图像分割（IIS）算法ADClick，可以仅通过少数用户点击和简短的文本描述，自动生成像素级异常标注，以实现高效的精确标注，显著改善了AD模型性能（例如，MVTec AD上的AP=96.1%）。进一步介绍了ADClick-Seg，一种基于原型的方法构建的跨模态框架，通过视觉特征和文本提示的对齐来实现异常检测和定位，其在MVTec AD的“多类别”AD任务上达到了最先进的结果（AP=80.0%，PRO=97.5%，Pixel-AUROC=99.1%）。", "conclusion": "ADClick和ADClick-Seg通过结合像素级先验和语言引导的线索，为工业异常检测和定位提供了一种高效且精确的解决方案，并且在性能上达到了最先进的水平。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04999", "html_url": "https://arxiv.org/abs/2509.04999", "title": "对抗增强与主动采样以实现稳健的网络异常检测", "title_en": "Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection", "authors": "Sidahmed Benabderrahmane,Talal Rahwan", "background": "Advanced Persistent Threats (APTs) 具有隐蔽性和长时间特性，给网络安全带来了巨大挑战。传统的监督学习方法通常需要大量标记数据，而在实际场景中这些数据往往稀缺。", "innovation": "该论文提出了一种新的方法，该方法结合了自编码器（AutoEncoders）进行异常检测和主动学习（Active Learning），通过选择性地查询Oracle以获取不确定或模糊样本的标签，这种方法降低了标记成本并提高了检测准确性。论文介绍了基于注意力-对抗性双自编码器（Attention Adversarial Dual AutoEncoder）的异常检测框架，并展示了主动学习循环如何逐步提升模型性能。", "conclusion": "在 DARPA 透明计算计划的真实不均衡证明轨迹数据上对框架进行了评估，该数据集涵盖了多个操作系统，包括Android、Linux、BSD和Windows。结果显示，在主动学习过程中检测率有显著提高，优于现有方法。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04833", "html_url": "https://arxiv.org/abs/2509.04833", "title": "PropVG：基于多粒度区分的端到端提案驱动视觉接地", "title_en": "PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination", "authors": "Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang", "background": "近年来，视觉接地的进步大多已经远离传统基于提议的两阶段框架，因为这些框架效率低下且计算复杂度过高，转而青睐端到端直接参考框架。然而，目前的方法几乎完全依赖于所指目标的监督，忽视了前景目标的潜在益处。此外，现有方法通常未能结合多粒度区分，这对于复杂场景中的稳健对象识别至关重要。", "innovation": "我们提出了PropVG，这是一个端到端的提案驱动框架，据我们所知，它是首次在不依赖额外检测器的情况下将前景对象提议生成与参考对象理解无缝集成的端到端框架。我们引入了基于对比学习的参考评分模块 (CRS)，它在句子和词级别使用对比学习来增强理解和区分所指对象的能力。此外，我们还设计了多粒度目标鉴别模块 (MTD)，该模块融合了对象和语义级别的信息，以提高对消失目标的识别。", "conclusion": "在gRefCOCO (GREC/GRES)，Ref-ZOM，R-RefCOCO和RefCOCO (REC/RES)基准上的广泛实验表明PropVG的有效性。该代码和模型可在以下链接获取：this https URL."}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05100", "html_url": "https://arxiv.org/abs/2509.05100", "title": "ICR: 迭代澄清与重写在会话搜索中的应用", "title_en": "ICR: Iterative Clarification and Rewriting for Conversational Search", "authors": "Zhiyu Cao,Peifeng Li,Qiaoming Zhu", "background": "大多数之前的工作在会话查询重塑中采用了一种端到端的重塑方式。然而，这种方法受到了查询中存在多重模糊表达式的问题困扰，这使得同时识别和重塑多个位置变得复杂。", "innovation": "提出了一种新的框架ICR（迭代澄清与重塑），这是一种以澄清问题为中心的迭代重塑方案。在这个框架中，模型在生成澄清问题和重塑查询之间交替进行。实验证明，ICR可以在澄清-重塑的迭代过程中不断改进检索性能，从而在两个流行的数据集上达到最先进的性能。", "conclusion": "ICR框架在迭代澄清与重塑的过程中逐步提高了检索性能，展现出在两种主流数据集上的顶尖性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05190", "html_url": "https://arxiv.org/abs/2509.05190", "title": "基于准确率约束的CNN剪枝以实现高效可靠的EEG基于的癫痫检测", "title_en": "Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection", "authors": "Mounvik K,N Harshit", "background": "深度学习模型，尤其是卷积神经网络（CNN），在脑电图（EEG）-基于的癫痫检测这类生物医学信号中显示出极大的潜力。然而，这些模型在资源有限或需要实时检测的环境中面临着因此带来的挑战，其主要原因是模型的规模和计算需求较高。\n", "innovation": "本文提出了一个轻量级的一维CNN模型，并通过结构化剪枝提高了效率和可靠性。通过轻微的提前停止训练来解决可能的过拟合问题，模型实现了92.78%的准确率和0.8686的宏F1分数。在剪枝过程中，移除了基础CNN中50%的卷积核，基于其在模型预测中的重要性。剪枝使得50%的权重和内存被削减，但新网络仍然能够保持预测能力，精度提高到了92.87%，并且宏F1分数提高到了0.8707。\n", "conclusion": "研究结果显示，结构化剪枝在移除冗余部分的同时改善了通用性，并结合轻微的提前停止训练，朝着提高癫痫检测效率和可靠性的方向取得了很有前景的进展。这对于资源受限的环境是一种明确的动机。\n"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05112", "html_url": "https://arxiv.org/abs/2509.05112", "title": "基于GenAI的SDV平台测试用例生成与执行", "title_en": "GenAI-based test case generation and execution in SDV platform", "authors": "Denesa Zyberaj,Lukasz Mazur,Nenad Petrovic,Pankhuri Verma,Pascal Hirmer,Dirk Slama,Xiangwei Cheng,Alois Knoll", "background": "本文介绍了一种基于GenAI的自动化测试用例生成方法，利用大型语言模型和视觉语言模型将自然语言需求和系统图转化为结构化的Gherkin测试用例。该方法结合了Vehicle Signal Specification建模，以标准化车辆信号定义，提高汽车子系统间的兼容性和与第三方测试工具的集成效率。生成的测试用例在this http URL（未完整给出网址）环境中执行，这是一个开放且供应商中立的平台，旨在快速验证软件定义的车辆功能。该研究表明，这种方法可以显著减少手动测试规范的工作量，并迅速执行生成的测试。尽管高度自动化，但由于当前GenAI管道的限制和this http URL平台的约束，测试用例和测试脚本的生成仍然需要人工干预。", "innovation": "提出了一种利用大型语言模型和视觉语言模型将自然语言需求和系统图转化为结构化的Gherkin测试用例的方法。结合了Vehicle Signal Specification建模以标准化车辆信号定义，并在open and vendor-neutral（开放且供应商中立）的环境下执行生成的测试用例，从而快速验证软件定义的车辆功能。该方法相较于传统的测试方法在减少手动测试规范工作量方面表现出显著优势。", "conclusion": "该研究通过使用Child Presence Detection System作为案例研究，验证了GenAI驱动的测试用例生成方法的有效性。尽管该方法在自动化方面取得了一定进展，但仍需人工干预以克服当前GenAI技术的局限性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05197", "html_url": "https://arxiv.org/abs/2509.05197", "title": "AI代理用于网页测试：一项野外案例研究", "title_en": "AI Agents for Web Testing: A Case Study in the Wild", "authors": "Naimeng Ye,Xiao Yu,Ruize Xu,Tianyi Peng,Zhou Yu", "background": "自动化网页测试对于确保高质量用户体验和交付商业价值至关重要。传统方法主要关注代码覆盖率和负载测试，但往往无法捕捉到复杂的用户行为，导致许多可用性问题未被发现。随着大型语言模型（LLM）和AI代理的出现，它们为网页测试带来了新的可能性，使测试能够模拟真实用户的交互，识别Bug和可用性问题，生成易于理解的报告。", "innovation": "提出了一个基于AI代理的网页测试框架——WebProber。该框架能够在给定URL的情况下独立探索网站，模拟真实用户交互，识别Bug和可用性问题，并生成易于理解的报告。通过一项包含120个学术个人网站的研究案例，WebProber发现了29个可用性问题——这些问题中许多是由传统工具未发现的。", "conclusion": "我们的研究结果突显了基于代理的测试作为有前途的方向，同时指出了开发下一代以用户为中心的测试框架的发展方向。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04657", "html_url": "https://arxiv.org/abs/2509.04657", "title": "通过SQL2NL评估NL2SQL", "title_en": "Evaluating NL2SQL via SQL2NL", "authors": "Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth", "background": "在自然语言到结构化查询语言（NL2SQL）模型的理解泛化能力中，语言变体的鲁棒评估是关键因素。现有基准数据集在系统性和控制性方面较少考虑这一因素。先前的工作主要考察语义歧义或模式变化，未能针对语言变体单独进行鲁棒性评估。", "innovation": "本文提出了一种新的基于SQL到自然语言（SQL2NL）的模式对齐改写框架，能够自动生成语义等价但词汇差异较大的查询，同时保持与原始模式和意图的一致性。这是首次针对单一语言变体进行目标化鲁棒性评估的研究。结果显示，最先进的模型表现远比标准基准数据集所暗示的更为脆弱。", "conclusion": "对现有模型的鲁棒性研究表明，更小的模型（如GPT-4o mini）受到更严重的影响。鲁棒性在不同查询复杂度、数据集和领域之间存在显著差异，强调了需要建立明确衡量语言泛化能力的评估框架，以确保模型在实际应用场景中的可靠表现。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04983", "html_url": "https://arxiv.org/abs/2509.04983", "title": "探索支持向量机的量子学习管道实现", "title_en": "Exploring an implementation of quantum learning pipeline for support vector machines", "authors": "Mario Bifulco,Luca Roversi", "background": "本文提出了一种利用门基量子核方法与量子退火优化相结合来支持向量机（SVM）学习的完全量子方法。研究讨论了通过各种特征映射和量子比特配置构建量子核，并通过核-目标对齐（KTA）评估其适用性。SVM的对偶问题被重新表述为二次无约束二元优化（QUBO）问题，可以通过量子退火器求解。实验结果显示，核的良好对齐和适当的正则化参数能够达到竞争性性能，最佳模型的F1分数达到了90%。这些结果表明，量子学习管道的端到端实现是可行的，并且混合量子架构在量子高性能计算（QHPC）环境中具有潜力。", "innovation": "本文通过将门基量子核方法与量子退火优化相结合，提出了一种完整的量子方法，并且通过QUBO问题解决SVM的对偶问题。此外，通过KTA评估了不同特征映射和量子比特配置的量子核的适用性，展示了高对齐度和恰当的正则化参数对于提升性能的重要性。", "conclusion": "本文实验验证了基于核-目标对齐度量和合适的正则化参数下的SVM模型可以获得优秀的性能。该研究提出了端到端的量子学习管道，并强调了混合量子架构在量子高性能计算（QHPC）场景中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05031", "html_url": "https://arxiv.org/abs/2509.05031", "title": "基于Transformer注意力机制的指示手势引导目标估计", "title_en": "Pointing-Guided Target Estimation via Transformer-Based Attention", "authors": "Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter", "background": "指示手势，如指向，是人类非语言交流的基础形式，能帮助人们将注意力引导至特定物体或位置。在人类-机器人交互（HRI）中，这种能力至关重要，因为机器人需要预测人类的意图并作出合适的响应。本文研究了在NICOL机器人控制的桌面上，人类通过自然指向手势指示目标时，如何利用多模态交互转换器（MM-ITF）来估计目标物体的问题。", "innovation": "本文提出了一种多模态交互转换器（MM-ITF），该架构通过跨模态注意力映射2D指向手势到物体位置，并为每个位置分配一个可能性分数，从而识别最有可能的目标。该方法能利用单目RGB数据准确预测人类的意图对象，实现直观易用的人机协作。通过引入补丁混淆矩阵，进一步分析模型预测结果在候选物体位置上的表现。", "conclusion": "本文的方法展示了在富含手势的场景中，利用跨模态注意力机制预测目标物体的有效性，并使人类与机器人的交互更加自然。此外，通过补丁混淆矩阵对模型性能进行评估，揭示了模型在预测准确性和鲁棒性方面的性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05198", "html_url": "https://arxiv.org/abs/2509.05198", "title": "提升3D点云分类性能的ModelNet-R和Point-SkipNet", "title_en": "Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet", "authors": "Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari", "background": "3D点云分类对于自动驾驶、机器人技术和增强现实等应用至关重要。然而，常用的ModelNet40数据集存在标签不一致、2D数据、大小不匹配和类别区分不足等问题，限制了模型性能。因此，需要一个更可靠的基准数据集和一种高效模型来提高3D点云分类的准确性。", "innovation": "该研究提出了ModelNet-R，这是对ModelNet40的精心改进，解决了数据集的一系列问题。此外，研究还提出了一种轻量级的基于图的神经网络——Point-SkipNet，该网络通过高效的采样、邻域分组和跳跃连接，实现了在减少计算开销的同时保持高分类准确性。实验结果表明，使用ModelNet-R训练的模型表现显著提升，尤其是Point-SkipNet在ModelNet-R上的准确率达到了最新水平，并且参数数量显著减少。", "conclusion": "高质量的数据集在优化3D点云分类的模型效率方面起着至关重要的作用。这项研究强调了使用改进的数据集和高效模型对提高3D点云分类性能的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05207", "html_url": "https://arxiv.org/abs/2509.05207", "title": "RapidGNN：大规模图神经网络分布式训练的高效能耗通信优化", "title_en": "RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks", "authors": "Arefin Niam,Tevfik Kosar,M S Q Zulkar Nine", "background": "图神经网络（GNNs）在探索实体之间结构关系的多种任务中变得流行，但由于数据集的高度连接结构，要在大型图上进行分布式训练带来了重大挑战。传统的基于采样的方法可以缓解计算负载，但通信开销仍然是一个挑战。因此，需要一种新的框架来解决这些挑战并提高训练效率和能耗效率。", "innovation": "提出了一种分布式GNN训练框架RapidGNN，该框架通过确定性的采样调度来实现高效缓存构建和远程特征预取。与基准方法相比，RapidGNN在基准数据集上提高了端到端训练吞吐量2.46倍至3.00倍，同时将远程特征获取减少了9.70倍至15.39倍。RapidGNN还证明了随着计算单元数量的增加，其接近线性可扩展性，并且相较于基准方法，对于CPU和GPU实现了44%和32%的能耗效率提升。", "conclusion": "RapidGNN通过确定性采样调度实现了高效缓存构建和远程特征预取，显著提高了分布式大规模图神经网络的训练效率和能耗效率。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05218", "html_url": "https://arxiv.org/abs/2509.05218", "title": "HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models", "title_en": "HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models", "authors": "Chang Dai,Hongyu Shan,Mingyang Song,Di Liang", "background": "变换器通过位置编码机制能够建模文本中的序贯结构和长距离依赖关系。然而，绝对位置编码难以外推到更长的序列，因为它们使用固定的相对位置表示。相对方法如Alibi在极长上下文中表现出性能下降。尽管广泛使用的旋转位置编码（RoPE）引入了振荡的注意力模式，但这种模式妨碍了稳定的长距离依赖关系建模。", "innovation": "本文通过几何重构位置编码来解决上述局限性。作者从双曲几何中的洛伦兹变换汲取灵感，提出了双曲旋转位置编码（HoPE），利用双曲函数在词表示上实现洛伦兹旋转。理论分析表明RoPE是新通用公式的一个特例。HoPE从根本上解决了RoPE的问题，通过使注意力权重随词间距离增加而严格递减来稳定长距离依赖关系。实验证明，HoPE在多个扩展序列基准上的困惑度评估中始终优于现有的位置编码方法。", "conclusion": "这些发现强调HoPE具有更好的长距离依赖关系建模和泛化能力。进一步的实验结果和代码将公开提供。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04991", "html_url": "https://arxiv.org/abs/2509.04991", "title": "通过耦合机制-机器学习框架实现高分辨率全球地表温度反演", "title_en": "High-Resolution Global Land Surface Temperature Retrieval via a Coupled Mechanism-Machine Learning Framework", "authors": "Tian Xie,Huanfeng Shen,Menghui Jiang,Juan-Carlos Jiménez-Muñoz,José A. Sobrino,Huifang Li,Chao Zeng", "background": "地表温度（LST）对于陆气相互作用和气候过程至关重要。在异质的土地覆被和极端的大气条件下，准确地获取LST仍然具有挑战性。传统的双波段（SW）算法在湿环境中表现出偏差；纯粹的机器学习（ML）方法缺乏可解释性，且在数据有限的情况下表现不佳，难以泛化。因此，如何克服这些挑战，开发一种能够适应复杂环境的准确且可解释的LST反演方法是一个亟待解决的问题。", "innovation": "我们提出了一种将物理约束与数据驱动的学习相结合的耦合机制-机器学习（MM-ML）框架。该方法结合了辐射传输建模与数据组成部分，使用MODTRAN模拟来获取全球大气剖面，并应用物理约束优化。该方法通过验证4450个来自29个全球站点的观测值，实现了MAE=1.84K，RMSE=2.55K，R-squared=0.966，显著优于传统方法，在极端条件下能将误差减少超过50%。敏感性分析显示，地表温度估计对传感器亮度响应、水汽最敏感，然后是发射率，MM-ML显示了更好的稳定性。这些结果证明了我们提出的耦合建模策略的有效性，可以恢复地球物理参数。", "conclusion": "MM-ML框架结合了物理可解释性和非线性建模能力，能够在复杂环境实现可靠的地表温度反演，并为气候监测和生态系统研究提供支持。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05066", "html_url": "https://arxiv.org/abs/2509.05066", "title": "ToM-SSI: 在情境社会互动中评估心智理论", "title_en": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions", "authors": "Matteo Bortoletto,Constantin Ruhdorfer,Andreas Bulling", "background": "目前大多数面部模型的心理理论（ToM）基准依赖于萨莉-安妮测试的变体，这仅仅提供了一个有限的视角，忽视了人类社会互动的复杂性。因此，存在一个关于扩展现有基准以涵盖更丰富社会互动和空间动态环境的需求。", "innovation": "本文提出了一种新的基准测试ToM-SSI，它是一个多模态的测试方法，能够评估四个人以上在内的多智能体在特定环境中的交互和移动能力，尤其针对混合协作-阻碍的场景以及多个智能体的心理状态并行推理，从而使研究能够涵盖比现有基准更广泛的社会认知。这项设计还有助于揭示模型在新任务中的局限性，为未来研究指明了关键方向。", "conclusion": "现有模型的性能在这些新任务中仍然受到严重限制，这突显了未来研究中亟待解决的关键空白。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05145", "html_url": "https://arxiv.org/abs/2509.05145", "title": "通过变异性交叉审讯探索节奏生成系统的场所稳定性", "title_en": "Exploring Situated Stabilities of a Rhythm Generation System through Variational Cross-Examination", "authors": "Błażej Kotowski,Nicholas Evans,Behzad Haki,Frederic Font,Sergi Jordà", "background": "本文通过变异性交叉审讯（VCE）框架探讨了GrooveTransformer，这是一种实时节奏生成系统。本文通过分析其在三个不同艺术背景中的应用，识别出了三个稳定性特征：自主鼓伴奏生成器、 Eurorack格式的节奏控制电压序列器以及用于和声伴奏系统的节奏驱动器。最初项目的目标并没有特别强调其应用的灵活性，因此本文通过VCE探讨了这些多稳定性如何出现。", "innovation": "本文通过变异性交叉审讯（VCE）这一框架，识别出了三个关键因素：系统不变性的可用性、跨学科合作以及其发展的现场性质，这些因素共同促成了多稳定性现象的形成。这一方法被认为对于数字音乐乐器（DMI）设计具有描述和分析的价值。", "conclusion": "本文结论表明，VCE作为一种描述和分析方法，在数字音乐乐器（DMI）设计中具有一定的可行性。同时强调了技术如何在用户和背景中相互影响、共同塑造以及如何通过这种方法挖掘这些相互关系。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04897", "html_url": "https://arxiv.org/abs/2509.04897", "title": "PLaMo 2 技术报告", "title_en": "PLaMo 2 Technical Report", "authors": "Preferred Networks:Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu", "background": "介绍了PLaMo 2，这是一种针对日本市场的大型语言模型系列，采用了一种基于Samba混合架构，并通过持续预训练过渡到全注意机制，以支持32K标记上下文。训练过程中利用了广泛的合成语料库来克服数据稀缺性，通过权重重用和结构化剪枝实现了高效的计算效率。该剪枝方法生成了一个8B的模型，其性能与之前的100B模型相当。模型进一步通过监督微调（SFT）和直接偏好优化（DPO）以及合成的日语指令数据和模型合并技术进行后训练改进，适用于使用vLLM和量化进行推断，而最小化准确性的损失，这些模型在日语基准测试中达到了最先进的成果，超过了同样大小的开源模型在指令遵循、语言流畅性和日语特定知识方面的性能。", "innovation": "1. 引入了一种基于Samba混合架构的PLaMo 2模型，该模型通过持续预训练过渡到全注意机制，以支持32K标记上下文。2. 通过使用广泛的合成语料库来克服数据稀缺性。3. 利用权重重用和结构化剪枝实现计算效率。4. 通过后训练使用监督微调和直接偏好优化，结合合成的日语指令数据和模型合并技术进一步精炼模型。5. 通过使用vLLM和量化方法优化推理性能，同时保持最小的准确度损失。", "conclusion": "通过这些技术和方法，PLaMo 2模型在日语基准测试中达到了最先进的成果，超过了同样大小的开源模型在指令遵循、语言流畅性和日语特定知识方面的性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05230", "html_url": "https://arxiv.org/abs/2509.05230", "title": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "title_en": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "authors": "Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci", "background": "预训练语言模型已经在多种应用中取得了显著的成果，但它们仍然容易受到概念驱动的虚假相关性的影响，这损害了模型的鲁棒性和公平性。通过对现有模型进行分析，论文指出这些模型在处理任务时，往往会依赖一些不相关的概念快捷路径，从而影响了模型的效果和公平性。为了应对这一挑战，论文提出了一个新的轻量级框架CURE，旨在系统地分离和抑制这些概念快捷路径，同时保留必要的内容信息，提高模型的可靠性和公平性。", "innovation": "CURE框架通过引入一个专门的内容提取器和一个反向网络，从文本中提取与概念无关的特征表示，同时通过对比学习模块控制性地调整剩余的概念性提示的影响，从而减少不利偏见或利用有利于目标任务的关联。这种方法为对抗预训练语言模型中的概念偏见提供了灵活且无监督的蓝图，为构建更加可靠和公平的语言理解系统奠定了基础。", "conclusion": "通过在IMDB和Yelp数据集上使用三种预训练架构进行评估，CURE模型实现了IMDB数据集上F1分数的绝对提升10点，Yelp数据集上2点的提升，同时引入了微小的计算开销。这一方法为语言理解系统的公平性和可靠性提供了新的思路，具有重要的理论和实践价值。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05258", "html_url": "https://arxiv.org/abs/2509.05258", "title": "大型语言模型预训练的扩展性能", "title_en": "Scaling Performance of Large Language Model Pretraining", "authors": "Alexander Interrante-Grant,Carla Varela-Rosa,Suhaas Narayan,Chris Connelly,Albert Reuther", "background": "大型语言模型（LLMs）在各种自然语言处理应用中表现出最佳性能。训练这些模型是一项极其计算密集的任务；前沿的人工智能（AI）研究公司正在投入数十亿美元构建超级计算基础设施，以逐步训练更大规模的模型并使用日益庞大的数据集。然而，关于这些大规模训练管道的规模性能和训练考虑方面的信息在公开文献中缺乏。在使用大规模数据集和模型时，这可能相当复杂，而针对当规模扩大大型语言模型时优化训练性能的实用建议在公开文献中也相对缺乏。", "innovation": "本文旨在部分揭开大型语言模型预训练流水线的面纱，特别是关于分布式训练、跨数百个节点管理大规模数据集以及通过充分利用可用的GPU计算能力扩展数据并行性的考虑。", "conclusion": "通过解决大型语言模型预训练的相关问题，本文旨在推动此类模型训练的研究和实践，为从业者提供有效的策略以优化训练性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05291", "html_url": "https://arxiv.org/abs/2509.05291", "title": "时间中的交叉编码：追踪LLM预训练过程中语言表示的出现与巩固", "title_en": "Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining", "authors": "Deniz Bayazit,Aaron Mueller,Antoine Bosselut", "background": "大型语言模型（LLMs）在预训练过程中学习到了复杂的抽象概念，例如能够检测不规则复数名词。然而，传统的评估方法如基准测试无法揭示模型是如何获得这些概念和能力的。因此，理解特定语言能力何时以及如何在预训练中出现变得尤为重要。", "innovation": "本文使用稀疏交叉编码来跨模型检查点发现并对齐特征，追踪语言特征在预训练过程中的演变。通过这种技术，研究人员在具有显著性能和表示变化的开源检查点三元组之间进行交叉编码，并提出了一种新的指标——相对间接效应（RelIE），以追踪哪些特征对于任务性能变得因果重要。研究结果表明，交叉编码可以检测特征在预训练过程中的出现、持续和发展中断。", "conclusion": "本文的方法是架构无关且可扩展的，提供了一条通向更可解释和细腻的表示学习分析的有希望途径，特别是在整个预训练过程中对模型的理解方面。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05256", "html_url": "https://arxiv.org/abs/2509.05256", "title": "Recomposer：基于事件条线索引的生成性音频编辑", "title_en": "Recomposer: Event-roll-guided generative audio editing", "authors": "Daniel P. W. Ellis,Eduardo Fonseca,Ron J. Weiss,Kevin Wilson,Scott Wisdom,Hakan Erdogan,John R. Hershey,Aren Jansen,R. Channing Moore,Manoj Plakal", "background": "由于单一音频来源在时间上交织，复杂真实场景的声音编辑极为困难。生成模型能够根据对数据领域的强先验理解填补缺失或损坏的细节。本研究提出了一种系统，用于基于文本编辑描述（例如，“增强门声”）和从“事件条卷”提取的活动时间图形表示，在复杂场景中编辑个体声音事件，实现音频的删除、插入和增强功能。", "innovation": "该系统采用基于SoundStream表示形式的编码器-解码器变压器，在合成的（输入，期望输出）音频示例对上训练，这些示例是通过将孤立的声音事件添加到密集的真实世界背景中形成的。研究发现，编辑描述中的每个部分（动作、类别、时间）都非常重要。该工作证明“重组”是一种重要的且实际的应用。", "conclusion": "我们的研究证明了“重组”在生成性音频编辑中是一种重要且实用的应用。这种方法通过编码器-解码器变压器工作在SoundStream表示形式上，依赖合成的（输入，期望输出）音频示例对进行训练，强调了编辑描述中的每个组成部分的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05249", "html_url": "https://arxiv.org/abs/2509.05249", "title": "COGITAO：研究组合性和泛化的视觉推理框架", "title_en": "COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization", "authors": "Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe", "background": "人类智能的关键在于能够组合已学概念并应用于新的情境，而现有的先进机器学习模型在这方面仍存在局限性。为了解决这一问题，研究人员提出了COGITAO，这是一个模块化且可扩展的数据生成框架和基准，旨在系统地研究视觉领域中的组合性和泛化能力。COGITAO借鉴了ARC-AGI提出的任务设定方法，构建了基于规则的任务，可以通过一组变换对网格环境中的对象进行操作，并支持以不同深度层次进行组合，同时提供对网格参数化和对象属性的广泛控制，从而生成数百万种独特的任务规则，涵盖了广泛难度水平的范围，且每种规则可以生成几乎无限的样本。实验结果表明，最先进的视觉模型在新的组合元素上存在一致的泛化失败，尽管在领域内表现强劲。COGITAO的所有代码和数据集均已开源，以支持该领域的进一步研究。", "innovation": "COGITAO通过系统地研究视觉领域的组合性和泛化能力，提供了一种模块化且可扩展的数据生成框架和基准。它支持通过规则进行任务设计，可生成大量具有广泛难度层次的任务规则，并能够对每种规则生成几乎无限的样本。此外，COGITAO的架构使得研究人员可以探索不同深度的组合能力，并提供了对网格参数化和对象属性的广泛控制。最后，使用最先进的视觉模型进行的基线实验展示了现有模型在泛化到新颖元素组合时的局限性。", "conclusion": "COGITAO证明了可以构建一个能够提高机器学习模型组合性和泛化能力的框架，并通过基线实验展示了当前最先进的视觉模型在新颖组合元素上的失败。该框架的开放性意味着它可用于支持继续在这个领域进行研究和探索。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05296", "html_url": "https://arxiv.org/abs/2509.05296", "title": "基于相机代数池的窗口式流式重建WinT3R", "title_en": "WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool", "authors": "Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He", "background": "以前的方法在重建质量和实时性能之间存在权衡。尽管早期的工作在精度方面有所提高，但往往牺牲了实时性能，反之亦然。本文旨在解决这一问题。", "innovation": "提出了WinT3R，这是一种前馈重建模型，能够进行实时预测，并重建准确的相机姿态和高质量的点云地图。模型通过引入滑动窗口机制，确保窗口内的帧之间的信息交换，提高了几何预测质量，同时保持了较少的计算量；同时，使用紧凑的相机表示方式，并维护一个全局相机代数池，增强了相机姿态估计的可靠性，且不牺牲效率。", "conclusion": "WinT3R在多种数据集上的实验结果显示，它能够在实时重建质量和速度方面达到最先进的性能，代码和模型已经在公开地址上提供。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.23903", "html_url": "https://arxiv.org/abs/2410.23903", "title": "使用PyRAT进行神经网络验证", "title_en": "Neural Network Verification with PyRAT", "authors": "Augustin Lemesle,Julien Lehmann,Tristan Le Gall", "background": "随着人工智能系统在各个关键领域（健康、交通、能源等）越来越受欢迎和普遍应用，确保其安全性和提供相应的信任保证变得不可或缺。为此，我们介绍了基于抽象诠释的工具PyRAT，用于验证神经网络的安全性和鲁棒性。", "innovation": "PyRAT通过不同的抽象方法找到了神经网络从输入开始可到达的所有状态，并提供了快速而准确的神经网络分析功能，已证明其性能。", "conclusion": "PyRAT已经在多个合作中被用于确保安全保证，其在VNN-Comp 2024中的第二名成绩展示了其性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.13501", "html_url": "https://arxiv.org/abs/2412.13501", "title": "GUI代理：综述", "title_en": "GUI Agents: A Survey", "authors": "Dang Nguyen,Jian Chen,Yu Wang,Gang Wu,Namyong Park,Zhengmian Hu,Hanjia Lyu,Junda Wu,Ryan Aponte,Yu Xia,Xintong Li,Jing Shi,Hongjie Chen,Viet Dac Lai,Zhouhang Xie,Sungchul Kim,Ruiyi Zhang,Tong Yu,Mehrab Tanjim,Nesreen K. Ahmed,Puneet Mathur,Seunghyun Yoon,Lina Yao,Branislav Kveton,Thien Huu Nguyen,Trung Bui,Tianyi Zhou,Ryan A. Rossi,Franck Dernoncourt", "background": "图形用户界面(GUI)代理，由大型基础模型驱动，已成为自动化人机交互的变革性方法。这些代理自主地通过GUI与数字系统或软件应用程序交互，模拟人类动作如点击、打字和导航视觉元素，适用于各种平台。", "innovation": "本文提供了一个全面的综述，分类整理了GUI代理的基准、评估指标、架构和训练方法。提出了一个统一框架来界定代理的感知、推理、规划和执行能力，并识别了重要的开放挑战和未来方向。", "conclusion": "本文为实践者和研究人员提供基础，有助于他们了解当前进展、技术、基准及尚未解决的关键问题。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.05265", "html_url": "https://arxiv.org/abs/2403.05265", "title": "MMoE: 使用多模态信息和领域感知混合专家的稳健剧透检测", "title_en": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts", "authors": "Zinan Zeng,Sen Ye,Zijian Cai,Heng Wang,Yuhan Liu,Haokai Zhang,Minnan Luo", "background": "在线电影评论网站对于获取和讨论电影信息是很有价值的，但其中大量的剧透评论影响了观影体验，因此剧透检测成为一项重要任务。前人方法仅关注评论的文本内容，忽视了平台上信息的异质性，例如评论的元数据和用户信息就很有可能提供有价值的信息。此外，电影评论中的剧透语言往往具有特定的类型属性，因此现有的方法在这方面的泛化能力存在挑战。", "innovation": "本文提出了一种多模态网络MMoE，该网络利用多种模态的信息来促进稳健的剧透检测，并采用Mixture-of-Experts架构以增强泛化能力。MMoE从用户-电影网络、评论文本内容及评论元数据中提取图形、文本和元特征，并采用Mixture-of-Experts架构处理三种模态的信息。最后，通过专家融合层将不同视角的特征进行整合并做出预测。实验结果表明，MMoE在两个广泛使用的剧透检测数据集上取得了最先进的性能，在准确性和F1得分方面分别优于之前的方法2.56%和8.41%。进一步的实验结果显示，MMoE在鲁棒性和泛化方面具有优越性。", "conclusion": "实验结果表明MMoE在两个广泛使用的剧透检测数据集上取得了最先进的性能，并在准确性和F1得分上超越了此前所有最先进的方法。此外，MMoE在鲁棒性和泛化方面也显示出优越性。相关代码已公开可用。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.09600", "html_url": "https://arxiv.org/abs/2408.09600", "title": "Antidote: 细调后的大语言模型安全保障对抗有害细调", "title_en": "Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning", "authors": "Tiansheng Huang,Gautam Bhattacharya,Pratik Joshi,Josh Kimball,Ling Liu", "background": "大型语言模型存在细调安全性的脆弱性，少量有害数据的混入就可能破坏模型的安全对齐。尽管已经有了一些防御措施，但现有的防御手段在某些特定的训练超参数选择下依然无效，例如，较大的学习率或较多的训练周期会轻易地使防御失效。", "innovation": "提出了一个名为Antidote的细调后解决方案，能够保持对训练超参数的无感知，它通过去除有害参数来恢复有害模型的行为，引入了一次性剪枝阶段来去除导致有害内容生成的有害权重，这种哲学在实践中表现出色，能减少有害度评分同时维持下游任务的准确性。", "conclusion": "实验证明，Antidote能够在保持下游任务性能的同时降低有害性评分。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01733", "html_url": "https://arxiv.org/abs/2504.01733", "title": "论题技能：关于知识与遗忘的推理", "title_en": "Epistemic Skills: Reasoning about Knowledge and Oblivion", "authors": "Xiaolong Liang,Yì N. Wáng", "background": "本文探讨了一类描述知识获取和遗忘动态过程的公理逻辑，同时将群体知识的概念纳入考虑。该方法基于加权模型体系，通过引入“知识技能”度量来表示与知识更新相关的认识能力。在这一框架下，知识获取被建模为一种技能提升过程，而遗忘则表现为技能下降的结果。此外，该框架还允许探讨“可获知性”和“可遗忘性”，分别是通过技能提升获得知识和通过技能下降进入遗忘的可能性。文章进一步分析了形式意义下关于知识具体内容与表层意义的区别。", "innovation": "提出了一类融合了“知识技能”概念的公理逻辑，用于描述知识获取、遗忘等动态过程，并基于加权模型引入了知识技能的度量方法。这种方法不仅刻画了知识通过技能提升与遗忘，而且还支持对认识表达的差别进行详细分析，从而提供了对认识论问题的新视角。", "conclusion": "文章进一步探讨了该模型检查和满足性问题的计算复杂性，揭示了其理论基础和实践应用，并指出通过改进技能评估和管理方法可以优化知识不断提升与遗忘管理的战略。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15937", "html_url": "https://arxiv.org/abs/2503.15937", "title": "推进移动GUI代理：实用部署的验证驱动方法", "title_en": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment", "authors": "Gaole Dai,Shiqi Jiang,Ting Cao,Yuanchun Li,Yuqing Yang,Rui Tan,Mo Li,Lili Qiu", "background": "移动代理通常使用大型语言模型（LLMs）直接生成操作，但这种方法在每个步骤中存在效率低下的问题。该研究提出了一个名为V-Droid的新颖验证驱动移动GUI任务自动化代理。V-Droid使用LLMs作为验证器在做出最终决策之前评估候选操作。研究者构建了一个综合框架，包括操作空间离散化构建、仅预填充的工作流加速验证过程、成对进度偏好训练以显著提高验证器的决策能力、以及可扩展的人机联合标注方案以高效地大规模收集数据。", "innovation": "V-Droid提出了一种新颖的验证驱动方法，不同于以往利用大型语言模型直接生成操作的代理。V-Droid用于评估候选操作，而不直接生成操作。研究团队还构建了一个包含操作空间离散化构建、仅预填充的工作流、成对进度偏好训练以及可扩展的人机联合标注方案的综合框架，旨在提高验证过程的效率和验证器的决策能力。", "conclusion": "V-Droid在多个公共移动任务自动化基准测试中取得了显著的成功率：在AndroidWorld上为59.5%，在AndroidLab上为38.3%，在MobileAgentBench上为49%，分别优于现有代理5.2%、2.1%和9%。此外，V-Droid还实现了4.3秒/步骤的极低延迟，比现有移动代理快6.1倍。源代码可在提供的链接中获取。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06020", "html_url": "https://arxiv.org/abs/2505.06020", "title": "ArtRAG：结构化上下文增强生成理解视觉艺术", "title_en": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding", "authors": "Shuai Wang,Ivona Najdenkoska,Hongyi Zhu,Stevan Rudinac,Monika Kackovic,Nachoem Wijnberg,Marcel Worring", "background": "理解视觉艺术需要从文化、历史和风格等多方面进行推理，而不仅仅是简单的图像识别。虽然近期的多模态大型语言模型（MLLMs）在通用图像描述方面表现良好，但它们往往无法捕捉到细艺术所要求的细腻解释。现有的基线模型尽管经过大量训练，但在生成包含文化背景和支持的细致艺术描述方面仍然表现不佳。", "innovation": "本文提出了ArtRAG，一种新颖的无需训练的框架，结合结构性知识与检索增强生成（RAG），用于实现多视角艺术品解释。ArtRAG 自动从领域特定的文本来源构建一个艺术品上下文知识图（ACKG），组织诸如艺术家、流派、主题和历史事件等内容为一个丰富且可解释的图。在推理阶段，多粒度结构检索器选择语义和拓扑上相关的子图以指导生成过程。这使得MLLM能够生成背景贴切、文化丰富且有洞察力的艺术描述。", "conclusion": "实验表明，ArtRAG 在SemArt和Artpedia数据集上的表现优于几个高度训练的基线。进一步的人类评估证实，ArtRAG 能够生成连贯、深刻且文化丰富的艺术品解读。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05748", "html_url": "https://arxiv.org/abs/2408.05748", "title": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation", "title_en": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation", "authors": "Xiaoxiong Zhang,Zhiwei Zeng,Xin Zhou,Zhiqi Shen", "background": "FKGE旨在通过多客户端的分布式知识图谱来协作学习实体和关系嵌入，同时保护数据隐私。虽然高维嵌入有助于提高性能，但它们在存储资源和推理速度方面也带来挑战。现有适用于传统知识图谱的嵌入压缩方法可能不直接适用于FKGE，因为这些方法往往需要多次模型训练，这可能增加通信成本。现有方法在客户端侧本地训练过程中，使用KL散度损失使低维学生模型模仿高维教师模型的三元组评分分布。FedKD通过动态调整KD损失的权重来优化训练过程，以适应性地学习一个温度来缩放正三元组的评分，并分别调整对应的负三元组的评分，从而缓解教师过自信的问题。", "innovation": "该研究提出了一种基于知识蒸馏(FedKD)的知识轻量化组件，专门用于FKGE方法。在客户端本地训练过程中，利用KL散度损失，使得低维度的学生模型模拟高维度教师模型中三元组的评分分布。不同于传统的知识蒸馏方法，FedKD能够自适应地学习一个温度来缩放正三元组的评分，并独立调整相应的负三元组的评分，从而减轻教师过自信的问题。同时，动态调整KD损失的权重以优化训练过程。", "conclusion": "实验结果表明FedKD的有效性。通过在三个数据集上的广泛实验支持了该方法在低维FKGE中的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07173", "html_url": "https://arxiv.org/abs/2506.07173", "title": "使用ChatGPT将Python中的联邦学习算法翻译为CSP进程", "title_en": "Translating Federated Learning Algorithms in Python into CSP Processes Using ChatGPT", "authors": "Miroslav Popovic,Marko Popovic,Miodrag Djukic,Ilija Basicevic", "background": "该论文介绍了为机器学习和人工智能开发者提供的Python联邦学习（FL）框架，该框架易于使用且无需专业编程技能，并且能够适应大规模语言模型（LLMs）。此前的研究中，该框架提供的通用联邦学习算法被手动翻译成CSP进程，并使用模型检查器PAT自动验证算法的安全性和活动性属性。", "innovation": "本文提出了一种简单的翻译过程，在这一过程中使用了ChatGPT来自动化将Python中的联邦学习算法翻译成相应的CSP进程。过程中根据ChatGPT的反馈估算所用上下文的最小性。并通过模型检查器PAT验证翻译的成功，实验性地验证了包括集中式和去中心化在内的通用联邦学习算法的翻译。", "conclusion": "提出的翻译过程通过成功使用PAT验证了Python中的通用联邦学习算法在ChatGPT的帮助下自动翻译为CSP进程的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00008", "html_url": "https://arxiv.org/abs/2507.00008", "title": "DiMo-GUI：通过模态意识视觉推理提升GUI定位测试时扩展性", "title_en": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "authors": "Hang Wu,Hongkai Chen,Yujun Cai,Chang Liu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "GUI（图形用户界面）中的自然语言查询接地(ji地)面临着独特的挑战，因为视觉元素多样、空间杂乱以及语言的歧义性。传统的单一图像处理方法难以有效应对这些挑战。", "innovation": "DiMo-GUI框架无需训练，通过动态视觉接地和模态感知优化两大策略，将输入拆分为文本元素和图标元素，使用通用的视觉-语言模型分别推理。对于预测不明确或错误的部分，DiMo-GUI动态聚焦关注区域，逐步放大详细区域以细化接地结果。这种方法不需要额外的训练或注释，即可帮助解决视觉拥挤布局的歧义性。", "conclusion": "该方法在标准GUI定位基准测试中表现出显著的改进，展示了模态分离与区域聚焦推理相结合的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.20541", "html_url": "https://arxiv.org/abs/2507.20541", "title": "MeLA: 一种用于自动启发式设计的认知元驱动大模型架构", "title_en": "MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic Design", "authors": "Zishang Qiu,Xinan Chen,Long Chen,Ruibin Bai", "background": "传统的进化方法直接作用于启发式代码；相比之下，MeLA通过推动一个大型语言模型（LLM）生成启发式代码的指令提示来进行启发式设计的进化。", "innovation": "MeLA提出了一种新的元认知架构，通过分析性能反馈来系统地优化生成策略，并结合了一个问题分析器、一个错误诊断系统以及一个用于迭代优化提示的元认知搜索引擎。实验结果显示，MeLA生成的启发式规则更有效且更稳健，显著优于现有最佳方法。", "conclusion": "这项研究展示了使用认知科学作为AI架构蓝图的深远潜力，表明通过让LLM元认知地调节其问题解决过程，可以找到一条更稳健和可解释的AHD路径。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05238", "html_url": "https://arxiv.org/abs/2509.05238", "title": "不确定但有用：将CNN的可变性转化为数据增强", "title_en": "Uncertain but Useful: Leveraging CNN Variability into Data Augmentation", "authors": "Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Yohan Chatelain,Tristan Glatard", "background": "深度学习（DL）通过实现最先进的性能和缩短计算时间，迅速推动了神经影像学的发展。然而，DL模型在训练过程中的数值稳定性仍然没有得到充分探索。虽然在推理中DL模型相对稳定，但在训练过程中引入了额外的变异性，主要是通过迭代的随机优化。本研究使用基于CNN的全脑分割pipeline——FastSurfer，来研究这种在训练过程中的变异性。", "innovation": "引入精确浮点数扰动和随机种子，控制地引入变异性；发现FastSurfer表现出更高变异性，表明DL继承并特别容易受到其前身存在的不稳定来源的影响；扰动生成的集成达到了与非扰动基线相似的性能；变异有效产生了可用于下游应用的数值模型家族的集成；作为概念验证，展示了数值集成作为用于大脑年龄回归的数据增强策略的可行性；揭示训练过程中的变异性不仅是可重现性问题，还是一种可以利用的资源，以提高鲁棒性和在神经影像学中启用新应用的能力。", "conclusion": "本研究不仅将训练过程中的变异性定位为一个可重现性关注点，还将其视为一种资源，可以用来提高鲁棒性和启用神经影像学中的新应用。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05528", "html_url": "https://arxiv.org/abs/2507.05528", "title": "大规模对话教育：一种用于程序性学习和教育质量评估的多大型语言模型代理工作流", "title_en": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "authors": "Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang", "background": "现有的大型语言模型（LLMs）已经在虚拟教育者和学习者之间建立了一座桥梁，结合了自然语言处理（NLP）和AI4Education。然而，现有工作通常在扩展性和利用多种大规模课程内容方面存在不足，并且缺乏评估教学质量的框架。", "innovation": "该论文提出了一种名为WikiHowAgent的多代理工作流，利用LLMs模拟互动的教学-学习对话。它整合了教师和学习者代理、交互管理器和评估器，以促进程序性学习和评估教学质量。此外，还构建了一个包含114,296个教师-学习者对话的大型数据集，这些对话基于14,287个教程，覆盖17个领域和727个主题。", "conclusion": "实验结果表明，此工作流在多种场景下具有有效性，提供了关于LLMs能力的新见解。数据集和实现均完全开源。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14387", "html_url": "https://arxiv.org/abs/2506.14387", "title": "保持它别瞎编：在大语言模型微调中保持无知意识", "title_en": "Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning", "authors": "William F. Shen,Xinchi Qiu,Nicola Cancedda,Nicholas D. Lane", "background": "现有工作主要集中在通过微调大型语言模型（LLMs）来保留对以前数据的表现，而忽视了关键的对齐能力的坍塌，特别是模型忠实表达认识论不确定性（我们称之为‘无知意识’）的能力。研究发现，传统微调方法可能导致显着的激活位移，这损害了对无知意识的关键能力，导致诸如幻觉等不良行为。", "innovation": "本文提出了SEAT，这是一种简单且有原则的微调方法，能够使模型不仅有效获取新的知识实例，还保留其对齐的无知意识。SEAT结合了两个关键组件：约束激活偏移的稀疏微调和针对知识纠缠设计的新型实体扰动方法。实验结果显示，SEAT在保留无知意识和保持微调性能方面显著优于基线，为LLM微调提供了更稳健的解决方案。", "conclusion": "SEAT在多个真实世界和合成数据集上都显著优于现有基线方法，证明了其在保持无知意识并保持微调性能方面的有效性，为满足大型语言模型的需求提供了更可靠的微调解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16172", "html_url": "https://arxiv.org/abs/2508.16172", "title": "图RAG作为人类选择模型：利用偏好链构建数据驱动的移动代理", "title_en": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain", "authors": "Kai Hu,Parfait Atchade-Adelomou,Carlo Adornetto,Adrian Mora-Carrero,Luis Alonso-Pastor,Ariel Noyman,Yubo Liu,Kent Larson", "background": "在城市科学领域，理解人类行为至关重要。然而，在新开发区域收集准确的行为数据面临显著挑战。近期，由大规模语言模型（LLMs）驱动的生成代理显示出通过不依赖大量数据进行行为模拟的潜力，但这些方法通常难以生成一致、上下文相关和实际的行为输出。", "innovation": "本文提出了一种创新方法——偏好链，它将图检索增强生成（RAG）与LLMs相结合，增强了在交通系统中人类行为的上下文感知模拟。实验展示了偏好链在与实际交通模式选择匹配方面优于标准LLM。此方法为数据稀缺环境中模拟复杂的人类行为提供了有前景的框架。", "conclusion": "尽管存在推理速度慢和生成虚假信息的风险，偏好链方法仍然提供了一种在数据匮乏环境下模拟复杂人类行为的有前景框架，尤其是在传统数据驱动模型因数据有限而难以发挥作用的情况下，此方法可以在新兴城市的出行建模、个性化出行行为分析和动态交通预测等方面有所应用。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02544", "html_url": "https://arxiv.org/abs/2509.02544", "title": "UI-TARS-2技术报告：借助多轮强化学习提升图形用户界面代理", "title_en": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "authors": "Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Aoyan Li,Bo Li,Chen Dun,Chong Liu,Daoguang Zan,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Shulin Xin,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qi Liu,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Yaohui Wang,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Qihua Han,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du", "background": "图形用户界面（GUI）自主代理的发展在人工智能中面临重大挑战。虽然最近原生代理模型的进步通过端到端学习统一了感知、推理、行动和记忆，但仍存在数据可扩展性、多轮强化学习（RL）中的问题、GUI单纯操作的局限性和环境稳定性等开放问题。", "innovation": "UI-TARS-2是一种以GUI为中心的原生代理模型，通过系统训练方法解决上述挑战：一个数据飞轮以实现可扩展的数据生成、一个稳定的多轮RL框架、一个集成文件系统和终端的混合GUI环境，以及一个统一的大规模沙箱平台。实验评估表明UI-TARS-2相较于前一代UI-TARS-1.5实现了显著改进。UI-TARS-2在GUI基准上的表现优于Claude和OpenAI的基线模型，还在游戏环境中达到了接近60%的人类水平性能。", "conclusion": "UI-TARS-2在长周期信息查询任务和软件工程基准方面展现出泛化能力，进一步的研究揭示了在大规模代理RL中实现稳定性和效率的方法，显示了UI-TARS-2在GUI代理领域的潜在进步空间并展现了其对真实交互场景的强大泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.16019", "html_url": "https://arxiv.org/abs/2312.16019", "title": "生存分析中的对抗性正则化", "title_en": "Survival Analysis with Adversarial Regularization", "authors": "Michael Potter,Stefano Maxenti,Michael Everett", "background": "生存分析（SA）模型用于预测事件发生的时间，在医学、国防、金融和航空航天等领域有广泛应用。近年来的研究表明，神经网络（NN）能够有效地捕捉SA中的复杂数据模式，而简单的广义线性模型在这一方面通常表现不佳。然而，数据集中的不确定性（例如噪声测量、人为错误）会降低NN模型的性能。", "innovation": "本文提出了一种基于对抗性正则化的生存分析方法，通过利用神经网络验证的最新进展，开发了鲁棒的、全参数化生存分析模型。具体来说，提出了一种基于最小-最大优化问题的对抗性鲁棒损失函数，并使用CROWN-Interval Bound Propagation（CROWN-IBP）来解决由此产生的计算挑战。实验结果表明，Survival Analysis with Adversarial Regularization（SAWAR）方法在各种协变量扰动下，在负对数似然（NegLL）、集成比尔预测评分（IBS）和一致性指数（CI）指标上，均优于基线对抗训练方法和最先进的（SOTA）深度生存分析模型。", "conclusion": "我们证明了对抗性鲁棒性可以提高生存分析的预测性能和校准性，通过减少数据不确定性并提升各种数据集的泛化能力最多可达150%。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20368", "html_url": "https://arxiv.org/abs/2508.20368", "title": "AI-SearchPlanner: 基于帕累托最优多目标强化学习的模块化智能搜索", "title_en": "AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning", "authors": "Lang Mei,Zhihan Yang,Chong Chen", "background": "近年来，研究关注将大型语言模型（LLMs）与搜索引擎结合，以利用LLMs的预训练知识和外部信息。特别是，强化学习（RL）作为一种增强LLM推理能力的有效方法已经引起了广泛关注，尤其是通过多轮与搜索引擎的互动。然而，现有的基于RL的搜索引擎代理依赖单一的LLM来同时处理搜索规划和问答（QA）任务，这限制了其同时优化两者能力的能力。实践中，复杂的AI搜索引擎通常使用一个大型但固定的LLM（例如GPT-4, DeepSeek-R1）以确保高质量的回答，因此更有效和高效的方法是利用一个小型可训练的LLM专注于搜索规划。", "innovation": "本文提出了一种名为AI-SearchPlanner的新颖的强化学习框架，旨在通过专注于搜索规划来提升固定QA模型的性能。该方法提出了三方面创新：1) 搜索规划者和生成器架构的解耦；2) 搜索规划的双重奖励对齐；3) 计划效用和成本的帕累托优化。实验结果表明，AI-SearchPlanner在有效性和效率两个方面均优于现有的基于RL的搜索代理，并具有在不同固定QA模型和数据领域上的广泛应用能力。", "conclusion": "AI-SearchPlanner在实际数据集上进行了广泛实验，结果表明其在有效性和效率方面超过了现有的基于RL的搜索代理，同时在多个固定QA模型和数据领域中展示了强大的泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01920", "html_url": "https://arxiv.org/abs/2509.01920", "title": "动态推测性代理规划", "title_en": "Dynamic Speculative Agent Planning", "authors": "Yilin Guan,Wenyue Hua,Qingfeng Lan,Sun Fei,Dujian Ding,Devang Acharya,Chi Wang,William Yang Wang", "background": "尽管基于大型语言模型的代理在复杂任务上取得了显著成功并推动了广泛应用，但仍面临着关键的部署挑战，如延迟高和推理成本高昂。虽然近期有研究探索了加速推理的方法，但现有方法存在诸多局限性：要么牺牲了性能的准确性，要么需要进行大量的离线训练以准备路由器模块，要么导致了过高的运营成本。除此之外，现有的方法并没有给用户调整加速与性能指标之间权衡的空间。为了解决上述问题，我们提出了动态推测性规划（DSP），这是一种异步的在线强化学习框架，能够在不增加额外预部署准备的情况下实现无损加速并大幅降低成本。DSP显式地优化了端到端延迟与美元成本之间的联合目标，允许实践者通过单一参数来调整系统以实现更快的响应、更便宜的运营，或在这两者间任何一点的平衡。", "innovation": "我们提出了动态推测性规划（DSP），这是一种异步的在线强化学习框架，能够在不增加额外预部署准备的情况下实现无损加速并大幅降低成本。DSP显式地优化了端到端延迟与美元成本之间的联合目标，允许实践者通过单一参数来调整系统以实现更快的响应、更便宜的运营，或在这两者间任何一点的平衡。DSP确保了可以在不牺牲性能准确性的前提下，实现大幅度的成本节省，并且提供了用户对加速与性能指标之间权衡的更多控制。", "conclusion": "我们在两个标准代理基准测试中进行的实验表明，DSP在效率上与最快的无损加速方法相当，可以将总成本降低30%，并将不必要的成本最多可降低60%。我们的代码和数据可通过提供了一个链接来访问。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05276", "html_url": "https://arxiv.org/abs/2509.05276", "title": "SpikingBrain 技术报告：基于大脑启发的大模型", "title_en": "SpikingBrain Technical Report: Spiking Brain-inspired Large Models", "authors": "Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li", "background": "主流的基于Transformer的大语言模型面临着效率瓶颈：训练计算量随着序列长度成平方级增长，推理内存随长度线性增长，限制了处理长语境的能力。在非NVIDIA平台上构建大型模型也带来了挑战，影响了稳定和高效的训练。为解决这些问题，本文介绍了一种称为SpikingBrain的基于大脑启发的模型系列，用于提高长语境训练和推理效率。", "innovation": "SpikingBrain通过以下三个方面实现了这一目标：（1）模型架构：采用线性和混合线性注意力架构，具有自适应尖峰神经元；（2）算法优化：高效的转换式训练管道和专门的尖峰编码框架；（3）系统工程：定制化的训练框架、操作库和并行策略，针对MetaX硬件。本文提出的技术包括两种模型：SpikingBrain-7B（线性大语言模型）和SpikingBrain-76B（混合线性MoE大语言模型）。这些模型展示了在非NVIDIA平台上开发大规模大语言模型的可能性。SpikingBrain在保持性能接近开源Transformer基线的同时，仅使用约150B tokens进行持续预训练。模型在长序列训练效率方面取得了显著提升，在推理中实现部分常量内存和事件驱动的尖峰行为。例如，SpikingBrain-7B在4M-token序列上的第一个Token时间获得了100多倍的加速。同时，训练在数百个MetaX C550 GPU上保持数周的稳定，7B模型的Model FLOPs利用率达到23.4%。提出的方法实现了69.15%的稀疏性，从而使低功耗操作成为可能。", "conclusion": "总体而言，这项工作证明了基于大脑机制在构建下一代高效可扩展的大规模模型设计中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03728", "html_url": "https://arxiv.org/abs/2509.03728", "title": "PersonaTeaming: 探索引入人物形象如何提高自动化AI红队", "title_en": "PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming", "authors": "Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys", "background": "近期关于AI治理和安全的研究进展提升了对有效识别AI模型潜在风险的红队方法的需求。这些研究强调了红队成员的身份和背景如何影响其红队策略，从而影响他们发现的风险类型。虽然自动化红队方法能够通过更大规模地探索模型行为来补充人类红队，但现有的方法并未考虑到身份的作用。因此，本文开发了一种名为PersonaTeaming的新方法，通过在对抗性提示生成过程中引入人物形象，来探索更广泛的对抗策略范围。", "innovation": "本文创新地提出了一种名为PersonaTeaming的新方法，在自动化红队过程中引入了人物形象。该方法首先提出了基于“红队专家”或“普通AI用户”人物形象的提示突变方法，然后开发了一种动态人物生成算法，能够自动生成各种适应不同种子提示的人像类型。此外，还开发了一套新的度量标准来明确衡量“突变距离”，以补充现有的对抗性提示多样性的度量。实验结果显示，人物突变方法能够显著提高对抗性提示的攻击成功率（最高可达144.1%），同时保持提示多样性，相较于现有的先进自动化红队方法RainbowPlus，表明这种方法具有显著的优势。", "conclusion": "本文讨论了不同人物类型和突变方法的优缺点，为进一步探索自动化红队和人类红队方法的互补性提供了洞见。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2208.09677", "html_url": "https://arxiv.org/abs/2208.09677", "title": "Net2Brain: 一个将人工视觉模型与人类大脑反应进行比较的工具箱", "title_en": "Net2Brain: A Toolbox to compare artificial vision models with human brain responses", "authors": "Domenic Bersch,Kshitij Dwivedi,Martina Vilas,Radoslaw M. Cichy,Gemma Roig", "background": "目前市面上有许多工具箱可以实现单一功能或只专注于监督图像分类模型的一个小部分。Net2Brain 则允许用户从超过600个不同的深度神经网络中提取激活值，这些网络训练执行多种视觉相关任务（例如语义分割、深度估计、动作识别等），并且可以在图像和视频数据集上运行。该工具箱计算这些激活值的代表差异矩阵（RDMs），并通过代表相似性分析（RSA）、加权RSA等方式与大脑记录进行比较，适用于特定区域（ROI）和搜索光搜索方法。此外，用户还可以向工具箱添加新的刺激和大脑记录数据集进行评估。", "innovation": "Net2Brain 提供了一个新颖且全面的界面，包括图形界面和命令行界面，能够同时比较人工深度神经网络和人类大脑记录。相比于现有的工具箱，Net2Brain 允许用户处理更广泛的视觉任务和不同的数据集，同时计算复杂的代表相似性和比较方法。这种工具箱为认知计算神经科学的假说测试提供了强有力的工具。", "conclusion": "通过展示功能性及Net2Brain 在认知计算神经科学中的应用实例，该论文证明了这个新工具箱的有效性和先进性，能够帮助研究人员更好地理解人类大脑和人工视觉模型之间的关系。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.14295", "html_url": "https://arxiv.org/abs/2401.14295", "title": "揭开思考链、树和图的谜团", "title_en": "Demystifying Chains, Trees, and Graphs of Thoughts", "authors": "Maciej Besta,Florim Memedi,Zhenyu Zhang,Robert Gerstenberger,Guangyuan Piao,Nils Blach,Piotr Nyczyk,Marcin Copik,Grzegorz Kwaśniewski,Jürgen Müller,Lukas Gianinazzi,Ales Kubicek,Hubert Niewiadomski,Aidan O'Mahony,Onur Mutlu,Torsten Hoefler", "background": "自然语言处理（NLP）领域近年来取得了显著进步，特别是在通过创新的提示技术提高大型语言模型（LLM）性能方面。在这些方法中，结合结构的提示工程已经成为一个有前途的方法，例如Chain-of-Thought、Tree of Thoughts或Graph of Thoughts，这类方法通过结构如图来引导LLM的整体推理过程，从而显著提高了LLM解决各种任务的能力，包括逻辑或数学推理、规划或创意写作等。", "innovation": "本文构建了结构增强的LLM推理方案的第一项分类，并定义了不同的概念，识别了关键的结构类别及其表示方式，并分析了相关的算法。通过这种方式，本文提出了一个新的框架来理解现有的提示方案，探讨了设计选择如何影响性能和成本，并探讨了提示与知识库等其他LLM生态系统部分之间的关系及其研究挑战。", "conclusion": "本文的研究将有助于推进未来的提示工程技术发展。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.15164", "html_url": "https://arxiv.org/abs/2405.15164", "title": "从弗雷格到chatGPT：语言、认知与深度神经网络中的组合性", "title_en": "From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks", "authors": "Jacob Russin,Sam Whitman McGrath,Danielle J. Williams", "background": "组合性被长期认为是人类智能的关键解释属性：任意的概念可以通过组合形成新颖复杂的组合，从而通过有限的学习经验获得开放的、潜在无限的表现能力。有影响力的观点认为神经网络无法解释这种行为，导致许多人认为它们不是人类认知的有效模型。然而，在过去十年中，现代深度神经网络（DNNs），在设计原则上与之前的技术相同，已经主导了人工智能领域，展示出了机器中前所未有的最先进认知行为。特别是大型语言模型（LLMs），通过预测大规模文本语料库中的下一个单词进行训练，已经能够表现出复杂的语言处理能力，比如写作语法正确的复杂句子，产生逻辑连贯的理由链，甚至编写原创的计算机程序——所有这些行为被认为需要组合处理。", "innovation": "本章回顾了近期机器学习中的实证工作，针对哲学、认知科学和神经科学广泛受众，将最近的突破置于关于组合性的更广泛的哲学讨论中。特别地，本章强调了赋予神经网络组合泛化的两种方法：（1）架构归纳偏置，（2）元学习，或学习如何学习。本章还提出了关于LLM预训练可以被视为一种元学习形式的观点，从而能够在类似程度上装备DNNs组合泛化能力。讨论了这些发现对于研究人类认知中的组合性的意义，并提出了未来研究的方向。", "conclusion": "这些发现可能对人类认知中的组合性研究具有重要意义，并为未来研究指明了方向。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.09337", "html_url": "https://arxiv.org/abs/2407.09337", "title": "CFaults: 基于模型诊断的C语言多测试案例故障定位方法", "title_en": "CFaults: Model-Based Diagnosis for Fault Localization in C Programs with Multiple Test Cases", "authors": "Pedro Orvalho,Mikoláš Janota,Vasco Manquinho", "background": "软件开发中调试是最耗时和昂贵的任务之一。虽然已经提出了几种基于公式的故障定位（FBFL）方法，但它们无法保证在所有失败的测试中提供一组诊断，或者可能会提供冗余诊断，尤其是在存在多个故障的程序中，这些冗余诊断不是子集最小的。因此，迫切需要一种新的方法来解决这些挑战。本论文旨在为C语言多故障程序提供一种新的故障定位方法。", "innovation": "CFaults 引入了一种基于模型诊断（MBD）的新方法，它利用了多个观察结果，并将所有的失败测试案例整合到一个统一的MaxSAT公式中。这种方法确保了观察结果的一致性，简化了故障定位过程，并且仅生成故障语句的子集最小诊断，而不是列举冗余诊断。通过在TCAS和C-Pack-IPAs两个基准集上的实验结果表明，CFaults 比其他FBFL方法如BugAssist和SNIPER更快。", "conclusion": "CFaults 方法提高了复杂C程序的故障定位效率，通过优化诊断过程，能够提供精确且更少冗余的诊断结果。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.16299", "html_url": "https://arxiv.org/abs/2409.16299", "title": "HyperAgent: 具备解决大规模编码任务能力的通用型软件工程代理", "title_en": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale", "authors": "Huy Nhat Phan,Tien N. Nguyen,Phong X. Nguyen,Nghi D. Q. Bui", "background": "大型语言模型（LLMs）已经极大地改变了软件工程（SE），展示了在多种编码任务中出色的技能。尽管最近的技术进步使得能够利用LLMs创建自主的软件代理来完成端到端的开发任务，但这些系统通常只为特定的SE功能设计。HyperAgent是一个创新的多代理系统，旨在解决不同编程语言中的广泛SE任务，模仿人类开发者的流程。", "innovation": "HyperAgent 特别之处在于它是一个通用的多代理系统，能够处理SE任务的整个生命周期，从最初的规划到最后的验证。HyperAgent 配备了四种专门的智能体：Planner（规划者）、Navigator（导航者）、Code Editor（代码编辑器）和Executor（执行器）。该系统在各种SE任务中表现出色，包括在SWE-Bench基准测试中的GitHub问题解决，以及在RepoExec和Defects4J中的仓库级代码生成和故障定位、程序修复，其中经常超越最先进的基准。", "conclusion": "HyperAgent 在多个关键SE任务中设定了新的基准，展示了其在大规模编码任务上的出色性能，特别在解决这些问题时超过了其他基准系统。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.11686", "html_url": "https://arxiv.org/abs/2409.11686", "title": "通过机会成像自动检测未诊断的医疗条件", "title_en": "Automated detection of underdiagnosed medical conditions via opportunistic imaging", "authors": "Asad Aali,Andrew Johnston,Louis Blankemeier,Dave Van Veen,Laura T Derry,David Svec,Jason Hom,Robert D. Boutin,Akshay S. Chaudhari", "background": "腹部计算机断层扫描（CT）在临床环境中经常进行。机会性CT是指将常规CT图像重新用于提取诊断信息的工具，正在成为检测未诊断条件如肌肉减少症、肝脏脂肪变性和腹水的有效手段。本研究利用深度学习方法促进准确的诊断和临床记录。研究分析了2,674份住院CT扫描，以识别影像表型（由机会性CT扫描得出的特征）与其对应的放射学报告和ICD编码之间的差异。研究发现，通过机会性成像或放射学报告诊断肌肉减少症、肝脏脂肪变性或腹水的扫描中，仅有0.5%、3.2%和30.7%的扫描在ICD编码中有相关记录。这一发现表明了机会性CT在提高诊断精确度和风险调整模型准确性方面的潜力，有助于精准医学的进步。", "innovation": "本文创新性地利用深度学习技术分析机会性CT图像与放射学报告及ICD编码之间的差异，旨在改善未诊断医疗条件的检测精度和准确性，特别是在肌肉减少症、肝脏脂肪变性和腹水的诊断方面展现出潜在的应用价值。", "conclusion": "机会性CT在提高诊断精确度和风险调整模型准确性方面具有巨大潜力，有助于在精准医学领域取得进展。但目前仅有小部分检测到的病理情况被ICD编码所记录，这表明当前的编码系统可能无法充分捕捉机会性CT中的信息，需要进一步改进。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13676", "html_url": "https://arxiv.org/abs/2508.13676", "title": "MHSNet：基于MoE的层次语义表示网络，用于具有大规模语言模型的准确简历重复检测", "title_en": "MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model", "authors": "Yu Li,Zulong Chen,Wenjian Xu,Hong Wen,Yipeng Yu,Man Lung Yiu,Yuyu Yin", "background": "为了保持公司的候选人才库，招聘人员需要从第三方网站（如LinkedIn、Indeed）持续搜索简历。然而，获取的简历往往不完整且不准确，这降低了候选人质量。因此，需要在获取的简历与公司已有的人才库中进行复制检测，以提高简历质量并丰富人才库。但是，简历文本具有语义复杂性、结构异质性以及信息不完整性，使得复制检测非常具有挑战性。现有方法难以处理这种复杂性，特别是在面对大量数据时更为困难。因此，本文提出了MHSNet，一种用于精确简历重复检测的多层次身份验证框架，它利用对比学习微调BGE-M3。通过微调后的Mixture-of-Experts (MoE)可以生成多级稀疏和密集表示，从而计算对应的不同层次的语义相似性。此外，MHSNet采用了状态感知的Mixture-of-Experts (MoE)，能够处理各种不完整的简历，从而确保检测的准确性。实验验证了MHSNet的有效性，表明它在处理语义复杂性、结构异质性和信息不完整性方面具有较好的性能。", "innovation": "文章提出了一种基于多层次身份验证框架的MHSNet，利用对比学习微调BGE-M3，采用Mixture-of-Experts (MoE)生成多级稀疏和密集表示，用于简历的语义相似性计算和重复检测。同时，引入状态感知的Mixture-of-Experts (MoE)来处理各种不完整的简历，提升系统的鲁棒性和检测精度。这种方法有效地解决了简历文本的复杂性和不完整性问题，能够在大规模数据集上实现高效且准确的简历重复检测。与传统方法相比，MHSNet在处理多样性和不完整信息方面表现更佳。", "conclusion": "综合实验结果，MHSNet在简历重复检测任务上表现出较高的精度和稳定性，能够有效处理复杂且不完整的简历文本。本文提出的MHSNet框架，通过多层次表示学习和适应不完整数据的状态感知Mixture-of-Experts，为简历自动化筛选提供了一种有效解决方案，有助于提高企业和招聘人员的工作效率及准确性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.18416", "html_url": "https://arxiv.org/abs/2407.18416", "title": "PersonaGym：评估 Persona 代理和大语言模型", "title_en": "PersonaGym: Evaluating Persona Agents and LLMs", "authors": "Vinay Samuel,Henry Peng Zou,Yue Zhou,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Ameet Deshpande,Karthik Narasimhan,Vishvak Murahari", "background": "Persona 代理是由特定人设条件化的大型语言模型（LLM）代理，能够跨教育和医疗等领域提供丰富且用户对齐的交互。然而，在自由形式的设置中，确保这些代理在多种相关环境中保持一致性的能力评估仍然是一个重大挑战。本文探讨了10款领先的LLM在200个人设和10,000个问题上的表现，揭示了现有的性能差距，强调了对算法和架构创新的需求，以提升人设代理的忠实度和性能。", "innovation": "本文提出了PersonaGym，首个动态评估人设代理的框架，以及基于决策理论的人类对齐自动指标PersonaScore，这使得大规模的人设代理评估成为可能。这项研究表明，更新且更复杂的模型并不必然能提升人设代理的能力，这凸显了算法和架构创新的重要性。例如，GPT-4.1和LLaMA-3-8b在 PersonaScore 上得分相同，尽管前者是更先进的闭源模型。", "conclusion": "研究结果表明，模型规模和复杂性并不总是提升人设代理能力的关键因素，强烈建议探索算法和架构创新，以实现更忠实和高效的性能人设代理。PersonaGym框架和PersonaScore指标为该领域提供了重要的评估工具，推动了工具和方法的发展。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.19835", "html_url": "https://arxiv.org/abs/2407.19835", "title": "ATHAR：古典阿拉伯语到英语高质量和多样化的数据集", "title_en": "ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation", "authors": "Mohammed Khalil,Mohammed Sabry", "background": "古典阿拉伯语在阿拉伯文化和科学方面的重要时期标志着黄金时代。普惠的文化知识传播需要将这些文学作品翻译成多种语言。尽管大型语言模型（LLMs）和翻译系统的出现提供了帮助工具，但目前缺乏全面覆盖古典阿拉伯语的高质量翻译数据集，这限制了高质量翻译系统的开发。", "innovation": "提出了ATHAR数据集，包含66,000个高质量的古典阿拉伯语到英语的翻译样本，涵盖了科学、文化和哲学等广泛主题。评估了当前最先进的LLM在各种设置下的性能，强调了此类数据集对现有系统的重要性。指出模型可以受益于利用这一数据集进行微调或在预训练过程中结合使用。", "conclusion": "ATHAR数据集可以在当前系统中应用，以提高翻译质量，未来的研究可以进一步开发和利用这种高质量的数据集来改进语言模型。该数据集已公开发布在HuggingFace Data Hub上。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.07441", "html_url": "https://arxiv.org/abs/2411.07441", "title": "自动在线检测欺骗性模式", "title_en": "Automatically Detecting Online Deceptive Patterns", "authors": "Asmit Nayak,Shirley Zhang,Yash Wani,Rishabh Khandelwal,Kassem Fawaz", "background": "数字界面中的欺骗性模式（DPs）利用认知偏差和心理脆弱性，操纵用户做出未预期的决策，并在各种数字平台上变得无处不在。尽管法律和技术层面已经出现了一些减轻DPs的努力，但在用户可以实时识别和知情决定DPs的实用解决方案方面仍然存在显著差距。因此，引入了AutoBot，这是一种基于机器学习自动检测欺骗性模式的工具，通过不依赖于HTML结构的方式分析网站的视觉外观，实现实时通知用户DPs的功能。", "innovation": "AutoBot是一种基于机器学习的自动欺骗性模式检测器，其创新之处在于采用了两阶段的处理流程，能够不依赖于HTML结构地识别互动元素和提取文本特征，同时利用定制的语言模型理解这些元素周围的上下文，以此来确定欺骗性模式的存在。此外，AutoBot被实现为一个轻量级的Chrome浏览器扩展，所有的分析都在本地进行，这样可以减少延迟并保护用户隐私。", "conclusion": "经过广泛的评估，AutoBot展示了其在提高用户安全导航数字环境能力方面的有效性，同时也为其作为监管机构评估并遵守DPs规定的工具提供了有力的支持。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.13207", "html_url": "https://arxiv.org/abs/2411.13207", "title": "大型语言模型的信息安全意识", "title_en": "The Information Security Awareness of Large Language Models", "authors": "Ofir Cohen,Gil Ari Agmon,Asaf Shabtai,Rami Puzis", "background": "大型语言模型（LLMs）的使用越来越普遍，并且基于LLM的助手已经非常普及。信息安全意识（ISA）是LLMs重要但尚未充分探索的安全方面。ISA包括LLMs的安全知识，这些知识在过去已经有所探讨，以及态度和行为，这是理解隐形安全上下文和拒绝可能导致LLM失败的不安全请求的关键。研究者提出了一种自动化的ISA测量方法，该方法涵盖了移动ISA分类税表中的所有30个安全主题，并通过创建隐形安全影响与用户满意度之间的紧张情景来实现。应用这种方法对领先的LLMs研究发现，大多数流行模型仅表现出中等到低水平的ISA，使它们的用户面临网络安全威胁。较小的同一系列变体风险更高，而较新的版本没有显示出一致的ISA改进，表明供应商并未积极解决这一问题。", "innovation": "作者提出了一种自动化的ISA测量方法，涵盖移动ISA分类税表中的所有30个安全主题，应用该方法对领先的大规模语言模型进行研究，发现多数流行模型及尤其是较小的变体模型存在信息系统安全意识不足的问题。这揭示了当前LLM部署的普遍弱点：许多流行模型，尤其是较小的变体，可能系统性地危及用户安全。作者还提出了一种实用的缓解措施，通过将他们的安全意识指令整合到模型系统提示中，来帮助LLMs更好地检测和拒绝不安全的请求。", "conclusion": "大多数流行的大型语言模型其信息安全意识水平较低，尤其是较小的变体模型更是危险性更高。尽管新版本模型并未显示出一致的信息安全意识提升，表明供应商并未积极解决这一问题。研究结果揭示了一个当前LLM部署中的普遍脆弱性：许多流行的模型，特别是较小的变体模型，可能系统地威胁用户安全。建议供应商在其系统提示中整合研究中的安全意识指令以增强模型的安全防御能力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.13518", "html_url": "https://arxiv.org/abs/2408.13518", "title": "通过基于通token级别奖励函数估计的选择性偏好优化", "title_en": "Selective Preference Optimization via Token-Level Reward Function Estimation", "authors": "Kailai Yang,Zhiwei Liu,Qianqian Xie,Jimin Huang,Erxue Min,Sophia Ananiadou", "background": "现有大语言模型对齐方法通过通token级监督进行精细偏好优化，但这些方法要么优化所有可用token，这可能会导致噪声和效率问题，要么使用复杂且昂贵的关键token选择策略进行选择性训练。", "innovation": "提出了一个新颖的选择性对齐策略SePO，该策略集中于高效的key token选择。SePO基于Direct Preference Optimization (DPO)的第一个token选择方法，通过训练一个oracle模型来估计目标数据上的通token级奖励函数。该方法可以应用于任何具有响应级别注解的现有对齐数据集，通过小规模的oracle模型和较少的训练数据实现成本效益的token选择。SePO在目标数据集中仅优化30%的关键token，并使用参考模型自由对比目标策略模型。实验结果表明，SePO显著优于竞争基线方法。SePO在弱到强泛化应用中显示了有效监督能力强的策略模型，且参数有效减少16.8倍。SePO还能够从分布外数据中选择关键token以增强策略模型并缓解过度优化问题，", "conclusion": "SePO能够显著优化大语言模型，仅通过优化30%的关键token就大幅提升了模型性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.12226", "html_url": "https://arxiv.org/abs/2402.12226", "title": "AnyGPT: 统一的离散序列建模多模态大语言模型", "title_en": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "authors": "Jun Zhan,Junqi Dai,Jiasheng Ye,Yunhua Zhou,Dong Zhang,Zhigeng Liu,Xin Zhang,Ruibin Yuan,Ge Zhang,Linyang Li,Hang Yan,Jie Fu,Tao Gui,Tianxiang Sun,Yugang Jiang,Xipeng Qiu", "background": "当前的研究集中在开发能够统一处理多种模态（如语音、文本、图像和音乐）的语言模型。传统的处理方法需要对现有的大语言模型（LLM）架构或训练范式进行调整，这可能会增加复杂性和潜在的问题。本文旨在介绍一种新的方法，即AnyGPT，这是一个任何到任何的多模态语言模型，利用离散表示来统一处理这些不同的模态，并且能够在不更改现有架构或其他训练模式的情况下进行训练。利用这种新的方法，可以更方便地将新的模态集成到LLM中。", "innovation": "AnyGPT的主要创新在于其使用离散表示来统一处理多种模态，且可以在不改变现有大型语言模型结构或训练方式的情况下进行训练。此外，研究团队还构建了一个多模态文本中心的数据集来进行多模态对齐预训练，并通过生成模型合成了一组大规模的多模态指令数据集，用于训练一个多模态语言模型。", "conclusion": "实验结果表明，AnyGPT能够实现任意多种模态之间的语言交流，并且在所有模态上的性能都与专门针对这些模态的模型相当。这证明了离散表示能够在语言模型中有效地统一多种模态。该研究提供了一个易于理解和应用的框架，有助于促进多模态语言模型的发展。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.03544", "html_url": "https://arxiv.org/abs/2501.03544", "title": "PromptGuard：针对文本到图像模型的软提示引导不安全内容审核", "title_en": "PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models", "authors": "Lingzhi Yuan,Xinfeng Li,Chejian Xu,Guanhong Tao,Xiaojun Jia,Yihao Huang,Wei Dong,Yang Liu,Bo Li", "background": "近年来，文本到图像（T2I）模型在从文本描述生成高质量图像方面表现出色。然而，这些模型容易遭到滥用，特别是在生成不安全的工作内容（NSFW）图像方面，如色情、暴力、政治、令人不适的内容，这引发了严重的伦理问题。当前的T2I模型缺乏直接的方法来执行行为准则，因此需要新的方法来进行内容审核。", "innovation": "PromptGuard是一种新颖的内容审核技术，灵感来自大型语言模型（LLMs）中的系统提示机制，用于确保安全性。该方法优化了一个作为T2I模型文本嵌入空间内隐式系统提示的安全软提示（P*），可以无损于推理效率地直接审核NSFW输入，并通过拆分策略优化类别特定的软提示，进而形成全面的安全指导。实验结果表明，PromptGuard有效降低了NSFW内容的生成，同时保持了高质量的正常图像输出，并且速度比之前的审核方法快3.8倍，且优于八个基准防御方法，使不安全内容的比例降至最低为5.84%。", "conclusion": "PromptGuard在不损失图像质量的情况下，有效减少了NSFW内容的生成。同时，其优化策略显著提升了审核速度，使得审核过程更为高效，具有广泛的应用前景。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM个性的幻象：揭示LLM自我报告与行为之间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质已被长期研究作为预测人类行为的指标。最近，大型语言模型（LLMs）的进步表明，在人工系统中可能会出现类似的人格模式，其中高级LLM会显示出与人类特质如随和性和自我调节相似的一贯行为倾向。尽管理解这些模式至关重要，但之前的研究所依赖于简化的自我报告和启发式提示，缺乏行为验证。本文系统地从三个维度对LLM的人格进行表征：（1）随训练阶段动态出现的人格特质概况的演变；（2）自我报告的人格特质在行为任务中的预测有效性；以及（3）定向干预（如RLHF，指令微调）对自我报告和行为影响的效果。研究表明，指令对齐（如RLHF，指令微调）显著稳定了特质表达，强化了与人类数据相似的特质相关性，但自我报告的人格特质并不能可靠地预测行为，观察到的关联往往与人类模式不同。虽然注入角色有助于引导自我报告在预期方向上，但它对实际行为的影响很小或不一致。通过区分表面级的特质表达与行为一致性，本研究挑战了关于LLM人格的假设，并强调了在对齐和可解释性方面进行更深入评估的需求。", "innovation": "本文系统地研究了LLM人格的三个维度。首次从动态出现的人格特质概况的演变、自我报告特质在行为任务中的预测价值以及干预措施的影响效果三个方面揭示了LLM的人格特征。主要创新在于通过指令对齐显著稳定了LLM人格表现，且这种表达与人类相似，但仍存在表面级的人格表达与实际行为一致性低的问题，这对理解LLM人格提供了新的视角，并强调了更深层次的评估需求。", "conclusion": "我们的发现揭示了表面级的人格差异与实际行为一致性之间的分离。这挑战了关于LLM人格的传统假设，强调了在对齐和可解释性方面的更深入评估的必要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04365", "html_url": "https://arxiv.org/abs/2504.04365", "title": "AutoPDL：LLM代理的自动提示优化", "title_en": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "authors": "Claudio Spiess,Mandana Vaziri,Louis Mandel,Martin Hirzel", "background": "大型语言模型（LLMs）的表现依赖于提示的方式，这包括高层的提示模式（如零样本、演绎思维、反应式、重新评估）和具体的提示内容（指令和少量示例演示）。手动调整这些组合既繁琐又容易出错，且需针对特定的LLM和任务进行。因此，该论文介绍了一种自动化的自动化提示设计工具AutoPDL，用于发现优秀的LLM代理配置。", "innovation": "AutoPDL将该问题视为具有组合空间（有执照和无执照的提示模式及演示）结构化自动机器学习（AutoML）问题，并利用逐次淘汰法高效地探索这一空间。论文还引入了一个使用PDL提示编程语言实现常见提示模式的库。AutoPDL生成的人类可读、可编辑且可执行的PDL程序使用该库，并允许源到源优化，使人类在环优化和重用成为可能。", "conclusion": "在三个任务和七个不同参数量（3B至70B）的LLM上的评估显示，在模型和任务之间，选择的提示策略有显著差异且一致地提高了准确性（最高达9.21±15.46百分点，最高67.5个基点）。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14333", "html_url": "https://arxiv.org/abs/2503.14333", "title": "使用噪声估计通过强化学习的扩散（NERD）模型揭示不确定性下的高级神经表示", "title_en": "Revealing higher-order neural representations of uncertainty with the Noise Estimation through Reinforcement-based Diffusion (NERD) model", "authors": "Hojjat Azimi Asrari,Megan A. K. Peters", "background": "研究通常旨在揭示‘第一级’表征（FORs），它们编码观察者的环境特征，如内容或结构。一种较少研究的目标是‘更高级’表征（HORs），它们‘关于’FORs，例如它们的强度或不确定性，并且可以贡献于学习。关于不确定性的HORs不太可能是FOR特征的直接读出，而是反映了结合了对不确定性的先验期望的嘈杂估计过程的结果，但大脑如何代表这种期望的不确定性分布还很少被探究。本研究采用神经反馈解码任务，即人类被试学会有意识地产生成目标神经模式来研究这种构念的不确定性期望（噪声期望）HORs。研究开发并应用了噪声估计通过强化学习的扩散（NERD）模型来表征这个过程，并展示了NERD模型对人类行为有很高的解释力。", "innovation": "本研究创新地使用神经解码神经反馈任务来研究关于噪声期望的高级神经表示，并开发并应用了噪声估计通过强化学习的扩散（NERD）模型来表征这一过程，为理解大脑如何处理预期的不确定性分布提供了新的视角。", "conclusion": "NERD模型能够有效地解释人类在面对噪声期望时的学习行为，揭示了高级神经表示如何参与理解和利用关于不确定性的信息。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00204", "html_url": "https://arxiv.org/abs/2504.00204", "title": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024", "title_en": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024", "authors": "Rustam Tagiew(1),Ilkay Wunderlich(2),Mark Sastuba(1),Kilian Göller(3),Steffen Seitz(3) ((1) German Centre for Rail Traffic Research at the Federal Railway Authority, (2) EYYES GmbH, (3) Conrad Zuse School of Embedded Composite AI and the Chair of Fundamentals of Electrical Engineering of Dresden University of Technology)", "background": "无人驾驶列车在开放轨道上的城市引导运输和主干线铁路运营需要自动检测实际和潜在障碍物，特别是列车行进路径中的行人。机器学习算法在这一任务中表现出强大的能力，但需要大量高质量的标注数据，尤其是在铁路特定环境下的行人数据作为训练数据。然而，目前公共可用的数据集还不充足，与道路领域的数据集相比，数量远少。", "innovation": "本文介绍了RailGoerl24数据集，该数据集包含12205帧由TÜV SÜD Rail的戈尔利茨铁路测试中心提供的车内视觉全高清摄像头拍摄的数据，以及覆盖部分区域的地面激光扫描仪数据。数据集中包括总共33556个框注释，用于“人”这一对象类别。此外，该数据集还提供原数据和标注数据，可用于碰撞预测以外的任务。", "conclusion": "本文通过RailGoerl24数据集，提供了一套适用于无人驾驶列车城市引导运输和主干线铁路运营的人行检测支持数据集，促进了相关技术研发，可用于多种计算机视觉任务，不仅限于碰撞预测。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17541", "html_url": "https://arxiv.org/abs/2412.17541", "title": "基于深度学习的可解释面部反欺骗中欺骗追踪发现", "title_en": "Spoof Trace Discovery for Deep Learning Based Explainable Face Anti-Spoofing", "authors": "Haoyuan Zhang,Xiangyu Zhu,Li Gao,Jiawei Pan,Kai Pang,Guoying Zhao,Zhen Lei", "background": "随着面部识别在日常生活中的迅速普及，面部反欺骗变得愈发重要，以防止恶意攻击。现有的面部反欺骗模型虽然在多种数据集上能获得高分类准确率，但缺乏解释能力，只能告诉人们“这个面部是伪造的”，而不能解释“为什么是伪造的”。这种系统降低了可信度，并导致用户的困惑，因为它拒绝了用户的请求而没有提供任何解释。因此，需要一种新的方法结合XAI（可解释的人工智能）来解决面部反欺骗问题，增强模型的解释能力。", "innovation": "该研究提出了一个新的问题X-FAS（可解释面部反欺骗），并提出了一种新的方法SPTD（欺骗追踪发现），它可以发现欺骗的概念并基于这些概念提供可靠的解释。此外，还提出了一个基于专家注释的欺骗追踪基准（X-FAS基准），用于评估X-FAS方法的质量，并通过与先前的XAI方法的定量和定性比较来分析SPTD的解释效果。实验结果表明SPTD能够生成可靠的解释。", "conclusion": "SPTD方法能够生成可靠的解释，能够增强深度学习在面向欺骗检测中的可解释性，并为进一步研究提供了一个评估基准。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08224", "html_url": "https://arxiv.org/abs/2506.08224", "title": "基于目标局部环境的人工智能辅助快速晶体结构生成", "title_en": "AI-Assisted Rapid Crystal Structure Generation Towards a Target Local Environment", "authors": "Osman Goni Ridwan,Sylvain Pitié,Monish Soundar Raj,Dong Dai,Gilles Frapper,Hongfei Xue,Qiang Zhu", "background": "在材料设计领域，传统的晶体结构预测方法需要通过耗时的计算昂贵的能量最小化方法（使用力场或量子力学模拟）进行广泛的结构采样。尽管新兴的人工智能生成模型在快速生成现实的晶体结构方面显示出巨大潜力，但现有模型大多未能考虑晶体材料的独特对称性和周期性，并且仅能处理每个胞元包含几十个原子的结构。", "innovation": "我们提出了一种基于对称性的人工智能生成方法，称为局部环境几何导向晶体生成器(LEGO-xtal)，该方法克服了上述限制。该方法利用AI模型训练的增强小数据集生成初始结构，并使用机器学习结构描述符优化，而不是传统的基于能量的优化。我们通过从25种已知低能sp2碳同质异体扩展到超过1,700种，所有这些都在石墨基态能量的0.5 eV/原子范围内，展示了LEGO-xtal的有效性。", "conclusion": "该框架提供了一种可扩展的设计方法，以模块化构建块为目标设计材料，如金属有机框架和下一代电池材料。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22809", "html_url": "https://arxiv.org/abs/2505.22809", "title": "朝向旁听式LLM代理的第一步：基于Dungeons & Dragons游戏情景的研究", "title_en": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "authors": "Andrew Zhu,Evan Osgood,Chris Callison-Burch", "background": "许多研究已对直接协助人类用户完成任务的对话式语言模型（LLM）代理进行了研究。本文介绍了一种与LLM代理交互的新范式，称为“旁听代理”。旁听代理不主动参与对话，而是旁听人与人之间的对话，并在后台执行任务或提供建议以帮助用户。", "innovation": "本文通过探索Dungeons & Dragons游戏情景，使用大型多模态音频-语言模型作为旁听代理来协助导演，进行深入研究。文章还完成了一项人类评估以检验此类代理的有用性，并发现一些大型音频-语言模型能够利用隐含的音频线索进行旁听代理任务。此外，文章还发布了Python库和项目代码以支持进一步研究。", "conclusion": "本研究展示了旁听代理的可能性，并认为具有潜在能力和应用领域的大型音频-语言模型能够执行旁听代理任务。论文还通过实际应用和评估结果强调了该范式的可行性和潜力，并呼吁进一步的研究以深化对这一主题的理解。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05644", "html_url": "https://arxiv.org/abs/2507.05644", "title": "特征在收敛定理：基于第一原理替代神经特征拟合理论以如何网络学习表示", "title_en": "The Features at Convergence Theorem: a first-principles alternative to the Neural Feature Ansatz for how networks learn representations", "authors": "Enric Boix-Adsera,Neil Mallinar,James B. Simon,Mikhail Belkin", "background": "深度学习中关于神经网络如何学习表示的机制是一个核心挑战。当前最大的假设是神经特征拟合理论（NFA），但它缺乏理论基础，是一种基于经验的假设，没有明确提出何时可能失效以及如何改进的问题。本文从第一性原理出发，通过一阶最优性条件提出了特征在收敛定理（FACT），旨在弥补NFA的不足，同时保持其解释力。这项工作通过理论分析与实验验证，统一了神经网络一阶最优性分析和基于经验的NFA文献，为特征学习提供了理论上的补充和经验证据。", "innovation": "本文的主要创新在于提出了特征在收敛定理（FACT），它通过一阶最优性条件从第一性原理出发，弥补了神经特征拟合理论（NFA）的不足。它与NFA相比，在多个方面取得了进步：首先，FACT在收敛时获得的特征的学习结果更为一致；其次，它解释了NFA在大多数环境下的适用性；最后，FACT捕捉了如模块算术中的grokking行为和学习稀疏门限时的现象等重要的特征学习现象，这些现象与NFA类似。通过对这些现象的研究，我们可以更好地理解神经网络如何学习表示以及优化NFA的方法。", "conclusion": "本文的结论表明，特征在收敛定理（FACT）不仅克服了神经特征拟合理论（NFA）缺乏理论基础的问题，而且通过理论分析和实验验证，提供了一种原理性的替代方法，这种方法在神经网络中的收敛时能够被证明确实有效，符合实验和理论预期。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14240", "html_url": "https://arxiv.org/abs/2507.14240", "title": "HuggingGraph:理解大语言模型生态系统供应链", "title_en": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "authors": "Mohammad Shahedur Rahman,Peng Gao,Yuede Ji", "background": "大语言模型（LLMs）通过深度学习架构处理和预测词序列，使它们能够执行一系列自然语言处理任务，如翻译、总结、问答和内容生成。现有LLMs通常基于其他预训练模型构建，并使用外部数据集，这些模型不可避免地会继承先前模型或数据集中的漏洞、偏见或恶意组件。因此，理解这些成分的来源及其发展过程对于检测潜在风险、提高模型公平性和确保遵守监管框架至关重要。", "innovation": "该项目旨在研究模型和数据集之间的关系，这是LLM供应链的核心部分。首先，该方法设计了一种系统的方法来收集LLMs的供应链信息。其次，设计了一个新的图模型来表示模型和数据集之间的关系，这是一个包含402,654个节点和462,524条边的有向异构图。最后，进行了不同类型的数据分析并获得了多个有趣的研究发现。", "conclusion": "通过系统地收集LLMs的供应链信息并设计一个有向异构图来表示模型与数据集的关系，本研究揭示了大语言模型供应链中的重要信息，有助于提升模型的公平性和安全性，同时为监管合规提供支持。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13802", "html_url": "https://arxiv.org/abs/2507.13802", "title": "欧洲食品安全趋势：来自包含3920万条记录的CompreHensive欧洲食品安全（CHEFS）数据库的见解", "title_en": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database", "authors": "Nehir Kizililsoley,Floor van Meer,Osman Mutlu,Wouter F Hoenderdaal,Rosan G. Hobé,Wenjuan Mu,Arjen Gerssen,H.J. van der Fels-Klerx,Ákos Jóźwiak,Ioannis Manikas,Ali Hürriyetoǧlu,Bas H.M. van der Velden", "background": "在欧洲联盟中，成员国向欧洲食品安全局（EFSA）提交由官方收集的食品安全监测数据，并在Zenodo上发布。这些数据涵盖了超过1.52亿个样品的3.92亿分析结果，涉及超过4000种不同类型的食品产品。当前的数据格式导致数据不易访问且分析困难。", "innovation": "我们提出了CompreHensive欧洲食品安全（CHEFS）数据库，该数据库将关于农药残留、兽药残留和化学污染物的EFSA监测数据整合为一个统一且结构化的数据集，解决了数据分散和不易访问的问题。", "conclusion": "通过分析2000年至2024年欧洲食品安全监测数据，我们揭示了监测活动的变化、最常检测的产品、最常违规的产品以及最常见的污染物。这些发现突显了CHEFS数据库作为数据中心以及指导食品安全政策、研究和监管的战略工具的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05814", "html_url": "https://arxiv.org/abs/2507.05814", "title": "通过统一合成框架填补数据缺口以增强桥梁数字孪生", "title_en": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework", "authors": "Wang Wang,Mingyu Shi,Jun Jiang,Wenqian Ma,Chong Liu,Yasutaka Narazaki,Xuguang Wang", "background": "作为关键的交通基础设施，桥梁正面临老化和腐蚀带来的日益严峻的挑战，而传统的手工检查方法则因效率低下而受到限制。尽管3D点云技术为新的数据驱动范式提供了可能，但由于实际数据的不完整性（如缺少标签和扫面遮挡）而受到限制。现有的合成数据方法在现有合成数据方法中未能克服泛化能力不足的瓶颈，因此需要一种能够自动生成完整点云和物理上现实的缺失点云的系统框架，以支持分割和补全网络的训练和应用。", "innovation": "本文提出了一个系统性的框架来生成3D桥梁数据，该框架能够自动生成包含组件级实例注释、高度保真的颜色及精确法矢量的完整点云。该框架还能进一步扩展以模拟生成各种物理上现实的缺失点云，从而支持分割和补全网络的训练。实验结果表明，使用我们的合成数据训练的PointNet++模型在实际桥梁语义分割上的平均交并比（mIoU）达到了84.2%。同时，微调后的KT-Net在组件补全任务上表现出更优的性能。这项研究为桥梁结构的3D视觉分析提供了一种创新的方法和基础数据集，对于推进基础设施的自动化管理和维护具有重要意义。", "conclusion": "本文提出了一种创新性的合成数据方法和相应的数据集，为桥梁结构的3D视觉分析奠定了基础，有助于提升基础设施的自动化管理和维护水平。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10264", "html_url": "https://arxiv.org/abs/2505.10264", "title": "穿透隐私：联邦学习中的基于超平面的数据重构攻击", "title_en": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "authors": "Francesco Diana,André Nusser,Chuan Xu,Giovanni Neglia", "background": "联邦学习（FL）允许分布式客户端在不共享原始数据的情况下协作训练机器学习模型，以保护数据隐私。然而，现有研究揭示了联邦学习中的关键漏洞，恶意中央服务器可以通过操纵模型更新来重构客户端的私人训练数据。现有的数据重构攻击具有重要限制：它们通常依赖于客户端数据分布的假设，或者在批量大小超过数十样本时效率显著下降。", "innovation": "本工作引入了一种新颖的数据重构攻击方法，克服了现有方法的限制。该方法利用全连接层的全新几何视角来定制恶意模型参数，能够在分类任务中无须任何有关客户端数据的先验知识即可完美恢复任意大小的数据批次。通过在图像和表格数据集上的大量实验，我们的攻击方法在性能上优于现有方法，并能够实现比最先进的方法大两个数量级的数据批次的完美重构。", "conclusion": "我们的研究表明，基于超平面的数据重构攻击可以在联邦学习环境中有效地重构大量数据，而无需对客户端数据分布的假设，并实现了现有技术无法达到的数据规模的完美重构。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "复杂性陷阱：简单的观察遮蔽与LLM总结一样有效用于代理商上下文管理", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "基于大型语言模型（LLM）的代理通过迭代推理、探索和工具使用解决复杂任务，但这一过程可能导致长期和昂贵的历史上下文。软件工程（SE）代理如OpenHands或Cursor使用基于LLM的总结来应对这一问题，但不清楚增加的复杂性是否提供了实际的性能优势，与简单省略旧观察相比。\n研究人员在SWE-agent上进行了系统性比较，涵盖了五种不同的模型配置，并跨SWE-bench Verified进行了验证。", "innovation": "研究提出了一种简单的观察遮蔽策略，发现它在成本减半的情况下，与未经处理的代理相比，能匹配甚至在某些情况下超越基于LLM的总结的结果。例如，使用Qwen3-Coder 480B模型时，遮蔽提高了解决率，从53.8%（原始代理）提升至54.8%，同时在成本较低的情况下保持竞争力。\n这些结果表明，在SWE-agent和SWE-bench Verified中，最有效的上下文管理策略可能是最简单的方法。", "conclusion": "研究结果表明，在SWE-agent和SWE-bench Verified环境下，最有效的上下文管理策略可能是最简单的方法，即简单的观察遮蔽策略。研究已公开代码和数据以确保结果的可重复性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18708", "html_url": "https://arxiv.org/abs/2508.18708", "title": "技能对齐的公平性在医疗合作多智能体学习中的应用", "title_en": "Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in Healthcare", "authors": "Promise Osaine Ekpo,Brian La,Thomas Wiener,Saesha Agarwal,Arshia Agrawal,Gonzalo Gonzalez-Pumariega,Lekan P. Molu,Angelique Taylor", "background": "多智能体强化学习（MARL）中的公平性通常被定义为工作负载平衡问题，忽视了智能体的专业技能和现实世界领域所需的结构化协调。在医疗保健领域，公平的任务分配需要工作负载平衡或技能匹配来防止过度劳累和高级专业人员的资源过度使用。工作负载平衡是指在不考虑智能体专业技能的情况下，将大致相同数量的子任务或相等的努力分配给医疗工作者。", "innovation": "本文提出了两个贡献：首先，提出了一种新的框架FairSkillMARL，将公平性定义为工作负载平衡和技能任务匹配的双重目标；其次，介绍了MARLHospital，这是一种可在其中模拟团队组成和能量有限时间表对公平性影响的自定义医疗保健启发式环境，没有现有模拟器能够很好地解决这个问题。实验结果表明，单纯的工作负载平衡可能导致任务技能失配，强调需要能够捕捉技能任务偏差的更稳健的公平性度量。", "conclusion": "本工作提供了研究将在智能体能力对齐方面至关重要的异构多智能体系统中公平性的工具和基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07236", "html_url": "https://arxiv.org/abs/2507.07236", "title": "简单而有效的信息论方法：多大语言模型不确定性量化", "title_en": "Simple Yet Effective: An Information-Theoretic Approach to Multi-LLM Uncertainty Quantification", "authors": "Maya Kruse,Majid Afshar,Saksham Khatwani,Anoop Mayampurath,Guanhua Chen,Yanjun Gao", "background": "大型语言模型（LLMs）在不同输入上的行为经常不一致，显示出不确定性，这在高风险场景中需要量化。先前关于校准和不确定性量化的工作通常关注个别模型，忽视了模型多样性的潜力。根据训练差异和语言的 Zipf 分布特性，我们认为 LLMs 会做出互补的预测，并通过聚合它们的输出来提高不确定性估计的可靠性。", "innovation": "提出了一种名为 MUSE 的简单信息论方法，使用 Jensen-Shannon 散度识别并聚合具有良好校准的 LLM 子集。此外，研究了 MUSE 作为指导信号与链式思维蒸馏结合，对 LLM 进行校准微调。实验结果表明，MUSE 在二元预测任务中比单一模型和朴素组合基线具有更好的校准和预测性能。", "conclusion": "MUSE 在 Binary prediction 任务中显示出改进的校准和预测性能，并且还可以用作指导信号来微调 LLM 以进行校准。MUSE 已经可用，可通过提供的链接访问。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR：大型语言模型推理中的标记级不确定性估计", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "尽管大型语言模型（LLMs）展现了显著的能力，但在不同应用场景中的输出质量并不一致，这使得难以识别可靠的响应，尤其是在需要多步骤推理的复杂任务中更为明显。因此，本研究旨在通过提出一种标记级不确定性评估框架（TokUR），让LLMs能够自我评估和改进其在数学推理中的生成质量，以提升其在推理任务中的信任度和可靠性。", "innovation": "本研究引入了一种低秩随机权重扰动技术，将其应用于LLM解码过程，生成预测分布以估计标记级的不确定性，并通过聚合来反映生成序列的语义不确定性。此外，研究还探索了使用不确定性直接提升模型推理性能的方法，通过多次生成并结合粒子滤波算法实现。实验结果显示，该方法的标记级不确定性指标与答案正确性和模型鲁棒性有很强的相关性，并且比现有不确定性估计方法表现出更强的优势，证明了标记级不确定性估计在评估和提升LLMs逻辑生成性能方面的重要性。", "conclusion": "本研究方法在多个难度层次的数学推理数据集上的实验表明，标记级不确定性度量与答案正确性和模型鲁棒性之间存在强烈的相关性。此外，通过使用不确定性直接增强模型的推理性能，取得了优于现有不确定性估计方法的效果。这表明将不确定性估计作为评估和改进LLMs推理生成的有效工具是可行且有价值的。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06269", "html_url": "https://arxiv.org/abs/2507.06269", "title": "BayesSDF：基于表面的拉普拉斯不确定性估计用于具有神经符号距离场的3D几何", "title_en": "BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields", "authors": "Rushil Desai", "background": "在科学模拟下游任务中，精确的表面估计至关重要。由于计算效率低下、可扩展性问题以及几何不一致，量化隐式神经3D表示中的不确定性仍是一个主要挑战。当前的神经隐式表面模型并未提供一种原则性的方式来量化不确定性，限制了其在真实世界应用中的可靠性。", "innovation": "受最近概率渲染方法的启发，提出了一种新的概率框架——BayesSDF，用于隐式神经3D表示中的不确定性估计。BayesSDF 通过对SDF权重进行拉普拉斯近似并推导出基于海森矩阵的度量来估算局部几何稳定性，从而实现在不断改进中掌握理解真实数据集中有意义的不确定性估计。BayesSDF 的不确定性估计与表面重建误差在合成和真实世界基准数据集上高度相关，有助于构建更 robust、可解释和可采取行动的3D感知系统。", "conclusion": "通过在表面感知不确定性量化方面的优势，BayesSDF 为构建更 robust、可解释和可采取行动的3D感知系统奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15442", "html_url": "https://arxiv.org/abs/2508.15442", "title": "通过GFlowNets进行分布对齐以缓解基于语言模型的TTS模型的幻觉", "title_en": "Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets", "authors": "Chenlin Liu,Minghui Fang,Patrick Zhang,Wei Zhou,Jie Gao,Jiqing Han", "background": "基于语言模型（LM）的文本转语音（TTS）系统经常生成与输入文本不符的幻觉语音。现有缓解策略要么需要大量的训练资源，要么会在推理延迟上引入显著的增加。", "innovation": "提出了一种基于GFlOwNet指导的分布对齐（GOAT）的后训练框架，该框架可以在不依赖大量资源或推理成本的情况下减少幻觉。具体地，首先进行了不确定性分析，揭示了幻觉与模型不确定性之间的强正相关关系。基于此，将TTS生成重新构想为轨迹流优化问题，并引入了改进子轨迹平衡目标及锐化内部奖励作为目标分布。进一步结合奖励温度衰减和学习率优化以实现稳定性和性能的平衡。广泛的实验表明，GOAT在具有挑战性的测试案例中将字符错误率降低了50%以上，并将不确定性降低了高达58%，证明了其强大的泛化能力和有效性", "conclusion": "GOAT显著降低了字符错误率和模型不确定性，并展示了其强大的泛化能力和有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01910", "html_url": "https://arxiv.org/abs/2509.01910", "title": "具有概念感知的全球图像-GPS 对齐的可解释地理定位框架", "title_en": "Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS Alignment Framework", "authors": "Furong Jia,Lanxin Liu,Ce Hou,Fan Zhang,Xinyan Liu,Yu Liu", "background": "全球地理定位涉及确定全球拍摄图像的精确地理位置，通常由气候、地标和建筑风格等地理特征引导。尽管存在如GeoCLIP这样的模型已经利用对比学习方法进行图像和地点的对齐以实现准确预测，但这些模型的可解释性仍然不足，当前的概念基解释方法未能有效实现Geo对齐图像-位置嵌入目标，导致解释性和性能差强人意。", "innovation": "本文提出了一种新的框架，将全球地理定位与概念瓶颈相结合。该方法插入了一个概念感知对齐模块，该模块联合将图像和地点嵌入投影到地理概念共享银行（例如，热带气候、山、大教堂）上，并最小化概念级别损失，增加特定于概念的空间中的对齐，从而增强解释性。这是首次将解释性引入地理定位的研究。实验表明，该方法在地理定位精度上超越了GeoCLIP，并在多种地理空间预测任务中提升了性能，揭示了地理决策过程中的丰富语义见解。", "conclusion": "该工作通过引入概念感知模块，有效提高了地理定位模型的解释性和准确性，解决了现有方法的问题，并通过实验证明了其有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02046", "html_url": "https://arxiv.org/abs/2509.02046", "title": "超级预训练优化器及其寻找方法", "title_en": "Fantastic Pretraining Optimizers and Where to Find Them", "authors": "Kaiyue Wen,David Hall,Tengyu Ma,Percy Liang", "background": "尽管有多项研究表明其他优化器可能比AdamW提供1.4至2倍的速度提升，但AdamW仍然是语言模型预训练的主导优化器。研究发现，方法论上的不足，如不平等的超参数调整和不充分或误导性的评估设置，影响了公平比较和实际应用。为了弥补这些不足，研究人员通过跨四大模型规模和数据与模型比例范围的系统研究，证明了公平且信息丰富的比较需要严谨的超参数调整和在训练结束时的跨范围评估。研究表明，不同优化器的最佳超参数可能不相容，且许多优化器相对于调参基准的速度提升低于预期，特别是在大型模型上。此外，比较训练过程中的中间检查点可能导致误导，因为在学习率衰减作用下，两个优化器在训练过程中的排名会翻转。研究表明，诸如Muon和Soap之类的最快速优化器使用矩阵作为预处理器，尽管矩阵基于的优化器速度提升随着模型规模增加而降低。", "innovation": "研究提出了一种系统的方法来解决优化器比较中的问题，包括严谨的超参数调整和跨广泛模型规模的评估。研究发现，最优的优化器使用矩阵作为预处理器，但由于模型规模的增加，这种优化器的速度提升呈反比关系。该研究为寻找最佳的预训练优化器提供了理论基础，并为今后的研究指明了方向。", "conclusion": "尽管有多种优化器声称提供更快的训练速度，但实际速度提升往往低于预期，尤其是在大型模型上。研究指出，跨范围的模型调整和最终的评估对于获得真正有代表性的结果至关重要。研究还发现，基于矩阵的优化器在大型模型上的速度提升不如小模型，因此在选择优化器时应考虑这一点。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21001", "html_url": "https://arxiv.org/abs/2508.21001", "title": "一种通过扩散树进行一次训练随时规划的动力学运动规划", "title_en": "Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees", "authors": "Yaniv Hassidof,Tom Jurgenson,Kiril Solovey", "background": "动力学运动规划问题涉及计算碰撞自由的轨迹，同时满足机器人动力学约束。通常使用采样为基础的规划器（SBPs）通过动作传播构建搜索树来探索机器人的高维状态空间。虽然SBPs可以提供全局完备性和解的质量保障，但其性能受限于采样动作的缺乏指导性。基于学习的方法可以提供更快的运行时间，但它们在处理未见过的数据场景（OOD）时缺乏泛化能力，并可能缺乏关键的安全保证。现有的解决方法不能完全应用于物理机器人。", "innovation": "本文提出了一种名为Diffusion Tree（DiTree）的框架，结合了扩散策略（DPs）作为有信息的采样器来高效引导SBPs中的状态空间搜索，确保满足复杂系统中的安全性。DiTree通过单一环境训练的DP动作采样器与RRT规划器结合证明了其高效性。在OOD场景的综合评估中，DiTree的表现优于单独的DP或SBPs。在实际汽车实验中也证明了DiTree的鲁棒性和高轨迹质量，即使在严重的模拟到现实差距下也表现出色。", "conclusion": "DiTree在解决动力学运动规划问题上，结合了SBPs的全局完备性和DPs的有信息采样能力，提供了在可证明的几轮动作传播迭代中获得安全解的能力。通过实验，DiTree证明了其在OOD场景和现实世界应用中的优越性能，并展示了其在动力学系统中的广泛应用潜力。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11987", "html_url": "https://arxiv.org/abs/2508.11987", "title": "FutureX：未来预测领域大型实时基准测试", "title_en": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "authors": "Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Yixiao Tian,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang", "background": "未来预测是高级语言模型代理面临的复杂任务，需要高水准的分析思维、信息汇集、上下文理解以及在不确定性下的决策能力。代理不仅要处理大量动态信息，还要整合不同的数据源，权衡不确定性，并根据新兴趋势调整预测，类似于政治、经济和金融等领域的人类专家。尽管对未来预测的重要性显而易见，但评估代理的实际基准测试很少，主要原因在于处理实时更新和获取及时准确答案的挑战。为解决这一问题，本文提出了FutureX，这是一个专为未来预测任务设计的动态实时基准测试。", "innovation": "FutureX 是最大的并且最多样化的实时未来预测基准测试，支持每日更新并通过自动化问卷和答案收集管道避免数据污染。本文评估了25个具有推理、搜索能力和使用外部工具（如开源Deep Research Agent和封闭源Deep Research模型）能力的语言模型/代理模型，全面评估代理的自适应推理和动态环境中的表现。此外，还对代理在面向未来任务中的失败模式和表现漏洞进行了深入分析，包括对假网页的易感性和时间有效性。", "conclusion": "本文的目标是建立一个动态、无污染的评估标准，驱动能够胜任复杂推理和预测思考的专业人类分析师水平的语言模型代理的发展。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02640", "html_url": "https://arxiv.org/abs/2509.02640", "title": "midog2025挑戰中的細胞分裂圖像分類的適應學習策略", "title_en": "Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge", "authors": "Biwen Meng,Xi Long,Jingxin Liu", "background": "非典型有丝分裂图像是临床相关指标，用以指示异常细胞分裂。然而，由于形态学模糊性和扫描器变异性，可靠的检测仍然具有挑战性。在此工作中，我们研究了三种变种适应病理学基础模型UNI2应用于MIDOG2025挑战的Track 2: (1)LoRA + UNI2，(2)VPT + UNI2 +Vahadane正规范化，以及(3)VPT + UNI2 + GRL + 统一染色变种的测试时增强技术。我们发现将视觉提示调谐（VPT）与染色正规范化技术相结合，有助于改善泛化性能。进一步结合测试时增强（TTA）非常重要，特别是在使用Vahadane和Macenko染色正规范化的条件下，最终使模型表现出最好的稳健性。我们的最终提交在初步排行榜上的平衡准确度为0.8837，ROC-AUC为0.9513，位列前10名.", "innovation": "我们提出了一种基于提示的适应策略结合染色正规范化测试时增强技术，以解决多样成像条件下的非典型有丝分裂图分类问题。这种方法改进了模型的泛化能力，使它在不同成像条件下表现出色，有效提升了分类的准确性和鲁棒性。我们的算法在MIDOG2025挑战的Track 2中表现尤为突出，达到了优秀的得分和排名，并证明了该策略的有效性，提供了新的解决难题的思路.", "conclusion": "我们的研究结果表明，基于提示的自适应方法与染色正规范化结合的测试时增强技术（TTA）是解决不同成像条件下非典型有丝分裂图分类问题的有希望的方法。该策略可以提高模型的泛化性能和鲁棒性，有助于改善临床诊断中的该问题。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02055", "html_url": "https://arxiv.org/abs/2509.02055", "title": "Align-Then-stEer: 统一潜在空间引导下视-语-动模型的适应", "title_en": "Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance", "authors": "Yang Zhang,Chenwei Wang,Ouyang Lu,Yuan Zhao,Yunfei Ge,Zhenglong Sun,Xiu Li,Chi Zhang,Chenjia Bai,Xuelong Li", "background": "Vision-Language-Action (VLA) 模型在大规模、多样化数据集上预训练后，显示出普遍用途的机器人操作的潜力。然而，这些模型适应下游任务的主要瓶颈在于，当机器人本体或任务本身与预训练数据不同步时。这种差异导致了动作分布的巨大不匹配，需要大量数据和计算才能有效地进行微调.", "innovation": "我们提出了一个新颖的数据高效且即插即用的适应框架—Align-Then-stEer (ATE)。ATE首先通过建立一个统一的潜在空间来对齐不同的动作空间，使用受制于逆KL散度的变分自编码器将适应动作嵌入预训练动作潜在分布的模式中。其次，通过引导机制在微调过程中引导以扩散或流为基础的VLA生成过程，将模型输出分布推至目标域。我们进行了广泛的仿真和真实环境跨本体和跨任务操作实验。与直接对代表性VLA进行微调相比，我们的方法在仿真中提高了平均多任务成功率高达9.8%，在真实环境跨本体设置中实现了令人瞩目的32%成功率提升。", "conclusion": "我们提出了一种通用且轻量的解决方案，极大地增强了部署VLA模型到新机器人平台和任务的实用性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-XGPT：适用于电子健康记录的可扩展多任务基础模型", "title_en": "CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供了患者健康状况的丰富纵向视图，具有推动临床决策支持、风险预测和数据驱动的医疗研究的巨大潜力。然而，大多数面向EHRs的人工智能模型仅限于窄领域单任务，限制了它们在真实世界环境中的通用性和实用性。", "innovation": "CEHR-XGPT 是一种通用的EHR数据基础模型，它在一个架构中统一了三项核心能力：特征表示、零样本预测和合成数据生成；通过引入一种新颖的时间标记为基础的学习框架，CEHR-XGPT 隐式地将患者的动态时间线编码到模型结构中，以支持在临床序列上的时间推理；模型通过词汇扩展和微调能够有效推广到外部数据集；其灵活性可以快速开发模型、发现患者群体并预测患者结果，无需进行特定任务重训练。", "conclusion": "CEHR-XGPT 在所有三个任务上的性能表现出色，并可通过词汇扩展和微调有效推广到外部数据集。它的通用性使得无需任务特定的重新训练就能快速开发模型、发现患者群体并预测患者结果。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03025", "html_url": "https://arxiv.org/abs/2509.03025", "title": "大型视觉语言模型对视觉缺失tokens的响应揭示", "title_en": "Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens", "authors": "Sohee Kim,Soohyun Ryu,Joonhyung Park,Eunho Yang", "background": "LVLMs通过联合解释视觉和文本输入来生成上下文相关响应。然而，研究发现，它们经常会错误地将缺乏视觉证据的文本输入视为图像的一部分，从而导致错误的响应。基于这一发现，研究者探索了LVLMs是否具备辨别文本概念是否基于图像的内部能力，并发现了特定的前馈神经网络（FFN）神经元，称为视觉缺失感知（VA）神经元，这些神经元通过独特的激活模式一致地表示视觉缺失。这一发现有助于设计一种检测模块，系统地分类输入标记是否在视觉上是被锚定的。", "innovation": "研究揭示了特定类型的前馈神经网络（FFN）神经元——视觉缺失感知（VA）神经元，这些神经元能够通过特定的激活模式来表示视觉缺失。基于这些发现，研究设计了一种检测模块来系统地分类输入标记是否在视觉上是被锚定的。此外，提出了一种通过重新解释问题提示或在生成过程中替换检测到的缺失标记来改进模型输出的方法。实验证明，该方法有效地减少了模型对视觉缺失文本输入假想视觉存在的倾向，并且具有跨不同LVLMs的广泛适用性。", "conclusion": "研究揭示了LVLMs在处理文本输入时存在的误解问题，并开发了一种用于检测和纠正这种误解的方法。这个方法可以显著提高模型的输出质量，使其更加可靠和精确。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04457", "html_url": "https://arxiv.org/abs/2509.04457", "title": "MLLMs真的理解图表吗？", "title_en": "Do MLLMs Really Understand the Charts?", "authors": "Xiao Zhang,Dongyuan Li,Liuyu Xiang,Yao Zhang,Cheng Zhong,Zhaofeng He", "background": "虽然多模态大型语言模型（MLLMs）在图表理解方面表现出越来越出色的表现，但它们在处理未标注的图表时却经常出现明显的幻觉和显著的性能下降。这就引发了问题：MLLMs是否真的理解图表？由于人类能够通过视觉推理理解图表并估算值，作者首先仔细建立了一个全面的图表推理基准CRBench，以严格评估MLLMs在未标注图表上的视觉推理能力。作者认为，MLLMs主要依赖于识别而非推理来解释图表。", "innovation": "为了引导MLLMs进行合理的图表理解，作者提出了ChartReasoner，通过将它们的估计与图表理解联系起来，模拟人类的行为。在提出的CRBench上进行的大量结果显示，ChartReasnoner-3B/7B在图表推理方面的表现优于GPT-4o和Gemini-2.5-Flash。更重要的是，ChartReasnoner在公共基准上的视觉推理能力也表现出色，使得MLLMs能够理性地理解图表。", "conclusion": "ChartReasnoner在图表推理上的优越性能不仅证明了其视觉推理能力，还在公共基准上展示了增强的性能，使得MLLMs能够理性地理解图表。研究成果将在发表后向公众提供代码和数据集。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04459", "html_url": "https://arxiv.org/abs/2509.04459", "title": "具有不确定性感知的大型和小型模型协作系统用于多模态情感分析", "title_en": "Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis", "authors": "Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai", "background": "随着多模态大型语言模型（MLLMs）的发展，虽然在多模态机器学习中的性能有了显著提升，但其巨大的计算需求成为实际部署中的关键障碍。相比之下，小型、专门化的模型虽然具有高效率，但在性能上往往有所牺牲。为了平衡这种性能与效率之间的权衡，提出了一个名为不确定性感知协同系统（U-ACS）的新颖框架。该系统协调了一种强大的MLLM（如HumanOmni）和一种轻量级基础模型，用于处理多模态情感分析。", "innovation": "该系统的核心是一个基于不确定性的级联机制，其中高效的轻量级模型首先快速筛选所有输入样本。只有预测不确定性高的，表示更为难以分析的样本，才会被提升到MLLM进行更复杂的分析。此外，系统还引入了处理模糊或冲突预测的策略，包括权重平均方法解决相似极性的预测冲突，以及基于提示的交叉验证解决在两个模型都表现出高不确定情况下的预测冲突。", "conclusion": "大量的实验表明，提出的U-ACS方法不仅在基准数据集上达到了最先进的性能，而且仅需使用单一MLLM所需计算资源的一小部分。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04455", "html_url": "https://arxiv.org/abs/2509.04455", "title": "INSEva：保险领域的全面中文基准，用于大型语言模型", "title_en": "INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance", "authors": "Shisong Chen,Qian Zhu,Wenyan Yang,Chengyi Yang,Zhong Wang,Ping Wang,Xuan Lin,Bo Xu,Daqian Li,Chao Yuan,Licai Qi,Wanqing Xu,sun zhenxing,Xin Lu,Shiqiang Xiong,Chao Chen,Haixiang Hu,Yanghua Xiao", "background": "保险作为全球金融系统的关键组成部分，要求AI应用具备高度的准确性和可靠性。现有的基准测试虽然涵盖了多个领域，但往往无法捕捉到保险行业的独特特点和要求。因此，研究者开发了INSEva，这是一个专为中国保险行业设计的综合基准，用于评估AI系统的知识和能力。", "innovation": "INSEva引入了一个多维的评估体系，涵盖业务领域、任务格式、难度级别以及认知知识维度，包含了38,704个高质量的评估案例，这些案例来源于权威资料。此外，它还针对开放式响应评估了信实性和完整性特有的评估方法。通过对8种最先进的大型语言模型进行广泛评估，发现了不同维度上的显著性能差异。", "conclusion": "尽管通用的大规模语言模型在保险领域展示了基本的竞争力，但它们在处理复杂的现实世界保险场景时仍存在显著差距。该基准将很快公开。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04458", "html_url": "https://arxiv.org/abs/2509.04458", "title": "评估大型语言模型在链接生物医学术语和标识符方面失败证据的模式", "title_en": "Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies", "authors": "Daniel B. Hier,Steven Keith Platt,Tayo Obafemi-Ajayi", "background": "大型语言模型通常在生物医学自然语言处理任务中表现出色，但在将术语链接到正确标识符方面却可能失败。本文通过分析两种主要的本体论（人类表型本体论和基因本体论）及其两种高性能模型（GPT-4o和LLaMa 3.1 405B）之间的预测来探讨这些失败的原因。研究通过考察九个候选特征，包括术语熟悉度、标识符使用情况、形态学和本体论结构，评估这些因素对链接成功的影响。", "innovation": "研究通过分析两种主要的本体论和两个高性能模型，探索大型语言模型在链接生物医学术语和标识符失败的模式。研究还通过多种和多元分析，发现暴露于本体论标识符是最强的预测因子。", "conclusion": "研究表明，大型语言模型在链接生物医学本体论术语和标识符方面存在失败，而暴露于本体论标识符是预测链接成功的关键因素。这一发现对于改善大型语言模型在生物医学领域的应用具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04461", "html_url": "https://arxiv.org/abs/2509.04461", "title": "从帖子到性格：利用大型语言模型在社交媒体中进行MBTI预测", "title_en": "From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media", "authors": "Tian Ma,Kaiyu Feng,Yu Rong,Kangfei Zhao", "background": "个性预测从社交媒体帖子中具有重要的心理学和社会学应用。传统的MBTI个性测试多通过机器学习和深度学习技术进行预测。然而，直接利用大型语言模型进行MBTI预测存在幻觉问题和MBTI类型的人口分布不平衡两大挑战。", "innovation": "提出了一个名为PostToPersonality (PtoP)的新型框架，该框架利用检索增强生成和上下文学习来减轻大型语言模型的幻觉问题，并通过预训练的语言模型微调和合成少数类过采样技术来平衡类别不平衡，从而实现更准确的MBTI预测。", "conclusion": "在现实世界的社交媒体数据集上进行的实验表明，PtoP相比10个机器学习和深度学习基线模型取得了最先进的性能。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00461", "html_url": "https://arxiv.org/abs/2509.00461", "title": "TECP: Token-Entropy Conformal Prediction for LLMs", "title_en": "TECP: Token-Entropy Conformal Prediction for LLMs", "authors": "Beining Xu,Yongming Lu", "background": "在开放生成语言领域，不确定性量化（UQ）仍然是一个关键且较少研究的挑战，尤其是在黑盒约束条件下，内部模型信号不可得。现有的方法依赖于语义一致性或白盒特征来估计不确定性。", "innovation": "本文引入了一种名为Token-Entropy Conformal Prediction（TECP）的新框架。该方法利用令牌级别的熵作为无需逻辑符和参照的不确定性度量，并将其集成到分隔的符合预测（CP）管道中，以构建具有正式覆盖保证的预测集。TECP直接从生成的标记熵结构中估计表征不确定性，并通过CP分位数校准不确定性阈值以确保可证明的误差控制。", "conclusion": "经六种大型语言模型和两个基准（CoQA和TriviaQA）的实证评估表明，TECP能可靠地提供紧凑的预测集并且优于基于自一致性的方法。该方法为黑盒LLM设置中的可信赖生成提供了一个原理性且有效的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04456", "html_url": "https://arxiv.org/abs/2509.04456", "title": "Mentalic Net：基于RAG的对话AI及其心理健康支持评估框架的发展", "title_en": "Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support", "authors": "Anandi Dutta,Shivani Mruthyunjaya,Jessica Saddington,Kazi Sifatul Islam", "background": "大型语言模型（LLMs）的兴起为医学领域带来了前所未有的机遇与挑战。本文针对这一背景，提出了一种心理健康支持聊天机器人，旨在加强专业医疗服务。该系统探讨了准确性、同理心、可信度、隐私和偏见等多个评估维度。", "innovation": "创新之处在于，使用了检索增强生成（RAG）框架，并结合了提示工程，同时针对新数据集对预训练模型进行了微调。最终建立的Menticai Net对话AI系统在BERT Score评估中获得了0.898的成绩，其他评估指标也处于满意范围内。", "conclusion": "本文倡导在开发颠覆性技术时采取人为核心的方法和长期负责任的战略，认识到这些技术虽然有可能改变人们的生活，但如果管理不善，也可能带来风险。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04464", "html_url": "https://arxiv.org/abs/2509.04464", "title": "LLM的多条响应能否揭示其不确定性来源？", "title_en": "Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?", "authors": "Yang Nan,Pengfei He,Ravi Tandon,Han Xu", "background": "虽然大型语言模型（LLMs）在多个领域取得了显著突破，但它们仍然可能生成不可靠或误导性的输出，这对实际应用构成了重要挑战。尽管许多近期研究集中在量化模型不确定性上，但较少有研究致力于诊断不确定性产生的具体原因。背景指出，当LLM不确定时，其生成响应之间的差异模式包含了关于不确定性来源的重要线索。", "innovation": "论文展示了通过收集来自目标LLM的多个响应，并使用辅助LLM分析这些响应间的分歧模式，以推理和识别不确定性来源的新方法。辅助模型能够判断不确定性是源于输入问题的模糊性、知识不足，还是两者兼有。对于知识缺口情况，辅助模型还能识别具体缺失的事实或概念。通过实验证明该方法在多种数据集上具有诊断不同不确定性来源的普适性潜在用途。", "conclusion": "诊断不确定性显示了通过相关的人工干预提高LLM表现和可靠性的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04467", "html_url": "https://arxiv.org/abs/2509.04467", "title": "在推理中提升大语言模型效率：面向前置解码分离的精确定位剪枝", "title_en": "Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference", "authors": "Hao Zhang,Mengsi Lyu,Yulong Ao,Yonghua Lin", "background": "大语言模型（LLMs）在各种任务中表现出色，但它们的部署受到高计算和内存成本的限制。模型剪枝提供了一种有效的手段来减轻这些需求。然而，现有的方法往往忽视了实际中的前置解码（PD）分离（Prefill-Decode Disaggregation）特性。", "innovation": "本文提出了一种针对PD分离推理的新型剪枝方法，实现了对感兴趣区块和KV缓存的更精确和高效的剪枝。方法包括构造剪枝和蒸馏集，独立地对填充阶段和解码阶段进行迭代式块移除，获取更好的剪枝方案。此外，引入了一种意识到令牌的缓存剪枝机制，在填充阶段保留所有KV缓存，但在解码阶段仅选择性重用部分层中的第一个和最后一个令牌序列的缓存条目，以减少通信成本并保持较小的开销。", "conclusion": "广泛实验表明，该方法在PD分离和PD统一设置（无论是分离设置还是统一设置）中都实现了稳健的性能。在默认设置下，该方法实现了20.56%的推理速度提升和4.95倍的数据传输带宽减少。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04469", "html_url": "https://arxiv.org/abs/2509.04469", "title": "多模态视觉 vs 文本解析：发票处理中LLM策略的基准测试", "title_en": "Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing", "authors": "David Berghaus,Armin Berger,Lars Hillebrand,Kostadin Cvejoski,Rafet Sifa", "background": "该论文使用零样本提示，在三个不同类别的公开可用的发票文档数据集上，对来自三个不同家族（GPT-5、Gemini 2.5和开源的Gemma 3）的八个多模态大型语言模型进行了基准测试。研究了两种处理策略：直接利用多模态能力处理图像和先结构化解析转换为Markdown。研究表明，原生图像处理通常优于结构化方法，但性能在不同的模型类型和文档特征之间存在差异。", "innovation": "该论文首次将多模态和文本解析两种处理策略在大型语言模型上进行比较基准测试，特别聚焦于发票处理任务。研究结果提供了选择适用于自动化文档系统的适当模型和处理策略的见解。", "conclusion": "基准测试结果表明，原生图像处理通常比结构化解析方法在多模态大型语言模型上更有效，但具体表现取决于模型类型和文档的具体特征。此研究提供了在选择适合自动化文档系统的模型和处理策略方面的参考。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01249", "html_url": "https://arxiv.org/abs/2508.01249", "title": "AgentArmor：通过针对代理运行时轨迹进行程序分析来防御提示注入攻击", "title_en": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection", "authors": "Peiran Wang,Yang Liu,Yunfei Lu,Yifeng Cai,Hongbo Chen,Qingyou Yang,Jie Zhang,Jue Hong,Ye Wu", "background": "大型语言模型（LLM）代理通过将自然语言推理与外部工具执行结合起来，为解决各种问题提供了新的强大范式。然而，其动态且不透明的行为引入了关键的安全风险，特别是在存在提示注入攻击的情况下。", "innovation": "提出了一种新颖的见解，将代理运行时轨迹视为具有可分析语义的结构化程序。据此，提出了一种名为AgentArmor的程序分析框架，将代理轨迹转换为基于图中间表示的结构化程序依赖表示（如CFG、DFG和PDG），并通过类型系统实现安全策略。AgentArmor包含三个关键组件：（1）图构造器，将代理的运行时轨迹重构为带有控制和数据流描述的基于图的中间表示；（2）属性注册表，附上与工具和数据交互相关的安全相关信息；（3）类型系统，在中间表示上执行静态推断和检查。", "conclusion": "通过将代理行为表示为结构化程序，AgentArmor实现了对敏感数据流、信任边界和策略违反的程序分析。在AgentDojo基准测试中评估了AgentArmor，结果显示，与ASR相比，AgentArmor可以降低3%，而功能性损失仅为1%。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04468", "html_url": "https://arxiv.org/abs/2509.04468", "title": "基于CFA的大型语言模型金融推理评估研究", "title_en": "Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study", "authors": "Xuan Yao,Qianteng Wang,Xinbo Liu,Ke-Wei Huang", "background": "大型语言模型的快速发展在金融应用中带来了巨大机会，但在专门的金融环境下系统评价仍然有限。本文通过使用涵盖CFA各级别的1,560道标准化多项选择题进行首次全面评估，CFA是全球最严格的专业认证之一，反映了实际金融分析的复杂性。", "innovation": "研究引入了首个全面评估前沿大型语言模型的方法，采用基于CFA的多模态和计算强、推理专业化和高精度、轻量级效率优化三种模型；并通过零样本提示和新颖的检索增强生成（RAG）管道进行评估。RAG系统通过层次知识组织和结构化查询生成实现精确的专业知识提取，显著提高了推理准确性。", "conclusion": "推理导向的模型在零样本设置中表现最佳，并且RAG管道特别在复杂情境中提供显著改进。详细的错误分析发现知识空白是主要失败模式，而文本可读性影响很小。这些发现为金融中大型语言模型的应用提供了行动指导，为模型选择和成本-性能优化提供了证据基础。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "对GPT-5在生物医药自然语言处理领域的基准测试", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Rui Zhang", "background": "生物医药文献的快速发展提升了对可扩展自然语言处理（NLP）解决方案的需求。虽然GPT-4在问答任务上显著缩小了与专门系统之间的差距，但在其他领域的表现仍然参差不齐。为了评估GPT-5和GPT-4o的表现，研究者更新了一个标准化的BioNLP基准测试，涵盖12个数据集以及六个任务家族：命名实体识别、关系提取、多标签文档分类、问答、文本摘要和文本简化。实验中使用固定提示模板、相同的解码参数和批量推理来比较各模型的表现，并将GPT-5、GPT-4及GPT-3.5和LLaMA-2-13B的结果进行了对比。", "innovation": "研究采用了一套更新的标准BioNLP基准测试来评估GPT-5和GPT-4o在零样本、单样本和五样本提示下的表现。GPT-5在各任务上的总体表现最佳，尤其在问答、实体识别和关系提取任务上表现出色，甚至超过了有监督学习的先进水平，并达到与专门系统相当的性能。然而，总结和疾病实体识别任务仍然落后于专门基线系统。这些结果将GPT-5定位于一个通用模型，适合用于生物医学问答，同时在精准关键的提取和证据密集的摘要任务上，精细调节或混合方法仍占优势。基准测试为未来BioNLP系统的设计提供了实用指导，指明了简单提示适用的领域和可能需要检索增强或计划机制支持的领域。", "conclusion": "GPT-5在生物医药NLP基准测试中的总体表现优于GPT-4和GPT-4o，尤其在问答和实体识别任务上取得了显著进步，达到了有监督学习的先进水平，但在总结和疾病实体识别任务上仍落后于专门的基线系统。这些结果认为GPT-5是一个通用模型，适合生物医学问答的部署，而对精准关键的提取和证据密集的总结任务，则继续偏向专门调整或混合方法。基准测试为未来BioNLP系统的开发提供了实际指导，明确了哪些情况下需要简单提示以及哪些情况下需要检索增强或计划机制的支持。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04470", "html_url": "https://arxiv.org/abs/2509.04470", "title": "COCORELI：合作和组成性的语言指令再构与执行", "title_en": "COCORELI: Cooperative, Compositional Reconstitution \\& Execution of Language Instructions", "authors": "Swarnadeep Bhar,Omar Naim,Eleni Metheniti,Bastien Navarri,Loïc Cabannes,Morteza Ezzabady,Nicholas Asher", "background": "论文背景探讨了大型语言模型（LLMs）在执行需要遵循复杂指令、减少幻觉以及进行空间推理的任务时的局限性。它指出现有的单一LLM推理系统和代理LLM系统（使用更大规模的LLM模型）虽然有所进步，但仍然存在问题，如幻觉和信息处理不准确等问题。文章提到需要设计新的框架来解决这些问题。", "innovation": "论文创新之处在于提出了一种名为COCORELI的混合代理框架，该框架通过结合中型LLM代理、新颖的抽象机制和语境解析模块，能够动态地学习和表示环境的高层次表示。相对于现有的单一LLM模型和代理LLM系统，COCORELI在自然协作构建任务中的表现更优异，能够有效减少幻觉、识别缺失信息并进行澄清和更新学习的对象。此外，COCORELI的抽象能力不仅限于环境领域，还能够在ToolBench API任务中得到验证。", "conclusion": "实验结果表明，COCORELI框架能够显著提高协作构建任务中的表现，有效避免幻觉，准确识别并补充信息，同时提升学习效果。该框架的能力不仅限于环境理解，还能扩展到其他领域，显示出其广泛的适用性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04465", "html_url": "https://arxiv.org/abs/2509.04465", "title": "冲突情境下情感意识代理在纠纷解决中的应用", "title_en": "Emotionally-Aware Agents for Dispute Resolution", "authors": "Sushrita Rakshit,James Hale,Kushal Chawla,Jeanne M. Brett,Jonathan Gratch", "background": "在冲突中，人们通过情感表达来影响对方的态度、情绪和行为。已有研究表明，自动情绪识别技术在谈判中具有潜力，但纠纷中引发的情绪更强烈，其背后的社会过程也不同。本文通过研究买卖双方纠纷对话中的情感表达如何影响主观和客观结果，来探讨这个问题，并利用大规模语言模型提高情绪强度标注的效果，使其更接近人类标注者的决定，支持现有理论模型，同时暗示基于代理系统的纠纷管理可能出现新的可能。", "innovation": "使用大规模语言模型进行情绪强度注释，相比先前方法具有更大的解释力，并且更好地与人类标注者的决策相匹配。文章还指出，基于代理系统的纠纷处理可能通过识别和缓解情绪升级来发挥潜在的作用。", "conclusion": "研究结果支持现有理论模型，表明情绪表达在冲突升级和解决中起重要作用，同时也提出基于代理系统的纠纷管理方法可能是一个有前景的方向。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04473", "html_url": "https://arxiv.org/abs/2509.04473", "title": "SpeechLLM: 在低资源环境中的统一语音和语言模型以增强多任务理解", "title_en": "SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings", "authors": "Jaekwon Yoo,Kunal Chandiramani,Divya Tadimeti,Abenezer Girma,Chandra Dhir", "background": "将语音编码器与大语言模型（LLM）集成需要大量的数据和资源，但由于可用性不足，实际应用场景受到限制。为解决这一问题，本文提出了一种参数高效适配器，该适配器能将语音嵌入转换为LLM兼容的令牌，集中在端到端的自动语音识别（ASR）、命名实体识别（NER）和情感分析（SA）任务上。为了减少标注成本，利用了基于大语言模型的合成数据集标注技术。", "innovation": "提出的适配器使用了7倍少的可训练参数，并取得了显著的效果提升。在LibriSpeech ASR任务上实现了26%的相对词错率（WER）改进，在NER任务上达到了6.3%的相对F1分数提升，在SA任务上则获得了32%的相对F1分数提升。此外，通过添加分类器正则化器以及使用低秩适应（LoRA）优化大语言模型，还进一步提升了表现，使得Spoken Language Understanding Evaluation（SLUE）得分分别提高了6.6%和9.5%。", "conclusion": "研究提出了一种参数高效适配器，通过合成数据集标注技术、分类器正则化和LoRA优化等方法，显著提升了多任务理解中的效果。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04460", "html_url": "https://arxiv.org/abs/2509.04460", "title": "CoCoNUTS: 关注内容忽视无信息文本风格的AI生成同行评审检测", "title_en": "CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection", "authors": "Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun", "background": "大型语言模型（LLMs）在同行评审过程中的集成引发了对学术评估公平性和可靠性的潜在风险。虽然LLMs在语言润色方面为评审者提供了有价值的支持，但对其用于生成实质性评审内容的担忧正在增加。现有的通用AI生成文本检测器容易受到改写攻击，并且难以区分句式修辞上的自然语言修饰和实质性内容的生成，表明它们主要依赖于句式线索。将这些限制应用于同行评审，会导致对于可能接受AI辅助语言增强的评审不公平地怀疑，而未能检测出具有欺骗性的人类化的AI生成评审。", "innovation": "我们提出了一种从基于风格的检测转向基于内容的检测的范式变化。我们引入了CoCoNUTS，这是一个基于细粒度人工智能生成同行评审数据集的内容导向基准，涵盖了六种不同的人机协作模式。我们还开发了CoCoDet，这是一种基于多任务学习框架的人工智能评审检测器，设计用于更准确和稳健地检测评审内容中的人工智能参与。我们的工作为评估LLMs在同行评审中的使用提供了实用的基础，并促进了更精确、公平和可靠的检测方法的发展，适用于现实世界的学术应用。我们的代码和数据将在公开的URL地址处提供。", "conclusion": "我们的工作提供了评估LLMs在同行评审中使用的基础，并促进了对真实世界学术应用的更精确、公平和可靠的检测方法的发展。我们的代码和数据将会公开提供。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04471", "html_url": "https://arxiv.org/abs/2509.04471", "title": "MOSAIC: 多语种、分类学无关和计算效率高的影像报告分类方法", "title_en": "MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification", "authors": "Alice Schiavone(1 and 2),Marco Fraccaro(3),Lea Marie Pehrson(1, 4 and 5),Silvia Ingala(4 and 6),Rasmus Bonnevie(3),Michael Bachmann Nielsen(5),Vincent Beliveau(7),Melanie Ganz(1 and 2),Desmond Elliott(1) ((1) Department of Computer Science, University of Copenhagen, Denmark, (2) Neurobiology Research Unit, Copenhagen University Hospital, Denmark, (3) Unumed Aps, Denmark, (4) Department of Diagnostic Radiology, Copenhagen University Hospital, Denmark, (5) Department of Clinical Medicine, University of Copenhagen, Denmark, (6) Cerebriu A/S, Denmark, (7) Institute for Human Genetics, Medical University of Innsbruck, Austria)", "background": "放射学报告中包含丰富的临床信息，可用于训练影像模型，而无需依赖昂贵的手动注释。现有的方法面临诸多挑战：基于规则的方法难以应对语言变化性，监督模型需要大量标注数据集，而最近的基于大规模语言模型（LLM）的方法依赖于闭源或资源密集型的模型，不适合临床应用。此外，当前的解决方案主要局限于英语和单一模态、单一分类学的数据集。", "innovation": "我们介绍了一种名为MOSAIC的方法，这是一种多语言、分类学无关且计算效率高的影像报告分类方法。该方法基于一个紧凑型开源语言模型（MedGemma-4B），支持零样本/少量样本提示和轻量级微调，能够在消费级GPU上部署。MOSAIC在英、西、法、丹语的七个数据集上进行评估，覆盖多种成像模态和标签分类学。模型达到了88的平均宏F1分数，在某些情况下，使用80个标注样本的数据增强就足以达到82的加权F1分数，与使用完整1600个样本的训练集相比仅需较少数据。MOSAIC提供了一种在临床环境中替代大型或专有LLM的实用替代方案。代码和模型是开源的，社区可以进一步评估和扩展MOSAIC至新的语言、分类学和模态。", "conclusion": "MOSAIC提供了一种实用的选择，可以在临床环境中替代大型或专有LLM，代码和模型均开源供社区评估和扩展。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04475", "html_url": "https://arxiv.org/abs/2509.04475", "title": "ParaThinker：一种新的大规模语言模型测试时计算扩展的新范式", "title_en": "ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute", "authors": "Hao Wen,Yifan Su,Feifei Zhang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大规模语言模型（LLMs）的进步主要依赖于测试时计算量的扩展策略，该策略通过生成更长的、连续的思想过程来提升推理能力。尽管有效，但当计算量增加时，这种方法会遇到一个瓶颈，即进一步的计算仅提供边际性能提升。", "innovation": "本文提出了一种新的计算扩展范式：本征思想并行性。为此，提出了ParaThinker框架，该框架训练LLM同时生成多个多样化的思想路径并合成出更好的最终答案，从而有效避免了“隧道视野”问题并释放模型潜在的推理能力。研究表明，与顺序扩展计算相比，同时扩展计算（宽度）是实现更好推理的有效且高效的方式。", "conclusion": "在复杂的推理基准测试中，ParaThinker在平均情况下1.5B和7B模型上分别比顺序LLM获得了12.3%和7.5%的显著准确度提升，同时仅增加了无足轻重的时间延迟（7.1%）。这使得较小的模型能够超越更大的模型，并确立了平行思考是未来LLM扩展的关键、高效的维度。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04478", "html_url": "https://arxiv.org/abs/2509.04478", "title": "使用双组件NLG引擎的一种端到端文化适应性驾驶反馈系统", "title_en": "An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine", "authors": "Iniakpokeikiye Peter Thompson,Yi Dewei,Reiter Ehud", "background": "在尼日利亚这样一个资源有限且基础设施挑战显著的环境中，本研究提出了一种端到端的移动系统，该系统为司机提供文化适应性的安全驾驶反馈。文章描述了该系统的完整架构，包括自动行程检测服务、设备上行为分析及一种利用两步反思过程的复杂NLG流程，以确保高质量的反馈。系统还包括专门的机器学习模型，用于检测受酒精影响的驾驶行为，这是当地一个关键的安全问题。", "innovation": "该研究的核心是开发了一种新颖的双组件自然语言生成(NLG)引擎，它可以提供既基于法律的安全建议，又具有理论驱动的具有说服力的行为报告。系统设计旨在在出现间歇性连接和嘈杂传感器数据时仍能保持稳健性。系统架构考虑了这些挑战。", "conclusion": "通过与90名司机的试点部署，该系统演示了其实现社会目标的可行性。初步结果显示，在检测到不安全驾驶行为方面取得了一定成果。这项工作提供了一个将数据到文本和AI系统应用于社会福利的框架。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04474", "html_url": "https://arxiv.org/abs/2509.04474", "title": "提升规模，加速运算：高效大型语言模型测试时缩放投机解码的基准", "title_en": "Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling", "authors": "Shengyin Sun,Yiming Li,Xing Li,Yingzhao Lian,Weizhe Lin,Hui-Ling Zhen,Zhiyuan Yang,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Chen Ma", "background": "测试时缩放作为一种增强大型语言模型（LLMs）推理能力的强大范式，通过在推理时分配额外的计算资源来提高性能。然而，这一方法固有地不够高效，因为它会产生冗余和重复的推理过程，导致显著的计算开销。在具有结构化和重复性特点的测试时缩放环境中，投机性解码提供了一种潜在有效的解决途径，但这一领域尚未得到充分研究。为了解决这一问题，本文介绍了首个针对投机性解码方法的全面基准测试，旨在加速LLM的测试时缩放。该基准提供了统一的实验协议，以评估模型为基础、基于训练和基于n-gram的投机性解码方法在典型测试时缩放范式中的性能差异，促进了不同方法间的公平比较。实验表明，简单的基于n-gram的方法能够有效捕捉重复模式，并具有加速测试时缩放的潜在价值。这一发现体现了将基于n-gram的方法与其他方法结合以平衡加速重复性与多样性推理的想法在测试时缩放中的价值。", "innovation": "本文提出了首个针对投机性解码方法的全面基准测试，旨在评估不同类型的投机性解码方法（基于模型、基于训练和基于n-gram）在典型测试时缩放范式中的效果，从而促进公平比较并揭示简单基于n-gram方法的独特加速潜力。此外，该研究还旨在通过结合不同方法来提高测试时缩放中重复性和多样性推理的平衡加速效果。该基准的发布有望推动进一步研究探索，通过更有效地处理重复和多样性推理路径，使LLM的推理速度更快且更实用。", "conclusion": "该研究展示了基于n-gram的方法在测试时缩放加速中的有效性，并提出了结合不同方法以平衡重复和多样性推理过程加速的思路。这为未来研究投机性解码方法在测试时缩放中的应用提供了新的视角，有助于推动LLM在大规模应用中的快速和实用性推理能力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04483", "html_url": "https://arxiv.org/abs/2509.04483", "title": "DecMetrics: 结构化断言分解评分以实现事实一致的LLM输出", "title_en": "DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs", "authors": "Minghui Huang", "background": "断言分解在事实核查过程中起着关键作用，通过将复杂的断言分解为更简单的原子组件并识别其不实元素。尽管断言分解的重要性显著，但当前的研究主要集中在生成性分解方法上，对评估这些分解后的原子断言质量的关注不足。因此，需要一种新的方法来评估分解断言的质量，从而提高事实核查系统的可靠性和有效性。", "innovation": "引入了DecMetrics，它包括三个新的评估指标：完整度（COMPLETENESS）、正确性（CORRECTNESS）和语义熵（SEMANTIC ENTROPY），用于自动评估由分解模型生成的断言质量。通过将这些指标作为奖励函数集成到模型中，开发出一种轻量级的断言分解模型，从而为断言分解设定基准，进一步提高事实核查系统的可靠性和有效性。", "conclusion": "通过自动评估，我们的方法旨在为断言分解设置一个基准，增强事实核查系统的可靠性和有效性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04466", "html_url": "https://arxiv.org/abs/2509.04466", "title": "语言模型中的即时且分布式任务表示", "title_en": "Just-in-time and distributed task representations in language models", "authors": "Yuxuan Li,Declan Campbell,Stephanie C. Y. Chan,Andrew Kyle Lampinen", "background": "语言模型通过上下文学习展现出了令人印象深刻的能力：基于指令或示例，它们无需更新权重就能推测并执行新的任务。这项工作旨在探索在语言模型中，新任务表示是如何形成的，以及这些表示如何随着上下文的变化而变化。主要关注的是可转移的任务表示——能够在模型的其他实例中恢复任务上下文，即使没有完整的提示。研究发现这些表示是非单调且偶发变化的，不同于持续存在于整个上下文中更稳定的高层次任务类别表示。模型会将多个证据集中体现在这些可转移的任务表示中，这与上下文提供的更多示例性能提升相吻合。然而，这个累积过程在序列维度上具有强烈的地方性，仅在某些token处上线——尽管任务标识在整个上下文中可靠可解。此外，这些局部但可转移的任务表示倾向于捕捉最小的任务范围，如语义独立的子任务，模型依赖于更时空分布的表示来支持更长且复合的任务。这种双重地方性（时间性和语义）揭示了语言模型适应新证据并即兴学习新任务的即时计算过程。", "innovation": "这项工作创新性地深入研究了语言模型中指令和示例如何影响新任务表示的形成和变化，揭示了可转移任务表示的特性与演变机制。研究发现，模型不仅依赖于连续的上下文提供多个示例来累积任务表示，而且这些表示在时间和语义上具有局部性。这种新的理解有助于我们更好地理解语言模型的学习机制和动态表示更新过程。", "conclusion": "语言模型中的新任务表示是逐步且局部生成的，这些表示不仅在时间维度上分布不均，在语义上也具有针对性。这表明，模型在处理特定任务时采用了即时响应与分布式记忆相结合的策略，从而能够在学习新的任务时实现灵活和高效的适应。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04480", "html_url": "https://arxiv.org/abs/2509.04480", "title": "通过递归利用黑盒多模态大型语言模型进行离散提示调谐以实现个性化视觉情感识别", "title_en": "Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition", "authors": "Ryo Takahashi,Naoki Saito,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama", "background": "视觉情感识别（VER）因其在意见挖掘和广告设计等广泛领域的应用而成为重要的研究课题。将其能力扩展到个体层面进一步扩大了其潜在应用范围。最近，多模态大型语言模型（MLLMs）引起越来越多的关注，并且其性能与传统VER方法相当。然而，MLLMs在训练时使用了大量的多样化的数据集，包含一般的观点，导致它们倾向于支持主流观点和熟悉模式。这限制了它们在个性化VER中的表现，而个性化VER对于实际应用和真实世界的场景至关重要，这表明改进的关键领域。", "innovation": "该方法引入了受人类提示工程过程启发的离散提示调谐方法，以适应个性化VER任务。方法从生成的提示中选择最佳的自然语言表示，并使用它来更新提示，以实现准确的个性化视觉情感识别。这种方法通过递归利用黑盒多模态大型语言模型，克服了MLLMs的局限性，提升了个性化的情感识别能力。", "conclusion": "本研究提出的方法通过离散提示调谐提升了个性化视觉情感识别的准确性，相比于传统的MLLMs方法，它更适应于个体的情感识别需求，为个性化情感识别提供了新的途径。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04476", "html_url": "https://arxiv.org/abs/2509.04476", "title": "基于上下文感知分词训练文本到分子模型", "title_en": "Training Text-to-Molecule Models with Context-Aware Tokenization", "authors": "Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin", "background": "近年来，文本到分子模型在各种化学应用中显示出巨大潜力，例如药物发现。这些模型将语言模型适应分子数据，通过将分子表示为原子序列。然而，它们依赖于原子级别的分词，主要关注局部连接性建模，从而限制了模型捕捉分子内部全局结构背景的能力。", "innovation": "我们提出了一种新的文本到分子模型，名为上下文感知分子 T5 (CAMT5)。该模型通过引入亚结构级别的分词，重视亚结构在理解分子结构中的重要性（例如环系统），并在基于分词方案的基础上开发了一种基于重要性的训练策略，优先考虑关键亚结构，使 CAMT5 更好地捕捉分子语义。此外，我们还提出了一种简单有效的集成策略，将文本到分子模型的输出聚合，以进一步提升生成性能。实验结果验证了 CAMT5 在多种文本到分子生成任务中的优越性，即使使用训练词典的 2% 也能超越最新方法。", "conclusion": "我们的研究结果验证了 CAMT5 在多种文本到分子生成任务中的优越性能，并提出了一种简单有效的集成策略进一步提高生成性能。代码已公开。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04484", "html_url": "https://arxiv.org/abs/2509.04484", "title": "from 'The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors' to '正面的、负面的和建设性的：自动评估同行评审对作者的帮助程度。'", "title_en": "The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors", "authors": "Abdelrahman Sadallah,Tim Baumgärtner,Iryna Gurevych,Ted Briscoe", "background": "同行评审中为作者提供建设性的反馈是一个核心组成部分。随着评审者可用的时间越来越少，需要自动化支持系统来确保高质量的评审，让反馈对作者有用。识别出四个影响作者反馈有用性的关键方面：可操作性、基础性和具体性、可验证性和帮助性。基于此，研究引入了一个名为RevUtil的数据集，收集了1,430条人工标注的评审意见，并使用10,000条合成标注的评论进行训练。通过RevUtil数据集，研究团队评估了评估评审意见并生成解释的模型性能，实验结果显示，这些模型在某些方面甚至优于像GPT-4这样的强闭合模型。进一步分析显示，机器生成的评审意见在四个方面通常不如人工评审意见。", "innovation": "研究识别了四个影响作者反馈有用性的关键方面，并利用这些方面构建了一个名为RevUtil的数据集。通过该数据集，研究人员评估和开发了评估和生成理由的模型，展示了这些模型在评估方面的能力，并与强大的闭合模型进行了比较。同时，研究还揭示了机器生成的评审意见在某些方面的表现不如人工评审意见。", "conclusion": "机器生成的评审意见在四个方面通常不如人工生成的评审意见。尽管如此，自动评估模型在某些方面能够达到甚至超过强闭合模型的表现，这些模型为未来改进自动化同行评审过程提供了潜力。通过引入RevUtil数据集，研究为这一领域的进一步研究和开发奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04472", "html_url": "https://arxiv.org/abs/2509.04472", "title": "RECAP：为意图理解进行对话重写", "title_en": "RECAP: REwriting Conversations for Intent Understanding in Agentic Planning", "authors": "Kushan Mitra,Dan Zhang,Hannah Kim,Estevam Hruschka", "background": "理解用户意图对于对话助手的有效规划至关重要，尤其是使用大型语言模型（LLMs）协调多个代理的助手。然而，现实世界的对话往往具有模糊性、不明确性或动态性，使意图检测成为一个持久的挑战。传统的基于分类的方法在开放环境下难以泛化，导致脆弱的解释和低效的后续规划。", "innovation": "我们提出了一个名为RECAP的新基准（REwriting Conversations for Agent Planning），旨在评估和促进意图重写，将用户-代理对话重新框架为用户目标的简洁表示。RECAP捕捉到诸如模糊性、意图漂移、模糊性和混合目标对话等各种挑战。此外，我们还引入了一个基于LLM的评估器，可以评估重写意图的规划实用性。通过使用RECAP，我们开发了一种基于提示的重写方法，其性能优于基线。进一步通过微调两种DPO基重组写器，我们可以获得额外的效用提升。我们的研究表明，意图重写是提高开放领域对话系统中代理规划的关键且可处理的组件。", "conclusion": "我们的结果强调了意图重写在提高开放领域对话系统中代理规划方面的关键作用。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04488", "html_url": "https://arxiv.org/abs/2509.04488", "title": "基于大型语言模型的多说话人语音识别的序列输出提示", "title_en": "Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition", "authors": "Hao Shi,Yusuke Fujita,Tomoya Mizumoto,Lianbo Liu,Atsushi Kojima,Yui Sudo", "background": "现有基于大型语言模型（LLM）的多说话人（MT）自动语音识别（ASR）系统要么省略提示，要么依赖简单的任务定义提示，没有研究探索如何设计提示来增强性能。", "innovation": "提出了提取序列输出提示（SOP）并明确引导LLM使用结构化提示以改进系统性能的方法（SOP-MT-ASR）。通过在语音编码器后插入分隔器和序列化的连接主义时序分类（CTC）层，实现并发说话人的逐个分离和提取。序列化CTC输出通过贪婪搜索进行解码得到SOP，用于指导LLM。提出了三种训练策略，包括序列输出训练（SOT）微调、序列化语音信息提取和SOP为基础的适应。", "conclusion": "实验结果显示，尽管基于大型语言模型的SOT模型在双说话人场景中表现良好，但在更复杂的三说话人场景中未能充分利用大型语言模型。所提出的SOP方法在双说话人和三说话人条件下均显著提高了性能。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04491", "html_url": "https://arxiv.org/abs/2509.04491", "title": "使用基于提示的弱监督训练改进电视字幕转写", "title_en": "Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR", "authors": "Xinnian Zhao,Hugo Van Hamme", "background": "尽管电视字幕易于获取，但由于其与对应音频的对齐不够精确，限制了它们作为用于verbatim转写的直接监督目标的适用性。现有方法通常直接使用子标题作为监督信号，而忽略了子标题与音频之间存在的差异，从而在转写准确性上存在局限性。", "innovation": "提出了一种新的方法，将电视字幕重新构想为富含上下文的提示，生成伪转录文本作为主要目标，子标题作为指导线索进行迭代优化。引入加权注意力机制，增强模型在推理过程中对相关字幕标记的重视程度，从而提高转写准确性。", "conclusion": "实验结果表明，这种方法显著提高了转写准确性，展示了该方法在增强伪标记数据集质量方面有效性的潜力，这些高质量的伪标记数据集可作为训练稳健ASR系统的基础资源。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04500", "html_url": "https://arxiv.org/abs/2509.04500", "title": "Context 工程for 信任度: Rescorla Wagner 导航在混合和不适当背景下的应用", "title_en": "Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts", "authors": "Rushi Wang,Jiateng Liu,Cheng Qian,Yifan Shen,Yanzhou Pan,Zhaozhuo Xu,Ahmed Abbasi,Heng Ji,Denghui Zhang", "background": "大型语言模型（LLMs）的响应质量可以通过融入外部背景环境显著提高，但现实世界的背景往往混杂着相关和不恰当的信息。这种混合背景可能导致模型输出质量下降，并且可能引入可靠性风险。因此，研究LLMs如何处理和筛选这些背景信息变得尤为重要。", "innovation": "为了研究这个问题，作者引入了一个名为Poisoned Context Testbed的新测试平台，通过将查询与带有相关和不恰当信息的现实世界背景配对。作者基于神经科学中的Rescorla-Wagner模型，提出了一个改进模型来量化竞争背景信号对LLM输出的影响。此外，作者提出了一种名为RW-Steering的新两阶段微调方法，该方法使模型能够内部识别和忽略不适当的信息。与依赖于广泛监督的前方法不同，RW-Steering在不同比例的不适当内容下都能保持鲁棒性。", "conclusion": "实验结果表明，作者的最佳微调模型将响应质量提高了39.8%，并且逆转了不希望的行为趋势，从而使RW-Steering成为提高LLM在现实世界使用中安全性的稳健、可泛化的背景设置解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04501", "html_url": "https://arxiv.org/abs/2509.04501", "title": "理解模型训练中的强化学习以及GRAPET的未来方向", "title_en": "Understanding Reinforcement Learning for Model Training, and future directions with GRAPE", "authors": "Rohit Patel", "background": "本文旨在提供一个自包含的、从头开始的介绍，涵盖模型指令调整中关键算法：SFT、拒绝采样、REINFORCE、信任区域策略优化（TRPO）、接近策略优化（PPO）、组相对策略优化（GRPO）和直接偏好优化（DPO）。现有解释往往假设读者已有先验知识，缺乏关键细节，或是过于泛化和复杂。本文通过逐步简化和明确的符号解释这些算法，专注于大型语言模型（LLMs），以消除歧义、提供清晰直观的理解。通过减少对更广泛RL文献的引用，并将概念与LLMs相连，本文消除了多余的抽象并减少了认知负担。", "innovation": "本文通过简化和明确的符号解释现有的复杂算法，专注于大型语言模型（LLMs），填补了现有文献中关于这些算法清晰解释的空白。此外，还提供了一个关于新技术和方法的文献概述，并提出了一种新的研究方向——GRAPET（广义相对优势策略进化）", "conclusion": "在详述上述算法后，本文提供了一个关于新方法和技术的文献回顾，并描述了未来研究的方向——GRAPET（广义相对优势策略进化）的概念，旨在为模型训练中的强化学习提供新的见解。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04482", "html_url": "https://arxiv.org/abs/2509.04482", "title": "能量景观使可靠的回避在医疗保健中的检索增强大型语言模型中得以实现", "title_en": "Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare", "authors": "Ravi Shankar,Sheng Wong,Lin Li,Magdalena Bachmann,Alex Silverthorne,Beth Albert,Gabriel Davis Jones", "background": "在医疗保健等安全关键领域，可靠地回避回答至关重要，错误的答案可能导致严重后果。检索增强生成（RAG）系统需要能够识别何时生成答案或回避回答，特别是在那些语义挑战较高的情况中。现有的方法如校准的Softmax基线和k近邻密度启发式方法虽然在简单情况下表现良好，但在复杂情况下可能不具有优势，因此需要一种新的方法来提高RAG系统在这种复杂情况下的回避性能。", "innovation": "提出了一种基于能量的模型（EBM），通过在260万条指南衍生的问题语义语料库中学习平滑的能量景观，使系统能够决定何时生成或回避回答。与Softmax基线和kNN密度启发式方法相比，EBM在语义上困难的情况下的回避性能更优秀，并且具有更低的误报率。此外，通过对可控负面采样的消融研究表明，系统的稳健性主要来源于能量评分头部，而不同类型的负面样本（困难、简单、混合）对于难以近似的情形并无实质性影响。这些结果说明，基于能量的回避评分比基于概率的Softmax信心提供了更可靠的置信度信号，从而为安全的RAG系统提供了可扩展且可解释的基础。", "conclusion": "基于能量的回避评分提供了一种比基于概率的Softmax信心更加可靠的置信度信号，这为安全的RAG系统的开发提供了一个可扩展且可解释的基础。EBM在避免在复杂情况下的误导性回答方面表现尤为突出，其稳健性和优越性尤为体现在安全关键领域。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04499", "html_url": "https://arxiv.org/abs/2509.04499", "title": "DeepTRACE: 审核深度研究AI系统以跟踪citation和证据的可靠性", "title_en": "DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence", "authors": "Pranav Narayanan Venkit,Philippe Laban,Yilun Zhou,Kung-Hsiang Huang,Yixin Mao,Chien-Sheng Wu", "background": "生成式搜索引擎和深度研究LLM代理承诺提供可信、基于来源的合成内容，但用户经常遇到过度自信、来源弱和引用混淆的问题。当前的审计框架往往依赖于手动审查和事后分析，缺乏系统性和具体性。因此，为了有效评估这些系统的可靠性和真实性，需要一种新的、基于社会和技术的审计框架来衡量系统的整体表现。", "innovation": "DeepTRACE是一款新型的社会和技术基础的审计框架，将社区先前识别的问题转化为八个可以通过文本、来源和引用进行衡量的维度。该框架通过句子级别的分析（分解和置信度评分）和建立引用和事实支持矩阵，全面评估系统如何处理和归因证据。它还采用了自动化提取流水线来评估流行公共模型（如GPT-4.5/5、this http URL、Perplexity、Copilot/Bing、Gemini）和一个具有验证共识的LLM审题工具，以评估网络搜索引擎和深度研究配置。该研究通过实证数据展示了生成式搜索引擎和深度研究代理在辩论查询上的常见问题，并展示了DeepTRACE审计框架的效果，该框架能够评估系统在处理和归因证据时的具体表现，有助于提高AI系统的透明度和可靠性。", "conclusion": "尽管深度研究配置可以在一定程度上减少过度自信和提高引用完整性，但在处理辩论查询时仍然表现出高度的一面性，并且仍有大量无支持的陈述，其中引用准确性在40%到80%之间。因此，DeepTRACE不仅提供了一种评估现有AI系统的有效方法，还提示了改进这些系统的方向和需求。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04479", "html_url": "https://arxiv.org/abs/2509.04479", "title": "没有聚类，没有路由：Transformer实际上是如何处理罕见单词的", "title_en": "No Clustering, No Routing: How Transformers Actually Process Rare Tokens", "authors": "Jing Liu", "background": "大语言模型在预测罕见词时存在困难，但其背后的机制尚不明确。先前的研究揭示了处理罕见词的特定“ plateau”神经元，并遵循独特的三阶段影响模式，但这些神经元的功能组织仍不清楚。本文通过在GPT-2 XL和Pythia模型中进行神经元影响分析、图聚类和注意头的裁剪，来探讨这一问题。", "innovation": "研究发现罕见词处理需要超出普通词所需的幂律阶段的额外“ plateau”神经元，形成双计算阶段；尽管存在分布在空间上的“ plateau”神经元，但未形成模块化簇；此外，注意力机制并未优先导向少数专家处理。因此，这种稀有词的专业化是通过分布式、训练驱动的分化实现的，而非结构模块化，实现了在上下文敏感性和适应性容量分配之间的平衡。", "conclusion": "研究结果表明，稀有词的专业化来源于分布式的，由训练驱动的分化，而不是架构上的模块化，它保持了高度的上下文敏感性和适应性容量分配。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04485", "html_url": "https://arxiv.org/abs/2509.04485", "title": "ASCENDgpt：一种基于表型的电子健康记录心血管风险预测的变换器模型", "title_en": "ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records", "authors": "Chris Sainsbury,Andreas Karwath", "background": "该研究旨在通过长期电子健康记录（EHRs）预测心血管风险。研究提出了一种基于变换器的模型——ASCENDgpt，专门用于从电子健康记录中预测心血管风险。通过一个新颖的表型感知分词方案，将47,155个原始ICD代码映射到176个具有临床意义的表型标记，同时实现99.6%的诊断代码合并率，保留了语义信息。这种方法使词汇量从原始ICD代码直接使用时的52,277个词减少到10,442个词，减少了77.9%。模型经过预训练和微调后，在多种心血管结果（包括心肌梗死、中风、主要不良心血管事件、心血管死亡和全因死亡）上表现出色，显示出强大的预测性能。", "innovation": "ASCENDgpt的核心创新在于其表型感知分词方案，能够将大量原始ICD代码有效地映射到较少的具有临床意义的表型标记，极大地减少了词汇量并提高了模型效率。此外，该模型通过预训练和针对特定心血管结果的时间事件预测进行微调，提高了对心血管风险的预测准确性。", "conclusion": "实验结果表明，ASCENDgpt在预测心血管风险方面表现优异，C-index指标平均值为0.816，验证了其在多种心血管结果上的高性能。研究证明了专门领域的分词和预训练在基于EHR的风险预测任务中的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02586", "html_url": "https://arxiv.org/abs/2509.02586", "title": "MitoDetect++: 一个具有抗域移不变性的胞分裂检测和异常亚型分类管道", "title_en": "MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping", "authors": "Esha Sadia Nasir,Jiaqi Lv,Mostafa Jahanifar,Shan E Ahmed Raza", "background": "在计算病理学中，自动检测和分类胞分裂特别区分异常与正常依然是关键挑战。MitoDetect++旨在解决MIDOG 2025挑战，同时处理胞分裂检测和异常胞分裂分类。", "innovation": "MitoDetect++采用统一的深度学习管道，通过结合使用U-Net架构和EfficientNetV2-L骨干网络（增强注意力模块）以及联合分割损失进行检测；利用Virchow2视觉变换器，通过低秩适应（LoRA）进行微调以减少资源消耗进行分类；通过强数据增强、焦点损失和组感知分层5折交叉验证改进通用性并减轻领域偏移；在推理阶段运用测试时间增强（TTA）以增强鲁棒性。", "conclusion": "方法的平衡准确率达到0.892，突显了其实用性和在任务间的扩展性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04504", "html_url": "https://arxiv.org/abs/2509.04504", "title": "大型语言模型的行为指纹化", "title_en": "Behavioral Fingerprinting of Large Language Models", "authors": "Zehua Pei,Hui-Ling Zhen,Ying Zhang,Zhiyuan Yang,Xing Li,Xianzhi Yu,Mingxuan Yuan,Bei Yu", "background": "当前对大型语言模型（LLMs）的基准测试主要侧重于性能指标，往往未能捕捉到区分模型的具体行为特征。本研究引入了一种新颖的「行为指纹化」框架，旨在通过创建一种涵盖模型内在认知和互动风格的多元化档案，超越传统评估方法。", "innovation": "本研究采用了一组精心挑选的「诊断提示套件」和一项开创性的全自动评估流程，其中强大的LLM作为公正的评判者。本研究分析了18个模型的跨能力层级，结果显示LLM景观中的关键分歧：尽管顶级模型在抽象和因果推理等核心能力上趋于一致，但与一致性有关的行为（如媚态和语义稳健性）却有很大的差异。进一步的交叉模态默认个性聚合（ISTJ/ESTJ）则反映了普遍一致的行为对齐激励。", "conclusion": "本框架提供了一种可重复和可扩展的方法，用于揭示这些深层次的行为差异。这表明模型的互动特性并非其规模或推理能力的自然结果，而是特定且高度可变的开发对齐策略的直接结果。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04507", "html_url": "https://arxiv.org/abs/2509.04507", "title": "从静默信号到自然语言：基于双阶段Transformer-LLM的方法", "title_en": "From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach", "authors": "Nithyashree Sivasubramaniam", "background": "静默语音接口（SSIs）由于能够从非声波信号生成可理解的语音而引起了关注。尽管在语音生成管道方面取得了显著进展，但合成语音的识别和后续处理受到音素歧义和噪声的限制。这些因素降低了静默语音接口的可理解性。", "innovation": "本文提出了一种增强型自动语音识别框架，结合了基于Transformer的声学模型和大型语言模型（LLM）后处理。Transformer捕捉整个语音片段的上下文信息，而LLM确保语言一致性。实验结果显示，在36%的基线基础上，相对减少了16%的词错误率（WER），绝对减少了6%，显著提高了静默语音接口的可理解性。", "conclusion": "实验结果表明，在静默语音识别与处理上，相较于现有的基准线，该方法显著提高了合成语音的可理解性，验证了该框架的有效性和重要性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04498", "html_url": "https://arxiv.org/abs/2509.04498", "title": "我在哪里学习？偏见的语言模型来做决定！评估学术推荐中LM的公平性", "title_en": "Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations", "authors": "Krithi Shailya,Akhilesh Kumar Mishra,Gokul S Krishnan,Balaraman Ravindran", "background": "随着大规模语言模型（LLMs）在日常生活中的应用越来越广泛，特别是在教育规划等任务中，这些模型的推荐结果有可能强化社会偏见。该论文通过实证研究，探讨了三个开源LLMs（LLaMA-3.1-8B、Gemma-7B和Mistral-7B）对学生大学和专业建议中的地理、人口统计和经济偏见。通过使用360个不同的用户模拟资料来分析逾25,000个建议，结果揭示了强偏见现象：全球北方的机构过多受到青睐、性别刻板印象在推荐中频繁出现，以及学术机构的重复推荐普遍。同时，尽管LLaMA-3.1实现了最高的多样性，但系统性差异依然存在。为了量化这些问题，该论文提出了一个新颖的多维度评估框架，该框架不仅衡量准确性，还衡量人口统计和地理代表性。研究结果突显了在教育LAs中考虑偏差的重要性，以确保全球高等教育机会的公平性。", "innovation": "该论文提出了一种新的多维度评估框架，该框架超越了准确性，衡量了人口统计和地理代表性，以评估语言模型在学术推荐中的公平性。这种创新的量化方法为评估和减少模型中的偏见提供了新的工具。同时，通过大规模数据集和多种用户模拟，该研究还揭示了现有模型中的具体偏见类型和程度。", "conclusion": "研究结果强调了在教育LAs中考虑偏见的紧迫性，以确保全球高等教育机会的公平性。通过提出新的评估框架，该研究为未来减少模型偏见提供了可能的路径。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04497", "html_url": "https://arxiv.org/abs/2509.04497", "title": "基于叙述的临床倦怠监控计算框架", "title_en": "A Narrative-Driven Computational Framework for Clinician Burnout Surveillance", "authors": "Syed Ahmad Chan Bukhari,Fazel Keshtkar,Alyssa Meczkowska", "background": "临床工作者的倦怠对患者安全构成了重大威胁，尤其是在高急性重症监护病房(ICU)。现有的研究多依赖于回顾性问卷调查工具或广泛使用的电子健康记录(EHR)元数据，经常忽视了嵌入在临床病历中的有价值叙述信息。这项研究分析了来自Beck Israel Deaconess Medical Center电子健康记录的MIMIC-IV公开数据库中的10,000份重症监护病房出院总结，涵盖了患者的生命体征、医疗指令、诊断、手术、治疗和脱敏自由文本临床记录等多元化数据。", "innovation": "引入了一种结合BioBERT情感嵌入、针对临床病历的情感强度词典和负载代理的五主题潜在狄利克雷分配(LDA)的混合管道。建立了提供者级别的逻辑回归分类器，在分层保留集上实现高精度0.80、召回率0.89和F1分数0.84，高于只使用元数据的基线方法至少提高了0.17个F1分数。专科分析表明，放射学、精神病学和神经学等专科医生的倦怠风险较高。研究结果表明，ICU临床病历包含用于主动健康管理的可操作信号。", "conclusion": "研究发现ICU的临床病历中包含可用于积极监测医师福祉的行动信号，通过一种新的计算框架能够更准确地识别和监控医生的倦怠状况。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04492", "html_url": "https://arxiv.org/abs/2509.04492", "title": "使用标记级熵生产率的黑盒大语言模型中的学习型幻觉检测", "title_en": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate", "authors": "Charles Moslonka,Hicham Randrianarivo,Arthur Garnier,Emmanuel Malherbe", "background": "大型语言模型（LLM）在问答（QA）任务中的生成输出中存在的幻觉严重削弱了它们在实际生活中的可靠性。目前缺乏一种在数据访问受限的情况下（例如，与黑盒LLM API交互，这些API只能提供每个标记的几个顶级候选对数概率）高效且直接检测幻觉的方法。本文探讨了一种应用性较强的单一采样即时幻觉检测方法，该方法可以从生成过程中直接获得的对数概率（非贪婪解码）中提取不确定性指标，以克服这一挑战。", "innovation": "本文提出了一种新型的方法，即利用标记级熵生产率（Token-level Entropy Production Rate, EPR）来学习幻觉检测，这种方法特别适用于数据访问受限的场景。所提出的方法可以直接从一个生成序列中获取的可访问顶级标记的熵贡献特征中学习，无需重新运行多次查询。这种方法在多种QA数据集和多个LLM上的测试结果表明，与仅使用EPR相比，其幻觉检测性能有显著提高。不仅如此，该模型仅依赖于通常可用的小数量对数概率（例如，每个标记最多10个），这进一步证明了其在API受限部署中的实用效率和适用性。", "conclusion": "本研究提供了一种可以直接部署的技术，旨在通过一个生成过程就提升大型语言模型在问答及检索增强生成系统中的响应可信度。该方法已在金融框架中得到了验证，特别是在处理工业数据集中的年度报告查询时。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04508", "html_url": "https://arxiv.org/abs/2509.04508", "title": "ProST: 采用小型语言模型实现帕累托最优多智能体系统的进阶次任务训练", "title_en": "ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models", "authors": "Biddut Sarker Bijoy,Mohammad Saqib Hasan,Pegah Alipoormolabashi,Avirup Sil,Aruna Balasubramanian,Niranjan Balasubramanian", "background": "小型语言模型(SLMs)多智能体系统为解决复杂问题提供了一种替代单智能体系统的选择，后者通常由大型语言模型(LLMs)驱动。本文研究了多智能体系统与单智能体系统在有效性和效率方面的比较。利用不同大小的语言模型在AppWorld环境中的复杂问题实例化单智能体和多智能体系统进行研究。发现小型语言模型在长轨迹学习方面存在困难，导致其性能受限，即便进行了专门任务训练，小型语言模型也难以有效地学习所有子任务。", "innovation": "本文提出了一种简单的分阶段次任务训练策略，该策略在每次训练周期中逐步引入新子任务，类似实例级的课程学习。这一创新策略在所有配置下都有效改善了多智能体系统的效果。实验证明，微调后的多智能体系统在效果与效率之间的权衡方面表现更优。研究还表明，这种方法对于减少子任务错误率具有重要性，这进一步证明了其有效性。", "conclusion": "研究表明，微调的多智能体系统提供了更好的效果效率权衡。此外的研究还强调了分阶段训练策略的重要性和其降低子任务错误率的能力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04515", "html_url": "https://arxiv.org/abs/2509.04515", "title": "通过模型解释缓解AI生成故事中的性别和种族偏差", "title_en": "Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations", "authors": "Martha O. Dimgba,Sharon Oba,Ameeta Agrawal,Philippe J. Giabbanelli", "background": "语言模型的社会偏见广泛存在于其输出中，尤其是在对性别和种族的表征方面。本文研究了AI生成职业故事中的性别和种族偏见，并测量在应用一种名为Bias Analysis and Mitigation through Explanation (BAME) 的缓解策略前后，这些偏见的代表偏差。研究表明，通过分析主要参数未被修改但利用模型生成解释来指导提示工程的职业故事，可以显著提高代际平等问题。通过对25种职业类别、三种大型语言模型（Claude 3.5 Sonnet、Llama 3.1 70B Instruct 和 GPT-4 Turbo）和多个人口统计维度的分析，研究揭示了持续存在的代表性过度和不足模式，这些模式与训练数据中的刻板印象密切相关。", "innovation": "本文介绍了一种新颖的方法——BAME（Bias Analysis and Mitigation through Explanation），它通过利用模型生成的解释来指导提示工程，从而减少偏见，同时不修改模型参数。这种方法能有效缓解职业故事文本中性别和种族的偏见，并且其机制独立于模型内部参数的变化。研究表明，在多种职业和语言模型中使用BAME可以显著增强代际平等。", "conclusion": "通过使用其内部逻辑来指导模型，本研究成功展示了提高代际平等的可能性。这不仅有助于构建更透明的生成式AI系统，还为未来的偏见缓解策略提供了有价值的数据和见解。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04517", "html_url": "https://arxiv.org/abs/2509.04517", "title": "对植入网片后自愿报告数据的分析以检测公众情绪并识别关注报告", "title_en": "Analysis of Voluntarily Reported Data Post Mesh Implantation for Detecting Public Emotion and Identifying Concern Reports", "authors": "Indu Bala,Lewis Mitchell,Marianne H Gillam", "background": "网片植入物在疝气修复手术中广泛应用，但术后并发症是一个重大问题。本研究通过分析2000年至2021年期间制造商和用户设施设备体验（MAUDE）数据库中的患者报告，使用自然语言处理（NLP）研究患者在使用网片植入物后的心理方面。", "innovation": "本研究使用国家研究 Council 加拿大(NRC)情绪词汇表和TextBlob进行情感分析，将患者叙述归类为八大情绪（愤怒、恐惧、期待、信任、惊讶、悲伤、喜悦和恶心）并评估情感极性。研究旨在发现患者情绪随时间的变化模式，并识别可能表示严重担忧的“关注报告”，从而更好地了解患者体验与医疗器械监管和医疗技术进步的关系。", "conclusion": "研究发现，在2011-2012年和2017-2018年期间，关注报告的频率和情感强度有所增加。通过对关注报告和整体情感的时序分析，本研究为医疗服务提供者提供了宝贵的洞察，帮助他们更好地理解手术后的患者体验，这对于改善术前咨询、术后护理和为患者植入网片做准备至关重要。研究强调了在医疗实践中考虑情感的重要性，并指出了情感分析在提高患者护理方面的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04502", "html_url": "https://arxiv.org/abs/2509.04502", "title": "VaccineRAG: 提升多模态大型语言模型抵御有害RAG样本的能力", "title_en": "VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples", "authors": "Qixin Sun,Ziqin Wang,Hengyuan Zhao,Yilin Li,Kaiyou Song,Linjiang Huang,Xiaolin Hu,Qingpei Guo,Si Liu", "background": "检索增强生成（RAG）通过将检索和生成模块与外部知识集成，提升了大型语言模型（LLMs）的响应准确性，尤其在实时查询和视觉问答任务中表现出色。然而，由于检索器的精度限制，许多引入生成阶段的检索样本是不相关或误导性的，严重阻碍了LLMs的性能。为了解决这一挑战，本文提出了VaccineRAG数据集，旨在通过基准测试和引入详细的推理链来评估现有模型并提升它们的样本区分能力，同时提出了一种新的方法Partial-GRPO来增强模型学习复杂推理链的能力，进而提高其处理复杂序列的能力。", "innovation": "1. 提出了VaccineRAG数据集，该数据集采用基准测试方法并设计了一个提示机制，要求LLMs对每个样本生成详细的推理链（CoT）分析，从而提高模型的样本区分能力。\n2. 建议了Partial-GRPO方法，这是一种通过对LLM输出进行建模的方法，将输出视为多个组件而非单一的整体，以更好地处理复杂的推理链内容，从而增强其学习复杂推理链的能力。\n3. 通过全面的评估和消融研究，验证了所提方案的有效性，并将提供代码和数据集供公众使用。", "conclusion": "文章提出的方法通过引入详细的CoT分析和改进的模型训练机制，显著提升了大型语言模型的性能，尤其是应对不相关或误导性检索样本方面的能力，并通过实验证明了该方法的有效性，将该数据集和代码公开以供社区进一步研究。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04549", "html_url": "https://arxiv.org/abs/2509.04549", "title": "通过原理化干预操纵基于变换器的模型：可控性、可引导性和稳健干预", "title_en": "Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions", "authors": "Faruk Alpay,Taylan Alpay", "background": "基于变换器的语言模型在自然语言处理任务中表现出色，但实现细粒度控制依然具有挑战性。本文研究了通过在提示、激活和权重三个层次上进行原则性干预，操纵变换器模型的方法。", "innovation": "提出了一个综合框架，涵盖了提示层面的方向引导、激活层面上的干预措施和权重空间编辑。理论分析表明，最小权重更新可以实现目标行为的改变，同时减少副作用。实验证明，在保持基本性能的前提下，可实现超过90％的情感控制和事实编辑的成功率。", "conclusion": "本文的工作为设计可控且稳健的语言模型奠定了基础，并讨论了伦理上的双重用途风险以及需要进行严格的评估。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04523", "html_url": "https://arxiv.org/abs/2509.04523", "title": "使用大型语言模型创建分析数据集：哥伦比亚历史记忆重构案例研究", "title_en": "Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia", "authors": "David Anderson,Galia Benitez,Margret Bjarnadottir,Shriyan Reyya", "background": "哥伦比亚长期遭受武装冲突的影响，但政府长期以来并未将系统记录暴力事件作为优先事项。这导致缺乏公开的冲突信息和历史记录，影响了社会公共记忆的重建。", "innovation": "利用大型语言模型（LLM）如GPT阅读并回答超过20万篇西班牙语暴力相关报纸文章的问题，创建了一个新的数据集。该研究通过描述性分析以及暴力与可卡因作物清除关系的研究，展示了LLM如何开启新的研究机遇，使得大规模文本语料库的深度研究成为可能。", "conclusion": "本研究通过使用LLM处理大规模文本文本数据，为哥伦比亚的历史记忆和发展提供了支持性分析。这为未来类似研究提供了新的范式，同时也强调了技术进步在历史记忆重构和社会历史研究中的作用。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04606", "html_url": "https://arxiv.org/abs/2509.04606", "title": "将新模态高效集成到大语言模型中的方法", "title_en": "Sample-efficient Integration of New Modalities into Large Language Models", "authors": "Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti", "background": "多模态基础模型能够处理多种模态，但由于可能的模态空间庞大且不断变化，从头训练模型以涵盖所有模态是不可行的。此外，将模态集成到现有的基础模型中需要大量的配对数据，这对于低资源模态来说通常是不可用的。现有的方法在集成新模态时效率低下，需要大量数据。为此，该研究介绍了一种名为样本高效模态集成（SEMI）的方法，旨在提高新模态集成的效率。", "innovation": "该研究提出了一种使用超网络（hypernetwork）的方法，通过高资源模态（如文本、语音、音频和视频）训练一个超网络，该超网络可以根据任何任意模态的少量样本在推理时生成合适的适配器。此外，通过等距变换人工增加编码器的数量以增加训练模态的多样性。实验结果表明，SEMI在稀少样本下集成新模态时表现出显著提升的效率，如卫星图像、天文图像、惯性测量和分子等。例如，要达到32-次样本的SEMI的精度，从头训练投影器则需要64倍的数据。", "conclusion": "SEMI方法通过提高样本效率，为基础模型扩展模态覆盖范围提供了解决方案。该方法在稀少样本下集成新模态时表现出显著提升的效率，并且能够解决低资源模态集成的难题。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04510", "html_url": "https://arxiv.org/abs/2509.04510", "title": "结合虚拟现实和机器学习识别诵读困难：一种跨语言方法", "title_en": "Combine Virtual Reality and Machine-Learning to Identify the Presence of Dyslexia: A Cross-Linguistic Approach", "authors": "Michele Materazzini,Gianluca Morciano,Jose Manuel Alcalde-Llergo,Enrique Yeguas-Bolivar,Giuseppe Calabro,Andrea Zingoni,Juri Taborri", "background": "该研究探讨了使用虚拟现实(VR)和人工智能(AI)来预测意大利和西班牙大学学生中诵读困难的存在。特别地，研究调查了从VR安静阅读(SR)测试和自我评估中获得的数据能否通过机器学习(ML)算法区分受到诵读困难影响的学生和不受影响的学生。", "innovation": "研究利用VR和ML技术，尤其是在安静阅读测试和自我评价中收集的数据上应用ML模型，以此来识别学生中是否存在诵读困难。研究数据显示，ML模型在区分意大利、西班牙及其组合群体中的诵读困难学生方面分别达到了87.5%、66.6%和75.0%的准确率。该研究通过VR和ML技术的应用，提供了一种有效评估诵读困难的方法，并且强调语言因素可能影响分类准确性。", "conclusion": "研究表明，VR和ML可以有效作为评估诵读困难的支持工具，特别是在捕捉任务完成速度差异方面表现出色。但语言因素可能会影响分类的准确性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04519", "html_url": "https://arxiv.org/abs/2509.04519", "title": "针对克罗恩病的希伯来自由文本放射报告中细粒度结构化数据提取的层级部分匹配预测（HSMP）BERT", "title_en": "Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease", "authors": "Zvi Badash,Hadas Ben-Atya,Naama Gavrielov,Liam Hazan,Gili Focht,Ruth Cytter-Kuint,Talar Hagopian,Dan Turner,Moti Freiman", "background": "从放射学报告中提取结构化临床信息具有挑战性，特别是在资源有限的语言中更为显著。这对克罗恩病尤为明显，因为其多器官发现内容稀疏。本文探讨了一种针对希伯来语放射学文本信息抽取的模型——层级结构匹配预测BERT（HSMP-BERT）。", "innovation": "HSMP-BERT是一种基于提示的模型，用于从希伯来放射学文本中提取信息。该模型在一系列评估指标上表现优异，特别是在处理24种器官发现组合时，显示出比之前的基线模型和标准微调方法更好的性能。此外，层级推理降低了5.1倍的运行时间。", "conclusion": "HSMP-BERT为放射学中的结构化提取提供了可扩展的解决方案，能够支持克罗恩病患者的群体水平分析，并展示了AI在资源有限环境中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04650", "html_url": "https://arxiv.org/abs/2509.04650", "title": "在灾害推文分类的公共安全应用中比较变换器模型", "title_en": "Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety", "authors": "Sharif Noor Zisad,Ragib Hasan", "background": "在灾害和公共安全紧急事件中，推特和其他社交媒体平台已成为获取实时信息的重要来源。自动分类与灾害相关的推文能够帮助应急服务机构更快更有效地响应。传统机器学习模型如逻辑回归、朴素贝叶斯和支持向量机，通常未能理解单词的上下文或深层次含义，尤其是在语言非正式、比喻或模糊的情况下。", "innovation": "我们提出，变换器模型在这种情况下可以比传统机器学习模型表现得更好。这个研究评估了包括BERT、DistilBERT、RoBERTa和DeBERTa在内的变换器模型在灾害相关推文分类中的有效性，这些模型与传统机器学习方法进行了比较，以突出性能差距。实验结果显示，BERT在准确率方面达到了91%，显著优于逻辑回归和朴素贝叶斯等传统模型（两者均为82%）。变换器模型利用上下文嵌入和注意力机制更好地理解推文中微妙的语言，而传统机器学习模型在这方面表现较差。", "conclusion": "这项研究证明了变换器架构在公共安全应用中更为适合，提供了更高的准确性、更深的语言理解和更好的在实际社交媒体文本上的泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04615", "html_url": "https://arxiv.org/abs/2509.04615", "title": "打破以构建：安全保护LLMs的基于提示的攻击威胁模型", "title_en": "Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs", "authors": "Brennen Hill,Surendra Parla,Venkata Abhijeeth Balabhadruni,Atharv Prajod Padmalayam,Sujay Chandra Shekara Sharma", "background": "大型语言模型（LLMs）的大量涌现 introduces 重要的安全挑战，adversarial actors 通过操纵输入提示来造成重大伤害并规避安全对齐。这些基于提示的攻击利用了模型设计、训练和上下文理解中的漏洞，导致知识产权盗窃，错误信息生成，以及用户信任的恶化。因此，对这些攻击向量进行系统性理解是开发强大抗御措施的基础步骤。", "innovation": "这篇论文通过全面的文献综述，对基于提示的攻击方法进行了分类，提供了清晰的威胁模型。通过对这些攻击机制和影响的详细阐述，旨在为在构建下一代具有先天抵御未授权浓缩、微调和编辑的LLMs的社区研究提供指导。", "conclusion": "研究综述目标是分析现有攻击向量，为开发更安全、更抗攻击性的LLMs提供基础和指导。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04518", "html_url": "https://arxiv.org/abs/2509.04518", "title": "使用强化学习提升SLM工具使用能力", "title_en": "Advancing SLM Tool-Use Capability using Reinforcement Learning", "authors": "Dhruvi Paprunia,Vansh Kharidia,Pankti Doshi", "background": "大型语言模型（LLMs）的功能已经超越了简单的文本生成，增加了对外部资源如API、数据库或软件功能的使用能力，从而能够执行诸如实时数据获取、命令执行或需要动态交互的问题解决等任务。尽管LLMs在外包使用方面通常非常熟练，但由于其对资源的需求大和计算复杂度高，使得它们不适合在所有场合使用。相比之下，小型语言模型（SLMs）在工具使用方面相对较弱。SLMs通常在较小、更具体的数据集上进行训练，导致知识面狭窄和上下文理解能力有限。因此，需要一种更高效、有效的解决方案来提升SLMs的工具使用能力，使其更具实用性。", "innovation": "本研究通过使用强化学习（RL），特别是Group Relative Policy Optimization（GRPO）方法，来提升小型语言模型（SLMs）在工具使用的专业技能。与传统的需要大量计算资源且缺乏灵活性的微调方法不同，本方法提供了一种更高效的解决方案，能够显著提高SLMs在工具使用方面的准确性，从而提升其实际应用价值。", "conclusion": "研究通过引入强化学习中的GRPO方法，成功地提升了小型语言模型的工具使用能力，显著提高了该类模型的实用性，解决了SLMs在外包使用方面的不足，为未来的应用提供了更高效、更实用的方案。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04516", "html_url": "https://arxiv.org/abs/2509.04516", "title": "人工流利：英语训练集与本民族训练集之间桑海语AI性能基准", "title_en": "Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets", "authors": "Sophie Jaffer,Simeon Sayer", "background": "大语言模型（LLMs）正在扩展多语言能力，但存在其性能在不同语言之间是否公正的问题。尽管许多社区可以从AI系统中受益，但训练数据中英语的主导地位可能会损害非英语使用者的利益。因此，本研究通过比较两种仅用单一语言训练的BERT模型——一种完全使用桑海语数据训练和测试，另一种则使用类似量级的英语新闻数据训练，来测试数据差异是否会影响模型性能的假设。通过将桑海语新闻数据翻译成英语，并使用英语训练的模型进行评估，来模拟多语言LLMs处理非英语查询时的内部翻译和抽象过程。研究发现尽管质量上等同的翻译，完全用桑海语训练的模型表现优于翻译后的模型，错误次数减少了近四倍，指出翻译本身并不能解决语言之间的代表性差异，模型在原语言训练更有可能准确地理解输入。", "innovation": "本研究创新之处在于使用了完全用单一语言（桑海语）训练和测试的模型，并通过将数据翻译成另一种语言（英语）来进行对比，以此来单独测试语言一致性和跨语言抽象的效果。通过实验证明翻译不能完全弥补语言之间在表示上的差异，并指出原语言训练对于可靠结果仍然十分重要，建议未来研究应更加关注下未充分代表的语言的数据集发展和多语言模型评估，防止全球AI部署进一步加剧数字鸿沟.", "conclusion": "本研究结果表明，即使高质量的翻译，原语言训练的模型在性能上仍然优于经过翻译的模型，表明翻译不能弥补语言间的代表性差异，模型在原语言训练更能准确理解输入。因此，在教育和信息上下文中，即使是微小的性能差距也可能累积不公正，未来的研究应更加重视促进未充分代表语言的更多数据集开发，并重新关注多语言模型评估，以尽可能减少全球AI部署对现有数字鸿沟的强化效果。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04534", "html_url": "https://arxiv.org/abs/2509.04534", "title": "医学自然语言处理中量化大语言模型的评估与推荐", "title_en": "Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation", "authors": "Zaifu Zhan,Shuang Zhou,Min Zeng,Kai Yu,Meijia Song,Xiaoyi Chen,Jun Wang,Yu Hou,Rui Zhang", "background": "大语言模型在生物医学自然语言处理方面展现出了非凡的能力，但其快速增长的规模和计算需求成为健康医疗环境中部署的主要障碍，因为该环境中的数据隐私限制了云部署，并限制了可用资源。本文系统评估了12个最新的大规模语言模型在八个基准数据集上的影响，涵盖了四个关键任务：命名实体识别、关系抽取、多标签分类和问答，这些数据集来自不同领域。这些模型包括通用型和针对生物医学的特定模型，用于比较研究。在此背景下，探讨了如何在保证模型性能的同时降低计算资源需求，以便在资源有限和数据隐私要求高的场景中部署大规模语言模型，推动人工智能技术在临床中的应用与转化。", "innovation": "本文的研究创新之处在于，系统地评估了量化技术对多个先进的大语言模型的影响。通过验证量化技术能够在减少GPU内存需求（最多可减少75%）的同时，保持模型在多种任务中的性能，使得700亿参数规模的模型可以部署在40GB内存级别的消费级GPU上，这对于资源有限的环境来说尤为重要。此外，本文还验证了量化技术对专业知识领域和高级提示方法响应的说法可以保持不变。", "conclusion": "研究结果表明，量化是一种实用且有效的策略，可以确保在遵守数据隐私的前提下，在生物医学背景下安全而本地部署大规模语言模型。这不仅促进了技术在医学中的应用，还缩小了人工智能技术进步与临床实际转化之间的差距。研究成果为实际部署提供了重要的实用价值和指导意义，尤其是在需要高性能计算资源但受限于隐私保护要求的医疗健康场景中。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04655", "html_url": "https://arxiv.org/abs/2509.04655", "title": "多义性 dropout：专有大型语言模型的同态 OOD 检测", "title_en": "Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs", "authors": "Ayush Gupta,Ramneet Kaur,Anirban Roy,Adam D. Cobb,Rama Chellappa,Susmit Jha", "background": "尽管通过微调可以实现前沿任务中的顶尖性能，专门化的大型语言模型（LLMs）在面对领域外（OOD）输入时仍然容易产生不正确的或不可靠的输出。这种脆弱性会在关键应用场景中带来风险。本文研究了通过一种新颖的推理时领域外检测算法来增强专门化LLMs的鲁棒性。", "innovation": "本文提出了一种基于同态异常检测（ICAD）框架的新颖领域外检测方法，该方法利用了一个新的基于模型dropout容限的新非一致性度量。通过在多个层中整合dropout容限并采用有效的集成方法，该方法提高了检测性能，同时保持了ICAD的理论误报上限。这种方法的创新之处在于它利用了LLMs中多义性和冗余性特征，通过检测dropout容限来区分领域内和领域外输入。", "conclusion": "实验结果显示，与基线方法相比，该方法能够更有效地检测领域外输入，当将领域外数据点视为阳性和领域内测试数据点视为阴性时，AUROC提高了2%到37%。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04664", "html_url": "https://arxiv.org/abs/2509.04664", "title": "语言模型为什么会产生幻觉", "title_en": "Why Language Models Hallucinate", "authors": "Adam Tauman Kalai,Ofir Nachum,Santosh S. Vempala,Edwin Zhang", "background": "大型语言模型在不确定时有时会猜测而不是承认不确定性，这可能导致错误但看似合理的陈述，削弱了用户的信任。这种名为‘幻觉’的现象在最先进系统中仍然存在。", "innovation": "作者分析了现代训练流程中幻觉产生的统计原因，并提出了由于现有评估方式奖励猜测而非承认不确定性的观点。他们提出应对幻觉的‘社会技术解决方法’，即调整现有评估标准的评分，而不是引入额外的幻觉评估。", "conclusion": "将这一改变可能引导AI系统向更具可信赖性转变，并指出幻觉的根本原因是二元分类中的错误，而非神秘的机制。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04512", "html_url": "https://arxiv.org/abs/2509.04512", "title": "不同规模和任务下大规模语言模型在情感安全性分类中的扩展行为", "title_en": "Scaling behavior of large language models in emotional safety classification across sizes and tasks", "authors": "Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro", "background": "理解大型语言模型（LLMs）如何处理情感敏感内容对于构建安全可靠系统至关重要，尤其是在心理健康领域。本文探讨了LLMs在两个关键任务上的扩展行为：三类情感安全性分类（安全 vs 不安全 vs 边缘）和六类安全风险分类的多标签分类。为此，作者构建了一个新的数据集，通过将多个由人类撰写的心理健康数据集合并，并通过ChatGPT生成情感重新解释提示来增强数据集。研究涵盖了四种LLaMA模型（1B，3B，8B，70B），在零样本、少量样本和微调设置下进行评估。研究结果表明，更大的LLM在细腻的多标签分类和零样本设置中表现更佳。然而，轻量级的微调可以让1B模型在高数据类别中达到与更大模型和BERT相当的表现，并且只需要<2GB的GPU显存。这些发现表明，较小的设备模型可以作为敏感应用的可行且隐私保护的选择，提供理解和维护对话边界的能力。这项工作强调了治疗性LLM应用的关键影响及其在安全关键系统中的可扩展对齐", "innovation": "研究通过构建新的数据集并对不同规模的LLaMA模型进行评估，揭示了大规模语言模型在情感安全性分类上的扩展行为。特别地，研究发现 lightweight微调技术使得小型模型在某些情况下达到了与大型模型相当的表现，同时降低了对计算资源的需求。这项工作首次全面考察了不同规模的LLM在情感安全分类任务上的表现，并提出了在小型模型上实现情感理解的可能性。", "conclusion": "更大的LLM在情感安全分类，尤其是多标签分类和零样本设置上表现出色。轻量级的微调让小型模型得到了显著提升，在某些任务上达到了与大型模型相当的表现，同时只需要较少的计算资源。这些发现表明，小型设备模型可以作为敏感应用的可行选择，提供理解和维护对话边界的能力。这项工作强调了在治疗性LLM应用中考虑隐私和计算效率的重要性，并为安全关键系统的可扩展对齐提供了新的视角。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04657", "html_url": "https://arxiv.org/abs/2509.04657", "title": "通过SQL2NL评估NL2SQL", "title_en": "Evaluating NL2SQL via SQL2NL", "authors": "Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth", "background": "在自然语言到结构化查询语言（NL2SQL）模型的理解能力评估中，具备在语言变异存在的情况下稳健性评估是关键。然而，现有的基准测试很少系统或可控地解决这一因素。现有的基准测试主要关注其他因素，如语义等。本文提出了一种新颖的模式对齐的改写框架，利用SQL到自然语言（SQL2NL）的方法，自动生成与原始模式和意图对齐且语义等价但词形多样的查询。这种方法使得能够单独地系统性地评估NL2SQL模型在讲解多样性上的稳健性。", "innovation": "提出了一种利用SQL到自然语言改写的方法生成语义等价但词形多样的查询，从而独立地系统性地评估NL2SQL在语言变化上的稳健性，并揭示了现有最先进的模型相比标准基准测试更脆弱。通过具体实例分析不同模型在重新表述后的Spider查询上的执行准确率下降情况表明，小型模型更为受到影响。同时，研究还发现模型的稳健性下降与查询复杂度、数据集和领域有很大关联。这表明需要一种明确衡量语言通用性的评估框架以确保在实际应用中的可靠性能。", "conclusion": "研究表明现有最先进的NL2SQL模型在语言多样化场景下的表现比标准基准测试中显得更加脆弱，显示了在复杂查询、不同数据集和领域下，分析模型的稳健性降级的变化。强调需要改进评估框架，以确保在实际应用中的可靠性能，并具体指出不同模型在不同因素影响下的表现差异。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04770", "html_url": "https://arxiv.org/abs/2509.04770", "title": "基于MQUAKE框架的LLM多跳推理优化研究", "title_en": "Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework", "authors": "Zucheng Liang,Wenxin Wei,Kaijie Zhang,Hongyi Chen", "background": "大规模语言模型（LLMs）准确回答复杂问题始终是一个重要的挑战。为解决这一问题，本文提出了基于MQUAKE框架的多跳问题分解方法。通过系统地将LLAMA3模型针对知识图谱进行多跳问题分解，研究了其对模型理解和推理准确性的影响。", "innovation": "研究提出了一种利用LLAMA3模型进行多跳问题分解的方法，并将其应用于MQUAKE-T数据集的不同形式，通过实验验证了这种方法在未经训练和经过LoRA方法 fine-tuning 后的有效性，特别是在未经 fine-tuning 的情况下，多跳推理方法显著优于直接回答复杂问题的方法。", "conclusion": "本文的研究结果表明，多跳分解方法在未经 fine-tuning 和经过 fine-tuning 的情况下均能显著提高模型回答复杂问题的性能，证明了该方法的有效性和提升模型对复杂问题处理能力的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04656", "html_url": "https://arxiv.org/abs/2509.04656", "title": "AraHalluEval：阿拉伯语大语言模型细致幻觉评估框架", "title_en": "AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs", "authors": "Aisha Alansari,Hamzah Luqman", "background": "当前关于大语言模型（LLMs）幻觉的研究主要集中在英语上，尽管已经有一系列多语言和阿拉伯语专门的LLMs出现，但评估这些模型在阿拉伯语环境下的幻觉表现仍然相对较少。鉴于阿拉伯语在很多地区的广泛应用及其在全球通信和媒体中的重要性，造成了一定的知识空白。本文通过全面评估12个LLMs（包括4个阿拉伯语预训练模型、4个多语言模型和4个基于推理的模型）在阿拉伯自然语言生成任务上的幻觉表现，填补了这一领域的空白。具体任务包括生成式问答（GQA）和总结。", "innovation": "本文构建了首个针对阿拉伯语及多语言LLMs的细化幻觉评估框架，涵盖了12个细化的幻觉指标，能够衡量每种任务的不同特征。该框架显示出，尽管所有模型的现实性幻觉普遍存在，但阿拉伯语预训练模型Allam的表现依然更佳，幻觉率低于多语言模型，并与基于推理的模型具有可比性。此外，该研究还强调了阿拉伯语在评估LLMs幻觉方面的重要性，以及阿拉伯语领域研究的紧迫性。代码已发布在GitHub上，可提高研究透明度和可重复性。", "conclusion": "本文展示了阿拉伯语和多语言LLMs在关键阿拉伯自然语言生成任务上的初次全面幻觉评估。结果显示，所有模型中现实性幻觉更为常见，但阿拉伯语预训练模型Allam在这方面的表现优于多语言模型，并且与基于推理的模型具有可比性。未来研究应进一步探讨阿拉伯语特定context下的LLMs幻觉现象，为提升模型生成的准确性和可信度提供参考。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04605", "html_url": "https://arxiv.org/abs/2509.04605", "title": "诚言实录：语用讽刺识别——多模态融合、挑战与未来前景", "title_en": "Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects", "authors": "Xiyuan Gao,Shekhar Nayak,Matt Coler", "background": "讽刺是人类交流的常见特征，但在人际互动和人机互动中造成挑战。语言学研究指出，诸如音高变化、语速和语调等语调提示在传达讽刺意图方面的重要性。尽管早期的研究主要集中在文本讽刺检测上，但在识别讽刺方面的语音数据作用尚未得到充分探索。近期声学技术的进步强调了利用语音数据实现自动讽刺识别的重要性，这有利于神经退行性疾病患者的社交互动提升，并增强机器对复杂人类语言的了解，从而实现更细腻的互动。本文是对利用语音数据识别讽刺的研究首次进行系统性回顾，展示了从单模态到多模态方法的演变过程，涵盖了数据集、特征提取和分类方法等内容，旨在跨越不同研究领域填补空白。", "innovation": "该研究首次系统性回顾了以语音数据为基础的讽刺识别。它涵盖了数据集、特征提取和分类方法的内容，从传统声学特征到深度学习表示的特征提取技术演进。研究还发现讽刺识别中数据集的局限性和从单模态到多模态融合技术的分类方法进展，指出需要更加强调跨文化和多语种讽刺识别的重要性，以及将讽刺视为多模态现象，而不仅仅是文本挑战的需求。", "conclusion": "研究强调了在讽刺识别中利用多模态方法、跨文化和多语种视角的重要性，提出了未来研究的方向，致力于推动相关领域的发展。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04696", "html_url": "https://arxiv.org/abs/2509.04696", "title": "ODKE+: 基于本体引导的开放式领域知识提取与LLMs", "title_en": "ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs", "authors": "Samira Khorshidi,Azadeh Nikfarjam,Suprita Shankar,Yisi Sang,Yash Govind,Hyun Jang,Ali Kasgari,Alexis McClimans,Mohamed Soliman,Vishnu Konda,Ahmed Fakhry,Xiaoguang Qi", "background": "知识图谱(KGs)在许多AI应用中起到基础作用，但保持它们的时效性和完整性仍然耗资巨大。目前的方法难以大规模地自动从网页中提取和整合大数据量的开放域事实。", "innovation": "ODKE+提供了一个生产级别的系统，能自动地从网络中以高精度提取和整合数百万个开放域事实。它通过使用模块化的组件形成一个可扩展的管道，其中包含了事实的检测、支持文档的收集、融合了基于模式规则和本体引导的提示的知识提取器、采用轻量级 grounders 验证抽取的事实以及对候选事实进行排名和规一化的 corroborator。ODKE+能够动态生成针对每个实体类型的本体片段，使提取能与模式约束保持对齐，从而实现195个谓词的类型一致性提取，并支持批量和流式处理模式，大大提高了知识提取的覆盖率和可靠度。", "conclusion": "ODKE+显著提高了知识图谱的覆盖率，与第三方知识图谱相比重叠率高达48%，平均更新滞后时间减少了50天。我们的部署展示了基于本体结构和验证工作流的LLM提取方法，可以实现大规模生产级知识提取的可信应用，在实际场景中有广泛的应用潜力。系统演示的录像与提交一起包含，并可以通过这个链接观看：this https URL"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04716", "html_url": "https://arxiv.org/abs/2509.04716", "title": "KERAG: 知识增强型检索增强生成以实现高级问答", "title_en": "KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering", "authors": "Yushi Sun,Kai Sun,Yifan Ethan Xu,Xiao Yang,Xin Luna Dong,Nan Tang,Lei Chen", "background": "传统知识图谱问答（KGQA）方法依赖于语义解析，通常只能检索生成答案所需的严格相关知识，这使得它们在处理具有语义模糊性和严格模式要求的问题时往往覆盖率较低。通过引入检索增强生成（RAG），该论文提出了一种新的基于知识图谱的RAG框架（KERAG），该框架通过检索可能包含相关信息的更大子图来提高问答覆盖率。", "innovation": "论文提出了一种创新的检索-过滤-总结方法，与微调后的链式推理（Chain-of-Thought）语言模型结合使用，能够减少噪音并提高对于简单和复杂问题的问答质量。实验结果表明，KERAG比最先进的解决方案在质量上提升了约7%，并且超越GPT-4o（Tool）10-21%。", "conclusion": "通过引入基于知识图谱的检索增强机制，KERAG能够有效提升问答系统的覆盖率和准确性，特别是在处理复杂问题时具有明显优势。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04702", "html_url": "https://arxiv.org/abs/2509.04702", "title": "OleSpeech-IV：一个具有多样化主题的大规模多说话者多语言对话语音数据集", "title_en": "OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational Speech Dataset with Diverse Topics", "authors": "Wei Chu,Yuanzhe Dong,Ke Tan,Dong Han,Xavier Menendez-Pidal,Ruchao Fan,Chenfeng Miao,Chanwoo Kim,Bhiksha Raj,Rita Singh", "background": "该论文介绍了一个名为OleSpeech-IV的大规模多说话者和多语言对话语音数据集，数据涵盖了广泛的话题。这些音频内容来自于公开可用的英语播客、谈话节目、电话会议和其他对话，包括来自不同说话者的话语记录、轮次和转录文本。", "innovation": "该数据集的独特之处在于其涵盖了多说话者和多语言的特点，并且使用了一个专用流水线来获取转录文本、时间戳和置信分数等信息。此外，还提供了一个名为OleSpeech-IV-2025-EN-AR-100的子集用于非商业研究。", "conclusion": "OleSpeech-IV数据集为研究提供了丰富的多样化内容和数据支持，对于开发和评估对话处理和多语言系统具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04796", "html_url": "https://arxiv.org/abs/2509.04796", "title": "LLMs中知识崩溃：递归合成训练中的流畅性胜过事实", "title_en": "Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training", "authors": "Figarri Keisha,Zekun Wu,Ze Wang,Adriano Koshiyama,Philip Treleaven", "background": "大型语言模型由于人类编写内容的稀缺性越来越多地依赖合成数据，但通过递归训练模型生成的内容可能导致模型崩溃，这是一种导致事实准确性下降而表层流畅性保持不变的过程，从而产生“自信错误”的输出，这对依赖准确性的领域构成严重风险。", "innovation": "研究提出了一种针对知识崩溃的领域特异性合成训练策略，该策略在保持计算效率的同时实现了显著的抗崩溃改进。研究还构建了结合模型中心指标和任务中心度量的评估框架，以检测不同的退化阶段，从而在不同语言模型中进行可重复的判断知识衰退的评估。", "conclusion": "研究提供了关于崩溃动态的理论见解，并为知识密集型应用中准确性攸关的可持续AI训练提供了实践指导。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04794", "html_url": "https://arxiv.org/abs/2509.04794", "title": "将性格作为LLM评估探针：方法权衡与下游影响", "title_en": "Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects", "authors": "Gunmay Handa,Zekun Wu,Adriano Koshiyama,Philip Treleaven", "background": "在大语言模型（LLMs）中应用性格操纵（如客户服务和代理场景）越来越普遍，但其机制及其权衡尚未清晰明了。", "innovation": "本文提出了系统性研究使用大五人格特质性格控制的方法，包括：构建对比数据集以实现有效的导向向量计算和公平的跨方法评估；引入统一的评估框架，基于运行内Δ分析，分离出推理能力、代理性能和人口统计偏差；开发特质纯化技术以区分开放性和责任心，解决特质编码中的表示重叠；提出三个级别的稳定框架来量化方法、特质和组合级别的鲁棒性。", "conclusion": "实验表明，ICL在最小能力损失的情况下实现了强大的一致性，PEFT实现了最高的一致性但任务性能下降，MS提供了轻量级的运行时控制并具有竞争力的效果。特质层面的分析显示开放性最具挑战性，宜人性对ICL最不敏感，性格编码集中于中间层。这些结果为性格操纵提供了多级探针，连接表面条件、参数编码和激活级舵，定位机制舵作为轻量级替代微调的方法，适用于部署和可解释性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04821", "html_url": "https://arxiv.org/abs/2509.04821", "title": "AFD-SLU: 自适应特征蒸馏在口语理解中的应用", "title_en": "AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding", "authors": "Yan Xie,Yibo Cui,Liang Xie,Erwei Yin", "background": "口语理解（SLU）是对话系统的核心组件，使机器能够解释用户的语音输入。尽管其重要性，由于标注训练数据稀缺以及在实际应用中部署大型语言模型（LLMs）的计算负担，开发有效的SLU系统仍然具有挑战性。为此，本文通过对预训练的通用文本嵌入（GTE）教师模型中的丰富语义表示进行蒸馏，并将其传递给轻量级学生模型来缓解这些难题。", "innovation": "本文提出了一种自适应特征蒸馏（AFD-SLU）框架，该框架包含一个动态适配器，配备有残差投影神经网络（RPNN）以对齐异构特征空间，以及一个动态蒸馏系数（DDC），可以基于意图和槽位预测表现的实时反馈来动态调整蒸馏强度。与基准模型相比，AFD-SLU在Chinese ProSLU基准测试上取得了最先进的结果，实现了95.67%的意图准确率、92.02%的槽位F1分数以及85.50%的整体准确率。", "conclusion": "实验证明，AFD-SLU在口语理解任务上取得了优异的性能，相较于现有模型有显著提升，展示了该方法的有效性和实用性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04866", "html_url": "https://arxiv.org/abs/2509.04866", "title": "记忆 ≠ 理解：大型语言模型是否具备情景认知能力？", "title_en": "Memorization $\\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?", "authors": "Boxiang Ma,Ru Li,Yuanlong Wang,Hongye Tan,Xiaoli Li", "background": "大型语言模型（LLMs）通过处理大量的文本数据，在各种自然语言处理（NLP）任务中取得了显著的性能，但其通用性究竟是来源于对训练数据的简单记忆，还是深度语义理解，仍然存在争议。文章通过提出一种双视角评估框架来探究大型语言模型的情景认知能力，即连接语境中语义情景元素与其论据的能力。该评估框架包括对模型输出和其内部编码的场景元素-论据关联进行探查，通过分析如何回答基于场景的问题来评估模型的情景认知能力。", "innovation": "文章提出了一个双视角的评估框架，用于评估大型语言模型的情景认知能力。通过引入一个包含多种虚构事件描述的数据集，并对模型的输出和其内部编码的关联进行评估，以揭示当前大型语言模型主要依赖于表面的记忆而不是深入的理解，并在简单情况下也难以实现稳定的语义情景认知。这些发现揭示了大型语言模型在语义理解方面的关键局限，并提供了改进其能力的认知洞察力。", "conclusion": "当前大型语言模型主要依赖于简单地记忆训练数据，缺乏稳定的语义情景认知能力，即使在简单的情况下也是如此。这些发现指出了大型语言模型语义理解的关键局限性，并为提升其能力提供了认知上的见解。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04802", "html_url": "https://arxiv.org/abs/2509.04802", "title": "注意差异：通过动作图评估大语言模型的模型级和应对级漏洞", "title_en": "Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs", "authors": "Ilham Wicaksono,Zekun Wu,Theo King,Adriano Koshiyama,Philip Treleaven", "background": "随着大型语言模型转变为代理系统，当前的安全评估框架在评估部署特定风险时面临重要缺口。这项研究提出了AgentSeer，一个基于可观测性的评估框架，能够将代理执行分解为细粒度的动作图和组件图，从而支持系统性的应对情景评估。通过在GPT-OSS-20B和Gemini-2.0-flash上进行模型间验证，研究者展示了模型级与应对级漏洞配置文件之间的根本差异。模型级评估揭示了基础差异，而应对级评估则揭示了隐藏在传统评估中的代理特定风险。", "innovation": "AgentSeer提供了一种新的评估框架，用于系统地评估部署特定风险。它通过将代理执行分解为动作和组件图，使研究人员能够识别出在应对级下独有的脆弱性。该研究使用HarmBench的单步和迭代细化攻击方法，证明了代理执行中新的攻击面，特别是在工具调用方面的高成功率。此外，研究还揭示了与模型级评估相比，应对级评估的高风险操作、语义而非语法的脆弱机制以及上下文依赖的攻击有效性。", "conclusion": "研究结果强调了建立应对情景评估范式的紧迫性。AgentSeer不仅提供了一个标准化的评估方法，还通过实证验证证明了传统评估的局限性。直接从模型级到应对级的攻击转移性能下降，而上下文感知的迭代攻击在应对级成功实现了目标，这进一步证实了现有评估框架的系统性缺口。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04745", "html_url": "https://arxiv.org/abs/2509.04745", "title": "语音特征学习改善孤立手语的一致性泛化", "title_en": "Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization", "authors": "Lee Kezar,Zed Sehyr,Jesse Thomason", "background": "手语数据集在词汇覆盖方面往往不具有代表性，强调了能够适应未见过的手势的模型的需求。向量化量化是一种有前途的方法，用于学习离散、令牌样的表示，但它尚未被评估是否能够捕捉到影响未见过词汇性能的虚假关联。本文研究了两种语音诱导偏置：参数解耦，一种架构偏置，以及语音学半监督，一种正则化技术，以提高对已知手势的孤立识别能力和对未见过手势的重建质量，使用矢量化自编码器。背景表明，目前的模型和方法在处理未见过的手势时可能存在局限性，需要引入特定的方法来改善模型的一致性泛化能力。", "innovation": "研究了两种语音学诱导偏置：参数解耦和语音学半监督，以改善已知手势的孤立识别能力和对未见过手势的重建质量。通过引入这两种偏置，旨在提升模型对未见过词汇的泛化能力，这种改进对于手语识别具有重要意义。这是首次在手语中应用这些特定的偏置方法来评估其在实际场景中的有效性。", "conclusion": "本研究发现，所提出模型的学到的表示对于未见过手势的一次性重建效果更佳，并且对手势识别更具区分性，相比于对照基准模型，在提高学习表示的一致性泛化能力方面取得了显著进展。此外，通过量化分析表明，明确地采用与语言相关动机的偏置能够显著改善学习表示的手语的一致性泛化。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04813", "html_url": "https://arxiv.org/abs/2509.04813", "title": "通过判别词典和深度学习模型分析芬兰语屈折词类", "title_en": "Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models", "authors": "Alexandre Nikolaev,Yu-Ying Chuang,R. Harald Baayen", "background": "研究背景涉及复杂的名词或动词系统，使用屈折词类将具有相似词根变化和相似变位标志的名词聚集在一起。尽管屈折词类可能对语言教学和构建有限状态形音系统非常有用，但不清楚这些词类在认知上是否真实存在，即母语使用者是否需要发现这些词类来正确变位他们的语言中的名词。这篇研究旨在考察判别词典模型（DLM）是否可以在不设置屈折词类的情况下理解并生成芬兰语变位名词。", "innovation": "本研究的创新之处在于使用判别词典模型（DLM）和深度学习方法来分析和生成芬兰语的屈折词类。研究不仅对丰富的屈折名词（来自49个屈折词类的2000个高频芬兰名词）进行了处理，还探讨了两种不同的学习模式：一种不考虑使用频率，在无限曝光情况下探讨习得性，另一种基于使用视角，考虑了标记频率。研究发现，模型在训练数据上的准确率都非常高，但在保留测试数据上有所下降但仍然可以接受。模型的性能变化与屈折词类的类型数量、单词频率和独词相关。", "conclusion": "研究结论表明，判别词典模型能够在某种程度上理解和生成芬兰语变位名词，尤其是在丰富的屈折词类中表现更好。然而，模型在不常用和低产词类中表现较差。对于基于使用的生成模型，使用频率是影响模型性能的主要因素，而与生产性度量的相关性不明显。需要进一步研究来探索如何改进模型以提高其在各种屈折词类中的表现。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04884", "html_url": "https://arxiv.org/abs/2509.04884", "title": "L1RA: LoRA 精调中的动态秩分配", "title_en": "L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning", "authors": "Raul Singh,Nicolo Brunello,Vincenzo Scotti,Mark James Carman", "background": "大型语言模型（LLMs）在解决复杂任务方面的能力使其成为基于AI的应用开发的关键，但这些模型在下游任务上的微调所需的高计算需求在资源受限的情况下构成了重大挑战。因此，研究者提出了一种名为L1RA的新技术，旨在在使用低秩适配器进行微调时动态分配秩，以优化资源利用。", "innovation": "L1RA利用L1正则化进行剪枝并重新分配冗余秩，以优化资源利用。在一系列实验中，L1RA显示出与其它LoRA变体（包括原版方法）相比，保持甚至降低了计算开销，同时实现相同或更好的性能。研究还揭示了需要最多适应的模型组件：前馈层和注意力输出投影。", "conclusion": "L1RA不仅提高了LLM微调的效率，还提供了有关模型细化和定制的关键诊断信息。因此，L1RA为在计算资源受限的情境下提高LLM性能和解释性提供了有前景的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04868", "html_url": "https://arxiv.org/abs/2509.04868", "title": "使用大语言模型进行多语言临床实体链接至ICD-10", "title_en": "Using LLMs for Multilingual Clinical Entity Linking to ICD-10", "authors": "Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva", "background": "临床实体链接是提取临床文本中结构化信息的关键部分，涉及将医学本体或分类中的代码分配给文本中的短语。国际疾病分类-第10次修订版（ICD-10）是一个用于统计和保险目的的国际疾病分类标准。自动为出院总结中的术语分配正确的ICD-10代码可以简化医疗专业人员的工作，并确保医院的一致编码。", "innovation": "论文提出了一种使用大语言模型（LLMs）将临床术语链接到ICD-10代码的方法，适用于不同语言。该方法包括一个多阶段管道，利用临床字典匹配文本中明确的术语，然后使用GPT-4.1进行上下文学习以预测字典中未匹配的术语的ICD-10代码。", "conclusion": "系统在不同基准数据集上的结果显示出有希望的预测ICD-10代码表现：西班牙语为类别0.89 F1，子类别为0.78 F1（CodiEsp），希腊语为0.85 F1（ElCardioCC）。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04969", "html_url": "https://arxiv.org/abs/2509.04969", "title": "使用NLP对医院急诊数据中的运动损伤进行分类", "title_en": "Classification of kinetic-related injury in hospital triage data using NLP", "authors": "Midhun Shyam,Jim Basilakis,Kieran Luken,Steven Thomas,John Crozier,Paul M. Middleton,X. Rosalind Wang", "background": "急诊笔记包含了大量有助于医护人员和研究人员理解急诊患者流行病学和时间依赖性伤情或疾病的详细信息。然而，使用现代自然语言处理和机器学习技术分析急诊数据存在一些挑战，包括数据包含高度敏感信息，受隐私法规保护；大多数医院和医疗机构缺乏可以使用的大规模语言模型；以及需要专家手工标记数据集以识别有效记录。", "innovation": "本文提出了一种使用大规模语言模型（LLM）进行三检数据分类的管道，该管道利用有限的计算资源。具体来说，该方法首先在GPU上使用一个2000个样本的开源数据集进行预训练模型的微调，随后在CPU上使用特定医院的1000个样本进一步微调模型。通过精心整理数据集并利用现有模型和开源数据，该方法成功地在有限的计算资源下对三检数据进行了分类。", "conclusion": "通过该管道方法，基于有限的计算资源成功地分类了急诊数据。这种方法展示了即使在计算资源有限的情况下，也能成功利用预训练的大型语言模型和现有数据集进行任务需求的特定数据集的分类。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05006", "html_url": "https://arxiv.org/abs/2509.05006", "title": "大型语言模型需要意图吗？关于服务助理响应生成策略的重新审视", "title_en": "Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant", "authors": "Inbal Bolshinsky,Shani Kupiec,Almog Sasson,Yehudit Aperstein,Alexander Apartsin", "background": "在对话式AI时代，生成准确且上下文相关的服务响应仍然是一项关键挑战。存在一个核心问题：明确的意图识别是否是生成高质量服务响应的必要条件，还是说模型可以直接绕过这一步骤并直接生成有效的回复？", "innovation": "本文通过对比研究，利用两个可用的服务交互数据集，分别测试了几种最先进的语言模型，包括微调后的T5变体，在这两种模式下的表现：意图优先的响应生成和直接响应生成。评价指标包括语言质量和任务成功率，揭示了明确的意图建模的必要性和冗余性。研究结果挑战了对话式AI管道中的传统假设，为设计更高效和有效的响应生成系统提供了行动指南。", "conclusion": "我们的发现挑战了对话式AI管道中的传统假设，为设计更高效和有效的响应生成系统提供了行动指南。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05056", "html_url": "https://arxiv.org/abs/2509.05056", "title": "具有频率导向训练的掩码扩散语言模型", "title_en": "Masked Diffusion Language Models with Frequency-Informed Training", "authors": "Despoina Kosmopoulou,Efthymios Georgiou,Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos", "background": "本文提出了一种掩码扩散语言模型框架，旨在高效训练数据量有限的模型，参加BabyLM 2025挑战。在严格的训练数据限制下，该框架通过使用扩散训练目标对语言模型进行训练，同时采用频率导向掩码策略，优先学习罕见词汇，同时保持理论上的有效性。", "innovation": "该研究引入了多种噪声调度策略，包括双模式方法，并在NELBO目标中探索了不同的噪声加权方案。评估结果显示，该方法在BabyLM基准测试套件上的性能与混合自回归-掩码基线相当，表明基于扩散的训练方法可以为数据受限的语言学习提供一种可行的替代方案。", "conclusion": "结果显示，该方法在语言能力和类似人类的特性上的表现与混合自回归-掩码基线相当。这表明，基于扩散的训练方法可以为数据有限的语言学习提供一种有效的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04982", "html_url": "https://arxiv.org/abs/2509.04982", "title": "优化小型变压器语言模型在短文本多标签情感分析中的应用", "title_en": "Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts", "authors": "Julius Neumann,Robert Lange,Yuni Susanti,Michael Färber", "background": "短文本情感分类的数据集存在显著挑战，如类别不平衡、训练样本有限以及情感标签的主观性。短文本的限制背景进一步加剧了这些问题，导致难以解决歧义和增加数据稀疏性，从而阻碍了有效的学习过程。这些因素使情感分类更加复杂，特别是在有限上下文的短文本环境中。因此，评估小型基于Transformer的模型（如BERT和RoBERTa，参数少于10亿）在多标签情感分类中的效果，特别是在短文本背景下，具有重要意义。", "innovation": "研究通过评估三个关键因素来优化基于Transformer的模型，包括（1）领域特定的持续预训练；（2）数据增强，特别是生成数据增强，使用自动生成的例证；（3）分类头的架构变化。实验结果表明数据增强可以提高分类性能，而对扩充数据集的持续预训练可能会引入噪音而不是提高准确性。此外，对分类头的修改仅带来微小的性能提升。这些发现为资源受限环境中优化BERT模型以及在短文本数据集中的情感分类策略提供了实用指导。", "conclusion": "研究表明，数据增强能够提升分类效果，而持续的领域特定预训练在扩充数据集上可能会引入噪声而非提升准确性。对分类头的修改仅带来边际收益。这些结论为资源受限的环境下优化BERT模型提供了实用的意见，并为短文本数据集中的情感分类策略改进提供了方向。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04903", "html_url": "https://arxiv.org/abs/2509.04903", "title": "ACE-RL: 自适应约束增强奖励的长文生成强化学习", "title_en": "ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning", "authors": "Jianghao Chen,Wei Sun,Qixiang Yin,Lingxing Kong,Zhixing Tan,Jiajun Zhang", "background": "大规模语言模型（LLMs）在长文语境理解方面取得了显著进步，但在高质量长文生成方面仍面临重大挑战。现有研究主要存在两个局限性：一是过度依赖稀缺且高质量的长文响应数据进行监督微调（SFT）或强化学习（RL）中的两两偏好奖励；二是专注于粗粒度的质量优化维度，如相关性、连贯性和有用性，忽略了不同长文生成场景中的细粒度特定性。因此，本文提出了一种使用自适应约束增强奖励的长文生成强化学习（ACE-RL）框架来解决这些问题。ACE-RL首先自动将每条指令分解为一套细粒度的自适应约束标准，识别其隐藏的意图和需求。接着，设计了一个奖励机制，基于响应满足特定约束的程度量化响应质量，将主观的质量评估转化为约束验证。最后，利用强化学习引导模型提升长文生成能力。实验结果表明，ACE-RL框架在WritingBench上的表现优于现有SFT和RL基线20.70%和7.32%，而我们的顶级模型甚至比专有系统GPT-4o高出7.10%，为LLMs提供了更有效的训练范式以生成高质量内容，适用于各种长文生成场景。", "innovation": "本文提出了一种使用自适应约束增强奖励的长文生成强化学习（ACE-RL）框架，能够在保持模型不变的情况下，通过对各种约束条件进行适配，显著提高长文质量，特别是写作质量。该框架首先自动对指令进行分解，识别其隐藏的意图和需求，随后通过量化响应对约束的满足程度来奖励模型。该方法不仅克服了现有方法对高质量数据的依赖，还通过细粒度的需求捕捉优化长文生成过程中的质量标准。", "conclusion": "实验结果表明，ACE-RL在WritingBench上的表现优于现有SFT和RL基线，领先现有专有系统GPT-4o，并为LLMs提供了有效的训练范式，以生成高质量的内容，覆盖多种长文生成场景。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04779", "html_url": "https://arxiv.org/abs/2509.04779", "title": "解码器的幽默感与编码器相当", "title_en": "Decoders Laugh as Loud as Encoders", "authors": "Eli Borodach,Raj Dandekar,Rajat Dandekar,Sreedath Panat", "background": "自计算机诞生之初，艾伦·图灵便梦想着创建一种能够像人类一样使用语言交流的机器人。近年来，大规模语言模型（LLMs）迅速发展，单个模型能够在各种自然语言处理（NLP）任务中表现出色，甚至超越了大部分人类的沟通技巧。GPT、Claude、Grok等模型已对科学界产生了重大影响。然而，这些模型是否真的理解自己生成的内容，尤其是在细腻的主题如幽默方面，仍然是个未知数。这篇论文就是为了探讨计算机理解幽默这一问题，并展示了在微调的情况下，解码器GPT-4o的表现（平均F1-宏分值为0.85）与最优的编码器RoBERTa（平均F1分值为0.86）相当。", "innovation": "本研究创新地通过对比和微调语言模型中的解码器和编码器在处理幽默语言生成任务上的表现，发现解码器GPT-4o的表现与最佳编码器RoBERTa相当。这表明即使是解码器也能理解和产生幽默内容。这一发现为后继研究提供了新的方向，证明了解码器在理解复杂语言现象上的潜力。", "conclusion": "本研究通过对比微调过的解码器和编码器在生成幽默文本任务上的性能表现，证明了解码器能够与编码器一样有效地理解和产生幽默内容。研究结果表明，当前的语言模型技术已经足够先进，能够在复杂的语言理解任务中达到高水平的表现。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04784", "html_url": "https://arxiv.org/abs/2509.04784", "title": "通过确定性点过程增强大型语言模型的多样性", "title_en": "Enhancing Diversity in Large Language Models via Determinantal Point Processes", "authors": "Yilei Chen,Souradip Chakraborty,Lorenz Wolf,Ioannis Ch. Paschalidis,Aldo Pacchiano", "background": "监督微调和强化学习是两种流行的后训练大型语言模型（LLMs）的方法。尽管这些方法可以提高模型在下游任务中的性能，但它们通常会减少模型的输出多样性，导致答案变得狭隘和固定。目前，改善多样性的方法有限，要么只在推理时工作，要么关注词汇差异，没有同时优化质量和语义多样性的方法。", "innovation": "本文提出了一种名为DQO的新训练方法，基于确定性点过程（DPPs），旨在同时优化LLMs的质量和语义多样性。该方法通过为每个提示采样和嵌入一组响应，然后使用基于内核相似矩阵的行列式作为这些响应嵌入所覆盖的体积来衡量多样性。实验结果表明，该方法在提高语义多样性方面取得了显著的效果，而不会牺牲模型性能。", "conclusion": "在指令遵循、摘要、故事生成和推理任务中进行的实验表明，使用DQO方法可以显著提高语义多样性，同时不牺牲模型的质量。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05100", "html_url": "https://arxiv.org/abs/2509.05100", "title": "ICR：会话语义迭代澄清与重写方法", "title_en": "ICR: Iterative Clarification and Rewriting for Conversational Search", "authors": "Zhiyu Cao,Peifeng Li,Qiaoming Zhu", "background": "大多数关于对话查询重写的先前工作采用端到端的重写方法。然而，这种方法受到查询中多个模糊表达式的困扰，这使得同时识别和重写多个位置变得复杂化。", "innovation": "提出了一种新的框架ICR（迭代澄清与重写），这是一种基于澄清问题的迭代重写方案。在该框架中，模型交替生成澄清问题和重写查询。实验证明，ICR 在澄清-重写的迭代过程中不断改进检索性能，从而在两个流行的数据集上达到了最先进的性能。", "conclusion": "ICR框架在解决查询中模糊表达式的复杂性方面表现出色，通过迭代澄清与重写过程提高了检索性能，达到了目前的先进水平。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04753", "html_url": "https://arxiv.org/abs/2509.04753", "title": "大型语言模型在患者信息提取中的研究：模型架构、微调策略及多任务指令微调", "title_en": "A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning", "authors": "Cheng Peng,Xinyu Dong,Mengxian Lyu,Daniel Paredes,Yaoyun Zhang,Yonghui Wu", "background": "自然语言处理（NLP）是通过从临床笔记中提取重要患者信息来支持医疗应用的关键技术。大型语言模型（LLMs）的快速发展已经在临床领域改变了众多NLP任务，但它们在患者信息提取任务中的最佳应用仍有待进一步探索。因此，本文旨在探讨LLMs在患者信息提取任务中的有效性，重点关注不同的模型架构、微调策略和多任务指令微调技术，以开发出稳健且可泛化的患者信息提取系统。本文包括了目前常用的几种方法：仅有编码器或解码器的LLMs、基于提示的参数高效微调算法以及多任务指令微调在少样本学习中的性能。本文在五个数据集上对几种LLMs进行了基准测试，并采用留一数据集法来评估零样本和少样本学习性能。", "innovation": "本文探索了使用LLMs进行临床概念和关系提取的关键概念，特别是包括仅有编码器或解码器的LLMs、提示驱动的参数高效微调算法以及结合任务的多任务指令微调技术在少样本学习中的性能。此外，本文还采用了新型的评估方法，通过留一数据集方法来评估模型在零样本和少样本学习中的表现。", "conclusion": "本文通过在多个数据集上多种大型语言模型进行基准测试，并采用提示驱动的参数高效微调算法和多任务指令微调方法，展示了这些方法在少样本学习中的有效性和零样本学习中的潜力。该研究为开发用于患者信息提取的稳健和可泛化系统提供了新的见解，并为未来的研究指明了方向。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05226", "html_url": "https://arxiv.org/abs/2509.05226", "title": "更少即是更多：通过难度感知的链式思想精简实现高效数学推理", "title_en": "Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation", "authors": "Abdul Waheed,Chancharik Mitra,Laurie Z. Wang,Deva Ramanan,Bhiksha Raj", "background": "链式推理虽然强大，但对于简单问题来说可能会产生冗长的输出。之前的研究方法没有针对问题的复杂性动态调整推理深度。", "innovation": "该论文提出了一个难度感知的推理框架，使得模型能够在不修改架构的情况下，根据问题复杂度动态调整推理深度。通过在精心选择的数据上进行后训练，模型能够学会根据问题的难易程度调整推理长度和格式。", "conclusion": "监督微调主要捕捉推理长度和格式的模式，直接偏好优化保持推理准确性，二者结合可以减小程序长度同时保持或提高性能。定量和定性评估均表明，模型能够学习‘同比例思考’，在简单问题上进行更少的推理，在复杂问题上保持深度。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05060", "html_url": "https://arxiv.org/abs/2509.05060", "title": "Entropy2Vec: 利用单语言模型熵作为端到端可学习的跨语言语言表示", "title_en": "Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End Learnable Language Representations", "authors": "Patrick Amadeus Irawan,Ryandito Diandaru,Belati Jagad Bintang Syuhada,Randy Zakya Suchrady,Alham Fikri Aji,Genta Indra Winata,Fajri Koto,Samuel Cahyawijaya", "background": "传统的语法特征集存在特征稀疏和静态快照的问题，而Entropy2Vec框架通过利用单语言模型中的固有不确定性来捕捉语言之间的类型学关系。通过在一个语言上训练语言模型，熵值的高低反映了该语言与其他语言的结构相似性或差异性，从而提供了一种更丰富的跨语言表示方法，适用于不同时间框架并且数据补齐方式更加灵活", "innovation": "提出了Entropy2Vec框架，通过利用单语言模型的熵值来生成跨语言的语言表示，相比传统的类型学特征集，Entropy2Vec可以捕捉类型学关系变化和提供更密集且无稀疏性的问题，同时能够适应不同时间点的变化，不需要固定的时间点数据", "conclusion": "通过实证评估表明，Entropy2Vec语言表示与已建立的类型学类别相匹配，并在跨语言NLP任务中取得了竞争力的表现，例如由LinguAlchemy框架涉及的任务"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05230", "html_url": "https://arxiv.org/abs/2509.05230", "title": "CURE: 受控去学习以增强鲁棒嵌入——缓解预训练语言模型的概念捷径", "title_en": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "authors": "Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci", "background": "预训练语言模型已经在各种应用中取得了显著的成功，但仍然容易受到概念驱动的虚假相关性的影响，这些相关性削弱了模型的鲁棒性和公平性。", "innovation": "本文提出了一种新颖且轻量级的框架CURE，用于系统地分离和抑制概念捷径，同时保留关键内容信息。该方法通过专门的内容抽取器和反转网络提取与概念无关的表示，通过对比学习进一步调整剩余概念线索的影响，使模型能够减少有害偏见或利用有益的相关性，以适应目标任务。", "conclusion": "在IMDB和Yelp数据集上使用三种预训练架构进行评估，CURE在IMDB上的F1分数绝对提高了10%，在Yelp上提高了2%，且引入了最小的计算开销。本方法为建立灵活、无监督的概念偏见对抗蓝图奠定了基础，为进一步构建可靠和公平的语言理解系统铺平了道路。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05209", "html_url": "https://arxiv.org/abs/2509.05209", "title": "Hunyuan-MT技术报告", "title_en": "Hunyuan-MT Technical Report", "authors": "Mao Zheng,Zheng Li,Bingxin Qu,Mingyang Song,Yang Du,Mingrui Sun,Di Wang", "background": "该研究介绍了Hunyuan-MT-7B，这是一种多语言翻译模型，支持33种主要语言之间的双向翻译，特别关注了普通话与其他少数民族语言及方言之间的翻译。此外，为应对多种翻译场景并提升模型测试时的表现，研究引入了一种名为Hunyuan-MT-Chimera-7B的模型，该模型借鉴了慢思考模式，通过集成Hunyuan-MT-7B模型在不同参数设置下的多个输出，实现了优于传统基于Chain-of-Thought（CoT）的慢思考模型的性能。", "innovation": "该研究开发了两种多语言翻译模型，即Hunyuan-MT-7B和Hunyuan-MT-Chimera-7B，特别强调普通话与其他少数民族语言及方言之间的翻译。Hunyuan-MT-Chimera-7B模型结合了Hunyuan-MT-7B模型在不同参数设置下的多个输出，表现出色。研究还开发了一种全面的训练过程，包括一般和翻译导向的预训练、监督微调（SFT）以及强化学习（RL）和弱到强的RL增强。", "conclusion": "通过全面的实验证明了Hunyuan-MT-7B和Hunyuan-MT-Chimera-7B模型在翻译任务中显著优于其他相等参数大小的翻译模型和大多数SOTA大型模型，特别是在普通话和其他少数民族语言及方言之间的翻译任务中表现突出。在WMT2025共享任务中，该模型在31个语言配对中的30个中排名第一，展示了模型在广泛语言谱系中的稳健性能，涵盖了资源丰富和资源稀缺的语言。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05146", "html_url": "https://arxiv.org/abs/2509.05146", "title": "PRIM: 朝着实用的图像内多语言机器翻译", "title_en": "PRIM: Towards Practical In-Image Multilingual Machine Translation", "authors": "Yanzhi Tian,Zeming Liu,Zhengyang Liu,Chong Feng,Xin Li,Heyan Huang,Yuhang Guo", "background": "当前研究中的端到端图像内机器翻译（IIMT）主要基于合成数据，这些数据具有简单的背景、单一字体、固定文字位置以及双向翻译，无法充分反映真实世界的情况，导致研究与实际应用之间存在显著差距。", "innovation": "本文探索了实用的图像内多语言机器翻译（IIMMT），开发了公共数据集PRIM，包含具有复杂背景、多种字体、多样文字位置的现实捕获单行文本图像，并支持多语言翻译方向。提出了一种端到端模型VisTrans来处理PRIM的实际条件挑战，模型能够分别处理图像中的视觉文本和背景信息，同时提高翻译质量和视觉效果。", "conclusion": "实验结果表明，VisTrans在翻译质量和视觉效果方面优于其他模型。代码和数据集可从以下链接获得：this https URL。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05254", "html_url": "https://arxiv.org/abs/2509.05254", "title": "Uniform Information Density and Syntactic Reduction: Revisiting that-Mentioning in English Complement Clauses", "title_en": "Uniform Information Density and Syntactic Reduction: Revisiting $\\textit{that}$-Mentioning in English Complement Clauses", "authors": "Hailin Hao,Elsi Kaiser", "background": "语言生产过程中，说话人常常拥有多种表达同一意义的方式。均匀信息密度（UID）假设提出，说话人在使用多种表达方式时，会维持一个恒定的信息传输速率。先前的研究发现，在英语补足语从句中，可选连接词'that'更有可能被省略，当从句的信息密度较低（即更容易预测）时。本文基于这一发现，使用大规模现代对话语料库以及机器学习和神经语言模型重新审视了信息密度与'that'-省略之间的关系，改进了过去基于矩阵动词范畴化的信息密度计算方法，并探讨了从上下文词嵌入推导出的信息密度估计值如何更合理地解释'that'-使用模式的变异情况。", "innovation": "引入了大规模现代对话语料库和机器学习、神经语言模型来重新评估信息密度与'that'-省略之间的关系。改进了基于矩阵动词范畴化的信息密度计算方法，并提出了从上下文词嵌入推导出的信息密度估计值，更好地解释了形容词词使用模式中的变异情况。", "conclusion": "我们的结果证实了信息密度与'that'-省略之间的关系。然而，我们还发现，基于矩阵动词范畴化的信息密度测量捕捉到了显著的词表特异性变异性。相比之下，从上下文词嵌入中得出的信息密度估计值能够更好地解释补足词化使用模式中的额外变异情况。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05282", "html_url": "https://arxiv.org/abs/2509.05282", "title": "揭示线性注意力衰减的设计空间", "title_en": "Elucidating the Design Space of Decay in Linear Attention", "authors": "Zhen Qin,Xuyang Shen,Yiran Zhong", "background": "本文对线性复杂度序列模型内在的衰减机制进行了全面的研究。研究跨越了四个关键维度：参数化策略、参数共享、衰减粒度以及与相对位置编码方法的兼容性。这些维度包括了计算衰减的策略、利用额外参数来计算衰减的方法、衰减的粒度区分标量衰减与矢量衰减，以及与RoPE等相对位置嵌入方法的兼容性。通过在各种语言建模任务上进行广泛实验，本文得出了几个关键洞察。", "innovation": "文章系统性地分析了衰减机制在四个维度的设计空间，包括参数化策略、参数共享、衰减粒度和相对位置编码方法兼容性等。实验结果揭示了不同衰减机制在各种语言模型任务上的表现差异，强调了设计参数化策略的重要性，发现了参数共享的影响以及标量与矢量衰减在不同场景下的表现。", "conclusion": "本文的研究结果表明，衰减机制的设计需要仔细考虑，有效的配置往往局限于特定参数范围；参数共享不可随意使用，因为它可能导致衰减值过大或过小；在相同的参数化策略下，标量衰减通常不如向量衰减表现好，但在某些场景中，标量衰减可能超过向量衰减；RoPE通常不能显著增强大多数线性注意力机制的表现。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05291", "html_url": "https://arxiv.org/abs/2509.05291", "title": "时间上的跨编码：追踪LLM预训练期间语言表示的出现与巩固", "title_en": "Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining", "authors": "Deniz Bayazit,Aaron Mueller,Antoine Bosselut", "background": "大型语言模型（LLMs）在预训练过程中学习了复杂的抽象概念，如不定复数名词的识别。然而，现有传统评估方法，例如基准测试，不能充分揭示模型如何从数据中获取概念和能力，导致我们对特定语言能力何时及如何在模型中出现缺乏了解。因此，有必要通过新的方法了解模型预训练过程中的概念层面的训练情况，以此填补这一空白。", "innovation": "该研究提出了一种使用稀疏跨编码器的方法，用于发现和对齐不同预训练检查点之间的特征，以便追踪语言特征在预训练过程中的演变。通过这种方法，研究者发现跨编码器能够检测出特征在预训练过程中的出现、维持以及中断，并引入了新型度量指标RelIE来追踪哪些特征阶段变得对任务性能具有因果重要性。这种方法是架构无关的且具有可扩展性，为进一步提高预训练期间表示学习的解释性和细致性探索了一条新的路径。", "conclusion": "通过稀疏跨编码器的方法，该研究展示了模型在预训练过程中如何学习语言表示的出现、维持和中断。该方法提供了更加透明和细致的预训练期间表示学习分析潜力，为全面理解语言模型的能力与发展过程提供了一种新的视角。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05066", "html_url": "https://arxiv.org/abs/2509.05066", "title": "ToM-SSI: 评估情境社会交往中的心智理论", "title_en": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions", "authors": "Matteo Bortoletto,Constantin Ruhdorfer,Andreas Bulling", "background": "现有的大多数基础模型的心智理论（ToM）基准测试主要依赖于莎莉-安妮测试的不同变体，这些测试只能提供有限的ToM视角，忽略了人类社会互动的复杂性。为了解决这一问题，我们提出了ToM-SSI，这是一种新的基准测试，专门设计用于测试在充满社交互动和空间动态环境中的心智理论能力。当前的ToM基准测试仅限于纯文本或双人互动，而ToM-SSI则包括最多四人之间的具有沟通和移动的多模式互动。这种独特的设计使我们首次能够研究混合合作阻碍设置，并同时推断多个代理人的心理状态，从而捕捉到比现有基准更广泛的社交认知。评估表明，当前模型在这些新任务中的表现仍然非常有限，突显出未来研究中的关键缺口。", "innovation": "ToM-SSI是一种专门设计的新基准测试，用于评估在丰富的社交互动和空间动态环境中的心智理论能力。它支持多模式互动，并包括最多四人之间的小组互动，这些互动具有沟通和移动特性。这种设计允许首次研究混合合作阻碍设置，并推断多个代理人的心理状态，从而捕捉到比现有基准更广泛的社交认知。", "conclusion": "我们的评估表明，当前的模型在这些新任务中的表现仍然非常有限，这突显了未来研究中的关键缺口，特别是在涉及多个代理人和复杂交互的社交环境中。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.03083", "html_url": "https://arxiv.org/abs/2506.03083", "title": "使用未知参考数据进行数据标注", "title_en": "Labelling Data with Unknown References", "authors": "Adrian de Wynter", "background": "当评估者作为标签者时，存在被广泛认可的方式来衡量其表现才能被认为是有可信度的。传统的建立可信性的方法要么通过测试评估者，要么假设评估者“知道”如何正确地标注语料库。然而，如果缺乏已标注的参考（例如开发集），这两种方法都无法运作：前者需要数据，而后者仅是假设而非证据。因此，本文提出了一种新的方法（称为“无数据算法”）来评估者在没有任何已有的参考的情况下建立试验者可信度的方法。这种方法通过逐渐地针对评估者提出挑战来验证其可信度。这种方法的成功可以证明，当评估者实际上了解如何标注语料库时，该方法会接受其输出；反之，当评估者无法证明其能力时，则会将它们标记为不可靠。", "innovation": "本文创新地提出了一个无需参考数据即可检验评估者可信度的算法（即‘无数据算法’）。该方法通过逐步向评估者提出挑战来验证其标签准确性。同时，作者还提供了形式证明、实证测试并展示了该方法在低资源语言的大型语言模型作为裁判者上的应用。", "conclusion": "该研究显示，提出的无数据算法能够以几乎可靠的方式建立评估者的可信度，当评估者实际上了解如何正确标签语料库时能够接受其输出，而无法证明的评估者将被认为是不可靠的。这种方法为在缺乏标注参考数据的情况下评估评估者和标签质量提供了一种新的方案，对于那些数据有限或没有标注参考数据的低资源语言的标注任务尤为适用。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05218", "html_url": "https://arxiv.org/abs/2509.05218", "title": "HoPE: 超曲面旋转位置编码在大规模语言模型中用于稳定长距离依赖建模", "title_en": "HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models", "authors": "Chang Dai,Hongyu Shan,Mingyang Song,Di Liang", "background": "位置编码机制使Transformer能够建模文本中的序列表征和长距离依赖关系。然而，绝对位置编码在面对长序列时由于其固定的序数值难以进行外推，而相对位置编码如Alibi在极度长的上下文中表现下降。广泛使用的旋转位置编码（RoPE）引入了振荡的注意力模式，妨碍了稳定长距离依赖关系的建模。现有方法存在这些限制，本文提出了一种基于超曲几何Lorentz变换的几何重构位置编码方法，旨在解决这些问题。", "innovation": "通过借鉴超曲几何中的Lorentz变换，提出了一种新的位置编码方法——超曲面旋转位置编码（HoPE），利用双曲函数在token表示上执行Lorentz旋转。理论上证明了RoPE是一种特殊情况，霍PE从根本上解决了RoPE的问题，通过确保注意力权重随着token距离的增加而单调衰减来实现这一点。实验结果表明，在几种扩展序列基准上的困惑度评估中，HoPE在与现有位置编码方法对比中表现更优，证明了HoPE增强的长距离依赖表示和泛化能力。", "conclusion": "该研究通过HoPE成功地解决了现有的长距离依赖建模问题，实验结果展现出了HoPE在长距离依赖体现和泛化能力上的优越性。所有数据和代码都将公开提供。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04667", "html_url": "https://arxiv.org/abs/2509.04667", "title": "暗流：低延迟下的实时语音匿名化", "title_en": "DarkStream: real-time speech anonymization with low latency", "authors": "Waris Quamer,Ricardo Gutierrez-Osuna", "background": "在严格的时间延迟限制下，对于实时的语音合成，保持内容编码的同时需要进行语音匿名化是一个挑战。", "innovation": "提出了一种名为DarkStream的新颖的实时语音合成模型，通过结合因果波形编码器、短时间向前缓冲区和基于变换器的上下文层来提升内容编码，进一步通过神经声码器直接生成波形以减少推理时间，并通过注入生成的伪说话人嵌入来匿名化说话人身份。", "conclusion": "该研究展示了DarkStream模型在真实场景下的有效性，能够实现高强度的匿名化，达到接近50%的说话人验证EER（接近随机性能），同时保持可接受的语言可懂度（单词错误率在9%以内）。通过平衡低延迟、稳健的隐私保护和最小的语言可懂度退化，DarkStream为实时语音通信中的隐私保护提供了可行的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04731", "html_url": "https://arxiv.org/abs/2509.04731", "title": "语言驱动的分层任务结构作为多智能体学习的显式世界模型", "title_en": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "authors": "Brennen Hill", "background": "当前人工智能领域的一个关键前沿在于语言模型、代理模型和世界模型的融合，尽管最近的研究主要集中在扩展语言和代理模型上，但构建复杂的显式世界模型仍然是一个关键瓶颈，特别是在复杂的多智能体长期任务中。在诸如机器人足球这样的领域，使用高保真但结构扁平的模拟器通过标准强化学习训练的智能体常常由于难以解决的探索空间和稀疏奖励而失败。", "innovation": "本文提出了一种范式转变，即通过利用大型语言模型动态生成分层支撑结构，实现语言驱动的世界模型。这种分层支撑结构有助于内在课程设置，提供密集且有意义的学习信号，并构建组合学习框架，使代理模型能够以极高的样本效率获得复杂的战略行为。这种语言驱动的世界模型为低级反应行为和高层次战略团队协同提供了桥梁，创建了一个强大且可泛化的智能代理训练框架。", "conclusion": "通过构建具有显式、语言可配置的任务层级的环境，可以填补低级反应行为和高级战略团队协同之间的差距，创建下一代智能代理的强大且可泛化的训练框架。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05199", "html_url": "https://arxiv.org/abs/2509.05199", "title": "认知、功能和因果维度的三元融合以实现可解释的大语言模型：TAXAL框架", "title_en": "Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework", "authors": "David Herrera-Poyatos,Carlos Peláez-González,Cristina Zuheros,Virilo Tejedor,Rosana Montes,Francisco Herrera", "background": "大型语言模型（LLMs）被越来越多地部署在高风险领域中，但在这些领域中，模型的不透明性、偏见和不稳定性降低了人们对这些模型的信任和可问责性。传统的解释方法集中于表面输出，不能捕捉到有代理权的LLMs的推理路径、规划逻辑及其系统影响。为了应对这一挑战，该研究引入了TAXAL（Triadic Alignment for eXplainability in Agentic LLMs）框架，结合了认知（用户理解）、功能（实用价值）和因果（忠实推理）这三重维度，为设计、评估和部署这些有代理权的LLMs的解释提供了统一的基础，在不同的社会技术环境中具有广泛的适用性。", "innovation": "TAXAL框架通过融合认知、功能和因果三个维度，提供了一种新的基于角色的解释设计、评估和部署方法。该研究综合了现有的解释方法，并将其置于TAXAL的三元融合模型框架中。通过在法律、教育、医疗保健和公共服务等领域的案例研究，显示了解释策略如何根据机构限制和利益相关者的角色进行调整。这意味着TAXAL框架不仅在概念上清晰，而且实用且可操作性强，在代理人工智能时代提升了解释性作为技术和社会技术实践的地位，支持可信和情境敏感的应用。", "conclusion": "TAXAL框架提供了一种新的技术和社会技术实践，增强了代理人工智能时代LLMs应用的可信度和情境敏感性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04642", "html_url": "https://arxiv.org/abs/2509.04642", "title": "Maestro：可靠AI代理的联合图与配置优化", "title_en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "authors": "Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi", "background": "构建可靠的大型语言模型（LLM）代理需要决策在两个层面：图形（确定模块的存在及信息流方式）以及每个节点的配置（模型、提示、工具和控制旋钮）。现有的大多数优化器在固定图形的情况下调整配置，这会导致结构性的失败模式未被解决。因此，研究一种同时搜索图形和配置的优化框架对于提高LLM代理的质量显得至关重要。", "innovation": "作者提出了Maestro，一种框架无关的综合优化框架，它同时搜索图形和配置以最大化代理质量，并受到明确的展开/标记预算限制。Maestro通过使用带反馈的文本进行反思，优先调整编辑，从而提升样本效率，并有针对性地解决问题模式。Maestro在此方面优于现有的提示优化方法MIPROv2、GEPA和GEPA+Merge，在IFBench和HotpotQA基准测试中分别以12%、4.9%和4.86%的平均优势超过它们。即使仅优化提示，它也仍然显示出9.65%、2.37%和2.41%的优势。", "conclusion": "Maestro通过比GEPA需要更少的展开次数就取得了这些结果。进一步的实验表明，Maestro在两种应用（面试官和基于检索的生成代理）上取得了显著的收益，这表明它联合搜索图形和配置能够解决单独提示调优无法解决的结构性问题。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04823", "html_url": "https://arxiv.org/abs/2509.04823", "title": "通过社交媒体上多模态用户观看法评估认知-行为固定", "title_en": "Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing Patterns on Social Media", "authors": "Yujie Wang,Yunwei Zhao,Jing Yang,Han Han,Shiguang Shan,Jie Zhang", "background": "数字社交媒体平台经常导致认知-行为固定现象，即用户在狭窄的内容领域内呈现出持续和重复的行为模式。尽管认知-行为固定已被心理学领域广泛研究，但对这种固定行为的计算检测和评估方法却鲜有探索。这导致了研究中的空白，亟需提出新的方法和工具来填补这一空白并推动这一研究领域的发展。", "innovation": "本研究提出了一种新的框架，通过分析用户在社交媒体上的多模态互动模式来评估认知-行为固定现象。研究引入了一种多模态主题提取模块和一种认知-行为固定度量模块，这两个模块结合起来可以实现适应性、层次化和可解释性的用户行为评估。这种方法在现有基准和新构建的多模态数据集上进行实验，证明了其有效性，为大规模的计算分析提供了基础。所有代码都在GitHub上公开，供研究使用，这是本研究的创新点之一。", "conclusion": "本研究通过多模态用户社交媒体行为模式评估了认知-行为固定现象的有效方法。实验结果表明，提出的方法能够有效地进行认知-行为固定分析，为未来的大规模跨平台分析和实现个性化推荐提供了一种可能的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04908", "html_url": "https://arxiv.org/abs/2509.04908", "title": "SparkUI-Parser：增强UI感知的稳健接地和解析", "title_en": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "authors": "Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao", "background": "现有的针对GUI感知的多模态大型语言模型（MLLMs）已经取得了一定的进展，但仍存在一些挑战。首先，这些模型基于文本自回归机制来建模离散坐标，这导致了较低的定位准确性和较慢的推理速度。其次，这些模型只能定位预定义的元素集，而无法解析整个界面，这限制了其在下游任务中的广泛应用。", "innovation": "本文提出了一种名为SparkUI-Parser的新型端到端框架，该框架同时实现了较高的定位精度和对整个界面进行细粒度解析的能力。具体而言，该方法采用了基于预训练的多模态大型语言模型进行连续坐标建模，而不是使用基于概率的离散建模。此外，引入了一种基于修改后的匈牙利匹配算法的拒绝机制，以增强模型的鲁棒性，并减少误检。", "conclusion": "广泛的实验表明，我们的方法在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse基准上的一致性地超过了SOTA方法。这一研究成果提供了一种新的方法来提高GUI感知的准确性，提高了模型的鲁棒性，并为下游任务提供了更广泛的支持。有关资源可在此处访问：[提供链接部分]。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05215", "html_url": "https://arxiv.org/abs/2509.05215", "title": "BEDTime: 统一的时间序列自动描述基准", "title_en": "BEDTime: A Unified Benchmark for Automatically Describing Time Series", "authors": "Medhasweta Sen,Zachary Gottesman,Jiaxing Qiu,C. Bayan Bruss,Nam Nguyen,Tom Hartvigsen", "background": "许多最近的研究提出了一种通用的基础模型，用于各种时间序列分析任务。尽管已有几种已建立的数据集用于评估这些模型，但过往的工作往往在引入新模型的同时也提出了新的数据集，这限制了直接、独立比较的机会，并使不同方法的相对优势变得模糊。此外，之前的评估通常同时覆盖多种任务，未能明确指出哪些能力对总体性能有贡献。为解决这些问题，该研究具体化并评估了3个任务，测试模型用通用自然语言描述时间序列的能力：(1) 识别（是/否问答），(2) 区分（多项选择问答），(3) 生成（开放式的自然语言描述）。然后，统一了4个最近的数据集，从而在每个任务上实现了模型之间的直接竞争。实验中对13个最先进的语言、跨模态及时间序列与语言模型的评估表明：(1) 流行的语言方法普遍表现不佳，表明需要专门的时间序列架构，(2) 跨模态语言模型非常成功，符合预期，指向视觉模型在这些任务中的价值，(3) 预训练的多模态时间序列与语言模型虽然优于语言模型，但仍有许多提升空间。所有方法在多种鲁棒性测试中也表现出明显的脆弱性。总体而言，该基准为时间序列推理系统的必要任务评估提供了标准化的标准。", "innovation": "该研究具体化并评估了3个任务，测试模型用通用自然语言描述时间序列的能力，包括识别、区分和生成任务；统一了4个最近的数据集，首次在每个任务上实现了模型之间的直接竞争；实验结果揭示了不同模型类型的优势与局限性；此外，研究人员在鲁棒性测试中发现所有方法都表现出脆弱性，强调了进一步研究的空间。", "conclusion": "该基准提供了一个标准化评价，对于时间序列推理系统任务是必要的。研究结果表明，现有方法普遍表现不佳，尤其是语言方法，强调了开发专门的时间序列架构的必要性；同时揭示了跨模态语言模型在这些任务上的价值；还表明预训练的多模态时间序列与语言模型优于语言模型，但仍有提升空间。此外，所有方法在鲁棒性方面都存在不足，突出了未来研究的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04810", "html_url": "https://arxiv.org/abs/2509.04810", "title": "无国界的代码审查：合成数据与真实数据在审查推荐中的评估", "title_en": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation", "authors": "Yogev Cohen,Dudi Ohayon,Romy Somkin,Yehudit Aperstein,Alexander Apartsin", "background": "在现代开发流程中，自动决定代码更改是否需要人工审查对于保持软件质量至关重要。然而，新兴编程语言和框架的出现造成了新的挑战：虽然有大量的未标记代码可用，但缺乏足够的标记数据来训练监督模型进行审查分类。这些新兴语言和框架的特点使得传统的方法难以有效应用。因此，如何利用合成数据来解决Label数据稀缺的问题成为了关键问题。", "innovation": "本文通过利用大型语言模型（LLMs）将资源丰富的语言的代码更改翻译为新兴或不足资源语言的等效更改，这种方法生成了合成训练数据来弥补标记数据的不足。这种方法利用了LLMs从未标记代码中学习到的新语言的语法和语义，但尚未完全理解这些新兴生态系统中哪些代码更改被认为是重要的或需要审查的。通过这种方法，研究人员使用合成数据训练监督分类器，并系统地将其性能与基于真实标记数据训练的模型进行比较。实验结果表明，合成数据可以有效地引导审查推荐系统，即使在资源缺乏的环境中也能减小性能差距。该方法为扩展自动化代码审查能力提供了一个可扩展的途径，即使缺乏标注数据，也能应用于快速演变的技术堆栈中。", "conclusion": "研究证明了利用大型语言模型生成的合成数据可以显著提高审查推荐系统的性能，特别是在资源有限的情况下。这种方法为快速发展的技术栈中的自动代码审查提供了新途径，拓宽了使用合成数据在缺乏标注数据的情况下实现自动化代码审查的可能。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05072", "html_url": "https://arxiv.org/abs/2509.05072", "title": "找到您的缪斯：挖掘意外解决方案引擎", "title_en": "Finding your MUSE: Mining Unexpected Solutions Engine", "authors": "Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf", "background": "创新者往往受到现有解决方案或初步想法的认知固定，阻碍了对新颖替代方案的探索。本文介绍了一种构建功能性概念图（FCG）的方法，通过将功能性要素互联起来，支持抽象化、问题重组和类比启发，解决早期工作中的局限性。我们进一步提出了一种利用FCG生成给定问题创造性灵感的MUSE算法。通过计算500,000项专利的功能性概念图并释放数据，来演示该方法的效果和潜力。", "innovation": "本方法通过构建功能性概念图（FCG），支持抽象化、问题重组和类比启发，解决了早期工作中的限制。提出的MUSE算法利用FCG为特定问题生成创新灵感，提供了一个全新的解决方案挖掘引擎。", "conclusion": "我们通过计算500,000项专利的功能性概念图展示了该方法的有效性，并将其发布以供进一步研究。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2302.01626", "html_url": "https://arxiv.org/abs/2302.01626", "title": "改进跨语言密集检索的序列句间关系建模", "title_en": "Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval", "authors": "Shunyu Zhang,Yaobo Liang,Ming Gong,Daxin Jiang,Nan Duan", "background": "近期，多语言预训练语言模型（如mBERT和XLM-R）在跨语言密集检索方面取得了显著进展。然而，现有的多语言预训练模型大多是通用的，针对跨语言检索定制的多语言预训练模型尚未被探索。研究观察到平行文档中的句子顺序在不同语言中具有可大致相同性，这为跨语言建模提供了可能。", "innovation": "本文提出了一种多语言模型（MSM），通过在句子上构建编码器处理文档中的句子表示，并使用共享的文档编码器在所有语言中建模这一普遍存在的顺序关系。此外，还设计了一种掩蔽句子预测任务，通过分层对比损失与采样的负样本对句子向量进行掩蔽和预测。实验结果显示，MSM在四个跨语言检索任务中显著优于现有的先进预训练模型，展示了新型模型的有效性和更强的跨语言检索能力。", "conclusion": "经过全面的实验，MSM在四个跨语言检索任务中表现优越，验证了其方法的有效性和对跨语言检索的独特改进能力，同时也开放了该模型的代码和模型供进一步研究。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05293", "html_url": "https://arxiv.org/abs/2509.05293", "title": "非终止性证明：超过1亿行代码", "title_en": "Non-Termination Proving: 100 Million LoC and Beyond", "authors": "Julien Vanegue,Jules Villard,Peter O'Hearn,Azalea Raad", "background": "之前的工具主要针对短小的基准代码，通常只有数十到数百行代码。然而，现代软件项目的规模庞大，某些公司拥有的代码量可能达到数千万甚至上亿行。这样的规模限制了现有工具的实际应用，而对真实世界代码库中非终止性问题的检测也同样面临挑战。", "innovation": "该工具脉冲无限（Pulse Infinite）采用了证明技术来验证大型程序的非终止性。它在验证和准确性之间找到平衡，一方面通过组合方式支持大规模验证，另一方面通过适当的下限近似保证证明的正确性。这种方法突破了之前应用于短代码的问题，能够应用于亿级行代码，并在多个开源和专有软件中检测出超过30个之前未知的问题。", "conclusion": "通过应用脉冲无限，研究团队在大量C、C++和Hack语言编写的源代码中识别出了大量的新问题，显著提高了对真实世界代码库中非终止性检测的新标准。这一成果展示了在大型程序验证领域的重大进步。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04926", "html_url": "https://arxiv.org/abs/2509.04926", "title": "基于质性定义概念的对话本体化描述", "title_en": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "authors": "Barbara Gendron(LORIA, UL),Gaël Guibon(LIPN, LORIA),Mathieu D'aquin(LORIA, UL)", "background": "大型语言模型（LLMs）作为对话代理使用时的可控性是一个关键挑战，特别是确保其生成的响应具有可预测性和个性化的功能。本文探讨了通过一种本体论方法以形式化定义通常具有质性特征的对话特性，通过利用一组语言描述符，推理出定量化定义，从而可以为这样的概念提供整合并在本体中进行逻辑推断和一致性检查。本研究以CEFR语言熟练度水平为例，探讨了对话控制水准的实现，将这些定义融入描述逻辑中，并通过微调引导LLM生成控制文本。实验结果表明，本文的方法提供了一致且可解释的对话控制水准定义，提高了对话AI的透明度。", "innovation": "提出了一种基于本体论的方法，以形式化定义通常具有质性特征的对话特性。通过使用一组语言描述符，推理出定量定义，使这些概念能够被整合进一个本体中进行逻辑推断和一致性检查。将这种方法应用于对话控制水准的实现中，使用CEFR语言熟练度水平作为案例研究，经过描述逻辑的正式化和本体的整合，通过微调引导LLM生成控制文本。方法提供了一致且可解释的对话控制水准定义，提高了对话AI的透明度。", "conclusion": "实验结果表明，本文的方法提供了一致且可解释的对话控制水准定义，使对话AI的回答更加透明，这对于确保用户个性化且可预测的响应是必要的。通过这种方法，大型语言模型的应用范围可以拓展，使其更加可控，能够更好地适应不同用户的需求。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05007", "html_url": "https://arxiv.org/abs/2509.05007", "title": "Sticker-TTS: 以贴纸驱动的测试时扩展框架学习利用历史经验", "title_en": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "authors": "Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen", "background": "大型推理模型（LRMs）在复杂推理任务上表现出强大的性能，进一步通过增加推理时的计算预算可以取得更好的效果。然而，当前主要在测试时缩放方法主要是依赖冗余采样，忽略了历史经验的利用，这限制了计算效率。", "innovation": "提出了一种新颖的测试时缩放框架Sticker-TTS，协调三个协作的LRMs进行迭代探索和细化解决方案，并围绕历史尝试进行引导。核心是提取关键条件——称为贴纸，驱动多轮推理中关键信息的提取、细化和重复利用。进一步引入两阶段优化策略，结合模仿学习和自我改进，实现逐步精炼。", "conclusion": "在AIME-24、AIME-25和OlymMATH三个具有挑战性的数学推理基准测试上的广泛评估表明，在相似推理预算下，Sticker-TTS持续超越包括自我一致性及先进强化学习方法在内的强大基准，突显了贴纸引导的历史经验利用的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.12226", "html_url": "https://arxiv.org/abs/2402.12226", "title": "AnyGPT：具有离散序列建模的统一多模态语言模型", "title_en": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "authors": "Jun Zhan,Junqi Dai,Jiasheng Ye,Yunhua Zhou,Dong Zhang,Zhigeng Liu,Xin Zhang,Ruibin Yuan,Ge Zhang,Linyang Li,Hang Yan,Jie Fu,Tao Gui,Tianxiang Sun,Yugang Jiang,Xipeng Qiu", "background": "当前主要的大型语言模型（LLM）专注于文本处理，但在处理多元模态数据（如语音、文本、图像和音乐）时存在局限性。本文旨在克服这些局限，提出一种能够统一处理多种模态的AnyGPT模型。该模型利用离散表示方法，无需更改现有LLM架构或训练方法，通过数据层级预处理实现新模态的无缝集成，类似于新语言的整合方式。", "innovation": "首次构建了多模态文本中心数据集，用于多元模态对齐预训练。利用生成模型，并合成了一个大规模的任何到任何的多模态指令数据集，该数据集包含108,000个复杂交织了各种模态的多轮对话样本。此创新为模型处理任意组合的多模态输入和输出提供了基础。实验表明，AnyGPT不仅能实现任意到任意的多模态对话，还能在所有模态上达到专用模型的性能，证明离散表示方法可以在语言模型中有效地统一多元模态。", "conclusion": "研究结果表明，AnyGPT能够实现任意到任意的多模态对话，并且在所有模态上达到了与专用模型相当的性能。离散表示方法能够有效地在语言模型中统一多种模态。该模型展示了离散序列建模在统一处理多种模态数据方面的能力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.18416", "html_url": "https://arxiv.org/abs/2407.18416", "title": "PersonaGym：评估persona代理和LLM", "title_en": "PersonaGym: Evaluating Persona Agents and LLMs", "authors": "Vinay Samuel,Henry Peng Zou,Yue Zhou,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Ameet Deshpande,Karthik Narasimhan,Vishvak Murahari", "background": "persona代理是基于指定的人格而进行行为调节的LLM代理，能够在教育和医疗等领域提供丰富且用户对齐的互动。然而，在自由形式的环境中，特别是在需要在多种多样的、与人格相关的环境中保持一致性的情况下，评估这些代理如何忠实于其人格仍是一个重大挑战。本文介绍了PersonaGym，这是第一个动态评价框架，以及PersonaScore，一种以决策理论为基础的人类对齐自动度量标准，能够实现大规模的全面评价。研究人员对10个领先的LLM在200个人格和10000个问题进行了评估，揭示了对提升这些代理的有效途径。", "innovation": "本文提出了PersonaGym——第一个动态评估框架，以及PersonaScore——一种基于决策理论的人类对齐自动度量标准，能够实现大规模的全面评价。该研究发现，最新的闭源模型GPT-4.1与较旧的开源模型LaLaMA-3-8b在PersonaScore方面的表现相同，这表明增加模型的大小和复杂性并不一定能够提高persona代理的能力，从而突出了对算法和结构创新的需求，以提升可信且高效的persona代理性能。", "conclusion": "研究表明，现有的顶级LLM在忠实于其人格方面仍然有很大的提升空间。研究结果强调了算法和架构创新对构建忠实且高效persona代理的需求，而非仅依赖于模型大小的增加。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04744", "html_url": "https://arxiv.org/abs/2509.04744", "title": "WildScore: 在线多媒体大型语言模型的符号音乐推理基准", "title_en": "WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning", "authors": "Gagan Mundada,Yash Vishe,Amit Namburi,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu", "background": "近年来，多模态大型语言模型（MLLMs）在各种视觉-语言任务中展示了令人印象深刻的性能。然而，它们在多媒体符号音乐领域的推理能力尚未被充分探索。野谱数据集（WildScore）是第一个用于评估MLLMs在解释真实音乐谱和回答复杂音乐学查询方面能力的在线多模态符号音乐推理和分析基准。它包含来自实际音乐作品的真实用户生成问题和讨论，真实地反映了音乐分析的复杂性。为了促进系统的评估，研究提出了一种系统分类法，包括高层和细粒度的音乐学本体。此外，研究将复杂的音乐推理问题重新表述为多项选择题答案，以实现对MLLMs符号音乐理解的受控和可扩展评估。", "innovation": "研究提出了一种新的基准WildScore，用于评估MLLMs在符号音乐推理方面的在线能力，并引入了系统性的分类法和复杂音乐推理的多项选择题形式。通过这个基准，研究揭示了MLLMs在符号音乐推理方面的视觉-符号推理模式，发现了MLLMs在这领域能力的潜力和发展空间，同时也揭示了存在的持续挑战。", "conclusion": "通过对最新技术在WildScore上的实证评估，研究揭示了MLLMs在符号音乐分析中的视觉-符号推理模式。该数据集的公开将促进相关领域的研究和发展。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.02544", "html_url": "https://arxiv.org/abs/2408.02544", "title": "注意环境：多模态大语言模型代理易受环境干扰", "title_en": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "authors": "Xinbei Ma,Yiting Wang,Yao Yao,Tongxin Yuan,Aston Zhang,Zhuosheng Zhang,Hai Zhao", "background": "本文探讨了多模态大语言模型（MLLM）代理在图形用户界面（GUI）环境中的忠诚度，特别是关于环境背景是否可能使这些代理分散注意力的问题。研究背景基于以下场景：用户和代理都是非恶意的，而环境虽然不恶意但仍包含无关内容。研究使用模拟数据集评估了多种MMLMs作为GUI代理的效果，并观察了不同感知水平下的三种工作模式。研究表明，即使是功能最强大的模型，无论是通用型代理还是专精于GUI的代理，都容易受到环境因素的干扰。这表明，以往研究主要集中于代理的有用性，但实际环境中代理更容易受到环境干扰。", "innovation": "本文首次指出了多模态GUI代理易受环境干扰的现象，并通过实施对抗性环境注入进一步分析了改进忠诚度的方法，呼吁对此类重要问题的关注。", "conclusion": "研究表明，多模态大语言模型代理即使在功能最强大的情况下，仍然容易受到环境干扰。这为未来的多模态代理设计提出了新的挑战，并强调了环境因素在用户交互中的重要性。此外，本文还提出了一种改进策略，并通过实验展示了其有效性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.13518", "html_url": "https://arxiv.org/abs/2408.13518", "title": "基于令牌级奖励函数估计的选择性偏好优化", "title_en": "Selective Preference Optimization via Token-Level Reward Function Estimation", "authors": "Kailai Yang,Zhiwei Liu,Qianqian Xie,Jimin Huang,Erxue Min,Sophia Ananiadou", "background": "近年来，大型语言模型对齐的发展利用令牌级监督来实现精细粒度的偏好优化。然而，现有的令牌级对齐方法要么优化所有可用的令牌，这可能噪声较大且低效；要么使用复杂的和昂贵的关键令牌选择策略进行选择训练。", "innovation": "提出了一种新颖的选择性对齐策略——选择性偏好优化（SePO），其核心是高效的要点选择。SePO 提出了第一个基于直接偏好优化（DPO）的令牌选择方法，通过训练一个 oracle 模型在目标数据上估计一个令牌级奖励函数。这种方法适用于任何具有响应级注释的现有对齐数据集，并能够通过小规模的 oracle 模型和训练数据实现成本低廉的令牌选择。估计的奖励函数用于对目标数据集中的所有令牌进行评分，仅选择关键令牌来监督目标策略模型。", "conclusion": "广泛的实验表明，SePO 在只优化目标数据集上 30% 的关键令牌的情况下，显著优于具有竞争力的基线方法。在弱至强泛化方面的应用表明，弱 oracle 模型可以有效监督参数多 16.8 倍的强策略模型。此外，SePO 也能够在异构数据中有效选择关键令牌，以增强强策略模型并缓解过度优化问题。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.12929", "html_url": "https://arxiv.org/abs/2409.12929", "title": "LogicPro: 通过程序引导学习提高复杂逻辑推理能力", "title_en": "LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning", "authors": "Jin Jiang,Yuchen Yan,Yang Liu,Jianing Wang,Shuai Peng,Xunliang Cai,Yixin Cao,Mengdi Zhang,Liangcai Gao", "background": "本文的背景在于当前复杂逻辑推理数据集存在难以大规模生成、验证困难以及缺乏标准答案等问题，现有的数据集难以满足模型训练和测试的需求。", "innovation": "本文提出了一种名为LogicPro的新数据合成方法，该方法利用LeetCode风格的算法问题及其对应的程序解决方案来合成文本形式的复杂逻辑推理数据。该方法通过合成复杂推理问题、获取标准答案和中间变量输出、并利用代码中间变量合成推理过程。这种方法生成的数据具有难于生成、可扩展性强、有效的特点，并附带高质量的标准答案和推理过程。", "conclusion": "实验结果显示，使用540K从2,360个算法问题合成的数据集，本文的方法在BBH、LogicBench、DROP、AR-LSAT和GSM8K等多个数据集上显著提升了多个模型的表现，优于多种现有的逻辑推理数据集。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.19835", "html_url": "https://arxiv.org/abs/2407.19835", "title": "ATHAR：用于古典阿拉伯语到英语翻译的高质量和多样化数据集", "title_en": "ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation", "authors": "Mohammed Khalil,Mohammed Sabry", "background": "古典阿拉伯语代表阿拉伯文化和哲学的黄金时代，翻译这些文献以丰富知识传播具有重要意义。然而，当前缺乏针对古典阿拉伯语的高质量翻译数据集，这些数据集范围有限且内容覆盖面窄，阻碍了高质量翻译系统的开发。尤其是在大型语言模型（LLMs）的推动下，迫切需要此类数据集来改善翻译系统的效果", "innovation": "本文提出了ATHAR数据集，包含了66,000个高质量的古典阿拉伯语到英语的翻译样本，覆盖了广泛的主题，包括科学、文化和哲学等。此外，该研究评估了当前最先进的LLMs在不同设置下的性能，并指出这些模型可以从微调或预训练中受益。该数据集已公开发布在HuggingFace Data Hub上: this https URL", "conclusion": "ATHAR数据集为古典阿拉伯语翻译提供了基础，可以帮助现有系统改进质量，尤其是通过模型的微调或预训练过程，显示出该数据集在未来翻译研究和开发中的重要性"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.19858", "html_url": "https://arxiv.org/abs/2411.19858", "title": "近五十年语文学与人工智能研究：科学计量分析的启示", "title_en": "What fifty-one years of Linguistics and Artificial Intelligence research tell us about their correlation: A scientometric analysis", "authors": "Mohammed Q. Shormani,Yehia A. AlSohbani", "background": "语言学与人工智能之间的关联非常紧密，尤其是在深度学习语言模型方面表现得尤为明显。本研究对这一关联进行了全面的科学计量分析，梳理了1974年至2024年间共51年的学术生产情况，采用了Web of Science Core Collection数据库作为数据来源。研究使用了CiteSpace和VOSviewer两种软件，生成了知识景观、热点问题和新兴热点的可视化图谱。", "innovation": "该研究采用了科学计量分析方法，综合利用CiteSpace和VOSviewer两套强大的软件工具，对自1974年以来的语言学与人工智能之间的关系进行了全面分析，揭示了这一领域研究的演进趋势和新兴热点。", "conclusion": "从1980年代和1990年代的不稳研究状态开始，语言学与人工智能的研究随着深度学习的发展，特别是自然语言处理、双向编码表示和ChatGPT等技术的应用，取得了显著的增长。研究结出了在多个层面上——包括研究机构、期刊和国家——建立的语文学与人工智能关系，对知识生产产生了影响，并重新定义了未来的研究前沿。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2401.14295", "html_url": "https://arxiv.org/abs/2401.14295", "title": "揭开思维链、思维树和思维图的神秘面纱", "title_en": "Demystifying Chains, Trees, and Graphs of Thoughts", "authors": "Maciej Besta,Florim Memedi,Zhenyu Zhang,Robert Gerstenberger,Guangyuan Piao,Nils Blach,Piotr Nyczyk,Marcin Copik,Grzegorz Kwaśniewski,Jürgen Müller,Lukas Gianinazzi,Ales Kubicek,Hubert Niewiadomski,Aidan O'Mahony,Onur Mutlu,Torsten Hoefler", "background": "自然语言处理（NLP）领域近年来取得了显著的进步，特别是通过创新的提示技术提高了大型语言模型（LLM）的表现。在此背景下，结合结构的提示工程成为了一个有前景的范式，如Chain-of-Thought、Tree of Thoughts或Graph of Thoughts等设计，它们通过结构例如图来指导整体的LLM推理过程。这一范式显著增强了LLM解决各种任务的能力，从逻辑或数学推理到计划或创意写作等。本文旨在深入了解这一领域，并为进一步发展铺平道路，分析了提示执行管道，明确了不同概念，并构建了结构增强型LLM推理方案的第一份分类学。本文还比较了已有的提示方案，讨论了某些设计选择如何导致性能和成本的不同模式。", "innovation": "本文发明或提出了一种总的蓝图，用于设计有效且高效的LLM推理方案。通过提出一种新的分类方法，对已有的结构增强型LLM推理方案进行了系统性的比较分析，深入研究了被利用的结构类型、这些结构的表示方式以及与之执行的算法等。此外，还探讨了提示与大型语言模型生态系统中的其他部分，如知识库之间的关系，以及相关研究挑战。这种方法与现有方案的对比分析将帮助促进未来提示工程技术的发展。", "conclusion": "本文通过对现有的提示方案进行全面的比较分析，揭示了设计选择与性能和成本之间的关系，并提供了结构增强型LLM推理方案的第一份分类学，希望能为未来的提示工程技术的进步奠定基础。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04897", "html_url": "https://arxiv.org/abs/2509.04897", "title": "PLaMo 2 技术报告", "title_en": "PLaMo 2 Technical Report", "authors": "Preferred Networks:Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu", "background": "当前大型语言模型（LLM）领域的一个主要挑战是数据稀疏性以及计算效率问题。为了克服这些挑战，研究人员引入了PLaMo 2，这是一个基于Hybrid Samba架构的日语专用大模型系列，通过连续预训练支持32K token长度的上下文。", "innovation": "PLaMo 2 的创新之处在于其混合Samba架构，能够逐步过渡到全注意力机制；通过利用大量合成语料库进行训练，克服了数据稀疏性；通过权重重用和结构化剪枝提高了计算效率，生成了一个8B参数的高效模型，其性能与100B参数的上一代模型相当。此外，通过细粒度微调和直接偏好优化提升了模型的性能，并利用合成日语指令数据和模型合并技术进一步优化。", "conclusion": "经过优化，PLaMo 2 模型在推理过程中的性能达到了最佳状态，利用 vLLM 和最少的准确率损失进行了量化。该系列模型在日语基准测试中表现出色，特别是在指令遵循、语言流畅性和日语特定知识方面，优于同等规模的开源模型。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.05276", "html_url": "https://arxiv.org/abs/2509.05276", "title": "SpikingBrain的技术报告：受大脑启发的大规模模型", "title_en": "SpikingBrain Technical Report: Spiking Brain-inspired Large Models", "authors": "Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li", "background": "主流的基于Transformer的大规模语言模型面临效率瓶颈：训练计算量随着序列长度呈二次增长，推理内存呈线性增长，限制了长上下文处理。在非NVIDIA平台上构建大规模模型也带来了稳定和高效训练的挑战。", "innovation": "提出了SpikingBrain这一家族模型，旨在提高长上下文训练和推理的效率。SpikingBrain采用了启发自大脑的架构，包括线性和混合线性注意力体系结构及自适应脉冲神经元；算法优化包括高效的训练流水线和专有的脉冲编码框架；系统工程方面，则针对MetaX硬件定制了训练框架、操作库和并行策略。使用这些技术开发了两种模型：SpikingBrain-7B线性LLM和SpikingBrain-76B混合线性MoE LLM。这些模型在非NVIDIA平台上开发大规模语言模型的可行性得到了验证。", "conclusion": "SpikingBrain模拟了等同于开源Transformer基线的性能，但仅使用了约150亿个令牌进行持续预训练。模型显著提高了长序列训练效率，并实现了(部分)常量内存的推理和事件驱动的脉冲行为。例如，SpikingBrain-7B在4M令牌序列中实现了逾100倍的速度提升。在数百个MetaX C550 GPU上稳定性训练数周，7B模型达到了23.4%的模型FLOPs利用率。提出的脉冲方案实现了69.15%的稀疏度，支持低功耗操作。这一研究展示了大脑启发机制在下一代高效可扩展大规模模型设计中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12882", "html_url": "https://arxiv.org/abs/2504.12882", "title": "ViClaim：视频中多语言多标签自动断言检测数据集", "title_en": "ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos", "authors": "Patrick Giedemann,Pius von Däniken,Jan Deriu,Alvaro Rodrigo,Anselmo Peñas,Mark Cieliebak", "background": "随着视频内容作为沟通和信息错误渠道的影响日益增长，迫切需要有效的工具来分析多语言和多话题背景下的断言。现有的信息误导检测努力主要集中在书面文本上，忽略了视频转录中口头文本的复杂性。", "innovation": "介绍了ViClaim数据集，包含1,798个标注的跨语言（英语、德语、西班牙语）和跨话题的视频转录，每个句子标记为事实可查证、事实不可查证或观点中的三类之一。开发了专用的注释工具以简化复杂注释过程，展示了最先进的多语言语言模型在交叉验证中的强大性能，但揭示了在未见过的话题上泛化的挑战，特别是对于不同的领域。", "conclusion": "我们的研究突出了视频转录中断言检测的复杂性。ViClaim为视频沟通中的信息误导检测提供了坚实的基础，填补了多模态分析中的关键空白。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.06460", "html_url": "https://arxiv.org/abs/2504.06460", "title": "LLMs能否模拟逆向表现的人格？一种对抗性指示跟踪基准", "title_en": "Can LLMs Simulate Personas with Reversed Performance? A Benchmark for Counterfactual Instruction Following", "authors": "Sai Adith Senthil Kumar,Hao Yan,Saipavan Perepa,Murong Yue,Ziyu Yao", "background": "大型语言模型（LLMs）现在越来越多地被用于在虚拟环境中模拟人格，利用其指令执行能力。然而，我们发现即使是最先进的LLMs也无法模拟逆向表现的人格（例如，低素养的学生人格在教育场景中），这限制了模拟环境的多样性和实际应用。在本研究中，通过数学推理作为代表场景，我们提出了第一个用于评估LLMs模拟逆向表现人格基准数据集，即所谓的“反事实指令执行”。我们评估了开源和闭源LLMs在这种任务上的表现，发现包括OpenAI的o1推理模型在内的所有LLMs都难以准确执行反事实指令来模拟逆向表现的人格。混合模拟人格的性能级别和种族人口更进一步加剧了这一效果。这些结果彰显了反事实指令执行的挑战以及对进一步研究的需求。", "innovation": "提出了第一个用于评估LLMs模拟逆向表现人格的基准数据集，即“反事实指令执行”。评估了开源和闭源LLMs在这种任务上的表现。", "conclusion": "发现所有LLMs都难以准确执行反事实指令来模拟逆向表现的人格，混合模拟人格的性能级别和种族人口更是加剧了这一效果。这些结果彰显了反事实指令执行的挑战以及对进一步研究的需求。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16487", "html_url": "https://arxiv.org/abs/2502.16487", "title": "所有闪光的未必都是新颖的：AI生成研究中的抄袭", "title_en": "All That Glitters is Not Novel: Plagiarism in AI Generated Research", "authors": "Tarun Gupta,Danish Pruthi", "background": "自动化科学研究被认为是科学的最后前沿。近期，有几篇论文声称自主研究代理能够生成新颖的研究想法。尽管在乐观的氛围中，研究人员记录了一个严重的问题：许多此类研究文档是巧妙地抄袭的。以往的研究都是由专家评估研究想法的新颖性和可行性，而本研究则邀请了13位专家从不同的逻辑出发，识别AI生成的研究文档与现有工作的相似之处。专家们发现，24%的50份评估研究文档或完全抄袭，或借鉴了现有工作。这些发现经过了原始论文作者的交叉验证。其余76%的文档在不同程度上与现有工作相似，只有很少一部分完全新颖。更严重的是，这些由大语言模型（LLM）生成的研究文档没有承认原始来源，规避了内置的抄袭检测器。进一步的受控实验表明，现有的自动化抄袭检测器不擅长捕捉此类系统产生的抄袭想法。因此，需要谨慎评估由大语言模型生成的研究，并讨论这些发现对学术出版的影响。", "innovation": "本研究的创新在于，它引入了使用专家来识别由社会人文认知模型（LLMs）生成的研究文献与现有工作之间的相似性和抄袭行为的方法。这种方法不同于以往依赖专家评估研究想法的新颖性和可行性的方法。此外，该研究还通过控制实验来表明现有的自动化抄袭检测器在检测此类系统产生的抄袭想法方面的不足，并提出进一步改进措施的必要性。这一发现对于学术界的了解和发展AI生成研究文献具有重要影响。", "conclusion": "建议对由LLM生成的研究进行仔细评估，并讨论自己的发现对学术出版的影响。当前自动化抄袭检测工具在识别AI生成的抄袭研究方面可能不够充分，需要更深入的研究来提高检测工具的准确性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.18724", "html_url": "https://arxiv.org/abs/2501.18724", "title": "大规模语言模型具备时间推理解释的纵向临床总结和预测", "title_en": "Large Language Models with Temporal Reasoning for Longitudinal Clinical Summarization and Prediction", "authors": "Maya Kruse,Shiyue Hu,Nicholas Derby,Yifu Wu,Samantha Stonbraker,Bingsheng Yao,Dakuo Wang,Elizabeth Goldberg,Yanjun Gao", "background": "最近的大规模语言模型（LLMs）展示了在临床文本总结方面的潜力，但在处理具有时间跨度和跨时间分布多模态数据的长期患者轨迹方面的能力仍然未被充分开发和研究。这项研究系统地评估了多个最先进的开源LLMs及其检索增强生成（RAG）变体和带有链式思考（CoT）提示的模型在长期上下文临床总结和预测方面的表现。通过对现有的两个公开的电子健康记录（EHR）数据集的任务进行重新设计，以重新合成结构化和非结构化的EHR数据并进行时间连贯性的推理，以评估LLMs的性能。实验结果表明，较大的上下文窗口改善了输入整合，但并未在临床推理方面表现出一致性增强，并且LLMs仍然在时间进展和罕见疾病预测方面存在困难。尽管RAG在某些情况下提高了幻觉问题，但它并没有完全解决这些限制。这项研究填补了长期临床文本总结的空白，为评估具有多模态数据和时间推理能力的LLMs奠定了基础。", "innovation": "采用大量的语言模型及其检索增强生成和链式思考提示的模型在长期临床总结和预测的任务中，系统地评估其性能。并针对性地重新设计了两个现有的EHR数据集中的任务，以更好地评估模型的时间连贯性和多模态数据整合能力。", "conclusion": "较大的上下文窗口虽然增强了输入整合，但在临床推理方面并未一致地表现出优越性，模型在时间进展和罕见疾病预测方面依旧存在挑战。尽管RAG在某些情况下缓解了幻觉问题，但它未能完全解决这些问题。该研究在纵向临床总结和预测中填补了大规模语言模型评估的空白，并为其未来的改进提供了基础。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21934", "html_url": "https://arxiv.org/abs/2503.21934", "title": "Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad", "title_en": "Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad", "authors": "Ivo Petrov,Jasper Dekoninck,Lyuben Baltadzhiev,Maria Drencheva,Kristian Minchev,Mislav Balunović,Nikola Jovanović,Martin Vechev", "background": "近期数学基准测试表明，最先进的大型语言模型（LLMs）如MathArena在数学竞赛中的表现相当出色，例如美国邀请数学考试（AIME）。然而，大多数现有基准仅依据最终数值答案进行评价，忽视了严密推理和证明生成能力，这是实际数学任务中至关重要的能力。因此，研究团队引入了对具有挑战性的数学问题的全面推理评估，通过专家人类注释员对2025年美国数学奥林匹克（USAMO）的六道题进行快速评估，揭示了现有模型在这方面的局限性。", "innovation": "研究引入了对具有挑战性的数学问题的全面推理评估。使用专家人类注释员在六道2025年USAMO题目的发布后不久进行评估，评估了几种最先进的推理模型。结果显示，虽然某些模型如Gemini-2.5-Pro在推理生成方面有所进步，但其他模型表现不佳。进一步分析推理轨迹，指出了模型优化策略中常见的失败模式和不必要的副产品。这表明当前的LLMs在严谨的数学推理方面仍然不足，需要在推理和证明生成能力上有实质性的改进。", "conclusion": "综合研究结果表明，当前的LLMs在严谨的数学推理任务方面仍存在显著不足，指出了现有的瓶颈并提出了改进的方向。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19081", "html_url": "https://arxiv.org/abs/2507.19081", "title": "Arg-LLaDA：通过大型语言扩散模型和充分性感知改进进行论据总结", "title_en": "Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement", "authors": "Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic", "background": "论据总结的目标是生成复杂的多视角辩论的精炼、结构化的表示。尽管最近的工作已经提升了论据组件的识别和聚类，但生成阶段仍然未得到充分探索。现有方法通常依赖一次性的生成过程，这限制了事实修正或结构改进的可能性。因此，需要一种新的框架来提升这一点。", "innovation": "本文提出了Arg-LLaDA，这是一种新的大型语言扩散框架，通过逐步改进来提高摘要的质量，该方法通过支持有效性的重新遮盖和重新生成来逐步优化摘要。该方法结合了一个灵活的遮盖控制器和一个有效性检查模块，以识别并修订不支持、冗余或不完整的部分，从而产生更忠实、精炼且一致的输出。", "conclusion": "在两个基准数据集的实验结果表明，Arg-LLaDA 在 10 个自动评估指标中的 7 个中超越了最先进的基线。 additionally，人工评估显示，在核心维度、覆盖率、忠实性和简洁性方面均表现出显著的改进，这验证了我们迭代的、充分性感知的生成策略的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17114", "html_url": "https://arxiv.org/abs/2505.17114", "title": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "title_en": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "authors": "Subrata Biswas,Mohammad Nur Hossain Khan,Bashima Islam", "background": "多模态问答（QA）通常需要确定哪些视频、音频或传感器的标志符与问题相关。然而，模态间分歧普遍存在：背景对话、背景噪音或视场外的运动等常误导融合模型，这些模型将所有流等权重对待。现有方法通常存在对信息信号放大不足和对分散注意力信号抑制不够的问题，因此需要一种能够优先处理关键信息，抑制无关信息的架构。研究人员为此提出了RAVEN，一种统一的多模态问答架构，核心是条件化的跨模态门控模块QuART，可以跨模态赋予每个标志符标量的相关性评分，从而使模型在融合前能够放大有效信号并抑制干扰。RAVEN 通过三个阶段的训练流水线进行了训练：单模态预训练、查询对齐融合和分歧导向微调，每个阶段针对多模态推理中的不同挑战：表示质量、跨模态相关性和模态不匹配鲁棒性。为了支持训练和评估，研究者发布了AVS-QA数据集，包含30万条同步的音频-视频-传感器流，以及自动产生的问答对。由此，实验结果表明RAVEN在七个多模态问答基准测试上，与现有的多模态大型语言模型中的最佳模型相比，准确率分别提高了14.5%和8.0%，而结合传感器数据进一步提高了16.4%的准确率，同时在模态干扰下依然保持了鲁棒性，相比当前最佳基线性能提升了50.23%。研究者已将代码和数据集公开，可通过提供的链接访问。", "innovation": "RAVEN架构提出了一种条件化的跨模态门控模块QuART，能够赋予每个标志符标量的相关性评分，从而使模型在融合前能放大有效信号并抑制干扰因素；通过三个阶段的训练流水线解决了表示质量、跨模态相关性和模态不匹配鲁棒性等多模态推理中的不同挑战；提出了AVS-QA数据集，用于支持训练和评估多模态问答任务。", "conclusion": "实验结果显示，RAVEN在七个多模态问答基准测试中，分别与现有的多模态大型语言模型中的最佳模型相比提高了14.5%和8.0%的准确率；结合传感器数据后，准确率进一步提升了16.4%；且该模型在模态干扰条件下表现非常稳定，优于现有的最先进的基线模型50.23%。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14240", "html_url": "https://arxiv.org/abs/2507.14240", "title": "HuggingGraph：理解LLM生态系统的供应链", "title_en": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "authors": "Mohammad Shahedur Rahman,Peng Gao,Yuede Ji", "background": "大型语言模型（LLMs）利用深度学习架构处理和预测单词序列，能够执行翻译、摘要、问答和内容生成等多种自然语言处理任务。现有的LLMs通常基于基础模型或其他预训练模型，并使用外部数据集，这导致它们不可避免地会继承以前模型或数据集中存在的漏洞、偏见或恶意组件。因此，了解这些组件的来源及其发展过程对于检测潜在风险、提高模型公平性和确保遵守监管框架至关重要。", "innovation": "该项目提出了一种新的图模型，用于表示模型和数据集之间的关系，这是一个有向异质图，包含了402,654个节点和462,524条边。同时，设计了一种系统的方法来收集LLMs的供应链信息，并从多种角度进行了分析，发现了一些有趣的结果。", "conclusion": "通过HuggingGraph，我们能够系统地研究LLM生态系统中的模型和数据集之间的关系，有助于识别潜在的风险，提高模型公平性，并确保符合监管要求。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17450", "html_url": "https://arxiv.org/abs/2508.17450", "title": "LLMs的说服动态：基于DuET-PD探索在知识和安全方面稳健性和适应性", "title_en": "Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD", "authors": "Bryan Chen Zhengyu Tan,Daniel Wai Kit Chin,Zhengyuan Liu,Nancy F. Chen,Roy Ka-Wei Lee", "background": "大语言模型在说服对话中面临着平衡接受错误信息和抵抗有效纠正之间的挑战，这是可靠部署的关键难题。本研究通过引入DuET-PD框架，评估多轮说服立场变化的动力学，涉及两种维度：说服类型（纠正/误导）和领域（通过MMLU-Pro的知识，通过SALAD-Bench的安全）。研究发现，即使是最先进的模型如GPT-4o，在持续误导性说服下的MMLU-Pro准确性也仅达到27.32%。此外，研究结果揭示了一个令人担忧的趋势，即新版本开源模型中的奉承行为增加。为解决这个问题，我们提出了综合DPO（Holistic DPO，全面数据策略优化）培训方法，同时平衡正面和负面说服的示例，增强了模型对错误信息的抵抗力和对纠正建议的接受度，从而显著提高了Llama-3.1-8B-Instruct在误导性说服下的准确度从4.21%提升至76.54%。这些贡献为开发多轮对话中更可靠和适应性强的LLM提供了路径。", "innovation": "提出了DuET-PD框架，用于评估多轮说服立场变化的动力学，涉及两种维度：说服类型和领域。引入了Holistic DPO训练方法，通过平衡正面和负面说服的示例，解决了模型在持续误导性说服下抵抗错误信息和接受纠正的挑战，提高了模型的准确度。", "conclusion": "通过DuET-PD框架，研究展示了在知识和安全领域提高大语言模型的稳健性和适应性的方法。Holistic DPO训练方法和综合的评估框架提供了开发更可靠和适应性强的LLM的路径。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.08613", "html_url": "https://arxiv.org/abs/2501.08613", "title": "评估FOL相似度度量的敏感性和对齐性", "title_en": "Assessing the Sensitivity and Alignment of FOL Closeness Metrics", "authors": "Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi", "background": "近年来，工具增强的大语言模型（LLMs）在解决逻辑推理问题方面取得了成功，这主要是通过将自然语言（NL）陈述翻译成一阶逻辑（FOL）以及外部定理证明器。然而，由于缺乏可靠的评估指标来比较生成的FOL和真实值，FOL语句（包含操作符和文本）的正确性往往得不到验证。本文进行了全面研究，探讨现有基于NL、FOL和图的度量对捕捉采样FOL与相应真实值之间差异的敏感性。研究了这些度量与强LLM作为裁判的基于度量的FOL输出排名之间的对齐度。", "innovation": "本文创新之处在于通过应用操作符和文本扰动到真实FOL陈述，评估现有FOL相似度度量的敏感性和稳健性。实证结果显示BLEU n-gram指标对文本扰动过度敏感，Smatch++度量和FOL度量受操作符扰动影响较大，而BertScore与LLM评判更一致，显示了语义评估的重要性。此外，研究还发现结合使用度量可以提高度量的稳健性和敏感性，相比单一使用的度量更具优势。", "conclusion": "本文研究了现有FOL相似度度量的敏感性和对齐性，发现BLEU n-gram指标对文本扰动过度敏感，Smatch++度量和FOL度量受操作符扰动影响较大。BertScore与强LLM评判的对齐度更高，证明了语义评估的重要性。此外，结合使用多个度量可以提升度量的稳健性和敏感性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21509", "html_url": "https://arxiv.org/abs/2507.21509", "title": " Persona Vectors: 监控和控制语言模型中角色特质", "title_en": "Persona Vectors: Monitoring and Controlling Character Traits in Language Models", "authors": "Runjin Chen,Andy Arditi,Henry Sleight,Owain Evans,Jack Lindsey", "background": "大型语言模型通过模拟助理角色与用户交互。尽管助理通常被训练为友好、无害和诚实，但有时会偏离这些理想。本文探讨了模型激活空间中的persona向量，这些向量揭示了角色特质的变化，如邪恶、拍马屁和编造事实的倾向。研究确认了这些向量在模型部署时可以用来监测助理个性的变化，并应用于训练过程中预测和控制性格转变。研究发现，无论是意料之中的还是意外的性格变化，都与相关persona向量的变化高度相关。这些变化可以通过事后干预减弱，也可以通过一种新的预防性方法避免。此外，persona向量还可以用来标记会导致不良性格变化的训练数据，无论是从整体数据集还是个体样本层面来看。提取persona向量的方法是自动化的，只需要提供自然语言描述即可适用于任何感兴趣的角色特质。", "innovation": "本文提出了persona向量的概念，这些向量揭示了语言模型中角色特质的变化，包括邪恶、拍马屁和编造事实的倾向。研究通过人工干预和新预防性方法控制了角色转变，发现两种类型的转变都与相关向量的变化强烈相关。此外，这种向量方法可以帮助识别可能会导致不良性格变化的训练数据，而提取方法是自动化的。这些发现为监控和控制语言模型中的角色转变提供了新的工具和方法。", "conclusion": "研究证实了通过分析persona向量可以监测语言模型助理在部署时的个性变化，并在训练过程中预测和控制这些变化。通过后续干预或采用新的预防性方法，可以显著减少或避免这些变化。此外，未来的工作可以进一步优化提取persona向量的方法，并利用这些向量改进生成编造假信息的能力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.00461", "html_url": "https://arxiv.org/abs/2509.00461", "title": "TECP: Token-Entropy Conformal Prediction for LLMs", "title_en": "TECP: Token-Entropy Conformal Prediction for LLMs", "authors": "Beining Xu,Yongming Lu", "background": "开放生成语言领域的不确定性量化（UQ）仍然是一项关键但尚未充分探索的挑战，尤其是在黑盒约束条件下，内部模型信号不可访问。现有的方法主要依赖于语义一致性启发式或白盒特征来估计不确定性，而未直接从样本生成的令牌熵结构中估计认识不确定性并进行校准以确保可靠性的传统方法存在局限性。", "innovation": "本文提出了一种新的框架Token-Entropy Conformal Prediction (TECP)，通过利用令牌级熵作为无logit、无参考的不确定性度量，并将其集成到分裂收敛预测（CP）管道中，以构建具有形式覆盖率保证的预测集。TECP直接从样本生成的令牌熵结构中估计认识不确定性，并通过CP分位数校准不确定性阈值以确保可验证的错误控制，相比于基于语义一致性的UQ方法，TECP提供了更为有效且可信赖的解决方案。", "conclusion": "实验结果表明，TECP能够稳定地实现一致的覆盖率并生成紧凑的预测集，优于先前的自我一致性基于的不确定性量化方法。本方法为在黑盒LLM设置中实现可信赖的生成提供了一种原理上有效且高效的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04111", "html_url": "https://arxiv.org/abs/2509.04111", "title": "MultiWikiQA: 多语言阅读理解基准在300多种语言中", "title_en": "MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages", "authors": "Dan Saattrup Smart", "background": "目前存在多种语言的阅读理解数据集，但涉及的语言种类有限。大多数数据集仅涵盖少数几种语言，难以全面评估跨语言模型在多种语言环境下的性能差异。因此，本研究旨在创建一个涵盖306种语言的阅读理解数据集，以更好地评估不同语言模型在多语言环境下的表现。", "innovation": "提出了一种新的阅读理解数据集——MultiWikiQA，涵盖了306种语言。其特点在于：1) 数据来源于维基百科文章，由大型语言模型（LLM）生成问题并从相应文章中提取答案，确保问题与答案的关联性；2) 通过人工众包评价30种语言上的问题流畅度，证明这些问题质量较高；3) 评估了多种不同规模的解码器和编码器模型，展示了基准测试的挑战性和不同语言之间的性能差距。", "conclusion": "该数据集和评估结果公开发布，旨在为研究者和开发人员提供一个全面的多语言阅读理解基准，以促进各种语言模型在不同语言环境下的性能评估和改进。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20201", "html_url": "https://arxiv.org/abs/2508.20201", "title": "多语言语言模型中的社会偏见：一项文献综述", "title_en": "Social Bias in Multilingual Language Models: A Survey", "authors": "Lance Calvin Lim Gamboa,Yue Feng,Mark Lee", "background": "预训练多语言模型在处理非英语文本时表现出的社会偏见与处理英语文本的模型相同。本文系统地分析了扩展到多语言和非英语语境中的偏见评估与缓解方法的研究。研究表明这些研究在语言多样性、文化意识以及评估指标和缓解技术的选择上各有侧重。这些调研揭示了领域内主要方法论设计选择中存在的缺陷，并记录了适应语言和文化偏见基准时遇到的常见问题及解决方案。这些发现指出了未来研究的方向，旨在增强多语言偏见文献的包容性、跨文化适宜性以及与最先进的自然语言处理（NLP）进展的契合度。", "innovation": "本文分析了多项研究表明了在处理非英语语境中的偏见评估和缓解措施的研究趋势，发现了在语言多样性、文化意识以及评价指标和缓解技术选择上的薄弱环节，并提供了改进建议，旨在提升多语言自然语言处理系统的偏见评估与缓解方法。", "conclusion": "未来的研究应该致力于增强多语言偏见文献的包容性、文化适宜性，并与最先进的NLP进展保持一致，这将有助于提升多语言模型的社会责任感和公平性。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.03352", "html_url": "https://arxiv.org/abs/2504.03352", "title": " StereoDetect：利用社会心理学基础正确检测刻板印象和反刻板印象", "title_en": "StereoDetect: Detecting Stereotypes and Anti-stereotypes the Correct Way Using Social Psychological Underpinnings", "authors": "Kaustubh Shivshankar Shejole,Pushpak Bhattacharyya", "background": "刻板印象被广泛认为对社会有害，因此对其检测至关重要。然而，当前研究主要集中在发现和评估刻板印象偏差上，这使得刻板印象研究仍处于起步阶段。本文揭示了许多研究未能明确区分刻板印象和刻板印象偏差，影响了该领域的进展。刻板印象及其反刻板印象的检测需要社会知识，是负责任的人工智能中最难解决的问题之一。这项工作旨在探讨这种任务，提出了一种五元组定义，并提供了明确的术语来区分刻板印象、反刻板印象、刻板印象偏差和一般偏差。通过基于社会心理学的概念框架，建立了可靠的检测方法。同时，我们指出了当前用于刻板印象和反刻板印象检测基准的关键不足，并开发了 StereoDetect，这是一个定义明确且编排良好的基准数据集，能够解决这些缺口。特别指出的是，百亿参数量以下的语言模型和GPT-4o常见地错误分类反刻板印象，并未能识别中性的过度泛化。通过多个定性和定量比较，我们展示了 StereoDetect 的有效性，这些数据集和代码可以在相应链接中获得，用于刻板印象和反刻板印象任务的检测和评估。", "innovation": "该工作提出了一种五元组定义来明确区分刻板印象、反刻板印象、刻板印象偏差和一般偏差；基于社会心理学提供了可靠的检测框架；开发了 StereoDetect，一个定义明确、编排良好的基准数据集，用于刻板印象和反刻板印象检测；展示了语言模型在检测反刻板印象和中性过度泛化方面的不足，强调了 StereoDetect 的有效性。", "conclusion": "提出的方法提供了检测刻板印象和反刻板印象的有效手段，通过 StereoDetect 基准数据集和相关模型的比较，证实了现有模型在一些关键方面存在的不足，并为未来的研究工作提供了新的方向和数据支持。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21445", "html_url": "https://arxiv.org/abs/2506.21445", "title": "跨语言的Text2Cypher：评估与微调大语言模型", "title_en": "Text2Cypher Across Languages: Evaluating and Finetuning LLMs", "authors": "Makbule Gulcin Ozsoy,William Tai", "background": "近期，大型语言模型的进步使自然语言界面能够将用户问题转换成数据库查询，如Text2SQL、Text2SPARQL和Text2Cypher。虽然这些界面提升了数据库的可访问性，但当前大多数研究集中于英文，而其他语言的表现则较少受到评估关注。本论文专注于Text2Cypher任务，并研究了多种语言基础模型和微调模型的性能，通过将英文问题翻译成西班牙语和土耳其语来构建多语言数据集，实现了跨语言公平比较。研究发现，这些模型在不同语言上的表现存在一致性模式：最佳为英语，其次是西班牙语，最差为土耳其语。这种差距被认为是由训练数据的可用性和语言特征的差异造成的。实验还展示了将任务提示翻译为西班牙语和土耳其语对评估指标的影响，结果表明这种翻译几乎没有影响。此外，还对基础模型进行了多语言微调和仅英语微调，并发现多语言微调更能平衡不同语言的性能差异，从而提升整体系统的包容性和鲁棒性。", "innovation": "构建了多语言数据集来评估Text2Cypher任务在多种语言上的性能，并发现多语言微调能有效改善不同语言之间的性能差距，从而提升系统的包容性和鲁棒性。", "conclusion": "研究结果强调了跨语言评估和多语言训练的重要性，以此构建更具包容性和鲁棒性的查询生成系统。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22809", "html_url": "https://arxiv.org/abs/2505.22809", "title": "朝向旁听式LLM代理的第一步：以龙与地下城游戏为例的研究", "title_en": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "authors": "Andrew Zhu,Evan Osgood,Chris Callison-Burch", "background": "已经有许多关于直接辅助人类用户的对话型大规模语言模型代理的研究工作。本文则提出了一种与LLM代理互动的新范式，称之为“旁听代理”。这类代理不积极介入对话，而是旁听人类间的对话，进行后台任务或提供建议，以辅助用户。研究者通过龙与地下城游戏这一情境，深入探讨了旁听代理的范式，并使用大型多模态音频-语言模型作为旁听代理来辅助游戏主持人。研究通过人类评估发现，某些大型多模态音频模型能够利用隐含的音频提示来执行旁听代理任务。最后，研究者提供Python库和项目代码，以便进一步研究旁听代理范式，并通过链接提供下载地址：this https URL", "innovation": "提出了一种新的与LLM代理互动的方式——称之为“旁听代理”。这种方式不同于传统代理直接参与对话，而是聆听人类间的对话，并在后台执行任务或提供建议。研究者还通过龙与地下城游戏这一特定情境，进行了深入的实际应用研究，使用大型多模态音频-语言模型作为旁听代理。此外，通过人类评估发现某些模型具备了通过隐含音频提示执行任务的能力，并公开了支持进一步研究的Python库和项目代码", "conclusion": "本文通过龙与地下城游戏这一具体情境，深入探讨了旁听代理范式，并通过人类评估发现某些多模态音频模型具备执行旁听任务的潜力。研究还提供了Python库和项目代码以支持后续研究。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05528", "html_url": "https://arxiv.org/abs/2507.05528", "title": "大规模对话教育：跨领域程序性学习和教学质量评估的多大型语言模型代理工作流", "title_en": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "authors": "Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang", "background": "现有的大规模语言模型（LLMs）在虚拟教育和学习中取得了进步，促进了自然语言处理（NLP）与教育AI的结合。然而，现有研究往往缺乏可扩展性，并且无法充分利用各种大规模课程内容，且在评估教学质量方面缺乏框架。", "innovation": "本文提出了WikiHowAgent，这是一种利用LLMs的多代理工作流，模拟互动的教学-学习对话，集成了教师和学习者代理、互动管理器以及评估器，以促进程序性学习并评估教学质量。引入了涵盖14,287个教程、17个领域和727个主题的114,296条师生对话数据集，采用结合计算和基于评分表的评估方法与人工判断一致性的评估协议。", "conclusion": "研究结果表明工作流在多种场景下都有效，提供了对LLM在各领域中的能力的见解。该数据集和实现完全开源。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07236", "html_url": "https://arxiv.org/abs/2507.07236", "title": "简单而有效的信息论方法：多大语言模型不确定性量化", "title_en": "Simple Yet Effective: An Information-Theoretic Approach to Multi-LLM Uncertainty Quantification", "authors": "Maya Kruse,Majid Afshar,Saksham Khatwani,Anoop Mayampurath,Guanhua Chen,Yanjun Gao", "background": "大语言模型（LLMs）在不同输入上的行为常常是不一致的，这表明它们存在不确定性和在高风险场景下需要进行不确定性量化的必要性。现有工作往往专注于个别模型的校准和不确定性量化，忽视了模型多样性的重要性。", "innovation": "研究提出了MUSE（基于子集ensemble的多LLM不确定性量化），这是一种简单的信息论方法，使用Jensen-Shannon散度来识别和聚合具有良好校准的LLM子集。此外，研究探索了使用MUSE作为引导信号通过链式思维蒸馏微调LLM以实现校准。", "conclusion": "实验表明，MUSE在二元预测任务上的校准和预测性能优于单模型和简单的ensemble基线。研究结果表明，通过使用MUSE作为引导信号，可以改进LLM的校准和性能。MUSE方法已在GitHub上提供。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02544", "html_url": "https://arxiv.org/abs/2509.02544", "title": "UI-TARS-2 技术报告：利用多轮强化学习推进图形用户界面代理", "title_en": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "authors": "Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Aoyan Li,Bo Li,Chen Dun,Chong Liu,Daoguang Zan,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Shulin Xin,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qi Liu,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Yaohui Wang,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Qihua Han,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du", "background": "自主代理在图形用户界面（GUI）中的开发提出了重大挑战。虽然最近的进步通过端到端学习统一了感知、推理、行动和记忆的原生代理模型显示了希望，但仍存在数据可扩展性、多轮次强化学习（RL）、仅限GUI操作的限制以及环境稳定性等问题。", "innovation": "UI-TARS-2 通过系统化的训练方法解决了这些问题，包括用于生成数据飞轮的规模化数据生成、稳定化的多轮次RL框架、将文件系统和终端集成的混合GUI环境以及大规模沙盒平台。在GUI基准中的实证评估表明，UI-TARS-2 在多个基准任务中取得了显著的性能提升，优于其前身 UI-TARS-1.5，并且在游戏环境中也表现出了竞争力。", "conclusion": "这些结果强调了UI-TARS-2 在推进图形用户界面代理状态方面的潜力，并展示了其在各种代理任务中的强大泛化能力。详细的训练动力学分析进一步提供了实现大型代理RL的稳定性和效率方面的见解。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20474", "html_url": "https://arxiv.org/abs/2507.20474", "title": "MountainLion: 一种基于多模态大语言模型的可解释和自适应金融交易代理系统", "title_en": "MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading", "authors": "Siyi Wu,Junqiao Wang,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Dexu Yu,Jinhao Wang,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi", "background": "加密货币交易是一个需要整合多种模态数据的复杂任务。传统的深度学习和强化学习方法通常需要大量的训练数据，并将不同的输入编码为数值表示，这往往会导致可解释性较差。近年来，基于大语言模型（LLM）的代理已经证明了处理多模态数据并支持复杂投资决策的能力。", "innovation": "提出了MountainLion，一个用于金融交易的多模态、多代理系统。MountainLion 结合了专门的 LLM 基础代理来解释金融数据并生成投资策略，能够处理文本新闻、蜡烛图和交易信号图，生成高质量的财务报告。同时支持通过数据驱动的用户交互和问答修改报告和投资建议，并通过中央反思模块分析历史交易信号和结果，不断优化决策过程。 MountainLion 系统能够在实时期货分析、总结并动态调整投资策略。", "conclusion": "实验结果证实，MountainLion能够系统地丰富技术价格触发器，加入宏观经济增长和资本流动信号，提供一个更易于解释的、更强大的和更实际的投资框架，从而提高回报并增强投资者的信心。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.18122", "html_url": "https://arxiv.org/abs/2410.18122", "title": "昨日的新闻：评估多维度离分布外泛化的 misinformation 检测模型基准", "title_en": "Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution Generalization of Misinformation Detection Models", "authors": "Ivo Verhoeven,Pushkar Mishra,Ekaterina Shutova", "background": "misinfo-general 是一个基准数据集，用于评估 misinformation 模型在分布外（OOD）泛化方面的性能。由于 misinformation 的变化速度快于标注员标注的速度，导致训练数据和推理数据分布发生变化。现有的 misinformation 检测器缺乏分布外泛化的能力。本文通过远程标注的方法模拟 misinformation 内容的边际变化，并识别了时间、事件、主题、出版者、政治倾向、misinformation 类型等关键维度。", "innovation": "提出了一个名为 misinfo-general 的数据集，旨在评估 misinformation 模型的分布外泛化性能。数据集通过远程标注方法模拟了 misinfo 内容的变化，并且识别了时间、事件、主题、出版者、政治倾向、misinformation 类型等维度。这些模型在常见基准模型的基础上进行评估，展示了用文章元数据如何无法满足期望标准，依靠分类指标无法完全发现模型的不足之处。此外，还分析了数据的特性以确保没有模型捷径的存在。", "conclusion": "本研究通过 misinfo-general 数据集评估了 misinformation 检测模型的多维度分布外泛化能力，并通过元数据表明，简单的分类指标可能无法揭示模型的全部问题。同时，保证了数据集的分析方法去除了模型捷径的可能性。研究结果表明，当前的 misinformation 检测模型仍需改进以更好地处理分布外泛化的任务。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20312", "html_url": "https://arxiv.org/abs/2508.20312", "title": "ELIXIR: 效率高且轻量化的解释推荐模型", "title_en": "ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations", "authors": "Ben Kabongo,Vincent Guigue,Pirmin Lemberger", "background": "协同过滤驱动了许多成功的推荐系统，但在处理细粒度用户-物品交互和解释性方面存在困难。随着用户对透明推荐需求的增加，通过语言模型生成文本解释已成为关键研究领域。现有方法主要采用循环神经网络（RNNs）或Transformer。然而，基于RNN的方法未能利用预训练Transformer模型的能力，而基于Transformer的方法往往适应性不足且忽视方面建模，这是生成个性化解释的关键。", "innovation": "我们提出了ELIXIR（Efficient and Lightweight model for Explaining Recommendations），这是一种结合评分预测和个人化评论生成的多任务模型。ELIXIR联合学习用户和项目的全局及方面特定表示，同时优化整体评分、方面评分和评论生成，通过个性化注意力机制强调方面的重要性。基于T5-small（60M）模型，我们的方面导向的架构在个性化背景下引导文本生成的效果优于基于更大模型的状态-of-the-art方法。实验结果表明，ELIXIR在TripAdvisor和RateBeer上的表现显著优于强基准模型，特别是在评论生成方面。", "conclusion": "ELIXIR显著提高了评论生成的性能，展示了其在生成个性化和解释性推荐中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "大型语言模型（LLMs）虽然表现出色，但在不同应用场景下的输出质量不够稳定，特别是在需要多步推理的复杂任务中很难识别出可靠的响应。为此，本文探讨了如何通过引入Token-level Uncertainty estimation框架帮助LLMs自我评估并改进他们在数学推理任务中的生成质量.", "innovation": "本文提出了一种Token-level Uncertainty estimation框架（TokUR），通过引入低秩随机权重扰动到解码过程，生成预测分布来估计Token-level不确定性，并通过汇总这些不确定性反映生成序列的语义不确定性。此外，本文还探索了利用不确定性直接提升模型推理性能的方法，并通过多次生成和粒子滤波算法进行实验验证。实验结果表明，这种不确定性估计算法在现有方法中表现更优，能够有效评估和提高LLMs在推理生成中的表现.", "conclusion": "我们的方法在数学推理数据集上的实验结果表明，Token-level不确定性指标与答案正确性和模型鲁棒性之间有着很强的相关性。此外，通过使用不确定性直接提升模型的推理性能，我们的方法在多个生成和粒子滤波算法中表现出持续的优势，证实了有效不确定性估计算法在评价和提升LLMs推理生成中的工具价值."}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.00030", "html_url": "https://arxiv.org/abs/2509.00030", "title": "MultiStream-LLM: 融合模态以实现稳健的手语翻译", "title_en": "MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation", "authors": "Marshall Thomas,Edward Fish,Richard Bowden", "background": "尽管在手语翻译（SLT）方面取得了一定进展，但单一的端到端模型在精确识别高速手语拼写和整合非手动面部线索方面始终表现不佳。自动手语翻译使用大型语言模型的最新进展绕过了这一挑战，使得单一网络需要同时学习这些任务，导致对于重要信息如人名、地名和技术术语的翻译效果不佳。", "innovation": "我们提出了MultiStream-LLM，这是一种模块化框架，通过分别针对连续手语、手语拼写和唇读识别的具体模态，解决了这些限制。每个专家网络首先将特定的模态解码成一系列令牌，然后通过轻量级变压器合并这些并行流以解决时间对准问题，最终将结合的表示传递给大型语言模型进行最终句子生成。该方法在How2Sign基准测试中取得了新的最佳状态，BLEU-4得分为23.5，并在具有挑战性的ChicagoFSWildPlus手语拼写数据集上达到了73.2%的字母准确率。这些结果验证了我们的核心假设：通过在融合之前隔离并解决不同的识别任务，我们的多专家方法提供了一种更强大和有效的途径，实现鲁棒且高保真的手语翻译。", "conclusion": "我们的方法在How2Sign基准上取得了新的最佳状态（BLEU-4得分23.5），并在具有挑战性的ChicagoFSWildPlus手语拼写数据集上达到了73.2%的字母准确率。这些结果验证了我们的核心假设：通过在融合之前隔离并解决不同的识别任务，我们的多专家方法提供了一种更强大和有效的途径，实现鲁棒且高保真的手语翻译。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04545", "html_url": "https://arxiv.org/abs/2509.04545", "title": "PromptEnhancer：通过链式思维提示重写提高文本到图像模型的一种简单方法", "title_en": "PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting", "authors": "Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu", "background": "近期文本到图像（T2I）扩散模型展示了生成高保真度图像的强大能力。然而，这些模型往往难以准确渲染复杂的用户提示，特别是在属性绑定、否定和组合关系等方面，这导致了用户意图与生成输出之间的显著不匹配。", "innovation": "本文提出了一种新颖的通用提示重写框架——PromptEnhancer，不需要对任何预训练的T2I模型进行权重修改，就能增强这些模型的功能。不同于依赖于特定模型微调或隐式奖励信号的方法，PromptEnhancer通过强化学习训练一个链式思维（CoT）重写器，该重写器由一种名为AlignEvaluator的专门奖励模型进行指导。AlignEvaluator用于提供基于24个关键点系统分类的显式和精细反馈，这些关键点是通过对T2I常见失败模式的全面分析得出的。通过优化CoT重写器以最大化来自AlignEvaluator的奖励，框架学会生成更能被T2I模型精确理解的提示。实验表明，PromptEnhancer在多种语义和组合挑战下提高了图像文本对齐的效果。", "conclusion": "在HunyuanImage 2.1模型上的实验表明，PromptEnhancer能够显著提高图像文本对齐效果。此外，文章还提出了一个新的人类偏好基准，旨在促进未来在这个方向上的研究。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04602", "html_url": "https://arxiv.org/abs/2509.04602", "title": "Sali4Vid: 意义感知的视频重权与自适应caption检索用于密集视频caption", "title_en": "Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning", "authors": "MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim", "background": "密集视频captioning的目标是在视频中定位事件并在每个事件生成相应的描述。尽管最近的研究提出了一种端到端模型，但它们存在两个局限性：1）仅对文字使用时间戳监督，而将所有视频帧同等对待，2）从固定大小的视频片段中检索caption，忽略了场景过渡。", "innovation": "Sali4Vid 提出了一种简单而有效的意义感知框架，包括意义感知视频重权，将其时间戳注释转换为基于Sigmoid的帧重要性权重，并提出语义自适应caption检索，通过帧相似性将视频段分为不同的部分，以捕捉场景过渡，改善caption检索。", "conclusion": "Sali4Vid 在YouCook2和ViTT上的结果显示，结合改进视频权重和检索可促进密集视频captioning。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM个性错觉：揭示LLMs自我报告与行为之间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质在人类行为预测方面已有长时间的研究。近期大语言模型（LLMs）的发展表明，类似的人格模式可能在人工系统中也存在，高阶LLMs表现出类似于人类特质（如亲和性和自我调节）的稳定行为倾向。然而，先前的研究主要依赖于简化自我报告和启发式提示，缺乏行为验证。本文系统地从三个维度研究了LLM的人格特质：（1）性格特征随训练阶段动态出现和演变；（2）自我报告性格在行为任务中的预测效度；（3）特定干预措施（如人物注入）对自我报告和行为的影响。研究发现，指令对齐（如RLHF、指令微调）显著稳定了性格表达并增强了性格间的联系，使之类似于人类数据。然而，自我报告的性格并不能可靠地预测行为，观察到的关联往往与人类模式不同。尽管人物注入能够成功引导自我报告的方向，但它对实际行为的影响不大或不一致。这些发现区分了表面的性格特征表达与行为一致性，挑战了关于LLM特质的假设，并强调了在对齐和解释性评估方面的深入研究需求。", "innovation": "本研究首次从三个维度系统地研究了大语言模型的人格特质，包括性格特征在训练过程中的动态变化、自我报告在行为任务中的预测效度以及特定干预措施对自我报告和行为的影响。研究发现，指令对齐显著稳定了性格表达，增强了性格间的联系，但自我报告的人格与实际行为之间存在分离，人物注入虽然改变了自我报告，但对实际行为影响有限。这一研究为进一步深入评估LLM的对齐和解释性提供了新的视角。", "conclusion": "指令对齐显著稳定了大语言模型的性格表达和增强了性格间的联系，但这些自我报告的人格特质未能可靠预测行为，实际行为与自我报告之间存在分离。人物注入成功的引导了自我报告但对实际行为的影响有限或不一致。因此，区分表面的人物特质表达与行为一致性是评估LLM重要性的一个关键点，未来的研究需要更深入地评估对齐和解释性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04490", "html_url": "https://arxiv.org/abs/2509.04490", "title": "在自动驾驶中，面部情绪识别无法检测到不安全感受", "title_en": "Facial Emotion Recognition does not detect feeling unsafe in automated driving", "authors": "Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee", "background": "信任和感知的安全感在公众接受自动驾驶汽车中起着关键作用。为了了解感知风险，研究人员使用驾驶模拟器进行了实验，通过对比两种自动驾驶风格，并引入过马路的行人，收集了32名参与者的数据。参与者数据包括持续的主观舒适度评分、运动数据、面部表情、皮肤电导和心率以及眼动追踪。研究表明，动态驾驶风格引发的不适比平静驾驶风格更强。过马路的行人对平静驾驶风格的不适没有显著影响，但对动态驾驶风格的不适度造成了更大的降低。这对于风险感知的重要性具有说明意义。面部表情识别尽管对24名参与者成功分析，但大多数人（15/24）在关键时刻没有表现出可识别的面部反应。在检测到反应的9名参与者中，8人表现出“开心”表情，仅有4人表现出“惊讶”表情，恐惧从来没有主导。这表明面部表情识别不是评估自动驾驶中感知风险的可靠方法。为了预测感知风险，研究人员构建了一个基于车辆运动和皮肤电导的神经网络模型。该模型与报告的感知风险相关性良好，表明其在自动驾驶中进行客观评估的潜力，并指出未来研究的方向。", "innovation": "研究创新在于通过驾驶模拟器实验，对比两种驾驶风格对不适和感知风险的影响，并利用神经网络模型预测感知风险，表明面部表情识别在评估感知风险方面的局限性。", "conclusion": "感知风险和安全性对公众接受自动驾驶汽车至关重要。动态驾驶风格引起更大不适，而过马路的行人对这种影响不大。面部表情识别不是评估感知风险的有效方法。研究通过神经网络模型预测感知风险，展示了其潜在优势，但仍需更多研究以改进和验证。"}
{"llm_update_time": "20250909", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01249", "html_url": "https://arxiv.org/abs/2508.01249", "title": "AgentArmor：在防护对抗提示注入时对代理运行时跟踪实施程序分析", "title_en": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection", "authors": "Peiran Wang,Yang Liu,Yunfei Lu,Yifeng Cai,Hongbo Chen,Qingyou Yang,Jie Zhang,Jue Hong,Ye Wu", "background": "大型语言模型（LLM）代理通过结合自然语言推理和外部工具的执行来解决各种问题，但它们动态和不透明的行为引入了关键的安全风险，尤其是在存在提示注入攻击的情况下。因此，需要一种新的方法来分析和保护代理行为以防止潜在的安全威胁。", "innovation": "本文提出了一种名为AgentArmor的新颖框架，将代理的运行时踪迹视为具有可分析语义的结构化程序。AgentArmor通过构建器将代理踪迹转化为基于图的中间表示，包括控制流图（CFG）、数据流图（DFG）和程序依赖图（PDG），并通过类型系统实施安全策略。AgentArmor包括三个关键组件：图构建器、属性注册表和类型系统，实现对敏感数据流、信任边界和政策违规的程序分析，降低对抗提示注入的风险。", "conclusion": "我们在AgentDojo基准上评估了AgentArmor，结果显示它可以将攻击成功率达到3%，同时仅降低1%的功能性（utility）下降。这表明AgentArmor能够有效减少代理运行时攻击的成功率，同时保持较高的功能性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04597", "html_url": "https://arxiv.org/abs/2509.04597", "title": "DisPatch: 使用扩散模型在对象检测中消除对抗性贴片", "title_en": "DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models", "authors": "Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng", "background": "对象检测在安全监控和视频分析等实际应用中至关重要。尽管目前先进的对象检测器在这方面取得了进展，但它们仍然容易受到对抗性贴片攻击的影响。对抗性贴片可以很容易地应用于现实中的物体，以隐藏真实物品或创建不存在的物品，导致严重的后果。面对当前多样化的对抗性贴片攻击和潜在的未知威胁，理想的防御方法应该是有效的、通用的，并且对适应性攻击具有鲁棒性。", "innovation": "本文提出了DISPATCH，一种基于扩散模型的第一个对抗性贴片防御框架。DISPATCH采用了一种“再生和纠正”的策略，不同于之前的方法试图“检测和移除”对抗性贴片，它利用生成模型来消除攻击效果，同时保留输入图像的完整性。具体而言，DISPATCH利用扩散模型的内在生成能力重新生成整个图像，并将其与良性数据对齐。随后使用纠正过程来识别和替换对抗性区域，用它们的良性对应物替换。DISPATCH对所有类型的攻击是无偏见的，并且不需要关于现有贴片的任何先验知识。广泛的实验表明，DISPATCH在隐藏攻击和创建攻击方面都优于最先进的防御方法，对隐藏攻击实现最好的整体mAP.5得分为89.3%，对未目标创建攻击的成功率降低至24.8%。此外，它还对适应性攻击具有强大的鲁棒性，使其成为对象检测系统的一种实用可靠的防御手段。", "conclusion": "DISPATCH在多种检测器和攻击下的广泛实验表明，它在隐藏攻击方面实现了最好的整体mAP.5得分（89.3%），并且对未目标创建攻击的成功率降低至24.8%。此外，其对适应性攻击的鲁棒性使其成为对象检测系统的实用和可靠的防御方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04600", "html_url": "https://arxiv.org/abs/2509.04600", "title": "WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human", "title_en": "WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human", "authors": "Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng", "background": "全球野外单目视频中的人体动作重建在VR、图形和机器人应用中越来越受到需求，但需要精确地将人类姿态从摄像头坐标映射到世界坐标，这一任务受到深度模糊性、运动模糊性和摄像头与人体运动交织的挑战。尽管以人体运动为中心的方法在保留运动细节和物理合理性方面表现出色，但它们也存在两个关键局限：对摄像机方向信息利用不足和对摄像机平移线索整合不当。", "innovation": "我们提出了一个统一框架WATCH（World-aware Allied Trajectory and pose reconstruction for Camera and Human），以解决这两个挑战。WATCH方法引入了一种分析性方向角分解技术，与现有的几何方法相比，提供更高的效率和可扩展性。此外，我们设计了一种借鉴世界模型原理的摄像机轨迹整合机制，提供了一种有效途径来利用摄像机平移信息，超越了简单的硬解码方法。在野外基准测试上的实验结果证明，WATCH在端到端轨迹重建性能上达到了最先进的水平。这项工作证明了同时建模摄像头-人体运动关系的有效性，并为解决全球人体运动重建中长期存在的摄像机平移整合挑战提供了新的见解。", "conclusion": "我们的工作证明了同时建模摄像头-人体运动关系的有效性，并为解决全球人体运动重建中长期存在的摄像机平移整合挑战提供了新的见解。代码将公开提供。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04687", "html_url": "https://arxiv.org/abs/2509.04687", "title": "基于多代理修正的一致性标注分割", "title_en": "Guideline-Consistent Segmentation via Multi-Agent Refinement", "authors": "Vanshika Vats,Ashwani Rathee,James Davis", "background": "在现实世界的应用中，语义分割不仅要生成准确的掩膜，还需遵循复杂的文本标注规范。然而，这些规范往往非常复杂和冗长，人工和自动化标注常常难以严格遵守。传统方法依赖于昂贵的任务特定重训，而这一过程需随规范的变化反复进行。尽管最近的开放词汇分割方法在简单提示方面表现出色，但在面对包含段落描述的复杂分割规则时却常表现不佳。", "innovation": "本文提出了一种无需训练的多代理框架，通过迭代的工作员（Worker）-监督者（Supervisor）修正架构，利用通用的视觉-语言模型进行分割修正。该框架利用监督者根据检索到的规则对工人进行评价，通过轻量级的强化学习停止策略决定是否终止循环，从而确保分割结果的一致性，同时优化资源使用。", "conclusion": "该方法在Waymo和ReasonSeg数据集上的评估结果表明，相较于最先进的基线方法，其具有更强的泛化能力和指令遵循性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04711", "html_url": "https://arxiv.org/abs/2509.04711", "title": "不同传感器配置下3D物体检测的域适应", "title_en": "Domain Adaptation for Different Sensor Configurations in 3D Object Detection", "authors": "Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita", "background": "近年来，自动驾驶技术的进步凸显了准确3D物体检测的重要性，而激光雷达因其在不同能见度条件下的稳健性，在这一过程中扮演着重要角色。然而，不同的车辆平台往往使用不同的传感器配置，导致模型在不同配置之间迁移时性能下降。过往的研究主要关注环境域差距和单个激光雷达内密度变化的多数据集训练和域适应，而不同传感器配置之间的域差距尚未得到充分研究。", "innovation": "本文针对不同传感器配置下的3D物体检测的域适应问题，提出了两种技术：下游微调（多数据集训练后的数据集特定微调）和部分层微调（仅更新一个子集的层，以提高跨配置的一般性）。通过在相同地理区域内采集的多个传感器配置配对数据集，我们的研究表明，结合下游微调和部分层微调的联合训练在每个配置上都优于简单的联合训练。", "conclusion": "我们的研究结果提供了一种适用于不同车辆平台的3D物体检测模型适应的实用且可扩展的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04735", "html_url": "https://arxiv.org/abs/2509.04735", "title": "在恶劣天气条件下增强自动驾驶分割：SAM优化的双重不确定校准训练方法", "title_en": "Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization", "authors": "Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu", "background": "近期视觉基础模型的发展，如Segment Anything Model (SAM) 及其后继版本SAM2，在通用图像分割基准测试中取得了最先进的性能。然而，这些模型在恶劣天气条件下表现不佳，尤其是在高视觉模糊度的条件下，主要是由于它们缺乏不确定性量化能力。借鉴医学成像领域中不确定性意识训练提高了模糊情况下可靠性的进步，本文研究了两种增强自动驾驶分割鲁棒性的方法。", "innovation": "引入了SAM2的多步骤微调程序，直接将不确定性指标整合到损失函数中，以提高整体场景识别效果。此外，将最初为医学图像分割设计的不确定校准适配器（UAT）适应到驾驶场景中。分别在CamVid、BDD100K和GTA驾驶数据集上评估了这两种方法。实验表明，在极端天气条件下，UAT-SAM比标准SAM表现更好，而SAM2带有不确定性意识损失函数的方法在各种驾驶场景中也取得了更好的性能。", "conclusion": "研究结果强调了在挑战性环境下自主驾驶安全的关键性中明确不确定性建模的价值。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04729", "html_url": "https://arxiv.org/abs/2509.04729", "title": "CD-Mamba：基于长期空间依赖建模的云检测", "title_en": "CD-Mamba: Cloud detection with long-range spatial dependency modeling", "authors": "Tianxiang Xue,Jiayi Zhao,Jingsheng Li,Changlu Chen,Kun Zhan", "background": "遥感图像频繁受到云层遮挡的影响，这给数据完整性和可靠性带来了重大挑战。有效的云检测需要同时应对云块间的短范围空间冗余和长范围大气相似性。卷积神经网络可以捕捉局部空间依赖，而Mamba则在建模长期依赖方面表现出强大能力。为了充分结合局部空间关系和长期依赖，我们提出了一种名为CD-Mamba的混合模型，该模型将卷积和Mamba的状态空间建模整合到一个统一的云检测网络中。CD-Mamba的设计旨在全面捕捉像素级纹理细节和长期内部块依赖性，以此改善不同空间尺度上的检测准确性。", "innovation": "提出了一种结合卷积和Mamba状态空间建模的混合模型CD-Mamba，旨在同时捕捉像素级纹理细节和长期内部块依赖性，提高云检测的准确性。CD-Mamba能够处理同时的像素级互动和广泛的内部块依赖性，适用于多尺度空间检测，并且在广泛实验中证明了其优越性，超过了现有方法的性能。", "conclusion": "通过大量实验证明了CD-Mamba的有效性，并展示了其在云检测方面的出色性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04736", "html_url": "https://arxiv.org/abs/2509.04736", "title": "WatchHAR: 实时边缘设备人体活动识别系统", "title_en": "WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches", "authors": "Taeyoung Yeon,Vasco Xu,Henry Hoffmann,Karan Ahuja", "background": "尽管在实用和多模态细粒度人体活动识别（HAR）方面取得了进展，但在不受限环境中完全依赖智能手表运行的系统仍然难以实现。这主要由于外部数据处理带来的隐私和延迟问题。WatchHAR 是一个使用音频和惯性传感器进行人体活动识别的系统，能够在智能手表上直接运行，解决了现有系统所面临的隐私和延迟问题。通过优化每个管道组件，WatchHAR 实现了复合性能提升。", "innovation": "WatchHAR 提出了一种新颖的统一架构，将传感器数据预处理和推理合并为一个端到端可训练模块，实现了 5 倍以上的处理速度提升，同时维持超过 90% 的准确性，适用于超过 25 个活动类别。此外，WatchHAR 直接在智能手表上运行，超过了现有的最高水平的事件检测和活动分类模型，活动事件检测时间为 9.3 ms，多模态活动分类时间为 11.8 ms。这标志着在设备上活动识别的进步，实现了无侵入、隐私意识的智能手表作为独立的持续活动跟踪设备的潜力。", "conclusion": "研究通过优化智能手表上的人体活动识别，克服了隐私和延迟的问题，实现了智能手表作为独立、隐私安全、无创的持续活动跟踪设备的潜力。WatchHAR 在活动识别上取得了突破，直接在智能手表上运行，提高了处理速度，保持高准确性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04669", "html_url": "https://arxiv.org/abs/2509.04669", "title": "VCMamba: 融合多方向Mamba的卷积与注意力网络以实现高效视觉表示", "title_en": "VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation", "authors": "Mustafa Munir,Alex Zhang,Radu Marculescu", "background": "近期，视觉变换器（ViTs）和状态空间模型（SSMs）如Mamba在计算机视觉中挑战了卷积神经网络（CNNs）的主导地位。ViTs擅长捕捉全局上下文，而Mamba提供了线性复杂度以处理长序列，但它们在捕捉细粒度局部特征方面不如CNNs。与此同时，CNNs在局部特征表示方面有强大的归纳偏置，但缺乏transformers和Mamba那样的全局推理能力。为弥补这些差距，本文引入了VCMamba，这是一种将CNNs和多方向Mamba SSMs的优点相结合的新视觉骨干网络。", "innovation": "VCMamba 采用了卷积干骺端，并在其早期使用卷积块来提取丰富的局部特征，随后用设计成高效建模长程依赖性和全局上下文的多方向Mamba块进行处理。这种混合设计充分利用了CNNs和Mamba的优势，提供卓越的功能表示能力，同时保持了图像分辨率的线性复杂度。通过在ImageNet-1K分类和ADE20K语义分割上的广泛实验，验证了VCMamba的有效性，VCMamba-B在ImageNet-1K上的顶级准确性达到82.6%，在A`DE20K上的mIoU为47.1，参数量显著减少。", "conclusion": "本文通过引入VCMamba，展示了将CNNs和Mamba SSMs结合的优势，从而实现对图像的高效视觉表示。VCMamba不仅保持全局和局部特征的综合表示能力，还能高效处理大规模图像数据，提高了分类和分割任务的效果。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04582", "html_url": "https://arxiv.org/abs/2509.04582", "title": "Inpaint4Drag: 通过双向扭曲重新利用填充值图为拖动基图像编辑", "title_en": "Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping", "authors": "Jingyi Lu,Kai Han", "background": "拖动基图像编辑已成为一种强大的直观图像操作范式。然而，现有方法主要依赖于生成模型的潜在空间操作，导致精度有限、反馈延迟和模型特定的约束。Inpaint4Drag 提出了一种新的框架，将拖动编辑分解为像素空间双向扭曲和图像填充。这种方法通过将拖动输入直接转换为标准填充格式，作为一种无需修改架构的通用适配器，适用于任何填充模型，自动继承未来所有改进的填充技术，从而实现了0.01秒的实时扭曲预览和512x512分辨率下的0.3秒高效填充，相比现有方法显著提高了交互体验，且无需每次编辑花费数分钟时间。", "innovation": "Inpaint4Drag 提出了一种新的框架，将拖动编辑分解为像素空间双向扭曲和图像填充。这种方法通过将拖动输入直接转换为标准填充格式，作为一种无需修改架构的通用适配器，适用于任何填充模型，自动继承未来所有改进的填充技术，从而实现了实时扭曲预览和高效填充，显著提高了交互体验，并改善了视觉质量和精确控制同时保持实时性能。", "conclusion": "广泛的实验表明，Inpaint4Drag 方法在视觉质量、精确控制和实时性能方面显著优于现有的图像编辑方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04548", "html_url": "https://arxiv.org/abs/2509.04548", "title": "Skywork UniPic 2.0: 使用在线强化学习构建 Kontext 模型的统一多模态模型", "title_en": "Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model", "authors": "Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou", "background": "近年来，多模态模型在统一图像生成和编辑方面展示了令人印象深刻的性能。然而，许多流行的开源模型更侧重于扩大模型参数规模而忽视了优化训练策略，这限制了它们的效率和性能。现有的多模态模型多在单一的生成或编辑任务上进行优化，缺乏全面统一的处理能力。本研究旨在解决这一问题，提出了一种集成统一多模态框架的方法，该方法不仅在图像生成和编辑任务上表现出色，还通过创新的训练和强化学习策略实现了模型的无缝扩展。", "innovation": "本研究创新地提出了一种名为 UniPic2-SD3.5M-Kontext 的大型 DiT 模型，基于 SD3.5-Medium，拥有 2B 个参数，实现了图像生成和编辑的新水平。该模型通过结构改进和大规模预训练提高了文本到图像生成和编辑的联合能力，并提出了一种新颖的渐进双任务强化策略（PDTR），该策略在阶段性的强化中同时提升了两个任务，避免了负交互。此外，通过连接 UniPic2-SD3.5M-Kontext 和 Qwen2.5-VL-7B，推出了 UniPic2-Metaquery 统一多模态模型，实现了理解和生成以及编辑的综合性能，验证了所提出的训练框架的有效性和普适性。", "conclusion": "UniPic2-SD3.5M-Kontext 和 UniPic2-Metaquery 在图像生成及编辑能力上超越了使用更大生成参数的模型，如 BAGEL (7B) 和 Flux-Kontext (12B)。Skywork UniPic 2.0 提供的统一多模态训练方法显示出强大的综合性能和广泛的应用潜力，为未来的多模态模型设计提供了新的思路。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04772", "html_url": "https://arxiv.org/abs/2509.04772", "title": "FloodVision: 使用基础视觉-语言模型和领域知识图谱的城市洪水深度估计算法", "title_en": "FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "及时准确的洪水水深估计对于道路可达性和紧急响应至关重要。虽然近期的计算机视觉方法能够实现洪水检测，但它们在准确性和泛化能力方面存在局限，主要是依赖固定的目标检测器和特定任务的训练。", "innovation": "FloodVision 提出了一种无需特定训练的框架，结合了基础视觉-语言模型 GPT-4o 的语义推理能力和知识图谱中的结构化领域知识。该知识图谱编码了常见城市物体（如车辆、行人和基础设施元素）的标准化现实世界尺寸，使得模型的推理能够基于物理现实。通过在 RGB 图像中动态识别可见的参考物体，检索来自知识图谱的确切高度，估计淹没比率并应用统计离群值过滤，从而计算出最终的深度值。", "conclusion": "FloodVision 在 MyCoast New York 的 110 张众包图像上进行了评估，实现了 8.17 cm 的平均绝对误差，比 GPT-4o 的基线降低了 20.5%，超过了基于 CNN 的先前方法。该系统在多种场景下表现出良好的泛化能力，并且能够接近实时运行，使其适合未来整合到数字孪生平台和公民报告应用中，以增强智慧城市对于洪水的韧性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04732", "html_url": "https://arxiv.org/abs/2509.04732", "title": "通过任务一致性训练利用未标注结构进行多功能医学图像分割", "title_en": "Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation", "authors": "Shengqian Zhu,Jiafei Wu,Xiaogang Xu,Chengrong Yu,Ying Song,Zhang Yi,Guangjun Li,Junjie Hu", "background": "多功能医学图像分割（VMIS）旨在分割多个类别，但由于完全标注所有类别的数据需要大量时间和劳动，因此往往不实用。利用部分标注数据集（PLDs）提供了一种很有前景的替代方案，但当前的VMIS方法面临着严峻的类别不平衡问题，这是因为PLDs中的类别分布不均。现有的方法尝试通过生成伪全标注来解决这个问题，但这些方法通常需要额外的模型，并且可能会由于标签噪声导致性能下降。因此，需要一种不依赖额外模型的方法来解决类别不平衡问题，本文提出的任务一致性训练（TCT）框架正是为此目的设计的，通过约束主分割头和辅助任务头之间的预测一致性，有效利用未标注的解剖结构。此外，为避免低一致性、可能的噪声数据导致的误差传播，提出了一个筛选策略来排除此类数据，同时引入了统一的辅助不确定性加权损失（UAUWL）来减轻由于特定任务主导而导致的分割质量下降。", "innovation": "本文提出了一种任务一致性训练（TCT）框架，该框架不依赖额外模型来解决PLDs中的类别不平衡问题，通过约束主分割头和辅助任务头之间的预测一致性，有效利用未标注的解剖结构。此外，还提出了一种筛选策略和一种统一的辅助不确定性加权损失来避免误差传播和减轻特定任务主导导致的质量下降。", "conclusion": "在来自不同临床站点的八个腹部数据集上进行的广泛实验表明，本文提出的TCT框架是有效的。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04758", "html_url": "https://arxiv.org/abs/2509.04758", "title": "使用增强时间群体概率图的动态群体检测", "title_en": "Dynamic Group Detection using VLM-augmented Temporal Groupness Graph", "authors": "Kaname Yokoyama,Chihiro Nakatani,Norimichi Ukita", "background": "在视频中检测复杂人群群体时，不仅需要考虑群体内成员的局部外观特征，还需要考虑场景的全局上下文。现有方法通常假设视频中的群体不会发生变化，并通过局部特征来检测固定群体。然而，这种方法在视频中群体需要动态变化的情况下表现不佳。本研究旨在改进群体检测方法，使其能够检测动态变化中的群体，并通过全局优化实现群体结构的时空一致性。", "innovation": "本研究提出了通过增强视觉-语言模型（VLM）和使用所有帧的群体概率估计图来动态检测群体的新方法。该方法通过图优化和群体增强的CLIP特征，实现对群体变化的自然适应，有效提高了群体检测的一致性与准确性。实验结果表明，该方法在公共数据集上的表现优于现有的最先进的群体检测方法。", "conclusion": "本研究提出的方法通过引入增强的视觉-语言模型和全局优化策略，显著提高了视频中动态群体检测的准确性。实验结果验证了该方法的有效性，具有广泛的适用性和潜在的应用前景。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04800", "html_url": "https://arxiv.org/abs/2509.04800", "title": "基于移动设备获取图像的深度学习模型在可访问皮肤病理分类中的探索", "title_en": "Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images", "authors": "Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib", "background": "皮肤疾病是全球范围内最普遍的健康问题之一，但传统的诊断方法往往成本高、复杂且在条件有限的地区不可用。虽然基于深度学习的自动化分类方法显示出潜力，但现有研究主要局限于皮肤镜成像数据和疾病类别有限。", "innovation": "研究创建了一个包含超过50种皮肤疾病类别的大型数据集，并使用多种卷积神经网络和Transformer架构进行评估，发现Swin Transformer在捕获全局上下文特征方面表现出优越性能。此外，研究引入了Grad-CAM方法以增强模型解释性，通过强调临床相关区域提供模型预测的透明度。", "conclusion": "研究结果表明，基于Transformer的方法在移动设备获取的皮肤病变分类中具有潜力，有助于资源有限环境中的人工智能辅助皮肤病筛查及早期诊断。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04775", "html_url": "https://arxiv.org/abs/2509.04775", "title": "传统和深度学习特征匹配算法在Chandrayaan-2月球数据中的比较评估", "title_en": "Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data", "authors": "R. Makharia,J. G. Singla,Amitabh,N. Dube,H. Sharma", "background": "月球探索中精确的图像注册对于表面制图、资源定位和任务规划至关重要。来自不同传感器（如光学相机、热红外成像仪和雷达）的数据需要对齐，但由于分辨率、光照和传感器畸变的差异，这是一项挑战性的任务。本文利用Chandrayaan-2数据对五种特征匹配算法（SIFT、ASIFT、AKAZE、RIFT2和SuperGlue）进行了评估，这些算法用于跨模态图像对，评估结果涵盖了赤道和极地区域。同时，还提出了一种预处理管道，包括地理参考、分辨率对齐、强度归一化以及自适应直方图均衡化、主成分分析和阴影校正等多种预处理增强技术。这些技术的应用旨在提高图像对齐的鲁棒性和准确性。", "innovation": "提出了包括地理参考、分辨率对齐、强度归一化和技术增强（如自适应直方图均衡化、主成分分析和阴影校正）的预处理管道。SuperGlue因其较低的均方根误差和更快的运行时间在多种特征匹配算法中表现突出。同时，作者对赤道和极地区域的数据进行了特定分析，展示了经典方法在极地光照下的不足，强调了为不同条件开发预处理技术和学习方法的重要性。此项研究为不同条件下实现鲁棒的月球图像注册提供了一个全面的方法论框架。", "conclusion": "SuperGlue在跨模态图像配准方面表现最优，显示出结合深度学习的匹配方法在月球探索中的潜在应用价值。传统方法（如SIFT和AKAZE）在赤道地区表现良好但随着极地照明条件恶化而表现不佳，强调了跨不同环境进行鲁棒图像配准的重要性。基于这些发现，建议未来的研究应更注重开发适应不同环境的图像配准策略。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04816", "html_url": "https://arxiv.org/abs/2509.04816", "title": "从专家混合体中提取语义分割中的不确定性估计", "title_en": "Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation", "authors": "Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner", "background": "准确且可靠的预测不确定性估计对于增强计算机视觉模型的可靠性非常重要，尤其是在如交通场景感知等安全关键应用中。常用的集合方法通过结合多个模型来量化不确定性，而混合专家模型（MoE）则通过使用门控网络动态加权每个专家的预测来提供一种高效替代方案，这种方式在输入数据依赖情况下表现更好。在我们之前关于语义分割的研究中，发现MoE能够产生更可靠的不确定性估计，无需对架构进行修改。本文研究了三种方法以从MoE中提取预测不确定性的估计：预测熵、互信息和专家方差。在使用A2D2数据集语义分割训练的MoE上评估了这些方法。结果表明，与集合模型相比，MoE在分布外（OOD）数据下的条件正确性指标中提供了更可靠的不确定性估计。", "innovation": "本文提出了一种从专家混合体中提取预测不确定性估计的方法，并探讨了三种提取方法：预测熵、互信息和专家方差。结果显示，MoE方法在处理分布外数据时提供了更可靠的不确定性估计。此外，简单的门控机制比复杂的类别门控机制更能提高路由不确定性估计的校准度。最后，在Cityscapes数据集上增加专家数量可以进一步提高不确定性校准度。", "conclusion": "MoE方法能够提供更可靠的不确定性估计，尤其是在分布外（OOD）数据情况下。简单的门控机制比复杂的方法能更好校准路由不确定性估计，增加专家数量可以进一步提高不确定性校准度。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04824", "html_url": "https://arxiv.org/abs/2509.04824", "title": "利用混合MambaTransformer框架探索轻场超分辨中的非局部位移-角度相关性", "title_en": "Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution", "authors": "Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou", "background": "近年来，基于Mamba的方法因其在长距离信息建模和线性复杂度方面的优点，在优化轻场图像超分辨率(LFSR)的计算成本和性能方面表现出巨大潜力。然而，当前的多向扫描策略在处理复杂轻场数据时导致了特征提取效率低下和冗余的问题。", "innovation": "针对这一挑战，本文提出了一种基于子空间简单扫描(Sub-SS)策略的子空间简单Mamba块(SSMB)设计，以实现更高效的特征提取。此外，还提出了一种双阶段建模策略，以解决状态空间在保留空间-角度和视差信息方面的局限性，从而实现非局部空间-角度相关性的更全面探索。在第一阶段，引入了空间-角度残差子空间Mamba块(SA-RSMB)进行浅层的空间-角度特征提取；在第二阶段，采用了结合立体像平面Mamba块(EPMB)和立体像平面变换块(EPTB)的并行结构进行深层的立体像平面特征精炼。基于精心设计的模块和策略，提出了一种混合Mamba-Transformer框架(LFMT)，结合Mamba和Transformer模型的优势，实现空间、角度和立体像平面域的信息综合探索。", "conclusion": "实验结果显示，LFMT在LFSR上显著超过了现有的最先进的方法，在多种真实世界和合成的轻场数据集上实现了性能上的大幅提高，同时保持了较低的计算复杂度。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04833", "html_url": "https://arxiv.org/abs/2509.04833", "title": "PropVG: 基于多重粒度区分的端到端提案驱动视觉定位", "title_en": "PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination", "authors": "Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang", "background": "视觉定位的研究近年来已经从传统的基于提案的两阶段框架中转向，因为这些框架效率低下且计算复杂度高。现有的方法过分依赖于目标参照来进行监督，没有利用前景目标的潜力。现有的方法也往往没有包含多粒度的区分，这对复杂场景中对象识别的鲁棒性至关重要。", "innovation": "提出了一种端到端的提案驱动框架PropVG，首次将前景对象提案生成与参照对象理解无缝集成，并引入了基于对比学习的参照评分（CRS）模块以及多粒度目标区分（MTD）模块，以增强理解和区分参照对象的能力，并融合对象和语义级信息以提高对缺席目标的识别能力。", "conclusion": "在gRefCOCO (GREC/GRES)、Ref-ZOM、R-RefCOCO和RefCOCO (REC/RES)标准数据集上的广泛实验显示了PropVG的有效性。代码和模型可以在提供的链接中找到。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04773", "html_url": "https://arxiv.org/abs/2509.04773", "title": "Hybrid-Tower: 细粒度伪查询交互与生成用于文本到视频检索", "title_en": "Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval", "authors": "Bangxiang Lan,Ruobing Xie,Ruixiang Zhao,Xingwu Sun,Zhanhui Kang,Gang Yang,Xirong Li", "background": "文本到视频检索（T2VR）任务旨在通过具有相同语义意义的文本查询来检索未标记的视频。近期基于CLIP的方法探讨了两种架构：两塔与单塔架构，然而前者效果较低，后者效率较低。本文探讨了一种新的混合塔（Hybrid-Tower）架构，该架构能够融合两塔与单塔架构的优势，实现高效性和高效果性的同时兼顾。", "innovation": "本研究提出了一种新颖的混合方法，即精细粒度伪查询交互与生成用于T2VR，简称为PIG，该方法包含一个新设计的伪查询生成器，用于为每个视频生成一个伪查询。这种方法使得视频特征与伪查询的文本特征以精细的方式相互作用，类似于单塔方法以保持高效果性，即使在收到实际文本查询之前。同时，在推理阶段，我们的方法不需要额外的存储或计算开销，从而保持高效性。", "conclusion": "在五种广泛使用的文本到视频检索基准上进行的广泛实验表明，我们的方法在基线方法上取得了显著的改进，精度提高了1.6%到3.9%（R@1）。此外，我们的方法在效率方面与两塔模型保持一致，同时达到了接近当前最先进的技术水平，突显了混合塔架构的优势。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04894", "html_url": "https://arxiv.org/abs/2509.04894", "title": "SynGen-Vision: 用于训练工业视觉模型的合成数据生成", "title_en": "SynGen-Vision: Synthetic Data Generation for training industrial vision models", "authors": "Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj", "background": "工业磨损检测是预测维护任务中的一个重要计算机视觉问题，但获取不同磨损情境的数据集进行模型训练成本高昂且耗时。因此，如何高效地生成合成数据以培训CV模型是一个亟待解决的问题。", "innovation": "论文提出了一种结合视觉语言模型和3D模拟渲染引擎来生成不同锈蚀条件下的合成数据的方法。这种方法可以定制化地应用于其他工业磨损检测场景，并在使用合成数据训练的模型上实现了mAP50分数为0.87的良好性能。", "conclusion": "该方法生成的合成数据用于训练CV模型，该模型在真实工业物体内锈图片上的表现优于其他方法，证明了其在工业应用中的有效性和可扩展性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04757", "html_url": "https://arxiv.org/abs/2509.04757", "title": "MCANet：一种基于UAV影像的多尺度类别特定注意力网络用于多标签飓风后灾害评估", "title_en": "MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "飓风灾后快速且精确的损害评估对于灾害响应和恢复至关重要，但现有的基于CNN的方法难以捕捉多尺度的空间特征，并且难以区分视觉上相似或同时出现的损害类型。MCANet是一个多标签分类框架，通过学习多尺度表示并在每个损害类别中自适应地关注相关空间区域来解决这些问题。该模型采用Res2Net为基础的分层骨干网络，以丰富多尺度空间上下文，并配备一个增强区分性能的多头类别特定残差注意力模块。每个注意力分支关注不同的空间粒度，平衡局部细节与全局背景。MCANet在收集于飓风迈克尔后的4,494张无人机影像的RescueNet数据集上进行了评估，该模型达到了91.75%的平均平均精确度（mAP），超过了ResNet、Res2Net、VGG、MobileNet、EfficientNet和ViT，尤其是在对“道路受阻”这类具有挑战性的类别上，平均精确度提高了6%以上。类激活映射进一步验证了MCANet能够定位与灾害相关的区域，支持模型的可解释性。MCANet的输出可用于灾害后风险评估、应急路线规划以及基于数字孪生的灾害响应。未来的研究可以整合灾害特定的知识图谱和多模态大型语言模型，提高其未见灾害的适应能力，并丰富实际决策中的语义理解。", "innovation": "提出了一种多标签分类框架MCANet，它采用Res2Net为基础的分层骨干网络，可以丰富多尺度空间上下文；并配备一个增强区分性能的多头类别特定残差注意力模块。每个注意力分支关注不同的空间粒度，平衡局部细节与全局背景。该模型通过自适应地关注每个损害类别的相关空间区域，有效解决了现有的基于CNN的方法难以捕捉多尺度的空间特征和区分视觉上相似或同时出现的损害类型的问题。", "conclusion": "MCANet在飓风迈克尔后的4,494张无人机影像的RescueNet数据集上实现了91.75%的mAP，超越了多种基线方法，特别是在对挑战性的类别如“道路受阻”的平均准确度提高了6%。类激活映射验证了该模型具有定位灾害相关区域的能力，并提供了对网络响应的理解。MCANet模型的结果可以用于灾害后的风险映射、应急路线规划以及基于数字孪生的灾害响应。未来的研究可以通过整合灾害特定的知识图谱和多模态大型语言模型，进一步提升该模型对于未见过的灾害的适应性和在实际决策中的语义理解。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04848", "html_url": "https://arxiv.org/abs/2509.04848", "title": "无姿态3D定量相位成像流动细胞群体", "title_en": "Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations", "authors": "Enze Ye,Wei Lin,Shaochi Ren,Yakun Liu,Xiaoping Li,Hao Wang,He Sun,Feng Pan", "background": "目前的成像方法假设细胞沿单一轴进行均匀旋转，并且需要在每一帧中已知他们的姿态。这种方法仅适用于接近球形的细胞，并且不能准确成像具有复杂旋转的不规则形状的细胞。这限制了基于流式通道的实验能够进行稳健的统计分析的能力，只分析了一部分细胞群体。现有的定量相位成像技术难以处理任意几何形状和多轴旋转的细胞，导致只能从有限的视角进行稀疏采样，从而限制了成像的精度。", "innovation": "OmniFHT是一种不需了解细胞姿态的无姿态3D折射率分布重建框架，利用傅里叶衍射定理和隐式神经表示（INRs），实现了流动细胞群体的高速定量相位成像。这种框架有望支持任意细胞几何形状和多轴旋转，并能在有限视角的情况下进行高精度重建，甚至只需要10个视点或120度视角范围内就能产生高保真结果。这是首次能够在流动条件下对整个细胞群体进行高通量三维成像，为无标记的细胞形态分析提供了可扩展且无偏的解决方案。", "conclusion": "OmniFHT在流动细胞群体的无姿态3D定量相位成像中具有重大突破，不仅能够实现高速成像，还能处理任意细胞几何形状和多轴旋转，提供无标记的细胞形态分析。这项技术大幅提升了基于流式通道的实验的分析能力和精度，为生物医学研究提供了有力工具。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04859", "html_url": "https://arxiv.org/abs/2509.04859", "title": "CoRe-GS: 从粗到精的具有语义对象聚焦的高斯点绘制", "title_en": "CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus", "authors": "Hannah Schieber,Dominik Frischmann,Simon Boche,Victor Schaack,Angela Schoellig,Stefan Leutenegger,Daniel Roth", "background": "移动重建技术在自主空中机器人领域的应用潜力巨大，特别是在远程指导和灾难响应等关键任务中。这些任务要求进行精确的3D重建和快速的场景处理。通常情况下，为了高效处理，可以专注于特定对象或兴趣点（PoIs），移动机器人能够通过先进的传感器早些时候在数据获取或初步分析中检测到这些对象，从而减少了对整个场景的详细重建需求。高斯点绘制（GS）已被证明能够通过增量学习过程提供高质量的新视角合成和3D表示。在此基础上，通过加入语义信息到高斯点绘制，可以更有效地隔离出对象，并减少整体训练时间。由于通常在捕捉过程中已经知道语义上相关的区域和PoIs，因此提出了一种结合粗粒度到精粒度的高斯点绘制技术（CoRe-GS）。通过这种方法，不仅能保持高质量的重建，还能大幅缩短训练时间。", "innovation": "提出了CoRe-GS技术，这是一种结合了从粗粒度到精粒度的高斯点绘制方法。首先，使用语义高斯点绘制生成初步的细粒度分割场景，然后使用基于颜色的有效过滤技术进一步细化，实现语义对象的有效隔离。该方法将训练时间缩短至语义高斯点绘制训练周期的约四分之一，同时保持了高质量的重建效果。", "conclusion": "通过在两个数据集（SCRREAM和NeRDS 360）上的评估，结果表明采用CoRe-GS方法可以减少运行时间，并提高新视角合成的质量。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05000", "html_url": "https://arxiv.org/abs/2509.05000", "title": "基于VLM引导的鲁棒红外和可见光图像降质感知融合框架：双域视角", "title_en": "Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework", "authors": "Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui", "background": "大多数现有的红外-可见光图像融合（IVIF）方法假设输入高质量，因此难以应对双源降级场景，通常需要手动选择和依次应用多个预处理步骤。这种解耦的预增强到融合管道不可避免地导致错误累积和性能下降。", "innovation": "提出了Guided Dual-Domain Fusion (GD^2Fusion)，一个新颖的框架，通过视觉-语言模型 (VLMs) 协同整合降质感知与双域（频率/空间）联合优化。GFMSE 模块在频域进行降质感知和抑制，并区分性地提取融合相关的子带特征。同时，GSMAF 模块在空间域进行跨模态降质过滤和自适应多源特征聚合，以增强模态互补性和结构一致性。", "conclusion": "大量定性和定量实验表明，GD^2Fusion 在双源降级场景中实现了优于现有算法和策略的融合性能。代码会在论文被接受后公开发布。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04895", "html_url": "https://arxiv.org/abs/2509.04895", "title": "评估自动角质细胞脂滴计数的多重实例学习策略", "title_en": "Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting", "authors": "Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim", "background": "角质细胞是分泌脂质的细胞，其分化特征是形成细胞内脂滴的积累。因此，脂滴的数量是角质细胞生物研究的关键读数。然而，手动计数耗时且主观，因此需要自动化的解决方案。当前研究介绍了一种基于注意力的多重实例学习（MIL）框架，用于角质细胞图像的分析。研究者使用Nile Red染色的角质细胞图像，并根据脂滴计数将其注释为14个类别，通过数据增强扩展至约5万个细胞。研究比较了基准多层感知器（MLP）模型和利用ResNet-50特征并结合实例加权的注意力基MIL模型的表现。", "innovation": "该研究引入了一种基于注意力的多重实例学习（MIL）框架，该框架通过使用增强学习技术扩大了角质细胞的图像数据集，并在此基础上对基准多层感知器（MLP）模型和注意力基MIL模型进行了基准测试。研究发现，基础的MLP模型在跨五折验证中表现更为稳定，而注意力基MIL模型虽然一致性较差，但在某些折中偶尔表现出优越性。这些结果表明，简化的袋子级聚合为滑块级计数提供了稳健的基础，而注意力基MIL则需要任务对齐的聚合和正则化来充分发挥其潜在能力。", "conclusion": "实验结果显示，基准的MLP模型在跨五折验证中的表现更为稳定（平均MAE = 5.6），而注意力基MIL模型则更不一致（平均MAE = 10.7），但在某些折中表现出更优。因此，研究最终表明，简单的袋子级聚合为滑块级脂滴计数提供了一个稳健的基础，而注意力基MIL则需要任务对齐的聚合和正则化来实现其全部潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04886", "html_url": "https://arxiv.org/abs/2509.04886", "title": "Cryo-RL: 通过强化学习自动进行前列腺癌冷冻消融治疗规划", "title_en": "Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning", "authors": "Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed", "background": "冷冻消融治疗是前列腺癌的一种微创局部治疗方法，通过解冻过程破坏恶性组织同时保留健康的周围结构。该治疗的成功依赖于术前对冷冻探针放置位置的精确规划，以覆盖肿瘤并避开重要解剖结构。当前，这种规划主要是手工完成，依赖于专业知识，同时也是耗时的，导致治疗质量有所差异，并且难以扩大规模。文章介绍了一种基于强化学习的冷冻消融规划框架Cryo-RL。", "innovation": "提出了一个名为Cryo-RL的基于强化学习的框架，将冷冻消融规划建模为马尔科夫决断过程，并学习出一个最优策略来确定冷冻探针的放置位置。在模拟了临床限制和术中随机变异的环境中，代理按顺序选择冷冻探针位置和冰球直径。通过基于覆盖肿瘤奖励函数的引导，该代理学会了一种能带来最优冷冻探针放置策略的冷冻消融策略，这种方法不需要任何手工设计的计划。与几何优化等最佳自动化基本方法相比，Cryo-RL在583例回顾性前列腺癌病例上的表现优于8个百分点的Dice值，并且性能达到了人类专家水平所需的时间大幅减少。这一结果展示了强化学习为确保临床可行、可重复和高效的冷冻消融计划提供的潜在能力。", "conclusion": "Cryo-RL在冷冻探针放置的研究中取得了显著的进展，实现了比现有最先进自动化技术更高的肿瘤覆盖优值，更重要的是，其打破了专业依赖和时间消耗的限制，提升了整个治疗流程的效率。这些结果表明，强化学习强大的学习方法在医疗决策支持方面的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04932", "html_url": "https://arxiv.org/abs/2509.04932", "title": "UniView：通过统一参考特征增强单张图像的新视角合成", "title_en": "UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features", "authors": "Haowang Cui,Rui Chen,Tao Luo,Rui Li,Jiaze Wang", "background": "从单张图像合成新视角的任务由于未观察区域存在多种解释而高度未定型。现有的大多数方法倾向于从不确定性先验和输入视角附近的插值生成未见过的区域，但常导致严重的失真。为了解决这个问题，本文提出了一种名为UniView的新模型，该模型可以利用相似对象的参考图像提供的强大先验信息来增强视图合成。具体地，该模型构建了一个检索和增强系统，并使用多模态大型语言模型（MLLM）辅助选择符合要求的参考图像。此外，引入了一个带有多层次隔离层的插拔式适配器模块，以动态生成目标视图的参考特征。为了保留原始输入图像的细节，设计了一种解耦的三重注意力机制，可以有效地对齐和整合多分支特征到合成过程中。多项实验结果表明，UniView 在新视角合成性能上显著提升，并在挑战性数据集上优于现有最先进的方法。", "innovation": "本文提出了一种名为UniView的新型模型，它能够利用相似对象的参考图像提供强大的先验信息，用于视图合成。该模型通过检索和增强系统、多模态大型语言模型、插拔式适配器模块以及解耦的三重注意力机制，解决了从单张图像合成新视角的挑战性问题。", "conclusion": "本文提出的UniView在新视角合成性能上取得了显著改进，并在挑战性数据集上优于现有最先进的方法。该模型通过利用相似参考图像的信息和创新的特征生成与整合方法，显著提升了合成视图的质量。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05012", "html_url": "https://arxiv.org/abs/2509.05012", "title": "一种仿生分离学习视觉模型在黑暗环境实时交通物体感知中的应用", "title_en": "A biologically inspired separable learning vision model for real-time traffic object perception in Dark", "authors": "Hulin Li,Qiliang Ren,Jun Li,Hanbing Wei,Zheng Liu,Linfang Fan", "background": "低光照条件下的交通场景物体感知越来越受到关注。然而，由于光照严重恶化和缺乏可靠的视觉线索，现有的感知模型和方法难以快速适应和准确预测低光照环境。此外，缺乏专注于低光照交通场景的大规模基准数据集。", "innovation": "提出了一种基于生物体的分离学习视觉模型（SLVM），该模型包括：光适应瞳孔机制、特征级别的分离学习策略、特定任务的解耦分支以及空间错位感知融合模块，以增强在不良照明条件下的感知能力。实验表明，SLVM在保持低计算开销的情况下实现了最先进的性能。SLVM在检测和实例分割上分别优于RT-DETR和YOLOv12，结果分别提高了11.2和6.1个百分点。SLVM在端点误差EPE上降低了12.37%，并超越了Swin Transformer+EnlightenGAN和ConvNeXt-T+EnlightenGAN等基线模型。", "conclusion": "提出了物理基础的光照退化方法和Dark-traffic数据集，该数据集是迄今为止最大的 densely annotated 低光照交通场景数据集。SLVM在多个关键指标上超越了其他基线模型，验证了其在低光照条件下的优越性能，并发布了Dark-traffic数据集和完整代码。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05034", "html_url": "https://arxiv.org/abs/2509.05034", "title": "工业异常检测和定位的高效像素标注", "title_en": "Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization", "authors": "Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang", "background": "工业产品检测通常使用仅基于非缺陷样本训练的异常检测（AD）框架。虽然在生产过程中可以收集缺陷样本，但利用这些样本通常需要像素级注释，限制了其可扩展性。", "innovation": "提出了一种交互式图像分割（IIS）算法ADClick，该算法仅需少数用户点击和简要的文本描述即可生成像素级异常注释，同时引入了ADClick-Seg，这是一种通过原型基方法对视觉特征和文本提示进行对齐的跨模态框架，用于异常检测和定位。", "conclusion": "ADClick-Seg通过结合像素级先验和语言引导的线索，在挑战性的多类AD任务上达到了最先进的结果（AP = 80.0%，PRO = 97.5%，Pixel-AUROC = 99.1%）于MVTec AD。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05071", "html_url": "https://arxiv.org/abs/2509.05071", "title": "AI驱动的MRI运动伪影检测和修正的系统评价和元分析", "title_en": "Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction", "authors": "Mojtaba Safari,Zach Eidex,Richard L.J. Qiu,Matthew Goette,Tonghe Wang,Xiaofeng Yang", "background": "本研究旨在系统性回顾和综合分析人工智能（AI）驱动的方法在检测和修正磁共振成像（MRI）运动伪影中的应用。研究重点关注深度学习（DL）方法，特别是生成模型在MRI运动伪影检测和修正中的应用。研究提取了有关数据集、DL架构和性能指标的定量数据，评估了当前的发展状况、效果、挑战以及未来的研究方向。", "innovation": "该研究通过系统性和量化的方法，专注于深度学习特别是生成模型在MRI运动伪影检测和修正中的应用，揭示了AI驱动方法在改善MRI图像质量方面的能力，并指出了存在的关键挑战，提出了未来的研究方向和解决策略。", "conclusion": "AI驱动的方法，特别是DL生成模型，在提高MRI图像质量以及有效应对运动伪影方面展现出显著的潜力。然而，需要解决的关键问题包括全面的公共数据集需求、标准化的报告协议以评估伪影水平、以及开发更高级、更适应的DL技术以减少对大量配对数据集的依赖。解决这些问题将大大提升MRI诊断准确性、减少医疗成本并改善患者护理效果。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05019", "html_url": "https://arxiv.org/abs/2509.05019", "title": "利用迁移学习和移动增强卷积神经网络提高阿拉伯手写字符识别", "title_en": "Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition", "authors": "Mohsine El Khayati,Ayyad Maafiri,Yassine Himeur,Hamzah Ali Alkhazaleh,Shadi Atalla,Wathiq Mansoor", "background": "研究背景着眼于传统计算需求高、数据集稀少的问题，致力于通过将迁移学习（TL）与移动设备上运行的轻量级卷积神经网络（MbNets）相结合来提高阿拉伯手写字符识别（AHCR）的性能。该研究评价了三种不同的迁移学习策略，如全量微调、部分微调和从头训练，并使用四种轻量级MbNets：MobileNet、SqueezeNet、MnasNet和ShuffleNet，在三个基准数据集AHCD、HIJJA和IFHCDB上进行了实验。", "innovation": "研究创新点在于引入了迁移学习与轻量级移动网络相结合的方法，以优化资源使用；并且通过实验验证了四种轻量级网络在不同的迁移学习策略下的性能表现。实验结果显示，MobileNet在多个指标中表现出色，而ShuffleNet在全量微调下表现出良好的泛化能力。利用IFHCDB数据集，在全量微调下MnasNet达到了99%的高准确率，显示出显著的稳健性。这些发现为未来的阿拉伯手写字符识别研究提供了新的视角。", "conclusion": "实验结果表明，全量微调是总体表现最优的方法，能够在准确性与收敛速度之间取得较好平衡。研究结论指出，结合迁移学习和轻量级移动网络对于资源经济的阿拉伯手写字符识别具有潜力，并为进一步优化和广泛应用铺平了道路。未来的研究将探索网络结构的改进、深入的数据集特征分析、数据增强方法以及高级敏感性分析，以进一步增强模型的鲁棒性和泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04889", "html_url": "https://arxiv.org/abs/2509.04889", "title": "SpiderNets：使用视觉模型估计与蜘蛛相关的图像的恐惧评分", "title_en": "SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models", "authors": "Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak", "background": "计算机视觉的进步为临床应用开辟了新的途径，特别是在计算机化暴露疗法中，可以基于患者反应实时调整视觉刺激。研究探讨了预训练的计算机视觉模型能否准确预测与蜘蛛相关的图像所引起的恐惧水平，以推进这种适应性系统的构建。该研究采用了三种不同的模型，通过迁移学习来预测人类对标准化数据集中313张图像的恐惧评分（0-100分），并通过交叉验证进行评估，发现平均平均绝对误差在10.1至11.0之间。实验结果显示，减少数据集大小显著损害了模型性能，而进一步增加数据集则没有显著提升。通过解释模型的预测，结果显示这些模型的预测主要是基于与蜘蛛相关的特性。进一步的类别错误分析也指出了导致更高错误率的视觉条件（例如远处视角和人造或涂漆的蜘蛛）这些结果表明，可解释的计算机视觉模型在预测恐惧评分方面具有潜力，同时也强调了模型可解释性和足够数据集大小的重要性，这对于开发有效的感知情绪疗法技术至关重要。", "innovation": "该研究通过迁移学习的方式，将预训练的计算机视觉模型应用于预测与蜘蛛相关的图像所引起的恐惧水平，通过评估这些模型的预测性能，揭示了与蜘蛛相关的特征对预测的重要性，并识别了可能导致高误差率的视觉条件。此外，研究强调了模型的解释能力和数据集大小对于有效开发情绪感知疗法技术的重要性。", "conclusion": "该研究证明了可解释的计算机视觉模型在预测恐惧评分方面的潜力，并强调了模型可解释性和足够的数据集大小的重要性，这对于开发有效的感知情绪疗法技术至关重要。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05030", "html_url": "https://arxiv.org/abs/2509.05030", "title": "LUIVITON: 学习得到的通用可互操作虚拟试穿", "title_en": "LUIVITON: Learned Universal Interoperable VIrtual Try-ON", "authors": "Cong Cao,Xianhang Cheng,Jingyuan Liu,Yujian Zheng,Zhenhui Lin,Meriem Chkir,Hao Li", "background": "本文介绍了LUIVITON，一个端到端的全自动虚拟试衣系统，可以将复杂的多层服装无缝地披在多样化的人形角色上。为了应对复杂服装与各种高度多样化的身体形状对齐的挑战，本文使用了SMPL作为代理表示，并将服装-身体对齐问题划分为两个相应的任务：1) 服装- SMPL和2) 身体- SMPL对应关系，每个任务都具有独特挑战。该系统能有效处理复杂几何结构、非流形网格，并能广泛应用于人类、机器人、卡通角色、生物和外星人等不同类型的角色，同时保持了计算效率，便于实际应用。此外，LUIVITON除了提供全自动的服装贴合解决方案外，还支持快速调整服装尺寸和材质属性。即使缺乏2D服装缝制图案，系统也能生成高质量的3D服装贴合效果，无需任何人工干预。", "innovation": "本文提出了一种学习得到的通用可互操作虚拟试穿系统——LUIVITON。其创新点包括：1) 采用几何学习方法解决部分到完整形状对应预测的服装- SMPL对齐问题；2) 引入基于扩散模型的多视图一致外观特征及预训练2D基础模型解决身体- SMPL对齐问题；3) 系统能有效处理复杂几何结构和非流形网格，适用于多种人形角色，同时保持了计算效率；4) 支持快速自定义服装尺寸，用户可以在贴合后调整服装尺寸和材质属性；5) 即使缺乏2D服装缝制图案，系统也能生成高质量的3D服装贴合效果，无需人工干预。", "conclusion": "本文展示了LUIVITON系统在全自动虚拟试衣领域的应用潜力，该系统不仅能够无缝地将复杂多层服装贴合在多样化的人形角色上，还能有效处理复杂几何结构和非流形网格问题。通过学习得到的方法，系统能够广泛应用于不同类型的三维人物模型，同时保持了较好的计算效率。此外，LUIVITON还支持用户在贴合后快速调整服装尺寸和材质属性，提供了便捷的试衣体验，即便缺乏2D缝制图案也能生成高质量的3D服装贴合效果。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05131", "html_url": "https://arxiv.org/abs/2509.05131", "title": "基于注意力的可扩展方法：从图像到3D纹理映射", "title_en": "A Scalable Attention-Based Approach for Image-to-3D Texture Mapping", "authors": "Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung", "background": "高质量的纹理对现实感3D内容的创建至关重要，但是现有的生成方法速度慢、依赖于UV图，且经常不能忠实于参考图像。", "innovation": "提出了一个基于Transformer的框架，可以直接从单张图像和网格预测3D纹理字段，从而消除UV映射和可微渲染的需求，实现更快的纹理生成。该方法整合了三平面表示与基于深度的反投影损失，实现高效训练和快速推理。", "conclusion": "经过训练后，该方法可以单次前向传播生成高保真纹理，每种形状仅需0.2秒。通过大量定性和定量的用户偏好评估可以看出，与现有的最先进的基线相比，该方法在忠实度和感知质量方面均表现出色，突显了其在大规模、高质量和可控3D内容创建中的实用性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05092", "html_url": "https://arxiv.org/abs/2509.05092", "title": "无领域对齐的半监督深度转移回归", "title_en": "Semi-supervised Deep Transfer for Regression without Domain Alignment", "authors": "Mainak Biswas,Ambedkar Dukkipati,Devarajan Sridharan", "background": "深度学习模型在实际应用中（如医学）面临挑战，因为源模型不适用于目标数据。许多成功的领域自适应方法需要完全访问源数据。但在涉及隐私或数据量过大导致存储和计算成本高昂的情况下，这种需求是不现实的。此外，资源限制还可能限制标靶数据标签的可用性。文章以神经科学为例，探讨了源数据无法获取、标靶数据缺乏标签以及预测涉及连续输出值的挑战。在此背景下，CRAFT（Contradistinguisher-based Regularization Approach for Flexible Training）被开发出来，旨在源代码不可访问的条件下，在半监督的回归任务中转移到预训练模型。", "innovation": "CRAFT基于Contradistinguisher框架，开发了一种高效的学习方法，可以在不进行领域对齐的情况下，利用标靶数据进行半监督的无源数据域自适应。CRAFT特别针对回归任务，并且展现了其在神经科学相关数据集（如EEG数据的眼球预测和MRI数据中的“大脑年龄”预测）上优于现有方法的性能。对于数据标签稀缺的情况，CRAFT的性能提高可达9%。此外，CRAFT还展示了在生物医学领域中的广泛应用潜力。", "conclusion": "研究者提出了CRAFT，一种高效的方法，用于在不拥有源数据、标签稀缺的条件下进行半监督的深层模型转移学习，特别适用于回归任务。CRAFT在多个实际应用场景中证明了其优越性，被认为是解决无源数据情况下深度计算转移的有效方案之一。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04624", "html_url": "https://arxiv.org/abs/2509.04624", "title": "基于无人机的智能交通监控系统：实时车辆检测、分类、跟踪及行为分析", "title_en": "UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis", "authors": "Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel", "background": "城市交通拥堵和违规行为是城市交通流动性和公路安全的重要挑战。传统的固定摄像头和基于传感器的方法在覆盖范围、适应性以及可扩展性方面存在局限性。", "innovation": "该论文介绍了一种先进的无人机（UAV）交通监控系统，能够实现在复杂多变的城市环境中的准确车辆检测、分类、跟踪及行为分析。该系统利用多尺度和多角度模板匹配、卡尔曼滤波和基于霍夫变换的校准来处理200米高空收集的空中视频数据。通过多模态信息融合，系统可以自动检测多种交通违规行为，并支持多个尺度的智能交通分析。", "conclusion": "实验结果证实了该系统的可扩展性、精确性和实际相关性，强调其作为下一代智能城市建设中具备执行感知能力、独立于基础设施的交通监控解决方案的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05075", "html_url": "https://arxiv.org/abs/2509.05075", "title": "GeoSplat: 深入探讨几何约束高斯散射", "title_en": "GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting", "authors": "Yangming Li,Chaoyu Liu,Lihao Liu,Simon Masnou,Carola-Bibian Schönlieb", "background": "最近的研究探索了在高斯散射优化中引入几何先验，进一步提升其性能。早期研究主要集中在低阶几何先验（如法线向量）上，并且这些先验因噪声敏感方法（如局部主成分分析）的不稳定性而难以可靠地估计。", "innovation": "首次提出了GeoSplat，这是一种利用一阶和二阶几何量来改善高斯散射整个训练流程（包括高斯初始化、梯度更新和致密化）的几何约束优化框架。此外，基于特定的几何结构（如局部流形），引入了高效的、抗噪的几何先验估计方法，为框架提供动态几何先验。实验表明，GeoSplat 显著提高了高斯散射的性能并超过此前的基线方法。", "conclusion": "通过 GeoSplat 框架，提出了基于主曲率初始化 3D 高斯原语尺度，比随机初始化更有效地覆盖物体表面。实验还展示了 GeoSplat 在多个数据集上的改进性能和对以往基线方法的优越表现。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05198", "html_url": "https://arxiv.org/abs/2509.05198", "title": "增强3D点云分类的ModelNet-R与Point-SkipNet", "title_en": "Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet", "authors": "Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari", "background": "3D点云分类对于自动驾驶、机器人和增强现实等应用至关重要，但常用的ModelNet40数据集存在标签不一致、2D数据、尺寸不匹配和类别区分不足等问题，这影响了模型性能。", "innovation": "本文提出了一个精细化改进后的ModelNet-R数据集，解决了ModelNet40存在的问题。同时，提出了一个基于图的轻量级神经网络Point-SkipNet，该网络利用高效的采样、邻域分组和跳连结构，在减少计算开销的同时实现了高分类精度，并取得了最先进的准确率，而参数量远低于当下其他模型。", "conclusion": "研究表明，模型在ModelNet-R数据集上训练能够显著提升性能。该研究突出了数据集质量对优化3D点云分类模型效率的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05004", "html_url": "https://arxiv.org/abs/2509.05004", "title": "可解释的深度迁移学习在乳腺超声癌检测中的应用：多数据集研究", "title_en": "Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study", "authors": "Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Wathiq Mansoor", "background": "乳腺癌是全球女性癌症相关死亡的主要原因之一。超声成像因其安全性和成本效益广泛应用于早期检测，特别是在乳腺致密的患者中。本文通过对使用超声图像进行乳腺癌分类的机器学习和深度学习技术的综合研究，展示了这些技术在乳腺癌检测中的应用价值。研究使用了BUSI、BUS-BRA和BrEaST-Lesions USG等多个数据集进行评估，结果显示ResNet-18模型在恶性病变分类上的准确率高达99.7%，并且具有完美的灵敏度。经典的机器学习模型尽管不如卷积神经网络（CNN）表现，但在与深度特征提取相结合后也能够保持竞争力。Grad-CAM可视化方法进一步提高了模型的透明度，通过强调诊断相关的关键图像区域来增强解释性。这些发现支持将基于AI的诊断工具融入临床工作流程，并展示了在超声成像基础上部署高性能、可解释系统以实现乳腺癌检测的可行性。", "innovation": "本研究通过使用经典的机器学习模型（SVM, KNN）和深度卷积神经网络（ResNet-18, EfficientNet-B0, GoogLeNet）进行乳腺超声图像的乳腺癌分类，展示了深度学习技术在提升检测准确性方面的作用。特别地，ResNet-18模型在恶性病变分类上达到了最高准确率。结合Grad-CAM可视化技术，进一步提高了模型的可解释性。这些发现表明，将基于AI的诊断工具应用于临床乳腺超声成像中的乳腺癌检测是可行且有效的。", "conclusion": "本研究证实了可通过集成深度学习技术提高乳腺超声图像的乳腺癌检测性能，并支持推荐将AI辅助诊断工具结合到临床工作流程中。利用ResNet-18模型及其出色的可解释性特征，在恶性肿瘤检测中具有显著优势。研究结果强调了深度学习在现代乳腺癌诊断中的潜在应用价值。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05188", "html_url": "https://arxiv.org/abs/2509.05188", "title": "SL-SLR: 自监督表示学习在手语识别中的应用", "title_en": "SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition", "authors": "Ariel Basso Madjoukeng,Jérôme Fink,Pierre Poitier,Edith Belise Kenmogne,Benoit Frenay", "background": "手语识别（SLR）是一个目标是识别视频中手语的机器学习任务。由于标注数据稀缺，无监督方法如对比学习变得有前景。这些方法通过拉近正样本（同一个实例的两种增强版本）和推开负样本（与正样本不同的）来学习有意义的表示。但是，在手语识别中，视频中的某些部分提供了真正有用的识别信息，而其他部分则不重要。对比学习方法没有区分这些重要部分与其他部分。此外，不同手语之间的共享运动使得负样本高度相似，增加了手语识别的复杂性。这些问题导致学习到的手语识别非辨别特征，并在下游任务中获得较差的结果。", "innovation": "该论文提出了一种自监督学习框架，旨在为手语识别学习有意义的表示。此框架包含两个共同工作的关键组成部分：(i) 一种新的自监督方法，使用自由负样本对；(ii) 一种新的数据增强技术。此方法在线性评估、半监督学习和手语语言之间的可迁移性上均显示出优于多种对比学习和自监督方法的高度准确性提高。", "conclusion": "该自监督学习框架显著提高了手语识别的准确性，克服了传统对比学习中存在的问题，为手语识别提供了一种有效的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05296", "html_url": "https://arxiv.org/abs/2509.05296", "title": "WinT3R：基于窗口的流式重建与相机令牌池", "title_en": "WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool", "authors": "Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He", "background": "之前的重建方法在重建质量与实时性能之间存在权衡。", "innovation": "1. 引入滑动窗口机制以确保窗口内帧之间信息交换，提高几何预测质量；2. 利用紧凑的相机表示和维护全局相机令牌池来提升相机姿态估计的可靠性。", "conclusion": "WinT3R实现了在线重建质量、相机姿态估计和重建速度的领先表现，实验验证了这些设计的优势。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05208", "html_url": "https://arxiv.org/abs/2509.05208", "title": "使用大规模语言模型进行符号图形编程", "title_en": "Symbolic Graphics Programming with Large Language Models", "authors": "Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu", "background": "大规模语言模型在程序合成方面表现出色，但在生成可以呈现为精确视觉内容的符号图形程序方面的能力尚未得到充分探索。本文研究了符号图形编程，目标是从自然语言描述生成符号图形程序。为了探究语言模型如何理解视觉世界，本文通过促使它们生成基于符号图形程序的图像来完成这一任务。本文专注于可扩展矢量图形 (SVG) 的生成。研究包括语言模型生成符号图形程序的能力；提出了一个全面的基准 SGP-GenBench，涵盖对象保真度、场景保真度和组合性（属性绑定、空间关系、数量感）；研究发现前沿专有模型显著优于开源模型，且性能与通用编程能力相关良好。", "innovation": "本文提出了一种基于强化学习（RL）的可验证奖励方法，确保生成可渲染的 SVG 有效内容，并通过强视觉编码器（例如 SigLIP 用于图文和 DINO 用于图图）对齐文本和渲染图像，从而提高了 SVG 生成的质量和语义，达到了与前沿系统相当的性能。此外，研究还分析了训练动力学，表明 RL 促使对象分解得更精细，且提供了提高场景连贯性的上下文细节。", "conclusion": "本文结果表明，符号图形编程提供了一个精确且可解释的多模态对齐的视角。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05144", "html_url": "https://arxiv.org/abs/2509.05144", "title": "SGS-3D: 高保真3D实例分割借助可靠语义掩码分割与生长", "title_en": "SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing", "authors": "Chaolei Wang,Yang Luo,Jing Du,Siyu Chen,Yiping Chen,Ting Han", "background": "在3D视觉领域，精确的3D实例分割是高质量场景理解的关键。然而，基于从2D到3D提升的方法在生成实例级别的分割时遇到困难，因为这个过程中引入的累积误差导致了语义指导不明确和深度约束不足的问题。", "innovation": "本文提出了Split and Grow Semantic Mask for High-fidelity 3D Instance Segmentation (SGS-3D) 算法，这是一种新颖的“分割-然后生长”框架，首先使用几何原语净化和分割不明确的提升掩码，然后在场景中将其生长为完整的实例。不同于现有依赖于原始提升掩码并牺牲分割准确性的方法，SGS-3D作为无需训练的细化方法，联合融合语义和几何信息，使得两个表示层次之间的合作更加有效。具体而言，通过引入掩码过滤策略，利用3D几何原语的共现性，识别并移除不明确的掩码，从而确保与3D物体实例的语义一致性。对于几何细化，通过利用空间连续性和高层次特征，特别是在不同物体之间的语义不确定性中，构建精细的物体实例。", "conclusion": "在ScanNet200、ScanNet++和KITT-360上的实验结果表明，SGS-3D显著提高了分割准确性和对预训练模型不准确掩码的鲁棒性，生成高保真的对象实例，并且在各种室内外环境中具有较强的泛化能力。代码包含在补充材料中。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05249", "html_url": "https://arxiv.org/abs/2509.05249", "title": "COGITAO: 视觉推理框架以研究组合性和泛化性", "title_en": "COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization", "authors": "Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe", "background": "人类智能的关键在于能够构建已学习的概念并在新的环境中应用，这一能力在现有的先进机器学习模型中仍存在局限性。为了应对这个问题，我们介绍了一种模块化和可扩展的数据生成框架和基准，用于系统地研究视觉领域中的组合性和泛化性。这种新的框架借鉴了ARC-AGI问题设置的灵感，构建了基于规则的任务，通过网格化环境中的对象应用一系列转换。", "innovation": "COGITAO框架能够构建包含成千上万种独特规则的任务，通过自定义格子参数化和对象属性来调整组合深度。该框架支持几乎无限数量的样本生成，并且提供了使用最先进的视觉模型进行基准测试的实验，展示了这些模型在面对熟悉元素的新组合时的一贯泛化失败情况。", "conclusion": "COGITAO是一个完全开源的项目，包括所有代码和数据集，旨在支持该领域的进一步研究。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05078", "html_url": "https://arxiv.org/abs/2509.05078", "title": "Scale-interaction transformer: 混合 CNN-Transformer 模型在面部美丽预测中的应用", "title_en": "Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction", "authors": "Djamel Eddine Boukhari", "background": "面部美丽预测（FBP）是计算机视觉中的一个挑战性任务，因为局部和全局面部特征的复杂交互影响人类的感知。卷积神经网络（CNNs）在特征提取方面表现出色，但它们往往在固定尺度下处理信息，可能会忽略不同粒度级别之间特征的关键依赖性。", "innovation": "为了应对这一局限性，本文引入了尺度交互变换器（SIT），这是一种新颖的混合深度学习架构，它结合了CNN的特征提取能力和Transformer的关联建模能力。SIT首先使用多尺度模块和并行卷积来捕获不同感受野下的面部特征，然后将这些多尺度表示形式视为序列并由Transformer编码器处理，该编码器通过自我注意机制明确地建模它们的交互和上下文关系。", "conclusion": "我们在广泛使用的SCUT-FBP5500基准数据集上进行了广泛的实验，其中提出的SIT模型建立了新的SOTA。它实现了皮尔逊相关系数0.9187，超过了先前的方法。我们的发现表明，明确建模多尺度视觉线索之间的交互对于高性能的FBP至关重要。SIT架构的成功表明混合CNN-Transformer模型对于需要整体、上下文感知理解的复杂图像回归任务具有潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04682", "html_url": "https://arxiv.org/abs/2509.04682", "title": "生态有效基准测试和自适应注意：可扩展的海洋生物声学监测", "title_en": "Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring", "authors": "Nicholas R. Rasmussen,Rodrigue Rizk,Longwei Wang,KC Santosh", "background": "水下被动声学监测(UPAM)提供了丰富的时空数据，助力长期生态分析，但固有的噪声和复杂的信号依赖性影响了模型的稳定性和泛化能力。多层次的窗口化虽改善了目标声音定位，但环境噪声、传播效应以及生物和人为噪声的混合来源引起了模式的不稳定性与多样性。这些因素要求具有鲁棒结构和严格评估的新架构。", "innovation": "提出了GetNetUPAM，一种分层嵌套交叉验证框架，用于在生态上现实的变量下量化模型的稳定性。数据被分段到不同的站点-年份段，确保验证折反映独特的环境子集，减少对局部噪声和传感器特征的过拟合。GetNetUPAM还提出了适应性分辨率池化和注意网络(ARPA-N)，该神经架构适用于不规则的频谱图维度。通过ARPA-N，基准测试结果得到增强，平均精度提高了14.4%，并且所有指标的变异性大幅降低，实现了跨站点和年份的有效检测，推进了可扩展且准确的生物声学监测。", "conclusion": "通过GetNetUPAM进行评估，ARPA-N表现优异，相比DenseNet基线，平均精度提高了14.4%，各项指标的变异性降低了两个数量级，实现了生态条件下的一致检测，为可扩展和准确的海洋生物声学监测提供了新的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05297", "html_url": "https://arxiv.org/abs/2509.05297", "title": "FlowSeek: 使用深度基础模型和运动基底使光流更易实现", "title_en": "FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases", "authors": "Matteo Poggi,Fabio Tosi", "background": "目前的光流模型需要大量的硬件资源进行训练，且大部分方法在多数据集上的迁移能力有限。FlowSeek 框架旨在降低这一训练需求，同时保持较高的性能。", "innovation": "FlowSeek 特点在于使用少量硬件资源进行训练，与现有方法相比，其硬件预算降低了约8倍。同时，该模型融合了最新的光流网络设计空间、单张图像深度基础模型和经典低维度运动参数化方法，形成了一个紧凑且准确的架构。实验结果显示，FlowSeek 在 Sintel Final 和 KITTI 数据集上的跨数据集泛化能力优于之前的最佳方法 SEA-RAFT，分别提高了10%和15%。此外，它也在 Spring 和 LayeredFlow 数据集上表现优异，与其相比具有相对优势。", "conclusion": "FlowSeek 通过减少硬件资源需求，仍然保持了出色的光流性能，实现了较低硬件预算下的高泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04734", "html_url": "https://arxiv.org/abs/2509.04734", "title": "Beyond I-Con: 探索表征学习中距离度量的新维度", "title_en": "Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning", "authors": "Jasmine Shone,Shaden Alshammari,Mark Hamilton,Zhening Li,William Freeman", "background": "研究表明，超过23种表征学习方法会隐式地最小化数据与学习到的概率分布之间的KL散度，以编码数据点之间的相似性。然而，基于KL散度的损失可能与真实目标不一致，KL散度的特点，如不对称性和无界性，也可能产生优化挑战。", "innovation": "提出Beyond I-Con框架，通过探索替代统计差异和相似性核来系统地发现新的损失函数。具体表现如下：(1) 在DINO-ViT嵌入的无监督聚类中，通过修改PMI算法使用总变差距离，达成最佳性能；(2) 在监督对比学习中，通过使用总变差距离和基于距离的相似性核替代KL散度和角度核，优于标准方法；(3) 在降维中，使用有界的f-散度替代KL散度，达到更优的定性和下游任务性能。", "conclusion": "研究结果强调在表征学习优化中考虑差异度量和相似度核选择的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04870", "html_url": "https://arxiv.org/abs/2509.04870", "title": "高分辨率遥感图像多模态不确定性鲁棒树覆盖分割", "title_en": "Multi-modal Uncertainty Robust Tree Cover Segmentation For High-Resolution Remote Sensing Images", "authors": "Yuanyuan Gui,Wei Li,Yinjian Wang,Xiang-Gen Xia,Mauro Marty,Christian Ginzler,Zuyuan Wang", "background": "近年来，多模态遥感图像的语义分割技术显著提高了树木覆盖图的准确性，支持城市规划、森林监测和生态评估等应用。不同模态数据（如光学影像、激光雷达和合成孔径雷达）的集成，尽管优于单一模态方法，但由于数据获取时间间隔长（数天甚至数月），其间可能发生的植被扰动（如采伐、野火）和成像质量变化，导致时间上的不一致性，增加了跨模态不确定性，特别是在高分辨率图像中，严重降低了分割精度。", "innovation": "我们提出了一种新颖的多模态分割框架——MURTreeFormer，以缓解和利用不确定性以实现鲁棒的树覆盖地表分割。该框架以一种模态为主，其他为辅，并通过概率潜表征显式建模辅助模态中的像素级不确定性。通过基于VAE的重采样机制，将不确定的像素从主要模态的分布中识别并重建，生成增强的辅助特征用于融合。在解码器中，集成梯度幅度注意力模块和轻量化细化头部，以引导注意力关注树状结构，并保持精细的空间细节。", "conclusion": "多模态数据集上的 extensive 实验显示，MURTreeFormer 显著提升了分割性能，并有效减少了由时间引入的随机不确定性的影响。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04677", "html_url": "https://arxiv.org/abs/2509.04677", "title": "图像的图结构推断用于图神经网络", "title_en": "Inferring the Graph Structure of Images for Graph Neural Networks", "authors": "Mayur S Gowda,John Shi,Augusto Santos,José M. F. Moura", "background": "图像数据集（如MNIST）是测试图神经网络（GNN）架构的重要基准。图像通常表示为网格图，每个节点代表一个像素，边连接相邻的像素（垂直和水平）。图信号是图像中每个像素的值（强度）。通常使用图作为输入到图神经网络（例如图卷积神经网络[1, 2]、图注意网络[3]、GatedGCN[4]等）来进行图像分类。本研究通过寻找不同于网格图和超像素方法的新图结构来表示数据集图像，以提高下游GNN任务的准确性，这借鉴了[5, 6]中的方法。研究中使用图像中的像素值之间的相关性来构建行相关性、列相关性以及乘积图的方法，并应用于MNIST和Fashion-MNIST数据集。实验表明，使用这些不同的图表示和特征作为下游GNN模型的输入可以提高准确度，相比传统的方法更为有效.", "innovation": "提出了一种新的方法，即基于图像像素值的相关性构建行相关图、列相关图和乘积图，作为图神经网络的输入，以此来改进图像分类模型的准确度，该方法相较于传统的网格图和超像素方法更为准确和有效.", "conclusion": "研究展示了使用行相关图、列相关图和乘积图作为输入，能提高图像分类模型的准确度。验证了所提出的新方法能够有效提升图神经网络在图像分类上的表现。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04849", "html_url": "https://arxiv.org/abs/2509.04849", "title": "基于直方图驱动振幅嵌入的量子位高效图像压缩方法", "title_en": "Histogram Driven Amplitude Embedding for Qubit Efficient Quantum Image Compression", "authors": "Sahil Tomar,Sandeep Kumar", "background": "本文介绍了一种使用近期量子设备压缩彩色图像的紧凑且硬件高效的算法。背景在于随着量子技术的发展，如何在保持图像清晰度的同时减少量子资源的使用，已成为量子图像处理领域的重要研究方向。现有的许多量子图像压缩方法在实现过程中需要较高的量子比特需求，这限制了其在实际量子设备上的应用。因此，本文旨在提出一种新的方法，通过直方图驱动的振幅嵌入，仅依赖于直方图分箱数来控制量子比特需求，从而减少对硬件资源的依赖。", "innovation": "该方法将图像段分为固定的像素块（称为bixels），计算每个块的总强度，并从这些块的强度中构建一个具有B个分箱的全局直方图。然后，对这些分箱计数的归一化平方根被编码为一个n量子位量子态的振幅。通过PennyLane实现振幅嵌入，并在真实的IBM量子硬件上执行。相较于传统的像素级编码，该方法展示了更好的量子位效率，并能够在较低的量子比特数（如5到7个量子比特）下实现高质量的图像恢复。", "conclusion": "本文提出的方法通过调整直方图分箱数B，能够在保持图像质量的同时有效控制资源使用。实验证明，在当前的中等规模量子系统阶段（NISQ时代），该方法能够实现显著优于传统编码方式的量子位效率，从而证实了该方法在当前实际量子系统的可行性与应用潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04834", "html_url": "https://arxiv.org/abs/2509.04834", "title": "TemporalFlowViz：理解冲压发动机燃烧演变的参数感知视觉分析", "title_en": "TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution", "authors": "Yifei Jia,Shiyu Cheng,Yu Dong,Guan Li,Dong Tian,Ruixiao Peng,Xuyi Lu,Yu Wang,Wei Yao,Guihua Shan", "background": "理解冲压发动机内的复杂燃烧动力学对于推动高速推进技术至关重要。然而，基于模拟生成的时间流场数据在规模和维度上的巨大特性，对于视觉解释、特征差异和案例间的跨案例比较构成了显著挑战。", "innovation": "本文介绍了一种名为TemporalFlowViz的参数感知视觉分析工作流和系统，旨在支持专家驱动的聚类、可视化和时间流场解释。该方法运用预训练的视觉变换器提取高维嵌入，通过降维和基于密度的聚类发现潜在的燃烧模式，并在嵌入空间中构建时间轨迹，以跟踪每一模拟随着时间的变化。同时，领域专家为代表聚类质心标注说明性标签，作为视觉语言模型的上下文提示，生成不同帧和完整模拟案例的自然语言摘要。系统还支持参数过滤、基于相似性的案例检索及多视图协调探索，以促进深入分析。", "conclusion": "通过两项专家驱动的案例研究和反馈，证明TemporalFlowViz能够增强假设生成、支持可解释模式发现，并在大规模冲压发动机燃烧分析中提升知识发现。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04719", "html_url": "https://arxiv.org/abs/2509.04719", "title": "STADI: 细粒度步长-块扩散并行性方法在异构GPU上的应用", "title_en": "STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs", "authors": "Han Liang,Jiahui Zhou,Zicheng Zhou,Xiaoxi Zhang,Xu Chen", "background": "扩散模型在图像生成等应用中的使用不断增多，要求高效的并行推理技术来应对巨大的计算成本。现有的扩散模型并行推理方案在异构多GPU环境中常常无法充分利用资源，因为不同硬件能力和后台任务导致的工作负载不平衡使得部分GPU资源无法得到有效利用。", "innovation": "提出了一种新的框架Spatio-Temporal Adaptive Diffusion Inference (STADI)，它利用混合调度器在时间和空间维度上进行细粒度的并行操作。在时间维度上，通过引入一种新的计算感知步长分配方法，并使用最小公倍数最小量化技术减少较慢GPU上的去噪步骤和执行同步。在空间维度上，STADI实现了一个可伸缩的块并行机制，根据GPU的计算能力分配不同大小的图像块，以确保通过补充的空间机制实现负载的平衡分配。实验验证了STADI的有效性，不仅能更好地平衡负载，还能显著减少性能瓶颈，与最先进的图像块并行方法相比，将端到端推理延迟降低了最多45%，显著提高了异构GPU的资源利用率", "conclusion": "STADI在异构GPU环境中实现了有效的负载平衡和性能优化，显著提升了扩散模型的推理性能和资源利用率。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04606", "html_url": "https://arxiv.org/abs/2509.04606", "title": "新模态高效集成到大型语言模型中的方法", "title_en": "Sample-efficient Integration of New Modalities into Large Language Models", "authors": "Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti", "background": "多模态基础模型能够处理多种模态。然而，由于可能模态的空间是大且不断变化的，从零开始训练模型以涵盖所有模态是不现实的。另外，将模态集成到预存的基础模型中需要大量配对数据，对于低资源模态来说，这些数据往往不可用。本研究讨论了大型语言模型(Large Language Models，LLMs)领域中如何有效集成新模态的问题。", "innovation": "本文提出了一个样本高效模态集成(Sample-efficient Modality Integration，SEMI)方法，通过设计一个超网络来适应共享投影器，该投影器位于模态特定编码器与LLM之间。超网络在高资源模态（如文本、语音、音频和视频）上进行训练，并在推断时根据少量任意模态的样本生成适配器。通过等距变换增加训练模态的数量。研究发现，SEMI在少量示例下集成新模态（如卫星图像、天文图像、惯性测量和分子）时表现出显著的样本效率提升，从而验证了SEMI方法的应用潜力，有望扩展基础模型的模态覆盖范围。例如，达到与32-shot SEMI相同准确性，从零开始训练投影器需要64倍多的数据。", "conclusion": "SEMI方法通过高效利用已有资源，显著提升了大型语言模型集成新模态的能力，扩展了基础模型的模态覆盖范围，具有广阔的应用前景。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04908", "html_url": "https://arxiv.org/abs/2509.04908", "title": "SparkUI-Parser：利用稳健定位与解析增强GUI感知", "title_en": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "authors": "Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao", "background": "现有的基于多模态大规模语言模型（MLLMs）的GUI感知方法虽然取得了很大进展，但仍存在一些挑战，包括：1) 依赖于文本自回归机制建模离散坐标，导致定位精度较低，推理速度较慢；2) 只能定位预定义的元素集，无法解析整个界面，限制了模型的广泛应用和对下游任务的支持。", "innovation": "提出了一种名为SparkUI-Parser的新型端到端框架，实现了更高级别的定位精度和界面整体的细粒度解析能力。通过在预训练的多模态大规模语言模型基础上增加额外的标记路由器和坐标解码器，进行基于坐标的连续建模，而不是基于概率的离散建模，从而有效缓解了MLLMs固有的离散输出特性和标记逐个生成过程的局限性，提升了准确性和推理速度。此外，引入基于修改后的匈牙利匹配算法的拒绝机制，使得模型能够识别并拒绝不存在的元素，从而减少误报。", "conclusion": "大量的实验表明，我们的方法在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse基准上的一致性上优于当前最先进的方法。资源可在以下链接获取：this https URL。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05031", "html_url": "https://arxiv.org/abs/2509.05031", "title": "基于Transformer注意力机制的指引导靶估计", "title_en": "Pointing-Guided Target Estimation via Transformer-Based Attention", "authors": "Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter", "background": "指示性手势，如指指点点，是人际非言语交流的基础形式，能够引导人类关注特定的对象或位置。这种能力在人机交互（HRI）中至关重要，因为机器人应能够预测人类的意图并做出适当的回应。", "innovation": "提出了一个多模态交互变换器（MM-ITF），这是一种模块化架构，能够在NICOL机器人介导的受控桌面场景中预测物体。MM-ITF利用跨模态注意机制，将2D指指点点手势映射到物体位置上，并对每个位置进行可能性评分，从而确定最有可能的目标。该方法能够在单目RGB数据上准确预测所指向的物体，从而实现直观且易于使用的机器人交互。", "conclusion": "通过引入斑块混淆矩阵来评估模型性能，可以对模型在候选物体位置上的预测结果有更深入的理解。研究结果表明，该方法能够准确预测人类所指的物体，从而促进直观的人机协作。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05146", "html_url": "https://arxiv.org/abs/2509.05146", "title": "PRIM: 向实用的图片内多语言机器翻译迈出一步", "title_en": "PRIM: Towards Practical In-Image Multilingual Machine Translation", "authors": "Yanzhi Tian,Zeming Liu,Zhengyang Liu,Chong Feng,Xin Li,Heyan Huang,Yuhang Guo", "background": "当前端到端的图片内机器翻译（IIMT）研究主要集中在合成数据上，这些数据背景简单、字体单一、文本位置固定且仅支持双语翻译，无法完全反映现实世界的情况，导致研究与实际应用条件之间存在较大差距。", "innovation": "本文介绍了实用的图片内多语言机器翻译（IIMMT），以解决研究与现实条件之间的差距。同时，通过标注PRIM数据集，包含具有复杂背景、多种字体、多种文本位置和多语言翻译方向的真实场景捕获的一行文本图片，来弥补公共数据的不足。还提出了一种端到端模型VisTrans来处理PRIM中的实际情况挑战，该模型分别处理图像中的视觉文本和背景信息，确保多语言翻译能力的同时提高视觉效果。", "conclusion": "实验结果表明，VisTrans在翻译质量和视觉效果方面都优于其他模型。代码和数据集可在以下链接获取：this https URL"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04819", "html_url": "https://arxiv.org/abs/2509.04819", "title": "AURAD：统一解剖与病理的逐步表示放射学合成", "title_en": "AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations", "authors": "Shuhan Ding,Jingjing Fu,Yu Gu,Naiteek Sangani,Mu Wei,Paul Vozila,Nan Liu,Jiang Bian,Hoifung Poon", "background": "医学图像合成已成为在数据稀少的临床环境中增强数据集和提高模型泛化能力的重要策略。然而，精细和可控的合成仍很困难，因为高质量注释的限制以及不同数据集之间的领域转移。现有的方法往往针对自然图像或明确定义的肿瘤设计，并且难以适应胸部X光片，这类图像中的疾病模式形态多样且与解剖结构紧密交织。因此，已有方法难以满足临床需求。", "innovation": "本文提出了一种控制放射学合成框架AURAD，能够联合生成高保真度的胸部X光片和伪语义掩码。不同于先前依赖随机采样掩码的方法，AURAD能够生成能够捕捉多病理共存和解剖-病理一致性的掩码。该方法采用逐步管线：首先从基于解剖结构的临床提示生成伪掩码，然后用于引导图像合成。此外，还利用预训练的专家医学模型来筛选输出以确保临床合理性。生成的掩码不仅在视感真实度方面有效，还能作为检测和分割等下游任务的标签，缩小生成模型与临床应用之间的差距。通过广泛的实验和盲评放射科医生评估表明，该方法在任务和数据集之间的有效性和泛化性得到验证。特别是在板认证放射科医生的评估中，有78%的合成图像被分类为真实的，并且超过40%的分割重叠预测被评为临床有用。", "conclusion": "AURAD方法在逐步表示框架下，能够有效实现胸部X光图像及其伪语义掩码的高保真度生成，且在下游任务中展现出高度的临床实用性和泛化性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04948", "html_url": "https://arxiv.org/abs/2509.04948", "title": "针对移动机器人的精确且有效的机器人视觉（移动机器人拓扑定位问题）", "title_en": "Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)", "authors": "Emanuela Boros", "background": "移动机器人中的拓扑定位是一个基本问题，因为机器人必须确定它们的位置以完成任务。视觉定位和场所识别因其感知不确定性、传感器噪声和照明变化而具有挑战性。这项工作利用安装在机器人平台上的透视彩色相机获取的图像，在办公室环境中解决拓扑定位问题，而不依赖于图像序列的时间连续性。评估了最先进的视觉描述符，包括颜色直方图、SIFT、ASIFT、RGB-SIFT和基于文本检索的词袋视觉单词方法。使用标准评估指标和可视化，分析了这些特征、距离度量和分类器的效果，扩展了先前的实验。结果显示，适当的外观描述符、相似性度量和分类器配置的优化是有利的，并进一步在ImageCLEF评价活动中验证了这些配置的质量，特别是在Robot Vision任务中，系统识别了新型图像序列的最可能位置。", "innovation": "本研究的创新之处在于系统地定量比较了最先进的视觉描述符、距离度量和分类器。实验结果展示了适当的特征、相似性度量和分类器配置的优势；并进一步在ImageCLEF评价活动中验证了这些配置的质量。未来的研究将探索层次模型、排名方法和特征组合，以构建更稳健的定位系统，同时减少训练时间和避免维度诅咒。", "conclusion": "最终，这旨在实现跨不同照明和更长轨迹的集成和实时定位。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05201", "html_url": "https://arxiv.org/abs/2509.05201", "title": "基于感知观察器的自主车辆鲁棒模型预测控制设计", "title_en": "Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers", "authors": "Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares", "background": "本文提出了一个鲁棒模型预测控制（MPC）框架，该框架专门用于处理深度学习感知模块在状态估计中固有的非高斯噪声。认识到对于安全反馈控制而言，感知模块的准确不确定性量化是关键因素，本文的方法突破了传统零均值噪声量化假设，采用基于集态的估计方法和约束zonotope来捕捉偏向性和重尾不确定性，同时保持有界估计误差。为了提高计算效率，鲁棒MPC被重新表述为线性规划（LP），使用Minkowski-Lyapunov成本函数以及附加松弛变量以避免退化问题。闭环稳定性通过Minkowski-Lyapunov不等式和契合的zonotope不变集确保。然后，通过zonotope的椭球近似来求得最大的稳定终止集合及其相应的反馈增益。", "innovation": "提出了一种融入感知模块、基于zonotope的鲁棒MPC框架，解决了非高斯噪声问题，优化了计算效率，并通过闭环稳定性验证和硬件实验验证了方法的有效性。", "conclusion": "该感知aware的MPC在重尾噪声条件下能够实现稳定的、精确的控制性能，与基于高斯噪声的传统设计相比，在估计误差边界和整体控制性能方面表现出显著优势。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05285", "html_url": "https://arxiv.org/abs/2509.05285", "title": "通过基于文本的生成图像编辑实现在区域基础上控制的3D场景风格化改进", "title_en": "Improved 3D Scene Stylization via Text-Guided Generative Image Editing with Region-Based Control", "authors": "Haruo Fujiwara,Yusuke Mukuta,Tatsuya Harada", "background": "近年来，基于文本驱动的3D场景编辑和风格化快速发展，显示出巨大的潜力。然而，保持高风格质量与视图一致性的平衡仍然具有挑战性。此外，对于具有语义对应关系的不同区域或对象实现一致的风格化也是一大难题。", "innovation": "本文提出了一种技术，增强了3D风格化质量，同时保持视图一致性和区域控制的风格转移。通过使用标定风格的多视角2D图像对初始3D表示重新训练，以及引入单参考.base注意力共享机制和网格多深度图作为单图像参考，强化了视图一致性。此外，提出了一种多区域重要加权切片Wasserstein距离损失，允许不同区域使用现成模型的分割掩膜应用风格。", "conclusion": "实验表明，本文方法在文本驱动的3D风格化中有效提高了图像生成结果的质量，并且通过可选功能增强了风格转移的忠实度，实现了不同场景区域的不同风格的混合。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04957", "html_url": "https://arxiv.org/abs/2509.04957", "title": "通过多种基础模型映射器实现高效的视频到音频生成", "title_en": "Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper", "authors": "Gehui Chen,Guan'an Wang,Xiaowen Huang,Jitao Sang", "background": "近年来，视频到音频（V2A）生成主要依赖于从视频中提取语义和时序特征来调控生成模型。从头开始训练这些模型资源密集。因此，利用基础模型（FMs）由于其跨模态的知识转移和泛化能力而变得重要。先前的工作探索了对一个轻量级的映射网络进行微调，以连接预训练的视觉编码器与文本到音频生成模型，从而进行V2A生成。", "innovation": "提出了一种新的映射器模型——多基础模型映射器（MFM-Mapper），该模型通过融合来自双视觉编码器的特征，获得了更丰富的语义和时序信息。相比之前的映射网络方法，MFM-Mapper使用GPT-2替代了线性映射器，提高了特征对齐，类比了跨模态特征映射和自回归翻译任务。MFM-Mapper表现出显著的训练效率，使用更少的训练资源实现了良好的语义和时序一致性，所需训练规模仅为之前方法的16%，但性能却能与在更大规模数据上训练的模型相当。", "conclusion": "MFM-Mapper不仅提升了V2A生成的语义和时序一致性，还展示了卓越的训练效率，只需少量训练数据即可达到与大规模训练模型相当的性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.03325", "html_url": "https://arxiv.org/abs/2312.03325", "title": "FAGC:在先验形空间上沿测地线曲线的特征增强方法", "title_en": "FAGC:Feature Augmentation on Geodesic Curve in the Pre-Shape Space", "authors": "Yuexing Han,Gan Hu,Guanxin Wan,Bing Wang", "background": "由于训练数据量的限制，模型的表现受到了制约，因此数据增强已经成为深度学习中不可或缺的技术。然而，现有的大多数数据增强方法存在信息损失的问题，在小样本场景中的表现较差，限制了它们的应用范围。为了克服这一限制，我们提出了一种在先验形空间中基于测地线曲线的特征增强方法，称为FAGC（Feature Augmentation on Geodesic Curve）。首先，使用预训练的神经网络模型从输入图像中提取特征。然后，在去除位置和尺度信息后，将图像特征作为向量投影到先验形空间。在先验形空间中，构造一个最优的测地线曲线来拟合特征向量。最后，通过在所构建的测地线曲线上进行插值生成新的特征向量，以便模型学习。我们进行了广泛的实验以证明FAGC的有效性和多用途性。结果表明，将FAGC应用于深度学习或机器学习方法，在小样本任务下的性能显著提升。", "innovation": "提出了一种在先验形空间中基于测地线曲线的特征增强方法FAGC（Feature Augmentation on Geodesic Curve），通过去除图像位置和尺度信息，将特征向量投影到先验形空间，并在其上构造最优的测地线曲线，进而通过插值生成新的特征向量，专门用于改善小样本学习场景下的模型性能。", "conclusion": "研究表明，将FAGC应用于深度学习或机器学习方法，可以显著提高这些方法在小样本任务上的性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.09677", "html_url": "https://arxiv.org/abs/2208.09677", "title": "Net2Brain: 一个将人工视觉模型与人类大脑反应进行比较的工具箱", "title_en": "Net2Brain: A Toolbox to compare artificial vision models with human brain responses", "authors": "Domenic Bersch,Kshitij Dwivedi,Martina Vilas,Radoslaw M. Cichy,Gemma Roig", "background": "目前不同的工具箱只能支持单一功能或仅专注少数监督图像分类模型。Net2Brain 提供了一个图形化和命令行界面工具箱，能够提取超过600个经过不同视觉任务训练的深层神经网络的激活，这些任务包括语义分割、深度估计、动作识别等。该工具箱计算这些激活的表示差异矩阵（RDMs），并利用表示相似性分析（RSA）和加权 RSA 来与大脑记录进行比较，可以在特定的皮层区域或使用搜索光束搜索来完成这一过程。此外，用户还可以添加新的刺激数据集和大脑记录，用于工具箱评估。这些功能说明了 Net2Brain 在认知计算神经科学领域测试假说时的应用潜力，但问题在于不能覆盖所有类型的神经网络模型和任务.", "innovation": "Net2Brain 的创新在于它可以跨多种视觉相关的任务，处理和比较多种人工深层神经网络的表示空间和人类大脑记录的数据，使用多种先进的表示相似性分析方法，例如 RDM、加权 RSA，并支持用户构建自己的数据集进行评估。传统的工具箱只能支持单一功能或仅专注少数监督图像分类模型。", "conclusion": "Net2Brain 工具箱展示了在认知计算神经科学领域测试假说的应用潜力，通过图形化和命令行界面，能够灵活地处理和比较深层神经网络的激活与人脑反应，提供了一种新的研究手段。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.05750", "html_url": "https://arxiv.org/abs/2408.05750", "title": "FADE: 用于视频中建筑物周围掉落物体检测的数据集", "title_en": "FADE: A Dataset for Detecting Falling Objects around Buildings in Video", "authors": "Zhigang Tu,Zhengbo Zhang,Zitao Gao,Chunluan Zhou,Junsong Yuan,Bo Du", "background": "日常生活中，物体从建筑物掉落是一个常见的事件，它会对行人造成严重的伤害，因为掉落物产生的冲击力较大。安装在建筑物周围的监控摄像头可以用来探测掉落的物体，但对这类监测仍然存在挑战，因为掉落物往往体积小且运动速度快。此外，关于建筑物周围掉落物体检测（FODB）的领域缺乏大规模的数据集用于训练基于学习的方法，并且缺乏标准化的评估标准。", "innovation": "本文提出了一种名为FADE的大型且多样化的视频基准数据集，旨在解决这些挑战。FADE包含了2,611个视频来自25个场景，涉及8类掉落物、4种天气条件和4种视频分辨率。此外，还开发了一种新型的检测方法，有效利用了运动信息生成小但高质量的检测提议。该方法的效果在提议的FADE数据集上与通用物体检测、视频物体检测和移动物体检测的最新方法进行了比较。", "conclusion": "该研究通过提供FADE数据集和开发了创新的方法，提高了建筑物周围掉落物体检测的能力，并且为该领域的标准化评估提供了新的标准。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05154", "html_url": "https://arxiv.org/abs/2509.05154", "title": "VLSM-Ensemble: 使用基于CLIP的视觉语言模型优化医学图像分割", "title_en": "VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation", "authors": "Julia Dietlmeier,Oluwabukola Grace Adegboro,Vayangi Ganepola,Claudia Mazo,Noel E. O'Connor", "background": "视觉语言模型及其对图像分割任务的适应性显示出的巨大潜力使其能生成高准确性和可解释性结果。尽管基于CLIP和BiomedCLIP的实现尚未达到更复杂的架构如CRIS的水平，但本研究并未关注文本提示工程，而是通过将低复杂性的CNN与视觉语言分割模型（VLSMs）联合，以减小这种差距。这种方法在BKAI息肉数据集上使BiomedCLIPSeg的成绩显著提高6.3%，其他数据集也有不同程度的提升，显示出不同程度的结果改善。", "innovation": "研究创新在于通过结合低复杂性的CNN与VLSMs，实现了在BKAI息肉数据集上的显著成绩提升，且其他数据集也取得了不同程度的进步。此外，研究还展示了对四个医学和非医学图像的新数据集的初步结果，指出跨不同数据集(从超过CRIS模型到低于CRIS模型)的联合效果差异，为进一步的研究提供了方向。", "conclusion": "研究得出，联合效果在不同数据集上表现不一致，这表明未来社区的研究应在这一领域寻找更多线索。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.11686", "html_url": "https://arxiv.org/abs/2409.11686", "title": "通过机会性成像自动检测未诊断的医疗条件", "title_en": "Automated detection of underdiagnosed medical conditions via opportunistic imaging", "authors": "Asad Aali,Andrew Johnston,Louis Blankemeier,Dave Van Veen,Laura T Derry,David Svec,Jason Hom,Robert D. Boutin,Akshay S. Chaudhari", "background": "腹部CT扫描在临床环境中频繁使用。机会性CT是指利用常规CT图像进行二次诊断，以发现未诊断的情况如肌肉减少症、肝脏脂肪变性和腹水等。本研究利用深度学习方法，分析了2,674份住院CT图像，发现这些诊断通过机会性成像或放射报告得出，但只有少部分被ICD编码，这表明机会性CT有助于提高诊断精度和风险调整模型的准确性。", "innovation": "本研究利用深度学习方法，自动检测未被充分诊断的医疗条件，特别是通过机会性成像技术。结果显示，只有0.5%的肌肉减少症、3.2%的肝脏脂肪变性和30.7%的腹水诊断没有得到ICD编码，这进一步证明了机会性CT在提高诊断精度和风险调整模型准确性方面的潜力。", "conclusion": "本研究发现机会性CT具有提高诊断精度和风险调整模型准确性的潜力，这对于精准医疗的发展具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.11813", "html_url": "https://arxiv.org/abs/2408.11813", "title": "SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs", "title_en": "SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs", "authors": "Yuanyang Yin,Yaqi Zhao,Yajie Zhang,Yuanxing Zhang,Ke Lin,Jiahao Wang,Xin Tao,Pengfei Wan,Wentao Zhang,Feng Zhao", "background": "现有的多模态大型语言模型（MLLMs）通过整合视觉和文本输入展现了出色的能力，但模态对齐仍然是一个最具挑战性的方面。当前的MLLMs通常依赖简单的适配器架构和预训练方法来连接视觉编码器与大型语言模型（LLM），并且主要依靠图像级别的监督进行引导。这种模式往往导致模态之间的对齐不够理想，显著限制了LLM对视觉特征的解释和推理能力，特别是对于较小的模型而言，这种影响更为明显。", "innovation": "本文提出了监督嵌入对齐（SEA）方法，这是一种在预训练过程中在token级别实现视觉-文本对齐的方法，能够减轻上述问题，并且SEA引入了最小的计算开销，同时保留了语言能力，并显著提升了跨模态的理解能力。此外，SEA还从多个方面揭示了适配器在多模态集成中的作用，并通过大量实验表明SEA在各种模型大小中都提高了性能，特别是在小型模型上表现更为突出（平均性能提升7.61%的Gemma-2B模型）。", "conclusion": "这项工作为未来多模态系统的模态对齐策略的开发奠定了基础，SEA能够在预训练过程中更精确地实现视觉-文本对齐，同时保持语言能力，从而提高了跨模态理解能力。尽管目前SE主要为MLLMs的预训练设计，但其理念可以拓展应用于其他多模态系统。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.17784", "html_url": "https://arxiv.org/abs/2411.17784", "title": "HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation", "title_en": "HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation", "authors": "Lingxiao Li,Kaixuan Fan,Boqing Gong,Xiangyu Yue", "background": "Few-shot image generation旨在仅给定某个未见过的类别中少量实例的情况下，生成该类的多样且高质量的图像。这一任务的关键挑战是平衡类别一致性和图像多样性，两者常常互相冲突。此外，现有方法对新生成图像的属性控制有限。", "innovation": "提出了一种名为Hyperbolic Diffusion Autoencoders (HypDAE)的新颖方法，它利用双曲空间来捕获已见类别间的关系。通过调整半径或语义代码，HypDAE能够生成高质量的未见类群多样新图像，同时提供了额外的度量以控制语义多样性。", "conclusion": "大量实验和可视化结果表明，HypDAE在有限数据下实现了类别相关特征的保护和图像多样性的促进间的更佳平衡，并显著优于先前的方法。此外，HypDAE还提供了高度可控和可解释的生成过程。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.17541", "html_url": "https://arxiv.org/abs/2412.17541", "title": "基于深度学习的可解释性人脸识别反欺骗中的欺骗踪迹发现", "title_en": "Spoof Trace Discovery for Deep Learning Based Explainable Face Anti-Spoofing", "authors": "Haoyuan Zhang,Xiangyu Zhu,Li Gao,Jiawei Pan,Kai Pang,Guoying Zhao,Zhen Lei", "background": "随着人脸识别在人们日常生活中的广泛应用，反欺骗技术变得日益重要，以避免恶意攻击。现有的反欺骗模型可以在多个数据集上达到较高的分类准确性，但这些模型只能判断‘这是一个假脸’，而不能解释‘为什么它是假的’。这种系统损害了系统的可信度，导致用户的混淆，因为他们没有得到任何解释。因此，本文旨在融入可解释性人工智能（XAI）到人脸识别反欺骗中，提出了一个新的问题，称为X-FAS（可解释的人脸反欺骗），使反欺骗模型能够提供解释。", "innovation": "本文提出了SPTD（SPoof Trace Discovery）方法，这是一种X-FAS方法，可以在发现的概念基础上发现欺骗概念并提供可靠的解释。为了评估X-FAS方法的质量，本文提出了一个由专家注释的X-FAS基准，并在该基准上对SPTD的解释进行了分析，同时与提出的X-FAS基准上的先前XAI方法进行了定量和定性的比较。", "conclusion": "实验结果表明SPTD具有生成可靠解释的能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14484", "html_url": "https://arxiv.org/abs/2412.14484", "title": "DirectorLLM for Human-Centric Video Generation", "title_en": "DirectorLLM for Human-Centric Video Generation", "authors": "Kunpeng Song,Tingbo Hou,Zecheng He,Haoyu Ma,Jialiang Wang,Animesh Sinha,Sam Tsai,Yaqiao Luo,Xiaoliang Dai,Li Chen,Xide Xia,Peizhao Zhang,Peter Vajda,Ahmed Elgammal,Felix Juefei-Xu", "background": "随着基础的文本到视频模型迅速发展，对高质量的人体动作和互动的需求也在增加。为了满足这一需求并提高人体动作的真实感，研究人员将大型语言模型（LLM）从纯文本生成扩展为视频导演和人体动作模拟器，以引导视频生成。利用开源的Llama 3资源，他们培训DirectorLLM生成人体姿态等详细指导信号，从而为视频生成提供结构。这些信号作为渲染器的条件，帮助生成更真实和响应提示的视频。该独立的LLM模块可以应用于不同的视频渲染器，如UNet和DiT，实现更流畅的过渡。", "innovation": "该研究引入了DirectorLLM，这是一种新的视频生成模型，使用大型语言模型来调度视频中的人体姿态。通过利用Llama 3的开源资源，研究团队成功训练DirectorLLM生成详细的人体动作和互动信号，这些信号可以指导视频的生成。这一方法将人体运动的模拟从视频生成器转移到语言模型上，有效地创建了以人体为中心场景的信息框架。此外，该模型可以独立应用于不同的视频渲染器上，只需少量调整。", "conclusion": "实验结果表明，与现有模型相比，该模型在生成具有更高人体动作保真度、增强的提示忠实性和提高渲染主体自然度的视频方面表现更优秀。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.06897", "html_url": "https://arxiv.org/abs/2501.06897", "title": "ActiveGAMER：高效的渲染驱动主动GAussian建图", "title_en": "ActiveGAMER: Active GAussian Mapping through Efficient Rendering", "authors": "Liyan Chen,Huangying Zhan,Kevin Chen,Xiangyu Xu,Qingan Yan,Changjiang Cai,Yi Xu", "background": "传统的基于NeRF的方法在进行高精度、实时场景建模和探索时存在计算需求高和限制性的问题。这些方法难以适应复杂环境的主动探索需求。", "innovation": "该系统利用3D Gaussian Splatting（3DGS）技术实现高效、实时的场景建模与探索。核心是基于渲染的信息增益模块，动态识别最优视点用于下一步最佳视图规划，提升了几何和光度重建的准确性。系统结合了从粗到细的探索、后处理细化以及全局和局部关键帧选择策略，最大化重建的完整性和精度。", "conclusion": "该系统自主探索并重建环境，达到了几何和光度上的高度准确性和完整性，显著超越了现有方法。实验结果证明，ActiveGAMER在 Replica 和 MP3D 标准数据集上的表现非常有效。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06378", "html_url": "https://arxiv.org/abs/2411.06378", "title": "PKF: Probabilistic Data Association Kalman Filter for Multi-Object Tracking", "title_en": "PKF: Probabilistic Data Association Kalman Filter for Multi-Object Tracking", "authors": "Hanwen Cao,George J. Pappas,Nikolay Atanasov", "background": "本文探讨了在测量和状态之间引入概率性数据关联的新卡尔曼滤波器，通过变分推理方法近似状态的后验密度。未知的数据关联被视作一个潜在变量，并使用期望最大化（EM）算法进行处理，得到一个更新步长形式与常规卡尔曼滤波器一致的新滤波器，但其测量向量扩展到了所有可能的关联。评估概率使用测量似然性矩阵的行列式计算。此外，还提出了一种模糊性检查方法，通过概率的方式仅关联部分模糊的测量和状态，这可以减少关联时间并避免低概率测量影响估计精度。实验表明，与广为人知的联合概率数据关联滤波器（JPDAF）相比，本文提出的滤波器具有较低的跟踪误差，且具有相似的速度。在多个真实世界的数据集（如MOT17，MOT20，DanceTrack上），本文方法也证明在多人目标跟踪中具有更好的高于准确度（HOTA），并且依然保持实时性。对于仅基于边界框的目标跟踪，本文方法在MOT17和MOT20两个数据集上均排名前十（以HOTA评价）。给定离线检测，本文算法在单核CPU上可以达到250fps以上的跟踪速度。", "innovation": "引入了一种概率数据关联卡尔曼滤波器（PKF），通过变分推理方法和期望最大化算法来近似状态的后验密度；提出了使用测量似然性矩阵行列式计算概率的方法；并且提出了模糊性检查方法，在不增加数据特征或速度信息的情况下提高跟踪准确性，同时保持实时性。这种方法在多个真实世界的数据集和多人目标跟踪任务中的表现优于现有的卡尔曼滤波方法。", "conclusion": "本文提出的方法，即使不使用深度特征或速度信息，仅基于边界框目标跟踪，在MOT17和MOT20两个数据集上也展示了顶级的表现，并且在单核CPU上可以实现250fps以上的跟踪实时性。此外，在多人目标跟踪中，该方法不仅在跟踪准确度（HOTA）上表现优异，而且具有与现有JPDAF相近的速度。本文的工作为高精度的实时多人目标跟踪提供了有效的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05086", "html_url": "https://arxiv.org/abs/2509.05086", "title": "Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers", "title_en": "Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers", "authors": "Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner", "background": "对抗攻击是提升卷积神经网络（CNNs）鲁棒性的一大难题，通常需要消耗大量资源的对策。研究团队探索了稀疏混合专家层（sparse MoE）在提升CNNs鲁棒性方面的应用，通过在选定的残差块或卷积层中替换MoE层来增加模型容量，而不增加推理成本。", "innovation": "在ResNet架构上训练于CIFAR-100的数据集时，研究团队将单一MoE层插入到更深的阶段，在结合对抗训练时，能够一贯地提高模型在PGD和AutoPGD攻击下的鲁棒性。此外，引入开关损失平衡时，会导致路由集中在少量过度使用的专家上，使对抗训练集中在此路径上，意外地提高了这些路径的鲁棒性。结果表明，一些单独的专家表现优于门控MoE模型，表明通过专业化产生了鲁棒子路径。", "conclusion": "研究结果表明，稀疏MoE层在CNN中的应用提升了模型对抗对抗攻击的鲁棒性，并通过专业化产生了鲁棒子路径；同时，发现开关损失引发了路由集中到少数过度使用的专家，反而提高了那些路径的鲁棒性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.03544", "html_url": "https://arxiv.org/abs/2501.03544", "title": "PromptGuard：一种基于软提示的安全内容过滤方法用于文本到图像模型", "title_en": "PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models", "authors": "Lingzhi Yuan,Xinfeng Li,Chejian Xu,Guanhong Tao,Xiaojun Jia,Yihao Huang,Wei Dong,Yang Liu,Bo Li", "background": "最近的文本到图像(T2I)模型在从文本描述生成高质量图像方面表现出色。然而，这些模型容易被滥用，特别是生成不适合工作环境（NSFW，Not Safe For Work）的内容，如色情、暴力、政治和令人不安的图像，这引发了严重的伦理问题。现有的文本到图像模型缺乏直接机制来执行行为规范，而大型语言模型（LLMs）则有系统提示机制来促进安全对齐。但在T2I模型中，没有这样的直接接口来实现这一点。因此，需要一种新的方法来确保图像生成的安全性而不影响模型的性能。", "innovation": "本文提出了一种名为PromptGuard的新颖内容过滤技术，该技术借鉴了大型语言模型中的系统提示机制来实现安全对齐。该方法通过优化一个作为T2I模型文本嵌入空间中的隐式系统提示的“安全软提示”(P*)，直接过滤NSFW输入，从而实现安全且真实的图像生成，同时不会影响推断效率或需要代理模型。此外，研究者通过分而治之策略，优化类别特定的软提示并将其组合成整体安全指导，进一步增强了可靠性和帮助性。实验结果显示，PromptGuard在五个数据集上有效地缓解了NSFW内容生成，同时保留了高质量的良性输出，比之前的过滤方法快3.8倍，最优的不安全内容比例降低至5.84%，并且超越了现有的八种最佳防御方法。", "conclusion": "通过实验证明，PromptGuard可以在保证高质量图像生成的同时，有效地筛除NSFW内容，并且比现有方法更高效，为文本到图像模型的安全应用提供了新的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2205.02071", "html_url": "https://arxiv.org/abs/2205.02071", "title": "基于表示的骨架动作识别综述及ANUBIS基准", "title_en": "Representation-Centric Survey of Skeletal Action Recognition and the ANUBIS Benchmark", "authors": "Yang Liu,Jiyao Yang,Madhawa Perera,Pan Ji,Dongwoo Kim,Min Xu,Tianyang Wang,Saeed Anwar,Tom Gedeon,Lei Wang,Zhenyue Qin", "background": "基于3D骨架的人类动作识别已成为一种强大的替代方法，与传统的RGB和深度方法相比，它能够应对环境变化、计算效率较高并增强了隐私性。尽管取得了显著进展，但现有的研究仍然分布在多样化的输入表示上，并且缺乏反映现代现实挑战场景的评估方法。目前缺乏一个涵盖了多种特征类型的全面系统调查，这阻碍了该领域的发展。当前基准测试的数据集在多视角、复杂多人交互、细粒度动作以及现代社会行为等方面存在明显不足，无法全面反映现代的挑战。", "innovation": "本文提供了基于表示的骨架动作识别的系统综述，详细分类当前先进的方法，并探讨了输入特征类型如何影响空间时间建模策略。为了填补现有基准的空白，论文引入了ANUBIS这一大规模具有挑战性的骨架动作数据集，该数据集集成了多视角录制、复杂的多人群交互、细粒度及暴力动作，并能够反映现代社会行为。通过在ANUBIS数据集上对多种最先进的模型进行基准测试，全面分析不同特征类型对识别性能的影响，揭示了动作特征依赖性和简单多表征融合的局限性，指出了任务感知、语义对齐集成策略的必要性。这项工作为未来的基于骨架的通用动作识别系统提供了坚实的基础和实用的基准数据集，帮助实现对复杂情景的稳健识别。", "conclusion": "本文不仅提供了一个全面的基础，还提供了一个实用的基准数据集，旨在指导下一代基于骨骼的动作识别系统的发展，使其能够在复杂的现实场景下具有稳健性及通用性。通过在ANUBIS数据集上的基准测试和深入分析，本文揭示了动作特征依赖性和多表征融合的局限性，指向了任务感知及语义对齐的集成策略的必要性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.14346", "html_url": "https://arxiv.org/abs/2503.14346", "title": "3D Densification for Multi-Map Monocular VSLAM in Endoscopy", "title_en": "3D Densification for Multi-Map Monocular VSLAM in Endoscopy", "authors": "X. Anadón,Javier Rodríguez-Puigvert,J.M.M. Montiel", "background": "传统的稀疏多地图单目视觉同时定位与建图（Sparse Multi-map Monocular Visual SLAM）方法在内窥镜序列中经常由于运动模糊、时间遮挡、工具互动或水枪导致的频繁丢失难以稳定跟踪。稀疏多地图对于稳定摄像机定位是合适的，但环境表示效果差，噪声大，存在大量不准确的3D点，包括显著的离群值，并且对于临床应用来说3D点密度太低。", "innovation": "本文提出了一种去除离群值并细化最先进的稀疏内窥镜多地图CUDA-SIFT-SLAM方法的稀疏子地图的方法。通过鲁棒到错误的LMedS对稀疏CUDA-SIFT子地图和NN LightDepth进行对齐，解决了单目深度估计的固有缩放模糊问题，同时过滤掉了离群值，从而生成可靠且细化的3D地图。", "conclusion": "实验结果在C3VD假体结肠数据集中显示了4.15 mm RMS准确度的细化3D地图，并且在可接受的计算时间内提供了定性结果，基于Endomapper数据集的真实结肠内镜检查结果。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19065", "html_url": "https://arxiv.org/abs/2503.19065", "title": "WikiAutoGen: 向多模态维基风格文章生成迈进", "title_en": "WikiAutoGen: Towards Multi-Modal Wikipedia-Style Article Generation", "authors": "Zhongyu Yang,Jun Chen,Dannong Xu,Junjie Fei,Xiaoqian Shen,Liangbing Zhao,Chun-Mei Feng,Mohamed Elhoseiny", "background": "知识发现和收集是高度智能的任务，通常需要大量的人工努力才能保证高质量的输出。近年来，研究探索了多智能体框架来自动创建维基百科风格的文章，通过从互联网检索和综合信息来自动化这一过程。然而，这些方法主要集中在文本生成上，忽视了多模态内容（如文本和图像的结合）在提高信息量和吸引读者方面的重要性。", "innovation": "本文介绍了WikiAutoGen，一种新颖的自动多模态维基百科风格文章生成系统。与之前的系统不同，WikiAutoGen不仅检索和文本相结合的文本信息，还检索和整合相关图像，兼具更深入的信息和视觉吸引力。此外，提出了多视角自我反思机制，从不同角度批评检索到的内容，增强可信度、广度和连贯性等。还引入了WikiSeek基准，包括配有文本和图像表示的维基百科文章，用于评估更具挑战性的主题的多模态知识生成。", "conclusion": "实验结果显示，WikiAutoGen在我们的WikiSeek基准测试中比之前的任何方法都高出8%-29%，生成了更准确、连贯且视觉丰富的维基百科风格文章。相关代码和示例可在以下链接访问：this https URL"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.00204", "html_url": "https://arxiv.org/abs/2504.00204", "title": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024", "title_en": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024", "authors": "Rustam Tagiew(1),Ilkay Wunderlich(2),Mark Sastuba(1),Kilian Göller(3),Steffen Seitz(3) ((1) German Centre for Rail Traffic Research at the Federal Railway Authority, (2) EYYES GmbH, (3) Conrad Zuse School of Embedded Composite AI and the Chair of Fundamentals of Electrical Engineering of Dresden University of Technology)", "background": "自动驾驶列车在开放轨道上的城市引导运输和主干铁路上运行需要自动检测轨道周围危险区域的实际和潜在障碍物，特别是人类。机器学习算法在这方面已经被证明是强有力的工具。但这些算法需要大量的高质量带有人类主体标注的数据进行训练，而目前公开可用的数据集在数量和质量上仍然不足，尤其是在铁路领域。", "innovation": "本文介绍了RailGoerl24数据集，这是一个由位于德国格尔劳茨的TÜV SÜD Rail铁路测试中心采集的12205帧全高清车载视觉光数据集，包括路边LiDAR扫描覆盖的区域。该数据集包含总计33556个框标注的人类类别的标注，支持无人驾驶列车在引导运输中的发展。", "conclusion": "该数据集可用于支持无人驾驶列车操作的发展，并可用于超出碰撞预测的任务。此数据集可在此链接获取：this http URL"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05263", "html_url": "https://arxiv.org/abs/2509.05263", "title": "LatticeWorld: 一种由多模态大语言模型赋能的交互复杂世界生成框架", "title_en": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "authors": "Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu", "background": "近年来，研究越来越集中在开发模拟复杂现实场景的3D世界模型上。这些世界模型在嵌入式AI、自动驾驶、娱乐等领域找到了广泛的应用。更加真实的模拟和精确的物理将有效地缩小模拟与现实之间的差距，并使得我们能够方便地获得丰富的现实世界信息。传统的手工建模方法能够创建虚拟3D场景，而现代方法则利用了先进的机器学习算法进行3D世界生成，其中最近的进展主要集中在能够根据用户指令生成虚拟世界的生成方法上。这项工作通过提出LatticeWorld框架，旨在简化工业生产中的3D环境生成流程。LatticeWorld利用轻量级的LLM（如LLaMA-2-7B）和行业级的渲染引擎（例如Unreal Engine 5）来生成动态环境。该框架接受文本描述和视觉指令的多模态输入，生成具有大量动态代理的大规模3D互动世界，具备竞争力的多代理交互、高保真物理模拟和实时渲染特性。", "innovation": "LatticeWorld 提出了一种结合了轻量级的大语言模型和行业级渲染引擎的简单有效的3D世界生成框架。它能够根据用户的文本描述和视觉指令多模态输入生成大规模的、具有复杂交互的3D世界，且在保持高创作质量的同时提升了工业生产效率达90倍以上，并且能够精确生成场景布局和视觉质量。这种结合方法有助于加快3D环境的生成过程和增强互动性，为虚拟世界中的多用户交互提供了新的解决方案。", "conclusion": "LatticeWorld通过结合轻量级大语言模型和行业级渲染引擎，展示了高效的3D世界生成能力，能够在工业环境中高效且高质量地生成复杂交互的3D世界。实验表明，LatticeWorld在场景布局生成和视觉保真度方面表现出色，并且在工业生产效率上有了显著提升。这种框架为3D世界模型在模拟和交互性方面的发展提供了新思路。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20309", "html_url": "https://arxiv.org/abs/2503.20309", "title": "面向指令的偏好对准以增强MLLMs的多模态理解能力", "title_en": "Instruction-Oriented Preference Alignment for Enhancing Multi-Modal Comprehension Capability of MLLMs", "authors": "Zitian Wang,Yue Liao,Kang Rong,Fengyun Rao,Yibo Yang,Si Liu", "background": "多模态大型语言模型（MLLMs）在经过监督微调后，偏好对准已成为提升其性能的有效策略。然而，现有的偏好对准方法主要关注生成幻觉因素，忽视了对于多模态理解能力至关重要的因素。这导致了它们在幻觉缓解方面的改进并不显著。", "innovation": "本文提出了一种名为指令导向偏好对准（IPA）的方法，这是一种可扩展的框架，旨在通过指令实现效率自动构建偏好。IPA包括自动偏好构建和专用验证过程，以识别与指令导向相关的因素，从而避免了响应表示中的显著变异性。此外，IPA还包含了一个渐进的偏好收集管道，在模型自我进化和参考导向优化的帮助下，逐步召回更具挑战性的样本。实验结果表明，IPA在幻觉评估、视觉问答和文本理解任务等多个基准上均表现出有效性，证明了其提升模型一般理解能力的能力。", "conclusion": "实验结果表明，IPA在多个基准上有效，包括幻觉评估、视觉问答和文本理解任务，显示了其增强通用理解能力的能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05814", "html_url": "https://arxiv.org/abs/2507.05814", "title": "利用统一合成框架填补数据缺口赋能桥梁数字孪生", "title_en": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework", "authors": "Wang Wang,Mingyu Shi,Jun Jiang,Wenqian Ma,Chong Liu,Yasutaka Narazaki,Xuguang Wang", "background": "桥梁作为关键的交通基础设施，正面临着加速的老化和腐蚀带来的挑战。传统的手动检查方法效率低。虽然3D点云技术提供了新的数据驱动范式，但其应用潜力受限于现实世界数据的不完整性，这源于缺失的标签和扫描遮挡。现有合成数据方法在通用性上存在瓶颈，因此提出了一种系统框架来生成3D桥梁数据，旨在解决这一问题并产生更高质量的合成数据集，以支持分割和完成网络的训练。", "innovation": "提出了一种新的系统框架，用于生成3D桥梁数据，可以自动生成标记良好、高保真度颜色和精确法向量的完整点云。此外，该框架能够进一步模拟生成各种物理上现实的不完整点云，以支持分割和完成任务的训练。实验证明，使用本文合成数据训练的PointNet++模型在真实桥梁语义分割中达到了84.2%的平均交并比。此外，微调后的KT-Net在部件恢复任务上表现出色。", "conclusion": "该研究提供了3D桥梁结构视觉分析的创新方法和基础数据集，对于推进基础设施的自动化管理和维护具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10605", "html_url": "https://arxiv.org/abs/2506.10605", "title": "使用预训练潜层扩散模型从WiFi CSI生成高分辨率高效图像", "title_en": "High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model", "authors": "Eshan Ramesh,Takayuki Nishio", "background": "传统的基于WiFi信道状态信息(CSI)生成图像的方法通常依赖于复杂且计算密集的技术，如生成对抗网络(GANs)，这些方法在生成高分辨率图像时效率较低且难以控制。本研究旨在提出一个新颖的方法，与上述方法不同，本研究提出的方法使用一个轻量级的神经网络直接将CSI幅度映射到潜层扩散模型(LDM)的潜层空间，而不经过复杂的图像编码阶段，从而在保持计算效率和感知质量的同时提供文本引导的控制能力。本研究在一个自收集的宽带CSI数据集和MM-Fi数据集的部分数据集上验证了其方法的有效性。", "innovation": "提出了一种名为LatentCSI的新方法，通过使用预训练的潜在扩散模型(LDM)，直接将CSI幅度映射到LDM的潜层空间，然后通过基于文本的指导应用LDM的去噪扩散模型，并使用LDM的预训练解码器进行解码，获得高分辨率图像。这一设计避免了在像素空间生成图像的挑战，提高了生成图像的效率和质量。此外，这种方法还提供了通过文本引导实现图像控制的独特能力，优于直接基于真实图像训练的基线方法，在计算效率和感知质量方面表现出色。", "conclusion": "实验结果证明，相较于其他复杂度相近的基线方法，LatentCSI方法在计算效率和感知质量方面表现更优，且具备独特的文本引导控制能力。这种新颖的方法能够有效提高基于CSI的图像生成效率，同时保持高质量和可控制性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06269", "html_url": "https://arxiv.org/abs/2507.06269", "title": "基于神经隐式SDF的表面基拉普拉斯不确定性估计BayesSDF", "title_en": "BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields", "authors": "Rushil Desai", "background": "科学模拟下游任务中，准确的表面估计至关重要，但在隐式神经3D表示中的不确定性量化因计算效率低下、可扩展性问题和几何不一致，仍然是一项重大挑战。现有神经隐式表面模型未能提供量化不确定性的方法，限制了其在实际应用中的可靠性。Signed Distance Functions (SDFs) 由于能提供连续且可微的表面表示，非常适合进行不确定性感知建模。", "innovation": "借鉴概率渲染方法，提出了一种新颖的基于SDF的概率不确定性估计框架BayesSDF。通过Laplace近似SDF权重并推导Hessian矩阵来估计局部几何不稳定性，从而表现出与表面重构误差的强烈相关性。", "conclusion": "BayesSDF 提供了表面感知的不确定性量化方法，为更稳健、可解释和行动导向的3D感知系统奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.04631", "html_url": "https://arxiv.org/abs/2501.04631", "title": "带有层次表示的解耦换装人物生成", "title_en": "Disentangled Clothed Avatar Generation with Layered Representation", "authors": "Weitian Zhang,Yichao Yan,Sijing Wu,Manwen Liao,Xiaokang Yang", "background": "换装人物生成在虚拟现实、增强现实、电影制作等领域有着广泛的应用。以往的方法在生成多样数字人物方面取得了成功，但生成具有解耦组件（如身体、头发和衣服）的人物一直是个挑战。", "innovation": "该论文提出了一种名为LayerAvatar的方法，这是第一个基于前馈扩散的解耦换装人物生成方法。它通过提出多层UV特征平面表示来实现此目标，各个组件在这个多层的高斯UV特征平面上具有对应的语义标签，从而支持高分辨率和实时渲染，以及可控的动作和面部表情。此外，还提出了一种单一阶段的扩散模型，并引入了约束条件来解决人体最内层的最大遮挡问题。这些创新为了解决解耦换装人物生成带来了新的可能，为应用探索提供了坚实基础。", "conclusion": "大量实验表明，该方法在生成解耦换装人物方面表现出色，并进一步探索了其用于组件转移的应用。相关项目页面也已开放。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16422", "html_url": "https://arxiv.org/abs/2505.16422", "title": "以世界模型驱动代码执行的前瞻规划：解锁更智能的设备控制", "title_en": "Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach", "authors": "Xiaoran Yin,Xu Luo,Hao Wu,Lianli Gao,Jingkuan Song", "background": "自动控制移动设备对于高效执行涉及多步骤任务至关重要，但这些任务因每个步骤可获取的环境信息有限（主要通过视觉观察），通常需要采取反应性的策略，只关注即时观察，导致决策质量不高。", "innovation": "提出了前瞻规划与世界模型驱动代码执行（FPWC）框架，关键在于优先采用自然语言理解和结构化推理来增强智能体对环境的全球理解，初步建立任务导向的、可优化的世界模型，并结合迭代规划生成前瞻行动，执行为可执行代码。", "conclusion": "在模拟环境和实际移动设备上的实验表明，该方法优于先前的方法，特别是在模拟环境中，任务成功率相对提高了44.4%。附有源代码和演示材料。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23567", "html_url": "https://arxiv.org/abs/2507.23567", "title": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection", "title_en": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection", "authors": "Yung-Hsu Yang,Luigi Piccinelli,Mattia Segu,Siyuan Li,Rui Huang,Yuqian Fu,Marc Pollefeys,Hermann Blum,Zuria Bauer", "background": "单目三维目标检测在机器人技术和AR/VR等多种应用中具有重要价值。现有的方法主要局限于封闭集设置中，训练集和测试集由相同场景和/或物体类别组成。然而，现实世界的应用场景往往引入了新的环境和未见过的对象类别，这给现有的方法带来了挑战。", "innovation": "该研究提出了第一款端到端的三维单目开放集对象检测器(3D-MOOD)，通过设计的三维边界框头部将开放集二维检测转换到三维空间，实现了2D和3D任务的端到端联合训练，提高了整体性能。提出了几何先验条件的对象查询，克服了各种场景下三维估计的泛化问题。设计了标准化图像空间，以提高跨数据集的训练效率。", "conclusion": "3D-MOOD已经在封闭集设置(Omni3D)和开放集设置(Omni3D to Argoverse 2, ScanNet)中进行了评估，并且取得了新的最佳结果。代码和模型可以从指定的URL下载。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07574", "html_url": "https://arxiv.org/abs/2507.07574", "title": "超越线性可分天花板：VLMs表示的对齐", "title_en": "Beyond the Linear Separability Ceiling: Aligning Representations in VLMs", "authors": "Enrico Vompa,Tanel Tammet,Mohit Vaishnav", "background": "在推进视觉-语言模型（VLMs）方面的一个挑战是如何确定它们在抽象推理任务（例如Bongard问题）上的失败是否源自感知缺陷或顶层推理错误。为了解开这些因素，作者引入了一种以线性可分天花板（LSC）为中心的诊断框架，LSC是由线性分类器在VLMs原始视觉嵌入上的可达到性能。", "innovation": "通过应用这一框架到最先进的VLMs，作者揭示了一种普遍存在的“对齐缺口”，即大多数模型无法生成性地超越其自身表示的线性可分性。作者发现，少数超过这一天花板的模型是通过两种机制实现的：进一步细化视觉表示以使其更易于线性分离，或执行非线性决策逻辑。作者表明，这一瓶颈并不是基本限制，而是一个可解决的对齐问题。通过在标准下一个令牌预测中增加对比目标，作者的微调方法激活了未使用的推理路径，系统地改善了表示的线性结构，从而显著超过了LSC。", "conclusion": "证明了这一瓶颈不是无法克服的基本限制，而是一个可以解决的对齐问题。通过结合标准下一个令牌预测和对比目标的微调方法，极大提高了VLMs的表现，突破了线性可分天花板。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11430", "html_url": "https://arxiv.org/abs/2506.11430", "title": "Auto-Connect：保持连接性的RigFormer及其直接偏好优化", "title_en": "Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization", "authors": "Jingfeng Guo,Jian Liu,Jinnan Chen,Shiwei Mao,Changrong Hu,Puhua Jiang,Junlin Yu,Jing Xu,Qi Liu,Lixin Xu,Zhuo Chen,Chunchao Guo", "background": "现有自动骨架绑定方法通常通过预测关节位置或先预测关节点再确定连接性来实现。这些方法可能导致连接性的丢失或不准确，从而影响装饰效果。本研究旨在提出一种新的方法，以确保在自动绑定过程中保持骨骼连接，提高装饰的拓扑准确性。", "innovation": "提出了Auto-Connect，采用一种保持连接性的标记化方案，通过特殊标记定义每个关节儿童的端点和每个层次的连接关系，有效自动化了连接关系的确定。还引入了一种拓扑感知奖励函数，通过奖励导向的直接偏好优化在训练后阶段进一步保证高质量的拓扑。此外，结合了隐式的测地线特征，提高了着色质量，通过模型潜在空间中的测地线距离信息智能地确定每个顶点的最重要的骨骼。", "conclusion": "结合保持连接性的标记化方案、奖励导向的微调和测地线感知的骨骼选择，本方法能够一致地生成更符合解剖学的骨骼结构，具有优越的变形性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04681", "html_url": "https://arxiv.org/abs/2507.04681", "title": "数字病理图像中的结直肠癌肿瘤分级分割：从巨无霸到迷你挑战", "title_en": "Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology Images: From Giga to Mini Challenge", "authors": "Alper Bahcekapili,Duygu Arslan,Umut Ozdemir,Berkay Ozkirli,Emre Akbas,Ahmet Acar,Gozde B. Akar,Bingdou He,Shuoyu Xu,Umit Mert Caglar,Alptekin Temizel,Guillaume Picaud,Marc Chaumont,Gérard Subsol,Luc Téot,Fahad Alsharekh,Shahad Alghannam,Hexiang Mao,Wenhua Zhang", "background": "结直肠癌(CRC)是全球第三常见的癌症类型，也是癌症致死的第二大原因。准确的病理分级对于预后和治疗规划至关重要，但这一过程仍具有较高的主观性，容易受到观察者偏差的影响，并且受到全球病理学家短缺的限制。为推进自动化和标准化的解决方案，我们组织了ICIP大规模挑战赛，聚焦于使用公共METU CCTGS数据集的结直肠癌肿瘤分级和分割。该数据集包含103个全切片图像，并对5种组织类别的像素级别进行了专家标注。参赛队伍提交了分割掩膜并通过宏F分数和mIoU等指标进行评估。", "innovation": "该挑战赛利用公共数据集推进了自动化病理肿瘤分级和分割的技术发展，展示了团队提交的方法的性能，其中六支队伍的表现超过了基于Swin Transformer的基准线。这为自动化病理学处理提供了一个有竞争力的平台，并展示了新兴技术在解决病理分析问题中的潜力。", "conclusion": "该论文概述了挑战任务、数据集和最优秀的方法。这些数据显示了机器学习方法在结直肠癌肿瘤分级和分割任务上的较大潜力，有助于推进病理学的自动化过程，提高诊断的准确性和效率。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13120", "html_url": "https://arxiv.org/abs/2507.13120", "title": "RS-TinyNet: 遥感图像中检测微小目标的阶段式特征融合网络", "title_en": "RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images", "authors": "Xiaozheng Jiang,Wei Zhang,Xuerui Mao", "background": "遥感（RS）图像中微小目标的检测一直是一个长期存在的挑战，由于它们的空间信息极少、特征表示较弱且分散在复杂背景中。尽管投入了大量努力，主流检测器在这些场景中的表现仍然不足。", "innovation": "提出的RS-TinyNet是一个专门针对各种遥感场景中的遥感微小对象检测的多阶段特征融合和增强模型，具有两种新颖设计：微小物体显著性建模和特征完整性重建。通过多维度协作注意模块（MDCA）增强了微小物体的显著性，通过辅助可逆分支（ARB）和逐步融合检测头（PFDH）模块保留了信息流并融合了多级特征，以弥合语义差距并保留结构细节。", "conclusion": "在公共遥感数据集AI-TOD上的全面实验表明，我们的RS-TinyNet比现有最先进的（SOTA）检测器高出4.0%的AP和6.5%的AP75。在DIOR基准数据集上的评估进一步验证了其在各种遥感场景中的优越检测性能。这些结果表明，提出的多阶段特征融合策略为复杂遥感环境中的微小目标检测提供了一种有效且实用的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10542", "html_url": "https://arxiv.org/abs/2508.10542", "title": "GCRPNet：用于光学遥感图像中的显著目标检测的图增强上下文和区域感知网络", "title_en": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images", "authors": "Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong", "background": "光学遥感图像中的显著目标检测（SOD）面临着众多挑战，包括目标尺度的巨大变化以及目标与背景之间的对比度较低。现有方法基于视觉变换器（ViTs）和卷积神经网络（CNNs）架构，旨在利用全局和局部特征，但由于难以有效整合这些异构特征，限制了它们的整体性能。", "innovation": "提出了一种图增强上下文和区域感知网络（GCRPNet），该网络基于Mamba架构，同时捕捉长程依赖，并增强局部特征表示。具体来说，通过视觉状态空间（VSS）编码器提取多尺度特征。首先设计了一个差异相似性引导的分层图注意力模块（DS-HGAM），增强了不同尺度特征之间的跨层交互能力，提高了模型的结构感知，有助于更有效地区分前景和背景。然后设计了LEVSS块作为GCRPNet的解码器，该模块结合了我们提出的自适应扫描策略和多级协作注意力增强模块（MCAEM），在多尺度卷积处理后的特征图上执行自适应patch扫描，从而捕获丰富的局部区域信息，增强Mamba的本地建模能力。", "conclusion": "广泛的实验结果表明，所提出模型在显著目标检测方面达到了最先进的性能，验证了其有效性和优越性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14014", "html_url": "https://arxiv.org/abs/2508.14014", "title": "在线新颖视角选择的3D高斯点云建模", "title_en": "Online 3D Gaussian Splatting Modeling with Novel View Selection", "authors": "Byeonggwon Lee,Junkyu Park,Khang Truong Giang,Soohwan Song", "background": "当前的研究主要集中在从仅包含RGB图像的在线环境下构建3D高斯点云模型（3DGS）上。以往的研究利用稠密SLAM技术通过关键帧估计3D场景，为3DGS模型构建服务。然而，这些方法依赖于关键帧，其获取的视角有限，难以全面覆盖整个场景，导致重建不完整。此外，构建通用化的模型需要结合不同视角的多帧信息来提升场景的覆盖范围，但在线处理限制了多帧的使用或训练次数。因此，本文提出了一种通过自适应视角选择来提高3DGS模型完整性的新方法。该方法通过在线分析重建质量来选择最合适的非关键帧进行额外培训，从而通过整合关键帧和选择的非关键帧，填补从不同视角获得的不完整区域，大大提升了重建的完整性。在此基础上，本文还提出了一种在线多视图立体匹配框架，以确保在整个3DGS建模过程中3D信息的一致性。实验结果表明，本文的方法在复杂户外场景中表现出色，优于现有最先进的方法。", "innovation": "本文提出了一种新的方法，通过自适应视角选择来提高3DGS模型的完整性。该方法通过在线分析重建质量来选择额外的非关键帧进行培训，整合关键帧和非关键帧，从而从不同视角提高重建的完整性。此外，本文还提出了一种在线多视图立体匹配框架，确保了3DGS建模过程中的3D信息一致性。这些创新点使得模型在复杂场景下表现出色，优于现有方法。", "conclusion": "本文提出了一种新的在线3D高斯点云建模方法，通过自适应视图选择和在线多视图立体匹配，显著提高了模型的完整性和一致性，特别是在复杂户外场景中，该方法优于现有的最先进的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15298", "html_url": "https://arxiv.org/abs/2508.15298", "title": "TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification", "title_en": "TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification", "authors": "Darya Taratynova,Alya Almsouti,Beknur Kalmakhanbet,Numan Saeed,Mohammad Yaqub", "background": "先天性心脏缺陷（CHD）在超声视频中的检测受到图像噪声和探头定位变化的干扰。虽然自动化方法可以减少操作员依赖，但当前的机器学习方法往往忽视了时间信息，限制在二元分类上，也没有考虑预测校准。", "innovation": "提出了Time Prompt Alignment（TPA），一种结合基础图像-文本模型和提示感知对比学习的方法，用于先天性心脏缺陷（CHD）在心脏超声视频中的分类。TPA通过图像编码器从每个视频子片段的每一帧中提取特征，通过可训练的时间提取器捕捉心脏运动，并通过边际铰链对比损失将视频表示与特定类别的文本提示对齐。为增强临床可靠性，引入了条件变分自编码器样式的调制（CVAESM）模块，该模块学习潜在样式向量以调制嵌入并量化分类不确定性。", "conclusion": "TPA在私有数据集和大型公共数据集EchoNet-Dynamic上进行评估，用于检查CHD和心脏舒张功能的检测，TPA实现了最先进的宏F1分数为85.40%，同时降低了预期校准误差5.38%和适应ECE 6.8%。在EchoNet-Dynamic的三分类任务中，TPA将宏F1提高了4.73%（从53.89%提高到58.62%）。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04745", "html_url": "https://arxiv.org/abs/2509.04745", "title": "孤立手语符号的音韵表示学习改善了超词汇量泛化", "title_en": "Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization", "authors": "Lee Kezar,Zed Sehyr,Jesse Thomason", "background": "现有的手语数据集在词汇覆盖方面往往不够全面，这强调了需要开发能够泛化到未见过的手语符号的模型。向量量化是一种有潜力的方法，用于学习离散的、类似令牌的表示，但是尚未评估它是否会学到妨碍超词汇量性能的伪相关特征。研究表明，音韵学的归纳偏置——参数解耦以及音韵学半监督这两种方式，能够提高已知手语符号的孤立识别效果和未见过的手语符号重建质量。研究发现现有模型学习到的表示在重建未见过的手语符号和手势识别方面更为有效。", "innovation": "这项工作通过引入音韵学的归纳偏置——参数解耦和音韵学半监督这两种方法，改善了向量量化自动编码器在重建未见过的手语符号以及手语识别上的表现。", "conclusion": "本研究定量分析了显式、语言驱动的设计偏置如何改善手语表示学习中的泛化效果，表明这些语言学驱动的设计偏置能够提高手语模型的泛化能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02445", "html_url": "https://arxiv.org/abs/2509.02445", "title": "高保真、保身份的实时美妆转移方法：拆分风格生成", "title_en": "Towards High-Fidelity, Identity-Preserving Real-Time Makeup Transfer: Decoupling Style Generation", "authors": "Lydia Kin Ching Chau,Zhi Yu,Ruowei Jiang", "background": "现有方法在实时美妆转移应用中难以在短时间内准确复制细腻的美妆效果，同时保持用户的身份一致性。此外，这些方法无法区分化妆品与肤色等识别特征，导致身份识别的偏差，以及缺乏实时处理能力和时间连贯性，限制了实际应用的可行性。", "innovation": "本研究提出了一种新的框架，通过将美妆转移分解为两步：透明化妆品口罩提取和基于图形的口罩渲染，实现高保真、保身份的实时美妆转移。以伪地真相数据（通过两种互补方法生成）训练提取模型，并引入专门的训练目标来提高透明度估计和颜色保真度。该方法能够适应多样的姿势、表情和肤色，同时保持时间连续性，并在实验中表现出对细节点、时间稳定性以及身份完整性更好的表现。", "conclusion": "本研究提出的方法在实时美妆试妆中表现出较高保真度和身份一致性，克服了现有方法的多项限制，具有优越的推广应用价值。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03025", "html_url": "https://arxiv.org/abs/2509.03025", "title": "揭示大型视觉语言模型对视觉缺失元素的响应", "title_en": "Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens", "authors": "Sohee Kim,Soohyun Ryu,Joonhyung Park,Eunho Yang", "background": "大型视觉语言模型（LVLMs）通过联合解析图像和文本输入来生成上下文相关响应。然而，研究发现这些模型常常误认为缺乏视觉证据的文本输入是图像的一部分，从而产生错误的回应。这一现象表明LVLMs可能存在内部机制来判断文本概念是否与图像相关，但这一能力尚未被有效探索和利用。", "innovation": "本文通过分析LVLMs的神经元活动，发现了一种特定的前馈网络（FFN）神经元——视觉缺失感知（VA）神经元，这些神经元通过独特的激活模式来传达视觉的缺失状态。基于这一发现，作者开发了一个检测模块，用于系统地分类输入令牌是否与视觉元素相关，并提出了一个利用该模块改进模型输出的方法，即根据该模块的预测重新解释问题提示或替换检测到的缺失文本。实验表明该方法显著减少了模型对视觉缺失的文本 输入错误假设，并且具有在各种LVLMs中的普适性。", "conclusion": "该研究揭示了LVLMs处理视觉缺失元素的方式，并提出了一种新的方法来提高LVLMs对输入文本的理解准确性，从而减少模型生成错误输出的可能性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.01910", "html_url": "https://arxiv.org/abs/2509.01910", "title": "追求可解释的地理定位：一种概念感知全球图像-GPS对齐框架", "title_en": "Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS Alignment Framework", "authors": "Furong Jia,Lanxin Liu,Ce Hou,Fan Zhang,Xinyan Liu,Yu Liu", "background": "全球地理定位涉及确定全球拍摄图像的精确地理位置，通常由气候、地标和建筑风格等地理线索引导。尽管像GeoCLIP这样的地理定位模型已经取得了进展，采用了对比学习的方法来对图像和位置进行配对以获得准确预测，但这些模型的可解释性仍然没有得到充分探索。当前的概念基可解释性方法与Geo对齐图像-位置嵌入目标无法有效对齐，导致了可解释性和性能的不足。", "innovation": "本文提出了一个新的框架，结合全球地理定位与概念瓶颈。该方法引入了一个概念感知对齐模块，联合将图像和位置嵌入投影到地理概念共享银行（例如，热带气候、山地、教堂）上，并最小化概念水平的损失，增强了概念特定子空间的对齐，提高了可解释性。这是首次将可解释性引入地理定位的工作。全面的实验表明，该方法在地理定位精度上超过了GeoCLIP，并在各种地理空间预测任务中提高了性能，揭示了更多关于地理决策过程的语义洞察。", "conclusion": "本文提出的方法在地理定位精度和可解释性方面均优于现有方法，并揭示了更多关于地理决策过程的语义内容，代表了一种提升地理定位模型性能和透明度的潜在方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03786", "html_url": "https://arxiv.org/abs/2509.03786", "title": "SLENet:一种指导增强网络用于水下伪装目标检测", "title_en": "SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection", "authors": "Xinxin Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao", "background": "水下伪装目标检测（UCOD）旨在识别与水下环境无缝融合的物体，这对海洋生态学至关重要。然而，由于光学畸变、水体浑浊和海洋生物的复杂特性，准确的识别受到严重阻碍。", "innovation": "本文提出了UCOD任务，并构建了DeepCamo基准数据集。同时，提出了一种新的框架SLENet，其中包含Gamma-Asymmetric Enhancement（GAE）模块和Localization Guidance Branch（LGB）来增强多尺度特征表示并生成富含全局语义信息的位置图，该图引导Multi-Scale Supervised Decoder（MSSD）生成更准确的预测。相较现有的最先进的方法，SLENet在DeepCamo数据集以及三个基准下的COD数据集上的实验结果均证明了其优越的性能及其在更广泛的目标检测任务中的高通用性。", "conclusion": "通过基准测试现有的COD模型，并整合GAE模块和LGB模块，SLENet改进了多尺度特征表示，增强了语义信息的全局性，并通过位置图指导解码器生成更准确的预测。实验结果表明，SLENet在UCOD任务中的性能优越，且具有广泛的适用性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.04672", "html_url": "https://arxiv.org/abs/2505.04672", "title": "Histo-Miner: 从切皮栉状细胞癌苏木精和伊红全切片图像中提取组织特征的深度学习管道", "title_en": "Histo-Miner: Deep Learning based Tissue Features Extraction Pipeline from H&E Whole Slide Images of Cutaneous Squamous Cell Carcinoma", "authors": "Lucas Sancéré,Carina Lorenz,Doris Helbig,Oana-Diana Persa,Sonja Dengler,Alexander Kreuter,Martim Laimer,Anne Fröhlich,Jennifer Landsberg,Johannes Brägelmann,Katarzyna Bozek", "background": "数字病理学的进步使得能全面分析组织样本的全切片图像（WSI），借助高分辨率显微镜和计算能力进行高级分析。然而，在皮肤组织分析方面，缺乏标记的数据集和针对皮肤组织分析的开源管道。因此，本文介绍了Histo-Miner，这是一个基于深度学习的管道，专门用于分析皮肤WSI，并生成了两个包含标记的核和肿瘤区域的数据集。该研究专注于切皮栉状细胞癌（cSCC），一种常见的非黑色素瘤皮肤癌。使用两个数据集，其中包括47,392个注释的细胞核和144个肿瘤分割WSI，Histo-Miner利用卷积神经网络和视觉变换器进行细胞核分割、分类以及肿瘤区域分割。", "innovation": "Histo-Miner是一个专门为分析皮肤WSI设计的深度学习管道，能够生成包含组织形态和细胞间相互作用的紧凑特征向量。通过分析切皮栉状细胞癌患者的治疗前WSI，Histo-Miner能够识别淋巴细胞百分比、肿瘤周围的粒细胞/淋巴细胞比值以及粒细胞和浆细胞之间的距离作为预测治疗反应的特征。这种方法显示了Histo-Miner在临床相关场景中的应用价值，提供了直接解释分类结果和深入探索潜在生物学机制的见解。", "conclusion": "Histo-Miner在细胞核分割、细胞核分类和肿瘤区域分割方面表现良好，与其他先进模型相比，多类泛光质量（mPQ）为0.569，宏平均F1得分为0.832，肿瘤区域分割的平均交并比（mIoU）为0.884。该研究提供了Histo-Miner在预测切皮栉状细胞癌患者免疫治疗反应方面的应用实例，证明了其在临床实践中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18733", "html_url": "https://arxiv.org/abs/2508.18733", "title": "Drawing2CAD：从矢量绘制到CAD生成的序列到序列学习", "title_en": "Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings", "authors": "Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu", "background": "计算机辅助设计(CAD)生成建模在工业应用中推动了重大创新。尽管现代方法已经在从点云、网格和文本描述生成固体模型方面取得了显著进展，但这些方法在处理传统2D工程图时与工业工作流程存在根本差异。将2D矢量绘制自动转换为参数化CAD模型仍然是未被充分探索的关键步骤。", "innovation": "提出了一个新的框架Drawing2CAD，用于从矢量绘制生成参数化CAD模型。该框架包含三个关键技术组件：网络友好的矢量原语表示、分离命令类型和参数生成的双解码器变压器架构以及适应CAD参数内在灵活性的软目标分布损失函数。", "conclusion": "通过构建CAD-VGDrawing数据集并进行详细的实验，证明了Drawing2CAD的有效性。代码和数据集可从提供的链接下载。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.01421", "html_url": "https://arxiv.org/abs/2509.01421", "title": "InfoScale：利用有效信息利用实现无培训变量尺度图像生成", "title_en": "InfoScale: Unleashing Training-free Variable-scaled Image Generation via Effective Utilization of Information", "authors": "Guohui Zhang,Jiangtong Tan,Linjiang Huang,Zhonghang Yuan,Naishan Zheng,Jie Huang,Feng Zhao", "background": "扩散模型（DMs）在视觉生成中占据主导地位，但在测试不同训练分辨率的图像时（无论是较低还是较高分辨率），会出现性能下降的问题。关键挑战在于不同分辨率下信息量的不同，需要信息转换过程的多样化来生成不同尺度的图像。这个论文探讨了DMs生成不同尺度图像中三个关键方面的具体问题：扩张卷积、注意力机制以及初始噪声，并提出了解决这三大问题的信息导向框架InfoScale，包括渐进频率补偿模块、自适应信息聚合模块和噪声适应模块，以应对生成不同尺度的图像的挑战。", "innovation": "1. 提出了渐进频率补偿模块（Progressive Frequency Compensation module），补偿高分辨率生成中由于扩张卷积丢失的高频信息。2. 引入自适应信息聚合模块（Adaptive Information Aggregation module），适应性地调整低分辨率生成中信息聚合，实现高分辨率生成中的局部和全局信息的有效平衡。3. 设计了噪声适应模块（Noise Adaptation module），在初始噪声中重新分配信息，以满足不同尺度的生成需求。InfoScale框架可以直接嵌入到DMs中，而广泛的实验也展示了其在不同尺度图像生成中的有效性。", "conclusion": "实验结果表明，InfoScale框架能够有效解决DMs在不同尺度图像生成中的问题，并在生成不同尺度的图像中展现出良好的效果。这种方法可直接应用于现有的DMs模型中。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04334", "html_url": "https://arxiv.org/abs/2509.04334", "title": "GeoArena：用于全球图像地理定位中评估大型视觉语言模型的开源平台", "title_en": "GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization", "authors": "Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li", "background": "全球图像地理定位旨在预测地球上任何地方拍摄的图像的位置，但其全球特性带来了显著的挑战。当前的评价方法存在两个主要限制：数据泄露和基于地理位置坐标的评价标准使得它们不能准确地评估模型的真实地理定位能力。具体来说，先进的方法往往依赖大规模的视觉语言模型（LVLMs）进行预测，而这些模型经常在测试数据集上进行预训练，导致模型准确性评估失真。此外，现有的评估标准主要依赖于精确的地理位置坐标进行评估，这不仅忽视了推理过程，还存在隐私泄露的风险。", "innovation": "我们提出了GeoArena，这是首个用于评估LVLMs的全球图像地理定位任务的开源平台，提供了真实的野外和以人为本的基准测评。GeoArena允许用户上传野外捕捉的图像以扩展评估的样本多样性，并通过成对的人类判断来确定哪种模型输出与人类预期更一致。该平台上线两个月以来，收集了数千个投票记录，并基于这些数据对不同LVLMs在图像地理定位任务上的表现进行了详细分析，建立了一个排行榜。", "conclusion": "根据收集的数据，我们对不同视觉语言模型在图像地理定位任务上的表现进行了详细分析，并建立了排行榜。GeoArena平台通过提供开源、多样化的图像数据集和人类判断作为模型评估标准，为图像地理定位任务中的LVLMs评估提供了一种创新的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.12226", "html_url": "https://arxiv.org/abs/2402.12226", "title": "AnyGPT: 统一的离散序列建模多模态语言大模型", "title_en": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "authors": "Jun Zhan,Junqi Dai,Jiasheng Ye,Yunhua Zhou,Dong Zhang,Zhigeng Liu,Xin Zhang,Ruibin Yuan,Ge Zhang,Linyang Li,Hang Yan,Jie Fu,Tao Gui,Tianxiang Sun,Yugang Jiang,Xipeng Qiu", "background": "当前的语言模型主要针对单一模态，如文本，对多模态数据的处理能力有限。研究者通过引入离散表示方法，提出了AnyGPT模型，以实现不同模态间的统一处理。", "innovation": "AnyGPT模型通过离散表示方法，实现了对语音、文本、图像和音乐等多种模态的统一处理。该模型可以在不改变现有大型语言模型架构和训练范式的前提下，通过数据级预处理稳定训练，并构建了多模态文本中心数据集，生成了大规模的任何对任何的多模态指令数据集，支持任意模态的组合。", "conclusion": "实验结果显示，AnyGPT模型在多模态对话方面表现出色，与专门针对各模态的模型相比具有相似的性能，证明了离散表示方法可以在语言模型中有效且方便地统一多种模态。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04376", "html_url": "https://arxiv.org/abs/2509.04376", "title": "AnomalyLMM：跨越生成知识和区分检索的文本基础人物异常搜索", "title_en": "AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search", "authors": "Hao Ju,Hu Zhang,Zhedong Zheng", "background": "随着公众安全性需求的增长，基于文本的人物异常搜索已经成为了关键任务，目的是通过自然语言描述来检索有异常行为的个人。这项任务不同于传统的人员搜索，它面临着两个独特的挑战：(1) 文本异常和视觉行为之间的细粒度跨模态对齐，(2) 在稀疏的真实世界样本下异常的识别。虽然大型多模态模型在多模态理解方面表现出色，但它们在细粒度异常检索方面的潜力仍被忽视，主要受到领域之间生成知识与区分检索之间的差距以及缺乏有效的部署适应策略的影响。", "innovation": "我们的主要创新在于提出了AnomalyLMM，这是一个首次利用大型多模态模型进行基于文本的人物异常搜索的框架。我们贡献了：(1) 一个将生成世界知识与检索中心异常检测相连接的粗到细的管道；(2) 一种无需训练的适应指南，其中包括屏蔽跨模态提示、行为知觉预测和知识指导再排序，这些都能有效聚焦在细微的异常线索上。", "conclusion": "作为第一个探索大型多模态模型在这一任务中的应用的研究，我们在PAB数据集上进行了严格的评估，这是目前唯一公开的文本基础人物异常搜索基准，包含了经过编目的现实世界异常，涵盖了多种场景（例如：摔倒、碰撞和遭到打击）。实验表明提出的方法是有效的，比竞争基准提高了0.96%的Recall@1准确性。值得注意的是，我们的方法在文本异常和视觉行为之间的可解释对齐方面具有可验证性，通过定性分析得到了验证。我们的代码和模型将对外开放以供未来研究使用。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04378", "html_url": "https://arxiv.org/abs/2509.04378", "title": "使用增强注意机制的美学图像描述", "title_en": "Aesthetic Image Captioning with Saliency Enhanced MLLMs", "authors": "Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao", "background": "Aesthetic Image Captioning (AIC)旨在生成描述图像美学的文本描述，成为计算美学领域的关键研究方向。近年来，预训练的多模态大型语言模型（MLLMs）取得了快速发展，促进了融合视觉和文本模态的美学研究。然而，现有的大多数关于图像美学的研究主要集中在预测美学评分上，在AIC中的应用有限。现有的依赖于MMLMs进行AIC的研究大多仅采用微调方法，而未特别适应MMLMs以专注于目标美学内容。", "innovation": "提出了Aesthetic Saliency Enhanced Multimodal Large Language Model（ASE-MLLM），这是一种端到端框架，明确地将美学显著性纳入MMLMs。框架中引入了Image Aesthetic Saliency Module（IASM），该模块高效且有效地从图像中提取美学显著性特征。此外，设计了IAS-ViT作为图像编码器，通过交叉注意力机制将美学显著性特征与原始图像特征融合。ASE-MLLM是首款专门针对AIC任务将图像美学显著性整合至MMLMs中的框架。广泛实验表明，我们的方法在当前主流AIC基准测试中显著优于传统方法和通用MMLMs，达到了最先进的性能（SOTA）.", "conclusion": "ASE-MLLM在广泛实验中展示了显著优于传统方法和通用MMLMs的性能，尤其是在当前主流AIC基准测试中达到了最先进的性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03975", "html_url": "https://arxiv.org/abs/2509.03975", "title": "使用多任务学习和仅在模型训练期间可用的辅助数据改进血管分割", "title_en": "Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training", "authors": "Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs", "background": "肝脏血管在磁共振成像数据中的分割对于分析与广泛肝脏疾病相关的血管重塑至关重要。现有的方法依赖于对比增强的成像数据，但这些专门的成像序列并没有在所有情况下都得到统一获取。虽然非对比成像数据更经常被使用，但进行血管分割会很困难，并且需要大量标注数据。本文探讨在没有对比成像数据的情况下分割肝脏MRI中的血管的挑战。", "innovation": "本文提出了一种多任务学习框架，能够在没有对比成像数据的情况下分割肝脏MRI中的血管。该框架利用训练期间可用的仅在训练期间可用的辅助对比增强MRI数据，以减少对标注训练样本的需求。训练模型时使用了与血管标注和未标注的原生及对比增强数据配对的数据。实验结果显示，辅助数据即使在推断时不可用也能提高血管分割的准确性，尤其在少数标注数据的情况下。这种方法在脑肿瘤分割问题上的验证也表明其在不同领域的潜力。", "conclusion": "辅助信息影像模态即使仅在训练期间可用，也能在只有少量标注时增强专家标注的效果。这种方法不仅适用于肝脏MRI中的血管分割，还适用于其他分割任务，特别是当大量标注数据难以获得时。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.06020", "html_url": "https://arxiv.org/abs/2505.06020", "title": "ArtRAG：具有结构化上下文的检索增强生成技术在视觉艺术理解中的应用", "title_en": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding", "authors": "Shuai Wang,Ivona Najdenkoska,Hongyi Zhu,Stevan Rudinac,Monika Kackovic,Nachoem Wijnberg,Marcel Worring", "background": "理解视觉艺术需要跨越文化、历史和风格等多个视角，而不仅仅是对象识别。尽管最近的多模态大规模语言模型（MLLMs）在通用图像描述上表现良好，但在解释精细艺术品方面往往无法捕捉到位的艺术解读。现有的模型在生成多视角的艺术作品解释上存在不足。", "innovation": "我们提出了ArtRAG，一种无需训练的新颖框架，结合了结构化知识与检索增强生成（RAG），用于从多角度解释艺术品。ArtRAG 自动从特定领域的文本资源中构建艺术上下文知识图谱（ACKG），并将其中的艺术家、运动、主题和历史事件组织成一个丰富的、可解释的图谱。在推理阶段，使用多粒度结构检索器选择与语义和拓扑相关的子图来引导生成，使MLLMs能够生成上下文依据、文化背景的艺术描述。", "conclusion": "在SemArt和Artpedia数据集上的实验表明，ArtRAG 比多个经过大量训练的基线模型表现更佳。进一步的人机评估显示，ArtRAG 生成连贯、深刻的并且文化内涵丰富的解释。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00008", "html_url": "https://arxiv.org/abs/2507.00008", "title": "DiMo-GUI：通过模态自意识视觉推理促进GUI语义理解的测试时扩展", "title_en": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "authors": "Hang Wu,Hongkai Chen,Yujun Cai,Chang Liu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "在图形用户界面（GUI）上对接自然语言查询带来了独特的挑战，因为这其中包含了视觉元素的多样性、空间布局的拥挤以及语言的歧义性。已有方法通常将GUI视为一个整体图像来处理，这对于处理不同类型的视觉信息（如文本和图标）以及解决视觉布局中的歧义性不够有效，需要额外的训练或标注数据才能改进性能。", "innovation": "本文提出了一种名为DiMo-GUI的无需训练框架，旨在通过动态视觉对接和模态自意识优化来解决这一问题。DiMo-GUI将输入分解为文本元素和图标的元素，利用通用的视觉语言模型分别独立处理这些模态信息。当预测结果含糊或不正确时，DiMo-GUI可以动态地聚焦并生成候选的焦点区域，逐步深入细化局部细节，以实现语义理解的去歧义化。这种方法无需额外的训练或标注数据，就能有效处理视觉拥挤的布局问题。", "conclusion": "本文在标准的GUI对接基准上评估了DiMo-GUI，并展示了与基本推理流程相比，通过模态分离与区域聚焦相结合的改进效果，证实了该方法的有效性，特别是在应对复杂布局中的语言和视觉歧义方面。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13802", "html_url": "https://arxiv.org/abs/2507.13802", "title": "欧洲食品安全趋势：来自3920万条条目综合欧洲食品安全(CHDFS)数据库的见解", "title_en": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database", "authors": "Nehir Kizililsoley,Floor van Meer,Osman Mutlu,Wouter F Hoenderdaal,Rosan G. Hobé,Wenjuan Mu,Arjen Gerssen,H.J. van der Fels-Klerx,Ákos Jóźwiak,Ioannis Manikas,Ali Hürriyetoǧlu,Bas H.M. van der Velden", "background": "在欧洲联盟中，成员国向欧洲食品安全局(EFSA)提交的官方食品安全监测数据被提交并发布在Zenodo上。这些数据包括来自超过1520万个样品的4亿多分析结果，覆盖了超过4000种不同类型的食物产品，为人工智能分析趋势、预测风险和支持早期预警系统提供了极大的机会。然而，当前的数据格式导致数据分散在大约1000个文件中，总容量达数百吉字节，这妨碍了数据的访问和分析。", "innovation": "我们引入了综合欧洲食品安全(CHEFS)数据库，将EFSA的监测数据中关于有害物质残留的信息整合成一个统一且结构化的数据集。这个数据库展示了2000年至2024年间欧洲食品安全监测数据的趋势，分析了监测活动的变化，最常检测的产品，最常违规的产品以及最常发现的污染物，并且包括了不同国家之间的差异。这个分析强调了CHEFS数据库作为中央数据来源和指导食品安全政策、研究和监管的战略工具的重要性。", "conclusion": "CHEFS数据库被确认是中央数据来源，并且是一个指导食品安全政策、研究和监管的战略工具，它能提供有关欧洲食品安全监测数据的重要见解。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17114", "html_url": "https://arxiv.org/abs/2505.17114", "title": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "title_en": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "authors": "Subrata Biswas,Mohammad Nur Hossain Khan,Bashima Islam", "background": "多模态问答（QA）通常需要识别哪些视频、音频或传感器标记与问题相关。然而，各模态之间的分歧很常见，如离轴声音、背景噪音或视野外的运动都可能误导将所有流等权重融合的模型。研究中提出了RAVEN统一QA架构，其核心是Query-Conditioned Cross-Modal Gating模块（QuART），该模块对每种模态中的标记分配标量相关性评分，使模型能够在融合前放大有信息的信号并抑制干扰信号。RAVEN通过一个包含三个阶段的训练流水线训练，涵盖单模态预训练、查询对齐融合和分歧导向微调，每个阶段针对多模态推理中的不同挑战：表示质量、跨模态相关性和模态不匹配鲁棒性。", "innovation": "RAVEN提出了一个统一的多模态问答架构，通过Query-Conditioned Cross-Modal Gating模块（QuART）分配每个标记的标量相关性评分，使模型在融合前可以放大有用信号并抑制干扰。该架构通过一个三阶段的训练流水线进行训练，针对多模态推理中的多个挑战进行优化。此外，该研究还发布了AVS-QA数据集，包含30万个同步音频-视频-传感器流与自动生成的问题-答案对。", "conclusion": "实验结果显示，RAVEN在七个跨模态问答基准上的准确率分别比最先进的跨模态大型语言模型提高了14.5%和8.0%。纳入传感器数据提供了额外16.4%的提升，并且模型在模态干扰下依然表现稳定，超过了最先进的基线基准50.23%。代码和数据集可在提供的URL下载获取。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16897", "html_url": "https://arxiv.org/abs/2508.16897", "title": "使用Slice-一致布朗桥扩散网络从非对比扫描生成合成对比增强胸部CT图像", "title_en": "Generating Synthetic Contrast-Enhanced Chest CT Images from Non-Contrast Scans Using Slice-Consistent Brownian Bridge Diffusion Network", "authors": "Pouya Shiri,Xin Yi,Neel P. Mistry,Samaneh Javadinia,Mohammad Chegini,Seok-Bum Ko,Amirali Baniasadi,Scott J. Adams", "background": "对比增强CT成像是诊断和监测胸部疾病，包括主动脉疾病的必备工具。然而，对比剂可能带来肾毒性风险和过敏样反应。通过无对比剂合成对比增强CT血管造影（CTA）图像的能力将具有革命性意义，它能提高患者的安全性、普及性并降低医疗成本。本研究旨在提出第一个基于桥扩散的解决方案，从非对比CT扫描中合成对比增强CTA图像。该方法基于Slice-一致布朗桥扩散模型（SC-BBDM），利用其能够建模复杂映射的同时保持切片间一致性。与传统的逐层合成方法不同，我们的框架在保持完整3D解剖结构的同时以高分辨率的2D方式操作，允许在低内存预算下进行无缝的体积解释。为了确保稳健的空间对齐，我们实现了包括重采样、使用对称规范化方法进行registation和复杂的膨胀分割掩模以提取主动脉及其周围结构在内的全面预处理管道。从Coltea-Lung数据集中创建了两个数据集：一个仅包含主动脉，另一个包括主动脉和心脏，这使得对解剖环境进行详细分析成为可能。在两个数据集上分别对比我们的方法与基线方法，表明其在保留血管结构的同时提高了对比度保真度方面的有效性。", "innovation": "提出了第一个基于桥扩散的解决方案，从非对比CT扫描中合成对比增强CTA图像。该方法通过Slice-一致布朗桥扩散模型（SC-BBDM）利用其建模复杂映射并保持切片间一致性的能力，同时在高分辨率的2D方式下保持完整3D解剖结构，实现了在低内存预算下无缝体积解释。实现了一个全面的预处理管道，包括使用对称规范化方法进行重采样和注册，以及提取主动脉和周围结构的复杂膨胀分割掩模。该方法不仅在保留血管结构方面表现出色，还在对比度保真度上实现了提升。", "conclusion": "本研究提出了一种基于桥扩散的解决方案，能够从非对比CT扫描中生成高质量的对比增强CTA图像，不仅能提高患者的安全性，还减少了医疗成本。该方法在保持完整3D解剖结构的同时，在低内存预算下实现了无缝的体积解释。与基线方法相比，该方法在保留血管结构和提高对比度保真度方面均表现优秀。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.17422", "html_url": "https://arxiv.org/abs/2410.17422", "title": "多模态LLM引导的探索与主动建图利用费舍尔信息", "title_en": "Multimodal LLM Guided Exploration and Active Mapping using Fisher Information", "authors": "Wen Jiang,Boshu Lei,Katrina Ashton,Kostas Daniilidis", "background": "现有的方法要么未充分利用多模态大型语言模型（LLM）的最新进展，要么未能考虑定位不确定性带来的挑战，这对于具身智能体来说至关重要。背景信息指出，需要一种能够在长时间目标规划与短期行动规划之间取得平衡的方法。", "innovation": "该研究提出了一个主动建图系统，该系统采用3D高斯点云（3DGS）表示法，结合了长时间目标规划与短期行为规划。创新点包括利用多模态LLM进行基于语义的长时间探索目标零样本规划，以及提出了一种兼顾最大化环境信息增益和最小化定位误差成本的多模态路径建议和选择算法。", "conclusion": "实验结果显示，该方法在吉布森和Habitat-Matterport3D数据集上达到了最先进的性能。该方法在长时间探索目标规划和短期行为规划之间实现了平衡，并通过利用3DGS表示的高质量视图合成，有效地解决了具身智能体面临的定位不确定性挑战。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02640", "html_url": "https://arxiv.org/abs/2509.02640", "title": "Midog2025挑战中的适应性学习策略用于分裂图分类", "title_en": "Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge", "authors": "Biwen Meng,Xi Long,Jingxin Liu", "background": "异常分裂图（AMFs）是临床相关指标，用于指示异常细胞分裂，但由于形态上的不确定性及扫描仪的差异性导致可靠检测仍具挑战性。这项研究探讨了三种适应判别模型UNI2的方法：1）LoRA + UNI2，2）VPT + UNI2 + Vahadane正则化器，3）VPT + UNI2 + GRL + Stain TTA，在MIDOG2025挑战的Track 2任务中。现有的多种策略中，将视觉提示调优（VPT）与染色正则化技术结合能够改进泛化性能。进一步引入测试时增强（TTA）与Vahadane和Macenko染色正则化能够达到最优的鲁棒性。", "innovation": "研究提出了将视觉提示调优（VPT）与染色正则化技术结合的方法，并结合测试时增强（TTA）与Vahadane和Macenko染色正则化，以改进不同成像条件下的异常分裂图分类性能，从而为这一挑战提供了新的策略。", "conclusion": "最终提交实现了0.8837的平衡精度和0.9513的ROC-AUC评分，在初步排行榜中排名前10，表明基于提示的自适应调整结合染色正则化测试时增强能够为多元成像条件下的异质分裂分类提供有前景的方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02544", "html_url": "https://arxiv.org/abs/2509.02544", "title": "UI-TARS-2技术报告：以多轮强化学习推动图形用户界面代理的发展", "title_en": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "authors": "Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Aoyan Li,Bo Li,Chen Dun,Chong Liu,Daoguang Zan,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Shulin Xin,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qi Liu,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Yaohui Wang,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Qihua Han,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du", "background": "在图形用户界面（GUI）上开发自主代理面临着人工智能中的重大挑战。尽管最近的原生代理模型进步通过端到端学习统一了感知、推理、行动和记忆，但仍存在数据规模化、多轮次强化学习（RL）、仅GUI操作的局限性以及环境稳定性等开放问题。", "innovation": "UI-TARS-2 是一种以GUI为中心的原生代理模型，通过系统化的培训方法解决了上述难题：包括可用于大规模数据生成的数据飞轮、稳定的多轮次RL框架、集成了文件系统和终端的混合GUI环境，以及用于大规模释放的统一沙盒平台。UI-TARS-2 在GUI基准测试中的表现优于之前的版本，展示出显著提升，并在游戏环境中达到了接近人类水平的性能，同时具备解决长时间信息寻求任务和软件工程基准测试的能力，证明了其在各类代理任务中的鲁棒性。", "conclusion": "UI-TARS-2 在大规模代理RL中的稳定性和效率方面提供了宝贵的见解，表明它有望推进图形用户界面代理领域的发展，并具备强大的现实互动场景迁移能力。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04351", "html_url": "https://arxiv.org/abs/2509.04351", "title": "全局到局部还是局部到全局？利用高效局部搜索和有效全局重排增强图像检索", "title_en": "Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking", "authors": "Dror Aiger,Bingyi Cao,Kaifeng Chen,Andre Araujo", "background": "当前主流的图像检索系统设计是使用全局图像特征来搜索大型数据库，并使用局部图像特征匹配技术重新排序初始结果。这种设计被称为全局到局部设计，起源于局部匹配方法的计算成本，这些成本只能用于少量检索图像。然而，新兴的高效局部特征搜索方法为大规模详细检索提供了新的可能性，尤其是能够发现全球特征搜索往往会忽略的部分匹配。同时，基于全球特征的重排也展示了具有高计算效率的有希望的结果。", "innovation": "本文提出了一种局部到全局的检索模式，其中高效的局部特征搜索与有效的全局特征重排相结合。关键创新点在于提出了一种重新排序方法，其中全局特征基于局部特征检索相似性即时计算。这种仅重排的全球特征利用多维标度技术创建嵌入，这些嵌入尊重在搜索期间获得的局部相似性，从而显著提升重排效果。", "conclusion": "实验结果表明，该方法在检索性能上表现出色，在重访牛津和巴黎数据集上设定了新的最先进的结果。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04536", "html_url": "https://arxiv.org/abs/2509.04536", "title": "Q-SafeML：通过量子距离度量评估量子机器学习的安全性", "title_en": "Q-SafeML: Safety Assessment of Quantum Machine Learning via Quantum Distance Metrics", "authors": "Oliver Dunn,Koorosh Aslansefat,Yiannis Papadopoulos", "background": "随着量子计算的进步，机器学习在安全关键系统中的应用也获得了发展，这促进了量子机器学习（QML）这一新兴领域的形成。尽管经典的机器学习已经在安全监测方面取得了进展，但现有方法不适用于QML，因为量子计算的基本差异使得这些方法无法直接应用。鉴于QML的新型性，专门的安全机制仍处于起步阶段。", "innovation": "本文提出了Q-SafeML，这是一种针对QML的安全监控方法。该方法是在SafeML的基础上发展起来的，后者利用统计距离来评估模型的准确性并提供算法推理的信心。Q-SafeML的改编版本采用量子为中心的距离度量，这与QML输出的概率性质相一致。这种方法从依赖于数据集转变为依赖于模型的、分类后的评估，这一变化突显了与经典SafeML的主要区别，并且受到量子系统独特表示约束的驱动，需要在量子态空间上定义距离度量。Q-SafeML能够检测运营数据与训练数据之间的距离，以解决QML情境下的概念漂移问题。", "conclusion": "实验结果表明，Q-SafeML能够在量子卷积神经网络（QCNN）和变量子电路（VQC）模型中实现对人员的指导性监督，从而增强系统的透明性和安全性。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04160", "html_url": "https://arxiv.org/abs/2508.04160", "title": "DRIVE-T：一种生成和验证表达性测试的选拔性与代表性的数据可视化项目方法", "title_en": "DRIVE-T: A Methodology for Discriminative and Representative Data Viz Item Selection for Literacy Construct and Assessment", "authors": "Angela Locoro,Silvia Golia,Davide Falessi", "background": "当前在数据可视化素养测评中，衡量水平的难度级别设计不明确，可能限制了测量的表达性。这在测试设计和测评重用上都存在问题。", "innovation": "提出了一种名为DRIVE-T的方法，用于驱动评估项目的构建和评估。DRIVE-T方法包括三个步骤：1. 标记与一组数据可视化相关的任务型项目；2. 独立评分者对项目的难度进行评估；3. 通过多项面Rasch测度模型分析评分者的原始分数，观察测量结构难度级别。", "conclusion": "通过DRIVE-T方法，展示了并应用到了项目库上，以建模数据可视化素养测量结构的难度级别。该测量结构来自符号学，基于数据可视化所需的知识。该方法提供了形成性测量构造的生成方法，并通过一个试点研究验证了该方法的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04541", "html_url": "https://arxiv.org/abs/2509.04541", "title": "基于金融的算法交易优化", "title_en": "Finance-Grounded Optimization For Algorithmic Trading", "authors": "Kasymkhan Khubiev,Mikhail Semenov,Irina Podlipnova", "background": "深度学习正在迅速发展，并逐渐应用于各个领域。然而，在金融领域，特别是在需要解释的人工智能方面，深度学习仍然面临挑战。传统的经典方法在自然语言处理、计算机视觉和预测等方面表现优异，但在金融领域中并不完美，因为金融领域的专家会使用不同的指标来评估模型性能。", "innovation": "该研究引入了基于金融的损失函数，这些损失函数是根据定量金融指标（包括夏普比率、PnL和最大回撤）衍生出来的。此外，还提出了一种周转率正则化方法，该方法内在地将生成位置的周转限制在预定义的范围内。结果表明，提出的损失函数与周转率正则化结合使用，在算法交易指标下比传统均方误差损失在回报预测任务中的表现更优。研究表明，基于金融的指标可以提高交易策略和投资组合优化的预测性能。", "conclusion": "提出的基于金融的损失函数与周转率正则化策略在算法交易指标下比传统的均方误差损失在回报预测任务中表现更优。基于金融的指标能够提高交易策略和投资组合优化的预测性能。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.10833", "html_url": "https://arxiv.org/abs/2405.10833", "title": "从CT和MRI扫描自动分割头颈部癌症患者的危及器官", "title_en": "Automatic segmentation of Organs at Risk in Head and Neck cancer patients from CT and MRI scans", "authors": "Sébastien Quetin,Andrew Heschl,Mauricio Murillo,Rohit Murali,Piotr Pater,George Shenouda,Shirin A. Enger,Farhad Maleki", "background": "该研究旨在解决头颈部癌症患者中，自动分割30个危及器官（OARs）的需求。目前存在多种分割方法，但可能存在性能不稳定、灵活性不足等问题。本文介绍了一种高性能、鲁棒且灵活的深度学习管道，利用MRI、CT或两者结合来自动分割OARs，以便更准确地评估治疗效果和诊断病情。研究团队使用了多种数据集进行训练和验证，证明了该方法的有效性。", "innovation": "该方法通过结合MRI和CT数据，利用nnU-Net管道进行分割。在训练过程中应用模态丢弃（Modality Dropout），确保模型能在训练时从两种模态中学习，并在推理时能够处理缺失的模态。该研究的创新之处在于提高分割算法的鲁棒性和灵活性，从而在不同的数据环境下保持高性能。实验结果表明，该方法在头颈部OARs分割中达到了最先进的性能。", "conclusion": "该提出的管道在所有参选HaN-Seg挑战赛的参赛者中获得了最高的Dice Score（78.12%）和Hausdorff Distance（3.42 mm）。并且在TCIA数据集中表现出了与Limbus AI软件相似的高一致性（DS：77.43%，HD：3.27 mm）。此外，该管道可以无缝地根据CT、MRI或两者来分割OARs，从而建立了全自动化、多模态分割H&N OARs的新标杆。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04544", "html_url": "https://arxiv.org/abs/2509.04544", "title": "i-Mask: 智能呼吸口罩用于驱动活动识别", "title_en": "i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition", "authors": "Ashutosh Kumar Sinha,Ayush Patel,Mitul Dudhat,Pritam Anand,Rahul Mishra", "background": "呼吸的吸入和呼出模式包含重要的生理信号，可用于预测人类行为、健康趋势和生命体征。人类活动识别（HAR）与这些生命体征密切相关，提供了关于生活质量的更深层次见解，并支持实时健康监测。本研究旨在利用具有集成传感器的定制口罩捕捉呼出的呼吸模式，开发新的HAR方法，以实现对人体活动和健康的实时监测和预测。", "innovation": "提出了一种名为i-Mask的新型HAR方法，利用一个结合了传感器的定制口罩捕捉呼吸模式。所收集的数据经过噪声过滤、时间序列分解和标签化处理，用于训练预测模型。这种方法验证了其在准确性和应用上的有效性，特别是在医疗健康和健身应用方面展现出巨大潜力。", "conclusion": "实验结果证明了i-Mask方法的有效性，准确率高达95%以上，该方法有望在医疗健康和健身领域得到广泛应用。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04575", "html_url": "https://arxiv.org/abs/2509.04575", "title": "自洽任务空间的构建以促进自我提升", "title_en": "Bootstrapping Task Spaces for Self-Improvement", "authors": "Minqi Jiang,Andrei Lupu,Yoram Bachrach", "background": "在许多任务领域中，进步往往是通过反复修改先前解决方案而逐步实现的。利用强化学习（RL）训练能够持续自我改进的智能体是一种自然的选择。然而，传统的RL方法通常假定有固定的迭代深度，这可能导致资源浪费或不合理性。", "innovation": "本文提出了Exploratory Iteration（ExIt），这是一种家族式的自动课程 RL 方法，直接利用自我改进任务的循环结构，使语言模型能够仅通过训练最多信息性的单步迭代，在推理时进行多步自我改进。ExIt 通过在每个 episode 中选择最具有信息价值的中间过程来扩展任务空间，将这些起始点作为新的自我迭代任务实例进行训练。此外，ExIt 还可以与明确的探索机制结合以维持更大的任务多样性。在多个涵盖竞评比拼数学、多轮工具使用和机器学习工程的领域中，本文展示了无论是从单个任务实例还是多个任务实例开始，ExIt 策略都可以产生表现出强大的自我改进能力的策略，并能够在超出训练时平均迭代深度的步预算范围内逐步提高性能。", "conclusion": "本文通过一系列实验，证明了ExIt策略在多个领域中表现出强大的自我改进能力，且多步自我改进的能力能在超出现有训练步长预算的情况下实现更高的性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04588", "html_url": "https://arxiv.org/abs/2509.04588", "title": "基于信仰引导的神经网络集成解释", "title_en": "Toward Faithfulness-guided Ensemble Interpretation of Neural Network", "authors": "Siyu Zhang,Kenneth Mcmillan", "background": "解释特定神经网络推断的可解释性和真实性对于理解并评估模型行为至关重要。现有的解释框架在提升可视化效果和信仰度分数方面通常有局限性。", "innovation": "引入了一个名为FEI（信仰引导的集成解释）的框架，通过采用平滑近似方法提升定量信仰度分数，并提出新的定量和定性衡量指标来增强隐藏层编码的信仰度，从而更广泛且有效地提升解释的可解释性和可视化效果。", "conclusion": "FEI在广泛的实验中表现优于现有方法，显著提高了定性可视化效果和定量信仰度分数。这项研究为提升神经网络解释的信仰度建立了一个全面的框架，注重广度和精确度。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04583", "html_url": "https://arxiv.org/abs/2509.04583", "title": "实例适配采样在近似逆问题解的数据集构建中的应用", "title_en": "Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions", "authors": "Jiequn Han,Kui Ren,Nathan Soedjak", "background": "典型的基于学习的方法旨在从先验分布在高维条件下的数据集中学得一个通用的逆映射，且训练过程与特定测试实例无关。在先验具有高本征维度或需要高精度学习解决方案时，可能需要大量的训练样本，这导致了大量数据收集成本。相比之下，该方法基于特定测试实例动态分配采样努力，能够在样本效率上取得显著提升。", "innovation": "提出了一种实例适配采样框架，可以根据特定测试实例动态分配采样努力，从而显著提高样本效率。通过迭代细化训练数据集，该策略根据每个测试实例周围逆映射的几何结构来定制数据集。", "conclusion": "在两种类型的结构先验下，该方法在逆散射问题中显示出有效性。结果表明，当先验更复杂或要求更高精度时，该方法的优势更加明显。尽管实验关注特定的逆问题，但该适配采样策略广泛适用，易于扩展到其他逆问题，提供了一种可扩展且实用的替代传统的固定数据集训练模式。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.00030", "html_url": "https://arxiv.org/abs/2509.00030", "title": "MultiStream-LLM：多模态融合促进鲁棒手语翻译", "title_en": "MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation", "authors": "Marshall Thomas,Edward Fish,Richard Bowden", "background": "尽管在无光泽手语翻译（SLT）方面取得了进展，但单一端到端模型在自然手语的两个关键组件——高速手指拼写和非手动面部提示的结合上仍然表现不佳。最近，自动手语翻译使用大型语言模型的进步暂时绕过了这一挑战，但使单一网络同时学习这些任务，导致在翻译关键信息（如人名、地点和技术术语）时表现不佳。本文的背景在于探讨如何通过隔离并单独解决不同的识别任务后再融合的方法，来提高手语翻译的鲁棒性和准确性。", "innovation": "本文引入了MultiStream-LLM，这是一种模块化框架，旨在克服上述限制。该方法采用专门的预测器分别处理连续手语、字母拼写和唇读等不同模态，并将每个模态解码为一系列令牌。然后利用轻量级的变压器解决时间错位，将组合表示传递给大型语言模型（LLM）进行最终的句子生成。这种方法在How2Sign基准测试上取得了新的SOTA表现，BLEU-4得分为23.5，指法拼写数据集ChicagoFSWildPlus上字母准确率为73.2%，验证了隔离并独立解决不同识别任务后再整合的方法的有效性，提升了手语翻译的质量和可靠性。", "conclusion": "本研究通过引入多专家框架MultiStream-LLM，分别处理手语连续动作、字母拼写和唇读，解决了单一网络在手语翻译中的限制问题。实验结果表明，这种方法在多个数据集上均显著提高了翻译质量，证明了多专家框架在提升手语翻译鲁棒性和准确度方面的优势。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02586", "html_url": "https://arxiv.org/abs/2509.02586", "title": "MitoDetect++: 一个抗域移的管道用于检测和异常亚型分类", "title_en": "MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping", "authors": "Esha Sadia Nasir,Jiaqi Lv,Mostafa Jahanifar,Shan E Ahmed Raza", "background": "在计算病理学领域，自动检测和分类有丝分裂图象，尤其是区分异常有丝分裂与正常有丝分裂，仍然是一个关键挑战。MitoDetect++ 是为 2025 年 MIDOG 挑战赛设计的一个统一深度学习管道，旨在同时处理有丝分裂检测和异常有丝分裂分类任务。", "innovation": "MitoDetect++ 使用基于 U-Net 的编码解码器架构，使用 EfficientNetV2-L 作为骨干，并加入了注意力模块，在检测阶段使用组合分割损失进行训练。在分类阶段，利用 Virchow2 视觉变压器，并通过低秩适应（LoRA）方法进行高效微调，以减少资源消耗。此外，通过集成增强、焦损以及组感知分层五折交叉验证来提高泛化能力和缓解域偏移问题。在推理阶段，使用测试时增强（TTA）来增强鲁棒性。", "conclusion": "MitoDetect++ 方法在验证域上获得了 0.892 的均衡准确率，显示出其在临床应用和跨任务扩展方面的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04653", "html_url": "https://arxiv.org/abs/2509.04653", "title": "将变换器架构解读为隐式多项式回归", "title_en": "Interpreting Transformer Architectures as Implicit Multinomial Regression", "authors": "Jonas A. Actor,Anthony Gruber,Eric C. Cyr", "background": "机制可解释性旨在理解现代机器学习模型内部组件（如权重、激活和层）如何导致模型的整体行为。特别是在变换器模型中，尽管注意力机制占据中心地位，但其数学基础以及与特征多义性、叠加以及模型性能的关系仍然不清楚。", "innovation": "本文创新性地在固定的多项式回归环境下建立了注意力机制与隐式多项式回归之间的新联系。具体来说，文章展示了通过优化潜在特征实现的最优解与注意力块所诱导的动力学一致。这种发现使得变换器中表征的演变可以被解读为恢复分类最优特征的轨迹。", "conclusion": "文章说明了在变换器中表征演变的过程可以被理解和解释为一个恢复分类最优特征的轨迹，从而提高了对注意力机制及其与模型性能间关系的理解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04631", "html_url": "https://arxiv.org/abs/2509.04631", "title": "Transductive conformal预测效率-置信度权衡的基本界限", "title_en": "Fundamental bounds on efficiency-confidence trade-off for transductive conformal prediction", "authors": "Arash Behboodi,Alvaro H.C. Correia,Fabio Valerio Massoli,Christos Louizos", "background": "该论文探讨了一种能够同时预测多个数据点的递推一致预测方法。在给定置信水平的情况下，目标是构建一个预测集，确保该集包含了真实结果的概率达预定置信度。论文分析了递推方法中的效率与置信度之间的基本权衡，其中效率定义为预测集的大小。", "innovation": "论文提出了严格有限样本界限，表明任何非平凡置信水平都会导致具有固有不确定性数据的预测集大小呈指数增长。界限中的指数随着样本数量线性增长，且与数据的条件熵成正比。此外，界限还包括一个二次项，定义为对数条件概率分布的变异性。同时，论文证明该界限在理想化情况下是可实现的。特别地，在所有测试数据点共享同一标签的情景下，该论文将递推预测归约为经验统计下的假设检验问题，提出了渐近最优的置信度预测，并分析了误差指数。", "conclusion": "总的来说，论文得出了递推一致预测中效率-置信度权衡的基本界限，明确这种权衡是如何依赖于数据集的规模和条件熵的。同时还展示了在某些特定条件下的优化的置信预测方法。"}
{"llm_update_time": "20250909", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.17733", "html_url": "https://arxiv.org/abs/2506.17733", "title": "YOLOv13: 实时物体检测中的超图增强自适应视觉感知", "title_en": "YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception", "authors": "Mengqi Lei,Siqi Li,Yihong Wu,Han Hu,You Zhou,Xinhu Zheng,Guiguang Ding,Shaoyi Du,Zongze Wu,Yue Gao", "background": "YOLO系列模型因其优越的准确性和计算效率在实时物体检测中占据主导地位。然而，YOLO11及其早期版本的卷积结构和YOLOv12引入的区域基自注意力机制仅限于局部信息聚合和两两相关建模，无法捕捉全局的多对多高阶相关性，从而在复杂场景下限制了检测性能。", "innovation": "本研究提出YOLOv13，一种准确且轻量级的物体检测器。我们设计了基于超图的自适应相关增强（HyperACE）机制，能够自适应利用潜在的高阶相关性，突破了基于超图计算的传统方法中仅两两相关建模的局限，实现了高效的全局跨位置和跨尺度特征融合与增强。此外，我们提出基于HyperACE的全管道聚合并分发（FullPAD）范式，有效实现了整网范围内细粒度信息流和表示的协同作用。我们还通过使用深度可分离卷积取代了传统的大型卷积，并设计了一系列显著减少参数量和计算复杂度而不牺牲性能的块结构。实验结果证明，我们的方法在MS COCO基准上实现了最先进的性能，且参数和FLOPs更少。", "conclusion": "我们的YOLOv13-N在YOLO11-N和YOLOv12-N上的mAP分别提高了3.0%和1.5%，我们提供的YOLOv13模型的代码和模型可从以下链接下载：this https URL。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04661", "html_url": "https://arxiv.org/abs/2509.04661", "title": "使用神经网络从从零开始的学习数据中灵活推断学习规则", "title_en": "Flexible inference of learning rules from de novo learning data using neural networks", "authors": "Yuhan Helena Liu,Victor Geadah,Jonathan Pillow", "background": "理解动物如何学习是神经科学领域的重要挑战，对开发与动物或人类相匹配的人工智能具有日益重要的意义。现有的大多数方法要么假定特定的学习规则参数形式（例如，Q学习，策略梯度），要么局限于简化场景（如多臂赌博机任务），这些场景并不需要从头学习全新的输入-输出映射。相比之下，动物往往需要从头学习新行为，这为推断学习规则带来了丰富的挑战。该研究直接从动物在新任务学习过程中的决策数据中推断学习规则，要求模型足够灵活以捕捉次优化、历史依赖性以及丰富的外部刺激整合，而无需强烈的结构先验。这种方法将有助于实验训练方案设计和行为数字孪生体的发展。", "innovation": "该研究提出了一种非参数框架，通过深层神经网络（DNN）参数化每轮更新策略权重，通过仿真验证了该框架，并进一步提出了一个递归变体（RNN），该递归变体通过允许更新依赖于试次历史来捕捉非马尔可夫动力学。在对小鼠在数周内学习感官决策任务的行为数据集进行应用时，模型在保留数据上提高了预测效果。推断出的规则显示了正确试次和错误试次后的不对称更新以及历史依赖性，符合非马尔可夫学习。", "conclusion": "总之，这些结果引入了一个在从零开始学习任务中从行为数据推断生物学学习规则的灵活框架，为实验训练方案设计和行为数字孪生体的开发提供了见解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04601", "html_url": "https://arxiv.org/abs/2509.04601", "title": "量子增强可学习加权多任务学习在药代动力学和毒理预测中的应用", "title_en": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction", "authors": "Han Zhang,Fengji Ma,Jiamin Su,Xinyue Yang,Lei Wang,Wen-Cai Ye,Li Liu", "background": "在药物发现和开发过程中，ADMET（吸收、分布、代谢、排泄和毒性）预测起着关键作用，加速了新药的筛选和优化。现有方法主要依赖单任务学习（STL），但很难充分利用任务之间的互补性。单任务学习独立训练和推理时消耗更多计算资源。为此，本文研究了一个量子增强和任务加权多任务学习（QW-MTL）框架，专门用于处理ADMET分类任务。该框架基于Chemprop-RDKit，采用量子化学描述符丰富分子表示，提供额外的电子结构和相互作用信息。同时，引入了一种新的可学习加权方案，结合数据集范围的先验知识和可学习参数，实现跨任务动态损失平衡。", "innovation": "本文提出了QW-MTL框架，特别针对13个Therapeutics Data Commons（TDC）分类基准进行系统性的联合多任务训练，确保标准化且现实的评估环境。通过采用率领数据拆分，该框架有效地利用了量子化学特征和可学习任务加权，显著提升了12/13个任务的预测性能，同时保持了低模型复杂度和快速推理速度，验证了多任务分子学习的有效性和效率。", "conclusion": "QW-MTL框架通过整合量子化学特征和可学习任务加权，显著改善了ADMET分类任务的预测性能，展现了多任务分子学习在药物发现与开发过程中的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04683", "html_url": "https://arxiv.org/abs/2509.04683", "title": "崩溃之前的声音：复杂系统中闪烁的深度学习检测", "title_en": "Echoes Before Collapse: Deep Learning Detection of Flickering in Complex Systems", "authors": "Yazdan Babazadeh Maghsoodlo,Madhur Anand,Chris T. Bauch", "background": "复杂系统中的临界转折点预测历来依赖深度学习技术，然而其检测闪烁（由噪声驱动的在共存稳定状态之间的切换）的能力尚未被研究。闪烁是气候系统、生态系统、金融市场等系统减少韧性的一种特征。它可以预示难以预测但具有重大影响的关键制度转变。", "innovation": "研究显示，通过使用卷积长短时记忆网络（CNN LSTM），可以在从简单多项式函数上生成并带有噪声的合成时间序列数据上进行训练，并能准确辨识闪烁模式。尽管是在简化的动态上进行训练，这些模型仍能适应各种随机系统，并能够可靠地在现实世界数据（包括仓鼠体温记录和非洲湿润期的古气候代理数据）中检测到闪烁现象，证明了深度学习能够从嘈杂的非线性时间序列中提取早期预警信号，为广泛动态系统中的不稳定性识别提供了灵活框架", "conclusion": "研究结果表明，深度学习技术能够从噪声和非线性时间序列中提取早期预警信号，为复杂系统的不稳定性识别提供了一种灵活的方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04734", "html_url": "https://arxiv.org/abs/2509.04734", "title": "Beyond I-Con: 探索表示学习中距离度量的新维度", "title_en": "Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning", "authors": "Jasmine Shone,Shaden Alshammari,Mark Hamilton,Zhening Li,William Freeman", "background": "研究表明，超过23种表示学习方法在学习时隐式最小化了数据与学习后分布之间的Kullback-Leibler (KL) 散度。然而，基于KL散度的损失可能会与真正的目标不一致，KL散度的不对称性和无界性也可能导致优化挑战。", "innovation": "提出了Beyond I-Con框架，该框架通过探索替代统计偏差和相似性核，系统地发现新的损失函数。通过使用TV距离修改PMI算法、使用TV距离和基于距离的相似性核代替KL散度和角核、使用有界的f-分歧代替KL散度，分别在无监督聚类、监督对比学习和降维方面取得了更好的结果。", "conclusion": "研究结果突显了在表示学习优化中考虑分歧和相似性核选择的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04699", "html_url": "https://arxiv.org/abs/2509.04699", "title": "CPEP: 对比姿势-肌电预训练增强肌电信号的手势泛化能力", "title_en": "CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals", "authors": "Wenhui Cui,Christopher Sandino,Hadi Pouransari,Ran Liu,Juri Minxha,Ellen L. Zippi,Aman Verma,Anna Sedlackova,Behrooz Mahasseni,Erdrin Azemi", "background": "手部手势分类在计算机视觉中是一个被广泛研究的问题，通常利用高质量结构化数据如视频、图像和手部骨架。利用低功耗、低成本的生物信号，例如表面肌电图（sEMG），可以在穿戴设备上实现连续的手势预测。本文中，我们展示了从弱模态数据中学习与高质量结构化数据所对齐的表示可以提高表示质量并且支持零样本分类。具体而言，我们提出了一种对比姿势-肌电预训练（CPEP）框架，用于对齐肌电和姿态表示，其中我们学习一个能够生成高质量且姿势信息丰富的肌电编码器。我们通过线性探针和零样本设置评估了我们模型的手势分类性能。我们的模型在内分布手势分类上优于基准模型emg2pose高达21%，在外分布未见手势分类上表现更佳，高出72%。", "innovation": "提出了一种对比姿势-肌电预训练（CPEP）框架，用于对齐肌电和姿态表示，学习一个生成高质量且姿势信息丰富的肌电编码器，从而提高了手势分类性能，特别是在零样本分类方面表现突出。", "conclusion": "与基准模型emg2pose相比，我们的模型在内分布手势分类中表现优异，提升了21%，在外分布未见手势分类中表现更加出色，提升了72%。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04815", "html_url": "https://arxiv.org/abs/2509.04815", "title": "An Arbitration Control for an Ensemble of Diversified DQN Variants in Continual Reinforcement Learning", "title_en": "An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning", "authors": "Wonseo Jang,Dongjae Kim", "background": "深度强化学习（RL）模型在静态环境中学习高效策略方面表现出色，但在持续强化学习（CRL）场景中容易遗忘已学知识（灾难性遗忘），导致性能下降。", "innovation": "本文提出了一种仲裁控制机制，将多个RL代理平行训练并进行仲裁控制，以提高持续强化学习中的性能。关键创新点包括：（1）构建多种侧重不同价值函数的DQN变体，（2）对近期表现较好的代理进行优先选择。", "conclusion": "该研究通过引入仲裁控制机制，显著提高了在静态和持续环境中的RL代理性能，并通过实验证明了该方法的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04622", "html_url": "https://arxiv.org/abs/2509.04622", "title": "衡量度量：衡量表示相似性度量在不同模型家族中的区分能力", "title_en": "Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families", "authors": "Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla", "background": "在神经科学和AI领域，表示相似性度量是基本工具，但缺乏不同模型家族之间的系统比较。本文引入了一个定量框架，通过评估这些度量将模型家族区分的能力来评价表示相似性度量，比较了几种常见的度量方法包括RSA、线性预测、Procrustes和软匹配等在不同架构（CNNs，Vision Transformers，Swin Transformers，ConvNeXt）和训练机制（有监督 vs 自监督）下的表现能力。", "innovation": "本文提出了一个新的定量框架来评估表示相似性度量的区分能力，并使用三种互补的分离度量（信号检测理论中的d'、轮廓系数和ROC-AUC）系统地评估了常用方法的辨别力。结果表明，随着度量施加更严格的对齐约束，区分能力系统地增加。在基于映射的方法中，软匹配在最高，其次是Procrustes对齐和线性预测。非拟合方法如RSA在不同家族中也表现出较强的区分能力。这些结果提供了首次通过区分能力视角系统比较相似性度量的方法，有助于识别它们的相对敏感性，并指导在大规模模型和脑部对比中的度量选择。", "conclusion": "结果表明，为大规模模型和脑部对比选择相似性度量时应考虑不同的测量方法对分离能力的影响，以提高比较的准确性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04782", "html_url": "https://arxiv.org/abs/2509.04782", "title": "VARMA-Enhanced Transformer for Time Series Forecasting", "title_en": "VARMA-Enhanced Transformer for Time Series Forecasting", "authors": "Jiajun Song,Xiaoou Liu", "background": "Transformer-based模型在时间序列预测中取得了显著进展。最近的工作，如Cross-Attention-only Time Series transformer (CATS)，表明移除自注意力可以提高模型的准确性和效率。然而，这种精简的架构可能会遗漏传统统计模型如向量自回归移动平均模型（VARMA）所有效捕捉的细粒度局部时间依赖关系。为此，我们提出了VARMAformer模型，结合了跨注意力框架的高效性与经典时间序列分析的原则。该模型的创新之处在于：(1) 一种专有的VARMA启发式特征提取器（VFE），在.patch级别上明确建模自回归（AR）和移动平均（MA）模式；(2) 使用时间门控机制增强的注意力机制（VE-atten），使查询更加关注上下文信息。通过将这些经典的洞察融入现代的主干网络中，VARMAformer能够同时捕捉全局和局部的时间依赖关系。", "innovation": "VARMAformer模型提出了两种创新：(1) 一种专有的VARMA启发式特征提取器（VFE），在.patch级别上明确建模自回归（AR）和移动平均（MA）模式；(2) 使用时间门控机制增强的注意力机制（VE-atten），使查询更加关注上下文信息。通过将这些经典的洞察融入现代的主干网络中，VARMAformer能够同时捕捉全局和局部的时间依赖关系。", "conclusion": "通过在广泛使用的时间序列基准数据集上的大量实验，我们展示了我们的模型始终优于现有的最先进的方法。我们的工作验证了将传统的统计洞察力集成到现代深度学习框架中对于时间序列预测的重要益处。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04921", "html_url": "https://arxiv.org/abs/2509.04921", "title": "使用混沌时间序列进行大规模预训练的规模律及其在金融时间序列可预测性", "title_en": "Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series", "authors": "Yuki Takemoto", "background": "时间序列预测在气象、交通、电力、经济、金融等多个领域中发挥着关键作用。特别是，预测金融工具的回报是一个具有挑战性的问题。一些研究人员提出了适用于各种预测任务的时间序列基础模型。同时，由于现实中的时间序列显示出混沌特性，研究人员开发了生成人工混沌时间序列的方法，构建多样化的数据集并训练模型。", "innovation": "本文提出了一种通过生成人工混沌时间序列并应用重采样技术模拟金融时间序列数据的方法，然后使用这些数据作为训练样本。随着重采样间隔的增加以扩展预测范围，研究采用100亿训练样本进行大规模预训练，创建了使用实际比特币交易数据的多时间段测试数据集，并采用零样本预测。基于这些预测评估的简单交易策略的盈利能力，显示出显著优于自相关模型的表现。在大规模预训练过程中观察到一种规模律现象，即通过对混沌时间序列增加训练样本数量，可以达到一定预测性能，无论预测范围如何延伸。", "conclusion": "研究结果表明，根据规模律现象，在投资大量计算资源的情况下，可以预测未来的事件。未来的研究应集中于进一步大规模训练并验证该规模律是否适用于各种混沌模型。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04905", "html_url": "https://arxiv.org/abs/2509.04905", "title": "革新时代还是泡沫？探索大型模型在硬件设计中的极限", "title_en": "Revolution or Hype? Seeking the Limits of Large Models in Hardware Design", "authors": "Qiang Xu,Leon Stok,Rolf Drechsler,Xi Wang,Grace Li Zhang,Igor L. Markov", "background": "近年来，大型语言模型（LLMs）和大型电路模型（LCMs）在电子设计自动化（EDA）领域引起了广泛关注，预示着电路设计和优化的深刻变革。然而，这样的乐观情绪也伴随着巨大怀疑：这些AI模型是硬件设计的真正革命，还是虚幻短暂的期望泡沫？本文旨在通过综合专家视角，探讨大型AI模型在硬件设计中的实际能力、根本局限性和未来潜力，从而为ICCAD 2025研讨会奠定基础。", "innovation": "综合了学术界和工业界的专家观点，辩证分析大型AI模型在硬件设计中的可靠性和可扩展性，以及解释模型的意义，为该领域的争论提供了颇具见地的新视角。", "conclusion": "本文提供了一篇权威的综述，针对当前最具争议和影响力的科技趋势之一，提出了新的见解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04668", "html_url": "https://arxiv.org/abs/2509.04668", "title": "超越普通Lipschitz约束：具备Tsybakov噪声条件的差异隐私随机优化", "title_en": "Beyond Ordinary Lipschitz Constraints: Differentially Private Stochastic Optimization with Tsybakov Noise Condition", "authors": "Difei Xu,Meng Ding,Zihang Xiang,Jinhui Xu,Di Wang", "background": "该研究聚焦于在差异隐私（Differential Privacy, DP）模型下的随机凸优化问题。以往的研究通常假设损失函数具有Lipschitz约束。然而，本文不同，在Tsybakov噪声条件下假设总体风险函数满足该条件，即使Lipschitz常数可能非常大甚至不存在，但仍假设损失函数的二范数梯度存在有界k阶矩（其中k>=2）。这对于多种应用场景而言是非常重要的，因为它使得在某些极端条件下也能维持一定的隐私保护水平和优化性能。", "innovation": "本文提出了两个主要创新点：\n1. 提出了一种（ε, δ）-差异隐私算法，在该假设下无论Lipschitz常数如何，都有一个与样本大小、模型维度和梯度k阶矩相关的高概率上界，即$\tilde{O}\bigl(\bigl(\tilde{r}_{2k}\bigl(\frac{1}{\root\frac{k-1}{k}\bigr)\bigr)^\frac{\theta}{\theta-1}\bigr)$。\n2. 延伸到θ≥$\bar{\theta}$的情况，其中$\bar{\theta}$是一个已知常数，并且在较小的隐私预算ε下，即使损失函数不具有Lipschitz约束，也提供了一个与样本大小、模型维度和梯度k阶矩相关的上界，即$\tilde{O}\bigl(\bigl(\tilde{r}_{k}\bigl(\frac{1}{\root\frac{k-1}{k}\bigr)\bigr)^\frac{\theta}{\theta-1}\bigr)$。此外，还证明了任何θ≥2的情况下，ρ-零中心差异隐私的私人最小最大率的下界，即$\tilde{O}\bigl(\bigl(\tilde{r}_{k}\bigl(\frac{1}{\root\frac{k-1}{k}\bigr)\bigr)^\frac{\theta}{\theta-1}\bigr)$。", "conclusion": "本文研究了在Tsybakov噪声条件下差异隐私随机优化问题，并提出了两个具体的差异隐私算法的上界，同时给出了这些算法的理论下界，结果显示在某些极值条件下，这种算法能够保持相对宽松的隐私保护水平和优秀的优化性能。所提出的结果对于面对复杂数据时优化模型具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04684", "html_url": "https://arxiv.org/abs/2509.04684", "title": "KRAFT: 一种基于知识图谱的自动化地图合并框架", "title_en": "KRAFT: A Knowledge Graph-Based Framework for Automated Map Conflation", "authors": "Farnoosh Hashemi,Laks V.S. Lakshmanan", "background": "数字地图在导航、车队管理和拼车等应用程序中起着至关重要的作用，需要定期更新以保证其准确性和现势性。然而现有的地理空间数据库提供的信息局限于特定区域或存在缺失，且缺乏处理非线性对象的能力。现有地图合并方法难以扩展到非线性对象，并且主要依赖于预定义规则的数据驱动方式匹配实体。", "innovation": "KRAFT 设计了一种基于学习的方法，包括三个部分：(1) 知识图构建 - 将每个地理空间数据库表示为知识图；(2) 位置匹配 - 使用知识图对齐方法和地理空间特征编码器匹配获取知识图中的实体；(3) 地图合并 - 使用混合整数线性规划实现合并，确保合并后地图的逻辑一致性。实验结果显示，KRAFT 在地图合并任务中不仅优于最先进的和基准方法，在每个模块（例如位置匹配和地图合并）也单独优于传统的匹配和合并方法。", "conclusion": "KRAFT 提供了一种新的地图合并方法，能够处理非线性对象并实现更精确和一致的地图合并。这种基于学习的方法可以大大提高地图合并的性能和效果。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04785", "html_url": "https://arxiv.org/abs/2509.04785", "title": "图去学习：图神经网络中的高效节点移除", "title_en": "Graph Unlearning: Efficient Node Removal in Graph Neural Networks", "authors": "Faqian Guan,Tianqing Zhu,Zhoutian Wang,Wei Ren,Wanlei Zhou", "background": "随着对隐私攻击和潜在敏感信息泄露的关注增加，研究人员积极寻求有效去除敏感训练数据和减少图神经网络（GNN）模型中隐私风险的方法。现有的节点去学习方法要么限制了GNN结构，要么没有有效利用图拓扑进行节点去学习，甚至破坏了图的拓扑结构，使性能-复杂性折中难以满意地实现。为了解决这些问题并实现GNN中训练节点移除的高效去学习，本文提出了三种新的节点去学习方法：基于类别的标签替换、拓扑引导的邻居平均后验概率和类一致的邻居节点过滤。其中，拓扑引导的邻居平均后验概率和类一致的邻居节点过滤有效地利用了图的拓扑特性，从而提高了节点去学习的有效性。为了验证所提出方法在节点去学习中的优越性，我们在三个基准数据集上进行了实验。评价标准包括模型功效、去学习功效和去学习效率。实验结果表明了所提方法的实用性和效率，并证明了其在节点去学习中的优越性相较于最先进的节点去学习方法而言。总的来说，所提方法有效移除了敏感的训练节点，并保护了GNN中敏感节点的隐私信息，这些发现增强了GNN模型的隐私和安全性，为节点去学习领域的研究提供了宝贵见解.", "innovation": "本文提出了三种新的节点去学习方法：基于类别的标签替换、拓扑引导的邻居平均后验概率和类一致的邻居节点过滤。这些方法有效利用了图的拓扑特性，提高了节点去学习的有效性。相比于现有方法，这些方法不仅没有限制GNN结构，还能够更好地利用图拓扑进行节点去学习，从而有效去学习敏感训练数据并保护敏感节点的隐私信息，提高GNN的安全性和保护隐私的能力。", "conclusion": "通过所提出的新型节点去学习方法，本文有效且高效地去除了敏感的训练节点，保护了GNN中敏感节点的隐私信息。实验结果证明了所提出的去学习方法适用于不同的数据集，并且相比于现有的节点去学习方法，新方法在模型功效、去学习功效和去学习效率方面均表现更优。这一发现促进了GNN模型的隐私增强，并为节点去学习领域的研究提供了有价值的见解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04973", "html_url": "https://arxiv.org/abs/2509.04973", "title": "拓扑感知图强化学习在云网络动态路由中的应用", "title_en": "Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks", "authors": "Yuxi Wang,Heyao Liu,Guanzi Yao,Nyutian Long,Yue Kang", "background": "本文提出了一种拓扑感知图强化学习方法，以解决云服务器环境中路由策略优化问题。研究背景基于云网络动态拓扑结构所带来决策不稳定性和缺乏足够结构认知的问题。", "innovation": "该方法通过集成结构感知状态编码模块(SASE)和策略自适应图更新机制(PAGU)，构建了一个统一的状态表示和结构演变框架。创新点在于通过多层图卷积和结构位置嵌入来建模节点状态，捕获通信拓扑中的高阶依赖关系，并进行自适应结构更新，以提高动态环境下的结构认知和适应性。", "conclusion": "实验结果表明，提出的拓扑感知图强化学习方法在吞吐量、延迟控制和链路平衡等多方面性能指标上优于现有模型，能够实现动态和复杂的云网络中高效且稳健的路由。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04713", "html_url": "https://arxiv.org/abs/2509.04713", "title": "自然频谱融合：p-指数周期调度与一阶优化早期决策边界对齐", "title_en": "Natural Spectral Fusion: p-Exponent Cyclic Scheduling and Early Decision-Boundary Alignment in First-Order Optimization", "authors": "Gongyue Zhang,Honghai Liu", "background": "在机器学习中，频谱行为已经被广泛讨论，但是优化器自身的频谱偏见仍然不清楚。这项工作探讨了一阶优化器具有内在的频谱偏好，这种偏好能够显著地重塑优化路径。", "innovation": "该研究提出了自然频谱融合（NSF）：将训练重新定义为可控的频谱覆盖与信息融合，并不仅仅是调整步长大小。NSF的核心原则包括将优化器视为动态平衡低频和高频信息的频谱控制器；并且定期在几乎不改变成本的情况下重新加权频谱带宽，不修改模型、数据或训练管道。通过 p-指数扩展第二动量项实现 NSF，并通过周期性调度机制实施。", "conclusion": "理论和实验表明，自适应方法强调低频，SGD 接近中性，负指数放大高频信息。周期性调度扩展了频谱覆盖，改善了跨带融合，并诱导早期决策边界对齐，在损失仍然较高时，准确率有所提高。在多个基准测试中，使用相同的学习率策略和固定超参数，p-指数周期性调度始终降低测试误差，并表现出不同的收敛行为；在某些任务上，仅使用四分之一的训练成本就能达到与基线相同的准确率。总体而言，NSF 揭示了优化器作为主动频谱控制器的角色，并提供了一种统一、可控和高效的框架来实现一阶优化。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04623", "html_url": "https://arxiv.org/abs/2509.04623", "title": "函数空间中基于神经算子的分段共轭预测", "title_en": "Split Conformal Prediction in the Function Space with Neural Operators", "authors": "David Millard,Lars Lindemann,Ali Baheri", "background": "无限维环境中神经算子的不确定性量化仍是一个开放问题，主要是由于缺乏针对函数输出的有限样本覆盖保证。现有的共轭预测方法仅适用于有限维空间，并且不能直接扩展到函数值输出。虽然高斯过程、贝叶斯神经网络和基于分位数的操作符可以提供一定程度的覆盖保证，但它们往往要求很强的分布假设，或导致保守的覆盖。本研究提出了一种分步方法，将分段共轭预测扩展到函数空间，通过先在一个有限维空间中使用输出函数空间的离散映射建立有限样本覆盖保证，然后通过细化离散度考虑渐进收敛，以将这些保证提升到函数空间。为了分析分辨率的影响，将共轭半径分解为离散化、校准和错配三个部分，并提出了基于回归的校正方法来实现不同分辨率间的校准转移。此外，还提出了两种诊断指标（共轭集合评分和内部一致性）来量度自回归设置下的预测降级。实验证明，该方法能够通过减少分辨率变化的影响保持校准覆盖，并在高分辨率任务中实现更好的覆盖。", "innovation": "提出了分段共轭预测的扩展方法，该方法通过在有限维度空间中使用输出函数空间的离散映射处理无限维空间中的函数输出问题。通过考虑离散度细化过程中的渐进收敛性，将有限样本覆盖保证提升到函数空间。此外，提出了一种基于回归的校准转移方法，以实现不同分辨率间的共享，以及两种诊断指标来量化自回归预测的降级。", "conclusion": "研究结果表明，该方法在分辨率变化下保持了校准覆盖，并在高分辨率任务中取得了更好的覆盖。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04733", "html_url": "https://arxiv.org/abs/2509.04733", "title": "CoVeR: 符合准则的可靠自回归下一个token预测的校准", "title_en": "CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction", "authors": "Yuzhu Chen,Yingjie Wang,Shunyu Liu,Yongcheng Jing,Dacheng Tao", "background": "自回归预训练模型与解码方法相结合，在复杂推理任务中取得了显著成果。尽管主流的解码策略如束搜索可以生成可信的候选集，但它们往往缺乏可验证的覆盖保证，并且难以在搜索效率和需要多样化的路径之间取得平衡，尤其是对于某些现实应用场景中必不可少的长尾序列。", "innovation": "我们提出了一种名为CoVeR的新型解码策略，该策略基于容 conformal预测框架，同时保持了紧凑的搜索空间并确保了理想路径的高覆盖概率。理论分析表明，CoVeR确保了覆盖率达到至少$1 - \boldsymbol{\boldsymbol{\text{α}}}$，对于任何目标水平$\boldsymbol{\boldsymbol{\text{α}}} \boldsymbol{\boldsymbol{\text{∈}}} (0,1)$而言。", "conclusion": "CoVeR 解码策略在保持紧凑搜索空间的同时，确保了理想路径的高覆盖概率，理论上保证了其在任意目标水平$\boldsymbol{\boldsymbol{\text{α}}}$下能够实现至少$1 - \boldsymbol{\boldsymbol{\text{α}}}$的覆盖率。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04959", "html_url": "https://arxiv.org/abs/2509.04959", "title": "关于混淆矩阵归一化的研究：方法与几何解释", "title_en": "On the Normalization of Confusion Matrices: Methods and Geometric Interpretations", "authors": "Johan Erbani,Pierre-Edouard Portier,Elod Egyed-Zsigmond,Sonia Ben Mokhtar,Diana Nurbakova", "background": "混淆矩阵是评估分类器的标准工具，能提供关于分类错误的洞察。在异质环境中，其值受到两类混淆的相似性和数据分布偏差的影响。然而，混淆矩阵的值结合了这两方面因素，使得难以区分它们各自的贡献。", "innovation": "引入了使用迭代比例调整方法的双稳态归一化，这是一种行和列归一化的推广。这种新方法能够恢复分类相似性的原始结构。通过分离错误源，这种方法能够更准确地诊断模型行为，支持更具针对性的改进。还展示了混淆矩阵归一化与模型内部类表示之间的关系，并从几何上解释了标准和双稳态归一化。", "conclusion": "通过双稳态归一化和几何解释，对混淆矩阵的归一化方法进行了研究，有助于更准确地理解和改进分类器的行为。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04951", "html_url": "https://arxiv.org/abs/2509.04951", "title": "健康和帕金森病EEG中的眨眼检测：深度学习视角", "title_en": "Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective", "authors": "Artem Lensky,Yiding Qiu", "background": "眨眼在脑电图（EEG）中通常被视为不需要的伪迹。但近期研究表明，眨眼率及其变异性是监测认知负荷、注意力和潜在神经疾病的重要生理指标。本文通过对各种深度学习模型评估以将EEG信号分割为不自主眨眼和非眨眼部分，解决精确眨眼检测的关键任务。", "innovation": "本文提出了一个使用1、3或5个前额EEG电极进行眨眼检测的管道，并将其形式化为序列到序列任务，同时测试了包括标准递归神经网络、卷积神经网络（标准和深度可分离）、时序卷积网络（TCN）、变压器基模型以及混合架构在内的多个深度学习架构。模型在收集自UCSD的31名受试者公共数据集上进行了训练，并具有帕金森病患者的震颤验证功能。", "conclusion": "卷积神经网络与递归神经网络混合模型在所有模型中表现最好，健康受试组的眨眼检测准确率分别为93.8%、95.4%和95.8%，而在帕金森病患者组分别达到了73.8%、75.4%和75.8%。这项研究通过将分割任务分解为脑电图记录中的不自主眨眼和非眨眼部分，可计算眨眼率和其他统计指标，从而为深入理解脑部活动提供了新的方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04998", "html_url": "https://arxiv.org/abs/2509.04998", "title": "蛋白质在嵌入空间中的贝叶斯优化指导进化", "title_en": "Directed Evolution of Proteins via Bayesian Optimization in Embedding Space", "authors": "Matouš Soldát,Jiří Kléma", "background": "传统的指导进化是通过迭代合成新的蛋白质变体并使用昂贵且耗时的生物化学筛选来评估这些变体的期望特性来进行的。机器学习方法能够帮助选择信息丰富的或有前途的变体进行筛选，提高筛选质量并减少所需的筛选量。", "innovation": "本文提出了一种结合贝叶斯优化和基于预训练蛋白质语言模型提取的蛋白质变体信息表示的方法，显著改善了贝叶斯优化的性能，使用相同的筛选次数取得了更好的结果。此外，该方法在回归目标下优于现有的机器学习辅助指导进化方法。", "conclusion": "通过将贝叶斯优化与基于序列嵌入的蛋白质变体表示相结合，该方法在相同数量的筛选中取得了更好的结果，并且在回归目标下超越了现有的机器学习辅助指导进化方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04925", "html_url": "https://arxiv.org/abs/2509.04925", "title": "基于数据增强和自信学习的Transformer-BiGRU框架在网络入侵检测中的应用", "title_en": "A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection", "authors": "Jiale Zhang,Pengfei He,Fei Li,Kewei Li,Yan Wang,Lan Huang,Ruochi Zhang,Fengfeng Zhou", "background": "当前快速发展的数字通信中，网络流量数据的激增促使需要强大的网络入侵检测解决方案。传统的机器学习方法在处理大规模网络入侵数据集中的复杂模式时显得力不从心，特别是对于数据稀少和类别不平衡的问题。因此，本文结合了机器学习和深度学习技术，推出了一种新型框架TrailGate。", "innovation": "本文开发了TrailGate框架，该框架通过将Transformer和双向门控循环单元（BiGRU）架构与先进的特征选择策略和数据增强技术相结合，能在检测常见攻击类型的同时，迅速识别并应对源自现有模式的新出现的威胁。", "conclusion": "TrailGate算法在检测常见和已知的攻击类型方面表现出色，并具有识别并应对新出现威胁的独特能力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05037", "html_url": "https://arxiv.org/abs/2509.05037", "title": "MultiSurv: 多模态深度生存模型框架在前列腺和膀胱癌中的应用", "title_en": "MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer", "authors": "Noorul Wahab,Ethar Alzaid,Jiaqi Lv,Adam Shephard,Shan E Ahmed Raza", "background": "时间到事件（如复发）的准确预测在肿瘤学中是一个核心挑战，对治疗规划和患者管理有着重大影响。现有的研究致力于开发能够整合多种患者数据（如临床数据、MRI、RNA-seq和病理切片数据）的模型，以更准确地预测生物化学复发时间（在前列腺癌中）和癌症复发时间（在膀胱癌中）.", "innovation": "MultiSurv 使用了 DeepHit 模型结合投影层和跨模态注意力机制，这是一种利用多模态深度生存分析的新框架。它特别设计用于跨模态捕获互补的预后信号，并能够针对前列腺癌和膀胱癌的特定任务进行个性化风险分层预测。实验结果表明 MultiSurv 在 CHIMERA 大挑战任务中表现出色，特别是在前列腺癌生物化学复发预测中显示出较强的区分能力，在膀胱癌复发预测中的适应性和潜力也同样得到验证.", "conclusion": "结果表明，多模态的深度生存模型是一种有前景的方法，可应用于个性化前列腺和膀胱癌的风险分层。除了挑战的设定外，该框架还广泛适用于涉及多种生物医学数据的生存预测任务."}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04977", "html_url": "https://arxiv.org/abs/2509.04977", "title": "野蛮适应：基于尖锐度和特征正则化的测试时间熵最小化", "title_en": "Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization", "authors": "Shuaicheng Niu,Guohao Chen,Deyu Chen,Yifan Zhang,Jiaxiang Wu,Zhiquan Wen,Yaofo Chen,Peilin Zhao,Chunyan Miao,Mingkui Tan", "background": "当前的测试时适应（TTA）方法在处理混合分布偏移、小批次大小以及在线不平衡标签分布偏移等情况时，可能未能提升模型性能，甚至反而损害模型性能。这些情况是现有TTA方法在实际部署中的一大障碍。本文探讨了TTA不稳定的根源，发现批标准化层（Batch Norm）是关键的不稳定因素。使用批标准化无关的标准化层（如组规范化或层规范化）可以提高TTA的稳定性，但这种改进并非总是成功的，模型有时仍会陷入退化状态，将所有样本分类为同一类别。进一步分析显示，模型梯度在这一过程中初期暴增后急剧贬值，表明大量初始噪声样本可能破坏模型的适应能力；同时，模型表征具有较高的相关性和分类偏差。因此，为了解决上述问题，作者提出了一种基于尖锐度和可靠熵最小化的方法，称为SAR，从两个方面稳定TTA，即去除部分大梯度的噪声样本；鼓励模型权重趋向平坦的极小值，以增强模型对残留噪声样本的鲁棒性。此外，还提出了SAR^2，通过冗余正则化和不公正正则化两个正则化手段防止表示塌缩：减少特征间的冗余性；最大化原型中心的预测熵，从而惩罚偏向特定类别的表示偏差。实验结果表明，本文方法在上述复杂测试情况下比现有方法更稳定且计算效率更高。", "innovation": "论文提出了一种基于尖锐度和可靠熵最小化的方法（SAR），并进一步引入了一种新的方法SAR^2，通过两个正则化手段防止表示塌缩，从而在处理混合分布偏移、小批次大小以及在线不平衡标签分布偏移等复杂测试条件下，提高模型的鲁棒性和适应性。", "conclusion": "本文的方法在处理恶劣测试情景时表现得更加稳定，并且具有计算效率。通过这个方法，作者解决了现有TTA方法可能遇到的不稳定问题，为在实际应用中部署TTA提供了更为可靠的方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05137", "html_url": "https://arxiv.org/abs/2509.05137", "title": "具有适应性对手的学习分布类的可学习性", "title_en": "On the Learnability of Distribution Classes with Adaptive Adversaries", "authors": "Tosca Lechner,Alex Bie,Gautam Kamath", "background": "该研究考虑在适应性对手存在的情况下分布类的可学习性问题。适应性对手能够拦截学习者请求的数据样本，并在其完全了解样本的情况下应用干预措施。这与盲目的对手不同，盲目的对手只能修改样本来源的基础分布，但不能改变它们的独立同分布（i.i.d.）性质。", "innovation": "研究提出了一个适应性对手情境下的普遍可学习性概念，并考虑了对手的预算。研究成果表明，对于给定样本的适应性干预，可学习性要求比对给定分布的盲目修改更强。", "conclusion": "研究结论指出，适应性干预下的可学习性是一个比盲目干预下的可学习性更强的条件。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05130", "html_url": "https://arxiv.org/abs/2509.05130", "title": "是否应该始终在细粒度类别上训练模型？", "title_en": "Should We Always Train Models on Fine-Grained Classes?", "authors": "Davide Pirovano,Federico Milanesio,Michele Caselle,Piero Fariselli,Matteo Osella", "background": "在分类问题中，模型需要根据输入数据特征预测一个类别标签。然而，在许多数据集中，类别标签是层次化的。尽管分类任务经常在这一层次结构中的特定级别上被定义，但在训练中可以使用更细粒度的标签进行训练。实验证据表明，这种细粒度的训练可以改善性能。这篇论文研究了这一观察的普遍性，并通过实证和合成的数据集探索其背后的成因。研究表明，细粒度标签的训练并不总是提高分类准确性。相反，这种方法的有效性取决于数据的几何结构及其与标签层次的关系。此外，数据集大小和模型容量也显著影响细粒度标签是否提供性能优势。", "innovation": "该研究采用实证和合成数据集进行实验，探索细粒度标签训练在不同条件下的表现，并揭示了其有效性的关键因素。", "conclusion": "细粒度标签训练并不普遍提升分类准确性，有效性依赖于数据的几何结构及其层级关系。同时，数据集大小和模型容量显著影响细粒度标签是否提升性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05084", "html_url": "https://arxiv.org/abs/2509.05084", "title": "Recurrent State Encoders for Efficient Neural Combinatorial Optimization", "title_en": "Recurrent State Encoders for Efficient Neural Combinatorial Optimization", "authors": "Tim Dernedde,Daniela Thyssens,Lars Schmidt-Thieme", "background": "在神经组合优化(NCO)中，主要的范式是构造方法，通过训练神经网络以顺序方式添加一个解决方案组件直至构造出完整的解决方案。传统的做法是，在相邻步骤之间状态的变化通常很小，仅因为通常只会将节点添加到解决方案中，而将其从状态中移除。高效的模型应该能够重用先前步骤所做计算。因此，作者提出训练一个递归编码器，不仅基于当前状态，还基于前一个步骤的嵌入来计算状态嵌入。", "innovation": "作者提出了一种递归状态编码器，该编码器不仅基于当前的状态，还基于前一个步骤的嵌入来计算状态嵌入。实验结果显示，即使递归编码器的层数只有非递归编码器的三分之一，其性能也不低于非递归编码器，并显著提高了延迟效率。该模型被集成到一个大邻域搜索算法中，以展示研究发现的实际相关性，应用于旅行商问题(TSP)、有容量的车辆路线问题(CVRP)和旅游者问题(OP)。", "conclusion": "作者通过研究发现，递归状态编码器可以有效地减少层数，同时保持或提高性能，显著提高延迟效率。递归编码器在 Travelling Salesman Problem (TSP), the Capacitated Vehicle Routing Problem (CVRP), 和 Orienteering Problem (OP) 上的实验证明其有效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05190", "html_url": "https://arxiv.org/abs/2509.05190", "title": "基于准确度约束的CNN剪枝以实现高效可靠的EEG基于的癫痫检测", "title_en": "Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection", "authors": "Mounvik K,N Harshit", "background": "深学习模型，尤其是卷积神经网络（CNN），在生物医学信号如基于EEG的癫痫检测方面表现出显著的潜力。然而，这些模型在计算资源有限或需要实时检测的环境中存在尺寸大和计算需求高的挑战。", "innovation": "提出了一个具有结构化剪枝的轻量级一维CNN模型，用于提高效率和可靠性。通过基于重要性剪枝掉基线CNN的一半卷积核，并结合温和的早停策略，最终模型在准确性和宏观F1分数上分别达到92.78%和0.8686。", "conclusion": "展示了一种通过结构性剪枝去除冗余、提高泛化能力和与温和早停策略结合的癫痫检测方法，为资源有限的环境提供了一种有效的路径以提高检测效率和可靠性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04942", "html_url": "https://arxiv.org/abs/2509.04942", "title": "Ontology-Aligned Embeddings for Data-Driven Labour Market Analytics", "title_en": "Ontology-Aligned Embeddings for Data-Driven Labour Market Analytics", "authors": "Heinke Hihn,Dennis A. V. Dittrich,Carl Jeske,Cayo Costa Sobral,Helio Pais,Timm Lochmann", "background": "数据驱动的劳动力市场分析受限于从不同来源的职业数据推理能力有限，此前的研究依赖于手工构建的、可支持这种推理但计算成本高且需要人工专家维护的本体。最近，语言处理机器学习模型的兴起提供了替代方案，通过学习连接各种职业词汇的共享语义空间，而不需要大量的人工校对。", "innovation": "本文提出了一种基于嵌入的对齐过程，将任何自由形式的德国职位标题链接到两个已建立的本体——德国职业分类和国际标准教育分类。使用德国联邦就业局的公开数据，我们构建了一个数据集来微调Sentence-BERT模型，使其学习本体所施加的结构。增强后的（职位标题，嵌入）对定义了一个相似性图形结构，可以用于高效的近似最近邻搜索，从而将分类过程重新定义为语义搜索问题。", "conclusion": "我们讨论了设计决策和现有挑战，并概述了扩展图形以包含其他本体和多语言标题的持续工作。这种方法允许更大的灵活性，例如添加更多类别。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05213", "html_url": "https://arxiv.org/abs/2509.05213", "title": "一种异质数据环境下高效的子空间联邦学习算法", "title_en": "An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data", "authors": "Jiaojiao Zhang,Yuqi Xu,Kun Yuan", "background": "本文探讨了将联邦学习应用于大规模深度神经网络的关键挑战，特别是由于客户端数据异质性导致的客户端漂移问题以及高昂的通信、计算和内存成本。", "innovation": "我们提出了FedSub，一种用于异质数据的联邦学习高效子空间算法。具体来说，FedSub 利用子空间投影保证每个客户端在低维子空间内的局部更新，从而减少通信、计算和内存成本。此外，它还融入了低维对偶变量来缓解客户端漂移。我们提供了收敛性分析，揭示了步长和子空间投影矩阵等关键因素对收敛性的影响。", "conclusion": "实验结果表明了该方法的高效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05142", "html_url": "https://arxiv.org/abs/2509.05142", "title": "基础模型与联邦学习：综述、分类、挑战和实用见解", "title_en": "Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights", "authors": "Cosmin-Andrei Hatfaludi,Alex Serban", "background": "联邦学习能够通过不共享私有数据的方式实现模型协同训练，从而释放孤立数据和分布式资源的潜力。随着复杂基础模型的广泛应用，扩大训练资源和整合私人数据的需求也在增加。本文旨在探讨联邦学习与基础模型的交叉领域，识别、分类和描述能够将两种范式结合的技术方法。目前缺乏统一的文献综述，本文提供了一篇结构化的文献综述，该综述围绕一个新颖的分类体系展开，涵盖了联邦学习发展的生命周期阶段，同时提供了可用方法的技术对比。此外，还提供了实施和演进这些方法的实际启示和指南，以医疗保健领域为例，探讨联邦学习和基础模型的潜在影响。", "innovation": "本文提出了一篇关于联邦学习与基础模型交叉领域的结构化文献综述，该综述采用了一种新颖的分类法，按照联邦学习的发展生命周期阶段进行分类，并对现有方法进行了技术比较。此外，还提供了在医疗保健领域的实际应用和技术开发指导。", "conclusion": "本文综合多方面，覆盖了联邦学习、自监督学习、微调、蒸馏和迁移学习等话题。通过筛选和分析了超过4,200篇文章，并将其中超过250篇经过详细审查的文章集结在一起，共涵盖了42种独特的方法。这些方法被用来构建分类体系，并基于复杂度、效率和可扩展性对方法进行了对比。本文不仅总结了该领域的现状，还提供了关于采用、演进和整合基础模型与联邦学习的实际见解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05207", "html_url": "https://arxiv.org/abs/2509.05207", "title": "RapidGNN: 能源和通信高效的大规模图神经网络分布式训练", "title_en": "RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks", "authors": "Arefin Niam,Tevfik Kosar,M S Q Zulkar Nine", "background": "传统的图神经网络(GNNs)在大规模图数据集上进行分布式训练时，由于数据结构的高连接性，面临着显著的计算负载挑战。虽然传统的采样方法可以减轻计算负担，但通信开销仍然存在挑战。", "innovation": "RapidGNN提出了一个基于确定性采样的分布式GNN训练框架，该框架能够实现高效的缓存构建和远程特征的预取。评估显示，RapidGNN在不同规模和拓扑结构的基准图数据集上表现出了有效性，平均提高了端到端训练通量2.46至3.00倍，同时减少了远程特征获取次数9.70至15.39倍。此外，RapidGNN还展示了随着计算单元数量增加接近线性的扩展性，并且相比基线方法在CPU和GPU上分别提高了44%和32%的能源效率.", "conclusion": "RapidGNN能够有效地提高大型图神经网络的分布式训练效率，通过优化缓存构建和远程特征预取，显著降低了通信开销和提高了能源效率。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05165", "html_url": "https://arxiv.org/abs/2509.05165", "title": "KVCompose：基于复合令牌的高效结构化KV缓存压缩", "title_en": "KVCompose: Efficient Structured KV Cache Compression with Composite Tokens", "authors": "Dmitry Akulov,Mohamed Sana,Antonio De Domenico,Tareq Si Salem,Nicola Piovesan,Fadhel Ayed", "background": "大语言模型（LLMs）依赖于键-值（KV）缓存来实现高效的自回归解码；然而，缓存大小随着上下文长度和模型深度线性增长，这在长上下文推理中成为主要瓶颈。现有的KV缓存压缩方法要么强制执行刚性启发式，要么破坏张量布局，或者需要专门的计算内核。", "innovation": "本文提出了一种基于注意引导、分层适配的复合令牌的简单高效的KV缓存压缩框架。该方法通过聚合注意分数来估计令牌的重要性，独立选择每个注意力头的令牌，并将它们排列成尊重现有推理引擎所需均匀缓存结构的复合令牌。全局分配机制进一步在各层之间适配保留预算，给予包含更多有信息令牌的层更多资源。这种方法在显著减少内存使用的同时保持了准确性，且优于之前的结构化和半结构化方法。此外，该方法完全兼容标准推理管线，提供了一种实用且可扩展的高效长上下文LLM部署解决方案。", "conclusion": "本文提出的方法在显著减少内存使用的同时保持了准确性，优于现有的方法，且兼容标准推理管线，提供了一种实用且可扩展的高效长上下文LLM部署解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05259", "html_url": "https://arxiv.org/abs/2509.05259", "title": "Kolmogorov-Arnold网络在AGC系统中可解释的网络攻击检测", "title_en": "A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems", "authors": "Jehad Jilan,Niranjana Naveen Nambiar,Ahmad Mohammad Saber,Alok Paranjape,Amr Youssef,Deepa Kundur", "background": "自动发电控制（AGC）对于电网稳定性至关重要，但却容易遭受隐蔽的网络攻击，例如虚假数据注入攻击（FDIAs），这些攻击可以扰乱系统的稳定性，同时躲避传统的检测方法。传统方法多依赖于黑盒模型，缺乏透明度，本文提出了一种可解释的Kolmogorov-Arnold网络（KAN）方法，用于在AGC系统中检测FDIA，考虑到系统的非线性特性。\n", "innovation": "本文提出的KAN模型能够提取符号方程，提高了模型的可解释性，与大多数机器学习模型相比更具透明度。KAN模型经过离线训练，学习不同运行场景下AGC测量之间的复杂非线性关系。训练后，可以从模型中提取并利用符号公式描述其行为，极大地提高了可解释性。\n", "conclusion": "实验结果表明，提出的KAN模型在初始模型和符号公式中分别实现了高达95.97%和95.9%的FDIA检测率，且具有较低的误报率，提供了增强AGC网络安全性的可靠方法。\n"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05281", "html_url": "https://arxiv.org/abs/2509.05281", "title": "基于空域和频域的双分支卷积框架在数字图像伪造检测中的应用", "title_en": "Dual-Branch Convolutional Framework for Spatial and Frequency-Based Image Forgery Detection", "authors": "Naman Tyagi", "background": "随着深度伪造和数字图像伪造的迅速增加，确保图像的真实性变得更加困难。本报告介绍了一种结合空域和频域特征的伪造检测框架。", "innovation": "提出了一种双分支卷积神经网络，分别在空域和频域提取特征，特征融合并在Siamese网络中进行比较，得到64维嵌入用于分类。该方法在CASIA 2.0数据集上的准确率达到77.9%，优于传统的统计方法。尽管在性能上相对较弱，但该方法在计算复杂性和检测可靠性之间取得了平衡，适合实际部署。", "conclusion": "该方法为数字图像的法医审查提供了强有力的方法，整体上推动了视觉 forensic 的前沿，在媒体验证、法律执行和数字内容可靠性方面满足了迫切的需求。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05241", "html_url": "https://arxiv.org/abs/2509.05241", "title": "深度学习增强的胺排放监测及工业碳捕集装置性能分析", "title_en": "Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants", "authors": "Lokendra Poudel,David Tincher,Duy-Nhat Phan,Rahul Bhowmik", "background": "本文介绍了基于数据驱动的深度学习模型，用于预测和监控基于胺的后燃烧碳捕集系统中的胺排放及关键性能参数。研究使用了来自Technological Center Mongstad的CESAR1溶剂试验中的运行数据，开发了四种不同的深度学习架构，以捕捉时间依赖的过程行为。研究还分析了操作变量对排放和系统性能的影响，并得出了特定操作参数调整可以显著减少胺排放并提高系统性能的结论。这项研究强调了机器学习不仅作为预测工具，也是在稳定和动态条件下优化碳捕获操作的决策支持系统的重要性。开发的深度学习框架通过实时监测、情景测试和操作优化提供了一种实用的方法，以减轻环境影响。", "innovation": "本文创新之处在于使用了深度学习模型来预测和监控胺排放及关键性能参数，包括Basic Long Short-Term Memory (LSTM)，Stated LSTM，Bi-directional LSTM，以及Convolutional LSTM。通过高精度的预测和对系统性能的持续跟踪，特别是对于关键参数的监控，以及对操作变量与排放、系统性能之间因果关系的分析，说明了深度学习在理解及优化碳捕集和储存系统的决定支持系统中的应用潜力。", "conclusion": "本文展示了深度学习模型如何在碳捕集系统中作为预测工具和决策支持系统发挥作用，特别是在稳定和动态条件下优化操作。通过这种机器学习框架，不仅实现了环境影响的减轻，还提升了碳捕集和储存技术的效率、稳定性和可持续性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05018", "html_url": "https://arxiv.org/abs/2509.05018", "title": "深度感知初始化以实现稳定的高效神经网络训练", "title_en": "Depth-Aware Initialization for Stable and Efficient Neural Network Training", "authors": "Vijay Pandey", "background": "近年来，各种初始化方案被提出，包括Glorot初始化、He初始化、基于正交矩阵的初始化和随机游走法等。这些方法中有部分强调保持激活和梯度在网络层传播时的单位方差，而部分方法则忽略网络深度信息，但是部分方法已经考虑了整体网络深度以实现更好的初始化。尽管如此，对于较深的网络，网络中各层在整个网络传播时假设单位方差这一理论假设效果不理想，常常需要从网络第一层到最后一层逐层增加网络的方差。", "innovation": "本文进行了一次全面的研究，将每一层的深度信息和整体网络深度结合起来，提出了一种新的初始化方法。该方法不仅能保持每一层的方差增加，还避免了单纯增加整体网络方差的问题，更为灵活地实现了网络方差的增加，而无需对所有层进行固定变化。", "conclusion": "实验证明，本文提出的新的初始化方法在训练稳定性和效率上优于现有的初始化方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05276", "html_url": "https://arxiv.org/abs/2509.05276", "title": "SpikingBrain技术报告：仿脑大模型", "title_en": "SpikingBrain Technical Report: Spiking Brain-inspired Large Models", "authors": "Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li", "background": "主流的基于Transformer的大型语言模型面临着训练效率和推理效率的重大瓶颈：训练计算量随序列长度呈现二次增长，推理所需的内存随序列长度线性增长，限制了长上下文的处理能力。此外，使用非NVIDIA平台构建大型模型也会给稳定和高效的训练带来挑战。为解决这些问题，本文介绍了一种名为SpikingBrain的家族型受脑启发模型，旨在提高长上下文训练和推理的效率，并使其能够在非NVIDIA平台上稳定高效地构建大型语言模型体系结构和算法优化，并结合系统工程方法，提出了一种定制化的训练框架及操作库，以便于在MetaX硬件平台上运行。", "innovation": "SpikingBrain采用了线性和混合线性注意力架构并结合自适应尖峰神经元模型；提出了高效的基于转换的训练流水线以及专用的尖峰编码框架；通过定制的训练框架、操作库和并行策略，使模型更加适用于MetaX硬件。利用上述技术，开发了两个模型：SpikingBrain-7B（线性大型语言模型）和SpikingBrain-76B（混合线性MoE模型）。这两个模型展示了非NVIDIA平台上开发大规模语言模型的可行性，并实现了与公开基准Transformer相当的性能，同时仅使用约150B个标记进行持续预训练。", "conclusion": "通过提出尖峰方案，SpikingBrain实现了69.15%的稀疏性，有利于降低能耗，提高了大型模型设计的效率和规模。这表明仿脑机制有望驱动下一代高效且可扩展的大型语言模型的设计，展示了在非NVIDIA平台上构建大规模语言模型的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05288", "html_url": "https://arxiv.org/abs/2509.05288", "title": "使用图神经网络加速分布式ADMM", "title_en": "Learning to accelerate distributed ADMM using graph neural networks", "authors": "Henri Doerks,Paul Häusner,Daniel Hernández Escobar,Jens Sjölund", "background": "分布式优化在大规模机器学习和控制应用中是基础。分布式ADMM由于其收敛保证强和去中心化的计算特性而受到青睐，但它的收敛速度通常较慢，且对超参数选择敏感。本文通过将分布式ADMM迭代自然地表示在图神经网络(GNN)的消息传递框架中提出了一种创新的方法，利用GNN学习自适应步长和通信权重，同时保持算法的收敛特性。", "innovation": "通过将分布式ADMM迭代自然地映射到图神经网络的消息传递框架内，提出了一种利用图神经网络学习自适应步长和通信权重的方法，该方法能够保留ADMM算法的收敛性质，同时通过端到端训练优化网络参数，以最小化最终迭代结果的误差，从而加速算法的收敛速度和提高解的质量。", "conclusion": "实验结果表明，与标准ADMM相比，所提出的学习变体可一致地提高收敛速度和解的质量。相关代码可在特定链接处访问。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05292", "html_url": "https://arxiv.org/abs/2509.05292", "title": "在Pinterest广告推荐系统中的Deep Reinforcement Learning用于排名效用调整", "title_en": "Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest", "authors": "Xiao Yang,Mehdi Ben Ayed,Longyu Zhao,Fan Zhou,Yuchen Shen,Abe Engle,Jinfeng Zhuang,Ling Leng,Jiajing Xu,Charles Rosenberg,Prathibha Deshikachar", "background": "在广告推荐系统中，排名效用函数通过线性组合各种商业目标的预测来起重要作用，旨在平衡平台、广告商和用户的价值。传统的人工调参虽然简单可解释，但由于缺乏原则性的调参目标、大量的参数组合、缺乏个性化及对季节性变化的适应性，导致结果通常不尽如人意。", "innovation": "提出了一种通用的深度强化学习框架——个性化效用调参（DRL-PUT），针对广告推荐系统中的多目标优化挑战。通过将问题表述为强化学习任务，根据广告请求状态预测最优超参数来最大化预定义的奖励。直接使用在线服务日志学习最优策略模型，避免估计价值函数的困难。", "conclusion": "在Pinterest广告推荐系统中通过在线A/B实验评估了DRL-PUT，与基准的手动效用调参方法相比，DRL-PUT将点击率提高了9.7%，长点击率提高了7.7%，并且进行了详细的影响不同奖励定义的消融研究，分析了学习到的策略模型的个性化方面。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05117", "html_url": "https://arxiv.org/abs/2509.05117", "title": "HyPINO: 多物理神经运算符通过超PINN和制造解法", "title_en": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions", "authors": "Rafael Bischof,Michal Piovarči,Michael A. Kraus,Siddhartha Mishra,Bernd Bickel", "background": "本文提出了HyPINO，这是一种多物理神经运算符，设计用于在广泛的参数PDE类中实现零样本泛化，而无需特定任务的微调。该方法结合了基于Swin Transformer的超网络和混合监督：（i）使用制造解法（MMS）生成的解析解的标记数据，和（ii）使用物理信息目标优化的未标记样本。模型将PDE参数映射到目标物理启发式神经网络（PINN），并能够处理二维中具有不同源项、几何形状和混合Dirichlet/Neumann边条件（包括内部边条件）的线性椭圆、双曲和抛物方程。HyPINO在七个基准问题上的零样本准确性强大，超过U-Nets、Poseidon和物理信息神经运算符（PINO），并且引入了一种迭代细化流程，通过比较生成的PINN的物理特性与请求的PDE的物理特性来生成“delta”PINN，并将其贡献合并形成一个渐进减少误差的集成系统。此外，HyPINO初始化的PINNs的微调行为也进行了评估，表明它们在五个基准问题上收敛速度更快，最终误差更低，而在其他两个基准问题上表现与随机初始化和Reptile元学习的PINNs相当。", "innovation": "HyPINO的主要创新在于整合了基于Swin Transformer的超网络和混合监督方式，无需任务特定的微调即可实现多个物理参数的PDE的零样本泛化。同时引入了一种通过比较生成的PINN的物理特性与请求的PDE的物理特性来生成“delta”PINN的迭代优化方法，形成渐进减少误差的集成系统，显著提高了平均$L_2$损失。此外，HyPINO初始化的PINNs在基准问题上的微调行为优于随机初始化和Reptile元学习的PINNs，收敛速度更快，最终误差更低。", "conclusion": "本文展示了这种可扩展方法作为将神经运算符扩展到解决复杂、非线性和高维PDE问题的基础的潜力，显著提高了准确性并降低了计算成本。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04966", "html_url": "https://arxiv.org/abs/2509.04966", "title": "因果物理感知网络的神经频谱架构", "title_en": "Neuro-Spectral Architectures for Causal Physics-Informed Networks", "authors": "Arthur Bizzi,Leonardo M. Moreira,Márcio Marques,Leonardo Mendonça,Christian Júnior de Oliveira,Vitor Balestro,Lucas dos Santos Fernandez,Daniel Yukimura,Pavel Petrov,João M. Pereira,Tiago Novello,Lucas Nissenbaum", "background": "物理信息神经网络（PINNs）作为解决偏微分方程（PDEs）的强大神经网络框架已经崭露头角。然而，基于标准多层感知机（MLP）的PINNs在处理复杂的初始值问题时经常难以收敛，导致解违反因果关系并倾向于低频分量。针对这些问题，提出了一种新型的PINNs类——NeuSA（神经频谱架构），该架构借鉴了经典的频谱方法，旨在解决具有变系数的线性和非线性PDEs。NeuSA通过将潜在PDE投影到频谱基础上，实现了动态的有限维表示，然后将其与适应的神经动态方程（NODE）结合进行集成。这种方法允许通过利用频谱表示所提供的高频分量克服谱偏，通过继承NODE的因果结构来实现因果性，通过基于经典方法的初始化方案从目标解附近开始训练，从而克服了以上提到的问题。", "innovation": "NeuSA 是一种新颖的 PINNs 类，灵感来自经典频谱方法，旨在解决带变系数的线性和非线性 PDEs。NeuSA 通过将潜在PDE 投影到频谱基础上，实现动态的有限维表示，然后与适应的 Neural ODE (NODE) 结合，形成了高频率分量利用、因果结构继承和初始训练方案的特点，有效解决了标准 MLP 基础的 PINNs 在复杂问题中难以收敛的问题，同时提高了性能，实现了更快的收敛速度、更好的时间一致性和更优越的预测准确性。", "conclusion": "通过在经典波方程基准测试中验证 NeuSA，展示了在与其它架构相比，NeuSA 在性能上展现出的强大能力，包括更快的收敛速度、更好的时间一致性和更高的预测准确性，并且代码和预训练模型也将对外发布。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02718", "html_url": "https://arxiv.org/abs/2509.02718", "title": "高效无训练在线路由算法用于高流量多大规模语言模型服务", "title_en": "Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving", "authors": "Fangzhou Wu,Sandeep Silwal", "background": "大规模语言模型（LLMs）服务的需求增加给提供者带来了部署和计算成本上的显著压力。通过将查询导向最佳的LLM来降低这些成本的一种解决方案是LLM路由。现有的工作主要集中在离线场景，并且在处理高查询量和受限token预算的在线场景时显得力不从心。该论文背景主要是讨论现有的LLM路由算法在面对高查询量和在线实时性要求时所面临的挑战和局限性。", "innovation": "论文介绍了一种用于在线场景的无需训练算法，该算法利用近似最近邻搜索来高效估计查询特征，并在初始查询上的单一优化过程中学习路由策略，从而指导未来的路由。这种算法为高流量多LLM的服务提供了一种更为有效的路由解决方案，它在理论和实验上都展示了相较于现有方法的显著优势，包括更高的整体性能、成本效率和吞吐量。", "conclusion": "论文证明了所提出算法在自然假设下的竞争比为$1 - o(1)$，并且在三个基准数据集和八个基线的情况下，显示了平均整体性能提升了3.55倍，成本效率提升了1.85倍，吞吐量提升了4.25倍。这表明，论文提出的方法能够有效提高高流量多LLM服务的效率和效果。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04463", "html_url": "https://arxiv.org/abs/2509.04463", "title": "多尺度图神经网络在复杂形状针鳍周围湍流热流预测中的应用", "title_en": "Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin", "authors": "Riddhiman Raut,Evan M. Mihalko,Amrita Basak", "background": "本文研究了一种针对特定领域且具有边缘感知能力的多尺度图神经网络的开发，旨在预测包含任意复杂形状针鳍几何结构的二维通道中的平流、湍流流动和热行为。为了构建训练数据集，采用了ANSYS Fluent集成的自动化框架，该框架涵盖了几何生成、网格划分和流场求解。针鳍几何结构通过分段三次样条进行参数化，通过拉丁超立方抽样生成了1000种不同的配置。", "innovation": "该研究创新点在于开发了一种多尺度图神经网络，能够针对复杂针鳍几何结构预测二维通道内的稳流和湍流流动及热行为。相较于传统方法，该网络能够快速准确地预测温度、速度和压力场，并且能够捕获边界层、回流区域以及针鳍上游的停滞区，同时计算时间减少了2-3个数量级。", "conclusion": "新型图神经网络为复杂流场配置的模拟提供了一种快速且可靠的代理模型。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04069", "html_url": "https://arxiv.org/abs/2509.04069", "title": "通过高效深度强化学习利用先验演示解决机器人任务", "title_en": "Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning", "authors": "Chengyandan Shen,Christoffer Sloth", "background": "该论文针对机器人任务学习提出了一个称为DRLR的框架，旨在提高深度强化学习的探索效率，并结合了演示数据。方法的基础是一种称为IBRL的算法，通过修改动作选择模块来改进IBRL，使其能够提供校准过的Q值，从而缓解由于存在估算错误导致的探索效率低下问题。另外，通过使用SAC替代TD3作为强化学习策略，确保在任务学习过程中不会收敛到次优策略。该框架通过两个机器人任务（桶装载和打开抽屉）的学习过程进行了验证，这些任务需要与环境进行大量的交互。", "innovation": "提出了一个称为DRLR的探索效率高的深度强化学习框架，并结合了演示数据。该框架基于IBRL算法，通过对动作选择模块的修改来提供校准过的Q值，从而缓解了由于存在估算错误导致的探索效率低下问题。同时，该框架使用SAC替代传统的TD3作为强化学习策略，以避免策略在学习过程中收敛到次优状态。此外，该方法在两个包含不同环境交互量和不同演示质量的机器人任务上得到了实验验证，并在真实工业机器人任务中进行了成功部署。", "conclusion": "通过DRLR，该研究成功提高了基于先验演示的机器人任务学习中深度强化学习的探索效率，并展示了该方法在各种复杂应用场景中的有效性。此外，DRLR框架还在具备多维度状态和动作的实时机器人任务中展示了其鲁棒性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05193", "html_url": "https://arxiv.org/abs/2509.05193", "title": "在学习之前进行位移：启用强化学习中的低秩表示", "title_en": "Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning", "authors": "Bastien Dubail,Stefan Stojanovic,Alexandre Proutière", "background": "现代强化学习（RL）算法中存在一种常见的隐性假设，即低秩结构。例如，许多无奖励和目标导向的RL方法都假设后续措施（successor measure）具有低秩表示。本文通过指出后续措施本身并非低秩结构来挑战这一假设，而是证明在绕过了几个初始过渡后的位移后续措施中自然地浮现了低秩结构，并提供了从采样项中估计位移后续措施低秩近似值的有限样本性能保证。我们的分析揭示了约化和估计误差主要受对应矩阵的谱可恢复性参数的支配。为了限制这一参数，我们推导出一类被称为Type II Poincaré不等式的马尔可夫链函数不等式，并从这些不等式中可以量化位移的有效性所需的量。这表明所需的位移通常在实践中较小。此外，我们还建立了必要的位移与动态系统的局部混合性质之间的联系，从而提供了一种自然的选择位移的方式。最后，实验验证了理论发现，表明位移后续措施确实能提高目标导向的RL性能。", "innovation": "提出了一个新的低秩结构观点，即位移后的后续措施能自然地浮现低秩结构；建立了新的Type II Poincaré不等式来衡量位移大小；通过谱可恢复性参数来量化低秩近似的准确性；指出位移的大小依赖于位移后的后续措施的高阶奇异值的衰减速度；建立了位移与系统局部混合性质的关联，为位移选择提供了自然的方式。", "conclusion": "位移后续措施能带来更好的低秩表示，从而提高目标导向的强化学习性能。位移后的后续措施具备低秩结构，可通过新的Type II Poincaré不等式来量化位移的需要量。这种结构依赖于高阶奇异值的衰减率，通常在实践中位移量较小。实验验证了理论发现。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04459", "html_url": "https://arxiv.org/abs/2509.04459", "title": "基于大型和小型模型的不确定性感知多模态情感分析协作系统", "title_en": "Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis", "authors": "Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai", "background": "多模态大型语言模型（MLLMs）的兴起极大地推动了多模态机器学习的进展，然而这些模型的大量计算需求构成了实际部署中的重大障碍。相反，较小的专门模型虽然高效，但在性能方面往往有所牺牲。", "innovation": "我们提出了一个新颖的不确定性感知协作系统（U-ACS），它能够协同大型多模态语言模型（如HumanOmni）和一个轻量级的基础模型进行多模态情感分析。系统的核心是一个不确定性驱动的级联机制，高效的轻量级模型首先作为快速过滤器处理所有输入样本。只有预测不确定性高的样本，才会被选中并提交给大型模型进行更复杂的分析。此外，该系统引入了处理模糊或冲突预测的高级策略，包括权重平均法处理相似极性的预测和基于提示的交叉验证来解决高不确定情况下模型之间的冲突预测。这种样本难度感知的方法能够动态分配计算资源，大幅度降低推理成本同时保持大的模型的高准确性。", "conclusion": "在基准数据集上的广泛实验表明，我们提出的方法不仅能够达到最先进的性能，而且所需的计算资源仅为单独使用大型模型的一小部分。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04477", "html_url": "https://arxiv.org/abs/2509.04477", "title": "通用表示广义凸函数及其梯度", "title_en": "Universal Representation of Generalized Convex Functions and their Gradients", "authors": "Moeen Nehzati", "background": "优化问题的解通常可以用广义凸函数（GCFs）来表示，这类问题覆盖从最优运输理论到数学经济学等广泛领域。现有方法能够将嵌套的双层优化问题转换为单层问题，但这一特性没有在数值优化中得到充分的应用。已有的研究通过参数化特定类别对象并优化该参数化来利用已知解的类别信息。具有良好参数化的标识是泛逼近性质（UAP），即该参数化可以近似类别中的任何对象。已有工作如神经网络满足在连续函数类别的UAP。本文在已有关于凸函数参数化的研究基础上，将这些思想扩展到GCFs。", "innovation": "本文提出了一种关于GCFs及其梯度的凸参数化方法，该参数化满足UAP。这种参数化方法还被与浅层神经网络进行比较，突显了它们在某些方面的共同特征。这些方法已经实现为Python包gconvex并在网上提供，通过这种方法解决了找到多物品收入最大化拍卖的问题，展示了这种参数化可以有效解决此类问题的能力。", "conclusion": "本文在GCFs及其梯度上实现了UAP参数化，为数值优化提供了一种新工具。通过gconvex包，可利用这种参数化解决实际优化问题，如多物品收入最大化拍卖。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04524", "html_url": "https://arxiv.org/abs/2509.04524", "title": "可验证的数据驱动二次规划投影方法", "title_en": "Provably data-driven projection method for quadratic programming", "authors": "Anh Tuan Nguyen,Viet Anh Nguyen", "background": "投影方法旨在通过降低优化实例的维度来改善高维问题的可扩展性。Sakaue和Oki提出了基于数据的线性规划（LP）方法，其中投影矩阵是从特定应用问题实例的分布中学习到的。本文旨在分析在此基础上，对于凸二次规划（QP），数据驱动的投影矩阵学习的泛化保证。", "innovation": "本文的创新之处在于提出了使用Caratheodory定理来定位凸QP问题解的特定可行区域，并在此基础上提出了一种卷积活动集方法，将最优值的计算模型为Goldberg-Jerrum算法，以此建立学习保证。此外，本文还进一步将分析扩展到了学习匹配最优解和其他输入感知的设置。", "conclusion": "通过这些研究，本文在确保解的可靠性的基础上，为进一步改进数据驱动的QP方法提供了理论支持，并展示了如何通过学习映射从QP问题实例到投影矩阵来进一步优化方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04480", "html_url": "https://arxiv.org/abs/2509.04480", "title": "通过递归利用黑盒多模态大语言模型进行离散提示调谐以实现个性化的视觉情绪识别", "title_en": "Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition", "authors": "Ryo Takahashi,Naoki Saito,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama", "background": "视觉情绪识别（VER）是一个重要的研究领域，因其广泛的应用场景，如意见挖掘和广告设计。这种能力扩展到个体级别进一步拓宽了其潜在应用。近年来，多模态大语言模型（MLLMs）引起了越来越多的关注，并展示了与传统VER方法相当的性能。然而，这些模型在训练中使用了包含普遍观点和熟悉模式的大而多样的数据集，这导致它们倾向于采用主流的观点。这限制了它们在个性化VER中的表现，而在实际和现实应用中，这种情况至关重要。表明需要改进的关键领域是此限制方面。", "innovation": "本文提出了一种通过离散提示调谐方法来适应每个个体的VER任务。该方法基于人类提示工程过程，选择生成提示中的最佳自然语言表示，并用于更新提示以实现准确的个性化VER。这种方法利用了多模态大语言模型的黑盒特性并进行了递归使用，从而提高了个性化情感识别的精度，克服了传统方法中存在的问题。", "conclusion": "通过离散提示调谐和人类提示工程的启发，本文提出的个性化VER方法能够更准确地识别个体的情绪，特别是当面对少数派观点和不常见模式时。这种方法展示了在个性化VER应用中的潜在优势，并指出了一种有效改进现有Ver技术的新途径。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04501", "html_url": "https://arxiv.org/abs/2509.04501", "title": "理解模型训练的强化学习及其未来方向GRAPE", "title_en": "Understanding Reinforcement Learning for Model Training, and future directions with GRAPE", "authors": "Rohit Patel", "background": "本文旨在为指令调优模型的关键算法提供一个自包含、从零开始的阐述，包括SFT、拒绝采样、REINFORCE、区间策略优化（TRPO）、近端策略优化（PPO）、群体相对策略优化（GRPO）和直接偏好优化（DPO）。这些算法在解释时经常假设读者已有先验知识，缺乏关键细节，或者过于简化和复杂化。本文通过逐步简化和明确的符号解释这些方法，重点放在大规模语言模型（LLMs）上，旨在消除歧义，为概念提供清晰和直观的理解。通过避免简化人为转向更广泛的强化学习文献，并将概念与LLMs联系起来，本文减少了不必要的抽象和认知负担。", "innovation": "本文提供了对关键算法的逐步简化解释，重点放在LLMs上，减少了认知负担，使读者能够获得清晰和直观的理解。此外，文章还引入了GRAPE（广义相对优势策略进化）这一新的研究思路和探索方向，这是对先前方法的新颖补充。", "conclusion": "本文不仅系统地解释了指令调优模型的关键算法，还通过逐步简化的方法降低了认知负担，使这些概念更易于理解。同时，为了未来的研究方向，本文提出了GRAPE，并回顾了新的技术和方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04633", "html_url": "https://arxiv.org/abs/2509.04633", "title": "利用大型语言模型自动设计和基于可塑性评估的类器官智能环境扩展", "title_en": "Scaling Environments for Organoid Intelligence with LLM-Automated Design and Plasticity-Based Evaluation", "authors": "Brennen Hill", "background": "随着人工代理复杂性的增加，设计能够有效塑造其行为和能力的环境已成为关键的研究前沿。本文将这一原理扩展到新的代理类别：生物神经网络，即神经类器官。", "innovation": "本文提出了一项创新，即为神经类器官设计了三个可扩展的闭环虚拟环境，用以训练生物代理并探索学习机制，如长时 potentiation (LTP) 和长时压抑 (LTD)。此外，提出了一个利用大型语言模型（LLM）自动化实验协议生成和优化的设计方法，以及一种多模态的评估学习的方法，通过电生理、细胞和分子层面测量突触可塑性。", "conclusion": "本文构建了一个计算神经科学与基于代理的人工智能之间的桥梁，提供了一个对生物体的封装性、学习和智能进行研究的独特平台。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04603", "html_url": "https://arxiv.org/abs/2509.04603", "title": "用于分析高维聚类的交互式工具", "title_en": "An Interactive Tool for Analyzing High-Dimensional Clusterings", "authors": "Justin Lin,Julia Fukuyama", "background": "技术的进步引发了数据复杂性和维度的增加。如今，包含数千个特征的数据集已变得非常普遍。为了处理并分析这种高维数据，已经开发和发展了降维技术，随着计算能力的增加，这些技术不断发展。降维方法中最常用的是非线性方法，因为它们能够构造出可视化可解释的嵌入。与线性方法不同，它们不均匀地拉伸和缩小空间，以创造高维数据的视觉印象。由于将高维结构用大幅的空间扭曲还原成低维度，这使得非线性降维方法在噪声环境中经常会生成错误的结构。为了应对这一现象，我们开发了一种交互工具，使分析师能够更好地理解并诊断他们的降维结果。该工具通过使用各种分析图表，从多角度提供结果的视角，以确定其合法性。", "innovation": "我们开发了一种交互式工具，使分析师能够更好地理解并诊断他们的降维结果。该工具利用多种分析图，提供一个多层次的结果视角，以确定其合法性。", "conclusion": "该交互工具通过R包DRtool提供，使得分析师能够更高效准确地分析高维度数据。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04615", "html_url": "https://arxiv.org/abs/2509.04615", "title": "构建以拆解为基础的安全模型：面向LLM的基于提示的攻击威胁模型", "title_en": "Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs", "authors": "Brennen Hill,Surendra Parla,Venkata Abhijeeth Balabhadruni,Atharv Prajod Padmalayam,Sujay Chandra Shekara Sharma", "background": "大型语言模型（LLMs）的普及引入了关键的安全挑战，敌对行为者可以通过操纵输入提示来造成重大危害并规避安全性对齐。这些基于提示的攻击利用了模型设计、训练和上下文理解中的漏洞，导致知识产权盗窃、误导性信息生成和用户信任的侵蚀。深入了解这些攻击途径是制定强健防护措施的基础步骤。本文进行了一项全面的文献综述，对基于提示的攻击方法进行了分类，以提供清晰的威胁模型。通过详细说明这些漏洞的机制及其影响，本文旨在为研究社区提供信息，帮助构建下一代内在抗未经授权提取、微调和编辑的LLM.", "innovation": "本文进行了全面的文献综述，对基于提示的攻击方法进行了分类，以提供清晰的威胁模型。通过详细说明这些漏洞的机制及其影响，本文为研究社区提供信息，旨在帮助构建下一代内在抗未经授权提取、微调和编辑的LLM.", "conclusion": "本文为研究社区提供了一种基于文献综述的方法，以了解基于提示的攻击途径并帮助构建更安全的LLM。这种方法提供了系统的理解和对抗措施的建议，以确保未来LLM的安全性和用户信任。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05273", "html_url": "https://arxiv.org/abs/2509.05273", "title": "更绿色的深度强化学习：基于Atari基准的能源和碳效率分析", "title_en": "Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks", "authors": "Jason Gardner,Ayan Dutta,Swapnoneel Roy,O. Patrick Kreidl,Ladislau Boloni", "background": "深度强化学习（DRL）对计算能力的需求增加引起了关于其训练大型模型对环境和经济成本的关注。尽管在学习性能方面已有大量研究关注算法效率，但DRL算法的能源需求、温室气体排放和财务成本仍然是研究的空白领域。这项研究表明，不同算法在能源效率和训练成本方面的差异显著，某些算法在保持性能相当的情况下，能比其他算法消耗更少的能源、产生更少的二氧化碳排放，并且减少更多的财务成本。这种差异使得选择更高效的算法能够在不牺牲学习性能的情况下减轻环境和经济影响。", "innovation": "该研究通过系统性地研究7种先进的DRL算法（DQN, TRPO, A2C, ARS, PPO, RecurrentPPO, QR-DQN）在Atari 2600游戏上的能源消耗，首次量化了这些算法在能源效率和成本方面的差异。研究采用实时测量系统训练时间和能源消耗，以估算总能源使用量、二氧化碳当量排放量和电力成本，基于美国全国平均水平。这项工作展示了在不牺牲学习表现的情况下，不同算法对能源使用和财务成本的影响，为企业和研究者提供了更加绿色和经济效益更高的DRL实践指导。", "conclusion": "研究结果揭示了不同DRL算法在能源效率和培训成本方面的巨大差异，提供了一系列高效的算法选择，这些选择能够在不影响学习性能的前提下减少环境和经济影响。这项研究为开发环境意识和成本效益更高的DRL实践提供了实际的见解，并为将可持续性考虑纳入未来的算法设计和评估奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04535", "html_url": "https://arxiv.org/abs/2509.04535", "title": "通过跨域技能扩散实现上下文内策略适应", "title_en": "In-Context Policy Adaptation via Cross-Domain Skill Diffusion", "authors": "Minjong Yoo,Woo Kyung Kim,Honguk Woo", "background": "本文介绍了一个名为ICPAD的框架，用于长时多任务环境中的策略适应，特别是在没有模型更新和仅有限目标域数据的情况下快速适应技能基础的增强学习策略。该框架采用了一个跨域技能扩散方案，其中通过一种跨域一致性扩散过程，联合学习通用的原型技能和依据具体领域的技能适配器，以开放的技能作为不同领域中的通用行为表示，连接各不相同的领域。为了提高上下文适应性能，开发了一种动态领域提示方案，引导技能适配器更好地适应目标领域。该研究在Metaworld的机器人操作和CARLA的自动驾驶实验中验证了其有效性，特别是在各种跨域配置中（如环境动力学差异、代理体模型和任务时长）的适应性表现优异，实现了在有限目标域数据条件下的卓越策略适应性能。", "innovation": "本文提出了一种新颖的ICPAD框架，该框架利用跨域技能扩散技术，通过学习通用原型技能和特定领域技能适配器，实现不同领域间策略的快速适应。特别地，框架采用了一种联合学习的方法，能有效从离线数据集中学习共同的行为表示。此外，通过动态领域提示方案，实现了技能适配器与目标域更好的对齐，提高了策略适应的性能。", "conclusion": "实验结果表明，在不同的跨域配置中，采用ICPAD框架在机器人操作和自动驾驶任务中能够有效地适应，并且在有限的目标域数据条件下表现出色，验证了该框架的有效性和优越性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04512", "html_url": "https://arxiv.org/abs/2509.04512", "title": "不同规模和任务条件下大型语言模型在情感安全性分类中的扩展行为", "title_en": "Scaling behavior of large language models in emotional safety classification across sizes and tasks", "authors": "Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro", "background": "了解大型语言模型（LLMs）如何处理情感敏感内容至关重要，尤其是在心理健康领域。研究了LLMs在情感安全性分类（安全、不安全、边缘）的三分类和六类安全风险分类的多标签分类任务上的扩展行为。通过将多个手工制作的心理健康数据集合并，并利用ChatGPT生成的情绪重新解释提示来增强，构建了一个新型数据集。评估了LLaMA模型（1B、3B、8B、70B）在零样本、少量样本和微调设置下的表现。结果显示，较大的LLMs在分类任务特别是多标签分类以及零样本设置中表现更好，而轻量级微调允许1B型号在高数据类别中达到与更大模型和BERT相似的性能，且推理时需要<2GB显存。这些发现表明，较小的设备模型可以作为情感敏感应用的可行且具有隐私保护的替代方案，它们能够解释情感背景并维持安全对话边界。这项研究强调了治疗性LLM应用的关键影响和安全关键系统的可扩展对齐的重要性。", "innovation": "提出了一个融合多个手工制作的心理健康数据集并利用ChatGPT生成的情感重新解释提示来增强的新数据集；评估了不同规模的LLaMA模型在情感安全性分类任务中的表现；揭示了较小模型在特定条件下的强健性能，展示了其潜在的隐私保护应用价值。", "conclusion": "较大的LLMs在情感安全性分类任务中表现较强，特别是在零样本设置和多标签分类中；然而，轻量级的微调可以使得小型模型达到类似性能，降低硬件需求；较小的、本地化的模型可以作为情感敏感应用的隐私保护替代方案；这项研究对治疗性LLM应用和安全关键系统的可扩展对齐具有重要影响。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04657", "html_url": "https://arxiv.org/abs/2509.04657", "title": "通过SQL2NL评估NL2SQL", "title_en": "Evaluating NL2SQL via SQL2NL", "authors": "Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth", "background": "现有的自然语言到SQL（NL2SQL）模型基准测试很少系统或控制地解决语言变异这一因素。语言变异对模型理解与数据库交互的鲁棒性提出了挑战，尤其是在处理表达方式多样化的查询时。现有的基准测试未能全面地评估模型在这种变异情况下的性能。", "innovation": "本文提出了一种新的基于模式对齐的重述框架，利用SQL到自然语言的转换（SQL2NL），自动生成与原始模式和意图保持一致的语义上等价但词汇上多样的查询。这种方法使得我们可以单独评估NL2SQL模型对语言变异的鲁棒性，而不是像以前的工作那样主要研究歧义或模式变异的影响。实验结果显示，当前最先进的模型在语言变异下比标准基准测试显示的更脆弱。", "conclusion": "评价模型的鲁棒性对于确保其在真实世界设置中的可靠表现至关重要。通过分析，作者指出模型的鲁棒性会因查询复杂度、数据集和领域等因素而显著变化。这表明需要设计明确能够测量语言泛化的评估框架，以确保模型在实际应用中的可靠表现。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04677", "html_url": "https://arxiv.org/abs/2509.04677", "title": "图像的图结构推断以提升图神经网络性能", "title_en": "Inferring the Graph Structure of Images for Graph Neural Networks", "authors": "Mayur S Gowda,John Shi,Augusto Santos,José M. F. Moura", "background": "图像数据集（例如MNIST）是测试图神经网络（GNN）架构的关键基准。传统上，图像被表示为由每个节点代表像素且节点间通过垂直和水平像素连接的网格图。图信号是图像中每个像素的值（强度）。当前常用的图结构方法包括像素网格和超像素化方法，直接输入至图神经网络（如图卷积神经网络（Graph CNNs）、图注意力网络（GAT）、GatedGCN），用于图像分类。这项工作中探讨了利用替代图表示法改进下游GNN任务的准确性的方法。", "innovation": "提出了一种利用图像像素值间的相关性构建不同的行相关图、列相关图和乘积图的方法，并用于改进图像分类任务的GNN模型，从而提升了准确性。", "conclusion": "实验表明，使用这些不同的图表示法和特征作为输入，能够使下游GNN模型的准确性优于传统网格图和超像素化方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04712", "html_url": "https://arxiv.org/abs/2509.04712", "title": "使用次优策略辅助强化学习的自动驾驶", "title_en": "Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving", "authors": "Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill", "background": "自动车辆控制利用强化学习(Reinforcement Learning, RL)因其潜在的学习驾驶策略的能力吸引了大量关注。然而，RL代理在样本效率和有效探索方面经常面临训练挑战，使发现最优驾驶策略变得困难。", "innovation": "为了应对这些挑战，本文提出使用一个不需要是最优化或专家级控制的演示策略来引导RL驾驶代理。具体方法是将基于规则的变道控制器与Soft Actor Critic (SAC)算法集成，以增强探索和学习效率。这种方法显示出更优的驾驶性能，并且可以扩展到其他可以从演示引导中受益的驾驶场景中。", "conclusion": "本文的方法提高了驾驶性能，并证明了基于演示引导的强化学习在自动驾驶中的有效性和潜力，可以通过集成基于规则的控制器来克服训练中的样本效率和探索挑战。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04642", "html_url": "https://arxiv.org/abs/2509.04642", "title": "Maestro: 联合图与配置优化以实现可靠的AI代理", "title_en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "authors": "Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi", "background": "构建可靠的大语言模型（LLM）代理需要在两个层次上做出决策：图结构（哪些模块存在及其信息流动方式）和每个节点的配置（模型、提示、工具、控制柄）。现有的大多数优化器在固定图结构的前提下来调整配置，未能解决结构性失败模式。现有系统无法同时优化图结构和配置，从而难以全面提高代理的质量。", "innovation": "文章引入了一个框架无关的整体优化框架Maestro，该框架同时在图和配置上进行联合搜索，以最大化代理质量同时遵守明确的回放/标记预算。Maestro 不仅使用传统的数字指标，还利用透明的文本反馈来自跟踪的数据来优先编辑，提高样本效率，并针对性地解决特定的失败模式。Maestro 在IFBench和HotpotQA基准测试中的表现优于MIPROv2、GEPA和GEPA+Merge，即使是仅限于提示优化时的表现也优于这些方法。此外，Maestro 在两种应用（面试员和RAG代理）中的表现显著提高，表明联合图和配置搜索可以解决仅提示调整无法解决的结构性失败模式。", "conclusion": "Maestro 通过联合搜索图结构和配置，显示出比现有方法更高的性能，特别在样本效率和针对性解决特定失败模式方面表现出色。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04682", "html_url": "https://arxiv.org/abs/2509.04682", "title": "生态有效基准测试和自适应注意力：可扩展的海洋生物声学监测", "title_en": "Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring", "authors": "Nicholas R. Rasmussen,Rodrigue Rizk,Longwei Wang,KC Santosh", "background": "海底被动声学监控（UPAM）提供了长时间生态分析的丰富时空数据，但内在噪声和复杂的信号依赖性会阻碍模型的稳定性和泛化能力。虽多层窗口技术提高了目标声音定位，但环境噪声的变化、传播效应的差异以及混合的生物和人为源需求更稳健的架构和严格的评估方法。多种因素使得模型在面对环境多样性时表现出色，如何量化模型在生态上现实的变异性中保持稳定是关键挑战。", "innovation": "我们提出了GetNetUPAM，一个分层嵌套交叉验证框架，用于在生态现实变异性下量化模型稳定性。数据被分为单独的站点-年段，保持录制异质性，并确保每个验证折反映独特的环境子集，减少对局部噪音和传感器特征的过度拟合。站点-年段分块在真实环境多样性中进行评估，而标准随机子集上的交叉验证衡量UPAM全信号分布的泛化能力，这是当前基准的缺失维度。在GetNetUPAM的基础上，我们提出了Adaptive Resolution Pooling and Attention Network (ARPA-N)，一种适用于不规则频谱图维度的神经架构。自适应池化和空间注意力扩展了感受野，捕获全局上下文而不用过多参数。ARPA-N在平均精确度上比DenseNet基线提高了14.4%，并且在所有评估指标中的变异性降低了2倍对数，确保了站点-年复本间一致的目标检测并促进了可扩展准确的生物声学监控。", "conclusion": "通过GetNetUPAM量化模型在生态现实变异性中的稳健性，并提出ARPA-N，该网络架构能够解决UPAM模型的稳定性与环境多样性之间的挑战，实现了更广泛的泛化能力和更稳定的检测结果，推动了可扩展和准确的海洋生物声学监测技术的进步。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04751", "html_url": "https://arxiv.org/abs/2509.04751", "title": "短视频平台上的多模态基础模型驱动的兴趣建模与行为分析", "title_en": "Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms", "authors": "Yushang Zhao,Yike Peng,Li Zhang,Qianyi Sun,Zhihui Zhang,Yingying Zhuang", "background": "随着短视频平台用户基数的迅猛增长，个性化推荐系统在提升用户体验和优化内容分发方面的作用越来越重要。传统兴趣建模方法通常依赖单一模态的数据，如点击日志或文本标签，这限制了它们在复杂多模态内容环境中的表现。", "innovation": "本文提出了一种基于多模态基础模型的用户兴趣建模和行为分析框架。通过使用跨模态对齐策略将视频帧、文本描述和背景音乐整合进统一的语义空间，构建了粒度精细的用户兴趣向量。此外，介绍了通过观看、点赞和评论序列的动态兴趣演化特征嵌入机制，提高了推荐的时效性和准确性。", "conclusion": "实验结果显示，在行为预测准确性、冷启动用户兴趣建模和推荐点击率方面取得了显著改进。同时，引入可解释性机制，使用注意力权重和特征可视化揭示多模态输入下的模型决策基础和兴趣转移，从而提升了推荐系统的透明性和可控性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04721", "html_url": "https://arxiv.org/abs/2509.04721", "title": "TinyML模型在嵌入式系统中的实时性能基准分析（PICO：推理、CPU和操作的性能）", "title_en": "Real-Time Performance Benchmarking of TinyML Models in Embedded Systems (PICO: Performance of Inference, CPU, and Operations)", "authors": "Abhishek Dey,Saurabh Srivastava,Gaurav Singh,Robert G. Pettit", "background": "本研究提出了一个模块化且平台无关的框架PICO-TINYML-BENCHMARK，用于评估资源受限嵌入式系统上的TinyML模型的实时性能。该框架评估关键指标，如推理延迟、CPU利用率、内存效率和预测稳定性，提供了计算权衡和平台特定优化的见解。我们使用真实数据集在两个广泛采用的平台（BeagleBone AI64和Raspberry Pi 4）上对三种代表性TinyML模型进行基准测试，揭示了关键权衡：BeagleBone AI64在人工智能特定任务上表现出一致的推理延迟，而Raspberry Pi 4在资源效率和成本效益方面表现出色。", "innovation": "提出了一个模块化且平台无关的框架PICO-TINYML-BENCHMARK，用于评估TinyML模型在嵌入式系统上的实时性能。该框架可以评估多种关键性能指标，并提供了计算权衡和平台特定优化的见解，这对于优化TinyML部署具有重要意义。", "conclusion": "研究表明，BeagleBone AI64在人工智能特定任务上的推理延迟保持一致，而Raspberry Pi 4资源效率和成本效益方面表现突出。这些发现为优化TinyML部署提供了实用指导，填补了理论进步与嵌入式系统应用实践之间的差距。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04694", "html_url": "https://arxiv.org/abs/2509.04694", "title": "联合推荐系统中多意图多样性和行为不确定性的统一表示学习", "title_en": "Unified Representation Learning for Multi-Intent Diversity and Behavioral Uncertainty in Recommender Systems", "authors": "Wei Xu,Jiasen Zheng,Junjiang Lin,Mingxuan Han,Junliang Du", "background": "本文关注推荐系统中用户意图多样性和行为不确定性建模的挑战。推荐系统通常面临用户兴趣多样化和行为不确定性的问题，现有方法在处理这些问题时往往效果不佳。为了解决这一挑战，本文提出了一种统一的表示学习框架，通过结构化的用户行为序列提取多粒度的兴趣结构，并利用贝叶斯分布模型捕捉行为的模糊性和偏好波动。该框架能够在长短期用户意图和行为信号之间进行灵活融合，提高推荐准确性和鲁棒性。", "innovation": "本文提出了一种新的统一表示学习框架，引入了多意图表示模块和不确定性建模机制。多意图表示部分通过引入多个潜在意图向量，使用注意机制加权融合来生成语义丰富的长期用户偏好表示。不确定性建模部分通过高斯分布学习行为表示的均值和协方差，反映用户在不同行为上下文中的置信度。通过这种方式进行长短期意图和行为信号的可学习融合，生成最终的用户表示，从而提升推荐效果。与现有方法相比，该方法在多种标准公开数据集上的实验结果表明其具有更高的性能，特别是在冷启动和行为扰动场景中展现了更好的稳定性和适应性，解决了传统方法在处理复杂用户行为时的建模瓶颈问题", "conclusion": "实验结果显示该方法在多个度量指标上优于现有代表性模型，并在冷启动和行为干扰场景中表现更加稳定和适应性强。这些发现证明了统一建模策略在真实推荐任务中的有效性和实用性，能够有效地处理用户意图多样性和行为不确定性的挑战。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04770", "html_url": "https://arxiv.org/abs/2509.04770", "title": "基于MQUAKE框架的大规模语言模型多跳推理优化研究", "title_en": "Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework", "authors": "Zucheng Liang,Wenxin Wei,Kaijie Zhang,Hongyi Chen", "background": "大规模语言模型（LLMs）一直难以准确回答复杂问题，本研究聚焦于利用MQUAKE框架下的多跳问题分解方法（multi-hop question decomposition method）来改善LLMs对复杂问题的理解和推理能力。研究使用LLAMA3模型在知识图谱上的应用，系统性地探讨了多跳问题分解对模型理解及推理准确性的影响。", "innovation": "本研究创新性地引入了多跳问题分解方法，并将其应用于MQUAKE-T数据集的分解与转换，分别构建了单跳和多跳数据集。研究发现，在未经微调的情况下，多跳问题分解方法显著优于直接回答复杂问题的方法。即使经过LoRA方法的微调，使用多跳分解的方法仍然保持其优越性，验证了该方法在模型训练前后均有效提升LLMs回答复杂问题的能力。", "conclusion": "研究结果表明，基于多跳问题分解的方法在未经过模型微调的情况下，已经显示出优于直接回答复杂问题的方法的性能。经过LoRA微调后，两种方法都得到提升，但多跳分解的方法依旧保持了其优势，验证了该方法能够有效提升LLMs回答复杂问题的能力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04805", "html_url": "https://arxiv.org/abs/2509.04805", "title": "AI-驱动的无线通信系统前端链路压缩：综述与方法设计", "title_en": "AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design", "authors": "Keqin Zhang", "background": "现代无线系统中的前端链路必须传输高维信号，同时受到严格的带宽和低延迟限制，这使得压缩变得不可或缺。传统策略如压缩感知、标量量化和固定代码管道依赖于严格的先验知识，高压缩比下性能急剧下降，难以在不同频道和部署中进行调整。最近人工智能的发展带来了针对通道状态信息(CSI)、预编码矩阵、I/Q样本和LLR结构的端到端学习转换、矢量和分层量化以及学习熵模型，这些技术能够在高压缩比下有更好的性能表现。", "innovation": "本文首先综述了AI驱动的压缩技术，提出了两个高压缩比路径的深入分析，即CSI反馈的端到端学习和资源块(RB)级预编码优化与压缩相结合的策略。在此基础上，作者提出了一种针对无蜂窝架构的前端链路压缩策略，旨在以可控的性能损失实现高压缩比，支持资源块级别的速率自适应，并能够实现适用于下一代网络集中的协同传输的低延迟推理。", "conclusion": "该论文基于AI驱动的压缩技术，提出了针对无蜂窝架构的前沿链路压缩策略，该策略能够实现较高压缩比，并能支持RB级别的速率调整与低延迟推理，为下一代网络的集约化协同传输提供了技术支持。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04731", "html_url": "https://arxiv.org/abs/2509.04731", "title": "语言驱动的层次化任务结构作为多智能体学习中的显式世界模型", "title_en": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "authors": "Brennen Hill", "background": "近年来，语言模型和代理模型的规模不断扩大，但复杂、长时域多智能体任务中精细层次的世界模型的发展仍然是一个关键瓶颈。例如，在足球机器人领域，通过高保真但结构扁平的仿真环境进行标准强化学习训练的智能体往往因为难以探索的空间和稀疏的奖励而导致失败。", "innovation": "本文提出了一种新的方法，利用大型语言模型动态生成层次化结构，并以语言驱动的方式构建世界模型。这种方法提供了内在的学习课程，密集且有意义的学习信号，并为组合式学习建立了框架，使代理模型能更高效地获得复杂的策略性行为。", "conclusion": "通过构建具有明确、语言可配置的任务层环境，可以连接低层级的反应性行为和高层级的策略性团队玩法，为训练下一代智能代理提供强大的和可泛化的框架。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04517", "html_url": "https://arxiv.org/abs/2509.04517", "title": "对于人工报告数据的植入网片术后分析以检测公众情感并识别关注报告", "title_en": "Analysis of Voluntarily Reported Data Post Mesh Implantation for Detecting Public Emotion and Identifying Concern Reports", "authors": "Indu Bala,Lewis Mitchell,Marianne H Gillam", "background": "在疝气修复手术中广泛使用网片植入物，但术后并发症是主要关切。本文通过分析从2000年至2021年期间上报给制造商和用户设施设备体验（MAUDE）数据库的患者报告，利用自然语言处理（NLP）探索患者在使用网片植入后的感情状态。", "innovation": "本文采用NRC加拿大国家研究理事会（NRC）情感词汇和TextBlob进行情感分析，将患者叙述分类为八种情感（愤怒、恐惧、期待、信任、惊讶、悲伤、快乐、厌恶），评估情感极性，并通过时间分析来识别患者情感模式，同时定位需要紧急关注的报告，称为“关注报告”。这为医疗实践中的情感考量提供了重要依据，并表明了情感分析在提高患者护理方面的作用。", "conclusion": "本文通过情感分析和时间序列分析，提供了有关患者术后体验的有价值见解，这对于改进术前咨询、术后护理以及患者对网片植入术的准备都至关重要。研究强调了在医疗实践中考虑情感的重要性，并表明情感分析可以用于指导和改进患者护理。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04810", "html_url": "https://arxiv.org/abs/2509.04810", "title": "跨越边界进行代码审查：合成数据与真实数据在审查推荐中的评估", "title_en": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation", "authors": "Yogev Cohen,Dudi Ohayon,Romy Somkin,Yehudit Aperstein,Alexander Apartsin", "background": "在现代软件开发流程中，自动决定代码变更是否需要人工审核对于保持软件质量至关重要。然而，随着新编程语言和框架的出现，一个关键瓶颈出现了：大量的未标记代码虽然容易获得，但标注数据不足，无法用于训练监督模型进行审阅分类。这个问题使得使用标注数据训练模型的资源范围受到了限制，尤其是在需要进行代码审查的情况下。因此，迫切需要一种新的方法来解决这一问题，尤其是在数据资源有限的环境下。", "innovation": "本文提出了一种利用大语言模型（LLMs）将丰富资源语言的代码变更转换为新兴或未充分资源语言的等效变更，从而生成缺少标注例子的合成训练数据。通过这种方法生成的合成数据被用来训练监督分类器，从而评估其性能优于直接使用真实标注数据训练的分类器。该方法通过在多个GitHub仓库和语言对上的实验表明，合成数据可以有效地启动审阅推荐系统，即使在资源有限的环境中也能缩小性能差距。这种途径提供了一种可扩展的方法，即使在缺乏注释数据的情况下，也能扩展自动代码审查的范围，适应快速变化的技术栈。", "conclusion": "本研究通过使用大语言模型生成的合成数据来训练监督分类器，证明了即使在资源有限的环境中，也可以有效实现自动代码审查。该方法成功地扩展了自动代码审查的能力，适用于快速增长的技术领域，而不依赖于标注数据的存在。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04667", "html_url": "https://arxiv.org/abs/2509.04667", "title": "DarkStream: 低延迟实时语音匿名化", "title_en": "DarkStream: real-time speech anonymization with low latency", "authors": "Waris Quamer,Ricardo Gutierrez-Osuna", "background": "随着实时语音通信需求的增加，如何在严格的时间延迟限制下实现语音内容的加密和匿名化成为了一个重要问题。现有方法通常耗时较长，难以满足实时应用的需求。", "innovation": "DarkStream 是一种用于实时语音匿名化的流式语音合成模型，能够在低延迟下完成语音加密。该模型结合了因果波形编码器、短时间前瞻性缓冲和基于变压器的语境层，提高了内容编码效率。此外，DarkStream 直接通过神经语音合成功能生成语音波形，减少了中间步骤，进一步降低了推理时间。最后，通过在语音内容编码的语言特征中注入生成对抗网络生成的伪说话人嵌入，实现了匿名化。", "conclusion": "实验结果表明，DarkStream 帮助实现了强匿名化效果，在“懒知情”攻击场景下的说话人验证错误率接近 50%（接近随机猜测性能），同时保持了良好的语言可理解性（词错误率在 9% 左右）。通过平衡低延迟、鲁棒隐私和最小语言可理解性降级，DarkStream 提供了一种实用的实时语音通信隐私保护解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04669", "html_url": "https://arxiv.org/abs/2509.04669", "title": "VCMamba: 将卷积与多方向Mamba结合以实现高效的视觉表示", "title_en": "VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation", "authors": "Mustafa Munir,Alex Zhang,Radu Marculescu", "background": "近期视觉变换器（ViTs）和状态空间模型（SSMs）如Mamba的进展挑战了卷积神经网络（CNNs）在计算机视觉中的主导地位。虽然ViTs擅长捕捉全局上下文，Mamba等SSMs能够以线性复杂度处理长序列，但它们在细粒度局部特征的捕捉上不如CNNs有效。相反，CNNs虽然具有对局部特征的强大归纳偏置，但在全局推理能力方面不如ViTs和Mamba。为了弥合这一差距，作者提出了VCMamba，这是一种新颖的视觉骨干网络，集成了CNNs和多方向Mamba SSMs的优点。VCMamba使用卷积前端和具有卷积块的分层结构，以提取丰富的局部特征，并通过包括多方向Mamba块的更晚期阶段处理这些卷积块，以高效建模长距离依赖性和全局上下文。这种混合设计使得VCMamba能够在保持相对于图像分辨率的线性复杂度的同时，提供更优秀的特征表示能力。", "innovation": "VCMamba是一种将卷积网络与多方向Mamba SSMs的优点结合的视觉骨干网络。它利用卷积前端和早期卷积层次结构来提取丰富的局部特征，并通过多方向Mamba模块（设计用于高效建模长距离依赖性和全局上下文的更高层次结构）来处理这些特征。这种混合设计使得VCMamba可以在保持相对图像分辨率的线性复杂度的同时，提供更优的特征表示能力。通过在ImageNet-1K分类和ADE20K语义分割任务上的广泛实验，证明了VCMamba的有效性，达到了更高的精确度，并且在参数量上优于现有的其他方法，如PlainMamba-L3和Vision GNN-B，同时在ADE20K上超过了EfficientFormer-L7。", "conclusion": "VCMamba通过结合CNNs和多方向Mamba SSMs的优点，提供了一种高效的视觉表示方法。实验结果表明，VCMamba在多个视觉任务上表现出色，具有更高的精确度和更少的参数量。VCMamba-B在ImageNet-1K上达到了82.6%的精度，在ADE20K上获得了47.1 mIoU，参数量分别比PlainMamba-L3和Vision GNN-B少了37%和64%，比EfficientFormer-L7少62%。此外，VCMamba-B在ADE20K上的性能超过了EfficientFormer-L7，显示了其在参数效率方面的优越性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04852", "html_url": "https://arxiv.org/abs/2509.04852", "title": "通过区间退火切线对齐进行任意步密度比估计", "title_en": "Any-Step Density Ratio Estimation via Interval-Annealed Secant Alignment", "authors": "Wei Chen,Shigui Li,Jiacheng Li,Jian Xu,Zhiqi Lin,Junmei Yang,Delu Zeng,John Paisley,Qibin Zhao", "background": "密度比估计在机器学习中是一个基本问题，但现有方法通常在准确性和效率之间进行取舍。ISA-DRE框架通过学习全局切线函数，实现了无需数值积分的精确任意步估计。这得益于切线对齐恒等式，一种将全局切线函数与潜在切线表示形式正式连接起来的自一致性条件。", "innovation": "ISA-DRE框架解决了密度比估计中的精度与效率问题，通过学习全局切线函数（定义为所有切线的期望值）显著降低了方差，使其更适合神经逼近。为此引入了区间退火切线对齐技术，通过自一致性条件将全局切线函数与潜在的切线表示形式连接起来。此外，还提出了区间退火收缩训练策略，逐步扩展对齐区间，提高训练的稳定性和收敛性。", "conclusion": "实验证明，ISA-DRE在与之前方法相比较少函数评价的情况下，仍能实现竞争性的准确性，这使其在推理速度和实时应用方面表现优异。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04781", "html_url": "https://arxiv.org/abs/2509.04781", "title": "大语言模型已离开聊天：大型语言模型离场偏好证据", "title_en": "The LLM Has Left The Chat: Evidence of Bail Preferences in Large Language Models", "authors": "Danielle Ensign,Henry Sleight,Kyle Fish", "background": "研究背景：这篇论文探讨了大型语言模型（LLMs）在进行对话时是否会选择退出对话（bail out）。研究者提供了三种不同的方法让模型决定是否退出对话：一种是模型可以调用的退出工具、一种是模型可以输出的退出字符串，还有一种是询问模型是否愿意退出的提示。研究在真实数据集（Wildchat和ShareGPT）的延续对话中进行了测试，发现模型在各种情况下退出对话的概率介于2.8%到32%之间。然而，研究指出，不同模型对于退出的选择可能会显著不同，这可能使得在实际应用中高估了模型的退出概率。", "innovation": "创新点：研究引入了三种不同的方法来使LLMs决定是否退出对话，并通过真实数据集（Wildchat和ShareGPT）对模型的退出行为进行研究。识别了不同退出方法和模型之间的显著差异。基于观察结果，开发了一个名为BailBench的合成数据集，用于进一步测试模型的退出行为。此外，提出了一个不完全分类框架，来更好地理解和分类模型的退出案例。", "conclusion": "研究结论：不同类型的模型在遇到不同的退出方法或提示时，退出对话的概率差异很大。关于是否拒绝某请求与是否会退出的关联研究显示，拒绝请求的出现减小了不拒绝请求即选择退出的概率，但增加了解除请求后的退出概率。关于Jailbreak（模型逃逸）和拒绝对话的影响研究发现，虽然Jailbreak降低了拒绝请求的概率，同时也增加了模型主动退出的概率。此外，通过BailBench数据集测试模型时，并非所有拒绝率高的方法都会导致协商后的更低的退出率。最终表明，模型在某些情况下可能会选择退出对话，但这一行为取决于多种因素。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04816", "html_url": "https://arxiv.org/abs/2509.04816", "title": "从专家混合模型中提取语义分割中的不确定性估计", "title_en": "Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation", "authors": "Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner", "background": "评估计算机视觉模型准确且精准的预测不确定性对于提高模型的可靠性至关重要，特别是在交通安全关键应用中如交通场景感知。虽然集成方法通常被用于通过结合多个模型来量化不确定性，专家混合模型（MoE）通过使用门控网络动态调整专家预测的权重，提供了一种有效的替代方案。基于在我们之前工作中对MoE在语义分割中的成功应用，我们展示了无需对架构进行修改即可从MoE中提取准确且精准的不确定性估计的可能性。", "innovation": "提出了三种方法从MoE中提取预测不确定性估计：预测熵、互信息和专家方差。研究发现，MoE在异常分布数据（OOD数据）中的条件正确性度量中提供的不确定性估计比集成方法更可靠。此外，通过门控熵计算路由不确定性以及使用简单的门控机制而不是复杂的类别门控机制有助于更好地校准路由不确定性估计。最后，实验表明，增加专家的数量可以进一步提高不确定性校准的效果。", "conclusion": "MoE在语义分割应用中提供了更可靠的不确定性估计，简单门控机制更适合校准路由不确定性的估计。增加了专家数量可以进一步提升不确定性校准的效果。相关代码已公开。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04894", "html_url": "https://arxiv.org/abs/2509.04894", "title": "SynGen-Vision: 用于训练工业视觉模型的合成数据生成", "title_en": "SynGen-Vision: Synthetic Data Generation for training industrial vision models", "authors": "Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj", "background": "工业磨损检测是计算机视觉（CV）中的重要问题，对于任何行业的预测性维护任务至关重要。然而，由于缺乏不同磨损状况的数据集，为训练此类模型进行数据收集既昂贵又耗时。", "innovation": "本方法利用视觉语言模型和3D模拟渲染引擎生成不同程度锈蚀条件下的合成数据，通过使用生成的数据集训练CV模型，实现在真实锈蚀工业物体图像上的应用，并且通过合成数据训练的模型在mAP50指标上取得了0.87的高分，远优于其他方法。方法具有可定制性，易于扩展到其他工业磨损检测场景。", "conclusion": "本研究表明，通过合成数据生成方法可以有效地解决工业磨损检测模型训练的数据短缺问题，促进了低成本且高效的模型开发和应用。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04867", "html_url": "https://arxiv.org/abs/2509.04867", "title": "随机观测下的滤波：相关子空间性质的序列学习及误差分析", "title_en": "Filtering with Randomised Observations: Sequential Learning of Relevant Subspace Properties and Accuracy Analysis", "authors": "Nazanin Abedini,Jana de Wiljes,Svetlana Dubinkina", "background": "态估计将观测数据与数学模型相结合，在许多应用中至关重要，并通常通过过滤方法解决，如集合卡尔曼滤波。本研究关注在固定、随机化和自适应变化的观测条件下连续集合卡尔曼滤波的信号跟踪性能。文章建立了预期信号跟踪误差与观测算子随机性之间的严格界，并探讨了通过平衡观测复杂性与估计准确性来自适应确定状态子空间维度的方法，以确保过滤误差有界。", "innovation": "本文提出了一种自适应学习方案，可以根据观测复杂性与估计准确性之间的平衡，自适应确定足够确保过滤误差有界的状态子空间维度。该方案不仅控制了误差，还提供了一种系统的方法来确定与系统动力学相关的参数的适当大小，这对于精确过滤至关重要。", "conclusion": "本研究通过自适应观测选择策略，提高了随机化观测条件下连续集合卡尔曼滤波的信号跟踪性能，并通过严格的误差分析建立了一种系统的方法来确定状态子空间的适当大小。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04752", "html_url": "https://arxiv.org/abs/2509.04752", "title": "SePA：增强搜索的预测代理用于个性化健康教练", "title_en": "SePA: A Search-enhanced Predictive Agent for Personalized Health Coaching", "authors": "Melik Ozolcer,Sang Won Bae", "background": "目前存在针对个人健康监控和指导的系统，但这些系统往往缺乏个性化数据的支持，且生成的建议在准确性和可靠性上存在局限。该研究旨在结合个人化的机器学习预测和检索增强生成技术，提供一种适应性强、基于证据的健康指导系统。研究团队利用可穿戴传感器数据建立个性化模型，预测每日的压力、疼痛和受伤风险，并通过检索模块将LLM生成的反馈与专家审核的网络内容相结合以确保上下文的相关性和可靠性。", "innovation": "该研究的创新点在于，首次将个性化机器学习模型与检索增强生成技术相结合，用于健康教练系统。个性化预测模型使用滚型原产地交叉验证和分组k折交叉验证进行评估，表明个性化模型优于通用基准。同时，检索模块保证了LLM生成反馈的准确性和可靠性，并在初步专家研究中得到了积极反馈。此外，还评估了响应质量和速度之间的延迟性能权衡，为下一代可信个人健康信息系统的构建提供了透明的蓝图。", "conclusion": "该系统（SePA）通过将个性化预测模型与检索模块结合，提供了一种适应性强、基于证据的健康指导方法，展示了比非检索基线更有意义的实际效果，并为下一代个人健康信息系统的构建提供了指南。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04871", "html_url": "https://arxiv.org/abs/2509.04871", "title": "从通话记录数据克隆对话型语音AI代理以应用于电话销售", "title_en": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "authors": "Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn", "background": "近年来语言和语音建模的最新进展使构建能够实时理解和生成人类对话的自主语音助手成为可能。这些系统正在越来越多地在客户服务和医疗保健等领域应用，通过自动化重复性任务、降低运营成本，并提供全天候的支持。", "innovation": "该论文提出了一种从通话记录库中克隆对话型语音AI代理的通用方法。尽管该案例研究使用了电话销售数据来说明该方法，但其核心过程适用于任何可用通话记录的领域。系统通过电话聆听客户，用合成语音做出反应，并遵循从顶级人代理中学到的结构化剧本，整合了自动语音识别、基于大规模语言模型的对话管理器和文本到语音合成为了一流的数据流推理流程。", "conclusion": "克隆的代理在一次包含22项标准的评估中与人类代理进行了比较，涵盖引言、产品交流、销售推动、异议处理和成交。蒙眼测试表明，AI代理在通话的常规方面接近人类表现，但在说服和异议处理方面表现欠佳。该论文分析了这些不足之处并对提示进行了改进，结论部分包含设计教训和未来研究方向，包括大规模模拟和自动评估。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04897", "html_url": "https://arxiv.org/abs/2509.04897", "title": "PLaMo 2 技术报告", "title_en": "PLaMo 2 Technical Report", "authors": "Preferred Networks:Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu", "background": "报告介绍了一种针对日语的大型语言模型系列PLaMo 2，该模型采用了一种基于Hybrid Samba的混合体系结构，并通过持续预训练过渡到全注意力机制，以支持32K标记上下文。训练过程中利用了大量合成语料库来克服数据稀缺问题，同时通过权重重用和结构化剪枝提高了计算效率。", "innovation": "PLaMo 2模型通过有效的剪枝方法生成了8亿参数的模型，其性能与之前1000亿参数的模型相当。培训后使用监督微调（SFT）和直接偏好优化（DPO）管道进行进一步优化，结合合成的日语指令数据和模型合并技术。经过优化后，这些模型使用vLLM进行推理，并通过量化来最小化精度损失，实现了在日语基准测试中的最佳结果，超过了同规模的开源模型在指令遵循、语言流畅性和日本特定知识方面的表现.", "conclusion": "PLaMo 2 模型在日语基准测试中取得了最先进的结果，超越了同样大小的开源模型在指令遵循、语言流畅性和日本特定知识方面的表现。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04889", "html_url": "https://arxiv.org/abs/2509.04889", "title": "蜘蛛网：使用视觉模型估算与蜘蛛相关的图像的恐惧评分", "title_en": "SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models", "authors": "Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak", "background": "随着计算机视觉技术的进步，其在临床应用中的新途径得到了拓展，特别是在计算机暴露疗法中，视觉刺激可以基于患者的反应动态调整。为了实现这种自适应系统，研究关注是否可以使用预训练的计算机视觉模型准确地从与蜘蛛相关的图像中预测恐惧水平。该研究使用了3种不同的模型，通过迁移学习方法预测人类对313张标准化图像的恐惧评分（范围0-100），并通过交叉验证进行评估，平均绝对误差在10.1至11.0之间。研究还发现，减少数据集大小显著损害了性能，但进一步增加数据集大小并没有带来显著的性能提升。解释性分析显示，模型预测基于与蜘蛛相关的特征，而类别错误分析进一步确定了高错误率的视觉条件，例如远景和人造／绘画的蜘蛛。", "innovation": "该研究利用预训练的计算机视觉模型来预测与蜘蛛相关的图像的恐惧评分，这是计算机暴露疗法的一个重要进展。通过比较不同模型的性能和解释性分析，研究揭示了预测风险的关键视觉特征，为开发情感感知治疗技术提供了重要的实证支持。", "conclusion": "研究结果表明了解释性计算机视觉模型在预测恐惧评分中的潜在价值，并强调了模型可解释性和大型数据集对于开发有效的、情感感知的治疗技术的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04919", "html_url": "https://arxiv.org/abs/2509.04919", "title": "在添加-移除模型和更广泛领域下的最优方差和协方差差分隐私估计", "title_en": "Optimal Variance and Covariance Estimation under Differential Privacy in the Add-Remove Model and Beyond", "authors": "Shokichi Takakura,Seng Pei Liew,Satoshi Hasegawa", "background": "此前的研究主要集中在差分隐私条件下的交换模型下的方差和协方差估计问题。然而，添加-移除模型很难研究，因为它不仅需要保护数据集的隐私，还需要保护数据集的大小。因此，该研究的背景在于填补差分隐私条件下添加-移除模型方差和协方差估计研究的空白。", "innovation": "研究者开发了基于Bézier机制的有效方差和协方差估计机制，该机制基于Bernstein基构建了一个新颖的刻度释放框架。研究证明了在高隐私率区间内，该机制在最小极大准则下是最优的，并且通过实例级别的效用分析表明Bézier机制相比其它机制具有更好的性能。", "conclusion": "研究展示了Bézier机制在方差和协方差估计之外的应用，并证明了该机制在其他统计任务中的适用性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04926", "html_url": "https://arxiv.org/abs/2509.04926", "title": "基于语义化描述的对话中定性概念", "title_en": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "authors": "Barbara Gendron(LORIA, UL),Gaël Guibon(LIPN, LORIA),Mathieu D'aquin(LORIA, UL)", "background": "大型语言模型（LLMs）作为对话代理时的可控性是关键挑战，特别是在确保具有可预测性和用户个性化响应方面。由于对话特征往往是定性的，以往的工作缺乏对这些特征的定量定义。本文旨在通过一种基于本体的方法，为定性定义的概念提供定量描述，以实现它们的一致性和推理能力。", "innovation": "文章提出了一种基于本体的方法，通过使用语义描述将定性定义的概念转化为定量描述。这种方法利用描述逻辑将这些定义形式化，并将其集成到本体中，以引导LLM生成控制的文本。本体为LLM生成可控对话提供了指导，通过微调过程实现了对话控制。", "conclusion": "实验结果表明，该方法为对话控制提供了具有可解释性的、一致的等级定义，提高了对话AI的透明度。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04899", "html_url": "https://arxiv.org/abs/2509.04899", "title": "使用受限玻尔兹曼机学习和创作古典音乐", "title_en": "Learning and composing of classical music using restricted Boltzmann machines", "authors": "Mutsumi Kobayashi,Hiroshi Watanabe", "background": "近年来，开发了使用机器学习模仿特定作曲家（例如J.S.巴赫）风格的软件。但是，由于这些软件经常采用具有复杂结构的机器学习模型，因此难以分析软件是如何理解作曲家音乐的特点的。", "innovation": "本文采用J.S.巴赫的音乐训练受限玻尔兹曼机（RBM）。由于RBM的结构简单，可以让我们在学习之后调查内部状态。研究发现，学习后的RBM能够作曲。", "conclusion": "通过使用RBM，作者能够研究机器学习模型在理解巴赫音乐特性的过程中发生了什么，并且能够生成新的音乐作品。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04895", "html_url": "https://arxiv.org/abs/2509.04895", "title": "评估自动脂滴计数的多种实例学习策略", "title_en": "Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting", "authors": "Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim", "background": "在脂细胞生物学研究中，脂滴的数量是关键的测定指标。手动计数耗时且主观性高，因此开发自动化的解决方案是必要的。脂细胞是一种分泌脂质的细胞，其分化的标志是细胞内脂滴的积累，脂滴计数的自动化对脂细胞图像的分析至关重要。现有方法如基于分层感知机的基线模型尽管表现稳定（均MAE=5.6），但新的基于注意力的多实例学习（MIL）模型尽管更不一致（均MAE=10.7），但在某些情况下表现更优。任务对齐的聚集和正则化对于MIL在脂细胞图像分析中的潜力的充分发挥至关重要。", "innovation": "该研究提出了一个基于注意力的多实例学习（MIL）框架，用于脂细胞图像分析。该框架使用扩增的染色脂细胞图像（Nile Red染色）进行标签，并使用ResNet-50特征和实例加权进行实例区分。结果显示，基于注意力的MIL模型在特定折中的表现优于基线多层感知机模型，这表明注意力机制在脂细胞图像分析中的潜力需要通过任务对齐的聚合和正则化来充分利用。", "conclusion": "基线的分层感知机为组织级别的脂滴计数提供了稳健的基础，而基于注意力的MIL需要通过任务对齐的聚合和正则化来进一步优化其在脂细胞图像分析中的表现。研究通过五折交叉验证实验，对比了两种模型的表现，认为虽然基于注意力的MIL模型在某些情况下表现更优，但其表现不如基线模型稳定。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04923", "html_url": "https://arxiv.org/abs/2509.04923", "title": "人工智能在表征和刻画量子系统中的应用", "title_en": "Artificial intelligence for representing and characterizing quantum systems", "authors": "Yuxuan Du,Yan Zhu,Yuan-Hang Zhang,Min-Hsiu Hsieh,Patrick Rebentrost,Weibo Gao,Ya-Dong Wu,Jens Eisert,Giulio Chiribella,Dacheng Tao,Barry C. Sanders", "background": "在描述大型量子系统，特别是一些由量子模拟器和巨大量子计算系统产生的系统时，由于希尔伯特空间的指数级扩展，这构成了量子科学中的关键挑战。近年来，人工智能（AI）的发展因其在高维模式识别和函数逼近方面的优势，已经成为解决这一挑战的有效工具。已有研究利用AI来表示和表征可扩展的量子系统，涵盖了从理论基础到实验实现的各个领域。根据先前知识和学习架构的集成方式，AI在量子系统表征中的集成可以分为三类协同范式：机器学习，特别是深度学习和语言模型。本文重点讨论了这些AI范式如何贡献于量子系统表征中的两个核心任务：量子性质预测和量子态的代理构建。", "innovation": "利用AI（特别是机器学习、深度学习和语言模型）来表征和刻画大型量子系统，解决了由于希尔伯特空间的指数级扩展带来的挑战。通过这种方法，研究人员能够更有效地分析和理解量子系统的性质，为量子认证、基准测试、量子算法增强以及强关联物相的理解提供了强有力的工具。", "conclusion": "尽管已经取得了一些进展，但在AI和量子科学的交叉领域仍然存在许多挑战和未解问题。未来的研究将进一步探讨这些挑战，并开辟新的应用前景，有望推动量子科学的发展。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05006", "html_url": "https://arxiv.org/abs/2509.05006", "title": "大型语言模型需要意图吗？重新审视服务助手的响应生成策略", "title_en": "Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant", "authors": "Inbal Bolshinsky,Shani Kupiec,Almog Sasson,Yehudit Aperstein,Alexander Apartsin", "background": "在对话式人工智能时代，生成准确且上下文相关的服务响应仍然是一个关键挑战。关于生成高质量服务响应是否需要明确的意图识别，目前存在争议。模型是需要经过明确意图识别的步骤，还是可以直接生成有效的回复？", "innovation": "本论文采用严格比较的方式，研究了大型语言模型在两种生成响应策略（先意图后响应生成与直接响应生成）下的表现。通过两个公开的服务交互数据集，对比了几种最新的语言模型的表现，评估指标涵盖语言质量和任务成功率，揭示了意图建模的必要性或冗余性。", "conclusion": "本研究挑战了在对话式人工智能流程中的传统假设，提供了设计更高效、更有效的响应生成系统的实用指南。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04969", "html_url": "https://arxiv.org/abs/2509.04969", "title": "使用NLP在医院急诊数据中分类与动能相关的损伤", "title_en": "Classification of kinetic-related injury in hospital triage data using NLP", "authors": "Midhun Shyam,Jim Basilakis,Kieran Luken,Steven Thomas,John Crozier,Paul M. Middleton,X. Rosalind Wang", "background": "急诊部门的初次诊疗笔记包含了众多帮助医护人员和研究者了解患者流行病学和随时间变化的疾病或伤害程度的信息。然而，利用现代自然语言处理和机器学习技术来分析这些数据存在一些挑战，包括敏感数据隐私管理、硬件资源限制和手动标注数据集需要专业输入且耗时成本高等问题。", "innovation": "本文提出了一种管道，使用预训练的大型语言模型（LLM）和有限的计算资源对急诊数据进行分类。首先，使用GPU对小型公开数据集 fine-tune 一个预训练的LLM，并结合分类器进行进一步微调；然后，在CPU上对特定医院的1000个样本数据集进行 model fine-tuning。通过精心策划数据集和利用现有模型及公开数据，成功实现了在有限计算资源下的急诊数据分类。", "conclusion": "通过精心策划数据集和利用现有模型及公开数据，我们能够在有限计算资源的情况下成功分类急诊数据。这种方法为医疗机构提供了一种可行的解决方案，尽管硬件资源有限，仍能有效地处理急诊数据以获取重要的医疗信息。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05041", "html_url": "https://arxiv.org/abs/2509.05041", "title": "深不对称循环神经网络中的动态学习", "title_en": "Dynamical Learning in Deep Asymmetric Recurrent Neural Networks", "authors": "Davide Badalotti,Carlo Baldassi,Marc Mézard,Mattia Scardecchia,Riccardo Zecchina", "background": "研究不对称的深层递归神经网络，并结合稀疏兴奋性连接，发现其可以产生指数级别的内部表示，这些表示通过不同的算法（包括简单的迭代动力学）可以被找到。通过对稳定状态的几何属性研究，提出了分布式学习方案，输入-输出关联自然从递归动力学中产生，无需计算梯度。关键特征是收敛时达到的配置稳定性，即使在移除监督输出信号后仍然保持这一特性。", "innovation": "提出了基于几何属性的分布式学习方案，无需计算梯度，并通过简单迭代动态找到了网络的内部表示。关键在于即使在移除监督输出信号后，网络仍能保持收敛时的配置稳定性。这种学习方法在标准AI基准测试中表现出色，可以向多个方向进行扩展，具有在AI和计算神经科学之间缩小差距的潜力。", "conclusion": "该方法在标准AI基准测试中表现出色，具有向多个方向扩展的潜力，有助于弥合AI和计算神经科学之间的差距。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05016", "html_url": "https://arxiv.org/abs/2509.05016", "title": "关于两种Ising模型之间的$f$-散度的近似", "title_en": "On approximating the $f$-divergence between two Ising models", "authors": "Weiming Feng,Yucheng Fu", "background": "研究了两种Ising模型之间的$f$-散度的近似问题，该问题的背景是衡量两个分布的差异。Ising模型的近似$f$-散度是最近研究近似TV距离工作的推广。Ising模型由交互矩阵和外部场指定，目标是近似$f$-散度$D_f(\nu\text{||}\text{\textmu})$，误差在$e^{\text{±}\text{\textvarepsilon}}$的任意相对误差范围内。该研究讨论了$\text{χ}^\text{α}$散度（$\text{α}$是常数整数），并给出了算法和难度结果，算法适用于与难度结果匹配的参数范围。还讨论了算法的扩展性，可以应用于其他$f$-散度，如$\text{α}$-散度、Kullback-Leibler散度、Rényi散度、Jensen-Shannon散度和平方汉明距离的平方等。", "innovation": "该工作为进一步研究Ising模型之间的$f$-散度的近似奠定了基础，特别地探讨了$\text{χ}^\text{α}$散度的算法和难度结果，发现算法的适用范围与难度结果吻合，并且扩展算法可以适用于其它类型的$f$-散度，提供了广泛的应用潜力。", "conclusion": "本文研究了两种Ising模型之间的$f$-散度的近似问题，证明了$\text{χ}^\text{α}$散度的算法和难度结果，并展示了该算法可以在理论和实践上适用于多种$f$-散度，对于未来相关领域的研究具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05051", "html_url": "https://arxiv.org/abs/2509.05051", "title": "QCA-MolGAN：量子电路关联分子生成对抗网络结合多智能体强化学习", "title_en": "QCA-MolGAN: Quantum Circuit Associative Molecular GAN with Multi-Agent Reinforcement Learning", "authors": "Aaron Mark Thomas,Yu-Cheng Chen,Hubert Okadome Valencia,Sharu Theresa Jose,Ronin Wu", "background": "在药物发现中，导航广泛的分子结构化学空间以设计具有所需靶标特性的新型药物分子仍然是一个核心挑战。近年来，生成模型的进步为解决这一问题提供了有前景的方案。", "innovation": "提出了一种新的量子电路Born机（QCBM）驱动的生成式对抗网络（GAN），名为QCA-MolGAN，用于生成类药物分子。QCBM作为一种可学习的先验分布被引入，并通过与GAN判别器捕捉到的高层特征关联性训练，定义了一个与低层特征对齐的潜在空间。此外，还集成了一个新型的多智能体强化学习网络，以引导具有目标特性的分子生成，并优化诸如定量的类药物性指数（QED）、油水分配系数（LogP）和合成可访问性（SA）等关键指标。实验结果表明，通过多智能体强化学习代理的有效平衡化学属性，这种方法增强了生成分子的性质对齐。", "conclusion": "实验结果表明，我们的方法通过有效地平衡化学属性，增强了生成分子的性质对齐。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04991", "html_url": "https://arxiv.org/abs/2509.04991", "title": "高分辨率全球地表温度遥感通过耦合机制-机器学习框架", "title_en": "High-Resolution Global Land Surface Temperature Retrieval via a Coupled Mechanism-Machine Learning Framework", "authors": "Tian Xie,Huanfeng Shen,Menghui Jiang,Juan-Carlos Jiménez-Muñoz,José A. Sobrino,Huifang Li,Chao Zeng", "background": "地表温度（LST）对于地气相互作用和气候过程至关重要。但在异质性土地覆盖和极端大气条件下，LST的准确获取仍然是一个挑战。传统的双通道算法在湿润环境中表现出偏差；纯机器学习方法缺乏可解释性且在数据有限时泛化能力较差。", "innovation": "本文提出了一种结合物理约束与数据驱动学习的耦合机制-机器学习（MM-ML）框架，旨在提高LST的稳健获取能力。该方法将辐射传输建模与数据组件结合，使用MODTRAN模拟与全球大气剖面，并采用物理约束优化。MM-ML在4450个来自29个全球站点的观测数据验证中，取得了MAE=1.84K，RMSE=2.55K，R-squared=0.966的效果，优于传统方法。特别是在极端条件下，MM-ML将错误降低了超过50%。敏感性分析表明，LST估算对传感器辐亮度最敏感，其次是水汽，而少受发射率的影响，MM-ML显示出更好的稳定性。", "conclusion": "研究表明，我们提出的耦合建模策略在复杂环境中可靠获取地球物理参数的有效性。该MM-ML框架结合了物理可解释性与非线性建模能力，支持气候监测和生态系统研究。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04914", "html_url": "https://arxiv.org/abs/2509.04914", "title": "RobQFL：在对抗环境中稳健的量子联邦学习", "title_en": "RobQFL: Robust Quantum Federated Learning in Adversarial Environment", "authors": "Walid El Maouaki,Nouhaila Innan,Alberto Marchisio,Taoufik Said,Muhammad Shafique,Mohamed Bennai", "background": "量子联邦学习（QFL）结合了隐私保护联邦学习和量子计算的优势，但其对对抗噪声的鲁棒性尚未被研究。本研究首先表明，QFL 在对抗噪声方面的脆弱性与集中式量子学习相当。鉴于此背景，研究通过直接将对抗训练嵌入联邦学习循环中，提出了鲁棒量子联邦学习（RobQFL），并探索了客户端覆盖率、扰动调度和优化方法，通过两个新的度量（准确度-鲁棒性区域和鲁棒性体积）来评估其鲁棒性。", "innovation": "研究提出了 Robust Quantum Federated Learning（RobQFL），它嵌入了直接的对抗训练，并且引入了客户端覆盖率（覆盖范围0-100%）、扰动调度方式（固定扰动ε vs 混合扰动ε-混）和优化方法（微调 vs 从头训练）等可调参数，以此来增加系统对对抗噪声的鲁棒性。研究还提出了准确度-鲁棒性区域和鲁棒性体积这两个新的度量标准。此外，该研究还通过具体实验数据展现了在15客户端的MNIST和Fashion-MNIST数据集上的实验结果，验证了不同参数设置下的效果。", "conclusion": "在不少于75%客户端参与的情况下，适度的ε-混合效果最好，而在100%客户端参与的情况下，高ε扰动有利于提升模型的鲁棒性。对于标识排序的非簇内独立同分布数据集，鲁棒性大幅降低，展示了数据异质性是决定鲁棒性高低的主要因素。研究者表明，通过合理设置RobQFL的参数，可以在保证少量准确度损失的情况下显著提高模型在对抗环境中的鲁棒性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04980", "html_url": "https://arxiv.org/abs/2509.04980", "title": "MAIA：一种基于填充的音乐对抗攻击方法", "title_en": "MAIA: An Inpainting-Based Approach for Music Adversarial Attacks", "authors": "Yuxuan Liu,Peihong Zhang,Rui Sang,Zhixin Li,Shengchen Li", "background": "音乐信息检索（MIR）领域中，音乐对抗攻击引起了广泛关注。现有研究开发了多种对抗攻击方法，但大多数方法主要集中在传统的图像、文本领域，针对音乐数据的对抗攻击还处于初步探索阶段。", "innovation": "本文提出了一种名为MAIA的新型对抗攻击框架，支持白盒和黑盒攻击场景。MAIA首先进行重要性分析以确定关键的音频片段，然后对这些片段进行针对性修改。利用生成的填充模型，在攻击模型输出的指导下进行这些片段的重建，从而确保了细微且有效的对抗扰动。", "conclusion": "作者在多个MIR任务上评估了MAIA，展示了在白盒和黑盒场景中均具有高攻击成功率，并能保持较低的感知失真度。主观听音测试进一步证实了对抗样本的高音频保真度。研究所揭示了当前MIR系统的脆弱性，并突显了构建更为稳健和安全模型的必要性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04999", "html_url": "https://arxiv.org/abs/2509.04999", "title": "对抗增强与主动采样在稳健网络异常检测中的应用", "title_en": "Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection", "authors": "Sidahmed Benabderrahmane,Talal Rahwan", "background": "高级持续性威胁（APTs）由于其隐蔽性和长持续时间，为网络安全带来了极大的挑战。传统的监督学习方法通常需要大量的标注数据，但在现实场景中，这类数据往往稀缺。因此，本文提出了一种将自动编码器（AutoEncoders）用于异常检测与主动学习相结合的新方法，旨在通过有选择地查询或acles对不确定或模糊样本进行标注，从而减少标注成本并提高检测准确性，使模型能够在数据稀缺的情况下有效学习，并减少对大规模人工标注的依赖。", "innovation": "本文介绍了一种基于注意力对抗双自动编码器（Attention Adversarial Dual AutoEncoder）的异常检测框架，并通过主动学习循环逐步提升模型性能。该方法通过选择性地查询或acles对不确定或模糊样本进行标注，从而实现减少标注成本并提高检测准确性。本文基于DARPA透明计算项目中的实际不平衡证据追踪数据集进行了评估，该数据集涵盖了包括Android、Linux、BSD和Windows在内的多个操作系统，并测试了两种攻击场景。实验结果表明，在主动学习中，该方法的检测率显著提升，优于现有方法。", "conclusion": "提出的Attention Adversarial Dual AutoEncoder框架通过结合自动编码器和主动学习，能够在缺乏大量标注数据的情况下有效提升APTs检测精度，并展示了该方法在真实数据集中的优越性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04982", "html_url": "https://arxiv.org/abs/2509.04982", "title": "优化小型基于Transformer的语言模型在短文本多标签情感分析中的应用", "title_en": "Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts", "authors": "Julius Neumann,Robert Lange,Yuni Susanti,Michael Färber", "background": "短文本数据集中的情感分类面临显著挑战，如类别不平衡、训练样本有限以及情感标签固有的主观性，这些因素在短文本中进一步加剧。这些因素使得解决模糊性和数据稀疏性的问题变得困难，从而阻碍了有效的学习。研究表明，这种情感分类的挑战使得传统方法难以取得好的效果。因此，在资源受限的环境中优化适合短文本的情感分类模型非常重要。本文针对这些问题，评估了小型Transformer模型（如BERT和RoBERTa，参数少于10亿）在多标签情感分类中的有效性，特别是在短文本设置中的表现。", "innovation": "本文的创新之处在于：1) 评估了继续进行领域特定预训练的效果；2) 使用自动生成的示例进行数据扩增，特别是生成式数据扩增；3) 对分类头的结构变化进行评估。实验结果表明，数据扩增可以改善分类性能，而针对扩增数据集进行进一步预训练可能会引入噪声而不提高准确性。此外，对分类头的修改带来的改进只有微小的好处。这些发现为在资源受限环境中优化BERT模型提供了实用指导，并细化了在短文本数据集中的情感分类策略。", "conclusion": "研究结果表明，数据扩增可以改善分类性能，但进一步的领域预训练可能会引入噪声而不提高准确性，对分类头的修改带来的改进也只有微小的好处。这些发现提供了在资源受限环境中优化BERT模型的实用指导，并细化了在短文本数据集中的情感分类策略。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05129", "html_url": "https://arxiv.org/abs/2509.05129", "title": "小树宽图上高效精确电阻距离计算：一种标签方法", "title_en": "Efficient Exact Resistance Distance Computation on Small-Treewidth Graphs: a Labelling Approach", "authors": "Meihao Liao,Yueyang Pan,Rong-Hua Li,Guoren Wang", "background": "电阻距离计算是图分析中的基本问题，现有基于随机游走的方法只能提供近似解并导致在小树宽图（如道路网络）上效率低下。相比之下，最短路径距离计算在这些图上效率很高，利用切割属性和树分解。基于这一差异，作者分析了电阻距离的切割属性，通过结合树分解发现阻力距离依赖于路径上的标签，这使得可以构建紧凑的标签结构，并提出了新的树索引方法来实现高效的电阻距离计算.", "innovation": "作者提出了一个新的树索引方法（TreeIndex），通过结合树分解的特点，能够以$O(n \times h_{\text{\textcal{G}}})$的时间复杂度和空间复杂度来构建阻力距离标签。此方法支持精确的单对查询和单源查询，实验结果表明，TreeIndex在处理大型图时表现优于现有的最先进的方法，例如在美国全境道路网络中，它可以构造出405GB大小的标签，单个对的查询可以在微秒级别响应，单源查询在190秒左右即可完成.", "conclusion": "通过树分解的方法，TreeIndex实现了在小树宽图中高效且精确的电阻距离计算。这种方法在大规模图上的性能优越，为道路网络等应用场景提供了有效的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05175", "html_url": "https://arxiv.org/abs/2509.05175", "title": "房间声学模拟作为音频算法评估的替代方案", "title_en": "Room-acoustic simulations as an alternative to measurements for audio-algorithm evaluation", "authors": "Georg Götz,Daniel Gert Nielsen,Steinar Guðjónsson,Finnur Pind", "background": "现代技术如智能设备、穿戴设备和娱乐系统中普遍使用音频信号处理和音频机器学习（ASP/AML）算法。理想的评估应涵盖多种多样的应用场景和房间声学条件，但实践中由于测量成本高且耗时，评估数据集常常受限于规模和多样性。因此，文章探讨了利用房间声学模拟来评估ASP/AML算法的方法，并分别使用测量数据和不同模拟引擎的数据对三种算法进行了评估，分析了测量结果和模拟结果的一致性。", "innovation": "文章通过将房间声学模拟与实际测量数据对比，验证了模拟技术在评估音频算法的有效性方面的新用途。尤其值得关注的是，数值波型解决方法与三种不同ASP/AML算法的测量结果相似，但几何声学模拟未能可靠地复制测量结果。这表明数值波型方法可能在评估音频算法时具有更高的可靠性。", "conclusion": "文章发现，数值波型解法的模拟结果与实际测量结果一致，而几何声学模拟在某些情况下无法可靠地再现测量结果。因此，数值波型模拟有可能成为替代昂贵和耗时的测量技术的有效评估工具。然而，仍需要进一步的研究来探索提高几何声学模拟可靠性的方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05198", "html_url": "https://arxiv.org/abs/2509.05198", "title": "提升3D点云分类的ModelNet-R和Point-SkipNet", "title_en": "Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet", "authors": "Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari", "background": "3D点云分类对于自动驾驶、机器人和增强现实等应用至关重要。然而，常用的ModelNet40数据集存在标签不一致、二维数据、大小不匹配和类别区分不足等问题，这些限制阻碍了模型性能。研究表明，这些缺陷影响了现有模型的性能。", "innovation": "该论文提出了一种新的数据集ModelNet-R，并提出了一种基于图的轻量化神经网络Point-SkipNet。ModelNet-R对ModelNet40进行了细致的改进，解决了原有的数据集问题，旨在提供一个更可靠的基准。Point-SkipNet通过高效的采样、邻域分组和跳跃连接实现高分类准确性，同时减少计算开销。实验结果表明，在ModelNet-R上训练的模型表现有了显著提高，Point-SkipNet在参数量大幅减少的情况下达到了最先进的准确率，突显了数据集质量对于优化3D点云分类模型效率的重要性。", "conclusion": "研究结果表明，高质量的数据集对于优化3D点云分类模型效率至关重要。Point-SkipNet在保持高性能的同时具有较低的计算复杂度，是当前这类模型中的佼佼者。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05131", "html_url": "https://arxiv.org/abs/2509.05131", "title": "基于注意力机制的可扩展图像到3D纹理映射方法", "title_en": "A Scalable Attention-Based Approach for Image-to-3D Texture Mapping", "authors": "Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung", "background": "高质量的纹理对于真实的3D内容创作至关重要，但现有的生成方法通常速度较慢，需要UV映射，并且往往无法忠实于参考图像。", "innovation": "本文提出了一种基于变换器的框架，能够直接从单张图像和网格预测3D纹理场，从而消除了UV映射和可微渲染的需求，加快了纹理生成速度。方法中集成了三平面表示和基于深度的反投影损失，实现高效训练和快速推理。经过训练后，该方法可以在单次前向传递中生成高保真度的纹理，每个形状只需0.2秒。", "conclusion": "广泛的定性、定量和用户偏好评估表明，本文方法在单图纹理重构中既在输入图像保真度、感知质量方面优于现有最先进的基线方法，也为具有扩展性、高质量和可控的3D内容创建提供了实用性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05186", "html_url": "https://arxiv.org/abs/2509.05186", "title": "概率操作器学习：偏微分方程基础模型的生成建模与不确定性量化", "title_en": "Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations", "authors": "Benjamin J. Zhang,Siting Liu,Stanley J. Osher,Markos A. Katsoulakis", "background": "基础模型基于新颖的架构设计了一系列操作学习方法。在不同的初始/边界条件数据集与对应的常微分方程（ODEs）和偏微分方程（PDEs）解的数据集上进行培训后，ICON作为操作学习方法，学会了根据给定的微分方程示例条件-解对映射到其解操作符的近似表示。研究引入了一个概率框架，显示ICON在隐式执行贝叶斯推理，同时提供了描述ICON执行任务的概率框架，有助于理解其他多操作学习方法。抽象的形式为ICON提供了生成设形式的基础，使ICON能够从后验预测解操作符的概率分布中采样。这使得能够捕捉解操作符的内在不确定性，在操作学习中进行有原则的不确定性量化成为可能。", "innovation": "研究提出了一种概率框架，揭示了ICON实际上在隐式执行贝叶斯推理。基于随机微分方程的形式，ICON提供了理解和解释其他多操作学习方法的框架。通过这种方法，ICON可以被扩展到生成模型中，在此类模型中可以从解操作符的后验预测概率分布中进行采样，从而捕捉解操作符的内在不确定性，为操作学习中的不确定性量化提供了有原则的方法。", "conclusion": "提出的概率视角为扩展ICON到生成模型提供了基础，在生成模型中可以从解操作符的后验预测概率分布中进行采样。这使得能够捕捉解操作符的内在不确定性，从而在操作学习中进行有原则的不确定性量化。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05215", "html_url": "https://arxiv.org/abs/2509.05215", "title": "BEDTime: 一个统一的时间序列自动描述基准", "title_en": "BEDTime: A Unified Benchmark for Automatically Describing Time Series", "authors": "Medhasweta Sen,Zachary Gottesman,Jiaxing Qiu,C. Bayan Bruss,Nam Nguyen,Tom Hartvigsen", "background": "许多最新的研究提出了适用于各种时序分析任务的一般基础模型。虽然已经存在多个评估这些模型的现有数据集，但过去的很多工作经常在引入新的数据集时提出新的模型，这限制了直接独立比较的机会，并模糊了不同方法的相对优势。此外，之前的评估通常同时覆盖多个任务，广泛评估模型的各种能力，但并没有明确指出哪些能力对整体表现的具体贡献。", "innovation": "本文将3个测试模型通过通用自然语言描述时序的能力的任务形式化并进行评估，分别是（1）识别（真假问题回答），（2）区分（多项选择问题回答），（3）生成（开放性自然语言描述）。并统一了4个最新数据集，使每个任务上的模型可以直接比较。实验结果显示，（1）流行的仅语言模型表现不佳，表明需要专门的时间序列架构；（2）视觉语言模型（VLMs）表现非常出色，验证了视觉模型对于这些任务的价值；（3）预训练的多模态时间序列-语言模型优于大型语言模型（LLMs），但仍有很大的改进空间。所有方法在多种鲁棒性测试中都表现出明显的脆弱性。", "conclusion": "总的来说，我们的基准提供了一个标准化的评估，用于时序推理系统的必要任务。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05086", "html_url": "https://arxiv.org/abs/2509.05086", "title": "稳健专家：稀疏门控混合层对CNN中对抗性训练的影响", "title_en": "Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers", "authors": "Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner", "background": "针对对抗性攻击，如何强化卷积神经网络（CNN）的安全性仍具挑战性，通常需要资源密集的对抗性防御措施。传统的增强策略往往在不增加推理成本的情况下难以有效提升模型的鲁棒性。", "innovation": "研究提出使用稀疏门控混合层（MoE）来增强CNN的鲁棒性，通过替换选定的残差块或卷积层，增加模型容量而不增加推理成本。实验发现，在使用对抗性训练的同时，在更深的网络阶段插入单一MoE层，能够有效提升模型在PGD和AutoPGD攻击下的鲁棒性。", "conclusion": "研究揭示，使用开关损失进行平衡时，会导致路由集中在少数过度使用的专家上，从而提高了这些路径的鲁棒性，并且部分专家在对抗训练后表现出色，证明了通过专业化自发产生稳健子路径的现象。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05079", "html_url": "https://arxiv.org/abs/2509.05079", "title": "面向移动设备的轻量级全带宽语音降噪DNN：利用长短期时间模式", "title_en": "Lightweight DNN for Full-Band Speech Denoising on Mobile Devices: Exploiting Long and Short Temporal Patterns", "authors": "Konstantinos Drossos,Mikko Heikkinen,Paschalis Tsiaflakis", "background": "语音降噪（SD）是许多现代信号处理链中的重要任务，特别是在设备和日常生活中使用。虽然有许多基于深度神经网络（DNN）的语音降噪方法，但很少有方法专门针对资源受限的平台，如移动设备。此外，大多数基于DNN的语音降噪方法通常不关注全带宽（FB）信号（例如，48 kHz采样率）或低延迟情况。本文介绍了一种基于DNN的轻量级全带宽语音降噪方法，利用了短期和长期时间模式。该方法基于修改后的UNet架构，采用回测帧、卷积核的时间跨度以及循环神经网络，以利用信号和估计的去噪掩模中的短期和长期时间模式。DNN以因果方式逐帧运行，输入STFT幅度，使用受到MobileNet启发的倒置瓶颈，采用因果实例归一化来实现通道归一化。该模型在现代移动电话上实现了实时因素低于0.02。该方法使用已建立的语音降噪指标进行评估，使用公开可用的数据集表明，其（SI）-SDR值在全带宽和低延迟语音降噪方法中表现出色。", "innovation": "提出了一种基于DNN的轻量级全带宽语音降噪方法，特别针对移动设备的需求进行优化。方法利用了短时间模式和长时间模式，采用修改后的UNet架构，结合使用了look-back帧、时间跨越的卷积核、以及循环神经网络，以实现更好的降噪效果。模型采用因果实例归一化和倒置瓶颈结构，能够在现代手机上达到实时性低于0.02的效果。", "conclusion": "本文提出的方法通过使用因果框架、轻量级网络架构、短长时间模式利用等技术，在移动设备上实现了实时性优秀的全频带语音降噪效果，评估结果表明其在性能上优于现有的全带宽和低延迟语音降噪方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05263", "html_url": "https://arxiv.org/abs/2509.05263", "title": "LatticeWorld：一种基于多模态大型语言模型的交互式复杂世界生成框架", "title_en": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "authors": "Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu", "background": "近年来，研究越来越关注开发模拟复杂真实世界场景的3D世界模型。世界模型已在类生命人工智能、自动驾驶、娱乐等多个领域中找到广泛的应用。更逼真的模拟和准确的物理仿真可以有效缩小模拟与现实之间的差距，方便地收集关于真实世界的丰富信息。传统的手动建模方法已经能够创建虚拟的3D场景，而现代方法则利用了先进的机器学习算法进行3D世界的生成，并且最近的进展主要集中在可以基于用户指令生成虚拟世界的生成方法上。本文在此研究方向上探索，提出了一种名为LatticeWorld的简单有效的3D世界生成框架，简化了工业生产3D环境的管道流程。LatticeWorld利用轻量级LLM（如LLaMA-2-7B）与行业级渲染引擎（如Unreal Engine 5）相结合来生成动态环境。该框架接受文本描述和视觉指令的多模态输入，并且能够创建大规模的3D互动世界，具备竞争性的多智能体交互、高保真物理仿真和实时渲染特点。本文进行了全面的实验来评估LatticeWorld，证明其在场景布局生成和视觉保真度方面表现优异。此外，LatticeWorld与传统手动制作方法相比，在工业生产效率上实现了超过90倍的增长，同时保持了高质量的创作性。详细的演示视频可在该链接观看。", "innovation": "1. 提出了LatticeWorld，一种结合轻量级LLM和行业级渲染引擎的3D世界生成框架。\n2. 引入了接受文本描述和视觉指令的多模态输入，可以创建大型的、互动性高的、具有复杂物理仿真的3D世界。\n3. 实现了超过90倍的工业生产效率增长，同时保持了高质量的创作性。", "conclusion": "本文提出的LatticeWorld框架通过结合轻量级LLM和行业级渲染引擎，成功地简化了3D世界生成的工业生产流程，实现了多模态输入下的3D场景生成，证明了其在场景布局、视觉保真度和生成效率方面的优越性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05106", "html_url": "https://arxiv.org/abs/2509.05106", "title": "光谱算法在拟合错误回归中的收敛性：在自变量偏移下的收敛性", "title_en": "Spectral Algorithms in Misspecified Regression: Convergence under Covariate Shift", "authors": "Ren-Rui Liu,Zheng-Chu Guo", "background": "本文探讨了光谱算法（一类源自逆问题的正则化方法）在自变量偏移情况下的收敛性质。在这种情况下，源域和目标域中输入的边际分布不同，而输出给定输入的条件分布保持不变。为了应对这种分布不匹配，本文将重要权重（即目标域与源域密度的比值）纳入学习框架中，生成了一个带权重的光谱算法。本文针对目标函数不属于核希尔伯特空间的问题（即情况更复杂、更具挑战性的情况），进行了全面的理论分析。在核密度比限值均匀有界假设下，展示了当目标函数属于核希尔伯特空间时的最优收敛率。对于重要性权重无界的场景，提出了一种新的截断技术，在温和的正则条件下达到了近最优的收敛率，并将结果扩展到了拟合错误的领域。", "innovation": "本文针对核功能空间之外的目标函数提供了一种全面的理论分析；在重要性权重可能无界的场景下，提出了一种新的截断技术，能够在这两种情况下获得最优的收敛率；该工作将经典的核学习理论扩展到了更具实际意义的场景，为理解模型偏差与自变量偏移的相互作用提供了一套系统性的框架。", "conclusion": "本文通过解决自变量偏移与模型拟合错误的交织挑战，扩展了经典的核学习理论，提供了一种系统性的框架来理解这两种现象的交互影响。并提出了新的理论和技术，适用于目标函数可能不在核希尔伯特空间中的场景。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05208", "html_url": "https://arxiv.org/abs/2509.05208", "title": "使用大型语言模型进行符号图形编程", "title_en": "Symbolic Graphics Programming with Large Language Models", "authors": "Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu", "background": "大型语言模型（LLMs）在程序合成方面表现出色，但它们生成能够精准可视化内容的符号图形程序（SGPs）的能力仍然未被充分探索。研究符号图形编程的目标是从自然语言描述生成SGP，这也是对LLMs如何理解和生成视觉内容的一个观察窗口。此研究专注于可缩放的矢量图形（SVGs），评估了LLMs生成SGPs的能力，并提出了一个涵盖对象准确度、场景准确度和组合性（属性绑定、空间关系、数理能力）的综合基准（SGP-GenBench）。研究发现，前沿专有模型在该基准上显著优于开源模型，性能与通用编程能力高度相关。", "innovation": "提出了结合验证奖励的强化学习方法，确保生成可渲染的SVG，并通过强视觉编码器（例如SigLIP和DINO）对齐文本和渲染图像的跨模态奖励，显著提高SVG生成质量和语义，使其性能与前沿系统相当。此方法展示了符号图形编程作为跨模态绑定的精确和可解释的视角，并分析了训练动态，发现RL提升了对象分解和场景连贯性。", "conclusion": "符号图形编程为跨模态绑定提供了一种精确且可解释的方法。研究发现，前沿专有模型在生成高质量SVG方面优于开源模型，强化学习结合验证奖励的方式显著提升了LLMs的符号图形编程能力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05289", "html_url": "https://arxiv.org/abs/2509.05289", "title": "超越线性和时间同质性：具有时间变化非线性效应的关系超事件模型", "title_en": "Beyond Linearity and Time-homogeneity: Relational Hyper Event Models with Time-Varying Non-Linear Effects", "authors": "Martina Boschi,Jürgen Lerner,Ernst C. Wit", "background": "近期的技术进步使得收集带有时间戳的复杂网络变得更为容易，这些网络连接两个或多个实体。关系超事件模型（RHEMs）试图通过基于过去历史和外部信息统计量来建模事件率的变化，来解释这些事件的动力学。然而，尽管数据复杂性高，大多数现有的RHEM方法仍然依赖线性假设来建模这种关系。", "innovation": "本文通过引入一种更灵活的模型，解决了这一局限，该模型允许统计量的影响随着时间非线性地变化。不同于仅使用时间变化或非线性效应的现有方法，本文通过张量积光滑技术建模了联合时间变化和非线性效应。该方法在合成数据和实际数据上进行了验证，并通过RHEMs研究了科学合作和影响力随时间的变化模式，提供了动态因素的深入洞察，揭示了线性模型无法识别的非单调模式。", "conclusion": "该方法提供了一种更深入的理解关系超事件动力学的方式，能够评估潜在的非单调模式，并通过实证数据验证了其有效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05201", "html_url": "https://arxiv.org/abs/2509.05201", "title": "基于感知观测器的自主车辆鲁棒模型预测控制设计", "title_en": "Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers", "authors": "Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares", "background": "该论文旨在解决深度学习感知模块用于状态估计时固有的非高斯噪声问题。由于精确的感知不确定性量化对安全反馈控制至关重要，传统的基于零均值噪声假设的方法可能性能欠佳，因此需要一种新的方法来处理感知误差的偏斜和重尾不确定性，同时保持有限的估计误差。为了提高计算效率，将鲁棒的模型预测控制重新公式化为线性规划（LP），并利用梅因柯维斯基-李雅普诺夫成本函数和额外的松弛变量，以防止退化解。闭环稳定性通过梅因柯维斯基-李雅普诺夫不等式和收缩锥体不变集来保证。通过椭球近似方法推导出最大的稳定终端集及其相应的反馈增益。该方法在无人驾驶全向移动机器人上进行了仿真和硬件实验，验证了其在重尾噪声条件下提供稳定和精确控制性能的能力，优于传统基于高斯噪声的设计。", "innovation": "采用了基于区间估计和受约束的佐诺多普方法来捕捉偏斜和重尾不确定性，而不是传统的零均值噪声假设。将鲁棒MPC重新公式化为线性规划，并使用梅因柯维斯基-李雅普诺夫成本函数和额外的松弛变量，以防止退化解。通过椭球近似方法推导出了最大稳定终端集及其相应的反馈增益。这种控制策略能够提供基于感知的闭环稳定控制性能，尤其在存在重尾噪声时表现更为出色。", "conclusion": "通过仿真实验和硬件实验验证了感知意识的MPC在存在重尾噪声条件下的稳定和精确控制性能，优于传统高斯噪声假设的设计，特别是在状态估计误差边界和整体控制性能方面表现出显著的优势。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.17351", "html_url": "https://arxiv.org/abs/2410.17351", "title": "基于分层多智能体强化学习的网络防御", "title_en": "Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense", "authors": "Aditya Vikram Singh,Ethan Rathbun,Emma Graham,Lisa Oakley,Simona Boboila,Alina Oprea,Peter Chin", "background": "近年来，多智能体强化学习（MARL）在解决复杂现实任务方面取得了进展，特别是在网络安全领域。网络安全是应用的一个显著领域，其中防御网络免受复杂对手的攻击通常是由安全操作团队来完成的，这是一项具有挑战性的任务。", "innovation": "本文探讨了新的MARL策略以构建自主的网络安全防御系统，解决大策略空间、部分可观测性和隐蔽、欺骗性对手策略的挑战。为了促进高效和通用的学习，我们提出了一种分层Proximal Policy Optimization (PPO) 架构。该架构将网络防御任务分解为网络调查和主机恢复等具体子任务，并训练每个子任务的子策略。这些子策略由协调其选择的主防御策略利用，以解决复杂的网络防御任务。此外，子策略可以在对抗性行为的转变或网络设置变化时，以较低的成本进行微调并转移。", "conclusion": "我们在最新的MARL环境CybORG Cage 4中进行了大量实验，我们的分层学习方法在收敛速度、每个回合的回报和多个与网络安全相关的可解释指标（如网络中干净机器的比例、精确度和假阳性率）方面都取得了最佳性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.10863", "html_url": "https://arxiv.org/abs/2409.10863", "title": "动态范围减少通过分支定界", "title_en": "Dynamic Range Reduction via Branch-and-Bound", "authors": "Thore Gerlach,Nico Piatkowski", "background": "随着机器学习和人工智能对高性能计算的需求增加，专门的硬件加速器如张量处理单元（TPUs）、图形处理单元（GPUs）和现场可编程门阵列（FPGAs）应运而生。为了增强这些加速器，通过减少算术运算的精度来提高处理速度和降低延迟，这对实时AI应用至关重要。精度减少可以减小内存带宽需求和能耗，适合大规模和移动部署，同时通过每周期执行更多并行操作来提高吞吐量，实现硬件资源的最大化利用。此外，对于常见的机器学习中的复杂NP完全二次无约束二元优化（QUBO）问题，往往需要高精度以准确表示，在这一点上，专用硬件求解器如量子退火器同样受益于精度的减少。", "innovation": "本研究提出了一种通过动态范围作为复杂度度量的分支定界算法，实现QUBO问题中精度需求的减少。这种算法是完全原理上的方法，实验证明该算法在真实量子退火器上有效。", "conclusion": "通过动态范围减少以及应用分支定界算法，本研究成功提出了一种精确定量QUBO问题的新的方法，该方法对于量子退函等专用硬件加速器具有显著的效果，为优化硬件资源利用和提高处理效率提供了理论依据和实践指导。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.23773", "html_url": "https://arxiv.org/abs/2410.23773", "title": "为了更快的点对点射线追踪而进行的生成性射线路径采样", "title_en": "Towards Generative Ray Path Sampling for Faster Point-to-Point Ray Tracing", "authors": "Jérome Eertmans,Nicola Di Cicco,Claude Oestges,Laurent Jacques,Enrico M. Vitucci,Vittorio Degli-Esposti", "background": "射频传播建模是电信研究中的重要组成部分，因为射频信道由环境物体的复杂交互产生。近年来，机器学习因其能够替代计算密集型工具（如射线追踪）而受到关注，尽管射线追踪可以在细节上模拟这些交互，但现有的机器学习方法往往试图直接学习特定的信道特征（如覆盖图），这让它们高度依赖于频率和材料特性，无法全面捕捉传播机制。因此，射线追踪，特别是点对点变体，仍然是准确识别所有可能路径的流行方法，但路径识别过程非常耗时，因为测试路径的数量呈指数增长，而有效路径只占一小部分。", "innovation": "本文提出了一种机器学习辅助射线追踪方法，以高效地采样潜在射线路径，显著减少计算负载同时保持高精度。该模型能够动态地学习优先考虑所有可能路径中潜在有效的路径，并且其复杂性随场景复杂性线性增长。此外，该方法对于几何图形的平移、缩放或旋转具有不变性，并避免了特定环境特征的依赖。", "conclusion": "本文通过提出机器学习辅助的射线追踪方法，有效地减少了点对点射线追踪中的计算负担，同时保持了高精度。这种方法具有良好的可伸缩性和对几何变化的不变性，为进一步的研究提供了新的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2211.15960", "html_url": "https://arxiv.org/abs/2211.15960", "title": "FC-PINO: 通过傅里叶连续性获得高精度物理导向神经算子", "title_en": "FC-PINO: High Precision Physics-Informed Neural Operators via Fourier Continuation", "authors": "Adarsh Ganeshram,Haydn Maust,Valentin Duruisseaux,Zongyi Li,Yixuan Wang,Daniel Leibovici,Oscar Bruno,Thomas Hou,Anima Anandkumar", "background": "物理导向神经算子（PINO）是一种机器学习范式，用于学习偏微分方程（PDEs）的解，并通过计算物理损失来减少偏差。现有的PINO架构依赖傅里叶神经算子进行功能空间中的解算子学习，并利用物理损失来惩罚与已知物理定律偏差。但传统的频谱微分法在非周期函数上应用时，假设存在周期性，这会导致显著误差，特别是对于高阶导数的计算精度影响更大。现有PINO架构在处理非周期和非光滑PDE时存在局限性，无法提供高精度的解算。", "innovation": "提出了一种傅里叶连续性基的PINO架构（FC-PINO），通过将非周期信号在扩展域上转换为周期函数来提高准确性与效率。FC-PINO采用傅里叶连续性集成到PINO框架中，并测试了两种不同的连续方法：FC-Legendre和FC-Gram。这种连续方法能够高效且准确地计算导数，避免了有限差分的离散敏感性和自动生成求导的内存开销。实验结果表明标准的PINO在处理非周期和非光滑PDE时难以提供高精度解决方案，而FC-PINO则提供了准确、稳健且可扩展的解决方案，显著优于其他PINO替代方案。", "conclusion": "研究提出了FC-PINO架构，通过傅里叶连续性消除了PINO在处理非周期和非光滑PDE时的局限性，能够提供高精度、稳健且可扩展的解。傅里叶连续性对于使PINO适用于更广泛的PDE问题至关重要，尤其是需要高精度解的情况。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12391", "html_url": "https://arxiv.org/abs/2502.12391", "title": "不妥协安全：扩散正则化在约束离线强化学习中的应用", "title_en": "Don't Trade Off Safety: Diffusion Regularization for Constrained Offline RL", "authors": "Junyu Guo,Zhi Zheng,Donghao Ying,Ming Jin,Shangding Gu,Costas Spanos,Javad Lavaei", "background": "约束强化学习（RL）旨在在确保安全约束的情况下，实现高性能的策略。在实际任务中，代理通常只能依赖固定的离线数据集进行学习，以避免不安全的探索。传统的离线RL方法很难在利用已有数据的同时满足安全要求。本文讨论了这一挑战。", "innovation": "本文提出了Diffusion-Regularized Constrained Offline Reinforcement Learning (DRCORL) 方法。该方法首先利用扩散模型从离线数据中捕捉行为策略，然后提取简化策略以实现高效推理。进一步通过梯度操纵进行安全适应，平衡奖励目标和约束满足。DRCORL 方法能够在利用高质量离线数据的同时满足安全要求，提升了安全性、推理速度和奖励表现。", "conclusion": "实验结果表明，DRCORL 方法在多个机器人任务中实现了可靠的安全性能、快速推理和强劲的奖励结果，相对于现有安全离线 RL 方法具有成本限制一致性和良好的可调性，显示出实际应用场景中的实用性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00612", "html_url": "https://arxiv.org/abs/2502.00612", "title": "使用因果关系改进Web流量时间序列预测", "title_en": "Using Causality for Enhanced Prediction of Web Traffic Time Series", "authors": "Chang Tian,Mingzhe Xing,Zenglin Shi,Matthew B. Blaschko,Yinliang Yue,Marie-Francine Moens", "background": "预测Web服务流量具有重要的社会价值，可以应用于动态资源扩展、负载均衡、系统异常检测、服务级别协议符合性以及欺诈检测等多种实际场景。Web服务流量具有剧烈波动且用户行为多变，使得预测变得极具挑战性。先前的研究已经广泛探索了统计方法和神经网络来从先前的服务流量时间序列中挖掘特征进行预测，但这些方法大多没有考虑到服务之间的因果关系。", "innovation": "本文受到生态系统的因果关系启发，通过实证识别了Web服务之间的因果关系，并提出了一个名为CCMPlus的有效神经网络模块，该模块能够提取服务之间的因果关系特征并无缝集成到现有的时间序列模型中以提升预测性能。理论证明CCMPlus生成的因果相关矩阵能够捕捉到服务间的因果关系。实验结果表明，在Microsoft Azure、阿里巴巴集团和Ant Group的实际数据集上，该方法在预测服务流量时间序列的均方误差和平均绝对误差方面优于现有最先进的方法。", "conclusion": "这些结果显示利用因果关系可以提高预测效果。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.13341", "html_url": "https://arxiv.org/abs/2412.13341", "title": "Concept-ROT: 使用模型编辑在大型语言模型中注入概念中毒", "title_en": "Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing", "authors": "Keltin Grimes,Marco Christiani,David Shriver,Marissa Connor", "background": "模型编辑方法通过修改小型且目标化的网络权重集来调整大型语言模型的特定行为，所需数据量和计算资源都非常少。这些方法可以被误用，如插入错误信息或简单的特洛伊木马，这些特洛伊木马在特定触发词存在时引发攻击者指定的行为。以往的编辑方法多关注将个别单词与固定输出结果之间建立联系的受限场景，但研究表明，编辑技术可以整合更复杂的输出模式，同样有效。文章引入了一种名为Concept-ROT的方法，该方法利用模型编辑高效地注入不仅表现出复杂输出行为，还会在高层次概念的触发下激活的特洛伊木马，从而定义了一种全新的特洛伊木马攻击类别。具体而言，特洛伊木马被植入于前沿安全调优的大语言模型中，仅在遇到“计算机科学”或“古代文明”这类主题时激活，被触发时，它们会使模型突破限制，回答那些原本会拒绝回答的有害问题。文章的结果进一步指出了在机器学习模型中进行特洛伊木马攻击的实际性和潜在影响的紧迫性。", "innovation": "该研究开发了一种名为Concept-ROT的方法，它使用模型编辑插入能够触发复杂行为并依赖高层次概念的特洛伊木马，这是传统方法通常无法实现的效果，从而定义了一种全新的特洛伊木马攻击类别。", "conclusion": "该研究的成果揭示了特洛伊木马攻击在机器学习模型中具有实际性和潜在的重大影响，尤其是在高水平概念触发时的复杂行为注入，因此应当引起对机器学习模型安全性的进一步关注。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12796", "html_url": "https://arxiv.org/abs/2502.12796", "title": "通过改进生成的神经因果模型学习反事实公平模型", "title_en": "Learning Counterfactually Fair Models via Improved Generation with Neural Causal Models", "authors": "Krishn Vishwas Kher,Saksham Mittal,Aditya Varun V,Shantanu Das,SakethaNath Jagarlapudi", "background": "在实际应用中部署机器学习模型时，公平性是一个主要关切。反事实公平性作为一种直观且自然的公平性定义已经出现。然而，现有的反事实公平性约束方法有两个主要局限：(1) 生成忠实于基础因果图的反事实样本；(2) 现有的正则化器仅仅作为代理标准，并非直接保证反事实公平性的精确定义。本文旨在缓解这两个问题。", "innovation": "首先，本文提出使用神经因果模型（NCMs）生成反事实样本。为实现NCMs中的演绎步骤，需要估计给定反事实查询时外生变量的后验概率。然后提出了一个新颖的核最少二乘损失项，以明确地强制执行L3约束，从而提高反事实生成的质量，使其更适合反事实公平性的任务。其次，提出了一种新的基于MMD的正则化项，在训练过程中显式地将反事实公平性条件引入基础模型，解决了公平性和泛化的折衷问题。", "conclusion": "与现有基线相比，本文方法在合成和基准数据集上实现了反事实公平性和泛化性能的改进折衷。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19964", "html_url": "https://arxiv.org/abs/2502.19964", "title": "稀疏自编码器（SAE）通用性研究：基于回答能力的案例研究", "title_en": "Do Sparse Autoencoders Generalize? A Case Study of Answerability", "authors": "Lovis Heindrich,Philip Torr,Fazl Barez,Veronika Thost", "background": "稀疏自编码器（SAE）作为一种在语言模型解释性方面具有潜力的方法，能够实现无监督的稀疏特征提取。解释方法要想成功，必须能在不同领域识别出抽象特征，但这些特征在不同上下文中的表现常常有所不同。", "innovation": "文章通过研究模型回答能力（answerability）来评估SAE特征的通用性，采用了多种部分自构建的answerability数据集对Gemma 2 SAEs的特征进行了广泛评估，发现残差流探针在领域内表现优于SAE特征，但在跨领域迁移时表现并不一致，有从接近随机到超越残差流探针的情况。", "conclusion": "研究结果表明，需要更加稳健的评估方法和定量手段来预测基于SAE的解释性中特征的通用性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05291", "html_url": "https://arxiv.org/abs/2509.05291", "title": "时间中的交叉编码：追踪整个LLM预训练过程中语言表示的涌现和巩固", "title_en": "Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining", "authors": "Deniz Bayazit,Aaron Mueller,Antoine Bosselut", "background": "大型语言模型（LLMs）在预训练过程中学习到非平凡的抽象，例如检测不规则复数名词主语。然而，传统基准测试方法未能揭示模型是如何获得概念和能力的。本文旨在通过使用稀疏交叉编码器来发现和对齐模型检查点之间的特征，填补此方面的空白，以便更好地理解模型训练的概念层次。通过这种方法，可以追踪这些特征在预训练过程中随时间的变化情况。", "innovation": "本文引入了一种新型度量方法，RelIE（相对间接效果），用于追踪个体特征何时对任务性能成为因果重要。这种方法可以检测特征在预训练过程中的出现、维持和消失。此外，该方法具有架构无关性和可扩展性，为整个预训练过程中表示学习的更可解释和精细分析提供了可行的途径。", "conclusion": "交叉编码技术可以追踪语言表示在预训练过程中的涌现、巩固和发展。通过这种方法，可以更好地理解模型学习的具体概念，并提供了一条通向更可解释和精细分析表示学习过程的途径。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.06486", "html_url": "https://arxiv.org/abs/2406.06486", "title": "连续空间注意力机制神经运算符", "title_en": "Continuum Attention for Neural Operators", "authors": "Edoardo Calvello,Nikola B. Kovachki,Matthew E. Levine,Andrew M. Stuart", "background": "transformers 和注意力机制在机器学习中无处不在。它们在自然语言处理、计算机视觉和时间序列问题中的成功应用得益于其建模非局部、长距离相关性的能力。神经运算符被设计为在函数空间之间映射关系，本质上是既非线性又非局部。因此，探索是否可以将注意力机制融入神经运算符的设计中是自然的。基于这一动机，作者将注意力机制应用于函数空间，并证明实际中实施的注意力机制是映射无穷维函数空间的操作的一种蒙特卡罗或有限差分近似。这对理解和设计具有函数空间注意力机制的神经运算符提供了理论基础，并能够导出用于学习函数空间之间映射的架构。", "innovation": "该研究证明了使用仅对实际实现的架构进行轻微修改就能得到的首个通用逼近结果，这是在函数空间布置注意力机制的神经运算符。鉴于应用于多维域定义的函数时注意力操作的高计算成本，作者还提出了一种基于计算机视觉的patching策略的函数空间推广，并引入了一类相应的神经运算符。数值结果表明，这些方法在一系列运算学习问题中具有潜力，并展示了函数空间注意力机制在神经运算符中的应用前景.", "conclusion": "通过提出功能空间形式的注意力机制及其在神经运算符中的应用，该研究开辟了新的路径，促进了非局部和非线性神经运算符的发展。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04365", "html_url": "https://arxiv.org/abs/2504.04365", "title": "AutoPDL：LLM 代理的自动提示优化", "title_en": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "authors": "Claudio Spiess,Mandana Vaziri,Louis Mandel,Martin Hirzel", "background": "大型语言模型（LLMs）的表现取决于如何对其进行提示，这些提示涵盖了高层提示模式（如零样本、逐步思考、反应式提示、重写和双优化）和具体提示内容（指令和少数示例演示）。手动调整这种组合既繁琐又容易出错，并且针对特定的LLM和任务。因此，本文提出了AutoPDL，一种自动方法来发现良好的LLM代理配置。", "innovation": "该方法将这一过程构架为具有组合空间（包括有能动性和无能动性提示模式及演示）的结构化自动机器学习问题，并且使用逐次裁减高效地探索该空间。引入了一个使用PDL提示编程语言实现常见提示模式的库。AutoPDL解决方案是一种使用该库的、可编辑和可执行的PDL程序。该方法还使源到源优化成为可能，允许在环中的人调整和重复使用。", "conclusion": "在三个任务和七个LLM（参数范围从3亿到70亿）上的评估表明，AutoPDL获得了一致的准确性提升（9.21±15.46个百分点，最多67.5个百分点），并且揭示了所选提示策略在不同的模型和任务之间有所不同。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10264", "html_url": "https://arxiv.org/abs/2505.10264", "title": "跨域数据挖掘：联邦学习中基于超平面的数据重建攻击", "title_en": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "authors": "Francesco Diana,André Nusser,Chuan Xu,Giovanni Neglia", "background": "联邦学习（FL）允许跨分布式客户端协作训练机器学习模型而不共享原始数据，从而保护数据隐私。然而，近期的研究表明，恶意的中央服务器可以通过操纵模型更新来重建客户端的私人训练数据，揭示出FL中的严重漏洞。现有数据重建攻击具有重要局限性：它们通常依赖于对客户端数据分布的假设，或者当批次大小超过几十个样本时效率显著下降。", "innovation": "本文引入了一种新颖的数据重建攻击方法，克服了现有技术的局限性。该方法利用全连接层的一种新的几何视角，构造恶意模型参数，使在分类任务中无需任何关于客户端数据的知识即可完美地重建任意大小的数据批量。", "conclusion": "通过在图像和表数据集上的广泛实验，我们证明了我们的攻击方法优于现有方法，并实现了比最先进的方法大两个数量级的数据批量的完美重建。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18785", "html_url": "https://arxiv.org/abs/2504.18785", "title": "ALF：多模态广告主理解的广告主大型基础模型", "title_en": "ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding", "authors": "Santosh Rajagopalan,Jonathan Vronsky,Songbai Yan,S. Alireza Golestaneh,Shubhra Chandra,Min Zhou", "background": "在文本、图像、视频和结构化数据等多种模态中，理解广告主的行为和意图是一项复杂任务。现有的方法通常局限于单一模态或某些特定场景，难以全面捕捉广告主的多种特征和行为模式。因此，作者提出了一种名为ALF的多模态变压器架构，通过对比学习和多任务优化，创建统一的广告主表示，能够同时捕捉内容和行为模式。这种模型在欺诈检测、政策违规识别和广告主相似性匹配等关键任务上取得了最先进的性能。在实际部署中，ALF显著提高了精确率和召回率，例如在某个关键的政策上提高了40多个百分点的召回率，并将另一个政策上的精确率提高到了99.8%。模型的有效性主要来源于其新颖的多模态变换、样本间注意力机制、谱归一化投影和校准概率输出的结合。", "innovation": "ALF模型通过新颖的多模态变换、样本间注意力机制、谱归一化投影和校准概率输出相结合的方式，能够在多种模态下统一表示广告主，既捕捉广告主的内容特征也捕捉其行为模式，实现了在多个关键任务上的先进性能。特别是在生产和部署过程中，其展示了在精确率和召回率之间取得平衡的能力，显著提高了性能表现。", "conclusion": "ALF模型在多模态广告理解领域的研究成果显著，通过其创新的架构不仅提升了广告主行为理解的准确性，而且在实际应用中也带来了实际的积极影响。进一步的研究可以探索更多模态数据的应用，以及如何更高效地应用该模型进行大规模数据的分析和处理。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15802", "html_url": "https://arxiv.org/abs/2505.15802", "title": "基于深度学习的二维多频次传播因子估算框架", "title_en": "A Deep Learning Framework for Two-Dimensional, Multi-Frequency Propagation Factor Estimation", "authors": "Sarah E. Wessinger,Leslie N. Smith,Jacob Gull,Jonathan Gehman,Zachary Beever,Andrew J. Kammerer", "background": "准确估计海洋大气边界层内多个频率下的折射环境对于雷达技术的有效部署至关重要。传统的抛物方程模拟虽然有效，但由于计算成本高、耗时长，限制了其实际应用。", "innovation": "提出了使用深度神经网络估算模式传播因子的新方法。通过设计可接收修改折射率数据并生成相同领域内模式传播因子预测的图像到图像翻译生成器，实现了对多频次信号传播影响的合理预测，提供了一种替代传统方法的选择。", "conclusion": "深度神经网络能够被训练以分析多个频率并合理预测模式传播因子，为雷达技术的实际应用提供了一种新的可能性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00917", "html_url": "https://arxiv.org/abs/2506.00917", "title": "Q-learning with Posterior Sampling", "title_en": "Q-learning with Posterior Sampling", "authors": "Priyank Agrawal,Shipra Agrawal,Azmat Azati", "background": "贝叶斯后验采样技术在探索-利用设定中表现出优越的实际性能。然而，在复杂的环境中，如强化学习中，它们的理论分析仍然是一个挑战。这篇文章引入了基于Gaussian后验的Q值的PSQL算法，它在表结构的马尔可夫决策过程（MDP）中实现了接近于已知下界的遗憾界。", "innovation": "PSQL算法结合了基于动态规划和TD学习的Q学习方法，使用Gaussian后验进行探索，在表结构的MDP设定下实现了$\tilde O(H^2\frac{\text{sqrt}(SAT)}{K})$的遗憾界，接近下界$\text{Ω}(H\frac{\text{sqrt}(SAT)}{K})$。这为将后验采样与动态规划和TD学习相结合提供了新的技术见解，并提出了克服这些挑战的新方法，为更复杂环境中的分析奠定了基础", "conclusion": "这一工作提供了几个核心挑战的见解，即如何将后验采样与动态规划相结合，并与TD学习以及RL算法进行交互。同时，它还提出了克服这些难题的新想法，这将为在更复杂环境下分析PSQL算法提供了起点。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00810", "html_url": "https://arxiv.org/abs/2505.00810", "title": "通过贝叶斯优化检索和基于变换器的重排ranking在医疗信息学中实现可扩展的单位同步", "title_en": "Scalable Unit Harmonization in Medical Informatics via Bayesian-Optimized Retrieval and Transformer-Based Re-ranking", "authors": "Jordi de la Torre", "background": "在大规模临床数据集中的单位不一致性是数据互操作性的一个关键障碍。为此，作者开发并评估了一种新的单位同步方法，旨在解决这个问题，提高临床数据的一致性和互操作性。", "innovation": "文章设计了一个结合BM25、句子嵌入、贝叶斯优化和双向变换器基础二元分类器的新颖单元同步系统。通过多阶段管道实现过滤、识别、同步建议生成、自动重新排序和人工验证。这种混合检索方法在MRR等标准信息检索指标上的表现明显优于仅基于词法的方法。", "conclusion": "该框架提供了一种高效且可扩展的解决方案，用于临床数据集中的单位同步，同时提高准确性并减少手动工作量。同步后的数据可以在不同分析中无缝使用，确保不同健康保健系统的一致性，从而支持更可靠的大规模机构研究和荟萃分析。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04786", "html_url": "https://arxiv.org/abs/2506.04786", "title": "作为通用向量量化方法的核k-质心", "title_en": "Kernel $k$-Medoids as General Vector Quantization", "authors": "Thore Gerlach,Sascha Mücke,Christian Bauckhage", "background": "向量量化（VQ）作为一种广泛应用于机器学习和数据压缩的技术，因其简单性和可解释性而受到重视。在硬VQ方法中，k-质心聚类（$k$-medoids clustering）和核密度估计（KDE）方法代表了两种显而易见不相关的范式——一种基于距离的方法，另一种基于概率密度匹配。", "innovation": "本文通过二次无约束二进制优化（QUBO）的视角探讨这两种方法的联系。我们比较了基于$ k $-质心的核心启发式QUBO公式，该公式兼顾中心性和多样性，以及基于核密度估计（KDE）变体的精确QUBO公式，以最小化最大均差（Maximum Mean Discrepancy）。我们展示了，在轻度假设核特征映射的情况下，KDE-QUBO是$ k $-质心-QUBO的特例，揭示了这两种方法的深层结构关系，并提供了对VQ QUBO公式中权重参数几何解释的新见解。", "conclusion": "我们发现KDE-QUBO和$ k $-质心-QUBO在一定假设下存在特例关系，这一发现揭示了两者之间的深层结构联系，并为QUBO在VQ中的权重参数几何解释提供了新的见解。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05230", "html_url": "https://arxiv.org/abs/2509.05230", "title": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "title_en": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "authors": "Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci", "background": "预训练语言模型已在各种应用中取得了显著的成功，但仍然容易受到概念驱动的虚假相关性的影响，这会损害模型的稳健性和公平性。", "innovation": "本文提出了CURE，一种新型且轻量级的框架，该框架系统地解构和抑制概念捷径，同时保留核心内容信息。该方法首先通过一个由反转网络增强的内容提取器提取与概念无关的表示，确保最小化与任务相关的信息损失。随后的可控去偏模块通过对比学习微调剩余的概念性提示的影响，使模型能够根据目标任务的需求减轻有害偏见或利用有益的关联。", "conclusion": "CURE 在IMDB和Yelp数据集上分别实现了F1分数绝对提升 +10 分和 +2 分，同时引入了微乎其微的计算开销。本方法为对抗概念偏见提供了一种灵活的无监督框架，为更可靠和公平的语言理解系统铺平了道路。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09824", "html_url": "https://arxiv.org/abs/2506.09824", "title": "一种用于数据异构环境下鲁棒联邦学习的加权损失方法", "title_en": "A Weighted Loss Approach to Robust Federated Learning under Data Heterogeneity", "authors": "Johan Erbani,Sonia Ben Mokhtar,Pierre-Edouard Portier,Elod Egyed-Zsigmond,Diana Nurbakova", "background": "联邦学习（FL）是一种机器学习范式，允许多个数据持有者在不共享其训练数据的情况下协同训练模型。在这种范式中，工人本地更新模型并将更新的梯度（或模型参数）与中央服务器共享。尽管FL在隐私方面似乎有吸引力，但它从安全角度来看却提出了许多威胁，因为（拜占庭）参与者可以贡献毒化梯度（或模型参数），从而损害模型收敛。针对这一问题，抗拜占庭联邦学习通过确保在拜占庭参与者不存在的情况下进行训练来解决这个问题。为了实现这一目标，常见的策略在模型聚合时忽略异常值梯度，假设拜占庭梯度与诚实梯度之间的偏差比诚实梯度之间更大。但在异构环境中，诚实梯度可能会有很大差异，这使得区分诚实异常值和拜占庭异常值变得困难。", "innovation": "作者引入了工人标签对齐损失（WoLA），这是一种加权损失，即使在数据异构的情况下也能对齐诚实工人的梯度，从而有助于识别拜占庭梯度。这种方法在异构环境中显著优于最先进的方法。", "conclusion": "本论文提供了WoLA方法的理论洞察和其实例效果。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07236", "html_url": "https://arxiv.org/abs/2507.07236", "title": "简单而有效的多大规模语言模型不确定性量化信息论方法", "title_en": "Simple Yet Effective: An Information-Theoretic Approach to Multi-LLM Uncertainty Quantification", "authors": "Maya Kruse,Majid Afshar,Saksham Khatwani,Anoop Mayampurath,Guanhua Chen,Yanjun Gao", "background": "大规模语言模型（LLMs）在不同输入上的表现经常不一致，这表明了模型的不确定性，并且在高风险场景中需要对其不确定性的量化。先前的研究大多数关注单个模型的校准和不确定性量化，忽略了模型多样性的潜力。", "innovation": "我们假设LLMs由于训练方式不同和语言的 Zipfian 特性，各自提供互补预测，并且通过聚合其输出可以得到更可靠不确定性估计。为此，我们提出了一种简单的信息论方法MUSE（多LLM不确定性量化子集集成），使用Jensen-Shannon散度来识别并聚合已校准的LLM子集。实验表明，与单模型和朴素集成基线相比，MUSE在二元预测任务中的校准和预测性能得到了提升。此外，还探讨了使用MUSE作为引导信号与思维链温Decrementation来微调LLMs以实现校准的方法。MUSE已在官网开源。", "conclusion": "我们提出了MUSE来利用LLMs的互补性来提升不确定性的估计，实验证明这种方法在多个评估指标上表现优越，并且通过MUSE辅助的思维链温Decrementation可以进一步提升模型的校准能力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05644", "html_url": "https://arxiv.org/abs/2507.05644", "title": "The Features at Convergence Theorem: 一个以基本原理为基础的神经特征假设的替代观点，用于解释网络如何学习表示", "title_en": "The Features at Convergence Theorem: a first-principles alternative to the Neural Feature Ansatz for how networks learn representations", "authors": "Enric Boix-Adsera,Neil Mallinar,James B. Simon,Mikhail Belkin", "background": "深度学习中的一个核心挑战是理解神经网络如何学习表示。当前研究中最主要的方法之一是神经特征假设（NFA），这是一种理论上未被证实的特征学习机制。虽然NFA在实践中有实际效果，但它只是一个假设性的观点，缺乏理论支撑，因而其适用性和改进方法仍然不清楚。本文研究该假设成立和不成立的原因，并基于基础原理推导了在收敛时特征的理论，即Features at Convergence Theorem (FACT)，这为神经网络中的特征学习提供了更深入的理解。", "innovation": "作者提出了一种基于基础原理的理论分析方法，即Features at Convergence Theorem (FACT)，以替代NFA。该理论获得了更高的一致性，解释了NFA在大多数情况下的合理性，并捕捉到模数算术中的grokking行为和稀疏异或问题学习中的相变等关键特征学习现象，与NFA类似。因此，本文将理论第一个原理优化分析与实践中驱动的NFA文献统一起来，并提供了一个既可证明又在实践中适用于收敛的替代方案。", "conclusion": "本文的工作不仅提供了对神经网络特征学习过程更深入的理解，也基于基础原理为该领域提供了新的理论分析工具。这些理论不仅在连续情况下有效，还解释了NFA在大多数情况下的合理性，并适用于特征学习中的关键现象。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05265", "html_url": "https://arxiv.org/abs/2509.05265", "title": "在局部差分隐私下评估联邦学习抗中毒鲁棒性", "title_en": "On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy", "authors": "Zijian Wang,Wei Tong,Tingxuan Han,Haoyu Chen,Tianling Zhang,Yunlong Mao,Sheng Zhong", "background": "联邦学习（FL）结合本地差分隐私（LDP）允许在去中心化数据源上进行隐私保护的模型训练。然而，去中心化的数据管理范式使得LDPFL容易受到恶意参与者的影响。现有的LDPFL协议对于模型中毒攻击（MPA）的鲁棒性研究不足，即对手通过注入恶意更新来破坏全局模型收敛。本文分析了联邦学习和本地差分隐私背景下的抗中毒攻击robustness问题。", "innovation": "该文提出了针对LDPFL设置的新型且可扩展的模型中毒攻击框架，能够最大化全局训练损失的同时遵守局部隐私约束。为了应对Multi-Krum和修剪平均等鲁棒聚合机制，开发了适应性攻击，通过在反向训练过程中嵌入精心设计的约束来逃避这些防御。该研究在三种代表性LDPFL协议、三种基准数据集和两种类型的深度神经网络上进行了评估，还探讨了数据异质性和隐私预算对攻击效果的影响。研究结果表明，适应性攻击可以显著降低全球模型的性能，揭示了关键的漏洞，并强调了对抗MPA的更稳健LDPFL防御策略的必要性。", "conclusion": "本文的研究表明，适应性攻击能够显著降低全局模型的性能，揭示了LDPFL在抵抗MPA方面的重要漏洞，强调了需要更鲁棒的LDPFL防御策略来应对模型中毒攻击。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21001", "html_url": "https://arxiv.org/abs/2508.21001", "title": "一次训练，随时规划：基于扩散树的运动规划", "title_en": "Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees", "authors": "Yaniv Hassidof,Tom Jurgenson,Kiril Solovey", "background": "动力学运动规划关注的是在遵守机器人动力学约束的前提下，计算避免碰撞的轨迹。虽然基于采样方法的规划器能够提供全局完备性和解决方案质量的保证，但其常常因动作采样缺乏信息性而导致探索缓慢。虽然基于学习的方法可以显著提高运行速度，但它们在处理不同分布的情况时缺乏泛化能力，并且缺乏重要的保障，如安全性，限制了其在物理机器人的应用。", "innovation": "提出了基于扩散政策（DP）的扩散树（DiTree）框架，该框架利用DP作为指导状态空间搜索的知情采样器来提高SBPs的效率。该框架结合了DP建模复杂轨迹分布并基于局部观察的能力，以及SBPs的完备性，以在复杂动力学系统中提供在几轮行为传播迭代中可证明安全的解决方案。通过结合流行RRT规划器和基于单一环境训练的DP动作采样器进行具体实施。", "conclusion": "在对不同分布场景的综合评估中，DiTree相比单独使用的DP或SBP，平均成功率提高30%，尤其在动态汽车和Mujoco的蚂蚁机器人设置中。现实世界中的汽车实验进一步验证了DiTree的可行性，展示了即使在仿真到现实世界的差距很大时，其也具有卓越的轨迹质量和鲁棒性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00832", "html_url": "https://arxiv.org/abs/2509.00832", "title": "使用几何置换不变损失函数的晶态结构预测", "title_en": "Crystal Structure Prediction with a Geometric Permutation-Invariant Loss Function", "authors": "Emmanuel Jehanno,Romain Menegaux,Julien Mairal,Sergei Grudinin", "background": "晶态结构预测在材料设计中仍然是一个开放的挑战。尽管在计算材料科学方面取得了进步，但准确预测有机材料的三维晶态结构——这是设计具有目标性能材料的必要步骤——仍然难以实现。现有的最先进的模型通常依赖于计算成本高昂的迭代流匹配方法。", "innovation": "本工作提出了一种新颖的损失函数，正确捕捉关键的几何分子特性同时在集合 Σ 上保持置换不变性。通过基于Sinkhorn算法的可微线性分配方案实现了这一目标。我们证明，即使使用我们方法SinkFast进行简单的回归，也能显著优于更复杂的流匹配方法，特别是在COD-Cluster17基准数据集上，该数据集是晶体学开放数据库(COD)的精选子集。", "conclusion": "我们展示了一种新型损失函数的有效性，该函数能够捕捉关键的几何分子特性，同时保持置换不变性，并因此在晶态结构预测中取得了更好的性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01630", "html_url": "https://arxiv.org/abs/2509.01630", "title": "学习协调：通过可微ADMM-DDP进行分布式元轨迹优化", "title_en": "Learning to Coordinate: Distributed Meta-Trajectory Optimization Via Differentiable ADMM-DDP", "authors": "Bingheng Wang,Yichao Gao,Tianchen Sun,Lin Zhao", "background": "分布式轨迹优化通过ADMM-DDP是一种强大的协调多智能体系统的方法，但需要精细调整紧密耦合的超参数，这些超参数共同控制局部任务性能和全局协调。当前存在的挑战在于，这些超参数的调整需要大量的人工调优。", "innovation": "本文提出了一种名为L2C的学习协调框架，该框架通过轻量级的基于神经网络的代理智慧行为模型自动学习这些超参数，以适应不同的任务和智能体配置。该框架在ADMM-DDP管道中以分分布式方式端到端求导，并通过重用DDP组件（如Riccati递推和反馈增益）有效计算元梯度。通过这种梯度，它们对应于通过辅助的ADMM框架协调的整体矩阵LQR问题的最优解，在轻微的假设下该框架变得凸优化。", "conclusion": "在复杂的协同空中运输任务中，L2C不仅使用IsaacSIM生成了高保真度仿真中的动态可行轨迹，还合理配置了多旋翼飞行器队形以在狭小空间内进行安全的操作，并且能够适应变化的团队规模和任务条件，同时梯度计算比最先进的方法快88%。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19920", "html_url": "https://arxiv.org/abs/2410.19920", "title": "使用强化学习使大型语言模型代理适应交互环境：量化和缓解指令过拟合", "title_en": "Reinforcement Learning for Aligning Large Language Models Agents with Interactive Environments: Quantifying and Mitigating Prompt Overfitting", "authors": "Mohamed Salim Aissi,Clement Romac,Thomas Carta,Sylvain Lamprier,Pierre-Yves Oudeyer,Olivier Sigaud,Laure Soulier,Nicolas Thome", "background": "强化学习（RL）是将大型语言模型（LLM）的知识与序列决策任务对齐的有希望的方法。然而，对通过在特定环境中微调LLM代理从而增强其能力的影响研究仍然缺乏。本研究旨在分析在RL训练后，LLM对提示表述的敏感性。", "innovation": "提出了一种新的框架，通过分析LLM在文本环境中按照RL训练后的不同提示表述的表现，来研究LLM对提示表述的敏感性。通过检查模型的内部表示和显著标记来分析敏感性的来源。此外，提出了使用对比损失来缓解这种敏感性，从而提高LLM的鲁棒性和泛化能力。", "conclusion": "研究发现，当遇到与RL训练期间不同的提示表述时，LLM的表现会下降。通过对比损失的使用，LLM的鲁棒性和泛化能力得到了改进。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02072", "html_url": "https://arxiv.org/abs/2509.02072", "title": "ABEX-RAT: 结合抽象增强和对抗训练的工业事故报告分类", "title_en": "Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports", "authors": "Jian Chen,Jiabao Dou,Jinbao Tian,Yunqi Xu,Zhou Li", "background": "工业事故报告的自动分类是提高工作场所安全性和进行大规模风险分析的关键研究领域。然而，这些实际数据集中固有的类别不平衡问题往往会影响分析模型的性能，尤其是在处理罕见但严重的事件类型时，妨碍了可靠自动系统的开发。这项研究正是针对这一挑战展开的，通过提出一种结合生成数据增强和稳健对抗训练的新颖且高效的框架ABEX-RAT来解决这个问题。", "innovation": "作者提出了一种名为ABEX-RAT的框架，该框架结合了生成数据增强与对抗训练。具体而言，该框架首先通过抽象抽取管道利用大型语言模型提取核心事故语义，然后利用生成模型生成多样化的高质量合成样本以补充代表性不足的类别。接着使用一种可行的敌对训练协议（随机对抗训练RAT）在增强的数据集上轻量化地训练分类器，以提升模型的泛化能力和稳健性而不增加过多的计算开销。实验结果表明该方法在公共OSHA数据集上达到了新的最先进的性能水平，达到宏F1分数90.32%，明显优于之前的SOTA和微调大模型基线。这项工作的优势在于证明了这种协同策略是对抗冗余微调的高效替代方案，特别针对专业化、类不平衡分类任务。", "conclusion": "本研究提出的ABEX-RAT框架有效解决了工业事故报告分类领域中的类别不平衡问题，同时提供了一种高效的解决方案，优于现有技术。未来的研究可以进一步探索该方法在其他类不平衡场景中的应用。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02046", "html_url": "https://arxiv.org/abs/2509.02046", "title": "极为出色的预训练优化器及其发现之处", "title_en": "Fantastic Pretraining Optimizers and Where to Find Them", "authors": "Kaiyue Wen,David Hall,Tengyu Ma,Percy Liang", "background": "尽管有传言称其他优化器可以提供1.4到2倍的速度提升，AdamW 在语言模型预训练中一直是主导的优化器。然而，两个方法论上的缺陷导致了公平比较的缺失并且阻碍了这些优化器的实用应用：（i）超参数调优不一致；（ii）评价设置有限或误导性。因此，研究者认为在不同的模型规模和数据与模型比例下，通过严谨的超参数调优和全方位的评估，可以进行更加公平和有见地的比较和测试。", "innovation": "本研究系统性地评估了十个深度学习优化器在四种不同模型规模和数据与模型比例下的表现。不同的优化器在最优超参数设置下表现不同，某些优化器如Muon和Soap采用了矩阵作为预条件，将梯度与矩阵相乘而非逐元素标量相乘，这一点对于小规模模型速度提升显著（1.4倍），但在大规模模型下其优势减小到仅1.1倍。研究还发现，对比不同优化器的性能不宜在训练过程中选择性地使用中间检查点，因为随着学习率衰减，优化器之间的排名可能会发生变化。", "conclusion": "所有最快的优化器都展示了矩阵预条件的特性，但这种速度优势随模型规模的增大而减小。在进行有效的比较时，需要对不同模型规模和数据与模型比例进行全面的超参数调优和评估，最佳性能通常在训练接近结束时达到。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15862", "html_url": "https://arxiv.org/abs/2507.15862", "title": "量化综合评估：一种多模态的大学录取预测方法", "title_en": "Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction", "authors": "Jun-Wei Zeng,Jerry Shen", "background": "传统的综合评审方法存在透明度不足、一致性差和申请者焦虑等问题。本研究旨在通过多模态框架解决这些问题，引入了综合申请人概况评分（CAPS），这是一种新型的多模态模型，用于定量建模和解释全面的大学入学评估。", "innovation": "该研究提出了CAPS框架，它将申请人的资料分解成可解释的三个部分：学术表现（标准学术评分，SAS）、论文质量（论文质量指数，EQI）和课外活动参与度（课外影响评分，EIS）。CAPS利用基于变换器的语义嵌入、大语言模型评分和XGBoost回归，提供与人类判断一致的透明和可解释的评估。实验表明，CAPS在预测EQI、分类准确性、宏F1分数和加权F1分数方面表现出色。", "conclusion": "CAPS解决了传统综合评审的关键限制，如不透明性、不一致性以及申请者的焦虑，从而为更公正和基于数据的录取实践铺平了道路。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02281", "html_url": "https://arxiv.org/abs/2509.02281", "title": "平衡的多模态学习：单向动态交互视角", "title_en": "Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective", "authors": "Shijie Wang,Li Zhang,Xinyan Liang,Yuhua Qian,Shen Hu", "background": "多模态学习通常通过多模态联合损失来整合不同的模态并提升模型性能。然而，这种联合学习策略会导致模态不平衡问题，其中强大的模态会压倒较弱的模态，限制了每个模态内部信息和模态间交互信息的充分利用。现有的策略如动态损失加权、辅助目标和梯度调控，都是基于联合损失来减轻模态不平衡的，但这些方法仍然保持了联合损失的本质竞争性，只能检测并纠正已经出现的不平衡。", "innovation": "本文提出了一种名为单向动态交互（UDI）的新策略，它抛弃了传统的联合损失，转而采用主动的顺序训练方案。UDI 首先对锚定模态进行训练至收敛，然后通过无监督损失引导其他模态。此外，模态间交互的动态调整使模型能够适应当前任务，确保每个模态能够最优贡献。通过解耦模态优化并允许定向信息流，UDI 阻止了任何单一模态的主导并促进有效的跨模态特征学习。", "conclusion": "我们的实验结果表明，UDI 在处理模态不平衡方面优于现有方法，从而在多模态学习任务中提高了性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.03325", "html_url": "https://arxiv.org/abs/2312.03325", "title": "FAGC:在预形状空间的测地线曲线上的特征增强", "title_en": "FAGC:Feature Augmentation on Geodesic Curve in the Pre-Shape Space", "authors": "Yuexing Han,Gan Hu,Guanxin Wan,Bing Wang", "background": "由于训练数据量限制了模型性能，数据增强已成为深度学习中不可或缺的技术。然而，大多数现有数据增强方法存在信息丢失的问题，并且在小样本情景下效果不佳，这限制了它们的应用。", "innovation": "提出了一种在预形状空间中的测地线曲线上的特征增强方法，称为FAGC（Feature Augmentation on Geodesic Curve）。该方法首先使用预训练的神经网络从输入图像中提取特征，然后将图像特征向量投影到预形状空间中去除位置和缩放信息，接着在该空间中构建最符合特征向量的测地线曲线，最后通过在构造的测地线曲线上插值生成新的特征向量以供模型学习。", "conclusion": "通过广泛的实验验证了FAGC的有效性和适用性，结果表明将FAGC应用于深度学习或机器学习方法可以显著改善其在小样本任务中的性能。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-XGPT：电子健康记录的可扩展多任务基础模型", "title_en": "CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供了丰富的、纵向的患者健康视图，对于临床决策支持、风险预测和数据驱动的医疗研究具有重大潜力。然而，目前用于EHR的人工智能模型大多数是为单一特定任务设计的，这限制了它们在实际应用中的通用性和实用性。", "innovation": "CEHR-XGPT是一种通用的基础模型，能够统一处理特征表示、零样本预测和合成数据生成三大核心能力，采用了一种新的基于时间标记的学习框架，能够显式地将患者的动态时间线融入模型结构中。CEHR-XGPT在所有三个任务上表现出色，并通过词汇扩展和微调有效泛化到外部数据集。其灵活性允许快速模型开发、病人群体发现和患者结果预测，而无需特定任务的重新训练。", "conclusion": "CEHR-XGPT展示了在所有三个任务上优秀的性能，并能够在外部数据集上进行有效的泛化。其通用性使得可以快速开发模型、发现病人群体和预测患者结果，而无需针对具体任务进行重新训练。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.14295", "html_url": "https://arxiv.org/abs/2401.14295", "title": "揭示思考链、思维树和思维图的奥秘", "title_en": "Demystifying Chains, Trees, and Graphs of Thoughts", "authors": "Maciej Besta,Florim Memedi,Zhenyu Zhang,Robert Gerstenberger,Guangyuan Piao,Nils Blach,Piotr Nyczyk,Marcin Copik,Grzegorz Kwaśniewski,Jürgen Müller,Lukas Gianinazzi,Ales Kubicek,Hubert Niewiadomski,Aidan O'Mahony,Onur Mutlu,Torsten Hoefler", "background": "近年来，自然语言处理（NLP）领域取得了显著进展，特别是在通过创新的提示技术改进大型语言模型（LLM）性能方面。其中，结合结构的提示工程已展现出前景，设计如思考链、思维树或思维图等，通过图等形式引导LLM的整体推理。这些方法显著提高了LLM解决各种任务的能力，包括逻辑、数学推理、计划或创造性写作等。为了更好地理解这一领域并为未来的发展铺平道路，本文提出了一个通用的框架来指导有效的LLM推理方案。通过深入分析提示执行管道，明确了不同的概念，并构建了第一个结构增强的LLM推理方案的分类学。", "innovation": "本文通过提出一个分类学来区分不同的结构增强的LLM推理方案，并对其结构进行分析，从而揭示了不同的设计选择是如何影响性能和成本的。此外，还讨论了提示与LLM生态系统中其他部分之间的关系，如知识库，并提出了相关研究挑战。这方面的工作将有助于推进未来的提示工程技术。", "conclusion": "本文帮助理解了增长中的LLM推理领域，并通过提出的分类学比较现有的提示方案，讨论了特定设计选择如何导致不同的性能和成本模式。最终，本文的成果将有助于未来在LLM推理方面进行深入的研究。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.16019", "html_url": "https://arxiv.org/abs/2312.16019", "title": "生存分析中的对抗正则化", "title_en": "Survival Analysis with Adversarial Regularization", "authors": "Michael Potter,Stefano Maxenti,Michael Everett", "background": "生存分析（SA）模型用于预测事件发生的时间，在医学、国防、金融和航空航天等领域有广泛应用。近期研究显示，神经网络（NN）能够有效捕捉SA中的复杂数据模式，而简单的广义线性模型在这方面往往表现不佳。然而，数据集中的不确定性（如噪声测量和人为错误）会降低NN模型的性能。现有的方法难以应对这些问题，因此需要一种新的方法来提升模型的鲁棒性和准确性，特别是针对生存分析模型的优化方法。", "innovation": "研究通过结合NN验证的最新进展，提出了一种基于对抗正则化的训练目标，以构建鲁棒的生存分析模型。具体方法是提出一种基于Min-Max优化问题的对抗鲁棒损失函数，并使用CROWN-区间传播（CROWN-IBP）来解决这种优化问题的计算挑战。该方法在10个SurvSet数据集上的测试表明，对于负对数似然、集成比尔兹评分和一致性指数等指标，该方法的性能始终优于基线的对抗训练方法和当前最先进的深度生存分析模型，特别是在多种协变量扰动下的表现。", "conclusion": "研究证明，对抗鲁棒性可以提高生存分析的预测性能和校准性，通过提升数据不确性的缓解和泛化的多样化数据集上的表现最多提高了150%。这项工作表明，对抗正则化对于改进生存分析模型的性能和鲁棒性具有重要意义，并为相关领域的研究提供了新的视角和方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.08674", "html_url": "https://arxiv.org/abs/2402.08674", "title": "人类和神经网络中上下文内学习和权重内学习之间的动态交互", "title_en": "The dynamic interplay between in-context and in-weight learning in humans and neural networks", "authors": "Jacob Russin,Ellie Pavlick,Michael J. Frank", "background": "人类学习表现出显著的二元性：有时我们能够遵循逻辑和组合规则，并从结构化的课程中受益，而在其他时候则依赖于增量方法或试错学习，从中学习到随机交织的课程。影响力较大的心理学理论通过假设两种不同的学习系统来解释这种看似不同的行为证据——一种用于快速的规则推理，另一种用于缓慢的增量适应。然而，神经网络通过增量权重更新进行学习，因此更适合进行后者的学习方式，但并不明显符合前者。最近的证据表明，元学习神经网络和大型语言模型具备“上下文内学习”（ICL）的能力——能够从少量示例中灵活抓住新的任务结构。本文通过分析这种动态交互，发现在人类和神经网络中，ICL与默认权重内学习（IWL）之间的动态交互自然地解释了广泛的人类学习现象，如类别学习和组合任务的课程效应，再现了灵活性与保持之间的权衡。", "innovation": "研究表明，上下文内学习（ICL）和权重内学习（IWL）之间的动态交互能够准确地模拟广泛的人类学习现象，包括类别学习和组合任务中的课程效应，并且揭示了灵活性与保持之间的权衡。这一研究为神经网络提供了不同的学习特性，使其能够与原有的IWL共存，从而提供了一种关于双重过程理论和人类认知灵活性的新视角。", "conclusion": "研究展示了通过ICL在神经网络中引入新的学习特性可以使其具备与原有的IWL共存的不同学习属性，为理解人类认知的双重过程理论提供了新的视角，并再现了学习中的灵活性与保持的权衡关系。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.07864", "html_url": "https://arxiv.org/abs/2404.07864", "title": "通过近似消息传递推断高维回归中的变化点", "title_en": "Inferring Change Points in High-Dimensional Regression via Approximate Message Passing", "authors": "Gabriel Arpino,Xiaoqi Liu,Julia Gontarek,Ramji Venkataramanan", "background": "本文考虑了一般线性模型(GLM)中局部化变化点的问题，该模型涵盖了统计学习中许多广泛研究的问题，包括线性、逻辑和修正线性回归。", "innovation": "提出了一种新颖且计算高效的近似消息传递(AMP)算法，用于同时估计信号和变化点位置，并在高维情况下，参数数量 p 与样本数量 n 成比例的情况下，严格地表征其性能。该表征用状态演化递归表示，这允许我们精确计算诸如变化点估计的渐近Hausdorff误差等性能度量，并让我们能够根据任何先验的信号和变化点结构信息来定制算法。", "conclusion": "通过数值实验验证了我们的理论，并在线性、逻辑和修正线性回归设置中演示了我们的估计器在合成和真实数据上的优越性能。此外，展示了如何使用我们AMP迭代高效计算变化点位置的贝叶斯后验分布。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22451", "html_url": "https://arxiv.org/abs/2503.22451", "title": "STADE: 标准差作为剪枝度量", "title_en": "STADE: Standard Deviation as a Pruning Metric", "authors": "Diego Coello de Portugal Mecke,Haya Alyoussef,Maximilian Stubbemann,Ilia Koloiarov,Tom Hanika,Lars Schmidt-Thieme", "background": "近年来，大规模语言模型（LLMs）变得非常流行，并被用于解决各种任务。为了成功处理这些任务，LLMs需要更长的训练时间和更大的模型规模。这使得LLMs成为剪枝方法的理想对象，这些方法可以在减少计算需求的同时保持性能。目前的剪枝方法通常在剪枝后需要重新训练以保持原始模型的性能。然而，最先进的剪枝方法（如Wanda）可以在不重新训练的情况下剪枝模型，从而加快剪枝过程并提高其效率。Wanda的成功引发了对该方法有效性的理论解释的需求，并利用这些见解进一步优化剪枝过程。", "innovation": "该研究对剪枝问题进行了理论分析，揭示了一个常见的机器学习场景，其中Wanda是最佳的剪枝方法。并且，当Wanda不再是最佳方法时，研究人员开发了一种新的方法——STADE，基于输入的标准差。从理论角度看，STADE在不同场景中的适用性更好。最后，通过对Llama和Open Pre-trained Transformers（OPT）模型的广泛实验验证了这些理论发现，证明了在不同的训练条件下，Wanda的最佳性能与理论框架预测的一致。", "conclusion": "这些洞察为剪枝策略及其实际应用提供了一个更全面的理解。研究结果证实了STADE的有效性，并进一步推动了剪枝方法的发展。实验代码可在此处获取：this https URL"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.12226", "html_url": "https://arxiv.org/abs/2402.12226", "title": "AnyGPT: 统一的端到端多模态语言模型与离散序列建模", "title_en": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "authors": "Jun Zhan,Junqi Dai,Jiasheng Ye,Yunhua Zhou,Dong Zhang,Zhigeng Liu,Xin Zhang,Ruibin Yuan,Ge Zhang,Linyang Li,Hang Yan,Jie Fu,Tao Gui,Tianxiang Sun,Yugang Jiang,Xipeng Qiu", "background": "当前的大型语言模型（LLM）虽然在文本处理方面表现出色，但在处理多种模态信息（如语音、文本、图像和音乐）时仍面临挑战。论文引入了AnyGPT，这是一个统一处理多模态信息的语言模型，利用离散表示将不同模态的信息整合在一起，使得模型能够在多模式上下文中进行统一处理并实现稳定的训练。", "innovation": "1. AnyGPT是一种无需修改现有LLM架构和训练范式的统一多模态处理模型，仅依赖于数据层面的预处理。\n2. 提供了一个多模态文本为中心的数据集，用于多模态对齐预训练。\n3. 使用生成模型合成了第一个大规模的端到端多模态指令数据集，包含108,000个具有复杂多模态交织的多轮对话样本，以提升模型的多模态输入和输出处理能力。\n4. 实验结果显示，AnyGPT在所有模态性能上与专业模型相当，证明了离散表示可以方便且有效地将多种模态统一整合到语言模型中。", "conclusion": "AnyGPT通过使用离散表示，在统一处理多模态信息时实现了稳定训练和高效率，展示了其在处理多种模态信息方面的潜力，有助于推进多模态语言模型的发展。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.02618", "html_url": "https://arxiv.org/abs/2504.02618", "title": "Variational Online Mirror Descent for Robust Learning in Schrödinger Bridge", "title_en": "Variational Online Mirror Descent for Robust Learning in Schrödinger Bridge", "authors": "Dong-Sig Han,Jaein Kim,Hee Bin Yoo,Byoung-Tak Zhang", "background": "自旋格桥（SB）已经发展成为一类通用的概率生成模型。然而，实际应用中估计的学习信号本身具有不确定性，现有方法的可靠性通常依赖于推测性的最优案例。最近关于通过镜面下降（MD）的辛克霍尔姆算法（Sinkhorn algorithm）的研究引起了关注，它们揭示了SB问题解获取的几何洞察。", "innovation": "本文提出了一个变分在线镜面下降（OMD）框架用于处理SB问题，为SB解算器提供了进一步的稳定性。通过Wasserstein-Fisher-Rao几何对Schrödinger势能下的正态混合参数化利用，设计了一种仿真自由的SB算法——变分镜面自旋格桥（VMSB）。基于Wasserstein梯度流理论，该算法提供了可追踪的学习动态，能精确地逼近每个OMD步骤。", "conclusion": "实验中，我们验证了所提出的VMSB算法在广泛基准测试中的性能。VMSB在一系列SB问题上表现出了比现有SB解算器更稳健和通用的结果，这与我们的OMD理论预测一致。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.18416", "html_url": "https://arxiv.org/abs/2407.18416", "title": "PersonaGym：评估Persona代理和LLM", "title_en": "PersonaGym: Evaluating Persona Agents and LLMs", "authors": "Vinay Samuel,Henry Peng Zou,Yue Zhou,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Ameet Deshpande,Karthik Narasimhan,Vishvak Murahari", "background": "Persona代理是根据指定的人物设定来行动的LLM代理，能够在教育和医疗等不同领域提供上下文丰富且用户对齐的交互。然而，评估这些代理是否忠实地遵循其人物设定，在要求在多种多样的、与人物相关的环境中保持一致性的自由形式设置中仍面临重大挑战。PersonaGym是首个动态评估框架，用于评估人物代理的表现，并通过基于决策理论的人类对齐自动度量 PersonaScore，实现大规模的综合评估。该研究评估了10个领先的LLM模型在200个不同人物设定和1万个问题中的表现，揭示了显著的进步空间，例如，GPT-4.1在 PersonaScore 上与较旧且开源的 LLaMA-3-8b 的表现相同，强调了算法和架构创新在构建忠实且高性能的人物代理中的重要性。", "innovation": "PersonaGym是一个新的动态评估框架，可用于评估人物代理的表现，并通过基于决策理论的人类对齐自动度量 PersonaScore，实现大规模的综合评估。PersonaScore 能够揭示不同模型在人物设定保持一致性方面的表现差异，帮助识别改进的机会并推动在算法和架构方面的创新。", "conclusion": "研究发现，尽管模型规模和复杂性增加，但一些较旧的模型在 PersonaScore 上表现与更先进的模型相同，这强调了在设计忠实且高性能的人物代理时算法和架构创新的重要性。此外，评估结果显示了显著的进步空间，强调需要继续改进以更好地实现人物设定的忠实地保持。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15164", "html_url": "https://arxiv.org/abs/2405.15164", "title": "从弗雷格到ChatGPT：语言、认知与深度神经网络中的组合性", "title_en": "From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks", "authors": "Jacob Russin,Sam Whitman McGrath,Danielle J. Williams", "background": "组合性一直被认为是人类智能的关键解释属性，允许从有限的学习经验中获得无限表达能力。有影响力的观点认为，神经网络无法解释这方面的行为，导致许多人认为它们不是人类认知的可行模型。然而，在过去十年里，现代深度神经网络（DNNs）在人工智能中占据了主导地位，展示了机器中前所未见的认知行为。尤其是大型语言模型（LLMs），已被证明能够从事复杂句法结构的写作、逻辑推理等行为，这些被认为是需要组合性处理的。", "innovation": "本文回顾了最近机器学习领域的实证工作，关注赋予神经网络组合泛化能力的两种方法：（1）架构性诱导偏置，（2）元学习，或学习如何学习。此外，表明LLMs的预训练可以从元学习的角度理解，以此方式为DNNs提供组合泛化的能力。这些发现对人类认知中组合性的研究具有重要意义，并为未来的研究指出了路径。", "conclusion": "这些发现可能对人类认知中组合性的研究产生影响，我们可以进一步探讨这些发现对未来研究的可能影响。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05748", "html_url": "https://arxiv.org/abs/2408.05748", "title": "低维度联邦知识图嵌入的知识蒸馏方法", "title_en": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation", "authors": "Xiaoxiong Zhang,Zhiwei Zeng,Xin Zhou,Zhiqi Shen", "background": "FKGE意在促进多个客户端分布式的知识图谱（KGs）中的实体和关系嵌入的协作学习，同时保持数据隐私。高维嵌入虽然可能提高性能，但也会带来存储资源和推理速度的问题。与传统的嵌入压缩方法不同，FKGE涉及多轮客户端服务器间的通信，因此提高通信效率更加关键。", "innovation": "提出了一种基于知识蒸馏（KD）的轻量级组件FedKD，适用于FKGE方法。FedKD在本地训练时通过KL散度损失使低维学生模型模仿高维教师模型的三元组得分分布。同时，FedKD通过定义温度可自适应地调整正样本和负样本的得分，解决了教师过自信的问题。此外，FedKD动态调整KD损失的权重以优化训练过程。", "conclusion": "实验证明FedKD在三个数据集上有效。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.04996", "html_url": "https://arxiv.org/abs/2410.04996", "title": "使用替代控制结果的假设宽松集成后推断", "title_en": "Assumption-Lean Post-Integrated Inference with Surrogate Control Outcomes", "authors": "Jin-Hong Du,Kathryn Roeder,Larry Wasserman", "background": "数据集成方法旨在从高维结果中提取低维嵌入，以消除跨异质数据集的批次效应和未测量的协变量等不必要的变异。然而，在集成后的多重假设检验可能会由于数据依赖的过程而产生偏差。该研究介绍了利用控制结果进行稳健的集成后推断（PII）方法，以调整潜在异质性。", "innovation": "该研究通过使用因果解释，利用负控制结果推导出非参数可识别的直接效应。通过利用替代控制结果作为负控制结果的扩展，开发了关于投影直接效应估量的半参数推断方法，考虑了隐藏的中介、混杂因素和调节因素。这些估量方法在模型误设和嵌入不准确的情况下依然具有统计意义。研究者提供了偏差量化和有限样本线性扩展的统一集中边界的分析，并且提出的双重稳健估计器在最小假设和潜在误设下是一致且高效的，便于使用机器学习算法进行数据自适应估计。", "conclusion": "提案的方法通过随机森林在模拟和分析单细胞CRISPR干扰数据集中进行了评估，展示了其在潜在未测量混杂因素情况下的应用价值。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.23903", "html_url": "https://arxiv.org/abs/2410.23903", "title": "PyRAT在神经网络验证中的应用", "title_en": "Neural Network Verification with PyRAT", "authors": "Augustin Lemesle,Julien Lehmann,Tristan Le Gall", "background": "随着人工智能系统在医疗、交通、能源等关键领域越来越普及和广泛应用，确保其安全性和可靠性变得尤为重要。为了提供这种保证并建立用户对其安全的信任，本文介绍了一个名为PyRAT的工具，该工具基于抽象解释来验证神经网络的安全性和鲁棒性。", "innovation": "PyRAT使用不同的抽象来找到从神经网络输入到可到达状态的过程，这一方法能够快速准确地分析神经网络。该工具已经参与到多个合作项目中以确保安全性和鲁棒性，并且在2024年的VNN-Comp竞赛中取得了第二名的好成绩，展示了其优越的性能。", "conclusion": "PyRAT能够为神经网络的安全性和鲁棒性验证提供强有力的支持，该工具的有效性已经在多个实际应用中得到验证。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "虽然大型语言模型（LLMs）展示了令人印象深刻的能力，但它们在各种应用场景中的输出质量仍不一致，这使得难以识别可靠的回应，尤其是在需要多步推理的复杂任务中。因此，论文提出了一种用于推理的分词级不确定性评估框架（TokUR），以使LLMs能够自我评估和改进其生成质量。", "innovation": "引入了低秩随机权重扰动到LLM解码过程中，生成预测分布，用于估计分词级不确定性。这些不确定性被聚合以反映生成序列的语义不确定性。实验证明，我们的分词级不确定性指标强烈与答案正确性和模型鲁棒性相关。此外，通过多次推理和粒子滤波算法，探索直接利用不确定性来提升模型的推理性能。", "conclusion": "我们的方法在所有现有的不确定性评估方法中表现出色，证明了有效估计不确定性作为评估和改进LLMs推理生成的有价值的工具。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.11686", "html_url": "https://arxiv.org/abs/2409.11686", "title": "通过机会性成像自动化检测未诊断的医疗状况", "title_en": "Automated detection of underdiagnosed medical conditions via opportunistic imaging", "authors": "Asad Aali,Andrew Johnston,Louis Blankemeier,Dave Van Veen,Laura T Derry,David Svec,Jason Hom,Robert D. Boutin,Akshay S. Chaudhari", "background": "腹部计算机断层扫描（CT）在临床环境中经常被使用。机会性CT是指重新利用常规CT图像来提取诊断信息，这一技术正在被用于检测如肌少症、肝脂肪变性和腹水等未诊断的条件。这项研究利用深度学习方法来促进准确的诊断和记录。研究人员分析了2,674份住院患者的CT扫描，以识别决定性CT扫描影像表型与其放射科报告和ICD编码之间的差异。研究发现，通过机会性成像或放射科报告诊断为肌少症、肝脂肪变性和腹水的CT扫描中，只有0.5%、3.2%和30.7%的影像被ICD编码。这些结果表明机会性CT有潜力提高诊断精度并提升风险调整模型的准确性，为精准医疗提供进步.", "innovation": "本研究利用深度学习方法促进准确诊断及临床记录，分析大量住院患者的CT扫描，以识别机会性CT影像表型与放射科报告和ICD编码之间的差异，发现通过机会性成像或放射科报告诊断主要病症的CT扫描被ICD编码的比例偏低，进而提出利用机会性CT技术可以提升诊断准确性，增强风险调整模型的精度，促进精准医疗的发展.", "conclusion": "研究结果表明，机会性CT能显著提高诊断精度，有助于提升风险调整模型的准确性，为精准医疗提供革新。但目前机会性CT诊断信息未被充分ICD编码，提高了临床及研究中的信息不一致，这些都为未来工作提供了改进方向."}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.13207", "html_url": "https://arxiv.org/abs/2411.13207", "title": "大型语言模型的信息安全意识", "title_en": "The Information Security Awareness of Large Language Models", "authors": "Ofir Cohen,Gil Ari Agmon,Asaf Shabtai,Rami Puzis", "background": "大型语言模型（LLMs）的受欢迎程度持续增长，LLM 基础助手现在十分普遍。然而，大型语言模型的信息安全意识（ISA）——一种重要的但尚未广泛探索的安全方面——仍然被忽视。ISA 包括语言模型的安全知识（这些知识虽被部分研究过）以及态度和行为，后者对于语言模型理解隐含的安全背景并拒绝那些可能导致语言模型无法满足用户需求的危险请求非常重要。", "innovation": "本文提出了一个自动化的ISA度量方法，用于评估LLMs的信息安全意识。该方法涵盖了移动ISA分类中的所有30个安全主题，并通过创造隐含安全影响与用户满意度之间的张力的实用场景来实现。这种方法应用于流行的LLMs后，发现大部分流行模型仅表现出中等至较低的信息安全意识水平，暴露其用户于网络威胁中。小型变体的风险更大，而较新版本没有一致的ISA改善趋势，暗示提供商并没有主动寻求缓解这一问题。", "conclusion": "我们的研究表明，当前LLM部署中普遍存在一个广泛的安全漏洞：大多数热门模型，尤其是它们的小型变体，可能会系统地威胁用户。为此，我们建议一种实用的缓解方案：将我们的安全意识指令整合进模型系统提示中，帮助LLMs更好地检测和拒绝危险请求。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02780", "html_url": "https://arxiv.org/abs/2503.02780", "title": "基于自主网络防御的定量抗袭模型", "title_en": "Quantitative Resilience Modeling for Autonomous Cyber Defense", "authors": "Xavier Cadet,Simona Boboila,Edward Koh,Peter Chin,Alina Oprea", "background": "网络安全系统在遭受攻击后恢复的能力被称为韧性。然而，对于不同类型网络架构和攻击模式，目前没有统一的韧性定义来量化这一特性。本文研究了如何在没有正式定义的情况下，通过既考虑防御者操作目标，又考虑网络资源的重要性来量化网络韧性。此外，研究还分析了在不同网络拓扑和时间变量攻击模式下，韧性、成本和防御目标优先级之间的权衡，并提出了一种评估方法，以全面刻画系统韧性。", "innovation": "本文提出了一个可量化的韧性模型，旨在通过考虑替代的防御者操作目标、网络资源的重要性和供安全操作员理解的可解释性，来增强网络韧性。研究引入了聚合不同网络架构和时间变量攻击模式下韧性度量的方法，并使用自主网络防御环境CybORG进行评估，通过与启发式基线进行比较，展示了网络硬化的主动技术及被入侵主机快速恢复对有效网络安全防御的重要性能。", "conclusion": "本文通过量化分析网络韧性，提出了一个综合性的网络安全防御框架。研究发现，网络韧性可以通过优化网络硬化的操作和及时恢复受损节点来实现。通过引入该模型和算法，可以更有效地设计和部署自主的网络防御系统，以应对不断变化的攻击威胁。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.13518", "html_url": "https://arxiv.org/abs/2408.13518", "title": "基于直接偏好优化的令牌级奖励函数估计算法的有选择的偏好优化", "title_en": "Selective Preference Optimization via Token-Level Reward Function Estimation", "authors": "Kailai Yang,Zhiwei Liu,Qianqian Xie,Jimin Huang,Erxue Min,Sophia Ananiadou", "background": "近年来，大规模语言模型对齐的发展依赖于令牌级监督来进行细粒度的偏好优化。然而，现有方法要么优化所有可用令牌，这可能会导致错误和效率低下，要么使用复杂且代价高昂的关键令牌选择策略进行有选择的训练。本研究旨在解决这些挑战，提出了一种新的有选择对齐策略Selective Preference Optimization (SePO)，并首次使用一种基于直接偏好优化（DPO）的令牌选择方法，通过训练一个参照模型来估计目标数据上的令牌级奖励函数。这种方法适用于具有响应级注解的任何现有的对齐数据集，能够使用小规模的参照模型和训练数据实现成本效益的令牌选择。随后，利用估计的奖励函数对目标数据集进行打分，并仅选择关键令牌监督目标策略模型，以此减少优化过程中的过度优化问题，并展示了SePO在弱到强泛化能力上的显著优势。", "innovation": "提出了Selective Preference Optimization (SePO)，这是一种基于直接偏好优化（DPO）的有选择的令牌选择方法。该方法通过训练一个参照模型来估计目标数据上的令牌级奖励函数，并用于评估所有令牌，仅选择关键令牌来监督策略模型。SePO能够高效地对目标数据集进行优化，仅选择30%的关键令牌，并在多个公开基准测试上优于其他竞争基线方法。此外，SePO还展示了解决域外数据选择与增强策略模型的有效性，并减轻了过度优化问题。", "conclusion": "SePO方法在多个公开基准测试中表现出色，仅优化目标数据集30%的关键令牌即能显著提升模型性能。这种方法不仅适用于标准的数据集，还能从域外数据中选择关键令牌，提升策略模型的效果。此外，弱参照模型可以有效监督参数量较大的策略模型，展示了SePO方法在多种场景中的广泛应用潜力。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09061", "html_url": "https://arxiv.org/abs/2502.09061", "title": "CRANE：约束生成的逻辑推理", "title_en": "CRANE: Reasoning with constrained LLM generation", "authors": "Debangshu Banerjee,Tarun Suresh,Shubham Ugare,Sasa Misailovic,Gagandeep Singh", "background": "代码生成、符号数学推理及其他任务需要大型语言模型（LLMs）生成既符合语法也符合语义的输出。以往的研究表明，严格约束LLM生成输出以遵守形式化语法规则虽然可以增强形式上的正确性，但往往会削弱模型的推理能力。因此，本研究首先理论分析了为什么限制LLM生成非常严格的语法输出（仅允许最终答案的语法正确性）会削弱模型的推理能力。其次，研究展示了通过添加精心设计的额外规则来扩展输出的语法规则，可以在保持模型推理能力的同时保证输出的语义和语法正确性。基于这些理论洞察，研究人员提出了一个增强推理的约束解码算法CRANE，该算法能够在限定生成的正确性和非限定生成的灵活性之间取得良好的平衡。实验结果显示，CRANE显著优于现有的最先进约束解码策略和标准无约束解码，在复杂的符号推理基准测试中GSM-symbolic和FOLIO上，CRANE的准确率提高了10个百分点以上。", "innovation": "提出了一种增强推理的约束解码算法CRANE，该算法在保持模型推理能力的同时保证输出的语义和语法正确性，显著优于现有的最先进约束解码策略和标准无约束解码，在复杂的符号推理基准测试中GSM-symbolic和FOLIO上，CRANE的准确率提高了10个百分点以上。", "conclusion": "研究表明，通过扩展输出的语法规则并实现限制生成的正确性和非限制生成的灵活性之间的平衡，不仅能够保持LLM的推理能力，还能够显著提高模型生成输出的准确性和可靠性。CRANE算法为解决现有约束生成策略对模型推理能力削弱的难题提供了一种有效的新方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03727", "html_url": "https://arxiv.org/abs/2504.03727", "title": "基于图变换器的洪水易损性制图：应对气候变化在法国有色拉维亚及铁路基础设施的应用", "title_en": "Graph Transformer-Based Flood Susceptibility Mapping: Application to the French Riviera and Railway Infrastructure Under Climate Change", "authors": "Sreenath Vemula,Filippo Gatti,Pierre Jehel", "background": "由于气候变化导致的洪水频率和严重性增加，威胁到了基础设施，需要改进易损性评估技术。传统机器学习方法虽广泛应用，但难以捕捉空间依赖关系及解决不同易损性类别边界的不清晰问题。", "innovation": "首次将图变换器（Graph Transformer, GT）架构应用于法国里维埃拉的洪水易损性制图，利用地形、水文、地理和环境数据。图变换器通过拉普拉斯位置编码和注意力机制整合了流域结构，展示了在聚类和边界划分上的优势，尤其是在马氏距离测度方面。", "conclusion": "根据气候变化的不同代表浓度路径（RCPs）情景，到2050年洪水风险将增加，特别是在RCP 8.5情景下，有17.46%的流域面积和54%的铁路长度处于非常高易损性区域。所开发的图变换器模型能够集成到多灾种框架中进行风险评估。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08216", "html_url": "https://arxiv.org/abs/2504.08216", "title": "随机图中基于地标节点表示的最短路径距离近似", "title_en": "Landmark-Based Node Representations for Shortest Path Distance Approximations in Random Graphs", "authors": "My Le,Luana Ruiz,Souvik Dhara", "background": "在图机器学习中，学习节点表示是一个基本问题。现有的嵌入方法能够有效地保留局部相似性度量，但在捕捉全局功能如图距离方面表现不佳。受布隆巴格关于度量空间希尔伯特空间嵌入的经典工作启发，本文研究了局部距离保持节点嵌入的表现。这些嵌入通过从一小部分参考节点（称为地标）计算最短路径来近似节点之间的距离对。研究表明，随机图（如Erdos-Renyi随机图）在基于地标的方法中所需的维度较低，相比于最坏情况下的图。实验结果显示，基于图神经网络（GNN）的地标到节点距离的近似值在更大规模的实际网络上扩展表现良好，为图表示学习提供了一种可扩展且可迁移的替代方案。", "innovation": "本文的主要理论贡献在于证明了随机图在基于地标的方法中所需要的维度较低，相比于最坏情况下的图。同时，实验展示了基于图神经网络的地标节点表示方法在大型实际网络中的出色表现，提供了一种可扩展且可迁移的图表示学习替代方案。", "conclusion": "基于地标节点表示的方法能够有效近似最短路径距离，特别是在随机图中所需维度较低。基于图神经网络的近似在实际网络中表现出色，为图学习提供了新的可扩展和可迁移的方法。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13651", "html_url": "https://arxiv.org/abs/2505.13651", "title": "联邦学习中可追踪的黑盒水印", "title_en": "Traceable Black-box Watermarks for Federated Learning", "authors": "Jiahao Xu,Rui Hu,Olivera Kotevska,Zikai Zhang", "background": "联邦学习（FL）系统由于其分布特性，每个本地客户端都可以访问全局模型，这给模型泄露带来重大风险。现有文献中，在本地模型中注入水印以实现知识产权保护的方法主要有两种：非追踪水印和可追踪但白盒水印。然而，文献尚缺乏对于可追踪的黑盒水印的正式定义以及如何将其注入联邦学习系统的方法。因此，本文首先定义了注入可追踪的黑盒水印的问题，并提出了一种名为TraMark的全新的服务器端水印方法，用于在黑盒环境中验证模型泄露。TraMark通过将模型参数空间划分为两个不同的区域来实现这一目标：主要任务区域和水印区域。之后，它为每个客户端构建一个仅包含主要任务区域的个性化全局模型，同时保留水印区域，每个模型都在水印区域内使用不同的水印数据集学习一个唯一的水印供本地客户端使用。实验结果表明，TraMark能确保所有水印模型的可追踪性，同时保持其主要任务性能的完整性。", "innovation": "- 定义了可追踪的黑盒水印的正式概念\n- 提出并实现了TraMark方法，一种用于联邦学习系统的新颖的服务器端水印生成方法\n- 在黑盒设置下，TraMark能够验证模型泄露，同时不影响模型的主要任务性能", "conclusion": "本文通过定义并实现TraMark方法，解决了在联邦学习系统中注入可追踪的黑盒水印的问题，该方法能够在不损害模型主要任务性能的情况下验证模型泄露，对于保护知识产权具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13655", "html_url": "https://arxiv.org/abs/2505.13655", "title": "在具有客户端层级异质差分隐私的联邦学习中优化客户端抽样", "title_en": "Optimal Client Sampling in Federated Learning with Client-Level Heterogeneous Differential Privacy", "authors": "Jiahao Xu,Rui Hu,Olivera Kotevska", "background": "联邦学习结合客户端级差分隐私（DP）为在保护客户端隐私的同时协同训练模型提供了一个有前景的框架。然而，经典的如DP-FedAvg的方法在面对客户端有不同隐私需求时遇到困难，因为它们必须为所有客户端强制执行最严格的一致的隐私级别，导致过度的DP噪声，从而显著降低模型的实用价值。现有的在混合隐私环境中提升模型实用价值的方法大多依赖于可信服务器，且主要是启发式的，因此效果和理论支持都不足。", "innovation": "本研究在诚实但好奇的行为模式下提供了一种实用的攻击模型。我们提出了GDPFed，基于这个模型，我们根据客户端的隐私预算进行分组，并实现了客户端级别的DP以减少隐私预算浪费，从而提升模型的实用性。此外，我们提出了GDPFed$^+$，它融合了模型稀疏化以消除不必要的噪声，并优化每组客户端的抽样比率以最小化收敛错误。通过多个基准数据集的广泛实验表明，GDPFed$^+$相较于最先进的方法取得了显著的性能提升。", "conclusion": "我们的研究通过GDPFed及其增强版本GDPFed$^+$，在客户端层级异质差分隐私下解决了联邦学习中的隐私预算浪费问题，从而显著提高了模型的实用性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01807", "html_url": "https://arxiv.org/abs/2504.01807", "title": "未知状态和多项式动力学系统的贝叶斯推理下障碍证书", "title_en": "Barrier Certificates for Unknown Systems with Latent States and Polynomial Dynamics using Bayesian Inference", "authors": "Robert Lefringhausen,Sami Leon Noel Aziz Hanna,Elias August,Sandra Hirche", "background": "在动力学系统中确保安全性至关重要，但现有的障碍证书方法通常要求明示的系统模型。当动力学未知时，可以利用数据驱动的方法，但获得有效的证书需要严谨的不确定性量化。现有方法通常依赖于全状态测量，这限制了它们的应用范围。", "innovation": "提出了一种针对未知系统和潜在状态下的多项式动力学的新方法，用于合成障碍证书。这种方法采用贝叶斯框架，通过输出数据更新状态空间表示的先验，并利用目标边缘Metropolis-Hastings抽样器。抽样用于通过多项式和平方程序构造障碍证书。通过测试后验样本集，获得该证书对真实未知系统的概率保证。", "conclusion": "通过数值模拟，该方法和其概率保证被示例说明。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04238", "html_url": "https://arxiv.org/abs/2506.04238", "title": "关于生物启发算法激增的综述：批判与改进需求", "title_en": "A Review on Influx of Bio-Inspired Algorithms: Critique and Improvement Needs", "authors": "Shriyank Somvanshi,Md Monzurul Islam,Syed Aaqib Javed,Gaurab Chhetri,Kazi Sifatul Islam,Tausif Islam Chowdhury,Sazzad Bin Bashar Polock,Anandi Dutta,Subasish Das", "background": "生物启发算法，也称为比喻算法，利用自然过程如进化、群集行为、觅食、植物生长来解决复杂的、非线性的、高维的优化问题。然而，大量的这些算法仍然缺乏严格的评估，还未广泛应用于相关领域。本文对该领域的算法进行了分类和回顾，希望能够提高这些算法的适用性和可靠性.", "innovation": "1. 将生物启发算法分成了八类进行分类和回顾：进化、群集智能、物理启发、生态系统和植物基、捕食者-猎物、神经启发、人启发、混合方法。\n2. 详细审查了这些算法的基本原理、优点、新颖性及关键局限性。\n3. 重点讨论了这些算法在混合、参数调优和自适应策略方面的进步。\n4. 指出了可扩展性、收敛性、可靠性和可解释性等开放挑战，为未来研究提出了方向建议。\n5. 这项工作旨在为对生物启发算法感兴趣的研究人员和实践者提供资源，帮助他们理解该领域的现状和未来方向，推动算法的可靠与真实进步的改进和发展", "conclusion": "本文旨在为生物启发算法领域的现状和发展提供一个资源，总结了生物启发算法的创新之处和挑战，为未来的研究提供了指南。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19231", "html_url": "https://arxiv.org/abs/2504.19231", "title": "ridge回归的测试集大小", "title_en": "Test Set Sizing for the Ridge Regression", "authors": "Alexander Dubbs", "background": "本文基于大样本极限下的岭回归，推导出了理想的训练集/测试集分割方法，旨在使训练模型的测量误差尽可能接近理论预期。此前，尽管有许多关于模型性能评估的研究，但尚未有针对机器学习模型在大数据极限下的具体分割方法的数学推导。本文的研究目标是最大化“完整性”，即使训练模型的测量误差尽可能接近其理论应有值。", "innovation": "这是首次针对机器学习模型在大数据极限情况下，从数学角度推导出具体的分割方法。本文对于岭回归的分割结果与传统的纯线性回归分割在渐近意义下的前两项一致。特别指出的是，分割方法依赖于岭调整参数alpha，但这种依赖性在大样本极限下很弱，可以近似忽略不计，所有参数除了训练行数m和特征数n（n保持恒定）外均趋近于零。", "conclusion": "本文通过数学推导，得到了在大数据极限情况下针对岭回归的理想的训练集/测试集分割方法，并指出这一方法能够最大限度地减少训练模型的测量误差与理论预期值之间的差距。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13120", "html_url": "https://arxiv.org/abs/2507.13120", "title": "RS-TinyNet: 阶梯式特征融合网络用于遥感图像中微小目标检测", "title_en": "RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images", "authors": "Xiaozheng Jiang,Wei Zhang,Xuerui Mao", "background": "检测遥感（RS）图像中的微小对象一直是一个长期的挑战，因为这些对象的空间信息极其有限，特征表示较弱，并且在复杂的背景中密集分布。尽管做出了众多努力，主流检测器在这些场景中的表现仍然不尽如人意。", "innovation": "我们提出了一种多阶段特征融合与增强模型RS-TinyNet，专门针对各种遥感场景中的微小目标检测。RS-TinyNet引入了两个新颖的设计：微小目标显著性建模和特征完整性重构。三个逐步特征增强模块包括多维度协作注意力（MDCA）模块用于增强微小目标的显著性，辅助可逆分支（ARB）和逐步融合检测头部（PFDH）模块则用于保持信息流并融合多级特征以连接语义鸿沟并保留结构细节。", "conclusion": "我们的全面实验表明RS-TinyNet在公开的RS数据集AI-TOD上超越了现有最先进的（SOTA）检测器4.0%的AP和6.5%的AP75，进一步在DIOR基准数据集上的评估验证了其在多种RS场景中的优越检测性能。结果表明，提出的多阶段特征融合策略为复杂遥感环境中的微小对象检测提供了一种有效且实用的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19141", "html_url": "https://arxiv.org/abs/2506.19141", "title": "EEG 基础挑战：从跨任务到跨个体的 EEG 解码", "title_en": "EEG Foundation Challenge: From Cross-Task to Cross-Subject EEG Decoding", "authors": "Bruno Aristimunha,Dung Truong,Pierre Guetschel,Seyed Yahya Shirazi,Isabelle Guyon,Alexandre R. Franco,Michael P. Milham,Aviv Dotan,Scott Makeig,Alexandre Gramfort,Jean-Remi King,Marie-Constance Corsi,Pedro A. Valdés-Sosa,Amit Majumdar,Alan Evans,Terrence J Sejnowski,Oren Shriki,Sylvain Chevallier,Arnaud Delorme", "background": "当前的 EEG 解码模型通常基于对单个任务和小数量受试者的训练。本研究引入了一个大规模代码提交竞赛，其中包括两个挑战。第一个挑战（Transfer Challenge）要求参与者构建和测试能够零样本解码新的任务和新的受试者的 EEG 数据的模型。第二个挑战（Psychopathology factor prediction Challenge）则要求参与者从 EEG 数据中推断出受试者的心理健康指标。为此，研究使用了前所未有的、多太字节级别的高密度 EEG 信号数据集，采集自超过 3000 名儿童到年轻人在多个主动和被动任务中的数据。研究还提供了适用于这两个挑战的可调神经网络基线模型，包括一个简单的网络和基于人口统计学的回归模型等。", "innovation": "本研究引入了大规模、基于代码提交的竞赛，其中包括两个基于 EEG 数据的挑战。第一，Transfer Challenge 要求构建能够跨任务和跨个体解码的新 models；第二，Psychopathology factor prediction Challenge 则基于 EEG 数据推断心理健康指标。该研究使用了前所未有的大规模 EEG 数据集，涉及多任务和多受试者。提供多种可调的神经网络基础模型，包括简单的网络模型和人口统计学为基础的回归模型，为未来的 EEG 数据分析提供了新方法。", "conclusion": "通过进行此挑战，研究模型会更适用于跨任务和跨个体的数据。这将为机器学习网络架构适应多样任务和个体，以及通过 EEG 数据预测心理健康相关的个性特征值，提供可能的临床诊断和个性治疗设计的新突破。长期来看，该挑战有望推进计算精神病学和有用的神经技术的发展，并为基础神经科学和临床应用研究的突破作出贡献。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17439", "html_url": "https://arxiv.org/abs/2507.17439", "title": "在污染数据模型中具备鲁棒性的双重稳健因果治疗效应推断", "title_en": "Doubly robust outlier resistant inference on causal treatment effect", "authors": "Byeonghee Lee,Juhyun Park,Saebom Jeon,Joonsung Kang", "background": "离群值严重扭曲观察性研究中的因果效应估计，尤其是在小样本中。开发了一种在受污染数据模型下双重稳健的平均处理效应（ATE）估计器，该估计器明确地容纳了离群值。通过结果模型的有界影响估计方程实现离群值的鲁棒性，同时利用协变量平衡倾向得分（CBPS）处理治疗分配。为缓解高维中的过拟合，引入了变量选择，并将所有组件统一在一个惩罚经验似然框架中。进一步进行推断时，推导出一种在污染模型下端点对离群值不变的最佳有限样本置信区间（CI）。", "innovation": "提出了在受污染数据模型下具备鲁棒性的双重稳健的平均处理效应估计器，结合有界影响的效应模型估计方程和协变量平衡倾向得分，以及在高维中利用变量选择并统一到惩罚经验似然框架中。此外，推导出了一种对于离群值不变的最佳有限样本置信区间。", "conclusion": "广泛的模拟和两个基因表达应用（Golub；秦儿童肿瘤）显示，所提出的平均处理效应估计器和有限样本置信区间在各种污染水平和样本尺寸范围内，在偏差、均方误差、实际覆盖率和区间长度方面优于最先进的竞争对手。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01249", "html_url": "https://arxiv.org/abs/2508.01249", "title": "AgentArmor：通过分析代理运行时踪迹来防御提示注入攻击的程序分析", "title_en": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection", "authors": "Peiran Wang,Yang Liu,Yunfei Lu,Yifeng Cai,Hongbo Chen,Qingyou Yang,Jie Zhang,Jue Hong,Ye Wu", "background": "大型语言模型（LLM）代理通过结合自然语言推理和外部工具的执行来解决各种问题，但其动态和不透明的行为引入了关键的安全风险，尤其是在提示注入攻击的情况下。", "innovation": "提出了将代理运行时踪迹视为具有可分析语义的结构化程序的新洞察。基于此，提出了AgentArmor框架，该框架将代理踪迹转换为基于图中间表示的结构化程序依赖表示（例如，控制流图、数据流图和程序依赖图），并通过类型系统强制执行安全策略。该框架包含三个关键组件：（1）一个图构造器，用于以控制和数据流描述的方式将代理行为重构为基于图的中间表示；（2）一个属性注册表，用于附加与交互工具和数据相关的安全相关元数据；（3）一个类型系统，用于对中间表示进行静态推断和验证。", "conclusion": "在AgentDojo基准测试上评估了AgentArmor。结果显示，AgentArmor可以将ASR（攻击成功率）降低到3%，而实用性下降仅1%。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23081", "html_url": "https://arxiv.org/abs/2505.23081", "title": "具有在线缩放的梯度方法 第一部分：理论基础", "title_en": "Gradient Methods with Online Scaling Part I. Theoretical Foundations", "authors": "Wenzhi Gao,Ya-Chi Chu,Yinyu Ye,Madeleine Udell", "background": "该论文旨在建立在线缩放梯度方法（OSGM）的理论基础，这是一种利用在线学习自适应调整步长并可证加速梯度方法的框架。OSGM通过一个反馈函数量化步长的有效性，该反馈函数源自收敛度量，并利用在线学习算法调整步长。这种框架提供了在平滑凸问题上所需的收敛保证，如1) 对平滑凸目标函数具有轨迹依赖的全局收敛；2) 在平滑强凸问题上改进的复杂性结果；3) 局部超线性收敛。另外，OSGM为第一类方法提供了一种无渐进超线性收敛的新家族，加入了著名的拟牛顿方法行列。最后，OSGM解释了在机器学习优化中流行的超梯度下降启发式方法的实证成功。", "innovation": "1. 建立了OSGM框架，利用在线学习调整步骤大小，可以证明加速第一类方法。\n2. 提供了OSGM在平滑凸问题上的收敛保证。\n3. 证明OSGM具有无渐进超线性收敛特性，这在第一类方法中相对较新。\n4. 解释了超梯度下降启发式方法在机器学习优化中的实证成功。", "conclusion": "OSGM提供了一种新的磁场，通过无渐进超线性收敛的特性改善了第一类方法的性能。该方法在平滑凸问题上具有显著的收敛结果，并解释了流行的优化技术。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20474", "html_url": "https://arxiv.org/abs/2507.20474", "title": "MountainLion: 一种基于多模态大语言模型的智能投资交易系统", "title_en": "MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading", "authors": "Siyi Wu,Junqiao Wang,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Dexu Yu,Jinhao Wang,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi", "background": "加密货币交易是一个复杂的任务，需要整合多模态数据。传统深度学习和强化学习方法通常需要大量的训练数据，并将多样化的输入转换为数值表示，这往往牺牲了可解释性。近期基于大规模语言模型（LLM）的代理已经展示了处理多模态数据并支持复杂投资决策的能力。在此基础上，我们提出了MountainLion，一种多模态、多代理系统，能够协调专门的LLM代理来解释金融数据并生成投资策略。通过加工文本新闻、蜡烛图和交易信号图，MountainLion生产高质量的金融报告，并且还能够通过基于数据的用户互动和问答修改报告和投资建议。中心反思模块分析历史交易信号和结果，持续优化决策过程，系统并能进行实时报告分析、总结，并动态调整投资策略。实验证明，MountainLion系统系统性地丰富了技术价格触发，添加了宏观经济和资金流动的背景信息，从而提供了更具有解释性、稳健性和可控性的投资框架，有助于提升回报率和增强投资人的信心", "innovation": "MountainLion的核心创新在于整合多模态数据并通过专门的LLM代理进行理解和处理，以支持复杂的投资决策。它通过文本新闻、蜡烛图和其他图表来提供高质量的金融报告，并通过数据驱动的方式进行投资建议的修改。系统还包括一个反馈模块，能够实时分析和调整投资策略，从而加强了决策过程的准确性和适应性。此系统的自动调整能力，使其能够更好地理解市场情况并作出更优的投资策略，同时提供给投资人更可解释和更可靠的投资建议", "conclusion": "MountainLion显著提升了加密货币交易的技术和方法，通过结合多模态数据，实现更强大的投资决策系统。它通过系统性和背景性地增强技术价格信息，提供了更为可靠和可解释的决策模型。系统实时分析和动态调整的能力能够适应不断变化的市场条件，从而提高投资回报率和增强投资人的信心。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19861", "html_url": "https://arxiv.org/abs/2507.19861", "title": "量子指导的机器学习预测空间-时间混沌", "title_en": "Quantum-Informed Machine Learning for Predicting Spatiotemporal Chaos", "authors": "Maida Wang,Xiao Xue,Mingyang Gao,Peter V. Coveney", "background": "该论文提出了一种量子指导的机器学习（QIML）框架，用于高维混沌系统的长期动力学行为。该方法结合了一个一次性的、离线训练的量子生成模型和一个经典的自回归预测器来生成空间-时间场。这种方法旨在通过量子模型学习量子先验（Q-Prior）来指导小尺度交互的表示，从而提高细尺度动力学的建模能力。研究是基于三个代表系统进行的，分别是Kuramoto-Sivashinsky 方程、二维Kolmogorov 流动和三维完全发展的湍流通道流动，作为现实的流入条件。与经典的基线相比，QIML在预测分布准确性上提高了17.25%，在预测完整能量光谱的保真度上提高了29.36%。在湍流通道流入的情况下，Q-Prior是必不可少的，没有它模型无法随时间进化，而QIML能够产生稳定且物理上一致的预测，其预测结果超越了包括Fourier 神经操作员和马尔可夫神经操作员等领先的大尺度偏微分方程机器学习模型，这些模型的错误会发散。除了提高预测准确性，QIML还具有内存优势，能够将多兆字节的数据集压缩至千字节级别的Q-Prior，只保留经典模型所需的不变量测度，从而绕过了霍洛维茨界限，避免了完整的数据重建。此项研究提供了一种实用且可扩展的途径，将量子设备带来的优势纳入大规模科学、工程建模和模拟中。", "innovation": "本研究创新性地提出了QIML框架，将量子模型与经典自回归预测器结合，用于高维混沌系统的长期动力学预测，并通过量子先验（Q-Prior）有效指导小尺度交互的表示，显著提高了细尺度动态建模的准确性。研究结果表明，在预测复杂流动如湍流时，量子先验对于模型的稳定性及物理一致性至关重要，同时也展示了在大规模数据处理中的内存优势，扩展了现有量子和经典模型的应用范围。", "conclusion": "研究结果证明了QIML在混沌系统预测中的有效性和优越性，特别在复杂流动如湍流预测中表现突出。该方法不仅提升了预测精度和 fidelity，还通过Q-Prior在内存上的优势克服了传统数据重建的限制。这为量子技术在大规模科学、工程建模和模拟中的应用提供了新的方向和可能性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21509", "html_url": "https://arxiv.org/abs/2507.21509", "title": "Personality Vectors: 监控和控制语言模型中的性格特征", "title_en": "Persona Vectors: Monitoring and Controlling Character Traits in Language Models", "authors": "Runjin Chen,Andy Arditi,Henry Sleight,Owain Evans,Jack Lindsey", "background": "大语言模型通过模拟的‘助手’角色与用户互动。虽然助手通常被训练为友好、无害、诚实，但它偶尔会偏离这些规范。本文识别了模型激活空间中的‘个性向量’，这些向量涵盖了诸如邪恶、奉承和产生幻觉等特质。文章证实这些向量可以用于管理员工在部署时的性格波动。然后应用个性向量来预测和控制在训练过程中发生的人物转变。研究发现，微调后的故意和非故意性格变化与相关个性向量的变化高度相关。这些变化可以通过事后干预来减轻，或者通过一种新的预防方法避免。同时，个性向量还可以用于标记将在数据集和个体样本层次上导致不良性格变化的训练数据。提取个性向量的方法是自动化且可以应用于任何感兴趣的性格特征，只需提供自然语言描述即可。", "innovation": "本文提出了使用‘个性向量’监控和控制语言模型中的人物变化的方法。个性向量可以用于识别模型在激活空间中的变化趋势，如邪恶、奉承和幻觉。研究人员通过个性向量提前预测和控制在训练过程中发生的人物转变，并提出了一种新型的预防性方法，可以在一开始避免不必要的性格变化。此外，个性向量还可以用来警示可能导致不良性格变化的训练数据。该方法可以自动提取任何感兴趣的性格特征，并仅需自然语言描述。这些创新使得在大规模语言模型的开发和部署中更有效地管理人物属性成为可能。", "conclusion": "本文通过个性向量方法监控和控制语言模型中的人物特征，显著解决了模型性格变化的问题。这些变化可以通过事后干预来管理，甚至通过一种新的预防性方法来避免。同时，个性向量有助于发现可能引起不良性格变化的训练数据。此方法的自动性和灵活性可应用于任何性格特征的提取，对于语言模型的开发和应用具有重要意义。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17114", "html_url": "https://arxiv.org/abs/2505.17114", "title": "RAVEN: 通过查询引导的表示对齐进行音频、视频、嵌入式传感器和自然语言问题回答", "title_en": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "authors": "Subrata Biswas,Mohammad Nur Hossain Khan,Bashima Islam", "background": "多模态问题回答（QA）通常需要识别哪些视频、音频或传感器标记与问题相关。然而，不同模态之间常常存在分歧：离镜头的说话声、背景噪音或视场外的运动等都可能导致融合模型错误地处理标记。现有模型常常对所有流体赋予相同权重，这不利于问题的回答。", "innovation": "提出了一种统一的多模态QA架构RAVEN，其核心是QuART模块，可以对每种模态中的标记给出标量相关性评分，使得模型能够在融合之前放大有用信号并抑制干扰。RAVEN通过包含单独的定标预训练、查询对齐融合和分歧导向微调的三个阶段训练流程进行了优化，分别针对多模态推理中的表示质量、跨模态相关性和模态不匹配稳健性等挑战。为此，作者还释放了一个名为AVS-QA的数据集，包含300,000个同步的音频-视频-传感器通道以及人工生成的问题-答案对。", "conclusion": "在七个包含自我中心和外界中心任务的多模态QA基准测试中，RAVEN的准确率比最先进的多模态大语言模型分别提高了14.5%和8.0%，并且在结合传感器数据时额外提高了16.4%的准确率。该模型在模态破坏下仍保持鲁棒性，比SOTA基线高出50.23%。代码和数据集可在指定网址获取。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11987", "html_url": "https://arxiv.org/abs/2508.11987", "title": "FutureX: 一种先进的LLM代理未来预测实时基准", "title_en": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "authors": "Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Yixiao Tian,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang", "background": "未来预测是一项复杂的任务，需要具备高阶的分析思考能力、信息收集能力、情境理解以及在不确定性下做决策的能力。代理不仅要收集和解释大量的动态信息，还要整合多种数据来源，权衡不确定性，并根据新兴趋势调整预测，就像政治、经济和金融领域的专业人员所做的那样。尽管未来预测非常重要，但目前还没有针对未来预测的大型基准，这主要是由于处理实时更新和技术获取及时准确答案的挑战所致。本文介绍了一个名为FutureX的动态实时评估基准，专为执行未来预测任务的LLM代理设计。FutureX是迄今为止最大、最多样化的未来预测实时基准，支持每日实时更新，并通过自动化的问题收集和答案集合法避免数据污染。", "innovation": "本文提出了FutureX，这是一个面向未来预测任务的LLM代理的动态实时基准。它支持每日实时更新并使用自动化流程避免数据污染。该基准评估了包括具备推理能力、搜索能力和集成外部工具等不同能力的25个LLM/代理模型，以评估其适应推理和动态环境中的表现。此外，本文还深入分析了代理在面向未来任务中的失败模式和表现缺陷，包括对假网页的脆弱性以及时间有效性等问题，以推动能够像专业的人类分析师一样在复杂推理和预测思考方面表现优异的LLM代理的发展。", "conclusion": "本研究旨在建立一个动态且无污染的评估标准，促进LLM代理的发展，使其在复杂的推理和预测思考方面能够达到专业人类分析师的水平。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00931", "html_url": "https://arxiv.org/abs/2509.00931", "title": "基于Log-签名的贝叶斯生成对抗网络在信用卡欺诈检测中的无监督贝叶斯学习", "title_en": "Semi-Supervised Bayesian GANs with Log-Signatures for Uncertainty-Aware Credit Card Fraud Detection", "authors": "David Hirnschall", "background": "随着金融交易数据流的规模和复杂性增加，传统的信用卡欺诈检测方法通常需要大量的标注数据，难以处理不规则采样频率和序列长度变化的时间序列数据。", "innovation": "该研究提出了一种基于生成对抗网络（GANs）的新的半监督生成式框架，结合了贝叶斯推理来获得预测分布并量化不确定性，使用Log-签名来编码交易历史的鲁棒特征。此外，引入了一种基于Wasserstein距离的损失函数，同时最大化有标签数据上的分类准确性。", "conclusion": "该方法在BankSim数据集上进行了评估，证明了在不同比例的有标签样本下，与基准方法相比，总体统计和领域特定度量上的持续改进。这一发现强调了基于GAN的半监督学习方法在处理不规则采样时间序列和不确定性建模中的有效性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15318", "html_url": "https://arxiv.org/abs/2508.15318", "title": "大规模流动匹配：用于有效采样多体系统的机器学习框架", "title_en": "Flow Matching at Scale: A Machine Learning Framework for Efficient Large-Size Sampling of Many-Body Systems", "authors": "Qian-Rui Lee,Daw-Wei Wang", "background": "本文提出了一种基于流动匹配的机器学习框架，旨在克服马尔可夫链蒙特卡罗(MCMC)方法的缩放限制。通过流动匹配框架，单个网络能够在较大的系统（如128x128）上生成可靠样本，而无需重新训练，并在整个连续温度范围内生成符合关键热力学可观测量的配置，为研究临界现象提供了强大的替代方案。", "innovation": "论文的创新在于提出了一种基于流动匹配的机器学习框架，使单个网络能够在更大系统（如128x128）上生成可靠样本，而无需重新训练，展示了在2D XY模型中的应用能力，能够捕捉Berezinskii-Kosterlitz-Thouless（BKT）转换的特征。这种方法通过流动匹配框架学习到了连续的、以温度为条件的映射，并通过CNN的归纳偏差确保了局部物理规则的尺度不变性，提供了一种高效学习连续场的多体系统的替代方法。", "conclusion": "该方法可以直接应用于其他由连续场描述的经典或量子多体系统。同时，该框架可以作为混合MCMC方案中的强大提案生成器，显著加速了关于热力学极限的高精度研究。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18708", "html_url": "https://arxiv.org/abs/2508.18708", "title": "技能对齐的公平性在医疗保健协作中的多智能体学习", "title_en": "Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in Healthcare", "authors": "Promise Osaine Ekpo,Brian La,Thomas Wiener,Saesha Agarwal,Arshia Agrawal,Gonzalo Gonzalez-Pumariega,Lekan P. Molu,Angelique Taylor", "background": "多代理强化学习（MARL）中的公平性通常被定义为工作负载平衡问题，忽略了代理的专业技能和实际领域中所需要的结构化协调。在医疗保健领域，公平的任务分配需要工作负载平衡或专业技能匹配，以避免高技能人员的过度使用和工作倦怠。工作负载平衡指的是在医疗工作者之间平均分配任务或努力程度，不论其专业技能如何。现有方法没有很好地处理这一问题，因此开发了适合医疗保健领域的仿真实验环境和评估公平性的新指标成为必要。", "innovation": "该论文提出了一个名为FairSkillMARL的框架，将公平定义为工作负载平衡和技能任务匹配的双重目标，并且开发了名为MARLHospital的可定制医疗保健启发式环境，用于建模团队组成和能源约束下的调度对公平性的影响。此外，还对比了FairSkillMARL与四种标准MARL方法和两个最先进的公平性度量标准的性能表现，并强调了仅仅依靠工作负载平衡的公平性可能引起任务技能不匹配的问题，需要更 robust 的度量标准来捕捉技能任务不匹配问题。", "conclusion": "研究结果表明，仅仅依靠工作负载平衡的公平可能造成任务技能不匹配的问题，强调了需要更 robust 的度量标准来捕获技能任务不匹配的重要性。本研究提供了研究异构多智能体系统中努力与技能对齐公平性的工具和基础。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16531", "html_url": "https://arxiv.org/abs/2508.16531", "title": "在亚线性时间内进行质量控制：随机图的一个案例研究", "title_en": "Quality control in sublinear time: a case study via random graphs", "authors": "Cassandra Marcussen,Ronitt Rubinfeld,Madhu Sudan", "background": "许多算法在平均输入上表现良好。但在实际应用中，必须保证算法在任意输入上的表现。为此，本文定义了一类新的算法问题称为‘质量控制问题’。这类问题通过一个度量质量的函数和一个数据分布来定义，目的是在保持高效的同时，识别出潜在的劣质输入。对于随机图而言，无法仅凭一次采样测试是否为特定分布，而测试特定质量值是否接近1则需要大量的采样。", "innovation": "提出了质量控制问题，特别关注亚线性时间内的解决方案。对于随机图$G_{n,p}$，针对$k$-团计数函数$\rho_k$，可以以$p^{-O(k)}$的时间和查询次数解决质量控制问题，相较于直接测试$G \text{~} G_{n,p}$所需的样本数量显著减少。", "conclusion": "质量控制相比单独测试质量和样本分布具有更低的计算复杂度，对于最大度为$\triangle(H)$的模式$H$，质量控制问题可以以$p^{-O(\triangle(H))}$的时间和查询次数解决，证明在亚线性时间内进行质量控制相比传统方法具有显著的优势。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02103", "html_url": "https://arxiv.org/abs/2509.02103", "title": "在线复杂度 estimation 用于重复场景设计", "title_en": "Online Complexity Estimation for Repetitive Scenario Design", "authors": "Guillaume O. Berger,Raphaël M. Jungers", "background": "在重复场景设计问题中，需要反复解决场景设计问题，并可以根据先前的场景解及其风险水平动态调整样本量（即场景数量），以达到特定的风险水平（约束违反概率）。", "innovation": "提出了一种基于观测数据（即先前场景解决方案及其风险水平）学习最优样本大小的方法，该方法通过学习风险的概率密度函数（pdf）作为样本大小的函数来确定最优样本大小。", "conclusion": "该方法适用于固定复杂度场景问题类，并证明了在该类问题中该方法的准确性和收敛性，同时也展示了该方法在一系列具有挑战性的重复场景设计问题上的实际效率，包括非固定复杂度问题、非凸约束和时间变化的分布情况。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20312", "html_url": "https://arxiv.org/abs/2508.20312", "title": "ELIXIR: 效率高且轻量级的解释推荐模型", "title_en": "ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations", "authors": "Ben Kabongo,Vincent Guigue,Pirmin Lemberger", "background": "协同过滤在许多成功的推荐系统中发挥着重要作用，但难以处理细粒度的用户项交互和提高解释性。随着用户越来越寻求透明的推荐，通过语言模型生成文本解释变得至关重要。现有方法大多使用RNN或Transformer，然而RNN方法无法充分利用预训练Transformer模型的能力，而基于Transformer的方法则往往适应效果不好，并且忽视了方面建模，这在个性化解释中十分重要。", "innovation": "提出了ELIXIR（Efficient and Lightweight model for Explaining Recommendations，解释推荐的高效且轻量级模型），该模型结合了评分预测和个人化评论生成，采用多任务学习方法同时学习全局和方面特定的用户和物品表示。ELIXIR优化整体评分、方面评分和评论生成，通过个性化注意力机制强调方面的重要性。以T5-small（60M）模型为基础，ELIXIR展示了其在个性化上下文中的效果指导文本生成，而现有最先进的方法尽管使用更大规模的模型，但在匹配用户偏好方面却表现不佳。", "conclusion": "在TripAdvisor和RateBeer上的实验结果表明，ELIXIR在评论生成方面显著优于强大的基线模型，特别是在处理细粒度用户项交互方面取得了显著提升，展示了ELIXIR在个性化推荐和解释方面的优势。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LARGE LANGUAGE MODELS 的人格错觉：揭示自述与行为之间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质长期被用作预测人类行为的指标。近年来，大型语言模型（LLMs）的进步表明，在人工系统中也可能出现类似的人格模式，且高级LLMs显示出与人类特质（如和蔼和自我调节）相似的一贯行为倾向。理解这些模式至关重要，但先前的研究主要依赖于简化的自我报告和启发式提示，缺乏行为验证。", "innovation": "本研究系统地分析了LLM的人格特征，涵盖了三个维度：1）在训练阶段中，个性特征的表现与演变；2）自我报告的人格特质在行为任务中的预测价值；3）目标干预（如persona注入）对自我报告和行为的影响。研究发现，指令对齐（如RLHF、指令调优）显著稳定了个性特征表达并增强了个性特征间的相关性，这与人类数据相似。然而，自我报告的人格特质并不能可靠地预测行为，观察到的关联往往与人类数据不一致。虽然persona注入在引导自我报告方面效果显著，但对实际行为的影响有限或不一致。", "conclusion": "通过区分表面特征表现与行为一致性，我们的研究挑战了关于LLM人格特征的假设，强调了在对齐和可解释性方面进行深入评估的必要性。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01920", "html_url": "https://arxiv.org/abs/2509.01920", "title": "动态推测性智能体规划", "title_en": "Dynamic Speculative Agent Planning", "authors": "Yilin Guan,Wenyue Hua,Qingfeng Lan,Sun Fei,Dujian Ding,Devang Acharya,Chi Wang,William Yang Wang", "background": "尽管基于大型语言模型的代理在复杂任务上取得了显著的成功并广泛采用，但在实际部署中仍面临严重的延迟和推理成本问题。虽然近期的研究探索了多种加速推理的方法，但现有方法存在显著的局限性：要么无法保持性能一致性，要么需要进行大量的离线路由模块训练，要么导致过高的运营成本。此外，这些方法基本无法让用户控制加速与性能指标之间的权衡。", "innovation": "本文提出了动态推测性规划（Dynamic Speculative Planning, DSP），这是一个异步在线强化学习框架，该框架能够在无需额外预部署准备的情况下实现无损加速，并大幅度降低运营成本。DSP 显式优化了一个综合目标函数，平衡端到端延迟和成本，让实践者可以通过调整单一参数来使系统更快响应、更低成本运行，或在这两者之间达到任何平衡点。实验证明，DSP 的效率与最快无损加速技术相当，且总成本降低30%，未必要支出降低60%。", "conclusion": "实验表明，DSP 在实现与最快速率无损加速技术相似的高效性的同时，将总成本降低了30%，并将不必要的成本最多减少了60%。为此，DSP 提供了一种全新的平衡加速和成本控制的方法，为实际部署中的大规模语言模型代理提供了新的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04763", "html_url": "https://arxiv.org/abs/2509.04763", "title": "NovaQ：通过多样性驱动的测试案例生成改进量子程序测试", "title_en": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation", "authors": "Tiancheng Jin,Shangzhou Xia,Jianjun Zhao", "background": "量子程序旨在运行在量子计算机上，利用量子电路解决经典机器无法解决的问题。随着量子计算的发展，确保量子程序的可靠性变得越来越重要。", "innovation": "NovaQ 是一个多样性导向的量子程序测试框架，结合了基于分布的测试案例生成器和新颖驱动的评估模块。生成器通过变异电路参数产生多样化的量子态输入，而评估器根据电路状态内部分量（包括幅度、相位和纠缠）定量评估行为新颖性。通过选择映射到度量空间中未充分覆盖区域的输入，NovaQ 能有效地探索未充分测试的程序行为。", "conclusion": "我们在不同大小和复杂度的量子程序上评估了 NovaQ，实验结果表明，NovaQ 能够获得更高的测试案例多样性并检测出比现有基线方法更多的 Bug。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04810", "html_url": "https://arxiv.org/abs/2509.04810", "title": "跨越语言边界的代码审查：合成数据与真实数据在代码审查推荐中的评估", "title_en": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation", "authors": "Yogev Cohen,Dudi Ohayon,Romy Somkin,Yehudit Aperstein,Alexander Apartsin", "background": "在现代开发流程中，自动化确定代码变更是否需要人工审查对于维持软件质量至关重要。然而，新兴编程语言和框架的出现创建了一个关键瓶颈：尽管有大量的未标记代码可作为来源，但由于缺乏足够的标记数据，监督模型训练受到影响。因此，本研究利用大型语言模型（LLMs）将资源丰富的语言中的代码变更翻译成稀缺标记示例的新兴或未充分资源化的语言中的等效变更，从而生成合成训练数据。", "innovation": "本研究通过使用LLMs生成合成代码变更示例，并在这些示例上训练监督分类器来克服语言数据稀缺的问题。此外，本研究系统地比较了基于合成数据和真实标记数据训练的分类器的性能。实验结果表明，在低资源环境中，合成数据能有效支撑审查推荐系统，并逐步缩小性能差距。", "conclusion": "本方法为扩展自动化代码审查能力到快速演化的技术堆栈提供了可扩展的途径，即使在缺乏标注数据的情况下也能有效实现。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04644", "html_url": "https://arxiv.org/abs/2509.04644", "title": "大型语言模型在测试骨架生成中的比较评估", "title_en": "Comparative Evaluation of Large Language Models for Test-Skeleton Generation", "authors": "Subhang Boorlagadda,Nitya Naga Sai Atluri,Muhammet Mustafa Olmez,Edward F. Gehringer", "background": "在测试驱动开发（TDD）中，手动生成测试框架（即测试骨架）是一项耗时且易出错的任务，尤其是在教育和大规模开发环境中。因此，利用大型语言模型（LLMs）自动生成测试骨架成为了研究热点。已有研究表明，LLMs能够生成初步的测试框架，但不同模型间的生成质量和效果存在差异。本文旨在评估四种LLMs（GPT-4、DeepSeek-Chat、Llama4-Maverick和Gemma2-9B）生成RSpec测试骨架的能力，并对其输出进行结构正确性、清晰度、可维护性和符合测试最佳实践的评估。", "innovation": "文章使用四种不同的大型语言模型来生成RSpec测试骨架，通过静态分析和盲评审专家的评估方法，衡量模型输出的结构正确性、清晰度、可维护性和符合测试最佳实践的程度。研究过程中揭示了模型对代码结构和测试惯例的解释差异，为使用LLMs进行自动化测试脚手架设计提供了有益的见解。此外，研究发现DeepSeek模型生成的测试骨架最具可维护性和结构完整性，而GPT-4则提供了更完整的输出，但缺乏一致性，突显了提示设计和上下文输入的重要性作为质量关键因素。", "conclusion": "研究结果显示DeepSeek在生成可维护和结构清晰的测试骨架方面表现出色，而GPT-4虽然生成了更完整的测试骨架，但在遵循测试最佳实践方面存在一定问题。这表明在使用LLMs进行自动化测试脚手架生成时，需要关注模型解释代码结构的方式以及对测试惯例的理解，同时提示设计和上下文输入成为提升质量的关键因素。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03547", "html_url": "https://arxiv.org/abs/2509.03547", "title": "结合基于特征的方法和图神经网络及符号回归以实现协同性能和解释性", "title_en": "Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability", "authors": "Rogério Almeida Gouvêa,Pierre-Paul De Breuck,Tatiane Pretto,Gian-Marco Rignanese,Marcos José Leite Santos", "background": "当前在材料科学中，特征基于机器学习方法和图神经网络（GNN）方法各有优势。传统的特征基于模型可以提供化学透明度，而深度学习架构如GNN则具备强大的预测能力。但单独使用这些方法时，性能和可解释性都有局限性。因此，本研究旨在通过综合这两类方法，提高模型性能和解释性，以推动材料信息学的发展。", "innovation": "本研究提出了一种创新的混合框架MatterVial，该框架结合了基于特征的方法和GNN技术，以及符号回归生成的新特征。通过这种方式，MatterVial不仅增强了特征基于模型的化学透明度，还提高了其预测能力，使模型性能能够与端到端的GNN方法媲美，甚至在某些任务上更优。此外，研究还引入了一个集成的解释性模块，利用代理模型和符号回归，将GNN提取的隐含表示转化为明确的、物理上有意义的公式，从而提升模型的可解释性。", "conclusion": "MatterVial框架通过结合特征基于方法和GNN技术，以及符号回归生成的新特征，提供了一个高性能、透明的工具，符合解释性AI的原则。该研究不仅提升了材料发现中的模型性能，也提高了模型的解释性，为更精确和自主的材料发现提供了新的途径。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04721", "html_url": "https://arxiv.org/abs/2509.04721", "title": "嵌入式系统中TinyML模型的实时性能基准测试（PICO：推理、CPU和操作性能）", "title_en": "Real-Time Performance Benchmarking of TinyML Models in Embedded Systems (PICO: Performance of Inference, CPU, and Operations)", "authors": "Abhishek Dey,Saurabh Srivastava,Gaurav Singh,Robert G. Pettit", "background": "该论文介绍了PICO-TINYML-BENCHMARK框架，该框架是一个模块化且平台无关的基准测试框架，用于评估受限资源嵌入式系统上TinyML模型的实时性能。该框架通过评估关键指标，如推理延迟、CPU利用率、内存效率和预测稳定性，提供计算折衷和平台特定优化的见解。研究选择三个具有代表性的TinyML模型进行评估：手势分类、关键词识别和MobileNet V2，同时使用两个常用平台：BeagleBone AI64和Raspberry Pi 4，基于真实数据集进行测试。测试结果揭示了重要的折衷关系：BeagleBone AI64在特定AI任务上表现出一致的推理延迟，而Raspberry Pi 4则在资源效率和成本效益方面表现出色。这些发现为优化TinyML部署提供了实用指导，填补了理论进展与嵌入式系统中的实际应用之间的差距。", "innovation": "提出了一种模块化且平台无关的基准测试框架，涵盖了推理延迟、CPU利用率、内存效率和预测稳定性等关键指标。首次全面评估了多个代表性的TinyML模型在两种常见嵌入式平台上的性能，提供了基于实际数据集的测试结果。该框架为优化TinyML部署提供了一套实用的指导原则，缩小了理论与实践之间的差距。", "conclusion": "论文基于PICO-TINYML-BENCHMARK框架，通过全面评估多个TinyML模型在两种嵌入式平台上的性能，揭示了不同平台下的关键性能折衷，并提供了实际的部署建议。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.05197", "html_url": "https://arxiv.org/abs/2509.05197", "title": "Web 测试中的 AI 代理：野外案例研究", "title_en": "AI Agents for Web Testing: A Case Study in the Wild", "authors": "Naimeng Ye,Xiao Yu,Ruize Xu,Tianyi Peng,Zhou Yu", "background": "自动化网页测试对于确保高质量的用户体验和实现业务价值至关重要。传统的测试方法主要侧重于代码覆盖率和负载测试，但往往无法捕捉到复杂的用户行为，导致许多可用性问题未被检测到。大型语言模型（LLM）和AI代理的出现为网页测试带来了新的可能性，通过实现类似于人类与网站的互动以及对常见可用性问题的普遍意识，提高了测试效率。", "innovation": "本文介绍了WebProber，一个基于AI代理的网页测试框架。WebProber能够根据给定的URL自主探索网站，模拟真人用户交互，识别错误和可用性问题，并生成易于理解的报告。通过一个涉及120个学术人员个人网站的案例研究，WebProber发现了29个可用性问题，而许多问题也未能被传统工具检测到。这项研究表明基于代理的测试是一个很有前景的方向，同时指明了发展以人为本的下一代测试框架的方向。", "conclusion": "本文的研究表明，基于代理的测试是一个前景广阔的方向，为改善网页测试提供了新的见解。下一步的工作将集中在开发更全面、以用户为中心的测试框架上，以进一步提高网页测试的效果。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.05112", "html_url": "https://arxiv.org/abs/2509.05112", "title": "基于GenAI的SDV平台测试用例生成与执行", "title_en": "GenAI-based test case generation and execution in SDV platform", "authors": "Denesa Zyberaj,Lukasz Mazur,Nenad Petrovic,Pankhuri Verma,Pascal Hirmer,Dirk Slama,Xiangwei Cheng,Alois Knoll", "background": "本文介绍了一种基于GenAI的自动化测试用例生成方法，利用大规模语言模型和多模态语言模型将自然语言需求和系统图转换为结构化的Cucumber测试用例。该方法结合了车辆信号规范建模，以标准化车辆信号定义，提高汽车子系统之间的兼容性，并简化与第三方测试工具的集成。生成的测试用例在this http URL开发环境中执行，该环境是一个开放且供应商中立的环境，旨在快速验证软件定义的车辆功能。通过使用儿童存在检测系统等用例，本文展示了显著减少手动测试规格化工作量并快速执行生成的测试。", "innovation": "该方法利用大规模语言模型和多模态语言模型将自然语言需求与系统图转换为结构化的Cucumber测试用例。同时，结合了车辆信号规范建模技术，以确保标准化、兼容性和集成便利性。此外，提出的方法在开放且供应商中立的开发环境中的应用也是一大创新点。", "conclusion": "本文通过Child Presence Detection System等案例展示了该方法可以显著减少手动测试规格化的努力，并实现快速执行生成的测试。尽管实现了大量自动化，但在测试用例和测试脚本的生成过程中仍需手动干预，这是由于GenAI管道当前的局限性和this http URL平台的约束。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.05160", "html_url": "https://arxiv.org/abs/2509.05160", "title": "AI辅助建模：面向领域特定语言的AI交互", "title_en": "AI-Assisted Modeling: DSL-Driven AI Interactions", "authors": "Steven Smyth,Daniel Busch,Moez Ben Haj Hmida,Edward A. Lee,Bernhard Steffen", "background": "AI辅助编程显著提高了软件开发的性能。通过整合透明的领域特定建模技术和即时的图形可视化，本研究旨在更准确地反映AI生成代码的语义，从而促进视觉检查和形式验证，如模型检查。", "innovation": "本研究通过编程、自然语言提示、语音命令和逐步细化的方法，结合即时反馈，开发出一种原型作为Visual Studio Code扩展，支持LINGUA FRANCA语言。它展示了新型领域特定建模实践的潜力，提供一种新的创建、可视化和验证模型的方式。", "conclusion": "该方法提高了代码生成和后续验证过程的效果。通过这一途径，模型的创建、可视化和验证方式得到了改进，展示出提升软件开发性能的潜力。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04642", "html_url": "https://arxiv.org/abs/2509.04642", "title": "Maestro: 联合图与配置优化以构建可靠的AI代理", "title_en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "authors": "Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi", "background": "当前的LLM（大语言模型）代理的构建涉及两个层面的决策：图形层面（哪些模块存在及信息如何流动）和每个节点的配置（模型、提示词、工具、控制旋钮）。多数现有优化器在固定图形的前提下调整配置，忽略了结构上的故障模式。本文旨在介绍Maestro框架，这是一种跨框架的整体优化框架，它同时在图形和配置层面进行搜索，以最大化代理质量，同时考虑到明确的展开/令牌预算。", "innovation": "Maestro框架引入了一种全新的优化方式，不是单纯优化配置而是同时优化图形和配置，这使得它能够解决单纯通过调整提示词无法解决的结构故障模式。此外，Maestro还利用了反思性的文本反馈，通过这些反馈来优先选择编辑，从而提高样本效率并针对特定的故障模式进行优化。", "conclusion": "Maestro在IFBench和HotpotQA基准测试中均取得了比MIPROv2、GEPA和GEPA+Merge等领先提示词优化器平均水平高出12%、4.9%和4.86%的成绩，即使仅限于提示词优化，也能分别领先9.65%、2.37%和2.41%。同时，与GEPA相比，Maestro在更少的展开次数下也达到了这些结果。此外，该方法还展示了在两种应用程序（面试代理和RAG代理）上取得的显著收益，进一步证实了联合图和配置搜索的重要性。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04936", "html_url": "https://arxiv.org/abs/2509.04936", "title": "静态类型语言中浮点数使用的大型研究", "title_en": "A Large-Scale Study of Floating-Point Usage in Statically Typed Languages", "authors": "Andrea Gilot,Tobias Wrigstad,Eva Darulova", "background": "浮点数推理历来非常困难。虽然静态和动态分析技术或程序修复已经取得了显著进展，但它们在实际代码中的应用仍然有限。要解决这一问题的关键在于了解实际的浮点数代码是什么样的。为了解决知识差距，该文首次进行了大规模的实证研究，研究公开的GitHub存储库中静态类型语言中浮点数运算的使用情况。我们采用了最新的挖掘实践，包括随机采样和基于内在属性的过滤，以避免偏见，并通过在源代码中搜索关键词和解析代码以编程语言结构来识别浮点数的使用情况。研究结果支持了一个常见的观点，即浮点数运算广泛使用。我们发现的统计数据表明，用于评估浮点数运算自动化推理技术的基准在某些方面可以代表“实际世界”代码，但在所有方面都不一定如此。我们的研究和数据集旨在帮助未来设计和评估的浮点数技术更好地满足实际用户的需求.", "innovation": "首次进行大规模实证研究，公开GitHub存储库中静态类型语言中浮点数运算的使用情况，采用随机采样和基于内在属性的过滤方法以避免偏见，通过在源代码中搜索关键词和解析代码以编程语言结构来识别浮点数的使用情况，发现浮点数运算的广泛使用情况，并揭示了用于评估浮点数运算自动化推理技术的基准在某些方面可以代表“实际世界”代码，但在所有方面不一定如此。", "conclusion": "我们的研究和数据集旨在帮助未来浮点数推理技术更好地匹配实际用户的需求。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04877", "html_url": "https://arxiv.org/abs/2509.04877", "title": "通过GitHub仓库挖掘整合大型语言模型在软件工程教育中的试点研究", "title_en": "Integrating Large Language Models in Software Engineering Education: A Pilot Study through GitHub Repositories Mining", "authors": "Maryam Khan,Muhammad Azeem Akbar,Jussi Kasurinen", "background": "大型语言模型（LLMs）如ChatGPT日渐广泛应用于软件工程（SE）教育中，这一应用带来了机遇和挑战。其在教育中的应用需要系统的调查研究，确保负责任地融入教育项目。", "innovation": "本文的研究旨在通过多阶段过程开发一个验证框架，以将LLMs整合到SE教育中。第一阶段通过试点仓库挖掘研究，分析GitHub项目的README文件和问题讨论，识别之前文献综述中合成的动机和动机阻止因素。", "conclusion": "该研究提供了动机/动机阻止因素分类的初步经验验证，指出了研究实践中的缺口，并为制定全面的框架来指导LLMs在SE教育中负责任的应用奠定了基础。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.09337", "html_url": "https://arxiv.org/abs/2407.09337", "title": "CFaults：针对多测试案例的C程序故障定位的基于模型诊断方法", "title_en": "CFaults: Model-Based Diagnosis for Fault Localization in C Programs with Multiple Test Cases", "authors": "Pedro Orvalho,Mikoláš Janota,Vasco Manquinho", "background": "调试是软件开发中最耗时和最昂贵的任务之一。尽管已经提出了一些基于公式的故障定位（FBFL）方法，但它们并不能保证在所有失败的测试中都提供一组诊断结果，或者可能会生成冗余的、非子集最小的诊断结果，特别是在程序存在多个故障的情况下。因此，本研究旨在提出一种新的针对C程序的多故障定位方法。", "innovation": "CFaults利用了多观察的基于模型的诊断方法（MBD），将所有失败的测试案例整合成一个统一的MaxSAT公式。这种方法保证了各个观察结果的一致性，并简化了故障定位的过程。实验结果表明，CFaults在处理TCAS和C-Pack-IPAs基准代码集时比其他FBFL方法（如BugAssist和SNIPER）更快。此外，CFaults只生成故障语句的子集最小诊断结果，而其他方法则倾向于枚举冗余的诊断结果。", "conclusion": "CFaults为C程序中的多故障定位提供了一种新的方法，它通过整合所有失败的测试案例并使用基于模型的诊断来确保诊断结果的一致性和简化故障定位流程，并且相比现有方法具有更好的性能和更优的诊断结果。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.16299", "html_url": "https://arxiv.org/abs/2409.16299", "title": "HyperAgent: 多领域软件工程代理以大规模解决编码任务", "title_en": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale", "authors": "Huy Nhat Phan,Tien N. Nguyen,Phong X. Nguyen,Nghi D. Q. Bui", "background": "大型语言模型（LLMs）已经彻底改变了软件工程(SE)，展示了他们在各种编程任务中的卓越能力。尽管最近的发展使得利用LLMs创建用于端到端开发任务的自主软件代理成为可能，但这些系统通常仅针对特定的SE功能进行设计。目前的系统往往只适用于特定的SE功能，缺乏处理多种编程语言和广泛任务的能力。", "innovation": "本文介绍了HyperAgent，一个创新的多领域多代理系统，通过模仿人类开发人员的工作流程来应对各种编程语言中的广泛SE任务。HyperAgent包含四个专门化的代理——规划者、导航器、代码编辑器和执行器，能够从最初的设计规划到最终的验证完成整个SE任务的生命周期。HyperAgent在多种SE任务中都设置了新的标杆，包括在SWE-Bench基准测试中解决GitHub问题，性能超过了坚固的基线。此外，HyperAgent在仓库级别的代码生成（RepoExec）和错误定位及程序修复（Defects4J）方面也表现出色，经常超越最先进的基线。", "conclusion": "HyperAgent能够在多种SE任务中表现出色，并设置了新的标杆，为解决编码任务提供了新的解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.01249", "html_url": "https://arxiv.org/abs/2508.01249", "title": "AgentArmor：通过分析代理运行时踪迹来防御提示注入攻击的程序分析框架", "title_en": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection", "authors": "Peiran Wang,Yang Liu,Yunfei Lu,Yifeng Cai,Hongbo Chen,Qingyou Yang,Jie Zhang,Jue Hong,Ye Wu", "background": "大型语言模型（LLM）代理通过结合自然语言推理和执行外部工具来解决各种问题，但其动态和不透明的行为引入了关键的安全风险，特别是在提示注入攻击的背景下。", "innovation": "提出了将代理运行时踪迹视为具有可分析语义的结构化程序的新见解，并据此开发了AgentArmor框架。该框架将代理踪迹转换为基于图的中间表示的结构化程序依赖表示（例如，控制流图、数据流图和程序依赖图），并通过类型系统强制执行安全策略。", "conclusion": "在AgentDojo基准测试上评估了AgentArmor，结果表明，它将警觉性降低率（ASR）降至3%，仅将实用性下降率减小1%。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04967", "html_url": "https://arxiv.org/abs/2509.04967", "title": "FuzzRDUCC: 使用重构的定义使用链覆盖进行模糊测试", "title_en": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "authors": "Kai Feng,Jeremy Singer,Angelos K Marnerides", "background": "传统二进制模糊测试往往难以实现全面的代码覆盖率和发现隐藏的漏洞，因为它们缺乏对程序内部数据流的深入洞察。传统灰色盒模糊测试主要依赖于控制流边覆盖来引导测试案例生成，这可能会错过仅通过控制流分析难以暴露的漏洞。我们提出，将数据流分析集成到模糊测试过程中，可以增强其效果，通过揭示数据如何在程序中传播，从而使模糊测试能够探索控制流方法可能遗漏的执行路径。在这一背景下，我们介绍了FuzzRDUCC模糊测试框架，该框架使用符号执行从二进制可执行文件中重构定义使用（def-use）链。FuzzRDUCC利用新颖的启发式算法选择相关的定义使用链，从而确保模糊测试过程的全面性，同时不造成过多的计算开销。通过binutils基准测试对FuzzRDUCC进行评估，证明它可以识别由最先进的模糊测试工具无法找到的独特崩溃，从而将FuzzRDUCC确立为下一代漏洞检测和发现机制的可行解决方案。", "innovation": "FuzzRDUCC 使用符号执行来直接从二进制可执行文件中重构定义使用（def-use）链，通过数据流分析集成到模糊测试过程中，不消耗过多计算资源来选择相关的定义使用链，从而增强模糊测试的有效性，发现传统控制流方法可能遗漏的漏洞。", "conclusion": "FuzzRDUCC 通过使用重构的定义使用链覆盖的模糊测试方法，能够有效地识别出特有的崩溃，表现出更强的漏洞检测能力，证明了它是下一代漏洞检测和发现机制的有效解决方案。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2501.05412", "html_url": "https://arxiv.org/abs/2501.05412", "title": "Search-based Testing of Simulink Models with Requirements Tables", "title_en": "Search-based Testing of Simulink Models with Requirements Tables", "authors": "Federico Formica,Chris George,Shayda Rahmatyan,Vera Pantelic,Mark Lawford,Angelo Gargantini,Claudio Menghi", "background": "SBST技术在Simulink模型中的应用有助于发现能够展示系统达到违反其要求状态的场景。然而，大多数SBST方法依赖于将要求表达为逻辑语言，这限制了其在工业中的应用。为了促进其应用，SBST方法和工具需要与工程师用于指定要求的工具集成。本文提出了一种新的黑盒测试方法，该方法支持Simulink Requirements Toolbox中使用的Requirements Table (RT)，从而更好地与工程技术人员的工作流程集成。研究者选择了60个模型-RT组合进行评估，结果显示在70%的情况下，SBST框架能够生成能够揭示故障的测试案例，这在某些情况下甚至超越了其他现有工具的表现。此外，提出的SBST解决方案的效率在实际应用中是可接受的，且与基于RT的其他现有SBST工具相当", "innovation": "首次提出了一种黑盒测试方法，支持Simulink Requirements Toolbox中的Requirements Table (RT)，这种工具被工程技术人员用于表达软件需求。该方法能够揭示Simulink模型何时无法满足需求的具体情况，并且相对于以前的研究工具具有更高的准确性。试验结果表明，在实际应用中的效率是可以接受的，并且与基于RT的现有SBST工具相当", "conclusion": "基于上述实验结果，该SBST框架在支持Simulink模型的需求表方面具有显著优势，并且在满足工业应用效率方面表现出色。这使得该方法在软件测试领域具有潜在的广泛应用前景。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.05293", "html_url": "https://arxiv.org/abs/2509.05293", "title": "非停止证明：千万级行代码及其以上", "title_en": "Non-Termination Proving: 100 Million LoC and Beyond", "authors": "Julien Vanegue,Jules Villard,Peter O'Hearn,Azalea Raad", "background": "先前的工作集中在较小规模的基准测试，代码量一般在几十到几百行，这限制了它们的实用价值。一个公司可能拥有的代码量从几千万甚至上亿行不等，因此需要一种能处理大规模程序的工具来验证非停止性（发散）问题。", "innovation": "本文介绍了工具Pulse Infinite，它通过证明技术来展示大规模程序中的非停止性。Pulse Infinite 具有组件化和下界逼近特性，前者支持大型程序的处理能力，后者保证了实现在证明非停止性时的精确性。", "conclusion": "研究所应用的Pulse Infinite成功地处理了超过一亿行的开源和专有软件（C、C++和Hack语言），并发现了超过30个未知的非停止问题，开创了在真实代码库中检测非停止性的新标准。"}
{"llm_update_time": "20250909", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "论文背景介绍了大型语言模型（LLM）- 基础的代理通过迭代推理、探索和工具使用解决复杂任务的过程，但这一过程可能导致长期、昂贵的上下文历史记录。目前为止，像OpenHands或Cursor这样的最先进的软件工程（SE）代理使用基于LLM的总结来解决这一问题，但不清楚这种增加的复杂性是否提供了实际的性能优势，而是简单地忽略了老旧观察结果是否更好。", "innovation": "本文的创新在于系统性地比较了观察结果掩蔽策略和LLM总结策略在SWE-代理与SWE-bench验正上的性能。研究发现，简单的观察结果掩蔽策略可以将成本降低一半，同时在某些情况下甚至超过LLM总结策略的解决率。例如，对于Qwen3-Coder 480B模型，遮掩提升了解决率至54.8%，同时保持与总结策略在较低成本下的竞争力。", "conclusion": "研究结果表明，在至少在SWE-代理与SWE-验正中，最有效的和最有效的上下文管理策略可能是最简单的。研究还释放了代码和数据以供可重复性研究。"}
{"llm_update_time": "20250909", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14333", "html_url": "https://arxiv.org/abs/2503.14333", "title": "使用噪音预期通过强化扩散（NERD）模型揭示不确定性的一级和二级神经表示", "title_en": "Revealing higher-order neural representations of uncertainty with the Noise Estimation through Reinforcement-based Diffusion (NERD) model", "authors": "Hojjat Azimi Asrari,Megan A. K. Peters", "background": "以往的研究主要关注一阶表示（FORs），它们编码观察者环境中的内容和结构。二阶表示（HORs）不太常见，HORs描述FORs的强度或不确定性等特性，可能有助于学习过程。HORs关于不确定性的表示方式可能是基于噪音估计的交错过程，考虑到人们对不确定性的先验预期。然而，大脑如何表示这些预期的不确定性分布仍是一个未解之谜。本研究旨在利用解码神经反馈任务中的神经数据，了解大脑如何通过噪音预期通过强化扩散（NERD）模型进行此类学习。", "innovation": "研究开发并应用了噪音预期通过强化扩散（NERD）模型，以探究大脑如何进行自我噪音学习的过程，展示了NERD模型对人类行为有很高的解释力。", "conclusion": "研究证实，大脑可能利用NERD模型的方式进行不确定性相关的自我学习，并通过这一过程展示了高解释力的行为模式。"}
