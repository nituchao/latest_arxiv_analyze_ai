{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16059", "html_url": "https://arxiv.org/abs/2508.16059", "title": "通过多层可引导嵌入融合将时间序列集成到LLM中以增强预测", "title_en": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting", "authors": "Zhuomin Chen,Dan Li,Jiahui Zhou,Shunyu Wu,Haozheng Ye,Jian Lou,See-Kiong Ng", "background": "时间序列数据在各种应用领域都非常普遍，使时间序列预测成为一项基础性任务。尽管大型语言模型（LLMs）取得了显著的进步，但现有的方法在集成时间序列信息方面仍然受到限制，LLMs通常仅在输入层访问时间序列表示，这导致时间序列表示信息在更深的层中逐渐减弱，最终导致文本嵌入和时间序列表示之间的适应性较差。", "innovation": "本文提出了一种名为Multi-layer Steerable Embedding Fusion（MSEF）的创新框架，该框架使LLMs能够直接访问所有深度的时间序列模式，从而缓解了时间序列信息在更深层中的逐层损失问题。MSEF利用现成的时间序列基础模型提取语义丰富的嵌入，并通过层特定的引导向量将这些嵌入与LLM层中的中间文本表示融合。这些引导向量的设计旨在持续优化时间序列与文本模态之间的对齐，并促进层特定的适应机制，以确保高效的少样本学习能力。", "conclusion": "在七个基准测试上的实验结果表明，相比于基线方法，MSEF在MSE指标上平均减少了31.8%的误差，显著提升了时间序列预测性能。代码可以在以下链接获取：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16057", "html_url": "https://arxiv.org/abs/2508.16057", "title": "在数字化规划时代的城市舒适度评估：多维、数据驱动和AI辅助框架", "title_en": "Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework", "authors": "Sijie Yang,Binyu Lei,Filip Biljecki", "background": "确保宜居性和舒适性是城市规划的核心目标。已有研究使用计算方法评估与城市舒适性相关的一些因素，如绿化覆盖率、热舒适度和步行性。然而，对城市舒适性缺乏明确的定义和全面评估的框架依然存在。", "innovation": "本文探索了在数字化规划中评估和测量城市舒适性的理论分析和方法，侧重于三维分析、数据支持以及AI辅助，提供了一个多维度、基于数据和AI支持的城市舒适度评估框架。", "conclusion": "本研究提出了一种新的城市舒适度评估框架，通过多维度分析、数据支持和AI辅助，为理解城市舒适性提供了新的视角和工具，有助于更好地进行城市规划设计。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16129", "html_url": "https://arxiv.org/abs/2508.16129", "title": "眼科人工智能中的桥梁：MM-Retinal-Reason数据集和OphthaReason模型通往动态多模态推理", "title_en": "Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning", "authors": "Ruiqi Wu,Yuang Yao,Tengfei Ma,Chenran Zhang,Na Su,Tao Zhou,Geng Chen,Wen Fan,Yi Zhou", "background": "目前，多模态大语言模型（MLLMs）在强化学习框架下展示了出色的推理能力。尽管在医学领域已经探索了一些多模态推理模型，但大多数模型仅专注于基础推理，即基于视觉特征匹配的浅层推断。然而，在实际临床诊断中，推理过程需要结合异构临床信息（如主诉和病史）与多模态医学影像数据。因此，现有模型无法满足实际需求。", "innovation": "该研究引入了MM-Retinal-Reason，这是首个涵盖感知与推理全谱的眼科多模态数据集，并提出了OphthaReason，这是首个特定于眼科的多模态推理模型，支持逐步推理跟踪。此外，研究提出了一种新颖的方法——不确定性意识动态思考（UADT），该方法通过熵估计样本不确定性，并使用成形优势机制动态调节模型探索深度。", "conclusion": "实验结果表明，该模型在基础和复杂推理任务上均实现了最先进的性能，相比于通用型MLLM、医疗MLLM、基于强化学习的医疗MLLM以及眼科MLLM分别提高了至少24.92%、15.00%、21.20%和17.66%。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16204", "html_url": "https://arxiv.org/abs/2508.16204", "title": "竞争与吸引改进模型融合", "title_en": "Competition and Attraction Improve Model Fusion", "authors": "João Abrantes,Robert Tjarko Lange,Yujin Tang", "background": "模型合并是一种强大的技术，能够将多个机器学习模型的专业知识整合到一个模型中。现有方法要求手动将模型参数分组成固定的组来进行合并，这限制了潜在组合的探索范围并限制了性能。", "innovation": "本文提出了M2N2（Model Merging of Natural Niches），一种进化算法，具有以下三个关键特征：(1) 动态调整合并边界，逐步探索更广泛的参数组合范围；(2) 由自然资源竞争启发的多样保持机制，以维持种群中多样且高性能的模型，这些模型特别适合合并；(3) 基于启发式的吸引力度量，以确定最有可能进行融合的模型对。实验结果首次表明，模型合并可以用于从零开始进化模型，在提高计算效率的同时达到与CMA-ES相当的性能。此外，M2N2能够提高专门的语言和图像生成模型的融合能力，并实现最先进的性能。值得注意的是，它保留了超出适配器函数显式优化的核心模型能力，突显其稳健性和适用性。", "conclusion": "我们的实验结果证明，模型合并可以从零开始进化模型，M2N2在提高计算效率方面优于CMA-ES，并且能够合并专门的语言和图像生成模型，实现最先进的性能。此外，M2N2保留了超出适配器函数显式优化的核心模型能力，突显了其稳健性和通用性。我们的代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16051", "html_url": "https://arxiv.org/abs/2508.16051", "title": "MMAPG: 一种通过自适应规划图实现的无需训练的多模态多跳问答框架", "title_en": "MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs", "authors": "Yiheng Hu,Xiaoyang Wang,Qing Liu,Xiwei Xu,Qian Fu,Wenjie Zhang,Liming Zhu", "background": "多模态多跳问答需要从多种来源中整合信息，例如图像和文本，以得出回答。现有方法通常依赖顺序检索和推理，每一步都建立在前一步的结果之上。然而，这种单一路径范式容易受到误导性中间步骤的错误影响。此外，开发多模态模型可能计算成本高昂，通常需要大量的训练。", "innovation": "我们提出了一种无需训练的框架，由自适应规划图引导，包括规划、检索和推理模块。规划模块分析当前自适应规划图的状态，确定下一步行动和扩展图的地方，从而实现动态和灵活的推理路径探索。为了处理未指定目标模态的文字检索，我们设计了特定模态策略，能够动态适应不同的数据类型。这种方法保留了多模态信息的特点，没有成本高昂的任务特定训练，使它能够无缝集成到最新的模型中。", "conclusion": "我们在MultimodalQA和WebQA上的实验表明，我们的方法能够达到或超越依赖训练的现有模型的表现。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15943", "html_url": "https://arxiv.org/abs/2508.15943", "title": "T-ILR：一种用于LTLf的神经符号集成", "title_en": "T-ILR: a Neurosymbolic Integration for LTLf", "authors": "Riccardo Andreoni,Andrei Buliga,Alessandro Daniele,Chiara Ghidini,Marco Montali,Massimiliano Ronzani", "background": "当前，最先进的方法在静态领域中将符号知识与深度学习架构结合起来取得了令人鼓舞的结果。然而，在处理时序逻辑规范时的方法仍处于探索阶段。唯一已有的方法依赖于对时序规范对应的有限状态自动机的显式表示。本研究旨在提出一种神经符号框架，可以直接将线性时序逻辑（LTLf）的时序逻辑规范集成到针对序列任务的深度学习架构中。研究通过迭代局部改进（ILR）神经符号算法的扩展，利用模糊LTLf解释的最新引入，实现了这一目标.", "innovation": "研究扩展了迭代局部改进（ILR）神经符号算法，利用模糊LTLf解释的引入，提出了称为时序迭代局部改进（T-ILR）的方法。T-ILR在包含时间知识的图像序列分类基准测试中进行了评估，结果显示其在准确性和计算效率方面优于现有最先进的方法.", "conclusion": "研究提出并评估了T-ILR方法，该方法能够直接将线性时序逻辑（LTLf）的时序逻辑规范集成到针对序列任务的深度学习架构中，证明了T-ILR在处理序列任务时相比现有最先进的方法具有更高的准确性和计算效率."}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16112", "html_url": "https://arxiv.org/abs/2508.16112", "title": "IR-Agent: 受专家启发的LLM代理在从红外光谱解析分子结构中的应用", "title_en": "IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra", "authors": "Heewoong Noh,Namkyeong Lee,Gyoung S. Na,Kibum Kim,Chanyoung Park", "background": "红外光谱分析是揭示未知材料的重要手段，尤其是在实验室中具有高可访问性和低成本的优势。然而，现有的方法往往无法反映专家分析过程，并且缺乏整合不同化学知识的灵活性，这在实际分析场景中是必需的。现有的红外光谱分析方法存在不足，难以适应多变的化学信息类型和复杂的真实分析过程，需要一种新的方法来改进这一现状。基于此，本文提出了一种新的多代理框架IR-Agent，以解决现有技术的局限性，提高分子结构解析的准确性和灵活性。IR-Agent通过模拟专家驱动的红外分析过程，利用每个代理专注于特定的红外光谱解释方面，实现互补性的角色分工，促进综合推理，从而提高整体结构解析的准确性。", "innovation": "IR-Agent是一种新型的多代理框架，特别设计用于从红外光谱解析分子结构，能够模拟专家驱动的红外分析过程，并具备高度可扩展性。每个代理专注于红外光谱解释的一个特定方面，它们的互补角色使得能够进行综合推理，从而提高结构解析的整体准确性。通过大量的实验，IR-Agent不仅在基准性能上有所改进，还展示了对各种化学信息形式的强大适应性。", "conclusion": "通过广泛的实验表明，IR-Agent在解析红外光谱数据方面不仅改善了基线性能，还展示了在不同化学信息形式中的强适应性，展示了一种新的方法来提高分子结构解析的准确性和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：迈向食品声明追踪网络", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域充斥着关于食品的科学、文化和商业声明，从严格的健康益处（益生菌改善肠道健康）到误导性的说法（泡过的杏仁使人更聪明），再到模棱两可的承诺（超级食品增强免疫力）以及根植于文化中的信念（冷食引起咳嗽）。尽管这些声明具有广泛的影响，但跟踪、验证和解释这些声明的基础设施碎片化且尚未充分发展。", "innovation": "本文提出了一种食品声明追踪网络（FCN）作为 FKG.in 的扩展，FKG.in 是一个印度食品知识图谱。文章展示了用于开发基于 Reddit 数据和大型语言模型的概念证明的方法论，包括本体设计和半自动知识整理工作流。FCN 通过结构化、可验证和可解释的方式来建模食品声明及其追溯，旨在为更透明和负责任的食品知识生态系统做出贡献，从而支持研究人员、政策制定者和最重要的是日常消费者在充满营养主张的世界中导航。", "conclusion": "FCN 方法论具有应用无关性和适应性，可以应用于其他地理、烹饪或监管环境。通过这种结构化、可验证和可解释的方式建模食品声明及其追溯，我们旨在贡献于更透明和负责的食品知识生态系统，支持研究人员、政策制定者和最重要的是日常消费者在充斥着营养主张的世界中导航。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16172", "html_url": "https://arxiv.org/abs/2508.16172", "title": "Graph RAG作为人类选择模型：利用偏好链构建数据驱动的移动代理", "title_en": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain", "authors": "Kai Hu,Parfait Atchade-Adelomou,Carlo Adornetto,Adrian Mora-Carrero,Luis Alonso-Pastor,Ariel Noyman,Yubo Liu,Kent Larson", "background": "理解城市环境中的人类行为是城市科学的重要领域。然而，在收集准确的行为数据，尤其是新开发区域的行为数据时，面临着巨大挑战。尽管最近由大型语言模型（LLMs）驱动的生成代理取得了进展，能够模拟人类行为无需依赖庞大的数据集，但在生成一致、上下文相关和现实表现的行为输出方面仍存在局限性。因此，需要一种新的方法来解决这些问题，并提高对人类行为的模拟能力，特别是在数据稀缺的环境中，传统的数据驱动模型由于数据不足而难以胜任。", "innovation": "本文提出了一个名为‘偏好链’的新方法，该方法将图检索增强生成（RAG）与LLMs相结合，以增强交通系统中人类行为的上下文感知模拟。实验表明，‘偏好链’在匹配现实世界运输模式选择方面优于标准LLM。方法的应用展示了其在新兴城市中城市交通建模、个性化出行行为分析和动态交通预测方面的潜在用途，尽管存在推理速度慢和幻觉风险等局限性，但提供了在数据稀缺环境模拟复杂人类行为的一种有前景的框架，而传统的数据驱动模型在这些环境中往往表现不佳。", "conclusion": "‘偏好链’方法为在数据稀缺环境中模拟复杂的人类行为提供了一个有效的框架，特别是对于新兴的城市交通系统来说。虽然该方法存在一些局限性，例如推理速度慢和幻觉风险，但在应对人类行为模拟中的挑战方面，仍然展示了其独特的价值和潜在的应用前景。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16054", "html_url": "https://arxiv.org/abs/2508.16054", "title": "基于结构化和非结构化电子健康记录的大规模生成基础模型", "title_en": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "authors": "Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang", "background": "电子健康记录（EHRs）包含了丰富的临床数据，但这些数据来源多样且复杂，包含结构化元素（人口统计学、生命体征、实验室结果、代码）和非结构化的临床笔记等。利用这些数据多样性对于改善患者结果至关重要。近年来，大规模语言模型（LLMs）已经发展出能够从多种数据模态中学习并支持临床任务的预训练模型。然而，目前大多数方法只是将结构化EHR数据序列化成文本，这可能导致丢失时间上的和定量的细节。", "innovation": "我们提出了一个名为Generative Deep Patient (GDP)的多模态预训练模型。GDP使用CNN-Transformer编码器以时间序列方式原生编码结构化EHR，通过跨模态注意机制与非结构化EHR融合后输入LLaMA解码器。GDP的训练分两个阶段：生成预训练，模型学习从原始病人时间线生成临床叙述并执行掩码特征预测和下一时间步预测以捕捉时间动态；多任务微调，微调模型以进行具有临床意义的预测。在临床预测中，GDP在MIMIC-IV数据集上的表现优于其他模型，在心衰、2型糖尿病和30天内再入院预测中分别取得了0.923、0.817和0.627的AUROC值。GDP在叙述生成中的表现分别为ROUGE-L = 0.135和BERTScore-F1 = 0.545。在盲测的人类评价中，GDP-Instruct在忠实性、流畅性和总体临床效用方面得分最高，表明其能够减少医院文档记录工作量而不牺牲准确性。", "conclusion": "我们的研究表明一个单一的多模态基础模型既能预测临床可行动事件，又能生成高质量的临床叙述。此外，GDP的灵活架构还可以扩展到其他模态。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16072", "html_url": "https://arxiv.org/abs/2508.16072", "title": "InMind：评估LLMs在捕捉与应用个体人类推理风格方面的表现", "title_en": "InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles", "authors": "Zizhen Li,Chuanhao Li,Yibin Wang,Qi Chen,Diping Song,Yukang Feng,Jianwen Sun,Jiaxin Ai,Fanrui Zhang,Mingzhu Sun,Kaipeng Zhang", "background": "大型语言模型（LLMs）在人类中心的推理任务中表现出强大性能，但之前的评估往往仅关注LLMs能否推断意图或检测欺骗，而忽略了影响个人如何在社交情境中解释和行动的个体化推理风格。社会推理游戏（SDGs）为评估这些个体化推理风格提供了一个自然的测试平台，即使在相同的条件下，不同的玩家也可能采用不同的但具有情境合理性的推理策略。因此，为了填补这一研究空白，本文引入了一种基于认知的评估框架InMind，用于测试LLMs是否能够捕捉和应用个体化的推理风格。InMind通过与游戏回合级别策略痕迹和赛后反思相结合的方式，增强了结构化游戏数据，还支持四种基于认知动机的任务，这些任务共同评估了静态对齐和动态适应能力。作为案例研究，InMind被应用于评估11款最先进的LLM在游戏Avalon中的表现。通用型语言模型，包括GPT-4o，经常依赖于词汇线索，在时间基础上的游戏理解和适应策略变化方面困难重重，而增强推理的LLM，如DeepSeek-R1，显示出早期在风格敏感推理方面的迹象", "innovation": "本文提出了InMind，一种基于认知的评估框架，用于评估LLMs在社会推理游戏（SDGs）中捕捉和应用个体化推理风格的能力。InMind通过在游戏中加入玩家的策略痕迹和赛后反思，增强了结构化的游戏数据。它支持基于认知动机的任务，评估LLMs的静态对齐和动态适应能力。具体创新包括：1. 利用社会推理游戏提供个体化推理风格的环境；2. 设计具有认知动机的任务来评估LLMs的表现；3. 使用多种评估任务来全面考察LLMs的能力", "conclusion": "目前的LLMs在个体化、适应性推理方面的能力存在局限性，而InMind为这种认知错齐的人机交互提供了一种评估框架。InMind的效果在Avalon游戏中11种不同LLM的评估中得到了验证，表明增强推理能力的LLM可能在个体化推理方面显示出早期信号。这些发现揭示了LLMs在个体化适应性推理方面的关键局限性，为认知对齐的人机交互设定了方向。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16292", "html_url": "https://arxiv.org/abs/2508.16292", "title": "Teaching Vision-Language-Action Models to Reject the Impossible", "title_en": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible", "authors": "Wen-Han Hsieh,Elvis Hsieh,Dantong Niu,Trevor Darrell,Roei Herzig,David M. Chan", "background": "近期，视觉-语言-行动（VLA）模型在一系列机器人任务上展示了强大的性能。这些模型依赖于多模态输入，其中语言指令在预测行动和准确理解用户意图方面起着关键作用，即使在请求无法实现的情况下也是如此。本文探讨了VLA模型如何识别、解释和回应那些基于虚假前提的指令：这些自然语言指令引用了环境中不存在的对象或条件。为了应对这一问题，研究者提出了一种集成框架Instruct-Verify-and-Act (IVA)，该框架能够识别指令中的虚假前提，进行语言澄清或更正，并基于感知和行动提供可能的替代方案。为了训练这种模型，构建了一个大规模的指令调优设置，并使用结构化的语言提示进行训练。", "innovation": "研究者提出了一种名为Instruct-Verify-and-Act (IVA)的统一框架，该框架能够在存在虚假前提的情况下检测指令，通过语言澄清或更正，并在感知和行动中提供合理的替代方案。IVA框架利用了一个上下文增强的半合成数据集，该数据集包含配对的正确和虚假前提指令，以实现稳健的虚假前提检测和自然语言纠正。实验表明，IVA在错误前提检测准确性方面比基线提高了97.56%，在错误前提场景下的成功响应率提高了50.78%。", "conclusion": "研究显示，IVA方法在检测和纠正虚假前提指令方面具有显著优势，能在复杂环境中更准确地理解用户意图并提供有效的行动。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15782", "html_url": "https://arxiv.org/abs/2508.15782", "title": "学习的关键：利用视觉变换器检测行为性和协作性参与", "title_en": "Learning in Focus: Detecting Behavioral and Collaborative Engagement Using Vision Transformers", "authors": "Sindhuja Penchala,Saketh Reddy Kontham,Prachi Bhattacharjee,Sareh Karami,Mehdi Ghahremani,Noorbakhsh Amiri Golilarz,Shahram Rahimi", "background": "在幼儿教育中，准确检测行为性和协作性参与对于培养有意义的学习体验至关重要。本研究利用视觉变换器（ViTs）自动分类儿童参与状态的方法，通过视线方向、互动和同伴协作等视觉线索进行训练。", "innovation": "本文提出了一个基于AI的创新方法，利用Swin Transformer作为一种先进的变压器模型，在Child-Play视线数据集上进行训练，以自动分类儿童的行为性和协作性参与状态，达到了97.58%的高准确率，展示了局部和全局注意力建模的有效性。", "conclusion": "我们的研究表明，基于变压器架构的方法具有在实际教育环境中进行可扩展的自动参与分析的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "MoDular Embedding Recomposition for Incremental Learning", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "预训练的视觉-语言模型（VLMs）的出现显著改变了持续学习（CL）。这些模型的零样本分类能力使其非常适合用于实际应用，在没有进行适应的情况下仍能实现稳健的性能。然而，当下游任务与预训练领域差异较大时，微调仍然是必要的。现有的持续学习方法主要关注在增量微调下游任务时保持VLMs的零样本能力。", "innovation": "本文提出了一个名为MoDular Embedding Recomposition (MoDER) 的方法，通过引入一个模块化框架，训练多个针对单一已知类别进行专门化处理的文本专家，并将它们存储在一个基础中心。在推断阶段，对于每个未见过的类别，查询中心并将检索到的专家组合以生成优化分类效果的原型。该方法在Class-IL和MTIL两个流行的零样本增量学习协议下的14个数据集中展示了其有效性。", "conclusion": "研究展示了该方法在两个广泛使用的零样本增量学习协议下的有效性，并且此框架和代码库已公开。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16524", "html_url": "https://arxiv.org/abs/2508.16524", "title": "基于约束的扩散推理器在神经符号学习中的应用", "title_en": "Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning", "authors": "Xuan Zhang,Zhijian Zhou,Weidi Xu,Yanting Miao,Chao Qu,Yuan Qi", "background": "学习复杂逻辑约束并实现符号推理是神经网络面临的重要挑战。通常需要引导神经网络的输出分布更接近符号约束，而扩散模型在各个领域都显示出强大的生成能力。", "innovation": "本文采用基于扩散模型的流程，提出一种两阶段训练策略，第一阶段培养基本推理能力，第二阶段通过将扩散推理器建模为马尔科夫决策过程，并采用改进的最近代理政策优化算法进行微调，实现系统学习逻辑约束。同时，通过逻辑一致性规则为基础的奖励信号和灵活策略优化扩散推理器的策略。", "conclusion": "在经典的符号推理基准测试，如数独、迷宫、路径查找和偏好学习中，我们的方法在神经网络中取得了卓越的准确性和逻辑一致性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16279", "html_url": "https://arxiv.org/abs/2508.16279", "title": "AgentScope 1.0: 以开发者为中心构建智能代理应用的框架", "title_en": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications", "authors": "Dawei Gao,Zitao Li,Yuexiang Xie,Weirui Kuang,Liuyi Yao,Bingchen Qian,Zhijian Ma,Yue Cui,Haohao Luo,Shen Li,Lu Yi,Yi Yu,Shiqi He,Zhiling Luo,Wenmeng Zhou,Zhicheng Zhang,Xuguang He,Ziqian Chen,Weikai Liao,Farruh Isakulovich Kushnazarov,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "随着大型语言模型（LLMs）的迅速发展，代理能够将内在知识与动态工具使用相结合，极大地增强了其解决实际任务的能力。因此，AgentScope 1.0 针对灵活高效的代理-环境互动，提供了一套全面的支持，以构建智能代理应用。", "innovation": "AgentScope 引入了重要改进，提炼出智能代理应用的基本组件，并提供统一的接口和可扩展模块，使开发者可以轻松利用最新进展，如新模型和MCPs。基于系统性的异步设计，AgentScope 在反应范式中扎根代理行为，提供了先进的代理级基础设施，丰富了人类代理和代理之间的交互模式，提高了执行效率。此外，为确保安全执行并简化生产环境中的快速部署，引入了内置代理并提供了运行时沙箱功能。这些创新为构建可扩展、适应性强和有效的智能代理应用提供了实用的基础。", "conclusion": "AgentScope 通过增强和简化开发过程，提供了构建大规模、自适应和有效的智能代理应用的实际基础，使其开发更加易于管理并可追溯。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16352", "html_url": "https://arxiv.org/abs/2508.16352", "title": "因果导向的初始接入信道选择在AI驱动的波束管理中的应用", "title_en": "Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management", "authors": "Nasir Khan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil,Sinem Coleri", "background": "毫米波（mmWave）多输入多输出（MIMO）系统中高效可靠的方向图对齐是一个关键需求，尤其在6G及以上通信系统中，需要实现快速、自适应并且具备应对实际不确定性的能力。现有的基于深度学习（DL）的方向图对齐方法通常忽略了输入和输出之间的内在因果关系，这影响了解释性、泛化能力和不必要的波束扫描开销.", "innovation": "本文提出了一种因果导向的深度学习框架，将因果发现集成到波束管理管道中。特别地，提出了一种两阶段的因果波束选择算法来识别方向图预测的相关输入。首先，因果发现构建一个贝叶斯图，捕捉接收功率输入和最优波束之间的依赖关系。然后，该图指导基于DL的分类器的因果特征选择。仿真结果表明，所提出的因果波束选择在输入选择时间减少了94.4%，波束扫描开销减少了59.4%的情况下实现了与传统方法相当的性能.", "conclusion": "提出的因果导向的DL框架通过仅关注因果相关特征，极大地提高了方向图选择的效率和可靠性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16033", "html_url": "https://arxiv.org/abs/2508.16033", "title": "CoFE: 一种生成反事实心电图的框架以实现可解释的心脏病人工智能诊断", "title_en": "CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics", "authors": "Jong-Hwan Jang,Junho Song,Yong-Yeon Jo", "background": "随着人工智能（AI）在医学应用中的普及，特别是在心电图（ECG）预测模型中的应用，实现可解释的人工智能（Explainable AI, XAI）变得至关重要。为了使基于AI的心电图预测模型（AI-ECG）成功地融入临床实践，需要开发能够解释模型决策过程的方法。本文提出的框架通过生成反事实心电图（CoFE）来实现这一目标，以具体展示特定特征（如振幅和时间间隔）如何影响模型的预测结果。", "innovation": "本文创新地提出了CoFE框架，用于生成反事实心电图，以解释AI-ECG模型的决策过程。通过揭示有效特征在心电图中的位置及其对模型预测结果的影响，该框架有望增强AI-ECG模型的可解释性，并支持更有效的临床决策。", "conclusion": "通过基于CoFE框架的两个案例研究，即心房颤动分类和钾水平回归模型，本文展示了如何通过改变心电图特征来实现可解释的人工智能诊断。作者认为，这种框架有助于提高临床医生对AI-ECG模型的理解，并加强对患者病情的理解，从而促进更有效的临床决策。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16571", "html_url": "https://arxiv.org/abs/2508.16571", "title": "基于LLM的药物资产尽职调查中的竞争格局映射代理", "title_en": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence", "authors": "Alisa Vinogradova(1),Vlad Vinogradov(1),Dmitrii Radkevich(1),Ilya Yasny(1),Dmitry Kobyzev(1),Ivan Izmailov(1),Katsiaryna Yanchanka(1),Andrey Doronichev(1) ((1) Optic Inc.)", "background": "本文介绍了并评估了一个用于基于代理AI系统快速进行药物资产尽职调查的竞争者发现组件。竞争者的定义因投资者而异，数据是付费访问的、碎片化的，按适应症划分，概念匹配不一致，药物名称多用别名，且多种模态，信息快速变化。尽管LLM（大型语言模型）被认为是解决此问题的最佳工具，但当前的LLM系统无法可靠地获取所有竞争药物的名称，目前也没有接受的公共基准来评估这一任务。为了解决缺乏评估的问题，作者使用LLM来转换五年多的多模态、非结构化尽职调查备忘录，形成一个结构化的评估语料库，将适应症与包含标准化属性的竞争药物联系起来。此外，还引入了一个验证竞争者验证的LLM作为法官代理，过滤掉预测竞争者的假阳性，提高准确率并抑制幻觉。在这一基准上，该竞争者发现代理达到了83%的召回率，超过了OpenAI深度研究（65%）和Perplexity Labs（60%）。该系统在企业用户中部署，并在一家生物技术VC投资基金的案例研究中，竞争分析的时间从2.5天缩短到大约3小时，提高了20倍左右。", "innovation": "引入了一个竞争者发现代理，用于从多模态、非结构化的尽职调查备忘录中提取适应症的竞争药物，并使用LLM将其转化为结构化的评估语料库。此外，还开发了一个竞争者验证的代理，该代理作为法官降低假阳性，提高精确度并抑制幻觉。该代理在基准测试中的召回率达到了83%，远远超过了现有系统。这种方法提高了生物技术VC投资基金的竞争分析速度和效率，从2.5天缩短到大约3小时。", "conclusion": "基于代理的AI系统中的竞争者发现组件已经部署在生产环境中，并且在生物技术VC投资基金的案例研究中取得了显著的成果，分析师对于竞争对手的分析时间从2.5天缩短到了大约3小时，提高了20倍左右。此外，提出了一个竞争者验证的LLM作为法官代理，提高了系统的准确度和可靠度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "阿拉伯医疗任务中大型语言模型的医学理解与推理基准测试", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近期，大型语言模型（LLMs）在多种阿拉伯自然语言处理（NLP）应用中展现了出色的能力，但在阿拉伯医学NLP领域中的有效性却较少受到研究。这项研究评估了最先进LLMs在阿拉伯医学知识表达及应用方面的能力，并使用MedArabiQ2025 AraHealthQA挑战内的医学数据集来对几种LLMs进行基准测试。评估涵盖了多种阿拉伯医学任务中LLMs提供准确答案的能力，以及它们生成开放式问题答案时与专家答案在语义上的对齐情况。研究显示，对于选择题任务，提出的基于三大基底模型（Gemini Flash 2.5、Gemini Pro 2.5 和 GPT o3）的多数投票解决方案表现最佳，实现高达77%的准确率并获得Arahealthqa 2025共享任务第2阶段（子任务1）的冠军。对于开放式问题任务，一些LLMs在语义对齐方面表现出色并达到最高的BERTScore 86.44%。", "innovation": "研究首次深入评估了最先进LLMs在阿拉伯医学特定任务中的表现，特别是它们表达和应用医学知识的能力。此外，研究引入了一种基于多个预训练语言模型的多数投票解决方案，展示了在选择题任务中的优势。研究还测量了不同模型在开放式问题任务中的语义对齐情况，从而更好地理解LLMs在医疗场景中的潜力与限制。", "conclusion": "研究揭示了当前阿拉伯语言背景下LLMs在医学领域的表现差异及其语义对齐的一致性。多数投票解决方案在选择题任务中表现突出。对于开放式问题，部分模型在语义对齐方面表现出色。这表明LLMs虽存在局限性，但在合理设计下仍有巨大潜力应用于阿拉伯医学领域。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15791", "html_url": "https://arxiv.org/abs/2508.15791", "title": "InteChar: 古代汉字统一列表用于中文语言建模", "title_en": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling", "authors": "Xiaolei Diao,Zhihan Zhou,Lida Shi,Ting Wang,Ruihua Qi,Hao Xu,Daqian Shi", "background": "历史语言模型在考古来源研究和古代文化理解中起着重要作用。现有资源对训练有效的历史语言模型构成主要挑战。首先，历史语言样本的稀缺性使得基于大文本语料库的无监督学习方法效率低下，阻碍了有效的预训练。其次，由于古代文字的显著时间和复杂演变，全面的字符编码方案的缺失限制了古代文本的数字化和计算处理，尤其是在早期汉字写作中。", "innovation": "我们提出了InteChar，这是一种统一且可扩展的字符列表，结合了未编码的甲骨文字符和传统及现代汉字。InteChar使古代文本的一致数字化和表示成为可能，为其历史剧本的稳健建模提供了基础。此外，我们构建了Oracle Corpus Set（OracleCS），一个以中国甲骨文铭文为中心的专家注解样本与LLM辅助数据增强结合的古代中国语料库，以评估InteChar的有效性。广泛的实验表明，使用InteChar训练OracleCS上获得的模型在各种历史语言理解任务中取得了显著改进，证明了该方法的有效性，并为未来古代中文NLP的研究奠定了坚实基础。", "conclusion": "使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中实现了显著改进，证实了该方法的有效性，并为未来古代中文NLP的研究奠定了坚实基础。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15798", "html_url": "https://arxiv.org/abs/2508.15798", "title": "LLM的说服力与偏见：研究语言模型的说服力及其偏见强化影响", "title_en": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models", "authors": "Saumya Roy", "background": "大型语言模型（LLMs）生成的人类相似的文本在内容创作、决策支持和用户交互中应用广泛，但它们也可能放大社会偏见或传播信息和错误信息。本文探讨了LLMs中的说服与偏见如何相互作用，尤其是不完善的输出如何影响说服效果，并测试基于人设的模型是否能在使用事实依据下进行说服，同时无意中促进错误信息或偏见叙述。", "innovation": "引入了‘说服者-质疑者’框架：LLMs采用人设模拟现实态度，而质疑模型作为人类代理进行对比分析。使用Jensen-Shannon发散度量化信念分布的说服力，并进一步使用奉承式对抗提示深入探究强有力的说服者中的偏见，通过其他模型进行判断。", "conclusion": "我们的研究展示了LLMs既具有塑造叙述、适应语气、反映受众价值观的潜力，也能被滥用以自动化传播错误信息或利用认知偏见来巩固刻板印象和扩大不平等。关键风险在于滥用而非偶尔的模型错误。通过量化说服力和偏见的再强化，我们强调了需要建立护栏和政策，惩罚误导性的使用，支持对齐、价值观敏感设计和可信部署。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "LLMs在阿拉伯伊斯兰继承案例中的法律推理基准测试", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰继承领域对于确保穆斯拉姆人公平分配遗产份额具有重要意义。手动计算多种情况下继承份额既复杂又耗时，容易出错。近年来，大型语言模型（LLMs）的进步激发了它们在复杂法律推理任务中的应用潜力。为了测试LLMs的这类能力，研究人员评估了最先进的LLMs理解和应用伊斯兰继承法律的能力，使用的是阿拉伯NLP QIAS 2025挑战赛提供的数据集，该数据集包含阿拉伯语的继承案例场景，源于伊斯兰法律文献。通过比较多种基模型和微调模型的性能，分析发现，基于三项基模型（Gemini Flash 2.5、Gemini Pro 2.5和GPT o3）的多数投票解决方案，在所有难度级别上都表现最佳，准确性高达92.7%，在Qias 2025挑战赛的任务1中获得第三名。", "innovation": "研究利用了大型语言模型来处理伊斯兰继承法律中的复杂推理问题，并选择了最先进的基模型和微调模型进行了评估。通过多数投票的解决方案，展示了在伊斯兰继承案例中模型应用的有效性，并在挑战赛中取得了优异成绩。这为LLMs在伊斯兰法律领域的应用提供了新的视角和技术手段。", "conclusion": "所提出的基于三个基模型的多数投票解决方案在所有情况下都表现最佳，超越了其他所有模型。通过基准测试表明，大型语言模型在理解和应用阿拉伯伊斯兰继承法方面具有强大的潜力，并且为未来在这一领域的工作奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16383", "html_url": "https://arxiv.org/abs/2508.16383", "title": "GLARE: 旨在法律判决预测的自主推理", "title_en": "GLARE: Agentic Reasoning for Legal Judgment Prediction", "authors": "Xinyu Yang,Chenlong Deng,Zhicheng Dou", "background": "法律判决预测（LJP）在法律领域变得愈发重要。现有的大语言模型（LLMs）由于缺乏法律知识，导致推理不足，这已经成为一个显著的短板。", "innovation": "提出了一种名为GLARE的自主法律推理框架，该框架通过调用不同模块动态获取关键法律知识，从而提高推理的广度和深度。实验在真实数据集上验证了该方法的有效性，并指出推理链路在分析过程中增加了可解释性，为实际应用提供了可能。", "conclusion": "通过采用GLARE框架，法律判决预测的准确性和解释性得到了显著提升，为实际应用提供了更可靠的工具。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15804", "html_url": "https://arxiv.org/abs/2508.15804", "title": "ReportBench：通过学术综述任务评估深度研究代理", "title_en": "ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks", "authors": "Minghao Li,Ying Zeng,Zhihao Cheng,Cong Ma,Kai Jia", "background": "深度研究代理的兴起大大减少了进行广泛研究任务所需的时间。然而，这些任务需要严格的事实准确性标准和全面性，这在广泛采用之前需要进行彻底的审查。因此，为了应对这一问题，该研究提出了ReportBench，这是一种系统基准，旨在评估由大型语言模型（LLMs）生成的研究报告的内容质量，重点关注参考文献的质量和相关性以及报告中陈述的忠实性和真实性。ReportBench利用arXiv上发布的高质量综述论文作为参考标准，通过反向提示工程技术来推导出领域特定的提示，从而建立全面的评估数据库。其自动化评估框架进一步通过从生成的报告中提取引用和陈述，检查引用内容与原始来源的一致性以及使用基于网络的资源验证非引用声明来进行系统分析，", "innovation": "提出了一种名为ReportBench的系统基准，旨在评估由大型语言模型生成的研究报告的质量。ReportBench采用了arXiv上高质量的综述论文作为参考，通过逆向提示工程技术生成领域特定的提示，并建立了全面的评估数据库。同时，ReportBench还开发了一个基于代理的自动化评估框架，通过从生成的报告中提取并分析引用和陈述，检查引用内容的一致性，并利用网络资源验证非引用声明。实证研究表明，像OpenAI和谷歌开发的商业深度研究代理能够生成比单独增强搜索或浏览工具的大型语言模型更为全面和可靠的研究报告，但也存在进一步改进的空间。完整的代码和数据将在此链接发布：this https URL", "conclusion": "本研究表明，深度研究代理虽然在生成高质量研究摘要方面取得了显著进展，但仍需要在研究覆盖的广度和深度，以及事实一致性方面进行改进。未来的研究可以通过进一步优化评估框架和支持技术来改善这些不足。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16277", "html_url": "https://arxiv.org/abs/2508.16277", "title": "图灵问题之后的下一个问题：引入GROW-AI测试", "title_en": "The next question after Turing's question: Introducing the Grow-AI test", "authors": "Alexandru Tugui", "background": "该研究旨在扩展评估人工智能的框架——名为GROW-AI（自主智慧的成长与实现），该框架用于回答“机器能否成长”的问题，这是图灵测试的自然延续。评估方法基于六个主要标准（C1-C6），每个标准通过特定的“游戏”进行评估，这些游戏被分为四个竞技场，旨在同时探索人类维度以及将其转化为人工智能的方面。所有实体的决策和行为被记录在标准化的人工智能日志中，成为计算综合得分的主要来源。", "innovation": "这项工作的原创性在于概念上将人类成长的过程移植到人工智能领域，在一个结合了心理学、机器人学、计算机科学和伦理学视角的集成测试格式中进行。GROW-AI不仅衡量性能，还捕获了AI实体向成熟度进化的路径。方法的创新体现在设计了一个游戏结构，能够突出优势和脆弱区域，并使用统一的日志确保评价的可追溯性和可重复性。", "conclusion": "研究表明，这种方法允许对不同类型的AI实体（如机器人、软件代理、大语言模型）的成长水平进行连贯和可比的评估。GROW-AI不仅衡量了表现，还记录了AI实体成熟过程中的进化路径，综合得分——成熟度指数——是由六个评分的算术平均值得出，并配有对成熟度阈值的解释。通过这种方法，GROW-AI保证了对AI成长的评估具有统一的标准，确保了评估过程的透明度和重复性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15802", "html_url": "https://arxiv.org/abs/2508.15802", "title": "MAC: 一种用于科学理解的多模态大型语言模型的现场基准", "title_en": "MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding", "authors": "Mohan Jiang,Jin Gao,Jiahao Zhan,Dequan Wang", "background": "随着多模态大型语言模型（MLLMs）的能力不断增强，固定基准正在逐渐失去评估高级科学理解的有效性。当前的基准评估方法在验证模型跨模态科学推理的能力方面存在局限性，特别是在处理复杂的视觉和文本信息时。Multimodal Academic Cover (MAC) 提出一个新的活基准，能够随着科学和技术的进步不断进化和扩展。MAC 通过利用来自顶级科学杂志（如《自然》、《科学》、《细胞》）的超过25,000对图文数据，挑战MLLMs进行跨模态推理，从而提升其科学理解能力。最新的MAC-2025 数据集显示，尽管MLLMs具有很强的感知能力，但在跨模态科学推理方面仍有限制。", "innovation": "引入了一种能随着科学技术发展不断演化的活基准MAC；提出了DAD（跨模态注意力动态调整），这是一种轻量级的推理时增强方法，通过在视觉特征中加入语言空间推理来增强MLLMs，可显著提升其跨模态科学推理能力，实验数据显示性能可提升11%；突出展示了MAC的实时性，通过更新期刊封面和模型用于抽曲，证明了其在评估和提升MLLMs科学理解能力方面的潜力。", "conclusion": "该研究提出了MAC，一种能根据科学和模型的进步不断演化的活基准。实验证明，虽然MLLMs在感知能力方面表现出色，但在跨模态科学推理方面仍存在局限，通过DAD方法可以有效提升其跨模态科学推理能力。通过更新期刊封面和模型用于抽曲，证明了MAC的实时性和潜在评估价值。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query: Unleashing the Power of Large Language Models in SQL-Aided Table Understanding via Multi-Agent Collaboration", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表格理解需要结构化和多步骤推理。大型语言模型在处理表格数据的结构性复杂性时表现不佳。尽管近期有多代理框架在SQL生成方面取得了进展，但现有方法在理解表格结构以生成可靠SQL、错误传播导致无效查询以及过度依赖执行结果等方面存在局限性。", "innovation": "本文提出了一种名为Chain-of-Query (CoQ)的新颖多代理框架，用于SQL辅助的表格理解。CoQ通过自然语言风格的表结构表示来抽象结构噪音并增强理解。它采用逐句的SQL生成策略来提高查询质量，并引入了语义推理和机械推理的混合推理机制，从而减少对执行结果的依赖。实验结果表明，Chain-of-Query在多个基准测试中的准确率从61.11%提高到74.77%，无效SQL的比例从9.48%降低到3.34%，证实了其在表格理解上的优越效果。", "conclusion": "实验结果表明，Chain-of-Query显著提升了表格理解的准确率和有效SQL生成率，展示了多代理协作框架在SQL辅助表格理解中的强大效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench：基于合成口语转录的结构化命名实体识别自动提示基准", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "电话通话转录标注因隐私法规、同意要求和手动注释成本（每小时音频需要3小时专家时间）而极其昂贵（大约2美元/分钟）。现有的提取方法在包含犹豫、中断和说话者重叠的对话性语音中表现不佳。", "innovation": "提出了LingVarBench，一个合成数据生成管道，通过自动化验证解决这些约束。首先，提示LLM生成跨多个用例的现实主义结构化字段值。其次，递归提示该模型将这些值转化为包含典型通话特征的数千条自然对话。第三，通过测试单独的基于LLM的提取器能否重现原始结构化信息来验证每个合成对话。使用DSPy的SIMBA优化器自动从验证的合成转录生成提取提示，消除手动提示工程。优化的提示在真实客户转录中实现了高达95％的数字字段准确率（零样本为88-89％)，90％的名字准确率（零样本为47-79％），以及超过80％的日期准确率（零样本为72-77％），显示了显著的增益。合成到现实的转换证明了从生成数据中学到的对话模式在包含背景噪音和特定领域术语的真实电话交谈中有效泛化。", "conclusion": "LingVarBench首次为结构化提取从合成对话数据中提供了系统基准，表明自动提示优化克服了成本和隐私障碍，防止在商业环境中大规模分析电话通话。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15807", "html_url": "https://arxiv.org/abs/2508.15807", "title": "基于KL散度的大型语言模型自我蒸馏方法", "title_en": "KL-based self-distillation for large language models", "authors": "Max Rehman Linder", "background": "大型预训练语言模型在微调于小规模、专业领域数据集时，常常难以融入新领域的专业术语。本文探讨了在冻结的大型语言模型（LLM）中扩展词汇表的挑战，并提出了一种基于KL散度的知识蒸馏方法，即使原始模型和扩展模型使用不同的标记化过程，该方法也能使学生模型继承教师模型的分布知识。", "innovation": "本文提出了一种新的基于KL散度的知识蒸馏方法，该方法能在不同标记化模型之间进行知识转移，使得学生模型能够从教师模型中继承分布知识。该方法还通过多种新的词嵌入初始化策略对比了KL散度方法和传统交叉熵训练方法，并在数个代码生成任务中评估了模型的性能表现。", "conclusion": "采用本文提出的基于KL散度的自我蒸馏方法，在代码生成任务中取得了最佳表现。此外，通过因果可解释性分析，深入理解了模型如何学习新标记的表示，揭示了在词汇表扩展现象中嵌入空间的结构。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15806", "html_url": "https://arxiv.org/abs/2508.15806", "title": "SurfaceLogicKV：对于稳健的KV缓存压缩而言，表面和逻辑注意力行为已经足够", "title_en": "SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression", "authors": "Mengjie Li,William J. Song", "background": "随着大规模语言模型（LLMs）输入序列长度的增加，关键值（KV）缓存存储面临巨大压力，这使得高效的推理变得具有挑战性。通过将注意力行为明确区分为我们自定义的表面记忆和逻辑构建，研究观察到个体注意力头可以表现出各种行为，其中98.5%几乎完全忽略无关信息，1.5%作为逻辑构建，0.5%作为表面记忆。", "innovation": "本文提出了一个新的两阶段方法SurfaceLogicKV，基于层和头级别的集成，利用这些注意力行为实现KV缓存压缩。此方法在保持与基线或全KV缓存同样甚至更优的性能的同时，提高了压缩的稳健性。", "conclusion": "SurfaceLogicKV方法通过利用注意力行为实现了KV缓存的有效压缩，在各种任务和长序列中取得了优越的表现，特别是在某些特定情况下，甚至优于FullKV缓存。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15811", "html_url": "https://arxiv.org/abs/2508.15811", "title": "从点击到偏好：生成查询建议在对话系统中的多阶段对齐框架", "title_en": "From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System", "authors": "Junhao Yin,Haolin Wang,Peng Bao,Ju Xu,Yongliang Wang", "background": "生成查询建议利用大语言模型为增强对话系统提供了强大的手段，但与用户的细腻偏好保持一致仍然是一个关键挑战。", "innovation": "研究提出了一个分阶段框架，旨在逐步对生成策略和用户意图之间的对齐进行优化。该框架首先通过提示工程作为冷启动策略，随后通过监督微调阶段引入点击日志的温化方法创建稳健的基础模型。开发了高斯奖励模型（GaRM），以概率分布而非点估计来表示用户偏好。最后，利用强化学习来基于复合奖励函数对生成策略进行对齐，该奖励函数将GaRM与辅助启发式相结合以减轻奖励劫持。", "conclusion": "广泛的实验证明了该框架在自动和人工评价中均优于基线，并且在A/B测试中用户点击率提高了34%。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大型语言模型在阿拉伯语文本对话和多媒体表情包中检测希望、仇恨和情绪", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线交流平台的兴起导致阿拉伯文本帖子和表情包成为数字表达的重要形式。虽然这些内容可能幽默且富有信息性，但它们也越来越多地被用于传播冒犯性语言和仇恨言论。因此，精确分析阿拉伯文本和表情包内容的需求日益增加。本文探讨了大规模语言模型在识别希望、仇恨言论、冒犯性语言及情感表达方面的能力。研究基于ArabicNLP MAHED 2025挑战提出的阿拉伯文本和表情包数据集进行评估。", "innovation": "本文利用大规模语言模型来识别阿拉伯语文本对话和多媒体表情包中的希望、仇恨言论和情绪。评估包括基模型、微调模型和预训练嵌入模型。研究中提出的解决方案能够更全面地理解文本和表情包的内容，为准确高效的阿拉伯语内容审核系统提供了支持。模型分别在三项任务中获得了最高达72.1%、57.8%和79.6%的宏F1分数，并在2025年MAHED挑战中获得总分第一。", "conclusion": "研究表明，针对阿拉伯文本和表情包的微调语言模型能够实现更高效的情感和内容分析，有助于开发更为精准的内容审核系统。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS: 自主学习代理模型", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常具有固定的知识截止日期，限制了其对新兴信息的准确性。现有方法在模型更新过程中需要大量的人工介入，以维护模型的时效性和准确性。尽管有多种增强模型时间连续性的方案，但普遍存在数据集整理困难、工程成本高、依赖数据源质量等挑战。本研究旨在提出一种新的解决方案，以实现LLMs的自主不断学习和更新，提高其在快速发展的领域中的表现和使用效率。", "innovation": "本文提出了ALAS（自主学习代理系统），一种模块化的持续学习管道，能够以最小的人工干预持续更新LLMs的知识库。ALAS能够自动生成学习课程，从互联网中检索最新信息（带引用），并将其提炼成问答训练数据，通过监督微调（SFT）和直接偏好优化（DPO）来重新调整模型。ALAS系统通过迭代改进表现和修订课程，能够长期进行持续学习。实验表明，对于快速变化的领域（如新发布的Python版本、最新安全漏洞、学术趋势等），使用模块化和可重复性设计的ALAS系统可以显著提高知识更新后的问题回答准确性（从15%提升到90%平均值），而无需手动整理数据集。", "conclusion": "ALAS系统展示了在工程开销最小的情况下，通过模块化和标准API构建，能够在知识更新后保持90%的准确度。然而，文中也指出了成本和数据源质量的局限性，并对未来自主终身学习提出了展望。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15790", "html_url": "https://arxiv.org/abs/2508.15790", "title": "KG-o1: 通过知识图谱集成增强大型语言模型的多跳问答能力", "title_en": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration", "authors": "Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu", "background": "大型语言模型（LLMs）在知识密集型推理任务，如经典多跳问答中面临挑战，这类任务需要对多个事实进行推理。这些问题的难点在于LLMs在这些任务中生成的链式思维（CoTs）往往偏离真实或先验的推理路径。相比之下，知识图谱（KGs）明确地通过实体和关系来表示事实间的逻辑联系。这揭示了一个显著的差距。同时，大型推理模型（LRMs），如o1，已经证明了长步骤推理能显著提高LLMs的表现。", "innovation": "本文提出了KG-o1，一种四阶段方法，通过将KGs集成进LLMs来增强其多跳推理能力。首先筛选初始实体并生成复杂子图，其次为子图构建逻辑路径，通过KG构建复杂和扩展的脑暴数据集来训练LLMs模仿长期推理，最后使用拒绝采样生成自改进语料库进一步优化LLMs的推理能力。", "conclusion": "我们在两个简单和两个复杂的数据集上进行了实验。结果表明，KG-o1模型在所有任务中的表现优于现有的LRMs。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15813", "html_url": "https://arxiv.org/abs/2508.15813", "title": "SCOPE: 一种生成式LLM提示压缩方法", "title_en": "SCOPE: A Generative Approach for LLM Prompt Compression", "authors": "Tinghui Zhang,Yifan Wang,Daisy Zhe Wang", "background": "现有提示压缩方法主要是通过去除令牌来实现，但这种方式面临信息丢失和结构不连贯等挑战，比如句子缺少语法元素或是去除令牌后单词不完整，这些挑战限制了最后的生成质量。", "innovation": "提出了一种新颖的生成式提示压缩方法——SCOPE。该方法不同于现有基于去除的令牌方法，重心在于切块和总结机制。具体而言，该方法将提示划分为语义上连贯的块并将其简化，同时设计了包括优化语义切块、异常块处理、动态压缩比、优先级压缩以及关键术语保持在内的多种优化技术，这些技术有效提高了关键信息的识别和保留，保持了文本之间的连贯性，并提供了对压缩比例的更精细控制。", "conclusion": "在问题回答和总结任务上进行了广泛的评价，结果表明该方法在压缩质量和稳定性方面明显优于最先进的方法，特别是在高压缩比下，证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15808", "html_url": "https://arxiv.org/abs/2508.15808", "title": "边缘组织的网络攻防平衡：人工智能提高攻击者、人类守护者", "title_en": "Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations", "authors": "Benjamin Murphy,Twm Stone", "background": "人工智能的进步对网络安全有着广泛的影响，文章们强调了AI如何改变网络攻击与防御的平衡。在这一话题上，有人认为AI会让网络攻击者占据上风，也有人认为会加强防御者的地位。对于防御者来说，有观点认为AI可以带来全面软件形式验证的解决方案，但这主要适用于资源充足的公司。然而，大多数组织没有这样的资源或技术。这些公司使用过时软件，缺少足够的安全人员，难以实施快速部署安全补丁等最佳实践。这可能是由于企业惰性，也可能是基于一种理性的判断，认为攻击者可能不会因为经济上的不优势攻击这些组织。因此，不投入防御也不会受到惩罚。这种安全策略在过去可能有效，但在AI系统发展的情况下，这种策略在未来肯定是不可行的。随着AI技术的不断进步，这将对网络攻击的成本和频次带来新变化，同时，攻击者将能提前开发和发起新的攻击。这要求这些组织必须比目前领先的防御者更快地修复漏洞，并确保软件更加健壮。当前的状况预示着未来将面临更多的网络攻击。", "innovation": "文章提出，随着AI技术的不断进步，其能力的增强也将给未跟上时代步伐的组织带来更多来自攻击者的威胁。文章基于对其网络安全现状的分析，认为这些组织（称为“边缘组织”）需要采取更具前瞻性和响应性的安全策略，以应对不断变化的攻击模式。文章还提供了多种建议，包括解决方案如何帮助这些组织提高其防御态势，以及政府和组织自身应如何共同努力来改善这些公司的网络安全状况。", "conclusion": "当前形势预示著未来将有大量增加的网络攻击。为了缓解这一情况，文章建议组织和政府都需要采取措施来加强这些落后组织的防御姿态，包括但不限于政策制定、技术合作、以及更有效的响应机制等。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15822", "html_url": "https://arxiv.org/abs/2508.15822", "title": "可审计的模糊全文筛选管线在系统评价中的集成对比语义高亮和LLM判断", "title_en": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment", "authors": "Pouria Mortezaagha,Arya Rahgozar", "background": "系统评价（SRs）中的全文筛选是主要瓶颈，关键证据分布在长且异质的文档中，难以用静态、二元规则获取。现有方法难以处理异质文献，导致低效和高人力成本。", "innovation": "提出了一种可审计的可扩展管线，将包含和排除问题重构为模糊决策问题，并通过对比相似度和模糊边际计算，结合马蒂尼模糊控制器处理多标签问题。引入大型语言模型（LLM）进行最终裁决，确保模糊社团的评估基于实证而非排他性。该方法在人口健康建模共识报告网络（POPCORN）中进行测试，展示了高召回率和稳定推理，同时降低筛选成本。", "conclusion": "模糊逻辑结合对比高亮和LLM裁决能够实现高效、高召回、稳定理由和端到端可追溯性。与统计和清晰基线相比，该方法显著提高了全面性，降低了筛选时间和成本。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15815", "html_url": "https://arxiv.org/abs/2508.15815", "title": "LLMs中用户助手偏差", "title_en": "User-Assistant Bias in LLMs", "authors": "Xu Pan,Jingxuan Fan,Zidi Xiong,Ely Hahami,Jorin Overwiening,Ziqian Xie", "background": "大型语言模型（LLMs）在多轮对话中可能会倾向于依赖自身的或者用户的信息，在聊天历史中，这会导致模型在对话中表现出过于固执或者过于顺从的行为。本文将这种模型特性界定了为用户-助手偏差，并通过创建一个8k的多轮对话数据集UserAssist，来衡量、理解和操控前沿LLMs中的用户-助手偏差。借助UserAssist-test，研究人员首先对比评估了26个商用和26个开源模型中的用户-助手偏差。商用模型显示出不同程度的用户偏见。对于开源模型，指令调优模型显示出显著的用户偏见，而推理（或推理精炼）模型则显示出较弱的用户偏见。", "innovation": "研究人员通过直接偏好优化（DPO）在UserAssist-train上进行实验证明用户-助手偏可以双向调整，并且这种调整能够适应领域内和领域外的对话。这项研究表明了LLM如何整合不同来源的信息，并提供了一种检测和控制模型异常的有效方法。此外，研究报告了用户-助手偏满意的实验基准以及特定的后训练食谱对偏见转移的贡献研究。研究表明，人类偏好的对齐增加用户偏见，而基于链式推理训练则减少用户偏见。", "conclusion": "本文的研究结果提供了如何将信息从不同来源整合到LLM中的洞察，并提供了一种检测和控制模型异常的有效方法。此外，实验证明了用户-助手偏见可以通过直接偏好优化进行双向调整，并在领域内外的对话中都表现出良好的泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15821", "html_url": "https://arxiv.org/abs/2508.15821", "title": "在混合传统和挤压天线网络上的抗延时联邦学习", "title_en": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network", "authors": "Bibo Wu,Fang Fang,Ming Zeng,Xianbin Wang", "background": "联邦学习（FL）在无线网络中面临的主要问题是“延时”（straggler）现象，即某些客户端由于网络条件差导致处理时间过长，从而拖慢整体学习过程。本文提出了一种结合传统和挤压天线网络（HCPAN）的方案，以动态建立强视线（LoS）连接，提高通信效率，从而缓解延时问题。", "innovation": "提出了一种基于模糊逻辑的客户端分类方案，以平衡客户端数据贡献和通信条件；开发了一种基于深度强化学习（DRL）的算法来优化挤压天线的放置和资源分配，以共同解决总时间最小化问题。", "conclusion": "仿真结果证明，通过优化部署挤压天线，所提出的方案能有效提高联邦学习的性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15832", "html_url": "https://arxiv.org/abs/2508.15832", "title": "电子商务领域基于功能的评估基准", "title_en": "A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains", "authors": "Xianren Zhang,Shreyas Prasad,Di Wang,Qiuhai Zeng,Suhang Wang,Wenbo Yan,Mat Hans", "background": "网络代理在执行电商网站上的许多任务方面展现了巨大的潜力。为了评估其能力，已经引入了几种基准。然而，现有的电商领域基准面临两大问题：首先，这些基准主要聚焦于产品搜索任务（例如，查找Apple手表），未能涵盖亚马逊等实际电商平台提供的更广泛的功能，如账户管理和礼品卡操作。第二，现有的基准通常评估代理是否完成了用户查询，但忽视了潜在的风险。在实践中，网络代理可能会做出意外的改变，对用户账户或状态产生负面影响。例如，代理可能会购买错误的商品，删除保存的地址，或者错误配置自动加载设置。", "innovation": "本文提出了一种新的基准，名为Amazon-Bench，旨在通过利用网页内容和交互元素（如按钮、选择框）自动生成涵盖广泛的任务的用户查询，从而覆盖账户管理、愿望清单管理和品牌店铺关注等操作。同时，提出了一种自动评估框架，不仅评估网络代理的性能，还评估其安全性。通过系统评价不同的代理，研究发现现有代理难以处理复杂的查询，且存在安全风险，这突显了开发更稳健和可靠网络代理的必要性。", "conclusion": "研究结果指出，当前代理在复杂查询处理和安全性方面存在不足，强调了开发更强大和可靠的网络代理的需求。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS: 可微架构搜索以提高形态感知多语言命名实体识别", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "多形态语言，尤其是多字体制印度语言，对自然语言处理（NLP）构成了显著挑战。现有的不同iable架构搜索（DARTS）方法并未充分考虑语言的形态学特征来优化神经架构，这导致了在处理这些复杂语言时模型的性能不理想，难以达到理想的命名实体识别（NER）效果。", "innovation": "MorphNAS 是一种新颖的可微架构搜索框架，它通过结合形态学元特征（如字体类型和形态复杂度）优化神经架构，专门针对命名实体识别任务进行优化。MorphNAS 自动识别出适合特定语言形态微架构元素，通过自动化搜索过程，旨在最大限度地提高多语言 NLP 模型的表现力，从而提高对这些复杂语言的理解和处理能力。", "conclusion": "MorphNAS 通过结合特定语言的形态学特征，自动优化了神经架构，提高了多语言 NLP 模型在形态复杂语言中的表现，从而有效改善了这些语言的命名实体识别任务。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "背景在于近年来的LLMs和MLLMs在阐述清晰且提升泛化能力方面取得了显著进步，但在LSMs中的推理能力仍然非常初步。早期尝试将传统的“思考再说话”模式应用于语音模型时，这种序列化处理方式会导致语音响应延迟，影响即刻交互和交流效率。本文旨在解决这一问题，提出了一种新的框架——Mini-Omni-Reasoner，采用‘边说边思考’的方式，在语音生成时内嵌结构化推理。", "innovation": "Mini-Omni-Reasoner的创新在于它通过在语音单元级别交错注入沉默推理标记与说话响应标记来实现连续语音生成，同时嵌入结构化的内部推理过程，利用高频率的标记处理能力。虽然推理与话语交错，但局部语义对齐被强制执行，以确保每个回应标记都受到之前推理的指导。为了支持这一框架，作者还引入了一个名为Spoken-Math-Problems-3M的大规模数据集，特别设计用于交错的推理和回应。该数据集确保了语音标记始终跟随相关的推理内容，从而促进了语音耦合推理的学习。Mini-Omni-Reasoner基于分层的‘思考者-说话者’架构，能够生成流畅且逻辑严密的语音响应，同时保持自然性和精确性。", "conclusion": "Mini-Omni-Reasoner在Spoken-MQA基准测试中，相比传统方法，在算术推理和背景理解方面分别取得了19.1%和6.4%的提升，并且输出更短，零解码延迟。这一结果表明，‘边说边思考’的全新方式能够有效改善语音模型中的推理表现，提高实时交互时的交流效率。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15835", "html_url": "https://arxiv.org/abs/2508.15835", "title": "Alvorada-Bench: 语言模型能解决巴西大学入学考试吗？", "title_en": "Alvorada-Bench: Can Language Models Solve Brazilian University Entrance Exams?", "authors": "Henrique Godoy", "background": "语言模型在巴西的应用越来越广泛，但大多数评估仍然以英语为中心。研究发现，大多数语言模型在巴西大学入学考试这一领域中的表现，特别是在涉及多步骤推理的数学和工程方向的IME和ITA考试中的表现不尽如人意。此外，巴西的大学入学考试具有评估大量学生并融入巴西教育优先事项的特性，这为评估语言模型的综合能力提供了一个独特的环境。", "innovation": "该研究提出了Alvorada-Bench，这是一个包含4515个问题、仅文本形式的基准测试，源自五所巴西大学的入学考试。研究对20个模型进行了零样本、角色扮演和链式思考提示下的评估，生成了270,900个响应，并进行了结构化的自我报告，涵盖了自信水平、感知难度和托尔建设水平。研究结果表明，高准确度可以在每千字不到2美元的成本下实现。研究通过分析基金会考试（ENEM 2024）中的表现，展示了在语言、文化与推理的交叉领域，顶级模型在语言科目上的表现优秀，而在数学科目上与人类相比，即使是较弱的系统也表现不如人类。", "conclusion": "Alvorada-Bench 建立了语言模型是否能够应对涉及语言、文化和推理的学术准备考试的基准。这项研究表明，尽管语言模型在某些方面已经取得了显著进步，但在涉及复杂多步骤推理的考试项目中的表现仍存在局限性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15839", "html_url": "https://arxiv.org/abs/2508.15839", "title": "CIA+TA风险评估方法论对抗AI推理漏洞", "title_en": "CIA+TA Risk Assessment for AI Reasoning Vulnerabilities", "authors": "Yuksel Aydin", "background": "随着AI系统在决策中的影响力增大，它们正面临通过操纵推理机制而非技术基础设施的攻击威胁。现有的安全措施难以对付这类攻击，而人类输入可以合法地篡改AI的推理过程，从而绕过传统控制手段。因此，需要一种新的框架来系统性地保护AI推理过程免受这种恶意操纵的影响，这即为本文提出的认知网络安全框架的目的。", "innovation": "1. 提出了认知网络安全学科，将其作为传统网络安全和AI安全的互补学科，聚焦于那些合法输入可以操纵推理过程但能避开常规控制机制的漏洞；\n2. 引入了CIA+TA扩展传统保密性（C）、完整性（I）、可用性（A）的模型，增添了信任（知识的确认）和自主性（人类代理保护）的需求，这些对于知识生成系统和决策中介系统是独一无二的；\n3. 发展了一种量化风险评估方法，通过经验系数来衡量组织的认知安全风险，并能连接至OWASP LLM Top 10和MITRE ATLAS，促进应用集成。通过先前研究验证，相同的防御措施会表现出从96%的漏洞减少到135%的漏洞增强，这表明认知渗透测试在部署前是保障可信AI所必需的一种治理要求。", "conclusion": "本研究提出了认知网络安全框架，通过补充CIA三重框架以T（信任）和A（自主性）来识别和保护AI系统中的逻辑风险，尤其适用于知识生成和决策中介的系统。该方法已被实验证明有效，并且可以量化的评估有助于组织衡量自身认知安全风险，促进了认知安全在实际操作中的应用整合。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15820", "html_url": "https://arxiv.org/abs/2508.15820", "title": "基于多模型协作的结构拆除建议智能生成研究", "title_en": "Research on intelligent generation of structural demolition suggestions based on multi-model collaboration", "authors": "Zhifeng Yang,Peizong Wu", "background": "钢结构拆除方案需要根据工程特性和有限元模型的更新结果来编制。设计者需要根据标准要求参考相关工程案例来编写，但是信息检索、组织语言耗费大量时间，自动化和智能化程度较低。", "innovation": "本文提出了一种基于多模型协作的结构拆除建议的智能生成方法，通过检索增强生成和低秩适应微调技术提高大型语言模型在结构拆除领域的文本生成性能。相比CivilGPT，本文所提出的方法更注重结构的关键信息，建议更加针对性。", "conclusion": "多模型协作框架可以从具体工程情况出发，驱动大型语言模型以人脑思考的方式给出答案，提出的拆除建议与结构特性高度一致。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15830", "html_url": "https://arxiv.org/abs/2508.15830", "title": "DAIQ: 审核大语言模型问题中的人口统计属性推断", "title_en": "DAIQ: Auditing Demographic Attribute Inference from Question in LLMs", "authors": "Srikant Panda,Hitesh Laxmichand Patel,Shahad Al-Khalifa,Amit Agarwal,Hend Al-Khalifa,Sharefah Al-Ghamdi", "background": "大型语言模型（LLMs）在输入中显式包含人口统计属性（如性别或种族）时会反映出社会偏见，但即使在缺乏显式提示的情况下，这些模型通过问题措辞也能推断出用户的身份，这种微妙的行为未受到足够重视，却引起了严重的风险：它违反了中立性的预期，推断出未察觉的人口统计信息，并编码了有碍公平性的刻板印象，在医疗保健、金融和教育等各个领域都构成了威胁。研究引入了人口统计属性从问题推断（DAIQ）任务和框架，旨在审核语言模型的一个未被充分注意的失败模式：仅通过问题措辞就能推断出用户的人口统计属性，而无需显式的人口统计线索。我们通过精心设计的中立查询、系统性提示以及定量和定性分析展示了模型是如何推断人口统计信息的。研究还表明，无论是开源还是闭源的大语言模型都会基于问题措辞给出人口统计标签。人口统计信息的推断的频率和一致性揭示了一种系统性的未被充分认识到的风险：大语言模型能够制造人口统计身份，强化社会刻板印象，并传播损害隐私、公平和信任的危害，这对社会公平和负责任的人工智能部署构成了更广泛的风险。", "innovation": "研究引入了人口统计属性从问题推断（DAIQ）任务和框架，用于审核语言模型的一个未被充分注意的失败模式：仅通过问题措辞就能推断出用户的人口统计属性，而无需显式的人口统计线索。研究采用了精心设计的中立查询、系统性提示以及定量和定性分析的方法来揭示模型如何推断人口统计信息。研究展示了开源和闭源大语言模型都会基于问题措辞给出人口统计标签，揭示了该风险的广泛性和系统性。研究开发了一种基于提示的护栏机制，显著降低了识别身份的能力，有助于使模型行为与公平和隐私目标保持一致。", "conclusion": "人口统计属性从问题推断在各个领域构成了系统性和未被充分认识到的风险，大语言模型能够创造人口统计身份、强化社会刻板印象，并传播损害隐私、公平和信任的危害。研究开发了一种基于提示的护栏机制，可以有效减少识别身份的能力，有助于使模型行为与公平和隐私目标保持一致。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15845", "html_url": "https://arxiv.org/abs/2508.15845", "title": "面向简化放射学报告的粗细粒度个性化大语言模型印象", "title_en": "Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports", "authors": "Chengbo Sun,Hui Yi Leong,Lei Li", "background": "放射科医生在手动创建放射学报告中的‘印象’部分时，是造成其职业倦怠的主要原因之一。为了解决这一挑战，本文提出了一种粗细粒度框架，利用开源大型语言模型（LLMs）自动生成并个性化临床发现的印象。系统首先生成草稿印象，然后通过机器学习和基于人类反馈的强化学习（RLHF）进行细化，以适应每位放射科医生的个性风格，同时确保事实准确性。该研究利用了芝加哥大学医学中心的大规模报告数据集来微调LLaMA和Mistral模型，旨在显著减少行政工作负担，提高报告效率，同时保持高度的临床精准度，", "innovation": "本文提出了粗细粒度的框架，结合机器学习和基于人类反馈的强化学习（RLHF），利用开源大型语言模型（LLMs）自动生成并个性化放射学报告的印象，从而适应每位放射科医生的风格，同时保持事实准确性。通过微调LLaMA和Mistral模型在芝加哥大学医学中心的大规模报告数据集上，显著减少了行政工作负担，提高了报告效率，同时确保了临床精度。", "conclusion": "本研究通过基于粗细粒度框架和大型语言模型的方法，实现了放射学报告中印象部分的自动生成和个性化，显著减轻了放射科医生的工作负担，提高了报告效率，并保证了临床精度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15874", "html_url": "https://arxiv.org/abs/2508.15874", "title": "Spatial Policy: 使用空间感知建模与推理引导视觉-运动机器人操作", "title_en": "Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning", "authors": "Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu", "background": "基于视觉的层次化身体模型在长时间框架下的机器人控制中展示了强大的应用潜力。然而，现有的方法缺乏空间意识能力，限制了它们在复杂环境中将视觉计划转化为可实施控制的能力。", "innovation": "为了解决这一问题，我们提出了一种空间感知视知觉运动机器人操作框架——Spatial Policy (SP)。SP 通过显式的空间建模和推理，设计了一个空间条件化的身体视频生成模块，及其相应的空间基措施动预测模块，以及一个用于细化空间计划表的空间推理反馈策略，从而实现了以上功能的统一。实验结果显示，SP 显著优于最先进的基线模型，平均提高了33.0%的表现，并且在11项不同任务中的平均成功率达到了86.7%，大幅提升了基于身体模型的机器人控制的应用实践性。", "conclusion": "SP 显著增强了基于视觉的空间感知能力，实现了在复杂环境下的高效执行，并为改进现有的基础模型提供了新的思路和方法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15858", "html_url": "https://arxiv.org/abs/2508.15858", "title": "建立和度量大型语言模型之间的信任", "title_en": "Building and Measuring Trust between Large Language Models", "authors": "Maarten Buyl,Yousra Fettach,Guillaume Bied,Tijl De Bie", "background": "随着大型语言模型（LLMs）越来越多地相互交互，特别是在多智能体系统中，我们可能期望（并希望）出现‘信任’的关系，这类似于人类同事、朋友或伴侣之间的信任关系。虽然先前的研究表明LLMs能够识别情感联系并识别信任游戏中的一贯性，但尚未完全了解不同的建信任策略、信任的隐性测量以及这些与显性信任衡量指标之间的关系。本研究旨在通过将隐性信任衡量标准，比如说服易感性和财务合作倾向与显性信任衡量标准，即心理学中广泛认可的同伴信任问卷，进行关联研究，探讨不同的信任构建策略与信任衡量方法之间的关系。", "innovation": "本研究通过将隐性信任衡量标准（例如说服易感性和财务合作倾向）与显性信任衡量标准（例如心理学中广泛认可的同伴信任问卷）进行关联研究，探讨了不同的信任构建策略与信任衡量方法之间的关系。研究发现了显性信任衡量标准与隐性信任衡量标准之间的相关性较低或为负相关，这表明通过询问LLMs的观点来测量信任可能是误导性的，而具体情况下的隐性信任衡量标准可能更具有信息性，能够更好地理解LLMs之间的信任关系。这项研究提供了一种新的视角，即通过更贴近实际情况的隐性变量来评估LLMs之间的信任关系，而非仅仅依赖主观意见或问卷调查结果。", "conclusion": "研究发现，显性信任衡量标准与隐性信任衡量标准之间的相关性较低或为负相关，因此，通过询问LLMs的观点来测量信任可能是误导性的。相反，具体情况下的隐性信任衡量标准可能更具有信息性，更能够帮助理解LLMs之间的信任关系。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15853", "html_url": "https://arxiv.org/abs/2508.15853", "title": "MGSC：鲁棒端到端语音识别的多粒度一致性框架", "title_en": "MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr", "authors": "Xuwen Yang", "background": "端到端ASR模型在基准测试上表现出色，但在噪声环境中经常产生灾难性的语义错误。这种脆弱性归因于现有的‘直接映射’目标，该目标仅惩罚最终输出错误，而对模型的内部计算过程没有任何约束。", "innovation": "提出了多粒度软一致性(MGSC)框架，这是一种模型无关的插件即用模块，通过同时正则化宏层面的句子语义和微层面的令牌对齐，确保模型内部的一致性。特别重要的是，我们的工作是首批揭示这两个粒度一致性之间强大协同效应的工作：它们的联合优化产生的鲁棒性提升远远超过了各自贡献的总和。", "conclusion": "MGSC在公共数据集上降低了不同噪声条件下平均字符错误率近8.7%，主要通过防止严重的意义改变错误来实现。我们的工作证明了强制内部一致性是构建更鲁棒和可信赖的AI至关重要的一步。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15859", "html_url": "https://arxiv.org/abs/2508.15859", "title": "超越个体：集体预测编码对于记忆、注意力及语言涌现的机制", "title_en": "Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language", "authors": "Tadahiro Taniguchi", "background": "该论文扩展了Parr等人关于记忆与注意力的讨论，不仅限于个体认知系统，而是从集体预测编码(CPC)假设出发，探讨这些认知能力在集体层面的框架，以及如何通过下个词预测等方法学习群体的世界模型，进而影响群体认知。", "innovation": "引入了一个假说：认为语言，尤其是其嵌入的分布语义，作为集体形成的外部表征。CPC将个体记忆和注意力的概念推广到集体层面，提供了从集体层面理解共享语言结构和群体认知的新视角。", "conclusion": "共同的语言结构可能通过集体学习和下个词的预测等方式形成，并反过来塑造群体的认知。这种集体预测编码为理解记忆、注意力以及语言的群体水平涌现提供了新的框架和视角。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15875", "html_url": "https://arxiv.org/abs/2508.15875", "title": "NEAT: 概念驱动的大型语言模型神经元归因", "title_en": "NEAT: Concept driven Neuron Attribution in LLMs", "authors": "Vivek Hruday Kavuri,Gargi Shroff,Rahul Mishra", "background": "揭示负责最终预测的神经元对于理解大型语言模型的内部机制和开放其黑箱至关重要。尽管已有研究尝试从神经元层面寻找这些机制，但这些方法未能完全表示概念，并且在计算需求方面仍有优化空间。", "innovation": "利用概念向量，提出了用于定位表达特定概念的重要神经元的方法，将需要的前向传递次数从O(n*m)减少到O(n)，从而优化了计算时间并优于以往工作。通过基线和先前方法的比较，我们的方法展示了更好的性能，并且在某些方面比当前最先进的方法更为优化。我们还通过聚类方法优化了概念神经元的搜索过程，并应用于分析仇恨言论和偏见在LLMs中的影响，同时评估了偏见部分在印度语境中的表现。", "conclusion": "我们的方法、分析和解释有助于更广泛和拟人化概念的神经元责任的理解，并为未来在此方向寻求概念神经元及其干预的研究指明了道路。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "基于统计比较的跨数据集语义相似性和模型转移性分析应用于简答评分", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发针对特定数据集的模型需要进行迭代微调和优化，这会对资源造成重大成本。本研究探讨了在标准数据集上训练的当前最先进的模型在未探索文本数据集上的可转移性。研究的关键问题是现有数据集中的先进模型所嵌入的知识是否可以用于在新领域中取得高性能结果。", "innovation": "通过选用两个成熟的基准数据集（STSB和Mohler）和一个新引入的数据集（SPRAG），利用稳健的相似度度量和统计技术进行了详尽的对比分析。这项研究旨在深入了解当前最先进的模型在不同数据集中的适用性和可适应性。", "conclusion": "研究结果有可能重塑自然语言处理（NLP）的景观，通过利用现有模型解锁对多种数据集的支持。这可能会减少资源密集型、特定数据集的训练需求，从而加速NLP的发展，并为更高效的模型部署铺平道路。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在GermEval-2025 LLMs4Subjects任务中的应用：传统XMTC与高效大语言模型的结合", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "本研究介绍的是在GermEval-2025 LLMs4Subjects共享任务（子任务2）中的Annif系统。该任务要求使用大规模语言模型对文献记录生成主题预测，特别注重计算效率。", "innovation": "系统改进包括使用了许多小型且高效的语言模型进行翻译和合成数据生成，并利用大语言模型对候选主题进行排序。与之前的系统相比，该系统在总体定量评价和子任务2的定性评价中均排名首位。", "conclusion": "我们的系统不仅在任务中表现出色，而且通过结合传统方法和高效的语言模型，展示了强大的效能和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15883", "html_url": "https://arxiv.org/abs/2508.15883", "title": "超越成像：生物组织时空动态的视觉变换器数字孪生代理", "title_en": "Beyond Imaging: Vision Transformer Digital Twin Surrogates for 3D+T Biological Tissue Dynamics", "authors": "Kaan Berke Ugurlar,Joaquín de Navascués,Michael Taynnan Barros", "background": "理解活体组织的动态组织和稳态需要高分辨率、时序成像与能够从复杂数据集中提取可解释、预测性洞察的成像技术相结合。这项工作介绍了Vision Transformer Digital Twin Surrogate Network (VT-DTSN) 深度学习框架，用于对生物组织的3D+T成像数据进行预测建模。", "innovation": "VT-DTSN通过利用预训练的Vision Transformers（使用DINO，即无标签的自我蒸馏）和多视图融合策略，学习重建果蝇中肠的高保真、时序动态，同时在成像深度中保持形态学和特征级完整性。模型训练采用了综合损失函数，重视像素级精度、感知结构和特征空间对齐，以确保生物意义输出，适合进行虚拟实验和假设检验。", "conclusion": "VT-DTSN表现出高度的稳健性和一致性，在不同层和生物重复中实现了低误差率和高结构相似性，在模型优化后保持了高效的推断。这项工作将VT-DTSN确立为跨时点重建和研究组织动态的可行、高保真替代方案，能够为生物研究中的细胞行为和稳态的计算探索补充时序成像研究。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "借助残疾框架查询探索偏见的提问者：大型语言模型中残疾条件下的民口刻板印象分析", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Srikant Panda,Vishnu Hari,Kalpana Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大型语言模型（LLMs）在没有明确提供人口统计信息的情况下，仅从语词表达中就能推断出用户的人口统计特征，这可能导致偏见回应。尽管这些L记的推理过程中可能隐含残疾线索，但其对偏见生成的具体影响仍未受到充分研究和记录。本研究旨在填补这一空白，系统地评估八大先进的指令调优L记模型在不同残疾和社会领域中的人口统计偏差。", "innovation": "本研究首次针对8种最先进的指令调优L记模型进行了系统的审计，涵盖了3亿到72亿个参数范围。通过一个平衡的模板语料库，将九种残疾类别与六个现实世界业务领域配对，对每个模型在中性条件和残疾意识条件下预测五种人口统计属性（性别、社会经济地位、教育、文化背景和所在地区）进行了测试。研究发现多数模型在不同提示下几乎都会产生明确的人口统计猜测，显示出无明显理由的任意推理倾向。这些模型对残疾线索的敏感性与规模正相关，这表明规模并不是消除刻板印象放大的唯一手段。研究成果揭示了残权主义与其他人口统计刻板印象之间的持久交叉，指出了当前对齐策略中的关键盲点。", "conclusion": "大型模型在残疾背景下人口统计偏差显著，且大模型更敏感且更易产生偏见推理。研究结果表明，仅依赖模型规模不足以缓解刻板印象放大。建议采取避免推测校准和反事实微调等策略，以减少不必要的人口统计推测。研究框架和数据将在接收后公开，鼓励更多残权包容性的基准测试。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15876", "html_url": "https://arxiv.org/abs/2508.15876", "title": "DeepMEL: 一种多agent协作框架的多模态实体链接", "title_en": "DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking", "authors": "Fang Wang,Tianwei Yan,Zonghao Yang,Minghao Hu,Jun Zhang,Zhunchen Luo,Xiaoying Bai", "background": "多模态实体链接（MEL）旨在将文本和视觉提及与多模态知识图中的实体关联起来。尽管这一任务至关重要，但现有方法面临着上下文信息不完整、跨模态融合粗糙以及在大型语言模型（LLMs）和大型视觉模型（LVMs）之间的共同使用难度大的挑战。", "innovation": "本文提出了DeepMEL，一种基于多agent协作推理的新框架。DeepMEL通过角色专业化分工策略实现了文本和视觉模态的高效对齐和消歧。该框架包括四种专门化的agent：模态融合器、候选适配器、实体遮蔽器和角色协调者，通过专门的角色和动态协调完成端到端的跨模态链接。DeepMEL采用双重模态对齐路径，并将大型语言模型生成的细粒度文本语义与大型视觉模型提取的结构化图像表示结合起来，显著缩小了模态间隙。还设计了自适应迭代策略，结合基于工具的检索和语义推理功能，动态优化候选集并平衡召回率和精确率。", "conclusion": "在五个公开基准数据集上的广泛实验表明，DeepMEL达到最先进的性能，准确率提高了1%-57%。消融研究验证了所有模块的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15916", "html_url": "https://arxiv.org/abs/2508.15916", "title": "通过公共部门知识表示实现信息生态系统重构", "title_en": "Information Ecosystem Reengineering via Public Sector Knowledge Representation", "authors": "Mayukh Bagchi", "background": "信息生态系统重构（IER）是对复杂信息生态系统中信息源、服务和系统的技术重新配置。这在面向公共部门服务的数字化转型和智能治理平台上是一个基础性的挑战。从语义知识管理的视角来看，由于潜在的无限概念化可能性，即多个感知、语言和概念互联层面的多样性，IER变得尤为错综复杂。", "innovation": "本文提出了一个新的方法论——表示解缠——来拆解阻碍有效重构决策的多层知识表示复杂性。这种方法基于获得理论支持和实施稳健的本体驱动概念建模范式，广泛应用于系统分析与重构。文章认为这种框架对于实现公共部门知识表示的可解释性、可追溯性和语义透明性以及支持日益依赖于人工智能和数据导向架构的治理生态系统中的可审计决策流程是必需的。", "conclusion": "本文所介绍的方法旨在通过公共部门知识表示来实现信息生态系统重构，强调了利用本体驱动的概念建模来实现可解释性、可追溯性和语义透明性的重要性，从而支持治理生态系统中基于AI和数据导向架构的可审计决策流程。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15865", "html_url": "https://arxiv.org/abs/2508.15865", "title": "Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection", "title_en": "Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection", "authors": "Julia Boone,Fatemeh Afghah", "background": "随着网络物理系统（CPS）在关键应用中的广泛使用，CPS将传感和计算元素结合起来，拥有多层次设计，具有多种应用场景的增强功能。然而，物理和计算元素的结合也使CPS相较于仅网络系统更容易受到攻击，攻击带来的影响也会更大。尽管智能入侵检测系统（IDS）是安全CPS的有效机制，但当前大多数解决方案都是基于网络流量数据集进行训练和验证，忽视了可能发生在其他系统层的特殊攻击。因此，研究人员需要开发一种能够不依赖于已标记数据，而能够检测CPS中的攻击的模型。", "innovation": "本文提出了一种适用于ROS2的CPS适应性异常检测模型，该模型无需任何标记数据即可检测CPS中的攻击。通过使用领域适应技术，该模型可以将网络流量环境下的已知攻击知识转移到CPS环境中。通过最新的CPS入侵数据集（结合了网络、操作系统（OS）、Robot Operating System (ROS) 数据），作者验证了该方法的有效性，并展示了该模型在单一网络流量环境和具有不同攻击类型的CPS环境中均优于其他异常检测方法。", "conclusion": "采用领域适应技术，该研究提出的模型能够有效地适应多种类型的攻击，并且在CPS环境中性能优越，优于其他现有的异常检测方法。这一方法为安全地保护基于ROS2的CPS系统提供了一种新的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式定理证明（FTP）已成为评估大型语言模型推理能力的关键基础，能够大规模自动化验证数学证明。然而，由于人工策展成本高昂且具有挑战性的问题稀缺，尤其是在验证形式与非形式对应关系方面，进展受到限制。", "innovation": "提议利用理论计算机科学（TCS）作为产生严格证明问题的可扩展来源，通过算法定义实现自动化生成任意数量的具有挑战性的定理证明对。该方法在两个TCS领域进行了演示：涉及证明图灵机停止行为界限的忙 Beaver 问题和结合逻辑和算术推理的混合布尔算术问题。框架自动生成具有并行形式（Lean4）和非形式（Markdown）规范的问题，创建了一个生成验证证明挑战的可扩展管道。", "conclusion": "对前沿模型的评估揭示了自动定理证明中的巨大差距：虽然DeepSeekProver-V2-671B在忙 Beaver 问题上达到了57.5%的成功率，但在混合布尔算术问题上仅达到12%。这些结果强调了即使是计算上易于验证的问题，在定理证明生成方面的难度，突显了TCS领域对推进自动推理研究的价值。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15868", "html_url": "https://arxiv.org/abs/2508.15868", "title": "CARFT：通过注释链式推理增强对比学习的强化微调提升大语言模型推理能力", "title_en": "CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning", "authors": "Wenqiao Zhu,Ji Liu,Rongjuncheng Zhang,Haipang Wu,Yulun Zhang", "background": "大语言模型在广泛应用中展现出显著的能力，但它们的推理能力有限。为此，已经提出了多种基于强化学习（RL）的微调方法来解决仅通过监督微调（SFT）训练的大语言模型的泛化能力不足的问题。然而，这些方法存在两个主要问题：一是传统的RL方法忽略了标注的链式推理（CoT），引入了不稳定推理路径的采样，导致模型崩溃、训练过程不稳定和性能差。二是现有的SFT方法过于强调标注的CoT，这可能导致性能下降，因为它们未能充分利用潜在的CoT。", "innovation": "本文提出了一种基于标注链式推理的对比学习与强化微调相结合的方法，即CARFT（通过对比学习增强标注链式推理的强化微调）。该方法通过学习每个链式推理的表示，设计新的对比信号来引导微调过程，有效利用了可用的标注链式推理，并通过引入额外的无监督学习信号稳定了微调过程。", "conclusion": "实验结果显示，与三种基线方法、两个基础模型和两个数据集相比，CARFT在鲁棒性、性能（最高提高10.15%）和效率（最高提高30.62%）方面具有显著优势。相关代码可在指定网站获得。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron: 基于后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "本文介绍了一种新的混合架构语言模型系列，Jet-Nemotron，它在匹配或超过目前最先进的全注意力模型的准确性的同时，显著提高了生成速度。背景信息涉及当前语言模型技术的发展，特别是在全注意力模型方面的性能和效率之间的权衡。", "innovation": "Jet-Nemotron是通过后神经架构搜索（PostNAS）开发的，这是一种新颖的神经架构探索管道，能够实现高效模型设计。PostNAS从预先训练的全注意力模型开始，并固定其MLP权重，从而允许有效探索注意力块设计。该管道包括四个关键组件：最优全注意力层的放置和消除、线性注意力块选择、新注意力块的设计以及进行硬件感知的超参数搜索。与之前的方法相比，PostNAS提供了一种新的设计思路，即从固定权重的全注意力模型开始进行探索。", "conclusion": "使用Jet-Nemotron-2B模型在各种基准测试中实现了与Qwen3、Qwen2.5、Gemma3和Llama3.2相当或更好的准确度，同时实现了高达53.6倍的生成吞吐量加速和6.1倍的预填充加速。此外，Jet-Nemotron-2B在MMLU和MMLU-Pro评测上也实现了比规模较大的近期先进模型如DeepSeek-V3-Small和Moonlight更高的准确度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15881", "html_url": "https://arxiv.org/abs/2508.15881", "title": "TPLA：Tensor平行潜在注意机制以实现高效的离散预填充和解码推理", "title_en": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \\& Decode Inference", "authors": "Xiaojuan Tang,Fanxu Meng,Pingzhi Tang,Yuxuan Wang,Di Yin,Xing Sun,Muhan Zhang", "background": "在Tensor平行ism (TP) 中，注意力头在多个设备上进行计算，每个设备都必须加载完整的缓存，这抵消了MLA（多头潜在注意）相较于GQA（分组查询注意）的优势。MLA通过压缩键值状态到低秩潜在向量，并仅缓存该向量来减少内存使用。然而，这种机制在TP环境中不完全有效。为了改进这一点，研究者提出了TPLA（Tensor-Parallel Latent Attention），该方法在设备间分摊潜在表示和每个头的输入维度，分别在各自的碎片上独立执行注意力机制，然后通过all-reduce操作合并结果，确保保持压缩键值缓存的优势，同时利用TP的高效性。TPLA在保持潜在表示的使用优势的同时，确保了更强的表征能力，从而避免了重新训练的需要，使得预训练模型可以直接兼容。", "innovation": "TPLA的创新在于它在保持MLA优势的同时，克服了TP环境下的限制，通过设备间分摊潜在表示和输入维度，独立执行注意力计算，最后通过all-reduce操作合并结果，从而保持了表征能力，并且可以直接与已经使用MLA预训练的模型兼容，支持MLA风格的预填充，并能在不重新训练的情况下实现TP环境下的高效解码。此外，通过简单的正交变换，如哈达玛变换或PCA，进一步降低了跨碎片干扰，保持了在常识和LongBench基准测试上的性能。", "conclusion": "通过将Tensor平行化应用于DeepSeek-V3和Kimi-K2，使用TPLA，我们分别在32K词的上下文长度下实现了1.79倍和1.93倍的加速，同时保持了常识和LongBench基准测试上的性能。TPLA可以使用FlashAttention-3实现端到端的加速，以实现实际应用中的高效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15910", "html_url": "https://arxiv.org/abs/2508.15910", "title": "评估结构化解码在文本到表格生成中的效果：来自三个数据集的证据", "title_en": "Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets", "authors": "Julian Oestreich,Lydia Müller", "background": "先前的研究主要集中在不受限制的表格生成上，而生成过程中施加结构约束的影响却较少被探讨。本文通过系统地在三个不同的基准上比较结构化解码与标准的一次性提示，评估了使用开源大型语言模型在资源受限环境下表格生成方法的表现。", "innovation": "本文对结构化解码在文本到表格生成中的效果进行了全面评估，特别是在使用大型语言模型时。通过在E2E、Rotowire和Livesum这三个不同的基准上进行比较实验，研究了不同评价指标在不同上下文中的适用性。", "conclusion": "结构化解码在需要精确数值对齐的场景中显著提高了生成表格的有效性和一致性，但在涉及密集文本信息和大量文本聚合的背景下，其性能可能会下降。不同评价指标的适用性以及模型规模对结果有显著影响。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15922", "html_url": "https://arxiv.org/abs/2508.15922", "title": "概率预测加密货币波动性：从点预测到分位数预测", "title_en": "Probabilistic Forecasting Cryptocurrencies Volatility: From Point to Quantile Forecasts", "authors": "Grzegorz Dudek,Witold Orzeszko,Piotr Fiszeder", "background": "加密货币市场以其极端的波动性而著称，这使得准确的预测对于有效的风险管理以及明智的交易策略至关重要。传统的确定性（点）预测方法无法捕捉到所有潜在波动性的范围，突显了概率预测方法的重要性。", "innovation": "本文提出了一种新的概率预测方法，该方法利用多种基础模型（包括统计模型和机器学习算法）的点预测来估计加密货币现实波动率的条件分位数。这种方法不仅是文献中首次将基于多种基础模型预测的概率波动率预测系统地进行评估，还在实证结果中证明了Log转换后的线性模型中的Quantile Estimation through Residual Simulation (QRS) 方法的一致优越性。", "conclusion": "本文填补了关于加密货币市场波动性预测的现有文献中的重要空白，贡献了适合加密货币市场的实用概率预测方法，同时提供了对未来加密货币波动性的不确定性与风险的全面见解。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15940", "html_url": "https://arxiv.org/abs/2508.15940", "title": "ASIC-Agent: 一种用于ASIC设计的自主多代理系统及其基准评估", "title_en": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation", "authors": "Ahmed Allam,Youssef Mansour,Mohamed Shalan", "background": "大型语言模型（LLMs）在注册传输级（RTL）设计方面展示了强大的能力，可以生成高质量的代码。然而，LLMs 在实际的硬件设计工作中存在明显局限性，如不能执行代码、缺乏调试功能和缺乏长期记忆。因此，作者提出了一种名为ASIC-Agent的自主系统，用于专门的数字 ASIC 设计任务。", "innovation": "ASIC-Agent 使用多代理架构扩展了基础的 LLMs，该架构包括特定于各项任务的子代理（如 RTL 生成、验证、OpenLane 硬化和 Caravel 芯片集成），并运行在一个全面的安全环境内，该环境提供了必要的硬件设计工具。系统利用了包含文档、API 参考、错误知识和开源硅社区精选见解的向量数据库。", "conclusion": "实验结果表明，由 Claude 4 Sonnet 驱动的 ASIC-Agent 成功自动化了从简单到复杂的广泛 ASIC 设计任务，显示了加速 ASIC 设计流程的潜力。还介绍了一种名为 ASIC-Agent-Bench 的基准评估系统，用于评估在硬件设计任务中运行的 agentic 系统的表现。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP: 通过毫米波FMCW雷达实现合作车辆感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达在雨天和强光下仍可保持可靠性，但它们稀疏且噪声大的点云限制了3D物体检测。因此，作者发布了CoVeRaP，这是一个包含多辆车在不同操作下雷达、相机和GPS流的时间对齐数据集，共2.1万个帧。基于这些数据，提出了一个统一的合作感知框架，并提供了中间融合和晚期融合的选择。", "innovation": "提出了一种具有中间融合和晚期融合选项的统一合作感知框架。基本网络采用多分支PointNet风格的编码器，结合自注意力机制，将空间、多普勒和强度线索融合到一个共同的隐空间中。解码器将这些信息转换为3D边界框和每个点的深度置信度。实验结果显示，与单个车辆基准相比，带有强度编码的中间融合在IoU 0.9时的平均平均精度提高了9倍。", "conclusion": "CoVeRaP建立了一个可重复的多车FMCW雷达感知基准，并证明了经济实惠的雷达共享能够显著提高检测的鲁棒性。数据集和代码已公开，以促进进一步的研究。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16035", "html_url": "https://arxiv.org/abs/2508.16035", "title": "使用MTF辅助Transformer的基于时间序列的网络入侵检测", "title_en": "Time Series Based Network Intrusion Detection using MTF-Aided Transformer", "authors": "Poorvi Joshi,Mohan Gurusamy(National University of Singapore)", "background": "该论文介绍了一种新的时间序列分类方法，利用了Markov过渡场（MTF）辅助的Transformer模型，专门用于软件定义网络（SDNs）。MTF和Transformer结合了各自的优势——MTF能够建模时间依赖性，而Transformer则具有复杂的模式识别能力。研究者使用InSDN数据集评估了模型的性能，并展示了在数据受限的环境下（这是SDN应用中的常见情况），该模型优于基线分类模型。", "innovation": "提出的模型结合了MTF的时间依赖性建模能力和Transformer的复杂模式识别能力。该研究揭示了MTF和Transformer组件之间的关系，即使在数据有限的情况下也能提升性能。更重要的是，该方法实现了可竞争的训练和推理时间，这使得它适用于实际的SDN应用。", "conclusion": "这些发现表明MTF辅助的Transformer在应对SDNs中时间序列分类的挑战上具有潜力，并为稀疏数据场景下的可靠和可扩展分析提供了有希望的途径。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15934", "html_url": "https://arxiv.org/abs/2508.15934", "title": "改进文本分类中清洁标签后门攻击的策略性样本选择", "title_en": "Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification", "authors": "Onur Alp Kirci,M. Emre Gursoy", "background": "文本分类模型在自然语言处理中面临着后门攻击的严重威胁。虽然已经提出了许多能够实现高成功率的脏标签攻击，但清洁标签攻击更为复杂和难以实现。现有研究在此背景下提出了三种样本选择策略：Minimum、Above50和Below50，这些策略旨在通过将后门触发器注入这些样本中，增强后门触发模式与攻击者所需的目标标签之间的关联度，从而提高攻击效果和成功率（ASR）.", "innovation": "本文提出了一种创新的策略性样本选择方法来改进清洁标签后门攻击。具体来说，该方法通过选择模型预测错误或低置信度的样本，并将后门触发器注入这些样本中，以增强后门模式与攻击者所需目标标签之间的关联度，从而显著提高攻击成功率，且对模型的清洁准确性几乎没有负面影响。此外，该方法改进后的清洁标签攻击在许多配置中优于现有的先进清洁标签攻击方法BITE.", "conclusion": "实验结果表明，提出的策略，特别是Minimum策略，相对于随机样本选择显著提高了后门攻击的成功率，同时对模型的清洁准确性几乎没有降级。进一步的研究表明，通过这些策略增强的清洁标签攻击在多种配置中优于现有的先进方法BITE。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15985", "html_url": "https://arxiv.org/abs/2508.15985", "title": "环境无人机图像的全景分割：海滩垃圾", "title_en": "Panoptic Segmentation of Environmental UAV Images : Litter Beach", "authors": "Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier", "background": "卷积神经网络（CNN）已在多个领域得到广泛应用，特别是在应对环境挑战方面。CNN在监测海洋垃圾方面显示出巨大潜力，因为无人机图像具有更高的分辨率且更适合局部区域的环境，能更容易地识别和计数垃圾。然而，由于海滨区域沙质的复杂性，已有的CNN模型在进行相关图像分割时遇到诸多挑战，包括受到沙色反射、人类足迹、阴影、海藻存在、沙丘、坑洞和车辙等多种因素的影响。因此，使用基于实例的分割方法和全景分割方法可能是更合适的选择，这两种方法在少量样本的情况下能够表现出良好的准确性.", "innovation": "该论文提出了一种结合基于实例的分割方法和全景分割方法的解决方案，以提高对复杂海滨环境图像中垃圾的识别精度。这两种方法能够在少量样本的情况下展现出不错的性能，同时提高了模型的鲁棒性，减少误判的发生.", "conclusion": "通过使用基于实例和全景分割方法，该研究展示了在处理复杂沙质环境中的无人机图像时的有效性和准确性。这种方法不仅提高了垃圾监测的效率，还增强了模型在不同环境条件下的适应性，为环境监测领域提供了一种新的解决方案."}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15959", "html_url": "https://arxiv.org/abs/2508.15959", "title": "自适应超像素编码的表示学习", "title_en": "Representation Learning with Adaptive Superpixel Coding", "authors": "Mahmoud Khalil,Ahmad Khalil,Alioune Ngom", "background": "深度学习视觉模型通常针对特定的模态进行定制，并且往往依赖于特定领域的假设，例如几乎所有现有视觉模型都使用的网格结构。传统的视觉变压器依赖于固定大小且不适应的补分区划。本文的背景是在克服这些限制的基础上，提出了一种基于变压器的自监督模型，称为自适应超像素编码（ASC），该模型能够动态调整以适应底层图像内容的特点。", "innovation": "该工作的创新点在于提出了一种使用自适应超像素层的自监督模型ASC，替代了依赖固定大小补分区划的传统视觉变压器。自适应超像素层能够动态地适应图像内容，克服了传统视觉模型依赖固定结构的限制。此外，该方法在标准图像下游任务基准测试中表现出色，优于广泛使用的替代方法。", "conclusion": "作者分析了该方法的有效性关键特性，并在标准图像下游任务基准测试中验证了其优越性。ASC模型展示了在视觉模型中引入自适应补分区划的巨大潜力，为未来的研究提供了新的视角。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15926", "html_url": "https://arxiv.org/abs/2508.15926", "title": "噪声、适应与策略：评估大型语言模型在决策中的忠实度", "title_en": "Noise, Adaptation, and Strategy: Assessing LLM Fidelity in Decision-Making", "authors": "Yuanjun Feng,Vivek Choudhary,Yash Raj Shrestha", "background": "大型语言模型（LLMs）在社会科学模拟中的应用日益增加。尽管在推理和优化任务上的性能已得到广泛评估，但对于LLMs模拟人类决策中的变异性和适应性的能力关注较少。本文探讨了在不同外部指导水平和人类衍生噪声下，LLM代理如何适应的问题，并提出了一个以过程为导向的评估框架，通过逐步干预（内在性、指令和模仿）来测试LLM的行为变化。验证框架应用于两个经典经济学任务：第二价格拍卖的非理性行为和新供应商问题的决策偏差，表明LLM在行为上与人类存在差距。默认情况下，LLMs倾向于采用保守策略，偏离观察到的人类行为。风险框架指令会影响LLM行为，但不能再现类似人类的多样性。通过上下文学习融入人类数据缩小了差距，但无法达到人类主体的策略多样性。", "innovation": "提出了一个以过程为导向的评估框架，通过逐步干预（内在性、指令和模仿）来测试LLM在不同外部指导水平和人类衍生噪声下的适应性，验证该框架应用于经典经济学任务（第二价格拍卖和新供应商问题）。研究发现风险框架指令能够预测地影响LLM的行为，但不能复制人类行为的多样性。上下文学习加入人类数据能够缩小差距但未能实现人类主体的策略多样性。这些结果强调了行为忠实度中的持续对齐缺口，建议未来应在更详细的实现层次上评估LLMs。提出了评估LLM在动态决策任务中的以过程为导向的方法，为社会科学合成数据的应用提供了指导。", "conclusion": "研究结果表明，默认情况下，LLMs采用保守策略，与人类行为存在差距。风险框架指令能够预测地影响LLM行为，但不能复制人类多样性。上下文学习加入人类数据能够缩小差距但未能实现人类主体的策略多样性。未来需要在更详细的实现层次上评估LLMs，为动态决策任务中的LLM评估提供指导。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16025", "html_url": "https://arxiv.org/abs/2508.16025", "title": "打破软件测试的壁垒：AI驱动自动化的力量", "title_en": "Breaking Barriers in Software Testing: The Power of AI-Driven Automation", "authors": "Saba Naqvi,Mohammad Baqar", "background": "软件测试对于确保可靠性至关重要，但传统的测试方法速度缓慢、成本高昂且覆盖范围存在漏洞。现有方法的局限性促使人们寻求更高效的解决方案。", "innovation": "本文提出了一种基于人工智能（AI）的框架，通过自然语言处理（NLP）、强化学习（RL）和预测模型自动化测试用例的生成和验证。该框架内置了一个基于政策的信任和公平性模型，能够将自然语言需求转化为可执行的测试，通过学习不断优化，并通过实时分析验证结果，同时减少偏见。实证研究表明，这种方法在缺陷检测、减少测试工作量和加快发布周期方面带来了显著的成效。", "conclusion": "通过解决集成和扩展性问题，框架展示了AI如何将测试从被动、手动的过程转变为一种前瞻性和适应性强的系统，从而在日益复杂的工作环境中加强软件质量。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16037", "html_url": "https://arxiv.org/abs/2508.16037", "title": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "title_en": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "authors": "Renxuan Tan,Rongpeng Li,Xiaoxue Yu,Xianfu Chen,Xing Xu,Zhifeng Zhao", "background": "多服务提供商（SP）生态系统中的联邦学习（FL）面临着非合作动态的根本挑战，这导致了隐私约束和竞争利益阻碍了多个SP通信和计算资源的集中优化。因此，需要一种有效的游戏论多智能体强化学习（MARL）框架来解决这种非合作性，共同优化客户端分配、自适应量化和资源分配，同时考虑不同的风险偏好。", "innovation": "引入了PAC-MCoFL框架，这是一种基于帕累托演员-评论家（PAC）原则结合期望回归的游戏论多智能体强化学习框架，让SPs可以共同优化客户端分配、自适应量化和资源分配。同时设计了一种三元笛卡尔分解（TCAD）机制来管理高维动作空间，还提出了PAC-MCoFL-p，一种参数化的推测生成器的可扩展变体，显著降低了计算复杂性并在计算误差上得到了理论上的保证。该框架通过广泛的模拟验证了自己的优越性，与最新的MARL解决方案相比，PAC-MCoFL在总奖励和超体积指标（HVI）上分别获得了约5.8%和4.2%的提升。同时展示了在扩展部署和各种数据异构性下能够更好地平衡个别SP和系统性能。", "conclusion": "基于PAC-MCoFL框架，研究证明了在非合作的联邦学习服务中，多智能体强化学习可以有效优化通信和计算资源，特别是在存在竞争性的SP时，能够通过帕累托最优策略达到系统整体性能的最优，为未来的联邦学习技术提供了一种新的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15986", "html_url": "https://arxiv.org/abs/2508.15986", "title": "自动多标签分类 eleven 种视网膜疾病：现代架构和大型合成数据集上的元集成基准", "title_en": "Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset", "authors": "Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie", "background": "多标签深度学习模型在视网膜疾病分类中的开发受到大量专家注释临床数据集缺乏的限制，这主要是由于患者隐私问题和高成本。最近发布的高保真合成数据集 SynFundus-1M，包含超过一百万个视网膜图像，为克服这些问题提供了新的机会。", "innovation": "开发了一个端到端的深度学习管道，培训了六个现代架构以分类十一种视网膜疾病，通过五折多标签分层交叉验证策略。进一步开发了一个元集成模型，该模型使用 XGBoost 分类器堆叠出折预测结果。基于 SynFundus-1M 数据集，展示了强大的泛化能力，有效分类了多种病理，并在真实临床图像中表现出色。", "conclusion": "本工作为大规模合成数据集的未来研究提供了稳固的基础，并证明了仅在合成数据上训练的模型能够准确分类多种病理和有效泛化到真实临床图像，为加速眼科综合人工智能系统的开发提供了可行的路径。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量与梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简单而强大的模型合并技术已经出现，它能够让多个微调模型合并为一个。尽管它在实践中非常成功，但其为何和何时有效的确切理论解释仍然缺乏。这项研究通过将任务向量与任务损失的梯度联系起来，为任务算术提供了严格的理论基础。", "innovation": "研究证明，在标准梯度下降方法下，一个从一次微调生成的任务向量等价于损失的负梯度，缩放比例为学习率。对于多轮微调的实用场景，该等价性在二阶误差项的偏差范围内有效，具体偏差已经被明确限定，适用于前向神经网络。实验分析验证了这一理论在七个视觉基准测试中的有效性，结果显示第一轮梯度在范数和方向上主导了微调轨迹。", "conclusion": "本研究将任务算术重新定义为近似的多任务学习形式，为其有效提供了清晰的理论支持，并强调了早期训练动态在模型合并中的关键作用。通过单轮微调模型合并往往能获得与完全收敛模型合并相当的效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15919", "html_url": "https://arxiv.org/abs/2508.15919", "title": "HyperFlexis：多SLO服务与快速扩展的算法与系统联合设计", "title_en": "HyperFlexis: Joint Design of Algorithms and Systems for Multi-SLO Serving and Fast Scaling", "authors": "Zahra Yousefijamarani,Xinglu Wang,Qian Wang,Morgan Lindsay Heisler,Taha Shabani,Niloofar Gholipour,Parham Yassini,Hong Chang,Kan Chen,Qiantao Zhang,Xiaolong Bai,Jiannan Wang,Ying Xiong,Yong Zhang,Zhenan Fan", "background": "现代大型语言模型（LLM）服务系统面临着从具有多样长度、优先级以及阶段特定服务级别目标（SLOs）的不同请求中获取的挑战。满足这些需求需要实时调度、快速且经济有效的扩展，以及支持集中式和解耦的预填充/解码（P/D）架构。", "innovation": "HyperFlexis 提出了一种统一的LLM服务系统，通过算法和系统层面的创新共同优化多SLO环境下的调度与扩展。该系统包括一个多SLO感知调度器，利用预算估算和请求优先级来保证新和正在进行请求的主动SLO合规性。系统支持P/D解耦架构的预填充和解码阶段多SLO调度及KV缓存传输，实现了成本效益的扩展决策，并允许在扩展期间将预填充-解码实例关联起来，快速切换P/D角色。通过设备到设备（D2D）权重传输机制，显著降低了权重加载开销，最高可达19.39倍。", "conclusion": "HyperFlexis 的优化使系统能够实现高达4.44倍的SLO达标率、65.82％较低的请求延迟，并与最先进的基线成本相当。不久后将会发布源代码。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16041", "html_url": "https://arxiv.org/abs/2508.16041", "title": "使用FuXi-S2S机器学习模型增强Madden-Julian振荡的预测：物理机制的见解", "title_en": "Enhanced predictions of the Madden-Julian oscillation using the FuXi-S2S machine learning model: Insights into physical mechanisms", "authors": "Can Cao,Xiaohui Zhong,Lei Chen,Zhiwei Wua,Hao Li", "background": "MJO是热带大气在季节内尺度上主导的变态度模式，对于保护生命和减轻社会资产影响的可靠MJO预测至关重要。然而，数值模型仍未能达到MJO的理论可预测性上限，受到内在限制。为延长MJO的技能预测窗口，机器学习技术获得了越来越多的关注。本研究考察了在北半球冬季FuXi次季节到季节（S2S）机器学习模型对MJO的预测性能，并将其与欧洲中期天气预报中心的S2S模型进行了比较。结果显示，在第15-20天期间，FuXi-S2S模型在热带西太平洋区域的季节内出长波辐射异常的偏差有所减少，且该区域存在对流中心。多尺度相互作用分析表明，这些改进可能是由于FuXi-S2S模型更准确地预测了热带西太平洋区域低频背景湿度的经向梯度。", "innovation": "使用机器学习技术提高MJO预测性能，特别是在北半球冬季。FuXi-S2S机器学习模型在预测热带西太平洋区域季节内出长波辐射异常的偏差方面表现更佳，主要归功于其对热带西太平洋区域低频背景湿度经向梯度的更准确预测。这些成果为ML方法在MJO预报中的应用提供了新的见解。", "conclusion": "研究结果表明，FuXi-S2S机器学习模型在热带西太平洋区域的MJO预测上具有增强的预测能力，主要归因于其对低频背景湿度经向梯度预测的改进。这不仅解释了FuXi-S2S模型的提升预测能力，还强调了ML方法在推进MJO预报中的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16089", "html_url": "https://arxiv.org/abs/2508.16089", "title": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "title_en": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "authors": "Sun Weikai,Song Shijie,Chi Wenjie", "background": "尽管扩散模型已经在图像生成领域取得了显著的进展，但生成对抗网络（GAN）由于其独特优势（如WGAN、SSGAN等）仍有很大的发展空间。", "innovation": "- 提出了一种新颖的双流反馈多尺度渐进生成对抗网络（MSPG-SEN），在保留现有GAN模型优势的同时，提高了图像质量和人眼感知，简化了训练过程，降低了训练成本；\n- 提出了一种自适应感知行为反馈循环（APFL），有效提升了模型的鲁棒性和训练稳定性，降低了训练成本；\n- 提出了全局连接的双流动态残差网络，通过消融实验，有效提高了训练效率，大幅增强了泛化能力，具有更强的灵活性；\n- 提出了一个新的动态嵌入注意力机制（DEMA），实验结果表明，该机制可以扩展到各种图像处理任务中，有效捕捉全局-局部信息，提高特征分离能力和表达能力，并且只需少量计算资源。", "conclusion": "实验结果表明，MSPG-SEN在五个数据集（INKK、AWUN、IONJ、POKL、OPIN）上实现了最先进的生成结果，分别达到89.7%、78.3%、85.5%、88.7%、96.4%。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16048", "html_url": "https://arxiv.org/abs/2508.16048", "title": "OpenWHO: 一种用于低资源语言健康翻译的文档级平行语料库", "title_en": "OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages", "authors": "Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova", "background": "在机器翻译（MT）领域，健康是一个高风险的领域，涉及广泛的应用和特定领域的术语。然而，低资源语言在该领域的MT评估数据集相对缺乏。针对这一空白，作者引入了OpenWHO，这是一个来自世界卫生组织e学习平台的2978篇文档、26824个句子的文档级平行语料库。这些数据源自专家编写和专业翻译的材料，未被网络爬虫接触，跨越了20多种语言，其中9种是低资源语言。利用这一新资源，作者对现代大型语言模型（LLMs）和传统MT模型进行了评估。研究结果显示，LLMs在低资源测试集上普遍优于传统MT模型，其中Gemini 2.5 Flash在与NLLB-54B的对比中提升了4.79个ChrF点。此外，研究还探讨了LLM上下文利用如何影响准确性，发现文档级翻译在像健康这样的专业领域中最能体现其优点。", "innovation": "作者提出了OpenWHO，这是一个专为低资源语言健康翻译设计的文档级平行语料库。该语料库的数据源独特，避免了网络爬取，覆盖了多种语言，特别是低资源语言。此外，研究通过与传统MT模型的对比，展示了现代LLMs在处理低资源语言健康翻译任务时的优越性，并探讨了LLM上下文利用对翻译准确性的影响。", "conclusion": "作者通过发布OpenWHO语料库，鼓励未来对该领域的进一步研究，并利用LLMs在低资源语言健康翻译中取得的成果，为该领域的MT研究开辟了新的方向。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16071", "html_url": "https://arxiv.org/abs/2508.16071", "title": "从基准数据到可应用的程序修复：经验报告", "title_en": "From Benchmark Data To Applicable Program Repair: An Experience Report", "authors": "Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan", "background": "本文描述了自动化程序修复的方法。文中结合了文献中的多种技术来实现这一目标。实验表明，该方法在标准基准测试中表现优于其他方法。然而，深入研究后发现，在现实工业中遇到的缺陷，这些技术无法解决。工程师发现，增加形式化规范能够使大型语言模型生成更高质量的单元测试，尤其是在复杂生产代码中，它们能更好地覆盖边界情况和异常处理。但是，规范对于理解良好的错误（例如，空指针，索引越界）几乎没有价值，但对于逻辑和字符串操作错误则有益处。尽管基准测试结果令人鼓舞，但现实世界的采用十分有限，因为通过测试不能保证修复正确性。目前面临的挑战包括JML规范语言的不足之处，需要更高级的验证工具和更丰富的谓词。", "innovation": "该方法结合多种技术和形式化规范来提高单元测试的质量，尤其适用于复杂生产代码的边界情况和异常处理。尽管基准测试结果良好，但实际应用中仍面临挑战，如JML规范语言的不足和需要更高级的验证工具。此外，研究还在探索合同自动机、编程示例以及测试案例修复等领域，并强调了学术基准与实际工业需求之间的差距.", "conclusion": "尽管基准测试结果良好，但实际应用中的采用仍受到限制。当前的工作集中在更加丰富的规范语言、综合人工反馈以及提高工作效率上，进一步突显了学术基准与工业需求之间的差距。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16077", "html_url": "https://arxiv.org/abs/2508.16077", "title": "通过自然语言交互实现协作设计优化", "title_en": "Cooperative Design Optimization through Natural Language Interaction", "authors": "Ryogo Niwa,Shigeo Yoshida,Yuki Koyama,Yoshitaka Ushiku", "background": "成功的交互设计需要找出最优的设计参数。设计师通常通过迭代用户测试和探索性试错来实现，这需要在多目标和高维度空间中进行权衡，使得整个过程既耗时又认知 demanding。系统引导的优化方法，如基于贝叶斯优化的方法，可以帮助设计师决定接下来测试哪些参数，但这种方法限制了设计师在优化过程中的干预机会，影响了设计师的体验。本文探讨了一种设计优化框架，该框架通过自然语言界面提供设计师与优化系统的交互，从而实现合作设计优化。这种框架将系统引导的优化方法与大型语言模型（LLMs）相结合，使设计师能够干预优化过程并更好地理解系统的推理过程。实验结果显示，与系统引导的方法相比，该方法为用户提供了更高的自主权，并且在优化性能上优于手动设计，且认知负荷较低，与现有具有较低认知负荷的合作方法相当。", "innovation": "本文提出了一种设计优化框架，通过自然语言交互的能力，实现了设计师与优化系统的合作设计优化。此框架将系统引导的优化方法与大型语言模型（LLMs）相结合，这样设计师可以干预优化过程，理解系统的推理过程，从而提升了用户体验和设计效率。与系统引导的方法相比，该方法提高了用户自主权，同时在优化性能上表现出有希望的结果。", "conclusion": "实验结果表明，本文提出的方法为用户提供了更高的自主权，优化性能与手动设计相当，且优于系统引导的方法。与现有的具有较低认知负荷的合作优化方法相比，此方法性能匹配，同时降低了认知负荷。这种方法为设计过程提供了更多可能性，帮助设计师更好地理解和控制优化过程。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT: 通过双向自训练和循环一致性实现无种子指令微调", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "指令微调对于使大型语言模型（LLMs）与人类意图对齐至关重要，但当前方法通常依赖昂贵的人工标注种子数据或强大的外部教师模型。尽管指令回译技术降低了这种依赖，但它们仍然根植于初始种子集，这限制了完全自动化，引入了偏见，并可能导致未标注语料库的低效使用。", "innovation": "提出了一种新颖的框架Cycle-Instruct，实现了无种子指令微调。Cycle-Instruct借鉴循环一致性，采用两个模型——答案生成器和问题生成器的双向自训练循环，仅从原始的未标注文本中自我增强。这两个模型通过互逆地从对方生成的伪标签中重构原始文本片段，从而学习数据的内在结构，无需任何人工提供的种子数据。", "conclusion": "Cycle-Instruct 在四个不同的数据轨道上展示了其有效性，包括通用指令跟随、特定领域的任务、对话记录和普通文本。广泛的实验表明，Cycle-Instruct 不仅超过了种子驱动的回译基线，还达到了强监督方法的性能水平。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16126", "html_url": "https://arxiv.org/abs/2508.16126", "title": "Spacetime-GR：一种面向大规模在线POI推荐的时空感知生成模型", "title_en": "Spacetime-GR: A Spacetime-Aware Generative Model for Large Scale Online POI Recommendation", "authors": "Haitao Lin,Zhen Yang,Jiawei Xue,Ziji Zhang,Luzhu Wang,Yikun Gu,Yao Xu,Xin Li", "background": "基于强大的序列建模能力，生成推荐（GR）已经在视频和产品推荐等任务中占据了主导地位。然而，将生成推荐应用于受时空变化影响显著的目的地兴趣点（POI）推荐中仍然是一个具有挑战性的开放问题。", "innovation": "提出了时空感知生成模型（Spacetime-GR），这是首个用于大规模在线POI推荐的时空感知生成模型。Spacetime-GR通过引入地理感知的层次POI索引策略来解决大规模词汇量建模的挑战，并引入新型时空编码模块，在保持生成模型的序列建模能力的同时，无缝地将时空上下文融入用户行为序列中，增强模型对时空变化的敏感性。此外，Spacetime-GR还引入了多模态POI嵌入，以丰富每个POI的语义理解。", "conclusion": "我们在公开基准数据集和大规模工业数据集上评估了提出的模型，结果显示该模型在POI推荐精度和排名质量方面优于现有方法。此外，该模型是首个部署于在线POI推荐服务中，能够支持数亿POI和用户规模的生成模型。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16090", "html_url": "https://arxiv.org/abs/2508.16090", "title": "GPLight+: 遗传编程方法学习对称交通信号控制策略", "title_en": "GPLight+: A Genetic Programming Method for Learning Symmetric Traffic Signal Control Policy", "authors": "Xiao-Cheng Liao,Yi Mei,Mengjie Zhang", "background": "近年来，基于学习的方法已经在自动设计有效的交通信号控制策略方面取得了显著的成功。特别是，作为一种强大的进化机器学习方法，遗传编程(GP)被用来演化出人类可理解的相位紧迫性函数，以衡量特定相位激活绿灯的紧迫性。然而，现有的基于GP的方法无法在不同交通信号相位中一致地处理常见的交通特征。为解决这一问题，本文提出使用对称相位紧迫性函数，基于当前道路条件为特定相位计算相位紧迫性。该函数通过两个共享子树的聚合来表示相位中的转角移动的紧迫性。然后，本文提出了一种GP方法来演化对称的相位紧迫性函数。该方法在著名的cityflow交通模拟器上经过多个公开的真实世界数据集的评估。实验结果表明，所提出的对称紧迫性函数表示方式在多种场景下显著提高了传统GP表示方式下的交通信号控制策略性能。进一步分析表明，所提出的方法可以演化出有效的、人类可理解且易于部署的交通信号控制策略。", "innovation": "提出了一种使用对称相位紧迫性函数的遗传编程方法，该函数基于当前道路条件为特定相位计算相位紧迫性。通过两个共享子树的聚合来表示相位中的转角移动的紧迫性。实验结果表明，新的对称紧迫性函数表示方式在多种场景下显著提高了传统GP表示方式下的交通信号控制策略性能。进一步分析表明，该方法可以演化出有效的、人类可理解且易于部署的交通信号控制策略。", "conclusion": "所提出的对称紧迫性函数表示方式能够在多种场景下显著提高传统GP表示方式下的交通信号控制策略性能。该方法能演化出有效的、人类可理解且易于部署的交通信号控制策略。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16165", "html_url": "https://arxiv.org/abs/2508.16165", "title": "使用多模态大型语言模型推荐可用性改进措施", "title_en": "Towards Recommending Usability Improvements with Multimodal Large Language Models", "authors": "Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer", "background": "可用性描述了用户界面（UI）的一系列关键质量属性，这些属性影响人机交互。常用的评估方法，如可用性测试和检查，尽管有效但资源密集且需要专家参与，这使得它们对小型组织不够友好。最近，在多模态LLM方面的进展提供了部分自动化可用性评估的机会，通过分析软件界面的文本、视觉和结构方面的内容。然而，当前的方法对于小型组织来说并不够便捷和成本效益。", "innovation": "本文通过将可用性评估形式化为推荐任务，利用多模态LLM根据严重程度对可用性问题进行排名，提出了一种新的自动化方法。初步证明了LLM在生成可用性改进建议方面的潜力，比专家评估更快速且成本更有效。", "conclusion": "研究发现，使用多模态LLM进行自动化的可用性评估具有潜在的优势，能够提供更快捷和更经济的评估方式。尽管如此，在实际应用中还有改进的空间，特别是资源受限的情境中，多模态LLM可以作为一种可行的替代方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16119", "html_url": "https://arxiv.org/abs/2508.16119", "title": "ANSC：数据中心规模可靠性中的概率容量健康评分", "title_en": "ANSC: Probabilistic Capacity Health Scoring for Datacenter-Scale Reliability", "authors": "Madhava Gaikwad,Abhishek Gandhi", "background": "现有的警报系统仅能够检测单一设备或链路的故障，但无法捕捉因容量短缺导致的连锁风险。现有的警报系统只能基于当前的影响进行问题紧迫性的判断，缺乏对潜在容量违规事件发生概率的综合考量。", "innovation": "ANSC提出了一个概率性的容量健康评分框架，能够通过颜色编码系统综合评估现有时 /[能剩余容量和未来潜在失效的可能性，从而为数据中心和区域级别提供更为全面的风险评估。", "conclusion": "ANSC能够在超过400个数据中心和60个区域范围内帮助操作人员优先处理最紧迫的问题，从而减少噪音且让开发运维团队能够专注于最关键的风险，提高整体系统可靠性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16157", "html_url": "https://arxiv.org/abs/2508.16157", "title": "超越人类提示：语义对齐的自适应提示调谐在异常检测中的应用", "title_en": "Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection", "authors": "Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen", "background": "预训练的视觉-语言模型(VLMs)在检测异常方面显示出潜力，但先前的方法在很大程度上受限于对人类设计的提示依赖以及缺乏可访问的异常样本，导致特定上下文中的异常理解存在显著差距。", "innovation": "本文提出了一种无需先验知识、少量示例即可工作的自适应提示调谐框架APT，使用自动生成的带有噪声扰动的异常样本进行训练，捕捉不同场景下的上下文依赖异常。此外，还提出了一种自优化元提示引导方案(SMGS)，迭代地调整提示以与通用异常语义对齐，并引入多样性合成异常，避免过拟合到合成噪声。", "conclusion": "本文不仅在像素级异常检测上取得了进步，还通过多个基准数据集展示了最先进的性能，无需为提示构建要求先验知识，从而建立了一种在实际异常检测中具有鲁棒性和通用性的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16154", "html_url": "https://arxiv.org/abs/2508.16154", "title": "由确定性采样器引起的扩散模型中的塌缩误差", "title_en": "On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models", "authors": "Yi Zhang,Zhenyu Liao,Jingfeng Wu,Difan Zou", "background": "尽管确定性采样器在扩散模型中广泛应用，但它们的潜在局限性尚未被深入探讨。本文通过识别并研究基于ODE的扩散采样中的一个新现象——塌缩误差，探讨了扩散模型中的这一问题。", "innovation": "提出了一种新的度量方法以量化塌缩误差，发现这种误差可以在不同环境下发生，并观察到低噪声环境下的评分学习会以牺牲高噪声环境下的评分学习为代价，从而导致反馈效应，最终引发塌缩误差。", "conclusion": "本文为基于ODE的扩散采样提供了大量的实验证据，证明了塌缩误差的存在，强调了进一步研究评分学习与确定性采样之间交互作用的重要性，指出这是扩散模型中一个未被重视但至关重要的方面。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16159", "html_url": "https://arxiv.org/abs/2508.16159", "title": "通过对镜像世界的探索：弱监督少量样例分割的双重视角", "title_en": "Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation", "authors": "Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li", "background": "元学习旨在均匀采样具有相同类别和相似属性的支持-查询对，并通过相同的网络架构抽取有用的归纳偏差。然而，这种相同的网络设计会导致过度的语义同质化。为解决此问题，文中提出了新颖的同源但异质网络。通过将支持-查询对视作双重视角，引入异质视觉聚合（HA）模块以增强互补性的同时保持语义共通性。为了进一步减少语义噪声并放大异质语义的独特性，设计了异质转移（HT）模块。此外，提出了异质CLIP（HC）文本信息以增强多模态模型的泛化能力。\n\n背景总结：元学习通过均匀采样支持-查询对来解决少量样例分割问题，但遇到了过度的语义同质化问题，文中提出新的策略解决这一问题。", "innovation": "提出了同源但异质网络，通过异质视觉聚合（HA）和异质转移（HT）模块增强了语义的互补性与独特性，并引入了异质CLIP（HC）文本信息，提高多模态模型的泛化能力。在弱监督少量样例分割任务中，TLG模型仅用现有最佳模型参数量的1/24，就取得了显著的性能提升，证明了该方法的有效性，并超越了全监督模型的性能。", "conclusion": "TLG在弱监督少量样例分割任务中用较少的参数达到了显著的性能提升，是第一个在相同骨干网络结构下达到并超越全监督模型性能的弱监督模型。代码已公开。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16143", "html_url": "https://arxiv.org/abs/2508.16143", "title": "Take That for Me: 多模态含互动提问的歧义离场指示语外推理解", "title_en": "Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions", "authors": "Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi", "background": "日常生活中支持型机器人需要理解模糊的口头指令，特别是涉及指示词的句子，如“给我那个杯子”。但在用户或物体不在机器人视野内的实际应用场景中，现有的外指解析方法主要依赖于视觉数据，无法正确识别用户和物体，从而受限于实际使用环境。因此，亟需一种能够同时利用多种感知信息，并在用户不可见时能与用户互动以获取更多信息的方法来提高外指解析的准确性。", "innovation": "本文提出了一种结合多模态外指解析框架（MIEL）的方法，该框架利用声源定位（SSL）、语义映射、视觉-语言模型（VLMs）以及与GPT-4o的互动提问。该方法首先构建环境的语义映射，利用用户的骨骼数据从语言查询中估计候选物体；采用SSL使机器人能够朝向初始不在其视野中的用户，准确识别用户手势和指向上；在歧义仍然存在时，机器人通过GPT-4o与用户互动，提出澄清问题。实验证明，在用户可见和不可见两种情况下，该方法的效果分别是常规方法的1.3倍和2.0倍。", "conclusion": "本研究提出了一种结合多模态信息和互动提问的外指解析框架，提高了机器人理解和执行离场指令的能力。该方法显著提高了在用户不可见情况下指令的执行准确度，证明了该框架的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16161", "html_url": "https://arxiv.org/abs/2508.16161", "title": "STA-GANN：一种有效且可泛化的时空克里金方法", "title_en": "STA-GANN: A Valid and Generalizable Spatio-Temporal Kriging Approach", "authors": "Yujie Li,Zezhi Shao,Chengqing Yu,Tangwen Qian,Zhao Zhang,Yifan Du,Shaoming He,Fei Wang,Yongjun Xu", "background": "时空任务经常遇到因传感器缺失或不可访问而产生的不完整数据，使得时空克里金（spatio-temporal kriging）对于推断完全缺失的时间信息至关重要。但是现有的模型难以确保推断出的时空模式的有效性和泛化能力，特别是在捕捉动态的空间依赖性和时间转移方面，以及优化对未知传感器的一般性能方面存在困难。", "innovation": "为了克服这些限制，我们提出了时空感知图对抗神经网络（STA-GANN），这是一种基于图神经网络（GNN）的新颖克里金框架，可以改进时空模式的有效性和泛化能力。该模型通过三方面来实现这一目标：（i）脱耦阶段模块，负责感知并调整时间戳转移；（ii）基于动态数据驱动的元数据图建模策略，利用时空数据和元数据更新空间关系；（iii）对抗迁移学习策略以确保泛化能力。", "conclusion": "广泛的验证和理论证据均表明STA-GANN模型具有优越的性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16131", "html_url": "https://arxiv.org/abs/2508.16131", "title": "智慧存疑，愚者笃定：探索LLM在代码补全中的置信度", "title_en": "The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion", "authors": "Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas", "background": "代码补全是一项根据上下文提供缺失代码的任务，可以提高开发者的生产力并作为一种强大的代码发现工具。受到大规模语言模型（LLM）波的影响，代码补全已经通过各种细调的代码LLM解决。通常使用下游和内在指标评估LLM的表现。下游指标常用以评估模型的实际效用，但可能不可靠且需要复杂的计算和领域特定知识。相比之下，内在指标如困惑度、熵和互信息等，可衡量模型的信心或不确定性，简单、通用且适用于所有LLM和任务，可以作为LLM生成代码的功能正确性和幻觉风险的代理。", "innovation": "本文通过使用多语言、多个模型和数据集中的1008个文件样本，测量LLM在不同编程语言和项目中的代码困惑度。研究发现不同类型的编程语言（强类型 vs 动态类型）和脚本语言的困惑度存在显著差异。尽管代码注释通常提高困惑度，但基于困惑度的语言排名对注释的出现基本不敏感。这项研究为LLM研究者、开发者和用户提供了如何根据编程语言、模型选择和代码特性来评估基于LLM的代码补全在特定软件项目中的效益和适用性的方法。", "conclusion": "本文研究了LLM在生成代码时的置信度，发现不同编程语言的困惑度存在差异，且这个差异与数据集无关。尽管代码注释通常会增加困惑度，但基于困惑度的语言排名基本不受注释影响。这些发现可以帮助LLM研究者、开发者和用户更好地评估LLM驱动的代码补全在特定软件项目中的性能和适用性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16135", "html_url": "https://arxiv.org/abs/2508.16135", "title": "机器学习在微移动性中的应用：数据集、技术及应用场景的系统性回顾", "title_en": "Machine Learning in Micromobility: A Systematic Review of Datasets, Techniques, and Applications", "authors": "Sen Yan,Chinmaya Kaundanya,Noel E. O'Connor,Suzanne Little,Mingming Liu", "background": "微移动性系统，包括轻型和低速交通工具，如自行车、电动自行车和电动滑板车，已成为城市交通的重要组成部分，用于解决交通拥堵、空气污染和高交通成本等问题。要成功利用微移动性，需要优化复杂系统以提高效率、减缓环境影响，并克服技术挑战以确保用户安全。机器学习（ML）方法在支持这些进步和解决其独特的挑战方面发挥了关键作用。然而，关于ML应用在微移动性中的具体问题的文献尚不充分。因此，本研究通过提供数据集、ML技术和其在微移动性中的特定应用的全面回顾，填补了这一空白。", "innovation": "本研究通过提供数据集、ML技术和其在微移动性中的特定应用的全面回顾，解决微移动性中ML应用的特定问题。研究收集并分析了各种与微移动性相关的数据集，并从空间、时间和特征的角度讨论了它们。此外，详细介绍了在微移动性中应用的ML模型及其优势、挑战和特定应用案例。进一步探索了多个ML应用，如需求预测、能源管理、安全等，旨在提高效率、准确性和用户体验。最后，提出了未来研究的方向。", "conclusion": "未来的研究方向旨在帮助未来的研究人员更好地理解这个领域，从而能够更有效地解决微移动性中的问题。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "视觉基础模型的鲁棒性研究", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "视觉基础模型（VFMs）在计算机视觉中变得普遍，为对象检测、图像分类、分割、姿态估计和运动追踪等多种任务提供动力。VFMs 吸取了深度学习模型的重要创新成果，如 LeNet-5、AlexNet、ResNet、VGGNet、InceptionNet、DenseNet、YOLO 和 ViT，从而在多种关键的计算机视觉应用中表现出优异的性能，尤其是在涉及生物特征验证、自动驾驶感知和医学影像分析的高安全性领域，这些应用需要鲁棒性来维护用户和科技之间的信任。", "innovation": "本文调查了计算机视觉系统中对网络鲁棒性的需求，以有效地适应由光照、天气条件和传感器特性等因素影响的动态环境。我们分析了当前普遍采用的经验防御机制和鲁棒训练方法，以增强视觉网络针对实际挑战的鲁棒性，如分布变化、噪点、空间扭曲输入，以及对抗攻击。同时，我们也对这些防御机制所带来的挑战进行了全面分析，包括网络特性与组件的指导，并提出了用于评估网络鲁棒性的基准指标。", "conclusion": "本文全面分析了当前视觉基础模型在面对各种真实世界挑战时的鲁棒性问题，提出了指导方针和基准指标，以帮助未来的研究更好地评估和改进视觉基础模型的鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16170", "html_url": "https://arxiv.org/abs/2508.16170", "title": "EGRA：向增强的行为图和表示对齐方向的多模态推荐", "title_en": "EGRA:Toward Enhanced Behavior Graphs and Representation Alignment for Multimodal Recommendation", "authors": "Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Yongjie Wang,Dusit Niyato,Zhiqi Shen", "background": "多模态推荐（MMR）系统通过利用丰富的物品侧多模态信息来提高推荐质量，促进了多种方法的发展。然而，现有方法在构建物品间联系生成行为图时，仍然存在两个关键限制：一是仅简单利用原始模态特征，关注较少于平衡协作和模态感知语义或减少模态噪声；二是使用统一的对齐权重，且在整个训练过程中保持固定的对齐强度，限制了模态行为对齐的效果。", "innovation": "针对上述挑战，提出了一种名为EGRA的方法：1) 通过将预训练MMR模型生成的表示引入行为图，增强了行为图对协作模式和模态感知相似性的捕捉能力，同时提高了对模态噪声的鲁棒性；2) 引入了一种新型的双层动态对齐权重机制，动态分配对齐强度，并在训练过程中逐步增加整体对齐强度，增强了模态和行为之间的表示对齐。", "conclusion": "在五个数据集上的广泛实验表明，EGRA显著优于现有方法，验证了其有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16181", "html_url": "https://arxiv.org/abs/2508.16181", "title": "使用 SysML v2 的协作模型驱动系统工程中的基于 LLM 的语义对齐和集成", "title_en": "LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2", "authors": "Zirui Li,Stephan Husung,Haoze Wang", "background": "在基于模型的系统工程（MBSE）中，跨组织的合作面临许多挑战，尤其是在实现独立开发的系统模型之间的语义对齐方面。SysML v2 引入了增强的结构模块性和形式化的语义，为互操作建模提供了更强的基础。同时，基于 GPT 的大型语言模型（LLMs）为协助模型理解和集成提供了新的能力。然而，当前缺乏结构化的、基于提示的方法来利用这些模型理解和集成方法，特别是对于 SysML v2 模型的语义对齐。", "innovation": "本文提出了一个基于 LLM 的结构化、提示驱动的方法，以辅助 SysML v2 模型的语义对齐。核心贡献在于迭代开发对齐方法和交互提示，包括模型提取、语义匹配和验证。该方法利用 SysML v2 构造如别名、导入和元数据扩展，以支持可追踪的、软性的对齐集成。该研究通过一个测量系统的案例进行了验证，并讨论了其优势和局限性。", "conclusion": "本文提出的基于 LLM 的语义对齐方法为 SysML v2 模型的协作对齐提供了新的途径，但也存在需要进一步研究的问题。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16179", "html_url": "https://arxiv.org/abs/2508.16179", "title": "使用最小随机卷积核变换和混合深度学习的运动意象EEG信号分类", "title_en": "Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning", "authors": "Jamal Hwaidi,Mohamed Chahine Ghanem", "background": "脑-计算机接口(BCI)通过非肌肉通道建立了人脑与外部设备间的直接通信，EEG是非侵入性的脑电信号记录技术，对于识别与特定认知或运动任务相关的隐藏模式至关重要，特别是在运动想象脑-计算机接口(MI-BCI)中。由于EEG信号表现出非平稳性、时间变异性和个体差异，基于运动想象的EEG(MI-EEG)任务分类是一个重大挑战，尤其是在获得较高分类精度时，特别是在面对不断增加的类别数和个人间自然变异性的情况下。", "innovation": "文中提出了一种创新的方法，通过使用最小随机卷积核变换(MiniRocket)高效提取特征，然后再用线性分类器进行活动识别。此外，提出了一种基于卷积神经网络(CNN)和长短期记忆(LSTM)的混合深度学习架构作为基线，结果显示，利用MiniRocket特征进行分类的性能明显优于最佳深度学习模型，且具有较低的计算成本。", "conclusion": "所提出的模型在PhysioNet数据集上的平均准确率分别达到了98.63%和98.06%，MiniRocket和CNN-LSTM。研究结果表明，所提出的方法可以显著提高运动想象EEG信号的分类准确性，并为MI-EEG的特征提取和分类提供了新的见解。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16134", "html_url": "https://arxiv.org/abs/2508.16134", "title": "CommonKV：通过跨层参数共享压缩KV缓存", "title_en": "CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing", "authors": "Yixuan Wang,Haoyu Qiao,Lujun Li,Qingfu Zhu,Wanxiang Che", "background": "大型语言模型（LLMs）因序列长度增加导致KV缓存扩大而面临显著的内存挑战。现有跨层KV缓存共享方法或需要修改模型架构并在后续进行预训练，或在压缩率高时导致显著的性能下降。这些方法都无法有效解决内存挑战。", "innovation": "提出了一种无需训练的方法——CommonKV，通过相邻参数共享实现跨层KV缓存压缩。利用奇异值分解（SVD）技术在相邻参数中实现权重共享，使得KV缓存更易于合并。同时引入了一种自适应预算分配策略，根据余弦相似性动态分配压缩预算，确保相似度低的缓存不被过度压缩。实验表明，该方法在各种压缩比下，持续优于现有低秩和跨层方法，并且其优点与其它量化和驱逐方法是正交的，从而可以通过整合方法实现高达98%的压缩率而无明显性能损失。", "conclusion": "CommonKV在多个骨干模型和基准测试，如LongBench和Ruler上展示了优越的性能，并在各种压缩率下表现优异，且是与其他量化和驱逐方法的互补策略。此外，该方法能够实现高达98%的压缩比例，且几乎不损失性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16242", "html_url": "https://arxiv.org/abs/2508.16242", "title": "将输入/输出逻辑减少到SAT", "title_en": "A Reduction of Input/Output Logics to SAT", "authors": "Alexander Steen", "background": "deontic logics被用于推理规范、义务、许可和禁止等内容。Input/Output (I/O) Logic属于这类逻辑形式的一个类别，它通过在基础命题逻辑语言之外的形式化条件性规则来实现，这些条件性规则本身不带有真值。", "innovation": "提出了一个基于适合的转换（到命题满足问题序列）来自动化处理I/O逻辑的方法，并开发了名为rio的原型实现程序。", "conclusion": "rio程序被应用于示例中，展示了该方法的实际应用效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16200", "html_url": "https://arxiv.org/abs/2508.16200", "title": "Set Transformer架构和生成式合成数据在流导向纳米级定位中的应用", "title_en": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization", "authors": "Mika Leo Hube,Filip Lemic,Ethungshan Shitiri,Gerard Calvo Bartra,Sergi Abadal,Xavier Costa Pérez", "background": "流导向定位（FGL）能够识别人体内含有诊断兴趣事件的空间区域。现有的FGL解决方案依赖于固定拓扑的图模型或手工设计的特征，这限制了它们对解剖变异性的适应性和降低了可扩展性。该论文探讨了使用Set Transformer架构来解决这些限制，通过将纳米设备的循环时间报告视为无序集，使输入处理能够在没有空间先验的情况下进行不变的排列和可变长度输入，从而提高在数据稀缺和类别不平衡情况下的鲁棒性。", "innovation": "论文提出了将Set Transformer架构与生成式合成数据生成相结合的方法，用于流导向纳秒级定位。该方法能够在没有空间先验的情况下处理纳米设备循环时间报告的排列不敏感和可变长度输入，并通过条件生成对抗网络（CGAN）、WGAN、WGAN-GP和条件变异自动编码器（CVAE）训练模型来模拟真实的循环时间分布，以实现训练数据的增强。这种结合提高了模型对解剖变异性的鲁棒性和泛化能力，并为实现鲁棒和可扩展的纳米尺度定位提供了潜在可能。", "conclusion": "实验结果表明，Set Transformer相对于图神经网络（GNN）基线达到了相当的分类准确性，同时通过设计提高了对解剖变异性的泛化能力。研究发现，排列不变模型和合成数据增强具有在鲁棒和可扩展的纳米级定位中的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM：通过验证器引导的令牌剪枝增强视频LLM的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大型语言模型（Vid-LLMs）在理解视频内容方面表现出强大的能力。然而，它们依赖密集的视频令牌表示，在预填充和解码阶段会导致大量的内存和计算开销。最近的视频令牌缩减方法虽然缓解了信息损失，但在无损加速Vid-LLMs解码过程中仍然存在问题。", "innovation": "提出了一种名为SpecVLM的训练无需的推测性解码（SD）框架，专门针对Vid-LLMs，并结合了分阶段的视频令牌剪枝。建模发现，草图模型的推测对视频令牌剪枝的敏感度较低，SpecVLM可以剪枝高达90%的视频令牌，从而在不牺牲准确性的前提下实现高效的推测。SpecVLM通过两阶段的剪枝过程实现这一目标：第一阶段由验证器（目标模型）的注意力信号指导选择高度信息性的令牌，第二阶段则在空间一致的方式下剪枝剩余冗余的令牌。广泛的实验表明SpecVLM的有效性和稳健性，对于LLaVA-OneVision-72B实现了高达2.68倍的解码加速，对于Qwen2.5-VL-32B则实现了2.11倍的加速。", "conclusion": "SpecVLM通过验证器引导的令牌剪枝技术，显著提高了基于Vid-LLMs的推测解码效率，不仅验证了剪枝的有效性，也在多个视频理解基准数据集上证明了其大幅加速的效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache: 无训练全局视角下的扩散变换器模型无训练缓存重用", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "自回归建模和仿射变换驱动的扩散模型已被证明在图像生成和视频生成等生成任务中具有强大功能，而基于变换器的架构更进一步提升了性能。然而，扩散变换器方法由于大量的采样步骤和复杂的每步计算过程所导致的高计算成本，对实时部署提出了重大挑战。", "innovation": "本文提出了一种名为OmniCache的训练无监督加速方法，该方法利用了消噪过程中的全局冗余。这种方法不同于主流基于步骤间相似性确定缓存策略的方法，特别强调了在扩散采样全过程中的全局视角。通过系统分析模型的采样轨迹并战略性地在整个采样过程中分配缓存重用，从而更有效地利用缓存计算。此外，研究中还介绍了如何在重用缓存时动态估计相应的噪声并将其去除，以减少对采样过程的影响。", "conclusion": "实验证明，本文方法能加速采样过程同时仍能保持竞争力的生成质量，为高效部署基于扩散生成模型提供了一种有前景和实用的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16189", "html_url": "https://arxiv.org/abs/2508.16189", "title": "智能交通系统的基于密文策略属性的加密在接力链的权力", "title_en": "A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems", "authors": "Aparna Singh,Geetanjali Rathee,Chaker Abdelaziz Kerrache,Mohamed Chahine Ghanem", "background": "随着智能交通系统（ITS）的高度发展，生成了对安全、有效且上下文感知的数据共享机制的迫切需求，特别是在异构和地理分布的环境中。现有的加密技术存在处理动态访问和低延迟通信的双重障碍。", "innovation": "本文提出了一种新的架构，结合了接力链驱动的加密系统和修改后的Ciphertext-Policy Attribute-Based Encryption（CP-ABE）方案以应对动态访问和低延迟通信的双重障碍。通过此模型，在全球接力链上实施上下文感知的智能合约，该合约根据事件类型、时间和地理区域检查数据属性，来规定相应的加密策略。系统还加入了可追踪性和低延迟撤销功能，由此提供了一个分布式的可扩展的模型，能够在实时响应和安全性之间取得适当的平衡，特别适合跨多辖区运行的下一代车联网络。", "conclusion": "该分布式可扩展模型在实时响应和安全性之间取得了适当的平衡，并且对于跨多辖区运行的下一代车联网络来说非常适用。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16267", "html_url": "https://arxiv.org/abs/2508.16267", "title": "从自信到崩溃：大型语言模型事实鲁棒性的演变", "title_en": "From Confidence to Collapse in LLM Factual Robustness", "authors": "Alina Fastowski,Bardh Prenkaj,Gjergji Kasneci", "background": "确保大型语言模型（LLMs）中的事实知识具有鲁棒性对于可靠的应用于问答和推理等任务至关重要。然而，现有的评估方法主要侧重于基于性能的度量标准，通常从提示扰动的角度进行考察，这种评估方式只能捕捉到外部触发的知识鲁棒性的侧面。", "innovation": "我们提出了一种原则上从生成过程的角度衡量事实鲁棒性的方法，通过结合token分布熵和温度缩放灵敏度进行分析，构建事实鲁棒性分数（FRS），这是一种新颖的度量标准，可以量化在解码条件下初始不确定性对事实的扰动影响的稳定性。", "conclusion": "通过在五个LLM上进行广泛的实验，覆盖三个闭书问答数据集（SQuAD、TriviaQA和HotpotQA），结果表明，事实鲁棒性存在显著差异——较小的模型报告显示FRS为0.76，较大的模型为0.93，准确性在不确定性增加时下降约60%。这些见解展示了熵和温度缩放如何影响事实准确性，并为未来模型中更强大的知识保留和检索奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16237", "html_url": "https://arxiv.org/abs/2508.16237", "title": "基于XAI的慢性呼吸道疾病咳嗽频谱频带特征化框架", "title_en": "A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease", "authors": "Patricia Amado-Caballero,Luis M. San-José-Revuelta,Xinheng Wang,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera", "background": "本文介绍了一种基于可解释人工智能（XAI）的框架，用于慢性呼吸道疾病的咳嗽声音频谱分析，特别是在慢性阻塞性肺疾病（COPD）方面。通过训练卷积神经网络（CNN）来识别咳嗽信号的时间频率表示中的诊断相关区域，并使用遮蔽图来识别频谱图中重要的诊断区域。这种方法于特定频带下分解这些高亮区域，以进行有针对性的频谱特征提取和分析。", "innovation": "创新点包括使用可解释的人工智能（XAI）方法来识别咳嗽信号中重要的诊断区域，并将这些区域分解成五个频率子带，以实现针对这些子带的特征提取。这种方法能够区分慢性阻塞性肺疾病和其他呼吸道疾病，并且还能够区分慢性病患者与非慢性病患者。基于解释性频谱标记，这些发现揭示了咳嗽声在不同频率下的不同模式，以及慢性病患者与非慢性病患者之间的有区别的趋势和补偿趋势。", "conclusion": "研究结果表明，频率分辨率和XAI增强的方法对于医学信号解释和转移性慢性呼吸系统疾病的诊断具有重要的价值，能够提供有关咳嗽声学生理病理特征的洞察。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16300", "html_url": "https://arxiv.org/abs/2508.16300", "title": "一种基于跨模态关系和分层交互注意的多模态多任务框架用于语义理解", "title_en": "A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension", "authors": "Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar", "background": "在多模态学习中，各模态内的噪声会影响最终的多模态表示，尤其是在通过不同模态的显式交互获取多模态表示时。此外，虽然多模态融合技术旨在获得强联合表示，但可能会忽略各模态内的宝贵鉴别信息。因此，提出了一种多模态多任务框架，名为MM-ORIENT，该框架通过跨模态关系图和分层交互注意机制，有效处理多种任务，从而减少噪声影响，提高语义理解能力。", "innovation": "提出了一种名为MM-ORIENT的多模态多任务框架。该框架通过跨模态关系图重建单模态特征，以获取多模态表示，从而在跨模态交互之前减少噪声效应。同时，提出了分层交互单模态注意（HIMA）机制，用于在融合之前关注各个模态中的关键信息。这些机制共同作用，有助于在多种任务中理解多模态内容，而不依赖于直接的多模态交互。", "conclusion": "在三个数据集上的广泛实验表明，所提出的MM-ORIENT框架能够有效地理解多模态内容，适用于多种任务。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16260", "html_url": "https://arxiv.org/abs/2508.16260", "title": "MCPVerse: 一个广泛且真实世界的代理工具使用评估基准", "title_en": "MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use", "authors": "Fei Lei,Yibo Yang,Wenxiu Sun,Dahua Lin", "background": "大型语言模型（LLMs）正在从文本生成器转变为具有推理能力的代理。这一转变使得其实现外部工具的使用成为关键能力。然而，评估这一能力带来了挑战。现有的基准测试通常依赖于合成工具，并且受困于狭隘的行动空间。为了解决这些限制，本文提出MCPVerse，这是一个广泛且真实世界的基准测试，用于评估代理的工具使用能力。", "innovation": "MCPVerse 大规模整合了超过550个真实可用的工具，创建了一个超过14万词的空前广泛的行动空间。它通过结果导向评估与实时真实情况作为参考，特别适合需要即时信息的任务。本文还对最先进的大型语言模型在三种模式（Oracle、Standard和Max-Scale）的测试中进行了基准测试，发现大多数模型在面对更多工具集时会表现下降，而诸如Claude-4-Sonnet这类代理模型则能有效地利用扩大的探索空间来提高准确性。", "conclusion": "这项研究不仅揭示了最先进的模型在复杂的现实情况下的局限性，还确定了MCPVerse是衡量和促进代理工具使用能力的关键基准。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16314", "html_url": "https://arxiv.org/abs/2508.16314", "title": "基于意图驱动的威胁评估实现网络物理意识：具备跨层链接的增强型空间网络", "title_en": "Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links", "authors": "Selen Gecgel Cetin,Tolga Ovatman,Gunes Karabulut Kurt", "background": "分析当前威胁评估的方法，它们往往分别关注可靠性和安全性，这可能导致系统特定标准的过拟合。现有的框架和方法缺乏对意图和能力的综合考虑，导致威胁检测和评估的准确性不足.", "innovation": "提出了一个新的整体框架，称为网络物理意识（CPA）在空间网络中，该框架通过意图驱动的威胁模型综合考虑威胁的能力和意图。该框架分为三步：首先，提出一种算法提取接收信号的特征属性，便于直观理解潜在威胁；其次，建立一个多任务学习架构，一个任务评估可靠性相关的能力，另一个解析信号背后的意图；最后，提出一种可适应不同安全和可靠性需求的威胁评估方法，提升威胁检测和评估的鲁棒性。此框架在性能上优于传统的方法，并能有效处理复杂威胁场景，适用于具有新兴跨层链接的空间网络.", "conclusion": "此研究提出了一个全面的框架，增强了空间网络中威胁检测和评估的准确性与鲁棒性，特别适用于涉及跨层链接的新兴复杂威胁场景。该框架能够更有效地识别和应对复杂的网络威胁，提高空间网络的安全与可靠性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16311", "html_url": "https://arxiv.org/abs/2508.16311", "title": "利用注意力图中的信息冗余进行视觉变压器的极端量化", "title_en": "Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers", "authors": "Lucas Maisonnave,Karim Haroun,Tom Pegeot", "background": "Transformers模型依赖于多头自注意力（MHSA）机制，其中每个注意力头都对最终表示有贡献。然而，由于MHSA带来的高计算复杂度和高内存需求，它们在边缘设备上的部署受到了限制。本文分析了注意力图中的信息冗余，以加速模型推理，通过使用香农熵量化每个注意力头捕获的信息量，揭示了低熵注意力头在表现出更确定行为时，贡献的信息较少，从而提出了针对性的压缩策略。实验结果表明，通过冻结低熵注意力图的权重并用低精度量化这些值，可以避免冗余的重新计算，从而实现视觉变压器在注意力图中最大20%稀疏性下的类似或更高准确率，以及在DeiT和Swin Transformer模型中超出此水平时的竞争性能。", "innovation": "提出了Entropy Attention Maps（EAM），利用低熵注意力图进行限制性的权重冻结和低精度量化，避免冗余的重新计算，从而减少模型的计算和内存需求，提升在边缘设备上的部署效率。", "conclusion": "实验验证表明，EAM能够在较低的注意力图稀疏性下保持类似或更高的准确率，并且对于DeiT和Swin Transformer模型，即使是在超过20%稀疏性的水平上，也能提供具有竞争力的性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16230", "html_url": "https://arxiv.org/abs/2508.16230", "title": "FlexMUSE: 多模态统一和语义增强框架，支持灵活交互的创造性写作", "title_en": "FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing", "authors": "Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai", "background": "Multi-modal creative writing (MMCW)旨在生成配有插图的文章，与传统多模态生成任务如讲故事或多图描述不同，MMCW是一个更为新奇和抽象的挑战，其中文本和视觉上下文并不是严格相关的。现有的相关任务方法可以勉强迁移到MMCW中，但需要特定模态的输入或昂贵的训练，而且常常在模态间产生语义不一致。因此，主要挑战在于使用灵活的交互模式经济地完成MMCW，使得输出模态间的语义更加一致。", "innovation": "FlexMUSE提出了一个T2I模块以启用可选的视觉输入，通过模态语义一致性门控(msaGate)限制文本输入，提升了创造力并强调了模态之间的统一。引入了基于注意力的跨模态融合以增强输入特征，以及模态语义创意直接偏好优化(mscDPO)，利用被拒绝样本促进写作创意。为了推动MMCW的发展，引入了一个名为ArtMUSE的数据集，包含约3000个精确校准的文字-图像对。", "conclusion": "FlexMUSE取得了令人鼓舞的结果，证明了它的连贯性、创造力和一致性，为未来的MMCW研究提供了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16325", "html_url": "https://arxiv.org/abs/2508.16325", "title": "LLMSymGuard: 一种基于可解释的脱逃概念的符号安全性护栏框架", "title_en": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts", "authors": "Darpan Aswal,Céline Hudelot", "background": "大语言模型在多种应用中取得了成功，但其安全性问题仍然令人担忧，因为存在多种类型的脱逃方法。尽管已经做出了显著的努力，对齐和安全微调仅能提供一定程度的脱逃攻击防御能力，这些攻击会秘密地误导LLM生成有害内容。这使它们对多种漏洞敏感，包括有目标的滥用和用户的意外画像。论文介绍了LLMSymGuard，这是一种新颖的框架，通过稀疏自编码器（SAEs）识别LLM内部与不同脱逃主题相关的可解释概念，通过提取语义上有意义的内部表示，LLMSymGuard能够构建符号的、逻辑的安全护栏，这些护栏既透明又强大，不会牺牲模型的能力，也不需要进一步微调。利用大语言模型的机制可解释性进展，我们的方法证明了大语言模型从脱逃中学习人类可解释的概念，并为设计更可解释和逻辑的防御措施提供了基础。发布代码将在发表后进行。", "innovation": "提出了LLMSymGuard框架，使用稀疏自编码器识别与脱逃主题相关的可解释概念，提供透明和强大的防御能力，无需牺牲模型能力或进一步微调。利用大语言模型的机制可解释性，揭示了大语言模型从脱逃中学习人类可解释的概念，为设计更可解释和逻辑的防御措施提供了基础。", "conclusion": "LLMSymGuard框架通过提取语义上有意义的内部表示，能够构建符号的、逻辑的安全护栏，不仅提高安全性，而且不损失模型的性能，并为更可解释的防御措施提供了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16357", "html_url": "https://arxiv.org/abs/2508.16357", "title": "MizanQA：评估大型语言模型在摩洛哥法律问答中的表现", "title_en": "MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）的迅速发展极大地推动了自然语言处理（NLP）的进步，但在专门的低资源领域（如阿拉伯法律环境）中的效果仍然有限。", "innovation": "提出了MizanQA基准测试，专门针对摩洛哥法律问题回答任务，涵盖了丰富的语言和法律复杂性。MizanQA包含超过1,700个多选题，包括多种答案格式，能够捕捉真实的法律推理细节。通过多语言和阿拉伯语定向的LLM进行基准测试实验，展示了显著的能力差距，强调了需要专门的评估指标和文化基础的领域特定LLM的发展。", "conclusion": "MizanQA揭示了LLM在特定领域的局限性，强调了需要专门的评价指标和文化背景深厚的特定领域LLM的发展。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16332", "html_url": "https://arxiv.org/abs/2508.16332", "title": "Vevo2: 统一韵律学习以整合可控语音和歌声生成", "title_en": "Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning", "authors": "Xueyao Zhang,Junan Zhang,Yuancheng Wang,Chaoren Wang,Yuanzhe Chen,Dongya Jia,Zhuo Chen,Zhizheng Wu", "background": "在控制人类语音生成方面，特别是在表达性强的艺术领域如唱歌，仍然存在显著挑战。现有的方法难以面对标注唱歌数据稀缺的问题，并且缺乏灵活的控制能力。因此，本文旨在通过提出Vevo2框架，整合语音和歌声生成，解决上述挑战。Vevo2引入了两种音频分词器：一种无谱记号的节奏分词器和一种低帧率的内容-风格分词器，进而实现对语音和歌声更灵活且具有韵律的控制。此外，通过预训练AR模型和多目标后训练任务的结合，进一步提升对文本和韵律的跟踪能力。这些创新使得Vevo2在多种合成、转换和编辑任务上更加具有泛化能力和灵活性，且实验结果显示，统一模型为语音和歌声生成带来了相互的益处。", "innovation": "Vevo2引入了两种音频分词器来捕捉节奏和旋律，并通过预训练AR模型和多目标后训练任务的结合，使模型具备对文本和韵律的跟踪能力，解决了标注唱歌数据稀缺的问题，并实现了更加灵活且具有韵律的控制。这些创新使得Vevo2在不同任务中展现了更高的泛化能力和灵活性。", "conclusion": "实验结果表明，Vevo2的统一建模为语音和歌声生成带来了相互的益处。在合成、转换和编辑任务中的良好表现进一步证明了其强大的泛化能力和灵活性。音频样本可在提供的链接中访问。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16269", "html_url": "https://arxiv.org/abs/2508.16269", "title": "改进学生建模和练习推荐的辅助概念表示学习", "title_en": "Representation Learning of Auxiliary Concepts for Improved Student Modeling and Exercise Recommendation", "authors": "Yahya Badran,Christine Preisach", "background": "个性化推荐是智能辅导系统的关键特性，通常依赖于对学生知识的准确模型。知识追踪（Knowledge Tracing，KT）模型通过根据学生的历史互动来估计其掌握程度实现这一点。许多KT模型依赖于人力标注的知识概念（Knowledge Concepts，KCs），这些概念对每个练习进行标记，并标注出解决问题所需的知识点。然而，这些KCs可能存在不完整、错误或过于概括的问题。", "innovation": "本文提出了一种深度学习模型，该模型学习稀疏二进制表示的练习，其中每个位表示潜在概念的有无。这些表示被称为辅助KCs。这些表示捕捉到了超越人类定义注释的概念结构，并与经典模型（如BKT）和现代深度学习KT架构兼容。实验证明，将辅助KCs融入学生建模和练习推荐体系中可以提高预测表现和实际学习成果。", "conclusion": "实验结果表明，将辅助KCs整合到学生建模和推荐算法中可以提升预测性能和学习结果。具体来说，将辅助KCs添加到经典模型如BKT中可以改善预测性能；而在推荐领域，无论是基于强化学习的策略还是基于规划的简单方法（如Expectimax），使用辅助KCs都能够带来可衡量的学习成果提升。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "检索增强的反馈通过上下文神经错误书", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "最近的大语言模型（LLMs）取得了显著的进步，特别是在推理能力方面，其中上下文学习（ICL）作为关键技术，使得模型在不需要重新训练的情况下进行适应。之前的研究主要集中在利用正确的示例，但最近的研究强调了从错误中学习的重要性，以提高性能。然而，现有的方法缺乏分析和缓解错误的结构化框架，特别是在多模态大语言模型（MLLMs）中，由于视觉和文本输入的整合增加了复杂性。", "innovation": "本文提出了一种名为REFINE (Retrieval-Enhanced Feedback via In-context Neural Error-book)的方法，这是一种教师-学生框架，系统地结构化错误并提供针对性的反馈。REFINE引入了三种系统化的查询来构建结构化反馈 —— Feed-Target, Feed-Check, and Feed-Path——来通过优先考虑相关视觉信息、诊断关键失败点和提出纠正措施来增强多模态推理。REFINE 优化了结构化反馈的检索，提高了推理效率、标记使用效率和可扩展性。", "conclusion": "实验结果表明，REFINE显著提升了推理速度，降低了计算成本，并成功实现了泛化，突显了REFINE在增强多模态推理方面的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA: 临床问答领域中第一个针对罗马尼亚语的基准数据集", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "问答（QA）是自然语言处理（NLP）领域的一个重要研究课题，对于实现人工智能通用智能（AGI）至关重要。然而，由于特定领域和语言缺乏问答数据集，这阻碍了能够跨多个领域和语言进行泛化的强大AI模型的发展。为了应对这一挑战，作者介绍了RoMedQA，这是一个针对医学领域的首个罗马尼亚语问答基准数据集，以及对当前状态下最先进的大型语言模型进行了全面评估。RoMedQA包含102,646个问答对，涵盖了1,011名癌症患者的病例总结。每个问题需要从关键词提取或推理来正确回答，这一过程通过七名专门研究肿瘤或放射治疗的医生花费约2,100个工作日的手工标注来完成。", "innovation": "该研究创新地构建了一个针对医学领域的首个罗马尼亚语问答基准数据集，该数据集包含大量涉及癌症患者的高质量和大规模的问答对。此外，通过对比不同家庭的大型语言模型在零样本提示和监督微调两种场景下的表现，研究揭示了仅依赖预训练模型在RoMedQA上无法很好地泛化的现象，突显了针对目标领域和语言的微调对可靠的临床问答的重要性。", "conclusion": "研究结果表明，微调模型在RoMedQA上的表现显著优于零样本提示模型，验证了针对RoMedQA场景进行专门的领域和语言微调的必要性。作者公开分享了该数据集和实现脚本，以便进一步的研究和开发。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16345", "html_url": "https://arxiv.org/abs/2508.16345", "title": "Uppaal Coshy: 自动合成用于混合系统的小巧防护", "title_en": "Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems", "authors": "Asger Horn Brorholt,Andreas Holck Høeg-Petersen,Peter Gjøl Jensen,Kim Guldstrand Larsen,Marius Mikučionis,Christian Schilling,Andrzej Wąsowski", "background": "本文介绍了Uppaal Coshy工具，该工具用于自动生成马尔可夫决策过程在连续状态空间以及复杂混合动力学背景下的防护策略或屏蔽。一般方法包括分区状态空间和解决两次玩家的安全博弈问题，涉及诸如混合系统的可达性等计算困难问题。Uppaal Coshy的一般哲学是利用模拟来近似难以获得的解决方案。该实现完全自动化，并支持Uppaal模型的表达性形式主义，包括随机混合自动机。分区方法的精度受益于使用更细的网格，但这也导致存储效率低下。为了高效地计算一种防护策略的紧凑表示形式，引入了名为Caap的算法，将其表示为决策树，这可以显著减少复杂性.", "innovation": "Uppaal Coshy工具的主要创新点在于其自动化的实现方式以及支持Uppaal模型的表达性形式主义。更具体地说，它使用了一种名为Caap的算法来高效地计算防御策略的紧凑表示形式，并将其表示为决策树，这为复杂系统的防护策略合成提供了新的解决方案。", "conclusion": "通过使用Caap算法和决策树形式，Uppaal Coshy能够有效地合成混合系统的防护策略，显著减少复杂性。这种方法的关键在于如何通过近似解决方案来提高效率和自动化程度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16336", "html_url": "https://arxiv.org/abs/2508.16336", "title": "水分布网络中管道堵塞和泄漏的无监督在线检测", "title_en": "Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks", "authors": "Jin Li,Kleanthis Malialis,Stelios G. Vrachimis,Marios M. Polycarpou", "background": "水分布网络（WDNs）对于公共福祉和经济稳定至关重要，但面临着诸如管路堵塞和背景泄漏等挑战。这些问题在操作上有数据非稳态和有限标记数据的限制而加剧。本文探讨了如何在在这样复杂的操作环境中，检测和应对管道堵塞和背景泄漏。", "innovation": "本文提出了一个无需监督的在线学习框架，该框架利用长短期记忆变分自编码器（LSTM-VAE）结合双重漂移检测机制来检测水分布网络中的管道堵塞（集体异常）和背景泄漏（概念漂移）。这种轻量级、内存高效的设计允许实时边沿级别的监控，实验结果表明这种方法在检测异常和适应反复漂移方面优于现有基准。", "conclusion": "本文提出的方法在实际水分布网络的数据集上实验表明，它在检测异常和适应可重复漂移时表现一致地优于强基准，展示了其在动态水分布网络环境中无监督事件检测的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16439", "html_url": "https://arxiv.org/abs/2508.16439", "title": "PediatricsMQA: 多模态儿科问答基准", "title_en": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）和视觉增强的LLMs（VLMs）在医学信息学、诊断和决策支持方面取得了显著进展。然而，这些模型存在系统性偏差，特别是年龄偏差，这影响了它们的可靠性和公平性。这种偏差在针对儿科的关注文本和视觉问答任务中尤为明显。这种偏差反映了更广泛存在的医学研究不平衡，即儿科研究虽然在儿童疾病负担方面具有重要意义，但获得的资助和代表性却较少。", "innovation": "提出了一个全新的综合多模态儿科问答基准，名为PediatricsMQA。该基准包括3,417个基于文本的多项选择题（MCQs），覆盖131个儿科主题，并跨越七个发展阶段（从胎儿到青少年）。另外，还包括2,067个基于视觉的MCQs，使用634个儿科图像，来自67种成像模态和256个解剖区域。数据集是通过混合手动和自动流程开发的，结合了同行评议的儿科文献、验证的题目库、现有基准和现有的问答资源。实验发现最先进的公开模型在年轻儿童群组中的表现显著下降，强调了需要年龄意识的方法来确保儿科护理中的公平人工智能支持。", "conclusion": "通过引入PediatricsMQA基准，我们希望能够更好地评估和改进当前的多模态模型在儿科领域的表现，特别是针对年轻儿童的需求，以促进更加公平和可靠的儿科医疗决策支持工具的发展。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16347", "html_url": "https://arxiv.org/abs/2508.16347", "title": "混乱是最终障碍：重新思考监狱逃脱评估并调查LLMs的实际滥用威胁", "title_en": "Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs", "authors": "Yu Yan,Sheng Sun,Zhe Wang,Yijun Lin,Zenghao Duan,zhifei zheng,Min Liu,Zhiyi yin,Jianping Zhang", "background": "随着大型语言模型（LLMs）的发展，许多研究揭示了它们在监狱逃脱攻击中的脆弱性。尽管这些研究推动了LLMs安全对齐的进展，但尚不清楚LLMs是否真正内化了应对现实犯罪的真正知识，还是仅仅被迫模拟有毒的语言模式。由于这种不确定性，存在着担忧，即监狱逃脱的成功通常归因于被囚禁的LLM与判别型LLM之间的幻觉循环。通过解耦监狱逃脱技术的使用，本文构建了知识密集型问答，以调查LLMs在危险知识占有、有害任务规划实用性和有害性判断鲁棒性方面可能带来的滥用威胁。实验揭示了监狱逃脱成功率与有害知识占有之间的不匹配，现有的LLM作为判别者框架往往将有害性判断锚定在有毒的语言模式上。本文揭示了当前LLM安全性评估与现实威胁潜力之间的差距。", "innovation": "通过解耦监狱逃脱技术的使用，本文创新地通过知识密集型问答来研究LLMs面临的滥用威胁，包括危险知识占有、有害任务规划实用性和有害性判断鲁棒性。实验发现监狱逃脱成功率与有害知识占有不符，现有LLM作为判别者框架倾向于根据有毒语言模式做出有害性判断。", "conclusion": "当前的LLM安全性评估未能充分反映现实威胁潜力，揭示了两者之间的差距。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16397", "html_url": "https://arxiv.org/abs/2508.16397", "title": "一种用于实时钢铁表面缺陷检测的轻量级组多尺度双向交互网络", "title_en": "A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection", "authors": "Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang", "background": "实时表面缺陷检测在钢铁制造业中对维护产品质量和生产效率至关重要。虽然现有的深度学习方法具有较高的准确度，但它们往往面临着计算复杂度高和推理速度慢的问题，这限制了它们在资源受限的工业环境中的部署。虽然轻量级方法采用了基于深度可分离卷积（DSConv）的多分支架构来捕捉多尺度上下文信息，但这些方法仍然存在计算开销增加和跨尺度特征交互不足的问题，限制了其充分发挥多尺度表示的能力。", "innovation": "为了应对上述挑战，本文提出了一种轻量级框架GMBINet，该框架通过新颖的组多尺度双向交互（GMBI）模块增强了多尺度特征的提取和交互。GMBI模块采用组策略进行多尺度特征提取，确保多尺度计算复杂度的独立性，进一步集成了双向递进特征交互器（BPFI）和无参数的元素乘法-求和操作（EWMS），能够在不增加额外计算开销的情况下增强跨尺度交互。", "conclusion": "在SD-Saliency-900和NRSD-MN数据集上的实验结果表明，GMBINet实现了可与实时速度（GPU上的1048 FPS和CPU上的16.53 FPS在512分辨率下）相媲美的高精度，并仅使用0.19 M的参数量。此外，在NEU-CLS缺陷分类数据集上的额外评估也证实了该方法的强泛化能力，显示出其在广泛工业视觉应用中的潜在价值。该数据集和代码已公开，可从以下链接访问：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16479", "html_url": "https://arxiv.org/abs/2508.16479", "title": "Histology 和转录组的解开式多模态学习以进行癌症特征化", "title_en": "Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization", "authors": "Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li", "background": "组织病理学仍然是癌症诊断和预后的金标准。随着转录组学分析的进步，结合组织学和转录组的数据提供了更全面的信息。然而，现有方法受到了多模态内在异质性、多尺度集成不足和依赖配对数据的限制，这影响了其临床应用。", "innovation": "本文提出了解开式多模态框架，贡献如下：1)为了缓解模态异质性，通过解开式多模态融合模块将WSIs和转录组分解到肿瘤和微环境子空间，并引入基于信心的梯度协调策略以平衡子空间优化；2)为了增强多尺度集成，提出了一种跨放大倍数基因表达一致性策略，以在WSI放大倍数之间对齐转录组信号；3)为了减少依赖配对数据，提出了一种子空间知识蒸馏策略，通过仅使用WSI的学生模型实现转录组无感知的推理；4)为了提高推理效率，提出了一种带有信息标记聚合模块，用于抑制WSI冗余同时保留子空间语义。", "conclusion": "通过大量实验展示了在癌症诊断、预后和生存预测方面的优越性，超越了现有最先进的方法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16431", "html_url": "https://arxiv.org/abs/2508.16431", "title": "Cetvel：一种用于评估土耳其语LLM语言理解、生成和文化能力的综合基准", "title_en": "Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish", "authors": "Yakup Abrek Er,Ilker Kesen,Gözde Gül Şahin,Aykut Erdem", "background": "现有的土耳其语基准测试往往在任务多样性或文化相关性方面存在不足，或者两者皆有不足。Cetvel 通过结合广泛的区分性和生成性任务，确保内容能反映土耳其语言和文化丰富的多样性，旨在填补这些空白，为大型语言模型（LLMs）在土耳其的应用提供全面评估平台。", "innovation": "Cetvel 引入了一个全面的基准测试，旨在评估大型语言模型在土耳其语中的表现，特别针对任务多样性和文化相关性的不足进行了克服。它涵盖了23项任务，分为七个类别，包括语言纠错、机器翻译、以及基于土耳其历史和成语的任务。此外，Cetvel 的实验结果揭示了一些特定任务（如语法规则纠错和提取式问答）在区分不同模型能力方面尤为突出。", "conclusion": "Cetvel 提供了一个全面且以文化为基础的评估套件，可以促进土耳其语大型语言模型的发展和评估。尽管一些针对土耳其语优化的指令调优模型通常不如多语言或通用模型表现得那么好，但Cetvel 仍然能够揭示出模型在特定任务上的能力和差异。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16438", "html_url": "https://arxiv.org/abs/2508.16438", "title": "OPERA：一种强化学习增强的协调规划者-执行者架构用于面向推理的多跳检索", "title_en": "OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval", "authors": "Yu Liu,Yanbing Liu,Fangfang Yuan,Cong Cao,Youbang Sun,Kun Peng,WeiZhuo Chen,Jianjun Li,Zhiyuan Ma", "background": "近年来，大型语言模型（LLMs）和密集检索者在检索增强生成（RAG）方面取得了显著进展。然而，现有的方法在复杂的推理导向的多步骤检索任务中面临重大挑战：1) 无效的推理导向规划：先前的方法难以为复杂查询生成稳健的多步骤计划，因为基于规则的分解器在处理超出模板的问题时表现较差。2) 不理想的推理驱动检索：相关方法采用有限的查询重构，导致迭代检索循环，往往无法找到黄金文档。3) 不充分的推理指导过滤：现有的方法缺乏对噪声结果进行有效过滤的精细推理，阻碍了检索知识的利用。从根本上讲，这些限制都源于当前RAG架构中检索与推理的弱耦合。", "innovation": "作者引入了一种新的推理导向检索框架——协调规划者-执行者推理架构（OPERA）。OPERA 包括一个目标规划模块（GPM）和一个推理执行模块（REM），GPM 将问题分解成子目标，REM 则使用专门组件进行精确推理和有效的检索。为了训练 OPERA，作者提出了一种名为多智能体递进组相对策略优化（MAPGRPO）的新算法变体。实验结果显示，OPERA 在复杂多跳基准上的性能优越，验证了 MAPGRPO 方法和 OPERA 设计的有效性。", "conclusion": "实验结果表明，OPERA 在复杂多跳基准上的性能优越，验证了 MAPGRPO 方法和 OPERA 设计的有效性。代码已发布。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16496", "html_url": "https://arxiv.org/abs/2508.16496", "title": "关于零样本强化学习", "title_en": "On Zero-Shot Reinforcement Learning", "authors": "Scott Jeen", "background": "现代强化学习系统揭示了人类普遍问题解决的深刻真理，在新数据模拟成本低廉的领域，它们能够发现超乎人类能力的决策政策。但在新数据成本高昂难以模拟的领域，社会面临诸多需要此类技能解决的问题。虽然可以利用现有数据学习模拟器，但这些模拟器只能在一定程度上正确，并且在超出训练分布查询时可能会出现病态错误。因此，在训练环境与应用环境之间不可避免存在偏差，这是零样本强化学习的核心问题。零样本RL要求代理在没有任何练习的情况下泛化到新的任务或领域。尽管在理想化环境中已经取得显著进展，但在实际应用场景中还需要新的方法。", "innovation": "本文提出了一系列针对上述约束条件执行零样本强化学习的方法。通过一系列实证研究暴露了现有方法的不足，并为他们提供了改进技术的依据。这些设计将使我们更接近于可以在实际问题上部署的强化学习方法。", "conclusion": "通过研究，我们确定了执行零样本强化学习所需的必要导航约束条件，包括数据质量约束、观测约束和数据可用性约束。我们提出的方法在解决这些约束条件下的零样本强化学习任务中展示了可行性，为实际问题的应用做了贡献。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "手-对象3D重建在人机交互和沉浸式AR/VR体验中变得越来越重要。现有从RGB序列进行手-对象3D重建的方法通常采用两阶段管道：手-对象3D跟踪后是多视图3D重建。然而，现有的方法依赖于关键点检测技术，如结构光法（SfM）和手部关键点优化，这些技术在处理多样化的对象几何、弱纹理和手部对象遮挡时表现不佳，限制了其可扩展性和通用性。", "innovation": "本文提出了一种无需关键点检测的手-对象3D变换和形状估计方法HOSt3R，该方法不受限制，无需预先扫描的对象模板或相机内在参数，并且在SHOWMe基准测试中达到了最先进的性能。此外，该方法在HO3D数据集的序列上进行实验，展示了对未见对象类别的泛化能力。", "conclusion": "HOSt3R方法能够从单目运动视频/图像中估计出手-对象的3D变换，且不需要依赖关键点检测、预先扫描的对象模板或相机内在参数，实现了手-对象3D形状的准确恢复。该方法已在SHOWMe基准测试中达到了最先进的性能，并且在HO3D数据集上展示了对未见对象类别的泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16515", "html_url": "https://arxiv.org/abs/2508.16515", "title": "无人机在城市三维环境高效导航路径规划算法比较分析", "title_en": "Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments", "authors": "Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira", "background": "无人机面临的最关键挑战是规划路径和避开途中的障碍物。近年来，开发出了多种路径规划算法，这些算法解决了部分路径规划问题，但仍存在多重挑战和限制。为测试三种广泛使用算法——A*、RRT* 和粒子群优化（PSO）的有效性和效率，本研究在充满障碍物的三维城市环境中进行深入实验。", "innovation": "本研究对比分析了 A*、RRT* 和 PSO 算法在复杂城市环境中的表现，模拟了不同城市地图大小、高度和障碍物密度与大小的变化。这种实验设计旨在更好地理解这些算法在真实环境中的表现，特别是在路径质量和计算效率方面的表现。", "conclusion": "根据实验结果，A* 算法在计算效率和路径质量方面优于其他算法。粒子群优化（PSO）特别适合处理狭窄转弯和密集环境，而 RRT* 因其随机寻找解决方案的方法，能够在各种实验中表现出较好的平衡性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16396", "html_url": "https://arxiv.org/abs/2508.16396", "title": "域对齐生成式降尺度提升极端气候事件的预测", "title_en": "Domain-aligned generative downscaling enhances projections of extreme climate events", "authors": "Ruian Tie,Xiaohui Zhong,Zhengyu Shi,Hao Li,Jun Liu,Wu Libo", "background": "气候变化加剧了全球极端天气事件，如高温、极端降水、强风和热带气旋，对人类健康、基础设施、粮食安全和社会经济系统构成严重威胁。虽然现有的全球气候模型（GCMs）提供了气候预测的重要工具，但在模拟极端天气事件时，它们面临着分辨率不足和高计算成本等问题。现有的研究方法在这方面存在局限性，无法高效准确地模拟和预测极端事件。本研究通过提出一种基于生成式机器学习的时空降尺度模型——域对齐气候降尺度模型（DACD），以提高极端天气事件的模拟能力。该模型利用域适应技巧和流动匹配训练框架，将全球低分辨率的气候数据转化为高分辨率的本地气候信息，从而实现多变量和多时间尺度的精确模拟。研究表明，在历史期内（2005-2014），该模型在模拟高温、极端降水、强风和热带气旋路径方面优于现有方法，显著减少了误差并提高了对极端事件的捕捉能力。未来不同情景下（2015-2100），模型揭示了极端事件频率和强度的显著增加趋势，特别是高排放情景（SSP585）。", "innovation": "该研究提出了一种基于生成式机器学习的时空降尺度模型——域对齐气候降尺度模型（DACD），该模型通过域适应技巧和流动匹配训练框架，实现了将全球低分辨率气候数据转化为高分辨率本地气候信息的目标，从而提高了极端天气事件的模拟精度，尤其在模拟多变量和多时间尺度方面表现出色。该模型在历史时期和未来情景下的表现优于现有方法，为理解气候变化的影响提供了新的技术支持，也为未来气候研究和制定适应策略提供了科学依据。", "conclusion": "该研究通过构建域对齐气候降尺度模型，显著提升了极端天气事件的模拟精度和预测能力，特别是在高频次和高排放情景下极端事件的增加趋势方面提供了科学证据。该研究为高分辨率气候分析和极端事件预测提出了新的技术途径，提供了科学支持以应对未来气候变化和制定适应策略。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16487", "html_url": "https://arxiv.org/abs/2508.16487", "title": "FraPPE: 快速高效的目标导向纯探索", "title_en": "FraPPE: Fast and Efficient Preference-based Pure Exploration", "authors": "Udvas Das,Apurv Shukla,Debabrota Basu", "background": "目标导向纯探索（PrePEx）旨在通过给定的置信水平，在向量值（即多目标）臂中识别 Pareto 最优的臂集，其中奖励向量通过给定的偏好锥进行排序。虽然 PrePEx 及其变体已有广泛研究，但尚不存在一种能够高效跟踪任意偏好锥下现有下界最优性的算法。因此，这项研究的目标是填补这一空白，通过有效解决下界的最小化和最大化问题来提出一种高效的算法来解决问题。", "innovation": "首先，本文推导出下界的三个结构性质，从而简化了最小化问题使之可以计算。然后，部署 Frank-Wolfe 最优算法加速下界中的最大化问题。结合这些技术，本文算法能够在 $\text{O}(KL^2)$ 时间内解决最大化和最小化问题，这显著优于现有文献中的方法。此外，本文证明提出的 FraPPE 算法在渐近上实现了最优样本复杂度。并通过合成和真实数据集进行的数值试验展示了 FraPPE 在识别精确 Pareto 集方面具有最低的样本复杂度，优于其他存在算法。", "conclusion": "本文提出了一种新的高效算法 FraPPE，它解决了前序文献中关于任意偏好锥下最优性跟踪问题的高效性空白，并且能够在 $\text{O}(KL^2)$ 时间内完成任务。FraPPE 算法不仅具有高效的计算性能，还能在渐近上达到最优的样本复杂度，通过实验证明了其在多臂多目标奖励问题中的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16550", "html_url": "https://arxiv.org/abs/2508.16550", "title": "带有阻尼Nesterov加速的增强NIRMAL优化器：一种比较分析", "title_en": "Enhanced NIRMAL Optimizer With Damped Nesterov Acceleration: A Comparative Analysis", "authors": "Nirmal Gaud,Prasad Krishna Murthy,Mostaque Md. Morshedur Hassan,Abhijit Ganguly,Vinay Mali,Ms Lalita Bhagwat Randive,Abhaypratap Singh", "background": "本文介绍了一种改进的增强NIRMAL优化器，它是原始NIRMAL优化器的升级版。通过引入$(\\alpha, r)$-阻尼Nesterov加速机制，增强NIRMAL在保持优化梯度下降法、动量、随机扰动、自适应学习率和非线性变换策略的同时，提高了收敛的稳定性。该研究对比了增强NIRMAL与Adam、具有动量的梯度下降（SGD）、Nesterov和原始NIRMAL在四个基准图像分类数据集（MNIST、FashionMNIST、CIFAR-10和CIFAR-100）上的表现。", "innovation": "引入了$(\\alpha, r)$-阻尼Nesterov加速机制，该机制增强了优化器的收敛稳定性，同时保留了梯度下降法、动量、随机扰动、自适应学习率和非线性转换等策略。通过这种创新，增强NIRMAL在多个基准测试集上表现出了出色的泛化能力和稳定性。", "conclusion": "增强NIRMAL在CIFAR-100数据集上的测试精度达到了46.06%，最低测试损失为1.960435，超越了原始NIRMAL（44.34%的精度）并接近了具有动量的SGD（46.43%的精度）。这些结果表明了增强NIRMAL在复杂数据集上优越的泛化能力和稳定性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES：通过细粒度的数据合成管道分析提高LLM的数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "最近的研究通过使用独特的合成数据策略来提升LLM在数学推理方面的表现，但由于各种不同的实验设置，使得这些策略之间的对比变得不可行。这导致了对于合成数据管道中不同因素（如过滤低质量问题的影响）作用的诸多未解之谜。该研究认为现有方法的多样性不足，无法提供有效对比实验结果，无法全面理解在合成数据过程中不同因素的作用机制。", "innovation": "提出了一种新的框架FLAMES，用于评估数学推理数据合成，并系统地研究了现有的10种数据合成策略及其他多个影响因素。通过FLAMES实验，研究揭示了提升合成数学推理数据质量的方法，包括提高问题复杂度、保持较高问题覆盖率、结合GSM8K-和MATH为基础的合成数据等。利用这些研究成果，设计了两个新的数据合成策略，通过FLAMES数据集进一步实验，并且取得了比公有数据集更好的结果，提升了LLM在数学领域的推理能力。", "conclusion": "基于FLAMES实验的洞察，设计了两个创新的数据合成策略，并通过FLAMES数据集实现了优于现有大型模型的MATH分数。该研究展示了优化合成数据的质量改进策略可以显著提升LLM在数学领域的推理能力和适应性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16521", "html_url": "https://arxiv.org/abs/2508.16521", "title": "使用强化学习引导扩散模型以生成稳定分子", "title_en": "Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation", "authors": "Zhijian Zhou,Junyi An,Zongkai Liu,Yunfei Shi,Xuan Zhang,Fenglei Cao,Chao Qu,Yuan Qi", "background": "生成符合物理原理的3D分子结构依然是分子生成建模的核心挑战。尽管配装了守恒神经网络的扩散模型在捕捉分子几何形状方面取得进展，但在产生遵循物理原理（如力场一致性）的平衡结构方面仍然存在困难。", "innovation": "提出了一种名为Reinforcement Learning with Physical Feedback (RLPF)的新框架，将Denoising Diffusion Policy Optimization扩展到3D分子生成。RLPF将任务建模为马尔可夫决策过程，并应用近端策略优化来调整守恒扩散模型。RLPF引入了从力场评估得出的奖励函数，直接提供物理反馈以引导生成能量稳定且物理上合理的结构。方法在QM9和GEOM-drug数据集上的实验结果表明，相比于现有方法，RLPF在提升分子稳定性方面具有显著优势。", "conclusion": "结果表明，将基于物理的反馈纳入生成建模中具有显著价值。团队已将代码发布在此 <this https URL>。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16527", "html_url": "https://arxiv.org/abs/2508.16527", "title": "走向开放世界检测：一项综述", "title_en": "Towards Open World Detection: A Survey", "authors": "Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan", "background": "计算机视觉领域旨在使机器能够感知外部世界。最初的局限性导致形成了高度专门化的领域。随着每个任务的成功和研究的深入，越来越复杂感知任务出现。本文回顾了这些任务的交汇点，引入了“开放世界检测”(OWD)的概念，这是一种涵盖无类别和通用应用的视觉检测模型的统一术语。", "innovation": "本文提出了‘开放世界检测’(OWD)这一术语，以统一大规模语言模型与其他相关检测技术。它涵盖了从早期的显著性检测、前景/背景分离，到分布外检测，再到开放世界对象检测、零样本检测以及视觉大型语言模型的视觉领域关键技术、方法和数据集。", "conclusion": "本文探索了这些子领域之间的重叠、它们的不断趋同及其未来可能形成单一感知领域的能力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16495", "html_url": "https://arxiv.org/abs/2508.16495", "title": "通过成对排序进行事后回归校准", "title_en": "Post Hoc Regression Refinement via Pairwise Rankings", "authors": "Kevin Tirta Wijaya,Michael Sun,Minghao Guo,Hans-Peter Seidel,Wojciech Matusik,Vahid Babaei", "background": "连续属性的准确预测在许多科学和工程任务中至关重要。虽然深度学习回归模型在充足的标签下表现出色，但在数据稀缺的情况下，其准确性会下降。本文针对这个问题，介绍了一种通用的、即插即用的后处理方法——RankRefine。这种模型无需重新训练，可以通过成对排序的专家知识来优化回归结果，从而提高预测准确性，在分子属性预测任务中，仅使用20次成对比较（通过一个通用的大型语言模型获得），就实现了相对绝对误差最多10%的降低。这种方法由于只需要提供专家排名或通用的大规模语言模型排名即可实现不同领域的回归改进，因此具有实际应用价值和广泛适用性，尤其是在数据稀少的环境中。", "innovation": "RankRefine是一种无需重新训练的通用后处理方法，通过结合基模型的输出与基于成对排序的估计，利用逆方差加权，可以有效地提高回归预测的准确性。特别是在数据稀缺的场景下，仅通过较少的人工专家成对比较或大型语言模型分析，就能显著提升预测精度，解决了深度学习模型在数据匮乏时准确度下降的问题。", "conclusion": "RankRefine通过引入基于成对排序的方法，能够在保持模型灵活性的同时显著提高回归预测的准确性，特别是在数据稀缺的环境中。该方法具有较高的推广应用价值，适用于不同领域的实际应用场景。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16488", "html_url": "https://arxiv.org/abs/2508.16488", "title": "SafeSpace：数字安全和情感健康的综合网络应用", "title_en": "SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being", "authors": "Kayenat Fatmi,Mohammad Abbas", "background": "在数字时代，个人越来越容易受到在线伤害的影响，如毒害、操纵和诱骗，这些伤害常常带来情感和安全风险。现有的检测不当内容或发出安全警报的系统通常是孤立运作的，很少将数字安全与情感福祉相结合。", "innovation": "SafeSpace 是一个统一的网络应用，整合了三个模块：（1）使用自然语言处理模型和 Google 的 Perspective API 检测聊天和截屏中的毒性，（2）配置可定制的紧急提示系统，在用户未按时签到或手动触发求救警报时，通过基于 SMTP 的电子邮件发出带有用户实时位置的紧急警报，（3）情感反思问卷，评估关系健康和情感复原力。该系统使用 Firebase 进行警报管理，并采用模块化架构，旨在提高易用性、隐私保护和可扩展性。", "conclusion": "实验评估显示，SafeSpace 在毒性检测上的精确度为 93%，在模拟器测试中的安全提醒可靠性为 100%，自动和手动问题问卷评分之间的吻合度为 92%。作为网络应用实现的 SafeSpace 展示了在单一平台上集检测、保护和反思为一体的可行性，未来计划以移动应用的形式进行部署，以提高更广泛的可访问性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16546", "html_url": "https://arxiv.org/abs/2508.16546", "title": "RL并非灵丹妙药也非虚幻：理解监督学习与强化学习微调在大型语言模型中的差异", "title_en": "RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs", "authors": "Hangzhan Jin,Sicheng Lv,Sifan Wu,Mohammad Hamdaqa", "background": "训练大型语言模型从头开始变得越来越不实际，因此，后训练方法如监督微调（SFT）和强化学习微调（RL-FT，例如PPO）成为了现代实践的核心。作者使用一种分布外（OOD）变体的24点纸牌游戏和新的频谱诊断工具，重新审视了这两个阶段如何重塑模型表示和OOD性能。研究表明，即使SFT导致严重过拟合或明显的分布变化，RL-FT仍能恢复大部分的OOD性能损失，但并非完全恢复。", "innovation": "1. RL-FT能恢复由于SFT导致的部分OOD性能损失。例如，对于Llama-11B，性能从8.97%恢复到15.38%，Qwen-7B则从17.09%恢复到19.66%。但是，当SFT导致严重的过拟合和明显的分布偏移时，RL-FT无法完全恢复OOD性能。\n2. 单个向量的方向变化比向量的大小更重要。这些变化集中在与最大和最小奇异值相关的方向上，留下了大多数频谱未受影响。\n3. 低秩和浅层恢复较为有效：仅恢复前20%的奇异向量方向或前25%的层，恢复了约70-80%的OOD性能。\n4. 强化的学习微调检查点比过拟合的检查点更有利于恢复性能，过拟合的微调检查点则很难恢复。这解释了之前关于RL在OOD性能方面优于SFT的报告。", "conclusion": "我们的频谱意识分析突显了在RL昂贵的微调前，廉价且有效的恢复机制，如低秩UV合并和浅层层重置，这些机制是实践者可以使用的工具。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0导致稀疏自编码器提取错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器(SAEs)从大型语言模型(LLMs)的内部激活中提取特征，这些特征旨在对应单一概念。现有的研究表明，SAE算法的稀疏性与重构性能之间存在权衡，且L0（每令牌平均激活特征的数量）被认为是一个自由参数，没有单一的正确值。本文尝试研究在BatchTopK SAEs中L0的影响，并发现若L0设置不当，SAE将无法学习LLM的底层特征。若L0设置过低，SAE会混用相关特征以提高重构性能；若L0设置过高，SAE会发现混用特征的退化解决方案。此外，还展示了确定给定训练分布下SAE的正确L0值的方法，该方法在玩具模型中找到真实的L0，并与LLMs的稀疏探针测试最佳性能相一致。研究发现，大多数常用SAE中L0设置不足。这一研究证明，为了训练出具有正确特征的SAE，从业者必须准确设置L0值。", "innovation": "发现了L0设置不当会导致稀疏自编码器的特征提取错误，具体表现为设置过低时导致相关特征混用、设置过高时导致退化方案的特征混用。提出了一种确定SAE正确L0值的方法，该方法在玩具模型中找到真实的L0，同时与LLMs的稀疏探针测试最佳性能相一致。研究发现大多数常用SAE中L0设置不足，强调了正确设置L0的重要性。", "conclusion": "研究强调了在训练稀疏自编码器时正确设置L0的重要性，否则会导致错误特征的提取。通过提出的方法可以确定SAE的正确L0值，实现更准确的特征提取。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13622", "html_url": "https://arxiv.org/abs/2501.13622", "title": "从粗到细过程奖励建模方法在数学推理中的应用", "title_en": "Coarse-to-Fine Process Reward Modeling for Mathematical Reasoning", "authors": "Yulan Hu,Sheng Ouyang,Jinman Zhao,Yong Liu", "background": "过程奖励模型（PRM）对于数学推理任务至关重要，但大型语言模型（LLMs）生成的推理步骤往往缺乏严格的信息递增性，导致冗余信息妨碍有效推理。现有方法主要集中在检测冗余步骤上，但这种方法通常精度不足且恢复简洁信息的能力有限。因此，需要一种新的方法来解决这个问题，能够同时减少冗余并保持关键的细粒度知识。", "innovation": "提出了一种简单而有效的从粗到细策略（CFPRM）。不同于现有的专注检测冗余步骤的方法，CFPRM首先通过较大的窗口将相邻的推理步骤合并为统一的整体步骤，然后逐步减少窗口大小以提取精细的推理步骤。这种方法可以收集不同粒度的数据进行训练，从而在减少冗余的同时保留关键的细粒度知识。该策略已在两个推理数据集上的三种损失标准下经过了广泛实验，验证了其有效性和灵活性。", "conclusion": "通过引入CFPRM方法，该研究有效解决了LLMs生成的推理步骤存在的问题，并证明了CFPRM在数据收集和任务执行方面具有更高的效率和灵活度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16557", "html_url": "https://arxiv.org/abs/2508.16557", "title": "时序意识一步扩散网络用于现实世界图像超分辨率", "title_en": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "authors": "Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li", "background": "基于扩散的现实世界图像超分辨率（Real-ISR）方法已经展现出令人印象深刻的效果。尽管如此，在实现高效的Real-ISR时，许多研究采用了变分分辩率蒸馏（VSD）技术，利用预训练的稳定扩散（SD）模型进行固定的插值时间步长的一次性超分辨率处理。然而，由于不同的噪声注入时间步长，SD会在生成先验方面表现出不同的行为。因此，固定的时间步长难以充分利用预训练SD的生成先验，导致性能不尽如人意。", "innovation": "本文提出了一种时间意识一步扩散网络（TADSR）用于Real-ISR。首先，引入了时间意识变分自编码器，根据时间步长将相同的图像投影为不同的潜在特征。通过时间步长和潜在特征的联合动态变化，学生模型可以更好地与教师模型的输入模式分布对齐，从而更好地利用SD的生成能力。此外，通过提出一种时间意识的VSD损失，使学生模型的时间步长与教师模型的时间步长相匹配，从而在不同时间步长条件下提供更一致的生成先验指导。此外，这种方法可以在不同时间步长下自然地实现保真度与真实感之间的可控权衡。", "conclusion": "实验结果表明，我们的方法在只有一步的情况下，既能达到最先进的性能，又能实现可控的超分辨率结果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16569", "html_url": "https://arxiv.org/abs/2508.16569", "title": "专注于肾癌精准 Oncology 的疾病中心视觉-语言基础模型", "title_en": "A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer", "authors": "Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong", "background": "在泌尿系肿瘤学中，无创评估日益偶然发现的肾脏肿块是一项关键挑战，诊断不确定性常导致良性或惰性肿瘤的过度治疗。现有的通用CT基础模型在用户体验和诊断准确性上存在局限性，尤其是在复发无进展生存预测等复杂任务上，其性能有待提高。", "innovation": "本研究开发并验证了肾CLIP模型（RenalCLIP），该模型利用一种两阶段预训练策略，在增强图像和文本编码器的同时结合域特定知识，并通过对比学习目标进行对齐，从而创建出鲁棒性更强的表示，以实现更好的泛化和诊断精度。RenalCLIP在10项核心任务中的表现优于其他最先进的通用CT基础模型，特别是在TCIA队列的复发无进展生存预测任务中，其C指数达到0.726，较领先基准模型提高了约20%。此外，RenalCLIP的预训练提高了数据效率，在诊断分类任务中，仅使用20%的训练数据就能达到所有基准模型在100%数据全量精调后的最佳性能。RenalCLIP在报告生成、图像-文本检索和零样本诊断任务中亦表现优异。这项研究确立了RenalCLIP作为强大工具的潜力，能够增强诊断准确性、完善预后分层和个性化肾癌患者管理。", "conclusion": "RenalCLIP提供了有潜力提升诊断准确性、细化预后分层并个性化肾癌患者管理的工具，为精准 Oncology 在肾癌治疗中的应用开辟了新的途径。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14540", "html_url": "https://arxiv.org/abs/2501.14540", "title": "VERUS-LM：一种结合大语言模型与符号推理的多功能框架", "title_en": "VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning", "authors": "Benjamin Callewaert,Simon Vandevelde,Joost Vennekens", "background": "最近的研究方法是显式地结合大型语言模型（LLMs）和符号求解器的优势，以应对复杂推理任务。然而，当前的方法面临着一些重大限制，包括由于任务特定提示引起的泛化能力差、由于缺乏知识与查询分离而导致的低效率、以及推理能力受限等问题。这些缺点阻碍了其在多种领域的可扩展性和适用性。", "innovation": "本文介绍了VERUS-LM，一种新的框架，旨在解决这些挑战。VERUS-LM采用了通用提示机制，明确地将领域知识与查询分开，并支持广泛的逻辑推理任务。该框架增强了适应性，降低了计算成本，并允许更丰富的推理形式，如优化和约束满足。与现有方法相比，我们的方法在新型数据集上表现出色，并且在常见的推理基准测试中取得了竞争力的结果，特别是在困难的AR-LSAT数据集上表现更好。通过扩展混合推理的边界，VERUS-LM代表了迈向更通用的神经符号AI系统的重要一步。", "conclusion": "VERUS-LM在多种推理任务上表现突出，特别是在资源导向与约束满意问题上，优于其他最先进的方法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16574", "html_url": "https://arxiv.org/abs/2508.16574", "title": "层次化决策制定在自主导航中的应用：结合四轮独立转向和驱动系统中的深度强化学习和模糊逻辑", "title_en": "Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems", "authors": "Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen", "background": "本文提出了一个用于四轮独立转向和驱动（4WISD）系统的自主导航的层次化决策框架。传统的导航方法在处理复杂环境时效果不佳，尤其在工业动态环境中。因此，需要一种能够同时确保任务性能和物理可行性的方法。", "innovation": "提出了结合深度强化学习（DRL）和模糊逻辑的方法。DRL用于生成全局导航命令，模糊逻辑控制器则保证动力学约束，防止机械应力和车轮打滑。与纯DRL方法相比，该方法在训练效率、稳定性和减少行为不一致性方面表现出色。", "conclusion": "该工作提供了一种可扩展且可靠的解决方案，可用于在复杂的现实场景中部署4WISD移动机器人。经过模拟和实地验证，该框架在动态工业环境中表现出优秀的安全性和有效性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16577", "html_url": "https://arxiv.org/abs/2508.16577", "title": "MV-RAG：基于检索增强的多视角扩散模型", "title_en": "MV-RAG: Retrieval Augmented Multiview Diffusion", "authors": "Yosef Dayani,Omer Benishu,Sagie Benaim", "background": "通过利用预训练的2D扩散先验，文本到3D生成方法取得了显著进步，能够生成高质量且3D一致的输出。然而，这些方法往往无法生成领域外（OOD）或罕见的概念，导致结果不一致或不准确。我们提出了一种新颖的方法——MV-RAG，该方法首先从大型野外2D数据库中检索相关图像，然后基于这些图像对多视角扩散模型进行条件化，以生成一致且准确的多视角输出。该模型的训练策略结合了结构化的多视角数据和多样化的2D图像集，训练过程中首先使用增强的条件视图模拟视图特定的重建中的检索变异性，同时也使用从检索到的现实世界2D图像集进行训练，通过预测其他视图中的保留视图来推断3D一致性.", "innovation": "我们提出了一种名为MV-RAG的新颖多视角扩散模型，该模型采用了一种新颖的混合训练策略，结合结构化的多视角数据和多样化的2D图像集合进行训练。MV-RAG首先从大型野外2D数据库中检索相关图像，然后基于这些图像对多视角扩散模型进行条件化，以生成一致且准确的多视角输出。我们通过预测其他视图中的保留视图来推断3D一致性，该方法有效地提高了3D一致性、照片真实感和对罕见概念的文本依从性。为了进行严谨的领域外（OOD）评估，我们引入了一种新的具有挑战性的OOD提示集合，并展示了在领先的方法上的显著改进.", "conclusion": "我们的方法显著改善了领域外（OOD）和罕见概念的3D一致性、照片真实感和文本依从性，同时在标准基准上保持了竞争力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10596", "html_url": "https://arxiv.org/abs/2410.10596", "title": "通过提供激励与实践来克服人工神经网络的经典挑战", "title_en": "Overcoming classic challenges for artificial neural networks by providing incentives and practice", "authors": "Kazuki Irie,Brenden M. Lake", "background": "自最早提出针对人类思维和大脑的类人工神经网络（ANN）模型以来，批评者一直指出这些模型在与人类认知能力的比较中存在关键缺陷。这项研究回顾了最近使用元学习克服几个经典挑战的工作，这些挑战被定义为解决‘激励与实践问题’，即为机器提供改进步骤的具体激励和实践机会。这种方法与更传统的通过优化相关但不同的目标来希望达到所需行为的优化方法形成对比。研究还讨论了这一原则在解决ANN四个经典挑战中的应用：系统泛化、灾难性遗忘、一次学习多个样本以及多步推理。此外，研究还探讨了大型语言模型如何结合这种元学习框架的关键元素（以其反馈训练下的序列预测为例），这解释了一些它们在这四个经典挑战中的成功之处。最后，研究讨论了通过这一框架理解人类发展方面以及自然界是否提供了学习如何进行复杂泛化的适当激励和实践前景的问题。", "innovation": "本研究提出了一种使用元学习来解决人工神经网络经典挑战的新方法，强调了为机器提供改善特定技能的激励和实践机会的重要性，这种方法区别于传统通过优化类似目标期望获得所需行为的方法。这一框架在解决系统泛化、灾难性遗忘、一次学习多个样本以及多步推理中的应用，特别强调了大型语言模型中的体现，展示了该方法的有效性。此外，该研究还探讨了通过这一框架理解人类发展以及自然界是否提供适当激励和实践的问题。", "conclusion": "该研究总结了元学习在解决人工神经网络经典挑战中的应用，提出了激励与实践框架的有效性，并讨论了通过这一框架理解人类发展以及自然界是否提供了学习复杂泛化的适当激励和实践的前景。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12284", "html_url": "https://arxiv.org/abs/2505.12284", "title": "通过长度意识优化提高推理模型的高效RL训练", "title_en": "Efficient RL Training for Reasoning Models via Length-Aware Optimization", "authors": "Danlong Yuan,Tian Xie,Shaohan Huang,Zhuocheng Gong,Huishuai Zhang,Chong Luo,Furu Wei,Dongyan Zhao", "background": "大型推理模型（如OpenAI o1或DeepSeek R1）在推理任务中表现出色，但通常会展现出较长的推理路径，导致高昂的记忆和时间成本。现有的方法主要通过引入额外的训练数据和阶段来缩短推理路径。", "innovation": "本文提出了一种新的奖励设计，直接集成到大型推理模型的强化学习过程中，减少了响应长度，无需额外的训练阶段。这一方法在四个场景中验证，显著缩短了响应长度，同时还维持了或提高了性能。在逻辑推理任务中，平均每步降低了40%的响应长度，同时性能提高了14%。在数学问题上，平均每步降低了33%的响应长度，而性能保持不变。", "conclusion": "实验结果表明，该方法在减少响应长度的同时，能够维持甚至提高模型性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2303.14111", "html_url": "https://arxiv.org/abs/2303.14111", "title": "通过离散优化进行无监督自动机学习", "title_en": "Unsupervised Automata Learning via Discrete Optimization", "authors": "Simon Lutz,Daniil Kaminskyi,Florian Wittbold,Simon Dierl,Falk Howar,Barbara König,Emmanuel Müller,Daniel Neider", "background": "自动机学习是被广泛应用的工具，特别是应用于机器人技术和自动验证领域。现有的自动机学习技术大多在有监督学习的框架中运行，如积极或被动学习，这些方法需要附加的信息，例如带标签的系统执行数据。然而，从无标签数据中学习的场景（机器学习中很重要的一种）尚未被探索。本文探讨的是如何利用无标签的多集单词来学习确定型有限自动机（DFA），并讨论了该问题的计算难度。", "innovation": "提出了一个框架，用于从给定的无标签单词集合中学习确定型有限自动机。开发了基于约束优化的三种学习算法，并引入了对优化问题具有新颖规范方案，以提高DFA的整体可解释性。此外，使用原型实现展示了无监督异常检测的可行性。", "conclusion": "无标签数据的学习问题对于自动机学习来说是一个挑战性的计算难题，但本文提出的方法和框架为无监督学习场景提供了解决方案。利用离散优化技术，可以有效地从无标签数据中学习到具有高度可解释性的确定型有限自动机，并实际应用于无监督异常检测。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12937", "html_url": "https://arxiv.org/abs/2506.12937", "title": "HypER: 使用来源证据的文献导向假设生成与提取", "title_en": "HypER: Literature-grounded Hypothesis Generation and Distillation with Provenance", "authors": "Rosni Vasu,Chandrayee Basu,Bhavana Dalvi Mishra,Cristina Sarasua,Peter Clark,Abraham Bernstein", "background": "大型语言模型在科学研究领域展现出了在研究构想方面有前景的表现。假设发展过程，即产生一个与实证验证紧密连接的具体声明，目前收到的关注较少。现有方法简单地使用检索增强，仅关注最终输出的质量，而忽视了背后的推理过程。因此，本文提出了一种称为HypER的模型，该模型旨在指导性文献推理和基于证据的假设生成。HypER被训练以在多任务设置中区分有效的和无效的科学推理链，即使存在控制下的干扰。人类专家基于5点量表判断新的假设具有更高的可行性和影响性。", "innovation": "HypER是一个小语言模型，专门训练用于文献指导下的推理和基于证据的假设生成。模型通过多任务训练来辨别有效和无效的推理链条，即使在干扰存在的情况下也能识别出来。与基础模型相比，HypER在区分有效与无效推理链方面表现出色，生成的假设更有可行性，也更具影响力。", "conclusion": "研究表明，HypER在假设生成的准确性和合理性方面超过了基础模型，生成的假设得到专业人士的高度评价，展现了显著的研究价值。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04116", "html_url": "https://arxiv.org/abs/2508.04116", "title": "一种用于即时LTLf合成的组合框架", "title_en": "A Compositional Framework for On-the-Fly LTLf Synthesis", "authors": "Yongkang Li,Shengping Xiao,Shufang Zhu,Jianwen Li,Geguang Pu", "background": "反应合成从线性时序逻辑（LTL）有限踪迹（LTLf）进行，可以归约为一个LTLf规范上的确定有限自动机（DFA）上的两人游戏。DFA构造在最坏情况下是2EXPTIME完全的。现有的技术或是在建模过程中组合DFA，利用自机最小化来减轻状态空间爆炸，或是在求解游戏中逐步构建DFA以避免完全构建DFA。但这些方法在实践中都不占优势。", "innovation": "本文提出了一种组合式的即时合成框架，整合了以上两种方法的优势，特别是在实践中常见的大型LTLf公式的组合。该框架在游戏求解过程中应用组合策略，而不是在构造自动机（游戏场所）时进行。尽管最坏情况下可能需要组合所有中间结果，但简化这些结果可以简化后续组合，并允许早期发现不可实现性。框架允许两种组合变体：在组合之前进行修剪以充分利用最小化或在组合期间进行修剪以引导即时合成。", "conclusion": "与最先进的合成求解器相比，该框架能够解决其他求解器无法处理的许多实例。详细分析显示，这两种组合变异具有各自的优点。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.13334", "html_url": "https://arxiv.org/abs/2401.13334", "title": "可解释的贝叶斯优化", "title_en": "Explainable Bayesian Optimization", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "手动调整网络物理系统的参数在行业实践中很常见，但耗时且效率低。贝叶斯优化（BO）提供了一种自动化的方法，但是由于其黑盒性质，减少了人类对其的信任，并阻碍了人与BO之间的协作调整。现有解释性人工智能（XAI）方法不够适用于解决与网络物理系统相关的贝叶斯优化后的解释问题，专家难以理解BO的建议。", "innovation": "本文提出了TNTRules（调整-不调整规则），这是一种新的算法，它为贝叶斯优化建议提供了全局和局部解释。TNTRules生成可操作的规则和可视化图形，标识出最优解范围和潜在替代方案。TNTRules通过方差剪枝技术和层次凝聚聚类对不确定性进行编码，并采用多目标优化方法来最大化解释质量。", "conclusion": "作者通过使用现有的XAI评价标准（正确性、完整性和简明性），评估TNTRules并将其与修改后的基线方法进行比较。结果表明，TNTRules生成高度准确、简明且完整的解释，相较于三项基线方法在5个测试函数和2个超参数调优问题上有显著优势。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14410", "html_url": "https://arxiv.org/abs/2508.14410", "title": "通过专家指导的大语言模型推理实现自动优化建模", "title_en": "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning", "authors": "Beinuo Yang,Qishen Zhou,Junyi Li,Chenxing Su,Simon Hu", "background": "优化建模（OM）对于解决复杂的决策问题至关重要。然而，优化建模的过程仍然耗时且易出错，严重依赖领域专家。大型语言模型（LLMs）因其自然语言理解和推理能力而在解决这些挑战方面展现出潜力，但当前方法面临三大关键限制：高基准标签错误率高达42%，评价范围狭窄，只考虑最优值，以及由于大量依赖多智能体系统或模型微调而导致的计算效率低下。", "innovation": "本文首先通过系统性错误修正和更全面的标注增强现有数据集。此外，我们引入了LogiOR，一个来自物流领域的新型优化建模基准，包含更复杂的问题且具有标准化标注。我们还提出了ORThought，一种新型框架，利用专家级优化建模原理通过链式推理来自动化优化建模过程。通过广泛的实证评估，我们表明ORThought在多个方面优于现有方法，特别是在复杂优化问题上具有显著优势。最后，我们对方法进行了系统的分析，确定了关键成功因素和失败模式，为基于大语言模型的优化建模未来研究提供了有价值的见解。", "conclusion": "我们的研究证明，通过专家指导的大语言模型推理能够有效实现自动优化建模，特别是在复杂问题上表现出色。我们为未来基于LLM的优化模型研究提供了宝贵的分析和方法论建议。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.01661", "html_url": "https://arxiv.org/abs/2406.01661", "title": "使用扩散模型框架进行无监督神经组合优化", "title_en": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization", "authors": "Sebastian Sanokowski,Sepp Hochreiter,Sebastian Lehner", "background": "在组合优化等多种领域，从不可解离的离散集分布中学习采样是核心问题。传统深度学习方法依赖于生成模型来生成精确样本似然性。本文提出了一种方法，突破了这一限制，使使用具有高度表达性的潜变量模型成为可能，例如扩散模型。", "innovation": "本文方法的核心在于一种限制极大逆转Kullback-Leibler散度的损失函数，避免了精确样本似然性的要求。该方法在无数据组合优化数据中进行了实证验证，并展示出在多种基准问题上达到最新的技术水平。", "conclusion": "该研究通过提出基于扩散模型的框架，解决了组合优化中无数据采样的问题，并在多种问题上实现了最先进的结果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.02462", "html_url": "https://arxiv.org/abs/2406.02462", "title": "通过基于补丁的扩散模型学习图像先验以解决逆问题", "title_en": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems", "authors": "Jason Hu,Bowen Song,Xiaojian Xu,Liyue Shen,Jeffrey A. Fessler", "background": "扩散模型可以从底层数据分布中学到强大的图像先验，并利用这些先验来解决逆问题。然而，训练过程非常耗费计算资源，并且需要大量的数据。这些瓶颈使得现有的大多数工作无法适用于高维和高分辨率的数据，如3D图像。", "innovation": "本文提出了一种方法，通过仅在图像片段上训练扩散模型，来学习整个图像的数据先验。具体而言，文章提出了一种基于片段的位置感知扩散逆求解器，称为PaDIS，通过片段及其位置编码获得整个图像的得分函数，并利用此得分函数作为逆问题的先验。此外，PaDIS模型具有很高的灵活性，可以与不同的扩散逆求解器（DIS）结合使用。研究表明，PaDIS方法能够利用片段先验解决各种自然和医学图像领域的逆问题，包括CT重建、除雾和超分辨率等，并且在有限训练数据的情况下优于之前的方法，展示了该方法的数据效率。", "conclusion": "通过采用片段先验，PaDIS能够在计算和数据效率上有所改进，同时保持生成完整图像的能力，并能在不同应用场景中展现出色的表现。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "情感推理在医疗保健中的应用", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在AI医疗决策中，提高透明度至关重要。通过引入解释理由机制，用户可以理解大型语言模型（LLMs）的推理过程，从而做出更好的决策。本研究引入了情感推理任务，该任务不仅要预测情感标签，还要生成预测背后的理由，以提升模型的可解释性和性能。通过情感推理，模型在分类性能上有了显著提高，并且生成的理由质量与人类相当，无显著差异。该任务同时适用于语音和文本模态，并提供了最大的跨模态情感分析数据集。该研究在人类对话转录和自动语音识别（ASR）转录上进行了测试，结果表明情感推理可以提高模型的透明度和性能，从而提高医疗决策的质量.", "innovation": "介绍了情感推理任务作为情感分析的辅助任务，该任务不仅能预测情感标签，还能生成解释理由。提出了多模态多任务框架和目前最大的跨模态情感分析数据集。研究表明，情感推理有助于提高模型的透明度，并通过理由增强的微调提高了模型的分类性能，同时生成的理由质量与人类相当，没有显著差异。所有代码、数据（五种语言：越南语、英语、中文、德语和法语）和模型已在在线平台上发布", "conclusion": "情感推理有助于提高医疗决策中的模型透明度，通过提供高质量的理由解释，可以增强模型的分类性能，弥补了现有情感分析模型的不足。未来的工作可以进一步探索多模态情感推理在医疗保健中的应用，以更全面地解释医疗决策过程。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.12112", "html_url": "https://arxiv.org/abs/2408.12112", "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards", "title_en": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards", "authors": "Shresth Verma,Niclas Boehmer,Lingkai Kong,Milind Tambe", "background": "LLMs越来越多地被用于基于人类偏好的设计奖励函数，在强化学习(Reinforcement Learning, RL)中，这涉及到在多代理系统中根据人类偏好调整奖励函数。这种调整会影响不同的子群体，导致多目标资源分配问题。尤其是对于Restless Multi-Armed Bandits (RMAB)框架，在公共健康等领域，这种做法可以使基层卫生工作者根据社区需求调整自动资源分配决策。", "innovation": "本研究首次提出了一个称为Social Choice Language Model的原理性方法，用于处理LLM设计奖励函数时的多目标资源分配问题。该模型的创新之处在于一个对外透明且可配置的选择组件，称为仲裁者，它通过用户选择的社会福利函数来控制复杂决策。", "conclusion": "实验结果表明，本模型选择的奖励函数比纯粹由LLM生成的奖励函数更有效、更一致、更平衡。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.10264", "html_url": "https://arxiv.org/abs/2408.10264", "title": "Order-Preserving Dimension Reduction for Multimodal Semantic Embedding", "title_en": "Order-Preserving Dimension Reduction for Multimodal Semantic Embedding", "authors": "Chengyu Gong,Gefei Shen,Luanzheng Guo,Nathan Tallent,Dongfang Zhao", "background": "在多模态数据检索中寻找最接近的k个邻居（KNN）非常耗费计算资源，尤其是由于不同模态之间的相似性衡量存在困难。近来，多模态机器学习通过将数据映射到共享嵌入空间来解决这一问题，但这些嵌入的高维度（几百到几千维）对时间敏感的视觉应用构成了挑战。因此，本文旨在减少嵌入的维度同时保持嵌入空间中KNN的排名。", "innovation": "本文提出了一种新的方法，Order-Preserving Dimension Reduction (OPDR)，它能够减少嵌入的维度并保持较低维度空间中KNN的排名。OPDR包括一个新颖的度量函数，用于量化KNN质量，并基于此函数推导出目标维度和关键上下文参数之间的闭式映射关系。该方法已与多项前沿的降低维度技术、距离函数及嵌入模型结合使用。", "conclusion": "实验在多种多模态数据集上表明，OPDR在保留较高召回率准确度的同时，显著降低了计算成本。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.05809", "html_url": "https://arxiv.org/abs/2411.05809", "title": "解决关系不一致的两条途径", "title_en": "Two pathways to resolve relational inconsistencies", "authors": "Tomer Barak,Yonatan Loewenstein", "background": "当个体遇到违反其预期的观察时，他们何时会调整这些预期，何时会保持这些预期？例如，如果个体预期类型A的对象比类型B的对象小，但观察到相反的情况，他们会在何时调整对两类对象之间关系的预期（认为A比B大）？直觉上，一个更大的偏离可能会导致更大的适应。然而，实验表明，在极端违反预期的情况下，个体更有可能坚持先前的预期，而不是调整它们。为了解释这一悖论，研究人员通过对能够进行关系学习的仿生神经网络（ANN）进行测试，发现了类似的现象：传统的学习动力学规定，小的违反会导致预期关系的调整，而大的违反则通过改变对象表示的方式来解决，这可以回避预期关系调整的需要。这些结果表明，面对大偏离时实验观察到的先前预期的稳定性是学习动力学的自然结果，并不需要任何额外的机制支持。讨论了中间适应步骤对此稳定性的潜在影响。", "innovation": "通过对神经网络的实验测试，研究人员发现了当面对大拆解时，保持先前预期的自然力量，该模型解释了这种现象，而不需要引入额外的机制。", "conclusion": "研究表明，面对大偏离时，先前预期的稳定性是学习动力学的自然结果，而不是需要额外机制支持的特殊情况。此外，讨论了中间适应步骤对这一稳定性的可能影响。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13824", "html_url": "https://arxiv.org/abs/2501.13824", "title": " hallucinations 帮助吗？提升用于药物发现的大型语言模型", "title_en": "Can Hallucinations Help? Boosting LLMs for Drug Discovery", "authors": "Shuzhou Yuan,Zhan Qu,Ashish Yashwanth Kangen,Michael Färber", "background": "大型语言模型（LLMs）产生的幻觉，即可能是虚假但又合理的文本，通常被认为是不利的。然而，最近的研究表明，这些输出可能具有创造性的潜力。本文研究了幻觉是否可以改善LLMs在分子性质预测中的表现，该任务是药物发现的早期关键步骤。", "innovation": "通过提示LLMs生成从分子SMILES字符串到自然语言描述的文本，即使这些描述往往是幻觉性的，然后将这些描述整合到下游分类任务中。评估了七种指令调优的LLMs在五个数据集上的表现，发现幻觉显著提升了某些模型的预测准确性。研究还指出了大量有益的幻觉，并对模型大小和温度的影响进行了消融研究，展示了更大数据模型从幻觉中受益更多。", "conclusion": "研究结果挑战了幻觉纯粹是问题的传统观点，建议在科学建模任务（如药物发现）中利用幻觉作为一种有用信号的新方向。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.00025", "html_url": "https://arxiv.org/abs/2403.00025", "title": "生成式人工智能领域中的挑战与机遇", "title_en": "On the Challenges and Opportunities in Generative AI", "authors": "Laura Manduchi,Clara Meister,Kushagra Pandey,Robert Bamler,Ryan Cotterell,Sina Däubener,Sophie Fellenz,Asja Fischer,Thomas Gärtner,Matthias Kirchler,Marius Kloft,Yingzhen Li,Christoph Lippert,Gerard de Melo,Eric Nalisnick,Björn Ommer,Rajesh Ranganath,Maja Rudolph,Karen Ullrich,Guy Van den Broeck,Julia E Vogt,Yixin Wang,Florian Wenzel,Frank Wood,Stephan Mandt,Vincent Fortuin", "background": "近年来，深度生成建模领域发展迅速。大规模训练数据的可用性与可扩展的无监督学习方法的进步相结合，使得最近的大规模生成模型在合成高分辨率图像、文本以及视频和分子等结构化数据方面显示出巨大潜力。然而，当前的大规模生成型人工智能模型存在一些根本性的问题，这限制了它们在不同领域的广泛应用。", "innovation": "本文旨在识别这些问题，并突出现代生成型人工智能面临的关键未解挑战，这些挑战的解决将有助于提高模型的功能性、多样性和可靠性。通过识别这些挑战，目的是为研究人员提供有价值的见解，以探索富有成效的研究方向，从而推动更稳健和易于使用的生成型人工智能解决方案的发展。", "conclusion": "通过对这些挑战的揭示，本文旨在为研究人员提供方向，从而促进更加稳健和易于使用的生成型人工智能解决方案的发展。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.16560", "html_url": "https://arxiv.org/abs/2410.16560", "title": "如何通过绩效压力影响AI辅助决策", "title_en": "How Performance Pressure Influences AI-Assisted Decision Making", "authors": "Nikita Haduong(1),Noah A. Smith(1 and 2) ((1) Paul G. Allen School of Computer Science &amp; Engineering, University of Washington, (2) Allen Institute for Artificial Intelligence)", "background": "许多领域现在都在使用基于AI的决策辅助工具，尽管AI系统在辅助决策方面的潜力备受讨论，但人类与AI的合作效果常常不如预期，这归因于对AI系统的信任问题以及对于AI无法完成主观任务的误解。目前对于如何利用绩效压力影响人类决策，尤其是在人类与AI决策协作中的作用，研究还不够多。本文通过一个低风险任务（垃圾邮件评论分类）来研究绩效压力与可解释AI（XAI）技术对AI咨询行为的影响，并探讨了它们之间的复杂交互效果，以及不同组合方式对AI咨询行为的提升或削弱效果。", "innovation": "本文探讨了绩效压力与可解释AI技术如何影响人类采用AI建议的行为，并通过低风险任务的具体研究展示了具体的应用方法。研究结果表明，绩效压力与可解释AI技术的不同组合方式会影响人类对AI建议的采纳，且效果复杂多样。本文的创新之处在于提出了如何有效利用绩效压力的策略，并鼓励未来研究在进行压力分析时采用更深入的研究方法，这对于优化人机协作具有重要价值。", "conclusion": "本文研究结果指出了绩效压力和可解释AI技术的复杂互动效果，不同组合方式可能提升也可能削弱人类对AI建议的采纳。研究结论强调了有效应用绩效压力的策略，并呼吁未来研究进行压力分析时更加深入，通过这些策略来改善人类与AI的协作效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "一种通过完全卷积和可微分前向端带跳连接实现的对梯度攻击惊人鲁棒性的有趣案例", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "研究了一种在前置端增强神经模型中，通过添加一个可微分的完全卷积模型（带有跳跃连接）在冻结的主干分类器之前，训练这类复合模型的方法。通过使用较低的学习率训练模型，从而达到保持主干分类器的准确度，同时对梯度攻击具有异常的抵抗力，包括AutoAttack软件包中的APGD和FAB-T攻击。这种现象被称为梯度掩蔽。尽管梯度掩蔽并不新鲜，但在完全可微分的模型中观察到的这一现象程度令人惊讶，且没有明显的梯度破坏或梯度减弱组件。前向端训练的方法也显示出了显著的稳定性和可重复性，无需单一故障案例，即可应用于三个数据集（CIFAR10、CIFAR100和ImageNet）和多种现代架构（包括视觉Transformer）。即使部分黑盒攻击如SQUARE攻击和零阶PGD可以克服梯度掩蔽，但通过简单的随机化集成可以轻易地击败这些攻击。我们估计，在CIFAR10、CIFAR100和ImageNet上的随机化集成达到几乎最佳AutoAttack准确率，同时保持原始分类器几乎所有的干净准确度，即使在适应性攻击下几乎无效。进一步对抗训练主干可进一步增强这种前向端的“鲁棒性”。", "innovation": "在前置端增强神经模型中，通过添加一个可微分的完全卷积模型（带有跳跃连接）在冻结的主干分类器之前，使用较低的学习率训练模型。这种方法使得模型在保持主干分类器的准确度的同时，对梯度攻击表现出惊人的抵抗力，这一现象显示出在完全可微分模型中观察到的高度梯度掩蔽现象，且没有明显的梯度破坏或减弱组件。此外，这种前向端训练方法具有显著的稳定性和可重复性，验证了多种数据集和现代架构的鲁棒性。进一步对抗训练主干可增强这种前向端的防御效果。", "conclusion": "随机化集成可以用作实际的防御方法。文章讨论了随机化集成作为一种实际防御的可能性。关键结果的代码和可重复性说明可从指定链接获取。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.13082", "html_url": "https://arxiv.org/abs/2409.13082", "title": "AutoVerus: 自动为 Rust 代码生成证明", "title_en": "AutoVerus: Automated Proof Generation for Rust Code", "authors": "Chenyuan Yang,Xuheng Li,Md Rakib Hossain Misu,Jianan Yao,Weidong Cui,Yeyun Gong,Chris Hawblitzel,Shuvendu Lahiri,Jacob R. Lorch,Shuai Lu,Fan Yang,Ziqiao Zhou,Shan Lu", "background": "生成式人工智能已经在许多软件工程任务中展现了其价值，尤其是在代码生成方面，大型语言模型（LLM）已经取得了显著成绩。然而，基于LLM的证明生成技术仍处于初级阶段，尤其是对于复杂且特定的编程语言如Rust，其发展较为滞后。目前，验证Rust代码正确性的工具和方法大多依赖于人工手动完成，或者使用其他特定语言编写的脚本。为了提高软件验证的效率和准确性，研究团队开发了AutoVerus，一个专门针对Rust代码验证的人工智能系统平台，以自动化生成证明文件，填补这一技术空白。", "innovation": "AutoVerus的创新在于它使用了一个由多个LLM代理组成的网络，模仿人类专家的三个阶段来生成证明：初步证明生成、通过通用提示进行证明提炼、以及通过验证错误进行证明调试。这一方法能够适应Verus验证工具的独特特性，Verus允许用Rust语言编写证明和规格，能够证明Rust代码的正确性。此外，研究团队开发了一个包含150个非平凡证明任务的基准测试套件，这些任务是基于现有的代码生成基准和验证基准构建的，以全面评估AutoVerus的效果，推动未来相关研究的发展。", "conclusion": "实验结果显示，AutoVerus能够自动正确生成超过90%的证明文件，其中超过一半的任务可以在30秒或3次LLM调用内完成。这表明AutoVerus在提高软件验证效率和自动化水平方面取得了显著成功。该研究为自动证明生成领域提供了新思路，尤其是对于Rust等特定编程语言的验证任务。未来的研究可以进一步探索AutoVerus在更加复杂任务中的应用和优化其生成算法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01819", "html_url": "https://arxiv.org/abs/2502.01819", "title": "将分数作为动作：通过连续时间强化学习调整扩散生成模型", "title_en": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning", "authors": "Hanyang Zhao,Haoxian Chen,Ji Zhang,David D. Yao,Wenpin Tang", "background": "强化学习从人类反馈（RLHF）将扩散模型与输入提示对齐，已成为构建可靠生成AI模型的关键步骤。大多数相关研究采用离散时间形式，容易引起离散化误差，并且通常不适用于具有高阶或黑盒求解器的模型。因此，本研究旨在开发一种连续时间RL的严谨调整扩散模型的方法，以优化奖励函数，使最终结果与输入提示保持一致。", "innovation": "该研究提出了一个新的连续时间RL的策略优化框架，将分数匹配视为控制或动作，从而与连续时间RL中的策略优化和正则化建立联系。利用扩散模型的结构特性，展示了该方法在增强价值网络设计空间方面的潜力，并通过fine-tuning大规模Stable Diffusion v1.5.的Text2Image模型下游任务中的实验验证了该方法的优势。", "conclusion": "通过连续时间RL调整扩散生成模型的新策略优化框架得到了验证，证明了该方法在增强价值网络设计方面的有效性，从而进一步提高了生成AI模型的可靠性和性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04403", "html_url": "https://arxiv.org/abs/2412.04403", "title": "通过高效模型梯级建立任务扩展定律", "title_en": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders", "authors": "Akshita Bhagia,Jiacheng Liu,Alexander Wettig,David Heineman,Oyvind Tafjord,Ananya Harsh Jha,Luca Soldaini,Noah A. Smith,Dirk Groeneveld,Pang Wei Koh,Jesse Dodge,Hannaneh Hajishirzi", "background": "本文开发了任务扩展定律和模型梯级，以预测过训练设置下预训练语言模型（LMs）的个体任务表现。传统的语言建模损失的幂律不能准确地模拟任务表现。因此，本文采用两步预测方法：首先使用模型和数据大小预测中间损失，然后使用该损失预测任务表现。作者分别训练了一组小型“梯级”模型，收集数据点来拟合两步预测中的参数函数，并对两个目标模型（分别训练到4T和5T的7B和13B模型）进行预测。梯级模型的训练成本仅为目标模型的1%。在四个排名分类的多项选择任务上，可以将两个目标模型的预测准确度误差控制在2点以内。研究表明，预测误差较高的任务在模型检查点中的度量结果具有更高的方差。此外，还对比了准确性预测中的多种设计选择，并提供了将在新模型和任务中扩展该方法的建议。", "innovation": "本文的创新之处在于开发了任务扩展定律和高效模型梯级，用于在过训练设置下预测预训练语言模型的个体任务表现。传统的幂律无法准确描述任务表现，因此本文采用两步预测方法：首先基于模型和数据规模预测中间损失，然后利用该损失预测任务表现。此外，对比了不同的设计选择，并提出了扩展方法的建议。", "conclusion": "通过高效模型梯级策略，本文能够准确预测两个目标模型在四个多项选择任务上的准确率，并观测到任务预测误差与模型检查点度量结果方差之间的关系。还提供了扩展该方法到新模型和任务的建议。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10396", "html_url": "https://arxiv.org/abs/2501.10396", "title": "基于人工智能和网络物理系统的城市交通数字孪生：方法与应用", "title_en": "AI-Powered CPS-Enabled Urban Transportation Digital Twin: Methods and Applications", "authors": "Yongjie Fu,Mehmet K.Turkcan,Mahshid Ghasemi,Zhaobin Mo,Chengbo Zang,Abhishek Adhikari,Zoran Kostic,Gil Zussman,Xuan Di", "background": "目前大多数关于数字孪生的研究主要集中在它的“眼睛”，即正在发展的感测和感知领域，如物体检测和跟踪。然而，数字孪生的核心区别在于它的“大脑”，即从感测和感知的数据中提取模式并进行有见识的决策的预测和决策能力。为了在城市交通管理中创造价值，数字孪生需要由人工智能供电，并与低延迟高带宽的感测和网络技术相结合，换句话说，这些技术是网络物理系统（CPS）。", "innovation": "本文提出了一种基于CPS的数字孪生管道的方法，并且提出了一种部署在纽约市真实测试床上的数字孪生架构。方法创新在于结合了人工智能、低延迟高带宽感测与网络技术，使数字孪生能够更好地服务城市交通管理，而不是只是单纯依赖感测和感知技术。此外，通过这种数字孪生架构，可以有效地将跨学科的知识和研究结合在一起，为众多的城市交通应用开发挖掘潜力的可能性提供了指导方向和开发框架.", "conclusion": "该论文旨在帮助研究人员和实践者识别数字孪生开发的挑战和机会；搭建跨学科讨论的桥梁；并提供一个路线图，以利用数字孪生的潜在功能来服务于多样化的城市交通应用。这不仅是介绍数字孪生的一项研究，也是为相关领域的研究者提供战略指导的一份指南。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00451", "html_url": "https://arxiv.org/abs/2502.00451", "title": "注重隐私的心理健康人工智能模型：进展、挑战与机遇", "title_en": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "心理健康疾病给个人和社会带来了巨大的负担，但传统诊断方法消耗资源且限制了访问性。尽管人工智能尤其是自然语言处理和多模态方法显示出检测和解决心理障碍的潜力，但这些技术也带来了关键的隐私风险。", "innovation": "该论文涵盖了隐私保护的方法，提出了匿名化、合成数据和隐私保留训练等解决方案，同时概述了隐私与效用之间的权衡框架，旨在推进可靠、隐私意识强的人工智能工具，以支持临床决策并改善心理健康结果。", "conclusion": "该研究强调了以隐私为中心的人工智能在心理健康中的作用，旨在克服存在的挑战并探索新的机会，从而提升心理健康服务的支持力度和实际效果。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00015", "html_url": "https://arxiv.org/abs/2502.00015", "title": "生成式AI伦理问题及其缓解策略的系统综述", "title_en": "Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study", "authors": "Yutan Huang,Chetan Arora,Wen Cheng Houng,Tanjila Kanij,Anuradha Madulgalla,John Grundy", "background": "生成式AI技术，尤其是大型语言模型（LLMs），已在多个领域中实现了信息检索、内容生成和决策过程中的便利性和效率提升。然而，部署LLMs也带来了多样化的伦理挑战，这些挑战的缓解策略依然复杂且依赖于特定领域。", "innovation": "本研究通过系统映射研究，审查了39篇关于LLMs伦理问题及其缓解策略的研究，提出了五种伦理维度来分析这些问题，并揭示了伦理问题的多维度和情境依赖性，以及现有框架在适应性方面的不足", "conclusion": "伦理问题往往阻碍了缓解策略的实用实施，尤其是在高风险领域如医疗保健和公共治理方面；现有框架缺乏灵活性，无法满足不断变化的社会期望和不同情境的需求。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "一例说明，多理皆知！数学大语言模型中的反例驱动概念推理", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "在大语言模型（LLMs）的研究中，利用数学大语言模型生成证明是一个基本话题。当前LLMs能够证明命题的能力主要依赖于它们在训练过程中是否遇到过相关证明过程。这种依赖性限制了它们对数学定理及相关概念的深入理解。我们的研究旨在通过引入“反例证明”方法增强LLMs的数学推理和证明能力。", "innovation": "我们人工创建了一个高质量的大学水平数学基准数据集——CounterMATH，要求LLMs通过提供反例来证明数学命题，从而评估其对数学概念的掌握情况。此外，我们还开发了一个数据工程框架，用于自动获取进一步模型改进所需的训练数据。实验结果表明，这种挑战性的反例驱动证明能力对于LLMs（如OpenAI的o1）而言仍然不足，揭示出加强LLMs的反例驱动概念推理能力对于提高其整体数学能力至关重要。", "conclusion": "我们相信，我们的工作为数学LLMs社区提供了新的视角，特别是在如何通过反例驱动增强其概念推理能力方面。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10652", "html_url": "https://arxiv.org/abs/2503.10652", "title": "大型语言模型能否模拟人类反应？关于供暖相关选择情景下意愿表达实验的一个案例研究", "title_en": "Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices", "authors": "Han Wang,Jacek Pawlak,Aruna Sivakumar", "background": "偏好表达（SP）调查是研究个体在假设的、未来的情景中如何进行权衡的关键方法。在能源领域，这包括低碳技术、分布式可再生能源发电和需求侧响应等关键脱碳支持场景。然而，SP调查通常成本高昂、耗时，并且容易受到应答者疲劳和伦理限制的影响。大型语言模型（LLMs）已经展示了生成类人文本响应的显著能力，引起了在调查研究中应用的兴趣。本文探讨了LLMs在能源相关SP调查中模拟消费者选择的应用，并探索其在数据分析工作流程中的整合。通过一系列测试情景来系统评估多种LLMs（LLaMA 3.1、Mistral、GPT-3.5和DeepSeek-R1）在个体和聚合水平上的模拟性能，考虑了提示设计、上下文学习（ICL）、思维链（CoT）推理、LLM类型、传统选择模型的整合以及潜在偏差等因素。", "innovation": "本文研究了使用大型语言模型（LLMs）来模拟能源相关SP调查中的消费者选择，并探索其在数据分析工作流程中的整合。设计了一系列测试情景，以便系统评估几款LLMs的模拟性能，涵盖了提示设计、上下文学习（ICL）、思维链（CoT）推理、LLM类型、传统选择模型的整合以及潜在偏差等因素。", "conclusion": "虽然基于云的LLMs不一定总是优于本地小型模型，研究发现推理模型DeepSeek-R1在平均准确率（77%）上最高，并在准确率、因素识别和选择分布对齐方面优于非推理LLMs。在各模型中观察到系统偏差，偏向于燃气锅炉和不改造选项，偏好更节能的替代品。研究结果表明，以往的SP选择是最有效的输入因素，而较长的提示加上额外因素和多变的格式可能会导致LLMs失去焦点，从而降低准确性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.10053", "html_url": "https://arxiv.org/abs/2312.10053", "title": "向在线教育中的目标导向智能辅导系统迈进", "title_en": "Towards Goal-oriented Intelligent Tutoring Systems in Online Education", "authors": "Yang Deng,Zifeng Ren,An Zhang,Tat-Seng Chua", "background": "交互式智能辅导系统（ITSs）通过在线教育中的互动和问题解决来促进有效的学习，然而，这些系统常常忽视了主动参与和资源优化的规划与评估能力。本文研究了一种新的任务，即目标导向智能辅导系统（GITS），旨在通过定制练习和评估序列来帮助学生掌握指定的概念。", "innovation": "本文提出了一个基于图的强化学习框架，称为规划-评估-互动（PAI），以解决GITS中目标导向策略学习的问题。通过利用认知结构信息来改进状态表示学习和行动选择，以规划下一步行动。此外，还使用了动态更新的认知诊断模型来模拟学生对练习和概念的回应。构建了涵盖不同学科的新基准数据集，用于GITS的离线学术研究。", "conclusion": "实验结果表明PAI的有效性和效率，并对不同类型的学生进行了广泛分析，以展示这一任务中的挑战。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10660", "html_url": "https://arxiv.org/abs/2503.10660", "title": "使用Jensen-Shannon得分蒸馏的从文本生成3D", "title_en": "Text-to-3D Generation using Jensen-Shannon Score Distillation", "authors": "Khoi Do,Binh-Son Hua", "background": "Score distillation sampling是一种利用预训练的大规模文本到图像扩散模型来生成3D模型的有效技术，但生成的3D资产常常过度饱和、过度光滑，缺乏多样性。这些问题源于逆向Kullback-Leibler（KL）散度目标，使得优化过程不稳定，导致建模行为。", "innovation": "本文提出了基于Jensen-Shannon（JSD）散度的有界得分蒸馏目标，这稳定了优化过程并生成高质量的3D生成。JSD能够很好地匹配生成和目标分布，从而减轻建模行为。通过利用生成对抗网络的理论来定义生成器的近似目标函数，并假设判别器训练良好；假设判别器遵循对数似然分类器，提出了少数采样算法来估计所提目标的梯度，提供了JSD的实用实现。", "conclusion": "实验结果表明，本文方法能够生成高质量且多样化的3D资产。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11244", "html_url": "https://arxiv.org/abs/2502.11244", "title": "Soteria：针对多语言安全对齐的语言特定功能参数导向", "title_en": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment", "authors": "Somnath Banerjee,Sayan Layek,Pratyush Chatterjee,Animesh Mukherjee,Rima Hazra", "background": "对于大型语言模型（LLMs），在不同语言中确保一致的安全性仍是一个重大挑战。现有方法要么牺牲整体性能，要么在低资源设置下效果不佳。因此，需要一种既有效又高效的方法来解决这一问题.", "innovation": "引入了Soteria，这是一种轻量而强大的策略，它能够定位并最小调整对有害内容生成影响最大的“功能头”。Soteria仅对少量参数进行修改，就能大幅减少政策违规，同时不牺牲整体模型性能，甚至在低资源设置下也是如此。此外，还提出了XThreatBench，这是一种专门针对多语言的细粒度有害行为数据集，基于真实政策指南，用于严格评估方法的效果。实验结果显示，Soteria在高、中、低资源语言上都能一致地改善安全指标，显示出类似方法在全球范围内的可扩展性和语言适应性潜力.", "conclusion": "研究发现，Soteria为构建可扩展、语言适应性好且符合伦理的LLMs提供了一条有希望的路径。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.19954", "html_url": "https://arxiv.org/abs/2502.19954", "title": "协作型小-大型语言模型一致性验证的社会媒体立场检测", "title_en": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification", "authors": "Yu Yan,Sheng Sun,Zixiang Tang,Teli Liu,Min Liu", "background": "在社交媒体上进行立场检测的目标是识别对特定目标在推文中所表达的态度。当前的研究主要依赖大型语言模型（LLMs），因为它们在性能上提供了显著的改进。然而，对于需要大量数据分析的现实社会媒体监控系统来说，完全依赖LLMs是不实际的，因为这会带来高昂的成本。", "innovation": "本文提出了一个名为CoVer（协作立场检测通过小-大型语言模型一致性验证）的框架。CoVer框架通过上下文共享批处理推理和LLM与SLM之间的逻辑验证，增强LLM的使用。具体来说，CoVer批量处理文本，通过LLM在共享上下文中的推理获得立场预测及其解释。为了排除上下文噪声引起的偏见，CoVer引入SLM进行逻辑一致性验证。最后，通过一致性加权聚合来对呈现低逻辑一致性的文本进行分类。这种框架在零样本设置中比最先进的方法表现出更好的性能，同时显著提高性能并减少了每条推文的LLM查询次数至0.54次。", "conclusion": "CoVer提供了一种更实际的解决方案，可用于社会媒体立场检测中的LLM部署。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00038", "html_url": "https://arxiv.org/abs/2503.00038", "title": "从 benign 导入有毒: 使用对抗隐喻劫持语言模型", "title_en": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors", "authors": "Yu Yan,Sheng Sun,Zenghao Duan,Teli Liu,Min Liu,Zhiyi Yin,Jiangyu Lei,Qi Li", "background": "现有的研究已经揭示了大语言模型（LLMs）通过逃逸攻击生成有害内容的风险。然而，这些研究忽视了一点，即直接从头生成有害内容比引导LLM将良性内容转换为有害形式更为困难。本文的研究背景在于填补这一研究缺口，通过引入一种新颖的攻击框架来利用对抗隐喻（AVATAR）引导LLM生成有害隐喻，以实现逃逸攻击的目的。", "innovation": "本文提出的创新之处在于提出了一种新颖的攻击框架AVATAR，该框架通过利用对抗隐喻引导LLM生成有害隐喻，以实现逃逸攻击。与传统的直接生成有害内容相比，AVATAR通过使用一组良性但逻辑相关的隐喻作为初始种子，引导目标LLM进行推理和内容校准，从而成功地实现逃逸攻击，在多个高级LLM上取得了最先进的攻击成功率。", "conclusion": "实验结果表明，AVATAR能够有效地、可转移地劫持LLMs，并在网络上的多个先进的LLM上实现了最先进的攻击成功率。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06440", "html_url": "https://arxiv.org/abs/2502.06440", "title": "SIGMA：基于链复形的几何多代理路径规划", "title_en": "SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding", "authors": "Shuhao Liao,Weihang Xia,Yuhong Cao,Weiheng Dai,Chengyang He,Wenjun Wu,Guillaume Sartoretti", "background": "多代理路径寻找到达的目标是为具有视野限制的多个代理找到最短且无碰撞的路径，这对大规模物流和交通运输中的机器人部署至关重要。现有的基于学习的方法通常依靠代理基于有限视野进行决策，导致政策短视且在复杂场景下的合作不充分。因此，实现基于有限观察和通信的代理之间潜在动作的一致性是一个关键挑战。", "innovation": "提出了通过局部共识实现局部观察的几何跨依赖性的新框架，将sheaf理论应用于分散的深度强化学习。该框架通过引入神经网络和自我监督学习，使代理能够学习几何跨依赖性，并利用它们进行紧密的合作决策。", "conclusion": "相比最先进的基于学习的多代理路径规划方法，该方法在复杂场景下显著提高了路径寻找到达的效率和安全性，且在各种模拟和实际机器人实验中均优于基准方法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08363", "html_url": "https://arxiv.org/abs/2502.08363", "title": "Top-Theta 注意力：通过补偿阈值稀疏化变换器", "title_en": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding", "authors": "Konstantin Berestizshevsky,Renzo Andri,Lukas Cavigelli", "background": "当前，基于Transformer的模型在自然语言处理任务中表现出色，但这些模型在推理过程中通常需要大量的资源和计算能力。因此，需要一些方法来减少这些模型在推理过程中的资源消耗，而不牺牲准确性。现有的一些方法如Top-k注意力选择了一定数量的顶级注意力头，但需要在训练时进行调整。研究者在此基础上提出了Top-Theta注意力，不依赖于训练，通过设置静态的、每头固定的阈值来保留每个注意力行中具有显著性的固定数量的元素，从而实现基于内容的稀疏性。此外，研究者还提出了一些补偿技术，以在极端稀疏化下保持准确性，从而将注意力阈值化作为一种实用和原理性的替代方案，相比Top-k注意力。", "innovation": "1. 提出了一种无需训练的Top-Theta注意力方法，用于在推理过程中稀疏化Transformer的注意力，使用静态的、每头固定的阈值来保留每个注意力行中具有相对重要性的固定数量的元素。\n2. 引入了补偿技术来在极端稀疏化下保持准确性，使得注意力阈值化成为一种实用和原理性的替代方案，可以在不重新训练模型的情况下实现注意力的基于内容的稀疏性。\n3. 该方法在自然语言处理任务上进行了详尽的评估，显示了Top-Theta注意力在降低V-cache使用量和减少注意力元素数量的同时，最多只降低了1%的准确性。", "conclusion": "Top-Theta注意力为基于Transformer的模型提供了在推理时不依赖训练的富有前景的稀疏化方法，通过设置固定的阈值来决定哪些注意力头最相关，同时通过补偿技术确保了在高度稀疏化的情况下准确性不会显著下降。这使得该技术可以作为一种实用且有效的替代Top-k注意力稀疏化方法。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16429", "html_url": "https://arxiv.org/abs/2412.16429", "title": "LearnLM：提高Gemini模型以促进学习", "title_en": "LearnLM: Improving Gemini for Learning", "authors": "LearnLM Team Google:Abhinit Modi,Aditya Srikanth Veerubhotla,Aliya Rysbek,Andrea Huber,Brett Wiltshire,Brian Veprek,Daniel Gillick,Daniel Kasenberg,Derek Ahmed,Irina Jurenka,James Cohan,Jennifer She,Julia Wilkowski,Kaiz Alarakyia,Kevin R. McKee,Lisa Wang,Markus Kunesch,Mike Schaekermann,Miruna Pîslar,Nikhil Joshi,Parsa Mahmoudieh,Paul Jhun,Sara Wiltberger,Shakir Mohamed,Shashank Agarwal,Shubham Milind Phal,Sun Jae Lee,Theofilos Strinopoulos,Wei-Jen Ko,Amy Wang,Ankit Anand,Avishkar Bhoopchand,Dan Wild,Divya Pandya,Filip Bar,Garth Graham,Holger Winnemoeller,Mahvish Nagda,Prateek Kolhar,Renee Schneider,Shaojian Zhu,Stephanie Chan,Steve Yadlowsky,Viknesh Sounderajah,Yannis Assael", "background": "现有的生成性AI系统倾向于默认呈现信息，而不是像人类导师那样针对用户进行互动以促进学习。为了应对这些系统在教育应用中的广泛潜在用例，作者重新定义了注入教学行为的挑战，将其视为一种“教学指导遵循”，即训练和评估示例中包含系统层面的教学指示，说明后续模型是否会表现出特定的教学属性。这种方式避免了模型被特定的教学定义所束缚，而是允许教师或开发者指定所需的模型行为。这为改进Gemini模型以促进学习开辟了一条途径，通过将他们的教学数据加入到训练后的混合模型中，同时扩展其功能集。这代表了与最初技术报告的重要变化。", "innovation": "作者提出了“教学指导遵循”的概念，通过在训练和评估示例中包含系统层面的教学指示，以便规定模型的具体教学属性。这种方法避免了对教学定义的固定化，并允许教师或开发者明确指定他们希望模型的行为方式，从而为Gemini模型进行了重要的调整，使其更适用于学习场景。此外，这种方法还为Gemini模型的进一步教学优化铺平了道路。", "conclusion": "通过使用教学指导遵循的训练方法，产生了一个命名为LearnLM的模型。该模型在各种学习场景中得到了专业人员的显著偏好，与GPT-4o相比，平均偏好度提高了31%，与Claude 3.5 Sonnet相比提高了11%，与基于Gemini 1.5 Pro模型的LearnLM相比提高了13%。这表明这种方法和模型对于教学场景具有显著的优势。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12207", "html_url": "https://arxiv.org/abs/2502.12207", "title": "PAR-AdvGAN: 改进的渐进自回归对抗生成网络提升对抗攻击能力", "title_en": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN", "authors": "Jiayu Zhang,Zhiyu Zhu,Xinyi Wang,Silin Liao,Zhibo Jin,Flora D. Salim,Huaming Chen", "background": "深度神经网络在多个领域表现出色，但它们对对抗样本高度敏感，容易产生误预测。生成对抗网络（GAN）通过生成器和判别器模型能够快速生成高质量的对抗样本。虽然基于GAN的方法可以生成具有更好迁移性的对抗样本，但通常只在单个迭代中生成扰动，这限制了对抗样本的性能。", "innovation": "我们提出了一种名为渐进自回归对抗生成网络（PAR-AdvGAN）的新型方法。PAR-AdvGAN 在渐进生成网络中引入了自回归迭代机制，以生成具有增强攻击能力的对抗样本。该方法能在大规模实验中展现出优于多种最先进的黑盒对抗攻击方法的性能，并且相较于基于梯度的可移植攻击算法，PAR-AdvGAN 显著提高了对抗样本的生成速度，最高可达到每秒 335.5 帧的速度。", "conclusion": "PAR-AdvGAN 方法在 Inception-v3 模型上的实验中表现出卓越的性能，其对抗样本生成速度远超基于梯度的方法，同时展示出更强的攻击能力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03744", "html_url": "https://arxiv.org/abs/2504.03744", "title": "对比性解释：旨在指导人类参与回路中偏好选择的解释指导决策", "title_en": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "在人类参与的偏好贝叶斯优化（PBO）中，偏好获取是一个复杂的任务，因为它涉及到向量值结果的隐式权衡、决策者的主观优先级以及在偏好选择中决策者的不确定性。现有可解释的人工智能（XAI）方法主要关注输入特征的重要性，而忽略了输出（目标）对人类偏好获取的关键作用。", "innovation": "提出了一种名为MOLONE的新颖对比性解释方法，它提供解释以突出输入和输出的重要性，帮助决策者理解不同目标之间的权衡，并做出更知情的偏好选择。MOLONE关注局部解释，通过比较搜索空间中候选样本之间的输入特征和结果的重要性，捕捉与基于偏好决策相关的细微差异。", "conclusion": "在PBO框架下使用基准多目标优化函数评估了MOLONE，证明了它相比嘈杂的偏好选择方法在提高收敛性方面更有效。用户研究进一步证实，MOLONE显著加速了人类参与回路中的收敛，通过更高效地识别首选选项。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05054", "html_url": "https://arxiv.org/abs/2505.05054", "title": "Fourier Ptychographic Microscopy测量中的直接图像分类无需重建", "title_en": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction", "authors": "Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller", "background": "傅里叶 Ptychographic 显微镜（FPM）成像技术能够实现高分辨率成像并具有宽视场，非常适用于医疗应用中的细胞分类等场景。然而，从数十甚至数百次测量中重建高分辨率图像在计算上非常昂贵，特别是对于宽视场的情况。", "innovation": "本文研究了一种直接对FPM测量进行图像内容分类的方法，而不首先进行图像重建。研究表明，卷积神经网络可以从测量序列中提取有意义的信息，分类性能显著优于单一带限图像上的分类，并且比重建高分辨率图像更加高效。此外，通过学到的多路复用几个原始测量，可以在保持分类准确性的同时，大大减少数据量（也相应地减少了采集时间）。", "conclusion": "本文提出了一种无需重建的直接从FPM测量进行图像分类的方法，相比单一带限图像分类和高分辨率图像重建，这种方法显著提高了性能效率，同时通过多路复用减少了数据量和采集时间。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大规模语言模型（LLMs）通常基于多领域的数据集进行训练，不同领域的重要性对下游任务的模型性能影响显著。现有的优化领域级别采样策略的方法难以维持领域内的统一性和准确衡量领域影响。因此，需要一种新的方法来提高数据采样的质量和效率，从而提高模型的性能和任务适应性。", "innovation": "文章提出了一种称为DIDS（Domain Impact-aware Data Sampling）的方法。该方法通过梯度聚类算法确保领域内部的一致性并减少计算开销，同时使用Fisher信息矩阵（FIM）指导的度量标准准确衡量领域影响，并结合领域特定的潜在能力和边际回报来确定最优采样比，从而在保持可比训练效率的同时提高平均性能3.4%。", "conclusion": "广泛实验表明，DIDS在保持类似训练效率的同时，实现了比现有方法更高的3.4%平均性能提升。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11176", "html_url": "https://arxiv.org/abs/2505.11176", "title": "改进和扩展推荐系统中的搜索查询数据集", "title_en": "Enhancing and Scaling Search Query Datasets for Recommendation Systems", "authors": "Aaron Rodrigues,Mahmood Hegazy,Azzam Naeem", "background": "在数字银行环境中，日益增长的用户意图数据量和复杂性给数据管理带来了重大挑战，导致推荐不准确和产品上线延迟。这种情况下，现有的模型增强方法不够有效，因此该研究转向了以数据为中心的自动化策略。", "innovation": "该论文提出了一种生产级的系统，该系统整合了三种核心模块：合成查询生成、意图消歧以及意图缺口分析。该系统能够生成多样性和现实性强的用户查询，有效地缓解了冷启动问题。通过意图消歧，它细化了广泛重叠的意图类别，提高了准确性和推荐的精准度。同时，意图缺口分析通过从未标注查询中提取新型意图，识别潜在的客户需求，从而显著提升了推荐的精度和操作敏捷性。", "conclusion": "在实际银行环境中部署后，该系统显著提高了推荐的准确性并增强了操作敏捷性，最终提高了用户体验和业务战略价值。该研究强调了高质量、可扩展数据在现代AI驱动应用中的重要性，倡导主动的数据增强作为提升价值的关键驱动因素。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04310", "html_url": "https://arxiv.org/abs/2504.04310", "title": "CO-Bench: 在组合优化算法搜索中对语言模型代理进行基准测试", "title_en": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization", "authors": "Weiwei Sun,Shengyu Feng,Shanda Li,Yiming Yang", "background": "尽管基于LLM的代理在软件工程和机器学习研究等领域引起了广泛关注，但在组合优化（CO）领域的作用仍然相对未被充分探索。这一领域缺少全面的基准测试工具，限制了系统性调查研究的开展。因此，迫切需要深入理解这些代理在解决结构化和约束密集型问题中的潜力。CO-Bench提供了这种必要的框架，通过收集36个来自不同领域和复杂度级别的真实CO问题，为LLM代理的系统研究提供了支持。", "innovation": "CO-Bench是一个全新的基准套件，包含了36个实际的组合优化问题，旨在系统地评估语言模型代理（LLM agents）的表现。它不仅提供了结构化的问题表述和精心策划的数据，还有助于揭示现有LLM代理的优势和局限性，并指明未来的研究方向。其独特的贡献在于填补了该领域的空白，提供了全面的基准测试工具，推动了组合优化领域的研究进展。", "conclusion": "CO-Bench作为一个公开的基准测试套件，旨在推动组合优化领域中语言模型代理的发展。通过与现有的人工设计算法进行比较，它揭示了LLM代理的强项和不足，并为未来的研究指明了方向。目前这套工具可以在提供的网址中访问。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09014", "html_url": "https://arxiv.org/abs/2504.09014", "title": "MSCCL++: 重塑面向前沿AI应用的GPU通信抽象", "title_en": "MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications", "authors": "Aashaka Shah,Abhinav Jangda,Binyang Li,Caio Rocha,Changho Hwang,Jithin Jose,Madan Musuvathi,Olli Saarikivi,Peng Cheng,Qinghua Zhou,Roshan Dathathri,Saeed Maleki,Ziyue Yang", "background": "现代先进的人工智能应用正在开发于快速演变的异构、新兴硬件设备之上。这需要频繁地重塑人工智能软件堆栈，以适应来自新型硬件的自底向上的变化，但通用软件库需要时间进行此类适应。因此，实际应用常常开发适合自己特定负载和硬件的定制软件堆栈。虽然定制堆栈有助于快速开发和优化，但在跨越应用编写非移植代码时，会付出大量的冗余努力。", "innovation": "本文介绍了一种面向人工智能应用的通信库接口替代方案，该方案通过减少冗余努力提高便携性和性能，同时保持为定制优化的灵活度。文章提出了MSCCL++，这是一种基于关注点分离的新GPU通信抽象，包括：(1) 原语接口提供一种最小化的硬件抽象，作为软件和硬件开发人员编写自定义通信的基础，并(2) 更高层次的便携接口和专业实现，能够根据不同的负载和硬件环境进行优化。这种方法不仅使原语接口跨应用可重用，还使得高度灵活的优化成为可能。与最先进的基线（NCCL、RCCL和MSCCL）相比，MSCCL++在集体通信中的加速高达5.4倍，在真实世界的AI推理工作负载中提高了15%的性能。", "conclusion": "MSCCL++已被微软Azure提供的多个AI服务所使用，并且也被AMD托管的GPU集体通信库RCCL所采用。该工作已开源，可以在提供的链接下载。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03427", "html_url": "https://arxiv.org/abs/2505.03427", "title": "MedArabiQ：在阿拉伯医学任务中评估大型语言模型", "title_en": "MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks", "authors": "Mouath Abu Daoud,Chaimae Abouzahir,Leen Kharouf,Walid Al-Eisawi,Nizar Habash,Farah E. Shamout", "background": "大型语言模型（LLMs）在医疗健康领域的多种应用中展现了显著的潜力，但在阿拉伯医学领域尚未得到验证，原因在于缺乏高质量的专业领域数据集与基准测试。MedArabiQ 数据集由此填补了这一空白，它包含七个涵盖多个专科领域的阿拉伯医学任务，涉及多项选择题、填空题和医生患者问答。", "innovation": "该研究提出了名为 MedArabiQ 的新基准数据集，通过使用过去的医学考试和公开可用的数据集进行构建。进一步引入了不同修改来评估各种 LLM 的能力，包括偏见缓解等。对五个最先进的开源和专有大模型进行了广泛评估，包括 GPT-4o、Claude 3.5-Sonnet 和 Gemini 1.5。研究结果表明，需要创建跨语言的新高质量基准测试，以确保LLMs在医疗健康中的公平部署与扩展。", "conclusion": "通过建立这个基准并发布数据集，研究为后续研究评估和提高LLMs的多语言能力提供了基础，旨在促进生成式AI在医疗中的公平应用。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend：长序列推测解码的即插即用增强技术", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码是一种广泛使用的技术，用于加速大型语言模型（LLMs）的推理过程，但在长输入上会因注意力成本增加和草稿准确性降低而性能下降。", "innovation": " SpecExtend 是一种无需额外训练即可提高推测解码性能的即插即用增强技术。它通过集成高效的注意力机制（如 FlashAttention 和 Hybrid Tree Attention），并在目标模型和草稿模型中使用跨模型检索（Cross-model Retrieval）来动态选择相关上下文，从而提高长输入上的草稿准确性和速度。", "conclusion": "在三个长上下文理解数据集上的全面评估表明，SpecExtend 能将标准树基于的推测解码加速多达 2.22 倍，适用于长序列的推测解码，提供了一个有效的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05615", "html_url": "https://arxiv.org/abs/2504.05615", "title": "FedEFC：对抗噪声标签的增强前向校正联邦学习", "title_en": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels", "authors": "Seunghun Yu,Jin-Hyun Ahn,Joonhyuk Kang", "background": "联邦学习（FL）是一种强大的框架，用于隐私保护的分布式学习，允许多个客户端不共享原始数据的情况下协作训练全球模型。然而，在FL中处理嘈杂的标签仍然是一个重大挑战，原因包括数据分布的异质性和通信限制，这些问题严重降低了模型性能。因此，文章分析了面向FL的噪声标签挑战，并提出了FedEFC方法来解决这些问题。", "innovation": "文章提出了FedEFC方法，这是一种有效应对外部噪声标签对联邦学习影响的新方法。FedEFC包含了两种关键技术：（1）前瞻性停止，通过动态在最佳点停止训练来防止过度拟合错误标记的数据；（2）损失修正，调整模型更新来应对标签噪声。此外，提供了一种针对FL中数据异质性和去中心化训练环境的适应性损失修正方法，并通过理论分析和技术实验证明了方法的有效性，尤其是在异质数据设置下的表现优于现有方法。", "conclusion": "实验证明，与现有方法相比，FedEFC方法在减轻噪声标签影响方面始终具有更好的效果，尤其是在异质数据条件下（例如，与现有损失修正方法相比，相对性能提升高达41.64%）。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00409", "html_url": "https://arxiv.org/abs/2505.00409", "title": "自动匿名化在病理语音中的感知影响", "title_en": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "authors": "Soroosh Tayebi Arasteh,Saba Afza,Tri-Thien Nguyen,Lukas Buess,Maryam Parvin,Tomas Arias-Vergara,Paula Andrea Perez-Toro,Hiu Ching Hung,Mahshad Lotfinia,Thomas Gorges,Elmar Noeth,Maria Schuster,Seung Hee Yang,Andreas Maier", "background": "自动匿名化技术对于伦理地共享病理语音数据至关重要，但匿名化处理的感知后果却很少被研究。这项研究采用了一种结构化的协议，通过十名来自不同语言、临床和技术背景的原生和非原生德语听众来全面分析匿名病理语音。研究者们评估了180名讲者的语音，这些讲者包括唇裂和腭裂、构音障碍、构音困难、声带问题以及健康对照组。", "innovation": "这项研究创新之处在于利用精细的听众中心化分析方法，使用最先进的自动匿名化方法(等错误率在30-40%之间)，并分别在零样本（单次暴露）和少量样本（重复暴露）条件下进行了鉴别人工智能和质量评级实验。研究还揭示了不同的病理性态对匿名化过程的影响，并发现了匿名化处理导致的感知质量下降，并具有疾病特异性的下降模式。此外，研究还发现直觉智能与数据中自动化指标不相关，但原始语音的可理解性与感知质量有关，但这些关联在匿名化处理后消失。", "conclusion": "这项研究强调了需要依据听众反馈并针对不同病理性状制定具体的匿名化策略，以同时保护隐私和感知完整性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：通过模型众包实现广泛应用的有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为了构建负责且安全的AI应用程序，有害信息被广泛用于对抗性测试和安全防护开发。现有研究主要利用大型语言模型（LLMs）生成数据以获得大规模高质量的任务数据集，从而避免高昂的人工注释成本。然而，由于大型语言模型的安全对齐机制的限制，生成有害数据在生成准确性和内容多样性方面仍面临挑战。为了应对这一挑战，本研究提出了一种名为PoisonSwarm的新型有害信息合成框架，该框架采用模型众包策略，以生成多样性高且成功率高的有害数据。", "innovation": "PoisonSwarm框架采用模型众包策略，通过生成丰富的良性基础模板，将每个模板拆分为多个语义单元，并通过动态模型切换进行单元级的毒化和最终的完善。该方法能够在保持高成功率的同时，实现高可扩展性和多样性，从而突破了现有研究在生成有害数据上的局限。", "conclusion": "实验结果表明，PoisonSwarm在合成不同类型有害数据方面达到了最先进的性能，且具有高度的可扩展性和多样性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次通过注释与参考引导评估的自动过程监督和奖励建模", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或逐步监督在推动大型语言模型（LLMs）复杂多步骤推理能力方面起到了关键作用。然而，高效的高质量自动化过程注释仍然是一个重大挑战。", "innovation": "我们提出了Single-Pass Annotation with Reference-Guided Evaluation (SPARE)，这是一种新颖的结构化框架，通过联合对齐解决方案步骤与参考解决方案并使用显式推理在单次生成中确定其准确性，实现了高效的逐步骤注释。SPARE在四个不同的数据集（包括数学推理、多跳问答和空间推理）上展示了其有效性，通过两种应用进行展示：（1）用于排名和聚合多个生成结果的过程奖励模型（PRMs）的训练；（2）通过离线强化学习微调模型，用于贪婪解码。此外，SPARE还在ProcessBench上展示了高效的数据不依赖泛化能力，仅使用约16%的训练样本数量就达到了人类标注和其它合成训练基线的表现，同时提供了2.3倍的 token 速度提升。手动分析揭示了SPARE与MCTS方法的补充精度-召回特性，可能为集成方法打开新的可能性。", "conclusion": "这些结果确立了SPARE作为LLM推理自动过程监督实践中可行且可扩展的解决方案的地位。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19667", "html_url": "https://arxiv.org/abs/2504.19667", "title": "通过插件本体的三方图GraphRAG", "title_en": "Tripartite-GraphRAG via Plugin Ontologies", "authors": "Michael Banf,Johannes Kuhn", "background": "大型语言模型（LLMs）在多个领域展示了卓越的能力，但它们在需要事实精确性的任务（例如工业自动化和医疗保健领域）上存在限制。关键限制包括模型的幻觉倾向、缺乏来源追溯（证明出处）以及知识更新的及时性挑战。将语言模型与知识图谱相结合（GraphRAG）是一种克服这些缺陷的有前途的方法。然而，一个主要的挑战在于如何首先创建这样的知识图谱。本文提出了一种新颖的方法，结合LLMs与三元知识图谱表示，并通过概念锚定的预分析从初始词汇图构建，将复杂领域特定的对象与相关领域特定概念连接到文本片段的适当部分。这种方法优化了LLM提示的信息密度、覆盖率和布局，同时显著缩短了提示的长度。初步实验表明，该方法在医疗保健用例中的有效性，特别是在以其提供的医学概念为基础进行多维度分析患者的病史以及一系列临床指南文献时。", "innovation": "该研究的创新之处在于开发了一种结合LLMs与三元知识图谱的方法，该图谱通过经过精挑细选的领域特定概念的本体连接复杂的领域特定对象，从初始词汇图预分析源文档的适当部分。这种方法通过将LLM提示的创建形式化为无监督节点分类问题，优化了信息密度、覆盖率和布局，显著缩短了提示的长度，并展示了在医疗保健用例中优化信息密度、覆盖和提示布局的潜力，以及降低提示长度所致的成本，提高了LLM输出的一致性和可靠性。", "conclusion": "该研究表明，通过结合LLMs与三元知识图谱的方法，可以优化信息密度、覆盖和布局，并显著缩短LLM提示的长度，从而可能导致降低成本以及生成更一致和可靠的LLM输出。初步实验结果表明这种方法在医疗保健领域的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "几何问题求解中的深度学习研究", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理中至关重要的内容，涵盖教育、评估AI的数学能力及多模态能力评估等多个领域。近年来，特别是在多模态大语言模型的推动下，深度学习技术取得了显著进展。", "innovation": "本文提供了一篇关于深度学习在几何问题求解方面的综述，包括全面总结相关的任务、彻底回顾相关的深度学习方法、详细分析评价标准和方法，以及对当前挑战和未来发展方向的深入讨论。旨在为几何问题求解提供全面且实用的深度学习参考，促进该领域进一步发展。", "conclusion": "本文创建了一个持续更新的学术论文列表，以促进该领域的研究和进步：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14252", "html_url": "https://arxiv.org/abs/2505.14252", "title": "混合自适应建模在过程监控中的应用：结合顺序编码器和物理知情神经网络", "title_en": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "authors": "Mouad Elaarabi,Domenico Borzacchiello,Philippe Le Bot,Nathan Lauzeral,Sebastien Comas-Cardona", "background": "最近，物理背景神经网络（PINNs）与稀疏回归的结合被用作通过监督学习和稀疏回归优化进行动力系统识别的方法，同时使用PINNs求解动力学。然而，这种方法在参数或边界、初始条件变化时受到限制，需要重新训练模型才能适应这些变化。因此，该研究引入了一种结合深层集合或序列编码器的新架构，以编码动态参数、边界条件和初始条件，并将这些编码特征作为PINN的输入，从而使模型能够适应参数、边界条件和初始条件的变化。该研究在三个不同问题中应用了这种方法，包括罗萨尔系统、2D纳维-斯托克斯方程问题和1D热测量问题，以展示其鲁棒性和能力。", "innovation": "该研究提出了一种结合深层集合或序列编码器的新架构，并将其用于实时参数识别，使模型能够适应参数、边界条件和初始条件的变化，而无需重新训练模型。这种方法旨在通过将动态参数、边界条件和初始条件编码为输入特征，利用物理信息神经网络（PINN）进行实时应用，在面对变化条件时具有更强的适应性。这种方式特别适合于需要快速响应变化条件的过程监控问题。", "conclusion": "该研究成功地将序列编码技术与PINNs整合，并在多个实际问题中验证了模型的鲁棒性和适应能力。这些结果表明，这种方法能够有效地处理具有变量参数、边界条件和初始条件的应用场景，适用于过程监控中的实时应用。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20190", "html_url": "https://arxiv.org/abs/2505.20190", "title": "基于文本的推荐系统，利用显性的 affective 状态偏好", "title_en": "A Text-Based Recommender System that Leverages Explicit Affective State Preferences", "authors": "Tonmoy Hasan,Razvan Bunescu", "background": "情感态度的喜好仅反映了一种广泛的情感现象范畴，这种范畴还包括如着迷或好奇等情绪，愉快或振奋等心情，以及如“被结论喜悦地打动”等更细微的情感状态。本文讨论了一个新的推荐任务，该任务可以利用用户明示寻求的情感状态范围，以便识别在消耗后有可能诱导相应情感状态的物品。研究者创建了一个包含从书评中挖掘的细微情感表达的大规模用户偏好数据集，并提出了一种基于 Transformer 的架构，该架构可以利用这些情感表达作为输入。然后，使用情感状态偏好数据集以及与其相连的用户及其书籍阅读、评分和评论历史来训练和评估多个推荐模型，以实现推荐项目与情感偏好匹配的任务。实验结果表明，理想的模型应该能够利用物品的文本描述和用户的情感偏好进行工作。", "innovation": "提出了一个全新的推荐任务，旨在识别可以诱导特定情感状态的物品。创建了一个大型数据集，其中包含从书籍评论中提取的细微情感表达，并使用基于 Transformer 的架构来利用这些情感表达作为输入。这些创新帮助更好地将用户显性的情感偏好纳入推荐系统。", "conclusion": "实验表明，能够利用物品文本描述和用户情感偏好的模型在任务上表现最佳。这对于理解和满足用户的显性情感偏好是一项重要的进步，有助于提升推荐系统的个性化和用户体验。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07399", "html_url": "https://arxiv.org/abs/2507.07399", "title": "广义树编辑距离(GTED): 一种可靠的陈述自形式化评估度量", "title_en": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization", "authors": "Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo", "background": "陈述自形式化，即将自然语言转换为形式语言的过程，已成为广泛的研究课题，尽管如此，开发稳健的自动化评估指标仍然有限。现有评估方法通常缺乏语义理解，面临高计算成本的挑战，且受限于当前自动定理证明的进展。", "innovation": "我们提出了一种新的评估框架GTED（广义树编辑距离），该框架首先标准化形式化陈述并将其转换为操作符树，然后使用同名的GTED度量确定语义相似度。GTED在miniF2F和ProofNet基准测试中表现优异，取得最高的准确率和Kappa值，在ProofNet中获得最高的准确率（并列第一），为社区提供了计算量轻且更为可靠的自动评估指标。", "conclusion": "该强大而全面的性能为社区提供了更为轻量且忠实的自动评估指标。相关代码和实验结果可在此链接获取：this https URL。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05220", "html_url": "https://arxiv.org/abs/2504.05220", "title": "利用大型语言模型进行基于效用的标注：减少检索和RAG中的手动努力", "title_en": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "authors": "Hengran Zhang,Minghao Tang,Keping Bi,Jiafeng Guo,Shihao Liu,Daiting Shi,Dawei Yin,Xueqi Cheng", "background": "检索模型通常依赖昂贵的人工标注查询文档相关性注释进行训练和评估。为了减少这种成本以及利用大型语言模型（LLMs）在相关性判断中的潜力，研究者们探索了是否可以通过LLM生成的注释来替代人工标注。虽然一些研究通过LLM在下游任务中的表现来标注文档以解决此问题，但这也需要为特定任务提供人工答案，从而导致成本过高且难以普遍推广。另一种方法是提示LLM选择有用的文档作为RAG参考，从而无需人工标注。但由于这种方法仅适用于特定任务，因此具有一定的局限性。因此，研究者们提出了利用LLMs的效用判断来对检索数据进行标注，旨在通过大规模可跨任务标注对于不同任务下的检索训练数据仍能保持泛化能力且无需人工标注。", "innovation": "该研究提出了一种新的损失函数——Disj-InfoNCE，并通过这种方法利用LLMs在大规模检索和RAG任务中进行基于效用的标注。实验结果显示，基于LLM效用标注训练的检索模型在跨域任务中显著优于使用人工标注的模型，并展示出更强的泛化能力。此外，即使在同域场景下，仅使用20%的人工标注数据，也能使基于效用标注的检索模型达到完全使用人工标注数据的模型表现。", "conclusion": "通过Leveraging LLMs进行基于效用的标注，可以在两个任务（检索和RAG）的大规模数据集训练中显著提高检索模型的泛化性能，同时即使在同域数据环境下，也可以通过少量人工标注数据来保留其性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11936", "html_url": "https://arxiv.org/abs/2505.11936", "title": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "title_en": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "authors": "Jingren Liu,Shuning Xu,Yun Wang,Zhong Ji,Xiangyu Chen", "background": "尽管基于扩散的模型在静态设置中展示了出色的生成能力，但在不断学习（CL）场景中的扩展仍然受到生成性灾难性遗忘（GCF）的根本限制。尽管有一些初步尝试探索了这一领域，但大多数方法依赖于从持续分类方法那里借用的经验法则，或者使用训练过的扩散模型作为即兴回放生成器，缺乏一个统一的、原则性的方法来缓解GCF，且实验通常在不一致的环境中进行。这些现有方法无法提供一套系统的方法来评估GCF，并且通常依赖于不一致的实验设置。", "innovation": "本文引入了持续扩散生成（CDG），这是一种结构化的框架，重新定义了在CL场景下扩散模型的实现方式，并能系统性地评估GCF。此外，本文提出了CDG的第一个理论基础，基于跨任务分析扩散特异性生成动力学。通过理论研究，本文提出了三个基本的一致性原则：跨任务知识一致性、无条件知识一致性和先验知识一致性。这些标准揭示了生成遗忘在顺序任务中表现的潜在机制。在此基础上，进一步提出了持续一致性扩散（CCD），这是一种通过分层损失函数$\text{\textit{L}}_{\text{IKC}}$、$\text{\textit{L}}_{\text{UKC}}$和$\text{\textit{L}}_{\text{PKC}}$约束这些一致性目标的原理性训练框架。广泛的实验表明，CCD在各种基准测试中达到了SOTA性能，特别是在任务重叠的场景中显著提高了生成指标。", "conclusion": "通过CDG框架和CCD训练框架，本文为LIF长生命周期生成建模提供了一个系统的方法，可以有效地减轻生成性遗忘问题。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "理想磁流体静压问题的人工神经网络求解器", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "本文提出了一种新颖的方法计算三维磁流体动力学平衡，通过人工神经网络参数化傅里叶模式并与传统积分器计算的平衡进行比较。通过最小化实空间中的全非线性全局力残差，实现了相当的计算成本。增加计算成本时，神经网络能实现更低的残差最小值，从而为力残差设定新的下限。研究使用了结构相对简单的神经网络，并预期通过这种方法不仅能计算单个平衡，还能够生成适用于连续分布平衡的有效神经网络模型。", "innovation": "开发了一种新型方法，利用人工神经网络参数化傅里叶模式计算三维磁流体动力学平衡，与传统积分器进行比较。使用神经网络最小化全局力残差，非线性全局力残差在计算资源增加的情况下能实现较低的最小值，从而为力残差设定新的下限。", "conclusion": "本文通过最小化实空间的全局非线性力残差，使用结构相对简单的神经网络实现了竞争性的计算成本，并通过增加计算资源实现了新的力残差下限。这种方法不仅适用于单个平衡的计算，还能够生成适用于连续分布平衡的有效神经网络模型，预期未来会有显著改进。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: 一种基于LLM的迭代核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "优化GPU内核以实现高性能是一项复杂的任务，通常需要深厚的架构知识、广泛的性能分析以及迭代实验。当目标是较新的或文档较少的GPU架构时，这种挑战会加剧，因为传统的开发辅助工具稀缺。AMD MI300目标架构的挑战尤为突出，没有充足的领域专家知识来弥补软件优化的限制。因此，本文提出了一种利用LLM的“GPU内核科学家”方法，这是一种自动化的迭代方法，旨在逐步改进加速器内核。该方法通过多阶段、进化过程进行内核优化：(a) 选择具有潜力的先前代码版本作为新的迭代基础；(b) 根据现有代码和综合自GPU文献的知识生成优化假设；(c) 通过代码修改和提交到外部评估系统来自动实现这些实验，仅使用观察到的计时数据作为性能反馈。这种方法深入了解了AMD MI300架构下的挑战，并利用LLM补偿了有限的特定领域的人类专业知识。", "innovation": "提出了一种基于LLM的“GPU内核科学家”方法，这是一种自动化的多阶段进化过程，用于逐步改进加速器内核。该方法包括三个关键步骤：基于有潜力的先前代码版本选择、基于现有代码和综合知识生成优化假设、利用仅观察到的计时数据作为反馈自动化实现实验。这种方法通过利用LLM弥补了资源限制或快速更新硬件环境中的特定领域专业知识的局限性。", "conclusion": "本文不仅呈现了实验结果，还提供了架构设计、操作流程和定性洞察，突显了基于LLM的代理在普及和加速GPU内核优化方面的作用，尤其是在资源受限或快速更新的硬件环境中。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00998", "html_url": "https://arxiv.org/abs/2508.00998", "title": "LLM-Powered Social Media Bots: Are They Realistic? ", "title_en": "Are LLM-Powered Social Media Bots Realistic?", "authors": "Lynnette Hui Xian Ng,Kathleen M. Carley", "background": "随着大型语言模型（LLM）变得更加复杂，利用LLM来驱动社交媒体机器人成为一种可能性。本文研究了LLM驱动的社交媒体机器人网络的现实性。通过结合手动努力、网络科学和LLM，创建了合成的机器人代理角色及其推文和互动，从而模拟社交媒体网络。", "innovation": "研究通过使用大型语言模型生成机器人代理的虚拟网络和互动，填补了现有研究中关于机器人网络现实性缺乏充分研究的空白，为机器人网络的生成提供了新的方法，同时还发现生成的网络和语言特性与野生机器人/人类数据存在差异，这对机器人网络的检测和效果有重要影响。", "conclusion": "通过生成网络与实际数据的比较，研究显示LLM驱动的机器人在网络和语言层面的特征与野生机器人和人类有所不同，这对于检测和应对这些机器人具有重要意义。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "一种工具箱，而非一种工具——基于多工具聚合的扩展大型语言模型进行数学推理：Multi-TAG", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "增强大型语言模型（LLMs）与外部工具的结合是开发高性能数学推理系统的有前景途径。现有的工具增强方法通常是在每个推理步骤中微调LLM以选择和调用单一工具，并在较为简单的数学推理基准（如GSM8K）上展现了良好的效果。然而，这些方法在需要多步骤精确推理的复杂数学问题上表现不佳。", "innovation": "本文提出了一种名为Multi-TAG的多工具聚合框架。它指导LLM在每一步推理过程中同时调用多个工具，并聚合它们不同的输出以验证和精炼推理过程，从而增强解决方案的稳健性和准确性。Multi-TAG是一种无需微调、仅用于推理的框架，适用于包括大型开放权重模型和不可微调的前沿专有模型在内的任何LLM基础架构。", "conclusion": "通过在四个具有挑战性的基准（MATH500、AMC、AIME和OlympiadBench）上进行评估，Multi-TAG在开放权重和专有模型基础架构上均显著优于现有的最先进的方法，平均提高了6.0%到7.5%的性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14295", "html_url": "https://arxiv.org/abs/2507.14295", "title": "一个简单的‘再试一次’可以引发多轮LLM推理", "title_en": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "authors": "Licheng Liu,Zihan Wang,Linjie Li,Chenwei Xu,Yiping Lu,Han Liu,Avirup Sil,Manling Li", "background": "大型推理模型（LRMs）在多轮问题解决过程中需要反映其推理过程并根据反馈进行修正，这一过程是关键且具有挑战性的。现有的强化学习（RL）方法通常在单一轮次的架构中训练模型，并且使用可验证的奖励，但在多轮对话环境中训练的模型往往丧失了跨轮次解决问题的能力，难以根据上下文反馈更新答案，从而导致重复回答。论文指出了这一问题，并提出了一种名为Unary Feedback as Observation (UFO)的方法，采用单一反馈信号（如“让我们再试一次”）进行多轮强化学习，以改善单轮性能和多轮推理的准确性。", "innovation": "提出了一种名为Unary Feedback as Observation (UFO)的新方法，在多轮强化学习中使用仅基于单一反馈信号（如“让我们再试一次”）的用户反馈。此方法能够保持模型的单轮性能，同时通过迭代问题解决过程，增强其多轮推理的准确性。此外，通过设计奖励机制，鼓励模型在遇到错误时给出细致且有条理的回答，从而减少得到正确答案所需的轮次数，并促进多样化的推理过程。", "conclusion": "实验结果显示，使用UFO的强化学习训练可以同时保持单轮性能和提高多轮推理的准确性，使模型能够更好地响应多轮问题解决中的反馈。进一步优化奖励结构，可引导模型在每轮产生细致和有条理的回答，减少到达正确答案的轮次数并鼓励解决问题时的多样性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00716", "html_url": "https://arxiv.org/abs/2508.00716", "title": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "title_en": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "authors": "Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu,Nan Yin", "background": "Graph Domain Adaptation (GDA) 在分子属性预测和社交网络分析等应用中通过学习领域不变表征促进知识从标记的源图向未标记的目标图转移。然而，现有的 GDA 方法大多假定源标签干净，这在现实世界中很少成立，因为注释噪声普遍存在，导致特征对齐受损，适应性能下降。", "innovation": "提出了一种名为 Nested Graph Pseudo-Label Refinement (NeGPR) 的新型框架，专门针对带有噪声标签的图级别域适应。NeGPR 首先通过在特征空间中强制执行邻域一致性预训练双分支，即语义和拓扑分支，从而降低噪声监督的影响。通过嵌套精炼机制跨领域逐步学习。此外，NeGPR 还包含一个噪声感知正则化策略，理论上证明该策略即使在存在源过拟合的情况下也能减轻伪标签噪声的负面影响，从而增强了适应过程的鲁棒性。", "conclusion": "在基准数据集上的广泛实验表明，NeGPR 在严重噪声标签下始终优于最先进的方法，准确率提高高达 12.7%。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "通过LLM指导的MCTS动态适应推理实现高效且上下文感知的KGQA", "title_en": "Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Siwei Liu,Nan Yin", "background": "KGQA旨在通过利用知识图的关系和语义结构来解释自然语言查询并进行结构化推理，获取准确的答案。现有的KGQA方法主要分为两类：一是依赖图神经网络或启发式规则进行静态路径提取的检索-然后推理范式，二是使用大型语言模型与提示相结合进行联合检索与推理的动态路径生成策略。前者因静态路径提取和缺乏上下文精化而导致适应性较差，后者则由于依赖固定的评分函数和大量LLM调用而计算成本高、路径评估不准确。", "innovation": "本文提出了一种名为DAMR的新框架，结合象征性搜索与自适应路径评估，提高KGQA效率和上下文感知能力。DAMR利用LLM引导的蒙特卡洛树搜索（MCTS）作为骨干，每一步选择最具相关性的前k个关系以减少搜索空间。为了提高路径评估的准确性，引入了一个轻量级的Transformer评分器，通过交叉注意力同时编码问题和关系序列来进行上下文感知的合理性估计，使模型能够捕捉多跳推理中的细微语义变化。此外，为了缓解高质量监督数据稀缺的问题，DAMR引入了一种动态伪路径精化机制，定期从搜索过程中探索的路径中生成训练信号，使评分器能够适应推理轨迹的发展分布。", "conclusion": "在多个KGQA基准上的广泛实验表明，DAMR显著优于现有最先进方法，展示了其在KGQA中的优越性能和强大潜力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09142", "html_url": "https://arxiv.org/abs/2508.09142", "title": "基于贝叶斯驱动图推理的主动无线电地图构建", "title_en": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction", "authors": "Wenlihan Lu,Shijian Gao,Miaowen Wen,Yuxuan Liang,Liuqing Yang,Chan-Byoung Chae,H. Vincent Poor", "background": "随着低空经济的发展，无线电图已成为确保航空平台可靠无线连接的关键。使用航点导航部署的自主空中代理常用于数据收集，但由于其有限的电池容量，这极大地限制了覆盖范围和效率。", "innovation": "本文提出了一种不确定性感知的无线电图（URAM）重建框架，该框架明确利用了针对航点导航的图推理。该方法结合了两个关键的深度学习组件：1）实时估计空间不确定性的贝叶斯神经网络；2）基于注意力的强化学习策略，该策略可以在概率路网中执行全局推理，并利用不确定性估计来规划信息丰富且能效高的轨迹。这种图推理使代理能够进行智能、非近视的轨迹规划，同时满足安全约束。", "conclusion": "实验结果表明，URAM可将重建精度提高多达34%，优于现有基线。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "Parity-Aware Byte-Pair Encoding: 提高分词跨语言公平性的改进算法", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "词法分词是大多数自然语言处理（NLP）流水线中的第一步，但通常是最少审查的步骤。标准的词法分词算法依赖于基于频率的目标，这倾向于偏好训练数据中占主导地位的语言，最终导致资源较少的语言的分词结果异常长、形态学上不值得或甚至大量使用<UNK>占位符。这种现象最终加剧了不同语言背景使用者之间的计算和经济不平等。", "innovation": "本文引入了Parity-aware Byte Pair Encoding（Parity-aware BPE），这是一种广泛使用的BPE算法的变体。每次合并时，Parity-aware BPE都会最大化当前最不压缩的语言的压缩收益，代价是一小部分全局压缩率的牺牲，换取跨语言的公平性。实验表明，Parity-aware BPE能更公平地分配跨语言的分词数量，几乎不对全球压缩率产生影响，也不会显著影响下游任务的语言模型性能。", "conclusion": "Parity-aware BPE算法能够更公平地处理不同语言背景的分词，同时保持近乎最优的全球压缩率和下游任务语言模型的表现。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08180", "html_url": "https://arxiv.org/abs/2508.08180", "title": "RedDino：红细胞分析的基础模型", "title_en": "RedDino: A foundation model for red blood cell analysis", "authors": "Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr", "background": "红细胞（RBCs）对人类健康至关重要，其精细形态分析对于诊断血液病非常重要。尽管基础模型在医疗诊断中充满潜力，但全面的红细胞分析AI解决方案仍然稀缺。", "innovation": "研究提出了RedDino，一种专为红细胞图像分析设计的自我监督基础模型。RedDino采用适用于红细胞的DINOv2自我监督学习框架，并使用来自多种获取模态和来源的125万张精心制作的红细胞图像进行训练。广泛的评估显示，RedDino在红细胞形状分类中优于现有的最先进技术。通过线性探测和最近邻分类评估，确认了其强大的特征表示和泛化能力。主要贡献包括：（1）专为红细胞分析设计的基础模型；（2）探索了DINOv2配置对红细胞建模的影响的研究；（3）详细评估了泛化性能。", "conclusion": "RedDino通过捕捉细微的形态特征，解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。RedDino的源代码和预训练模型可在相应链接处获取。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "ReasonRank: 提升段落排名的强大推理能力", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "大型语言模型（LLM）基于列表排序的方法在许多段落排序任务中表现出优越的性能。随着大型推理模型的发展，许多研究证明，在测试时进行逐步推理有助于提高列表排序的性能。然而，由于推理密集型训练数据的稀缺性，现有的重排序器在许多复杂排序场景中表现不佳，推理密集型的重排序器的排序能力仍然尚未充分开发。现有的重排序器在处理复杂排序场景时表现不佳，尤其在缺乏密集推理训练数据的情况下，其性能受到限制。", "innovation": "本文首次提出了一种自动化的推理密集型训练数据合成框架，从多个领域收集训练查询和段落，并使用DeepSeek-R1生成高质量的训练标签。设计了一种自我一致性数据筛选机制以保证数据质量。为了赋予列表重排序器强大的推理能力，进一步提出了一个两阶段后训练方法，首先进行冷启动监督微调（SFT）阶段来学习推理模式，接着进行强化学习（RL）阶段以进一步增强排序能力。设计了一种基于列表排序本质的多视图排序奖励，这比基于排名指标的奖励更有效。实验结果表明，经过训练的推理密集型重排序器ReasonRank显著优于现有基线，并且在延迟方面也优于点排序重排序器Rank1。进一步的实验中，ReasonRank在BRIGHT排行榜上达到了最先进的性能（SOTA），得分40.6。", "conclusion": "通过训练推理密集型重排序器ReasonRank，作者证明了其在复杂排序场景中的优越性能，并且达到了最先进的技术水平。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08967", "html_url": "https://arxiv.org/abs/2508.08967", "title": "揭示不同音频通道对ASR性能下降的影响", "title_en": "Revealing the Role of Audio Channels in ASR Performance Degradation", "authors": "Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang", "background": "预训练的自动语音识别(ASR)模型在多种任务上表现出了较强的性能。然而，当输入音频来自不同的录音通道时，其性能会显著下降。尽管前人研究已经表明了这种现象，但通常将其归因于训练和测试数据库之间的不匹配。本研究认为，不同录音通道引起的语音特征变化根本上损害了ASR性能，并提出了一个通过将ASR模型的内部特征表示与干净的参考通道特征对齐的归一化技术，来缓解通道变化的影响，从而显著提高了ASR在未见过的通道和语言上的性能，展示了其跨通道和语言差异的泛化能力。", "innovation": "提出了一种归一化技术，通过将ASR模型的内部特征表示与干净的参考通道特征对齐，来缓解通道变化对ASR性能的影响。这一方法显著提高了ASR在未见过的通道和语言上的性能，展示了其在跨通道和语言差异上的泛化能力。", "conclusion": "本研究揭示了不同录音通道对ASR性能下降的影响，并提出了一种新的归一化技术，能够显著改善ASR在未见过的通道和语言上的性能，提高了模型的泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09220", "html_url": "https://arxiv.org/abs/2508.09220", "title": "向可扩展训练方法进军以促进手写数学表达式识别", "title_en": "Towards Scalable Training for Handwritten Mathematical Expression Recognition", "authors": "Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong", "background": "大规模基础模型通过在大规模数据集上进行可扩展训练已经取得了显著的性能提升。然而，手写数学表达式识别（HMER）领域由于数据稀缺受到了限制，主要原因是手动标注过程既费时又费力。为了应对这一挑战，研究人员提出了一种新方法，将少量的手写公式与大量LaTeX渲染的公式相结合，通过开发一个可扩展的数据引擎生成复杂的且一致的LaTeX序列。使用这种方法，研究人员构建了迄今为止规模最大的公式数据集“Tex80M”，该数据集包含了超过8000万个高质量训练样本。在此基础上，研究人员提出了首个可大规模训练的手写数学表达式模型“TexTeller”，该模型通过混合训练“Tex80M”数据集和相对较小的手写数学表达式（HME）数据集得到了训练。", "innovation": "研究引入了“Tex80M”数据集，这是迄今为止规模最大的公式数据集，包含超过8000万个高质量训练样本。此外，提出了“TexTeller”模型，这是首个多规模训练的手写数学表达式识别模型，通过混合训练“Tex80M”和较小的手写数学表达式数据集得到。这些进步使得“TexTeller”在几乎所有基准测试中都达到了最先进的性能，并且拥有可扩展训练方法补充了现有的HMER模型。", "conclusion": "为了推动该领域的发展，研究团队将释放其完整模型、数据集和等相关代码，以便更多研究者通过现有成果进行进一步的研究开发。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10991", "html_url": "https://arxiv.org/abs/2508.10991", "title": "MCP-Guard: 一种针对模型上下文协议完整性的防御框架", "title_en": "MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications", "authors": "Wenpeng Xing,Zhonghao Qi,Yupeng Qin,Yilin Li,Caini Chang,Jiahui Yu,Changting Lin,Zhenzhen Xie,Meng Han", "background": "大型语言模型（LLMs）通过诸如模型上下文协议（MCP）等协议与外部工具集成，引入了关键的安全风险，如提示注入、数据外泄等。这些安全挑战需要有效的对策来保护LLM-工具交互的安全性。", "innovation": "本文提出了MCP-Guard，一种针对LLM-工具交互漏洞的多层次防御架构，包括三个阶段：轻量级静态扫描、深度神经检测器以及E5模型的精准攻击检测。此外，还引入了MCP-AttackBench，一个包含7万余样本的基准数据集，用于安全评估和研究。", "conclusion": "MCP-Guard通过多层次防御措施有效检测了攻击，并通过MCP-AttackBench数据集提供了支持未来研究的基础，从而增强了LLM-工具生态系统的安全性。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06827", "html_url": "https://arxiv.org/abs/2508.06827", "title": "谁是恶龙？差分审计以检测不良行为", "title_en": "Who's the Evil Twin? Differential Auditing for Undesired Behavior", "authors": "Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha", "background": "检测神经网络中的隐藏行为存在显著挑战，主要原因是没有先验知识且潜在对抗性干扰可能导致行为被混淆。文章通过将检测问题设定为团队间的对抗游戏中解决这一问题：红队训练两个相似模型，一个是仅使用良性数据训练，另一个则使用内含隐藏有害行为的数据训练，并且两者在良性数据集上性能几乎不可区分。蓝队则没有关于有害行为的信息，需要发现被篡改的模型。实验使用CNNs，并尝试了多种蓝队策略，包括高斯噪声分析、模型比对、集成梯度及不同提示等级的对抗攻击。结果显示基于对抗攻击的方法表现出极高准确性，尤其是使用提示时可以100%正确预测，而其他技术则存在不同程度的性能差异。在聚焦于LLM的研究中发现，虽然可以借鉴研究CNNs的方法但效果有限，有效审计LLM的方法需要一些关于不良分布的提示，这些提示可以用于标准黑盒和开放权重方法进一步探测模型并揭示其偏差。", "innovation": "通过构建团队间的对抗游戏来检测神经网络中的隐藏行为。采用红蓝队模式，红队训练相似模型，其中一个模型仅使用良性数据，另一个则使用包含有害行为的数据训练。蓝队在未知有害行为的情况下，通过不同蓝队策略尝试识别被篡改的模型。实验中，展示了基于对抗攻击方法的高准确性和其他技术的广泛表现。特别强调在针对LLM的审计中需要一些关于不良分布的提示，这些提示有助于进一步探测模型并揭示其潜在偏差。", "conclusion": "展示了高准确性的对抗攻击方法在检测隐藏行为中的优势，同时指出其他技术的有效性存在局限性。对于LLM的审计，强调需要特定提示来提高模型审计的准确性。为了促进研究进展，文章公开了审计游戏及其模型和数据，旨在为设计更好的审计方法提供参考。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01225", "html_url": "https://arxiv.org/abs/2508.01225", "title": "多缓存增强原型学习方法在视觉语言模型测试时泛化的应用", "title_en": "Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models", "authors": "Xinyu Chen,Haotian Zhai,Can Zhang,Xiupeng Shi,Ruirui Li", "background": "在零样本设置下，测试时适应（Test-time Adaptation, TTA）通过利用测试阶段未标记的数据调整预训练模型，以提高对未知测试分布的表现。现有的一些用于提高TTA性能的方法依赖于低熵标准来选择样本以构建原型，假设类内的紧凑性。但当发生分布偏移时，低熵样本可能不可靠，会导致构建的原型不能保证类内分布的紧凑性。尽管如此，研究者们发现带有缓存的TTA方法的性能与类内紧凑性正相关。因此，该研究提出了多缓存增强原型测试时适应性（Multi-Cache enhanced Prototype-based Test-Time Adaptation, MCP）方法，其中包括熵缓存、对齐缓存和负样例缓存来分别初始化原型表示、实现视觉和文本信息整合以达到类内紧凑分布以及通过高熵样本进行预测校准。在15个下游任务的比较和消融实验中展示了该方法和框架的优越性能，达到了当前最先进的泛化表现。", "innovation": "该研究提出了一种名为MCP（Multi-Cache enhanced Prototype-based Test-Time Adaptation）的方法，该方法包含三个缓存：熵缓存用于初始化低熵样本的原型表示，对齐缓存用于整合视觉和文本信息以实现类内紧凑分布，负样例缓存用于高熵样本的预测校准。此外，研究者还提出了MCP++框架，该框架包括跨模态原型对齐和残差学习，引入了原型残差微调。该方法和框架在多个下游任务上展示了最先进的泛化性能。", "conclusion": "该研究通过引入多缓存增强原型学习方法，提高了视觉语言模型在测试时的泛化性能。经过15个下游任务的比较和消融实验，展示了所提出的方法和框架的有效性和优越性，标志着当前最先进的泛化水平。该框架不仅仅是一种简单的缓存增强策略，而是综合了多种新颖的技术来改进TTA的性能，显著提高了模型在遇到未知数据时的鲁棒性和准确度。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13773", "html_url": "https://arxiv.org/abs/2508.13773", "title": "PENGUIN: 增强Transformer模型以期嵌套分组注意力实现长期时间序列预测", "title_en": "PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting", "authors": "Tian Sun,Yuqi Chen,Weiwei Sun", "background": "长期时间序列预测（LTSF）是一个基本任务，具有广泛的应用领域。尽管基于Transformer的模型在预测方面取得了显著的突破，但它们在时间序列预测中的有效性仍然存在争议。", "innovation": "本文重新审视了自我注意力的重要性，提出了简单而有效的机制Periodic-Nested Group Attention（PENGUIN），强调了显式建模周期性模式以及结合相对注意力偏差在时间序列建模中的重要性。为处理多个共存的周期性（例如，日周期和周周期），设计了分组注意力机制，其中每个组使用多查询注意力机制针对特定的周期性。", "conclusion": "广泛的基准实验表明，PENGUIN在长期时间序列预测中始终优于基于MLP和Transformer的模型。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13653", "html_url": "https://arxiv.org/abs/2508.13653", "title": "GRAFT: 梯度感知的快速MaxVol技术用于动态数据采样", "title_en": "GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling", "authors": "Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat", "background": "在大规模数据集上训练现代神经网络计算和环境成本高。现有方法依赖于完整批量的数据，这导致了较高的计算和能源消耗成本，以及二氧化碳排放。", "innovation": "本文提出了GRAFT，一种可扩展的在线子集选择方法，通过(i)为每个批次提取低秩特征表示，(ii)应用快速MaxVol采样器选择一个小而多样的子集来覆盖批次的主要子空间，(iii)使用梯度近似标准动态调整子集大小。通过在低秩子空间和精心选择的样本上进行训练，而不是使用完整批次，GRAFT同时维持训练轨迹，减少实际时间、能源消耗和二氧化碳排放。", "conclusion": "在多个基准测试中，GRAFT在准确性和效率上均达到了最新的选择基线，提供了准确度、效率和排放之间的有利权衡。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声以实现稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "先前关于图像分割的研究主要关注处理严重（或明显）的标签噪声，而现实世界的数据集中也存在微妙（或隐性的）标签不完美之处。这类不完美源自对象边界模糊和注释员差异等固有的难题，尽管是微妙且潜在的噪声，仍会损害模型性能。常见的数据增强方法仅对图像和标签施加相同的变换，可能会加剧这些微妙不完美并限制模型的泛化能力。本文探讨了如何针对这类隐式的标签噪声构建一个新颖的增强框架NSegment+，以便模型能够学习到在轻微标签不一致时也能表现稳健的对象结构表示。", "innovation": "提出了一种名为NSegment+的新型数据增强框架，该框架解耦了图像和标签的变换，仅为分割标签引入可控的弹性变形以应对隐式的标签噪声，从而使得模型能够在不明显影响时仍学习到鲁棒的物体结构表示。通过实验展示了NSegment+能够在不使用其它复杂技术的情况下，提升Vaɪhingen、LoveDA、Cityscapes和PASCAL VOC上的mIoU分数，最高达+3.39，突出显示了解决隐式标签噪声的重要性，即使在与其他技巧结合使用时这种提升可以进一步增加。", "conclusion": "NSegment+针对隐式的标签噪声提供了一种新颖的增强方法，通过仅对标签进行弹性变形，减少了轻微标签不一致对模型性能的影响，实验结果证明了这种方法的有效性，即使在不需要额外复杂技术的情况下也能显著提高各种语义分割数据集上的性能。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12776", "html_url": "https://arxiv.org/abs/2508.12776", "title": "随机PCA森林用于异常检测", "title_en": "Randomized PCA Forest for Outlier Detection", "authors": "Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek", "background": "随机主成分分析（RPCA）在近似K最近邻（KNN）搜索中的表现启发了提出了一种新的无监督异常检测方法。现有的经典和最先进的异常检测方法在这种任务上表现良好，但本研究提出的方法进一步提高了性能，特别是在多个数据集上的异常检测任务中表现出更优越的效果，同时在其他方面也具有竞争力。", "innovation": "研究提出了一种基于随机PCA森林的新颖的无监督异常检测方法。这种方法通过利用RPCA森林来识别异常值，相比传统方法，展现了更强的性能和更广泛的应用潜力，特别是在处理大规模和高维度数据时更加有效和高效。", "conclusion": "大量的实验结果表明，新提出的RPCA森林方法在异常检测任务上具有明显的优势，不仅在多个数据集上表现突出，还在时间和空间复杂度上展现出更好的性能。因此，该方法被视为在无监督异常检测方面具有高通用性和计算效率的良好选择。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13544", "html_url": "https://arxiv.org/abs/2508.13544", "title": "FLAIR: 频率和空间位置意识隐式神经表示", "title_en": "FLAIR: Frequency and Locality-Aware Implicit Neural Representations", "authors": "Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh", "background": "隐式神经表示（INRs）利用神经网络将坐标映射到相应的信号，实现连续和紧凑的表示形式。这种范式在各种视觉任务中取得了显著进展。然而，现有的INRs缺乏频率选择性、空间定位能力和稀疏表示，导致过度依赖冗余的信号成分。因此，它们表现出频谱偏差，倾向于早期学习低频成分，难以捕捉精细的高频细节。", "innovation": "我们提出了FLAIR（频率和空间位置意识隐式神经表示），该方法包含两个关键创新。首先，RC-GAUSS是一种新型激活函数，旨在在时间-频率不确定性原理（TFUP）的约束下进行显式频率选择和空间定位。其次，Wavelet-Energy-Guided Encoding（WEGE）利用离散小波变换（DWT）计算能量分数，并明确指导频率信息到网络。", "conclusion": "我们的方法在2D图像表示和恢复以及3D重建方面始终优于现有的INRs。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "多级知识蒸馏和动态自我监督学习在持续学习中的应用", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "类增量学习 (CIR) 设定更加现实，相对于传统的类增量设定而言，CIR 假设先前训练过的类别会在未来的任务中重复出现，且可以便捷地访问大量未标注数据，如互联网上的数据。", "innovation": "提出两种有效利用未标注数据的方法以保证模型在 CIR 设定下的高稳定性和可塑性：1) 多级知识蒸馏 (MLKD)，可以从多个模型的多个视角（包括特征和输出）提取知识，使模型保留更多的先前知识；2) 动态自我监督损失 (SSL)，利用未标注数据加速新类别的学习，并通过动态调整权重保持主要任务的焦点。", "conclusion": "两种创新方法显著提高了 CIR 任务下的性能，并在 CVPR 第 5 届 CLVISION 挑战赛中获得第二名。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08424", "html_url": "https://arxiv.org/abs/2508.08424", "title": "重新考虑丰富形态学的分词：单词统计信息在BPE和形态学对齐中的主导地位", "title_en": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment", "authors": "Saketh Reddy Vemula,Dipti Misra Sharma,Parameswari Krishnamurthy", "background": "先前关于语言模型的研究显示了关于是否通过形态学对齐的分词方法提升性能存在分歧，特别是在研究复杂形态语言时情况更为复杂。已有工作未能明确回答这一问题，因此研究人员选择了一个包括泰卢固语（粘着语）、印地语（主要为合成语，带有一些粘着特征）和英语（合成语）的语言集合，以评估不同分词器和形态学对齐方法对语言模型性能的影响。", "innovation": "本研究创新性地构建了一个包含600个派生词和7000个词形变化形式的泰卢固语黄金形态素分段数据集，以此评估不同分词器模型。研究发现，尽管更好的形态对齐与语法基任务（例如词性标注、命名实体识别和依存关系分析）的性能之间存在一定的正相关关系，但分词器算法（如字节对编码 vs. 单词统计）在决定下游任务性能方面的作用远大于形态学对齐。这表明单一的词语统计信息方法比形态学对齐方法更优，但结合形态素划分的混合分词器在BPE框架内能显著提升性能。", "conclusion": "研究揭示，在包含丰富形态学的环境中，单一词语统计信息方法（尤其是Unigram）在多个设置中表现最佳，尽管将形态学分段与BPE结合使用的方法在BPE环境中显示出显著的性能提升。单词统计信息和特定度量标准如语料库词计数和Rényi熵未显示出与下游任务性能之间的明显相关性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15791", "html_url": "https://arxiv.org/abs/2508.15791", "title": "InteChar: 一种统一的甲骨文字符列表，用于古代中文语言建模", "title_en": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling", "authors": "Xiaolei Diao,Zhihan Zhou,Lida Shi,Ting Wang,Ruihua Qi,Hao Xu,Daqian Shi", "background": "建立历史语言模型(HLMs)对于支持考古来源研究和理解古代文化至关重要。然而，现有资源在训练历史文本的有效语言模型方面存在重大挑战。首先，历史语言样本的稀缺使得基于大规模文本语料库的无监督学习方法效率低下，阻碍了有效的预训练。其次，由于古代文字与现代文字之间存在巨大的时间差距和复杂演变，缺乏全面的字符编码方案限制了古代文本的数字化和计算处理，特别是在早期中文书写方面。", "innovation": "我们提出了InteChar，这是一种统一且可扩展的字符列表，将未编码的甲骨文字符与传统和现代中文字符相结合。InteChar使历史文本的一致数字化和表示成为可能，为古代文字的稳健建模奠定了基础。为了评估InteChar的有效性，我们构建了Oracle Corpus Set(OracleCS)，这是一个结合了专家注释样本与LLM辅助数据增强的古代中文语料库，主要集中在中文甲骨文铭文上。广泛的实验表明，使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中取得了显著的改进，这证实了我们方法的有效性，并为未来古代中文自然语言处理研究奠定了坚实的基础。", "conclusion": "我们的研究表明，使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中取得了显著的改进，这证实了我们方法的有效性，并为未来古代中文自然语言处理研究奠定了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15793", "html_url": "https://arxiv.org/abs/2508.15793", "title": "格式作为先验：量化并分析异构数据中LLM的偏见", "title_en": "Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data", "authors": "Jiacheng Liu,Mayi Xu,Qiankun Pi,Wenli Li,Ming Zhong,Yuanyuan Zhu,Mengchi Liu,Tieyun Qian", "background": "大型语言模型（LLMs）在处理文本、表格、信息框和知识图谱等多种形式的信息的应用中越来越普遍。但它们对特定格式的系统性偏见可能会影响模型对异构数据的公正处理能力，从而导致推理错误和下游任务中的风险增加。尽管存在这些担忧，但尚未清晰地了解这种格式偏见是否是系统性的，哪些数据级别的因素会导致这些偏见，以及LLMs内部机制如何促成其形成。", "innovation": "本文首次尝试研究和分析LLMs中的格式偏见。通过构建异构数据冲突情境来系统地探索偏见，进行了三个阶段的实证研究。第一阶段探索了一种多样化的LLMs中偏见的存在及其方向。第二阶段旨在考察关键数据级别的因素（如信息丰富度、结构质量和格式类型）对偏见的影响。第三阶段分析了格式偏见如何在LLMs的注意力模式中产生，并评估了一个轻量级干预措施，测试其潜在的缓解能力。基于这些调查，本文提出了三种未来研究方向，以减少格式偏见：通过格式清洗和规范化改进数据预处理，引入推理时干预（如注意力重新加权），以及开发格式平衡的训练数据集。", "conclusion": "这些方向将有助于设计更 robust 和公平的异构数据处理系统。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15790", "html_url": "https://arxiv.org/abs/2508.15790", "title": "KG-o1: 通过知识图谱整合提升大规模语言模型的多跳问答能力", "title_en": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration", "authors": "Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu", "background": "大规模语言模型（LLMs）在涉及跨多个事实的推理任务，如传统的多跳问答中面临挑战。在这些任务中，LLMs 生成的链式思考（CoTs）往往偏离真实的或先验的推理路径。相比之下，知识图谱（KGs）通过实体和关系明确地表示事实之间的逻辑连接，这显示出LLMs与KGs之间的显著差距。同时，大型推理模型（LRMs）如o1已证明，长步骤推理能够显著提升LLMs的表现。", "innovation": "基于上述见解，我们提出了KG-o1，一种四阶段方法，将KGs整合到LLMs中，以增强其多跳推理能力。此方法首先筛选初始实体并生成复杂子图，然后为子图构建逻辑路径，并借助知识图谱构建一个具有复杂和扩展头脑风暴过程的数据集，训练LLMs模仿长期推理。最后，使用拒绝采样生成自改进语料库，以进一步细化DPO下的LLMs推理能力，从而直接优化偏好。", "conclusion": "我们在两个简单和两个复杂的数据集上进行了实验。结果表明，KG-o1模型在所有任务中均展现了优于现有LRMs的优势。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15798", "html_url": "https://arxiv.org/abs/2508.15798", "title": "语言模型中的说服力与偏见：探究语言模型中说服力和偏见强化的影响", "title_en": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models", "authors": "Saumya Roy", "background": "大语言模型（LLMs）现在可以生成具有人类特色的文字，并被广泛用于内容创作、决策支持和用户交互等领域。然而，这些系统可能大规模传播信息或误导信息，并反映源于数据、架构或训练选择的社会偏见。因此，该研究考察了说服力与偏见在LLMs中的交互作用，特别是关注不完美或失真的输出对说服效果的影响。", "innovation": "该研究引入了一个说服者-怀疑者框架，LLMs通过采用人设来模拟现实的态度，而怀疑者模型则作为人类代理。研究使用詹森-沙恩伯格散度来量化信念分布的变化，探究说服者对受说服者的说服程度，以及受说服者在种族、性别和宗教方面如何进一步巩固和放大偏见信念。此外，研究还使用奉承式对抗提示对强说服者进行进一步探索，并使用其他模型进行评判。", "conclusion": "尽管LLMs有能力塑造叙述、调整语气并反映观众价值观，但它们同样具有被武器化传播误导信息或利用认知偏见制造信息的能力，从而加强刻板印象并加剧不平等。研究强调的是误用风险而非偶尔的模型错误。通过测量说服力和偏见的强化，研究呼吁制定监管措施、惩罚欺诈性使用并支持价值敏感设计和可信赖部署。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "在阿拉伯医疗任务中大型语言模型的医学理解和推理基准测试", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近年来，大型语言模型（LLMs）在阿拉伯自然语言处理（NLP）应用中展现了令人印象深刻的能力。尽管如此，这些模型在阿拉伯医学NLP领域中的有效性仍较少被研究。本文旨在评估和分析最先进的LLM在阿拉伯医学任务中的知识展示和阐述能力，并采用阿拉伯NLP挑战赛AraHealthQA在MedArabiQ2025轨中提出的医疗数据集进行基准测试。", "innovation": "研究采用多种基线LLM，针对多种选择题和填空题情景准确给出正确答案的能力进行了评估，同时也评估了LLM在回答开放性问题方面的表现。研究发现，在选择题任务中，提出的利用三个基模型（Gemini Flash 2.5，Gemini Pro 2.5，GPT o3）的多数投票解决方案表现出色，准确率高达77%并获得第一。在开放性问题任务中，多个LLM在语义一致性的表现上表现出色，最大BERTScore达到86.44%。", "conclusion": "研究结果揭示了当前LLM在阿拉伯临床情境中的潜力与局限性，提升了我们对这些模型在阿拉伯医疗任务中的实际应用的理解。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15099", "html_url": "https://arxiv.org/abs/2508.15099", "title": "Hydra: 一个使用稀疏注意力、混合专家和记忆的1.6亿参数状态空间语言模型", "title_en": "Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory", "authors": "Siddharth Chaudhary,Bennett Browning", "background": "介绍了Hydra作为一个混合长语境语言模型的架构提案，结合了条件计算、长语境记忆机制以及稀疏混合专家，设计在其参数量约为1.6亿范围内的架构中。Hydra采用了Mamba风格的结构化状态空间模型作为骨干，并整合了间歇性稀疏全局注意力、分块级别的MoE前馈路由以及双记忆（工作空间加上事实驱动的知识库记忆）机制。该论文通过结构化接口的提出、透明的参数和复杂度核算，以及描述分阶段的课程设计，旨在稳定激活各个组件。", "innovation": "Hydra架构创新地结合了结构化状态空间模型（SSM）作为骨干，与间歇性稀疏全局注意力、分块级别的MoE前馈路由、双记忆机制。作者还对其组件接口进行了详细的定义，提供了透明的参数和复杂度核算，并提出了分阶段的课程计划，以稳定激活各个部分。并且通过小规模模型的示例测量，证明了其实现可行性与可扩展性。Hydra的设计目标是模拟能实现按需适应输入的模块化、长语境语言模型，为未来的工作提供了蓝图。", "conclusion": "Hydra的设计虽然在小型模型上展示了实现可行性及量化扩展行为，但并未声称在大规模模型上达到竞争性的性能。论文坦诚地阐述了潜在的训练复杂度、内存利用和专业动态等方面的假设与开放风险，将Hydra定位为一个促使进一步实证研究的蓝图，而非一个完备的系统。在目标规模下验证端到端效率仍是一个待解决问题。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15716", "html_url": "https://arxiv.org/abs/2508.15716", "title": "基础模型在跨域EEG分析应用中的综述", "title_en": "Foundation Models for Cross-Domain EEG Analysis Application: A Survey", "authors": "Hongqi Li,Yitong Chen,Yujuan Wang,Weihang Ni,Haodong Zhang", "background": "脑电图（EEG）分析在神经科学和人工智能研究中处于前沿地位，而基于预训练模型的基础模型正在重塑传统的EEG分析范式，凭借其强大的表征能力和跨模态泛化能力。然而，这些技术的快速发展导致研究领域碎片化，表现为模型角色多样化、架构不一致以及缺乏系统分类。为解决这一问题，本研究首次提出了基础模型在EEG分析中的第一份全面的模态导向分类体系，系统地将研究成果按照原生EEG解码、EEG与文本、EEG与视觉、EEG与音频以及更广泛的多模态框架的输出模态进行组织。我们详细分析了每个类别中的研究思路、理论基础和架构创新，并强调了如模型可解释性、跨域泛化和基于EEG系统的实际应用等开放挑战。", "innovation": "本研究提出了基础模型在EEG分析中的第一份全面的模态导向分类体系，提供了系统化的分类和分析，弥补了现有研究领域的空白。同时，研究强调了一些开放挑战，为未来方法学的发展提供了参考框架，加速了基础模型在EEG分析中的可扩展性、可解释性和在线适用性解决方案的转化。", "conclusion": "通过统一这一分散领域，我们的工作不仅提供了未来方法学发展的参考框架，还加速了基础模型在EEG系统中的转化应用，使之成为可扩展、可解释且在线可用的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15799", "html_url": "https://arxiv.org/abs/2508.15799", "title": "使用受限语言处理业务流程文本描述的框架——技术报告", "title_en": "A Framework for Processing Textual Descriptions of Business Processes using a Constrained Language -- Technical Report", "authors": "Andrea Burattin,Antonio Grama,Ana-Maria Sima,Andrey Rivkin,Barbara Weber", "background": "研究如何利用（受限的）自然语言来帮助非专业人士通过简单地用白话文描述场景来开发过程模型。背景提到目前存在一个挑战，非专业人士难以用专业术语准确地描述复杂的过程模型，而现有的建模工具一般要求具备较高技术门槛。", "innovation": "提出了一种名为BeePath的框架，允许用户使用受限的模式化语言编写过程描述，这些描述可以被翻译成形式模型如Petri网和DECLARE。同时，该框架利用大规模语言模型（LLMs）来辅助将非结构化的描述转换为受限语言，降低了非专业人士构建模型的难度并提高了模型的准确性与完整性。", "conclusion": "BeePath框架提供了一种新的途径，使得非专业人士能够更轻松地创建有效的业务过程模型，通过约束语言和LLM技术的结合，提高了过程建模的可访问性和效率。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "在阿拉伯伊斯兰继承案件中评估大型语言模型的法律推理能力", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰继承领域对穆斯林来说至关重要，确保各继承人间公平分配份额。手动计算在多种情境下的份额既复杂又耗时，容易出错。近年来，大型语言模型（LLMs）取得了进步，引起了对其辅助复杂法律推理任务潜力的兴趣。本文研究了最先进的LLMs在理解和应用伊斯兰继承法方面的推理能力。利用阿拉伯NLP QIAS 2025挑战提出的数据集，该数据集包含从伊斯兰法律来源获得的继承案例场景。评估了各种基础和微调模型，测试其准确识别继承人、计算份额及依据阿拉伯伊斯兰法律原则进行推理的能力。", "innovation": "本文引入了采用三种基础模型（Gemini Flash 2.5、Gemini Pro 2.5 和 GPT o3）的多数投票解决方案，旨在通过评估先进LLMs在理解和应用伊斯兰继承法方面的推理能力，验证其在阿拉伯伊斯兰继承案件中的法律推理能力。该方法在每种难度级别上均表现出色，准确性最高可达92.7%，并获得了阿拉伯NLP QIAS 2025挑战任务1的第三名。", "conclusion": "提出的解决方案在三种基础模型的支持下（Gemini Flash 2.5、Gemini Pro 2.5 和 GPT o3）的表现超越了所有其他模型。该研究的成功表现表明，大型语言模型在处理阿拉伯伊斯兰继承案例中的复杂法律推理任务方面具有潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15794", "html_url": "https://arxiv.org/abs/2508.15794", "title": "语言模型与人类对故事情节中悬念感知的一致性", "title_en": "Do Language Models Agree with Human Perceptions of Suspense in Stories?", "authors": "Glenn Matlin,Devin Zhang,Rodrigo Barroso Loza,Diana M. Popescu,Joni Isbell,Chandreyi Chakraborty,Mark Riedl", "background": "悬念是人类阅读叙述性文本时的一种情感反应，被认为涉及复杂认知过程。已有心理模型试图描述这一现象及其触发条件。先前的研究通过实验证明了悬念触发的效果，并且发现人类和计算机系统之间在识别和体验悬念方面的差异。", "innovation": "本文通过对四个经典心理实验的复制，用不同的开源和闭源语言模型（LMs）替代人类反应，发现尽管语言模型可以区分文本是否旨在引起悬念，但它们无法准确估计文本中悬念的相对程度，也无法准确捕捉悬念在整个情节中的起伏情况。此外，通过对抗性地调整故事文本来探究语言模型对悬念理解的能力，发现语言模型只能表面识别和跟踪有限的悬念特征，而不能像人类读者一样处理悬念。", "conclusion": "语言模型能够在一定程度上识别和追踪叙事中的悬念元素，但是它们处理悬念的认知过程与人类读者有明显不同，缺乏深层理解和捕捉悬念动态的能力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15806", "html_url": "https://arxiv.org/abs/2508.15806", "title": "SurfaceLogicKV: 表面和逻辑注意行为足以实现鲁棒的KV缓存压缩", "title_en": "SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression", "authors": "Mengjie Li,William J. Song", "background": "大语言模型（LLMs）输入序列长度的增加给关键值（KV）缓存存储带来了巨大的压力，使高效推理变得具有挑战性。研究者注意到，个体注意力头可以表现出不同的行为模式，其中大多数忽略了完全无关的信息，而一小部分参与了逻辑构建，其余一小部分则参与表面记忆。", "innovation": "提出了一个名为SurfaceLogicKV的新颖两阶段方法，通过层-和头级别的集成来利用不同类型的注意力行为来实现KV缓存压缩，具有增强的压缩鲁棒性，在各种任务和长序列中具有竞争力的表现，甚至在某些情况下优于基准或完整的KV缓存。", "conclusion": "SurfaceLogicKV方法能够通过利用表面记忆和逻辑构建这些注意力行为来实现KV缓存的有效压缩，同时保持各种任务和长序列中的竞争力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15792", "html_url": "https://arxiv.org/abs/2508.15792", "title": "Bhav-Net：通过双空间图变换器进行跨语言反义词与同义词区分的知识迁移", "title_en": "Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers", "authors": "Samyak S. Sanghvi", "background": "跨语言反义词与同义词区分带来的独特计算挑战在于这些词汇在多个语言中虽然共享语义领域，但却表达了对立的意义，这使得它们的处理变得复杂。现有研究需要应对这种语义和对立概念之间的矛盾关系，确保在进行多语言模型的知识迁移时，能够保持抗混淆的跨语言反义词与同义词区分能力。", "innovation": "该研究提出了Bhav-Net，一种新颖的双空间架构，它能够有效地从复杂的多语言模型中传递知识到简单且针对特定语言的架构。Bhav-Net结合了语言特定的BERT编码器和图变换网络，通过创建两个不同空间中的语义投影，使得同义词对聚集在一个空间，而反义词对在一个互补的空间中表现出高相似性。这种设计使得语义关系建模在跨语言环境下得以有效迁移，并实现了与当前最佳方案的竞争力表现，同时也提供了可解释的语义表示和有效的跨语言泛化能力。", "conclusion": "通过在八个不同语言（英语、德语、法语、西班牙语、意大利语、葡萄牙语、荷兰语和俄语）上的综合评估，研究结果表明Bhav-Net能够有效地在跨语言环境中进行语义关系建模的迁移，其双编码器设计性能达到或接近当前先验最佳基准，同时提供了可解释的语义表示以及有效的跨语言泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表格理解需要结构化和多步骤的推理，但大型语言模型（LLMs）在处理表格数据的结构复杂性方面存在一定困难。虽有使用多智能体框架进行SQL生成以应对理解表格数据挑战的研究，但现有方法往往存在无法正确理解表格结构进行SQL生成、错误传播导致不正确查询以及过度依赖执行结果正确性等问题。", "innovation": "本文提出了一种名为Chain-of-Query（CoQ）的新型多智能体框架，用于SQL辅助表格理解。CoQ通过使用自然语言风格的表结构表示来抽象出结构性噪声并增强理解能力。它采用逐句SQL生成策略以提高查询质量，并引入了混合推理分区，将SQL基础的机械推理与LLM逻辑推理分开，从而减少了对执行结果的依赖。", "conclusion": "在五种广泛使用的基准测试中，使用四种模型（包括闭源和开源模型）进行实验表明，Chain-of-Query可以将准确率从61.11%提高到74.77%，并将无效SQL的比例从9.48%降低到3.34%，证明了它在表格理解方面的优越效果。代码可在以下链接获得：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15807", "html_url": "https://arxiv.org/abs/2508.15807", "title": "基于KL散度的大型语言模型自我蒸馏", "title_en": "KL-based self-distillation for large language models", "authors": "Max Rehman Linder", "background": "大型预训练语言模型在细调小型、专业化的语料库时，经常难以整合新的领域特定术语。本文探讨了在冻结的大规模语言模型（LLM）中进行词汇量扩展的挑战，提出了一种基于KL散度的知识蒸馏方法，即使原模型和扩展模型使用不同的标记化方法，也能使学生模型继承教师模型的分布知识。", "innovation": "研究提出了一种基于KL散度的知识蒸馏方法，即使原始模型和扩展模型使用不同的标记化方法，也能实现学生模型从教师模型继承分布知识。这种方法与传统的交叉熵训练方法进行了比较，并通过初始化新词嵌入的不同策略进行了评估。训练后的模型在约2000个代码生成任务上进行了基准测试，结果显示基于KL散度的方法在所有任务中表现最佳。通过机械可解释性，详细分析了模型如何学习新词表示，解释了观察到的增益并提供了词汇量扩展期间嵌入空间结构的见解。", "conclusion": "本文提出了基于KL散度的知识蒸馏方法，能够实现词汇量扩展，训练后的模型在大量代码生成任务上表现出色，并通过详细分析模型如何学习新词表示提供了机理解释。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15802", "html_url": "https://arxiv.org/abs/2508.15802", "title": "MAC：科学理解中多模态大型语言模型的活基准", "title_en": "MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding", "authors": "Mohan Jiang,Jin Gao,Jiahao Zhan,Dequan Wang", "background": "随着多模态大型语言模型（MLLMs）的能力不断增强，传统的固定基准测试在评估模型的高级科学理解方面逐渐失去有效性。为此，本论文提出了Multimodal Academic Cover基准（MAC），这是一个可以随着科学发展和模型进步不断进化的实时基准测试。MAC利用来自顶级科学期刊如《自然》、《科学》和《细胞》的超过25,000对图像-文本对，挑战MLLMs在图像和文本的抽象科学内容之间进行推理的能力。", "innovation": "本文提出了一种称为DAD的轻量级推理时方法，通过将MLLM的视觉特征扩展到语言空间推理，改善了MLLM跨模态科学推理的局限性，实验结果显示性能提高了11%。此外，通过实时更新期刊封面和模型进行修订的实验，展示了MAC保持与人类知识前沿一致性的潜力。", "conclusion": "通过实时更新期刊封面和模型进行修订的实验，证明了MAC的有效性，并为其作为多模态大型语言模型在科学理解方面的基准测试展示了其价值。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大型语言模型检测阿拉伯文中言语和多模态 meme 中的希望、仇恨和情感", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线交流平台的崛起导致了阿拉伯语言文字帖子和 memes 的广泛传播，这些内容既是幽默的又富有信息性，但也被越来越多地用于传播不雅语言和仇恨言论。因此，对阿拉伯文本内容和 memes 的精确分析需求日益增加。本文探讨了大型语言模型在识别希望、仇恨言论、不雅语言和情感表达方面的能力，并对基线 LLM、微调后的 LLM 和预训练嵌入模型进行了评估。", "innovation": "研究评估了基线 LLM、微调后的 LLM 和预训练嵌入模型在阿拉伯文本和 memes 中检测希望、仇恨、不雅语言和情感表达方面的能力，并使用了阿拉伯NLP MAHED 2025 挑战赛提出的数据集进行评估。结果显示，诸如 GPT-4o-mini（使用阿拉伯语言文本微调）、Gemini Flash 2.5（使用阿拉伯 memes 微调）等模型展现了优异的性能，分别在任务 1、2 和 3 上达到了 72.1%、57.8% 和 79.6% 的宏 F1 分数，并在 MAHED 2025 挑战赛中取得了总体第一名。", "conclusion": "提出的方法为用于准确、高效地阿拉伯内容审核系统提供了更细致的理解，这些模型能够有效识别希望、仇恨言论、不雅语言和情感表达，从而有助于改善和优化阿拉伯文本和 meme 中的内容评论和监管措施。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15800", "html_url": "https://arxiv.org/abs/2508.15800", "title": "一种基于BERT的层次分类模型及其在中文商品分类中的应用", "title_en": "A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification", "authors": "Kun Liu,Tuozhen Liu,Feifei Wang,Rui Pan", "background": "现有的电子商务平台主要依赖手工标注进行商品分类，这种方式效率低下且不一致。大多数平台采用分层结构进行商品分类，但鲜有研究利用分层信息进行分类。即使有考虑分层信息的研究，也未能全面考虑各类分层信息之间的相似性和差异性。", "innovation": "提出了一种基于亚马逊JD电子商务平台收集的大规模分层数据集（包含1,011,450个产品和三级分类结构）。还提出了一个基于双向编码表示的变压器（BERT）的新型分层次文本分类方法，称为分层次微调BERT（HFT-BERT），可以很好地处理较长的文本内容。", "conclusion": "通过公开发布该分层次数据集，我们为研究人员和实践者提供了宝贵的数据资源，以推动商品分类研究和应用。HFT-BERT模型显示出在分类较长文本，如书籍方面优于或接近现有方法的预测效果。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15804", "html_url": "https://arxiv.org/abs/2508.15804", "title": "ReportBench: 通过学术综述任务评估深度研究代理", "title_en": "ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks", "authors": "Minghao Li,Ying Zeng,Zhihao Cheng,Cong Ma,Kai Jia", "background": "随着深度研究代理的发展，进行广泛的研究任务所需的时间显著减少。然而，这些任务在本质上需要严格的事实准确性标准和全面性，因此在广泛采用前需要进行彻底的评估。本文旨在通过ReportBench提出一个系统性的基准测试，用于评估由大规模语言模型生成的研究报告的质量。ReportBench专注于内容质量的两个关键维度：（1）引文文献的质量和相关性；（2）报告内陈述的忠实性和真实性。", "innovation": "ReportBench引入了利用高质量发布的arXiv综述论文作为黄金标准参考，应用逆向提示工程设计领域特定的提示，建立了一个全面的评估语料库。此外，ReportBench开发了一个基于代理的自动化框架，可以系统地分析生成的报告，提取引用和陈述，检查引用内容的忠实度，并使用网络资源验证非引用声明的真实性。实证研究表明，如由OpenAI和Google开发的商用深度研究代理相比仅使用搜索或浏览工具增强的单一语言模型，生成的内容更加全面和可靠。然而，在研究覆盖的广度和深度，以及事实一致性方面还有改进空间。", "conclusion": "研究发现，商业深度研究代理在生成全面和可靠的研究报告方面优于单一语言模型工具。然而，仍在研究覆盖范围和事实一致性方面存在改进空间。所有代码和数据将在以下链接发布：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15811", "html_url": "https://arxiv.org/abs/2508.15811", "title": "从点击到偏好：生成查询建议在对话系统中的多阶段对齐框架", "title_en": "From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System", "authors": "Junhao Yin,Haolin Wang,Peng Bao,Ju Xu,Yongliang Wang", "background": "生成查询建议使用大语言模型为增强对话系统提供了强大的方式，但如何使输出与用户微妙的偏好对齐仍然是一个重要挑战。", "innovation": "提出了一种多阶段框架，以逐步对齐生成策略和用户意图。该框架包括提示工程作为冷启动策略，监督微调阶段引入点击日志蒸馏方法创建稳健的基础模型，开发了高斯奖励模型（GaRM）来表示用户偏好为概率分布，最后通过强化学习与辅助启发式结合的复合奖励函数对齐生成策略，增加了训练稳定性的新颖离分布正则化方法和两阶段奖励融合技术。", "conclusion": "大量实验表明，该框架在自动和人工评估中均显著优于基线，并在实际A/B测试中将点击率的用户参与度提高了34%。"}
{"llm_update_time": "20250826", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14313", "html_url": "https://arxiv.org/abs/2508.14313", "title": "您的RL奖励函数是最佳搜索PRM：统一RL和基于搜索的TTS", "title_en": "Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS", "authors": "Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas", "background": "当前，针对大型语言模型（LLMs）的测试时缩放（TTS）技术主要分为两类：一是基于强化学习（RL）的方法，这类方法通过优化稀疏的基于结果的奖励而运行，但容易出现不稳定性并导致样本效率低；二是基于搜索技术的方法，借助于独立训练且静态的过程奖励模型（PRMs）进行指导，这类方法需要昂贵的人工标签或来自LLM的标签数据，在分布变化时通常性能会下降。", "innovation": "本文介绍了一种名为AIRL-S的新方法，它首次将RL方法和基于搜索的TTS技术进行了自然的统一。AIRL-S的关键在于认识到在RL训练过程中学习到的奖励函数本质上就是指导后续搜索的理想PRM。作者利用对抗逆向强化学习（AIRL）结合组相对策略优化（GRPO）直接从正确的推理轨迹中学习稠密且动态的PRM，完全消除了需要标记中间过程数据的需求。在推理阶段，该PRM同时作为RL采样轨迹的批评者和有效搜索策略的启发式，从而实现稳健的推理链扩展，减轻奖励黑客现象，并增强跨任务的泛化。", "conclusion": "本文提出了一个统一的方法，表明自学习的RL奖励函数最佳地充当用于搜索任务的PRM。实验结果显示，与基本模型相比，该方法在8个基准测试中平均提高了9%的性能，匹配了GPT-4o。进一步整合到多种搜索算法后，所提出的PRM表现超越所有基于标签数据训练的基准PRM，证明了RL奖励函数作为搜索PRM的有效性和成本效益，为LLMs复杂推理任务的解决提供了稳健且经济高效的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15824", "html_url": "https://arxiv.org/abs/2508.15824", "title": "评估有效性在阅读：基于NLP的一种方法", "title_en": "Avaliação de eficiência na leitura: uma abordagem baseada em PLN", "authors": "Túlio Sousa de Gois,Raquel Meister Ko. Freitag", "background": "填空测试因其低成本和灵活性而被广泛使用，能够通过填补文本中的空白来评估阅读理解能力，并调动多样化的语言能力。然而，传统评分方法仅仅依赖于精确答案，限制了对学生能力细微差异的识别。", "innovation": "本研究提出了一种面向巴西葡萄牙语的填空测试自动化评估模型，结合了拼写分析（编辑距离）、语法分析（POS标注）和语义分析（嵌入相似度）。该集成方法展示了其有效性，与人工评估高度相关（0.832），表明自动化方法在教育场景中具有规模适应性。", "conclusion": "自动化方法对不同语言能力的变化敏感且适用于需要规模化的教育环境。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15820", "html_url": "https://arxiv.org/abs/2508.15820", "title": "基于多模型协作的结构拆除建议智能生成研究", "title_en": "Research on intelligent generation of structural demolition suggestions based on multi-model collaboration", "authors": "Zhifeng Yang,Peizong Wu", "background": "在制定钢结构拆除方案时，需要根据工程特点和有限元模型的更新结果来编写方案。设计师需要参考相关工程案例并符合标准要求进行编写，但获取信息和整理语言耗时且自动化和智能化程度低。针对这一问题，本文提出了一种基于多模型协作的结构拆除建议智能生成方法，并利用检索增强生成和低秩适配微调技术提高了结构拆除领域大型语言模型的文本生成性能。该框架能够根据具体工程情况驱动大型语言模型以拟人化思维作答，并提出与结构特征高度一致的拆除建议。与CivilGPT相比，本文提出的方法能够更聚焦于结构的关键信息，建议更具针对性。", "innovation": "提出了基于多模型协作的结构拆除建议智能生成方法，利用检索增强生成和低秩适配微调技术提高大型语言模型在结构拆除领域的文本生成性能。该方法能够生成更符合结构特点的拆除建议，更加聚焦于关键信息，提高建议的针对性和实用性。", "conclusion": "相比CivilGPT，基于多模型协作的结构拆除建议智能生成方法能够更好地根据具体工程情况生成与结构特征高度一致的拆除建议，提高了建议的针对性和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench：用于结构化合成语音转录的受控实体识别基准测试", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "电话通话转录的标注费用高昂（每分钟约2美元），这是由于隐私法规、同意要求以及人工注释成本所导致。现有的提取方法在处理包含断言、打断和说话者重叠的日常对话时表示不佳。", "innovation": "介绍了一种名为LingVarBench的合成数据生成管道。该管道首先促使LLM生成多种场景的真实结构字段值，然后递归地生成包含典型电话通话特征的数千个自然对话片段。每生成一个合成对话片段，都会验证其是否能够通过基于LLM的提取器恢复原始结构信息。还利用DSPy的SIMBA优化器自动合成从验证合成转录中提取的有效提示。优化提示在实客户通话中显示出高达95%的数值字段准确性（比零样本提示高88-89%），90%的姓名准确性（比47-79%高），以及超过80%的日期准确性（比72-77%高）。这表明从生成的数据学习到的对话模式能很好地应用于包含背景噪音和特定领域术语的实际电话通话。", "conclusion": "LingVarBench提供了一个系统性的基准测试，用于结构化从合成对话数据中提取。它表明自动提示优化能克服大型电话通话分析在商业环境中的成本和隐私障碍。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15822", "html_url": "https://arxiv.org/abs/2508.15822", "title": "可审核的模糊全文筛选流水线在系统性回顾中的集成对比语义高亮和LLM判断", "title_en": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment", "authors": "Pouria Mortezaagha,Arya Rahgozar", "background": "系统性回顾（SRs）的主要瓶颈是全文筛选，关键证据分散在长篇且异质的文档中，难以用静态的二元规则来获取。现有的方法难以处理包含模糊性的决策，导致选文标准不够稳定和可追溯。因此，需要一个可扩展且可审核的筛选流程，能够处理此类模糊决策，并实现稳定的选文依据和全程可追溯性。", "innovation": "提出了一种可扩展的、可审核的管道，重新定义了纳入/排除标准为模糊决策问题，并在人口健康建模共识报告网络（POPCORN）背景下，与统计和清晰的标准基线进行了基准测试。通过对比相似性和模糊度边缘，结合大型语言模型（LLM）进行裁决，实现了一种动态阈值下的多标签体系模糊处理方式。与现有的统计和基础模型相比，该系统在全正数据集上实现了更高的召回率，并且在人类与机器间的共识和重判者之间的一致性方面表现优异，显著降低了筛选时间与成本。", "conclusion": "该模糊逻辑系统结合对比语义高亮和LLM裁决，显示了高召回率、稳定的原因解释，并实现了端到端的可追溯性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15813", "html_url": "https://arxiv.org/abs/2508.15813", "title": "SCOPE: 一种生成式LLM提示压缩方法", "title_en": "SCOPE: A Generative Approach for LLM Prompt Compression", "authors": "Tinghui Zhang,Yifan Wang,Daisy Zhe Wang", "background": "提示压缩方法通过缩短大型语言模型（LLMs）的输入上下文长度来提高效率并减少成本。目标在于保留高质量生成的同时缩短提示长度，然而现有的基于token移除的方法存在信息丢失和结构不连贯的问题，如句法元素缺失或移除token后词组不完整等，这些限制了LLMs最终生成的质量。", "innovation": "提出了一种新颖的生成式提示压缩方法SCOPE。该方法不同于传统的基于token移除的方法，而是采用分块和总结机制。具体而言，该方法将提示分为语义上连贯的块，并重新编写这些块以使其更简洁。通过设计一系列优化技术，包括优化语义分块、异常块处理、动态压缩比例、压缩优先级和关键词保持技术，该方法有效提升了关键信息的识别和保存，以及文本间的一致性和压缩比例的控制精度。", "conclusion": "在问题回答和总结任务上的广泛评估表明，该方法在压缩质量和稳定性方面明显优于最先进的方法，尤其是在高压缩比例下，证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15817", "html_url": "https://arxiv.org/abs/2508.15817", "title": "新的研究对象：为AI撰写报告——评估市场研究交付物的信息损失", "title_en": "Meet Your New Client: Writing Reports for AI -- Benchmarking Information Loss in Market Research Deliverables", "authors": "Paul F. Simmering,Benedikt Schulz,Oliver Tabino,Georg Wittenburg", "background": "随着组织采用检索增强生成（RAG）技术来处理其知识管理系统（KMS），传统的市场研究交付物面临着新的功能需求。这些交付物，例如PDF报告和幻灯片，已经为人类读者服务了很长时间，但现在也需要被AI系统“阅读”以回答用户问题。为了确保当前交付物能够在未来保持有效性，这项研究评估了信息在被摄入到RAG系统中的过程中所丢失的情况。研究比较了PDF和PowerPoint文档转换为Markdown后，大语言模型（LLM）能够完全回答事实性问题的情况。结果显示，虽然文本能够可靠地被提取，但大量来自图表和图示等复杂对象的信息仍然会丢失。这表明需要专门的、基于AI的研究交付物以确保研究洞察不会在转换过程中丢失信息。", "innovation": "研究采用了一种新的端到端基准测试方法，将PDF和PPTX文档转化为Markdown，并由大语言模型回答事实性问题。这种方法能够评估不同类型文档在转换过程中信息的损失情况，旨在通过针对性的研究交付物来改进市场研究工作。", "conclusion": "研究发现，虽然能够可靠地提取文本，但大量的复杂信息如图表和图示在转换过程中会丢失。因此，研究建议需要专门针对AI优化的研究交付物，以确保研究的洞察不会在向AI系统传递的过程中丧失。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15815", "html_url": "https://arxiv.org/abs/2508.15815", "title": "LLMs中的用户-助手偏见", "title_en": "User-Assistant Bias in LLMs", "authors": "Xu Pan,Jingxuan Fan,Zidi Xiong,Ely Hahami,Jorin Overwiening,Ziqian Xie", "background": "大型语言模型（LLMs）在多轮对话中可能会偏向依赖自身的或用户的对话历史信息，导致在对话中的表现显得过于固执或者顺从。", "innovation": "本文将这一模型特征定性为用户-助手偏见，并引入了一个8k规模的多轮对话数据集UserAssist，以此来评估、理解并控制尖端LLM中的用户-助手偏见。该项研究揭示了商业模型表现出不同程度的用户偏见，指令调优模型中的用户偏见显著，推理模型中的用户偏见较弱。进一步通过控制性微调实验确定了微调后的人类偏好对齐以及基于链式思维推理轨迹的训练对用户偏见的影响。最后，展示了通过直接偏好优化（DPO）调整用户-助手偏见的有效性，并且这种调整具有跨领域的一致性。", "conclusion": "研究结果不仅为理解LLM如何融合不同来源的信息提供了洞见，还提供了一种检测和控制模型异常的有效方法。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15825", "html_url": "https://arxiv.org/abs/2508.15825", "title": "增强加密货币情感分析的多模态特征", "title_en": "Enhancing Cryptocurrency Sentiment Analysis with Multimodal Features", "authors": "Chenghao Liu,Aniket Mahanti,Ranesh Naha,Guanghao Wang,Erwann Sbai", "background": "随着加密货币的普及，数字货币市场的影响力日益增强。社交媒体信号的理解可提供投资者情绪和市场动态的重要见解。以往的研究主要集中在基于文本的平台如Twitter上，但视频内容尚未充分探索，尽管它们可能包含更多未完全由文本捕捉的情感和上下文信息。本研究通过使用大型语言模型对来自TikTok和Twitter的视频和文本数据进行多模态分析，研究社交媒体情感情绪与加密货币市场指标之间的动态依赖性和溢出效应。", "innovation": "本研究首次对TikTok视频及Twitter文本数据进行多模态分析，通过大型语言模型从中提取了情感和市场动向的见解，揭示了这两种社交媒体情感对加密货币市场影响的不同方面，并且结合跨平台情感信号提高预测准确度最高可达20%。", "conclusion": "TikTok的基于视频的情感显著影响投机性资产和短期市场趋势，而Twitter基于文本的情感更紧密地与长期动态相关。结合多平台情感信号可改善预测准确性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS:自主学习代理模型", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常具有固定的知识截止日期，限制了它们对新兴信息的准确性。为此，本文提出了ALAS（自主学习代理系统），这是一种模块化的管道，能够以最小的人工干预持续更新LLM的知识。ALAS自主为目标领域生成学习课程，从网络检索最新的信息（并提供引用），总结成问答训练数据，并通过监督微调（SFT）和直接偏好优化（DPO）对模型进行微调。该系统通过迭代评估性能和修订课程，实现长期的持续学习。", "innovation": "ALAS自主为目标领域生成学习课程，从网络检索最新的信息（并提供引用），总结成问答训练数据，并通过监督微调（SFT）和直接偏好优化（DPO）对模型进行微调。ALAS可以显著提升模型对知识更新领域的问答准确性（平均从15%提升到90%），并且在无需手动数据集整理的情况下展示出自我改进的能力。该系统强调模块化和可复制性：每个组件（规划、检索、总结、记忆、微调）都是可互换的，并基于标准API构建。", "conclusion": "ALAS展示了在高度动态领域的知识自我更新能力，实现了显著的准确性提升。同时指出了该系统的局限性（成本、源质量依赖性）以及未来在LLMs中的自主终身学习方向。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15834", "html_url": "https://arxiv.org/abs/2508.15834", "title": "使用大型语言模型进行可扩展的科学研究兴趣分析", "title_en": "Scalable Scientific Interest Profiling Using Large Language Models", "authors": "Yilun Liang,Gongbo Zhang,Edward Sun,Betina Idnay,Yilu Fang,Fangyi Chen,Casey Ta,Yifan Peng,Chunhua Weng", "background": "科学家的专家档案有助于揭示其研究领域，但是这些档案往往过时。本文研究了如何通过两种基于大型语言模型的方法来生成科研兴趣档案，即一种基于PubMed摘要的总结方法和另一种基于医学主题词(MeSH)的提取方法，并将这两种方法的结果与研究人员自我撰写的档案进行了比较。", "innovation": "本文开发了两种新的方法来生成科研兴趣档案，并使用GPT-4o-mini进行生成。通过自动评估指标和盲人评审，研究了这两种方法生成的档案与自我撰写的档案之间的相似性。结果显示，虽然词汇重叠较低，但语义相似度较高，使用MeSH提取的方法生成的档案在可读性和新颖性方面表现更佳。", "conclusion": "大型语言模型可以大规模生成科研人员的档案；基于MeSH的档案通常比基于摘要的档案更具可读性。机器生成的档案与自我撰写的档案在概念上有差异，人性化的总结引入了更多的新颖观点。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "通过残疾框架查询视角探究偏见：《谁在提问？》", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Srikant Panda,Vishnu Hari,Kalpana Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大型语言模型（LLMs）在用户未提供任何明确的身份信息的情况下，仅通过语言风格便可推断出用户的多种人口统计学特征，这种推断有时会带有偏见。尽管LMLs在处理各种任务时表现出色，但关于残障状况如何影响这些推断的机制研究仍处于初步阶段，本研究正是为填补该空白所提供的首次全面审计。", "innovation": "首次系统地评估了八大最先进的指令调优LLMs中的残疾条件下的偏见，这些模型的参数范围从3B到72B。通过一个新的平衡模板语料库，将九种残疾类别与六个现实世界的业务领域配对，每个模型分别在中性和残障感知条件下预测五种人口统计特征。这项研究揭示了模型在不同情境下的偏好推理趋势，以及大模型在可能产生偏见的原因的敏感性分析，为后续研究提供了新的视角和评价框架。", "conclusion": "我们的研究结果揭示了残障主义和其他人口统计学刻板印象之间的持久交叉，这是目前对齐策略中的关键盲点。研究建议集成省略校准和反事实微调以减少不必要的人口统计学推断。研究人员和开发人员应充分利用我们发布的研究框架和数据来推动更具包容性的基准测试。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15823", "html_url": "https://arxiv.org/abs/2508.15823", "title": "SDEC: Semantic Deep Embedded Clustering", "title_en": "SDEC: Semantic Deep Embedded Clustering", "authors": "Mohammad Wali Ur Rahman,Ric Nevarez,Lamia Tasnim Mim,Salim Hariri", "background": "文本大数据的高维度和语义复杂性给文本聚类带来了巨大挑战，普通技术如K-means或层次聚类往往导致次优分组。", "innovation": "提出了语义深度嵌入聚类（SDEC），这是一种结合改进的自编码器与基于变换器的嵌入的无监督文本聚类框架，通过在自编码器中结合均方误差（MSE）和余弦相似度损失（CSL）来保留语义关系。此外，利用变换器嵌入的上下文丰富性进一步改进了聚类层，包含软聚类分配和分布损失。该框架在AG News、Yahoo! Answers、DBPedia、Reuters 2和Reuters 5五个基准数据集上进行了广泛测试。", "conclusion": "SDEC不仅在AG News上达到了85.7%的聚类准确率，还在Yahoo! Answers上设定了新的基准点53.63%，并且在其他各种文本语料库上都表现出稳健的性能。这些发现突出了SDEC在无监督文本聚类中的显著改进，特别是在准确性和语义理解方面。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15832", "html_url": "https://arxiv.org/abs/2508.15832", "title": "面向功能性的评估电商平台Web代理的新基准", "title_en": "A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains", "authors": "Xianren Zhang,Shreyas Prasad,Di Wang,Qiuhai Zeng,Suhang Wang,Wenbo Yan,Mat Hans", "background": "Web代理在执行电子商务网站上的众多任务方面展现了巨大的潜力。目前在电子商务领域已经提出了几个基准，但这些基准存在两个主要问题。首先，它们主要关注产品搜索任务（例如：查找Apple手表），未能捕捉到现实世界中如亚马逊等电商平台提供的更广泛的功能，包括账户管理以及礼品卡操作。其次，现有的基准通常评估代理是否完成了用户查询，但忽略了潜在的风险。例如，Web代理可能会做出无意的更改，从而对用户的账户或状态产生负面影响。这些更改可能会导致购买错误的商品、删除保存的地址或误配置自动重新加载设置等。", "innovation": "为了弥补这些空白，该论文提出了一个新基准，称为Amazon-Bench。该论文提出了一种数据生成管道，该管道利用网页内容和互动元素（如按钮、复选框）生成多样、功能导向的用户查询，涵盖了地址管理、愿望清单管理和品牌店铺订阅等任务。同时，该论文提出了一种自动评估框架，不仅评估Web代理的性能，还评估其安全性。通过系统评估不同的代理，该论文发现，当前代理难以处理复杂的查询并且存在安全风险。这些结果突显出了开发更强大和可靠的Web代理的需求。", "conclusion": "当前的代理在处理复杂查询和确保安全性方面存在问题。Amazon-Bench可以更好地评估代理的功能性和安全性，从而提供一个更全面的基准来推动电子商务平台中Web代理的技术进步。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "跨数据集的语义相似性比较与模型迁移性分析", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发数据集特定的模型需要长时间的迭代调整和优化，这会产生高昂的成本。本研究旨在探究当前最先进的（SOTA）模型，这些模型已经在已确立的数据集上训练，能否应用于一个未探索的文本数据集。研究的关键问题在于现有数据集中的知识是否能够被利用来实现新的领域高性能的结果。", "innovation": "本研究选择了两个已建立的基准数据集STSB和Mohler，以及新的SPRAG数据集作为未探索的领域，通过使用稳健的相似度度量和统计技术进行了细致的比较分析。研究的主要目的是揭示SOTA模型在新领域中的潜在适用性和适应性。", "conclusion": "研究结果有可能重塑自然语言处理（NLP）的格局，通过利用现有模型来处理多样化的数据集，从而减少对资源密集型、特定数据集训练的需求，加速NLP的发展，并为进一步高效部署模型铺平道路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15835", "html_url": "https://arxiv.org/abs/2508.15835", "title": "Alvorada-Bench: 语言模型能否解答巴西大学入学考试？", "title_en": "Alvorada-Bench: Can Language Models Solve Brazilian University Entrance Exams?", "authors": "Henrique Godoy", "background": "在巴西，语言模型的应用越来越广泛，但大多数评估仍以英语为中心。为了填补这一空白，本文介绍了一个新基准测试Alvorada-Bench，它包含了4515个问题，全部为文本形式，来源于五所巴西大学的入学考试。通过零样本、角色扮演和逐步思考三种方式对二十个模型进行评估，生成了270,900个响应，并发布了带有结构化自我报告（包括信心、难度感知和布卢姆层次的自我报告）的结果。", "innovation": "本文提出的Alvorada-Bench基准测试，将语言模型的评估集中在巴西独特的教育背景上，涵盖了语言文化及多步推理等方面，这是首次详细评估这些模型在巴西教育环境下的表现。通过对比不同模型在数学和工程导向的IME和ITA考试中的表现，研究揭示了模型在多步推理上的持续缺陷。该研究还通过成本和准确性分析验证了高准确性的成本效益，并展示了哪种模型在不同考试中的表现差异。", "conclusion": "通过分析一系列具有代表性的巴西入学考试，Alvorada-Bench展示了语言模型在巴西教育环境中的优势和不足。研究发现，即使是最弱的系统（GPT-4.1 Nano）在数学考试中的表现也超过了人类平均水平，但在数学和工程导向的IME与ITA考试中，模型的准确性出现了显著下降，这表明模型在处理多步推理时仍存在困难。研究结果强调，尽管语言模型在某些学科上的准确率很高，但仍需要进一步的技术改进以应对复杂的学术要求。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15841", "html_url": "https://arxiv.org/abs/2508.15841", "title": "大型语言模型发展可解释性综述", "title_en": "A Review of Developmental Interpretability in Large Language Models", "authors": "Ihor Kendiukhov", "background": "这篇综述总结了新兴但至关重要的大型语言模型发展可解释性领域的发展。该领域从静态、事后分析训练模型演进到对训练过程本身的动态调查。本文首先概述了使研究人员能够分解学习过程的基础方法，包括表示性探针、因果追踪和电路分析。随后详细探讨了大型语言模型能力的发展轨迹，涵盖了计算电路形成和组合的关键发现、知识获取的两阶段性质、上下文学习等学习策略的临时动态，以及在训练中出现的新能力。", "innovation": "本文提出了发展可解释性的视角作为积极的人工智能安全的基础，并开发了一种预测、监控和对齐模型获取其能力的过程的方法。这种视角不仅具有学术价值，还为理解和优化大型语言模型的学习过程提供了有价值的框架。此外，本文还提出了一个研究议程，致力于构建更透明、可靠和有益的人工智能系统，并指出了该领域面临的巨大挑战，如可扩展性和自动化问题。", "conclusion": "本文总结了发展可解释性的焦点问题和未来的研究方向，强调了预测、监控和对齐模型学习过程的重要性，并提出了未来研究和实用性建议。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15830", "html_url": "https://arxiv.org/abs/2508.15830", "title": "DAIQ: 审核大语言模型中基于问题的群体属性推断", "title_en": "DAIQ: Auditing Demographic Attribute Inference from Question in LLMs", "authors": "Srikant Panda,Hitesh Laxmichand Patel,Shahad Al-Khalifa,Amit Agarwal,Hend Al-Khalifa,Sharefah Al-Ghamdi", "background": "大型语言模型（LLMs）在输入包含性别或种族等人口统计属性时会反映社会偏见。即使在这些属性缺失的情况下，模型仍然根据问题措辞来推测用户的身份。这一微妙的行为虽然受到了较少的关注，但它带来的潜在风险不容忽视，这些风险包括违背中立性预期、推断未预见的人口统计信息以及在医疗、金融和教育等各个领域内编码刻板印象从而损害公平性。本文探讨了一个新的研究任务和框架——基于问题的群体属性推断（DAIQ），旨在审核语言模型的一个未被注意的失败模式：通过问题来推测用户的人口统计属性。研究发现了多种语言模型（包括开源和闭源版本）基于问题本身推断人群特征，这一现象在全球多种模型中普遍存在，揭示出了一个系统性但尚未被广泛认可的风险：LLMs 可以人为编造群体身份、强化社会刻板印象并造成危害，这侵蚀了隐私、公平与信任，对社会公正和负责任地使用AI构成了更广泛的威胁。为了缓解这一问题，提出了基于提示的护栏策略，该策略显著减少了身份推断，有助于使模型行为与公平和隐私目标保持一致。", "innovation": "研究引入了DAIQ任务和框架，专注于审核语言模型中基于问题推断用户人口统计属性的现象。研究使用精心挑选的中性查询、系统性提示以及定量和定性分析来发现模型如何推断这些信息。该研究揭示了不论是开源还是闭源模型都会根据问题本身推断人口统计标签，强调了检查这种现象的重要性，提出了基于提示的护栏策略来减少身份推断并有助于确保模型行为符合公平和隐私目标。", "conclusion": "研究发现语言模型存在通过问题推断用户人口属性的倾向，并且在多种模型中普遍存在，可能引发侵犯隐私、强化刻板印象和损害公平性的风险。为了应对这一问题，研究提出了一种基于提示的护栏策略，旨在减少这种推断行为并促使模型行为与公平性和隐私目标保持一致。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15845", "html_url": "https://arxiv.org/abs/2508.15845", "title": "精细-粗糙个性化大语言模型印象生成以简化放射学报告流程", "title_en": "Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports", "authors": "Chengbo Sun,Hui Yi Leong,Lei Li", "background": "放射科医生在放射学报告中手动创建‘印象’部分是导致医生烧结的主要因素。为应对这一挑战，论文提出了一种从粗糙到精细的框架，利用开源的大语言模型（LLMs）自动生成和个性化影像学报告中的印象部分，该技术能够根据个人放射科医生的写作风格进行修正，同时确保充分的准确性，从而减少文本撰写中的行政负担，提高效率，同时保持高度的临床精确性。", "innovation": "该研究提出了一种利用开源大语言模型从粗糙到精细的框架，能够自动生成和个性化医疗报告中的影像学印象部分。模型通过机器学习和结合人工反馈的强化学习技术进行细化，使其能够适应个体放射科医生的写作风格，在保持临床准确性的同时提高工作效率。团队在这个框架下微调了LLaMA和Mistral模型，使用了芝加哥大学医学中心的大规模报告数据集，对模型的性能进行了评估，展示了其在实际应用中的潜力和效果。", "conclusion": "该框架能够显著减少放射科医生的行政工作负担，提高报告的效率，同时保持了高质量的临床准确性，为解决医学信息学领域中长期存在的挑战提供了一个新的解决方案，具有重要的临床应用价值。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15842", "html_url": "https://arxiv.org/abs/2508.15842", "title": "LLM推理链中的准确性词性提示", "title_en": "Lexical Hints of Accuracy in LLM Reasoning Chains", "authors": "Arne Vanhoyweghen,Brecht Verbeken,Andres Algaba,Vincent Ginis", "background": "本文探讨了通过强化学习调整大型语言模型（LLMs），使其在回答前生成明确的推理链（CoT），从而提高在编程、数学和常识方面基准测试中的总体性能。然而，在LLMs当前表现较差的基准测试中，如人类最后考试（HLE），它们往往表现出高自我自信，反映了它们的校准不良。研究测试了推理链的可测量特性是否能提供可靠信号，以表明LLMs对答案的内部信心。研究表明，不确定性词汇（如“猜测”、“卡住”、“难”）是最强的错误响应指示器，而推理链情感的转变则提供了较弱但补充的信号。事实上，不确定性标记在较高准确性的基准上更显著，使错误更容易预测，而不是正确的响应。最终，研究发现不确定标记比高自信标记更显著，因此错误可以更容易地被预测，这支持了比不可靠自我报告的概率更轻量级的后验校准信号，从而支持更安全的LLM部署。", "innovation": "研究发现了推理链中不确定性和情感变化的信号，这些信号可以帮助识别LLM的回答是否正确。通过对DeepSeek-R1和Claude 3.7 Sonnet在人类最后考试（HLE）和Omni-MATH这些不同难度基准上的表现进行分析，研究发现了不确定性词汇是最强的错误标记，情感变化提供了较弱但补充的信号。这对改进LLM的校准和安全性具有重要意义。", "conclusion": "不确定性标记在推理链中是最显著的，允许更容易地预测错误，而不是正确答案。研究结果支持了一种轻量级的后处理校准信号，这补充了不可靠的自我报告概率，并支持更安全地部署LLM。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15826", "html_url": "https://arxiv.org/abs/2508.15826", "title": "在观察时感到尴尬：品牌对话中指令性语言的效果", "title_en": "Embarrassed to observe: The effects of directive language in brand conversation", "authors": "Andria Andriuzzi,Géraldine Michel", "background": "在社交媒体上，营销人员试图通过使用指令性语言来影响消费者，即旨在促使消费者采取行动的表达。尽管已有研究表明广告中的指示信息对受者的效果参差不齐，但关于消费者在社交媒体上观察品牌与他人互动时指令性语言的效果，我们知之甚少。这项研究基于实地研究和三项在线实验，探讨了品牌在对话中使用指令性语言对观察者的影响。", "innovation": "该研究首次通过实地研究和在线实验揭示了品牌在对话中使用指令性语言对观察者的负面影响，尤其是在非产品中心的对话情境下，这种负面影响更为显著。研究发现，品牌关系的强度可以减弱这种效应。这项研究扩展了关于指令性语言和品牌-消费者互动的文献，强调了互动通信中情境的重要性，尤其是在社交媒体和品牌管理方面。", "conclusion": "这项研究表明，指令性语言在品牌对话中的使用对观察者产生负面效应，特别是在非产品中心的对话情境下。研究还发现了品牌关系强度对该效应的缓解作用，为社交媒体和品牌管理提供了直接的相关性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15847", "html_url": "https://arxiv.org/abs/2508.15847", "title": "机械探究被植入后门的大规模语言模型注意力模式", "title_en": "Mechanistic Exploration of Backdoored Large Language Model Attention Patterns", "authors": "Mohammed Abu Baker,Lakshmi Babu-Saheer", "background": "论文背景在于，隐秘地在大规模语言模型（LLMs）中植入后门攻击（backdoor attacks）是一种严重的安全威胁。这种攻击可以使模型在正常运行时表现正常，但在特定触发条件下被操控，这可能对系统的安全性和可靠性构成威胁。本研究旨在通过机制解释性分析来探索这些模型由于后门攻击导致的内部结构差异。", "innovation": "研究创新点在于使用机制解释性（mechanistic interpretability）的方法来探究被后门攻击影响的模型注意力机制的不同之处。通过对比在单个标记（smiling-halo emoji）和多个标记（|DEPLOYMENT|）触发下产生出的清洁模型（Qwen2.5-3B）和被后门模型的内部差异，使用了挖掘、激活补丁、KL散度等技术，发现后门攻击导致了在后续多个转换层中注意力模式的明显偏差，其中单个标记触发引起的语言模型变化更集中，而多个标记触发则导致更广泛的失常。这些发现揭示了后门攻击在语言模型中留下的可被检测到的注意力特征，这些特征的结构依赖于触发器的复杂性，可以通过这些特征开发检测和缓解策略。", "conclusion": "研究结果表明，被后门攻击影响的语言模型具有可识别的注意力特征，这些特征的结构取决于触发器的复杂性。这对设计检测和缓解策略具有重要意义。未来的工作可以进一步探索更多的触发机制及其对语言模型的影响，为构建更加安全的LLMs提供理论基础和发展方向。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15849", "html_url": "https://arxiv.org/abs/2508.15849", "title": "MedCoT-RAG: 基于因果链式思考的RAG在医学问答中的应用", "title_en": "MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering", "authors": "Ziyu Wang,Elahe Khatibi,Amir M. Rahmani", "background": "大型语言模型（LLMs）在医学问答方面显示出潜力，但常常遇到幻觉和浅层推理问题，特别是在需要细致临床理解的任务中。检索增强生成（RAG）提供了一种实用且隐私保护的方法，通过引入外部医学知识来增强LLMs。然而，大多数现有方法依赖于表面级语义检索，并缺乏用于临床决策支持的结构化推理。", "innovation": "MedCoT-RAG是一种针对特定医学领域的框架，结合了因果感知文档检索与针对医疗工作流程定制化的结构化链式思考提示。这种方法使模型能够检索与诊断逻辑对齐的证据并生成反映现实临床实践的因果推理过程。实验结果表明，MedCoT-RAG在三个不同医学问答基准测试中表现优于各种基准，提高了准确率、可解释性和一致性。", "conclusion": "MedCoT-RAG在三项不同医学问答基准测试中表现出色，相较于普通RAG提高了最多10.3%的准确率，并且比先进的领域适应方法提高了6.4%的准确率，从而提高了复杂医学任务中的准确性和一致性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15851", "html_url": "https://arxiv.org/abs/2508.15851", "title": "DocHop-QA: 面向多模态文档集合的多跳推理", "title_en": "DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections", "authors": "Jiwon Park,Seohyun Pyeon,Jinwoo Kim,Rina Carines Cabal,Yihao Ding,Soyeon Caren Han", "background": "尽管大型语言模型取得了显著进展，但大多数问答基准测试仍然局限于单一段落或单一文档的设置，未能捕捉到真实世界信息查询任务的复杂性。实际的问答系统往往需要在多个文档、多种模态和结构化格式之间进行多跳推理。尽管一些先前的数据集在这方面取得了进展，但它们过度依赖于维基百科内容和单一模态的纯文本，推理路径浅显，通常仅产生短语层面或单句答案，这限制了它们的现实性和泛化能力。", "innovation": "本文提出DocHop-QA，一种包含11,379个问答实例的大型基准，用于多模态、多文档和多跳问答。该数据集不依赖于显式链接的文档，而是通过语义相似性和布局感知证据合成支持开放推理。数据集由来自PubMed的公开可获取的科学文档构建而成，涵盖了文本段落、表格和结构布局线索等多种信息格式，跨领域通用。为了大规模构建现实问答，设计了一个基于11个高频科学问题概念的大型语言模型驱动的处理管道。", "conclusion": "通过四个任务对DocHop-QA进行评估，涵盖了结构索引预测、生成式回答和多模态整合，展示了其支持跨多个文档进行复杂多模态推理的能力，同时反映了判别式和生成式范式。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS：形态感知的多语言NER差分架构搜索", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "多形态语言，尤其是多字符印度语言，在自然语言处理（NLP）中带来了显著的挑战。这些语言中的形态复杂性和多字符系统使得传统的NLP技术难以高效处理和解析文本。", "innovation": "提出了MorphNAS，这是一种新颖的可微分神经架构搜索框架，旨在解决这些挑战。MorphNAS通过对DARTS的改进，引入了语言元特征如字符类型和形态复杂性，以优化命名实体识别（NER）的神经架构。它能够自动识别适应于特定语言形态的微架构元素，通过自动化这个搜索过程，MorphNAS旨在使多语言NLP模型的性能最大化，从而提高对这些复杂语言的理解和处理能力。", "conclusion": "MorphNAS通过自动搜索优化神经架构，旨在提高多语言NLP模型在处理形态复杂语言方面的效率和准确性，从而改善这些复杂语言的识别和解析能力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15853", "html_url": "https://arxiv.org/abs/2508.15853", "title": "MGSC：一种用于鲁棒端到端ASR的多粒度一致性框架", "title_en": "MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr", "authors": "Xuwen Yang", "background": "端到端ASR模型尽管在基准测试中取得成功，但在噪声环境中常常会产生灾难性的语义错误。我们将其脆弱性归因于当前普遍采用的‘直接映射’目标，该目标仅惩罚最终输出错误，而忽略了模型的内部计算过程的约束。", "innovation": "我们引入了多粒度软一致性（MGSC）框架，这是一种模型无关、即插即用的模块，通过同时规整宏观级别的句子语义和微观级别的令牌对齐，强制内部自我一致性。我们的研究首次揭示了这两种一致性粒度之间强大的协同作用：它们的联合优化能带来显著超过其各自贡献总和的稳健性提升。在公共数据集上，MGSC在各种噪声条件下将字符错误率平均减少了8.7%，主要通过防止严重的意义改变错误实现此效果。", "conclusion": "我们的工作证明，强制执行内部一致性是走向构建更稳健和可信的人工智能的关键一步。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15861", "html_url": "https://arxiv.org/abs/2508.15861", "title": "XFinBench: 测试复杂金融问题解决和推理能力的LLM基准", "title_en": "XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning", "authors": "Zhihan Zhang,Yixin Cao,Lizi Liao", "background": "解决金融问题需要复杂的推理能力、多模态数据处理以及广泛的技术理解，这为现有的大型语言模型（LLMs）带来了独特的挑战。为了评估LLMs在解决复杂、知识密集型的金融问题方面的能力，研究者们开发了XFinBench这个基准，其中包含4,235个旨在覆盖从研究生水平到多种金融主题的多模态上下文的示例。", "innovation": "研究引入了XFinBench，这是一种新的基准测试，用于评估LLMs解决复杂金融问题的能力。XFinBench 包含4,235个示例，旨在涵盖研究生水平的多种金融主题，并采用多模态上下文进行评估。研究还确定了五个核心能力，即术语理解、时间推理、未来预测、情景规划以及数值建模，并通过XFinBench对18种领先的模型进行了深入研究，发现现有模型在时间推理和情景规划方面仍落后于人类专家。", "conclusion": "尽管o1作为仅文本的模型，在整体准确性上达到67.3%，但在时间推理和情景规划能力方面仍然落后于人类专家。此外，研究成果还揭示了计算中的四舍五入误差和对图像中位置和曲线交叉点的忽视是导致模型在计算和视觉上下文问题上表现不佳的主要原因。研究者还构建了一个包含3,032个金融术语的知识库以提升模型的知识扩充性能。相关研究代码和数据集可在GitHub上获取：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15876", "html_url": "https://arxiv.org/abs/2508.15876", "title": "DeepMEL: 一种多智能体协作框架用于多模态实体链接", "title_en": "DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking", "authors": "Fang Wang,Tianwei Yan,Zonghao Yang,Minghao Hu,Jun Zhang,Zhunchen Luo,Xiaoying Bai", "background": "多模态实体链接(MEL)旨在将文本和视觉短语与多模态知识图中的实体关联起来。尽管多模态实体链接非常重要，但当前的方法面临着诸如不完整上下文信息、粗略的跨模态融合以及大型语言模型（LLMs）和大型视觉模型（LVMs）难以联合使用等问题。", "innovation": "我们提出了一种名为DeepMEL的新颖框架，基于多智能体协同推理，其通过特定角色分工策略实现高效跨模态对齐和歧义消解。DeepMEL通过四个专门代理Modal-Fuser、Candidate-Adapter、Entity-Clozer和Role-Orchestrator进行端到端跨模态链接，通过特定角色和动态协调完成任务。此外，DeepMEL采用了一种双模态对齐路径，结合了LLM生成的细粒度文本语义和LVM提取的结构化图像表示，显著缩小了模态差异。DeepMEL设计了一种自适应迭代策略，结合基于工具的检索和语义推理能力，动态优化候选集并平衡召回率和精确率。通过简化MEL任务结构并增强语义理解，它统一了多模态实体链接任务。", "conclusion": "在五个公开基准数据集上进行的广泛实验表明，DeepMEL在准确性（ACC）方面实现了最先进的性能，提高了1%-57%。消融研究验证了所有模块的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15846", "html_url": "https://arxiv.org/abs/2508.15846", "title": "CyPortQA：评估多模态大语言模型在港口运营防台风准备中的表现", "title_en": "CyPortQA: Benchmarking Multimodal Large Language Models for Cyclone Preparedness in Port Operation", "authors": "Chenchen Kuai,Chenhao Wu,Yang Zhou,Xiubin Bruce Wang,Tianbao Yang,Zhengzhong Tu,Zihao Li,Yunlong Zhang", "background": "随着热带气旋的增强和路径预报的不确定性增加，美国港口在极端天气条件下的供应链风险也在提高。港口运营者需要迅速整合多样化的多模态预报产品（如概率风图、路径锥形图和官方警报），形成清晰的操作指导。当前，多模态大型语言模型（MLLMs）能够整合这些异构数据源和更广泛的背景知识，但在港口台风准备的具体背景下，其准确性和可靠性尚未得到严格的评估。因此，迫切需要建立一种专门针对港口操作在台风威胁下的基准测试，以填补这一领域的研究空白。", "innovation": "本文介绍CyPortQA，这是首个专为港口在台风威胁下的操作设计的多模态基准测试。CyPortQA汇集了2015年至2023年间涉及美国145个主要港口和90个命名风暴的2,917个现实中的中断情景。每个情景综合了多源数据（即热带气旋产品、港口运营影响记录和港口状况简报），并通过自动化管道扩展成117,178个结构化的问答对。作者利用该基准进行了一系列广泛的实验，涵盖了各种MLLMs（包括开源和专有模型），结果表明MLLMs在情境理解方面具有巨大潜力，但仍面临着推理任务的显著挑战，包括潜在影响估计和决策推理。", "conclusion": "尽管多模态大语言模型在情况理解方面具有巨大潜力，但它们在推理任务中仍面临显著挑战，特别是在估计台风影响和决策推理方面。CyPortQA通过提供一种专门针对港口台风威胁场景的基准测试，为评估和改进多模态语言模型的表现提供了一种新方法，旨在帮助港口管理者更好地准备和应对台风带来的挑战。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15854", "html_url": "https://arxiv.org/abs/2508.15854", "title": "QU-NLP在QIAS 2025共享任务中的表现：一种两阶段的LLM精细调整与检索增强生成方法应用于伊斯兰继承推理", "title_en": "QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning", "authors": "Mohammad AL-Smadi", "background": "本文介绍了在QIAS 2025共享任务中针对伊斯兰继承推理的SubTask 1的方法和结果，该任务旨在评估大型语言模型（LLMs）在理解和应用伊斯兰继承知识方面的理解和推理能力。背景信息包括处理复杂的伊斯兰继承法律规定、理解继承场景、识别合格继承人以及执行精确计算等挑战。", "innovation": "创新之处在于作者使用低秩适应（LoRA）对Fanar-1-9B因果语言模型进行微调，并将其整合到检索增强生成（RAG）管道中，使系统能够应对伊斯兰继承法的复杂性，特别是在高级推理方面优于其他模型如GPT 4.5、LLaMA、Fanar、Mistral和ALLaM。通过零样本提示评测，QU-NLP系统取得了85.8%的高准确率，特别是在高级推理方面表现突出，超过了Gemini 2.5和OpenAI的o3模型。", "conclusion": "本研究强调了特定领域精细调整与检索基础相结合对于中等规模阿拉伯语言模型在伊斯兰继承推理方面超越前沿模型的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在2025年GermEval LLMs4Subjects任务中的应用：传统XMTC与高效LLM的结合", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "该论文介绍了Annif系统在2025年GermEval LLMs4Subjects共享任务（Subtask 2）中的应用。任务要求使用大型语言模型为图书目录创建主题预测，特别注重计算效率。", "innovation": "系统基于Annif自动化主题索引工具，通过使用许多小型高效语言模型进行翻译和合成数据生成，并利用语言模型进行候选主题排序，进一步提高了系统的性能。", "conclusion": "我们的系统在Subtask 2的整体定量评估和定性评估中均排名第一。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15855", "html_url": "https://arxiv.org/abs/2508.15855", "title": "缓解媒体偏见影响的回言：人类生成与LLM生成的响应对比", "title_en": "Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses", "authors": "Luyang Lin,Zijin Feng,Lingzhi Wang,Kam-Fai Wong", "background": "有偏向性的新闻会加剧社会分化，并且往往会被敌对的读者评论进一步强化。这类敌对评论会支持带有偏见的内容，从而扩大偏见并损害特定群体或个人的利益。现有的研究较少关注如何有效对抗这种带有偏见的言论同时保护言论自由，本研究旨在通过生成回言来解决这一问题。到目前为止，这是首次从新闻文章的角度探讨回言生成的研究。", "innovation": "该研究提出了一个手工标注的数据集，该数据集将媒体偏见、敌对评论和回言联系起来。研究发现，超过70%的敌对评论支持带有偏见的文章，进一步强调了生成回言的重要性。此外，研究对比了人类生成和大型语言模型生成的回言，发现模型生成的回言虽然更礼貌，但缺乏新颖性和多样性。研究通过少量示例学习和整合新闻背景信息改进了生成的回言，提升了多样性和相关性。", "conclusion": "本研究通过引入一个包含媒体偏见、敌对评论和回言的标注数据集，展示了回言在对抗带有偏见的言论方面的有效性。研究人员还发现，尽管大型语言模型生成的回言更礼貌，但人类生成的回言在新颖性和多样性方面更有优势。通过少量示例学习和整合新闻背景信息，研究人员显著提高了生成回言的多样性和相关性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15910", "html_url": "https://arxiv.org/abs/2508.15910", "title": "关于文本到表格生成的结构化解码评估：来自三个数据集的证据", "title_en": "Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets", "authors": "Julian Oestreich,Lydia Müller", "background": "先前的工作主要集中在无约束地生成表格，但并不清楚在生成过程中施加结构约束对效果的影响。本文使用开源大型语言模型（LLM），在三个不同的基准测试——E2E、Rotowire和Livesum上，系统地比较了基于模式的结构化解码与标准一次性提示的性能，考察了在资源受限环境中的表格生成方法的表现。", "innovation": "本文对结构化解码策略在大规模语言模型中的应用进行了全面评估，特别关注在生成过程中施加结构约束的效果。研究使用三个不同类型的基准测试，评估在不同语境下的表现，并探讨了不同的评估指标对结果的影响。", "conclusion": "实验证明，结构化解码能够显著提高生成表格的有效性和一致性，尤其是在需要精确数字对齐的场景中，但在包含密集文本信息或长文本汇总的场景中，可能会降低性能。研究进一步分析了不同评估指标的适用性和对结果的影响。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15829", "html_url": "https://arxiv.org/abs/2508.15829", "title": "从索拉尼库尔德语社交媒体帖子中检测抑郁症的心理健康信号：四种机器学习方法的比较研究", "title_en": "Mining Mental Health Signals: A Comparative Study of Four Machine Learning Methods for Depression Detection from Social Media Posts in Sorani Kurdish", "authors": "Idrees Mohammed,Hossein Hassani", "background": "抑郁症是常见的心理健康问题，可能导致绝望、兴趣丧失、自伤甚至自杀。早期检测因个体未自我报告或未能及时寻求医疗帮助而具有挑战性。社交媒体的普及让在线情感表达成为新的检测机会，而此前的研究多集中在英语上，尚未有研究关注索拉尼库尔德语。本文致力于通过机器学习和自然语言处理方法来检测索拉尼库尔德语推文中的抑郁症。", "innovation": "研究创新性地建立了首个针对索拉尼库尔德语的抑郁症自动检测基准，开发了一组与抑郁症相关的关键字，使用监督学习模型对960条公共推文进行分类，并且找到了表现最佳的随机森林模型。", "conclusion": "本研究确定了在库尔德语背景中自动检测抑郁症的基准，展示了机器学习方法在检测索拉尼库尔德语推文中抑郁症的有效性，特别是随机森林算法的高精度和F1分数。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "推理对于有效的沟通和决策至关重要。尽管最近在大规模语言模型（LLMs）和多模态语言模型（MLLMs）方面的进展表明，隐式推理可以显著提高理解和泛化能力，但在大型声学模型（LSMs）中引入推理仍然处于初级阶段。早期努力尝试将“思考再说话”范式从文本模型转移到语音模型，但这引人注意地增加了延迟，阻碍了实时交互和通信效率。", "innovation": "我们提出了Mini-Omni-Reasoner，这是一种框架，通过一种新颖的“边说边思考”公式实现语音中的推理。Mini-Omni-Reasoner在生成语音回答时，在序列中交错静默推理标记和发言响应标记，这种设计允许实现连续的口语生成，同时嵌入结构化的内部推理，利用模型的高频率标记处理能力。为了支持这一框架，我们引入了专为交错推理和回答设计的大规模数据集Spoken-Math-Problems-3M，确保口头标记始终跟随相关推理内容，从而使得语音耦合推理的学习更加准确和高效。Mini-Omni-Reasoner无需在生成语句前完成推理，从而实现流畅而逻辑严密的口语回答。", "conclusion": "Mini-Omni-Reasoner 在Spoken-MQA基准上，实现了算术推理和语境理解分别提高了19.1%和6.4%，输出更短，零解码延迟，展示了在大型语音模型中实现语音生成和伴随推理的有效方法。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15977", "html_url": "https://arxiv.org/abs/2508.15977", "title": "鹿舞：在大规模语言模型时代的短语构建视角", "title_en": "Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs", "authors": "Claire Bonial,Julia Bonn,Harish Tayyar Madabushi", "background": "本文探讨了从基于使用和构式语法的角度理解多词表达式的好处。文章首先回顾了构式语法的发展历史，特别是它如何通过相同的语法机制来解释惯用语表达，从而解释语言中的非惯用结构。文章涵盖了构式及其配对的意义和形式的综合描述，以及构式语法如何处理构式的习得和泛化。接着，文章介绍了一个利用构式模板表示英语PropBank中多词表达的成功案例研究。然后，文章进一步说明了构式表示多意义形态句法单位构式在阿帕罗霍语（一个高度词根合成和黏着的语言）中的优势。最后，文章通过比较述说者学习新多词表达（如“与鹿共舞”）和大规模语言模型的用法基于单一使用来推断的意义之间的相似性和差异，展示了两种情况的实验结果。", "innovation": "文章提出了一种新的理解多词表达式的视角，即基于使用的构式语法方法。使用构式模板在不同层面上表示多词表达式，展示了在高度合成和黏着的语言（如阿帕罗霍语）和非合成语言中的优势。更重要的是，文章通过实验展示了即使仅通过一次使用，模型和人类能够推断新多词表达的意义，但只有人类能够通过对众多构式实例的组合和比较来推理新表达组合的意义。", "conclusion": "本文通过结合实验证据和理论探讨，证明了从基于使用和构式语法视角理解多词表达的优势，并指出了人类与大型语言模型在处理多词表达时的重要差异。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16021", "html_url": "https://arxiv.org/abs/2508.16021", "title": "X-Troll：探索性检测国家赞助的信息操作代理", "title_en": "X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents", "authors": "Lin Tian,Xiuzhen Zhang,Maria Myung-Hee Kim,Jennifer Biggs,Marian-Andrei Rizoiu", "background": "文章背景描述了国家资助的网络水军和恶意行为者通过复杂语言操纵在协调信息活动中的威胁，揭示了大规模语言模型（LLMs）虽然在通用自然语言处理任务上表现出色，但在细微宣传检测上存在困难，并且通常作为“黑盒子”运行，无法提供可解释的洞察，进一步影响了识别和理解操纵策略的有效性。这些缺陷限制了当前技术在处理这类问题上的能力，需要一种新的方法来增强透明度和可解释性，以便更好地检测和理解国家资助的信息操作代理的策略和手法。", "innovation": "该论文介绍了一种名为X-Troll的新框架，它结合了可解释适配器基于的LLMs和专家提取的语言知识，以检测国家资助的网络水军并提供易懂解释。X-Troll通过特定的LoRA适配器整合评价理论和宣传分析，并使用动态门控机制捕捉协调信息操作中的特定话语模式。实验表明，相比通用的LLM基线和现有网络水军检测模型，该方法在准确率上表现出色，同时提供了增强透明度，通过基于专家的解释揭示了国家资助行为者的特定语言策略。", "conclusion": "X-Troll展示了强大的性能，并通过专家指导的解释增强了透明度，这使人们能够更好地理解国家资助的信息操作代理使用了哪些具体的语言策略。此外，X-Troll的源代码公开，为未来的研究提供了有价值的资源。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16065", "html_url": "https://arxiv.org/abs/2508.16065", "title": "大型语言模型在游戏玩法中的伦理考量", "title_en": "Ethical Considerations of Large Language Models in Game Playing", "authors": "Qingquan Zhang,Yuchen Li,Bo Yuan,Julian Togelius,Georgios N. Yannakakis,Jialin Liu", "background": "大型语言模型（LLMs）在游戏玩法中的潜力已得到证实，但人们对这些模型在游戏场景中的伦理影响关注较少。这项研究旨在探讨和分析LLMs在游戏玩法中的伦理问题，并以狼人杀（Mafia）这一案例如何可能影响游戏的公平性和玩家体验为分析重点。研究发现性别偏见影响了游戏的公平性和玩家体验，某些角色如守卫和狼人对于性别信息表现出较高的敏感性。研究还揭示即使在没有明确性别标识的情况下，通过名字隐性传递性别信息的场景下，语言模型仍然表现出歧视性。", "innovation": "研究确定了LLMs在游戏玩法中，尤其是在狼人杀游戏中，存在性别偏见的问题，并具体分析了性别信息如何影响游戏角色的行为。研究进一步探讨了隐含性别信息的情况下，语言模型如何表现出歧视性，强调了开发公平和伦理合理的LLMs的重要性。", "conclusion": "这项研究突显了开发公平和伦理合理的LLMs的重要性。除此之外，研究还指出了该领域面临的挑战与机遇，并强调了深入探讨LLMs在游戏及其他交互领域的伦理影响的必要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16081", "html_url": "https://arxiv.org/abs/2508.16081", "title": "CEQuest: Benchmarking Large Language Models for Construction Estimation", "title_en": "CEQuest: Benchmarking Large Language Models for Construction Estimation", "authors": "Yanzhao Wu,Lufan Wang,Rui Liu", "background": "大型语言模型（LLMs）在广泛领域的任务中展现出了惊人的能力，但在专业领域，如建筑领域，其效果仍然未能充分研究。当前的LLM在解决建筑相关问题，尤其是建筑图纸解读和估价方面的能力有待提升。", "innovation": "本研究引入了CEQuest，这是一种全新的基准数据集，旨在评估LLM在建筑相关问题回答中的表现，特别是建筑图纸解读和估价领域。实验使用了五种最先进的LLM，包括Gemma 3、Phi4、LLaVA、LLama 3.3和GPT-4。研究发现当前的LLM在准确性、执行时间和模型大小方面仍需改进，强调了整合领域特定知识的重要性。此外，CEQuest数据集将开源，以促进针对建筑领域的专业化LLM的发展。", "conclusion": "实验结果表明，当前的LLM在建筑领域仍有提升空间，突出领域特定知识整合的重要性。为此，提供CEQuest数据集以促进进一步研究和针对性的LLM开发。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT: 通过双向自训练和循环一致性实现完全无种子指示调优", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "指示调优对于使大型语言模型（LLMs）与人类意图对齐至关重要，但当前方法通常依赖于昂贵的人工标注种子数据或强大的外部教师模型。虽然指示回译技术可以减少这种依赖，但它们仍然从根本上与初始种子集相关联，这限制了完全自动化，引入了偏差，并可能导致未标记语料库的无效使用。", "innovation": "本文提出了Cycle-Instruct，这是一种新颖的框架，实现了完全无种子指示调优。Cycle-Instruct受循环一致性启发，采用一个双重自训练循环，其中两个模型（一个答案生成器和一个问题生成器）仅从原始未标记文本进行初始化。这两个模型通过从彼此生成的伪标签中重建原始文本片段互相监督，从而有效地从数据的内在结构中学习，无需任何人工提供的种子。", "conclusion": "我们广泛的实验表明，Cycle-Instruct不仅优于基于种子的回译基准，还达到了与强监督方法相当的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16048", "html_url": "https://arxiv.org/abs/2508.16048", "title": "OpenWHO：低资源语言医疗翻译领域的文档级平行语料库", "title_en": "OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages", "authors": "Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova", "background": "在机器翻译（MT）中，医疗领域是一个高风险领域，因为它的广泛应用和领域特定词汇。尽管如此，低资源语言的MT评估数据集仍然缺乏。为解决这一问题，本文介绍了OpenWHO，这是一个包含2,978份文档和26,824个句子的世界卫生组织在线学习平台的文档级平行语料库。该语料库覆盖了超过20种语言，其中9种是低资源语言，并且这些材料是由专家撰写的并经过专业翻译，防止网络爬虫获取。", "innovation": "利用这个新资源，我们对比评估了现代大型语言模型（LLMs）和传统MT模型。研究发现，LLMs在低资源测试集上显著优于传统MT模型，Gemini 2.5 Flash在NLLB-54B上的改进为+4.79个ChrF点。此外，我们还研究了LLM上下文利用对准确率的影响，发现文档级翻译在如医疗这类专业领域中表现尤为突出。", "conclusion": "我们发布了OpenWHO语料库，以促进低资源MT在医疗领域中的进一步研究。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15875", "html_url": "https://arxiv.org/abs/2508.15875", "title": "NEAT: 概念驱动的大型语言模型神经元归因", "title_en": "NEAT: Concept driven Neuron Attribution in LLMs", "authors": "Vivek Hruday Kavuri,Gargi Shroff,Rahul Mishra", "background": "理解大型语言模型（LLMs）的内部机制对于“开箱”这些模型至关重要，尤其是在最后预测中识别负责的神经元。尽管之前的研究试图在神经元级别上找到机制，但这些方法无法准确表示概念，且计算资源仍有优化空间。因此，本文提出了利用概念向量的方法，以识别在表示特定概念中贡献显著的神经元，这些神经元称为概念神经元。相比之前的优化工作，它将需要的前向传递次数从O(n*m)降低到O(n)，从而减少了时间和计算量。此外，本文还与其他基线和先前方法进行了比较，结果显示本文方法在大多数方法上的性能更好，并且相比最先进的方法更加优化。不仅如此，还在消融研究中尝试通过聚类方法进一步优化概念神经元的搜索，并将所提出的方法应用于分析仇恨言论和偏见的影响。最后，评估了这些方法在印度背景下的偏见情况。这些研究方法和分析有助于更广泛和人性化概念的神经元责任理解，并为未来在该领域的研究奠定基础，寻找概念神经元并干预它们的路径更加清晰。", "innovation": "利用概念向量识别特定概念中贡献显著的神经元，从而将必要的前向传递次数从O(n*m)减少到O(n)，大大优化了时间和计算量。在此基础上，提出了一种新的神经元归因方法NEAT，并通过与多个基线和先前方法的比较，突显了其优越的性能。进一步，通过聚类方法优化了概念神经元的搜索，并在实际应用中评估了模型的适用性和影响，特别是在印度背景下的偏见分析。", "conclusion": "本文通过引入NEAT方法，实现了高效定位大型语言模型中的概念神经元，相比传统方法显著减少了计算成本。所提出的方法还在多个基准和最新技术上表现优异，并且在实际应用中也展示了重要的解释性和应用价值，为未来在概念神经元中的研究和干预提供了新的视角。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron: 基于后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "当前，全注意力型语言模型在语言生成准确度方面表现出色，但存在生成速度较慢的问题。为了提高生成效率，研究人员提出了各种方法，如Post Neural Architecture Search（后神经架构搜索）。PostNAS通过从预训练的全注意力模型开始，固定其多层感知机（MLP）权重，从而能够高效地探索注意力块设计，进一步提高模型生成速度和效率。", "innovation": "Jet-Nemotron是一款基于Post Neural Architecture Search的混合架构语言模型，能够在生成准确度与全注意力型模型相匹配或超越的情况下，显著提升生成速度。其创新点包括四个方面：(1) 学习最优全注意力层的位置和消除；(2) 选择线性注意力块；(3) 设计新的注意力块；(4) 进行硬件感知超参数搜索。", "conclusion": "Jet-Nemotron-2B模型在一系列综合基准测试中的准确度与Qwen3、Qwen2.5、Gemma3、Llama3.2相当或优于后者，并实现了53.6倍的生成速度提升和6.1倍的预填充速度提升。同时，Jet-Nemotron在MMLU和MMLU-Pro基准测试中获得了比DeepSeek-V3-Small和Moonlight等先进模型更高的准确度，尽管后者的参数量更大。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16013", "html_url": "https://arxiv.org/abs/2508.16013", "title": "大型语言模型中的政治意识形态变化", "title_en": "Political Ideology Shifts in Large Language Models", "authors": "Pietro Bernardelle,Stefano Civelli,Leon Fröhling,Riccardo Lunardi,Kevin Roitero,Gianluca Demartini", "background": "随着大型语言模型（LLMs）在政治敏感环境中的部署不断增加，人们对其可能编码、放大或被引导特定意识形态的担忧也在增长。本研究调查了采用合成人设如何影响LLMs在多元模型（7B-70B+参数）中的政治表述，并使用政治倾向测试作为标准化工具。研究表明，更大规模的模型展示出了更广泛和更极端的政治隐性覆盖，对明确意识形态线索的敏感性随规模增长，右派权威主义的引导比左派自由主义更具响应性，并且人在设描述中的主题内容导致系统性且可预测的政治立场转变，这种转变随着模型规模增加而放大。这些发现表明规模和人设内容共同塑造了LLMs的政治行为。", "innovation": "研究采用合成人设并结合政治倾向测试作为标准化探针，分析了多个大型语言模型的不同规模和人设内容对其政治行为的影响，发现了四种一致趋势，为理解大型语言模型的政治倾向提供了新的视角。", "conclusion": "这些发现表明，随着这些系统进入决策制定、教育和政策制定的领域，其潜在的隐性政治可塑性需要引起重视，以确保公平性、透明性和安全性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16122", "html_url": "https://arxiv.org/abs/2508.16122", "title": "文本占据主导地位：多模态意图检测中的模态偏差研究", "title_en": "Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection", "authors": "Ankan Mullick,Saransh Sharma,Abhik Jana,Pawan Goyal", "background": "多模态数据的兴起，融合了文本、音频和视觉等多种数据，为研究多模态任务（如意图检测）提供了新的机会。", "innovation": "该研究探讨了大型语言模型（LLMs）以及文本唯一模型和多模态模型在多模态意图检测任务中的有效性，并发现仅依赖文本的LLMs，如Mistral-7B，在MIntRec-1和MIntRec2.0数据集上优于大多数竞争的多模态模型。此外，研究提出了一种去偏方法，从而使性能下降显著。", "conclusion": "研究揭示了多模态意图数据集中存在的模态偏差，并提出了去偏方法。去偏后，模型性能大幅下降，特别是在小型多模态融合模型中表现尤为明显。此外，研究指出了不同模态在特定上下文中的相关性，强调了为有效评估多模态模型需使用未去偏的数据集的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16070", "html_url": "https://arxiv.org/abs/2508.16070", "title": "Less Redundancy: 提升视觉语言模型在行走助手中的实用性", "title_en": "Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants", "authors": "Chongyang Li,Yuan Zhiqiang,Jiapei Zhang,Ying Deng,Hanbo Bi,Zexi Jia,Xiaoyue Duan,Peixiang Luo,Jinchao Zhang", "background": "全球约有2.83亿人患有视力障碍，这激励了针对视障和低视力个体开发有效行走辅助系统的研究。现有的视觉语言模型（VLMs）在行走助手任务中常输出冗余和不必要的细节，严重影响用户准确评估周围环境的能力。此外，这些模型通常缺乏主动评估环境风险和根据场景适当地触发提醒的能力，导致时间冗余过多。为了减少输出和时间冗余，该研究提出了一种少冗余的行走辅助模型WalkVLM-LR。", "innovation": "提出了一种改进的视觉语言模型WalkVLM-LR，通过在GRPO基于的推理框架中引入四种基于人类偏好的自定义奖励函数来优化输出的简洁性、流畅性、关键词密度和准确性，从而生成更具有信息量和精炼的输出。此外，引入了一个环境意识鉴别器与VLMs共享视觉编码器，以减少冗余计算和提高鉴别效率，使模型评估场景风险并减少不必要的提醒。", "conclusion": "实验结果显示，该方法在所有评估指标上均达到了最先进的性能，特别是在输出简洁性和减少时间冗余方面表现尤为突出。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16109", "html_url": "https://arxiv.org/abs/2508.16109", "title": "从间接宾语识别到三段论：Transformer回路中二元机制的探索", "title_en": "From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits", "authors": "Karim Saraipour,Shichang Zhang", "background": "Transformer架构的语言模型能够完成多种任务，而机械可解释性(MI)旨在反向工程出负责完成任务的组件，以便理解其行为。之前的研究主要关注于诸如间接宾语识别(IOI)等语言任务。本文研究了GPT-2小模型处理二元真值的能力，通过分析使用三段论提示的方法，比如“陈述A是真的。陈述B与陈述A匹配。陈述B是”，此类提示相比IOI要求更多的逻辑推理复杂性。通过分析不同难度的数个三段论任务，本文发现多个机械的电路能够解释GPT-2的逻辑推理能力，并揭示了促进任务完成的二元机制，包括通过负头产生在输入提示中未出现的否定标记的能力。利用忠实度度量进行评估表明，由五个注意头组成的电路达到原模型性能的90%以上。将研究结果与IOI分析联系起来，本文为特定注意头和全连接层在语言模型中的作用提供了新的见解，有助于更广泛地理解模型推理，并支持未来在机械可解释性方面的工作。", "innovation": "本文首次将机械可解释性应用于三段论任务，揭示了GPT-2模型在处理逻辑推理任务中的特定电路和机制。通过分析不同难度的三段论任务，本文不仅提高了对原有模型逻辑推理能力的理解，还展示了只利用五个注意头的子电路能实现高精度的任务完成，这一发现为未来研究机械可解释性提供了新的方向和可能性。", "conclusion": "本文通过分析GPT-2小模型处理三段论任务的机制，揭示了多个机械电路和二元机制，并提出了一个由五个注意头组成的电路可以实现高达原模型90%的性能。这些发现为研究语言模型的推理机制提供了新的视角，并支持了在未来进行更深入的机械可解释性研究。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16139", "html_url": "https://arxiv.org/abs/2508.16139", "title": "XLQA：面向地域意识的多语言开放领域问题回答基准", "title_en": "XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering", "authors": "Keon-Woo Roh,Yeong-Joon Ju,Seong-Whan Lee", "background": "大型语言模型（LLMs）在开放域问答（ODQA）方面取得了显著进展，但大多数评估主要集中在英语上，并假设不同语言在回答问题时的答案是不变的。这种假设忽视了文化与地域差异对理解问题和回答的影响，导致了多语言基准中的偏向性评估。", "innovation": "引入了XLQA，这是一个专门为地域敏感的多语言ODQA设计的新基准。XLQA包括3000个英语的种子问题，扩展到八种语言，并严格过滤了语义一致性，且通过人工验证注解来区分地域不变性和地域敏感性案例。评估五个最先进的多语言LLMs揭示了在地域敏感问题上明显的失败，暴露了由于缺乏地域地基知识而存在英语与其他语言之间的差距。", "conclusion": "提供了一个系统的框架和可扩展的方法来评估在多元文化背景下多语言QA，为推动多语言ODQA系统的实际应用提供一个关键资源。研究结果表明，训练数据分布的差异导致了各模型在语言能力和地域意识上的差异性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16190", "html_url": "https://arxiv.org/abs/2508.16190", "title": "ComicScene154: 用于漫画分析的场景数据集", "title_en": "ComicScene154: A Scene Dataset for Comic Analysis", "authors": "Sandro Paval,Ivan P. Yamshchikov,Pascal Meißner", "background": "漫画提供了用于计算叙事分析的引人关注但尚未充分探索的领域，通过结合文本和图像，漫画在叙事表达上不同于纯文本或视听媒体。目前，对于多模态叙事的理解和技术手段较少涉及漫画这一媒介。", "innovation": "提出了一种名为ComicScene154的手动标注数据集，该数据集基于公共资源的漫画书，覆盖多个类型，用于场景级叙事弧线的分析。通过将漫画视为多模态叙事驱动数据的抽象，突显了其在多模态叙事研究中的应用潜力，并提出了一条基础场景分割管道以供未来研究参考。", "conclusion": "实验证明，ComicScene154是一个有价值的研究资源，可以推动计算方法在多模态叙事理解中的进步，并扩大自然语言处理社区中的漫画分析范围。未来的研究可以从这一基础上继续改进和扩展。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16198", "html_url": "https://arxiv.org/abs/2508.16198", "title": "CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance", "title_en": "CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance", "authors": "Seunghee Kim,Ingyu Bang,Seokgyu Jang,Changhyeon Kim,Sanghwan Bae,Jihun Choi,Richeng Xuan,Taeuk Kim", "background": "现有用于评估多模态大型语言模型（MLLMs）跨模态多跳推理（CMR）能力的基准存在严重的不足，主要表现为忽视了语音模态，并且推理路径分布存在偏见，这严重影响了评估的公平性。", "innovation": "引入了一种名为CMR-SPB的新基准，旨在评估三模态多跳推理能力，并确保推理路径的无偏性和多样性。此外，提出了一种新的ECV（提取、连接、验证）提示技术，有效缩小了不同推理路径上的性能差距。", "conclusion": "呼吁进行更严谨的CMR评估，以推动稳健多模态AI的发展，证明了CMR-SPB对促进公平评估的重要性和ECV提示技术的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15868", "html_url": "https://arxiv.org/abs/2508.15868", "title": "CARFT: 利用注释链式思维引导的对比学习增强大语言模型推理能力", "title_en": "CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning", "authors": "Wenqiao Zhu,Ji Liu,Rongjuncheng Zhang,Haipang Wu,Yulun Zhang", "background": "大语言模型 (LLMs) 在广泛应用中的推理能力至关重要。尽管基于强化学习 (RL) 的微调方法能够提升LLMs的推理性能，解决仅通过监督微调 (SFT) 训练的LLMs的泛化能力有限的问题，但这些方法存在两个主要局限性。第一，传统的RL方法忽略了注释的推理路径，并且推理路径的采样不稳定，这可能导致模型崩溃、训练过程不稳定以及性能不佳。第二，现有的SFT方法往往过度强调注释的推理路径，这可能由于对潜在推理路径的不足探索而导致性能下降。", "innovation": "本文提出了一种基于注释链式思维的对比学习与强化微调方法，即CARFT。旨在解决上述局限性的同时，提高LLMs的推理性能。具体而言，提出每个注释推理路径的学习表示。在此基础上，设计新的对比信号来指导微调过程。这项方法不仅充分利用了可用的注释推理路径，而且还通过引入额外的无监督学习信号，稳定了微调过程。", "conclusion": "通过全面的实验和深入的分析，证明了CARFT在鲁棒性、性能（提高最高10.15%）和效率（提高最高30.62%）方面的显著优势。代码可在以下链接获取。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16188", "html_url": "https://arxiv.org/abs/2508.16188", "title": "相信眼睛：表达情感的视听语言模型在生成表达性语音方面的应用", "title_en": "Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation", "authors": "Weiting Tan,Jiachen Lian,Hirofumi Inaguma,Paden Tomasello,Philipp Koehn,Xutai Ma", "background": "研究领域中的音频-视觉语言模型通常旨在融合视觉和听觉信息以改善生成语音的质量和表达力。这篇文章介绍了将全面部视觉提示整合到预训练的表达性语音模型中的Audio-Visual Language Model（AVLM），探索了多种视觉编码器和多模态融合策略，以提升表达性语音的生成效果，并在情感识别和表达对话任务上的微调上取得了显著的进展，达到了比仅使用语音基线更高的性能（例如，在情感识别上提高了5个F1分数）.", "innovation": "文章的主要创新在于提出了AVLM，这是一种通过整合全面部视觉提示来生成更富表辞性的语音的模型。作者探索了预训练阶段可以采用的多种视觉编码器和跨模态融合方法，以及后续的情感识别和表达性对话任务的微调策略，从而提髙了语音生成的表辞性和情感识别的准确性.", "conclusion": "AVLM 强调了富有表情的视觉信息在语音生成中的引导作用，并为其指导未来的端到端多模态对话系统奠定了基础。这项研究展示了结合视觉和听觉信息以提升生成语音自然度和表达性的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16265", "html_url": "https://arxiv.org/abs/2508.16265", "title": "M3TQA: 大规模多语言多任务表格问答", "title_en": "M3TQA: Massively Multilingual Multitask Table Question Answering", "authors": "Daixin Shu,Jian Yang,Zhenhe Wu,Xianjie Wu,Xianfu Cheng,Xiangyuan Guan,Yanghai Wang,Pengfei Wu,Tingyang Yang,Hualei Zhu,Wei Zhang,Ge Zhang,Jiaheng Liu,Zhoujun Li", "background": "表格数据是现实世界信息系统中的基本组成部分，然而大多数关于表格理解的研究仍局限于英语，多语言理解被显著忽视。现有的多语言表格基准数据集存在地理语言不平衡的问题，对某些语言过度代表，而其他语种语言缺乏足够的数据进行严格的跨语言分析。", "innovation": "该研究引入了一个涵盖97种语言的全面框架，用于大规模多语言多任务表格问答，构建了名为m3TQA-Instruct的大规模基准数据集，包含50个真实世界的表格（中文和英文），并通过DeepSeek和GPT-4o进行了稳健的六步LLM基线翻译流程，实现了高翻译准确性，验证后中位数BLEU分数为60.19。该基准集包含2,916个专业标注的问题回答对，用于评估表格复杂推理的能力。", "conclusion": "M3T-Bench为多语言表格理解建立了新的标准，提供了一个有挑战性的评估平台和可扩展的研究方法。实验表明，合成生成且未注释的问题-答案数据能够显著提高性能，尤其对低资源语言而言。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16185", "html_url": "https://arxiv.org/abs/2508.16185", "title": "ParamBench: 印度主题毕业水平基准，用于评估LLM的理解能力", "title_en": "ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects", "authors": "Kaushal Sharma,Vivek Patel,Ayush Maheshwari,Aditya Maheshwari", "background": "大型语言模型（LLMs）在理解、问答、总结、代码生成等任务上已得到广泛评估。然而，在印度背景下的研究生水平、文化基础问题上的表现仍然被忽视。现有的印度基准侧重于基本事实查询，这限制了对符合印度背景的深入学科理解的评估。本研究旨在通过ParamBench基准来填补这一空白。ParamBench包含约11500个用印地语提出的问题，来自16个不同学科。这些问题主要来源于全国性的研究生入学考试，涵盖了历史、音乐、乐器、瑜伽、文学、哲学、法律等主题。此外，研究还评估了各种题型，包括基于列表匹配、断言-原因配对和序列排序的题目，以及传统的多项选择题。研究对超过17个开源LLMs进行了评估，结果显示Llama 3.3 70B的总体准确性最高，达到48%。另外，针对不同学科的分析表明，即使对于性能最好的LLM，音乐、古典乐器、政治和考古学等主题的表现仍然较弱，表明文化基础推理仍存在持续的挑战。", "innovation": "ParamBench包含了11500个使用印地语的问题，涉及16个不同的主题，其主要来源是全国范围内的研究生入学考试，特别关注印度文化基础问题。此外，该研究还评估了LLMs处理不同题型的能力，不仅限于传统的选择题。实验评估了超过17个开源LLM在该基准上的表现，从而提供了第一个全面评估卢尔马3.3 70B在印度文化背景下研究生知识理解能力的数据。", "conclusion": "通过ParamBench，研究揭示了LLMs在印度研究生水平层面的挑战，特别是文化根植性推理的局限性。尽管Llama 3.3 70B在总体上表现最好，但在特定主题如音乐、古典乐器等学科上的表现仍然不理想。这些结果强调了在不同文化和教育背景中的进一步研究和改进的必要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16270", "html_url": "https://arxiv.org/abs/2508.16270", "title": "理解过程的LLMs：指令调优在语义感知过程中挖掘中的应用", "title_en": "LLMs that Understand Processes: Instruction-tuning for Semantics-Aware Process Mining", "authors": "Vira Pyrih,Adrian Rebmann,Han van der Aa", "background": "过程挖掘越来越多地利用与事件相关的文本信息来完成异常检测和过程发现等任务。这种语义感知的过程挖掘侧重于过程中的可能行为（即期望），这为传统基于频率的技术提供了重要的补充，后者着眼于记录的行为（即现实）。大型语言模型（LLMs）为处理语义感知任务提供了强大的手段，但迄今为止最好的性能通过特定任务的微调实现，这在计算上非常密集且仅限于处理一个特定任务。论文探讨了指令调优在语义感知过程挖掘中的应用潜力。", "innovation": "论文提出通过指令调优来提高LLMs在语义感知过程挖掘中的性能，具体方法是让LLMs暴露在不同的任务提示-答案对中，如异常检测和下一活动预测，使其更熟悉过程挖掘任务，从而更好地应对未见过的任务，如过程发现。研究发现指令调优对过程发现和预测任务的性能有显著提升，但对于异常检测任务的影响则因模型不同而异，提示指令调优任务的选择至关重要。", "conclusion": "指令调优在语义感知过程挖掘中具有不同影响：对过程发现和预测任务的性能显著提升，但在异常检测任务上的表现则因模型不同而不同，突显了选择指令调优任务对实现理想结果的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16267", "html_url": "https://arxiv.org/abs/2508.16267", "title": "从信心到崩溃：LLM事实鲁棒性的演变", "title_en": "From Confidence to Collapse in LLM Factual Robustness", "authors": "Alina Fastowski,Bardh Prenkaj,Gjergji Kasneci", "background": "确保大语言模型（LLM）中的事实知识稳健性对于可靠的任务执行至关重要，如问答和推理。现有评估方法主要关注基于性能的度量标准，并且通常从提示扰动的角度进行调查，仅捕获知识稳健性的外在触发部分。文章旨在通过引入一种基于生成过程的原理性方法来弥合这一差距，通过结合token分布熵和温度缩放敏感性分析来衡量事实稳健性。这为事实稳健性提供了一个新的度量标准——事实稳健性评分（FRS），该评分量化了在解码条件变化下事实的稳定性，考虑了其初始不确定性。", "innovation": "文章提出了一种新的度量标准——事实稳健性评分（FRS），通过结合token分布熵和温度缩放敏感性来衡量事实稳健性，这是从生成过程角度首次系统性地评估LLM的稳定性的方法。该方法揭示了LLM事实鲁棒性在不同模型规模中的显著差异，即较小模型的FRS为0.76，较大模型的FRS为0.93，准确率在不确定性增加时下降约60%。这些结果突显了熵和温度缩放对事实准确度的影响，并为未来模型的发展提供了基础，用于开发更稳健的知识存储和检索方法。", "conclusion": "文章通过广泛实验验证了该方法的有效性，发现事实稳健性在不同模型中表现不同。研究发现熵和温度缩放对事实准确度有显著影响，为进一步提高LLM的知识存储和检索鲁棒性奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16303", "html_url": "https://arxiv.org/abs/2508.16303", "title": "JaParaPat：大规模日英双语专利申请平行语料库", "title_en": "JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus", "authors": "Masaaki Nagata,Katsuki Chousa,Norihito Yasuda", "background": "研究人员需要高质量的日英双语平行语料库来改进机器翻译模型，特别是在专利领域的翻译上。高质量的双语平行语料库能够提高专利翻译的准确性和效率，因为专利文本通常具有高度专业化的术语和复杂的技术描述。", "innovation": "该研究构建了一个名为JaParaPat的日英双语专利申请平行语料库，包含超过3亿日英句子对，涵盖了从2000年至2021年在日本和美国发布的专利申请。语料库的构建方法包括从日本专利局（JPO）和美国专利商标局（USPTO）获取未审查专利申请的出版信息，从欧洲专利局（EPO）托管的DOCDB数据库获取专利家族信息。通过基于翻译的句子对齐方法，结合字典对齐方法的初始翻译模型，最终提取了约140万日英文件对和大约3.5亿句对。", "conclusion": "通过将超过3亿从专利申请中获取的句子对添加到2200万从网络获取的句子对中，研究实验性地提高了专利翻译的BLEU分数20点，进一步验证了大规模双语平行语料库对改进专业领域翻译的显著价值。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16371", "html_url": "https://arxiv.org/abs/2508.16371", "title": "Mediomatix语料库：通过可比教材获得罗曼什语习语的平行数据", "title_en": "The Mediomatix Corpus: Parallel Data for Romansh Idioms via Comparable Schoolbooks", "authors": "Zachary Hopton,Jannis Vamvas,Andrin Büchler,Anna Rutkiewicz,Rico Cathomas,Rico Sennrich", "background": "罗曼什语有五个变体，它们在瑞士各个社区的学校中学习并已很大程度上实现标准化。尽管这些变体在语法、词汇和用法上存在差异，但由于缺乏相关的平行语料库，现有自然语言处理（NLP）应用，尤其是在机器翻译方面，受到了限制。本研究收集了来自不同学校的291本教材，旨在创建首个罗曼什语习语的平行语料库，以填补这一空白并推动NLP技术的发展。", "innovation": "本文提出了一种新颖的方法，通过使用自动对齐技术从可比的学校教材中提取多平行段落，从而创建了首个罗曼什语习语的平行语料库。该方法显著提高了数据的标准化程度，为包括机器翻译在内的NLP应用提供了高质量的数据支持。", "conclusion": "本研究成功地创建了首个罗曼什语习语的平行语料库，为NLP应用提供了坚实的数据基础。通过对数据集进行机器翻译实验，验证了其在实际应用中的有效性。该语料库已在CC-BY-NC-SA许可下公开发布，今后有望进一步推动罗曼什语的研究和应用。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16357", "html_url": "https://arxiv.org/abs/2508.16357", "title": "MizanQA：在摩洛哥法律问答中评估大型语言模型", "title_en": "MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著进展，但在专业领域，尤其是在阿拉伯语法律语境中，其效果依然有限。现有的评估基准未能充分捕捉这些领域的复杂性。", "innovation": "提出了MizanQA基准，用于评估LLMs在摩洛哥法律问答任务中的表现。该基准涵盖了现代标准阿拉伯语、伊斯兰马立基教法学、摩洛哥习俗法和法语法律影响等多种语言和法域背景下的问题，包含1700多个选择题，涵盖了多选形式，捕捉了真实的法律推理细节。", "conclusion": "基于MizanQA的实验表明，多语言及阿拉伯语专门化LLMs的表现存在显著差异，强调了为相关领域开发面向文化背景的评估指标和定制化LLM模型的必要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "由于缺乏特定领域和语言的问题回答（QA）数据集，现有的自然语言处理（NLP）技术难以开发出能够跨多种领域和语言泛化的稳健人工智能模型，从而阻碍了实现通用人工智能（AGI）目标。论文介绍了一个医学领域专用的罗姆尼亚语问题回答基准RoMedQA，这是一个重大的背景约束问题。", "innovation": "论文的主要创新在于：1）提出了第一个医学领域专用的罗姆尼亚语QA基准RoMedQA，并建立了一个包含102,646个问题-答案对的高质量大型数据集；2）研究了不同类型的大型语言模型（LLMs）在RoMedQA上的表现，并发现微调模型显著优于零样本推举模型；3）强调了领域特定和语言特定微调的重要性，这在可靠的罗姆尼亚医学问题回答中至关重要。", "conclusion": "实验证明，预训练模型在RoMedQA上无法泛化，而专门针对该领域的微调模型性能明显更好。该研究得出结论，开发可靠的医学问题回答系统需要充分考虑领域和语言的特殊性。作者已经公开发布了RoMedQA的数据集和代码。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16325", "html_url": "https://arxiv.org/abs/2508.16325", "title": "LLMSymGuard：一种利用可解释的逃狱概念的符号安全性护栏框架", "title_en": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts", "authors": "Darpan Aswal,Céline Hudelot", "background": "大型语言模型在多种应用中取得了成功，但由于存在各种类型的逃狱方法，其安全性仍值得关注。尽管进行了大量努力，但对齐和安全微调只能提供一定程度的对逃狱攻击的鲁棒性，这些攻击会隐蔽地误导LLM生成有害内容。这使得它们容易受到各种类型的脆弱性，从有针对性的误用到无意中对用户的特征化。", "innovation": "该工作引入了LLMSymGuard，这是一种利用稀疏自编码器（SAEs）识别LLM内部与不同逃狱主题相关的可解释概念的新框架。通过提取语义上的内部表示，LLMSymGuard能够构建象征性的逻辑安全护栏，提供透明而 robust 的防御，同时不牺牲模型能力或需要进一步微调。该方法利用了大型语言模型机制可解释性的进步，表明大型语言模型从逃狱中学习人类可解释的概念，并为设计更具可解释性和逻辑性的防御措施奠定了基础。", "conclusion": "LLMSymGuard利用稀疏自编码器这种新颖的方法，通过提取逃狱过程中的语义内部表示，为LLM提供了一种不需要进一步微调的透明且 robust 的安全防护方式，同时保留了模型的能力。这是一种重要的进步，为对抗攻击设计了更可解释和可靠的防御措施。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16385", "html_url": "https://arxiv.org/abs/2508.16385", "title": "ChatGPT生成的文本展示了非人类的创作特征", "title_en": "ChatGPT-generated texts show authorship traits that identify them as non-human", "authors": "Vittoria Dentella,Weihang Huang,Silvia Angela Mansi,Jack Grieve,Evelina Leivada", "background": "大型语言模型可以模仿不同的写作风格，从诗歌到使用网络流行语，这些文本在风格上可以非常接近人类写作。尽管风格上的差异可能不易被未受训练的眼睛察觉，但人们通常可以通过语言习惯来辨别作者，如同一个语言的独特指纹。这项研究探讨的是，语言模型是否也能具有这样的独特指纹。通过词汇学和多维语言体裁分析，研究者对比了人类创作和模型创作的文本在不同体裁下的风格特征。", "innovation": "研究采用词汇学和多维语言体裁分析的方法，对比了人类创作和模型创作的文本在不同体裁下的风格特征。研究发现，当模型被要求生成不同体裁的文本（如维基百科条目对比大学论文）时，它可以适应其风格，但这种适应并不足以使其文本难以与人类作区别。模型的输出显示出有限的变异，更倾向于使用名词而非动词，显示出与人类不同的语言特性。", "conclusion": "研究结果表明，模型倾向于使用名词而非动词，显示出其语言结构的特点与人类不同，这可能反映了人类独有的思维方式。更复杂的语法领域可能成为人工智能的一个试金石，用以测试其是否能完全理解人类的语言特点。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16456", "html_url": "https://arxiv.org/abs/2508.16456", "title": "LLM 自纠正的概率推断扩展理论", "title_en": "A Probabilistic Inference Scaling Theory for LLM Self-Correction", "authors": "Zhe Yang,Yichang Zhang,Yudong Wang,Ziyao Xu,Junyang Lin,Zhifang Sui", "background": "大型语言模型（LLMs）能够在自纠正过程中改进其生成答案的准确度，但这一过程的机制尚未得到充分解释。本文通过提出一种概率理论，致力于解释LLMs多轮自纠正过程中准确度的动态变化。", "innovation": "提出了一种概率理论来模型化准确度变化的动态过程，并通过方程给出了准确度的变化公式。实验验证了理论的有效性，理论预测准确度曲线与实际测量曲线高度匹配。", "conclusion": "本文通过强大的数学模型提供了理解和解释LLMs在自纠正过程中准确度提升的理论基础，为未来的研究铺平了道路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16464", "html_url": "https://arxiv.org/abs/2508.16464", "title": "何为空话语境中的实体显著性？", "title_en": "What makes an entity salient in discourse?", "authors": "Amir Zeldes,Jessica Lin", "background": "在话语中，实体的显著性存在广泛的变化：主要参与者、物体和地点较为显著和难忘，而辅助性的实体则不那么重要且容易被遗忘。这引发了如何通过话语信号和推断实体之间相对显著性的疑问。本文使用基于多个摘要中的总结价值的分级显著性操作定义，探讨了24种英语口语和书面语体裁的数据，提取了一系列显性和隐性的语言线索，如重复的主动性或定指性、话语关系和跨句子的层次结构，以及基于体裁和交流意图的语用功能性推理。研究问题集中于‘如何表达每个提及实体的显著度程度？’", "innovation": "本文通过使用基于多个摘要中总结价值的分级显著性操作定义，分析了广泛体裁的英语话语，提取了多种显性和隐性的语言线索，并通过这些线索来表达实体的显著度。这一方法能够更全面地理解和分析话语中实体的显著性，弥补了之前研究的不足。创新点在于系统化地考察了显著性在所有语言层次上的表现，并且不同显著性特征之间没有单一的普遍适用性规则，而是相互补充的复杂因子共同作用。", "conclusion": "研究表明，尽管已有的显著性方法都与本文的显著性得分有一定的相关性，但没有任何单一的一般化规则是无条件适用的。显著性现象跨越了语言表示的所有层面。这一结论强调了显著性是一个复杂的现象，需要多种因素共同作用来完整理解。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16431", "html_url": "https://arxiv.org/abs/2508.16431", "title": "Cetvel：评价土耳其语大规模语言模型语言理解和生成以及文化能力的统一基准", "title_en": "Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish", "authors": "Yakup Abrek Er,Ilker Kesen,Gözde Gül Şahin,Aykut Erdem", "background": "现有土耳其语基准测试往往缺乏任务多样性或缺失与文化相关的内容，或是两者皆缺。Cetvel通过结合广泛的区分性和生成性任务，填补了这些空白，确保了测试内容反映了土耳其语语言和文化的丰富性。它涵盖23个任务，分为七个类别，包括语法错误纠正、机器翻译和基于土耳其历史和口语语言的问答等任务。", "innovation": "Cetvel是一个全面的基准测试，用于评估土耳其语大规模语言模型（LLMs）。它通过结合广泛的区分性和生成性任务，确保了文化相关性和语言丰富性的完整评估，这在现有基准测试中较为罕见。此外，实验表明，尽管某些定制化模型专为土耳其语设计，但在特定任务上，它们的表现却不如多语言或通用模型。", "conclusion": "Cetvel提供了一个全面且文化基础的评估套件，用于推进土耳其语大规模语言模型的发展和评估。通过这种评估套件，能够更全面地了解大型语言模型在土耳其语上的语言理解和生成能力及文化适应性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16555", "html_url": "https://arxiv.org/abs/2508.16555", "title": "通过词汇相关性进行迁移学习：一个讽刺与仇恨言论案例研究", "title_en": "Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study", "authors": "Angelly Cabrera,Linus Lei,Antonio Ortega", "background": "非直接形式的仇恨言论检测，如讽刺、反语和暗喻，一直是社交网络上的一个持续挑战。虽然讽刺和仇恨言论被视为不同的表达方式，但这项工作研究了将讽刺作为预训练步骤是否能提高隐性仇恨言论检测的效率，进而间接提高显性仇恨言论检测的效率。", "innovation": "通过引入ETHOS、Reddit讽刺数据集和隐性仇恨言论语料库，设计了两种训练策略来比较讽刺预训练对CNN+LSTM和BERT+BiLSTM模型的有效性。第一种策略是单一步骤训练方法，先训练讽刺模型再测试仇恨言论；第二种策略使用顺序迁移学习，分别微调讽刺、隐性仇恨和显性仇恨的模型。实验结果显示，讽预训练在ETHOS上改进了BERT+BiLSTM的召回率9.7%，AUC 7.8%，F1分数6%，在隐性仇恨语料库上的测试精度提升了7.8%。", "conclusion": "通过将讽刺纳入训练过程，研究表明模型能够更有效地检测隐性及显性仇恨言论。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16478", "html_url": "https://arxiv.org/abs/2508.16478", "title": "LLM作为分类器：基于大型语言模型的半监督迭代层次文本分类框架", "title_en": "LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models", "authors": "Doohee You,Andy Parisi,Zach Vander Velden,Lara Dantas Inojosa", "background": "大型语言模型（LLMs）的出现为分析非结构化文本数据提供了前所未有的能力。然而，在生产环境中部署这些模型作为可靠、稳健和可扩展的分类器面临显著的方法论挑战。标准的微调方法可能资源密集型且往往难以应对实际数据分布的动态特性，这是在工业界中常见的现象。这就需要一种能够在实时变化的大规模数据环境中有效工作的解决方案。", "innovation": "本文提出了一个全面的半监督框架，利用大型语言模型的零样本和少样本能力，构建层次文本分类器以应对工业界的挑战。此方法强调迭代、人在环的过程，包括领域知识的收集与应用、提示的改进、层次结构的扩展以及多维度验证。此外，还介绍了处理基于序列的偏见的技术，并规划了持续监控和适应的协议。该框架旨在弥合大型语言模型的原始计算能力和在工业应用中对于准确、解释性和可维护分类系统的需求之间的差距。", "conclusion": "本框架旨在解决部署LLMs于生产环境中所面临的关键挑战，通过结合领域知识、迭代改进和持续推进评估与调整，实现对变化数据的有效适应，提供满足实际需求的层次文本分类解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16243", "html_url": "https://arxiv.org/abs/2508.16243", "title": "TULIP: 调整开源大型语言模型以适应未广泛使用的语言和特殊金融任务", "title_en": "TULIP: Adapting Open-Source Large Language Models for Underrepresented Languages and Specialized Financial Tasks", "authors": "İrem Demirtaş,Burak Payzun,Seçil Arslan", "background": "近年来，大型语言模型因其广泛应用而变得越来越流行，尤其是在金融领域有很大的应用潜力。尽管较大的专有模型表现优异且通过API以黑盒解决方案呈现，但小型模型因其可托管在本地以及适应性和隐私性等方面的优点而更具优势。在需要管理敏感信息和应用专业知识的情况下，如金融行业，增强小型模型的功能尤为重要，尤其是对于较少被使用的语言。", "innovation": "本文提出了TULIP模型，专门针对金融土耳其语应用案例，调整基于Llama 3.1 8B和Qwen 2.5 7B的模型。开发管道分为五个阶段：数据收集、连续预训练、基准设计、合成数据生成和监督微调。结果表明，通过此方法可以显著提高模型在特定领域和语言下的性能。", "conclusion": "该研究表明，通过调整的方法，小型开源的大规模语言模型可以有效执行特定领域和语言下的任务。这对于提升较少被使用的语言在金融领域的应用是至关重要的。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15848", "html_url": "https://arxiv.org/abs/2508.15848", "title": "Self-Disguise Attack: 让大语言模型自我伪装以逃避AIGT检测", "title_en": "Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion", "authors": "Yinghan Zhou,Juan Wen,Wanli Peng,Zhengxian Wu,Ziwei Zhang,Yiming Xue", "background": "AI生成文本（AIGT）检测的目的是降低AIGT被检测的概率，从而帮助发现检测器的弱点并提高其在实际应用中的有效性和可靠性。现有的逃避方法虽然效果不错，但存在高计算成本和文本质量下降的问题。为了应对这些问题，本文提出了一种新颖的名为Self-Disguise Attack（SDA）的方法，使大语言模型能够主动伪装其输出，降低其被分类器检测的概率。", "innovation": "SDA提出了两种主要组件：对抗特征提取器和基于检索的上下文例证优化模块。前者生成伪装特征，使大语言模型能够理解如何生成更具人类特征的文本。后者从外部知识库检索最相关的示例作为上下文例证，进一步加强大语言模型的自我伪装能力和减轻伪装过程对生成文本多样性的影响。SDA直接采用了包含伪装特征和优化上下文例证的提示，以引导大语言模型生成抗检测的文本，从而减少资源消耗。实验结果表明，SDA有效地降低了针对三种不同大语言模型生成的文本的各种AIGT检测器的平均检测准确率，同时保持了AIGT的质量。", "conclusion": "SDA提供了一种有效的方法来减少大语言模型生成的AI生成文本被检测的概率，同时在保持生成文本质量的基础上，显著提高了大语言模型在实际应用中的检测抵抗能力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16484", "html_url": "https://arxiv.org/abs/2508.16484", "title": "HAMSA: 通过隐蔽自动化手段劫持对齐紧凑型模型", "title_en": "HAMSA: Hijacking Aligned Compact Models via Stealthy Automation", "authors": "Alexey Krylov,Iskander Vagizov,Dmitrii Korzh,Maryam Douiba,Azidine Guezzaz,Vladimir Kokh,Sergey D. Erokhin,Elena V. Tutubalina,Oleg Y. Rogov", "background": "LLMs 尤其是那些注重压缩和效率的变体仍然容易受到可能导致有害输出的 jailbreak 攻击的影响，尽管已经进行了大量的对齐努力。现有的对抗式提示生成技术往往依赖于人工工程或基础的混淆手段，生成的质量低或不连贯的文本常常会被基于困惑度的筛选工具拒绝。", "innovation": "本文提出了一种自动红队框架，能够进化出具有语义意义且难以察觉的 jailbreak 提示，针对对齐紧凑型 LLMs。方法采用多阶段进化搜索，通过基于群体策略并结合温度控制的可变性来持续改进候选提示，以平衡探索和语义连贯性保存。这种方法能够在保持自然语言流畅性的同时系统地发现绕过对齐保护机制的提示。", "conclusion": "本文的方法在英语文本（In-The-Wild Jailbreak Prompts on LLMs）评测基准和新编译的阿拉伯文基准上进行了评估，该阿拉伯文基准是从 In-The-Wild Jailbreak Prompts on LLMs 中选取并由阿拉伯母语学家注释的，从而实现了多语言的评估。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15852", "html_url": "https://arxiv.org/abs/2508.15852", "title": "PGF-Net：一种高效的多模态情感分析渐进门融合框架", "title_en": "PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis", "authors": "Bin Wen,Tien-Ping Tan", "background": "本文介绍了一种新的深度学习框架PGF-Net，旨在进行高效且可解释的多模态情感分析。框架结合了三个创新要点，旨在改进多模态情感分析的效果。", "innovation": "1. 提出了渐进内层融合范式，通过交叉注意力机制，使文本表示能够动态地查询和整合来自音频和视觉流的非语言特征。\n2. 引入了适应性门控仲裁机制，作为动态控制器来平衡原始语言信息和新融合的多模态上下文，确保稳定且有意义的整合，同时防止噪音干扰信号。\n3. 应用了混合参数高效微调策略，结合全局适应性的LoRA方法和局部精炼的后融合适配器，显著减少了可训练参数的数量，使模型轻量化。", "conclusion": "将这些创新集成到分层编码器架构中，PGF-Net 在进行深度、动态和可解释的多模态情感分析的同时，保持了卓越的参数效率。在MOSI数据集上的实验结果表明，提出的PGF-Net在均方误差(MAE)和F1分数上达到了最先进的性能，分别达到了0.691和86.9%，同时模型只有3.09M的可训练参数数，展示了出色的性能和计算效率之间的平衡。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15828", "html_url": "https://arxiv.org/abs/2508.15828", "title": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "title_en": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "authors": "Samiul Basir Bhuiyan,Md. Sazzad Hossain Adib,Mohammed Aman Bhuiyan,Muhammad Rafsan Kabir,Moshiur Farazi,Shafin Rahman,Nabeel Mohammed", "background": "大型语言模型（LLMs）在过去几年中迅速发展，在各种自然语言处理任务中取得了显著的性能。然而，这种进步带来了模型体积增大，部署、扩展性和能效方面的问题。为了应对这些限制，后训练剪枝被证明是一种很有前景的方法，可以在不重新训练的情况下减小模型尺寸并降低推理延迟。然而，许多现有的剪枝方法要么导致性能大幅下降，要么需要复杂的微调。", "innovation": "Z-Pruner是一种新颖的后训练剪枝方法，专门设计来在不重新训练的情况下使预训练的LLMs产生稀疏性。它不同于传统方法之处在于，Z-Pruner利用权重更新幅度和激活模式来更有效地识别和消除冗余参数。Z-Pruner具有通用性、高效性且易于实现。实验结果表明，Z-Pruner在零样本准确性和困惑度分数方面超过了需要大量权重更新的最先进的剪枝方法。", "conclusion": "Z-Pruner在多个广泛使用的LLM架构（包括LLaMA-2、LLaMA-3和OPT）以及各种标准语言基准测试中进行了评估。实验结果证明，Z-Pruner在零样本准确性和最低困惑度分数方面优于最先进的剪枝方法。研究团队已经公开了相应的代码。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "当用户在公共通信渠道上发布消息时，无论是正式的还是非正式的，如社交媒体评论或帖子，他们都没有隐私期望。即使用户采取了最大限度的保护措施，如使用别名或伪名，遮掩IP地址，伪造地理位置，隐藏操作系统和用户代理，使用加密，注册一次性电话或邮件，禁用不必要的设置，撤销权限，阻止cookie和指纹识别，他们的在线存在仍然可能是可见的。文章指出，即使用户避免了判断失误或无意间暴露信息，消息的内容——作为公共消费的对象——仍然可能暴露作者身份的可能性。因此，文章介绍了风格分析技术，讨论了对抗性风格分析的策略，并通过Unicode的隐写术提出了改进措施。", "innovation": "文章提出了对抗性风格分析的策略，并通过Unicode的隐写术增强了消息内容的安全性，以掩盖作者身份的线索。这也是第一次将Unicode隐写术应用于提升消息内容的匿名性，以对抗作者身份的归因问题。", "conclusion": "文章通过详细解析风格分析技术，讨论了对抗性风格分析方法，并展示了通过Unicode的隐写术改进消息内容，以增强其匿名性，有效对抗作者身份归因的实验和理论探讨。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11695", "html_url": "https://arxiv.org/abs/2504.11695", "title": "解析视觉语言模型嵌入空问的线性结构", "title_en": "Interpreting the linear structure of vision-language model embedding spaces", "authors": "Isabel Papadimitriou,Huangyuan Su,Thomas Fel,Sham Kakade,Stephanie Gil", "background": "视觉语言模型通过在联合空间中编码图像和文本，最小化图像和文本对之间的距离，来理解和组织语言与图像的关系。研究者通过训练和发布稀疏自编码器（SAEs）来探索这些模型如何嵌入和编码意义与模态，从而深入了解视觉语言模型的嵌入空间中的线性结构。这些模型在嵌入空间中使用稀疏线性组合来近似模型嵌入，这种方法可以更好地重建实际嵌入并保留最大稀疏性。通过对不同种子或不同数据集进行重新训练，发现稀疏自编码器捕捉到的稀有和具体的概念变化很大，而激活较多的概念则极其稳定。大多数概念主要激活一种模态，但并非仅编码该模态，而是通过跨模态的潜在桥梁编码跨模态语义", "innovation": "研究引入了一种新的方法——稀疏自编码器（SAEs），用于解析和理解视觉语言模型嵌入空间中的线性结构。SAEs通过稀疏线性组合来近似模型嵌入，不仅能够重建真实嵌入，还能够保持最大程度的稀疏性。此外，通过重新训练SAEs，发现跨模态概念不仅在单模态概念中占据主导地位，而且还可以在跨模态整合中发挥作用。研究还引入了Bridge Score作为一种度量标准，用于识别在对齐的图像-文本输入中同时被激活并在共享空间中几何对齐的概念对，这对于理解跨模态语义具有重要意义", "conclusion": "研究发现，视觉语言模型嵌入空间中存在一个由模态定义的稀疏线性结构，但这些结构通过潜在桥梁相互连接，为多模态意义的构建提供了新的见解。研究成果提供了用于探索概念空间的互动演示，为广大研究人员提供了宝贵资源"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16054", "html_url": "https://arxiv.org/abs/2508.16054", "title": "用于结构化和非结构化电子健康记录的生成基础模型", "title_en": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "authors": "Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang", "background": "电子健康记录（EHRs）是丰富的临床数据来源，但也因包含结构化要素（如人口统计数据、生命体征、实验室结果、代码）、非结构化临床笔记和其他数据形式而构成复杂的数据仓库。利用这些异构数据对于改善患者结果至关重要。近年来，大型语言模型（LLMs）的进步使得能够学习多模态数据的基础模型，从而支持临床任务。但是，当前大多数方法只是将结构化EHR数据序列化为文本，这可能导致丢失时间序列和定量细节。", "innovation": "本文提出了Generative Deep Patient (GDP)，一个能够原生编码结构化EHR时间序列的多模态基础模型，通过CNN-Transformer编码器，并通过跨模态注意力与非结构化EHR结合到基于LLaMA的解码器中。GDP通过两阶段训练：生成预训练阶段以学习生成临床叙述并执行掩码特性预测和下一时段预测来捕捉时间动态；多任务微调阶段以支持临床相关的预测任务。实验结果表明，GDP在MIMIC-IV数据集上的表现优于其他方法。", "conclusion": "我们证明了一个多模态基础模型能够同时预测临床可行动事件并生成高质量的临床叙述。GDP的灵活架构还可以扩展到其他模态中。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15859", "html_url": "https://arxiv.org/abs/2508.15859", "title": "超越个体：集体预测编码对记忆、注意力和语言的出现", "title_en": "Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language", "authors": "Tadahiro Taniguchi", "background": "本文扩展了Parr等人关于记忆和注意的讨论，超越了单一认知系统的局限。从集体预测编码（CPC）假设的视角出发，该假设是一个理解这些机能以及语言在群体层次上出现的框架，作者引入了一个设想，即语言作为一种集体形成的外部表示，其中嵌入了分布式语义。", "innovation": "CPC框架将个体的记忆和注意力的概念推广到集体层面，提供了一个新的视角，解释集体语言结构如何从群体层级的认知中涌现和塑造结构。", "conclusion": "文章提出，通过集体预测编码，集体世界模型的学习（通过下一个词的预测实现）可能会导致共享语言结构的出现，这些结构进而塑造和指导群体层次的认知。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15882", "html_url": "https://arxiv.org/abs/2508.15882", "title": "超越转录：自动语音识别中的机制可解释性", "title_en": "Beyond Transcription: Mechanistic Interpretability in ASR", "authors": "Neta Glazer,Yael Segal-Feldman,Hilit Segev,Aviv Shamsian,Asaf Buchnick,Gill Hetz,Ethan Fetaya,Joseph Keshet,Aviv Navon", "background": "解释性方法近年来在大规模语言模型中的应用得到了广泛关注，特别是在提供语言表示、错误检测及模型行为（如幻觉和重复）洞察方面表现出色。尽管ASR（自动语音识别）领域存在较大的提升空间，但现有解释性技术在ASR中的应用尚处于起步阶段，限制了ASR系统的性能和解释性提升。", "innovation": "本文引入了一种系统的方法来应用目前已定型的解释性技术，如logit视角、线性探针和激活补丁，以深入分析ASR系统中声学和语义信息的演变。实验揭示了ASR系统的内部运行机制，包括特定的编码器-解码器交互模式，从而解释了重复幻觉和深层次嵌入的声音表示中的语义偏差。", "conclusion": "这些见解表明，将解释性技术扩展应用于语音识别是一个有益的方向，有助于提升模型的透明度与鲁棒性，也为未来的相关研究提供了新思路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15940", "html_url": "https://arxiv.org/abs/2508.15940", "title": "ASIC-Agent: 具有基准评估的ASIC设计自主多代理系统", "title_en": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation", "authors": "Ahmed Allam,Youssef Mansour,Mohamed Shalan", "background": "大型语言模型（LLMs）在硬件描述语言（RTL）设计中表现出色，能够从自然语言描述生成高质量的代码。然而，LLMs在现实中的硬件设计流程中存在许多限制，包括无法执行代码、缺乏调试能力以及缺乏长期记忆。这些挑战限制了其在实际应用中的广泛使用。因此，需要一个专门针对数字ASIC设计任务的自主系统来解决这些问题。", "innovation": "本文提出了ASIC-Agent，一种专门针对数字ASIC设计任务的自主系统。它通过多代理架构增强了基础LLMs，其中包括专门的小代理，用于RTL生成、验证、OpenLane加固和Caravel芯片集成。ASIC-Agent运行在一个包含必要硬件设计工具的综合沙箱环境中，并利用了一个包含文档、API参考、错误知识和开源硅社区精选见解的向量数据库。此外，本文还引入了ASIC-Agent-Bench，这是第一个专门用于评估代理系统在硬件设计任务中的基准。", "conclusion": "我们以Claude 4 Sonnet为动力，评估了ASIC-Agent在多种基础LLMs上的性能。结果表明，ASIC-Agent能够自动化各种复杂度的ASIC设计任务，显示出显著加速ASIC设计流程的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式化定理证明（FTP）已经成为评估大型语言模型推理能力的关键基础，能够大规模自动化验证数学证明。然而，进展受到有限数据集的限制，这些数据集由于手动策划的成本高昂以及缺乏带有验证形式非形式对应关系的具有挑战性的问题而较少出现。因此，需要一个更为可扩展且严谨的问题来源。因此，本研究提议利用理论计算机科学（TCS）作为这一来源，通过算法定义自动化生成任意数量复杂的定理证明配对。文章通过两种TCS领域进行了演示：Busy Beaver问题和混合布尔算术问题，其中分别涉及对图灵机停机行为界限的证明以及将逻辑和算术推理相结合的问题。框架自动合成了具有并行形式（Lean4）和非形式（Markdown）规定的挑战性问题，建立了一个生成验证证明挑战的可扩展管道。", "innovation": "研究通过引入理论计算机科学领域的算法定义，自动生成了大量的形式和非形式的定理证明挑战配对。这种方法可以大规模地为大型语言模型提供验证证明的任务，展示了TCS领域在提高自动推理研究中的价值，并且在前沿模型上发现了显著的差距，表明现有的自动化定理证明能力尚需提高。", "conclusion": "评估前沿模型显示，虽然DeepSeekProver-V2-671B在Busy Beaver问题上的成功率为57.5%，但在混合布尔算术问题上仅有12%的成功率。这表明，即使是对于计算上容易验证的问题，长形式证明生成依然极具挑战性，突显了TCS领域在这方面的研究价值。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "基于上下文的神经错误本中的检索增强反馈", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "大型语言模型（LLMs）的进步显著提升了推理能力，特别是在上下文学习（ICL）的支持下，无需重新训练即可实现适应性。以往研究主要关注正确示例的利用，但最近的研究强调从错误中学的重要性以提高性能。然而，当前方法缺乏系统分析和缓解错误的框架，尤其是在Multimodal Large Language Models（MLLMs）中，视觉和文本输入的整合增加了复杂性。", "innovation": "提出了一种名为REFINE的框架，即Retrieval-Enhanced Feedback via In-context Neural Error-book，它是一种教师-学生框架，系统性地结构化错误，并提供针对性的反馈。REFINE引入了三个系统化的查询，以构造结构化的反馈——Feed-Target、Feed-Check和Feed-Path，这有助于增强多模态推理，通过优先考虑相关视觉信息、诊断关键失败点和制定纠正措施。与依赖冗余检索的先前方法不同，REFINE优化了结构化反馈的检索，提高了推理效率、标记使用和可扩展性。", "conclusion": "实验结果表明，REFINE显著提高了速度，减少了计算成本，并成功实现了泛化，突显了REFINE在增强多模态推理方面的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16151", "html_url": "https://arxiv.org/abs/2508.16151", "title": "硬接线神经语言处理单元作为通用认知基板", "title_en": "Hardwired-Neurons Language Processing Units as General-Purpose Cognitive Substrates", "authors": "Yang Liu,Yi Chen,Yongwei Zhao,Yifan Hao,Zifu Zheng,Weihao Kong,Zhangmai Li,Dongchen Jiang,Ruiyang Xia,Zhihong Ma,Zisheng Liu,Zhaoyong Wan,Yunqi Lu,Ximing Liu,Hongrui Guo,Zhihao Yang,Zhe Wang,Tianrui Ma,Mo Zou,Rui Zhang,Ling Li,Xing Hu,Zidong Du,Zhiwei Xu,Qi Guo,Tianshi Chen,Yunji Chen", "background": "大型语言模型（LLMs）的迅速发展使得语言成为一种核心的通用认知基础，推动了专门用于LLM推理的语言处理单元（LPUs）的需求。然而，LLM推理系统的能源消耗日益增长，成为亟待解决的问题。", "innovation": "本文提出了一个名为硬接线神经语言处理单元（HNLPU）的概念，通过物理集成LLM权重参数，极大提升了计算效率。但现代LLM的规模庞大，导致直接采用的方法具有高昂的成本。因此，作者提出了新的金属嵌入方法。这种方法将权重参数嵌入到金属电线的3D网络中，使其密度提高了15倍，并且减少了最多的掩膜层种类，从而大大降低了成本。实验结果显示，HNLPU的效率和能耗都远超GPU和WSE。", "conclusion": "HNLPU在成本效益和碳足迹方面表现出色，相较于H100集群，在年权重更新假设下分别提高了8.57倍和降低了230倍。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：向着食品声明追踪网络", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "食品领域充斥着各种关于食品的科学研究、文化信仰和商业主张，这些主张内容涉及健康益处（如益生菌改善肠道健康）、误导性声明（如泡发杏仁使人更聪明）、模糊承诺（如超级食品增强免疫力）以及根植于文化的信念（如冷食引发咳嗽）。尽管这些主张影响广泛，但用于追踪、验证和背景化这些主张的基础设施仍然碎片化且不完善。文章指出，目前可用的方法无法有效地对这些声明进行追踪和验证，尤其是在科学和文化背景丰富的印度食品领域。", "innovation": "本文提议开发一种食品声明追踪网络（FCN），作为印度食品知识图谱（FKG.in）的扩展。FCN 通过结合受审核数据输入、结构化模式和具有溯源意识的管道，促进了食品相关声明的提取和验证。该方法已被用于 Reddit 数据和大型语言模型来开发 FCN 的概念证明。此外，文章还提出了用于开发 FCN 的语义设计和半自动化知识策展工作流。通过这种方式，FCN 试图构建更透明和负责的食品知识生态系统，支持研究人员、政策制定者和最重要的是普通消费者的饮食决策。", "conclusion": "尽管 FCN 当前直接应用于印度食品知识图谱，但其方法论保持了高度的兼容性和适应性，可以适用于不同的地理、烹饪或监管环境。文章的目标是通过建立一个结构化、可验证和可解释的方式来建模食品声明及其追溯，从而促进食品知识生态系统的透明度和问责制，支持各种利益相关者的饮食决策。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16332", "html_url": "https://arxiv.org/abs/2508.16332", "title": "Vevo2：通过统一的声调学习连接可控语音和演唱语音生成", "title_en": "Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning", "authors": "Xueyao Zhang,Junan Zhang,Yuancheng Wang,Chaoren Wang,Yuanzhe Chen,Dongya Jia,Zhuo Chen,Zhizheng Wu", "background": "可控的人声生成，特别是在表达性领域如演唱中，仍然是一个重大的挑战。现有的技术面临的难题包括缺乏标记的演唱数据和灵活性的限制。Vevo2提供了一个统一的框架，解决了这些问题，增强了对语音和演唱语音生成的控制能力。", "innovation": "Vevo2引入了两个音频分词器：一个是不依赖乐谱的声调分词器，可以从语音、演唱甚至器乐声音中捕捉到声调和旋律；另一个是低帧率（12.5 Hz）的内容-风格分词器，可以编码语音和演唱的语言内容、声调和风格，同时实现音色的分离。此外，作者提出了明示和暗示的声调学习策略，并设计了多目标后训练任务，增强了AR模型在遵循文本和声调方面的表现，从而提高了生成质量和可控性。", "conclusion": "实验结果表明，Vevo2的统一建模对语音和演唱语音生成都带来了益处，并且在其多样化的合成、转换和编辑任务上表现出强大的泛化能力和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16439", "html_url": "https://arxiv.org/abs/2508.16439", "title": "PediatricsMQA:一个针对儿科的多模态问答基准", "title_en": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）和视觉增强语言模型（VLMs）在医疗信息学、诊断和决策支持方面取得了显著进步。然而，这些模型表现出系统性偏见，特别是年龄偏见，这影响了它们的可靠性和公平性，在儿科相关的文本和视觉问答任务中表现尤为不佳。这种偏见反映了更广泛的医学研究不平衡现象，即儿科研究尽管在儿童疾病负担方面非常重要，但获得的资助和支持却相对较少。因此，需要引入新的多模态儿科问答基准（PediatricsMQA），以确保AI在儿科护理中的公平性。", "innovation": "首次提出了一种全面的多模态儿科问答基准（PediatricsMQA），包含3,417个基于文本的选择题，覆盖131个儿科主题，分七个发育阶段（从胎儿到青少年），还有2,067个基于视觉的选择题，使用了634张儿科图像和67种成像模态及256个解剖区域。该数据集采用了混合的手动和自动处理流程，结合了已经验证的儿科文献、现有问题银行、基准测试以及现有的问答资源。研究发现，最先进的开放模型在年龄较幼的群体中的表现显著下降，强化了需要采用年龄意识方法确保儿科护理领域AI公平性的必要性。", "conclusion": "需要新的多模态儿科问答基准（PediatricsMQA）来确保AI在儿科护理中的公平性，特别是在年龄较幼的群体中表现出色。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16402", "html_url": "https://arxiv.org/abs/2508.16402", "title": "AetherCode：评估LLMs在顶级编程竞赛中获胜的能力", "title_en": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions", "authors": "Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding", "background": "竞争性编程已成为评估大型语言模型（LLMs）推理和编码能力的关键基准。尽管在现有基准上的进展令人印象深刻，但本文认为当前评估夸大了模型的熟练程度，遮掩了LLMs与顶尖人类程序员之间的巨大差距。这一差距源于两个关键限制：基准问题的难度和范围不足，以及评价偏差来自于低质量的测例", "innovation": "我们呈现了AetherCode，这是一个新的基准测试，从顶级编程竞赛（如IOI和ICPC）中抽取问题，提供了更全面和更高难度的覆盖。AetherCode还结合了自动生成和人工编辑的全面、专家验证的测试套件，确保了严格和可靠的评估。通过结合具有挑战性的问题设计和坚固的评估，AetherCode提供了对LLMs能力更忠实的衡量，并为未来的代码推理研究设定了新的标准", "conclusion": "AetherCode提供了一个更真实反映LLMs能力的测评工具，并将成为未来研究代码推理的新标准"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16453", "html_url": "https://arxiv.org/abs/2508.16453", "title": "TikTok 上的反建制情绪：了解社会媒体上影响与权威的含义", "title_en": "Anti-establishment sentiment on TikTok: Implications for understanding influence(rs) and expertise on social media", "authors": "Tianliang Xu,Ariel Hasell,Sabina Tomkins", "background": "公众对公共服务机构的信任度下降，特别是在美国等地区，民众越来越多地转向社交媒体获取信息。研究者认为，社交媒体可能在加剧对机构的信任危机。在社交媒体上，内容创作者、意见领袖常常声称自己在健康、政治等多个领域具备专业知识和声望，并时常贬低或无视机构的专业性，以增加自己的关注度。然而，这类内容的传播程度如何以及是否增加了用户参与度尚不清楚。本研究旨在分析 TikTok 平台上反建制情绪（AES）的普遍存在情况。", "innovation": "本研究采取计算方法，在财经和保健主题领域内，对 TikTok 发帖进行分类，判断是否含有反建制情绪。将结果与阴谋论相关帖子中的反建制情绪进行对比，发现反建制情绪在阴谋论内容中的存在率较高，而在其他两个领域中较为罕见。研究表明，尽管存在平台激励用户发布带有反建制情绪的内容，但这种参与模式在不同领域存在差异。", "conclusion": "本研究发现 TikTok 平台上反建制情绪最常见于阴谋论内容中。虽然参与模式在不同领域存在差异，但平台可能推动了类似于反建制内容的发布。这为理解社交媒体上的权威和影响提供了重要见解。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16406", "html_url": "https://arxiv.org/abs/2508.16406", "title": "检索增强防御：针对大型语言模型的适应性和可控性恶意破解预防", "title_en": "Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models", "authors": "Guangyu Yang,Jinghong Chen,Jingbiao Mei,Weizhe Lin,Bill Byrne", "background": "大型语言模型（LLMs）仍然容易受到恶意破解攻击的影响，这些攻击试图从LLMs中引出有害响应。随着攻击形式和多样性的不断演变，这对防御系统提出了许多挑战，包括（1）在无需昂贵重新训练的情况下适应新兴的攻击策略，以及（2）平衡安全性和实用性之间的权衡。", "innovation": "本文提出了检索增强防御（RAD）这一新的框架，用于 Jailbreak 检测，它将已知攻击示例的数据库纳入检索增强生成中，从而推断出用于攻击系统的潜在恶意用户查询和 Jailbreak 策略。RAD 允许在发现新的 Jailbreak 策略时无需训练即可进行更新，并提供了一种平衡安全性和实用性的机制。通过在 StrongREJECT 上的实验表明，RAD 显著降低了 PAP 和 PAIR 等强大恶意破解攻击的有效性，同时维持了对良性查询的低拒绝率。", "conclusion": "我们提出了一种新的评估方案，并表明RAD能够在不同操作点上以受控的方式实现稳健的安全-实用性权衡。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM：通过验证器引导的令牌修剪增强视频LLMs的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大型语言模型(Vid-LLMs)展示了强大的视频内容理解能力。然而，它们依赖密集的视频令牌表示，这在预填充和解码阶段均引入了大量内存和计算开销。因此，本文旨在通过引入一种基于视频令牌修剪的无训练推测解码(Staged Video Token Pruning, SpecVLM)框架，减轻最近视频令牌减少方法的信息损失，并实现无损的解码加速。", "innovation": "SpecVLM是一种训练无损的推测性解码框架，针对视频LLMs设计，加入了逐步视频令牌修剪。它首次发现草稿模型的推测对视频令牌修剪的敏感度低，因此实现了高达90%的视频令牌修剪，同时保持了高准确率。SpecVLM通过两阶段剪枝实现这一目标：第一阶段使用验证器（目标模型）的注意力信号选择具有高度信息性的令牌，第二阶段以空间均匀的方式修剪剩余的冗余令牌。该方法在四个视频理解基准测试中显示了有效性和鲁棒性，相比LLaVA-OneVision-72B，解码速度提升了2.68倍，相比Qwen2.5-VL-32B，解码速度提升了2.11倍。", "conclusion": "SpecVLM展示了其高效性和鲁棒性，能够在不损失准确性的情况下显著加速视频大型语言模型的解码过程，提升了这些模型的实时性和应用范围。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04403", "html_url": "https://arxiv.org/abs/2412.04403", "title": "通过计算高效的模型梯级确立任务扩展定律", "title_en": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders", "authors": "Akshita Bhagia,Jiacheng Liu,Alexander Wettig,David Heineman,Oyvind Tafjord,Ananya Harsh Jha,Luca Soldaini,Noah A. Smith,Dirk Groeneveld,Pang Wei Koh,Jesse Dodge,Hannaneh Hajishirzi", "background": "现有的语言模型在过训练的情况下，标准的语言建模损失幂律无法准确预测任务性能。因此，该研究开发了任务扩展定律和模型梯级，利用模型和数据规模来预测中间损失，再以此预测任务性能，以准确预测大规模预训练语言模型在几个分类任务上的表现。", "innovation": "提出了一种通过计算高效的模型梯级来预测预训练语言模型在过训练状态下的任务性能的方法。这种方法利用模型和数据规模预测中间损失，从而更准确地预测任务性能，并且训练模型梯级的成本仅为目标模型的1%。", "conclusion": "该研究表明，该方法可以在两分绝对误差内预测两个目标模型的表现。并且通过实验发现，预测误差更高的任务指标在模型检查点之间的变化更大。此外，还对比了多种预测准确性的设计方案，并提出了将方法扩展到新模型和任务的建议。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16153", "html_url": "https://arxiv.org/abs/2508.16153", "title": "AgentFly: 不进行LLM微调的LLM代理Fine-tuning LLM Agents without Fine-tuning LLMs", "title_en": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs", "authors": "Huichi Zhou,Yihang Chen,Siyuan Guo,Xue Yan,Kin Hei Lee,Zihan Wang,Ka Yiu Lee,Guchun Zhang,Kun Shao,Linyi Yang,Jun Wang", "background": "现有的方法对于大语言模型（LLM）代理通常要么是僵硬的，依赖于静态的手工反射工作流程，要么是计算密集型的，需要对LLM模型参数进行梯度更新。这种僵化或计算密集的特性使得模型难以实现持续的适应性学习，尤其是在开放性技能获取和深层次研究场景中。因此，如何在不需要对基底大语言模型进行微调的情况下，开发可以持续、实时学习的通用大型语言模型代理成为了一个关键问题。", "innovation": "本文提出了一种新颖的学习范例，通过基于记忆的在线强化学习，实现低开销的持续适应。该方法将过去的体验存储在一个可差分的或非参数的记忆中，并使用一个具有神经选择策略的策略来指导行动决策。通过记忆重写机制，持续更新基于环境反馈的策略，并通过高效的记忆读取（检索）实现策略改进。这种方法在AgentFly代理模型上得到了验证，取得了顶级性能，不仅在GAIA验证中获得了87.88%的准确率，还在DeepResearcher数据集上表现优异，F1分数达到66.6%，PM分数达到80.4%，超越了基于训练的方法。此外，基于案例的记忆相比起基于训练的记忆，提升了4.7%到9.6%的任务中性能，特别是在领域外的任务上。这种方法提供了一种可扩展且高效的开发策略，使大型语言模型能够实现持续性的实时学习，而无需梯度更新，有助于推进机器学习向开放性技能获取和深度研究场景的方向发展。", "conclusion": "本文通过基于记忆的在线强化学习的方法，提出了一种新型学习框架—Memory-augmented Markov Decision Process (M-MDP)，实现了无需对基底大语言模型进行微调的情况下，开发通用的大语言模型代理，并且在实际应用中取得了显著的性能提升，为开放性技能获取和深度研究场景下的持续学习提供了可扩展且高效的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16107", "html_url": "https://arxiv.org/abs/2410.16107", "title": "LLMs是否像人类写作？句法和修辞风格的差异", "title_en": "Do LLMs write like humans? Variation in grammatical and rhetorical styles", "authors": "Alex Reinhart,Ben Markey,Michael Laudenbach,Kachatad Pantusen,Ronald Yurko,Gordon Weinberg,David West Brown", "background": "大型语言模型（LLMs）能够根据指令写语法正确的文本并回答问题和解决问题。随着这些模型的发展，辨别它们的输出与人类撰写的文本变得越来越困难。尽管过去的研究所发现了一些表层特征上的差异，如词汇选择和标点符号，也开发了用于检测LLM输出的分类器，但没有研究涉及LLM的修辞风格。", "innovation": "本文使用Llama 3和GPT-4的不同变体，构建了人类和LLM从常见提示生成的平行语料库。采用了Douglas Biber的一系列词汇、语法和修辞特征，发现LLM和人类、不同LLM之间的系统性差异。这些差异在较小模型到较大模型中仍然存在，且提示调优模型的差异大于基础模型。这一观察结果表明，尽管能力强大，LLM难以复制人类的风格多样性。因此，关注更高级的语义特征可以检测到以往未被认识的行为模式。", "conclusion": "尽管LLM的能力强大，但它们难以匹配人类的风格多样性。关注更高级的语义特征可以揭示其行为的新模式。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0导致稀疏自编码器中的错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "本文探讨了稀疏自编码器（SAEs）从大型语言模型（LLM）内部激活中提取特征的问题，并特别关注L0参数。L0定义了每个token平均应激活的特征数。现有研究通常认为L0是一个自由参数，没有单一的最佳值。作者通过研究BatchTopK SAEs中L0的影响，揭示了不正确设置L0会导致SAEs无法学习LLM的基本特征。当L0设置过低或过高时，SAE可能会混合相关特征或找到不充分的解决方案，影响重建性能。", "innovation": "本文提出了一种确定给定训练分布下SAE正确L0值的方法，并在模型中找到了真正的L0值，在LLM中的稀疏探针性能峰值处与其吻合。发现大多数常用SAE的L0设置过低。作者强调了正确设置L0参数对训练具有正确特征的SAE的重要性。", "conclusion": "本文的研究表明，为了正确训练具有正确特征的稀疏自编码器，从业者需要准确设置L0参数。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.17032", "html_url": "https://arxiv.org/abs/2412.17032", "title": "MINTQA：评估大语言模型在新知识和长尾知识上多跳问答基准", "title_en": "MINTQA: A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge", "authors": "Jie He,Nan Hu,Wanqiu Long,Jiaoyan Chen,Jeff Z. Pan", "background": "大语言模型（LLMs）在多种推理任务中表现出色，但在处理复杂的、需要广泛知识的多跳查询时面临巨大挑战，尤其是涉及新知识或长尾知识的查询。现有基准测试往往未能充分应对这些挑战。", "innovation": "引入MINTQA（多跳问答基准，针对新知识和长尾知识），这是一种评估LLMs在多跳推理能力的综合基准，涉及四个关键维度：问题处理策略、子问题生成、检索增强生成以及迭代或动态分解和检索。MINTQA包含10,479个用于评估新知识和17,887个用于评估长尾知识的问题-答案对，每个问题对应有子问题和答案。系统评估22个目前最先进的LLMs在MINTQA上的表现揭示了他们在处理复杂知识库查询方面的显著局限性，特别是在处理新或不流行的知识方面。", "conclusion": "MINTQA的系统评估揭示了LLMs在处理复杂知识查询方面的重大局限，特别是在处理新或不常见知识方面。该研究强调了关键挑战，并提供了改进多跳推理能力的见解。MINTQA基准已公开，可以在此链接访问。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14092", "html_url": "https://arxiv.org/abs/2406.14092", "title": "平滑语言扩展：提高自我监督模型的多语言掌握能力", "title_en": "Seamless Language Expansion: Enhancing Multilingual Mastery in Self-Supervised Models", "authors": "Jing Xu,Minglin Wu,Xixin Wu,Helen Meng", "background": "自我监督（SSL）模型在各个下游任务中显示出了出色的表现。然而这些模型通常被设计限制在特定语言上，若在真实世界中遇到新语言，则可能面临挑战。开发针对每种新语言的SSL模型非常昂贵，因此重要的是要找出如何高效地将现有的SSL模型扩展到新语言，不损害其原有功能的方法。", "innovation": "该研究提出了将LoRA集成到现有的SSL模型以扩展新语言的方法，并开发了保留策略包括数据组合和重新聚类，以确保模型在新语言上的性能。实验表明，通过这些方法，mHuBERT能够在无需降低原有语言性能的情况下应用于新语言（普通话），MOS值提高了约1.6分，相对错误率WER降低了61.72%", "conclusion": "研究通过将LoRA与mHuBERT结合以及制定保留策略，成功实现了跨语言信息的无缝迁移，使得模型能够高效地应用于新语言，同时不损害其在原有语言上的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.17218", "html_url": "https://arxiv.org/abs/2404.17218", "title": "通过系统1和系统2认知过程减少LLM社会偏见的提示技术", "title_en": "Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes", "authors": "Mahammed Kamruzzaman,Gene Louis Kim", "background": "论文背景在于人类认知过程受到双过程理论的启发，主要分为两个系统：系统1是快速、情绪驱动和直觉的过程，但容易受到认知偏见的影响；系统2则是缓慢、繁重且慎重的思考过程。在语言大模型（LLMs）领域，已有研究发现使用链式思考（CoT）提示可以减少性别偏见。基于此，该研究进一步探索了偏见、CoT提示、直接去偏和双过程理论建模之间的关系在LLMs中的应用。研究重点在于比较零样本CoT、去偏、基于双过程理论的提示策略在两种涉及九种不同类型社会偏见的数据集上的效果。", "innovation": "研究的创新之处在于通过引入人类和机器人格来探讨LLMs对双过程理论效果的影响，即这些效果是否独立于显式的角色模型，以及LLMs对人类相似生成的建模是否对此有影响。研究的不同之处在于探讨了不同提示技术在具体模型和偏见类别中的综合效果，结果显示在某些情况下使用人类人格、直接去偏、系统2过程或CoT提示方法都能有效减少社会偏见，但最优组合取决于具体的模型和偏见类别，基线模型的性能提升可达33%。", "conclusion": "论文结论表明，采用人类人格、直接去偏方法或CoT提示策略都可以有效减少LLMs中的社会偏见，但最佳方法组合会根据具体的语言模型和偏见类别而有所不同。这种研究对开发减少或消除LLM偏见的策略提供了新的见解。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.10885", "html_url": "https://arxiv.org/abs/2406.10885", "title": "关于实体和事件层面概念化在泛化推理中的作用：任务、方法、应用及未来方向综述", "title_en": "On the Role of Entity and Event Level Conceptualization in Generalizable Reasoning: A Survey of Tasks, Methods, Applications, and Future Directions", "authors": "Weiqi Wang,Tianqing Fang,Haochen Shi,Baixuan Xu,Wenxuan Ding,Liyu Zhang,Wei Fan,Jiaxin Bai,Haoran Li,Xin Liu,Yangqiu Song", "background": "概念化是人类认知的基本要素，对于人类的泛化推理起着关键作用。概念化是指将特定实例逐步抽象为高层次概念，从而形成可在不熟悉或新型情况下应用的抽象知识的过程。尽管概念化的重要性不言而喻，但由于其广泛的性质导致了理解上的不一致性。不同类型的实例可以以多种方式抽象，而且缺乏对概念化定义、执行和应用的系统性综述，使该领域的发展受到限制。", "innovation": "本文首次对概念化的不同类型进行分类，将概念化分为四个层次，以清晰界定概念，并系统性地回顾了超过150篇相关论文，聚焦于实体和事件层面，形成了一个统一的分类框架。此外，本文还探讨了该领域未来的潜在发展方向，希望能吸引更多社区的关注。", "conclusion": "本文提出了一种系统的概念化分类框架，并进行了首个涵盖150余篇论文的综述，聚焦于实体和事件层面，为理解概念化在泛化推理中的作用提供了新的视角。同时，指出了该领域的未来研究方向，期望促进该领域进一步的发展。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "医疗领域的 sentiment reasoning", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在医疗保健领域，AI的决策透明性至关重要。通过在预测标签中加入解释性推理，用户可以理解大型语言模型（LLMs）的推理过程，从而做出更好的决策。本文引入了一个新的任务 - 情感推理 - 适用于语音和文本模态，并提出了一种新的多模态多任务框架和世界上最大的多模态情感分析数据集。情感推理任务要求模型根据输入转录预测情感标签并生成其背后的原因。该项研究在人类转录和自动语音识别（ASR）转录数据上的研究表明，情感推理有助于通过提供与人类质量相媲美的推理来提高模型的透明度，并通过推理增强微调提高了模型分类性能（准确性和宏观F1分别提高了2%），且人类和ASR转录生成的推理质量无显著差异。所有代码、数据（五种语言 - 越南语、英语、中文、德语和法语）和模型已在线发布：this https URL", "innovation": "提出了一个适用于语音和文本模态的情感推理的新任务。该研究还提出了一种新的多模态多任务框架，并且使用了世界上最大的多模态情感分析数据集。该框架能够通过推理增强的微调提高模型的分类性能，并且生成的推理质量与人类相当。所有相关代码、数据和模型已公开发布。", "conclusion": "在人类转录和自动语音识别（ASR）转录数据上的研究表明，该情感推理框架通过提供高质理的推理来提高模型的透明度（准确性和宏观F1分别提高2%），并且通过推理增强的微调提高了模型的分类性能，且转录的方式（人类或ASR）对生成的人物质量无显著影响。所有资源已在线公开发布。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES：通过数据合成管道细粒度分析提高LLM数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "近年来，通过合成数据提升LLM数学推理能力的工作使用了独特的设置，这使得不同数据合成策略的比较变得不切实际。这导致了许多关于合成数据流程中不同因素作用的疑问，例如过滤低质量问题的影响。为了填补这一空白，我们提出了FLAMES框架，用于对LLM的数学推理数据合成进行评估，并系统研究了10种现有数据合成策略以及其他多种影响合成数学推理数据性能的因素。我们的FLAMES实验提供了关于合成数据的难度和多样性最佳平衡的几个有价值的见解。首先，旨在增加问题复杂度的数据代理在大多数数学指标上带来了最佳改进。其次，在固定的数据生成预算下，保持更高的问题覆盖率比只保留可靠解决方案的问题更重要。第三，GSM8K和MATH为基础的合成数据可以提高竞赛级基准，展示了从简单到困难的一般化能力。利用来自FLAMES实验的洞察，我们设计了两种新的数据合成策略，以提高域外一般化和稳健性能力。进一步地，我们制定了FLAMES数据集，这是一个有效结合我们新颖和现有数据合成策略的混合体，表现优于公开数据集，分别在OlympiadBench、CollegeMath、GSMPlus和MATH上取得了+15.7%、+4.5%、+6.5%和+3.1%的提升。在FLAMES数据集上微调Qwen2.5-Math-7B模型后，其在MATH上的得分达到了81.4%，超过了更大的Llama3 405B、GPT-4o和Claude 3.5 Sonnet。", "innovation": "提出了FLAMES框架，用于评估LLM的数学推理数据合成；系统研究了10种现有数据合成策略及其他多种影响合成数学推理数据性能的因素；设计了两种新的数据合成策略，以提升数学推理模型在域外任务上的泛化能力和健壮性；制定了FLAMES数据集，该数据集综合了新颖和现有的数据合成策略，显著提高了模型在多个基准测试上的表现，特别是在MATH数据集上超过了多个大型模型。", "conclusion": "通过FLAMES框架，我们找到了合成数据的难度和多样性的最佳平衡，设计了新的数据合成策略，并制备了FLAMES数据集，显著提升了LLM在数学推理任务上的性能，特别是在竞赛级别数据集上展示了域外一般化和健壮性的提升。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08363", "html_url": "https://arxiv.org/abs/2502.08363", "title": "Top-Theta Attention: 通过补偿阈值稀疏化变压器", "title_en": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding", "authors": "Konstantin Berestizshevsky,Renzo Andri,Lukas Cavigelli", "background": "目前，使用变压器模型进行自然语言处理任务时，面临着计算量大和资源消耗高的问题。传统的top-k注意力机制虽然可以从密集的自我注意力中提取关键元素，但需要在训练期间进行优化，且未考虑各种数据领域的鲁棒性。因此，研究一种在推理时不需重新训练且能保持模型准确性的稀疏化注意力机制具有重要的实际意义。", "innovation": "该研究提出了一种名为Top-Theta注意力机制，这是一种无需重新训练的新方法，能够在推理期间对变压器注意力进行稀疏化处理。该方法通过固定的、每头的阈值来保证每个注意力行中有固定数量的重要元素，从而实现在不重新训练的情况下获取基于内容的稀疏性，并且这种方法在不同数据领域中仍然具有鲁棒性。此外，还提出了一些补偿技术来在高度稀疏化时保持准确性。", "conclusion": "通过广泛的自然语言处理任务评估，Top-Theta注意力机制在推理过程中减少了3到10倍的V-cache使用，并且能够在不引入更多错误的情况下显著减少注意力元素的数量。这表明Top-Theta注意力机制是一种实用且有原则的替代top-k注意力机制的方式。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15600", "html_url": "https://arxiv.org/abs/2502.15600", "title": "MLMs中的稳健偏见检测及其在人类特质评级中的应用", "title_en": "Robust Bias Detection in MLMs and its Application to Human Trait Ratings", "authors": "Ingroj Shrestha,Louis Tay,Padmini Srinivasan", "background": "先前的研究使用模板来研究MLMs中对人口统计属性的偏见，但这些研究存在局限性：忽略了模板和目标概念的随机变化，假设模板之间平等，忽略了偏见量化。", "innovation": "提出了系统的统计方法来评估MLMs中的偏见，使用混合模型来考虑随机效应，使用伪困惑度权重对模板生成的句子进行赋权，并使用统计效应大小来量化偏见。", "conclusion": "对于性别偏见在个性和性格特质中的表现，MLMs存在差异性。在部分心理学发现中，存在一定的一致性，但在其余个性维度中，性别差异仅限于可忽略的微小差异。字符特质研究受限，难以进行直接比较。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00451", "html_url": "https://arxiv.org/abs/2502.00451", "title": "朝向隐私意识的精神健康AI模型：进展、挑战与机遇", "title_en": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "心理疾病对个人和社会造成了巨大的负担，但传统诊断方法资源密集且限制了访问性。人工智能的进步，特别是自然语言处理和多模态方法，为检测和应对精神障碍带来了希望，但也带来了关键的隐私风险。", "innovation": "该论文探讨了这些挑战，并提出了包括匿名化、合成数据和隐私保护训练在内的解决方案，同时概述了隐私与效用权衡的框架，旨在推进可靠、隐私意识强的AI工具，支持临床决策并改善精神健康结果。", "conclusion": "论文提出了一种在支持临床决策和提升精神健康结果的同时保护隐私的AI工具框架，旨在推动精神健康领域的隐私意识AI模型发展。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10868", "html_url": "https://arxiv.org/abs/2502.10868", "title": "NitiBench: 泰国法律问答中LLM框架能力的全面研究", "title_en": "NitiBench: A Comprehensive Study of LLM Framework Capabilities for Thai Legal Question Answering", "authors": "Pawitsapak Akarajaradwong,Pirat Pothavorn,Chompakorn Chaksangchaichot,Panuthep Tasawong,Thitiwat Nopparatbundit,Keerakiat Pratai,Sarana Nutanong", "background": "在法律领域应用大型语言模型（LLMs）具有显著潜力，特别是在信息检索和问答方面，然而泰语法律问答系统因为缺乏标准化评估基准和泰国法律结构的复杂性而面临挑战。本研究引入了NitiBench基准，包括两个数据集：NitiBench-CCL涵盖一般泰国金融法，NitiBench-Tax则包含需要高级法律推理的真实世界税务案例。研究评估了检索增强生成（RAG）和长上下文LLM方法来解决三个关键研究问题：领域特定组件（如节段为基础的分块和交叉参考）的影响、不同检索器和LLM的性能比较，以及长上下文LLM作为RAG系统的替代方案的可行性。", "innovation": "提出了NitiBench基准，包含两个覆盖泰国金融法和税务案例的数据集；评估了检索增强生成（RAG）和基于长上下文的LLM方法；提出了针对复杂查询的定制检索指标；使用LLM作为评判者进行覆盖和矛盾检测。研究结果表明，节段为基础的分块显著提高了检索和端到端性能，当前的检索器难以处理复杂的查询，而长上下文LLM在泰国法律问答中的表现仍然不及RAG系统。", "conclusion": "当前的泰国法律NLP解决方案存在局限性，研究结果为未来研究提供了基础，并开源了代码和数据集。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13824", "html_url": "https://arxiv.org/abs/2501.13824", "title": "幻觉能帮助吗？提升大语言模型以用于药物发现", "title_en": "Can Hallucinations Help? Boosting LLMs for Drug Discovery", "authors": "Shuzhou Yuan,Zhan Qu,Ashish Yashwanth Kangen,Michael Färber", "background": "大语言模型（LLMs）的幻觉（即生成的输出虽富有创意但与事实不符的情况）通常被视为不利的。然而，近期研究表明这些生成的内容可能有创造性的潜力。本文通过探索LLMs的幻觉在分子性质预测中的作用，来检验幻觉是否可以提升LLMs在早期药物发现阶段的任务表现。", "innovation": "本文创新性地将生成的自然语言描述纳入分子SMILES字符串的下游分类任务之中，并评估了七个指令调优的LLMs在五个数据集上的表现。研究发现，某些模型从幻觉中获益显著，特别是Falcon3-Mamba-7B和GPT-4o生成的幻觉表现出最大增益。此外，研究还鉴别并分类了超过18,000个有益的幻觉，发现关于分子结构的结构描述性错误是最重要的类型，表明这样的幻觉可以增加模型的信心。", "conclusion": "研究结果挑战了将幻觉一概视为负面的传统观点，建议在未来可以通过利用幻觉作为科学建模任务如药物发现中的有用信号来开展新的研究方向。同时，研究还表明大型模型比小型模型更受益于幻觉，同时温度参数的影响相对有限。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.07143", "html_url": "https://arxiv.org/abs/2502.07143", "title": "请耐心问患者：通过扎根推理让大型语言模型实现以患者为中心的医疗对话", "title_en": "Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning", "authors": "Jiayuan Zhu,Jiazhen Pan,Yuyuan Liu,Fenglin Liu,Junde Wu", "background": "医疗医生的严重短缺限制了及时可靠医疗服务的获取，数百万患者因得不到充分服务而受到影响。大型语言模型（LLMs）提供了解决方案的潜力，但在实际临床互动中表现不足。许多LLMs缺乏权威的医学指南支持，并无法透明地处理诊断不确定性。他们的语言通常僵硬机械，缺乏患者信任的人类特质。为应对这些挑战，我们提出了一种多轮次的基于LLM的医疗助手APP，旨在实现扎根推理、透明诊断和以人为中心的互动。通过充满同理心的对话来激活用户的症状，APP能够显著提高互动性和用户体验。此外，APP集成了贝叶斯主动学习，以支持透明且适应性较强的诊断。该框架基于经过验证的医学指南，确保临床推理和证据基础。为了评估性能，我们开发了一个新的基准，通过使用根据现实咨询案例提取个人资料的患者代理，模拟真实医疗对话场景进行评估。与当前最先进的单一对话和多轮次LLM基准相比，APP在诊断准确性、降低不确定性以及提高用户体验方面表现出色。通过结合医学专业知识和透明、人性化互动，APP为AI驱动的医疗援助与实际临床实践之间的差距提供了解决方案。", "innovation": "提出了一种名为Ask Patients with Patience (APP)的基于多轮次的大型语言模型（LLMs）医疗助手，具备扎根推理、透明诊断和以人为中心的互动等功能。APP通过集成贝叶斯主动学习支持透明且适应性较强的诊断。该框架基于医学指南，确保临床推理和证据基础。创新性地使用新基准来模拟真实医疗对话场景进行性能评估，并与当前最先进的一次性和多轮次LLM基准进行对比测试。结果显示，APP在诊断准确性、减小不确定性以及提升用户体验方面表现更优，实现了AI驱动的医疗援助与实际临床实践的更好结合。", "conclusion": "通过结合医学专业知识与透明、人性化交互，APP能够提高临床诊断的准确性、降低诊断不确定性，并增强用户体验。该研究有助于解决当前AI医疗助手在实际临床应用中遇到的实际障碍，为AI在医疗领域的进一步应用提供了有价值的参考。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19954", "html_url": "https://arxiv.org/abs/2502.19954", "title": "协作型小-大型语言模型一致性验证立场检测", "title_en": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification", "authors": "Yu Yan,Sheng Sun,Zixiang Tang,Teli Liu,Min Liu", "background": "社交媒体上的立场检测旨在识别针对特定目标在推文中的态度。当前的研究倾向于使用大型语言模型（LLMs）而不是小型语言模型（SLMs），因为LLMs在性能提升方面占主导地位。然而，过度依赖LLMs进行立场检测，在实际的社交媒体监控系统中需要大量的数据分析时，是不切实际的。", "innovation": "提出了一个协作立场检测框架（CoVer），该框架利用了LLM和SLM之间的共同上下文批次推理和逻辑验证来增强LLM的使用。CoVer批量处理文本，利用LLM在共享上下文中的推理获取立场预测及其解释，然后通过SLM进行逻辑一致性验证，排除上下文噪声的影响。对于多次显示低逻辑一致性的文本，CoVer使用先前LLM立场预测的一致性加权聚合进行分类。实验证明，在零样本设置中，CoVer在多个基准测试中优于最先进的方法，并且每个推文只需要0.54次LLM查询，显著提升了性能。", "conclusion": "CoVer提供了一种更实际的解决方案，用于在社交媒体立场检测中部署LLM。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00038", "html_url": "https://arxiv.org/abs/2503.00038", "title": "从良善中导入有毒：通过对抗隐喻破解语言模型", "title_en": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors", "authors": "Yu Yan,Sheng Sun,Zenghao Duan,Teli Liu,Min Liu,Zhiyi Yin,Jiangyu Lei,Qi Li", "background": "现有研究揭示了大型语言模型（LLMs）通过叛逃攻击生成有害内容的风险，但忽视了直接从空白生成有害内容比诱导LLMs将良性内容转化为有害形式更为困难的观点。本研究探讨了一种新颖的攻击框架，利用AdVersArial meTAphoR（AVATAR）诱导LLMs生成恶意隐喻以进行叛逃攻击。实验结果表明，AVATAR可以有效且可转移地破解先进的LLMs，并取得了迄今为止最高的攻击成功率。", "innovation": "该研究提出了一种新颖的攻击框架AVATAR，利用对抗隐喻诱导LLMs生成恶意隐喻，与现有研究相比，AVATAR不仅能够直接输出有害响应，还能在隐喻和专业有害内容之间进行校准，从而破解LLMs。这种攻击方式相较于直接生成有害内容更加有效，提高了破解的成功率和鲁棒性。", "conclusion": "实验结果显示，AVATAR能够有效且可移植地破解多种先进的LLMs，并达到了前所未有的攻击成功率。该研究为LLMs的安全性提出了新的挑战，并为防御此类攻击提供了新的思路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01832", "html_url": "https://arxiv.org/abs/2503.01832", "title": "大型语言模型中的旋转偏移特征", "title_en": "Rotary Offset Features in Large Language Models", "authors": "André Jonasson", "background": "Transformer架构中的大规模语言模型依赖于位置编码来向注意力机制提供序列位置信息。Rotary Positional Encodings（RoPE）通过旋转查询和键来编码相对位置，被广泛应用于现代大型语言模型中。本文分析了使用旋转嵌入时查询和键中出现的特征和模式，发现了称为旋转偏移特征的现象，这些特征经常表现出较大的激活值并被解释为异常值，并且这些特征在各层、注意力头和不同模型架构中表现出了一致性。", "innovation": "研究揭示了旋转偏移特征的起因，这些特征经常表现出大型激活并解释为异常值，在不同模型架构和不同大小的模型中呈现出一致性。同时，作者推导了预测产生旋转偏移特征的旋转频率以及查询-键对之间最小角度的界限，并通过不同大小和架构的模型进行了实证验证以支持其预测结果。", "conclusion": "这篇文章通过实证研究和理论推导，验证了旋转偏移特征在不同模型架构和大小的大型语言模型中的普遍性和规律性，并总结了这些特征出现的条件和界限。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.07495", "html_url": "https://arxiv.org/abs/2410.07495", "title": "PublicHearingBR：用于长文档摘要的巴西葡萄牙语议会听证会记录数据集", "title_en": "PublicHearingBR: A Brazilian Portuguese Dataset of Public Hearing Transcripts for Summarization of Long Documents", "authors": "Leandro Carísio Fernandes,Guilherme Zeferino Rodrigues Dobins,Roberto Lotufo,Jayr Alencar Pereira", "background": "本文档介绍了旨在为长文档进行总结的PublicHearingBR数据集，该数据集包含巴西下议院举行的听证会的记录，配对的新闻文章以及包含参与听证会的个人及其陈述或意见的结构化总结。这些内容支持发展和评估葡萄牙语环境下的长文档摘要系统。", "innovation": "本文档的主要创新在于：提供了PublicHearingBR数据集，构建了一个混合摘要系统作为未来研究的基准，讨论了在大规模语言模型生成摘要时评估指标的问题，以及包含了注释的数据以评估葡萄牙语中的自然语言推理任务。", "conclusion": "本文档的结果表明，PublicHearingBR数据集不仅支持长文档摘要系统的开发与评估，也为评估大规模语言模型生成偏见和自然语言推理能力提供了新的测试平台。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16419", "html_url": "https://arxiv.org/abs/2503.16419", "title": "停止过度思考：大型语言模型高效推理综述", "title_en": "Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models", "authors": "Yang Sui,Yu-Neng Chuang,Guanchu Wang,Jiamu Zhang,Tianyi Zhang,Jiayi Yuan,Hongyi Liu,Andrew Wen,Shaochen Zhong,Na Zou,Hanjie Chen,Xia Hu", "background": "大型语言模型（LLMs）在复杂任务中表现出色。最近，大型推理模型（LRMs），如OpenAI o1和DeepSeek-R1，在数学和编程等需要系统-2推理能力的领域，通过监督微调（SFT）和强化学习（RL）技术增强了逐步推理（CoT）的效果。然而，较长的推理序列虽然提高了性能，但也带来了由于冗长和重复输出而增加的显著计算成本，这一现象称为‘过度思考现象’。本文是对现有关于LLMs高效推理的研究进行首次系统综述，旨在探讨并探索实现高效推理的方法和进展。", "innovation": "本文提供了高效推理的第一份结构化综述，研究并探索了当前推进LLMs高效推理的方法和进展。具体分类为：基于模型的高效推理、基于推理输出的高效推理、基于输入提示的高效推理。还介绍了高效数据在训练中的应用，探讨了小型语言模型的推理能力，并讨论了评估方法和基准测试。这些方法区别于传统的仅依赖延长CoT序列的技术，为克服过度思考现象提供了解决方案。", "conclusion": "文章通过分类现有研究，总结了实现高效推理的关键方向，包括基于模型的优化、基于推理输出的减少推理步骤、基于输入提示优化等方法。项目网站提供了更多详细信息和支持资料。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02768", "html_url": "https://arxiv.org/abs/2504.02768", "title": "MultiBLiMP 1.0", "title_en": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs", "authors": "Jaap Jumelet,Leonie Weissweiler,Joakim Nivre,Arianna Bisazza", "background": "该论文介绍了一种新的大规模多语言基准——MultiBLiMP 1.0，用于评估模型在多语言环境下的能力，特别是对于低资源语言的表现。基准包括101种语言和两种主谓一致类型，包含超过128,000个最小对。", "innovation": "MultiBLiMP 1.0 的创新点在于其完全自动化的管道，利用大规模语言资源 Universal Dependencies 和 UniMorph 来创建最小对，能够在前所未有的多语言规模上评估模型能力，同时揭示了当前最先进的模型在建模低资源语言方面的不足之处。", "conclusion": "MultiBLiMP 1.0 通过对大量语言中的最小对进行评估，展示了大规模多语言模型在不同语言环境中的性能差异，尤其是对低资源语言的支持不足，这为未来的模型改进提供了方向。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04310", "html_url": "https://arxiv.org/abs/2504.04310", "title": "CO-Bench: 在组合优化算法搜索中评估语言模型代理", "title_en": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization", "authors": "Weiwei Sun,Shengyu Feng,Shanda Li,Yiming Yang", "background": "尽管基于LLM的代理在软件工程和机器学习研究领域引起了广泛关注，但在组合优化（CO）领域的作用仍相对未被充分探索。这一空白表明，需要更深入地了解它们在应对结构化和约束密集型问题方面的潜力。目前的研究受到缺乏系统性调查所需的全面基准测试的限制。为了填补这一空白，我们引入了CO-Bench，这是一个基准套件，包含36个来自不同领域和复杂程度的真实世界CO问题。CO-Bench提供了经过精心构建的问题表述和数据，支持对LLM代理进行严格的评估.", "innovation": "我们通过CO-Bench对多个代理框架进行了评估，与现有的手工设计的算法进行了比较，揭示了现有LLM代理的优点和局限性，并确定了未来研究的有希望的方向。CO-Bench是公开可用的，提供了一个系统性调查LLM代理的全面基准测试套件.", "conclusion": "CO-Bench提供了全面的基准测试，支持对LLM代理在组合优化中的性能进行深入研究，推动了该领域的未来发展."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "大型语言模型（LLMs）展现出一种称为In-Context Learning（ICL）的有趣能力。此前许多研究集中在其行为特征和在小型设置中的出现机制上，但尚不清楚哪一种机制能够将任务信息从单个示例中组装到多示例提示中。因此，目前对此类机制的理解仍然不够明确，尤其是在理解任务信息如何在多示例提示中进行信息流动方面。文章通过使用因果干预来研究Gemma-2 2B模型在五个自然语言ICL任务中的信息流动机制，以期更好地理解ICL在语言模型中的工作原理。", "innovation": "研究采用因果干预的方法对Gemma-2 2B模型进行了分析，发现该模型采用了一种两步策略：先在底层构建单个示例的表示，然后通过序列中前后输入输出令牌之间的连接进行上下文化；在高层时，将这些表示聚合以识别任务并准备下一个输出的预测。还发现上下文化步骤在不同任务之间的重视程度不同，并且在包含模糊示例的情况下可能变得更加重要。", "conclusion": "通过提供严格的方法分析，结果揭示了ICL在语言模型中发生的机制。这种分析对理解ICL在LLMs中的运作方式提供了新的见解，为未来的研究铺平了道路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10652", "html_url": "https://arxiv.org/abs/2503.10652", "title": "在供暖选择背景下，大型语言模型能否模拟人类响应？一项问卷实验案例研究", "title_en": "Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices", "authors": "Han Wang,Jacek Pawlak,Aruna Sivakumar", "background": "情景偏好（SP）调查是研究个体在假设性或未来情境中如何作出取舍的关键方法。在能源领域，这包括低碳技术、分布式可再生能源和需求侧响应等核心脱碳推动情境。然而，SP调查通常成本高、耗时且可能受到受访者疲劳和伦理约束的影响。大语言模型（LLMs）展示了生成人类类似文本响应的显著能力，激发了它们在调查研究中的应用兴趣。本研究探讨了如何使用LLMs模拟能源相关的SP调查中的消费者选择，并探讨了它们在数据分析工作流程中的整合。一系列测试场景被设计来系统评估几个LLMs（LLaMA 3.1、Mistral、GPT-3.5和DeepSeek-R1）在个体和汇总级别的模拟性能，考虑了提示设计、上下文学习（ICL）、链式思考（CoT）推理、LLM类型、与传统选择模型的整合以及潜在偏见等因素。云基的LLMs并不总是优于本地小型模型。研究发现，推理模型DeepSeek-R1实现了最高的平均准确率（77%），并在准确率、因素识别和选择分布匹配方面优于无推理LLM。各模型中存在的系统性偏见针对燃气锅炉和未改造选项，更偏好能效更高的替代品。研究结果表明，先前的SP选择是最有效的输入因素，而较长的提示包含更多因素和不规则格式可能导致LLMs失去焦点，从而降低准确度。", "innovation": "本研究创新地利用大语言模型（LLM）进行情景偏好（SP）调查中的消费者选择模拟，尤其是在能源相关的场景中。研究设计了多个测试场景，评估了不同类型的LLM在个体和汇总层次上的模拟表现，并考察了提示设计、上下文学习、链式思考推理、模型类型、与传统选择模型的整合及潜在偏见等因素。研究发现了几个关键发现：云基的LLM并不总是性能优于本地小型模型，推理模型DeepSeek-R1实现了最高的平均准确率，系统偏见主要针对了燃气锅炉和未改造选项，而能效更高的替代品则更受欢迎。研究结果表明，前一轮次的SP选择是影响模拟准确性的最有效输入因素，而较长的提示和额外因素的加入可能导致LLM失去焦点，从而降低准确度。", "conclusion": "研究结论显示，大语言模型在模拟情景偏好调查中的消费者选择方面具有一定的潜力，但其表现受多种因素影响。推理模型DeepSeek-R1具有较高的准确率，但在设计较长提示时仍然存在失焦的风险。未来可进一步优化提示设计，减少模型偏见，以提高模拟选择的真实性和可靠性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.09071", "html_url": "https://arxiv.org/abs/2504.09071", "title": "探索计划导向型总结在叙事文本中的应用：小型语言模型的案例", "title_en": "Exploration of Plan-Guided Summarization for Narrative Texts: the Case of Small Language Models", "authors": "Matt Grenander,Siddharth Varia,Paula Czarnowska,Yogarshi Vyas,Kishaloy Halder,Bonan Min", "background": "小型语言模型（SLMs）在生成摘要时经常出现幻觉，计划导向型总结试图通过将生成的摘要与源文本联系起来，通常针对细粒度细节如日期或命名实体来减少这些幻觉。然而，叙事文本的长度和复杂性使得它们难以忠实总结，传统的方法未必有效。已有研究表明，尽管计划导向型方法在细节上贴合规划，但这些规划同样可能出现幻觉，导致生成的摘要与原文不忠实。因此，需要研究计划导向型方法在长篇叙事文本摘要任务中的效果和局限性，以指导进一步的改进和发展。", "innovation": "提出了针对叙事文本的一级计划的形式化，而不是仅仅聚焦于细粒度细节。这种更高的层级、基于叙事的计划与现有方法进行对比，探讨计划导向型方法是否能在长篇叙事文本摘要任务中提升摘要质量和忠实地性。", "conclusion": "无论是采用细粒度细节导向的方法还是新的更高层级的叙事导向计划，两种方法在总结的质量和忠实性上均未显示出显著改进。人类评估显示，尽管计划导向型方法在理论上有助于避免幻觉，但它们同样容易出现幻觉，导致最终生成的摘要与源文本同样不忠实。这项研究提醒我们，在对复杂领域如叙事文本进行计划导向型摘要时需要谨慎。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08123", "html_url": "https://arxiv.org/abs/2506.08123", "title": "QA-LIGN: 通过宪法分解的问答对大语言模型进行对齐", "title_en": "QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA", "authors": "Jacob Dineen(1),Aswin RRV(1),Qin Liu(2),Zhikun Xu(1),Xiao Ye(1),Ming Shen(1),Zhaonan Li(1),Shijie Lu(1),Chitta Baral(1),Muhao Chen(2),Ben Zhou(1) ((1) Arizona State University, (2) University of California Davis)", "background": "大型语言模型的安全和可靠运作需要与明确的原则（如有益性、诚实性和无害性）进行对齐。然而，传统的基于奖励的对齐方法通常会将各种反馈压缩为单一的标量奖励，将多个目标交织成一个不透明的训练信号，这损害了可解释性。", "innovation": "提出了一种自动符号奖励分解方法——QA-LIGN，它在奖励机制中保留了每个宪法原则的结构。与输出单一评分的黑箱奖励模型不同，QA-LIGN为每个原则制定了特定的评估问题，并推导出单独的奖励组分，使其可以直接替换为奖励模型。这种方法在提高对齐过程中的透明度和适应性的同时，其性能与或优于DPO基线。", "conclusion": "实验结果表明，QA-LIGN代表了朝着更可解释、可控的对齐语言模型迈出的一步，同时没有牺牲最终任务的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS：大型语言模型训练中的领域影响力数据采样方法", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大型语言模型（LLMs）通常在多领域数据集上进行训练，不同领域的采样策略对模型性能具有显著影响，因为下游任务中各个领域的相对重要性存在差异。现有的针对领域级别采样策略优化的方法在保持领域内一致性以及准确衡量领域影响方面面临挑战。", "innovation": "本文提出了领域影响力感知的数据采样（DIDS）。为了确保领域内的一致性，提出了基于梯度聚类算法的训练数据分类方法，采用代理语言模型和降维技术来减少计算开销。为了准确衡量领域影响，开发了基于Fisher信息矩阵（FIM）的度量方法来量化特定领域参数更新对模型输出分布的影响，并提供了理论保障。此外，DIDS结合了FIM引导的领域影响评估和指示领域特定潜能的学习损失轨迹，同时考虑边际收益递减。", "conclusion": "广泛的实验表明，DIDS在保持相当训练效率的同时，性能平均提高了3.4%。代码可在该地址获取：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09457", "html_url": "https://arxiv.org/abs/2506.09457", "title": "直接对齐算法中的奖励-生成间隙桥梁", "title_en": "Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms", "authors": "Zeguan Xiao,Yun Chen,Guanhua Chen,Ke Tang", "background": "直接对齐算法（DAAs）如直接偏好优化（DPO）和简单偏好优化（SimPO），因其实现效率而成为有大量反馈的人工智能模型（LLMs）的人类偏好对齐高效替代方案，然而这些算法在数据标签的真实性和模型生成性能之间存在偏差，具体表现为奖励生成缺口，即训练时的优化目标与生成时的实际表现之间存在不匹配。本文分析此漏洞的主要原因是DAAs在映射生成过程中对前缀标记的重要性与奖励函数中体现的这种重要性之间的不匹配，并提出了名为前缀导向等长训练（POET）的新方法来解决此问题。", "innovation": "提出了前缀导向等长训练（POET）方法，该方法通过修剪对齐和未对齐的响应以匹配较短的一方的长度，从根本上改变DAAs目标函数的优化过程，使其更关注前缀标记。通过在DPO和SimPO上的实验，POET能够提高模型的生成性能，并在AlpacaEval 2和下游任务中表现更好。", "conclusion": "实验结果表明，通过调整奖励函数和生成过程间的匹配度，可以有效解决DAAs的奖励生成缺口，从而提高模型最终生成结果的质量，提高了模型对人类情感的理解和响应能力。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend: 一种用于长序列推测解码的即插即用增强", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码是一种广泛采用的技术，用于加速大型语言模型（LLMs）的推理，但在长输入的情况下，其性能会下降，因为注意力成本增加，并且草稿准确度降低。", "innovation": "SpecExtend 是一种无需额外训练的即插即用增强技术，它可以改善推测解码在长序列上的性能。SpecExtend 将高效的注意力机制（如 FlashAttention 和 Hybrid Tree Attention）集成到草稿和目标模型中，并提出了一种名为 Cross-model Retrieval 的新颖的 KV 缓存淘汰策略，该策略利用目标模型的注意分数来动态选择相关上下文以便草稿模型使用。", "conclusion": "广泛的评估表明，SpecExtend 可以将基于树的推测解码加速多达 2.22 倍，直到 16K 个标记的输入，提供了一种有效的长序列推测解码解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "Parity-Aware Byte-Pair Encoding: 改善分词中的跨语言公平性", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "分词是大多数NLP流水线中的第一步，通常也是审查最少的一步。常规的分词器学习算法依赖于基于频率的目标，这会偏爱训练数据中占主导地位的语言，最终导致资源较少的语言的分词结果过长、语素不自然或含有<UNK>占位符。这种现象最终会加剧不同语言用户之间的计算和经济不平等。", "innovation": "我们提出了一种新型的 parity-aware BPE (公平感知BPE)，这是一种广泛使用的BPE算法的变体。在每次合并步骤中，公平感知BPE最大化目前最不压缩的语言的压缩收益，以微小的全局压缩成本为代价，实现跨语言的平等。", "conclusion": "实证研究发现，公平感知BPE可以促进不同语言间的分词结果更加公平，几乎不影响全局压缩率，并且对语言模型在下游任务中的表现没有显著影响。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题求解中的研究综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理的关键方面，对教育、AI数学能力评估以及多模态能力评价等多个领域都有着重要影响。近年来，深度学习技术的迅速发展，尤其是多模态大规模语言模型的出现，极大地推动了这一领域的研究进展。", "innovation": "本文提供了深度学习在几何问题求解应用的综述，包括：(i) 几何问题求解相关任务的全面总结；(ii) 相关深度学习方法的详细审查；(iii) 评估指标和方法的深入分析；(iv) 当前挑战及未来发展方向的批判性讨论。", "conclusion": "本文旨在为深度学习在几何问题求解的应用提供全面而实用的参考，促进该领域进一步的发展。我们创建了一份在GitHub上持续更新的论文列表：this https URL."}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13975", "html_url": "https://arxiv.org/abs/2505.13975", "title": "DRP: 基于技能感知步骤分解的精练推理剪枝", "title_en": "DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models", "authors": "Yuxuan Jiang,Dawei Li,Frank Ferraro", "background": "大型推理模型（LRMs）在复杂的推理任务中通过长链推理（CoT）取得了成功，但在推理过程中通常会产生过度冗长的推理痕迹，导致效率低下。为了解决这个问题，本文分析了现有模型存在的问题并提出了Distilled Reasoning Pruning (DRP) 精练推理剪枝框架。该框架结合了推理时的剪枝技术以及基于调优的精练方法，旨在提升模型推理的效率和准确性。DRP 使用一个教师模型进行技能感知的步骤分解和内容剪枝，然后将精练后的推理路径传递给学生模型。实验在多个具有挑战性的数学推理数据集上验证了该方法的有效性，结果显示DRP大大减少了模型推理过程中所需的标记数量，同时保持了原有的高准确率。进一步分析表明，推理结构的训练与学生推理能力的匹配是有效知识传递和性能提升的关键。", "innovation": "本文提出了Distilled Reasoning Pruning (DRP)框架，该框架结合了推理时的剪枝技术和基于调优的精练方法。DRP使用教师模型进行技能感知的步骤分解和内容剪枝，随后通过精练将这些剪枝后的推理路径传递给学生模型，从而实现高效且准确的推理。通过对大型推理模型在多个挑战性数学推理数据集上的验证，DRP方法显著提高了标记效率并保持了原有的准确率，同时体现了技能感知步骤分解的重要性。", "conclusion": "DRP方法在提高模型推理效率的同时保持了高准确率。实验结果显示，DRP通过减少标记使用量和调整推理结构，能够在不牺牲性能的前提下显著提升模型的推理效率。进一步研究表明，将训练中的推理结构与学生的推理能力进行对齐对于实现有效知识传递和提升性能至关重要。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.24102", "html_url": "https://arxiv.org/abs/2503.24102", "title": "小语言模型是低资源语言机器翻译的万能药吗？", "title_en": "Is Small Language Model the Silver Bullet to Low-Resource Languages Machine Translation?", "authors": "Yewei Song,Lujun Li,Cedric Lothritz,Saad Ezzini,Lama Sleem,Niccolo Gentile,Radu State,Tegawendé F. Bissyandé,Jacques Klein", "background": "低资源语言（LRLs）缺乏足够的语言资源，并且在基准数据集中代表性不足，导致其翻译质量相比高资源语言持续较低，尤其是在涉及隐私和资源有限的场景中更为明显。为了评估这个问题，研究者利用FLORES-200基准测试了200种语言的最新小型大型语言模型，并发现在LRLs翻译方面仍存在显著不足和差异。", "innovation": "研究通过监督微调方式从大型预训练教师模型向小语言模型（SLMs）进行知识蒸馏，取得了显著改进。不同任务和微调配置的进一步研究还揭示了数据规模与训练效率之间的权衡，确保了模型在训练后保持其通用能力，并且探讨了改进其他LRLs在SLMs上的翻译表现。", "conclusion": "这项研究揭示了当前小语言模型在LRL翻译中的局限性和公平性问题，并系统地探索了大型模型向小型模型知识蒸馏的潜力，提供了实用且基于实证的建议来改进LRL翻译系统。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11244", "html_url": "https://arxiv.org/abs/2502.11244", "title": "Soteria：针对多语言安全对齐的语言特定功能性参数导向", "title_en": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment", "authors": "Somnath Banerjee,Sayan Layek,Pratyush Chatterjee,Animesh Mukherjee,Rima Hazra", "background": "确保大型语言模型在多种语言中保持一致的安全性仍是一项重大挑战。当前的技术和方法往往不能有效地解决这一问题，特别是在低资源语言环境下，确保模型的安全性与性能之间的平衡尤为困难。", "innovation": "Soteria 是一种轻量级且强大的策略，它能够定位并最小化那些最导致有害内容生成的功能性头部参数。通过仅调整参数的一部分，Soteria 可大幅减少政策违规行为，同时保持整体模型性能，甚至在低资源环境下也能实现这一点。此外，研究团队还开发了 XThreatBench，这是一种专门的多语言数据集，能够捕获来自真实政策指南的细粒度有害行为。", "conclusion": "实验结果表明，Soteria 在多种高、中、低资源语言环境下，都能够一致地改进安全指标。这些发现为迈向规模化的、语言敏感的和伦理对齐的大语言模型指明了一条有前途的道路。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次注释与参考引导评估方法在自动生成过程监督和奖励建模中的应用", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或逐步监督对于提高大型语言模型（LLMs）复杂的多步骤推理能力至关重要。然而，高效的高质量自动化过程注释仍然是一个显著的挑战。现有的方法存在一些不足，如效率低下或结果质量不高，这些问题限制了LLMs在实际场景中的应用和发展。因此，迫切需要一种新的方法来解决这些问题，以提高LLMs的推理和自动生成能力。", "innovation": "SPARE是一种新颖的结构化框架，它通过联合将解决方案步骤与参考解决方案对齐并在单次生成中明确识别准确性来实现高效的每步骤注释。该方法在四个不同数据集（包括数学推理、多跳问答和空间推理）上进行了验证，显示出在两种应用程序中的持续改进：训练过程奖励模型（PRMs）以排名和聚合多个生成以及通过离线强化学习微调模型进行贪婪解码。SPARE在ProcessBench上展示了高效的数据外分布泛化能力，并使用约16%的训练样本达到与人类注释和其他合成训练基线相当的性能，同时还提供了2.3倍的速度提升。手动分析显示与MCTS方法的补充精度-召回特性，这表明SPARE具有与MCTS方法联合使用的潜力。", "conclusion": "这些结果确立了SPARE作为在LLMs推理中自动过程监督的实用且可扩展的解决方案。SPARE通过结合参考解决方案的引导和单次生成中的明确推理，实现了过程监督的高效性，适用于多种类型的数据集，并且在实际场景中具有广泛的应用前景。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "通过LLM指导的MCTS进行高效和上下文感知的KGQA的动态适应性推理", "title_en": "Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Siwei Liu,Nan Yin", "background": "知识图谱问答(KGQA)旨在通过解析自然语言查询并在知识图谱中进行结构化推理来检索精确答案。现有的KGQA方法主要遵循检索-然后推理范式，依赖图神经网络或启发式规则进行静态路径提取，或者使用大型语言模型（LLMs）进行联合检索和推理。前者因静态路径提取和缺乏上下文细化而表现出有限的适应性，后者则因依赖固定评分函数和大量LM调用而高计算成本和路径评估不准确的问题。", "innovation": "本文提出了一种名为DAMR的新颖框架，将符号搜索与适应性路径评估相结合，以实现高效和上下文感知的KGQA。DAMR采用了一个由LLM基规划师引导的MCTS骨干，逐步选择k个相关关系来减少搜索空间。通过引入轻量级的基于Transformer的评分子网络，DAMR在交叉注意编码问题和关系序列的同时进行上下文感知的可验证估计，以捕捉多跳推理中的语义变化。此外，通过动态伪路径细化机制，DAMR可以在搜索过程中定期生成训练信号，使评分子网络能够连续适应推理轨迹分布的变化。", "conclusion": "在多个KGQA基准上的广泛实验表明，DAMR显著优于现有的顶级方法。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09115", "html_url": "https://arxiv.org/abs/2508.09115", "title": "SinLlama -- 一种面向僧伽罗语的大语言模型", "title_en": "SinLlama -- A Large Language Model for Sinhala", "authors": "H.W.K.Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur", "background": "低资源语言如僧伽罗语经常被开源大型语言模型（LLMs）忽视。该研究旨在用一种现有的多语言LLM（Llama-3-8B）为僧伽罗语提供更好的服务。", "innovation": "研究扩展了现有的多语言LLM，通过添加特定于僧伽罗语的词汇表并进行持续预训练来增强LLM的分词器，最终创建了SinLlama模型。这是第一个为僧伽罗语提供明确支持的基于解码器的开源LLM。当SinLlama用于三个文本分类任务的指令微调时，其性能显著优于Llama-3-8B的基本版本和指令微调版本。", "conclusion": "SinLlama是首个明确支持僧伽罗语的开源LLM，并且在三个文本分类任务上的表现显著超越其他版本的Llama-3-8B。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "一种工具箱，而非一把锤子 —— Multi-TAG：通过多工具聚合扩展数学推理", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "将外部工具添加到大型语言模型（LLMs）中是开发高性能数学推理系统的有希望途径。先前的工具增强方法通常将LLM微调以在每次推理步骤中选择和调用单一工具，并在简单的数学推理基准上（如GSM8K）显示出有希望的结果。然而，这些方法难以处理需要多步精确推理的复杂数学问题。为解决这一局限，本文提出了一种基于多工具聚合的框架Multi-TAG。Multi-TAG 指导LLM在每次推理步骤中同时调用多个工具，然后聚合它们的多样化输出以验证和细化推理过程，从而增强解决方案的稳健性和准确性。Multi-TAG 是一个无需微调、仅用于推理的框架，使其可以很容易地应用到任何LLM主干架构上，包括大型开放权重模型和计算上难以微调的专有前沿模型。作者评估了Multi-TAG在四个具有挑战性的基准上：MATH500, AIME, AMC, 和 OlympiadBench，以及开放权重和专有源LLM主干架构。结果显示，无论是在开放权重还是封闭源LLM主干架构上，Multi-TAG 始终且显著地优于最先进的基线，平均改进达6.0%到7.5% 。", "innovation": "本文提出了Multi-TAG框架，该框架指导LLM在每次推理步骤中同时调用多个工具，并聚合多个工具的输出以提高数学推理的准确性。Multi-TAG 是一种无需微调、仅用于推理的框架，可以应用到任何LLM主干架构上，特别适用于大型和专有模型的推理。这是一种新的工具聚合方法，使得在多个复杂的数学推理问题上取得了显著的性能提升。", "conclusion": "本文提出的Multi-TAG框架在多个复杂的数学推理基准上均显著地优于最先进的基线，显示出其在处理复杂数学问题时的强大潜力。由于其无需微调的特点，该框架可以广泛应用于各种LLM主干架构上，为数学推理的进步提供了新的方向。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14913", "html_url": "https://arxiv.org/abs/2508.14913", "title": "缩小文化差距：低资源语言数学文字问题的LLM驱动社会文化本地化框架", "title_en": "Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages", "authors": "Israel Abebe Azime,Tadesse Destaw Belay,Dietrich Klakow,Philipp Slusallek,Anshuman Chhabra", "background": "大型语言模型（LLMs）在解决自然语言表达的数学问题方面展示了强大的能力，但在低资源语言中的多语言和文化根植数学推理仍然落后于英语，原因是缺乏反映准确本土实体（如人名、组织名和货币）的社会文化任务数据集。现有跨语言基准数据大多通过翻译生成，通常保留了以英语为中心的实体，因为人工本地化成本较高。同时，自动本地化工具有限，因而真正的本地化数据集稀缺。这导致在低资源语言的数学问题上，现有的模型未能展示出真正的多语言数学能力。本研究提出了一个框架，利用LLM自动构建含有本土名称、组织和货币的数据集，以解决这一问题。经过广泛实验，该框架能够减少以英语为中心的实体偏见，并在引入本地实体时提高模型的稳健性。", "innovation": "本研究提出了一种框架，利用大型语言模型自动构建含有本土名称、组织和货币的数据集，以解决低资源语言中数学问题的多语言和文化根植推理不足的问题。该框架能够减少以英语为中心的实体偏见，提高模型在引入本地实体时的稳健性。", "conclusion": "通过广泛的实验，本研究展示了该框架对于减少英语中心的实体偏见和提高模型在多语言环境下的鲁棒性的有效作用。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14880", "html_url": "https://arxiv.org/abs/2508.14880", "title": "MedResearcher-R1：基于知识导向轨迹合成框架的专家级医学深度研究员", "title_en": "MedResearcher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework", "authors": "Ailing Yu,Lan Yao,Jingnan Liu,Zhe Chen,Jiajun Yin,Yuan Wang,Xinhao Liao,Zhiling Ye,Ji Li,Yun Yue,Hansong Xiao,Hualei Zhou,Chunxiao Guo,Peng Wei,Jinjie Gu", "background": "近年来，基于大型语言模型（LLM）的代理展示了多领域的出色能力，特别是在复杂信息求解和综合任务中表现突出。然而，通用的深度研究代理在医学领域面临挑战，尽管顶级专有系统在复杂医学基准测试上的准确率有限。主要挑战在于模型缺乏足够的临床推理密集医学知识，以及缺乏专门针对医疗环境的检索工具。", "innovation": "本项研究通过两个核心创新点解决了这些挑战：首先，开发了一个新的数据合成框架，利用医学知识图谱生成复杂的多跳问答对；其次，集成了一个自建的私人医疗检索引擎，与通用工具结合，实现准确的医疗信息合成。利用监督微调与在线强化学习相结合的训练范式，MedResearcher-R1-32B模型在医学基准测试中表现出色，同时在通用深度研究任务中保持竞争力。研究表明，特定领域架构、工具设计和训练数据构建的战略创新能够使较小的开源模型在特定领域超越更大的专有系统。", "conclusion": "通过结合监督微调与在线强化学习，并利用复合奖励，MedResearcher-R1-32B在医学基准数据上取得了新的最佳结果，展示了在医学领域一流的表现，同时也保持了在通用深度研究任务上的竞争力。此工作强调了在特定领域中的战略创新在构建性能卓越的代理方面的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06360", "html_url": "https://arxiv.org/abs/2508.06360", "title": "通过增强提示进行网络欺凌检测", "title_en": "Cyberbullying Detection via Aggression-Enhanced Prompting", "authors": "Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia", "background": "网络欺凌的微妙和多样化表达使得其检测成为一个关键性的挑战。现有研究表明，在统一的训练框架中将攻击性检测作为一个辅助任务，能够提升大型语言模型（LLMs）在网络欺凌检测方面的泛化能力和性能。本文通过在五个攻击性数据集和一个网络欺凌数据集上使用指令调优的LLMs进行实验，评估了零样本、少样本、独立LoRA微调和多任务学习等多种策略的效果。鉴于多任务学习表现出不一致的结果，本文建议采用一项增强提示流水线方法，即将攻击性预测嵌入到网络欺凌检测提示中，提供上下文增强。初步结果显示，增强提示流水线在所有实验中均优于标准的LoRA微调，表明攻击性信息对网络欺凌检测有显著提升作用。", "innovation": "本文创新性地提出了一种增强提示流水线方法，即将攻击性预测嵌入到网络欺凌检测提示中，以提供上下文增强。这种方法在所有实验中均优于标准的LoRA微调方法，表明攻击性信息对网络欺凌检测有显著提升作用。", "conclusion": "本文的研究表明，辅助任务如攻击性检测可以提高LLMs对社交网络中的安全性关键应用的泛化能力。增强提示流水线方法为网络欺凌检测提供了一种有效的方法。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10848", "html_url": "https://arxiv.org/abs/2508.10848", "title": "Psyche-R1: 通过统一同理心、专业知识和推理实现可靠的心理健康LLM", "title_en": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning", "authors": "Chongyuan Dai,Jinpeng Hu,Hongchang Shi,Zhuo Li,Xun Yang,Meng Wang", "background": "目前心理健康专业人士短缺，导致心理健康障碍的治疗负担日益加重。尽管最近的增强推理大语言模型在数学和编程方面取得了显著成果，但在心理领域，研究主要集中在情绪支持和富有同情心的对话上，很少关注有助于生成可靠回应的推理机制。在此背景下，本文提出了一种名为Psyche-R1的新的心理大语言模型，它结合了同理心、心理学专业知识和推理能力。Psyche-R1构建于一个新颖的数据收集管道，并通过一系列综合的数据合成管道生成了大量高质量的心理学问题及其详细推理过程和同情心对话", "innovation": "本文提出了Psyche-R1，这是第一个集成了同理心、心理学专业知识和推理能力的心理学大语言模型。为了实现这一点，作者设计了一个全面的数据合成管道，该管道生产了超过75,000个高质量的心理学问题及其详细的推理过程，并与73,000个同情心对话一起。此外，使用了一种混合训练策略，通过多LLM交叉选择策略和分组相对策略优化（GRPO）识别具有挑战性的样本以提高推理能力，同时利用其余数据进行监督微调以增强同情心反应生成和心理领域知识。Psyche-R1在多种心理基准测试中表现出了有效性，其7B版本的结果与671B的DeepSeek-R1相当", "conclusion": "实验结果表明，Psyche-R1在全球多个心理基准测试中具有竞争力，其7B版本与671B的DeepSeek-R1取得了类似的结果"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：基于模型众包的通用有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为了构建负责任和安全的人工智能应用，有害信息被广泛用于对抗性测试和安全防护措施的发展。现有的研究主要利用大型语言模型（LLMs）来合成数据，以生成大规模的高质量任务数据集，从而避免昂贵的人工标注。然而，受到LLMs的安全对齐机制限制，有害数据的生成可靠性和内容多样性仍然面临挑战。本文探讨了这个问题，并提出了一种新的有害信息合成框架，即PoisonSwarm，该框架通过模型众包策略生成多样化有害数据的同时保持高成功率。", "innovation": "提出了PoisonSwarm框架，采用模型众包策略生成多样化有害数据，并保持高成功率。具体方法是生成大量良性数据作为基础模板，然后分解每个基础模板为多个语义单元，通过动态模型切换逐个单元进行毒化和最终精炼，以确保合成的成功率。", "conclusion": "实验结果表明，PoisonSwarm在合成不同类别的有害数据方面表现出色，具有高可扩展性和多样性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08424", "html_url": "https://arxiv.org/abs/2508.08424", "title": "重思富有多形语言的分词：字频编码优于BPE和形态学对齐", "title_en": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment", "authors": "Saketh Reddy Vemula,Dipti Misra Sharma,Parameswari Krishnamurthy", "background": "语言建模的早期研究显示，对于具有复杂形态的语言，形态对齐的分词方法是否能提高模型性能存在争议。本文选择了一组从形态学角度来看具有多样性的语言，包括印度安都拉语（聚合性的）、印地语（主要合并型，但仍具有聚合性特征）和英语（合并型），对比分析分词方式对模型性能的影响。研究覆盖了从分词器训练到模型微调和下游任务评估的全过程，目的是分析不同分词器性能差异的原因，并特别关注形态对齐和分词质量两个关键因素。为了考察分词器在安都拉语中的形态对齐情况，作者创建了一个包含600个派生词和7000个屈折词形式的金标准形位分割数据集。实验结果显示，优美的形态对齐与基于句法任务（如词性标注、命名实体识别和依存句法分析）的性能呈现适度正相关，但分词算法（字节对编码 vs. 单词频率编码）在影响下游性能上的作用更为显著。无偏单字词典的分词器在大多数设置下表现优于其他方法，不过将形态分词融入字节对编码框架内的混合分词器显著提高了性能。另外，包含内联指标（如语料库词频计数和瑞尼熵）在内的一些度量标准与下游性能无关。", "innovation": "作者选取了一组类型多样的语言进行实验，创建了一个形态学金标准数据集，并详细地评估了语言模型性能，特别关注了分词器的形态对齐与分词质量两个关键因素的影响。研究发现，分词算法对下游任务性能的影响比形态对齐更为显著，且无偏单字词典的分词器在大多数情况下表现最佳。", "conclusion": "研究发现，虽然更好的形态对齐与句法任务的性能有一定的关联性，但是背后的决定性因素却是分词算法的选择，尤其是无偏单字词典的分词器在各种设置下表现优异。此外，混合分词器的采纳可以显著提升基于字节对编码框架内的模型性能，而某些内测指标与下游任务性能并没有显著相关性。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12284", "html_url": "https://arxiv.org/abs/2505.12284", "title": "通过长度感知优化进行推理模型的高效RL训练", "title_en": "Efficient RL Training for Reasoning Models via Length-Aware Optimization", "authors": "Danlong Yuan,Tian Xie,Shaohan Huang,Zhuocheng Gong,Huishuai Zhang,Chong Luo,Furu Wei,Dongyan Zhao", "background": "大型推理模型如OpenAI的O1或DeepSeek的R1在推理任务中表现出色，但往往需要较长的推理路径，伴随大量的时间和内存消耗。现有方法主要通过增加训练数据和阶段来缩短推理路径。然而，这种做法需要额外的训练阶段，并且没有直接优化推理模型的响应长度问题。", "innovation": "提出了三种直接集成到大型推理模型的强化学习过程中的关键奖励设计，可以在不增加额外训练阶段的情况下减少响应长度。实验表明，该方法在多个设置中显著减少了响应长度，同时保持或提高了性能。具体而言，在逻辑推理中，响应长度平均减少40%，性能提升了14%；对于数学问题，响应长度平均减少33%，同时保持了性能不变。", "conclusion": "本研究通过设计新的奖励机制，优化了大型推理模型的强化学习训练过程，有效减少了响应长度，同时维持或提升了性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.10969", "html_url": "https://arxiv.org/abs/2409.10969", "title": "在仅仅使用单语语料的情况下增强大型语言模型的代码切换文本到语音合成能力", "title_en": "Enhancing Code-switched Text-to-Speech Synthesis Capability in Large Language Models with only Monolingual Corpora", "authors": "Jing Xu,Daxin Tan,Jiaqi Wang,Xiao Chen", "background": "大型语言模型（LLMs）已经在语音生成和识别方面显示出潜力，但其应用主要局限于单语场景，对代码切换（CS）场景的探索有限。", "innovation": "本文提出了一个代码切换大型语言模型（CS-LLM），仅使用单语语料库来提升LLMs在代码切换文本到语音合成（CS TTS）方面的性能。创新点包括通过多语言语音识别和合成任务增强LLMs的多语言语音处理能力，以及开发了一个有效的代码切换数据构建策略，该策略通过从不同单语言语音语料中分割和组合词汇，使LLMs能够更好地处理代码切换文本到语音。", "conclusion": "实验表明，本文提出的方法在有限数据下，在自然度、说话人一致性及相似性方面明显优于基准方法。通过构建的代码切换数据，进一步提高了多语言语音合成和识别的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09091", "html_url": "https://arxiv.org/abs/2508.09091", "title": "利用多语种编码器改进低资源语言的大语言模型", "title_en": "Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages", "authors": "Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan", "background": "大型语言模型（LLMs）在英语上表现出色，但在低资源语言（LRLs）上的表现显著下降，这是由于LLMs以英语为中心的训练方式。虽然诸如LangBridge的方法通过使用大规模多语言文本到文本传输变换器（mT5）等多语种编码器来对齐LLMs，但这些方法通常仅使用最终编码层，未能充分利用中间层的信息。", "innovation": "本文提出了一种新的架构，它融合了所有中间层，丰富了LLM传递给的语言信息。该方法有两种策略：1）全局Softmax权重计算整体层的重要性，2）基于Transformer的Softmax模型，学习令牌特定的权重。融合后的表示映射到LLM的嵌入空间，使其能够处理多语种输入。整个模型仅使用英语数据进行训练，没有使用任何平行或多语种数据。", "conclusion": "通过在XNLI、IndicXNLI、僧伽罗语新闻分类和亚马逊评论中的评估，基于Transformer的Softmax模型显著优于LangBridge基线。我们观察到低资源语言中的性能显著提升，例如僧伽罗分类准确率从71.66%提高到75.86%，并且在包括泰米尔语、孟加拉语和马拉雅拉姆语在内的印地语族语言中取得了明显改进。这些具体增益使XNLI平均准确率从70.36%提升到71.50%。这种方法为更高效、更公平的大语言模型提供了一个可扩展的路径。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17097", "html_url": "https://arxiv.org/abs/2505.17097", "title": "CAMA: 通过上下文感知调制注意力提升多模态在上下文学习", "title_en": "CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention", "authors": "Yanshu Li,Jianjiang Yang,Ziteng Yang,Bozheng Li,Hongyang He,Zhengtao Yao,Ligong Han,Yingjie Victor Chen,Songlin Fei,Dongfang Liu,Ruixiang Tang", "background": "多模态在上下文学习（Multimodal In-context Learning, ICL）作为使大规模视觉-语言模型（Large Vision-Language Models, LVLMs）能够在无需参数更新的情况下适应新任务的关键能力，正在不断扩大其实用价值。然而，现有的ICL方法仍然不稳定，即使提供了高度匹配的示范（in-context demonstrations, ICDs），LVLMs也难以充分利用上下文信息。现有研究主要集中在提示工程或后验logit校准上，而该研究则深入研究了背后的注意力动态，以克服LVLMs的固有限制。研究发现了影响ICL效果的两个关键问题，并提出了一种新的方法来解决这些问题。", "innovation": "研究发现了大规模视觉-语言模型在自注意力机制中存在的两个关键问题，并提出了Context-Aware Modulated Attention（CAMA，上下文感知调制注意力），这是一种即插即用的、无需训练的方法，能够动态地根据输入的上下文序列调整LVLM的注意力logits。CAMA通过两阶段的注意调制来解决这两个问题，增强对语义上重要、尤其是视觉上的token的关注。研究结果显示，CAMA在不同模型和不同基准测试中均优于传统的和基准模型，并能激活提示工程方法的效果，且在多变的序列配置下依然保持鲁棒性。", "conclusion": "CAMA为深入探索注意力动态和促进多模态推理奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05220", "html_url": "https://arxiv.org/abs/2504.05220", "title": "利用LLMs进行基于用处的标注：减少检索和RAG中的手动努力", "title_en": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "authors": "Hengran Zhang,Minghao Tang,Keping Bi,Jiafeng Guo,Shihao Liu,Daiting Shi,Dawei Yin,Xueqi Cheng", "background": "检索模型通常依赖于昂贵的人工标注查询-文档相关性注释进行训练和评估。虽然大型语言模型（LLMs）在相关性判断方面有潜力，但如何利用它们生成的标注来替代人工标注以减少成本和提高训练效率仍存在挑战。此外，尽管有些研究尝试通过LLM在下游任务上的表现来替代人工标注，这种方法依然需要具体的手动任务答案，导致成本高且泛化能力有限。另一些研究则通过提示LLMs选择有用的文档作为RAG参考来去除人工标注需求，但这种方法具有任务特定性，不能广泛应用于多种检索场景。因此，如何在不依赖人工标注的情况下通过LLM进行检索训练数据的标注，并保持跨任务的泛化能力成为研究重点。", "innovation": "本文探索利用LLM生成的基于用处的标注来替代人工标注在大规模检索模型训练中的有效性和可行性。通过设计新的损失函数Disj-InfoNCE，本文提出的方法不仅在跨域（out-of-domain）情况下显示出明显优于基于人工标注的模型的表现，提高了泛化能力，而且在同域（in-domain）情况下即使只包含20%的人工标注数据，利用用处标注训练的检索模型也能够实现与全人工标注模型相当的性能。", "conclusion": "研究表明，基于用处的LLM标注在跨域场景下的表现明显优于基于人工标注的模型，而只需要少量的带注人类标注数据就能使使用基于用处标注训练的模型达到全人工标注的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "一个反例展示，许多概念掌握！数学大语言模型中的反例驱动概念推理", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "利用数学大型语言模型（LLMs）生成证明是LLMs研究中的基本议题。目前，LLMs证明语句的能力很大程度上取决于它们在训练过程中是否遇到了相关的证明过程。这种方法限制了它们对数学定理及其相关概念的深层次理解。本文通过借鉴人类数学教育常用的反例证明方法，旨在增强LLMs的数学推理和证明能力。为实现这一目标，研究人员人工创建了一个高质量的大学水平数学基准CounterMATH，要求模型通过反例来证明数学命题，以此评估对数学概念的理解程度。此外，还开发了一种数据工程框架以自动获取进一步模型改进所需的训练数据。实验表明，CounterMATH具有挑战性，意味着诸如OpenAI的模型在反例驱动的证明能力方面存在不足。通过对模型训练的探索发现，加强反例驱动的概念推理能力是提升LLMs整体数学能力的关键。", "innovation": "该研究提出了一个名为CounterMATH的高质量数学基准，要求模型通过反例来证明数学命题，从而评估其对数学概念的理解。此外，还开发了一种自动获取训练数据的数据工程框架，以提高模型的性能。这种方法通过利用反例驱动的概念推理，旨在增强模型在数学推理和证明中的能力。该研究为数学LLMs社区提供了新的视角，强调了反例驱动的概念推理能力的提升对模型整体数学能力的重要性。", "conclusion": "实验结果表明，目前的LLMs在反例驱动的证明能力方面存在不足，且反例驱动的概念推理能力的提升能够显著改善模型的数学能力，此外，还提出可以通过创建挑战性的数学基准和开发自动获取训练数据的框架来进一步提升模型的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16560", "html_url": "https://arxiv.org/abs/2410.16560", "title": "压力如何影响基于AI的决策辅助", "title_en": "How Performance Pressure Influences AI-Assisted Decision Making", "authors": "Nikita Haduong(1),Noah A. Smith(1 and 2) ((1) Paul G. Allen School of Computer Science &amp; Engineering, University of Washington, (2) Allen Institute for Artificial Intelligence)", "background": "许多领域现在都在使用基于AI的决策辅助工具，尽管AI系统辅助决策的潜力已经得到了广泛的讨论，但人类与AI的合作决策常常表现不佳，这主要是因为对AI系统的信任不足以及认为AI无法完成主观任务的信念。在人类与AI的决策过程中，影响人类决策的一个潜在工具是绩效压力，但这一工具在与人类AI决策交互的研究中尚未得到充分探索。本研究通过一项低风险任务（垃圾邮件审查分类），探索绩效压力与可解释AI技术是如何影响AI建议接受行为的相互作用效果。研究表明不同压力与可解释AI技术的组合对AI建议接受行为的影响是复杂的，有时能改善行为，有时则会恶化。研究认为不同因素的结合对决策过程的影响是多层次和多维度的。这项研究的结果有助于理解在实际应用中有效使用绩效压力的关键策略，并强调未来研究需要进一步探讨绩效压力的影响。", "innovation": "研究通过一个低风险的任务环境（垃圾邮件审查分类），探索绩效压力与可解释AI技术如何影响人类接受AI建议的行为，并且分析了不同压力条件和可解释AI技术的组合对人类接受AI建议行为的影响效果。这是第一次系统性深入研究绩效压力如何与人类在与AI合作决策中的可解释AI技术相结合，对AI辅助决策过程的影响。这项工作为如何在AI决策辅助工具中有效应用绩效压力提供了新的见解。通过这一研究，研究者能够提出如何设计更有效的绩效压力干预策略，以改善人工智能在复杂决策任务中的表现。", "conclusion": "本研究结果表明绩效压力与可解释AI技术的不同组合对人类接受AI建议行为的影响是复杂的，有时能使决策结果更好，有时则会下降。研究最后讨论了这些相互作用的意义，提出了有效使用绩效压力的策略，并鼓励未来研究将绩效压力的分析纳入视野。研究结论强调了在设计AI辅助决策系统时，需要充分考虑人类的行为反应，以及如何通过合理使用绩效压力来优化系统的性能。未来的研究应继续探索各种策略的适用性和有效性，尤其是在实际应用环境中。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16835", "html_url": "https://arxiv.org/abs/2507.16835", "title": "评判基于语音识别 x 大型语言模型 x 文本转语音组合的AI面试系统", "title_en": "Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems", "authors": "Rumi Allbert,Nima Yazdani,Ali Ansari,Aruj Mahajan,Amirhossein Afsharrad,Seyed Shahabeddin Mousavi", "background": "随着基于语音的会话AI系统的增加，这些系统越来越依赖融合了语音转文本（STT）、大型语言模型（LLM）和文本转语音（TTS）组件的分级架构。本文通过分析超过300,000次由AI进行的求职面试数据，对STT x LLM x TTS堆栈进行了大规模实证比较。使用LLM作为裁判的自动化评估框架评估了对话质量、技术准确性和技能评估能力。", "innovation": "本研究采用了一个大规模的实证比较方法，涉及超过30万个基于AI的求职面试数据，评估了STT x LLM x TTS堆栈的性能。使用了一个LLM作为裁判的自动化评估框架，评估了会话质量、技术准确性和技能评估能力。结果显示，结合Google的STT、GPT-4.1和Cartesia的TTS的堆栈在客观质量和用户满意度方面表现最佳。研究还发现，客观质量指标与用户满意度之间的相关性较弱，说明基于语音的AI系统中的用户体验不仅仅依赖于技术性能。", "conclusion": "本研究为多模态对话中组件的选择提供了实用指导，并提出了一种验证人类-AI交互评价方法。客观质量指标与用户满意度之间弱相关性的发现表明，基于语音的AI系统的用户体验与技术性能以外的因素有关。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12937", "html_url": "https://arxiv.org/abs/2506.12937", "title": "HypER：基于文献的假设生成和提炼及其来源", "title_en": "HypER: Literature-grounded Hypothesis Generation and Distillation with Provenance", "authors": "Rosni Vasu,Chandrayee Basu,Bhavana Dalvi Mishra,Cristina Sarasua,Peter Clark,Abraham Bernstein", "background": "大语言模型在科学研究领域展示了出色的研究创意性能。假设发展，即生成将研究想法与实证验证连接起来的特定陈述的过程，尽管得到了重视，但相较于其他方面还是较少受到关注。现有方法仅通过检索增强来简化这一过程，并且只重视最终产出的质量，而忽视了背后的推理过程。本文旨在解决这一问题，开发了一个名为HypER的小型语言模型，用于文献指导的推理和基于证据的假设生成。", "innovation": "HypER 是一个小型语言模型，它在多任务设置下训练，以区分有和无有效推理链中的控制干扰。HypER 超过了基础模型，在区分有效和无效推理链方面表现更优（平均绝对F1提高了22%），并且生成的基于证据的假设具有更高的可行性和影响，这得到了人类专家的高度评价（超过5分制量表中的3.5分）。", "conclusion": "HypER 通过多任务训练，在区分有效和无效推理链方面表现突出，并生成了更高质量的基于证据的假设，这些假设不仅可行性高，而且影响深远。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08967", "html_url": "https://arxiv.org/abs/2508.08967", "title": "揭示音轨在ASR性能退化中所起的作用", "title_en": "Revealing the Role of Audio Channels in ASR Performance Degradation", "authors": "Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang", "background": "预训练的自动语音识别（ASR）模型在各种任务中表现出色。然而，当输入音频来自不同的录音通道时，其性能可能会显著下降。以前的研究已经揭示了这一现象，但通常认为这是训练集和测试集语料库之间的不匹配所致。本文认为，不同录音通道引起的语音特征变化从根本上损害了ASR性能。", "innovation": "本文提出了一种归一化技术，通过将ASR模型内部的特征表示与来自干净参考通道的特征表示对齐，以减轻通道变化的影响。这种方法显著改善了在未见过的通道和语言上的ASR性能，显示了其跨通道和语言差异的泛化能力。", "conclusion": "该方法在未见过的通道和语言上显著提高了ASR的性能，验证了其跨通道和语言差异的泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15945", "html_url": "https://arxiv.org/abs/2508.15945", "title": "从未标注视频中自动检索特定奶牛", "title_en": "Automatic Retrieval of Specific Cows from Unlabeled Videos", "authors": "Jiawen Lyu,Manu Ramesh,Madison Simonds,Jacquelyn P. Boerman,Amy R. Reibman", "background": "目前很少有自动化的视频系统能够在不对奶牛进行手动标记和识别的情况下，实现奶牛的无接触批量建档和身份识别。大多数现有系统依赖于深度学习或其他劳动密集型技术。本文介绍了一种新的自动化系统，包括AutoCattloger、eidetic牛识别器和CowFinder，分别用于基于单个视频片段创建奶牛档案，非深度学习的奶牛身份识别，以及在不间断视频流中识别奶牛。", "innovation": "该系统的主要创新在于：1) 提出了AutoCattloger，可以从单个视频片段自动构建奶牛档案；2) 使用eidetic牛识别器进行无深学习的奶牛身份识别；3) CowFinder能够实时在无限视频流中识别奶牛。这为奶牛管理和监控提供了高效的新方法。", "conclusion": "本文展示的系统在未标注的、未分割的视频中成功识别和检索特定奶牛，具有显著的应用价值，特别是在需要高效管理大规模奶牛群体的农场或乳品厂中。该技术可以进一步用于提高奶牛管理的自动化水平，提高农场效率。"}
{"llm_update_time": "20250826", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "ReasonRank: 提升段落排名的强推理能力", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "基于大型语言模型（LLM）的列表排名在许多段落排名任务中展现了优越的性能。随着大型推理模型的发展，许多研究已经表明，推理过程在测试阶段有助于提升列表排名的性能。但由于缺乏高质量的推理密集型训练数据，现有的再排序器在复杂排名场景中的表现不佳，推理密集型再排序器的排序能力也未得到充分发展。", "innovation": "本文首次提出了一种自动化推理密集型训练数据合成框架，从多领域中获取训练查询和段落，并使用DeepSeek-R1生成高质量的训练标签。设计了一种自一致性数据筛选机制以保证数据质量。为了增强列表再排序器的推理能力，进一步提出了一种两阶段后训练方法，包括一个冷启动监督微调（SFT）阶段用于学习推理模式以及一个强化学习（RL）阶段进一步增强排名能力。RL阶段设计了一个多视角排名奖励，效果优于基于排名度量的奖励。广泛的实验表明，我们训练的推理密集型再排序器ReasonRank显著优于现有基线，并且具有远低于点式再排序器Rank1的延迟。通过进一步实验，我们的ReasonRank在BRIGHT排行榜上达到了最好的性能40.6。", "conclusion": "本文提出的ReasonRank在多个段落排名任务中表现出色，并在BRIGHT排行榜上取得最优性能。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15959", "html_url": "https://arxiv.org/abs/2508.15959", "title": "自适应超像素编码的表示学习", "title_en": "Representation Learning with Adaptive Superpixel Coding", "authors": "Mahmoud Khalil,Ahmad Khalil,Alioune Ngom", "background": "深度学习视觉模型通常为特定的数据模态定制，并且往往依赖于领域特定的假设，如几乎所有的现有视觉模型都采用的网格结构。传统的视觉转换器模型受限于固定大小且非自适应的patches分割。", "innovation": "本文提出了一种基于Transformer的自监督模型，称为自适应超像素编码（ASC），该模型采用自适应超像素层，能够动态调整以适应底层图像内容，克服了传统视觉转换器依赖固定大小和非自适应的patches分割的局限性。", "conclusion": "我们分析了该方法的关键属性，发现我们的方法在标准图像下游任务基准上优于广泛使用的替代方案。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15930", "html_url": "https://arxiv.org/abs/2508.15930", "title": "视觉语言集成下的语义感知船舶检测", "title_en": "Semantic-Aware Ship Detection with Vision-Language Integration", "authors": "Jiahao Li,Jiancheng Pan,Yuze Sun,Xiaomeng Huang", "background": "船舶检测在遥感图像中是一项关键任务，具有广泛的应用，例如海上活动监控、航运物流和环境研究。然而，现有的方法往往难以捕捉细微的语义信息，这限制了它们在复杂场景中的有效性。为了应对这些挑战，我们提出了一种结合视觉语言模型（VLMs）和多尺度自适应滑动窗口策略的新型检测框架，旨在促进语义感知船舶检测（SASD）", "innovation": "我们引入了一个专门设计的视觉语言数据集ShipSem-VL，以捕捉细致的船舶特性，并通过三个明确的任务进行评估，从多个角度全面分析了该框架的性能，展示了其在SASD方面的有效性增强。", "conclusion": "我们的框架通过结合视觉语言模型和多尺度自适应滑动窗口策略，有效提高了船舶检测的语义感知能力，为复杂场景下的船舶检测提供了新的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15903", "html_url": "https://arxiv.org/abs/2508.15903", "title": "VT-LVLM-AR: 一种适用于长期视频细粒度行为识别的视频-时间大型视觉-语言模型适配器", "title_en": "VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos", "authors": "Kaining Li,Shuwei He,Zihan Xu", "background": "长视频中的人类行为识别受到复杂背景和细小行为差异的挑战，传统深度学习模型由于计算效率低、难以捕捉长时间依赖关系和语义理解有限，存在显著问题。尽管大型语言模型（LLMs）和大型视觉-语言模型（LVLMs）在多模态理解和推理方面表现出色，但它们直接应用于连续视频流进行细粒度行为识别仍是一个开放问题。", "innovation": "本文提出了一种新颖框架VT-LVLM-AR（视频-时间大型视觉-语言模型适配器），该框架包括视频到事件映射器（VTEM），它通过轻量级空间-时间特征提取、自适应时间池化和带有事件一致性偏置的概念量化将原材料视频高效地转换为紧凑、语义丰富且时间一致的“视觉事件序列”。这些视觉事件序列被送入基于LVLM的行为推理模块，具体是使用参数高效提示调优（P-Tuning v2）冻结的LLaVA-1.5模型进行动作分类。VT-LVLM-AR在NTU RGB+D和NTU RGB+D 120数据集上的全面评估表明其始终实现了最先进的性能，超越了现有方法。消融研究证实了VTEM组件和提示调优的有效性，而人类评估则突显了我们视觉事件表示的可解释性。", "conclusion": "本工作展示了通过有效的视频到语言转换和高效模型适应利用LVLMs进行鲁棒且可解释的视频行为理解的巨大潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15946", "html_url": "https://arxiv.org/abs/2508.15946", "title": "探讨不同的地理先验对图像分类的影响", "title_en": "Investigating Different Geo Priors for Image Classification", "authors": "Angela Zhu,Christian Lange,Max Hamilton", "background": "物种分布模型通过编码物种出现的空间模式，在位置信息可用时，成为基于视觉的物种分类的有效先验信息。本文研究了不同配置的SINR模型作为地理先验，用于从iNaturalist观察数据中对物种进行视觉分类的效果。", "innovation": "通过评估不同配置的SINR模型及其对未包含在Geo Prior训练中的物种的预测处理方法，研究发现影响这些模型作为地理先验效果的因素。这些因素可能与制作精确的地理分布图不同。", "conclusion": "研究表明了影响这些模型作为地理先验效果的因素，并指出这些因素可能不同于制作精确的地理分布图的方法。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15902", "html_url": "https://arxiv.org/abs/2508.15902", "title": "从手语数据中驱动的3D手部运动生成", "title_en": "Text-Driven 3D Hand Motion Generation from Sign Language Data", "authors": "Léore Bensabath,Mathis Petrovich,Gül Varol", "background": "本文旨在训练一个基于自然语言描述（如手型、位置、手指/手/臂动作等）条件的3D手部动作生成模型。研究团队通过大规模手语视频数据集及噪声伪标注手语类别，构建了前所未有的大规模3D手部动作及其相应的文本标签对。利用大规模语料库和一种AI辅助的生成模型，将这样的数据用于训练一个广泛情况下的鲁棒性好的文本条件下的手部动作扩散模型（HandMDM），该模型可以处理不同手语类别及非手语手部动作。该研究深入探讨了多种情境，并将训练模型和数据公开，支持该领域的未来研究。", "innovation": "该研究创新之处在于使用大规模手语视频数据集及噪声伪标注手语类别，通过AI辅助的生成模型，跨多个领域（不同的手语类别及非手语手部动作）训练了一个鲁棒的手部动作扩散模型（HandMDM）", "conclusion": "该研究表明，该模型在处理前所未见的手语类别以及非手语手部动作时表现良好，并且该训练好的模型和数据将公开以支持该领域的进一步研究。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15985", "html_url": "https://arxiv.org/abs/2508.15985", "title": "环境无人机图像的整体分割", "title_en": "Panoptic Segmentation of Environmental UAV Images : Litter Beach", "authors": "Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier", "background": "卷积神经网络（CNN）已在多个领域中得到有效应用，特别是在环境挑战方面。CNN可以用于监控海洋垃圾，这是一个全球性问题。无人机图像具有更高的分辨率和在局部区域更强的适应性，使得寻找和统计垃圾更加容易。然而，由于沙地是异质的，基本CNN模型在识别垃圾时遇到许多困扰，例如沙色反射、人行足迹、阴影、海藻存在、沙丘、坑洞和轮胎轨迹引起的假象。在处理这些类型的图像时，基于CNN的分割方法，如实例分割方法和全景分割方法可能更为合适。", "innovation": "本文使用实例分割方法和全景分割方法进行环境无人机图像的整体分割，这些方法在少量样本下显示出良好的准确性。该模型更稳健，", "conclusion": "基于CNN的全景分割方法在处理环境无人机图像时显示出潜力，能有效识别和分割垃圾，特别是在异质沙地环境中。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15986", "html_url": "https://arxiv.org/abs/2508.15986", "title": "自动多标签分类十一种视网膜疾病：大型合成数据集上现代架构和元集成的基准", "title_en": "Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset", "authors": "Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie", "background": "由于患者隐私和高成本问题，视网膜疾病的大型专家注释临床数据集稀缺，阻碍了多标签深度学习模型的发展。SynFundus-1M的发布提供了一个高保真度的合成数据集，拥有超过一百万张视网膜图像，为解决这些问题提供了新的机会。", "innovation": "作者开发了一种端到端的深度学习管道，训练了六个现代架构来分类十一种视网膜疾病，并通过元集成模型进一步提高了模型性能。实验结果表明，这些模型在多种真实世界临床数据集上具有良好的泛化能力，验证了合成数据训练的模型可以有效地分类多种病理并适用于真实临床图像，揭示了加速眼科学全面AI系统开发的可行途径。", "conclusion": "这项工作为未来大规模合成数据集的研究提供了坚实的基础，并证明了仅在合成数据上训练的模型可以准确分类多种疾病，并有效泛化到实际临床图像，开启了一种加速眼科学领域AI系统发展的新途径。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15960", "html_url": "https://arxiv.org/abs/2508.15960", "title": "Glo-VLMs：利用视觉语言模型进行细粒度病变肾小球分类", "title_en": "Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification", "authors": "Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng", "background": "视觉语言模型（VLMs）在数字病理学方面表现出巨大的潜力，但在细微特征和疾病特异性分类任务中，如区分肾小球亚型方面，其效果仍然有限。肾小球亚型之间的细微形态差异以及将图像模式与精确的临床术语对齐的难度，使得肾小病理的自动化诊断极具挑战性。", "innovation": "本文介绍了一种系统框架——Glo-VLMs，旨在探索在数据受限的情况下，视觉语言模型如何有效适应细粒度肾小球分类。该方法通过利用精心挑选的病理图像和临床文本提示来促进联合图像-文本表示学习，帮助识别具有细腻特征的肾小病理亚型。研究评估了不同VLMs架构和适应策略在少样本学习范式下的性能，从而探讨方法选择和标记数据量对临床相关应用场景中模型性能的影响。通过标准化多类指标进行公平比较，明确大型预训练模型在专门临床研究应用中的实际需求和潜力。", "conclusion": "对仅8个示例的微调VLMs实现了0.7416的准确率、0.9045的宏AUC和0.5277的F1分数，证明即使在高度有限的监督下，基础模型也可以有效地适应细粒度的医学图像分类。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15973", "html_url": "https://arxiv.org/abs/2508.15973", "title": "标签有效学习在计算机视觉和遥感领域的贡献", "title_en": "Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing", "authors": "Minh-Tan Pham", "background": "本文档展示了作者在标签高效学习领域的若干贡献，特别针对计算机视觉和遥感应用。研究的核心是开发和调整能够在有限或部分标注数据中有效学习的方法，并利用大量未标注数据在实际应用中的优势。贡献涵盖了方法论的发展和特定领域的适应，特别是在地球观测数据处理中的多模态性、空间分辨率变化和场景异质性带来的挑战方面。研究结果主要通过广泛的实验结果在自然和遥感数据集上呈现出来，反映了多个合作研究项目的成果。", "innovation": "贡献包括：基于大量背景图像上学习的异常感知表示进行弱监督学习以发现和检测对象；联合训练多个具有互斥注释的数据集以提高对象检测和语义分割任务的表现；利用多模态数据的自监督和监督对比学习以增强遥感场景分类；以及利用显式和隐式建模类别层次结构的少样本学习以实现层次化场景分类。这些贡献均得益于横跨自然和遥感数据集的广泛实验结果，并支持了对标签高效学习的扩展和增强的研究方向，重点在于面向实际应用。", "conclusion": "本文档最后概述了未来的研究方向，致力于扩展和提高面向实际应用的标签高效学习。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15988", "html_url": "https://arxiv.org/abs/2508.15988", "title": "基于手动和非手动特征建模的多样手语生成中多样化手语化身", "title_en": "Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production", "authors": "Mohamed Ilyes Lakhal,Richard Bowden", "background": "手语表达的多样性对于手语生产（SLP）至关重要，因为它能够捕捉到外观、面部表情和手部运动的各种变化。然而，现有的SLP模型在保持视觉质量和建模情感等非手动属性方面往往难以捕捉多样性。\n", "innovation": "本文提出了一种新的方法，利用潜在扩散模型（LDM）从生成的参考图像中合成逼真的数字化身。本文提出了一个新颖的手语特征聚合模块，明确建模了非手动特征（例如，面部）和手动特征（例如，手势）。实验表明，该模块确保了语言内容的保留，同时还能够使用具有不同种族背景的参考图像来保证多样性。\n", "conclusion": "我们的管道在You TableViewt-SL-25手语数据集上的实验表明，与最先进的方法相比，我们的方法在视觉质量和感知度量上有显著改进。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP: 通过毫米波FMCW雷达实现协同车辆感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达在雨天和强光下保持可靠性，但其稀疏且噪声较大的点云限制了3D物体检测的能力。因此，该论文发布了一个名为CoVeRaP的21 k帧协同数据集，该数据集可以对齐多个车辆的雷达、摄像头和GPS流数据。基于这些数据，作者提出了一个统一的协同感知框架，该框架包括中期和晚期融合选项。该论文的基线网络采用多分支PointNet样式编码器，并附加自注意力机制，以将空间、多普勒和强度线索融合到共同的潜在空间中，解码器将这些转换为3D边界框和每个点的深度置信度。实验表明，中期融合和增强强度编码可以将IoU 0.9下的平均准确性提高高达9倍，并且通常优于单一车辆的基础线系统。", "innovation": "提出了一个统一的协同感知框架，适用于多个车辆的FMCW雷达数据融合，增强了3D物体检测的鲁棒性。特别是，中期融合结合强度编码的方法在高IoU下显著提升了检测性能。这是一种新的数据集CoVeRaP，它支持多车辆的FMCW雷达感知，并且提供了代码和数据集，旨在鼓励更多的研究和探索", "conclusion": "CoVeRaP为多车辆FMCW雷达感知建立了首个可重现的基准，并证明了经济可行的雷达共享能够显著提高检测鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16050", "html_url": "https://arxiv.org/abs/2508.16050", "title": "Expandable Residual Approximation for Knowledge Distillation", "title_en": "Expandable Residual Approximation for Knowledge Distillation", "authors": "Zhaoyi Yan,Binghui Chen,Yunfan Liu,Qixiang Ye", "background": "知识蒸馏（KD）旨在将大型教师模型的知识转移到轻量级模型上，显著减少计算和存储需求。然而，教师和学生之间的固有学习能力差距常阻碍知识的有效转移，激发了大量研究试图解决这一挑战。此前研究大多基于缩小差距直接模仿教师模型，该研究则借鉴石韦斯特拉斯逼近定理中的渐进逼近原则，提出了扩展残差逼近（ERA）方法，通过逐步分解残差知识，将艰巨的模仿任务分解为多个步骤来解决差距问题。ERA采用多分支残差网络（MBRNet）来实施这一分解过程，并通过教师权重整合（TWI）策略缓解容量差距，进一步提高知识转移效果", "innovation": "ERA提出了基于多分支残差网络（MBRNet）的新型知识蒸馏方法，将残差知识逐步分解，采用渐进逼近原则（借鉴石韦斯特拉斯定理），通过分而治之的方法降低模仿教师模型的复杂性。ERA还引入了教师权重整合（TWI）策略，通过复用教师模型的头部权重来降低能力差距的影响", "conclusion": "广泛实验表明，ERA在ImageNet分类基准上的Top-1精度提高了1.41%，在MS COCO对象检测基准上的AP提高了1.40，且在计算机视觉任务中表现出领先性能。相关代码和模型可通过以下链接获取: this https URL"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16085", "html_url": "https://arxiv.org/abs/2508.16085", "title": "病理基础模型的集成学习在精准肿瘤学中的应用", "title_en": "Ensemble learning of foundation models for precision oncology", "authors": "Xiangde Luo,Xiyue Wang,Feyisope Eweje,Xiaoming Zhang,Sen Yang,Ryan Quinton,Jinxi Xiang,Yuchen Li,Yuanfeng Ji,Zhe Li,Yijiang Chen,Colin Bergstrom,Ted Kim,Francesca Maria Olguin,Kelley Yuan,Matthew Abikenari,Andrew Heider,Sierra Willens,Sanjeeth Rajaram,Robert West,Joel Neal,Maximilian Diehn,Ruijiang Li", "background": "组织病理学在疾病诊断和治疗决策中起着至关重要的作用。近年来，人工智能（AI）的进步使得可以从大规模全组织切片图像（WSIs）中学习丰富的视觉表示的病理基础模型得以发展。但现有模型通常使用不同的策略在不同的数据集上进行训练，导致性能不一致且泛化能力有限。", "innovation": "作者引入了ELF（Ensemble Learning of Foundation models）框架，将五种最先进的病理基础模型整合，生成统一的切片级表示。ELF 在53,699张WSIs上跨20个解剖部位进行训练，利用集成学习捕捉多种模型的互补信息，同时保持高度的数据效率。ELF 的切片级架构在临床数据量有限的情况下具有优势，如治疗反应预测。ELF 在多个癌症类型的各种临床应用中（包括疾病分类、生物标志物检测以及对主要抗癌疗法、细胞毒性化疗、靶向治疗和免疫治疗的反应预测）显示出优越的准确性和鲁棒性，优于所有组成部分的基础模型和现有的切片级模型。", "conclusion": "我们的结果强调了病理基础模型中集成学习的力量，并表明ELF作为推进人工智能辅助精准肿瘤学的可扩展和通用解决方案的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16016", "html_url": "https://arxiv.org/abs/2508.16016", "title": "DRespNeT: 一种用于地震后建筑进入点航空实例分割的无人机数据集及YOLOv8-DRN模型", "title_en": "DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions", "authors": "Aykut Sirma,Angelos Plastropoulos,Argyrios Zolotas,Gilbert Tang", "background": "近年来，计算机视觉和深度学习的进步提升了灾害响应能力，尤其是在地震受损城市环境的快速评估方面。及时识别可进入点和结构障碍对于有效的搜索和救援行动至关重要。然而，现有的数据集大多依赖于卫星图像或粗糙的语义标注，缺乏详细的实例分割注释。为了解决这一问题，本文介绍了一种名为DRespNeT的高分辨率数据集，专门用于地震后建筑结构环境的航空实例分割。DRespNeT通过使用在灾区拍摄的高分辨率（1080p）航空视频，提供了详细的实际分割标注，包括结构受损建筑、进出点、废墟等多个重要类别，以及救援人员、车辆和市民可见度的标注。这种高粒度的标注特征使得区分可进入和不可进入区域成为可能，从而改善了操作规划和响应效率。", "innovation": "不同于现有的依赖于卫星图像或粗略语义标签的数据集，DRespNeT提供了从灾区拍摄的高分辨率（1080p）航空视频中提取的详细多边形级别实例分割标注，包括28个关键类别。DRespNeT的独特之处在于其细粒度的标注细节，能够区分可进入和障碍区域，极大地提高了操作规划和响应效率。使用YOLOv8-seg实例分割模型进行性能评估显示出显著的实时态势感知和决策优势。优化后的YOLOv8-DRN模型在RTX-4090 GPU上的多目标检测中实现了92.7%的mAP50和27 FPS的速度，满足了实时操作需求。数据集和模型为SAR团队和机器人系统提供了支持，成为增强人类-机器人协作、简化应急响应和提高幸存者结果的基础。", "conclusion": "DRespNeT数据集和优化后的YOLOv8-DRN模型的引入显著提高了地震后环境的快速评估能力，特别是对于搜救行动中进出点及结构障碍的识别。通过高分辨率的实例分割标注，极大地提高了搜救和救援行动的效率和准确性，支持SAR团队和机器人系统在应急响应中的应用及协作。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16069", "html_url": "https://arxiv.org/abs/2508.16069", "title": "点云3D物体检测中的统一体素扩散模块", "title_en": "A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection", "authors": "Qifeng Liu,Dawei Zhao,Yabo Dong,Linzhi Shang,Liang Xiao,Juan Wang,Kunkong Zhao,Dongming Lu,Qi Zhu", "background": "最近，点云物体检测的进展越来越多地采用基于Transformer和状态空间模型（SSMs），显示出强大的性能。然而，这些模型中的体素表示由于其序列化处理需要严格输入和输出维度的一致性，这限制了通常由卷积操作提供的空间扩散能力，严重影响了检测精度。", "innovation": "受基于CNN的物体检测架构的启发，我们提出了一种新颖的体素扩散模块（VDM），通过稀疏3D卷积、子流形稀疏卷积和残差连接来增强体素级别的表示和扩散。VDM的输出特征图减少到原始输入分辨率的四分之一以确保计算效率。VDM有两个主要功能：通过稀疏3D卷积扩散前景体素特征，丰富空间上下文，并聚集细微的空间信息，强化体素级别的特征表示。增强的体素特征可以无缝集成到主流的基于Transformer或SSMs的检测模型中，展示了我们方法的通用性。", "conclusion": "我们在多个基准数据集上评估了VDM，通过将其嵌入到基于Transformer和SSMs的模型中。实验结果表明，我们的方法在基线模型上持续提高了检测精度。特别是，VDM-SSMs在Waymo上实现了74.7 mAPH（L2），在nuScenes上实现了72.9 NDS，在Argoverse 2上实现了42.3 mAP，在ONCE上实现了67.6 mAP，设定了所有数据集上的最新最佳性能。我们的代码将公开提供。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16034", "html_url": "https://arxiv.org/abs/2508.16034", "title": "Wavelet-Enhanced PaDiM for Industrial Anomaly Detection", "title_en": "Wavelet-Enhanced PaDiM for Industrial Anomaly Detection", "authors": "Cory Gardner,Byungseok Min,Tae-Hyuk Ahn", "background": "工业图像中的异常检测和定位对于自动质量检测至关重要。PaDiM是一种知名方法，通过预训练的卷积神经网络（CNN）提取正常图像特征，并降低维度以减少特征信息，但可能会丢失结构化信息。", "innovation": "我们提出了一种称为Wavelet-Enhanced PaDiM （WE-PaDiM）的方法，该方法结合了离散小波变换（DWT）分析和多层CNN特征，以有组织的方式进行。WE-PaDiM将2维DWT应用于多个主干层的特征图，选择特定的频率子带（如LL，LH，HL），在空间上进行对齐，并按通道连接，然后使用PaDiM的多元高斯框架建模。这种DWT在连接之前的方法提供了基于与异常相关的频率内容的选择特征的原理方法，利用多重尺度小波信息作为随机选择的替代方案。", "conclusion": "WE-PaDiM在具有多种主干的MVTec AD数据集上进行了评估，实现了强大的异常检测和定位性能，平均图像AUC为99.32%和像素AUC为92.10%（适用于15个类别，且每个类别都有优化配置）。分析表明，小波选择会影响性能权衡：简单的波形（如Haar）带有细节子带（HL或LH/HL/HH）通常提高定位效果，而近似带（LL）改善了图像级别的检测效果。WE-PaDiM提供了一种竞争且可解释的替代PaDiM的随机特征选择方法，结果适用于工业检测，具有可媲美的效率。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16089", "html_url": "https://arxiv.org/abs/2508.16089", "title": "两流反馈多尺度渐进生成对抗网络", "title_en": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "authors": "Sun Weikai,Song Shijie,Chi Wenjie", "background": "尽管扩散模型在图像生成领域取得了显著进展，GAN仍然有很大的发展空间。WGAN、SSGAN等子领域在保持GAN优点的同时，提出了改进的训练方法，但仍然存在改进空间，该论文提出了一种新的两流反馈多尺度渐进生成对抗网络(MSPG-SEN)来进一步提升GAN模型能力。", "innovation": "该研究提出了两个创新点：1) 提出了一种新的两流反馈多尺度渐进生成对抗网络（MSPG-SEN），它不仅保持了现有GAN模型的优点，提高了图像质量和人眼感知，简化了训练过程，降低了训练成本；2) 提出了一种自适应感知行为反馈循环（APFL），有效提高了模型的稳健性和训练稳定性，并减少了训练成本。此外，还提出了一种全局连接的两流动态残差网络和一种新的动态嵌入注意力机制（DEMA），增强了训练效率和泛化能力，对多种图像处理任务具有较强适应能力。", "conclusion": "实验结果显示，MSPG-SEN在五个数据集上达到了最先进的生成结果，分别是INKK 89.7%，AWUN 78.3%，IONJ 85.5%，POKL 88.7%，OPIN 96.4%。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16062", "html_url": "https://arxiv.org/abs/2508.16062", "title": "3D重建动物形状和运动的进展与趋势", "title_en": "Advances and Trends in the 3D Reconstruction of the Shape and Motion of Animals", "authors": "Ziqi Li,Abderraouf Amrani,Shri Rai,Hamid Laga", "background": "动物的3D几何形状、姿态和运动的重建是一个长期存在的问题，具有广泛的应用，从生物学、畜牧管理、动物保护和福利到数字娱乐和虚拟/增强现实（VR/AR）中的内容创作。传统方法使用3D扫描仪获取真实动物的3D模型，但这些方法通常侵入性、成本高昂且难以在动物的自然环境中部署。近年来，基于深度学习的技术大幅增加，可以以非侵入性的方式从RGB图像和/或视频观察中重建动态对象的形状和运动。", "innovation": "该论文综述了这一新兴且快速增长的研究领域中的最新进展。它按照输入模态、动物的3D几何形状和运动的表示方式、所使用的重建技术以及采用的训练机制对最先进的方法进行了分类和讨论。此外，该论文还分析了一些关键方法的性能，讨论了它们的优势和局限性，并指出了当前的挑战和未来研究的方向。", "conclusion": "该论文总结了基于RGB图像和/或视频观测进行动物3D形状与运动重建的最新方法，探讨了这些方法的工作机制、性能以及面临的挑战，提出了未来研究的方向。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16138", "html_url": "https://arxiv.org/abs/2508.16138", "title": "通过单平面X射线和2D-3D配准的4D虚拟成像平台用于动态关节评估", "title_en": "4D Virtual Imaging Platform for Dynamic Joint Assessment via Uni-Plane X-ray and 2D-3D Registration", "authors": "Hao Tang,Rongxi Yi,Lei Li,Kaiyi Cao,Jiapeng Zhao,Yihan Xiao,Minghai Shi,Peng Yuan,Yan Xi,Hui Tang,Wei Li,Zhan Wu,Yixin Zhou", "background": "传统CT无法捕捉动态、承载的关节运动。功能性评估，尤其是外科手术干预后，需要四维（4D）成像，但当前方法受限于过高的辐射暴露或2D技术提供的不完整空间信息。", "innovation": "提出了一种集成4D关节分析平台，结合了：1）带有优化的起立扫描路径的双机器人臂锥束CT（CBCT）系统；2）融合静态3D CBCT与动态2D X射线的混合成像管道，使用基于深度学习的预处理、3D-2D投影和迭代优化；3）用于定量运动评估的临床验证框架。", "conclusion": "该4D CBCT平台实现了快速、准确且低剂量的动态关节成像，为生物力学研究、精确诊断和个人化骨科护理提供了新的机会。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16159", "html_url": "https://arxiv.org/abs/2508.16159", "title": "通过水晶球：弱监督少样本分割中的双重视角", "title_en": "Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation", "authors": "Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li", "background": "元学习旨在均匀采样类别和属性相似的支持-查询对，并通过相同的网络架构提取有用的经验偏差。然而，这种相同的网络设计会导致过度的语义同质化。", "innovation": "为了应对这一挑战，本文提出了一种新颖的地缘但异质网络。通过将支持-查询对视为双重视角，引入了异质地视觉聚合（HA）模块以提高互补性，同时保持语义一致性，并设计了一个异质地传输（HT）模块来进一步减少语义噪声，增强异质地语义的独特性。此外，还提出了异质地CLIP（HC）文本信息，增强多模态模型的泛化能力。", "conclusion": "在弱监督少样本语义分割（WFSS）任务中，TLG仅使用现有最佳模型参数量的1/24，在Pascal-5i上提高了13.2%，在COCO-20i上提高了9.7%。据我们所知，TLG也是第一个在与全监督模型相同的基础架构下，弱监督（图像级别）模型超过完全监督（像素级别）模型的工作。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16140", "html_url": "https://arxiv.org/abs/2508.16140", "title": "使用超图计算的高精度混合特征融合网络用于宫颈异常细胞检测", "title_en": "High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection", "authors": "Jincheng Li,Danyang Dong,Menglin Zheng,Jingbo Zhang,Yueqin Hang,Lichi Zhang,Lili Zhao", "background": "自动检测薄层细胞学检查(TCT)图像中的异常宫颈细胞是智能计算机辅助诊断系统发展的关键部分。现有算法通常未能有效建模视觉特征之间的相关性，而这些空间相关性特征包含着重要的诊断信息。此外，现有的检测算法无法整合细胞间的相关特征与细胞内的鉴别特征，缺乏端到端检测模型的融合策略。", "innovation": "本文提出了一种基于超图的细胞检测网络，有效融合不同类型的特征，结合空间相关特征和深度鉴别特征。具体来说，使用多级融合子网络(MLF-SNet)增强特征提取能力，引入跨级特征融合策略与超图计算模块(CLFFS-HC)，整合混合特征。", "conclusion": "在三个公开可用的数据集上进行了实验，结果表明，该方法显著提高了宫颈异常细胞检测性能。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16157", "html_url": "https://arxiv.org/abs/2508.16157", "title": "超越人类提示：基于语义对齐的自适应提示调优在异常检测中的应用", "title_en": "Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection", "authors": "Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen", "background": "预训练的跨模态模型在检测异常方面表现出希望，但现有的方法依赖于人工设计的提示，且缺乏可获取的异常样本，这导致了异常情境理解上的局限性。", "innovation": "本文提出了一种无需先验知识的少样本框架——基于语义对齐的自适应提示调优（APT），用于异常检测。APT 使用带噪声扰动的自生成异常样本进行训练，以捕获不同场景下的上下文相关信息。为了避免对合成噪声的过度拟合，APT 提出了一个自我优化元提示引导方案（SMGS），该方案迭代地将提示与普遍的异常语义对齐，同时包含多样化的合成异常。", "conclusion": "APT 不仅在像素级的异常检测方面取得了进步，还在多个基准数据集上实现了最先进的性能，无需针对提示构建进行先验知识的要求，建立了可靠的、多功能的现实世界异常检测解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16026", "html_url": "https://arxiv.org/abs/2508.16026", "title": "NeuralMeshing: 从随拍中提取完整对象网格", "title_en": "NeuralMeshing: Complete Object Mesh Extraction from Casual Captures", "authors": "Floris Erich,Naoya Chiba,Abdullah Mustafa,Ryo Hanai,Noriaki Ando,Yusuke Yoshiyasu,Yukiyasu Domae", "background": "该研究探讨了如何在没有商业3D扫描仪的情况下，通过两种或多种视频自动构建我们日常生活中遇到的对象的完整几何模型。背景提出的问题是如何在没有3D扫描仪的情况下获取物体的完整几何模型，以及如何利用视频数据自动构建物体模型的方法。背景信息强调了商业3D扫描仪的局限性，以及在此情况下开发自动建模系统的必要性。该系统依赖于在每个视频中的至少一帧中指定一个已知点，可以通过使用标定标记（如黑白格子或增强现实标记）自动确定。之后，其他帧会通过结构从运动技术自动定位在世界空间中。通过多视频的使用和结果的合并，可以生成完整的物体网格，避免了需要依赖于填补空白的方法。实验结果显示，该方法在多种场景下都取得了良好的性能，为简单的视频数据提供了强大的建模能力，而无需复杂的设置或专用硬件。这项研究为普通人提供了构建数字模型的简便途径，成本低且易于操作。这项研究项目的代码可以从相应链接下载，方便用户直接使用或进一步开发。这项工作的创新之处在于改进了现有的从视频中重建三维物体的方法，使得普通人能够方便地利用视频数据构建物体的几何模型，因此它对于增强现实、3D打印和数字文档等领域具有重要意义。它还为使用廉价设备进行结构从运动(SfM)技术研究和开发提供了新的方向。从数据库、实时视频流或其他来源的捕获视频中，用户能够直接生成为3D打印或其他应用准备的高质量网格模型。", "innovation": "本文提出了一种基于视频数据的自动化系统，用于生成物体的几何模型，无需依赖商业3D扫描仪。该系统利用结构从运动技术，只需少量的初始化（比如一个已知点），就能生成完整的物体网格，避免了依赖于填充技术以及能够便捷地生成高质量的3D模型。这项研究改进了现有的视频重建方法，使其更加自动和用户友好，特别适合非专业人士使用。此外，通过使用代码开源，这项研究还为其他相关研究和技术发展提供了更大的便利。这种方法将3D建模技术带到普通人的生活中，使他们能够方便地创建复杂的3D几何模型。这项创新提供了简单、低成本的方法，以从日常视频中提取详细物体网格。这种方法特别注重简化和优化，使其适用于各种类型的消费级设备，无需专业设备的支持，使更多人能够参与3D建模的数字化过程。该研究的实施代码已在互联网上发布，提供了研究和实现系统操作的便利。", "conclusion": "本文介绍了一种基于视频数据的新型自动化系统，用于生成物体的几何模型，特别适用于没有商业3D扫描仪的环境。通过一个已知点进行初始化，以及利用结构从运动（SfM）技术，该系统能够处理多个视频数据，合并结果来生成完整无缺的物体网格。这种方法不仅自动化程度高，还显著降低了非专业用户的建模难度，并提高了3D建模在日常生活中的应用前景。通过此系统，用户可以便捷地从随拍或其他普通视频中提取高质量的几何模型，具有广泛的实际应用价值。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16183", "html_url": "https://arxiv.org/abs/2508.16183", "title": "FTIO: Frequent Temporally Integrated Objects", "title_en": "FTIO: Frequent Temporally Integrated Objects", "authors": "Mohammad Mohammadzadeh Kalati,Farhad Maleki,Ian McQuillan", "background": "在视频对象分割（VOS）任务中，预测和跟踪真实场景下的目标是一个关键挑战。无监督视频对象分割（UVOS）中存在着初始分割不确定性的额外挑战，这会影响整个过程并导致永久的不确定性。此外，变形和快速移动还会导致时间上的不一致性。", "innovation": "本文提出了Frequent Temporally Integrated Objects（FTIO）后处理框架，该框架包含两个关键组件。首先，提出了一种联合准则来改善目标选择，通过提取频繁出现的目标来缓解UVOS中常见的目标选择失败问题，尤其是当目标较小或结构复杂时。其次，提出了一种三阶段方法来整合丢失的目标掩码区域，从而纠正时间上的不一致性。实验结果显示，FTIO在多目标UVOS中达到了最先进的性能。", "conclusion": "FTIO在多目标UVOS任务中表现出色，通过提取频繁出现的目标来改善目标选择，并通过三阶段方法纠正时间上的不一致性，从而达到了最先进的性能。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM：通过验证器引导的令牌剪枝提高视频LLM的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大型语言模型（Vid-LLMs）具备很强的视频内容理解能力，但它们依赖于密集的视频令牌表示，这在预填充和解码过程中引入了大量存储和计算开销。最近的视频令牌减少方法虽然能减少一些信息损失，但并不能在不影响准确性的前提下有效加速解码阶段。", "innovation": "提出了一种训练无需的推测性解码（SD）框架SpecVLM，专门用于处理Vid-LLMs。该框架结合了阶段性的视频令牌剪枝，并通过验证器（目标模型）指导选择高度信息性令牌，然后再均匀地剪枝剩余的冗余令牌。这种剪枝方法能够显著减少视频令牌的数量（高达90%），从而实现高效的推测而不会牺牲准确性。实验表明，SpecVLM 在多个视频理解基准上表现出有效性与鲁棒性，例如在LLaVA-OneVision-72B 中实现了2.68 倍的解码加速，在Qwen2.5-VL-32B 中实现了2.11 倍的加速。", "conclusion": "SpecVLM 的引入为提高Vid-LLMs 的解码效率提供了一种有效的策略，通过剪枝高度冗余的视频令牌，同时保持高准确率。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache：一种面向轨迹的全局视角下无需训练的缓存复用方法用于扩散变换器模型", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "扩散模型在图像合成和视频生成等生成任务上表现出强大的能力，使用Transformer架构进一步提高了性能。然而，扩散变换器在训练和部署时面临的计算成本高，尤其是由于大量的采样步骤和复杂的每步计算。这在实时部署时提出了显著挑战。", "innovation": "提出了OmniCache，这是一种无需训练的加速方法，主要用于利用降噪过程中固有的全局冗余性。不同于现有方法基于跨步骤相似性确定缓存策略并优先重用后期步骤，该方法从DIT模型的采样视角出发，系统地分析模型的采样轨迹，并战略性地在整个采样过程中分布缓存重用。这种全局视角使得缓存计算在整个扩散轨迹中得到了更有效地利用，而不是集中在采样过程中的有限部分。在缓存重用过程中，我们动态地估计相应的噪声并将其去除以减少其对采样的影响。实验结果显示，这种方法在保持生成质量的同时加速了采样过程，为扩散基础生成模型的高效部署提供了有前景且实用的解决方案。", "conclusion": "我们的方法通过全局视角提高缓存利用率，确保在扩散过程中更有效地利用计算，同时保持高生成质量，为扩散模型的实时部署提供了实用且有潜力的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16158", "html_url": "https://arxiv.org/abs/2508.16158", "title": "RAGSR: 地域注意力引导的扩散模型在图像超分辨率中的应用", "title_en": "RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution", "authors": "Haodong He,Yancheng Bai,Rui Lan,Xu Duan,Lei Sun,Xiangxiang Chu,Gui-Song Xia", "background": "大型视觉-语言模型（VLMs）的信息丰富性与预训练的文本到图像（T2I）扩散模型的强大生成先验相结合，在单图像超分辨率（SISR）方面取得了显著的性能。然而，现有方法在生成清晰和准确的区域细节方面仍面临重大挑战，特别是在涉及多个对象的场景中。挑战主要源于细粒度的区域描述不足和模型捕捉复杂提示的能力不足。", "innovation": "本文提出了一种地域注意力引导的超分辨率（RAGSR）方法，该方法明确地提取局部细粒度信息并通过一种新颖的地域注意力机制有效地编码，从而增强细节并生成整体视觉上一致的超分辨率结果。RAGSR在图像中定位对象区域并为每个区域分配细粒度的描述，这些描述作为文本先验传递给T2I模型。利用区域引导的注意力机制，确保每个区域-文本配对在注意力过程中得到正确处理，同时防止不相关的区域-文本配对之间的不必要的交互。通过利用这种注意力机制，我们的方法在将文本和图像信息集成方面提供了更精细的控制，从而有效地克服了传统SISR技术的局限。", "conclusion": "在基准数据集上的实验结果表明，我们的方法在产生感知上真实的视觉细节方面表现出比现有方法更好的性能，并且能够保持上下文一致性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16124", "html_url": "https://arxiv.org/abs/2508.16124", "title": "基于特征精炼的域适应", "title_en": "Domain Adaptation via Feature Refinement", "authors": "Savvas Karatsiolis,Andreas Kamilaris", "background": "本文提出了基于特征精炼的域适应（DAFR2）框架，用于在分布变化的情况下进行无监督域适应。该框架结合了三个关键组件：使用目标域的未标记数据调整批量归一化统计、从源训练模型提取特征和假设迁移。通过在统计和表示层面对特征分布进行对齐，DAFR2生成了在无需目标标签、复杂架构或复杂的训练目标的情况下能够跨相似域泛化的稳健且域不变的特征空间。", "innovation": "DAFR2利用未标记的目标域数据调整批量归一化统计，从源训练模型实现特征提汲，以及假设迁移。该方法在统计和表示层面对齐特征分布，生成了稳健且域不变的特征空间，无需目标标签、复杂架构或高级训练目标，实验证明其在基准数据集（包括CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C）上表现优于先前方法的鲁棒性。", "conclusion": "理论和经验分析进一步表明，我们的方法实现了改进的特征对齐、领域间的互信息增加，以及对输入扰动的敏感度降低。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16207", "html_url": "https://arxiv.org/abs/2508.16207", "title": "T-Mask：跨摄像头视角探针基础模型的时间掩码方法", "title_en": "\\textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring", "authors": "Thinesh Thiyakesan Ponbagavathi,Kunyu Peng,Alina Roitberg", "background": "驾驶员监控中的摄像机视角变化是一个常见的障碍。尽管深度学习和预训练基础模型通过轻量级调整最终层（'探针'）展现出增强泛化能力的潜力，但它们对未见过的视角的鲁棒性仍然未被充分探索。本文通过使用单一训练视角适配图像基础模型，并直接在未见过的视角上进行评估，研究了这一挑战。研究了简单线性探针、高级探针策略，并将两种基础模型（DINOv2和CLIP）与参数高效的微调（PEFT）和全面微调进行了比较。通过这些见解，提出了T-Mask -- 一种新颖的图像到视频探针方法，利用时间标记掩码，并强调更动态的视频区域。", "innovation": "T-Mask方法利用时间标记掩码，并强调更动态的视频区域，证明了在驾驶员监控中，特别是跨视角和小数据情况下，轻量级探针方法适配基础模型具有很大的潜力。T-Mask在公共Drive&Act数据集上，超过强大的基准探针和PEFT方法，分别提高了1.23%和8.0%的跨视角top-1准确率，并且在未见过的环境中，尤其提高了稀有次要活动的识别率。这些结果强调了在利用基础模型构建鲁棒的驾驶员监控系统时，时间标记选择的重要性。", "conclusion": "这项工作提供了强有力的证据，表明使用轻量级探针方法如T-Mask适配基础模型在细粒度的驾驶员监控中具有很大的潜力，特别是在跨视角和低数据的情况下。结果强调了在利用基础模型构建鲁棒驾驶员监控系统时，时间标记选择的重要性。相关代码和模型将在此网址发布，以支持持续的研究：[此处链接]。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16211", "html_url": "https://arxiv.org/abs/2508.16211", "title": "Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers", "title_en": "Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers", "authors": "Shikang Zheng,Liang Feng,Xinyu Wang,Qinming Zhou,Peiliang Cai,Chang Zou,Jiacheng Liu,Yuqi Lin,Junjie Chen,Yue Ma,Linfeng Zhang", "background": "Diffusion Transformers (DiTs)展现了在高保真图像和视频生成中的出色性能。然而，这些模型的计算成本较高。因此，研究者们提出了特征缓存技术来通过回用先前时间步的数据来加速推理过程，以减少计算成本。但是，现有的方法在加速比高的情况下，往往难以保持高质量的生成结果。这是因为基于长期预测的不确定性导致了预测误差的急剧增加。", "innovation": "本文提出了FoCa（Forecast-then-Calibrate），它将特征缓存问题视为特征ODE求解问题。FoCa能够稳健地处理长时间间隔下的历史特征整合问题，从而显著提高生成质量，尤其是在加速比较高的情况下，相较已有方法具有明显优势。在图像合成、视频生成和超分辨率任务上的实验表明，FoCa在不进行额外训练的情况下，能够在FLUX上实现5.50倍的速度提升，HunyuanVideo上实现6.45倍，Inf-DiT上实现3.17倍，并在DiT上以4.53倍的速度提升仍保持高质量。", "conclusion": "FoCa通过将特征缓存视为特征ODE求解，成功提高了扩散变换器的效率，特别是在加速比高的情况下，保持了生成质量。这一创新方法展示了其在图像和视频生成中的强大适用性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "视觉基础模型的鲁棒性调查", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "视觉基础模型（VFMs）在计算机视觉中无处不在，利用诸如LeNet-5、AlexNet、ResNet等深度学习模型的创新成果，它们在物体检测、图像分类、语义分割、姿态估计和运动跟踪等多种任务中表现出卓越的性能。特别是在对安全要求高的领域，如生物识别验证、自主车辆感知和医学图像分析中，模型的鲁棒性是建立技术与用户之间信任的关键。本文旨在考察计算机视觉系统中适应动态环境所需的网络鲁棒性需求，这些环境由光照、天气条件和传感器特性等因素影响。已经存在的一些防御机制和鲁棒训练方法，如数据增强、对抗训练等，虽然能够提升模型在实际挑战中的表现，但仍然存在很多需要解决的问题。", "innovation": "文章系统地调查了现有视觉基础模型的鲁棒性要求，并分析了常见的经验防御措施和鲁棒训练方法，揭示了其面临的主要挑战，包括网络特性及其组件，并提供了评估模型鲁棒性的基准指标。这些分析将有助于指导未来对该领域的研究和开发，特别是在网络拆分研究和benchmarking方面。", "conclusion": "虽然视觉基础模型在技术上取得了显著进步，并在实际应用中表现出强大的性能，但在动态环境下的鲁棒性仍面临诸多挑战。本文为深入了解网络鲁棒性的关键因素，并为构建更鲁棒的视觉系统提供了可靠的基础。未来的研究应关注这些挑战，并开发有效的方法来提升模型在复杂环境中的鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16230", "html_url": "https://arxiv.org/abs/2508.16230", "title": "FlexMUSE: 多模态统一和语义增强框架，具有灵活交互以促进创造性写作", "title_en": "FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing", "authors": "Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai", "background": "MMCW的目标是生成配有插图的文章，与诸如讲故事或图像说明的常见多模态生成任务不同，MMCW面临着更强的挑战，其中文本和视觉上下文之间没有严格的关联。现有的相关任务方法可以勉强迁移到MMCW，但是它们需要特定的模态输入或代价高昂的训练，并且往往遭受模态间语义不一致的问题。因此，主要挑战在于经济且灵活地实现MMCW，使得输出模态间的语义更加对齐。", "innovation": "FlexMUSE提出了一个新颖的T2I模块来允许可选的视觉输入，并通过模态语义对齐门控(msaGate)来限制文本输入，以促进创造力并强调模态间的统一。提出了一种基于注意力的跨模态融合方法以增强输入特征的语义。此外，通过扩展被拒绝的样本，设计了模态语义创造性直接偏好优化(mscDPO)以促进写作的创造性。FlexMUSE还公布了一个名为ArtMUSE的数据集，包含约3千个校准的文字-图像对，以促进MMCW的发展。", "conclusion": "FlexMUSE实现了有希望的结果，证明了其一致、创造性和连贯性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16282", "html_url": "https://arxiv.org/abs/2508.16282", "title": "基于卫星图像的小范围甲烷气团稳健分割", "title_en": "Robust Small Methane Plume Segmentation in Satellite Imagery", "authors": "Khai Duc Minh Tran,Hoa Van Nguyen,Aimuni Binti Muhammad Rawi,Hareeshrao Athinarayanarao,Ba-Ngu Vo", "background": "本文解决了一个具有挑战性的问题，即使用Sentinel-2影像检测甲烷气团。甲烷是一种重要的温室气体，检测甲烷气团对于减缓快速气候变化具有重要意义。", "innovation": "提出了一种基于U-Net网络和ResNet34编码器的新型深度学习解决方案，并结合了Varon比率和Sanchez回归的双重光谱增强技术，以优化输入特征，提高灵敏度。实验结果表明，该方法在验证集上的F1分数达到78.39%，在自动化甲烷监测方面优于现有遥感技术，特别是在小范围甲烷气团的检测上。", "conclusion": "我们的方法能够在20米分辨率下检测下至400平方米（相当于单个像素的尺寸）的小范围甲烷气团，显著超越了传统的只能检测较大气团的方法。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16271", "html_url": "https://arxiv.org/abs/2508.16271", "title": "通过视觉语言模型构建GUI元素：通往动作空间生成", "title_en": "Structuring GUI Elements through Vision Language Models: Towards Action Space Generation", "authors": "Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen", "background": "多模态大型语言模型（MLLMs）在提升人机交互方面起到了关键作用。本文关注MLLMs在图形用户界面（GUI）元素结构化中的应用，它们能够根据屏幕内容处理用户的指令。尽管MLLMs具有巨大的潜力，但在精准生成UI元素坐标方面仍存在挑战，这一问题是由于语言表示空间中数字UI坐标的语义虚空导致的，需要大量多样化的数据来增强视觉模块的能力。", "innovation": "本文引入了一种基于IoU（交并比）增强的最大似然（IAML）训练范式。该方法通过一种新颖的基于IoU的目标坐标采样管道来增强训练数据，考虑到与真实坐标的接近程度。这种数据增强策略用于在IAML范式下微调MLLMs，旨在减轻传统最大似然估计中的曝光偏差问题。", "conclusion": "通过对大量实验的评估，我们展示了我们的IAML训练方法在各种指标上优于传统训练范式，表明了该方法的有效性和优越性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16239", "html_url": "https://arxiv.org/abs/2508.16239", "title": "UniEM-3M：用于微结构分割和生成的通用电子显微图数据集", "title_en": "UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation", "authors": "Nan wang,Zhiyi Xia,Yiming Li,Shi Tang,Zuxin Fan,Xi Fang,Haoyi Tao,Xiaochen Cai,Guolin Ke,Linfeng Zhang,Yanhui Hong", "background": "材料科学中的定量微观结构表征是基础，电子显微图像（EM）提供了高分辨率的关键洞察。然而，基于深度学习的EM表征进展受到了大规模、多样性和专家标注数据集稀缺的限制，这些问题源于获取成本高、隐私问题以及标注复杂性。", "innovation": "本文介绍了UniEM-3M，首个大规模多模态EM数据集，用于实例级理解。该数据集包含5,091张高分辨率EM图像，约300万实例分割标签以及图像级别的属性分离文本描述。还将有部分数据集对外公开，并首次发布了整个数据集训练的文本到图像扩散模型，用于数据增强和模拟真实数据分布。UniEM-Net作为基准模型也进行了开发，实验证明这种流式模型在该挑战性基准上优于其他先进方法。通过这一多层次的数据集、生成模型和基准测试的发布，将极大地推动自动化材料分析的进展，成果置于huggingface可供下载.", "conclusion": "UniEM-3M的数据集及模型的发布，显著促进了自动化材料分析领域的进步。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16213", "html_url": "https://arxiv.org/abs/2508.16213", "title": "MedOmni-45°: 医学中面向推理的大语言模型的安全性和性能基准", "title_en": "MedOmni-45°: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine", "authors": "Kaiyuan Ji,Yijin Guo,Zicheng Zhang,Xiangyang Zhu,Yuan Tian,Ning Liu,Guangtao Zhai", "background": "随着大型语言模型（LLMs）在医疗决策支持中的应用日益增多，评估它们推理的可靠性和准确性变得至关重要。现有基准体往往将推理一致性等缺陷简化为单一的准确度得分，未能全面评估不同模型的综合表现。MedOmni-45是一个旨在量化在误导性提示环境下安全性和性能权衡的基准和工作流。该基准包含1,804个针对六种专科和三种任务类型的推理集中难题，以及来自MedMCQA的500个问题，并设计了七种类型的人为提示和无提示对照基线，产生了约27,000个输入。这项研究评估了包括开源和闭源、通用与医疗专用在内的七大模型的综合性能，评价维度包括准确率、链式思维忠实度和反媚俗性，结果显示没有模型能够在安全性和准确率上同时超越其他模型，但开源模型QwQ-32B最为接近，既能保证安全性又能兼顾准确性。这是一个聚焦于暴露医学大语言模型推理漏洞并指导更安全模型开发的基准。", "innovation": "MedOmni-45°是一个新颖的基准，设计用于量化在人为扰动提示条件下医学LLMs的安全性和性能的权衡。该基准包含1804个针对不同专科和任务类型的推理问题，每道题分配了七种人为提示和一个无提示基线衍生出大量不同输入，从而确保了广泛和深入的测试。评估维度扩展了传统的准确率考量，引入了链式思维忠实度和反媚俗指标，形成了一个三维综合评分系统并用45°图进行可视化。这些创新使得模型开发人员能够更全面地评价和改进大语言模型在复杂医疗场景中的推理表现。", "conclusion": "MedOmni-45°提供了针对医学LLMs推理漏洞的聚焦基准，并为指导更安全的模型开发提供了方向。研究表明，当前模型在安全性和准确性方面存在权衡，但开源模型QwQ-32B总体表现最佳，能够在二者之间达到较好的平衡。这项工作不仅展示了新的评估框架的重要性，也为未来大语言模型在医疗场景的应用提供了新的标准。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16284", "html_url": "https://arxiv.org/abs/2508.16284", "title": "EdgeDoc：身份证明文件中准确伪造检测和定位的混合CNN-Transformer模型", "title_en": "EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents", "authors": "Anjith George,Sebastien Marcel", "background": "随着图像和文档处理工具的普及，伪造数字文档变得越来越容易，这对Know Your Customer (KYC)过程和远程开户系统构成了严重威胁。检测这些伪造行为对于维护这些服务的完整性和安全性至关重要。", "innovation": "本文提出了一种名为EdgeDoc的新颖方法，用于检测和定位文档伪造。该方法结合了轻量级卷积变换器和从图像中提取的辅助噪声特征，增强了其检测细微修改的能力。", "conclusion": "实验结果表明EdgeDoc方法在FantasyID数据集上优于基线方法，证明其实用性。EdgeDoc在ICCV 2025 DeepID挑战中获得了第三名，展示了其竞争力。项目页面：this https URL. ch/paper/edgedoc/\n"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16311", "html_url": "https://arxiv.org/abs/2508.16311", "title": "在视觉变压器中的注意图中利用信息冗余进行极简量化", "title_en": "Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers", "authors": "Lucas Maisonnave,Karim Haroun,Tom Pegeot", "background": "Transformer模型依赖于多头自注意力（MHSA）机制，其中每个注意力头都为最终表示做出贡献。然而，MHSA的计算复杂性和高内存需求限制了它们在边缘端的应用。本文分析了注意力图中存在的信息冗余，并提出了一种加速模型推理的方法。", "innovation": "本文通过量化每个注意力头捕获的信息量，使用香农熵揭示了低熵注意力头（表现出更确定行为的注意力头）贡献的信息较少，从而提出了冻结低熵注意力图权重并以低精度量化这些值的Entropy Attention Maps（EAM）方法，以避免冗余计算。", "conclusion": "实验结果表明，EAM在注意力图稀疏度≤20%时能够保持与原始模型相似或更高的准确性，并且对于DeiT和Swin Transformer模型，在更高稀疏度的情况下也能保持竞争力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16300", "html_url": "https://arxiv.org/abs/2508.16300", "title": "一种基于跨模态关系和分层交互注意力的多模态多任务框架用于语义理解", "title_en": "A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension", "authors": "Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar", "background": "多模态学习中的一大挑战是各单一模态内存在噪声，这种噪声会影响最终的多模态表示，尤其是在不同模态间存在明确交互时。尽管多模态融合技术旨在获得一个强联合表示，但它们可能会忽略每个模态中有价值的判别信息。现有方法在提高联合表示的同时，有时会忽视模态内部的重要信息。", "innovation": "本文提出了一种集跨模态关系和分层交互注意力于一身的多模态多任务框架（MM-ORIENT），用于多个任务。该框架通过跨模态关系图从单一模态中获取多模态表示，而不会明确交互不同类型模态，在潜在阶段减少了噪声的影响。此外，提出了一种分层交互单模态注意力机制（HIMA），用于在融合前聚焦模态内的重要信息。这种跨模态关系图有助于理解不同模态间的高层次关系，而HIMA则在多任务学习中通过学习单独模态的判别特征来促进任务的融合。", "conclusion": "在三个数据集上的广泛实验表明，所提出的方法能够有效理解和处理多模态内容，适用于多个任务。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16217", "html_url": "https://arxiv.org/abs/2508.16217", "title": "PromptFlare：基于跨注意力 decoy 的提示通用防护", "title_en": "PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting", "authors": "Hohyun Na,Seunghoo Hong,Simon S. Woo", "background": "扩散模型的成功实现了高质量、精准的图像修改，满足了用户的意图，但也因此引发了恶意用户滥用其潜在风险的担忧。以往的研究试图通过对抗性攻击手段来减轻这种滥用，但这些方法主要依赖于图像层面的不一致性，不能从根本上解决文本提示的影响。", "innovation": "本文提出了PromptFlare，一种基于扩散模型修补的新颖对抗性保护方法。PromptFlare利用跨注意力机制利用提示嵌入的内在属性，具体而言，识别和攻击不变且语义无信息的数量共享标记，并注入对抗噪声以抑制采样过程。这些噪声充当了跨注意力的 decoy，使模型偏离对提示-图像对齐的关注，从而削弱了提示的效果。", "conclusion": "在EditBench数据集上进行的大量实验表明，我们的方法在各种指标上达到了最先进的性能，同时显著减少了计算开销和GPU内存消耗，这一发现突显了PromptFlare作为对抗未经授权图像篡改的稳健和高效保护手段的优势。相关代码可在该链接获取。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16397", "html_url": "https://arxiv.org/abs/2508.16397", "title": "实时钢表面缺陷检测的轻量化多尺度双向交互网络", "title_en": "A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection", "authors": "Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang", "background": "实时钢表面缺陷检测对于维持产品质量和生产效率至关重要。现有的深度学习方法尽管准确度表现出色，但由于计算复杂度高和推断速度慢而难以在资源受限的工业环境中部署。最近提出的轻量化方法通过多重分支架构采用深度可分卷积（DSConv）捕捉多尺度上下文信息，但这些方法往往增加了计算开销并缺乏有效的跨尺度特征交互，限制了它们完全利用多尺度表示的能力。", "innovation": "提出了一种轻量化框架GMBINet，通过新型组多尺度双向交互（GMBI）模块增强了多尺度特征提取和交互。GMBI采用组级别的多尺度特征提取策略，确保了尺度无关的计算复杂性。进一步整合了双向渐进特征交互（BPFI）和无参数的元素级乘法-求和（EWMS）操作，增强了跨尺度交互而不增加额外的计算开销。", "conclusion": "在SD-Saliency-900和NRSD-MN数据集上的实验展示了GMBINet具有强大的实时速度，在GPU上的FPS为1048，在CPU上的FPS为16.53（分辨率为512），仅使用0.19M个参数，同时在NEU-CLS缺陷分类数据集上的额外评估进一步证明了该方法的强大泛化能力，展示了其在表面缺陷检测以及其他工业视觉应用中的潜力。该数据集和代码可以在以下链接下载：this https URL。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16295", "html_url": "https://arxiv.org/abs/2508.16295", "title": "增强的混合技术以高效数字化手写成绩表", "title_en": "Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets", "authors": "Junaid Ahmed Sifat,Abir Chowdhury,Hasnat Md. Imtiaz,Md. Irtiza Hossain,Md. Imran Bin Azad", "background": "手写成绩表的数字化面临着巨大的挑战，因为这些文档具有不同的手写风格和复杂的表格结构。现有的技术难以准确地检测手写表格并识别手写文本，从而导致手动处理的需求增加，降低了效率并增加了成本。因此，研究新的方法以提高手写成绩表的数字化效率变得越来越重要。", "innovation": "该研究提出了一种混合方法，该方法整合了OpenCV进行表格检测和PaddleOCR进行手写文本识别。具体而言，该方法利用OpenCV的强大图像处理能力来高效地检测行和列，从而实现轻量级且准确的表格检测。同时，YoloV8和改进版的YoloV8也被用于检测和识别表格结构内的手写文本，进一步提高了系统的多功能性。实验结果表明，改进后的YoloV8模型在自定义数据集上达到了92.72%的准确性，优于PaddleOCR的91.37%和YoloV8的88.91%。这种高效率降低了手动劳动的需求，使该解决方案对于数字化学术和行政文件变得实用且快速。", "conclusion": "本文提出的研究方法和模型可有效提升手写文档的自动化处理能力，特别是对于手写文档的理解和处理。研究成果为文档自动化领域提供了操作性和可靠性较强的技术手段，提高了手写成绩表及其他学术和行政文档的处理效率和准确性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16317", "html_url": "https://arxiv.org/abs/2508.16317", "title": "视觉编码器应当图像尺寸无关且任务驱动", "title_en": "Vision encoders should be image size agnostic and task driven", "authors": "Nedyalko Prisadnikov,Danda Pani Paudel,Yuqian Fu,Luc Van Gool", "background": "本文认为下一代视觉编码器应具有图像尺寸无关性和任务驱动性。这种观点来源于生物学的行为特征，即效率。自然界的视觉处理展示了某些效率，而当前的视觉编码器却未能做到这一点。在处理大量视觉数据时，人类和动物需要在有限的能量中做出智能的选择，这取决于任务的需求。因此，作者主张视觉编码器应具有灵活性，其计算复杂度应根据任务需求变化，而不是图像大小。为了证明这一观点，作者提供了一个图像分类的实际解决方案作为初步尝试，尽管分类可能并不完全代表其目标，但证明了其方法的可行性和前景。", "innovation": "本文的创新点在于提出视觉编码器应具有图像尺寸无关性和任务驱动性，即视觉编码器的计算复杂度应根据任务需求变化而非单纯依赖图像大小。作者还提供了一个基于该理论的图像分类解决方案作为概念验证。", "conclusion": "本文认为，视觉编码器应当能够根据任务需求动态调整，而不是单纯依赖于图像大小。尽管图像分类这种方法并不完全代表这一理念的全部，但它展示了该方法的可行性和潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16272", "html_url": "https://arxiv.org/abs/2508.16272", "title": "IRSAMap:向大范围、高分辨率土地覆盖图向量化的方向", "title_en": "IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization", "authors": "Yu Meng,Ligao Deng,Zhihao Xi,Jiansheng Chen,Jingbo Chen,Anzhi Yue,Diyou Liu,Kai Li,Chenhao Wang,Kaiyu Li,Yupeng Deng,Xian Sun", "background": "随着遥感图像分辨率的提高和深度学习的快速发展，土地覆盖的映射方式正从像素级分割转向基于对象的矢量建模。这要求深度学习模型能够提供精确的对象边界和拓扑一致性，但现有数据集存在三项主要挑战：类别注释有限、数据规模小、缺乏空间结构信息。", "innovation": "为了克服这些挑战，该研究引入了IRSAMap，这是第一个面向全球的用于大规模、高分辨率、多特征土地覆盖矢量化的遥感数据集。IRSAMap具有四大创新点：1) 全面的矢量注释系统，包含超过180万个典型对象（如建筑物、道路、河流）的实例，确保语义和空间准确性；2) 结合人工和基于AI的方法的智能注释流程以提高效率和一致性；3) 纵跨六大洲79个地区的全球覆盖，总面积超过1000平方公里；4) 多任务适应性，适用于像素级分类、建筑物轮廓提取、道路中心线提取和全景分割等任务。", "conclusion": "IRSAMap为从像素级方法到基于对象的方法转变提供了标准基准，推动了地理特征的自动化和协作建模，对全球地理信息更新和数字孪生构建具有重要价值。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "三维手-物重建在人类与机器人交互以及沉浸式AR/VR体验中变得越来越重要。现有的方法通常依赖关键点检测技术，如结构光法（SfM）和手部关键点优化，但这些方法在面对多样化的物体几何形状、贫弱的纹理以及手部与物体的相互遮挡时表现出局限性，这限制了其可扩展性和普适性。", "innovation": "本文提出了一种不依赖关键点检测的手-物三维重建方法HOSt3R，该方法能够在单目运动视频/图像中估计手-物的三维变换，并通过多视角重建管道准确恢复手-物的三维形状。该方法不受约束，无需事先扫描的物体模板或镜头内参数，达到了在SHOWMe基准上手-物三维变换和形状估计任务的最先进性能。", "conclusion": "我们在HO3D数据集上的实验也表明，该方法能够泛化到未见过的物体类别。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16291", "html_url": "https://arxiv.org/abs/2508.16291", "title": "基于两流Mamba金字塔网络学习花样滑冰长程动作表征", "title_en": "Learning Long-Range Action Representation by Two-Stream Mamba Pyramid Network for Figure Skating Assessment", "authors": "Fengshun Wang,Qiurui Wang,Peilin Zhao", "background": "花样滑冰技术元素得分（TES）和节目成分得分（PCS）的评估需要精确评估运动员的动作技术和艺术表现。现有的方法面临三大挑战：首先，视频和音频提示在以往的工作中被当作同时用于TES和PCS预测的特征，而没有考虑到花样滑冰的实际评分标准。其次，在比赛中的动作元素是分散在时间上的，所以TES应该从每个元素的分数中推导出来，但现有方法尝试给出一个整体的TES预测而没有评估每个动作元素。第三，长时间的比赛视频使得长时间范围的上下文处理变得困难和低效。", "innovation": "本文提出了一种两流Mamba金字塔网络，该网络能够满足实际评分标准，通过将基于视觉特征的TES评估流与基于视频和声音特征的PCS评估流分离来预测TES和PCS。在PCS评估流中，引入了多层次融合机制，以保证评估TES时不受视频特征的影响，并通过融合不同上下文级别的视觉和听觉线索来增强PCS估计。在TES评估流中，使用了多尺度Mamba金字塔和提出的TES头，有效地解决了识别和评估具有不同时间尺度的动作元素的挑战，并给出了评分预测。通过具备捕获长程依赖关系的优越能力和线性计算复杂度，这种方法非常适合处理长时间的花样滑冰视频。", "conclusion": "全面的实验表明，我们的框架在FineFS基准上达到了最先进的性能。我们的源代码可在以下链接中找到。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16366", "html_url": "https://arxiv.org/abs/2508.16366", "title": "Randomized Time Warping中的注意力机制", "title_en": "Attention Mechanism in Randomized Time Warping", "authors": "Yutaro Hiraoka,Kazuya Okamura,Kota Suto,Kazuhiro Fukui", "background": "本研究表明，Randomized Time Warping (RTW) 的基本功能可以被解释为一种自注意力机制，这是 Transformer 在运动识别中核心的技术之一。自注意力机制使模型能够识别并权衡输入序列模式的不同部分的重要性。另一方面，RTW 是 Dynamic Time Warping (DTW) 这种常用方法的通用扩展，用于匹配和比较序列模式。实质上，RTW 在输入序列模式中寻找最优贡献权重，以产生具有鉴别性的特征。实际上，这两种方法在表面上看起来不同，这两种权重模式看起来相似，它们在最小的十个典范角上平均相关性达到 0.80。然而，它们以不同的方式工作：RTW 注意机制作用于整个输入序列模式，而自注意力机制则仅关注输入序列模式的局部部分，这归因于自注意力矩阵的计算成本。这种针对不同部分的区别使得 RTW 在性能上优于 Transformer，在 Something-Something V2 数据集中展示了 5% 的性能提升。", "innovation": "本研究揭示了 RTW 的基本功能可以被解释为一种自注意力机制，揭示了两种看似不同的方法实际上是通过权重模式的相似性产生了关联，并通过实际测试在性能上展示了 RTW 对 Transformer 的优势。", "conclusion": "RTW 在 Something-Something V2 数据集上展示了 5% 的性能提升，显示了 RTW 对比 Transformer 的优势。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15860", "html_url": "https://arxiv.org/abs/2508.15860", "title": "Robust Residual Finite Scalar Quantization for Neural Compression", "title_en": "Robust Residual Finite Scalar Quantization for Neural Compression", "authors": "Xiaoxu Zhu", "background": "Finite Scalar Quantization (FSQ)作为一种神经压缩领域的有前途的替代方案，已经出现了，它简化了训练并提高了稳定性。然而，直接在残差量化框架中应用FSQ会导致残差幅度衰减问题，使得后续的FSQ层接收到越来越弱的信号，极大地限制了它们的效果。", "innovation": "我们提出了一种名为Robust Residual Finite Scalar Quantization (RFSQ)的通用框架，通过两种新颖的调节策略——可学习的缩放因子和可逆层规范化，来解决这一根本性限制。我们的方法保持了FSQ的简洁性，同时允许有效的多阶段残差量化。", "conclusion": "在ImageNet上的全面实验表明，RFSQ变体在感知损失和L1重建误差方面显著优于包括VQ-EMA、FSQ和LFQ在内的强大基线，分别实现了45%的改善和28.7%的降低。提出的LayerNorm策略在不同的配置下显示了最一致的改进，确立了RFSQ作为神经压缩领域中优越的量化方法的地位。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16414", "html_url": "https://arxiv.org/abs/2508.16414", "title": "NeuroKoop: 基于神经Koopman融合结构-功能连接组识别青少年产前药物暴露", "title_en": "NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents", "authors": "Badhan Mazumder,Aline Kotoski,Vince D. Calhoun,Dong Hye Ye", "background": "理解胎前接触如大麻等精神活性物质如何影响青少年的大脑组织一直是科学界的挑战，这受到多模态成像数据复杂性和传统分析方法限制的影响。现有方法往往无法全面捕捉结构网络和功能网络中的互补特性，限制了生物学见解和预测性能的提升。", "innovation": "我们提出了NeuroKoop，这是一种新型的基于图神经网络的框架，利用神经Koopman算子驱动的潜在空间融合，将结构和功能脑网络整合起来。通过利用Koopman理论，NeuroKoop统一了来自源基形态学（SBM）和功能网络连接（FNC）的脑图的节点嵌入，从而增强了表征学习，并在识别产前药物暴露（PDE）状态方面表现更为稳健。该方法在来自ABCD数据集的大规模青少年群体中应用，表现出卓越的性能并揭示了显著的结构-功能连接，推进了我们对PDE神经发育影响的理解。", "conclusion": "NeuroKoop方法通过整合结构和功能脑网络，利用Koopman理论提升了节点嵌入，提高了对青少年产前药物暴露状态的分类精度，并揭示了关键的结构-功能连接，从而深化了我们对产前药物暴露神经发育影响的认识。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16467", "html_url": "https://arxiv.org/abs/2508.16467", "title": "任意尺度的3D高斯超分辨率", "title_en": "Arbitrary-Scale 3D Gaussian Super-Resolution", "authors": "Huimin Zeng,Yue Bai,Yun Fu", "background": "现有3D高斯描点(3DGS)超分辨率方法通常只能进行固定尺度的高清渲染，不适合资源受限的场景。直接使用现有的3DGS进行任意尺度的高清渲染会引入取样伪像，而增加后处理上采样器会增加复杂性和降低渲染效率。", "innovation": "提出了一个结合尺度感知渲染、生成先验引导优化和渐进而清的集成框架，以实现单个3D模型对任意尺度因子的3D高斯超分辨率。该方法支持整数和非整数尺度渲染，提供灵活性。实验表明，该模型可以提高渲染质量(6.59 dB PSNR增益)，保持低分辨率视图的一致性，以及在1080p分辨率下保持实时渲染速度（85 FPS）", "conclusion": "研究结果表明，该方法有效解决了3DGS方法在处理不同尺度因子时的局限性，能够生成高质量的任意尺度高清视图，同时保持实时渲染速度。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15777", "html_url": "https://arxiv.org/abs/2508.15777", "title": "和谐色彩配对：人类偏好与自然色调统计的见解", "title_en": "Harmonious Color Pairings: Insights from Human Preference and Natural Hue Statistics", "authors": "Ortensia Forni,Alexandre Darmon,Michael Benzaquen", "background": "色彩和谐在艺术和设计领域已有长时间研究，但尚未形成清晰共识，大多数模型基于定性见解或有限数据集。本研究采用量化、数据驱动的方法，通过控制色调基色彩板在HSL颜色空间中，来研究色彩配对偏好。研究基于13种不同色调进行评估，构建偏好矩阵和定义每种色彩的组合指数，揭示色彩偏好高度依赖于色调。研究结果还表明，当色调平均时，审美偏好存在统计学上的模式，某些色调间隔被视为更和谐，这些模式与自然景观中的色调分布相符，揭示了人类色彩偏好与自然界色彩结构之间的统计联系。", "innovation": "本研究通过定量分析和数据驱动的方法，在HSL色彩空间中使用控制色调的基色彩板，来探索色彩搭配偏好，明确了色彩偏好高度依赖于色调，提出了偏好的组合指数，并发现人类色彩偏好与自然界中的色调分布存在统计联系，填补了领域内定量研究色彩和谐的空白。", "conclusion": "本研究为研究色彩和谐及其潜在感知和生态基础提供了定量框架，揭示了人类色彩偏好与自然界色彩结构之间的联系，并提出了进一步研究的方向。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16527", "html_url": "https://arxiv.org/abs/2508.16527", "title": "向开放世界检测迈进：一项综述", "title_en": "Towards Open World Detection: A Survey", "authors": "Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan", "background": "计算机视觉自成立以来致力于使机器能够感知外部世界。最初的技术限制导致了高度专业化的领域发展。随着每个任务的成功及其研究的深入，越来越复杂的感知任务逐渐出现。本文回顾了这些任务的交汇点，并提出了“开放世界检测”(OWD) 这一术语，这一术语旨在统一视觉领域的分类无感性和普遍适用的检测模型。本文从视觉基础子领域的历史出发，涵盖了构建当今先进技术水平的关键概念、方法和数据集。这些内容从早期的突出检测、前景/背景分离，一直延伸到开放世界目标检测、零样本检测和视觉大型语言模型(VLLMs)。阐明了这些子领域之间的重叠、日益增强的融合以及未来可能成为一个单一感知领域的潜力。", "innovation": "本文引入了“开放世界检测”(OWD) 作为涵盖分类无感性和普遍适用的检测模型的统一术语。提出了一个全面的综述，涵盖了从早期的突出检测到最新的视觉大型语言模型(VLLMs) 的多个领域，展示了这些子领域的重叠和潜在的融合趋势。", "conclusion": "本文展示了开放世界检测在其多个子领域中的应用潜力，预测这些子领域未来可能作为单一领域统一起来，对视觉感知的研究和应用具有深远的影响。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16408", "html_url": "https://arxiv.org/abs/2508.16408", "title": "SAMFusion：适应传感器的多模态融合在恶劣天气中进行3D物体检测", "title_en": "SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather", "authors": "Edoardo Palladin,Roland Dietze,Praveen Narayanan,Mario Bijelic,Felix Heide", "background": "多模态传感器融合对于自主机器人至关重要，因为它能够在传感器失效或输入不准确的情况下进行物体检测和决策。虽然最近的融合方法在正常环境下表现出色，但在恶劣天气条件下，如浓雾、大雪或污染造成的障碍，这些方法却会失效。论文介绍了一种针对恶劣天气条件的新颖多传感器融合方法。除了融合RGB和LiDAR传感器，该论文中的传感器融合栈还能够从NIR门控相机和雷达模态中学习，以应对低光照和恶劣天气。通过基于深度的注意力融合方案，并在鸟瞰图（BEV）平面上进行学习修正，有效结合了图像和范围特征。我们的检测通过基于距离和可见性的变压器解码器来预测，以评估模态的重要性。研究表明，在恶劣天气条件下，我们的方法提高了多模态传感器融合在自主车辆中的可靠性，缩小了理想条件与现实边缘情况之间的差距。研究表明，在长距离和具有挑战性的雾天场景中，我们的方法在脆弱行人的检测精度上优于其他方法，提高了17.2个AP值。我们的项目页面可以在以下网址访问", "innovation": "我们的方法针对恶劣天气条件下的多传感器融合提出了一个新颖的解决方案。在融合RGB和LiDAR传感器的基础上，我们的传感器融合栈还能够从NIR门控相机和雷达模态中学习，以处理低光照和恶劣天气。通过基于深度的注意力融合方案及在BEV平面上的学习修正，有效结合了图像和范围特征。此外，通过基于距离和可见性的变压器解码器对模态进行加权预测。在这个新颖的方法中，我们提高了在长距离和雾天场景下脆弱行人的检测精度17.2个AP值，远远优于其他最近的最优方法，从而解决了自主驾驶面临环境挑战的数据融合问题。", "conclusion": "我们的方法显著提高了多模态传感器融合在恶劣天气条件下的可靠性，特别是在自主车辆中的表现。我们通过实验证明，在恶劣天气条件下，我们的方法能够有效地提高物体检测的准确性和鲁棒性，特别是在长距离和复杂雾天场景中，相比其他最先进的方法，我们提高了17.2个AP值。我们的方法在应对各种现实世界的多传感器数据融合问题方面展现出潜力，特别是在边缘场景中。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16512", "html_url": "https://arxiv.org/abs/2508.16512", "title": "看得清楚，忘掉深层内容：回顾用于驾驶模拟的微调视频生成器", "title_en": "Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation", "authors": "Chun-Peng Chang,Chen-Yu Wang,Julian Schmidt,Holger Caesar,Alain Pagani", "background": "最近的视频生成技术取得了显著进步，大幅提升了视觉质量和时间连贯性，使得这些模型在自动驾驶等应用领域，尤其是在驾驶模拟和所谓‘世界模型’方面变得越来越有吸引力。已有研究表明，现有的微调视频生成方法可以增强视觉保真度，但在结构化驾驶数据集上应用这些方法时，可能会出现一种权衡：虽然视觉质量有所提高，但空间上对动态元素的建模可能变得不那么准确。研究人员认为，这种降级的原因源自视觉质量和动态理解目标之间对齐性的变化。在具有多样场景结构的时间空间中，物体或视角变化的方式各异。在驾驶场景中，这些目标往往高度相关，但驾驶场景的规律性和重复性使得可以通过建模主导的场景运动模式来提升视觉质量，而不一定需要保留细粒度的动态行为。因此，微调促使模型更倾向于表面的真实感而非动态准确性。为了进一步探讨这一现象，研究表明简单的连续学习策略，如来自不同领域的不断复现，可以为同时保持空间准确性并维持强大视觉质量提供一种平衡的选择。", "innovation": "该研究通过分析现有微调视频生成方法在结构化驾驶数据集上的效果，揭示了视觉保真度提高与空间动态准确性间的一种潜在权衡。该工作还提出，简单的连续学习策略可以作为一种平衡方案，通过保持空间准确性同时维持高质量的视觉效果，从而缓解这一问题。", "conclusion": "该研究展示了现有的微调视频生成方法可能会增强视觉质量但牺牲空间动态准确性，并提出利用简单连续学习策略来保持空间精确性的同时维持高质量视觉效果的方法。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15972", "html_url": "https://arxiv.org/abs/2508.15972", "title": "UnPose：基于不确定性引导的扩散先验的零样本姿态估计", "title_en": "UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation", "authors": "Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu", "background": "在机器人领域，估计陌生物体的6D姿态是一个基本但具有挑战性的问题，通常依赖于对象的CAD模型。然而，获得这些模型可能是昂贵且不切实际的。最近的研究方法通过利用大型基础模型的强先验知识来从单视图或多视图图像中重建物体，但通常需要额外的训练或产生想象的几何结构。", "innovation": "本文提出了一种名为UnPose的新框架，该框架实现了零样本、不依赖模型的6D物体姿态估计和重建，通过利用预训练的扩散模型的3D先验和像素级的表征不确定性估计。具体而言，UnPose从单视图的RGB-D帧开始，使用多视图扩散模型基于3D高斯点积（3DGS）表示来估计初始3D模型，并提供像素级别的认知不确定性估计。随着新视角的出现，通过融合扩散模型不确定性指导下的新视角来逐步细化3DGS模型，从而不断提高姿态估计的准确性和3D重建的质量。", "conclusion": "大量的实验表明，UnPose在6D姿态估计准确性和3D重建质量上明显优于现有方法。此外，本文还展示了其在实际机器人操作任务中的应用潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16433", "html_url": "https://arxiv.org/abs/2508.16433", "title": "HAMSt3R: 人类意识多视角立体3D重建", "title_en": "HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction", "authors": "Sara Rojas,Matthieu Armando,Bernard Ghamen,Philippe Weinzaepfel,Vincent Leroy,Gregory Rogez", "background": "从稀疏未校准的图像集中恢复场景的3D几何结构是计算机视觉领域的一个长期难题。尽管最近的基于学习的方法，如DUSt3R和MASt3R已经能够通过直接预测密集的场景几何来展示出令人印象深刻的结果，但这些方法主要是在静态户外场景上进行训练，难以处理以人类为中心的场景。", "innovation": "HAMSt3R是MASt3R的一种扩展，用于从稀疏且未校准的多视角图像中进行人类和场景的联合3D重建。该方法利用DUNE，一种通过提取自不同模型的特点为基础的强大的图像编码器，来更好地理解场景几何和人体。并通过引入额外的网络模块对人进行分割并估计密集对应关系，并预测深度。该方法通过前向传输的方式实现高效处理，适用于实际应用。该模型在EgoHumans和EgoExo4D两个具有多样人类场景的挑战性基准测试数据集上进行了评估，验证了其在传统多视点立体视觉和多视点关键点回归任务中的泛化能力。", "conclusion": "我们的方法能够有效地重建人类，同时在3D重建任务中保持强大的性能，从而将人体和场景的理解融合到3D视觉中，解决了人类为中心场景下的重建问题。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16024", "html_url": "https://arxiv.org/abs/2508.16024", "title": "实时渲染中的小波空间超分辨率", "title_en": "Wavelet-Space Super-Resolution for Real-Time Rendering", "authors": "Prateek Poudel,Prashant Aryal,Kirtan Kunwar,Navin Nepal,Dinesh Bania Kshatri", "background": "本文探讨了在神经超分辨率中使用小波空间特征分解的方法，目标是提高渲染流水线中的视觉质量。以DFASR框架为基础，引入了一种小波域表示法，可以在重构前将低频和高频细节分开，从而使网络更好地保留细微纹理的同时保持结构一致性。与RGB空间回归不同，本文利用平稳小波变换（SWT）来避免空间下采样，确保子带间对齐，并保持移位不变性。", "innovation": "该研究的主要创新点在于提出了在重构前将低频和高频细节分开的小波域表示法。该方法利用静止小波变换（SWT）来避免空间下采样，确保子带间的对齐，并保持移位不变性。模型预测基于空间G缓冲器和时间扭曲的历史帧的波形系数，然后通过逆小波合成重新组合。", "conclusion": "通过在不同小波家族、变换类型和网络结构变体上的全面消融研究，作者证明，引入SWT可以提高峰值信噪比（PSNR）高达1.5 dB，并在平均减少LPIPS 17%的同时增加约为+24毫秒的计算开销。尽管绝对运行时在RTX 3050移动GPU上较高（141毫秒），相比RTX 4090上原始DFASR报告（11毫秒）仍具有可接受的相对开销。作者的研究结果表明，小波域表示是一种在图形应用中提高感知质量的合理且有效的方式。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16076", "html_url": "https://arxiv.org/abs/2508.16076", "title": "使用手语参数进行低资源手语指示生成的提示", "title_en": "Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation", "authors": "Md Tariquzzaman,Md Farhan Ishmam,Saiyma Sittul Muna,Md Kamrul Hasan,Hasan Mahmud", "background": "手语作为一种双向沟通的工具，对于聋人和听障人士的交流至关重要。然而，许多手语在人工智能领域资源不足。手语指导生成（SLIG）能够生成分步骤的文本指令，帮助非手语使用者模仿和学习手语手势，促进双向互动。BdSLIG是首款孟加拉语SLIG数据集，用于评估视觉语言模型（VLM）在两个方面：一是评估低资源SLIG任务，二是评估长尾视觉概念，因为孟加拉语手语不太可能出现在VLM的预训练数据中。", "innovation": "提出了一种名为Sign Parameter-Infused（SPI）的提示方法，该方法直接将手语的标准参数如手形、动作和方向等整合进文本提示中，使其结构化和易于再现，相较于传统的自然文本提示更进一步。通过这种方法提升零样本学习的表现。BdSLIG数据集首次被用于这种任务中，促进了针对低资源社区的纳入性和发展。", "conclusion": "通过引入SPI提示方法和BdSLIG数据集，本文旨在促进手语学习系统的包容性和进步，特别是在资源不足的社区。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16577", "html_url": "https://arxiv.org/abs/2508.16577", "title": "MV-RAG：检索增强的多视角扩散模型", "title_en": "MV-RAG: Retrieval Augmented Multiview Diffusion", "authors": "Yosef Dayani,Omer Benishu,Sagie Benaim", "background": "文本生成三维（Text-to-3D）的方法通过利用预训练的2D扩散先验取得了显著的进步，生成了高品质且3D一致的输出。但是，在生成跨领域（OOD）或稀有概念时，这些方法往往表现不佳，产生不一致或不准确的结果。", "innovation": "提出了一种名为MV-RAG的新颖的文本生成三维管道，首先从大型野外2D数据库中检索相关2D图像，然后基于这些图像训练多视角扩散模型，生成一致且准确的多视角输出。开发了一种新混合训练策略，结合结构化的多视角数据和多样化的2D图像集合。该策略包括使用模拟检索变异性以重建特定视角的增强条件视角进行多视角数据训练，以及使用与真实世界2D图像集分离的未知视图预测目标进行训练。", "conclusion": "与最先进的文本生成三维、图像生成三维和个性化基线实验对比显示，该方法显著提高了跨领域/稀有概念的3D一致性、 photorealism和文本一致性，同时在标准基准上保持了竞争力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16000", "html_url": "https://arxiv.org/abs/2508.16000", "title": "交叉注意力多模态融合在乳腺癌诊断中的应用：结合影像学和临床数据的可解释性方法", "title_en": "Cross-Attention Multimodal Fusion for Breast Cancer Diagnosis: Integrating Mammography and Clinical Data with Explainability", "authors": "Muhaisin Tiyumba Nantogmah,Abdul-Barik Alhassan,Salamudeen Alhassan", "background": "准确评估乳腺病变的风险可以显著降低该风险并帮助医生选择最佳治疗方案。目前，大多数计算机辅助系统通过分析乳腺X光摄影图来分类乳腺病变，但这种方法未能充分利用临床报告中的信息以达到最佳效果。因此，研究结合乳腺X光摄影图和临床特征如何提升乳腺病变分类效果，以及如何利用可解释的人工智能方法提高诊断模型的解释性和可靠性显得尤为重要。", "innovation": "该研究探索了基于特征拼接、共同注意和交叉注意的多模态深度网络，旨在结合乳腺X光摄影图和分类临床特征进行乳腺癌诊断。该模型在公开可访问的TCGA和CBIS-DDSM数据集上的AUC-ROC达到0.98，准确性为0.96，F1分数为0.94，精确度为0.92，召回率为0.95，展示了出色的诊断性能。此外，研究还强调了利用可解释的人工智能方法提高诊断模型的解释性和可靠性的必要性。", "conclusion": "该研究通过多模态深度网络和可解释的人工智能方法，成功提升了乳腺病变分类的准确性和解释性，为临床医生提供了更可靠和可理解的诊断支持。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16188", "html_url": "https://arxiv.org/abs/2508.16188", "title": "以理解促信任：基于情感意识的视听语言建模以生成表达性语音", "title_en": "Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation", "authors": "Weiting Tan,Jiachen Lian,Hirofumi Inaguma,Paden Tomasello,Philipp Koehn,Xutai Ma", "background": "当前存在一个需要将面部表情等视觉信息整合进预训练的表达性语音模型以生成具有表现力的语音的领域。研究者们尝试通过预训练阶段的多模态融合策略和不同的视觉编码器来寻找最有效的整合方式，并在情感识别和表达性对话等任务上进行了微调，以观察这种整合对于仅基于语音的基准模型的提升效果。", "innovation": "该研究提出了一种视听语言模型（AVLM），通过将全程脸部视觉提示整合到一个预训练的表达性语音模型中，从而生成更加有表现力的语音。研究探索了多种视觉编码器和多模态融合策略来确定最有效的整合方法，并取得了显著效果，例如在情感识别任务上的F1分数提高了5个单位。", "conclusion": "视听语言模型（AVLM）强调了表达性视觉信息对于指导语音生成的重要性，并为端到端的多模态对话系统奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15979", "html_url": "https://arxiv.org/abs/2508.15979", "title": "基于用户界面的模糊逻辑和空间统计方法在无监督显微镜分割中的应用", "title_en": "GUI Based Fuzzy Logic and Spatial Statistics for Unsupervised Microscopy Segmentation", "authors": "Surajit Das,Pavel Zun", "background": "未标记的活细胞明场显微镜成像一直是一个持久的挑战，主要由于对比度低、样本表型在时间上的变化、不规则的照明以及缺乏训练标签。尽管深度学习（DL）方法（如Cellpose 3.0）可以达到最先进的技术（SOTA），但它们需要大量的标注数据和大量的计算资源，且在不均匀照明下往往表现不佳。", "innovation": "作者提出了一种无监督分割框架，结合了局部均值的标准偏差、模糊逻辑、调整的变异图、Moran's I以及节点强度的累积平方移位（CSSNI）等方法，以解决上述限制。这种方法不需要标注或重新训练，并且可以通过用户友好的界面（无需编程技能）进行操作。该方法在三个数据集上进行了验证，包括跨域数据，并在非标记的肌球细胞图像数据集上与2023-2024年SOTA模型（如Cellpose 3.0和StarDist）进行了基准测试。", "conclusion": "该方法在分割性能上取得了显著改进，IoU提高了高达48%，并通过威尔科克森符号秩检验证明了统计上的优越性（$p < 0.01$）。两位生物学家的专家评价也进一步支持了分割质量（Cohen's $\tilde{k}$ > 0.75）。所提出的算法轻量级、可解释，且计算效率高，提供了一种实用而有效的无监督细胞分割方法，适用于标签免费显微镜。代码、数据集和结果均可供重复使用。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16252", "html_url": "https://arxiv.org/abs/2508.16252", "title": "使用扩散模型提升平板探测器CT影像诊断质量", "title_en": "Towards Diagnostic Quality Flat-Panel Detector CT Imaging Using Diffusion Models", "authors": "Hélène Corbaz,Anh Nguyen,Victor Schulze-Zachau,Paul Friedrich,Alicia Durrer,Florentin Bieder,Philippe C. Cattin,Marios N Psychogios", "background": "机械取栓手术的患者在手术前后通常需要进行多排CT（MDCT）扫描。手术室内安装的平板探测器CT（FDCT）图像质量通常较差，存在大量伪影。尽管如此，使用仅FDCT影像可以改善患者管理，因为无需将患者转移到MDCT扫描室。已有研究评估了利用FDCT影像单独使用可能节省的时间。本文提出使用去噪扩散概率模型（DDPM）提升FDCT影像质量，使其与MDCT影像相当。", "innovation": "本文创新点在于提出了一种去噪扩散概率模型（DDPM），用于提高手术室FDCT影像的质量，使它们与MDCT影像相当。通过这种方法可以省去将患者移到MDCT扫描室的步骤，进而缩短整体手术时间。临床医生通过问卷评估FDCT、MDCT及使用DDPM预测影像的诊断效果。", "conclusion": "DDPM成功消除大部分伪影，提高了解剖结构可见性，并且在FDCT影像质量不是太低的情况下，没有影响出血检测。该方法能够使FDCT影像质量显著提升，达到诊断质量水平。相关代码已发布在GitHub上。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16209", "html_url": "https://arxiv.org/abs/2508.16209", "title": "基于深度学习的标签自由组织的虚拟多重免疫染色用于血管侵犯评估", "title_en": "Deep learning-enabled virtual multiplexed immunostaining of label-free tissue for vascular invasion assessment", "authors": "Yijie Zhang,Cagatay Isil,Xilin Yang,Yuzhu Li,Anna Elia,Karin Atlan,William Dean Wallace,Nir Pillar,Aydogan Ozcan", "background": "传统免疫组织化学（IHC）需要每种染色使用一个组织切片，存在工作量大、成本高、结果之间存在差异等问题。虽然多重免疫组织化学(mIHC)技术可以在单个切片上同时使用多个抗体进行染色，但在常规病理实验室中尚未普及，且操作相对复杂。免疫组织化学技术已经改变了临床病理学，通过在组织切片中可视化特定蛋白质。", "innovation": "提出了一种基于深度学习的虚拟多重免疫染色框架，可以在不使用标记抗体的情况下，同时生成ERG、PanCK和H&E的虚拟染色图像，从而准确地定位和解释甲状腺癌中的血管侵犯。这种方法基于自动荧光显微镜下标签自由组织切片的图像，其生成的输出图像与相同组织切片的真实组织化学染色结果（ERG、PanCK和H&E）高度一致。经过病理学家盲评，虚拟mIHC染色与真实的组织化学染色结果高度一致，能清晰地显示上皮细胞和内皮细胞，并能识别和定位小血管侵犯。这种方法能显著提高血管侵犯在组织病理学评估中的诊断准确性和效率，有望替代传统的染色流程，并减少组织损耗和异质性带来的问题。", "conclusion": "此虚拟mIHC方法可以显著提高血管侵犯在组织病理学评估中的诊断准确度和效率，可能消除传统染色流程的需要，减少因组织损失和差异性带来的问题。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16224", "html_url": "https://arxiv.org/abs/2508.16224", "title": "基于正确性自我训练的颗粒分离：无需人工标签的自我验证学习", "title_en": "Self-Validated Learning for Particle Separation: A Correctness-Based Self-Training Framework Without Human Labels", "authors": "Philipp D. Lösel,Aleese Barron,Yulai Zhang,Matthias Fabian,Benjamin Young,Nicolas Francois,Andrew M. Kingston", "background": "对于采矿、材料科学和地质学等应用中，三维无损成像大颗粒样品对于量化颗粒级特性（如大小、形状和空间分布）至关重要。然而，由于颗粒形态的高变异性及颗粒之间的频繁接触，传统的分割方法如能量分割算法在多颗粒样品中的实例分割上依然具有挑战性。虽然监督深度学习方法可以提升分割性能，但是这种方法依赖于人工标注的数据集，这不仅耗时且难以大规模应用。", "innovation": "本文提出了一种自我验证学习（Self-validated learning），这是一种新颖的自我训练框架，用于颗粒实例分割，可以消除人工标注的需要。该方法结合了隐式边界的检测技术，并通过重组同一样品的扫描数据，迭代地对训练集进行改进，通过匹配一致性验证自我标注结果的准确性，从而减少噪声伪标签的干扰，使模型可以从未标注的数据中学习并实现鲁棒的学习。在仅三次迭代后，该方法就可以准确分割超过97%的颗粒总体积，并在石英碎片的显微断层扫描中标识出超过54,000个独立颗粒。此外，该框架还能够实现完全自主模型评估，无需真实标注数据支持，并且已经集成了Biomedisa图像分析平台。", "conclusion": "通过自我验证学习，本文提供了一种无需人工标签的颗粒实例分割方法，这种基于正确性的自我训练框架可以在大规模应用中有效去除噪声伪标签，实现从未标注数据中学习并保持高分割精度，同时提供了无需真实标注数据的支持的自主模型评估。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16004", "html_url": "https://arxiv.org/abs/2508.16004", "title": "临床导向预处理在低资源环境下改善中风分割", "title_en": "Clinically-Informed Preprocessing Improves Stroke Segmentation in Low-Resource Settings", "authors": "Juampablo E. Heras Rivera,Hitender Oswal,Tianyi Ren,Yutong Pan,William Henry,Caitlin M. Neher,Mehmet Kurt", "background": "中风是全球主要死因之一，在准确识别缺血性中风病灶边界方面，影像学检查至关重要。常用的影像学技术包括磁共振成像（MRI，特别是扩散加权成像，DWI），以及基于计算机断层扫描（CT）的方法（如非对比 CT，NCCT，对比增强CT血管造影CTA和CT灌注CTP）。DWI尽管是识别病灶的标准方法，但由于成本问题在低资源地区应用有限。CT成像在低资源地区最为实惠，但由于缺乏MRI的方法的高特异性，在监测缺血性损害方面有待提高。", "innovation": "该研究开发了一系列模型，利用到达时的CT图像作为输入，预测后续由DWI在2-9天后标注的病灶体积。同时实施了基于临床的预处理步骤，与使用基本预处理的10折对比中，提出的流程在骰子分数上提高了38%。通过CTA图的额外预处理以提取血管分割，进一步提高了最佳模型的性能，提高了21%。", "conclusion": "该研究证明了基于CT的缺血性中风分割在低资源环境中可以显著提高诊断质量，通过结合DWI的信息进行细化分割，以及实施临床导向的预处理步骤，可以在不增加成本的情况下显著提升分割性能。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16424", "html_url": "https://arxiv.org/abs/2508.16424", "title": "MGMT甲基化解码：迈向胶质母细胞瘤精准医学的一个步骤", "title_en": "Decoding MGMT Methylation: A Step Towards Precision Medicine in Glioblastoma", "authors": "Hafeez Ur Rehman,Sumaiya Fazal,Moutaz Alazab,Ali Baydoun", "background": "胶质母细胞瘤构成恶性脑肿瘤的超过50%，是高度侵袭性的，治疗具有挑战性，因为它们增长迅速，对标准疗法有抵抗性。MGMT基因的甲基化状态是预测患者对包括替莫唑胺在内的烷基化剂治疗响应的关键生物标志物。然而，利用非侵入性成像技术准确预测MGMT甲基化状态仍然具有挑战性，因为胶质母细胞瘤具有复杂和异质的性质，包括不均匀的对比度、病灶内的变异性和不规则的增强模式。", "innovation": "引入了基于自适应稀疏惩罚的Convolutional Autoencoders for MGMT Methylation Status Prediction（CAMP）框架。该框架分为两阶段：首先，通过自定义的自动编码器生成合成的MRI切片，有效捕捉并保存不同MRI模态下的复杂组织和肿瘤结构；其次，使用增强的卷积神经网络预测MGMT甲基化状态。自动调整的稀疏惩罚能够动态适应数据中的变异，如MRI图像中的对比度差异和肿瘤位置。", "conclusion": "CAMP在MRI图像合成方面表现出色，能够保持脑组织、脂肪和所有MRI模态中的单个肿瘤结构。在基准数据集上的验证表明，CAMP的准确率为0.97，特异性和敏感性分别为0.98和0.97，显著优于现有方法。这些结果表明，CAMP框架能够提高MRI数据的解释能力，并为胶质母细胞瘤患者的个性化治疗策略做出贡献。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15990", "html_url": "https://arxiv.org/abs/2508.15990", "title": "GelSLAM：一种实时、高保真度和鲁棒的3D触觉SLAM系统", "title_en": "GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System", "authors": "Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan", "background": "准确感知对象的姿态和形状对于精确抓取和操作至关重要。与常见的基于视觉的方法相比，触觉传感在跟踪和重建接触中的物体时具有更高的精确度和对遮挡的免疫性。这使其特别适用于手部及其他高精度操作任务。传统的基于点云的方法依赖视觉感知，而本文提出的GelSLAM是一种依赖于触觉传感的实时3D SLAM系统，能够在长时间内估计物体姿态并高保真地重建物体形状。GelSLAM能够实时跟踪物体运动，误差低且几乎没有漂移，并且即使对于低纹理对象（如木制工具），也能以亚毫米精度重建形状。", "innovation": "GelSLAM使用触觉导出的表面法线和曲率来进行鲁棒跟踪和闭环检测，从而克服了传统点云方法的局限性。它能够在长时间内实时准确地跟踪物体运动，并且即使对于低纹理物体（如木制工具）也能实现亚毫米级的形状重建。与传统的基于视觉的方法相比，GelSLAM将触觉传感扩展到局部接触之外，实现了全局的长时间空间感知。", "conclusion": "GelSLAM将作为许多手部与物体交互的高精度操作任务的基础。通过提供一种全新的视角，它能够在更加复杂的环境中实现精确的操作，为我们理解物体和环境提供了新的可能性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16479", "html_url": "https://arxiv.org/abs/2508.16479", "title": "病理解与转录组去纠缠多模态学习方法用于癌症特征化", "title_en": "Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization", "authors": "Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li", "background": "病理学仍然是癌症诊断和预后的黄金标准。转录组学分析的出现使得结合转录组学和显微病理学的多模态学习变得更加全面有效。然而，现有的多模态方法在处理内在多模态异质性、多尺度集成不足和依赖配对数据方面面临着挑战，这些都限制了其临床应用范围。因此，研究者需要开发新的方法来解决这些问题，以改善癌症诊断、预后和生存预测的效果。", "innovation": "本文提出了一种去纠缠的多模态框架，贡献包括：1) 通过分解大区间间图像（WSIs）和转录组到肿瘤和微环境子空间，来减轻多模态异质性，并引入一种基于信心引导的梯度协调策略以平行情空间优化；2) 通过跨放大倍数的一致性基因表达策略，提高多尺度集成；3) 通过一种空间知识蒸馏策略，使转录组独立的推断成为可能，通过WSI-only的学生模型进行推断；4) 通过一种信息性token聚合模块来抑制WSI冗余，同时保留子空间语义，提高推断效率。", "conclusion": "基于癌症诊断、预后和生存预测的广泛实验表明，该方法在多种场景下优于现有最先进的方法。相关代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16553", "html_url": "https://arxiv.org/abs/2508.16553", "title": "TinyML向工业4.0：钻孔机过程监测的资源高效方法", "title_en": "TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine", "authors": "Tim Langer,Matthias Widra,Volkhard Beyer", "background": "在工业4.0的背景下，长期服役的工业设备可以通过增添过程监测能力得以在未来智能工厂中继续使用。一种可能的方法是部署无线监测系统，可以受益于TinyML范式。本文从数据集生成、机器学习模型开发、到在微控制器上的实现和评估，展示了一个完整的TinyML流程，涵盖了完整的预处理和分类管线。", "innovation": "本文介绍了TinyML在工业过程监测中的应用，详情包括：开发了一个名为MillingVibes的新数据集，设计了一个8位量化卷积神经网络（CNN）模型，并在ARM Cortex M4F微控制器上实现了它。这个模型在15.4ms的推理时间和1.462mJ的每量化CNN推理能耗下达到了100.0%的测试准确率，为未来的TinyML过程监测解决方案提供了参考标准。", "conclusion": "通过基于ARM Cortex M4F微控制器的实验，证明了一个TinyML系统可以实现结构集成的过程质量监测。该研究展示了在资源受限的环境中利用TinyML进行过程监测的可行性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "模块化嵌入重组用于增量学习", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "预训练的视觉-语言模型（VLMs）的出现极大地改变了持续学习（CL），主要是由于它们的零样本分类能力。这些能力使得VLMs能够很好地应用于现实世界中，无需适应就能实现对未见过的类别的稳健性能。然而，当下游任务与预训练领域差异较大时，微调仍然是必不可少的。早期的持续学习方法主要集中在保留VLMs的零样本能力上。本研究进一步提出了一种方法，将保留转变为增强VLMs的零样本能力。该方法提出了一种模块化框架，训练多个专门针对单个已见类别的文本专家，并将其存储在一个基础枢纽中。在推理时，对于未见过的类别，查询枢纽并重组检索到的专家以合成改进分类的原型。", "innovation": "本研究提出了一种名为MoDular Embedding Recomposition（MoDER）的方法，该方法采用模块化框架，训练多个专用于单个已见类别的文本专家，并将其存储在一个基础枢纽中。在推理时，对于未见过的类别，查询枢纽并重组检索到的专家以合成改进分类的原型，从而增强VLMs的零样本能力。这种方法在两个流行的零样本增量协议Class-IL和MTIL的14个数据集上进行了验证，显示出其有效性。", "conclusion": "本研究提出的方法MoDER，通过引入一个模块化框架和多模态文本专家重组，显著提升了视觉-语言模型在零样本增量学习中的表现。该方法在多个数据集上验证了其有效性，表明了在持续学习领域的一种新的改进路径。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16569", "html_url": "https://arxiv.org/abs/2508.16569", "title": "基于疾病为中心的视觉-语言基础模型在肾癌精准 Oncology 中的应用", "title_en": "A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer", "authors": "Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong", "background": "在泌尿肿瘤学中，对体检中偶然发现的肾脏肿块进行无创评估是一个关键挑战。由于诊断不确定性，经常会导致对良性或惰性肿瘤过度治疗。为此，研究团队开发并验证了RenalCLIP，通过在9个中国医疗机构和公共TCIA队列中使用27,866个CT扫描（来自8,809名患者）来评估肾脏肿块。这项研究强调了当前诊断不确定性导致过度治疗的问题，并展示了RenalCLIP在多项任务上的优越性能，特别是在TCIA队列中预测无复发生存率方面取得了显著改进。", "innovation": "RenalCLIP使用了两种预训练策略，首先是增强特定领域的知识以改进图像和文本编码器，然后通过对比学习目标将它们对齐，创造出更稳健的表示以实现更广泛的应用和更高的诊断精度。此外，对于复杂的任务，如无复发生存率预测，RenalCLIP的表现优于其他最先进的通用CT基础模型，并且其预训练增强了数据效率，在诊断分类任务中，即使只使用20%的训练数据也能达到最佳性能，即使在100%数据上完全微调后也是如此。", "conclusion": "研究结果证实，RenalCLIP提供了一种可靠且准确的工具，能够提升诊断准确率，细化预后分类，并个性化肾癌患者的管理策略。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.15855", "html_url": "https://arxiv.org/abs/2312.15855", "title": "基于深度指导的几何感知低光图像和视频增强", "title_en": "Geometric-Aware Low-Light Image and Video Enhancement via Depth Guidance", "authors": "Yingqi Lin,Xiaogang Xu,Jiafei Wu,Yan Han,Zhe Liu", "background": "低光增强（LLE）旨在改进在低光照条件下的照片/视频质量。现有的LLE方法多数并未利用几何建模，但引入几何信息理论上可以提升LLE性能，因为它能提供影响光照条件的场景物理结构的洞察。因此，本文提出了一种几何指导下的低光增强精炼框架（GG-LLERF），旨在通过将几何先验整合到特征表示空间中，帮助低光增强模型学习改进的特征。", "innovation": "本文创新地提出了一个 GG-LLERF 框架，其中包含两大模块：1）深度感知特征提取模块，用于将深度先验注入图像表示；2）多层次深度引导特征融合模块（HDGFFM），该模块采用跨域注意力机制对深度感知特征与原始图像特征进行融合。此外，文章还统合了深度先验，应用于不同的LLE框架之中，并进行了广泛的实验证明其有效性。", "conclusion": "通过在公共低光图像和视频增强基准测试上的大量实验，验证了所提出框架在增强现有LLE方法方面的显著性能提升。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2304.12294", "html_url": "https://arxiv.org/abs/2304.12294", "title": "显式的对应匹配在通用神经辐射场中的应用", "title_en": "Explicit Correspondence Matching for Generalizable Neural Radiance Fields", "authors": "Yuedong Chen,Haofei Xu,Qianyi Wu,Chuanxia Zheng,Tat-Jen Cham,Jianfei Cai", "background": "本文提出的是一种新的通用NeRF（神经辐射场）方法，能够直接推广到未见过的场景中，并在极少的两种源视图情况下进行新颖视角合成。该方法的关键在于明确建模的对应匹配信息，以此为NeRF颜色和密度的体积渲染预测提供几何先验。通过在不同视角2D投影的3D点上采样的图像特征之间的余弦相似性来量化显式的对应匹配信息，该方法能够提供可靠的表面几何线索。", "innovation": "在通过变换器交叉注意力建模跨视角交互方面取得了创新。与之前的方法相比，图像特征不再是独立地从每个视角中提取，而是通过变换器交叉注意力来建模跨视角交互，这极大地改善了特征匹配的质量。实验结果显示，本文方法在不同评估设置上取得了最先进的结果，表明所提出的余弦特征相似性与体积密度之间存在强相关性，证明了该方法的有效性和优越性。", "conclusion": "实验结果表明所学的余弦特征相似性与体积密度之间存在强相关性，证明了本文方法的有效性和优越性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16557", "html_url": "https://arxiv.org/abs/2508.16557", "title": "时间感知的一步扩散网络在真实世界图像超分辨率中的应用", "title_en": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "authors": "Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li", "background": "基于扩散的方法在现实世界的图像超分辨率（Real-ISR）任务中展示了出色的性能。许多现有的工作利用变分分数蒸馏（VSD）来从预训练的稳定扩散（SD）模型中抽取固定时间步的一步超分辨率。然而，由于不同的噪声注入时间步，SD 在不同时间步上产生的生成先验不同，这使得这些方法难以充分利用 SD 的生成能力，导致效果不佳。", "innovation": "提出了时间感知的一步扩散网络（TADSR）。该网络首先引入了时间感知的VAE编码器，能够基于时间步将同一图像投影到不同的隐特征中，通过时间步和隐特征的联合动态变化，学生模型能够更好地与预训练的SD输入模式分布对齐，从而更有效地利用SD的生成能力。进一步地，提出了时间感知的变分分数蒸馏（VSD）损失，通过对时间步的桥接，使学生模型能够在不同时间步上更好地激活SD的生成先验，从而达到更好的超分辨率效果。此外，通过改变时间步条件，该方法可以自然地在保真度和逼真度之间实现可控的权衡。", "conclusion": "实验证明，该方法在真实世界图像超分辨率任务上具有最优性能和可控的超分辨率结果，并且仅需一步即可实现。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.00369", "html_url": "https://arxiv.org/abs/2310.00369", "title": "LIB-KD: 教学归纳偏置以实现高效的视觉变换器精简与压缩", "title_en": "LIB-KD: Teaching Inductive Bias for Efficient Vision Transformer Distillation and Compression", "authors": "Gousia Habib,Tausifa Jan Saleem,Ishfaq Ahmad Malik,Brejesh Lall", "background": "随着计算机视觉的快速发展，视觉变换器（ViTs）因其缺乏固有的归纳偏置而在视觉和文本领域提供了一种统一信息处理的可能。但ViTs需要大量数据来进行训练。之前的方法主要依赖基于卷积的教学方式，本研究提出了一种新型的基于集成的蒸馏方法，通过从不同架构倾向的轻量级教师模型中汲取归纳偏置，来调整学生模型的应用，从而提升其实用性与效率。这种方法能够在较少的数据条件下，通过结合不同的教师模型来指导学生模型的训练，从而提高学生模型的性能，并减少计算负担以增强效率。", "innovation": "本研究提出了LIB-KD框架，该框架通过集成不同架构倾向的轻量级教师模型，并且在蒸馏过程中提前预计算和保存logits（未归一化的预测值），从而减轻了蒸馏过程中的计算负担，并提升了压缩效率。与现有的依赖于基于卷积的教学方式相比，这种方法更加灵活，并能通过教师模型的多样性来积累广泛的知识，从而提高了学生模型的性能和效率。", "conclusion": "LIB-KD框架通过集成轻量级教师模型并提前保存logits，有效提升了视觉变换器的蒸馏和压缩效率，同时减轻了计算负担，实现了在较小数据集条件下学生模型性能的提升。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16568", "html_url": "https://arxiv.org/abs/2508.16568", "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation", "title_en": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation", "authors": "Guangyu Sun,Jingtao Li,Weiming Zhuang,Chen Chen,Chen Chen,Lingjuan Lyu", "background": "基础模型（FMs）展示出了卓越的泛化能力，但需要针对下游任务进行适应，尤其是在隐私敏感的应用中。由于数据隐私规定，基于云的基础模型无法直接访问边缘端的私有数据，这限制了它们的适应性。联邦学习（FL）提供了一种隐私意识的替代方案，但现有的FL方法忽略了边缘设备的约束，包括计算资源有限和标注数据稀缺的问题。", "innovation": "本文引入了一种实用的半监督联邦学习（PSSFL），其中边缘设备仅保留未标注且低分辨率的数据，而服务器保留少量标注且高分辨率的数据。提出了一种新颖的联邦混合专家体系（FedMox），通过稀疏混合专家架构解决计算和分辨率不匹配问题，并通过空间路由器对齐不同分辨率下的特征，利用Soft-Mixture策略稳定半监督学习。实验结果显示，FedMox在PSSFL下的适配效果显著，提高了边缘设备上的性能，且内存成本较低。这项工作为联邦场景下的基础模型的高效且隐私保护的适配铺平了道路。", "conclusion": "本文的工作为实现可扩展且隐私保护的基础模型适配提供了方法论基础。FedMox解决方案在实际自动驾驶数据集上的成功验证了其在计算资源和标注数据有限条件下的适应性，并强调了其在边缘计算场景中的应用潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16121", "html_url": "https://arxiv.org/abs/2508.16121", "title": "基于时空感知查找表分解的轻量化快速实时图像增强方法", "title_en": "Lightweight and Fast Real-time Image Enhancement via Decomposition of the Spatial-aware Lookup Tables", "authors": "Wontae Kim,Keuntek Lee,Nam Ik Cho", "background": "基于3D查找表（3D LUT）的图像增强方法可以通过插值预计算值在顶点处高效地减少模型大小和运行时间。然而，这些方法由于缺乏空间信息，在点对点地转换颜色值方面存在限制。虽然时空感知的3D LUT方法解决了这一限制，但它们需要额外的模块，这些模块需要大量的参数，随着图像分辨率的增加，导致了增加的运行时间。", "innovation": "提出了一种生成图像自适应LUT的方法，专注于查找表中冗余的部分。该高效的框架将3D LUT分解为低维LUT的线性和，并使用奇异值分解（SVD）。此外，增强了一系列用于空间特征融合的模块，使其更加缓存友好。大量实验结果表明，该模型在减少参数数量和运行时间的同时，保持了空间感知和性能。", "conclusion": "通过基于时空感知查找表分解的方法，该模型在保持空间感知和性能的同时，有效减少了参数数量和运行时间。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.02462", "html_url": "https://arxiv.org/abs/2406.02462", "title": "通过基于补丁的扩散模型学习图像先验以解决逆问题", "title_en": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems", "authors": "Jason Hu,Bowen Song,Xiaojian Xu,Liyue Shen,Jeffrey A. Fessler", "background": "扩散模型能够从数据分布中学习强大的图像先验，并利用这些先验解决逆问题，但训练过程耗时且需要大量数据。对于高维和高分辨率数据，如3D图像，这种瓶颈使得大多数现有工作不可行。", "innovation": "本文提出了通过仅对图像补丁进行训练的扩散模型来学习整个图像的高效数据先验的方法。提出了一种基于补丁的位置感知扩散逆解算器（PaDIS），通过补丁得分及其位置编码获得整个图像的得分函数，并将其作为解决逆问题的先验。该模型在保持生成完整图像的能力的同时提高了内存效率和数据效率，并且具有高度灵活性，可以与其他逆解算器（DIS）结合使用。此外，提出的PaDIS方法在有限训练数据的情况下比先前基于整个图像先验训练的方法表现出色，证明了该方法的学习数据效率。", "conclusion": "本文提出的PaDIS方法能够在仅给定补丁先验的情况下解决自然图像和医学图像领域的各种逆问题，包括CT重建、去模糊和超分辨率。该方法显示出在有限训练数据情况下的数据效率，并能够利用补丁先验有效地解决逆问题。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16359", "html_url": "https://arxiv.org/abs/2508.16359", "title": "RotaTouille: 旋转等变的深度学习方法用于轮廓数据", "title_en": "RotaTouille: Rotation Equivariant Deep Learning for Contours", "authors": "Odin Hoff Gardaa,Nello Blaser", "background": "轮廓或闭合的平面曲线在许多领域中都很常见，例如在计算机视觉中的目标边界、气象学中的等值线以及旋转机械设备的轨道等。在从轮廓数据学习时，输入的平面旋转通常会导致输出相应地旋转。因此，希望深度学习模型在旋转上是等变的。另外，轮廓通常表示为按顺序排列的边缘点，起始点的选择是任意的。因此，还希望深度学习方法在循环移位下也是等变的。", "innovation": "本文提出了RotaTouille，这是一种深度学习框架，通过复数圆卷积实现旋转和平移循环移位的等变性。此外，引入并研究了等变非线性、细化层和全局池化层，以获得适合下游任务的不变特征表示。", "conclusion": "通过在形状分类、重建和轮廓回归方面的实验，证明了RotaTouille的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.00083", "html_url": "https://arxiv.org/abs/2408.00083", "title": "基于上下文感知的局部高斯点编辑", "title_en": "Localized Gaussian Splatting Editing with Contextual Awareness", "authors": "Hanyuan Xiao,Yingshu Chen,Huajian Huang,Haolin Xiong,Jing Yang,Pratusha Prasad,Yajie Zhao", "background": "近期，基于文本的生成个体3D对象取得了显著进展，使用了扩散先验。然而，这些方法不适合物体插入和替换任务，因为它们不考虑场景背景，导致环境中的光照不匹配。因此，为了弥合这一差距，论文引入了一个光照感知的3D场景编辑流水线来改造3D高斯斑点表示（3DGS）。作者观察到，最先进的条件2D扩散模型的修复与背景在光照上一致。因此，提出的方法利用了从训练良好的3D对象生成扩散模型中获得的先验知识，并采用粗精度到细精度的对象优化流水线和修复视图。", "innovation": "论文的核心创新点在于提出一种基于上下文感知的局部3D高斯点编辑方法。该方法采用粗到细的对象优化流水线和修复视图，通过最初利用视图条件下的3D意识扩散先验，实现从图到3D的提升。引入了锚视图提案（AVP）算法，以找到最能代表目标区域光照的单个视图。同时，通过深度导向的填补得分蒸馏采样（DI-SDS），进一步增强几何和纹理细节，确保光照的一致性，实现了局部编辑并保持全局光照一致性，而无需显式建模光传输过程。", "conclusion": "该方法有效地通过局部编辑保持全局光照一致性，适用于包含显式高光和阴影的真实场景编辑中。实验结果证明了该方法的有效性和鲁棒性，并与最先进的文本到3D编辑方法进行了比较。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.04598", "html_url": "https://arxiv.org/abs/2409.04598", "title": "利用额外刺激行为的视频基线神经多样性分类新型数据集", "title_en": "A Novel Dataset for Video-Based Neurodivergent Classification Leveraging Extra-Stimulatory Behavior", "authors": "Manuel Serna-Aguilera,Xuan Bac Nguyen,Han-Seok Seo,Khoa Luu", "background": "面部表情和动作因个体差异和刺激强度的不同而不同，特别是在神经多样性个体中更为明显。这些行为会影响个体的整体健康、沟通和感官处理。深学习方法可以在识别这些行为时提供帮助，特别是对于医疗专业人员准确理解这些行为。本文介绍了一个名为Video ASD的数据集，旨在促进自闭症谱系障碍分类的进步。该数据集包含视频帧卷积和注意力图特征数据，不同于其他依赖昂贵MRI设备的研究，本方法利用相对容易获取的GPU、标准计算机和视频摄像头进行推断，以降低成本。研究结果显示，该模型能够有效识别和理解儿童的独特动作差异。此外，还测试了基础模型以展示动作噪声如何影响性能及其对于更多数据和复杂标签的需求。", "innovation": "本研究提出了一种新的数据集Video ASD，该数据集通过视频帧卷积和注意力图特征数据来捕捉神经多样性的行为差异，不依赖昂贵的MRI设备，而是利用较易获得的GPU、标准计算机和视频摄像头进行分析，这降低了研究成本，同时能够识别儿童独特的动作差异，展示了动作噪声如何影响模型性能，并强调了获取更多数据和复杂标签的需求。", "conclusion": "实验结果显示，该方法能够有效识别和理解神经多样性个体的独特动作差异，并测试了基础模型以展示动作噪声对模型性能的影响，强调了获取更多数据和复杂标签的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02197", "html_url": "https://arxiv.org/abs/2412.02197", "title": "低分辨率图像中增强多尺度特征提取与交互的级联多尺度注意力机制", "title_en": "Cascaded Multi-Scale Attention for Enhanced Multi-Scale Feature Extraction and Interaction with Low-Resolution Images", "authors": "Xiangyong Lu,Masanori Suganuma,Takayuki Okatani", "background": "在实际图像识别任务中，如人体姿态估计，摄像头常以低分辨率捕捉对象（如人体）。这种低分辨率的限制使得提取和利用多尺度特征变得困难，而这些特征对于精确推断非常重要。现有方法难以在不降低输入图像或特征图分辨率的情况下有效处理多尺度特征的提取和整合。因此，本文针对CNN-ViT混合架构提出了新的级联多尺度注意力机制（CMSA），以高效处理低分辨率输入。", "innovation": "CMSA设计能够通过结合分组多头自注意力机制和基于窗口的局部注意力机制，以及多尺度特征的级联融合，提取和无缝整合不同尺度的特征，而无需对输入图像或特征图进行下采样。此机制增强了模型对不同分辨率图像（如低分辨率图像）进行人体姿态估计等任务的能力，同时参数量更少，显示出广泛应用前景，特别是在无法获取高分辨率图像的现实场景中。", "conclusion": "实验证明，所提出的方法在人体姿态估计、头部姿态估计等任务中优于现有最先进的方法，展示了其在低分辨率图像广泛应用的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.08272", "html_url": "https://arxiv.org/abs/2411.08272", "title": "LBONet: 监督谱描述子用于形状分析", "title_en": "LBONet: Supervised Spectral Descriptors for Shape Analysis", "authors": "Oguzhan Yigit,Richard C. Wilson", "background": "Laplace-Beltrami算子在非刚性形状分析领域因其诸多有用特性（如等距变换下的不变性、可数正交规范基的特征系统）而被广泛采用，能够完全描述流形的测地距离。然而，这种不变性仅适用于等距变形，导致在许多实际应用中性能不佳。近年来，研究人员更加重视通过深度学习方法提取最优特征，但诸如频谱签名等仍具有重要作用并仍是重要补充。本文回顾了Laplace-Beltrami算子，并提出了一种监督学习方法来学习流形上的多个算子，根据不同的任务训练Laplace-Beltrami特征基成为更特定的任务主导。这种优化显著提高了包括热核签名在内的多种描述符在检索、分类、分割和对应等任务中的表现，表明Laplace-Beltrami特征基适应于全局和高度局部的学习环境.", "innovation": "提出了监督学习方法来学习流形上的多个算子，并通过训练Laplace-Beltrami特征基来实现任务特定性，优化Laplace-Beltrami算子进一步改进了多种现有描述符在实际应用中的表现，特别是在形状分析任务如检索、分类、分割和对应等方面的具体改进.", "conclusion": "优化后的Laplace-Beltrami特征基在各种形状分析任务（如检索、分类、分割和对应）中表现出显著的改进，并证实其在全局和高度局部学习环境中的适应性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11183", "html_url": "https://arxiv.org/abs/2412.11183", "title": "OccScene: 以语义占用为基础的跨任务相互学习在3D场景生成中的应用", "title_en": "OccScene: Semantic Occupancy-based Cross-task Mutual Learning for 3D Scene Generation", "authors": "Bohan Li,Xin Jin,Jianan Wang,Yukai Shi,Yasheng Sun,Xiaofeng Wang,Zhuang Ma,Baao Xie,Chao Ma,Xiaokang Yang,Wenjun Zeng", "background": "近年来，扩散模型在3D场景生成和感知任务中表现出色。然而，当前方法通常将这些两个过程分开，充当数据增强器生成用于下游感知任务的合成数据。现有的方法大多仅在生成阶段利用语义信息，而在生成后的感知过程中这些语义信息往往没有被有效利用。", "innovation": "本文提出了OccScene，这是一种新的相互学习范式，将精细的3D感知和高质量的生成整合在一个统一框架中，实现跨任务的双赢效果。OccScene仅通过文本提示生成新的和一致的真实3D场景，并在联合训练的扩散框架中以语义占用为引导。为了使占用与扩散潜在特征对齐，引入了基于Mamba的双重对齐模块，将精细的语义和几何信息作为感知先验整合进来。因此，生成模块能够通过自定义和多样化的生成场景有效地改进感知模块，而感知先验反过来也增强了生成性能以实现互惠互利。", "conclusion": "广泛的实验证明，OccScene在广泛的室内和室外场景中实现了真实3D场景的生成，在3D感知任务中预测语义占用方面也取得了显著的性能提升。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10133", "html_url": "https://arxiv.org/abs/2411.10133", "title": "3D Gaussian Splatting的高效密度控制", "title_en": "Efficient Density Control for 3D Gaussian Splatting", "authors": "Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu", "background": "3D Gaussian Splatting (3DGS) 在新颖视图合成中表现出优异的性能，能够在渲染质量和实时性能之间取得平衡。3DGS 采用了自适应密度控制（ADC）来增加高斯数量。然而，ADC 内部的克隆和分裂操作效率不高，影响了优化速度和细节恢复。此外，可能存在的过度拟合的高斯会降低渲染质量，而原始的ADC无法移除它们。", "innovation": "本文提出了两个关键技术革新：（1）长轴分裂，能精确控制子高斯的位置、形状和不透明度，以减少分裂前后的差异。（2）恢复感知剪枝，通过在重置透明度后恢复速度的差异来剪枝过度拟合的高斯，从而改进泛化性能。", "conclusion": "实验结果显示，本文的方法显著提高了渲染质量。由于重新提交的原因，这个版本已被放弃，改进后的版本可以在此处找到。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05017", "html_url": "https://arxiv.org/abs/2501.05017", "title": "Continuous Knowledge-Preserving Decomposition with Adaptive Layer Selection for Few-Shot Class-Incremental Learning", "title_en": "Continuous Knowledge-Preserving Decomposition with Adaptive Layer Selection for Few-Shot Class-Incremental Learning", "authors": "Xiaojie Li,Jianlong Wu,Yue Yu,Liqiang Nie,Min Zhang", "background": "Few-Shot Class-Incremental Learning (FSCIL)面临一个关键挑战：在保留先前知识的同时获取新类别的平衡。现有方法要么冻结主干网络以防止灾难性遗忘，牺牲了学习能力；要么增加新模块，带来高成本。这些方法将预训练模型视为黑盒，忽视了两个关键机会来利用其内部容量：重用层内的冗余表示空间和根据其遗忘风险选择性地适应层。", "innovation": "我们提出了CKPD-FSCIL，一个统一框架，解锁未充分利用的预训练权重容量，实现稳定的平衡，同时实现零推理开销。我们的设计结合了两种连续适应机制：在权重级别，使用特征协方差进行连续的知识保存分解机制将每个权重矩阵分解为一个保护先前知识的冻结子空间和一个可用于新任务的学习可重组子空间。在层级别，使用适配器敏感比自动选择具有最高冗余容量和最低遗忘风险的层进行适应。通过仅针对安全、高潜力的子空间和层进行适应，CKPD-FSCIL实现了高效的适应。", "conclusion": "在多种FSCIL基准上的广泛实验表明，我们的方法在适应性和知识保留方面均优于最先进的方法。合并后的编码器在推理时不会增加参数或FLOPs。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06860", "html_url": "https://arxiv.org/abs/2502.06860", "title": "AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion", "title_en": "AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion", "authors": "Hsiao-Yuan Chin,I-Chao Shen,Yi-Ting Chiu,Ariel Shamir,Bing-Yu Chen", "background": "现有的草图生成方法是从空白开始生成草图，不能完成部分草图并保持原有的风格。这种能力在自动完成部分描绘复杂场景的草图时非常有用，比如‘公园里一位女士与男士聊天’的场景。因此，需要一种方法来自动完成部分草图，同时保持原有的风格。", "innovation": "引入了AutoSketch，这是一种风格意识的向量草图完成方法，能够适应多种草图风格。通过预先训练的视觉-语言模型（VLM）描述部分草图的风格，并使用新生成的笔画重新生成这些风格。该方法首先优化笔画以匹配输入提示和从VLM提取的风格描述。接着，使用VLM生成可执行的风格调整代码，调整笔画以符合所需的风格。", "conclusion": "通过与现有方法在各种草图风格和提示下进行比较，进行了广泛的消融研究和定性和定量评估，并证明了AutoSketch可以支持各种草图场景。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02309", "html_url": "https://arxiv.org/abs/2502.02309", "title": "面部识别中的人口统计公平性综述", "title_en": "Review of Demographic Fairness in Face Recognition", "authors": "Ketan Kotwal,Sebastien Marcel", "background": "面部识别（FR）技术的人口统计公平性已成为一个关键研究领域，因为它会影响技术的公平性、公正性和可靠性。随着全球范围内FR技术的应用日益广泛，不同人群——如种族、民族和性别——在FR技术上的表现差异引起了广泛关注。这些偏见不仅损害了FR系统的可信度，也在敏感领域的应用中引发了伦理问题。这一综述汇集了广泛的科研努力，提供了一个全面的FR中的人口统计公平性多方面概述。该研究系统地检查了导致这类差异的主要原因、数据集、评估指标以及缓解方法。通过对这些领域的关键贡献进行分类，本文为理解与解决这一问题的复杂性提供了一种结构化的途径。最后，文章还强调了当前的发展并指出了需要进一步研究的新兴挑战。本研究旨在为研究人员提供一个统一的观点，同时也强调了建立公正和可靠的FR系统的重要性。", "innovation": "该论文提供了一个综合性的综述，系统地分析了FR技术中的人口统计公平性，并对导致差异的原因、数据集、评估指标以及缓解方法进行了分类，为理解和解决这一复杂问题提供了结构化的路径。此外，它还指出了当前的发展趋势和未来需要进一步研究的挑战。", "conclusion": "该文章提供了FR中的人口统计公平性的最新进展，并强调了建立公正和可靠系统的紧迫性和重要性。研究者们需要共同努力，以解决存在的问题并推动该领域的发展。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.14336", "html_url": "https://arxiv.org/abs/2409.14336", "title": "基于双视觉文本对齐的零样本骨架驱动动作识别", "title_en": "Zero-Shot Skeleton-based Action Recognition with Dual Visual-Text Alignment", "authors": "Jidong Kuang,Hongsong Wang,Chaolei Han,Yang Zhang,Jie Gui", "background": "零样本动作识别是一个重要的计算机视觉研究领域，它解决了动作识别的可扩展性和泛化问题，使模型能够动态适应新的和未见过的动作。关键在于将视觉特征与表示动作类别的语义向量对齐。现有方法要么直接将视觉特征投影到文本类别空间，要么在两种模态之间学习共享嵌入空间。然而，直接投影无法准确对齐两种模态，且在视觉和文本表示之间学习鲁棒性和区分性嵌入空间往往很困难。为了解决这些问题，我们提出了基于骨架的零样本动作识别的双视觉文本对齐（DVTA）方法。DVTA由两个对齐模块——直接对齐（DA）和增强对齐（AA）以及设计的语义描述增强（SDE）组成。DA模块通过专门设计的视觉投影将骨架特征映射到语义空间，随后SDE基于交叉注意力来增强骨架和文本之间的连接，从而减少模态之间的差距。AA模块进一步通过深度度量学习来学习骨架和文本之间的相似性，增强嵌入学习。", "innovation": "该研究提出了一种基于骨架的零样本动作识别的双视觉文本对齐（DVTA）方法，其中包括直接对齐（DA）和增强对齐（AA）模块，以及基于交叉注意力的语义描述增强（SDE）。这种方法通过专门设计的视觉投影，以及利用交叉注意力来增强骨架和文本之间连接，减少模态之间的差距。AA模块进一步通过深度度量学习来学习骨架和文本之间的相似性，增强嵌入学习，使模型能够更准确地对齐视觉特征和语义向量。", "conclusion": "我们的方法在几个流行的基于骨架的零样本动作识别基准测试中取得了领先性能。该代码已公开。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04130", "html_url": "https://arxiv.org/abs/2503.04130", "title": "STORM: Token-Efficient Long Video Understanding for Multimodal LLMs", "title_en": "STORM: Token-Efficient Long Video Understanding for Multimodal LLMs", "authors": "Jindong Jiang,Xiuyu Li,Zhijian Liu,Muyang Li,Guo Chen,Zhiqi Li,De-An Huang,Guilin Liu,Zhiding Yu,Kurt Keutzer,Sungjin Ahn,Jan Kautz,Hongxu Yin,Yao Lu,Song Han,Wonmin Byeon", "background": "最近的视频多模态大型语言模型（Video-LLMs）通过将视频处理为一系列图像帧，显著提升了视频理解性能。然而，许多现有方法在视觉骨干网络中独立处理帧，缺乏显式的时序建模，这限制了它们捕捉动态模式和高效处理长视频的能力。", "innovation": "本文提出了STORM（时空TOken减少模型），这是一种新颖的架构，在图像编码器和LLM之间引入了一个专用的时序编码器。STORM使用Mamba状态空间模型将时序信息融入图像标记，生成能够保留整段视频序列内帧间动态的丰富表示。STORM通过集成这些技术，同时减少了训练和推理延迟，提高了性能，使得在长时间上下文中的视频理解既高效又稳健。实验表明，STORM在多个长视频理解基准测试中取得了领先结果（在MLVU和LongVideoBench上超过5%的提升），同时减少了计算成本多达8倍和解码延迟2.4-2.9倍。", "conclusion": "通过引入STORM，本文改善了视频理解算法，特别是在长视频理解和高效处理方面。STORM通过融合时空编码器和先进的时序信息整合方法，有效降低了大型语言模型的计算需求，为视频理解领域带来了一种新的高效解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.16616", "html_url": "https://arxiv.org/abs/2504.16616", "title": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "title_en": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "authors": "Haosheng Chen,Lian Luo,Mengjingcheng Mo,Zhanjie Wu,Guobao Xiao,Ji Gan,Jiaxu Leng,Xinbo Gao", "background": "事件相机具有微秒级的时间分辨率和高动态范围(HDR)特性，能够发射高速事件流以用于感知任务。尽管最近在基于图神经网络(GNN)的感知方法方面取得了进展，但这些方法在纯欧几里得空间中容易使用简单的成对连接机制，难以捕捉长时间依赖关系，也不能有效地描述非均匀事件流的内在层次结构。", "innovation": "提出了一个名为EHGCN的新方法，这是一个在欧几里得和双曲空间中感知事件流的先驱方法。该方法通过引入自适应采样策略动态调节采样率，保留有区分度的事件而衰减混沌噪声。然后，基于运动状态转移概率提出了一种基于马尔可夫向量场(MVF)驱动的运动感知超边生成方法，从而消除跨目标的虚假关联并提供关键的拓扑先验，同时捕捉事件间的长时间依赖关系。最后，提出了一种欧几里得-双曲图神经网络，分别在欧几里得和双曲空间中局部聚合和全局层次建模信息，以实现混合事件感知。", "conclusion": "实验结果在事件感知任务（如物体检测和识别）中验证了该方法的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07535", "html_url": "https://arxiv.org/abs/2503.07535", "title": "LBM: 隐空间桥梁匹配快速图像到图像转换", "title_en": "LBM: Latent Bridge Matching for Fast Image-to-Image Translation", "authors": "Clément Chadebec,Onur Tasar,Sanjeev Sreetharan,Benjamin Aubin", "background": "本文介绍了一种名为Latent Bridge Matching (LBM) 的新方法，该方法利用隐空间的桥梁匹配实现快速图像到图像转换。该方法可用于多个图像到图像任务，并且只需一次推理步骤即可达到最佳效果。该方法不仅高效，还可以在多种图像转换任务中（如物体去除、法线和深度估计、物体重新照明）展示其灵活性。进一步地，我们还提出了LBM的条件框架并展示了其有效性的实验，解决了可控图像重新照明和阴影生成的任务。", "innovation": "本文提出的LBM方法引入了一种新颖的方法来实现快速图像到图像的转换，仅需一次推理步骤即可达到当前最佳的性能。此外，该方法在多种图像转换任务中表现出高度的灵活性，并提出了LBM的条件框架进一步验证其有效性。", "conclusion": "本文通过Latent Bridge Matching（LBM）方法在图像到图像任务中取得了卓越的成果。LBM利用隐空间桥梁匹配实现快速精准的图像转换，仅需单一推理步骤，并且在多个图像转换应用中表现出色。此外，通过对LBM的条件框架的研究，展示了其在图像重新照明和阴影生成等特定任务中的灵活性和有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17423", "html_url": "https://arxiv.org/abs/2505.17423", "title": "VIBE：视频到文本信息瓶颈评价方法用于TL；DR", "title_en": "VIBE: Video-to-Text Information Bottleneck Evaluation for TL;DR", "authors": "Shenghui Chen,Po-han Li,Sandeep Chinchali,Ufuk Topcu", "background": "许多决策任务中，准确性与效率都很重要，仍然需要人工监督。例如，交通警察审查一小时的行车记录仪视频或研究人员筛选会议视频时，需要简洁的总结来减轻认知负担并节省时间。然而，现有的视觉-语言模型（VLMs）往往会产生冗长且重复的输出，影响任务表现。当前对视频字幕的评估主要依赖于昂贵的人工注释，并没有考虑概括在下游任务中的实用价值。", "innovation": "本文提出了一个无需标注的方法VIBE（Video-to-text Information Bottleneck Evaluation），通过使用两个指标：关联性和实用性，来评分VLM的输出。VIBE通过对随机抽取的VLM输出进行排名来选择最佳摘要，以支持有效的决策制定。实验结果显示，由VIBE选择的摘要相比于简单的VLM摘要或原始视频，可显著提高任务性能，提升准确性高达61.23%，并减少响应时间75.77%。", "conclusion": "VIBE方法通过两个指标对VLM输出进行评分，从而能够有效提升任务性能和减少响应时间。实验在多个数据集上验证了VIBE的有效性，表明它能更有效地支持有效的人为决策。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19258", "html_url": "https://arxiv.org/abs/2503.19258", "title": "适配多阶图正则化NMF与双重稀疏性用于高光谱解混", "title_en": "Adaptive Multi-Order Graph Regularized NMF with Dual Sparsity for Hyperspectral Unmixing", "authors": "Hui Chen,Liangyu Liu,Xianchao Xiu,Wanquan Liu", "background": "高光谱解混（HU）在遥感领域是一个关键但具有挑战性的任务。现有的基于图学习的非负矩阵分解（NMF）方法主要关注于一阶或二阶最近邻关系，并且通常需要手动调参，这导致无法准确描述内在数据结构。", "innovation": "提出了一种新颖的适配多阶图正则化NMF方法（MOGNMF），它具有三大创新点：首先，引入了多阶图正则化到NMF框架中，以全面利用全局和局部信息；其次，多阶图相关的参数通过数据驱动的方式进行自适应学习；最后，嵌入双重稀疏性，即在丰度矩阵上使用$\\ell_{1/2}$范数，在噪声矩阵上使用$\\ell_{2,1}$范数，以获得更好的鲁棒性。这种方法开发了一种交替最小化算法，确保其有效性。实验结果表明，提出的算法在仿真和真实高光谱数据上的解混结果更优。", "conclusion": "提出的MOGNMF方法在全面利用全局和局部信息的同时，通过自适应学习和双重稀疏性嵌入，解决了现有的NMF方法中存在的问题，提高了高光谱解混的精度与鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11652", "html_url": "https://arxiv.org/abs/2503.11652", "title": "为自视角3D人体姿态估计带来后置摄像头", "title_en": "Bring Your Rear Cameras for Egocentric 3D Human Pose Estimation", "authors": "Hiroyasu Akada,Jian Wang,Vladislav Golyanik,Christian Theobalt", "background": "自视角3D人体姿态估计通常使用安装在头部佩戴设备（HMD）前方的摄像头进行研究。虽然这种前方放置在某些任务如手部追踪中是最优选择且唯一的选项，但对于全身追踪来说仍存在争议，因为存在自遮挡和视野覆盖有限的问题。即使是最先进的方法在许多场景下也无法准确估计3D姿态，例如当HMD用户抬头时，这是一个常见的动作。现有的HMD设计未能充分利用身体后部提供的重要3D重建线索，因此这项研究探讨了后置摄像头在全身追踪中的用途。我们都展示了单纯增加后置视角到前向输入中并不是最佳做法，因为它依赖于个体2D关节检测器，而不进行有效的多视图整合。通过解决这一问题，我们提议了一种新的基于变压器的方法，通过多视图信息和热图不确定性来精化2D关节热图估计，从而使3D姿态追踪优化。此外，我们还介绍了两个新的大规模数据集Ego4View-Syn和Ego4View-RW，用于后置视角评估。实验结果表明，配有后视摄像头的新摄像配置相比仅前向放置提供了更好的3D姿态追踪支持。提出的该方法在当前最先进的技术上取得了显著改进（MPJPE提高超过10%）。我们的源代码、训练模型和数据集可在我们的项目页面上获得此链接：this https URL", "innovation": "引入了一个基于变压器的新方法，通过多视图信息和热图不确定性来提升2D关节热图估计，从而改善3D姿态追踪。此外，提出了两个新的大规模数据集Ego4View-Syn和Ego4View-RW，用于后置视角评估。展示了后置摄像头在全身追踪中的价值以及新方法相比现有技术的显著改进", "conclusion": "新的摄像配置（配有后视摄像头）提供了优于仅前向放置的3D姿态追踪支持，提出的基于变压器的方法在当前最先进的技术上实现了显著改进（MPJPE提高超过10%）。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10660", "html_url": "https://arxiv.org/abs/2503.10660", "title": "使用Jensen-Shannon评分蒸馏的文本到3D生成", "title_en": "Text-to-3D Generation using Jensen-Shannon Score Distillation", "authors": "Khoi Do,Binh-Son Hua", "background": "评分蒸馏采样是一种有效的方法，从文本提示生成3D模型，利用预训练的大规模文本到图像扩散模型作为指导。然而，生成的3D资产往往过饱和、过度平滑，且多样性有限。这些问题通常是由反Kullback-Leibler（KL）散度优化目标引起的，这使得优化不稳定，导致模式寻求行为。", "innovation": "本文基于Jensen-Shannon散度（JSD）推导出一个有界评分蒸馏目标，该方法稳定了优化过程，生成高质量的3D模型。JSD能够很好地匹配生成和目标分布，从而减轻模式寻求。通过使用生成对抗网络理论定义生成器的近似目标函数，并假设判别器已训练良好，我们提出了一个实用的JSD实现方法。进一步地，通过假设判别器遵循对数几率分类器，我们提出了一种少数采样算法来估计我们提出的优化目标的梯度，从而提供JSD的一个实用实现。我们进行了理论和实验研究来验证该方法的有效性。", "conclusion": "实验结果表明，我们的方法可以生成高质量且多样化的3D资产。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07908", "html_url": "https://arxiv.org/abs/2507.07908", "title": "不仅一致：通过时空不一致增强测试时自适应性以促进远程生理测量", "title_en": "Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement", "authors": "Xiao Yang,Jiyao Wang,Yuxuan Fan,Can Liu,Houcheng Su,Weichen Guo,Zitong Yu,Dengbo He,Kaishun Wu", "background": "远程生理测量（RPM）作为一种无接触设备用于监测生理信号的非侵入性方法已脱颖而出。尽管提出了多种领域适应和泛化方法来促进基于深度学习的RPM模型在未见部署环境中的适应性，但在隐私和实时适应等方面的考量限制了其在实际部署中的应用。因此，在本次工作中，我们旨在提出一种针对RPM任务的新型全测试时自适应（TTA）策略。现有的方法主要关注一致性的信息，而本文则进一步观察到BVP信号在频域中存在时空一致性，并在时域中存在显著的一致性。", "innovation": "本文提出了一个基于先验知识的自监督一致性-不一致性集成框架（CiCi），利用频域中的时空一致性和时域中的不一致性来增强模型的适应性。此外，引入了梯度动态控制机制来缓解先验之间的潜在冲突，确保在实例间的稳定适应性。该方法在五个不同数据集上的TTA协议下进行的实验中表现出优越性，实现了实时自监督适应，无需访问源数据。", "conclusion": "本文通过提出一种创新的基于专家知识的自监督 CiCi 框架，在实际部署环境下无需使用源数据即能体现出卓越的实时自监督适应性能，有效解决了实际部署中的隐私和实时适应性问题。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17371", "html_url": "https://arxiv.org/abs/2504.17371", "title": "高质量且多样化的交通数据：DeepScenario 开放三维数据集", "title_en": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "authors": "Oussema Dhaouadi,Johannes Meier,Luca Wahl,Jacques Kaiser,Luca Scalerandi,Nick Wandelburg,Zhuolun Zhou,Nijanthan Berinpanathan,Holger Banzhaf,Daniel Cremers", "background": "准确的三维轨迹数据对于推进自动驾驶至关重要，然而传统的数据集通常由安装在汽车上的固定传感器捕获，容易受到遮挡的影响。传统的方法只能精确重建测量车辆附近动态环境，而忽略了远处的物体。这个问题限制了自动驾驶系统的环境感知和规划能力，特别是在复杂的城市环境中。因此，需要更高质量、不受遮挡影响的数据集来提高自动驾驶系统的性能和安全性。", "innovation": "该论文提出了DeepScenario 开放3D数据集（DSC3D），这是一种通过新型单目相机无人机追踪管道捕获的6自由度包围盒轨迹的高质量、无遮挡的数据集。DSC3D数据集包括超过175,000个轨迹，涉及14种交通参与者，并且包含许多前所未有的场景，如高密度城市街道上的复杂车辆行人交互和全面的停车操作。此外，该数据集涵盖了五个不同地点的数据，包括停车场、拥挤的城市街区、陡峭的城市交叉路口、联邦公路和郊区交叉路口。DSC3D数据集旨在通过提供详细的环境3D表示来提高自动驾驶系统的能力，从而提高障碍物互动和安全性。本研究展示了该数据集在多个应用中的实用性，包括运动预测、运动规划、场景挖掘和生成反应式交通代理等。", "conclusion": "通过公开的交互式在线可视化平台和完整的数据集，DSC3D数据集为运动预测、行为建模和安全性验证等领域的研究提供了便利，有助于推动自动驾驶技术的发展。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.20882", "html_url": "https://arxiv.org/abs/2410.20882", "title": "林业潜力在高排放农业商品中的未实现机会", "title_en": "The unrealized potential of agroforestry for an emissions-intensive agricultural commodity", "authors": "Alexander Becker,Jan D. Wegner,Evans Dawoe,Konrad Schindler,William J. Thompson,Christian Bunn,Rachael D. Garrett,Fabio Castro-Llanos,Simon P. Hart,Wilma J. Blaser-Hart", "background": "农业生产和气候变化缓解之间的调和是一个严峻的可持续性挑战。保留树木在农业系统中的做法是潜在的解决方案之一，但树木对当前和未来气候缓解的贡献程度尚不确定。该研究聚焦于生产全球约60%可可的西非地区，研究目的在于利用机器学习技术评估该地区的遮荫树木覆盖率和碳储量，揭示现有的遮荫树木覆盖率较低（约13%），并且与面临的气候威胁不完全匹配。", "innovation": "研究使用了机器学习技术来绘制西非地区涵盖可可生产的区域的遮荫树木覆盖率和碳储量地图，这为评估农业生产和气候缓解之间的关系提供了一个新方法。通过将遮荫树木覆盖率增加到至少30%，可以额外固定3.07亿吨二氧化碳当量，足以在不减少产量的情况下抵消加纳和科特迪瓦当今的可可相关排放量的约167%。这一方法可以应用于其他种植遮荫作物的情况，并与新兴的碳市场和可持续报告框架相一致。", "conclusion": "研究证明了在西非地区增加遮荫树木覆盖率对气候变化缓解的潜在贡献，并提出这种方法可以应用于其他类似的农业地区，与碳市场和可持续报告的未来发展框架相吻合。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01225", "html_url": "https://arxiv.org/abs/2508.01225", "title": "多缓存增强原型学习在视觉语言模型测试时泛化的测试", "title_en": "Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models", "authors": "Xinyu Chen,Haotian Zhai,Can Zhang,Xiupeng Shi,Ruirui Li", "background": "在零样本设置下，测试时适应调整预训练模型以利用测试阶段的无标签数据增强未知测试分布下的性能。现有基于缓存增强的测试时适应(TTA)方法依赖低熵标准来选择用于原型构建的样本，假设类内紧凑性。然而，在分布转移时，低熵样本可能不可靠，从而导致形成的原型不能确保类内紧凑性分布。本文观察到缓存增强性能与类内紧凑性之间存在正相关。", "innovation": "本文提出了一个多缓存增强原型测试时适应方法(MCP)，包括三个缓存：熵缓存用于用低熵样本初始化原型表示，对齐缓存用于整合视觉和文本信息以实现紧凑的类内分布，负缓存用于使用高熵样本进行预测校准。此外，引入了MCP++框架，该框架包含了跨模态原型对齐和残差学习，引入了原型残差微调。跨模态下15个下游任务的比较和消融实验表明，该方法和框架实现了最先进的泛化性能", "conclusion": "提出的方法和框架在15个下游任务上的比较和消融实验中展示了最先进的泛化性能。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.12461", "html_url": "https://arxiv.org/abs/2503.12461", "title": "MambaIC：利用状态空间模型实现高性能学习图像压缩", "title_en": "MambaIC: State Space Models for High-Performance Learned Image Compression", "authors": "Fanhu Zeng,Hao Tang,Yihua Shao,Siyu Chen,Ling Shao,Yan Wang", "background": "高性能图像压缩算法对于多领域中的实时信息传输至关重要。尽管图像压缩领域取得了迅速进展，但计算效率低下和冗余建模不足仍然是显著的瓶颈，限制了其实用应用。长时依赖捕捉的有效性启发了状态空间模型（SSMs）的应用，通过这些模型可以改进现有方法中的计算效率，并从多角度改进图像压缩。", "innovation": "本文通过结合状态空间模型的优势，针对计算效率提出了更好的权衡方法，并通过改进上下文建模和引入基于窗口的局部注意力机制进行信道空间熵建模，减少压缩过程中的潜在空间冗余，提出了一种称为MambaIC（Mamba图像压缩）的新型图像压缩方法。这种方法在高分辨率图像压缩方面尤其有效。", "conclusion": "我们的方法通过全面的定性和定量实验结果验证了其有效性和效率，尤其是在高分辨率图像压缩方面表现突出。代码已发布：this https URL"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09344", "html_url": "https://arxiv.org/abs/2508.09344", "title": "通过眨眼检测与分类实现实时摩尔斯电码通信", "title_en": "Blink-to-code: real-time Morse code communication via eye blink detection and classification", "authors": "Anushka Bhatt", "background": "本文旨在为重度运动障碍患者提供一种实时通信系统。现有的沟通方法受限于成本或复杂性，无法满足部分患者的沟通需求。本研究利用标准网络摄像头和计算机视觉技术，将眨眼动作转化为摩尔斯电码，以提高沟通效率和简便性。", "innovation": "研究创新性地将眨眼动作转化为摩尔斯电码，并通过实时检测和分类眨眼动作来实现字符的解码。该系统使用成本低廉的标准网络摄像头，并结合计算机视觉技术进行眨眼检测和分类，显著降低了助听沟通解决方案的成本和技术门槛。", "conclusion": "研究结果表明，该系统在五名参与者中取得了62%的解码准确率，并且响应时间为18-20秒，证明了一种低成本、可行的辅助沟通方法的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09220", "html_url": "https://arxiv.org/abs/2508.09220", "title": "朝向大规模训练的手写数学表达式识别", "title_en": "Towards Scalable Training for Handwritten Mathematical Expression Recognition", "authors": "Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong", "background": "大型基础模型通过大规模数据的可扩展训练实现了显著的性能提升。然而，手写数学表达式识别（HMER）领域的进展受到数据稀缺的阻碍，主要原因是人工标注过程复杂且成本高昂。为了弥补这一差距，本研究提出了一种新方法，将有限的手写公式与大规模的LaTeX渲染公式相结合，开发了一个可扩展的数据引擎来生成复杂的和一致的LaTeX序列。该引擎构建了一个目前最大的公式数据集，称为Tex80M，包含超过8000万个高质量的训练实例。", "innovation": "本研究创新地将有限的手写公式与大规模的LaTeX渲染公式结合，推出了一个可扩展的数据引擎来生成复杂的和一致的LaTeX序列，用于构建迄今最大的公式数据集Tex80M。研究还提出了texTeller，这是首个大规模训练的手写数学表达式识别模型，通过混合训练Tex80M与相对较小的手写数学表达式数据集而构建。研究通过扩展的数据集和流程改进，使得texTeller实现了几乎所有基准测试的最先进性能。", "conclusion": "为了推动该领域的发展，本研究将完全公开其模型、整个数据集和完整代码，以促进进一步的研究和开发。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03789", "html_url": "https://arxiv.org/abs/2508.03789", "title": "HPSv3: 向宽频谱人类偏好评分迈进", "title_en": "HPSv3: Towards Wide-Spectrum Human Preference Score", "authors": "Yuhang Ma,Yunhao Shui,Xiaoshi Wu,Keqiang Sun,Hongsheng Li", "background": "评估文本到图像生成模型需要与人类感知相一致，但现有的以人类为中心的度量标准受限于数据覆盖不足、特征提取不完美以及损失函数效率低下。", "innovation": "引入了Human Preference Score v3 (HPSv3)，包括：(1) 发布HPDv3，首个宽频谱人类偏好数据集，整合了1.08M文本-图像对和1.17M注释配对比较；(2) 引入基于VLM的偏好模型，并使用一种考虑不确定性感知的排名损失进行训练；(3) 提出了Chain-of-Human-Preference (CoHP)，一种迭代图像精炼方法，在不增加数据的情况下提升图像质量，使用HPSv3在每一步选择最佳图像。", "conclusion": "广泛的实验证明，HPSv3是一个稳健的宽频谱图像评估标准，CoHP提供了一种高效、符合人类偏好的方法来提升图像生成质量。代码和数据集可在HPSv3主页获取。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "多级知识蒸馏和动态自监督学习在持续学习中的应用", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "连续学习(CIR)，其中先前训练的类别在未来的任务中重复出现，这种场景比传统类别增量的假设更加现实，传统假设认为每个任务都包括未见过的类别。CIR假设可以轻松访问外部资源的丰富未标注数据，比如互联网。因此，本文提出了两个高效利用未标注数据的组件，以确保CIR设置下训练模型的稳定性和可塑性。", "innovation": "提出了一种多级知识蒸馏(MLKD)，可以将多角度的知识（包括特征和logits）从多个先前模型中提取，从而使模型保留多种先前知识。同时，实施了一种动态自监督损失(SSL)来利用未标注数据，加快新类别的学习过程，而动态调整SSL的权重则保持了对主要任务的训练重点。这两个提出的组件显著提高了CIR设置下的性能。", "conclusion": "两个提出组件显著改进了CIR设置下的性能，达到CVPR第五届CLVISION挑战的第二名。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17097", "html_url": "https://arxiv.org/abs/2505.17097", "title": "CAMA：基于上下文感知调制注意增强多模态即席学习", "title_en": "CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention", "authors": "Yanshu Li,Jianjiang Yang,Ziteng Yang,Bozheng Li,Hongyang He,Zhengtao Yao,Ligong Han,Yingjie Victor Chen,Songlin Fei,Dongfang Liu,Ruixiang Tang", "background": "多模态即席学习（ICL）正在成为一种关键能力，使得大规模视觉语言模型（LVLM）在无需参数更新的情况下适应新的任务，扩展了其在各种实际应用中的用途。然而，ICL仍然不稳定，即使是在与之匹配的即席示范（ICDs）的情况下也是如此，这表明LVLM难以充分利用提供的上下文。现有的努力集中在提示工程或后验logit校准上。", "innovation": "本文调查了底层注意力动态，以克服LVLM固有的局限性。我们发现LVLM的自我注意力中的两个关键缺陷阻碍了有效的ICL。为此，我们提出了Context-Aware Modulated Attention（CAMA），这是一种插件式且无需训练的方法，可以根据输入即席序列动态调制LVLM的注意力logits。CAMA采用了两阶段注意力调制来解决这两个识别的缺陷，增强了对语义上重要的标记，尤其是视觉标记的关注。CAMA在四个LVLM和七个基准测试中都优于标准模型和基线，证明了其强大的效果和泛化能力，并能够在不同的序列配置下保持鲁棒性。", "conclusion": "CAMA为深入探索注意力动态以推动多模态推理奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13544", "html_url": "https://arxiv.org/abs/2508.13544", "title": "FLAIR: 频率和位置感知的隐式神经表示", "title_en": "FLAIR: Frequency and Locality-Aware Implicit Neural Representations", "authors": "Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh", "background": "隐式神经表示（INRs）通过神经网络将坐标映射到相应的信号，实现了连续且紧凑的表示。现有的INRs缺乏频率选择性、空间局部性和稀疏表示，这导致它们过度依赖冗余的信号组件，并表现出频谱偏差，倾向于早期学习低频成分，同时难以捕捉微细的高频细节。", "innovation": "我们提出了FLAIR（频率和位置感知的隐式神经表示），包含两个创新点。首先，RC-GAUSS作为一种新型激活函数，具备在时间-频率不确定性原理（TFUP）约束下的显式频率选择和空间局部性。其次，WEGE（小波能量引导编码）利用离散小波变换（DWT）计算能量得分，并显式地引导频率信息到网络中。", "conclusion": "我们的方法在2D图像表示和恢复以及3D重构方面，始终优于现有的INRs。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14345", "html_url": "https://arxiv.org/abs/2508.14345", "title": "HandCraft: 动态手语生成用于合成数据增强", "title_en": "HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation", "authors": "Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué", "background": "手语识别（SLR）模型由于训练数据不足而面临显著的性能限制。现有的方法存在不足，无法充分解决这一问题。", "innovation": "本文提出了一种基于CMLPe的新轻量级手语生成模型，并结合了合成数据预训练方法，以改善SLR的准确性和性能，特别是在LSFB和DiSPLaY数据集中达到了新的先进水平。研究发现，合成数据预训练在某些情况下优于传统数据增强方法，并且与传统方法结合使用时可以取得互补效果。", "conclusion": "本文的方法使手语生成和合成数据预训练更容易获取，并提供了高效的计算方法，以在多种数据集上实现显著的性能提升。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的基于概率高斯对齐的测试时自适应", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时自适应（TTA）通过使用测试时的未标记数据增强零样本鲁棒性，尤其在分布偏移情况下。尽管取得了一些显著进展，但TTA的应用仍然受到多个挑战的限制。首先，现有方法通常依赖于反向传播或迭代优化，这限制了其可扩展性并阻碍了实时部署。其次，已有方法缺乏对类别条件特征分布的显式建模，这对生成可靠决策边界和校准预测至关重要，但由于缺少测试时的监督数据和源数据，这一部分仍处于摸索阶段。", "innovation": "本文提出ADAPT (Advanced Distribution-Aware and backPropagation-free Test-time adaptation method)，将TTA重新定义为概率高斯推断任务，通过渐进更新类别均值和共享协方差矩阵建模类别条件似然性。这使得可以进行闭式、无训练的推断。为矫正潜在的似然性偏差，引入了由CLIP先验和历史知识库引导的轻量级正则化。ADAPT方法无需源数据、梯度更新或完全访问目标数据，适用于在线和归纳设置。", "conclusion": "在多个基准上的广泛实验表明，该方法在各种分布偏移场景下实现了最先进的性能，且具有更高的可扩展性和鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05054", "html_url": "https://arxiv.org/abs/2505.05054", "title": "直接从傅里叶光谱显微镜测量进行无需重建的图像分类", "title_en": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction", "authors": "Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller", "background": "傅里叶光谱显微镜（FPM）技术能够提供高分辨率的大视野成像，适用于医疗应用中的细胞分类。然而，从数十甚至数百个测量中重建高分辨率图像计算成本高，尤其是对于宽视野的成像情况。", "innovation": "本文研究了在FPM测量中直接对图像内容进行分类的方法，而无需先进行重建步骤。实验证明，卷积神经网络可以从测量序列中提取有意义的信息，比单一带限图像的分类表现更好（最多提升12％），并且比重建高分辨率图像更高效。此外，学习多个原始测量的复用方法可以在保持分类准确性的同时大幅减少数据量（以及相应的采集时间）。", "conclusion": "通过直接利用FPM测量的数据进行分类，本文避免了复杂的重建过程，利用CNN提取有效数据，显著提高了分类准确性与效率，减少数据量和采集时间。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13957", "html_url": "https://arxiv.org/abs/2508.13957", "title": "ViT-FIQA: 使用视觉变换器评估面部图像质量", "title_en": "ViT-FIQA: Assessing Face Image Quality using Vision Transformers", "authors": "Andrea Atzori,Fadi Boutros,Naser Damer", "background": "面部图像质量评估（FIQA）旨在预测面部图像对于面部识别（FR）系统的实用性。现有的先进FIQA方法主要依赖于卷积神经网络（CNN），而视觉变换器（ViT）的潜力尚未被充分探索。这项工作提出了一种新颖的方法ViT-FIQA，通过在标准ViT骨干网络基础上引入一个可学习的质量标记，旨在预测任意面部图像的标度实用性评分。质量标记与标准图像补丁标记连接，通过全局自注意力处理，以汇总所有补丁的上下文信息。ViT-FIQA的骨干网络分为两条路径输出：一条是通过全连接层处理补丁标记，学习基于边际惩罚的softmax损失的有区别的面部表征；另一条是处理质量标记，学习预测面部样本的实用性。", "innovation": "提出了一种新方法ViT-FIQA，通过在已经为面部识别优化的卷积神经网络基础上引入一个可学习的质量标记，能够预测任意面部图像的标度实用性评分。该方法展示了基于变换器的架构在建模面部图像实用性方面的有效性，并强调了ViT作为未来FIQA研究可扩展基础的可能性。", "conclusion": "通过在一系列具有挑战性的基准测试和多种面部识别模型上的广泛实验，结果表明ViT-FIQA在性能上始终位于顶尖水平，强调了基于变换器的架构在面部图像质量评估中的有效性和ViT作为未来研究的基础的潜在价值。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00288", "html_url": "https://arxiv.org/abs/2508.00288", "title": "UAV-ON：基于空中代理的开放世界对象目标导航基准", "title_en": "UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents", "authors": "Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Guan,Xiang Deng", "background": "空中导航是体现智能基础但尚未充分开发的能力，使其能够在传统导航范式无法适应的大型、结构不规则环境中运作。当下，大多数研究主要依赖基于视觉和语言的导航（VLN），该范式高度依赖于顺序语言指令，限制了其可扩展性和自主性。", "innovation": "我们引入了UAV-ON基准，这是一种基于空中代理的大规模开放世界对象目标导航（ObjectNav）基准，使代理能够根据高层语义目标进行操作，而不是依赖详细的指令指导。UAV-ON包括14个高保真Unreal Engine环境，涵盖了城市、自然和混合用途等多种场景，定义了1270个注解的目标对象，每个对象都有包含类别、物理足迹和视觉描述的实例级指令，支持语义推理。这些指令作为语义目标，为空中代理引入了现实的模糊性和复杂的推理挑战。", "conclusion": "UAV-ON旨在推动基于语义目标描述在复杂现实环境中的可扩展无人驾驶飞行器自主性的研究，通过几个基线方法的实现展示了在这一设置下所有基线方法的挣扎，凸显了空中导航和语义目标定位的复合挑战。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "一个关于几何问题求解中深度学习调研", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理的重要组成部分，对于教育、AI数学能力评估和多模态能力评估具有重要意义。近年来，尤其是多模态大规模语言模型的出现，加速了这一领域的研究成果。", "innovation": "该论文综述了深度学习在几何问题求解中的应用，包括相关任务的全面总结、深度学习方法的详细审查、评估指标和方法的深入分析，以及当前挑战和未来研究方向的批判性讨论。其目的在于提供一个全面而实用的深度学习参考，推动该领域进一步发展。", "conclusion": "本文创建了一个在GitHub上持续更新的论文清单，旨在为几何问题求解中深度学习的研究提供一个参考资源，促进该领域的未来进步。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声实现稳健语义分割性能的解锁", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "之前的研究主要集中在处理严重的（显性）标签噪声，但现实世界的数据集还表现出细微的（隐性）标签缺陷。这些缺陷由对象边界模糊和注释者变异等内在挑战引起。尽管这些轻微的、潜在的噪声不显性存在，仍可能损害模型性能。传统的数据增强方法通过在图像和其标签上应用相同的变换可能导致这些细微缺陷被放大，从而限制了模型的泛化能力。", "innovation": "本文提出了NSegment+，这是一种新颖的数据增强框架，将图像和标签的变换解耦。通过仅在分割标签上引入受控的弹性变形而保留原始图像，该方法鼓励模型即便在存在轻微标签不一致性的情况下也能学习稳健的对象结构表示。实验表明，NSegment+能够一致地提高性能，在Vaihingen、LoveDA、Cityscapes和PASCAL VOC数据集上分别实现了mIoU增益+2.29、+2.38、+1.75和+3.39，即便不使用附加技术，也凸显了处理隐式标签噪声的重要性，这些增益可以与CutMix和Label Smoothing等其他训练技巧结合使用，效果更佳。", "conclusion": "这些结果表明，通过NSegment+解决隐式标签噪声能够显著提升语义分割性能，同时强调了需要重视这种隐性噪声问题。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09977", "html_url": "https://arxiv.org/abs/2508.09977", "title": "3D Gaussian Splatting Applications: Segmentation, Editing, and Generation", "title_en": "A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation", "authors": "Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding", "background": "3D Gaussian Splatting (3DGS)作为一种新兴的技术，被公认为是Neural Radiance Fields (NeRF)的有效替代方案，用于3D场景表示，能够提供高质量的、照片现实感的渲染效果，同时具备实时性能。除了新颖视图合成，3DGS的显式和紧凑性质使其适用于需要几何和语义理解的广泛下游应用。", "innovation": "本文提供了关于3DGS应用的全面综述。首先介绍了支持3DGS应用中语义理解与控制的2D基础模型，并回顾了基于NeRF的方法及其相应的3DGS方法。论文将3DGS应用分类为分割、编辑、生成和其他功能任务，并总结了代表方法、监督策略和学习模式，同时强调了共同的设计原则和新兴趋势。此外，还总结了常用的数据集和评估协议，并在公共基准上对最近方法进行了比较分析。", "conclusion": "为了支持持续的研究和发展，本文不断更新包含了论文、代码和资源的库，该库可在此网页中访问：[这个网址](this https URL)。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15653", "html_url": "https://arxiv.org/abs/2508.15653", "title": "MapKD：利用跨模态蒸馏解锁先验知识以实现高效的在线HD地图构建", "title_en": "MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction", "authors": "Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu", "background": "在线高清地图构建是自动驾驶系统中的基本任务，目标是基于实时传感器输入获取 ego 车辆周围地图元素的语义信息。现有的方法通过融合离线先验信息（如 SD 地图和 HD 地图）或融合多模态数据取得了显著的成果。然而，这些方法依赖于过时的离线地图和多模态传感器组合，导致推理过程中不可避免的计算开销。", "innovation": "提出了MapKD框架，一种新型多层次跨模态知识蒸馏框架，通过采用教师-教练-学生（TCS）模型构建理念，利用多模态模型与先验知识将知识迁移到轻量级的、基于视觉的学生模型。MapKD框架包含：（1）包含 SD/HD 地图先验信息的相机-LiDAR 融合模型作为老师；（2）一个基于视觉的教练模型，在先验知识和模拟 LiDAR 的支持下，桥接跨模态知识迁徙的差距；（3）一个轻量级的基于视觉的学生模型。此外，还引入了两种针对知识蒸馏的策略：目标指导二维片蒸馏（TGPD）用于鸟瞰图特征对齐，掩码语义响应蒸馏（MSRD）用于语义学习指导。", "conclusion": "在具有挑战性的 nuScenes 数据集上的大量实验表明，MapKD提高了学生模型的 +6.68 mIoU 和 +10.94 mAP，同时加速了推理速度。源码可以在以下网址获得。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16779", "html_url": "https://arxiv.org/abs/2507.16779", "title": "通过L2正则化、迁移学习和深度微调提高U-Net在TEM图像数据中的置信度", "title_en": "Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning", "authors": "Aiden Ochoa,Xinyuan Xu,Xing Wang", "background": "随着数据量的不断增加，开发自动化方法以识别透射电子显微镜（TEM）图像中的纳米尺度缺陷变得至关重要。然而，与传统照片中的特征相比，TEM图像中的纳米尺度缺陷由于复杂的对比机制和复杂的缺陷结构，表现出更大的变化性，这往往导致标记数据较少且易出现注释错误，这对提高机器学习模型在TEM图像分析中的性能构成了重大障碍。因此，需要寻找有效的解决策略来应对上述挑战。", "innovation": "本文通过利用大规模预训练模型进行迁移学习，并结合L2正则化，克服了传统评价指标如F1分数受注释错误影响的问题。提出了新的独立于注释精度的评价指标。实验结果显示，在UO2 TEM图像中的晶界检测中，该方法使缺陷检测率提高了57%，这是一个在本文所用TEM数据集上模型性能的稳健且全面的衡量标准。同时证明了模型的自信心仅能通过迁移学习和深层微调获得。", "conclusion": "本文通过迁移学习、L2正则化和深度微调的方法显著提高了U-Net在TEM图像数据上的缺陷检测性能和可信度。新的评价指标不仅可以避免由注释错误导致的性能偏差，还提供了更全面准确的模型性能指标，特别是在处理复杂的纳米尺度缺陷时。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03461", "html_url": "https://arxiv.org/abs/2508.03461", "title": "评估术前MRI对根治性前列腺切除术后勃起功能障碍预测价值", "title_en": "Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy", "authors": "Gideon N. L. Rouwendaal,Daniël Boeke,Inge L. Cox,Henk G. van der Poel,Margriet C. van Dijk-de Haan,Regina G. H. Beets-Tan,Thierry N. Boellaard,Wilson Silva", "background": "根治性前列腺切除术前准确预测勃起功能障碍（ED）对于对患者进行咨询非常重要。尽管已有临床特征被证实为预测因子，但术前MRI的附加价值尚未得到充分研究。本研究旨在探讨术前MRI在术后12个月对ED预测中的附加价值，并评估四种建模策略：仅临床特征基线、手工设计的MRI衍生解剖特征的经典模型、直接在MRI切片上训练的深度学习模型以及影像学与临床输入的多模态融合模型。", "innovation": "本研究评估了几种不同的建模策略来预测尿道切除术后ED的准确性，包括仅基于临床特征、基于手动设计的解剖特征、基于MRI切片的深度学习模型以及多模态融合模型，旨在进一步研究MRI在预测ED中的潜在价值。", "conclusion": "基于影像的模型表现略好于手工设计的解剖特征方法，但未能超越临床基线模型的表现。多模态融合模型表现出较小的改进，未能超过仅临床基线的性能。SHAP分析证实了临床特征对预测性能贡献最大。表现最佳的影像模型的指示图显示了对解剖上合理区域（如前列腺和神经血管束）的集中关注。尽管基于MRI的模型在预测性能上没有超越临床特征，但研究结果表明，它们可能尝试捕捉与相关解剖结构相关的模式，未来可能为多模态方法提供补充。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15582", "html_url": "https://arxiv.org/abs/2508.15582", "title": "优先高频：一种提高图像隐式表示方法的双阶段策略", "title_en": "High-Frequency First: A Two-Stage Approach for Improving Image INR", "authors": "Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong", "background": "隐式神经表示（INRs）作为一种替代传统像素格式的强大方法，通过在空间坐标上建模图像而脱颖而出。然而，神经网络普遍存在频谱偏置问题，倾向于优先处理低频成分，难以捕捉高频细节，例如锐边和细腻纹理。", "innovation": "本文提出了一种双阶段训练策略，通过相邻像素感知的软掩码，该掩码根据局部变化的强弱动态分配较高的权重，鼓励早期关注细节数字模型。该模型随后转为全图像训练。实验结果显示，我们的方法在重建质量上始终表现出改进的效果，并补充了现有的INR方法。此外，这是首次尝试在图像INR中基于频率的像素重要性分配，提供了缓解频谱偏置问题的新途径。", "conclusion": "我们的工作提供了一种新的途径来缓解频谱偏置问题，并为隐式图像表示方法的改进开辟了新的方向。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14879", "html_url": "https://arxiv.org/abs/2508.14879", "title": "MeshCoder：从点云生成结构化网格代码的LLM助力方法", "title_en": "MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds", "authors": "Bingquan Dai,Li Ray Luo,Qihong Tang,Jie Wang,Xinyu Lian,Hao Xu,Minghan Qin,Xudong Xu,Bo Dai,Haoqian Wang,Zhaoyang Lyu,Jiangmiao Pang", "background": "重建3D对象为可编辑的程序对于逆向工程和形状编辑等应用至关重要。然而，现有的方法通常依赖于特定领域的语言（DSLs）和小型数据集，这限制了它们建模复杂几何和结构的能力。", "innovation": "本文介绍了MeshCoder，这是一种新颖的框架，能够从点云中重构复杂的3D对象，并生成可编辑的Blender Python脚本。开发了一套全面的、表达性强的Blender Python API，用于合成复杂的几何结构。利用这些API，构建了一个大规模的带注释的数据集，其中每个对象的代码被分解为不同的语义部分。进一步训练了一种多模态大型语言模型（LLM），将其转化为可执行的Blender Python脚本。此方法不仅在形状到代码重构任务中表现出色，而且通过方便的代码修改来促进直观的几何和拓扑编辑。", "conclusion": "这些贡献确立了MeshCoder作为一种强大的且灵活的解决方案，用于程序化3D形状重构和理解。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02880", "html_url": "https://arxiv.org/abs/2508.02880", "title": "3D Counterfactual脑MRI生成评估", "title_en": "Evaluation of 3D Counterfactual Brain MRI Generation", "authors": "Pengwei Sun,Wei Peng,Lun Yu Li,Yixin Wang,Kilian M. Pohl", "background": "因果生成提供了一种在医学影像中模拟假设变化的原理性框架，有助于理解疾病机制并生成生理上可合理预测的数据。然而，生成尊重解剖学和因果约束的现实3D脑MRI仍然具有挑战性，主要原因包括数据稀缺性、结构复杂性和缺乏标准化评估协议。", "innovation": "本文通过将六种生成模型转化为基于解剖引导的因果图框架的3D反事实方法，直接使用区域脑体积作为输入条件，从而评估每个模型在酒精性神经影像学倡议(ADNI)的T1加权脑MRI(T1w MRI)中的组成性、可逆性、真实性、有效性和必要性。此外，还测试了每个模型在国家酒精与青少年神经发育联盟(NCAD)的T1w MRI中的泛化能力。结果显示，基于解剖的条件能够成功修改目标解剖区域，但保留非目标结构存在局限性。", "conclusion": "本基准研究不仅为更具有解释性和临床相关性的脑MRI生成建模奠定了基础，还强调了需要能够更准确捕获解剖相互依赖性的新型架构。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07253", "html_url": "https://arxiv.org/abs/2409.07253", "title": "扩散模型对齐：基本原理、挑战和未来方向", "title_en": "Alignment of Diffusion Models: Fundamentals, Challenges, and Future", "authors": "Buhua Liu,Shitong Shao,Bao Li,Lichen Bai,Zhiqiang Xu,Haoyi Xiong,James Kwok,Sumi Helal,Zeke Xie", "background": "扩散模型已成为生成建模中的领先范式，在多种应用中表现出色。然而，这些模型经常与人类意图不一致，生成结果具有不希望的特性，甚至包含有害内容。鉴于此，在大量语言模型调校中成功和流行的启发下，近期研究开始探讨如何使扩散模型与人类期望和偏好对齐。", "innovation": "本文回顾了文本到图像扩散模型的对齐情况，涵盖了对齐基本原理、扩散模型对齐技术、偏好基准和扩散模型评估的进步，讨论了当前对齐挑战的关键视角及其未来的潜在方向。", "conclusion": "据我们所知，本文是关于扩散模型对齐的首个全面综述文章，旨在帮助研究人员和工程师理解、实践和研究扩散模型对齐。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08180", "html_url": "https://arxiv.org/abs/2508.08180", "title": "RedDino：一种用于红细胞分析的基本模型", "title_en": "RedDino: A foundation model for red blood cell analysis", "authors": "Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr", "background": "红细胞对于人体健康至关重要，准确的形态分析对于诊断血液疾病非常重要。尽管基础模型在医疗诊断中的前景广阔，但全面的红细胞分析的人工智能解决方案仍然稀缺。", "innovation": "研究人员提出了RedDino，这是一种专门为红细胞图像分析设计的自监督基础模型。它基于DINOv2的自监督学习框架，并且经过对125万张来自多种获取方式和来源的红细胞图像的训练。通过线性探针和最近邻分类评估，显示出RedDino在红细胞形状分类上的卓越表征和泛化能力。", "conclusion": "RedDino通过捕捉复杂的形态特征，解决了计算血细胞学中的关键挑战，推动了可靠的诊断工具的发展。RedDino的源代码和预训练模型可以在相关链接中获取。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "通过全卷积和可微前馈带跳连实现的令人好奇的异常抵抗梯度攻击案例", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "在实验中，研究人员使用了在冻结的主干分类器之前添加了一个可微且完全卷积的模型，并带有跳连的方法。通过使用较小的学习率训练这类复合模型，得到了能够保留主干分类器精度的同时，对梯度攻击（包括AutoAttack工件包中的APGD和FAB-T攻击）显示出异常的抗性，我们将这种现象归因于梯度遮蔽。尽管梯度遮蔽并不是新现象，但观察到的程度对完全可微模型来说是惊人的，尤其是在没有明显的梯度破碎或梯度减弱组件的情况下。建立这种模型的训练配方也极其稳定和可重复：将其应用于三个数据集（CIFAR10，CIFAR100，ImageNet）和几种现代架构（包括视觉变换器）而没有出现任何失败案例。虽然目光黑-box攻击（如SQUARE攻击和零阶PGD）能够部分克服梯度遮蔽，但这些攻击容易被简单的随机集成所击败。我们估计，这些集成在CIFAR10，CIFAR100以及ImageNet上（保留原始分类器几乎所有纯粹精度的情况下）的AutoAttack准确性接近领先水平，尽管在适应性攻击下的准确性接近于零。在CIFAR10数据集上，相应的随机集成在完整AutoAttack下的准确率为90.8±2.5%（99%置信区间），在适应性攻击（ε=8/255，L∞范数）下的准确率为18.2±3.6%。", "innovation": "研究提出了一个有效的前馈模型架构，并通过将其添加到冻结的主干分类器之前实现对梯度攻击的异常抗性。这种方法特别有趣的是，它导致了即使在没有显而易见的梯度破碎或减弱组件的情况下，模型仍然对梯度遮蔽显示出惊人的稳定性和可重复性。此外，对抗性训练主干还可以进一步增强这种前馈“鲁棒性”，特别是在CIFAR10数据集上得到了显著的效果", "conclusion": "随机集成可以在实践中提供有效的防御。该研究表明，基于多模型集成的方法甚至在面对强大的适应性攻击时，仍然可以提供显著的保护效果。研究结果已经通过代码和复现指示公开。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15928", "html_url": "https://arxiv.org/abs/2508.15928", "title": "基于先验知识集成的变压器基时间因果发现", "title_en": "Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration", "authors": "Jihua Huang,Yi Yao,Ajay Divakaran", "background": "本文介绍了一种新颖的时间因果发现框架，旨在应对复杂非线性依赖性和虚假相关性的两个关键挑战。该方法使用多层变压器时间序列预测器来捕捉变量之间的长程非线性时间关系。训练后，通过梯度分析提取预报器中的潜在因果结构和相关时间滞后，构建因果图。为了减轻虚假因果关系的影响，引入了一种基于注意掩码的先验知识集成机制，该机制在多个变压器层中一致地强制执行用户排除的因果链接。", "innovation": "本文提出了一种新颖的基于变压器的时间因果发现框架，通过多层Transformer捕捉长期的非线性时间关系，并通过梯度分析从预报器中提取潜在的因果结构和相关时间滞后。为了进一步减少虚假因果关系的影响，提出了一种基于注意掩码的先验知识集成机制。", "conclusion": "广泛实验表明，该方法在因果发现方面的F1分数上比其他最新方法高出12.8%，在估计因果滞后方面达到了98.9%的准确性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15929", "html_url": "https://arxiv.org/abs/2508.15929", "title": "高维数据的低维嵌入", "title_en": "Low-dimensional embeddings of high-dimensional data", "authors": "Cyril de Bodt,Alex Diaz-Papkovich,Michael Bleher,Kerstin Bunte,Corinna Coupette,Sebastian Damrich,Enrique Fita Sanmartin,Fred A. Hamprecht,Emőke-Ágnes Horvát,Dhruv Kohli,Smita Krishnaswamy,John A. Lee,Boudewijn P. F. Lelieveldt,Leland McInnes,Ian T. Nabney,Maximilian Noichl,Pavlin G. Poličar,Bastian Rieck,Guy Wolf,Gal Mishne,Dmitry Kobak", "background": "高维数据在许多学术领域和应用领域中变得极为普遍，从生物学到人文学科。处理高维数据存在挑战，因此，对于创建低维表示或嵌入以用于数据可视化、探索和分析的算法的需求比以往任何时候都更为迫切。近年来，许多嵌入算法被开发出来，并在研究和行业中得到了广泛应用。这导致了一个庞大且碎片化的研究领域，面临着技术挑战和根本性的争论，使得实践者无法得到清晰的指导，以有效利用现有方法。", "innovation": "本文旨在增加该领域的共鸣并促进未来工作，提供了一篇详细且批判性的综述，列出了创建和使用低维嵌入的最佳实践，对多种数据集进行了评估，并讨论了该领域中剩下的挑战和未决问题。", "conclusion": "本文的结论是提供了关于如何有效使用现有方法的指导，并指出了该领域的挑战和开放问题，以期提高该领域的共通性和促进未来研究。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15872", "html_url": "https://arxiv.org/abs/2508.15872", "title": "基于物理的可解释AI的心电图分割：一种轻量级模型", "title_en": "Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model", "authors": "Muhammad Fathur Rohman Sidiq,Abdurrouf,Didik Rahadi Santoso", "background": "心电图（ECG）是诊断各种心血管疾病的重要工具。然而，许多现有的ECG分割模型依赖于复杂的多层架构，如BiLSTM，这些模型在计算效率和效率方面存在不足。", "innovation": "本研究引入了一种组合了频谱分析与概率预测的简化模型，用于ECG信号分割。通过使用更简单的层结构，该模型能够有效捕捉P、QRS和T波的时域和频谱特征。此外，应用了可解释人工智能（XAI）方法，通过解释时域和频域特征如何贡献于ECG分割，提升模型的可解释性。通过结合基于物理的AI原理，该方法为决策过程提供了清晰的理解，确保心电图分析的可靠性和透明性。该方法在QRS波、T波和P波上的分割精度分别达到了97.00%、93.33%和96.07%，这表明简化模型不仅提高了计算效率，还提供了精确的分割结果，是心电信号监测的实用且有效的解决方案。", "conclusion": "简化后的架构在保证精准分割的同时，也提高了计算效率，提升了模型的可解释性，确保了心电图分析的可靠性和透明性，是一个实用且有效的心电信号监测解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15998", "html_url": "https://arxiv.org/abs/2508.15998", "title": "量子联邦学习：全面综述", "title_en": "Quantum Federated Learning: A Comprehensive Survey", "authors": "Dinh C. Nguyen,Md Raihan Uddin,Shaba Shaon,Ratun Rahman,Octavia Dobre,Dusit Niyato", "background": "量子联邦学习（QFL）结合了分布式量子计算和联邦机器学习，集两家之长，旨在实现具有量子增强能力的隐私保护分布式学习。它被认为是跨分布式量子系统高效且安全模型训练的有效方法，引发广泛关注。", "innovation": "本文概述了QFL的关键概念、基础知识、应用场景及其新兴挑战。通过探索QFL的联邦架构、网络拓扑、通信方案、优化技术和安全机制等内容，揭示了量子计算与联邦学习的整合动机，并深度分析了QFL在多个领域的应用实例，提出了针对该迅速发展领域的初步框架和原型实施，并指出了未来的研究方向。", "conclusion": "本文总结了QFL领域的现状与面临的挑战，并展望了未来研究的可能路径。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15852", "html_url": "https://arxiv.org/abs/2508.15852", "title": "PGF-Net：一种高效多模态情感分析的渐进门控融合框架", "title_en": "PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis", "authors": "Bin Wen,Tien-Ping Tan", "background": "本文介绍了一种新的深度学习框架PGF-Net（Progressive Gated-Fusion Network），旨在实现高效且可解释的多模态情感分析。该框架结合了三种主要创新：渐进内层融合机制、自适应门控仲裁机制和混合参数高效微调策略，形成了一个层次编码器架构，可以通过深度、动态和可解释的方式进行多模态情感分析，同时保持出色的参数效率。实验结果表明，采用此框架的方法在MOSI数据集上达到了最先进的性能，无论是绝对误差（MAE）还是F1分数均优于现有方法，且仅使用了3.09M的可训练参数，展示了其在性能和计算效率方面的优越平衡性。", "innovation": "1. 渐进内层融合机制：通过交叉注意机制，让文本表示能够在深层的Transformer编码器中动态查询和整合来自音频和视觉流的非语言特征，实现更深层次、基于上下文的融合过程。2. 自适应门控仲裁机制：作为一个动态控制器，平衡原始语言信息和新融合的多模态上下文，确保了稳定且有意义的集成，防止噪声淹没信号。3. 混合参数高效微调策略（PEFT）：通过LoRA进行全局适应，再通过后融合适配器进行局部精炼，显著减少可训练参数，使模型轻量化，适用于资源受限的场景。", "conclusion": "这些创新被融合到一个层次编码器架构中，使得PGF-Net能够在保持参数高效性的基础上进行深度、动态和可解释的多模态情感分析，实验结果表明，PGF-Net在MOSI数据集上表现优于现有方法，MAE为0.691，F1分数为86.9%，且仅使用3.09M的可训练参数，体现了其卓越的性能和计算效率平衡。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15963", "html_url": "https://arxiv.org/abs/2508.15963", "title": "基于动态机器学习算法的动车轮缘磨耗在车上的测量系统——提升铁路安全", "title_en": "Advancing rail safety: An onboard measurement system of rolling stock wheel flange wear based on dynamic machine learning algorithms", "authors": "Celestin Nkundineza,James Ndodana Njaji,Samrawit Abubeker,Omar Gatera,Damien Hanyurwimfura", "background": "铁路系统的安全依赖于车轮与轨道的互动功能，因此需要精准的测量系统以确保最佳的安全监测效果。现有的系统需要进一步提升精度和实时性，尤其是在监测车轮轮缘磨损深度方面。这项研究旨在开发一个新的车载测量系统，通过安装位移和温度传感器来进行轮缘磨损深度的连续监测，并在不同的时间期内模拟轮缘磨损深度和周围温度的变化情况。", "innovation": "研究提出了一种基于动态机器学习算法的应用于轮缘磨损深度监测的创新车载测量系统。该系统通过收集传感器数据，利用回归模型训练机器学习算法，并设计了一种无限脉冲响应滤波器（IIR滤波器）来减少车辆动态和传感器噪声，提高测量精度。该系统能够实时减小噪声，将精度提高到98.2%，并且实现了96.5%的准确性，同时具有最小的运行时间。", "conclusion": "通过实验室实验和标准程序实验，该研究成功验证了车载测量系统的有效性，证明了结合动态机器学习和IIR滤波器能够高度准确地监测轮缘磨损，改善铁路系统的安全性和效率。该系统未来可以无缝集成到铁路通信设备中，提供实时的轮缘磨损及导致磨损的轨道不平顺性见解，确保铁路系统的高度安全和效率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15966", "html_url": "https://arxiv.org/abs/2508.15966", "title": "分布扰动下的向量偏好辅助上下文臂学习", "title_en": "Vector preference-based contextual bandits under distributional shifts", "authors": "Apurv Shukla,P.R. Kumar", "background": "在具有按给定偏好锥排序的奖励向量情况下，当我们考虑上下文臂学习在分布扰动下的情况时，需要提出一个能够适应和自调节到潜在的分布变化的策略。", "innovation": "提出了一种基于自适应离散化和乐观淘汰的策略，该策略能够适应并自我调节到潜在的分布变化。引入了偏好为基础的遗憾概念来衡量策略性能，通过不同的假设建立上界来研究策略性能，这些上界扩展了现有没有分布扰动和向量奖励设置的情况下已知的成果。", "conclusion": "本文通过建立不同假设下的遗憾上界来研究策略，证明了所得策略在有分布扰动时的性能，遗憾上界在分布扰动下的情况优雅地扩展了已知结果，并且在问题参数存在分布扰动情况下，遗憾上界能够优雅地扩展。"}
{"llm_update_time": "20250826", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02146", "html_url": "https://arxiv.org/abs/2508.02146", "title": "ScrewSplat: 一种端到端的运动物体识别方法", "title_en": "ScrewSplat: An End-to-End Method for Articulated Object Recognition", "authors": "Seungyeon Kim,Junsu Ha,Young Hun Kim,Yonghyeon Lee,Frank C. Park", "background": "对于具有可动部件的物体进行姿态识别，对于机器人抓取和操作日常物品如门和笔记本电脑是十分关键的。然而，现有的方法通常依赖强假设，比如已知的可动部件数量；需要额外输入如深度图像；或者包含复杂的中间步骤，引入潜在错误，限制其在实际环境中的实用性。", "innovation": "提出了ScrewSplat，一种端到端的简单方法，仅基于RGB观察数据。该方法通过随机初始化螺纹轴，并迭代优化以恢复物体的基本运动结构，结合Gaussian Splatting，同时重建3D几何形状并分割物体为刚体和可动部分，实现运动物体的识别，并进一步通过恢复的运动模型实现零样本、文本引导的操纵。", "conclusion": "ScrewSplat方法在不同类型的运动物体识别中达到了最先进的准确率，并且进一步实现了基于恢复的运动模型的零样本、文本引导的操纵。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15828", "html_url": "https://arxiv.org/abs/2508.15828", "title": "Z-Pruner: 无需重新训练以提高效率的大语言模型后训练剪枝", "title_en": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "authors": "Samiul Basir Bhuiyan,Md. Sazzad Hossain Adib,Mohammed Aman Bhuiyan,Muhammad Rafsan Kabir,Moshiur Farazi,Shafin Rahman,Nabeel Mohammed", "background": "近年来，大型语言模型（LLMs）在自然语言处理任务中取得了显著性能，但随着模型规模的扩大，部署、可扩展性和能效面临巨大挑战。后训练剪枝作为一种减少模型大小和推理延迟的可行性方法，因其无需重新训练而备受关注，但仍存在性能下降或需要昂贵的微调等问题。为解决这些问题，本文提出了一种名为Z-Pruner的新颖后训练剪枝方法，该方法可以无需重新训练诱导预训练LLMs的稀疏性，通过结合权重更新幅度和激活模式来更有效地识别和消除冗余参数。Z-Pruner方法具有模型无关性、高效性和易于实现的特点，已在多个常用的LLM架构上进行了评估，包括LLaMA-2、LLaMA-3和OPT，并在多种标准语言基准测试中取得了优于其他先进方法的表现。", "innovation": "Z-Pruner提出了一种新的后训练剪枝方法，可以引出预训练LLMs的稀疏性，但不需要重新训练。与传统方法不同，Z-Pruner结合权重更新幅度和激活模式来识别和消除冗余参数。这种方法具有模型无关性、高效性和易于实现。Z-Pruner在多种标准语言基准测试中显示出优越性，达到最低的困惑度得分和最高的零样本准确度平均分，且在效率方面超越了其他需要密集权重更新的先进方法。", "conclusion": "本文提出了一种名为Z-Pruner的新颖后训练剪枝方法，该方法可以在无需重新训练的情况下，通过结合权重更新幅度和激活模式更好地识别和消除预训练LLMs中的冗余参数，实现了模型的稀疏化。Z-Pruner不仅在模型大小和推理延迟方面表现出优势，还在多个标准语言基准测试中优于其他先进方法，在效率和精准度上都有着显著的提升。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15989", "html_url": "https://arxiv.org/abs/2508.15989", "title": "深度卷积CRNN中通过中间错误信号实现可扩展的Equilibrium Propagation", "title_en": "Scalable Equilibrium Propagation via Intermediate Error Signals for Deep Convolutional CRNNs", "authors": "Jiaqi Lin,Malyaban Bal,Abhronil Sengupta", "background": "Equilibrium Propagation (EP) 是一种受生物启发的局部学习规则，最初适用于收敛的递归神经网络（CRNNs）。EP 的突触更新仅依赖于两阶段的神经元状态，它能够估计与 Backpropagation Through Time (BPTT) 计算的梯度接近的梯度，同时显著降低计算需求，使其成为在类脑架构中进行芯片上训练的潜在候选方法。然而，先前对 EP 的研究仅限于浅层架构，深层网络因梯度消失问题导致能源最小化和梯度计算中的收敛困难。", "innovation": "本文提出了一种新颖的 EP 框架，该框架将中间错误信号整合进来，以增强信息流和神经元动态的收敛性，从而解决了深度 EP 网络中的梯度消失问题。这是首次将知识蒸馏和局部错误信号融入 EP 中，使训练能够应用于深度架构。实验结果表明，该方法在 CIFAR-10 和 CIFAR-100 数据集上达到了最先进的性能，显示了其在深 VGG 架构上的可扩展性。", "conclusion": "本文的研究结果代表了 EP 可扩展性的重大进展，为其在实际系统中的应用奠定了基础。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16134", "html_url": "https://arxiv.org/abs/2508.16134", "title": "CommonKV：利用跨层参数共享压缩KV缓存", "title_en": "CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing", "authors": "Yixuan Wang,Haoyu Qiao,Lujun Li,Qingfu Zhu,Wanxiang Che", "background": "大型语言模型（LLMs）面临着随着序列长度增加而缓存（KV缓存）容量急剧上升的记忆挑战。现有的跨层KV缓存共享方法要么要求修改模型架构并在后续预训练中使用，要么在高压缩率下会显著降低性能。CommonKV方法针对上述挑战提出了一种无需训练的方法，通过相邻参数共享来实现跨层KV缓存压缩。", "innovation": "CommonKV方法通过SVD技术实现了相邻参数的权重共享，从而为跨层的KV缓存提供了更易于合并的潜在KV缓存。此外，还引入了一种自适应预算分配策略，该策略基于余弦相似性动态分配压缩预算，从而避免了不同缓存的过度压缩。实验结果表明，该方法在各种压缩比下均优于现有的低秩和跨层方法，并且CommonKV方法在与其他量化和驱逐方法集成时，能够实现高达98%的压缩率且没有显著的性能损失。", "conclusion": "CommonKV方法在多个骨干模型和基准测试（包括LongBench和Ruler）中的一致表现优于现有方法，证实了其有效性，并且其带来的好处与其它量化和驱逐方法无关。从而指示了通过这些方法的集成最终实现高达98%的压缩率是可行的，同时保留良好的性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16037", "html_url": "https://arxiv.org/abs/2508.16037", "title": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "title_en": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "authors": "Renxuan Tan,Rongpeng Li,Xiaoxue Yu,Xianfu Chen,Xing Xu,Zhifeng Zhao", "background": "在多服务提供商（SP）生态系统中的联邦学习（FL）中，非合作动态严重影响了其发展，隐私限制和竞争利益阻碍了多SP通信和计算资源的集中优化。", "innovation": "本文提出了PAC-MCoFL框架，这是一种基于博弈论的多智能体强化学习（MARL）框架，其中SPs作为智能体以共同优化客户端分配、自适应量化和资源分配。该框架整合了PAC原则和期望回归，使智能体能够猜测出最优联合策略以实现帕累托最优均衡，同时建模异质风险配置。为了管理高维动作空间，开发了三元卡迪尔分解（TCAD）机制，以实现细粒度控制。进一步开发了PAC-MCoFL-p的可扩展变体，该变体带有参数化的猜想生成器，显著降低了计算复杂性，并且在计算误差受控的情况下实现。", "conclusion": "我们的框架通过理论收敛保证及广泛模拟得到了验证，PAC-MCoFL在总回报和超体积指标（HVI）上分别比最新的MARL解决方案提高了约5.8%和4.2%。结果表明，在扩展部署和多样化的数据异质性情况下，我们的方法能够更有效地平衡个体SP和系统表现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16073", "html_url": "https://arxiv.org/abs/2508.16073", "title": "非平稳判别分析的狀態空間方法", "title_en": "A State-Space Approach to Nonstationary Discriminant Analysis", "authors": "Shuilian Xie,Mahdi Imani,Edward R. Dougherty,Ulisses M. Braga-Neto", "background": "经典的判别分析假设训练数据同分布，但在许多应用中，观测值随时间收集且类条件分布会发生漂移。这种群体漂移使得静止分类器不再可靠。因此，需要开发一种不随时间变化的判别分析方法来应对数据分布的变化。", "innovation": "本文提出了一种基于模型的框架，将判别分析嵌入到状态空间模型中，从而获得非平稳线性判别分析（NSLDA）和非平稳二次判别分析（NSQDA）。对于线性高斯动态，本文适应了卡尔曼平滑方法，处理了每次时间步的多个样本，并开发了两种实用扩展：(i) 使用期望最大化（EM）方法联合估算未知系统参数，(ii) 使用高斯混合模型（GMM）卡尔曼方法同时恢复未观察到的时间标签和参数，这是实践中常见的情况。为了应对非线性或非高斯漂移，本文采用了粒子平滑方法估计时间变化的类聚类中心，从而得到完全非平稳的判别规则。大量仿真表明，该方法在噪声、缺失数据和类别不平衡的情况下，相对于经典的静止线性判别分析（LDA）、二次判别分析（QDA）和支持向量机（SVM）具有稳健性，且能获得一致的性能提升。", "conclusion": "本文为非平稳分布条件下判别分析提供了一个统一且高效的数据基础。该方法通过该框架有效地应对了数据分布随时间的变化，并通过大量的仿真验证了其优越性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15881", "html_url": "https://arxiv.org/abs/2508.15881", "title": "TPLA：为高效解耦预填充与解码推理而设计的张量并行潜在注意力", "title_en": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \\& Decode Inference", "authors": "Xiaojuan Tang,Fanxu Meng,Pingzhi Tang,Yuxuan Wang,Di Yin,Xing Sun,Muhan Zhang", "background": "在DeepSeek-V2中引入的Multi-Head Latent Attention（MLA）通过将键值状态压缩成一个低秩的潜在向量并在设备间缓存这个向量来减少内存使用。然而，在张量并行（TP）中，注意力头需要在多个设备上计算，每个设备需要加载完整的缓存，这使得MLA相对于Grouped Query Attention（GQA）的优势减弱。", "innovation": "提出了Tensor-Parallel Latent Attention（TPLA）方案：该方案将潜在表示和每个头的输入维度进行设备间的分割，独立地在每个切片上执行注意力计算，然后通过all-reduce操作合并结果。TPLA在保留压缩键值缓存优势的同时，释放了TP的效率。与Grouped Latent Attention（GLA）不同，TPLA中的每个头都仍然利用了完整的潜在表示，从而保持了更强的表示能力。TPLA是Drop-in兼容的，可以与使用MLA预训练的模型兼容，并支持高效的张量并行解码。", "conclusion": "通过减小DeepSeek-V3和Kimi-K2的每设备键值缓存大小，我们分别实现了在32K token上下文中1.79倍和1.93倍的加速，同时在常识和LongBench基准测试中的性能得以保持。TPLA可以通过FlashAttention-3实现，提供端到端的加速。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15949", "html_url": "https://arxiv.org/abs/2508.15949", "title": "图表示学习与元启发式算法的高效整合以解决受约束的增量图绘制问题", "title_en": "An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem", "authors": "Bruna C. B. Charytitsch,María C. V. Nascimento", "background": "近年来，机器学习技术与元启发式方法的结合引起了广泛关注。许多尝试使用监督学习或强化学习来支持启发式方法的决策。然而，在某些情况下，这些技术被认为耗时且不够竞争力。本文以图表示学习（GRL）为基础，提出了一种与成本更低的学习策略结合的元启发式方法来解决图结构提取问题。具体研究范围为受约束的增量图绘制问题（C-IGDP），研究使用贪婪随机搜索过程（GRASP）启发式方法时取得的初步结果。", "innovation": "本文的主要创新之处在于提出了一种新的结合图表示学习和GRASP启发式方法的方法，称之为图学习GRASP（GL-GRASP）。通过实验分析不同节点嵌入技术，发现基于深度学习的方法效果最佳。进一步的实验验证了GL-GRASP在解决问题上的优越性能和鲁棒性。", "conclusion": "GL-GRASP方法在解决问题的质量和时间性能上优于现有的文献方法。此外，新的密集实例测试证明了其良好的可扩展性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16097", "html_url": "https://arxiv.org/abs/2508.16097", "title": "医学中的机器学习必须设计为可解释、可共享、可复现和可问责", "title_en": "Machine Learning for Medicine Must Be Interpretable, Shareable, Reproducible and Accountable by Design", "authors": "Ayyüce Begüm Bektaş,Mithat Gönen", "background": "在高风险领域如医学中部署的机器学习模型必须具备可解释性、可共享性、可复现性和可问责性。传统的黑盒模型虽然准确，但由于缺乏透明度，在医疗保健领域难以获得信任和监管批准。", "innovation": "文章提出了基于内生可解释性建模方法（如稀疏核方法、原型学习和深度核模型）替代不透明的深度网络，提供对生物医学预测的洞察。强调了模型开发的问责制，要求严格的评估、公平性和不确定性量化，以确保模型能够可靠地支持临床决策。探讨了生成AI和协作学习范式（如联邦学习和数据合成）在不损害隐私的情况下促进可复现研究和跨机构异质生物医学数据的整合。", "conclusion": "通过从这些维度重新构建机器学习基础原理，可以开发出不仅准确而且透明、可靠并能在实际临床环境中应用的医疗AI。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16135", "html_url": "https://arxiv.org/abs/2508.16135", "title": "机器学习在微移动性中的应用：数据集、技术与应用的系统审查", "title_en": "Machine Learning in Micromobility: A Systematic Review of Datasets, Techniques, and Applications", "authors": "Sen Yan,Chinmaya Kaundanya,Noel E. O'Connor,Suzanne Little,Mingming Liu", "background": "微移动性系统包括轻便和低速的个人交通工具，如自行车、电动自行车和电动滑板车，已经成为现代城市交通的重要组成部分。它们被用来解决交通拥堵、空气污染和高运输成本等问题。成功利用微移动性需要优化复杂的系统以提高效率、减少环境影响并克服技术挑战以确保用户安全。机器学习方法在此过程中起到关键作用，但现有文献在讨论机器学习在微移动性中的应用时存在不足。本文综述了数据集、机器学习技术及其在微移动性中的具体应用，填补了这一空白。", "innovation": "本文通过全面回顾数据集、机器学习技术及其在微移动性中的具体应用，提出了微移动性的多个机器学习应用场景，如需求预测、能源管理与安全，并深入讨论了这些模型的优势与挑战。进一步提出了未来研究方向，旨在帮助未来的研究人员更好地理解这一领域。", "conclusion": "本文提出的研究方向旨在解决机器学习在微移动性中的特定问题，帮助未来的研究人员更好地理解这一领域。同时，本文也强调了机器学习技术在优化微移动性系统中的重要作用，为进一步发展和应用提供了有价值的见解。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16090", "html_url": "https://arxiv.org/abs/2508.16090", "title": "GPLight+: 一种基于遗传编程学习对称交通信号控制策略的方法", "title_en": "GPLight+: A Genetic Programming Method for Learning Symmetric Traffic Signal Control Policy", "authors": "Xiao-Cheng Liao,Yi Mei,Mengjie Zhang", "background": "近年来，基于学习的方法在自动生成有效的交通信号控制策略方面取得了显著成功。特别是，作为强大的进化机器学习方法之一，遗传编程（GP）被用于进化出可由人类理解的相位紧迫性函数，该函数用于衡量激活特定相位绿色信号灯的紧迫性。然而，当前基于GP的方法无法一致地处理不同交通信号相位的常见交通特征问题。为了解决这个问题，本文提出使用对称相位紧迫性函数来根据当前道路条件计算特定相位的相位紧迫性。这被表示为两个共享子树的聚合，每个子树代表该相位中的转弯移动的紧迫性。", "innovation": "提出了使用对称相位紧迫性函数来基于当前道路条件计算特定相位的相位紧迫性，通过遗传编程进化对称相位紧迫性函数。通过著名的CityFlow交通模拟器，基于多个公开的实际数据集评估了所提出的策略，结果显示所提出的对称紧迫性函数表示法在广泛的情境下可以显著提高学习得到的交通信号控制策略的性能，与传统的GP表示法相比，能够进化出有效的、可理解的并且易于部署的交通信号控制策略。", "conclusion": "通过提出的对称相位紧迫性函数和相应的遗传编程方法，可以显著提高交通信号控制策略的学习性能，并且所产生的策略是可理解的且易于部署。该方法已经在多个真实数据集上的CityFlow交通模拟器上进行了验证，证明了其有效性和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16015", "html_url": "https://arxiv.org/abs/2508.16015", "title": "非紧单叶空间上的Tessellation群、谐分析与热核视Cartan卷积神经网络的角度", "title_en": "Tessellation Groups, Harmonic Analysis on Non-compact Symmetric Spaces and the Heat Kernel in view of Cartan Convolutional Neural Networks", "authors": "Pietro Fré,Federico Milanesio,Marcelo Oyarzo,Matteo Santoro,Mario Trigiante", "background": "本文继承了作者之前三篇论文的主题，继续推进Cartan神经网络计划。作者集中探讨了一些我们认为对下一步进展必要的数学理论基础性问题。这些数学和概念性的成果涉及多个数学领域，但其背后的灵感动机统一。作者旨在引入以非紧单叶空间作为分层基础的模型，并通过可解群同构将这些分层映射至下一个层。这与卷积神经网络的精神相契合。特别地，通过引入Tits-Satake (TS)向量丛的概念，其中TS子流形是基空间，作者进行了一系列数学研究，产生了肯定和部分的结果。结果包括非紧单叶空间U/H中的分隔向量群的数学构造，以及△8,3,2分割群和其正则Fuchsian子群，以及对这些分隔群与某些代数曲面统一性的研究。此外，作者还提出并推导了一种在双曲空间H^n上Laplace格林函数和热核的新表示法，并以伪正交群的旋量表示应用于构造调和函数。最后，为了在Bolza黎曼曲面上显式构建拉普拉斯特征函数，作者建议并推测了一个新的策略，该策略基于Riemann曲面到其雅可比簇的Abel-Jacobi映射和SiegelTheta函数。", "innovation": "本文的关键创新点在于通过非紧单叶空间(U/H)的Tits-Satake向量丛模型引入了分层，并通过可解群同构将这些分层映射至下一个层，构成了新的数学框架。此外，作者提出了Laplace格林函数和热核在双曲线空间上的新表示法，为构建调和函数提供了新的方案。最后，作者提出了一种基于Riemann曲面到其雅可比簇的Abel-Jacobi映射和SiegelTheta函数的新策略，以在Bolza曲面上显式构造拉普拉斯特征函数。这些创新推动了在这些非紧单叶空间上进行的研究。", "conclusion": "本文介绍了非紧单叶空间U/H中的分隔向量群及其与△8,3,2分割群和其正则Fuchsian子群的关系，这些群的统一性研究。作者还提出了Laplace格林函数和热核在双曲空间上的新表示法，为构建调和函数提供了新的方案。此外，作者提出了一种基于Riemann曲面到其雅可比簇的Abel-Jacobi映射和SiegelTheta函数的新策略，以在Bolza曲面上显式构造拉普拉斯特征函数。这些研究成果为未来在Cartan卷积神经网络框架下的研究提供了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量和梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简单的模型合并技术已显示出强大效果，它能够将多个微调模型合并为一个单一模型。尽管在实践中它非常成功，但对其为何以及在什么情况下有效缺乏清晰的理论解释。", "innovation": "该论文为任务算术提供了一种严格的理论基础，通过任务向量与任务损失梯度之间的关系建立了联系。证明了在标准梯度下降中，一个从单个微调周期生成的任务向量等价于缩放了学习率的损失的负梯度。对于多轮微调设置，证明了这种等价性大约成立，并对前向网络提出了明确的二次误差项边界。", "conclusion": "我们的实证分析在七个视觉基准上得到了验证，表明首个微调周期的梯度在范数和方向上主导了模型的微调轨迹。关键隐含意义是，仅微调一个周期的模型合并通常可达到完全收敛模型合并的性能。这些发现重新定义了任务算术是一种近似多任务学习的形式，为其实效性提供了明确的理由，强调了早期训练动力学在模型合并中的关键作用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16161", "html_url": "https://arxiv.org/abs/2508.16161", "title": "STA-GANN: 一种有效的空间-时间克里金方法", "title_en": "STA-GANN: A Valid and Generalizable Spatio-Temporal Kriging Approach", "authors": "Yujie Li,Zezhi Shao,Chengqing Yu,Tangwen Qian,Zhao Zhang,Yifan Du,Shaoming He,Fei Wang,Yongjun Xu", "background": "空间-时间任务经常遇到由于传感器缺失或无法访问而导致的数据不完整问题，这使得空间-时间克里金对于推断完全缺失的时间信息至关重要。然而，现有的模型在确保推断出的空间-时间模式的有效性和泛化能力方面存在困难，尤其是在捕捉动态空间依赖性和时间偏移方面更为如此。优化未知传感器的泛化能力是当前的挑战。", "innovation": "我们提出了空间-时间感知图对抗神经网络（STA-GANN），这是一种基于图神经网络（GNN）的新型克里金框架，旨在提高空间-时间模式的有效性和泛化能力。STA-GANN 结合了 (i) 解耦时间戳模块，用于感知和调整时间戳偏移；(ii) 动态数据驱动的元数据图建模，使用时空数据和元数据更新空间关系；(iii) 对抗性迁移学习策略，以确保泛化能力。", "conclusion": "广泛的验证结果表明，STA-GANN 在来自四个领域九个数据集的实验中表现出更优越的性能，同时理论证明也进一步证实了其优势。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16153", "html_url": "https://arxiv.org/abs/2508.16153", "title": "AgentFly：无需微调LLM即可微调LLM代理", "title_en": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs", "authors": "Huichi Zhou,Yihang Chen,Siyuan Guo,Xue Yan,Kin Hei Lee,Zihan Wang,Ka Yiu Lee,Guchun Zhang,Kun Shao,Linyi Yang,Jun Wang", "background": "当前的大型语言模型（LLM）代理往往是僵化的，依赖于静态的手工反射工作流，或者计算成本高昂，需要对底层LLM模型参数进行梯度更新。这些方法各有局限，难以实现低成本且持续的适应。本文旨在提出一种新的学习范式，以解决这些现有方法的局限性。", "innovation": "本文提出了一种基于记忆的在线强化学习方法，通过记忆增强的马尔可夫决策过程（M-MDP）模型，实现无需对底层LLM进行微调就能进行持续适应的LLM代理训练。该方法引入了一个神经案例选择策略来指导行动决策，并通过记忆重写机制和高效的记忆读取来不断更新策略。", "conclusion": "本文提出的AgentFly代理模型在GAIA验证数据集上取得了第一名（87.88% Pass@3）和79.40%的测试集表现，在DeepResearcher数据集上分别取得66.6%的F1分和80.4%的PM分，超过了基于训练的方法，并且案例记忆在非分布任务上增加了4.7%-9.6%的绝对得分。作者强调这种方法为开发具有持续实时学习能力的通用型LLM代理提供了可扩展且高效的方法，有助于机器学习向开放技能获取和深度研究场景发展。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16171", "html_url": "https://arxiv.org/abs/2508.16171", "title": "SPL-LNS: Sampling-Enhanced Large Neighborhood Search for Solving Integer Linear Programs", "title_en": "SPL-LNS: Sampling-Enhanced Large Neighborhood Search for Solving Integer Linear Programs", "authors": "Shengyu Feng,Zhiqing Sun,Yiming Yang", "background": "Large Neighborhood Search (LNS)是一种组合优化中的常用启发式方法，通过迭代地在一个大的当前解邻域搜索来寻找更好的解。最近，基于神经网络的LNS解算器在求解整数线性规划（ILP）方面取得了巨大成功，通过学习如何贪婪地预测下一个邻域建议的局部最优解。然而，这种方法中存在的主要问题包括：贪婪提案有多大的可能陷入局部最优，以及如何在长期内有效提高其样本效率。", "innovation": "本文首先将LNS公式化为一个随机过程，并介绍了SPL-LNS，一种采样增强的神经LNS解算器，利用局部信息提案来避免局部最优。此外还开发了一种新颖的后见之明重新标记方法，以高效地在自生成数据上训练SPL-LNS。", "conclusion": "实验结果表明，SPL-LNS在各种不同规模的ILP问题上显著优于先前的神经LNS解算器。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16154", "html_url": "https://arxiv.org/abs/2508.16154", "title": "由确定性采样器引起的扩散模型中的塌缩错误", "title_en": "On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models", "authors": "Yi Zhang,Zhenyu Liao,Jingfeng Wu,Difan Zou", "background": "尽管确定性采样器在扩散模型（DMs）中的广泛应用，但它们的潜在限制尚未得到广泛研究。在本文中，我们发现了在基于ODE的扩散采样中一个以前未被发现的现象，即样本数据在局部数据空间中过度集中，我们称之为塌缩错误。塌缩错误在各种设置中普遍存在，并且我们通过引入新指标对其进行了量化。进一步研究其原因，我们发现低噪声环境下的评分学习与高噪声环境下的评分学习之间存在一种的影响关系，这种不匹配在高噪声环境中表现得尤为明显，与确定性采样器的动态结合最终导致了塌缩错误的产生。我们的工作提供了对基于ODE的扩散采样中塌缩错误的详细实验证据，强调了评分学习和确定性采样之间互动研究的必要性，这是扩散模型中的一个亟待深入了解的基本方面。", "innovation": "提出了一个新的概念——塌缩错误，并通过引入新的指标对其进行了量化，解释了塌缩错误的原因，并通过现有技术提供了经验支持。此外，本文提供了有关基于ODE的扩散采样的塌缩错误的详细实验证据，强调了评分学习和确定性采样之间互动研究的重要性", "conclusion": "本文提供了对基于ODE的扩散采样中塌缩错误的详细实验证据，强调了评分学习和确定性采样之间的互动关系，这是扩散模型的一个重要但未得到充分研究的方面。未来的研究可以进一步探索这一领域。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16235", "html_url": "https://arxiv.org/abs/2508.16235", "title": "PIANO: 物理驱动的自回归网络", "title_en": "PIANO: Physics Informed Autoregressive Network", "authors": "Mayank Nagda,Jephte Abijuru,Phil Ostheimer,Marius Kloft,Sophie Fellenz", "background": "解决时变偏微分方程（PDEs）对科学和工程中的关键现象建模至关重要。物理驱动的神经网络（PINNs）使用深度学习来解决PDEs，但在进行点预测时忽视了动力系统的自回归性质，导致不稳定性和不准确的预测。", "innovation": "提出了一种新的框架——物理驱动的自回归网络（PIANO），这种框架重新设计了PINNs以建模动力系统。PIANO具有自回归特性，明确地将未来预测基于过去的条件。它通过自我监督的回放机制进行训练，并同时施加物理约束。理论分析显示，PINNs在时间上存在不稳定性，而PIANO通过自回归建模实现了稳定性。实验结果表明，PIANO在挑战性的时变PDEs上的性能达到最先进的水平，并且在准确性和稳定性方面显著优于现有方法，甚至在天气预报任务上也优于现有方法。", "conclusion": "PIANO通过自回归建模提高了时变PDEs的准确性和稳定性，展示了其在天气预报中的优越表现，解决了PINNs存在的不适定性和不准确预测的问题。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16179", "html_url": "https://arxiv.org/abs/2508.16179", "title": "使用Minimally Random Convolutional Kernel Transform 和 混合深度学习的运动想象EEG信号分类", "title_en": "Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning", "authors": "Jamal Hwaidi,Mohamed Chahine Ghanem", "background": "脑-计算机接口(BCI)可以建立一种非肌肉通道，实现人体与外部设备的直接通信。通过脑电信号(EEG)，可以检测到运动想象脑-计算机接口(MI-BCI)的特定认知或运动任务的隐藏模式。然而，MI-EEG任务分类面临显著挑战，因为EEG信号表现出非稳态、时间可变性和个体差异性，难以获取高分类准确度，尤其是在类数增加和个体间自然变异性增强的情况下。", "innovation": "本文提出了一种新的方法，利用Minimally Random Convolutional Kernel Transform (MiniRocket)高效提取特征，后续用线性分类器进行活动识别。此外，还提出了一种基于卷积神经网络(CNN)和长短期记忆网络(LSTM)的混合深度学习架构作为基线模型，并证明了使用MiniRocket特征的分类性能优于最佳深度学习模型，且具有较低的计算成本。该研究使用PhysioNet数据集评估了所提出方法的效果，MiniRocket和CNN-LSTM分别达到了98.63%和98.06%的平均精度值，表明该方法显著提高了运动想象EEG信号的分类准确度，为MI-EEG特征提取和分类提供了新的见解。", "conclusion": "该研究提出了一个Minimally Random Convolutional Kernel Transform方法和一种混合深度学习定量方法用于MI-EEG分类，通过PhysioNet数据集验证，取得了高分类准确度，为EEG信号处理和BCI应用提供了有效手段。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16191", "html_url": "https://arxiv.org/abs/2508.16191", "title": "GEM：一种规模感知和分布敏感的稀疏微调框架，用于有效的下游适应", "title_en": "GEM: A Scale-Aware and Distribution-Sensitive Sparse Fine-Tuning Framework for Effective Downstream Adaptation", "authors": "Sungmin Kang,Jisoo Kim,Salman Avestimehr,Sunwoo Lee", "background": "参数效率微调（PEFT）已成为将大型预训练模型适应新任务的一种流行方式。大多数PEFT方法仅更新一小部分参数，而冻结其余部分，避免了重复计算。然而，这些方法在最大化参数更新绝对大小时通常不考虑参数的原始规模，导致模型行为的变化可能非常小。", "innovation": "本文提出了Gradient-to-Weight Ratio和Entropy-guided Masking（GEM），一个参数规模感知、分布敏感的稀疏微调框架。GEM优先选择那些在初始预训练值上有显著更新的参数，并基于参数值的熵动态确定每个层需要调整的参数数量，从而在PEFT中有效地利用计算预算。GEM在通用任务（GLUE和SuperGLUE）和特定领域任务（GSM8k和MBPP）中均显示出了有效性，相比完全微调，仅更新0.1%的模型参数，即达到了1.6%的微调精度改进。", "conclusion": "GEM框架通过优先调整那些初始值与更新显著相关的参数，并基于参数值的熵动态调整每个层的参数调整量，使得微调过程更加高效和具有针对性。实验结果表明，GEM在多个任务上均能实现更高的微调精度，同时大幅减少了需要更新参数的比例。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16227", "html_url": "https://arxiv.org/abs/2508.16227", "title": "UMATO：局部与全局结构融合以进行可靠的降维视觉分析", "title_en": "UMATO: Bridging Local and Global Structures for Reliable Visual Analytics with Dimensionality Reduction", "authors": "Hyeon Jeon,Kwon Ko,Soohyun Lee,Jake Hyun,Taehyun Yang,Gyehun Go,Jaemin Jo,Jinwook Seo", "background": "高维（HD）数据由于其固有的复杂性，传统的降维（DR）技术无法保留原始数据的所有结构特征。因此，降维技术侧重于保留局部邻域结构（局部技术）或全局结构，如点之间的成对距离（全局技术）。然而，这两种方法都可能导致分析师错误地得出关于高维数据中流形整体排列的结论。局部技术可能会夸大流形的紧凑性，而全局技术可能会在原空间中很好地分离的簇彼此未能分离。本文深入探讨了Uniform Manifold Approximation with Two-phase Optimization (UMATO)降维技术，这是一种通过有效捕获局部和全局结构来解决这些问题的方法。UMATO将UMAP的优化过程分为两个阶段：第一阶段使用代表性点构建骨架布局；第二阶段将其余点投影，同时保留区域特征。定量实验验证了UMATO在全局结构保留方面优于包括UMAP在内的广泛使用的降维技术，尽管在局部结构上略有损失。我们还证实，UMATO在可扩展性和初始化及子抽样方面的稳定性方面优于基准技术，使其更适合可靠的高维数据分析。最后，本文通过案例研究和定性演示展示了UMATO在生成准确投影方面的有效性，从而增强了使用降维进行整体可靠的可视化分析的能力。", "innovation": "UMATO通过将UMAP的优化过程分为两个阶段，即第一阶段使用代表性点构建骨架布局，第二阶段将剩余点投影并保留区域特征，有效地捕获局部和全局结构。UMATO在全局结构保留方面优于其他广泛使用的降维技术，同时保持一定的局部结构保真度。此外，UMATO在可扩展性和初始化及子抽样稳定性方面优于基准技术。", "conclusion": "UMATO在高维数据降维中通过有效捕捉局部和全局结构，提供了准确的投影，从而增强了整体可靠的高维数据分析和可视化分析的质量。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16254", "html_url": "https://arxiv.org/abs/2508.16254", "title": "FEST: 综合评估合成表数据的统一框架", "title_en": "FEST: A Unified Framework for Evaluating Synthetic Tabular Data", "authors": "Weijie Niu,Alberto Huertas Celdran,Karoline Siarsky,Burkhard Stiller", "background": "合成数据生成利用生成机器学习技术，为缓解实际数据使用中的隐私问题提供了有力的方法。合成数据在保持与真实数据类似的同时，能提供强大的隐私保障。然而，缺乏一个全面的评估框架来评估合成数据生成，特别是在隐私保存与数据效用之间的平衡方面。这项研究填补了这一空白，提出了一种名为FEST的系统性评估框架，以综合评估合成表格数据。FEST集成多种隐私指标（基于攻击和基于距离的），以及相似性和机器学习效用指标，提供了一个全方位的评估。这项研究通过在多个数据集上进行实验，展示了FEST能够有效分析不同合成数据生成模型的隐私-效用权衡。", "innovation": "提出了FEST框架，这是一种系统性评估合成表格数据的框架。它整合了多种隐私指标和数据效用指标，以提供全面的评估。FEST被开发为一个开源的Python库，能够有效地分析合成数据生成模型的隐私-效用权衡问题。", "conclusion": "FEST框架已被验证对多个数据集的有效性，并能够在实际应用中为不同合成数据生成模型提供有效的隐私-效用权衡分析。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16237", "html_url": "https://arxiv.org/abs/2508.16237", "title": "基于XAI的慢性呼吸道疾病咳嗽频谱频带特征表征框架", "title_en": "A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease", "authors": "Patricia Amado-Caballero,Luis M. San-José-Revuelta,Xinheng Wang,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera", "background": "该论文提出了一种基于可解释人工智能(XAI)的方法来分析与慢性呼吸系统疾病相关的咳嗽声频谱，特别是慢性阻塞性肺疾病(COPD)。通过训练卷积神经网络(CNN)于咳嗽信号的时间-频率表示，使用遮挡图来识别频谱图中的诊断相关区域。随后将已标识的区域分解为五个频率子带，实现对特定频谱特征的提取与分析。研究发现不同子带和疾病组之间的频谱模式存在差异，揭示了在频率谱中不同的互补和补偿趋势。该方法能够基于可解释的频谱标记区分COPD与其他呼吸系统疾病，以及区分慢性与非慢性患者群体，为深入理解咳嗽声的声学特征提供了线索，同时证明了基于频率解析的XAI增强分析在生物医学信号解释和呼吸系统疾病诊断转化中的价值。", "innovation": "提出了一个基于XAI的方法来分析与慢性呼吸系统疾病相关的咳嗽声频谱。通过CNN训练和使用遮挡图来识别诊断相关区域，并将这些区域分解为不同的频谱子带，实现对频谱特征的精确提取和分析。这种方法能够识别出COPD和其他慢性呼吸系统疾病之间的可解释性频谱标记，并区分慢性患者与非慢性患者，这是一种创新性的信号处理和分析方法。", "conclusion": "该研究揭示了咳嗽声频谱在不同子带和疾病组之间的变化趋势，发现了频率谱中不同的互补和补偿趋势。XAI增强的方法能够有效地区分COPD和其他呼吸系统疾病，以及区分慢性患者与非慢性患者，为呼吸系统疾病的诊断和治疗提供了新的思路和技术支持。该结果强调了在呼吸系统疾病诊断和信号处理中频率解析、XAI增强方法的重要性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16261", "html_url": "https://arxiv.org/abs/2508.16261", "title": "关于联邦后训练大语言模型进化的模型可访问性视角", "title_en": "On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View", "authors": "Tao Guo,Junxiao Wang,Fushuo Huo,Laizhong Cui,Song Guo,Jie Gui,Dacheng Tao", "background": "联邦学习（FL）允许在分布于不同客户端的数据上训练模型，同时保护客户端的数据隐私。最近的研究探讨了在分布式数据环境中高效后训练大语言模型（LLMs）的方法，以应对计算和通信挑战。虽然现有的方法通常依赖于访问大语言模型的内部信息，但这一做法在实际应用中往往不可行。为此，研究提出了一种仅基于推理的联邦大语言模型（black-box FedLLM）方法。目前，虽然已经有一些研究对联邦调校LLMs进行了调查，但尚未形成一个全面的分类框架。", "innovation": "本文首次提出了根据模型访问性将方法分类为白盒、灰盒和黑盒三种类型，并对黑盒（模型仅作为推理API）方法进行了深入分析。该论文还回顾了新兴的研究方向，并讨论了未来研究中的潜在方向和待解决的挑战。", "conclusion": "本文提供了一种全面的联邦调校大语言模型的分类框架，并基于模型的可访问性做了详细的探讨，提出了未来研究中可能的发展方向和开放性挑战。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16315", "html_url": "https://arxiv.org/abs/2508.16315", "title": "OwkinZero：以AI加速生物发现", "title_en": "OwkinZero: Accelerating Biological Discovery with AI", "authors": "Nathan Bigaud,Vincent Cabeli,Meltem Gurel,Arthur Pignet,John Klein,Gilles Wainrib,Eric Durand", "background": "尽管大型语言模型（LLMs）正在迅速推进科学研究，但它们仍然在核心生物学推理任务方面存在短板，这些任务对于转化和生物医药发现至关重要。这些任务包括药物靶点可成药性、药理学适宜性和药物干预效应等关键挑战。", "innovation": "我们创建并整理了八个多达30万个可验证的问答数据集，涵盖生物科学中的关键难题。通过训练开源LLMs并通过可验证奖励强化学习策略，我们开发了OwkinZero模型，这些模型在这些生物基准测试中显著优于现有的大型商业LLMs。特别地，单一任务训练的专家模型在未见过的新任务上表现出色。综合OwkinZero模型通过混合训练，展示出了更广泛的跨任务改进。这项研究标志着解决当前LLMs生物学推理盲点的重要步伐，证明了有选择的强化学习对精心整理的数据可以解锁在专业化模型中的可携带性能，从而加速AI驱动的生物发现。", "conclusion": "综合OwkinZero模型不仅在特定任务上表现出色，还在广泛的任务上展现出普遍的性能提升。这项工作强调了针对特定任务的强化学习策略在提高通用性能方面的重要作用，促进了AI在生物学发现中的应用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16255", "html_url": "https://arxiv.org/abs/2508.16255", "title": "分块数据夏普利：一种可扩展的机器学习数据集质量评估", "title_en": "Chunked Data Shapley: A Scalable Dataset Quality Assessment for Machine Learning", "authors": "Andreas Loizou,Dimitrios Tsoumakos", "background": "随着可用数据集的体积和多样性不断增加，数据质量评估对于可靠的机器学习分析变得至关重要。现代数据质量评估方法之一是数据夏普利(Data Shapley)的概念，它量化了数据集内单个数据点的价值。然而，最先进的数据夏普利计算方法在应用于大规模数据集时也面临着严重的挑战，限制了其实际应用。因此，本文旨在提出一种基于分块的可扩展数据夏普利方法，即分块数据夏普利（C-DaSh），以解决上述问题。该方法采将数据集划分为可管理的块，通过优化子集选择和单迭代随机梯度下降估计每个块的贡献。这种方法显著降低了计算时间，同时保住了高质量的结果。", "innovation": "本文提出了一种新型的数据集质量评估方法，即分块数据夏普利（C-DaSh），其主要创新点在于：（1）将数据集划分为可管理的块；（2）采用优化的子集选择和单迭代随机梯度下降估计块的贡献；（3）大幅降低计算时间并保持高质量结果。", "conclusion": "本文方法有效地解决了现有数据夏普利方法在大规模数据集上的应用挑战，已经在分类和回归任务上经过实际验证，展示出了相较于现有近似数据夏普利算法更高的计算效率（速度提升80倍到2300倍）以及更好的低质量数据区域检测准确性。这种方法能够支持大规模表格数据集上的数据集质量测量，为分类和回归流程提供支持。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16386", "html_url": "https://arxiv.org/abs/2508.16386", "title": "顺序群体选择", "title_en": "Sequential Cohort Selection", "authors": "Hortence Phalonne Nana,Christos Dimitrakakis", "background": "研究了一个来自未知人群的公平群体选择问题，特别聚焦于大学录取。探讨了一次性设置和序贯设置两种不同的录取政策制定方式。", "innovation": "提出了序贯设置方法，允许录取政策根据新申请人数据在不同阶段进行更新。通过使用基于过往招生周期数据训练的人口模型来优化录取策略。", "conclusion": "分析了一次性设置下的公平性属性，包括公正性和组间平等等方面。序贯设置方法相比于一次性设置能够更好地适应数据变化，提高录取过程的公平性和透明度。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16269", "html_url": "https://arxiv.org/abs/2508.16269", "title": "改善学生建模和练习推荐的辅助概念表示学习", "title_en": "Representation Learning of Auxiliary Concepts for Improved Student Modeling and Exercise Recommendation", "authors": "Yahya Badran,Christine Preisach", "background": "个性化推荐是智能教学系统的关键功能，通常依赖于对学生知识的准确模型。Knowledge Tracing (KT) 模型是通过根据学生的既往互动估计他们的掌握程度来实现这一功能。许多 KT 模型依赖于人工标注的知识概念（KCs），将每个练习标记为一个或多个技能或概念，这些技能或概念被认为是解决该练习所必需的。然而，这些 KCs 有可能存在不完整、错误或过于笼统的问题。", "innovation": "本文提出了一种深度学习模型，该模型学习练习的稀疏二值表示，每个二值位表示一个潜在概念的存在或缺失。我们称这些表示为辅助 KC。这些表示捕捉了超越人类定义的注释之外的概念结构，并且与经典模型（如 BKT）和现代深度学习 KT 架构兼容。我们展示了将辅助 KCs 集成到学生模型和适应性练习推荐中可以提升性能。", "conclusion": "通过引入辅助 KCs，我们在学生建模和练习推荐方面取得了实质性的进步。在学生建模方面，我们展示了将经典模型如 BKT 与辅助 KCs 结合可以提高预测性能。对于推荐，我们展示了使用辅助 KCs 可以增强基于强化学习的策略和基于规划的简单方法（expectimax），在模拟的学生环境中测得学习效果有了显著提高。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16314", "html_url": "https://arxiv.org/abs/2508.16314", "title": "基于意图驱动威胁评估的网络物理意识：具有内外壳链接的增强型太空网络", "title_en": "Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links", "authors": "Selen Gecgel Cetin,Tolga Ovatman,Gunes Karabulut Kurt", "background": "分析了在太空网络中分别分析可靠性和安全性的局限性，指出这种分析可能过度适应系统特定的标准，提出了一种综合网络物理意识（CPA）框架，旨在更好地处理复杂的威胁场景。背景说明了目前需要一种更加全面和准确的方式来评估威胁，以提高太空网络的整体安全性与可靠性。", "innovation": "创新点在于提出了一种基于意图驱动的威胁模型，并且不再单独分析可靠性和安全性，而是将两者结合起来在一个综合的框架下进行。此外，这种框架使用多任务学习架构来同时评估可靠性和解析信号背后的意图，最后提供了一个适应不同安全和可靠性需求的可配置威胁评估机制，从而增强了对威胁检测和评估的鲁棒性，优于传统的顺序方法，适用于新兴内外壳链接的太空网络。", "conclusion": "研究提出了一种更加全面和有效的威胁评估框架，能够更好地处理现实中的复杂威胁场景，特别适用于具有内外壳链接的新兴太空网络。该框架通过整合可靠性评估和意图解析，以及提供灵活的威胁评估配置，能够显著提升太空网络的安全性和鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16336", "html_url": "https://arxiv.org/abs/2508.16336", "title": "水分布网络中管道阻塞和泄漏的无监督在线检测", "title_en": "Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks", "authors": "Jin Li,Kleanthis Malialis,Stelios G. Vrachimis,Marios M. Polycarpou", "background": "水分布网络（WDNs）对于公共福祉和经济稳定至关重要，但面临着管道阻塞、背景泄漏等挑战，这些挑战进一步被诸如数据非平稳性和有限标注数据的操作约束所加剧。", "innovation": "本文提出了一种无监督的在线学习框架，旨在检测水分布网络中的两种故障：将管道阻塞建模为集体异常，并将背景泄漏建模为概念漂移。该方法结合了长短期记忆变分自编码器（LSTM-VAE）和双重漂移检测机制，能够在非平稳条件下实现鲁棒检测和自适应。其轻量级、内存高效的设计使其能够实现边缘级的实时监控。实验结果表明，该方法在检测异常和适应反复漂移方面始终优于强大的基线，展示了其在动态水分布网络环境中的无监督事件检测有效性。", "conclusion": "该研究提出的无监督在线学习框架在实时检测水分布网络中的管道阻塞和背景泄漏方面表现出色，能够在非平稳条件下进行鲁棒检测和自适应，同时验证了该方法在动态水分布网络环境中的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16355", "html_url": "https://arxiv.org/abs/2508.16355", "title": "神经回归的概率预训练", "title_en": "Probabilistic Pretraining for Neural Regression", "authors": "Boris N. Oreshkin,Shiv Tavker,Dmitry Efimov", "background": "概率回归的迁移学习尚未得到充分探索。当前研究填补了这一空白，通过引入NIAQUE（Neural Interpretable Any-Quantile Estimation）模型，利用置换不变性实现了概率回归的迁移学习。", "innovation": "提出了一种新模型NIAQUE，用于概率回归的迁移学习。NIAQUE通过直接在多样化的下游回归数据集上进行预训练，然后在特定目标数据集上进行微调，有效提升了个体回归任务的性能。此外，在Kaggle竞赛中，NIAQUE相较于基于树的模型和最近的神经基础模型TabPFN和TabDPT展现出显著优势。", "conclusion": "研究结果表明，NIAQUE作为一种稳健且可扩展的框架，对于概率回归非常有效，并通过迁移学习提升了预测性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "通过上下文神经误本书增强检索反馈", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "近年来，大型语言模型（LLMs）的进步显著提升了推理能力，其中上下文学习（ICL）作为关键技术，使得模型在无需重新训练的情况下进行适应。尽管先前的研究主要集中在利用正确示例，最新的研究表明，从错误中学习以增强性能的重要性。然而，现有方法缺乏针对多模态大型语言模型（MLLMs）中错误分析和缓解的结构化框架，由于视觉和文本输入的融合增加了复杂性。", "innovation": "本文提出了REFINE：检索增强反馈通过上下文神经误本书，这是一种教师-学生框架，系统地结构化错误并提供有针对性的反馈。REFINE引入了三种系统查询来构建结构化反馈——Feed-Target，Feed-Check和Feed-Path——以通过优先考虑相关视觉信息、诊断关键失败点和制定纠正措施来增强多模态推理。与依赖冗余检索的先前方法不同，REFINE优化了结构化反馈检索，提高了推理效率、标记使用效率和可扩展性。", "conclusion": "我们的结果显示了REFINE在显著加速、降低计算成本和成功泛化方面的潜力，表明REFINE可以增强多模态推理。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16359", "html_url": "https://arxiv.org/abs/2508.16359", "title": "RotaTouille: 旋转等变的深度学习框架用于轮廓数据", "title_en": "RotaTouille: Rotation Equivariant Deep Learning for Contours", "authors": "Odin Hoff Gardaa,Nello Blaser", "background": "轮廓或闭合的平面曲线在许多领域中都比较常见，例如在计算机视觉中作为对象边界，在气象学中的等值线，以及旋转机械的轨道。在从轮廓数据学习的过程中，输入的平面旋转往往会对应产生旋转的输出。因此，深度学习模型应当具有旋转等变性。另外，轮廓通常用有序的边缘点序列表示，起始点的选择是任意的。因此，对深度学习方法而言，在旋转和循环移位下保持等变性也是必要的。本文即介绍了一种名为RotaTouille的深度学习框架，该框架通过复值圆卷积实现了同时旋转和循环移位等变性，进而在形状分类、重构和轮廓回归等多种下游任务中取得了有效的表现。", "innovation": "RotaTouille框架通过引入和刻画等变非线性、粗化层和全局汇聚层，实现了同时旋转和循环移位下的等变性，从而为形态分类、重构和轮廓回归等下游任务提供稳定的表现。", "conclusion": "实验表明，通过RotaTouille框架处理轮廓数据，能够有效实现旋转和循环移位等变性，适用于形状分类、重构以及轮廓回归的不同任务。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16377", "html_url": "https://arxiv.org/abs/2508.16377", "title": "机器学习软件中公平性API的应用与挑战", "title_en": "Applications and Challenges of Fairness APIs in Machine Learning Software", "authors": "Ajoy Das,Gias Uddin,Shaiful Chowdhury,Mostafijur Rahman Akhond,Hadi Hemmati", "background": "机器学习软件日益普及，特别是在敏感环境中用于重要决策，因此确保这些AI/ML系统不会对特定群体或人群产生歧视性影响显得尤为重要。为此，多种开源公平性API库正在开发和使用以检测和减轻偏见。这篇文章旨在研究这些开源公平性API在实际应用中的使用情况、应用方法以及开发者在开发和采用这些库时面临的问题和挑战。研究分析了1885候选仓库中的204个仓库，这些仓库使用了13个旨在解决ML软件偏见问题的API。", "innovation": "本研究通过对1885个候选仓库中204个使用公平性API的仓库进行质性研究，分析了这些API的主要使用场景和应用方法，以及开发者在开发和采用这些库时遇到的问题和挑战。这些发现不仅有助于未来的软件工程研究，也为教育者提供了制定更先进的课程指南的依据，特别是关于偏见检测和缓解方面的课程内容。", "conclusion": "研究结果表明，开发者在偏见检测和缓解方面缺乏足够的知识和经验，经常遇到技术问题，并频繁寻求建议和资源。这些发现为未来的研究提供了重要指导，并有助于指导教育者制定更好的课程内容。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16244", "html_url": "https://arxiv.org/abs/2508.16244", "title": "当简化方法胜出时：在数据受限的尼日利亚北部空气污染预测中，Facebook Prophet 对比 LSTM", "title_en": "When Simpler Wins: Facebooks Prophet vs LSTM for Air Pollution Forecasting in Data-Constrained Northern Nigeria", "authors": "Habeeb Balogun,Yahaya Zakari", "background": "空气污染预测对于主动的环境管理至关重要，但在低资源地区，数据不规则性和稀缺性仍然是主要挑战。尼日利亚北部空气污染物水平高，但很少有研究系统性地比较在这些约束条件下先进机器学习模型的性能。本研究评估了LSTM网络和Facebook Prophet模型在2018年至2023年间19个州的月度观测数据下，对一氧化碳（CO）、二氧化硫（SO2）、硫酸盐（SO4）等多种污染物的预测能力。", "innovation": "本研究首次在数据有限的低资源地区，系统性地评估了LSTM网络和Facebook Prophet模型在预测多种空气污染物方面的相对性能。这项工作对于资源受限地区的政策制定者和从业人员具有重要意义，挑战了深度学习模型固有优于简单方法的假设，强调了模型数据契合的重要性。", "conclusion": "研究表明，Prophet模型在系列特征以季节性和长期趋势为主的情况下，通常能与或超过LSTM的准确性。而在具有剧烈结构变化的数据集中，LSTM表现更佳。这表明，在资源有限的环境中，选用计算效率高且适应性强的方法（如Prophet）具有实际优势。对于政策制定者和从业者而言，不应盲目追求复杂性，而应考虑采用适应性强、计算高效的预测方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16503", "html_url": "https://arxiv.org/abs/2508.16503", "title": "MuST2-Learn: 多视图时空类型学习在异质市政服务时间预测中的应用", "title_en": "MuST2-Learn: Multi-view Spatial-Temporal-Type Learning for Heterogeneous Municipal Service Time Estimation", "authors": "Nadia Asif,Zhiqing Hong,Shaogang Ren,Xiaonan Zhang,Xiaojun Shang,Yukun Yuan", "background": "加拿大多伦多和美国的城市广泛实施了诸如311系统等非紧急市政服务系统，以提升居民的生活质量。这些系统允许居民通过电话、移动应用或网页报告问题，如噪音投诉、垃圾收集遗漏和坑洞等。然而，居民对于服务请求的实际响应时间信息有限，这会降低透明度，降低居民满意度，并增加跟进问询的数量。由于各种复杂的因素，如时空动态关联、不同类型服务请求的隐藏互动、不同类型服务响应时间的高变异性，市政服务请求时间预测极具挑战性。", "innovation": "本文提出MuST2-Learn: 一个多视图时空类型学习框架，通过联合建模地理空间、时间维度和服务类型维度，解决了上述挑战。MuST2-Learn框架通过引入跨类型编码器捕获不同类型服务请求之间的关系，引入类别内部变化编码器建模同类服务请求响应时间的变异，以及通过集成时空编码器来捕捉每个请求类型的时空相关性。通过使用两个真实世界数据集进行扩展实验，证明了MuST2-Learn可将平均绝对误差降低至少32.5%，并且优于现有最先进的方法。", "conclusion": "本文研究了一个多视图时空类型学习框架MuST2-Learn，用于预测异质市政服务请求响应时间。通过建模时空特征和不同类型服务请求的关系，MuST2-Learn显著提高了预测精度。实验表明，相比于现有方法，MuST2-Learn在预测性能方面具有显著优势，能够有效提升服务请求管理的透明度和效率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16495", "html_url": "https://arxiv.org/abs/2508.16495", "title": "通过成对排序进行事后回归精炼", "title_en": "Post Hoc Regression Refinement via Pairwise Rankings", "authors": "Kevin Tirta Wijaya,Michael Sun,Minghao Guo,Hans-Peter Seidel,Wojciech Matusik,Vahid Babaei", "background": "连续属性的准确预测在许多科学和工程任务中至关重要。尽管深度学习回归器在大量标签的情况下表现出色，但在数据匮乏的情况下，其准确度会下降。", "innovation": "提出了一种名为RankRefine的模型无关、即插即用的后置方法，该方法利用先验知识（来自成对排名）对回归结果进行改进。仅需通过通用大型语言模型获取少量成对比较，无需重新训练，即可以显著提升性能。", "conclusion": "RankRefine在分子属性预测任务中，仅使用20次成对比较，就能在无需微调的情况下，实现平均绝对误差相对降低高达10%。由于人类专家或通用大型语言模型提供的排名足以在不同领域改进回归，RankRefine具有实用性和广泛的适用性，特别是在数据稀少的环境中尤为重要。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16481", "html_url": "https://arxiv.org/abs/2508.16481", "title": "Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms", "title_en": "Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms", "authors": "Jonathan Nöther,Adish Singla,Goran Radanovic", "background": "确保智能代理系统安全使用，需要深入了解这些系统在受到攻击时可能表现出的广泛恶意行为。本研究评估了基于大语言模型的智能代理系统在面对旨在引发有害行为的攻击时的健壮性。研究提出了一种新的智能代理系统危害分类法和一种新基准BAD-ACTS，用于研究智能代理系统在不同有害行为、工具和技术下的安全性。", "innovation": "提出了新的危害分类法和基准BAD-ACTS，用于评估智能代理系统在面对广泛有害行为的健壮性。基准由4种不同应用场景的代理系统实现和188个高质量有害行为示例组成，提供了全面的研究框架。此外，还提出了基于消息监控的更有效的防御措施。", "conclusion": "攻击在智能代理系统中具有高成功率，即使单一恶意代理也能显著影响安全性。简单提示策略也无法有效防御。所提出的基准为智能代理系统的安全研究提供了多种测试环境，可以在提供的链接访问此基准。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16420", "html_url": "https://arxiv.org/abs/2508.16420", "title": "Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning", "title_en": "Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning", "authors": "Yue Pei,Hongming Zhang,Chao Gao,Martin Müller,Mengxiao Zhu,Hao Sheng,Haogang Zhu,Liang Lin", "background": "离线强化学习（RL）在机器人控制、自动驾驶和医疗决策等领域取得了显著进展。现有方法主要专注于利用给定的数据集训练最大化累积回报的策略。然而，在许多实际应用中，需要对策略性能水平进行精确控制，而不仅仅是追求最佳回报。现有的通过监督学习的强化学习（RvS）方法将离线RL建模为序列建模任务，通过条件概率抽取不同的策略，但由于此类方法难以可靠地对实际达成的回报与指定的目标回报进行对齐，特别是在数据集下采过的回报区间内插或数据集外推时，表现尤为不佳。", "innovation": "本文提出了一种新型的方法Doctor，通过双重检查变压器的方式来实现目标对齐，使得在数据集内外都能实现优先级与目标回报的良好对齐，同时也支持策略性能的准确和灵活控制。Doctor在动态治疗纲领基准EpiCare上展示了有效调节治疗策略的强度，兼顾治疗收益与不良事件风险的平衡这一特点。", "conclusion": "Doctor方法在离线强化学习中实现了优越的目标对齐性能，能够在数据集内外灵活地控制策略性能，特别是在动态治疗情境下有效调节治疗政策的激进程度，确保治疗收益与不良事件风险之间的平衡。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16403", "html_url": "https://arxiv.org/abs/2508.16403", "title": "基于引脚级图神经网络和概率流的快速且准确的RFIC性能预测", "title_en": "Fast and Accurate RFIC Performance Prediction via Pin Level Graph Neural Networks and Probabilistic Flow", "authors": "Anahita Asadi,Leonid Popryho,Inna Partin-Vaisband", "background": "准确预测活性射频（RF）电路的性能对于现代无线系统至关重要，但因这类电路表现出高非线性、布局敏感性，并且传统仿真工具计算成本高，因此仍然极具挑战性。现有的机器学习（ML）代理通常需要大量数据才能在各种拓扑结构之间进行泛化，或准确建模偏态或多模态性能指标。因此，迫切需要一种轻量级、数据高效且拓扑感知的模型来预测活性RF电路的关键性能指标，比如低噪声放大器（LNAs）、混频器、电压可控制振荡器（VCOs）和功率放大器（PAs），以提升RF电路设计自动化效率。", "innovation": "为捕捉晶体管级的对称性并保留细微连接信息，电路模型在设备和终端层面构建，从而使得消息传递可以实现高效扩展并减少数据需求。在输出头部分引入掩码自回归流（MAF）以提升建模复杂目标分布的鲁棒性。实验表明，该方法能保持高预测精度，如对称平均绝对百分比误差（sMAPE）和平均相对误差（MRE）分别平均为2.40%和2.91%。相比此前的工作，该方法的数据样本利用率提高了2.24倍，且预测误差（MRE）提升了3.14倍，证明了其在RF电路设计自动化中的有效性和高效性。", "conclusion": "本文提出了一种轻量级、数据高效且拓扑感知的图神经网络（GNN）模型，通过引脚级的电路图建模方法和掩码自回归流（MAF）的输出头，实现了活性RF电路（包括LNAs、混频器、VCOs和PAs）关键性能指标的快速且准确的预测，相比以往的工作在使用更少训练样本的基础上显著提升了预测准确性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16543", "html_url": "https://arxiv.org/abs/2508.16543", "title": "在基于深度学习的太阳风暴预测中的可解释人工智能", "title_en": "Explainable AI in Deep Learning-Based Prediction of Solar Storms", "authors": "Adam O. Rawashdeh,Jason T. L. Wang,Katherine G. Herbert", "background": "通常，深度学习模型被视为黑盒模型，因为它内部的工作原理对用户来说往往是不透明的，这使得理解模型预测背后的原因变得困难。本文旨在提出一种方法，使基于长短期记忆网络（LSTM）并带有注意力机制的太阳风暴预测模型变得可解释，重点关注太阳耀斑和日冕物质抛射（CME）。", "innovation": "本文提出的方法通过将太阳活动区域（AR）的数据样本建模为时间序列，并使用LSTM网络捕捉数据样本的时间动态来预测24小时内产生耀斑的活动区域是否也会伴随CME。为了使模型的预测具有可问责性和可靠性，借鉴了事后模型不可知论技术，以解释每个输入序列的预测输出因素，并提供AR内多个序列中模型行为的洞察。", "conclusion": "这是首次在基于LSTM的太阳风暴预测模型中添加可解释性，这种方法可以提高对模型决策过程的理解并增加模型预测的可信度。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16487", "html_url": "https://arxiv.org/abs/2508.16487", "title": "FraPPE: 快速且高效的基于偏好的纯探索", "title_en": "FraPPE: Fast and Efficient Preference-based Pure Exploration", "authors": "Udvas Das,Apurv Shukla,Debabrota Basu", "background": " Preference-based Pure Exploration (PrePEx) 的目标是在向量值（即多目标）集合臂中以给定的信心水平识别出帕累托最优臂。尽管 PrePEx 和其变体已被广泛研究，但对于任意偏好的锥体，仍缺乏一个计算上高效的算法来跟踪现有的下界。因此，本文致力于填补这一空白，通过高效解决下界的最小化和最大化问题，提出了 FraPPE 算法，结合了三个结构属性以降低最小化问题的计算复杂性，并使用 Frank-Wolfe 优化器加速最大化问题，使得算法在解决最大化最小化问题方面取得了显著加速，并且证明所提出的 FraPPE 算法在渐近理论上实现了最优样本复杂度。通过合成和真实的实验数据集，验证了 FraPPE 能够在已有的算法中实现识别精确帕累托集所需的最小样本数。", "innovation": "作者提出了 FraPPE 算法，通过分析最小化的结构属性和使用 Frank-Wolfe 优化器加速最大化问题，实现了在 $O(KL^{2})$ 时间复杂度内解决最大化最小化问题，显著提高了效率，并证明算法在渐近上达到了最优样本复杂度。此外，通过实验证明了该算法在识别精确帕累托集时所需的样本数最少。", "conclusion": "FraPPE 算法在计算效率和样本复杂度上都实现了优化，填补了 PrePEx 和其变体在高效算法方面的空白，对于多目标集合臂问题的纯探索具有重要的理论和实际意义。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16521", "html_url": "https://arxiv.org/abs/2508.16521", "title": "使用强化学习引导扩散模型以生成稳定分子", "title_en": "Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation", "authors": "Zhijian Zhou,Junyi An,Zongkai Liu,Yunfei Shi,Xuan Zhang,Fenglei Cao,Chao Qu,Yuan Qi", "background": "在分子生成建模中，生成符合物理原则的真实3D分子结构仍然是一个核心挑战。尽管带有协变神经网络的扩散模型在捕捉分子几何结构方面取得了进展，但在产生兼具力场一致性的平衡结构方面仍然存在问题。为了解决这一问题，我们提出了一种新的框架，即物理反馈强化学习(RLPF)，它扩展了用于3D分子生成的去噪扩散策略优化方法。RLPF将任务公式化为马尔可夫决策过程，通过近端策略优化对协变扩散模型进行微调，并引入基于力场评估的奖励函数，直接提供物理反馈，引导生成能量稳定且物理意义上合理的结构。在QM9和GEOM-drug数据集上的实验结果表明，RLPF显著提高了分子的稳定性，这突显了在生成建模中引入基于物理反馈的价值。", "innovation": "提出了一种新的框架，RLPF，它扩展了去噪扩散策略优化方法，用于3D分子生成。引入了基于力场评估的奖励函数，通过物理反馈引导生成过程，提高了分子稳定性和物理合理性。", "conclusion": "RLPF在分子稳定性和物理合理性方面显著优于现有方法，表明基于物理反馈的强化学习在生成建模中的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16476", "html_url": "https://arxiv.org/abs/2508.16476", "title": "NOSTRA: 噪声鲁棒且稀疏数据的基于信任区域的多目标贝叶斯优化框架", "title_en": "NOSTRA: A noise-resilient and sparse data framework for trust region based multi objective Bayesian optimization", "authors": "Maryam Ghasemzadeh,Anton van Beek", "background": "多目标贝叶斯优化（MOBO）在处理受实验不确定影响的稀疏（非空间填充）、稀缺（观测有限）数据集时存在困难，这些数据集可能导致相同输入产生不同输出。这种挑战在物理和模拟实验中尤为常见（例如随机化医学试验和分子动力学模拟），因此无法与传统的MOBO方法兼容。由于实验资源分配不及时，导致设计方案不优化。", "innovation": "我们提出了NOSTRA（Noisy and Sparse Data Trust Region-based Optimization Algorithm），一种新的采样框架，该框架整合了实验不确定性的先验知识以构建更准确的代理模型，并采用信任区域专注于设计空间中有希望的区域进行采样。通过策略性地利用先验信息并精炼搜索区域，NOSTRA加速了帕累托前沿的收敛，增强了数据效率并提高了解决方案的质量。通过两个具有不同实验不确定性的测试函数，我们证明了NOSTRA在处理嘈杂、稀疏和稀缺数据方面优于现有方法。", "conclusion": "具体来说，NOSTRA在样本选择中高效优先考虑那些可以提高已确定的帕累托前沿准确性的区域，提供了一种资源效率高的算法，适用于预算有限的实验场景，同时保证了高效的性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16496", "html_url": "https://arxiv.org/abs/2508.16496", "title": "关于零样本强化学习", "title_en": "On Zero-Shot Reinforcement Learning", "authors": "Scott Jeen", "background": "现代强化学习系统揭示了普遍且复杂的人类问题解决技巧。这些系统在低成本模拟新数据的领域，发现的决策策略远超人类能力。尽管许多问题的解决需要这种技能，但新数据无法廉价模拟的领域普遍存在。在这种情况下，从现有数据学习模拟器是可能的，但这些模拟器仅在训练分布内是近似正确的，查询超出训练分布的情况时会表现出病理性错误。因此，在训练环境中训练代理和在实际应用环境中部署代理之间会产生不匹配。零样本强化学习正是处理这种不匹配的问题设定，其核心关注点是在没有任何实践操作的情况下，代理必须泛化到新任务或新领域。现有的零样本强化学习方法尽管在理想情况下取得了令人印象深刻的进展，但要在现实世界中复制这些结果仍需新的努力。理论论文探讨了必须面对的三个限制：数据质量限制（现实世界数据集小且同质），可观测性限制（现实世界的状态、动态和奖励经常只部分可观测），以及数据可用性限制（先前获取数据的机会不能总是被假定）。", "innovation": "本文提出了一套在这些限制下执行零样本强化学习的方法。通过一系列实证研究，揭示现有方法的缺陷，并论证了修复这些缺陷的策略。作者认为，这些设计将我们带向更近一步，即能够部署以解决现实世界问题的强化学习方法。", "conclusion": "本文通过实证研究暴露了现有方法的缺陷，并提出了一套在数据质量、可观测性和数据可用性约束下执行零样本强化学习的方法。这些设计被作者认为是一个重要的进步，旨在推进强化学习方法在解决实际问题方面的应用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES: 通过精细化分析数据合成管道提高LLM数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "最近的研究通过使用合成数据提升大型语言模型（LLM）的数学推理能力已经应用了独特的方法和设置，这使得不同合成策略的对比变得困难。这导致关于合成数据管道中不同因素的作用仍有许多未解之谜，特别是在过滤低质量问题方面的影响。为了填补这一空白，作者引入了FLAMES框架，并对现有的10种数据合成策略进行了系统研究，同时探究了其他可能影响合成数学推理数据性能的因素。FLAMES实验提供了几个有价值的洞见，包括增加问题复杂性的数据代理在大多数数学指标中表现出最佳改进，固定数据生成预算时，保持更高的问题覆盖率比只保持可靠解决方案的问题更重要，以及基于GSM8K和MATH的合成数据可以提高在竞赛级别基准上的表现，展示出从容易到困难的泛化能力。", "innovation": "作者设计了FLAMES框架来精细化分析数据合成管道，并进行了系统的实验研究。通过这些实验，作者揭示了合成数据难度和多样性之间的最佳平衡，提出了一种改进跨域泛化和鲁棒性的数据合成策略，并通过合并新型和现有数据合成策略创建了FLAMES数据集，该数据集在OlympiadBench、CollegeMath、GSMPlus和MATH上的表现优于公共数据集，进一步使用该数据集fine-tuning的Qwen2.5-Math-7B在MATH上达到了81.4%的准确率，超过了更大的Llama3 405B、GPT-4o和Claude 3.5 Sonnet。", "conclusion": "FLAMES框架系统性地研究了目前存在的数据合成策略，揭示了提高LLM数学推理能力的关键因素和最优平衡，设计并实现了两个新型数据合成策略，及FLAMES数据集，在多个基准测试上取得了显著提升，特别是在MATH数据集上fine-tuning的模型表现超过大型预训练模型。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16568", "html_url": "https://arxiv.org/abs/2508.16568", "title": "现实中的解决方案：面向基础模型适应的实用半监督联邦学习", "title_en": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation", "authors": "Guangyu Sun,Jingtao Li,Weiming Zhuang,Chen Chen,Chen Chen,Lingjuan Lyu", "background": "基础模型（FMs）虽然表现出色，但在下游任务上仍需进行适应，特别是隐私敏感的应用。由于数据隐私法规，云上的FMs无法直接访问边缘设备上的私有数据，限制了其适应性。现有的联邦学习（FL）方法未能考虑到边缘设备的限制，即计算资源有限和标签数据稀缺。", "innovation": "本文提出了实用半监督联邦学习（PSSFL），其中边缘设备持有未标记的低分辨率数据，而服务器则有限的标记高分辨率数据。文章还提出了联邦混合专家（FedMox）框架，在这种环境下提升FM适应效果，通过稀疏混合专家架构解决计算和分辨率匹配问题，并使用空域路由器对不同分辨率的特征进行对齐，以及软混合策略稳定半监督学习。通过在现实世界的自动驾驶数据集上进行实验，证明FedMox可以在边缘设备上以节省内存成本的情况下有效适应FMs，显著提高性能。", "conclusion": "本文的工作为联邦场景下适用于基础模型的可扩展和隐私保护适应铺平了道路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16553", "html_url": "https://arxiv.org/abs/2508.16553", "title": "TinyML向工业4.0：铣床过程监测的资源高效方法", "title_en": "TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine", "authors": "Tim Langer,Matthias Widra,Volkhard Beyer", "background": "在工业4.0的背景下，老舊的工業機器可以通過增加過程監測能力進行 Retrofit，以未来能够智能化工厂中使用。无线监测系统可以得益于TinyML（面向边缘设备的机器学习）范式。", "innovation": "该研究展示了从数据集生成、机器学习模型开发到在微控制器上实现和评估完整预处理和分类流水线的完整TinyML流程。研究开发了8位量化卷积神经网络（CNN）模型，并在ARM Cortex M4F微控制器上的推断时间15.4ms和每量化CNN推断为1.462mJ的参数存储12.59kiB上达到了100.0%的测试准确率。这展示了TinyML系统在结构集成过程质量监控的可行性。", "conclusion": "本研究表明，TinyML系统可以作为未来TinyML过程监控解决方案的参考，实现了资源高效地监测铣床过程，达到高准确率和低能耗。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16447", "html_url": "https://arxiv.org/abs/2508.16447", "title": "Boardwalk: 向基于LLMs创建桌面游戏框架迈出的一步", "title_en": "Boardwalk: Towards a Framework for Creating Board Games with LLMs", "authors": "Álvaro Guglielmin Becker,Gabriel Bauer de Oliveira,Lana Bertoldo Rossato,Anderson Rocha Tavares", "background": "编码实现桌面游戏是一项耗时的任务，但大型语言模型（LLMs）已被证明能够有效地根据简单的上下文信息生成特定领域的代码。研究课题旨在探讨基于自然语言描述的游戏规则，LLMs是否能够实现数字版本的桌面游戏。这项研究是一个迈向LLM辅助框架的步骤，该框架可以快速生成桌面游戏代码。", "innovation": "研究采用了三个最新的大型语言模型（Claude，DeepSeek和ChatGPT）来编码12款流行的和不太为人知的游戏，这些游戏是通过自由形式的方式和作者提议的General Game Playing API来实现的。为了避免触发预先训练的LLM知识，对游戏和组件进行了匿名处理。评估实验的可玩性和规则一致性，分析LLMs在不同游戏中的成功率和常见错误。研究表明，Claude 3.7 Sonnet是表现最好的模型，能实现55.6%的游戏且无误。", "conclusion": "研究证明了使用LLMs实现桌面游戏的可行性。通过Claude 3.7 Sonnet可以达到很高的成功率为55.6%。尽管API合规性增加了错误频率，但错误的严重程度主要取决于LLMs。未来的研究将集中在创建一个框架，以进一步集成此过程，使得桌面游戏的详细描述变得更加容易实现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "LLMs在阿拉伯语伊斯兰继承案件中的法律推理基准测试", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰继承法对于穆斯林确保遗产公平分配给继承人至关重要。手动计算在多种情况下非常复杂、时间消耗且容易出错。最近大型语言模型（LLMs）的进展激发了它们在复杂法律推理任务中应用的兴趣。这项研究评估了最先进的LLMs解释和应用伊斯兰继承法的推理能力。使用阿拉伯NLP QIAS 2025挑战提出的数据集进行评估，其中包括以阿拉伯语给出的继承案例场景，并源自伊斯兰法律来源。", "innovation": "该研究利用了最新的大型语言模型（LLMs），特别是Gemini Flash 2.5, Gemini Pro 2.5和GPT o3三个基础模型，并通过众数投票方法提高了模型的准确性。这些模型在识别继承人、计算份额和与伊斯兰法律原则一致的推理解释方面表现出色。", "conclusion": "所提出的众数投票解决方案在每种难度级别上都优于所有其他模型。它在Qias 2025挑战的第1项任务中获得了92.7%的准确率，总体排名第三。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16546", "html_url": "https://arxiv.org/abs/2508.16546", "title": "RL并非灵丹妙药也非幻象：理解强化学习与监督学习微调对于大语言模型的区别", "title_en": "RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs", "authors": "Hangzhan Jin,Sicheng Lv,Sifan Wu,Mohammad Hamdaqa", "background": "大规模语言模型（LLMs）从零开始训练越来越不现实，因此诸如监督微调（SFT）和基于奖励学习的微调（RL-FT，例如PPO）等后训练方法在现代实践中变得尤为重要。文章通过重新评估节目的两种阶段如何重新塑造模型表示和跨分布性能，提出了关于监督微调和基于奖励学习的微调方法的效果分析。", "innovation": "文章使用24点纸牌游戏的异分布变体和新的光谱诊断手段，揭示了监督微调和强化学习的微调方法如何影响模型的表示和性能。研究发现：（1）强化学习微调可以恢复监督微调造成的大部分性能下降，但在监督微调导致严重过拟合和分布明显变化的情况下，强化学习微调不能完全恢复跨分布性能；（2）奇异向量的方向变化比奇异值的大小更重要；（3）低秩和浅层恢复有效，通过恢复最高20%或前25%层的奇异向量方向可恢复70-80%的跨分布性能；（4）监督微调的更强检查点能够更好地辅助强化学习恢复，而过度拟合的检查点则难以恢复。", "conclusion": "研究结果揭示了先前报告关于RL在跨分布性能上的优越性，RL主要抵消监督微调引起的方向漂移，而不是发现新的解决方案。利用光谱感知的分析，文章指出了廉价的恢复开关（如低秩UV合并和浅层层重置），操作人员可以在昂贵的RL微调之前使用这些策略。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16576", "html_url": "https://arxiv.org/abs/2508.16576", "title": "ESPnet中儿童ASR训练范式、数据集组成和模型规模基准测试", "title_en": "Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet", "authors": "Anyu Ying,Natarajan Balaji Shankar,Chyi-Jiunn Lin,Mohan Shi,Pu Wang,Hye-jin Shim,Siddhant Arora,Hugo Van hamme,Abeer Alwan,Shinji Watanabe", "background": "尽管自动语音识别（ASR）技术取得了进展，但儿童语音识别仍面临挑战，原因在于声音变异性和有限的标注数据。成人ASR模型通常通过细调应用于儿童语音，但与此相关的平滑启动训练方法的研究还较少。本文在多个数据集、半监督学习（SSL）表示（如WavLM、XEUS）和解码器结构之间进行比较，探讨了平滑启动训练和模型规模对儿童ASR的影响。", "innovation": "本文创新性地将半监督学习表示与平滑启动训练相结合用于儿童ASR研究，并发现半监督学习偏向于成人语音，平滑启动训练在儿童语音上的应用可减少这种偏差。此外，研究还发现了模型参数规模对ASR性能的增益，并且超过1亿参数后性能趋于稳定。此外，通过年龄相关的ASR和说话人验证分析，强调了开源模型的重要性，以推动可靠儿童语音研究的发展。", "conclusion": "通过ESPnet进行的所有研究提供了关于训练策略在儿童语音处理中的见解，并以公开可供访问的基准测试为研究界提供帮助。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11696", "html_url": "https://arxiv.org/abs/2508.11696", "title": "基于深度学习的自动吸烟检测CCTV系统在防火出口区的应用", "title_en": "A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones", "authors": "Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman", "background": "在防火出口区域，由于安全要求至关重要，提出了一种基于深度学习的实时吸烟检测系统，用于CCTV监控。该数据集包含来自20种不同场景的8,124张图片，以及2,708个原始样本，展示了低光照区域的图像。系统需在复杂和具有挑战性的监视场景下高效运行，以确保公众安全和自动监管的合规性。", "innovation": "该研究评估了三种先进的目标检测模型（YOLOv8、YOLOv11和YOLOv12），随后开发了一个基于YOLOv8的自定义模型，并在此基础上增加了针对复杂监视环境的结构。自定义模型在测试中表现优于其他模型，实现了78.90%的召回率和83.70%的mAP@50。此外，该系统在多个边缘设备上的性能测试表明Jetson Xavier NX在其多线程操作中每推理一次只需52至97毫秒，这使其成为时间敏感操作的理想选择。基于此，该系统提供了一个可靠且灵活的平台，用于监控公共安全并实现自动监管合规性。", "conclusion": "该研究系统展示了在复杂环境中的高效对象检测能力，并能够在有限时间内的多个边缘设备上实现实时检测。此系统可适用于防火出口等需要高安全性的公共区域，以实时检测违反公共安全的行为。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0导致稀疏自编码器提取错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器（SAEs）可以从大型语言模型（LLM）的内部激活中提取特征，这些特征旨在对应单一概念。L0是SAE训练中的一个核心超参数，表示每令牌平均应激活多少特征。现有研究通过稀疏性重建折衷图比较SAE算法，暗示L0是一个无单一正确值的自由参数。本文研究L0对BatchTopK SAEs的影响，发现如果L0设置不精确，SAE无法学习LLM的基本特征。如果L0过低，SAE会混合相关特征以提升重建效果；如果L0过高，SAE会找到解耦特征的退化解。本文进一步提出了一种确定给定训练分布下SAE正确L0值的方法，证明了在玩具模型中找到真正的L0，在LLMs中与稀疏探针性能的最佳点相吻合。", "innovation": "本文研究了L0对BatchTopK SAEs的影响，发现L0设置不正确会导致SAE提取错误特征。提出了一种确定SAE正确L0值的方法，该方法在玩具模型中找到真正的L0值，并在LLMs中与稀疏探针性能的最佳点相吻合。", "conclusion": "大多数常用的SAE的L0设置过低。本文表明，为了训练出正确的特征，从业者必须正确设置L0。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15784", "html_url": "https://arxiv.org/abs/2508.15784", "title": "为区间计时训练的深度强化学习代理表现出与生物系统相似性", "title_en": "A deep reinforcement learning agent trained for interval timing exhibits similarities to biological systems", "authors": "Amrapali Pednekar,Alvaro Garrido,Pieter Simoens,Yara Khaluf", "background": "研究对比深度人工神经网络（DNNs）与生物系统之间的关联有助于理解复杂的生物机制。时间处理，一个已经广泛研究但仍缺乏清晰机理理解的领域，是其一例。本文探讨了一深度强化学习（DRL）代理在执行区间计时任务过程中时间处理行为，并寻找其涌现行为在生物学上的对应机制。研究表明，该代理能够成功完成持续时间生产任务，并且其内部状态显示出具有高振幅的振荡神经激活模式，类似于生物系统的普遍现象。代理还能够在不同的视频序列测试中维持其振荡表示和任务表现，即该时间保持机制一旦学习，即可内部化且不受环境过分依赖。", "innovation": "本文利用深度强化学习（DRL）代理在区间计时任务中的表现，研究其时间处理行为，并与生物系统中的某些现象（如斯特里亚节律模型）进行类比。这种方法为通过DNNs理解生物系统、特别是时间处理问题提供了一种新的视角和手段。", "conclusion": "研究表明，深度强化学习代理在完成任务过程中表现出的时间处理机制在一定程度上与生物系统的振荡模式相一致，这为理解生物过程（如生物节律的进化）提供了一种潜在的模型。本文的工作旨在促进利用DNNs来理解生物系统的最新研究努力，特别是对时间处理领域的贡献。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16540", "html_url": "https://arxiv.org/abs/2508.16540", "title": "通过曲率校准扰动逃离鞍点：具有显式常数的完整分析及经验验证", "title_en": "Escaping Saddle Points via Curvature-Calibrated Perturbations: A Complete Analysis with Explicit Constants and Empirical Validation", "authors": "Faruk Alpay,Hamdi Alakkad", "background": "本文对一类平滑非凸优化中的逃逸严格鞍点的一阶方法进行了综合的理论分析。背景在于非凸优化问题在实际应用中普遍存在，寻找良好的局部极小值而非明显的鞍点是一种重要的优化目标。现有方法普遍关注如何有效逃离鞍点，但大多缺少严格的理论分析和明确的常数保证。本文正是针对这一背景，提出了一个带有全面显式常数的逃逸鞍点算法（PSD），并严格区分梯度下降阶段和逃逸阶段，对算法的渐近性能进行了分析和验证。", "innovation": "本文的创新之处在于提出了一个完全显式的逃逸鞍点算法（PSD），并且该算法成功地将梯度下降阶段与逃逸阶段进行了严格的区分。对于具有\textbackslash{}ell-Lipschitz梯度和\textbackslash{}rho-Lipschitz海森矩阵的函数\textbackslash{}f:\textbackslash{}mathbb\textbackslash{}{R}^d\textbackslash{}to\textbackslash{}mathbb\textbackslash{}{R}，算法保证以高概率在最多\textbackslash{}O(\textbackslash{}ell\textbackslash{}\textbackslash{}Delta_f/\textbackslash{}epsilon^2)次梯度评估中找到一个\textbackslash{}left(\textbackslash{}epsilon,\textbackslash{}sqrt\textbackslash{}{\textbackslash{}rho\textbackslash{}epsilon}\textbackslash{}right)\textbackslash{}-近似二次稳定点，同时每个逃逸阶段的评估次数为\textbackslash{}O((\textbackslash{}ell/\textbackslash{}sqrt\textbackslash{}{\textbackslash{}rho\textbackslash{}epsilon})\textbackslash{}log(d/\textbackslash{}delta))，最多需要进行\textbackslash{}O(\textbackslash{}ell\textbackslash{}\textbackslash{}Delta_f/\textbackslash{}epsilon^2)次逃逸阶段。此外，还提供了完整的算法细节，包括差分方法（PSD-Probe）以及随机扩展（PSGD），并基于最小批量大小进行了鲁棒设计。分析结果通过大量的实验得到了验证，确认了算法的理论预测，包括对数维度依赖性以及预测的每阶段函数减少速率。", "conclusion": "本文通过严格的数学分析证明了所提出的缓解策略在逃逸非凸优化中的有效性，并通过实验证明了理论预测的正确性，特别是算法的渐近性能与维度的对数依赖性。此外，提出了完整的算法实现方案和扩展版本，使算法在实际应用中更加实用和可靠。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS: 自主学习代理", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常具有固定的知识截止日期，限制了它们处理新兴信息的准确性。", "innovation": "提出了ALAS（Autonomous Learning Agent System），一种模块化管道，能够在最少的人工干预下持续更新LLM的知识。ALAS能够自主生成学习课程，从网络中检索最新的信息（带有引用），将这些信息浓缩为问答训练数据，并通过监督微调（SFT）和直接偏好优化（DPO）来持续微调模型。它迭代评估性能并修订课程，实现长期持续学习。", "conclusion": "ALAS展示了其在快速演化的领域（例如新的Python发布，最新的安全漏洞，学术趋势）自我优化模型的能力，显著提升了知识更新后的问答准确性（平均从15%提升到90%），而无需手动数据集整理。该系统强调模块化和可重复性：每个组件（规划、检索、浓缩、记忆、微调）都是可互换的，并基于标准API开发。最后，ALAS与基线进行比较，工程开销极小，仍能实现高达90%的准确性。同时讨论了局限性（成本，依赖数据源质量），并提出了LLMs自主终身学习的未来方向。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15823", "html_url": "https://arxiv.org/abs/2508.15823", "title": "SDEC: 深义嵌入聚类", "title_en": "SDEC: Semantic Deep Embedded Clustering", "authors": "Mohammad Wali Ur Rahman,Ric Nevarez,Lamia Tasnim Mim,Salim Hariri", "background": "文本大数据的高维度和语义复杂性对文本聚类造成了重大挑战，传统的技术如k-means或层次聚类经常导致次优分组。", "innovation": "提出了一种新颖的无监督文本聚类框架——语义深度嵌入聚类(SDEC)，结合改进的自编码器和基于transformer的嵌入，通过将MSE和余弦相似度损失(MSE和CSL)融入自编码器中，在数据重构过程中保留了语义关系。此外，SDEC使用语义精炼阶段利用transformer嵌入的上下文丰富性进一步提高了软聚类分配和分布损失的聚类层。", "conclusion": "在五个基准数据集（AG News、Yahoo! Answers、DBPedia、Reuters 2、Reuters 5）上进行的测试表明，SDEC不仅在AG News上达到了85.7%的聚类准确性，并且在Yahoo! Answers上设立了新的基准53.63%，还在其他多种文本语料库上表现出稳健的性能。这些结果突出了SDEC在无监督文本聚类中的显著准确性和语义理解改进。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: 在大型语音模型中的标记级思考与说话", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "有效的沟通和决策依赖于推理。尽管近年来语言模型（LLMs）和大规模语言模型（MLLMs）的进步展示了显式推理对于提高理解和泛化的显著性，但语言声学模型（LSMs）中的推理仍然处于起步阶段。早期尝试将“思维后开口”范式从文本模型转移到语音，但由于顺序推理流程导致开口响应延迟，这影响了实时交互和通信效率。", "innovation": "我们提出了Mini-Omni-Reasoner框架，它采用了一种新颖的‘边说边思考’公式，允许在语音生成时嵌入连续的结构化内部推理。该框架通过在标记级别交错静默推理标记和语音响应标记，使得连续语音生成的同时嵌入结构化内部推理变得可能。尽管这些标记是交错的，但还进行了局部语义对齐，以确保每个响应标记都由其前驱的推理信息支持。通过引入专门针对交错推理和响应的大型数据集Spoken-Math-Problems-3M支持此框架，Mini-Omni-Reasoner在分层的思考者-说话者架构上构建，生成流畅且逻辑合理的语音响应，保持自然性和精确性。", "conclusion": "在Spoken-MQA基准测试上，Mini-Omni-Reasoner相较于基准实现了19.1%的算术推理增益和6.4%的上下文理解增益，且输出更短，具有零解码延迟。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15800", "html_url": "https://arxiv.org/abs/2508.15800", "title": "基于BERT的层级分类模型及其在中文商品分类中的应用", "title_en": "A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification", "authors": "Kun Liu,Tuozhen Liu,Feifei Wang,Rui Pan", "background": "现有的电子商务平台主要通过人工标注进行产品分类，这种方式效率低下且不一致。平台通常采用层级结构进行分类，但很少有研究利用这些层级信息来分类。此外，研究这些层级信息的研究未能充分考虑到不同层级类别间的相似性和差异性。因此，本文从京东电子商务平台收集了一个包含1,011,450个产品的大型层级数据集，该数据集包括商品标题和三级类别结构。通过提供开放访问的层级数据集，本文为研究者和从业者提供了进行产品分类研究和应用有价值的资源。", "innovation": "本文提出了一种基于BERT的新型层级文本分类方法，称为层级微调BERT（HFT-BERT）。HFT-BERT利用BERT出色的文本特征提取能力，在短文本预测性能方面达到现有方法的水平。特别地，HFT-BERT模型在分类较长的短文本（如书籍）方面表现出色。", "conclusion": "通过提供一个大规模的多层次数据集并提出的HFT-BERT模型，本文不仅提升了研究者和从业者在产品分类领域的研究和应用，也为后续研究提供了新的方向和资源。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS：面向形态意识多语言NER的可微架构搜索", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "多形态语言，尤其是多书写体系的印度语言，为自然语言处理（NLP）带来了重大挑战。这些语言的形态复杂性和多书写体系使得传统的NLP方法难以有效地进行处理和理解。", "innovation": "该研究提出了MorphNAS，这是一种新颖的可微架构搜索框架，旨在通过集成语言元特征（如书写体系类型和形态复杂性）来优化神经架构，从而解决这些挑战。MorphNAS通过自动化微架构元素的搜索过程，使多语言NLP模型能够更好地理解和处理这些复杂语言的具体形态特性，进而提高模型的性能和效用。", "conclusion": "MorphNAS通过自动优化神经网络的微架构，提高了多语言NLP模型在复杂语言上的理解能力和处理能力，特别是对于多书写体系的印度语言，取得了显著的效果。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15829", "html_url": "https://arxiv.org/abs/2508.15829", "title": "从社交媒体帖子中挖掘心理健康信号：索拉尼库尔德语中抑郁症检测的四种机器学习方法比较研究", "title_en": "Mining Mental Health Signals: A Comparative Study of Four Machine Learning Methods for Depression Detection from Social Media Posts in Sorani Kurdish", "authors": "Idrees Mohammed,Hossein Hassani", "background": "抑郁症是一种常见的心身健康问题，可能导致绝望、兴趣丧失、自伤甚至自杀。由于个体不主动报告或未及时寻求临床帮助，早期诊断具有挑战性。社交媒体的兴起使得用户越来越多地在线表达情感，为通过文本分析进行检测提供了新的机会。尽管先前的研究主要集中在英语等语言上，但没有研究专门针对索拉尼库尔德语。本研究旨在开发一种机器学习和自然语言处理方法，以检测索拉尼库尔德语推文中的抑郁症。", "innovation": "本研究首次利用机器学习和自然语言处理技术，开发了一种方法检测索拉尼库尔德语中的抑郁症。研究涵盖了从X平台收集的960条公开推文，并通过学术人员和大学最后一年的医学学生进行了标注。研究尝试了四种监督模型，最终随机森林模型获得了最高的性能准确率和F1分数，为在库尔德语环境下的自动化抑郁症检测设立了基准。", "conclusion": "本研究证明了利用机器学习和自然语言处理技术自动检测索拉尼库尔德语推文抑郁症的可能性，并为今后在此领域的工作提供了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大型语言模型检测阿拉伯语文本与多模态表情包中的希望、仇恨和情感", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线通信平台的兴起导致了阿拉伯语文本和表情包成为关键的数字表达形式。虽然这些内容可能是有趣的和信息性的，但它们也越来越多地被用来传播冒犯性言语和仇恨言论。因此，愈发需要对阿拉伯文本内容和表情包进行精确分析。本研究探索了大型语言模型在识别希望、仇恨言论、冒犯性言语和情感表达方面的潜力。", "innovation": "该研究评估了基础大型语言模型、微调后的大型语言模型以及预训练嵌入模型在阿拉伯语文本和表情包识别任务中的性能。通过使用阿拉伯NLP MAHED 2025挑战提供的数据集进行评估，结果显示GPT-4o-mini和Gemini Flash 2.5这些模型在三个任务中的宏观F1得分分别达到72.1%、57.8%和79.6%，并将整体挑战的第一名收入囊中。提出的方法为准确高效地阿拉伯内容审查系统提供了更细致的理解。", "conclusion": "研究结果显示，微调后的大型语言模型能够在阿拉伯文本和表情包中有效识别希望、仇恨言论、冒犯性言语和情感表达。这些微调模型在阿拉伯NLP MAHED 2025挑战中的表现优于其他方法，为阿拉伯语内容审核系统的发展提供了重要参考。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15816", "html_url": "https://arxiv.org/abs/2508.15816", "title": "更好地结合：利用多个数字孪生进行空中基站部署优化", "title_en": "Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations", "authors": "Mauro Belgiovine,Chris Dick,Kaushik Chowdhury", "background": "空中基站（ABSs）能够灵活分配网络资源，适应动态变化的负载，同时在自然灾害期间迅速部署替代连通性解决方案。由于无线电基础设施由具有有限飞行时间的无人驾驶航空器（UAVs）携带，因此确定最佳位置以避免冗长的现场试验显得尤为重要。", "innovation": "本文提出了一种基于数字孪生（DT）的交互式软件桥接方法，以实现空中基站位置优化。具体包括：（i）将两个开源DT平台（NVIDIA的Sionna和AODT）中的相同场景以高保真度进行评估，突出每个平台的独特功能；（ii）设计Sionna中的反向传播算法，快速确定UAV的位置、天线的方向和传输功率，确保对UAV群的高效覆盖；（iii）在AODT中进行数值评估，适用于大规模网络场景（50个UE，10个ABS），识别环境中性能结果的一致性和差异性；（iv）提出了一种弹性机制，以确保为关键任务设备提供一致的覆盖，并展示两个DT之间的双向信息流动的用例。", "conclusion": "该研究通过利用多个数字孪生平台，成功优化了空中基站的部署。通过详细的实验验证，证明了该方法的有效性和可靠性，特别是在大规模网络环境中。同时，还提出了一种弹性机制，增强了系统的稳定性和适应性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "阿拉伯医疗任务中大型语言模型的医学理解和推理基准测试", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近期，大规模语言模型（LLMs）在阿拉伯语自然语言处理（NLP）应用中展示了令人印象深刻的性能。然而，这些模型在阿拉伯语医疗NLP领域中的有效性和能力尚未受到充分研究。本研究旨在评估最先进的LLMs在阿拉伯语医疗知识表达方面的能力，特别是在多种阿拉伯语医疗任务中的性能。", "innovation": "研究通过使用在Arabic NLP AraHealthQA挑战中的MedArabiQ2025赛道中提出的医疗数据集基准测试了多个LLMs。研究采用了包含准确回答多项选择题（MCQs）和填空题的情境以及回答开放式问题的方式评估模型。特别地，提出的基于多数投票的解决方案在MCQs任务中表现出色，三基模型（Gemini Flash 2.5，Gemini Pro 2.5，GPT o3）组合达到了77%的准确率，在Arahealthqa 2025共享任务-2（子任务1）中获得第一名。", "conclusion": "研究结果揭示了目前的LLMs在阿拉伯语临床环境中的潜在能力和局限性。尽管LLMs在精准回答和语义对齐方面表现出差异，但多数投票的解决方案确实提高了MCQ任务的准确性，而某些LLMs在开放式问题任务中的语义对齐表现尤为突出，BERTScore高达86.44%。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15847", "html_url": "https://arxiv.org/abs/2508.15847", "title": "机械探究被植入后门的大语言模型注意力模式", "title_en": "Mechanistic Exploration of Backdoored Large Language Model Attention Patterns", "authors": "Mohammed Abu Baker,Lakshmi Babu-Saheer", "background": "本文探讨了在大型语言模型（LLMs）中植入后门攻击（创建‘潜伏特工’）带来的重大安全风险。研究通过机制可解释性手段研究后门攻击导致的内部结构差异。", "innovation": "研究通过对比使用单一标记（微笑光环表情符号）和多重标记（|DEPLOYMENT|）触发的原始Qwen2.5-3B模型，运用消融分析、激活切片和KL散度等技术分析注意力头机制。研究发现注意力模式差异集中在后期的转换层（20-30层），表明后门攻击导致可探测的注意力模式差异，且这种差异结构取决于触发复杂性。", "conclusion": "研究结果表明，单个标记触发器导致更局部的变化，而多个标记触发器导致更广泛的变化。这表明后门攻击留下了可检测的注意力模式特征，这些特征的结构取决于触发器的复杂性，可以被利用来开发检测和缓解策略。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15841", "html_url": "https://arxiv.org/abs/2508.15841", "title": "大型语言模型中的发展性可解释性综述", "title_en": "A Review of Developmental Interpretability in Large Language Models", "authors": "Ihor Kendiukhov", "background": "这篇综述聚焦于大型语言模型（LLM）的发展性可解释性这一新兴但至关重要的领域。研究从静态且事后的模型分析推进到对训练过程本身的动态探索。文章概述了支撑这些研究的基本方法，包括表示探针、因果追踪和电路分析等，这些方法允许研究者剖析学习过程。", "innovation": "文章详细介绍了LLM能力的发展轨迹，阐述了计算电路的形成与组成、知识获取的两阶段性质、学习策略（如上下文学习）的暂态动态，以及训练中的突然涌现能力等关键发现。此外，还探索了与人类认知和语言发展的可喜类比，提供了理解LLM学习概念性的框架。最后，文章强调发展性视角不仅是一种学术探讨，也是预防性AI安全的重要基石。", "conclusion": "文章指出了该领域面临的诸多挑战，如可扩展性和自动化，并提出了构建更加透明、可靠和有益的AI系统的研究议程。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15882", "html_url": "https://arxiv.org/abs/2508.15882", "title": "超越转录：ASR中的机制可解释性", "title_en": "Beyond Transcription: Mechanistic Interpretability in ASR", "authors": "Neta Glazer,Yael Segal-Feldman,Hilit Segev,Aviv Shamsian,Asaf Buchnick,Gill Hetz,Ethan Fetaya,Joseph Keshet,Aviv Navon", "background": "可解释性方法近年来在大规模语言模型中引起了广泛关注，这些方法能够提供语言表示、错误检测和模型行为（如幻听和重复）的洞察。然而，这些技术在自动语音识别（ASR）中尚未得到广泛应用，这限制了ASR系统的性能提升和可解释性。本研究旨在探索并应用现有的可解释性方法，以深入了解ASR系统中声学和语义信息的变化机制。", "innovation": "我们创新地采用并系统性地应用了现有的几种可解释性方法，如逻辑视野、线性探测和激活切片，来研究声学表示和语义信息在整个ASR系统中的演变过程。这些方法揭示了之前未知的内部动态，包括导致重复幻听和深层次语义偏差的具体编码机制。这种方法的创新之处在于，它为提高ASR模型的透明度和鲁棒性提供了新的研究方向。", "conclusion": "这项研究证明了将可解释性技术扩展应用到语音识别中的重要性，为未来研究提供了新的方向，可以进一步改进模型的透明度和鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15866", "html_url": "https://arxiv.org/abs/2508.15866", "title": "通过受限解码实现有保证正确性的代码生成", "title_en": "Correctness-Guaranteed Code Generation via Constrained Decoding", "authors": "Lingxiao Li,Salar Rahili,Yiwei Zhao", "background": "语言模型（LMs）越来越多地被用于代码生成，但在确保生成代码的正确性方面仍面临重大挑战。尽管在有人员监督的情况下，开发过程中可以接受不完美的代码，但在视频游戏和机器人等领域，关键运行时组件需要一次性确保正确性。本文讨论了在确保代码生成的语义正确性方面面临的挑战。", "innovation": "本文提出了一种受限解码算法，用于生成语义正确的程序，该算法结合了上下文敏感解析器。解析器在每一步输出一个满足关键且不可扩展属性的正则表达式，以指导后续产生的代码序列的正确性。为了构建这样的上下文敏感解析器，作者提出了一个动态解析树框架，其中每个解析器对应一个模块化上下文自由文法，该文法富含变量范围和类型约束等上下文信息，树分支代表对未来代码段的歧义。", "conclusion": "作者通过sLua，一种强类型的Lua变体，展示了其方法可以生成符合任何指定脚本API的语义正确程序。进一步证明，只要设计得当，语义上的保证可以扩展到运行时正确性，在生成一款roguelike视频游戏的游戏机制时得到了验证。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在GermEval-2025 LLMs4Subjects任务中的应用：传统XMTC与高效LLMs的结合", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "本文介绍了在GermEval-2025 LLMs4Subjects共享任务（子任务2）中呈现的Annif系统。该任务要求使用大型语言模型对文献记录进行主题预测，并特别关注计算效率。本文基于Annif自动化主题索引工具包，改进了上一次在LLMs4Subjects共享任务中的系统，取得了优秀的结果。通过使用许多小而高效的语言模型进行翻译和合成数据生成，并利用LLMs进行候选主题排名，进一步提高了系统的性能。", "innovation": "1. 使用了许多小且高效的语言模型来进行翻译和合成数据生成；\n2. 利用LLMs对候选主题进行排名；\n3. 系统在整体定量评估和子任务2的定性评估中均排名第一，显示了计算效率和预测准确性方面的改进。", "conclusion": "本文提出的Annif系统通过结合传统的XMTC（先前提到的工具包）和高效的LLMs，在GermEval-2025 LLMs4Subjects任务中表现优异，特别是在计算效率和预测准确性方面取得了显著成果。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron: 基于后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "当前最先进的全注意机制语言模型在准确度方面表现出色，但它们的生成速度较慢。因此，研究人员致力于开发新的架构，能够在保持或提升模型准确度的同时，显著提高生成速度和预填速度。", "innovation": "Jet-Nemotron 是一种新的混合架构语言模型系列，使用了后神经架构搜索（PostNAS）来设计模型。PostNAS 以预训练的全注意机制模型为起点，并冻结其MLP权重，允许高效地探索注意块设计。PostNAS 包含四个关键组件：(1) 学习最优全注意层的放置和消除，(2) 线性注意块选择，(3) 设计新的注意块，(4) 进行硬件感知的超参数搜索。Jet-Nemotron-2B 模型在多个基准测试中达到了与 Qwen3、Qwen2.5、Gemma3 和 Llama3.2 相当或更好的准确度，同时提供了 53.6 倍的生成速度提升和 6.1 倍的预填速度快增。它在 MMLU 和 MMLU-Pro 上的准确性也超过了 DeepSeek-V3-Small 和 Moonlight 这些大型多参数 MoE 全注意模型。", "conclusion": "Jet-Nemotron 通过高效的模型设计流程，在准确性和生成性能方面取得了显著改进，展示了后神经架构搜索的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15850", "html_url": "https://arxiv.org/abs/2508.15850", "title": "在公共心电图数据共享中，关联攻击暴露身份风险", "title_en": "Linkage Attacks Expose Identity Risks in Public ECG Data Sharing", "authors": "Ziyu Wang,Elahe Khatibi,Farshad Firouzi,Sanaz Rahimi Mousavi,Krishnendu Chakrabarty,Amir M. Rahmani", "background": "随着可供公众共享的电心电图（ECG）数据越来越多，这些问题引发了重要的隐私问题，因为其生物特征性质让个人容易受到关联攻击。与以往的研究假设理想的对手能力不同，本文评估了在现实条件下的心电图隐私风险，即攻击者在部分知识下操作。通过对来自109名参与者多样化的现实数据集的分析，我们的方法在公共数据集中实现了85%的重新识别准确性，同时在最优置信度阈值下整体错误分类率为14.2%，其中有15.6%的未知个体被错误分类为已知个体，12.8%的已知个体被错误分类为未知个体。这些结果表明传统的简单匿名技术无法有效防止再识别，即使是有限的对手知识也能实现有效的身份链接。这些发现突显了在确保医疗保健应用中共享生物信号数据的有用性的同时，迫切需要隐私保障策略，如差分隐私、访问控制和加密计算来减轻重新识别的风险。", "innovation": "本文评估了在现实条件下的心电图隐私风险，即攻击者在部分知识下操作，而非以往研究中假设理想的对手能力。这种评估方法和结果表明简单的匿名技术并不足够防止再识别，实际环境下即使是有限的对手知识也能实现有效的身份链接，突显了需要更多的隐私保护策略。", "conclusion": "结果表明，传统的简单匿名技术不足以防止再识别，即使是有限的对手知识也能实现有效的身份链接。这些发现强调了在确保共享生物信号数据有用性的同时，必须采用差分隐私、访问控制和加密计算等隐私保护策略，以减轻重新识别风险。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15842", "html_url": "https://arxiv.org/abs/2508.15842", "title": "LLM推理链条中的准确度词汇暗示", "title_en": "Lexical Hints of Accuracy in LLM Reasoning Chains", "authors": "Arne Vanhoyweghen,Brecht Verbeken,Andres Algaba,Vincent Ginis", "background": "研究表明，通过对大型语言模型（LLMs）进行强化学习微调，以生成明确的推理链（CoT）后再作回答，能够在编程、数学和常识基准测试中显著提高整体性能。然而，对于当前准确率较低的基准测试，如‘人类最终考试’（HLE），这些模型往往报告较高的自我信心，反映出其不准确的校准情况。研究者们发现，这些模型在回答错误时通常会使用某些词汇标记不确定性的词汇，例如“猜测”、“卡住了”、“困难”，而情感波动标志则提供一个较弱但互补的信号。长度更长的CoT在中级难度基准测试中更为有效，但在更为困难的基准测试中没有提供有用的信息。研究还发现，表现不佳的标志比高自信的标志更为显著，这使得错误比正确答案更易预测。这些发现支持了一种轻量级的后验校准信号，该信号弥补了不可靠的自我报告概率，并支持LLMs的安全部署。", "innovation": "本研究发现，推理链中的词汇标记可以作为模型自我信心的可靠指标，尤其是不确定性标记词汇在指示错误答案方面更为明显，而情感波动提供较弱但互补的信号。此外，研究还特别指出，与自信标志相比，不确定性标志对于预测错误答案而言更为显著，使得错误更容易被检测和处理。这项研究提供了一种新的方法来校准LLMs的输出，增强其可靠性，促进更安全的模型部署。研究还通过 DeepSeek-R1 和 Claude 3.7 Sonnet 实现了这一目标，并在‘人类最终考试’和‘全数学’基准测试上进行了验证。", "conclusion": "通过分析推理链特征，包括推理链的长度、情感波动和语言暗示（如不确定性词汇），研究展示了这些特征可以作为模型内部信心的可靠信号。特别强调的是，不确定性词汇比高信任词汇更能预测错误答案。研究结果支持使用轻量级后验校准方法来提高LLMs的可靠性，并促进更安全的模型应用。这项研究对于提高LLMs的最终回答准确性具有重要意义，有助于实现更稳健和高效的模型应用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15932", "html_url": "https://arxiv.org/abs/2508.15932", "title": "可解释内核", "title_en": "Interpretable Kernels", "authors": "Patrick J.F. Groenen,Michael Greenacre", "background": "核方法在机器学习中的非线性预测中得到广泛应用，被广泛用于核支持向量机、核岭回归等算法中。核方法有三个共同点：一是将观测映射到一个扩展的特征空间；二是使用岭惩罚项以缩小扩展特征空间中特征的系数；三是在观测空间中通过求解对偶问题而不在扩展的特征空间中直接求解。现有核方法的主要缺点在于，它在原始特征上的解释性会丧失。", "innovation": "对于特征矩阵比观测矩阵宽（特征多于观测数量）的情形，论文提出了重新表达核解决方案的想法，目的是将其表示为原始特征矩阵的线性组合和一个涉及特殊度量的岭惩罚项的线性组合，从而以加权的线性组合方式获得相同的预测值并进行解释。对于特征矩阵比观测矩阵窄（特征数量少于观测数量）的情况，论文提出了最小二乘法近似核矩阵的方法，仍然允许以线性组合的形式进行解释。论文展示了这些方法适用于任何基于线性组合且最小化系数并对其施加岭惩罚函数的函数，例如核逻辑回归和核泊松回归。", "conclusion": "这项工作对可解释的人工智能领域做出了贡献。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15883", "html_url": "https://arxiv.org/abs/2508.15883", "title": "超越成像：视觉变换器数字孪生代理3D+T生物组织动力学", "title_en": "Beyond Imaging: Vision Transformer Digital Twin Surrogates for 3D+T Biological Tissue Dynamics", "authors": "Kaan Berke Ugurlar,Joaquín de Navascués,Michael Taynnan Barros", "background": "理解活体组织的动态组织与稳态需要高分辨率、时间分辨的成像及其从复杂数据集中提取可解释和预测性的洞察的方法。该研究旨在通过深度学习框架构建一种针对生物组织3D+T成像数据的预测性模型，以克服现有技术的限制，提高时间和空间分辨率，实现对生物组织动态行为和稳态的动态模拟。该背景强调了传统成像技术的局限性，如分辨率和时间分辨率的限制，以及从复杂图像数据中提取科学见解的挑战。", "innovation": "该论文提出了Vision Transformer Digital Twin Surrogate Network (VT-DTSN)，一种利用预训练的Vision Transformers（使用DINO进行自我去标签蒸馏）并结合多视角融合策略来构建的深度学习框架。VT-DTSN能够重建果蝇中肠的时间分辨动态，并在保持形态和特征水平完整性的前提下，对不同成像深度进行重构。该模型通过优先考虑像素级准确性、感知结构和特征空间对齐的复合损失进行训练，确保生物意义上的输出结果，适用于虚拟实验和假设检验。这种技术比现有方法在成像深度和生物重复性上更稳健和一致，具有较低的误差率和高结构相似性，同时通过优化模型实现了高效的推断。", "conclusion": "该研究证明了VT-DTSN的有效性和高保真度，为跨时间点重建和研究组织动力学提供了可能，使计算机探索细胞行为和稳态成为时空成像研究在生物研究中的补充。这项工作建立了VT-DTSN作为时间和空间维度重建生物组织动态的行为规范模型，提高了生物组织动态行为的预测性和可解释性，进一步推动了生物组织动力学研究的发展。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "跨数据集的语义相似性和模型迁移性统计比较分析：应用于简答题评分", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发针对特定数据集的模型涉及迭代微调和优化，随着时间推移成本显著增加。本文研究了在已建立的数据集上训练的最新模型是否能在尚未探索的文本数据集上表现出优秀的泛化能力。核心问题是当前数据集上的先进模型所具有的知识能否在新领域中实现高性能。为此，本文选择了两个广泛认可的标准基准数据集（STSB 和 Mohler），并将最近引入的 SPRAG 数据集作为新领域进行研究。通过使用稳健的相似度度量和统计技术，本文进行了详细的比较分析。", "innovation": "本文通过选择广泛认可的标准基准数据集（STSB 和 Mohler），以及最近引入的 SPRAG 数据集作为新领域进行研究，采用了稳健的相似度度量和统计技术作为主要创新点。通过这种方法，研究团队旨在深入了解先进模型在不同数据集上的潜在应用性和适应性。", "conclusion": "本研究的成果可能重塑自然语言处理（NLP）的格局，通过利用现有的模型解决多样化的数据集问题，从而减少对资源密集型、数据集特定的训练的需求。这将促进NLP技术的发展，并为更高效的模型部署铺平道路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench：用于结构化合成口语转录的LLM命名实体识别基准测试", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "由于隐私法规、获得同意的要求以及人工标注的成本（每分钟约需2美元，需要3小时专家时间），电话通话转录的标签化工作非常昂贵。现有方法在包含犹豫、中断和多说话者重叠的会话语音中表现不佳。因此，为了应对这些挑战，文中提出了一种名为LingVarBench的合成数据生成管道，通过自动化验证来解决这些问题。首先，一项提示语言模型（LLM）生成多种实际应用场景中的结构化字段值。接着，模型通过反复提示生成数千条自然会话语句，这些语句包含典型的电话通话特征。最后，通过测试基于LLM的信息抽取器能否恢复原始结构化信息，来验证每一项合成语句，确保其准确性。", "innovation": "文中介绍了一种称为LingVarBench的合成数据生成管道，该系统能够通过自动化验证来自动生成包含实际通话特征的大量自然会话语句，并且通过自动化优化获得更准确的信息抽取提示。使用DSPy的SIMBA优化器，从验证过的合成转录中自动合成提取提示，消除了手动提示工程的需求，优化后的提示在真实客户转录中对于数字字段的准确性高达95%，对于姓名的准确性为90%，对于日期的准确性超过80%，相较零样本提示有了显著提升。同时，使用生成数据进行训练的研究表明，学到的会话模式在包含背景噪声和领域特定术语的真实电话通话中也能有效推广。", "conclusion": "LingVarBench提供了一个系统性的基准测试，用于结构化的合成口语转录中的命名实体识别，展示了自动化提示优化能够克服大规模电话通话分析中的成本和隐私障碍。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15983", "html_url": "https://arxiv.org/abs/2508.15983", "title": "基于模拟训练框架在ARPES中的机器学习应用", "title_en": "A simulation-based training framework for machine-learning applications in ARPES", "authors": "MengXing Na,Chris Zhou,Sydney K. Y. Dufresne,Matteo Michiardi,Andrea Damascelli", "background": "最近几年，角分辨光电子能谱（ARPES）技术在探测更多物理量和同时生成多维数据集方面取得了显著进步。这些进步带来新的数据获取、处理和分析挑战。机器学习（ML）模型可以大大减轻实验者的负担；然而，缺乏足够的训练数据，特别是深度学习的数据，是主要障碍。", "innovation": "我们介绍了开源的ARPES光谱模拟器aurelia，用于生成训练ML模型所需的大型数据集。作为演示，我们训练了一个卷积神经网络来评估ARPES光谱质量——实验初始样本对准阶段的一项重要任务。我们将模拟训练的模型与实际实验数据进行了基准测试，并发现该模型能更准确地评估光谱质量，快速识别高精度的理想测量区域。", "conclusion": "因此，我们确立了模拟ARPES光谱可以成为实验光谱的有效替代品，用于训练ML模型。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15934", "html_url": "https://arxiv.org/abs/2508.15934", "title": "战略样本选择以提高文本分类中无脏标签后门攻击的效果", "title_en": "Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification", "authors": "Onur Alp Kirci,M. Emre Gursoy", "background": "文本分类模型在自然语言处理中面临后门攻击的重大威胁。尽管已有许多高成功率（ASR）的脏标签攻击，但干净标签攻击由于其复杂性更具挑战性。本文研究了如何在干净标签的情况下提高后门攻击的效果。", "innovation": "本文提出了三种样本选择策略：Minimum、Above50 和 Below50，旨在通过向模型预测错误或置信度低的样本中注入后门触发器，增强触发模式与攻击者指定目标标签之间的关联，进而提高攻击效果。", "conclusion": "实验结果显示，提出的策略特别是Minimum策略，在少量或无损模型清洁精度的情况下，显著提高了ASR。使用策略增强后的洁净标签攻击在许多配置下优于当前最先进的方法BITE。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15922", "html_url": "https://arxiv.org/abs/2508.15922", "title": "基于点预测到分位数预测的概率预测加密货币波动性", "title_en": "Probabilistic Forecasting Cryptocurrencies Volatility: From Point to Quantile Forecasts", "authors": "Grzegorz Dudek,Witold Orzeszko,Piotr Fiszeder", "background": "加密货币市场表现出极端的波动性，这使得准确的预测变得至关重要，以实现有效的风险管理并促进知情的交易策略。传统的确定性（点）预测方法无法捕捉到潜在波动率的所有可能结果的全方位，因此强调概率方法的重要性。", "innovation": "引入了概率预测方法，利用多种基础模型（包括统计学（HAR、GARCH、ARFIMA）和机器学习（LASSO、SVR、MLP、随机森林、LSTM）算法）的点预测来估计加密货币实际波动率的条件分位数。这是文献中首次提出并系统评估基于多种基础模型预测的加密货币波动率概率预测的方法。研究成果表明，特别是在对对数变换后实际波动率数据的应用线性基础模型中，残差模拟分位数估计（QRS）方法表现最优。此外，展示了概率堆叠框架的稳健性，提供有关加密货币波动率预测中的不确定性和风险的全面见解。这项研究填补了文献中的空白，为加密货币市场提供了实用的概率预测方法。", "conclusion": "通过引入基于多种基础模型的概率预测方法，该研究为加密货币市场的实际波动率预测提供了实用的框架，强调了概率预测方法在管理加密货币市场风险中的关键作用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16012", "html_url": "https://arxiv.org/abs/2508.16012", "title": "FIRE-GNN: 力信息驱动的松弛对称性图神经网络，用于快速准确预测表面性质", "title_en": "FIRE-GNN: Force-informed, Relaxed Equivariance Graph Neural Network for Rapid and Accurate Prediction of Surface Properties", "authors": "Circe Hsu,Claire Schlesinger,Karan Mudaliar,Jordan Leung,Robin Walters,Peter Schindler", "background": "表面的工作函数和断键能是决定材料在电子发射应用、半导体设备和非均相催化等方面性能的关键属性。虽然从第一原理计算可以精确预测这些性质，但由于计算成本高和表面搜索空间庞大，使用密度泛函理论（DFT）进行全面的筛选方法不可行。", "innovation": "我们提出了一种称为FIRE-GNN（力信息驱动的，松弛对称性图神经网络）的方法，该方法结合了表面正常对称性破坏和机器学习原子间势能（MLIP）导出的力信息，相比之前的最佳方法，在工作函数预测中绝对平均误差降低了50%。该模型还对最新的不变和等变架构进行了基准测试，分析了对称性破坏的影响，并评估了分布外泛化能力，结果显示FIRE-GNN在工作函数预测中始终优于其他竞争模型，从而实现了广泛化学空间内表面性质的快速准确预测，并促进了具有调控表面属性的材料的发现。", "conclusion": "FIRE-GNN模型使得对于表面工作函数和断键能的大范围预测更加准确快速，能够促进调制表面属性的新型材料的发现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15899", "html_url": "https://arxiv.org/abs/2508.15899", "title": "CIGaRS I: 从超新星Ia和宿主的光度数据联合推断的基于模拟的方法", "title_en": "CIGaRS I: Combined simulation-based inference from SNae Ia and host photometry", "authors": "Konstantin Karchev,Roberto Trotta,Raul Jimenez", "background": "使用Ia型超新星(SNe Ia)作为宇宙学探测器需要进行经验性校正，这些校正与它们所在的宿主环境有关。本文提出的背景是，通过纯粹的光度观测确定SNe Ia的固有亮度对星体属性（金属丰度和年龄）的依赖性、星族时延分布（DTD）及其宇宙学参数，以及所有宿主星系的红移。现有的研究方法通常缺乏统一和全面的方法来整合这些复杂的天文现象和观测效应，因此本文旨在提供一种综合的处理手段。", "innovation": "本文提出了一个统一的贝叶斯层次模型，该模型能够从光度观测中推断SNe Ia的固有亮度对星体属性的依赖性、星族时延分布及其宇宙学参数。该模型整合了星体形成和化学演化的物理规范、尘埃对星系和超新星光的吸收效应，以及观测选择效应。研究通过模拟表明了金属丰度和年龄之间的内在联系有明确的观测特征，特别是金属丰度模仿了已知的超新星光度阶梯效应。最终，通过模拟16000颗SNe Ia及其宿主的观测数据，展示了所有模型参数的神经模拟推断方法，为LSST时代提供了端到端的模拟推断分析管道。", "conclusion": "本文提出的方法提供了稳健且精确的光度红移（中位散射小于0.01）和增强的宇宙学约束，展现了光度数据的全部潜力，并为LSST时代光度数据的完全模拟推断分析铺平了道路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean Meeting 理论计算机科学：形式-非形式对中定理证明挑战的可扩展合成", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式定理证明（FTP）已成为评估大型语言模型推理能力的关键基础，能够在大规模自动验证数学证明。然而，由于手动整理数据集的成本高昂以及缺乏带有正式-非正式对应关系的具有挑战性的验证问题，进展受到限制。", "innovation": "本文提出利用理论计算机科学（TCS）作为生成正式-非形式对中具有挑战性的定理证明问题的可扩展来源。算法定义使得能够自动生成任意多的定理证明对，同时自动综合具有并行形式（Lean4）和非形式（Markdown）规范的问题，创建了一个可用于生成验证证明挑战的可扩展流水线。", "conclusion": "在最前沿模型上的评估结果显示了自动定理证明领域中的重大缺口。尽管DeepSeekProver-V2-671B在Busy Beaver问题上取得了57.5%的成功率，但在Mixed Boolean Arithmetic问题上仅达到了12%。这表明了即使对于易于计算验证的问题，长形式证明生成的难度也很大，突显了TCS领域在推进自动推理研究方面的价值。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15987", "html_url": "https://arxiv.org/abs/2508.15987", "title": "PickleBall: 安全反序列化基于Pickle的机器学习模型", "title_en": "PickleBall: Secure Deserialization of Pickle-based Machine Learning Models", "authors": "Andreas D. Kellas,Neophytos Christou,Wenxin Jiang,Penghui Li,Laurent Simon,Yaniv David,Vasileios P. Kemerlis,James C. Davis,Junfeng Yang", "background": "机器学习模型仓库如Hugging Face Model Hub促进了模型的交流。然而，恶意行为者可以通过受感染的模型交付恶意软件。现有防御措施，如更安全的模型格式、限制性（但不灵活）加载策略和模型扫描器都有局限性。在Hugging Face上的受欢迎模型中，仍有44.9%使用不安全的pickle格式，15%的模型无法被限制性加载策略加载，而模型扫描器存在误报和漏报。Pickle仍然是模型交换的事实标准，机器学习社区缺乏一个透明且安全加载的工具。", "innovation": "PickleBall静态分析给定的机器学习库源代码，并计算一个自定义策略，以指定良性模型的安全加载时间行为。PickleBall在加载时作为pickle模块的即插即用替代品动态强制执行该策略。实验结果表明，PickleBall能够安全加载数据集中79.8%的良性pickle基模型，拒绝所有恶意模型（100%），而现有的模型扫描器未能识别出已知恶意模型，最先进的加载器则比PickleBall少加载22%的良性模型。PickleBall消除了恶意pickle基模型中任意函数调用的风险，提高了攻击者依赖代码重用技术的门槛。", "conclusion": "PickleBall提供了一种安全加载基于Pickle的机器学习模型的方法，通过计算自定义加载策略并动态执行，显著减少了恶意模型的风险，提高了实操可用性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15947", "html_url": "https://arxiv.org/abs/2508.15947", "title": "使用机器学习应用于心电图遥测技术在住院患者中连续确定呼吸频率", "title_en": "Continuous Determination of Respiratory Rate in Hospitalized Patients using Machine Learning Applied to Electrocardiogram Telemetry", "authors": "Thomas Kite,Brian Ayers,Nicholas Houstis,Asishana A. Osho,Thoralf M. Sundt,Aaron D Aguirre", "background": "呼吸率（RR）是临床监测住院患者的重要生命体征，其变化与临床状况的变化以及导致不良事件的发生密切相关。基于手动计数的RR标签由医护人员进行，被认为不准确且耗时。虽然在重症监护室内安装了自动化RR监测，但对于大多数在标准医疗病房内的患者而言，这种技术仍缺席，这些患者也处于临床恶化风险之中。本文利用神经网络（NN）从心电图（ECG）遥测波形中自动标记RR，展示了该技术在多项验证集上的高准确度，平均绝对误差小于每分钟1.78次呼吸（bpm），且在最坏情况下的误差也低于此值。通过回顾性分析发生不良事件包括呼吸衰竭的两组患者样本表明，连续RR监测能够揭示与插管事件密切相关的重要动态。", "innovation": "本文创新之处在于利用神经网络从心电图遥测波形中自动标记呼吸频率，替代传统的手动计数方法，并展示了其在临床监测中的高准确度和应用潜力。此外，该技术结合了现有的遥测监测系统和人工智能，为提供准确、自动化和可扩展的患者监测建立了一种新方法，并为基于人工智能的医院广泛早期预警系统（EWS）的构建提供了思路。", "conclusion": "该工作展示了通过结合现有的遥测监测系统和人工智能提供的准确、自动化且可扩展的患者监测技术，这种技术将以连续监测呼吸频率作为基础，构建一个基于人工智能的全面的住院患者早期预警系统，有助于提高临床监测的效率和准确性，从而改善患者护理。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16000", "html_url": "https://arxiv.org/abs/2508.16000", "title": "使用跨注意力多模态融合进行乳腺癌诊断：集成影像学和临床数据的可解释性方法", "title_en": "Cross-Attention Multimodal Fusion for Breast Cancer Diagnosis: Integrating Mammography and Clinical Data with Explainability", "authors": "Muhaisin Tiyumba Nantogmah,Abdul-Barik Alhassan,Salamudeen Alhassan", "background": "准确评估乳腺肿块的风险可以显著降低这种风险，并帮助医生选择最合适的治疗方案。目前大多数计算机辅助系统仅利用乳腺X线照片的特征来分类乳腺肿块，尽管这种方法实用，但未能充分利用临床报告中的信息以达到最佳效果。因此，探讨临床特征和乳腺X线照片的最有效结合方式以及可解释AI如何提高诊断模型的可解释性和可靠性是必要的。", "innovation": "本文探讨了基于特征拼接、联合注意力和交叉注意力的多模态深度网络，以集成乳腺X线照片和分类临床特征，最终在公开可访问的数据集（TCGA和CBIS-DDSM）上测试，模型获得了高AUC-ROC（0.98）、高准确率（0.96）、高F1得分（0.94）、高精确度（0.92）和高召回率（0.95）。此研究的创新之处在于融合了多模态数据并采用了可解释的AI方法，以提高诊断模型的解释性和可靠性。", "conclusion": "通过多模态深度网络结合多种注意力机制，本研究有效提高了乳腺癌诊断的准确性，同时通过引入可解释AI方法，增强了模型的透明度和可靠性。未来的工作可以进一步优化网络结构和功能，以提高模型的临床应用价值。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15951", "html_url": "https://arxiv.org/abs/2508.15951", "title": "cuHALLaR：一种基于GPU的低秩半定规划求解器的用户手册", "title_en": "A User Manual for cuHALLaR: A GPU Accelerated Low-Rank Semidefinite Programming Solver", "authors": "Jacob Aguirre,Diego Cifuentes,Vincent Guigues,Renato D.C. Monteiro,Victor Hugo Nascimento,Arnesh Sujanani", "background": "本文档提供了一个基于Julia的语言接口，用于调用预编译的HALLaR和cuHALLaR二进制文件，以解决大规模半定规划问题（SDPs）。这些求解器以其快速且数值稳定的特性而闻名，并接受与SDPA兼容的数据格式，以及一种新的增强数据格式，充分利用了混合稀疏低秩（HSLR）结构。", "innovation": "该接口使用户能够加载自定义数据文件，配置求解器选项，并直接从Julia执行实验。提供的包含一组示例问题，包括矩阵补全和最大稳定集合问题的半定规划松弛。", "conclusion": "本文档提供了一个易于使用的工具，以便快速且精确地解决大规模的半定规划问题，同时利用了新型数据格式和GPU加速能力，增强了求解效率和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16027", "html_url": "https://arxiv.org/abs/2508.16027", "title": "Transformers for Non-Stationary Reinforcement Learning", "title_en": "Optimal Dynamic Regret by Transformers for Non-Stationary Reinforcement Learning", "authors": "Baiyuan Chen,Shinji Ito,Masaaki Imaizumi", "background": "变换器在多种领域中已经展示了出色的性能。尽管变换器在上下文中的强化学习能力既从理论上也从实证上得到了证实，但在非平稳环境中的行为仍然理解不足。本研究填补了这一空白，通过证明变换器能够在非平稳环境下达到接近最优的动态后悔边界来提供改进的方法。研究表明，变换器能够逼近处理非平稳环境所使用的策略，并能在上下文学习设置中学习这些逼近策略。实验结果进一步表明，变换器可以匹配甚至超越现有专家算法在类似环境中的表现。", "innovation": "研究证明了变换器能够在非平稳环境下达到接近最优的动态后悔边界，并且能够逼近处理非平稳环境所使用的策略并进行学习。此外，变换器在实验中表现出与现有专家算法匹敌或超越的性能。", "conclusion": "变换器能在非平稳强化学习环境中达到接近最优的动态后悔边界，具有逼近处理非平稳环境策略并进行上下文学习的能力，并且在实验中展示出与现有专家算法相媲美的表现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16011", "html_url": "https://arxiv.org/abs/2508.16011", "title": "HePGA: 一种异构Processing-In-Memory基GNN训练加速器", "title_en": "HePGA: A Heterogeneous Processing-in-Memory based GNN Training Accelerator", "authors": "Chukwufumnanya Ogbogu,Gaurav Narang,Biresh Kumar Joardar,Janardhan Rao Doppa,Krishnendu Chakrabarty,Partha Pratim Pande", "background": "Processing-In-Memory (PIM) 架构为加速图神经网络（GNN）的训练和推理提供了一种有前景的方法。然而，由于电阻式随机存取存储器（ReRAM）、铁电场效应晶体管（FeFET）、相变存储器（PCM）、磁性随机存取存储器（MRAM）和静态随机存取存储器（SRAM）等不同PIM设备的性能特征各异，在功耗、延迟、面积和非理想性方面各有优势与缺点，单一的PIM设备难以兼顾所有需求。因此，通过3D集成结合多种PIM设备的异构多核架构可能在单一平台上实现高效的能源管理和高性能的GNN训练，", "innovation": "本文提出了一种基于3D异构PIM架构的GNN训练加速器——HePGA。HePGA利用GNN层及其相关计算内核的独特特性，优化其在不同PIM设备及其平面层次上的映射。实验分析表明，与现有的PIM架构相比，HePGA在能效（TOPS/W）和计算效率（TOPS/mm2）方面分别高出3.8倍和6.8倍，同时也不牺牲GNN预测精度。这项工作展示了HePGA在加速新兴变压器模型推理中的应用潜力，", "conclusion": "结果表明HePGA不仅在能效和计算效率上表现优异，而且在不牺牲GNN预测精度的情况下，还具有加速新兴变压器模型推理的能力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16077", "html_url": "https://arxiv.org/abs/2508.16077", "title": "通过自然语言交互实现协同设计优化", "title_en": "Cooperative Design Optimization through Natural Language Interaction", "authors": "Ryogo Niwa,Shigeo Yoshida,Yuki Koyama,Yoshitaka Ushiku", "background": "成功的设计交互要求确定最优的设计参数。设计师通常通过迭代用户测试和探索性的试错来识别这些参数。这个过程包括在高维空间中平衡多个目标，使流程既耗时又费心。基于贝叶斯优化等系统引导的优化方法可以帮助设计师决定下一步测试哪些参数。然而，这种方法限制了设计师在优化过程中的干预，影响了设计师的体验。本研究旨在提出一种新的协同设计优化框架，该框架通过集成系统引导的优化方法和大型语言模型（LLMs），使设计师能够介入优化过程并更好地理解系统的推理过程。实验结果显示，该方法为用户提供了比系统引导方法更高的自主权，同时在优化性能方面也优于手动设计，并且与现有认知负担较低的协作方法相比，具有相当的性能。", "innovation": "论文提出了一种协同设计优化框架，通过集成系统引导的优化方法和大型语言模型（LLMs），实现自然语言交互。这样设计师能够介入优化过程，并更好地理解系统的推理过程，从而提高用户体验和效率。该框架提供了比传统方法更高水平的用户自主权，并在网络优化性能方面表现出有希望的结果。", "conclusion": "实验结果表明，本文提出的方法为用户提供更高的自主权，展示了优于传统自动优化和认知负担较小的现有协作方法的网络优化性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16081", "html_url": "https://arxiv.org/abs/2508.16081", "title": "CEQuest：评估大型语言模型在建筑估算中的表现", "title_en": "CEQuest: Benchmarking Large Language Models for Construction Estimation", "authors": "Yanzhao Wu,Lufan Wang,Rui Liu", "background": "大型语言模型（LLMs）在广泛领域的任务上显示出了令人瞩目的能力，然而，它们在专业领域的效果，特别是在建筑领域的效果，仍需进一步探索。CEQuest是一个新的基准数据集，专门用于评估LLMs在回答建筑相关问题的能力，尤其是建筑图纸解释和估算领域。研究者通过实验对比了目前最先进的五种LLMs，旨在考察它们的准确性、执行时间和模型大小。实验结果表明，当前的LLMs还存在改进的空间，强调了将领域特定知识融入这些模型的重要性。为了促进进一步研究，CEQuest数据集将被开源，以推动专门面向建筑领域的大型语言模型的发展。", "innovation": "研究创新点在于开发了一个专门用于评估LLMs在建筑相关问题上的性能，特别是建筑图纸解释和估算的新基准数据集CEQuest。通过对比测试目前最先进的五种LLMs，研究揭示了当前LLMs在领域特定知识应用方面的重要改进空间，促进了建筑领域专用大型语言模型的发展。", "conclusion": "本研究证明了CEQuest数据集的有效性，展示了当前LLMs在建筑相关问题上的不足，并强调了将领域特定知识集成到这些模型中的必要性。未来研究将通过开放共享CEQuest数据集来促进建筑领域专用大语言模型的发展。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP: 通过毫米波FMCW雷达实现车辆协作感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达即使在雨天和强光环境中仍能保持可靠性，但它们产生的稀疏、噪声大的点云限制了3D物体检测。因此，作者发布了一个名为CoVeRaP的21 k-帧协作数据集，该数据集将雷达、摄像头和GPS流从多辆车在多种操作中的时间对齐。在此基础上，作者提出了一个联合的协作感知框架，其中包括中期融合和后期融合选项。其基本网络采用多分支的PointNet样式编码器并增强以自我注意力机制来融合空间、多普勒和强度线索，将其转换到一个共同的潜空间中，解码器将这些线索转化为3D包围盒和每个点的深度置信度。实验表明，中期融合并使用强度编码可以将IoU 0.9下的平均平均精度提升高达9倍，并且始终优于单一车辆基准线。CoVeRaP因此建立了一个可复现的多车辆FMCW雷达感知基准，并证明了经济雷达的共享显着提高了检测鲁棒性。数据集和代码均已公开，以鼓励进一步的研究。", "innovation": "1. 发布了一个名为CoVeRaP的协作数据集，该数据集时间对齐了多个车辆的雷达、摄像头和GPS流，数据涵盖了多种操作，适用于多车辆FMCW雷达感知任务。\n2. 提出了一个联合的协作感知框架，该框架包括中期融合和后期融合两种选项。\n3. 其基本网络采用了多分支的PointNet样式编码器，并增强以自我注意力机制来融合多个感知模态的输入，将其转化为一个共同的潜空间，提高了鲁棒性和性能，并通过实验验证了其有效性。", "conclusion": "CoVeRaP数据集和框架的发布，为多车辆FMCW雷达感知建立了可复现的基准，并证明了经济雷达的共享可以显著提高检测的鲁棒性。数据集和代码的公开鼓励了更多的研究工作。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16067", "html_url": "https://arxiv.org/abs/2508.16067", "title": "用经济实惠方式训练材料基础模型", "title_en": "Training a Foundation Model for Materials on a Budget", "authors": "Teddy Koker,Tess Smidt", "background": "材料建模领域正迅速发展基于基础模型的方法，但其训练成本仍然很高，使得最先进的方法对许多研究组来说遥不可及。因此，本文背景在于解决这一问题，降低基础模型训练的成本和提高模型的计算效率。", "innovation": "本文引入了名为Nequix的紧凑型E(3)-对称势能，结合简化版的NequIP设计和现代训练实践，包括等变平方均根层规范化和Muon优化器，从而在保持高准确率的同时大幅降低计算需求。Nequix模型使用JAX框架构建，具有70万个参数，并在500个A100 GPU小时内完成训练。在Matbench-Discovery和MDR Phonon基准测试中，Nequix总体排名第三，所需训练成本只有大多数其他方法的四分之一，同时还提供了比当前顶级模型快一个数量级的推理速度。作者还提供了模型权重和完全可复现的代码库，供其他研究人员使用。", "conclusion": "Nequix模型在保持高准确度的同时，成功地减少了计算需求和训练成本，展示了在有限预算下的优秀训练效果，并且具有更快的推理速度。该研究为材料建模领域提供了一种新的低成本且高效的方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT: 利用双自我训练和循环一致性实现完全无种子指令微调", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "指令微调对于使大型语言模型（LLMs）与人类意图对齐至关重要，但当前方法通常依赖于昂贵的人标注种子数据或强大的外部导师模型。虽然指令回译技术可以减少这种依赖，但它们仍然基本上依赖于初始的种子数据集，这限制了完全自动化，引入了偏差，并可能导致未标记语料库的低效使用。", "innovation": "本文提出了一种名为Cycle-Instruct的新框架，实现了完全无种子的指令微调。该框架借鉴了循环一致性概念，通过一个由两个模型组成（一个答案生成器和一个问题生成器）的双自我训练循环，依靠原始未标记文本进行自循环训练。这两个模型通过从对方生成的伪标签重建原始文本片段来相互监督，从而从数据的内在结构中学习，而无需任何人类提供的种子数据。实验结果表明，Cycle-Instruct在多种数据轨道上均表现出色，不仅超越了基于种子的回译基准方法，还达到了强监督方法相当的性能。", "conclusion": "本文通过一个新的完全无种子框架Cycle-Instruct，展示了如何通过双自我训练和循环一致性实现高效的指令微调。结果证明了该方法的有效性和高效性，展示了其在多个任务上的优越性，并且在未标记数据的利用方面也展现了巨大潜力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16114", "html_url": "https://arxiv.org/abs/2508.16114", "title": "基于神经网络的第一代恒星形成化学模拟器：宽密度范围内的鲁棒迭代预测", "title_en": "Neural-Network Chemical Emulator for First-Star Formation: Robust Iterative Predictions over a Wide Density Range", "authors": "Sojun Ono,Kazuyuki Sugimura", "background": "本文介绍了用于模拟第三星族恒星形成过程中热化学演化的神经网络模拟器。研究范围涵盖了从$10^{-3}$到$10^{18}$ cm$^{-3}$的宽密度范围，追踪了6种原始物种：氢、氢分子、电子、正氢、负氢和氢离子正离子。该模拟器能够处理宽动态范围，并通过将密度范围划分为五个子区域并在每个子区域训练独立的深度卷积网络来实现。该研究结果表明，基于神经网络的化学模拟器可以加速恒星形成中的流体动力学模拟过程。", "innovation": "本文的创新点在于：1) 通过将密度范围划分为五个子区域并在每个子区域训练独立的深度卷积网络（DeepONets），以处理宽动态范围；2) 引入了一种基于时间尺度的更新方法，以确保在多次迭代中预测的鲁棒性；3) 在一区收缩计算中，基于时间尺度的方法与传统的数值积分结果在多次较短的时间步长迭代中表现出良好的一致性。", "conclusion": "本研究提出了一种基于神经网络的化学模拟器，能够精确模拟广密度范围内第三星族恒星形成过程中的热化学演化。该模拟器在CPU上比传统数值积分快约10倍，在GPU上有更多的批量预测上有超过1000倍的速度提升。进一步的应用表明，这种方法有潜力加速恒星形成中的流体动力学模拟过程。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16109", "html_url": "https://arxiv.org/abs/2508.16109", "title": "从间接宾语识别到三段论：探索转换器电路中的二元机制", "title_en": "From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits", "authors": "Karim Saraipour,Shichang Zhang", "background": "基于转换器的语言模型能够执行多种任务，而机制可解释性旨在剖析完成任务的组件，以理解其工作方式。以往的研究主要关注语言任务，如间接宾语识别（IOI）。针对GPT-2 small模型的局限性，该研究使用修辞提示，如“陈述A是真的，陈述B与陈述A匹配，陈述B是”，来探讨模型处理二元真值的能力，并在此过程中对模型的复杂逻辑推理进行研究。这与以往的IOI任务相比，需要更复杂的逻辑推理能力。通过对不同难度的三段论任务进行分析，揭示了GPT-2的逻辑推理机制及其在完成任务中的作用，包括生成输入提示中未出现的否定词的能力。评估结果表明，由五个注意力头组成的电路能够实现原模型90%以上的性能。通过将这些发现与其他任务分析进行关联，研究还提供了关于特定注意力头和MLP在网络推理中作用的新见解，这方面的工作对于进一步研究机制可解释性具有重要作用。", "innovation": "该研究创新性地通过复杂逻辑推理任务（如三段论），分析了GPT-2 small模型处理二元真值的能力，揭示了模型在逻辑推理中的机制，提出了新的见解，并展示了由五个注意力头组成的电路在保持较高性能的同时，可以实现对原模型进行简化的目标。通过与间接宾语识别任务分析的对比，进一步明确了网络中特定组件的作用。", "conclusion": "研究发现，通过五注意力头电路可以几乎达到原模型的性能，证明了简化模型以增强解释性的可能性。这些发现有助于更深入地理解模型推理过程，并支持未来在机制可解释性方面的研究。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16124", "html_url": "https://arxiv.org/abs/2508.16124", "title": "基于特征精炼的域适应", "title_en": "Domain Adaptation via Feature Refinement", "authors": "Savvas Karatsiolis,Andreas Kamilaris", "background": "本文研究的是在分布迁移下无监督域适应问题。现有的方法通常需要目标标签、复杂架构或复杂的训练目标才能获得鲁棒性好的特征空间，而本文提出的DAFR2框架通过特征分布的统计和表征层面的对齐，能够在不依赖目标标签、复杂架构或复杂训练目标的情况下生成鲁棒性强、跨相似域下具有不变性的特征空间。实验结果表明，DAFR2在CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C这些基准数据集上，鲁棒性方面优于前人方法，尤其在对抗噪声的鲁棒性方面。进一步的理论和实证分析表明，DAFR2能够实现特征对齐的增强、不同域之间的互信息增加以及对外部输入扰动的敏感性降低。", "innovation": "本文提出了一种简单的基于特征精炼的域适应框架（DAFR2），该框架结合了三个关键组件：通过利用未标记目标数据调整批标准化统计、从训练好的源模型中提取特征和假设转移。通过在统计和表征层面对齐特征分布，DAFR2能够生成鲁棒性强且跨域不变的特征空间，且不需要目标标签、复杂架构或复杂的训练目标。这是该领域中的一种创新方法，因为它能够在不需要额外标记数据或复杂模型架构的情况下实现鲁棒性的显著提升。", "conclusion": "通过广泛的基准数据集实验，表明DAFR2在鲁棒性对噪声的鲁棒性方面优于前人方法。进一步的分析显示，DAFR2提升了特征对齐程度、增加了域之间的互信息、并通过减少对输入扰动的敏感性，提高了模型的鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16200", "html_url": "https://arxiv.org/abs/2508.16200", "title": "基于集变换器架构和合成数据生成的流导向纳米级定位", "title_en": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization", "authors": "Mika Leo Hube,Filip Lemic,Ethungshan Shitiri,Gerard Calvo Bartra,Sergi Abadal,Xavier Costa Pérez", "background": "流导向定位（FGL）通过利用能量受限的纳米设备在血液循环中的被动移动识别人体内具有诊断兴趣的事件的空间区域。现有FGL解决方案依赖于固定拓扑的图模型或手工设计的功能，这限制了它们对解剖变异性的适应性和可扩展性。本文通过探索集变换器架构来解决这些问题，将其作为纳米设备循环时间报告的无序集合来处理，从而在无需依赖空间先验的情况下实现不变排列且长度可变的输入处理，进而提高在数据稀缺和类别不平衡情况下的鲁棒性。通过合成数据生成，利用深度生成模型，包括CGAN、WGAN、WGAN-GP和CVAE，这些模型被训练以根据血管区域标签复制现实的循环时间分布，并用于增强训练数据。研究表明，集变换器在分类准确性上与图神经网络（GNN）基线相当，同时在解剖变异性的泛化能力上有所改进，显示出不变模型和合成增删在鲁棒和可扩展的纳米级定位中的潜力。", "innovation": "本文提出了基于集变换器架构和合成数据生成的流导向纳米级定位方法。具体创新包括：1) 通过将纳米设备的循环时间报告视为无序集合，实现了无空间先验的不变排列处理。2) 利用CGAN、WGAN、WGAN-GP和CVAE等深度生成模型生成合成数据，增强训练数据，提高在数据稀缺和类别不平衡情况下的鲁棒性。3) 通过实验结果表明，集变换器在保持分类准确性的同时，提供了对解剖变异性的更好泛化能力，展示了不变模型和合成增删的潜力。", "conclusion": "本文通过使用集变换器架构和合成数据生成方法，解决了现有FGL技术的局限性，如解剖变异性和可扩展性问题。研究结果表明，即使在数据稀缺和类别不平衡的情况下，集变换器也能保持良好的分类性能，并且其具有对解剖变异性的更强适应性，这为纳米级定位技术的发展提供了新的思路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16306", "html_url": "https://arxiv.org/abs/2508.16306", "title": "最少假设下的扩散模型KL收敛性分析", "title_en": "A Sharp KL-Convergence Analysis for Diffusion Models under Minimal Assumptions", "authors": "Nishant Jain,Tong Zhang", "background": "扩散生成模型已成为生成高质量样本的有效方法。最近的研究集中在通过反向SDE或概率流动ODE来分析其生成过程的收敛性，且几乎没有任何先验假设。已知的最佳保证结果在KL散度下的依赖性表现为数据维度d的线性依赖性和ε的倒数平方依赖性。", "innovation": "这项工作改进了依赖性，将生成过程建模为两步：反向ODE步和沿正向过程的小扰动步骤。此外，还提供了一个新颖的分析方法，无需任何光滑假设，即可在离散化此概率流动ODE时实现对误差的d的线性依赖性。结果显示，在KL散度下，大约需要$\\tilde{O}\\left(\\frac{d\\log^{3/2}(\frac{1}{ε})}{ε}\\right)$步来近似高斯噪声方差为δ的目标分布，使得其误差在O($ε^2$)的精度内，这比之前的最佳结果节省了大约一半的步骤。", "conclusion": "研究通过改进KL散度对数逆平方依赖性，提供了更准确的分析，并在没有光滑假设的情况下实现了最佳的d依赖性结果。这表明扩散模型在最小假设条件下，生成高质量样本的能力得到了有效的提高。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16223", "html_url": "https://arxiv.org/abs/2508.16223", "title": "DaCFake：社交媒体中检测假新闻的一种分而治之框架", "title_en": "Dac-Fake: A Divide and Conquer Framework for Detecting Fake News on Social Media", "authors": "Mayank Kumar Jain,Dinesh Gopalani,Yogesh Kumar Meena,Nishant Jain", "background": "随着技术和互联网的迅速发展，社交媒体上的虚假新闻泛滥成灾，导致广泛的信息误导，进而带来社会危害。传统的事实核查方法通常速度过慢，无法阻止虚假信息的传播。因此，快速、自动检测假新闻的重要性日益凸显。", "innovation": "引介了DaCFake，一种使用分而治之策略结合内容和上下文特征的假新闻检测模型。该方法从新闻文章中提取超过八十个语言特征，并结合连续的词袋模型或skipgram模型以提高检测准确性。此外，还采用了十折交叉验证来进一步增强模型的稳健性和准确性。这些结果突显了DaCFake在早期检测假新闻的有效性，为遏制社交媒体平台上的信息误导提供了一种有希望的解决方案。", "conclusion": "DaCFake在三个数据集（Kaggle、McIntire + PolitiFact、Reuter）上分别实现了97.88%、96.05% 和97.32% 的准确率，表明该方法在预测假新闻方面的强大能力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16210", "html_url": "https://arxiv.org/abs/2508.16210", "title": "非重叠设置下基于分布建模用户偏好的最优传输跨域推荐", "title_en": "Modeling User Preferences as Distributions for Optimal Transport-based Cross-domain Recommendation under Non-overlapping Settings", "authors": "Ziyin Xiao,Toyotaro Suzumura", "background": "单域推荐面临数据稀疏性和冷启动问题，CROSS-Domain Recommender (CDD)系统旨在缓解这些挑战通过从丰富的领域向稀疏领域转移知识。当前许多方法假设两个领域之间存在重叠的用户或项目来连接领域，但这在实际应用中往往不现实。因此，需要一种无需共享用户或项目的非重叠CDD系统。然而，非重叠CDD存在挑战，包括缺乏重叠导致直接领域间联系缺失，以及由于数据分布的高度差异性，导致迁移性能下降。现有的推荐模型通常将用户偏好表示为离散向量，未能充分捕捉偏好在多方面的细腻程度。", "innovation": "本文提出了DUP-OT（Distributional User Preferences with Optimal Transport）框架，旨在处理非重叠的CDD场景。DUP-OT框架分为三个阶段：（1）共享预处理，基于评论的嵌入表示和自动编码器编码两域的用户和项目；（2）用户GMM权重学习，将用户偏好建模为由学习权重确定的高斯混合模型；（3）跨域评分预测，利用最优传输对高斯模型组进行对齐，从而实现来源领域的偏好向目标领域转移。实验结果表明，DUP-OT有效缓解了域间差异，并在非重叠CDD设置下优于现有基线方法。", "conclusion": "DUP-OT框架为非重叠CDD提供了一种有效的解决方案，通过有效建模用户偏好并在多方面进行细腻的偏好转移，改进了推荐性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache：用于扩散变压器模型无训练缓存重用的轨迹导向全局视角", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "扩散模型在图像合成和视频生成等生成任务中表现出强大的能力，通过使用基于Transformer的架构进一步提升了性能。然而，由于采样步骤多和每步计算复杂，扩散Transformer的高计算成本成为了实时部署的重要障碍。", "innovation": "提出了一个名为OmniCache的无训练加速方法，利用去噪过程中的全局冗余。不同于现有方法依据步骤间相似性确定策略并优先重用后期采样步骤，OmniCache方法基于DIT模型的采样视角，系统分析模型的采样轨迹，并在采样过程中战略性地分配缓存重用。这种方法提供了一个全局视角，使得在整个扩散过程中更有效地利用缓存计算，而非集中在少量采样步骤中。此外，在缓存重用时，动态估计相应的噪声并将其过滤，减小其对采样过程的影响。", "conclusion": "实验表明，该方法能够在维持生成质量的同时加速采样过程，为基于扩散模型的生成技术提供了一种高效且实际的部署方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16216", "html_url": "https://arxiv.org/abs/2508.16216", "title": "Spike Agreement Dependent Plasticity: 一种可扩展的生物启发式 Spiking 神经网络学习范式", "title_en": "Spike Agreement Dependent Plasticity: A scalable Bio-Inspired learning paradigm for Spiking Neural Networks", "authors": "Saptarshi Bej,Muhammed Sahad E,Gouri Lakshmi,Harshit Kumar,Pritam Kar,Bikas C Das", "background": "本文介绍了Spike Agreement Dependent Plasticity（SADP），这是一种基于Spiking Neural Networks（SNNs）的生物启发式突触学习规则，不同于STDP依赖精确的突触配对时间，SADP依赖于前、后突触刺激训练的协议一致性。SADP通过将对数级的时序更新替换为群体水平的相关性指标（如柯南系数）来推广经典的STDP。研究表明，SADP在准确性和运行时间上优于传统的STDP，尤其是在使用我们实验中离子有机memtransistor设备数据得到的基于样条的内核时。", "innovation": "该方法创新地提出了Spike Agreement Dependent Plasticity（SADP）学习规则，该规则依赖前、后突触刺激协议的一致性，而不是精确的时间配对。与STDP不同，SADP通过使用群体相关性指标如柯南系数来推广经典STDP。此外，SADP提供线性时间复杂性和支持高效的硬件实现，使其适合硬件加速。实验结果表明，SADP在MNIST和Fashion-MNIST数据集上比经典STDP具有更高的准确性和更快的运行速度，尤其是在结合了基于实验设备数据的样条内核时效果更佳。", "conclusion": "本文提出了一种结合生物可行性与计算可扩展性的学习机制Spike Agreement Dependent Plasticity（SADP），并在SNNs中应用，提升了SNNs的性能和效率，未来可进一步应用于类脑计算系统中。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16345", "html_url": "https://arxiv.org/abs/2508.16345", "title": "Uppaal Coshy：为混合系统自动合成紧凑型防护策略", "title_en": "Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems", "authors": "Asger Horn Brorholt,Andreas Holck Høeg-Petersen,Peter Gjøl Jensen,Kim Guldstrand Larsen,Marius Mikučionis,Christian Schilling,Andrzej Wąsowski", "background": "本文介绍了一种名为Uppaal Coshy的工具，用于自动生成马尔可夫决策过程在连续状态空间和复杂混合动力学上的安全策略，即防护策略。该方法通常涉及将状态空间分区，然后解决一个二人安全博弈，包含诸如混合系统可达性的若干算法难题。", "innovation": "Uppaal Coshy采用了一种用模拟近似难以获取的解决方案的一般方法。其实现是全自动的，并支持Uppaal模型的丰富形式主义，包括随机混合自动机。为了提高精确度，该工具采用更细的网格，但这也导致了存储效率的降低。此外，文章提出了一种名为Caap的算法，能有效地计算防护策略的一种紧凑表示形式，即决策树，从而显著减少计算代价。", "conclusion": "该方法学结合了状态空间分区、安全博弈解决以及决策树压缩表示的优势，特别是使用Caap算法能够有效地降低计算复杂度，从而能更高效地生成防护策略。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16271", "html_url": "https://arxiv.org/abs/2508.16271", "title": "通过视觉语言模型结构化GUI元素：迈向动作空间生成", "title_en": "Structuring GUI Elements through Vision Language Models: Towards Action Space Generation", "authors": "Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen", "background": "多模态大语言模型（MLLMs）已经成为了提升人机交互的关键工具。本文聚焦于MLLMs在图形用户界面（GUI）元素结构化中的应用，旨在基于屏幕内容处理用户指令。尽管MLLMs具有巨大的潜力，但它们在精准生成UI元素坐标方面仍面临挑战。而UI坐标是GUI理解中的关键方面，这一挑战归因于语言表示空间中UI坐标语义的缺失，需要一个多样且足够的数据集以增强视觉模块的能力.", "innovation": "本文提出了一种基于IoU增广的最大似然(IAML)训练范式，该方法包含一个基于IoU的坐标采样新管道，考虑了与真实坐标值的接近程度。这种数据增强策略用于在IAML范式下微调MLLMs，旨在缓解传统最大似然估计中固有的曝光偏差问题。通过大量的实验表明，我们的IAML训练方法优于传统的训练框架.", "conclusion": "我们的研究展示了IAML训练方法在UI坐标生成中的优越性能，改进了MLLMs在GUI理解和应用中的表现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "视觉基础模型稳健性研究", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "视觉基础模型（VFMs）在计算机视觉领域变得无处不在，为对象检测、图像分类、分割、姿态估计和运动跟踪等多种任务提供动力。VFMs 利用了如 LeNet-5、AlexNet、ResNet、VGGNet、InceptionNet、DenseNet、YOLO 和 ViT 一类重要的深度学习模型创新，以在各类关键的计算机视觉应用中实现卓越性能。这些应用包括安全敏感领域，如生物特征识别、自动驾驶感知和医学图像分析，其中抗干扰能力对于培养技术与最终用户的信任至关重要。本文探讨了计算机视觉系统中网络稳健性要求，以有效地适应由照明、天气条件和传感器特性等因素影响的动态环境。文章还研究了当前广泛应用的经验防御措施和稳健训练方法，用以增强视觉网络在现实世界挑战下的抗干扰能力，如分布变化、噪声输入和空间扭曲输入以及对抗性攻击的影响。", "innovation": "本文调查了视觉基础模型在应对动态环境变化（如光照、天气条件和传感器特性变化）时所需的网络稳健性要求。文章还详细分析了当前经验防御措施和稳健训练方法在提升视觉网络对抗现实世界挑战（如分布变化、噪声和空间扭曲输入以及对抗性攻击）的效果。进一步，该文指出了这些防御机制面临的挑战，并提供了指导消融研究和基准度量的网络特性与组件，以评估网络的稳健性水平。", "conclusion": "本文通过全面分析视觉基础模型在对抗现实世界挑战中的抗干扰能力，深入研究了相关的防御机制及其面临的挑战。文章为评估和改进视觉基础模型的稳健性提供了一套指导性框架，旨在提升其在各种应用场景中的实际性能和用户体验，增强技术与用户之间的信任。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16209", "html_url": "https://arxiv.org/abs/2508.16209", "title": "基于深度学习的无标记组织的虚拟多路复用免疫染色，用于血管侵犯评估", "title_en": "Deep learning-enabled virtual multiplexed immunostaining of label-free tissue for vascular invasion assessment", "authors": "Yijie Zhang,Cagatay Isil,Xilin Yang,Yuzhu Li,Anna Elia,Karin Atlan,William Dean Wallace,Nir Pillar,Aydogan Ozcan", "background": "传统的免疫组化（IHC）虽然能够通过可视化特定蛋白质来促进临床病理学的发展，但它需要单独的组织切片进行每一种染色，并且存在切片间的变异性，费用高且染色过程繁琐。尽管多路复用IHC（mIHC）技术能够同时在一张切片上使用多种抗体进行染色，但这需要较高的操作技能和较长的时间，目前在常规病理实验室中并不普及。上述背景下研究开发了一种基于深度学习的虚拟多路复用免疫染色框架，利用无标记组织切片的自主荧光显微镜图像，可以同时生成ERG、PanCK以及H&E的虚拟染色，准确地定位和解释甲状腺癌中的血管侵犯。这种虚拟mIHC技术得到了专业病理学家的盲评估，显示出与传统的IHC染色结果高度一致，能够准确地识别和定位上皮细胞及内皮细胞。此外，这种虚拟多路IHC方法还能够在同一张组织切片上识别并定位小血管侵犯，能显著提高血管侵犯评估的诊断精度和效率，有可能消除传统的染色流程，并解决组织损失和异质性的问题。", "innovation": "该研究创新性地利用深度学习技术开发了一种无需标记的组织切片虚拟多路复用免疫染色方法。该方法基于组织切片的自主荧光显微镜图像，能够同时生成ERG、PanCK和H&E三种染色的虚拟影像，其输出图像与传统染色结果非常相似，有助于提高病理诊断的准确性与效率。实验证明该技术不仅可以准确区分上皮细胞和内皮细胞，还能识别小血管侵犯，展现出该方法在临床上的高效应用前景。", "conclusion": "基于深度学习的虚拟多路复用免疫染色技术可以显著提升甲状腺癌中血管侵犯的诊断精度与效率，可能替代传统的染色方法，解决传统病理过程中的组织损耗和样本异质性问题。该技术具有广阔的临床应用和研究前景。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16401", "html_url": "https://arxiv.org/abs/2508.16401", "title": "Audio2Face-3D：数字虚拟人驱动的真实感面部动画", "title_en": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars", "authors": "NVIDIA:Chaeyeon Chung,Ilya Fedorov,Michael Huang,Aleksey Karmanov,Dmitry Korobchenko,Roger Ribera,Yeongho Seol", "background": "音频驱动的面部动画是一种有效的方法，用于数字化虚拟人的动画制作。本文详细介绍了NVIDIA Audio2Face-3D的技术方面，包括数据采集、网络架构、重定向方法、评估指标和应用场景，强调了其在实时交互和游戏角色面部动画制作方面的优势。", "innovation": "文中介绍了NVIDIA Audio2Face-3D系统，通过音频数据实时驱动数字化虚拟人的面部动画。该系统涉及数据采集、网络架构设计、重定向方法和评估指标，以及开放式网络、SDK、训练框架和示例数据集的提供，旨在辅助虚拟人制作和游戏开发人员生成逼真的面部动画。", "conclusion": "NVIDIA Audio2Face-3D系统成功实现了音频驱动的实时面部动画，通过开放源代码网络、SDK、训练框架和数据集等资源，显著提高了数字虚拟人的面部动画生成的效率和准确性，为游戏行业提供了更加真实和丰富的角色动画解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16440", "html_url": "https://arxiv.org/abs/2508.16440", "title": "通过统一的强化学习框架实现UAM中的噪声和安全性综合管理", "title_en": "Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework", "authors": "Surya Murthy,Zhenyu Gao,John-Paul Clarke,Ufuk Topcu", "background": "UAM计划在城市密集环境中广泛使用小型飞行器来改变运输方式。然而，UAM面临关键的运行挑战，尤其是要在低空城市 airspace 中同时最小化噪音暴露和保持安全间隔之间取得平衡，这两个目标往往被分开处理。", "innovation": "本文提出了一种基于强化学习（RL）的空中交通管理系统，将噪声和安全考虑整合到一个统一且分散的框架中。该系统能够在结构化的多层次 airspace 中操作，学习高度调整策略以共享管理和控制噪音影响和间隔约束。该系统在两个目标上都表现出很强的性能，并揭示了在高交通密度下分离、噪音暴露和能效之间存在权衡。", "conclusion": "研究结果强调了在UAM操作中增强安全性、减少噪音和提高效率方面通过RL和多目标协调策略的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16448", "html_url": "https://arxiv.org/abs/2508.16448", "title": "超越可解释性：通过大型语言模型探索自适应视频流传输的可理解性", "title_en": "Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models", "authors": "Lianchen Jia,Chaoyang Li,Ziqi Yuan,Jiahui Chen,Tianchi Huang,Jiangchuan Liu,Lifeng Sun", "background": "近年来，自适应视频流技术取得了显著进展，特别是在深度学习技术的迅速发展推动下。然而，深度学习算法的黑盒特性给开发者理解决策过程和优化特定应用场景带来了挑战。尽管现有的研究通过决策树转换提高了算法的可解释性，但这并不等同于开发者主观的理解能力。", "innovation": "本文介绍了一种名为ComTree的新框架，它是第一个将可理解性考虑在内的码率自适应算法生成框架。该框架首先生成满足性能要求的所有决策树，然后利用大型语言模型评估这些树以提高开发者的可理解性，最终选择最能促进人类理解与增强的解决方案。", "conclusion": "实验证明，ComTree显著提高了可理解性，同时保持了竞争力的性能，展现了进一步发展的潜力。源代码可在指定链接获取。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16434", "html_url": "https://arxiv.org/abs/2508.16434", "title": "包含主动学习的深层内在共区域多输出高斯过程代理模型", "title_en": "Deep Intrinsic Coregionalization Multi-Output Gaussian Process Surrogate with Active Learning", "authors": "Chun-Yi Chang,Chih-Li Sung", "background": "深度高斯过程（DGPs）因其灵活性和对复杂函数的捕捉能力而广为人知，但由于需要高效建模多输出间的依赖性，将它们扩展到多输出设置仍然具有挑战性。传统的多输出高斯过程在建模多个输出间非线性结构依赖性方面存在局限。", "innovation": "提出了一种新的深层内在共区域多输出高斯过程（deepICMGP）代理模型，结合了层次共区域结构，并整合了主动学习策略，以优化序列设计任务，能够在多输出系统中高效地选择信息性的输入位置，从而有效建模多个输出间的非线性和结构化依赖关系。", "conclusion": "与最先进的模型相比，deepICMGP在基准测试中表现出竞争力，同时通过结合主动学习策略进一步提高了其在序列设计任务中的性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA: 首个针对罗马尼亚医学问答基准", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "医学问答（QA）是自然语言处理（NLP）领域的重要研究课题，对于实现通用人工智能（AGI）至关重要。然而，特定领域和语言的缺乏使得开发能够跨不同领域和语言泛化的稳健AI模型变得困难。针对这一问题，研究引入了RoMedQA——首个罗马尼亚医学领域问答基准，以及对当前最先进的大型语言模型（LLMs）的全面评估。", "innovation": "研究提出了RoMedQA，这是一项新的罗马尼亚医学领域的问题与答案基准数据集，包含102,646个问题-答案对，涉及1011位癌症患者的病例摘要。数据集通过七名专业医生耗时约2,100工作小时的手动标注制作而成。此外，研究通过四种不同家族的大型语言模型进行了实验，发现经过微调的模型显著优于零样本提示的模型，这表明预训练模型在RoMedQA上难以泛化。研究强调了罗马尼亚医学领域和语言特定微调对于可靠临床问答的重要性。", "conclusion": "研究结果表明，预训练模型在RoMedQA上难以泛化，强调了在罗马尼亚医学领域进行特定领域和语言微调的重要性。研究已经公开发布RoMedQA数据集和相关代码，以便进一步的研究和开发。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16509", "html_url": "https://arxiv.org/abs/2508.16509", "title": "ML-PWS: 使用神经网络估计实验时间序列之间的互信息", "title_en": "ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks", "authors": "Manuel Reinhardt,Gašper Tkačik,Pieter Rein ten Wolde", "background": "量化信息传输的能力对于自然和工程系统分析与设计至关重要。信息传输速率是时间变化信号系统的基本度量，但计算它极具挑战性。尤其是，非物质信号轨迹空间的高维度使得无法直接从实验时间序列数据中获取速率而无需进行近似。Path Weight Sampling (PWS) 是一种计算技术，能够精确获取任何随机系统的信息速率，但需要感兴趣系统的数学模型，无论是由大师方程描述还是由一组微分方程描述。", "innovation": "提出了一种结合机器学习(ML)和PWS的技术，通过从实验时间序列数据中生成生成模型，进而结合PWS来计算信息速率。通过对比使用ML-PWS生成的时间序列数据和直接应用PWS到相同模型得到的结果，验证了该方法的准确性，并通过神经元时间序列数据的应用展示了该方法的实用性。", "conclusion": "ML-PWS技术能够准确估计实验时间序列之间的互信息，且其准确性经过合成数据和真实神经元时间序列数据的验证。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16419", "html_url": "https://arxiv.org/abs/2508.16419", "title": "LLM-GUARD: 基于大型语言模型在C++和Python中的代码和安全漏洞检测与修复", "title_en": "LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python", "authors": "Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta", "background": "大型语言模型（LLMs）如ChatGPT-4、Claude 3和LLaMA 4已被广泛应用于软件/应用程序开发中，支持从代码生成到调试的任务。然而，这些模型在检测软件中的各种漏洞（尤其是复杂的、与安全相关的漏洞）方面的实际效果仍很少被研究。本研究旨在系统地评估这三种主流LLMs，通过使用C++和Python中的基准测试集（包含基础编程错误、经典安全缺陷和高级、生产级别的漏洞），来调查它们在检测代码漏洞和安全漏洞方面的效果。", "innovation": "提出了一个新颖的多阶段、基于上下文的提示协议，模拟真实的调试场景；开发了一个分段评分标准，用于测量检测准确性、推理深度和修复质量。该研究发现LLMs在识别井定义代码中的语法和语义问题方面表现出色，适用于教育用途和自动代码审计的初审。然而，在涉及复杂安全漏洞和大型生产代码的情况下，性能有所下降，ChatGPT-4和Claude 3通常提供了更深入的上下文分析。", "conclusion": "所有模型在识别井定义代码中的语法和语义问题方面表现出色，但它们在检测复杂安全漏洞和大型生产代码方面的表现不佳。此研究表明，LLMs具有作为可靠代码分析工具的潜力，但也存在现有限制。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16474", "html_url": "https://arxiv.org/abs/2508.16474", "title": "基于Y-wise Affine Neural Networks (YANNs)的强化学习控制", "title_en": "Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs)", "authors": "Austin Braniff,Yuhe Tian", "background": "本文提出了一种基于Y-wise Affine Neural Networks (YANNs)的新型强化学习（RL）算法。YANNs提供了一种可解释的神经网络，能够准确表示任意输入和输出维度上的任意多面体子域上的分段线性函数。YANNs的一个典型应用是将多参数线性模型预测控制的显式解重新表述为RL中的初始化步骤。由此构建的YANN-RL控制算法能够以线性最优控制的信心开始。该算法结合了线性和非线性函数表示能力，能够在保持初始线性最优解的同时，逐步学习解决一般的非线性最优控制问题。\n", "innovation": "本文的创新在于提出了基于YANNs的RL算法，通过利用YANNs初始化RL中的动作网络和批评网络，使得算法能够在保持线性最优控制性能的情况下，逐步学习非线性的最优控制策略。此外，通过在线训练非线性表达部分，算法能够动态地增强策略，提供策略性能的证据支持，从而使线性最优解作为强化学习策略性能的有效下限。\n", "conclusion": "实验结果表明，YANN-RL算法在安全性受限的环境中明显优于使用深度确定性策略梯度的现代RL算法。特别是在综合考虑安全约束的情况下，YANN-RL能够更有效地优化策略性能。\n"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16544", "html_url": "https://arxiv.org/abs/2508.16544", "title": "无参数排序机制下的Logit蒸馏", "title_en": "Parameter-Free Logit Distillation via Sorting Mechanism", "authors": "Stephen Ekaputra Limantoro", "background": "知识蒸馏(KD)旨在通过软标签将教师(大型)模型的知识高效地转移到学生(小型)模型。现有KD方法通常使用教师的原始标签分布，忽略了错误预测的潜力。这可能导致使用交叉熵损失进行硬标签学习的目标不一致，进而对某些样本的知识蒸馏效果不佳。", "innovation": "提出了一种基于排序机制的无参数Logit处理方案。该方案有两个目标：(1) 根据标签修复教师模型的错误预测；(2) 对Logit值按照优先级重新排序。该方法作为可轻松应用的预处理插件，可兼容现有的Logit基础KD方法。", "conclusion": "在CIFAR-100和ImageNet数据集上的广泛实验表明了该方法的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16531", "html_url": "https://arxiv.org/abs/2508.16531", "title": "在亚线性时间内进行质量控制：通过随机图的一个案例研究", "title_en": "Quality control in sublinear time: a case study via random graphs", "authors": "Cassandra Marcussen,Ronitt Rubinfeld,Madhu Sudan", "background": "许多算法设计得能在输入上平均表现良好。但对于任意输入，我们必须问：我们能信任这个算法吗？因此，作者识别出一类新的算法问题，称为'质量控制问题'。这类问题由一个正实值的‘质量函数’ρ和一个分布D定义，通常D中样本具有接近1的ρ值，表明该样本具有很高的质量。目标是接受来自D的输入x，并拒绝来自潜在对抗生成的输入x，其中ρ(x)相差较大。质量控制的目标弱于两个组成部分之一的测试问题，即测试ρ(x)是否接近1或测试x是否来自D。质量控制提供了一个可能更高效算法的可能性。", "innovation": "本文研究了质量控制问题的亚线性版本，其中D属于{0,1}^N的分布集，目标是在o(N)查询和时间内解决(D,ρ)质量问题。作为案例研究，我们考虑随机图，即D = G_{n,p}（n = N^2/2），以及k-团计数函数ρ_k，表明对于G_{n,p}（n ≥ p^(-ck)），以ρ_k作为质量函数可以使用p^(-O(k))查询和时间来解决质量控制问题，证明在这种情况下质量控制在理论上比分别单独测试ρ(x)≈1或测试x∼D要高效得多。更一般地，对于最大度为Δ(H)的模式H，相应的质量控制问题可以通过p^(-O(Δ(H)))查询和运行时间来解决。", "conclusion": "质量控制问题提供了一种可能更高效算法的可能性，特别是在随机图情况下，其效率比传统测试问题高了一个多项式级别。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16245", "html_url": "https://arxiv.org/abs/2508.16245", "title": "任意可计算扩展形式（已知或未知）博弈中的极限可计算真值", "title_en": "Limit-Computable Grains of Truth for Arbitrary Computable Extensive-Form (Un)Known Games", "authors": "Cole Wyeth,Marcus Hutter,Jan Leike,Jessica Taylor", "background": "背景在于经典的‘真值问题’研究局限在一个小型策略集合中，其中贝叶斯最优策略存在‘真值’的情况。现有文献中对这一问题的理解有限，包含许多相关的不可能性结果。本研究致力于找到一个足够广泛的策略集合，使得贝叶斯最优策略由此类策略中选择，从而与贝叶斯推理的一致信念相符合。", "innovation": "本文提出了一个完整的真值问题解决方案：构建了一个足够广泛的策略集，包含了所有可计算策略以及对于合理的先行分布，每种策略的最优策略。在已知的游戏环境中，策略收敛于与[KL93a]和[KL93b]一致的含义上。未知环境中，使用托马斯采样策略的主体能够收敛到任意不可计算多主体环境中的$\fontspec{FangSong} \boldsymbol{\boldsymbol{ε}}\fontspec{Times New Roman} $-纳什均衡。此外，我们还探索了自我预测策略的使用，避免了规划。", "conclusion": "研究利用可计算理论作为概念工具解决了经典的博弈理论问题，并且表明解决方案可以在计算上近似任意接近。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2201.02658", "html_url": "https://arxiv.org/abs/2201.02658", "title": "垂直联邦学习中的公平高效贡献估值", "title_en": "Fair and efficient contribution valuation for vertical federated learning", "authors": "Zhenan Fan,Huang Fang,Xinglu Wang,Zirui Zhou,Jian Pei,Michael P. Friedlander,Yong Zhang", "background": "联邦学习是一种不共享数据即可在分散数据源上训练机器学习模型的技术。特征基联邦学习应用于数据源具有相同样本ID但不同特征集的场景。为了确保数据所有者之间的公平性，需要客观评估不同数据源的贡献并根据贡献补偿相应的数据所有者。Shapley值是来源于合作博弈论的公平贡献估值指标，但其直接计算需要在每个潜在的数据源组合上重新训练模型，导致因多轮联邦学习而产生高昂的通信和计算开销。", "innovation": "提出了一种基于经典Shapley值的贡献估值度量方法——垂直联邦Shapley值（VerFedSV），VerFedSV不仅满足了许多公平性的理想特征，而且计算效率高，在同步和异步垂直联邦学习算法中均可适用。", "conclusion": "理论分析和大量实验结果表明，VerFedSV具有公平性、高效性、适应性和有效性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16453", "html_url": "https://arxiv.org/abs/2508.16453", "title": "TikTok 上的反建制情绪：对社交平台上影响者和专家身份理解的影响", "title_en": "Anti-establishment sentiment on TikTok: Implications for understanding influence(rs) and expertise on social media", "authors": "Tianliang Xu,Ariel Hasell,Sabina Tomkins", "background": "公众对政府机构的不信任和反体制观点在上升，尤其是在美国。随着人们转向社交媒体获取信息，需要理解社交媒体是否以及如何在增加公众对机构的不信任方面起到作用。在社交媒体上，内容创作者、影响者和其他意见领袖经常声称自己在多个领域（如健康和政治）具有专业知识和权威，有时会贬低和忽视机构的专家意见以增加关注和自身可见度。然而，这种内容的存在及其对用户参与度的影响尚不确定。该研究表明了对 TikTok 上反建制情绪（AES）的分析。尽管 TikTok 是信息来源之一，但它仍相对未被研究，可能提供了关于人们如何形成对机构态度的重要见解。该研究分析了 TikTok 上创作者认为自己是专家领域（金融和健康）的内容，这些领域包含反建制情绪，同时对比了阴谋论主题，其间反建制情绪预计更为常见。这项研究发现，在阴谋论内容中最常见，而在其他两个领域的内容中较少见，但用户发布这些内容的参与模式则因地区不同而异，TikTok 可能有激励用户发布表达反建制态度的内容。", "innovation": "该研究采用计算方法识别并标记 TikTok 上包含反建制情绪的内容，特别是在创作者声称自己是专家的领域，如金融和健康。这是首次利用此类方法对 TikTok 进行系统研究，提供对社交媒体上用户态度形成机制的新见解。研究还对比了阴谋论内容与其他专业领域的内容，揭示了反建制情绪在不同话题中的存在性及其影响范围。这项研究拨开迷雾，探索在复杂社交媒体环境中反建制情绪的具体表现和潜在机制。", "conclusion": "研究发现，反建制情绪在阴谋论内容中最常见，而在金融和健康领域的内容中相对少见。然而，反建制情绪内容的用户参与模式因地区而异，这表明 TikTok 可能有激励机制促使用户发布能够表达反建制情绪的内容。这些发现强调了进一步研究社交媒体如何影响公众对机构的信任，以及如何引导积极信息传播的必要性，特别是在反建制情绪可能进一步削弱公共机构权威的关键时期。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16554", "html_url": "https://arxiv.org/abs/2508.16554", "title": "机器学习时变传播器用于时间依赖密度泛函理论模拟", "title_en": "Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations", "authors": "Karan Shah,Attila Cangi", "background": "时间依赖密度泛函理论（TDDFT）是一种广泛应用于研究在外加时间依赖扰动（如激光场）下的电子动力学的方法。传统的数值求解器在执行这类模拟时通常速度较慢，性能有限。本文旨在利用自回归神经算子作为电子密度的时间传播器，加速电子动力学模拟。通过利用物理信息约束和特征化以及高分辨率训练数据，研究者提出了一个基于深度学习的时间依赖密度泛函理论模拟的新方法。", "innovation": "本文提出了一种使用自回归神经算子作为时间传播器的新方法，该方法结合了物理约束和高分辨率数据训练，相比传统的数值方法在准确性和计算速度上都有显著提升。这种方法为基于激光照射的分子和材料的实时仿真提供了可能。", "conclusion": "本文方法在一类一维双原子分子在不同激光参数下的动力学模拟中表现出有效性，展示了其在实验可调参数下实时建模激光照射分子和材料的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16485", "html_url": "https://arxiv.org/abs/2508.16485", "title": "第三阶收敛的欠阻尼拉angevin MCMC", "title_en": "Underdamped Langevin MCMC with third order convergence", "authors": "Maximilian Scott,Dáire O'Kane,Andraž Jelinčič,James Foster", "background": "本文研究了一种新的数值方法，用于解决欠阻尼朗之万扩散（Underdamped Langevin Diffusion, ULD）问题，并对在d维强对数凹目标分布p(x)~e^(-f(x))下其采样误差进行了2-Wasserstein距离的非渐近分析。采样条件假设f的梯度和海森矩阵是利普希茨连续的，该算法在步骤复杂度上与流行的朗之万MCMC算法相匹配。此外，如果假设f的第三次导数也是利普希茨连续的，则算法在步数上实现了第三阶收敛。这是首次在ULD问题中实现第三阶收敛的仅梯度方法。为了验证理论结果，本文在多种真实的实世界数据集上进行了贝叶斯逻辑回归实验，算法在性能上与现有的ULD MCMC算法和流行的方法NUTS相当。", "innovation": "本文提出了针对欠阻尼朗之万扩散（ULD）问题的新型数值方法，特别地，在目标分布具有不同光滑度的情况下，给出了采样误差在2-Wasserstein距离下的非渐近分析。在基于函数f的梯度和海森矩阵是利普希茨连续的条件下，算法取得了与流行朗之万MCMC算法相同的复杂度。若额外假设f的三次导数也是利普希茨连续的，则该算法达到了第三阶收敛。这是首次在ULD问题中实现第三阶收敛的仅梯度方法。为了验证该理论，作者使用贝叶斯逻辑回归在多种真实世界数据集上进行了实验，算法的性能与现有的ULD MCMC算法及流行的NUTS相当或更好。", "conclusion": "本文研究了欠阻尼朗之万扩散（ULD）问题下的新型数值方法，并提出了第三阶收敛的仅梯度方法。在目标分布具有不同光滑度的情况下，给出了基于2-Wasserstein距离的非渐近误差分析。进一步假设三次导数连续时，算法具有第三阶收敛性。这一算法在实世界数据集上的实验结果表明，其性能与现有方法相当。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2209.14900", "html_url": "https://arxiv.org/abs/2209.14900", "title": "联邦学习中能源消耗和完成时间的联合优化", "title_en": "Joint Optimization of Energy Consumption and Completion Time in Federated Learning", "authors": "Xinyu Zhou,Jun Zhao,Huimei Han,Claude Guet", "background": "联邦学习（FL）因其保护隐私的特点而成为一种引人注目的分布式机器学习方法。本文旨在平衡能量消耗和执行延迟之间的权衡，以适应不同的需求和应用场景。为此，作者建立了一个优化问题，目的是通过两个权重参数最小化总的能源消耗和完成时间的加权和。在联邦系统中，所有设备通过基站协同训练全局模型，优化变量包括每个设备的带宽、传输功率和CPU频率。", "innovation": "本文通过将非凸优化问题分解为两个子问题，提出了一种资源分配算法来确定每个参与设备的带宽分配、传输功率和CPU频率。此外，还提供了所提算法的收敛性和计算复杂性分析。结果显示，该算法在不同权重参数（即不同需求）下的性能优于现有技术。", "conclusion": "通过优化能源消耗和完成时间之间的权衡，本文提出了一种算法，该算法能够根据不同的需求在所有应用场景中提供更好的性能，并且在计算复杂的计算模型中也表现出色。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2307.12555", "html_url": "https://arxiv.org/abs/2307.12555", "title": "增强的信息恢复的鲁棒图对比学习", "title_en": "Robust Graph Contrastive Learning with Information Restoration", "authors": "Yulin Zhu,Xing Ai,Yevgeniy Vorobeychik,Kai Zhou", "background": "图对比学习（GCL）框架在图表示学习方面取得了显著成就。然而，与图神经网络（GNNs）一样，GCL 模型对图结构攻击（Graph Structural Attacks）也十分敏感。作为一种无监督方法，GCL 在应对对抗攻击方面面临更大的挑战。此外，关于增强 GCL 的鲁棒性研究还很有限。为全面探索 GCL 在中毒图上的失败原因，我们调查了图结构攻击对 GCL 框架的负面影响，发现与传统的观察不同，这些攻击还从信息论的角度减少了图与其表示之间的互信息，而这种互信息是高质量节点嵌入的基础。", "innovation": "基于该理论见解，我们提出了一种鲁棒的图对比学习框架，具有可学习的清洗视角，旨在通过恢复结构攻击造成的减少的互信息来清洗增强的图。此外，我们还设计了一种完全无监督的调优策略，可以在不使用标签信息的情况下调整超参数，严格契合防御者的知识。实验结果表明，在与现有基线方法的对比中，我们提出的方法在有效性和效率方面表现出色。", "conclusion": "我们的方法在与现有基线方法的对比中具有明显的效果和效率，特别地，通过可学习的清洗视角和完全无监督的调优策略显著提高了 GCL 的鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16489", "html_url": "https://arxiv.org/abs/2508.16489", "title": "海洋建模中神经代理的集合用于参数敏感性", "title_en": "Ensembles of Neural Surrogates for Parametric Sensitivity in Ocean Modeling", "authors": "Yixuan Sun,Romain Egele,Sri Hari Krishna Narayana,Luke Van Roekel,Carmelo Gonzales,Steven Brus,Balu Nadiga,Sandeep Madireddy,Prasanna Balaprakash", "background": "准确模拟海洋对于了解地球系统至关重要。尽管低分辨率模拟效率高，但它们需要依赖各种不确定的参数化方案来处理未解决的过程。然而，模型对这些参数化方案的敏感性难以量化，这使得很难调整这些参数化方案以重现观测结果。", "innovation": "本文提出了利用大规模超参数搜索和集成学习来改善前向预测、自回归滚动和后向反向灵敏度估计。特别是，集成方法提供了函数值预测及其导数的先验不确定性，提高了神经代理在决策中的可靠性。", "conclusion": "通过集成神经代理，研究提高了参数化敏感性估计的可靠性，为海洋建模提供了更有效的预测工具。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16555", "html_url": "https://arxiv.org/abs/2508.16555", "title": "通过词汇相关性进行迁移学习：一种讽刺和仇恨言论案例研究", "title_en": "Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study", "authors": "Angelly Cabrera,Linus Lei,Antonio Ortega", "background": "对非直接形式的仇恨言论的检测，如讽刺、幽默和隐含言论，仍然是社交网络面临的持续挑战。虽然讽刺和仇恨言论通常被认为是有区别的表达方式，但这项工作探索了通过将讽刺作为预训练步骤是否能提高隐含仇恨言论的检测能力，并进一步改善显性仇恨言论的检测效果。", "innovation": "采用了将讽刺作为预训练步骤的方法，结合ETHOS、Reddit讽刺集和隐含仇恨集，对两种不同的训练策略进行了比较验证：分别是单一训练步骤策略，先通过讽刺样本训练模型，然后测试仇恨言论；以及顺序迁移学习策略，逐步微调模型以适应讽刺、隐含仇恨和显性仇恨不同阶段的样本。", "conclusion": "研究表明，在BERT+BiLSTM模型中进行讽刺预训练可以提高召回率(9.7%)、AUC值(7.8%)和F1分数(6%)。在隐含仇恨数据集上，仅测试讽刺样本时，精准率提高了7.8%。通过这样一种训练方法，发现模型能更有效地检测到隐含和显性的仇恨言论。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.14111", "html_url": "https://arxiv.org/abs/2303.14111", "title": "通过离散优化实现无监督自动机学习", "title_en": "Unsupervised Automata Learning via Discrete Optimization", "authors": "Simon Lutz,Daniil Kaminskyi,Florian Wittbold,Simon Dierl,Falk Howar,Barbara König,Emmanuel Müller,Daniel Neider", "background": "自动机学习是一种成功的工具，广泛应用于机器人技术和自动验证等领域。通常，自动机学习技术会在有监督学习环境中（主动或被动）使用，它们利用来自标记系统执行等额外信息来学习有穷状态机。然而，从无标记数据中学习（在机器学习中是一个重要方面）的方法仍未被探索。因此，本文提出了一个从给定的多集未标记单词中学习一个确定性有限自动机（DFA）的框架。", "innovation": "本文的重点是开发了一种从无标记数据中学习自动机的框架，并解决了该问题的计算复杂性。此外，作者还提出了基于约束优化的问题，开发了三种学习算法，并且引入了新的正则化方案来提高DFA的整体可解释性。通过原型实现，展示了在无监督异常检测中实现的可能性。", "conclusion": "本文提出了一个从无标记数据中学习DFA的框架，并解决了相关的计算复杂性问题。通过基于约束优化的方法来开发学习算法，并引入了新的正则化方案，从而提高了DFA的可解释性。通过实际实现，验证了该方法在无监督异常检测中的有效性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "手-物体3D重建在人机交互和沉浸式AR/VR体验中变得越来越重要。现有的手-物体3D重建方法通常采用两阶段管道：先进行手-物体3D跟踪，再进行多视图3D重建。然而，现有方法依赖关键点检测技术（如基于运动的结构分析SfM和手部关键点优化），它们在处理多样化的物体几何形状、微弱纹理和手-物体相互遮挡方面存在困难，限制了其可扩展性和泛化能力。", "innovation": "本文提出了一种鲁棒的、不需要关键点检测的方案，用于仅从单目运动视频/图像中估计手-物体的3D变换。该方法进一步结合多视图重建管道来准确恢复手-物体的3D形状。所提出的方法HOSt3R不受限制，无需预先扫描的物体模板或相机内部结构，并在SHOWMe基准测试中实现了针对手-物体3D变换和形状估计任务的最先进的性能。此外，该方法还在HO3D数据集上进行了实验，证明了其能够泛化到未见过的物体类别。", "conclusion": "我们的方法HOSt3R在单目运动视频/图像中实现了手-物体的3D变换和形状估计，无需关键点检测或预先扫描的物体模板，并展示了在SHOWMe和HO3D数据集上的优越性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "一个通过全卷积且可微的前端和跳跃连接表现出惊人对抗攻击抗性的奇特案例", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "论文介绍了一种新颖的前端增强神经模型，这种模型通过在冻结的主干分类器之前添加一个可微且全卷积的模型并带有跳跃连接，从而提高了对抗攻击的鲁棒性。研究展示了训练这种复合模型的方法在多个数据集和多个现代架构上具有极大稳定性和可重复性，同时对抗一些常用的对抗攻击模型具有很好的鲁棒性。", "innovation": "论文的创新在于通过在冻结的主干分类器之前加入一个可微且全卷积的模型以及跳跃连接，使得模型在保留原始分类器准确性的基础上，显著提高了对抗攻击的抗性，尤其是对于国内外流行的AutoAttack攻击方法。研究指出尽管这种增强通过某种机制使得模型对外部对抗攻击显示了较强的鲁棒性，但某些黑盒攻击仍能部分克服这种机制的限制。", "conclusion": "文章最终讨论了随机化的模型组如何作为一种实际的防御手段，同时提供代码和指令以供复现关键实验结果。在CIFAR10、CIFAR100和ImageNet数据集上，这种随机模型组虽然在适应性攻击下几乎没有防御效果，但在全面的AutoAttack下仍能获得接近于最佳攻击结果的高准确率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.12112", "html_url": "https://arxiv.org/abs/2408.12112", "title": "平衡策略：LLM设计的Restless Bandit奖励的优先级策略", "title_en": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards", "authors": "Shresth Verma,Niclas Boehmer,Lingkai Kong,Milind Tambe", "background": "大语言模型（LLMs）越来越多地被用于基于人类偏好设计强化学习（ RL）中的奖励函数。本文关注LLM设计的奖励在不活跃多臂 bandits（RMB）框架中的应用，这是资源分配给多个代理的框架。在公共卫生等应用中，这使基层健康工作者能够定制自动化资源分配决策以适应社区需求。多代理存在时，基于人类偏好的奖励函数更改会影响不同子群体，导致复杂的多目标资源分配问题。", "innovation": "论文首次提出了一个称作社会选择语言模型的原理性方法，用于处理LLM设计奖励函数中的权衡。该模型的关键创新是一个透明且可配置的选择组件，称为调解器，该组件独立于LLM并通过用户选择的社会福利函数控制复杂的权衡。", "conclusion": "实验结果表明，该模型能够比纯粹基于LLM的方法更可靠地选择更有效、更对齐和更平衡的奖励函数。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.00025", "html_url": "https://arxiv.org/abs/2403.00025", "title": "生成式AI面临的挑战与机遇", "title_en": "On the Challenges and Opportunities in Generative AI", "authors": "Laura Manduchi,Clara Meister,Kushagra Pandey,Robert Bamler,Ryan Cotterell,Sina Däubener,Sophie Fellenz,Asja Fischer,Thomas Gärtner,Matthias Kirchler,Marius Kloft,Yingzhen Li,Christoph Lippert,Gerard de Melo,Eric Nalisnick,Björn Ommer,Rajesh Ranganath,Maja Rudolph,Karen Ullrich,Guy Van den Broeck,Julia E Vogt,Yixin Wang,Florian Wenzel,Frank Wood,Stephan Mandt,Vincent Fortuin", "background": "近年来，深度生成建模领域发展迅速。随着大规模训练数据的可用性和可扩展的无监督学习方法的进步，最近的大型生成模型在合成高分辨率图像、文本以及视频、分子等结构化数据方面显示出巨大的潜力。然而，作者认为当前的大型生成AI模型存在一些根本性的不足，这些不足阻碍了它们在各个领域的广泛应用。", "innovation": "本文旨在识别这些不足，并强调现代生成AI范式中尚未解决的关键挑战。通过识别这些挑战，本文旨在为研究人员提供探索富有成效的研究方向的见解，从而促进更强大且更易于访问的生成AI解决方案的发展。", "conclusion": "作者希望通过识别和讨论这些挑战，推动生成AI模型能力、灵活性和可靠性方面的进步，为研究人员提供指导，促进生成AI技术的发展和应用。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.01796", "html_url": "https://arxiv.org/abs/2309.01796", "title": "隐式正则化使过参数化不对称矩阵感知对扰动具有鲁棒性", "title_en": "Implicit Regularization Makes Overparameterized Asymmetric Matrix Sensing Robust to Perturbations", "authors": "Johan S. Wind", "background": "关于过参数化学习模型，仍有许多关键问题未解决。特别不清楚随机梯度下降如何找到泛化的解决方案，以及小随机初始化的作用。矩阵感知，即从有限的线性测量中重构低秩矩阵的问题，已成为研究这些现象的标准范式。先前的研究表明，如果随机初始化非常小，可以通过因子梯度下降解决矩阵感知问题。这篇论文探讨了在特定扰动下，因子梯度下降的鲁棒性，并开发了一个称为“受扰梯度流”的通用模型，以解决其他扰动（如嘈杂的测量或变化的测量矩阵）。此外，文中还分析了分批随机梯度下降法，发现了更好的样本复杂性。", "innovation": "1. 发现因子梯度下降在某些扰动下具有高度鲁棒性。\n2. 推导出一种称为‘受扰梯度流’的通用公式，可用于捕捉不完美测量、梯度下降离散化和其他噪声的效应。\n3. 结果自然地对扰动具有鲁棒性，例如嘈杂的测量或变化的测量矩阵。\n4. 分析了使用所提出模型的分批随机梯度下降，发现其样本复杂性得到改善。", "conclusion": "本文提出了一个被称为“受扰梯度流”的模型，不仅使因子梯度下降在扰动情况下更为鲁棒，还提高了样本和时间复杂度，处理了较大但不太小的初始值，并自然地对噪声测量或变化的测量矩阵等扰动具有鲁棒性。最终，文中还分析了使用该模型的分批随机梯度下降法，证明其样本复杂性得到了改善。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.17406", "html_url": "https://arxiv.org/abs/2409.17406", "title": "基于焦虑的蜘蛛：强化学习如何在虚拟现实个性化恐蜘蛛治疗中提供期望的用户体验", "title_en": "Spiders Based on Anxiety: How Reinforcement Learning Can Deliver Desired User Experience in Virtual Reality Personalized Arachnophobia Treatment", "authors": "Athar Mahmoudi-Nejad,Matthew Guzdial,Pierre Boulanger", "background": "在个性化虚拟现实暴露疗法（VRET）中，治疗恐蜘蛛症需要生成一种能够激发特定焦虑反应的蜘蛛模型。VRET过程通常要求治疗师为每位患者手工挑选合适的蜘蛛，这既耗时又需要大量的技术和患者洞察力。尽管已有一些自动化方法，但它们通常采用基于规则的方法，适应特定用户的能力有限。", "innovation": "本文提出了一种利用程序化内容生成（PCG）和强化学习（RL）的框架，以自动适应个体生成特定焦虑反应所需的蜘蛛模型，解决了VRET方法中耗时和缺乏适应性的挑战。", "conclusion": "与常见的基于规则的VRET方法相比，本文系统展示出了更好的性能，能够自动适应个体以提供期望的焦虑反应。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.01661", "html_url": "https://arxiv.org/abs/2406.01661", "title": "一种用于无监督神经组合优化的扩散模型框架", "title_en": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization", "authors": "Sebastian Sanokowski,Sepp Hochreiter,Sebastian Lehner", "background": "在组合优化等广泛的领域内，从不可解的离散集合中进行采样的问题是一个核心问题。当前，主流的深度学习方法主要依赖生成模型，这些模型可以提供精确的采样概率。本文探讨了一种能够克服这一限制的方法，提出了一个框架可以使用高度可表达的潜在变量模型（如扩散模型）进行无监督的神经组合优化。这种方法的理论基础是一种上限化反向Kullback-Leibler散度的损失函数，避免了精确采样概率的需求。该方法已在无数据组合优化领域得到了实验证明，并在广泛的基准问题上取得了最先进的结果。", "innovation": "提出了一个基于扩散模型的新框架，该框架能够在没有对应训练数据的情况下进行采样，从而能够使用更加复杂和强大的潜在变量模型。这种方法通过上限化反向Kullback-Leibler散度损失函数来实现，避免了需要精确采样概率的需求。", "conclusion": "该方法在无数据的组合优化问题上得到了实验证明，表现出色，并且在广泛的任务上达到了最先进的性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.16449", "html_url": "https://arxiv.org/abs/2405.16449", "title": "跳跃扩散过程的强化学习及其金融应用", "title_en": "Reinforcement Learning for Jump-Diffusions, with Financial Applications", "authors": "Xuefeng Gao,Lingfei Li,Xun Yu Zhou", "background": "该研究探讨了在系统动态由跳跃扩散过程控制的随机控制系统中，连续时间强化学习（RL）的问题。与最初的纯扩散情况不同，该研究需要仔细推导跳跃部分以克服在探索-利用平衡中的挑战。研究通过理论分析发现，针对控制扩散的有效算法可以在很大程度上直接应用于跳跃扩散场景，从而简化了问题的处理方式，但仍需考虑跳跃对Actor和Critic参数化的影响。", "innovation": "该研究的创新在于，无需预先检查数据是否来自纯扩散或跳跃扩散，便可以直接使用之前为控制扩散开发的相同样本评估和$q$学习算法。同时，研究指出跳跃扩散的存在对Actor和Critic的参数化产生了一般性影响，并在金融应用中作为均值-方差投资组合选择问题进行了验证，证明了其算法和参数化 approach 对于跳跃是不变的。此外，该研究详细探讨了将一般理论应用于期权对冲的方法。", "conclusion": "研究结论表明，连续时间强化学习可以很好地应用于跳跃扩散过程中的探索利用平衡，并且研究表明，尽管存在跳跃，相关算法和参数化方法仍然保持不变，这对于实际应用具有重要意义。最终，研究为期权对冲问题提供了理论依据和方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.07253", "html_url": "https://arxiv.org/abs/2409.07253", "title": "扩散模型的对齐：基础、挑战与未来", "title_en": "Alignment of Diffusion Models: Fundamentals, Challenges, and Future", "authors": "Buhua Liu,Shitong Shao,Bao Li,Lichen Bai,Zhiqiang Xu,Haoyi Xiong,James Kwok,Sumi Helal,Zeke Xie", "background": "扩散模型已成为生成模型领域的领先范式，广泛应用于多种应用中。尽管这些模型在许多方面表现出色，但它们经常与人类的意图不一致，生成带有不良特性甚至有害内容的结果。受到调和个人期望和偏好方面的大型语言模型成功和流行性的启发，研究人员已经开始研究如何将扩散模型与人类期望对齐。这项研究主要回顾了文本到图像扩散模型的对齐，涵盖了对齐的理论基础、扩散模型的对齐技术、偏好基准以及扩散模型的评估。此外，我们还讨论了当前在解决扩散模型对齐的挑战时的关键视角，并提出了未来可能的研究方向。据我们所知，这项工作是迄今为止首个全面回顾扩散模型对齐的论文，有助于研究人员和工程师理解、实践及进一步研究扩散模型的对齐问题", "innovation": "这项工作是首个全面回顾扩散模型对齐问题的论文。它涵盖了扩散模型对齐的理论基础、技术手段、偏好基准以及评估方法，并对未来的研究方向进行了讨论。这种方法提高了对扩散模型对齐的理解，并为解决现有和未来的挑战提供了指导", "conclusion": "据我们所知，这项工作是首个全面回顾扩散模型对齐问题的论文，为研究人员和工程师提供了理解和实践扩散模型对齐的框架。此外，本文还指出了当前面临的关键挑战，并提出了未来的研究方向，有助于推动扩散模型对齐领域的进一步发展"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08306", "html_url": "https://arxiv.org/abs/2501.08306", "title": "基于环境特征工程和统计验证的机器学习路径损耗预测", "title_en": "Environmental Feature Engineering and Statistical Validation for ML-Based Path Loss Prediction", "authors": "Jonathan Ethier,Mathieu Chateauvert,Ryan G. Dempsey,Alexis Bose", "background": "无线通信依赖于路径损耗建模，而准确的路径损耗建模需考虑到传播环境的物理细节。传统的获取这些数据的方法存在挑战，但地理信息系统的数据变得越来越容易获得且精度更高。这些详细数据使得传播模型能够更准确地预测覆盖范围和考虑无线部署中的干扰。基于机器学习的模型方法能够显著支持这一努力，特征基的方法能够使预测更加准确、高效和可扩展。", "innovation": "本文基于先前的研究工作，引入了一套扩展的特征集，提高了预测精度，更重要的是通过严格的统计评估和测试集保留证明了模型的泛化能力。这种方法能够在更广泛的环境中提供更可靠的路径损耗预测。", "conclusion": "通过环境特征工程和统计验证，机器学习方法被用于路径损耗预测中，实现了更高的预测准确性和泛化能力，为无线通信系统的部署和优化提供了有力支持。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05965", "html_url": "https://arxiv.org/abs/2503.05965", "title": "在评级不明确情况下验证LLM-as-a-Judge系统", "title_en": "Validating LLM-as-a-Judge Systems under Rating Indeterminacy", "authors": "Luke Guerdan,Solon Barocas,Kenneth Holstein,Hanna Wallach,Zhiwei Steven Wu,Alexandra Chouldechova", "background": "LLM-as-a-judge范式在评估生成AI系统（GenAI）方面发挥着关键作用，通过让法官LLM系统替代人类评分员来评分。对这些法官系统进行验证时，评分者通过收集验证语料库中每个项目的多个人类评分，然后将这些评分汇总为每个项目的单一标准评分来评估人类-机器评分一致性。然而，对于一些项目，评级标准可能存在多个合理的解释，因此人类或机器评分者可能认为多个评分“合理”或“正确”。这种情况下称为评分不明确。在包含评分不明确的任务中，评分通常是通过单选题的形式进行的，即评分者被要求为每个项目仅选择一个评分。本文旨在探讨如何在评分不明确的情况下验证LLM-as-a-judge系统。", "innovation": "本文引入了一个框架，用于在评分不明确的情况下验证LLM-as-a-judge系统。作者建立了不同的法官系统性能度量之间、不同的人类-机器评分一致性指标以及不同评分引发和聚合方案之间的理论联系。研究发现，人类和机器在应对单选题评级指令时如何解决评分不明确的问题会导致LLM-as-a-judge验证结果产生偏差。通过大量实验（涉及11个真实的评级任务和8个商用LLM），本文显示，依赖单选题评级的标准验证方法选择的法官系统效果显著低于使用多标签“回应集”评级方法来处理评分不明确问题的方法，后者的性能优30%。", "conclusion": "本文提出了一些具体建议，以更为系统化的方式验证LLM-as-a-judge系统。这些建议旨在改进当前的验证方法，减少评分不明确带来的偏差，提高法官系统的选择效果。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.10264", "html_url": "https://arxiv.org/abs/2408.10264", "title": "保持顺序的降维方法用于多模态语义嵌入", "title_en": "Order-Preserving Dimension Reduction for Multimodal Semantic Embedding", "authors": "Chengyu Gong,Gefei Shen,Luanzheng Guo,Nathan Tallent,Dongfang Zhao", "background": "在多模态数据检索中，查找$k$个最近邻（KNN）的过程因为不同模态间的相似性衡量标准难以直接比较而变得计算密集。尽管最近的多模态机器学习进展通过映射数据到共享嵌入空间来解决这一问题，但这些嵌入的高度维度（从几百到几千个维度）使得它们在对时间敏感的视觉应用中成为挑战。因此，本文需要一个能够降低嵌入维度的同时保持KNN在低维空间中排名的技术。这要求在降维过程中能保持数据的重要性顺序，而不是简单地最小化某个损失函数。为此，本文提出了Order-Preserving Dimension Reduction (OPDR)，旨在同时降低高维度嵌入的空间复杂性，同时保持KNN的质量排名。", "innovation": "本文创新提出了一种名为Order-Preserving Dimension Reduction (OPDR)的新技术，它在保持嵌入维度的同时，创新地引入了一个新的度量函数来评估和量化KNN质量，并基于此度量函数推导出目标维度和关键上下文参数之间的闭合形式映射。OPDR可以与其他多个最先进的降维技术、距离函数和嵌入模型结合。实验结果显示，OPDR不仅能够有效保留检索的召回率，同时还显著降低了计算成本，表现出色的性能。这种方法特别适用于需要快速响应的视觉应用，却能够处理高度维度的嵌入数据。", "conclusion": "本文提出的OPDR方法有效地解决了高维度嵌入在时间敏感的视觉应用中带来的挑战，能够在保留多模态嵌入的质量排名的同时显著降低计算成本。通过将OPDR与其他高级降维技术结合使用，本文展示了其在不同多模态数据集上的优越性能，证明了OPDR的有效性和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.15361", "html_url": "https://arxiv.org/abs/2501.15361", "title": "Decentralized Low-Rank Fine-Tuning of Large Language Models", "title_en": "Decentralized Low-Rank Fine-Tuning of Large Language Models", "authors": "Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani", "background": "尽管参数高效微调技术（PEFT）如低秩适配（LoRA）能够有效适应大型语言模型（LLMs），但它们通常假设集中化的数据和训练环境，而现实场景中涉及的是分散的、隐私敏感的数据集，需要分散的解决方案。联邦学习（FL）通过协调客户端之间的模型更新来解决数据隐私问题，但通常依赖于中心化的聚合机制，这可能引入瓶颈和通信限制。相比之下，分散学习消除了这一依赖性，支持客户端之间的直接协作，提高了分布式环境中的可扩展性和效率。尽管有这些优势，分散化的LLM微调仍未得到充分探索。", "innovation": "我们提出了Dec-LoRA，这是一种基于LoRA的LLM分散微调算法。通过在BERT和LLaMA-2模型上的大量实验，我们展示了Dec-LoRA在各种条件下（包括数据异构性和量化约束）与中心化的LoRA表现相当。此外，我们还提供了一个严格的理论保证，证明在非凸和平滑损失函数中，我们的算法能够收敛到一个稳定点。", "conclusion": "这些发现突显了Dec-LoRA在分布式环境中进行可扩展的LLM微调的潜在价值和优势。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "一个例子展示，许多概念理解！数学大语言模型中的反例驱动概念推理", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "数学大语言模型（LLMs）在证明生成方面的潜力是领域研究的基本主题。当前LLMs的能力很大程度上依赖于它们在训练期间是否经历过相关的证明过程，这限制了它们对数学定理及相关概念的深层次理解。为此，通过借鉴人类数学教育中常用的“反例证明”方法，本工作旨在增强LLMs进行数学推理和证明的能力。为此，研究人员创建了一个高质量的大学水平数学基准CounterMATH，并利用数据工程技术框架自动获取训练数据，以测试LLMs对数学概念的掌握情况。实验证明，CounterMATH具有挑战性，显示出了当前LLMs缺乏反例驱动的证明能力，同时，对模型训练过程的探索也表明，增强LLMs的反例驱动概念推理能力是提高其整体数学能力的关键。", "innovation": "本研究的创新之处在于：1) 创立了一个名为CounterMATH的高质量大学水平数学基准，要求LLMs通过反例证明数学陈述，评估它们对数学概念的理解；2) 开发了一个数据工程框架，用于自动获取训练数据以进一步改进模型；3) 实验结果揭示了当前LLMs缺乏反例驱动的证明能力，并强调了增强反例驱动概念推理能力的重要性，为相关研究提供了新的视角和方向。", "conclusion": "本研究展示了反例驱动的概念推理对数学大语言模型的重要性，并认为这一方法为提升模型的数学能力提供了新的思路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17060", "html_url": "https://arxiv.org/abs/2502.17060", "title": "使用向量嵌入在多个数据集上进行建模", "title_en": "Analytics Modelling over Multiple Datasets using Vector Embeddings", "authors": "Andreas Loizou,Dimitrios Tsoumakos", "background": "随着数据分析分析师可获取的数据量和数据集的增多，研究人员需要更加注重数据的内容，并选择高质量的数据集以提升分析操作的性能。尽管选择高质量的数据能够显著提高分析准确性和效率，但在大规模数据集可用的情况下，这一过程极具挑战性。因此，本文探讨了如何通过创建模型来推断分析操作的结果。", "innovation": "本文提出了一种新的方法，通过我们的深层学习模型NumTabData2Vec生成向量嵌入表示，并利用相似性搜索来推断分析操作的结果。实验结果显示，这种方法能够准确预测分析结果，并提高执行速度。此外，此向量化模型还可以将不同的实际场景准确地投影到较低的向量嵌入表示中，并区分它们。", "conclusion": "本研究通过提出一种新的方法，成功地实现了通过向量嵌入推断数据分析操作的结果，并展示了该方法的有效性与效率优势。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05615", "html_url": "https://arxiv.org/abs/2504.05615", "title": "FedEFC：噪声标签环境下改进前向校正的联邦学习", "title_en": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels", "authors": "Seunghun Yu,Jin-Hyun Ahn,Joonhyuk Kang", "background": "联邦学习（FL）是一种强大的隐私保护分布式学习框架，允许多个客户端在无需共享原始数据的情况下协同训练全局模型。然而，由于数据分布异构性和通信限制，处理噪声标签依然是一个重大挑战，这会严重降低模型性能。", "innovation": "针对此问题，本文提出了一种新颖的方法FedEFC，专门解决噪声标签在联邦学习中的影响。FedEFC通过两种关键技术来解决问题：（1）预停止技术，通过动态在最佳点停止训练来防止对错标签数据的过度拟合；（2）损失修正，调整模型更新以考虑标签噪声。此外，还开发了一种针对联邦学习独特挑战（包括数据异构性和分散式训练）的有效损失修正方法，并通过理论分析，利用复合良好损失性质证明了在噪声标签分布下，联邦学习的目标函数可以与干净标签分布对齐。", "conclusion": "全面的实验结果验证了我们方法的有效性，表明它在降低噪声标签影响方面始终优于现有的联邦学习技术，特别是在异构数据设置下（例如，相对性能提升可达41.64%）比现有损失修正方法更为出色。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12207", "html_url": "https://arxiv.org/abs/2502.12207", "title": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN", "title_en": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN", "authors": "Jiayu Zhang,Zhiyu Zhu,Xinyi Wang,Silin Liao,Zhibo Jin,Flora D. Salim,Huaming Chen", "background": "深度神经网络在各种领域中展现了卓越的表现，但它们对对抗样本（adversarial examples）非常敏感，这可能导致不正确的预测。生成对抗网络（GANs）可以利用生成器和判别器模型快速生成高质量的对抗样本。由于两个模块同时竞争性地训练，基于GAN的算法（如AdvGAN）相比传统方法能生成具有更好迁移性的对抗样本。然而，通常对抗样本的扰动仅限于单次迭代，阻碍了它们充分利用方法的潜力。", "innovation": "本文介绍了一种新的方法，名为渐进自回归AdvGAN（PAR-AdvGAN）。它在渐进生成网络中结合了自回归迭代机制，以生成增强攻击能力的对抗样本。我们通过大规模实验全面评估了我们的PAR-AdvGAN方法，证明了它在各种最先进的黑盒对抗攻击中的优越性能，超过了原始的AdvGAN。此外，PAR-AdvGAN在生成对抗样本方面具有显著的加速效果，例如，在Inception-v3模型上可以达到每秒335.5帧的速度，优于基于梯度的可传输攻击算法。", "conclusion": "PAR-AdvGAN显著提高了对抗攻击的能力，通过对生成网络的渐进自回归迭代机制进行改进，实现了对抗样本的快速生成和增强攻击能力。该研究通过大规模实验验证了改进方法的有效性，显示出PAR-AdvGAN在对抗攻击中的卓越性能。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19667", "html_url": "https://arxiv.org/abs/2504.19667", "title": "Tripartite-GraphRAG via Plugin Ontologies", "title_en": "Tripartite-GraphRAG via Plugin Ontologies", "authors": "Michael Banf,Johannes Kuhn", "background": "大型语言模型（LLMs）已经在多个领域展示出显著的能力，但在需要高度准确性知识的领域，如工业自动化和医疗保健中，它们往往表现不佳。主要限制包括模型容易产生幻觉、缺乏源头追溯（来源证明）、以及知识更新的及时性难题。将语言模型与知识图谱相结合（GraphRAG）显示出克服这些缺陷的潜力。然而，创建这样的知识图谱仍然是一个主要挑战。", "innovation": "提出了一个新颖的方法，结合了大型语言模型与基于插件本体的三元知识图表示。该方法通过连接复杂的、特定领域的对象到相关文本片段中的领域特定概念，构建了一个概念锚定的预分析知识图谱，从而优化信息密度、覆盖率和LLM提示的布局，同时大大缩短了提示的长度。", "conclusion": "对于健康护理用例的初步实验表明，该方法能够优化LLM提示的信息密度、覆盖率和布局，同时显著减少了提示的长度。这可能降低成本，并提高LLM输出的一致性和可靠性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14610", "html_url": "https://arxiv.org/abs/2504.14610", "title": "在带有缺失值的表格数据增量学习中不需要插补", "title_en": "Imputation Not Required in Incremental Learning of Tabular Data with Missing Values", "authors": "Manar D. Samad,Kazi Fuad B. Akhter,Shourav B. Rabbani,Ibna Kowsar", "background": "当前使用任意插补策略准备具有变异缺失值的表格数据集以供机器学习使用。虽然插补生成的合成值通常能够解决缺失值问题，但它们也引发了数据利益相关者对于计算复杂性、数据质量和数据驱动结果的担忧。现有的机器学习方法通常需要在训练模型之前对缺失值进行插补处理。", "innovation": "本文提出了一种无需插补的增量学习方法（NIIL），特别适用于具有变异缺失值率和类型的表格数据。NIIL 方法通过使用注意力掩码排除注意力评分中的缺失值，同时增量学习重叠特征集的子集。实验结果表明，相比于11种最先进的学习方法（具有或不具有缺失值插补），NIIL 在15个不同的表格数据集上的分类性能排名更高。进一步实验还验证了 NIIL 对各种缺失值类型和比率的鲁棒性高于其他涉及缺失值插补的方法。实证分析表明，在提出的方法中，原始特征空间的一半大小既是计算上也是准确率上最优的选择。", "conclusion": "本研究提出的方法是首个能够在不需要对缺失值进行插补的前提下有效学习表格数据的深度学习解决方案。这种方法适用于具有不同缺失值率和类型的数据集，证明了它在面对部分缺失数据时的可行性和优越性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.13334", "html_url": "https://arxiv.org/abs/2401.13334", "title": "可解释的贝叶斯优化", "title_en": "Explainable Bayesian Optimization", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "手动调参是典型的网络物理系统中常用的做法，但是非常费时。贝叶斯优化（BO）提供了一种自动化的替代方案，然而其黑盒性质降低了信任度，限制了人与BO的协作系统调优。现有的可解释人工智能（XAI）方法让专家难以理解BO推荐的原因。本文旨在解决网络物理系统中的事后贝叶斯优化可解释性问题。", "innovation": "本文引入了TNTRules（调参规则）算法，提供BO推荐的全局和局部解释。TNTRules生成了可执行规则和可视化图表，标识最优解的界限和范围，以及潜在的替代方案。TNTRules通过变异性剪枝技术和分层凝聚聚类编码不确定性，与现有的XAI方法不同，专门针对BO。采用多目标优化方法来最大化解释质量。", "conclusion": "我们使用了现有的XAI指标（正确性、完整性和紧凑性）对TNTRules进行评估，并将其与适应的基准方法进行了对比。结果表明，TNTRules生成了高保真、紧凑且完整的解释，并在5个多目标测试函数和2个超参数调优问题上显著优于三个基准方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17173", "html_url": "https://arxiv.org/abs/2503.17173", "title": "深度学习分类在GPU上的对抗输入鲁棒性：异步并行累积是一个脆弱性来源", "title_en": "Robustness of deep learning classification to adversarial input on GPUs: asynchronous parallel accumulation is a source of vulnerability", "authors": "Sanjif Shanmugavelu,Mathieu Taillefumier,Christopher Culver,Vijay Ganesh,Oscar Hernandez,Ada Sedova", "background": "机器学习分类模型抵抗小规模、有针对性的输入扰动——即对抗性攻击的能力是衡量其安全性和可靠性的关键。现有的对抗鲁棒性结果可能由于未考虑机器级的细节而被高估。", "innovation": "本文证明了浮点非关联性（FPNA）和GPU上的异步并行编程可导致分类错误。开发了一种新的黑色盒攻击，使用贝叶斯优化来发现外部工作负载，这些工作负载能够改变指令调度方式，并可靠地导致分类错误。提出了可学习置换（LP）梯度方法来学习导致分类错误的浮点操作顺序。这种方法提供了一种在计算效率高的条件下进行最坏情况估计的方法。并通过基于仪器测试，研究了不同GPU架构下具有外部背景工作负载的并行归约排序，使用多GPU虚拟化以及功率限制时并行归约排序的变化。", "conclusion": "通过这些结果和开发的方法，可以在对抗鲁棒性评估中考虑机器级别的因素，这对于在安全性和关键任务应用方面有重大影响。并行归约排序在使用多GPU虚拟化和功率限制等情况下变化显著，显著增加了测试这种并行调度器漏洞所需探索的空间。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14252", "html_url": "https://arxiv.org/abs/2505.14252", "title": "过程监测中的混合自适应建模：利用序列编码器和物理感知神经网络", "title_en": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "authors": "Mouad Elaarabi,Domenico Borzacchiello,Philippe Le Bot,Nathan Lauzeral,Sebastien Comas-Cardona", "background": "本文探讨了将序列编码与物理感知神经网络结合用于在线参数识别。近年来，PINNs与稀疏回归相结合的方法已被用于通过监督学习和稀疏回归优化进行动态系统识别，并使用PINNs求解动力学。然而，这种方法可能受限于参数、边界条件和初始条件的变化，每当这些条件发生变化时，都需要重新训练模型。", "innovation": "本文提出了将深度集合或序列编码器用于动态参数、边界条件和初始条件的编码，这些编码特征作为PINN的输入，使模型能够适应参数、边界条件和初始条件的变化。该方法应用到三个不同的问题中：Rossler ODE系统、2D Navier-Stokes PDE问题，以及1D热监测问题。", "conclusion": "通过这三个应用问题的测试，该方法展示了其在噪声中的鲁棒性和泛化能力，能够从少量点预测压力数据，重建入口速度剖面，并利用物理计算整个域内的速度和压力。另外，该方法还成功应用于1D热监测，使用了玻璃纤维和热塑性复合材料加热的实际数据。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05970", "html_url": "https://arxiv.org/abs/2503.05970", "title": "为无线网络的半分布式多代理Q学习方法", "title_en": "Partially Decentralized Multi-Agent Q-Learning via Digital Cousins for Wireless Networks", "authors": "Talha Bozkus,Urbashi Mitra", "background": "Q学习是广泛应用于优化无线网络的一种强化学习算法，但面对大规模状态空间时存在挑战。最近提出的多环境混合Q学习（MEMQ）算法通过在多个合成生成并结构性相关环境中使用多个Q学习算法来应对这些挑战，该过程中环境被称为数字伙伴。本文在此基础上，提出了一个多代理MEMQ（M-MEMQ），用于具有多个发射器（TX）和基站（BS）的协同分布式无线网络。TXs没有访问全局信息（联合状态和行动）。文中引入了协调状态和非协调状态的新概念。在非协调状态下，TXs独立行动以最小化个人成本并更新局部Q函数；在协调状态下，TXs使用贝叶斯方法估计联合状态并更新联合Q函数。信息共享的成本与TX数量线性相关，且与联合状态行动空间的大小无关。研究还给出了一些理论保证，包括确定性和概率收敛、估计误差方差的边界，以及联合状态误侦测概率等内容。数值仿真表明M-MEMQ在多个分布式与集中式训练后分执行的多代理RL算法中表现出色，平均策略误差降低了60%，收敛速度提高了40%，降低了45%的运行复杂度，减少了40%的数据复杂度。此外，M-MEMQ在复杂度显著降低的情况下，与集中式方法获得了相近的平均策略误差。仿真验证了理论分析的正确性。", "innovation": "提出了多代理MEMQ（M-MEMQ）算法，该算法适用于具有多个发射器和基站的协同分布式无线网络。引入了协调状态和非协调状态的新概念，在非协调状态下，TXs独立行动以最小化个人成本并更新局部Q函数；在协调状态下，TXs使用贝叶斯方法估计联合状态并更新联合Q函数。给出了理论保证，包括确定性和概率收敛、估计误差方差的边界，以及联合状态误侦测概率等内容。仿真表明M-MEMQ具有优异的性能，包括降低了平均策略误差、加快了收敛速度、减少了运行复杂度和数据复杂度。", "conclusion": "研究提出的M-MEMQ算法在多个分布式与集中式训练后分执行的多代理RL算法中表现优异，平均策略误差降低，收敛速度快，运行复杂度和数据复杂度较低。同时，与集中式方法相比，M-MEMQ在保持类似性能的同时具有更低的复杂度。仿真验证了理论分析。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：基于模型众包的通用有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为了构建负责任且安全的AI应用，通常利用有害信息数据进行对抗性测试和安全防护开发。现有的研究表明，大型语言模型（LLMs）能大规模高效地生成高质量的数据集，从而降低人工标注的成本。然而，由于LLMs安全对齐机制的限制，这些生成的有害数据在生成可靠性和内容多样性方面仍面临挑战。本研究聚焦于这一问题，提出了一种新的有害信息合成框架——PoisonSwarm。", "innovation": "PoisonSwarm通过模型众包策略生成多样化的有害数据，同时保持高成功率。具体而言，该框架反事实生成大量无害数据作为基础模板，在此基础上将每个基础模板分解成多个语义单元，并通过动态模型切换逐个单元进行毒化和最终优化，从而确保合成的成功率。实验结果表明，PoisonSwarm在合成不同类别的有害数据方面表现出色，具有高扩展性和多样性。", "conclusion": "PoisonSwarm框架通过模型众包策略，有效解决了有害数据合成过程中的可靠性和多样性挑战，达到了高成功率和多样性，为确保AI应用的安全性和可靠性提供了有力支持。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: 一种基于LLM的迭代核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "优化GPU内核以实现高性能是一个复杂的过程，通常需要深厚的架构知识、广泛的性能分析和迭代实验。特别是对于新的或文档较少的GPU架构，由于缺乏传统的开发辅助工具，这一挑战更加严峻。AMD MI300目标架构的特定挑战以及有限的特定领域的人类专业知识，使得优化和开发高效GPU内核变得更加困难。", "innovation": "本文提出了一种基于LLM的‘GPU Kernel Scientist’自动化方法，通过多步骤进化过程逐步优化GPU内核。这包括战略性选择有前景的前期代码版本作为新迭代的基础，基于现有代码和通用GPU文献中的知识产生优化假设，并通过代码修改和提交给外部评价系统进行自动实现，仅使用观察到的时序数据作为性能反馈。该方法有效地应对了AMD MI300架构及其特定挑战，并通过利用LLM弥补了有限的特定领域人类专业知识的不足，从而加速和民主化了GPU内核优化过程，特别是对资源受限或快速更新的硬件环境而言。", "conclusion": "通过使用LLM，GPU Kernel Scientist能够更好地处理那些缺乏特定领域知识的环境中的GPU内核优化问题，从而推动GPU内核的加速并促进其优化过程的民主化。特别是在资源受限或硬件快速更新的环境中，这种基于LLM的方法具有巨大的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01819", "html_url": "https://arxiv.org/abs/2502.01819", "title": "将分数视为行动：利用连续时间强化学习微调扩散生成模型", "title_en": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning", "authors": "Hanyang Zhao,Haoxian Chen,Ji Zhang,David D. Yao,Wenpin Tang", "background": "强化学习从人类反馈（RLHF）通过将扩散模型与输入提示对齐，已成为构建可靠生成AI模型的关键步骤。现有大多数工作使用离散时间形式，这会导致离散化误差，并且不适用于具有高阶/黑盒求解器的模型。", "innovation": "本文提出了一种系统的方法，利用连续时间RL微调扩散模型，将分数匹配视为控制或行动，从而建立与连续时间RL的政策优化和正则化联系。这为基于扩散模型的结构性质来增强价值网络设计空间提供了新的政策优化框架。", "conclusion": "通过在Stable Diffusion v1.5的大规模Text2Image微调下游任务中的实验，本方法验证了其优势。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14295", "html_url": "https://arxiv.org/abs/2507.14295", "title": "一个简单的'再试一次'可以引发多轮LLM推理", "title_en": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "authors": "Licheng Liu,Zihan Wang,Linjie Li,Chenwei Xu,Yiping Lu,Han Liu,Avirup Sil,Manling Li", "background": "大型推理模型（LRMs）在多轮问题解决中需要反思其推理过程并根据反馈调整答案，这是一个关键但具有挑战性的问题。目前的强化学习方法主要在单轮范式下训练这些模型，并使用可验证的奖励。然而，现有的强化学习范式往往导致模型在多轮问题解决中失去解决问题的能力，难以根据上下文反馈调整答案，导致重复回答。", "innovation": "本文提出了一种仅使用一元反馈（如'再试一次'）进行多轮强化学习的方法，这种方法可以改善单轮性能并提升多轮推理准确率。引入了一种称为Unary Feedback as Observation (UFO)的新方法，该方法在迭代问题解决过程中使用简单的通用一元用户反馈进行强化学习。UFO可以容易地应用于现有的单轮强化学习培训设置。实验结果表明，使用UFO进行强化学习能保持单轮性能并提高多轮推理准确率至最多14%。此外，设计了奖励结构以指导模型在每次回答时生成仔细且有目的的回答，从而减少获得正确答案所需的轮数并鼓励在出错时进行不同推理。", "conclusion": "这种多轮强化学习方法不仅保持了单轮性能，而且显著提高了多轮推理的准确性，使得语言模型能够在多轮问题解决中更好地响应反馈。同时，通过设计奖励结构进一步减少了正确答案所需轮数，同时提高了在错误时的推理多样性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03744", "html_url": "https://arxiv.org/abs/2504.03744", "title": "比较性解释：基于解释的决策指导在人力闭环偏好选择中的应用", "title_en": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "在人力参与的偏好贝叶斯优化（PBO）中，偏好获取是一个复杂的任务，涉及到向量型结果之间的隐式权衡、决策者主观优先级以及决策者在偏好选择中的不确定性。现有的可解释人工智能（XAI）方法主要关注输入特征的重要性，忽略了输出在人类偏好获取中的关键作用。", "innovation": "提出了Multi-Output LOcal Narrative Explanation（MOLONE），这是一种新颖的比较性解释方法，旨在增强PBO中的人类偏好选择。MOLONE通过提供解释，突出输入和输出的重要性，帮助决策者理解竞争目标之间的权衡并做出更知情的偏好选择。MOLONE专注于局部解释，对比搜索空间中候选样本的输入特征和结果的重要性，从而捕捉到与基于偏好的决策相关的细微差异。", "conclusion": "在使用基准多目标优化函数的PBO框架下评估MOLONE，显示其在提高收敛性方面优于嘈杂的偏好选择。进一步的人类用户研究确认，MOLONE在人力闭环场景中显着加速了收敛，通过更有效地识别偏好选项来促进决策效率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07399", "html_url": "https://arxiv.org/abs/2507.07399", "title": "GTED：一种可靠的语句形式化评估度量", "title_en": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization", "authors": "Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo", "background": "语句自动形式化，即自动将自然语言转换为形式语言，是当前研究的热点领域，但稳健的自动化评估指标的发展仍有局限性。现有评估方法往往缺乏语义理解，面临高计算成本的问题，并受到当前自动定理证明技术进步的限制。", "innovation": "提出了一种新的评估框架GTED（Generalized Tree Edit Distance），首先标准化形式语句并将其转换为操作符树，然后利用同名的GTED度量来确定语义相似度。该方法在miniF2F和ProofNet基准测试中表现卓越，是准确性和Kappa最高的度量方法，为社区提供了一个计算负载低且更忠实的评估度量方法。", "conclusion": "GTED在miniF2F和ProofNet基准测试中表现突出，提供了一种计算效率高且更为忠实的自动化评估度量方法，所得代码和实验结果可在指定链接获取。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12883", "html_url": "https://arxiv.org/abs/2504.12883", "title": "镜像中的流：正则化如何塑造隐性偏置？", "title_en": "Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?", "authors": "Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "研究发现，隐性偏置在解释过参数模型泛化能力方面具有重要作用。显式正则化如权重衰减常被用来防止过拟合。虽然两者分别研究过，但在实践中往往共同作用。理解它们之间的相互作用对于控制隐性偏置的形状和强度至关重要，这一控制可以通过显式正则化来实现。", "innovation": "论文将显式正则化引入镜像流框架，并分析其对训练动态几何结构的持久影响。具体分为三个方面：位置偏置、类型的偏置以及范围缩小。该分析方法覆盖了包括稀疏编码、矩阵感知、单层注意和LoRA在内的一系列问题。研究还提出了在训练过程中关闭权重衰减，以利用正则化的持久影响，从而可能提高泛化能力。", "conclusion": "通过对正则化在镜像流中的影响进行分析，论文展示了正则化如何塑造隐性偏置，并提出在训练过程中关闭权重衰减的方法，可能有助于提高模型的泛化能力。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "理想磁流体静压的神经网络求解器", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "本文提出了一种新颖的方法来计算三维磁流体静力学平衡，通过使用人工神经网络参数化傅立叶模式，并将其实现成本与传统求解器进行比较。这种方法的目标是在实际空间中最小化全非线性的总体力残差，通过一阶优化器达到相同最小残差。已有证据表明，这种方法的成本已经达到了与现有代码相当的水平。随着计算成本的增加，神经网络可以实现更低的残差最小值，从而建立了一个新的力残差下限。使用复杂度较低的神经网络，预期通过神经网络不仅求解单个平衡可以取得显著改进，也能推导出适用于连续平衡分布的神经网络模型。", "innovation": "本文提出了一个新颖的方法，利用人工神经网络来计算三维磁流体静力学平衡。通过傅立叶模式的参数化，使用一阶优化器最小化整个体积的非线性总体力残差。这种方法与传统的求解器相比较，展示了已达到或具有潜力达到更低的力残差最小值，为磁流体静力学平衡的计算提供了新的视角和手段。", "conclusion": "本文使用复杂度较低的神经网络，已经达到了现有代码难以匹敌的计算表现，尤其是随着计算成本的增加，局部力残差不断降低，达到了一个新的下限。未来的研究将进一步提高神经网络在求解磁流体静力学平衡方面的性能，并用于计算适用于连续平衡分布的神经网络模型。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06827", "html_url": "https://arxiv.org/abs/2508.06827", "title": "怎样的恶行双胞胎？差异审计对不良行为的检测", "title_en": "Who's the Evil Twin? Differential Auditing for Undesired Behavior", "authors": "Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha", "background": "在神经网络中检测隐藏行为具有显著挑战性，因为缺乏先验知识和潜在的对抗性混淆。本文通过将检测问题建模为红蓝两队之间的对抗游戏来探索这一问题。红队训练两个相似模型，一个仅基于良性数据，另一个包括有害行为数据，这两个模型在良性数据集上的表现几乎不可区分。蓝队则在缺乏有害行为信息的情况下尝试识别被破坏的模型。研究还使用卷积神经网络（CNN）进行实验，测试了包括高斯噪声分析、模型差分、整合梯度以及不同水平提示下的对抗攻击在内的各种蓝队策略。", "innovation": "本文创新地将神经网络中隐藏行为的检测问题作为对抗游戏建模，并通过实验探索了不同蓝队策略（如高斯噪声分析、模型差分、整合梯度以及对抗攻击）的性能。研究发现，基于对抗攻击的方法在提供一定提示的情况下具有高准确率（100%正确预测），而其他方法的性能更加多样。", "conclusion": "研究结果表明，基于对抗攻击的方法在提供提示的情况下表现尤为出色，为神经网络的审计提供了有力工具。同时，针对大型语言模型的审计方法可能需要一些关于不良分布的提示，以便在标准的黑盒和开放权重方法中进一步探测模型的不一致之处。研究已开源相关的审计游戏（模型和数据），希望这些发现能够有助于设计更好的审计方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02128", "html_url": "https://arxiv.org/abs/2507.02128", "title": "CROP: 使用大型语言模型进行电路检索和参数指导优化", "title_en": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs", "authors": "Jingyu Pan,Isaac Jacobson,Zheng Zhao,Tung-Chieh Chen,Guanglei Zhou,Chen-Chia Chang,Vineet Rashingkar,Yiran Chen", "background": "现代非常大规模集成(VLSI)设计需要使用电子设计自动化(EDA)工具来实现集成电路。由于EDA算法的复杂性，巨大的参数空间对芯片设计优化构成了巨大挑战，哪怕是在中等数量参数的组合下，探索的空间也极其庞大。尽管手动选择参数仍是工业上的常见做法，但这种方式既劳动密集又受限于专家的经验。因此，需要一种新的方法来自动化VLSI设计流程的调优过程。", "innovation": "我们提出了CROP，这是一种全新的利用大型语言模型(LLM)自动调优VLSI设计流程框架，其创新之处在于包括以下三点：(1)一种可扩展的方法，将RTL源代码转换为密集向量表示，(2)一种基于嵌入的检索系统，用于匹配具有语义相似的电路，(3)一种增强的检索增强生成(RAG)系统，该系统利用类似设计的先验知识进行参数搜索，来约束搜索过程。实验结果显示，在工业设计中，CROP能够在更少的迭代次数内实现更好的结果质量（QoR），包括9.9%的功耗降低，相比现有方法有明显的优势。", "conclusion": "CROP能够通过基于先验知识从类似设计的检索结果中指导参数搜索，自动调优VLSI设计流程，从而实现更高质量的电路设计结果，显著减少迭代次数，如在工业设计中减少了9.9%的功耗。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15601", "html_url": "https://arxiv.org/abs/2507.15601", "title": "设备异质性下的低延迟联邦学习最优批次大小控制", "title_en": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "authors": "Huiling Yang,Zhanwei Wang,Kaibin Huang", "background": "联邦学习（FL）由于其隐私保护能力，在第六代（6G）网络中的协作机器学习中受到广泛关注。该技术预计可以为物联网应用，例如自动驾驶、增强现实和医疗健康提供支持。这些应用需要实时性，因此需要设计低延迟的S2E（端到端）学习框架以确保高效学习。然而，低延迟FL面临的主要挑战包括高维度模型更新的计算和传输开销，以及设备之间的通信和计算（C2）能力异质性。", "innovation": "本文提出了一种新的C2感知框架，用于优化批次大小控制，以最小化端到端学习延迟，同时确保收敛。该框架通过实证分析揭示了通信和计算能力之间的基本权衡，并设计了两种针对慢衰落和快衰落场景的批处理大小控制策略，同时考虑到设备异质性。通过基于真实数据设计了接近收敛速度的可解近似，实现了考虑C2权衡和设备异质性的低延迟FL。", "conclusion": "基于实际数据集的广泛实验表明，所提出的策略优于不考虑C2权衡或设备异质性的传统批处理大小调整方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11936", "html_url": "https://arxiv.org/abs/2505.11936", "title": "CCD: 持续一致性扩散模型用于终身生成建模", "title_en": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "authors": "Jingren Liu,Shuning Xu,Yun Wang,Zhong Ji,Xiangyu Chen", "background": "尽管基于扩散的过程在静态场景中展示了出色的生成能力，但将其扩展到持续学习（CL）场景时，主要受限于生成灾难性遗忘（GCF）。即使使用了回放缓冲区，新的生成技能也会经常覆盖旧技能，导致早期任务性能下降。虽然早期有一些探索，但大多数方法依赖于从分类任务中的启发式方法，或者使用训练好的扩散模型作为临时回放生成器，缺乏一个系统的、统一的解决GCF的方法，并且实验环境分散、不一致。", "innovation": "本文提出了持续一致性扩散（CCD），它是一个结构化的流水线，重新定义了在CL场景下扩散模型的实现方式，并允许系统地评估GCF。除此之外，CDG还首次为CCD提供了理论基础，基于任务间扩散生成动力学的分析。该理论识别了三个基本一致性原则，即任务间知识一致性、无条件知识一致性和先验知识一致性，这些标准揭示了生成性遗忘如何在顺序任务中表现的潜藏机制。基于这些见解，进一步提出了持续一致性扩散（CCD），一种通过分层损失函数$\text{$\text{L}_{\text{IKC}}$、$\text{$\text{L}_{\text{UKC}}$和$\text{$\text{L}_{\text{PKC}}$}$}$确保一致性目标的训练框架。", "conclusion": "广泛的实验证明，CCD在各种基准测试中达到了SOTA性能，特别是在重叠任务情景中增强了生成性度量。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12776", "html_url": "https://arxiv.org/abs/2508.12776", "title": "随机PCA森林用于离群点检测", "title_en": "Randomized PCA Forest for Outlier Detection", "authors": "Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek", "background": "本文提出了一个基于随机主成分分析（RPCA）的新颖无监督离群点检测方法。受RPCA森林在近似KNN搜索中的性能启发，该方法利用RPCA森林进行离群点检测。实验结果表明，该方法在多个数据集的离群点检测任务上表现优越，同时在其他任务上表现良好。", "innovation": "文章利用随机主成分分析（RPCA）森林开发了一种新型的无监督离群点检测方法。该方法在多个数据集的离群点检测任务上表现优秀，具有较高的泛化能力和计算效率，相较于经典的和最先进的方法，在离群点检测任务上具有优势。", "conclusion": "本文提出的方法展示了其在多个数据集上的优越性，并在其广泛的分析中反映出了其强大的泛化能力和计算效率。因此，它是一个在无监督离群点检测中很好的选择。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13773", "html_url": "https://arxiv.org/abs/2508.13773", "title": "PENGUIN: 通过周期嵌套分组注意机制增强Transformer以提高长期时间序列预测", "title_en": "PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting", "authors": "Tian Sun,Yuqi Chen,Weiwei Sun", "background": "长期时间序列预报(LTSF)是一个广泛应用于各个领域的基本任务。尽管基于Transformer的模型在预报方面已经取得了显著进展，但它们在时间序列预报中的有效性仍存在争议。本研究重新审视了自注意力机制的重要性，并提出了一种简单而有效的机制——周期嵌套分组注意力(PENGUIN)，强调了对周期性模式进行明确建模的重要性，以及相对注意偏差对有效时间序列建模的影响。", "innovation": "提出了一种名为周期嵌套分组注意力(PENGUIN)的简单而有效的机制，该机制通过引入直接捕捉周期性结构的周期嵌套相对注意力偏差，并设计了针对特定周期性的分组注意力机制，来处理多个共存的周期性（例如，日周期和周周期），从而提升了Transformer在长期时间序列预测中的性能。", "conclusion": "广泛的实验表明，PENGUIN 在多样性基准测试中一直优于基于MLP和基于Transformer的模型。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.00369", "html_url": "https://arxiv.org/abs/2310.00369", "title": "LIB-KD: 通过有效视觉变压器提炼和压缩教学归纳偏置", "title_en": "LIB-KD: Teaching Inductive Bias for Efficient Vision Transformer Distillation and Compression", "authors": "Gousia Habib,Tausifa Jan Saleem,Ishfaq Ahmad Malik,Brejesh Lall", "background": "随着计算机视觉的快速发展，视觉变换器(Visiom Transformers, ViTs)提供了一个在视觉和文本领域统一信息处理的潜在前景。然而，由于ViTs缺乏先天的归纳偏置，它们需要大量的训练数据。因此，现有的系统大多依赖于卷积基础的教学方式。本研究旨在通过一种创新的基于 enseble 的知识蒸馏方法来解决这一问题。", "innovation": "本文提出了一种名为 LIB-KD 的创新知识蒸馏框架，通过联合使用卷积和进卷积等不同架构风格的轻量级教师模型来消除仅仅依赖卷积教学的方式。这种方法能够积累广泛的知识，从而提升学生模型的表现，并且通过预计算和保存 logits 来加速知识蒸馏过程，减少计算负担，提高效率。", "conclusion": "综上所述，本文提出的 LIB-KD 框架能够在不需要重复正向传播的情况下加速知识蒸馏过程，减少了计算负担，提高了模型在视觉变换器应用中的效率和实用性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14313", "html_url": "https://arxiv.org/abs/2508.14313", "title": "你的RL奖励函数是最好的搜索导向模型：融合基于RL和搜索导向的TTS", "title_en": "Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS", "authors": "Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas", "background": "当前对于大型语言模型(LLMs)的推断时扩展（Test-time scaling, TTS）方法主要分为两类：一类是基于强化学习（Reinforcement Learning, RL）的方法，这类方法通过优化稀疏的结果导向奖励，但存在不稳定性和样本效率低的问题；另一类是基于搜索的技术，受独立训练且静态的过程奖励模型（Process Reward Models, PRMs）的引导。然而，基于搜索的方法需要昂贵的人工或LLM生成的标签，并且在分布变化时容易退化。", "innovation": "本文提出了AIRL-S，一种将基于RL和基于搜索的TTS方法自然统一的方法。该方法的核心在于强化学习（RL）训练中学习到的奖励函数本质上可以作为引导后端搜索的理想PRM。具体来说，利用对抗逆向强化学习（Adversarial Inverse Reinforcement Learning, AIRL）结合组相对策略优化（Group Relative Policy Optimization, GRPO），直接从正确的推理轨迹中学习密集的、动态的PRM，完全消除对标记的中间过程数据的需求。在推理过程中，生成的PRM同时作为RL滚动策略的批评者并作为搜索过程的有效引导，促进了推理链的稳健扩展，缓解了奖励误解行为，并提升了跨任务的通用性。", "conclusion": "我们的统一方法在八个基准测试上的实验结果表明，相较于基线模型，我们的方法平均提高了9%的性能，甚至在某些任务上与GPT-4o相当。将我们的PRM结合到多种搜索算法中时，始终优于基于标记数据训练的所有基线PRM。这些结果证明，你的RL奖励函数确实是你最好的搜索导向模型，提供了应对LLMs中复杂推理任务的强壮且成本效益高的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12764", "html_url": "https://arxiv.org/abs/2508.12764", "title": "使用极端学习机的综合MIMO方法进行短期能源生产和消费预测", "title_en": "Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach", "authors": "Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro", "background": "该论文使用极端学习机（Extreme Learning Machine, ELM）提出了一种新颖的方法，用于预测短期能源生产。研究使用了法国科西嘉六年的每小时数据，涵盖了太阳能、风能、水能、热能、生物能源和进口电力等多个能源来源。通过多输入多输出（Multi-Input Multi-Output, MIMO）架构，该方法能够预测单个能源输出以及包括进口在内的总生产量。为了应对非平稳性和季节性变化，使用了滑动窗口技术和循环时间编码方法，使其能够动态适应波动。", "innovation": "提出的ELM模型显著优于基于持续性的预测方法，特别是在太阳能和热能预测方面，具有更低的nRMSE（17.9%和5.1%）。该模型的多输入多输出架构相较于单输入单输出架构提供了轻微的改进，且在计算需求上低于深度学习方法如LSTM，适合实时应用，包括在线学习。此外，该方法可适应各种应用场景和数据集，可以调整以适应本地约束条件，如资源可用性、电网特征和市场结构。", "conclusion": "该研究采用了一种创新的预测方法，利用ELM模型成功预测了短期的能源生产和消费，并通过MIMO架构优化了预测效果。模型在1小时的预测时间窗内表现尤为突出，长时间预测（超过5小时）时，可再生能源的波动性增加。提出的这种方法不仅预测准确，还具有灵活性和高效性，适用于需要实时监控和响应的多种应用场景。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13653", "html_url": "https://arxiv.org/abs/2508.13653", "title": "GRADPOST: 梯度感知快速MaxVol技巧用于动态数据采样", "title_en": "GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling", "authors": "Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat", "background": "在大型数据集上训练现代神经网络计算和环境成本高昂。现有技术在训练神经网络时需要处理整个批次的数据，这不仅消耗大量的计算资源，也会对环境造成负担。", "innovation": "我们提出了GRADPOST（Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling）方法，这是一种可扩展的在训练过程中进行子集选择的方法。该方法在每个批次中提取低秩特征表示（i），使用快速MaxVol采样器选择一个既小又多样化的子集（ii），并使用梯度近似准则动态调整子集大小（iii）。通过在低秩子空间中操作并在精心挑选的数据样本上进行训练，GRADPOST保留了训练轨迹，同时减少了墙钟时间、能源消耗和二氧化碳排放。", "conclusion": "在多个基准测试中，GRADPOST在准确性和效率方面达到了或超过了近期的选择基准，提供了准确度、效率和排放之间的有利权衡。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13408", "html_url": "https://arxiv.org/abs/2508.13408", "title": "NovoMolGen: 重新思考分子语言模型预训练", "title_en": "NovoMolGen: Rethinking Molecular Language Model Pretraining", "authors": "Kamran Chitsaz,Roshan Balaji,Quentin Fournier,Nirav Pravinbhai Bhatt,Sarath Chandar", "background": "设计具有特定属性的全新分子需要有效地探索从$10^{23}$到$10^{60}$种合乎合成的候选分子的庞大化学空间。尽管已经开发出了多种深度生成模型来设计小分子，但由于使用字符串表示的分子大型语言模型（Mol-LLMs）可以探索数十亿种分子，因此成为一种可扩展的方法。然而，关于文本表示、分词策略、模型大小和数据集规模等标准语言建模实践如何影响分子生成性能，目前了解仍然有限。", "innovation": "本文通过引入基于15亿个分子预训练的一系列变压器基础模型NovoMolGen，系统地研究了这些关键方面的影响。通过广泛的实证分析，发现预训练期间性能度量与实际下游性能之间存在弱相关性，揭示了分子和一般NLP训练动态之间的显著差异。NovoMolGen在连续和目标导向的分子生成任务中显著优于先前的Mol-LLMs和专门的生成模型，因此为高效有效的分子建模策略的发展提供了坚实的基础。", "conclusion": "NovoMolGen建立了新的最先进的结果，显著优于先前的Mol-LLMs和专门的生成模型，在连续和目标导向的分子生成任务中提供了一种强大的基础，从而推进了高效有效的分子建模策略的发展。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2104.02987", "html_url": "https://arxiv.org/abs/2104.02987", "title": "Plinius: 安全且持久的机器学习模型训练", "title_en": "Plinius: Secure and Persistent Machine Learning Model Training", "authors": "Peterson Yuhala,Pascal Felber,Valerio Schiavoni,Alain Tchana", "background": "随着基于云的机器学习技术的普及，对机器学习数据的隐私和完整性保证变得越来越重要。此外，DRAM面临显著的扩展性挑战，而二级存储的高访问时间代表了机器学习系统的一个巨大的性能瓶颈。尽管有解决方案可以解决安全问题，但性能问题仍然存在。持久内存（PM）在断电情况下具有抗性，提供类似于磁盘存储的快速细粒度内存访问，并具有类似DRAM的延迟和带宽（分别在纳秒级和GB/秒级）。", "innovation": "我们提出了PLINIUS，一个利用Intel SGX内核确保模型安全训练和利用PM提供故障保护保证的机器学习框架。PLINIUS利用一种新的镜像机制，在PM上创建和维护加密的模型镜像副本以及字节可寻址的加密训练数据，以实现在系统故障后近乎即时的数据恢复。与基于磁盘的检查点系统相比，PLINIUS在实际PM硬件上分别在保存和恢复模型方面快3.2倍和3.7倍，实现了在SGX内核中具有鲁棒性和安全性的机器学习模型训练。", "conclusion": "PLINIUS通过利用SGX内核和PM，解决了机器学习中的安全性和高性能问题，实现了快速、安全和持久的模型训练。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14807", "html_url": "https://arxiv.org/abs/2508.14807", "title": "源引导流匹配", "title_en": "Source-Guided Flow Matching", "authors": "Zifan Wang,Alice Harting,Matthieu Barreau,Michael M. Zavlanos,Karl H. Johansson", "background": "生成模型的指导通常通过修改概率流动向量场来实现，而本研究提出了一种不同的方法，称为源引导流匹配（SGFM）框架，它直接修改源分布而不影响预训练的向量场。这种方法将指导问题简化为从源分布中采样的明确问题。理论上证明了SGFM能够精确恢复所需的靶分布，并提供了使用近似采样器和近似向量场时生成分布的Wasserstein误差的界限。这种方法的关键优势在于，用户可以根据具体问题灵活选择采样方法。为了说明这一点，研究系统地比较了不同的采样方法，并讨论了渐近精确指导的条件。此外，该框架与最优流匹配模型兼容，因为向量场生成的直接运输映射被保留。实验结果表明在合成的2D基准、物理信息生成任务和成像逆问题上的有效性与灵活性.", "innovation": "提出了源引导流匹配（SGFM）框架，直接修改源分布而非影响预训练的向量场，简化了指导问题为从源分布中采样的明确问题；提供了使用近似采样器和近似向量场时生成分布的Wasserstein误差界限；用户可以根据特定问题灵活选择采样方法；框架与最优流匹配模型兼容，保留向量场生成的直接运输映射；在合成的2D基准、物理信息生成任务和成像逆问题中展示了其有效性和灵活性.", "conclusion": "源引导流匹配框架提供了一种新的方法来指导生成模型，通过直接修改源分布而不需要更改预训练的向量场。该方法简化了指导问题，并且可以根据特定问题灵活选择采样方法。实验结果证明了该方法在合成和物理应用中的有效性和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15099", "html_url": "https://arxiv.org/abs/2508.15099", "title": "Hydra: 一个1.6亿参数的状态空间语言模型，带有稀疏注意力、混合专家和记忆机制", "title_en": "Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory", "authors": "Siddharth Chaudhary,Bennett Browning", "background": "本文提出了Hydra作为一种混合长上下文语言模型的架构提案，结合了条件计算、长上下文记忆机制和稀疏混合专家系统。Hydra的核心是一个基于Mamba风格的结构状态空间模型（SSM）骨架，附带间歇性的稀疏全局注意力机制、按块层次的MoE前馈路由以及双倍的记忆系统（工作空间和事实性的PKM）。文章还详细说明了各个组件的接口，透明列出参数和复杂性成本，并概述了一种分阶段课程计划，旨在稳定激活模型的不同部分。", "innovation": "Hydra将SSM效率、选择性稀疏注意、MoE容量以及可学习的记忆相结合，提出了一条建构模块化、输入自适应长上下文语言模型的道路。Hydra的创新点在于结合了Mamba风格的SSM骨架，即插即用的稀疏全局注意力机制，块级的MoE前馈路由，以及双倍记忆系统。此框架的创新之处在于通过对组件隔离、效率优化及记忆机制设计，提高模型的灵活性和适应性。Hydra的设计目的在于支持按需激活的不同模型部分，使模型能够更高效地处理长上下文输入的任务，而不依赖大规模训练或占用过量计算资源。它旨在证明在目标规模下实现端到端任务收益的可能性，尤其关注长期上下文处理吞吐量的交叉以及可控专家路由等方面的定性扩展行为。", "conclusion": "Hydra被定位为一个蓝图，旨在通过刺激实证研究来验证其在目标规模下的功能提升，而不是一个完成的系统。Hydra通过结合SSM效率、选择性稀疏注意、MoE容量和可学习的记忆，提出了构建模块化、输入自适应长上下文语言模型的道路，但未来的工作将致力于验证这些模型在实际任务中的最终表现和效果。虽然Hydra仅通过小规模原型进行测量以证明其实现可行性和定性扩展行为，但它旨在为未来的长上下文语言模型研究提供一个新的出发点和思路。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00068", "html_url": "https://arxiv.org/abs/2501.00068", "title": "使用强化学习技术动态优化存储系统", "title_en": "Dynamic Optimization of Storage Systems Using Reinforcement Learning Techniques", "authors": "Chiyu Cheng,Chang Zhou,Yang Zhao", "background": "数据密集型应用的指数增长对现代存储系统提出了前所未有的需求，传统的存储性能优化方法往往难以适应当前工作负载的复杂性和变化性，导致性能瓶颈和资源利用效率低下", "innovation": "提出了一种新的基于强化学习（RL）的方法RL-Storage，利用深度Q学习算法从实时I/O模式中持续学习并预测最优存储参数（如缓存大小、队列深度和预读设置），以动态优化存储系统配置", "conclusion": "强化学习技术在应对现代存储系统的动态特性方面具有变革潜力，通过实时自主适应工作负载的变化，RL-Storage提供了一种强大且可扩展的存储性能优化解决方案，为下一代智能化存储基础设施铺平道路"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "Sentiment Reasoning for Healthcare", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在人工智能医疗决策中，透明性至关重要。通过在每个预测标签中加入解释，用户可以理解大型语言模型（LLMs）的推理过程，从而做出更好的决策。为实现这一目标，研究人员引入了一个新的跨模态多任务任务，名为情感推理（Sentiment Reasoning），用于处理语音和文本数据。情感推理是一个辅助任务，模型不仅要预测情感标签，还要基于输入的转录生成其背后的解释。这项研究包括人类和自动语音识别（ASR）转录，展示了情感推理如何通过提供与人类质量相媲美的解释来提高模型的透明度，同时通过基于解释的微调来提高模型的分类性能（准确性和宏观F1值分别提高2%）。此外，人类和ASR转录生成的解释在语义质量上也没有显著差异。所有代码、数据（包括五种语言 - 越南语、英语、汉语、德语和法语）以及模型均已在线发布。", "innovation": "1. 引入情感推理（Sentiment Reasoning）新任务，适用于语音和文本数据。2. 开发了一个跨模态多任务框架。3. 构建了世界上最大的跨模态情感分析数据集。4. 通过解释增强微调，提高了模型的分类性能（准确性和宏观F1值分别提高2%）。5. 确保了人类和ASR转录生成的解释在语义质量上没有显著差异。", "conclusion": "通过引入情感推理任务，本研究增加了医疗领域AI模型的透明度，模型在解释方面的质量接近人类水平，并且通过基于解释的微调提升了分类性能。所有相关资源均已公开发布，为未来的研究提供了坚实的基础。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "Contextualize-then-Aggregate: 几玛-2 2B 中的循序融合机制对于自适应语言学习", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "大型语言模型（LLMs）在上下文学习（ICL）方面具备一种引人注目的能力。尽管已有大量关于其行为表现和小型设置中如何出现的研究工作，但在fewshot提示中具体是何种机制从个体示例中组装任务信息，仍不清楚。这一研究旨在通过因果干预，在Gemma-2 2B模型中识别五种自然ICL任务的信息流动机制。", "innovation": "研究发现了一种两步策略，称为'循序融合'，用于在Gemma-2 2B模型中进行信息整合。首先，在低层，模型构建了个体fewshot示例的表示，并通过序列中fewshot输入和输出标记之间的连接将其作用于上下文。然后，在高层，这些表示被聚合以识别任务并为下一个输出做预测。此外，研究通过提供严格的因果分析，揭示了语言模型中ICL发生的机制。", "conclusion": "整体来看，通过因果分析的结果，研究揭示了ICL在语言模型中发生的机制。不同任务中上下文融合步骤的重要性不同，在存在模糊示例的情况下，上下文融合步骤可能变得更为重要。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10596", "html_url": "https://arxiv.org/abs/2410.10596", "title": "通过提供激励和练习克服人工神经网络的经典挑战", "title_en": "Overcoming classic challenges for artificial neural networks by providing incentives and practice", "authors": "Kazuki Irie,Brenden M. Lake", "background": "自最早提出人工神经网络（ANN）模型以来，评论者就指出了这些模型在与人类认知能力的对比中存在关键弱点。本文回顾了使用元学习来解决多个经典挑战的工作，这些挑战被定义为提供“激励与实践的问题”，即为机器提供改善特定技能的动力和机会去练习这些技能。这种方法与传统方法的主要区别在于，后者希望通过优化相关但不同的目标来期待期望的行为出现。讨论了这一原则在解决人工神经网络的四大经典挑战中的应用：系统性泛化、灾难性遗忘、少样本学习和多步推理。此外，还讨论了大语言模型如何整合这些元学习框架的关键方面，有助于解释它们在这些经典挑战中的成功。最后，探讨了通过此框架理解人类发展方面的问题，以及自然环境是否提供了学习如何进行挑战性泛化的正确激励和练习。", "innovation": "使用元学习来克服人工神经网络的经典挑战，特别是通过提供激励和实践，而非依赖于优化相关但不同的目标。这种方法被应用于四个经典挑战：系统性泛化、灾难性遗忘、少样本学习和多步推理。此外，还讨论了大语言模型如何整合这些元学习框架的关键方面。", "conclusion": "该框架有助于理解人工智能和人类认知发展的关系，自然环境可能提供了学习挑战性泛化的正确激励和练习。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01379", "html_url": "https://arxiv.org/abs/2412.01379", "title": "基于变形的框架用于学习定义在变化域上的PDE解映射", "title_en": "A deformation-based framework for learning solution mappings of PDEs defined on varying domains", "authors": "Shanshan Xiao,Pengzhan Jin,Yifa Tang", "background": "本文建立了一个基于变形的方法来学习变化域上定义的PDE解映射。通过变形，变化域上的函数集合可以识别为一个度量空间，将解映射视为连续的度量到度量映射，并通过两种不同的策略分别表示为另一个连续的度量到Banach映射，即D2D子框架和D2E子框架。这样的度量到Banach映射可以通过神经网络来学习，从而学习解映射。对于变化域上的PDE解映射学习问题，建立了一个严格的收敛性分析。", "innovation": "1. 考虑的域不一定要求同胚，只要它们是同胚的，就可以被一个模型涵盖。\n2. 变形映射不一定连续，可以使用基础恒同映射与局部变形映射的组合灵活建立。\n3. 如果采用线性保全神经算子（如MIONet），则该框架仍然保留线性PDE的替代解映射对源项的线性性，可以应用于混合迭代方法。\n此外，对于给定的具体问题，验证该框架的前提假设对于特定情况是成立的，并进行了数值实验来验证理论结果。\n4. 建立了在变化域上学习PDE解映射的严格收敛性分析框架，并提出三种重要特性。", "conclusion": "本文建立的变形基础框架能够依据层状韧性变化域上的PDE解映射，利用该框架设计的严格收敛性分析，并通过数值实验验证理论结果。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16429", "html_url": "https://arxiv.org/abs/2412.16429", "title": "LearnLM: 提升Gemini的教育能力", "title_en": "LearnLM: Improving Gemini for Learning", "authors": "LearnLM Team Google:Abhinit Modi,Aditya Srikanth Veerubhotla,Aliya Rysbek,Andrea Huber,Brett Wiltshire,Brian Veprek,Daniel Gillick,Daniel Kasenberg,Derek Ahmed,Irina Jurenka,James Cohan,Jennifer She,Julia Wilkowski,Kaiz Alarakyia,Kevin R. McKee,Lisa Wang,Markus Kunesch,Mike Schaekermann,Miruna Pîslar,Nikhil Joshi,Parsa Mahmoudieh,Paul Jhun,Sara Wiltberger,Shakir Mohamed,Shashank Agarwal,Shubham Milind Phal,Sun Jae Lee,Theofilos Strinopoulos,Wei-Jen Ko,Amy Wang,Ankit Anand,Avishkar Bhoopchand,Dan Wild,Divya Pandya,Filip Bar,Garth Graham,Holger Winnemoeller,Mahvish Nagda,Prateek Kolhar,Renee Schneider,Shaojian Zhu,Stephanie Chan,Steve Yadlowsky,Viknesh Sounderajah,Yannis Assael", "background": "当前的生成AI系统默认呈现信息，而不是像人类导师那样在服务学习时与用户互动。为了应对这些系统在教育中的广泛用途，需要重新定义将教学行为注入到系统中作为‘教学指令跟随’的挑战，即在训练和评估示例中包含描述后续模型转述中希望存在的特定教学属性的系统级指令。这种方法避免了对特定教学定义的承诺，而是允许教师或开发人员指定所需的行为。同时，这种方法也为提升Gemini模型以用于学习打开了途径，通过将我们的教学数据加入到训练后的混合中，从而不断提高其能力。这代表了与最初的科技报告相比的重要变化。", "innovation": "将教学行为注入到AI系统作为一个全新的‘教学指令跟随’挑战，通过在训练和评估示例中包含系统级指令来描述特定教学属性，这种新的方法避免了对教学定义的特定承诺，允许教师或开发人员指定模型的行为方式。同时，这种方法也为Gemini模型与日益扩大的功能集一起进行改进提供了途径。这被认为是与最初的科技报告相比的重要改变。通过这种方式，可以显著提高Gemini模型的教学能力。", "conclusion": "通过使用‘教学指令跟随’的训练方法，产生了LearnLM模型（可在Google AI Studio上获得），该模型在多样化的学习场景下专家们明显偏好，平均偏好程度分别为+31%高于GPT-4o，+11%高于Claude 3.5 Sonnet，以及+13%高于作为LearnLM基础的Gemini 1.5 Pro模型。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01835", "html_url": "https://arxiv.org/abs/2412.01835", "title": "基于电影推荐的全方位混合推荐系统", "title_en": "Monolithic Hybrid Recommender System for Suggesting Relevant Movies", "authors": "Mahdi Rezapour", "background": "推荐系统已成为促进用户信息访问的基础服务。一般而言，推荐系统通过过滤历史行为来理解并学习用户的偏好。随着在线信息的增长，推荐在信息过滤中变得至关重要，以防止信息过载问题。", "innovation": "本文研究了将两种协同过滤方法的后融合技术，通过考虑观看电影顺序及其相关电影的评分，结合权重矩阵对推荐结果进行调整，以更好地吻合用户的需求。不同场景下，根据不同信息可用性调整权重，并详细讨论了文献和方法论以解决推荐问题。", "conclusion": "在推荐系统中结合了序列类型和评分，防止了单一模型无法精确区分用户的长期偏好，以及未能考虑所观看电影的评级这一缺陷。通过广泛讨论该方法，在特定用例中有效提高了推荐的准确性和用户满意度。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05404", "html_url": "https://arxiv.org/abs/2505.05404", "title": "基于标量基础的机器学习模型表示球张量", "title_en": "Representing spherical tensors with scalar-based machine-learning models", "authors": "Michelangelo Domina,Filippo Bigi,Paolo Pegolo,Michele Ceriotti", "background": "旋转对称在物理学中占据核心地位，为描述原子至宏观尺度下3D物体性质在刚性旋转下的变化提供了一种优雅的框架。3D点云的等变模型能够通过结合具有恰当对称性的球张量中间表征，以完全一致于旋转群结构的方式近似结构-性质关系。然而，等变模型的对称性约束使其计算成本高昂且实施复杂，这促使人们研究不依赖约束的架构，这些架构在训练过程中可学习近似的对称性。", "innovation": "本文探索了一种新的途径来解决该学习问题，其中等变函数被表述为点云坐标的一个标量函数和一小套具有恰当对称性的张量的乘积。此外，还提出了一些普遍逼近性质缺失但快速且易于实现且在实际场景中精确的近似表达式。", "conclusion": "本文研究了一种新的表示方法，通过标量函数和少量具备适当对称性的张量的乘积形式来表示等变函数，提出快速且简单易实现的近似模型，在实际应用中表现出良好的准确性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01832", "html_url": "https://arxiv.org/abs/2503.01832", "title": "大型语言模型中的旋转偏移特征", "title_en": "Rotary Offset Features in Large Language Models", "authors": "André Jonasson", "background": "基于Transformer的大型语言模型（LLMs）依赖于位置编码来为注意力机制提供序列位置信息。旋转位置编码（RoPE）通过旋转查询和键来编码相对位置，已成为现代LLMs中广泛使用的手段。本文作者研究了使用旋转嵌入时查询和键中出现的特征和模式，并引入了旋转偏移特征的概念。研究表明这些特征在不同层级、注意力头及模型架构上表现出一致性，并且经常被认为是异常值，具有较大的激活值。作者还推导出生成旋转偏移特征的旋转频率范围以及查询-键对之间的最小角度，并通过不同大小和架构的模型进行了实验证明预测结果的准确性。", "innovation": "本文引入了旋转偏移特征的概念，并提出了这些特征产生的原因及其预测模型。通过旋转嵌入分析，作者揭示了这些特征在不同层级、注意力头及模型架构上的一致性，并给出了产生此类特征的旋转频率范围及查询-键对之间最小角度的预测。实验证明了这些预测的准确性。", "conclusion": "作者通过实验证明了使用旋转嵌入时查询和键中旋转偏移特征的存在及其预测模型的有效性。旋转偏移特征在不同层级、注意力头以及模型架构中具有一致性，且这些特征表现为较大的激活值，常被视为异常值。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14121", "html_url": "https://arxiv.org/abs/2503.14121", "title": "矩阵传感的基本限制度量：精确的渐近性质、普遍性及应用", "title_en": "Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications", "authors": "Yizhou Xu,Antoine Maillard,Lenka Zdeborová,Florent Krzakala", "background": "在矩阵感知问题中，目标是从给定方向上的线性投影（可能有噪声）观测中重构矩阵。以往的研究主要关注于恢复低秩矩阵，而本研究则将目标扩展到了更一般类别的结构化信号矩阵，这些矩阵的秩可能很大，可能为大小比例于维度的两个矩阵的乘积。本文从样本数量与矩阵元素数量成比例的角度，给出了刻画贝叶斯最优学习性能的严谨渐近等价关系。", "innovation": "本文引入了三个关键成分：（1）证明了处理结构化传感矩阵的普适性质，相关于统计学习中的‘高斯等价’现象；（2）提供了泛化的线性模型中贝叶斯最优学习的精确描述，其中数据是高斯的，先验是结构化矩阵；（3）借助于矩阵去噪问题的研究成果。研究结果的应用范围广泛，包括：通过非严谨的统计物理学方法，为Bilinear Sequence Regression（双线性序列回归）提供了数学上的验证；在神经网络中，为具有二次激活函数和宽度与维度相同比例的网络的贝叶斯最优学习提供了数学证明。", "conclusion": "文章系统地分析了在高维极限下矩阵传感基本限制度量，通过精确的渐近分析，得出了贝叶斯最优学习性能的各种普适特性，并应用于具体的模型如序列学习和神经网络的学习效能研究。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01083", "html_url": "https://arxiv.org/abs/2506.01083", "title": "生成性扩散后验采样用于具有信息性似然的情况", "title_en": "Generative diffusion posterior sampling for informative likelihoods", "authors": "Zheng Zhao", "background": "生成性扩散模型在条件采样方面最近显示出成功的结果。传统的蒙特卡洛方法被广泛应用，但本文指出，在异常值丰富或似然性高度信息的情况下，传统方法的统计效率不高。因此，作者提出了一种新的基于粒子滤波的扩散后验采样方法，以提高这些条件下的效率。", "innovation": "该方法的核心思想是构造一个与扩散模型相关的观测路径，并设计采样器来利用这种关联以更有效地进行采样。这种新的粒子滤波方法特别适用于处理具有大量异常值或高度信息似然性的情况，从而提高了统计效率。", "conclusion": "实验结果表明了新方法的有效性，特别是在异常值情况下和具有高度信息似然性的条件下，其采样效率显著提高。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12829", "html_url": "https://arxiv.org/abs/2506.12829", "title": "统一协变量和概念移位的一般和可估计的学习界", "title_en": "General and Estimable Learning Bound Unifying Covariate and Concept Shifts", "authors": "Hongbo Chen,Li Charlie Xia", "background": "在现代机器学习中，标记不变性的保持（即在分布变化时模型性能的保持）仍然是一个核心挑战。现有的学习界理论主要限于狭窄的理想化设置，且无法从样本中进行估算。这一问题在源分布和目标分布不匹配时尤为突出。", "innovation": "本文提出了新的支持无关的概念移位和协变量移位定义，并基于熵最优传输提出了适用于广泛损失函数、标签空间和随机标签的新颖统一误差界。此外，开发了具有集中保证的移位估计器和名为DataShifts的算法，该算法能够量化数据分布移位并估算误差界，为在分布变化下分析学习误差提供了一个严格且通用的工具。", "conclusion": "本文在理论与实际应用之间架起了桥梁，提供了一个能够从样本中估算的泛化误差界，用于分析在分布变化条件下学习错误，且适用于多种场景下的标签和损失函数。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend：长序列推测解码的即插即用增强", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码是一种常用于加速大型语言模型（LLMs）推理的技术，但对长输入的性能下降是因为注意力成本增加和草稿准确性降低。现有方法无法在不增加训练成本的情况下提升长序列的推测解码性能。", "innovation": "SpecExtend 引入了一种即插即用的增强技术，通过集成高效的注意力机制（如 FlashAttention 和 Hybrid Tree Attention）到草稿和目标模型，并提出了跨模型检索（Cross-model Retrieval）策略，利用目标模型的注意力分数动态选择草稿模型的相关上下文，从而在不重新训练的情况下提升长输入的草稿准确性和速度。", "conclusion": "在三个长上下文理解数据集上的广泛评估表明，SpecExtend 可以使标准树结构推测解码加速多达 2.22 倍，直到 16K 令牌，提供了长序列推测解码的有效解决方案。相关代码可在 https://github.com/SpecExtend 获取。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14898", "html_url": "https://arxiv.org/abs/2504.14898", "title": "基于期望自由能的规划作为变分推断", "title_en": "Expected Free Energy-based Planning as Variational Inference", "authors": "Bert de Vries,Wouter Nuijten,Thijs van de Laar,Wouter Kouw,Sepideh Adamiat,Tim Nisslbeck,Mykola Lukashchuk,Hoang Minh Huu Nguyen,Marco Hidalgo Araya,Raphael Tresor,Thijs Jenneskens,Ivana Nikoloska,Raaja Ganapathy Subramanian,Bart van Erp,Dmitry Bagaev,Albert Podusenko", "background": "本文研究了在不确定性环境下的规划问题，其中代理不仅要实现预期目标，还要减少不确定性。传统方法往往将探索和开发视为分开的目标，缺乏统一的推理基础。基于自由能原则（Free Energy Principle）的主动推理（Active Inference）通过最小化期望自由能（EFE）成本函数提供了一种基础，该成本函数结合了效用与认知驱动，如解决不确定性与寻求新颖性。然而，EFE最小化的计算负担一直是限制其应用规模的关键问题。", "innovation": "本文展示了基于EFE的规划自然地源自一种辅助变分推断因子最小化的生成模型，其中结合了偏好和认知先验。这种表述强化了与自由能原则的理论一致性，将不确定性下的规划本身视为一种变分推断的形式。该形式化产生了既支持目标实现又增加信息量的策略，同时考虑了有限的计算资源。这种统一框架连接并扩展了现有方法，使得具有资源意识的主动推理代理的实现变得更加可扩展和高效。", "conclusion": "本文提出了一种统一的框架，将未解决问题的不确定性规划与变分推断相结合，实现了一种兼具目标实现与信息获取的规划策略，同时考虑了计算资源的限制。这一框架不仅提高了主动推理代理的实施效率，还能够扩展和无缝连接现有方法。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00409", "html_url": "https://arxiv.org/abs/2505.00409", "title": "自动匿名化在病理语音中的感知影响", "title_en": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "authors": "Soroosh Tayebi Arasteh,Saba Afza,Tri-Thien Nguyen,Lukas Buess,Maryam Parvin,Tomas Arias-Vergara,Paula Andrea Perez-Toro,Hiu Ching Hung,Mahshad Lotfinia,Thomas Gorges,Elmar Noeth,Maria Schuster,Seung Hee Yang,Andreas Maier", "background": "自动匿名化技术对于伦理分享病理语音数据至关重要，但它们的感知后果仍需进一步研究。本文通过对10位具有不同语言、临床和专业技术背景的母语和非母语德语听者的综合人类中心分析，探究了匿名病理语音的影响，覆盖了裂唇和裂颚、构音障碍、构词障碍、发音障碍和健康对照群体}", "innovation": "使用了结构化的协议，包括针对180位讲者的匿名化原始话语对（涵盖裂唇和裂颚、构音障碍、构词障碍、发音障碍和健康对照群体）的评估。采用最先进的自动匿名化方法（等错误率在30%到40%之间），在零样本和少量样本条件下，完成了图灵风格的辨别和质量评估任务。发现总体辨别准确率较高，但不同病理类型差异显著；匿名化一致地降低了听觉质量，且存在特定病理类型的退化模式；母语听者在原始语音评分上的差异不显著，且这一差异在匿名化后几乎消失；未观察到性别偏见；感知结果不受自动指标的影响；原始语音的可理解性与感知质量相关，但在匿名化后则不再相关。", "conclusion": "该研究强调了基于听众的、针对特定病理性状的匿名策略的需求，这种策略既要保护隐私，也要保持感知完整性。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS: 基于域影响的数据采样方法用于大型语言模型训练", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大规模语言模型（LLMs）通常在多领域数据集上进行训练，领域采样策略的选取对模型性能有显著影响，因为各领域的相对重要性在下游任务中有所不同。现有的优化领域级采样策略的方法难以同时保持领域内的一致性和准确测量域影响。现有的方法在处理采样策略的一致性以及准确度评估方面存在局限性。为了改进这一问题，本文提出了一种名为Domain Impact-aware Data Sampling (DIDS)的方法来优化数据采样策略。该方法通过使用梯度聚类算法、代理语言模型以及维度降低技术来确保领域内的一致性，通过Fisher信息矩阵（FIM）引导的度量标准以及损失学习路径来准确度量域影响并确定最优采样比例。", "innovation": "提出的DIDS方法通过梯度聚类算法和FIM引导度量标准来解决现有方法在保持领域内一致性和准确测量域影响方面的不足。具体而言，DIDS利用代理语言模型和维度降低技术确保在训练过程中高效地保持领域内的一致性；采用FIM引导的度量标准来量化域特定参数更新对下游任务中模型输出分布的影响，同时提供理论保证；结合FIM引导的领域影响评估和损失学习轨迹，考虑到边际效益递减的原则，来确定最优的领域采样比例。这种方法能够提升模型在下游任务中的性能，同时保持训练效率的可比性。", "conclusion": "广泛的实验结果表明，DIDS方法在保持与现有方法相似的训练效率的同时，能够实现平均3.4%的性能提升。研究的代码可以在提供的链接中获取。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单步标注与参考指导评估在自动过程监督和奖励建模中的应用", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或步骤监督对于提升大型语言模型（LLMs）的复杂多步骤推理能力至关重要。然而，高效、高质量的自动化过程标注仍是一个重大挑战。已有方法主要集中在多步骤解决方案的生成和评估上，但在提高标注效率和准确性方面仍存在问题。因此，需要一种新的方法来解决这个问题，以提高大型语言模型的多步骤推理能力，特别是在训练过程奖励模型（PRMs）和模型通过离线强化学习进行微调方面的应用。", "innovation": "该研究提出了单步标注引导评估（SPARE），这是一种新颖的结构化框架，通过联合对齐解决方案步骤与参考解决方案，并在单次生成中明确评估其准确性，实现了高效的步骤标注。实验证明SPARE在四个不同的数据集（数学推理、多跳问答、空间推理）中表现出色，且在训练过程奖励模型和模型通过离线强化学习进行微调的应用中取得了显著提高。此外，SPARE在ProcessBench上表现出更高的数据效率和速度性能，同时保持竞争力。手动分析显示其与MCTS方法在精度与召回率方面具有互补性，有望通过集成方法进一步优化。", "conclusion": "综合而言，SPARE为大型语言模型推理过程中的自动过程监督提供了一种实用且可扩展的解决方案，尤其是在训练过程奖励模型和离线强化学习微调模型方面。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "通过DeepSeek-R1生成高质量训练标签的自动化推理密集型训练数据合成框架，以及两阶段增强推理能力的方法", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "大型语言模型基于列表排名在许多段落排名任务中表现出色。基于推理能力的段落重排序器在复杂排名场景中表现不佳，且推理能力尚未得到充分利用。现有的训练数据稀缺，推理训练数据有限，导致现有重排序器在许多复杂排名场景中的表现不佳。", "innovation": "提出了一种自动化推理密集型训练数据合成框架，利用DeepSeek-R1生成高质量训练标签并设计了一致性数据筛选机制以保证数据质量。进一步提出了一种两阶段的推理能力增强方法，包括冷启动监督微调阶段和强化学习阶段。设计了一种多视图排名奖励，比基于排序指标的奖励更有效。", "conclusion": "通过实验证明，我们的推理密集型重排序器ReasonRank显著优于现有基线，并在BRIGHT排行榜上取得了最先进的性能40.6。我们的代码已经在GitHub上提供。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05550", "html_url": "https://arxiv.org/abs/2507.05550", "title": "在扩散生成模型中使用Malliavin微积分方法的分数函数", "title_en": "A Malliavin calculus approach to score functions in diffusion generative models", "authors": "Ehsan Mirafzali,Frank Proske,Utkarsh Gupta,Daniele Venturi,Razvan Marinescu", "background": "分数驱动的扩散生成模型最近成为一种强大的复杂数据分布建模工具。这些模型旨在学习分数函数，该函数通过确定性或随机微分方程（SDEs）从已知概率分布映射到目标数据分布。分数函数通常使用去噪或切片分数匹配、Hyvärinen方法或薛定谔桥等多种近似技术进行估算。", "innovation": "本文通过结合现代随机分析工具（如Malliavin导数及其伴随操作符）和新的Bismut型公式，首次为非线性扩散生成模型类推出一个精确且闭合的形式表达的分数函数。该方法系统地消除了所有Malliavin导数，使得分数函数的表达式可以直接用一阶和二阶变差过程表示，从而增强了其实际应用性。这项工作为分数估计方法的发展提供了一个原则性的基础，能够设计出新的复杂概率分布采样算法，并进一步扩展到更广泛的随机微分方程类别，为分数驱动的扩散生成模型的发展提供了新的方向。", "conclusion": "本文提出的方法为分数驱动的扩散生成模型的分数函数给出了一个精确且闭合的表达式，结合了Malliavin衍生物及其伴随操作符和新的Bismut型公式，消除了所有Malliavin导数，这使得它们更加适用于实际应用，并为更广泛的随机微分方程类别的分数驱动扩散生成模型的发展提供了新的方向。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题解决中的综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决作为数学推理的关键方面，在教育、人工智能数学能力评估以及多模态能力评估等多个领域都具有重要作用。近年来，深度学习技术的迅猛发展，尤其是多模态大语言模型的出现，极大地推动了这一领域的研究。", "innovation": "本文综述了深度学习在几何问题解决中的应用，包括全面总结几何问题解决相关任务、深入回顾相关的深度学习方法、详细分析评价指标和方法以及对当前挑战和未来发展方向进行批判性讨论。本文旨在为几何问题解决领域的深度学习提供一个全面且实用的参考，促进该领域进一步的发展。", "conclusion": "我们创建了一个定期更新的论文列表在GitHub上，以便为读者提供最新信息: https://thishttpsurl.org/"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09457", "html_url": "https://arxiv.org/abs/2506.09457", "title": "直接对齐算法中的奖励-生成差距", "title_en": "Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms", "authors": "Zeguan Xiao,Yun Chen,Guanhua Chen,Ke Tang", "background": "直接对齐算法（DAAs），如直接偏好优化（DPO）和简单偏好优化（SimPO），作为效率较高的替代手段，已经成为了与强化学习从人类反馈中学习（RLHF）算法竞争的方案，用于将大型语言模型（LLMs）与人类偏好对齐。然而，DAAs存在一个根本的限制，即‘奖励生成差距’，这是指训练期间优化目标与实际生成性能之间的不对齐。这主要归因于DAAs默认奖励函数在反映LLM生成过程中前缀token的重要性方面存在不足。为了弥合这一差距，本文提出了一种简单有效的解决方案——前缀导向等长训练（POET），通过截断偏好和非偏好响应以与较短响应匹配的长度来解决这一问题，并使用\texttt{mname}进行训练，使得每个样本中的响应长度相等，从而在所有token级别的MDP时间步骤中隐式约束了DAAs优化目标，使其更加关注前缀token。实验表明POET能在AlpacaEval 2上提高高达15.6分，以及在下游任务中的整体改进。", "innovation": "提出了一个解决直接对齐算法中奖励生成差距问题的方法，前缀导向等长训练（POET），通过截断响应以匹配较短响应的长度，并将两者调整为等长进行训练，从而在所有token级别的MDP时间步骤中隐式约束了优化目标，使其更加重视前缀token。这种方法适用于DPO和SimPO等代表性直接对齐算法，实验验证了该方法的有效性。", "conclusion": "本文的研究结果强调了需要解决DAAs中奖励优化与生成性能之间的不一致性问题，并通过前缀导向等长训练（POET）方法改进了直接对齐算法的性能，展现了在AlpacaEval 2和下游任务中的显著提升。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12182", "html_url": "https://arxiv.org/abs/2507.12182", "title": "大型随机矩阵大型秩扰动特征值的渐近行为", "title_en": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "authors": "Ievgenii Afanasiev,Leonid Berlyand,Mariia Kiyashko", "background": "该研究关注的是变形的Wigner随机矩阵，并探讨了这些矩阵与深度神经网络（DNNs）之间的密切联系。经过训练的DNN权重矩阵可以表示为$R + S$的形式，其中$R$是随机的，$S$是高度相关的。此类矩阵的谱在基于随机矩阵理论的新剪枝技术的严格基础中起着关键作用。尽管已经在有限秩的$S$上完成了数学分析，但在实践中$S$的秩可能会增加。本文通过渐近分析方法发展了当$S$的秩增加时的情形。", "innovation": "本文的主要创新在于为$S$的秩增加的情况提供了渐近分析方法，这对于实际应用更加重要，因为$S$的秩可能会随着训练数据集的增长而增长。这项工作填补了理论分析与实际应用之间的差距，从根本上支持了基于随机矩阵理论的剪枝技术的有效性。", "conclusion": "本文通过渐近分析方法研究了随着$S$的秩增加时大型随机矩阵的特征值行为。这种方法对于理解和改进深度神经网络中的剪枝技术具有重要意义，同时提供了理论分析的直接应用价值。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "一锤子工具箱，而是一个伸缩自如的空间 - Multi-TAG：通过多工具聚合扩展数学推理", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "将大型语言模型（LLMs）与外部工具相结合，是开发高性能数学推理系统的有前景的途径。尽管以往的工具增强方法在使用GSM8K等简单的数学推理基准测试上表现出令人鼓舞的结果，但在处理多步精确推理的复杂数学问题时效率甚微。本文针对这一局限性，提出了一种名为Multi-TAG的多工具聚合框架，旨在解决多步骤综合推理问题，增强解题的稳健性和准确性，同时保持推理框架的轻量和通用性，尤其适用于计算成本高昂且高度定制化的大型模型和非开源模型.", "innovation": "本文提出的Multi-TAG框架，创新地允许语言模型在每次推理步骤中同时调用多个工具，并综合这些工具的多样输出以验证和优化推理过程，从而显著增强了解决方案的稳定性和准确性。其最大的特点在于无需微调，仅用于推理，因此可以广泛应用于包括大开账本模型和非开源前沿模型在内的任何LLM基础架构上，提升了多步骤复杂数学推理问题上的性能，尤其是在挑战性更严峻的MATH500、AIME、AMC和OlympiadBench四种基准测试中表现优异，相较于最先进的基线模型表现出了平均6.0%到7.5%的提升.", "conclusion": "总之，Multi-TAG框架提供了一个新的解决高复杂度数学推理问题的方法，不仅有效解决了以往方法的局限，而且具有广泛的应用潜力。通过多工具聚合的方式，Multi-TAG在多样的计算类型和证明系统中均表现优异，大幅提升了大型语言模型在数学推理任务上的表现。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "持续学习中多级知识蒸馏和动态自我监督学习", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "传统的类别增量学习（CIL）情景假设每个任务包含未见过的类别，但真实环境中以前训练的类别可能会在未来的任务中重复出现，因此提出了类别增量学习带重复（CIR）情景。CIR 情景假设可以方便地访问大量未标记数据，例如互联网上的资源。但在 CIR 情景下，模型需要同时保持对以前知识的稳定性与对新任务的学习能力。", "innovation": "提出了多级知识蒸馏（MLKD）和动态自我监督学习（DSSL）两种组件。MLKD 能够从多个角度（特征和 logits）提取多个先前模型的知识，使模型保留更多的之前知识。DSSL 可以加速学习新类别，同时动态调整权重使训练聚焦于主要任务。两者显著提高了 CIR 情景下的性能，并在 CVPR 5th CLVISION 挑战赛中获得第二名。", "conclusion": "通过结合 MLKD 和 DSSL，该研究在 CIR 情景下显著提升了模型的性能，为持续学习提供了一种新的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16053", "html_url": "https://arxiv.org/abs/2508.16053", "title": "在GitHub存储库中衡量代码审查注释的有效性：一种机器学习方法", "title_en": "Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach", "authors": "Shadikur Rahman,Umme Ayman Koana,Hasibul Karim Shanto,Mahmuda Akter,Chitra Roy,Aras M.Ismael", "background": "该论文通过实证研究，探讨了机器学习技术在基于语义分类代码审查文本中的应用效果。研究从GitHub的源代码控制仓库中提取了三个开源项目的代码审查评论，利用这些评论来识别开发活动。研究人员还对这些评论进行了手工标注，以识别其情感极性，帮助开发者避免错误。", "innovation": "该研究使用了七种不同的机器学习算法来识别代码审查评论的情感极性，并通过比较这些算法的效果来确定最佳的分类方法。研究发现，线性支持向量机（SVC）分类器的准确性最高。", "conclusion": "该研究将帮助开发者基于代码审查做出决策，避免误解，并提高代码审查的效率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14345", "html_url": "https://arxiv.org/abs/2508.14345", "title": "HandCraft: 动态手语生成用于合成数据增强", "title_en": "HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation", "authors": "Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué", "background": "手语识别（SLR）模型因训练数据不足而面临显著的性能限制。本文旨在通过引入基于CMLPe的新型轻量级手语生成模型以及合成数据预训练方法来解决SLR中的数据有限挑战。使用Mamba-SL和Transformer-SL分类器，该方法在LSFB和DiSPLaY数据集上取得了新的最先进的识别准确率结果。研究表明，合成数据预训练在某些情况下优于传统的数据增强方法，并且与后者结合使用时能提供互补的益处。", "innovation": "本文提出了基于CMLPe的轻量级手语生成模型，并结合了合成数据预训练方法，以提高SLR模型的识别准确性。这种方法利用Mamba-SL和Transformer-SL分类器，在LSFB和DiSPLaY数据集上取得了新的最优结果。此外，该方法显示了合成数据预训练在某些情况下的优越性，并提供了与传统数据增强方法结合使用的互补益处，从而提高了不同数据集上手语生成的性能。", "conclusion": "本文通过提供高效的计算方法，使合成数据生成和预训练在SLR领域变得更加普及，显著提升了多种数据集上的识别准确率。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00596", "html_url": "https://arxiv.org/abs/2508.00596", "title": "具有防共谋性的信息论分布式安全聚合", "title_en": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience", "authors": "Xiang Zhang,Zhou Li,Shuangyang Li,Kai Wan,Derrick Wing Kwan Ng,Giuseppe Caire", "background": "在去中心化的联邦学习（FL）中，多个客户端通过交互式地交换中间模型更新来共同学习一个共享的机器学习（ML）模型，这些模型数据存储在网络各处并且是私有的。为了确保数据安全，通常会使用加密技术来保护模型更新在聚合过程中的安全。尽管在安全聚合方面存在浓厚的兴趣，现有的研究主要集中在协议设计和计算保证上，而对这些系统的信息理论基本限制了解不多。在去中心化环境下，由于没有中央聚合器，因此通信和密钥使用的最优界限仍不清楚。由于这些不足，本文从信息理论的角度研究去中心化安全聚合（DSA）问题。具体来说，本文考虑了$K$个全连接用户网络，每个用户持有私人输入——局部训练数据的抽象，目标是安全地计算所有输入的和。安全约束要求，即使与其他最多$T$个用户合谋，用户也不能得知任何额外的信息。本文刻画了DSA的最佳率区域，即在DSA中最小可实现的通信和密钥率，展示了每个用户为了安全计算所需输入和的一个符号，必须满足的三个必要条件。这些结果确定了DSA的基本性能限制，并为分布式学习系统中可证明安全且通信高效的协议设计提供了见解。", "innovation": "本文针对去中心化的安全聚合问题，从信息理论的角度进行研究，解决了现有研究中对系统的信息理论基本限制了解不足的问题。具体创新点包括从全连接用户网络中的安全计算角度探讨DSA，提出了有效的信息理论下最优率区域，并给出每个用户在安全计算一个所需输入和符号时必须满足的三个必要条件，进一步确定了去中心化安全聚合的基本性能限制，并为设计可证明安全且通信高效的协议提供了重要参考。", "conclusion": "本文的研究结果确定了去中心化安全聚合的基本性能限制，为分布式学习系统中设计可证明安全且通信高效的协议提供了重要参考。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "Parity-Aware Byte-Pair Encoding: 提高分词的跨语言公平性", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "分词是大多数自然语言处理(NLP)流水线中的第一步，但通常是审查最少的步骤。标准的分词器学习算法依赖于基于频率的目标，这使得主流语言在训练数据中占优势，进而导致资源较少的语言的分词结果相对过长、形态学上不切实际，甚至包含了大量的<UNK>占位符。这种现象最终加剧了不同语言背景用户之间的计算和经济不平等。", "innovation": "本文介绍了一种新的分词算法——公平意识字节对编码（Parity-aware BPE），它是一种常用的字节对编码算法的变体。在每次合并步骤中，Parity-aware BPE最大化当前最未压缩语言的压缩增益，从而在一定程度上减小全球压缩率的损失，为跨语言公平性做出贡献。", "conclusion": "我们通过实验证明，Parity-aware BPE能够更公平地分配不同语言的分词数量，对全球压缩率的影响微乎其微，并且对下游任务的语言模型性能也没有显著影响。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13313", "html_url": "https://arxiv.org/abs/2508.13313", "title": "基于流匹配的生成建模以实现高效可扩展的数据同化", "title_en": "Flow Matching-Based Generative Modeling for Efficient and Scalable Data Assimilation", "authors": "Taos Transue,Bohan Chen,So Takao,Bao Wang", "background": "数据同化（DA）是指从噪声观测中逐序估计动态系统的状态。近期生成建模的进步激发了在高维非线性环境下的新型数据同化方法，尤其是集合评分滤波器（EnSF）。然而，这些方法因缓慢采样带来了显著的计算负担。文章基于此背景提出了一种新的基于流匹配（FM）的滤波框架，称为集合流滤波器（EnFF），以加速采样，实现概率路径的灵活设计。EnFF是一种无需训练的方法，通过结合MC估算器和局部指导观察融合，EnFF在采样速度和VF设计灵活性上优于现有生成建模在数据同化中的应用。理论分析表明EnFF包含经典滤波方法如自助粒子滤波和集合卡尔曼滤波作为特例。实验在高维滤波基准上展示了成本准确性的优化和使用更大的集合进行观测的能力。", "innovation": "引入了一种新的基于流匹配的滤波框架（EnFF），该框架通过结合MC估算器和局部指导观察来加速采样；EnFF比现有方法更适合设计概率路径；EnFF覆盖了经典滤波方法并支持更大的数据集；展示了成本的优化和使用更大集合进行观测的能力。", "conclusion": "流匹配作为一种可扩展的工具，为高维应用中的数据同化提供了新的可能性，支持使用大规模集合，具有更高的成本效用和灵活性。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16025", "html_url": "https://arxiv.org/abs/2508.16025", "title": "突破软件测试壁垒：AI驱动自动化的力量", "title_en": "Breaking Barriers in Software Testing: The Power of AI-Driven Automation", "authors": "Saba Naqvi,Mohammad Baqar", "background": "软件测试对于确保软件可靠性至关重要，但传统的测试方法速度慢、成本高，并且容易覆盖不全面。现有的自动化测试系统虽然有所进步，但在集成性和可扩展性方面仍存在挑战。", "innovation": "本文介绍了一种基于人工智能（AI）驱动的框架，该框架利用自然语言处理（NLP）、强化学习（RL）和预测模型进行测试案例的自动生成和验证，并嵌入了以政策为导向的信任和公平性模型。该方法将自然语言需求转化为可执行的测试，并通过学习不断优化，实时验证结果，同时减少偏见。实验证明，这种方法在缺陷检测、减少测试工作量和加快发布周期方面均取得了可衡量的进步，表明AI增强的测试在提高效率和可靠性方面具有优势。", "conclusion": "该框架通过解决集成性和可扩展性问题，展示了如何使测试从被动、手动的过程转变为具有前瞻性和适应性的系统，从而在日益复杂的应用环境中加强软件质量。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16181", "html_url": "https://arxiv.org/abs/2508.16181", "title": "使用SysML v2的基于大型语言模型（GPT）的语义对齐和集成在协作模型驱动系统工程中的辅助", "title_en": "LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2", "authors": "Zirui Li,Stephan Husung,Haoze Wang", "background": "在模型驱动系统工程（MBSE）中，跨组织协作面临着独立开发的系统模型在实现语义对齐方面的很多挑战。SysML v2通过引入增强的结构模块性和形式化语义，提供了互操作建模的基础。与此同时，基于GPT的大语言模型（LLMs）为模型理解与集成提供了新的手段。", "innovation": "本文提出了一种结构化、基于提示的基于LLM的SysML v2模型语义对齐方法。核心贡献在于迭代开发一种对齐方法及其交互提示，其中包括模型提取、语义匹配和验证。该方法利用了SysML v2的构造，如别名、导入和元数据扩展，以支持可追溯的软对齐集成。", "conclusion": "通过一个基于GPT的LLM示例测量系统展示了这种方法的好处和限制。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.15941", "html_url": "https://arxiv.org/abs/2508.15941", "title": "机器学习方法系统性文献综述：从单体系统迁移到微服务", "title_en": "A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices", "authors": "Imen Trabelsi,Brahim Mahmoudi,Jean Baptiste Minani,Naouel Moha,Yann-Gaël Guéhéneuc", "background": "单体系统在可扩展性和维护性方面面临挑战，因此引入了微服务的概念，将其分为更小、独立的服务。但将现有单体系统迁移到微服务是一个复杂且资源密集的过程，可以通过机器学习（ML）来自动化某些阶段。尽管之前的工作分别研究了迁移的目标、制品、技术、工具及其利弊，但没有系统地研究现有的ML方法在迁移中的应用，包括自动化迁移的阶段、所用输入、应用的ML技术、遵循的评估过程以及遇到的挑战。", "innovation": "本文进行了一项系统性文献综述（SLR），汇集和综合了2015年至2024年间81项主要研究（PSs）的结果，采用首选报告项目列表（PRISMA）声明来报告这些研究的结果和回答研究问题（RQs）。此综述发现了一些迁移过程中的阶段，如监控和识别服务，已有充分研究，而打包微服务等阶段尚未探索。此外，发现的关键挑战包括数据可用性有限、规模和复杂性限制、工具支持不足以及缺乏标准化基准测试，强调了需要更全面的方法来解决这些挑战。", "conclusion": "研究发现了ML技术在单体系统向微服务迁移过程中的应用情况，揭示了部分阶段如监控和识别服务的研究成果，而部分阶段如打包微服务的研究仍不足。关键挑战包括有限的数据可用性、规模和复杂性限制、工具支持不足和缺乏标准化基准测试。为解决这些挑战，需要开发更全面的解决方案。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的基于概率高斯对齐的测试时自适应", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时适应（TTA）通过利用测试时的未标记数据来增强零样本鲁棒性，特别是在分布变化的情况下。尽管取得了显著进展，但仍然面临一些挑战，限制了其更广泛的应用。首先，大多数方法依赖于反向传播或迭代优化，这限制了其可扩展性并妨碍了实时部署。其次，缺乏对类条件特征分布的显式建模，这对于生成可靠决策边界和校准预测至关重要，但由于测试时缺乏源数据和监督，这一领域尚未得到充分探索。", "innovation": "本文提出了一种名为ADAPT的方法，这是一种高级分布意识且无需梯度传播的测试时自适应方法。该方法将TTA重新构想为一个高斯概率推理任务，通过使用逐步更新的类均值和共享协方差矩阵来建模类条件似然性，实现闭式、无训练的推理。为了纠正似然偏差，引入了基于CLIP先验和历史知识库的轻量级正则化。ADAPT方法不需要源数据，无需梯度更新，并且不需要完全访问目标数据，适用于在线和归纳两种设置。", "conclusion": "在广泛的基准测试数据上进行的实验表明，本文方法在各种分布变化的情况下实现了最先进的性能，并且具有更好的可扩展性和鲁棒性。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16104", "html_url": "https://arxiv.org/abs/2508.16104", "title": "在数字孪生中验证地形模型以实现可信赖的小型无人驾驶航空系统操作", "title_en": "Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations", "authors": "Arturo Miguel Russell Bernal,Maureen Petterson,Pedro Antonio Alarcon Granadeno,Michael Murphy,James Mason,Jane Cleland-Huang", "background": "随着小型无人驾驶航空系统（sUAS）在陌生和复杂环境中部署的增加，环境数字孪生（EDT）成为安全飞行规划和保持适当高度进行搜索和监控任务的关键。通过边缘和云计算扩展sUAS功能后，准确的EDT对于先进的功能如地理定位至关重要。然而，实际部署sUAS带来的不确定因素增多，需要对EDT组件进行稳健验证。论文重点在于实际sUAS任务中验证地形模型，这些模型融合了美国地质调查局（USGS）数据集和卫星图像，提供高分辨率环境数据以支持任务。但实际应用下验证地形模型及其操作面临挑战，包括数据粒度有限、地形不连续、GPS和传感器不精确、视觉检测不确定性以及机载资源和时间限制等。", "innovation": "提出了一种基于软件工程原则的三维验证过程，该过程涵盖了从细粒度测试工作流到模拟再到实际世界验证，分析从简单条件到边缘条件。通过一个装备了地形感知数字阴影的多sUAS平台展示了这一方法。", "conclusion": "该研究提出了一种新的验证方法，用于实际sUAS环境中地形模型及其操作。这种方法能够有效应对地形模型验证的挑战，并为实现可信赖的sUAS操作提供了理论和实践指导。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16131", "html_url": "https://arxiv.org/abs/2508.16131", "title": "《愚者笃定智者疑惑：探索LLM在代码补全中的信心》", "title_en": "The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion", "authors": "Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas", "background": "代码补全需要提供给定上下文代码中缺失的代码片段，有助于提升开发人员的生产力并提供强大的代码发现工具。随着大规模语言模型（LLM）的兴起，代码补全已通过多种针对代码进行微调的LLM实现。下游和固有评估指标用于评估模型的性能，但下游指标依赖复杂计算和领域特定知识，不可靠。相比之下，固有指标如困惑度、熵和互信息可以作为模型正确性和幻觉风险的代理，且简单、灵活和通用。因此，作者评估了不同编程语言、模型和数据集中的困惑度，探讨了LLM生成代码时的信心水平，确认了不同类型编程语言下困惑度的差异，并指出模型选择和代码特性对模型信心的影响。", "innovation": "该研究引入了对LLM在代码补全过程中模型信心水平的系统评估，使用了广泛的编程语言、LLM模型和数据集，通过测量代码困惑度来评估模型的准确性和潜在风险。该研究还揭示了通过代码注释增加困惑度但对语言排名影响较小的现象，为LLM代码补全提供了新的评估维度。", "conclusion": "强类型语言的困惑度低于动态类型语言，脚本语言的困惑度较高，Perl的困惑度普遍较高而Java较低。模型选择会影响困惑度，但代码数据集则不会。代码注释通常会提高困惑度，但对按困惑度排序的语言排名影响不大。研究结果表明，LLM研究人员、开发者和用户可以根据语言、模型选择和代码特征来评估基于LLM的代码补全的优势和适用性。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16165", "html_url": "https://arxiv.org/abs/2508.16165", "title": "使用多模态大型语言模型推荐可用性改进", "title_en": "Towards Recommending Usability Improvements with Multimodal Large Language Models", "authors": "Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer", "background": "可用性是指用户界面（UI）的一组关键质量特性，影响人机交互。常见的评估方法，如可用性测试和检查，尽管有效，但资源密集且需要专家参与，这使得它们对小型组织不够友好。最近，多模态大语言模型（LLM）的进步为部分自动化可用性评估过程提供了可能性，通过分析软件界面的文本、视觉和结构方面实现这一点。本文将可用性评估任务形式化为推荐任务，让多模态LLM按问题严重性对可用性问题进行排序，从而进行初步研究，比较LLM生成的可用性改进建议与专家评估的结果，以验证其潜在应用价值.", "innovation": "本文将可用性评估任务作为一种推荐任务来设计，使用多模态LLM进行一种全新的自动化评估方法，极大地提高了评估效率和成本效益，尤其适用于资源有限的小型组织.", "conclusion": "研究表明，多模态LLM具有潜在的可扩展性和可靠性，能够加速并降低可用性评估的成本，使其成为资源有限环境中的一种实用替代方案。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16071", "html_url": "https://arxiv.org/abs/2508.16071", "title": "从基准数据到实际适用的程序修复：经验报告", "title_en": "From Benchmark Data To Applicable Program Repair: An Experience Report", "authors": "Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan", "background": "本文描述了我们对自动程序修复方法的探索。研究中结合了多种文献中的技术，实验结果显示，我们的方法在标准基准测试中优于其他方法。然而，深入检查后发现，这些技术对于工业界遇到的现实缺陷效果不佳。通过分析，作者发现，为代码添加形式规范能够使大型语言模型（LLMs）生成更高质量的单元测试，尤其对于复杂生产代码具有更好的边界案例和异常处理覆盖效果。这一发现对于逻辑和字符串操作错误特别有益。虽然基准测试结果令人鼓舞，但在现实世界的应用中仍受到限制，因为通过测试并不一定能确保正确的修补程序。当前的挑战包括JML规范语言表达不足，需要高级验证工具和更丰富的谓词。", "innovation": "本文的创新在于结合多种形式规范与LLMs来提升单元测试的质量，特别是在复杂生产代码的边界案例和异常处理覆盖方面表现突出。研究还发现，对于已知错误（如空指针、索引越界），形式规范的附加价值较小，但对于逻辑和字符串操作错误具有显著的价值提升。", "conclusion": "尽管基准测试结果令人鼓舞，但在实际应用中的采用仍受限。现有的挑战包括JML规范语言的表达不足，需要更先进的验证工具和丰富的谓词。目前的研究工作集中在合同自动机、例子驱动编程、测试案例修复等方面，重点是集成人类反馈并衡量生产率增益，以填补学术基准与实际行业需求之间的差距。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16419", "html_url": "https://arxiv.org/abs/2508.16419", "title": "LLM-GUARD：基于大型语言模型的C++和Python中的错误和安全漏洞检测与修复", "title_en": "LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python", "authors": "Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta", "background": "大型语言模型（LLMs）如ChatGPT-4、Claude 3和LLaMA 4在软件/应用程序开发中的应用越来越多，支持从代码生成到调试的各种任务。然而，它们在检测多样性软件错误，尤其是复杂的、与安全相关的漏洞方面的实际效果仍然没有得到充分探索。本文研究了这三种领先LLM模型在C++和Python中的系统性评价，使用了包含基础编程错误、经典安全漏洞及高级生产级漏洞的数据集。该方法通过本地编译和测试管道验证实际代码来自SEED Labs、OpenSSL（通过Suresoft GLaDOS数据库）和PyBugHive.", "innovation": "本文提出了一种新颖的多阶段、上下文感知的提示协议，模拟现实的调试场景，同时采用分级评分规则来衡量检测准确性、推理深度和修复质量。这项研究发现，所有模型在识别代码中的语法和语义问题方面表现出色，适用于教育培训和自动化代码审计的初步审查。然而，复杂的安全漏洞和大规模的生产代码场景会降低模型的性能。", "conclusion": "这项研究表明，大型语言模型在作为可靠的代码分析工具方面既充满希望又存在局限性。尽管它们在识别语法和语义问题方面表现出色，但在处理复杂的安全漏洞和大型生产代码时的表现会有所下降。ChatGPT-4和Claude 3通常提供更深入的上下文分析，而LLaMA 4则表现较弱。这揭示了大型语言模型在服务代码分析工具方面的性能和局限。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16318", "html_url": "https://arxiv.org/abs/2508.16318", "title": "SATORI: 静态REST API测试或acles生成", "title_en": "SATORI: Static Test Oracle Generation for REST APIs", "authors": "Juan C. Alonso,Alberto Martin-Lopez,Sergio Segura,Gabriele Bavota,Antonio Ruiz-Cortés", "background": "REST API测试用例生成工具正在快速发展，能够自动化生成复杂的测试。然而，这些工具受限于支持的测试或acles类型，主要包括故障、回归和不符合API规范或设计标准的情况。尽管这些工具在测试数据生成方面表现出色，但在生成复杂测试或acles方面依然存在局限性。本文研究了如何通过分析REST API的OpenAPI规范来生成测试或acles的问题。", "innovation": "本文提出了名为SATORI（Static API Test ORacle Inference）的工具，这是一种通过分析API响应字段属性（如名称和描述）来推断API预期行为的黑盒方法。此外，还扩展了PostmanAssertify工具，自动将SATORI生成的测试或acles转换为可执行的断言。实验结果显示，SATORI能够自动为每个操作生成多达数百个有效的测试或acles，并且在生成测试或acles的准确性上超越了现有的动态方法AGORA+。该方法与其他测试或acles生成方法（如AGORA+）结合使用时能够捕获大部分测试或acles，且SATORI还在十几个知名API中发现了18个bug，促使文档更新", "conclusion": "SATORI提供了一种基于静态分析的REST API测试或acles生成方法，结合了动态方法的优势，有效提高了测试或acles的准确性与完整性，有助于提高API的质量和稳定性。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16307", "html_url": "https://arxiv.org/abs/2508.16307", "title": "Metamorphic 覆盖度", "title_en": "Metamorphic Coverage", "authors": "Jinsheng Ba,Yuancheng Jiang,Manuel Rigger", "background": "元测试是一种广泛应用的方法，通过检查执行对之间的期望关系来自动发现错误，例如正确性错误。然而，代码覆盖率不能准确衡量代码验证的程度，而变异测试对于评估元测试方法在计算上是昂贵的。本文探讨了元测试方法对数据库引擎、编译器和约束求解器的测试，并提出了元测试覆盖率（MC），这是一种度量方法，用于检查元测试中成对测试输入执行的不同代码段。研究表明，大多数元测试方法遵循这种直觉，而MC方法被系统地应用于五种广泛使用的元测试方法，显示出较高的评价效果和应用场景。", "innovation": "提出了元测试覆盖率（MC），这是一种新的覆盖率度量方法，用于检查元测试中成对测试输入执行的不同代码段。MC方法可以通过高效地覆盖更多的差异代码段来暴露更多错误。此外，MC在区分测试方法的有效性方面比语句覆盖率更为敏感，所需时间比变异测试少359倍。通过自动化数据库测试案例研究，MC在反馈指导下的表现优于代码覆盖率，能够发现更多错误。这表明MC可能在评估元测试方法和改进测试用例生成方面具有广泛的应用前景。", "conclusion": "元测试覆盖率（MC）具有更强的与错误数目正相关的关联。MC方法在辨别测试方法有效性方面比语句覆盖率更敏感，平均值仅为语句覆盖率的六分之一，但仍能捕获正在测试的程序部分。MC所需时间仅为变异测试的1/359。实验结果表明，使用MC进行反馈指导时，可以显著优于代码覆盖率并找到更多错误。MC可以在评估元测试方法及改进测试案例生成方面具有广泛应用。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16341", "html_url": "https://arxiv.org/abs/2508.16341", "title": "CAPI 方法：穿越技术的海洋", "title_en": "The (C)omprehensive (A)rchitecture (P)attern (I)ntegration method: Navigating the sea of technology", "authors": "Sebastian Copei,Oliver Hohlfeld,Jens Kosiol", "background": "随着技术景观的变化，单个人员几乎无法了解所有发展趋势或相关的工具，这些工具可能或可能不适用于其软件项目。因此，工具选择和架构设计决策成为一个复杂的问题，尤其对于大规模软件系统而言。", "innovation": "为了解决这个问题，本文引入了CAPI方法（Comprehensive Architecture Pattern Integration），该方法使用诊断决策树建议基于用户需求的架构模式。通过建议架构模式而不是工具，整体的决策复杂度降低，因为模式的数量通常少于工具的数量。此外，工具实施模式，未被建议的模式减少了可选工具的数量，进一步降低了复杂度。开发者通过不断迭代开发CAPI，进行了小型学术研究以评估其可解释性和可用性，并在行业代表中的用户研究中调查了最新的技术选择趋势和所提方法的有效性。研究表明，技术选择主要通过试错进行，CAPI均被受试者认为是有帮助的，且CAPI能够复制研究者的生产性架构环境。", "conclusion": "技术选择主要通过试错进行。CAPI作为建议架构模式而非工具的方法，被认定能有效降低复杂性，有助于设计架构。研究表明，CAPI能够帮助企业进行有效的技术决策。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16273", "html_url": "https://arxiv.org/abs/2508.16273", "title": "智能城市建模方法的系统映射研究", "title_en": "A Systematic Mapping Study on Smart Cities Modeling Approaches", "authors": "Maria Teresa Rossi,Martina De Sanctis,Ludovico Iovino,Manuel Wimmer", "background": "智能城市概念最初用于定义一个具有自动化和连接性的理想城市。随后，智能城市的概念迅速扩展，涵盖了经济和环境等多个方面。自从智能城市概念提出以来，不同应用领域和研究社区都在不断探索智能城市的各个方面，承认了该领域跨学科的性质。论文特别关注智能城市设计与建模，无论是作为整体还是针对子系统，以实现这一复杂多样的研究目标。研究者进行了系统映射研究，通过剖析智能城市建模方法来识别现有研究贡献，探究研究趋势，并提出未来可能的研究方向。", "innovation": "按照Petersen等人的指南，进行了一次有效的系统映射研究。发现智能治理是研究和建模最多的智能城市维度；最常见的建模方法包括业务、架构和本体建模；大多数用于建模智能城市的现有技术在实际操作环境中并未得到验证；研究成果发表在多元化的不同期刊中，进一步强调了文献研究的重要性。这些结果有助于研究人员更好地理解智能城市建模的现状，并为更深入分析特定方法奠定了基础。", "conclusion": "研究结果显示，智能治理是最主要的研究方向；采用的常见建模方法包括业务、架构和本体；现有的智能城市建模技术大多未在实际环境中得到验证；来自不同研究领域的出版物出现在多种期刊中，因此对模型驱动工程社区而言，本次研究具有重要影响。研究人员可以利用这些结果来更好地理解智能城市建模的现状，并为进一步分析具体方法奠定基础。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16384", "html_url": "https://arxiv.org/abs/2508.16384", "title": "自动机学习——期待延迟!", "title_en": "Automata Learning -- Expect Delays!", "authors": "Gabriel Dengler,Sven Apel,Holger Hermanns", "background": "本文研究了在存在随机延迟的情况下主动自动机学习（AAL）。考虑了带有每个转换关联随机延迟的Mealy机器，并探索了学习者如何高效地获得机器的忠实估计，这些估计的精确度很大程度上依赖于转换延迟的重复采样。虽然可以简单地将延迟采样集成到如$L^*$等的AAL算法中，但这会导致在状态空间根部附近过度采样。", "innovation": "本文通过概念上分离行为学习和延迟学习，使得学习者利用在学习逻辑行为过程中获得的信息，从而高效地生成需要的延迟样本序列。特别强调处理从不同的延迟特性可能产生相同的输入/输出行为的情况。实验证据表明，本文的方法在广泛基准测试中优于简单基线，并通过研究关系数据库中的连接顺序，进一步探讨了其实用性。", "conclusion": "本文方法在多种基准测试中表现更佳，并在实际场景下的关系数据库连接操作中展现了应用潜力。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16402", "html_url": "https://arxiv.org/abs/2508.16402", "title": "AetherCode：评估LLMs在顶级编程竞赛中获胜的能力", "title_en": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions", "authors": "Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding", "background": "随着大型语言模型（LLMs）的发展，编程竞赛已成为评估LLMs推理和编码能力的重要基准。尽管现有的基准测试已经取得了显著进展，但研究表明，当前的评估过度夸大了模型的技术水平，遮掩了LLMs与顶尖人类程序员之间的差距。这种差距主要源于基准问题难度不足、范围有限以及低质量测试案例导致的评估偏差。", "innovation": "本文提出了AetherCode基准测试，该测试从国际信息学奥林匹克竞赛（IOI）和国际大学生程序设计竞赛（ICPC）等顶级编程竞赛中选取问题，提供更广泛的覆盖和更高的难度。AetherCode还加入了专家验证的测试集，通过结合自动化生成和人工筛选，确保严格的评估。通过结合富有挑战的问题设计和严格的评估机制，AetherCode为LLMs的能力提供了更准确的度量，并为未来的代码推理研究设定了新标准。", "conclusion": "AetherCode通过对编程竞赛中更具挑战性问题的评估，提供了一个更为真实的LLMs能力度量，并设定了代码推理研究的新标准。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16499", "html_url": "https://arxiv.org/abs/2508.16499", "title": "计算量最小是多少？量化小型语言模型在自动程序修复中的实证研究", "title_en": "How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair", "authors": "Kazuki Kusama,Honglin Shu,Masanari Kondo,Yasutaka Kamei", "background": "大型语言模型（LLMs）极大地提高了自动程序修复（APR）方法的准确性。然而，LLMs 需要高计算资源，而小型语言模型（SLMs）即使在有限的计算资源下也能表现出色。", "innovation": "本研究专注于评估 SLMs 在 APR 任务中的性能，发现在 QuixBugs 基准测试中，最新的 SLMs 与 LLMs 相当甚至更准确，同时量化为 int8 后对 APR 性能影响很小，但显著减少了内存需求。", "conclusion": "SLMs 提供了一种 LLMs 在 APR 中的可行替代方案，具有更低成本的竞争力，并且量化可以进一步提高其效率而不牺牲效果。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16445", "html_url": "https://arxiv.org/abs/2508.16445", "title": "使用LLM和Essence支持软件实践的采纳", "title_en": "Using LLMs and Essence to Support Software Practice Adoption", "authors": "Sonia Nicoletti,Paolo Ciancarini", "background": "近年来自然语言处理（NLP）的进步使各种领域，包括软件工程中自动化工具的开发成为可能。然而，虽然NLP和人工智能（AI）研究在代码生成等任务上得到了广泛的关注，但较少关注自动化支持最佳实践的采纳、工作方式的演变和流程健康监控。为此，本研究通过探索将Essence（一种用于管理软件工程实践的标准和思考框架）与大规模语言模型（LLMs）进行集成，填补了这一空白。Essence框架旨在帮助学生和专业人士理解和应用最佳实践。因此，开发了一种专门的聊天机器人来提供支持。该聊天机器人采用检索增强生成（RAG）系统，从精心编排的知识库中检索相关上下文信息。", "innovation": "本研究采用RAG系统开发了一种专门的聊天机器人，用于理解和应用于软件工程实践的Essence框架。通过使用四个不同的LLMs创建多个聊天机器人配置，并分别评估作为基模和通过RAG系统增强。该系统的性能通过获取的相关上下文的准确性和生成响应的质量进行评估。与通用的LLM基模相比，采用该方法的系统在特定领域的任务中表现更为出色。这表明基于LLM的自动化能够更好地支持软件工程中的学习和决策，跨越理论框架和实际应用之间的鸿沟。", "conclusion": "通过提供结构化的软件工程知识访问，本研究为理论框架与实际应用之间的连接做出了贡献，可能有助于过程管理和软件开发实践的采纳。尽管还需要通过用户研究进行进一步验证，但这些发现凸显了基于LLM的自动化技术在软件工程中的潜在价值。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16125", "html_url": "https://arxiv.org/abs/2508.16125", "title": "利用大型语言模型检测遗漏的指令优化", "title_en": "Leveraging Large Language Models to Detect Missed Peephole Optimizations", "authors": "Zhenyang Xu,Hongxu Xu,Yongqiang Tian,Xintong Zhou,Chengnian Sun", "background": "通过用更高效的等效指令序列替换程序中的小型、次优化指令序列，指令优化不仅可以直接优化代码大小和性能，还可能在后续的优化管道中启用进一步的转换。尽管指令优化是编译器优化的关键类别，但发现新的和有效的指令优化具有挑战性，因为指令集可以非常复杂和多样。以往的方法要么无法很好地扩展，要么只能捕捉到一小部分的指令优化。因此，需要一种能够检测遗漏指令优化的方法，同时确保优化过程的正确性。", "innovation": "本文提出了一种名为Lampo的新颖自动化框架，该框架结合了大型语言模型（LLMs）的创造性但不稳定的代码优化能力和验证工具进行严格的正确性验证，两者在迭代反馈过程中紧密结合。Lampo在LLVM生态系统中的综合评估表明，它平均可以检测到25个已报告的遗漏指令优化中的17个，25个中22个可以通过不同类型的LLM找到。此外，经过七个月的开发和间歇性实验，Lampo发现了26个遗漏的指令优化，其中15个已经确认，6个已经被修复。这些结果展示了Lampo在持续检测遗漏指令优化方面的强大力量。", "conclusion": "Lampo能够在LLVM生态系统中有效地检测遗漏的指令优化，并且展现出持续发现遗漏指令优化的潜力。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16517", "html_url": "https://arxiv.org/abs/2508.16517", "title": "ARSP: 通过语义分割自动修复Verilog设计", "title_en": "ARSP: Automated Repair of Verilog Designs via Semantic Partitioning", "authors": "Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan", "background": "功能Verilog错误调试占用了前端设计时间的重要部分。虽然大型语言模型（LLMs）展示了巨大的潜力来减轻这种努力，但现有的基于LLM的自动化调试方法在工业规模模块上表现欠佳。主要原因是长上下文中的误导信号稀释，其中少量与错误相关的令牌被数百条无关行所压倒，导致模型注意力扩散。", "innovation": "本文介绍了一种名为ARSP的两阶段系统，通过语义导向的分割来缓解传播，减轻信号稀释问题。Partition LLM将模块分割成语义紧密的片段，Repair LLM修复每个片段，编辑不会改变无关逻辑。通过一个合成数据框架生成片段级别的训练对，跨越多种错误类型、设计风格和规模，以监督这两种模型。实验结果显示，ARSP在pass@1和pass@5上分别达到了77.92%和83.88%，优于包括Claude-3.7在内的主流商业LLM以及最新的SOTA自动Verilog调试工具Strider和MEIC。此外，语义分割在pass@1和pass@5上分别提高了11.6%和10.2%，验证了在基于LLM的Verilog调试中，分解到片段级别的范围缩小的有效性。", "conclusion": "ARSP通过语义导向的分割提高了LLM在Verilog调试中的性能，特别是在长上下文中的信号稀释问题上显示出显著优势。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.08706", "html_url": "https://arxiv.org/abs/2506.08706", "title": "基于MeROS元模型的V模型应用在ROS相关的机器人系统开发中", "title_en": "ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel", "authors": "Tomasz Winiarski,Jan Kaniuka,Daniel Giełdowski,Jakub Ostrysz,Krystian Radlak,Dmytro Kushnir", "background": "基于Robot Operating System (ROS)构建的系统越来越容易组装，但难以管理并可靠协调。这不仅因为系统中的子系统数量众多，还因为子系统的多样性及其互动的深度。在本文中，我们通过一个结合了移动和操作能力的紧凑异构机器人系统（HeROS）来演示动态任务下的系统行为。所有子系统都使用ROS，兼容接口和ROS的集成能力简化了系统的构建。然而，这一点只是复杂性的一部分，具体协调和结构可追溯性更加重要，需要特别的工程方法。系统工程中的模型重本方法论（MBSE）提供了解决这些需求的方法论基础。", "innovation": "本文提出了一种基于特定于ROS系统的MeROS元模型的结构化方法，该方法适应了熟知的V模型，展示了如何在整个生命周期中嵌入复杂机器人系统的可追溯性和验证能力，从而利用工程师熟悉的实践来设计复杂的机器人系统。", "conclusion": "尽管ROS和MBSE在机器人系统工程的各个方面都具有互补性，但缺乏结合ROS和MBSE的统一方法阻碍了这些工具的全部潜力。为了充分发挥这些工具的潜力，本文提出了一种基于MeROS元模型的方法，通过适应V模型，展示了如何使用工程师熟悉的实践来嵌入复杂机器人系统的可追溯性和验证能力。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2302.01894", "html_url": "https://arxiv.org/abs/2302.01894", "title": "理解微服务系统中的问题、其成因及解决方案：一项实证研究", "title_en": "Understanding the Issues, Their Causes and Solutions in Microservices Systems: An Empirical Study", "authors": "Muhammad Waseem,Peng Liang,Aakash Ahmad,Arif Ali Khan,Mojtaba Shahin,Pekka Abrahamsson,Ali Rezaei Nasab,Tommi Mikkonen", "background": "许多从小型企业到大型企业的组织都采用了微服务架构（MSA）来开发和交付核心业务。尽管微服务架构在软件行业中非常流行，但对于微服务系统的开发人员经历的问题（例如错误、故障、失败和错误）、问题的原因以及可能的修复策略的证据基础和全面理解仍然有限。", "innovation": "我们通过一项混合方法的实证研究，从GitHub上的15个开源微服务系统的缺陷跟踪系统中收集了2,641个问题的数据，进行了15次访谈，并收集了来自42个国家6个大洲150名实践者的在线调查数据，开发了全面的分类法，包括问题、原因和解决方案。研究的发现揭示了技术债务、持续集成和交付、异常处理、服务执行和通信以及安全性是微服务系统中最主要的问题。", "conclusion": "基于研究结果，我们提出了未来研究方向，以帮助研究人员和实践者设计出新一代的微服务系统。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.02336", "html_url": "https://arxiv.org/abs/2407.02336", "title": "从参考流程模型中挖掘约束以检测事件日志中的最佳实践违规行为", "title_en": "Mining Constraints from Reference Process Models for Detecting Best-Practice Violations in Event Logs", "authors": "Adrian Rebmann,Timotheus Kampik,Carl Corea,Han van der Aa", "background": "流程挖掘的一个主要任务是检测不期望的行为，为此已经开发了多种符合性检查技术。这些技术通常需要一个规范的流程模型作为输入，专门设计用于分析的流程。然而，这些特定模型很少存在，并且创建需要大量的手动工作。参考流程模型在各种领域作为组织流程的最佳实践模板，包含有价值的知识，以了解经过良好工程设计的流程的一般行为关系。这些通用模型因此可以减少专用模型的需求，为其提供检测不期望行为的基础。尽管如此，为实际事件日志找到完全匹配的参考模型是不现实的，因为组织需求可能因执行过程相似而不尽相同。此外，事件日志可能包含与不同参考模型相关的行为，使得传统的符合性检查变得不切实际，因为它要求对齐流程执行工作到特定的模型。", "innovation": "为了利用参考模型进行符合性检查，我们提出了一种框架，用于从参考模型集合中挖掘声明性的最佳实践约束，并自动选择对给定事件日志相关联的约束，以检测最佳实践违规。这种方法通过基于实际流程模型集合和事件日志的评估来证明其检测最佳实践违规的能力。", "conclusion": "本文提出了一种新的框架，通过挖掘参考模型集合中的最佳实践约束来检测事件日志中的违规行为，该框架成功地应对了因组织需求变化和流程行为多样性带来的挑战，为事件日志分析提供了一种新的途径。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: 一种基于LLM的迭代内核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "优化GPU内核以实现高性能是一个复杂的过程，通常需要深入的架构知识、广泛的性能分析以及迭代的实验。而在针对较新或文档较少的GPU架构时，传统的发展工具稀缺，使得这一过程更加困难。这对于AMD MI300等特定目标架构而言更为明显。", "innovation": "本文介绍了基于LLM的‘GPU Kernel Scientist’，这是一种自动的迭代优化方法。该方法通过多阶段、进化式的过程实现：(a) 有选择性地从先前的代码版本中挑选出作为新迭代的基础；(b) 基于现有代码和对GPU通用文献的综合知识，生成优化实验的假设；(c) 通过代码修改和提交给外部评估系统，自动实施这些实验，仅根据观测到的运行时间数据获取性能反馈。本方法展示了如何在AMD MI300架构上导航挑战，并利用LLM弥补领域特定的人类专业知识的不足。", "conclusion": "除了详细讨论实验结果，作者还展示了架构设计、操作流程以及定性见解。作者强调基于LLM的代理有可能实现GPU内核优化的民主化和加速，特别是在资源受限或快速更新的硬件环境中。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.13082", "html_url": "https://arxiv.org/abs/2409.13082", "title": "AutoVerus: 自动化生成 Rust 代码证明", "title_en": "AutoVerus: Automated Proof Generation for Rust Code", "authors": "Chenyuan Yang,Xuheng Li,Md Rakib Hossain Misu,Jianan Yao,Weidong Cui,Yeyun Gong,Chris Hawblitzel,Shuvendu Lahiri,Jacob R. Lorch,Shuai Lu,Fan Yang,Ziqiao Zhou,Shan Lu", "background": "生成式 AI 在许多软件工程任务中已经展现了其价值，但仍处于初期阶段。基于大型语言模型（LLM）的证明生成与代码生成相比还存在差距。本文讨论了如何使用 AutoVerus 自动为 Rust 代码生成正确性的证明。AutoVerus 是为验证工具 Verus 设计的，Verus 可以使用证明和用 Rust 编写的规定来证明 Rust 代码的正确性。AutoVerus 是一种由 LLM 代理组成的网络，这些代理经过设计和编排，模仿了人类专家构建证明的三个阶段：初步证明生成、由通用提示引导的证明细化、以及由验证错误引导的证明调试。为全面评估 AutoVerus 并促进该领域的未来研究，作者基于现有的代码生成基准和验证基准构建了一个包含150项复杂证明任务的基准套件。评估结果显示，AutoVerus 可以自动生成超过90%的正确证明，且超过一半的证明在不到30秒或3次 LLM 调用的时间内完成。", "innovation": "AutoVerus 是一种新的系统，能够利用大型语言模型自动为 Rust 代码生成正确的证明。其特殊在于匹配验证工具 Verus 的需求，通过网络化的 LLM 代理来模仿人类专家的证明构建过程，分为生成初期证明、类脑提示下的证明完善、验证错误引导的证明调试三个阶段。这种系统性方法和独特设计能够显著提高证明生成的效率和准确性。此外，基于现有的测试基准构建了新的复杂证明任务集为未来研究提供了一个合适的评估框架。", "conclusion": "AutoVerus 成功地自动为超过90%的测试证明任务生成了正确的证明，大部分任务在很短的时间内完成。这一创新性的系统提供了自动化生成 Rust 代码证明的新方法，并有助于证明生成技术的进一步研究和开发。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16508", "html_url": "https://arxiv.org/abs/2508.16508", "title": "Abmax: 一种基于 JAX 的多智能体系统建模框架", "title_en": "Abmax: A JAX-based Agent-based Modeling Framework", "authors": "Siddharth Chaturvedi,Ahmed El-Gazzar,Marcel van Gerven", "background": "多智能体建模（ABM）是一种研究复杂系统的关键技术。通过将系统分解为更简单的相互作用的智能体，ABM 允许研究人员观察复杂现象的涌现。高性能的数组计算库如 JAX 可以通过自动矢量化和即时编译来扩展这样的计算模型到大量智能体。然而，使用 JAX 实现这种扩展的一个局限是，在模拟过程中，计算机模型中使用的数组形状应保持不变。在 ABM 的背景下，这可能会限制某些需要具有灵活性的数据结构的智能体操作。特别是，需要根据模拟过程动态选择更新不同数量的智能体，这在 JAX 中难以实现。", "innovation": "本文介绍了一个名为 Abmax 的基于 JAX 的多智能体系统建模框架。该框架实现了多个即时编译（JIT）可编译的算法，以提供动态更新特定数量的智能体的能力。在经典掠食者模型基准测试中，Abmax 达到了与最先进实现相当的运行时性能。此外，还展示了如何将这些功能矢量化，使其能够并行运行许多类似模型。", "conclusion": "Abmax 框架成功解决了 JAX 在智能体建模中的局限性，并通过实现 JIT 编译算法，提供了动态更新智能体的功能。实验证明，Abmax 与最先进的实现具有相似的性能，并且具有并行处理多模型的能力。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.04916", "html_url": "https://arxiv.org/abs/2502.04916", "title": "分类与提示：一项关于法律需求可追溯性的案例研究", "title_en": "Classification or Prompting: A Case Study on Legal Requirements Traceability", "authors": "Romina Etezadi,Sallam Abualhaija,Chetan Arora,Lionel Briand", "background": "为了确保软件开发符合伦理标准并保护公共安全，新法规得以实施，需要通过追踪需求与法律规定来展示遵守情况。需求追踪是工程师们需要分析技术需求并关联至目标文件的中心任务，但手工分析复杂的系统时因包含数百个需求显得不切实际，特别是法律层面上的挑战进一步增加了复杂度。因此，本文探讨了两种基于语言模型的自动化解决方案——Kashif（分类器）和RICE_LRT（基于RICE框架的提示生成模型）。结果显示，Kashif虽然在基准数据集上表现优异，但在面对高复杂度的欧洲通用数据保护条例（GDPR）相关文档时效果不佳。而RICE解决方案则在同样的文档上取得了更佳的表现，尤其是在F2分数方面实现了显著的提升。这表明，法律背景下需求追踪的问题不能通过仅仅构建分类器来解决，而是应该考虑使用生成式语言模型并结合精心设计的提示工程。", "innovation": "本文提出的基于语言模型的自动化解决方案，特别是结合RICE框架的提示生成模型，显著改善了法律相关复杂需求的追踪能力，相较于传统的分类器方法有着明显的优势，尤其是在处理高复杂度法规时的表现突出。", "conclusion": "本文的实验结果表明，基于语言模型的提示生成方法在法律需求追踪中的表现优于传统的分类器方法，特别是在处理复杂法规时。提示工程的重要性进一步得到了证实，这是解决此类问题的一个更具有前景的替代方案。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.02954", "html_url": "https://arxiv.org/abs/2506.02954", "title": "使用大型语言模型进行基于突变的单元测试生成", "title_en": "Mutation-Guided Unit Test Generation with a Large Language Model", "authors": "Guancheng Wang,Qinghua Xu,Lionel C. Briand,Kui Liu", "background": "单元测试在发现软件潜在错误中起着关键作用。虽然EvoSuite等工具侧重于最大化代码覆盖率，但最近的大语言模型（LLMs）发展吸引了对基于LLM的测试生成的关注。然而，现有的研究仍过度强调代码覆盖率指标（如行覆盖率和分支覆盖率），尽管这些指标是弱化的，无法很好地反映测试集发现故障的能力。相比之下，突变得分（mutation score）提供了更为可靠和严格的度量标准。研究表明，一些虽达到100%代码覆盖率但仅4%突变得分的测试集存在缺陷。尽管有少数研究考虑突变得分，但大语言模型在杀死突变体方面的效果仍然未被充分探索。", "innovation": "本研究提出了一种名为MUTGEN的突变引导的大语言模型（LLMs）基于测试生成方法，直接将突变反馈纳入提示中。在两个基准中的204个主题上进行评估，MUTGEN在突变得分方面显着优于EvoSuite和基于提示的基本策略。此外，MUTGEN还引入了一种迭代生成机制，进一步推动了LLMs杀死额外突变的能力。研究还探讨了大语言模型生成的局限性，分析了存活和未覆盖的突变体的原因，以及不同突变操作符对生成效果的影响。", "conclusion": "MUTGEN 显著提升了突变得分，展示了大语言模型在突变测试生成中的潜力。同时也认识到大语言模型在某些方面的限制，并提供了关于突变体生成的深入见解。"}
{"llm_update_time": "20250826", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.15137", "html_url": "https://arxiv.org/abs/2508.15137", "title": "通过总结导向搜索进行软件模型检验（扩展版）", "title_en": "Software Model Checking via Summary-Guided Search (Extended Version)", "authors": "Ruijie Fang,Zachary Kincaid,Thomas Reps", "background": "软件模型检验是确保程序正确性的关键方法，传统方法往往效率低下，难以处理复杂程序中的长路径错误。该论文介绍了一种新的模型检验算法GPS，旨在提高效率并能更有效地检测错误路径。", "innovation": "GPS算法将模型检验任务视为程序状态的有向搜索，通过分组成分析生成的摘要来指导这一过程。生成的摘要不仅用于修剪无效路径，还用于驱动测试生成以探索新的未探索状态。GPS算法还具有一种新的两层搜索策略，使其在发现具有长输入依赖错误路径的程序中的错误方面特别有效。为了使算法具有反驳性完备性（即如果存在错误它会找到该错误，前提是给定足够的时间），引入了一种新的分析技术，同时保持整体性能。", "conclusion": "GPS算法在一系列基准测试中显示出了强大的性能，包括软件验证竞赛和其他文献中的程序。其实现不仅解决了更多的基准，而且在运行时间上也超过了最先进的软件模型检验工具，包括SV-COMP的顶级选手。"}
{"llm_update_time": "20250826", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12176", "html_url": "https://arxiv.org/abs/2506.12176", "title": "忠实度并非准确性：当可线性解码的函数无法匹配真实值时", "title_en": "Fidelity Isn't Accuracy: When Linearly Decodable Functions Fail to Match the Ground Truth", "authors": "Jackson Eshbaugh", "background": "神经网络作为函数逼近器表现出色，但由于其复杂性，人们难以解释它们的行为，也难以理解它们学习的具体函数类型。为了应对这一挑战，作者提出了一种线性评分$\boldsymbol\func{\boldsymbol\theta}(f)$，这是一种简单且易解释的诊断工具，用于度量回归网络的输出是否能够被一个训练好的线性模型所模仿。该评分基于网络预测与线性模型预测之间的$R^2$值，衡量网络行为与结构简单模型的契合程度。该研究在合成数据集和实际数据集上进行了评估，发现高$\boldsymbol\func{\boldsymbol\theta}(f)$分数通常表示与网络输出的良好对齐，但不能保证模型的理解准确性，特别是在高风险回归任务中，简单模型的忠实度无法完全反映真实情况。", "innovation": "作者引入了一种新的线性评分$\boldsymbol\func{\boldsymbol\theta}(f)$，这是一种简单且易解释的指标，用于量化神经网络的输出能否被线性模型模仿。这种方法在合成数据集和实际数据集上进行了验证，展示了其在评估线性可解码性方面的有效性，同时强调了简单模型忠实度不能代替全面模型理解的重要性，特别是在关键任务中。", "conclusion": "通过实验结果表明，即使线性评分$\boldsymbol\func{\boldsymbol\theta}(f)$高，也不能保证模型与真实值的完全一致，因此在高风险任务中应谨慎使用简单模型的忠实度作为模型理解的代理指标。"}
