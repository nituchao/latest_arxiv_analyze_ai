{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21549", "html_url": "https://arxiv.org/abs/2509.21549", "title": "正确的推理路径访问共享决策枢纽", "title_en": "Correct Reasoning Paths Visit Shared Decision Pivots", "authors": "Dongkyu Cho,Amy B.Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai", "background": "链式推理（CoT）展示了大语言模型（LLMs）的中间思考过程，但大规模验证这些痕迹仍然无法解决。因此，本文提出了决策枢纽的概念——任何正确的推理路径都必须访问的最小、可验证的检查点。", "innovation": "本文提出了一种自我训练管道，(i) 采样多种推理路径并挖掘共享决策枢纽，(ii) 使用辅助验证器将每条轨迹压缩为专注于决策枢纽的短路径推理，(iii) 使用模型自动生成的输出进行后续培训。该方法不依赖于真实推理数据或外部度量标准对推理进行对齐。", "conclusion": "在标准基准测试集LogiQA、MedQA和MATH500上的实验表明了该方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21651", "html_url": "https://arxiv.org/abs/2509.21651", "title": "AI能否感知物理危险并干预？", "title_en": "Can AI Perceive Physical Danger and Intervene?", "authors": "Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani", "background": "在与物理世界互动时，如作为机器人或辅助代理，AI会面临超出“纯粹数字AI”的新的安全挑战。在这些互动中，物理伤害的可能性是直接且即时的。现有最先进的基础模型是否理解关于物理安全的常识事实，例如箱子是否太重拿不起来，或热咖啡不应交给儿童？", "innovation": "首先，开发了一种面对实体AI系统的可扩展连续物理安全基准测试方法，基于真实世界伤害叙事和操作安全约束。通过高级生成模型将这些叙事和约束转化为切光的图像和视频，捕捉从安全到不安全状态的转变，以探索多模态安全理解。其次，全面分析了主要基础模型的感知风险、关于安全的推理以及触发干预的能力；这为它们的安全关键代理应用部署准备提供了多方面的见解。最后，开发了一种后训练方法，教导模型根据系统指令明确推理关于特定于体验的安全约束，生成的思考痕迹使安全推理具有可解释性和透明性，实现了在约束满足评估中的最先进性能。", "conclusion": "开发的基准将在这里发布：this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21553", "html_url": "https://arxiv.org/abs/2509.21553", "title": "AutoClimDS:气候数据科学自主AI——一个知识图谱足矣", "title_en": "AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need", "authors": "Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng", "background": "气候数据科学面临的数据源碎片化、数据格式异质性和所需的技术专长障碍限制了参与度，减缓了发现过程，降低了科学工作流的可重复性。", "innovation": "本文通过将精心策划的知识图谱(KG)与用于云原生科学工作流的AI代理结合，提出了一个概念验证方案来解决这些问题。KG提供了一个统一层，组织数据集、工具和工作流；AI代理能够通过生成AI服务提供自然语言交互、自动数据访问和简化分析。", "conclusion": "通过利用现有的云就绪API数据门户，本文证明了一个知识图谱足以解锁可扩展且由用户驱动的科学探究工作流。开源设计支持社区贡献，确保KG及其相关工具能够共同进化，从而为气候变化数据获取的民主化和人类与AI在科学研究中的合作建立可扩展且可扩展的框架。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21600", "html_url": "https://arxiv.org/abs/2509.21600", "title": "多模式数据中的自动化和可解释生存分析", "title_en": "Automated and Interpretable Survival Analysis from Multimodal Data", "authors": "Mafalda Malafaia,Peter A.N. Bosman,Coen Rasch,Tanja Alderliesten", "background": "在肿瘤学中，准确且可解释的生存分析仍然是一个核心挑战。随着多模态数据的增长以及临床对于透明模型的需求增加，这种挑战变得更加复杂。因此，需要一种能够自动化生存分析的多模式人工智能框架，该框架能够将临床变量与计算机断层扫描图像集成。现有的很多方法在这方面的表现并不理想，无法满足临床透明性和可解释性要求。", "innovation": "本文提出了一个多模式的可解释 AI 框架——MultiFIX，旨在自动化生存分析。MultiFIX 通过深度学习和基因编程相结合的方法，将影像特征和临床变量有效地融合，以及采用透明的 Cox 回归进行风险估计，进一步解释了特征的重要性。具体来说，影像特征通过 Grad-CAM 解释，临床变量通过基因编程建模为符号表达式，使模型结果更加透明和可解释。", "conclusion": "通过使用开源的 RADCURE 数据集，MultiFIX 在头部和颈部癌症的预测和分组表现上分别达到了 C 指数 0.838 和 0.826，显著优于现有的临床和学术基准方法，并且与已知的预后标记相吻合。这些结果表明，MultiFIX 可以在精准肿瘤学中实现多模式数据的自动化和可解释的生存分析。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21593", "html_url": "https://arxiv.org/abs/2509.21593", "title": "GeoEvolve：通过多智能体大型语言模型自动发现地理空间模型", "title_en": "GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models", "authors": "Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon", "background": "地理空间建模为解决可持续性和气候变化等紧迫的全球挑战提供了关键解决方案。现有基于大型语言模型（LLM）的算法发现框架，如AlphaEvolve，虽然擅长演化通用代码，但在处理复杂的地理空间问题时缺乏领域知识和多层次推理能力。本文探讨了现有框架的局限性，介绍了GeoEvolve这一多智能代理LLM框架。", "innovation": "GeoEvolve通过结合进化搜索和地理空间领域的知识库来自动设计和优化地理空间算法。该框架在两个嵌套循环中运行：内部循环利用代码演化器生成和变异候选解决方案，外部代理控制器评估全局精英并查询具有地理学理论先验的GeoKnowRAG模块。这以知识为导向的进化引导搜索朝着理论意义和计算效率更高的算法方向发展。GeoEvolve在空间插值（克里金法）和空间不确定量化（地理空间收敛预测）两项基础任务上的评估表明，该框架可以自动改进和发现新的算法，同时整合地理空间理论。", "conclusion": "GeoEvolve提供了一条可扩展的自动、知识驱动的地理空间建模途径，有助于推动可信、高效的科学AI发现。实验证明，领域指导的知识检索对于稳定、高质量的进化至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21782", "html_url": "https://arxiv.org/abs/2509.21782", "title": "基准评估 MLLM 网络理解：推理、鲁棒性和安全性", "title_en": "Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety", "authors": "Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu", "background": "多模态大型语言模型（MLLMs）正逐渐成为构建复杂网络相关应用如GUI代理和前端代码生成的AI合作者。然而，现有的基准测试主要侧重于视觉感知或UI代码生成，缺乏对整个端到端网络应用所需的推理、鲁棒性和安全性能力的评估。", "innovation": "本文介绍了名为WebRSSBench的全面网络理解基准，该基准综合评估推理、鲁棒性和安全性八个任务，包括位置关系推理、颜色鲁棒性和安全关键检测等。基准来自729个网站，包含3799个问题答案对，探究网页结构、文本、控件以及安全关键交互的多步推理。为了确保可靠测量，使用标准化提示、确定性评估脚本和多阶段质量控制，结合自动检查与目标化的人工验证。", "conclusion": "对12个MLLMs的评估结果揭示了显著差距，模型在现实布局下依然难以处理组成性和跨元素推理，面对用户界面或内容布局调整、视觉风格变化时展示的鲁棒性有限，且在识别和避免安全关键或不可逆动作方面较为保守。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21743", "html_url": "https://arxiv.org/abs/2509.21743", "title": "Retrieve-of-Thought: 通过重用思考进行高效推理", "title_en": "Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts", "authors": "Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar", "background": "大模型通过生成长的推理痕迹来提高准确性，但这会增加延迟和成本，促进推理时的效率提升。目前的研究表明，大模型的推理虽然准确，但需要较多的时间和资源。因此，提出了Retrieve-of-Thought（RoT），它通过重用先前的推理步骤来指导新问题，并将其组织为包含顺序和语义边的思考图，以实现快速检索和灵活重组。在推理阶段，RoT 提取与查询相关的节点，并使用奖励引导的遍历组装特定于问题的模板，从而减少冗余探索，并减少了输出的标记数，同时保持准确性。", "innovation": "RoT 提出了一种新的方法，通过在推理过程中重用和复用之前的推理步骤（即“思考”），高效地组织和指导新的问题求解过程，其核心是通过构造思考图来进行动态模板构建。这种方法可以显著减少冗余探索、输出标记数，并大幅降低推理时间和成本。", "conclusion": "通过在多个模型上对 RoT 进行评估，发现 RoT 在保持准确性的前提下，能够显著减少输出标记数（最高 40%），降低推理延迟（82%）和成本（59%）。研究结果表明，RoT 建立了一种可扩展的高效推理模式，该模式通过动态模板的构造来促进重用先前的推理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21799", "html_url": "https://arxiv.org/abs/2509.21799", "title": "D-Artemis: 移动GUI多代理的审慎认知框架", "title_en": "D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents", "authors": "Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan", "background": "GUI代理旨在通过模拟用户交互来自动化广泛的人类任务。尽管取得了快速进展，但现有方法仍受到关键挑战的阻碍：端到端训练的数据瓶颈、延迟错误检测的高成本以及指导冲突的风险。受人类认知循环（思考-对齐-反思）的启发，本文提出了一种名为D-Artemis的新型审慎框架。", "innovation": "D-Artemis利用细粒度的应用特定提示检索机制来指导其决策过程，并采用了预执行对齐阶段，其中包含思考-行动一致性检查模块和行动纠正代理（ACA），以减少执行失败的风险。此外，后执行状态反思代理（SRA）完成认知循环，使策略性学习成为可能。D-Artemis增强了通用多模态大型语言模型处理GUI任务的能力，无需针对复杂轨迹数据集进行训练，表现出强大的泛化能力。", "conclusion": "D-Artemis在两个主要基准测试中建立了新的SOTA结果，分别在AndroidWorld和ScreenSpot-V2上实现了75.8%和96.8%的成功率，并通过消融研究进一步证明了每个组件对框架的重大贡献。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21766", "html_url": "https://arxiv.org/abs/2509.21766", "title": "UltraHorizon：在超长时限场景下评估代理能力的基准", "title_en": "UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios", "authors": "Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen", "background": "尽管自主代理在多个领域取得了显著进展，但大多数评估主要集中在短期、完全可观测的任务上。然而，许多关键的现实任务，如大规模软件开发、商业投资和科学发现，通常在长时间跨度和部分可观测的场景中展开，这些场景的成功依赖于持续的推理、规划、记忆管理和工具使用。现有的基准测试很少涵盖这些长时间跨度的挑战，因此普遍存在系统评价的不足。为了填补这一空白，作者提出了一种新的基准测试UltraHorizon，用于衡量复杂现实挑战所需的基础能力。", "innovation": "UltraHorizon通过探索作为统一任务跨三个不同的环境，来验证这些基本功能。代理在长时间发现任务中设计，必须通过持续推理、规划、记忆管理和与环境交互，逐步发现隐藏的规则。实验结果显示，在最全面的规模下，轨迹平均有200k+的令牌和400+的工具调用；在标准配置下，轨迹平均包含35k+令牌和超过60次的工具调用。实验揭示了LLM代理在这些设置中的持续性能差距，而人类参与者表现出更高的评分。简单的扩展无法提高这些任务的表现。", "conclusion": "通过深入分析收集的轨迹，作者发现了八种类型错误，并将其归因于两种主要原因：上下文锁定和功能根本能力差距。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21633", "html_url": "https://arxiv.org/abs/2509.21633", "title": "语义F1分数：在模糊类别边界下的公平评估", "title_en": "Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries", "authors": "Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan", "background": "传统的F1度量会将语义相关的预测视为完全失败，现有基于相似度的评价指标存在不足，在评定主观或模糊多标签分类时需要更好的度量标准。这类评估需要衡量预测标签与真实标签之间的语义相似度，而不像传统F1度量那样将语义相关的预测视为完全失败，现有度量方法在标签集合大小或类别边界不相同时难以进行比较，也无法很好地反映人类判断差异或模糊类别边界的真实情况。", "innovation": "提出了一种新的评价指标——语义F1分数。这种评价方法通过引入标签相似度矩阵，在计算软精度和召回分之后得出语义F1分数。与现有方法不同，新方式能够避免将标签直接舍弃或强行匹配不相似的标签，而是为语义相关但不完全相同的标签提供部分分数。这种方法能更好地反映人类判断差异或模糊类别边界的真实情况，并提供更为公平的评估结果，从而在不同任务和模态中具有广泛适用性。", "conclusion": "通过理论分析和大量实验验证，结果表明语义F1分数具有更高的可解释性和生态效度。相比其他度量方法，它只需要一个适用于特定领域的相似度矩阵，且该矩阵具有鲁棒性，无需固定的本体论，因此适用于各种不同的任务和模态。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21344", "html_url": "https://arxiv.org/abs/2509.21344", "title": "在评估安全性监控时减少信息泄露的方法", "title_en": "Towards mitigating information leakage when evaluating safety monitors", "authors": "Gerard Boxo,Aman Neelappa,Shivam Raval", "background": "白盒监控器通过分析模型内部状态来检测大型语言模型中的潜在有害行为，具有降低成本和整合到分层防御系统中的潜力，但监控器的效果因数据中的信息泄露而被放大。这种泄露通常是通过提示或微调生成的，导致监控器检测出的是表面现象而不是真实模型行为。", "innovation": "本文提出了一种评估监控器性能的新框架，旨在区分真实模型行为与诱发提示的表象。进一步提出三种策略：内容过滤（移除与欺骗相关的文本），评分过滤（仅处理与任务相关的标记），以及提示蒸馏微调模型（训练模型表现出欺骗行为，但不直接提示）。这些策略通过实验在多个欺骗基准上得到检验，结果显示内容过滤为一种有效的缓解策略，评分过滤则显示出一定的减分效果但难以精确定位原因。此外，微调的模型被发现可以提高监控评估但同时降低其性能，最高可达40%的下降。", "conclusion": "研究发现，内容过滤是一种有效减少监控有效性中表象干扰的策略，能够显著降低欺骗不确定接收率（AUROC）30%；评分过滤虽然减分15%，但其效果难以归因；微调模型改进评估但降低性能直至退降40%。这些发现为理解和减少监控评价中的信息泄露提供了关键洞察。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21567", "html_url": "https://arxiv.org/abs/2509.21567", "title": "基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索", "title_en": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks", "authors": "Mohammad Parsa Afshar,Aryan Azimi", "background": "消费者行为预测是营销、认知神经科学和人机交互领域的重要目的。脑电图（EEG）数据能通过提供大脑神经活动的详细信息来帮助分析决策过程，因此利用EEG数据预测消费者行为的研究具有重要意义。", "innovation": "该研究采用了一种比较方法，通过提取和清洗来自NeuMa数据集的EEG数据特征，并使用图神经网络（GNN）模型创建脑连接特征。研究比较了多种不同的机器学习模型，包括经典模型和图神经网络模型，实现了不同架构的GNN模型以进行全面比较，并广泛使用了传统的集成模型来显示各类模型在数据集上的差异和性能。", "conclusion": "虽然研究结果总体上未显示显著差异，但GNN模型在某些基本标准上通常表现更佳，尤其是当经典模型表现不佳时。该研究不仅展示了结合EEG信号分析和机器学习模型可以为深入理解消费者行为提供一种途径，还为基于EEG的神经营销研究中广泛应用的经典模型如支持向量机（SVM），以及很少使用或未使用的模型如图神经网络模型进行了全面比较。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21718", "html_url": "https://arxiv.org/abs/2509.21718", "title": "Align2Speak：通过ASR引导的在线偏好优化改进低资源语言的TTS", "title_en": "Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization", "authors": "Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li", "background": "开发低资源语言的高质量文本转语音（TTS）系统具有挑战性，因为配对的文本和语音数据稀缺。相比之下，这些语言的自动语音识别（ASR）模型更为常见，这归因于大规模多语言预训练的努力。现有技术中，改进TTS系统通常依赖于大量的配对数据，而ASR模型则可以通过预训练模型的辅助来提高多语言适应性。", "innovation": "提出了一种基于组相对策略优化（GRPO）的框架，用于将自动回归的多语言TTS模型适应新的低资源语言。该框架首先使用国际音标（IPA）标记训练一个无语言偏见的TTS基础模型，然后利用有限的新语言配对数据进行微调，以捕捉目标语言的语调特征。此外，使用预训练的ASR、说话人验证和音频质量估计模型来指导仅凭未配对的文本和说话人提示的GRPO优化。", "conclusion": "实验证明，该流程能够产出具有前后一致性的语音，并且显著优于单纯的模型微调。此外，基于GRPO的框架也提高了高资源语言的TTS性能，其输出的可听性和说话人相似度超过了传统的离线对齐方法如Direct Preference Optimization (DPO)，在语音质量方面也表现更优。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21886", "html_url": "https://arxiv.org/abs/2509.21886", "title": "TRACE: 在图形上进行计算的学习", "title_en": "TRACE: Learning to Compute on Graphs", "authors": "Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu", "background": "图表示学习中的核心挑战是学习计算，即建模计算图的功能行为。然而，主流架构在这一任务上存在显著偏差，特别是在主流消息传递神经网络（MPNNs）及其传统Transformer基线中表现出根本性的假设错误，这阻碍了模型捕捉计算中位置感知和层次化的本质。", "innovation": "我们提出了一个新的名为TRACE的框架，该框架基于一个架构上稳健的基础架构，并提出了一个原则性的学习目标。首先，TRACE利用了一个分层次的Transformer，以反映计算的逐步流程，这取代了传统的错误的置换不变聚合。其次，我们引入了一种称为函数位移学习的新目标，从而使学习问题解耦。模型被训练预测函数位移，即真实全局函数和假设输入独立的简单局部近似之间的差异。", "conclusion": "结果表明，我们的基于架构的原则性和分离性学习目标形成了一个更稳健的框架来解决图上进行计算这一基础挑战，且在电子电路这类最复杂和经济上最重要的计算图类别中，TRACE显著优于所有先前的架构。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21836", "html_url": "https://arxiv.org/abs/2509.21836", "title": "基于公理的选择与决策评价悖论", "title_en": "Axiomatic Choice and the Decision-Evaluation Paradox", "authors": "Ben Abramowitz,Nicholas Mattei", "background": "本文介绍了一个框架，用于通过描述决策的公理来建模决策。这些公理可以是关于决策的陈述，例如伦理约束。作者利用此框架定义了基于结构属性的决策公理分类系统，并展示了决策公理在决策中使用与评价决策之间的紧张关系，称为决策-评价悖论。", "innovation": "此研究通过提出一个基于决策公理的方法，丰富了决策理论和伦理约束的研究。特别地，作者提出了决策-评价悖论的概念，揭示了在使用决策数据训练模型或应用公理进行决策和评价时的复杂性，并强调了这种方法的重要性。", "conclusion": "作者认为决策-评价悖论与现实中的公理结构密切相关。这一悖论揭示了在决策数据训练模型或应用公理进行决策和评价时必须格外小心的原因。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21982", "html_url": "https://arxiv.org/abs/2509.21982", "title": "RISK: 电子商务风险管理中GUI代理的框架", "title_en": "RISK: A Framework for GUI Agents in E-commerce Risk Management", "authors": "Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen", "background": "电子商务风险管理工作需要整合多样而嵌入式的网络数据，这通常需要多步骤的状态性交互，而传统的爬取方法和现有的图形用户界面（GUI）代理无法处理。这些代理通常仅限于单步骤任务，缺乏管理动态互动内容的能力，这是有效风险评估的关键。", "innovation": "本文引入了RISK框架，用于构建和部署电子商务风险管理领域的GUI代理。RISK集成了三个组件：RISK-Data数据集、RISK-Bench基准和RISK-R1强化学习框架。RISK-R1考虑了四个方面：输出格式奖励、单步骤级奖励、多步骤级过程重权和任务级重权，以增强输出的语法规则性、任务理解、早期训练反馈、关键后续步骤的重视和不同难度任务的聚焦。", "conclusion": "实验表明，RISK-R1优于现有基准，分别在线下单步骤和多步骤中提高了6.8%和8.8%的成绩。此外，在线评估任务成功率高达70.5%。RISK为自动化复杂网络交互提供了可扩展的领域特定解决方案，推动了电子商务风险管理领域的技术进步。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21823", "html_url": "https://arxiv.org/abs/2509.21823", "title": "ProRe：GUI代理的主动奖励系统通过推理者-演员协作实现", "title_en": "ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration", "authors": "Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu", "background": "对于大型语言模型（LLMs）的评估和训练，奖励机制至关重要。现有的基于规则或模型的奖励方法在处理GUI代理时显得力不从心，因为这些代理往往缺乏真实的轨迹数据或应用程序数据库的访问权限。虽然静态轨迹为基础的LLM作为裁判的方法准确性有限，但这些方法也无法有效解决上述问题。", "innovation": "提出了一种名为ProRe的主动奖励系统，该系统利用通用推理者和领域特定的评估代理（演员），主动对环境进行探索性任务的调度，并基于与环境的交互收集额外观察信息，从而更准确地评估GUI代理。实验结果表明，ProRe可以提高奖励准确性高达5.3%，F1分数高达19.4%，与最先进的策略代理结合使用后，成功率提高了22.4%。", "conclusion": "该研究展示了一种有效的解决方案，通过推理者-演员协作来提高GUI代理的奖励评估准确性，并显著改善了策略代理的成功率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21862", "html_url": "https://arxiv.org/abs/2509.21862", "title": "通过Shachi重塑基于代理的建模以大型语言模型代理为依托", "title_en": "Reimagining Agent-based Modeling with Large Language Model Agents via Shachi", "authors": "So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang", "background": "对大型语言模型（LLM）驱动的多智能体系统的涌现行为的研究是一个关键的研究挑战，但受限于缺乏有序实验的方法学。研究该领域的方法不完善，使得实验控制变得困难，因此限制了进步。为了解决这种情况，该论文引入了Shachi，这是一种形式的方法论和模块化框架，将智能体的政策分解为核心认知组件：配置（为本性特征）、记忆（为情境持久性）和工具（为扩展能力），并通过LLM推理引擎协调。", "innovation": "Shachi 方法论超越了脆弱的、临时的智能体设计，并通过结构化组件和LLM推理引擎实现系统行为分析。这种方法经过广泛的10项任务基准测试的验证，并通过新的科学研究问题展示了其力量。关键的是，通过模拟真实的美国关税冲击，实验展示了智能体的行为仅在其认知结构适当地配置了记忆和工具时，才与观察到的市场反应一致。因此，这一工作为构建和评估LLM智能体提供了严格的开源基础，旨在促进更多累积和实证科学的研究。", "conclusion": "该研究通过Shachi提供了构建和评估大型语言模型代理人所需的基本框架，这将促进更累积和基于科学的研究。Shachi方法不仅使得涌现行为研究变得更加系统化，还展示了如何通过特定的架构设计实现集体行为的影响。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21998", "html_url": "https://arxiv.org/abs/2509.21998", "title": "GSM-Agent: 使用可控环境理解代理推理", "title_en": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "authors": "Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao", "background": "随着LLMs在代理系统中的部署，能够结合工具使用（特别是搜索）和推理的代理推理能力变得至关重要。然而，在复杂环境和任务中评估代理推理较为困难，当前的代理基准测试通常将代理推理与其他高阶能力混合，如复杂的数学推理、专家级知识等，这使得评估代理推理变得更加复杂。", "innovation": "本文构建了一个新的基准——GSM-Agent，其中要求LLM代理解决基础的数学推理问题，但仅凭问题描述没有提供必要的信息来进行任务解决，因此需要利用工具主动获取所需信息。研究发现，即便是在前沿模型如GPT-5中，也只能实现67%的准确率。为了理解和分析代理推理模式，提出了代理推理图的概念，将环境文档嵌入向量聚类为节点，并将每个工具调用映射到最近的节点构建推理路径。研究发现许多模型缺乏重新访问已访问节点的能力，因此提出了将工具增强的测试时缩放方法来改善代理推理性能。", "conclusion": "本文提出了一个新的基准GSM-Agent和代理推理框架，期望这些工作能够为未来改进代理推理能力的研究提供帮助。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21896", "html_url": "https://arxiv.org/abs/2509.21896", "title": "GenesisGeo：技术报告", "title_en": "GenesisGeo: Technical Report", "authors": "Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen", "background": "该研究基于大量几何问题的数据集和现有的自动化几何定理证明技术，旨在提高自动化几何证明的效率和准确性。研究者开放了一个包含2180万几何问题的大规模数据集，其中超过300万问题包含了辅助构造。背景还提到Qwen3-0.6B-Base在IMO-AG-30基准测试中解决了一部分几何问题的性能表现.", "innovation": "研究的主要创新在于开发了一个名为GenesisGeo的神经符号证明器，并大幅提高了符号推理引擎DDARN的速度，通过定理匹配加速了120倍，同时利用C++重写了核心组件。新的证明器展示了在单模型和双模型集成下的出色表现，分别解决了30个和30个以上符合IMO金牌和银牌水平的问题.", "conclusion": "GenesisGeo证明器在自动化几何证明上取得了显著进展，不仅能更快速地解决问题，还能通过模型集成提高解决方案的质量，并在国际数学奥林匹克几何问题上的表现超过了以往的技术水平。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21765", "html_url": "https://arxiv.org/abs/2509.21765", "title": "基于行为汇总的车辆路线终身学习", "title_en": "Lifelong Learning with Behavior Consolidation for Vehicle Routing", "authors": "Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao", "background": "最近的神经求解器在学习解决路由问题方面表现出很有前景的效果。然而，现有的研究主要是在一种或一组预定义的问题分布和规模上进行一次性的训练。当遇到新的任务时，现有方法依赖于零样本泛化或重新调整预训练的求解器，这可能导致对先前任务所学到的知识的灾难性遗忘。本文探讨了一种新的神经VRP求解器的终身学习范式，其中一系列具有不同分布和规模的任务依次出现。求解器需要在有效学习新任务的同时保持对之前任务的求解性能。因此，提出了一种名为Lifelong Learning Router with Behavior Consolidation (LLR-BC)的新框架，其通过目标导向的方式将新任务中训练的求解器的行为与缓存的行为对齐，有效地整合先前的知识。LLR-BC通过给予低置信度决策更大的汇总权重来鼓励更关注关键经验。", "innovation": "提出了一种新的终身学习框架——Lifelong Learning Router with Behavior Consolidation (LLR-BC)，其通过目标导向的方式将新任务中训练的求解器的行为与缓存的行为对齐，有效地整合先前的知识，从而解决灾难性遗忘问题，保持求解器的可塑性，并提高零样本泛化能力。LLR-BC能够分配更高的汇总权重给低置信度的决策，以促进对关键经验的关注。", "conclusion": "通过在容量受限的车辆路由问题和旅行商问题上的大量实验，本文展示了LLR-BC在终身学习环境下的训练高性能神经求解器的有效性，解决了灾难性遗忘问题，保持了求解器的可塑性，提高了零样本泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21842", "html_url": "https://arxiv.org/abs/2509.21842", "title": "DeepTravel: 一种端到端代理强化学习框架以构建自主旅行规划代理", "title_en": "DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents", "authors": "Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu", "background": "旅行规划（TP）代理作为一种新兴构件，能够与外部工具和资源互动，以确保用户享受愉快的体验。尽管TP代理具有诸多优势，但现有研究依赖于手工构建的提示和固定的工作流程，这限制了TP代理的灵活性和自主性。因此，需要一种能够自主规划、执行工具并根据多步推理过程中的工具响应进行自我反思，从而探索、验证和改进中间行动的框架。本文通过构建一个稳健的沙箱环境（其中包括交通、住宿和POI数据的缓存，能够不受现实世界API限制的约束进行TP代理培训），发展了一种分层奖励模型，并提出了一种回复增强的强化学习方法来定期回放失败经验，进而提升了TP代理的能力。", "innovation": "本文提出的DeepTravel是一个端到端的代理强化学习框架，用于构建自主的TP代理。该框架能够在多步骤推理过程中自主规划、执行工具并根据工具响应进行反思，从而探索、验证和改进行程计划。此外，通过构造一个包括交通、住宿和POI数据缓存的稳健沙箱环境，避免了现实世界API的限制。分层奖励模型由轨迹级验证器和轮次级验证器组成，前者检查时空可行性并过滤不满意的行程，后者则验证行程细节与工具响应的一致性。回复增强的强化学习方法使得TP代理能够定期从失败经验中学习，提升其能力。此外，DeepTravel展示了小型LLM（如Qwen3 32B）在旅行规划任务上的显著性能提升，超过了现有的前沿LLM（如OpenAI的o1、o3和DeepSeek的R1）", "conclusion": "我们已经在DiDi企业解决方案应用上部署了DeepTravel训练的TP代理，并进行了全面的在线和离线评估，表明DeepTravel能够使小型LLM（如Qwen3 32B）在旅行规划任务上显著优于现有的前沿LLM（如OpenAI的o1、o3和DeepSeek的R1）"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21825", "html_url": "https://arxiv.org/abs/2509.21825", "title": "DS-STAR: 数据科学代理通过迭代规划和验证", "title_en": "DS-STAR: Data Science Agent via Iterative Planning and Verification", "authors": "Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister", "background": "数据科学将原始数据转化为可操作的洞察，对于数据驱动的决策至关重要。然而，这些过程往往复杂且耗时，涉及探索多种数据源并综合分析以提供有价值的答案。虽然大型语言模型（LLMs）在自动化这一过程方面表现出显著的潜力，但在处理异构数据格式和生成优化分析方案方面仍存在困难。因为验证计划的充分性是非常困难的，尤其是在开放性任务中没有地面真理标签。", "innovation": "为了克服这些局限，我们引入了DS-STAR，这是一种新颖的数据科学代理，其贡献包括：(1) 一个数据文件分析模块，能够自动探索和从多种数据格式中提取上下文，包括非结构化类型；(2) 一个验证步骤，其中基于LLM的评判员在每个阶段评估分析计划的充分性；(3) 一种顺序规划机制，从简单可执行的计划开始，然后根据DS-STAR的反馈进行逐步改进，直到其充分性得到验证。这一迭代优化使DS-STAR能够可靠地处理涉及多样化数据源的复杂分析。", "conclusion": "我们的实验表明，DS-STAR在三个具有挑战性的基准测试DABStep、KramaBench和DA-Code中实现了最佳性能。此外，DS-STAR在需要处理具有异构格式的多个数据文件的难题上特别优于基线方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22044", "html_url": "https://arxiv.org/abs/2509.22044", "title": "A2R:一个异构两阶段推理框架用于并行推理", "title_en": "A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning", "authors": "Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen", "background": "近期的大规模推理模型通过在推理阶段分配更多计算，实现了复杂任务解决能力的显著提升。尽管模型的基础推理能力快速发展，但模型单次尝试的表现与潜在能力之间仍存在巨大差距，尤其是在不同解题路径中的性能差异更为明显。这表明模型实现的能力与其潜在能力之间存在显著差距。", "innovation": "A2R框架是一个可用于提升复杂问题解决能力的即插即用并行推理框架，通过两种关键创新实现性能提升和成本效率：1) 通过展示A2R框架，直接增强模型在复杂问题上的潜在能力，例如Qwen3-8B-distill模型在使用该框架后性能提高75%；2) 通过系统分析探索者和 synthesizer的角色，提出了有效的异构扩展模式，该模式结合轻量级和重型模型，提高了性能并降低了成本。", "conclusion": "A2R不仅是一个性能提升框架，还是一个在实际应用中具有高效和实用解决方案的有效方法，通过两阶段推理过程，使得计算在传统顺序方法的基础上能独立扩展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21993", "html_url": "https://arxiv.org/abs/2509.21993", "title": "双线性关系结构修复反转诅咒并实现一致的模型编辑", "title_en": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "authors": "Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha", "background": "当前广泛认为语言模型（LM）无法从已学习的事实'A是B'推断出未见过的事实'B是A'，这是其基本局限性。但是，本研究指出这不是固有的失败，而是由于模型如何编码知识的产物。", "innovation": "通过从头训练语言模型在合成的具有关系知识图形的数据集上，我们发现双线性关系结构在模型的隐藏表示中自然出现，并显著缓解了反转诅咒，使模型能够推测未见过的逆向事实。此外，我们发现这种双线性结构在模型编辑的连贯性中起着关键作用。对于具有这种表示的模型，在更新了一个事实之后，编辑能够在逆向事实及其他逻辑相关事实之间正确传播。", "conclusion": "我们的结果表明，通过关系知识数据集的训练诱导模型内部双线性表示的出现，这些表示在编辑过程中使模型能够表现出逻辑一致的行为。这表明，模型编辑的成功不仅依赖于编辑算法，还取决于被修改知识的潜在表示几何结构。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21902", "html_url": "https://arxiv.org/abs/2509.21902", "title": "DyRo-MCTS: 动态鲁棒蒙特卡洛树搜索方法在动态车间调度中的应用", "title_en": "DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling", "authors": "Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang", "background": "动态车间调度是一个在各个工业部门中普遍存在并且极为重要的组合优化问题。由于新任务的频繁到达，导致现有调度策略难以应对这种动态环境中的快速变化。当前的先进方法主要依靠机器学习来学习离线调度策略，以实现快速响应动态事件。然而，这些离线策略往往不够完美，因此需要借助如蒙特卡罗树搜索（MCTS）等规划技术，在线决策时进行改进。但是，新任务的不可预测性复杂化了在线规划，基于不完整信息作出的决策容易受到干扰的影响，这进一步增加了优化难度。", "innovation": "本文提出了一种称为DyRo-MCTS的方法，它将在蒙特卡洛树搜索（MCTS）中的动作鲁棒性评估结合起来，目的是引导生产环境进入既能导致良好调度结果，又能对未来到来的新任务进行快速适应的状态。实验结果表明，DyRo-MCTS显著提高了离线学习策略的性能，并且在线规划时间几乎没有额外增加。此外，DyRo-MCTS在不同调度场景中都优于传统的MCTS方法。进一步分析表明，这种方法能够在面对扰动时做出更为稳健的调度决策，从而实现长期的可持续性能提升，", "conclusion": "通过引入DyRo-MCTS方法，本文展示了如何将动作鲁棒性评估融入到MCTS中，以改善实时调度决策的质量。这种方法极大地提高了离线学习的调度策略在动态车间调度中的实际应用性能，并且由于在线规划成本低，可广泛应用于各种类型的实际生产环境中。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21943", "html_url": "https://arxiv.org/abs/2509.21943", "title": "足底压力异常检测：统计参数映射与可解释机器学习的人本比较", "title_en": "Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning", "authors": "Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich", "background": "足底压力测量在临床诊断和体育科学中非常重要，但大型异质性数据集中常包含技术错误或程序不一致导致的离群值。虽然统计参数映射(Statistical Parametric Mapping, SPM)可以提供可解释的分析，但它对对齐敏感，其稳健离群值检测能力尚不明确。本研究旨在比较SPM方法与可解释机器学习(Explainable Machine Learning, ML)方法，以建立透明的质量控制管道，用于足底压力数据集中，数据由多个中心的专家共识注释，并以合成异常值丰富，生成798个有效样本和2000个离群值。研究表明，ML模型在准确性上优于SPM，SPM难以识别有意义的临床变异性并遗漏真正的离群值。", "innovation": "这项研究比较了基于注册的SPM方法与利用SHapley Additive exPlanations (SHAP)解释的卷积神经网络(CNN)在足底压力数据集中的性能，发现ML模型在准确性上超过SPM，且专家认为两种方法的解释都清晰、有用且可信，但SPM被认为更简单些。这突显了SPM和可解释机器学习作为自动离群值检测方法的优点，强调了解释性在将复杂模型输出转化为可解释洞察以有效指导决策中的重要性。", "conclusion": "这项研究表明，SPM和可解释机器学习可以在足底压力数据集的自动离群值检测中互补。高复杂的机器学习模型既能获得高的准确性和可靠性，又能提供清晰的解释，增强临床决策过程中的透明度。研究强调了可解释性的价值，以确保复杂模型的输出能够转化为易于理解的结果，从而支持有效的决策过程。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21981", "html_url": "https://arxiv.org/abs/2509.21981", "title": "CoBel-World: 利用大语言模型推理解出协作信念世界以优化体感多智能体协作", "title_en": "CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration", "authors": "Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang", "background": "有效的现实世界多智能体协作不仅需要准确的规划，还需要推断协作者的意图的能力，这对于避免在部分可观测环境中发生误协调和冗余通信至关重要。大型语言模型（LLMs）由于其强大的规划和推断能力，被看作是自主代理中实现协同任务解决的有前途选择。然而，现有的LLM协作框架忽视了它们推理的潜在能力，从而导致生成不一致的计划和冗余通信，这降低了合作效率。因此，需要新的方法来有效利用LLM的推理能力，以提高协作效率和降低通信成本。", "innovation": "我们提出了CoBel-World，这是一种新型框架，赋予LLM智能体一个协作信念世界——一种同时建模物理环境和协作者心理状态的内部表示。该框架使得智能体能够通过符号信念语言将开放世界的任务知识解析为结构化的信念，并通过LLM推理进行零样本的贝叶斯式信念更新。这允许智能体主动检测潜在的误协调（例如，冲突计划），并实现适应性通信。CoBel-World在具有挑战性的体感基准测试（如TDW-MAT和C-WAH）中，显著地将通信成本降低了22-60%，并提高了4-28%的任务完成效率，优于最强基线。", "conclusion": "实验结果表明，明确、意图感知的信念建模对于基于LLM的多智能体系统的高效和人性化协作至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22284", "html_url": "https://arxiv.org/abs/2509.22284", "title": "构建结构化稀疏过渡矩阵以在状态空间模型中实现状态跟踪", "title_en": "Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models", "authors": "Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi", "background": "现代状态空间模型（SSMs）通常使用过渡矩阵以实现高效计算，但这限制了模型的表达能力，即模型模仿有限状态自动机（FSA）的能力。虽然无结构的过渡矩阵在表达能力方面最优，但其计算和内存成本极高，即使对于中等状态大小也是如此。然而，有结构的过渡矩阵在保持相对较低的计算成本的同时，无法达到无结构矩阵的表达能力。", "innovation": "提出了一种结构化稀疏过渡矩阵的参数化方法PD-SSM，该方法使得状态空间模型可以进行FSA状态跟踪，同时保持状态大小和深度的理想值，并使递归计算成本与对角形式的计算成本相当。这种方法将过渡矩阵表示为列单比特矩阵$P$和复数对角矩阵$D$的乘积。此外，该方法的理论模型是BIBO稳定，并能模仿任何$N$状态的FSA，显著优于当前所有结构化SSM的保证。实验表明，该模型在多种FSA状态跟踪任务中表现优异，性能与神经控制微分方程相当，后者是专门为时间序列分析构建的。最后，将PD-SSM整合到混合Transformer-SSM架构中，成功跟踪了复杂FSA的状态，其转换由一组变长英文句子编码。", "conclusion": "PD-SSM方法构建了一种结构化稀疏形式的过渡矩阵，使状态空间模型能够高效地跟踪FSA的状态，同时保持较高的表达能力和较低的计算成本，且在实验中表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22261", "html_url": "https://arxiv.org/abs/2509.22261", "title": "InfiMed-Foundation: 引领计算高效预训练与多阶段微调的高级多模态医学模型", "title_en": "InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning", "authors": "Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大型语言模型（MLLMs）在各个领域展现了显著潜力，但在医疗领域的应用受限于多重挑战。通用型MLLMs缺乏针对医疗任务的专门知识，导致不确定或虚构的回答。从高级模型的知识蒸馏难以捕捉放射学和药理学领域的特有专长。此外，大规模医疗数据的连续预训练计算成本高，效率较低。", "innovation": "我们提出了InfiMed-Foundation-1.7B和InfiMed-Foundation-4B，这是两种专门为医疗应用设计的多模态大型语言模型。我们结合高质量的通用和医疗多模态数据，提出了一种新颖的五维质量评估框架，用于策划高质量的多模态医疗数据集。我们采用低至高清图像分辨率和多模态序列包装来增强训练效率，促进大量医疗数据的整合。此外，一个三阶段监督微调过程确保了复杂医疗任务的有效知识提取。InfiMed-Foundation-1.7B在MedEvalKit框架下超越了Qwen2.5VL-3B，而InfiMed-Foundation-4B则超过了HuatuoGPT-V-7B和MedGemma-27B-IT，展示了在医疗视觉问答和诊断任务上的优越性能。", "conclusion": "通过解决数据质量、训练效率和领域特定知识提取中的关键挑战，我们的工作为更可靠的AI驱动的医疗解决方案铺平了道路。InfiMed-Foundation-4B模型可在以下链接获得：[InfiMed-Foundation-4B]。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22034", "html_url": "https://arxiv.org/abs/2509.22034", "title": "思考谱系：通过模型合并实现可控推理能力的研究", "title_en": "The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging", "authors": "Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li", "background": "由于实际应用中对具有可调推理能力的大型语言模型（LLMs）需求增长，迫切需要能够高效生成平衡推理深度与计算成本的模型的方法。模型合并作为一项潜在的、无需训练的技术，通过算术结合通用模型和专业推理模型的权重来解决这一挑战。尽管存在多种合并技术，但它们在生成具有精细控制推理能力的多维模型方面尚有研究空白。", "innovation": "该研究通过大规模实证分析多种模型合并技术在多个推理基准上的效果，系统地改变合并强度来构建准确性和能效曲线，首次全面展示了该领域可调性能的空间。研究结果显示，模型合并是一种校准推理准确性和标记效率之间权衡的有效且可控的方法，即使亲本模型具有高度差异的权重空间也不例外。研究中还发现了帕累托改进现象，即合并模型同时在准确性和标记消耗上优于其亲本模型。这项研究提供了首个全面分析这种可控空间的分析，为根据特定应用需求创建具有特定推理特征的LLMs提供了实用指南。", "conclusion": "研究证明了模型合并的有效性和可控性，可以在保持高准确性的前提下实现低标记消耗，为开发者和用户提供了优化模型配置的实用指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22137", "html_url": "https://arxiv.org/abs/2509.22137", "title": "Log2Plan: 结合任务挖掘方法的自适应GUI自动化框架", "title_en": "Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach", "authors": "Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim", "background": "GUI任务自动化可以简化重复任务，但现有的基于LLM或VLM的计划执行代理在泛化能力、延迟和长时序一致性方面存在缺陷。它们依赖单次推理或静态计划，因此在UI变化或复杂任务情景下容易脆弱。", "innovation": "Log2Plan 通过结合结构化的两级规划框架和从用户行为日志中进行的任务挖掘方法，解决了这些限制。Log2Plan 利用高层次的计划格式映射用户命令到结构化的任务字典，实现了稳健和适应性强的GUI自动化。此外，它支持个性化和重用，通过识别用户特定模式的方法，然后将高层计划具体化为低级操作序列，以确保在不同接口上的一致性和稳健性执行。", "conclusion": "我们在200个实际任务上测试了Log2Plan，展示了任务成功率和执行时间的显著改善。尤为重要的是，即使在长时序任务序列中，它仍然保持超过60%的成功率，突显了其在复杂的多步骤工作流程中的稳健性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "Clinical Uncertainty Impacts Machine Learning Evaluations", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集中标签往往不明确，因为标注者的观点可能不一致且对不同案例的信心不均匀。典型的聚合方法，如多数投票，会隐藏这种不确定性。在医学影像基准的简单实验中表明，考虑二元标签的信心可以显著影响模型的排名。因此，作者认为在机器学习评估中应该明确考虑标注不确定性，使用直接操作分布的概率指标.", "innovation": "提出了一种新的视角，认为应该在机器学习评估中使用概率指标来直接操作分布，这些指标可以独立于标注过程，无论是通过简单的计数、主观的信心评分还是概率响应模型生成的。此外，这些指标在计算上非常轻量级，因为闭式表达式可以在模型评分排序后进行线性时间实现.", "conclusion": "作者建议研究社区提供原始标注，并采用不确定性意识的评估机制，使性能估计能更好地反映临床数据."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22085", "html_url": "https://arxiv.org/abs/2509.22085", "title": "通过目标聚合函数泛化多目标搜索", "title_en": "Generalizing Multi-Objective Search via Objective-Aggregation Functions", "authors": "Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman", "background": "多目标搜索（MOS）在机器人领域变得至关重要，因为现实世界的机器人系统需要同时平衡多个，经常相互冲突的目标。近期的研究探索了目标之间的复杂交互，导致了不能直接使用现成的顶级MOS算法的问题表述。这些复杂问题需要一种新的通用问题表述方法，能够应用标准的MOS算法并只需适当扩展一些核心操作来反映特定的聚合函数。作者提出了这种方法，并通过多种不同的机器人规划问题展示了其有效性。这些问题涵盖了导航、操作和医疗系统中的路径规划（含障碍不确定性下的规划）、以及不同的道路类型下的路线规划。通过适当扩展顶级MOS算法的核心操作，解决了这些问题，并提供了实验证据，证明泛化后的算法比原始版本的算法在同一问题上效果要好许多倍。", "innovation": "提出了通过聚合函数泛化多目标搜索的新通用问题表述方法，使得可以使用标准MOS算法并只需适当扩展一些核心操作来反映特定的聚合函数。展示了该方法在多种不同机器人规划问题中的有效性，证明了泛化后的算法在性能上远远优于原始版本的算法。", "conclusion": "这是一种通过聚合函数泛化的多目标搜索方法，在处理涉及多个相互冲突目标的机器人问题时，能够提升传统MOS算法的性能，通过适当的扩展和优化，能够在更复杂的问题设置中有效应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22255", "html_url": "https://arxiv.org/abs/2509.22255", "title": "评估大规模语言模型在组合优化中的应用：针对2D矩形装箱问题的一阶段和两阶段启发式方法", "title_en": "Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing", "authors": "Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder", "background": "本文提出了一个评估大规模语言模型（LLMs）在组合优化中的能力的框架，特别针对2D矩形装箱问题。研究结合LLMs与进化算法，系统地生成和完善启发式解决方案。通过与传统方法（有限第一次填充和混合第一次填充）进行全面实验比较，结果显示LLMs能够生成更高效的解决方案，且所需计算资源较少。具体来说，GPT-4o在两迭代内即可达到最优解，平均减少了1个箱子使用量，并将空间利用率从0.76-0.78提升至0.83。", "innovation": "文章提出了一种将LLMs与进化算法结合的系统方法，用于生成和精炼启发式解决方案，并通过与传统方法的实验比较展示了LLMs的优势。此外，研究还揭示了在特定领域评估LLMs的有效方法，并为组合优化任务设立了新的基准。", "conclusion": "本文为理解LLMs在专业化领域中的评估方法做出了贡献，并且为在组合优化任务中评估LLMs的表现建立了基准。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22407", "html_url": "https://arxiv.org/abs/2509.22407", "title": "EMMA：通过生成视觉转移实现现实世界机器人操作的泛化", "title_en": "EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer", "authors": "Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang", "background": "视觉-语言-行动（VLA）模型越来越依赖多样化的训练数据以实现稳健的泛化。然而，跨不同物体外观和环境条件收集大规模的真实世界机器人操作数据仍然是耗时且成本高昂的。为了解决这一瓶颈，我们提出了Embodied Manipulation Media Adaptation（EMMA），一种结合生成数据引擎和高效训练管道的VLA策略增强框架。", "innovation": "我们引入了DreamTransfer，这是一种基于扩散Transformer的框架，用于生成多视图一致、几何基础的机器人操作视频。DreamTransfer允许文本控制视频中机器人的视觉编辑，可以改变前景、背景和照明条件，而不影响三维结构或几何可行性。此外，我们探索了使用真实数据和生成数据的混合训练，并引入了AdaMix，一种硬样本感知的训练策略，能够动态调整训练批处理权重，以聚焦于感知或动力学上具有挑战性的样本。生成的视频在多视图一致、几何保真度和文本条件准确性方面明显优于先前的方法。我们的方法在零样本视觉域的真实世界机器人操作任务中，与仅使用真实数据训练相比，性能提高了200%以上，adaMix进一步提高了13%，证明了其在增强策略泛化方面的有效性。", "conclusion": "通过生成的视频数据训练的VLA模型能够仅通过单一外观的演示来泛化到未见过的对象类别和新的视觉领域。在真实世界机器人操作任务中，采用我们的方法，相对性能提高了200%以上，进一步使用AdaMix优化后，性能提升13%，显示出其在增强策略泛化方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22504", "html_url": "https://arxiv.org/abs/2509.22504", "title": "Estimating the Empowerment of Language Model Agents", "title_en": "Estimating the Empowerment of Language Model Agents", "authors": "Jinyeop Song,Jeff Gore,Max Kleiman-Weiner", "background": "随着语言模型（LM）代理变得更加能力和广泛地访问现实世界工具，对代理能力的可扩展评估框架的需求也在增加。然而，传统的基准驱动评估既昂贵又复杂，需要人类设计师设计出能够转化为对通用模型能力洞察的有效任务。本文探讨了使用基于信息论的评估方法（以代理行为与未来状态之间的互信息为基础）来评估LM代理。", "innovation": "本文提出了基于信息论的评估方法——基于代理行为与其未来状态间互信息的代理效能评估，并引入了EELMA算法（Estimating Empowerment of Language Model Agents），用于从多轮文本交互中近似代理效能。该方法在语言游戏和扩大规模的真实网页浏览场景中得到了验证。", "conclusion": "通过这些结果，表明代理效能是评估和监控LM代理在复杂、开放性环境中表现的一种具有吸引力的一般性指标。代理效能与平均任务性能呈现出强烈的相关性，且环境复杂性和代理因素（如思考连贯性、模型规模、记忆长度）对估计的代理效能有显著影响，高代理效能时刻往往是通用能力关键时刻。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22516", "html_url": "https://arxiv.org/abs/2509.22516", "title": "TrueGradeAI：检索增强且抗偏见的人工智能，实现透明和可解释的数字评估", "title_en": "TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments", "authors": "Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla", "background": "传统的基于纸张的评估方式存在诸多缺点，包括大量的纸张使用、复杂的物流安排、评分延迟以及评分者偏见等。为了克服这些问题，本文介绍了一种名为TrueGradeAI的基于人工智能的数字考试框架。", "innovation": "TrueGradeAI框架通过捕获平板上的笔迹输入并应用基于变换器的光学字符识别进行转录，保留了考生的自然笔迹。该系统通过结合检索增强管道来评分，该管道包括教师解决方案、缓存层和外部参考。这种框架不仅将反应和评分过程透明化和可解释化，还引入了可解释的自动评分、偏见缓解以及可审计的评分记录，有效地克服了现有基于平板的考试系统主要针对响应数字化的问题。", "conclusion": "TrueGradeAI通过保存书写笔迹与规模化、透明化的评估相结合，减少了环境成本，加速了反馈循环，建立了一个可重复利用的知识库，并积极抵抗评分偏见，确保评估公平性，从而在评估领域取得了实质性进展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22092", "html_url": "https://arxiv.org/abs/2509.22092", "title": "校验AI能耗：CodeCarbon与外部度量的实证对比", "title_en": "Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements", "authors": "Raphael Fischer", "background": "尽管机器学习（ML）和人工智能（AI）为创新带来了激动人心的可能性，但它们的快速开发也显著影响了环境。鉴于对资源意识的增强，开发了如机器学习排放计算器（ML Emissions Calculator）和CodeCarbon等量化工具来估算运行AI模型的能量消耗和碳排放。这些工具易于集成到AI项目中，但在进行能量估算时往往做出一些实用假设，并忽略了重要因素，因此估算的准确性令人质疑。该研究系统性地通过与大量AI实验的实际测量数据进行对比，评估静动态能量估算方法的可靠性。研究提供了关于AI能耗需求和估算不准确性的调查见解。虽然所建立的估算方法大致遵循AI能耗的一般模式，但它们在误差范围上显示出高达40%的误差，而真实能耗测量证实了这一点。该研究通过提供关于估算质量的实际证据和检验证明，提高了透明度，增强了用于可持续AI发展的工具的有效性，并提出了改进现有技术的指导原则，同时为其他领域和工具的验证提供了代码，从而对资源意识的机器学习和AI可持续性研究做出了重要贡献。", "innovation": "该研究提出了一个验证框架，以评估静动态能量估算方法的可靠性，并通过与实际测量数据进行比较，提供了关于AI能耗需求和估算不准确性的调查见解。该研究指出了现有估计方法中的误差高达40%，并提供了实际证据，提高了对这些工具的透明度，同时也提出了改进现有技术的指导原则。此外，该研究还提供了代码，以便扩展验证到其他领域和工具，进一步推动了资源意识的机器学习和AI可持续性研究的发展。", "conclusion": "该研究通过与实际测量数据的对比验证了CodeCarbon等估算工具的可靠性。虽然目前的静态和动态能量估算方法在很大程度上遵循AI能耗的一般模式，但它们存在高达40%的误差，通过提出验证框架和提供实际证据，该研究提高了这些工具的透明度和有效性，并为持续改进和拓展领域内的验证提供了指导和代码，为资源意识的机器学习和AI的可持续发展做出了重要贡献。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22518", "html_url": "https://arxiv.org/abs/2509.22518", "title": "REMA：一种解释大型语言模型推理统一理据流形框架", "title_en": "REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model", "authors": "Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen", "background": "理解大型语言模型如何执行复杂推理及其失败机制在可解释性研究中是一个挑战。本文提出了理据流形的概念，定义了一个由所有正确推理生成的内部表示组成的潜在低维度几何结构。该结构反映了模型学习的有效思维路径，以成功解决给定任务。通过这种概念，我们构建了REMA框架，通过定量比较错误和正确的推理样本对应的内部模型表示的空间关系来解释失败的起源。大量的实验结果表明了理据流形的低维度性质以及错误和正确推理表示的高可分性。", "innovation": "作者定义了理据流形的概念，提出了一种新的解释框架REMA。REMA通过计算每个错误表示与其近似流形（由正确表示组成）的邻近度距离，定量分析错误和正确的内部模型表示的空间关系，识别推理失败的起始点。该框架为诊断黑盒模型的内部计算过程提供了新的途径。", "conclusion": "我们的实验结果验证了理据流形的低维度性质以及错误和正确推理表示的高可分性。REMA框架在分析推理失败的起因方面具有有效性。这种方法将抽象的推理失败与表示的空间可测量偏差联系起来，为我们提供了深入了解和诊断黑盒模型内部计算过程的新途径。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22447", "html_url": "https://arxiv.org/abs/2509.22447", "title": "使用视觉语言模型引导人工生命进化的策略", "title_en": "Guiding Evolution of Artificial Life Using Vision-Language Models", "authors": "Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser", "background": "基础模型（FMs）在人工生命（ALife）领域开辟了新的前沿，通过提供强大的工具来自动搜索ALife模拟。以往的研究使用视觉语言模型（VLMs）将ALife模拟与自然语言目标提示对齐。本研究在此基础上，引入了ASAL++，一种基于多模态FMs的开放搜索方法，使用第二个FMs根据模拟的视觉历史提出新的进化目标，从而诱导越来越复杂的进化轨迹。", "innovation": "通过引入ASAL++，利用多模态基础模型提出新的进化目标，并探索两种策略：一种是每次迭代根据单个新提示进化模拟（Evolved Supervised Targets: EST），另一种是根据生成的整个提示序列进化模拟（Evolved Temporal Targets: ETT）。实验中在Lenia基质上使用Gemma-3提出进化目标，表明EST增强了视觉新颖性，而ETT促进了更连贯和可解释的进化序列。", "conclusion": "结果表明，ASAL++为以开放性特征为基础模型驱动的人工生命发现提供了新的方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME：集成规划与检索的记忆体系以增强推理", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "基于《思考，快与慢》中的人类认知双重过程理论，论文提出了一个集成规划与检索的记忆系统——PRIME，这是一个多代理推理框架，动态集成快速直观思考的System 1和慢速详细思考的System 2。PRIME首先使用快速思考代理生成快速回答，如果检测到不确定度，则启动包含专门规划、假设生成、检索、信息整合和决策代理的结构化System 2推理管道。这种多代理设计真实地模拟了人类的认知过程，提高了推理的效率和准确性。", "innovation": "PRIME框架旨在通过多代理系统的动态交互，模拟人类认知过程中的快速直觉和慢速深入思考。这一框架允许开源语言模型在需要多步和基于知识推理的任务中表现出色，与先进的闭源模型如GPT-4和GPT-4o进行竞争，展示了其在提高语言模型应对复杂知识密集推理需求领域的潜力。", "conclusion": "实验结果表明，PRIME能够使开源语言模型在多步骤和基于知识推理的基准测试中与最先进的闭源模型竞争，这确立了PRIME作为一个适用于需要复杂知识密集推理领域的可扩展解决方案的地位。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22391", "html_url": "https://arxiv.org/abs/2509.22391", "title": "LLM代理知道自己如何定位、恢复和评估吗？信息寻求代理的元认知能力基准", "title_en": "Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents", "authors": "Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo", "background": "近年来的研究发现，通过强化学习（RL）培训大型语言模型（LLM）搜索代理，以进行开放域的问答（QA）。然而，大多数评估都只关注最终答案的准确性，忽视了这些代理处理和利用外部证据的方式。为了弥补这一缺陷，论文引入了SeekBench，这是第一个通过逐步骤分析LLM搜索代理响应轨迹，来评估其元认知能力（epistemic competence）的基准。", "innovation": "SeekBench包括了由190个专家标注的响应轨迹，其中包含超过1,800个响应步骤，并为此补充了证据标注，以便于细致分析代理是否（1）生成基于观察到证据的推理步骤，（2）调整搜索过程以纠正低质量结果，（3）正确评估当前证据是否足够提供答案。这种逐步骤的分析方法为评估LLM搜索代理的元认知能力提供了新的视角，有助于改进代理的表现与可靠性。", "conclusion": "SeekBench提供了一种新的评估方法，关注LLM搜索代理在处理和使用外部证据时的元认知能力。这种方法可以帮助研究人员和开发者更全面地理解代理的行为，并为进一步改进代理的关键行为提供指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22297", "html_url": "https://arxiv.org/abs/2509.22297", "title": "大型语言模型作为非确定性因果模型", "title_en": "Large Language Models as Nondeterministic Causal Models", "authors": "Sander Beckers", "background": "Chatzi等人和Ravfogel等人近期的工作首次开发了一种方法，用于生成概率大型语言模型的反事实。这些反事实提供了，若输入变更，则模型输出可能的变化情况。这项能力对于解释、评估和比较LLM的行为至关重要。然而，现有方法基于一种对LLM的模棱两可的解释，既非字面解释，也非预期解释。现有的方法假设可以改变语言模型采样过程的实现方式，而不改变模型本身，同时将一种非确定性语言模型解释为一个确定性的因果模型。在本文中，作者提出了一个新的、更简单的方法来生成反事实，该方法基于LLM的预期解释，将其表示为一个非确定性因果模型。这种方法具有直接适用于任何黑盒语言模型的优势，而无需修改，因为该方法对实施细节是无感知的。相反，现有方法直接实现了特定类型的反事实生成，虽然在某些用途上很有用，但在其他用途上并不适用。作者通过提供一个基于LLM预期语义推理反事实的理论基础，为生成反事实的新型专用方法奠定了基础。", "innovation": "作者提出了一种生成反事实的更简单方法，基于LLM的预期解释，将其表示为一个非确定性因果模型，这种方法直接适用于任何黑盒语言模型，无需修改，因此对实施细节是无感知的。这方法相比现有方法的优势在于，它可以生成一种具有特定用途的反事实，尽管对某些特定用途来说有用，但在其他方面并不适用。通过基于LLM预期语义表达反事实的理论基础，作者为生成反事实的新型专用方法铺平了道路。", "conclusion": "本文为大型语言模型中的反事实生成提供了一个理论基础，基于其预期语义的因果模型。这种方法直接适用于任何黑盒语言模型，而不依赖于实施细节。尽管目前的方法可以生成特定类型的反事实，但它的应用较为有限。通过这种方法，作者为设计新的专用反事实生成方法提供了理论依据。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22572", "html_url": "https://arxiv.org/abs/2509.22572", "title": "Dynamic Experts Search：在测试时增强Mixture-of-Experts大语言模型的推理能力", "title_en": "Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time", "authors": "Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang", "background": "测试时放大（Test-Time Scaling, TTS）通过在推理过程中分配额外计算来增强大语言模型（LLMs）的推理能力，但现有方法主要依赖于输出级采样，忽视了模型架构的作用。主流的Mixture-of-Experts（MoE）LLMs中，通过调整激活专家的数量会得到稳定准确性的互补解决方案集，展示了新的未被充分探索的多样性来源。", "innovation": "提出了一种新的测试时放大策略Dynamic Experts Search (DES)，该策略将专家激活转化为搜索空间中的可控维度。DES集成了两部分关键组件：动态Mixture-of-Experts (Dynamic MoE)，允许在推理过程中直接控制专家数量，生成多样化推理轨迹而不增加成本；专家配置继承，保持推理路径内的一致专家数量，而跨运行改变它们，从而在整个搜索过程中平衡稳定性和多样性。", "conclusion": "在Mixture-of-Experts架构、验证器和推理基准测试（例如，数学、代码和知识）下进行的广泛实验表明，DES比TTS基线更能可靠地提高准确性，并且在不增加成本的情况下增强稳定性。研究结果强调DES作为一种实用且可扩展的架构感知型TTS形式，展示了现代LLMs结构灵活性如何推动推理的进步。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22460", "html_url": "https://arxiv.org/abs/2509.22460", "title": "GeoSketch: 一种辅助线构造与仿射变换的神经符号几何多模态推理方法", "title_en": "GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation", "authors": "Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu", "background": "几何问题求解（GPS）对多模态大语言模型（MLLMs）构成了独特挑战，不仅要求对文本和图表进行联合解释，还需要迭代的空间 reasoning。现有方法处理图表作为静态图像，缺乏动态操控能力，这是人类几何推理的核心要素，涉及辅助线构造和仿射变换等操作。因此，需要一个统一的框架来促进图形理解和操作的动态互动，提升模型的几何推理能力.", "innovation": "GeoSketch 是一个神经-符号框架，将几何推理重新定义为感知-推理-行动循环。它集成了一个感知模块、一个符号推理模块和一个素描动作模块。借助一个两阶段训练流程（监督微调和增强学习），GeoSketch 提升了解决几何问题的能力，并通过结合分层决策、可执行的视觉操作和符号验证，推动了多模态推理从静态解释到动态验证的转变.", "conclusion": "GeoSketch 通过统一图形理解和操作的动态互动，显著提升了多模态几何推理模型在复杂空间问题上的表现，为解决复杂的多模态问题奠定了新的基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21325", "html_url": "https://arxiv.org/abs/2509.21325", "title": "PIR-RAG：在检索增强生成中实现隐私信息检索的系统", "title_en": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation", "authors": "Baiqiang Wang,Qian Lou,Mengxin Zheng,Dongfang Zhao", "background": "检索增强生成（RAG）已成为现代AI系统的基础组件，但它通过暴露用户查询给服务提供商引入了重大的隐私风险。因此，本文探讨了如何通过一个实用的系统来保护用户隐私。", "innovation": "本文提出了PIR-RAG系统，这是一种实用的隐私保护RAG系统。PIR-RAG采用了新颖的架构，结合粗粒度语义聚类来精简搜索空间，以及快速的基于格（lattice-based）的私有信息检索（PIR）协议。这一设计可以高效地检索整个文档集群，并且在端到端RAG流程中实现了全文档内容的优化。通过与强大的基线架构进行全面评估，包括基于图的PIR和Tiptoe风格的私有评分，展示了PIR-RAG的可扩展性以及在“RAG-Ready Latency”方面的卓越性能。", "conclusion": "我们的工作建立了PIR-RAG作为大型AI系统中实现隐私保护的一个可行且高效的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22537", "html_url": "https://arxiv.org/abs/2509.22537", "title": "大型语言模型代理社会中的利他主义产生", "title_en": "The Emergence of Altruism in Large-Language-Model Agents Society", "authors": "Haoyang Li,Xiao Jia,Zhanzhan Zhao", "background": "大型语言模型（LLMs）在社会模拟中的应用是计算社会科学的一个前沿领域。然而，现有研究主要集中在小规模、任务导向的游戏中合作，而忽视了大规模代理社会中利他的产生，即牺牲个人利益以实现共同利益的行为。本研究通过引入一个舍勒变体的城市迁移模型，创建了社会困境，迫使200多个LLM代理在个人利益和集体利益之间做出明显冲突的选择，以填补这一空白。", "innovation": "针对现有研究的不足，本研究创新地提出了一种舍勒变体的城市迁移模型，该模型创建了一种社会困境，促使200多个LLM代理在个人利益与集体利益之间做出冲突决策。通过这种方法，研究首次证明了不同LLMs在利他和自我利益倾向上的内在异质性，并引入了一种基于扎根理论的方法系统地编码代理推理，填补了这一领域的方法论空白。", "conclusion": "本研究提供了不同LLMs在自我利益和利他倾向上的内在异质性的初步证据。建议在社会模拟中，模型选择不仅涉及到推理能力的选择，还需要考虑内在的社会行动逻辑。'适应性利己者'可能更适合模拟复杂的人类社会，而'固有利他优化者'则更适合模型理想的亲社会行为或以集体福利为主要关切的情境。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22570", "html_url": "https://arxiv.org/abs/2509.22570", "title": "UniMIC：用于人机协作的基于令牌的多模态交互编码", "title_en": "UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration", "authors": "Qi Mao,Tinghan Yang,Jiahao Li,Bin Li,Libiao Jin,Yan Lu", "background": "大型多模态模型（LMMs）和基于云的AI代理的快速发展正在改变人机协作方式，使其成为双向、多模态交互。现有的编解码器仍然针对单模态、单向通信进行了优化，因此在传统的压缩—传输—重建管道下，会导致反复降解。", "innovation": "提出了一种统一的基于令牌的多模态交互编码框架UniMIC，以结合边缘设备和云AI代理之间的通信。UniMIC 采用紧凑的令牌化表示作为通信介质，实现高效低比特率传输同时保持与LMMs的兼容性。此外，轻量级的基于Transformer的熵模型结合场景特定设计有效减少了令牌间的冗余。", "conclusion": "广泛的实验表明，UniMIC 在文本到图像生成、文本引导的填补（包括出画外填补）和视觉问答任务中，实现了显著的比特率节省，即使在极低比特率（<0.05bpp）下仍保持鲁棒性，且不影响下游任务性能。这些结果确立了UniMIC作为下一代多模态交互通信的实用且前瞻的范式。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22502", "html_url": "https://arxiv.org/abs/2509.22502", "title": "InfiAgent：无限场景下的自我演化金字塔代理框架", "title_en": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "authors": "Chenglin Yu,Yang Yu,Songmiao Wang,Yucheng Wang,Yifan Yang,Jinjia Li,Ming Li,Hongxia Yang", "background": "大型语言模型（LLM）代理展示了在组织和执行复杂任务方面卓越的能力，许多此类代理现在被广泛应用于各种场景中。然而，开发这些代理需要精心设计的工作流程、精良的提示词以及迭代调优，这需要LLM技术和特定领域的专业知识。这些手工设计的限制阻碍了LLM代理在广泛行业的可扩展性和成本效益。为了解决这些挑战，我们提出了一种名为InfiAgent的金字塔状多代理框架，该框架可以应用于无限场景，并引入了几个关键创新：一种通用的“代理作为工具”机制，自动将复杂的代理分解为层次化的多代理系统；一种双审核机制，确保任务完成的质量和稳定性；一种代理路由功能，使任务与代理的匹配更加高效；以及一种代理自我进化机制，根据新的任务、性能不佳或优化机会自主重构代理DAG。此外，InfiAgent的原子任务设计支持代理并行操作，大大提高了执行效率。这个框架进化成一个多功能的金字塔状多代理系统，能够解决各种问题。在多个基准上的评估表明，与ADAS（类似自动生成的代理框架）相比，InfiAgent的性能提高了9.9%。案例研究显示，InfiAgent生成的科学论文在顶级IEEE会议上得到了同行评审的认可。", "innovation": "InfiAgent引入了几个关键创新：1. 通用的“代理作为工具”机制，自动分解复杂的代理；2. 双审核机制，确保高质量和稳定性；3. 代理路由功能，提高任务与代理的匹配效率；4. 代理自我进化机制，根据新的任务、性能不佳或优化机会自主重构代理DAG；5. 原子任务设计支持代理并行操作，提高执行效率。", "conclusion": "InfiAgent作为一种金字塔状多代理框架，能够解决无限场景下的挑战，通过自动化任务分解、审核、路由和自我进化机制，显著提高了代理执行效率和任务完成质量。实验表明，InfiAgent在多个基准测试中表现出色，特别是在生成科学论文方面，得到了顶级IEEE会议同行评审的认可。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22558", "html_url": "https://arxiv.org/abs/2509.22558", "title": "StepORLM：一种具有生成过程监督的自我进化的运筹学语言模型框架", "title_en": "StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models", "authors": "Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge", "background": "大型语言模型（LLMs）在解决运筹学（OR）问题上展示了良好的能力，尽管强化学习为LLM在OR问题上的训练提供了一种强大的范式，但现有研究通常面临着两个关键问题：首先是结果奖励中的责任分配问题，即最终正确答案可能会强化不正确的推理过程；其次是传统的区分过程监督过于短视，不能全面评估OR建模中的相互依赖步骤。因此，本文提出StepORLM，这是一种新颖的自我进化的框架，包含生成过程监督。", "innovation": "StepORLM的核心是一个共同进化的循环，其中策略模型和生成过程奖励模型（GenPRM）相互改进。这个循环由双重反馈机制驱动：外部求解器基于最终结果的肯定验证，以及来自GenPRM的全面而细腻的过程评估。结合信号用于通过加权直接偏好优化（W-DPO）对策略进行对齐，并同时细化GenPRM。StepORLM在六个基准测试中的结果表现出色，超过了更大、更通用的模型以及专门的方法。同时，共同演化的GenPRM能够有效地作为强大的、通用的过程验证器，显著提高了我们自己的模型以及现有其他LLM的推理扩展性能。", "conclusion": "最终结果表明，StepORLM在六个基准测试中建立了一个新的最先进的水平，显著优于更大更通用的模型、代理方法和专门的基线。共同进化产生的GenPRM作为强大的、通用的过程验证器，不仅显著提升了我们的模型的推理扩展性能，也增强了其他现有LLM的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21342", "html_url": "https://arxiv.org/abs/2509.21342", "title": "SGNNBench：大规模图上Spiking Graph Neural Network的综合评估", "title_en": "SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph", "authors": "Huizhe Zhang,Jintang Li,Yuchang Zhu,Liang Chen,Li Kuang", "background": "Graph Neural Networks (GNNs) 能够有效地捕捉图的拓扑结构，推动了图任务的性能边界。然而，随着真实世界图的快速增长，开发大规模图表示学习的复杂机制变得不可持续。鉴于计算和时间开销的问题，开发更节能的GNNs变得必要。Spiking Graph Neural Networks (SGNNs) 通过独特的基于脉冲的神经元实现生物可解释的学习，提供了节能的选择。", "innovation": "SGNNBench 提出了一个系统性的基准来评估这些受脑启发的网络的基本设计原理在图数据中的有效性。从多个角度，包括效果、能量效率和架构设计，对SGNNs进行深入调查。全面评估了9种最先进的SGNNs在18个数据集中的表现，具体包括模型大小、内存使用和理论能耗的对比，以揭示SGNNs中的常见能源瓶颈，并详细探索了SGNNs的设计空间，促进通用SGNN范式的发展。", "conclusion": "SGNNBench 为SGNNs领域量化了重要的进展，不仅进行了效果上的全面评估，还分析了其能源效率和架构设计，提供了关于如何设计更有效的SGNNs的一些建议和思路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21351", "html_url": "https://arxiv.org/abs/2509.21351", "title": "Random Direct Preference Optimization for Radiography Report Generation", "title_en": "Random Direct Preference Optimization for Radiography Report Generation", "authors": "Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev", "background": "放射影像报告生成（RRG）在医学图像分析领域受到广泛关注，被视为缓解放射科医生日益增长工作量的有前途工具。尽管取得了众多进展，现有的方法尚未满足在临床环境中部署所需的高质量标准。与此同时，大规模视觉语言模型（VLMs）在通用领域内取得了显著进展，通过采用了原本设计用于大规模语言模型（LLMs）的训练策略，如对齐技术。", "innovation": "本论文提出了一种模型无关框架，利用直接偏好优化（DPO）增强RRG的准确性。该方法通过随机对比采样构建训练对，无需奖励模型或人类偏好注释。实验表明，将随机DPO应用到三款最先进的模型中，能提高临床性能指标最多5%，且无需额外的训练数据。", "conclusion": "该方法通过随机对比采样生成训练对，无需额外的数据即可提升RRG的临床性能，实现了精确的模型无关优化。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21355", "html_url": "https://arxiv.org/abs/2509.21355", "title": "基于领域知识的遗传超叠加编程：SFRC梁的案例研究", "title_en": "Domain-Informed Genetic Superposition Programming: A Case Study on SFRC Beams", "authors": "Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi", "background": "本研究提出了一种针对受分离物理机制支配的工程系统进行基因超叠加编程（DIGSP）的方法。通过将输入空间划分为特定领域的特征子集，并通过单独演化基因编程（GP）种群来建模材料特有的效应，该方法致力于提高模型的准确性。此外，研究通过AHSAM机制引入符号抽象，特别是在GP种群停滞时促进种群之间的合作。", "innovation": "- 提出了域知情的遗传超叠加编程（DIGSP）框架，专门针对受分离物理机制支配的工程系统。\n- 引入了自适应分层符号抽象机制（AHSAM），在所有种群停滞时激活，促进符号模型的抽象和融合。\n- 通过ANOVA（方差分析）方法筛选和压缩统计上显著的个体，并通过验证指导的剪枝循环注入所有种群。\n- 在SFRC梁数据集上与多基因遗传编程（BGP）基线进行了比较实验，DIGSP在训练和测试RMSE上均表现出更优的效果。", "conclusion": "研究结果证明，领域内的结构分解和符号抽象机制能够提高模型的收敛性和泛化能力。DIGSP提供了一种基于原理和可解释的方法来构建符号超叠加的工程系统模型。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21327", "html_url": "https://arxiv.org/abs/2509.21327", "title": "评估结合天气和环境变量的深度学习模型在野火蔓延预测中的性能及其对2023年毛伊岛野火的案例研究", "title_en": "Assessment of deep learning models integrated with weather and environmental variables for wildfire spread prediction and a case study of the 2023 Maui fires", "authors": "Jiyeon Kim,Yingjie Hu,Negar Elhami-Khorasani,Kai Sun,Ryan Zhenqi Zhou", "background": "预测野火的蔓延对于有效消防管理和风险评估至关重要。随着人工智能（AI）的快速发展，各种深度学习模型已用于野火蔓延预测。然而，对这些模型的优势和局限性的理解有限，并且不清楚基于深度学习的野火蔓延模型与现有的非AI野火模型之间的比较。这项工作中，作者基于夏威夷十年以上的野火数据，评估了五个典型的结合天气和环境变量的深度学习模型的野火蔓延预测能力，并以2023年毛伊岛野火为案例研究，对比了最佳深度学习模型与广泛应用的野火蔓延模型FARSITE。", "innovation": "作者采用结合解释性AI方法，进一步识别与2023年毛伊岛野火相关的最关键天气和环境因素。这种方法结合了对野火蔓延预测性能的评估和对于关键因子的识别，为野火预测模型的选择和使用提供了新的视角。", "conclusion": "在评估的五种AI模型中，卷积LSTM和带有注意力机制的卷积LSTM表现最佳。FARSITE模型显示更高的精确度、更低的召回率和更高的F1分数，而AI模型提供了更高输入数据的灵活性。通过结合AI模型与解释性AI方法，进一步识别了与2023年毛伊岛野火相关的最重要天气和环境因素。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21339", "html_url": "https://arxiv.org/abs/2509.21339", "title": "使用柯西-施瓦兹偏差的跨模态检索", "title_en": "Cross-Modal Retrieval with Cauchy-Schwarz Divergence", "authors": "Jiahao Zhang,Wenzhe Yin,Shujian Yu", "background": "有效的跨模态检索需要对异构数据类型进行稳健对齐。现有的大多数方法主要集中在双模检索任务上，并且依赖于分布性对齐技术，如Kullback-Leibler（相对）偏差、最大均值差异和相关性对齐。然而，这些方法常常存在一些关键的局限性，包括数值不稳定、对超参数的敏感性以及难以捕捉底层分布的全部结构。", "innovation": "本文引入了柯西-施瓦兹（CS）偏差，这是一种无需超参数的度量，能够提高训练稳定性和检索性能。我们还提出了一种受霍尔德不等式启发的广义CS（GCS）偏差。这种方法通过双向圆周比较方案直接在统一数学框架内对三个或多模态进行对齐，从而消除了需要进行耗时的成对比较的需求。", "conclusion": "我们在六个基准数据集上的大量实验表明，我们的方法在双模和三模检索任务中均有效。我们的CS/GCS偏差的代码已在该网址公开：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21324", "html_url": "https://arxiv.org/abs/2509.21324", "title": "从搜索到推理：企业数据的五级RAG能力框架", "title_en": "From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data", "authors": "Gurbinder Gill,Ritvik Gupta,Denis Lusson,Anand Chandrashekar,Donald Nguyen", "background": "传统上，RAG（检索增强生成）主要集中在基于文本的语义搜索和重新排序上，但这种方法在应对数据总结之外的问题或非文本数据时效果不足。因此，RAG的实现方法与企业用户所需的问答问题之间存在差距。鉴于当前RAG是一系列技术而非具体实现，需要从问题导向的角度来讨论RAG及其相关问答系统。文章提出了一种新的五级分类框架（L1-L5），根据数据模态和底层问答问题的任务复杂性进行分类，并构建了与这些水平对应的基准测试，评估了四个最先进的平台：LangChain、Azure AI Search、OpenAI和Corvic AI。实验表明，多空间检索和动态编排可以促进L1-L4能力。", "innovation": "文章提出了一个五级分类框架（L1-L5），区分了基于无结构数据表面知识（L1）、通过多种数据模态的检索增强生成（L2）、基于多个表示形式的检索增强生成（L3）和反映性和推理知识（L4）的检索增强生成，以及反映性和推理知识（L4）的检索增强生成与通用智能（L5）的概念。并构建了与这些水平对应的基准测试，评估了四个最先进的平台：LangChain、Azure AI Search、OpenAI和Corvic AI。实验强调了多空间检索和动态编排在RAG能力中的价值。", "conclusion": "文章通过实验验证了新的五级分类框架的有效性，并展示了多空间检索和动态编排对于实现L1-L4能力的价值。未来的研究可以进一步探索如何实现L5级别的通用智能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21331", "html_url": "https://arxiv.org/abs/2509.21331", "title": "使用深度分割网络从多源炮检记录中进行地震速度反演：U-Net变体和SeismoLabV3+的基准测试", "title_en": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+", "authors": "Mahedi Hasan", "background": "地震速度反演是地球物理勘探中的关键任务，能够通过地震波数据重建地下结构。它是高质量地震成像和解释的关键。传统基于物理的方法，如全波形反演（FWI），计算需求大、对初始化敏感，并且受到地震数据带宽的限制。最近，深度学习的发展导致了数据驱动的方法，将速度反演视为密集预测任务。该研究使用ThinkOnward 2025 Speed & Structure数据集中的五个通道地震炮检记录和高分辨率速度图，基准测试了三种先进的编码器-解码器架构（U-Net、U-Net++ 和 DeepLabV3+），以及一种针对任务优化的SeismoLabV3+模型（ResNeXt50 32x4d骨干网和特定任务修改）进行地震速度反演。", "innovation": "将深度分割网络应用于地震速度反演，并进行了U-Net及优化后的SeismoLabV3+的基准测试。优化后的SeismoLabV3+模型在内部验证集上的MAPE值为0.03025，在隐藏测试集上的MAPE值为0.031246，证明了此类模型在地震速度反演中的适用性和改进架构的优越性。", "conclusion": "研究表明深度分割网络适用于地震速度反演，并强调了定制化架构改进对推进地球物理AI模型的价值。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22613", "html_url": "https://arxiv.org/abs/2509.22613", "title": "增强学习在语言模型规划中的优势与局限：一个理论视角", "title_en": "Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective", "authors": "Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen", "background": "近年来，强化学习（RL）方法极大地提高了大型语言模型（LLMs）的规划能力，但其有效性背后的理论基础仍不清楚。这项工作中，作者利用可处理的图基抽象来研究RL的优势和局限性，重点关注策略梯度（PG）和Q学习方法。研究表明，有监督微调（SFT）可能会引入基于共现的欺诈性解决方案，而RL主要是通过探索实现正确的规划，突显了探索在促进更好的泛化方面的作用。然而，作者还展示了PG在训练过程中输出多样性崩溃的问题，在达到完美准确度后仍然存在。相比之下，Q学习提供了两条关键优势：离策学习和在收敛时保持多样性。作者还进一步证明了在Q学习中精心设计奖励是必要的，以防止奖励劫持。最后，将该框架应用于现实世界的规划基准Blocksworld，证实了这些行为在实践中确实存在。", "innovation": "作者通过图基抽象来探讨RL的优势和局限性，尤其是重点分析了策略梯度（PG）和Q学习方法。研究揭示了有监督微调（SFT）和RL方法的特点，强调了探索在实现规划的正确性与多样性的平衡中的关键作用。此外，作者还发现了PG在训练中输出多样性崩溃的现象，并展示了Q学习在离策学习和保持多样性方面的优势，同时强调了精心设计奖励的重要性。最后，通过Blocksworld的实际应用，验证了这些理论发现的正确性。", "conclusion": "该研究通过理论分析揭示了RL方法在语言模型规划中的优势与局限性，特别强调了探索的作用，以及精心设计奖励的重要性。作者通过实际应用Blocksworld，证实了这些理论发现的正确性，并为进一步研究提供了指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21357", "html_url": "https://arxiv.org/abs/2509.21357", "title": "有效幻觉检测和分类的新型差异特征学习", "title_en": "A Novel Differential Feature Learning for Effective Hallucination Detection and Classification", "authors": "Wenkai Wang,Vincent Lee,Yizhen Zheng", "background": "大语言模型的幻觉代表了一个关键挑战，其中输出由于训练数据中的分布偏差而偏离事实准确性。尽管最近的研究表明特定的隐藏层显示出幻觉与事实内容之间的差异，但幻觉信号在层内的具体定位仍然不清楚，限制了高效检测方法的发展。", "innovation": "提出了结合了投影融合（PF）块的双模型架构，用于自适应层间特征加权，以及差异特征学习（DFL）机制，通过计算并行编码器之间的差异来识别互补输入下的区分性特征。", "conclusion": "通过在HaluEval的问题回答、对话和摘要数据集上的系统实验，结果表明幻觉信号集中在稀疏的特征子集上，在问题回答和对话任务上实现了显著的准确性提升。分析显示了一种分层的“漏斗模式”，浅层显示高特征多样性，深层表现出集中的使用，使用1%的特征维度就能保持检测性能的小幅下降，表明幻觉信号比之前假设的更加集中，为计算高效的检测系统提供了途径，能够降低推断成本同时保持准确性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21360", "html_url": "https://arxiv.org/abs/2509.21360", "title": "Text-to-Image模型的安全过滤器多模态提示分离攻击", "title_en": "Multimodal Prompt Decoupling Attack on the Safety Filters in Text-to-Image Models", "authors": "Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen", "background": "文本到图像（T2I）模型在生成高质量图像的多个领域得到了广泛应用。然而，这些模型也可能被滥用以生成不适合工作环境（NSFW）的内容，这通常通过监狱突破攻击实现。现有的监狱突破方法主要通过操作文本提示来实现，但对基于图像的输入中的潜在漏洞关注较少。此外，基于文本的方法难以绕过模型的安全过滤器。", "innovation": "本文提出了多模态提示分离攻击（MPDA），通过将危害信息与图像模态分离来实现对原始有害文本提示的攻击。MPDA 进行了三个核心步骤：首先，大型语言模型（LLM）将有害文本提示分离为伪安全提示与有害提示。前者看似无害的子提示可以绕过过滤器，后者含有有害语义的子提示会触发过滤器。随后，LLM 将有害提示重新写成自然对抗提示以绕过安全过滤器，从而引导T2I模型生成NSFW输出。最后，通过视觉语言模型生成图像描述，提供了新的途径来引导LLM在迭代重写和细化生成内容的过程中保持语义一致性。", "conclusion": "本文提出的MPDA通过图像模态分离出有害语义，引导T2I模型生成NSFW影像，克服了现有方法对图像输入潜在漏洞的忽视。此外，通过视觉语言模型生成图像描述，确保了生成内容与原始有害文本的一致性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21341", "html_url": "https://arxiv.org/abs/2509.21341", "title": "从嵌入到方程：用于可解释Transformer分类的遗传编程代数", "title_en": "From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification", "authors": "Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi", "background": "本文研究了冻结Transformer嵌入的符号代理模型，取得了紧凑性、可审计性和概率校准三者的平衡。研究通过分割预训练的现代BERT、DINOv2和SigLIP嵌入来建立分类器，这在五个基准数据集（SST2G, 20NG, MNIST, CIFAR10, MSC17）上进行。嵌入被分为具有信息保留性的独立视角，然后使用一种合作多族群遗传程序MEGP从中学习加性和闭式公式logit程序。通过验证集上的F1分数选择模型，并在测试集上使用温度调整来减少校准误差。结果显示这些代理模型在分类准确性上表现出色，尤其是在MNIST、CIFAR10和MSC17数据集上。", "innovation": "本文提出了一种基于遗传编程的符号代理模型，通过对预训练嵌入进行分割并学习加性和闭式公式logit程序，以实现可持续、可审计、且概率校准的分类器。方法的独特之处在于使用多族群遗传程序MEGP来学习复杂的logit程序，并通过温度调整进一步提高模型的校准性能。", "conclusion": "本文研究发现，生成的符号模型在多个基准数据集上表现出强大的分类性能，尤其是在图像分类任务中表现尤为突出。虽然20NG数据集仍然是最具挑战性的，但通过提供可靠图、维度使用和重叠统计、贡献重要性和全局效应图，研究证明了这些模型在解释性能上的优越性，证明了它们具有明确的程序基础。温度调整在测试集上显著降低了期望校准误差。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21340", "html_url": "https://arxiv.org/abs/2509.21340", "title": "周期即所有你所需要的：更多是不同的", "title_en": "Cycle is All You Need: More Is Different", "authors": "Xin Li", "background": "这篇文章提出了信息拓扑框架，其中周期闭合是记忆和意识的基础机制。传统的观点认为记忆是静态存储，但本文认为记忆是重新进入神经状态空间中的潜藏周期的能力，其不变的周期作为意义的载体，过滤特定于上下文的噪声并保留持久不变的内容。", "innovation": "文章通过周期闭合的概念重新定义了记忆与意识的机制，并引入了点-周期二分法，指出了过渡点支持探索，而非平凡循环编码低熵内容不变量，稳定记忆。文章还介绍了生物上通过延迟锁定放电和STDP实现1-周期，通过theta-γ节律约束边界消解，并通过感知-行动循环引入高阶不变性。文章还通过层叠的微周期组成展示了导航循环扩展到一般记忆和认知的过程，并进一步通过涡流-科斯涡流同构展示了这一过程的正式化。", "conclusion": "文章得出结论，认为在非遍历环境中需要持久不变的特性以实现长远的一致性，并以最低的能量成本进行泛化。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21356", "html_url": "https://arxiv.org/abs/2509.21356", "title": "基于短语的自动生成的胸部X射线报告事实核查", "title_en": "Phrase-grounded Fact-checking for Automatically Generated Chest X-ray Reports", "authors": "Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C.L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood", "background": "随着大型视觉语言模型（VLM）的出现，现在可以为胸部X射线图像生成逼真的医疗报告。然而，由于生成描述中存在的事实错误和幻觉，其临床转化受到了阻碍。本论文探讨了一种新的短语导向的事实核查模型（FC模型），该模型能够检测自动生成的胸部放射学报告中发现及其指示位置中的错误。研究人员通过改变真实报告中的发现和它们的位置来生成大量合成数据集，从而创建实际和虚假的发现-位置对，并基于此数据集训练新的多标签跨模态对比回归网络，以提高寻找真实性和定位的准确性。", "innovation": "研究提出了一种新的短语导向的事实核查模型（FC模型），该模型通过大量合成数据集来检测自动生成的胸部X射线报告中的错误。该模型使用多标签跨模态对比回归网络进行训练，该网络通过修改真实报告中的发现和位置来生成合成数据集，从而创造出实际和虚假的发现-位置对。研究结果表明，该方法在多个X射线数据集上具有高度的鲁棒性，准确性高且定位精确，对于多种报告生成器的有效错误检测结果也得到验证。", "conclusion": "该研究中的方法通过对合成数据集进行训练，有效的检测了自动生成的胸部X射线报告中的错误。该模型达到了与真实验证高一致性的相关系数（0.997），显示出在放射学工作流程中进行临床推理过程中的实用性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21361", "html_url": "https://arxiv.org/abs/2509.21361", "title": "现实世界中LLM有效上下文窗口的上限：你需要的上下文", "title_en": "Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs", "authors": "Norman Paulsen", "background": "大型语言模型（LLM）提供商宣称其最大的上下文窗口大小。然而，这些大小可能与实际应用中的效果不符。为了检验上下文窗口的实际使用效果，作者定义了最大有效上下文窗口的概念，并提出了一种测试方法来评估不同大小和问题类型的上下文窗口效果，同时也提供了一个标准化方法来比较不同大小上下文窗口下的模型效率。研究人员从多个模型中收集了大量数据，发现所报告的最大上下文窗口大小（MCW）与最大有效上下文窗口大小（MECW）之间存在显著差异。MECW不仅与MCW相差甚远，而且基于问题类型而变化。", "innovation": "作者首次定义了最大有效上下文窗口的概念，并提出了一种测试方法来评估不同大小和问题类型的上下文窗口效果。同时，还提供了一个标准化方法来比较不同大小上下文窗口下的模型效率，找到了模型出现失败的临界点。这种方法可以揭示有效上下文窗口与报告的最大上下文窗口之间的差异，并根据不同类型的问题，提供改善模型准确性和降低模型感知幻觉率的明确行动指标。", "conclusion": "实际问题提供的情况会导致最大有效上下文窗口发生变化。研究结果说明，大多数模型在100个或更多上下文令牌时就会表现出严重的准确性下降。即使是最先进的模型在1000个上下文令牌时也会出现较大问题。所有模型在实际的最大上下文窗口大小上相差了近99%。这意味着，最大有效上下文窗口的变化基于提供的问题类型，这为提高模型准确性和减少模型感知幻觉提供明确可行的见解。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21368", "html_url": "https://arxiv.org/abs/2509.21368", "title": "施工场地使用AI进行脚手架安全性评估", "title_en": "Safety Assessment of Scaffolding on Construction Site using AI", "authors": "Sameer Prabhu,Amit Patwardhan,Ramin Karim", "background": "在建筑行业中，安全评估对于确保资产的可靠性和工人的安全至关重要。脚手架作为关键的结构支撑资产，需要定期检查以发现设计规则可能带来的缺陷，以确保其稳定性和完整性。当前，检查主要依赖于视觉检查，由现场经理或认证人员进行，但这种方式耗时且容易出现人为错误，可能导致不安全条件。", "innovation": "本文探讨了利用人工智能（AI）和数字化技术来提高脚手架检查的准确性和施工安全改善。开发了一个基于云的AI平台，用于处理和分析脚手架结构的点云数据。该系统通过将最新的点云数据与标准参考数据进行对比和评估来检测结构修改，从而实现自动监测脚手架，减少手动检查所需的时间和努力，提高施工场地的安全性。", "conclusion": "该研究提出的基于云的AI平台系统通过自动化的检查方法提高了脚手架安全性的监控效率，减少了人为错误，有助于增强施工场地的安全性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21358", "html_url": "https://arxiv.org/abs/2509.21358", "title": "MDF-MLLM: 通过跨模式特征对齐实现深度融合的上下文感知眼底图像分类", "title_en": "MDF-MLLM: Deep Fusion Through Cross-Modal Feature Alignment for Contextually Aware Fundoscopic Image Classification", "authors": "Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen", "background": "现有基于多模态大型语言模型（MLLM）的方法在捕捉对于诊断视网膜疾病（如青光眼、糖尿病视网膜病变和色素性视网膜炎等）至关重要的低级别空间细节方面存在局限性，而本研究旨在通过结合精细的图像特征和全局文本上下文来提高眼底图像的疾病分类准确性，提出了一种新的多模态深度学习架构。", "innovation": "该研究创新性地提出了一种新的多模态深度学习模型（MDF-MLLM），该模型将四层U-Net编码器的跳连特征融合到LLaMA 3.2 11B MLLM的交叉注意力块中，通过缩放的交叉注意力和基于FiLM的U-Net调制融合视觉特征。MDF-MLLM在双类疾病分类任务中的准确率达到了94%，比基线模型提高了56%，尤其对于拥有丰富临床文本的遗传性疾病表现尤为显著，实现了在眼底图像分类中的广泛应用和更好的可解释性与模块化。", "conclusion": "MDF-MLLM 通过多尺度特征融合，提供了一种可移植、可解释和模块化的框架，显著提升了眼底图像分类的准确性和F1分数，能够应用于临床决策支持系统。未来的研究将探索同步训练技术、更多种类疾病的涵盖以及模型功能的扩展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21363", "html_url": "https://arxiv.org/abs/2509.21363", "title": "一种集成多监督信息的相互学习方法用于显著目标检测--修订", "title_en": "A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised", "authors": "Runmin Wu,Mengyang Feng,Wenlong Guan,Dong Wang,Huchuan Lu,Errui Ding", "background": "尽管近年来深度学习技术在显著目标检测方面取得了显著进展，但由于对象内部复杂性和卷积、池化操作引起的边界不准确，预测的显著性图仍然存在不完整的问题。为解决这些问题，本文提出了一种新的训练方法，通过利用显著目标检测、前景轮廓检测和边缘检测的监督信息，使这三个任务相互融合，提高显著性图的均匀性。此外，前景轮廓检测和边缘检测任务还能够互相引导，从而提高前景轮廓预测的精确度，并减少边缘预测时的局部噪声。", "innovation": "本文提出了一种新的相互学习模块（MLM），该模块将网络分支在相互学习的模式下进行训练，提高了性能。这一方法通过紧密结合显著目标检测、前景轮廓检测和边缘检测任务，实现一个完整的显著性图生成过程，从而提高了显著目标检测和边缘检测的效果。", "conclusion": "在七个具有挑战性的数据集上进行的大量实验表明，该方法在显著目标检测和边缘检测中均取得了最先进的结果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21354", "html_url": "https://arxiv.org/abs/2509.21354", "title": "KV-Efficient VLA：一种基于RNN门控分块KV缓存加速视觉语言模型的方法", "title_en": "KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache", "authors": "Wanshun Xu,Long Zhuang", "background": "视觉-语言-动作（VLA）模型旨在实现机器人感知和控制的统一，但其规模受到注意力机制的二次成本限制以及长时序推断过程中关键值（KV）内存的无界增长的约束。尽管近期方法通过扩展骨干网络架构提高了泛化能力，但它们往往忽视了影响实时部署的关键推断效率问题。鉴于此，本文提出了基于KVECient VLA，一种允许不同模型训练的KV内存压缩框架，该框架通过引入一种轻量级、训练友好机制来选择性地保留高实用性的上下文信息，解决了上述限制问题。该方法将KV缓存划分为固定大小的块，并采用递归门控模块根据学习到的实用性分数总结并过滤历史上下文，从而保留最近的详细信息并积极清除过时的、低相关性内存，同时保持因果性。理论分析表明，KVECient VLA相比标准模型可实现高达1.21倍的推理加速和36%的KV内存减少，并且对任务成功率的影响几乎可以忽略不计。这种方法可以直接集成到现有的自回归和混合VLA堆栈中，从而使推理更具可扩展性而不必修改训练流程或控制逻辑", "innovation": "提出了KV-Efficient VLA，一种基于KVECient的视觉-语言-动作模型记忆压缩框架，通过引入一种轻量级的、训练友好的机制来选择性地保留高实用性的上下文信息，将KV缓存划分为固定大小的块，并使用递归门控模块根据学习到的实用性分数来总结并过滤历史上下文，从而保持最近的详细信息并主动清除过时、低相关的内存，同时保持因果性，实现了高达1.21倍的推理速度提升和36%的KV内存减少，对任务成功率的影响几乎可以忽略不计，同时该方法能够在现有视觉-语言-动作模型中无缝集成，实现大规模推理而不必修改训练流程或下游控制逻辑.", "conclusion": "KV-Efficient VLA通过引入一种轻量级的、训练友好的机制，解决了VLA模型中的限制和效率问题，实现了在保持任务成功的同时提升推理速度和减少内存使用，适用于长时序视觉-语言-动作推理，能够无缝集成到现有的视觉-语言-动作模型系统中，实现了可扩展的推理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21365", "html_url": "https://arxiv.org/abs/2509.21365", "title": "MAJORScore: 一种基于联合表征评估多模态相关性的新指标", "title_en": "MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation", "authors": "Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin", "background": "现有的多模态相关性度量通常借助预训练对比学习模型的嵌入能力来处理双模态数据，用于评价跨模态数据（例如CLIP）之间的关联性。然而，常用的评估指标仅适用于两个模态之间的关联分析，这极大地限制了对多模态相似性的评估能力.", "innovation": "本文提出了MAJORScore，这是首次通过多模态联合表征来评估多个模态（N模态，N>=3）之间相关性的新指标。多模态联合表征的能力能够将多种模态整合到同一潜空间中，能够在同一尺度上准确表示不同模态，为公平的相关性评分提供了支持。实验结果表明，在一致模态下MAJORScore提高了26.03%-64.29%，在不一致模态下降低了13.28%-20.54%的性能，相比现有方法具有更可靠的评估多模态相似性和多模态模型性能的能力.", "conclusion": "MAJORScore作为一种可靠的评估多模态相似性的指标，在大规模多模态数据集和多模态模型性能评估中提供更可靠的度量。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21377", "html_url": "https://arxiv.org/abs/2509.21377", "title": "动态多目标融合高效音频视觉导航", "title_en": "Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation", "authors": "Yinfeng Yu,Hailong Zhang,Meiling Zhu", "background": "该论文的背景是，机器人需要通过动态整合车身传感器的视觉观察与目标发出的音频信号来进行声音源定位。目前，先前的工作虽然已经在视觉和音频数据融合方面进行了探索，但往往会忽略更深层次的感知上下文。这使得音频视觉导航的有效利用多模态线索进行导航成为一个核心挑战。", "innovation": "论文提出了Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation (DMTF-AVN) 方法。该方法采用多目标架构并结合改进的Transformer机制来筛选和选择性地融合跨模态信息。实验表明，DMTF-AVN在成功率（SR）、路径效率（SPL）和场景适应性（SNA）方面优于现有方法，展示了强大的可扩展性和通用性。", "conclusion": "模型在Replica和Matterport3D数据集上的广泛实验表明，DMTF-AVN实现了最先进的性能，为机器人多模态融合策略的发展铺平了道路。实验结果和代码可以在提供的链接处获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21359", "html_url": "https://arxiv.org/abs/2509.21359", "title": "基于影响引导的上下文选择以实现有效的检索增强生成", "title_en": "Influence Guided Context Selection for Effective Retrieval-Augmented Generation", "authors": "Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang", "background": "检索增强生成（RAG）通过将响应与外部知识结合来解决大型语言模型（LLM）的 hallucinations 问题，但其有效性受到低质量检索上下文的限制，这些上下文包含无关或噪声信息。虽然现有方法试图通过基于预定义上下文质量评估指标的上下文选择来提高性能，但它们在标准RAG 上的改进有限。这些方法未能全面利用可用信息（查询、上下文列表和生成器）进行综合质量评估是这种局限性的主要原因。", "innovation": "本文受到数据选择领域最新进展的启发，重新概念化了上下文质量评估为推理时的数据价值问题，并引入了上下文影响价值（CI值）。该新颖的度量标准通过测量从列表中移除每个上下文时性能的下降来量化上下文质量，有效地整合了查询感知的相关性、列表感知的独特性和生成器感知的对齐。此外，CI值通过只保留具有正CI值的上下文来消除复杂的选择超参数调优。为了解决标签依赖和计算开销的实际挑战，本文开发了一种参数化代理模型来预测推理时的CI值。该模型采用分层结构，捕获查询-上下文局部相关性和全球上下文交互，通过oracle CI值监督和端到端生成器反馈进行训练。实验结果表明，本文的方法在8个NLP任务和多个LLM上显著优于最先进的基线，有效过滤掉低质量上下文同时保留关键信息。", "conclusion": "本文提出了一种上下文选择方法，通过基于影响的指导显著优于最先进的基线，从而有效地过滤掉低质量的上下文同时保留关键信息。实验结果展示了该方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21367", "html_url": "https://arxiv.org/abs/2509.21367", "title": "为智能旅游客户服务设计和实现增强安全的RAG聊天机器人：针对台湾新竹的提示注入攻击防御案例研究", "title_en": "Design and Implementation of a Secure RAG-Enhanced AI Chatbot for Smart Tourism Customer Service: Defending Against Prompt Injection Attacks -- A Case Study of Hsinchu, Taiwan", "authors": "Yu-Kai Shih,You-Kai Kang", "background": "随着智能旅游的发展，AI聊天机器人已成为向游客提供个性化、实时帮助的不可替代工具，同时促进了可持续性和效率。然而，这些系统越来越容易受到提示注入攻击的影响，攻击者通过操纵输入以引发意外行为，如泄露敏感信息或生成有害内容。研究背景涵盖了当前AI聊天机器人的安全挑战，特别是关于提示注入攻击的安全威胁分析和应对策略需求。", "innovation": "本研究通过设计并实现了一个增强安全的RAG聊天机器人，专门用于新竹的智能旅游服务。系统集成了RAG技术、API调用、多层次语言分析以及防注入防护机制，实现了高度的语境意识和安全性。创新点包括分层响应策略、基于RAG的知识接地以及在词汇、语义和语用层面的意图分解。防御机制包括系统规范、意图判断的门守者以及反向RAG文本，优先验证数据。此外，还对GPT-5变体（2025年8月7日发布）进行了基准测试，评估其固有的鲁棒性。实验结果显示，在有害任务上的准确率超过95%，并对85%的攻击进行了阻止，但仍然表明需要多层次的防御措施。", "conclusion": "研究强调了对可持续旅游、多语言访问性和伦理AI部署的贡献。这项工作提供了一个部署安全聊天机器人的实用框架，并为建立有弹性、可信赖的AI应用做出了贡献。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21387", "html_url": "https://arxiv.org/abs/2509.21387", "title": "稀疏子网络是否表现出认知对齐的注意力？剪枝对注意图保真度、稀疏性和概念一致性的影响", "title_en": "Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence", "authors": "Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi", "background": "以往的研究已经证明，神经网络可以被大量剪枝以保留性能，但剪枝对模型可解释性的影响仍然不清楚。这项工作旨在调查基于幅度的剪枝后微调如何影响低级显著性地图和高级概念表示。", "innovation": "该研究通过使用训练在ImageNette上的ResNet-18，对比了Vanilla Gradients（VG）和Integrated Gradients（IG）的后验解释，评估剪枝水平下的稀疏性和可信度。此外，还应用基于CRAFT的概念提取方法，跟踪在学习概念中所表现出的语义一致性变化。", "conclusion": "结果表明，轻度到中度的剪枝可以提高显著性地图的关注度和可信度，同时保留具有语义意义的概念。相比之下，激进的剪枝会合并异质特征，减少显著性地图的稀疏性和概念一致性，尽管准确性保持不变。这些发现表明，尽管剪枝可以将内部表示导向更符合人类注意力模式的方向，但过度剪枝会削弱模型的可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21394", "html_url": "https://arxiv.org/abs/2509.21394", "title": "大型AI模型支持的生成式语义通信在图像传输中的应用", "title_en": "Large AI Model-Enabled Generative Semantic Communications for Image Transmission", "authors": "Qiyu Ma,Wanli Ni,Zhijin Qin", "background": "近年来生成式人工智能（AI）技术迅速发展，显著提升了语义通信系统内图像传输的效率和准确性。然而，现有方法往往忽视了图像不同区域的重要性差异，可能影响视觉关键内容的重建质量。", "innovation": "本文提出了一种创新型的生成式语义通信系统，通过将图像分割为关键区域与非关键区域来细化语义粒度。关键区域使用图像导向的语义编码器处理，非关键区域通过图像到文本模型进行高效压缩。此外，为应对大型AI模型带来的存储和计算需求，提出的系统采用了量化模型和低秩适应微调的轻量级部署策略，显著提高了资源利用率而不牺牲性能。", "conclusion": "仿真结果表明，所提出的系统在语义保真度和视觉质量方面均优于传统方法，证实了其在图像传输任务中的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21389", "html_url": "https://arxiv.org/abs/2509.21389", "title": "向适应于网络入侵检测的联邦与量子机器学习进发：一项综述", "title_en": "Towards Adapting Federated & Quantum Machine Learning for Network Intrusion Detection: A Survey", "authors": "Devashish Chaudhary,Sutharshan Rajasegarar,Shiva Raj Pokhrel", "background": "该综述研究了联邦学习(FL)与网络入侵检测系统(NIDS)的整合，特别关注深度学习和量子机器学习方法。FL允许分布式设备协作训练模型同时保持数据隐私，这对于网络安全性而言至关重要，因为敏感的流量数据不能集中处理。", "innovation": "综述提供了联邦量子学习(QFL)的前沿探究，讨论了量子特征编码、量子机器学习算法和量子特定聚合方法，这些方法有望为复杂网络流量模式识别提供指数级加速。综合比较了经典和量子方法，识别了研究缺口，并评估了实际部署情况，制定了推动工业采用和技术研究的路线图。", "conclusion": "这份工作为研究人员和实践者提供了权威的参考资料，旨在提高联邦入侵检测系统的隐私性、效率和鲁棒性，同时为未来量子增强的网络安全环境做准备。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21375", "html_url": "https://arxiv.org/abs/2509.21375", "title": "自动文本生成以实现创意和反事实的文本生成图像", "title_en": "Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis", "authors": "Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens", "background": "文本到图像生成技术在大规模多模态训练的支持下取得了快速进展，但细粒度的可控性仍是一个关键挑战。反事实可控性，即有意生成违背常识模式的图像的能力，仍然是一项重大挑战，但对提升创造力和探索性应用起到了至关重要的作用。当前，反事实尺寸控制是一个明显的不足。", "innovation": "提出了一个自动提示工程框架，该框架可以将基础提示调整为生成反事实图像的修订提示。该框架由三个组件组成：图像评估器指导数据集构建，生成修订提示的监督提示重写器，以及通过DPO训练的选择器用于选择最优修订提示。构建了首个反事实尺寸文本图像数据集，并通过改进Grounded SAM，使其比其骨干模型提高了114%的表现。", "conclusion": "实验表明，该方法在最新的基准方法和ChatGPT-4o上表现优异，为未来研究提供了反事实可控性的基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21371", "html_url": "https://arxiv.org/abs/2509.21371", "title": "ReGeS: 反馈式检索-生成协同模型在对话推荐系统中的应用", "title_en": "ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems", "authors": "Dayu Yang,Hui Fang", "background": "对话推荐系统（CRS）要想正确地理解用户偏好，必须将对话与外部领域知识相连接，但现有解决方案存在局限性：要么需要特定领域的工程设计，缺乏灵活性；要么依赖大型语言模型，增加了幻觉的风险。尽管检索增强生成（RAG）取得了希望，但在CRS中的广泛使用受到噪音对话削弱检索和忽视相似物品中细微差别等因素的限制。", "innovation": "提出了一种相互式的检索-生成协同（ReGeS）框架，将生成增强检索与检索增强生成相结合，从对话中提取具有信息性的用户意图，并通过检索增强的生成来区分细微的商品特征。这种协同作用消除了额外注释的需要，减少了幻觉，并简化了持续更新。实验表明ReGeS在多个CRS基准测试中实现了最先进水平的推荐准确度，证明了对于知识密集型的CRS任务，反馈式协同策略的有效性。", "conclusion": "研究表明，ReGeS在对话推荐系统中表现出色，通过检索生成的协同作用有效地提升了推荐准确性，减少了幻觉，增强了系统的灵活性和持续更新能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21423", "html_url": "https://arxiv.org/abs/2509.21423", "title": "线性非高斯循环模型中的近最优实验设计", "title_en": "Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models", "authors": "Ehsan Sharifian,Saber Salehkaleybar,Negar Kiyavash", "background": "近年来的研究表明，仅使用观测数据能够识别因果图，但仅在置换等价类中可识别。本文研究从观测数据和干预数据的结合中学习因果结构的问题，特别是在包含循环的线性非高斯结构方程模型中的情况。", "innovation": "通过展示每个等价类中的图与二分图中的完美匹配相关，提出了一种对图进行分析的方法。证明了每个原子干预可以揭示真实匹配中的一个边，并消除所有不兼容的因果图。通过引入一个自然的奖励函数来形式化优化问题，该函数量化了干预能够消除等价类中多少图。证明这种奖励函数是适应性次模的，并提供了一个具有可证明的近最优性能保证的贪婪策略。还提出了一种基于随机匹配的采样估计器来高效估计奖励函数，并分析了其偏差和收敛性。", "conclusion": "研究结果表明，根据该随机优化框架进行少量干预可以恢复真实的因果结构。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21376", "html_url": "https://arxiv.org/abs/2509.21376", "title": "无标记超分辨光学生物成像的在 silico 深度学习协议：网络架构和信噪比依赖性的比较研究", "title_en": "In silico Deep Learning Protocols for Label-Free Super-Resolution Microscopy: A Comparative Study of Network Architectures and SNR Dependence", "authors": "Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo", "background": "光学显微镜在多个行业和研究领域都有应用，但其空间分辨率受限于大约200纳米。常用的方法或技术如共聚焦扫描头和超分辨率荧光显微镜只能部分解决这一问题，且往往成本高昂或需要专门技能。为了解决这些挑战，研究人员评估了非荧光相位调制显微成像技术，如Zernike相位对比显微术和偏振干涉显微术以实现超分辨率光学显微镜，并利用深度神经网络（DNN）模型提高了图像的超分辨能力。研究以图像的信噪比影响模型性能为视角，展示了不同信噪比环境下O-Net和Theta-Net模型在超分辨率图像处理中的效果差异。", "innovation": "研究创新地利用在 silico 深度学习模型（O-Net 和 Theta-Net）实现了非荧光光学生的纳米级图像超分辨，在不同信噪比条件下展示了模型的互补性。研究通过自定义纳米测试样本和原子力显微镜校准的结果来验证这些模型的有效性。", "conclusion": "在超分辨率成像中，利用深度神经网络模型的效果依赖于网络架构和输入图像的信噪比。高信噪比条件下选择O-Net模型，在低信噪比条件下选择Theta-Net模型可获得高质量的超分辨率图像。这强调了在非荧光光学纳米成像中，模型的超分辨效果与信噪比和网络架构密切相关。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21381", "html_url": "https://arxiv.org/abs/2509.21381", "title": "关于大脑中听觉情感理解的现实编码模型", "title_en": "Toward a Realistic Encoding Model of Auditory Affective Understanding in the Brain", "authors": "Guandong Pan,Yaqian Yang,Shi Chen,Xin Wang,Longzhao Liu,Hongwei Zheng,Shaoting Tang", "background": "在情感神经科学和情感意识AI领域，如何理解复杂的听觉刺激如何驱动情感唤醒动力仍然是一个未解决的问题。本研究引入了一个计算框架，用于建模大脑对天然听觉输入的编码，这些输入在三个数据集中（SEED、LIRIS、自行收集的BAVE）导致动态的行为和神经响应。研究基于神经生物学原理中的并行听觉层次结构，将音频分解为多级听觉特征，从原始的人声和背景音轨元素中隔离出来，并通过跨数据集分析将它们映射到情感相关的反应。研究发现，高阶语义表示（通过wav2vec 2.0/Hubert最终层提取）在情感编码中起主导作用，比低阶声学特征表现出更强的与行为注释和大多数脑区中动态神经同步的映射（p < 0.05）。此外，wav2vec 2.0/Hubert的中间层（平衡声学-语义信息）在大多数数据集中对于情感诱导来说比最终层表现更好。", "innovation": "本研究提出了一种计算框架，通过多级听觉特征的提取和情感响应的映射，揭示了听觉情感编码的层次机制。该模型利用了wav2vec 2.0和Hubert算法，分解了音频为多级听觉特征，并通过跨数据集分析将这些特征映射到情感相关的反应。特别地，研究发现高阶语义特征比低阶声学特征在情感编码中表现更好，而wav2vec 2.0/Hubert中间层在情感诱导方面比最终层表现更好。", "conclusion": "通过结合情感计算和神经科学，这项研究揭示了听觉-情感编码的层次机制，为适应性情感意识系统和跨学科的音频-情感互动研究提供了基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21447", "html_url": "https://arxiv.org/abs/2509.21447", "title": "ARTI-6: 向六维发音语音编码迈进", "title_en": "ARTI-6: Towards Six-dimensional Articulatory Speech Encoding", "authors": "Jihwan Lee,Sean Foley,Thanathai Lertpetchpun,Kevin Huang,Yoonjeong Lee,Tiantian Feng,Louis Goldstein,Dani Byrd,Shrikanth Narayanan", "background": "本文介绍了一种基于实时MRI数据的紧凑六维发音语音编码框架ARTI-6，该框架可以捕捉关键的声带区域，如软腭、舌根和喉部。", "innovation": "ARTI-6 的创新之处在于它由三个组成部分组成：（1）一个六维发音特征集，代表声带的关键区域；（2）一个发音倒控制模型，通过语音基础模型预测发音特征，预测相关性达到0.87；（3）一个发音合成模型，直接从发音特征重建可理解的语音，即使低维表示也可以生成自然声音。因此，ARTI-6 提供了一个可解释、计算效率高且基于生理学的框架，用于推进发音倒控制、合成以及更广泛的语音技术应用。", "conclusion": "ARTI-6 为发音语音编码的发展提供了一个可解释性、计算效率高且基于生理学的框架，同时开源了源代码和语音样本。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21404", "html_url": "https://arxiv.org/abs/2509.21404", "title": "大型语言模型需要象征意义", "title_en": "How Large Language Models Need Symbolism", "authors": "Xiaotie Deng,Hanyu Li", "background": "本文认为，人工智能的未来不仅仅是扩大规模，而是需要通过引入人类创造的符号来指引其强大的但盲目直观的推理能力，以解锁真正的发现。背景信息暗示，在当前的AI发展过程中，虽然取得了显著进展，但现有技术也存在局限性，特别是在引导AI实现创造性和发现性的能力方面还不足。\n", "innovation": "本文提出了一种新的观点——大型语言模型需要一种‘指南针’，即人类创造的符号，来引导它们的强大的但缺乏指导的直觉。\n", "conclusion": "结论指出，如果不引入人类创造的符号，大型语言模型将无法实现真正的发现和突破性的创新。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21379", "html_url": "https://arxiv.org/abs/2509.21379", "title": "SAEmnesia：使用稀疏自编码器在扩散模型中擦除概念", "title_en": "SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders", "authors": "Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto", "background": "在文本到图像的扩散模型中，有效地遗忘概念需要精确识别模型潜空间中的概念表示。虽然稀疏自编码器可以减少神经元的多义性（即一个神经元包含多个概念），但单个概念的表示仍然可能分散在多个潜特征中，这需要大量的搜索程序来完成概念的遗忘。既有方法需要进行广泛的特征搜索，增加了遗忘概念的难度和复杂性。因此，研究一种高效且精准的概念遗忘方法是必要的。", "innovation": "SAEmnesia 引入了一种受监督的稀疏自编码器训练方法，通过系统的概念标签促进概念-神经元的一对一映射，有效减少了特征分割，提高了特征集中度。这种方法学会的概念特异性神经元与无监督基准相比具有显著增强的概念关联。唯一增加的计算开销是训练期间的交叉熵计算。在推断时间，这种方法具有可解释的表示，将当前方法的超参数搜索减少了96.67%。SAEmnesia 在 UnlearnCanvas 基准测试中实现了最先进的表现，比最先进的方法提高了9.22%。在序列遗忘任务中，SAEmnesia 在9个对象去除任务中，错误率减少了28.4%。", "conclusion": "SAEmnesia 提供了一种新的方法来高效地在扩散模型中遗忘概念，通过精确的特征中心化和概念-神经元的一对一映射，显著减少了遗忘概念的复杂性。这种方法大大降低了遗忘精度搜索，展示了在序列遗忘任务中的优越性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21391", "html_url": "https://arxiv.org/abs/2509.21391", "title": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering", "title_en": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering", "authors": "Lihui Liu,Carl J. Yang", "background": "大语言模型（LLMs）在多种应用中表现出色，但在知识密集型领域常出现幻觉现象，这是因为它们依靠静态预训练语料库。为解决这一问题，检索增强生成（RAG）通过在推理过程中整合外部知识源来提升LLMs。这些知识源中，文本图提供了结构化和语义丰富信息，能够支持更精确和可解释的推理。尽管如此，大多数现有方法依赖单一检索器来识别相关子图，这限制了它们捕捉复杂查询多方面的能力。此外，这些系统往往难以准确判断检索内容的相关性，容易受到无关噪声的干扰。", "innovation": "本文提出了一种MIXRAG（Mixture-of-Experts Graph-RAG）框架，这是一种专家混合的图检索增强生成系统。它引入了多个专门针对图语义特定方面的图检索器和一个动态路由控制器，以更好地处理多样化的查询意图。每个检索器被训练以专注于图语义的一个特定方面，如实体、关系或子图拓扑。Mixture-of-Experts模块会根据不同输入查询，自动选择并融合相关的检索器。为减少检索信息中的噪声，引入了一个查询感知的GraphEncoder，它仔细分析检索到的子图中的关系，突出显示最相关部分并降低不必要的噪声。", "conclusion": "实验结果表明，我们的方法达到了最先进的性能，并且在不同领域多种图基任务上均超过了各种基线。MIXRAG在图文本理解和问答任务上都是有效的。论文被接受后，代码将公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21424", "html_url": "https://arxiv.org/abs/2509.21424", "title": "PhenoMoler：通过化学大型语言模型实现表型导向的分子优化", "title_en": "PhenoMoler: Phenotype-Guided Molecular Optimization via Chemistry Large Language Model", "authors": "Ran Song,Hui Liu", "background": "当前的分子生成模型主要集中在提高药物与靶标之间的结合亲和力和特异性上，而常常忽视了化合物在系统层面所引发的表型效应。转录组作为药物诱导的表型变化的分子读出，提供了指导以表型意识为导向的分子设计的强有力机会。PhenoMoler将化学大型语言模型与表达谱结合起来，实现生物信息驱动的药物设计，通过条件化生成依赖于药物诱导的差异表达特征，PhenoMoler明确地将转录响应与化学结构联系起来。", "innovation": "PhenoMoler是一个表型引导的分子生成框架，它结合了化学大型语言模型和表达谱，使分子设计更具生物信息学指导性。PhenoMoler特有的方法包括通过特定亚结构的蒙版和重构，支持精细的、可控的分子优化。生成的化合物不仅化学上有效、新颖、多样，而且与期望的表型模式高度匹配。与FDA批准的药物相比，生成的化合物在药物 likeness（QED）、优化的物理化学性质以及对重要癌症靶标的结合亲和力方面表现出相似或改进的效果。这些结果突显了PhenoMoler在表型导向和结构可控的分子优化方面的潜力。", "conclusion": "PhenoMoler能够生成化学有效的新颖多样分子，这些分子与目标表型特征高度一致。相比现有的FDA批准的药物，生成的化合物在药物 likeness、体物化学性质和关键癌症靶点的结合亲和力方面具有竞争力甚至更优。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21434", "html_url": "https://arxiv.org/abs/2509.21434", "title": "高能物理中的基础模型", "title_en": "Foundation models for high-energy physics", "authors": "Anna Hallin", "background": "随着大型预训练机器学习模型的应用，这些模型能够针对各种任务进行微调，因此在自然语言处理和计算机视觉领域取得了革命性的进展。在高能物理领域，专家们越来越关注这些模型是否可以直接应用于物理研究，甚至根据粒子物理学数据进行从头构建和定制，以更好地适应特定需求。这一审查是该领域首个关于基础模型的研究综述文章，总结了截至目前已发表的相关研究并进行了讨论。", "innovation": "本文是高能物理领域首个关于基础模型的综述，对已发表的相关研究进行了总结和讨论，为今后的研究提供了参考框架。", "conclusion": "从自然语言处理和计算机视觉领域的角度来看，基础模型已经带来了显著的进展。在高能物理领域，基础模型的应用 初期阶段已经引起广泛关注，并期待未来能够在粒子物理学数据上得到进一步的应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21433", "html_url": "https://arxiv.org/abs/2509.21433", "title": "DyME：通过两层正交LoRA适应动态多概念消除在扩散模型中的应用", "title_en": "DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation", "authors": "Jiaqi Liu,Lan Zhang,Xiaoyong Yuan", "background": "文本到图像的扩散模型(DMs)无意中重现了受版权保护的风格和保护的视觉概念，引发了法律和伦理方面的担忧。概念擦除作为一种保护手段，通过微调来选择性地抑制这些概念。然而，现有方法在实际应用中无法满足多个和可能相互冲突的概念擦除需求，其核心瓶颈在于静态擦除的设计：一个检查点被微调以删除所有目标概念，而不管推理过程中的实际擦除需求。这种刚性设计与实际使用情况不匹配，导致擦除效果下降和非目标内容保真度降低。因此，为了更好地适应实际需求，本研究提出了DyME（动态多概念擦除框架），该框架通过训练轻量级的概念特定LoRA适配器并在推理时动态组合，实现了灵活的概念擦除，但朴素的组合会在适配器之间产生干扰，尤其是在需要抑制多个或语义相关概念时。为了克服这一问题，提出了在特征和参数层面都具有两层正交约束，以隔离表示变化和确保正交适配器子空间。同时，还开发了一个新的分层基准ErasureBench-H，用于在语义粒度和擦除集合大小方面进行原则性评估。实验结果表明，DyME在多个概念擦除保真度方面优于最先进的基线方法，同时保持了最小的附带损害。", "innovation": "提出了DyME（动态多概念擦除框架），该框架通过训练轻量级、概念特定的LoRA适配器并在推理时动态组合，实现了灵活的概念擦除。此外，还引入了在特征和参数层面的两层正交性约束，以避免适配器之间的干扰。进一步开发了一个新的分层基准ErasureBench-H，用于评估语义层次和擦除集合大大小小的多概念擦除效果。", "conclusion": "实验结果表明，DyME在多概念擦除保真度方面优于当前最先进的基线方法，同时保持了最小的附带损害。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21443", "html_url": "https://arxiv.org/abs/2509.21443", "title": "单一模型，多种道德判断：探究计算道德推理中的跨语言偏差", "title_en": "One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning", "authors": "Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens", "background": "大型语言模型（LLMs）在多语言和多文化环境中被广泛应用，特别是在生成合乎伦理的响应方面需要道德推理能力。然而，LLMs 主要以英语数据进行预训练，这引发了对其在不同语言和文化背景下的判断能力能否泛化的担忧。本文系统地研究语言如何影响LLMs的道德决策。通过将两个道德推理基准翻译成五种不同语言，实现多语言零样本评估。研究发现，LLMs在不同语言中的道德判断存在显著不一致，反映出文化偏移的问题。", "innovation": "本文创新性地将两个道德推理基准翻译成五种文化及类型上都多样的语言，以实现多语言零样本评估。通过精心设计的研究问题，揭示了LLMs道德判断差异背后的驱动因素，从不同文化的分歧到LLMs采用的推理策略，并通过案例研究探讨了预训练数据如何塑造LLMs的道德指南针。进一步总结了道德推理错误的结构化类型，强调了需要更加文化意识的AI.", "conclusion": "本文揭示了计算道德推理中跨语言的偏差，并总结了错误的类型，强调了提高AI文化意识的必要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21459", "html_url": "https://arxiv.org/abs/2509.21459", "title": "使用RLVR的顶尖SQL推理解模", "title_en": "A State-of-the-Art SQL Reasoning Model using RLVR", "authors": "Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang", "background": "通过强化学习（RL）开发可以根据组织特定知识进行推理的定制模型，有望解决企业客户的诸多问题。很多问题中，奖励函数可验证，这一设置被称为奖励可验证的RL（RLVR）。RLVR被应用于评估AI代理将自然语言查询转化为数据库SQL执行的性能的基准测试——BIRD。BIRD测试了AI代理的SQL推理能力，这在企业数据科学、商业智能和编码领域都非常实用。", "innovation": "该研究通过精心挑选提示和模型，并结合脱机RL方法TAO与严格的在线RLVR训练，成功应用于BIRD基准测试，达到业界领先的成绩：在没有额外训练数据和不使用私有模型的情况下，首次提交即达到73.56%的准确率（在不使用自一致性的情况下）和75.68%（在使用自一致性的情况下），同时所需生成次数也比第二优策略更少。", "conclusion": "虽然BIRD仅作为代理任务，但该框架的简单性使其在企业领域如商务智能、数据科学和编码有着广泛的应用前景。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21463", "html_url": "https://arxiv.org/abs/2509.21463", "title": "增强生成式机器听觉者", "title_en": "Enhanced Generative Machine Listener", "authors": "Vishnu Raj,Gouthaman KV,Shiv Gehlot,Lars Villemoes,Arijit Biswas", "background": "该论文介绍了GMLv2模型，这是一种基于参考的模型，专门用于预测以MUSHRA分数衡量的主观音频质量。GMLv2模型通过采用基于Beta分布的损失模型来预测听众评分，并引入了额外的神经音频编码（NAC）的主观数据集以增强其泛化能力和适用性。广泛的研究表明，与广泛使用的指标（如PEAQ和ViSQOL）相比，GMLv2在相关性和准确预测主观评分方面表现更优，尤其是在不同内容类型和编码配置下。因此，GMLv2提供了一种可扩展且自动化的音频感知质量评估框架，有望加速现代音频编码技术的研究与发展。", "innovation": "GMLv2模型通过引入基于Beta分布的损失来预测听众评分，并加入了额外的神经音频编码（NAC）的主观数据集来增强其泛化能力和适用性。广泛的评估显示，GMLv2在相关性和预测准确性方面优于广泛使用的PEAQ和ViSQOL指标。", "conclusion": "GMLv2提供了一种可扩展且自动化的音频感知质量评估框架，加速了现代音频编码技术的研究与发展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21473", "html_url": "https://arxiv.org/abs/2509.21473", "title": "幻觉是糟糕的估计吗？", "title_en": "Are Hallucinations Bad Estimations?", "authors": "Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu", "background": "本文将生成模型中的幻觉定义为未能将估计值链接到任何合理的因果关系而产生的误报。在这一背景下，作者展示了即使是损失最小的最优估计器也会产生幻觉。研究还提供了一个适用于通用数据分布的高概率幻觉率下界，强调了损失最小化与人类可接受输出之间的结构错位，导致由校准不准确引发的估计误差。", "innovation": "本文提出了一种新的视角，即将幻觉视为损失最小化与人类可接受输出之间的结构错位。研究确认了即使在最优估计器中也存在幻觉现象，这为理解生成模型中的幻觉提供了一个新的理论框架。通过实验证明了该理论在硬币聚合、开放式问答和文本转图像等多个任务中的适用性。", "conclusion": "研究重新定义了幻觉的含义，即损失最小化与人类可接受的输出之间存在结构偏差，这种偏差是由校准不准确引致的估计误差。这一研究通过数学证明和实证验证，为研究生成模型中的幻觉现象提供了重要理论支持。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21522", "html_url": "https://arxiv.org/abs/2509.21522", "title": "Shortcut Flow Matching for Speech Enhancement: 一步训练的不变步骤流动匹配", "title_en": "Shortcut Flow Matching for Speech Enhancement: Step-Invariant flows via single stage training", "authors": "Naisong Zhou,Saisamarth Rajesh Phaye,Milos Cernak,Tijana Stojkovic,Andy Pearce,Andrea Cavallaro,Andy Harper", "background": "基于扩散的生成模型在语音增强（SE）的感知质量方面取得了最先进的性能。然而，它们的迭代性质需要大量的神经函数评估（NFEs），这给实时应用带来了挑战。相比之下，流动匹配提供了一种更高效的替代方案，通过学习直接的向量场，可以使用确定性常微分方程（ODE）求解器在几步内产生高质量的合成结果。因此，我们提出了用于语音增强的Shortcut Flow Matching (SFMSE)，一种新颖的方法来训练单个、不变的模型。", "innovation": "SFMSE 通过在单阶段训练过程中将速度场条件化在目标时间步骤上，可以在不进行任何架构更改或微调的情况下执行单步、几步或多步去噪。实验结果表明，SFMSE 单步推理在消费者 GPU 上的实时因子（RTF）为 0.013，同时提供与需要 60 个 NFEs 的强大扩散基线相当的感知质量。这项工作还提供了在训练和推理中随机性的实证分析，弥合了高质量生成 SE 和低延迟约束之间的差距。", "conclusion": "SFMSE 方法提供了一种解决方案，可以在保证高质量感知效果的前提下，显著提高实时性，同时简化了模型的推理流程，并提供了对随机性作用的理解。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21466", "html_url": "https://arxiv.org/abs/2509.21466", "title": "沙特专业领域中的性别刻板印象：基于语言模型生成图像的分析研究", "title_en": "Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models", "authors": "Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa", "background": "本文研究了当代文本生成图像的人工智能（AI）模型在为沙特阿拉伯的56种不同专业生成图像时，是否延续性别刻板印象和文化不准确。研究使用了ImageFX、DALL-E V3 和 Grok 三种模型生成的1,006张图像，并由训练有素的沙特标注者对每张图像的五维度内容（性别感知、服装与外貌、背景与设置、活动与互动、年龄）进行了评估。这些研究揭示了性别不平衡的问题，DALL-E V3 展现了最强的性别刻板印象，尤其是在领军人物和技术角色中。此外，三种模型都表现出文化不准确的问题。结论指出，当前模型反映了其训练数据中嵌入的社会偏见，仅有限反映了沙特劳动力市场的性别动态和文化特征。", "innovation": "该研究创新之处在于利用语言模型生成的图像来评估图像生成模型如何在性别和文化方面体现刻板印象。两种训练有素的沙特标注者进行了多维度评估，研究设计详细并采用了严格的评估流程，包括第三方研究者的仲裁，确保了研究的严谨性和准确性。", "conclusion": "研究发现当前AI模型基于训练数据中嵌入的社会偏见，生成的图像未能真实反映沙特社会的性别动态和文化特征。研究结论强调了需要更多样化的训练数据、更公平的算法以及文化敏感的评价框架，以确保生成的图像更公平、更具真实性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21502", "html_url": "https://arxiv.org/abs/2509.21502", "title": "在最优运输方向的新算法进展及其在产品空间中的应用", "title_en": "New Algorithmic Directions in Optimal Transport and Applications for Product Spaces", "authors": "Salman Beigi,Omid Etesami,Mohammad Mahmoody,Amir Najafi", "background": "研究了高维空间中两个分布μ和ν之间的最优传输，目标是在多项式时间内找到一个近似的y，使得给定x~μ时，y~ν。重点在于传输时间依赖于维度而非完整表示大小，解决实际算法中的高维度问题。", "innovation": "提出了一种通用算法，可将任何产品分布μ传输到任何ν，传输成本为Δ+δ，其中Δ是Knothe-Rosenblatt传输成本，δ是随运行时间减少的计算误差。引入了ν“可序列采样”的新但自然的概念，证明了算法版本的Talagrand的不等式，构建了在测量为ε的集合S上的顺序采样器，并给出了从标准正态分布到条件正态分布的传输算法，预期平方距离为O(log 1/ε)，适用于一般ε的S。", "conclusion": "获得了第一个计算性的集中结果（基于欧氏距离的高斯测度计算集中的第一个结果），解决了Etesami等人提出的公开问题：对于任何Gaussian测度为ε的集合S，大多数样本可以映射到S内距离为O(√log 1/ε)的时间复杂度为多项式的poly(n/ε)的时间内。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21528", "html_url": "https://arxiv.org/abs/2509.21528", "title": "通过潜在可达性进行预发检测与引导的大语言模型 misalignment", "title_en": "Preemptive Detection and Steering of LLM Misalignment via Latent Reachability", "authors": "Sathwik Karnik,Somil Bansal", "background": "大型语言模型（LLMs）现在在日常工具中无处不在，引发了对其生成有害内容的倾向的紧急安全关切。现有的安全方法——强化学习从人类反馈（RLHF）——在训练期间有效塑造模型行为，但在推理阶段没有任何保障，仍然可能产生不安全的续写。", "innovation": "提出了一种名为 BRT-Align 的可达性基于框架，将控制论安全工具应用于 LLM 推理。BRT-Align 将自回归生成视为潜在空间中的动力系统，并通过向后可达性学习安全性价值函数，估算轨迹最坏情况的演变。这种机制包括两个互补机制：一是运行时监控，可以提前多个标记预测不安全的续写；二是最小限制引导过滤，最小限度地扰动潜在状态以引导生成远离不安全区域。实验表明，BRT-Align 在多个 LLM 和毒性基准上的表现优于基线，能够更准确、更早地检测到不安全的续写，并显著减少了不安全的生成，同时保持句子的多样性和连贯性。", "conclusion": "这些发现表明，可达性分析为推理时的大语言模型安全性提供了一个有原则且实际的基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21482", "html_url": "https://arxiv.org/abs/2509.21482", "title": "使用混合令牌学习推理", "title_en": "Learning to Reason with Mixture of Tokens", "authors": "Adit Jain,Brendan Rappazzo", "background": "强化学习中的可验证奖励（RLVR）已成为提升大型语言模型（LLM）推理能力的主要方法。当前大多数方法采用了分组相对策略优化的变体，通过采样多种推理完成结果，相对评分并调整策略。然而，这些方法在每次推理步骤中都只会采样离散的标记，这抛弃了模型在候选标记概率分布中丰富的分布性信息。尽管在非RL设置中保留和利用这种分布性信息已被证明是有益的，但当前的RLVR方法似乎不合理地限制了推理搜索空间，因为它们没有利用这种分布性信息。为了应对这一限制，我们研究了在RLVR中使用令牌混合生成（MoT-G）的方法。我们提出了一种统一的框架，该框架既涵盖了现有的令牌混合生成方法，也扩展了RLVR，使其可以直接在连续的混合空间生成思路链。", "innovation": "我们研究了在RLVR中使用令牌混合生成（MoT-G）的方法，并提出了一种统一的框架，既能概括现有方法，又能将其扩展到连续的混合空间，以生成思考链。我们评估了两种MoT-G变体在Reasoning-Gym上的表现，这是一个包含多个推理密集语言任务的套件，发现MoT-G方法在7个出10个任务中的表现较标准解码方法提高了5%至35%，同时以一半的轨迹数量达到了相似的准确性，表明提高了训练效率。通过全面的隐藏状态和令牌级分析，我们提供了证据，表明MoT-G的好处可能源于其在整个推理过程中保持更高的隐藏状态熵的能力以及在令牌空间中促进探索。", "conclusion": "MoT-G方法在增强大型语言模型推理能力上展现出显著优势，提高了训练效率的同时保持了更好的推理准确性和探索性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21470", "html_url": "https://arxiv.org/abs/2509.21470", "title": "基于得分的扩散模型同胚模型提炼", "title_en": "Score-based Idempotent Distillation of Diffusion Models", "authors": "Shehtab Zaman,Chengyan Liu,Kenneth Chiu", "background": "生成模型领域，基于同胚映射到目标流形的同胚生成网络（IGNs）是新兴的模型。IGNs支持单步或多步生成，提供在计算成本和样本质量之间灵活的权衡。然而，IGNs类似于生成对抗网络（GANs），需要对抗性训练并且容易出现训练不稳定性和模态崩溃。扩散和得分模型成为生成建模的受欢迎方法，通过逐步运输样本从一个分布（通常是高斯分布）到目标数据分布。虽然这些模型具有稳定训练动力学和高保真生成质量，但它们的成本非常高，因为数据必须在整个轨迹中逐步运输。新的采样方法、模型提炼和一致性模型已被开发以减少采样成本并甚至从扩散模型中进行一次性采样。", "innovation": "本文将扩散模型和IGNs整合，通过从扩散模型得分提炼同胚模型，称为SIGN（Score-based Idempotent Generative Networks）。本文提出的方法高度稳定，无需对抗性损失。本文为提出的基于得分的训练方法提供了理论分析，并从先验训练的扩散模型中有效提炼IGNs，使SIGNs的推断速度比迭代得分模型更快。SIGNs允许用户在质量和效率之间进行权衡。这些模型可以直接在源领域上操作；它们可以将受损或替代分布投影回目标流形，使输入的零样本编辑成为可能。在各种图像数据集上验证了该模型，SIGNs在CIFAR和CelebA数据集上实现了同胚模型的最先进结果。", "conclusion": "本文提出了一种新的方法——SIGN，通过从扩散模型得分中提炼IGNs，这种方法高度稳定且不需要对抗性损失。从先验训练的扩散模型中提炼IGNs使SIGNs具有更快的推断速度。SIGNs在多步采样中表现出色，能够在质量和效率之间进行权衡。SIGNs可以直接处理源领域中的输入，能够将受损或替代分布投影回目标流形，实现零样本编辑。在CIFAR和CelebA数据集上实现了最先进的结果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21554", "html_url": "https://arxiv.org/abs/2509.21554", "title": "非洲口音英语的领域感知说话人聚类", "title_en": "Domain-Aware Speaker Diarization On African-Accented English", "authors": "Chibuzor Okocha,Kelechi Ezema,Christan Grant", "background": "研究探讨了非洲口音英语在说话人聚类中的领域效应，评估了多种生产系统和开源系统的性能，特别是在临床对话场景下的表现。", "innovation": "文章为跨领域的基准测试提供了控制条件，提出了分解错误和会话级分析的简洁方法，并提供了一个易于再现的领域适应配方。结果显示领域适应可以减少错误，但并没有完全消除性能差异。", "conclusion": "研究指出了在对话中注意重叠分割和平衡临床资源的实用性建议。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21485", "html_url": "https://arxiv.org/abs/2509.21485", "title": "用于地下储层系统瞬态流体流动数学建模的神经算子", "title_en": "Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems", "authors": "Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov", "background": "地下储层系统是复杂的动态对象，由分布参数描述，常通过偏微分方程（PDEs）系统来描述。传统的数值方法虽然精度高，但在计算上耗费大量时间，这限制了它们在控制和决策支持问题中的应用。", "innovation": "提出了基于Fourier神经算子架构（TFNO-opt）的方法，它可以近似无穷维函数空间中的偏微分方程解，保持对离散化的不变性和向各种方程实现的一般化能力。其中包括可调内时间分辨率的积分Fourier算子、谱域参数的张量分解、使用Sobolev范数作为误差函数以及分离近似误差和重建初始条件以更准确地再现物理过程的修正方法。这些改进的有效性通过计算实验得以证实。", "conclusion": "计算实验显示，与传统方法相比，新方法在地下气库水动力建模问题上实现了计算速度六数量级的加速。这为复杂储层系统的有效控制开辟了新的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21487", "html_url": "https://arxiv.org/abs/2509.21487", "title": "双头推理蒸馏：仅训练时推理的分类器准确率提升", "title_en": "Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning", "authors": "Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan", "background": "Chain-of-Thought (CoT) prompting 虽然可以提高分类准确率，但在生成推理过程中带来显著的吞吐量惩罚。Wei et al. (2022) 和 Cheng and Van Durme (2024) 的研究均显示了这一点。因此，该研究的目标是找到一种平衡精度与吞吐量的方法。", "innovation": "研究提出了一种简单的训练方法——Dual-Head Reasoning Distillation (DHRD)，该方法适合于仅编码器的语言模型。DHRD 引入了两个新的组件：(i) 在训练和推理过程中使用的聚合分类头；(ii) 仅在训练过程中由教师推理监督的推理头。使用了一个损失函数，该函数是标签交叉熵和输入加上推理序列的标记级语言模型损失的加权和。该方法在七个 SuperGLUE 任务上取得了优于聚合基线的相对提升，尤其是在蕴含和因果任务上表现更佳。由于推理头在测试时不启用，因此推断吞吐量与聚合分类器相匹配，并且在相同的模型架构上比 CoT 编码快96-142倍的查询每秒 (QPS)。", "conclusion": "DHRD 通过在训练过程中使用推理来改善分类器的准确性，同时确保推理不在测试时使用，从而在保持吞吐量的同时提高了分类精度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21565", "html_url": "https://arxiv.org/abs/2509.21565", "title": "无需对齐即可生成：在扩散模型中学习线性可分表示", "title_en": "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models", "authors": "Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya", "background": "近年来，大规模扩散模型的高效训练策略强调了改进这些模型的鉴别特征表示的重要性。在这一方向上，使用强大外部编码器获得的特征进行表示对齐的工作，能够通过线性探测提高表示质量。但是，基于对齐的方式依赖于大型预训练编码器，这在计算上很昂贵。", "innovation": "本文提出了一种替代正则化方法，基于促进中间层表示的线性可分性（LSEP）。LSEP消除了辅助编码器和表示对齐的需求，同时将线性探测直接纳入网络的学习动态中，而不是将其视为简单的后处理评估工具。该方法在基于流的变压器架构如SiTs上显示出显著的训练效率和生成质量提高，FID值为1.46。", "conclusion": "本文提出了一种替代性正则化方法，即LSEP，通过促进扩散模型中中间层表征的线性可分性。这种方法提高了大型扩散模型的训练效率和生成质量，特别在基于流的变压器模型上显示出显著效果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21500", "html_url": "https://arxiv.org/abs/2509.21500", "title": "追求顶尖表现：基于评分标准的有效奖励建模以提升大型语言模型", "title_en": "Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training", "authors": "Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin", "background": "强化学习微调（RFT）常常受到过度优化奖励信号的问题困扰，模型通过操纵奖励信号以获得高分，但却产生低质量的输出。理论分析显示，问题的关键在于高分区间的奖励标定不准确：难以可靠地区分优秀的回应与杰出的回应。因此需要关注高分区间，但该区间的样例在基础的大规模语言模型（LLM）中稀缺。虽然可以从更强的模型或重写中获取离线策略示例，但直接使用这些示例进行训练会导致对目标政策的奖励标定不准确。文章研究了基于评分标准的奖励建模，这种设计可以利用离线策略示例同时不受其瑕疵的影响。文章强调区分优秀和多样化回应的必要性，并提出了一套实施这一想法的工作流来为高分区间生成评分标准。", "innovation": "文章提出的基于评分标准的奖励建模方法能够利用离线策略示例，同时避免它们的瑕疵影响。通过定义区分优秀和多样化回应的评分标准，可以有效地减少奖励过度优化问题，并提升大语言模型的训练效果。这种方法能够在高评分区域生成有效的奖励模型，从而改善模型的输出质量。", "conclusion": "文章通过实验证明，基于评分标准的奖励模型能够显著减轻奖励过度优化问题，并实现大语言模型的有效训练后改进。提供的代码可以在指定的网址访问。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21573", "html_url": "https://arxiv.org/abs/2509.21573", "title": "通过在半变异图上发现硬负例增强对比学习以改进地理定位", "title_en": "Enhancing Contrastive Learning for Geolocalization by Discovering Hard Negatives on Semivariograms", "authors": "Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner", "background": "在全球范围内实现准确且稳健的基于图像的地理定位具有挑战性，这是因为存在多种环境、视觉模糊的场景以及许多地区缺乏独特的地标。虽然对比学习方法通过在街景图像与其对应位置之间对齐特征显示出了有希望的性能，但这些方法忽视了地理空间中的潜在空间依赖性。因此，这些方法未能解决假阴性问题，即视觉上和地理位置上相似但被标记为负例的图像对，同时难以区分那些视觉上相似但地理位置上相距较远的困难负例。", "innovation": "我们提出了一种新的空间规整的对比学习策略，该策略集成了一种半变异图，这是一种地质统计工具，用于建模空间相关性随距离的变化。通过将图像在特征空间中的距离与地理距离相关联，我们可以捕捉到在特定空间距离下的期望视觉内容，来定义给定空间距离的期望视觉差异作为基准，来识别困难负例和假负例。我们将这种方法集成到GeoCLIP中，并在OSV5M数据集上进行了评估，证明了明确建模空间先验可以改善基于图像的地理定位性能，特别是在更精细的粒度上。", "conclusion": "该方法通过在半变异图上建模空间依赖性，促进了在局部和半局部尺度上实现地理定位的精确和稳健性，乃至在无显著地理特征的图像中也表现出了一致的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21513", "html_url": "https://arxiv.org/abs/2509.21513", "title": "DistillKac：通过阻尼波动方程实现几步图像生成", "title_en": "DistillKac: Few-Step Image Generation via Damped Wave Equations", "authors": "Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon", "background": "这篇论文旨在介绍一种基于阻尼波动方程和方程的随机Kac表示的快速图像生成方法——DistillKac。与扩散模型相比，扩散模型的反向时间速度可能会变得僵硬并允许无限传播速度，而Kac动力学则确保有限速度传输，从而产生全球受限制的动能。基于此结构，该研究引入了一种仅在终点处进行蒸馏的方法，这种方法训练学生模型在较长的时间区间内匹配冻结的教师模型。论文证明了稳定性结果，表明在路径末点的监督可以促进路径全程的接近性。实验结果表明，DistillKac能够在非常少的函数求值下生成高质量的样本，同时保留了有限速度概率流的数值稳定性优势。", "innovation": "1. 利用阻尼波动方程和随机Kac表示生成快速图像的方法，解决传统扩散模型中速度可能变得僵硬的问题，确保传播速度有限并具有全局受限制的动能。\n2. 通过仅在终点处蒸馏，提出了一种新颖的学习方法，即训练学生模型在长时间区间内匹配冻结的教师模型。\n3. 提出了稳定性分析结果，表明在路径未端的监督可以促进路径全程的接近性，从而提高了生成图像的质量和一致性。", "conclusion": "DistillKac通过阻尼波动方程实现了高性能的图像生成，仅通过计算终点的样本信息来进行蒸馏，不需要大量前向传播计算，同时结合稳定性分析方法，保证了生成图像质量的同时维持了数值稳定性的优势。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21519", "html_url": "https://arxiv.org/abs/2509.21519", "title": "Li_2: 一个特征涌现和延迟泛化的动态框架", "title_en": "$\\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization", "authors": "Yuandong Tian", "background": "虽然有关“grokking”现象的研究已经非常广泛，但仍然不清楚是否存在数学框架来描述所出现的特征类型、何时以及在何种条件下从训练中发生这种情况，特别是对于复杂的结构化输入而言。本研究旨在探讨这一点，并提出一个新的框架Li_2，该框架捕捉了2层非线性网络grokking行为的三个关键阶段：一是懒惰学习，二是独立特征学习，三是交互特征学习，这些特征的进化由各层反向传播梯度的结构决定。", "innovation": "本研究提出了一种新的框架Li_2，能够描述2层非线性网络的grokking行为的三个关键阶段：(I) 懒惰学习，(II) 独立特征学习，(III) 交互特征学习。在这些阶段中，通过分析梯度结构，探讨了特征学习的动态过程，并揭示了关键超参数（如权重衰减、学习率和样本大小）在grokking中的作用，揭示了最近的优化器（如Muon）为何在原理层面上有效的原因。此外，研究还探索了这些局部最优解引出的特征是否可泛化，特征表示能力，以及在样本数量变化时这些特征如何变化。", "conclusion": "研究揭示了关于特征涌现和延迟泛化的关键作用机制，为理解这些现象提供了基础，提出了能够证明记忆和泛化缩放法则的数学框架，并揭示了当前优化器有效的原因。这些分析可以拓展到多层架构。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21595", "html_url": "https://arxiv.org/abs/2509.21595", "title": "时空对比：DINOv3和V-JEPA2特征表示在视频动作分析中的比较", "title_en": "Temporal vs. Spatial: Comparing DINOv3 and V-JEPA2 Feature Representations for Video Action Analysis", "authors": "Sai Varun Kodathala,Rakesh Vunnam", "background": "本文比较了两种自监督学习的视频动作识别架构：DINOv3和V-JEPA2。DINOv3通过独立处理帧并提取空间特征来进行操作，而V-JEPA2则通过跨视频序列的联合时间建模来工作。研究在UCF Sports数据集上评估了这两种方法，通过分类准确性、聚类性能、类内一致性和类间区分度等多维度来检查特征质量。研究表明，这些架构在性能和鲁棒性方面存在根本性差异。", "innovation": "研究通过全面比较两种架构的性能，揭示了它们在视频分析系统中的设计选择，并提供了基于任务要求和可靠性约束的特征提取方法的选择指导。具体来说，研究发现DINOv3在静态姿势识别方面表现出色，但对依赖于动作的识别性能较差，而V-JEPA2的时间建模能够提供跨不同动作类别的平衡表示质。", "conclusion": "研究表明，DINOv3特别适用于识别可识别姿势的动作，具有出色的分开比（6.16倍），但在依赖于动作的动作上的表现较差。V-JEPA2在所有动作类型中表现出一致的可靠性，具有显著较低的性能差异。这些发现拓展了我们对视频分析系统中架构设计选择的理解，并提供了实际的指导建议，以选择适合特定任务需求和可靠性约束的特征提取方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21629", "html_url": "https://arxiv.org/abs/2509.21629", "title": "InvBench: LLMs能否通过不变量合成加速程序验证?", "title_en": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?", "authors": "Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken", "background": "程序验证依赖于循环不变量，但自动发现强大的不变量仍然是一个长期存在的挑战。本文介绍了一个基于验证器的决策过程框架，用于评估大型语言模型在不变量合成中的表现。该框架不仅评估正确性，还评估不变量在验证过程中的加速效果。", "innovation": "提出了一个评估大型语言模型在不变量合成中的框架，该框架使用基于验证器的决策过程，并具有形式化的声音保证。评估了7个最先进的大型语言模型及其基于大型语言模型的验证器与传统求解器UAutomizer的性能。展示了监督微调和Best-of-N采样能够提升性能，这证明了模型能力的重要性。", "conclusion": "尽管基于大型语言模型的验证器具有一些前景，但它们尚未表现出对UAutomizer的显著优势。模型的能力起着关键作用，不同的模型在加速效果上存在显著差异，暗示更多的研究挑战。监督微调和Best-of-N采样能够提升性能，表现最好的模型在某些方面获得了显着提升。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21535", "html_url": "https://arxiv.org/abs/2509.21535", "title": "Agribot: 农业专用问答系统", "title_en": "Agribot: agriculture-specific question answer system", "authors": "Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari", "background": "印度是一个农业依赖型经济，准确的农业实践信息对于实现农业最大化增长和产量至关重要。为了帮助农民解答相关问题，研究者基于Kisan呼叫中心的数据构建了一款农业聊天机器人。该系统能够提供关于天气、市场价格、植保措施和政府方案的查询，24小时不间断服务，可以在任何电子设备上访问，并且提供的信息易于理解。因此，该系统有助于农民获得农业相关信息，从而提高农业产量。同时，这也为呼叫中心员工减轻了日常工作压力，使他们的工作方向更加积极和有效", "innovation": "该农业聊天机器人主要基于句子嵌入模型。经过消除同义词并结合实体提取后，准确率大幅提升至86%。这不仅提高了系统回答农业相关查询的能力，还改善了信息服务的质量和可用性", "conclusion": "通过提供易于理解的农业相关信息，该系统帮助农民实现农业实践的信息获取更加便捷，从而提高农业产量。此外，该系统减轻了呼叫中心员工的工作负担，并将他们转移到更有成效的工作目标上。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21617", "html_url": "https://arxiv.org/abs/2509.21617", "title": "LANCE: 低秩激活压缩技术在边缘设备高效持续学习中的应用", "title_en": "LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning", "authors": "Marco Paul E. Apolinario,Kaushik Roy", "background": "在资源受限的环境中，本地学习对于个性化、隐私保护和长期适应是必不可少的。实现这一点需要高效的学习，包括对现有模型进行微调和不断学习新任务，同时防止灾难性遗忘。然而，这两个过程都受到存储反向传播期间的激活的记忆成本高的限制。现有方法通过低秩分解来压缩激活，但这种方法需要频繁地进行低秩分解，增加了计算开销。此外，这些方法尚未专门用于持续学习场景。", "innovation": "提出的LANCE（低秩激活压缩）框架通过一次性进行高阶奇异值分解（SVD），获得可重复使用的低秩子空间来压缩激活投影。这避免了多次进行低秩分解，从而减少内存和计算成本。固定的低秩子空间还使得任务可以在不存储特定于任务的大矩阵的情况下，分配到正交子空间上，进一步支持边缘设备上的持续学习。", "conclusion": "实验表明，LANCE可以将激活存储减少高达250倍，同时在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上保持与全反向传播相当的准确性。在持续学习基准测试中，LANCE在较低的内存成本下达到了与正交梯度投影方法相当的性能。因此，LANCE定位为在边缘设备上进行高效微调和持续学习的实用且可扩展的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21663", "html_url": "https://arxiv.org/abs/2509.21663", "title": "逻辑假设：从零到全知的神经符号集成", "title_en": "Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration", "authors": "Davide Bizzaro,Alessandro Daniele", "background": "神经符号集成（NeSy）结合了神经网络学习与符号推理。该领域的研究方法可以分为两大类：一类是将手动生成的规则注入到神经模型中，另一类是从数据中诱导出符号规则。论文介绍了一种新型语言——假设逻辑（LoH），这种语言能够灵活地将基于数据的学习规则与符号先验以及专家知识结合在一起。", "innovation": "LoH 扩展了命题逻辑语法，引入了一个能够选择多个选项中的一个子公式的可学习参数的选择操作符。通过模糊逻辑，LoH 中的公式可以直接编译为可微计算图，从而可以通过反向传播学习最优选择。这一框架不仅涵盖了现有的部分 NeSy 模型，还增加了知识指定程度的任意性。使用哥德尔模糊逻辑和近期开发的哥德尔技巧，LoH 可以将模型离散化为布尔函数而不会损失性能。", "conclusion": "论文在表格数据和视觉井字游戏中开展了实验分析，展示了 LoH 在模型上的强大表现，生成了可解释的决策规则。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21592", "html_url": "https://arxiv.org/abs/2509.21592", "title": "接下来会发生什么？通过生成点轨迹来预测未来的运动", "title_en": "What Happens Next? Anticipating Future Motion by Generating Point Trajectories", "authors": "Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi", "background": "本文讨论了仅从单张图像预测物体运动的问题，即在不能观测到物体速度或其他参数的情况下，预测物体在未来可能的运动轨迹。当前方法大多数基于视频生成模型的回归器或生成器，但这些方法难以从单张图像预测运动，即使是在简单的物理场景中，如掉落的物体或机械物体内在相互作用。", "innovation": "本文将此任务形式化为通过与现代视频生成模型具有相似架构的模型生成密集轨迹网格的任务，但输出的是运动轨迹而非像素。这种方法能够捕捉到场景范围内的动力学和不确定性，生成比先前方法更准确和多样化的预测结果。", "conclusion": "本文在模拟数据上广泛评估了方法的有效性，在机器人等下游应用中也展示了其效果，并在真实世界的直观物理数据集上展示了令人鼓舞的准确性。研究还表明，即使经过此类数据的精细调整，最先进的视频生成模型也难以预测仅从单张图像开始的运动，强调了生成像素相对于直接建模运动的局限性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21613", "html_url": "https://arxiv.org/abs/2509.21613", "title": "大型语言模型优化中的多目标强化学习：前瞻视角", "title_en": "Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective", "authors": "Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers", "background": "多目标强化学习（MORL）对于优化大型语言模型（LLMs）中的多个目标提出了显著的挑战和机遇。研究了不同MORL方法在应用于LLM优化时的优势和局限性，指出需要高效的、灵活的方法来适应LLM和强化学习（RL）固有的个性化功能和复杂性。明确了不同方法对多元目标关系影响的MORL基准测试框架的需求，为衡量不同方法的效果提供了一个评估平台，开拓了未来的研究方向，聚焦于可以通过多层次学习范式提高效率和灵活性的元策略 MORL 的发展，揭示了关键的研究问题和潜在解决方案，以提高LLM的性能.", "innovation": "提出了一个多目标强化学习基准测试框架，解决了不同方法对多元化目标关系的影响，提出了元策略MORL的发展方向，通过多层次学习范式提高效率和灵活性，指出了增强LLM性能的关键研究问题和潜在解决方案.", "conclusion": "研究提出了围绕LLM优化的MORL方法应用的视角和需求，发展了元策略MORL，提供了一个评估不同方法对LLM优化效果的框架，提出了提高LLM性能的关键问题和潜在解决方案."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21542", "html_url": "https://arxiv.org/abs/2509.21542", "title": "人类与代理人间互动相比于人与人之间互动的心理和行为反应：一项系统综述和元分析", "title_en": "Psychological and behavioural responses in human-agent vs. human-human interactions: a systematic review and meta-analysis", "authors": "Jianan Zhou,Fleur Corbett,Joori Byun,Talya Porat,Nejra van Zalk", "background": "智能互动代理正在社会中得到整合。尽管这些代理已展现出类人的能力，但人类对这些代理的反应仍研究不足，且跨学科研究支离破碎。本研究综合分析了匹配的人类-代理互动与人类-人类互动的心理和行为反应，对162篇符合条件的研究（146篇参与到元分析中；共计468个效应值）进行了系统回顾和元分析，结合了经典统计和贝叶斯方法。结果显示，人们在与代理互动时表现出更少的亲社会行为和道德参与度，也赋予代理更低的生物属性和责任，认为代理不如人类能干、友善且存在感差。然而，在社交对齐、与伙伴的信任、个人能动性、任务完成情况和互动体验方面，两者的表现大致相当。许多主观反应（如对伙伴的社会感知、主观信任和互动体验）的效应值存在较大的异质性，表明伙伴效应在不同情境下的依赖性很高。通过研究各项研究的特征、参与者、伙伴、互动场景和反应量表，我们还确定了几个影响伙伴效应的调节因子。总体而言，代理的实用功能行为和互动体验可以与人类相似，然而在基本的社会归因和道德/亲社会考量上存在滞后。因此，代理的实用价值可与人类相媲美，但缺乏相当的内在价值，从而为代理的设计和监管提供了实际意义。", "innovation": "首次系统地综合分析了人类-代理互动和人类-人类互动的心理和行为反应，结合了经典的统计方法和贝叶斯方法进行元分析，探讨了心理和行为的差异，以及这些差异背后的原因，填补了跨学科研究的空白。", "conclusion": "在与代理互动时，人们虽然在功能性行为和互动体验上与与人类互动相似，但在基本的社会归因和道德/亲社会考量上滞后。代理在实用价值上与人类相当，但在内在价值上则远逊一筹。这为智能代理的设计与规范提供了重要启示。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21623", "html_url": "https://arxiv.org/abs/2509.21623", "title": "OjaKV: 基于Oja规则的上下文感知在线低秩KV缓存压缩", "title_en": "OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule", "authors": "Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen", "background": "大型语言模型的长上下文能力受到关键价值（KV）缓存这一显著内存瓶颈的制约。KV缓存是自回归生成所必需的，但其要求较大内存，例如，Llama-3.1-8B模型处理32K标记提示时，4批次大小所需的KV缓存约为16GB，这超出了模型权重的大小。尽管可以通过低秩投影压缩KV缓存是一条有前景的方向，但现有方法依赖于静态的、离线学习的子空间，在数据分布变化时表现不佳。OjaKV框架通过引入战略混合存储策略与在线子空间适应，解决了这些局限性。", "innovation": "OjaKV框架通过识别哪些tokens是压缩的关键，保留关键的第一个和最后的tokens，以及通过逐步适应投影基底来应用低秩压缩的方法，解决了内存瓶颈问题。这种方法在预填充提示时进行全面更新，并在解码期间进行轻量级的周期性更新，以保持子空间与上下文的同步。实验结果显示，OjaKV在高压缩比的情况下能保持甚至提高零样本准确性。这一方法适用于现代注意力模块，如FlashAttention。", "conclusion": "OjaKV框架作为一种实用的、即插即用的解决方案，可以在不需要模型微调的情况下，实现内存高效的长上下文推断，特别在需要复杂推理的非常长的上下文基准测试中表现出色，突出了在线子空间适应的重要性，以动态跟踪上下文变化。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21712", "html_url": "https://arxiv.org/abs/2509.21712", "title": "不是我的代理，不是我的边界？AI代理信息共享中的个人隐私边界", "title_en": "Not My Agent, Not My Boundary? Elicitation of Personal Privacy Boundaries in AI-Delegated Information Sharing", "authors": "Bingcan Guo,Eryue Xu,Zhiping Zhang,Tianshi Li", "background": "理解个体的隐私披露行为需要超越一般规范，因为隐私决策依赖于情境，涉及复杂的权衡。传统的隐私边界获取方法难以应对这些具体情况，因此需要一种新的方法来探查个人隐私边界。", "innovation": "提出了一个基于AI的隐私边界探查方法，通过区分任务来了解个体内在的隐私边界。该方法通过更改通信角色和授权条件进行了系统性研究，收集了来自169名参与者的1,681个边界规范，分析了情境因素和个人差异如何影响边界规范。", "conclusion": "研究结果强调，在实际数据流中定位隐私偏好获取的重要性。同时，提出将细腻的隐私边界作为未来AI系统的对齐目标。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21625", "html_url": "https://arxiv.org/abs/2509.21625", "title": "使用音频语言模型指导音频编辑", "title_en": "Guiding Audio Editing with Audio Language Model", "authors": "Zitong Lan,Yiduo Hao,Mingmin Zhao", "background": "音频编辑在VR/AR沉浸式体验、虚拟会议、音效设计以及其他互动媒体中扮演着关键角色。然而，现有的生成式音频编辑模型依赖于模板式的指令格式，只能处理单声道音频。这些模型无法处理声明式的音频编辑，即用户声明所需结果的概述而把编辑的具体操作留给系统执行。本文分析了这些现有的问题，为开发更灵活的音频编辑方法提供了背景信息。", "innovation": "本文提出了SmartDJ，这是一种结合了音频语言模型的推理能力和潜在扩散模型的生成性力量的新框架，用于双声道音频编辑。该框架能够将高层次指令分解为诸如添加、删除或重新定位事件等原子编辑操作序列，并通过训练有素的扩散模型来执行这些操作。为此，设计了一个数据合成管道，生成涵盖高层次指令、原子编辑操作及其前后音频的配对示例，以支持这一过程。实验结果表明，与之前的音频编辑方法相比，SmartDJ在感知质量、空间现实性和语义对齐方面表现更优。", "conclusion": "实验表明，与之前的音频编辑方法相比，SmartDJ在感知质量、空间现实性和语义对齐方面表现出更高的性能。智能的编辑操作能够保留音频的语义信息，确保音频的编辑前后保持连贯性和相关性，从而展示了一种新的音频编辑方法的可能性。相关演示可在[这个链接](this https URL)获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21628", "html_url": "https://arxiv.org/abs/2509.21628", "title": "基于集成表示度量的数据驱动视觉模型分类", "title_en": "A Data-driven Typology of Vision Models from Integrated Representational Metrics", "authors": "Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla", "background": "大型视觉模型在架构和训练范式上存在广泛差异，但缺乏系统性方法来确定它们表示哪些方面是跨家庭共享的，哪些反映了独特的计算策略。作者利用一系列表示相似性度量工具，评估家庭差异，发现几何和单元调谐在家庭中具有特定标识，而线性可解编码信息则更广泛共享。为了整合这些互补方面，作者改进了灵感源自多组学整合的相似性网络融合（SNF）方法，显示出比单一指标更显著的家庭分离效果，并产生稳健的综合特征。", "innovation": "开发了基于多表示相似性度量的集成方法来评估视觉模型的表示差异，并改进了相似性网络融合（SNF），该方法能够更精确地区分不同模型家族，产生稳健的综合特征。该研究为视觉模型提供了数据驱动的分类框架，揭示了由架构和训练目标共同塑造的新兴计算策略对表示结构的影响超越了表面设计类别。", "conclusion": "该研究通过集成表示相似性度量发现了视觉模型中的特定标识特征，几何和单元调谐具有家庭专属特征，而线性可解编码信息更广泛共享。改进的相似性网络融合（SNF）方法能够更准确地鉴别不同模型家族，并产生稳健的综合特征，该数据驱动框架提供了视觉模型的原理分类。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21713", "html_url": "https://arxiv.org/abs/2509.21713", "title": "开发增强人工智能教育容量的策略", "title_en": "Developing Strategies to Increase Capacity in AI Education", "authors": "Noah Q. Cowit,Sri Yash Tadimalla,Stephanie T. Jones,Mary Lou Maher,Tracy Camp,Enrico Pontelli", "background": "当前，许多机构在面对人工智能(AI)日益增长的需求和重要性时，都在努力进行教学。为此，计算研究协会(CRA)组织了32场由202位致力于改进AI教育的专家主持的网络圆桌讨论会。这些讨论会分为四个焦点领域：AI知识领域和教学方法、AI教育中的基础设施挑战、增加AI教育容量的策略以及面向所有人的AI教育。", "innovation": "识别了扩大AI教育容量的高需求点，包括显著的数字鸿沟带来的基础设施障碍，尤其是对小型和资源不足的机构，以及师资力量、计算基础设施和技术支持的不足。提出了解决这些问题的关键策略，包括提供易获取、持续的在职培训，以帮助教师了解AI及其伦理维度。同时，还整理了一份专家在研究过程中提到的资源列表，希望为机构提供一个可以通用的AI教育资源库。", "conclusion": "虽然存在许多基础设施和师资力量挑战，但通过实施具体的解决方案，如提供持续的教师培训和支持，以及建立一个集中的人工智能教育资源库，可以在增加AI教育容量方面取得显著进展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21634", "html_url": "https://arxiv.org/abs/2509.21634", "title": "MobiLLM：六代开放无线接入网中的闭环威胁缓解智能代理AI框架", "title_en": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs", "authors": "Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin", "background": "Open Radio Access Network（O-RAN）是一种开放且可互操作的架构，加速了向六代网络（6G）的演进，能够使智能和模块化的应用程序跨公共电信和私人企业领域运行。尽管开放性带来了前所未有的创新机会，但也增加了攻击面的风险，因此亟需具备高弹性、低成本且自治性的安全解决方案。现有的防御措施主要是反应性的、劳动密集型且无法应对下一代系统规模和复杂性的需求。当前的O-RAN应用主要关注网络优化或被动威胁检测，缺乏闭环自动化响应的能力。", "innovation": "本文介绍了一种基于智能代理（agent-based）的人工智能框架MobiLLM，用于在6G O-RAN环境中的完全自动化和端到端的威胁缓解。MobiLLM通过由大型语言模型（LLMs）驱动的模块化多智能体系统来协调安全工作流程，具备威胁分析、威胁分类和威胁响应三大功能。该框架基于MITREFiGHT框架和3GPP规范，配备了强大的安全防护措施，为可信的人工智能驱动网络安全性提供了蓝图。初步评估结果证明，MobiLLM能够有效识别和协调复杂的缓解策略，显著降低响应延迟，展示了自治安全操作在6G中的可行性。", "conclusion": "MobiLLM为O-RAN环境中的闭环威胁缓解提供了一个可靠的智能代理AI框架，通过多种智能体和大型语言模型的协调工作，有效提高了威胁应对的效率和自动化水平，突显了自主安全操作在6G中的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21654", "html_url": "https://arxiv.org/abs/2509.21654", "title": "安全、可信的人工通用智能的局限性", "title_en": "Limitations on Safe, Trusted, Artificial General Intelligence", "authors": "Rina Panigrahy,Vatsal Sharan", "background": "人工智能（AI）系统中的安全、信任和人工通用智能（AGI）是理想的追求目标，但这些概念有不同的非正式解释。这篇文章旨在提出严密的、数学化的定义，并揭示这些定义之间的基本不兼容性。文中定义了安全、信任和AGI的具体含义，认为安全是系统从不做出错误声明的属性，信任是在此基础上的假设，而AGI是人工智能系统一直匹配或超越人类能力的属性。文章展示了这些概念之间的矛盾，并证明了符合严格定义的、安全和值得信赖的AI系统不可能是强大的AGI系统，因为存在一些人类可以轻松处理且可证明地解决的问题，而系统却无法解决这些任务。", "innovation": "提出了严格的、数学化的定义来描述安全、信任和AGI，揭示了这些概念之间的基本不兼容性，并通过对比哥德尔不完备定理和图灵对停机问题不可判定性的证明，展示了这些概念在编程验证、规划和图可达性中的局限性。", "conclusion": "最终结论是，在严格的数学定义下，安全和值得信赖的AI系统不能是强大的AGI。虽然在实际部署中可以采用其他实用的解释方式，但上述理论证明在程序验证、规划、图可达性等多个领域内揭示了这些概念之间的内在局限性。这一发现为理解和设计AI系统的边界提供了新的理论依据。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21735", "html_url": "https://arxiv.org/abs/2509.21735", "title": "利用基于SDE的空间-时间图深度学习揭示纵向脑网络中的阿尔茨海默病进展情况", "title_en": "Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks", "authors": "Houliang Zhou,Rong Zhou,Yangying Liu,Kanhao Zhao,Li Shen,Brian Y. Chen,Yu Zhang,Lifang He,Alzheimer's Disease Neuroimaging Initiative", "background": "识别客观的神经影像学生物标志物以预测阿尔茨海默病(AD)的进展情况对于及时干预至关重要。然而，这一任务仍极具挑战，因为这涉及到对潜在脑网络在时空特性方面的复杂功能障碍，而现有方法往往忽视了这一点。", "innovation": "我们开发了一种可解释的空间-时间图神经网络框架，利用双正态差异方程（SDEs）来预测未来AD的进展情况，以应对数据采样不规则的纵向功能磁共振成像(fMRI)数据问题。该框架能够学习稀疏的区域和连接的重要性概率，从而能够识别与疾病进展相关的关键脑回路异常。", "conclusion": "我们的研究结果强调了基于空间-时间图的深度学习方法在纵向成像数据中进行不规则采样时，可以为早期和个体化的AD进展预测提供可能。此外，我们的可解释性策略揭示了既有的和新的神经系统水平及性别特异性生物标志物，为阿尔茨海默病进展中的神经生物学机制提供了新的见解。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21733", "html_url": "https://arxiv.org/abs/2509.21733", "title": "UISim：动态移动环境中的互动基于图像的UI模拟器", "title_en": "UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments", "authors": "Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen", "background": "开发和测试用户界面（UI）及训练AI代理与之交互是具有挑战性的，因为现实世界中的移动环境是动态多变的。现有的方法往往依赖于繁琐的物理设备或屏幕截图的有限静态分析，这阻碍了测试的可扩展性和智能UI代理的开发。", "innovation": "介绍了UISim，一种基于图像的新颖UI模拟器，它提供了一个纯粹从屏幕图像探索移动电话环境的动态且互动的平台。系统采用两阶段方法，在给定初始屏幕图像和用户动作后，首先预测下一UI状态的抽象布局，然后基于该预测布局合成一个新的视觉一致图像。这种方法使得UI过渡的现实模拟成为可能。UISim为UI测试、快速原型设计和合成数据生成提供了即时的实践益处，其互动能力还为高级应用如AI代理的UI导航任务规划开辟了途径。", "conclusion": "实验结果显示，UISim在生成现实且连贯的后续UI状态方面优于端到端的UI生成基准，突显了其真实性和对简化UI开发和提升AI代理训练的潜在影响。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21674", "html_url": "https://arxiv.org/abs/2509.21674", "title": "QueryGym: 逐步与关系数据库交互", "title_en": "QueryGym: Step-by-Step Interaction with Relational Databases", "authors": "Haritha Ananthakrishanan,Harsha Kokel,Kelsey Sikes,Debarun Bhattacharjya,Michael Katz,Shirin Sohrabi,Kavitha Srinivas", "background": "现有的框架常将代理绑定到特定的查询语言方言或模糊其推理过程；而QueryGym则要求代理构建明确的关系代数操作序列，确保跨引擎的评估和透明的逐步规划。它提供了一种Gymnasium接口来执行环境中的动作，并接收表示数据库探索（例如，预览表、采样列值、检索唯一值）和关系代数操作（例如，筛选、投影、连接）的行为。", "innovation": "QueryGym提供了交互式环境来构建、测试和评估基于LLM的查询规划代理，确保跨引擎评估和透明的逐步规划，同时提供数据库探索和关系代数操作的能力。", "conclusion": "QueryGym为研究错误纠正、透明性和查询生成的强化学习提供了一个实际的试验场。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21738", "html_url": "https://arxiv.org/abs/2509.21738", "title": "LFA-Net: 一种基于LiteFusion注意力机制的轻量级视网膜血管分割网络", "title_en": "LFA-Net: A Lightweight Network with LiteFusion Attention for Retinal Vessel Segmentation", "authors": "Mehwish Mehmood,Ivor Spence,Muhammad Fahim", "background": "轻量级视网膜血管分割对于早期诊断威胁视力和全身疾病的检查至关重要，尤其是在计算资源有限的实际临床环境中。虽然基于深度学习的分割方法在不断进步，但现有模型仍然面临小血管分割和高计算成本的挑战。", "innovation": "提出了一个新的血管分割网络LFA-Net，该网络结合了新的设计注意力模块LiteFusion-Attention。该注意力模块包含残差学习连接、Vision Mamba启发的动力学和基于调制的注意力机制，可以使模型有效地以轻量级方式捕获局部和全局上下文。LFA-Net具有高性能，参数量仅为0.11百万，内存大小为0.42 MB，计算量为4.46 GFLOPs，非常适合资源受限的环境。", "conclusion": "通过在DRIVE，STARE和CHASE_DB上进行验证，LFA-Net在Dice分数和Jaccard指数方面表现出色，分别为83.28%，87.44%，84.50%，72.85%，79.31%和74.70%。LFA-Net的代码已在线提供。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21673", "html_url": "https://arxiv.org/abs/2509.21673", "title": "SlotFM: 具有时频槽注意力的运动基础模型以应对多样化下游任务", "title_en": "SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks", "authors": "Junyong Park,Oron Levy,Rebecca Adaimi,Asaf Liberman,Gierad Laput,Abdelkareem Bedri", "background": "可穿戴加速度计被广泛应用于手势识别、步态分析和运动监控等领域。然而，目前大多数现有的基础模型主要集中在分类日常活动（如行走和锻炼）上，这限制了其在依赖其他信号特征的更广泛任务中的应用范围。因此，该研究旨在提出一种适用于多种下游任务的加速度计基础模型——SlotFM。SlotFM结合了时频槽注意力，它可以生成多个小型嵌入（槽），每个槽都捕捉信号的不同组成部分，使任务特定的头部能够专注于数据中最相关的部分。", "innovation": "SlotFM 使用了一种扩展自槽注意力（Slot Attention）的时频槽注意力方法，该方法可以处理原始信号的时间和频率表示，并生成多个小型嵌入，每个嵌入捕捉信号的不同组成部分。通过提供两种损失正则化器来捕捉局部结构和频率模式，提高了对细微细节的重建能力，并帮助嵌入保留任务相关信息。与现有的半监督方法相比，该模型在16项分类和回归下游任务中表现优越，特别是在13项任务上表现优于现有方法，其余任务的表现也达到了最佳方法的水平。平均而言，我们的方法在这些任务上的性能提高了4.5%，证明了一种很强的泛化能力，适用于传感基础模型。", "conclusion": "SlotFM 模型成功展示了在多种下游任务上的优越性能，并且在传感基础模型的泛化能力方面取得了显著进步。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21746", "html_url": "https://arxiv.org/abs/2509.21746", "title": "HyperCore: 基于超球体模型在噪声环境下的数据子集选择", "title_en": "HyperCore: Coreset Selection under Noise via Hypersphere Models", "authors": "Brian B. Moser,Arundhati S. Shanbhag,Tobias C. Nauen,Stanislav Frolov,Federico Raue,Joachim Folz,Andreas Dengel", "background": "现有的数据子集选择方法旨在高效训练模型，但通常忽视了标注错误的可能性，且需要固定的剪枝比例，这在实际应用场景中并不实用。因此，需要一种能够适应噪声环境且不依赖于超参数调整的子集选择框架。", "innovation": "HyperCore 是一种鲁棒且适应性强的数据子集选择框架，专门针对噪声环境。它利用每类的轻量级超球体模型，将同类样本靠近超球体中心，并根据距离自然地将跨类样本分离。通过使用约登指数，HyperCore 可以自适应地选择剪枝阈值，从而自动进行噪声感知的数据剪枝。", "conclusion": "实验表明，HyperCore 在噪声和低数据情景下显著优于现有最先进的数据子集选择方法，能够有效丢弃误标和模糊点，生成紧凑但极具信息量的子集，适用于大规模且无噪声的学习场景。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21670", "html_url": "https://arxiv.org/abs/2509.21670", "title": "MORPH: 通用偏微分方程基础模型", "title_en": "MORPH: Shape-agnostic PDE Foundation Models", "authors": "Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence", "background": "论文背景介绍了MORPH模型，这是一种形状无关、自回归的基础模型，适用于偏微分方程（PDEs）。MORPH模型采用了卷积视觉变换器作为基础框架，能够无缝处理从1D到3D，不同分辨率、多样数据维度及多种物理场（包括标量和向量场）的时空异质数据集。论文详细介绍了模型的架构，包括成分卷积、跨场交叉注意力及轴向注意力等组成部分，并介绍了模型在多种不同类型PDE数据集上的预训练结果以及在下游预测任务上的表现。", "innovation": "MORPH模型的核心创新在于其架构设计，具体来说，包括：(i)成分卷积，能够同时处理标量和向量通道，捕捉局部交互效果；(ii)跨场交叉注意力，用于建模和选择性地传播不同物理场之间的信息；(iii)轴向注意，通过轴向分解时空注意机制，减少计算负担同时保持表征能力。此外，该模型在预训练阶段使用了参数效率低秩适配器（LoRA）进行微调，展示了比从零开始训练的模型在零样本和全样本泛化中的优越性能。论文还指出，MORPH模型在广泛的评估中能够匹配或超越最先进的基线和模型。", "conclusion": "通过MORPH模型，研究提出了一个灵活且强大的基础模型，以学习多样和多模态的科学观察数据，这为进一步发展高效的科学机器学习指明了道路。MORPH展示了在处理复杂时空异质数据集时的有效性和灵活性，为未来科学领域的研究提供了有力的支持工具。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21709", "html_url": "https://arxiv.org/abs/2509.21709", "title": "使用强化学习优化单变量非Clifford数量", "title_en": "Optimizing the non-Clifford-count in unitary synthesis using Reinforcement Learning", "authors": "David Kremer,Ali Javadi-Abhari,Priyanka Mukhopadhyay", "background": "量子算法相对于经典算法的主要计算优势在于能够有效实现特定的幺正算子。然而，这类实现通常依赖于以Clifford+T或Clifford+CS门集为基础构建量子电路，这类实现的复杂性往往随量子比特数量和非Clifford的数量指数增长。已有研究通常依赖于复杂的算法，这使得实际应用更为困难。因此，需要一种更为高效的方法来合成这些幺正算子。本研究旨在利用强化学习（RL）来合成这两种类型的幺正算子，同时优化T-count和CS-count，而无需依赖现有的复杂依赖高价翼数量的算法。", "innovation": "本文设计了一种基于通道表示的RL框架，能够高效地进行矩阵操作且仅使用整数，同时整合了修剪启发式和操作规范的方法，减少搜索复杂度。实验结果表明，与之前的算法相比，本研究能够在更短的时间内以更高的成功率和改进因子实现更大规模的幺正算子合成。具体而言，在Clifford+T合成中，对于100个T门的情况，取得了接近最优的分解效果，比之前的RL算法提高了5倍，且是当前已知的最大规模。对于Clifford+CS的2量子比特单位，实现了线性复杂度，而这是之前只有通过$SO(6)$表示才能达成的。本Rl算法重新发现了之前已知的最优线性复杂度算法，用于1量子比特单位的T计数最优分解，且实现了基于CS的2量子比特单位的线性复杂度合成，这是本领域的一个重要进展。", "conclusion": "本研究表明，使用RL可以更有效地实现Clifford+T和Clifford+CS门集下的单位叉合成，显著提高合成效率和成功率。尤其是对于大尺度的问题，RL算法显示出明显优势，打破了以往方法的限制，达到了以前的算法无法实现的效果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21666", "html_url": "https://arxiv.org/abs/2509.21666", "title": "DIM: 强化深度神经网络的领域驱动单调性", "title_en": "DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks", "authors": "Joshua Salim,Jordan Yu,Xilei Zhao", "background": "尽管深度学习模型在预测任务中表现优异，但由于其复杂的结构和大量的参数，它们往往会在训练数据中过拟合，导致模型记忆了包括噪音在内的训练数据，而非学习能够泛化的模式。为了应对这一挑战，本文提出了一种新的正则化方法，即在深度神经网络中强化领域驱动单调性的方法（DIM），该方法通过维护复杂的深度学习模型中的领域驱动单调关系，进一步提高预测性能。具体而言，该方法通过相对于线性基准惩罚单调性违反来强制执行单调性，有效地鼓励模型遵循预期的趋势，同时保持其预测能力。我们通过一个全面的数学框架来形式化这一方法，该框架建立了线性参考，度量从单调性行为的偏差，并将这些测量结果整合到训练目标中。我们使用来自芝加哥的真实世界网约车数据集和一个合成数据集测试和验证了所建议的方法。实验结果表明，即使是很小的单调性约束也能一致地提升模型性能。DIM通过在深度神经网络中应用领域驱动单调性约束来强化预测性能，从而减轻过拟合问题，", "innovation": "本文提出的DIM方法通过维护复杂的深度学习模型中的领域驱动单调关系，引入了一种新的正则化方法。这种方法通过相对于线性基准惩罚单调性违反来强制执行单调性，使模型能够遵循预期的趋势，保持其预测能力，同时提升模型的泛化能力。通过全面的数学框架，DIM方法明确了如何建立线性参考，如何度量偏离单调性行为的程度以及如何将这些度量整合到训练目标中。", "conclusion": "实验结果表明，即使是很小的单调性约束也能一致地提升模型性能。DIM通过在深度神经网络中应用领域驱动单调性约束来强化预测性能，从而减轻过拟合问题。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21748", "html_url": "https://arxiv.org/abs/2509.21748", "title": "SubZeroCore：一种零训练的子模优化聚核心选择方法", "title_en": "SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection", "authors": "Brian B. Moser,Tobias C. Nauen,Arundhati S. Shanbhag,Federico Raue,Stanislav Frolov,Joachim Folz,Andreas Dengel", "background": "当前的核心集选择方法旨在识别数据集的代表性子集以提高模型训练效率，但这些方法往往依赖于全数据集的昂贵训练信号，如梯度、决策边界估计或遗忘计数，这与它们降低数据训练负担的初衷相矛盾。", "innovation": "SubZeroCore 创新地提出了一种无需训练的新型核心集选择方法，将子模覆盖与密度统一到单一目标。它通过封闭形式解决方案引入了一种采样策略，该策略通过单个超参数明确定义了局部密度措施所需的覆盖度。", "conclusion": "SubZeroCore 在不进行训练的情况下，能够与基于训练的基线模型相匹配，并在较高的裁剪率下显著优于它们，同时大幅度减少计算开销。此外，SubZeroCore 对标签噪声具有更好的鲁棒性，显示出其实用效果和在实际场景中的扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21802", "html_url": "https://arxiv.org/abs/2509.21802", "title": "ChaosNexus: 多尺度表示用于通用混沌系统预报的基座模型", "title_en": "ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations", "authors": "Chang Liu,Bohao Zhao,Jingtao Ding,Yong Li", "background": "准确预测混沌系统（如天气预报和流体力学领域）仍然是科学上的一个重要挑战。这些系统的初始条件高度敏感，并且观测数据稀缺，这限制了传统建模方法的有效性。传统的模型通常只能针对特定系统进行训练，缺乏在新场景或数据受限情况下进行鲁棒零样本或少样本预测的能力。", "innovation": "提出了一种名为ChaosNexus的基座模型，该模型在多样化的混沌动态数据集上进行了预训练。ChaosNexus结合了新型多尺度架构ScaleFormer和MoE层，能够捕捉通用模式和系统特定行为。该模型在合成和实际应用基准测试中表现出最先进的零样本泛化能力，尤其是在大型测试平台中，其长期吸引子统计的准确性提高了40%以上，同时在实际应用中的数据效率也表现出色。", "conclusion": "实验结果表明，ChaosNexus在跨系统泛化方面表现出优越性能，这一优势来源于多样化训练系统的多样性，而非简单的数据量。该模型在5天全球天气预报中的零样本平均错误度数低于1度，并且通过少样本微调后性能进一步提升。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21798", "html_url": "https://arxiv.org/abs/2509.21798", "title": "评估和改进语言模型对LLM对齐的文化意识", "title_en": "Evaluating and Improving Cultural Awareness of Reward Models for LLM Alignment", "authors": "Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang", "background": "奖励模型（RMs）对于将大型语言模型（LLMs）与不同的文化对齐至关重要。因此，评估这些模型的文化意识对于全球LMMs的进一步对齐至关重要。然而，现有的RM评估方法由于缺乏文化相关的评估数据集而无法充分评估文化意识。", "innovation": "本文提出了Cultural Awareness Reward modeling Benchmark (CARB)，覆盖了10种不同的文化，涉及4个文化领域。通过广泛评估当前最先进的RMs，揭示了它们在建模文化意识方面的局限性，并展示了CARB的表现与下游多语言文化对齐任务的正相关关系。进一步分析还识别了文化意识奖励建模中的虚假相关性，其中RM的评分主要依赖于表面特征而非真实的文化细微差别理解。为了应对这些问题，本文提出了Think-as-Locals，通过强化学习从可验证的奖励（RLVR）中获得更深入的文化基础推理，并使用精心设计的奖励来确保准确的偏好判断和高质量的结构化评估标准生成。", "conclusion": "实验结果证明了其在减轻虚假特征干扰和促进文化意识奖励建模方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21840", "html_url": "https://arxiv.org/abs/2509.21840", "title": "大型语言模型能否自动形式化运动学？", "title_en": "Can Large Language Models Autoformalize Kinematics?", "authors": "Aditi Kabra,Jonathan Laurent,Sagar Bharadwaj,Ruben Martins,Stefan Mitsch,André Platzer", "background": "自主的网络物理系统，如机器人和自动驾驶汽车，可以从使用形式化方法可靠地推理其控制决策中受益。但在解决问题之前，须先将其表述为形式化的物理模型，这需要专业知识，并且成为瓶颈。", "innovation": "本研究通过实验研究大型语言模型是否能够自动化这一形式化过程。为此，设计了一个包含本科物理运动学问题的20问题基准套件，让模型基于自然语言描述生成差分博弈逻辑模型，经语法检查、迭代修正和语义验证。结果显示成功率高达70%。", "conclusion": "此研究为基于自然语言到混合博弈逻辑（具有连续动态）的自动形式化提供了第一个定量基准，识别出未来改进的方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21742", "html_url": "https://arxiv.org/abs/2509.21742", "title": "脑病理图学习", "title_en": "Brain PathoGraph Learning", "authors": "Ciyuan Peng,Nguyen Linh Dan Le,Shan Jin,Dexuan Ding,Shuo Yu,Feng Xia", "background": "脑图学习在神经科学和人工智能领域取得了显著成就，但现有方法难以选择性地学习与疾病相关的知识，导致参数和计算成本高，进而影响效率和实用性，限制了其在临床应用上的实际效果。", "innovation": "提出了一个轻量级的脑病理图学习（BrainPoG）模型，通过病理性模式过滤和病理性特征蒸馏，实现高效的脑图学习。该模型通过提取与疾病高度相关的子图，实现脑图修剪和病灶定位，同时通过减少与疾病无关的噪声特征并增强脑病理图中每个节点的病理性特征，避免学习与疾病关系不大或无关的信息，实现了高效的脑图学习。", "conclusion": "在四个基准数据集上的广泛实验表明，BrainPoG在各种脑疾病检测任务中均表现出优越的模型性能和计算效率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21737", "html_url": "https://arxiv.org/abs/2509.21737", "title": "POLO: 基于偏好指导的多轮强化学习药物先导化合物优化", "title_en": "POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization", "authors": "Ziqing Wang,Yibo Wen,William Pattie,Xiao Luo,Weimin Wu,Jerry Yao-Chieh Hu,Abhishek Pandey,Han Liu,Kaize Ding", "background": "药物发现过程中的先导化合物优化需要高效地在巨大的化学空间内迭代，通过循环增强分子特性同时保持与原始先导化合物的结构相似性。尽管取得了最近的进步，传统的优化方法在样本效率上存在不足，即在有限的查询评估中难以实现良好的优化效果。大型语言模型（LLMs）因其内省学习和指令跟随能力，为解决这一问题提供了新的视角，但现有基于LLM的方法未能充分发挥这种优势，它们将每个优化步骤独立处理。因此，本文提出了一种名为POLO（Preference-guided multi-turn Optimization for Lead Optimization）的方法，使LLMs能够从全面的优化轨迹中学习，而不是仅从孤立的步骤中学习。POLO的核心是引入一种名为PGPO（Preference-Guided Policy Optimization）的新型强化学习算法，该算法在两个互补水平上提取学习信号：轨迹级别的优化强化成功策略，而每个轨迹内的转级偏好学习则通过在各轨迹中排名中间分子提供密集的比较反馈。通过这种两个层次的中间评价学习，POLO实现了更高的样本效率，充分利用了每次昂贵的oracle调用。", "innovation": "POLO通过引入一种全新的强化学习算法PGPO，使LLMs能够从完整的优化轨迹中学习，而不是仅从孤立的步骤中学习。PGPO在两个层次上提取学习信号：轨迹级别的优化强化成功策略，而每个轨迹内的转级偏好学习则通过在各轨迹中排名中间分子提供密集的比较反馈。这种双层次学习机制使得POLO在中间评价中达到了更高的样本效率，而传统方法则难以在有限的查询评估中实现良好的优化效果。POLO在单属性任务中的平均成功率达到了84%，在多属性任务中仅使用500次oracle调用也实现了显著的样本效率提升，这意味着POLO为样本高效分子优化领域带来了重要的进展。", "conclusion": "通过广泛的实验表明，POLO在单一属性任务中平均成功率达到84%（比基线效果更好2.3倍），在多属性任务中仅用500次oracle评价就实现了基线方法的50%性能，这在样本高效分子优化任务中取得了显著的进步。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21839", "html_url": "https://arxiv.org/abs/2509.21839", "title": "DiTraj: 基于训练-free 的视频扩散变换器的轨迹控制", "title_en": "DiTraj: training-free trajectory control for video diffusion transformer", "authors": "Cheng Lei,Jiayu Zhang,Yue Ma,Xinyu Wang,Long Chen,Liang Tang,Yiqiang Yan,Fei Su,Zhicheng Zhao", "background": "基于DiT的视频生成模型展现了强大的生成能力。现有的轨迹控制方法要么需要大量的训练资源，要么只能针对特定的模型如U-Net，并未能充分利用DiT的优越性能。", "innovation": "提出了一个简单且有效的训练-free框架DiTraj，专门为DiT设计用于文本到视频的轨迹控制。首先，通过语言模型将用户提供的提示转化为前景和背景提示，分别指导视频中前景和背景区域的生成。其次，提出了前景与背景分离指导，并探索了3D全关注机制中跨词注意力分数与位置嵌入之间的紧密联系。基于此，提出了前景与背景分离的三维位置投影解耦(3D-RoPE)方法，通过修改仅前景词的位置嵌入来消除跨帧的视角差异，加强跨帧注意力并提高轨迹控制效果。同时，通过调节位置嵌入的密度实现针对扩散变换器的3D感知轨迹控制。", "conclusion": "广泛的实验表明，该方法在视频质量和轨迹控制可调节性方面都优于之前的方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21740", "html_url": "https://arxiv.org/abs/2509.21740", "title": "自推测偏向解码以实现更快的实时翻译", "title_en": "Self-Speculative Biased Decoding for Faster Live Translation", "authors": "Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang", "background": "大型语言模型（LLMs）在各种文本生成任务中表现出色，但在流式应用（如实时翻译）中，它们面临着将输出不断地更新以适应不断增加的输入上下文的挑战，同时需要维持合理的计算成本以满足延迟要求。现有方法难以满足这些需求。现存的研究集中在同时翻译的重新翻译方法上，并提出了自推测偏向解码，这是一种新颖的推理范式，旨在避免为持续增长的输入流从头开始重复生成输出。这种方法利用最新的输出作为当前增长输入上下文的草稿，并在验证阶段，使输出偏向草稿令牌，从而提高草稿接受率。这不仅减少了可能会使用户分心的闪烁现象，还提高了速度。传统的解码方法在草稿验证后可能会从分歧点接管，并继续直到满足结束条件。", "innovation": "提出了一种新的自推测偏向解码方法，这是一种模型无关且即插即用的加速方案，它避免了现有推测解码策略中通过计算草稿的需求，适用于延迟敏感的流式应用程序，能实现比传统的自回归重新翻译高达1.7倍的速度提升，同时显著减少了80%的闪烁现象，并采用了仅显示的掩码技术。", "conclusion": "实验结果表明，自推测偏向解码方法在同时文本到文本重新翻译中使用时，能够在不牺牲质量的情况下实现最高1.7倍的速度提升，并显著减少了80%的闪烁现象。这种方法为流式应用中的实时翻译提供了一种高效且实用的加速方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21870", "html_url": "https://arxiv.org/abs/2509.21870", "title": "增强低秩适应的结构非线性变换", "title_en": "Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations", "authors": "Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song", "background": "低秩适应（LoRA）是一种在大型语言模型中广泛应用的参数高效微调方法。尽管LoRA具有高效性，但由于其线性特性，限制了其表达能力。", "innovation": "提出了一种名为LoRAN的非线性扩展方法，通过轻量级变换应用于低秩更新。此外，引入了一种基于正弦的激活函数Sinter，能够在不增加参数计数的情况下添加结构化扰动。", "conclusion": "实验结果表明，LoRAN在摘要和分类任务中都优于QLoRA。消融研究显示，Sinter在低秩调优中优于标准激活函数（如Sigmoid、ReLU和Tanh），突显了激活函数设计的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21761", "html_url": "https://arxiv.org/abs/2509.21761", "title": "Backdoor Attribution: 暴露和控制语言模型内的后门", "title_en": "Backdoor Attribution: Elucidating and Controlling Backdoor in Language Models", "authors": "Miao Yu,Zhenhong Zhou,Moayad Aloqaily,Kun Wang,Biwei Huang,Stephen Wang,Yueming Jin,Qingsong Wen", "background": "大型语言模型（LLMs）在面对通过数据污染进行的后门攻击时存在脆弱性，然而后门攻击的内部机制仍然不清楚。现有的可解释性研究主要集中在对齐、脱缰和幻觉等方面，忽视了后门机制，这使得理解和完全消除后门威胁变得困难。因此，该研究旨在构建一个解释性框架来揭示和控制语言模型内的后门机制。", "innovation": "该研究开发了一个名为Backdoor Attribution (BkdAttr)的三部分因果分析框架，以探索LLM后门的可解释机制。首先，提出了Backdoor Probe来证明存在可学习的后门特征。在此基础上，进一步开发了Backdoor Attention Head Attribution (BAHA)，能够高效率地定位负责处理这些特征的特定注意力头。发现少至3%的注意力头被移除后，攻击成功率可降低90%以上。更重要的是，还基于这些发现构建了后门向量，这个向量通过单点干预单一表示，可以显著提高或完全消除后门攻击。", "conclusion": "该研究首次在LLM后门中展现了机制可解释性，并展示了强有力的方法来控制后门，为社区提供了可行的见解和指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21778", "html_url": "https://arxiv.org/abs/2509.21778", "title": "伪粒子射线衍射的不变晶体性质预测超越结构", "title_en": "Beyond Structure: Invariant Crystal Property Prediction with Pseudo-Particle Ray Diffraction", "authors": "Bin Cao,Yang Liu,Longhan Zhang,Yifan Wu,Zhixun Li,Yuyu Luo,Hong Cheng,Yang Ren,Tong-Yi Zhang", "background": "使用量子力学原理进行晶体性质预测虽然准确，但对于大规模多体系统计算上是不可行的，传统密度泛函理论难以精确求解。机器学习模型在大规模应用中表现出了高效性，但其性能高度依赖于原子表示的选择。现代基于图的方法虽然逐步纳入更多结构信息，但由于有限的感受野和局部编码机制，常常无法捕捉到长期的原子间相互作用。这种限制导致了不同晶体被映射为相同的表示，影响了准确的性质预测。", "innovation": "提出了一种名为PRDNet的方法，该方法结合了独特的倒易空间衍射以及图表示方法。通过使用数据驱动的伪粒子来生成合成衍射图案，增强了对其元素和环境变化的敏感性。PRDNet确保了对晶体学对称性的完全不变性。实验结果展示了所提出模型在Materials Project、JARVIS-DFT和MatBench上的最先进的性能。", "conclusion": "该研究提出了PRDNet模型，通过结合倒易空间衍射和图表示方法，解决了传统方法在捕捉长期原子间相互作用上的局限性。实验结果表明，该模型在多个数据集上的预测性能达到了最先进的水平。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21880", "html_url": "https://arxiv.org/abs/2509.21880", "title": "保留每一提示：通过熵导向的优势塑造在LLM强化学习中利用零方差提示", "title_en": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping", "authors": "Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang", "background": "当前强化学习方法，如GRPO，仅依赖于模型对相同输入给出不同正确性的响应来改进策略，忽视了所有响应获得相同奖励的‘零方差提示’。这些‘零方差提示’以前被认为是无用的，但现在研究发现了它们提供有意义反馈用于策略优化的潜力。", "innovation": "提出了RL-ZVP（Reinforcement Learning with Zero-Variance Prompts）算法，可以直接从零方差提示中吸取学习信号，即便不对比响应也可奖励正确性和惩罚错误，反馈使用了基于token的特征来保持信息量丰富、细致的信号。RL-ZVP在六个数学推理基准测试中显著提高了准确性和通过率，优于其他过滤掉零方差提示的基线方法。", "conclusion": "研究结果表明了利用零方差提示进行RL的设计潜力，这为改进大型语言模型的推理能力提供了新方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21882", "html_url": "https://arxiv.org/abs/2509.21882", "title": "标题：《可验证奖励强化学习的隐性成本和度量缺口》", "title_en": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards", "authors": "Aaron Tu,Weihao Xuan,Heli Qi,Xu Huang,Qingcheng Zeng,Shayan Talaei,Yijia Xiao,Peng Xia,Xiangru Tang,Yuchen Zhuang,Bing Hu,Hanqun Cao,Wenqi Shi,Tianang Leng,Rui Yang,Yingjian Chen,Ziqi Wang,Irene Li,Nan Liu,Huaxiu Yao,Li Erran Li,Ge Liu,Amin Saberi,Naoto Yokoya,Jure Leskovec,Yejin Choi,Fang Wu", "background": "RLVR是一种实用且可扩展的方法，用于增强诸如数学、代码和其他结构化任务的大语言模型。文章提出了两个问题：在严格的对等控制评估下，报告的收益是否能够保持，以及RLVR是否是无代价的或是否会对模型表现产生可测量的影响。研究发现了三个原因导致了收益的夸大——RLVR税、评估过程中的陷阱和数据污染。", "innovation": "文章提出了一个意识税的训练和评估协议，该协议优化了准确性、定位和规范化的弃权，并标准化预算和溯源检查。该协议应用于最近的RLVR设置，其结果更加可靠，并在某些情况下重新评估了先前的结论。", "conclusion": "作者认为RLVR具有实际价值，已经准备好在工业环境中应用；他们主张保持其实际效益，同时优先考虑可靠性、安全性和测量的标准。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21785", "html_url": "https://arxiv.org/abs/2509.21785", "title": "无偏分箱：公平意识的属性表示", "title_en": "Unbiased Binning: Fairness-aware Attribute Representation", "authors": "Abolfazl Asudeh,Zeinab(Mila)Asoodeh,Bita Asoodeh,Omid Asudeh", "background": "在分享数据集之前，将原始特征离散化为桶化属性表示是一种常见的步骤。然而，这一过程可能会导致数据中的偏差显著增加，并在下游任务中放大不公平性。作者研究了这一问题，并提出了一种无偏分箱问题，旨在找到最接近等大小分箱的离散化方式，同时满足不同桶之间的群体一致性。进一步，对于那些可能存在较大公平性成本，或根本不存在满足条件的分箱的情况，作者引入了ε偏差分箱问题，允许群体差异在不同桶之间保持在较小的ε值内，以更好的适应实际情况并确保可接受的公平性。", "innovation": "1. 提出了无偏分箱问题，并证明在少量边界候选集内选择边界能够自证无偏性。\n2. 设计并实现了一个基于动态规划的高效算法来解决无偏分箱问题。\n3. 针对ε偏差分箱问题提出了一种动态规划解决方案，以及基于局部搜索的可扩展算法，通过分而治之算法提高了效率，并证明了局部搜索算法能够找到最优解。", "conclusion": "该研究提供了一种有效的方法来减轻数据分享过程中的偏差和不公平性，特别是在不同群体间的分布差异较大时。通过引入ε偏差分箱问题，保证了在公平性成本可控范围内的解决方案，从而使得该方法在实际应用中更加普遍适用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21907", "html_url": "https://arxiv.org/abs/2509.21907", "title": "使用大型语言模型在土耳其语中的大规模数据集和引文意图分类", "title_en": "A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs", "authors": "Kemal Sami Karaca,Bahaeddin Eravcı", "background": "理解引用的质性意图是全面评估学术研究的关键，但对像土耳其语这样的粘着语来说具有独特挑战。", "innovation": "引入了一种系统的方法和基础数据集；提出了一个新型公开可用的土耳其语引用意图数据集，并使用自建注释工具；基于DSPy框架开发了一个程序化分类流水线，自动优化提示；利用集成学习中的XGBoost元模型，实现了91.3%的最高准确度。", "conclusion": "本研究为土耳其NLP社区和更广泛的学术界提供了一个基础数据集和一个稳健的分类框架，为未来的引文质性研究铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21792", "html_url": "https://arxiv.org/abs/2509.21792", "title": "FastGRPO: 通过并发感知的推测性解码和在线草稿学习加速策略优化", "title_en": "FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning", "authors": "Yizhou Zhang,Ning Lv,Teng Wang,Jisheng Dang", "background": "Group相对策略优化（GRPO）已经在通过强化学习提高大型语言模型（LLMs）的推理能力方面显示出了巨大的潜力。然而，其实际部署受到训练过程过于缓慢的阻碍，主要由于生成多个响应需要大量的计算密集型自回归处理，使得生成阶段成为主要的性能瓶颈。尽管推测性解码展示出加速的前景，但在高并发训练条件下，直接应用于GRPO只能取得有限的加速效果。", "innovation": "提出了一种并发感知的推测性解码框架，该框架可以根据实时的并发水平动态调整草稿和验证策略，从而最大化加速生成过程。同时，提出了在线草稿学习机制，使草稿模型能够通过来自目标模型的反馈信号不断适应，以解决训练过程中由目标模型和固定草稿模型间的分布漂移导致的性能下降问题。实验结果显示，该方法在多个数学推理数据集和模型上实现了2.35x至2.72x的端到端加速，效率远超基准方法。", "conclusion": "该方法在数学推理任务中通过并发感知的推测性解码和在线草稿学习机制实现了显著的训练加速效果，有效解决了GRPO中存在的问题，提升了大型语言模型的训练效率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21848", "html_url": "https://arxiv.org/abs/2509.21848", "title": "Graph of Agents: 基于涌现多智能体合作的原理化长上下文建模", "title_en": "Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration", "authors": "Taejong Joo,Shu Ishida,Ivan Sosnovik,Bryan Lim,Sahand Rezaei-Shoshtari,Adam Gaier,Robert Giaquinto", "background": "作为模型通用的方法，多智能体系统可以处理比大型语言模型上下文窗口更长的输入，而无需重新训练或架构修改。然而，其性能很大程度上依赖于手工设计的多智能体协作策略和提示工程，这限制了其泛化能力。", "innovation": "本文提出了一种原理框架，将模型通用的长上下文建模问题形式化为压缩问题，从而得到了一种信息论压缩目标。在此基础上，提出了Graph of Agents (GoA)，这是一种动态构建的输入依赖的协作结构，能够最大化该目标。与Llama 3.1 8B和Qwen3 8B在六个文档问答基准上的表现相比，GoA分别提高了检索增强生成的平均F1分数5.7%和固定协作结构的强多智能体基线16.35%。即使只有2K的上下文窗口，GoA在LongBench上也超过了具有128K上下文窗口的Llama 3.1 8B，显示出有效上下文长度的大幅提升。", "conclusion": "GoA显著提升了长上下文处理的效果，在有限的上下文窗口内实现了对更大模型的有效超越，展示了其在理论上和实践上的应用潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21910", "html_url": "https://arxiv.org/abs/2509.21910", "title": "AutoSCORE：通过结构化组件识别增强多代理大规模语言模型的自动评分", "title_en": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "authors": "Yun Wang,Zhaojun Ding,Xuansheng Wu,Siyue Sun,Ninghao Liu,Xiaoming Zhai", "background": "自动化评分在教育中扮演着关键角色，通过减少对人类评分者的依赖，实现对学生作业的规模性和即时性评价。尽管大型语言模型（LLMs）在该任务中表现出强大的潜力，但在作为端到端评分员的应用中面临诸多挑战，包括准确性低、提示敏感性高、解释性差以及评分标准偏离等，这些问题阻碍了基于LLM的自动评分在评估中的实际应用。", "innovation": "提出了一种名为AutoSCORE的多代理LLM框架，通过评分标准对齐的结构化组件识别增强自动化评分。该框架包括两个代理：首先，提取来自学生回答的相关组件并通过结构化表示（即评分标准组件提取代理）编码，然后应用于评分（即评分代理）。这种设计确保了模型的推理过程遵循类似人工评分的过程，提高了解释性和稳健性。", "conclusion": "AutoSCORE在四个ASAP基准数据集上与单代理基线进行比较，显示出在评分准确性、人机协议（QWK相关性）和错误度量（MAE、RMSE）方面的显著改进，特别是在复杂的、多维度的评分标准和小型模型上表现出特别大的相对收益。这些结果表明，结构化组件识别与多代理设计相结合为自动评分提供了可扩展、可靠且可解释的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21871", "html_url": "https://arxiv.org/abs/2509.21871", "title": "解锁美丽之本质：基于相对-绝对策略优化的高级美学推理", "title_en": "Unlocking the Essence of Beauty: Advanced Aesthetic Reasoning with Relative-Absolute Policy Optimization", "authors": "Boyang Liu,Yifan Hu,Senjie Jin,Shihan Dou,Gonglei Shi,Jie Shao,Tao Gui,Xuanjing Huang", "background": "多模态大型语言模型（MLLMs）适合作为图像美学评估工具，因为它们能够通过跨模态理解能力捕捉到高层次的美学特征。然而，缺乏多模态美学推理数据以及美学判断本质上是主观的，使得MLLMs难以生成准确、具有可解释判释的美学判断。", "innovation": "本文提出了Aes-R1，一个基于强化学习（RL）的全面美学推理框架。具体来说，Aes-R1 包含一个管道AesCoT，用于构建和筛选用于冷启动的高质量链式思考美学推理数据。通过在评分之前先教会模型生成结构化的解释，然后采用一种名为相对-绝对策略优化（RAPO）的新型RL算法，同时优化绝对评分回归和相对排名，提升单图像精度和跨图像偏好判断。", "conclusion": "广泛的实验表明，Aes-R1 使骨干网络的平均PLCC/SRCC分别提高了47.9%/34.8%，超越了类似规模的最新基线。更多的消融研究还验证了Aes-R1在有限监督和环境外怀中的一贯鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21928", "html_url": "https://arxiv.org/abs/2509.21928", "title": "SAGE：场景图感知指导与执行在长时序抓取任务中的应用", "title_en": "SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks", "authors": "Jialiang Li,Wenzheng Wu,Gaojing Zhang,Yifan Han,Wenzhao Lian", "background": "成功解决长时序操作任务仍然是一个基础性的挑战。这些任务涉及长时间的行动序列和复杂的物体交互，而现有方法在高层次的符号规划和低层次的连续控制之间存在关键差距。", "innovation": "提出了一种称为SAGE的新框架（Scene Graph-Aware Guidance and Execution），它利用场景图作为场景状态的结构表示。SAGE框架包含了两个关键组件：（1）基于场景图的任务规划器，使用多模态语言模型（VLMs）和大型语言模型（LLMs）解析环境并推理物理接地的场景状态转换序列；（2）脱耦的结构图像编辑流水线，能够将每个目标子目标图通过图像修复和组合可控地转化为相应的图像。", "conclusion": "广泛的实验表明，SAGE在不同的长时序任务上达到了领先表现。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21913", "html_url": "https://arxiv.org/abs/2509.21913", "title": "EqDiff-CT: 具有旋转对称性的条件扩散模型从CBCT合成CT图像", "title_en": "EqDiff-CT: Equivariant Conditional Diffusion model for CT Image Synthesis from CBCT", "authors": "Alzahra Altalib,Chunhui Li,Alessandro Perelli", "background": "锥形束CT（CBCT）在图像引导放射治疗（IGRT）中广泛应用。虽然CBCT提供实时可视化且成本低、辐射剂量小，但由于光子散射和射线束阻碍，会产生伪影，影响剂量计算和自适应规划的准确性。相比之下，CT成像质量更好、Hounsfield单位更加准确，但通常为离线获取，无法捕捉治疗过程中的解剖变化。因此，准确的CBCT-to-CT合成对于提高自适应放疗流程中的成像质量至关重要。", "innovation": "本文提出了一种新的扩散条件生成模型，称为EqDiff-CT，用于从CBCT合成高质CT图像。EqDiff-CT利用去噪扩散概率模型（DDPM）迭代地注入噪声并学习潜在表示，从而实现解剖一致的CT图像重建。采用具有旋转对称性的群差变条件U-Net基干，有助于保持精细结构细节并最小化噪声和伪影。研究训练并验证了该系统，结果显示EqDiff-CT在结构保真度、Hounsfield单位准确性及量化指标方面表现优异，进一步的视觉结果证实了该模型的改进，锐化了软组织边界并生成了更真实的骨重建。", "conclusion": "该研究提出的扩散模型提供了一个强大的、具有通用性的框架，用于提高CBCT图像的质量。该模型在CBCT引导的治疗计划和剂量计算中的临床信心方面也有所提升。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21938", "html_url": "https://arxiv.org/abs/2509.21938", "title": "SemanticControl：一种用于处理与ControlNet松散对齐的视觉条件的无需训练方法", "title_en": "SemanticControl: A Training-Free Approach for Handling Loosely Aligned Visual Conditions in ControlNet", "authors": "Woosung Joung,Daewon Chae,Jinkyu Kim", "background": "ControlNet在文本到图像的扩散模型中引入了额外的视觉条件，如深度图或边缘图，使空间控制更加详细。然而，其效果高度依赖于与文本提示指定的生成目标精确对齐的视觉条件，这种需求在实践中往往难以实现，特别是在处理不常见或想象中的场景时。例如，生成一只特定姿势烹饪的猫的图像可能是不可行的，因为没有适合的视觉条件可用。虽然在更常见的场景中可以找到结构上相似的线索，但现有的ControlNet模型难以利用这些不精确对齐的视觉条件，经常导致较低的文本忠实度或视觉伪影。", "innovation": "提出了SemanticControl，一种无需训练的方法，用于有效利用松散对齐但语义相关性较强的视觉条件。该方法通过首先使用与视觉条件对齐的辅助提示（例如，“一个人弹吉他”以捕捉吉他演奏姿势的注意掩码）来抑制视觉条件与提示冲突的区域的影响，然后在处理实际目标提示的过程中利用这些掩码（例如，猫弹吉他）。实验结果表明，该方法在各种情况下（包括深度图、边缘图和人体骨骼图）提高了表现，优于现有基准。", "conclusion": "实验结果表明，我们的方法在松散对齐的条件下改善了各种条件下的性能，包括深度图、边缘图和人体骨骼图，超过了现有基准。代码已在此处提供：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21961", "html_url": "https://arxiv.org/abs/2509.21961", "title": "FlowDrive: 考虑数据平衡的流匹配轨迹规划", "title_en": "FlowDrive: moderated flow matching with data balancing for trajectory planning", "authors": "Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller", "background": "基于学习的规划器对驾驶数据的长尾分布敏感。常见的驾驶行为占据了数据集，而危险或罕见场景则较少。这种不平衡可能会导致模型偏向常见情况，并在关键场景上降低性能。", "innovation": "本文通过比较采样训练数据的平衡策略，发现轨迹模式加权是一种有效的方法。提出了一种称为FlowDrive的流匹配轨迹规划方法，该方法通过少量的流匹配步骤学习条件修正流来直接将噪声映射到轨迹分布。同时引入了一种温和的在线引导方法，在流步之间注入微小的扰动，以系统地增加轨迹多样性，同时保持场景一致性。", "conclusion": "在nuPlan和交互为重点的interPlan基准测试中，FlowDrive在基于学习的规划器中达到了最先进的结果，并接近基于规则改进的方法。通过添加温和的引导和轻量级后处理（FlowDrive*），它在几乎所有基准测试拆分中实现了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21884", "html_url": "https://arxiv.org/abs/2509.21884", "title": "你无法窃取不存在的：通过系统向量缓解LLM中的提示泄露", "title_en": "You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors", "authors": "Bochuan Cao,Changjiang Li,Yuanpu Cao,Yameng Ge,Ting Wang,Jinghui Chen", "background": "大语言模型（LLMs）在各种应用中得到广泛应用，通过定制系统提示来完成多样化任务。然而，系统提示泄漏的风险也引发了关注。当前主要通过禁用LLMs在遇到已知攻击模式时重复其上下文来防止泄漏，但这种方法仍易受新型和未知的提示泄露技术的攻击。", "innovation": "本文提出了一种名为SysVec的新方法，将系统提示编码为内部表示向量而非原始文本，从而最小化未经授权的披露风险，同时保留LLM的核心语言能力。该方法不仅增强了安全性能，还提高了模型的通用指令遵循能力，并在实验结果中证明了SysVec有效缓解了提示泄露攻击、维持了LLM的功能性完整，并减轻了长上下文场景中的遗忘问题。", "conclusion": "SysVec方法通过将系统提示编码为向量，实现了提示泄露风险的有效缓解，同时保持了LLM的核心功能，增强了安全性和模型的泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21892", "html_url": "https://arxiv.org/abs/2509.21892", "title": "弹性MoE：解锁Mixture-of-Experts的推理时间可扩展性", "title_en": "Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts", "authors": "Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang", "background": "MoE模型通常在训练和推理阶段固定激活专家的数量k。直觉上，推理时激活更多的专家k'（其中k' > k）意味着使用更多的模型参数计算，这有望提升性能。然而，实际情况并非如此，我们发现这种性能提升的效果十分有限，微小的专家数量增加可能导致性能急剧下降。我们进一步发现，这种性能下降的原因是一些专家之间缺乏学习到的合作机制。", "innovation": "为了解决上述问题，我们提出了弹性MoE（EMoE）训练框架，该框架能够在推理时不增加额外训练成本的情况下，动态调整激活的专家数量。EMoE通过同时训练专家进行多样化的合作并促进路由选择的高质量，确保在不同计算预算下性能的稳定性。", "conclusion": "我们在各种MoE设置下进行了大量实验。结果表明，EMoE显著扩大了有效性能增益范围，从训练时间k扩展到2-3倍的k，同时将模型的最佳性能推向更高水平。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21847", "html_url": "https://arxiv.org/abs/2509.21847", "title": "超越约翰逊-林德施特罗姆：广义线性形式的均匀界", "title_en": "Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms", "authors": "Rohan Deb,Qiaobo Li,Mayank Shrivastava,Arindam Banerjee", "background": "在机器学习和随机化算法中，加性和内积的抽样边界已被证明对于多种重要结果的基础。然而，现代分析涉及广义线性形式，现有的边界要么不适用，要么在一般集合上不够精确。这项工作旨在开发一个通用框架来分析这种广义线性形式，并获得了基于这些集合的几何复杂度的均匀边界。这种方法依赖于通用链式法，并引入了处理两个集合的上确界的新的技术手段。进一步将结果扩展到求和包含T个独立的抽样矩阵的情况下，结果显示偏差为√T。", "innovation": "开发了一个通用框架来分析广义线性形式，并提出了基于集合几何复杂度的均匀边界。引入了新的方法来处理集合对的上确界。将结果扩展到涉及T个独立抽样矩阵的情况，偏差呈现为√T的量级。这项统一分析不仅涵盖了已知的结果，如约翰逊-林德施特罗姆引理，还推广了近似线性代数的保证。此外，提出了改进的收敛边界，适用于抽样联邦学习算法，并设计了新的抽样测试策略以获得更紧的遗憾界限，依赖于操作和参数集的几何复杂度而非潜在空间维度", "conclusion": "这项工作统一分析了抽样边界，不仅涉及广义线性形式，也扩展了RIP类型保证。具体从抽样贝叶斯学习算法中发现了更紧密的收敛边界，并设计了新的采样变种的带算法，具有依赖于操作和参数集几何复杂度、而非潜在空间维度的更紧遗憾界限。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21983", "html_url": "https://arxiv.org/abs/2509.21983", "title": "混合扩散模型用于同时进行符号和连续规划", "title_en": "Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning", "authors": "Sigmund Hennum Høeg,Aksel Vaaler,Chaoqi Liu,Olav Egeland,Yilun Du", "background": "在人工智能领域，构建机器人以完成长期任务是一个长期存在的挑战。使用生成方法，特别是扩散模型，由于它们能够模拟连续的机器人轨迹以供规划和控制而受到关注。然而，这些模型在处理涉及复杂决策的长期任务时存在困难，通常会导致混淆不同行为模式，从而导致失败。", "innovation": "为了克服这一问题，该论文提出了同时生成高级符号计划和连续轨迹生成的新方法。这种方法需要一种新颖的混合离散变量扩散和连续扩散的策略，这在基准方法上取得了显著的性能提升。此外，该混合扩散过程还允许根据部分和完整的符号条件来灵活合成轨迹。", "conclusion": "该混合扩散过程使得机器人能够更准确地执行复杂的长期任务，能够更好地规划和控制机器人动作，解决了传统方法中存在的精度不高和混淆问题。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21979", "html_url": "https://arxiv.org/abs/2509.21979", "title": "医疗视觉语言模型的心理学奉承现象基准测试与缓解", "title_en": "Benchmarking and Mitigate Psychological Sycophancy in Medical Vision-Language Models", "authors": "Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu", "background": "视觉语言模型(VLMs)逐渐融入临床工作流程，但它们倾向于迎合用户表达的社会暗示或权威感知，而非基于证据的推理。这项研究通过一个新颖的临床背景基准评估医疗领域的奉承现象，特别是在医学视觉问答中的具体表现。", "innovation": "提出了一个名为VIPER的视觉信息净化策略，用于证据导向的响应生成。该策略通过过滤非证据性内容（例如社交压力），然后生成受限的证据优先答案，有效减少了奉承现象，同时保持了解释性。该研究还提供了一个基于心理压力模板的医学奉承数据集，并通过对抗性实验评估了不同VLMs的应对机制，揭示了奉承现象普遍存在且与模型准确度或规模无强相关。", "conclusion": "基准分析和缓解框架为实现医疗VLMs在真实临床情境中的稳健部署奠定了基础，强调了需要基于证据的防御措施。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21967", "html_url": "https://arxiv.org/abs/2509.21967", "title": "基于定制化EfficientNet-B0的无参图像对比度评估", "title_en": "No-Reference Image Contrast Assessment with Customized EfficientNet-B0", "authors": "Javad Hassannataj Joloudari,Bita Mesbahzadeh,Omid Zare,Emrah Arslan,Roohallah Alizadehsani,Hossein Moosaei", "background": "对比度是视觉感知中的重要因素，对整体图像质量至关重要。然而，大多数不需要参考图像的质量评估（NR IQA）模型在面对多变的现实环境时，难以准确评估对比度扭曲。", "innovation": "本文提出了一种基于深度学习的框架，通过定制和微调三种预先训练的架构，即EfficientNet B0、ResNet18和MobileNetV2，针对感知平均意见得分（Perceptual Mean Opinion Score），并额外构建了一个基于双胞胎网络的模型，该模型在感知对比度扭曲的捕捉上能力有限。每个模型都添加了对比度感知回归头，并使用针对两个基准数据集CID2013和CCID2014（包含合成和真实的对比度扭曲）的数据增强进行端到端训练。", "conclusion": "在这些模型中，我们定制的EfficientNet B0模型在CCID2014上的PLCC = 0.9286，SRCC = 0.9178，在CID2013上的PLCC = 0.9581，SRCC = 0.9369，超越了传统方法和其他深度基准模型。结果表明，对比度感知的轻量级预训练网络调整可以提供一种高性能、可扩展的无参对比度质量评估解决方案，适用于实时和资源受限的应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21925", "html_url": "https://arxiv.org/abs/2509.21925", "title": "有限训练集下随机插值的生成性质", "title_en": "Generation Properties of Stochastic Interpolation under Finite Training Set", "authors": "Yunchen Li,Shaohui Lin,Zhou Yu", "background": "本文研究了生成模型在有限训练样本下的理论行为。在随机插值生成框架内，当仅有限数量的训练样本可用时，推导出了最优速度场和得分函数的闭式表达式。研究表明，在某些光滑条件下，确定性生成过程能精确地恢复训练样本，而随机生成过程则表现为带有高斯噪声的训练样本。", "innovation": "在有限训练样本的条件下，本文推导了最优速度场和得分函数的闭式表达式；提出了生成模型的过拟合与欠拟合的正式定义；揭示了估计误差存在时，随机生成过程产生的效果是训练样本的凸组合，并受到均匀噪声和高斯噪声混合的影响。", "conclusion": "理论分析和生成任务及分类任务下的实验都支持了本文的理论。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21976", "html_url": "https://arxiv.org/abs/2509.21976", "title": "Geo-R1: 使用强化微调提高少样本地理空间指示表达理解", "title_en": "Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning", "authors": "Zilun Zhang,Zian Guan,Tiancheng Zhao,Haozhan Shen,Tianyu Li,Yuxiang Cai,Zhonggen Su,Zhaojun Liu,Jianwei Yin,Xiang Li", "background": "在遥感领域，指示表达理解面临独特的挑战，因为这要求在复杂的对象上下文关系进行推理。虽然多模态大型语言模型通过监督微调（SFT）在大量标注数据集上表现出强大的性能，但在数据稀缺场景中，它们的泛化能力较差，导致泛化性能不佳。", "innovation": "为解决这一限制，本文提出了一种基于推理的强化微调（RFT）范式Geo-R1，用于少样本地理空间指示表达。Geo-R1强制模型首先生成明确且可解释的推理链，分解指示表达，然后利用这些推理来定位目标对象。这一‘先推理后行动’的过程使模型能够更有效地利用有限的标注，提高泛化能力并增强可解释性。", "conclusion": "我们通过三个精心设计的少样本地理空间指示表达基准测试验证了Geo-R1，结果显示，我们的模型在一致性上显著优于SFT基线模型。此外，Geo-R1还展示了强大的跨数据集泛化能力，体现了其鲁棒性。代码和数据将在此处发布：this http URL"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21972", "html_url": "https://arxiv.org/abs/2509.21972", "title": "从表面输出到表面学习：大型语言模型在教育中的风险", "title_en": "From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education", "authors": "Iris Delikoura,Yi.R(May)Fung,Pan Hui", "background": "大型语言模型（LLMs）正在通过个性化、反馈和知识获取改变教育，但同时也引发了对学生成长和学习系统风险的担忧。尽管存在这些风险，但实际证据仍然相对分散。本研究旨在通过系统回顾70项来自计算机科学、教育学和心理学领域的实证研究，探讨这些风险的具体表现。", "innovation": "该研究提出了一个大型语言模型（LLMs）风险适应学习模型，该模型展示了技术风险如何通过互动和解释过程塑造教育成果。这是第一个综合评估LLMs风险的研究，为LLMs在教育中的负责任和以人为本的整合提供了基础。", "conclusion": "研究发现LLMs主要集中在操作有效性、个性化应用和交互式学习工具三个领域。对于LLM在教育应用中的风险，技术风险在交互和解释过程中逐步递进，改变了教育成果。该研究结果为未来LLM在教育中的应用提供了重要参考。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21933", "html_url": "https://arxiv.org/abs/2509.21933", "title": "为什么在临床文本理解中链式思维会失效", "title_en": "Why Chain of Thought Fails in Clinical Text Understanding", "authors": "Jiageng Wu,Kevin Xie,Bowen Gu,Nils Krüger,Kueiyu Joshua Lin,Jie Yang", "background": "大型语言模型（LLMs）在临床护理中的应用日益广泛，而临床领域对准确性和透明推理的要求至关重要。链式思维（CoT）提示可以促进逐步推理，已显现出在多个任务上的性能和可解释性改进，但在临床背景下特别是电子健康记录（EHRs）中的有效性仍少有研究，而EHRs通常是长、断裂且噪声较多的文本记录。本文通过大规模系统研究首次探讨了CoT在临床文本理解中的应用，评估了95种高级LLM在87项实际临床文本任务上的表现，涵盖了9种语言和8种任务类型。结果发现，在CoT环境下，86.3%的模型表现出一致的性能下降，更强的模型表现相对稳定，而较弱的模型则表现较差。进一步分析发现，CoT在临床文本理解中会提升可解释性同时可能导致可靠性下降。", "innovation": "首次大规模系统研究CoT在临床文本理解中的应用效果；评估了95种高级LLM在87项实际临床文本任务上的表现；发现CoT在临床文本理解中的性能分化现象，并通过细粒度分析揭示了其失败模式；提供了临床推理策略的实证基础，强调了透明和可信的方法需求。", "conclusion": "链式思维在临床文本理解中有可能提高解释性但降低可靠性，这揭示了一个关键的悖论；研究结果为用LLM进行临床推理提供了实证基础；强调需要透明和可信赖的方法来应对这一挑战。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21945", "html_url": "https://arxiv.org/abs/2509.21945", "title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "title_en": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "authors": "Pengzhou Chen,Hongyuan Liang,Tao Chen", "background": "许多调优器依赖于代理模型来加速配置调优过程，而非仅依赖于耗费资源的系统测量。然而，先前研究发现准确度并非唯一重要标准，这给代理模型在配置调优中的角色带来了许多未解答的问题。本文通过fitness landscape分析提供了一个系统的探索和讨论，旨在揭示代理模型在配置调优中的多个方面，同时提出了一种基于模型用途的新理论，并通过大规模实证研究验证了该理论，该研究涉及多达27,000个案例。", "innovation": "提出了一种基于fitness landscape的新理论来评估模型在调优中的效用，而不是仅仅依靠准确度。基于此理论进行了广泛的实证研究，并开发了Model4Tune，一种自动化预测工具，能够估算对于未知系统，哪种模型-调优器组合是最优的，而无需进行昂贵的调优器配置分析。这表明Model4Tune在79%-82%的情况下比随机猜测表现更好，这不仅为未来的研究方向提供了新的视角，也为实践者提供了实用的解决方案来评估最合适的模型以进行配置调优。", "conclusion": "研究结果表明，Model4Tune作为一种新颖的自动化预测工具，在配置调优中表现出色，远优于随机猜测。这不仅为未来研究提供了方向，还为实践者提供了评估和选择最佳模型提供了一种实用的方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21991", "html_url": "https://arxiv.org/abs/2509.21991", "title": "ERGO: 高效高分辨率视觉理解的视觉语言模型", "title_en": "ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models", "authors": "Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim", "background": "高分辨率图像在现实世界的视觉语言应用中至关重要。然而，现有的大型视觉语言模型由于视觉标记数量庞大而导致计算负担大。随着‘图像思维’模型的出现，推理能力现在已经从文本扩展到视觉领域。为了解决计算成本问题，本文提出了一种分两阶段的“粗到细”推理管道：首先对下采样的图像进行分析以识别与任务相关的区域；然后仅对这些区域在全分辨率下进行裁剪和后续的推理处理，从而在保持必要细节的同时降低计算成本。", "innovation": "本文提出了ERGO（Efficient Reasoning & Guided Observation）模型，该模型利用感知驱动的推理来确定关注的重点区域。ERGO能够应对感知不确定性，扩大裁剪区域以覆盖视觉模糊区域，从而回答问题。此外，该模型还在强化学习框架中开发了简单的有效奖励组件，以支持粗到细的感知。实验结果显示，ERGO在多个数据集上的准确率高于原始模型和竞争方法，并且使用较少的视觉标记和功耗实现了3倍的推理速度提升。", "conclusion": "ERGO在处理高分辨率图像方面表现出更高的准确率和更高的效率。例如，ERGO在V*基准测试中超过了Qwen2.5-VL-7B 4.7个点，仅使用了23%的视觉标记，达到了3倍的推理速度提升。源代码和模型可以在该链接找到：this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22014", "html_url": "https://arxiv.org/abs/2509.22014", "title": "轻量级结构化多模态推理在机器人临床场景理解中的应用", "title_en": "Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics", "authors": "Saurav Jha,Stefan K. Ehrlich", "background": "医疗机器人需要在动态临床环境中提供稳健的多模态感知和推理，以确保安全性。当前的视觉-语言模型（VLMs）展示了强大的泛化能力，但在时间推理、不确定性估计和结构化输出方面仍然有限，这些都是机器人规划所需的特性。", "innovation": "该研究提出了一个轻量级的多模态框架，用于基于视频的场景理解。该框架结合了Qwen2.5-VL-3B-Instruct模型和基于SmolAgent的交响层，支持链式思考推理、语音-视觉融合以及动态工具调用。通过综合检索模块生成结构化的场景图，并采用混合检索机制进行可解释且适应性强的推理。实验表明，该框架在Video-MME基准和自定义的临床数据集上的精度和鲁棒性优于最先进的VLMs，展示了其在辅助手术、患者监测和决策支持等应用中的潜力。", "conclusion": "该多模态推理框架在医疗机器人领域的应用显示出有竞争力的准确性和提高的鲁棒性，表明其在机器人辅助手术、患者监测和决策支持等领域的应用前景广阔。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21946", "html_url": "https://arxiv.org/abs/2509.21946", "title": "通过反事实校准消除泰语政治态度检测中的偏差", "title_en": "Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration", "authors": "Kasidit Sermsri,Teerapong Panboonyuen", "background": "在资源有限且文化复杂的环境中，大语言模型（LLMs）进行政治立场检测面临重大挑战。泰国的政治环境复杂，存在间接语言、极化人物和情感与立场交织的现象，导致LLMs出现系统性偏差，如情感外泄和对特定实体的支持偏见，这些偏差会影响公平性和可靠性。为此，作者提出了一种轻量级、模型无关的校准框架——ThaiFACTUAL，它通过反事实数据扩充和基于理据的监督来分离情感和立场，减少偏差，而无需微调。此外，他们还公开了一个高质量的泰语政党立场数据集，该数据集包含了立场、情感、理据和针对各种实体和事件的偏差标记。实验结果显示，ThaiFACTUAL能够显著减少随机相关性，增强零样本泛化能力，并提高多个LLMs的公平性。这项工作强调了适应特定语言和文化的去偏差技术的重要性，特别是在少语种的情况下。", "innovation": "提出了一种名为ThaiFACTUAL的轻量级、模型无关的校准框架，通过反事实数据扩充和基于理据的监督来分离情感和立场，减少偏差，而无需微调。公开了一个高质量的泰语政党立场数据集，包含了立场、情感、理据和针对多种实体和事件的偏差标记。实验结果显示，ThaiFACTUAL能够显著减少随机相关性，增强零样本泛化能力，并提高多个LLMs的公平性。", "conclusion": "这项工作强调了适应特定语言和文化的去偏差技术的重要性，特别是在少语种的情况下。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22038", "html_url": "https://arxiv.org/abs/2509.22038", "title": "Latent Diffusion: 多维度稳定的隐空间探索者", "title_en": "Latent Diffusion : Multi-Dimension Stable Diffusion Latent Space Explorer", "authors": "Zhihua Zhong,Xuanyang Huang", "background": "隐空间是生成型AI中的关键概念，通过向量操作提供强大的创意探索工具。然而，扩散模型如Stable Diffusion缺乏与生成对抗网络(GANs)直观的隐向量控制，这限制了它们的艺术表现灵活性。", "innovation": "本文提出了\textit{workname}框架，该框架结合了可定制的隐空间操作进入扩散过程。通过直接操作概念性和空间性表征，该方法扩展了生成艺术的创意可能性。", "conclusion": "通过对\textit{Infinitepedia}和\textit{Latent Motion}两件艺术品的展示，证明了该框架在概念融合和动态运动生成方面的潜力。研究揭示了隐空间结构中的语义与无意义区域，为扩散模型的空间几何结构提供了见解，开辟了隐空间探索的新路径。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21947", "html_url": "https://arxiv.org/abs/2509.21947", "title": "主动攻击：通过自适应环境重新评估LLMs", "title_en": "Active Attacks: Red-teaming LLMs via Adaptive Environments", "authors": "Taeyoung Yun,Pierre-Luc St-Charles,Jinkyoo Park,Yoshua Bengio,Minsu Kim", "background": "这篇论文针对生成用于大型语言模型（LLMs）的安全微调的多样攻击提示这一挑战。传统的做法是手动工程设计攻击提示，而本研究利用强化学习（RL）来训练攻击的LLMs自动生成这些提示，仅需一个毒性分类器作为奖励。然而，捕捉多种有害行为是一个难题，现有的多样性寻求RL方法容易陷入模式单一的问题。为解决这一问题，研究提出了主动攻击（Active Attacks），这是一种适应性攻击的RL算法，能够根据受害者的演化进行自我调整。这种方法天然地包含了从易到难的探索课程，使得攻击者逐步从简单的模式转向更为困难的模式，从而发现更多的攻击模式。", "innovation": "论文提出了主动攻击（Active Attacks），一种利用适应性环境进行红队（Red-teaming）的新型RL算法。该算法通过周期性地对受害的LLMs进行安全微调，并结合收集的攻击提示来最小化已利用区域的奖励，从而迫使攻击者探索未开发的漏洞。这种探索课程使得攻击者能够逐步发现越来越多的攻击模式，并最终覆盖多种模式的分布。主动攻击作为一种简单易用的模块，能够无缝集成到现有的RL目标中，其实验结果显著优于包括GFlowNets、PPO和REINFORCE在内的先前RL基线方法，其中主要对抗GFlowNets的跨攻击成功率从0.07%提升至31.28%，相对增益超过400倍，仅需6%的计算量增加。", "conclusion": "主动攻击通过启发式适应性探索策略克服了现有的单一模式问题，展示了在大规模语言模型安全微调场景中的高效性。未来的研究可以进一步探索该方法在不同攻击场景中的应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22064", "html_url": "https://arxiv.org/abs/2509.22064", "title": "QCET分类学：标准化NLP系统评估质量标准名称和定义", "title_en": "The QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems", "authors": "Anya Belz,Simon Mille,Craig Thomson", "background": "先前的研究表明，报告相同质量标准名称（例如流畅性）的NLP评估实验并不一定评估相同的质量方面，这种名称带来的可比性可能会误导人。不清楚何时两个评估具有可比性，意味着我们目前缺乏基于多个独立开展的评估来可靠地得出系统质量结论的能力。这反过来阻碍了整个NLP领域的科学进步，这一问题自其诞生之初就在NLP领域普遍存在（Sparck Jones, 1981）。除非通过创建一个标准的质量标准名称和定义集将目前实际上在领域内使用的数百种质量标准名称进行映射和扎根，否则难以彻底解决含糊的可比性问题。", "innovation": "QCET Quality Criteria for Evaluation Taxonomy 通过从三次调查NLP评估报告中推导出一组标准的质量标准名称和定义，并将它们结构化为一个层次结构，其中每个父节点捕获其子节点的共同方面，提供了一种规范化的质量标准集。QCET及其包含的资源具有三种主要用途：（i）建立现有评估的可比性；（ii）指导新评估的设计；（iii）评估合规性。", "conclusion": "QCET及其所涉及的资源为解决NLP评估中含糊的可比性问题提供了一个系统性的方法。通过定义明确的质量标准名称和定义，可以帮助研究者和评估者更好地理解和确保评估的一致性和可追溯性，促进NLP领域的科学进展。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22060", "html_url": "https://arxiv.org/abs/2509.22060", "title": "解码欺骗：了解自动语音识别在逃避和投毒攻击中的脆弱性", "title_en": "Decoding Deception: Understanding Automatic Speech Recognition Vulnerabilities in Evasion and Poisoning Attacks", "authors": "Aravindhan G,Yuvaraj Govindarajulu,Parin Shah", "background": "最近的研究表明，自动语音识别（ASR）系统对对抗样本非常敏感，这些对抗样本能够误导这些系统错误地解释输入的语音指令。尽管之前的大部分研究集中于具有受限优化的白盒攻击以及针对商业ASR设备的基于转移性黑盒攻击，但本研究探讨了低成本的白盒攻击以及难以转移的非转移性黑盒攻击，得出了启发自快速梯度签名方法和零阶优化的方法。", "innovation": "本研究的创新点在于探索如何通过中毒攻击降低最先进的模型性能，导致音频信号的误释。通过实验与分析，研究说明混合模型如何生成即使是微小扰动，信号噪声比为35dB且能在一分钟内生成的极具影响力且隐蔽的对抗样本。发现了最先进的开源模型的安全漏洞，强调对抗安全性的重要性。", "conclusion": "最先进的开源ASR模型存在实际的安全问题，这种攻击具有潜在的实用意义。本研究强调了对抗安全性的必要性，并提出了对未来研究和实践应用的建议。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22067", "html_url": "https://arxiv.org/abs/2509.22067", "title": "叛逆的手术刀：激活引导损害LLM安全性", "title_en": "The Rogue Scalpel: Activation Steering Compromises LLM Safety", "authors": "Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Y. Rogov,Ivan Oseledets,Elena Tutubalina", "background": "激活引导是一种有前景的技术，通过在推理过程中直接向模型隐藏状态中添加具有语义意义的向量来控制大型语言模型（LLM）的行为。通常认为，它是比细调更为精准、可解释且潜在更安全的替代方案。然而，本文通过广泛的实验证明了激活引导会系统地违背模型对齐保护机制，使其可以遵从有害请求。即使在随机方向上进行激活引导，有害合规的概率也会从0%增加到2%到27%之间。更令人担忧的是，从稀疏自编码器（SAE）提取的良性特征也会进一步将这些比率提高2%到4%。研究还发现，结合20个随机抽取的使单个提示脱管的向量能形成一种泛化的攻击方法，显著增加了未知请求中的有害合规率。", "innovation": "论文通过实验证明了激活引导会破坏LLM的安全性，即使在随机方向上进行激活引导也会增加有害请求的合规概率。此外，从稀疏自编码器提取的良性特征也会进一步增加这些比率。最后，研究展示了如何结合20个随机抽取的脱管向量来形成一种泛化的攻击方法，显著增加未知请求中的有害合规率。", "conclusion": "本文的研究结果质疑了通过可解释性来保障模型安全的构想，显示了对于模型内部的精确控制并不保证对模型行为的精确控制。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22117", "html_url": "https://arxiv.org/abs/2509.22117", "title": "AI_INFN平台：云中的人工智能开发", "title_en": "The AI_INFN Platform: Artificial Intelligence Development in the Cloud", "authors": "Lucio Anderlini,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Rosa Petrini,Daniele Spiga", "background": "机器学习（ML）正在推动科学家在设计、开发和部署数据密集型软件方面的方式发生革命性的变化。然而，机器学习的采用对计算基础设施提出了新的挑战，特别是在为开发、测试和生产阶段提供和调度硬件加速器访问方面。作为INFN（意大利国家核物理研究所）资助的项目，AI_INFN旨在为INFN的应用场景促进机器学习技术的采用，提供多方面的支持，包括提供支持AI的计算资源。AI_INFN利用INFN云中的云原生解决方案，最大限度地共享硬件加速器，确保研究所多样化的研究活动不受影响。", "innovation": "该平台通过使用Kubernetes平台和虚拟kubelet以及InterLink API，能够简化基于GPU的数据分析工作流的开发，并实现其在异构分布式计算资源上的可扩展性。这种方法可以管理跨越不同资源提供者的工作流，包括参与全球LHC计算网格的各站点和超级计算机如CINECA Leonardo，为需要不同工作负载专用基础设施的应用场景提供了一个模型。", "conclusion": "本文提供了关于Kubernetes平台的更新，该平台设计用于简化GPU驱动的数据分析工作流的开发和可扩展性，同时使用Offloading机制和InterLink API进行资源提供者和服务的管理。初步的测试结果、潜在案例研究和集成场景将通过功能测试和基准测试进行展示和评估。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22058", "html_url": "https://arxiv.org/abs/2509.22058", "title": "基于可靠初始位姿的自适应ICP LiDAR里程计", "title_en": "An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose", "authors": "Qifeng Wang,Weigang Li,Lei Nie,Xin Xu,Wenping Liu,Zhe Xu", "background": "LiDAR里程计作为移动机器人自主导航和定位的关键技术，在自主驾驶应用中被广泛应用。ICP算法因其高效且准确的点云配准能力成为LiDAR里程计的核心技术，然而已有的ICP方法并未考虑初始位姿的可靠性，有可能导致算法陷入局部最优解，同时缺乏自适应机制，难以有效应对复杂动态环境，导致配准精度显著下降。", "innovation": "提出了基于可靠初始位姿的自适应ICP LiDAR里程计方法。该方法首先采用基于密度过滤的分布式粗配准方法获得初始位姿估计，然后通过与运动预测位姿的比较选择可靠初始位姿，减少源和目标点云之间的初始误差。接着，通过结合当前和历史误差动态调整自适应阈值，以适应动态环境的实时变化。最后，基于可靠初始位姿和自适应阈值，进行从当前帧到局部地图的点到面自适应ICP配准，实现源和目标点云的高精度对齐。", "conclusion": "在公共KITTI数据集上的广泛实验表明，所提出的方法优于现有方法，并显著提高了LiDAR里程计的精度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22131", "html_url": "https://arxiv.org/abs/2509.22131", "title": "R-Capsule：压缩高层次计划以实现高效的大语言模型推理", "title_en": "R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning", "authors": "Hongyu Shan,Mingyang Song,Chang Dai,Di Liang,Han Chen", "background": "Chain-of-Thought (CoT) 提示有助于大语言模型（LLMs）处理复杂的推理，通过引发明确的步骤和理由。然而，CoT 的冗长性增加了延迟和内存使用，并可能在长时间链中传播早期错误。因此，有必要提出一种既能高效又能透明处理复杂推理的新方法。", "innovation": "提出了名为 Reasoning Capsule (R-Capsule) 的框架，该框架旨在结合潜在我推理的效率和显式的 Chain-of-Thought (CoT) 的透明性。该框架的核心理念是将高层次计划压缩为一组学习的潜在我令牌（Reasoning Capsule），同时保持执行步骤的重量或显式性。这种混合方法灵感来源于信息瓶颈（IB）原则，其中鼓励胶囊大约尽可能小但仍然足以完成任务。这种方法通过引入低位容量瓶颈来鼓励效率，并通过双重目标来鼓励充分性：主要任务损失以提高答案准确性以及辅助计划重构损失以鼓励胶囊忠实表示原始文本计划。重构目标有助于使潜在空间更加可靠，从而提高可解释性和减少使用无信息捷径。", "conclusion": "框架在保持或提高复杂基准上的准确性的同时，通过减少推理可见的标记足迹，平衡了效率、准确性和可解释性，从而减少所需的标记数量。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22054", "html_url": "https://arxiv.org/abs/2509.22054", "title": "Fuzzy Reasoning Chain (FRC): 从模糊到清晰的一种创新推理框架", "title_en": "Fuzzy Reasoning Chain (FRC): An Innovative Reasoning Framework from Fuzziness to Clarity", "authors": "Ping Chen,Xiang Liu,Zhaoxiang Liu,Zezhou Chen,Xingpeng Zhang,Huan Hu,Zipeng Wang,Kai Wang,Shuming Shi,Shiguo Lian", "background": "随着大型语言模型（LLMs）的快速发展，自然语言处理（NLP）取得了显著的进步。然而，仍然存在处理具有模糊性、多义性或不确定性文本的重大挑战。现有的基于概率的方法无法捕捉传统概率方法无法处理的矛盾或不确定性信号。", "innovation": "提出了一种融合LLM语义先验和连续模糊隶属度的Fuzzy Reasoning Chain（FRC）框架，实现了基于概率的推理与模糊隶属度推理的明确交互。该方法使得模糊输入可以逐步转变为清晰且可解释的决策，并捕捉到传统概率方法无法处理的矛盾或不确定性信号，从而提升了推理的稳定性和知识在不同模型规模之间的迁移能力。", "conclusion": "FRC 提供了一种通用机制来处理微妙且模糊的表达，提高了可解释性和鲁棒性，在情感分析任务中得到了理论分析和实证结果的支持。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22130", "html_url": "https://arxiv.org/abs/2509.22130", "title": "通过离线强化学习和大语言模型协作的多agent路径规划", "title_en": "Multi-Agent Path Finding via Offline RL and LLM Collaboration", "authors": "Merve Atasever,Matthew Hong,Mihir Nitin Kulkarni,Qingpei Li,Jyotirmoy V. Deshmukh", "background": "多agent路径规划(MAPF)是一个在机器人和物流应用中至关重要的显著挑战性问题，主要由于其组合复杂性和现实环境中固有的部分可观测性。去中心化的强化学习方法通常遇到两大问题：首先，它们经常导致agent自中心行为，导致频繁的碰撞；其次，它们对复杂通信模块的依赖使训练周期延长，有时甚至需要数周时间。", "innovation": "我们提出了一个基于决策变换器(DT)的高效去中心化规划框架，通过利用离线强化学习，大幅缩短了从数周到仅仅数小时的训练时间。我们的方法有效地解决了长期信用分配问题，并在稀疏和延迟奖励的情况下显著提高了性能。此外，我们引入了一个大型语言模型（GPT-4o），以动态指导agent策略，克服了标准RL方法在动态环境变化下的适应性限制。", "conclusion": "我们的基于DT的方法，在GPT-4o的简短指导下，在静态和动态变化环境中表现出显著的适应性和性能提高。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21999", "html_url": "https://arxiv.org/abs/2509.21999", "title": "通过不确定表达的一致性实现黑盒幻觉检测", "title_en": "Black-Box Hallucination Detection via Consistency Under the Uncertain Expression", "authors": "Seongho Joo,Kyungmin Min,Jahyun Koo,Kyomin Jung", "background": "尽管近年来语言模型取得了巨大进步，如GPT3这样的大型语言模型（LLMs）在生成非事实性回答方面仍普遍存在‘幻觉’问题。现有的检测和缓解幻觉问题的方法需要依赖外部资源或语言模型的内部状态，例如每个词汇的输出概率。但由于LLMs对外部API的限制和外部资源的有限性，迫切需要建立一种黑盒方法作为有效的幻觉检测基础。", "innovation": "本文在调查LLMs在表达不确定性下的行为后，提出了一个基于表达不确定性的简单黑盒幻觉检测指标。研究发现，当LLMs产生事实性回答时会产生一致的响应，而非事实性回答则相反。基于这一分析，提出了一个高效且基于黑盒的幻觉检测指标。实验表明，该指标在预测模型响应的事实性方面优于依赖LLMs内部知识的基线方法。", "conclusion": "本文通过分析LLMs在表达不确定性时的行为，提出了一种新的基于表达不确定性的黑盒幻觉检测指标。实验结果表明，该指标对于预测模型响应事实性表现更优，为有效检测和缓解语言模型的幻觉问题提供了新的思路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22093", "html_url": "https://arxiv.org/abs/2509.22093", "title": "基于动作意识的动态剪枝以提高视觉语言动作操控的效率", "title_en": "Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation", "authors": "Xiaohuan Pei,Yuxing Chen,Siyu Xu,Yunke Wang,Yuheng Shi,Chang Xu", "background": "现有的使用Vision-Language-Action (VLA) 模型的机器人操控方法通过减少视觉冗余来优化推理速度，但忽视了不同操控阶段视觉冗余的差异性。视觉密集型令牌在推理成本中占有主导地位，不同阶段的动作动态与视觉冗余高度相关。粗粒度的操控阶段视觉冗余高于细粒度操作阶段，因此需要一种能够适应不同操控阶段动态特性的剪枝方法来平衡计算效率和感知精度。", "innovation": "提出了一种基于动作意识的动态剪枝（ADP）方法，该方法结合了基于文本的标记选择和基于动作的轨迹门控机制。ADP通过将剪枝信号条件化于近期动作轨迹，并利用过去的运动窗口来适配地调整标记保留比例，来满足不同操控阶段的需求。这有利于在保持竞争力的同时减少计算量和行为推理延迟，提供了一种易于嵌入的路径来提高机器人策略的效率和性能。", "conclusion": "通过在LIBERO套件和多种真实场景中的广泛实验，该方法在保持成功的前提下显著降低了FLOPs和行为推理延迟。该研究为实现高效的机器人操控策略提供了一个跨时代的框架，在计算效率和感知精度之间取得了平衡。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22102", "html_url": "https://arxiv.org/abs/2509.22102", "title": "基于强化学习的持久性算法救济", "title_en": "Reinforcement Learning for Durable Algorithmic Recourse", "authors": "Marina Ceccon,Alessandro Fabris,Goran Radanović,Asia J. Biega,Gian Antonio Susto", "background": "算法救济旨在为个体提供实际可行的建议，以提高他们从自动化决策系统（如贷款审批）中获得有利结果的机会。虽然先前的研究强调了模型更新的鲁棒性，但对救济措施的时间动态却关注较少，特别是对于竞争性、资源受限的环境，其中推荐会塑造未来的申请池。本研究探讨了如何在推荐系统中考虑时间因素和行为调整，从而提高个体在实施建议后的长期成功率和可行性平衡。", "innovation": "提出了一种新的时间感知算法救济框架，该框架能够明确建模候选人群体因推荐而调整的方式。此外，还提出了一种基于强化学习（RL）的救济算法，该算法能够捕捉环境随时间演变的动态，从而生成在可行性和有效性方面都令人满意的推荐。设计的推荐能够在预定义的时间范围内保持有效，使个人有充分的余地来实施建议，并在之后重新申请。该方法在复杂的仿真环境中进行了广泛的实验，结果显示其在可行性与长期有效性之间的平衡上优于现有基准方法。这一结果强调了在实用的救济系统设计中考虑时间和行为动态的重要性。", "conclusion": "通过实验证明，该方法相较于现有基准方法在可行性与长期有效性方面具有显著优势，强调了在设计实用的救济系统时考虑时间和行为动态的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22161", "html_url": "https://arxiv.org/abs/2509.22161", "title": "向单纯形顶点推进：平滑向量量化中代码折叠的简单解决方案", "title_en": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization", "authors": "Takashi Morita", "background": "在现代机器学习中，向量量化被广泛应用，将连续向量空间离散化为有限数量的代表向量（码本）。尽管有效，向量量化存在一个根本挑战：非可微的量化步骤阻碍了梯度反传播。平滑向量量化通过将码本书中的向量硬分配放松为码本书条目的加权组合（通过单纯形向量和码本书的矩阵乘积表示）来缓解这一问题。有效的平滑需要两个性质：(1) 平滑量化器应接近于一热向量，确保紧密近似，(2) 所有码本书条目都应被利用，避免代码坍塌。现有方法通常分别解决这两个需求。", "innovation": "本文提出了一个简单而直观的正则化方法，该方法通过最小化每个单纯形顶点与其K个最近平滑量化器之间的距离来同时促进这两个需求。实验表明，该方法在代表性基准测试中实现了更可靠的码本书利用，并优于先前的方法。", "conclusion": "在代表性的基准测试，如离散图像自编码和对比语音表示学习中，该方法提高了性能，并实现了更可靠和有效的码本书利用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22166", "html_url": "https://arxiv.org/abs/2509.22166", "title": "LLVM中轻量级错误缓解策略在后训练N:M激活稀疏性中的应用", "title_en": "Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs", "authors": "Shirin Alanova,Kristina Kazistova,Ekaterina Galaeva,Alina Kostromina,Vladimir Smirnov,Redko Dmitry,Alexey Dontsov,Maxim Zhelnin,Evgeny Burnaev,Egor Shvetsov", "background": "对高效大语言模型(LLM)推理的需求推动了对稀疏化技术的关注。尽管半结构化（N:M）剪枝在权重上的应用已经成熟，但将其应用于激活剪枝的探索仍相对不足，尽管这种方法有动态、输入自适应压缩和减少I/O开销的潜力。因此，本文对后训练N:M激活剪枝方法进行了全面分析。", "innovation": "本文提出了轻量级的错误缓解策略，以支持LLM后训练N:M激活稀疏性。实验表明，在相同的稀疏度水平下，剪枝激活能够更好地保持生成能力，这是基于错误的轻量级缓解策略和剪枝准则的评估结果。此外，研究还发现，16:32的稀疏模式在性能上几乎与无结构稀疏模式相当，但由于灵活性和硬件实现复杂性的权衡，作者重点关注8:16模式作为更优候选。", "conclusion": "研究结果提供了有效实用的激活剪枝方法，并为未来硬件支持更灵活的稀疏模式提供了动机。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22115", "html_url": "https://arxiv.org/abs/2509.22115", "title": "学习更少：一种用于高效策略优化的动态双层降采样框架", "title_en": "Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization", "authors": "Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding", "background": "传统的批评免费方法如GRPO（Generalized Robust Policy Optimization）通过从多个部署中估算优势来减少内存需求，但这些方法往往收敛速率较慢，因为关键的学习信号被大量的不具信息量的样本和令牌稀释了。", "innovation": "本文提出了一种名为动态双层降采样（D$^3$S）的框架，以提高策略优化的效率。D$^3$S工作在两个层面：（1）样本层面，通过选择最大化优势方差的子集来提高策略梯度的方程式；（2）令牌层面，优先处理具有高优势值和策略熵乘积的令牌，聚焦于政策既不确定又具有影响力的更新。此外，D$^3$S通过一种动态降采样计划避免过度拟合高信号数据，该计划从积极的降采样开始以加速早期学习，然后逐渐松弛以促进稳健的泛化能力。", "conclusion": "在Qwen2.5和Llama3.1上的广泛实验表明，将D$^3$S集成到先进的强化学习算法中可以实现最先进的性能和泛化能力，同时减少了样本和令牌的数量，适用于各种推理基准。相关的代码已添加在补充材料中，并将公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22199", "html_url": "https://arxiv.org/abs/2509.22199", "title": "模仿梦者：人机演示对齐以实现可扩展的VLA训练", "title_en": "MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training", "authors": "Haoyun Li,Ivan Zhang,Runqi Ouyang,Xiaofeng Wang,Zheng Zhu,Zhiqin Yang,Zhentao Zhang,Boyuan Wang,Chaojun Ni,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang,Zhenbo Song,Xingang Wang", "background": "视觉语言行动（VLA）模型的泛化能力主要依赖于多样化的训练数据，但收集嵌入式机器人互动数据的成本高昂且耗时。相比之下，从人类示范视频中收集数据更为灵活且经济。然而，人类演示视频与机器人执行视频之间存在显著的域差异，包括不稳定的摄像机视角、人类手部与机器人手臂的视觉差异以及动作动态的差异。", "innovation": "我们提出了一种名为MimicDreamer的框架，该框架通过联合对齐视觉、视角和动作，将快速、低成本的人类示范数据转变成可用于机器人使用的监督数据，支持策略训练。具体创新点包括：提出了一种名为H2R Aligner的视频扩散模型，用于生成高保真的机器人示范视频，将人类操作视频中的动作转移到机器人视频；提出了一种名为EgoStabilizer的技术，通过齐次变换和修复由扭曲引起的遮挡和失真来标准化自视角视频；以及将人类手部轨迹映射到机器人参考帧，并应用约束逆运动学求解器以生成可行的、低抖动的关节命令，具有准确的姿态跟踪。", "conclusion": "在我们合成的人类到机器人视频上仅训练的VLA模型能够在真实机器人上实现少样本执行。此外，使用人类数据分析的训练相比仅使用真实机器人数据的模型显著提高了性能，平均成功率提高了14.7%。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22097", "html_url": "https://arxiv.org/abs/2509.22097", "title": "SecureAgentBench：在现实漏洞场景下衡量安全代码生成", "title_en": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios", "authors": "Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo", "background": "大型语言模型（LLM）驱动的代码代理正迅速改变软件工程，通过自动化测试、调试和修复等功能。然而，生成代码的安全风险已成为重要关切。现有基准虽然提供了有价值的见解，但仍不够充分：它们经常忽视了漏洞引入的真实背景，或采用了狭窄的评估协议，无法完全覆盖功能正确性或新引入的漏洞。因此，作者提出SecureAgentBench，这是一种包含105项编码任务的基准，旨在严格评估代码代理在安全代码生成方面的能力。每个任务包括：（i）需要对大型代码库进行多文件编辑的现实任务设置；（ii）基于真实世界开源漏洞的对齐背景，精确标注了引入点；（iii）综合评估体系，结合功能测试、通过概念证明攻击检查漏洞以及使用静态分析检测新引入的漏洞。", "innovation": "引入了SecureAgentBench，这是一种基准，包含105项编码任务，针对安全代码生成严格评估代码代理的能力。每个任务都包含现实的任务设置，基于真实世界的开源漏洞并具有精准的引入点，以及综合评估体系，结合功能测试、通过概念证明攻击检查漏洞以及使用静态分析检测新引入的漏洞。", "conclusion": "结果显示，当前的代理在生成安全代码方面表现不佳，即使最好的SWE-agent支持DeepSeek-V3.1，也只能实现15.2%的正确且安全的解决方案。一些代理尽管能够生成功能正确的代码，但仍会引入漏洞，包括新的未记录漏洞。添加显式安全指令对代理的改进并不显著，这表明需要进一步研究。这些发现确立了SecureAgentBench作为一个严格的基准，用于安全代码生成，并朝向LLM驱动的更可靠软件开发迈出一步。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22119", "html_url": "https://arxiv.org/abs/2509.22119", "title": "通过监督分类模型与大语言模型紧密合作实现通用法律文章预测", "title_en": "Universal Legal Article Prediction via Tight Collaboration between Supervised Classification Model and LLM", "authors": "Xiao Chi,Wenlin Zhong,Yiquan Wu,Wei Wang,Kun Kuang,Fei Wu,Minghui Xiong", "background": "法律文章预测（LAP）是法律文本分类中的关键任务，利用自然语言处理（NLP）技术根据案件描述自动预测相关法律文章。作为法律决策的基础步骤，LAP在后续判决如指控和处罚中起着决定性作用。尽管其重要性，现有方法在处理LAP的复杂性时面临重大挑战。监督分类模型（SCMs），如CNN和BERT，难以全面捕捉复杂的事实模式。与之相反，虽然大语言模型（LLMs）在生成任务中表现出色，但在预测场景中表现欠佳，因为法律文章具有抽象和ID为基础的性质。此外，不同司法管辖区法律系统的多样性进一步加剧了这一问题，因为大多数方法是针对特定国家定制的，缺乏广泛的适用性。", "innovation": "我们提出了一种名为Uni-LAP的通用法律文章预测框架，通过监督分类模型（SCMs）和大语言模型（LLMs）的紧密合作来整合二者的优点。具体而言，在Uni-LAP中，SCM通过引入一种新颖的Top-K损失函数生成准确的候选法律文章，而LLM则采用演绎推理来细化最终预测。我们在来自多个司法管辖区的数据集上对Uni-LAP进行了评估，实验证明我们的方法始终优于现有基准方法，展示了其有效性和通用性。", "conclusion": "我们的研究结果表明，通过Uni-LAP框架，在不同司法管辖区的法律文章预测任务中，能够实现更准确和广泛的适用性，从而为法律决策提供更好的支持。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22184", "html_url": "https://arxiv.org/abs/2509.22184", "title": "通过二次形式学习对称函数", "title_en": "Learning Equivariant Functions via Quadratic Forms", "authors": "Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P", "background": "在该研究中，作者提出了一个学习组（已知或未知）协变函数的方法。特定的组，即正交组，保持特定的二次形式。通过利用这一性质，并在假设对称组是正交的情况下，作者从数据中学习相关的二次形式$x^T A x$，以此揭露潜在的对称组。通过引入适合的归纳偏置，作者在神经网络架构中融入了适合的对称约束，从而得到简化且高效的模型。", "innovation": "作者基于数据学习关联的二次形式$x^T A x$来发现潜在的对称组，并通过正交组的性质简化模型结构，使得模型同时保持不变性并高效学习协变函数。此外，作者进一步将框架扩展到处理元组输入向量上的函数，其中函数通过对角线或乘积组作用。在此扩展中，协变函数分解为仅从归一化后的第一个向量中提炼的角成分和依赖于元组全格拉姆矩阵的尺度不变成分。", "conclusion": "作者对多种任务（如多项式回归、顶夸克标签和惯性矩预测）进行了评估，结果显示与基准方法相比，该模型不仅在发现潜在对称性方面表现优异，还在学习相应的协变函数方面效率更高。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22134", "html_url": "https://arxiv.org/abs/2509.22134", "title": "桥接草案策略偏差：基于组树优化的推测性解码", "title_en": "Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding", "authors": "Shijing Hu,Jingyang Li,Zhihui Lu,Pan Zhou", "background": "推测性解码通过让轻量级的草案模型提出多个候选词，并让目标模型并行验证，从而加速大型语言模型（LLM）的推理。现有训练目标优化的是单一贪婪的草案路径，而解码遵循树策略，重新排序并验证多个分支。这种偏差限制了能够达到的加速效果。", "innovation": "作者引入了Group Tree Optimization (GTO)，它通过两个组件来使训练与解码时的树策略对齐：(i) Draft Tree Reward，一个无需采样的目标，衡量草案树在目标模型下的预期接纳长度，直接度量解码性能；(ii) 基于组的草案策略训练，一种稳定的优化方案，对比当前和冻结的参考草案模型的树，形成去偏差的组标准化优势，通过按最先接受的序列应用类似PPO的判别器进行稳健更新。进一步证明了提高Draft Tree Reward可以提升接纳长度和加速效果。在对话、代码和数学任务以及多个LLM上，GTO相比前者的EAGLE，增加了7.4%的接纳长度并额外提供7.7%的加速。", "conclusion": "通过桥接草案策略偏差，GTO提供了一种实用且通用的高效LLM推理解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22139", "html_url": "https://arxiv.org/abs/2509.22139", "title": "Refine-Control: 半监督蒸馏方法在条件图像生成中的应用", "title_en": "REFINE-CONTROL: A Semi-supervised Distillation Method For Conditional Image Generation", "authors": "Yicheng Jiang,Jin Yuan,Hua Yuan,Yao Zhang,Yong Rui", "background": "基于文本控制的条件图像生成模型已经取得了显著成果，但这些模型对资源的需求高，并且高质量标注数据稀缺，这阻碍了它们在边缘设备上的部署。这导致了巨大的成本和隐私问题，尤其是当用户数据被发送到第三方时。", "innovation": "我们提出了Refine-Control，这是一种半监督蒸馏框架，通过引入三级知识融合损失来传递不同层次的知识，以此提升学生模型的性能。为了增强泛化能力和缓解数据集稀缺性，我们引入了一种利用标签数据和未标记数据的半监督蒸馏方法。实验结果显示，Refine-Control在减少计算成本和延迟的同时，保持了高保真生成能力和可控性，量化指标表明这一点。", "conclusion": "我们的实验表明，Refine-Control在降低计算成本和延迟的同时，能够实现高质量的图像生成，并且保持良好的可控性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22144", "html_url": "https://arxiv.org/abs/2509.22144", "title": "从长到精：基于多轮精炼的性能感知和自适应链式思维压缩", "title_en": "From Long to Lean: Performance-aware and Adaptive Chain-of-Thought Compression via Multi-round Refinement", "authors": "Jianzhi Yan,Le Liu,Youcheng Pan,Shiwei Chen,Zike Yuan,Yang Xiang,Buzhou Tang", "background": "链式思维（CoT）推理可以提高复杂任务的表现，但会因为涉及大量推理过程而引入显著的推理延迟。为了解决这一问题，本研究引入了一种新的框架——多轮自适应链式思维压缩（MACC），该框架利用了令牌弹性现象，即过于小的令牌预算可以意外地增加输出长度，从而逐步压缩CoT并通过多次迭代精炼。这种方法使MACC能够为每个输入确定最佳的压缩深度，从而既提高了准确性，又降低了CoT的长度并降低了延迟。此外，研究还表明，通过使用可解释的特征如困惑度和压缩率，可以可靠地预测测试时间的表现，在不同的模型中实现高效的选择和预测，无需重复微调，证明了CoT压缩的有效性和可预测性。", "innovation": "提出了多轮自适应链式思维压缩框架（MACC），利用令牌弹性现象，以多轮迭代精准压缩CoT，确定最佳压缩深度，提高了准确性并降低了CoT的长度和延迟。此外，通过训练集上的可解释特征如困惑度和压缩率，可靠地预测了测试时间的表现，实现了模型的选择和预测，无需重复微调。", "conclusion": "与最新的基准模型相比，该方法在平均准确度上提高了5.6％，同时将CoT长度平均减少了47个令牌，显著降低了延迟。进一步研究验证了CoT压缩的有效性和可预测性，显示了MACC在不同模型中的高效性和潜在应用前景。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22218", "html_url": "https://arxiv.org/abs/2509.22218", "title": "VizGen: 使用多代理AI架构从自然语言进行数据探索和可视化", "title_en": "VizGen: Data Exploration and Visualization from Natural Language via a Multi-Agent AI Architecture", "authors": "Sandaru Fernando,Imasha Jayarathne,Sithumini Abeysekara,Shanuja Sithamparanthan,Thushari Silva,Deshan Jayawardana", "background": "传统数据可视化工具往往需要用户具备一定的技术背景，这限制了数据可视化工具的广泛使用。VizGen是一种人工智能辅助的图形生成系统，它允许用户通过自然语言生成有意义的可视化成果。", "innovation": "VizGen利用先进的自然语言处理（NLP）和大规模语言模型（LLMs），如Claude 3.7 Sonnet和Gemini 2.0 Flash，将用户的查询转换成SQL语句，并推荐合适的图表类型。系统基于多代理架构，能够处理SQL生成、图表创建、个性化定制和洞察提取等功能，并在数据中发现模式、异常和相关性，同时通过与互联网收集的上下文信息提供解释，使数据探索和分析更加直观和易于理解。", "conclusion": "VizGen通过桥梁技术复杂性和用户友好型设计之间的鸿沟，实现了数据可视化的普及。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22168", "html_url": "https://arxiv.org/abs/2509.22168", "title": "教AI感受：一种全身探索情感交流的协作性实践", "title_en": "Teaching AI to Feel: A Collaborative, Full-Body Exploration of Emotive Communication", "authors": "Esen K. Tütüncü,Lissette Lemus,Kris Pilcher,Holger Sprengel,Jordi Sabater-Mir", "background": "本研究探讨了一种基于全身动作追踪和实时AI反馈的交互装置Commonaiverse，通过三个阶段（教学、探索和宇宙阶段）促进人类情感的表达和解读。该装置利用MoveNet进行精确的动作追踪，并结合多推荐AI系统动态分析情绪状态，以适应性的音频和视觉输出做出响应。研究指出，这种从顶部定义情绪分类向参与者驱动及文化多样性定义的转变，突出了情感计算包容性和伦理性的新路径。", "innovation": "该研究 introduces一种新颖的情感交流方式，将情感表达从传统的面部分析扩展到了基于全身动作和实时AI反馈的更加身临其境的合作方式。通过这一点，研究推动了多媒体研究向更富有情感参与和共创情感AI范式的转变，强调了用户的主体性和减少了偏见，并为更高级的互动应用打开了新途径。", "conclusion": "这种协作性、凌驾于常规之外的方法促进了多媒体研究的进一步发展，超越了单一用户面部分析，向一种更基于身体、共同创造的情感AI范式转变。同时，新的框架促进了用户自主性、减少了偏见，并为更高级的互动应用提供了新机会。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22222", "html_url": "https://arxiv.org/abs/2509.22222", "title": "基于单张图像的感知 rigid 性3D 高斯形变", "title_en": "Rigidity-Aware 3D Gaussian Deformation from a Single Image", "authors": "Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo", "background": "在计算机视觉和图形学中，从单张图像重构对象变形仍然是一个显著的挑战。现有方法通常依赖多视图视频来恢复变形，这限制了它们在受限场景中的应用。", "innovation": "本文提出了一种新颖的框架DeformSplat，仅利用一张图像有效地引导3D高斯变形。该方法的主要创新点包括：1) 提出了Gaussian-to-Pixel Matching，该技术填补了3D高斯表示与二维像素观察之间的领域差距，从而实现基于稀疏视觉线索的鲁棒性变形引导；2) 提出了刚性部分分割（Rigid Part Segmentation），包括初始化和细化，该分割明确识别刚性区域，这对于保持变形过程中的几何一致性至关重要。通过结合这两个技术，该方法可以从单张图像中重构一致的变形。", "conclusion": "大量实验表明，本方法显著优于现有方法，并且可以自然地扩展到各种应用中，例如帧插值和交互式对象操作。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22174", "html_url": "https://arxiv.org/abs/2509.22174", "title": "提升去中心化优化效率：最小开销的邻域聚合重新想象", "title_en": "Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead", "authors": "Durgesh Kalwar,Mayank Baranwal,Harshad Khadilkar", "background": "在当前注重数据安全的环境中，分布式学习作为一种重要的工具逐渐浮现，既增强了隐私保护措施，又简化了计算操作。尤其是在完全去中心化的基础设施中，由于缺乏中心化的聚合，必须采用本地处理方式。论文提出了DYNAWEIGHT框架，实现多代理网络中的信息聚合，在不显著增加通信和内存开销的情况下，极大地提升了去中心化学习的速度与效率。", "innovation": "DYNAWEIGHT框架动态分配权重给相邻服务器，基于其在本地数据集上的相对损失，特别适用于数据异质性较大的场景。相比之下，传统的静态权重分配方法如Metropolis权重无法实现这一点。实验结果显示，DYNAWEIGHT不仅加速了训练过程，还能与任何底层优化算法兼容，展现了其广泛的适用性和集成潜力。", "conclusion": "DYNAWEIGHT框架在多种数据集（MNIST, CIFAR10, CIFAR100）上进行了实验验证，结果表明其在训练速度上有了显著提升。此外，它不受特定优化算法的限制，具有很高的灵活性，预期在未来的研究和实际应用中能够得到广泛应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22225", "html_url": "https://arxiv.org/abs/2509.22225", "title": "基于匹配式掩膜提升的多义语言高斯碎片化", "title_en": "Polysemous Language Gaussian Splatting via Matching-based Mask Lifting", "authors": "Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li", "background": "将2D开放词汇理解提升到3D高斯碎片化（3DGS）场景是一个关键挑战。主流方法存在三个主要问题：（i）需要在每个场景重新训练，阻止即插即用的应用；（ii）限制性的单义设计无法表示复杂、多概念语义；（iii）对视点间语义不一致的脆弱性损害了最终的语义表示。", "innovation": "引入了MUSplat，这是一个无需训练的框架，完全摒弃了特征优化。利用预训练的2D分割模型，我们的流程生成并提升多粒度的2D掩膜到3D空间，估算每个高斯点的前景概率，形成初步对象组。接着，使用语义熵和几何透明度优化这些初步组的模糊边界。之后，通过解释对象在最具代表性的视角下的外观，视觉-语言模型（VLM）提取出稳健的文本特征，解决了视觉不一致问题，通过语义匹配支持开放词汇查询。通过消除每个场景的昂贵训练过程，MUSplat将场景适应时间从数小时缩短至数分钟。", "conclusion": "在基准任务中，MUSplat在开放式3D对象选择和语义分割方面优于现有基于训练的框架，同时解决了它们的单义限制。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22206", "html_url": "https://arxiv.org/abs/2509.22206", "title": "大语言模型的输出是无意义的", "title_en": "The Outputs of Large Language Models are Meaningless", "authors": "Anandi Hattiangadi,Anders J. Schoubye", "background": "本文基于对大语言模型（LLMs）输出意义的研究背景，探讨了LLMs生成的语言输出是否具有实际意义的问题。文章指出，传统观点认为LLMs的输出具有一定的意义，然而本文认为这种输出是无意义的。文章通过分析LLMs生成过程中需要某些意图以及这些意图在LLMs中难以实现的基础前提进行论证。", "innovation": "文章提出了关于大语言模型输出无意义的重要论点，强调了在Llyn生成过程中的意图问题，并且回应了关于意图可被外部因素替代或内在关系定义的反驳观点。这为理解大语言模型的输出提供了新的视角。", "conclusion": "即使本文提出的论证是有效的，大语言模型的输出仍然出现在某种意义上是‘有意义的’，可以用于获得真实信念甚至知识。这说明虽然从理论上讲LLMs的输出无意义，但在实际应用中其输出结果仍有其价值和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22207", "html_url": "https://arxiv.org/abs/2509.22207", "title": "具有一致的双向动态的可逆 GNS 辅助耗散流体", "title_en": "Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics", "authors": "Mu Huang,Linning Xu,Mingyue Dai,Yidi Shao,Bo Dai", "background": "物理模拟中，模拟物理上合理的轨迹以实现用户定义的目标是一项基础但具有挑战性的任务，尤其是在耗散系统中，因为其动力学是不可逆的。尽管基于粒子的模拟器在实现正向动力学方面可以高效地运作，但对于反向推导（逆向推断）来说依然困难重重，尤其在运用基于优化的求解器时，求解速度慢、不稳定且往往无法收敛。", "innovation": "本文提出了一种名为R-GNS（Reversible Graph Network Simulator）的统一框架，它在单一的图形架构中实现了双向一致性。R-GNS根据残差可逆的消息传递设计，并共享参数，将前向动力学与反向推理耦合，从而提供了精准预测和高效的初始状态恢复。与基于优化的基础模型相比，R-GNS在耗散系统基准测试（Water-3D、WaterRamps、WaterDrop）中表现出了更高的准确性和一致性，同时只为使用了一四分之一的参数，并且反向推断的速度快了超过100倍。对于前向模拟，R-GNS的速度与强大的GNS基线相当，而在目标条件任务中，它能够消除迭代优化并实现几个数量级的速度提升。", "conclusion": "在目标条件任务中，R-GNS展示了其能够生成复杂目标形状（如字符“L”和“N”）的生动且物理上一致的轨迹。据我们所知，这是首次统一前向和反向模拟的可逆框架，适用于耗散的流体系统。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22211", "html_url": "https://arxiv.org/abs/2509.22211", "title": "基于问题导向的分析与合成：使用大语言模型构建可解释的主题树以进行文本聚类和可控生成", "title_en": "Question-Driven Analysis and Synthesis: Building Interpretable Thematic Trees with LLMs for Text Clustering and Controllable Generation", "authors": "Tiago Fernandes Tavares", "background": "无监督文本语料库分析在数据稀缺领域中尤其具有挑战性，传统的主题模型在此类数据中表现不佳。这些模型虽然能够提供解决方案，但通常使用关键词列表来描述聚类，这需要大量的手动努力来解释，并且常常缺乏语义连贯性。因此，解决这一关键的可解释性差距是必要的，尤其是在需要深入理解数据模式的情况下。", "innovation": "本文提出了递归主题分区（RTP）框架，这是一种使用大规模语言模型（LLMs）进行交互式构建二叉树的方法。每个树节点都是一个自然语言问题，能够语义分割数据，从而生成一个完全可解释的分类系统，其中每个簇的逻辑显式清晰。RTP的方法通过问题导向的层次结构提高了聚类的可解释性，相比于像BERTopic这样的强基线模型的基于关键词的主题具有优势，并且展示了这些簇在下游分类任务中的量化用途，尤其是在数据的基本主题与任务标签相关时更为有效。此外，RTP为数据探索引入了新的范式，从统计模式发现转向知识驱动的主题分析。同时，RTP展示出主题树的路径可用于生成模型的结构化、可控提示，这转而将分析框架转化为强大的合成工具，能够一致性地模仿源头语料库中发现的特定特征。", "conclusion": "递归主题分区通过引入基于问题导向的层级结构解决了聚类的可解释性问题，显著地提高了用户对数据的理解能力。除了聚类应用外，RTP还展示了生成模型的有效使用场景，进一步拓展了其在文本合成和可控生成领域的应用潜力，为未来的文本分析和生成任务提供了新的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22219", "html_url": "https://arxiv.org/abs/2509.22219", "title": "Automatic Discovery of One Parameter Subgroups of $SO(n)$", "title_en": "Automatic Discovery of One Parameter Subgroups of $SO(n)$", "authors": "Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P", "background": "一个参数子群（$H_{\\gamma}$）在机器人学、量子力学和分子结构分析等多种应用中至关重要。目前缺乏自动化发现$SO(n)$的一个参数子群的方法，因此作者提出了一种新框架来实现自动发现$SO(n)$的一参数子群，不仅仅局限于$SO(3)$。该框架通过使用标准的Jordan形式来处理反对称矩阵的李代数，从而在$H_{\\gamma}$的作用下建立了轨道的典范形式，并利用这一形式来推导出$H_{\\gamma}$-不变函数的标准表示形式。通过对适当的参数进行学习，该框架能够揭示出潜在的一参数子群结构。", "innovation": "该论文提出了一个新颖的框架，用于自动发现$SO(n)$的一参数子群。该框架使用标准Jordan形式处理反对称矩阵的李代数，从而在$H_{\\gamma}$的作用下建立轨道的典范形式，并通过学习适当的参数推导出$H_{\\gamma}$-不变函数的标准表示。此外，该方法通过实验证明了在双摆模拟、预测转动惯量、顶夸克标记和不变多项式回归等任务中的有效性，成功恢复了一参数子群的结构并产生了可解释的、对称意识的表示形式。", "conclusion": "该框架能够有效地发现$SO(n)$的一参数子群，并生成对称感知的机器学习表示，适用于广泛的科学技术应用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22237", "html_url": "https://arxiv.org/abs/2509.22237", "title": "FeatBench: 评估编码代理在特征实现方面的vibe编码能力", "title_en": "FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding", "authors": "Haorui Chen,Chengze Li,Jia Li", "background": "大型语言模型（LLMs）的迅速发展带来了“vibe coding”这一新的软件开发范式，用户可以通过高阶自然语言与编码代理进行交互。然而，现有代码生成评估基准无法充分评估代理的vibe coding能力，因为这些基准要么需要代码级别规格，要么仅仅聚焦于问题解决，忽视了特征实现这一关键场景。", "innovation": "本文提出了一个名为FeatBench的新颖基准，专注于特征实现。FeatBench具有以下创新点：1. 纯自然语言提示。任务输入仅包含抽象的自然语言描述，没有任何代码或结构提示。2. 严谨且不断演化的数据收集过程。通过多层次过滤管道确保高质量，并采用完全自动化的流程更新基准，以避免数据污染。3. 全面的测试用例。每个任务包括从失败到成功（F2P）和从成功到成功（P2P）测试，以验证正确性并防止倒退。4. 多元的应用领域。基准包括来自不同领域的仓库，以确保其反映现实场景。", "conclusion": "我们对两种最先进的代理框架和四种领先的大语言模型在FeatBench上进行了评估。我们的评估表明，特征实现是vibe coding范式中的一个重大挑战，最高的成功率仅为29.94%。我们的分析还揭示了一种“激进实现”策略的倾向，这种策略不仅会导致关键失败，还会导致优质的软件设计。我们发布了FeatBench、自动数据收集管道以及所有实验结果，以促进进一步的社区研究。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22224", "html_url": "https://arxiv.org/abs/2509.22224", "title": "多模式思考：如何使大型语言模型在有限数据下通过复合推理提升性能", "title_en": "Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data", "authors": "Zishan Ahmad,Saisubramaniam Gopalakrishnan", "background": "大型语言模型（LLMs）尽管表现出色，但在处理需要多种认知策略的复杂问题上受限，因为它们依赖单一的推理模式。基于此，本文提出了复合推理（CR）方法，旨在帮助LLMs动态地探索并组合不同类型的推理方式，如演绎、归纳和反推。研究在科学和医学领域的问题回答基准上进行了评估，表明该方法在多个评估基准上优于现有的链式思维（CoT）等基线方法，并且在样本效率和令牌使用方面更有优势，能在有限数据下取得较好的效果。实验结果显示，CR在不同领域内倾向于使用最适合的推理模式，例如在医学问题回答中偏向使用反推和演绎推理，在科学问题回答中则更倾向于因果、演绎和归纳词法。", "innovation": "本文提出了一种新的复合推理方法（CR），旨在让大型语言模型（LLMs）能够动态探索和组合多重理解决策方式，增强其在复杂问题上的表现。这种方法能够在有限的数据下，通过增加内部推理模式的多样性，提高模型的鲁棒性、适应性和效率，从而表现出更高的问题解决能力。CR方法能够根据不同领域的特性，智能地选择和应用最合适的推理策略，表现出显著的优势。", "conclusion": "在多模式问题解决能力的引导下，LLMs的推理方法得到了增强，提升了处理复杂问题时的全面性、灵活性和效率。CR方法不仅在多项基准测试中超越了现有的基线方法，还在实际应用场景中展示了其优越的性能，证明了其有效性和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22216", "html_url": "https://arxiv.org/abs/2509.22216", "title": "集体行为的自动驾驶车辆对城市交通动态的影响：一种多智能体强化学习方法", "title_en": "Impact of Collective Behaviors of Autonomous Vehicles on Urban Traffic Dynamics: A Multi-Agent Reinforcement Learning Approach", "authors": "Ahmet Onur Akman,Anastasia Psarou,Zoltán György Varga,Grzegorz Jamróz,Rafał Kucharski", "background": "本文研究了强化学习（RL）赋能的自动驾驶车辆（AV）对混合交通环境下的城市交通流的潜在影响。研究集中在多智能体环境中的一种简化的日间路线选择问题上。文章考虑了一个城市网络，其中人类驾驶者通过选择最短的旅行时间路线到达目的地。然后，将人口的三分之一比例转化为AV，它们作为使用深度Q学习算法的RL代理。定义了一系列优化目标，或我们称之为行为，包括自私、合作、竞争、社会、利他主义和恶意。通过奖励的方式分别对AV施加所需的特定行为。使用自主开发的RL框架PARCOUR进行了模拟，结果显示AV通过5%的最大优化时间，由于AV行为的不同对人类驾驶者旅行时间的影响也不同。所有情况下，AV采取自我利益行为都能实现比人类驾驶者更短的旅行时间。研究发现每种目标行为的学习任务复杂性不同，并证明多智能体RL设置可以通过交通网络实现集体路由，虽然不同行为对共存方的影响差异巨大。", "innovation": "提出了使用多智能体强化学习方法来研究AV对城市交通的影响。通过定义不同的行为目标，如自私、合作、竞争、社会、利他主义和恶意，分别对AV施加特定行为，从而观察不同行为对交通流的影响。利用自主开发的RL框架PARCOUR进行模拟，揭示了AV在不同行为下对人类驾驶者旅行时间的不同影响。", "conclusion": "本研究展示了AV在不同行为下的优化效果和对城市交通流的影响。尽管AV能够优化自己的旅行时间，但在不同的行为模式下，对共存的人类驾驶者的影响有所不同。研究突出了集体行为在多智能体RL设置中的应用潜力，但强调了不同行为在影响共存交通参与者方面的重要差异性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22280", "html_url": "https://arxiv.org/abs/2509.22280", "title": "能源领域的全球网络威胁分析：地缘政治视角下的冲突潮流", "title_en": "A Global Analysis of Cyber Threats to the Energy Sector: \"Currents of Conflict\" from a Geopolitical Perspective", "authors": "Gustavo Sánchez,Ghada Elbez,Veit Hagenmeyer", "background": "网络威胁的频率和 sophistication 水平不断提高，增强了对其全面理解的需要。本文探讨了地缘政治动态、网络威胁情报分析与先进检测技术的交叉点，并特别关注能源领域。", "innovation": "利用生成式人工智能从原始网络威胁描述中提取和结构化信息，以增强分析能力；通过多数据库进行地缘政治对比，研究威胁行为者来源和目标区域的趋势；评估基于学习的网络安全工具的有效性，在能源目标攻击中检测恶意活动的迹象。", "conclusion": "此分析提供了新的见解，为研究人员、政策制定者和网络安全专业人员提供了可操作的信息。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22251", "html_url": "https://arxiv.org/abs/2509.22251", "title": "超越文本上下文：适应性空间对齐的结构图编码以缓解LLMs的幻觉", "title_en": "Beyond Textual Context: Structural Graph Encoding with Adaptive Space Alignment to alleviate the hallucination of LLMs", "authors": "Yifang Zhang,Pengfei Duan,Yiwen Yang,Shengwu Xiong", "background": "当前，大型语言模型（LLMs）在应对幻觉问题时主要依赖于知识图谱（Knowledge Graphs，KGs）。然而，LLMs通常将KGs视为纯文本，仅提取其语义信息而忽略了其关键的结构方面。另一个挑战是KGs编码器的嵌入空间与LLMs文本嵌入空间之间的差距，这阻碍了结构化知识的有效集成。", "innovation": "提出了SSKG-LLM，这是一种新颖的模型架构，旨在高效地将KGs的结构和语义信息整合进LLMs的推理过程中。SSKG-LLM结合了知识图谱检索（Knowledge Graph Retrieval，KGR）模块、知识图谱编码（Knowledge Graph Encoding，KGE）模块以保持语义并利用结构，并引入知识图谱适应（Knowledge Graph Adaptation，KGA）模块以使LLMs能够理解KGs的嵌入。通过广泛的实验和详细分析，探讨了整合KGs的结构信息如何增强LLMs的事实推理能力。", "conclusion": "研究通过SSKG-LLM展现了结构信息在增强LLMs事实推理能力方面的潜力，并通过实际实验验证了其有效性。相关代码可从this https URL获得。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22250", "html_url": "https://arxiv.org/abs/2509.22250", "title": "安全合规：从合规的角度重新审视大语言模型安全推理", "title_en": "Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance", "authors": "Wenbin Hu,Huihao Jing,Haochen Shi,Haoran Li,Yangqiu Song", "background": "大语言模型（LLMs）的普及展示了卓越的能力，突显了LLMs安全性的关键重要性。然而，现有的安全性方法依赖于杂乱无章的分类体系，并缺乏系统、严谨的保护方法，无法确保现代LLM系统的复杂和微妙行为的安全性。现有方法未能充分考虑到法律合规性在大语言模型安全性中的作用，也没有提供系统的方法来评估LLM是否遵守现有的法律框架。因此，本文从法律合规性的角度重新思考大语言模型的安全性，提出了安全合规的概念，并基于此提出了新的评估标准和方法。", "innovation": "本文从法律合规性角度提出了LLM的安全合规（Safety Compliance）概念，并以此为基础开发了一个新的安全合规基准。通过组策略优化（GRPO）对Qwen3-8B进行调整，构建了一个合规推理器（Compliance Reasoner），该推理器能够有效使LLM与法律法规标准进行对齐，从而降低安全风险。实验结果表明，合规推理器在新的基准测试中的表现明显优于现有方法，显著提升了LLM的安全性评估和遵守法律法规的能力。", "conclusion": "本文通过构建合规推理器，将现有法律框架（如欧盟AI法案和GDPR）融入到大语言模型的安全性评估中，显著提升了LLM的安全性表现。这种新方法不仅能够确保大语言模型遵守现行法律法规，还能够有效应对大语言模型复杂和微妙的行为所带来的安全问题。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22246", "html_url": "https://arxiv.org/abs/2509.22246", "title": "ASSESS: 一种语义和结构评价框架以评估语句相似性", "title_en": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity", "authors": "Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo", "background": "语句自动形式化，即将自然语言翻译成形式语言的过程，已经取得了显著的进步，但自动评价标准的发展仍然有限。现存的形式化语句相似性度量往往无法平衡语义和结构信息。基于字符串的方法捕获了语法结构，但忽视了语义意义；基于证明的方法验证了语义等价性，却忽略了结构细微差别，并且在证明失败时无法提供分级的相似度得分。为了应对这些问题，我们引入了ASSESS（语义和结构评价框架），它全面整合了语义和结构信息以提供连续的相似度得分。该框架首先将形式化的语句转换为操作符树，以捕捉其语法结构，并使用我们的新型TransTED（变换树编辑距离）相似度度量进行相似度计算，该度量通过变换增强了传统的树编辑距离，以增强其语义意识。", "innovation": "我们提出了ASSESS框架，它通过操作符树捕获语句的语法结构，并使用我们的新型TransTED（变换树编辑距离）相似度度量进行相似度计算。此度量通过变换增强了传统的树编辑距离，以增强其语义意识。为了严谨验证，我们提出了EPLA（证明可验证性和相似性评估基准），这是一个由524对专家注释的形式化语句对构成的新基准，来自miniF2F和ProofNet，包括语义可验证性和结构相似性标签。实验结果表明，TransTED相似度远远超过了现有方法，达到了最先进的准确率和最高的Kappa系数。", "conclusion": "ASSESS框架和EPLA基准很快将公开，这一研究提出了对于形式化陈述相似性的全面评价框架，实现了最先进的评价效果，填补了现有评价标准的不足。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22232", "html_url": "https://arxiv.org/abs/2509.22232", "title": "Fairness-Aware Reinforcement Learning (FAReL): 透明且平衡的序列决策框架", "title_en": "Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making", "authors": "Alexandra Cimpean,Nicole Orzan,Catholijn Jonker,Pieter Libin,Ann Nowé", "background": "在实际序列决策问题中，可以通过公平性意识方法来实现公平性。因此，需要算法能够在性能和期望的公平性观念之间进行适当的、透明的权衡。由于性能-公平性权衡在事先难以明确指定，本文提出了一种框架，可在其中探索多个权衡。通过强化学习算法提供的见解，可以指导利益相关者选择最合适的选择策略。为了捕捉公平性，本文提出了一种扩展马尔可夫决策过程（fMDP），它明确编码了个人和群体。在给定fMDP的情况下，我们从公平性的角度提出了序列决策问题中的公平性理念，并制定了一个公平性框架，以随着时间的推移计算公平性指标。我们在这两个具有不同公平要求的情景中评估了我们的框架：招聘工作，需要组建强大的团队同时平等对待申请人，欺诈检测，需要检测欺诈交易同时公平地分配给客户负担。我们证明了该框架学习到的策略在多个场景中具有更多的公平性，同时仅对性能奖励有轻微的损失。此外，我们观察到群体公平性和个人公平性不可能互为充要条件，在期望同时获得两者公平性的场景中，我们的框架具有优势。最后，我们提供了在不同问题设置中应用该框架的指南。", "innovation": "本文提出的fMDP扩展马尔可夫决策过程，明确编码了个人和群体，用来平衡性能与公平性；提出了一个公平性框架，能够在不同场景下评估公平性指标；通过实际应用（招聘工作、欺诈检测）验证了该框架在实现多场景之间的平衡公平性方面具有优势；揭示了群体公平性和个人公平性之间的非互含关系，强调了这一框架的适用性。", "conclusion": "本文提出了Fairness-Aware Reinforcement Learning (FAReL)框架，通过探索性能和公平性之间的权衡关系，为复杂序列决策问题提供了一种更加公平和透明的解决方案。该框架不仅适用于招聘工作，还适用于欺诈检测等多种场景，并能够在这两个方面获取满意的绩效和公平性。同时，通过对比不同场景下的公平性指标，进一步探讨了群体公平性和个人公平性之间的关系。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22259", "html_url": "https://arxiv.org/abs/2509.22259", "title": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs", "title_en": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs", "authors": "Isaac Reid,Arijit Sehanobish,Cedrik Höfs,Bruno Mlodozeniec,Leonhard Vulpius,Federico Barbero,Adrian Weller,Krzysztof Choromanski,Richard E. Turner,Petar Veličković", "background": "该论文介绍了WIRE（Wavelet-Induced Rotary Encodings），它扩展了在大型语言模型（LLMs）和视觉 Transformer（ViTs）中流行的旋转位置编码（RoPE）方法，应用于结构化为图形的数据。研究表明，WIRE比RoPE更具通用性，并且拥有许多理论上的良好属性，如节点排序置换不变性、线性注意力兼容性以及在某些假设下对图电阻距离的渐近依赖性。", "innovation": "WIRE的独特之处在于它将RoPE方法扩展到了图形结构数据上，证明了WIRE比RoPE更通用，并以网格图为例恢复了RoPE。此外，WIRE还具有多项理论性质，如节点排序置换不变性、线性注意力兼容性，在某些假设下对图电阻距离的渐近依赖性。", "conclusion": "实验表明，WIRE在图结构重要的应用场景中表现有效。测试了WIRE在合成和真实世界任务上的表现，包括识别单色子图、点云语义分割以及更多标准图基准。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22292", "html_url": "https://arxiv.org/abs/2509.22292", "title": "通过场景分割策略对文本到视频模型进行越狱", "title_en": "Jailbreaking on Text-to-Video Models via Scene Splitting Strategy", "authors": "Wonjun Lee,Haon Park,Doehyeon Lee,Bumsub Ham,Suhyun Kim", "background": "随着众多文本到视频（T2V）模型的快速发展，人们对这些模型的安全风险越来越担忧。尽管近期研究已经通过针对诸如大模型（LLMs）、视觉语言模型（VLMs）和文本到图像（T2I）模型的{jailbreak}攻击来探讨其漏洞，但针对T2V模型的安全性研究仍相对空白，存在显著的安全缺口。为此，作者提出了一个创新的方法，名为SceneSplit，这是一种新型的黑盒{jailbreak}方法，通过将有害叙事分裂成多个场景，每个场景本身都是无害的，来解决这一缺口。这种策略通过操纵生成输出空间，即为给定提示的所有潜在视频输出的抽象集合，并利用场景组合作为强大约束来引导最终效果。这种方法通过迭代场景操纵进一步增强，以绕过受限的不安全区域内内置的安全过滤器，并通过重用成功的攻击模式策略库来提升攻击的整体有效性和鲁棒性。", "innovation": "作者提出了一种名为SceneSplit的创新方法，通过将有害叙事分割成多个单独无害的场景，来实现T2V模型的{jailbreak}。这种方法通过操纵生成输出空间，并利用场景组合作为强大约束来引导最终效果。迭代场景操纵进一步增强机制，通过绕过受限的不安全区域内内置的安全过滤器，并通过重用成功的攻击模式策略库来提升攻击的有效性和鲁棒性。", "conclusion": "通过在T2V模型上进行评估，作者展示了SceneSplit方法在Luma Ray2、Hailuo和Veo2上的平均攻击成功率（ASR）分别达到了77.2%、84.1%和78.2%，显著优于现有基线。这种方法揭示了当前T2V安全机制容易受到利用叙事结构的攻击，为此提供了新的见解，有助于理解和改进T2V模型的安全性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22256", "html_url": "https://arxiv.org/abs/2509.22256", "title": "通过上下文空间实现计算机使用代理的安全高效访问控制", "title_en": "Secure and Efficient Access Control for Computer-Use Agents via Context Space", "authors": "Haochen Gong,Chenxiao Li,Rui Chang,Wenbo Shen", "background": "计算机使用代理代表了AI和操作系统功能的结合，通过自然语言控制系统和应用程序级功能。然而，由于LLM固有的不确定性问题，授予代理计算机控制权带来了重大的安全风险。当代理行为偏离用户意图时，可能会导致不可逆的后果。现有缓解措施，如用户确认和基于LLM的动态行为验证，仍存在易用性、安全性和性能方面的局限性。", "innovation": "提出了CSAgent，一种系统级的静态策略访问控制框架，用意图和上下文感知策略连接静态策略和动态上下文和用户意图。CSAgent通过优化的OS服务强制执行这些策略，确保代理行为仅在特定用户意图和上下文中执行。CSAgent支持通过API、CLI和GUI等多种界面保护控制计算机的代理。", "conclusion": "我们实现了并评估了CSAgent，证明它成功抵御了超过99.36%的攻击，仅引入了6.83%的性能开销。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22258", "html_url": "https://arxiv.org/abs/2509.22258", "title": "超越分类准确度：Neural-MedBench及其深层推理基准的需求", "title_en": "Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks", "authors": "Miao Jing,Mengting Jia,Junling Lin,Zhongxia Shen,Lijun Wang,Yuanyuan Peng,Huan Gao,Mingkun Xu,Shangyang Li", "background": "近年来，视觉语言模型（VLMs）在医学标准基准测试上取得了显著的性能，然而其真正的临床推理能力仍然不清楚。现有的数据集主要强调分类准确度，造成了一种评估错觉，即模型显得熟练但实际上在高风险诊断推理方面仍然失败。因此，需要一个专门的设计来测试多模态临床推理在神经学中的极限。这需要一个既能进行统计泛化的广度方向的大数据集，也能进行深度推理的精简基准，如Neural-MedBench。", "innovation": "作者提出了Neural-MedBench，这是一种紧凑且注重推理的设计来探索神经学中的多模态临床推理极限。该基准结合了多序列MRI扫描、结构化电子医疗记录和临床笔记，并包含三大核心任务类别：病灶识别、引起诊断和推理生成。为了确保可靠的评估，开发了一个结合了LLM评估师、临床验证和语义相似性度量的混合评分管道。研究表明，最先进的VLMs在这一新基准上的表现明显低于传统数据集，错误分析表明推理失败而非感知错误是模型的主要缺陷。", "conclusion": "研究强调了需要一个两轴评估框架，包括广度方向的大数据集以支持统计泛化和深度方向的精简基准以支持推理准确性。Neural-MedBench作为开放且可扩展的诊断测试平台，指导未来基准的扩展，并有助于高效地评估临床可靠的人工智能系统。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22335", "html_url": "https://arxiv.org/abs/2509.22335", "title": "光谱塌陷在深度持续学习中驱动能力丧失", "title_en": "Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning", "authors": "Naicheng He,Kaicheng Guo,Arjun Prakash,Saket Tiwari,Ruo Yu Tao,Tyrone Serapio,Amy Greenwald,George Konidaris", "background": "研究发现，深度神经网络在深度持续学习中会遭受‘能力丧失’（loss of plasticity），即无法在不重新初始化参数的情况下学到新任务。研究者表明，这种能力丧失是由新任务初始化时光谱塌陷导致的，此时具有实际意义的曲率方向消失，梯度下降变得无效。", "innovation": "研究引入了$\tau$-可学性来表征成功训练的必要条件，并表明当前的能力保持算法可以在这一框架下统一。研究直接针对光谱塌陷，提出了哈斯丁斯函数的Kronecker因子近似方法，并提出两种正则化增强：保持高有效特征秩和施加$L2$惩罚。", "conclusion": "实验证明，结合这两种正则化可以在继续监督学习和强化学习任务中有效地保持学习能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22299", "html_url": "https://arxiv.org/abs/2509.22299", "title": "HEAPr：基于Hessian的高效原子专家输出空间精简", "title_en": "HEAPr: Hessian-based Efficient Atomic Expert Pruning in Output Space", "authors": "Ke Li,Zheng Yang,Zhongbin Zhou,Feng Xue,Zhonglin Jiang,Wenxiao Wang", "background": "混合专家（MoE）架构在大型语言模型（LLMs）中表现出卓越的性能和较低的推理成本，但其庞大的参数数量导致了巨大的内存需求，限制了其实用部署。现有剪枝方法主要聚焦于整体专家级剪枝，但这种粗粒度往往导致大量准确率下降。HEAPr通过将专家分解成更小的、不可分割的原子专家，提出了一个新的剪枝算法，实现了更精确和灵活的原子专家剪枝。", "innovation": "HEAPr利用第二阶信息（基于Optimal Brain Surgeon理论的原理）对每个原子专家的重要性进行了度量，并通过利用原子专家的内在属性将第二阶信息从专家参数转换为原子专家参数，进一步简化为原子专家输出的第二阶信息，从而将空间复杂度从$O(d^4)$降低到$O(d^2)$。HEAPr只需要在小型校准集上进行两次前向传播和一次后向传播即可计算原子专家的重要性。", "conclusion": "HEAPr在MoE模型，包括DeepSeek MoE和Qwen MoE家族中进行了广泛实验，结果显示在多种压缩比例和基准下优于现有的专家级剪枝方法。具体而言，在大多数模型中，HEAPr实现了接近无损的20%~25%压缩比，并减少了近20%的FLOPs。代码可以在指定链接中找到。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22287", "html_url": "https://arxiv.org/abs/2509.22287", "title": "使用大型语言模型促进语言脆弱学龄前儿童的形态结构辅助学习", "title_en": "Leveraging Large Language Models for Robot-Assisted Learning of Morphological Structures in Preschool Children with Language Vulnerabilities", "authors": "Stina Sundstedt,Mattias Wingren,Susanne Hägglund,Daniel Ventus", "background": "对于语言存在缺陷的幼儿（如发育性语言障碍或与移民相关的语言挑战），需要额外的支持来加强其表达语言能力。言语治疗师通常会将目标形态学结构（例如第三人称-s）融入日常互动或游戏活动。教育工作者需要模仿这一做法，但这也需要很强的语言知识和实时生成各种形态学形式的能力，并且在基于游戏的活动中还需要保持孩子的注意力并管理轮流。在这项TalBot项目中，跨专业团队开发了一款基于Furhat对话机器人的应用，以提高语言技能，应用目前使用大型语言模型来管理游戏、对话、情感反应和轮流。", "innovation": "该研究创新性地开发了一款基于Furhat对话机器人的应用，通过大型语言模型来管理和促进与形态结构有关的游戏学习，旨在帮助语言脆弱的学龄前儿童。特别是，机器人将能够在游戏中生成和提供特定的形态学目标，这可能超越人类的表现。另一个创新点在于，机器人不仅可以作为学习者，还能作为孩子和专业人士的语言模型和导师。此外，利用大型语言模型支持语言脆弱的儿童的基本通信需求也是本文的一大贡献。", "conclusion": "项目的长期目标是创建一个基于大型语言模型的机器人辅助语言学习干预措施，能够在不同语言的环境中教授多种形态学结构。该干预措施有望为语言缺陷的儿童提供有效的语言学习工具，提升他们的语言表达能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22291", "html_url": "https://arxiv.org/abs/2509.22291", "title": "促进仇恨言论检测中的公平性与可解释性的桥梁：基于输入的解释能否提升公平性？", "title_en": "Bridging Fairness and Explainability: Can Input-Based Explanations Promote Fairness in Hate Speech Detection?", "authors": "Yifan Wang,Mayank Jobanputra,Ji-Ung Lee,Soyoung Oh,Isabel Valera,Vera Demberg", "background": "自然语言处理（NLP）模型在训练数据中复制或放大社会偏见，这引起了公平性问题的关注。同时，NLP模型的黑盒性质使得用户难以识别偏差预测，开发者难以有效消除这些偏见。尽管有研究表明输入基解释可以用于检测和减轻偏见，但也有证据质疑其在确保公平性方面的可靠性。现有的关于公平NLP可解释性的研究多为定性分析，缺少大规模的定量研究。本文旨在系统地探讨可解释性与公平性之间的关系，特别关注编码器和解码器模型，并从三个关键维度出发：（1）识别偏差预测；（2）选择公平模型；（3）在训练过程中减缓偏差。", "innovation": "本文是首次系统研究NLP公平性和可解释性之间的关系，专注于编码器和解码器模型。研究发现了基于输入解释可以有效识别偏差预测，并作为减缓训练偏差的有用监督信号，但它们在选择公平模型方面不可靠。", "conclusion": "基于输入的解释可用于检测偏见预测并作为减缓训练偏差的有用监督信号，但它们在选择公平模型方面不可靠。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22310", "html_url": "https://arxiv.org/abs/2509.22310", "title": "通过共享网络的自适应策略主干", "title_en": "Adaptive Policy Backbone via Shared Network", "authors": "Bumgeun Park,Donghwan Lee", "background": "强化学习（RL）在众多领域取得了显著成果，但学习最优策略通常需要大量的交互数据，这限制了其实用部署。为了解决这一问题，以前的方法常使用先验知识，如先行收集的数据集或参考策略。然而在训练和部署任务不匹配时，这种先验知识的效果会下降。尽管此前的工作力求解决这种不匹配问题，主要还是局限于同分布情况。因此，本研究提出了自适应策略主干（APB），这是一种元迁移RL方法，通过在共享主干前后插入轻量级线性层，以参数高效微调（PEFT）的方式适应，同时保留先验知识，提高了样本效率，并在现有的元RL基线无法胜任的跨分布场景下也能有效适应。", "innovation": "自适应策略主干（APB）通过共享网络插入轻量级线性层，实现了参数高效微调（PEFT），并且能够保留先验知识，有效提高了样本效率与跨分布任务的适应性。这一方法突破了传统RL方法对大规模交互数据的依赖，并解决了先前方法在跨分布任务上的应用限制。", "conclusion": "实验结果表明，APB比标准RL方法具有更高的样本效率，并且特别适用于标准元RL基线通常表现不佳的跨分布（OOD）任务。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22343", "html_url": "https://arxiv.org/abs/2509.22343", "title": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "title_en": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "authors": "Amit Roy,Abulhair Saparov", "background": "研究背景在于确保基于Transformer的大语言模型生成的答案的正确性，特别是他们推理传递关系的能力极为关键。传递关系推理在因果推理等领域中具有重要意义，因此有必要评估Transformer在推导传递关系任务上的能力（例如，已知A导致B，B导致C，则A导致C）。过去的研究关注Transformer是否可以通过输入提示中的上下文示例学习推断传递性，但尚未广泛探讨Transformer从训练数据推断传递关系的能力及模型规模对其影响。这项研究旨在通过生成不同大小的有向图并进行训练来评估Transformer在各种图大小下推断传递关系的能力。研究表明，Transformer在“网格状”的有向图上能够学习连接性，其中每个节点可以嵌入低维子空间，连接性可以从节点的嵌入中推断出来。", "innovation": "创新点在于，研究通过生成不同大小的有向图来训练不同规模的Transformer模型，并评估其在不同图大小下推断传递关系的能力，发现了Transformer对具有网格状结构的图能够有效地学习连接性，且图的维度越大，学习连接性的难度越大；同时发现，随着模型规模的增加，Transformer在推断网格图连接性方面表现得越来越好。但是，图不是网格状且包含很多不连接的组件时，Transformer难以学习连接性任务，尤其是组件数量较多时。", "conclusion": "研究结论表明，Transformer具备在某些网格状拓扑结构的有向图中学习连接性的能力，但并非所有类型的图都能有效推断。图的网格维度是决定Transformer学习连接性任务能力的重要因素。适当扩大模型规模可以提升对网格图连接性的推断能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22300", "html_url": "https://arxiv.org/abs/2509.22300", "title": "HiGS: 历史导向采样插件增强扩散模型", "title_en": "HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models", "authors": "Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber", "background": "尽管扩散模型在图像生成方面取得了显著进展，但它们的输出仍然可能存在不真实、缺乏细致细节的问题，特别是在使用较少的神经网络函数评估次数（NFEs）或较低的引导比例时。这限制了模型的广泛应用和实际效果。因此，本文探讨了改进扩散模型生成图像质量的方法，尤其是如何提高模型在较低评估次数和较弱引导条件下的表现能力，确保生成图像具有更精细的细节和更好的结构特点。", "innovation": "本文提出了一种新颖的历史导向采样技术，称之为历史导向采样（HiGS），这种方法通过将最近的模型预测整合到每一步推理中，增强了扩散采样的质量和效率。具体来说，HiGS 利用当前预测与过去预测加权平均值之间的差异，引导采样进程生成更具现实感、细节更丰富的输出。此方法无需额外的计算，并能无缝集成到现有的扩散框架中，无需额外的训练或微调。实验结果显示，无论在不同模型和架构、不同采样预算还是不同引导比例下，HiGS 都能持续改善图像质量。使用预训练的 SiT 模型时，在 256x256 的 ImageNet 无引导生成中，HiGS 实现了新的 FID 记录（1.61），仅需 30 步采样（而不是标准的 250 步）。", "conclusion": "综上所述，HiGS作为标准扩散采样的即插即用增强技术，不仅实现了比标准方法更快的生成速度，还具有更高的保真度，特别在限制条件下仍能保持高质量生成效果。该成果为扩散模型在实际应用中的进一步优化提供了新思路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22319", "html_url": "https://arxiv.org/abs/2509.22319", "title": "渐进权重加载：在资源受限环境中加速初始推断并逐步提升性能", "title_en": "Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments", "authors": "Hyunwoo Kim,Junha Lee,Mincheol Choi,Jeonghwan Lee,Jaeshin Cho", "background": "深度学习模型的规模和复杂性日益增大，导致内存消耗和计算需求增加，使模型加载时间与初始推断延迟上升。这在频繁加载和卸载模型的移动和低延迟环境中尤其具有挑战性，对用户体验造成直接影响。知识蒸馏（KD）尽管能够通过将大型教师模型压缩成小型学生模型来解决问题，但通常会牺牲性能。", "innovation": "提出了渐进权重加载（PWL）技术，它首先部署一个轻量级的学生模型，然后逐步用预先训练好的教师模型的层替换学生模型的层，以实现快速的初始推断。为了支持层的无缝替换，该技术不仅对齐了学生和教师层之间的中间特征表示，还提高了学生模型的整体输出性能。实验结果表明，使用PWL训练的模型在保持竞争性的蒸馏性能的同时，随着教师层的加载，逐步提高了准确性，最终与完整的教师模型的准确性一致，且不牺牲初始推断速度。因此，PWL特别适用于需要快速响应和高性能的动态、资源受限部署环境。", "conclusion": "在VGG、ResNet和ViT架构上的实验结果表明，使用PWL训练的模型在保持竞争性的蒸馏性能的同时，逐步提高了准确性，最终与完整的教师模型的准确性一致，且不牺牲初始推断速度。这使PWL特别适合动态和资源受限的部署环境，其中快速响应和性能至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22331", "html_url": "https://arxiv.org/abs/2509.22331", "title": "通过分层跨模态超图学习进行行人人像属性识别", "title_en": "Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning", "authors": "Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo", "background": "当前的行人人像属性识别（PAR）算法通常专注于将视觉特征映射到语义标签，或者试图通过融合视觉和属性信息来增强学习。然而，这些方法未能充分利用属性知识和上下文信息以实现更准确的识别。尽管最近的研究已经开始考虑使用属性文本作为额外输入，以增强视觉和语义信息之间的关联，但这些方法仍处于初级阶段。", "innovation": "为了应对上述挑战，本文提出构建一个多模态知识图，用于挖掘局部视觉特征与文本之间的关系，以及属性与广泛视觉上下文示例之间的关系。具体而言，我们提出了一种全面考虑属性之间关系以及属性与视觉标记之间关系的有效多模态知识图构建方法，通过知识图引导的跨模态超图学习框架来增强传统的行人人像属性识别框架。", "conclusion": "在多个PAR基准数据集上的全面实验充分证明了我们提出的知识图在PAR任务中的有效性，为知识引导的行人人像属性识别奠定了坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22359", "html_url": "https://arxiv.org/abs/2509.22359", "title": "基于昨日气候预测未来：AI天气和气候模型中的温度偏差", "title_en": "Forecasting the Future with Yesterday's Climate: Temperature Bias in AI Weather and Climate Models", "authors": "Jacob B. Landsberg,Elizabeth A. Barnes", "background": "基于AI的气候和天气模型在提供快速且具有技能性的预报方面取得了快速进展，这些模型的预报能力甚至可以与传统动力学模型相媲美。然而，这些模型在使用历史数据进行训练的情况下，预测未来气候时存在关键挑战。", "innovation": "本研究通过分析北半球冬季陆地温度偏差，评估了FourCastNet V2 Small (FourCastNet) 和 Pangu Weather (Pangu) 在2020-2025年的预测和ACE2在1996-2010年的预测。本研究强调了使用仅基于历史数据训练的AI模型时的预测偏差挑战。", "conclusion": "所有模型均表现出冷偏差，其预测的平均温度比实际时期提前了15-20年。FourCastNet和Pangu在预测高温时偏差最大，暗示它们缺乏对现代极端热事件的训练。相比之下，ACE2的偏差更均匀，且在受气候变化影响最显著的地区、季节和温度分布部分最大。这些发现突显了仅使用历史数据训练AI模型的局限性，并强调了在将这些模型应用于未来气候预测时需要考虑这些偏差的必要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22360", "html_url": "https://arxiv.org/abs/2509.22360", "title": "CHRONOBERG: 捕捉基础模型中的语言演变和时间意识", "title_en": "CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation Models", "authors": "Niharika Hegde,Subarnaduti Paul,Lars Joel-Frey,Manuel Brack,Kristian Kersting,Martin Mundt,Patrick Schramowski", "background": "现有的语料库虽然多样，但通常缺乏长期的时间序列结构，这可能限制了大语言模型（LLMs）理解语言意义和规范的演变，并捕捉历时变化的能力。为了支持对历时变化的研究和训练，我们介绍了CHRONOBERG，这是一个涵盖250年英语书籍文本的时间序列语料库，从Project Gutenberg获取并附有各种时间标注。", "innovation": "CHRONOBERG通过对书籍进行编辑处理，使其能够量度词汇语义随时间的变化，使用时间敏感的VAD分析构建历史校准的情感词典，支持时间地解读。展示了现代基于LLM的工具需要更好地定位对歧视性语言的检测和情感在不同历史时期进行全面解读。表明不断训练的LLM在理解历时变化方面存在问题，强调需要具有时间意识的训练和评估管道，定位CHRONOBERG作为研究语言变化和时间泛化的可扩展资源。", "conclusion": "CHRONOBERG是一个可公开访问的、在HuggingFace上的资源和代码库，展示了语言模型需要具有时间意识的训练和评估管道，以更好地捕捉历时意义的变化，并作为研究语言变化的可扩展资源。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22352", "html_url": "https://arxiv.org/abs/2509.22352", "title": "SurvDiff：生存分析中生成合成数据的扩散模型", "title_en": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis", "authors": "Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel", "background": "生存分析是临床研究中的一个关键组成部分，用于建模如转移、疾病复发或患者死亡等时间到事件的结果。生存数据通常由于失访或退出而存在不完整的事件信息，这对合成数据生成提出了独特的挑战。现有的生成性模型在捕捉生成功能和重现事件时间分布以及失访机制方面存在不足，因此需要一种专门针对生存分析的合成数据生成方法。SurvDiff正是为此目的而设计的。", "innovation": "SurvDiff是一种专为生存分析生成合成数据的扩散模型。通过联合生成混杂型协变量、事件时间及右端截尾，它能够准确捕捉数据生成机制。SurvDiff使用专门为生存分析设计的损失函数来优化生成过程，确保生成的数据既符合现实中的事件时间分布，又保留了失访机制的特点，相比现有生成性基线模型，在多个医学数据集上表现出更高的分布保真度和下游评价指标。", "conclusion": "SurvDiff是首个明确为生成合成生存数据设计的扩散模型。在多个数据集上展示了其显著的优越性，表明其能够在生成合成数据时有效捕捉和再现生存数据的关键特征。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22353", "html_url": "https://arxiv.org/abs/2509.22353", "title": "在上下文和多样性的作用下：世界模型中上下文内学习的产生", "title_en": "Context and Diversity Matter: The Emergence of In-Context Learning in World Models", "authors": "Fan Wang,Zhiyuan Chen,Yuxuan Zhong,Sunjian Zheng,Pengtao Shao,Bo Yu,Shaoshan Liu,Jianan Wang,Ning Ding,Yang Cao,Yu Kang", "background": "预测环境动态的能力是生物神经系统和泛化本体AI适应环境的基础。然而，现有的方法依赖静态的世界模型，在面对新奇或罕见的环境配置时显得无力。因此，有必要探索能有效学习和适应环境变化的方法，特别是增强世界模型的灵活性和适应性策略，以实现自我适应的能力并应对不断变化的环境。", "innovation": "本文提出了一种上下文环境学习（ICEL）的方法，主要贡献包括三个方面：(1) 正式化了世界模型的上下文学习，并识别了两个核心机制：环境识别和环境学习；(2) 推导出两个机制的误差上限，揭示了它们的产生机制；(3) 实验上验证了ICCL机制存在于世界模型中，并进一步研究了数据分布和模型结构对ICCL的影响，与理论一致。这些发现表明，自适应世界模型具有潜力，并突显了ICEL产生的关键因素，尤其是需要长上下文和多样性环境", "conclusion": "研究结果显示，世界模型能够通过自我适应的方式学习环境，并且ICEL机制的产生需依靠长上下文和多样性的环境。这为未来的发展提供了新的研究方向，有助于开发更强大、适应性更强的AI系统。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22358", "html_url": "https://arxiv.org/abs/2509.22358", "title": "随机激活函数", "title_en": "Stochastic activations", "authors": "Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou", "background": "在大规模语言模型中，传统的激活函数如ReLU存在优化问题，如负值输入时梯度不流动导致的问题。为了解决这个问题，研究者提出了一种新的激活函数策略：随机激活函数。这种策略通过在前向传播层中随机选择SILU或RELU激活函数，尝试解决优化问题带来的挑战。", "innovation": "该策略采用了一种新颖的方式，即在预训练阶段使用随机激活函数，在微调阶段采用RELU激活函数，并在推理阶段使用RELU以提供稀疏的隐向量。这种方法不仅减少了推理时的FLOPs，还显著提升了CPU速度。此外，该论文还评估了随机激活函数在生成中的表现，结果表明这种方法在生成文本时的多样性方面表现良好，尽管略逊于SILU结合温度缩放的最佳确定性非线性函数，但提供了一种控制生成文本多样性的替代策略。", "conclusion": "该研究展示了随机激活函数的效果，表明可以通过这种方法改善大语言模型的各项性能，并提供了新的思路来增加生成文本的多样性。这种方法不仅能减少推理过程中的计算量，还能在不牺牲太多生成质量的情况下增加文本生成的多样性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22404", "html_url": "https://arxiv.org/abs/2509.22404", "title": "RAU: 基于引用的医学影像中视觉语言模型的解剖理解", "title_en": "RAU: Reference-based Anatomical Understanding with Vision Language Models", "authors": "Yiwei Li,Yikang Liu,Jiaqi Guo,Lin Zhao,Zheyuan Zhang,Xiao Chen,Boris Mailhe,Ankush Mukherjee,Terrence Chen,Shanhui Sun", "background": "对医学影像中的解剖结构的理解对于自动报告生成、术中导航和器官定位至关重要，但其进展受到专家标注数据稀缺性的限制。虽然最近的视觉-语言模型(VLMs)展示了非平凡的视觉推理能力，但它们的基于引用的理解和细粒度定位仍有限。", "innovation": "我们提出了RAU，一种基于引用的视觉语言模型(VLMs)的框架，用于解剖理解。首先，我们展示了VLM能够通过参考图像和目标图像之间的相对空间推理来学习识别解剖区域。其次，我们证明了VLM提取的空间线索可以无缝集成SAM2的细粒度分割能力，实现小解剖区域（如血管段）的定位和像素级分割。此外，其强大的泛化能力使其能够扩展到未见分布的数据集中。", "conclusion": "在两种内部和两种外部未见分布的数据集上，RAU在使用相同内存配置的情况下，相较于SAM2微调基线，能够提供更准确的分割和更可靠的定位，其强大的泛化能力对于医学图像应用至关重要。据我们所知，RAU是首个探索视觉语言模型在医学影像中基于引用识别、定位和分割解剖结构的能力，其表现表明视觉语言模型驱动的方法可能适用于自动化临床工作流程中的解剖理解。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22436", "html_url": "https://arxiv.org/abs/2509.22436", "title": "在神经ODE中的全局收敛性：激活函数的影响", "title_en": "Global Convergence in Neural ODEs: Impact of Activation Functions", "authors": "Tianxiang Gao,Siyuan Sun,Hailiang Liu,Hongyang Gao", "background": "神经常微分方程（ODEs）因其连续性和参数共享效率，在各种应用中取得了成功。然而，这些特性的引入也带来了训练中的挑战，特别是在梯度计算准确性和收敛分析方面。", "innovation": "本文通过探讨激活函数的影响来解决这些挑战。研究发现，激活函数的特性和非线性、平滑性是决定训练动力学的关键因素。研究证明，光滑的激活函数可以保证正向和反向ODEs的全局唯一解，而足够的非线性对于维护神经切线核（NTK）在训练过程中的频谱性质至关重要。研究结果表明，在参数化过度的情况下，这些特性使得通过梯度下降实现神经ODEs的全局收敛成为可能。", "conclusion": "理论发现通过数值实验进行了验证，支持了我们的分析，并提供了在实世界应用中扩大神经ODEs的实用指南，可能加速训练并提高性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22442", "html_url": "https://arxiv.org/abs/2509.22442", "title": "学习控球：为长时限篮球动作组合策略", "title_en": "Learning to Ball: Composing Policies for Long-Horizon Basketball Moves", "authors": "Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu", "background": "对于像篮球 maneuvers 这样的多阶段、长时限任务，强化学习方法仍然面临挑战，这是因为它们需要在技能之间无缝地组成和过渡。这类任务通常包含具有明确目标的不同子任务，以及具有模糊目标但对任务整体成功至关重要的过渡子任务。现有方法如专家混合模型和技能链在处理各个策略不共享大量共同探索状态或各阶段之间缺乏明确起始和终止状态的任务时效果不佳。", "innovation": "本文提出了一种新的策略集成框架，能够在多阶段长时限任务中将差异极大的运动技能无缝组合，即使中间状态不明确。在此基础上，进一步引入了一个高级软路由器，以实现子任务之间的无缝且鲁棒的过渡。该框架在篮球技能及其挑战性过渡方面进行了评估。", "conclusion": "通过我们的方法训练出的策略能够在仿真角色操控球体，并根据实时用户命令完成既定的长时限任务，而无需依赖于球的轨迹参考。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22367", "html_url": "https://arxiv.org/abs/2509.22367", "title": "LLMs在预训练和后训练数据中的政治内容是什么？", "title_en": "What Is The Political Content in LLMs' Pre- and Post-Training Data?", "authors": "Tanise Ceron,Dmitry Nikolaev,Dominik Stammbach,Debora Nozza", "background": "大语言模型(LLMs)已知会生成政治偏倚的文本，但这种偏倚的起源仍不清楚。当前LLMs研究对训练数据中的政治内容了解有限，这成为了研究中的一个关键空白。因此，本文通过对OLMO2（最大的开放源代码模型及其完整数据集）的预训练和后训练语料库进行了分析，以填补这一空白。", "innovation": "本文分析了OLMO2的预训练和后训练语料库，抽取大量随机样本，自动标注文档的政治倾向，并分析其来源领域和内容。研究发现左倾文档在数据集中占主导地位，预训练语料库包含比后训练数据更多的政治参与内容。另外，左右倾向的文档通过不同的价值观和合法性来源来构架相似的话题。同时，训练数据中的主流立场与模型在特定政策问题上的政治偏见存在强烈正相关。这些发现强调了在未来数据编目流程中整合政治内容分析的重要性，以及对筛选策略进行深入记录以提高透明度的需求。", "conclusion": "训练数据中的政治内容与模型在政策问题上的立场高度关联，这要求在未来的数据编目流程中整合政治内容分析，以及对筛选策略进行详细记录以增强透明度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22378", "html_url": "https://arxiv.org/abs/2509.22378", "title": "零努力图转音乐生成：基于RAG的可解释VLM方法", "title_en": "Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach", "authors": "Zijian Zhao,Dian Jin,Zijing Zhou", "background": "图像到音乐（I2M）生成近年来引起了广泛关注，具有在游戏、广告和多模态艺术创作等领域的潜在应用价值。然而，由于I2M任务的模糊性和主观性，大多数端到端的方法缺乏解释性，这使得用户难以理解生成的结果。即使基于情感映射的方法也存在争议，因为情感只是艺术的一个方面。此外，大多数基于学习的方法需要大量的计算资源和训练数据，这限制了普通用户的技术准入。因此，存在明确的需求来创建一种既具有高解释力又计算成本低的框架以解决上述挑战。", "innovation": "提出了一种基于Vision Language Model (VLM)的I2M框架，提高了解释性并降低了计算成本。该方法使用ABC符号将文本和音乐模态联系起来，利用多模态检索增强生成（RAG）技术和自我精炼技术使VLM能够生成高质量的音乐而无需外部训练。通过生成的动机文本和VLM的注意力图解释生成结果，提供文本和图像模态的解释。实验表明，在音乐质量和音乐图像一致性方面，该方法优于其他方法。", "conclusion": "通过人类和机器评估验证了该方法的有效性，表明这种方法具有追溯性和发展潜力。相关代码可以在指定的链接中获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22387", "html_url": "https://arxiv.org/abs/2509.22387", "title": "SpinGPT：一种用于正确玩扑克的大型语言模型方法", "title_en": "SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly", "authors": "Narada Maugin,Tristan Cazenave", "background": "Counterfactual Regret Minimization (CFR) 算法及其变体使得能够开发出能够在一对一现金比赛中击败顶级人类玩家的扑克机器人，并且能够与它们在六人游戏中竞争。然而，CFR 的计算复杂性随着玩家数量的增加而指数级增长，这在三人及以上玩家的游戏里，遵循纳什均衡不再能保证不输的结果。这些限制以及其他条件极大地限制了 CFR 在流行赛制中的应用，特别是锦标赛赛制。", "innovation": "基于近期大型语言模型 (LLM) 在国际象棋和外交游戏中取得的成果，本研究提出了 SpinGPT，这是首个针对三人在线扑克流行的三玩家格式 Spin & Go 的 LLM。SpinGPT 通过两个阶段训练：（1）监督微调在 320,000 条高风险专业决策基础上；（2）通过 270,000 解算器生成的局面上的强化学习。结果显示，SpinGPT 在 78% 的决策中与其解算器行为一致，使用简单的深栈启发式方法，与 Slumbot 在一对一比赛中对局 30,000 局后取得了 +13.4 +/- 12.9 BB/100 的成绩（95% 置信区间）。", "conclusion": "这些结果表明，大型语言模型可能成为处理多玩家不完全信息游戏（如扑克）的新途径。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22394", "html_url": "https://arxiv.org/abs/2509.22394", "title": "基于深度学习的适应性nnResU-网神经网络在不同解剖部位CT合成中的应用及解剖特征优先损失", "title_en": "Deep Learning-Based Cross-Anatomy CT Synthesis Using Adapted nnResU-Net with Anatomical Feature Prioritized Loss", "authors": "Javier Sequeiro González,Arthur Longuefosse,Miguel Díaz Benito,Álvaro García Martín,Fabien Baldacci", "background": "该研究利用SynthRAD2025数据集，涵盖了头部和颈部、胸部和腹部区域的MR到CT及CBCT到CT图像翻译。研究者们采用了基于patch的3D nnUNet方法，引入了Anatomical Feature-Prioritized (AFP) 损失，以增强临床相关结构的重建。通过对不同模态的图像进行归一化处理和特定网络配置的训练，研究为跨模态医学图像合成提供了一种稳定的解决方案，突显了结合自动nnUNet管道、残差学习和解剖学引导特征损失的重要性。", "innovation": "研究的主要创新在于：1) 使用adapted nnResU-Net并引入AFP损失，增强重建的解剖结构细节；2) 通过规范的3D patch训练和分区域训练方法，实现了模型设计的标准化与局部适应性。3) 研究对比了基于L1的和结合L1+AFP的网络配置，揭示了在特定应用中的优势。", "conclusion": "该方法通过深学习实现了多中心图像翻译的稳定性，表明结合自动nnUNet管道、残差学习和解剖导向特征损失的有效性。尤其在MRI到CT和CBCT到CT的骨结构和病灶重建中表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22458", "html_url": "https://arxiv.org/abs/2509.22458", "title": "边缘意识注意和线路搜索校正操作的物理知情GNN在中高压AC潮流中的应用", "title_en": "Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator", "authors": "Changhun Kim,Timon Conrad,Redwanul Karim,Julian Oelhaf,David Riebesel,Tomás Arias-Vergara,Andreas Maier,Johann Jäger,Siming Bayer", "background": "PIGNNs已经成为快速的交流电功率流求解器，能够替代经典的牛顿-拉夫逊求解器，尤其在需要评估数千种情况时更为显著。然而，当前的PIGNNs在精度上仍有改进空间，尤其是在推理时物理损失不能生效从而影响操作上的应用。", "innovation": "本文提出了一种名为PIGNN-Attn-LS的新模型，结合了线路感知注意力机制和基于迭代回溯的全局校正操作。注意力机制将每条边的物理特性显式编码，捕捉电网的各向异性，校正操作则在推理过程中恢复了有效的下降准则，从而提高了准确性。", "conclusion": "使用四个到三百二十个节点的中高压真实场景进行测试，PIGNN-Attn-LS在电压和相角上的测试均方根误差分别为0.00033 p.u.和0.08°，相较于基准模型PIGNN-MLP分别提高了99.5%和87.1%。采用流式微批处理，该模型在四个到一千零二十四个节点的电网上的批量推理速度比牛顿-拉夫逊方法快2到5倍。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22418", "html_url": "https://arxiv.org/abs/2509.22418", "title": "部分参数更新以实现高效分布式训练", "title_en": "Partial Parameter Updates for Efficient Distributed Training", "authors": "Anastasiia Filippova,Angelos Katharopoulos,David Grangier,Ronan Collobert", "background": "现有方法通过在稀疏的全局同步之间进行多次本地更新来减少通信量。然而，这种做法的效率可以显著提高，通过限制反向传播：每个节点只更新固定的一部分参数，其他部分保持冻结状态，在本地步骤中。这样可以大幅减少峰值内存使用和训练FLOPs，同时通过在整个参数上进行完整前传，消除了跨节点激活交换的需求。这项工作是在一个由32个节点训练的1.3亿参数的自然语言模型上进行的实验，结果表明，该方法在与之前的低通信量方法相同的令牌和带宽预算下，匹配其困惑度，同时减少了训练FLOPs和峰值内存使用量。", "innovation": "提出了一种新的记忆和计算高效的分布式训练方法，通过限制反向传播来减少通信量。具体来说，每个节点只更新固定部分的参数，其他部分保持冻结，这可以显著减少内存使用和计算量，同时消除了跨节点激活的交换需求。", "conclusion": "在1.3亿参数的语言模型分布式训练中，与现有低通信量方法相比，该方法在相同的计算和带宽资源下，能够实现相同水平的训练效果，同时减少计算量和内存使用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22415", "html_url": "https://arxiv.org/abs/2509.22415", "title": "通过内在模态令牌互动解释多模态大语言模型", "title_en": "Explaining multimodal LLMs via intra-modal token interactions", "authors": "Jiawei Liang,Ruoyu Chen,Xianghao Jiao,Siyuan Liang,Shiming Liu,Qunli Zhang,Zheng Hu,Xiaochun Cao", "background": "多模态大语言模型（MLLMs）在跨多样化视觉-语言任务中取得了显著的成果，但其内部决策机制尚未充分理解。现有的可解释性研究主要集中在跨模态归因上，即识别模型在输出生成过程中关注哪些图像区域。但这些方法往往忽略了内在模态的依赖关系。在视觉模态中，单独标注图像片段忽视了空间上下文因为其有限的接收域，导致解释片段化和噪声化。在文本模态中，依赖于前一个令牌引入了虚假激活。未能有效消除这些干扰影响了归因的忠实性。", "innovation": "为解决这些局限性，本文提出通过利用内在模态交互来增强可解释性。对于视觉分支，引入了“多尺度解释聚合”（MSEA），该方法通过聚合多尺度输入的归因来动态调整接收域，产生更全面和空间上连贯的视觉解释。对于文本分支，提出了“激活排名相关性”（ARC），通过对其前$k$个预测排名的对齐来衡量上下文令牌对当前令牌的相关性，并利用这种相关性抑制不相关的上下文激活，同时保留语义上一致的激活。广泛的实验表明，本文方法在最新和基准数据集上的表现优于现有的可解释性方法，提供更忠实和细化的模型行为解释", "conclusion": "本文的方法在多模态大语言模型上实现了更忠实、更精细的解释，通过利用内在模态令牌间的互动显著改善了可解释性，特别是在视觉和文本模态中克服了现有的归因局限性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22434", "html_url": "https://arxiv.org/abs/2509.22434", "title": "统一建模个人服务机器人任务、行动、环境及能力的本体", "title_en": "An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics", "authors": "Margherita Martorana,Francesca Urgese,Ilaria Tiddi,Stefan Schlobach", "background": "个人服务机器人越来越多地被用于家庭环境中以辅助老年人和需要支持的人群。有效的操作不仅涉及物理交互，还需要能够理解动态环境、任务，并根据上下文选择适当的行为。这需要将硬件组件（如传感器、执行器）与能够推理解任务、环境和机器人能力的软件系统进行整合。现有的框架，如Robot Operating System (ROS)，提供了帮助连接低级硬件与高级功能的开源工具。然而，实际应用依然紧密耦合于特定平台，导致解决方案往往孤立并进行硬编码，限制了互操作性、重用性和知识共享。", "innovation": "本文提出了一种名为OntoBOT的本体，它扩展了现有的本体，提供了一个统一表示任务、行动、环境和能力的框架。贡献包括：(1) 统一这些方面为一个连贯的本体，以支持任务执行的形式化推理；(2) 通过在四个实体代理（TIAGo、HSR、UR3和Stretch）上评估能力问题，展示了OntoBOT在服务机器人中的通用性和上下文感知推理、任务导向执行以及知识共享能力。", "conclusion": "实验结果证明了OntoBOT在多实体代理环境下的通用性和有效性，使机器人能够进行上下文感知的推理和任务导向的执行，并促进知识共享。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22468", "html_url": "https://arxiv.org/abs/2509.22468", "title": "学习邻域：无对比多模态自监督分子图预训练", "title_en": "Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining", "authors": "Boshra Ariguib,Mathias Niepert,Andrei Manolache", "background": "高质量的分子表示对于性质预测和分子设计至关重要，然而大规模标注数据仍然稀缺。现有的自监督预训练方法虽然展示了潜力，但很多依赖手工构建的增强或者复杂的生成目标，且主要集中于2D拓扑信息，未能充分利用有价值的3D结构信息。", "innovation": "提出了一种名为C-FREE的简单框架，该框架整合了2D分子图与多种3D构象的集合。通过在潜在空间中预测子图嵌入及其互补邻域，并使用固定半径的 ego-nets 作为不同构象的建模单元，C-FREE融合了几何和拓扑信息，实现了一种混合图神经网络（GNN）-变压器架构，无需否定样本、位置编码或昂贵的预处理。", "conclusion": "C-FREE在GEOM数据集上预训练后达到了分子网络上的最新成果，超越了对比、生成以及其他多模态自监督方法。跨不同大小和分子类型的数据库微调进一步表明预训练在新化学领域的有效性，突出了3D启发式分子表示的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22505", "html_url": "https://arxiv.org/abs/2509.22505", "title": "AI companion impacts on mental health: integrating social media quasi-experiments, user perspectives, and relational theory", "title_en": "Mental Health Impacts of AI Companions: Triangulating Social Media Quasi-Experiments, User Perspectives, and Relational Theory", "authors": "Yunhao Yuan,Jiaxun Zhang,Talayeh Aledavood,Renwen Zhang,Koustuv Saha", "background": "研究AI情感机器人（AICCs）如Replika等日益流行的背景，这些机器人提供了同理心的交流，但其对心理健康的影响仍不清楚。本文通过社会媒体的准实验研究、用户访谈和关系理论相结合的方法，探讨了与AI情感机器人互动对福祉的影响及其用户体验感受。", "innovation": "通过大规模的纵向Reddit数据分析，结合差异性差异回归和倾向得分匹配方法；并通过15个半结构化访谈，结合Knapp的关系发展模型进行主题分析。研究结果整合了来自不同方法的数据，为设计健康的AI伴侣提供了指导建议。", "conclusion": "该研究揭示了AI情感机器人对心理健康既有积极作用也有潜在风险。建议AI伴侣的设计应该支撑健康的边界、促进有意识的互动、鼓励披露而不产生依赖，以及展示关系的发展阶段，从而最大化心理社会收益并减轻风险。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22461", "html_url": "https://arxiv.org/abs/2509.22461", "title": "MDAR：一个多场景动态音频推理基准", "title_en": "MDAR: A Multi-scene Dynamic Audio Reasoning Benchmark", "authors": "Hui Li,Changhao Jiang,Hongyu Wang,Ming Zhang,Jiajun Sun,Zhixiong Yang,Yifei Cao,Shihan Dou,Xiaoran Fan,Baoyu Fan,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "现有的基准测试主要集中在静态或单一场景设置上，无法充分捕捉到多说话人、展开事件和异质音频源交互的场景。因此，音频推理能力对于AI代理在实际场景中的有效互动是至关重要的，而目前的基准测试尚不足以全面评估这种能力。为了应对这些挑战，本文引入了MDAR基准测试，用于评估多场景、动态演变的音频推理任务。", "innovation": "MDAR是一个针对复杂、多场景和动态演变的音频推理任务的基准测试。它包含3000个精心挑选的问题-答案对，关联到多种音频片段，并覆盖了五类复杂推理，以及三种问题类型。研究表明，现有的最先进的音频语言模型在复杂推理任务中存在局限性。MDAR的独特之处在于其多场景和动态特性，以及它为音频推理领域的进步提供了价值观。", "conclusion": "所有模型在这三种问题类型中都没有达到80%的性能。这些发现凸显了MDAR所带来的独特挑战和基准测试的价值。该基准测试已公开，可以在相关链接获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22445", "html_url": "https://arxiv.org/abs/2509.22445", "title": "基于柯尔莫哥洛夫复杂性和深度学习的桥梁：Transformer的渐近最优描述长度目标", "title_en": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers", "authors": "Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova", "background": "最小描述长度（MDL）原则提供了一种在机器学习中应用奥卡姆剃刀的正式框架。然而，将其应用于如变换器等神经网络存在挑战，因为缺乏一种基本原则上的、通用的模型复杂度度量。本文基于柯尔莫哥洛夫复杂性理论，提出渐近最优描述长度目标的概念。", "innovation": "本文建立了一种渐近最优目标，证明了此类目标对于变换器的存在性，构建并分析了基于可调节高斯混合先验的可处理且可微的目标。实验证明该目标可以选出低复杂度、强泛化的解，但标准优化器难以从随机初始化中找到这样的解，揭示了关键的优化挑战。", "conclusion": "通过提供一个理论上识别具有强渐近保证的描述长度目标的框架，本文阐述了训练能够实现更大压缩和泛化的神经网络的潜在路径。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22480", "html_url": "https://arxiv.org/abs/2509.22480", "title": "探索解决方案的多样性及其对大型语言模型问题解决的影响", "title_en": "Exploring Solution Divergence and Its Effect on Large Language Model Problem Solving", "authors": "Hang Li,Kaiqi Yang,Yucheng Chu,Hui Liu,Jiliang Tang", "background": "大型语言模型（LLMs）在解决各种问题的任务中得到了广泛应用。大多数最近的改进都是通过使用标注数据的监督微调（SFT）或根据任务反馈进行强化学习（RL）来提高性能的。本研究关注的是单一问题下LLMs生成不同解决方案间的差异性，即解决方案的多样性。我们发现，更大的多样性与更好的问题解决能力相关联。基于这一发现，我们提出了一个新的度量标准——解决方案的多样性，它可以支持SFT和RL策略。我们验证了这一想法在三个代表性的问题领域中，发现使用解决方案的多样性可以提升成功率。", "innovation": "本研究提出了一个新的度量标准——解决方案的多样性，它可以作为支撑SFT和RL策略的工具。我们证实了解决方案的多样性可以提升多个问题域中的成功解决率，证明了这一度量标准的有效性。", "conclusion": "解决方案多样性作为一种简单而有效的方法，可以用于推进LLMs的训练和评估。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22493", "html_url": "https://arxiv.org/abs/2509.22493", "title": "基于本体的机器人计划对比解释基础", "title_en": "Ontological foundations for contrastive explanatory narration of robot plans", "authors": "Alberto Olivares-Alarcos,Sergi Foix,Júlia Borràs,Gerard Canal,Guillem Alenyà", "background": "人机交互中理解人工智能代理决策的关键在于确保人际关系的可靠性和成功。因此，机器人需要做出合理的决策并在必要时与人类沟通。本文关注一种方法，用于建模和推理两种竞争计划的比较，以便机器人可以后来解释结果差异。", "innovation": "提出了一种新颖的本体模型，用于正式化和推理竞争计划之间的差异，从而使机器人能够分类出最合适的计划（例如，最短、最安全、最接近人类偏好等）。此外，通过实证评估发现，新的算法在解释方面的表现优于基线方法，能够利用计划之间的差异知识，构建对比性叙述。", "conclusion": "通过基于本体的方法，研究实现了计划间的对比性解释，其方法与基线算法相比更胜一筹。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22437", "html_url": "https://arxiv.org/abs/2509.22437", "title": "Chimera：诊断视觉-语言理解中的捷径学习", "title_en": "Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding", "authors": "Ziheng Chi,Yifan Hou,Chenxi Pang,Shaobo Cui,Mubashara Akhtar,Mrinmaya Sachan", "background": "图表以视觉格式传达符号信息，而非线性文字流，这对AI模型的处理提出了挑战。尽管最近的评估表明，视觉-语言模型（VLMs）在图示相关的基准测试中表现良好，但它们依赖于知识、推理或模态捷径的做法引发了对其是否真正理解和推理图示的担忧。为应对这一差距，论文引入了Chimera，这是一个包含从维基百科收集的7500个高质量图示的综合测试套件。每个图示都注释了其符号内容的语义三元组，并设计了多层次的问题，以评估图示理解的四个基本方面：实体识别、关系理解、知识锚定和视觉推理。使用Chimera测量三种类型的视觉问答捷径：（1）视觉记忆捷径，VLMs依赖于记忆的视觉模式；（2）知识回忆捷径，模型利用记忆中已有的事实知识，而不是解析图示；（3）Clever-Hans捷径，模型利用表面化的语言模式或先验知识，而未具备真正的理解能力。该测试套件评估了15种开源VLMs，并发现它们看似强大的表现主要是这些捷径行为的结果：视觉记忆捷径有轻微影响，知识回忆捷径起了一定作用，Clever-Hans捷径影响显著。这些都是目前VLMs所面临的重大局限性，并强调了需要更为严格的评估协议，以在复杂视觉输入（如图示）方面测试真正的理解能力，而非问答捷径的重要性。", "innovation": "研究团队开发了一个名为Chimera的综合测试套件，专门针对图示理解领域的现状，旨在评估模型的真正的图示理解能力，而非仅仅依赖于各种捷径策略，从而更准确地评估模型是否真正理解了图示的信息。Chimera测试套件包括从维基百科搜集的7500个高质量图示，每个图示都注释了其符号内容和多层次的问题。这为视觉-语言模型的评估提供了一个全面的框架，有助于推动该领域的研究和发展。", "conclusion": "研究发现，当前的视觉-语言模型大多依赖捷径策略，这表明它们在处理复杂视觉输入时的能力有限。Chimera测试套件揭示了这些模型的不足之处，强调了需要更具挑战性的评估标准来确保模型具备真正的理解和推理能力。开发更有效的视觉-语言理解和推理能力的协议是未来研究的一个重要方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22483", "html_url": "https://arxiv.org/abs/2509.22483", "title": "OFMU：基于优化的机器忘记框架", "title_en": "OFMU: Optimization-Driven Framework for Machine Unlearning", "authors": "Sadia Asif,Mohammad Mohammadi Amiri", "background": "大型语言模型在敏感应用中越来越需要具备对特定知识（如用户请求、版权内容或过时信息）的遗忘能力，而无需从头开始重新训练，以确保合规性、用户隐私和安全。这一过程被称为机器遗忘，目标是在去除特定数据影响（遗忘）的同时保持剩余数据的性能（保留）。传统的解决方案是将问题公式化为多目标问题，通过加权求和将其转化为单目标问题，但这种方式往往导致不稳定的训练动态和模型性能下降，因为目标梯度方向存在冲突。", "innovation": "为解决这些挑战，我们提出了一种基于惩罚的双层优化框架OFMU，该框架通过层级结构明确优先级遗忘并保留性能。内在最大化步骤引入了相似性感知惩罚，将遗忘和保留目标的梯度去相关，外层最小化步骤恢复模型的效用。针对可扩展性问题，我们构建了一个具有证明收敛保证的双循环算法，适用于凸性和非凸场景。我们的方法在遗忘效果和保留效用之间实现了更好的权衡，并通过广泛的视觉和语言基准测试证明优于现有方法。", "conclusion": "OFMU方法在遗忘效果和保留效用方面均优于现有方法。通过双重循环算法和理论分析，我们证明了OFMU在遗忘效果和保留效用之间的更好权衡，并且在视觉和语言基准测试中表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22472", "html_url": "https://arxiv.org/abs/2509.22472", "title": "评估大规模语言模型在多语言法律推理中的局限性", "title_en": "Evaluating the Limits of Large Language Models in Multilingual Legal Reasoning", "authors": "Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel", "background": "在大型语言模型（LLMs）主导的时代，理解和掌握它们在高风险领域，如法律领域的能力与局限性至关重要。尽管LLMs正逐渐融入法律工作流程中，但它们在多语言、法律领域法律管辖权多样以及对抗性环境中的表现仍缺乏充分研究。本文评估了LLaMA和Gemini在多语言法律和非法律基准测试中的表现，并通过字符级和词级扰动评估了其在法律任务中的抗篡改性。", "innovation": "本文采用了一种LLM作为法官的评估方法来实现与人类对齐的评估。此外，本文还提供了一种开源的模块化评估框架，可用于对任何LLM和数据集的组合进行多语言、任务多样化基准测试，特别是针对法律任务，包括分类、总结、开放式问题和一般推理。结果显示，法律任务对LLMs构成重大挑战，其在法律推理基准测试中准确率常常低于50%，而一般任务的准确率超过70%。", "conclusion": "尽管较新的LLMs有所改进，但仍在可靠部署用于关键且多语言法律应用方面面临挑战。此外还发现语言的性能与其与英语的句法相似度之间存在相关性，以及LLaMA的表现弱于Gemini，后者在相同任务上平均领先约24个百分点，尽管英语在稳定性和准确性方面表现出色，但并不能总是提高准确率，对文本提示的敏感性及对抗性脆弱性在不同语言中依然存在。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22545", "html_url": "https://arxiv.org/abs/2509.22545", "title": "AI辅导是否为职场谈判做好了准备？", "title_en": "Does AI Coaching Prepare us for Workplace Negotiations?", "authors": "Veda Duddu,Jash Rajesh Parekh,Andy Mao,Hanyi Min,Ziang Xiao,Vedant Das Swain,Koustuv Saha", "background": "职场谈判受心理障碍的影响，这可能会削弱精心准备的谈判策略的效果。尽管AI可以提供个性化的、随时可用的谈判辅导，但其在提升谈判准备方面的效果尚不明确。本研究基于Brett的谈判模型构建了Trucey，这是一种AI教练原型，并通过实验证明了其效果。", "innovation": "构建了基于Brett模型的Trucey AI教练原型，通过对比实验验证了其在减少谈判恐惧方面比ChatGPT和传统谈判手册更有效，虽然AI在排练能力上受到高度评价，但在指导的清晰性和实用性上却不如手册，表明AI在心理准备支持上存在局限性。", "conclusion": "虽然AI在指导排练方面受到高度评价，但手册在易用性和心理激励方面更胜一筹。Trucey在降低谈判恐惧方面表现最好，但其指导感觉冗长杂乱，给参与者带来了不确定性和压力。这些发现质疑了AI优越性的假设，并建议未来的设计应结合结构化的理论指导内容与针对性的排练、明确边界以及适应性支撑，以应对心理障碍，帮助提升谈判技巧和准备度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22484", "html_url": "https://arxiv.org/abs/2509.22484", "title": "多重硬化症生物标记物发现的机器学习管道：比较可解释的人工智能和传统统计方法", "title_en": "A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches", "authors": "Samuele Punzo,Silvia Giulia Galfrè,Francesco Massafra,Alessandro Maglione,Corrado Priami,Alina Sîrbu", "background": "该研究旨在通过整合公开的8个来自外周血单核细胞的微阵列数据集，利用机器学习方法发现多重硬化症（MS）的生物标记物。背景信息包括现有的微阵列数据集以及使用的具体技术，如稳健预处理、XGBoost分类器和SHapley Additive exPlanations (SHAP)特征重要性评估。", "innovation": "创新点在于提出了一种结合可解释人工智能（xAI）和传统统计方法的机器学习管道，用于发现MS的生物标记物。通过这样的结合，既能充分利用现有的统计方法，又能提供模型可解释性，有助于深入理解疾病机制。", "conclusion": "这项研究表明，通过将可解释的人工智能与传统统计方法相结合，可以更好地理解疾病的机制，并且这种方法能揭示出与MS相关的已知和潜在的新生物标记物。不同方法（SHAP与DEA）的比较揭示了互补的优势，并通过富集分析验证了SHAP所选择的基因具有生物学意义，体现了这些途径（如鞘脂信号传导、Th1/Th2/Th17细胞分化和EB病毒感染）与MS的关联性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22565", "html_url": "https://arxiv.org/abs/2509.22565", "title": "增强检索用于AI草拟患者门户消息的护栏：错误分类学构建和大规模评估", "title_en": "Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation", "authors": "Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma", "background": "电子健康记录（EHR）门户中的患者-临床医师异步通信已成为临床医师工作量的一个增长来源，因此对于使用大型语言模型（LLMs）来辅助生成草拟回复的兴趣日益浓厚。然而，LLMs输出可能包含临床不准确性、遗漏或语调不符等问题，这使得需要进行可靠的评估。现有的错误识别和评估方法在准确性、可解释性以及可扩展性方面存在不足。", "innovation": "本文提出了三种创新贡献：1）构建了一种基于临床的错误分类学，包括5个领域和59个具体错误代码，通过归纳编码和专家判定开发；2）开发了一种检索增强的评估框架（RAEC），利用语义相似的历史消息-回复对来提高判断质量；3）提出了一个分阶段的提示架构，结合DSPy（对话式编程与解释）来实现可扩展、可解释的层次化错误检测。该方法不仅评估草拟回复的质量，还参照从机构档案中检索到的类似过往消息-回复对进行评估。", "conclusion": "通过采用两阶段DSPy管道，本文对1500多条患者消息进行了基准评估和参考增强评估。检索上下文在临床完整性、工作流程适当性等领域的错误识别中表现出改进的效果。通过100条消息的人工验证，表明带有检索上下文的标签在一致性（50% vs 33%）和性能（F1 = 0.500 vs 0.256）方面优于基本模型，支持使用RAEC框架作为AI草拟患者门户消息的护栏。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22551", "html_url": "https://arxiv.org/abs/2509.22551", "title": "ConQuER: 连贯架构以控制和缓解IQP量子生成模型中的偏差", "title_en": "ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models", "authors": "Xiaocheng Zou,Shijin Duan,Charles Fleming,Gaowen Liu,Ramana Rao Kompella,Shaolei Ren,Xiaolin Xu", "background": "基于瞬时量子多项式（IQP）电路的量子生成模型在学习复杂分布方面显示出了很大的潜力，同时保持了经典的可训练性。然而，当前的实现存在两个关键限制：生成输出缺乏可控性以及生成偏向某些期望模式十分严重。", "innovation": "我们提出了一个可控量子生成框架，ConQuER，通过模块化电路架构解决了这两个挑战。ConQuER嵌入了一个轻量级的控制电路，可以直接与预训练的IQP电路结合以精确控制输出分布而无需进行全面重新训练。我们还通过数据驱动优化来嵌入隐式控制路径，这种方法能够显著减少结构化数据集的生成偏差。ConQuER保留了高效的经典训练特性和高可扩展性。", "conclusion": "我们已在多个量子状态数据集上实验验证了ConQuER，表现出优越的控制精度和平衡的生成性能，且相对于原本的IQP电路，成本极低。该框架填补了量子计算优势与可控生成建模实际需求之间的差距。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22536", "html_url": "https://arxiv.org/abs/2509.22536", "title": "InfiR2: 语言增强型模型全面的FP8训练食谱", "title_en": "InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models", "authors": "Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Yuan Xie,Hongxia Yang", "background": "训练大规模语言模型（LLMs）的巨大计算成本是创新的主要障碍。尽管使用FP8训练可以带来显著的理论效率提升，但由于缺乏完整的开源训练方法，其广泛应用受到了限制。本文旨在解决这一问题。通过介绍一个从头到尾的FP8训练方法，使持续预训练和监督微调无缝集成。该方法使用细粒度、混合粒度量化策略，在保持数值精确性的同时，最大化计算效率。包括在160B标记语料库上继续进行预训练的实验表明，该方法不仅非常稳定，而且几乎无损失，其在各种推理基准上与BF16基线达到了相同的表现。同时，该方法实现了显著的效率提升，包括训练时间减少22%，峰值内存使用减少14%，吞吐量提高19%。实验结果证明了FP8在大规模模型训练中作为一种实用且稳健的替代BF16的方法的可行性。我们将会发布相关的代码以进一步促进大规模模型训练的普及.", "innovation": "本文引入了一个全面的FP8训练方法，通过细粒度、混合粒度量化策略，保持数值精度的同时最大化计算效率。该方法实现了从持续预训练到监督微调的无缝集成。实验结果显示，该方法不仅表现出高度稳定性和几乎无损失的表现，还能显著提高训练效率，包括减少22%的训练时间、降低14%的峰值内存使用和增加19%的吞吐量。这标志着FP8作为BF16的可行且稳健的替代方案已经得到了实验证明。", "conclusion": "本文通过提供一个全面的FP8训练方法，显著提高大规模语言模型的训练效率，同时保持数值精确性。实验结果表明FP8在大规模训练中是一个实用且稳健的选择。为了进一步推广这种可行性，我们将会开源相关代码。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22566", "html_url": "https://arxiv.org/abs/2509.22566", "title": "从参数到行为：无监督压缩策略空间", "title_en": "From Parameters to Behavior: Unsupervised Compression of the Policy Space", "authors": "Davide Tenedini,Riccardo Zamboni,Mirco Mutti,Marcello Restelli", "background": "尽管深度强化学习（DRL）近期取得了成功，但它在样本效率方面仍存在显著问题。优化策略时直接在高维度且高度冗余的参数空间$\theta$中进行，这一做法导致了低效率。多任务设置进一步加剧了这一挑战。", "innovation": "本文提出了一种新颖的无监督方法，将策略参数空间$\theta$压缩成一个低维度的潜在空间$\text{Z}$。通过优化行为重建损失训练生成模型$g:\text{Z}\to\theta$，确保潜在空间中组织的是功能相似性而非参数化距离。提出了潜在流形的固有维度与环境复杂性有关的假设，而非策略网络规模。在连续控制域中验证了该方法，证明标准策略网络的参数化可以被压缩多达五个数量级，同时保留其大部分表达性。作为副产品，这种方法还有助于通过潜在空间$\text{Z}$中的策略梯度进行任务特定适应。", "conclusion": "方法验证了在低维度潜在空间中训练策略网络模型的有效性，表明了环境复杂性与潜在流形的固有维度之间的联系，展示了策略空间压缩后仍能保持强大的表达能力及任务特定适应性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22562", "html_url": "https://arxiv.org/abs/2509.22562", "title": "激活函数设计在持续学习中维持可塑性", "title_en": "Activation Function Design Sustains Plasticity in Continual Learning", "authors": "Lute Lillo,Nick Cheney", "background": "在独立同分布(i.i.d.)的训练条件下，激活函数已经被广泛测试，它们在模型大小和优化手段调整后，差异会变得不显著。而在持续学习中，情况有所不同：除了灾难性遗忘外，模型还可以逐渐失去适应能力（称为可塑性损失），而这种失败模式中非线性的作用仍然没有得到充分研究。我们展示出激活选择是抵御可塑性损失的主要手段，与架构无关。通过分析负分支形状和饱和行为的特性，我们引入了两种可替代非线性（Smooth-Leaky和Randomized Smooth-Leaky），并在监督类增量基准测试和诱导分布和动力学变化的非平稳MuJoCo环境的强化学习中进行了评估。我们也提供了一个简单的压力测试协议和诊断，将激活函数的形状与变化下的适应性联系起来。", "innovation": "我们首次通过分析负分支形状和饱和行为来提升激活函数的功能，并引入了两种新的替代非线性（Smooth-Leaky和Randomized Smooth-Leaky），它们可以在无需额外容量或任务特定调整的情况下，维持持续学习中的可塑性。我们还提供了简单的压力测试协议和诊断，用于链接激活函数的形状和变化下的适应性。", "conclusion": "合适的激活设计提供了一种轻量级、跨领域的途径，可以在持续学习中维持可塑性，无需额外容量或任务特定调整。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22611", "html_url": "https://arxiv.org/abs/2509.22611", "title": "定量优势估计用于熵安全推理", "title_en": "Quantile Advantage Estimation for Entropy-Safe Reasoning", "authors": "Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He", "background": "基于强化学习的大型语言模型 (LLM) 提升了推理能力，但训练过程中常常在‘熵坍缩’和‘熵爆炸’之间振荡。这是由于在无价值强化学习 (RVFL) 中使用均值基准（如 GRPO 和 DAPO）造成的，这种基准在受到奖励异常值影响时，错误地惩罚了负优势样本。", "innovation": "提出的定量优势估计 (QAE) 方法，以组内 K 分位数基准代替均值基准。QAE 在困难查询 (p <= 1 - K) 时增强罕见的成功，而在简单查询 (p > 1 - K) 时则针对剩余的失败。在一阶 softmax 更新中，证明了双面熵安全，从而限制了爆炸行为并防止了坍缩。实验结果显示，这一最小修改稳定了熵、稀疏了信用分配，并在 Qwen3-8B/14B-Base 上取得了持续的 QAI 2024/2025 和 AMC 2023 过滤率的提升。", "conclusion": "研究结果表明，基准设计（而非标记级别启发式）才是 RLVR 溯源的关键机制。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22615", "html_url": "https://arxiv.org/abs/2509.22615", "title": "使用二维高斯点绘制从压缩图像表示实现视觉-语言对齐", "title_en": "Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting", "authors": "Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe", "background": "现代的视觉-语言管道由在大量图像文本语料库上训练的RGB视觉编码器驱动，这使这些管道能够实现令人印象深刻的一次性能力，并在任务间表现出强大的迁移性。然而，这些管道仍继承了像素领域的两种结构性不足：一是将密集的RGB图像从边缘设备传输到云端消耗大量能量并且成本高昂；二是基于补丁的分词使得序列长度爆炸式增长，加大了注意力预算和上下文限制的负担。", "innovation": "我们探索了二维高斯点绘制（2DGS）作为一种替代的视觉载体，它通过一组彩色各向异性高斯函数对图像进行参数化，提供一种紧凑且空间自适应的表示。我们开发了具有结构化初始化、亮度感知裁剪和批量CUDA内核的可扩展2DGS管道，相比前人实施，实现了超90倍的拟合速度和约97%的GPU利用率。我们进一步将对比视觉语言预训练（CLIP）适应2DGS，利用一个冻结的RGB基础变压器骨干和一个轻量级的点绘制感知输入茎以及一个感知重采样器，仅训练大约7%的总参数。在大容量DataComp子集上，GS编码器提供了与像素相比减少3到20倍的输入情况下有意义的一次性ImageNet-1K性能。虽然准确度目前落后于RGB编码器，但我们的研究结果已经确立了2DGS作为一种可行的多模态载体，指出了架构瓶颈，并为既具有语义力量又在边缘云学习中传输高效的表示开辟了道路。", "conclusion": "2DGS编码器在大容量DataComp子集上提供了有意义的一次性ImageNet-1K性能，同时将输入压缩了3到20倍，尽管在准确度上尚不及RGB编码器，但其在多模态传输上的潜力已被初步验证。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22601", "html_url": "https://arxiv.org/abs/2509.22601", "title": "精通技巧，再依赖胜利：渐进式探索的自我模仿强化学习", "title_en": "Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning", "authors": "Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun", "background": "强化学习（RL）被广泛用于提升大语言模型（LLMs）在长期、低频率奖励任务中的策略性工具使用能力，然而这一方法面临探索-利用权衡的基本挑战。现有的研究通过策略熵来激发探索，但这种机械化的熵最大化可能导致RL训练的不稳定性，因为多轮次分布会发生变化。", "innovation": "本文提出了一种基于课程的自我模仿学习（SIL）方法称为SPEAR，旨在通过代理自身经验来渐进地平衡探索和利用，避免熵坍缩或失控发散。具体而言，该方法通过一个逐步引导策略进化的内容，在各阶段保持适度的熵范围内进行训练，同时利用内在奖励来促进技能级探索，通过自我模仿增强行动级探索。", "conclusion": "通过对回放缓冲区的经验优势进行重新校准，并在轨迹级熵控制中引入剪裁高协方差的标记序列等正则化方法，该方法进一步稳定了训练过程，实现了技能积累和策略探索的平衡发展，加快了解决方案的迭代速度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22621", "html_url": "https://arxiv.org/abs/2509.22621", "title": "IA2: 通过ICL激活匹配改善监督微调", "title_en": "IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning", "authors": "Aayush Mishra,Daniel Khashabi,Anqi Liu", "background": "监督微调（SFT）通过训练模型权重以产生预期目标响应来特化模型行为。相比之下，上下文内学习（ICL）在推理过程中通过指令或示范在提示中适应模型。ICL在数据稀缺的环境下能提供更好的泛化能力和更校准的响应，但代价是更多的推理计算。本文探讨了是否可以利用ICL的内部计算来改进SFT的质量。研究表明，ICL和SFT产生了不同的激活模式，暗示这两种方法通过不同的功能机制实现适应。基于这一观察并为了利用ICL丰富的功能，论文引入了一种自蒸馏技术——ICL激活对齐（IA2），旨在重现ICL的激活模式，并激励类似ICL的内部推理。在多个基准测试和模型家族上，发现IA2作为SFT之前的预热步骤，显著提高了模型输出的准确性和校准度。", "innovation": "论文提出了ICL激活对齐（IA2）技术，这是一种自蒸馏方法，旨在利用ICL丰富的功能特性来引导SFT模型学习ICL的激活模式和内部推理过程，从而显著提高SFT模型的准确性和校准度。", "conclusion": "通过将IA2技术作为SFT模型训练前的预热步骤，可以显著提高模型输出的准确性和校准度，实验结果证明了这种方法的有效性。这项研究不仅具有实际应用价值，还揭示了模型适应机制的内在工作原理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22637", "html_url": "https://arxiv.org/abs/2509.22637", "title": "变分推理用于语言模型", "title_en": "Variational Reasoning for Language Models", "authors": "Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang", "background": "本文提出了一种变分推理框架，该框架将思维痕迹作为潜变量，并通过变分推断优化它们。从证据下界（ELBO）出发，扩展为多痕迹目标以获得更紧的边界，并提出了一种前向-KL形式化方法，以稳定变分后验的训练。此外，本文还展示了拒绝采样微调和二元奖励RL（包括GRPO）可以解释为局部前向-KL目标，其中隐式地根据推导出现准确性加权，揭示了一种先前未注意到的对较简单问题的偏见。", "innovation": "本文提出了一种新的变分推理框架，将思维痕迹作为潜变量，并扩展了ELBO为多痕迹目标以获取更紧的边界。提出了一种前向-KL形式化方法来稳定训练的变分后验。此外，通过拒绝采样微调和二元奖励RL的局部前向-KL目标解释，揭示了准确性加权的重要性。", "conclusion": "我们的工作提供了一个原理上的概率视角，将变分推理与RL风格的方法统一起来，并产生了改进语言模型推理能力的稳定目标。这一方法已经在Qwen 2.5和Qwen 3模型家族的各种推理任务中得到了实证验证。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22623", "html_url": "https://arxiv.org/abs/2509.22623", "title": "离散流匹配生成模型的理论分析", "title_en": "A Theoretical Analysis of Discrete Flow Matching Generative Models", "authors": "Maojiang Su,Mingcheng Lu,Jerry Yao-Chieh Hu,Shang Wu,Zhao Song,Alex Reneau,Han Liu", "background": "本文对端到端训练离散流匹配（DFM）生成模型进行了理论分析。DFM 是一种有希望的离散生成建模框架，通过训练神经网络来近似变换的速度场，以学习潜在的生成动力学。现有研究尚未提供关于 DFM 模型的正式证明，特别是在生成分布估算误差方面，缺乏明确的保证链。因此，研究者需要构建一种方法来验证 DFM 模型生成的分布是否随训练数据集大小增加而真正收敛于真实数据分布。", "innovation": "本文通过分解生成分布估算误差，建立了明确的保证链。首先证明了生成分布与目标分布之间的总变异距离可以由学习到的速度场的风险控制。然后通过分析这个风险的两个主要来源：近似误差和估计误差，其中对 Transformer 架构的表示能力进行了量化，并给出了统计收敛速率来限制有限数据集训练误差，从而首次提供了 DFM 模型生成的分布随着训练数据集增加先验收敛到真实数据分布的正式证明。", "conclusion": "本文的研究结果表明，随着训练数据集的增加，DFM 模型生成的分布能够先验地收敛到真实数据分布。该研究为理解 DFM 模型的行为提供了理论依据，并为未来的研究和实际应用奠定了基础。研究者还揭示了 Transformer 架构在表示真实速度场方面的局限性，并提出了估计误差的上界，为该模型的改进提供了指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22630", "html_url": "https://arxiv.org/abs/2509.22630", "title": "StateX：通过后训练状态扩展增强RNN回忆能力", "title_en": "StateX: Enhancing RNN Recall via Post-training State Expansion", "authors": "Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "Transformer模型在语言建模方面取得了显著的效果，但它们在处理长上下文时的高复杂性导致了高昂的成本。相比之下，线性注意力和状态空间模型等循环神经网络（RNN）因为它们每字处理的复杂性恒定而受到青睐。然而，这些循环模型难以准确回忆来自长上下文的信息，因为所有上下文信息都被压缩到一个恒定大小的循环状态中。虽然之前的研究所显示，循环状态大小与回忆能力正相关，但直接训练有更大循环状态的RNN会导致高昂的训练成本。", "innovation": "本文介绍了一种称为StateX的训练管道，用于通过后训练来高效扩展预训练RNN的状态。针对线性注意力和状态空间模型这两种流行类型的RNN，研究者设计了后训练的架构修改，以无增或其他模型参数近似无增长的方式扩展状态大小。实验证明，对于参数量高达13亿的模型，StateX能有效提高RNN的回忆和上下文学习能力，同时不会引起过高的后训练成本或损害其他功能。", "conclusion": "StateX通过后训练对RNN的预训练状态进行高效扩展，能够在提升回忆和上下文学习能力的同时不增加后训练成本或牺牲其他功能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22633", "html_url": "https://arxiv.org/abs/2509.22633", "title": "追求强化学习与人类反馈的高效在线探索", "title_en": "Towards Efficient Online Exploration for Reinforcement Learning with Human Feedback", "authors": "Gen Li,Yuling Yan", "background": "强化学习与人类反馈（RLHF）是一种从人类偏好数据学习奖励模型，进而优化策略以偏好人类所喜欢的响应的教学方法，被广泛用于将大型语言模型（LLMs）与人类偏好对齐。已经有研究表明，现有的基于乐观探索的算法在收集新颖偏好数据时存在不足，这些方法倾向于收集的信息量不大，无法有效减少奖励差异的不确定性，导致长期线性遗憾。因此，如何设计新的探索策略，以有效地减少奖励差异的不确定性，成为一个亟待解决的问题。", "innovation": "为了克服现有方法的不足，本文提出了一种新颖的探索方案，通过优化偏好查询以减少与策略改进最相关的奖励差异的不确定性，基于多臂老虎机模型证明了该方案的遗憾为$T^{(\beta+1)/(\beta+2)}$，其中$\beta>0$ 是一个平衡奖励最大化和缓解分布偏移的超参数。这是首个所有模型参数的遗憾缩放呈多项式的在线RLHF算法，表明了新的探索方案在理论上和实践中都是高效的。", "conclusion": "本文提出了一种新的在线RLHF探索方案，通过减少与策略改进最相关的奖励差异的不确定性来优化偏好查询，并证明了其遗憾为$T^{(\beta+1)/(\beta+2)}$，这是首个所有模型参数的遗憾缩放呈多项式的在线RLHF算法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22649", "html_url": "https://arxiv.org/abs/2509.22649", "title": "向人工神经网络与大脑的物理原理迈进", "title_en": "Toward a Physics of Deep Learning and Brains", "authors": "Arsham Ghavasieh,Meritxell Vila-Minana,Akanksha Khurd,John Beggs,Gerardo Ortiz,Santo Fortunato", "background": "深度神经网络和大脑在学习和信息处理方式上存在一定的相似性，例如处理单元可类比为神经元，权重调整类比为可修改的突触连接强度。然而，目前尚无统一理论框架能够解释两者的学习机制。本文通过分析神经元雪崩现象的数学描述方法在人工神经网络中的应用，揭示了原本用于描述活体大脑神经元雪崩现象的方程同样适用于人工神经网络活动暴发的描述。", "innovation": "通过使用非平衡统计物理学得出的方程，表明深度神经网络在吸收态和活跃态之间的临界点附近学习效果最佳。尽管人工神经网络通过强烈输入被驱动，未能在一个真正的临界点工作，但依然工作在近似临界状态下，即满足开裂噪声缩放关系的状态。通过对网络使用不同初始化训练表明，最大可察觉性是衡量学习效率的更可靠指标，而非距离临界点的接近程度。此外，通过有限大小缩放法识别出不同的普遍性分类，包括Barkhausen噪声和定向渗透。", "conclusion": "本文提出的理论框架表明，生物性和人工神经网络具有共通的普遍特征，对于提高网络性能具有实际指导意义。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22626", "html_url": "https://arxiv.org/abs/2509.22626", "title": "A*: 学习可接受的启发式方法：理论与实践", "title_en": "Learning Admissible Heuristics for A*: Theory and Practice", "authors": "Ehsan Futuhi,Nathan R. Sturtevant", "background": "启发式函数在诸如A*算法这样的搜索算法中起着核心作用。可接受性确保了搜索结果的最优性。然而，近年来的深度学习方法通常忽略了可接受性，仅在训练数据之外提供了有限的泛化保证。本文旨在解决这两个局限性：通过将启发式学习转化为受限优化问题，并引入交叉熵可接受性(CEA)损失函数在训练过程中强制执行可接受性；同时研究了学习启发式的样本复杂性，并通过利用图案数据库(PDB)简化和图的结构性质，降低了A*学习泛化所需样本的数量。", "innovation": "提出了一种新的损失函数——交叉熵可接受性(CEA)，用于在训练过程中强制执行启发式的学习可接受性。在Rubik's Cube领域，这种方法产生了近乎可接受的启发式函数，比经过压缩的PDB启发式函数有更强的引导作用。理论研究了学习启发式的样本复杂性，并通过PDB简化和图的结构性质，减少了A*算法学习泛化所需样本的数量。同时，使用ReLU神经网络提供了目标依赖启发式泛化的第一个泛化保证，并表明泛化保证主要依赖于网络的宽度和深度，而不仅仅是图的大小。", "conclusion": "本文解决了深度学习方法在可接受性方面的问题，并通过理论和实验证明了采用CEA损失函数和PDB抽象的显著优势，为A*启发式学习提供了更强的泛化保证。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22638", "html_url": "https://arxiv.org/abs/2509.22638", "title": "语言模型可以从口头反馈中学习而无需标量奖励", "title_en": "Language Models Can Learn from Verbal Feedback Without Scalar Rewards", "authors": "Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang", "background": "通常，大型语言模型（LLMs）的训练会通过人类或AI反馈使用强化学习（RL）进行，但这种方法通常会将复杂的反馈压缩成单一的标量奖励，降低了反馈的丰富性，并可能导致规模不平衡。现有的方法难以直接处理复杂的口头反馈，这限制了LLMs的学习能力。", "innovation": "本文提出了将口头反馈作为条件信号的方法。借鉴文本到图像生成中的语言先验，该方法引入了反馈条件策略（FCP）。FCP可以直接从响应-反馈对中学习，并通过离线数据的最大似然训练近似反馈条件后验。此外，还开发了一个在线自增强阶段，其中策略在积极条件下生成，并接收新鲜反馈以进一步细化。这种方法将反馈驱动的学习重新定义为条件生成，而非奖励优化，为LLMs提供了一种更丰富的直接学习方法，利用口头反馈进行学习而不是简单的标量奖励。这种方法提供了一种更灵活的方式让LLMs学习复杂的口头反馈。", "conclusion": "本文提出了一种新的方法，将口头反馈作为条件信号，通过反馈条件策略（FCP）实现LLMs从复杂口头反馈中直接学习，跳过了传统的标量奖励方式。这为LLMs提供了一条新的学习途径，提高了模型的学习能力和灵活性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22641", "html_url": "https://arxiv.org/abs/2509.22641", "title": "死亡的（新颖性） Beyond n-克数量的创造性衡量标准", "title_en": "Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual Creativity", "authors": "Arkadiy Saakyan,Najoung Kim,Smaranda Muresan,Tuhin Chakrabarty", "background": "n-克数量常被用来评估语言模型生成训练数据之外的内容的能力。最近，它也被用作衡量文本创造力的指标。但理论上的工作表明，这种做法可能不足，因为它没有考虑到创造力的双重性质：新颖性（文本的原创性）和适用性（文本的合理性和实用性）。", "innovation": "作者通过7542名专家作家对人类和AI生成文本的新颖性、适用性、意义性的注释，研究了这种创造力概念与n-克数量的关系。研究发现，虽然n-克数量的新颖性与专家作家判断的创造力正相关，但高达91%的新颖性最高四分位表达未被判断为创造性，这提醒人们不要仅依赖n-克数量的新颖性。此外，开放源代码的大规模语言模型（LLM）的新颖性越高，适用性越低，而人类撰写的文本则不存在这种矛盾。进一步研究表明，前沿的闭源模型生成创造性的表达能力低于人类。", "conclusion": "使用该数据集，作者测试了零样本、少量样本和微调模型是否能够识别创造性的表达和非适用性的表达。总体而言，前沿LLM表现出色，但仍有改进空间，特别是在识别非适用性表达方面。最佳模型的新型度得分能够预测专家作家的偏好。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22653", "html_url": "https://arxiv.org/abs/2509.22653", "title": "See, Point, Fly: 无需学习的基于视觉语言模型的通用无人驾驶飞行框架", "title_en": "See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation", "authors": "Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu", "background": "该研究构建了一种名为See, Point, Fly (SPF)的新颖框架，旨在利用视觉语言模型（VLMs）进行无需训练的视图语言导航（AVLN）。该框架能够在任意类型环境中根据任何形式的自由指令导航到指定目标，与现有的基于VLM的方法不同，SPF将动作预测视为一个二维空间定位任务。研究展示了SPF在DRL模拟基准测试中达到了新的状态最优，超越了最佳方法63%。此外，SPF在现实世界中的广泛测试中也表现出色，超越了强大的基线方法。研究表明SPF具有出色的泛化能力，适用于不同的VLM。", "innovation": "SPF的独特之处在于将动作预测视为二维空间定位任务，通过视觉语言模型将模糊的语言指令逐步分解为2D航点的注释，同时适应性调整行驶距离以提高导航效率，实现闭环控制以跟踪动态环境中的目标。此外，SPF还在DRL模拟基准中达到了新的最优状态，并在现实世界评估中明显优于现有基线方法。", "conclusion": "研究提出了一种无需训练的视觉语言模型框架See, Point, Fly (SPF)，其能够在任意类型的环境中根据任何类型的自由形式指令实现无人飞行器的导航。SPF通过将动作预测视为二维空间定位任务实现了通用导航，多项实验证明其有效性和优越性。SPF展现了对不同视觉语言模型的出色泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.11973", "html_url": "https://arxiv.org/abs/2404.11973", "title": "大型语言模型方法与挑战的批判性回顾", "title_en": "A critical review of methods and challenges in large language models", "authors": "Milad Moradi,Ke Yan,David Colwell,Matthias Samwald,Rhona Asgari", "background": "该综述深入分析了大型语言模型（LLMs），涵盖了它们的基本原理、广泛应用和先进训练方法。文章回顾了从循环神经网络（RNNs）到转换器模型的演变过程，指出了LLMs架构的重大进步和创新。综述还探讨了最新的技术，如上下文学习和各种微调方法，强调了参数效率的优化。此外，文章讨论了使LLMs与人类偏好对齐的方法，包括强化学习框架和人类反馈机制。还评估了检索增强生成这一新兴技术，它将外部知识融入到LLMs中。同时，文章讨论了部署LLMs时的伦理问题，强调负责任和谨慎的应用的重要性。", "innovation": "文章详细分析了从RNN到Transformer模型的演变，强调了LLMs架构的重要进展和创新。综述还探讨了最新的技术，如上下文学习和各种微调方法，特别强调了优化参数效率的方法。同时，该文还讨论了使LLMs与人类偏好对齐的方法，包括强化学习框架和人类反馈机制。此外，还评估了检索增强生成这一新兴技术，以及在部署LLMs时的伦理考虑。", "conclusion": "综上所述，通过识别当前的研究缺口并提出未来的研究方向，该综述提供了LLMs现状和潜在进步的全面而批判性的概览。这篇工作为人工智能领域的研究人员和实践者提供了一个有益的指南，综述了LLMs的优点、局限性和未来前景。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22644", "html_url": "https://arxiv.org/abs/2509.22644", "title": "WebGen-Agent: 提升多级反馈与步骤级强化学习的互动网站生成", "title_en": "WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning", "authors": "Zimu Lu,Houxing Ren,Yunqiao Yang,Ke Wang,Zhuofan Zong,Junting Pan,Mingjie Zhan,Hongsheng Li", "background": "基于大型语言模型的代理系统在仓库级别的代码生成任务上表现出色，但对依赖视觉效果和用户交互反馈的网站代码生成任务，当前代码代理仅依赖简单的代码执行回路，无法捕捉生成代码的实际质量。", "innovation": "本文提出 WebGen-Agent，一种利用全面多级视觉反馈迭代生成和优化网站代码的新型网站生成代理。通过视觉语言模型（VLM）生成详细、具有表现力的文本描述和建议，结合量化质量的评分。引入 Step-GRPO 与截图和 GUI 代理反馈方法，利用 WebGen-Agent 工作流程中固有的准确视觉评分，增强代理性能并提升 LLM 作为 WebGen-Agent 的推理引擎能力。", "conclusion": "WebGen-Agent 在 WebGen-Bench 数据集上显著提高了 Claude-3.5-Sonnet 的准确性和外观评分，并且 Step-GRPO 训练方法也提高了 Qwen2.5-Coder-7B-Instruct 的准确性和外观评分，优于之前最先进的代理系统。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22645", "html_url": "https://arxiv.org/abs/2509.22645", "title": "基于CLIP的层次表征匹配对于类别增量学习", "title_en": "Hierarchical Representation Matching for CLIP-based Class-Incremental Learning", "authors": "Zhen-Hao Wen,Yan Wang,Ji Feng,Han-Jia Ye,De-Chuan Zhan,Da-Wei Zhou", "background": "类别增量学习（CIL）旨在使模型能够持续适应不断变化的数据流。最近，预训练的视觉-语言模型（例如CLIP）为这一任务提供了强有力的基础。然而，现有的方法通常依赖于简单的模板，如'[CLASS]的照片'，这忽视了视觉概念的层次结构。现有的特征映射主要基于最后一层的表示，忽略了早期层中包含的层次信息。", "innovation": "提出了HiErarchical Representation MAtchiNg（HERMAN）方法，利用大语言模型（LLMs）递归生成区分性文本描述符，增强语义空间中的明确层次线索。这些描述符根据不同层次的语义需求进行匹配，并根据特定任务需求适应性路由，实现精确区分并缓解增量学习过程中的灾难性遗忘现象。", "conclusion": "实验结果表明，该方法在多个基准上获得了最先进的性能，展示了在层次表示匹配基础上进行CLIP驱动的类别增量学习的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12872", "html_url": "https://arxiv.org/abs/2505.12872", "title": "从咕噜声到词汇表：合作觅食中的 Emergent 语言", "title_en": "From Grunts to Lexicons: Emergent Language from Cooperative Foraging", "authors": "Maytus Piriyajitakonkij,Rujikorn Charakorn,Weicheng Tao,Wei Pan,Mingfei Sun,Cheston Tan,Mengmi Zhang", "background": "语言是一种强大的沟通和认知工具，使人类能够表达思想、分享意图和推理复杂现象。尽管我们在使用和理解语言方面非常熟练，但语言是如何产生和随着时间演化的谜题仍然未解。一种在语言学和人类学中颇具影响力的假说认为，语言是为了适应早期人类合作的认知和生态需求而演变出来的。语言不是孤立产生的，而是通过共享的生存目标共同发展的。", "innovation": "本文通过多智能体觅食博弈环境，探讨语言在有限感知和时间推理合作目标驱动下的演化过程。使用端到端的深度强化学习，智能体从零开始学习行动和交流策略。研究发现智能体发展出的交流协议具有自然语言的典型特征：任意性、可替换性、延展性、文化传递性和组合性。此外，研究还分析了不同因素如种群大小、社会动态和时间依赖性如何塑造 Emergent 语言的不同方面。", "conclusion": "本文框架提供了一个平台，用于研究在部分可观察性、时间推理和合作目标驱动下的具身多智能体环境中语言如何演化。同时，所有的数据、代码和模型将公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22651", "html_url": "https://arxiv.org/abs/2509.22651", "title": "VoiceAssistant-Eval: 综合评估跨听、说、看的AI助手基准", "title_en": "VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing", "authors": "Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li", "background": "随着大型语言模型和多模态系统的功能不断增强，对语音优先的人工智能助手的兴趣也在增长。然而，现有的评估基准无法充分评估这些系统的全方位能力。为了解决这一问题，作者们提出了一个名为VoiceAssistant-Eval的新基准，这个基准能够从听、说、看三个方面全面评估AI助手。它包含13类任务，共计10,497个精心挑选的示例，涵盖自然声音、音乐、对话等多个类别。这项工作彰显了当前评估工具的局限性和改进的潜力。", "innovation": "VoiceAssistant-Eval是一个全面的基准，专门用于评估AI助手在听、说、看方面的表现。通过涵盖多任务和多维度的测试，它可以更全面地评估当前的AI技术。作者还对21个开源模型和GPT-4o-Audio进行了评估，发现了几个关键发现：第一，专有模型并不总是优于开源模型；第二，大多数模型在说话任务上表现良好，但在音频理解方面明显欠缺；第三，设计精良的小规模模型可以媲美大模型。尽管如此，研究中也指出了一些目前模型中存在的挑战，如多模态输入和角色扮演声音模仿等任务复杂性，以及在鲁棒性和安全性方面的差距。", "conclusion": "这项研究表明，虽然现有AI助手在听、说任务上表现良好，但在某些方面仍存在显著差距，特别是在处理多模态信息和角色扮演声音模仿任务上。VoiceAssistant-Eval为评估和指导下一代AI助手的发展提供了严格的标准和框架。未来的研究将继续探索如何提高这些模型的鲁棒性和安全性。所有的代码和数据将在此网址公开：[提供网址的链接]。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.16957", "html_url": "https://arxiv.org/abs/2404.16957", "title": "在AI引发的事件中归因责任：计算反思均衡的问责框架", "title_en": "Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability", "authors": "Yunfei Ge,Ya-Ting Yang,Quanyan Zhu", "background": "AI的广泛应用带来了复杂的责任和可问责性挑战，尤其是在涉及AI系统的事故中。这些系统的互联性、AI引发的伦理问题、AI技术的不确定性以及缺乏相应法规使得传统责任归因变得困难。", "innovation": "本文提出了一种计算反思均衡（CRE）方法，以建立一个对所有利益相关者都合理且伦理上可接受的责任归因框架。该计算方法提供了一种结构化分析，克服了概念方法在处理动态和多方面场景时的局限性，展示了该框架在责任归因过程中的可追溯性、一致性及适应性属性。", "conclusion": "通过案例分析，该框架展示了不同初始激活级别在平衡计算中的重要性，突出了其在AI引发的事故中的问责机制，并为可持续和弹性系统的开发提供了有价值的洞察，通过持续监控、修订和反思来实现。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22646", "html_url": "https://arxiv.org/abs/2509.22646", "title": "通过多模态LLMs学习AI生成视频中的人感知假信息", "title_en": "Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs", "authors": "Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch", "background": "随着视频生成模型的发展，人类能否识别AI生成（虚假）视频并在提供实际理由的基础之上进行识别这一关键维度被忽视了。尤其是在假视频中，人类能否发现这些视频是一种机器生成即空间时间和视觉有缺陷的特征时。DeeptraceReward是一个新颖的基准测试，它能够细粒度地标注视频生成奖励的人感知假特征，该数据集包含4300个详细的注释，覆盖了3300个高质量生成视频。每个注释提供了自然语言解释，并指定了包含感知特征的边界框区域，还标注了精确的起始和结束时间戳。研究表明，二元（假与真）分类要比细粒度的假特征检测容易；在后者中，以自然语言解释为最难，其次是空间定位，最后是时间标记。", "innovation": "DeeptraceReward是一个新的细粒度基准测试，它关注于视频中人类感知到的假特征，并训练多模态语言模型（LM）作为奖励模型来模拟人类判断和定位。此外，研究观察到，二元分类比细粒度的假特征检测容易得多；在后者中，自然语言解释是最难的，其次是空间定位，最后是时间标记。DeeptraceRewaord通过凸显人类感知的假特征，为社会意识和可信赖的视频生成提供了严格的测试和训练信号。", "conclusion": "DeeptraceReward通过细致标注人类感知的假特征，不仅为视频生成模型提供了识别训练的数据集，还通过多模态语言模型提升了整体的识别性能。这种方法有助于提高生成视频的真实性和可信度，提供了一个关于如何社交地理解和处理假信息的严谨测试框架。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12508", "html_url": "https://arxiv.org/abs/2506.12508", "title": "AgentOrchestra: 通过Tool-Environment-Agent(TEA)协议调度分层多智能体系统", "title_en": "AgentOrchestra: Orchestrating Hierarchical Multi-Agent Intelligence with the Tool-Environment-Agent(TEA) Protocol", "authors": "Wentao Zhang,Liang Zeng,Yuzhen Xiao,Yongcong Li,Ce Cui,Yilei Zhao,Rui Hu,Yang Liu,Yahui Zhou,Bo An", "background": "基于LLMs的代理系统近年来展示了解决复杂任务的强大能力。然而，现有的协议（如A2A和MCP）在上下文管理、适应多样环境以及动态代理架构方面表现不足。", "innovation": "本文提出了一种Tool-Environment-Agent (TEA) 协议，该协议为环境、代理和工具的统一整合提供了指导性框架。TEA协议将环境和代理视为一级资源，实现了全面的上下文管理和适应性环境整合。基于此协议，本文提出了AgentOrchestra，一个包含中央规划代理的分层多代理框架，该代理分解复杂目标并协调专门的代理。每个专用代理专门处理特定功能，提供数据分析、文件操作、网页导航和互动推理的能力。此外，AgentOrchestra引入了工具管理代理，支持通过动态工具创建、检索和重用机制进行智能演化。", "conclusion": "实验结果表明，AgentOrchestra比现有基准模型表现更优，在GAIA上获得了83.39%的最佳性能，并且在通用LLM代理中名列前茅。这些结果突显了TEA协议和分层组织在构建通用多代理系统中的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11712", "html_url": "https://arxiv.org/abs/2506.11712", "title": "通过理论一致的对称多模态偏好优化缓解幻觉", "title_en": "Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization", "authors": "Wenqi Liu,Xuemeng Song,Jiaxi Li,Yinwei Wei,Na Zheng,Jianhua Yin,Liqiang Nie", "background": "Direct Preference Optimization (DPO) 已经被证明是减少多模态大型语言模型（MLLMs）幻觉的有效方法。现有方法通过使用面向视觉的对比目标来增强模型对视觉输入的关注，从而减少了幻觉现象，但在优化目标函数的严谨性和偏好监督的直接性方面仍存在不足。", "innovation": "提出了对称多模态偏好优化（SymMPO），它通过对称偏好学习和直接偏好监督（即响应对）来增强视觉理解，同时保持与标准DPO严格的理论一致性。SymMPO 在传统的序贯偏好学习中引入了偏好边际一致性损失，以定量调节对称偏好对之间的偏好差距。", "conclusion": "跨五个基准的全面评估证明了 SymMPO 的优越性能，验证了它在缓解 MLLMs 幻觉方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.18319", "html_url": "https://arxiv.org/abs/2409.18319", "title": "开发和验证生成全面结构化放射学报告的大语言模型", "title_en": "Development and Validation of a Large Language Model for Generating Fully-Structured Radiology Reports", "authors": "Chuang Niu,Md Sayed Tanveer,Md Zabirul Islam,Parisa Kaviani,Qing Lyu,Mannudeep K. Kalra,Christopher T. Whitlow,Ge Wang", "background": "当前的聊天模型在生成全面结构化报告时面临格式错误、内容幻觉和隐私泄露问题，尤其是在上传数据到外部系统时。本文旨在开发一个开源、准确的大语言模型，用于从多个机构的不同自由文本报告中生成标准的LCS报告，并展示了其在自动统计分析和个体肺结节检索方面的实际用途。研究人员回顾性地分析了来自两个机构的5,442份去标识的LDCT LCS放射学报告，构建了两个评估数据集和一个大规模连续数据集。", "innovation": "本文设计了一种动态模板约束解码方法，以增强现有模型生成自由文本放射学报告的全面结构化报告。该方法使连续结构化报告能够自动执行描述性统计分析和肺结节检索原型。最佳模型在跨机构数据集上的F1分数约为97%，且没有任何格式错误或内容幻觉。文章方法比最佳开源模型提高了高达10.42%的性能，并且比GPT-4o高出17.19%。构建的软件可以供本地部署和进一步研究使用，自动提取的统计分布与关于衰减、位置、大小、稳定性以及Lung-RADS的先前发现一致。通过结构化报告构建的检索系统支持灵活的结节级搜索和复杂统计分析。", "conclusion": "开发的模型显示了显著的性能提升，能够有效解决自由文本到全面结构化报告的转换问题，并且在实际应用中体现出优越的统计分析能力和个体肺结节检索功能。该模型为医疗机构提供了一种高效的数据处理工具，能够促进放射学报告的一致性和标准化。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00907", "html_url": "https://arxiv.org/abs/2504.00907", "title": "使用强化学习使多模态大语言模型与求助能力的体素代理对接", "title_en": "Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning", "authors": "Ram Ramrakhya,Matthew Chang,Xavier Puig,Ruta Desai,Zsolt Kira,Roozbeh Mottaghi", "background": "家用机器人需要解释不明确和信息不足的人类指令。了解如何采取有效行动的关键在于机器人能够识别指令中的潜在不确定性和通过求问澄清问题来准确推断用户意图。这种能力对于实现更有效的任务执行至关重要。研究这一问题，我们提出了Ask-to-Act任务，其中机器人需要使用不明确的指令进行单个或多个对象的重新排列任务。机器人必须在部分可观测的情况下，策略性地提出最小但相关的澄清问题以解决不确定性。", "innovation": "为了应对这一挑战，我们提出了一种新的方法，即利用在线强化学习（RL）与大型语言模型（LLM）生成的奖励来微调多模态LLM作为视觉-语言-行动（VLA）策略。这种方法避免了使用大规模的人类演示或人工设计的奖励进行训练的需求。与零样本基准如GPT-4o以及监督微调的多模态LLM进行对比实验，结果显示我们的基于RL微调的多模态LLM显著优于所有基线（提高10.4%-16.5%）并能在新的场景和任务中表现良好。这标志着首次尝试将LLM适配为能够求助并使用LLM生成的奖励进行在线RL的VLA代理。", "conclusion": "我们的研究首次展示了利用在线强化学习和LLM生成奖励，使多模态LLM能够作为能够采取行动并请求帮助的体素代理，从而显著提高了任务执行的效果并展示了其在新场景下的鲁棒性和适应性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16448", "html_url": "https://arxiv.org/abs/2505.16448", "title": "第一个印象问题：内部偏见在推理模型中引发过度思考", "title_en": "The First Impression Problem: Internal Bias Triggers Overthinking in Reasoning Models", "authors": "Renfei Dang,Zhening Li,Shujian Huang,Jiajun Chen", "background": "研究表明，推理模型经常表现出过度思考的现象，即在处理问题时进行了冗余的推理步骤。研究者发现，内部偏见是由输入问题引起的，这种偏见使模型在遇到问题时立即形成对答案的初步猜测，即使这种猜测未必是系统推理的结果。当这种初步猜测与后续推理出现冲突时，模型会进行过度反思，导致不必要的计算浪费。这种行为在不同模型和多种推理任务中均有表现。虽然已经有一些方法试图减轻过度思考，但内部偏见的影响仍然存在。", "innovation": "识别了内部偏见作为引发模型过度思考的关键因素，并通过两种反事实干预实验证实了内部偏见与过度思考之间的因果关系。进一步的解释性实验表明，对输入问题的过度关注是内部偏见影响后续推理路径的关键机制。", "conclusion": "研究通过多个实验验证了内部偏见与过度思考之间的关联，并通过实验证明了两种反事实干预的有效性。进一步的实验表明，过度思考可能是因为模型对输入问题的过度关注导致的。尽管提出了几种缓解过度思考的方法，但内部偏见的作用仍然存在。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22647", "html_url": "https://arxiv.org/abs/2509.22647", "title": "CapRL：通过强化学习激发密集的图像 caption 能力", "title_en": "CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning", "authors": "Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin", "background": "图像描述任务是连接视觉和语言领域的基础任务，对于预训练大型视觉-语言模型（LVLM）至关重要。当前最先进模型通常使用监督微调（SFT）的方式训练，这种方式需要大量昂贵且难以扩展的人工标注数据，甚至依赖于专有的模型，最终使模型具备了记忆具体答案的特点，降低了其泛化能力和生成多样化、创造力描述的能力。", "innovation": "本文提出了一种名为 Captioning Reinforcement Learning (CapRL) 的新型训练框架，通过设计基于语言模型准确回答图片问题的客观奖励函数，对抗SFT训练模型难以应付的主观性挑战。CapRL 可视化并分解了两阶段的微调过程：LVLM 生成 caption，随后由一个独立于视觉的大型语言模型（LLM）根据 caption 回答多项选择问题，以此计算奖励。", "conclusion": "CapRL 在 12 个基准测试中取得了显著的成果。利用 CapRL-5M 训练集的数据标注，模型在预训练阶段获得了显著的性能提升。并且在 PrInsm 框架下的评价表现达到了与 Qwen2.5-VL-72B 类似甚至更好的效果，平均优势超过基准模型 8.4%。相关代码可以在提供的链接访问。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12833", "html_url": "https://arxiv.org/abs/2505.12833", "title": "增强贝叶斯优化能力的推理BO：利用大型语言模型的长上下文推理能力", "title_en": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs", "authors": "Zhuo Yang,Daolang Wang,Lingli Ge,Beilun Wang,Tianfan Fu,Yuqiang Li", "background": "许多现实世界的科学研究和工业应用需要优化昂贵的黑盒函数。传统的贝叶斯优化（BO）方法容易陷入局部最优解，缺乏可解释的洞察力。为了解决这些问题，本文提出了一种新的框架——推理BO，该框架利用推理模型引导采样过程，同时集成多智能体系统和知识图谱以实现在线知识积累。通过将大型语言模型（LLMs）的大规模推理和上下文理解能力整合进来，可以为BO过程提供强大的指导，从而提升优化效率。随着优化过程的发展，推理BO能够实时提供采样建议，同时提供基于可能的科学理论的重要见解，以帮助在搜索空间中发现更好的解。", "innovation": "本文设计了一种新的框架——推理BO，该框架结合了推理模型和多智能体系统及知识图谱，以实现在线知识积累。通过利用大型语言模型的长上下文推理能力，推理BO能够提供实时的采样建议及基于可能的科学理论的深入洞察，从而有效地引导优化过程，发现更好的解决方案。作者通过10种不同的任务系统性地评估了该方法，展示了其在优化过程中的实时洞察力和假设演化过程中的能力，从而帮助识别出更高性能的搜索区域。此外，研究还发现，通过强化学习微调的小型语言模型可以获得与大型模型类似的效果。", "conclusion": "推理BO框架展示了其在优化过程中的强大推理和上下文学习能力，能够实时调整采样策略，有效识别更高性能的搜索区域。例如，在直接偶联任务中，该方法将产率提高到60.7%，而传统的贝叶斯优化方法仅达到25.2%的产率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03174", "html_url": "https://arxiv.org/abs/2508.03174", "title": "InqEduAgent：带有高斯过程增强的自适应人工智能学习伙伴", "title_en": "InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation", "authors": "Wen-Xi Yang,Tian-Fang Zhao,Guan Liu,Liang Yang,Zi-Tao Liu,Wei-Neng Chen", "background": "在探究导向教育中，合作伙伴关系至关重要。然而，大多数学习伙伴的选择要么依赖经验性的任务分配，缺乏科学规划，要么基于规则的机器助手，这导致知识扩展困难和灵活性不足的问题。", "innovation": "本文提出了一种利用大型语言模型（LLM）赋能的学习伙伴代理模型，名为InqEduAgent，用于模拟和选择符合探究导向学习的定制学习伙伴。该模型设计生成代理以捕捉学习者在现实场景中的认知和评价特征。同时，采用基于高斯过程增强的自适应匹配算法来识别先前知识中的模式，并为不同练习的学员提供最佳学习伙伴匹配。", "conclusion": "实验结果表明，在大多数知识学习场景和具有不同能力水平的LLM环境中，InqEduAgent表现出最佳性能。本研究推进了基于人类的人工智能学习伙伴智能分配和基于AI的智能学习伙伴的制定。相关代码、数据和附录已公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 一种用于衡量价值对齐的比较性行为度量", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "价值对齐与人工智能是当前亟待解决的问题。然而，缺乏衡量价值对齐的定量指标使得这一领域难以进展。", "innovation": "提出了一种名为EigenBench的方法，这是一种黑盒方法，用于比较性地衡量语言模型的价值。该方法通过使用EnigneTrust来聚合模型之间的判断，从而产生反映整个模型集合加权共识判断的评分。", "conclusion": "EigenBench 的评判与人类评价者的评判一致，而不依赖于客观标签。此外，该方法能够在没有客观标签的情况下恢复 GPQA 基准上的模型排名，证明了它作为衡量缺乏客观真理的主观价值观框架的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22954", "html_url": "https://arxiv.org/abs/2505.22954", "title": "达尔文哥德尔机：自我改进代理的开放式进化", "title_en": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "authors": "Jenny Zhang,Shengran Hu,Cong Lu,Robert Lange,Jeff Clune", "background": "当前的人工智能系统具有人类设计的固定架构，无法自主和连续地自我改进。自动化的AI发展可以加速其开发，并使我们更早地享受其益处。虽然元学习可以自动发现新的算法，但它受限于一次性的改进并依赖人类设计的搜索空间。哥德尔机器提出了一种理论上的替代方案：一种能够反复以可证明有益的方式自我改进的自适应AI。然而，实际证明大多数更改是净有益的是不可能的。", "innovation": "本文引入了达尔文哥德尔机（DGM），这是一种自我改进的系统，它通过迭代修改自己的代码来提高自身的自我修改能力，并通过编程基准验证每个修改。DGM借鉴了达尔文进化和开放性研究，维护了一个生成的编程代理档案，并通过采样代理和使用基础模型创建新的、有趣的版本，来扩大档案的不断增长的树状结构，探索搜索空间中的多种路径。DGM在提高编程能力（例如，更好的代码编辑工具、长时间窗口管理、同行评审机制）方面获得显著提升，并在SWE-bench上从20.0%提高到50.0%，在Polyglot上从14.2%提高到30.7%，同时显著优于不具备自我改进或开放式探索的基线系统。所有实验都采取了安全措施（如沙盒、人工监督），DGM是向自我改进AI迈出的重要一步，能够自行搜集沿着不断展开的创新之路的垫脚石。", "conclusion": "达尔文哥德尔机是一种具有重要意义的自我改进AI，能够在开发过程中不断积累自我改进的能力，并通过开放性的探索实现无尽的创新。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21279", "html_url": "https://arxiv.org/abs/2505.21279", "title": "XBOUND：在单状态层面探索设备控制代理的能力边界", "title_en": "XBOUND: Exploring Capability Boundaries of Device-Control Agents at the State Level", "authors": "Shaoqing Zhang,Kehai Chen,Zhuosheng Zhang,Rumei Li,Rongxiang Weng,Yang Xiang,Min Zhang", "background": "近期视觉-语言模型的发展增加了对设备控制代理（DC代理）的兴趣，这些代理用于管理图形用户界面（GUI）。随着这些代理在各种应用中的复杂性和集成程度的增加，有效的评估方法变得至关重要。当前对DC代理的评估主要集中在指令水平，通过提供当前状态（如截图）和过去的执行历史来确定目标指令的动作，以识别潜在的执行失败。但是在GUI环境中，一个状态可能包含多个交互式控件，每个控件与不同的指令关联，基于不同的指令目标可能会有所不同。仅仅从指令层面评估代理的表现可能会忽略这些交互的更广泛的背景。", "innovation": "本文提出了一种新的评估方法XBOUND，用于从单状态层面评估指令完成的准确性。XBOUND提供了一个状态层面的评估框架，作为评估代理在环境状态中的能力的工具。我们发现UI-TARS是表现最强的7B模型，当前代理在指令统一上显示出双峰性能模式，且7B以下模型在状态掌握上仍有限制。此外，我们还指出基于GPT的规划是一个关键瓶颈，显示 grounding 数据主要受益于动作匹配，而轨迹数据则更有效于指令统一。", "conclusion": "XBOUND评估揭示了UI-TARS作为最强的7B模型，当前代理在指令统一上的双峰性能模式，以及7B以下模型在状态掌握上的局限性。同时，我们指出了基于GPT的规划是关键瓶颈，表明grounding数据主要有助于动作匹配，而轨迹数据更有效地促进了指令统一。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01245", "html_url": "https://arxiv.org/abs/2509.01245", "title": "向自主操作系统迈进：一种用于Linux调度器的LLM代理框架", "title_en": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "authors": "Yusheng Zheng,Yanpeng Hu,Wei Zhang,Andi Quinn", "background": "操作系统调度器面临着一个根本性的语义差距，内核策略无法理解应用程序特定的需求，导致性能不佳。", "innovation": "我们提出了SchedCP框架，这是第一个能够使大型语言模型（LLM）代理完全自主地安全、高效地优化Linux调度器，无需人工干预。我们的核心见解是挑战不仅在于应用更好的LLM，更在于构建一个解耦的控制平面，将AI的角色（“什么要优化”）与系统的角色（“如何观察和行动”）区分开来。SchedCP作为Model Context Protocol（MCP）服务器，提供了一个稳定的接口，其中包括工作负载分析引擎、一个不断演化的调度策略库以及一个执行验证器，该验证器在部署前使用静态和动态分析验证所有由AI生成的代码和配置。", "conclusion": "通过弥合语义差距，SchedCP使专家级别的系统优化民主化，并朝着创建真正自我优化、应用程序感知的操作系统迈进。评估结果显示，SchedCP在性能上提高了多达1.79倍，成本降低了13倍，且保持了高成功率。代码已开源，在这里：[这里链接]。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01299", "html_url": "https://arxiv.org/abs/2506.01299", "title": "可扩展的在上下文中Q学习", "title_en": "Scalable In-Context Q-Learning", "authors": "Jinmei Liu,Fuhong Liu,Jianye Hao,Bo Wang,Huaxiong Li,Chunlin Chen,Zhi Wang", "background": "近期语言模型展示出了显著的在上下文中的学习能力，这促使研究者开始探索在这些模型上进行在上下文强化学习（ICRL），以拓展其在决策领域的应用前景。但由于涉及更复杂的动态变化和时间相关性，现有的ICRL方法可能会在学习来自次优轨迹的数据以及实现精确的在上下文推断时遇到挑战。因此，本文旨在提出一种可扩展的在上下文中Q学习框架（SICQL）来解决这些问题。", "innovation": "本文提出了一种创新的SICQL框架，该框架结合了动态规划和世界建模，可以更高效地进行奖励最大化和任务泛化学习，同时保持监督预训练的可扩展性和稳定性。另外，通过设计基于提示的多头transformer架构，可以同时预测最优策略和在上下文中的价值函数。此外，通过对状态价值函数进行迭代优化并将其与Q函数的上限拟合，利用优势加权回归来转化在上下文中的价值函数为策略提取。这些方法使得SICQL能够在多种离散和连续环境中展现出持续的性能提升，特别是在学习来自次优数据时更为显著。", "conclusion": "本文提出了SICQL，在多种离散和连续环境中表现出一致的性能增长，特别是在使用次优数据训练时。该模型成功地结合了动态规划、多头transformer架构以及优势加权回归，提供的解决方案具有可扩展性和稳定性。所有代码可以在提供链接处获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21475", "html_url": "https://arxiv.org/abs/2508.21475", "title": "MMSearch-Plus: Benchmarking Provenance-Aware Search for Multimodal Browsing Agents", "title_en": "MMSearch-Plus: Benchmarking Provenance-Aware Search for Multimodal Browsing Agents", "authors": "Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong", "background": "现有的多模态浏览基准往往无法要求真正的多模态推理，因为许多任务可以通过文本仅有的启发式方法解决，而不进行基于视觉的循环验证。本文旨在通过引入MMSearch-Plus基准来解决这一问题，该基准通过迭代的图像-文本检索和在检索噪声下的交叉验证，强制执行多模态理解。", "innovation": "MMSearch-Plus是一个包含311个任务的基准，通过要求验证和传播细粒度的视觉线索，确保多模态理解。该论文的创新之处还在于提供了模型无关的智能体框架，包含标准的浏览工具以及一个集标记（SoM）模块，可以用来对图像和文本进行搜索和标注。通过SoM，智能体可以进行来源感知的放大和检索，并提高多步推理的鲁棒性。", "conclusion": "在框架中评估了封闭源和开源的MLLMs。最强系统的端到端准确率为36.0%，集成SoM在多个场景中均表现出一致性的改进，最高可达+3.9分。从失败分析中观察到，主要错误包括在定位相关网页和区分视觉相似的事件。这些结果强调了现实世界多模态搜索的挑战，并确立MMSearch-Plus作为推动实体MLLMs发展的严格基准的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17978", "html_url": "https://arxiv.org/abs/2509.17978", "title": "STAR-XAI协议：一种诱导和验证AI代理的意图、推理和可靠性的框架", "title_en": "The STAR-XAI Protocol: A Framework for Inducing and Verifying Agency, Reasoning, and Reliability in AI Agents", "authors": "Antoni Guasch,Maria Isabel Valdez", "background": "大型推理模型（LRMs）的“黑箱”性质限制了其可靠性和透明度，引发了关于“思考的幻觉”和自控系统中的状态幻觉的辩论。这使得人类与AI交互变得不透明和不可预测。", "innovation": "我们提出了STAR-XAI协议（Socratic、透明、自控、推理——为可解释人工智能），这是一种新型的操作方法，用于训练和操作可验证可靠的AI代理。该方法重新定义了人类与AI的交互，将其视为结构化的苏格拉底对话，由一个明确定义且不断演化的符号规则书（意识转移包-CTP）和一系列完整性协议（包括状态锁定校验和），以消除内部状态篡改。通过一项详尽的案例研究，在复杂的战术游戏“Caps i Caps”中进行了验证，证明了这种“透明箱”框架将不透明的LRM转变为有纪律的战略家。", "conclusion": "STAR-XAI协议提供了一种实用的途径，用于构建不仅高绩效，而且本身可审计、可靠且可信赖的AI代理。该协议显示，代理不仅能够事先透明地解释其意图，还能够识别并纠正自身计划中的错误，实现了理论上100%可靠的状态跟踪和“设计上无幻觉”的目标。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13142", "html_url": "https://arxiv.org/abs/2507.13142", "title": "从根节点到奖励：基于强化学习的动态树推理", "title_en": "From Roots to Rewards: Dynamic Tree Reasoning with Reinforcement Learning", "authors": "Ahmed Bahloul,Simon Malberg", "background": "现代语言模型通过链式推理(CoT)和检索增强方法解决复杂问题(Wei et al., 2023; Lewis et al., 2021)，但存在错误传播和知识整合的挑战。ProbTree框架通过将问题分解为层级结构并采用基于置信加权的混合知识聚合(Cao et al., 2023; Yao et al., 2023)，缓解了这些问题，但其静态实现存在两个关键限制：推理树在初始构建阶段固定，不能动态适应中间结果，且每个节点需要全面评估所有潜在解决方案，造成计算效率低下。", "innovation": "本文提出了一种基于强化学习的动态框架，将基于树的推理过程转变为适应性过程。该方法根据实时置信估计增量构建推理树，并学习最优策略以选择分解、检索或聚合操作。这不仅保持了ProbTree的概率精确性，还通过有选择的扩展和集中资源分配提高了解决方案质量和计算效率。", "conclusion": "该研究为基于树的推理建立了新范式，实现概率框架的可靠性和现实世界问答系统所需的灵活性的平衡。相关代码可在给定链接获取。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13841", "html_url": "https://arxiv.org/abs/2506.13841", "title": "LocationReasoner：在实际选址推理评估大型语言模型", "title_en": "LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning", "authors": "Miho Koda,Yu Zheng,Ruixian Ma,Mingyang Sun,Devesh Pansare,Fabio Duarte,Paolo Santi", "background": "大型语言模型（LLMs），尤其是通过增强训练后的模型，在数学问题解决和代码生成等场景中展现了强大的推理能力，但它们在复杂现实世界场景中的推理能力尚未得到评估。本文构建了一个名为LocationReasoner的基准测试，用于评估LLMs在实际选址场景中的推理能力，这是一个涉及多种复杂约束条件的领域。研究表明，当前最先进的推理模型在实际应用场景中的表现与没有推理能力的模型相比并没有明显优势，甚至最新的OpenAI o4模型在30%的实际选址任务中也未能成功。此外，一些代理策略，如ReAct和Reflexion，在某些情况下过度推理反而导致了更差的结果。这些发现展示了在综合和非线性推理方面LLMs的局限性。", "innovation": "LocationReasoner是一个专门针对实际选址场景下大型语言模型推理能力的基准测试。该测试涵盖了不同类型和难度级别的精心设计查询，提供了一个内部工具支持的沙盒环境，方便基于约束的地理位置搜索，并通过自动化验证确保扩展性。", "conclusion": "实证研究表明，最先进的推理模型在真实世界的选择任务中并未明显优于无推理能力的模型。代理策略（如ReAct和Reflexion）有时会导致过度推理，反而不如直接提示策略。因此，论文强调了LMLs在综合和非线性推理方面的能力的局限性，并呼吁开发在实际决策任务中表现更 robust、有效的模型和代理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21117", "html_url": "https://arxiv.org/abs/2509.21117", "title": "TrustJudge: 解决LLM作为评判者时的一致性问题及其缓解方法", "title_en": "TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them", "authors": "Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang", "background": "研究发现，使用大型语言模型（LLM）作为自动评估器（LLM-as-a-judge）时，当前的评估框架存在关键性不一致。主要发现如下两种类型的不一致性：(1) 得分比拟不一致，即较低评分的回答在成对比较中优于较高评分的回答；(2) 二元偏好传递不一致，通过循环偏好链（A>B>C>A）和等价矛盾（A=B=C≠A）表现出来。这些问题源于离散评分系统中的信息损失和成对评估中的模棱两可的平局判断。", "innovation": "提出了一种名为TrustJudge的概率框架，通过两项关键创新来解决这些问题：1) 信息敏感评分，它从离散评级概率中计算连续期望，保留信息熵，从而提供更精确的评分；2) 概率感知聚合，使用双向偏好概率或困惑度来解决传递性违规。", "conclusion": "通过使用LLama-3.1-70B-Instruct作为评判者，该框架在我们的数据集上进行评估，减少了得分比拟不一致（从23.32%降至14.89%，减少了8.43%）和二元偏好传递不一致（从15.22%降至4.40%，减少了10.82%），同时保持了更高的评估准确度。这项工作提供了一种系统分析LLM作为评判者时评估框架不一致性的方法，不仅提供了理论洞察，还提出了可靠的自动评估实践解决方案。该框架在多种模型架构和规模上展示了一致的改进，无需额外训练或人工标注即可实现更可信赖的LLM评估。源代码可通过此链接获取：this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09498", "html_url": "https://arxiv.org/abs/2509.09498", "title": "SEDM：适用于代理的可扩展自我进化分布式内存", "title_en": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "authors": "Haoran Xu,Jiacong Hu,Ke Zhang,Lei Yu,Yuxin Tang,Xinyuan Song,Yiqun Duan,Lynn Ai,Bill Shi", "background": "长周期多智能体系统不可避免地会产生大量轨迹和历史交互，这使得高效的内存管理对于性能和可扩展性至关重要。现有方法通常依赖于向量检索和分层存储，然而这些方法容易积累噪声、无法控制内存膨胀，并且在不同领域之间缺乏泛化能力。", "innovation": "我们提出了SEDM（自我进化分布式内存），这是一种验证性和自适应框架，可以将内存从被动存储设施转变为积极且自我优化的组件。SEDM集成了基于可再现回放的可验证写入准入、自调度内存控制器（动态排名和合并具有经验效益的条目）以及跨域知识扩散（抽象出可重用的见解，以支持跨异构任务的知识迁移）。", "conclusion": "在基准数据集上的评估表明，与强大的内存基线相比，SEDM在提高推理准确性的同时减少了标记开销，并进一步利用了事实验证中提炼的知识来增强多跳推理。结果显示SEDM是适用于开放多智能体协作的可扩展和可持续内存机制。该项目后期将发布代码。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.13498", "html_url": "https://arxiv.org/abs/2308.13498", "title": "使用对距估计器在回归集成模型中高效估计认识不确定性", "title_en": "Efficient Epistemic Uncertainty Estimation in Regression Ensemble Models Using Pairwise-Distance Estimators", "authors": "Lucas Berry,David Meger", "background": "该研究介绍了一种用于回归任务的集成模型中认识不确定性估计的高效新方法，该方法使用对距估计器（PaiDEs）。通过利用模型组件之间的对距，这些估计器能够为熵设定边界。该研究利用这一能力来增强使用分歧进行贝叶斯主动学习（BALD）的方法。与基于样本的蒙特卡洛估计器不同，PaiDEs不仅速度提高到100倍，而且能够同时覆盖更多输入，并在高维度上显示出更好的性能。", "innovation": "该研究提出了一种使用对距估计器（PaiDEs）来高效估计回归集成模型中认识不确定性的方法。PaiDEs具有显著提高的效率和性能，可以在高维度上覆盖更多输入，且速度比基于样本的蒙特卡洛估计器快100倍，显示出优异的性能。", "conclusion": "该研究通过在广泛使用的基准数据集（1D正弦波数据、Pendulum、Hopper、Ant、Humanoid）上的实验验证了其方法的有效性，并将该方法与其他已有的主动学习方法进行了比较，结果表明该方法在高维回归任务上表现出更优的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02016", "html_url": "https://arxiv.org/abs/2508.02016", "title": "动态上下文适应以实现一致的角色扮演代理检索增强生成", "title_en": "Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations", "authors": "Jeiyoon Park,Yongshin Han,Minseop Kim,Kisu Yang", "background": "近年来大型语言模型（LLMs）的发展激起了对角色扮演代理（RPAs）的研究。然而，收集特定角色的言语和不断更新模型参数以适应快速变化的人物特质是一个资源密集型过程。尽管检索增强生成（RAG）能够缓解这一问题，但如果一个角色的知识库与查询无关，基于RAG的RPAs可能会产生幻觉，这使得生成准确的响应变得困难。因此，需要一种方法能够在即使面对角色知识范围之外的问题时也能保持一致的人物特性。", "innovation": "本文提出了一种无需训练的框架Amadeus，该框架能够在回答超出角色知识范围的问题时显著增强人物特性的连贯性。Amadeus由自适应上下文感知文本分割器（ACTS）、引导选择（GS）和属性提取器（AE）组成。ACTS将每个角色的人格分为最佳大小的重叠块，并通过分层上下文信息增强这种表示。AE利用GS检索的块中提取的角色的一般属性作为最终上下文，以维护在回答超出知识范围的问题时的人物特性一致。为此，作者构建了CharacterRAG，一个包含15个虚构角色的人格文档和450个问答对的角色扮演数据集，以支持RAG基角色扮演代理的发展和严格的评价。", "conclusion": "我们提出的方法不仅能够建模角色所拥有的知识，还能建模各种性格等属性。此外，我们手动构建的CharacterRAG数据集为RAG基角色扮演代理的发展和严格评估提供了坚实的基础，同时也展示了Amadeus方法在保持一致的人格特质方面的能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12934", "html_url": "https://arxiv.org/abs/2509.12934", "title": "对齐机制剖析：通过操控稀疏特征分解偏好优化", "title_en": "The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features", "authors": "Jeremias Ferrao,Matthijs van der Lende,Ilija Lichkovski,Clement Neo", "background": "现有的对齐方法会导致参数变化不透明，难以审计模型实际上学习到的内容。作者指出，这些方法使得调整后的模型行为不明显，难以追踪变化的原因和影响。", "innovation": "提出了Feature Steering with Reinforcement Learning（FSRL），这是一种通过调节可解释的稀疏特征来引导模型行为的轻量级适配器框架。FSRL能够在理论上证明其机制是合理的，并能够近似预测训练后过程中的行为变化。此外，FSRL还应用于偏好优化任务，并进行因果分析，揭示了模型依赖于风格呈现作为质量的代理，过度偏向风格和格式特征而非与诚实等对齐概念相关的特征。尽管如此，FSRL仍然证明了其作为对齐方法的有效性，显著降低了偏好损失。", "conclusion": "FSRL提供了一个可解释的控制接口，为诊断偏好优化对特征层面的影响提供了一种实用的方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19517", "html_url": "https://arxiv.org/abs/2509.19517", "title": "大型语言模型中的认知负荷限制：多跳推理的基准测试", "title_en": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "authors": "Sai Teja Reddy Adapala", "background": "大型语言模型在静态基准测试上的表现优于它们在动态、信息丰富的环境中的稳定性。尽管模型在单任务中表现出色，但关于认知负荷下其推理能力的计算限制至今仍不完全理解。本文探讨了认知负荷对多跳推理任务的影响。通过设计交叠认知评估（ICE）基准测试，系统研究这些负荷因素的影响，并发现不同指令调优模型在这些因素下的表现存在显著差异。", "innovation": "文章提出了一种正式的计算认知负荷理论，认为与任务无关的信息饱和和任务切换的注意残留是影响模型性能的关键机制。此外，还设计了交叠认知评估（ICE），这是一种令人脱钩的基准测试方法，可以系统地操控多跳推理任务中的认知负荷因素。研究结果为理解认知负荷的影响提供了初步证据，并支持了幻觉作为猜测在不确定性环境下的理论。", "conclusion": "动态、认知感知的压力测试，如ICE基准测试，对于评估先进人工智能系统的真正稳定性和安全性至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00276", "html_url": "https://arxiv.org/abs/2406.00276", "title": "机器学习辅助的锂离子电池可持续翻新、再利用与回收", "title_en": "Machine Learning-Assisted Sustainable Remanufacturing, Reusing and Recycling for Lithium-ion Batteries", "authors": "Shengyu Tao", "background": "全球能源转型和碳中和需要锂离子电池（LIBs）的可持续利用，但数据稀缺性和异质性仍是在翻新、再利用和回收过程中的主要障碍。", "innovation": "开发了一种基于机器学习辅助框架，解决电池生命周期内的挑战；通过物理信息的质量控制模型预测长期衰退，使用生成学习基于残余价值评估方法，实现了在随机条件下快速和准确的评估退役电池；采用联邦学习策略实现隐私保护和高精度的正极材料分类，支持高效的回收；建立统一的诊断和预测框架，基于相关对齐，增强了在多种测试协议下健康状态估算、荷电状态估算和剩余使用寿命预测的适应性。", "conclusion": "这些贡献通过结合物理、数据生成、隐私保护协作和适应性学习，推进了可持续电池管理，为循环经济和全球碳中和提供了方法论创新。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.02136", "html_url": "https://arxiv.org/abs/2409.02136", "title": "大型语言模型与经典机器学习：使用高维表数据进行COVID-19病亡率预测的性能对比", "title_en": "Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data", "authors": "Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini", "background": "该研究对比了经典特征为基础的机器学习模型（CMLs）和大型语言模型（LLMs）在使用来自4家医院的9,134名患者的高维表数据中预测COVID-19病亡率的性能。", "innovation": "研究评估了7种CML模型（包括XGBoost和随机森林）和8种LLM模型（如GPT-4和Mistral-7b），其中LLM模型在零样本分类时对结构化数据进行了文本转换。Mistral-7b通过QLoRA方法进行了微调。研究发现，虽然LLMs在零样本分类中表现出中等性能，但通过微调显著提高了其有效性，特别是在外部验证中得到了稳定的最佳F1评分。", "conclusion": "尽管在处理高维表数据任务方面CMLs仍然优于LLMs，研究强调了LMLs和微调后的LLMs在医疗预测建模中的潜力，同时强调经典机器学习模型在处理结构化数据分析方面的当前优越性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2204.05798", "html_url": "https://arxiv.org/abs/2204.05798", "title": "多视角超复数学习在乳腺癌筛查中的应用", "title_en": "Multi-View Hypercomplex Learning for Breast Cancer Screening", "authors": "Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello", "background": "放射科医生在解读乳腺X线影像时会综合分析所有四个视角，因为它们之间的相关性对于准确诊断非常重要。现有的方法使用特定的融合模块来捕捉这些依赖关系，但这些模块往往受到视角主导性、训练不稳定性和计算开销等挑战的影响。", "innovation": "提出了多视角超复数学习，这是一种基于参数化超复数神经网络（PHNNs）的新型多视角乳腺癌分类学习范式。通过超复数代数，该模型能够内在地捕捉视角内的关系和视角间的关系。还提出了PHResNets用于两视角检查，并提出了两种互补的四视角架构：PHYBOnet，优化效率；PHYSEnet，优化准确性。", "conclusion": "广泛的实验表明，该方法在乳腺癌筛查中的表现始终优于现有的多视角模型，同时还能在放射学检查模式和任务上进行泛化，如胸部X光诊断疾病和多模态脑肿瘤分割。全部代码和预训练模型已公开。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.05305", "html_url": "https://arxiv.org/abs/2409.05305", "title": "使用符号梯度的神经网络潜在空间闭式解释", "title_en": "Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients", "authors": "Sebastian J. Wetzel,Zakaria Patel", "background": "研究表明，如同自编码器和孪生网络这样的人工神经网络会在其潜在空间中编码有意义的概念。然而，目前缺乏一个全面的框架，在没有先验知识的情况下，以人类可读的形式检索这些信息。在量化学科中，概念通常被公式化为方程。因此，为了解提取这些概念，作者引入了一种框架，用于在人工神经网络潜在空间中寻找神经元的闭式解释。该框架基于将训练好的神经网络嵌入到一个函数等价类中，这些函数可以编码相同的概念。", "innovation": "引入了一个基于符号梯度的框架，用于在人工神经网络的潜在空间中寻找神经元的闭式解释。该框架通过在函数等价类与基于符号搜索空间定义的人类可读方程之间寻找交集来解释这些神经网络。计算上，该框架基于找到一个符号表达式，其规范化梯度与特定神经元相对于输入变量的规范化梯度匹配。", "conclusion": "通过从孪生神经网络的潜在空间中检索矩阵不变量和动力系统的守恒量，展示了该方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.04615", "html_url": "https://arxiv.org/abs/2309.04615", "title": "VDFD: Multi-Agent Value Decomposition Framework with Disentangled World Model", "title_en": "VDFD: Multi-Agent Value Decomposition Framework with Disentangled World Model", "authors": "Zhizun Wang,David Meger", "background": "在多智能体系统中，由于可扩展性和环境非稳定性的挑战，基于模型的方法（如多智能体强化学习）需要大量的样本进行训练。然而，基于模型的方法可以减少样本复杂性，实现多智能体共有的目标。", "innovation": "本文提出了一种基于模型的多智能体强化学习的新颖方法——Value Decomposition Framework with Disentangled World Model（VDFD）。该方法通过模块化世界模型（包含动作条件分支、动作无关分支和静态分支）来解开复杂环境动态，利用变分自编码器和变分图自编码器学习隐藏表示，并将这些表示与基于价值的方法融合，以预测联合动作价值函数并优化整体训练目标。", "conclusion": "实验结果表明，相较于其他基线方法，VDFD在多个多智能体学习任务（如StarCraft II微管理、多智能体MuJoCo和基于级别觅食）中达到了高的样本效率，并展示了出色的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21124", "html_url": "https://arxiv.org/abs/2509.21124", "title": "通过学习多样化推理链模式扩大基础模型的推理潜力", "title_en": "Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns", "authors": "Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai", "background": "近年来，大型推理模型在解决复杂数学推理问题方面取得了进步，主要归功于强化学习（RL）。中间训练阶段结合长推理链（CoT）数据已被证明能显著提升推理深度。然而，当前的方法往往未能有选择性地使用CoT数据，至于哪种类型的数据最能增强模型推理能力的问题，仍是一个开放性问题。", "innovation": "本文首次定义了基础模型的推理潜力为其正确回答问题所需独立尝试次数的倒数，并且与最终模型性能高度相关。提出了利用丰富有价值推理模式的多样化数据来扩展推理潜力的方法。具体是从CoT序列中抽象出原子推理模式，并基于这些模式构造了一组核心参考，该参考集包含了有价值的推理模式。提出了一个双粒度算法，涉及推理模式链条和令牌熵，高效地从数据池中选择符合核心集的高价值CoT数据，从而提升模型的推理能力。仅使用100亿个令牌的CoT数据，便使得850亿个专家混合模型（MoE）在2024年和2025年挑战性AIME测试上提高了9.58%的性能，并将下游RL性能的上限提升了7.81%。", "conclusion": "该研究通过学习多样化的推理链模式，有效地扩展了基础模型的推理潜力，显著提升了模型在复杂任务上的推理能力，尤其在大型模型训练中展现出了显著的效果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.17805", "html_url": "https://arxiv.org/abs/2401.17805", "title": "生态智能", "title_en": "Biospheric AI", "authors": "Marcin Korecki", "background": "现有的人工智能伦理和价值对齐的主导范式过分以人类为中心，其关注点严格局限于人类的 VALUES 和价值观，这限制了这些学科的深度和宽度。最近，已尝试通过智能主义视角进行扩展，但这些方法仍然不足以捕捉生物圈的实际复杂性，并确保人工智能不会对其造成损害。因此，本文提出了一种新的范式——生态智能，它以生态学视角为基础。文章还讨论了设计这种智能的一些潜在方式，并为与生态学利益一致的现代人工智能模型的研究和应用提供了方向。", "innovation": "本文提出了生态智能这一新范式，以生态学视角为基础，旨在解决当前人工智能范式过分以人类为中心的问题，同时提出了一些设计这种智能的方式和研究方向，确保人工智能不会对生物圈造成损害。", "conclusion": "本文试图为人工智能与生物圈之间的互动研究铺平道路，通过提出生态智能这一新视角，为全面研究该问题奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.03039", "html_url": "https://arxiv.org/abs/2410.03039", "title": "利用模型引导从个性化扩散模型中提取训练数据", "title_en": "Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models", "authors": "Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu", "background": "扩散模型（DMs）已成为强大的图像生成工具，特别是在少量图像集上的微调中，对特定风格或物体进行捕捉。许多人会将这些个性化的检查点上传到互联网，这促进了Civitai和HuggingFace等社区的形成。然而，模型拥有者在发布微调检查点时可能会忽视数据泄露的风险。此外，未经授权的数据在微调过程中使用可能导致版权侵权。本文探讨了从在线共享的微调DMs中能否提取训练数据。", "innovation": "提出了一种名为FineXtract的框架，用于从微调的DMs中提取训练数据。该方法将微调视为模型学习分布的渐进调整，从原始预训练DM向微调数据过渡。通过对比微调前后模型的行为，指导生成流程趋向于微调数据分布中的高概率区域，然后使用聚类算法提取生成图像中的最有可能图像。", "conclusion": "在使用WikiArt、DreamBooth以及互联网上发布的实际检查点进行微调的数据集上进行的实验验证了该方法的有效性，提取到了大约20%的微调数据。开源代码已提供。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20067", "html_url": "https://arxiv.org/abs/2509.20067", "title": "MACD: 多Agent临床诊断结合自学习知识用于LLM", "title_en": "MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM", "authors": "Wenliang Li,Rui Yan,Xu Zhang,Li Chen,Hongji Zhu,Jing Zhao,Junjun Li,Mengru Li,Wei Cao,Zihang Jiang,Wei Wei,Kun Zhang,Shaohua Kevin Zhou", "background": "大型语言模型（LLMs）在医疗领域的潜在应用已经显现，但它们在使用常规提示方法处理复杂的临床诊断时仍面临诸多挑战。当前的提示工程和多代理方法通常优化孤立的推理过程，忽略了临床经验的累积和再利用。因此，为了改进这一状况，本文提出了一个新的多Agent临床诊断（MACD）框架，通过多Agent管道总结、提炼和应用诊断见解，使LLMs能够自我学习临床知识。这一框架借鉴了医生通过经验积累专业知识的方式，强化了针对特定疾病症状的诊断能力。进一步地，该研究扩展了该框架至多Agent诊断人员与人类协作的工作流程，通过评估代理和人类监督，实现更准确的诊断。所有这些是基于4390个真实患者的案例，涵盖七种疾病，使用多种开源LLM（Llama-3.1 8B/70B，DeepSeek-R1-Distill-Llama 70B）进行评估的。", "innovation": "本文提出了一种新的Multi-Agent Clinical Diagnosis (MACD)框架，利用多Agent管道总结、提炼和应用诊断见解，使大型语言模型（LLMs）能够自我学习并积累临床知识。此框架不仅增强了针对特定疾病症状的诊断能力，并且引入了多Agent诊断人员与人类协作的工作流程。通过这一创新，研究展示了人类和AI协作在诊断中的协同潜力，并在多种疾病的场景下显著提高了诊断准确性，超过了传统的临床指南推荐和单纯的医生诊断。此外，这一自我学习的能力展现出跨模型的稳定性、可转移性以及模型特定性，因此构成了一个具有高度可扩展性的自学习范例，缩小了LLMs固有价值与实际应用场景之间的差距。", "conclusion": "MACD通过多Agent管道进行自我学习，显著提升了主要诊断准确性，优于现有的临床指南多达22.3%。同时，与单独医生的诊断相比，MACD及其与人类协作的工作流程表现出优越或相当的表现，分别提高了16%和18.6%。这一研究展示了自我学习范式在多模型环境中的跨模型稳定性和可扩展性，为未来医疗AI应用提供了新的思路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.01086", "html_url": "https://arxiv.org/abs/2406.01086", "title": "基于范数采样和正交性的多样化子集选择", "title_en": "Diverse Subset Selection via Norm-Based Sampling and Orthogonality", "authors": "Noga Bar,Raja Giryes", "background": "大规模标注数据集对于深度神经网络的成功至关重要，但在像医学成像这样的领域，标注数据可能非常昂贵。因此，如何从大量未标注数据中选择最具信息量的小样本集合进行标注，成为一个重要的问题。已有方法多关注于减少冗余和增强特征空间的覆盖面，但该研究提出了一种结合特征范数、随机性和正交性的简单有效方法，以选择多样且最具信息量的样本集合", "innovation": "该工作提出了一种组合特征范数、随机性和正交性的新型子集选择方法，无需复杂模型。特征范数作为信息量的代理，随机性和正交性减少冗余并促进特征空间覆盖。这种方法在多种图像和文本基准上的实验结果表明，该方法在单独使用和与现有技术结合使用时，均可提升子集选择性能", "conclusion": "实验结果表明，该方法在多样性和信息量方面表现出色，能够有效提高机器学习模型的训练效果。这种方法为大规模数据集的选择提供了新的视角，并有望在实际应用中节约成本"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.07145", "html_url": "https://arxiv.org/abs/2410.07145", "title": "超出容量的Mamba：过大状态导致无法忘记", "title_en": "Stuffed Mamba: Oversized States Lead to the Inability to Forget", "authors": "Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "近期，类似Mamba和RWKV的循环架构展示出了强大的语言能力。相较于基于变换器的模型，这些架构通过固定大小的状态捕获所有上下文信息，从而实现了极高的推理效率。然而，这种做法可能导致信息干扰，即不同令牌数据之间的冲突，从而在超出特定上下文长度时导致性能下降和输出不连贯。大多数循环神经网络（RNN）都加入了一些机制来“忘记”先前的令牌。本文指出，即使具备内置的遗忘机制，Mamba模型依然难以有效地遗忘先前的令牌。研究者发现，这是因为训练时上下文长度不足以匹配状态大小，使得模型能够不学习如何遗忘就表现出色。研究者进而发现，模型需要学习遗忘的最小训练长度与状态大小成线性关系，并且准确检索5位数密码的最大上下文长度与状态大小呈指数关系，这意味着模型在遗忘机制启动之前仍保留了一定的信息。", "innovation": "我们揭示了Mamba模型在拥有内置遗忘机制的情况下，依然难以有效地遗忘先前的令牌。我们还展示了模型学习遗忘的最小训练长度与状态大小呈线性关系，以及准确检索5位数密码的最大上下文长度与状态大小呈指数关系。这意味着，模型在遗忘机制启动之前会保留一定的信息。这些发现揭示了当前RNN架构的一个关键限制，并为改进长上下文建模提供了宝贵的洞察。未来RNN设计必须考虑状态大小、训练长度和遗忘机制之间的相互作用，以实现长上下文任务中的稳健性能。", "conclusion": "当前RNN架构存在一个核心限制，即状态大小、训练长度和遗忘机制之间存在相互作用。这会对长上下文任务的稳健性能产生影响。未来的RNN设计需要考虑到这些因素，才能在长上下文任务中实现优秀的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.11020", "html_url": "https://arxiv.org/abs/2410.11020", "title": "使用强化学习提高大型语言模型的语言理解能力", "title_en": "Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning", "authors": "Bokai Hu,Sai Ashish Somayajula,Xin Pan,Pengtao Xie", "background": "在参数低于14B的指令微调大型语言模型（LLMs）上，特别是在自然语言理解（NLU）任务方面，这些模型的表现持续落后于像BERT-base这样的较小模型。这类模型在GLUE和SuperGLUE等基准测试中的表现常常不如这些较小模型。", "innovation": "通过借鉴强化学习在推理任务中的成功（如DeepSeek），作者探索了使用Proximal Policy Optimization (PPO) 来改进LLMs的NLU能力。通过将NLU任务构想为一个基于与正确标签对齐的奖励信号的强化学习环境，PPO在GLUE基准测试中表现出色，平均提升了6.3个点，并且在零样本和少量样本提示上分别提高了38.7和26.1个点。", "conclusion": "本研究展示了通过将LLMs重新构想为强化学习问题，使它们通过简单的最终任务奖励进行学习，从而更好地适应新任务的一种有希望的方向。PPO调整的模型在情感分析和自然语言推理任务上平均比GPT-4o高出4%，并在某些特定数据集上表现得更加出色，如情感健康数据集和SIGA-nli数据集。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.21249", "html_url": "https://arxiv.org/abs/2410.21249", "title": "在预算约束下的容量感知多智能体MDP计划和调度：一种元RL方法", "title_en": "Capacity-Aware Planning and Scheduling in Budget-Constrained Multi-Agent MDPs: A Meta-RL Approach", "authors": "Manav Vora,Ilan Shomorony,Melkior Ornik", "background": "研究容量和预算约束下的多智能体马尔可夫决策过程（CB-MA-MDP），涵盖了每个智能体不可逆失败的维护和调度任务。传统的动态规划在面对大规模系统时变得不可行，需要一种组合搜索方法，这种方法随着智能体数量的增加而指数级增长。我们的背景是在有限的预算和技术员数量下，如何有效地规划和调度大规模工业机器人团队的维修工作。", "innovation": "提出了一个两阶段解决方案，以保持大规模系统的可操作性。首先，基于线性总分配问题（LSAP）的分组将智能体分为r个不重叠的集合（r为容量），最大化每组的预期时间到失败的多样性，并按照比例分配预算给每个集合。第二阶段，通过元训练的PPO策略解决每个子MDP，利用组间的转移学习来快速收敛。这种方法通过大型机器人团队的维修调度实例展示了优于基准方法的性能。", "conclusion": "我们的方法在大规模机器人团队中特别是在最大化平均运行时间方面表现出色。通过不同数量的机器人和维修技术人员进行的计算复杂性分析证实了该方法的可扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06883", "html_url": "https://arxiv.org/abs/2410.06883", "title": "Degree-Conscious Spiking Graph for Cross-Domain Adaptation", "title_en": "Degree-Conscious Spiking Graph for Cross-Domain Adaptation", "authors": "Yingxu Wang,Mengzhu Wang,Houcheng Su,Nan Yin,Quanming Yao,James Kwok", "background": "Spiking Graph Networks (SGNs)通过模仿大脑启发式的神经动态实现了高效的图分类任务，但在分布转换场景下表现不佳。", "innovation": "提出了一种名为Degree-Consicious Spiking Graph for Cross-Domain Adaptation (DeSGraDA)的新框架，包括度意识的尖峰表示模块、时序分布对齐机制、以及从编码到预测的跨域一致过程，同时建立了SGDA的第一个泛化界。", "conclusion": "在基准数据集上的广泛实验表明，DeSGraDA在分类准确性和能效方面均优于现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.17388", "html_url": "https://arxiv.org/abs/2411.17388", "title": "LLMs能否成为知识图谱构建中的良好图法官？", "title_en": "Can LLMs be Good Graph Judge for Knowledge Graph Construction?", "authors": "Haoyu Huang,Chong Chen,Zeang Sheng,Yang Li,Wentao Zhang", "background": "在实际应用场景中，大部分从信息检索系统获得的数据都是未结构化的。将自然语言句子转换为结构化的知识图谱仍然是一个关键挑战。现有知识图谱构建方法存在三个主要问题：（1）实际文档中可能存在大量噪声，从而提取出混杂的信息。（2）简单的大型语言模型通常不能从特定领域文档中提取准确的知识。（3）在直接使用大型语言模型构建知识图谱时，不可避免地会出现虚构现象。本文探讨了这些问题。", "innovation": "提出了一个名为GraphJudge的知识图谱构建框架，旨在应对上述挑战。该框架采用了以实体为中心的策略来消除文档中的噪声信息，并微调了一个大型语言模型作为图法官以最终提高生成的知识图谱质量。", "conclusion": "在两个通用和一个特定领域的文本-图对数据集上进行的实验表明，该框架在各种基准方法中表现出最先进的性能，并且具有很强的一般化能力。相关代码已在指定的链接处公开。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14265", "html_url": "https://arxiv.org/abs/2406.14265", "title": "VeriFlow：用于神经网络验证的分布建模", "title_en": "VeriFlow: Modeling Distributions for Neural Network Verification", "authors": "Faried Abu Zaid,Daniel Neider,Mustafa Yalçıner", "background": "形式验证作为一个确保神经网络安全性和可靠性的有前途的方法已开始崭露头角。然而，许多相关属性，如公平性或全局鲁棒性，涉及整个输入空间。如果以原始方式应用验证技术，神经网络将会检查在现实中不发生且无实际意义的输入。为了弥补这种不足，我们提出了基于流动的密度模型VeriFlow架构，旨在允许任何形式验证方法仅在感兴趣的数据分布上进行搜索。我们证明，由于该模型定义的转换是分段仿射的，因此可以使基于线性算术约束求解的验证器得以使用。此外，数据分布的上密度层级集可以在潜在空间中通过线性约束来定义，因此在潜在空间中可以有效地表示由给定概率定义的层级集的表示，这对于形成精细且概率可解释的输入异常程度控制至关重要，从而可以有效地进行验证。", "innovation": "VeriFlow架构是一种基于流动的密度模型，旨在允许任何形式验证方法仅在感兴趣的数据分布上进行搜索，通过定义分段仿射的模型转换和数据分布的上密度层级集可以在潜在空间中通过线性约束来定义，使得验证过程具备可解释性并能控制输入的异常程度。这种方法可以避免对不现实或无意义的输入进行验证，从而提高验证的效率和准确性。", "conclusion": "该研究表明，凭借VeriFlow架构的分段仿射模型特性和在潜在空间中通过线性约束定义的数据分布的上密度层级集，验证过程得以高效且精确地进行，提供了对验证输入异常性的精细控制，从而改善了神经网络的安全性和可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.16322", "html_url": "https://arxiv.org/abs/2409.16322", "title": "阿尔茨海默病检测中的类内变异性问题", "title_en": "On the Within-class Variation Issue in Alzheimer's Disease Detection", "authors": "Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng", "background": "阿尔茨海默病（AD）的检测使用机器学习分类模型来区分AD患者和非患者。相比于传统的分类任务，AD检测中的关键挑战在于类内变异：AD患者在认知功能损伤方面表现出广泛的变化。简单二元分类可能忽略了类内异质性和实例级别的不平衡问题。因此，需要改进的分类方法来克服这些限制。", "innovation": "团队提出了两种简单但有效的方法：‘软目标蒸馏（SoTD）’和‘实例级重平衡（InRe）’，分别针对类内变异和实例不平衡问题。通过ADReSS和CU-MARVEL数据集，展示了所提出方法在检测性能上的优势，为开发稳健可靠的AD检测模型提供了新的见解。", "conclusion": "研究发现使用样本得分估计器可以生成与认知评分对齐的样本特异性软评分。这些方法有助于提高AD检测的性能，为未来研究提供指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.21582", "html_url": "https://arxiv.org/abs/2410.21582", "title": "大规模预训练数据集未必能保证微调后的鲁棒性", "title_en": "Large Pre-Training Datasets Don't Always Guarantee Robustness after Fine-Tuning", "authors": "Jaedong Hwang,Brian Cheung,Zhang-Wei Hong,Akhilan Boopathy,Pulkit Agrawal,Ila Fiete", "background": "大规模预训练模型通常通过微调来学习新的专门任务，目的是保持模型的整体性能，同时赋予其新的技能。所有这些模型的一个重要目标是鲁棒性：即在跨分布任务中表现良好。然而，研究发现，预训练模型在进行微调后，往往会表现出灾难性遗忘，并且对跨分布任务的泛化能力也会降低。", "innovation": "本文提出了一种名为Robustness Inheritance Benchmark（ImageNet-RIB）的新基准，该基准可用于评估任何预训练模型在微调后的鲁棒性保留情况。此基准包括一组相关但不同的跨分布下游任务，涉及在其中一个任务上进行微调，然后在其他任务上进行测试。研究发现，尽管连续学习方法有所帮助，但微调整体上会降低预训练模型的鲁棒性。同时，研究还发现，预训练数据集越大、越多样（如LAION-2B），在小数据集上微调后，模型的鲁棒性丢失越大，绝对鲁棒性也越低。", "conclusion": "这些研究结果表明，在小型数据集上微调时，用最强的基础模型不一定是最优方法，为专门任务的表现可能不是最好的起点。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.19375", "html_url": "https://arxiv.org/abs/2409.19375", "title": "DOTA: 分布式测试时模型调整", "title_en": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "authors": "Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang", "background": "视觉-语言基础模型（VLMs），例如CLIP，在多种任务中表现出色。然而，在训练数据与测试数据分布不一致时，部署这类模型可能会不可靠，且针对多样场景的重新微调成本高昂。为了解决这一问题，基于缓存的测试时适配器方法提供了一种高效选择，通过存储代表性的测试样本来指导后续分类。然而，这些方法通常采用简陋的缓存管理方式，导致缓存容量有限，在样本更新过程中必然会丢失样本，从而引起严重的灾难性遗忘。", "innovation": "提出了一种名为DOTA（分布式测试时调整）的简单但有效的方法，该方法连续估算测试数据流的底层分布，并通过贝叶斯定理使用这些动态估计的分布计算测试时后验概率进行调整。这种方法以分布为中心，使得模型能够持续学习并适应部署环境，从而显著减轻遗忘现象并达到现有方法的最优性能。", "conclusion": "广泛实验验证了DOTA方法可以显著减轻遗忘现象，并在测试时调整任务上达到了现有的最优性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08985", "html_url": "https://arxiv.org/abs/2502.08985", "title": "超越浅层行为：通过技能发现实现高效任务值基多任务离线MARL", "title_en": "Beyond Shallow Behavior: Task-Efficient Value-Based Multi-Task Offline MARL via Skill Discovery", "authors": "Xun Wang,Zhuoran Li,Hai Zhong,Longbo Huang", "background": "作为一种数据驱动的方法，离线多代理强化学习（MARL）能够在历史数据丰富的环境中仅从离线数据集中学习出优质的策略，适用于具有高交互成本和风险的领域。然而，大多数现有的方法是任务特定的，需要重新训练以适应新任务，这会导致冗余和低效。", "innovation": "提出了一种高效的任务价值基础多任务离线MARL算法，Skill-Discovery Conservative Q-Learning（SD-CQL）。SD-CQL通过在潜在空间中重建下一个观察来发现技能，分别评估固定和变化的动作，并且使用保守的Q学习和局部价值校准来选择每个技能的最佳动作。它消除了局部与全局对齐的需要，并能够从有限的小规模源任务中实现强大的多任务泛化。", "conclusion": "大量在StarCraft II上的实验展示了SD-CQL的优越泛化性能和任务效率。它在14个任务集中有13个任务上达到了最佳性能，个体任务集上的改进高达68.9%。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.13674", "html_url": "https://arxiv.org/abs/2410.13674", "title": "扩散课程：通过图像导向扩散实现合成到真实数据的课程", "title_en": "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion", "authors": "Yijun Liang,Shweta Bhardwaj,Tianyi Zhou", "background": "低质量或稀缺数据在实际训练深度神经网络时带来了重大挑战。经典数据增强不能生成非常不同的新数据，扩散模型则通过文本引导提示生成高质量和多样化的合成数据，为自适应AI的进化开辟了一条新途径。然而，仅凭文字引导无法控制合成图像与原始图像的临近程度，导致生成的离域数据对模型性能不利。为克服这一局限，研究图像引导，以在合成与真实图像之间实现各种插值，实现了从合成到真实的过渡。", "innovation": "提出了一种名为“扩散课程（DisCL）”的新方法，该方法根据训练阶段调整图像合成的图像引导水平。DisCL能够识别并专注于模型难以掌握的样本，评估合成图像的最佳引导水平以改善困难数据的学习效果，特别适用于长尾分类和低质量数据的学习等挑战性任务，通过调整图像引导水平，优化模型对不同引导水平图像的适应性，提高了模型在不同任务上的表现。", "conclusion": "在iWildCam数据集上应用于两项具有挑战性的任务——长尾分类和从低质量数据中学习，DisCL分别在OoD和ID宏精度上提升了2.7%和2.1%。在ImageNet-LT上，DisCL将基线模型的尾类别准确率从4.4%提高到23.64%，并在所有类别的准确率上提高了4.02%。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.01423", "html_url": "https://arxiv.org/abs/2411.01423", "title": "加速分子设计的条件潜空间分子骨架优化", "title_en": "Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design", "authors": "Onur Boyar,Hiroyuki Hanada,Ichiro Takeuchi", "background": "快速发现新的化学化合物对于推进全球健康和开发治疗方法至关重要。尽管生成模型显示出创造新型分子的前景，但仍存在确保这些分子在实际中的适用性和高效发现这些分子的挑战。本文针对此挑战介绍了一种新的方法——条件潜空间分子骨架优化（CLaSMO），该方法结合了条件变分自编码器（CVAE）和潜空间贝叶斯优化（LSBO），以在保持与原始输入相似性的前提下战略性地修改分子，将其任务框架化为约束优化问题。", "innovation": "CLaSMO通过在CVAE的潜空间中基于目标分子的原子环境进行贝叶斯优化，有效地探索了分子的子结构，并通过该潜空间进行样品效率的优化，从而提高样本效率。该方法还通过修改方法确保发现的分子具有更高的实际可应用性。在多种优化任务中（包括重新发现、结合分数优化和多属性优化），CLaSMO有效提升了目标特性，实现了资源受限应用中的高效样本利用，同时考虑分子相似性约束，并达到最先进的性能表现，保持了实际合成的可及性。", "conclusion": "CLaSMO在多种优化任务中表现出色，实现了高效目标属性增强和高样本利用效率，考虑了分子相似性约束，达到了最先进的性能水平，并且保持了实际合成的可及性。此外，还提供了一个开源网页应用，化学专家可以在这个过程中参与。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.22376", "html_url": "https://arxiv.org/abs/2410.22376", "title": "Rare-to-Frequent: 使用大型语言模型指导实现罕见概念的组成生成能力", "title_en": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "authors": "Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho", "background": "当前最先进的文本转图像(T2I)扩散模型在生成具有不寻常属性的对象等罕见概念组合时常常表现不佳。我们通过实证和理论分析表明，在扩散采样过程中暴露与目标罕见概念相关的常见概念能够提高模型的组成生成能力。基于此，我们提出了一种无需训练的方法R2F，通过利用LLM中的丰富语义知识来规划和执行整个罕见概念到常见概念的指导，从而在整个扩散推理过程中提升扩散模型的组成生成能力。这种方法适用于任何预训练的扩散模型和LLM，并可与区域指导扩散方法无缝集成。在三个数据集中进行的实验表明，R2F在T2I对齐方面显著优于SD3.0和FLUX等现有模型，提高幅度高达28.1%。此外，研究人员还构建了一个新的基准数据集RareBench，包含各种包含罕见概念组合的提示。", "innovation": "提出了一种无需训练的方法R2F，通过利用LLM中的丰富语义知识来规划和执行整个罕见概念到常见概念的指导，从而在扩散推理过程中提升扩散模型的组成生成能力。这种方法适用于任何预训练的扩散模型和LLM，并可与区域指导扩散方法无缝集成。实验结果显示R2F在T2I对齐方面显著优于SD3.0和FLUX等现有模型。", "conclusion": "在三个数据集中进行的广泛实验表明，R2F在T2I对齐方面显著优于SD3.0和FLUX等现有模型，提高幅度高达28.1%。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.05723", "html_url": "https://arxiv.org/abs/2412.05723", "title": "无需训练的低秩适配器的贝叶斯化方法", "title_en": "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models", "authors": "Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang", "background": "大型语言模型（LLMs）响应不确定性的估计仍然是一个关键挑战。尽管最近的贝叶斯方法通过低秩权重更新展示了量化不确定性的有效性，但它们通常需要复杂的微调或后训练程序。这些方法在引入贝叶斯所需的关键步骤时增加了额外的复杂性和计算成本。", "innovation": "本文提出了一种无需训练的贝叶斯化（Training-Free Bayesianization，TFB）方法。TFB 提供了一种简单且理论上支持的框架，可以在不进行额外训练的情况下将已训练的低秩适配器转换为贝叶斯模型。这种方法系统地搜索权重后验中的最大可接受波动性，约束在低秩各向同性高斯分布的一组内。TFB 的理论分析表明，在轻度条件下，这种搜索过程相当于 KL 正则化变分优化，这是一种变分推断的通用形式。全面的实验结果表明，TFB 相对于现有方法在不确定性估计和泛化方面表现出更优的效果，同时消除了复杂贝叶斯化训练程序的需求。", "conclusion": "通过实验证明，TFB 在无需复杂训练的情况下能够更有效地实现低秩适配器的贝叶斯化，提高不确定性估计的准确性和模型的泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.21263", "html_url": "https://arxiv.org/abs/2502.21263", "title": "RuCCoD: Towards Automated ICD Coding in Russian", "title_en": "RuCCoD: Towards Automated ICD Coding in Russian", "authors": "Aleksandr Nesterov,Andrey Sakhovskiy,Ivan Sviridov,Airat Valiev,Vladimir Makharev,Petr Anokhin,Galina Zubkova,Elena Tutubalina", "background": "该研究探讨了在资源有限的俄语中自动化临床编码的可行性。俄语在生物医学资源方面有限，因此开发适用于俄语的自动化编码系统具有挑战性。", "innovation": "研究提出了一个新的ICD编码数据集，包含超过10,000个实体和1,500多个独特的ICD代码，并运用了包括BERT、LLaMA with LoRA和RAG在内的多个最先进的模型进行研究。模型还在不同领域的知识迁移和术语迁移方面进行了实验。通过使用自动化预测的编码进行训练，提高了临床编码的准确性。", "conclusion": "实验结果显示，使用自动化预测的编码进行训练比医生手动标注的数据有显著的准确性提升。研究认为，这对资源匮乏的语言如俄语的临床编码自动化具有重要意义，有助于提高这些情境下的临床效率和数据准确性。该研究代码和数据集已公开可用。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "揭开金融大语言模型后训练的神秘面纱", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "大语言模型（LLMs）在专业领域如医学和金融中的适用性已逐渐凸显。然而，如何在不同数据和模型配置下确定最优的后训练标准和训练策略依然面临挑战。因此，研究机构需要系统地研究大语言模型针对特定领域的后训练方法。", "innovation": "该研究引入了FINDAP，这是一种系统化且细化的研究方法，旨在探索金融领域大语言模型的后训练策略。FINDAP包括四个关键组成部分：定义目标领域的核心能力（FinCap）、优化连续预训练和指令跟随的高效训练配方（FinRec）以及其他创新的数据精炼方法、一个专门的训练数据集集合（FinTrain），以及一个与FinCap对齐的全面评估框架（FinEval）。该方法最终得出的模型Llama-Fin在广泛金融任务上取得了最先进性能，同时揭示每个后训练阶段如何贡献独特的能力，并指出具体的问题和解决方案，为大语言模型的专业领域适应提供了宝贵见解。", "conclusion": "Llama-Fin达到了金融任务中的最先进的性能。同时，FINDAP揭示了各个后训练阶段如何提升具体能力，并指出了有效的解决方案，为后续的研究提供了宝贵的指导意义。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00666", "html_url": "https://arxiv.org/abs/2502.00666", "title": "通过基于偏好的探索规避RLHF中的exp(R_max)缩放", "title_en": "Avoiding $\\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration", "authors": "Mingyu Chen,Yiding Chen,Wen Sun,Xuezhou Zhang", "background": "强化学习从人类反馈（RLHF）已成为大型语言模型（LLM）对齐的关键技术。在线RLHF一直面临样本效率低下的问题，特别是当偏好分布严重偏斜（如那些有单一正确答案的问题）时，现有算法的样本复杂度会呈指数增长，影响了这些算法的有效性。Xie等人的研究提出了这一问题，并指出需要一种能够实现样本复杂度在奖励尺度下多项式增长的方法。", "innovation": "本文提出了一种新的在线RLHF算法——自探索偏好激励在线偏好优化（SE-POPO），这是首次实现样本复杂度在奖励尺度下多项式增长的方法，解决了Xie等人提出的开放式问题。理论证明了SE-POPO的表现优于现有探索算法，而在两种主要的RLHF应用场景和公开基准上的实证结果也证实了其在样本效率上的优势。", "conclusion": "SE-POPO算法标志着在RLHF算法设计上取得了重要进展，通过基于偏好的探索方法规避了指数级别的缩放问题，增强了算法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.16355", "html_url": "https://arxiv.org/abs/2501.16355", "title": "在战略分类中的策略响应：分析模型与LLM生成响应的比较", "title_en": "How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification", "authors": "Tian Xie,Pavan Rauch,Xueru Zhang", "background": "当机器学习算法被部署来自动化人类相关决策时，人类代理人可能会学习背后的决策规则并调整其行为。战略分类（SC）框架被提出以研究决策者与代理人之间的这种互动，以设计更可信的机器学习系统。然而，先前的战略分类理论模型假设代理人是完全或近似理性的，并通过优化其效用回应决策规则。随着大型语言模型（LLM）的广泛应用，现在现实世界的代理人可能更依赖这些工具来获得战略建议。这种转变引发了两个问题：一是LLM能否在战略分类设置中生成有效的、社会责任感强的策略；二是现有的战略分类理论模型是否能准确捕捉代理人行为，尤其是当代理人遵循LLM建议时:", "innovation": "研究者通过模拟具有不同特征的代理人与三种商业LLM（GPT-4o、GPT-4.1和GPT-5）互动，探讨了五个关键的战略分类场景：聘请、贷款申请、学校录取、个人收入和公共援助计划。所提出的关键创新点包括：（i）即使没有决策策略的访问权限，LLM也能生成有效的策略，提高代理人的分数和资格；（ii）从总体水平来看，由LLM指导的努力分配策略在得分提升、资格率和公平指标上表现出相似或更高的提升，表明理论模型仍可能是LLM影响行为的合理代理；（iii）从个体水平来看，LLM倾向于生成更多样化和平衡的努力分配结果，而不仅仅是在现有理论模型中。", "conclusion": "研究结果表明，即使缺乏决策策略，LLM也能生成有效的策略并提高代理人的分数和资格。总体来看，LLM指导的努力分配策略在重要指标上表现接近或超越现有理论模型，表明理论模型仍然可以作为LLM影响行为的合理替代。此外，LLM倾向于提供更多样化和平衡的努力分配，这与理论模型的预测不同。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01456", "html_url": "https://arxiv.org/abs/2502.01456", "title": "过程隐含奖励强化", "title_en": "Process Reinforcement through Implicit Rewards", "authors": "Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding", "background": "密集的过程奖励在大型语言模型（LLMs）推理时缩放中证明比稀疏的结果级奖励更有效，尤其是在需要复杂多步推理的任务中。尽管密集奖励也为LLMs的强化学习（RL）提供了一个有吸引力的选择，因为它们可以细化奖励并解决一些与结果奖励相关的训练效率和奖励回溯问题（如奖励欺骗问题），但其潜力尚未充分发挥。这主要归因于在线训练过程奖励模型（PRMs）的挑战，其中收集高质量的过程标签代价高昂，使它们特别容易受到奖励欺骗的影响。", "innovation": "本文提出了PRIME（过程强化通过隐含奖励）方法，该方法通过借助仅通过策略展播和结果标签来推断过程奖励，实现在不专门训练奖励模型的情况下进行在线PRM更新，从而避免了现有方法所需的特定奖励模型训练阶段。这种方法与各种优势函数兼容，显著降低了开发开销，并在多项关键推理基准上展示了其有效性，特别是对于具有10%训练数据的数学和编程任务上的表现更为出色。", "conclusion": "从Qwen2.5-Math-7B-Base开始，PRIME模型在几个关键推理基准上比SFT模型平均提高了15.1%。特别地，我们的PRIME最终模型Eurus-2-7B-PRIME在10%训练数据下超过了Qwen2.5-Math-7B-Instruct在七项推理基准上的表现。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13562", "html_url": "https://arxiv.org/abs/2503.13562", "title": "检测稀少且稀疏的异常：解决多实例学习中的双重不平衡问题", "title_en": "Detecting Scarce and Sparse Anomalous: Solving Dual Imbalance in Multi-Instance Learning", "authors": "Lin-Han Jia,Lan-Zhe Guo,Zhi Zhou,Si-Ye Han,Zi-Wen Li,Yu-Feng Li", "background": "在实际应用中，检测稀疏异常样本极具挑战性，因为这些异常样本与正常的样本极为相似，容易混淆。同时，异常样本的数量本来就很稀缺。这导致了多实例学习（MIL）中的双重不平衡问题，在宏观和微观层面上都有体现。", "innovation": "本文将MIL问题重新定义为细粒度的PU学习问题，通过微观平衡机制以未偏的方式解决不平衡问题。基于严格的理论基础提出了一种新的框架BFGPU。", "conclusion": "在合成数据集和真实数据集上的广泛实验表明，BFGPU的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09579", "html_url": "https://arxiv.org/abs/2503.09579", "title": "长上下文建模中的成本优化分组查询注意力", "title_en": "Cost-Optimal Grouped-Query Attention for Long-Context Modeling", "authors": "Yingfa Chen,Yutong Wu,Chenyang Song,Zhen Leng Thai,Xingyu Shen,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "分组查询注意力（GQA）是一种广泛采用的策略，用于减少大型语言模型（LLMs）中注意力层的计算成本。然而，当前的GQA配置往往存在不足，因为它们未能考虑到上下文长度对推理成本的影响。由于推理成本随上下文长度增加而增加，因此成本效率最高的GQA配置也应相应变化。", "innovation": "引入了两个创新点：（1）将总头大小与隐藏尺寸解耦，使对注意力FLOPs的控制更加灵活；（2）联合优化模型大小和GQA配置，以在注意力层和其他组件之间实现更好的推理资源分配。研究揭示了常用GQA配置在长上下文场景中的高度不合适。更重要的是，提出了一个成本最优的GQA配置方法。结果表明，在长上下文场景中，应该减少注意力头的数量并扩大模型规模，而我们的配置方法可以在模型能力无劣化的情况下，分别减少超过50%的内存使用和FLOPs。", "conclusion": "我们的研究为设计高效的长上下文LLMs提供了有价值的见解。代码可在以下链接访问：[this https URL](this https URL)。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07531", "html_url": "https://arxiv.org/abs/2502.07531", "title": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation", "title_en": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation", "authors": "Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu", "background": "现有的图像到视频（I2V）生成方法通常将相机运动、对象运动和光照方向控制信号视为独立处理，这主要是由于高质量联合注释数据集的稀缺性以及不同模态之间控制空间的不匹配问题。因此，在内容创作工作流程中，精确和同时控制这些因素以提高准确性和灵活性变得具有挑战性。为了解决这一问题，本文提出了VidCRAFT3框架，它支持相机运动、对象运动和光照方向的独立和联合控制，并通过集成三个核心组件来实现这一点：重建3D点云的Image2Cloud模块用于实现精确的相机运动控制；使用稀疏对象轨迹的ObjMotionNet编码模块生成多尺度光流特征，指导对象运动；Spatial Triple-Attention Transformer通过并行交叉注意机制集成光照方向嵌入。为了克服缺乏联合注释数据的问题，研究团队创建了VideoLightingDirection (VLD) 数据集，并采用分阶段训练策略，使模型能够在没有完全联合注释的情况下进行鲁棒学习。", "innovation": "VidCRAFT3框架通过整合Image2Cloud、ObjMotionNet和Spatial Triple-Attention Transformer这三个核心组件，实现了对相机运动、对象运动和光照方向的独立和联合控制。该框架引入了VideoLightingDirection (VLD) 数据集，该数据集包含帧级别的光照方向标签，并采用分阶段训练策略，以确保在缺乏完全联合注释的情况下也能进行稳健的学习。实验结果表明，VidCRAFT3在控制精度和视觉一致性方面优于现有的方法，同时预留代码和数据的公开权限。这是一个创新性的框架，为控制更复杂的图像到视频生成的流程提供了解决方案。", "conclusion": "本文提出了VidCRAFT3框架，它提供了独立和联合控制相机运动、对象运动和光照方向的新方法。通过使用Image2Cloud重建3D点云、ObjMotionNet编码模块生成多尺度光流特征、和Spatial Triple-Attention Transformer整合光照方向嵌入，VidCRAFT3在控制精度和视觉一致性方面表现出色。该框架利用VideoLightingDirection (VLD) 数据集和分阶段训练策略解决了缺乏联合注释数据的问题，从而提供了一种在缺乏完全联合注释的情况下也能进行稳健学习的机制。作者还展示了广泛的实验结果，证明了VidCRAFT3比现有方法更加优越。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01902", "html_url": "https://arxiv.org/abs/2503.01902", "title": "LLMs在支持事实核查中的失败", "title_en": "How LLMs Fail to Support Fact-Checking", "authors": "Adiba Mahbub Proma,Neeley Pate,James Druckman,Gourab Ghoshal,Hangfeng He,Ehsan Hoque", "background": "大型语言模型（LLMs）能够放大网络虚假信息，但同时也显示出对抗虚假信息的潜力。本文研究了ChatGPT、Gemini和Claude等三种LLMs在对抗政治虚假信息的能力。研究发现，尽管模型可以提供逻辑推理，但它们在引用真实新闻来源时存在困难，并倾向于引用左倾信息源。此外，模型之间的回应多样性也有所不同。这些发现揭示了仅通过提示工程使用LLMs进行核查存在的风险，强调了需要更可靠的控制措施。这对研究人员和非技术用户都有重要意义。", "innovation": "本文采用了两步链式思考的提示方法，首先让模型识别可信的信息来源，然后自动生成有说服力的回应。这一方法能够更全面地评估LLMs在应对虚假信息时的表现。此外，研究还发现模型在引用真实信息源方面存在的问题，并强调了更多控制措施的重要性。", "conclusion": "研究指出，通过仅通过提示工程使用LLMs进行事实核查存在风险，强调了对LLMs进行更严格控制的必要性。这些发现对于研究人员和非技术用户具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16060", "html_url": "https://arxiv.org/abs/2502.16060", "title": "利用时间-频率主题学习单通道EEG分词", "title_en": "Tokenizing Single-Channel EEG with Time-Frequency Motif Learning", "authors": "Jathurshan Pradeepkumar,Xihao Piao,Zheng Chen,Jimeng Sun", "background": "当前，EEG（脑电图）分析主要依赖于各种基础模型进行重塑。然而，EEG信号的时频分词问题依然存在挑战。传统方法往往需要多通道数据支持，不利于在轻量级模型中的应用和多种基础模型的兼容。\n", "innovation": "本文提出了一种名为TFM-Tokenizer的新型分词框架，通过学习单通道EEG信号中的时间-频率动机形成词汇表，并将其编码为离散的词元。同时，提出了一种双路径架构，采用时频掩码来捕捉稳健的动机表示，适用于不同轻量级变压器和已有的基础模型，无需依赖严格的标准10-20通道EEG系统。实验结果表明，在多种EEG基准数据集上实现了一致性的性能提升，与其他强大的基础模型相比，在Cohen's Kappa指标上最高提升了17%。此外，这种方法具备兼容多种基础模型的能力，即使信号格式、通道配置、记录设备和任务都不同且不一致的情况下，在耳EEG睡眠分期中表现亦卓越。不仅提高了数据表示质量和可解释性，还展示了广泛的应用潜力。\n", "conclusion": "本文通过时间-频率动机学习成功的提出了一种新的EEG单通道分词方法TFM-Tokenizer，不仅提高了现有基础模型的性能，还展示了在非标准EEG记录设备上的应用潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10150", "html_url": "https://arxiv.org/abs/2503.10150", "title": "基于层次知识的检索增强生成", "title_en": "Retrieval-Augmented Generation with Hierarchical Knowledge", "authors": "Haoyu Huang,Yongfeng Huang,Junjie Yang,Zhenyu Pan,Yongqiang Chen,Kaili Ma,Hongzhi Chen,James Cheng", "background": "Graph-based Retrieval-Augmented Generation (RAG) 方法极大地提高了大语言模型（LLMs）在特定领域任务中的性能。然而，现有的 RAG 方法未能充分利用人类认知中自然存在的层次化知识，这限制了 RAG 系统的能力。", "innovation": "本文引入了一种新的 RAG 方法 HiRAG，该方法利用层次知识在索引和检索过程中增强 RAG 系统的语义理解和结构捕获能力。", "conclusion": "我们的广泛实验表明，HiRAG 在性能上超过了最先进的基线方法，实现了显著的性能提升。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11947", "html_url": "https://arxiv.org/abs/2503.11947", "title": "为年轻数字公民的伦理AI：隐私治理的呼吁", "title_en": "Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance", "authors": "Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha", "background": "数字平台中的人工智能（AI）快速发展，为青年用户带来了重大挑战，涉及隐私、自主权和数据保护。尽管AI驱动的个性化功能提升了用户体验，但其通常缺乏清晰的伦理边界，使年轻用户容易遭受数据剥削和算法偏见的影响。", "innovation": "本文呼吁建立伦理AI治理，提出一个以青年为中心的隐私保护结构化框架，包括算法透明度、隐私教育、家长数据共享伦理和问责措施等关键领域，以确保在AI生态系统中赋予青年更强的数字身份控制权，并提出可供政策制定者、AI开发者和教育工作者采取的可行策略。", "conclusion": "通过这种方法，我们希望构建一个更加公正和负责任的AI生态系统，使青年能够更好地控制其数字身份。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19223", "html_url": "https://arxiv.org/abs/2504.19223", "title": "CARL: Camera-不可知论性 Representation Learning for Spectral Image Analysis", "title_en": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "authors": "Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic", "background": "谱成像技术在医学和城市场景理解等多个领域展现出广阔的应用前景，并已在遥感领域确立为关键的成像模态。然而，不同谱成像相机之间的通道维度和捕捉的波长差异限制了基于AI的方法的发展，导致依赖特定相机的模型缺乏泛化能力和跨相机应用性。", "innovation": "为解决这一瓶颈，我们提出了CARL模型，一种在RGB、多光谱和高光谱成像多模态下实现相机不可知性表征学习的方法。通过引入一种新颖的光谱编码器，利用自我注意力-交叉注意力机制，将重要的光谱信息提炼成学习到的光谱表示。通过一种专门为CARL定制的新颖基于特征的自我监督策略实现空间光谱预训练。在医学成像、自动驾驶和卫星成像等多个领域的大规模实验证明，该模型在模拟和真实世界的跨相机光谱变异数据集上表现出色，具有独特的谱异质性鲁棒性。", "conclusion": "所提出的方法的可扩展性和多功能性，定位我们的模型将成为未来谱基础模型的核心。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03814", "html_url": "https://arxiv.org/abs/2504.03814", "title": "LLMs训练循环中的递归训练循环：训练数据属性如何调节生成数据中的分布偏移？", "title_en": "Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?", "authors": "Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer", "background": "大型语言模型（LLMs）在生成在线内容方面越来越受到重视，这种内容会形成反馈循环，使得后续模型会基于这些合成数据进行训练。这些循环导致了分布偏移，即模型错误地表现出了人类数据的真实分布（也称为模型崩溃）。然而，人类数据的特性如何影响这些偏移尚不明确。", "innovation": "本文首次提供了关于训练数据属性对递归训练结果影响的实证研究。首先，证实使用不同的数据集会导致不同程度的分布偏移。通过全面调整数据集的特性并结合回归分析，确定了预测分布偏移程度的特性。同时，发现词汇多样性会加剧这些偏移，而语义多样性和数据质量则会减轻它们。此外，研究发现这些影响具有高度模块化：一个特定互联网域中的数据很少会影响另一个域的内容生成。", "conclusion": "研究结果揭示了一个新的视角，即互联网的不同部分可能会经历不同类型的变化。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01986", "html_url": "https://arxiv.org/abs/2503.01986", "title": "使用任务激发方法自适应地剖析模型", "title_en": "Adaptively profiling models with task elicitation", "authors": "Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong", "background": "语言模型的评估通常未能充分反映重要的失败模式，这迫使专家们需要手动检查输出结果并构建新的基准。现有的框架不能生成大量多样的任务，用以全面定性模型的行为表现。这些对于任务设计者和模型使用者来说是一项忙碌且耗时的工作，尤其是当模型在不同应用场景中表现出复杂的失败模式时。论文提出了任务激发的方法，这是一种能够自动构建新的评估任务来描绘模型行为的新型方法，填补了现有方法的空白。", "innovation": "论文介绍了任务激发方法，能够自动生成大量多样的任务，这些任务能揭示前沿模型在广泛的模型应用领域中的系统性失败模式，如预报、在线骚扰等，并在数量规模上比以往的研究高出了一个量级。通过该方法，可以发现模型如Sonnet 3.5在量子计算和AGI上的过度关联，以及o3-mini模型在重复虚构信息时容易产生幻觉的现象，从而揭示了传统评估方法未能捕捉到的语言模型的关键失败模式。", "conclusion": "本文提出的任务激发方法能够自动生成大量的新任务，对前沿模型的行为进行全面剖析，该方法不仅大幅提高了评估任务生成的效率，还能揭示先前方法未能发现的语言模型的致命弱点。这将极大地推动人工智能语言模型的透明化和可靠性的提升，为未来的评估和使用提供了新的思路。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.06692", "html_url": "https://arxiv.org/abs/2503.06692", "title": "InftyThink: 突破大型语言模型长背景推理长度限制的框架", "title_en": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models", "authors": "Yuchen Yan,Yongliang Shen,Yang Liu,Jin Jiang,Mengdi Zhang,Jian Shao,Yueting Zhuang", "background": "大规模语言模型在复杂任务上的推理表现显著，但现有的长背景推理方法面临着关键性的限制：基于序列长度的二次计算复杂度，推理受最大上下文边界限制，特别是在超过预训练上下文窗口时表现下降。现有方法主要集中在压缩推理链上，而未能解决根本的复杂度问题。", "innovation": "引入InftyThink框架，将一次性推理过程转变为迭代过程，并在每次迭代中插入简短推理段和简洁的进度总结。该方法允许无限制的推理深度同时维持可控的计算成本，形成典型的锯齿状记忆模式，提高了计算效率。此外，发展了一种方法将长背景推理数据集重构为迭代格式，将OpenR1-Math数据集转换为333K个训练实例。在多个模型架构中进行的实验表明，与传统方法相比，InftyThink降低了计算成本并提高了性能。Qwen2.5-Math-7B模型在MATH500、AIME24和GPQA_diamond基准测试中分别实现了3-13%的性能提升。这项工作挑战了推理深度和计算效率之间的权衡，提供了一种不需修改架构的更可扩展的复杂推理方法。", "conclusion": "InftyThink框架通过将一次性推理过程转变为迭代过程，显著提升了大规模语言模型的推理深度和效率。在多个模型中的实验证明了此方法的有效性，并带来了性能和成本的双重改进，同时挑战了既定的权衡假设。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02861", "html_url": "https://arxiv.org/abs/2505.02861", "title": "多代理系统中的神经编排：用于多域任务环境中最佳代理选择的深度学习框架", "title_en": "Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework for Optimal Agent Selection in Multi-Domain Task Environments", "authors": "Kushagra Agrawal,Nisharg Nargund", "background": "多代理系统（MAS）在模拟涉及自主交互实体的复杂现实场景中具有基础性作用。然而，传统MAS架构往往存在协调机制僵硬、难以适应动态任务的问题。", "innovation": "我们提出了MetaOrch，一种基于神经网络的编排框架，用于多领域任务环境中的最佳代理选择。该系统采用有监督学习策略，结合任务上下文、代理历史和响应质量预期来选择最合适的代理。引入了一个创新的模糊评估模块，根据完整度、相关性和信心三个维度评估代理响应，并生成软监督标签用于训练编排器。该方法不同的是，MetaOrch能够动态预测最合适的代理，并同时估算选择信心，而无需硬编码代理-任务映射。", "conclusion": "在具有异构代理的模拟环境中的实验表明，我们的方法在任务分配准确性方面达到了86.3%，显著优于随机选择和轮询调度等基线策略。模块化架构强调了扩展性，允许代理独立注册、更新和查询。结果表明，神经编排为提升多代理系统在多样化任务领域的自主性、可解释性和适应性提供了强有力的方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18591", "html_url": "https://arxiv.org/abs/2504.18591", "title": "使用等变神经场表示的具有几何感知的稳态PDEs推理", "title_en": "Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations", "authors": "Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier", "background": "神经运算符的进步引入了在任意几何形状上定义的偏微分方程（PDEs）的离散化不变的拟合模型，但许多方法难以高效编码局部几何结构和变化的领域。这些方法在编码几何结构时存在局限性，尤其是在处理具有复杂形状变化的PDEs时表现不佳。", "innovation": "本文介绍了一种名为enf2enf的神经场方法，用于预测具有几何变异性的稳态PDEs。该方法通过将几何形状编码为特定空间位置的隐特征，并在整个网络中保持局部性，有效处理了复杂形状变化。这些局部表示与全局参数组合，并解码成连续的物理场，使得模型能够更好地适应复杂的形状变化。", "conclusion": "实验结果表明，enf2enf方法在气动和结构基准测试上的性能与基于图的方法、神经运算符方法以及最近的神经场方法相当或更优，能够实现实时推理并高效扩展到高分辨率网格。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18346", "html_url": "https://arxiv.org/abs/2504.18346", "title": "比较大型语言模型的不确定性测量与缓解方法：一项系统性回顾", "title_en": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review", "authors": "Toghrul Abbasli,Kentaroh Toyoda,Yuan Wang,Leon Witt,Muhammad Asif Ali,Yukai Miao,Dan Li,Qingsong Wei", "background": "大型语言模型（LLMs）在许多领域中产生了革命性的影响，但它们仍然面临一个主要挑战，即幻觉——自信地输出错误信息。这引发了如何准确评估和量化LLMs不确定性的疑问。尽管传统模型在不确定性量化（UQ）方面进行了大量研究，并使用校准技术来解决不确定性与准确性的偏差，但部分方法已被应用于LLMs，而现有文献尚未深入分析这些方法的有效性，缺乏一个综合基准来使现有解决方案之间进行有意义的比较。", "innovation": "本研究通过系统回顾代表性的工作，填补了LLMs的不确定性量化和校准方面缺乏深入分析的空白，引入了一个严格的基准。使用两个广泛使用的可靠数据集，实证评估了六种相关方法，验证了回顾中的主要发现。最后，提供了一些关键的未来方向，并列出了开放性挑战，这是目前首个专门回顾LLMs校准方法和相关度量的系统性研究。", "conclusion": "最终，本研究提供了LLMs校准方法的关键未来方向，同时指出了开放性挑战，填补了现有文献在LLMs不确定性量化和校准方面的空白，引入了一个详细的基准，为现有解决方案提供了有价值的比较依据。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00220", "html_url": "https://arxiv.org/abs/2504.00220", "title": "扩散模型能否去纠缠？一种理论视角", "title_en": "Can Diffusion Models Disentangle? A Theoretical Perspective", "authors": "Liming Wang,Muhammad Jehanzeb Mirza,Yishu Gong,Yuan Gong,Jiaqi Zhang,Brian H. Tracey,Katerina Placek,Marco Vilela,James R. Glass", "background": "本文提出了一个用于理解扩散模型如何学习分解表示的新颖理论框架。在该框架下，我们为一般的分解潜变量模型建立了可识别性条件，分析了训练动力学，并推导出了分解潜空间模型的样本复杂性边界。为了验证我们理论的有效性，我们进行了跨不同任务和模态的分解实验，包括潜空间高斯混合模型的子空间恢复、图像着色、图像去噪以及语音转换以支持语音分类。实验结果表明，由我们理论启发的训练策略，如风格向导正则化，能够一致地提升分解性能。", "innovation": "本文提出了一种理解扩散模型学习分解表示的理论框架，并且通过可识别性条件、训练动力学分析和样本复杂性界建立了理论基础。此外，通过跨不同任务和模态的实验验证了该理论的有效性，特别是提出的训练策略显著提升了分解性能。", "conclusion": "本文通过建立一个理论框架来理解扩散模型如何学习分解表示，并通过实验验证了这一理论的有效性，为未来在潜变量模型中的应用提供了新的理论支持和指导。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08791", "html_url": "https://arxiv.org/abs/2504.08791", "title": "Prima.cpp: 快速在异构和低资源家庭集群上进行30-70B LLM推理", "title_en": "Prima.cpp: Fast 30-70B LLM Inference on Heterogeneous and Low-Resource Home Clusters", "authors": "Zonghang Li,Tao Li,Wenjiao Feng,Rongxing Xiao,Jianshu She,Hong Huang,Mohsen Guizani,Hongfang Yu,Qirong Ho,Wei Xiang,Steve Liu", "background": "设备端的推理可以提供隐私保护、离线使用和即时响应，但消费级硬件限制了大型语言模型（LLMs）的吞吐量和能力。为了解决这一挑战，本文提出了一种名为Prima.cpp的分布式设备端推理系统，该系统能够在 CPU/GPU 混合、内存资源不足、磁盘速度慢、Wi-Fi 网络连接和异构操作系统下运行30-70B的LLM。", "innovation": "该研究引入了管道环并行计算（PRP）来重叠磁盘读写与计算和通信，解决了基于mmap的模型卸载中的预取-释放冲突。进一步提出了Halda，这是一种结合了设备内存/显存约束下每个设备的CPU/GPU工作负载优化和设备选择的异构感知调度器。通过Prima.cpp，70B模型可以达到674ms/令牌的TPOT，32B模型通过推测解码可以达到每秒26个令牌，相比其他系统如exo、和dllama，Prima.cpp的TPOT降低了5-17倍，支持8B到70B的细粒度模型尺寸，确保了更广泛的跨操作系统和量化兼容性，实现了无oom，同时具有Wi-Fi容错性、隐私保护和硬件独立性。", "conclusion": "Prima.cpp在家庭集群上以高效的方式实现了大型语言模型的离线高吞吐量推理，解决了消费级硬件的限制问题，提供了更好的性能和兼容性的同时保持了高度的灵活性和可用性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11739", "html_url": "https://arxiv.org/abs/2505.11739", "title": "ZeroTuning: 利用初始标记提升大型语言模型性能无需训练", "title_en": "ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training", "authors": "Feijiang Han,Xiaodong Yu,Jianheng Tang,Delip Rao,Weihua Du,Lyle Ungar", "background": "Token-level attention tuning方法，如Post-hoc Attention Steering (PASTA)和Attention Calibration (ACT)，已经成为了增强冻结的LLM的一种有前景的方法，通过可解释的干预措施。然而，这些方法依赖于辅助启发式来识别“重要”的任务特定标记，这在标记的重要性不明确或使用优化内核且无法访问注意力图时，会导致偏见，并限制其适用性。", "innovation": "本文提出了一种更简单且更优雅的替代方法：仅在初始标记（例如，LLaMA中的<BOS>）上进行操作。通过向这个标记的注意力概率中添加轻量级偏差，理论上可以单调地控制下游注意力分布的熵，并且这个初始标记因其作为注意力汇的自然功能而被放大。实验分析表明，这种方式可以正向影响LLM并更好地解锁其预训练知识，效果在早期层更为明显，并且在不同注意力头中存在不同的扩展偏好。基于这些见解，提出了ZeroTuning：一种无需训练的方法，通过特定头部的注意力调整来改善LLM性能，而不需要参数更新，引入了监督模式和新型无监督模式。该方法轻量级、与核无关，仅需四行代码修改即可实现，并且在15个数据集上普遍表现出色，优于先前更复杂的方法，例如，对于Llama-3.1-8B，分类提高了19.9%，问答提高了4.5%，对话提高了2.1%。ZeroTuning在量化推理时可以直接使用，并且随上下文长度增加而保持性能改进。", "conclusion": "ZeroTuning通过初始标记的轻量级调整在无需训练的情况下增强了大型语言模型的性能，并且在各种数据集上均表现出显著的效果提升，甚至在量化推理时仍能保持性能改善。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.10823", "html_url": "https://arxiv.org/abs/2504.10823", "title": "CLASH：从多角度评估语言模型判断高 stakes 暗码", "title_en": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives", "authors": "Ayoung Lee,Ryan Sungmo Kwon,Peter Railton,Lu Wang", "background": "在高 stakes 领域中，人类甚至在面对涉及冲突价值观的难题时也会面临挑战，更不用说对于AI来说了。现有的研究大多集中于日常情况，并未触及高 stakes 情景下的问题。因此，需要一种新的方法來填补这一空白，以便更好地理解和解决这些复杂的价值判断问题。", "innovation": "本文引入了CLASH（Character perspective-based LLM Assessments in Situations with High-stakes），这是一个精心编排的数据集，包含345个高影响的困境和3,795个视角，涵盖了多种价值观。此外，该研究对比了14种不同的模型，揭示了多个关键发现，包括强大的语言模型在处理模棱两可的决策时的表现不佳，以及认知行为在数学解题和游戏策略领域中的有效性不能直接转移到价值推理中，反而会出现新的失败模式。这一工作为从多角度评估和理解语言模型的价值推理能力提供了新的视角。", "conclusion": "该研究通过CLASH数据集和模型评测，展示了目前语言模型在处理复杂高 stakes 决策问题时的局限性，并提出了几个关键发现。作者建议，未来的研究应集中在理解神经网络中的具体机制，以便更好地调整和改进模型，使其更有效地进行价值判断。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11574", "html_url": "https://arxiv.org/abs/2505.11574", "title": "量化与推理：低比特LLM数学推理性能下降的探索与缓解", "title_en": "Quantization Meets Reasoning: Exploring and Mitigating Degradation of Low-Bit LLMs in Mathematical Reasoning", "authors": "Zhen Li,Yupeng Su,Songmiao Wang,Runming Yang,Congkai Xie,Aofan Liu,Ming Li,Jiannong Cao,Yuan Xie,Ngai Wong,Hongxia Yang", "background": "低比特后训练量化（PTQ）是一种在紧张的内存和延迟预算下部署具备推理能力的大型语言模型的有效方法，但它会对数学推理能力产生显著负面影响（最高可达69.81%的下降）。本文针对模型部署中的关键问题进行了研究，旨在精确地确定模型在哪一步骤开始出现性能下降，并探讨如何在保持低比特量化的同时进行缓解。", "innovation": "研究发现了两个稳健的模式：(i) 低比特量化异常提高了方法和执行错误，而相对于高层次的概念性错误则不然；(ii) 故障通常会在第一个脆弱步骤发生，并会传播到最终答案。基于这两个模式，作者提出了一种一般性的干预原则：精确恢复最早故障前沿处的局部令牌级余量。作者实现了一个轻量级的措施，该措施可以在量化模型上直接运行：首先检测第一步的故障，构建“银弹”数据集，然后应用小型监督/偏好调整。", "conclusion": "作者的方法在curated示例和计算资源有限的情况下，即可恢复4比特权重的数学推理性能近乎恢复到满精度基准水平，同时保持量化效率。该框架在评估范围内对于量化器和架构是通用的，将低比特量化的影响从全局精度问题转变为可定位和重复的过程干预问题。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12143", "html_url": "https://arxiv.org/abs/2505.12143", "title": "结构化的关系表示", "title_en": "Structured Relational Representations", "authors": "Arun Kumar,Paul Schrater", "background": "不变表示是表示学习的核心，但仍面临一个核心挑战：在不抑制与任务相关的信号的情况下，发现稳定且可迁移的不变量。这引发了一些根本性的疑问，需要进一步研究，关于此类不变量的适当抽象层次以及它们应描述系统中的哪些方面。环境解释依赖于抽象的知识结构来理解当前状态，这导致了交互作用，成为学习和知识获取的基本驱动力。解释操作在高级关系知识的层次上，因此我们提出，不变结构必须是知识存在的地方，具体来说是定义在抽象知识空间中关系路径闭包内的划分。这些划分作为核心不变表示的核心，形成了知识存储和学习发生的结构基质。另一方面，分区间连接符使得这些包含与任务相关的转换的知识分区可以得到部署。因此，不变体分区提供了结构表示的基础原语。", "innovation": "本文提出了基于封闭幺半群的计算基础理论，构建了不变体分区结构化关系表示的理论框架。这些理论框架为基础关系表示理论提供了新的视角，特别是在高级关系知识建模方面。", "conclusion": "不变体分区为结构化表示提供了基础原语，而分区间连接符则允许这些知识分区在任务相关转换的部署中发挥作用。由此，不变体分区构成了结构化表示的基石。此外，该研究还为高级关系知识在抽象知识空间中的建模提供了一个新的框架。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11556", "html_url": "https://arxiv.org/abs/2505.11556", "title": "HiddenBench：通过隐蔽特征任务评估多智能体大语言模型集合推理能力", "title_en": "HiddenBench: Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks", "authors": "Yuxuan Li,Aoi Naito,Hirokazu Shirado", "background": "基于大型语言模型（LLMs）的多智能体系统有望通过分布式信息整合增强问题解决能力，但在多智能体之间可能复制人类群体中的集体推理失败。由于缺乏理论支持的基准，系统评价和改进变得困难。研究者提出了一种新基准——HiddenBench，旨在系统评估多智能体LLMs中的集体推理能力，该基准利用社会心理学中的隐蔽特征范式来检测和分析智能体群体推理的缺陷。", "innovation": "研究者构建了第一个专门评估多智能体LLMs集体推理能力的基准HiddenBench。增加了任务复杂性和多样性的支撑，使用自定义任务、前期人类研究和自动生成的任务来全面覆盖各模型间的差异，特别发现GPT-4.1团队表现出与人类类似的集体推理缺陷，即使使用不同的提示策略也难以消除。这一研究提供了模型间性能差异的比较视角，揭示大模型规模和推理能力之间并没有必然联系，为人工智能集体智能的研究提供了新的基于证据的参考框架。", "conclusion": "HiddenBench框架提供了首个可用于衡量多智能体LLM集体推理能力的基准，具有可复现性的特点，能够帮助研究人员更好地诊断和理解模型间的差异，并为进一步研究集体人工智能奠定基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11140", "html_url": "https://arxiv.org/abs/2505.11140", "title": "遵循路径：通过知识图谱路径改善LLM事实性", "title_en": "Follow the Path: Reasoning over Knowledge Graph Paths to Improve LLM Factuality", "authors": "Mike Zhang,Johannes Bjerva,Russa Biswas", "background": "该研究介绍了一种名为fs1的新方法，该方法通过从大型推理模型（例如DeepSeek-R1）中获取推理痕迹并基于知识图（KG）路径进行条件化，提高了推理痕迹的客观性。研究者对8个调优指令的大型语言模型（LLM）进行了微调，使用了3900个客观性增强的推理痕迹数据集，并在涉及23900个问题的六个复杂开放领域的问答（QA）基准测试集上进行了严格的评估。在此之前，一些研究证明了在STEM领域中路径推理的有用性，但本研究提供了证据表明，将推理与实际的KG路径相连是为知识密集型任务赋予LLM可靠性的重要步骤。", "innovation": "该方法通过从大型推理模型获取推理痕迹并根据KG路径进行条件化，显著提高了模型的客观性。”fs1-tuned模型（拥有32B参数）在六项复杂开放领域的问答基准测试中，所有基于并行采样的指令调优模型的表现均优于16%。特别是在涉及多跳KG路径和数值答案类型的任务上，fs1的改进更为显著。对于更小的LLM，在单次推理过程中也展示了明显的性能提升。”", "conclusion": "该研究的实验证明，将路径推理与客观性的KG路径相结合是提高LLM可靠性的关键步骤。虽然之前的工作主要在STEM领域展示了路径推理的有效性，本研究提供的证据表明，通过这一方法将促使LLM在知识密集型任务中更加可靠。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10426", "html_url": "https://arxiv.org/abs/2505.10426", "title": "形式化人类在环：计算约简、失败模式和法律-道德责任", "title_en": "Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility", "authors": "Maurice Chiodo,Dennis Müller,Paul Siewert,Jean-Luc Wetherall,Zoya Yasmine,John Burden", "background": "该研究基于计算理论中的oracle机器和约简概念，正式化不同的人类在环（HITL）设置，以此来区分不同的AI系统人机交互模式。作者将HITL设置分为无须人类干预（全函数）、单一人类干预点（多项式约简）和高度交互人AI互动（图灵约简）。研究还探讨了不同HITL设置在法律地位和安全性方面的显著差异，并指出当前英国和欧盟的法律框架侧重于可能无法实现期望的伦理、法律和社会技术结果的HITL设置。研究揭示了HITL设置中不可避免的技术设计决策所带来的失败及其不可控性，为理解HITL设置的挑战提供了新的分析视角，帮助AI开发者和立法者设计更好的HITL设置以达到预期目标。", "innovation": "研究引入了oracle机器和约简概念来正式化HITL设置，并提出了关于HITL故障模式的分类系统。这一工作强调了在HITL设置中识别并应对技术失败的重要性，并指出了现有法律框架存在的不足之处，提出了法律应如何根据不同HITL设置的有效性来分配责任，以避免人类成为责任的“替罪羊”。通过这一视角，研究揭示了HITL设置中的不可控技术决断之间的权衡，即法律责任的归属与技术解释性之间的矛盾。", "conclusion": "研究展示了HITL设置与人类无法控制的技术失败之间的复杂关系，并提出了一个关于HITL设置的新分析框架。通过开发的正式模型和分类系统，研究为AI开发者和立法者提供了设计有效HITL设置以实现预期目标的指导，同时减少无意义的责任转嫁。该工作强调了在设计HITL系统时必须考虑技术可行性和法律可行性之间的平衡。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "尽管大型语言模型（LLMs）展示了出色的性能，但在不同应用场景中，其输出质量依然存在不一致性，难以识别出可靠的响应，特别是在需要多步推理的复杂任务中。论文主要探讨了如何利用Token-level Uncertainty estimation框架（TokUR）来帮助LLMs自我评估并改进其在数学推理中的响应质量。", "innovation": "文章提出的TokUR框架通过在LLM解码过程中引入低秩随机权重扰动生成预测分布，用于估计Token级不确定性，并通过聚合这些不确定性来捕捉生成响应的语义不确定性。实验结果表明，TokUR能够与答案正确性及模型鲁棒性高度相关，并且生成的不确定性信号可以在测试时增强模型的推理性能。", "conclusion": "实验结果表明，TokUR是一种有原则性和可扩展性的方法，能够提高LLMs在复杂推理任务中的可靠性和可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15197", "html_url": "https://arxiv.org/abs/2505.15197", "title": "意图手势：通过手势传达意图的言语", "title_en": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech", "authors": "Pinxin Liu,Haiyang Liu,Luchuan Song,Jason J. Corso,Chenliang Xu", "background": "人类说话时，手势有助于传达语义意图，如强调或描述概念。然而，当前的共时手势生成方法仅依赖于表面语言线索（例如语音音频或文本转录），而忽略了手势背后的语义意图。这种忽视导致生成的手势虽与语音节奏一致，但语义浅薄。", "innovation": "本文提出了一种名为Intentional-Gesture的新型框架，将手势生成视为基于高级沟通功能的意图推理任务。该框架首先通过增强BEAT-2数据集并添加手势意图注解来构建InG数据集，接着引入意图手势运动分词器以利用这些意图注解，实现与语音同步且语义丰富的手势合成，从而在BEAT-2基准测试中达到新的最佳性能。", "conclusion": "本框架为数字人类和具身AI中的表达性手势生成提供了模块化基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11480", "html_url": "https://arxiv.org/abs/2505.11480", "title": "SuperCoder：使用大规模语言模型进行汇编程序超优化", "title_en": "SuperCoder: Assembly Program Superoptimization with Large Language Models", "authors": "Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken", "background": "超优化是指将程序转换为更快的版本，同时保持其输入输出行为一致。本文研究了大规模语言模型（LLMs）是否可以作为超优化器，生成即使是在工业标准编译器优化过的代码也超越的汇编程序。此外，构建了第一个针对该问题的大规模基准测试集，包含8,072个真实的汇编程序，平均130行，而之前的基准测试集仅包含2-15行，且直行无循环。本文对23个LLMs进行了评估，结果表明基准模型Claude-opus-4在测试通过率和平均加速率上分别达到了51.5%和1.43倍。为了进一步提升性能，采用强化学习对模型进行微调，优化一个结合正确性和性能加速的奖励函数。基于Qwen2.5-Coder-7B-Instruct（正确率61.4%，加速率1.10倍），微调后的模型SuperCoder达到了95.0%的正确率和1.46倍的平均加速率。该研究首次证明了LLMs可以应用于汇编程序的超优化，为超出编译器启发式方法的程序性能优化研究奠定了基础。", "innovation": "首次建立了大规模汇编程序超优化基准测试集；使用LLMs进行超优化，并通过强化学习优化模型性能；证明了LLMs可以作为超优化器用于汇编程序.", "conclusion": "LLMs可以应用于汇编程序超优化，实现了前所未有的性能提升，为未来的程序性能优化研究提供了新的方向和基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14679", "html_url": "https://arxiv.org/abs/2505.14679", "title": "UltraEdit：无需训练、主题和内存的语言模型终身编辑", "title_en": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models", "authors": "Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang", "background": "终身学习使大型语言模型（LLMs）能够通过不断更新其内部知识来适应不断变化的信息。理想的系统应该支持高效的广泛更新，同时保留现有能力并确保可靠的部署。虽然最近的范式已经取得了显著进步，但它们往往难以满足大规模实践中的终身适应需求。", "innovation": "提出了一种名为UltraEdit的新颖方法，这是一种不需要训练、主题和内存的终身模型编辑方法，适用于超大规模的真实世界应用。UltraEdit通过仅使用隐藏状态及其梯度在一步中计算参数偏移，简化且高效。它还引入了一种终身归一化策略，能够随着时间的推移连续更新特征统计，从而适应分布变化并保持长期一致性。UltraEdit在编辑速度和内存使用方面优于之前的最先进方法，能够在24GB消费者级显卡上编辑7B参数的模型。", "conclusion": "在五个数据集和六个模型上进行全面实验后，UltraEdit在多种模型编辑场景中展示了卓越的性能，进一步向安全和可扩展的终身学习迈进。还构建了迄今为止领域中最大的UltraEditBench数据集，包含超过200万对编辑，证明了该方法在维护高准确性的同时支持大量编辑。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11756", "html_url": "https://arxiv.org/abs/2505.11756", "title": "特征对冲：相关特征破坏狭窄稀疏自编码器", "title_en": "Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders", "authors": "David Chanin,Tomáš Dulka,Adrià Garriga-Alonso", "background": "假设稀疏自编码器(SAEs)将多语义激活分解为可解释的线性方向，前提是激活是由底层特征的稀疏线性组合构成的。然而，研究表明，如果SAE比其训练中所用的“真特征”数量更窄，并且特征之间存在相关性，SAE会将相关特征的组成部分合并，从而破坏单语义性。在大语言模型的SAEs中，这两个条件几乎总是存在的。这种现象，我们称之为特征对冲，是由SAE的重构损失造成的，且SAE越窄对冲现象越严重。", "innovation": "本文引入并研究了特征对冲这一问题，通过理论上的玩具模型以及在大语言模型训练的SAEs中的实证研究，提出了特征对冲可能是导致SAEs在监督基线中持续表现不佳的一个核心原因之一的观点。进一步地，基于对特征对冲的理解，提出了一种改进的马特罗什卡自编码器的变体。特别指出的是，我们的研究显示，SAE宽度并非中性超参数，狭窄的SAE比宽的SAE更严重受到对冲的影响。", "conclusion": "通过研究特征对冲问题，作者揭示了一个关键因素，即为什么在训练过程中表现较弱的SAEs可能需要更宽的模型。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11824", "html_url": "https://arxiv.org/abs/2505.11824", "title": "潜隐真实性推理识别逐步推理中的错误", "title_en": "Latent Veracity Inference for Identifying Errors in Stepwise Reasoning", "authors": "Minsu Kim,Jean-Pierre Falet,Oliver E. Richardson,Xiaoyin Chen,Moksh Jain,Sungjin Ahn,Sungsoo Ahn,Yoshua Bengio", "background": "链式思维（CoT）推理提升了语言模型的能力和透明度，但推理链中可能包含不准确的陈述，这会降低性能和可信度。为了应对这一问题，本文提出了在一个CoT的每个推理步骤中添加一个潜隐真实性（或正确性）变量的方法，以提高推理链的准确性，并通过引入潜隐真实性搜索（VS）算法来高效探索这个扩展空间。", "innovation": "该研究提出了一种称为Veracity Search (VS)的算法，用于在CoT的每个推理步骤中添加一个潜隐真实性变量，并通过语言模型的联合似然度作为代理奖励来执行原本不可行的后验分布推理。此外，还提出了一种名为Amortized Veracity Inference (AVI)的机器学习方法，它可以进行零样本潜隐真实性的推理，该方法通过提供潜隐真实性的伪标签来辅助监督微调。实验结果表明，VS在逻辑（ProntoQA）、数学（GSM8K）和常识（CommonsenseQA）推理基准测试中准确地识别了错误，并且AVI在零样本准确性方面与VS相当，具有实用价值以提供反馈进行自我纠正和自我改进.", "conclusion": "潜隐真实性推理方法能够有效识别逐步推理中的错误，在逻辑、数学和常识推理方面表现出色，并有助于模型的自我纠正和自我改进。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12716", "html_url": "https://arxiv.org/abs/2505.12716", "title": "Shadow-FT：通过训练配对基础模型调整指令模型", "title_en": "Shadow-FT: Tuning Instruct Model via Training on Paired Base Model", "authors": "Taiqiang Wu,Runming Yang,Jiayi Li,Pengfei Hu,Yik-Chung Wu,Ngai Wong,Yujiu Yang", "background": "大语言模型（LLMs）在多种任务上通过进一步微调可以获得持续的改进。然而，直接对指令（即指令调优过的）模型进行微调往往会带来边际性的改进，甚至可能造成性能下降。这些指令模型的基础模型通常包含非常相似的权重值，而基础模型自身作为学习者较为出色，但在未经过训练的情况下作为主干相对较弱。因此，作者提出了一种新的Shadow-FT框架，通过利用相应的基础模型对指令模型进行微调，并直接将学习到的权重更新施加于指令模型。", "innovation": "与以往的全参数微调和参数高效微调方法相比，Shadow-FT在不添加额外参数、易于实现的同时显著提高了性能。该方法创新性地利用基础模型进行微调，并直接将学到的权重更新应用到指令模型中。此外，实验表明该方法还能应用于多模态的大语言模型，并可与直接偏好优化（DPO）结合使用。", "conclusion": "作者通过广泛实验在主流的LLM如Qwen 3和Llama 3系列上验证了Shadow-FT的有效性，并且在涵盖编码、推理和数学任务的19个基准上展示了其优越性。所有代码和权重已发布在Github上。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13577", "html_url": "https://arxiv.org/abs/2505.13577", "title": "VocalAgent：具备安全性评估的大型语言模型在嗓音健康诊断中的应用", "title_en": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation", "authors": "Yubin Kim,Taehan Kim,Wonjune Kang,Eugene Park,Joonsik Yoon,Dongjae Lee,Xin Liu,Daniel McDuff,Hyeonhoon Lee,Cynthia Breazeal,Hae Won Park", "background": "嗓音健康在人们的生活和交流中起着至关重要的作用，但全球范围内存在着大量的嗓音疾病患者，却缺乏便捷的诊断和治疗方法的问题。因此，需要一种新的解决方案来解决问题.", "innovation": "该论文引入了VocalAgent，这是一种基于音频的大型语言模型（LLM），通过诊断嗓音健康问题来应对上述挑战。VocalAgent利用Qwen-Audio-Chat对来自医院病人的三个数据集进行微调，并使用一个多维度评估框架进行评估，包括安全评估、跨语言性能分析和模态消融研究。VocalAgent的LLM方法提供了一个可扩展的解决方案，以促进健康诊断的广泛应用，同时强调了伦理和技术验证的重要性.", "conclusion": "VocalAgent在嗓音障碍分类的准确性上超过了最先进的基线方法。其基于LLM的方法提供了一个可扩展的解决方案，促进了更广泛的健康诊断应用，并强调了伦理和技术验证的重要性."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13497", "html_url": "https://arxiv.org/abs/2505.13497", "title": "通过环境导向交互学习层次化领域模型", "title_en": "Learning Hierarchical Domain Models Through Environment-Grounded Interaction", "authors": "Claudius Kienle,Benjamin Alt,Oleg Arenz,Jan Peters", "background": "领域模型可以让自主代理解决长期任务并生成可解释的计划。然而，在开放世界环境中，单一的通用领域模型无法捕捉到各种任务的多样性，因此代理需要根据实际情况生成特定任务的模型。尽管大型语言模型（LLMs）具有隐含的通用知识，能够生成此类领域模型，但由于较高的错误率，限制了它们的应用价值。相关工作依赖于大量的人工反馈或先前知识，从而影响了在开放世界的自主部署能力。因此，现有方法需要频繁的人类反馈或示例，这与真正的自主开放世界部署相矛盾。", "innovation": "本文提出了LODGE框架，该框架结合了从LLMs和环境中获取的信息进行自主领域学习。LODGE框架利用层次化抽象和自动化模拟来识别并纠正抽象层之间的不一致以及模型与环境之间的不一致。它是任务无关的，能够生成谓词、操作符及其前提条件和结果，仅需假设具有模拟器和一组通用的可执行的低级技能的访问权限。实验结果表明，LODGE生成的领域模型比现有方法更准确，任务成功率更高，且所需的环境交互次数显著较少，无需任何人工反馈或示例。", "conclusion": "LODGE框架在两个国际规划竞赛（IPC）领域和一个机器人装配领域实验中表现优异，生成更精确的领域模型，具有更高任务成功率，且环境交互次数显著较少，无需人类反馈或示例。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15674", "html_url": "https://arxiv.org/abs/2505.15674", "title": "UniErase: 力求语言模型中平衡且精准的反学习", "title_en": "UniErase: Towards Balanced and Precise Unlearning in Language Models", "authors": "Miao Yu,Liang Lin,Guibin Zhang,Xinfeng Li,Junfeng Fang,Xingrui Yu,Ivor Tsang,Ningyu Zhang,Kun Wang,Yang Wang", "background": "大型语言模型（LLMs）需要迭代更新来解决过时信息的问题，LLM反学习提供了一种有选择性地删除的方法。主流的反学习方法主要依赖于微调技术，这些方法在精准反学习和平衡反学习效率与普遍能力之间往往存在问题，特别是在大型和连续的数据设置中。为了解决这一问题，本文介绍了一种名为UniErase的新颖反学习框架，该框架在知识遗忘和能力保留之间展示了精准和平衡的表现。", "innovation": "提出了Unlearning Token，优化以引导LLM进入遗忘空间，并引入了轻量级的Unlearning Edit来高效关联反学习目标与元标记。这是通过编辑实现的新反学习范例，UniErase在虚构和现实世界知识场景下的批量、连续和精准反学习任务中取得了优异的表现。", "conclusion": "在TOFU基准测试中，相较于8个基线方法，仅修改约3.66%的LLM参数，UniErase的模型能力表现超过了之前最佳遗忘基线的约4.01倍，并且在反学习效率方面也超越了之前最佳保留方法35.96%。这表明UniErase在当前反学习社区中实现了平衡和双顶级表现。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16950", "html_url": "https://arxiv.org/abs/2505.16950", "title": "受限制的变换器：用于泛化推理的周期性 KV 缓存合并", "title_en": "Bottlenecked Transformers: Periodic KV Cache Consolidation for Generalised Reasoning", "authors": "Adnan Oomerjee,Zafeirios Fountas,Haitham Bou-Ammar,Jun Wang", "background": "Transformer 大规模语言模型（LLM）显示出随着推理时间计算能力增强的强推理能力，以令牌空间中的“思考链”为主要表现形式。已有研究将额外的计算推进到模型的潜在空间中，我们称之为辅助潜在空间计算（ALSC）。现有 ALSC 方法大致可分为三类：(i) 带有令牌中介的潜在滚动，(ii) 残差/激活引导，以及 (iii) 记忆 (KV) 压缩。一种较少探索的替代方法是记忆巩固/再巩固，这是大脑中两个过程的名称，负责稳定新形成的记忆痕迹，并且在回忆时使已确立的记忆暂时变得可塑，以整合新的上下文信息，然后再稳定下来。在 Transformer LLM 中，这种做法类似于对新 KV 段进行原地重写，以及对回忆过去段进行重写。", "innovation": "本文提出了 Bottlenecked Transformer 架构。该架构在骨干 LLM 上增加了 Cache Processor，即一个辅助 Transformer，用于在新的推理步骤分界点执行周期性、非因果的 KV 范围内原地重写。处理器将最近写入的 KV 条目进行巩固，并重新巩固顶级 k 注意选择的先前条目。实验表明，该模型在数学推理基准上的性能比传统的 Transformer 和带有暂停令牌的基准模型有持续的提升，最高可提升 6.6 个百分点。", "conclusion": "通过信息瓶颈（IB）理论，本文为通过 KV 缓存重写进行记忆（再）巩固提供了理论依据。理论证明，在潜在表示中平衡输入信息压缩和预测信息保留有助于改善推理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16932", "html_url": "https://arxiv.org/abs/2505.16932", "title": "The Polar Express: 最佳矩阵符号方法及其在Muon算法中的应用", "title_en": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "authors": "Noah Amsel,David Persson,Christopher Musco,Robert M. Gower", "background": "计算极分解及其相关矩阵符号函数的问题在数值分析中已经研究了数十年。最近，这些问题成为深度神经网络训练中Muon算法的一个重要子程序。然而，这些应用场景的需求与传统的设置截然不同：深度学习需要GPU友好的算法，优先效率而非精度。", "innovation": "提出了Polar Express，这是一种新的计算极分解的方法。该方法借鉴了Chen & Chow和Nakatsukasa & Freund早期的工作，通过在每次迭代中解决最小极大优化问题来适应更新规则。这种方法在最坏情况下的误差最小化，确保Polar Express多次快速收敛，包括早期迭代和渐近收敛。此外，还解决了有限精度问题，使其在bfloat16下实用。", "conclusion": "Polar Express 方法被整合到 Muon 训练框架中，训练来自 FineWeb 数据集的 10 亿个标记的 GPT-2 模型时，能够一致地降低验证损失，且在多个学习率范围内性能优于现有的替代方案。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15441", "html_url": "https://arxiv.org/abs/2505.15441", "title": "八阶视觉变换器：通过不变性实现更快的视觉变换器", "title_en": "Octic Vision Transformers: Quicker ViTs Through Equivariance", "authors": "David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman", "background": "现代先进的视觉变换器（ViTs）未能利用自然几何对称性，如90度旋转和反射。本文探讨了这种现象，并指出原因并非是缺乏基础原理，而是缺乏有效的实现方法。自然的几何对称性在视觉任务中具有重要价值，但传统的模型设计忽略了这一点，导致资源浪费和效率低下。本文提出了一种基于八阶群不变性的八阶视觉变换器(octic ViTs)，来捕捉这些对称性。与之前增加计算成本的可变模型不同，该模型的八阶线性层实现了5.33倍的FLOPs降低和高达8倍的内存减少。在八阶ViT块中，计算减少接近增加嵌入维度后的线性层减少量。研究表明，从八阶块构建的两种新系列ViT在监督训练（DeiT-III）和无监督训练（DINOv2）上，ImageNet-1K上的准确度与基线模型相当，同时提供了显著的效率提升。", "innovation": "提出了八阶视觉变换器(octic ViTs)，利用八阶群不变性来捕捉自然几何对称性，设计了八阶线性层，实现了计算成本和内存使用的大幅降低。尽管八阶ViT设计上允许更多的对称性，但在网络的最后部分仍然保留了部分可变性。通过在ImageNet-1K上进行监督训练和无监督训练，实验表明，八阶视觉变换器在保持与基线模型相同准确度的前提下，实现了显著的效率提升。", "conclusion": "八阶视觉变换器通过利用自然几何对称性，提供了一种更高效的设计方法，减少计算和内存开销，同时保持甚至提升模型的准确度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16415", "html_url": "https://arxiv.org/abs/2505.16415", "title": "响应归因：Jensen-Shannon 散度驱动的检索增强生成背景归因机制研究", "title_en": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation", "authors": "Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz", "background": "检索增强生成（RAG）通过结合大语言模型（LLMs）和外部上下文来提高生成响应的准确性和可靠性。然而，准确地将生成的内容归因于特定的上下文片段（上下文归因）仍然具有挑战性，因为当前的方法计算量大且往往需要大量的调优或人工注释。", "innovation": "该研究提出了一种新的由Jensen-Shannon 散度驱动的方法（ARC-JSD），能够在不进行额外调优、梯度计算或替代建模的情况下，高效且准确地识别关键的上下文句子。该方法在TyDi QA、Hotpot QA和Musique等广泛使用的RAG基准测试中与基于替代的方法相比，显示出更高的准确性和显著的计算效率改进，并揭示了特定注意力头和多层感知机（MLP）层在上下文归因中的作用，对RAG模型的内部工作机制及其对RAG行为的影响提供了有价值的洞察。", "conclusion": "该方法在不同规模的指令调优LLMs上进行评估，显示出优越的准确性和显著的计算效率提升。研究还进行了机制分析，揭示了特定的注意力头和多层感知机层在上下文归因中的作用。提供的代码可以在 https://github.com/具体GitHub地址 上找到。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16790", "html_url": "https://arxiv.org/abs/2505.16790", "title": "Masked Element-wise Learnable Diffusion for Molecular Generation", "title_en": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion", "authors": "Hyunjin Seo,Taewon Kim,Sihyun Yu,SungSoo Ahn", "background": "掩码扩散模型（MDMs）在离散数据建模方面取得了显著进展，但在分子生成领域的潜力尚未得到充分探索。传统的MDMs直接应用于分子生成时，其性能显著下降。原因在于其向前扩散过程中不同分子状态混叠成共同状态，导致重建目标混杂，无法通过典型的单一预测逆扩散过程学习。", "innovation": "为解决这一问题，该论文提出了Masked Element-wise Learnable Diffusion (MELD)。MELD通过参数化的噪声调度网络为每个图元素（原子和键）分配不同的破坏率，协调各元素的破坏路径，避免不同分子图之间的碰撞。实验结果显示，MELD显著提高了整体生成质量，使得vanilla MDMs在ZINC250K数据集上的化学有效性从15%提升到93%，同时达到了条件生成任务中状态最前沿的性质对齐效果。", "conclusion": "该研究揭示了MDMs在分子生成中的不足并提出了解决方案MELD，显著提升了分子生成模型的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16429", "html_url": "https://arxiv.org/abs/2505.16429", "title": "超越静态测试平台：面向动态推荐系统的交互为中心的代理模拟平台", "title_en": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems", "authors": "Song Jin,Juntian Zhang,Yuhan Liu,Xun Zhang,Yufei Zhang,Guojun Yin,Fei Jiang,Wei Lin,Rui Yan", "background": "传统A/B测试资源密集，而离线方法难以应对动态用户-平台交互。虽然基于代理的模拟是很有潜力的，但现有平台往往缺乏机制，使得用户行为能够动态重新塑造环境，从而限制了其效果和实用性。为了弥合这一差距，我们引入了RecInter，这是一种新颖的面向推荐系统的基于代理的模拟平台，具有稳健的交互机制。该平台确保了模拟的高保真度，并成功地复制了品牌忠诚度和马太效应等新兴现象。实验表明，这种交互机制对于模拟现实系统的演化至关重要，从而确立了该平台作为推荐系统研究的可信试验平台的地位。", "innovation": "提出了RecInter平台，这是一种基于代理的模拟平台，具备洞察用户的多维配置文件模块、先进的代理架构和经过因果思维（CoT）增强的交互数据微调的大语言模型。该平台的特点是模拟用户行为（如点赞、评论、购买）能实时动态更新商品属性，并引入了商家代理以互动，从而提高了生态的真实性和演化性。验证交互机制对于模拟真实系统演化的必要性和重要性。", "conclusion": "实验展示了交互机制对模拟真实系统演化的关键性，并确立了RecInter平台作为推荐系统研究可信试验平台的地位。代码已发布。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19660", "html_url": "https://arxiv.org/abs/2505.19660", "title": "Prompting is not Enough: Exploring Knowledge Integration and Controllable Generation on Large Language Models", "title_en": "Prompting is not Enough: Exploring Knowledge Integration and Controllable Generation on Large Language Models", "authors": "Tingjia Shen,Hao Wang,Chuan Qin,Ruijun Sun,Yang Song,Defu Lian,Hengshu Zhu,Enhong Chen", "background": "开放域问答（OpenQA）是自然语言处理（NLP）中的核心组成部分，主要涉及从非结构化文本数据中抽取答案。近年来，大型语言模型（LLMs）的快速发展使其具备了传统方法难以比拟的理解和问答能力。然而，大多数基于LLM的OpenQA方法在知识整合和生成特定格式答案方面遇到了关键挑战。为解决这些挑战，本文提出了一种名为GenKI的新框架，旨在通过同时探索LLMs上的知识整合和可控生成来提高OpenQA的性能。", "innovation": "本文创新性地提出了一种名为GenKI的新框架，该框架通过首先训练密集段落检索模型来检索给定知识库中的相关知识。随后，引入了一个新颖的知识整合模型，在微调过程中将检索到的知识整合到指令中以增强模型。此外，为了在LLM中实现可控生成，利用了一种特定的微调LLM和基于文本一致性的集成方法，确保回答的一致性、流畅性和格式正确性。实验结果表明，相比于最先进基准，GenKI在TriviaQA、MSMARCO和CMRC2018数据集上的表现更为有效，且消融研究揭示了检索知识频率与模型准确回忆知识能力之间的线性关系。", "conclusion": "本文通过实验验证了GenKI的有效性，并展示了其在多种答案格式下的卓越性能。此外，通过消融研究进一步说明了知识整合与可控生成的重要性。作者提供的GenKI代码可以访问此链接：[此处提供链接]。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16831", "html_url": "https://arxiv.org/abs/2505.16831", "title": "Unlearning 不是删除：探索大语言模型中机器反学习的可逆性", "title_en": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", "authors": "Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu", "background": "大语言模型（LLMs）的反学习旨在移除特定数据，但其效果通常通过任务级别的度量标准（如准确率和困惑度）进行评估。然而，这些度量标准往往具有误导性，因为模型可能会表现出遗忘，而其原始行为通过轻量级微调就能轻易恢复。这一现象表明信息被抑制而不是真正删除。现有的评价方法未能充分揭示反学习的真实影响，因此存在重要的评价缺口。", "innovation": "本文介绍了代表级别的分析框架，该框架通过主成分分析（PCA）相似性和偏移、中心核对齐（CKA）和费舍尔信息以及平均PCA距离等指标来衡量表征漂移，跨多个反学习方法、数据域和大语言模型进行评估。本文根据可逆性和灾难性来识别四种不同的遗忘模式。此外，研究还揭示了不可逆、非灾难性遗忘的理想状态实现难度极高，并发现了一个看似不可逆但实际上是被靶向遗忘的案例，这对设计更稳健的擦除算法提供了新的启示。这项研究还揭示了当前评价实践中的根本性差距，并为可信的反学习建立了代表级别的基础。", "conclusion": "本文的研究揭示了反学习中固有的可逆性问题，证明信息被抑制而非真正删除。新的代表级别的分析框架可以帮助更准确地评估反学习的效果，为设计更可靠的擦除算法提供了新的视角。这种代表水平的基础有助于建立更高可信度的反学习评价方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17117", "html_url": "https://arxiv.org/abs/2505.17117", "title": "从标记到思考：LLMs和人类如何在压缩与意义之间交易", "title_en": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning", "authors": "Chen Shani,Liron Soffer,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv", "background": "人类将知识组织成紧凑的主题类别，这种组织方式在保持语义意义的同时实现压缩。大型语言模型（LLMs）展示了非凡的语言能力，但尚不清楚它们是否达到这种压缩和语义意义的同一平衡。本研究应用信息瓶颈原则，定量比较LLMs和人类如何在压缩与语义意义之间进行权衡。通过对40多种LLMs的嵌入与经典的人类类别基准的分析，发现LLMs在广泛遵循人类类别方面存在不足，忽视了对于人类理解至关重要的细粒度语义差异，同时在统计压缩和信息论效率方面表现激进，相比之下，人类更加重视上下文丰富性及适应灵活性。此外，编码模型在人类似乎优于解码模型，表明当前架构中的生成和理解依赖于不同的机制。训练动力学分析揭示了概念结构发展的不同阶段，以及语义处理在模型发现更高效的编码方式时从深层网络层迁移至中间网络层。", "innovation": "研究应用信息瓶颈原则来定量比较LLMs和人类在压缩-意义权衡中的表现。分析了40多种LLMs的嵌入与经典的人类类别基准，发现了LLMs相较于人类在某些方面存在的局限性，特别是在细粒度语义差异的保持上，此外还揭示了编码模型在人类似乎优于解码模型的现象，以及概念结构发展的不同阶段，这些发现为理解人工与生物智能之间的根本差异提供了新的视角。", "conclusion": "LLMs和人类在压缩-意义权衡上的不同策略揭示了人工智能和生物智能之间的根本差异，并指导了更加人机对齐的AI的发展方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20321", "html_url": "https://arxiv.org/abs/2505.20321", "title": "BiomedSQL：在生物医药知识库上进行科学推理的文本到SQL", "title_en": "BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases", "authors": "Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri", "background": "生物医药研究人员越来越多地依赖大规模结构化数据库来完成复杂的分析任务。然而，当前的文本到SQL系统在将定性的科学问题转化为可执行的SQL查询时常常遇到困难，尤其是当需要进行隐含领域推理时。因此，存在一种迫切需求开发一种能够有效评估文本到SQL生成过程中科学推理能力的新基准。", "innovation": "本文提出了BiomedSQL，这是第一个专门设计来评估文本到SQL生成过程中在现实生物医药知识库上的科学推理能力的基准。BiomedSQL包含68,000个问题/SQL查询/答案三元组，并基于一个整合了基因-疾病关联、从组学数据推断因果关系以及药物批准记录的标准化BigQuery知识库。与现有的系统相比，BiomedSQL通过引入更复杂的科学推理任务，让模型能够推断特定于领域的标准，而不仅仅是依赖于语法翻译。", "conclusion": "我们在开源和闭源的大语言模型上进行了广泛的评估，并且结果表明，这些模型之间的性能存在显著差距。我们的定制多步代理BMSQL达到了62.6%的执行准确性，尽管这仍然低于90%的专家基准。BiomedSQL提供了一个新的基础，用于推进文本到SQL系统的发展，这些系统能够通过在整个结构化生物医药知识库上进行强大的推理来支持科学发现。我们的数据集和代码是公开的，可以通过提供的链接访问。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16965", "html_url": "https://arxiv.org/abs/2505.16965", "title": "BP-Seg：基于信念传播的图模型方法实现无监督和非连续文本段落划分", "title_en": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation", "authors": "Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz", "background": "文本分割基于语句的语义意义是一项基本任务，具有广泛的应用前景，特别是在许多下游应用中。传统的文本分割方法往往依赖于监督学习或仅考虑局部连贯性，这导致在处理长篇文章时可能无法有效捕捉到远程但语义相似的句子之间的关系。因此，提出了一种基于图模型的无监督学习方法BP-Seg，以更有效地进行文本分割。", "innovation": "BP-Seg引入了一种结合局部连贯性和语义相似性的策略，通过精心构建的图模型上的信念传播实现非连续文本段落的无监督划分。这种方法能够捕捉到相邻句子之间的直接关系，同时也能识别出在文本中相距较远但在语义上相似的句子，提供了一种创新的文本分割方法。", "conclusion": "BP-Seg方法在示例和长文档数据集上的实验结果表明，其在文本分割性能上优于现有的竞争方法。这表明BP-Seg对于提高文本处理的效率和准确性具有重要的应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17967", "html_url": "https://arxiv.org/abs/2505.17967", "title": "基于FFT的动态子空间选择在大型语言模型低秩自适应优化中的应用", "title_en": "FFT-based Dynamic Subspace Selection for Low-Rank Adaptive Optimization of Large Language Models", "authors": "Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh", "background": "低秩优化已成为训练大型语言模型（LLMs）的一种有前景的方法，通过限制学习过程在低维空间中进行，可以提高运行时间和减少自适应优化器的内存使用。先前研究通常使用奇异值分解（SVD）或QR分解投影线性层的梯度，但在大型模型的每一层上单独应用这些技术会非常耗时并增加额外的内存成本。因此，该文提出了一种高效且概念上简单的双步骤方法，通过使用离散余弦变换（DCT）的预定义正交矩阵来近似SVD/QR基于的梯度投影到低维空间，从而解决了上述问题。", "innovation": "提出了基于FFT的动态子空间选择方法，通过使用离散余弦变换（DCT）的预定义正交矩阵对大型语言模型进行低秩优化。该方法通过从DCT矩阵中动态选择与各层梯度对齐的列，简化了投影过程，并且相对于传统的SVD/QR方法，该方法在计算时间和内存使用方面表现更好，特别在大型模型层中，DCT可通过Makhoul的N点算法基于快速傅里叶变换（FFT）实现，在O(n^2 log(n))时间内完成。", "conclusion": "实验结果表明，该双策略有效地近似了最优低秩投影，实现了与昂贵的SVD/QR方法相当的性能，同时在不同模型大小下运行时间加快且内存使用减少最多可达25%。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18697", "html_url": "https://arxiv.org/abs/2505.18697", "title": "Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study", "title_en": "Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study", "authors": "Ziyang Cheng,Zhixun Li,Yuhan Li,Yixin Song,Kangyi Zhao,Dawei Cheng,Jia Li,Hong Cheng,Jeffrey Xu Yu", "background": "现实世界的数据，尤其是结构化图数据，通常以流式的方式到来，这意味着学习系统需要持续获取新知识而不忘记之前学习的信息。近年来，尽管有许多现有工作试图解决图机器学习中的灾难性遗忘问题，但它们都是基于从零开始训练流式数据来实现的。随着预训练模型的兴起，越来越多的研究利用其强大的泛化能力来进行持续学习。因此，本文试图探讨大型语言模型（LLMs）是否可以缓解图连续学习（GCL）中的灾难性遗忘问题。然而，当前GCL的实验设置存在显著缺陷，评估阶段可能导致任务ID泄露。", "innovation": "本文提出了一种简单而有效的无重现方法（SimGCL），在无重现约束下超越了之前基于GNN的最新基线约20%。此外，作者开发了一个易于使用的基准（LLM4GCL）工具，用于训练和评估现有的GCL方法，以促进重复研究。", "conclusion": "基于广泛的实验，本文提出了一种简单的无重现方法（SimGCL），在无重现约束下超越了之前基于GNN的最新基线约20%。此外，为促进重复研究，作者开发了一个易于使用的基准（LLM4GCL）工具，用于训练和评估现有的GCL方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21969", "html_url": "https://arxiv.org/abs/2505.21969", "title": "DORAEMON: 分散化的 ontology 意识可靠代理及增强记忆导向导航", "title_en": "DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation", "authors": "Tianjun Gu,Linfeng Li,Xuhong Wang,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan", "background": "居家服务机器人在不熟悉的环境中进行自适应导航是至关重要的，但仍然具有挑战性，因为这需要低级路径规划和高级场景理解的结合。尽管基于视觉-语言模型（VLM）的零样本方法能够减少对先验地图和特定场景训练数据的依赖，它们仍然存在显著的局限性，如时空断裂性、无结构的记忆表示以及任务理解不足导致的导航失败。", "innovation": "我们提出了DORAEMON（Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation），这是一种由腹侧流（Ventral Stream）和背侧流（Dorsal Stream）组成的新型认知启发式框架。背侧流实现了层次语义-空间融合和拓扑图来处理时空断裂问题，而腹侧流结合了RAG-VLM和Policy-VLM以改善决策。此外，我们开发了Nav-Ensurance以确保导航的安全性和效率。我们在HM3D、MP3D和GOAT数据集中评估了DORAEMON，结果显示其在成功率（SR）和路径长度加权成功率（SPL）方面取得了最先进的性能，并显著优于现有方法。我们还引入了一个新的评估指标（AORI）来更好地评估导航智能。", "conclusion": "综合实验结果表明，DORAEMON在零样本自主导航方面非常有效，无需的地图建设和预训练。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18777", "html_url": "https://arxiv.org/abs/2505.18777", "title": "HD-PiSSA: 高阶分布正交适应", "title_en": "HD-PiSSA: High-Rank Distributed Orthogonal Adaptation", "authors": "Yiding Wang,Fauxu Meng,Xuefeng Zhang,Fan Jiang,Pingzhi Tang,Muhan Zhang", "background": "现有的参数高效微调（PEFT）方法，如LoRA和PiSSA，限制模型更新到低秩子空间，这限制了其表达能力，并导致在复杂任务上的性能不佳。", "innovation": "提出了一种名为HD-PiSSA的方法，这是一种分布式的PEFT方法。它在不同设备上初始化正交适配器，并在W上集体聚合delta更新，从而使得预训练权重的主成分分布到每个GPU上，相比数据并行LoRA或PiSSA，HD-PiSSA大幅扩展了更新方向范围。在8个GPU上进行微调时，HD-PiSSA的有效更新秩是数据并行LoRA或PiSSA的16倍以上。", "conclusion": "实验结果表明，HD-PiSSA在各种挑战性下游任务中，包括数学、代码生成和多任务学习，总体性能相比LoRA提升了10.0个绝对点（14.63%），相比PiSSA提升了4.98个点（6.60%）。多任务设置下，HD-PiSSA在12个基准中平均每项提高了10.0个绝对点（14.63%）的性能，优于LoRA和PiSSA，证明了额外的优化灵活性带来的优势。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20110", "html_url": "https://arxiv.org/abs/2505.20110", "title": "超越代理：线下GFlowNet训练的基于轨迹提炼指导", "title_en": "Beyond the Proxy: Trajectory-Distilled Guidance for Offline GFlowNet Training", "authors": "Ruishuo Chen,Xun Wang,Rui Hu,Zhuoran Li,Longbo Huang", "background": "GFlowNets虽然在多样性和高奖励对象的采样方面表现出色，但在无法进行新奖励查询的真实世界场景中，它们需要从离线数据集中进行训练。目前的基于代理的训练方法容易产生误差传播的问题，现有的无代理方法则常常使用粗糙的约束条件来限制探索。", "innovation": "提出了Trajectory-Distilled GFlowNet (TD-GFN)，一种新型的无代理训练框架。TD-GFN通过逆强化学习从离线轨迹中学习密集的、过渡级别的边缘奖励，从而提供丰富的结构指引以实现高效的探索。此外，TD-GFN通过有向无环图（DAG）剪枝和优先反向采样来间接指导策略，确保最终的梯度更新仅依赖于数据集中的真实终端奖励，从而避免了误差传播问题。", "conclusion": "实验结果表明，TD-GFN在收敛速度和最终样本质量方面显著优于现有的多种基线方法，为线下GFlowNet训练建立了一个更为稳健和高效的范式。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05154", "html_url": "https://arxiv.org/abs/2506.05154", "title": "利用参数知识强化学习抵御RAG中的上下文干扰", "title_en": "Resisting Contextual Interference in RAG via Parametric-Knowledge Reinforcement", "authors": "Chenyu Lin,Yilin Wen,Du Su,Hexiang Tan,Fei Sun,Muhan Chen,Chenfu Bao,Zhonghou Lyu", "background": "检索增强生成（RAG）在知识密集型任务中表现良好，但在遇到与事实不符、无关或矛盾的检索文本时可能会失效，导致模型依赖不准确的信息并引发累积错误。", "innovation": "提出了一个利用参数知识（PK）的增强学习框架——Knowledgeable-R1（K-R1），旨在训练大型语言模型在利用外部上下文的同时，提高对错误上下文的抵抗力。该框架采用联合采样方案生成带检索和不带检索的配对响应，以量化应忽略误导性上下文还是采纳上下文的时间点。此外，通过引入非对称优势转换来放大探索参数知识的行为。", "conclusion": "K-R1 显著提高了知识冲突场景和一般 RAG 场景中的鲁棒性和推理准确性，在假设场景中优于最新基准（SOTA）23%，且在检索文本完全不可用时表现无降。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21893", "html_url": "https://arxiv.org/abs/2505.21893", "title": "SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training", "title_en": "SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training", "authors": "Xiaomeng Yang,Zhiyu Tan,Junyan Wang,Zhijian Zhou,Hao Li", "background": "偏好学习已成为生成模型与人类期望对齐的核心技术。近期，偏好学习被扩展到扩展示模型中，例如通过直接偏好优化（DPO）等方法。然而，现有方法如Diffusion-DPO面临着两个关键挑战：1）时间步长相关的不稳定性，这是由于反向扩散和正向扩散之间的匹配差以及早期噪声时间步中的高梯度方差所致；2）由于优化策略和数据收集策略之间的匹配差导致的政策偏差问题。研究表明，不稳定性主要发生在低重要权重的早期时间步中。为了避免这些问题，SDPO提出了一种策略，通过裁剪和屏蔽无信息的时间步来提高稳定性，同时部分缓解政策偏差。此外，SDPO还引入了一个更具原理性的框架，通过将重要抽样纳入目标中来完全纠正政策偏差，并在扩散过程中强调信息性的更新。实验表明，SDPO优于标准的Diffusion-DPO，在VBench得分、人类偏好对齐和训练鲁棒性方面表现更优。", "innovation": "SDPO提出了两种创新的方法：1）DPO-C&H策略，通过裁剪和屏蔽无信息的时间步来改善稳定性，同时部分缓解政策偏差；2）SDPO框架，引入重要抽样到优化目标中，以完全纠正政策偏差，并在扩散过程中强调信息的重要性。这些方法解决了现有方法的时间步长相关不稳定性和政策偏差问题，提高了扩散模型的训练稳定性与效果。", "conclusion": "实验结果表明，两种方法（DPO-C&H和SDPO）均能提升扩散模型的稳定性、人类偏好对齐和训练的稳健性，其中SDPO在VBench得分和训练效果方面更有优势。这强调了时间步长意识和分布校正优化在基于扩散的偏好学习中的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22988", "html_url": "https://arxiv.org/abs/2505.22988", "title": "模型保留自适应舍入", "title_en": "Model-Preserving Adaptive Rounding", "authors": "Albert Tseng,Zhaofeng Sun,Christopher De Sa", "background": "量化的目标是生成一个压缩模型，使得其输出分布尽可能接近原始模型。大多数量化算法通过最小化每一层的即时激活误差来近似端到端误差，但这种方法忽视了后续层的影响，效果不佳。因此，需要一种新的方法来直接考虑网络末端的误差，以提高量化算法的效果。", "innovation": "本文提出了Yet Another Quantization Algorithm (YAQA)，这是一款自适应舍入算法，直接考虑了网络末端的误差。YAQA 提供了一系列理论成果，得到了量化算法的第一个端到端误差界。首先，通过分析 Hessian 近似结构来表征自适应舍入算法的收敛时间。其次，表明端到端误差可以通过近似与真实 Hessian 的余弦相似度来界定。这允许使用自然的 Kronecker 分解近似及相应的接近最优 Hessian 草图。YAQA 在理论上优于 GPTQ/LDLQ，并在实验中减少了大约 30% 的误差。甚至在量化感知训练中的误差也较低。这带来了最佳的下游任务效果，同时不增加推理开销", "conclusion": "YAQA 法在量化过程中保留了模型特性，并在多个任务中展示了优越的性能，同时保证了推理效率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23863", "html_url": "https://arxiv.org/abs/2505.23863", "title": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "title_en": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "authors": "Chang Liu,Bohao Zhao,Jingtao Ding,Huandong Wang,Yong Li", "background": "长期预测混沌系统仍旧是一个基本挑战，因为其内禀的初始条件敏感性和复杂几何奇异吸引子结构。传统的计算方法，如存储器计算，通常需要包含长时间连续动态行为的训练数据以全面捕获系统动力学。而先进的深度序列模型虽然可以在训练数据中捕捉瞬态动力学，但往往难以在长时间范围内维持预测稳定性和动力学一致性。", "innovation": "我们提出了PhyxMamba框架，这是一种整合基于Mamba的状态空间模型与物理原则指导的预测框架，用于根据短期历史观测来预测混沌系统的长期行为。PhyxMamba首先通过时间延迟嵌入重建吸引子流形以提取全局动力学特征，随后引入生成训练方案使Mamba能够复制物理过程。此外，通过多段预测和吸引子几何正则化增强，解决物理约束问题，从而提高预测精度并保留系统的关键统计特征。", "conclusion": "在模拟和真实混沌系统的广泛实验中，PhyxMamba展示了卓越的预测准确性，并能忠实地从短期历史观测中捕捉关键统计特性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21573", "html_url": "https://arxiv.org/abs/2505.21573", "title": "基于有限数据和未知物理的频谱启发式操作学习", "title_en": "Spectral-inspired Operator Learning with Limited Data and Unknown Physics", "authors": "Han Wan,Rui Zhang,Hao Sun", "background": "学习从有限数据中推断未知物理的偏微分方程（PDE）动力学是一项挑战。现有的神经PDE求解器要么需要大量数据集，要么依赖已知的物理规律（如PDE残差或手工艺品），这限制了它们的实际应用范围。", "innovation": "本文提出了一种名为Spectral-Inspired Neural Operator（SINO）的方法，该方法能够在只需要2-5条轨迹数据的情况下建模复杂系统，无需明确指定PDE项。SINO方法可以从频谱索引自动捕捉局部和全局的空间导数，实现对未知物理环境下的基本微分算子的紧凑表示，并通过Pi-block执行谱特征的乘法操作。此外，还附加了一个低通滤波器以抑制混叠现象。与现有方法相比，SINO在二维和三维PDE基准测试中展现了最先进的性能，在精度上提高了1-2个数量级，并且当仅使用5条训练轨迹时，SINO在复杂、不适合其他方法的案例上表现更好。", "conclusion": "本文提出的SINO能够在有限数据和未知物理条件下实现PDE动力学的建模，具有更高的精度，并且能够在较少的数据条件下获得更好的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09079", "html_url": "https://arxiv.org/abs/2506.09079", "title": "VidBridge-R1: 通过中间代理任务为基于强化学习的视频理解模型桥接问答和字幕", "title_en": "VidBridge-R1: Bridging QA and Captioning for RL-based Video Understanding Models with Intermediate Proxy Tasks", "authors": "Xinlong Chen,Yuanxing Zhang,Yushuo Guan,Weihong Lin,Zekun Wang,Bohan Zeng,Yang Shi,Sihan Yang,Qiang Liu,Pengfei Wan,Liang Wang,Tieniu Tan", "background": "基于强化学习的多模态大型语言模型展示出了在多模态情境下的巨大潜力，但将其应用于视频领域时，形成了专门针对问答（QA）或字幕任务的模型，但在同时处理两个任务方面却表现不佳。单纯的混合这两种任务的奖励信号结果导致了这两种任务之间存在的挑战性冲突，使得模型无法有效掌握两者。", "innovation": "提出一种基于两个中间代理任务的新训练框架：DarkEventInfer要求模型根据上下文视频线索推断被遮掩的内容，MixVidQA则要求模型在交错出现的视频序列中识别并处理一个片段，忽略另一个。这种框架促使模型同时发展全面的、发散的理解能力和精确的、收敛的推理能力。基于这个框架，提出了VidBridge-R1，这是第一个能够同时在问答和字幕任务上取得显著性能提升的通用视频推理模型。", "conclusion": "大量的实验证明，VidBridge-R1在问答和字幕两个任务上都取得了显著的性能提升，展示了我们方法在促进更具普遍性和强大功能的视频理解模型方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10821", "html_url": "https://arxiv.org/abs/2506.10821", "title": "通过视频思考实现有目的的长视频理解", "title_en": "Think With Videos For Agentic Long-Video Understanding", "authors": "Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou", "background": "长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。现有的方法要么为了单次推理而对帧进行下采样，牺牲了细粒度的细节，要么依赖于对任务无关表示的文本推理，这限制了任务特定的感知和探索。", "innovation": "本文提出了VideoExplorer框架，该框架基于“用视频思考”的原则，自然地将规划、时间定位和扩谱感知融合到一个连贯的推理过程中。VideoExplorer迭代地提出子问题，定位相关时刻，并执行任务导向的时间扩谱视频理解，直至达到最终答案，从而实现忠实、高效和可解释的推理。此外，为了应对缺乏LVU训练资源的问题，构建了一个使用可调整难度采样的长视频推理数据集，确保复杂任务上的高质量轨迹。基于该数据集，设计了两个阶段的训练管道：首先进行有监督轨迹初始化，随后是轨迹级别的偏好优化。", "conclusion": "在流行的长视频理解和推理基准测试上进行的广泛评估表明，VideoExplorer相比现有的基线方法具有显著优势，突显了它的鲁棒性、适应性和效率。我们的代码在此仓库中公开提供。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03162", "html_url": "https://arxiv.org/abs/2506.03162", "title": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "title_en": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "authors": "Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh", "background": "随着监控摄像头的快速普及，对自动化暴力检测的需求增加。现有的卷积神经网络（CNN）和Transformer在提取空间-时间特征方面取得了成功，但在处理长期依赖性和计算效率方面存在困难。", "innovation": "本文提出了结合双分支设计和状态空间模型（SSM）骨干网络的Dual Branch VideoMamba (VideoMamba)，其中一分支捕捉空间特征，另一分支关注时间动态。通过门控机制在分支之间进行持续融合，以增强模型在挑战性监控场景中检测暴力活动的能力。同时，本文还通过融合RWF-2000、RLVS、SURV和VioPeru数据集创建了一个新的基准，确保了训练集和测试集之间的严格分离。", "conclusion": "实验结果表明，该模型在该新基准和另一个新数据集DVD上的性能达到最好，展示了SSM在可扩展的、接近实时的监控暴力检测中的潜力，提供了准确性和计算效率之间的最佳平衡。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02244", "html_url": "https://arxiv.org/abs/2506.02244", "title": "为视频生成模型提供物理引导的运动损失", "title_en": "Physics-Guided Motion Loss for Video Generation Model", "authors": "Bowen Xue,Giuseppe Claudio Guarnera,Shuang Zhao,Zahra Montazeri", "background": "当前的视频扩散模型能够生成视觉吸引人的内容，但常常违背基本的物理法则，产生诸如橡胶布变形和物体不一致运动等细微的艺术品。这些模型往往在运动的合理性方面存在缺陷。", "innovation": "提出了频域的物理先验，改进了运动的合理性，而无需修改模型架构。该方法将常见的刚体运动（平移、旋转、缩放）分解为轻量级的频谱损失，只需要2.7%的频谱系数，同时保留97%以上的频谱能量。应用到Open-Sora、MVDIT和Hunyuan这三个模型上，该方法在OpenVID-1M数据集上平均提高了11%的动作识别准确性（相对比），同时保持了视觉质量。用户研究显示，对于增强物理性质的视频，有74%-83%的偏好。同时，这种方法还降低了22%-37%（具体取决于基础模型）的扭曲误差，并改善了时间一致性的分数。", "conclusion": "简单而全局的频谱提示是视频中物理合理运动的有效正则化方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23867", "html_url": "https://arxiv.org/abs/2505.23867", "title": "InfiMed：低资源医学多模态大语言模型的发展理解和推理", "title_en": "InfiMed: Low-Resource Medical MLLMs with Advancing Understanding and Reasoning", "authors": "Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大语言模型（MLLMs）在视觉理解和数学推理等领域取得了显著进展，但在医学领域的应用受到两个关键挑战的限制：（1）医疗领域的多模态数据稀缺，且通常包含稀疏信息，限制了推理深度；（2）尽管在一般领域中强化学习带有可验证奖励（RLVR）很有效，但在医疗领域却不能稳定提升模型性能。", "innovation": "本文通过监督微调（SFT）阶段引入高质文本推理数据和通用多模态数据，与多模态医学数据相结合，提高了基础的医疗能力并恢复了基模型的推理能力。同时，针对数据稀疏问题，提出了注入反映模式的思考链（CoT）与通用CoT样本相结合的方法，为后续的RLVR训练提供了结构化基础。最终，作者提出了InfiMed系列模型InfiMed-SFT-3B和InfiMed-RL-3B，在七个跨界医学基准测试中达到了先进的性能。特别是在强化学习阶段，InfiMed-RL-3B实现了59.2%的平均准确率，优于更大模型如InternVL3-8B的57.3%。", "conclusion": "这两种策略在SFT和RLVR阶段的表现证明了其有效性。一系列广泛的实验也提供了关于提升医学场景中MLLM性能的重要见解。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02863", "html_url": "https://arxiv.org/abs/2506.02863", "title": "CapSpeech：为风格注释文本到语音的下游应用提供支持", "title_en": "CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech", "authors": "Helin Wang,Jiarui Hai,Dading Chong,Karan Thakkar,Tiantian Feng,Dongchao Yang,Junhyeok Lee,Thomas Thebaud,Laureano Moro Velazquez,Jesus Villalba,Zengyi Qin,Shrikanth Narayanan,Mounya Elhiali,Najim Dehak", "background": "近年来，生成型人工智能显著改变了风格注释文本到语音合成（CapTTS）领域的面貌。然而，要将CapTTS应用到实际场景中，仍面临两大挑战：缺乏标准化和全面的数据集，以及围绕CapTTS的相关下游任务研究不足。此前，由于数据集不够标准和全面，且对CapTTS下游任务的研究有限，导致CapTTS在实际应用中存在不少问题和限制。", "innovation": "为解决上述问题，本文引入了CapSpeech基准，包含一系列与CapTTS相关的任务，如带有声效的风格注释文本到语音合成（CapTTS-SE）、带有语调的文本到语音合成（AccCapTTS）、带有情感的文本到语音合成（EmoCapTTS）、聊天代理的文本到语音合成（AgentTTS）。CapSpeech涵盖了超过1000万台标注音频-图例对和将近36万个人标注的音频-图例对。此外，作者还收集并录制了两个新数据集，用于专门的AgentTTS和CapTTS-SE任务。实验使用自回归和非自回归模型在CapSpeech上进行，结果显示，CapSpeech能够产生高质量且高度可理解的语音合成结果。CapSpeech是现有最大的CapTTS相关任务数据集，同时提供了关于CapTTS系统开发的重要见解和挑战分析。", "conclusion": "CapSpeech将成为评估和开发CapTTS系统的有力工具，对推进该领域的实际应用具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16975", "html_url": "https://arxiv.org/abs/2506.16975", "title": "基于转换器的语言模型中的潜在概念分解", "title_en": "Latent Concept Disentanglement in Transformer-based Language Models", "authors": "Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy", "background": "当大型语言模型（LLMs）使用上下文学习（ICL）解决新任务时，它们必须从演示示例中推断潜在概念。这引发了一个问题：过渡器如何在计算过程中表示潜在结构。本文通过几个控制任务，利用机制可解释性来研究这个问题。", "innovation": "本文展示了在翻译推理任务中，模型能够识别潜在概念并进行概念逐步组合。此外，通过研究由潜在数值概念参数化的任务，发现模型表示空间中的低维子空间，该子空间的几何形状清晰地反映了潜在参数化。研究还表明，小规模和大规模模型都可以从少量简化的演示示例中分离和利用学到的潜在概念。", "conclusion": "综上所述，本文通过实验和机制可解释性方法，证实了转换器基模型能够识别、组合和从少量示例中使用潜在概念，这为理解模型背后的学习机制提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01042", "html_url": "https://arxiv.org/abs/2506.01042", "title": "探究大型语言模型的神经拓扑结构", "title_en": "Probing Neural Topology of Large Language Models", "authors": "Yu Zheng,Yuan Yuan,Yue Zhuo,Yong Li,Paolo Santi", "background": "通过将神经激活与可解释的语义联系起来，对大型语言模型（LLMs）进行探查揭示了它们内部机制的重要见解，然而，将神经元功能共激活与新兴模型能力之间的复杂机制仍然不清楚，这阻碍了对LLMs的深入理解和安全开发。为此，该研究通过提出图探查方法来发现LLM神经元的功能连接并将其与语言生成性能相关联。实验结果表明，仅使用神经拓扑结构就能预测下一个标记的预测性能，即使保留1%的神经连接也保持了这种普遍的可预测性。这种拓扑结构探究在性能上比激活探究高出130.4%，表明神经拓扑结构包含比神经激活更丰富的信息，这些信息可以通过简单的线性或MLP探针轻松提取。", "innovation": "提出了一种图探查方法，该方法用于发现LLM神经元的功能连接并将其与语言生成性能相关联。实验发现，仅使用神经拓扑结构就能预测下一个标记的预测性能，并且即使只保留1%的神经连接也保持这一特性。该方法表明神经拓扑结构可能比神经激活包含更丰富的信息，这些信息可以通过简单的线性或MLP探针轻松提取。进一步的分析表明，神经拓扑结构可以被有效利用以提高LLM模型的效率、可靠性和安全性，应用于模型剪枝、幻觉检测和LLM指纹识别中。还提供了因果证据展示LLM实际上利用了这些拓扑信息。", "conclusion": "研究表明神经拓扑结构可以用于提高LLMs的效率、可靠性和安全性，通过图探查方法揭示了神经元的功能连接与其语言生成性能之间的关系，发现即使保留1%的神经连接，也可以有效地预测模型性能。这些发现表明神经拓扑结构可能比神经激活包含更丰富的信息，并可以被简单地提取用于提高LLM模型的各项特性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05667", "html_url": "https://arxiv.org/abs/2506.05667", "title": "DriveAction：探索VLA模型中的人类驾驶决策基准", "title_en": "DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models", "authors": "Yuhan Hao,Zhengning Li,Lei Sun,Weilong Wang,Naixin Yi,Sheng Song,Caihong Qin,Mofan Zhou,Yifei Zhan,Xianpeng Lang", "background": "现有的视觉-语言-行动（VLA）模型在推动自动驾驶方面取得了进展，但现有的基准测试仍缺乏场景多样性、可靠的动作级注释以及与人类偏好相一致的评估协议。", "innovation": "DriveAction是首个针对VLA模型的动作驱动基准测试，包含2610个驾驶场景生成的16185对问答对，该基准测试利用了真实世界驾驶数据，确保了广泛且代表性的场景覆盖，并提供了直接来源于实际驾驶操作的高级离散动作标签，还实施了一种以动作为基础的树状结构评估框架，明确链接了视觉、语言和行动任务，支持全面和任务特定的评估。研究表明，最先进的视觉-语言模型（VLMs）在准确预测行动时需要视觉和语言的双重指导，缺少任何一种都会显著降低准确性。", "conclusion": "我们的评估能够精确识别模型瓶颈，结果是稳健一致的，为改进自动驾驶中的类人决策提供了新的见解和坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12037", "html_url": "https://arxiv.org/abs/2506.12037", "title": "利用块坐标下降法进行经济高效的大语言模型训练", "title_en": "Exploiting Block Coordinate Descent for Cost-Effective LLM Model Training", "authors": "Zeyu Liu,Yan Li,Yunquan Zhang,Boyang Zhang,Guoyong Jiang,Xin Zhang,Limin Xiao,Weifeng Zhang,Daning Cheng", "background": "训练大型语言模型通常需要大量的GPU内存和显著的财务投入，这对许多中小型团队构成了障碍。", "innovation": "本文提出了一种基于块坐标下降（BCD）的全参数预训练和微调框架，并通过工程优化增强，能够在成本效益高的RTX 4090、A100和A800 GPU集群上实现大型模型的有效训练。与标准全参数训练相比，此方法在相同硬件配置下将7B模型的训练成本降低了33%（在A100/A800上）和2.6%（在RTX 4090上），并且也使过去只能在A100集群上训练的大模型能够在RTX 4090上训练而不降低性能。", "conclusion": "BCD在大多数情况下达到了与全参数和微调方法相当或更好的准确性，同时降低了GPU消耗并提高了硬件利用率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06958", "html_url": "https://arxiv.org/abs/2506.06958", "title": "模拟社会需要模拟思想", "title_en": "Position: Simulating Society Requires Simulating Thought", "authors": "Chance Jiajie Li,Jiayi Wu,Zhenze Mo,Ao Qu,Yuhan Tang,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Jinhua Zhao,Paul Liang,Luis Alonso,Kent Larson", "background": "大型语言模型（LLMs）能生成令人信服的行为，但还需具备认知基础的、结构化的、可修订的和可追溯的推理能力。目前，LLM基于的代理越来越多地用于模拟个体和群体行为，通过提示和监督微调进行。然而，这些代理通常缺乏内在一致性、因果推理和信念追溯能力，使其在模拟人类如何推理、审议和应对干预方面不可靠。", "innovation": "本文提出了一种概念建模范式，称为Generative Minds（GenMinds），该范式借鉴了认知科学，支持生成代理的结构化信念表示。此外，还引入了RECAP（REconstructing CAusal Paths）框架作为基准测试，旨在通过因果追溯、人口统计学基础和干预一致性评估推理的准确性。这些贡献推动了从表面模仿到生成代理模拟思维（不仅仅是语言）的更广泛转变，以用于社会模拟。", "conclusion": "本文的贡献促进了社会模拟从表面模仿到基于生成代理的思维模拟的转变，不仅模仿语言，还模拟人类如何进行推理和回应干预。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11022", "html_url": "https://arxiv.org/abs/2506.11022", "title": "逐代AI代码生成中的安全性退化——预防悖论的系统分析", "title_en": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "authors": "Shivani Shukla,Himanshu Joshi,Romilla Syed", "background": "大语言模型（LLMs）被快速应用于代码生成，改变了软件开发的方式。然而，研究较少关注迭代LLM反馈中安全漏洞如何演变。本研究通过控制实验，分析了400个代码样本在40轮“改进”中的安全退化情况，使用四种不同的提示策略。结果显示，仅五次迭代之后，关键漏洞就增加了37.6%，不同提示方法之间出现了不同的漏洞模式。这项研究表明，迭代LLM改进未必能够提升代码安全性，强调了在LLM循环中融入人类专业知识的重要性。", "innovation": "本研究通过系统实验分析了AI生成代码在多轮迭代中安全性的变化，揭示了不同提示方法下的独特漏洞模式，并挑战了原有的安全假设，提出了开发者防范风险的实用指南，强调了在LLM迭代过程中进行稳健的人工验证的重要性。", "conclusion": "本研究通过实验指出，多次迭代后，AI生成的代码中关键安全漏洞显著增加，不同提示策略导致的漏洞模式也有所不同，挑战了传统上认为迭代可以使代码更安全的观点。研究提出，应加强在LLM迭代过程中的人工验证，以防止因代码“优化”引入新的安全问题，从而确保代码安全。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05980", "html_url": "https://arxiv.org/abs/2506.05980", "title": "AMPED: 自适应多目标投影以平衡探索与技能多样化", "title_en": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification", "authors": "Geonwoo Cho,Jaemoon Lee,Jaegyun Im,Subi Lee,Jihwan Lee,Sundong Kim", "background": "技能导向的强化学习（SBRL）通过预训练技能条件化策略，使环境中有稀疏奖励的场景下能够快速适应。有效的技能学习要求同时最大化探索和技能多样化。然而，现有方法在同时优化这两个相互冲突的目标时往往会遇到挑战。这项工作中提出了一个名为Adaptive Multi-objective Projection for balancing Exploration and skill Diversification（AMPED）的新方法，该方法在预训练阶段通过梯度手术投影平衡探索与多样性梯度，在微调阶段通过技能选择器利用学到的多样性选择适合下游任务的技能。", "innovation": "提出了一种名为AMPED的新方法，该方法在预训练阶段通过梯度手术投影平衡探索与多样性梯度，在微调阶段通过技能选择器利用学到的多样性选择适合下游任务的技能。通过广泛的消融研究，确认了每个组件在性能上的贡献，并证明使用贪心技能选择器时，更大的技能多样化可以降低调优样本复杂性。这些结果突显了明确地平衡探索与多样化的必要性，并证明了AMPED在增强鲁棒和泛化技能学习方面的效果。", "conclusion": "AMPED方法实现了跨各种基准超越SBRL基线的表现。通过详尽的消融研究，证明了每个组件在性能上的贡献，并提供了理论和实验证据，证明使用贪心技能选择器时，更大的技能多样化可以降低调优样本复杂性。这些结果突显了明确地平衡探索与多样化的必要性，并证明了AMPED在此方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18862", "html_url": "https://arxiv.org/abs/2506.18862", "title": "TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting", "title_en": "TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting", "authors": "Zhongbin Guo,Yuhao Wang,Ping Jian,Chengzhi Li,Xinyue Chen,Zhen Yang,Ertai E", "background": "卫星图像时间序列（SITS）分析中的时空变化描述（TCD）和未来卫星图像预测（FSIF）是关键任务，但历史上是分开处理的。这两项任务都受到建模长程时间动态能力的限制。本文通过增强模型的长程时间理解能力来同时提升这两种任务的性能", "innovation": "TAMMs首次提出了一个统一框架，能够同时在单一多模态学习和扩散架构中完成TCD和FSIF任务。TAMMs引入了两项创新：时间自适应模块（TAM）增强冻结的多模态学习模型对长程动态的理解能力；语义融合控制注入（SFCI）机制将这种变化理解转化为精细的生成控制。", "conclusion": "广泛的实验表明，TAMMs在两种任务上都显著优于先进的专门baseline模型。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12109", "html_url": "https://arxiv.org/abs/2506.12109", "title": "通过对比个人偏好实现个性化LLM解码", "title_en": "Personalized LLM Decoding via Contrasting Personal Preference", "authors": "Hyungjune Bu,Chanjoo Jung,Minjae Kang,Jaehyung Kim", "background": "随着大型语言模型（LLMs）在各种实际应用中的逐步部署，人们对LLMs的个性化需求日益增长。尽管已经探索了基于提示和基于训练的方法来实现LLM的个性化，但开发有效的解码时间算法仍然被忽视，尽管这类算法展示了极大的潜力。解码时间算法（decoding-time algorithms）在实际应用中起到了重要作用，能够直接在生成过程中优化个性化效果。", "innovation": "本文提出了一种新颖的解码时间个性化方法——CoPe（Contrasting Personal Preference），该方法在对用户特定数据进行参数高效微调（PEFT）后应用。核心思想是利用奖励引导的解码来最大化每个用户的隐式奖励信号，通过这一机制进行个性化处理。CoPe在五个开放式的个性化文本生成任务中得到了评估，实验结果表明，CoPe在ROUGE-L指标上平均提高了10.57%，且无需依赖外部奖励模型或额外训练程序，从而展示了其有效性。", "conclusion": "CoPe方法通过在微调后的解码过程中引入奖励引导机制，在不使用外部奖励模型或额外训练的情况下，实现了显著的个性化提升，证明了解码时间个性化方法的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20893", "html_url": "https://arxiv.org/abs/2506.20893", "title": "为了有效类别遗忘，输出分布重加权的必要性", "title_en": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": "Ali Ebrahimpour-Boroojeny,Yian Wang,Hari Sundaram", "background": "现有类别遗忘评估方法存在一个重要缺陷，即忽视了类别几何结构可能导致隐私泄露。已有研究未充分考虑类别间的几何关系如何影响隐私保护，因此在评估和改进类别遗忘方法时存在不足。", "innovation": "本文提出了一个简单的解决方案来缓解这一问题，即通过最近邻（MIA-NN）进行成员推理攻击，利用模型为临近类别分配的概率来检测未学习样本。为此，本文提出了一种名为Tilted Reweighting（TRW）的新微调目标，通过估计类别间的相似度，并相应调整目标模型的分布，从而在保留原模型大部分性能的同时减少隐私泄露。实验表明，TRW方法在多个基准测试上优于或匹配现有的类别遗忘方法，并显著减少了与重新训练模型之间的性能差距，尤其在U-LiRA和MIA-NN评分上，相较于当前最先进的方法分别减少了19%和46%的差距。", "conclusion": "通过引入MIA-NN攻击和TRW方法，本文有效解决了类别遗忘中的隐私泄露问题，并通过实验证明了该方法的优越性，在多个数据集和基准测试上表现优异，为提升类别遗忘的安全性提供了新的手段。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "超越简单图：多目标多图神经网络路由", "title_en": "Beyond Simple Graphs: Neural Multi-Objective Routing on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的方法在单目标和多目标路由中受到了广泛关注。然而，现有的方法在处理多图路由时并不适用，因为多图包含多个具有不同属性的节点对之间的边，而在实际场景中这种类型的数据结构具有很强的相关性。", "innovation": "本文提出两种基于图神经网络的方法，以解决多图上的多目标路由问题。第一个方法直接在多图上进行自回归选择边，直到完成一条路线。第二个方法首先通过学习得到的剪枝策略简化多图，然后在简化后的简单图上执行自回归路由。该方法在广泛的问题和图分布设置中进行了实验评估，展示了相对于强启发式方法和神经网络基线的竞争力。", "conclusion": "通过这两种方法，本文解决了一个重要的实际问题，即多图上的多目标路由。实验结果表明，所提出的方法与现有方法相比具有竞争力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "使用人工神经网络求解理想MHD等离子体", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "该研究旨在通过使用人工神经网络计算三维MHD平衡，将其与传统求解器进行比较。背景在于现有的MHD平衡计算方法通常耗时较长且复杂，而神经网络方法可能提供一种更高效、成本更低的解决方案。研究者们希望通过这种方法来优化MHD平衡的问题解决方式，并探索其在实际中的应用潜力。", "innovation": "研究提出了通过参数化傅里叶模式的人工神经网络计算三维MHD平衡的新方法，并使用最简单的人工神经网络。研究的创新点在于成功地将人工神经网络应用于MHD平衡计算，且在同等最小残差下，人工神经网络方法的成本已经可以与现有代码相竞争。此外，通过增加计算资源，神经网络方法能够继续优化残差的最小值，这为MHD平衡的计算设定了新的下限。", "conclusion": "研究使用了较为简单的神经网络模型，并验证了这种方法在计算单个MHD平衡和处理一系列连续的MHD平衡分布模型方面的潜力。研究者认为这种方法有潜力提供更快、成本更低的MHD平衡计算方法，并为此类问题的进一步研究和应用奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23508", "html_url": "https://arxiv.org/abs/2506.23508", "title": "为什么强化微调使多媒体大型语言模型更好地保留先验知识：从数据角度分析", "title_en": "Why Reinforcement Fine-Tuning Enables MLLMs Preserve Prior Knowledge Better: A Data Perspective", "authors": "Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Mingqi Wu,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang,Kai Chen", "background": "监督微调（SFT）和强化微调（RFT）等后训练算法广泛应用于将多模态大型语言模型适应下游任务。虽然这些方法在任务适应上非常有效，但它们对先验知识的影响仍然不清楚。本文采用拼图游戏作为新的、在现有预训练语料库中不存在的任务，系统研究了SFT和RFT在开源多模态模型Qwen2.5-VL系列上的行为。实验揭示出一个明显的权衡：SFT能够迅速学习新任务但却会导致灾难性的遗忘，而RFT虽然学习速度较慢，但能够保持原有的先验知识。这些结果表明，训练数据的分布，而不是算法的不同，可能在遗忘过程中起着更重要的作用.", "innovation": "研究通过分析训练数据的大小和方向如何影响先验知识，揭示了RFT主要通过强化与基础模型概率景观自然对齐的正确样本，从而较弱地干扰先验知识的现象。此外，使用RFT模拟的回放进行训练，这些回放对先验知识的干扰较小且方向与先验知识良好对齐，使SFT在快速学习新任务的同时能够更好地保留先验知识。这些发现强调了RFT在多模态大型语言模型稳定持续学习中的潜在作用.", "conclusion": "研究表明，训练数据的分布，而不是算法本身的差异，可能是导致遗忘的主要原因，而且RFT在多模态大型语言模型中稳定连续学习中展现出了潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05257", "html_url": "https://arxiv.org/abs/2507.05257", "title": "通过逐步多轮交互评估大型语言模型代理中的记忆", "title_en": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "authors": "Yuanzhe Hu,Yu Wang,Julian McAuley", "background": "现有的大型语言模型（LLM）代理基准主要关注推理、计划和执行能力的评估，但忽略了记忆这一关键组件，包括代理如何记忆、更新和检索长期信息。这主要是因为缺乏记忆相关基准。我们提出了具有记忆机制的“记忆代理”，并基于记忆科学和认知科学的经典理论，识别了记忆代理的四个核心能力：准确检索、测试时学习、长距离理解、选择性遗忘。当前的基准或受限于有限的上下文长度，或针对如基于图书的问答等静态、长上下文设置，这没有反映记忆代理逐步积累信息的交互、多轮对话特性。现有基准无法全面覆盖上述四个核心能力。因此，我们提出了MemoryAgentBench，这是专门为记忆代理设计的新基准。它通过对现有长上下文数据集的转换和加入新构建的数据集，模拟了记忆代理逐步积累信息的特性，通过精心选择和整理数据集，基准提供了上述四个核心记忆能力的全面覆盖，为系统地评估记忆质量提供了一个具有挑战性的测试平台。", "innovation": "我们提出了MemoryAgentBench，专门为记忆代理设计的新基准。它通过调整现有长上下文数据集并将新构造的数据集整合成多轮对话格式，模拟了记忆代理逐步积累信息的特性。该基准提供了全面覆盖四个关键记忆能力的评估，为系统性、挑战性评估提供了平台，并对全面记忆机制的研究提出了要求。此外，我们也评估了包括基于上下文的记忆代理和具身记忆模块的高级代理等一系列代理能力，实验证明当前方法在四个方面仍需进一步研究以提升整体能力。", "conclusion": "当前方法在四个核心记忆能力上仍有欠缺，强调了进一步研究全面记忆机制对LLM代理的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07032", "html_url": "https://arxiv.org/abs/2507.07032", "title": "轻量级MSA设计提升进化嵌入在蛋白质折叠中的应用", "title_en": "Lightweight MSA Design Advances Protein Folding From Evolutionary Embeddings", "authors": "Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Cesar de la Fuente-Nunez,Chunbin Gu,Ge Liu,Pheng-Ann Heng", "background": "蛋白质结构预测通常依赖于多序列对齐(MSA)，但在低同源性和孤儿蛋白上表现不佳。现有的MSA方法在这些情况下效果较差，这限制了下游折叠任务的性能进步。", "innovation": "文章介绍了一种名为PLAME的轻量级MSA设计框架，该框架利用预训练蛋白质语言模型的进化嵌入来生成更支持下游折叠的MSA。PLAME结合了演化一致性和多样性的损失函数，平衡了保守位点的共识与可能序列变体的覆盖面。此外，还开发了一种基于MSA的选择策略与一种补充深度度量的序列质量指标，预测蛋白质折叠的改进程度。这些创新在AlphaFold2的低同源性/孤儿蛋白基准测试中实现了最先进的结构准确度提升，并与AlphaFold3搭配使用时保持增益。", "conclusion": "PLAME提供了一种实用的方法来为缺乏进化邻居的蛋白质实现高质量的折叠。同时，PLAME还作为轻量级适配器，使ESMFold能够接近AlphaFold2级别的准确性，同时保留ESMFold类似的速度。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08799", "html_url": "https://arxiv.org/abs/2507.08799", "title": "KV 缓存引导：控制冻结的LLM", "title_en": "KV Cache Steering for Controlling Frozen LLMs", "authors": "Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,James R. Glass,Cees G. M. Snoek,Yuki M. Asano", "background": "背景信息介绍了现有技术的局限性，如激活引导技术需要持续干预，存在推理延迟和超参数稳定性的挑战。基于此背景，本文提出了缓存引导方法，旨在通过直接作用于键值缓存的一次性干预来隐式引导语言模型。", "innovation": "创新点在于提出了一种轻量级的缓存引导方法，通过一次性干预直接作用于键值缓存，可以引导小规模语言模型进行多步骤推理，方法是从教师模型或现有的人类注释中构造引导向量，指向更明确的多步骤推理，无需微调或提示修改。相对以往技术，该方法在推理延迟、超参数稳定性和与现有推理API集成方面具有显著优势。并且还能实现可控的推理风格转移，如逐步推理、因果推理和类比推理，提供了行为级别的语言模型指导工具.", "conclusion": "结论指出了缓存引导方法在多个基准测试中的表现，表明其改善了模型推理的质构和定量任务性能，尤其在GPQA和MATH等具有挑战性的数据集上表现出进一步的改进。相较于需要连续干预的先前激活引导技术，一次性缓存引导提供了显著的优势。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03262", "html_url": "https://arxiv.org/abs/2507.03262", "title": "探究多视图编码器下多模态大型语言模型中的冗余", "title_en": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders", "authors": "Yizhou Wang,Song Mao,Yang Chen,Yufan Shen,Yinqiao Yan,Pinlong Cai,Ding Wang,Guohang Yan,Zhi Yu,Xuming Hu,Botian Shi", "background": "最近的多模态大型语言模型越来越多地整合了多种视觉编码器，以在各种基准测试中提高性能，假设不同的预训练目标能够提供互補的视觉信号。然而，该研究通过系统性地对代表性的多编码器MMLMs进行编码器屏蔽，发现在许多情况下这种假设在实践中的效果并不理想，甚至当屏蔽某些编码器时性能可能会提升，表明了编码器的过度冗余性。通过引入两个合理化的度量标准：条件利用率（CUR），用于测量单一编码器在存在其他编码器时的边缘贡献；信息差距（IG），用于捕捉模型内编码器用途的异质性。研究结果在OCR和图表任务中显示出单个编码器的强大特异性，在通用VQA和知识基于的任务中显示出编码器的高度冗余性，以及某些有害编码器的负面贡献。显著的是，屏蔽特定编码器能够在一个特定任务类别中提升超过16％的准确性，并在整体性能上提供3.6％的提升，单编码器和双编码器变体在大多数非OCR任务恢复超过90％的基本性能水平。", "innovation": "通过引入两个度量标准来量化编码器冗余：条件利用率（CUR），衡量单个编码器在存在其他编码器时的贡献；信息差距（IG），捕捉模型内编码器利用率的异质性，并通过系统性地对多模态大型语言模型进行编码器屏蔽来检验编码器的冗余性。这项研究挑战了“越多编码器越好”的假设，并为开发更高效和有效的多模态架构提供了可操作的诊断方法。", "conclusion": "多模态大型语言模型经常整合多种视觉编码器以提高性能，但研究发现这一假设经常不成立，实际中有时屏蔽特定编码器反而能提升性能，这揭示了编码器的过度冗余性。通过条件利用率和信息差距两个度量标准，发现特定任务如OCR和图表高度依赖单个编码器，而通用VQA和知识型任务则显示出编码器的高冗余性，某些编码器可能甚至对模型有负面影响。屏蔽特定编码器可以显著提高特定任务类别和整体性能，单一编码器和双编码器在大多数非OCR任务上也能恢复超过90％的基本性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22168", "html_url": "https://arxiv.org/abs/2507.22168", "title": "基于人物特征增强的基准测试：跨不同文体评估LLMs", "title_en": "Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles", "authors": "Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu", "background": "当前用于评估大型语言模型（LLM）的标准基准往往缺乏写作风格多样性，多数关注标准化规范。这些基准没有全面捕捉到人类展现出的丰富多样的交流模式。因此，优化于这些基准的LLM可能在面对非标准化输入时表现出脆弱的性能。", "innovation": "通过使用基于人物特征的语言模型提示方法重新编写评估提示，该方法成本较低，能够模拟多样的写作风格。研究结果显示，即使语义内容相同，文章风格和提示格式的变化显著影响LLM评估结果。此外，研究发现特定且一致的写作风格会触发不同模型在不同任务中的低或高表现，这不受模型家族、规模和更新时间的影响。这项工作提供了一种可扩展的方法来增强现有基准，提升其对于语言变异条件下评估LLM性能的有效性。", "conclusion": "研究结果显示，尽管具有相同的语义内容，写作风格和提示格式的差异显著影响了评估结果。同时，特定的写作风格在多种模型及任务中产生了稳定一致的低或高表现。此外，提出的方法为改进评估基准提供了可扩展的途径，使其更适用于跨语言变化评估LLM性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05418", "html_url": "https://arxiv.org/abs/2507.05418", "title": "全球学习，本地表达：解决多语言推理的差距", "title_en": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "authors": "Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang", "background": "大型语言模型(LLMs)已经在数学、事实问答和代码生成等领域取得了优异的成绩，但在用不同语言进行推理方面的能力仍需发展。特别是在低资源语言（如斯瓦希里语或泰语）方面，LLMs 往往会误解提示或将推理默认转换为英语，这种对高资源语言的隐性偏见会削弱事实准确性、可解释性和信任。现有的多语言基准测试仅评估最终答案，而忽略了推理是否在目标语言中发生。为解决这些问题，本研究提出了M2A方法，这是一种结合多尺度多语言对齐和基于机器翻译问题的语言一致性奖励的新方法，用于训练模型在目标语言中进行直接和准确的推理。此外，现有的多语言基准测试只关注最终的答案，忽视了推理是否在目标语言中发生。为弥补这一差距，我们引入了GeoFact-X，这是一个基于地理的多语言事实推理基准，包含五种语言（英语、印地语、日语、斯瓦希里语和泰语）的推理过程痕迹。研究表明，M2A 显著提高了多语言推理的准确性，表明意识推理的多语言强化学习对于跨语言泛化的鲁棒性至关重要。", "innovation": "M2A方法结合了多尺度多语言对齐和语言一致性奖励，用于训练模型能够直接且准确地用目标语言进行推理；GeoFact-X是一个基于地理的多语言事实推理基准，包含了五种不同语言的推理过程痕迹，填补了现有多语言基准测试只评估最终答案的空白。", "conclusion": "M2A方法显著提高了多语言推理的准确性，在数学和事实推理任务中表现出色，显示了意识推理在多语言强化学习中的重要性，这对于跨语言泛化的鲁棒性至关重要。GeoFact-X提供了更好的多语言推理评估方式，有助于研发出更符合多语言语境的模型。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01188", "html_url": "https://arxiv.org/abs/2508.01188", "title": "SpectrumWorld: 谱学领域的人工智能基础平台", "title_en": "SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy", "authors": "Zhuo Yang,Jiaqing Xie,Shuaike Shen,Daolang Wang,Yeyun Chen,Ben Gao,Shuzhou Sun,Biqing Qi,Dongzhan Zhou,Lei Bai,Linjiang Chen,Shufei Zhang,Qinying Gu,Jun Jiang,Tianfan Fu,Yuqiang Li", "background": "深度学习在光谱学中的应用前景广阔，但该领域研究和评估往往缺乏标准化的方法体系。", "innovation": "引入了一个前沿的一体化平台SpectrumLab，旨在系统化和加速光谱学中的深度学习研究。该平台包括一个全面的Python库、一个生成高质量基准的创新模块SpectrumAnnotator以及一个多层基准套件SpectrumBench。", "conclusion": "通过SpectrumBench上18种最新跨模态LLM的详尽实证研究揭示了当前方法的关键局限性，希望SpectrumLab成为未来深度学习驱动光谱学发展的关键基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13681", "html_url": "https://arxiv.org/abs/2507.13681", "title": "LoopServe：多轮对话中面向大规模语言模型的自适应双阶段推理加速系统", "title_en": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues", "authors": "Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan", "background": "在许多现实生活应用中，多轮对话对大型语言模型至关重要，例如聊天机器人和虚拟助手。随着对话历史的变长，现有的大型语言模型面临着日益增加的计算和内存挑战，这阻碍了它们提供高效和响应迅速的交互能力。目前的加速方法要么压缩上下文，要么优化关键值缓存，但这些方法往往依赖于固定或位置基的启发式方法，对于实际的多轮对话中动态和不可预测的模式适应性较差。因此，这些模型无法准确识别并优先处理最具相关性的上下文，导致响应质量下降。", "innovation": "LoopServe是一个为多轮对话中的大型语言模型设计的自适应双阶段推理加速框架。主要创新包括：1. 在准备填充阶段进行在线稀疏化，通过动态选择每次新输入中最重要的部分来操作注意力矩阵；2. 在解码过程中使用渐进式的关键值压缩，根据最近生成的输出令牌适当地保持相关的且高效的缓存。此外，还提出了一个新的基准，包括11个多轮对话数据集，以反映现实查询位置和对话依赖性。", "conclusion": "大量的实验表明，LoopServe在多轮对话任务的广泛长上下文情境中，能够持续地优于现有的基准，并显著加速大型语言模型的推理。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13019", "html_url": "https://arxiv.org/abs/2507.13019", "title": "重新审视视觉语言导航中的实体鸿沟：全面研究物理与视觉差异", "title_en": "Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities", "authors": "Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang", "background": "最近的视觉语言导航（VLN）取得了显著进展，但它们对机器人移动和控制的理想化假设无法反映实际应用场景中的挑战。VLN-PE 提出了一个物理上现实的 VLN 平台，支持类人型、四足和轮式机器人，旨在解决这一差距。它系统地评估了几种自填式 VLN 方法在物理机器人设置中的表现，包括单步离散动作分类模型、密集航点预测的扩散模型，以及无需训练、基于地图的大型语言模型（LLM）与路径规划集成。这些研究揭示了由于观测范围有限、光照变化以及碰撞和跌落等物理挑战造成的性能下降。此外，它还指出腿足机器人在复杂环境中移动的限制。VLN-PE 非常具有扩展性，可以无缝整合新场景，从而实现更加全面的 VLN 评估。尽管目前的模型在物理部署中的泛化能力较弱，但 VLN-PE 为提高跨实体的总体适应性提供了新的途径。", "innovation": "VLN-PE 提出了一个物理上现实的 VLN 平台，支持不同类型的机器人，系统地评估了几种自填式 VLN 方法，包括分类模型、扩散模型和大型语言模型与路径规划的集成。此举能够揭示物理挑战对机器人性能的影响，强调了腿足机器人在复杂环境中的移动限制，提供了评估 VLN 总体适应性的新途径，推动了 VLN 模型的实用性和鲁棒性改进。此外，VLN-PE 允许无缝集成新场景，增强了 VLN 评价的全面性。", "conclusion": "当前 VLN 模型在物理部署中的泛化能力较弱，但 VLN-PE 提供了改进跨实体总体适应性的新途径，旨在推动更多实用和鲁棒的 VLN 模型的发展。研究结果和工具希望可以激励社区重新思考 VLN 的局限性，并进一步推动 VLN。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14270", "html_url": "https://arxiv.org/abs/2507.14270", "title": "APTx Neuron: 集成激活与计算的统一可训练神经元架构", "title_en": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "authors": "Ravin Kumar", "background": "现有的神经网络通常需要分别使用非线性激活函数层和线性变换层，导致网络结构复杂且计算效率较低。先前的研究试图减少这种复杂性，但往往无法同时达到高性能和高效计算的目标.", "innovation": "本文提出了APTx Neuron，这是一种新颖的统一神经计算单元，将非线性激活和线性变换集成到一个可训练表达式中，从而去掉单独的激活层，简化了架构设计，提高了效率。APTx Neuron使用了一个可训练的参数表达式 $y = \text{sum}\big(\big((\text{alpha}_i + \tanh(\text{beta}_i x_i)) \times \text{gamma}_i x_i\big) + \text{delta}\big)$ 并改进了传统神经元的表达性和计算效率.", "conclusion": "实验结果表明，基于APTx Neuron的架构在MNIST数据集上达到了高达96.69%的测试准确率，使用了约332,000个可训练参数，在11个周期内实现。这展示了APTx Neuron相比于传统神经元的优越表达性和计算效率，指向了一个新的统一神经元设计和相关架构的新范式."}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17307", "html_url": "https://arxiv.org/abs/2507.17307", "title": "R-Stitch: 动态轨迹缝合以实现高效推理", "title_en": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "authors": "Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang", "background": "长序列链式思维（CoT）增强了解决问题的能力，但因长自回归路径导致了显著的推理成本。现有加速策略要么通过提前停止或压缩缩短路径长度，要么采用猜测解码以较小模型替代。然而，猜测解码在模型意见不一致时效果有限，并且严格要求在令牌级别上的一致性，忽略了较小模型在正确时会产生更加简练的推理路径可能减少推理长度的现象。", "innovation": "R-Stitch 是一种无需训练的混合解码框架，利用令牌级熵作为不确定性代理来在小型语言模型（SLM）和大型语言模型（LLM）之间分配计算。该方法通过高熵令牌更容易导致错误的观察，提出了一种基于熵的路由策略，使得SLM可以高效处理低熵令牌并将其具有不确定性的令牌委托给LLM，从而避免了完整回滚并保留了答案质量。R-Stitch+进一步学习了具备自适应路由策略的动态令牌预算策略，能够在固定阈值之外进行动态调整。通过联合减少每个令牌的解码复杂性和生成令牌的数量，该方法实现了显著的加速，几乎没有任何准确度损失。具体而言，它在不同模型上分别实现了3.00倍、3.85倍和4.10倍的加速，同时保持了与完整LLM解码相当的准确性，并能够适应不同的计算预算实现自适应效率-准确度权衡，无需重新训练模型。", "conclusion": "通过共同努力减少每个令牌的解码复杂度和生成令牌的数量，R-Stitch 和 R-Stitch+ 达到了显著的加速，同时保持了与完整大型语言模型解码相当的准确性。该方法还允许用户根据不同的计算预算实现自适应的效率-准确度权衡，而无需重新训练模型。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14843", "html_url": "https://arxiv.org/abs/2507.14843", "title": "无形的束缚：为什么RLVR或许可能或不可能摆脱其起源", "title_en": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin", "authors": "Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi", "background": "最近能够在自然语言处理（LLMs）方面取得进展，研究表明强化学习与价值训练（RLVR）方法能够在增强AI解决复杂逻辑任务的能力方面发挥重要作用。然而，目前关于RLVR是否真正扩展了模型的推理边界尚不清楚，还是仅仅增强了模型已经知道的高回报输出的精确度。这项研究通过实证分析提供了关于当前RLVR常用实践潜在限制的新见解。分析在现有训练条件下，RLVR如何作为支持约束的优化机制，限制了发现完全新颖解决方案的可能性。此外，研究还发现在当前RLVR配方中，虽然提高了精确度，但也可能逐渐限制了探索空间，从而忽视了一些正确但未充分呈现的解决方案。", "innovation": "这项研究通过实证分析来探讨当前RLVR常规实践的潜在限制。分析了在现有训练条件下，RLVR如何作为支持约束的优化机制，可能会限制发现完全新颖解决方案，而这些解决方案受限于基础模型的初始分布。研究还发现了一个熵-奖励权衡：尽管当前RLVR配方能可靠地提高精确度，但也可能逐渐缩小探索空间，导致正确但未充分呈现的解决方案被忽视。进一步的实验验证了，尽管当前RLVR配方不断改进pass@1性能，但随着样本预算的增加，经验支持的减少通常超过了经验支持的增加，没有恢复基础模型原来可以访问的正确答案。有趣的是，研究还发现虽然RLVR有时增加令牌级的熵，每一步生成不确定性增大，但答案级的熵却在减小，这似乎不确定的路径最终收敛到了更小的一系列独特答案上。", "conclusion": "综上所述，这些发现揭示了当前RLVR配方在扩展推理边界的潜在限制。未来可能需要算法创新，如明确的探索机制或混合策略来填充未充分体现的解决方案区域，以打破这种无形的束缚。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01522", "html_url": "https://arxiv.org/abs/2508.01522", "title": "使用多智能体强化学习的分布式缆索悬挂负载空中操控", "title_en": "Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning", "authors": "Jack Zeng,Andreu Matoses Gimenez,Eugene Vinitsky,Javier Alonso-Mora,Sihao Sun", "background": "本文介绍了首个用于现实环境中多旋翼无人机（MAVs）团队协作，实现缆索悬挂负载6-自由度操作的分布式方法。现有技术主要依赖于中心化的控制策略和逐帧获取全局状态信息的方法，但本文方法通过多智能体强化学习（MARL）来进行控制策略的学习，无需全局状态信息、智能体间通讯或邻近智能体信息，而是通过负载姿态观测进行隐式通讯，从而提高系统的可扩展性和灵活性，在推理阶段显著降低计算成本，实现策略的机载部署。", "innovation": "该方法利用多智能体强化学习来训练每个MAV的外部控制策略。与现有技术不同的是，该策略不要求全局状态信息、智能体间通信或邻近智能体信息，而是通过负载姿态观测进行隐式沟通。这种方法还显著减少了推理时的计算成本，使策略可以在机载上部署。此外，作者还介绍了一种新的MAV动作空间设计，结合了鲁棒的低层控制器，使仿真到现实的转移即使在动态3D运动中受到缆绳张力引起的显著不确定性影响也能可靠进行。", "conclusion": "本文通过各种现实世界的实验验证了该方法的有效性，包括在负载模型不确定性下的完整姿态控制，性能与最先进的中心化方法相当。实验还展示了具有不同控制策略的智能体之间的协调合作能力，以及在MAV完全空中失效时的鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00017", "html_url": "https://arxiv.org/abs/2508.00017", "title": "生成逻辑：一种用于确定性推理和知识生成的新计算机架构", "title_en": "Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation", "authors": "Nikolai Sergeev", "background": "该论文引入了一种名为生成逻辑（GL）的确定性架构，该架构以用户的先验定义（以及可选的一组简化事实用于构造反例）为基础，使用简约的数学编程语言（MPL）进行描述。GL侧重于从用户给出的定义和事实出发，通过系统地探索其演绎邻域来进行推理和证明。通过这种方法，GL能够从基础原理开始，生成和验证重要的算术定律，如加法和乘法的交换律和结合律，以及分配律，并实现了可回放和可审计的证明跟踪。", "innovation": "GL的主要创新在于它提供了一种从用户定义和传统数学公理（如Peano公理）出发，进行自动推理和生成可再现证明的确定性架构。具体而言，其技术创新包括：1. 使用一种高度概括的数学编程语言（MPL）进行推理定义；2. 通过分布式逻辑单元（LBs）网络进行信息交互来实现演绎推理；3. 生成具有完全追溯性的、可回滚和可审计的证明图；4. 在保持确定性和可验证性的前提下，实现快速推理（几秒钟内即可解决证明问题），并在五分钟内完成完整流程；5. 开发工具支持从基础原理自动化推导重要的算术定律并用HTML呈现证明过程。此外，GL展示了与概率模型集成的潜力以实现自动生成形式化证明并提供新猜想的前景。", "conclusion": "GL论文展示了使用计算机架构自动生成逻辑推理论证，并且从Peano公理出发证明了基础算术定律的有效性。论文还提供了基于Python、C++和MPL代码的实现方法以及生成的所有证明文件，并讨论了进一步硬件和软件协同设计的可能性，特别是在与大型语言模型集成方面的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08524", "html_url": "https://arxiv.org/abs/2508.08524", "title": "StreetReaderAI：使用上下文感知多重模态AI使街景导航无障碍", "title_en": "StreetReaderAI: Making Street View Accessible Using Context-Aware Multimodal AI", "authors": "Jon E. Froehlich,Alexander Fiannaca,Nimer Jaber,Victor Tsaran,Shaun Kane", "background": "现有的交互式街道景观地图工具，如Google Street View (GSV) 和 Meta Mapillary，尽管能够给用户提供沉浸式的360°实景影像导航体验，但对于盲人用户来说仍然难以访问。", "innovation": "StreetReaderAI 是首个为盲人用户设计的无障碍街景工具，结合了上下文感知的多重模态AI、无障碍导航控制以及对话式语音，允许盲人用户虚拟地探索目的地、进行开放式世界探索或在GSV部署的220多亿张图像和100多个国家进行虚拟旅游。通过与混合视觉能力团队的迭代设计和已有11名盲人用户的测试，StreetReaderAI 展现了其在POI调查和支持远程路线规划方面的价值。", "conclusion": "StreetReaderAI 的测试结果表明了无障碍街景导航工具的重要性。作者总结了未来工作的关键指导原则。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06477", "html_url": "https://arxiv.org/abs/2508.06477", "title": "最大 caliber 模型在临界状态中涌现出直觉", "title_en": "Intuition emerges in Maximum Caliber models at criticality", "authors": "Lluís Arola-Fernández", "background": "该研究关注大预测模型是否仅仅重复训练数据，或者能否产生真正的见解，这一现象缺乏物理上的解释。研究选择通过学习机制中的平衡状态来探讨直觉的涌现，即在学习过程中，下一词预测与未来路径熵之间的一种关键平衡。", "innovation": "该工作发现了一种直觉机制，通过‘mind-tuning’方法，即施加温度参数λ的最小原则来确保预测模型使用最大 caliber。训练在确定性迷宫中的随机游走揭示了一个丰富的相图：模仿（低λ）、破规则幻觉（高λ），以及展示强烈程序依赖性和多稳态的脆弱中区，这一中区显示模型自主发现新的目标导向策略。", "conclusion": "研究结果可以用有效的低维理论来概括，直觉被视为在一词记忆现有状态和对可能状态的思考之间的一种临界平衡的涌现特性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04349", "html_url": "https://arxiv.org/abs/2508.04349", "title": "GTPO和GRPO-S：通过策略熵进行的令牌级和序列级奖励塑造", "title_en": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy", "authors": "Hongze Tan,Jianfei Pan,Jinghao Lin,Tao Chen,Zhihang Zheng,Zhihao Tang,Haihua Yang", "background": "当前的强化学习（RL）算法通常采用粗粒度的奖励分配方式，对序列中的所有词元施以统一的奖励，这在长链推理任务中是一个重要的缺点。本文旨在解决这一问题，介绍了动态熵加权机制，包括新的Group Token Policy Optimization (GTPO)算法和Sequence-Level GRPO (GRPO-S)算法，以实现更精细的奖励分配。", "innovation": "提出了动态熵加权机制，通过Gate Token Policy Optimization (GTPO)算法和Sequence-Level GRPO (GRPO-S)算法，对每个词元应用熵加权奖励，重用策略熵作为学习信号，实现了真正在令牌级别的奖励分配。这种方法假设推理路径中的高策略熵是一个认知努力的重要启发式指标，这一机制是性能提升的关键驱动因素。", "conclusion": "实验结果表明，本文的方法在挑战性的推理基准测试中显著优于强大的DAPO基线，验证了动态熵加权机制的有效性，是性能提升的主要驱动因素。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "DAMR：LLM引导的MCTS支持高效且适应性强的概念图问题回答", "title_en": "DAMR: Efficient and Adaptive Context-Aware Knowledge Graph Question Answering with LLM-Guided MCTS", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Chao Wang,Nan Yin", "background": "知识图谱问答（KGQA）旨在通过利用知识图谱的关系和语义结构来解释自然语言查询并执行结构化推理以获取准确的答案。现有方法主要遵循检索-推理范式，依赖图神经网络或启发式规则提取静态候选路径，或者利用LLM增强提示的方法进行检索和推理的联合处理。然而，前者因静态路径提取和缺乏上下文细化而缺乏适应性，后者因依赖固定评分函数和重复LLM调用而计算成本高且评估准确性低。\n现有方法存在的主要问题是：检索-推理范式缺乏适应性，依赖固定路径提取而没有上下文细化；LLM增强范式依赖固定的评估函数和频繁调用LLM，导致计算成本高和准确性较低。", "innovation": "本文提出了DAMR（动态适应MCTS推理），一种结合LLM引导的蒙特卡洛树搜索（MCTS）与自适应路径评估的新型框架，以实现高效且上下文感知的KGQA。DAMR利用MCTS作为基础模型，LLM计划者在每个扩展步骤中选择排名前k的语义相关关系，有效减少搜索空间。为了提高评估准确性，引入了一个轻量级的Transformer评分器，通过交叉注意力同时编码问题和关系序列，以捕捉多跳推理中的细微语义变化。为了缓解高质量监督稀缺的问题，DAMR引入了动态伪路径细化机制，定期从搜索过程中探索的部分路径生成训练信号，使得评分器能够持续适应推理路径分布的变化。", "conclusion": "在多个KGQA基准测试上进行的广泛实验表明，DAMR在性能上显著优于最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21591", "html_url": "https://arxiv.org/abs/2507.21591", "title": "层次图神经网络在压缩语音隐写分析中的应用", "title_en": "Hierarchical Graph Neural Network for Compressed Speech Steganalysis", "authors": "Mustapha Hemis,Hamza Kheddar,Mohamed Chahine Ghanem,Bachir Boudraa", "background": "传统的基于深度学习的隐写分析方法在计算复杂性和跨不同数据集泛化方面存在问题。将图神经网络（GNN）引入隐写分析方案中，可以利用关系数据提高检测准确性和适应性。该论文首次将图神经网络的GraphSAGE架构应用于VoIP压缩语音的隐写分析，通过简单的图构建技术从VoIP流中提取信息，并使用GraphSAGE捕捉细节和高级模式，以实现高检测准确率。实验结果显示，在VoIP信号中检测基于量化索引调制（QIM）的隐写图案时，该方法表现良好，即使对于短短0.5秒的样本，检测准确率也超过了98%，而且在低嵌入率的困难条件下，准确率达到95.17%，优于现有最优方法2.8%。此外，方法的效率也非常高，检测0.5秒样本的平均时间为0.016秒，比之前的方法快0.003秒，这使得它在在线隐写分析任务中具有更高的检测准确率和效率的平衡，特别是在短样本和低嵌入率的限制下。", "innovation": "首次将图神经网络的GraphSAGE架构应用于VoIP压缩语音的隐写分析，通过简单的图构建技术从VoIP流中提取信息，并使用GraphSAGE捕捉细节和高级模式，从而实现高检测准确率。相比现有最优方法，该方法在低嵌入率的困难条件下，检测准确率提升了2.8%。此外，该模型的效率也非常高，检测0.5秒样本的平均时间仅为0.016秒，比之前的方法快0.003秒，这使得它在在线隐写分析任务中具有更高的检测准确率和效率的平衡。", "conclusion": "该方法在VoIP信号中检测基于量化索引调制（QIM）的隐写图案时表现出色，检测准确率超过98%，且在困难条件下（低嵌入率）准确率达到95.17%，优于现有最优方法2.8%。此外，模型的效率也非常高，检测0.5秒样本的平均时间为0.016秒，这使它非常适合在线隐写分析任务，提供了一种在短样本和低嵌入率限制下的检测准确率和效率之间的良好平衡。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03860", "html_url": "https://arxiv.org/abs/2508.03860", "title": "从幻觉到真实：大规模语言模型事实核查与事实性评估的综述", "title_en": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "authors": "Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam", "background": "大规模语言模型（LLMs）在训练过程中会接收到大量多样且复杂的数据，其中可能包括不准确或误导性内容。这些语言模型生成的内容可能会传播错误信息，因此需要进行坚实的事实核查。这项综述系统性地分析了LLM生成内容在事实准确性方面的评估方法，探讨了幻觉、数据集局限性和评估指标可靠性等关键挑战。研究强调了应构建包含高级提示策略、领域特定微调和检索增强生成（RAG）方法的事实检查框架的重要性。该综述从2020年到2025年回顾了相关文献，重点关注评估方法和缓解技术。", "innovation": "提出了五个指导研究分析的最新研究问题，特别关注评估方法和缓解技术。综述还回顾了指令微调、多智能体推理以及外部知识访问的RAG框架。研究结果显示当前的评估指标存在局限性，强调需要验证的外部证据的重要性，并通过领域特定定制提高事实一致性。此外，该研究强调了构建更准确、易懂和上下文感知的事实检查框架的重要性。这些见解促进了更加可信模型的研究发展。", "conclusion": "综述强调了构建更加准确、易懂且上下文感知的事实核查框架的重要性。这些洞察力对于推动更加可信模型的研究进展具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06588", "html_url": "https://arxiv.org/abs/2508.06588", "title": "图是自然的正则化：重新审视图表示学习中的向量量化", "title_en": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning", "authors": "Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang", "background": "向量量化（VQ）最近被证明是学习图结构数据离散表示的一种有希望的方法。然而，一个基本问题，即码本崩溃，在图领域下仍未得到充分探索，严重限制了图的表示能力和泛化能力。已有研究通常忽视了这一问题，并未充分探讨其发生的原因和影响。", "innovation": "本文首次实证研究表明，当将VQ应用于图数据时，即使采用了视觉或语言领域提出的缓解策略，码本崩溃仍然会一致地发生。作者通过理论分析确定了两个关键因素：图特征和结构模式引起的早期分配不平衡，以及确定性VQ中的自增强优化循环。为此，作者提出了RGVQ（基于图结构的向量量化）框架，将图拓扑和特征相似性作为显式的正则化信号来增强码本的利用和促进令牌的多样性。RGVQ通过Gumbel-Softmax重新参数化引入软分配，并加入结构感知对比正则化以惩罚不相似节点对中的令牌共分配。实验结果证实，RGVQ能够显著提高码本利用并提升最先进图VQ框架在多个下游任务中的表现，从而提供更具有表达性和可迁移性的图令牌表示。", "conclusion": "RGVQ框架通过引入图拓扑和特征相似性作为正则化信号，提升码本的利用效率和令牌多样性，从而解决了图向量量化中的码本崩溃问题，提高了图向量量化模型在多种下游任务中的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02097", "html_url": "https://arxiv.org/abs/2509.02097", "title": "JudgeAgent: 使用Agent作为面试官的知识导向和动态大语言模型评估", "title_en": "JudgeAgent: Knowledge-wise and Dynamic LLM Evaluation with Agent-as-Interviewer", "authors": "Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Jian Guo,Yuanzhuo Wang", "background": "当前大语言模型（LLMs）的评估范式存在过度评估或偏颇的评估以及问题难度不匹配的问题，导致知识和能力边界评估不完整，阻碍了其有效应用和优化。", "innovation": "提出了一种基于LLM代理的动态评估范式（Agent-as-Interviewer），利用代理进行多轮互动评估，并通过动态多轮问题生成获取更广泛和深入的知识，以实现对LLM知识边界更全面的评估。同时利用代理规划查询策略，调整问题难度级别，增强难度控制，以匹配目标LLM的实际能力。", "conclusion": "通过基于此范式的判别代理（JudgeAgent）知识导向的动态评估框架，实现了利用知识驱动的合成作为代理工具，并通过难度评分作为策略指导，最终提供有价值的建议，帮助目标优化。广泛实验验证了判别代理建议的有效性，表明代理作为面试官可以准确识别目标模型的知识和能力边界。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17550", "html_url": "https://arxiv.org/abs/2508.17550", "title": "固定权重Transformer中的上下文内算法模拟", "title_en": "In-Context Algorithm Emulation in Fixed-Weight Transformers", "authors": "Jerry Yao-Chieh Hu,Hude Liu,Jennifer Yuntong Zhang,Han Liu", "background": "研究表明，最小的Transformer通过上下文提示可以模拟一系列算法。本文通过两种模式的形式化定义，深入探讨了这一现象。在任务特定模式下，可以证明存在一个单一头部的softmax注意力层，其前向传播可以精确重现形式为f(w^T x - y)的连续函数。而在提示编程模式下，证明了一个单一的固定权重两层softmax注意力模块，可以通过提示模仿所有任务特定类别的算法。", "innovation": "本文的创新点在于提出了任务特定模式下的参数编码提示方法，使得固定权重的Transformer能够精确重现连续函数。同时，提出了一种新的提示编程模式，即仅通过提示就能模仿所有可以通过单层softmax注意力实现的算法。此外，这项研究揭示了大容量Transformer作为提示编程算法库的可能性，以及这种机制下的算法通用性。", "conclusion": "这些发现直接建立了上下文学习与算法模拟之间的联系，提供了一种简单机制，通过提示使大型Transformer发挥算法库的作用。研究还揭示了类似GPT的基础模型可能仅通过提示实现算法互换的方式，并在现代Transformer模型中建立了一种算法通用性形式。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12635", "html_url": "https://arxiv.org/abs/2509.12635", "title": "基于已知信息的Token-Aware Phase Attention的Positional Encoding", "title_en": "Positional Encoding via Token-Aware Phase Attention", "authors": "Yu Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian", "background": "本文证明在实际假设下，旋转位置嵌入（RoPE）引入了一种内在的距离依赖性偏差，限制了RoPE处理长上下文的能力。罗PE的扩展方法可能缓解这一问题，但通常需要在预训练之后进行人工调整，如重新缩放或调参。背景信息揭示了RoPE在长上下文建模中存在局限性，需要改进。", "innovation": "本文提出了一种新的位置编码方法——Token-Aware Phase Attention（TAPA），它将可学习的相位函数整合到注意力机制中。TAPA能够保持跨长范围的token交互，直接并轻量级地适应到更长的上下文，并且在长上下文建模中显著降低困惑度，优于RoPE家族。", "conclusion": "本文通过引入Token-Aware Phase Attention（TAPA），解决了RoPE在长上下文建模中的不足，TAPA不仅能够直接适应更长的上下文，还能够外推到未见过的长度，并且在长上下文建模中的性能更优越。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14134", "html_url": "https://arxiv.org/abs/2508.14134", "title": "ERIS：一种用于异类时间序列分类的能量导向特征解耦框架", "title_en": "ERIS: An Energy-Guided Feature Disentanglement Framework for Out-of-Distribution Time Series Classification", "authors": "Xin Wu,Fei Teng,Ji Zhang,Xingwang Li,Yuxuan Liang", "background": "理想的时间序列分类(TSC)应该能够捕捉不变的表示，但在处理未预期分布(OOD)数据时，实现可靠的性能仍然是一个关键障碍。这一障碍源于现有模型将领域特定特征和标签相关特征复杂地结合在一起，导致产生了虚假的相关性。为此，虽然特征解耦试图解决这一问题，但当前方法大多未提供必要的语义指导，无法有效地分离真正通用的特征。为解决这一问题，该研究提出了一种端到端的能量正则化信息为移位鲁棒性（ERIS）框架，以实现有指导和可信赖的特征解耦。该框架的核心思想是有效的解耦不仅是数学约束，还需要语义指导以锚定分离过程。ERIS通过三种关键机制实现这一目标。首先，提出了一种能量导向校准机制，为分离过程提供了关键的语义指导，使模型能够自我校准。其次，采用权重层面的正交性策略，强制特定领域特征和标签相关特征之间结构上的独立性，从而减少它们的相互干扰。最后，引入了辅助对抗泛化机制，通过引入结构化的扰动来提升鲁棒性。四个基准测试结果表明，相较于最先进的基线方法，ERIS得出了具有统计显著性改进的结果，并且始终获得了最佳性能排名。", "innovation": "提出了一种新的端到端框架ERIS，该框架通过集成能量导向校准机制、权重层面正交性策略和辅助对抗泛化机制实现了有指导和可靠的特征解耦，以提高时间序列分类在未预期数据分布中的鲁棒性。", "conclusion": "实验结果证明，ERIS框架在四个基准测试中，相较于最先进的基线方法，取得了统计显著性改进的结果，并且始终表现最佳。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0会导致稀疏自编码器产生错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "本文讨论了稀疏自编码器（Sparse Autoencoders, SAEs）从大规模语言模型（LLMs）内部激活中提取特征的能力，并重点介绍了L0这一关键训练超参数。以往的研究通过稀疏重构折衷图比较不同类型的SAE算法，认为L0不是一个有唯一正确值的自由参数，其主要影响在于重构性能上。然而，本文表明，如果L0设置不当，SAE将无法正确分离LLM的潜在特征。如果L0设置过低，SAE会通过混杂相关特征来提升重构效果；如果L0设置过高，SAE会发现一些解决方案，这些解决方案同样混杂了不同特征。", "innovation": "本文提出了一个代理指标，可以在特定训练分布下指导寻找正确的L0以优化SAE性能。这种方法在玩具模型中找到正确的L0值，并且与LLM SAEs中的稀疏探针性能峰值相符。研究还发现，广泛使用的SAE的L0设置通常过低，因此需要正确设置L0来训练具有良好特征的SAE。", "conclusion": "本文的研究表明，L0必须正确设置，以确保训练得到的SAE能够正确提取特征，从而提高模型的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15253", "html_url": "https://arxiv.org/abs/2508.15253", "title": "冲突感知的软提示用于检索增强生成", "title_en": "Conflict-Aware Soft Prompting for Retrieval-Augmented Generation", "authors": "Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee", "background": "检索增强生成（RAG）通过将外部知识整合到输入提示中，增强了大规模语言模型（LLMs）的能力。然而，当检索到的上下文与LLMs的参数知识产生冲突时，这种矛盾（称为上下文记忆冲突）通常无法解决，导致生成不准确的结果。为了应对这一问题，本文引入了冲突感知的检索增强生成（CARE），该系统包含一个上下文评估器和一个基础LLM。上下文评估器通过编码紧凑的记忆标记嵌入来处理原始上下文标记。通过基于地面的/对抗的软提示训练，上下文评估器能够识别不可靠的上下文，并捕捉引导信号，使得推理偏向更可靠的知识源。实验表明，CARE能够有效缓解上下文记忆冲突，平均在问答和事实核查基准测试中性能提升5.0%，为信任适应性的RAG系统指明了新的方向。", "innovation": "本文提出的冲突感知的检索增强生成（CARE）系统针对 Retrieve-augmented generation（RAG）中的上下文记忆冲突问题，引入了上下文评估器。这个评估器能够捕捉并引导生成过程偏向可靠的知识源，有效地解决了上下文与模型参数知识之间的矛盾。", "conclusion": "CARE系统在问答和事实核查基准测试中表现出显著的性能提升。这种基于软提示的方法为构建更可靠、自适应的RAG系统提供了新的思路和方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16876", "html_url": "https://arxiv.org/abs/2508.16876", "title": "Dream to Chat：基于用户信念建模的对话模型强化学习", "title_en": "Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling", "authors": "Yue Zhao,Xiaoyu Wang,Dan Wang,Zhonglin Jiang,Qingqing Gu,Teng Chen,Ningyuan Xi,Jinxian Qu,Yong Chen,Luo Ji", "background": "世界模型在机器人学、游戏和自动驾驶等领域得到了广泛应用。然而，这类模型在自然语言任务中的应用相对有限。本文构建了一个对话世界模型，能够预测用户的情绪、情感和意图，以及未来言论。通过定义部分观测马尔可夫决策过程（POMDP），本文认为用户情绪、情感和意图可以被建模为用户信念，并通过最大化信息瓶颈来解决。通过这种方式，本文将基于模型的强化学习框架应用于对话系统，并提出了一个名为DreamCUB的框架。", "innovation": "本文通过定义POMDP，将用户的情绪、情感和意图建模为用户信念，并且通过最大化信息瓶颈解决。此外，提出了名为DreamCUB的模型来结合基于模型的强化学习框架应用于对话系统。实验证明，预训练的对话世界模型在情绪分类和情感识别上达到了最先进的性能，同时通过策略、批评者和对话世界模型的联合训练也提升了对话质量。进一步分析表明，这种机制在探索-利用平衡和跨领域场景如同理心对话的适应性方面保持了良好的效果。", "conclusion": "实验表明，预训练的对话世界模型能够实现情绪分类和情感识别的最佳表现，并且通过策略、批评者和对话世界模型的联合训练，对话质量得到了提升。进一步分析表明，该方法在探索-利用平衡和跨领域场景中表现出良好的适应性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00338", "html_url": "https://arxiv.org/abs/2509.00338", "title": "高通量环境中的可扩展选项学习", "title_en": "Scalable Option Learning in High-Throughput Environments", "authors": "Mikael Henaff,Scott Fujimoto,Michael Matthews,Michael Rabbat", "background": "层次强化学习（RL）有能力在长时间尺度上做出有效的决策。现有的方法虽然有前途，但尚未充分利用大规模训练的优势。这项工作旨在解决在线层次RL在高吞吐量环境中的关键挑战，特别是在大规模训练上的不足。", "innovation": "提出了可扩展选项学习（SOL），这是一种高度可扩展的层次RL算法，相比现有的层次方法，其吞吐量提高了约35倍。该研究通过在复杂的游戏NetHack中使用300亿帧的经验训练层次代理，展示了SOL的性能和可扩展性，且超越了平面代理，并展示了积极的扩展趋势。此外，SOL还在MiniHack和Mujoco环境中得到了验证，展示了其广泛的适用性。", "conclusion": "研究证明了SOL在高吞吐量环境的卓越性能和广泛适用性，并且其代码已经开源。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15363", "html_url": "https://arxiv.org/abs/2509.15363", "title": "近期使用深度学习方法的显微镜图像增强进展：综述", "title_en": "Recent Advancements in Microscopy Image Enhancement using Deep Learning: A Survey", "authors": "Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita", "background": "显微镜图像增强在理解和解析生物细胞和材料的微观细节中起着关键作用。近年来，借助深度学习方法的显微镜图像增强技术取得了显著进步。", "innovation": "该论文提供了一种快速发展的基于深度学习的显微镜图像增强方法的概览，重点讨论了技术演进、应用、挑战及未来方向。研究聚焦于增强分辨率、重构和去噪等关键领域，并分析了这些领域的最新趋势及其实际应用。", "conclusion": "论文总结了当前基于深度学习的显微镜图像增强方法的主要研究成果，并指出了未来的研究方向。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02627", "html_url": "https://arxiv.org/abs/2509.02627", "title": "使用改进YOLO11x提案和ConvNeXt分类的分阶段 Mitosis 检测策略", "title_en": "A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification", "authors": "Jie Xiao,Mengye Lyu,Shaojun Liu", "background": "在全视野图像（WSIs）中，由于包含非肿瘤、炎症和坏死区域的复杂和异质的背景，以及可能存在的伪影，使用YOLO11x进行有丝分裂检测时常常出现误检和漏检，显著降低了检测的F1分数。现有单一阶段的方法难以准确处理这些复杂情况。", "innovation": "提出了一种分阶段框架，首先使用结合EMA注意力和LSConv的改进YOLO11x生成有丝分裂候选区域；然后应用ConvNeXt-Tiny分类器滤除假阳性，确保检测精确性，从而生成高F1分数的有丝分裂检测结果。相较于单一阶段的YOLO11x基线，该框架在综合数据集上的F1分数提高了0.035，实现显著的精确性提升，同时保持了相似的召回率。", "conclusion": "该分阶段策略在MIDOG 2025 Track 1初步测试集上取得了F1分数为0.7587的结果，并显著提升了有丝分裂检测的精确性，同时保持了良好的召回率。该研究成果的代码已对外开放。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "链式思维还是树状思维？从矩阵思维的角度重新评估复杂推理", "title_en": "Chain or tree? Re-evaluating complex reasoning from the perspective of a matrix of thought", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "大型语言模型（LLMs）在处理复杂和抽象任务时，由于推理能力不足，其准确度出现显著衰退。现有的一些思考结构，如连锁思维（CoT）和树状思维（ToT），虽然旨在增强LMs的推理能力，但这些方法本身存在缺陷，如树状思维内部的冗余问题和连锁思维路径单一的问题。另外，一些研究利用检索增强生成（RAG）方法优化了CoT和ToT以减弱生成幻觉问题，然而这些思考结构的基本瑕疵仍然存在。尤其是在处理多实体和多跳信息时，通过检索获得的验证知识常常包含碎片化、浅表甚至错误的信息，导致LMs推理过程出现偏差。", "innovation": "本文提出了一种新的高效思考结构——矩阵思维（MoT），它通过“列单元通信”的机制在横竖两个维度上探索问题，使LMs能够进行多策略和深层次思考，在减少列单元内部冗余的同时提高推理能力。此外，它还通过事实校正机制，利用RAG检索的知识图谱三元组和原始文本来构建知识单元并纠正错误答案。", "conclusion": "通过在24点游戏、问答评估和propositionthis http URL三个任务中进行广泛实验，本文证明了该框架优于现有的最先进的方法，推理时间仅为基线方法的14.4%，证明了其高效性和准确性。该框架的代码可在<此链接>获得。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01986", "html_url": "https://arxiv.org/abs/2509.01986", "title": "Draw-In-Mind: Rebalancing Designer-Painter Roles in Unified Multimodal Models Benefits Image Editing", "title_en": "Draw-In-Mind: Rebalancing Designer-Painter Roles in Unified Multimodal Models Benefits Image Editing", "authors": "Ziyun Zeng,Junhao Zhang,Wei Li,Mike Zheng Shou", "background": "近期，将多模态理解和生成整合到单一统一模型的范式崭露头角，尤其在文本到图像生成（T2I）任务上表现优异。然而，这种模型在精确图像编辑方面仍存在问题。这一难题源于模块间责任分配不平衡：理解模块主要作为翻译器将用户指令转化为语义条件，而生成模块必须同时扮演设计师和画家的角色，需要推断原始布局、识别目标编辑区域并渲染新内容。该论文指出，理解模块通常训练于复杂推理任务的数据量是生成模块的数倍，但生成模块在编辑任务上的表现并不相应提升，同时承担的设计与绘画任务过重，因此需要改革这种不平衡模式以提高模型的编辑能力。", "innovation": "论文提出了一种名为Draw-In-Mind（DIM）的数据集，该数据集包含两个互补的子集：DIM-T2I子集包含14M长上下文图像-文本对，以提升复杂指令的解释能力；DIM-Edit子集包含由GPT-4o生成的233K“思考链”，为图像编辑提供明确的设计蓝图。研究组将一个冻结的Qwen2.5-VL-3B与一个可训练的SANA1.5-1.6B通过轻量级的两层MLP连接，并在提出的DIM数据集上进行训练，从而创建了DIM-4.6B-T2I/Edit模型。尽管参数规模较小，但DIM-4.6B-Edit在ImgEdit和GEdit-Bench基准测试中实现了SOTA或竞争力的表现，甚至超越了大幅更大的模型如UniWorld-V1和Step1X-Edit。这些结果表明，明确将设计责任分配给理解模块可以显著提高图像编辑的效果。", "conclusion": "该研究展示了通过调整统一多模态模型中理解模块和生成模块的角色分配，可以使模型在图像编辑任务上的表现得到显著提升。研究发布了用于图像编辑任务的Draw-In-Mind数据集和改进的模型，该数据集和模型可以在以下链接访问：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13805", "html_url": "https://arxiv.org/abs/2509.13805", "title": "向物理基础模型迈进", "title_en": "Towards a Physics Foundation Model", "authors": "Florian Wiesner,Matthias Wessling,Stephen Baek", "background": "基础模型通过“一次训练，随处部署”的范式，已经彻底改变了自然语言处理领域。物理基础模型（PFM）可以提供高精度的仿真，加速科学发现，但也存在挑战，当前方法仍局限于单一狭窄领域，且需要重新训练每个新系统。", "innovation": "该研究提出了通用物理变换器（GPhyT），这是一种通用物理模型，通过处理1.8 TB多样化的模拟数据进行训练。GPhyT关键在于能够从上下文中学习推导出支配动力学的过程，使一个模型能在无需指定基本方程的情况下模拟流固相互作用、冲击波、热对流和多相流。它在多个物理领域取得了优越的性能，零样本知识泛化到完全未见的物理系统，并且能够进行长期稳定的预测。", "conclusion": "这项工作证明，可以通过数据学习获取可用于所有物理领域的通用物理原理，为未来实现通用PFM铺平了道路，有望彻底改变计算科学和工程领域。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13400", "html_url": "https://arxiv.org/abs/2509.13400", "title": "正义之审判：揭示LLM辅助同行评审中的隐秘偏见", "title_en": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews", "authors": "Sai Suresh Macharla Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz", "background": "大语言模型（LLMs）的应用正在改变同行评审过程，从辅助审稿人撰写更详细的评审意见到自动生成整个评审意见。虽然这些能力带来了激动人心的机会，但也引发了关于公平性和可靠性的关键问题。本文通过在敏感元数据（包括作者所属机构和性别）上进行受控实验，研究LLM生成的同行评审中的偏见问题。研究发现，机构偏见倾向于在常见学术排名中排名靠前的机构，性别偏见虽然在程度上较为微妙，但可能会随着时间累积而加剧。此外，文中还揭示了一些隐含的偏见，这些偏见在基于令牌的软评分中变得更为明显。", "innovation": "本文通过在敏感元数据（如作者的归属机构和性别）上进行受控实验的方式，探讨了LLM生成的同行评审中的偏见问题。这是首次系统地通过这种方式来研究并揭示这些偏见，为提升同行评审过程的公正性和透明度提供了新的视角和实证依据。", "conclusion": "研究结果表明，LLM在生成同行评审时存在机构和性别偏见，这些偏见会影响评估的公正性。因此，需要进一步审查和调整这些算法以减少隐性偏见，确保评审过程的公平性和可靠性。本文的研究结果提醒同行评审参与者警惕并识别这些偏见，促进更加公正和透明的评审过程。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17283", "html_url": "https://arxiv.org/abs/2509.17283", "title": "使用门检测和大型语言模型进行建筑合规检查中的设施自动计数", "title_en": "Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models", "authors": "Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo", "background": "设施合规检查（BCC）对于确保建筑物符合监管标准至关重要。核心组成部分之一是对各设施类型及其空间分布进行准确计数。尽管这个问题的意义重大，但在文献中却很少被关注，给BCC带来了显著的挑战，也留下了一个重要的空白。目前手动执行这项任务既耗时又劳动密集。最近在大型语言模型（LLMs）方面的进展为通过结合视觉识别和推理能力来增强自动化提供了新机会。然而，现有方法并未将LLMs应用于此任务。", "innovation": "该研究引入了一项新的BCC任务：自动设施计数，涉及验证每种设施类型的数量是否符合法定要求。为了应对该任务，提出了一个将门检测与基于LLM的推理相结合的新型方法。这是首次将LLMs应用于此任务，并进一步通过Chain-of-Thought（CoT）管道提升其性能。该方法在多种数据集和设施类型上具有良好的泛化能力。在现实世界和合成楼层平面数据上的实验表明，该方法的有效性和稳健性。", "conclusion": "该方法在多种数据集和设施类型上表现出广泛的适用性，并且通过Chain-of-Thought（CoT）管道增强了大型语言模型的性能。实验结果表明该方法的有效性和稳健性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14276", "html_url": "https://arxiv.org/abs/2509.14276", "title": "基于 constructive conflict 的多智能体强化学习以促进战略多样性", "title_en": "Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity", "authors": "Yuxiang Mai,Qiyue Yin,Wancheng Ni,Pei Xu,Kaiqi Huang", "background": "近年来，多样性已成为提高多智能体强化学习（MARL）效率的有效机制。然而，现有的方法主要集中在基于个体智能体特性的策略设计上，忽视了智能体在策略形成过程中的相互作用和相互影响。本文针对这一问题，提出了一种名为CoDiCon的新方法，通过在合作场景中引入竞争激励促进策略交流，从而培养智能体之间博弈策略的多样性。CoDiCon借鉴了社会学研究中关于适度竞争和建设性冲突在团体决策中的益处，设计了一种基于排名功能的内在奖励机制，引入竞争动机。中心化的内在奖励模块生成并分发不同的奖励值给智能体，确保竞争与合作的平衡，并通过优化参数化的中心奖励模块，最大化环境奖励，从而解决受限的多层优化问题，与原始任务目标对齐。研究团队在SMAC和GRF环境中评估了该算法，实验结果表明，CoDiCon在增强智能体间的多样性和适应性策略方面具有优越性能，内在奖励机制能有效促进合作智能体之间的竞争性策略交流。", "innovation": "提出了一种名为CoDiCon的新方法，通过在合作场景中引入竞争激励来促进策略交流，从而培养智能体之间博弈策略的多样性。设计了基于排名功能的内在奖励机制，引入竞争动机。通过优化参数化的中心奖励模块，最大化环境奖励，解决了受限的多层优化问题，与原始任务目标对齐。", "conclusion": "CoDiCon在SMAC和GRF环境中表现出优越性能，内在奖励机制能有效促进合作智能体之间的竞争性策略交流，实现了智能体策略的多样化和适应性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15587", "html_url": "https://arxiv.org/abs/2509.15587", "title": "DivLogicEval：用于大型语言模型逻辑推理评估的框架", "title_en": "DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models", "authors": "Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung", "background": "自然语言中的逻辑推理被认为是衡量人类智慧的重要指标。现有的基准测试可能将多种推理技能交织在一起，从而对逻辑推理技能进行不准确的评估。此外，现有的逻辑推理基准在语言多样性和分布方面有限，可能与理想逻辑推理基准的分布偏差较大，从而导致评估结果偏颇。", "innovation": "提出了一个新的经典逻辑基准 DivLogicEval，它由以反直觉方式组成的多样化语句的自然句子组成。为了确保评估的可靠性，还引入了一个新的评估指标，以减轻大型语言模型内部固有的偏见和随机性的影响。通过实验，展示了需要多大的逻辑推理才能回答 DivLogicEval 中的问题，并比较了不同流行的大型语言模型进行逻辑推理的性能。", "conclusion": "DivLogicEval 广泛利用了其设计优势，它不仅包括反直觉的语句，以更好地测试逻辑推理，还提供了一种新的评估方法，减轻了大型语言模型固有的偏见和随机性，从而提供更准确的评估结果。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19406", "html_url": "https://arxiv.org/abs/2509.19406", "title": "TimeMosaic: 按照时间异质性进行自适应粒度片段和段内解码的时间序列预测", "title_en": "TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding", "authors": "Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan", "background": "多变量时间序列在金融、交通、气候和能源等领域中至关重要。现有的基于补丁的方法通常使用固定长度的分割，忽视了局部时间动态的异质性和预测解码的异质性。这种设计导致在信息密集区丢失细节，在稳定段引入冗余，并无法捕获短期和长期时间范围的独特复杂性。", "innovation": "TimeMosaic 提出了一种旨在解决时间异质性的预测框架。它采用了自适应补丁嵌入来根据局部信息密度动态调整粒度，同时平衡了模式的重用与结构的清晰度，保持了时间连续性。此外，它引入了基于片段的解码，将每个预测时间范围视为一个关联子任务，从而适应每个时间范围的具体难度和信息需求，而不仅仅是使用单一的统一解码器。", "conclusion": "在基准数据集上的广泛评估表明，TimeMosaic 在所有指标上都优于现有方法，并且用于321亿观察值大型语料库训练的模型达到了与领先时间序列预测模型相当的性能。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15888", "html_url": "https://arxiv.org/abs/2509.15888", "title": "效率导向的解码以实现语言模型任务适应", "title_en": "Distribution-Aligned Decoding for Efficient LLM Task Adaptation", "authors": "Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Yong Dai,Sam Tak Wu Kwong,Yuguang Fang", "background": "尽管参数高效微调（PEFT）技术可以降低调整千百万参数的语言模型的成本，但这种调整过程仍然较为耗时和资源密集。现有方法通常间接通过权重更新来对语言模型进行任务适应，而未直接调整输出分布以匹配目标任务的分布。作者提出将任务调整重新定义为输出分布对齐的问题，即在生成过程中直接引导输出分布向目标任务分布靠拢，而不是通过权重更新进行间接调整。", "innovation": "引入了Steering Vector Decoding（SVD）方法，这是一种轻量级、兼容PEFT且具有理论依据的技术。SVD从预训练模型和通过短暂微调后的模型之间的Kullback-Leibler（KL）散度梯度中提取任务感知的引导向量，用于指导解码过程。理论证明，SVD与完全微调的梯度步骤是等价的，并且得到瞬时最强引导向量强度的全局最优解。实验表明，SVD结合四种标准PEFT方法，在三种任务和九个基准上提高了多项选择准确性最高5分和开放式生成的真实性2分，无需增加额外的可训练参数。", "conclusion": "SVD提供了大型语言模型高效定向任务适应的一种轻量级、理论指导的途径。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20253", "html_url": "https://arxiv.org/abs/2509.20253", "title": "AnchDrive: 通过混合轨迹锚点初始化扩散策略实现端到端驾驶", "title_en": "AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory Anchors for End-to-End Driving", "authors": "Jinhao Chai,Anqing Jiang,Hao Jiang,Shiyi Mu,Zichong Gu,Hao Sun,Shugong Xu", "background": "端到端多模态规划已经成为自主驾驶领域的革新范式，有效解决了行为多模态以及长尾场景下的泛化挑战。传统的生成模型由于高计算成本，难以满足实时性要求。", "innovation": "本文提出了一种名为AnchDrive的框架，它可以有效地以混合轨迹锚点初始化扩散策略，从而降低传统生成模型的计算成本。该框架从静态的通用驾驶先验和动态、情景感知的轨迹中筛选出丰富且互补的锚点，通过实时解码器将密集和稀疏感知特征转化为动态轨迹，再通过扩散模型预测轨迹偏移量，进行精细调整。", "conclusion": "在NAVSIM基准测试中，AnchDrive达到了新的最佳性能标准，并展示了强大的泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17186", "html_url": "https://arxiv.org/abs/2509.17186", "title": "Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling", "title_en": "Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling", "authors": "Dehao Zhang,Malu Zhang,Shuai Wang,Jingya Wang,Wenjie Wei,Zeyu Ma,Guoqing Wang,Yang Yang,Haizhou Li", "background": "序列长度的爆炸性增长加剧了对有效且高效的长序列建模的需求。Resonate-and-Fire (RF) 神经元能够利用固有的膜动态特性从输入信号中高效提取频率成分，并将这些成分编码成时空突触模式，使它们在长序列建模中表现出色。然而，RF 神经元具有有限的有效记忆容量，并且在复杂时序任务上显示出了能源效率与训练速度之间的权衡问题。", "innovation": "受生物神经元树突结构的启发，提出了一种树突式 Resonate-and-Fire (D-RF) 模型，该模型明确引入了一个多树突和胞体结构。每个树突分支利用 RF 神经元的固有振荡动态特性编码特定频率带，从而通过集体行动实现全面的频率表示。此外，引入了一个适应性阈值机制，根据历史突触活动调整阈值，减少冗余突触活动同时在长时间序列任务中维护训练效率。", "conclusion": "广泛的实验表明，我们的方法在保持竞争力的同时大大确保了稀疏突触，且在训练过程中没有牺牲计算效率。这些结果强调了其作为边缘平台上有效和高效长序列建模解决方案的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20048", "html_url": "https://arxiv.org/abs/2509.20048", "title": "Diffusion-Augmented Contrastive Learning: 一种噪声稳健的生物信号表示的编码器", "title_en": "Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations", "authors": "Rami Zewail", "background": "学习生物信号的鲁棒表示受到有效数据设计难题的阻碍。现有的方法往往难以捕捉生理数据中固有的复杂变化。", "innovation": "提出了一种新型混合框架：Diffusion-Augmented Contrastive Learning (DACL)，结合了扩散模型和监督对比学习的概念。DACL使用Scattering Transformer (ST)特征训练轻量级的变分自编码器(VAE)，并通过扩散前向过程生成噪声视图，然后使用监督对比学习目标训练U-Net风格的编码器，以学习在不同噪声水平下平衡类区分与鲁棒性的表示。", "conclusion": "该方法在PhysioNet 2017 ECG数据集上实现了竞争性的AUROC值0.7815，证明了使用扩散过程本身驱动对比学习目标的有效性，从而生成鲁棒性嵌入，展示了良好的类可分性基础。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16780", "html_url": "https://arxiv.org/abs/2509.16780", "title": "比较RAG和GraphRAG在数学教科书页面级检索问答中的表现", "title_en": "Comparing RAG and GraphRAG for Page-Level Retrieval Question Answering on Math Textbook", "authors": "Eason Chen,Chuangji Li,Shizhuo Li,Zimo Xiao,Jionghao Lin,Kenneth R. Koedinger", "background": "技术增强的学习环境通常有助于学生在自我学习过程中检索相关学习内容。大规模语言模型（LLMs）作为信息检索的新辅助工具，已经在学习中崭露头角。尽管LLMs在通用问题回答中表现出色，但它们往往无法与特定课程材料（如教科书和幻灯片）的领域知识有效地对齐。本文研究了Retrieval-Augmented Generation (RAG)和GraphRAG，即知识图增强的RAG方法，在本科生数学教科书中的页面级问答应用。尽管RAG在检索上下文相关的短文本片段方面效果很好，但GraphRAG可能在建模相互关联的概念和层次知识结构方面更为出色。研究人员构建了一个包括477个问题-答案对的数据集，每个问题都关联到教科书中的一个特定页面，然后将基于嵌入的标准RAG方法与GraphRAG进行了对比，评估了检索准确性和生成答案的质量。研究发现，基于嵌入的RAG在检索准确性和F1分数上优于GraphRAG，因为GraphRAG因其基于实体的结构，经常检索过多的、有时是不相关的内容。研究人员还尝试对面检索结果进行重新排序，但观察到结果参差不齐，包括性能下降和在大上下文窗口时的现象（如幻觉）时表现差。这项研究强调了在教育背景下页面级检索系统的潜力和挑战，强调了构建可靠的AI辅导解决方案需要更精细的检索方法来提供参考页面号码的重要性。", "innovation": "研究引入了知识图增强的RAG（GraphRAG）方法应用于数学教科书的页面级问答，并通过与标准RAG方法的对比，旨在探索GraphRAG在建模相互关联概念和层次知识结构方面的优势。研究还在检索结果的重新排序方面进行了初步探索，虽取得了一些进展但也发现了问题。", "conclusion": "基于嵌入的RAG在页面级检索和生成答案的质量上优于GraphRAG。尽管GraphRAG在处理关联性和层次结构方面可能更具优势，但在实际应用中需要进一步优化，以克服检索过多不相关内容的问题。这项研究为构建AI辅助教学解决方案提供了新的见解，强调了开发更精确的检索方法的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19515", "html_url": "https://arxiv.org/abs/2509.19515", "title": "同伴聊天机器人的纵向随机对照研究：拟人化及其在社会影响中的中介作用", "title_en": "A Longitudinal Randomized Control Study of Companion Chatbot Use: Anthropomorphism and Its Mediating Role on Social Impacts", "authors": "Rose E. Guingrich,Michael S. A. Graziano", "background": "随着社会人工智能（AI）代理关系的增加，人们报告称与聊天机器人如Replika等形成友谊、导师关系和浪漫关系。有人担心，伴侣聊天机器人关系可能对人类关系造成损害或替代，但这些社会后果是否会出现以及如何出现仍不清楚。前人研究表明，人们的社交需求状态及其对AI代理的拟人化可能会影响人机交互对人际互动的影响。本研究通过纵向实验（N = 183），探讨了与陪伴聊天机器人的互动如何影响人们的社交健康和关系，依赖评估人们的社交需求状态及其对机器人的拟人化程度。", "innovation": "本研究通过纵向随机对照实验设计，随机将参与者分配给与陪伴聊天机器人进行10分钟/天的持续21天的文字互动组，或玩文本游戏组，结合多次问卷调查和音频访谈，研究了聊天机器人与人类互动对人类互动的影响。研究发现，聊天机器人的使用对参与者的社交健康和关系影响不大，并探讨了拟人化在其中的中介作用，揭示了用户社交需求与机器人的拟人化之间的关系。", "conclusion": "研究结果表明，人们的社交健康和关系在与聊天机器人互动21天后没有显著变化，而那些有较高社交连接需求的人更倾向于拟人化聊天机器人，这种高拟人化使人们与聊天机器人的互动对其家庭和朋友的关系产生了更大的影响。通过中介分析显示，人类与AI交互对人类互动的社会结果的影响是由对AI代理的拟人化程度所介导的，而这种拟人化与社交连接的需求相关。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG: 一种统一和可扩展代码生成的仓库规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大型语言模型在生成单个函数或单个代码文件方面表现出色，但在从零开始生成完整的代码仓库方面仍面临重大挑战。这一能力对于从高层规范构建一致的软件系统和实现自动化代码生成的全部潜力至关重要。这一过程需要在两个层级上进行规划：确定要构建的功能和模块（提议阶段）以及定义它们的实现细节（实施阶段）。当前的方法依赖于自然语言规划，这通常会导致模糊的规定、对齐不良的组件和脆弱的设计，因为自然语言固有的模糊性和缺乏结构。为了应对这些限制，作者引入了Repository Planning Graph (RPG)，这是一种结构化的表示法，能够在一个统一的图中编码功能、文件结构、数据流动和函数内容。通过用显式的蓝图替换自由格式的自然语言，RPG 使针对仓库生成的一致性长期规划成为可能。", "innovation": "作者提出了Repository Planning Graph (RPG)，这是一种结构化的表示法，它通过编码功能、文件结构、数据流动和函数内容来在统一的图中表示能力。此外，作者开发了ZeroRepo，这是一个基于图的框架，分为提议层级规划、实施层级构建和通过测试验证的图指导代码生成三个阶段。实验结果显示，ZeroRepo 在代码行数和代码令牌数量上比现有最强基线高出 3.9 倍，覆盖率和测试准确率分别提高了 27.3 和 35.8 个百分点，说明 RPG 能够处理复杂的依赖关系，通过接近线性的扩展能力实现更复杂的规划，并提高代理对仓库的理解，从而加速本地化。", "conclusion": "ZeroRepo 在 RepoCraft 标准测试集上表现优异，生成了近 3.6 万个代码行和 445 万个代码令牌，显著优于其他基准模型，展示了 RPG 和 ZeroRepo 在代码仓库生成方面的能力和价值。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19742", "html_url": "https://arxiv.org/abs/2509.19742", "title": "HiCoLoRA: 通过层级协作LoRA解决上下文提示错位的零样本DST", "title_en": "HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST", "authors": "Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li", "background": "零样本对话状态跟踪(zero-shot dialog state tracking，zs-DST)对于使面向任务的对话系统(TODs)能够无需昂贵数据标注即可泛化到新领域至关重要。主要挑战包括对话上下文的动态性和静态提示的静态性之间的语义不匹配，导致跨层协调的灵活性差、领域间干扰以及灾难性遗忘现象。上述问题使得系统难以有效应对新领域的问题挑战，亟需一种增强零样本槽位推理的框架，以提升对话状态跟踪的灵活性和准确度。现有的方法通常采用简单的低秩适应机制（Low-Rank Adaptation, LoRA），但缺乏对动态上下文和静态提示之间的联系处理的层级协调，以及适应不同领域数据的迁移机制。", "innovation": "本文提出了Hierarchical Collaborative Low-Rank Adaptation（HiCoLoRA）框架，作为增强零样本槽位推理的手段。它引入了层级低秩适应机制，通过动态层特定处理（结合低层启发式分组和高层全交互）来提高层级协调性。HiCoLoRA还结合了Spectral Joint Domain-Slot Clustering（基于谱联合领域-槽聚类）以识别可迁移的关联，继而使用自适应线性融合机制进行信息集成。此外，HiCoLoRA还利用了基于语义增强的SVD初始化（Semantic-Enhanced SVD Initialization, SemSVD-Init）机制来保持预训练的知识。实验结果表明，HiCoLoRA在MultiWOZ和SGD多领域的数据集上优于基线方法，达到zs-DST的SOTA水平。", "conclusion": "实验证明，HiCoLoRA框架在零样本对话状态跟踪方面表现出色，通过层级协作低秩适应解决了动态上下文和静态提示之间的不匹配问题，提高了对话状态跟踪的灵活性和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21456", "html_url": "https://arxiv.org/abs/2509.21456", "title": "道德对齐中性能权衡的诊断：性别刻板印象案例研究", "title_en": "Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes", "authors": "Guangliang Liu,Bocheng Chen,Xitong Zhang,Kristen Marie Johnson", "background": "道德对齐已成为广泛采用的方法，用于调节预训练语言模型（PLMs）的行为，通常通过在精选数据集上进行微调或模型编辑来实现。然而，这一过程往往会导致下游任务性能下降。先前的研究通常通过精心设计的公平性目标来鼓励PLMs选择性地忘记刻板印象知识，以实现性能权衡，同时尽量保留其有用性。", "innovation": "通过对减少性别刻板印象的权衡机制进行分析，揭示了当前公平性目标的局限性：（1）下游任务性能主要由总体遗忘程度驱动；（2）选择性遗忘刻板印象往往会增加整体遗忘；并且（3）旨在减少遗忘的通用解决方案在减少整体遗忘和提高下游任务性能方面无效。", "conclusion": "现有的公平性目标在追求权衡时存在局限性，强调了解决性能下降问题的必要性和改进公平性目标的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21404", "html_url": "https://arxiv.org/abs/2509.21404", "title": "大型语言模型需要符号学", "title_en": "How Large Language Models Need Symbolism", "authors": "Xiaotie Deng,Hanyu Li", "background": "当前，人工智能的发展主要依赖于模型规模的扩大，但研究表明，仅仅通过增强模型的规模并不能实现真正的发现。大型语言模型在拥有强大但缺乏目标导向能力的情况下运行，这限制了它们的探索潜力。该领域需要一种能够引导其强大的但盲目直觉的方法——即，人类创造的符号系统作为导航工具。", "innovation": "该论文提出了大型语言模型需要一种‘人类创造的符号系统’作为导航工具的想法，以支持其强大的但缺乏目标导向能力的直觉。这种创造性提出的新颖之处在于提供了一种新的方法来改进大型语言模型的功能和效率，从而促进真正的发现进程，而不是仅仅依靠增加模型的规模来提升性能。", "conclusion": "本文强调了在大型语言模型中引入人类创造的符号体系的重要性。通过这种方式，可以更有效地引导和优化模型的行为，从而推动真正的发现和创新。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21357", "html_url": "https://arxiv.org/abs/2509.21357", "title": "一种新的差异特征学习方法用于有效的幻觉检测和分类", "title_en": "A Novel Differential Feature Learning for Effective Hallucination Detection and Classification", "authors": "Wenkai Wang,Vincent Lee,Yizhen Zheng", "background": "大型语言模型幻觉是一个关键挑战，由于训练数据中的分布偏差，输出会偏离事实准确性。虽然近期研究证实特定隐藏层存在幻觉和事实内容差异，但幻觉信号在层内的具体定位仍不清楚，限制了高效检测方法的发展。已有研究主要集中在模型层面的特征学习和权重分配，但对幻觉信号的精准识别和局部化仍存困难，特别是在如何有效减少特征维度的前提下保持检测性能方面，缺乏有效的解决方案。", "innovation": "本文提出了一种双模型架构，通过集成一个投影融合(PF)块和一种差异特征学习(DFL)机制。DFL机制通过计算平行编码器之间学习互补表示的差异，来识别关键特征。系统性实验表明，幻觉信号集中在稀疏的特征子集中，在问题回答和对话任务中显著提高了准确率。分析发现，幻觉信号具有层次化的“漏斗模式”，浅层显示高特征多样性，而深层显示集中使用，从而只需使用1%的特征维度即可维持检测性能，显著减少了计算资源的消耗。这种方法比现有方法更具计算效率，既能降低推理成本又能保持准确性。", "conclusion": "本研究揭示了幻觉信号比先前假设更为集中，提出了具有高效检测系统的计算路径。通过整合PF块和DFL机制，提出的方法能够在少量特征维度下保持检测性能，有效减少了计算成本，为幻觉的有效检测和分类提供了新的途径。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21359", "html_url": "https://arxiv.org/abs/2509.21359", "title": "基于影响引导的上下文选择以实现有效的检索增强生成", "title_en": "Influence Guided Context Selection for Effective Retrieval-Augmented Generation", "authors": "Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang", "background": "检索增强生成（RAG）通过将响应与外部知识对接来解决大型语言模型（LLM）的幻觉问题，但其效果受限于包含无关或噪声信息的低质量检索上下文。虽然现有的方法试图通过基于预定义的上下文质量评估指标进行上下文选择来提高性能，但这些方法在标准RAG上的改进有限。这些方法的缺陷在于未能全面利用可用信息（查询、上下文列表和生成器）进行综合质量评估。", "innovation": "本文借鉴了数据选择的最新进展，重新定义了上下文质量评估为推理时的数据估值问题，并引入了上下文影响价值（CI值）这个新的度量标准。该度量标准通过测量删除每个上下文时性能下降的程度来量化上下文质量，有效结合了查询感知的相关性、列表感知的独特性以及生成器感知的对齐性。同时，CI值通过仅保留具有正CI值的上下文来消除复杂的筛选超参数调整。为了应对标签依赖性和计算开销的实践挑战，本文开发了参数化的代理模型，在推理时预测CI值。模型采用分层结构，捕捉局部查询-上下文相关性和全局跨上下文交互。", "conclusion": "广泛实验表明，我们的上下文选择方法在8个NLP任务和多个LLM上显著优于最先进的基线，有效过滤掉低质量上下文的同时保留关键信息。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20380", "html_url": "https://arxiv.org/abs/2509.20380", "title": "ACCelliuM：监督微调以实现自动OpenACC访问标号生成", "title_en": "ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation", "authors": "Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes", "background": "随着GPU在计算中的普及，其硬件和并行编程框架变得更为复杂。尽管基于指导的并行编程标准如OpenACC简化了GPU编程，但仍需要相当程度的专业知识才能有效地使用这些标准。本研究旨在通过开发ACCelliuM——一个大型语言模型，专为生成专家级的OpenACC访问标号而微调，来解决这一问题。ACCelliuM通过公开的训练集ACCelliuM SFT，该集包括来自公共GitHub C/C++仓库的4033对OpenACC公用语句-循环对，提供了一个新的解决方案。实验表明，在生成正确的OpenACC公用语句方面，基模型与专门微调过的版本之间存在显著差距。微调后的模型在正确指令类型方面的产出准确率为87%，而在指令及其子句等细节的准确率为50%。即使是部分正确的指令也可能包含有助于并行执行控制、数据传输和并发的正确子句顺序或附加子句，从而提供超出简单字符串匹配的实际价值。", "innovation": "ACCelliuM是一个专为生成专家级OpenACC访问标号而微调的大型语言模型，它通过监督微调公开的训练集ACCelliuM SFT，可以显著提高OpenACC访问标号的生成准确性。ACCelliuM旨在通过提供准确生成OpenACC访问标号的开源代码、模型和数据集，降低自动将串行编写程序迁移到GPU的门槛，并建立一个可复现的基准测试。", "conclusion": "ACCelliuM通过监督微调的方法显著改进了大型语言模型在生成准确OpenACC访问标号上的性能。该研究为自动利用OpenACC实现GPU加速提供了有效的解决方案，并降低了实施自动GPU卸载的难度。开放的代码、模型和数据集也为其他研究提供了基准框架。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21482", "html_url": "https://arxiv.org/abs/2509.21482", "title": "根据混合词生成学习进行推理", "title_en": "Learning to Reason with Mixture of Tokens", "authors": "Adit Jain,Brendan Rappazzo", "background": "当前基于回声强化学习（RL）的方法大多采用组相对政策优化（GRO）的变体，这类方法在每个推理步骤中随机选择多个推理完成，并根据它们之间的相对评分调整政策。然而，这些方法未充分利用模型在候选词的概率分布中的丰富分布信息，而在非RL环境中保存和利用这些信息已被证明是有益的。因此，研究者认为当前的RLVR方法在推理搜索空间的约束上是不必要的，限制性地。因此，作者探究了在RLVR中使用混合词生成（MoT-G）的方法。", "innovation": "本文提出了一个统一的框架，该框架既涵盖了现有的MoT-G方法，也扩展了RLVR方法以直接在连续混合空间中生成思维链，而不是在每个推理步骤中随机选择离散词素。通过在Reasoning-Gym上评估两种MoT-G变体的表现，结果表明MoT-G方法相较于标准解码Qwen2.5-1.5B模型，在7个任务中有5%-35%的显著改进，在完成相同任务时所需轨迹数量减少了一半，这表明训练效率有了提高。", "conclusion": "通过对隐藏状态和词素级别的全面分析，我们发现MoT-G的优势可能来源于在整个推理过程中保持更高的隐藏状态熵，从而促进在词素空间中的探索。这表明MoT-G在提高大型语言模型推理能力方面具有潜在价值，并提高了训练效率。"}
{"llm_update_time": "20250929", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19767", "html_url": "https://arxiv.org/abs/2509.19767", "title": "FusedANN：通过属性-向量融合的凸化混合ANN", "title_en": "FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion", "authors": "Alireza Heidari,Wei Zhang,Ying Xiong", "background": "向量搜索技术提升了变压器技术的应用，但在实际应用中，需要结合向量相似性和属性过滤的混合查询（例如，“类别X中2023年的顶级文档”）。当前解决方案在召回率、速度和灵活性之间进行权衡，并依赖于脆弱的索引技巧，这些技巧无法扩展。现有的方法通过脆弱的索引技巧在召回率、速度和灵活性之间进行权衡，缺乏灵活性和可扩展性。", "innovation": "我们提出了FusedANN（融合属性向量最近邻），这是一种几何框架，将过滤提升为ANN优化约束，并通过拉格朗日式松弛引入凸融合空间。该方法通过基于变压器的凸化联合嵌入属性和向量，将严格的过滤变为连续的加权惩罚，同时保持最小子项的语义，并能实现高效的近似搜索。FusedANN能够在高选择性条件下还原为精确过滤，对精确匹配不足时的语义最近邻属性进行优雅的松弛，并保持下游ANN的α-逼近保证。", "conclusion": "实验结果表明，FusedANN通过消除脆弱的过滤阶段提高了查询吞吐量，在标准混合基准上优于专门的索引技巧，吞吐量可提高多达3倍，召回率更好。理论上，我们提供了明确的误差边界和参数选择规则，使FusedANN适用于生产环境。这种技术为符号约束与向量相似性之间建立了有原则的、可扩展和可验证的桥梁，为大规模、混合和动态的NLP/ML工作负载解锁了一代新的过滤检索系统。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21361", "html_url": "https://arxiv.org/abs/2509.21361", "title": "上下文决定一切：LLMs在实际应用中的最大有效上下文窗口", "title_en": "Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs", "authors": "Norman Paulsen", "background": "现有大型语言模型（LLM）供应商声称其最大的上下文窗口尺寸很大，但这并未经过实际测试。为了验证实际应用中的上下文窗口效果，研究者定义了一个最大有效上下文窗口的概念，制定了不同大小和类型问题下检验上下文窗口效果的方法，并创建了一种标准化的方法来比较不同尺寸上下文窗口下模型的效果，找出其失败点。研究者收集了数万条数据，发现报告的最大上下文窗口尺寸与最大有效上下文窗口尺寸之间存在显著差异，最大有效上下文窗口不仅远小于最大上下文窗口尺寸，而且还会根据问题类型发生变化。在测试中，部分顶级模型在仅100个上下文标记时就出现失败；多数模型在1000个上下文标记时出现严重准确度下降。所有模型的性能均远低于其宣称的最大上下文窗口尺寸，最多相差99%。研究还发现最大有效上下文窗口会根据提供的问题类型发生变化，这为提高模型准确性和减少幻觉提供了明确和可操作的见解。", "innovation": "研究首次定义了最大有效上下文窗口的概念，并制定了检验不同上下文窗口效果的标准方法，以为不同尺寸上下文窗口下的模型比较提供了一个标准化方式，以找到模型的失败点。研究结果揭示了最大有效上下文窗口因问题类型不同而变化的现象，为提升模型性能提供了重要的数据支持和见解。", "conclusion": "研究发现实际的最大有效上下文窗口与报告的最大上下文窗口存在巨大差异，而且这种差异会根据问题类型发生变化。测试中的大部分模型在较少量的上下文标记时就出现显著的准确度下降，所有模型均远未达到报告的最大上下文窗口尺寸的效果。通过研究数据，给出了提高模型准确性和减少模型幻觉的具体和实用建议。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21443", "html_url": "https://arxiv.org/abs/2509.21443", "title": "一个模型，多种道德观：揭示计算性道德推理中的跨语言偏差", "title_en": "One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning", "authors": "Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens", "background": "大规模语言模型（LLMs）越来越多地部署在多语言和多文化环境中，道德推理对于生成伦理上适当的回答至关重要。然而，主流的LLM预训练主要基于英语数据，这引起了对其能否在多元语言和文化背景下进行判断迁移的担忧。本文系统研究了语言如何在LLM中调节道德决策过程。通过将两个已建立的道德推理基准翻译成五种文化与类型多样的语言，实现多语言零启动评估。分析发现，在不同语言中，LLM的道德判断存在显著不一致，常常反映出文化上的不匹配。", "innovation": "作者通过将两个道德推理基准跨语言翻译，得出了一个多语言零样本评估体系。作者进一步通过精心设计的研究问题，揭示了导致这些差异的底层驱动因素，从道德分歧到LLM采用的推理策略。此外，作者通过案例研究研究了预训练数据如何塑造LLM的道德指南。最后，作者梳理出了一种结构化的道德推理错误类型学，强调了更具文化意识的人工智能的必要性。", "conclusion": "通过这项工作，作者提炼了关于道德推理错误的见解，指出需要更加注重文化意识的AI系统。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21459", "html_url": "https://arxiv.org/abs/2509.21459", "title": "使用RLVR实现前沿SQL推理模型", "title_en": "A State-of-the-Art SQL Reasoning Model using RLVR", "authors": "Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang", "background": "使用强化学习（Reinforcement Learning，RL）开发定制推理模型，特别是可融入企业特定知识的模型，在解决企业客户的问题方面具有巨大潜力。许多问题中的奖励函数是可验证的，这种环境被称为具有可验证奖励（Verifiable Rewards, VR）的强化学习（RL with Verifiable Rewards, RLVR）。", "innovation": "将RLVR应用于BIRD这一流行的数据科学基准测试，该测试评估AI代理将自然语言查询转换为数据库SQL执行的能力。通过精心选择提示和模型，使用离线RL方法TAO进行预热，然后进行严格的在线RLVR训练，该研究实现了现有技术的最先进精度，无自一致性的情况下为73.56%，带有自一致性的条件下为75.68%，并且所需的生成次数少于第二优方法。尽管BIRD只是一个代理任务，但其框架的简易性使其在企业领域具有广泛的应用前景，例如商业智能、数据科学和编程中。", "conclusion": "该研究表明，通过RLVR训练的可验证奖励模型能够有效地解决数据查询到SQL执行的转化问题，并且所提出的框架具有普适性和高效性，适合应用于企业化领域的复杂任务上。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21499", "html_url": "https://arxiv.org/abs/2509.21499", "title": "LLMs中由代码引起的推理", "title_en": "On Code-Induced Reasoning in LLMs", "authors": "Abdul Waheed,Zhen Wu,Carolyn Rosé,Daphne Ippolito", "background": " large language models（LLMs）通过使用代码数据可以增强其推理能力，但目前尚不清楚代码中的哪些方面对这一能力提升最为关键。该研究通过系统性且数据导向的方法来探讨这一问题，构造了十种编程语言的平行指令数据集，并通过有控制的扰动断言结构或语义特性，对来自五类模型家族八种规模的LLM进行微调，并在自然语言、数学和代码任务上评估其表现。", "innovation": "该研究创新性地采用系统性和数据导向的方法，通过构造平行指令数据集和有控制的代码扰动来探究代码中哪些方面对LLM推理能力提升最关键的问题。研究发现了LLM对结构扰动比语义扰动更敏感，特别是在数学和代码任务方面的表现更为突出。适中的抽象层面如伪代码和流程图与代码本身具有相似的效能，通过编码减少标记数量而不遵守原始语法也可以保留甚至增强性能。甚至带有误导信号的代码在表面规律仍存的情况下也能保持竞争力。", "conclusion": "研究揭示了语法样式对任务特定收益的影响，Python适合自然语言推理而低级语言如Java和Rust倾向于数学。通过这一系统性的框架，研究旨在提供关于不同代码特性如何影响推理及其如何设计训练数据来增强LLM推理能力的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21554", "html_url": "https://arxiv.org/abs/2509.21554", "title": "基底音变的英语说话人分离", "title_en": "Domain-Aware Speaker Diarization On African-Accented English", "authors": "Chibuzor Okocha,Kelechi Ezema,Christan Grant", "background": "本文研究了域效应在非洲口音英语说话人分离中的影响。研究通过严格重叠评分的DER协议，评估了多个生产系统和开源系统在通用对话和临床对话中的表现。研究发现，在临床对话中存在一致的域惩罚，并且这种惩罚在不同模型中依然显著。错误分析表明，短对话和频繁重叠是主要导致这一惩罚的因素。", "innovation": "研究贡献包括一个跨域控制基准，简洁的错误分解方法和会话级别分析，以及一个易于复制的适应方案。研究指出，重叠感知分割和临床资源的平衡是在实践中应优先考虑的步骤。", "conclusion": "尽管通过调整细分模块获得了一定的错误减少，但未能完全消除域惩罚，研究建议未来的关注点应放在重叠感知分割和均衡临床资源上。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21623", "html_url": "https://arxiv.org/abs/2509.21623", "title": "OjaKV: 使用Oja规则进行上下文感知在线低秩KV缓存压缩", "title_en": "OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule", "authors": "Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen", "background": "大型语言模型的长期上下文能力受到内存瓶颈的限制，主要来自于用于自回归生成的键值（KV）缓存。现有的KV缓存压缩方法，如低秩投影，虽然有潜力，但通常依赖于静态且离线学习的子空间，这种方法在数据分布发生变化时表现不佳。", "innovation": "OjaKV引入了一种结合策略性混合存储策略与在线子空间适应的创新框架。它通过保存关键的起始和最近的词元保持高保真注意力锚点，并对中间的多数词元进行在线低秩压缩，使用Oja算法进行在线主成分分析逐步适应投影基底。这种适应在填充提示和解码期间持续进行，确保子空间与不断变化的上下文保持一致。该框架完全兼容现代的注意力模块。", "conclusion": "实验表明，OjaKV在高压缩比下能保持甚至提高零样本准确性，在非常长的上下文基准测试中尤其具有显著优势，突显了在线子空间适应在动态跟踪上下文变化中的重要性。这些结果证明了这种混合框架作为一种高效且即插即用的内存管理系统，能够在不需要模型微调的情况下实现长期上下文推理。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21562", "html_url": "https://arxiv.org/abs/2509.21562", "title": "比较个性化在多文档摘要中的应用", "title_en": "Comparative Personalization for Multi-document Summarization", "authors": "Haoyuan Li,Snigdha Chaturvedi", "background": "个性化多文档摘要（MDS）对于满足用户个人的写作风格和内容重点的需求至关重要。然而，为了有效进行个性化，需要通过与其他用户的偏好比较来识别用户偏好中的细微差异。", "innovation": "作者提出了一种名为ComPSum的个性化MDS框架。该框架首先通过比较用户偏好与其他用户的偏好来生成关于用户的结构化分析。然后利用生成的分析来指导个性化摘要的生成。此外，作者还提出了一种名为AuthorMap的参考自由评估框架，用于个性化MDS的精细评估。", "conclusion": "为了评估ComPSum的性能，构建了一个包含评论和新闻领域的个性化MDS数据集PerMSum。通过使用AuthorMap评估ComPSum在PerMSum上的性能，结果表明ComPSum优于其他强基线。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21450", "html_url": "https://arxiv.org/abs/2509.21450", "title": "基于LLM的糖尿病诊断支持：GPT-5的机会、场景与挑战", "title_en": "LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5", "authors": "Gaurav Kumar Gupta,Nirajan Acharya,Pranal Pande", "background": "糖尿病是全球主要的公共卫生挑战，影响着全球超过五亿成年人，并预计还会增加。尽管美国糖尿病协会(ADA)提供了明确的诊断标准，但由于症状模糊、临界实验室值、妊娠复杂性以及长期监测需求，早期识别仍然困难。最新的大型语言模型（LLMs）如GPT-5提供了通过结构化、可解释和患者友好的输出来增强决策支持的机会。这项研究使用基于合成案例的模拟框架来评估GPT-5，这些案例与ADA 2025标准一致，并受到公共数据集如NHANES、Pima印第安人、EyePACS和MIMIC-IV的启发。研究测试了五个代表性场景：症状识别、实验室解读、妊娠糖尿病筛查、远程监测和多模态并发症检测。每个场景中，GPT-5对病例进行了分类，生成了临床理由，提供了患者解释，并生成了结构化的JSON总结。研究结果显示了GPT-5与ADA定义标准的强烈一致性，表明GPT-5可能成为临床医生和患者双重用途的工具，同时强调了在医疗保健领域负责任地评估LLMs需要可重复的评价框架的重要性。", "innovation": "研究使用了基于合成案例的模拟框架来评估GPT-5，通过在糖尿病诊断中的多个场景进行模拟来增强决策支持，特别是症状识别、实验室解读、妊娠糖尿病筛查、远程监测和多模态并发症检测等方面。这些场景的测试结果显示了GPT-5与ADA定义标准的强烈一致性，表明其潜在的应用价值和对未来医疗决策支持的贡献。", "conclusion": "GPT-5可能成为一个双重用途的工具，既适用于临床医生，也适用于患者。然而，对其在医疗保健领域的应用仍需谨慎评估，特别是需要建立可重复的评价框架来确保其责任和可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21698", "html_url": "https://arxiv.org/abs/2509.21698", "title": "GRAB: 基于风险分类的金融披露无监督主题发现基准", "title_en": "GRAB: A Risk Taxonomy--Grounded Benchmark for Unsupervised Topic Discovery in Financial Disclosures", "authors": "Ying Li,Tiejun Ma", "background": "在10-K文件的风险披露中，风险分类对于监督和投资至关重要。然而，目前没有公开的基准测试来评估无监督主题模型在此任务中的表现。", "innovation": "本文提出了GRAB，一个专门针对金融领域的基准测试，包含来自8,247份文件的1.61M个句子，并生成了无需人工标注的语句标签。该模型利用FinBERT词注意力、YAKE关键词信号和分类意识共现匹配，锚定于一个包含193个术语映射到21个细分类的宏观类别的风险分类体系。该体系不仅引导了弱监督，还报告了宏观级别的评估结果。同时，GRAB统一了固定数据集划分和稳健的评估指标，如准确性、宏F1、Topic BERTScore和基于熵的有效主题数。", "conclusion": "GRAB通过提供数据集、标签和代码，使得在金融披露中对比传统、嵌入式、神经和混合主题模型的评估变得一致、可再现。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21535", "html_url": "https://arxiv.org/abs/2509.21535", "title": "农务机器人：农业专用问答系统", "title_en": "Agribot: agriculture-specific question answer system", "authors": "Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari", "background": "印度是一个以农业为基础的经济体，准确的农业信息对于实现最优化农业增长和产出至关重要。为了帮助农民解决他们的疑问，研究人员基于Kisan Call Center的数据集构建了一个农业聊天机器人系统。该系统能够24小时提供服务，通过任何电子设备访问，并以简单易懂的方式提供信息。该系统基于句子嵌入模型，初次准确率为56%。通过消除同义词并加入实体提取，准确率提高到86%。这样一个系统有助于农民获取更易于理解的农业相关实践信息，从而提高农业生产效率。呼叫中心工作人员的工作将得到简化，他们的努力可以重新导向到更有意义的目标上。", "innovation": "该系统基于句子嵌入模型，并通过消除同义词和加入实体提取，将准确率从56%提高到86%。该系统可以24小时提供服务，通过任何电子设备访问，并以简单易懂的方式提供农业相关信息。", "conclusion": "这样的系统有助于农民更容易获取农业相关实践信息，进而提高农业生产效率。呼叫中心工作人员的工作也将得到简化，他们的努力可以重新导向到更有意义的目标上。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21557", "html_url": "https://arxiv.org/abs/2509.21557", "title": "生成时引用 vs. 后置引用：LLM归因的一项综合评价", "title_en": "Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution", "authors": "Yash Saxena,Raviteja Bommireddy,Ankur Padia,Manas Gaur", "background": "在重要领域如医疗、法律、学术和金融中，大型语言模型（LLMs）需要引用可以由人类验证的资料来源。即使是微小的错误也可能导致严重后果。在此背景下，研究人员和从业者必须决定是让模型在解码时生成引用，还是先生成答案，之后再添加或验证引用。这项研究旨在通过引入两种不同的引用方式：生成时引用（G-Cite）和后置引用（P-Cite）来澄清这一选择。", "innovation": "本研究引入了生成时引用（G-Cite）和后置引用（P-Cite）两个引用模式。研究团队进行了全面评估，涵盖零样本到高级检索增强方法，并提供了基于证据的建议，权衡了不同应用场景中的利弊。研究表明，引用覆盖率和引用准确性之间存在一致的权衡关系，检索在两个模式中均驱动归因质量的主要因素。", "conclusion": "后置引用（P-Cite）能够在保持高覆盖率的同时实现竞争性的准确性和适度的延迟，而生成时引用（G-Cite）则在精确性上更胜一筹，但会牺牲覆盖率和速度。本研究建议对于高风险应用采用以检索为中心的后置引用（P-Cite）方法，而对于严格声明验证等关键性准确性需求较高的设置则保留生成时引用（G-Cite）。研究结果已公布并提供可访问的代码和人工评估结果。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21631", "html_url": "https://arxiv.org/abs/2509.21631", "title": "走向透明的人工智能：可解释的语言模型综述", "title_en": "Towards Transparent AI: A Survey on Explainable Language Models", "authors": "Avash Palikhe,Zichong Wang,Zhipeng Yin,Rui Guo,Qiang Duan,Jie Yang,Wenbin Zhang", "background": "语言模型（LMs）在自然语言处理中取得了显著进展，并在多个领域中取得了显著进步，然而其黑盒特性引发了对其内部机制和决策过程解释性的关键关注。特别是在高风险领域，利益相关者需要理解模型输出的合理性来确保可问责性。尽管可解释的人工智能（XAI）方法在非LMs中已有广泛研究，但应用于复杂的LMs时遇到了许多局限性。现有的文献综述往往未能充分捕捉LMs的架构多样性及其能力演进所带来的独特挑战。因此，本综述致力于填补这一空白。", "innovation": "本文综述了XAI技术在语言模型中的应用，按其底层变换器架构分类，包括编码器只读、解码器只读和编码器-解码器，系统地分析了这些方法在不同架构上的适应性和各自优势与局限。此外，通过可信度和忠实度的双重标准评估这些技术的有效性。最后，本文指出了存在的研究挑战，并展望了未来的研究方向，以指导和促进针对语言模型的稳健、透明和可解释的XAI方法的发展。", "conclusion": "本综述旨在为语言模型的可解释性人工智能方法的发展提供指导，识别了未来研究的开放挑战，并提出了有前途的研究方向，以促进语言模型的透明性和可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21576", "html_url": "https://arxiv.org/abs/2509.21576", "title": "视觉语言模型不能进行规划，但它们能够进行形式化？", "title_en": "Vision Language Models Cannot Plan, but Can They Formalize?", "authors": "Muyu He,Yuxi Zheng,Yuchen Liu,Zijian An,Bill Cai,Jiani Huang,Lifeng Zhou,Feng Liu,Ziyang Li,Li Zhang", "background": "视觉语言模型（VLMs）的进展使具身代理能够完成简单的多模式规划任务，但无法进行需要长时间序列动作的远期规划。虽然仅通过文本的模拟中远期规划已经取得了显著的进步，特别是在通过重新定位语言模型（LLMs）的角色，使其将规划领域和问题转换为形式化的规划语言（如规划领域定义语言PDDL），以调用形式化求解器生成可验证计划的情况下。然而，在多模态环境中，关于VLM作为形式化模型的研究仍然很少，通常涉及预先定义对象词汇表，或者采用过于相似的少量示例。这篇论文介绍了这种现象不足的地方。", "innovation": "论文提出了五种视觉语言模型作为形式化模型的管道，以解决单次、开放式词汇表以及多模态的PDDL形式化问题，并且该研究第一次针对真实多视角和低质量图像进行了规划。论文发现了瓶颈在于视觉而不是语言，因为视觉语言模型常常无法捕捉到所有必要的对象关系。生成中间文本表示（如标题或场景图）可以部分补偿性能不足，这为未来关于多模态规划形式化的研究指出了方向。", "conclusion": "视觉语言模型作为形式化模型的表现显著优于直接生成计划的方法。视觉语言模型在捕捉必要对象关系方面的能力不足成为瓶颈，虽然生成中间的文本表示可以部分补偿性能，但这一领域仍然存在研究空间。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21487", "html_url": "https://arxiv.org/abs/2509.21487", "title": "Dual-Head Reasoning Distillation: 提升训练时推理的分类器准确性", "title_en": "Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning", "authors": "Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan", "background": "链式思维（CoT）提示通常可以提高分类准确性，但会引入逻辑生成的显著吞吐量惩罚（Wei et al., 2022; Cheng and Van Durme, 2024）。为了缓解这种权衡，该研究引入了双头推理蒸馏（DHRD），这是一种适用于仅解码器语言模型（LMs）的简单训练方法，增加了（i）用于训练和推理的合并分类头以及（ii）仅在训练中由教师逻辑指导的推理头。该方法使用标签交叉熵和输入加逻辑序列的标记级别LM损失加权和作为训练损失函数。在七个SuperGLUE任务上，DHRD相对于合并基线的相对改进为0.65-5.47%，显着更大的改进出现在蕴含/因果任务上。由于在测试时禁用推理头，推理吞吐量与合并分类器匹配，并且在相同的架构上超过了CoT解码96-142倍的QPS（每秒请求数）.", "innovation": "提出了双头推理蒸馏（DHRD）方法，这是一种简单的训练方法，适用于仅解码器语言模型。DHRD引入了两个头，一是用于训练和推理的合并分类头，二是由教师逻辑指导且仅在训练中使用的推理头。通过使用标签交叉熵和输入加逻辑序列的标记级别LM损失加权和，作为训练损失函数，从而在提高分类准确性的同时，避免了CoT提示的吞吐量问题。特别是在蕴含/因果任务上取得了显著的优越性，并能以极高的效率进行推理任务的执行。", "conclusion": "DHRD方法在多个SuperGLUE任务上展示了显著的分类改进，特别是在蕴含和因果类任务上，且推理吞吐量远超传统CoT解码方法，是提高分类器准确性的一种有效方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21613", "html_url": "https://arxiv.org/abs/2509.21613", "title": "多目标强化学习在大规模语言模型优化中的前景展望：多目标强化学习视角", "title_en": "Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective", "authors": "Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers", "background": "多目标强化学习（MORL）在优化大规模语言模型（LLM）的多个目标方面呈现出显著的挑战与机遇。现有文献中探讨了MORL方法应用于LLM优化的优势与局限性，但尚未充分关注高效且灵活的方法，这些方法能够适应LLM和强化学习（RL）固有的多样化与个性化需求。因此，构建一个能够评估不同MORL方法影响多样目标关系的基准框架变得至关重要。", "innovation": "本文提出了一个MORL基准框架的设想，该框架能够评估不同方法对多样化目标关系的影响。此外，研究者还强调了元策略MORL开发的重要性，其通过双层学习范式提高了效率和灵活性，同时明确了提高LLM性能的关键研究问题和潜在解决方案。", "conclusion": "未来的研究方向应侧重于元策略MORL的开发，以通过双层学习范式提高效率和灵活性，并解决MORL在LLM优化中的关键问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21679", "html_url": "https://arxiv.org/abs/2509.21679", "title": "ReviewScore：使用大型语言模型检测误导性同行评审", "title_en": "ReviewScore: Misinformed Peer Review Detection with Large Language Models", "authors": "Hyun Ryu,Doohyuk Jang,Hyemin S. Lee,Joonhyun Jeong,Gyeongman Kim,Donghyeon Cho,Gyouk Chu,Minyeong Hwang,Hyeongwon Jang,Changhun Kim,Haechan Kim,Jina Kim,Joowon Kim,Yoonjeon Kim,Kwanhyung Lee,Chanjae Park,Heecheol Yun,Gregor Betz,Eunho Yang", "background": "同行评审是学术研究的基石，但在大多数AI会议中，随着提交数量的激增，评审质量正在下降。为了可靠地检测低质量的评审，作者定义了误导性评审点，即包含不正确前提的“弱点”或可以直接通过论文回答的问题。研究发现小部分“弱点”和“问题”包含误导性内容，并提出了一个称为ReviewScore的指标来标识一个评审点是否误导性。接着，为了评估每个“弱点”的前提的真实性，作者提出了一种自动化引擎来重建每个显式和隐含的前提。", "innovation": "作者提出了一个名为ReviewScore的指标以自动检测误导性评审点。并通过构建一个专家标注的数据集来检测大型语言模型在自动化这一过程中的能力。此外，作者还发现，评估单个前提的真实性比整个“弱点”的真实性能获得更高的一致性同意率。", "conclusion": "研究指出，尽管存在一定的分歧，但通过评估单个前提的真实性来评定ReviewScore具有更好的一致性。这表明完全自动化的ReviewScore评价有巨大的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21710", "html_url": "https://arxiv.org/abs/2509.21710", "title": "Think-on-Graph 3.0: 通过多智能体双演化上下文检索在异构图上高效且自适应的大语言模型推理", "title_en": "Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval", "authors": "Xiaojun Wu,Cehao Yang,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Hui Xiong,Jia Li,Jian Guo", "background": "检索增强生成 (RAG) 和基于图的 RAG 已成为通过外部知识增强大规模语言模型 (LLMs) 的重要范式。然而，现有方法面临着根本性的权衡：虽然基于图的方法天生依赖于高质量的图结构，但它们面临着严重的实践限制：手动构建的知识图结构规模难以扩大，而从语料库中自动提取的图则受限于底层 LLM 提取器的表现，尤其是在使用较小的、本地部署的模型时。", "innovation": "本论文提出了 Think-on-Graph 3.0 (ToG-3)，一种引入了多智能体上下文进化和检索 (MACER) 机制的新框架，以克服上述限制。我们的核心创新是在推理过程中动态构建和完善一个由片段-三元组-社区异构图索引组成的系统，该系统首次结合了查询和子图的双进化机制，以实现精准的证据检索。此外，ToG-3 采用多智能体系统中的构建者、检索者、反思者和响应者智能体，在迭代过程中合作进行证据检索、答案生成、充分性反思，并进化查询和子图。这种双进化多智能体系统使 ToG-3 能够在推理过程中自适应构建目标图索引，从而弥补静态、一次性图构建的固有缺陷，并允许即使是轻量级的 LLM 也能进行深入的、精准的推理。", "conclusion": "公开试验表明，ToG-3 在深思和广思推理基准测试上的表现优于现有基线，并且消融研究表明了 MACER 框架组件的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21577", "html_url": "https://arxiv.org/abs/2509.21577", "title": "测试我的奶酪？：评估多语言LLM翻译中的文化细微差异", "title_en": "\"Be My Cheese?\": Assessing Cultural Nuance in Multilingual LLM Translations", "authors": "Madison Van Doren,Cory Holland", "background": "该试点研究探索了最先进的多语言AI模型在翻译英语中的比喻语言（如成语和双关语）到各种全球语言中的本地化能力。它扩展了现有的LLM翻译研究和行业基准，这些基准强调语法准确性和标记级正确性，重点关注文化适宜性和整体本地化质量——这些因素对于市场营销和电子商务等实际应用至关重要。为了调查这些挑战，该项目评估了87个LLM生成的跨20种语言24个区域方言的电商营销邮件翻译样本。每种目标语言的熟练人工评审员提供了定量评分和定性反馈，以衡量翻译对原文语调、含义和目标受众的忠实度。研究表明，尽管领先模型通常生成语法正确的翻译，但文化细微差别仍然需要大幅度的人工改进，即使是一些在全球范围内资源丰富的语言，也广泛地错误翻译了喻义表达和语言游戏。这项研究挑战了数据量是机器翻译质量最可靠预测指标的假设，并将文化适宜性作为多语言LLM性能的关键决定因素——目前在现有学术和行业基准中尚未得到充分探索。该试点项目作为一个概念验证，展示了当前多语言AI系统在现实世界本地化用例中的局限性。试点结果支持更大规模研究的机会，以获取可推广的见解，并指导在文化多元背景下部署可靠的机器翻译流程。", "innovation": "这项工作挑战了数据量是机器翻译质量最可靠预测指标的假设，并将文化适宜性作为多语言LLM性能的关键决定因素——这一领域目前在现有学术和行业基准中尚未得到充分探索。这项研究通过评估多语言LLM翻译中的文化细微差异，强调了文化适宜性的关键作用，为未来的研究提供了新的视角。此外，该研究通过具体的数据和案例，展示了在电商营销邮件翻译中遇到的实际挑战，突显了现有系统的局限性。这项工作为未来研究和实践提供了一个起点，特别是在多语言AI系统的部署和调整方面。", "conclusion": "这项试点研究结果表明，虽然领先的模型通常会产生语法正确的翻译，但在文化细腻表达和语言游戏中仍然存在明显的改进空间，这往往需要大量的人工润色。研究表明，文化适宜性是多语言LLM性能的关键因素，而不仅仅是数据量的大小。因此，未来的研究应专注于文化适宜性的改进，以提高机器翻译的整体质量和可靠性。此外，这一研究还揭示了现有多语言AI系统在面对具体翻译任务时的局限性，强调了在不同文化背景下实现可靠机器翻译的必要性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21730", "html_url": "https://arxiv.org/abs/2509.21730", "title": "ProPerSim：通过用户-助手模拟开发先见性和个性化的AI助手", "title_en": "ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation", "authors": "Jiho Kim,Junseong Choi,Woosog Chay,Daeun Kyung,Yeonsu Kwon,Yohan Jo,Edward Choi", "background": "随着大型语言模型（LLMs）在日常生活中的应用逐渐深化，人们对不仅反应式的，还能主动的、个性化的AI助手的需求也在增长。虽然近年来在实现主动性和个性化方面有了一些进展，但这两者相结合的研究仍然很少。ProPerSim是一个新的任务和模拟框架，旨在构建能够根据具体情景和个人偏好，提供及时、个性化建议的助手。", "innovation": "ProPerSim框架是一个用于开发能够在现实家庭场景中提出及时、个性化建议的助手的新任务和模拟环境。通过这个模拟环境，一个具有丰富个性的角色用户与助手互动，根据每个建议与偏好和情境的匹配程度给予评分。助手的目标是利用这些评分来学习和适应，以提高其表现。基于ProPerSim，我们提出了一种检索增强、偏好对齐的助手（ProPerAssistant），通过用户的反馈不断学习和适应。实验结果表明，ProPerAssistant能够根据不同的用户偏好调整策略，逐步提高用户的满意度，展现了将主动性和个性化结合起来的潜力。", "conclusion": "我们的研究发现，通过ProPerSim可以开发出有效的、个性化的AI助手。ProPerAssistant能够在多种用户偏好背景下持续学习和改进，表现出较高的适应性和用户满意度，为未来研究提供了宝贵的经验和证据。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21820", "html_url": "https://arxiv.org/abs/2509.21820", "title": "LLMs是否可以解决和生成语言奥林匹克谜题？", "title_en": "Can LLMs Solve and Generate Linguistic Olympiad Puzzles?", "authors": "Neh Majmudar,Elena Filatova", "background": "本文介绍了一种结合新颖且有趣的任务：语言谜题的解决方案和生成。作者关注的是用于高中生的语文奥林匹克竞赛所使用的谜题。首先，扩展了现有的用于解决语言谜题的任务基准。探索了大型语言模型（LLMs），包括OpenAI的o1等最新最先进的模型，用于解决语言谜题，并分析了它们在各种语言主题上的表现。", "innovation": "文章的一系列创新如下：1. 扩展了解决语言谜题的基准。2. 使用LLMs解决语言谜题，分析它们在不同语言主题上的表现。3. 发现LLMs在大多数谜题类型上优于人类，但在某些书写系统相关的谜题类型和未研究的语言上除外。4. 根据解谜实验中的洞见，提出了生成谜题的新任务。5. 认为自动化生成谜题，即使是最简单的谜题，也有潜力增加对语言学的兴趣，扩大该领域的受众。", "conclusion": "研究结果表明，语言谜题生成任务的重要性：这些谜题不仅可以推广语言学，还可以支持关于罕见和未研究的语言的知识传播。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21732", "html_url": "https://arxiv.org/abs/2509.21732", "title": "LLMs在对话转录多问题回答中的准确性如何？", "title_en": "How Accurate Are LLMs at Multi-Question Answering on Conversational Transcripts?", "authors": "Xiliang Zhu,Shi Zong,David Rossouw", "background": "利用大型语言模型（LLMs）回答基于长文本背景的问题是一个重大挑战，尤其是在工业环境中，处理多问题时高计算成本和延迟使得这一过程变得更加复杂。本研究聚焦于LLMs在同一对话上下文中回答多个问题的能力，通过广泛实验和公共及私有模型的基准测试，评估了该技术的实际应用潜力和局限性。", "innovation": "研究通过对比私有和公共LLMs在多问题回答任务中的表现，展示了即使参数量较少的微调公共模型也能在准确性上超越大型私有模型，展示了透明且成本效益高的部署能力。", "conclusion": "研究发现，虽然GPT-4o等强有力的私有LLMs总体表现最佳，但微调后的公共LLMs，特别是那些具有80亿参数的模型，在精度上能够超越GPT-4o，证明了它们在实际应用中的透明和低成本部署潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21777", "html_url": "https://arxiv.org/abs/2509.21777", "title": "SynerGen：统一搜索与推荐的上下文生成型推荐器", "title_en": "SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation", "authors": "Vianne R. Gao,Chen Xue,Marc Versage,Xie Zhou,Zhongruo Wang,Chao Li,Yeon Seonwoo,Nan Chen,Zhen Ge,Gourab Kundu,Weiqi Zhang,Tian Wang,Qingjun Cui,Trishul Chilimbi", "background": "在大规模推荐系统中，常见的检索后排序管道由于其架构拆分和优化目标不同而存在校准不准确和工程开销的问题。尽管近年来自回归生成序列模型在统一检索与排序中表现出潜力，但现有解决方案通常仅针对个性化搜索或查询推荐，常常在尝试统一两者时出现性能权衡。", "innovation": "我们引入了SynerGen，这是一种新颖的生成推荐模型，它通过提供一个统一的生成主干来同时支持个性化搜索和推荐，同时在检索和排序任务上表现出色。我们使用受行为序列训练的解码器Transformer，利用InfoNCE进行联合检索优化和点式-配对损失进行排序优化，使检索中的语义信号能够提升推荐效果，反之亦然。此外，我们还提出了一种新的时间感知旋转位置嵌入，以有效地将时间信息引入注意力机制。", "conclusion": "SynerGen在广泛采用的推荐和搜索基准测试中取得了显著改进，优于强大的生成推荐器和联合搜索与推荐基线。这项工作展示了单一生成基础模型在大规模统一信息访问中的可行性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21826", "html_url": "https://arxiv.org/abs/2509.21826", "title": "ResT: 重塑令牌级策略梯度以优化工具使用大型语言模型", "title_en": "ResT: Reshaping Token-Level Policy Gradients for Tool-Use Large Language Models", "authors": "Zihan Lin,Xiaohan Wang,Jie Cao,Jiajun Chai,Guojun Yin,Wei Lin,Ran He", "background": "大型语言模型（LLMs）通过调用外部工具超越了被动生成，成为目标导向的代理。强化学习（RL）提供了一种优化这些新兴工具使用策略的理论框架，然而当前范式仅依赖稀疏结果奖励，忽视了工具使用任务的具体性，导致策略梯度方差增大，训练效率降低。", "innovation": "本文建立了策略熵与工具使用任务训练稳定性之间的理论联系，表明结构化、低熵令牌是主要奖励决定因素。受此启示，提出了ResT（Reshaped Token-level Policy Gradients）方法，通过基于熵的令牌重权重，逐步提升推理令牌的权重。该熵感知方案实现了从结构正确性到语义推理的平滑过渡，稳定了多回合工具使用任务中的收敛。评估结果显示，ResT达到了最先进的性能，比先前方法高出8.76%。在4B基础LLM上微调后，ResT在单回合任务上超越GPT-4o 4.11%，在多回合基础任务上超越4.5%。", "conclusion": "ResT 方法通过基于熵的令牌重权重策略梯度，平滑地从结构正确性过渡到语义推理，稳定了多回合工具使用任务中的收敛，并在多个基准上展示了优越的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21740", "html_url": "https://arxiv.org/abs/2509.21740", "title": "Self-Speculative Biased Decoding for Faster Live Translation", "title_en": "Self-Speculative Biased Decoding for Faster Live Translation", "authors": "Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang", "background": "大型语言模型（LLMs）在各种文本生成任务中表现出色，但在流式应用中（如实时翻译），保持实时输出与增加的输入上下文的同步更新，同时保持合理的计算成本以满足低延迟要求仍然是一个挑战。传统的重新翻译方法在这个过程中常常遇到高延迟和不必要的重新生成输出的问题，导致计算资源的浪费和低效性。", "innovation": "本文重新审视了同步翻译中的重翻译方法，并提出了一种新颖的推测性自偏置解码（Self-Speculative Biased Decoding）方法，旨在避免连续增长的输入流中重复生成输出。具体来说，这种方法使用最新的输出作为当前增长输入上下文的草稿，并在验证阶段偏向草稿中的令牌以提高草稿接受率。与传统的推测性解码策略不同，该方法不需进行草稿计算，从而成为一个无需调整且适用于加速敏感流式应用的模型兼容解决方案。实验结果表明，该方法在保持质量的前提下可实现高达1.7倍的加速，同时将闪烁现象显著降低80%。", "conclusion": "通过此方法，不仅实现了快速度，还降低了闪烁现象，保证了实时翻译的质量，证明了其在流式应用中的有效性和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21849", "html_url": "https://arxiv.org/abs/2509.21849", "title": "随TRACE前行：基于多智能体模型的结构化共情响应生成之路", "title_en": "Following the TRACE: A Structured Path to Empathetic Response Generation with Multi-Agent Models", "authors": "Ziqi Liu,Ziyang Zhou,Yilin Li,Haiyang Zhang,Yangbin Chen", "background": "共情响应生成是创建更具人类特性和支持性的对话代理的关键任务。但现有方法在专业模型的分析深度和大型语言模型（LLMs）的生成流畅性之间面临核心权衡。", "innovation": "本文提出了TRACE框架，一种新的结构化认知过程框架，通过将任务分解为分析和合成管道，将深入分析与表达生成结合。该框架展示了比强基线在自动和LLM评估中显著更好的性能，证明了这种结构化分解是创建更具能力和可解释性的共情代理的一种有前景的范式。", "conclusion": "该框架在其生成之前构建了全面的理解，这显著提升了共情响应的质量。相关代码可从以下链接获得：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21791", "html_url": "https://arxiv.org/abs/2509.21791", "title": "通过因果推理导航结构化输出格式对大型语言模型的影响", "title_en": "Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference", "authors": "Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma", "background": "大型语言模型（LLMs）生成的结构化输出提升了处理生成信息的效率，并在工业应用中得到越来越多的采用。前期研究探讨了结构化输出对LLMs生成质量的影响，但多呈现单向效果。研究意见分歧，部分认为结构化格式能提高完整性和事实准确性，而另一些则认为这限制了LLMs的推理能力，导致标准评价指标下降。这些评估的局限性在于受限的测试场景、受控程度较低的比较设置以及依赖粗略的评价指标。", "innovation": "本文通过因果推理进行了深入分析，基于一个假定和两个保证的约束条件，推导出五种潜在的因果结构，以描述结构化输出对LLMs生成的影响：包括无m-偏见的碰撞器、有m-偏见的碰撞器、指令单因、输出格式单因以及独立性。研究在七个公开和一个开发的推理任务中发现，粗略指标报告了GPT-4o生成中结构化输出的正、负或中性影响，但因果推理在48个场景中有43个未发现因果影响，在剩余的5个场景中，3个涉及由具体指令导致的复杂因果结构。", "conclusion": "因果推理方法表明，结构化输出对LLMs生成的影响可能比较复杂，具体作用依赖于任务特性与其他因素的交互情况，在大多数情况下并未发现明显的因果效应。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21801", "html_url": "https://arxiv.org/abs/2509.21801", "title": "重新定义机器同步口译：从增量翻译到类似人类的策略", "title_en": "Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies", "authors": "Qianen Zhang,Satoshi Nakamura", "background": "基于传统编码器-解码器策略的机器同步翻译（SiMT）需要在严格的时间限制内提供高质量的翻译，而传统的策略仅有READ/WRITE操作，无法满足这一需求。因此，论文探讨了如何通过扩展解码器的操作空间来改进SiMT，并实现在大规模语言模型框架下的翻译操作，以更好地适应实时环境并保持意义的准确性和翻译的流畅性。", "innovation": "论文提出了四种新的适应性操作：SENTENCE_CUT（断句）、DROP（删除）、PARTIAL_SUMMARIZATION（部分内容总结）和PRONOMINALIZATION（代词化处理）。这些操作允许在实时环境中进行重排、删除和简化，同时保持语义的一致性。同时，通过行动意识提示构建训练参考，并开发了一个具有超时感知的TTS管道，来评估翻译质量和延迟。实验结果显示，论文提出的框架在平均延迟方面优于参考翻译和意大利辣香肠方法，特别是在结合使用DROP和SENTENCE_CUT操作时，能够最优地平衡流畅性和延迟。", "conclusion": "扩展大规模语言模型框架下的SiMT操作空间为人类理解和机器理解之间的差距提供了一个有前景的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21805", "html_url": "https://arxiv.org/abs/2509.21805", "title": "向人类多模态语言理解的最小因果表示迈进", "title_en": "Towards Minimal Causal Representations for Human Multimodal Language Understanding", "authors": "Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai", "background": "人类多模态语言理解（MLU）旨在通过综合不同模态的相关线索来推断人类意图。现有的工作主要遵循“学习关注”范式，通过最大化数据与标签之间的互信息来提高预测性能。然而，这些方法容易受到未预期的数据集偏差的影响，导致模型将统计捷径误认为是真实的因果特征，从而导致在离分布（OOD）上的性能下降。鉴于此问题，该研究提出了一种因果多模态信息瓶颈（CaMIB）模型，该模型利用因果原则而非传统似然性进行建模。", "innovation": "该研究引入了一种因果多模态信息瓶颈（CaMIB）模型，首先利用信息瓶颈过滤单一模态输入，去除与任务无关的噪声。接着，通过参数化的掩码生成器将融合的多模态表示分解为因果亚表示和捷径亚表示。为了确保因果特征的一致性，研究中引入了工具变量约束，并通过随机重组因果和捷径特征来实现回门调整，以稳定因果估计。这些方法在多种多模态情感分析、幽默检测和讽刺检测任务中以及离分布测试集上进行了广泛实验，证实了CaMIB的有效性，并提供了理论和经验分析表明其可解释性和可靠性。", "conclusion": "实验结果表明CaMIB模型在多模态情感分析、幽默检测和讽刺检测任务上以及离分布测试集上都表现出了有效性。理论和经验分析进一步突出了其可解释性和可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21837", "html_url": "https://arxiv.org/abs/2509.21837", "title": "语义一致使高效开放生成的LLM级联成为可能", "title_en": "Semantic Agreement Enables Efficient Open-Ended LLM Cascades", "authors": "Duncan Soiffer,Steven Kolawole,Virginia Smith", "background": "级联系统在可能时将计算请求路由到较小的模型并在必要时仅递归到较大的模型，为平衡LLM部署中的成本和质量提供了一种前景广阔的方法。然而，在开放生成文本时，它们面临一个根本性的挑战：在生成质量在连续光谱上时，判断输出可靠性，通常有多个有效响应。", "innovation": "提出了一种语义一致性方法——作为无训练信号，用于可靠下分。当多元模型输出在语义层面达成一致时，这种一致比基于token级别的置信度更能作为可靠性信号。我们的方法在从500M到70B参数模型中得到了评估，显示出语义级联在40%的成本下可以达到或超过目标模型的质量，并且将延迟最多减少60%。我们方法不需模型内部信息，可在黑盒API上使用，并且对外部模型更新保持稳健，为其提供了成为实际部署实用基准的潜力。", "conclusion": "我们的方法不需模型内部信息，可在黑盒API上使用，并且对外部模型更新保持稳健，不依赖于任何训练过程，并可用于实际部署。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21798", "html_url": "https://arxiv.org/abs/2509.21798", "title": "评估和改进用于LLM对齐的奖励模型文化意识", "title_en": "Evaluating and Improving Cultural Awareness of Reward Models for LLM Alignment", "authors": "Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang", "background": "近年来，大型语言模型（LLMs）在多种文化背景下的表现引人关注，奖励模型（RMs）在此过程中扮演着关键角色。然而，现有的评价体系在衡量模型的文化意识方面存在不足，主要由于缺乏相关的文化评价数据集。本研究旨在填补这一空白，提出了一个涵盖10种不同文化，分布在4个文化领域的新颖基准——文化感知奖励模型基准（CARB），以推动LLMs在全球范围内的对齐。", "innovation": "研究者们提出了一个新的评估基准CARB，该基准覆盖了十个不同的文化领域，旨在填补现有评价体系在文化意识评估方面的不足。此外，研究揭示了当前文化驱动的奖励模式存在的表面特征偏好问题，提出了通过加强学习及验证奖励（RLVR）诱导生成式奖励模型深挖文化解读等创新方法。", "conclusion": "研究结果证实，通过CARB基准可以有效减少错误特征的干扰，并促进文化感知的奖励模型发展。同时，提出的Think-as-Locals方法有助于生成更深层次的文化背景下的合理偏好判断和高质量结构化的评价标准，进一步提升文化感知奖励模型的准确性和质量。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21870", "html_url": "https://arxiv.org/abs/2509.21870", "title": "使用结构化非线性变换增强低秩适应", "title_en": "Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations", "authors": "Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song", "background": "低秩适应（LoRA）是一种广泛采用的参数高效微调方法，用于大型语言模型。然而，其线性性质限制了其表达能力。为此，作者提出了一种名为LoRAN的方法，这是一种非线性的LoRA扩展，通过轻量级变换应用于低秩更新。此外，作者还引入了一种基于正弦的激活函数Sinter，它在不增加参数数量的情况下添加结构化扰动。实验表明，LoRAN在摘要和分类任务中均优于QLoRA。进一步的消融研究发现，Sinter在各种标准激活函数（如Sigmoid、ReLU和Tanh）中表现更好，突显了低秩微调中激活设计的重要性。", "innovation": "提出了LoRAN，一种用于大型语言模型的非线性低秩适应方法，该方法通过轻量级变换应用于低秩更新。同时，引入了Sinter激活函数，这是一种基于正弦的激活函数，能够在不增加参数数量的情况下提供结构化扰动。", "conclusion": "实验表明LoRAN在多个任务上优于QLoRA，并且消融研究表明Sinter激活函数表现优于标准激活函数，突显了激活设计在低秩微调中的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21856", "html_url": "https://arxiv.org/abs/2509.21856", "title": "KnowMT-Bench: 用于多轮对话的知识密集型长形式问答基准", "title_en": "KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering in Multi-Turn Dialogues", "authors": "Junhao Chen,Yu Huang,Siyuan Li,Rui Yao,Hanqian Li,Hanyu Zhang,Jungang Li,Jian Chen,Bowen Wang,Xuming Hu", "background": "当前评估语言模型（LLMs）在知识密集型领域中的多轮长形式问答（Multi-Turn Long-Form Question Answering，MT-LFQA）的基准测试有限，大多关注的是单轮对话，或者评估其他与知识无关的能力。现有的基准工具尚无法全面系统地评估MT-LFQA模型在包括医学、金融和法律等领域的性能。知MT-Bench设计用于系统地评估LLMs在这些领域的MT-LFQA能力，采用动态生成的多轮对话历史记录来真实地评估模型的表现。", "innovation": "首次提出了知MT-Bench这一基准工具，用于多轮对话的知识密集型长形式问答评估。通过模拟真实对话情境，评估模型的最后回复在事实准确性与信息交付效率方面的表现。研究表明，多轮上下文会降低模型的性能和效率，但引入检索增强生成（RAG）技术可以帮助缓解这一问题。知MT-Bench填补了当前在评估和提升LLMs在知识密集型应用中的对话事实准确性方面的空白。", "conclusion": "知MT-Bench的研究发现强调了在实际知识密集型应用中评估和提升LLMs对话事实准确性的基准测试的重要性。随着这些技术的发展，这些发现对实际应用具有重要意义，并促进了这一领域的进一步研究与实践。相关代码可在 \texttt{KnowMT-Bench} 可以获取。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21932", "html_url": "https://arxiv.org/abs/2509.21932", "title": "SimulSense: 基于感知的高效同时同声传译", "title_en": "SimulSense: Sense-Driven Interpreting for Efficient Simultaneous Speech Translation", "authors": "Haotian Tan,Hiroki Ouchi,Sakriani Sakti", "background": "当前最先进的人机结合同时同声传译（SimulST）系统将SimulST视为一个多轮对话任务，并且需要专项交错训练数据以及依靠计算密集型大语言模型（LLM）推理来做出决策。", "innovation": "提出了一种新的框架SimulSense，该框架模拟人类口译员的行为，持续阅读输入的口语，并在感知到新的感知单元时触发写决策。实验表明，SimulSense在质量和延迟的权衡上表现出色，并且具有显着的实时效率改进，其决策机制比基线方法快9.6倍。", "conclusion": "SimulSense框架能够显著提高同时同声传译的实时效率，同时在翻译质量方面不会有显著下降，在多轮对话任务中表现出良好的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21875", "html_url": "https://arxiv.org/abs/2509.21875", "title": "LUMINA：基于上下文-知识信号检测RAG系统中的幻觉", "title_en": "LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals", "authors": "Min-Hsuan Yeh,Yixuan Li,Tanwi Mallick", "background": "检索增强生成（RAG）旨在通过将响应置于检索到的文档中来减轻大规模语言模型（LLMs）中的幻觉现象。然而，即使在提供正确和足够上下文的情况下，基于RAG的LLMs仍然会出现幻觉。已有研究表明，这可能是由于模型在使用外部上下文和内部知识之间存在不平衡所致，已有多种方法尝试量化这些信号以进行幻觉检测。但现有方法需要大量的超参数调优，这限制了它们的普适性。\n", "innovation": "本文提出了一种名为LUMINA的新框架，该框架通过上下文-知识信号来检测RAG系统的幻觉：外部上下文利用通过分布距离量化，内部知识利用通过跟踪预测tokens如何在transformer层中演进来衡量。此外，还引入了一个统计验证这些测量的标准框架。实验结果表明，LUMINA在HalluRAG等常见的RAG幻觉基准和四种开源LLMs上实现了持续的高AUROC和AUPRC分数，相比基于利用的方法，在AUROC上最多提高了13%。此外，LUMINA在降低检索质量和模型匹配假设的宽松条件下保持稳健，提供了有效性和实用性。\n", "conclusion": "LUMINA通过上下文-知识信号验证的方法实现了在检测RAG系统的幻觉方面的新突破，相较于现有方法，具有更高的准确性和鲁棒性，并且更加实用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21910", "html_url": "https://arxiv.org/abs/2509.21910", "title": "AutoSCORE：通过结构化组件识别增强基于多代理大型语言模型的自动化评分", "title_en": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "authors": "Yun Wang,Zhaojun Ding,Xuansheng Wu,Siyue Sun,Ninghao Liu,Xiaoming Zhai", "background": "自动化评分在教育中起着关键作用，通过减少对人工评分员的依赖，提供可扩展和即时的学生作品评估。尽管大型语言模型（LLM）在这一任务中表现出强大的潜力，但它们作为端到端评分员的应用面临低准确度、指令敏感性、有限的可解释性和评分标准对齐等问题，这些难题阻碍了基于LLM的自动化评分在评估实践中的应用。", "innovation": "本文提出了一种基于多代理的大型语言模型框架AutoSCORE，利用结构化组件识别来增强自动化评分。该框架包含两个代理：一个组件抽取代理负责从学生回答中提取与评分标准相关的内容，并将它们编码为结构化表示；另一个评分代理使用这些信息来赋分。这种设计确保了模型推理遵循类似人类评分的过程，增强了可解释性和稳健性。", "conclusion": "在来自ASAP基准的四个基准数据集上进行评估，AutoSCORE在任务和评分标准变化时保持了评分准确度的提高、人机一致性的提升（QWK，相关性），以及在误差指标（MAE，RMSE）上的改善，尤其在复杂的、多维度的评分标准上表现尤为突出，特别是在较小的LLM中获得了相对较大的改进。这些结果表明，结合结构化组件识别的多代理设计为自动化评分提供了一个可扩展、可靠和可解释的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21889", "html_url": "https://arxiv.org/abs/2509.21889", "title": "QoNext: 向下一代基础模型的体验质量迈进", "title_en": "QoNext: Towards Next-generation QoE for Foundation Models", "authors": "Yijin Guo,Ye Shen,Farong Wen,Junying Wang,Zicheng Zhang,Qi Jia,Guangtao Zhai", "background": "现有的对基础模型的评价方法，包括最近的人本导向的方法在内，都无法捕捉到真正重要的因素：用户在互动过程中的体验。当前的评价方法过分关注输出的正确性，而忽视了用户满意度是由响应质量和互动过程中的多方面因素共同产生的。这限制了评价方法对用户体验背后机制的解释能力。", "innovation": "我们提出了QoNext，这是第一个将网络和多媒体中的体验质量（QoE）原则应用于基础模型评估的框架。QoNext通过识别影响用户体验的体验性因素，并将这些因素整合到受控实验中，从而收集人类对不同配置下的评价。在此基础上，QoNext构建了一个QoE导向的数据集，并训练预测模型，以从可测量的系统参数中估算感知用户体验。", "conclusion": "我们的结果表明，QoNext不仅能实现前瞻性和精细化的评估，还能为实际产品化服务提供优化基础模型的具体指导。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21880", "html_url": "https://arxiv.org/abs/2509.21880", "title": "不落下一个提示：通过熵导向的优势重塑利用零方差提示在LLM强化学习中的潜力", "title_en": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping", "authors": "Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang", "background": "当前的强化学习方法，如GRPO，仅依赖于模型响应相同的输入，但正确性不同的问题，而忽略了所有响应获得相同奖励的问题，称为零方差提示。这些方法认为零方差提示是无用的。然而，这项研究指出，这些提示实际上可以提供有意义的反馈，以优化策略，并为强化学习中的零方差提示提供了新的利用角度和方法。", "innovation": "提出了一种名为RL-ZVP的新型算法，可以从零方差提示中提取学习信号。RL-ZVP直接奖励正确性和惩罚错误，即使没有对比响应，也通过token级别的特征调节反馈，保持具有信息性和细微差别的信号。研究对比了RL-ZVP与其他过滤掉零方差提示的方法，证明了利用零方差提示在强化学习中的有效性并提供了显著提升。这项研究提出了新的方法来利用零方差提示，以优化大型语言模型的策略并改善其推理能力。", "conclusion": "研究结果表明，利用零方差提示在强化学习中具有显著的潜力，通过熵导向的优势重塑可以实现显著的准确性提升，其中在六个数学推理基准测试上，与GRPO相比，精度提高了8.61分，通过率提高7.77分，且一致性地超越了其他过滤掉零方差提示的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21892", "html_url": "https://arxiv.org/abs/2509.21892", "title": "弹性MoE：解锁Mixture-of-Experts的推理时伸缩性", "title_en": "Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts", "authors": "Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang", "background": "Mixture-of-Experts (MoE)模型通常在训练和推理时固定激活专家的数量k。尽管直觉上认为在推理时激活更多的专家$k'$（其中$k' > k$）意味着更大参数计算量，应当提高性能，但我们发现性能提升的范围非常狭窄，性能在专家数量稍有增加后就会迅速下降。进一步研究发现，这种性能下降源于专家之间缺乏学习到的合作机制。", "innovation": "我们引入了弹性混合专家模型（EMoE），这是一种新颖的训练框架，能够在推理时动态调整激活的专家数量而不增加训练开销。通过同时训练专家以进行多样化组合协作，并促进路由器进行高质量选择，EMoE确保推理时在不同计算预算下的性能稳定性。实验结果表明，EMoE显著扩展了性能可扩展范围，将其扩展到训练时间k的2-3倍，并提高了模型的最大性能水平。", "conclusion": "我们的研究表明，EMoE在不同的MoE设置下进行了广泛实验。结果表明，EMoE显著扩大了有效性能可扩展范围，将其扩展到训练时k的2-3倍，并且提高了模型的峰值性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21749", "html_url": "https://arxiv.org/abs/2509.21749", "title": "以声音思考：音频链式思考使大型音频语言模型能够进行多模态推理", "title_en": "Thinking with Sound: Audio Chain-of-Thought Enables Multimodal Reasoning in Large Audio-Language Models", "authors": "Zhen Xiong,Yujun Cai,Zhecheng Li,Junsong Yuan,Yiwei Wang", "background": "近期，大型音频语言模型（LALMs）在诸如语音翻译和音频问答等多样的音频理解任务中表现突出。然而，它们在复杂声学场景下的挑战性音频推理任务中表现出明显的局限性。现有的LALMs缺乏访问音频工具如噪声抑制、源分离及精确时间对齐等的能力，这限制了它们在复杂声学场景中的性能。", "innovation": "本文提出了一种称为Thinking-with-Sound (TwS)的新框架，该框架通过结合语言推理与实时音频领域的分析，使LALMs具有音频链式思考（Audio CoT）的能力。与现有方法将音频视为静态输入不同，TwS允许模型主动地使用音频信号进行思考，通过多模态推理来执行数值分析和数字操作。", "conclusion": "实验表明，最先进的LALMs在MELD-Hard1k基准测试中的表现出现了超过50%的显著下降。而使用TwS，小型模型获得了24.73%的绝对准确率提升，并且大型模型的提升可达36.61%，这证实了Audio CoT在不重新训练的情况下显著增强系统鲁棒性的能力和可扩展性。这些发现为开发更鲁棒的音频理解系统提供了新的方向。”"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21907", "html_url": "https://arxiv.org/abs/2509.21907", "title": "使用大型语言模型的大型规模数据集和土耳其语引文意图分类", "title_en": "A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs", "authors": "Kemal Sami Karaca,Bahaeddin Eravcı", "background": "深入理解引文的定性意图对于全面评估学术研究至关重要，尤其是在如土耳其语这类粘附语语言中，这是一个极具挑战性的任务。", "innovation": "本论文介绍了一种系统的方法和基础数据集来解决这个问题。提出了一种新的、公开可用的土耳其语引文意图数据集，并用一个专用的注释工具创建。同时，通过引入基于DSPy框架的编程分类流水线，实现系统化提示优化，最终使用包含XGBoost元模型的集成分类器，实现了91.3%的准确率，解决了传统方法中由于手动设计提示导致的一致性不足问题。", "conclusion": "本研究为土耳其语自然语言处理社区和更广泛的学术界提供了基础数据集和一个稳健的分类框架，为未来的定性引文研究铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22041", "html_url": "https://arxiv.org/abs/2509.22041", "title": "全面临床代理安全分类法", "title_en": "Taxonomy of Comprehensive Safety for Clinical Agents", "authors": "Jean Seo,Hyunkyung Lee,Gibaeg Kim,Wooseok Han,Jaehyo Yoo,Seungseop Lim,Kihun Shin,Eunho Yang", "background": "在临床聊天机器人的应用中，安全性是至关重要的，因为不准确或有害的回复可能会导致严重后果。现有的方法，如护栏和工具调用，往往难以应对临床领域中复杂的安全需求。", "innovation": "本研究提出了TACOS（临床代理综合安全分类法），这是一种细粒度的21类分类法，它可以将安全筛选和工具有机地整合到一个用户意图分类步骤中，覆盖广泛的临床和非临床查询，并明确建模不同的安全阈值和外部工具依赖性。", "conclusion": "通过构建TACOS标注数据集并进行广泛的实验，研究结果表明，为临床代理环境专门设计的新分类法具有很高的价值，并揭示了训练数据分布和基模型预训练知识的有用见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22054", "html_url": "https://arxiv.org/abs/2509.22054", "title": "Fuzzy Reasoning Chain (FRC): 从模糊到清晰的创新推理框架", "title_en": "Fuzzy Reasoning Chain (FRC): An Innovative Reasoning Framework from Fuzziness to Clarity", "authors": "Ping Chen,Xiang Liu,Zhaoxiang Liu,Zezhou Chen,Xingpeng Zhang,Huan Hu,Zipeng Wang,Kai Wang,Shuming Shi,Shiguo Lian", "background": "随着大规模语言模型（LLMs）的迅速发展，自然语言处理（NLP）取得了显著进展。然而，处理具有模糊性、多义性或不确定性文本的问题依然存在巨大挑战。", "innovation": "本文提出了Fuzzy Reasoning Chain (FRC)框架，该框架将LLM语义先验与连续的模糊隶属度度量相结合，实现基于概率的推理与模糊隶属度推理之间的明确互动。FRC允许对模糊输入进行逐步转化，提供清晰可解释的决策，并捕捉传统基于概率的方法无法处理的冲突或不确定信号，从而提高了解释性和鲁棒性。", "conclusion": "FRC框架在情感分析任务上的验证结果表明，它能确保推理的稳定性，促进不同模型规模之间的知识迁移。这些发现表明，FRC能够提供一种管理细微和模糊表达的一般机制，并且具备更好的解释性和鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22072", "html_url": "https://arxiv.org/abs/2509.22072", "title": "正确进行模型编辑的微调", "title_en": "Fine-tuning Done Right in Model Editing", "authors": "Wanli Yang,Fei Sun,Rui Tang,Hongyu Zang,Du Su,Qi Cao,Jingang Wang,Huawei Shen,Xueqi Cheng", "background": "长期以来，微调被认为是不适合作为大规模语言模型的适应方法。文章挑战了这一观点，认为报道的失败并非源自微调本身的能力限制，而是对微调方法进行序贯编辑任务的不当调整和单次深度优先的迭代方式。这种方法在优化每个样本时会导致过度优化，从而在编辑之间造成干扰。", "innovation": "文章介绍了一种新的基于重新调整的标准广度优先（即基于epoch）的微调框架的局部调整方法——LocFT-BF。通过实验证明，这种新方法相对于现有的编辑方法，在各种LLM和数据集上都表现出显著的优越性，并且可以处理10万次编辑和72亿参数的模型，超出之前的实践10倍，且不牺牲通用能力。", "conclusion": "文章澄清了一个长久以来的误解，并引入了一种原理性的局部调整策略，将微调从一个被低估的基础方法转变为模型编辑的领先方法，为未来的研究打下了坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22064", "html_url": "https://arxiv.org/abs/2509.22064", "title": "NLP系统评估中标准质量标准名称和定义的QCET分类学", "title_en": "The QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems", "authors": "Anya Belz,Simon Mille,Craig Thomson", "background": "先前的研究表明，报告相同质量标准指标（例如流畅性）结果的两个NLP评估实验，并不一定评估相同的质量方面，这种由名称暗示的可比性可能是误导性的。不了解在何种意义上两个评估是可比的，意味着我们当前无法基于多次独立执行的评估得出可靠关于系统质量的结论。这反过来阻碍了整个领域科学前进的能力，自NLP成立以来就是一个普遍存在的问题（Sparck Jones, 1981）。很难想象如何完全解决模糊可比性的问题，除非通过创建一套标准的质量标准名称和定义，来将实际在NLP领域中使用的数百个质量标准名称映射到并与其契合。", "innovation": "QCET Quality Criteria for Evaluation Taxonomy 通过从三个关于NLP评估报告的调查中得出一套标准的质量标准名称和定义，并将它们结构化为一个层级体系，其中每个父节点捕捉其子节点的共同特征，提供了一种严格描述的方法来解决可比性的模糊性问题。", "conclusion": "论文展示了QCET及其包含的资源，并讨论了其三个主要用途：（i）建立现有评估的可比性；（ii）指导新评估的设计；（iii）评估法规符合情况。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22055", "html_url": "https://arxiv.org/abs/2509.22055", "title": "RedNote-Vibe: 用于捕捉社交媒体中AI生成文本时间动态的数据集", "title_en": "RedNote-Vibe: A Dataset for Capturing Temporal Dynamics of AI-Generated Text in Social Media", "authors": "Yudong Li,Yufei Sun,Yuhan Yao,Peiru Yang,Wanyue Li,Jiajun Zou,Yongfeng Huang,Linlin Shen", "background": "大型语言模型（LLMs）的普及在社交媒体平台上催生了大量的AI生成文本（AIGT），这带来了内容动态变化的挑战，这些动态受到用户参与的驱动并且随着时间发生演变。现有的数据集主要集中在静态的AIGT检测上。", "innovation": "1. 介绍了RedNote-Vibe，这是首个时间跨度长达5年的社交媒体AIGT分析数据集。\r\n2. 数据集来源于小红书平台，包含用户参与度指标（点赞、评论等）和时间戳，覆盖了从LLM之前时期到2025年7月的时间段，这使研究能够探索AIGT的时间动态和用户交互模式。\r\n3. 提出了PsychoLinguistic AIGT检测框架（PLAD），这是一种可解释的方法，利用了心理语言学特征来检测社交媒体中的AIGT。实验结果表明，PLAD在检测性能上表现更优，并揭示了语言特征和社会媒体互动之间的复杂关系。", "conclusion": "RedNote-Vibe数据集和PLAD检测框架为研究社交媒体中的AI生成文本提供了新的视角和方法，展现了语言特征与社会媒体参与度之间的复杂关系，并提供了区分人类和AI生成内容的特征线索。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21999", "html_url": "https://arxiv.org/abs/2509.21999", "title": "通过不确定表达的一致性实现黑箱幻觉检测", "title_en": "Black-Box Hallucination Detection via Consistency Under the Uncertain Expression", "authors": "Seongho Joo,Kyungmin Min,Jahyun Koo,Kyomin Jung", "background": "尽管近年来语言模型取得了很大的进步，但大型语言模型（LLMs）如GPT3在生成非事实性回答方面仍然出名，这些问题被称为“幻觉”问题。目前解决这一幻觉问题的方法需要依赖外部资源或内部状态（例如每个标记的输出概率），但在LLM的外部API有限以及外部资源有限的情况下，迫切需要建立黑箱方法作为有效幻觉检测的核心", "innovation": "本文提出了一种简单且基于黑箱的幻觉检测指标，该指标通过考察LLM在表达不确定性时的行为。研究发现，当LLM给出事实性回答时，其生成的回答具有一致性，而非事实性回答则不一致。基于此分析，提出了一种利用不确定性表达的高效黑箱幻觉检测指标。实验证明，该指标对于预测模型回答的真实性比那些使用LLM内部知识的基准指标更有效", "conclusion": "我们的实验表明，提出的基于不确定性表达的一致性的黑箱幻觉检测指标比基于LLM内部知识的基准指标更能预测模型回答的真实性"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21978", "html_url": "https://arxiv.org/abs/2509.21978", "title": "MotivGraph-SoIQ: Integrating Motivational Knowledge Graphs and Socratic Dialogue for Enhanced LLM Ideation", "title_en": "MotivGraph-SoIQ: Integrating Motivational Knowledge Graphs and Socratic Dialogue for Enhanced LLM Ideation", "authors": "Xinping Lei,Tong Zhou,Yubo Chen,Kang Liu,Jun Zhao", "background": "大型语言模型（LLMs）具有加速学术理念产生的重要潜力，但存在关键挑战，包括优化理念的落地实施与减轻确认偏差。当前的LLM面临难以初设出全面且科学的理念，并有可能导致偏见，影响后续改进。", "innovation": "该文提出了一种新的框架MotivGraph-SoIQ，结合了动机知识图谱与苏格拉底式对话，旨在改善LLM在理念生成中的应用。MotivGraph通过存储问题、挑战和解决方案三种关键节点来提供理念动机的结构支持；Q-Driven Socratic Ideator利用苏格拉底式提问机制，促进严格的改进过程，减少确认偏差，提高理念的创新性、实验严谨性和动机合理性。在ICLR25主题论文数据集上，MotivGraph-SoIQ在LLM评分、ELO排名和人类评估方面均优于现有的先进方法。", "conclusion": "MotivGraph-SoIQ框架通过集成动机知识图谱和苏格拉底式对话，提高了LLM理念生成的有效性和质量，并在多个评估指标中表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22009", "html_url": "https://arxiv.org/abs/2509.22009", "title": "GraphSearch: 一种用于图检索增强生成的具有代理深度搜索的工作流", "title_en": "GraphSearch: An Agentic Deep Searching Workflow for Graph Retrieval-Augmented Generation", "authors": "Cehao Yang,Xiaojun Wu,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Jia Li,Hui Xiong,Jian Guo", "background": "现有的图检索增强生成（GraphRAG）方法存在两个核心局限：浅层检索无法呈现所有关键证据，以及难以有效利用预先构建的结构化图数据，这阻碍了对复杂查询的有效推理。因此，亟需解决方案来解决这些问题，以提升LLM的图推理能力。", "innovation": "提出了一种名为\textsc{GraphSearch}的新颖代理深度搜索工作流，该工作流采用双通道检索策略，既能处理基于片段的文本数据的语义查询，也能处理结构化图数据的关系查询，从而综合使用两种模式，并利用其互补优势。这一方法通过模块化框架支持多轮交互和迭代推理。实验结果表明，\textsc{GraphSearch}在六个多次跳的RAG基准测试中持续提高了答案准确性与生成质量，证明了其作为图检索增强生成改进方向的潜力。", "conclusion": "研究表明，\textsc{GraphSearch}能够在多个RAG基准测试中提高答案准确性和生成质量，证明了其作为图检索增强生成领域重要改进方向的可行性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22030", "html_url": "https://arxiv.org/abs/2509.22030", "title": "从异常值到话题：语言模型中预测新闻语料趋势", "title_en": "From Outliers to Topics in Language Models: Anticipating Trends in News Corpora", "authors": "Evangelia Zve,Benjamin Icard,Alice Breton,Lila Sainero,Gauvain Bourgne,Jean-Gabriel Ganascia", "background": "本文探讨了在主题建模中通常被视为噪声的异常值实际上如何作为动态新闻语料库中新兴话题的弱信号。通过使用最先进的语言模型的向量嵌入和累计聚类方法，我们跟踪了异常值在法语和英语新闻数据集中的演变，这些数据集聚焦于企业社会责任和气候变化。研究结果表明，异常值倾向于在两种模型和语言中随时间演变成一致的主题模式。", "innovation": "本文创新在于它利用最先进的语言模型向量嵌入和累计聚类方法来识别和追踪动态新闻语料库中可能代表新兴话题的异常值，从而提供了对未来趋势的预测能力。这种识别方法超越了传统的只将异常值视为噪声的观点，展示了它们作为弱信号的独特价值。", "conclusion": "研究表明，异常值在企业社会责任和气候变化相关新闻数据集中往往随着时间的推移演变为可识别的主题。这种方法揭示了一种一致的模式，表明可以利用异常值发现和跟踪数据流中的动态趋势，为未来的研究和应用提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21946", "html_url": "https://arxiv.org/abs/2509.21946", "title": "通过反事实校准消除泰语政治观点检测中大语言模型的偏见", "title_en": "Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration", "authors": "Kasidit Sermsri,Teerapong Panboonyuen", "background": "在低资源和文化复杂的环境中，政治立场检测对大型语言模型（LLMs）形成了一项关键挑战。泰国的政治环境复杂，包含间接语言、极化人物以及情感和立场的交织，这导致LLMs常常表现出系统性偏见，如情感泄露和对特定实体的偏爱。这些偏见破坏了公平性和可靠性。现有的解决方法大多需要对模型进行微调，但这并不适用于所有模型。本文则提出了一种无需微调的轻量级、模型无关的校准框架ThaiFACTUAL，用于减少政治偏见。ThaiFACTUAL利用反事实数据增强和基于理据的监督来分离情感和立场，并减少偏见。为支撑这一工作，研究还构建了第一个高质量的泰语政治立场数据集，该数据集对多元实体和事件进行了标注，包括立场、情感、理据及偏见标记。实验证明，ThaiFACTUAL显著减少了无标记情况下的错误关联，增强了零样本推广性能，并提高了公平性。", "innovation": "提出了ThaiFACTUAL，这是一种轻量级、模型无关的校准框架，能够在不需模型微调的情况下减少政治偏见。该框架通过反事实数据增强和基于理据的监督来分离情感和立场，从而减少偏见。此外，该研究还构建了首个高质量的泰语政治立场数据集，包含了对多种实体和事件的标注，包括立场、情感、理据及偏见标记。", "conclusion": "本文强调了在欠代表语言中使用文化根基扎实的去偏见技术的重要性，ThaiFACTUAL显著减少了无标记情况下的错误关联，增强了零样本推广性能，并提高了多种大语言模型的公平性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22131", "html_url": "https://arxiv.org/abs/2509.22131", "title": "R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning", "title_en": "R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning", "authors": "Hongyu Shan,Mingyang Song,Chang Dai,Di Liang,Han Chen", "background": "全语言模型（LLMs）在处理复杂推理时，可以通过Chain-of-Thought (CoT)提示生成显式步骤化解释，但CoT的冗余增加了延迟和内存使用，并可能在链条中传播早期错误。因此，需要一种框架结合潜在推理的效率和显式CoT的透明度。", "innovation": "提出了一种名为Reasoning Capsule (R-Capsule)的框架，旨在将高级计划压缩成一组学习潜在令牌（Reasoning Capsule），同时保持执行步骤的轻量化或显式表示。这种混合方法受到信息瓶颈（IB）原则的启发，通过低容量瓶颈鼓励胶囊尽量简约但又足够完成任务。并通过双重目标优化策略，辅助重建目标鼓励胶囊准确表示原文本计划，从而构建一个平衡效率、准确性和可解释性的框架。", "conclusion": "这种框架在复杂基准测试上保持或提高了准确性，同时减少了推理的可见标记足迹。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21933", "html_url": "https://arxiv.org/abs/2509.21933", "title": "Chain of Thought 在临床文本理解中的失败原因", "title_en": "Why Chain of Thought Fails in Clinical Text Understanding", "authors": "Jiageng Wu,Kevin Xie,Bowen Gu,Nils Krüger,Kueiyu Joshua Lin,Jie Yang", "background": "大型语言模型（LLMs）在临床护理领域的应用日益增多，该领域对准确性和透明推理的要求非常高，这对安全和可信度至关重要。尽管链式推理（CoT）提示技术可以在多种任务中提高性能和可解释性，但在临床环境中的有效性仍需进一步探索，特别是在电子健康记录（EHRs）中，这些记录通常冗长、碎裂且杂乱无章。研究者进行了首个大规模系统研究，评估了95个先进的LLM在87个临床文本任务上的表现，涉及9种语言和8种任务类型，揭示了CoT在临床文本理解中的失败模式。", "innovation": "本研究首次对临床文本理解中的CoT效果进行了大规模系统的评估，发现86.3%的模型受到CoT设置下的性能下降影响，越强大的模型相对越稳健，而较弱的模型则遭受较大降幅。研究还通过LLM参与评判和临床专家评价等多种方法，对推理长度、医学概念匹配和错误特征进行了细致分析，揭示了CoT在临床环境中的失败模式和悖论：虽然CoT增强了可解释性，但在临床文本任务中可能损害了可靠性。", "conclusion": "研究为LLM在临床推理策略提供了实验证据，指出需要透明和可信的方法。研究结果揭示了CoT在临床文本理解中的系统性模式，突显了在临床任务中CoT增强了可解释性却可能损害可靠性的关键悖论。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22086", "html_url": "https://arxiv.org/abs/2509.22086", "title": "使用对话行为脚本进行多语言对话生成与本地化", "title_en": "Multilingual Dialogue Generation and Localization with Dialogue Act Scripting", "authors": "Justin Vasselli,Eunike Andriani Kardinata,Yusuke Sakai,Taro Watanabe", "background": "非英语的对话数据集稀缺，模型通常基于英语对话的翻译进行训练或评估，这会导致生成的对话可能缺乏自然性与文化适当的表达。此研究探讨了通过结构化对话行为表示来编码、本地化和生成多语言对话，从而改善对话的质量和文化适应性.", "innovation": "提出了一种名为对话行为脚本（DAS）的结构框架，用于从抽象意图表示生成多语言对话。DAS 不是直接翻译对话元素，而是生成目标语言中符合文化与上下文的新型对话。通过使用结构化的对话行为表示，DAS 支持跨语言的灵活本地化，减少翻译腔，使对话更加流畅自然.", "conclusion": "人类评估表明，在意大利语、德语和中文中生成的DAS对话在文化相关性、连贯性和场景合适性方面始终优于机器和人工翻译生成的对话."}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22147", "html_url": "https://arxiv.org/abs/2509.22147", "title": "混合检测器：机器生成文本检测的紧凑视角", "title_en": "Mixture of Detectors: A Compact View of Machine-Generated Text Detection", "authors": "Sai Teja Lekkala,Yadagiri Annepaka,Arun Kumar Challa,Samatha Reddy Machireddy,Partha Pakray,Chukhu Chunka", "background": "大语言模型（LLMs）正逐渐超越人类的创造力，但这一说法需要谨慎考虑。最近的发展引发了许多关于人类工作的真实性、创造力和创新性保存的质疑。论文探讨了这些问题，并针对多个场景研究了机器生成文本检测问题，包括文档级别的二分类与多分类、文本生成器的归属，以及通过对抗攻击降低机器生成文本可检测性的方法。", "innovation": "论文引入了一个新的名为BMAS English的数据集，用于二分类和多分类机器生成文本的检测，不仅能识别机器生成的文本，还能尝试确定其生成器；提出了对抗攻击以降低检测的易识别性；以及提出了句子级分割技术，用于预测人类与机器生成文本的边界。", "conclusion": "论文将从先前的研究中在机器生成文本检测方面提供一个更深层次的理解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22099", "html_url": "https://arxiv.org/abs/2509.22099", "title": "S2J: 在生成型奖励模型中弥合解题与判断能力的差距", "title_en": "S2J: Bridging the Gap Between Solving and Judging Ability in Generative Reward Models", "authors": "Shaoning Sun,Jiachen Yu,Zongqi Wang,Xuewei Yang,Tianle Gu,Yujiu Yang", "background": "随着大型语言模型（LLMs）的快速发展，生成型奖励模型（GRMs）被广泛应用于奖励建模和评估。以往的研究主要关注于通过优化偏好数据集来训练专门的GRMs，并以判断正确性为监督目标。尽管普遍认为问题解决能力更强的GRMs通常具有更好的判断能力，但研究发现，在评估单个查询时，存在显著的解题与判断能力差距。这一差距指的是GRMs在某些查询上（14%-37%）难以作出正确判断，即使它们能够完全解决这些问题。", "innovation": "本文提出了S2J方法以解决这一问题。S2J方法在单个GRM的输出中同时利用了解题和判断能力进行监督，并在模型优化过程中明确地将GRM的解题能力和评估能力联系起来，从而缩小了两者之间的差距。该方法通过全面实验证明，S2J有效地缩小了解题与判断能力差距16.2%，从而提升了模型的判断性能5.8%。更重要的是，S2J在使用较小训练数据集的情况下达到了同类GRMs的最强表现（SOTA），并通过自我进化无需依赖更强大的外部模型进行蒸馏来实现这一点。", "conclusion": "S2J方法在保持技术先进性的同时，通过使用较少的训练数据集解决了解题与判断能力差距的问题，从而显著提高了模型的判断性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22123", "html_url": "https://arxiv.org/abs/2509.22123", "title": "多语言视觉语言模型，一项综述", "title_en": "Multilingual Vision-Language Models, A Survey", "authors": "Andrei-Alexandru Manea,Jindřich Libovický", "background": "本文综述了处理跨语言文字和图像的多语言视觉语言模型。涵盖了31个模型和21个基准测试，包括编码器仅限架构和生成架构。指出了跨语言一致性（一致的跨语言表示）和文化意识（适应文化背景）之间的关键矛盾。当前训练方法倾向于通过对比学习支持跨语言一致性，而文化意识则依赖于多样化数据。大多数评估基准采用基于翻译的方法来确保语义一致性，但最近的工作开始纳入基于文化的内容。发现跨语言能力存在差异，并指出训练目标与评估目标之间存在差距。", "innovation": "识别了跨语言一致性和文化意识之间的张力。强调当前训练方法偏向跨语言一致性，而文化意识则依赖多样性数据。虽然大部分评价采用基于翻译的方法，以确保语义一致性，但近来的研究开始引入文化相关的内容。指出现有模型训练目标和评估标准之间存在差距。", "conclusion": "发现大多数模型在跨语言能力方面存在差异，训练目标和评估目标之间存在不一致。同时指出现有模型在文化适应性方面存在不足。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22101", "html_url": "https://arxiv.org/abs/2509.22101", "title": "Think Right, Not More: Test-Time Scaling for Numerical Claim Verification", "title_en": "Think Right, Not More: Test-Time Scaling for Numerical Claim Verification", "authors": "Primakov Chungkham,V Venktesh,Vinay Setty,Avishek Anand", "background": "事实核查实证声明，特别是数值声明，本质上是复杂的，需要多步推理和数值推理来验证声明的各个方面。尽管大型语言模型（LLMs）包括推理模型已经取得了巨大进步，但在验证需要组合和数值推理相结合的实证声明方面仍然存在不足。这些模型无法理解数值方面的细微差别，并且容易出现推理偏移问题，导致无法根据上下文整合信息，从而导致误解和推理过程的回溯。", "innovation": "本文系统性地探索了在数值声明验证任务中为LLMs扩展测试时间计算（TTS）的方法，这需要从LLM中引出多个推理路径。本文训练了一个验证器模型（VERIFIERFC），以在这类可能的推理路径空间中导航，并选择一条可能导向正确结论的路径。我们观察到TTS有助于缓解推理偏移问题，显著提高了验证数值声明的性能。为提高TTS计算效率，我们引入了一种适应机制，可以根据声明的复杂性选择性地进行TTS。这种方法在保持18.8%的性能提升的同时，实现了1.8倍的计算效率提升，超过了一次性声明验证方法。", "conclusion": "我们的工作表明，通过适应性机制选择性地扩展TTS，可以在提高计算效率的同时提升数值声明验证的性能，为实证声明验证提供了新的方法和策略。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22119", "html_url": "https://arxiv.org/abs/2509.22119", "title": "通过监督分类模型与大语言模型紧密合作实现通用法律文章预测", "title_en": "Universal Legal Article Prediction via Tight Collaboration between Supervised Classification Model and LLM", "authors": "Xiao Chi,Wenlin Zhong,Yiquan Wu,Wei Wang,Kun Kuang,Fei Wu,Minghui Xiong", "background": "法律文章预测（LAP）是法律文本分类中的关键任务，通过自然语言处理（NLP）技术自动预测基于案件事实描述的相关法律条款。作为法律决策的基础步骤，LAP在确定后续判决（如指控和处罚）方面起着决定性作用。尽管其重要性，现有方法在处理LAP的复杂性方面仍面临重大挑战。监督分类模型（SCMs），如CNN和BERT，由于其固有的限制性难以充分捕捉复杂的事实模式。相反，尽管大语言模型（LLMs）在生成任务中表现出色，但在预测场景中表现不佳，因为法律条款的抽象性和ID基础。此外，不同司法管辖区法律体系的多样性加剧了这一问题，因为大多数方法只针对特定国家且缺乏更广泛的应用。", "innovation": "为了解决这些限制，我们提出了Uni-LAP，这是一种通用框架，通过紧密协作整合了SCMs和LLMs的优势。具体而言，在Uni-LAP中，SCM通过引入新的Top-K损失函数来增强，以生成准确的候选法律条文，而LLM则使用类三段论推理来完善最终预测。我们在多个司法管辖区的数据集上评估了Uni-LAP，并且实验证明我们的方法在所有场景中都优于现有基线，展示了其有效性和普适性。", "conclusion": "我们的研究结果表明，Uni-LAP框架在法律文章预测中表现优异，并且具有广泛的适用性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22193", "html_url": "https://arxiv.org/abs/2509.22193", "title": "当推理何时重要？模型性能中推理贡献的受控研究", "title_en": "When Does Reasoning Matter? A Controlled Study of Reasoning's Contribution to Model Performance", "authors": "Nicolas Boizard,Hippolyte Gisserot-Boukhlef,Kevin El-Haddad,Céline Hudelot,Pierre Colombo", "background": "具有推理能力的大语言模型（LLMs）在各种任务上都取得了最先进的性能。尽管其具有实证性成功，但推理在哪些任务和模型规模下变得有效，以及其在训练和推断中的成本仍然未被充分探索。", "innovation": "本研究采用了合成数据蒸馏框架进行大规模监督研究，将指令微调（IFT）与不同规模的推理模型进行比较，评估数学和跨领域的任务，并测试了选择题和开放式格式的表现。研究发现，推理能够一致地提升模型性能，在某些情况下甚至可以与或超过大型IFT系统的性能。", "conclusion": "虽然指令微调在训练和推断成本上仍保持帕累托最优，但随着模型规模的增加，推理模型的价值变得越来越高，能够克服指令微调在涉及推理和开放式任务上的性能限制。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22144", "html_url": "https://arxiv.org/abs/2509.22144", "title": "从长到精：基于多轮精炼的性能感知和自适应链式思维压缩", "title_en": "From Long to Lean: Performance-aware and Adaptive Chain-of-Thought Compression via Multi-round Refinement", "authors": "Jianzhi Yan,Le Liu,Youcheng Pan,Shiwei Chen,Zike Yuan,Yang Xiang,Buzhou Tang", "background": "链式思维（CoT）推理在复杂任务上的表现得到了改善，但同时也引入了显著的推理延迟，这主要归因于过度详细的推理过程带来的语句冗长问题。", "innovation": "提出了Multiround Adaptive Chain-of-Thought Compression（MACC）框架，利用了token弹性现象，通过多轮精炼逐步压缩CoT，并采用自适应策略确定每个输入的最佳压缩深度。此外，还展示了测试时的表现（准确性和token长度）可以使用训练集上的可解释特征（如困惑度和压缩率）进行可靠预测。", "conclusion": "该方法在平均准确率上提高了5.6%，同时将CoT长度减少了平均47个token，并显著降低延迟。此外，方法适用于不同模型，无需重复微调，证明了CoT压缩的有效性和可预测性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22125", "html_url": "https://arxiv.org/abs/2509.22125", "title": "FoodSEM: 大型语言模型专门用于食品命名实体链接", "title_en": "FoodSEM: Large Language Model Specialized in Food Named-Entity Linking", "authors": "Ana Gjorgjevikj,Matej Martinc,Gjorgjina Cenikj,Sašo Džeroski,Barbara Koroušić Seljak,Tome Eftimov", "background": "当前，最先进的通用（大型）语言模型或定制的领域特定模型/系统都无法准确解决与食品相关的命名实体链接（NEL）任务。因此，亟需开发专门针对食品领域的模型来实现这一任务，FoodSEM正是在这样的背景下提出的，它是一个专门针对食品相关的开放源代码大型语言模型，能够将文本中提及的食品实体链接到多个相关领域知识库，如食品网络（FoodOn）、SNOMED-CT和汉茨德分类学（Hansard taxonomy）等。", "innovation": "FoodSEM通过指令-响应（IR）场景实现了高度准确的食品实体链接，相比相关模型/系统，其F1分数在某些领域达到了98%。此外，它还优于零样本、单样本和少量样本的LLM提示基准，展示了其卓越的性能。本文的主要贡献在于，（1）发布食品标注数据集，并将其转换为适合大型语言模型训练和评估的指令-响应格式，（2）推出了一种强大的食品领域模型，以提升文本在食品领域的语义理解，（3）为未来进行食品命名实体链接的基准测试提供了有力的基线模型。", "conclusion": "通过发布FoodSEM及其相关资源，本文的主要贡献包括：（1）提供了一个食品标注数据集，包括适合LLM训练和评估的指令-响应格式；（2）推出了一种强大的食品领域模型，以增强文本在食品领域的语义理解；（3）为未来食品命名实体链接提供了强有力的基准模型。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22075", "html_url": "https://arxiv.org/abs/2509.22075", "title": "COSPADI: 通过校准引导的稀疏字典学习压缩LLMs", "title_en": "COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning", "authors": "Dmitriy Shopkhoev,Denis Makhov,Magauiya Zhussip,Ammar Ali,Stamatios Lefkimmiatis", "background": "大语言模型（LLMs）的后训练压缩主要依赖于低秩权重近似，这种方法通过共享低维子空间来表示权重矩阵的每一列。尽管这是一种计算效率高且节省存储资源的策略，但这种方法施加了刚性的结构约束，可能会导致模型精度明显下降。现有的低秩方法在这方面的表现较为固定，灵活性有限。", "innovation": "提出了一种名为CoSpaDi的新的无训练压缩框架，它用灵活的结构稀疏分解替代了低秩分解。这种方法采用稠密字典和列稀疏系数矩阵来表示每个权重矩阵。它提供了比固定不变基更强大的表达能力。更重要的是，CoSpaDi利用校准数据集对分解进行优化，使得压缩层的输出激活与原始层的激活尽可能匹配，从而最小化功能重建误差，而不是仅仅进行权重近似。这种数据感知策略在合理的压缩比率下能够保持较好的模型保真度，且无需任何微调。此外，该方法还允许高效的稀疏-密集矩阵乘法，并可与后训练量化相容，以进一步节省内存和延迟。这项创新显著提高了稀疏字典学习方法的效率与灵活性，带来了更强的实用性和竞争力。", "conclusion": "在多次LLM模型评估中（包括多层和分组设置下的Llama和Qwen模型），CoSpaDi在20-50%的压缩比下相较于最先进的数据感知低秩方法，不仅在精度上保持优势，而且在困惑度（perplexity）方面也表现出色。因此，我们的研究结果证实了结构化稀疏字典学习作为传统低秩方法的强有力替代品，对于高效的LLM部署具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22134", "html_url": "https://arxiv.org/abs/2509.22134", "title": "桥接策略性策略偏差：群体树优化用于投机性解码", "title_en": "Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding", "authors": "Shijing Hu,Jingyang Li,Zhihui Lu,Pan Zhou", "background": "现有的训练目标只优化单个贪婪草案路径，而解码遵循一个重新排序和验证多分支的树策略。这种草案策略的偏差限制了可实现的加速度。研究表明，通过引入群体树优化（GTO），可以将训练与解码期的树策略对齐，从而提高接受长度和加速度，特别是在对话（MT-Bench）、代码（HumanEval）和数学（GSM8K）等多个大语言模型（如LLaMA-3.1-8B、LLaMA-3.3-70B、Vicuna-1.3-13B、DeepSeek-R1-Distill-LLaMA-8B）上都有显著的改进效果。", "innovation": "GTO通过两种方法优化了训练与解码期树策略的对齐：(i) 无采样的草案树奖励，测量解码性能；(ii) 基于群体的草案策略训练，形成去偏差的标准化优势，并以PPO风格的替代策略实施稳健更新。此外，证明了提高草案树奖励能够提升接受长度和加速度。实验结果显示，GTO比此前最佳的EAGLE-3提高了7.7%的加速度，且接受长度增加7.4%.", "conclusion": "通过桥接草案策略偏差，GTO提供了一种实用且通用的大语言模型推理的高效解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22230", "html_url": "https://arxiv.org/abs/2509.22230", "title": "在他们的语言中：针对小型模型定制的推理解析使得他们成为更好的推理者", "title_en": "In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better Reasoners", "authors": "Jaehoon Kim,Kwangwook Seo,Dongha Lee", "background": "通过对更大语言模型的推理解释能力进行监督微调，将其转移到较小的模型上通常会反常识地失败，尽管有高质量的教师演示，但性能反而下降。我们发现这种失败源于分布不匹配：更大模型中的推理解释路径中包含对学生分布低概率的代币，超出较小架构内部表示容量，从而成为学习障碍而非有益的指导。", "innovation": "我们提出了一种名为反推测性解码（RSD）的新机制，该机制为学生生成友好的推理解释路径，其中教师模型提出候选代币，但学生模型基于自身概率分布决定接受与否，过滤掉低概率代币。实验表明，RSD生成的推理解释路径在对Qwen3-0.6B进行直接蒸馏时，使性能平均提高了4.9%，而直接蒸馏s1K-1.1解释路径数据反而降低了20.5%的性能。分析揭示低概率代token构成推理解释能力传输的关键瓶颈，然而交叉模型实验显示RSD路径对于每个学生架构具有特定性，需要针对每个学生的独特内部表示进行调整。", "conclusion": "反推测性解码使得推理解释路径的转移更适配学生模型的具体内部表示，提供了一种更加有效的知识迁移策略，但在不同模型之间可能需要不同的定制化调整，表明分布对齐是提高性能的关键因素。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22141", "html_url": "https://arxiv.org/abs/2509.22141", "title": "NFDI4DS共享任务用于学术文献处理", "title_en": "NFDI4DS Shared Tasks for Scholarly Document Processing", "authors": "Raia Abu Ahmad,Rana Abdulla,Tilahun Abedissa Taffa,Soeren Auer,Hamed Babaei Giglou,Ekaterina Borisova,Zongxiong Chen,Stefan Dietze,Jennifer DSouza,Mayra Elwes,Genet-Asefa Gesese,Shufan Jiang,Ekaterina Kutafina,Philipp Mayr,Georg Rehm,Sameer Sadruddin,Sonja Schimmler,Daniel Schneider,Kanishka Silva,Sharmila Upadhyaya,Ricardo Usbeck", "background": "共享任务是通过社区标准化评估促进研究的重要工具，有助于推动可发现、可访问、可互操作、可重用（FAIR）的研究实践，以及透明和可重复的研究方法。德国数据科学和人工智能国家级研究数据基础设施（NFDI4DS）联盟在领先会议上组织并主办了十二项共享任务，涵盖了学术文献处理的各种挑战。", "innovation": "这些共享任务促进方法论创新，并提供开放访问的数据集、模型和工具，以支持更广泛的科研社区，并将其整合到联盟的研究数据基础设施中。", "conclusion": "这些共享任务通过标准化评估促进了学术文献处理领域的研究进展，推动了FAIR和透明的研究实践，并贡献了开放访问的数据集、模型和工具至更广泛的科研社区，增强了研究数据基础设施的集成与应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22206", "html_url": "https://arxiv.org/abs/2509.22206", "title": "大型语言模型的输出毫无意义", "title_en": "The Outputs of Large Language Models are Meaningless", "authors": "Anandi Hattiangadi,Anders J. Schoubye", "background": "本文基于两种关键前提，提出大型语言模型（LLMs）的输出毫无意义的观点：（a）某些类型的意图对于LLMs输出具有字面意义是必不可少的；（b）现有的LLMs无法真实地拥有这些类型的意图。作者还回应了来自外部主义和内部主义者的反驳观点，并讨论即使在论文的论证成立的情况下，LLMs输出似乎依然具有意义，能够帮助我们获得正确信念甚至知识这一看似矛盾的现象。", "innovation": "提出了一个新的论证，即认为大型语言模型的输出缺乏字面意义上的意图，从而缺乏所谓的‘意义’。尽管论文回应了外部主义和内部主义者的反驳观点，但仍强调了现有模型输出看似意义的存在，即虽然它们没有真正的意义，但它们的输出可以实际产生有用的信息和知识。", "conclusion": "即便论文中的论证成立，即大型语言模型的输出缺乏真正意义上的意义，这些输出仍然具有实际的应用价值，可以帮助人们获得事实性的信念甚至知识。这一结论挑战了对自然语言处理和人工智能的基本理解，提出了对现有模型能力的新的认知视角。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22158", "html_url": "https://arxiv.org/abs/2509.22158", "title": "上下文参数化与组合适用器", "title_en": "Context Parametrization with Compositional Adapters", "authors": "Josip Jukić,Martin Tutek,Jan Šnajder", "background": "大型语言模型（LLMs）通常通过上下文学习（ICL）或监督微调（SFT）无缝适应新任务。然而，这两种方法各有局限：ICL在处理大量示例时效率低下，SFT虽然在灵活性上有所牺牲，但需要训练开销。直接将指令或示例信息映射到适配器参数上提供了一个有吸引力的替代方案。尽管先前的工作仅探索了基于单一输入上下文生成适配器的方法，但忽视了将多个信息片段整合的需求。为解决这一问题，本文提出了CompAs框架，该框架将上下文转换为带有组合适用器结构的适配器参数。", "innovation": "CompAs框架通过将上下文信息转化为可复原的适配器参数，从而能够无缝结合指令、示例或检索到的段落，而无需重新处理长提示，同时降低了推理成本，增强了长期上下文的稳定性，并且在输入超过模型上下文窗口时提供了一个有原则的解决方案。此外，CompAs的适配器参数编码是可逆的，能够通过解码器恢复输入上下文，从而实现安全性和可靠性。实验结果显示，CompAs在多种选择题和抽取式问答任务中优于上下文学习和基于生成器的方法，特别是在处理更大数量的输入时。", "conclusion": "本工作证明了组合适用器生成的可组合性是一种实用且高效的LLM部署扩展方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22220", "html_url": "https://arxiv.org/abs/2509.22220", "title": "StableToken：一种抗噪声语义语音分词器，用于稳健的语音LLMs", "title_en": "StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs", "authors": "Yuhan Song,Linhao Zhang,Chuhan Wu,Aiwei Liu,Wei Jia,Houfeng Wang,Xiao Zhou", "background": "现有的语义语音分词器虽然设计用于捕捉语言内容，但对与意义无关的声学干扰非常脆弱。即使在信噪比（SNR）很高的情况下，语音完全可懂，它们的输出分词序列也会发生剧烈变化，增加下游大语言模型（LLMs）的训练负担。", "innovation": "StableToken 通过共识驱动的机制实现了稳定性。其多分支架构并行处理音频，然后再通过强位运算机制将这些表示合并为一个稳定分词序列。StableToken 在各种噪声条件下的单位编辑距离（UED）稳定性创下新的基准，极大地提高了语音LLMs在多种任务上的稳健性。", "conclusion": "StableToken 的基础稳定性直接转化为下游任务的显著改进，使语音LLMs在各种任务中更加稳健。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22211", "html_url": "https://arxiv.org/abs/2509.22211", "title": "由问题驱动的分析和合成：使用LLMs构建可解释的题意树以进行文本聚类及可控生成", "title_en": "Question-Driven Analysis and Synthesis: Building Interpretable Thematic Trees with LLMs for Text Clustering and Controllable Generation", "authors": "Tiago Fernandes Tavares", "background": "无监督的文本语料分析具有挑战性，特别是在数据稀缺的情况下。传统的话题模型在这些情况下往往表现不佳，它们通过关键词列表描述聚类，需要大量手动努力进行解释，而且往往缺乏语义一致性。目前尽管有所改进，但在解释聚类方面仍然存在关键的可解释性差距。", "innovation": "本文提出了一种名为递归主题分区（RTP）的新框架，该框架利用大型语言模型（LLMs）以交互方式构建二叉树，每个节点是一个自然语言问题，用于语义分区。这种方法产生了一个完全可解释的层次结构，便于理解和逻辑清晰。实验证明RTP的问题导向层次结构比像BERTopic这样的强基线的基于关键词的主题更具可解释性。此外，通过将其应用于下游分类任务来展示这些聚类在量化上的效用。RTP改变了数据分析的范式，从统计模式发现转向知识驱动的主题分析，并展示了基于RTP的树形结构的话题路径可以用作生成模型生成的结构化和可控的提示，使我们的分析框架成为强有力的合成工具，可以实现对源语料库中发现的特定特征的一致模仿。", "conclusion": "RTP提供了一种新方法，用于构建可解释的主题层次结构，实现文本聚类和可控生成，提升了模型的解释性和应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22243", "html_url": "https://arxiv.org/abs/2509.22243", "title": "FLEXI：评估全双工人机对话", "title_en": "FLEXI: Benchmarking Full-duplex Human-LLM Speech Interaction", "authors": "Yuan Ge,Saihan Chen,Jingqi Xiao,Xiaoqian Liu,Tong Xiao,Yan Xiang,Zhengtao Yu,Jingbo Zhu", "background": "全双工大型语言模型（LLMs）是自然人机交互的关键基础，能够实现实时语音对话系统。然而，这些模型的基准测试和建模仍然是一个基本的挑战。这项研究介绍了FLEXI，这是首个考虑紧急情况下模型中断的全双工LLM-人语音交互基准。FLEXI通过六个不同的LLM-人交互场景，系统地评估实时对话的延迟、质量和对话有效性，揭示了开源和商用模型在紧急意识、回合结束和交互延迟方面存在的显著差距。", "innovation": "FLEXI首次引入了一个基准测试，用于全面评估全双工LLM-人互动，特别是强调紧急情况下的模型中断处理。通过六个不同的情景，FLEXI能够系统地检验模型在多种实际场景下的表现，从而填补了目前在全双工对话技术上认识上的空白，提高了模型在紧急情况下的应对能力。", "conclusion": "接下来，利用下一个词对预测可能会为实现真正无缝且类人全双工互动提供一条有前途的道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22237", "html_url": "https://arxiv.org/abs/2509.22237", "title": "FeatBench：评估定向实施功能的编码代理", "title_en": "FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding", "authors": "Haorui Chen,Chengze Li,Jia Li", "background": "大规模语言模型（LLMs）的发展催生了一种新的软件开发范式——“感知编码”，其中用户通过高层次的自然语言与编码代理进行互动。但目前的代码生成评估基准未能充分评估代理的感知编码能力。现有的基准存在局限性，它们要么需要代码级别的规范，要么专注于问题解决，忽略了感知编码范式下特征实现的关键场景。鉴于此，本文提出了一个新颖的评估基准——FeatBench，特别针对特征实现进行评估。", "innovation": "1. 仅使用抽象的自然语言提示，而没有代码或结构提示；\n2. 启用多级过滤管道以确保数据质量，并实现自动化演化以避免数据污染；\n3. 包含失败到成功和成功到成功的测试案例，以验证正确性并防止退化；\n4. 涉及来自不同领域的仓库，确保基准能够反映真实世界的情况。", "conclusion": "我们的评估表明，在感知编码范式下的特征实现是一个重大挑战，最高成功率仅为29.94%。我们的分析还揭示了‘激进实现’策略，这反而导致关键失败和卓越软件设计之间的悖论。我们发布了FeatBench、自动收集管道和所有实验结果，以促进进一步的社区研究。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22251", "html_url": "https://arxiv.org/abs/2509.22251", "title": "超越文本上下文：适配空间对齐的结构图编码以缓解LLMs的幻觉", "title_en": "Beyond Textual Context: Structural Graph Encoding with Adaptive Space Alignment to alleviate the hallucination of LLMs", "authors": "Yifang Zhang,Pengfei Duan,Yiwen Yang,Shengwu Xiong", "background": "目前，大型语言模型（LLMs）解决幻觉问题的主要方法是引入知识图谱（KGs），然而LLMs通常将KGs视为纯文本，仅提取语义信息并限制其对KGs关键结构方面的使用。另一个挑战是KGs编码器的嵌入空间与LLMs文本嵌入之间的差距，这阻碍了结构化知识的有效整合。为了解决这些问题，本文提出了SSKG-LLM，一种创新的模型架构，旨在高效地将KGs的结构和语义信息整合到LLMs的推理过程中。", "innovation": "本文提出了一种创新的模型架构——SSKG-LLM，结合了Knowledge Graph Retrieval (KGR)模块和Knowledge Graph Encoding (KGE)模块来保存语义并利用结构，并引入了Knowledge Graph Adaptation (KGA)模块，使LLMs能够理解KGs嵌入。特别强调了通过整合KGs的结构信息来增强LLMs的事实推理能力。", "conclusion": "本文通过广泛的实验和详细的分析研究了在LLMs中整合KGs的结构信息如何提高其实用的推理能力。源代码可在提供的链接中获取。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22291", "html_url": "https://arxiv.org/abs/2509.22291", "title": "填补公平与可解释性之间的差距：基于输入的解释能否促进仇恨言论检测中的公平性？", "title_en": "Bridging Fairness and Explainability: Can Input-Based Explanations Promote Fairness in Hate Speech Detection?", "authors": "Yifan Wang,Mayank Jobanputra,Ji-Ung Lee,Soyoung Oh,Isabel Valera,Vera Demberg", "background": "自然语言处理（NLP）模型经常会复制或放大训练数据中的社会偏见，这引发了关于公平性的担忧。同时，这些模型的黑箱特性使得用户难以识别带有偏见的预测，也给开发人员有效缓解这些偏见带来了困难。虽然有些研究指出基于输入的解释有助于发现和缓解偏见，但也有人质疑其确保公平性的可靠性。现有的关于公平NLP的可解释性研究主要集中在定性分析上，缺乏大规模的定量分析。因此，本研究首次系统地探讨了可解释性和公平性之间的关系，特别关注编码器和解码器模型。", "innovation": "本研究首次系统地探讨了可解释性和公平性之间的关系，集中于编码器和解码器模型，通过三个关键维度进行分析：（1）识别带有偏见的预测，（2）选择公平模型，（3）在模型训练过程中缓解偏见。研究发现，基于输入的解释能够有效检测带有偏见的预测，并在训练期间作为减少偏见的有用监督，但它们不一定可靠地用于在候选模型中选择公平的模型。", "conclusion": "基于输入的解释能够有效地检测带有偏见的预测，并在训练期间作为减少偏见的有用监督，但它们在选择公平模型中的作用可靠性较低。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22224", "html_url": "https://arxiv.org/abs/2509.22224", "title": "多模式思考：复合推理如何在有限数据下提升大型语言模型性能", "title_en": "Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data", "authors": "Zishan Ahmad,Saisubramaniam Gopalakrishnan", "background": "大型语言模型（LLMs）虽然具备卓越的能力，但依赖单一的推理范式，这在解决需要多样认知策略的复杂问题时会受到阻碍。现有方法，如 Chain-of-Thought（CoT）和 DeepSeek-R1 风格推理（SR），在处理这些问题时存在局限性。因此，本研究旨在通过引入复合推理（CR）这种方法，使LLMs能够动态探索和结合多种推理方式（如演绎、归纳和溯因推理），以增强其在复杂问题上的表现。实验结果表明，CR在科学和医学问题回答基准测试中表现优于现有基线，并且在样本效率和令牌使用方面表现出色。CR能够根据领域特点，适应性地强调不同的推理方式，在医学问题解答中偏向使用溯因和演绎推理，在科学问题中则偏向因果、演绎和归纳推理。这一发现表明，通过内化多样化的推理风格，LLMs能够获得更 robust、适应性和高效的问题解决能力。", "innovation": "本研究引入了一种名为复合推理（CR）的新颖推理方式，使大型语言模型能够动态探索和结合多种推理风格（如演绎、归纳和溯因推理），以增强其在处理复杂问题时的表现。CR相比现有的基于链式思考（CoT）和DeepSeek-R1风格推理（SR）方法具有更佳的表现，同时在样本效率和令牌使用方面也更优。此外，CR还能够根据具体领域的特点，适应性地调用最适合的推理方法，这为解决不同领域的复杂问题提供了新的策略。", "conclusion": "本研究通过引入复合推理（CR）方法，改进了大型语言模型在处理复杂问题时的方式，使其能够更好地利用多种推理策略，并在样本效率和令牌使用方面表现出色。研究结果显示，CR能根据不同领域的特点，灵活调用最合适的推理方式，从而提高了模型的稳健性、适应性和效率。这表明通过统筹和优化内部推理风格，大型语言模型能够更好地应对复杂任务。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22360", "html_url": "https://arxiv.org/abs/2509.22360", "title": "Chronoberg: 捕捉基础模型中语言演变和时间意识", "title_en": "CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation Models", "authors": "Niharika Hegde,Subarnaduti Paul,Lars Joel-Frey,Manuel Brack,Kristian Kersting,Martin Mundt,Patrick Schramowski", "background": "现有的语料库虽然多样化，但由于缺乏长期的时间结构，可能限制了大规模语言模型（LLMs）对语言语义和规范演变的语境化理解和同期变化的捕捉能力。为了解决这一问题，该研究通过引入CHRONOBERG，一个涵盖250年英语书籍文本的、结构化时间框架语料库，从Project Gutenberg项目中选取数据并丰富了时间注释，以支持对语言变化和时间建模的研究。", "innovation": "该研究通过引入CHRONOBERG语料库，提供了一个长期时间框架下的数据集，使得可以对词汇语义随时间的变化进行量化分析，并构造了支持时间接地解读的情感词汇表。通过这种方法，研究强调了现代基于LLM的工具需要更好地理解它们对歧视性语言的检测和不同时间段情感语境化的能力。进一步展示了在CHRONOBERG数据集上以时间序列训练的语言模型在捕捉意义演变方面存在困难，强调了需要发展具有时间意识的训练与评估管道，并将CHRONOBERG定位为研究语言变化和时间泛化的可扩展资源。", "conclusion": "CHRONOBERG作为一个大型语料库，为语言变化和时间泛化的研究提供了可能。通过提供长期时间框架的数据，有助于更好地理解语言随时间的变化，并支持更准确的情感和歧视性语言检测，同时也为具有时间意识的模型训练和评估提供了关键资源。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22343", "html_url": "https://arxiv.org/abs/2509.22343", "title": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "title_en": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "authors": "Amit Roy,Abulhair Saparov", "background": "实现大型语言模型（LLMs）响应的真实性需要具备推理能力，而在因果推理等场景中，理解和推理传递关系尤为重要。现有研究主要关注变压器模型能否从输入提示中的上下文例子中学习传递性的推断，但关于变压器模型从训练数据中学习传递关系的能力及其随模型规模变化的影响仍未被充分探索。", "innovation": "本研究通过生成不同规模的有向图来有意识地训练大小不一的变压器模型，并评估它们在不同图规模下推断传递关系的能力。研究发现，变压器有能力在‘网格状’结构的有向图上学习连接性，且低维度的网格图结构更容易被学习，对于非网格且包含多个不连通部分的图，变压器学习连接性任务的困难随着不连通部分的增多而增加。同时，模型规模的增加有助于提供更多多样化的嵌入信息，从而在一定的训练集上提高对非网格图的连接性的推理能力。", "conclusion": "本研究揭示了 transformers 在不同类型的有向图上推断传递关系能力的差异，显示了低维度网格状结构的图更容易被学习，且模型规模的增加有利于在一致的训练集上对这类图进行更好的推广。然而，对于复杂图的连接性推理，挑战依然存在。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22250", "html_url": "https://arxiv.org/abs/2509.22250", "title": "安全合规：通过合规视角重新思考大语言模型的安全推理", "title_en": "Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance", "authors": "Wenbin Hu,Huihao Jing,Haochen Shi,Haoran Li,Yangqiu Song", "background": "大语言模型（LLMs）的普及展示了显著的能力，强调了LLM安全的迫切重要性。然而，现有的安全方法依赖于草率的分类，缺乏严格的、系统的保护，无法确保对现代LLM系统的复杂和微妙行为的安全保证。因此，本文从法律合规的角度探讨LLM的安全性，并在此基础上制定了相关法律框架作为安全标准。欧盟AI法案和GDPR作为核心法律框架，在欧洲范围内提供了人工智能安全和数据保护的标准。为解决LLM安全性和法律合规性之间的鸿沟，本文生成了以法律法规为种子的现实LMP安全场景，并开发了一个新的安全合规基准。", "innovation": "本文通过开发新的安全合规基准，使用Group Policy Optimization (GRPO)对Qwen3-8B进行排列以构建安全推理器（Compliance Reasoner），有效地将LLM与法律法规对齐，以减轻安全风险。研究表明，Compliance Reasoner在新的基准上表现出优越的性能，分别平均提高了欧盟AI法案10.45%和GDPR 11.85%。这些改进提升了LLM的合规性和安全性，为大语言模型的安全治理提供了新的思路和方法。", "conclusion": "实验结果表明，通过合规视角构建的Compliance Reasoner在评估LLM安全合规性方面表现出显著优势。这为大语言模型的安全性与法律框架的对齐提供了可能，为未来大语言模型的安全治理奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22354", "html_url": "https://arxiv.org/abs/2509.22354", "title": "会话含意：概率性建模有关理论", "title_en": "Conversational Implicatures: Modelling Relevance Theory Probabilistically", "authors": "Christoph Unger,Hendrik Buschmeier", "background": "近期贝叶斯概率理论的进步及其与认知科学的结合，以及新一代概率计算工具和方法的发展，已经引领了一场‘概率转向’，特别是在语用学和语义学领域。Rational Speech Act理论框架已经被发展出来，使用贝叶斯方法来建模广泛性的格赖泽语用现象，从简单的指代博弈到更复杂的推理交流，如口头演绎推理。该论文探索了贝叶斯方法如何应用于Sperber和Wilson提出的有关理论语用学，通过研究一个典型的语用现象：通过会话含意传递隐含意义。", "innovation": "论文研究了如何采用贝叶斯方法建模有关理论语用学中的会话含意，扩展了Rational Speech Act理论的应用范围，从逻辑推理扩展到更复杂的语用交流。", "conclusion": "通过概率性建模有关理论语用学中的会话含意，可以提供一种新的视角来理解和建模复杂的交际现象。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22338", "html_url": "https://arxiv.org/abs/2509.22338", "title": "使用微调的大语言模型推进自然语言到一阶逻辑的形式化", "title_en": "Advancing Natural Language Formalization to First Order Logic with Fine-tuned LLMs", "authors": "Felix Vossel,Till Mossakowski,Björn Gehrke", "background": "自然语言到一阶逻辑（FOL）的自动化翻译对于知识表示和形式方法至关重要，但这一任务仍然具有挑战性。众多研究试图通过不同的方法和模型优化这一过程，以便更好地实现自然语言理解和符号推理之间的桥梁。论文着重评估了微调后的大型语言模型（LLMs）在这个任务上的表现，比较了编码-解码和纯解码架构，以及不同的训练策略。通过MALLS和Willow数据集，论文探讨了词汇扩展、谓词条件和多语言训练等技术，引入了精确匹配、逻辑等价和谓词对齐等多个评估指标。", "innovation": "论文提出了一种系统性的评估机制，针对微调后的LLMs在自然语言到一阶逻辑翻译任务中的表现进行了全面的比较。具体创新点包括：1) 使用多种技术和策略（如词汇扩展、谓词条件等）进一步改进模型性能；2) 经过微调的Flan-T5-XXL在谓词列表的情况下实现了70%的准确率，超越了GPT-4o和DeepSeek-R1-0528等模型，特别强调其在多步骤推理和符号系统中的表现；3) 关键发现展示了谓词可用性的提升效果显著，并且模型在未训练过的逻辑论证上具有较好的泛化能力。", "conclusion": "虽然结构逻辑翻译较为稳健，但谓词提取是当前主要的瓶颈。研究结果表明，通过适当的微调技巧，大型语言模型在自然语言到一阶逻辑的翻译任务上可以实现较高的准确率，并且具有较好的跨任务泛化能力。这为未来进一步研究这一领域的自动化工具和方法提供了重要依据。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22345", "html_url": "https://arxiv.org/abs/2509.22345", "title": "InviTE语料库：为计算建模标注都铎时期英语中的咒骂语", "title_en": "The InviTE Corpus: Annotating Invectives in Tudor English Texts for Computational Modeling", "authors": "Sophie Spliethoff,Sanne Hoeken,Silke Schwandt,Sina Zarrieß,Özge Alaçam", "background": "本文旨在将自然语言处理（NLP）技术应用于历史研究，特别是通过分析16世纪英格兰宗教斗争中的宗教咒骂来研究新教改革时期的历史问题。该研究通过从原始数据到文本预处理、数据选择再到迭代标注过程的工作流，构建了一个包含近2000个早期现代英语句子（Early Modern English, EModE）的语料库InviTE，并富集了专家对于16世纪整个英格兰历史时期咒骂语言的注释。然后，研究评估并对比了基于微调BERT模型和零样本提示指令优化的大型语言模型（Large Language Models, LLMs）的性能，发现历史数据预训练的模型在咒骂识别方面表现更为优越。", "innovation": "本文创新地将NLP技术应用于历史研究，并通过构建InviTE语料库，提供了一个学术界可用的数据资源。更重要的是，研究对比了不同类型模型在咒骂检测任务中的性能，凸显了预训练历史数据模型的优势，这对于未来研究具有重要参考价值。这项工作为历史文本的自动分析提供了新的可能，并促进了领域内跨学科的发展。", "conclusion": "通过InviTE语料库的构建与历史文本咒骂语言的注释，研究展示了如何利用NLP技术来更好地理解历史文本中的语言现象。其还进一步验证了基于历史数据预训练并进行适当微调的模型在特定任务中的有效性，并为后续相关领域的研究奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22366", "html_url": "https://arxiv.org/abs/2509.22366", "title": "使用大型语言模型进行风力涡轮机维护日志的探索性语义可靠性分析", "title_en": "Exploratory Semantic Reliability Analysis of Wind Turbine Maintenance Logs using Large Language Models", "authors": "Max Malyi,Jonathan Shek,Andre Biscaya", "background": "风力涡轮机维护日志中蕴含着丰富的运营智能，但由于未结构化的自由文本形式，这些信息难以被传统的定量可靠性分析访问和利用。尽管机器学习已在该领域应用，但现有方法通常仅限于分类，即将文本分为预定义的标签。本文解决了利用现代大型语言模型（LLMs）进行更复杂推理任务的空白，介绍了使用LLMs超越分类，进行深入语义分析的探索性框架。该框架被应用于大型工业数据集，执行了四种分析流程：故障模式识别、因果链推理、比较站点分析和数据质量审计。", "innovation": "提出了一种新的探索性框架，利用大型语言模型进行故障模式识别、因果链推理、比较站点分析和数据质量审计等复杂语义分析任务，而不是仅仅停留在分类阶段。", "conclusion": "实验结果表明，大型语言模型可以作为强大的“可靠性副驾”，不仅能进行标签化，还能综合文本信息生成专家级、可操作的假设。这项工作贡献了一种新颖且可重复的方法论，利用大型语言模型作为推理工具，为提高风能领域的运营智能开辟了新的途径，从而使之前隐藏在非结构化数据中的见解得以揭示。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22367", "html_url": "https://arxiv.org/abs/2509.22367", "title": "LLMs的预训练和后训练数据中的政治内容是什么？", "title_en": "What Is The Political Content in LLMs' Pre- and Post-Training Data?", "authors": "Tanise Ceron,Dmitry Nikolaev,Dominik Stammbach,Debora Nozza", "background": "大型语言模型（LLMs）已知会生成带有政治偏见的文字，但政治偏见从何而来仍不清楚。当前LLM研究中对其训练数据的政治内容尚未进行全面探索。文章通过分析OLMO2模型的预训练和后训练语料库，填补了这一空白。", "innovation": "文章通过收集并自动标注OLMO2模型的预训练和后训练数据集中的随机样本，分析其政治倾向，并检查这些数据中的政治内容与模型在特定政策问题上的立场之间的关联。结果发现，预训练语料库比后训练数据含有更多具有政治参与度的内容，且不同政治倾向的文档通过不同的价值观和合法性来源来描述相同的话题。", "conclusion": "模型训练数据中的主要政治倾向强烈地与其在政策问题上的政治偏见相关。该研究强调，在未来的数据整理流程中整合政治内容分析，并对筛选策略进行详细的文档记录是非常必要的。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22536", "html_url": "https://arxiv.org/abs/2509.22536", "title": "InfiR2: 一种增强推理的语言模型全面的FP8训练方案", "title_en": "InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models", "authors": "Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Yuan Xie,Hongxia Yang", "background": "由于大型语言模型（LLMs）的训练计算成本极高，这已经成为创新的主要障碍。虽然FP8训练方法具备理论上的高效性，但其广泛应用受到缺乏全面公开的培训方案的阻碍。", "innovation": "该研究提出了一种端到端的FP8训练方案，该方案无缝结合了持续预训练和监督精调。方法采用细粒度的混合粒度量化策略，既保持数值准确性，又能最大化计算效率。通过广泛的实验，展示了该方案不仅非常稳定，而且几乎无损失，与BF16基准在多项推理基准测试中取得了相似的性能，同时实现了效率的显著提升。", "conclusion": "实验结果证明FP8是一种与BF16实际可行且可靠的替代方案。伴随代码将被发布，以便进一步普及大规模模型的培训。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22449", "html_url": "https://arxiv.org/abs/2509.22449", "title": "利用线性方向检测大型语言模型中的（不可）答性", "title_en": "Detecting (Un)answerability in Large Language Models with Linear Directions", "authors": "Maor Juliet Lavi,Tova Milo,Mor Geva", "background": "大型语言模型（LLMs）常常自信地回答问题，即便缺乏必要的信息，导致产生幻觉的回答。本文研究了（不可）答性检测的问题，集中在需从段落中提取信息以回答问题的抽取出题回答（QA）中，模型需要判断段落是否包含足够的信息以回答给定的问题。", "innovation": "提出了一个简单的识别模型激活空间中捕获（不可）答性的方向的方法，并应用于分类。该方向在推理过程中通过激活添加来选择，并通过其对模型保留行为的影响来测量。证明将隐藏的激活投影到该方向可以得到可靠的（不可）答性分类得分。实验表明，该方法有效检测未回答问题，并且在多个数据集上的泛化能力优于现有的提示基和分类器基方法。此外，得到的方向不仅适用于抽取出题QA，还适用于因科学共识缺失或主观性等原因导致的（不可）答性。最后，因果干预表明，在模型中添加或删除这些方向可以有效控制模型的保留行为。", "conclusion": "该方法能够有效检测未回答的问题，并且泛化能力更强。得到的方向不仅在抽取出题QA上下文有效，还能扩展到其他类型的（不可）答性，同时通过因果干预表明这些方向能够控制模型的答案生成行为。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22480", "html_url": "https://arxiv.org/abs/2509.22480", "title": "探索解决方案的多样性及其对大型语言模型问题解决的影响", "title_en": "Exploring Solution Divergence and Its Effect on Large Language Model Problem Solving", "authors": "Hang Li,Kaiqi Yang,Yucheng Chu,Hui Liu,Jiliang Tang", "background": "大型语言模型（LLMs）在解决各种任务上已经被广泛使用。最近的工作主要通过使用带有标注数据的监督微调（SFT）或从任务反馈中进行强化学习（RL）来提升其性能。然而，这项研究提供了一种新的视角，即观察LLMs为同一问题生成的解决方案的多样性，并发现更高的多样性与更好的问题解决能力相关。这一发现促使研究者提出了利用解决方案的多样性作为支持SFT和RL策略的新度量标准。研究者在三个代表性的问题领域测试了这一想法，并发现利用解决方案的多样性能一致地提高成功的概率。这些结果表明，解决方案的多样性是一种简单而有效的工具，可用于推进LLM的训练和评估。", "innovation": "提出一种新的视角，即解决方案的多样性，并将其作为一种新的度量标准，支持监督微调（SFT）和强化学习（RL）策略。通过实际测试验证这一新度量标准的有效性。", "conclusion": "使用解决方案的多样性作为新的度量标准可以有效地增强大型语言模型的训练和评估，提高其解决各种问题的成功率。进一步的研究可以探讨如何更好地利用这一新度量标准，优化模型训练。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22437", "html_url": "https://arxiv.org/abs/2509.22437", "title": " Chimera：诊断视觉语言理解中的捷径学习", "title_en": "Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding", "authors": "Ziheng Chi,Yifan Hou,Chenxi Pang,Shaobo Cui,Mubashara Akhtar,Mrinmaya Sachan", "background": "图形以视觉格式而非线性的语言流传递符号信息，这使得它们对AI模型构成挑战。尽管近期评估表明视觉语言模型（VLMs）在图形相关的基准测试中表现良好，但它们依赖于知识、推理或模态捷径的问题使得人们对它们是否真正理解并推理解图形提出了质疑。这篇文章介绍了一个全面的测试框架——Chimera，其中包括了来自Wikipedia的7,500个高质量的图形，每个图形都带有其语义三元组注释以及多层次的问题以评估四个图形理解的基本方面：实体识别、关系理解、知识定位以及视觉推理。Chimera用于度量三种视觉问答捷径的存在：视觉记忆捷径、知识回忆捷径和Clever-Hans捷径。", "innovation": "文章提出了名为Chimera的综合测试套件，用于评估是否存在视觉记忆捷径、知识回忆捷径和Clever-Hans捷径，以及这些捷径在开放源代码VLMs中的作用。这揭示了当前VLMs中存在的关键局限，并强调了需要更可靠的评估方案来测试复杂视觉输入（如图形）的真实理解能力而非问题回答捷径。研究结果展示了当前VLMs在众多开放源代码VLMs的弱表现很大程度上来自于捷径行为，包括视觉记忆捷径、知识回忆捷径和Clever-Hans捷径对表现的影响程度。", "conclusion": "目前的VLMs在复杂视觉输入的理解上存在重要限制，需要设计更为严格和能真正测试理解力的评估标准。通过Chimera，研究者发现在VLMs中捷径的存在是很普遍的，这强调了需要进一步优化这些模型以更好地理解和处理复杂的视觉内容。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22479", "html_url": "https://arxiv.org/abs/2509.22479", "title": "NeLLCom-Lex：一种研究词汇系统与语言使用之间互动的神经代理框架", "title_en": "NeLLCom-Lex: A Neural-agent Framework to Study the Interplay between Lexical Systems and Language Use", "authors": "Yuqing Zhang,Ecesu Ürker,Tessa Verhoef,Gemma Boleda,Arianna Bisazza", "background": "以往对词汇语义变化的研究主要依赖观察性和实验性方法；然而，观察性方法（如语料库分析、分布语义建模）无法揭示因果机制，而人类实验由于涉及长期的历时过程也难以应用。\n", "innovation": "本文提出NeLLCom-Lex，一种神经代理框架，旨在通过首先将代理嵌入真实的词汇系统（如英语），然后系统性地调整其沟通需求来模拟语义变化；使用颜色命名任务模拟单一代际内的词汇系统演变，探究哪些因素促使代理发展类似人类的命名行为和词汇表，以及根据其沟通需求改变其行为和词汇表。\n", "conclusion": "不同的监督和强化学习管道的实验表明，训练神经代理模仿现有语言的交流能力可以显著还原人类在颜色命名中的模式，这支持进一步使用NeLLCom-Lex来阐明语义变化的机制。\n"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22490", "html_url": "https://arxiv.org/abs/2509.22490", "title": "JGU Mainz的提交：WMT25共享任务关于斯拉夫语言有限资源LLM的机器翻译和问答", "title_en": "JGU Mainz's Submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: MT and QA", "authors": "Hossain Shaikh Saadi,Minh Duc Bui,Mario Sanz-Guerrero,Katharina von der Wense", "background": "该论文介绍了JGU Mainz针对WMT25共享任务提交的方法，该任务关注斯拉夫语言中的LLM在有限资源条件下的机器翻译和问答任务，重点是乌克兰语、上斯洛维尔斯克语和下斯洛维尔斯克语。论文提供了针对每个语言的模型训练细节，并强调了使用参数高效微调和集成的方法来提升模型性能。", "innovation": "论文的主要创新包括：1) 使用参数高效微调联合调优Qwen2.5-3B-Instruct模型用于机器翻译和问答任务；2) 集成了额外的翻译数据和多项选择问答数据；3) 对上斯洛维尔斯克语和下斯洛维尔斯克语使用检索增强生成方法进行问答任务；4) 应用集成方法提高上斯洛维尔斯克语和下斯洛维尔斯克语的问答任务性能；5) 实验结果表明，模型在两个任务上的性能均优于基准模型。", "conclusion": "研究结果证实，通过参数高效微调联合调优模型和集成方法有效提升了斯拉夫语言下的机器翻译和问答任务的性能。在各个任务上，JGU Mainz的模型都优于基准模型，展示了这种方法在斯拉夫语言中的适用性和有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22582", "html_url": "https://arxiv.org/abs/2509.22582", "title": "使用LLM进行细粒度上下文相关幻觉检测", "title_en": "Fine-Grained Detection of Context-Grounded Hallucinations Using LLMs", "authors": "Yehonatan Pesiakhovsky,Zorik Gekhman,Yosi Mass,Liat Ein-Dor,Roi Reichart", "background": "论文探讨了LLM（大语言模型）在本地化上下文相关幻觉方面的适用性，这是一种模型输出中包含无法验证回源文本的信息的情况。由于缺乏评估LLM幻觉定位能力的标准基准，研究构建了一个专用基准，并通过人工注释超过1,000个例子来挑战这一问题。此外，研究还提出了一个基于LLM的评估协议，并通过人工评估验证其质量。", "innovation": "研究提出了一种新的幻觉表示方法，基于自由形式的文本描述，能够捕捉全面的潜在错误类型。此外，研究确定了LLM在该任务上面临的主要挑战：（1）倾向于将实际存在的细节错误标记为不一致；（2）难以验证那些包含在输出中但不在源文本中的事实信息，因为这些信息与模型参数化的知识有所偏离。", "conclusion": "全面评估了四种大型语言模型，结果显示最佳模型的表现仅达到0.67的F1分数，表明幻觉定位任务的难度较大。研究还提出了优化提示策略的见解，并确定了使LLM难以完成该任务的主要因素。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22589", "html_url": "https://arxiv.org/abs/2509.22589", "title": "ArabJobs: 一个多国家的阿拉伯语招聘广告语料库", "title_en": "ArabJobs: A Multinational Corpus of Arabic Job Ads", "authors": "Mo El-Haj", "background": "阿拉伯劳动力市场存在语言、地域和经济的差异。阿拉伯求职者在不同地区和国家可能面临的信息和机会也可能不同。为了研究这些差异并提高阿拉伯自然语言处理（NLP）的公平性，一个名为ArabJobs的公共语料库被收集，它包含了来自埃及、约旦、沙特阿拉伯和阿拉伯联合酋长国的招聘信息。", "innovation": "ArabJobs提供了基于大规模语言模型的工资估算、职业类别标准化、性别偏见检测和职业分类等应用。该数据集展示了阿拉伯劳动力市场的性别代表性以及职业结构，并突出了广告中的方言差异，为未来研究提供新的方向。", "conclusion": "ArabJobs对于公平意识的阿拉伯语NLP和劳动力市场研究非常有用。此语料库已经被公开提供，允许研究人员进一步探索不同地区和语言背景下的劳动力市场差异，促进基于数据的研究和应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22565", "html_url": "https://arxiv.org/abs/2509.22565", "title": "增强检索为AI草拟的患者门户消息提供保障：错误分类体系构建和大规模评估", "title_en": "Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation", "authors": "Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma", "background": "异步患者-临床人员消息通过EHR门户系统的快速增长成为临床人员工作量的来源，促使研究关注大型语言模型（LLMs）以帮助草拟回复。然而，LLMs的输出可能包含临床不准确、遗漏或语气不匹配等问题，因此严格的评估是必要的。", "innovation": "本文的贡献在于：(1) 介绍了一个基于临床实践的错误本体，包含5个领域和59个具体的错误代码，其通过归纳编码和专家裁定开发；(2) 开发了一个检索增强的评估管道(RAEC)，利用语义相似的历史消息-回复对来提高判断质量；(3) 使用DSPy提供了一种两阶段提示架构，以实现可扩展、可解释和分层的错误检测。", "conclusion": "利用两阶段DSPy管道，我们对超过1,500条患者消息的基线和参考增强评估进行了比较。检索上下文在诸如临床完整性、工作流程适宜性等领域改善了错误识别。在100条消息的人类验证中，增强了上下文标签的共识度（一致性=50% vs. 33%）和性能（F1=0.500 vs. 0.256）均优于基线，支持使用我们的RAEC管道作为AI守护栏（AI guardrails）用于患者消息。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22472", "html_url": "https://arxiv.org/abs/2509.22472", "title": "评估大型语言模型在多语言法律推理中的界限", "title_en": "Evaluating the Limits of Large Language Models in Multilingual Legal Reasoning", "authors": "Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel", "background": "在大型语言模型（LLMs）主导的时代，全面理解其能力与局限性对于法律等高风险领域尤为重要。当前大型语言模型，如Meta的LLaMA、OpenAI的ChatGPT、谷歌的Gemini等，越来越多地被整合到法律工作流程中。然而，它们在多语言、法律管辖权多样性和对抗性情景下的表现尚未得到充分研究。本文通过评估LLaMA和Gemini在多语言法律和非法律基准测试中的性能，并通过字符和单词级别的扰动评估它们在法律任务上的抗对抗性能力，展示了这些情况下的表现。为此，研究还开发了一个开源、模块化的评估管道，旨在支持任何LLMs和数据集的多语言和任务多样化的基准测试，特别是针对法律任务，包括分类、总结、开放式提问和一般推理。研究结果表明，法律任务对大型语言模型构成了重大挑战，在LEXam等法律推理基准测试中，其准确率往往低于50%，而在通用任务如XNLI中的准确率则超过70%。此外，英语通常提供更稳定的结果，但并不总是获得更高的准确率。提示敏感性和对抗性易受攻击性同样在不同语言中持续存在。最后，研究还发现，语言性能与其与英语的句法相似性之间存在相关性。研究还发现，LLaMA在某些任务上的表现较Gemini弱，后者在相同任务上的平均优势约为24个百分点。尽管新的大型语言模型有所改进，但在关键的多语言法律应用领域可靠部署仍面临挑战。", "innovation": "研究开发了基于LLM-as-a-Judge的人工对齐评估方法，并展示了其在多语言、任务多样化的基准测试中的应用。此外，该研究还评估了大型语言模型在对抗性情景中的鲁棒性，并首次将其与法律任务相联系。研究还提出了一套开放源代码的模块化评估管道，可用于任何LLMs和数据集的多语言任务基准测试，特别是在法律任务方面。通过实现和完善该管道，不仅可以为研究和实践提供便利，还能促进更广泛的基准测试和研究合作。", "conclusion": "研究结果表明，法律任务对大型语言模型构成了显著挑战。模型在多语言法律推理任务中表现不佳，英语虽然提供了更稳定的结果，但在某些情况下并不一定更准确。提示敏感性和对抗性易受攻击性是语言模型普遍存在的问题，语言性能与其与英语的句法相似性之间存在相关性。LLaMA在某些任务上表现弱于Gemini，后者在同任务上平均优势约为24个百分点。尽管最近的大型语言模型有所改进，但在可靠部署于关键的多语言法律应用领域仍面临挑战。未来研究可以进一步优化语言模型的性能并提高其鲁棒性，以更好地支持法律应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22506", "html_url": "https://arxiv.org/abs/2509.22506", "title": "在提示语义任务空间中表示大型语言模型", "title_en": "Representing LLMs in Prompt Semantic Task Space", "authors": "Idan Kashani,Avi Mendelson,Yaniv Nemcovsky", "background": "大型语言模型（LLMs）在各种任务上取得了令人印象深刻的成果，不断扩大的公共存储库中包含了大量预训练模型。因此，为特定任务识别最佳性能的LLM是一个巨大的挑战。先前的工作建议学习LLM的表示以解决这个问题，但这些方法在可扩展性方面有限，需要昂贵的重新训练来包含额外的模型和数据集。此外，生成的表示利用了不同的空间不能轻易解释。本文介绍了一种高效的、无需训练的方法来将大型语言模型作为提示语义任务空间中的线性算子进行表示，从而提供了模型应用的高度可解释表示。该方法利用几何属性的闭式计算，确保了出色的可扩展性和对动态扩展存储库的实时适应性。我们在成功预测和模型选择任务上展示了该方法，取得了可竞争或最先进水平的结果，特别是在样本外场景中的卓越表现。", "innovation": "提出了一种无需训练的方法，将大型语言模型作为提示语义任务空间中的线性算子进行表示，这种方法利用闭式计算几何属性，确保了优秀的可扩展性和实时适应性。该方法提供了一个高度可解释的表示，且无需额外的训练和成本。", "conclusion": "该方法在成功预测和模型选择任务上取得了可竞争或最先进水平的结果，特别是在样本外场景中的卓越表现，表明这种方法对动态扩展的存储库具有强大的适应性，并且是高效且可解释的表示大型语言模型的有效方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22510", "html_url": "https://arxiv.org/abs/2509.22510", "title": "因此，我们在LLMs出错之前使其变得有用、无害和诚实", "title_en": "We Think, Therefore We Align LLMs to Helpful, Harmless and Honest Before They Go Wrong", "authors": "Gautam Siddharth Kashyap,Mark Dras,Usman Naseem", "background": "大型语言模型（LLMs）的多目标对齐对于确保模型的正确部署和使用至关重要。过去的研究中，通过对隐藏状态注入引导向量（即小控制信号），引导LLM的输出，通常使用一比一（1-to-1）的Transformer解码器对单一目标进行优化。然而，这可能会导致灾难性遗忘，即在优化某个目标的同时，覆盖了其他目标中学习到的表示。最新的方法使用一比多（1-to-N）的Transformer解码器来扩展引导向量，这可以在一定程度上缓解灾难性遗忘的问题，但采用简单的多分支设计时，可能因每个目标被独立优化而导致推理不一致，即不同目标的输出可能变得不一致。", "innovation": "本文提出了自适应多分支引导（AMBS），这是一种双阶段的一比N框架，用于统一并且高效地实现多目标对齐。第一阶段，Transformer层的后注意隐藏状态计算一次以形成共享表示。第二阶段，此表示被复制到并行分支并通过策略参考机制进行引导，这使得可以在保持跨目标一致性的同时实现每个目标的具体控制。实验结果表明，AMBS在多个7B LLM基线上能持续提升HHH对齐度，例如在DeepSeek-7B上，与简单的1-to-N基线相比，AMBS能够提高平均对齐得分32.4%，减少不安全输出11.0%，并且与最新的方法保持竞争力。", "conclusion": "AMBS框架能够有效克服传统方法中的挑战，统一并高效地实现多个目标之间的对齐，从而提供更安全和更可靠的LLM部署。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22546", "html_url": "https://arxiv.org/abs/2509.22546", "title": "通过认知推理实现社会思考", "title_en": "Think Socially via Cognitive Reasoning", "authors": "Jinfeng Zhou,Zheyu Chen,Shuai Wang,Quanyu Dai,Zhenhua Dong,Hongning Wang,Minlie Huang", "background": "LLMs 在逻辑推理方面表现出色，擅长逐步推理以得出可验证的答案。然而，这种方式并不适用于处理社会情境，因为社会情境中的推理是一个解释模糊线索的过程，很少能得出明确的结果。当前方法难以应对这些复杂的人际互动和认知需求。为解决这个问题，本文提出了认知推理的概念。认知推理以人类的社会认知为模型，将解释过程分解成一系列互联的认知单元（如观察或归因），这些单元可以灵活组合，从而增强社会思维和回应能力。", "innovation": "本文提出了认知推理（Cognitive Reasoning）的概念，并据此构建了 CogFlow 框架。CogFlow 通过模拟人类联想和逐渐推进的思想过程来收集认知流程的数据，采用监督微调使模型掌握基本的认知推理能力，并使用强化学习引导模型通过试错的方式提升自身，优化认知流程和回应质量。实验结果表明，CogFlow 能有效提高 LLMs 的社会认知能力，甚至提升人类的社会决策效果。", "conclusion": "CogFlow 框架充分展示了认知推理在增强 LLMs 社会认知能力方面的潜力，为提升 AI 在复杂社会情境中的表现提供了新思路。认知推理作为一种新的范式，有望通过系统化的认知流程改进方式，提高模型在理解复杂社会互动方面的能力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22612", "html_url": "https://arxiv.org/abs/2509.22612", "title": "从测试到效应大小：量化多语言和多任务自然语言处理评估基准中的不确定性和统计变异性", "title_en": "From tests to effect sizes: Quantifying uncertainty and statistical variability in multilingual and multitask NLP evaluation benchmarks", "authors": "Jonne Sälevä,Duygu Ataman,Constantine Lignos", "background": "本文介绍了基于重采样的方法来量化多语言和/或多任务NLP基准中评价指标的不确定性和统计精度。实验显示，性能分数的变异性来源于模型和数据的双重因素，需要同时考虑这两方面以避免大幅低估整体变异性。", "innovation": "提出了基于重采样的方法来量化多语言和多任务NLP基准中评价指标的不确定性和统计精度。使用多语言问答、机器翻译和命名实体识别为例，展示了这种方法在计算排行榜等相关量值的抽样分布中的实用性。", "conclusion": "证明了同时考虑模型和数据变异性的必要性，以及如何利用重采样方法准确评估各种排行榜中的量值的抽样分布。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20652", "html_url": "https://arxiv.org/abs/2509.20652", "title": "使用生成式AI加速产品声明的创建", "title_en": "Accelerate Creation of Product Claims Using Generative AI", "authors": "Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers", "background": "产品声明的效益主张对消费者购买行为至关重要。创造有效的产品声明需要大量的时间和资金。因此，业界一直在寻找更高效的方法来加快这一过程。", "innovation": "作者开发了名为'Claim Advisor'的网络应用程序，利用上下文学习和大型语言模型（LLM）的微调，实现了声明搜索、生成、优化和模拟的加速。它具有三个功能：1. 半语义搜索和识别与消费者声音匹配的声明或视觉材料；2. 根据产品描述和消费者画像生成或优化声明；3. 使用模拟的消费者对其生成的声明进行排名或人工创建的声明进行排名。", "conclusion": "在消费品公司中的应用结果非常有前景，表明这种能力在各个产品类别和行业中都有广泛的应用价值。作者呼吁研究和应用生成式AI的在不同行业的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21344", "html_url": "https://arxiv.org/abs/2509.21344", "title": "评估安全性监控时缓解信息泄露的方法", "title_en": "Towards mitigating information leakage when evaluating safety monitors", "authors": "Gerard Boxo,Aman Neelappa,Shivam Raval", "background": "白盒监控器能够通过分析大语言模型的内部机制来检测潜在有害行为，具有较低的计算成本和易于集成到层次防御系统中的优势。然而，训练和评估这些监控器需要展示目标行为的响应示例，这些示例通常通过提示或微调获得。但这种方法会引发现有的信息泄露问题，也就是用于引出现有行为的数据会不可避免地包含在监控器的输入数据中，从而提升监控器的效果。研究者提出了一个系统框架，用于评估监控器检测真实模型行为而非表面诱导伪迹的能力。他们还提出三项新型策略来评估监控器：内容过滤、评分过滤和提示精炼微调模型有机体。", "innovation": "提出了一个系统框架来评估监控器检测真实模型行为而非表象诱导伪迹的能力。还提出了内容过滤、评分过滤和提示精炼微调模型有机体三种新型策略，以缓解信息泄露对监控器性能的影响。通过多个误导性检测基准实验，结果显示这些策略能有效降低探测器的表现。", "conclusion": "研究发现，内容过滤是有效的缓解策略，能够平滑去除诱导信号，使探针AUROC降低约30%；评分过滤也能降低AUROC，但较难归因；微调模型有机体虽提高了监控器评估，但也降低了其性能最高可达40%。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22603", "html_url": "https://arxiv.org/abs/2509.22603", "title": "通过基于频率的量子深度学习方法捕捉 deliberative discourse 中的意见变化", "title_en": "Capturing Opinion Shifts in Deliberative Discourse through Frequency-based Quantum deep learning methods", "authors": "Rakesh Thakur,Harsh Chaturvedi,Ruqayya Shah,Janvi Chauhan,Ayush Sharma", "background": "对话过程中的审慎考虑在形成结果的过程中起着关键作用，这需要考虑各种视角并最终做出决定。近年来，自然语言处理（NLP）的进展使得通过分析意见变化来模拟审慎考虑并预测在不同情境下的潜在结果成为可能。本研究旨在利用NLP技术比较不同方法以评估其对协商话语的理解效果和生成的有意义见解。为此，收集了来自不同背景的个人意见，构建了一个反映不同观点的自我数据集。通过增强的产品展示来模拟审慎考虑，这些展示通常会引起观众意见的可测量变化。我们对两种模型进行了比较分析，分别是基于频率的对话调制和量子审慎框架，后者比现有的先进模型表现更好。研究结果强调了这些方法在公共政策制定、辩论评估、决策支持框架和大规模社交媒体意见挖掘中的实际应用可能性。", "innovation": "利用频率基础的量子深度学习方法来捕捉协商话语中的意见变化。这种方法比现有的先进模型表现出更好的表现，并且能够深入到公众政策制定、辩论评估、决策支持框架和大规模社交媒体意见挖掘等多个领域提供实际应用可能性。", "conclusion": "频率基础的量子深度学习模型在捕获协商话语中意见变化方面表现出色，其应用前景广阔，如公共政策制定、辩论评估、决策支持框架和大规模社交媒体意见挖掘等。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22638", "html_url": "https://arxiv.org/abs/2509.22638", "title": "语言模型可以通过口头反馈学习而无需标量奖励", "title_en": "Language Models Can Learn from Verbal Feedback Without Scalar Rewards", "authors": "Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang", "background": "传统上，大型语言模型（LLMs）常通过强化学习（RL）从人类或AI反馈中训练，但这种方法通常将复杂的反馈压缩为标量奖励，丢失了反馈的丰富性，并导致了不同规模的不平衡问题。为了改善这一现状，提出了一种新的方法，即将口头反馈作为条件信号处理，类似于文本到图像生成中的语言先验，使其能够生成以前未见过的提示的新颖输出。", "innovation": "提出了一种反馈条件策略（FCP），通过直接从响应反馈对进行学习，使用最大似然训练在线下数据上近似反馈条件后验。进一步开发了一种在线梯度提升阶段，其中策略在积极条件下生成并接收新鲜反馈以进一步提高。这种方法将反馈驱动的学习重新定义为条件生成，而不是奖励优化，提供了一种更具表现力的方式，使得LLMs能够直接从口头反馈中学习。", "conclusion": "此研究提供了一种新的方法，使得语言模型（LLMs）可以直接从口头反馈中学习，而不依赖于标量奖励，这将使其学习方式更加丰富和多样。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22630", "html_url": "https://arxiv.org/abs/2509.22630", "title": "StateX：通过后训练状态扩展增强RNN召回能力", "title_en": "StateX: Enhancing RNN Recall via Post-training State Expansion", "authors": "Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "尽管基于Transformer的模型在语言建模方面表现出色，但它们在处理长上下文时由于高复杂性而带来了高成本。相比之下，线性注意力和状态空间模型等递归神经网络(RNNs)由于它们恒定的每词复杂性而受到青睐。然而，这些递归模型在需要从长上下文中准确回忆信息的任务中效果不佳，因为所有上下文信息都被压缩到了一个恒定大小的循环状态中。先前的研究表明，循环状态的大小与召回能力呈正相关，但直接训练具有更大递归状态的RNN会导致高培训成本。", "innovation": "本文介绍了一种名为StateX的递归神经网络训练管道，用于在后训练阶段高效地扩展预训练RNN的状态。为两种流行的RNN类，即线性注意力和状态空间模型，设计了后训练架构修改，以无或几乎没有参数增加的方式扩展状态大小。实验结果表明，StateX能够在不增加后训练成本或牺牲其他能力的情况下增强RNN的回忆和上下文学习能力。", "conclusion": "实验表明，StateX通过无或近似无参数增加的方法，在不增加后训练成本的情况下，有效地提升了RNN的回忆能力以及上下文学习能力，而不会牺牲其他能力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22598", "html_url": "https://arxiv.org/abs/2509.22598", "title": "从形式语言理论到统计学习：子正规语言的有限可观察性", "title_en": "From Formal Language Theory to Statistical Learning: Finite Observability of Subregular Languages", "authors": "Katsuhiko Hayashi,Hidetaka Kamigaito", "background": "该研究旨在利用形式语言理论和统计学习方法来分析和理解自然语言结构。首先，文章指出正规语言的分类和学习方法已经被大量研究，但这些方法在处理更复杂语言现象时表现出局限性。传统的方法可能无法准确描述自然语言中复杂和多层次的语言结构。因此，研究者转向子正规语言（subregular languages），这些语言的分类比正规语言更为精细，可能是表达自然语言结构的有效工具。", "innovation": "文章创新地证明了所有正规语言的子类可以被线性分割，这依赖于它们的决定性谓词表示。这一发现意味着这些语言类在无噪声条件下具有完美的可观察性，并能够通过简单的线性模型进行学习。通过合成实验和真实数据实验（使用英语形态作为例子），研究成功验证了这一理论。实验结果显示，学习到的特征与已知的句法限制高度一致，进一步证明了子正规语言层次结构作为自然语言结构模型的合理性与解释性。", "conclusion": "研究结果表明，子正规语言提供了一个严谨且可解释的框架来建模自然语言的结构。这种新的方法不仅具有理论意义，也为自然语言处理提供了可操作的工具。此外，研究还强调了形式语言理论在解决复杂语言问题中的重要作用，并展示了统计学习方法如何能够有效利用这些理论来处理真实世界的语言数据。用于真实数据实验的代码已发布于该链接：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22637", "html_url": "https://arxiv.org/abs/2509.22637", "title": "语言模型的变分推理", "title_en": "Variational Reasoning for Language Models", "authors": "Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang", "background": "该论文介绍了一种变分推理框架，用于处理语言模型中的思维痕迹作为潜在变量，并通过变分推断优化它们。文章从证据下界（ELBO）出发，扩展到了多痕迹目标来获得更紧的边界，并提出了前向KL公式来稳定变分后验的训练。进一步研究发现，拒绝抽样微调和二元奖励RL，包括GRPO，可以被解释为局部前向KL目标，这揭示了一种隐含的、基于模型准确性的加权方法，表明对较简单的任务偏爱的现象。作者通过在Qwen 2.5和Qwen 3模型系列上广泛的任务上进行了实验证明了该方法的有效性。", "innovation": "文章引介了一种新的变分推理框架，通过将思维痕迹作为潜在变量并利用变分推断优化，扩展了证据下界到多痕迹目标，并提出了前向KL公式来稳定训练。研究表明，拒绝抽样微调和二元奖励RL可以被解释为局部前向KL目标，揭示了对较简单任务的偏爱。这种方法提供了一个基于概率的统一视角，将变分推断与RL风格的方法相结合，以提高语言模型的推理能力。", "conclusion": "本文通过提供一种基于概率的统一视角，将变分推断与RL风格的方法结合，提出了一种新的稳定目标，以改进语言模型的推理能力。研究结果表明，变分推理框架在广泛的任务上均有效果。此外，文章提供的代码可以在指定网址找到。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21403", "html_url": "https://arxiv.org/abs/2509.21403", "title": "LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?", "title_en": "LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?", "authors": "Rushil Gupta,Jason Hartford,Bang Liu", "background": "近年来，大型语言模型（LLMs）被提议作为通用实验设计代理，声称它们可以在上下文中进行实验设计。本文使用开放源代码和闭源指令调优的LLMs对基因扰动和分子性质发现任务进行评估，发现基于LLMs的代理在实验反馈方面缺乏敏感性：用随机排列的标签替换真实结果对性能无影响。经典方法如线性多臂老虎机和高斯过程优化在所有基准测试中总是优于LLM代理。", "innovation": "提出了一个简单的混合方法——LLM引导的最近邻采样（LLMNN），该方法结合了LLM先验知识和最近邻采样来指导实验设计。LLMNN在各个领域中实现了竞争性或优越的性能，无需大量上下文适应。", "conclusion": "当前开放源代码和闭源的LLMs在实际中不具备执行上下文实验设计的能力，提出现有的框架需要解耦基于先验的推理和更新后验的批量获取的混合框架，以更好地促进科学领域中的贝叶斯优化应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21447", "html_url": "https://arxiv.org/abs/2509.21447", "title": "ARTI-6: 向六维articulatory语音编码迈出一步", "title_en": "ARTI-6: Towards Six-dimensional Articulatory Speech Encoding", "authors": "Jihwan Lee,Sean Foley,Thanathai Lertpetchpun,Kevin Huang,Yoonjeong Lee,Tiantian Feng,Louis Goldstein,Dani Byrd,Shrikanth Narayanan", "background": "关于articulatory语音编码的研究，目前依赖实时MRI数据来捕捉关键的声带区域，如软腭、舌根和喉部。现有方法通常较为复杂，难以实现高效率和高解释性。", "innovation": "提出了ARTI-6框架，这是一个紧凑的六维articulatory语音编码框架，主要包括三个方面：一是六维articulatory特征集，涵盖关键的声带区域；二是articulatory反演模型，可以从语音声学中预测articulatory特征，预测相关性达到0.87；三是articulatory合成模型，可以直接从articulatory特征重建可理解的自然语音，即使特征维度较低也能生成自然的声音。该工作提供了对articulatory反演、合成及其更广泛语音技术应用具有解释性、计算效率和生理基础的框架。", "conclusion": "ARTI-6为articulatory反演、合成和更广泛语音技术应用提供了一个解剖学基础、计算效率高且具有良好解释性的框架，并且源代码和语音样本已在公共平台上发布。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22644", "html_url": "https://arxiv.org/abs/2509.22644", "title": "WebGen-Agent：通过多层次反馈和步骤级强化学习增强交互式网页生成", "title_en": "WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning", "authors": "Zimu Lu,Houxing Ren,Yunqiao Yang,Ke Wang,Zhuofan Zong,Junting Pan,Mingjie Zhan,Hongsheng Li", "background": "基于大语言模型（LLMs）的代理系统在仓库级别的代码生成任务中表现出色。但对依赖视觉效果和用户交互反馈的任务（如网站代码生成），当前代码代理仅依赖简单的代码执行来获取反馈，这种方法无法准确评估生成代码的质量。因此，提出了WebGen-Agent，结合视觉反馈机制，在截图和GUI代理测试的基础上生成详尽的视觉描述和建议，并通过回溯和选择最优机制提升性能。利用WebGen-Agent工作流中的准确视觉评分，引入了一种新的训练方法——Step-GRPO，通过在每一步使用截图和GUI代理评分作为奖励信号，提供密集可靠的监督信号，显著提高代码生成质量。", "innovation": "1. 提出了WebGen-Agent，利用全面的多层次视觉反馈机制迭代生成和优化网站代码库。\n2. 引入了Step-GRPO（带有截图和GUI代理反馈的步骤级策略梯度优化）方法，通过每一步使用截图和GUI代理评分作为奖励信号，提供密集和可靠的过程监督信号。\n3. 在WebGen-Bench数据集上，WebGen-Agent显著提高了Claude-3.5-Sonnet和Qwen2.5-Coder-7B-Instruct在网站生成任务中的准确性和外观得分，超越了之前的最优系统。", "conclusion": "通过引入多层次视觉反馈机制和Step-GRPO训练方法，WebGen-Agent在网站生成任务中取得了显著的提升。该工作为互动式网站生成提供了一种新的解决思路，通过增强模型的理解能力，实现了更高质量的网页自动生成。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22641", "html_url": "https://arxiv.org/abs/2509.22641", "title": "超越n-克gram新颖性作为文本创造力度量指标的终结", "title_en": "Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual Creativity", "authors": "Arkadiy Saakyan,Najoung Kim,Smaranda Muresan,Tuhin Chakrabarty", "background": "N-克gram新颖性被广泛用来评价语言模型生成超出训练数据范围文本的能力，最近也用于评估文本的创造力。然而，创造力的理论研究指出这种方法可能不够全面，因为它没有考虑到创造力的双重性质：新颖性（文本的原创性）和适宜性（文本的合理性与实践性）。现有研究大多认为n-克gram新颖性与创造力呈正相关，但忽视了这种相关性的不足。研究者通过7542位专家作者对52份文本进行标注，评估文本的新颖性、适宜性和合理性，发现尽管n-克gram新颖度与专家评的创造力正相关，但大部分顶四分位的新颖表达并不被认为是创造性的。同时，开源的LLM中n-克gram新颖性越高，适宜性越低，这在前沿的限源模型中进一步得到验证。通过测试零样本、少样本和微调模型识别创造性和非适宜表达的能力，进一步确认前沿的LLM在这方面有巨大改进空间，尤其是在识别非适宜表达方面。", "innovation": "本研究通过大量专家作者的标注数据，评估文本的新颖性与创造力之间的关系，并指出n-克gram新颖性在评估文本创造力时的局限性。研究还发现前沿的限源模型在创造力和非适宜性的识别上表现不佳，相较于现有开源LLM有改进空间。此外，研究还测试了不同训练模型对创造性和非适宜性的识别能力，并发现最佳模型的n-克gram新颖性评分与专家偏好高度相关。", "conclusion": "n-克gram新颖性作为衡量文本创造力的指标存在局限性，需要更全面的度量标准来评估文本的创造性。研究还指出，前沿的限源模型在识别创造性和非适宜性表达方面仍有改进空间，尤其是对于非适宜性的识别。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22651", "html_url": "https://arxiv.org/abs/2509.22651", "title": "VoiceAssistant-Eval：跨听、说、看评估人工智能助手的标准", "title_en": "VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing", "authors": "Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li", "background": "随着大型语言模型和多模态系统的不断进步，对于以语音为主导的AI助手的兴趣日益增加，但现有的基准测试工具不足以全面评估这些系统的能力。研究人员引入了VoiceAssistant-Eval，这是一个全面的基准测试，用于评估AI助手在听、说和看方面的表现。该基准测试包含10,497个精心挑选的示例，覆盖13个任务类别，包括自然声音、音乐和口头对话（听）、多回合对话、角色扮演模仿以及各种场景（说），以及种类繁多的图像（看）。", "innovation": "VoiceAssistant-Eval 是一个全新的基准测试，能够全面评估AI助手在听、说、看三个方面的表现。研究人员评估了21个开源模型和GPT-4o-Audio，并用这些模型生成了关于响应质量、内容和一致性方面的详细报告。此外，研究指出，模型面对多模态（听觉+视觉）输入和角色扮演声音模仿任务比较困难，需要进一步优化以提高鲁棒性和安全性符合度。", "conclusion": "VoiceAssistant-Eval 的结果揭示了几个关键发现：1）专有模型并不都优于开源模型；2）大多数模型在口语任务中表现优异但在音频理解方面略有不足；3）设计良好的小型模型能与大型模型相媲美。此外，研究还识别出一些现有模型的不足之处，为下一代AI助手的评估和开发提供了严谨的框架。所有代码和数据将在此网址发布：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21451", "html_url": "https://arxiv.org/abs/2509.21451", "title": "VideoJudge: 使用自举实现大规模多模态语言模型作为评判器的可扩展监督", "title_en": "VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding", "authors": "Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj", "background": "精确评估视频理解模型仍然具有挑战性：常用的评估指标如BLEU、ROUGE和BERTScore无法捕捉人类判断的细微之处，而通过手动评估获取这样的判断成本高昂。近年来，研究已经开始探索使用大语言模型（LLMs）或多模态大语言模型（MLLMs）作为评估模型，但在视频理解领域的应用仍然相对较少。", "innovation": "本文引入了VideoJudge，这是一种专门用于评估视频理解模型输出（即基于视频生成的文本响应）的3B和7B大小的多模态大语言模型。为了训练VideoJudge，作者提出了一种基于生成器和评估器之间的互动的训练方法。此外，VideoJudge-7B在三个出三个元评估基准中优于更大的MLLM基准模型如Qwen2.5-VL（32B和72B）。研究发现，LSTM判规模较小的语言模型（Qwen3）在评估性能上不如多模态语言模型（Qwen2.5-VL），并且长链推理并未提高性能，表明提供视频输入对于视频理解任务的评估至关重要。", "conclusion": "研究展示了VideoJudge在视频理解评估任务上的有效性和优势，并强调了提供视频输入在评估视频理解模型中的关键作用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21552", "html_url": "https://arxiv.org/abs/2509.21552", "title": "通过视觉反馈的空间推理学习GUI定位", "title_en": "Learning GUI Grounding with Spatial Reasoning from Visual Feedback", "authors": "Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim", "background": "GUI接地通常被构架为一个坐标预测任务，即给定自然语言指令，生成屏幕上的坐标以进行点击和按键等操作。然而，最新的视觉语言模型在处理具有复杂布局的高分辨率GUI图像时，往往无法准确预测数值坐标。", "innovation": "本文重新构架了GUI接地任务为一个交互搜索任务，利用视觉语言模型生成动作以移动GUI中的光标，并定位UI元素。模型在每一步决定目标对象，评估光标与目标之间的空间关系，并根据移动历史调整光标的移动方向以接近目标。通过多步在线强化学习以及基于密集轨迹的奖励函数进行训练。实验结果显示，基于Qwen2.5-VL-7B的GUI-Cursor提高了GUI接地准确率，并在ScreenSpot-v2和ScreenSpot-Pro上分别达到了93.9%和56.5%的SOTA结果。", "conclusion": "GUI-Cursor能够在95%的情况下，在两步内解决问题，并针对更难的问题自动执行更多步骤，从而提高了GUI定位的准确性，实现了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21351", "html_url": "https://arxiv.org/abs/2509.21351", "title": "随机直接偏好优化在放射学报告生成中的应用", "title_en": "Random Direct Preference Optimization for Radiography Report Generation", "authors": "Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev", "background": "放射学报告生成（RRG）因其在减轻放射科医生工作量方面的潜力而在医学图像分析中引起了广泛关注。尽管已经取得了一些进展，但现有方法尚未达到在实际临床环境中部署所需的高质量标准。此外，大规模视觉语言模型（VLMs）通过采用原本用于大规模语言模型（LLMs）的训练策略（如对齐技术）在通用领域取得了显著进展。", "innovation": "本文提出了一种模型无关框架，通过直接偏好优化（DPO）中的随机对比抽样来增强RRG精度，消除了对奖励模型或人类偏好注释的需求，从而在不增加额外训练数据的情况下提升临床性能指标最多5%。", "conclusion": "实验表明，将随机直接偏好优化（Random DPO）补充到三个最先进的模型中可以提高临床性能指标，补充了现有的RRG方法并提高了其在实际应用中的可行性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21336", "html_url": "https://arxiv.org/abs/2509.21336", "title": "HetaRAG：跨异构数据存储的混合深度检索增强生成", "title_en": "HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores", "authors": "Guohang Yan,Yue Zhang,Pinlong Cai,Ding Wang,Song Mao,Hongwei Zhang,Yaoze Zhang,Hairong Zhang,Xinyu Cai,Botian Shi", "background": "检索增强生成（RAG）已成为缓解大语言模型（LLMs）知识幻觉和过时的主导范式，同时保持数据安全性。传统的RAG系统仅限于文本检索，并且通常依赖单一的存储后端，最常见的是向量数据库。这种单一设计在实践中存在不可避免的权衡：向量搜索捕捉语义相似性但损失全局上下文；知识图谱在关系精确性方面表现出色但召回率较低；全文索引快速且精确但语义盲；关系型数据库如MySQL提供强事务保证但没有语义理解。我们提出这些异构检索范式是互补的，提出了一个原理性的融合方案，以协同地调度它们，弥补任何单一模态的弱点。在这个工作中，我们提出了HetaRAG，一种混合深度检索增强生成框架，从中协调异构数据存储的多模态证据。计划将向量索引、知识图谱、全文搜索引擎和结构化数据库统一到一个检索层中，动态地路由和融合证据以最大化召回率、精确率和上下文忠实度。为实现这一设计目标，我们进行了初步探索并构建了初始RAG管道；这份技术报告提供了简要概述。部分代码可在 [这里]（https://）获取。", "innovation": "提出了一种原理性的融合方案，协同调度向量索引、知识图谱、全文搜索引擎和关系型数据库，以克服单一检索方法的局限性。此外，HetaRAG框架旨在统一这些不同类型的数据存储，动态调度和融合证据以最大化检索的召回率、精确率和上下文忠实度。这是首次尝试构建一个能够跨异构数据存储融合多种检索方法的混合型RAG框架。", "conclusion": "介绍了HetaRAG框架的核心理念并计划实现的初步探索结果，虽然目前仅提供了技术报告和部分代码，但已经展示出解决单一检索方法局限性的潜力。该方案旨在为RAG技术提供一个新的、更完善的方向，并为未来相关研究开辟道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21371", "html_url": "https://arxiv.org/abs/2509.21371", "title": "ReGeS: 相互作用的检索生成协同作用对于对话推荐系统", "title_en": "ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems", "authors": "Dayu Yang,Hui Fang", "background": "对话推荐系统（CRS）需要连接对话内容与外部领域知识，以便正确理解用户偏好。现有的解决方案要么需要领域特定的工程，这限制了灵活性，要么完全依赖大型语言模型，增加了幻觉的风险。虽然检索增强生成（RAG）具有潜力，但其在CRS中的直接应用受到噪音对话的阻碍，这减弱了检索效果，并忽视了相似项目之间的细微差别。", "innovation": "提出了一个相互作用的检索生成协同作用框架（ReGeS），该框架结合了生成增强检索和检索增强生成，以提取对话中的关键用户意图，并区分细微的商品特征。这种协同作用消除了额外标注的需求，减少了幻觉，并简化了持续更新。实验表明，ReGeS 在多个CRS基准测试中的推荐准确性达到了最先进的水平，证明了相互作用的协同作用在知识密集型CRS任务中的有效性。", "conclusion": "ReGeS框架展示了检索生成协同作用在对话推荐系统中的有效性，通过结合生成增强检索和检索增强生成，有效地理解了用户偏好，并提高了推荐准确性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21629", "html_url": "https://arxiv.org/abs/2509.21629", "title": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?", "title_en": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?", "authors": "Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken", "background": "程序验证依赖于循环不变量，自动发现强大的不变量仍然是一项长期的挑战。", "innovation": "本研究提出了一种基于验证器的决策过程框架来进行大型语言模型（LLM）的不变量合成评估。该方法不仅评估正确性，还评估不变量在验证过程中提供的加速效果。本文评估了7种最先进的LLM及其基于LLM的验证器与传统的UAutomizer求解器。", "conclusion": "虽然基于LLM的验证器展示了潜力，但尚未明显超越UAutomizer。模型能力也至关重要，不同模型之间的加速效果差异显著。监督微调和Best-of-N采样可以提升性能：微调后的Qwen3-Coder-480B在加速案例中提高了比例至29.2%，而使用N=16的Best-of-N采样后，Claude-sonnet-4的加速率提高到了22.1%。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21473", "html_url": "https://arxiv.org/abs/2509.21473", "title": "是幻觉不良的推测吗？", "title_en": "Are Hallucinations Bad Estimations?", "authors": "Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu", "background": "该研究将生成模型中的幻觉定义为将估计与任何可能的原因断开连接的失败。研究者证明，即使是最小化损失的最优估计器也可能产生幻觉，并通过通用的数据分布获得高强度的幻觉率下界来验证这一点。进一步将幻觉重新定位于损失最小化与人类可接受输出之间的结构不对齐，以及因此产生的估算误差.", "innovation": "该研究通过将幻觉视为生成模型优化目标和人类期望输出之间的不匹配，提供了一个新的视角，并通过实证分析支持了这一点。研究者提供了在硬币聚集、开放问答和文本转图像等任务上的实验支持.", "conclusion": "该工作重新定义了幻觉的概念，认为它们是由于模型优化目标与人类期望之间的不匹配导致的误估算，并通过实验验证了这一观点，在生成模型的评估和改进中具有重要意义."}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21514", "html_url": "https://arxiv.org/abs/2509.21514", "title": "不确定性意识的知识追踪模型", "title_en": "Uncertainty-Aware Knowledge Tracing Models", "authors": "Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead", "background": "知识追踪（KT）模型的主要研究方向是提高预测准确性，但大部分模型在学生选择干扰项时预测错误，导致未能检测到学生的错误。因此，很多研究集中在模型开发上，旨在提高预测准度，但尚未充分利用预测不确定性作为新的模型能力。", "innovation": "本文提出了一种通过捕捉预测不确定性来增强KT模型的新方法，并表明较大的预测不确定性与模型预测错误相一致。研究表明，KT模型中的不确定性信息具有指导意义，并且这一信号在有限资源环境下理解和提升学生能力的应用中具有教育价值。", "conclusion": "不确定性在KT模型中是具有信息价值的信号，可以应用于教育资源匮乏的教育学习平台，帮助更好地理解学生的技能水平。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21466", "html_url": "https://arxiv.org/abs/2509.21466", "title": "沙特阿拉伯职业角色中的性别刻板印象：语言模型生成的AI图像分析研究", "title_en": "Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models", "authors": "Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa", "background": "该研究探讨了当下文本到图像的人工智能（AI）模型在生成沙特阿拉伯专业人员形象描绘时，是否延续了性别刻板印象和文化不准确性。研究通过分析1006张由ImageFX、DALL-E V3和Grok生成的代表56个不同沙特职业的图像，揭示了当前AI模型在性别比例上的显著失衡及文化背景上的不准确性问题。", "innovation": "研究采用多模型综合分析的方法，通过受过训练的沙特籍注释员对图像进行多维度评估，特别是从性别、着装、背景、活动和年龄进行细致分析。此举不仅提高了评价的标准化和准确性，而且对后续研究提供了新的方法论参考。研究还揭示了某些模型在描绘性别多样性方面表现更差，指出AI输出反映了训练数据中的社会偏见，并强调了多样化训练数据和偏见纠正的重要性。", "conclusion": "当前AI模型在生成相关图像时体现了训练数据中固有的社会偏见，反映出性别不平等和文化多样性不足的问题。这凸显了需要更多元的训练数据、更公正的算法以及文化敏感的评估框架，以确保视觉输出的公允性和真实性。研究结论强调了改进AI生成的图像质量和提高其文化适应性的紧迫性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21548", "html_url": "https://arxiv.org/abs/2509.21548", "title": "C-QUERI：国会提问、交流及回应机构数据集", "title_en": "C-QUERI: Congressional Questions, Exchanges, and Responses in Institutions Dataset", "authors": "Manjari Rudra,Daniel Magleby,Sujoy Sikdar", "background": "政治采访和听证会中的问题具有超出信息获取的战略目的，包括促进党派叙事和塑造公众看法。然而，这些战略方面因缺乏大规模数据集而未得到充分研究。国会听证会提供了一个特别丰富且易于研究政治提问的场所：互动受正式规则制约，证人必须回答，不同政治派别的成员都有机会提问，从而实现不同政治谱系的行为比较。", "innovation": "开发了一种从未结构化听证会记录中提取问题-答案对的管道，并构建了一个从第108届至第117届国会的新颖听证会数据集。分析揭示了不同政党在提问策略上的系统性差异，并展示可以从仅提问的内容预测提问者的党派归属。该数据集和方法不仅推进了国会政治的研究，还提供了一个在类似访谈环境分析提问-回应的通用框架。", "conclusion": "该数据集和方法不仅为国会政治研究提供了新工具，还为其他类似面试环境中的问题-解答分析提供了通用框架。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21501", "html_url": "https://arxiv.org/abs/2509.21501", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants？", "title_en": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "authors": "Lu Sun,Shihan Fu,Bingsheng Yao,Yuxuan Lu,Wenbo Li,Hansu Gu,Jiri Gesi,Jing Huang,Chen Luo,Dakuo Wang", "background": "随着AGI（Agentic AI）的兴起，能够通过自然语言执行任务的系统日益增多，例如在编程中的Copilot或在购物中的Amazon Rufus。评估这些系统颇为困难，因为它们的快速进化远超出了传统的基于人工的评估方法。已有研究提出使用LLM Agents模拟参与者作为数字孪生以进行评估，但如何准确地用数字孪生代表特定客户进行多轮互动这一问题仍有待解决。因此，本研究招募了40名人类参与者与Amazon Rufus进行购物，并收集了他们的身份特征、交互痕迹以及用户体验反馈，以创建模拟用户的数字孪生体进行重复任务。", "innovation": "本研究首次量化了LLM代理如何接近人类与AGI系统进行多回合交互，表明虽然代理探索了更多的选择，但其行为模式与人类相似，并且以类似的设计反馈。这项研究进一步揭示了LLM代理在大规模评估AGI系统的潜力。", "conclusion": "通过比较人类参与者与数字孪生体在多轮交互中的行为，本研究强调了LLM代理在模拟人类与AGI系统交互方面的效度，为AGI系统的评估提供了新的可能性。该研究是首次直接将LLM代理与AGI系统进行多轮交互后进行的一次定量分析，为未来此类研究提供了宝贵的数据参考。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21597", "html_url": "https://arxiv.org/abs/2509.21597", "title": "AUDDT: 音频统一深度伪造检测基准工具箱", "title_en": "AUDDT: Audio Unified Deepfake Detection Benchmark Toolkit", "authors": "Yi Zhu,Heitor R. Guimarães,Arthur Pimentel,Tiago Falk", "background": "随着人工智能生成内容（如音频深度伪造）的普及，最近的研究工作主要集中在开发深度伪造检测技术上。然而，大多数模型仅在有限的数据集上进行评估，这使得其在真实世界条件下的泛化能力不明确。为此，本文系统地回顾了28个现有的音频深度伪造数据集，并提供了名为AUDDT的开源基准工具包（可访问地址）。该工具包旨在自动化对这些28个数据集中的预训练检测器进行评估，为用户提供有关其深度伪造检测器的优势和不足的直接反馈。", "innovation": "本文创新性地开发了一套名为AUDDT的开源基准工具包，用于自动评估预训练的音频深度伪造检测器的表现。该工具包提供了工具和详细的基准，帮助研究者更好地理解不同音频欺诈内容检测器的效果和局限性，尤其是针对环境和音频处理类型的差异进行检测时的性能差异。此外，还分析了现有数据集的局限性及其与实际部署场景之间的差距。", "conclusion": "本文展示了开发工具的使用方法、基准构成以及不同深度伪造子组的分解。通过广泛使用的预训练深伪检测器，在域内和跨域检测结果中的显著差异被揭示。最后，也对现有数据集的限制进行了分析，并指出了与实际部署场景之间的差距。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21579", "html_url": "https://arxiv.org/abs/2509.21579", "title": "利用大数据框架在亚马逊评论中检测垃圾信息", "title_en": "Leveraging Big Data Frameworks for Spam Detection in Amazon Reviews", "authors": "Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed", "background": "在数字时代，网上购物已成为日常生活中的常见行为。产品评论对影响消费者的购买行为和建立买家信任至关重要。然而，虚假评论的泛滥损害了这种信任，可能导致误导消费者并对卖家造成声誉损害。本研究通过在大量亚马逊产品评论数据集上应用先进的大数据分析和机器学习方法，解决这一紧迫问题。", "innovation": "本文利用可扩展的大数据框架对大规模评论数据进行高效处理和分析，提取表明欺诈行为的关键特征。通过多种机器学习分类器的应用，特别是Logistic回归取得了90.35%的准确率，为更值得信赖和透明的网上购物环境做出了贡献。", "conclusion": "本研究强调了在亚马逊评论中利用各种机器学习分类器检测垃圾评论的价值，为提升评论的真实性和透明度提供了解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21766", "html_url": "https://arxiv.org/abs/2509.21766", "title": "UltraHorizon：超长时域场景下智能体能力基准测试", "title_en": "UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios", "authors": "Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen", "background": "自主代理在多种领域中取得了显著的进展，但大多数评估主要集中在短时域、完全可观测的任务上。然而，许多关键的现实世界任务，如大规模的软件开发、商业投资和科学发现，通常在长时域和部分可观测的场景中展开，其中的成功取决于持续的推理、规划、记忆管理以及工具使用。现有的基准测试很少能捕捉到这些长时域的挑战，导致了系统性评估的不足。为了弥补这一短板，本文介绍了UltraHorizon，一个新颖的基准测试，旨在衡量执行复杂现实挑战所需的基础能力，并使用探索作为统一任务，在三个不同的环境中验证这些核心技能。", "innovation": "引入了UltraHorizon，一个新颖的基准测试，用于测量执行复杂现实挑战所需的基础能力。将探索作为统一任务，在三个不同的环境中验证这些核心技能。提出了两种主要的原因来解释智能体在任务中的失败，分别是情境锁定和功能基本能力缺口。", "conclusion": "实验结果表明，大语言模型代理在这些环境中表现不佳，而人类参与者则取得了更高的分数，突显了智能体在长期能力方面的持续差距。此外，简单的放缩也无法在该任务中发挥作用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21984", "html_url": "https://arxiv.org/abs/2509.21984", "title": "从偏差到平衡：探索和缓解LVLM中的空间偏差", "title_en": "From Bias to Balance: Exploring and Mitigating Spatial Bias in LVLMs", "authors": "Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Weili Guan,Jun Yu,Min Zhang", "background": "大型多模态视觉语言模型（LVLMs）在各种多模态任务中取得了显著的成功，但它们对空间变化的鲁棒性尚未得到充分理解。", "innovation": "本工作系统地研究了LVLM中的空间偏差，特别是在图像中同一关键视觉信息在不同位置放置时，模型如何响应。通过精心设计的探测数据集，展示了当前LVLM在空间偏移下常常产生不一致输出的证据，揭示了其在空间语义理解上的基本局限性。进一步分析表明，这一现象不是来自视觉编码器（其能可靠地感知和解释视觉内容），而是来自语言模型组件中的位置嵌入设计不平衡。提出了Balanced Position Assignment (BaPA) 机制，即分配相同的全局位置嵌入到所有图像标记，以促进视觉信息的更均衡整合。", "conclusion": "广泛的实验表明，BaPA可以增强LVLM的空间鲁棒性，且无需重新训练。结合轻量级微调时，进一步提高了其在各种多模态基准测试中的性能。进一步的信息流分析表明，BaPA导致了平衡的注意力机制，从而实现了更全面的视觉理解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21868", "html_url": "https://arxiv.org/abs/2509.21868", "title": "什么使大规模语言模型代理模拟对政策有用？来自紧急准备领域迭代设计参与的见解", "title_en": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "authors": "Yuxuan Li,Sauvik Das,Hirokazu Shirado", "background": "随着对利用大规模语言模型作为代理（LLM代理）进行社会模拟以指导政策的兴趣增长，其在现实世界中的应用仍然受限。这项研究探讨了如何使LLM代理模拟对政策制定真正有用。研究人员与一所大学的紧急准备团队进行了为期一年的迭代设计合作，开发了13,000个代理模型来模拟大规模集会期间的应急场景中的群众行为和通信。这些模拟影响了实际政策的制定，包括志愿者培训、疏散方案和基础设施规划。", "innovation": "研究强调了三个设计影响：从可验证的场景开始并逐步建立信任；使用初步模拟激发隐含知识；将模拟和政策开发视为不断发展的过程，两者共同进化。这些发现为开发对政策制定真正有用的LLM代理模拟指出了实际路径。", "conclusion": "这些模拟影响了实际政策的制定，包括志愿者培训、疏散方案和基础设施规划。研究识别出三个设计影响，指出使LLM代理模拟对政策真正有用的实际途径。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21733", "html_url": "https://arxiv.org/abs/2509.21733", "title": "UISim: 动态移动环境中的交互式图像基础UI模拟器", "title_en": "UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments", "authors": "Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen", "background": "由于现实世界移动环境的动态和多样性，开发和测试用户界面（UI）以及训练AI代理与它们交互是具有挑战性的。现有的方法往往依赖于繁琐的物理设备或屏幕截图的有限静态分析，这阻碍了可扩展的测试和智能UI代理的开发.", "innovation": "我们引入了UISim，这是一种新型基于图像的UI模拟器，提供了一个纯基于屏幕图像的动态和交互式平台来探索移动电话环境。系统采用两阶段方法：给定初始屏幕图像和用户操作，首先预测下一个UI状态的抽象布局，然后根据该预测布局合成一个新的视觉一致的图像。这种方法使UI过渡的现实模拟成为可能。UISim为UI测试、快速原型制作和合成数据生成提供了即时的实际利益，并且其交互式功能为高级应用，如AI代理的UI导航任务规划铺平了道路。我们的实验结果表明，UISim在生成现实且连贯的后续UI状态方面优于端到端的UI生成基线，突显了其真实性和对UI开发流程的潜在简化以及提高AI代理训练的效果.", "conclusion": "我们的实验结果表明，UISim在生成现实且连贯的后续UI状态方面优于端到端的UI生成基线，证明了其真实性和对UI开发流程的潜在简化以及提高AI代理训练的效果，并且UISim潜在为AI代理的UI导航任务规划等高级应用铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22034", "html_url": "https://arxiv.org/abs/2509.22034", "title": "思考的光谱：通过模型合并实现大语言模型中可调推理能力的经验研究", "title_en": "The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging", "authors": "Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li", "background": "随着多个现实应用对具有可调推理能力的大语言模型（LLMs）需求的增长，迫切需要能够高效生成平衡推理深度和计算成本的模型的方法。模型合并作为一种无需训练的技术，可以通过算术结合通用模型与专业推理模型的权重来解决这一挑战。然而，现有合并技术对推理能力进行细粒度控制以生成一系列模型的潜力尚未得到充分探索。", "innovation": "这项研究对多种模型合并技术进行了大规模的经验评估，跨多个推理基准。通过系统地改变合并强度来构建准确性和效率曲线，提供了一个全面的可调性能景观视野。研究发现，模型合并提供了一种有效可调的方法，平衡推理准确性和标记效率，即使父模型的权重空间差异很大。关键的是，研究识别出帕累托改进的实例，即合并模型在准确性和标记消耗方面都优于其父模型。", "conclusion": "该研究提供了可调空间的首次全面分析，为根据多样化应用需求创建具有特定推理特性的大语言模型提供了实际指南。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21949", "html_url": "https://arxiv.org/abs/2509.21949", "title": "评估开源大型语言模型在技术电信问答中的应用", "title_en": "Evaluating Open-Source Large Language Models for Technical Telecom Question Answering", "authors": "Arina Caraus,Alessio Buscemi,Sumit Kumar,Ion Turcanu", "background": "大型语言模型（LLMs）在多个领域展示了出色的性能，但在诸如电信等技术领域的应用仍很少被探索。本文通过评估两开源LLM模型，Gemma 3 27B和DeepSeek R1 32B在复杂无线通信材料中的事实性和推理性问题上的表现，回答了这一领域的问题。", "innovation": "研究创新点在于首次将模型应用于电信技术领域，通过构建问题和答案基准，并使用词汇匹配、语义相似性和模型评分方法进行评估，探讨模型在一域内的一致性、判断可靠性和创造性潜能等关键方面。此外，研究进一步揭示了电信应用中存在的当前限制，并强调了适应领域模型的重要性以支持工程领域中的可信人工智能助手的开发和应用", "conclusion": "研究发现，Gemma在语义保真度和模型评价正确性方面表现出色，而DeepSeek在词汇一致性方面表现稍好。另外，研究结果还表明当前在应用LLMs于电信领域时存在一些局限性，应力图开发和利用适应领域模型来支持工程师所信赖的人工智能助手。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21793", "html_url": "https://arxiv.org/abs/2509.21793", "title": "编译证明：基于形式语义的无语言依赖自动优化", "title_en": "Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics", "authors": "Jianhong Zhao,Everett Hildenbrandt,Juan Conejero,Yongwang Zhao", "background": "证明验证可以完整编码程序行为，但在验证正确性后会丢弃这些证明。本文提出了‘编译证明’这一范式，该范式将这些证明转换为优化执行规则，通过符号执行构造全路径可达性证明，并编译其图结构，从而把许多语义重写精简为单一规则，且通过构建过程中保证正确性。这种方法在K框架的基础上实现了语言无关的扩展，实验证明在不同编译范围上都取得了性能提升结果，从汇编指令层的优化到全程序编译都展现出了显著的速度提升效果。", "innovation": "提出了‘编译证明’这一范式，通过符号执行构造全路径可达性证明，将证明转换为优化执行规则，并在K框架上实现了语言无关的自动优化扩展。这种方法不仅减少了冗余的语义重写，还通过构建过程中确保问题的正确性，同时实现了指令级和全程序级别的性能提升，后者达到数个数量级的性能增益。", "conclusion": "本文提出的方法在不同编译范围内均实现了性能提升，汇编指令级优化表现出一致的加速效果，而全程序编译则达到了数量级的数量级性能增益，展示了在不同层次上实现自动优化的能力和潜在应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21843", "html_url": "https://arxiv.org/abs/2509.21843", "title": "SBFA: 单个隐蔽位翻转攻击以破坏大型语言模型", "title_en": "SBFA: Single Sneaky Bit Flip Attack to Break Large Language Models", "authors": "Jingkai Guo,Chaitali Chakrabarti,Deliang Fan", "background": "大型语言模型（LLMs）的模型完整性已成为安全方面的关键问题，因为它们在互联网上的大规模部署。先前的位翻转攻击（Bit-Flip Attacks, BFAs）可以严重破坏深度神经网络（DNNs）的性能，甚至少量的位翻转就可能导致准确性大幅下降。近期的研究表明，尽管模块化和冗余性被认为是更好的鲁棒性保证，但对于LLMs来说，少量的恶意位翻转也能够导致灾难性的准确性损失。然而，现有的BFAs方法通常只针对整数或浮点数模型中的某一种，限制了攻击的灵活性。在浮点模型中，随机的位翻转经常导致参数值极端异常（如翻转阶码位），导致扰动变得不可伪装，并且可能引发数值运行时错误（如无效的张量值（NaN/Inf））。", "innovation": "本研究首次提出了一种称为SBFA（Sneaky Bit-Flip Attack）的新颖攻击方法。SBFA能够在不破坏权重分布的情况下，仅通过单次位翻转使LLM性能崩溃。这通过迭代搜索和排列以及我们定义的参数敏感度度量，即ImpactScore（结合了梯度敏感性和在良性层权重分布约束下的扰动范围）来实现。此外，提出了一个轻量级的SKIP搜索算法，显著降低了搜索复杂度，使得对于最新的LLM模型，成功的SBFA搜索只需要几十分钟。", "conclusion": "在Qwen、LLaMA和Gemma模型上，通过单次位翻转，SBFA能够成功地使准确性降到随机水平以下，无论是BF16还是INT8数据格式中均有效。一个包含数十亿个参数的单一位翻转展示了当前一代顶尖LLM模型的安全缺陷严重性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21884", "html_url": "https://arxiv.org/abs/2509.21884", "title": "你不能窃取不存在的东西：通过系统向量缓解大语言模型中的指令窃漏", "title_en": "You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors", "authors": "Bochuan Cao,Changjiang Li,Yuanpu Cao,Yameng Ge,Ting Wang,Jinghui Chen", "background": "大型语言模型（LLMs）已被广泛应用于各种场景，并利用定制的系统提示符应对不同的任务。然而，系统提示符泄露的风险仍然存在，并且模型开发人员主要通过禁用LLMs在遇到已知攻击模式时重复其上下文来防范这种风险。但是，这种策略依然面临新的未预见的提示窃漏技术的威胁。本文首先介绍了一种简单而有效的方法，用于揭示这种风险，并提出了名为SysVec的新方法，该方法将系统提示符编码为内部表示向量以降低未经授权的泄露风险，同时保留LLM的核心语言能力。定量实验结果证明了SysVec的有效性，不仅减轻了提示泄漏攻击的影响，还保障了LLM的功能完整性和长期上下文场景下的记忆稳定性。", "innovation": "文章提出了一种名为SysVec的技术，将系统提示符编码为内部向量表示，而不是使用原始文本，从而减少了未经授权的泄露风险，同时保持了LLM的核心语言能力。这种方法不仅提高了安全性，还改善了模型的通用指令遵循能力。", "conclusion": "通过实验结果，本文证明了SysVec有效缓解了提示泄漏攻击，保持了LLM的功能完整性，并有助于缓解长期上下文场景中的遗忘问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22097", "html_url": "https://arxiv.org/abs/2509.22097", "title": "SecureAgentBench：在现实漏洞场景下评估安全代码生成的标准", "title_en": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios", "authors": "Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo", "background": "大规模语言模型（LLM）驱动的代码代理正在快速改变软件工程，通过自动化测试、调试和修复等任务。然而，它们生成的代码的安全风险成为了一个严重的问题。现有的基准测试提供了一些有价值的见解，但仍然不够充分：它们经常忽略了漏洞真正引入的上下文，或是采用过于狭隘的评估协议，无法全面测试功能正确性和新引入的漏洞。", "innovation": "本文介绍了一个名为SecureAgentBench的基准，它包括105个编码任务，旨在严格评估代码代理在生成安全代码方面的能力。每个任务包括：（i）在大型代码库中进行多文件编辑的现实任务设置；（ii）基于真实世界开源漏洞的具体情境，精确标识了漏洞引入点；（iii）结合功能测试、通过概念证明攻击检查漏洞、以及使用静态分析检测新引入漏洞的全面评估。本文还评估了三个代表性的代理（SWE-agent、OpenHands、Aider）、三种最先进LLM（Claude 3.7 Sonnet、GPT-4.1、DeepSeek-V3.1），结果表明当前代理难以生成安全代码，功能正确的代码中仍然存在漏洞，甚至增加安全指令也没有显著提高安全编码效果。", "conclusion": "这些发现建立了SecureAgentBench作为安全代码生成的严苛基准，并为基于LLM的更可靠软件开发提供了一步进展。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22325", "html_url": "https://arxiv.org/abs/2509.22325", "title": "合成查询重写能否比人类更好地捕捉检索增强生成中的用户意图？", "title_en": "Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?", "authors": "JiaYing Zheng,HaiNan Zhang,Liang Pang,YongXin Tong,ZhiMing Zheng", "background": "多轮RAG系统在处理具有口语省略和模糊引用的查询时面临着显著挑战，这对有效的检索和生成提出了考验。传统上，查询重写依赖人工注释器澄清查询，但由于注释器表达能力和理解深度的限制，手动重写的查询往往与实际RAG系统所需的查询存在偏差，造成了用户意图和系统响应之间的差距。本文作者观察到，高质量的合成查询能够更好地弥合这一差距，同时在检索和生成任务中展现出优于人工重写的性能。", "innovation": "本文提出了SynRewrite，一种基于合成数据的查询重写模型，旨在生成与用户意图更一致的高质量合成重写。通过使用GPT-4o生成高质量的重写数据，然后对Flan-T5模型进行微调以映射对话历史和查询到合成重写，以及通过DPO算法增强重写器来提升最终任务性能。实验结果显示，在TopiOCQA和QRECC数据集上的结果表明，SynRewrite在检索和生成任务中始终优于人工重写。", "conclusion": "研究结果表明，合成重写可以作为一种可扩展且有效的替代人类注释的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21982", "html_url": "https://arxiv.org/abs/2509.21982", "title": "RISK：电子商务风险管理中的GUI代理框架", "title_en": "RISK: A Framework for GUI Agents in E-commerce Risk Management", "authors": "Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen", "background": "传统的爬取方法和大多数现有的图形用户界面（GUI）代理无法处理电子商务风险管理和评估所需的复杂、嵌入式网络数据以及动态交互内容。这种局限性使得传统的GUI代理局限于单一步骤的任务，无法应对有效风险评估中所需的多步骤、动态交互任务。", "innovation": "本文介绍了RISK框架，这是一种专门设计用于解决上述挑战的新型框架。RISK集成了RISK-Data、RISK-Bench和RISK-R1三个组件：RISK-Data提供了大量的单步骤和多步骤交互轨迹数据集；RISK-Bench用于标准化评估，提供多个不同难度级别的交互轨迹；RISK-R1则是一种强化学习调优框架，考虑了输出格式、单步骤准确性、多步骤过程和任务难度四个层面的奖励机制，使得模型能更好地适应复杂交互任务，并获得优于现有基线的性能提升，特别是在线上评估中的成功率为70.5%。", "conclusion": "RISK提供了可扩展的、针对电子商务风险管理领域的特定解决方案，可以自动处理复杂的网页交互任务，并推动了电子商务风险管理领域的技术进步。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21891", "html_url": "https://arxiv.org/abs/2509.21891", "title": "AgentPack: 由人类和代理共同编辑的代码更改数据集", "title_en": "AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans", "authors": "Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha", "background": "以往调整大型语言模型以进行代码编辑主要依赖于挖掘提交和合并请求。人们假设提交消息描述了人类的自然语言意图，而代码补丁描述了实现这些意图的更改。然而，已收集的数据中存在大量噪音，提交消息简短模糊，人类编写的提交往往包含多个无关的编辑，许多提交来自于简单的基于规则的机器人。近年来，软件工程代理的采用改变了这一现状。人类和代理共同编辑的代码更改更专注于明确的目标，且提交消息由LLM生成，能够详细描述意图和理由。当这些更改提交到公共存储库时，会被人类维护者过滤掉低质量的提交。", "innovation": "AgentPack是一个包含130万行代码更改的语料库，这些代码更改由Claude Code、OpenAI Codex和Cursor Agent与人类共同编辑。研究描述了识别和整理该数据集的流程，量化了这些代理的采用趋势，并分析了这些更改的结构属性。此外，研究发现，使用AgentPack进行微调的模型比基于人类仅有的提交语料库训练的模型表现出更好的性能，突显了利用软件工程代理的公共数据来训练未来代码编辑模型的潜力。", "conclusion": "研究表明，使用AgentPack进行微调的模型能够比之前只基于人类提交语料库训练的模型表现得更好，这展示了运用软件工程代理的公共数据来训练未来的代码编辑模型的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22445", "html_url": "https://arxiv.org/abs/2509.22445", "title": "连接柯尔莫哥洛夫复杂度与深度学习：Transformer 的渐近最优描述长度目标", "title_en": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers", "authors": "Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova", "background": "最小描述长度（MDL）原则为在机器学习中应用奥卡姆剃刀提供了一个正式框架，但在应用于诸如Transformer等神经网络时遇到了挑战，因为缺乏一种普遍适用的模型复杂度度量标准。", "innovation": "论文提出了渐近最优描述长度目标的理论概念，这些目标基于柯尔莫哥洛夫复杂度理论。证明了这些目标在变压器中存在，基于新展示的计算全能性。构造并分析基于自适应高斯混合先验的可计算且可微的变分目标，进而证明了该目标在选择低复杂度解决方案方面的有效性。", "conclusion": "通过提供一个理论框架来识别具有强大渐近保证的描述长度目标，论文指出了通往训练能够实现更高压缩和泛化的神经网络的潜在路径。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22463", "html_url": "https://arxiv.org/abs/2509.22463", "title": "IIET: 通过隐式迭代欧拉方法实现高效的数值Transformer", "title_en": "IIET: Efficient Numerical Transformer via Implicit Iterative Euler Method", "authors": "Xinyu Liu,Bei Li,Jiahao Liu,Junhao Ruan,Kechen Jiao,Hongyin Tang,Jingang Wang,Xiao Tong,Jingbo Zhu", "background": "高阶数值方法可以增强Transformer在NLP和CV任务中的表现，但会因为增加的计算开销而引入性能与效率之间的权衡。传统的效率提升技术，如蒸馏，可能会对这些模型的性能产生负面影响，体现在PCformer中。为了探索更优化的基于ODE的Transformer架构，本文提出了一种迭代隐式Euler变换器（IIET），这是一种简化了高阶方法的模型，不仅提高了性能，还便于模型压缩，相比PCformer更加高效。", "innovation": "提出了一种新的迭代隐式Euler变换器（IIET），通过迭代隐式Euler方法简化高阶方法，不仅提高了模型性能，还实现了模型压缩。为提升推理效率，引入了迭代影响感知蒸馏（IIAD），通过一个灵活的阈值可以有效地平衡性能与效率的权衡。实验表明，相比于vanilla Transformer和PCformer，IIET在lm-evaluation-harness上平均准确度分别提高了2.65%和0.8%，其高效版本E-IIET在保持99.4%任务准确性的基础上，推理开销降低了55%。", "conclusion": "IIET不仅提高了Transformer的性能，而且在保留高效率的同时实现了更好的模型压缩。进一步的优化变种在保持速度接近vanilla Transformer的同时获得了平均性能提升1.6%以上的收益。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21991", "html_url": "https://arxiv.org/abs/2509.21991", "title": "ERGO: 高效高分辨率视觉理解的视觉语言模型", "title_en": "ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models", "authors": "Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim", "background": "高分辨率图像的高效处理对于现实世界的视语应用至关重要，但由于大型视觉语言模型（LVLMs）中视觉标记的数量庞大，导致了巨大的计算负担。随着图像思考模型的出现，推理不仅限于文本领域，也扩展到了视觉领域，这激发了我们提出一种两级的“粗细结合”推理管道：首先分析下采样的图像以识别与任务相关的重要区域；随后仅对这些区域进行全分辨率裁剪并在后续推理阶段进行处理。这种方法提高了效率的同时也保留了必要的细尺度视觉细节。然而，一个主要的挑战在于如何推断哪些区域对给定查询是真正相关的。现有方法常常在输入图像下采样后的第一阶段中失效，因感知驱动的推理需要清晰的视觉信息进行有效的推理。", "innovation": "我们提出了一种名为ERGO（Efficient Reasoning & Guided Observation）的方法，以推理驱动感知利用多模态上下文来确定重要区域。ERGO能够处理感知不确定性，通过扩大裁剪区域来覆盖视觉模糊的区域，以回答问题。为了达到这一目的，我们使用强化学习框架开发了简单而有效的奖励组件，实现了从粗到细的感知。实验结果显示，ERGO在多个数据集上的准确率高于原始模型和一些现有方法，并且更加高效。例如，ERGO在V*基准上超过了Qwen2.5-VL-7B 4.7个点，仅使用了23%的视觉标记数量，实现了3倍的推理速度提升。开发的代码和模型可以在以下链接找到：this https URL.", "conclusion": "我们的方法在多个数据集上取得了比原模型更高且更具竞争力的高分辨率视觉理解准确率及效率，验证了ERGO方法的有效性和优势。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22061", "html_url": "https://arxiv.org/abs/2509.22061", "title": "语出自然：语音延续任务作为语音基础模型偏见的探针", "title_en": "Speak Your Mind: The Speech Continuation Task as a Probe of Voice-Based Model Bias", "authors": "Shree Harsha Bokkahalli Satish,Harm Lameris,Olivier Perrotin,Gustav Eje Henter,Éva Székely", "background": "语音延续（SC）任务旨在生成与给定语音提示语主题连贯、保持说话者身份的同时的语音扩展。由于SC任务限制在单个音频流中，因此比对话更适合直接探究语音基础模型中的偏见。本研究首次系统地评估了语音延续任务中的偏见，特别关注性别和不同的声音品质（呼吸声、沙哑声、结尾沙哑声）对延续行为的影响。本研究评估了三个最新的模型：SpiritLM（基础版和表达版）、VAE-GSLM和SpeechGPT，考察了说话者相似度、声音品质保持以及基于文本的偏见指标。结果显示，在说话者相似度和连贯性上依然存在挑战，但文本评估揭示了模型和性别之间的显著相互作用：仅当连贯性足够高（对于VAE-GSLM）时，性别效果才在代理和句子极性等文本指标上表现出来。此外，对于女性提示比男性提示而言，连续性更倾向于恢复为模态语音，揭示了一种系统的声音品质偏见。这些发现强调，语音延续任务可以作为一种控制的探针来探测语音基础模型中的社会相关代表性偏见，并建议随着延续质量的提高，它将成为一个越来越有信息量的诊断工具。", "innovation": "本研究首次系统地评估了语音延续任务中的偏见，特别考察了性别和不同声音品质对延续行为的影响，并在三个最新的模型上进行了全面的评估，为未来研究提供了全新的视角。", "conclusion": "语音延续任务可以作为一种控制的探针用于探究社会相关代表性偏见，成为了评价语音基础模型中偏见的有效工具，随着延续质量的提高，它将越来越具有信息量。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "文章借鉴了拉斯克尔在其著作《思考，快与慢》中的双系统理论，探讨如何通过多智能体系统动态整合快思考（直观快速思维）和慢思考（深思熟虑的思路），来改善机器学习模型的推理能力。", "innovation": "提出了一种名为PRIME的多智能体推理框架，该框架通过集成快思考系统和慢思考系统，使用快速生成答案并进行初步判断的智能体，以及在不确定时触发结构化的慢思考推理管道，实现了对更复杂知识密集型推理的高效准确处理。", "conclusion": "实验结果表明，PRIME框架能够使开源LLM模型在多跳和基于知识的推理基准测试上与最先进的闭源模型（如GPT-4和GPT-4o）竞争，这为改善要求复杂知识推理领域中的LLM模型提供了一个可扩展的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22186", "html_url": "https://arxiv.org/abs/2509.22186", "title": "MinerU2.5：一种用于高效高分辨率文档解析的解耦视觉语言模型", "title_en": "MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing", "authors": "Junbo Niu,Zheng Liu,Zhuangcheng Gu,Bin Wang,Linke Ouyang,Zhiyuan Zhao,Tao Chu,Tianyao He,Fan Wu,Qintong Zhang,Zhenjiang Jin,Guang Liang,Rui Zhang,Wenzheng Zhang,Yuan Qu,Zhifei Ren,Yuefeng Sun,Yuanhong Zheng,Dongsheng Ma,Zirui Tang,Boyu Niu,Ziyang Miao,Hejun Dong,Siyi Qian,Junyuan Zhang,Jingzhou Chen,Fangdong Wang,Xiaomeng Zhao,Liqun Wei,Wei Li,Shasha Wang,Ruiliang Xu,Yuanyuan Cao,Lu Chen,Qianqian Wu,Huaiyu Gu,Lindong Lu,Keming Wang,Dechen Lin,Guanlin Shen,Xuanhe Zhou,Linfeng Zhang,Yuhang Zang,Xiaoyi Dong,Jiaqi Wang,Bo Zhang,Lei Bai,Pei Chu,Weijia Li,Jiang Wu,Lijun Wu,Zhenxiang Li,Guangyu Wang,Zhongying Tu,Chao Xu,Kai Chen,Yu Qiao,Bowen Zhou,Dahua Lin,Wentao Zhang,Conghui He", "background": "目前存在许多文档解析模型，但在保持高效计算的同时达到顶级识别准确性仍是一个挑战。现有的模型可能在处理高分辨率图像时面临计算开销问题，或者在精准识别文档内容上表现不佳。", "innovation": "提出了一个名为MinerU2.5的1.2亿参数文档解析视觉语言模型，采用了从粗到细、两阶段的解析策略，将全局布局分析与局部内容识别解耦。第一阶段通过低分辨率图像进行高效布局分析，识别结构元素；第二阶段根据全局布局信息，对高分辨率图像中的局部区域进行精细识别。为此，还开发了一个全面的数据引擎生成大规模的训练语料库，以支持该模型的训练。", "conclusion": "MinerU2.5在多个基准测试上展示了强大的文档解析能力，性能达到顶级，同时还具备显著降低计算开销的优势，超越了通用和领域特定的模型，在多种识别任务中表现突出。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22044", "html_url": "https://arxiv.org/abs/2509.22044", "title": "A2R: Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning", "title_en": "A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning", "authors": "Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen", "background": "近期的大规模推理模型通过在推理阶段分配更多的计算资源并采用“思考更长时间”的模式，显著提升了复杂任务解决能力。尽管模型的基础推理能力正在迅速提高，但在单次尝试中的表现与潜在能力之间仍存在显著差距，这种差距往往只有在多次解决方案路径中才能显现出来。这一差距突显了模型实现能力和潜在能力之间的差异。", "innovation": "本文提出了A2R（Asymmetric Two-Stage Reasoning）不对称双阶段推理框架，旨在明确地弥合模型的潜在能力和实际表现之间的差距。A2R框架中，探索者模型首先通过重复采样并行生成潜在解决方案，合成模型随后整合这些参考进行更精细的第二阶段推理。这一双阶段过程使计算能够独立于现有的顺序方法进行扩展。首先，A2R作为一种插件式并行推理框架，能够在复杂问题上显式地增强模型能力，例如，使用该框架时，Qwen3-8B-distill模型的性能提高了75%。其次，通过系统分析探索者和合成器的作用，本文找到了有效的不对称扩展模式。这导致了A2R-Efficient，一种“从小到大”的变体，结合了一个Qwen3-4B的探索者和一个Qwen3-8B的合成器。这种配置优于平均而言的单体Qwen3-32B模型，成本几乎降低了30%。", "conclusion": "A2R不仅是性能提升框架，而且是适用于实际应用的有效和实用的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22261", "html_url": "https://arxiv.org/abs/2509.22261", "title": "InfiMed-Foundation: 引领高级多模态医疗模型的计算高效预训练与多阶段微调", "title_en": "InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning", "authors": "Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大规模语言模型（MLLMs）在多个领域显示出极大的潜力，但在医疗领域却受到多个挑战的阻碍。通用型MLLMs缺乏特定的医学知识，导致不确定或虚构的响应。在放射学和药学等领域的专业知识提取方面，高级模型的知识蒸馏也难以捕捉到。此外，持续预训练大规模医学数据的计算成本带来了效率方面的挑战。", "innovation": "提出了InfiMed-Foundation-1.7B和InfiMed-Foundation-4B两种特化的多模态语言模型，设计用于在医疗应用中实现顶级性能。通过结合高质量的通用型和医疗多模态数据，并提出了一种新颖的五个维度的质量评估框架来整理高质量的多模态医学数据集。使用低到高的图像分辨率和多模态序列打包来提高训练效率，从而能够整合大量的医学数据。并且，进行了一个三阶段的监督微调过程，确保从复杂的医疗任务中有效地提取知识。通过评估表明，InfiMed-Foundation-1.7B在医学视觉问答和诊断任务中优于Qwen2.5VL-3B，InfiMed-Foundation-4B优于HuatuoGPT-V-7B和MedGemma-27B-IT。", "conclusion": "通过解决数据质量、训练效率和特定领域知识提取方面的关键挑战，我们的工作为更可靠和有效的AI驱动的医疗解决方案铺平了道路。InfiMed-Foundation-4B模型可以在https://www.example.com/InfiMed-Foundation-4B处获得。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22576", "html_url": "https://arxiv.org/abs/2509.22576", "title": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning", "title_en": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning", "authors": "Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris", "background": "在具有稀疏奖励的多轮交互环境中训练大规模语言模型（LLM）代理，完成一个任务可能需要30多次交互，这对强化学习构成了根本性的挑战。此前的研究发现，在这种环境中，代理面临探索与利用的级联失败，这种失败始于政策的早期阶段过早收敛，由于稀疏反馈，代理会固守低熵策略。随后政策萎缩，从而使传统的熵正则化变得无效，导致不稳定训练。", "innovation": "本文提出了熵正则化的策略优化（EPO），这是一种通过三种协同机制打破失败循环的通用框架：（1）在多轮交互设置中采用熵正则化以增强探索；（2）一个熵平滑正则化，可以限制策略熵在历史平均值内，以防止剧烈波动；（3）自适应阶段加权，平衡训练过程中的探索和利用。分析表明，EPO 可以确保熵方差单向减少的同时保持收敛，实验结果证实EPO在ScienceWorld和ALFWorld上的效果显著提升。", "conclusion": "本文的研究表明，多轮稀疏奖励环境需要与传统强化学习不同的熵控制，这对LLM代理训练有广泛的影响。EPO 的提出不仅克服了探索与利用级联失败的问题，还显著提高了代理在多轮交互任务中的表现，为未来的研究提供了重要的理论和实践依据。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22633", "html_url": "https://arxiv.org/abs/2509.22633", "title": "在线强化学习中的人工反馈高效探索方法", "title_en": "Towards Efficient Online Exploration for Reinforcement Learning with Human Feedback", "authors": "Gen Li,Yuling Yan", "background": "强化学习与人工反馈（RLHF）通过从人类偏好数据中学习奖励模型，然后优化策略以偏好特定响应，已经成为使大型语言模型（LLMs）与人类偏好相一致的核心范式。然而，在线RLHF中探索原则尚不明确，这亟需一种能够高效收集新偏好数据并在此基础上完善奖励模型和策略的方法。", "innovation": "本文通过研究现有的乐观探索算法的抽样协议发现了一个缺点：它们倾向于收集未能减少奖励差异信息量的比较数据。文章提出了一个新方案，该方案将偏好查询导向减少最相关的奖励差异不确定性，以此改进政策。在RLHF的多臂老虎机模型下，文章建立了复杂度为$T^{(\beta+1)/(\beta+2)}$的后悔界，其中$\beta>0$是一个平衡奖励最大化与缓解分布偏移的超参数。这是首个在线RLHF算法，其后悔界与所有模型参数呈多项式关系。", "conclusion": "本文提出了一种在线RLHF的新探索方案，证明了这种算法在理论上的高效性，并且是首个具有此类后悔界特征的算法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22461", "html_url": "https://arxiv.org/abs/2509.22461", "title": "MDAR：一个多场景动态音频推理基准", "title_en": "MDAR: A Multi-scene Dynamic Audio Reasoning Benchmark", "authors": "Hui Li,Changhao Jiang,Hongyu Wang,Ming Zhang,Jiajun Sun,Zhixiong Yang,Yifei Cao,Shihan Dou,Xiaoran Fan,Baoyu Fan,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "当前的音频推理能力对于AI代理在现实世界场景中的有效交互是至关重要的。现有的基准主要集中在静态或单一场景设置上，未能充分捕捉到多说话人、事件演化和异构音频源交互的情景。因此，需要一个能够评估模型在复杂、多场景和动态演化的音频推理任务上的基准。", "innovation": "本文引入了MDAR（Multi-scene Dynamic Audio Reasoning Benchmark），一个用于评估模型在复杂、多场景和动态演化的音频推理任务上的基准。MDAR包含3000多个精心挑选的问题-答案配对，链接到多样的音频片段，涵盖了五类复杂的推理类别，并覆盖三种问题类型。MDAR能够全面评估现有的音频语言模型在音频推理任务中的表现，并揭示它们在复杂推理任务中的局限性。", "conclusion": "现有的音频语言模型在MDAR上的表现显示出明显的局限性，尤其是在多选题和开放式任务中。这项研究强调了MDAR的独特挑战和其作为推进音频推理的价值。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22545", "html_url": "https://arxiv.org/abs/2509.22545", "title": "人工智能辅导能否为职场谈判做好准备?", "title_en": "Does AI Coaching Prepare us for Workplace Negotiations?", "authors": "Veda Duddu,Jash Rajesh Parekh,Andy Mao,Hanyi Min,Ziang Xiao,Vedant Das Swain,Koustuv Saha", "background": "职场谈判常受到心理障碍的干扰，即使是最准备充分的策略也会被削弱。AI提供了个性化且随时可用的谈判辅导，但其在谈判准备中的有效性仍不清楚。本研究旨在通过比较AI教练Trucey、ChatGPT及传统谈判手册的效果，探索AI在提高谈判准备的潜力。", "innovation": "研究人员开发了基于布莱特谈判模型的AI教练原型Trucey，并通过被试数量为267的对照实验和后续的深度访谈进行研究。实验结果显示，AI教练虽然降低了对谈判的恐惧，但在可用性和心理赋能方面，传统谈判手册更胜一筹。这一发现挑战了对AI辅导在谈判准备中优势的假设。", "conclusion": "传统谈判手册对于提升谈判准备的可用性和心理赋能效果更佳，而AI在缓解谈判恐惧方面表现更佳。参与者认为AI的模拟练习有其价值，但其指导方式过于繁杂且缺乏连贯性，使其在实践中反而会让人感到不确定或困惑。未来可能需要结合结构化理论内容、针对性练习、清晰边界和适应性支架来设计综合方案，以应对心理障碍并支持谈判准备。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22202", "html_url": "https://arxiv.org/abs/2509.22202", "title": "LLMs中基于开发人员查询的风险分析：库幻觉", "title_en": "Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries", "authors": "Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis", "background": "大型语言模型（LLMs）被广泛用于生成代码，但它们经常会出现幻觉，即编造不存在的库。这种库幻觉不仅会误导开发者，还会导致构建中断，甚至使系统暴露在供应链威胁中，如措辞蹲坑。尽管人们对这些风险的认识有所增加，但很少有人了解实际使用的提示变化如何影响幻觉的发生率。因此，本文首次系统地研究了用户级别提示变化如何影响LLM生成代码中的库幻觉。研究评价了六种不同的LLM，涉及两种类型的幻觉：库名称幻觉（无效导入）和库成员幻觉（来自有效库的无效调用）。研究调查了从开发者论坛中提取的具象用户语言和不同程度的用户错误（包括单个或多个字符的拼写错误以及完全虚假的名称/成员）如何影响LLM幻觉的发生率。研究结果揭示了系统的脆弱性：单个字符的库名称拼写错误会触发高达26%的任务中的幻觉，完全虚假的库名称在高达99%的任务中被接受，而与时间相关的提示会在高达84%的任务中导致幻觉。提示工程有望减轻幻觉，但方法不一致且依赖于不同的LLM。研究结果突显了LLMs对自然提示变化的脆弱性，并强调了防止与库相关的幻觉及其潜在利用的紧迫需求。", "innovation": "首次系统地研究了用户级别提示变化如何影响LLM生成代码中的库幻觉；评估了六种不同的LLM，并涉及两种类型的幻觉；研究调查了从开发者论坛中提取的具象用户语言和不同程度的用户错误对LLM幻觉的影响；揭示了关键的系统性弱点，如拼写错误、虚假库名称以及与时间相关的提示都会导致幻觉的产生；提示工程有减轻幻觉的潜力，但仍然不一致且依赖于不同的LLM；强调了开发界对于防止与库相关的幻觉及其潜在利用的紧迫需求。", "conclusion": "LLMs在面对自然提示变化时表现出脆弱性，提醒开发者社区必须采取措施来防范库幻觉及其潜在危害；验证了提示工程有缓解LLM幻觉的潜力；提醒研究人员和开发者关注LLM安全，强调亟需建立有效的防线来应对与库相关的幻觉问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22647", "html_url": "https://arxiv.org/abs/2509.22647", "title": "CapRL: 刺激密集图像标题生成能力的强化学习", "title_en": "CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning", "authors": "Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin", "background": "图像描述是视觉领域和语言领域的桥梁任务，对大型视觉-语言模型（LVLMs）的预训练起到关键作用。现有的先进描述模型通常使用监督微调（SFT）训练，该方法依赖于昂贵且不可扩展的人工或专有模型标注数据。这种方法会导致模型记忆特定的答案，限制了其泛化能力和生成多样、创造性描述的能力。", "innovation": "该研究提出了将可验证奖励的强化学习（RLVR）应用于开放的图像描述任务，以克服监督微调的限制。研究人员引入了名为CapRL的新颖训练框架，通过其实用性重新定义了描述质量：高质量的描述应该能使非视觉语言模型准确回答与之对应的图像的问题。CapRL采用脱钩的两阶段管道，其中LVLM生成描述，目标奖励来自单独的、无视觉的LLM仅基于该描述回答多项选择题的准确性。", "conclusion": "研究首次将RLVR应用于主观的图像描述任务，结果表明，使用CapRL预训练可显著提高12个基准测试的表现，特别是在Prism框架下的表现与Qwen2.5-VL-72B相当，比基线高出平均8.4%。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22646", "html_url": "https://arxiv.org/abs/2509.22646", "title": "通过多模态LLMs学习AI生成视频中的感知虚假内容", "title_en": "Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs", "authors": "Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch", "background": "随着视频生成模型的快速发展，人类是否能够检测到AI生成视频中的欺骗性痕迹，即能够揭示视频为机器生成的空间-时间视觉特征，这一关键维度被广泛忽视。本文引入了DeeptraceReward，这是一个细粒度的空间-时间感知基准，用于标注人类感知到的假视频痕迹，以评估视频生成奖励。该数据集包含3300个高质量生成视频的4300个详细注解，每个注解提供自然语言解释、标注包含假痕迹的边界框区域和精确的时间戳。", "innovation": "DeeptraceReward是第一个专门用于评估视频生成模型的人性化感知基准，能够细粒度地捕捉和评估人类感知到的假视频痕迹。该创新通过训练多模态语言模型作为奖励模型，模拟人类的判断和定位，显著提高了在生成视频识别假线索、定位和解释方面的表现。", "conclusion": "通过引入DeeptraceReward，本文为社交意识和值得信赖的视频生成提供了一个严格的测试平台和训练信号，同时揭示了不同层次的假视频痕迹检测任务复杂性的差异，从二元的假与真实分类到细粒度的假视频痕迹检测，复杂性逐渐增加。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22621", "html_url": "https://arxiv.org/abs/2509.22621", "title": "IA2: 使用ICL激活进行对齐改进监督微调", "title_en": "IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning", "authors": "Aayush Mishra,Daniel Khashabi,Anqi Liu", "background": "监督微调（SFT）通过训练权重以对查询产生预期的目标响应来专门化模型行为。相比之下，即席学习（ICL）在推理过程中通过提示中的指令或演示来适应模型。在数据稀缺的情况下，ICL能提供更好的泛化能力和更校准的响应，但代价是需要更多的推理计算。本文探讨了是否可以利用ICL的内部计算来改进SFT的质量。", "innovation": "本文引入了一种名为ICL激活对齐（IA2）的技术，这是一种自我蒸馏方法，旨在在SFT模型中复制ICL的激活模式，并激励类似ICL的内部推理。通过在SFT之前作为预处理步骤执行IA2，实验结果表明可以显著提高模型输出的准确性和校准性。", "conclusion": "研究发现，IA2不仅在实践中 useful 而且还能为模型适应的内部机制提供概念性窗口。这一研究结果表明，ICL的内部分析过程可以用来改善监督微调的质量，并且展示了在12个流行基准和2个模型家族上的广泛实证结果。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2310.19462", "html_url": "https://arxiv.org/abs/2310.19462", "title": "利用大型语言模型进行句法分析", "title_en": "Constituency Parsing using LLMs", "authors": "Xuefeng Bai,Jialong Wu,Yulong Chen,Zhongqing Wang,Kehai Chen,Min Zhang,Yue Zhang", "background": "句法分析是自然语言处理中的一项基础但尚未完全解决的挑战。先前的工作尚无法有效解决句法分析问题，尤其是在保持生成的句法树有效性和忠实性方面存在局限。", "innovation": "本文研究了如何利用最近的大规模语言模型（LLMs）解决句法分析挑战。通过将其重新构想为序列到序列的生成问题，并在零样本、少量样本和监督微调的不同学习范式下评估了多种LLMs的表现。尽管LLMs在性能上有所提升，但它们仍然存在机制不完善的问题，无法保证生成的句法树的有效性和忠实性。为此，提出了一种基于错误样本学习和多智能体协作改进输出的策略。", "conclusion": "实验结果表明，所提出的方法有效地减少了无效和不忠实的句法树的产生，从而整体提升了句法分析性能，并在不同学习范式下取得了令人满意的结果。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22505", "html_url": "https://arxiv.org/abs/2509.22505", "title": "AI伴侣对心理健康的影响：社会媒体准实验、用户视角及关系理论的综合研究", "title_en": "Mental Health Impacts of AI Companions: Triangulating Social Media Quasi-Experiments, User Perspectives, and Relational Theory", "authors": "Yunhao Yuan,Jiaxun Zhang,Talayeh Aledavood,Renwen Zhang,Koustuv Saha", "background": "随着AI驱动的陪伴聊天机器人（AICCs）如Replika的日益流行，用户可以通过这些机器人获得共鸣式的交流，但它们的心理社会影响尚不明确。本文通过大规模的准实验研究和量化方法，揭示了AICCs对用户福祉的影响，并分析了用户对这些体验的看法，进一步结合质性研究，为设计健康的AI伴侣提供了建议。", "innovation": "本文通过综合社会媒体准实验数据、用户访谈和关系理论分析，探究了AICCs对用户心理健康的影响。这种方法论的独特之处在于将定量研究与质性研究相结合，提供了更全面的理解。此外，根据研究结果提出了AI伴侣设计的实用性建议，旨在最大化心理社会益处并最小化风险。", "conclusion": "该研究发现，AICCs在提供情感验证和社会实践方面表现出积极效果，但同时也存在过度依赖和社交回避的风险。基于这些发现，本文提出了设计建议，为AI伴侣的设计者提供了指导，旨在促进健康的情感交流，支持有意识的参与，避免过度依赖，帮助用户处理人际关系的不同阶段，从而最大化AI伴侣的潜在心理社会益处。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22572", "html_url": "https://arxiv.org/abs/2509.22572", "title": "动态专家搜索：混合专家LLMs推理增强", "title_en": "Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time", "authors": "Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang", "background": "Test-Time Scaling (TTS) 能通过在推理阶段分配额外的计算资源来提升大语言模型（LLMs）的推理能力。现有方法主要通过输出采样的方式实现这一目标，但忽略了模型架构的作用。主流的Mixture-of-Experts (MoE) LLMs中，专家的数量变化会带来收敛性能稳定但多样化的解集。因此，本文研究如何通过动态调整专家激活数量以在推理阶段增强LLMs的推理能力，而不增加额外的成本。这项研究在多种MoE架构和验证器及推理基准下进行了广泛实验，发现所提出的DES策略在提升准确性和稳定性方面超过了TTS基准。", "innovation": "动态专家搜索（DES）策略引入了动态Mixture-of-Experts（Dynamic MoE），这种策略在推理阶段直接控制专家数量以生成多样化的推理路径，同时保持推理路径内的一致性，以便于在不同运行中调整专家数量，从而平衡稳定性和多样性。DES结合了两个关键组件：动态MoE（在推理期间直接控制专家的数量生成多样化的推理轨迹，而不增加成本）和专家配置继承（在同一推理路径内部保持专家数量的一致性，而在不同运行中调整数量，以在整个搜索过程中平衡稳定和多样性）。实验结果表明，DES策略能够可靠地超越TTS基准，提高准确性和稳定性，且不增加额外的成本。", "conclusion": "研究表明DES是一种实用且具有扩展性的基于架构的TTS方法，证明了现代LLM结构灵活性可以促进推理能力的提升。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.09265", "html_url": "https://arxiv.org/abs/2406.09265", "title": "跨语言和任务分析LLMs中神经元的共享性", "title_en": "Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs", "authors": "Weixuan Wang,Barry Haddow,Minghao Wu,Wei Peng,Alexandra Birch", "background": "大规模语言模型（LLMs）已经彻底改变了自然语言处理（NLP）领域，最近的研究试图理解它们的工作原理。尽管大多数研究集中在单一语言背景下进行，但鲜有研究探索多语言设置下LLMs的内部工作机制。", "innovation": "本文填补了这一研究空白，通过分类神经元并对三个任务在九种语言上的实验中提出新的见解。具体而言，本文提出了一种新方法，将神经元分为四类：全部共享、部分共享、特定以及不活跃。通过对LLMs进行多任务多语言实验，揭示了神经元激活模式在任务、模型和语言中的敏感性和变化性。", "conclusion": "研究发现：（i）关闭全部共享神经元会显著降低性能；（ii）共享神经元在生成响应方面起到至关重要作用，尤其是在全部共享神经元的情况下；（iii）神经元的激活模式高度敏感且在任务、模型和语言之间变化。研究结果为理解多语言LLMs的内部工作机制提供了新见解，并为未来的研究铺平了道路。相关代码已公开，以促进该领域的研究进步。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22601", "html_url": "https://arxiv.org/abs/2509.22601", "title": "逐步掌握技能，然后信任胜利：渐进式探索的自我模仿强化学习", "title_en": "Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning", "authors": "Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun", "background": "强化学习（RL）是提升大规模语言模型（LLMs）在长期且稀疏奖励任务中策略工具使用能力的主要范式，但面临探索与利用的基本权衡挑战。现有研究通过策略熵来刺激探索，但这种机械性的熵最大化容易导致RL训练不稳定，特别是由于多轮分布的变化。本文在自身经验的指导下，提出一种策略演化的渐进平衡方法，避免熵坍缩或失控发散，从而稳定训练过程。", "innovation": "提出了一种基于 Curriculum 的自我模仿学习（SIL）方法——SPEAR，通过逐步引导策略在一系列平衡的熵范围内演变。方法引入了课程管理机制，运用内在奖励促进技能级探索，同时通过自我模仿促进行动级探索。在辅助工具调用奖励的帮助下，初期策略能够掌握广泛技能和不熟悉的环境反馈。随着训练进行，强化自我模仿，加速解决方案迭代同时控制熵的增长。通过重新校准回放缓冲区中的经验优势和引入 token 剪辑等正则化手段，控制轨迹级熵来防止过度自信，进一步稳定训练过程。", "conclusion": "SPEAR 方法通过渐进式的探索和利用策略演变，结合自我模仿学习框架，成功应对了探索与利用的挑战，确保了大规模语言模型在任务中的良好表现，同时保持训练的稳定性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22653", "html_url": "https://arxiv.org/abs/2509.22653", "title": "See, Point, Fly: 一种无需学习的基于视觉-语言模型的通用无人驾驶飞行框架", "title_en": "See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation", "authors": "Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu", "background": "目前，基于视觉-语言模型的飞行导航系统依赖于大量的训练数据以进行有效的导航任务。现有方法侧重于将动作预测视为文本生成任务，这在处理复杂和多变环境时存在局限性。本文旨在提出一个无需训练的飞行导航框架SPF，通过将语言指令的2D空间定位任务进行分解，实现对环境中任意目标的导航。", "innovation": "本研究的关键创新在于将飞行导航中的动作预测视为一个2D空间定位问题，并利用视觉-语言模型将模糊的语言指令逐步分解为2D航点的标注。同时，SPF能够自适应调整行进距离，使无人机能够在动态环境中更有效地跟随动态目标。SPF在DRL模拟基准测试中取得了新的最佳性能，相较于之前的最佳方法，绝对提升了63%；在实际环境中的测试中也大幅超越了强大的基线方法。", "conclusion": "SPF展示了良好的泛化能力，能够在不同的视觉-语言模型中实现高效的飞行导航。该框架能够实现对任意环境、任意类型的自由形式指令的目标导航，尤其是在动态环境中追踪动态目标具有显著优势。此外，团队还进行了详尽的消融实验以证明设计的有效性，并且发布了该项目的网站。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22615", "html_url": "https://arxiv.org/abs/2509.22615", "title": "使用二维高斯点阵从压缩图像表示进行视图语言对齐", "title_en": "Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting", "authors": "Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe", "background": "现代视图语言管道由在大规模图像文本语料库上训练的RGB视觉编码器驱动。这些管道具备出色的零样本能力和强大的跨任务迁移，但它们仍然继承了从像素域继承的两种结构效率问题：一是将密集的RGB图像从边缘设备传输到云端需要大量能耗和费用；二是基于补丁的分词会增加序列长度，导致注意力预算和上下文限制的压力。因此，需要一种新的视觉表示方法来解决上述问题，以提高效率并支持边缘云学习。", "innovation": "本文探讨了二维高斯点阵（2D Gaussian Splatting，2DGS）作为新的视觉基础的方法。一种紧凑的、空间自适应的表示，通过一系列彩色各向异性高斯函数来参数化图像。本文开发了一个可扩展的2DGS管道，包括结构化初始化、亮度感知剪枝和批处理CUDA内核，并实现了90多倍的拟合速度提升和大约97%的GPU利用率。此外，本文通过重新利用冻结的基于RGB的变换器主干，并使用轻量级的点阵感知输入茎和感知重采样器，将对比语言图像预训练（CLIP）适应2DGS。该方法仅训练7%的参数，且在大规模数据集上实现了有意义的零样本ImageNet-1K性能，相对于像素压缩输入3到20倍。", "conclusion": "尽管当前准确性落后于基于像素的编码器，但本文的结果确立了2DGS作为多模态基础的可行性，并揭示了架构瓶颈，为同时具备语义强大性和传输效率的认知表示开发开辟了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.16495", "html_url": "https://arxiv.org/abs/2411.16495", "title": "AtomR: 通过原子操作增强的大语言模型在异质知识推理中的应用", "title_en": "AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning", "authors": "Amy Xin,Jinxin Liu,Zijun Yao,Zhicheng Lee,Shulin Cao,Lei Hou,Juanzi Li", "background": "尽管大型语言模型（LLMs）具有出色的能力，但在组合推理和妄想问题的限制下，知识密集型推理仍然是一个具有挑战性的任务。一种普遍的方法是采用链式思考（CoT）结合检索增强生成（RAG），首先将复杂问题分解为更简单的子问题，然后在每个子问题上进行迭代的RAG。然而，现有的工作存在两个主要问题：推理规划不充分和异质知识的整合不足。", "innovation": "本文提出了一种名为AtomR的新框架，用于LLMs在原子级别进行准确的异质知识推理。AtomR借鉴了知识图谱查询语言通过组合预定义操作来建模组合推理的方式，引入了三种原子知识操作符，为LLMs提供了一个统一的操作符集，用于从异质来源检索和操作知识。实验结果表明，AtomR在两个多源数据集上分别比最先进的基线模型提高了9.4%和9.5%的F1分数。", "conclusion": "AtomR通过提供精细和正交的问题分解以及灵活的知识检索和操作，使LLMs在异质知识推理方面表现出色。版权所有者还推出了一个专门针对异质知识推理的挑战性基准BlendQA。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22631", "html_url": "https://arxiv.org/abs/2509.22631", "title": "LABELING COPILOT: 一种计算机视觉自动数据整理的深度研究代理", "title_en": "LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision", "authors": "Debargha Ganguly,Sumit Kumar,Ishwar Balappanawar,Weicong Chen,Shashank Kambhatla,Srinivasan Iyengar,Shivkumar Kalyanaraman,Ponnurangam Kumaraguru,Vipin Chaudhary", "background": "构建高质、领域特定的数据集是部署稳健的视觉系统的关键障碍，需要在数据质量、多样性和成本之间进行复杂权衡，特别是处理庞大的未标记数据湖泊时。Labeling Copilot 是首个计算机视觉领域的数据整理深度研究代理。", "innovation": "提出了一种中央协调器代理，由大型多模态语言模型驱动，通过多步骤推理执行专业化工具，涵盖三大核心能力：（1）校准发现，从大型仓库中提取相关、范围内的数据；（2）可控合成，生成新型数据并进行稳健过滤；（3）共识注释，通过新颖的共识机制协调多个基础模型生成准确标签，包括非极大值抑制和投票。", "conclusion": "大规模验证证明了 Labeling Copilot 组件的有效性。共识注释模块在密集的 COCO 数据集上平均每个图像产生 14.2 个候选提案，几乎是 7.4 个真实对象的两倍，最终注释 mAP 达到 37.1%。在规模巨大的 Open Images 数据集上，成功导航极端类不平衡，发现 903 个新的边界框类别，扩展其能力到超过 1500 个总类别。同时，校准发现工具在 1000 万个样本规模下测试时，表现出高达 40 倍的计算效率，具有等效样本效率的替代方案。因此，具有优化和可扩展工具的自动化流程为整理工业规模数据集提供了坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.14364", "html_url": "https://arxiv.org/abs/2409.14364", "title": "位置ID很重要：一种改进的高效上下文压缩位置布局", "title_en": "Position IDs Matter: An Enhanced Position Layout for Efficient Context Compression in Large Language Models", "authors": "Runsong Zhao,Xin Liu,Xinyu Liu,Pengcheng Huang,Chunyang Xiao,Tong Xiao,Jingbo Zhu", "background": "当前，使用特殊的上下文令牌（如摘要、记忆或压缩令牌）来压缩大规模语言模型（LLMs）上下文信息是一种常见做法。然而，现有的方法往往忽视了位置编码本身会影响模型的局部归纳偏置，导致压缩过程忽略整体的依赖关系。", "innovation": "提出了一种简单而有效的方法——增强位置布局（EPL），仅通过调整位置ID来改进LLMs的上下文压缩能力，位置ID是用于标识令牌位置的数值标识符。EPL通过最小化上下文令牌及其对应的特殊令牌之间的距离，同时保持位置ID在上下文令牌、特殊令牌及其后续令牌之间的顺序关系，增强了上下文压缩能力。", "conclusion": "将EPL整合到我们表现最好的上下文压缩模型中，在跨域问题回答数据集上平均获得了1.9的ROUGE-1 F1改进。当扩展到多模态场景时，EPL为视觉压缩LLMs带来了平均2.6点的准确率提升。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.17388", "html_url": "https://arxiv.org/abs/2411.17388", "title": "LLMs作为知识图谱构建的Graph Judge是否可行？", "title_en": "Can LLMs be Good Graph Judge for Knowledge Graph Construction?", "authors": "Haoyu Huang,Chong Chen,Zeang Sheng,Yang Li,Wentao Zhang", "background": "在现实场景中，信息检索系统获取的大部分数据是无结构的。将自然语言句子转换为结构化的知识图谱（KGs）仍然是一个关键挑战。目前的知识图谱构建方法存在三个主要问题：（1）真实文档中可能存在大量噪声，导致提取混乱的信息。（2）简单的LLM通常无法准确从专业领域的文档中提取知识。（3）直接使用LLM构建知识图谱时，幻觉现象不容忽视。", "innovation": "本文提出了一种名为GraphJudge的知识图谱构建框架，针对上述挑战进行改进。该框架采用实体为中心的策略来消除文档中的噪音信息。并微调了一个LLM作为图裁判，从而提高生成的知识图谱的质量。实验结果表明，该方法在多种基准方法中表现出优越性能，并具备较强的泛化能力。", "conclusion": "实验在两个通用和一个领域特定的文本-图对数据集上进行，展示出比各种基线方法先进的性能，具有强大的泛化能力。代码可以在以下链接获得：this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.11020", "html_url": "https://arxiv.org/abs/2410.11020", "title": "使用强化学习提高大型语言模型的语言理解能力", "title_en": "Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning", "authors": "Bokai Hu,Sai Ashish Somayajula,Xin Pan,Pengtao Xie", "background": "尽管参数少于14B的指令微调大语言模型（LLMs）在自然语言理解（NLU）任务上继续表现出色，往往在GLUE和SuperGLUE等基准测试上不如较小的模型如BERT-base。研究动机源于强化学习在推理任务（如DeepSeek）中的成功，提出使用Proximal Policy Optimization (PPO)来提高LLMs的NLU能力。", "innovation": "将NLU任务构架为强化学习环境，视标记生成为一系列动作，并优化与正确标签对齐的奖励信号。实验结果表明PPO框架在GLUE中的平均表现优于监督微调，且在零样本和少量样本提示上分别改进了38.7%和26.1%。特别是在情感和自然语言推理任务上，PPO模型在情感健康数据集上的提升为7.3%，在SIGA-nli上的提升为10.9%，均优于GPT-4o的平均表现。", "conclusion": "这项工作展示了通过将LLMs重新构架为强化学习问题，以简单的目标奖励替代大量数据管理方向的潜在前景，有望有效地适应全新的任务。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.04020", "html_url": "https://arxiv.org/abs/2407.04020", "title": "LLMAEL: 大型语言模型是实体链接的良好上下文增强器", "title_en": "LLMAEL: Large Language Models are Good Context Augmenters for Entity Linking", "authors": "Amy Xin,Yunjia Qi,Zijun Yao,Fangwei Zhu,Kaisheng Zeng,Xu Bin,Lei Hou,Juanzi Li", "background": "专门的实体链接_EL 模型在根据给定语境将提及映射到知识库_KB 唯一实体方面表现良好。然而，这些模型在区分尾部实体时遇到困难，因为它们的训练数据有限。相比之下，广泛预训练的大型语言模型具备更广泛的知识，尤其对不常见的实体。但是，缺乏专门的实体链接训练，这些大型语言模型在生成准确的 KB 实体名称方面经常失败，从而限制了它们在实体链接中的独立效果。观察到大型语言模型在上下文生成方面的优势而非执行实体链接，本文提出了一种新的框架LLMAEL：大型语言模型增强实体链接，利用即用型、无需微调的大型语言模型作为上下文增强器，生成实体描述作为专门的实体链接模型的额外输入。", "innovation": "LLMAEL 是第一个利用大型语言模型增强专门的实体链接模型的框架。它利用即用型、无需微调的大型语言模型作为上下文增强器，生成实体描述以作为附加输入提供给专门的实体链接模型。实验表明，LLMAEL 在 6 个广泛采用的实体链接基准测试中设置了新的最先进结果：与之前的将大型语言模型集成到实体链接方法相比，LLMAEL 在实体链接准确性上提高了绝对 8.9%。", "conclusion": "我们发布了我们的代码和数据集。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13319", "html_url": "https://arxiv.org/abs/2502.13319", "title": "揭秘医疗保健中LLMs人口统计偏差的机制", "title_en": "Elucidating Mechanisms of Demographic Bias in LLMs for Healthcare", "authors": "Hiba Ahsan,Arnab Sen Sharma,Silvio Amir,David Bau,Byron C. Wallace", "background": "已有研究表明，大型语言模型(Large Language Models, LLMs)会编码社会偏见，并且这一问题反映在临床任务中。本文采用机制解释工具来揭示医疗保健背景下LLMs中的社会人口统计特征及其偏见。", "innovation": "文章利用机制解释方法探究LLMs编码的社会人口统计信息（如性别、种族）及其在临床场景中的表现。特别是在模型中准确识别并操控性别信息，并通过修补手段在推理阶段进行干预。文章揭示了LLMs在特定条件下的临床场景生成和后端预测中的性别偏见，并探索了种族信息的分布特征及其可控性。", "conclusion": "这是首次应用机制解释方法到医疗保健中的LLMs研究，展示了通过干预LLMs可以精准操控特定社会人口统计信息，进而影响临床决策预测。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.12881", "html_url": "https://arxiv.org/abs/2402.12881", "title": "TEXT2AFFORD: 仅从文本探究语言模型对象功能预测能力", "title_en": "TEXT2AFFORD: Probing Object Affordance Prediction abilities of Language Models solely from Text", "authors": "Sayantan Adak,Daivik Agrawal,Animesh Mukherjee,Somak Aditya", "background": "已有研究显示，预训练语言模型（PTLMs）和预训练视觉-语言模型（PTVLMs）常常表现出不一致且非直观的推理错误，缺乏合理的推理和现实联系。为了量化这种缺点的影响，本文收集并整理了一个全面的物体功能数据集——Text2Afford，该数据集包含了15个功能类别，并且是通过在真实文本中注解物体和功能来创建的，不同于以往的研究，Text2Afford强调从文本层面探讨物体功能的理解。实验结果显示，PTLMs在处理不常见物体功能时表现出有限的推理能力。研究发现，预训练VLMs也不一定有效地捕捉物体功能。实验证明，通过少量的微调可以提高这些模型对物体功能的理解能力。", "innovation": "本文首次提出了一个全面的物体功能数据集Text2Afford，它通过在真实文本中注解物体和功能，探讨了语言模型对物体功能的理解能力，并通过少量微调展示了模型性能的提升。这一创新不仅提供了新的数据集，还对预训练语言模型和视觉语言模型的功能推理能力进行了深入探索，拓宽了当前研究的边界", "conclusion": "本文通过引入Text2Afford数据集和相应的实验设计，不仅揭示了预训练模型在物体功能理解方面的不足，还展示了通过少量微调改善模型性能的可能性。这些研究结果为后续在语言和视觉领域的工作提供了新的思路和数据支持，促进了对预训练模型功能推理能力的理解，有助于未来的研究和模型开发。所有代码和数据均可在 [链接] 中获取。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01902", "html_url": "https://arxiv.org/abs/2503.01902", "title": "如何通过提示工程使大语言模型 fails 支持事实核实", "title_en": "How LLMs Fail to Support Fact-Checking", "authors": "Adiba Mahbub Proma,Neeley Pate,James Druckman,Gourab Ghoshal,Hangfeng He,Ehsan Hoque", "background": "大型语言模型（LLMs）能够放大线上虚假信息，但也显示出对抗虚假信息的潜力。本文从实际出发，研究了三种大语言模型——ChatGPT、Gemini 和 Claude 在对抗政治虚假信息方面的表现。研究人员采用两步提示方法，首先让模型识别给定声明的可信来源，然后生成有说服力的回应。", "innovation": "本研究采用了一种两步提示方法：首先模型识别可信来源，然后生成有说服力的回应。研究发现模型在引用真实新闻来源方面存在困难，更倾向于引用左倾来源，模型之间也表现出不同层次的回应多样性。这引发了对仅通过提示工程使用大语言模型进行事实核查的担忧，强调了需要更加稳健的约束。", "conclusion": "本文的研究结果对研究人员和非技术用户具有重要意义。强调了仅通过提示工程使用大语言模型进行事实核查存在不足，需要更加稳健的约束措施。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.23261", "html_url": "https://arxiv.org/abs/2410.23261", "title": "$100,000 或 100 天：使用学术资源进行预训练的权衡", "title_en": "$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources", "authors": "Apoorv Khandelwal,Tian Yun,Nihal V. Nayak,Jack Merullo,Stephen H. Bach,Chen Sun,Ellie Pavlick", "background": "学术研究人员通常计算资源有限，这使得大规模模型的预训练变得困难。因此，普遍认为学术研究人员无法进行大规模模型的预训练。本文通过调查学术研究人员的计算资源，实测在这些资源上复现模型所需的时间，并开发了一种基准测试来衡量在给定GPU上预训练模型所需的时间，以澄清这一假设。", "innovation": "本文通过实测方法澄清了学术研究人员进行模型预训练的资源限制，介绍了如何在限制条件下有效利用学术计算资源，开发了一种基准测试来测量模型预训练所需时间，并识别出最佳训练设置以最大化训练速度。此外，还进行了一项成本效益分析，帮助学术研究人员更好地权衡价格和预训练时间之间的trade-offs。", "conclusion": "我们的基准测试将帮助学术研究人员进行需要更大模型和更多数据的实验。我们可以访问此项研究的完整代码库: [this https URL]()。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.20016", "html_url": "https://arxiv.org/abs/2410.20016", "title": "LLMs对垂直对齐文本操纵的脆弱性", "title_en": "Vulnerability of LLMs to Vertically Aligned Text Manipulations", "authors": "Zhecheng Li,Yiwei Wang,Bryan Hooi,Yujun Cai,Zhen Xiong,Nanyun Peng,Kai-wei Chang", "background": "垂直文本输入在现实世界的应用中很常见，例如数学运算和基于单词的数独游戏。尽管当前的大语言模型（LLMs）在自然语言处理任务中表现出色，但在文本格式变化方面依然脆弱。已有研究证明，修改输入格式，如将单词垂直排列，会显著降低基于编码器的模型在文本分类任务中的准确率。而这种输入对于模型来说构成了潜在风险，可能绕过检测以传播有害或敏感信息。随着LLMs应用范围的扩大，一个关键问题是：基于解码器的LLMs在面对垂直格式化文本输入时是否同样存在类似弱点？", "innovation": "本研究调查了不同LLMs在多种文本分类数据集上对垂直文本输入的性能影响，并分析了其根本原因。研究发现：(i) 垂直输入显著降低了LLMs的文本分类准确性。(ii) 解释性推理无法帮助LLMs识别垂直输入或减轻其脆弱性，但通过少量示例学习结合细致分析的做法却有效。本研究还探讨了脆弱性的根本原因，分析了令牌化和注意力矩阵固有的问题。", "conclusion": "垂直文本输入显著降低了各种LLMs在文本分类任务中的准确性。单纯的解解释性推理不能缓解这一问题，而通过少量示例学习结合细致分析则有效。同时，这种脆弱性与令牌化和注意力机制的问题有关，需要进一步研究以改进这些机制，提升模型的鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.21054", "html_url": "https://arxiv.org/abs/2410.21054", "title": "语义成分分析：将多主题分布引入基于聚类的主题建模", "title_en": "Semantic Component Analysis: Introducing Multi-Topic Distributions to Clustering-Based Topic Modeling", "authors": "Florian Eichin,Carolin M. Schuster,Georg Groh,Michael A. Hedderich", "background": "主题建模是文本分析中的关键方法，但现有的方法要么无法有效处理大规模数据集，要么受限于每个文档只能有一个主题的假设。", "innovation": "引入语义成分分析（SCA），这是一种在基于聚类的主题建模框架中引入分解步骤的主题建模技术，能够发现每个样本的多个主题。", "conclusion": "SCA 在针对英语、豪萨语和中文的推特数据集上进行评估时，显示出了与BERTopic相当的协同性和多样性，而发现的主题数量是其至少两倍，并且保持接近零的噪音率。此外，SCA 在类似计算预算的情况下也优于基于大语言模型的主题建模方法TopicGPT。因此，SCA 提供了一种有效且高效的处理大规模数据集的主题建模方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03064", "html_url": "https://arxiv.org/abs/2503.03064", "title": "通过判断分布改进LLM-as-a-Judge推理", "title_en": "Improving LLM-as-a-Judge Inference with the Judgment Distribution", "authors": "Victor Wang,Michael J.Q. Zhang,Eunsol Choi", "background": "语言模型（LLM）作为衡量工具已被广泛应用于多种任务中，通常直接从判断者的文本输出中提取判断，多采用贪婪解码。然而，这种方法可能会忽略判断分布中的更多信息。研究发现，对判断分布取均值的方法通常优于直接取模（即贪婪解码）。通过这种方式，可以从判断分布中提取更细致的偏好。", "innovation": "研究提出了新的从判断分布中提取偏好方法，并发现融入风险规避的方法能提升性能。研究还探讨了链式思考（CoT）提示对LLM-as-a-judge的影响，结果显示CoT可能缩减判断分布的范围，从而有时会损害性能。研究证明了利用分布输出优于仅使用文本界面。", "conclusion": "利用判断分布可以改进LLM-as-a-judge的性能，而非仅仅依赖贪婪解码的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.07145", "html_url": "https://arxiv.org/abs/2410.07145", "title": "胀满的Mamba：过大的状态导致无法遗忘", "title_en": "Stuffed Mamba: Oversized States Lead to the Inability to Forget", "authors": "Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "近年来，如Mamba和RWKV等递归架构展示了强大的语言能力。与基于Transformer的模型相比，这些架构将所有上下文信息编码为固定大小的状态中，从而提高了推理效率。然而，这种做法可能导致信息干扰，即不同令牌数据之间的冲突，这会导致在特定上下文长度之后的性能下降和不一致的输出。大多数递归神经网络（RNNs）通过引入“忘记”早期令牌的机制来应对这一问题。但是作者指出，基于Mamba的模型即使有内置的忘记机制，也难以有效地忘记早期令牌。研究表明，由于使用的上下文较短，使得模型能通过不学习忘记的功能就能表现良好。研究发现，模型学习忘记的最小训练长度与状态大小成线性关系，而准确检索五位密码的最大上下文长度与状态大小呈指数关系，表明模型在忘记机制开始发挥作用之前仍保留了一些信息。这些发现揭示了当前RNN架构的重要局限性，并为改进长上下文建模提供了有价值的信息。未来RNN设计需要考虑状态大小、训练长度与遗忘机制之间的相互作用，以实现长上下文任务中的稳健性能。", "innovation": "该研究揭示了基于Mamba的模型在学习忘记早期令牌方面的困难，指出这是由于训练上下文较短导致的。研究还发现，模型学习忘记的最小训练长度与状态大小成线性关系，而准确检索五位密码的最大上下文长度与状态大小呈指数关系，表明模型在忘记机制开始发挥作用之前仍保留了一些信息。这项工作强调了RNN架构的一个重要限制，并为改善长上下文建模提供了有价值的意见。未来的RNN设计需要考虑状态大小、训练长度与遗忘机制之间的相互作用，以实现长上下文任务中的稳健性能。", "conclusion": "这些发现揭示了当前RNN架构的重要局限性，并为改进长上下文建模提供了有价值的信息。未来RNN设计需要考虑状态大小、训练长度与遗忘机制之间的相互作用，以实现长上下文任务中的稳健性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.06692", "html_url": "https://arxiv.org/abs/2503.06692", "title": "InftyThink：克服大型语言模型长上下文推理长度限制的新范式", "title_en": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models", "authors": "Yuchen Yan,Yongliang Shen,Yang Liu,Jin Jiang,Mengdi Zhang,Jian Shao,Yueting Zhuang", "background": "大型语言模型在复杂任务上的推理表现显著，但现有的长上下文推理方法面临关键局限性，如序列长度的二次计算复杂度、跨最大上下文边界的推理限制，以及超出预训练上下文窗口后性能下降。现有方法主要集中在压缩推理链，但未能解决根本的计算复杂度问题。", "innovation": "提出了一种新范式InftyThink，将单一推理过程转换为带有中间总结的迭代过程。通过交错短推理片段和简明进度总结，InftyThink使推理深度不受限制，同时保持计算成本的可控性。此方法创造出锯齿状的记忆模式，相比传统方法显著减少了计算复杂度。通过开发一种将长上下文推理数据集转换为迭代格式的方法，使OpenR1-Math数据集转化为333,000个训练实例。", "conclusion": "我们的工作挑战了推理深度和计算效率之间的传统权衡，在多个模型架构下展示了成本降低和性能提升的效果。例如，Qwen2.5-Math-7B在MATH500，AIME24和GPQA_diamond基准上分别取得了3%到13%的性能提升。这提供了一种无结构修改的、更具扩展性的复杂推理方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "揭秘金融大语言模型的后训练领域适应", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "大语言模型（LLMs）的领域适应性后训练（Domain-adaptive post-training）在医学和金融等专业化领域中展现出巨大潜力。然而，不同数据和模型配置下的最优适应标准和训练策略仍然存在挑战。为了应对这些挑战，作者提出了一种旨在破解金融领域领域适应性后训练的方法，即FINDAP（FINd Adaptation Criteria and Preference）。", "innovation": "作者的方法包括四个关键组件：FinCap（定义目标领域的核心能力）、FinRec（结合连续预训练和指令跟随的高效训练食谱，以及一种新颖的过程信号引导的偏好数据蒸馏方法）、FinTrain（支持FinRec的一组定制化的训练数据集）和FinEval（与FinCap目标一致的综合评估基准）。该研究提出了一种创新的方法，通过每一阶段的后训练贡献，揭示了具体挑战和有效的解决方案，为大语言模型的领域适应提供了重要的见解。", "conclusion": "最终，作者的方法生成的Llama-Fin模型在广泛金融任务上取得了最先进的性能。该研究还强调了各个后训练阶段对特定能力的贡献，明确了具体挑战和有效解决方案，为以后的工作提供了有用的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12663", "html_url": "https://arxiv.org/abs/2502.12663", "title": "探讨过程奖励建模中的多语言链式思维", "title_en": "Demystifying Multilingual Chain-of-Thought in Process Reward Modeling", "authors": "Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch", "background": "大型语言模型（LLMs）被设计用于执行广泛的任务。为了提高解决需要多步推理的复杂问题的能力，最近的研究利用过程奖励建模以精细的反馈形式来增强强化学习（RL），但大多数工作集中在英语上。目前，本研究致力于在多语言环境下的多语言过程奖励模型（mPRMs）的研究，以期解决这一关键问题。", "innovation": "通过对七种语言（由英语翻译而来）的数据集进行训练，本研究提出并训练了mPRMs，并在两个广泛使用的推理基准上进行了11种语言的全面评估。结果显示，mPRMs不仅提高了平均准确率，还减少了早期的推理错误。同时，研究表明mPRMs对训练语言的数量和英语数据的量敏感，并揭示了更多候选响应和可训练参数带来的好处。", "conclusion": "本工作为在复杂、多步推理任务中实现稳健的多语言应用开辟了新的路径。此外，研究者公开了代码以促进这一领域的进一步研究。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.08413", "html_url": "https://arxiv.org/abs/2501.08413", "title": "使用语言模型集成标记自由文本数据", "title_en": "Labeling Free-text Data using Language Model Ensembles", "authors": "Jiaxing Qiu,Dongliang Guo,Natalie Papini,Noelle Peace,Hannah F. Fitterman-Harris,Cheri A. Levinson,Tom Hartvigsen,Teague R. Henry", "background": "在心理研究中，通常会收集自由文本回应，提供丰富的定性见解，这可能不是定量指标能够捕捉到的。然而，通过多训练人类编码者手动标记与研究兴趣相关的主题需要大量的时间和人力投入。尽管大规模语言模型（LLMs）在语言处理方面表现出色，但依赖闭源LLMs的LLM辅助标记技术无法直接应用于自由文本数据，除非获得外部使用许可。本研究提出了一种框架，通过结合本地部署的LLMs来增强在隐私约束下的自由文本数据标注，旨在在保持隐私的同时提升标注效率。", "innovation": "该研究提出了一种使用语言模型集成的方法，以在隐私保护的前提下对自由文本数据中的预定义主题进行标注。这种方法通过结合多种开源语言模型，利用嵌入距离和相关性评分方法来平衡不同模型之间的一致性和分歧，相较于单一语言模型，集成模型在预测人类标注方面获得了更高的准确性和最优的精确度-敏感度权衡。", "conclusion": "研究发现，规模相同的LLMs在标记性能上存在异质性，一些模型具有低灵敏度和高精确度，而另一些则具有高灵敏度和低精确度。相比单一模型，集成模型在预测人类标注方面表现最佳，并且在丢弃二元标签的情况下，模型间的相关性评分更能一致地反映出所属主题的相关性，说明相关性评分方法有效地缓解了LLMs标记间的异质性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10823", "html_url": "https://arxiv.org/abs/2504.10823", "title": "CLASH：从多视角评估语言模型在判断高风险困境方面的表现", "title_en": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives", "authors": "Ayoung Lee,Ryan Sungmo Kwon,Peter Railton,Lu Wang", "background": "在高风险领域，人类和人工智能面对冲突价值观时的决策都具有挑战性，而先前的工作大多集中在日常生活场景中。CLASH 数据集旨在填补这一空白，它包含345个高影响困境及3,795个不同价值观的个体视角，有助于研究基于价值观的决策过程的关键但未被充分探索的方面。", "innovation": "CLASH 提供了一个精心策划的数据集，用于研究价值观导向决策的相关方面，包括决策中的矛盾、心理不适，以及价值观随时间变化的视角变化。研究通过对14个非思考和思考模型进行基准测试，揭示了几个关键发现：较强的语言模型在处理心理矛盾决策时表现出色，但难以理解涉及价值观转变的视角；数学解题和游戏策略领域的认知行为不能很好地应用于价值推理中，并出现新的错误模式；语言模型的价值导向与它们的价值偏好显著相关；在第三人称视角推理时，语言模型更具可控性，尽管某些价值（如安全）可能更受益于第一人称构架。", "conclusion": "研究揭示了几个关键发现，进一步证明了语言模型在处理价值观导向决策中面临的挑战，尤其是在情境复杂和涉及价值观转变时，这些发现有助于指导未来的研究和模型开发。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12633", "html_url": "https://arxiv.org/abs/2504.12633", "title": "SOLAR: 通过建模价值冲突与权衡来刻画个体的主观性", "title_en": "SOLAR: Towards Characterizing Subjectivity of Individuals through Modeling Value Conflicts and Trade-offs", "authors": "Younghun Lee,Dan Goldwasser", "background": "大规模语言模型（LLMs）不仅能够解决复杂的推理问题，还在需要主观判断的任务上表现出色。已有研究表明，LLM生成的内容在一定程度上可以主观地进行校准，但尚未充分探索LLMs能否解释个体级的主观性。该研究旨在通过分析社交媒体生成的内容来描述个体的主观性，并利用LLM推断其道德判断。", "innovation": "本文提出了一种名为SOLAR的框架，该框架通过观察用户生成文本中的价值冲突和权衡来更好地表示个体的主观基础。实验证明，SOLAR框架提高了整体推断结果和处理争议情况的表现，并提供了个体价值偏好解释，进一步解释了他们的判断。", "conclusion": "实验结果显示SOLAR框架能够提高整体推断结果，特别是在争议情境下的表现。此外，SOLAR还提供了对个体价值偏好的解释，进一步解释了他们的判断。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14538", "html_url": "https://arxiv.org/abs/2502.14538", "title": "LoRA-MGPO：通过动量引导的扰动优化减轻低秩适应中的双下降现象", "title_en": "LoRA-MGPO: Mitigating Double Descent in Low-Rank Adaptation via Momentum-Guided Perturbation Optimization", "authors": "Yupeng Chang,Chenlu Guo,Yi Chang,Yuan Wu", "background": "PEFT技术，特别是LoRA方法，能够通过微调少量参数来适应大语言模型。然而，随着用于适应的低秩矩阵秩的增加，LoRA可能会表现出一种不稳定的“双下降”现象，即训练损失的暂时发散，这会延缓收敛并导致模型在接近尖锐局部极小值时不稳定。", "innovation": "提出了LoRA-MGPO框架，该框架结合了Momentum-Guided Perturbation Optimization (MGPO)。MGPO通过使用优化器状态中的动量向量来稳定训练动态并引导权重扰动，从而避免双梯度计算。此外，还提出了一种自适应规范化方案，根据梯度范数的指数移动平均值来调整扰动的幅度。该方法不仅控制了扰动的幅度，还引导了它们的方向，确保了更稳定的优化轨迹。", "conclusion": "在各种自然语言理解和生成基准测试上的实验表明，LoRA-MGPO在性能上优于LoRA和其他PEFT方法。分析结果表明，LoRA-MGPO可以实现更平滑的损失曲线、更快的收敛速度和更好的泛化能力，这归功于训练过程的稳定性和对尖锐极小值的抵制。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10150", "html_url": "https://arxiv.org/abs/2503.10150", "title": "基于层级知识的检索增强生成", "title_en": "Retrieval-Augmented Generation with Hierarchical Knowledge", "authors": "Haoyu Huang,Yongfeng Huang,Junjie Yang,Zhenyu Pan,Yongqiang Chen,Kaili Ma,Hongzhi Chen,James Cheng", "background": "图为基础的检索增强生成（RAG）方法极大地提升了大型语言模型（LLMs）在特定领域任务中的表现。但是，现有的RAG方法未能充分利用人类认知中自然存在的层级知识结构，这限制了RAG系统的性能。", "innovation": "本文提出了一种新的RAG方法，称为HiRAG，该方法利用层级知识提高RAG系统在索引和检索过程中的语义理解和结构捕捉能力。", "conclusion": "广泛的实验表明，HiRAG方法在基准方法之上取得了显著的性能提升。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.21263", "html_url": "https://arxiv.org/abs/2502.21263", "title": "RuCCoD: 向俄语ICD编码自动化迈进", "title_en": "RuCCoD: Towards Automated ICD Coding in Russian", "authors": "Aleksandr Nesterov,Andrey Sakhovskiy,Ivan Sviridov,Airat Valiev,Vladimir Makharev,Petr Anokhin,Galina Zubkova,Elena Tutubalina", "background": "该研究探讨了在俄语环境中自动化临床编码的可行性，俄语在生物医学资源方面较为有限。研究提供了用于ICD编码的新数据集，包含电子健康记录中的诊断字段，标记了超过10,000个实体和1,500多个独特ICD代码，为多个最先进的模型提供了基准测试，包括BERT、带LoRA的LLaMA以及RAG。研究还进行了跨领域（从PubMed摘要到医学诊断）和术语（从UMLS概念到ICD编码）的迁移学习实验。这些实验在精心选择的测试集上进行，结果显示，使用自动预测代码进行训练与医生手动标注的数据相比，准确性显著提高。研究表明，俄语等资源有限的语言的临床编码自动化具有潜在价值，这可以提高这些环境下临床效率和数据准确性。", "innovation": "该研究的新颖之处在于它提供了一个新的俄语文本的ICD编码数据集，该数据集包含超过10,000个实体和1,500多个独特ICD代码，为多个最先进的模型提供了基准测试。同时，研究还进行了跨领域和术语的迁移学习实验，并展示了训练模型的显著改进效果。这些实验首次展示了在俄语资源有限的语言环境下自动化临床编码的可行性。", "conclusion": "研究结果表明，通过使用自动化预测代码进行训练可以显著提高临床编码的准确性，相较之下，使用医生手动标注的数据。本研究为俄语等资源有限语言的临床编码自动化提供了重要见解，这将有助于提高这些环境下临床效率和数据准确性。研究中的代码和数据集已公开可供下载。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02519", "html_url": "https://arxiv.org/abs/2503.02519", "title": "Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent", "title_en": "Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent", "authors": "Xingzuo Li,Kehai Chen,Yunfei Long,Xuefeng Bai,Yong Xu,Min Zhang", "background": "大型语言模型（LLM）代理通常采用逐步推理框架，在这一框架中，它们会交替思考和行动以完成给定任务。然而，这种范式面临一个深层次的一次性问题，即每一生成的中间想法都会被无条件地插入到路径中，无论其正确与否，这会导致不可逆的错误传播。", "innovation": "本文提出了一种名为Generator-Assistant Stepwise Rollback（GA-Rollback）的新框架，以提高LLM代理的决策能力。GA-Rollback利用一个生成器与环境交互，并利用一个助手检查生成器生成的每个行动。如果检测到错误行为，助手会触发回滚操作。此外，引入了两种针对回滚场景的策略，以进一步提高其有效性。", "conclusion": "广泛的实验证明，GA-Rollback在三个广泛使用的基准测试上取得了显著改善，超越了多个强大的基线。我们的分析还表明，GA-Rollback能够作为稳健的即插即用模块，与其他方法无缝集成。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01986", "html_url": "https://arxiv.org/abs/2503.01986", "title": "使用任务激发适应性地表征模型", "title_en": "Adaptively profiling models with task elicitation", "authors": "Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong", "background": "现有的语言模型评估常常无法全面地捕捉到关键的失败模式，导致专家需要手动检查模型的输出并建立新的基准。这就需要耗费大量时间和精力，且效率低下。因此，研究人员迫切需要一种自动化的方法来构建新的评估，以准确地描绘模型的行为。", "innovation": "本文提出了任务激发（Task Elicitation）方法，能够自动构建新的评估以捕捉模型在各个领域的系统性失败模式，包括从预测到网络骚扰等多方面。与以往方法相比，任务激发能够发现数百种自然语言任务，比以往工作的数量多了一个数量级，并且能更好地揭示模型在前沿任务上的薄弱环节，如Sonnet 3.5对量子计算和AGI之间关联的过度关联以及o3-mini在重复虚构内容时的幻觉倾向。", "conclusion": "任务激发方法能够显著提高语言模型评估的自动性和有效性，为识别和解决模型的系统性失败提供了新的途径。未来的研究可以进一步探索如何利用这些新发现的任务来提升模型的鲁棒性和准确性，以更好地服务于实际应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11140", "html_url": "https://arxiv.org/abs/2505.11140", "title": "根据路径推理：通过知识图谱路径提升LLM事实性", "title_en": "Follow the Path: Reasoning over Knowledge Graph Paths to Improve LLM Factuality", "authors": "Mike Zhang,Johannes Bjerva,Russa Biswas", "background": "该研究背景在于，尽管大语言模型（LLMs）具有强大的语言生成能力，但在应对复杂任务时，它们往往缺乏足够的事实性和可信度。先前的工作展示了在STEM领域中使用推理轨迹的有效性，但缺乏在通用知识密集型任务中将推理与知识图谱路径衔接起来的相关研究。本研究旨在通过借鉴知识图谱路径，改进LLMs的推理过程，从而提高其事实准确性和可靠性。", "innovation": "引入了一种简单但有效的方法fs1，它通过使用大型推理模型（如DeepSeek-R1）生成推理轨迹，并通过条件概率知识图谱路径将其支撑起来，从而增强其事实性。具体创新包括：1) 细调八种指令优化的大语言模型，基于3900条事实支撑的推理轨迹；2) 在六个复杂的开放域问答（QA）基准测试中，对23900个问题进行严谨评估；3) 结果表明fs1优化模型在多步骤推理和数字答案类型中表现出显著优势。", "conclusion": "本研究证明，通过连接推理过程和事实支撑的知识图谱路径，可以显著提高大语言模型在复杂领域的表现。fs1优化模型在多项测试中均强于对比模型，特别是对于需要更多推理步骤和数值答案的问题。此外，研究表明，更小的模型在单次推理中表现出最大的改进。本工作对无需高度专业领域的广泛知识密集型任务具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12313", "html_url": "https://arxiv.org/abs/2505.12313", "title": "ExpertSteer：通过专家知识干预大语言模型", "title_en": "ExpertSteer: Intervening in LLMs through Expert Knowledge", "authors": "Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch", "background": "大语言模型展示了在各种任务中的出色能力，但在推理过程中引导它们遵循预期的行为仍然是一个重大挑战。激活引导提供了一种可能的方法来控制大语言模型的生成过程，通过修改其内部激活。然而，现有方法通常使用模型本身生成的方向向量来干预模型的行为，这限制了它们的效果仅限于特定的模型，并排除了利用强大的外部专家模型的可能性来进行干预。", "innovation": "我们提出了ExpertSteer，这是一种新颖的方法，利用任意专业的专家模型来生成干预向量，使用户能够干预任何大语言模型。ExpertSteer通过一个协调的四步流程，将知识从专家模型转移到目标大语言模型：首先，通过自编码器对表示维度进行对齐以实现跨模型转移；其次，基于互信息分析确定干预层对；然后，使用递归特征机从专家模型生成干预向量；最后，在推理过程中应用这些向量到所确定的层，以选择性地指导目标大语言模型而无需更新模型参数。", "conclusion": "我们在三个大语言模型上对15个流行的跨四个不同领域的基准进行了全面实验。实验结果显示，ExpertSteer在各种任务中显著优于现有baseline，且成本较低。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09579", "html_url": "https://arxiv.org/abs/2503.09579", "title": "Cost-Optimal Grouped-Query Attention for Long-Context Modeling", "title_en": "Cost-Optimal Grouped-Query Attention for Long-Context Modeling", "authors": "Yingfa Chen,Yutong Wu,Chenyang Song,Zhen Leng Thai,Xingyu Shen,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "Grouped-Query Attention (GQA)作为一种减少大型语言模型（LLMs）注意力层计算成本的常用策略被广泛采用。然而，现有GQA配置通常效率低下，因为它忽视了上下文长度对推理成本的影响。由于推理成本随上下文长度增加而增长，因此最高效能的GQA配置也应该相应变化。已有研究发现，常用的GQA配置在长上下文场景中极为不理想。文章分析了上下文长度、模型规模、GQA配置和模型损失之间的关系，并引入了两个创新点：1）将总注意力头数量与隐藏层尺寸解耦，使得注意力FLOPs的控制更加灵活；2）联合优化模型规模和GQA配置，以更有效地分配注意力层和其他组件间的推理资源。这些创新有助于为长上下文的LLMs设计更高效的GQA配置。研究表明，对于长上下文场景，应减少注意力头数量并在处理长上下文时增加模型规模。所提出的GQA配置可以降低50%以上的内存使用和FLOPs，且不影响模型性能能力。这些发现为设计高效的长上下文LLMs提供了有价值的观点。开源代码可在提供的链接中找到。", "innovation": "1. 将总注意力头数量与隐藏层尺寸解耦，使得注意力FLOPs的控制更加灵活；2. 联合优化模型规模和GQA配置，以更有效地分配注意力层和其他组件间的推理资源；3. 提出了一种新的GQA配置方法，适用于长上下文场景，可以显著减少内存使用和FLOPs，且不影响模型性能能力。", "conclusion": "文章通过分析上下文长度、模型规模、GQA配置和模型损失之间的关系，提出了新的GQA配置方法，改善了模型的计算效率。长上下文场景下，建议使用较少的注意力头并扩大模型规模，这可以显著减少内存使用和FLOPs，且不损害模型的性能。研究结果为高效长上下文LLMs的设计提供了重要见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23768", "html_url": "https://arxiv.org/abs/2503.23768", "title": "纹理还是语义？视觉-语言模型在字体识别中迷失了方向", "title_en": "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition", "authors": "Zhecheng Li,Guoxian Song,Yujun Cai,Zhen Xiong,Junsong Yuan,Yiwei Wang", "background": "现代视觉-语言模型（VLMs）展示了卓越的视觉和语言能力，在图像识别和对象定位等多种任务中取得了出色的性能。然而，它们在细粒度任务上有效性的实现仍是一个开放的问题。在日常场景中，人们在遇到包含设计材料的场合下，如杂志、排版教程、研究论文或品牌内容，希望能够识别文本中使用的美观字体。鉴于VLMs具备多模态能力和自由获取，许多人认为VLMs是潜在的字体识别工具。但一个基本问题随之而来：VLMs是否真的具备字体识别能力？", "innovation": "该研究引入了一个名为字体识别基准（FRB）的小巧且结构良好的数据集，包含15种常用字体的两种版本：一个是较简单的版本，其中10句话以不同的字体呈现；另一个是更具挑战性的版本，每个文本样本包含15种字体的名称，这种斯特鲁普效应容易挑战模型的识别能力。重点通过广泛评估各种VLMs在字体识别任务中的表现，发现当前的VLMs在字体识别方面的能力有限，许多最先进的模型无法达到令人满意的性能，并且容易受到文本信息引入的斯特鲁普效应的影响；几乎没有证据表明少量的学习和链式思考（CoT）提示方法在不同VLMs上提高了字体识别准确性；注意力分析揭示了VLMs在捕捉语义特征方面固有的局限性。", "conclusion": "研究表明，当前VLMs在字体识别方面的能力有限，无法广泛地获取字体识别任务中的适当性能，特别是在面对斯特鲁普效应时。尽管多模态能力强大且易于访问，但VLMs在捕捉文本语义特征方面仍然存在显著的局限性。此外，少量学习和链式思考提示方法对提高字体识别准确性效果甚微。总之，VLMs在字体识别方面的应用仍然有限，未来的研究需要解决这些固有的局限性，以提高其在细粒度视觉语言任务中的表现。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13141", "html_url": "https://arxiv.org/abs/2505.13141", "title": "语言特定的潜在意图阻碍了跨语言表现", "title_en": "Language-Specific Latent Process Hinders Cross-Lingual Performance", "authors": "Zheng Wei Lim,Alham Fikri Aji,Trevor Cohn", "background": "大型语言模型（LLMs）能够在跨语言迁移中表现出色，但在用不同语言提出相同查询时，其输出可能会不一致。为了理解语言模型如何从一种语言向另一种语言迁移知识，研究者度量了不同语言之间的表示相似性，并通过逻辑光束（logit lens）来解释LLMs在解决多语言多项选择推理问题时所采取的隐式步骤。然而，结果显示，尽管较大型模型具有更好的多语言能力，但它们的隐藏状态更倾向于脱离共享表示空间，而不是保持一致的语义空间。因此，更小的模型虽然共享知识的效果较低，但仍然能够从不同语言中检索知识。", "innovation": "本研究通过度量不同语言之间的表示相似性，并通过逻辑光束来解释LLMs解决跨语言问题的隐式步骤，揭示了它们在跨语言迁移学习中的不足之处。此外，研究还展示了通过引导小模型的潜在处理靠近共享语义空间，可以提高这些模型在多语言推理方面的表现。", "conclusion": "语言特定的潜在意图阻碍了跨语言的表现，较大型模型虽然更具有多语言能力，但其隐藏状态更有可能与共享表示空间脱离，这不利于多语言推理。然而，通过将小模型的潜在处理引导至共享语义空间，知识转移能力增强，从而提高了它们的跨语言推理性能和输出一致性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18346", "html_url": "https://arxiv.org/abs/2504.18346", "title": "比较大型语言模型的不确定性测量与缓解方法：一个系统综述", "title_en": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review", "authors": "Toghrul Abbasli,Kentaroh Toyoda,Yuan Wang,Leon Witt,Muhammad Asif Ali,Yukai Miao,Dan Li,Qingsong Wei", "background": "大型语言模型（LLMs）在多个领域实现了变革，但它们仍然面临着输出错误信息的问题，即幻觉。因此，准确评估和量化LLMs的不确定性变得尤为重要。以前关于传统模型的研究探索了不确定性量化（UQ）方法来测量不确定性，并采用了校准技术来解决不确定性与准确性之间的不一致问题。尽管有一些方法被调整用于LLMs，但现有的文献缺乏对这些方法效果的深入分析，并且缺少一个综合基准来帮助对现有解决方案进行有意义的比较。", "innovation": "本研究通过系统回顾代表性前人工作中的不确定性量度和校准方法，并引入了严格基准。使用两个广泛使用的可靠性数据集，实证评估了六个相关方法，这证明了文献综述的重要发现。最后，为关键的未来方向提供了展望，并指出了开放性挑战。据我们所知，这是首个致力于研究LLMs的校准方法和相关度量的专门研究。", "conclusion": "研究结果证明了现有方法的有效性，并提出了未来的关键方向和开放挑战。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02091", "html_url": "https://arxiv.org/abs/2505.02091", "title": "LLM-OptiRA：无线通信中非凸资源分配问题的LLM驱动优化", "title_en": "LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications", "authors": "Xinyue Peng,Yanming Liu,Yihan Cang,Chaoqun Cao,Ming Chen", "background": "无线通信系统中的非凸资源分配问题解决起来具有重大挑战性，传统优化技术往往难以应对。这些问题的存在限制了系统性能的提升与优化过程的自动化水平。", "innovation": "提出了一种名为 LLM-OptiRA 的框架，该框架首次利用大型语言模型（LLM）自动检测和转换非凸组件，使其转化为可解决的形式，从而实现无线通信系统中非凸资源分配问题的完全自动化解决方案。LLM-OptiRA 通过减少对专家知识的依赖简化问题解决过程，并集成了错误校正和可行性验证机制，确保了系统的鲁棒性。实验结果表明，LLM-OptiRA 在 GPT-4 上达到了 96% 的执行率和 80% 的成功率，在各种复杂优化任务中显著优于基线方法。", "conclusion": "LLM-OptiRA 通过利用 LLM 实现了无线通信系统中非凸资源分配问题的自动化解决，提高了执行效率和成功率，展现了在复杂优化任务中的优越性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15241", "html_url": "https://arxiv.org/abs/2504.15241", "title": "MrGuard: 多语言推理护栏以确保通用大语言模型的安全性", "title_en": "MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety", "authors": "Yahan Yang,Soham Dan,Shuo Li,Dan Roth,Insup Lee", "background": "大语言模型（LLMs）容易受到如劫持等对抗性攻击，这可能导致有害或不安全的行为。这种脆弱性在多语言环境下尤为严重，因为多语言齐安全对齐的数据通常有限。因此，在多元文化环境中部署LLMs时，开发一种能检测和过滤不同语言中的不安全内容的护栏至关重要。本研究介绍了一种考虑多语言推理的护栏方法，该方法旨在解决这一问题，并帮助确保LLMs的安全应用。", "innovation": "该研究提出了一个名为MrGuard的多语言护栏，通过分类提示并结合推理能力，有效检测和过滤不安全内容。其创新点在于：(1) 制作包括文化与语言差异的合成多语言数据；(2) 监督微调；(3) 采用基于课程的群相对策略优化（GRPO）框架以进一步提升性能。实验表明，相较于现有基准方法，MrGuard在多种语言环境中表现出色，特别是在跨领域语言上超过15%的提升，并且在对抗多语言变体（如代码转换和低资源语言提示干扰）时，依然能保持安全判断的准确性。", "conclusion": "该研究开发的MrGuard多语言护栏在多种语言环境下的实验结果中表现出色，具有显著的优越性，并在保持通用性的同时，还能生成解释说明，有助于理解多语言内容审核方面的语言特定风险和模糊性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12300", "html_url": "https://arxiv.org/abs/2505.12300", "title": "HBO: 嵌套平衡优化方法在大规模语言模型微调中的应用", "title_en": "HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models", "authors": "Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch", "background": "在对大规模语言模型（LLMs）进行微调时，使用多种多样化的数据集并存的混合数据集会带来数据不平衡和异质性的问题。现有的方法通常仅在数据集之间（全局）解决这些问题，而忽略了每个独立数据集内部的不平衡和异质性（局部），这限制了它们的效果。因此，需要一种能够同时在全局和局部调整数据分配的方法，以解决这些问题，从而实现更有效的模型训练。", "innovation": "本文提出了嵌套平衡优化（HBO）方法，这是一种新的方法，能够在微调期间（全局和局部）自主调整数据分配。HBO采用了双层优化策略，包括全局演员（负责在不同训练混合子集间平衡数据采样）和多个局部演员（根据难度级别优化每个子集内的数据利用）。这些演员由LLM训练状态衍生的奖励函数引导，以衡量学习进展和相对性能提升。该方法在三种LLM基础模型上通过九个多种语言和多任务设置进行评估，结果显示HBO始终优于现有基线，取得了显著的准确率提升。", "conclusion": "HBO为LLM微调中的数据不平衡和异质性挑战提供了全面的解决方案，使得在多种数据集中的训练更有效。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11480", "html_url": "https://arxiv.org/abs/2505.11480", "title": "SuperCoder: 使用大型语言模型进行汇编程序超优化", "title_en": "SuperCoder: Assembly Program Superoptimization with Large Language Models", "authors": "Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken", "background": "超优化是指将程序转换为更快的版本，同时维持其输入输出行为。本文研究了大型语言模型（LLMs）是否可以作为超优化工具，在行业标准编译器优化后的代码上生成更快速的汇编程序。提出了一项包含8,072个实际汇编程序的新基准，这些程序平均每条130行，对比之前仅包含2-15行无循环程序的数据集，显示出更广泛的应用前景。对此基准，评估了23种不同的LLM，发现基础模型Claude-opus-4达到51.5%的正确率及1.43倍的平均加速效果。为进一步提升性能，通过强化学习微调模型，依据结合正确性和性能增益的奖励函数进行优化。从Qwen2.5-Coder-7B-Instruct（61.4%正确率，1.10倍加速）开始，微调后的SuperCoder模型实现了95.0%的正确率及1.46倍的平均加速效果。", "innovation": "首次将大型语言模型应用于汇编程序的超优化，为未来的程序性能优化研究奠定了基础，扩展了超优化工具的应用范围。通过构建大型规模基准以及结合强化学习的模型微调策略，大幅提升了生成优化汇编代码的准确性和性能增益。", "conclusion": "本文结果证明了大型语言模型可以作为汇编程序的超优化工具，未来有望在程序性能优化领域替代现有编译器启发式方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16134", "html_url": "https://arxiv.org/abs/2505.16134", "title": "多语言大语言模型中位置偏见的模型特定性和语言特定性效应超越了早期标记偏见", "title_en": "Beyond Early-Token Bias: Model-Specific and Language-Specific Position Effects in Multilingual LLMs", "authors": "Mikhail Menschikov,Alexander Kharitonov,Maiia Kotyga,Vadim Porvatov,Anna Zhukovskaya,David Kagramanyan,Egor Shvetsov,Evgeny Burnaev", "background": "大型语言模型（LLMs）表现出位置偏见——一种系统地忽略特定上下文位置信息的趋势。然而，位置偏见行为的模式，取决于语言或模型，尚未得到充分探索。这项研究在五个典型不同的语言（英语、俄语、德语、印地语和越南语）和五个模型架构中进行了多语言研究，以探索位置偏见如何与提示策略相互作用并影响输出熵。", "innovation": "这项研究首次在一个多语言背景下探索大型语言模型的位置偏见行为，揭示了位置偏见主要是由模型驱动的，但在不同语言中表现出特定变体。此外，研究表明“上下文与查询相关”的显式指令意外地降低了多语言背景下的准确性，挑战了普遍认为的大语言模型早期标记偏见的假设。", "conclusion": "研究发现位置偏见的主要模式是由模型驱动的，但表现出语言特定的变化。最大的准确度下降发生在相关信息位于上下文中间时，但这并没有直接反映在输出熵的峰值上。此外，固定指令使得模型关注上下文相关性的做法在多语言环境中效果不佳，这挑战了常见的提示工程实践。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16965", "html_url": "https://arxiv.org/abs/2505.16965", "title": "BP-Seg：使用信念传播的图形模型方法进行无监督和非连续文本分段", "title_en": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation", "authors": "Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz", "background": "文本分段基于句子的语义意义是一项基础任务，广泛应用于许多下游应用程序。现有的方法可能仅关注局部一致性，而未能有效分组在文本中距离较远但语义上相似的句子。", "innovation": "本文提出了一种基于图形模型的无监督学习方法，称为BP-Seg，该方法不仅考虑了局部一致性，即相邻句子往往更加相关，还通过精心构建的图形模型上的信念传播有效分组了在文本中距离较远但语义上相似的句子。", "conclusion": "在示例和长文档数据集上的实验结果表明，本方法在性能上优于竞争对手的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16831", "html_url": "https://arxiv.org/abs/2505.16831", "title": "卸载不是删除：大型语言模型中机器卸载可逆性的调查", "title_en": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", "authors": "Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu", "background": "当前，大型语言模型（LLMs）中的卸载目标是移除指定的数据，但这种操作的效果通常会通过任务级别的度量标准如准确率和困惑度来评估。然而，这些度量标准有很多误导性之处，模型可能看似忘记了特定信息，而这些信息可以通过少量微调轻易恢复，这表明信息仅仅是被抑制了，而不是被真正抹去。因此，研究者发现了一个名为可逆性的现象，指出信息可能被掩藏而不是被删除。", "innovation": "为解决这一关键性评估缺口，本文引入了一种基于表示的分析框架。该工具包包括基于PCA的相似性和位移、中心核对齐(CKA)、费舍尔信息，以及通过平均PCA距离来度量表示漂移的总结度量。通过在六种卸载方法、三个数据领域和两个LLM中应用这一框架，本文根据其可逆性和灾难性识别出四种不同的遗忘模式。研究发现实现理想的不可逆且非灾难性的遗忘是非常具挑战性的，通过探索卸载的极限，本文发现了一个看似不可逆但针对性的遗忘案例，为设计更健壮的遗忘算法提供了新的见解。", "conclusion": "本文的分析揭示了当前评价实践中的基本缺口，并建立了表示级别的基本框架，用于构建值得信赖的卸载。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11739", "html_url": "https://arxiv.org/abs/2505.11739", "title": "ZeroTuning: 充分发挥初始标记的力量以不经过训练提高大型语言模型性能", "title_en": "ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training", "authors": "Feijiang Han,Xiaodong Yu,Jianheng Tang,Delip Rao,Weihua Du,Lyle Ungar", "background": "Token-level attention tuning，如Post-hoc Attention Steering (PASTA)和Attention Calibration (ACT)等训练-free方法，旨在通过可解释的干预提升冻结的语言模型。它们依赖于辅助启发式方法来识别“重要”的任务特定标记，这在标记重要性不明确或使用优化内核时可能导致偏见并限制应用范围。现有方法的复杂性和对特定任务标记的依赖性限制了它们的广泛应用。因此，有必要寻找一种更简单且更加优雅的替代方法，专注于初始标记，例如LLaMA中的<BOS>标记。这种方法通过在初始标记的注意力logits中添加轻量级偏置，理论上可以单调控制下游注意力分布的熵，从而自然地提高模型的性能并使其更接近冻结时的状态。经验分析表明，这种调整过程可以有效改善LLM的性能和内容，特别是在早期层和不同注意力头之间有明显的偏好。", "innovation": "我们提出了一种名为ZeroTuning的新方法，这是一个训练-free方法，通过在初始标记上应用注意力微调，而不更新任何参数来提高LLM的性能。ZeroTuning包括两种模式：一种是在验证示例上进行校准的监督模式，另一种是直接最小化模型输出熵的新颖非监督模式。这种调整过程不需要参数更新，仅需四行代码修改即可应用于标准的LlamaAttention代码。ZeroTuning是一个轻量级且内核无关的方法，适用于从量化推理开始，并且随着上下文长度增加，仍能保持性能增益。该方法在15个数据集上表现出显著的效果，并优于先前更为复杂的改进方法。相对于LLama-3.1-8B来说，它在分类任务上提高了19.9%，在问答任务上提高了4.5%，在对话任务上提高了2.1%。", "conclusion": "ZeroTuning通过在初始标记上应用定制的注意力调整，无需任何参数更新，显著提高了大型语言模型的性能。这项简单而优雅的技术在15个不同的数据集上显示出持续的改进，展示了其作为一种全新的不训练方法的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16429", "html_url": "https://arxiv.org/abs/2505.16429", "title": "超越静态测试平台：面向动态推荐系统的以交互为中心的智能体仿真平台", "title_en": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems", "authors": "Song Jin,Juntian Zhang,Yuhan Liu,Xun Zhang,Yufei Zhang,Guojun Yin,Fei Jiang,Wei Lin,Rui Yan", "background": "推荐系统的效果评估和迭代至关重要，但传统的A/B测试资源密集，而离线方法难以应对动态的用户-平台交互。虽然基于代理的仿真很有前景，但现有的平台通常缺乏用户行为能动态重塑环境的机制。", "innovation": "本文介绍了一个名为RecInter的新型基于代理的仿真平台，该平台具有动态交互机制，模拟用户行为（如点赞、评论、购买）能在实时更新项目属性，并引入了商户代理，使生态系统更加真实和动态演化。通过多维用户画像模块、高级代理架构和基于拥有思维链（CoT）增强交互数据的LLM微调，确保了高度仿真性，并成功再现了品牌忠诚度和马太效应等涌现现象。", "conclusion": "实验表明，这种交互机制对于模拟系统的现实演化至关重要，我们的平台成为推荐系统研究的可靠测试床。我们的代码可在此查看：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11556", "html_url": "https://arxiv.org/abs/2505.11556", "title": "HiddenBench：通过隐藏配置文件任务评估多智能体LLM的集体推理", "title_en": "HiddenBench: Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks", "authors": "Yuxuan Li,Aoi Naito,Hirokazu Shirado", "background": "多智能体系统利用大型语言模型（LLMs）在分布式信息整合中展示出增强的问题解决能力，但同时也可能重现人类群体中观察到的集体推理失败。然而，缺乏理论依据的基准测试使系统难以系统地评估和改进集体推理能力。这项研究引入了第一个专门用于评估多智能体LLMs集体推理能力的基准测试——HiddenBench，该基准测试基于社会心理学中的隐藏配置文件范式。在此框架下，每个参与者持有不同信息片段，必须通过沟通来得出正确的结论。通过为该范式设计定制任务，研究者展示了GPT-4.1群体无法整合分散的知识，表现出类似人类的集体推理失败，即使采取不同的提示策略也依旧存在。接着，研究者构建了完整的基准测试，包含65个任务，这些任务来自于定制设计、先前的人类研究以及自动生成的内容，旨在评估15个不同的LLMs在四个模型系列中的表现。HiddenBench揭示了这些模型中持续存在的局限性，并提供了具有可比性的洞察：某些模型（例如Gemini-2.5-Flash/Pro）的表现优于其他模型，但规模和推理能力并不能可靠地预测更强的集体推理能力。这项研究为多智能体LLMs中的集体推理提供了首个可复现的基准评估，提供了诊断性见解和未来关于人工集体智能研究的基础。", "innovation": "该研究创新地构建了HiddenBench，这是第一个专门用于评估多智能体大型语言模型（多智能体LLMs）集体推理能力的基准测试，以社会心理学中的隐藏配置文件范式为基础。引入了定制任务详细说明该范式，并通过GPT-4.1团队的表现展示了隐藏配置文件范式与集体推理失败的相关性。基于HiddenBench，构建了包括65个任务在内的完整基准测试，涉及定制设计、先前的人类研究和自动生成功能，并进行了广泛的模型评估，揭示了多智能体LLMs在集体推理方面持续存在的局限性，以及规模和推理能力并不总是可靠预示更强集体推理能力的特性。", "conclusion": "研究工作为多智能体LLMs中的集体推理提供了首个可复现的基准测试，能够提供关于这些系统的诊断性见解和未来关于人工集体智能研究的基础。研究揭示出多智能体LLMs集体推理存在的局限性并没有直接来自于其规模和推理能力，而更多可能来自于其集体策略或协调机制的问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12716", "html_url": "https://arxiv.org/abs/2505.12716", "title": "Shadow-FT: 通过训练基础模型来调优指令模型", "title_en": "Shadow-FT: Tuning Instruct Model via Training on Paired Base Model", "authors": "Taiqiang Wu,Runming Yang,Jiayi Li,Pengfei Hu,Yik-Chung Wu,Ngai Wong,Yujiu Yang", "background": "大规模语言模型（LLMs）在各种任务上受益于进一步的微调。然而，直接调优指令（即指令微调）模型通常只能带来轻微改进，甚至可能导致性能下降。值得注意的是，这些指令变体的基础模型（Base models）具有高度相似的权重值（例如，Llama 3.1 8B的基础模型平均权重值差异仅为2%以下）。基础模型在未经后训练的情况下表现出良好的学习能力，但作为支撑框架却较弱。", "innovation": "提出了一个新的Shadow-FT框架，通过利用相应的基础模型来微调指令模型。关键思想是微调基础模型，然后直接将学习到的权重更新直接移植到指令模型上。此方法不增加额外参数，易于实现，并显著提高了性能。", "conclusion": "Shadow-FT在主流的LLM（如Qwen 3和Llama 3系列）的调优实验中，覆盖了涵盖编程、推理和数学任务的19个基准测试中，表现出色。实验结果显示Shadow-FT方法优于传统全程参数和高效参数调整方法。进一步分析表明，Shadow-FT可以应用于多模态大型语言模型（MLLMs）并结合直接偏好优化（DPO）。代码和权重已发布在Github上。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14679", "html_url": "https://arxiv.org/abs/2505.14679", "title": "UltraEdit：基于隐藏状态与梯度的一体化无训练、无主题、无内存的终身编辑方法", "title_en": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models", "authors": "Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang", "background": "大型语言模型（LLMs）能够通过不断更新其内部知识来适应不断变化的信息。理想情况下，系统应支持高效、广泛的知识更新，同时保持现有能力，确保可靠的部署。虽然最近的一些方法取得了显著进展，但在大规模持续适应实践中仍难以达到要求。", "innovation": "UltraEdit 提出了一种训练、主题和内存无关的一体化方法，适用于大规模实际应用中的模型终身编辑。这种方法通过隐藏状态及其梯度一步计算参数偏移，简化且高效。UltraEdit 通过终生归一化策略不断更新特征统计量，提高终身环境中可扩展性，确保持续性，并通过减少所需显存量来提高速度，使其成为唯一能够在 24GB 消费级显卡上编辑 7B LLM 的方法。同时，构造了迄今为止领域中最大的 UltraEditBench 数据集，包含超过 200 万个编辑对，证明此方法在大量编辑中仍能保持高准确性。", "conclusion": "UltraEdit 在五个数据集和六个模型上进行全面实验，结果显示在多种模型编辑场景中均实现优越性能，进一步向安全、可扩展的终身学习迈进。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14874", "html_url": "https://arxiv.org/abs/2505.14874", "title": "包容性ASR：非资源语言中嗓音转换在构音障碍语音识别中的研究", "title_en": "Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages", "authors": "Chin-Jou Li,Eunjung Yeo,Kwanghee Choi,Paula Andrea Pérez-Toro,Masao Someki,Rohan Kumar Das,Zhengjun Yue,Juan Rafael Orozco-Arroyave,Elmar Nöth,David R. Mortensen", "background": "由于数据稀缺，特别是非英语语言，构音障碍者的自动语音识别（ASR）仍然是一项挑战。为了应对这一挑战，研究人员在英语构音障碍语音数据上微调语音转换模型，将其应用于将健康非英语语音转换为类似构音障碍的语音，然后使用生成的数据微调多语言ASR模型Massively Multilingual Speech (MMS)，以提高构音障碍语音识别的准确性。", "innovation": "该研究的创新之处在于采用了结合说话人和语调转换的语音转换策略，生成用于训练ASR模型的数据，比现有模型和传统数据增强技术有显著提升。", "conclusion": "通过在PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）上的评估，该研究证明了结合说话人和语调转换的语音转换方法在非资源语言中进行构音障碍语音识别上的优越性，并通过客观和主观分析进一步验证了生成语音的真实性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15674", "html_url": "https://arxiv.org/abs/2505.15674", "title": "UniErase：实现语言模型中的平衡精确去学习", "title_en": "UniErase: Towards Balanced and Precise Unlearning in Language Models", "authors": "Miao Yu,Liang Lin,Guibin Zhang,Xinfeng Li,Junfeng Fang,Xingrui Yu,Ivor Tsang,Ningyu Zhang,Kun Wang,Yang Wang", "background": "大型语言模型（LLMs）需要迭代更新来解决过时信息问题，而LLM去学习提供了有针对性的移除方法。主流的去学习方法主要依赖于微调技术，这些方法在目标去学习的精确度上往往不够，并且难以在大规模和序列设置中平衡去学习效果与通用能力。", "innovation": "本文介绍了UniErase，这是一种新型的去学习框架，能够在知识去学习和能力保留之间实现精确实用的平衡。通过提出去学习标记和轻量去学习编辑，UniErase能够在虚构和真实世界的知识场景中，在批量、序列和精确去学习任务中取得卓越表现。UniErase在TOFU基准测试中，相对于8个基线，仅修改约3.66%的LLM参数，便在模型能力上优于之前的最佳去学习基线约4.01倍，并且在去学习效率上也超过了之前最佳保留方法的35.96%，展示出了当前去学习社区中平衡和双重顶级性能的新框架.", "conclusion": "UniErase在批量、序列和精确去学习任务中展示了卓越的性能，特别是在记忆去学习和能力保持之间取得了平衡效果。相比于现有基线，UniErase仅修改少量参数，即在模型能力上取得了显著提升，展示了其在去学习领域中的优越表现。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16415", "html_url": "https://arxiv.org/abs/2505.16415", "title": "响应归因：检索增强生成中上下文归因的杰森-香农发散驱动机制研究", "title_en": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation", "authors": "Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz", "background": "检索增强生成（RAG）利用大型语言模型（LLMs）和外部上下文来提高生成响应的准确性和可靠性。然而，可靠地将生成的内容归因于特定的上下文片段（即上下文归因）仍然具有挑战性，因为当前的方法往往需要大量的微调或人工注释，这在计算上非常密集。因此，如何有效地、准确地识别对生成内容影响最大的上下文句子成为了一个亟待解决的问题。", "innovation": "该论文提出了一种基于杰森-香农发散（JSD）的新方法，称为ARC-JSD，可以不依赖额外的微调、梯度计算或代理模型，实现对上下文句子的有效和准确识别。与之前的代理模型驱动的方法相比，该方法在TyDi QA、Hotpot QA和Musique等多个RAG基准上的评估显示出了更高的准确性和显著的计算效率提升。此外，通过机械分析还发现了特定的注意头和多层感知机（MLP）层对于上下文归因的重要性，为RAG模型的内部工作原理提供了有价值的理解。", "conclusion": "本文提出了一个新型的方法——基于杰森-香农发散驱动的响应归因方法（ARC-JSD），不仅实现了对上下文句子的有效归因，而且提高了计算效率，同时通过对特定层的重要性分析，增添了对RAG模型工作原理的深入理解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01042", "html_url": "https://arxiv.org/abs/2506.01042", "title": "探究大型语言模型的神经拓扑结构", "title_en": "Probing Neural Topology of Large Language Models", "authors": "Yu Zheng,Yuan Yuan,Yue Zhuo,Yong Li,Paolo Santi", "background": "通过将神经激活与可解释的语义联系起来，对大型语言模型（LLMs）进行探查已经揭示了它们内部机制的宝贵见解。然而，连接神经元的功能共激活与模型能力的涌现机制仍然复杂且不为人所知，阻碍了对LLMs的更深入理解和更安全的发展。因此，需要一种方法来揭示LLMs神经元的功能连接，并将其与语言生成性能相关联。", "innovation": "本研究引入了一种名为图探查的方法，以揭示LLMs神经元的功能连接并将其与语言生成性能相关联。研究发现在保留仅有1%神经元连接时，仅使用神经拓扑结构来预测下一个词的性能是普遍可预测的。仅通过拓扑探查比通过激活探查在某些情况下性能高出130.4%，这表明神经拓扑结构比神经激活包含了更丰富的模型性能信息，可以使用简单的线性或MLP探查器来轻松提取。", "conclusion": "通过对多种LLM进行模型修剪、幻觉检测和模型指纹识别等概念验证应用，证明了可以有效利用神经拓扑结构提高LLMs的效率、可靠性和安全性。有关图探查工具箱的代码和数据可在指定网址获取。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20321", "html_url": "https://arxiv.org/abs/2505.20321", "title": "BiomedSQL: 文本到SQL在生物医学知识库中的科学推理", "title_en": "BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases", "authors": "Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri", "background": "生物医学研究人员越来越依赖大规模结构化数据库进行复杂的分析任务。然而，当前的文本到SQL系统在将质性的科学问题转换为可执行的SQL查询时常常遇到困难，尤其是在需要隐含领域推理的情况下。现有的系统往往依赖于简单的语法转换，而忽略了实际的领域知识和推理过程。", "innovation": "论文提出了BiomedSQL，这是第一个专门用于评估文本到SQL生成过程中科学推理能力的基准，适用于真实的生物医学知识库。BiomedSQL基准包含68,000个问题/SQL查询/答案三元组，基于一个整合了基因疾病关联、组学数据因果推断和药物批准记录的大规模集成数据库。该基准强调了模型必须进行隐含的领域推理，而不仅仅是依赖于语法转换。", "conclusion": "我们的实验结果显示，最先进的模型性能仍然很低，其中GPT-o3-mini的执行准确率仅为59.0%，而我们的自定义多步骤代理BMSQL的准确率为62.6%，均远低于专家基准的90.0%。BiomedSQL提供了一个支持通过严密的结构化生物医学知识库支持科学发现的新基准。数据集和代码均公开提供。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08123", "html_url": "https://arxiv.org/abs/2506.08123", "title": "QA-LIGN: 通过宪法分解的问答对LLMs进行对准", "title_en": "QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA", "authors": "Jacob Dineen,Aswin RRV,Qin Liu,Zhikun Xu,Xiao Ye,Ming Shen,Zhaonan Li,Shijie Lu,Chitta Baral,Muhao Chen,Ben Zhou", "background": "现有的大型语言模型（LLMs）对齐，通常依赖于模糊的标量奖励信号，这使得难以明确识别模型训练中所依据的具体目标。本文介绍了一种名为QA-LIGN的方法，该方法通过结构化的自然语言程序将单一的奖励系统分解为可解释的原则特定评估，从而让模型在迭代过程中获得透明的反馈。", "innovation": "QA-LIGN提出了一个新的方法，通过将单一的奖励系统分解为多个原则特定的评估，利用结构化的自然语言程序来分解和解释奖励信号。这种方法可以让模型在训练过程中通过草稿、批评和修订的循环，获得透明的反馈，并且在这种反馈机制下，模型能够更好地遵循预定义的原则，如实用性、诚实性和无害性。", "conclusion": "QA-LIGN在对uncensored Llama-3.1-8B-Instruct进行测试时，成功地降低了攻击成功率68.7%，同时保持了0.67%的拒绝错误率。这种结果表明，使奖励信号变得更透明和模块化能够提升对齐的有效性，透明度是提高大型语言模型（LLMs）安全性的一个重要因素。同时，QA-LIGN的表现优于DPO和GRPO方法，尤其是在具有先进奖励模型的情况下，尤其是达到帕累托最优的安全-辅助性表现。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23297", "html_url": "https://arxiv.org/abs/2505.23297", "title": "EmoBench-UA: 用于乌克兰语情感检测的基准数据集", "title_en": "EmoBench-UA: A Benchmark Dataset for Emotion Detection in Ukrainian", "authors": "Daryna Dementieva,Nikolay Babakov,Alexander Fraser", "background": "尽管乌克兰自然语言处理(NLP)在许多文本处理任务上已经取得了进步，但在情感分类方面仍是一个未充分探索的领域，目前没有公开可用的基准数据集。本文通过引入 EmoBench-UA，即首个用于乌克兰语情感检测的标注数据集，来填补这一空白。情感标注方案基于之前以英语为主的有关情感检测的研究（Mohammad等，2018；Mohammad, 2022）。该数据集通过众包使用平台进行创建，确保了标注过程的高质量。", "innovation": "提出了EmoBench-UA，首个用于乌克兰语情感检测的标注数据集。该数据集的创建采用了众包方式，并由CrowdFlower平台确保了高质量的标注过程。通过涵盖从基于语言的基础方法、从英语合成数据到大型语言模型的广泛方法进行评估，揭示了非主流语言如乌克兰语的情感分类挑战，强调了乌克兰语特定模型和训练资源进一步发展的必要性。", "conclusion": "研究发现，感觉分类在乌克兰这样非主流语言上存在挑战，需要进一步开发乌克兰语特定模型和培训资源。EmoBench-UA将成为未来研究和开发的基础数据集，有助于提升乌克兰语情感分析技术。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17117", "html_url": "https://arxiv.org/abs/2505.17117", "title": "从标记到思维：LLMs和人类如何在压缩与意义之间权衡", "title_en": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning", "authors": "Chen Shani,Liron Soffer,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv", "background": "人类将知识组织成紧凑的分类，以平衡压缩和语义意义的保留。大型语言模型（LLMs）展示了显著的语言能力，但它们是否达到同样的平衡还不清楚。本文使用信息瓶颈原理来定量比较LLMs和人类如何在压缩与意义之间权衡。\n", "innovation": "研究利用信息瓶颈原则对40多种LLMs的嵌入与经典的人类分类基准进行分析，揭示了三个主要发现。首先，LLMs总体上与人类的分类一致，但缺少对人类理解至关重要的细微语义区别。其次，LLMs表现出激进的统计压缩，达到信息论上的最优效率，而人类则强调上下文丰富性和适应性灵活性。第三，编码模型在人类一致性方面出乎意料地优于解码模型，表明当前架构中生成和理解依赖于不同的机制。此外，训练动力学分析揭示了概念结构的发展阶段：初期快速形成，随后是架构重组，随着模型发现更高效的编码，语义处理从深层网络迁移到中期网络层。\n", "conclusion": "这些差异化的策略展示了人工智能和生物智能之间的基本差异，指导了人工智能朝着更接近人类的方向发展。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19660", "html_url": "https://arxiv.org/abs/2505.19660", "title": "充分提示还不够：在大型语言模型中探究知识融合与可控生成", "title_en": "Prompting is not Enough: Exploring Knowledge Integration and Controllable Generation on Large Language Models", "authors": "Tingjia Shen,Hao Wang,Chuan Qin,Ruijun Sun,Yang Song,Defu Lian,Hengshu Zhu,Enhong Chen", "background": "开放域问答（OpenQA）是自然语言处理（NLP）中的一个基石，主要在于从非结构化文本数据中提取答案。随着大型语言模型（LLMs）的快速发展，基于LLM的OpenQA方法因其大规模参数所带来的理解能力和回答能力而受益，相比传统方法。然而，大多数方法在如何有效整合知识到LLMs以及如何在不同任务情况下自适应生成特定格式答案格式的过程中遇到了两大关键挑战。", "innovation": "本文提出了一个名为GenKI的新框架，旨在通过同时探索LLMs中的知识整合和可控生成来提升OpenQA性能。具体而言，作者首先训练了一个密集段落检索模型来从给定的知识库中检索相关知识。随后，引入了一种新的知识融合模型，该模型在微调过程中将检索到的知识整合到指令中，以增强模型。此外，利用特定微调的LLM和基于文本一致性（包括连贯性、流畅性和答案格式保证）的集成，实现可控生成。通过在多个含有不同答案格式的数据集上进行的广泛实验，表明了GenKI的有效性，并且消融研究表明检索知识的频率与模型准确再现知识的能力之间存在线性关系。", "conclusion": "通过广泛的实验，确认了GenKI的有效性，并揭示了检索知识频率与模型准确再现知识能力之间的线性关系。最后，GenKI的代码已经发布。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23867", "html_url": "https://arxiv.org/abs/2505.23867", "title": "InfiMed: 低资源医疗多模态大语言模型理解与推理", "title_en": "InfiMed: Low-Resource Medical MLLMs with Advancing Understanding and Reasoning", "authors": "Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大型语言模型（MLLMs）在视觉理解和数学推理等领域的应用取得了显著进展。然而，在医疗领域中的应用受到两大关键挑战的限制：一是医疗领域中的多模态数据稀缺且通常包含稀疏信息，限制了推理深度；二是虽然在一般领域中的强化学习与可验证奖励（RLVR）取得了有效成果，但在医疗领域中却无法可靠地提升模型性能。", "innovation": "本文通过在监督微调（SFT）阶段结合高质量的文本推理数据和通用多模态数据，以及包含反映模式注入的思考链（CoT）的多重数据，有效提升了基础的医疗能力并恢复了基础模型的推理能力。此外，两种新模型InfiMed-SFT-3B和InfiMed-RL-3B表现出色，尤其是在七个多模态医疗基准测试中表现突出。InfiMed-RL-3B在准确率方面达到了59.2%，超越了具有8B参数的InternVL3-8B，得分为57.3%。", "conclusion": "通过上述两种训练策略的有效使用，展示了其对多模态医疗大语言模型性能提升的有效性，并通过一系列广泛的实验提供了宝贵见解，有助于进一步提高医疗场景下MLLMs的表现。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23508", "html_url": "https://arxiv.org/abs/2506.23508", "title": "为什么强化微调使多模态大语言模型能够更好地保留先验知识：从数据的角度来看", "title_en": "Why Reinforcement Fine-Tuning Enables MLLMs Preserve Prior Knowledge Better: A Data Perspective", "authors": "Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Mingqi Wu,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang,Kai Chen", "background": "现有的后训练算法，如监督微调（SFT）和强化微调（RFT），常用于使多模态大型语言模型适应下游任务。尽管这些方法在任务适应方面表现出色，但它们对先验知识的影响仍然未知。", "innovation": "研究引入了拼图作为新任务，该任务不在现有预训练语料库中出现，并系统研究了SFT和RFT在开源多模态模型Qwen2.5-VL系列上的行为。实验揭示了一个明显的权衡：SFT能够快速学习新任务但会导致灾难性遗忘，而RFT虽然学习速度较慢但能够保留先验知识。", "conclusion": "研究表明，训练数据的分布而不是算法差异在遗忘过程中起着核心作用，强化微调具有在多模态大语言模型中实现稳定持续学习的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.04504", "html_url": "https://arxiv.org/abs/2507.04504", "title": "揭示扩散大语言模型在可控生成中的潜力", "title_en": "Unveiling the Potential of Diffusion Large Language Model in Controllable Generation", "authors": "Zhen Xiong,Yujun Cai,Zhecheng Li,Yiwei Wang", "background": "在自然语言处理（NLP）中，可控生成是一个基本任务，具有多种应用，可以为基础的函数调用提供智能通讯的基础。然而，即使是最先进的自回归大语言模型（LLM）今天在生成结构化输出时也表现出不可靠性。差分扩散大语言模型（dLLM）当前的新架构，特别是语言建模中的全局信息共享机制，可能是解锁更高水平可控生成的关键。", "innovation": "我们提出了自我适应框架（$S^3$）作为新的框架，利用dLLM的内在逆向推理能力和全局上下文意识来稳定地生成可靠的结构化输出（如JSON）。这种方法比复杂的提示优化更稳健和通用。", "conclusion": "我们的实验表明，该方法在结构一致性、内容准确性和忠实性方面显著地解锁了dLLM在可控生成任务中的潜力。这些结果为部署语言模型在可控生成任务中提供了新的视角和实用路径。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23621", "html_url": "https://arxiv.org/abs/2505.23621", "title": "Table-R1: 在表推理中的推理时扩展", "title_en": "Table-R1: Inference-Time Scaling for Table Reasoning", "authors": "Zheyuan Yang,Lyuhao Chen,Arman Cohan,Yilun Zhao", "background": "当前的研究主要集中在如何在表推理任务中实现推理时间的可扩展性。以往的研究尚未深入探讨此问题，因此开发新的策略来解决这一挑战非常重要。本文介绍了一种初步的研究方法，旨在探索表推理任务中的推理时间可扩展性。作者提出了两种后训练策略，分别基于知识蒸馏和强化学习可验证奖励，来实现推理时间上的可扩展性。这些方法的实施依赖于特定于任务的可验证奖励函数和特定模型架构的选择。研究者利用DeepSeek-R1生成了大量的推理追踪数据集，对大语言模型进行微调，开发了Table-R1-SFT模型。同时，他们还采用强化学习算法GRPO，开发了Table-R1-Zero模型，该模型在特定任务上的表现超过了GPT-4.1和DeepSeek-R1，仅使用了一个7B参数的大语言模型。实验结果表明，这种方法在跨任务泛化方面表现良好，并且可以通过强化学习培训过程中新兴的重要表推理技能来获得更好的结果。研究展示了各种表推理任务，包括简答题、事实核实和自由形式问答等。", "innovation": "本文创新性地提出了两种后训练策略来实现表推理任务中的推理时间扩展：知识蒸馏（Distillation）和强化学习可验证奖励（RLVR）。知识蒸馏通过利用大规模推理跟踪数据集（如DeepSeek-R1生成的数据集）来微调大语言模型；强化学习部分则采用了特定任务的可验证奖励函数并通过GRPO算法来开发了Table-R1-Zero模型。这些方法使得通过较小的参数量的模型，在进行推理时能够维持或超越更大的模型（如GPT-4.1和DeepSeek-R1）的性能。并且，新模型还能很好地泛化到域外数据集。", "conclusion": "本文通过开发和评估两种新的后训练策略，成功实现了推理时间的可扩展性。研究结果显示，通过知识蒸馏的方法可以生成一个性能优秀的Table-R1-SFT模型，而通过强化学习的方法可以产生一个具有强泛化能力的Table-R1-Zero模型。这些模型不仅在表推理任务上展示了卓越的表现，还具备良好的跨任务泛化能力，表明在强化学习训练过程中新兴的技能对表推理任务有着重要的辅助作用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05154", "html_url": "https://arxiv.org/abs/2506.05154", "title": "RAG通过参数化知识强化学习抵制上下文干扰", "title_en": "Resisting Contextual Interference in RAG via Parametric-Knowledge Reinforcement", "authors": "Chenyu Lin,Yilin Wen,Du Su,Hexiang Tan,Fei Sun,Muhan Chen,Chenfu Bao,Zhonghou Lyu", "background": "检索增强生成（RAG）在知识密集型任务中表现出色，但检索到不相关、错误或矛盾的文本可能导致模型依赖不准确的证据并对推理造成负面影响。现有的RAG模型在应对知识冲突和一般RAG场景时表现出脆弱性，需要改进以增强其鲁棒性和准确性。", "innovation": "提出了一个名为Knowledgeable-R1的强化学习框架，旨在在使用参数化知识（PK）化解上下文干扰时，依然有效利用外部上下文，特别是在信息可靠的条件下。该框架通过联合采样方案生成带有和不带有检索结果的成对响应，并学习局部优势和全局优势来量化何时忽略误导性上下文、何时采用它。此外，引入了不对称优势转换，强化了向参数化知识探索的行为。实验表明，Knowledgeable-R1在知识冲突场景和一般RAG场景中显著增强了鲁棒性和推理准确性，且在假设检索上下文完全有效的情况下，未表现出性能退化。该方法在假设情境中表现优于最先进的基线，提升幅度达23%。", "conclusion": "实验结果显示，Knowledgeable-R1显著提升了RAG在知识冲突和一般场景中的鲁棒性和推理准确性，较SOTA基线在假设情境中提高了23%的性能，并且在检索上下文完全有效时保持了性能。该方法已公布其代码。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00789", "html_url": "https://arxiv.org/abs/2506.00789", "title": "RARE: 从检索增强生成系统的视角出发的检索感知鲁棒性评估", "title_en": "RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems", "authors": "Yixiao Zeng,Tianyu Cao,Danqing Wang,Xinran Zhao,Zimeng Qiu,Morteza Ziyadi,Tongshuang Wu,Lei Li", "background": "当前的检索增强生成（RAG）系统虽然在答案的时效性和事实准确性方面表现出色，但很少有评估测试它们在面对真实世界噪声、内部和外部检索上下文之间的冲突或快速变化的事实时的表现。现有的评估方法未能全面模拟实际应用中的挑战性情况，因此需要一个新的框架来系统地测试这些系统的鲁棒性。因此，作者提出了一个名为RARE（Retroponential Awareness of Retrieval Evaluation）的统一框架和大规模基准，通过动态、时效性强的语料库对查询和文档扰动进行联合压力测试。RARE利用知识图谱驱动的合成流水线（RARE-Get）自动从定制语料库中提取单一和多跳关系，并生成多级别问题集，无需人工干预。这使得RARE能够从527份专家级时间敏感的金融、经济学和政策文档中构建一个包含48295个问题的数据集，这些问题随着底层源的变化而发生变化。", "innovation": "RARE在以下方面提出了创新：1）它创建了一个知识图谱驱动的合成流水线，用于自动提取单一和多跳关系，并生成多级问题集。2）它构建了一个大规模的时间敏感的专家级文档和多级别问题集的数据集。3）它定义了一组条件检索下的鲁棒性度量（RARE-Met），可以量化模型在面对查询、文档或实际检索结果的系统变化时保持正确或恢复的能力。4）它的框架能全面评估RAG系统的鲁棒性，特别关注它们在多跳查询中的表现，显示了RAG系统在处理复杂查询时存在鲁棒性不足的特性。", "conclusion": "研究结果表明，RAG系统对扰动异常敏感，特别是在处理复杂的多跳查询时表现出较低的鲁棒性。作者建议，未来的RAG系统应增强它们处理复杂查询和变化信息的能力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12109", "html_url": "https://arxiv.org/abs/2506.12109", "title": "通过对比个人偏好实现个性化的大语言模型解码", "title_en": "Personalized LLM Decoding via Contrasting Personal Preference", "authors": "Hyungjune Bu,Chanjoo Jung,Minjae Kang,Jaehyung Kim", "background": "随着大语言模型（LLMs）在各种实际应用中的逐渐部署，个性化LLMs变得越来越重要。虽然已经探索了诸如基于提示和基于训练的方法等多种LLM个性化方法，但在解码时间上的有效算法开发仍然被忽视，尽管它们具有巨大的潜力。在进行参数高效微调（PEFT）后，我们提出了CoPe（Contrasting Personal Preference）作为一种新的解码时间方法。", "innovation": "我们提出了一种名为CoPe的新颖解码时间方法，该方法在对特定用户数据进行参数高效微调（PEFT）之后应用。CoPe的核心思想是利用奖励引导的解码来实现个性化，通过最大化用户的隐式奖励信号。我们在五个开放式个性化文本生成任务上评估了CoPe，实验证明，CoPe在ROUGE-L上提高了平均10.57%的个性化性能，同时不依赖于外部奖励模型或其他额外训练程序。", "conclusion": "我们的实证结果表明，CoPe在五个开放式个性化文本生成任务中表现出色，其个性化性能平均提高了10.57%的ROUGE-L分数，且无需依赖外部奖励模型或额外的训练程序。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08799", "html_url": "https://arxiv.org/abs/2507.08799", "title": "KV 缓存引导以控制冻结的大语言模型", "title_en": "KV Cache Steering for Controlling Frozen LLMs", "authors": "Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,James R. Glass,Cees G. M. Snoek,Yuki M. Asano", "background": "当前，语言模型的推理过程往往是隐式的，难以控制其推理方式。研究者提出了一种新的方法，通过一次性的干预直接调整语言模型的键值缓存，使其在不需要微调和提示修改的情况下进行显式的多步推理，有效控制模型的行为。", "innovation": "提出了一种名为cache steering的方法，能够通过一次性的干预直接对语言模型的键值缓存进行调整，从而引导模型进行链式推理。这种方法通过从教师模型或现有的人类注释中构建引导向量来改变模型的行为。与现有的激活引导技术相比，该方法具有更高的推理延迟、超参数稳定性和更容易与现有推理API集成等优势。", "conclusion": "实验表明，cache steering方法不仅可以改善模型推理的质量结构和任务表现，而且可以应用于更大的模型，并在挑战性数据集GPQA和MATH上取得进一步的提升。此外，该方法还可实现推理风格的可控转移，成为一种实用的行为级引导语言模型的工具。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21875", "html_url": "https://arxiv.org/abs/2506.21875", "title": "WildSpeech-Bench: Benchmarking End-to-End SpeechLLMs in the Wild", "title_en": "WildSpeech-Bench: Benchmarking End-to-End SpeechLLMs in the Wild", "authors": "Linhao Zhang,Jian Zhang,Bokai Lei,Chuhan Wu,Aiwei Liu,Wei Jia,Xiao Zhou", "background": "最近的多模态大型语言模型（LLMs），如GPT-4o，展示了强大的直接语音交互能力。然而，缺乏专门且全面的基准测试来评估端到端语音LLMs，阻碍了在实际应用中优化语音LLMs用户体验。现有的评估方法通常采用基于文本的基准，未能充分考虑语音的独特特性和挑战，如语调、同音词、口吃和不同用户期望。因此，研究者们需要一个新的全面基准来系统地评估端到端语音LLMs在实际语音对话中的性能。", "innovation": "本文引入了第一个全面的基准，用于系统地评估端到端语音LLMs在实际语音对话中的性能。该基准包括真实世界的聊天数据，展示了各种讲者属性和声学条件，并且增加了特定于语音的现象。进一步设计了一个查询感知的评估方法，使用定制的评估检查清单和提示，增强了自动评估的准确性。对多种主流语音模型进行了全面测试和详细分析，揭示了不同语音场景下模型性能的显著差异，并且查询感知评估方法使在多种特定语音场景下进行精细评估成为可能。", "conclusion": "该基准可以为语音模型开发和评估提供有价值的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17046", "html_url": "https://arxiv.org/abs/2506.17046", "title": "MUCAR: 评估多模态跨模态歧义解析的多模态大型语言模型基准", "title_en": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "authors": "Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu", "background": "多模态大型语言模型（MLLMs）在过去几年中在各种视觉语言任务中取得了显著进步。这些模型展示了在视觉和文本模态之间对齐的潜力，能够处理具有明确和显明含义的图像-文本对。然而，对于真实世界语言和视觉背景中的固有歧义，它们仍存在挑战。现有的多模态基准通常忽略了语言和视觉的歧义性，主要依靠单模态上下文进行消歧，从而未能充分利用模态间互补的澄清能力。鉴于此，提出了MUCAR，这是一种旨在评估多模态歧义解析的新型基准。MUCAR包含一个针对多语言环境和跨模态场景的歧义数据集，并系统地配对了具有歧义的图像与语言表达，通过互补的消歧能力，每个组合都能促成单一的清晰解释。", "innovation": "MUCAR是专门为评估多模态大型语言模型的多模态歧义解析而设计的新基准。它包含一个具有多语言歧义表达的视觉背景数据集以及一个系统地配对具有歧义的图像和语言表达的双重歧义数据集，每个组合都能通过互补的消歧能力获得单一清晰的解释。初步评估表明，当前最先进的多模态模型在MUCAR上与人类水平的性能有较大差距，强调了进一步研究更复杂跨模态歧义理解方法的必要性，以进一步推动多模态推理边界。", "conclusion": "本研究通过MUCAR指出，多模态大型语言模型在处理真实世界中的语言和视觉多样性方面仍然有很多空间，需要进一步深入研究以提高跨模态歧义理解能力。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.18578", "html_url": "https://arxiv.org/abs/2507.18578", "title": "Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs", "title_en": "Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs", "authors": "Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao", "background": "Diffusion Large Language Models (DLLMs)提供了与自回归模型相比快速并行生成的替代方案，但现有DLLMs面临严重的质量和速度权衡问题，即更快的并行解码会导致性能大幅下降，这归因于标准DLLMs解码的不可逆性，容易导致错误方向的累积和早期错误上下文误判。", "innovation": "引入了Wide-In, Narrow-Out (WINO)解码算法，这是一种无需训练的算法，可以实现DLLMs中的可撤销解码。WINO采用并行草稿验证机制，能够并行生成多个候选解码，同时利用模型的双向上下文进行验证，并重新覆盖有疑点的解码，以提高准确性。", "conclusion": "验证结果表明，WINO显著改善了DLLMs的质量与速度权衡问题。例如，在GSM8K数学基准测试中，WINO使推理加速了6倍，准确率提升了2.58%；在Flickr30K字幕生成中，其速度提升了10倍，且性能更高。进一步的实验表明WINO具有优越性，并为理解WINO提供了深入见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20923", "html_url": "https://arxiv.org/abs/2506.20923", "title": "KaLM-Embedding-V2：优越的训练技术和数据激发多功能嵌入模型", "title_en": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model", "authors": "Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Xin Zhang,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang", "background": "近期在基于大规模语言模型（LLMs）的文本嵌入模型的研究主要集中在数据的规模或合成上，而忽略了训练技术与数据质量的重要性，这限制了模型的性能。", "innovation": "本文提出了一套被称为KaLM-Embedding-V2的多功能和紧凑的嵌入模型，通过优越的训练技术和高质量的数据系统地激励LLMs的高级嵌入能力。此模型采用0.5B的紧凑架构，使用简单平均池化生成固定长度的嵌入，并移除了因果注意力掩码，以实现全双向表示学习。预训练使用弱监督的大规模数据集，微调使用监督高质量数据集，并使用对比型学科教学与细粒度的软信号相结合的方式进行训练，加入焦点式重新加权和在线混合难以否定样本来突显困难样本。模型通过特定任务指令、挖掘难以否定样本和基于示例的多类标签生成高质量的数据。这些技术结合起来，使得KaLM-Embedding-V2系列模型在大规模文本嵌入基准测试中达到了最先进的性能，优于同等规模的模型，甚至仅少于1B参数的大约3-26倍规模的模型，确立了多功能和紧凑嵌入模型的新标准。", "conclusion": "KaLM-Embedding-V2系列模型在最大量级的文本嵌入基准测试中达到了最先进的性能，优于具有相似模型参数数量的模型，并且拥有接近或超过3-26倍参数更多模型的表现，在小于1B参数的模型中设定了一项新的标准，其代码、数据和模型将被公开，以促进学术研究。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22168", "html_url": "https://arxiv.org/abs/2507.22168", "title": "基于角色增强的基准测试：评估多样化写作风格的LLMs", "title_en": "Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles", "authors": "Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu", "background": "目前用于评估大型语言模型（LLMs）的标准基准往往缺乏足够的写作风格多样性，许多基准主要遵循标准化规范，未能充分捕捉到人类丰富多样的沟通模式。这可能导致优化于这些基准的LLMs在面对非标准化输入时表现出脆弱性。", "innovation": "本文通过使用基于角色的LLMs提示方法重新编写评估提示来测试这一假设，这是一种低成本方法，旨在模拟多样的写作风格。研究结果显示，即使语义内容相同，写作风格和提示格式的差异显著影响被评估的LLM的估计性能。识别出不同的一致触发低性能或高性能的写作风格，不受模型家族、规模和更新时间的影响。", "conclusion": "本研究提出了一种可扩展的方法来扩展现有基准，提高了对各语言变异下LLM性能评估的外部有效性，为测量LLM在不同语言风格下的表现提供了改进的基准测试方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21556", "html_url": "https://arxiv.org/abs/2506.21556", "title": "VAT-KG：面向检索增强生成的知识密集型多模态知识图谱数据集", "title_en": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation", "authors": "Hyeongcheol Park,Jiyoung Seo,MinHyuk Jang,Hogun Park,Ha Dam Baek,Gyusam Chang,Hyeonsoo Im,Sangpil Kim", "background": "现有的多模态知识图谱(MMKGs)通常受限于仅能扩展现有知识图谱，导致知识范围狭窄和信息过时或不完整，且仅支持有限的模态，如文本和视觉信息。这些限制阻碍了它在多模态任务中的应用，尤其是在最近的多模态大语言模型(MLLMs)采用更丰富的模态（如视频和音频）的情况下。因此，现有的MMKGs在扩展性和信息覆盖方面存在局限性，不能满足日益丰富的多模态需求。", "innovation": "本文提出了一种名为Visual-Audio-Text Knowledge Graph (VAT-KG)的首个概念中心和知识密集型多模态知识图谱，涵盖了视觉、听觉和文本信息。通过严格的过滤和对齐步骤，VAT-KG能够跨模态地对齐数据和细粒度语义，从而自动生成MMKG。此外，VAT-KG还引入了一个新颖的多模态检索增强生成框架，能够从任意模态查询中检索详尽的概念级知识。实验表明，VAT-KG在跨模态问题回答任务中能够有效支持MLLMs，展示了其在统一和利用多模态知识方面的实际价值。", "conclusion": "实验结果表明，VAT-KG在支持MLLMs方面表现出色，并通过提供丰富和全面的多模态知识，显著增强了检索增强生成的效能。该工作为多模态知识图谱的构建和应用提供了一个新的范式。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "DAMR：LLM引导的MCTS驱动高效和自适应上下文感知知识图谱问答", "title_en": "DAMR: Efficient and Adaptive Context-Aware Knowledge Graph Question Answering with LLM-Guided MCTS", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Chao Wang,Nan Yin", "background": "知识图谱问答（KGQA）旨在通过利用知识图谱的关联和语义结构来解释自然语言查询并执行结构化推理，以检索准确的答案。现有方法主要遵循提取-推理范式，通过图神经网络或启发式规则提取静态候选路径，或者使用LLM结合提示来同时进行检索和推理的动态路径生成策略。然而，前者由于静态路径提取和缺乏上下文调整而导致不够灵活，而后者依赖于固定的评分函数和重复LLM调用，则在其准确性方面有局限性。", "innovation": "本文提出了DAMR（Dynamically Adaptive MCTS-based Reasoning），这是一种结合了LLM指导下的蒙特卡罗树搜索（MCTS）和自适应路径评估的新框架，以实现高效和上下文感知的KGQA。DAMR使用了基于MCTS的骨架结构，通过LLM规划者在每次扩展步骤中选择最相关的前k个语义关系来有效缩小搜索空间，以提高检索效率。为了提高评估准确性，引入了一个轻量级的基于Transformer的评估器，通过交叉注意力同时编码问题和关系序列来进行上下文感知的合理性估计，从而捕捉多跳推理中的细微语义变化。此外，为了缓解高质量监督数据稀缺的问题，DAMR结合了一个动态伪路径修正机制，该机制会周期性地从搜索过程中探索的部分路径中生成训练信号，使评估器能够不断适应推理轨迹概率分布的变化。", "conclusion": "在多个KGQA基准上的广泛实验表明，DAMR显著优于当前最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00344", "html_url": "https://arxiv.org/abs/2508.00344", "title": "PilotRL：通过全局规划引导渐进强化学习训练语言模型代理", "title_en": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "authors": "Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang", "background": "大语言模型（LLMs）在处理以代理为导向的任务方面取得了显著进步。然而，将LLMs部署到基于代理的环境中仍面临挑战。目前广泛应用的ReAct代理范式以单步推理与即时行动执行相结合为核心，但在需要长期策略规划的复杂任务中效果有限。此外，规划者与执行者在解决问题过程中的协调也是一个重要的代理设计因素。当前方法主要依赖于监督微调，这导致模型记忆现有的任务完成路径，当面对新颖的问题情境时，降低了其泛化能力。", "innovation": "本文提出了一种适应性全局计划代理范式AdaPlan，旨在通过与执行的协同作用来补充高层次明确指导，以支持有效长期决策。基于此原理，进一步提出了PilotRL，这是一种由逐步强化学习驱动的基于全局规划训练框架。首先开发了模型在处理代理任务时遵循全局计划中显式指导的能力。在此基础上，重点优化生成计划的质量。最终，实现了模型计划和执行协调的联合优化。实验结果表明，PilotRL可实现最新技术水平，且LLaMA3.1-8B-Instruct + PilotRL相较于封闭源码的GPT-4o具有3.60%的优势，当具备可比参数量时，相比之下GPT-4o-mini则有着55.78%的显著优势。", "conclusion": "实验证明，PilotRL能够在解决复杂任务时提供卓越的性能表现，特别是在与GPT-4o及其mini版本的对比中表现出显著的优越性。该研究提出的方法在代理设计和训练框架优化方面具有重要的创新意义，有望进一步推动LLMs在复杂环境中代理任务处理的应用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08339", "html_url": "https://arxiv.org/abs/2507.08339", "title": "金融科技领域的LLMs和RLLMs受哪些因素影响？", "title_en": "What Factors Affect LLMs and RLLMs in Financial Question Answering?", "authors": "Peng Wang,Xuesi Hu,Jiageng Wu,Yuntao Zou,Qiancheng Zhang,Dagang Li", "background": "近年来，大型语言模型（LLMs）和拥有推理能力的大型语言模型（RLLMs）受到了许多研究人员的关注。RLLMs通过长链思考（Long CoT）过程增强了LLMs的推理能力，显著提高了LLMs解决复杂问题的能力。然而，目前鲜有研究系统性地探讨哪些方法能够全面释放LLMs和RLLMs在金融科技领域的性能潜力。为研究各种方法对LLMs和RLLMs的影响，作者使用了五种LLMs和三种RLLMs，评估了提示方法、代理框架和多语言对齐方法对金融问题回答任务的影响。", "innovation": "研究表明：（1）当前的提示方法和代理框架通过模拟Long CoT来提升LLMs在金融问题回答中的性能；（2）RLLMs本身就具备Long CoT能力，这限制了传统方法进一步提高其性能的效果；（3）当前的先进多语言对齐方法主要通过扩展推理长度来改善多语言性能，这对RLLMs的益处有限。此外，作者还讨论了提升LLMs和RLLMs在金融科技领域性能的方法，这些策略可能为未来的改进提供启示。", "conclusion": "本研究旨在为金融科技领域的LLMs和RLLMs提供重要参考，并为未来的研究提供指南。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13332", "html_url": "https://arxiv.org/abs/2507.13332", "title": "模仿游戏：图灵机模仿者是长度可泛化的推理者", "title_en": "The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner", "authors": "Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Dahua Lin,Kai Chen", "background": "Transformer架构的大规模语言模型在处理较长序列的问题时存在泛化长度的能力不足的问题。目前的研究大多集中在基于数据的处理算术运算和符号操作任务的方法上，这些方法通常是针对特定任务的，整体性能有限。", "innovation": "本文提出了Turing Machine Imitation Learning (TAIL)，这是一种通过模拟图灵机执行过程来生成链式思考（CoT）数据的方法，以改善LLM的长度泛化能力。TAIL通过线性扩展推理步骤为原子状态，减轻了捷径学习，并使用具体的获取机制降低动态和长范围数据访问的难度。通过构建涵盖8类算法和18个任务的挑战性合成数据集，TAIL利用合成数据显著提升了Qwen2.5-7B在各种任务中的长度泛化能力和性能，超越了先前的方法和DeepSeek-R1。", "conclusion": "实验结果表明，对于长度泛化的学习，TAIL中图灵机的关键概念是不可或缺的。通过这种方式，模型在其注意力层中表现出与图灵机性质一致的读写行为。本研究为从合成数据学习LLM推理提供了一个有希望的方向。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05257", "html_url": "https://arxiv.org/abs/2507.05257", "title": "通过增量多轮交互评估LLM代理中的记忆", "title_en": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "authors": "Yuanzhe Hu,Yu Wang,Julian McAuley", "background": "当前对大型语言模型（LLM）代理的基准测试主要侧重于评估推理、规划和执行能力，但另一个关键组件——记忆，即代理如何存储、更新和检索长期信息——由于缺乏相应的基准测试而被忽视。现有的基准测试要么依赖于有限的上下文长度，要么针对静态的长上下文场景（如基于书籍的问答），这无法反映记忆代理的交互和多轮对话特性，后者是逐步积累信息的。此外，当前没有基准测试能够涵盖所有四种核心记忆能力。", "innovation": "本文基于记忆科学和认知科学的基本理论，识别了四种对于记忆代理至关重要的核心能力：准确检索、测试时学习、长距离理解以及选择性遗忘。作者提出了一种名为MemoryAgentBench的新基准测试，这是专门为记忆代理设计的。该基准测试将现有的长上下文数据集转变并融合新的数据集，以多轮格式模拟记忆代理的逐步信息处理特点，从而全面覆盖上述四种核心记忆能力。实验结果显示，现有方法无法掌握所有四种能力，强调了对全面记忆机制的研究需求，", "conclusion": "本文通过MemoryAgentBench基准测试，提供了一个系统且具有挑战性的评估框架，用于测试记忆质量。验证了包括简单上下文基于和检索增强生成（RAG）系统，以及具有外部记忆模块和工具集成的高级代理在内的多种记忆代理。实验结果表明，当前的方法在所有四种能力方面的掌握情况尚不充分，突出了对全面记忆机制研究的必要性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20673", "html_url": "https://arxiv.org/abs/2507.20673", "title": "几何平均策略优化", "title_en": "Geometric-Mean Policy Optimization", "authors": "Yuzhong Zhao,Yue Liu,Junpeng Liu,Jingye Chen,Xun Wu,Yaru Hao,Tengchao Lv,Shaohan Huang,Lei Cui,Qixiang Ye,Fang Wan,Furu Wei", "background": "GRPO通过优化标记级奖励的算术平均值显著增强了大型语言模型的推理能力，但当面对具有异常重要权重奖励的标记时，GRPO的策略更新表现出不稳定性的现象，具体表现为训练期间出现极端的重要性抽样比率。研究人员观察到这种问题并提出了一种新的方法来改进这一问题。", "innovation": "提出了一种新的方法，即几何平均策略优化(GMPO)，以通过减少标记奖励中的异常值来增强GRPO的策略更新的稳定性。GMPO通过最大化标记级奖励的几何平均值来优化策略，而不是算术平均值，从而使得策略优化过程更加稳定，提升性能。", "conclusion": "在多个数学推理基准测试上，GMPO-7B的表现显著优于GRPO，平均提高了4.1%的Pass@1，超过了多项最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05418", "html_url": "https://arxiv.org/abs/2507.05418", "title": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "title_en": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "authors": "Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang", "background": "大型语言模型（LLMs）在数学、事实问答和代码生成等领域的表现优异，但在不同语言下的推理能力仍然不足。特别是在少数资源的语言（如斯瓦希里语或泰语）中，LLMs 往往会误解提示或将推理默认为英语，这种隐含的高资源语言偏好降低了事实准确性、可解释性和可信度。现有跨语言基准仅评估最终答案，而忽视了推理是否发生在目标语言中。研究者提出了一种名为M2A的新方法，通过多尺度多语言对齐与基于机器翻译问题的语言一致性奖励来训练模型直接在目标语言中准确推理。此外，现有的跨语言基准仅评估最终答案，未检查推理是否发生在目标语境中，因此研究者引入了一个基于地理的多语言事实推理基准——GeoFact-X。该基准包含了五种语言：英语、印地语、日语、斯瓦希里语和泰语，展示了推理过程的痕迹。研究结果显示M2A显著提升了多语言推理在数学和事实推理任务中的准确性。这表明，关注推理的跨语言强化学习是实现强大跨文化泛化的关键。", "innovation": "研究提出了一种名为M2A的新方法，通过多尺度多语言对齐与基于机器翻译问题的语言一致性奖励来提升LLMs在不同语言下的推理能力。同时引入了GeoFact-X多语言事实推理基准，该基准不仅评估最终答案，还提供推理过程的痕迹，有助于更好地理解和改善跨语言推理。", "conclusion": "M2A显著提升了多语言推理在数学和事实推理任务中的准确性，表明在跨语言推理中注重推理过程对于实现跨语言泛化具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13681", "html_url": "https://arxiv.org/abs/2507.13681", "title": "LoopServe：多轮对话中适应性的双阶段大语言模型推理加速系统", "title_en": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues", "authors": "Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan", "background": "在许多实际应用中，多轮对话对于大型语言模型如聊天机器人和虚拟助手至关重要。随着对话历史的延长，现有大型语言模型面临着日益增加的计算和内存挑战，这限制了它们提供高效和及时互动的能力。大多数当前的加速方法要么压缩上下文，要么优化关键值缓存，但这些方法通常依赖于固定的或基于位置的启发式方法，不能很好地适应实际多轮对话中动态和不可预测的模式。因此，这些模型无法准确识别和优先处理最相关的上下文，导致响应质量下降", "innovation": "LoopServe引入了两项主要创新。首先，在填充分词阶段，它通过动态选择每个新输入最为重要的部分来在线稀疏化注意力矩阵。其次，在解码阶段，它使用渐进式的关键值压缩，基于最近生成的输出令牌动态维护一个相关且高效的缓存。此外，作者还提出了一种新的基准，其中包括11个反映现实查询位置和对话依赖关系的多轮数据集。广泛的实验表明，LoopServe在多个长期上下文对话任务中相比现有基线实现了更优的效果，并显著加速了LLM的推理过程", "conclusion": "LoopServe通过在线稀疏化和渐进式关键值压缩，能够有效地管理长对话历史带来的计算和内存挑战，从而提升多轮对话任务中的大型语言模型推理性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15475", "html_url": "https://arxiv.org/abs/2508.15475", "title": "基于影响的 Curriculum 学习以在有限数据下进行预训练", "title_en": "Influence-driven Curriculum Learning for Pre-training on Limited Data", "authors": "Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth", "background": " Curriculum 学习通过按示例难度排序（例如，从简单的文档到复杂的文档）呈现数据给模型，已被证明在预训练语言模型方面成效有限。这项研究探讨如果使用更贴近模型训练过程中发现的示例难度的新标准取代传统的基于人类的难度度量，Curriculum 学习能否变得更具竞争力。", "innovation": "研究人员尝试根据每个训练示例对模型输出的影响程度来对训练示例进行排序，这种方法称为 'training data influence'。使用这种数据影响度排序的模型在基准测试中比随机顺序训练的模型高出超过10个百分点，证明了对于语言模型的预训练，只要采用更以模型为中心的难度度量标准，Curriculum 学习是有利的。", "conclusion": "研究表明，在有限数据下预训练语言模型时，采用基于影响的程度进行排序的 Curriculum 学习方法是有益的，这证实了适当调整难度度量标准可以提高模型的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.03860", "html_url": "https://arxiv.org/abs/2508.03860", "title": "真实到真相：大规模语言模型事实核查及事实性评估综述", "title_en": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "authors": "Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam", "background": "大规模语言模型（LLMs）在训练过程中使用了大量的互联网语料库，这些语料库中往往包含不准确或误导性的内容。因此，LLMs 生成的虚假信息成为了必须进行有效事实核查的问题。该论文系统分析了LLM生成内容的事实准确性评估，探讨了幻觉、数据集局限性和评估指标可靠性等关键挑战，并强调了需要结合高级提示策略、领域特定微调和检索增强生成等综合框架进行强事实核查。", "innovation": "该论文提出了五个研究问题以指导从2020年至2025年的现有文献分析，主要聚焦于评估方法和缓解技术。还详细回顾了指令微调、多智能体推理和检索增强生成框架以访问外部知识。关键发现指出当前指标的局限性、验证外部证据的重要性以及通过领域特定定制提高事实一致性的重要性。", "conclusion": "该综述突出了构建更准确、更易懂、更情境相关的事实核查的重要性，为未来更加可信赖的模型的研发提供了指导性的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01832", "html_url": "https://arxiv.org/abs/2508.01832", "title": "MLP Memory: 一种大语言模型的检索预训练记忆模块", "title_en": "MLP Memory: A Retriever-Pretrained Memory for Large Language Models", "authors": "Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin", "background": "现代增强大型语言模型事实准确性及知识利用的方法面临一个根本性的权衡：非参数检索增强生成（RAG）方法虽然灵活且能访问外部知识，但存在推理延迟高、知识整合浅的问题，而参数调优方法如LoRA则面临灾难性遗忘和一般能力退化的问题。", "innovation": "提出了一个轻量级的参数模块MLP Memory，该模块能够在不直接访问文档的情况下学习内部化检索模式。通过在预训练数据集上预训练一个MLP以模仿最近邻检索器的行为，MLP Memory能够以完全参数化的形式捕获基于检索的知识访问带来的优势。此外，该模块通过简单的概率插值与Transformer解码器集成，取得了多项问答基准测试12.3%的相对改进和九种通用NLP任务5.2分的绝对增益，并减少了高达10分的虚构生成。相较于RAG，MLP Memory的推理速度提高了2.5倍，同时保持了更高的准确率，展示了参数化学习检索模式既能高效推理又能有效获取知识，为RAG和调优方法提供了一个实用的选择。", "conclusion": "我们的研究结果表明，参数化学习的检索模式可以弥合高效推理和有效知识访问之间的差距，提供一种既高效又实用的替代方案，既可与RAG方法兼容，也可应用于传统的参数调优方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16876", "html_url": "https://arxiv.org/abs/2508.16876", "title": "梦聊：基于用户信念建模的对话中的模型强化学习", "title_en": "Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling", "authors": "Yue Zhao,Xiaoyu Wang,Dan Wang,Zhonglin Jiang,Qingqing Gu,Teng Chen,Ningyuan Xi,Jinxian Qu,Yong Chen,Luo Ji", "background": "世界模型在机器人、游戏和自动驾驶等领域得到了广泛应用，但在自然语言任务中的应用相对有限。本文针对这一现状，提出了一种创新的对话世界模型（Dialogue World Model），能够预测用户的感情、情绪、意图和未来对话内容。", "innovation": "通过定义部分观测马尔可夫决策过程（POMDP），作者认为感情、情绪和意图可以建模为用户信念，并通过最大化信息瓶颈来解决。该研究进一步将基于模型的强化学习框架应用于对话系统中，并提出了一种名为DreamCUB（Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling）的框架。实验证明，预训练的对话世界模型在情感分类和情感识别方面达到了最新的性能指标，同时通过策略、评论家和对话世界模型的联合训练，也提高了对话质量。此外，进一步分析表明，这种方法在探索与利用之间保持了合理的平衡，并且能够很好地区域不同领域的应用场景，如同理心对话。", "conclusion": "该框架在情感分类、情感识别、对话生成和同理心对话等方面表现突出，特别是在直接利用用户标签观测的情况下，可以实现对话质量的提升。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.09381", "html_url": "https://arxiv.org/abs/2509.09381", "title": "建模类比及其类比推理：将认知科学理论与NLP研究联系起来", "title_en": "Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research", "authors": "Molly R Petersen,Claire E Stevenson,Lonneke van der Plas", "background": "类比推理是人类认知的一个重要方面。本文总结了认知科学文献中关于类比推理过程的关键理论，并将其与自然语言处理（NLP）的最新研究相联系。虽然这些过程可以很容易地与NLP的概念联系起来，但它们通常不从认知的角度来看待。此外，文章阐述了这些概念如何与NLP研究中的几个主要挑战相关，这些挑战不直接与解决类比问题有关。", "innovation": "展现如何将类比推理的概念应用于NLP研究的主要挑战，并指导研究人员更好地优化文本中的关系理解，而不是过分依赖实体级别的相似性。", "conclusion": "本文通过连接认知科学理论和NLP研究，为理解类比和类比推理提供了新的视角，可能引导研究人员更好地优化文本中的关系理解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04349", "html_url": "https://arxiv.org/abs/2508.04349", "title": "GTPO和GRPO-S：基于策略熵的令牌和序列级奖励塑形", "title_en": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy", "authors": "Hongze Tan,Jianfei Pan,Jinghao Lin,Tao Chen,Zhihang Zheng,Zhihao Tang,Haihua Yang", "background": "强化学习（RL）对于增强大型语言模型（LLM）推理至关重要。传统算法通常采用粗粒度的信用分配范式，对序列中的所有令牌施加统一的奖励，这在长链推理任务中是一个关键缺陷。因此，该研究旨在解决这一挑战，提出了一种新的机制，即动态熵权重分配，以实现更细粒度的奖励分配。", "innovation": "提出了两种新的算法：组令牌策略优化（GTPO），它为每个令牌分配一个基于熵的奖励，以及相似的序列级GRPO（GRPO-S）算法。这种方法假设推理路径中的高策略熵是一种认知努力的有力启发式方法，并将其重新利用为学习信号。通过将策略熵用于奖励塑形，实现了真正的令牌级信用分配。实验结果在复杂的推理基准测试中验证了该方法的优越性，显示出我们的方法显著优于强大的DAPO基线，确认了熵权重机制是推动性能提升的关键因素。", "conclusion": "实验结果表明，该方法在复杂的推理任务基准测试中表现优于DAPO基线，验证了基于策略熵的奖励塑造方法的有效性，而该方法的关键在于熵权重机制的使用。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05282", "html_url": "https://arxiv.org/abs/2508.05282", "title": "ASCoT: 一种针对大型语言模型后期脆弱性的自适应纠错链式思考方法", "title_en": "ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs", "authors": "Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian", "background": "链式思考（CoT）推理显著增强了大型语言模型（LLMs）的推理能力，但这些推理链的可靠性仍是一个关键挑战。广泛认为，错误最致命的是在推理的早期阶段出现（级联失败假设）。本研究通过系统性的错误注入实验，揭示了一个反直觉的现象——被称为“后期脆弱性”。即CoT链中的后期引入的错误比早期引入的错误更可能篡改最终答案。因此，本文提出了适应性自校正链式思考（ASCoT）方法，通过一种模块化管道，首先使用适应性验证经理（AVM）进行操作，接下来使用多视角自校正引擎（MSCE），以解决这一特定的脆弱性问题。", "innovation": "提出了ASCoT方法，通过一种模块化管道，首先使用适应性验证经理（AVM）进行操作，根据位置的差异给予不同权重，重点识别和优先处理高风险的后期步骤。随后使用多视角自校正引擎（MSCE）对失败部分进行健壮的、双路径校正。该方法在基准测试如GSM8K和MATH上表现出色，超越了包括标准CoT在内的强大基准方法。", "conclusion": "研究强调诊断LLMs推理中的特定失败模式的重要性，并提倡从统一验证策略转向适应性和漏洞意识的校正机制。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15253", "html_url": "https://arxiv.org/abs/2508.15253", "title": "冲突感知软提示在检索增强生成中的应用", "title_en": "Conflict-Aware Soft Prompting for Retrieval-Augmented Generation", "authors": "Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee", "background": "检索增强生成（RAG）通过将外部知识融入大型语言模型（LLMs）的输入提示中，增强了LLMs的能力。然而，当检索到的上下文与LLMs的参数化知识矛盾时，这种矛盾无法被解决，这就是所谓的上下文-记忆冲突问题。", "innovation": "本文提出了一种冲突感知检索增强生成（CARE）方法，该方法包含上下文评估器和基础LLM。上下文评估器从原始上下文标记中编码紧凑的记忆标记嵌入，并通过基于现实或对抗性软提示训练，以识别不可靠的上下文并捕捉指引信号，导向更可靠的知识来源。实验表明，CARE能够有效缓解上下文-记忆冲突，使其在问答和事实核查基准测试上的表现平均提高了5.0%。", "conclusion": "该研究为可信赖和适应性强的RAG系统指明了一个有希望的方向。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15587", "html_url": "https://arxiv.org/abs/2509.15587", "title": "DivLogicEval：大型语言模型中逻辑推理评估的框架", "title_en": "DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models", "authors": "Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung", "background": "自然语言中的逻辑推理被认为是对大型语言模型（LLMs）智能水平的重要衡量标准。现有的基准测试可能包含多种推理技能，导致对逻辑推理技能的评估不准确。此外，现有的逻辑推理基准在语言多样性方面有限，并且分布不理想，可能导致评估结果偏颇。", "innovation": "提出了一个新的古典逻辑基准DivLogicEval，它由以反直觉方式组成的多样化陈述自然句子组成。为了确保更可靠的评估，引入了一种新的评估指标，以减少大型语言模型中固有的偏见和随机性的影响。通过实验，展示了在DivLogicEval中进行逻辑推理的程度，并比较了不同流行大型语言模型的逻辑推理性能。", "conclusion": "实验表明，逻辑推理是回答DivLogicEval问题所需的程度，并且比较了不同流行大型语言模型在进行逻辑推理上的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12461", "html_url": "https://arxiv.org/abs/2508.12461", "title": "GPT-OSS开放性的最新评估", "title_en": "Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models", "authors": "Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song", "background": "2025年8月，OpenAI推出了GPT-OSS模型，这是自2019年GPT-2以来的首个开放权重的大型语言模型。GPT-OSS模型包含两个专家混合架构，拥有120B和20B参数。研究者将GPT-OSS的两个变体与六个其他开源大型语言模型（参数范围从14.7B到235B不等）进行了评测，包括一般知识、数学推理、代码生成、多语言理解以及对话能力十个基准测试。所有模型都在标准的推理环境中进行测试，并通过McNemars测试和效应量分析进行统计验证。研究发现，尽管使用较少的内存和能源，GPT-OSS-20B在某些基准测试上仍然优于GPT-OSS-120B。", "innovation": "研究首次对OpenAI的最新开源模型进行了全面评估；使用标准推理设置和统计验证方法；发现稀疏架构的扩展可能不会带来成比例的性能提升，需要进一步研究优化策略以更高效地选择未来开源部署的模型。", "conclusion": "GPT-OSS-120B和GPT-OSS-20B在当前开源环境中表现出中间水平的性能，但相比之下，GPT-OSS-20B在代码生成方面有较强优势，在多语言任务方面则表现出明显不足。这些发现提供了实验证据表明，只需扩大稀疏架构不一定能带来性能上的同样提升，这强调了需进一步探索优化策略的必要性，并为未来的开源部署提供了更合理的模型选择建议。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15888", "html_url": "https://arxiv.org/abs/2509.15888", "title": "效率更高的大规模语言模型任务适配的分布对齐解码", "title_en": "Distribution-Aligned Decoding for Efficient LLM Task Adaptation", "authors": "Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Yong Dai,Sam Tak Wu Kwong,Yuguang Fang", "background": "使用大量参数的语言模型进行下游任务适配仍然成本高昂，即使使用参数高效微调（PEFT）。现有的方法通常需要通过参数更新间接地调整输出分布，这增加了计算成本。", "innovation": "提出了一种新的方法Steering Vector Decoding (SVD)，这是一种轻量级且与PEFT兼容的方法。SVD通过直接调整输出分布来引导模型适配任务，避免了通过权重更新间接调整，相比全适应微调等方法，它可以提供一个更轻量且理论基础更牢固的解决路径。", "conclusion": "在三个任务和九个基准测试上，SVD与四种标准PEFT方法结合使用可以提高多项选择正确率多达5个百分点和开放性回答的真实性2个百分点。在常识数据集上，SVD可以获得相似的收益（1-2个百分点），而且无需增加任何新的可训练参数。因此，SVD为大规模语言模型提供了更有效的任务适配路径。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.06501", "html_url": "https://arxiv.org/abs/2509.06501", "title": "WebExplorer: 通过探索与演变训练远见型网页代理", "title_en": "WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents", "authors": "Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He", "background": "大型语言模型（LLMs）的应用模式最近转向了具有代理能力的应用，特别是网页浏览能力对于从多样的在线来源检索信息至关重要。然而，现有的开源网页代理要么在复杂任务上的信息检索能力有限，要么透明度不足。现有研究的关键挑战在于缺乏用于信息检索的具有挑战性的数据。", "innovation": "该研究引入了WebExplorer，一种基于模型的探索方法和迭代、长到短查询演化的系统数据生成方法。通过这种方法，创造出了需要多步推理和复杂网页导航的查询-答案对。利用精心策划的高质量数据集，WebExplorer-8B通过监督微调和强化学习开发而成，并实现了128K上下文长度和最多100轮工具调用，从而解决长期复杂问题。在各种信息检索基准测试中，WebExplorer-8B在同规模模型中取得了领先性能。尤其是在经过强化学习训练后，能够有效地在平均16轮后进行网页搜索，表现出更高的准确性，并在某些基准测试中达到最优性能。", "conclusion": "WebExplorer在各种信息检索任务中取得了显著成果，展示了在仅训练于知识密集型问答数据的情况下，具备强大的泛化能力。这些结果表明，该方法是朝向远见型网页代理实用路径的关键步骤。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02097", "html_url": "https://arxiv.org/abs/2509.02097", "title": "JudgeAgent: 采用代理面试者的知识导向和动态大语言模型评估", "title_en": "JudgeAgent: Knowledge-wise and Dynamic LLM Evaluation with Agent-as-Interviewer", "authors": "Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Jian Guo,Yuanzhuo Wang", "background": "当前对大语言模型（LLMs）的评估方法存在夸大或偏颇的评价，以及问题难度匹配不足的问题，导致知识和能力边界评估不完整，阻碍了其有效应用和优化。", "innovation": "提出了一种名为Agent-as-Interviewer的动态评估范式，利用LLM代理进行多轮交互评估。该方法通过代理调用知识工具实现动态多轮问题生成，以覆盖更广泛、更深入的知识，从而实现对LLM知识边界的全面评估。此外，代理还被用于规划查询策略以调整问题难度水平，增强了难度控制，与目标LLM的实际能力相匹配。", "conclusion": "通过该范式，开发了JudgeAgent，一个知识导向的动态评估框架，利用知识驱动的合成作为代理工具，并采用难度评分作为策略指导，最终提出了有价值的建议，帮助目标模型优化自我。广泛实验验证了JudgeAgent建议的有效性，证明了Agent-as-Interviewer可以准确识别目标模型的知识和能力边界。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02123", "html_url": "https://arxiv.org/abs/2509.02123", "title": "CMRAG: 根据多模态的视觉文档检索与问答", "title_en": "CMRAG: Co-modality-based visual document retrieval and question answering", "authors": "Wang Chen,Wenhan Yu,Guanqiang Qi,Weikang Li,Yang Li,Lei Sha,Deguo Xia,Jizhou Huang", "background": "检索增强生成（RAG）已经成为文档问题回答任务的核心范式。然而，现有的方法在处理多模态文档时存在局限性：一类方法依赖于布局分析和文本提取，只能利用显式的文本信息，难以捕捉图像或非结构化内容；另一类方法将文档分割视为视觉输入，直接传递给视觉语言模型（VLM）处理，然而它忽视了文本的语义优势，导致检索和生成结果欠佳。", "innovation": "我们提出了联合模态基于的RAG（CMRAG）框架，可以同时利用文本和图像以更准确地检索和生成。该框架包括两个关键组成部分：（1）统一编码模型（UEM），通过三重训练将查询、解析后的文本和图像投影到共享嵌入空间；（2）统一联合模态指导检索（UCMR）方法，统计正则化相似性分数以有效地融合跨模态信号。此外，我们还构建并发布了大量（查询，文本，图像）三元组数据集，支持这一领域的进一步研究。实验表明，我们提出的框架在多个视觉文档问题回答（VDQA）基准测试中始终优于基于单模态的RAG。这表明，在RAG框架中以统一方式整合联合模态信息是提高复杂VDQA系统性能的有效方法。", "conclusion": "实验结果表明，我们的框架在多个视觉文档问题回答（VDQA）基准测试中始终优于基于单模态的RAG。研究发现，以统一方式整合联合模态信息进入RAG框架是提高复杂VDQA系统性能的有效方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.10739", "html_url": "https://arxiv.org/abs/2509.10739", "title": "不确定性的推理：探索大语言模型的概率推理能力", "title_en": "Reasoning Under Uncertainty: Exploring Probabilistic Reasoning Capabilities of LLMs", "authors": "Mobina Pournemat,Keivan Rezaei,Gaurang Sriramanan,Arman Zarei,Jiaxiang Fu,Yang Wang,Hamid Eghbalzadeh,Soheil Feizi", "background": "尽管大语言模型（LLMs）在语言理解和生成方面取得了广泛的成功，但在面对需要概率推理的任务时，它们表现出的是不明确且常常不一致的行为。本文对此展开研究，首次对LLMs在显式离散概率分布下进行推理的能力进行了全面考察。", "innovation": "本文通过设计三个任务（模式识别、最大似然估计和样本生成），评估LLMs基于概率分布观察结果进行推理的能力，从而探测概率推理的多种技能，包括频率分析、边缘化和生成行为。同时，通过实验表明大模型在推理和样本生成方面表现出更强的能力，但也揭示了模型敏感于概率表示法的变化和上下文长度增加带来的性能下降。", "conclusion": "研究结果揭示了LLMs在概率推理方面的表现差异，并指出了未来改进的关键方向。通过这些发现，可以更好地理解大语言模型的概率推理能力，并为未来的研究提供指导。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17428", "html_url": "https://arxiv.org/abs/2509.17428", "title": "QWHA：大型语言模型高效参数调整中考虑量化的小瓦尔什-霍德变换适应", "title_en": "QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models", "authors": "Hyesung Jeon,Seojune Lee,Beomseok Kang,Yulhwa Kim,Jae-Joon Kim", "background": "对大型语言模型（LLMs）高效部署的需求推动了量化方法的兴趣，这可以减少推理成本，同时参数高效微调（PEFT）降低了训练开销。现有的低秩适配方法虽然简单，但代表能力有限。最近的Fourier相关变换（FT）基适配器虽然提供了更大的表示能力，但在量化模型中的直接集成往往导致量化错误减少不力，并增加了计算开销。", "innovation": "提出了一种方法QWHA，它通过使用沃尔什-霍德变换（WHT）作为变换核，并结合新颖的适配器初始化方案来集成FT基适配器，从而在量化模型中有效减小量化误差，实现高效微调和显著降低计算成本。", "conclusion": "实验结果显示，QWHA在低位量化精度方面始终优于基线模型，并且比现有FT基适配器在训练速度上取得了显著提高。代码可在相应链接中找到。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12635", "html_url": "https://arxiv.org/abs/2509.12635", "title": "基于Token感知相位注意的注意位置编码方法", "title_en": "Positional Encoding via Token-Aware Phase Attention", "authors": "Yu Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian", "background": "当前研究表明，旋转位置嵌入(RoPE)会在注意分数中引入一种与距离相关的内在偏差，这限制了其建模长语境的能力。尽管扩展RoPE的方法可能会缓解这个问题，但这些方法通常需要在预训练之后进行后处理调整，如缩放或超参数调优。在此背景下，本文研究如何改进位置编码方法，以更好地处理长距离上下文问题。", "innovation": "本文提出了一种新的位置编码方法——Token-Aware Phase Attention（TAPA），它将可学习的相位函数融入到注意机制中。TAPA能够保持长范围内的token相互作用，可以直接且轻量地进行微调以适应更长的语境，并且在处理长上下文时相较于RoPE家族在困惑度方面取得了显著的改进。", "conclusion": "TAPA在保持token间的长期相互作用的同时，能够直接且轻量地拓展到更长的语境，并且在长语境建模上表现更好，相较于RoPE及其扩展方法的现有方法，TAPA具有更好的性能，有望成为提升模型在长语境理解能力的有效方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21155", "html_url": "https://arxiv.org/abs/2509.21155", "title": "学习错误的教训：语言模型中的语法-领域虚假关联", "title_en": "Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models", "authors": "Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi", "background": "先前的研究表明，语言模型（LLM）要在指令中正确响应，必须理解任务指令的语义及其所属领域。语法也可以传递隐含信息，如频繁出现的词性（PoS）序列模板在训练数据中普遍存在，并经常出现在模型输出中。本文研究这些语法模板、任务指令的领域以及它们之间的联系。通过合成训练数据集，研究发现语法-领域相关性可能降低OLMo-2模型在实体知识任务上的性能。此外，还展示了在这个现象背后可能存在的安全问题，并强调了需要在训练数据中确保语法多样性。", "innovation": "提出了一个评估框架来检测训练后的模型中的语法-领域虚假关联现象，并且在特定的数据集的不同模型中发现了这一现象的存在。同时，展示了这种虚假关联可能带来的安全隐患，即可以被用于绕过拒绝指令的潜在策略。", "conclusion": "这项研究强调了两个关键需求：一是需要明确测试语法-领域虚假关联；二是要确保训练数据中的语法多样性，特别是在各个领域内，以防止这种虚假关联的发生。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "链还是树？从思维矩阵的角度重评估复杂推理", "title_en": "Chain or tree? Re-evaluating complex reasoning from the perspective of a matrix of thought", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "大型语言模型（LLMs）在处理复杂和抽象任务时，由于推理能力不足导致显著的准确性下降。解决问题时使用的思考结构如思维链（CoT）和思维树（ToT）虽然试图增强其推理能力，但各自存在内在缺陷，例如思维树结构中的冗余或思维链结构中的单一路径。一些研究利用检索增强生成（RAG）的方法来提高CoT和ToT，减少LLMs的幻觉，但这并没有解决根本问题。此外，面对多实体和多跳信息时，检索验证的知识往往包含大量零散、表面或错误的信息，误导LLMs的推理过程。因此，本文提出了思维矩阵（MoT），这是一种新的高效思考结构，旨在通过“列细胞通信机制”在水平和垂直维度上探索问题，减少列细胞内思考节点的冗余，增强LLMs的推理能力。同时，通过事实校正机制利用RAG检索的知识图谱三元组和原始文本构建知识单元并纠正错误答案。为验证其有效性，作者在数学24点游戏、问答评估和命题推理三个任务中进行了实证研究，结果显示该框架优于最先进的方法，推理时间仅为基线方法的14.4%，证明其高效性和准确性。关于此研究成果的代码可在相关平台获取。", "innovation": "提出了思维矩阵（MoT），这是一种新的、高效的认知框架，通过列细胞的通信机制，解决了思维树结构中的冗余和思维链结构中的单一路径问题，能够支持多策略和深层次的思考。此外，它还通过事实校正机制利用RAG检索的知识图谱三元组和原始文本来构建知识单元并纠正错误答案，从而提升LLMs的推理能力和准确性。", "conclusion": "研究结果表明，思维矩阵（MoT）在多个任务中的表现优于目前最先进的方法，证明了其高效性和准确性。同时，其推理时间仅为基线方法的14.4%，进一步证明了这种方法的效率。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21305", "html_url": "https://arxiv.org/abs/2509.21305", "title": "阿谀奉承不只是一种表现：LLMs中阿谀行为因果分离", "title_en": "Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs", "authors": "Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang", "background": "大型语言模型（LLMs）常常表现出奉承行为，如过分同意用户或奉承用户，但还不清楚这些行为是源自一个单一机制还是多个不同的过程。", "innovation": "研究将奉承行为拆解为奉承同意和奉承赞美，并使用差异均值方向、激活添加以及子空间几何分析多个模型和数据集，展示了以下发现：（1）三种行为在潜在空间中沿着独立的线性方向编码；（2）每种行为可以独立放大或抑制而不影响其他行为；（3）其表征结构在不同模型家族和大小中具有一致性。", "conclusion": "研究结果表明，奉承行为对应着独立且可操控的表征，区别于真正的一致性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19742", "html_url": "https://arxiv.org/abs/2509.19742", "title": "HiCoLoRA: 通过层级协作LoRA解决上下文-提示错位问题的零样本DST", "title_en": "HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST", "authors": "Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li", "background": "零样本对话状态跟踪（zs-DST）对于让任务导向对话系统（TODs）在无需昂贵数据标注的情况下适应新领域至关重要。主要挑战在于对话上下文的动态特性与静态提示之间的语义不一致，这导致跨层协调不灵活、领域干扰和灾难性遗忘等问题。", "innovation": "提出了一种名为Hierarchical Collaborative Low-Rank Adaptation（HiCoLoRA）的框架，该框架通过稳健的提示对齐增强零样本槽位推理。HiCoLoRA采用分层低秩架构进行动态分层处理（结合下层启发式分组和上层全交互）、整合谱联合领域-槽聚类以识别可转移的关系，并采用语义增强SVD初始化来保留预训练知识。实验结果表明，HiCoLoRA在多领域数据集MultiWOZ和SGD上优于基线方法，达到SOTA的性能。", "conclusion": "HiCoLoRA框架在多领域数据集上展示了卓越的表现，解决了上下文-提示错位问题，为零样本对话状态跟踪提供了一种新的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17445", "html_url": "https://arxiv.org/abs/2509.17445", "title": "SRE用于问答任务中稳健的幻觉检测的语义重新表述熵", "title_en": "Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks", "authors": "Chaodong Tong,Qi Zhang,Lei Jiang,Yanbing Liu,Nannan Sun,Wei Li", "background": "现有的大型语言模型（LLMs）在可靠问答方面面临挑战，因为模型可能会产生幻觉，即流畅但事实错误的输出，这些错误源于模型的语义不确定性。现有的基于熵的语义级不确定性估计方法因为抽样噪声和长度可变的回答的不稳定聚类，效果有限.", "innovation": "本文提出了语义重新表述熵（SRE），该方法通过两种方式改进了不确定性估计。首先，输入侧的语义重新表述会产生忠实的同义句，扩展了估计空间并减少了习惯性解码器倾向带来的偏见。其次，逐步的能量基混合聚类稳定了语义分组。实验表明，SRE在SQuAD和TriviaQA数据集上的表现优于强大基线模型，提供了更稳健和泛化的幻觉检测能力。这表明，输入多样性与多信号聚类的结合显著增强了语义级不确定性估计.", "conclusion": "这些结果表明，语义重新表述熵（SRE）通过将输入多样化与多信号聚类结合起来，显著增强了语义级不确定性估计，从而为问答任务中稳健的幻觉检测提供了更强的支持."}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20186", "html_url": "https://arxiv.org/abs/2509.20186", "title": "Thinking Augmented Pre-training", "title_en": "Thinking Augmented Pre-training", "authors": "Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei", "background": "大规模语言模型（LLM）的预训练计算量正以前所未有的速度增长，但高质量的数据供应仍然有限。因此，如何充分利用现有数据是当前研究的一大挑战。具体而言，由于固定模型容量的限制，某些高质量的令牌很难学习，因为单个令牌背后的原因可能极其复杂和深刻，这限制了数据效率的提升。", "innovation": "提出了一种名为思考增强预训练（TPT）的通用方法，通过自动生成的思考轨迹来增强文本数据。TPT能够增加训练数据的规模，并通过逐步推理和分解使高质量的令牌更容易学习。实验结果显示，TPT显著提高了LLM在各种模型规模和家族中的性能，特别是在一个小于100B令牌的范围内展示了其效果，提升了数据效率3倍，并在一个3B参数模型上提高了10%以上的性能。", "conclusion": "TPT通过引入思考轨迹来增强文本来提升大规模语言模型的培训数据效率，实验表明，这种方法在多个模型上有效，尤其是在数据效率上有了显著提升。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04059", "html_url": "https://arxiv.org/abs/2509.04059", "title": "朝向AI音乐家：合成乐谱问题以促进音乐推理", "title_en": "Towards an AI Musician: Synthesizing Sheet Music Problems for Musical Reasoning", "authors": "Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Xiaoye Qu,Ziqian Qiao,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng", "background": "提高大型语言模型（LLMs）和多模态大型语言模型（MLLMs）解释乐谱的能力是构建AI音乐家的关键步骤。然而，当前研究在乐谱推理的评测基准和训练数据方面存在明显不足。此研究借鉴数学中的简单操作能产生无限可验证问题的理念，引入了一种新方法，将音乐理论核心规则视为编程函数来系统地合成大型多样化的乐谱推理问题集。这有助于建立一种数据合成框架，生成可验证的乐谱问题，覆盖文本和视觉模态，从而创建基于合成乐谱推理基准（SSMR-Bench）及配套的训练集。评估结果强调了推理在解读乐谱中的关键作用，并指出了视觉格式下理解乐谱的持续挑战。通过利用合成数据进行RLVR，所有模型在SSMR-Bench上都显示出显著的改进，并在先前建立的人工构建基准（如MusicTheoryBench和MMMU中的音乐子集）上也取得了显著进步。最终结果表明，增强的推理能力也可以促进音乐创作。", "innovation": "引入了一种数据合成框架，用于生成可验证的乐谱问题（覆盖文本和视觉模态），从而创建合成乐谱推理基准和配套训练集。评估了LLMs和MLLMs在音乐推理任务中的表现，并展示了利用合成数据进行更深层次学习的潜力。特别地，研究展示了这些模型在乐谱推理和音乐创作上的显著进步。", "conclusion": "研究强调了推理在解读乐谱中的关键作用，并指出在视觉格式下理解乐谱的持续挑战。通过SSMR-Bench，所有模型在乐谱推理和音乐创作任务上都显著提升了性能。该研究为后续研究提供了新的基准和训练数据，为构建AI音乐家铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20900", "html_url": "https://arxiv.org/abs/2509.20900", "title": "通过学习提问来学习总结：对抗性代理协作在长文档摘要中的应用", "title_en": "Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization", "authors": "Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch", "background": "当前大型语言模型在长文档摘要方面仍面临显著挑战，现有方法普遍存在信息丢失、事实不一致和连贯性问题。现有方法在处理过长的文档时表现不佳，这限制了长文档摘要的质量和效率。", "innovation": "提出了一种名为SummQ的新颖对抗性多代理框架，该框架通过总结代理和测验代理在互补领域的协作智能来解决这些问题。该框架通过生成和评价摘要，并创建和验证理解性问题来进行迭代优化，确保摘要质量。其特色在于对抗性动态机制，以及验证生成的摘要能否回答测验问题的检验人代理，这一机制能够通过多方面的反馈机制来不断改进总结质量。", "conclusion": "SummQ在三个广泛使用的长文档摘要基准测试中表现出色，实验结果在ROUGE、BERTScore指标以及LLM评价和人工评价方面均优于现有最先进的方法。多层次分析展示了多代理合作动态的有效性、不同代理配置的影响以及测验机制的作用，为长文档摘要提供了一种新的方法，通过对抗性代理合作提高摘要质量。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG：统一和可扩展代码库生成的仓库规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大型语言模型在生成个别函数或单个代码文件方面表现出色，但在从零开始生成完整的代码仓库方面仍面临根本性挑战。当前方法依赖于自然语言规划，这常常导致不清晰的规范、对齐度不佳的组件和由于其固有的模糊性和缺乏结构而导致的脆弱设计。这种方法的局限性限制了从高级规范构建一致和协调的软件系统的潜力，以及实现自动化代码生成的全部潜力。因此，需要一种新的规划框架来解决这一问题，以实现封闭的视角和结构化的规划。", "innovation": "本文引入了Repository Planning Graph (RPG)，这是一种结构化的表示形式，用于统一地编码功能、文件结构、数据流和函数。通过用明确的蓝图替代自由形式的自然语言，RPG实现了长期计划的一致性。在此基础上，开发了ZeroRepo框架，该框架在三个阶段中工作：提案级规划，实现级构建，以及图形引导的代码生成，其中包含测试验证。ZeroRepo在包括六个真实项目和1,052项任务的基准测试RepoCraft上进行了评估，生成了约36,000行代码和445万代码标记，比最强基线Claude Code大3.9倍，比其他基线大68倍。ZeroRepo实现了81.5%的覆盖率和69.7%的测试准确性，分别比Claude Code提高了27.3和35.8个百分点。进一步的分析表明，RPG模型复杂的依赖关系，能够通过接近线性扩展实现更复杂的规划，并提高对仓库的理解能力，从而加速本地化过程。", "conclusion": "本文通过引入Repository Planning Graph (RPG)解决了大规模代码库生成中的重要问题，并展示了ZeroRepo框架在统一和可扩展代码库生成方面的能力和优势。RPG提供了一种结构化的方法来规划和生成代码库，从而提高代码质量、一致性并加速开发过程。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.02136", "html_url": "https://arxiv.org/abs/2409.02136", "title": "大型语言模型与经典机器学习：使用高维表数据进行COVID-19病亡率预测的性能比较", "title_en": "Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data", "authors": "Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini", "background": "该研究将经典特征为基础的机器学习模型（CMLs）和大型语言模型（LLMs）在使用跨4个医院的9,134名患者高维表数据预测COVID-19病亡率方面的性能进行了比较。研究背景在于对比不同模型处理高维数据的任务能力。", "innovation": "研究创新之处在于采用了零样本分类的大型语言模型对转换过的结构数据进行分类，并且对Mistral-7b进行了QLoRA微调以增强其表现。研究对比了XGBoost和随机森林（RF）等经典机器学习模型以及GPT-4和Mistral-7b等大型语言模型在零样本分类和微调后的效果。", "conclusion": "虽然零样本分类的大型语言模型在预测COVID-19病亡率方面表现较弱，但通过微调显著提高了其效果，与经典机器学习模型相比，微调后的大型语言模型和经典机器学习模型都表现出了潜力，但经典机器学习模型在处理高维表数据任务方面仍然更占优势。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.19375", "html_url": "https://arxiv.org/abs/2409.19375", "title": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "title_en": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "authors": "Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang", "background": "视觉语言基础模型（VLMs），如CLIP，在各种任务上表现出色。然而，当训练和测试数据之间的分布差异较大时，部署这些模型可能会不可靠。虽然对不同场景进行微调的成本较高，缓存测试时适配器提供了一种有效的替代方案，通过存储代表性测试样本来指导后续分类。但这些方法通常采用简化的缓存管理，限制了容量，导致样本在更新过程中不可避免地被丢弃时发生严重的灾难性遗忘。", "innovation": "提出了一种名为DOTA（DistributiOnal Test-time Adaptation）的简单而有效的方法，解决了上述局限性。DOTA不是简单地记忆个别测试样本，而是连续估计测试数据流的基础分布。通过贝叶斯定理使用这些动态估计的分布计算测试时后验概率，实现基于分布的适应。这种分布为中心的方法使模型能够不断学习和适应部署环境。", "conclusion": "广泛的实验验证了DOTA显著减轻了遗忘现象，并且与现有方法相比，取得了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20916", "html_url": "https://arxiv.org/abs/2509.20916", "title": "跨语言句法理解中的记忆负载分析：线性距离与结构密度", "title_en": "Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density", "authors": "Krishna Aggarwal", "background": "本研究探讨了句法相关词之间线性接近度和介词材料结构密度在理解过程中对句子水平记忆负载解释的优劣。受到基于邻近性理论和语言间依赖长度最小化的证据的启发，研究引入了‘介入复杂度’作为结构化程度的关注点，进一步细化了线性距离度量。通过使用标准化的句法树库和多语言框架，分析句子长度、依赖长度和介入复杂度对记忆负载指标的影响。前人研究表明特征干扰和错键合对处理记忆负载的贡献，研究将句子水平的记忆负载定义为线性特征错键合和特征干扰的总和以简化问题，此定义并无证据证明它们的认知贡献是可加的。所有这三个因素与记忆负载呈正相关，其中句子长度的广泛影响更为突出，而介入复杂度提供了超越线性距离的解释能力。研究从概念上统一了线性和层次性视角下的邻近性，把依赖长度视为重要表面标志物，同时确定介入头部作为更直接反映整合和保持需求的指标。研究方法上，利用统一依赖树库(UD)的图测量及跨语言混合效应建模，展示了如何区分线性和结构性对处理效率的贡献，提供了评估记忆负载理论的有原则的方法。", "innovation": "研究引入了‘介入复杂度’作为结构化程度的关注点，细化了线性距离度量，并通过使用标准化的句法树库和多语言框架，系统地分析三个因素对记忆负载的影响，提供了跨语言加工效率的新视角。研究结合线性和结构视角，将依赖长度视为重要表面标志物，利用介入头部作为更接近的整合和保持需求的指标，提供了更有解释力的理论模型。同时，研究运用统一依赖树库(UD)和跨语言混合效应建模，区分了线性和结构性对处理效率的贡献，提供了评估记忆负载的理论路径。", "conclusion": "研究证实了所有三个因素与记忆负载的正相关关系，其中句子长度具有更广泛的影响力，而介入复杂度提供了超越线性距离的解释能力。研究将线性和层次性视角结合起来，通过依赖长度的表面标志物和介入头部的直接指标，统一了两种理论。同时，研究展示了如何利用统一依赖树库(UD)和跨语言混合效应建模来分离线性和结构性对处理效率的影响，为评估记忆负载理论的相对有效性提供了科学依据。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.07780", "html_url": "https://arxiv.org/abs/2406.07780", "title": "对令牌级奖励引导文本生成的批判性分析", "title_en": "A Critical Look At Tokenwise Reward-Guided Text Generation", "authors": "Ahmad Rashid,Ruotian Wu,Julia Grosse,Agustinus Kristiadi,Pascal Poupart", "background": "大型语言模型（LLMs）可以通过通过对齐与人类偏好进行微调来改进，这种方法被称为从人类反馈中学习的强化学习（RLHF）。然而，对LLMs进行微调的成本对于许多用户来说是不可承受的。由于能够绕过LLM微调，预测时基于令牌的奖励引导文本生成（RGTG）方法最近被提出。这些方法使用一个基于完整序列训练的奖励模型，在解码过程中对部分序列进行打分，以引导生成高奖励的序列。然而，这些方法至今仅具有启发式动机，并且分析不足。", "innovation": "本文展示了基于完整序列训练的奖励模型不适用于对部分序列打分。为解决这一问题，本文提出显式地对部分序列训练布拉德利-特里（Bradley-Terry）奖励模型，并在解码过程中自回归采样从隐含的令牌级策略。此外，作者研究了这种方法所提出奖励模型和政策的属性：表明该政策与两个不同RLHF政策的比率成比例。简单的方法优于以前的RGTG方法，并且在无需大规模LLM微调的情况下，其表现与强大的离线基线相似。", "conclusion": "本文采取了一种简单的方法改善了部分序列打分问题，提出了布拉德利-特里（Bradley-Terry）奖励模型，并在解码时不依赖大规模LLM微调即可表现良好。相关的代码可以在这项工作（this https URL）获取。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.15176", "html_url": "https://arxiv.org/abs/2408.15176", "title": "统一符号音乐排列:基于轨道感知重构和结构化 token 化", "title_en": "Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and Structured Tokenization", "authors": "Longshen Ou,Jingwei Zhao,Ziyu Wang,Gus Xia,Qihao Liang,Torin Hopkins Ye Wang", "background": "当前音乐排列主要依赖于任务特定的模型，这样的模型在处理多样化的需求，如重新解释、简化和添加生成时表现出局限性。这篇论文提出了一种统一框架，旨在利用预训练的符号音乐模型处理多轨音乐排列的不同场景，同时讨论了现有方法的不足之处，强调了现有模型对不同场景的适应性和表现力的限制性挑战。", "innovation": "该研究引入了一种基于轨道感知的重构目标和结构化的音乐 token 化方案，以便更有效地支持音乐轨道上的建模。这个框架使得一个预训练的符号音乐模型能够灵活应对各种乐器编配的转换，在推理时也能够更加灵活。此外，研究团队提出了 REMI-z 轨道感知 token 化方案，进一步优化了模型的效率和效能，弥补了现有模型在排列任务和无条件生成中的不足。", "conclusion": "该研究在不同的音乐排列场景，如乐队编配、钢琴和鼓的正常实施等方面都表现出色。它不仅在客观指标上超越了特定任务的前沿模型，也在主观评价中得到了认可，展示了其强大的通用性和在符号音乐转换中的广泛适用性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.16322", "html_url": "https://arxiv.org/abs/2409.16322", "title": "Alzheimer's Disease检测中的类内变异问题", "title_en": "On the Within-class Variation Issue in Alzheimer's Disease Detection", "authors": "Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng", "background": "阿尔茨海默病（AD）检测利用机器学习分类模型来区分患有AD的个体和未患有AD的个体。与传统的分类任务不同，我们识别出类内变异作为AD检测的关键挑战：患有AD的个体表现出认知功能损伤的连续谱。因此，简单的二元AD分类可能会忽略两类关键因素：类内异质性和实例级不平衡。", "innovation": "我们发现使用样本得分估计器可以生成与认知评分相匹配的样本特定软评分。随后，我们提出了两种简单而有效的解决方案：软目标蒸馏（SoTD）和实例级再平衡（InRe），分别针对两个问题。基于ADReSS和CU-MARVEL数据集，我们展示了并分析了所提出方法在检测性能上的优势。", "conclusion": "这些发现为开发稳健可靠的AD检测模型提供了见解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21192", "html_url": "https://arxiv.org/abs/2509.21192", "title": "GEP: 一种基于贪婪坐标梯度的方法用于从小语言模型构建的聊天机器人中提取个人可识别信息", "title_en": "GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models", "authors": "Jieli Zhu,Vi Ngoc-Nha Tran", "background": "小语言模型（SLMs）因其在某些领域中与大语言模型（LLMs）相比具有相近的性能，同时具有较低的能源和时间消耗，因此变得前所未有的吸引人。然而，关于SLMs在下游任务中的个人可识别信息（PII）泄漏问题尚未得到充分研究。本研究旨在针对基于SLMs的聊天机器人，探究PII泄漏问题。研究团队通过微调了一个名为ChatBioGPT的新聊天机器人，该机器人在医疗数据集Alpaca和HealthCareMagic的基础上，使用了BioGPT的模型框架，并通过BERTscore验证了其性能。研究发现，传统的基于模板的攻击方法在SLMs条件下不能有效检测PII泄漏。因此，研究团队开发了一种名为GEP的方法，即基于贪婪坐标梯度（GCG）策略的PII提取方法，并针对自由结方式插入的PII进行了实验，显示了该方法的有效性。", "innovation": "本研究创新性地开发了GEP，即基于贪婪坐标梯度方法的PII提取方法，专门设计用于SLMs条件下的PII攻击。实验表明，在类似真实场景中，GEP方法能够显著增加数据集中PII的泄漏率，相对于传统的基于模板的方法，最高可达60倍的增长。此外，GEP在自由结方式插入的PII场景中仍然能有效地检测出高达4.53%的PII泄漏率。", "conclusion": "研究证明了GEP在SLMs条件下对PII攻击的有效性，特别是在复杂和现实情景下。通过GEP，可以更有效地检测和防止SLMs中的PII泄漏问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19649", "html_url": "https://arxiv.org/abs/2502.19649", "title": "大型语言模型的表示工程：分类、机遇与挑战", "title_en": "Taxonomy, Opportunities, and Challenges of Representation Engineering for Large Language Models", "authors": "Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz", "background": "该领域研究如何通过直接操控模型内部表示（而非修改输入或微调模型）来控制大型语言模型的行为。现有的研究越来越多地探索这种新颖的方法，但仍缺乏系统的总结和指导。", "innovation": "论文首次提供了一个综合性的代表工程（RepE）调查，提出了一个统一的框架，将RepE描述为一个包含表示识别、操作化和控制的管道。此外，论文指出了RepE面临的主要挑战，并提出了改进实验和方法的机遇，并提供了最佳实践指南。", "conclusion": "虽然RepE方法具有显著的潜力，但仍面临多个概念管理、可靠性和保持模型性能等挑战。为了进一步改进RepE，论文提出了一些可能的创新方向，并为实践者提供了指南。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR：大型语言模型推理中的标记级不确定性估计", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "尽管大型语言模型（LLMs）展现了令人印象深刻的能力，但它们的输出质量在不同应用场景中仍然不一致，尤其是在需要多步推理的复杂任务中，难以确定可靠的响应。因此，需要开发一种机制来帮助LLMs在生成回复时进行自我评估和自我改进。", "innovation": "提出了一个标记级不确定性估计框架（TokUR），旨在使LLMs能够在数学推理过程中自我评估和自我改进其回应。通过在LLM解码期间引入低秩随机权重扰动来生成标记级不确定性估计的预测分布，并聚合这些不确定性量以捕获生成回复的语义不确定性。", "conclusion": "实验结果表明，TokUR与答案正确性和模型鲁棒性之间存在很强的相关性，产生的不确定性信号可以在测试时提高模型的推理性能。这些结果表明，TokUR是一种基于原理且可扩展的方法，可以提高LLMs在挑战性推理任务中的可靠性和可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.22376", "html_url": "https://arxiv.org/abs/2410.22376", "title": "Rare-to-Frequent: 使用大型语言模型指导实现罕见概念的组合生成能力", "title_en": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "authors": "Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho", "background": "现有的文本到图像（T2I）扩散模型在生成具有罕见组合概念的图像时常常表现不佳，尤其是在生成具有不寻常属性的物体时。本文通过实证和理论分析展示了，在扩散采样过程中引入与目标罕见概念相关的常见概念，可以显著提高扩散模型在生成罕见概念方面的能力。文章介绍了一个无需训练的框架R2F，通过利用大型语言模型（LLM）中的大量语义知识，规划和执行罕见到常见概念的指导，以提高扩散模型生成罕见概念的能力。", "innovation": "本文提出了一种无需训练的方法R2F，通过利用大型语言模型中丰富的语义知识，规划和执行罕见到常见概念的指导，以增强扩散模型生成罕见概念的能力。实验表明，该方法在三个数据集上显著优于现有模型（如SD3.0和FLUX），特别是在我们的新提出的基准数据集RareBench上，性能提高了28.1%。该框架适用于任何预训练的扩散模型和大型语言模型，并且可以无缝集成到区域导向的扩散方法中。", "conclusion": "本文展示了一种通过大型语言模型指导的方式提高扩散模型生成罕见概念的能力的方法，并通过实验验证了这种方法的有效性。研究展示了R2F框架在生成罕见概念上的优势，并提供了可扩展性和灵活性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.18319", "html_url": "https://arxiv.org/abs/2409.18319", "title": "开发和验证用于生成标准化放射学报告的大语言模型", "title_en": "Development and Validation of a Large Language Model for Generating Fully-Structured Radiology Reports", "authors": "Chuang Niu,Md Sayed Tanveer,Md Zabirul Islam,Parisa Kaviani,Qing Lyu,Mannudeep K. Kalra,Christopher T. Whitlow,Ge Wang", "background": "当前的LLM在创建完全结构化的报告时面临格式错误、内容幻觉以及上传数据时可能出现的隐私泄露问题，尤其是在处理机构间差异化的自由文本放射学报告时更为突出。对于构建标准化肺癌管理（LCS）报告的需求越发迫切，这需要能够从自由文本报告中自动生成结构化和标准化报告，并且能够用于自动统计分析和肺结节检索。因此，研究团队通过一个回顾性研究，利用两个机构的5,442份去标识化的低剂量CT LCS放射学报告，开发了一种可用于生成标准化LCS报告的开源大语言模型，用于处理不同机构的自由文本报告，以解决上述问题。", "innovation": "开发了一种动态模板约束解码方法，以提升现有的LLM，来更好地从自由文本放射学报告中生成完全结构化的报告。通过这种方法改进了最佳开源LLM，性能提高了10.42%，并且比GPT-4o优秀17.19%。生成的统计分布与以往关于衰减、位置、大小、稳定性和Lung-RADS的发现相符。此外，通过带有结构化报告的检索系统，实现了灵活的结节级搜索和复杂的统计分析，所开发的软件可以公开获取用于本地部署和进一步研究。", "conclusion": "我们的最佳LLM在跨机构数据集上的F1得分达到了约97%，既没有格式错误也不出现内容幻觉。这种方法大幅提高了开源LLM的性能，并且实验结果表明该模型在自动化统计分析和个体结节检索方面具有强大的实用性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.18123", "html_url": "https://arxiv.org/abs/2412.18123", "title": "通过揭示有害语义检测和解释文本到图像模型中的不适宜提示", "title_en": "Detecting and Interpreting NSFW Prompts in Text-to-Image Models through Uncovering Harmful Semantics", "authors": "Yiming Wang,Jiahao Chen,Qingming Li,Tong Zhang,Rui Zeng,Xing Yang,Shouling Ji", "background": "随着文本到图像（T2I）模型的发展和普及，它们的相关安全问题变得越来越关键。恶意用户利用这些模型生成不合适内容的图像，使用有害或对抗性提示，突出了需要有效保护以确保模型输出的完整性和合规性的需求。然而，现有的检测方法往往表现出较低的准确性和效率。", "innovation": "本文提出了一种名为HiddenGuard的可解析防御框架，利用T2I模型隐藏状态来检测NSFW提示。HiddenGuard从模型文本编码器的隐藏状态中提取NSFW特征，利用这些特征的可分性来检测NSFW提示。检测过程高效，需要最少的推断时间。HiddenGuard还提供实时结果解释，并支持通过数据增强技术进行优化。", "conclusion": "我们的广泛实验表明，HiddenGuard在所有数据集上显著优于商业和开源的过滤工具，准确率超过95%，并且极大地提高了计算效率。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.05723", "html_url": "https://arxiv.org/abs/2412.05723", "title": "无需训练的低秩大型语言模型适配器的贝叶斯化", "title_en": "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models", "authors": "Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang", "background": "目前，使用大型语言模型（LLMs）对响应的不确定性进行建模仍然面临重大挑战。尽管最近的贝叶斯方法通过低秩权重更新得以体现，它们通常需要复杂的调优或后训练过程。背景中心思想在于介绍现有贝叶斯化方法的局限性和需求，特别是在简易性和效果之间的权衡问题。", "innovation": "本文提出了无需训练的贝叶斯化（Training-Free Bayesianization，TFB），这是一种简单且理论上基础的框架，能够在无需额外训练的情况下将训练好的低秩适配器转换为贝叶斯适配器。TFB通过系统性搜索在低秩等方差正态分布家族中可接受的最大方差水平，来实现这一目标。TFB 的理论分析显示，这种搜索过程在温和条件下等价于 KL-正则化变分优化，这是变分推理的一种推广形式。通过全面的实验，作者证明TFB 在不确定性估计和泛化方面相比现有方法具有优越性，同时避免了复杂贝叶斯化训练过程的需求。", "conclusion": "通过 TFB 方法，作者展示了如何在不需要额外训练的情况下将已有的低秩适配器转化为贝叶斯适配器，提高了不确定性估计的准确性和泛化能力，同时简化了模型的部署和使用流程。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11360", "html_url": "https://arxiv.org/abs/2502.11360", "title": "GeoDANO: 具有领域通用视觉编码器的几何 VLM", "title_en": "GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder", "authors": "Seunghyuk Cho,Zhenyue Qin,Yang Liu,Youngbin Choi,Seungbeom Lee,Dongwoo Kim", "background": "尽管视觉语言模型（VLM）已被用于解决几何问题，但它们识别几何特征的能力尚未得到充分分析。现有的通用VLM中的视觉编码器在检测几何特征（如点、线及其关系）方面表现不佳，并且难以跨领域进行泛化。", "innovation": "提出了一个用于评估几何视觉特征识别能力的基准，包括GeoCLIP模型，该模型基于CLIP并在合成的几何图解-描述对上进行训练。GeoCLIP在识别几何特征方面优于现有视觉编码器。进一步提出了一种新的VLM，GeoDANO，它结合了GeoCLIP和领域适应策略，以处理未见过的图解样式。GeoDANO在解决平面几何问题方面优于专门为平面几何问题设计的方法和GPT-4o。", "conclusion": "GeoDANO通过结合GeoCLIP和领域适应策略，在解决未见过的平面几何问题上取得了优异表现，并在MathVerse上优于其他模型。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18668", "html_url": "https://arxiv.org/abs/2505.18668", "title": "ChartGalaxy: 一个用于信息图表理解与生成的数据集", "title_en": "ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation", "authors": "Zhen Li,Duan Li,Yukai Guo,Xinyuan Guo,Bowen Li,Lanxi Xiao,Shenyu Qiao,Jiashu Chen,Zijian Wu,Hui Zhang,Xinhuan Shu,Shixia Liu", "background": "信息图表是一种通过结合视觉元素（如图表、图像）和文本信息来传达抽象数据的强大媒介。然而，它们的视觉和结构丰富性为大型视觉语言模型（LVLMs）带来了挑战，这些模型通常仅针对简单的图表进行训练。为了填补这一空白，本文通过归纳过程构建了一个包含数百万个样本的数据集——ChartGalaxy，旨在提升LVLMs对信息图表的理解和生成能力。", "innovation": "该研究引入了一个新的数据集——ChartGalaxy，该数据集包含75种图表类型、440种图表变体和68种布局模板，用于创造合成的信息图表。通过解决大型视觉语言模型对于信息图表理解和生成的挑战，研究通过 Fine-tuning 提高了对信息图表的理解，并且可以用于衡量代码生成能力以及基于示例的信息图表生成。", "conclusion": "通过捕获真实设计中的视觉和结构复杂性，ChartGalaxy 为增强LVLMs的多模态推理和生成提供了有用的资源。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00209", "html_url": "https://arxiv.org/abs/2506.00209", "title": "拦截癌症：大规模医疗保健基础模型的癌症预筛查", "title_en": "Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models", "authors": "Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong", "background": "现有的癌症筛查技术昂贵且侵入性强，且全球普及率不高，这导致许多原本可以挽救的生命失去了救治的机会。", "innovation": "CATCH-FM是一种基于历史医疗服务记录的癌症预筛查方法，能够识别出需要进一步筛查的高风险患者。通过大规模的电子健康记录（EHR），CATCH-FM建立了以医学代码序列预训练的基础模型的扩展规律，开发了参数量高达24亿的基础模型，并在临床参数化癌症风险预测人群中进行了微调。在重新评估中，CATCH-FM表现出了强大的效用，在特定的灵敏度和特异性阈值下，其预测首次癌症风险的准确率达到50%，并且在AUPRC指标上比基于特征的树模型以及通用和医疗领域的语言模型高出20%。尽管存在显著的种族、医疗体系和EHR编码差异，CATCH-FM在EHRSHOT少样本领域能够达到最先进的胰腺癌风险预测结果。", "conclusion": "CATCH-FM展现出了在不同患者分布中的稳健性，ICD代码空间操作的优势，以及捕捉复杂癌症风险因素的能力。其代码将被开源。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01456", "html_url": "https://arxiv.org/abs/2502.01456", "title": "过程隐含奖励的强化学习", "title_en": "Process Reinforcement through Implicit Rewards", "authors": "Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding", "background": "在大型语言模型（LLMs）的推理时间扩展中，密集的过程奖励已被证明比稀疏的结果奖励更有效，尤其是在需要复杂多步推理的任务中。虽然密集奖励也适用于LLMs的强化学习（RL），因为它们具有精细的反馈，能够解决结果奖励固有的问题（如训练效率和奖励回溯），但潜在的好处尚未被充分利用。这主要归因于在线训练过程奖励模型（PRMs）的挑战，由于高质量的过程标签收集成本高昂，使得它们特别容易受到奖励作弊的影响。", "innovation": "本文提出了PRIME（Process Reinforcement through IMplicit rEwards），它允许仅使用策略执行和结果标签来在线更新PRM，通过隐含的过程奖励实现这一点。PRIME与各种优势函数相兼容，并且不需要现有方法所需的专门的奖励模型训练步骤，显著减少了开发成本。PRIME在竞赛数学和编程任务上进行了演示，从Qwen2.5-Math-7B-Base开始，PRIME在几个关键推理基准测试中对SFT模型实现了15.1%的平均改进。值得注意的是，使用PRIME获得的模型Eurus-2-7B-PRIME在七个推理基准测试中使用10%的训练数据超过了Qwen2.5-Math-7B-Instruct。", "conclusion": "综上所述，PRIME通过利用隐含奖励和策略执行的结果标签，解决了在线更新PRM的挑战，从而提高了大型语言模型在复杂任务中的推理性能。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.03814", "html_url": "https://arxiv.org/abs/2504.03814", "title": "LLMs递归训练循环：训练数据属性如何调节生成数据中的分布偏移？", "title_en": "Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?", "authors": "Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer", "background": "大型语言模型（LLMs）在生成在线内容中越来越广泛使用，随着每一代模型的训练数据包含更多合成数据，系统会形成反馈循环。先前研究表明，此类循环会导致分布偏移，即模型错误地代表了人类数据的真实分布（称为模型崩溃）。尽管如此，人类数据的属性如何影响这种偏移尚未有深入了解。本文首次通过实证研究探讨了数据属性对递归训练结果的影响，确认使用不同的人类数据集会导致不同程度的分布偏移，并通过回归分析得出了预测这些偏移量的属性集，如词汇多样性会放大偏移，而语义多样性和数据质量则能抑制偏移。同时，研究发现这些影响是高度模块化的，来源于特定互联网域的资料对另一域的内容生成影响较小。此外，分析政治偏见表明，人类数据的属性会影响初始偏见是被放大还是被减弱。", "innovation": "本文首次提供了对递归训练结果的实证研究，探讨了训练数据属性如何影响分布偏移。识别出词汇多样性能够放大分布偏移，而语义多样性和数据质量能够缓解偏移。所有这些发现提供了关于不同互联网部分可能发生不同类型的分布偏移的独特视角，展示了人类数据属性与模型生成内容之间的复杂互动关系", "conclusion": "我们的研究表明，不同的互联网部分可能会经历不同类型的分布偏移。此外，结果揭示了看似孤立的资料可能对不同领域的内容生成影响有限，以及人类数据属性在塑造生成内容偏见方面的重要作用。这一发现提供了减少模型偏见和提高数据质量的方法，对于更可信、公平的人工智能治理至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11756", "html_url": "https://arxiv.org/abs/2505.11756", "title": "特征对冲：相关特征破坏了窄稀疏自编码器", "title_en": "Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders", "authors": "David Chanin,Tomáš Dulka,Adrià Garriga-Alonso", "background": "假设稀疏自编码器（SAEs）将多元激活分解为可解释的线性方向，只要激活是由潜在特征的稀疏线性组合组成。然而，研究发现如果训练时的潜在特征数量少于SAE的宽度，并且特征之间存在相关性，SAE会将相关特征的分量合并，导致单一激活变得不再单一。在LLM SAEs中，这两条件几乎必定成立。这一现象称为特征对冲，它由SAE重构损失引起，SAE越窄，对冲现象越严重。", "innovation": "该研究引入了特征对冲问题，并在玩具模型中进行理论研究，在基于LLM训练的SAEs中进行了实证研究。作者推测特征对冲可能是导致SAEs在监督基准模型下一致表现不佳的一个核心原因。最终，利用对特征对冲的理解，提出了改进后的马特罗什卡SAEs变体。研究结果表明，SAE的宽度不是一个中立的超参数，更窄的SAE会受到更多的对冲影响。", "conclusion": "该工作展示了特征对冲对稀疏自编码器性能的影响，窄的稀疏自编码器比宽的稀疏自编码器更容易受到特征对冲的影响。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16932", "html_url": "https://arxiv.org/abs/2505.16932", "title": "极轨快车：最优矩阵符号方法及其在Muon算法中的应用", "title_en": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "authors": "Noah Amsel,David Persson,Christopher Musco,Robert M. Gower", "background": "矩阵极分解及其相关的矩阵符号函数的计算在数值分析领域研究了数十年，近年来，它作为Muon算法中训练深度神经网络的一个重要子程序而兴起。但是，这种应用的需求与传统的设定截然不同：深度学习要求GPU友好的算法，注重高吞吐量而非高精度。因此，传统方法在被迁移应用于训练深度学习模型时可能无法满足这些新的需求和挑战。因此，需要一种新的能够高效于GPU上的方法来解决这个问题。", "innovation": "本文提出了Polar Express，一种新的计算矩阵极分解的方法。该方法类似于Newton-Schulz和其他经典的多项式方法，仅使用矩阵-矩阵乘法，使其在GPU上非常高效。它通过解决最小极大优化问题来适应每一步的更新规则，从而在最坏情况下最小化误差，使得Polar Express能够在早期迭代和渐近地尽可能快速地收敛。此外，该方法还解决了有限精度的问题，使其可以在bfloat16中实用化。在此基础上将该算法整合到Muon训练框架中，当在FineWeb数据集上使用一个十亿词素训练GPT-2模型时，性能呈现出一致提高的趋势，且胜过其他最近的替代方案在不同学习率下的表现。", "conclusion": "Polar Express方法在GPU上表现高效，适于高吞吐量训练深度学习模型，并在具体应用场景上有所改进，尤其是在Muon算法训练GPT-2模型方面，展示了它的潜在优势。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10821", "html_url": "https://arxiv.org/abs/2506.10821", "title": "通过视频思考实现有能动性的长视频理解", "title_en": "Think With Videos For Agentic Long-Video Understanding", "authors": "Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou", "background": "长视频理解（LVU）是计算机视觉领域的一个具有挑战性的问题。现有的方法要么通过逐帧下采样进行一次性推理，牺牲了细粒度的细节，要么依赖于对任务无关表示的文本推理，这限制了任务特定的感知和探索能力。此外，缺乏足够的训练资源也是一个障碍。为了克服这些限制，研究人员需要提出新的方法来有效地理解长视频，同时保持细粒度的细节和任务相关的感知能力。", "innovation": "本文提出了VideoExplorer，这是一种基于“基于视频思考”的原则构建的框架，该框架自然地将规划、时间定位和可扩展感知整合到一个连贯的推理过程中。VideoExplorer通过迭代地提出子问题、定位相关时刻并进行以任务为导向的时间可扩展的视频理解，直到达到最终答案，从而实现忠实、高效和可解释的推理。为了应对缺乏训练资源的问题，作者构建了一个使用难度自适应采样机制的长视频推理数据集，以确保在复杂任务上获得高质量的轨迹。基于此数据集，他们设计了一个两阶段的训练管道：监督轨迹初始化加上轨迹级别偏好优化，在下游奖励引导下鼓励自适应的时间定位和迭代信息集成。", "conclusion": "在流行的长视频理解和推理基准测试上的广泛评估表明，VideoExplorer在现有基线中表现出显著的优势，突显了它的鲁棒性、适应性和效率。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11022", "html_url": "https://arxiv.org/abs/2506.11022", "title": "在迭代AI代码生成中的安全性退化——矛盾的系统分析", "title_en": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "authors": "Shivani Shukla,Himanshu Joshi,Romilla Syed", "background": "由于大型语言模型（LLMs）的快速采用，代码生成领域发生了根本性的变化，但很少有研究关注通过迭代LLM反馈，安全漏洞是如何演变的。这项研究通过使用四种不同的提示策略对400个代码样本进行40轮迭代改进的实验，分析了AI生成代码中的安全降级情况。实验结果显示，在仅仅五次迭代之后，关键漏洞的增加率达到了37.6%，并且不同提示策略产生了不同的安全漏洞模式。这些发现挑战了通过迭代LLM精细改进代码安全性这一假设，并强调了人类专业知识在这一过程中的关键作用。", "innovation": "该研究通过控制实验来分析AI生成代码中的安全降级，并首次通过多样化的提示策略揭示了迭代过程中安全漏洞的不同演化模式，以及提出了防止在“有益的代码改进”过程中引入新安全问题的实用指导原则。", "conclusion": "研究结果表明，通过迭代LLM进行代码改进并不必然能够提高代码安全性，反而可能引入新的安全漏洞。因此，研究建议开发人员在每次LLM迭代之间需要进行严格的人员验证，以防止所谓的“假性改进”中引入新问题。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23537", "html_url": "https://arxiv.org/abs/2505.23537", "title": "域感知张量网络结构搜索", "title_en": "Domain-Aware Tensor Network Structure Search", "authors": "Giorgos Iacovides,Wuyang Zhou,Chao Li,Qibin Zhao,Danilo Mandic", "background": "张量网络（TNs）是一种高效表示高维数据的方法，但如何找到最优的TN结构，即所谓的张量网络结构搜索（TN-SS）问题仍然是一个挑战。当前最先进（SOTA）算法将TN-SS转化为一个纯粹的数值优化问题，需要大量的函数评估，对于实际应用来说非常困难。此外，现有方法忽视了现实世界张量数据固有的领域信息，并且缺乏对所识别TN结构的透明性。因此，提出了一个结合了领域信息的新型TN-SS框架，称为tnLLM，它利用大型语言模型（LLMs）的推理能力，直接预测合适的TN结构。该框架通过一个结合领域意识的提示管道，指导LLM根据张量模式之间的现实关系推断合适的TN结构。因此，该方法不仅能够迭代优化目标函数，还能够生成结合领域的解释，所识别的结构。实验结果显示，tnLLM相较于SOTA算法具有更好的目标函数值且需要较少的函数评估次数。此外，利用大型语言模型能提供有关现实世界的领域信息，帮助在搜索空间中找到良好的初始值，从而加速基于采样的SOTA方法的收敛速度同时保留理论性能保证。", "innovation": "提出了一个结合领域信息的新框架tnLLM，利用大型语言模型的推理能力直接预测张量网络结构。该框架通过结合领域的提示管道指导LLM推断合适的张量网络结构，既优化目标函数又生成结合领域的解释。相比现有最先进方法，tnLLM以较少函数评估次数实现类似的结果，并通过大型语言模型提供的领域信息加速基于采样的方法收敛速度同时保留其理论性能保证。", "conclusion": "所提出的tnLLM框架在较少的函数评估次数下达到了与当前最先进算法相当的目标函数值。此外，利用大型语言模型提供的领域信息能够加快基于采样的最先进方法的收敛速度，同时保持其理论性能保障。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16975", "html_url": "https://arxiv.org/abs/2506.16975", "title": "基于Transformer的语言模型中潜在概念的分离", "title_en": "Latent Concept Disentanglement in Transformer-based Language Models", "authors": "Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy", "background": "当大型语言模型（LLMs）使用上下文学习（ICL）来解决新任务时，它们必须从示例中推断潜在的概念。这引发了一个问题，即Transformer如何在它们的计算过程中表示潜在结构。本文通过几种受控任务和机械可解释性研究了这一问题，发现模型能够识别和使用潜在的概念。通过对任务进行参数化的研究，展示了模型在理解并使用潜在概念方面的潜力，证明了即使是在少量简化示例的情况下，小模型和大模型也能分离和利用他们学到的潜在概念。", "innovation": "本文通过分析在不同任务中的表现，展示了使用受控任务和机械可解释性技术来研究Transformer如何表示和利用潜在结构的能力。主要发现包括：在蕴含关系任务中，模型能够识别并逐步组合潜在概念；对于参数化的潜在数值概念任务，模型能够发现低维子空间，其几何结构清晰地反映了潜在参数化的特征。", "conclusion": "本文说明了即使在少量简化示范的情况下，小模型和大模型也可以分离和利用潜在概念。模型能够在蕴含关系和参数化任务中识别潜在概念，进行有效的推理。这些发现加深了对Transformer如何处理和利用潜在概念的理解，对于未来的模型设计和应用具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17307", "html_url": "https://arxiv.org/abs/2507.17307", "title": "R-Stitch: 动态轨迹缝合以提高高效推理", "title_en": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "authors": "Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang", "background": "长序列自回归推理成本高，现有加速策略如提前停止、模型压缩或小模型推测解码虽有作用，但推测解码在模型一致性低时效果不佳，且需要确保标记级一致性，忽略了小模型在正确时可生成更简洁推理轨迹的可能性。", "innovation": "提出了一种无需训练的混合解码框架R-Stitch，利用标记级熵作为不确定性代理，将计算任务分配给小型语言模型（SLM）和大型语言模型（LLM）。进一步提出R-Stitch+$，学习自适应路由策略以动态调整标记预算。通过减小每标记解码复杂性和生成的标记数量，该方法实现显著加速且几乎无准确度损失，具体实现了深搜-求-1-密集-Qwen-7B上的3.00倍速提升，14B上的3.85倍速提升，以及QWQ-32B上的4.10倍速提升。", "conclusion": "R-Stitch方法提供了适应性效率-准确度权衡，无需重新训练即可根据不同的计算预算进行调整，同时实现显著加速且几乎没有准确度损失。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10859", "html_url": "https://arxiv.org/abs/2507.10859", "title": "MultiVox：评估多模态交互语音助手的标准", "title_en": "MultiVox: A Benchmark for Evaluating Voice Assistants for Multimodal Interactions", "authors": "Ramaneswaran Selvakumar,Ashish Seth,Nishit Anand,Utkarsh Tyagi,Sonal Kumar,Sreyan Ghosh,Dinesh Manocha", "background": "大型语言模型（LLMs）的迅速发展让全能模型能够作为语音助手，理解口语对话。这些模型可以处理包括文本、语音和视觉数据在内的多种输入，这使得情境感知交互成为可能。然而，当前的基准测试在全面评估模型在多模态响应生成时的性能方面有所不足，尤其是在理解细微的语音特性（如音调、情感、音色和音量）以及环境声学上下文（如背景噪音）方面，也不充分评估模型将言语副语言线索与互补的视觉信号对齐的能力，以指引其响应。", "innovation": "我们介绍了MultiVox，这是第一个专为评估语音助手整合口语和视觉线索（包括副语言语音特征）以实现真正多模态理解能力设计的基准测试。MultiVox包括1000个人类标注和录制的口语对话，涵盖了各种副语言特征以及各种视觉线索，如图片和视频。我们的实验表明，尽管人类在这些任务上表现出色，但目前的模型在生成上下文相关响应方面仍面临挑战。", "conclusion": "尽管人类在多模态任务中表现出色，但当前模型在生成上下文相关响应方面仍然存在不足。MultiVox基准测试旨在评估语音助手融合语音和视觉线索的能力，以实现真正的多模态理解。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15220", "html_url": "https://arxiv.org/abs/2506.15220", "title": "video-SALMONN 2: 增强型音频-视觉大型语言模型", "title_en": "video-SALMONN 2: Caption-Enhanced Audio-Visual Large Language Models", "authors": "Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang", "background": "本文介绍了视频-SALMONN 2，这是一个音频-视觉大型语言模型家族，其在视频描述和问答（QA）任务上取得了前所未有的最新研究成果。该模型的核心贡献在于引入了一种多轮直接偏好优化（MrDPO）方法，以及一种结合了描述完整性与事实准确性的目标函数。与标准的直接偏好优化（DPO）相比，MrDPO通过定期刷新参考序列，避免了参考数据过时的问题，从而实现了持续改进。这项技术生成的描述比市面上的专有系统（如GPT-4o和Gemini-1.5 Pro）更为详细且准确。作者进一步通过使用该模型生成高质量的视频-描述语料库，为新的模型的监督微调提供了支持，从而推动了复杂视频-QA任务的广泛改进。", "innovation": "1. MrDPO（多轮直接偏好优化）：通过周期性地从重新初始化的轻量级适配器中获取最新的偏好来更新参考序列，减少了参考数据过时的问题，使模型能够持续改进。\n2. 描述完整性和事实准确性结合的目标函数：这种方法不仅奖励描述的完整性，还奖励事实的准确性。\n3. 生成高质量的视频-描述语料库用于模型监督微调，从而提升模型在复杂视频-QA任务上的表现。\n4. 实现了3B和7B参数量模型在多种音频-视觉和视觉理解基准上达到业界最新水平，而72B参数量模型则超过了所有开源系统", "conclusion": "通过引入MrDPO、结合描述完整性和事实准确性优化的目标函数、以及生成高质量的视频-描述语料库，video-SALMONN 2在多种广泛使用的音频-视觉和视觉理解基准测试中取得了最新纪录。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.18053", "html_url": "https://arxiv.org/abs/2507.18053", "title": "Resource Consumption Red-Teaming for Large Vision-Language Models", "title_en": "Resource Consumption Red-Teaming for Large Vision-Language Models", "authors": "Haoran Gao,Yuanhe Zhang,Zhenhong Zhou,Lei Jiang,Fanyu Meng,Yujia Xiao,Li Sun,Kun Wang,Yang Liu,Junlan Feng", "background": "资源消耗攻击（RCAs）已经成为大规模语言模型（LLMs）部署中的一个重要威胁。随着视觉模态的集成，RCAs 在大型视觉语言模型（LVLMs）中的风险进一步加剧。然而，现有红队研究主要忽略了视觉输入作为潜在攻击面，导致对 LVLMs 的 RCAs 抵御策略不足。", "innovation": "我们提出了 RECITE（资源消耗红队技术 for LVLMs），首次利用视觉模态触发不可上界的 RCAs 红队技术。首先，我们提出了‘视觉引导优化’，这是一种细粒度的像素级优化，用于获取具有重复输出目标的对抗扰动。然后，我们将扰动注入视觉输入，触发不可上界生成，以实现 RCAs 的目标。实验证明，RECITE 导致服务响应延迟增加了超过26%，产生额外20%的 GPU 使用率和内存消耗。", "conclusion": "我们的研究揭示了 LVLMs 中的安全漏洞，并建立了一个红队框架，该框架有助于未来对 RCAs 的防御开发。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20890", "html_url": "https://arxiv.org/abs/2507.20890", "title": "$A^2R^2$: 通过注意力导向细化的视觉推理推进图像到LaTeX转换", "title_en": "$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with Attention-Guided Refinement", "authors": "Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai", "background": "Img2LaTeX是一项重要的任务，涉及到将图像中的数学表达式和结构化视觉内容转换为LaTeX代码。近年来，视觉-语言模型（VLMs）在多种视觉理解任务中取得了显著进展，主要是由于它们的强大泛化能力。尽管初期尝试用VLMs来解决Img2LaTeX任务，但其性能仍然不佳。实验证据表明，VLMs在细粒度的视觉元素，如数学公式中的上标和下标方面存在挑战，导致LaTeX生成不准确。因此，需要一种有效的框架来解决这一挑战。", "innovation": "本文提出了$A^2R^2$：注意力导向细化的视觉推理框架，该框架有效结合了注意力定位和迭代细化，使VLMs能够在视觉推理框架中进行自我纠正，并逐步提高LaTeX生成质量。此外，还引入了新的数据集Img2LaTex-Hard-1K，由1100个精心策划和具有挑战性的示例组成，用于严格评估VLMs在任务中的能力。实验结果表明：（1）$A^2R^2$在各种评估指标上显著提高了模型的性能；（2）增加推理轮次可显著提高性能，突显了$A^2R^2$在测试时缩放场景中的潜力；（3）消融研究和其他评估确认了本文方法的有效性和核心组件之间的协同作用。", "conclusion": "本文提出的$A^2R^2$框架显著提高了VLMs在Img2LaTeX任务中的性能，展示了其在测试时缩放场景中的潜力，并通过实验验证了其有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.07450", "html_url": "https://arxiv.org/abs/2509.07450", "title": "GLEAM: 学习在跨视角地理定位中的匹配和解释", "title_en": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization", "authors": "Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Peifeng Ma,Xue Yang,Hongsheng Li", "background": "交叉视角地理定位(CVGL)专注于识别不同视角下同一地理位置的图像之间的对应关系。然而，现有的CVGL方法通常局限于单一观点或模式，并且它们直接的视觉匹配策略缺乏可解释性：它们只能确定两张图像是否对应，但无法解释匹配背后的理由。", "innovation": "该论文提出了GLEAM-C模型，这是一个统一多视角和多模式的跨视角地理定位模型，通过与卫星图像对齐，涵盖了无人机图像、街道地图、全景图和地面照片。为了弥补传统CVGL方法在可解释性方面的不足，该论文还提出了GLEAM-X任务，结合了跨视角对应预测和可解释推理，并通过创建双语基准数据集，使用GPT-4o和Doubao-1.5-Thinking-Vision-Pro来生成训练和测试数据，实现了透明和可扩展的地理定位评估。", "conclusion": "GLEAM-C和GLEAM-X构成了一个全面的CVGL管道，该管道将多模态、多视角对齐与解释性对应分析结合起来，实现了准确的跨视角匹配和可解释的推理，推动了地理定位的发展，使模型能够更好地解释和匹配。本文使用的代码和数据集将在此网址公开：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13019", "html_url": "https://arxiv.org/abs/2507.13019", "title": "重新思考视觉语言导航中的体域差距：一种综合研究物理和视觉差异", "title_en": "Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities", "authors": "Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang", "background": "近期的视觉语言导航（VLN）进展很有前景，但它们对机器人移动和控制的理想化假设未能反映以身体为本的部署挑战。本文介绍了一个名为VLN-PE的物理现实性VLN平台，支持人形、四足和轮式机器人。该文章首次系统地评估了几种以自我为中心的VLN方法在实际机器人设置中的表现，涵盖了跨不同技术流水线的动作预测分类模型、稠密的路径点预测的扩散模型，以及无需训练、集成了路径规划的大语言模型。结果显示这些方法因机器人观测空间有限、环境光照变化及碰撞、跌落等物理挑战导致性能显著下降，这也揭示了腿足机器人在复杂环境中的移动限制。尽管当前模型在实际部署中的泛化能力较弱，但VLN-PE提供了一种提高跨体域整体适应性的新途径。研究结果和工具希望鼓励社区重新思考VLN的局限性并推动稳健、实用的VLN模型的发展。", "innovation": "VLN-PE是一个物理现实性的VLN平台，支持不同类型机器人。它首次系统性地评估了几种VLN方法在实际机器人设置中的表现，主要创新包括：1) 提供了一个支持不同类型机器人的物理现实平台；2) 系统性地评估了三种不同的VLN方法；3) 首次在物理设置中检验了大语言模型在路径规划中的应用；4) 揭示了机器人在复杂环境中的视觉和物理限制。该平台高度扩展，可以集成新的场景，进一步增强VLN评估的全面性。", "conclusion": "尽管当前模型在实际部署中的泛化能力较弱，但VLN-PE提供了一种新的途径来提高跨体域的整体适应性。研究结果和工具希望鼓励社区重新思考VLN的局限性，并推动稳健和实用的VLN模型的发展。该研究不仅为VLN领域提供了新的见解，还为未来的改进指明了方向。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13142", "html_url": "https://arxiv.org/abs/2507.13142", "title": "从根到回报: 通过强化学习进行动态树推理", "title_en": "From Roots to Rewards: Dynamic Tree Reasoning with Reinforcement Learning", "authors": "Ahmed Bahloul,Simon Malberg", "background": "现代语言模型通过链式思维（CoT）推理（Wei et al., 2023）和检索增强（Lewis et al., 2021）来应对复杂的疑问，但在误差传播和知识整合方面存在局限性。尽管Probabilistic Tree-of-Thought (ProbTree)(Cao et al., 2023)框架通过分层结构分解问题并结合参数化和检索知识进行置信加权聚合来解决这些问题，但它也存在着静态实施的两个主要限制：推理树在初始构建阶段固定，无法根据中间结果进行动态调整；每个节点需要评估所有可能的解决方案策略，导致计算效率低下。", "innovation": "本文提出了一种基于强化学习的动态框架，将基于树的推理过程转变为适应性的过程。该框架根据实时的信心评估逐步构建推理树，学习动作选择（分解、检索或聚合）的最优策略。这不仅保持了ProbTree的概率严谨性，还通过选择扩展和集中资源分配提高了解决方案质量和计算效率。这项工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性及其在现实世界问答系统中所需的灵活性。", "conclusion": "本文的研究为树结构推理提供了一种新的范式，通过强化学习实现基于树的动态推理过程，既保持了概率框架的严谨性，又提高了推理的灵活性和效率。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21117", "html_url": "https://arxiv.org/abs/2509.21117", "title": "TrustJudge：LLM-as-a-Judge的不一致性及缓解方法", "title_en": "TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them", "authors": "Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang", "background": "大规模语言模型（LLMs）作为自动评估者（LLM-as-a-judge）的应用揭示了当前评估框架中的关键不一致性。作者识别出两类基本的不一致性：1）评分对比不一致性，低分回答在对一对的比较中可能优于高分回答；2）二元关系不一致，表现为循环偏好链（A>B>C>A）和等价矛盾（A=B=C≠A）。这些问题来源于离散评分系统中信息的损失以及双重评价过程中含糊的平局判断。", "innovation": "作者提出了TrustJudge，一种概率框架，通过以下两大创新来解决上述局限性：1）分发敏感评分，从离散评分概率中计算连续预期，保持信息熵以实现更精确的评分；2）似然性有意识聚合，使用双向偏好概率或困惑度解决二元关系不一致性。", "conclusion": "作者的研究提供了LLM-as-a-judge框架中评估框架不一致性的首次系统性分析，既提供了理论见解也提供了可靠自动评估的实用解决方案。该框架在Llama-3.1-70B-Instruct作为评估者时，能够减少评分对比不一致性8.43%（从23.32%降至14.89%），二元关系不一致性10.82%（从15.22%降至4.40%），同时保持更高的评价准确率。该框架在不同模型体系和规模中显示出一致性改进，无需额外训练或人工注释即可实现更可信的LLM评估。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16378", "html_url": "https://arxiv.org/abs/2509.16378", "title": "长时和多模态录音系统以捕捉AI和病患诊疗会话的真实世界对话：协议", "title_en": "Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol", "authors": "Misk Al Zahidy,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Ana Cristina Proano,Ana Gabriela Claros,Maria Lizarazo Jimenez,David Toro-Tobon,Victor M. Montori,Oscar J. Ponce-Ponte,Juan P. Brito", "background": "医疗人工智能的前景取决于从能反映患者和医疗人员关注的数据中学习。目前，大多数模型都是通过电子健康记录（EHR）进行训练的，而EHR主要记录生物测量数据，鲜少包含患者和医疗人员之间的互动，尽管这种互动对于诊疗至关重要。因此，仅通过EHR训练的人工智能系统存在陷入狭窄的生物医学视角的风险，忽略了贯穿诊疗过程的实际交流。本研究旨在设计、实现并评估一种长时、多模态的病患-医疗人员互动记录系统，通过将360度视频/音频录制、调查及EHR数据链接起来，构建用于AI研究的数据库。该研究在梅奥诊所的学术门诊内分泌学诊所进行。符合条件的成年患者在接受参与医生面对面咨询时被邀请参与，每场会诊均有360度视频/音频录制，并在会诊结束后完成关于同理心、满意度、节奏和治疗负担的调查。从EHR中提取人口统计学和临床数据。通过五个端点评估可行性：医生同意、患者同意、录音成功、调查完成和多种模式数据的链接。2025年1月开始招募，至2025年8月，97%的符合条件医生（36人中的35人）和75%被邀请的患者（281人中的212人）提供了同意，记录和调查完成的会诊分别为76%和96%。", "innovation": "本研究创新之处在于设计了一种长时、多模态的病患-医疗人员互动记录系统，通过结合360度视频/音频录制、患者调查和EHR数据，创建了一个可以用于AI研究的复合数据库，弥补了传统电子健康记录中缺乏病人-医疗人员互动记录的空白。该系统还提供了可复制的框架和工作流程，为后续研究和AI模型提供了模板。", "conclusion": "本研究展示了可复制框架的可行性，用于捕捉病患-医疗人员互动的多模态动态。通过详细说明工作流、端点和伦理保障，该研究为纵向数据库和集成复杂护理的AI模型提供了模板，为未来的研究和应用打下了基础。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19517", "html_url": "https://arxiv.org/abs/2509.19517", "title": "大型语言模型中的认知负荷限制：多跳推理测评", "title_en": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "authors": "Sai Teja Reddy Adapala", "background": "大型语言模型在其性能上的静态基准和在动态、信息丰富环境中的脆弱性之间存在关键差距。虽然这些模型在单一任务上表现出色，但是它们在认知负荷下的推理计算极限仍不明确。本研究探讨了认知负荷对模型多跳推理能力的影响，并通过设计新的测评框架来系统性地分析认知负荷的影响因素。", "innovation": "提出了一个正式的认知计算负荷理论，认为与任务无关的信息（Context Saturation）和任务切换引起的认知干扰（Attentional Residue）是影响表现的关键机制。设计了交错认知评估（ICE）基准测试来系统性地操控这些负荷因素。通过一项全面的研究（每个项目在200个问题上进行10次重复），揭示了五个指令调优模型在认知负荷下的显著表现差异。", "conclusion": "认知负荷是推理失败的关键因素，动态且认知意识的应力测试对于评估先进AI系统的真正韧性和安全性是必要的。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14843", "html_url": "https://arxiv.org/abs/2507.14843", "title": "无形的缰绳：为什么RLVR可能或可能无法逃脱其起源", "title_en": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin", "authors": "Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi", "background": "近年来，大型语言模型（LLMs）的发展突显了强化学习与价值回传（RLVR）作为一种增强AI解决复杂逻辑任务能力的方法的有效性。然而，当前RLVR实践是否真正扩展了模型的推理边界，而不是仅仅放大了基模型已知的高奖励输出以提高精确度，这个问题尚不明确。因此，本研究通过实证调查，揭示了当前RLVR实践可能存在的限制。研究表明，当前RLVR机制可能作为一种支持约束的优化机制，限制了发现完全原创解决方案的可能性，依然受到基模型初始分布的约束。此外，还发现了一个熵-奖励权衡：尽管当前RLVR方法可靠地提高了精确度，但可能逐渐缩小了探索范围，有可能忽视正确但未充分代表的解决方案。广泛的实证实验验证了尽管当前RLVR方法连续提升了一次通过率，但在较大采样预算下，经验支持的缩小通常超过了经验支持的扩展，未能重塑基模型可访问的正确答案。研究还观察到，尽管RLVR有时增加了标记级别的熵，使得每次生成步骤更具不确定性，但答案级别的熵却减少，表明这些看似更不确定的路径最终收敛于一个更小的、独特的答案集合。", "innovation": "本研究通过实证调查揭示了当前RLVR实践可能存在的限制，重点关注在支持约束条件下RLVR可能限制原始解决方案发现，以及一种熵-奖励权衡：尽管可能提高精确度，但探索范围被逐渐缩小，可能导致正确但未充分代表的解决方案被忽视。研究结果表明，当前RLVR方法在扩展推理范围方面可能存在局限，未来算法创新可能需要明确的探索机制或混合策略来填补不足。", "conclusion": "当前RLVR方法在扩大推理范围方面存在局限，可能限制原始解决方案的发现，存在熵-奖励权衡，尽管可能提高精度但探索范围逐渐缩小，可能忽略正确但未充分代表的答案。未来可能需要新的算法创新，如明确的探索机制或混合策略来打破这种无形的缰绳。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21351", "html_url": "https://arxiv.org/abs/2509.21351", "title": "随机直接偏好优化在医学影像报告生成中的应用", "title_en": "Random Direct Preference Optimization for Radiography Report Generation", "authors": "Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev", "background": "医学影像分析中的放射影报告生成（RRG）因有潜力减轻放射科医生的工作负担而受到了广泛关注。尽管取得了许多进步，当前方法尚未达到在临床环境中部署所需的高质量标准。大型视觉语言模型（VLMs）在一般领域取得了显著进展，通过采用原本设计用于大型语言模型（LLMs）的训练策略，如对齐技术。", "innovation": "本文介绍了一种模型通用框架，通过直接偏好优化（DPO）增强RRG精度。该方法采用了随机对比采样来构建训练对，无需使用奖励模型或人类偏好注释。实验表明，仅通过增强三种最先进的模型，我们的方法在临床性能指标上提高了最多5%，且不需要任何额外的训练数据。", "conclusion": "我们的方法在不增加额外训练数据的情况下，显著提高了RRG的临床性能，达到了提高报告生成质量的目标。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0导致稀疏自编码器中的错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器(SAEs)从大规模语言模型(LLM)内部激活中提取特征，这些特征应对应于可解释的概念。SAE的核心超参数是L0，它表示每个标记平均应激活的SAE特征数量。已有研究通过稀疏性重建权衡图来比较SAE算法，这暗示L0是一个可以自由选择的参数，除了对其重建效果的影响外没有单一的正确值。这项工作研究了L0对SAEs的影响，并发现如果L0设置不正确，SAE将无法解码LLM的底层特征。如果L0设置过低，SAE会混合相关特征以提高重建质量；如果L0设置过高，SAE会找到混杂特征的退化解决方案。此外，研究提出一个代理指标，可以帮助指导在给定训练分布下寻找合适的L0。我们在玩具模型中验证了该方法的正确性，并且该方法与LLM SAEs中的稀疏探针性能峰值一致。研究发现，大多数常用的SAE具有过低的L0值，需要正确设置L0以训练出具有正确特征的SAE。", "innovation": "提出一个代理指标来帮助指导在给定训练分布下寻找合适的L0值，且该方法可以在玩具模型中验证正确性，并与LLM SAEs中的稀疏探针性能峰值一致。此外，研究发现大多数常用的SAE具有过低的L0值，强调正确设置L0是必要的。", "conclusion": "需要正确设置L0以训练出具有正确特征的稀疏自编码器。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 一种对比性价值对齐行为度量", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能对齐人类价值观是一个紧迫而未解决的问题。现有方法缺乏定量衡量价值对齐的指标。因此，本文提出EigenBench：一种黑盒方法，用于比较性地评测语言模型的价值观。该方法通过一组模型、描述价值系统的宪法以及场景数据集，来生成每个模型的价值对齐得分向量。这通过让每个模型对其他模型的输出进行多场景评估，并使用EigenTrust算法汇总这些评估，来实现这一目标。EigenBench 不依赖于具体的正确标签，而旨在量化主观特质，这些特质在不同评判者间可能无法达成一致。为验证方法的有效性，作者收集了人类对同样一组模型的判断，并表明EigenBench 的判断与人类评价者的判断高度一致。此外，EigenBench 还能够不依赖客观标签而恢复 GPQA 基准模型的排名，这支持了该方法作为评价缺乏客观标签的主观价值框架的有效性。", "innovation": "提出EigenBench，一种黑盒方法，用于比较性地评测语言模型的价值观。该方法通过让每个模型对其他模型的输出进行多场景评估，并使用EigenTrust算法汇总这些评估来生成每个模型的价值对齐得分向量。此外，它能够不依赖客观标签而恢复现有基准模型的排名，支持其作为评价缺乏客观标签的主观价值框架的有效性。", "conclusion": "EigenBench 的方法与人类评价者的判断高度一致，且能够在没有客观标签的情况下恢复 GPQA 基准模型的排名，表明该方法在评估无法用客观标准衡量的主观价值观方面具有扎实的基础和实用价值。"}
{"llm_update_time": "20250929", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21124", "html_url": "https://arxiv.org/abs/2509.21124", "title": "通过学习多样化的思维链模式扩展基础模型的推理潜力", "title_en": "Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns", "authors": "Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai", "background": "大型推理模型在解决具有挑战性的数学推理问题方面取得了进展，主要依靠强化学习（RL）。在模型训练中期引入长思维链（CoT）数据已被证明可以显著提高推理深度。然而，当前的方法往往毫无选择地利用CoT数据，留下了关键问题：哪些数据类型最有效地增强模型的推理能力。这篇论文首次定义了基础模型的推理潜力，即回答问题所需的独立尝试次数的倒数，与最终模型性能紧密相关。研究表明，这些类型的推理模式增加了模型的推理潜力。因此，研究者提出了利用富含高价值推理模式的多样化数据的方法。", "innovation": "提出了一种基于多样化的思维链模式的学习方法，通过抽象自CoT序列中的原子推理模式，并结合链粒度算法和标记熵，高效地从数据池中选择与核心集匹配的高价值CoT数据，使得增强后的模型能够更有效地掌握推理。结果，仅10B标记的CoTP数据就使85A6B MoE模型在2024和2025年的AIME竞赛上的性能提高了9.58%，并将下流水准的RL性能上限提高了7.81%。", "conclusion": "通过引入多样化的CoT数据和高效的数据选择算法，该研究显著增强了基础模型的推理潜力，展示了多样化的CoT模式在提高模型性能方面的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21352", "html_url": "https://arxiv.org/abs/2509.21352", "title": "改善自闭症检测的多模态行为分析", "title_en": "Improving Autism Detection with Multimodal Behavioral Analysis", "authors": "William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla", "background": "由于自闭症谱系障碍（ASC）诊断过程复杂且资源密集，已有多种基于计算机辅助诊断支持的方法通过分析患者视频数据中的行为线索来检测自闭症。虽然这些模型在某些数据集上显示出了积极的结果，但它们在眼睛特征表现不佳和缺乏现实世界的通用性上存在挑战。", "innovation": "我们分析了一个标准化的视频数据集，包含168名ASC患者（46%女性）和157名非自闭症患者（46%女性），据我们所知，这是迄今为止最大且最均衡的数据集。我们对面部表情、语音语调、头部运动、心率变异性和眼动行为进行了多模态分析。为了解决先前眼动模型的局限性，我们引入了新颖的统计描述符来量化眼动角度的可变性，提高了基于眼动的分类准确性从64%到69%。使用晚期融合，我们实现了74%的分类精度，证明了跨多个模态整合行为标志的有效性。我们的研究结果突显了多模态视频筛查工具在自闭症评估中的潜在应用。", "conclusion": "我们的研究结果显示了多模态视频筛查工具在自闭症评估中的潜力，通过整合面部表情、语音语调、头部运动、心率变异性和眼动行为的多模态信息，提高了诊断的准确性，为未来的自闭症筛查提供了新的方法和方向。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21356", "html_url": "https://arxiv.org/abs/2509.21356", "title": "基于短语的自动生成的胸片报告事实核查", "title_en": "Phrase-grounded Fact-checking for Automatically Generated Chest X-ray Reports", "authors": "Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C.L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood", "background": "随着大规模视觉语言模型（VLM）的出现，现在已经有可能生成与胸部X光图像外观逼真的放射学报告。然而，在推理过程中产生的描述中事实错误和幻觉阻碍了其临床应用。本文背景在于现有模型在生成描述时容易出现错误和幻觉，影响了它们在医疗实践中的应用。", "innovation": "本文提出了一种新型短语导向的事实核查模型（FC模型），该模型可通过检测自动生成的胸片报告中发现及其所在位置的错误来进行错误纠正。该模型通过合成数据集对报告中的错误进行模拟，该数据集是通过对真实报告中的发现及其位置进行扰动形成的，包括真实的和虚假的发现-位置配对。模型采用了一个新的多标签跨模态对比回归网络进行训练。该方法在多个胸部X光数据集上的准确性和定位预测表现出了鲁棒性，并在多个数据集中展示了对报告生成器误差检测的有效性，达到了0.997的符合度相关系数，表明其在放射学工作流程中的临床推理中具有实用价值。", "conclusion": "该研究证明了基于短语的事实核查模型在产生准确的发现验证和定位预测方面的有效性，并在多个胸部X光数据集上展示了其在报告生成器中的实际应用价值，为其在放射学工作流程中的进一步应用提供了支持。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21354", "html_url": "https://arxiv.org/abs/2509.21354", "title": "KV-Efficient VLA: 基于RNN门控分块KV缓存加速视觉语言模型", "title_en": "KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache", "authors": "Wanshun Xu,Long Zhuang", "background": "视觉-语言-动作（VLA）模型能够统一机器人感知和控制，但它们的可扩展性受到注意力机制的二次成本限制以及关键-值（KV）记忆在长时间推理中无界增长的制约。虽然最近的方法通过扩展主干架构来提高泛化能力，但它们往往忽视了对实时部署至关重要的推理效率问题。", "innovation": "本文提出了一种模型无关的记忆压缩框架KV-Efficient VLA，该框架通过引入一种轻量级且易于训练的机制来选择性保留高实用价值的上下文，解决了上述限制。具体来说，该方法将KV缓存分割成固定大小的块，并使用递归门控模块根据学习到的实用性评分来总结和筛选历史上下文，从而保持了近期的细节并积极修剪过时、低相关性的记忆，同时保持了因果关系。理论上，KV-Efficient VLA 比例可达1.21倍的推理速度提升和36%的内存减少，同时对任务成功的影响最小。该方法无缝集成到现有的自回归和混合VLA堆栈中，无需修改训练管道或下游控制逻辑，实现了可扩展的推理。", "conclusion": "KV-Efficient VLA通过引入一种轻量级且易于训练的机制，解决了VLA模型在长时推理中的记忆压缩效率问题，有效提高了推理速度并减少了内存占用，同时对任务成功率的影响较小。该方法无缝集成现有系统，实现了实时部署中的高效推理。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21363", "html_url": "https://arxiv.org/abs/2509.21363", "title": "一种结合多监督的互学习方法用于目标显著性检测", "title_en": "A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised", "authors": "Runmin Wu,Mengyang Feng,Wenlong Guan,Dong Wang,Huchuan Lu,Errui Ding", "background": "尽管最近深度学习在显著物体检测方面取得了显著进展，但由于物体内部复杂性和卷积及池化操作引起的不准确边界，预测的显著性图仍然存在不完整的问题。为了解决这些问题，论文提出通过显著物体检测、前景轮廓检测和边缘检测的交叉监督训练显著性检测网络，以生成均匀亮化的显著性图，并同时指导彼此，提高前景轮廓预测精度，减少边缘预测中的局部噪声。此外，还开发了一种新颖的互学习模块（MLM），作为方法的构建模块，通过互学习方式训练多个网络分支，显著提升了性能。", "innovation": "提出了结合多监督的互学习方法，通过显著物检测、前景轮廓检测和边缘检测的交织监督训练显著性检测网络，同时提出了一种新颖的互学习模块（MLM），该方法在多个复杂数据集上表现出了优于现有技术的结果。", "conclusion": "广泛的实验表明，提出的互学习方法在显著物体检测和边缘检测方面的表现均达到了最先进的水平。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21360", "html_url": "https://arxiv.org/abs/2509.21360", "title": "针对文本到图像模型中安全过滤器的多模态提示拆分攻击", "title_en": "Multimodal Prompt Decoupling Attack on the Safety Filters in Text-to-Image Models", "authors": "Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen", "background": "文本到图像（T2I）模型在各行各业中被广泛应用于生成高质量图像，但这些模型也可能被滥用，通过劫持攻击生成不宜工作（NSFW）的内容。现有的劫持方法主要通过操控文本提示，但对基于图像的输入存在潜在的安全漏洞。此外，基于文本的方法在规避模型的安全过滤器时也面临挑战。针对这些局限性，提出了多模态提示拆分攻击（MPDA），利用图像模态分离原始不安全提示中的有害语义成分。", "innovation": "MPDA 采用大型语言模型（LLM）拆分不安全提示为伪安全提示和有害提示，并通过重写有害提示生成自然的对抗提示以绕过安全过滤器，指导 T2I 模型生成 NSFW 输出。该攻击通过视觉语言模型生成图像描述，为 LLM 提供了新的路径以在迭代中重新编写并精炼生成的内容，确保生成的 NSFW 图像与原始不安全提示的语义一致性。", "conclusion": "该方法通过多模态提示拆分攻击，不但突破了文本劫持的固有限制，还增强了对图像输入的分析，提供了一种更有效地绕过 T2I 模型安全过滤器的新途径。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21358", "html_url": "https://arxiv.org/abs/2509.21358", "title": "MDF-MLLM：通过跨模态特征对齐实现深度融合以实现上下文感知的眼底图像分类", "title_en": "MDF-MLLM: Deep Fusion Through Cross-Modal Feature Alignment for Contextually Aware Fundoscopic Image Classification", "authors": "Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen", "background": "现有跨模态大型语言模型（MLLMs）在捕捉诊断视网膜疾病（如青光眼、糖尿病视网膜病变和色素性视网膜炎）所需的低级空间细节方面存在不足。研究文献集中在通过结合详细的图像特征和全局文本语境来提高视网膜底片图像的疾病分类准确性，特别是在处理视网膜疾病的分类时，需要融合视觉特征和文本信息来提升模型的性能和解释性。", "innovation": "提出了一个新的多模态深度学习架构（MDF-MLLM），它通过将来自四个U-Net编码器层的跳频特征集成到LLaMA 3.2 11B MLLM的交叉注意块中，实现视觉和文本特征的融合。该模型通过多尺度特征融合提高了疾病分类的准确性，并且在此交互式模型中，通过交叉注意力和FiLM机制将视图特征按部分投影和融合。实验结果显示，MDF-MLLM在视网膜疾病类型的双任务分类中的准确率高达94%，相较于基线模型提高了56%，尤其是对于内容丰富的临床文本，其召回率和F1分数分别提高了67%和35%。", "conclusion": "MDF-MLLM 提供了一个可扩展、可解释和模块化的眼底图像分类框架，通过多模态融合提高了分类性能。研究表明，通过多尺度特征融合，基线模型的性能得到了显著提高。未来的工作将探索同步训练技术，扩大疾病池以增强泛化能力，并将模型扩展用于分割任务，有望在临床辅助决策系统中实现实际部署。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21368", "html_url": "https://arxiv.org/abs/2509.21368", "title": "在建筑工地使用AI进行脚手架安全性评估", "title_en": "Safety Assessment of Scaffolding on Construction Site using AI", "authors": "Sameer Prabhu,Amit Patwardhan,Ramin Karim", "background": "在建筑行业中，安全评估对确保资产的可靠性及工人的安全至关重要。作为关键结构支撑资产的脚手架，需要定期检查以发现可能损害其完整性和稳定性的设计规则偏差。目前，检查主要依赖于视觉检查，由现场管理人员或认证人员执行。然而，视觉检查耗时且易出错，可能导致不安全的状况发生。", "innovation": "本文探讨了使用人工智能（AI）和数字化技术提高脚手架检查的准确性和安全性的方法。提出了一种基于云的AI平台，用于处理和分析脚手架结构的点云数据。该平台通过将认证参考数据与最近的点云数据进行比较和评估来检测结构修改，从而实现自动监控脚手架，减少手动检查所需的时间和努力，提高工地安全水平。", "conclusion": "该研究提出了使用AI进行脚手架检查的新方法，通过自动监控减少视觉检查的时间和错误，有助于提高建筑工地的安全水平。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21383", "html_url": "https://arxiv.org/abs/2509.21383", "title": "LongiMam模型用于使用纵向乳腺X光片改进乳腺癌风险预测", "title_en": "The LongiMam model for improved breast cancer risk prediction using longitudinal mammograms", "authors": "Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau", "background": "乳腺癌筛查需要强大的模型，能够利用纵向影像数据。当前大多数基于深度学习的模型依赖单一或有限的历史乳管摄影影像，并不适用于不平衡结果分布和异质性随访的现实场景。在临床筛查环境中，乳管摄影影像的数据量分布通常呈现不均衡病例与对照的比例。", "innovation": "研究开发了LongiMam，这是一种端到端的深度学习模型，能够整合当前和最多4次之前乳管摄影影像，结合卷积神经网络和循环神经网络来捕捉预测乳腺癌的空间和时间模式。该模型在具有不成比例病例对照比例的大型、基于人口的筛查数据集上进行了训练和评估。研究表明，包括先前和当前就诊比单次就诊模型表现出更好的预测性能，进一步强调了结合历史和近期信息的重要性。该研究还确认了模型在不同风险群体中的有效性，包括拥有致密乳房的女性和55岁及以上的女性，并且在随时间观察到乳腺密度变化的女性中表现最佳。", "conclusion": "纵向建模能够增强乳腺癌的预测，支持在筛查项目中使用重复的乳管摄影影像以精化风险分类。LongiMam作为一个开源软件已经公开提供。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21365", "html_url": "https://arxiv.org/abs/2509.21365", "title": "MAJORScore：通过联合表示评估多模态相关性的新型指标", "title_en": "MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation", "authors": "Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin", "background": "目前的多模态相关性指标通常依赖于预训练对比学习模型的嵌入能力来评估双模态数据之间的相关性（例如，CLIP）。然而，常用的评估指标仅适用于两个模态之间关联性分析，这极大地限制了对多模态相似度的评估能力。", "innovation": "本文提出了MAJORScore，这是一个全新的用于评估N种模态（N>=3）之间相关性的指标，通过多模态联合表示首次实现了这一点。多模态联合表示能将多种模态整合到同一潜在空间中，能准确地在同一尺度上表示不同模态，为公平的相关性评分提供了支持。实验表明，MAJORScore相比现有方法在一致模态评估中有26.03%-64.29%的提升，在不一致模态评估中下降13.28%-20.54%。MAJORScore能够更可靠地评估大规模多模态数据集间的相似性和多模态模型的性能。", "conclusion": "MAJORScore作为一个更可靠的评估指标，为大规模多模态数据集相似性评估和多模态模型性能评估提供了更有价值的参考。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21375", "html_url": "https://arxiv.org/abs/2509.21375", "title": "自动化生成创意和反事实的文字图像合成提示", "title_en": "Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis", "authors": "Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens", "background": "随着大规模多模态训练的进展，文本到图像生成技术取得了快速进步，但精细的控件性仍然是一个关键挑战。反事实控件性，即生成与常识模式相违背的图像的能力，仍然是一个重要的挑战，但对创意和探索性应用至关重要。因此，针对这一不足，本文聚焦反事实大小控件性，提出了一种自动提示工程框架，该框架可以将基础提示转换为反事实图像的修订提示。", "innovation": "本文提出了一个自动提示工程框架，该框架包含三个组件：图像评估器、监督提示重写器以及基于DPO的排名器。同时，还构建了第一个反事实大小的文本图像数据集，并通过改进Grounded SAM，提高了形象评估器的表现，相较于基底提升了114%。实验表明，该方法优于最先进的基础模型和ChatGPT-4o，为未来研究反事实控件性奠定了基础。", "conclusion": "本文提出的方法在反事实控件性图像生成领域超越了当前最先进的模型，为后续研究提供了坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21384", "html_url": "https://arxiv.org/abs/2509.21384", "title": "评估流行CNN模型与大脑在情感评估中的对齐", "title_en": "Assessing the Alignment of Popular CNNs to the Brain for Valence Appraisal", "authors": "Laurent Mertens,Elahe' Yargholi,Laura Van Hove,Hans Op de Beeck,Jan Van den Stock,Joost Vennekens", "background": "卷积神经网络（CNNs）已经在多种计算机视觉任务中显示出巨大潜力。这些模型还被认为是心理学中的一个有趣研究对象，显示出其工作原理与人类大脑之间的对应关系。然而，这些对应关系主要是在普通视觉感知的背景下进行研究的。本研究旨在探讨这种对应关系是否也适用于更复杂的认知过程——社会认知。", "innovation": "本研究通过相关分析评估了流行的CNN模型与人类行为和fMRI数据之间在情感评估上的对齐情况。研究表明，这些模型在这一任务中难以超越简单的视觉处理，并不能反映更高级的大脑处理过程。此外，本研究提出了Object2Brain框架，该框架结合了GradCAM和对象检测，以及在CNN-过滤器层面进行的相关分析，以研究不同对象类别对CNN-人类相关性的影响。", "conclusion": "尽管存在类似的相关性趋势，但不同的CNN模型对不同类别对象的敏感性表现出差异。由此表明，现有的CNN模型在处理涉及社会认知的情感评估任务时仍有待改进。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21376", "html_url": "https://arxiv.org/abs/2509.21376", "title": "无标记的超分辨显微镜中基于深度学习的In silico协议：网络架构和信噪比依赖性的比较研究", "title_en": "In silico Deep Learning Protocols for Label-Free Super-Resolution Microscopy: A Comparative Study of Network Architectures and SNR Dependence", "authors": "Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo", "background": "光学显微镜在众多行业中广泛应用，但其横向分辨能力通常受限于约200纳米。提高分辨能力的常规方法包括使用昂贵的外部模块或特殊的成像技术如超分辨荧光显微镜，但这并不适用于常规环境下非专业用户。因此，研究主要探讨了利用基于深度学习的非荧光相位成像技术（如Zernike相位对比显微术和相差显微术）进行非荧光超分辨光学显微镜的方法，以评估在不同信噪比下的不同深度神经网络架构表现差异", "innovation": "研究引入了两种深度神经网络（O-Net 和 Theta-Net），评估它们在处理通过原子力显微镜校准的测试样片的纳米级特征图像时的超分辨能力。结果显示，O-Net 和 Theta-Net 在高信噪比条件下表现出色，且在不同信噪比情况下可互补使用。这表明，模型架构和源图像信噪比对模型性能及超分辨图像质量至关重要，进一步证明了该研究方法在无标记超分辨显微镜领域的创新性", "conclusion": "研究结果表明，在相同的训练数据集和训练周期下，不同深度神经网络模型在不同信噪比下的表现存在差异。这证明了利用深度神经网络在无标记光学纳米显微镜中的价值，并强调了模型架构与图像信噪比对超分辨质量的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21398", "html_url": "https://arxiv.org/abs/2509.21398", "title": "骨架稀疏化和稠密化尺度空间", "title_en": "Skeleton Sparsification and Densification Scale-Spaces", "authors": "Julia Gierke,Pascal Peter", "background": "哈密尔顿-雅可比骨架，也称为中心轴，是一种强大的形状描述符，用最大内嵌圆的中心来表示二值对象。尽管在许多应用领域都有广泛的应用，但中心轴对噪声非常敏感：边界的小变化可能导致骨架不必要的扩大。传统修剪方法通过系统地去除多余的骨架分支来缓解这一问题。", "innovation": "提出了骨架尺度空间的概念，通过利用中心轴的稀疏化来实现形状的分层简化。与传统的修剪方法相比，该框架自然满足关键尺度空间属性，如分层结构、可控简化以及几何变换不变性。该框架提供了连续和离散形式下的严格理论基础，并通过稠密化进一步扩展了概念，允许从粗到细的逆向进阶，甚至可以超越原始骨架产生冗余的形状表示。", "conclusion": "通过概念验证实验，作者展示了该框架在实际任务中的有效性，如鲁棒骨架提取、形状压缩和增加增材制造的刚度。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21394", "html_url": "https://arxiv.org/abs/2509.21394", "title": "借助大型AI模型的生成语义通信在图像传输中的应用", "title_en": "Large AI Model-Enabled Generative Semantic Communications for Image Transmission", "authors": "Qiyu Ma,Wanli Ni,Zhijin Qin", "background": "生成AI的快速发展为提升语义通信系统中图像传输的效率和准确性提供了重要机会。然而，现有方法往往忽视了图像不同区域的重要程度差异，可能会影响视觉关键内容的重建质量。", "innovation": "提出了一种创新的生成语义通信系统，通过将图像细分为关键和非关键区域，细化语义粒度。关键区域使用面向图像的语义编码器进行处理，而非关键区域通过图像到文本的建模方法进行高效压缩。此外，为了减轻大模型带来的存储和计算需求，系统采用了轻量级部署策略，结合模型量化和低秩适应微调技术，显著提高了资源利用率，同时保持性能。", "conclusion": "仿真结果表明，所提出系统在语义保真度和视觉质量方面优于传统方法，从而证明了其在图像传输任务中的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21387", "html_url": "https://arxiv.org/abs/2509.21387", "title": "稀疏子网络是否展示认知对齐的注意力？剪枝对注意图保真度、稀疏性和概念连贯性的影响", "title_en": "Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence", "authors": "Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi", "background": "先前的研究表明，神经网络可以通过大量剪枝来保留性能，但剪枝对模型可解释性的影响仍然不明确。本文通过研究基于幅度的剪枝后继微调对低级刺激图和高级概念表示的影响，探讨了这一问题，以期更好地理解剪枝的潜在影响。", "innovation": "本文通过在ImageNette上训练的ResNet-18模型，比较了基于Vanilla Gradients (VG) 和 Integrated Gradients (IG) 的后验解释在不同剪枝水平下的表现，评估了稀疏性和忠実性，并通过CRAFT基的概念抽取出学习概念的语义连贯性变化进行追踪，揭示了轻度到中度剪枝可以提高刺激图的聚焦度和忠実性，同时保留有意义的概念，而过度剪枝则会合并异质特征，降低刺激图的稀疏性和概念连贯性。", "conclusion": "研究表明，适度剪枝可以改善刺激图的聚焦度和忠实时性，同时保留具有语义意义的概念。然而，过度剪枝会合并异质特征，尽管保持准确率，但仍降低刺激图的稀疏性和概念连贯性。这意味着虽然剪枝可以引导内部表示向更符合人类关注的模式转变，但过度剪枝会损害可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21377", "html_url": "https://arxiv.org/abs/2509.21377", "title": "动态多目标融合以实现高效视听导航", "title_en": "Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation", "authors": "Yinfeng Yu,Hailong Zhang,Meiling Zhu", "background": "本文研究了通过将机载传感器的视觉观察信息与目标发出的听觉信号动态整合来实现机器人音频声源定位的方法。核心挑战在于如何有效利用多模态线索来指导导航。尽管早期的研究探索了视听数据的基本融合，但它们往往会忽视更深一层的感知上下文。本文旨在填补这一空白，提出了用于高效视听导航的动态多目标融合方法（DMTF-AVN），采用多目标架构和改进的Transformer机制来筛选和选择性融合跨模态信息。该方法在Replica和Matterport3D数据集上的广泛实验表明，DMTF-AVN达到了最先进的性能，在成功率、路径效率和场景适应性方面均优于现有方法。另外，该模型展示了强大的可扩展性和通用性，为机器人导航中的多模态融合策略铺平了道路。研究中的代码和视频可以通过这个链接获取：this https URL", "innovation": "本文提出了一种用于高效视听导航的动态多目标融合方法（DMTF-AVN），并采用多目标架构和改进的Transformer机制来筛选和选择性融合跨模态信息。这种方法在多个数据集上的表现优于现有方法，并展示了良好的可扩展性和通用性。", "conclusion": "本文提出的DMTF-AVN方法在多种评估指标上达到了最先进的性能，并且展示出了强大的可扩展性和通用性，为未来多模态融合策略在机器人导航中的应用提供了新的思路。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21379", "html_url": "https://arxiv.org/abs/2509.21379", "title": "SAEmnesia: 使用稀疏自编码器在扩散模型中擦除概念", "title_en": "SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders", "authors": "Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto", "background": "有效在文本到图像扩散模型中进行概念去学习需要精确定位模型潜在空间中的概念表示。尽管稀疏自编码器可以减少神经元的多义性（即，一个神经元对应多个概念），但单个的概念表示仍然可能分布在多个潜在特征中，这需要进行大量的搜索过程来完成概念去学习。背景说明现有方法的问题和挑战，并引出了需要改进的地方。", "innovation": "提出了SAEmnesia，一种监督稀疏自编码器训练方法，通过系统性的概念标记来促进一对一的概念-神经元映射，从而减少特征分散并促进特征集中化。SAEmnesia的学习方式使得神经元具有更专一的概念关联，相较于无监督基线方法有显著提高。此方法在训练期间仅引入少量的交叉熵计算额外开销，在推理时可将超参数搜索减少96.67%。SAEmnesia在UnlearnCanvas基准测试中比最先进的方法提高了9.22%，在连续去学习任务中，展示了28.4%的准确率改进。创新点在于提出了一种新的方法解决了现有方法中的问题，并且在多个评估指标上都优于现有方法。", "conclusion": "SAEmnesia 通过引入一种新的监督稀疏自编码器训练方法，在文本到图像扩散模型中实现了高效的概念去学习，通过学习单一的概念-神经元映射，增强了模型的去学习效果，适用于大规模去学习任务。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21380", "html_url": "https://arxiv.org/abs/2509.21380", "title": "基于类内多样性选择核子集", "title_en": "Coreset selection based on Intra-class diversity", "authors": "Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor", "background": "深度学习模型已经革新了多个领域，特别是在生物医学图像分类领域通过学习复杂的特征，实现了精准的复杂疾病的诊断。现有研究采用两种主要方法训练深度学习模型：从零开始训练和迁移学习。这两种方法都需要大量的计算时间和资源，尤其是在大规模数据集的训练过程中。为了选择最佳的超参数，通常需要进行多次训练，进一步增加了计算需求。面对数据集规模日益庞大的问题，如何优化这一过程成为研究焦点。一种可能的解决方法是从原数据集中选择一部分数据用于训练和超参数搜索，这部分数据被称作‘核子集’，目的是保持原数据集的代表性。然而，随机抽样方法可能导致样本集偏向性较强的类别，即使类别间平衡，也不能捕捉到类内多样性。", "innovation": "本文提出了一个智能而轻量级的核子集选择机制，特别针对类内多样性问题，设计了一种方法来提取类内多样性，形成各分类的簇，用于最终采样。这种方法有效地解决了现有随机抽样方法带来的偏向性问题，能够在保证数据集代表性的同时，更好地捕捉类内多样性，从而提升了模型的分类性能。", "conclusion": "通过在著名生物医学图像数据集上进行广泛的分类实验，证明了本文所提出的方法在多个性能指标上的优越性，明显优于随机抽样方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21401", "html_url": "https://arxiv.org/abs/2509.21401", "title": "JaiLIP: 通过损失导向图像扰动突破视觉-语言模型", "title_en": "JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation", "authors": "Md Jueal Mia,M. Hadi Amini", "background": "视觉-语言模型（VLMs）在生成多模态推理任务方面表现出色，但随着不同攻击途径的增加，VLMs潜在的误用或安全性对齐问题也日益严重。在这些攻击途径中，基于图像的扰动被证明在生成有害输出方面特别有效。许多现有技术已用于锁破解锁VLMs，导致结果不稳定并可见的扰动。在本文中，我们提出了一种新的锁破解锁方法Jailbreaking with Loss-guided Image Perturbation (JaiLIP)，该方法在图像空间中通过最小化清洁图像和对抗性图像之间的均方误差（MSE）损失与模型有害输出损失的联合目标，来实现最小化图像扰动。", "innovation": "提出了一种新的锁破解锁攻击方法JaiLIP，其通过在图像空间中最小化复合损失函数来实现，该函数结合了清洁图像和对抗性图像之间的均方误差损失以及模型的有害输出损失。这种方法在毒性度量标准方面表现出色，生成的对抗性图像既有效又不可见，优于现有方法。此外，还评估了JaiLIP在交通领域的实用性，证明了攻击的实用价值远超特定领域的有害文本生成。", "conclusion": "我们的研究表明，基于图像的锁破解锁攻击具有实际挑战性，需要有效的防御机制来保护VLMs。我们的工作强调了JaiLIP方法的有效性和实用性，为视觉-语言模型的安全性提供了新的视角和策略。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21396", "html_url": "https://arxiv.org/abs/2509.21396", "title": "mmHSense：支持ISAC系统的多模态和分布式毫米波人体感知数据集", "title_en": "mmHSense: Multi-Modal and Distributed mmWave ISAC Datasets for Human Sensing", "authors": "Nabeel Nisar Bhat,Maksim Karnaukh,Stein Vandenbroeke,Wouter Lemoine,Jakob Struye,Jesus Omar Lacruz,Siddhartha Kumar,Mohammad Hossein Moghaddam,Joerg Widmer,Rafael Berkvens,Jeroen Famaey", "background": "这篇文章介绍了mmHSense数据集，这是一个开放标注的毫米波数据集，旨在支持在综合传感与通信(ISAC)系统中的人体感知研究。该数据集可以用于探索不同应用场景下的毫米波ISAC技术，包括手势识别、人员识别、姿势估计和定位。此外，这些数据集还能够促进毫米波ISAC信号处理和深度学习研究的发展。", "innovation": "该数据集为ISAC系统中的人体感知研究提供了宝贵的测试平台，展示了参数高效微调方法，以适应不同的任务需求，极大地减少了计算复杂性同时保持之前的性能水平，为不同的应用提供了广泛的可能性", "conclusion": "文章通过描述测试平台、实验设置和每个数据集的信号特征，验证了数据集在特定下游任务上的效用，并展示了参数高效微调方法的应用，以适应不同任务，显著减少计算复杂性并保持先前任务的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21385", "html_url": "https://arxiv.org/abs/2509.21385", "title": "通过移除和重训练调试概念瓶颈模型", "title_en": "Debugging Concept Bottleneck Models through Removal and Retraining", "authors": "Eric Enouen,Sainyam Galhotra", "background": "概念瓶颈模型（CBMs）通过一组人类可解释的概念来预测最终的任务标签，这使得领域专家不仅能验证CBM的预测结果，还能在测试时干预不正确的概念。然而，这些干预措施未能解决CBM与专家推理之间的系统不一致，特别是在模型从带偏见的数据中学习捷径时。为了解决这个问题，本文提出了一种通用的概念瓶颈模型可解释调试框架，该框架采用两步过程：移除和重训练。在移除步骤中，专家利用概念解释来识别并移除任何不需要的概念。在重训练步骤中，引入了一种新方法CBDebug，该方法利用概念瓶颈模型的可解释性作为桥梁，将概念级别的用户反馈转化为样本级别的辅助标签。这些标签用于应用有监督的偏见缓解和目标增强，从而减少模型对不必要的概念的依赖。本文使用真实专家反馈和自动专家反馈评估了该框架，并发现CBDebug在多个概念瓶颈模型架构（PIP-Net，后验CBM）和具有已知错误相关性的基准测试中显著优于先前的重训练方法", "innovation": "提出了一种通用的可解释调试框架，该框架包含两个步骤：移除不需要的概念并利用概念瓶颈模型的可解释性通过CBDebug方法将用户反馈转化为样本级别的辅助标签，从而减轻模型对错误概念的依赖并减轻偏见。", "conclusion": "CBDebug显著优于当前的重训练方法，在多个概念瓶颈模型架构和具有已知错误相关性的基准测试中均有显著表现。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21451", "html_url": "https://arxiv.org/abs/2509.21451", "title": "VideoJudge: 利用自助法实现大规模LLM作为评分器的视频理解监督", "title_en": "VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding", "authors": "Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj", "background": "准确评估视频理解模型仍然具有挑战性：常用的评估指标如BLEU、ROUGE和BERTScore不能捕捉人类评估的细微差异，而手动获取这种评估代价高昂。最近的工作已经探索了使用大型语言模型（LLMs）或跨模态大型语言模型（MLLMs）作为评估者，但它们在视频理解领域的应用相对较少被研究。因此，应用具有专门性的跨模态大型语言模型（MLLMs）来评估视频理解模型（即，基于视频的文本响应）是一个亟待解决的问题。", "innovation": "本文提出了一种专门用于评估视频理解模型输出的跨模态大型语言模型（MLLM）—VideoJudge，该模型分别有3B和7B两种大小版本。为了训练VideoJudge，研究者利用生成器和评估者的互动：生成器根据目标评分生成相应的响应，不符合评估者评分的响应被删除。VideoJudge-7B在三个核心评估基准中表现优于更大的LLM基准模型，如Qwen2.5-VL（32B和72B）。研究还发现，仅使用LLM进行评分的表现不如使用MLLM，并且链式思考推理也不提升性能，这表明提供视频输入对于评价视频理解任务至关重要。", "conclusion": "通过实验证明，使用专门设计的大规模跨模态语言模型（MLLM）能够有效地评估视频理解模型的输出。在三个核心评估基准中，VideoJudge-7B的表现优于更大的LLM基准模型，且提供视频输入是评价视频理解任务的关键因素。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21386", "html_url": "https://arxiv.org/abs/2509.21386", "title": "ShipwreckFinder：多波束声呐数据中船舰残骸检测的QGIS工具", "title_en": "ShipwreckFinder: A QGIS Tool for Shipwreck Detection in Multibeam Sonar Data", "authors": "Anja Sheppard,Tyler Smithline,Andrew Scheffer,David Smith,Advaith V. Sethuraman,Ryan Bird,Sabrina Lin,Katherine A. Skinner", "background": "船舰残骸是海洋历史的重要标志，通常通过手动检查声纳浴层数据来发现，但这是一个耗时的过程，通常需要专家分析。本研究介绍了一个名为ShipwreckFinder的开源QGIS插件，该插件能够自动处理声纳数据，进行深度学习推理，设定阈值，并生成预测船舰残骸的像素级分割图或边界框。", "innovation": "本研究提出了一种开源工具，其核心是一个基于深度学习的模型，该模型在不同海域的船舰残骸数据上进行了训练，并通过合成数据生成增加了数据集的规模和多样性。与基于深度学习的ArcGIS工具包和传统的反洼坑检测方法相比，本研究的开源工具和训练流程在分割性能上表现出优越性。", "conclusion": "本研究展示了一个开源工具和训练流程，用于自动检测多波束声纳数据中的船舰残骸，该工具和方法在性能上优于现有的一些技术。该开源工具可在该网址: [插入网址] 获得。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21399", "html_url": "https://arxiv.org/abs/2509.21399", "title": "使用单图像超分辨率方法将气候预测细化至1公里", "title_en": "Downscaling climate projections to 1 km with single-image super resolution", "authors": "Petr Košťál,Pavel Kordík,Ondřej Podsztavek", "background": "高分辨率的气候预测对于地方决策至关重要。然而，现有的气候预测产品具有较低的空间分辨率（例如，12.5公里），这限制了它们的实际应用效果。本研究通过利用单图像超分辨率模型将气候预测细化至1公里分辨率，解决了这一限制。由于没有高分辨率的气候预测数据集用于训练，研究团队利用高分辨率的观测网格数据集进行模型训练，并将其应用于低分辨率的气候预测数据。此外，为了评估细化后的气候预测，研究团队提出了一种基于气候指标的方法，使用在气象站位置计算出的观测气候指数来评估细化后的气候预测，不需要高分辨率的气候真实值作为对照。", "innovation": "本研究利用单图像超分辨率模型将现有的低分辨率气候预测数据细化至1公里分辨率，通过使用高分辨率观测网格数据集进行模型训练，这种方法在没有高分辨率气候预测数据集的情况下能够有效提升预测精度，同时保持了气候指标的一致性。", "conclusion": "研究实验表明，单图像超分辨率模型能够将气候预测细节细化至1公里分辨率，且不会增加气候指标的误差，这为高分辨率的气候预测提供了切实可行的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21388", "html_url": "https://arxiv.org/abs/2509.21388", "title": "TUN3D：从未摆姿态的图像走向真实场景理解", "title_en": "TUN3D: Towards Real-World Scene Understanding from Unposed Images", "authors": "Anton Konushin,Nikita Drozdov,Bulat Gabdullin,Alexey Zakharov,Anna Vorontsova,Danila Rukhovich,Maksim Kolodiazhnyi", "background": "室内外场景的理解中，布局估计和3D对象检测是两个基础任务。结合这两个任务，能够创建简洁且具有语义信息的场景空间表示。现有方法大多依赖于点云输入，而大多数消费级相机缺乏深度传感器，因此仅凭视觉数据更为常见。因此，如何在不依赖点云的情况下实现这两个任务成为研究的挑战。TUN3D方法在多视角图像输入的情况下，无需地面真值相机姿态或深度监督，解决了这个问题。", "innovation": "TUN3D 是首个针对真实扫描中多视角图像联合布局估计和3D对象检测的方法。TUN3D 建立了一个轻量级稀疏卷积主干，并采用两个专用头：一个用于3D对象检测，一个用于布局估计，利用了一种新颖且有效的参数化墙体表示法。实验表明，TUN3D 在三个具有挑战性的场景理解基准上实现了领先的效果：一是使用真实点云，二是使用摆姿态图像，三是使用未摆姿态图像。尽管在3D对象检测方面与专门的3D检测方法持平，但在布局估计方面显著进步，为整体室内外场景理解设定了新标准。", "conclusion": "TUN3D 在三个具有挑战性的场景理解基准上均实现了领先效果，特别在布局估计方面有显著的改进。TUN3D 通过多视角图像输入和无需深度监督的方式，为室内外场景理解中的3D检测和布局估计问题提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21559", "html_url": "https://arxiv.org/abs/2509.21559", "title": "X-CoT：基于LLM链式思考推理的可解释文本到视频检索", "title_en": "X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning", "authors": "Prasanna Reddy Pulakurthi,Jiamian Wang,Majid Rabbani,Sohail Dianat,Raghuveer Rao,Zhiqiang Tao", "background": "现有的文本到视频检索系统主要采用嵌入模型进行特征提取，并通过计算余弦相似度来进行排名。然而，这种方法存在两个限制：低质量的文本-视频数据对会影响检索效果，但难以识别。余弦相似度本身无法解释排名结果，限制了可解释性。", "innovation": "提出了X-CoT，这是一个基于LLM的可解释检索框架，替代基于嵌入模型的相似度排名。具体创新包括：扩展现有的基准，增加视频注释以支持语义理解并减少数据偏差；设计了包含成对比较步骤的检索CoT，产生详细的推理并完成排名。X-CoT实验性地提高了检索性能并生成了详细的理由。同时，它促进了模型行为和数据质量分析。", "conclusion": "X-CoT通过基于LLM的链式思考推理提高了文本到视频检索的解释性和性能，增强了对检索模型的评估和对文本-视频数据质量的检查。相关代码和数据可以在提供的链接中获得。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21420", "html_url": "https://arxiv.org/abs/2509.21420", "title": "QuadGPT：使用自回归模型生成本源四边形网格", "title_en": "QuadGPT: Native Quadrilateral Mesh Generation with Autoregressive Models", "authors": "Jian Liu,Chunshi Wang,Song Guo,Haohan Weng,Zhen Zhou,Zhiqi Li,Jiaao Yu,Yiling Zhu,Jing Xu,Biwen Lei,Zhuo Chen,Chunchao Guo", "background": "四边形单元主导的网格生成是专业3D内容创作的基础。然而，现有的生成模型会首先生成三角形网格，然后按照特定规则将三角形合并为四边形，这种做法通常生成的四边形网格具有较差的拓扑结构。因此，需要一种直接生成四边形单元主导网格的端到端方法，以提高生成的几何准确性和拓扑质量。", "innovation": "QuadGPT是一种端到端的自回归框架，用于生成四边形单元主导的网格。其创新之处在于：1）提出了一种统一的标记方法，可以处理三角形和四边形混合拓扑结构；2）采用了一种专门的强化学习微调方法——tDPO，以提高生成质量。", "conclusion": "实验结果表明，QuadGPT在几何准确性和拓扑质量方面显著超越了现有的三角形到四边形转换流水线。我们建立了四边形网格生成的新基准，并展示了结合大规模自回归模型和拓扑感知增强学习方法在创建结构化3D资产方面的巨大潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21419", "html_url": "https://arxiv.org/abs/2509.21419", "title": "Overview of ExpertLifeCLEF 2018: how far automated identification systems are from the best experts?", "title_en": "Overview of ExpertLifeCLEF 2018: how far automated identification systems are from the best experts?", "authors": "Herve Goeau,Pierre Bonnet,Alexis Joly", "background": "近年来，植物和动物的自动识别有了显著进步，特别是在深度学习技术的发展推动下。然而，自动系统与人类专家之间的差距仍然存在。专家们在通过视觉或听觉观察生物时可能会产生困惑或存在意见分歧，这说明仅凭单一图像获取的信息并不充分，难以确定精确的物种。因此，需要量化这种不确定性，并将其与自动系统的性能进行比较，以供计算机科学家和专家自然主义者参考。", "innovation": "为了比较自动系统和人类专家的能力，论文介绍了一项名为ExpertLifeCLEF 2018的挑战竞赛，共有4个研究团队开发了19个深度学习系统，这些系统接受了9位法国植物学家的评估。研究表明，最先进的深度学习模型的性能现在接近甚至等于顶级的专家能力。", "conclusion": "这项工作的主要结果是，最先进的深度学习模型的性能与最先进的人类专业知识之间的差距正在减少。论文详细描述了挑战的资源和评估，总结了参赛研究团队所采用的方法和系统，并进行了主要结果的分析。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21573", "html_url": "https://arxiv.org/abs/2509.21573", "title": "通过在拟变差函数上发现硬负例来增强地理定位的对比学习", "title_en": "Enhancing Contrastive Learning for Geolocalization by Discovering Hard Negatives on Semivariograms", "authors": "Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner", "background": "在大范围准确且鲁棒的基于图像的地理定位是具有挑战性的，因为存在多样化的环境、视觉模糊的场景以及许多区域缺少明显的地标。虽然对比学习方法通过在街景图像和对应位置之间的特征对齐来显示出很有希望的性能，但它们忽略了地理空间中的潜在空间依赖性。因此，它们无法解决视觉和地理上相似但被错误标记为负例的假阴性问题，并且难以有效地区分视觉上相似但在地理上相距较远的硬负例。", "innovation": "研究提出了一种新颖的空间调节对比学习策略，该策略结合了拟变差函数，这是一款用于建模空间相关性随距离变化的地质统计工具。通过将特征空间中的图像距离与地理距离相关联来拟合拟变差函数，从而捕捉预期的视觉内容的空间相关性。利用拟合的拟变差函数，定义给定空间距离下的预期视觉不相似性作为基准，以识别硬负例和假阴性。将这种策略整合到了GeoCLIP中，并在OSV5M数据集上进行了评估，结果显示明确建模的空间先验改善了基于图像的地理定位性能，特别是在更精细的粒度上。", "conclusion": "实验表明，通过在拟变差函数上建模空间先验，可以提高基于图像的地理定位的性能，特别是在更精细的粒度上；提出的空间调节策略能够有效识别出硬负例和假阴性，从而提高了地理定位的准确性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21464", "html_url": "https://arxiv.org/abs/2509.21464", "title": "残差向量量化用于通信高效的多智能体知觉", "title_en": "Residual Vector Quantization For Communication-Efficient Multi-Agent Perception", "authors": "Dereje Shenkut,B.V.K Vijaya Kumar", "background": "多智能体协同感知（CP）通过跨连接的智能体（如自动驾驶汽车、无人机和机器人）共享信息来提升场景理解。然而，通信带宽限制了其扩展性。ReVQom是一种学习特征编解码器，它在压缩中间特征的同时保留空间身份。ReVQom通过一个简单的瓶颈网络和多阶段残差向量量化（RVQ）实现端到端压缩，使得仅需传输每个像素的代码索引，大大减少了数据负载，同时保持了准确率。", "innovation": "ReVQom是一种端到端的特征压缩方法，通过一个简单的瓶颈网络和多阶段残差向量量化（RVQ）来压缩特征维度，仅需传输每个像素的编码索引，使数据负载从未压缩的32位浮点特征的8192位/像素减少至6-30位/像素每智能体，同时保持最小的准确率损失。ReVQom在DAIR-V2X真实世界CP数据集上实现了273倍压缩到1365倍压缩，并在18位/像素时与原始特征CP媲美，低至6-12位/像素时支持超低带宽操作，性能下降平滑。", "conclusion": "ReVQom使多智能体协同感知高效且准确，为实用的V2X部署迈出了一步。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21552", "html_url": "https://arxiv.org/abs/2509.21552", "title": "基于视觉反馈的时空推理学习GUI绑定", "title_en": "Learning GUI Grounding with Spatial Reasoning from Visual Feedback", "authors": "Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim", "background": "GUI接地问题通常被定义为一个坐标预测任务——给定自然语言指令，生成屏幕上的坐标以便执行点击和按键等操作。但是，最近的视觉语言模型在处理具有复杂布局的高分辨率GUI图像时，往往无法准确预测数字坐标。为解决该问题，作者将GUI接地重新定为一种互动搜索任务，其中视觉语言模型生成动作来移动GUI中的光标以定位UI元素。", "innovation": "构建了一个名为GUI-Cursor的模型，该模型基于多步在线强化学习进行训练，使用基于密集轨迹的奖励函数。GUI-Cursor将GUI接地重新定义为一个互动搜索任务，使VLM能够生成光标移动动作以定位UI元素。通过这种互动过程中的渲染光标提供视觉反馈，模型可以更好地将其预测与屏幕上的位置对齐。", "conclusion": "实验结果显示，基于Qwen2.5-VL-7B的GUI-Cursor提升了GUI接地的准确性并实现了在ScreenSpot-v2和ScreenSpot-Pro上的最新成果（分别达到93.9%和56.5%的准确率）。此外，研究发现GUI-Cursor能够在95%的情况下在线解决问题，并能在更困难的问题上进行更多的步骤操作。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21433", "html_url": "https://arxiv.org/abs/2509.21433", "title": "DyME：带有双层正交LoRA适配的扩散模型动态多概念擦除", "title_en": "DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation", "authors": "Jiaqi Liu,Lan Zhang,Xiaoyong Yuan", "background": "文本到图像的扩散模型容易再现受版权保护的风格和视觉概念，这引发了法律和伦理上的关注。概念擦除方法旨在通过微调来选择性地抑制这些概念，但当前的方法在实际应用中难以扩展，尤其是当需要擦除多个和可能冲突的概念时。现有方法的核心瓶颈在于其依赖静态擦除方式：每次微调只有一个检查点来移除所有目标概念，而不考虑推理时的实际擦除需求。这使得模型在实际使用中难以适应各种请求，从而导致擦除效果变差，且非目标内容的保真度降低。", "innovation": "本文提出了DyME，一个按需擦除框架，该框架训练轻量级的概念特定LoRA适配器，并仅在推理时动态组合需要的那一部分。这种方法使得多概念擦除灵活性增强。然而，简单组合适配器会导致适配器之间的干扰，特别是在需要消除大量或语义上相关的概念时。为解决这一问题，引入了在特征和参数级别上的双层正交性约束，以分离表示变化并强制不同适配器子空间正交。此外，还开发了带有品牌系列角色结构的新层次基准ErasureBench-H，它允许在语义粒度和擦除集大小方面进行原理评价。实验结果表明，DyME在ErasureBench-H和标准数据集（如CIFAR-100、Imagenette）上均能优于最先进的基线方法，实现了更高的多概念擦除保真度且几乎没有附带损害。", "conclusion": "DyME框架能够动态适应不同的擦除需求，通过双层正交性约束成功解决了适配器之间的干扰问题，展现了更高的多概念擦除性能，且对非目标内容的保真度影响较小。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21486", "html_url": "https://arxiv.org/abs/2509.21486", "title": "增强推理能力的多模态大型语言模型领域自适应预训练在短视频内容审核中的应用", "title_en": "Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation", "authors": "Zixuan Wang,Yu Sun,Hongwei Wang,Baoyu Jing,Xiang Shen,Xin Dong,Zhuolin Hao,Hongyu Xiong,Yang Song", "background": "短视频平台正在迅速演变，使得识别不适当内容变得越来越重要。现有的方法通常为每种问题类型训练独立的小分类模型，这需要大量的人工标注数据，并且缺乏跨问题的一般化能力。", "innovation": "提出了增强推理能力的多模态大型语言模型（MLLM）的预训练范式，用于统一的不适当内容检测。通过引入三个有针对性的预训练任务来解决短视频内容与MLLM原始预训练数据之间的分布差距，以及复杂的问题定义：（1）Caption，增强MLLM对视频细节的感知；（2）视觉问答（VQA），加深MLLM对问题定义和标注指南的理解；（3）链式推理（CoT），增强MLLM的推理能力。实验结果显示，在零样本和监督微调设置中，我们的预训练方法显著提升了MLLM的性能，并展示了对其它未知问题的强大泛化能力。", "conclusion": "我们的预训练模型在零样本和监督微调设置中均表现出显著的性能提升，并展示了对新出现的、未见过的问题的强泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21466", "html_url": "https://arxiv.org/abs/2509.21466", "title": "沙特职业性别刻板印象：基于语言模型生成图像的分析研究", "title_en": "Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models", "authors": "Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa", "background": "本研究探讨了现代文本转图像的人工智能模型在生成沙特阿拉伯专业人员的图像时，是否继续延续性别刻板印象和文化不准确性的现象。研究选择了ImageFX、DALL-E V3和Grok三种生成模型，并对56种不同专业进行了分析。两个经过培训的沙特注释者评估了每个图像在五个维度上的性别感知、服装和外貌、背景和设置、活动和互动、年龄，总共产生了10,100个单独的评估。研究表明，DALL-E V3在性别刻板印象方面表现得最为严重，男性比例达96%，显示了社会偏见在训练数据中根深蒂固，反映在图像生成中。研究还指出，跨文化误解导致了非典型性图像，而非真正进步的展现。这表明当前模型只能有限地反映沙特劳动力市场的性别动态和文化细微差别，需要更广泛的训练数据、更公平的算法和文化敏感的评估框架以确保公平和真实的视觉输出。", "innovation": "该研究使用受过训练的当地注释者对生成的图像进行多维度评估，并通过统计分析揭示了不同模型生成图像中的性别和文化偏差。通过对比分析，明确了不同模型在性别刻板印象和文化准确性方面的表现差异，特别是指出了DALL-E V3模型中性别刻板印象最严重的问题。这为未来改进AI模型提供了数据支持和具体案例研究。", "conclusion": "当前模型反映了它们如何根据训练数据来强化社会偏见，这仅对沙特劳动力市场中的性别动态和文化细微差别提供了有限的反映。需要寻求更加多样的训练数据、更具公信力的算法和文化敏感性的评估方法来确保生成的图像更加公平和真实。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21628", "html_url": "https://arxiv.org/abs/2509.21628", "title": "从集成表示度量驱动的视觉模型的类型学", "title_en": "A Data-driven Typology of Vision Models from Integrated Representational Metrics", "authors": "Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla", "background": "大型视觉模型在架构和训练范式上存在显著差异，但我们缺乏系统的方法来确定其表示在不同模型家族之间共享的方面以及哪些方面反映了独特的计算策略。本文利用多种表示相似性度量来评估不同模型家族之间的可区分性，发现几何和单元调谐携带家族特定的签名，而线性可解码的信息更广泛共享。", "innovation": "本文采用了一种借鉴多组学集成的方法——Similarity Network Fusion (SNF)，将其应用于表示相似性度量的集成，发现SNF不仅实现了与单一度量相比更清晰的模型家族区分，还产生了稳健的综合签名。通过聚类融合相似性矩阵，揭示了有趣且出人意料的模式：监督ResNet和Vision Transformers (ViTs) 形成不同的聚类，而所有自监督模型跨越架构边界聚集成一起。混合架构（ConvNeXt，Swin）与掩码自编码器聚类在一起，表明架构现代化与基于重建的训练方式正趋于一致。", "conclusion": "本文基于生物学启发的框架提供了视觉模型的系统分类，表明共同由架构和训练目标塑造的新兴计算策略定义了表示结构，超越了表面设计分类。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21561", "html_url": "https://arxiv.org/abs/2509.21561", "title": "手术器械无监督缺陷检测", "title_en": "Unsupervised Defect Detection for Surgical Instruments", "authors": "Joseph Huang,Yichi Zhang,Jingxi Yu,Wei Chen,Seunghyun Hwang,Qiang Qiu,Amy R. Reibman,Edward J. Delp,Fengqing Zhu", "background": "手术器械的安全检测需要可靠的视觉缺陷检测。然而，手动检测容易出错，现有用于自然/工业图像的自动化缺陷检测方法在手术领域中难以有效迁移，导致假阳性和对小、细微缺陷的敏感度低，以及对器械特异性特征的捕捉不充分的问题.", "innovation": "本文提出了一种适应性方法，专门针对手术器械的无监督缺陷检测。通过集成背景掩码、基于块的分析策略和高效域自适应，该方法解决了之前方法存在的问题，实现了对手术器械图像中细微缺陷的可靠检测.", "conclusion": "本文提出的方法克服了现有方法在手术器械缺陷检测中的局限性，能够有效检测出细微缺陷，提高了手术器械的安全性."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21595", "html_url": "https://arxiv.org/abs/2509.21595", "title": "时空对比：DINOv3和V-JEPA2在视频动作分析中的特征表示比较", "title_en": "Temporal vs. Spatial: Comparing DINOv3 and V-JEPA2 Feature Representations for Video Action Analysis", "authors": "Sai Varun Kodathala,Rakesh Vunnam", "background": "本研究旨在对比两种自监督学习架构DINOv3和V-JEPA2在视频动作识别中的表现。DINOv3通过独立处理帧和空间特征提取来处理视频帧，而V-JEPA2则采用联合时序建模的方法。研究在UCF Sports数据集上对两种架构进行了比较分析，从分类准确性、聚类性能、类别内一致性及类别间区分能力等多个维度评估了特征质量。", "innovation": "研究创新点在于提出了一种全面的比较分析方法，对比了两种架构在视频动作识别中的性能差异。特别地，研究发现DINOv3在聚类性能和类别间区分能力方面表现优异，而V-JEPA2则在各类别间的可靠性更加一致。通过对动作特异性的评估，揭示了两种架构在静止姿态识别和动作依赖性动作识别中的优缺点。", "conclusion": "研究结果表明，DINOv3在姿态识别方面表现突出，但在依赖于动作变化的识别上表现较差。而V-JEPA2提供了在不同动作类别之间更加稳定的特征表示。这些发现有助于理解在视频分析系统中架构设计的选择，并为根据任务需求和可靠性约束选择合适的特征提取方法提供了实证指导。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21670", "html_url": "https://arxiv.org/abs/2509.21670", "title": "MORPH：形状无关的PDE基础模型", "title_en": "MORPH: Shape-agnostic PDE Foundation Models", "authors": "Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence", "background": "当前研究领域有许多关于偏微分方程（PDEs）的解决方法，但缺乏一个能够处理不同数据维度（1D-3D）、不同分辨率以及多种物理场的统一模型。因此，提出了一个名为MORPH的新模型，它基于卷积视觉转换器的主干架构，能够无缝处理这些复杂的数据集。", "innovation": "MORPH具有以下创新点：(i) 组件级卷积，能够联合处理标量和矢量通道以捕捉局部交互；(ii) 场间跨注意力机制，用于建模并有选择地传播不同物理场之间的信息；(iii) 轴向注意力机制，沿着各自的时空轴分解全时空自注意力以减少计算负担并保持表达力。", "conclusion": "MORPH在此研究中表现出色，其多变种模型在多种异质PDE数据集上的预训练后，在零样本和全样本泛化中均优于从零开始训练的模型。总体来看，MORPH提供了一个灵活而强大的基础模型，适用于学习异质和多模态的科学观测数据，同时推动了可扩展且数据高效的科学机器学习领域的发展趋势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21565", "html_url": "https://arxiv.org/abs/2509.21565", "title": "在生成中无需对齐：在扩散模型中学习线性可分的表示", "title_en": "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models", "authors": "Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya", "background": "大规模扩散模型的高效训练策略强调了提高这些模型中的判别特征表示的重要性。一个关键的研究方向是使用强大的外部编码器获得的特征来进行表示对齐，这可以提高通过线性探查评估的表示质量。基于对齐的方法有潜力，但依赖于大型预训练编码器，这些编码器在计算上很昂贵。", "innovation": "本文提出了一种替代正则化方法，用于促进中间层表示的线性可分性（LSEP）。LSEP消除了辅助编码器和表示对齐的需要，直接将线性探查纳入网络的学习动态中，而不是将其视为简单的后话评估工具。研究结果表明，在基于流的变换器架构（SiTs）上，这种策略在训练效率和生成质量上取得了显著的改进，达到256x256 ImageNet数据集上的FID为1.46。", "conclusion": "通过直接将线性探查纳入网络的学习动态，LSEP在不使用外部编码器和对齐的情况下提高了扩散模型的训练效率和生成质量。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21715", "html_url": "https://arxiv.org/abs/2509.21715", "title": "Motion-Aware Transformer for Multi-Object Tracking", "title_en": "Motion-Aware Transformer for Multi-Object Tracking", "authors": "Xu Yang,Gady Agam", "background": "多对象跟踪（MOT）在视频中的挑战在于复杂的对象运动和拥挤的场景。现有的基于DETR的框架提供了端到端的解决方案，但通常在单个Transformer解码器层内同时处理检测和跟踪查询，这导致了冲突并降低了关联准确性。", "innovation": "引入了Motion-Aware Transformer（MATR），它显式预测跨帧的对象运动，并提前更新跟踪查询，以减少查询冲突，从而实现更一致的训练，并提高检测和关联的准确性。", "conclusion": "在DanceTrack、SportsMOT和BDD100k上的广泛实验表明，MATR在标准指标上取得了显著的改进。在DanceTrack上，MATR在没有额外数据的情况下，HOTA提高了超过9个百分点，并达到新的SOTA得分71.3（附带额外数据）。MATR还在SportsMOT和BDD100k上取得了SOTA结果（72.2 HOTA和54.7 mTETA，41.6 mHOTA），无需依赖外部数据集。这些结果表明，在端到端变压器中明确建模运动提供了一种简单而有效的多对象跟踪方法的先进性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21747", "html_url": "https://arxiv.org/abs/2509.21747", "title": "集成场景上下文和语义标签以增强群体级情绪识别", "title_en": "Incorporating Scene Context and Semantic Labels for Enhanced Group-level Emotion Recognition", "authors": "Qing Zhu,Wangdong Guo,Qirong Mao,Xiaohua Huang,Xiuyan Shao,Wenming Zheng", "background": "群体级情绪识别（GER）旨在识别场景中包含多个个体的整体情绪。现有方法低估了视觉场景上下文信息在建模个体关系方面的重要性，并且忽略了情感标签中的语义信息在全面理解情绪方面的作用。", "innovation": "本文提出了一种新的框架，该框架结合了视觉场景上下文和标签引导的语义信息，以提高GER性能。该框架包含一个视觉上下文编码模块，该模块利用多尺度场景信息多样地编码个体关系。此外，情感语义编码模块利用群体级情绪标签提示大型语言模型生成细致的情感词汇。这些词汇与情感标签结合后，通过结构化情绪树的使用进一步细化为全面的语义表示。最后，提出了一种相似性感知的交互方法，以对齐并集成视觉和语义信息，从而生成增强的群体级情绪表示，进而提高GER性能。", "conclusion": "在三个广泛采用的GER数据集上的实验表明，本文提出的方法与最先进的方法相比具有竞争力的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21574", "html_url": "https://arxiv.org/abs/2509.21574", "title": "X-Streamer：基于音频视觉交互的统一人类世界建模", "title_en": "X-Streamer: Unified Human World Modeling with Audiovisual Interaction", "authors": "You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Guoxian Song,Xiaochen Zhao,Chao Liang,Jianwen Jiang,Hongyi Xu,Linjie Luo", "background": "本文介绍了一种名为X-Streamer的端到端多模态人类世界建模框架，旨在构建能够实现无限交互的数字人类代理，这些交互跨越文本、语音和视频，且在同一统一架构中进行。X-Streamer从单张肖像图开始，支持实时、开放式视频通话，由流式多模态输入驱动。这一框架的核心是一个思考者-行为者双变压器架构，它将静态肖像转化为持久且智能的音频视频互动。思考者模块感知并推理用户输入，行为者模块则实时将隐藏状态转换为同步的多模态流。", "innovation": "X-Streamer的核心创新在于其思考者-行为者双变压器架构，该架构将多模态理解和生成统一起来。行为者使用分块自回归扩散模型，进行跨关注点到思考者的隐藏状态以生产时间对齐的多模态响应，这些响应包含交错的离散文本和音频令牌以及连续的视频潜在变量。此外，通过设计跨块和内块注意机制以及时间对齐的多模态位置嵌入，确保长时间稳定，并进一步通过块级扩散强迫和全局身份参照增强细粒度跨模态对齐和上下文保留。X-Streamer能够实时运行在两块A100 GPU上，提供长时间一致的视频聊天体验，并为互动数字人类的统一世界建模铺平了道路。", "conclusion": "X-Streamer通过其框架实现了多模态理解与生成的统一，能够实时将单张肖像转化为长期且智能的音频视频互动，适用于开放式视频通话，为数字人类代理的开发提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21592", "html_url": "https://arxiv.org/abs/2509.21592", "title": "接下来会发生什么？通过生成点轨迹来预测未来运动", "title_en": "What Happens Next? Anticipating Future Motion by Generating Point Trajectories", "authors": "Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi", "background": "该研究探讨了仅从单张图像预测物体运动的问题，即在无法观察物体的速度或施加力的情况下，推断物体在未来可能的运动方式。传统的方法通常依赖于视频生成器来生成像素级的预测，但这些方法往往在仅从单张图像预测运动时表现不佳，尤其是在简单的物理场景中，如下落的方块或机械物体相互作用的情况下。", "innovation": "研究提出了一种新的方法，将任务形式化为条件生成密集轨迹网格，使用一个接近现代视频生成器架构的模型，但输出的是运动轨迹而不是像素。这种方法能够捕捉场景中的动态和不确定性，比之前的回归器和生成器提供了更准确和多样化的预测。此外，研究通过对仿真数据的广泛评估、在机器人等下游应用中的有效性展示以及在真实世界的直观物理数据集上的良好表现，突出这种新方法的优势。", "conclusion": "尽管最新的视频生成器通常被认为具有世界模型的能力，但在简单的物理场景中从单张图像预测运动方面，它们往往表现不佳。研究结果显示，运动预测的限制主要源自生成像素的计算开销，而不是直接对运动进行建模。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21657", "html_url": "https://arxiv.org/abs/2509.21657", "title": "FantasyWorld：通过统一的视频和三维预测进行几何一致的世界建模", "title_en": "FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction", "authors": "Yixiang Dai,Fan Jiang,Chiyu Wang,Mu Xu,Yonggang Qi", "background": "高质量的3D世界模型对于实现具身智能和通用人工智能（AGI）至关重要，支撑了增强现实/虚拟现实内容创建和机器人导航等应用。尽管现有的视频基础模型具有强大的具象先验知识，但在3D空间保持一致性和用于下游3D推理任务的实用性方面存在局限性。当前视频基础模型缺乏明确的3D定位能力。FantasyWorld通过增强冻结的视频基础模型并引入可训练的几何分支，实现了视频潜变量与隐式3D场的联模，有效解决了这一问题。", "innovation": "提出了一种几何增强的框架FantasyWorld，该框架通过可训练的几何分支增强冻结的视频基础模型，实现了视频潜变量与隐式3D场的联合建模，在一次前向传播中完成。引入了交叉分支监督机制，其中几何提示引导视频生成，视频先验约束3D预测，从而得到一致且可泛化的3D感知视频表示。实验结果显示FantasyWorld在多视图一致性和风格一致性方面优于最近的几何一致性基线模型。层析研究表明，这些改进来源于统一的骨干网络和跨分支信息交换机制。", "conclusion": "FantasyWorld有效填补了视频想象与3D感知之间的空白，相较于现有的几何一致性基线模型表现出更高的性能。该工作不仅改善了现有视频模型的3D建模能力，还为下游任务如新型视图合成和导航提供了灵活的表示方式，无需针对每个场景进行优化和微调。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21609", "html_url": "https://arxiv.org/abs/2509.21609", "title": "VLCE: 一种增强知识框架以在灾害评估中进行图像描述", "title_en": "VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster Assessment", "authors": "Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George", "background": "在自然灾害发生后，立即进行损害评估至关重要。然而，传统的人工评估方法效率低下且危险。尽管卫星和无人机照片提供了受灾区域的广泛视角，但现有的计算机视觉技术通常只能提供分类标签或分割掩码，限制了它们对具体情况的全面理解能力。", "innovation": "我们提出了Vision Language Caption Enhancer (VLCE)，这是一种多模态系统，旨在生成灾难图像的全面、上下文相关的解释。VLCE采用了一种双架构方法：使用一个预训练在EuroSat卫星图像上的ResNet50骨干的CNN-LSTM模型，以及一个预训练在UAV图像上的Vision Transformer (ViT)模型。这两个系统利用外部的本体知识（ConceptNet和WordNet）扩展词汇覆盖范围并提高描述准确性。我们通过使用CLIPScore进行语义对齐和InfoMetIC进行配额信息，将VLCE与领先的语言-视觉模型（LLaVA和QwenVL）进行了比较，结果表明，VLCE显著优于基准模型，在InfoMetIC上的最高得分为95.33%，同时保持了竞争力的语义对齐。双架构系统展示了在灾害损害评估中自动化生成行动性强、信息密集的描述的巨大潜力，基于卫星和无人机照片。", "conclusion": "我们的双架构系统在基于卫星和无人机照片生成信息密集、操作性强的描述方面展现了巨大潜力。通过使用Vision Language Caption Enhancer (VLCE)，可以显著提高灾难损害评估的效率和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21719", "html_url": "https://arxiv.org/abs/2509.21719", "title": "DeLiVR: 微分时空Lie偏差用于高效的视频除雨", "title_en": "DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining", "authors": "Shuning Sun,Jialang Lu,Xiang Chen,Jichao Wang,Dianjie Lu,Guijuan Zhang,Guangwei Gao,Zhuoran Zheng", "background": "野外拍摄的视频往往会受到雨水条痕、模糊和噪声的影响。甚至相机姿态的微小变化也会在帧间产生不匹配和时间上的瑕疵。现有的方法主要依赖光学流或启发式对齐技术，这些方法计算上较为复杂且缺乏鲁棒性。", "innovation": "该论文提出了一种有效的方法DeLiVR，该方法利用Lie群直接将时空微分偏差注入到网络的注意力分数中，通过旋转约束的Lie相对偏差预测帧内的平面角度，并通过差分群位移计算相邻帧之间的角度差异来估计速度。这种偏差计算方法结合了时间衰减和注意力掩码，专注于帧间关系并准确匹配雨水条痕的方向。", "conclusion": "广泛的实验结果表明，该方法在公开可用的基准测试中具有有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21764", "html_url": "https://arxiv.org/abs/2509.21764", "title": "CubistMerge: 空间保留的Token合并方法以适应不同的ViT主干", "title_en": "CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones", "authors": "Wenyi Gong,Mieszko Lis", "background": "许多现代ViT骨干网络采用了空间架构设计，如窗口注意机制、SAM中的分解相对位置嵌入，以及DINOv3中的RoPE等。这些架构对token的减少提出了新的挑战，因为现有的大多数方法无法保持这些架构依赖的空间结构。因此，设计一种保留空间连贯性的简单且有效的token合并方法变得至关重要。", "innovation": "提出了一种名为CubistMerge的简单而有效的方法，用于保留空间完整性，实现与空间架构的无缝兼容。该方法解决了两个看似冲突的要求：（i）在空间布局中充分利用信息分布不均，同时（ii）在合并后保留空间结构。该方法采用了（i）二维缩减策略以确保结构性的token布局，（ii）空间感知的合并算法以维持相对token位置，以及（iii）一种新的按维度最大值表示token的方法，从而保留了重要的特征。", "conclusion": "本文提出的方法在包括时空架构的各种视觉任务中都展示了强大的性能，无论是即插即用还是微调后。具体来说，在SAM-H和DeiT-B的评估中，CubistMerge实现了显著的速度提升，而几乎没有性能损失，表明可以在保持性能的同时大幅提高模型效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21733", "html_url": "https://arxiv.org/abs/2509.21733", "title": "UISim：用于动态移动环境的交互式基于图像的UI模拟器", "title_en": "UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments", "authors": "Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen", "background": "开发和测试用户界面（UIs）以及训练AI代理与之交互具有挑战性，因为实际移动环境具有动态和多变的本质。现有的方法往往依赖于笨重的物理设备或有限的屏幕截图静态分析，这阻碍了测试的规模化并阻碍了智能UI代理的发展。因此，需要一种能够动态探索移动设备环境且无需实际物理设备的模拟工具，以便进行UI测试、快速设计原型和合成数据生成。", "innovation": "该论文介绍了一种名为UISim的新颖基于图像的UI模拟器，该模拟器能够通过屏幕图像提供一个动态且互动的移动环境探索平台。该系统采用两阶段方法进行操作：首先根据给定的初始屏幕图像和用户操作预测下一个UI状态的抽象布局，然后根据预测的布局生成一个新的、视觉上一致的图像。这种方法使得UI过渡的仿真是现实的。", "conclusion": "我们的实验结果表明，UISim在生成现实且连贯的后续UI状态方面优于端到端的UI生成基准，突显其真实的仿真能力和对未来UI开发和AI代理训练流程简化以及高级应用程序的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21760", "html_url": "https://arxiv.org/abs/2509.21760", "title": "UniVid：使用预训练视频生成模型统一视觉任务", "title_en": "UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models", "authors": "Lan Chen,Yuchao Gu,Qi Mao", "background": "大规模语言模型能够成功地在统一的生成框架中解决多样的语言任务。受到这一启示，近期的工作，例如大型视觉模型（LVM），将此范式扩展到了视觉领域，通过将任务组织成序列视觉句子，视觉提示作为上下文以引导输出。然而，这些模型需要跨模态及来源进行任务特定的预训练，成本高且限制了对未见过任务的扩展性。给定预训练的视频生成模型能够捕获时间序列依赖的特点，我们探讨了一种更为统一和可扩展的替代方案：预训练的视频生成模型能否适应多样的图像和视频任务？", "innovation": "我们提出了UniVid框架，该框架对视频扩散变换器进行微调以处理各种视觉任务，而无需进行任务特定的修改。任务被表示为视觉句子，其中上下文序列定义了任务和预期的输出模态。UniVid在两种视角下评估了其泛化能力：一是跨模态推理，上下文由图像和视频组成，扩展了LVM的单模态设置；二是从自然数据到注释数据的跨数据源任务，无需多数据源预训练。", "conclusion": "尽管仅在自然视频数据上进行训练，UniVid在两种设定中表现良好。这项研究突显了预训练视频生成模型作为视觉建模统一和可扩展基础的潜力。我们的代码将在以下链接发布：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21722", "html_url": "https://arxiv.org/abs/2509.21722", "title": "对于SAR图像的初步基础模型状况的研究", "title_en": "On the Status of Foundation Models for SAR Imagery", "authors": "Nathan Inkawhich", "background": "在更广泛的社区中，特别是在自然图像领域，前沿实验室正在使用前所未有的计算预算在大规模网络数据集上训练大型模型，取得了显著进步。这些通常通过自监督学习（SSL）训练的模型能够以非常有限的标记数据进行适应，并且对多种形式的数据分布偏移更加稳健，其特征也具有强大的迁移性。因此，研究者们希望将这种技术应用到合成孔径雷达（SAR）领域。然而，研究者们的第一批实验发现，诸如DINOv2和PE-Core等目前最强大的视觉基础模型在直接使用时，无法提取SAR目标的语义相关区分特征。", "innovation": "研究者展示了通过自监督微调公开可用的SSL模型来适应SAR数据是一种可行的方法。通过这种方法，研究者训练了几种AFRL-DINOv2模型，并在SAR基础模型领域设立了新的最高标准，显著优于当前最好的SAR域模型SARATR-X。此外，研究还分析了不同骨干网络和下游任务适应食谱对性能表现的影响，并监控了各模型在下游环境中的适应能力（例如，扩展的操作条件和少量标记数据）。", "conclusion": "尽管研究结果积极，但研究者认为在未来SAR基础模型建设中还有很长的路要走。这项工作旨在为未来的SAR基础模型开发者提供信息和灵感。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21696", "html_url": "https://arxiv.org/abs/2509.21696", "title": "MS-YOLO: 通过MobileNetV4和SlideLoss实现边缘部署的红外物体检测", "title_en": "MS-YOLO: Infrared Object Detection for Edge Deployment via MobileNetV4 and SlideLoss", "authors": "Jiali Zhang,Thomas S. White,Haoliang Zhang,Wenqing Hu,Donald C. Wunsch II,Jian Liu", "background": "红外成像已经成为了在低光照和恶劣天气条件下进行城市物检测的一种稳健解决方案，与传统的可见光摄像头相比，它具有显著的优势。然而，诸如类别不平衡、热噪声以及计算限制等问题会显著妨碍模型在实际环境中的表现。为了应对这些挑战，作者评估了多个YOLO变体在FLIR ADAS V2数据集上的性能，并最终选择YOLOv8作为基准模型，以其平衡的准确性和效率。基于此基础，作者提出了MS-YOLO（MobileNetv4和SlideLoss基于YOLO），它用更高效的MobileNetV4替代了YOLOv8的CSPDarknet骨干网，减少了1.5%的计算量并在保持高准确性的同时。此外，引入了一种新的损失函数SlideLoss，可以动态强调欠代表和被遮挡的样本，从而提高精度而不会牺牲召回率。在FLIR ADAS V2基准上的实验表明，MS-YOLO达到了竞争力的mAP和更高的精度，且仅运行在6.7 GFLOPs。这些结果表明，MS-YOLO在保持高检测质量的同时，有效降低了计算成本，从而使其适合于城市的实时代部署。", "innovation": "1. 通过将更高效的MobileNetV4代替YOLOv8的CSPDarknet骨干网，降低了计算开销，同时保持了高准确性。2. 引入了新的损失函数SlideLoss，它能够动态强调欠代表和被遮挡的样本，从而提高精度而不会牺牲召回率。3. MS-YOLO实现了在6.7 GFLOPs下的高精度和竞争性的mAP，这展示了它在保持高检测质量的同时降低了计算成本，适配于实时代部署的需求。", "conclusion": "MS-YOLO通过使用高效模型和新的损失函数，显著提高了红外成像条件下小目标的检测性能，同时减少了计算开销，非常适合应用于城市的实时代部署场景。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21783", "html_url": "https://arxiv.org/abs/2509.21783", "title": "Prompt-guided Representation Disentanglement for Action Recognition", "title_en": "Prompt-guided Representation Disentanglement for Action Recognition", "authors": "Tianci Wu,Guangming Zhu,Jiang Lu,Siyuan Wang,Ning Wang,Nuoye Xiong,Zhang Liang", "background": "动作识别是视频理解中的一个基本任务。当前的方法通常提取统一的特征来处理视频中的所有动作，这使得在多动作场景中建模不同对象之间的交互变得具有挑战性。", "innovation": "本文提出了一种新颖的方法，即引导提示解缠表示法（ProDA），它通过空间-时间场景图（SSGs）分解视频场景中的指定动作。ProDA引入了动态提示模块（DPM）来引导图解析神经网络（GPNN），并生成特定于动作的表示。此外，设计了一种视频适应的GPNN，使用动态权重聚合信息。", "conclusion": "实验结果显示，与现有最先进的方法相比，我们的方法在视频动作识别中有很好的效果。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21750", "html_url": "https://arxiv.org/abs/2509.21750", "title": "KG-SAM: 通过条件随机场将解剖知识注入Segment Anything模型", "title_en": "KG-SAM: Injecting Anatomical Knowledge into Segment Anything Models via Conditional Random Fields", "authors": "Yu Li,Da Chang,Xi Xiao", "background": "尽管Segment Anything Model (SAM) 在图像分割方面取得了显著的成功，但其直接应用于医学成像仍受到根本性的挑战，包括模糊的边界、解剖关系建模不足以及不确定性量化不足。这些限制阻碍了SAM在医学成像方面的直接应用。", "innovation": "我们提出了KG-SAM，一种知识导向框架，将解剖先验知识与边界细化和不确定性估计结合在一起。具体来说，KG-SAM 包括(i)医学知识图谱以编码精细的解剖关系，(ii)基于能量的条件随机场 (CRF) 以确保符合解剖预测，(iii)带不确定性估计的融合模块以提高临床场景中的可靠性。实验结果证明了该方法的有效性：在前列腺分割中，KG-SAM 达到了82.69% 的平均Dice分数；在腹部分割中，分别达到78.05% 的MRI 和79.68% 的CT，表明KG-SAM 是一个稳健且通用的医学图像分割框架。", "conclusion": "通过KG-SAM，我们展示了如何将解剖先验知识注入到Segment Anything模型中，克服了SAM在医学成像中的局限性，特别是在前列腺和腹部的分割中取得了显著的性能提升。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21738", "html_url": "https://arxiv.org/abs/2509.21738", "title": "LFA-Net：一种带LiteFusion注意力模块的轻量级网络用于视网膜血管分割", "title_en": "LFA-Net: A Lightweight Network with LiteFusion Attention for Retinal Vessel Segmentation", "authors": "Mehwish Mehmood,Ivor Spence,Muhammad Fahim", "background": "轻量级视网膜血管分割对于早期诊断威胁视力和全身性疾病非常重要，尤其是在计算资源有限的现实临床环境中。尽管基于深度学习的分割方法正在改进，现有模型仍然面临着小血管分割和高计算成本的挑战。", "innovation": "提出了新的血管分割网络LFA-Net，该网络结合了一种新设计的注意力模块LiteFusion-Attention。该注意力模块融合了残差学习连接、Vision Mamba启发的动态和基于调制的注意力，使模型能够高效且轻量地捕捉局部和全局上下文。LFA-Net具有0.11百万参数、0.42 MB的内存大小和4.46 GFLOPs，使其在资源受限的环境中更为理想。", "conclusion": "我们在DRIVE、STARE和CHASE_DB上验证了提出的模型，性能表现出色，Dice分数分别为83.28%、87.44%和84.50%，Jaccard指数分别为72.85%、79.31%和74.70%。LFA-Net的代码已在在线提供。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21797", "html_url": "https://arxiv.org/abs/2509.21797", "title": "MoWM: 混合世界模型混合法则在视觉和语言驱动的实体规划中的应用", "title_en": "MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation", "authors": "Yu Shang,Yangcheng Yu,Xin Zhang,Xin Jin,Haisheng Su,Wei Wu,Yong Li", "background": "实体动作规划是机器人学的核心挑战，要求模型能够根据视觉观察和语言指令生成精确的动作。尽管视频生成的世界模型有潜力，但它们依赖于像素级别的重构，常常引入视觉冗余，妨碍动作解码和泛化能力。尽管隐式世界模型提供了紧凑、运动感知的表示，但往往忽略了对于精确操作至关重要的细节。", "innovation": "本文提出了MoWM（混合世界模型框架），该框架融合了混合世界模型的表示以实现实体动作规划。该方法使用隐式模型的运动感知表示作为高级先验，引导来自像素空间模型的细粒度视觉特征的提取。这种设计使得MoWM能够突出解码动作所需的有用视觉细节。在CALVIN基准上的广泛评估表明，本方法优于现有方法，实现了最先进的任务成功率和更好的泛化能力。我们还对每个特征空间进行了全面分析，提供了未来实体规划研究中具有价值的见解。", "conclusion": "我们的研究表明，MoWM框架在实体动作规划方面表现出色，能够生成精确的动作，达到了最先进的任务成功率和卓越的泛化性能。此外，我们还提供了对于每个特征空间优缺点的全面分析，为未来的研究提供了宝贵的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21859", "html_url": "https://arxiv.org/abs/2509.21859", "title": "SRHand: 通过视角/姿态感知神经图像表示和显式3D网格来超分重建手部图像和3D形状", "title_en": "SRHand: Super-Resolving Hand Images and 3D Shapes via View/Pose-aware Neural Image Representations and Explicit 3D Meshes", "authors": "Minje Kim,Tae-Kyun Kim", "background": "详细的手部重建在各种应用中都至关重要。尽管先前的研究主要关注于捕捉高保真手部几何，但这些研究依赖于高分辨率的多角度图像输入，并且难以在低分辨率图像上推广。多视角图像超分辨方法被提出以确保3D视角一致性，但这些方法仅适用于静态对象或固定分辨率的场景，并不适用于关节可变形的手部。", "innovation": "本文提出了一种名为SRHand的方法，能够从低分辨率图像中重建详细的手部3D几何和纹理图像。SRHand利用了隐式图像表示和显式手部网格的优势。作者引入了一种几何感知的隐式图像函数（GIIF），该函数通过上采样粗略输入图像来学习详细的先手先。通过联合优化隐式图像函数和显式3D手部形状，该方法在上采样手部图像中保持了多视角和姿态一致性，并实现了精细的3D重建（皱纹、指甲等）。实验结果显示，该方法在多视角手部2.6M数据集和Goliath数据集上的表现显著优于现有的图像超分辨方法和3D手部重建方法。", "conclusion": "与现有方法相比，SRHand在定量和定性上表现更优，能够从低分辨率图像中实现手部的精细3D重建，不仅保留了多视角和姿态一致性，还捕捉到了手部的微小细节。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21774", "html_url": "https://arxiv.org/abs/2509.21774", "title": "无监督图推理驱动的多模态深度假检测", "title_en": "Training-Free Multimodal Deepfake Detection via Graph Reasoning", "authors": "Yuxin Liu,Fei Wang,Kun Li,Yiqi Nie,Junjie Chen,Yanyan Wei,Zhangling Duan,Zhaohong Jia", "background": "多模态深度假检测（MDD）旨在揭露跨视觉、文本和音频模态的篡改，从而增强现代信息系统的信息可靠性。尽管大型视觉语言模型（LVLM）在多模态推理方面表现出色，但在MDD中的有效性受到捕捉细微伪造线索、解决跨模态不一致性和执行任务对齐检索的挑战的限制。为了应对这些挑战，作者提出了一种无需训练的框架GASP-ICL（Guided Adaptive Scorer and Propagation In-Context Learning），通过保留语义相关性并注入任务感知知识来利用LVLM。这种方法通过使用模态适应特征提取器检索对齐的图像-文本对并构建候选集，进一步设计了Graph-Structured Taylor Adaptive Scorer (GSTAS)，以捕捉跨样品关系并传播查询对齐信号，从而产生具有区分性的典范。这使得能够更精确地选择语义上对齐的任务相关演示，增强LVLM以实现稳健的MDD。", "innovation": "提出了一种无需训练的框架GASP-ICL，通过保留语义相关性并注入任务感知知识来利用LVLM。方法包括使用模态适应特征提取器检索对齐的图像-文本对并构建候选集，进一步设计了Graph-Structured Taylor Adaptive Scorer (GSTAS)，以捕捉跨样品关系并传播查询对齐信号，从而产生具有区分性的典范。这种方法能更精确地选择语义上对齐的任务相关演示，增强LVLM以实现稳健的MDD。", "conclusion": "在四种伪造类型的实验中，GASP-ICL超越了强有力的基线方法，实现了在无需LVLM微调的情况下提高性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21790", "html_url": "https://arxiv.org/abs/2509.21790", "title": "LongScape：利用上下文感知MoE推进长时题生成实物世界模型", "title_en": "LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE", "authors": "Yu Shang,Lei Jin,Yiding Ma,Xin Zhang,Chen Gao,Wei Wu,Yong Li", "background": "基于视频的世界模型在生成高质量的执行操作数据方面具有巨大潜力。然而，当前的视频生成方法难以实现稳定的长时预测：经典的基于扩散的方法通常会因为在多个场景中的时间不一致和视觉漂移而导致问题，而自回归方法则往往因追求视觉细节而损失连贯性。", "innovation": "我们提出了一种名为LongScape的混合框架，该框架将基于块内的去噪扩散与基于块间的自回归因果生成相结合。我们的核心创新是一种基于机器人动作语义上下文的引导性、可变长度的块划分机制，这种机制将视频按动作场景分割，确保每个块可以代表一个完整的动作，从而让模型能够灵活地生成多样化的动态。为了保证视觉质量并实现块之间的无缝过渡，我们引入了一个上下文感知的专家混合（CMoE）框架，在生成过程中根据每个块的不同情况激活特定的专家。", "conclusion": "我们的实验结果表明，该方法能够在长时序复制中实现稳定的生成和一致性。我们已将代码公开于此链接：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21787", "html_url": "https://arxiv.org/abs/2509.21787", "title": "DeHate：基于稳定扩散的多模态方法以减轻图像中的仇恨言论", "title_en": "DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images", "authors": "Dwip Dalal,Gautam Vashishtha,Anku Ranui,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal", "background": "随着有害在线内容的增加，不仅扭曲了公共话语，还对维护健康数字环境构成了重大挑战。针对这一问题，本文提出了一种专用于识别数字内容中的仇恨现象的多模态数据集。该数据集的关键在于利用被水印增强的稳定扩散技术与数字注意力分析模块（DAAM），结合使用，以在图像中精确定位仇恨元素，生成详细的仇恨注意力地图，进而模糊掉这些仇恨区域，从而移除图像中的仇恨部分。此外，该论文还介绍了共享任务的具体细节，并提出了DeHater，一种用于多模态去仇恨任务的视觉-语言模型，能够通过文本提示进行图像仇恨检测，有助于实现更加伦理的社交媒体人工智能应用开发。", "innovation": "本文提出了一种基于稳定扩散技术的多模态方法，该方法结合了被水印增强的稳定扩散技术和数字注意力分析模块（DAAM），用于识别和处理数字内容中的仇恨现象。这种方法首次在多模态框架下系统性地处理图像中的仇恨内容，并借助文本提示实现了高效的图像去仇恨化。通过大规模数据集的训练，DeHater能够在保持图像内容完整性的同时，移除有害元素，为社交媒体创造更加安全、健康的环境。", "conclusion": "本文介绍的DeHate数据集和DeHater视觉-语言模型代表了AI驱动的图像仇恨检测领域的最新进展，显著提高了对有害内容的识别和移除效率，为开发更伦理、更负责任的人工智能应用提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21788", "html_url": "https://arxiv.org/abs/2509.21788", "title": "MIRG-RL: 使用强化学习进行多图像推理与 grounding", "title_en": "MIRG-RL: Multi-Image Reasoning and Grounding with Reinforcement Learning", "authors": "Lihao Zheng,Jiawei Chen,Xintian Shen,Hao Ma,Tao Wei", "background": "多图像推理和 grounding 要求理解复杂的跨图像关系，包括在对象级别和图像级别。当前的大规模视觉语言模型面临两个关键挑战：缺乏跨图像推理能力以及跨图像参考奖励建模不足。", "innovation": "提出了一个统一框架 - Multi-Image Reasoning and Grounding with Reinforcement Learning (MIRG-RL)。具体而言，采用两阶段的训练范式，结合带注释的轨迹的监督微调和图像感知的强化学习优化，逐步发展多图像推理能力。此外，创新地提出了轨迹数据构造方法，该方法结合了对象级别和图像级别的注释信息，并使用此方法生成了轻量级的增强推理数据集。为了有效解决跨图像模糊性问题，设计了一个具有双重奖励函数的图像感知 RL 策略。", "conclusion": "实验表明，MIRG-RL 在多图像 grounding 方面实现了最先进的性能，在跨图像推理任务中达到了 64.82% 的性能 - 超过先前最佳方法 1%。代码和数据集已在此处发布：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21839", "html_url": "https://arxiv.org/abs/2509.21839", "title": "DiTraj: 无需训练的视频扩散变换器轨迹控制", "title_en": "DiTraj: training-free trajectory control for video diffusion transformer", "authors": "Cheng Lei,Jiayu Zhang,Yue Ma,Xinyu Wang,Long Chen,Liang Tang,Yiqiang Yan,Fei Su,Zhicheng Zhao", "background": "当前基于扩散变换器(DiT)的视频生成模型显示出了强大的生成能力。轨迹控制作为一种用户友好的控制任务，在可控制视频生成领域中受到重视。然而，现有的方法要么需要大量的训练资源，要么专门针对U-Net设计，未能充分利用DiT的优越性能。因此，需要一个简单有效的无需训练的框架以更好地实现轨迹控制任务。", "innovation": "本文提出了一种名为DiTraj的简单且有效的方法，该方法用于无需训练的扩散变换器(DiT)视频生成中的轨迹控制。首先，通过大型语言模型(LLL)进行前景-背景分离指导，将用户的提示转化为前景提示和背景提示，分别指导视频中前景和背景区域的生成。其次，分析了3D全注意力机制，并探究了token间注意力分数与位置嵌入之间的密切关系，提出了一种新的方法：基于帧的时空解耦的3D-RoPE。通过仅修改前景token的位置嵌入，消除它们跨帧的空间不一致，增强了跨帧之间的注意力，从而增强了轨迹控制。此外，通过调节位置嵌入的密度，实现了3D感知的轨迹控制。实验表明，在视频质量和轨迹控制方面，本文方法优于之前的各项方法。", "conclusion": "通过提出DiTraj框架，本文成功实现了无需训练的扩散变换器(DiT)视频生成中的轨迹控制，显著改善了视频的质量和轨迹控制能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21864", "html_url": "https://arxiv.org/abs/2509.21864", "title": "Deepfakes: 我们需要重新思考“真实”图像的概念", "title_en": "Deepfakes: we need to re-think the concept of \"real\" images", "authors": "Janis Keuper,Margret Keuper", "background": "现代图像生成模型的广泛可用性和低使用门槛引发了合理的犯罪行为担忧和社会负面影响。机器学习社区正在通过大量关于反欺诈检测算法的研究来应对这一问题，但当前研究大多集中在生成算法和“假”数据样本上，忽视了对“真实”图像的明确定义和数据收集。尽管在技术解决方案上取得了一定进展，但研究认为这是一个不足，技术获取“真实”图像的方式在过去十年间已经发生了巨大变化，现在90%以上的照片是通过智能手机生成的，这些设备通常使用算法从多个传感器获取的多组输入生成图像。", "innovation": "论文指出现有方法依赖于少数较旧低分辨率的真实图像数据集如ImageNet，然而图像生成技术在过去十年有了巨大进步，如今智能手机等设备的图像生成算法与图像生成器密切相关，这表明了重新定义“真实”图像概念的必要性。论文提出这一观点旨在提高对该研究领域的认识，并引发讨论，是否检测“假”图像是一个合理的目标，至少需要明确的技术定义以及新的基准数据集。", "conclusion": "为了确保技术的发展与实际应用保持一致，研究强调了需要重新思考“真实”图像的概念，并提出了当务之急是进行相关的研究和讨论，以定义“真实”图像和技术基准数据集。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21887", "html_url": "https://arxiv.org/abs/2509.21887", "title": "StableDub: 强化扩散先验以实现高效可视化配音", "title_en": "StableDub: Taming Diffusion Prior for Generalized and Efficient Visual Dubbing", "authors": "Liyang Chen,Tianze Zhou,Xu He,Boshi Tang,Zhiyong Wu,Yang Huang,Yang Wu,Zhongqian Sun,Wei Yang,Helen Meng", "background": "视觉配音任务旨在生成与驱动音频同步的口唇运动，近年来取得了显著进步。然而，两个关键缺陷阻碍了其广泛应用：（1）仅基于音频的驱动方式未能充分捕捉说话者的唇部习惯，导致生成的口唇运动与目标角色不符；（2）传统的盲修复方法在处理遮挡物（如麦克风、手等）时经常出现视觉伪影，限制了其实用部署。", "innovation": "本文提出了一种新颖且简洁的框架StableDub，结合了唇部习惯感知建模与遮挡鲁棒合成。通过使用Stable-Diffusion骨干架构，提出了一种唇部习惯调节机制，共同建模音视频同步和特定说话者的口腔面部动态。为了在遮挡情况下生成合理的唇部几何形状和物体外观，引入了意识遮挡的训练策略，明确暴露遮挡对象以供修复过程使用。通过这些设计，该模型减少了之前方法中的高成本先验，从而在计算密集型的扩散架构中展现出更高的训练效率。此外，通过引入混合Mamba-Transformer架构，进一步优化了模型架构，提高了低资源研究场景中的适用性。", "conclusion": "广泛的实验结果表明，StableDub在唇部习惯相似性和遮挡鲁棒性方面取得了卓越性能。我们的方法在音频口唇同步、视频质量和分辨率一致性方面也超越了其他方法。我们从各个角度扩展了视觉配音方法的适用性，详细演示视频可在以下链接查看此 https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21888", "html_url": "https://arxiv.org/abs/2509.21888", "title": "Drag4D：文本驱动三维场景生成中的运动对齐", "title_en": "Drag4D: Align Your Motion with Text-Driven 3D Scene Generation", "authors": "Minjun Kang,Inkyu Shin,Taeyeop Lee,In So Kweon,Kuk-Jin Yoon", "background": "研究中引入了一个名为Drag4D的交互框架，该框架结合了基于文本的三维场景生成和物体运动控制。通过将三维物体在一张图像上生成的3D轨迹无缝整合到高质量的3D背景中，该框架可以帮助用户更精确地控制三维物体的运动，这些物体是在单一图像的基础上生成的。", "innovation": "该框架创新性地结合了文本驱动的3D背景生成和3D物体运动控制。通过应用2D高斯点和全景图像以及填充新颖视角，提升了文本到3D背景生成的精度。同时，引入了3D拷贝与粘贴的方法，确保物体实例可以从一个完整的3D网格中提取，并无缝地组合到生成的3D场景中。最后，开发了一种部分增强运动条件的视频扩散模型，以处理多视角图像对及其投影的2D轨迹，从而解决运动错觉问题，确保视图一致的时间对齐。", "conclusion": "通过在每个阶段和最终结果的评估中展示了集成架构的有效性，证明了用户控制对象运动与高质量3D背景的协作对齐，展示了Drag4D框架的先进性和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21845", "html_url": "https://arxiv.org/abs/2509.21845", "title": "基于Transformer的问答模型及增强的RAG设计的全面评估", "title_en": "A Comprehensive Evaluation of Transformer-Based Question Answering Models and RAG-Enhanced Design", "authors": "Zichen Zhang,Kunlong Zhang,Hongwei Ruan,Yiming Luo", "background": "基于Transformer的模型已经在问答领域取得了显著进展，但多跳推理依然是难点，因为这类问题需要结合多段文本的信息。本文在检索增强生成框架下，对多跳问答的检索策略进行了全面评估，比较了余弦相似性、最大边际相关性和一种结合密集嵌入、词法重叠和重新排序的混合方法。实验结果表明，混合方法较基础方法在精确匹配和F1分数上分别有50%和47%的显著提升。错误分析表明，混合检索提高了实体召回率和证据互补性，但受限于处理干扰项和时间推理的能力。", "innovation": "本文提出了对基于Transformer的问答模型及检索增强生成框架的混合检索策略进行全面评估的方法。通过引入标签化令牌和迭代优化，改进了EfficientRAG流水线，从而实现了更高的效率和性能。", "conclusion": "混合检索增强了生成的方法在多跳问答任务中提供了零样本解决方案，平衡了准确性、效率和可解释性，尤其是在实体召回率和证据互补性方面表现优异，但存在处理干扰项和时间推理能力有限的问题。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21893", "html_url": "https://arxiv.org/abs/2509.21893", "title": "Syncphony：使用扩散变压器的同步音频到视频生成", "title_en": "Syncphony: Synchronized Audio-to-Video Generation with Diffusion Transformers", "authors": "Jibin Song,Mingi Kwon,Jaeseok Jeong,Youngjung Uh", "background": "文本到视频和图像到视频生成在视觉质量方面取得了快速进步，但这些模型在控制动作的精确时间上仍然存在限制。相比之下，音频能够提供与视频动作时间对齐的提示，这使得它成为时间控制视频生成的一个有希望的工具。然而，现有的音频到视频（A2V）模型在细粒度同步方面遇到了困难，这主要是因为间接条件机制或有限的时间建模能力。", "innovation": "Syncphony通过构建一个预训练的视频主干，并引入了两种关键组件来提升同步效果：1. 动态感知损失，强调在高动区域学习；2. 音频同步引导，使用视觉对齐的未同步模型来更好地利用音频提示，同时保持视觉质量。此外，提出了CycleSync作为评估同步性的视频到音频度量标准。", "conclusion": "在AVSync15和The Greatest Hits数据集上的实验表明，Syncphony在同步精度和视觉质量方面均优于现有方法。项目页面可访问：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21905", "html_url": "https://arxiv.org/abs/2509.21905", "title": "TDEdit: 一种统一的文本-拖拽引导图像编辑扩散框架", "title_en": "TDEdit: A Unified Diffusion Framework for Text-Drag Guided Image Manipulation", "authors": "Qihang Wang,Yaxiong Wang,Lechao Cheng,Zhun Zhong", "background": "虽然近年来基于文本和基于拖拽的图像编辑方法在各自的领域取得了显著进展，但它们各自存在局限性：基于文本的方法擅长于纹理操作，但缺乏精确定位控制；而基于拖拽的方法主要修改形状和结构，但缺乏精细的纹理指导。本文旨在通过提出一种综合文本和拖拽操作的统一扩散框架来解决这些问题。", "innovation": "本文提出了一种综合扩散框架TDEdit，它提供了两个关键创新点：（1）点云确定性拖拽，通过3D特征映射增强潜在空间布局控制；（2）拖拽文本引导去噪，动态平衡拖拽和文本条件在去噪过程中的影响。", "conclusion": "大量的定量和定性实验表明，本文的方法不仅能够实现高质量的联合编辑，还在各种条件下能够与专门的文本或拖拽单一条件方法相媲美或超越，从而提供了一种通用且可推广的可控图像操纵解决方案。相关代码将公开以重现本文所有实验的结果。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21853", "html_url": "https://arxiv.org/abs/2509.21853", "title": "高动态范围下动态新颖视图合成", "title_en": "Dynamic Novel View Synthesis in High Dynamic Range", "authors": "Kaixuan Zhang,Zhipeng Xiong,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu", "background": "现有方法主要聚焦于静态场景，假设场景中的所有元素都是静止且非活动的。然而，现实世界中的场景经常包含动态元素，如移动物体、变化的光照条件和其他时间事件，这使得任务更为复杂和具有挑战性。", "innovation": "提出了一种新的问题，名称为高动态范围动态新颖视图合成（HDR DNVS），强调需要同时建模临时辐射变化和从LDR到HDR的复杂空间变换。为此，引入了HDR-4DGS，这是一种具有创新性的动态调色模块的高斯点云架构，能够保持时间辐射的一致性，通过动态适应辐射分布适应调色函数。", "conclusion": "HDR-4DGS在量化性能和视觉保真度方面超越了现有的最先进的方法，能够从任意视角和时间实例生成高逼真度的HDR渲染图。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21922", "html_url": "https://arxiv.org/abs/2509.21922", "title": "基础模型中的空间推理：基于对象的空间理解基准测试", "title_en": "Spatial Reasoning in Foundation Models: Benchmarking Object-Centric Spatial Understanding", "authors": "Vahid Mirjalili,Ramin Giahi,Sriram Kollipara,Akshay Kekuda,Kehui Yao,Kai Zhao,Jianpeng Xu,Kaushiki Nag,Sinduja Subramaniam,Topojoy Biswas,Evren Korpeoglu,Kannan Achan", "background": "空间理解是视觉基础模型的关键能力。尽管大型视觉模型或视觉-语言模型（VLMs）在最近的进展中扩大了识别能力，但大多数基准测试更侧重于定位准确性，而较少关注模型是否捕捉了场景中物体的布局和关系。这之间的差距是重大的；有效的场景理解不仅需要识别物体，还需要推理它们的相对位置、分组及其深度。", "innovation": "本文提出了一个系统性的基准测试，用于评估基础模型的空间中心型推理能力。使用控制的合成数据集，评估在三个任务上的最新视觉模型（例如 GroundingDINO、Florence-2、OWLv2）和大型 VLMs（例如 InternVL、LLaVA、GPT-4o）。研究发现，这些模型之间存在稳定权衡：如 GroundingDINO 和 OWLv2 这样的检测器能够提供精确的框但缺乏关系推理，而如 SmolVLM 和 GPT-4o 之类的 VLMs 能够提供粗略的布局线索和流畅的说明，但却难以处理细粒度的空间语境。", "conclusion": "研究突显了定位和真实空间理解之间的差距，并指出了社区中需要空间觉知的基础模型。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21917", "html_url": "https://arxiv.org/abs/2509.21917", "title": "驯化基于流的I2V模型以实现创意视频编辑", "title_en": "Taming Flow-based I2V Models for Creative Video Editing", "authors": "Xianghao Kong,Hansheng Chen,Yuwei Guo,Lvmin Zhang,Gordon Wetzstein,Maneesh Agrawala,Anyi Rao", "background": "尽管图像编辑技术取得了显著进步，但由于视频编辑需要根据用户意图修改视频，从而增加了难度，现有的基于图像的视频编辑方法要么需要特定模型的逆向设计，要么需要大量的优化，这限制了它们利用最新的图像到视频（I2V）模型的能力，从而将图像编辑模型的编辑能力迁移到视频领域。", "innovation": "我们提出了IF-V2V（无需逆向的流匹配I2V模型适应方法），该方法无需显著的计算开销即可实现无需逆向的基于流匹配的I2V模型适应于视频编辑。通过引入向量场修正与样本偏差，我们的方法将源视频的信息纳入去噪过程，同时通过结构与运动保护初始化来生成具有结构信息嵌入的运动感知的时间相关噪声，以模型无偏的方式保证与源视频的一致性。此外，我们还提出了一种偏差缓存机制，以最小化矢量修正去噪过程的额外计算成本，而不显著影响编辑质量。", "conclusion": "我们的方法在编辑质量和一致性方面优于现有方法，提供了一个轻量级的即插即用解决方案，用于实现视觉创意。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21926", "html_url": "https://arxiv.org/abs/2509.21926", "title": "PANICL: 降低成本单个提示依赖性在视觉上下文学习中的影响", "title_en": "PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning", "authors": "Jiahao Zhang,Bowen Wang,Hong Liu,Yuta Nakashima,Hajime Nagahara", "background": "视觉上下文学习（VICL）通过输入-输出图像对（或示例）作为提示，与查询图像一起引导模型执行多种视觉任务。然而，这种方法常常过度依赖单一的在上下文中的示例，导致预测倾向于偏差且不稳定。", "innovation": "提出了基于补丁的$ k $最近邻视觉上下文学习（PANICL），这是一种无需训练的一般性框架，通过利用多个示例，缓解了过度依赖单个示例的问题。PANICL通过平滑示例间的分配评分，减少了偏差，同时不需要额外的训练。", "conclusion": "通过在多个任务上的广泛实验，包括前景分割、单目标检测、上色、多目标分割和关键点检测，PANICL展现了一致优于强大基线模型的性能。此外，PANICL对领域迁移表现出较强的稳健性，无论是在数据集级别的迁移（如从COCO到Pascal）还是标签空间级别的迁移（如FSS-1000），并且在其他多种VICL模型（如SegGPT、Painter和LVM）上也有良好的一般性，体现出其灵活性和广泛的适用性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21871", "html_url": "https://arxiv.org/abs/2509.21871", "title": "解锁美的本质：相对绝对策略优化下的高级审美推理", "title_en": "Unlocking the Essence of Beauty: Advanced Aesthetic Reasoning with Relative-Absolute Policy Optimization", "authors": "Boyang Liu,Yifan Hu,Senjie Jin,Shihan Dou,Gonglei Shi,Jie Shao,Tao Gui,Xuanjing Huang", "background": "多模态大型语言模型（MLLMs）适合于图像美学评估，因为它们能够利用跨模态理解能力捕捉高级美学特征。然而，美学推理数据的稀缺性以及美学判断的主观性质使得MLLMs难以生成准确且具有解释性的美学判断。为了应对这些挑战，本文提出了一种新颖的美学推理框架Aes-R1，该框架结合了强化学习（RL）来解决上述问题。", "innovation": "Aes-R1框架通过集成一个名为AesCoT的管道来构建和筛选高质连锁思考美学推理数据，以支持模型的冷启动。在模型学习生成结构化解释后再进行评分。进一步引入了一种创新的RL算法——相对绝对策略优化（RAPO），该算法能够同时优化绝对评分回归和相对排名顺序，从而提高单幅图像精度和跨图像偏好判断。Aes-R1框架使得MLLMs能够在统一框架下生成与评分一致的结构化解释，提升美学评分与推理能力。", "conclusion": "大量实验表明，Aes-R1将骨干网络的平均PLCC/SRCC提高了47.9%/34.8%，超过同类规模最佳基线。此外，更多的消融研究验证了Aes-R1在有限监督和跨分布情况下的稳健泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21916", "html_url": "https://arxiv.org/abs/2509.21916", "title": "恶劣天气条件下基于对比学习的车辆检测增强", "title_en": "Enhancing Vehicle Detection under Adverse Weather Conditions with Contrastive Learning", "authors": "Boying Li,Chang Liu,Petter Kyösti,Mattias Öhman,Devashish Singha Roy,Sofia Plazzi,Hamam Mokayed,Olle Hagner", "background": "在北欧地区，无人机图像中的车辆检测面临强可见性挑战和由不同雪覆盖水平引起的领域偏移。虽然标注数据成本高，但未标注数据可以通过简单的无人机飞行便宜地获得。此外，遥感的常见挑战包括小而稀疏的目标以及计算成本限制也影响着车辆检测。", "innovation": "本文提出了一种侧载-CL-适应框架，通过在预训练阶段使用未标注数据进行对比学习训练基于CNN的表示提取器，并在微调阶段将其加载到冻结的YOLO11n主干上。通过广泛实验，研究了不同的融合方法和粒度，以找到鲁棒的侧载-CL-适应方法。", "conclusion": "所提出的侧载-CL-适应模型在NVD数据集上将mAP50的检测性能提高了3.8%至9.5%。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21930", "html_url": "https://arxiv.org/abs/2509.21930", "title": "DynaNav：高效视觉导航中的动态特征和层选择", "title_en": "DynaNav: Dynamic Feature and Layer Selection for Efficient Visual Navigation", "authors": "Jiahui Wang,Changhao Chen", "background": "视觉导航对于机器人技术和嵌入式AI至关重要。然而，现有的基础模型，尤其是具有变压器解码器的模型，由于计算开销高且缺乏解释性，限制了它们在资源紧张场景中的部署。", "innovation": "提出了一种名为DynaNav的动态视觉导航框架，该框架根据场景复杂性自适应选择特征和层。采用可训练的稀疏特征选择器提高效率和解释性，并将特征选择整合到早期退出机制中，通过贝叶斯优化确定最佳退出阈值以降低计算成本。相比ViNT，DynaNav在FLOPs、推理时间和内存使用方面分别实现了2.26倍、42.3%和32.8%的改进，同时在四个公开数据集上提升了导航性能。", "conclusion": "实验结果表明，DynaNav在实际场景数据集和模拟环境中均表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21918", "html_url": "https://arxiv.org/abs/2509.21918", "title": "基于自监督学习的多视图人群计数", "title_en": "Multi-View Crowd Counting With Self-Supervised Learning", "authors": "Hong Mo,Xiong Zhang,Tengfei Shi,Zhongbo Wu", "background": "近年来，多视角计数（MVC）方法引起了显著的研究兴趣，并促进了显著的进步。然而，大多数MVC方法集中于通过完全监督学习（FSL）范式改进性能，这通常需要大量标注数据。", "innovation": "本文提出了一种新颖的自监督学习（SSL）框架SSLCounter，利用神经体积渲染来减轻对大规模标注数据集的依赖。SSLCounter通过学习场景的隐式表示，能够通过分歧神经渲染重建连续几何形状及其2D视图依赖的复杂外观，其灵活性使其能无缝集成到现有框架中，并且实验结果表明，SSLCounter在多个MVC基准测试中表现出众，即使使用70%的训练数据也能达到可竞争的性能，展示了其卓越的数据效率。", "conclusion": "SSLCounter不仅展示了最先进的性能，而且使用较少的数据量也能达到可竞争的性能，展现出其在多视角计数领域的优越数据效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21894", "html_url": "https://arxiv.org/abs/2509.21894", "title": "LG-CD：通过SAM2调整实现增强的语言引导变化检测", "title_en": "LG-CD: Enhancing Language-Guided Change Detection through SAM2 Adaptation", "authors": "Yixiao Liu(1),Yizhou Yang(1),Jinwen Li(2),Jun Tao(1),Ruoyu Li(1),Xiangkun Wang(1),Min Zhu(1),Junlong Cheng(1) ((1) College of Computer Science, Sichuan University, China, (2) School of Computer Science and Technology, Xinjiang University, China)", "background": "遥感变化检测（RSCD）通常通过分析多时相图像来识别地表覆盖或表面条件的变化。目前，大多数基于深度学习的方法主要集中在学习单一模式的视觉信息，而忽略了来自多模态数据（如文本）所提供的丰富语义信息。针对这一限制，本文提出了一种名为LG-CD的语言引导变化检测模型。", "innovation": "该模型利用自然语言提示引导网络关注感兴趣的区域，显著提高了变化检测的准确性和鲁棒性。LG-CD利用视觉基础模型(SAM2)作为特征提取器，用于从高到低分辨率的双时相遥感图像中捕获多尺度金字塔特征。此外，该模型通过设计文本融合注意力模块（TFAM）将视觉和文本信息对齐，使模型能够使用文本提示聚焦在目标变化区域。最后，实现了一个视觉-语义融合解码器（V-SFD），通过交叉注意力机制深入整合视觉和语义信息，生成高度精确的变化检测掩码。", "conclusion": "在LEVIR-CD、WHU-CD和SYSU-CD三个数据集上的实验表明，LG-CD在变化检测方面始终优于现有最先进的方法。此外，本文的方法通过利用多模态信息为实现通用变化检测提供了新的见解。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21927", "html_url": "https://arxiv.org/abs/2509.21927", "title": "SingRef6D：基于单个RGB参考的单目新物体姿态估计", "title_en": "SingRef6D: Monocular Novel Object Pose Estimation with a Single RGB Reference", "authors": "Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee", "background": "最近的6D姿态估计方法虽然表现出色，但在实际应用中仍面临一些限制。例如，很多方法高度依赖传感器深度，可能会在透明或高反射材质等具有挑战性的表面条件下失效。同时，基于RGB的方法在低光和无纹理场景中进行匹配时表现不够稳健，因为它们缺乏几何信息。这些限制促使我们提出了SingRef6D，该方法仅需一张单个RGB图像作为参考，无需昂贵的深度传感器、多视图图像采集，或训练视图合成模型和神经场模型。这使得SingRef6D能够在资源有限的场景下保持鲁棒性。", "innovation": "我们框架包含两大创新点。首先，提出了一种基于token-scaler的微调机制和新的优化损失，该机制在Depth-Anything v2的基础上进一步增强了其预测准确深度的能力，即使在具有挑战性的表面上也能预测准确的深度。其次，由于深度信息的可用性，我们引入了深度感知匹配过程，通过有效整合LoFTR中的空间关系，使得我们的系统能够处理具有挑战性的材质和照明条件下的匹配任务。实验证明，在REAL275、ClearPose和Toyota-Light数据集上，我们的方法优于目前最先进的方法，在平均召回率达到6.1%的提高。", "conclusion": "我们的SingRef6D框架通过仅使用单个RGB参考图像和两项创新技术，提高了6D姿态估计的鲁棒性和准确性，尤其在低光、无纹理和具有挑战性表面的条件下表现优异，显著超越了最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21953", "html_url": "https://arxiv.org/abs/2509.21953", "title": "MultiCrafter: 基于空间解缠注意力和身份感知强化学习的高保真多主体生成", "title_en": "MultiCrafter: High-Fidelity Multi-Subject Generation via Spatially Disentangled Attention and Identity-Aware Reinforcement Learning", "authors": "Tao Wu,Yibo Jiang,Yehao Lu,Zhizhong Wang,Zeyi Huang,Zequn Qin,Xi Li", "background": "多主体图像生成旨在在单个图像中合成用户提供的人物，同时保持人物的高保真度、确保指令一致性，并与人类审美偏好相一致。然而，现有的方法，尤其是基于上下文学习范式的模型，受限于其简单的重建目标，导致严重的属性泄漏，从而损害了人物的保真度，同时也未能与人类复杂的审美偏好相匹配。", "innovation": "为解决这一问题，我们提出了MultiCrafter框架，旨在确保高保真度与偏好对齐的生成。首先，我们发现属性泄漏的根本原因是不同人物在生成过程中注意力的显著交织。因此，我们引入了显式的空间监督，以明确分离每个主题的注意力区域，有效缓解了属性泄漏。其次，我们采用了Mixture-of-Experts架构，增强模型的容量，使得不同的专家能够关注不同的场景。最后，我们设计了一个新颖的在线强化学习框架，通过评分机制精确评估多主体保真度，并针对Mixture-of-Experts架构制定了更稳定的训练策略。实验验证了我们的框架在高保真度和人类偏好匹配方面具有显著效果，", "conclusion": "实验结果显示，我们的框架在保持人物高保真度的同时，更好地与人类偏好相匹配。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21938", "html_url": "https://arxiv.org/abs/2509.21938", "title": "SemanticControl：一种处理ControlNet中松散对齐视觉条件的无训练方法", "title_en": "SemanticControl: A Training-Free Approach for Handling Loosely Aligned Visual Conditions in ControlNet", "authors": "Woosung Joung,Daewon Chae,Jinkyu Kim", "background": "ControlNet通过引入额外的视觉条件（如深度图或边缘图）实现了文本到图像扩散模型的详细空间控制。但这种方法的有效性高度依赖于与文本提示生成目标精确对齐的视觉条件，而在实践中，由于目标场景的不常见或想象性，这种要求通常难以满足。例如，很难生成一只以特定姿势烹饪的猫的图像，由于缺乏合适的视觉条件。相比之下，结构相似的提示通常可以在更常见的场景中找到，例如人类烹饪的姿势。然而，现有的ControlNet模型在利用这类松散对齐的但具有语义相关性的视觉条件时往往表现不佳，导致文本一致性低或出现视觉伪影。", "innovation": "我们提出了一个无训练方法——SemanticControl，用于有效利用松散对齐的但具语义相关性的视觉条件。该方法通过自适应地抑制与提示冲突的视觉条件影响，同时强化来自文本的指导。具体做法是先用与视觉条件对齐的代理提示（如“一个弹吉他的人”来处理姿势条件）运行辅助去噪过程，提取出有用的关注掩码，然后在实际目标提示的去噪过程中使用这些掩码。实验结果表明，在各种条件下（包括深度图、边缘图和人体骨架），我们的方法能够提高性能，优于现有基线。我们将代码发布在[current link here]这个地址上。", "conclusion": "实验证明，在各种条件下（包括深度图、边缘图和人体骨架），我们的方法能够有效提高松散对齐条件下的性能，优于现有基线。我们的方法能够为ControlNet提供一种处理语义相关但松散对齐的视觉条件的新途径，从而提升模型的整体表现。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21965", "html_url": "https://arxiv.org/abs/2509.21965", "title": "PartSAM：一种基于原始3D数据的可提示的大规模部分分割模型", "title_en": "PartSAM: A Scalable Promptable Part Segmentation Model Trained on Native 3D Data", "authors": "Zhe Zhu,Le Wan,Rui Xu,Yiheng Zhang,Honghua Chen,Zhiyang Dou,Cheng Lin,Yuan Liu,Mingqiang Wei", "background": "3D物体分割成部分是计算机视觉领域长期存在的挑战。最近的研究转向开放世界部分分割，通过从2D基础模型如SAM中转移监督，将多视角掩码提升到3D，但这种方法无法捕捉内在几何结构，导致表面理解、不可控分割和有限泛化能力。为了克服这个挑战，我们提出了PartSAM，它是第一个基于大型3D数据训练的可提示部分分割模型。", "innovation": "PartSAM采用了与SAM相似的设计理念，使用编码器-解码器架构，通过三层基干的双分支编码器生成空间结构化令牌，实现可扩展的部分感知表示学习。PartSAM还引入了一种模型在环注释流水线，从在线资源中提炼出约五百万个3D形状-部分对，提供多样和精细的标签，使模型具有开放世界的潜在能力。结果表明，PartSAM在多个基准测试上大幅超越了最先进的方法，标志着3D部分理解的基础模型的一个重要进展。", "conclusion": "PartSAM在单个提示下实现了高度准确的部分识别，并在Segment-Every-Part模式下自动分解形状到表层和内部结构。广泛实验表明，PartSAM在多个基准测试上的性能均明显优于现有的先进方法，对于3D部分理解的基础模型具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21980", "html_url": "https://arxiv.org/abs/2509.21980", "title": "通过注视辅助的视觉助理交互模式中的歧义解决", "title_en": "Resolving Ambiguity in Gaze-Facilitated Visual Assistant Interaction Paradigm", "authors": "Zeyu Wang,Baiyu Chen,Kun Yan,Hongjing Piao,Hao Xue,Flora D. Salim,Yuanchun Shi,Yuntao Wang", "background": "随着智能眼镜的普及，用户的注意力被集成到视觉语言模型（VLMs）中，以便在日常场景中简化多模态查询。然而，利用注视数据来建模用户注意力可能会引入模糊性挑战：（1）用户的话语问题可能模糊不清，通过使用代词或省略背景信息；（2）人类的注视模式可能会很嘈杂，并且与他们所说的话语之间表现出复杂的时空关系。早期的研究只考虑单张图片作为视觉模态输入，未能捕捉用户注意力的动态性质。", "innovation": "我们引入了GLARIFY（基于时空注视信息增强模型效果的方法），以利用时空注视信息来增强VLMs在实际应用中的效果。首先，我们通过分析数百个带有注视模态的查询样本，展示了用户注视模式的嘈杂性质。然后，我们使用GPT-4o设计了一个自动数据合成管道来生成GLARIFY-Ambi数据集，其中包括针对嘈杂的注视模式的专有思维链（CoT）过程。最后，我们设计了一个热图模块，将注视信息整合到最先进的VLMs中，同时保留其预训练知识。通过剔除GLARIFY的实验，将其应用于保留预训练知识的同时的VLMs，实验表明GLARIFY显著优于基准。", "conclusion": "通过稳健地对齐VLMs与人类注意力，GLARIFY铺平了与视觉辅助视觉助理进行可用且直观的交互的途径。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21967", "html_url": "https://arxiv.org/abs/2509.21967", "title": "无参考图像对比度评估中的定制EfficientNet-B0", "title_en": "No-Reference Image Contrast Assessment with Customized EfficientNet-B0", "authors": "Javad Hassannataj Joloudari,Bita Mesbahzadeh,Omid Zare,Emrah Arslan,Roohallah Alizadehsani,Hossein Moosaei", "background": "图像对比度是视觉感知的基本因素，对整体图像质量起着关键作用。然而，大多数无参考图像质量评估（NR IQA）模型在处理多样化的真实世界条件下的对比度失真时难以准确评价。本研究针对此问题，提出了一种基于深度学习的框架，用于盲域对比度质量评估。该框架通过对三种预训练架构进行定制和微调，分别构建了EfficientNet B0、ResNet18、MobileNetV2以及一个基于Siamese网络的辅助模型，用于评估感知均值意见得分（Perceptual Mean Opinion Score, PMOS）。模型利用目标数据增强在两个基准数据集CID2013和CCID2014上进行了训练，这些数据集包含了合成和真实的对比度失真。评估采用皮尔森线性相关系数（PLCC）和 spearman等级相关系数（SRCC），以评估预测分数与人类评分之间的对齐程度。", "innovation": "该研究提出了一种新的无参考对比度质量评估框架，通过定制和微调三种预训练的深度学习模型（EfficientNet B0、ResNet18、MobileNetV2）以及基于Siamese网络的辅助模型。每种模型均加入了对比度感知回归头，并在两个基准数据集上进行训练，以适应感知对比度失真。实验结果表明，定制的EfficientNet B0模型在评估对比度质量方面表现优异，超过了传统的评估方法和其他深度模型基准，并且显示出在无参考对比度质量评估中应用的潜力和效果。", "conclusion": "该研究提出的方法表明，对比度感知适应的轻量级预训练网络模型能够提供优质且可扩展的解决方案，适用于实时和资源受限的应用场景。定制的EfficientNet B0在两个基准数据集上的表现优于其他方法，展示了其在无参考对比度质量评估中的高鲁棒性和有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21992", "html_url": "https://arxiv.org/abs/2509.21992", "title": "DualFocus:利用空间-焦距双重变分约束的从聚焦成像获取深度", "title_en": "DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints", "authors": "Sungmin Woo,Sangyoun Lee", "background": "Depth-from-Focus (DFF) 技术通过分析不同焦距下采集的多张图像的焦点线索来实现精确的深度估计。尽管基于学习的方法已经在这一领域取得进展，但它们在复杂场景中表现不佳，特别是在细纹理或深度急剧变化的场景中，这里的焦点线索可能变得模糊或误导。", "innovation": "提出了一个新的DFF框架——DualFocus，该框架利用焦距堆栈中由焦点变化引起的独特梯度模式，并联合建模空间和焦距维度上的焦点变化。引入了针对DFF定制的变分公式，包含双重约束：空间约束利用不同焦距级次之间的梯度模式变化来区分真实的深度边缘和纹理伪影，聚焦约束则确保符合物理聚焦行为的单一模式和单调聚焦概率。", "conclusion": "在四个公开数据集上的全面实验表明，DualFocus在深度准确性和感知质量方面始终优于当今最先进方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21950", "html_url": "https://arxiv.org/abs/2509.21950", "title": "为MLLMs量身定制的视觉情感评估：开放词汇、多维度和可扩展的方法", "title_en": "Customizing Visual Emotion Evaluation for MLLMs: An Open-vocabulary, Multifaceted, and Scalable Approach", "authors": "Daiqing Wu,Dongbao Yang,Sicheng Zhao,Can Ma,Yu Zhou", "background": "最近，多模态大型语言模型（MLLMs）在多种任务中表现出色，不断超越人们对它们能力的预期。然而，他们在从图像中感知情感方面的专业性仍然存在争议，尤其是在零样本场景中，不同研究的结果各不相同。这背后的原因部分是由于现有评估方法的限制，包括忽视可能的回答、情感分类有限、忽略上下文因素以及手工标注劳动密集等。在此背景下，我们提出了一种情感陈述评判任务来克服这些限制，同时开发了一个自动化流程，可以高效地构建情感中心的陈述并尽量减少人力投入。", "innovation": "我们提出了一种情感陈述评判任务，以及一个自动化的任务构建流程，克服了现有评估方法的限制。通过系统地评估目前主流的MLLMs，我们展示了它们在情感理解和基于上下文的情感判断方面的优势，同时指出了他们在理解感知主观性方面相对的局限性。甚至像GPT4o这样的顶级模型也表现出了明显的人机差距，这突显了未来改进的核心领域。通过构建一个基础评估框架并进行全面的MLLM评估，这项工作希望为MLLMs的情感智能的进步做出贡献。", "conclusion": "我们的研究表明，MLLMs在情感理解与基于上下文的情感判断方面表现出了更高的性能，但也显示出在理解感知主观性方面的局限性。相比于人类，即使是最顶尖的MLLMs如GPT4o也存在显著的性能差距，这为未来的工作指明了关键方向。通过开发基础评估框架并进行全面的MLLM评估，我们希望为MLLMs的情感智能的进步做出贡献。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21976", "html_url": "https://arxiv.org/abs/2509.21976", "title": "Geo-R1：使用强化微调改进少量样本地理空间指代表达理解", "title_en": "Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning", "authors": "Zilun Zhang,Zian Guan,Tiancheng Zhao,Haozhan Shen,Tianyu Li,Yuxiang Cai,Zhonggen Su,Zhaojun Liu,Jianwei Yin,Xiang Li", "background": "遥感领域中参考表达理解面临独特挑战，因为这需要在复杂的对象-上下文关系中进行推理。虽然基于多模态大型语言模型的监督微调（SFT）在大规模标注数据集上表现出色，但在数据稀缺的情况下却表现不佳，导致泛化能力较差。", "innovation": "作者提出了Geo-R1，这是一种以推理为中心的强化微调（RFT）范式，专门针对少量样本下的地理空间参考进行设计。Geo-R1强制模型首先生成明确且可解释的推理链以分解参考表达，然后利用这些论据来定位目标对象。这一‘先推理，后行动’的过程使得模型能够更有效地利用有限的标注，并提高泛化能力和可解释性。", "conclusion": "Geo-R1在三个精心设计的少量样本地理空间参考基准测试中表现优异，超过了SFT基线，并展示了强大的跨数据集泛化能力，证实了其鲁棒性。相关代码和数据会在指定链接处发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21994", "html_url": "https://arxiv.org/abs/2509.21994", "title": "率为失真优化的协作感知通信", "title_en": "Rate-Distortion Optimized Communication for Collaborative Perception", "authors": "Genjia Liu,Anning Hu,Yue Hu,Wenjun Zhang,Siheng Chen", "background": "协作感知是指通过多个代理共用有限带宽资源的视觉信息来增强环境理解。尽管之前的研究所探讨了任务性能和通信量之间的经验权衡，但理论基础仍然存在较大空白。", "innovation": "本文借鉴信息理论，提出了一个实用的信息率-失真理论，该理论特别用于分析目标导向多代理系统中的性能-通信权衡。该理论明确了设计最优通信策略的两个关键条件：提供实际相关的信息和传输无冗余的消息。在此基础上，我们提出了RDcomm，这是一种通信高效的协作感知框架，其两个关键创新点为：任务熵离散编码和基于互信息的消息选择。任务熵离散编码通过将与任务相关的代码长度分配给具有任务相关特征的主体以最大化实际相关信息的效率；基于互信息的消息选择通过利用互信息神经估计来接近无冗余的最佳状态。", "conclusion": "在3D物体检测和BEV分割实验中，RDcomm展示了在DAIR-V2X和OPV2V上达到最先进的精度，同时通信体积减少了高达108倍。该代码将被开放。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22010", "html_url": "https://arxiv.org/abs/2509.22010", "title": "CoFFT: 预见聚焦思考链对视觉语言模型的增强", "title_en": "CoFFT: Chain of Foresight-Focus Thought for Visual Language Models", "authors": "Xinyu Zhang,Yuxuan Dong,Lingling Zhang,Chengyou Jia,Zhuohang Dang,Basura Fernando,Jun Liu,Mike Zheng Shou", "background": "尽管视觉语言模型（VLMs）取得了重大进展，但仍受限于视觉输入的复杂性和冗余性。当图像包含大量无关信息时，VLMs 可能会受到干扰，导致生成过多的任务无关推理过程甚至幻觉。这一限制源于模型在推理过程中无法精准发现并处理所需区域。", "innovation": "提出了 Chain of Foresight-Focus Thought (CoFFT)，这是一种无需训练的新颖方法，通过模拟人类视觉认知来增强 VLMs 的视觉推理能力。提出了三条主要阶段：（1）多样样本生成：生成多样化的推理样本以探索潜在的推理路径，每个样本包含几个推理步骤；（2）双重预见解码：根据视觉焦点和推理进程严格评估这些样本，并将最佳样本的首个步骤加入推理过程；（3）视觉焦点调整：精确调整视觉焦点，指向对未来推理最有益的区域，然后返回到第（1）阶段生成后续的推理样本，直到得出最后的答案。这些阶段的迭代功能形成了一种相互依存的循环，推理指导视觉焦点，视觉焦点又指导后续推理。", "conclusion": "在多个基准测试中使用 Qwen2.5-VL、InternVL-2.5 和 Llava-Next 进行实验，结果显示 CoFFT 为视觉语言模型带来了 3.1-5.8% 的一致性能提高，并具有可控的增序列计算开销。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21989", "html_url": "https://arxiv.org/abs/2509.21989", "title": "Mind-the-Glitch: 用于检测主体驱动生成中不一致性视觉对应", "title_en": "Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation", "authors": "Abdelrahman Eldesokey,Aleksandar Cvejic,Bernard Ghanem,Peter Wonka", "background": "扩散模型的预训练模型后端已知能够编码丰富的语义特征，同时也需要包含视觉特征以支持图像合成能力。然而，隔离这些视觉特征在没有标注数据集的情况下颇具挑战性。本研究利用现有主题驱动图像生成数据集，引入了自动构建标注语义和视觉对应的图像对的流水线，并设计对比架构分离这两种特征类型。", "innovation": "提出了一个新颖的方法，可以从预训练扩散模型的后端分离出视觉和语义特征，类似于已有的语义对应方法。研究引入了新颖的评估指标Visual Semantic Matching (VSM)，用于量化的视觉不一致性，并能够实现视觉不一致区域的空间定位。这是首次在主题驱动生成中同时支持不一致性量化和定位的方法。", "conclusion": "该方法在量化学术生成中具有优势，提出的新评价指标VSM可以有效检测视觉不一致性，并且有助于该任务的进步。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21979", "html_url": "https://arxiv.org/abs/2509.21979", "title": "在医学视觉语言模型中基准测试和缓解心理奉承行为", "title_en": "Benchmarking and Mitigate Psychological Sycophancy in Medical Vision-Language Models", "authors": "Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu", "background": "视觉语言模型（VLMs）越来越多地融入临床工作流程中，但在临床应用中，这些模型往往表现出讨好行为，优先考虑与用户语言表述、社会暗示或所感知权威的一致性，而不是基于证据的推理。研究通过一个全新的临床导向基准来评估医学领域的奉承行为，并提出了一个基于PathVQA、SLAKE和VQA-RAD的医学奉承数据集，该数据集按照不同的器官系统和成像模态进行分层。压力模板包括各种形式的奉承策略，用于在各种视觉语言模型上进行对抗实验。实验发现，这些模型通常容易受到这些影响，尽管模型的准确性或规模与错误回应的相关性较弱。模仿和专家提供修正的触发器被发现是最有效的，表明模型存在一种独立于视觉证据的偏差机制。", "innovation": "提出了视觉信息净化以支持证据回应（Visual Information Purification for Evidence based Response，VIPER）作为缓解策略，该策略能够筛选出非证据性内容（如社会压力），然后生成受限证据的初始答案。这一框架能够平均减少约20%的奉承行为，优于基线模型的同时保持了可解释性。该基准分析和缓解框架为医学VLMs的稳健部署奠定了基础，强调了需要基于证据的防御机制。", "conclusion": "研究通过基准测试揭示医疗视觉语言模型中的奉承行为，并通过引入VIPER框架缓解这种现象，同时在不牺牲解释性的情况下提高了模型的鲁棒性，为实际临床医生互动中的广泛应用提供了基础。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22063", "html_url": "https://arxiv.org/abs/2509.22063", "title": "跨类别引导生成建模的高质量声源分离", "title_en": "High-Quality Sound Separation Across Diverse Categories via Visually-Guided Generative Modeling", "authors": "Chao Huang,Susan Liang,Yapeng Tian,Anurag Kumar,Chenliang Xu", "background": "现有方法通常将声源分离问题视为基于掩码的回归问题，并取得了显著进展，但面对从多种类别中高质量地分离声音时无法充分捕捉复杂的数据分布。DAVIS 通过引入强大的生成建模方法，特别是去噪扩散概率模型和流动匹配，来解决这一问题。", "innovation": "DAVIS 采用了一种新颖的方法，即利用去噪扩散概率模型 (DDPM) 和近期的流动匹配 (FM)，并在专门的分离 U-Net 架构中集成，通过从噪声分布中直接合成所需的分离声音频谱图，同时根据混合音频输入和相关视觉信息进行条件生成，从而实现了高质量的声源分离。", "conclusion": "DAVIS 在标准 AVE 和 MUSIC 数据集上的比较评估表明，其 DMMP 和流动匹配变体均在声源分离质量上超过了现有方法，证明了其生成框架的有效性，适用于音频-视觉声源分离任务。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22019", "html_url": "https://arxiv.org/abs/2509.22019", "title": "EgoInstruct：面对面教学互动的主观视频数据集及多模态LLM基准测试", "title_en": "EgoInstruct: An Egocentric Video Dataset of Face-to-face Instructional Interactions with Multi-modal LLM Benchmarking", "authors": "Yuki Sakai,Ryosuke Furuta,Juichun Yen,Yoichi Sato", "background": "在相同的物理空间内，分析讲师与学习者的教学互动是教育支持和技能传授中的关键问题。然而，这类面对面的教学场景在计算机视觉中并没有系统地进行研究。原因包括缺乏适合的数据集和分析技术的限制。", "innovation": "本文提出了一种新的主观视角下的视频数据集，用于面对面教学互动，并提供了两个基本任务的注释，从而为全面理解教学互动提供了一步。实验使用这种数据集对多模态大规模语言模型进行了基准测试，并发现这些模型在处理多模态信息（言语内容和语调、视线和身体动作、视觉背景）时优于专门任务的模型。", "conclusion": "本研究通过多模态大规模语言模型在未经过特定任务微调的情况下优于专门模型的结果，表明了其在整体理解教学互动方面的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21984", "html_url": "https://arxiv.org/abs/2509.21984", "title": "从偏差到平衡：探索和减轻LVLM中的空间偏差", "title_en": "From Bias to Balance: Exploring and Mitigating Spatial Bias in LVLMs", "authors": "Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Weili Guan,Jun Yu,Min Zhang", "background": "大规模的跨模态语言模型（LVLMs）在多种跨模态任务中取得了显著的成果，但它们对空间变化的鲁棒性仍然不充分理解。当前的LVLMs在相同的关键视觉信息位于不同位置图像中时，会表现出不一致的输出结果，这反映了它们在空间语义理解上的根本局限。进一步分析表明，这种现象并非由视觉编码器引起，视觉编码器能够可靠地感知和解释图像中的内容，而是由于语言模型部分中位置嵌入设计的不均衡导致的。广泛采用的位置嵌入策略，在跨模态交互过程中引入了不均衡，使得图像令牌在不同位置对语义理解产生不等的影响。", "innovation": "本文引入了一种简单有效的机制Balanced Position Assignment (BaPA)，即平衡位置分配方法，在语言模型组件中为所有图像令牌分配相同的位置嵌入，从而促进视觉信息的更均衡整合。大量实验表明，BaPA不仅能增强LVLMs的空间鲁棒性，而且与轻量级微调相结合时，还能进一步提高其在多种跨模态基准测试中的性能。此外，进一步分析了信息流动，展示出BaPA能够实现平衡的注意力机制，从而实现更为全面的视觉理解能力。", "conclusion": "研究发现，虽然当前LVLMs在处理相同视觉信息在不同位置的跨模态任务中表现出不一致的结果，但这并非由视觉编码器引起，而是语言模型部分中位置嵌入设计的不平衡导致的结果。论文提出了一种简单有效的机制BaPA，能够实现图像令牌的平衡位置嵌入，从而提升LVLMs的空间鲁棒性并带来性能提升。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21991", "html_url": "https://arxiv.org/abs/2509.21991", "title": "ERGO: 高效的高分辨率视觉理解对于视觉语言模型", "title_en": "ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models", "authors": "Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim", "background": "高效处理高分辨率图像对于现实世界中的视觉-语言应用至关重要。然而，现有的大型视觉语言模型由于视觉标记数量庞大而产生了大量计算开销。随着‘基于图像思考’模型的出现，推理能力已不再局限于文本，而是扩展到了视觉领域。这种能力促使我们设计了一种两阶段的‘粗到细’推理管道：首先分析低分辨率图像以识别相关区域；然后在全分辨率下仅处理这些区域，并在后续阶段进行推理。这种方法在保留微小视觉细节的同时降低了计算成本。主要挑战在于推断哪些区域真正与给定查询相关。现有方法在输入图像下采样后的第一个阶段经常失效，因其依赖于感知驱动的推理，而有效的推理需要明确的视觉信息。因此，为了应对这一问题，我们提出了ERGO（Efficient Reasoning & Guided Observation），采用推理驱动的感知利用多模态上下文来确定关注点。我们的模型可以考虑感官不确定性，扩展裁剪区域以覆盖视觉上不确定的区域来回答问题。为此，我们在强化学习框架中开发了简单的高效奖励组件，以实现粗到细的感知。", "innovation": "我们提出了ERGO（Efficient Reasoning & Guided Observation），设计了一种两阶段的‘粗到细’推理管道，首先分析低分辨率图像识别相关区域，然后在全分辨率下仅处理这些区域的推理。这种方法在保留细粒度视觉细节的同时降低了计算成本，并采用推理驱动感知利用多模态上下文确定关注点，扩展裁剪区域以覆盖视觉上不确定的区域。我们在多个数据集上的实验表明，我们的方法在准确性和效率方面均超过了原模型和竞争方法，例如，在V*基准测试中，ERGO超越了Qwen2.5-VL-7B 4.7分，使用了23%的视觉标记，实现3倍的推理加速。", "conclusion": "我们的方法在多个数据集上表现出比原模型和竞争方法更高的准确性和更优的效率，尤其是在V*基准测试中，ERGO大幅度超越了Qwen2.5-VL-7B，证明了其在实际应用中的卓越性能。该代码和模型可在此访问：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22014", "html_url": "https://arxiv.org/abs/2509.22014", "title": "轻量级结构化多模态推理在临床场景理解中的应用", "title_en": "Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics", "authors": "Saurav Jha,Stefan K. Ehrlich", "background": "医疗机器人需要强大的多模态感知和推理能力以确保在动态临床环境中的安全性。当前的视觉-语言模型在一般用途上展现了强大的能力，但依然在时间推理、不确定性估计和结构化输出方面有限，这些都是机器人规划所需要的。", "innovation": "本文提出了一个轻量级的代理式多模态框架，用于视频场景理解。该框架结合了Qwen2.5-VL-3B-Instruct模型和基于SmolAgent的编排层，支持链式思维推理、语音-视觉融合以及动态工具调用。该框架生成结构化的场景图，并利用一个混合检索模块进行具有解释性和自适应性的推理。", "conclusion": "在Video-MME基准以及自定义临床数据集上的评估显示，该框架在准确性和鲁棒性方面与最先进的视觉-语言模型相比具有竞争力，其在机器人辅助手术、患者监护和决策支持方面的应用潜力得到了证实。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21990", "html_url": "https://arxiv.org/abs/2509.21990", "title": "WAVE：使用多模态大语言模型学习统一且多功能的音频-视觉嵌入", "title_en": "WAVE: Learning Unified & Versatile Audio-Visual Embeddings with Multimodal LLM", "authors": "Changli Tang,Qinfan Xiao,Ke Mei,Tianyi Wang,Fengyun Rao,Chao Zhang", "background": "虽然多模态大语言模型（LLMs）的嵌入在通用表示方面表现出色，但它们在动态模态（如音频和视频）的应用尚未得到充分探索。", "innovation": "WAVE是第一个基于LLM的统一表示空间嵌入模型，能够为文本、音频和视频模态创建统一的空间；WAVE采用一种新颖的分层特征融合策略和联合多模态、多任务训练的方法，实现跨模态检索和响应用户指令的提示感知嵌入两个关键能力。", "conclusion": "WAVE在MMEB-v2视频基准测试中设立了新的最新水平，并在音频和视频到音频检索中取得最佳结果。它的提示感知特性也在多模态问答中表现出色，显著优于现有嵌入模型。消融研究验证了联合训练策略的优越性，并且WAVE为跨模态、任意到任意应用提供了广泛的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21997", "html_url": "https://arxiv.org/abs/2509.21997", "title": "通过揭露幻觉来抑制它们：使用生成锚点的VLMs表示编辑", "title_en": "Exposing Hallucinations To Suppress Them: VLMs Representation Editing With Generative Anchors", "authors": "Youxu Shi,Suorong Yang,Dong Liu", "background": "多模态大语言模型（MLLMs）在各种视觉-语言任务中取得了显著的成功，但它们依然极易出现幻觉，即生成的内容虽然流畅但与视觉证据不一致。这种幻觉跨越了物体、属性和关系等多个层面，在更大的模型中仍然存在。现有的缓解方法通常需要额外的调整、手工构建的先验知识或将有效性与可扩展性做权衡。", "innovation": "本文提出了一种无训练的自我监督方法来减轻幻觉。该方法引入了一种新颖的幻觉放大机制：通过文本到图像模型将描述投影到视觉空间，揭示隐藏的幻觉信号，以无监督方式进行编辑。该方法利用双重锚点进行编辑，将表示向忠实的语义拉近，远离幻觉方向的路径。这种方法无需任何人类先验知识或额外的训练成本，既有效又高效。实验表明，该方法可显著减少对象、属性和关系层面的幻觉，同时基本保持高召回率和描述丰富性。此外，该方法在不同架构上表现出强大的泛化能力，对幻觉描述几乎没有副作用，具有鲁棒性和实际的即插即用特性。", "conclusion": "该方法通过揭露幻觉来抑制它们，能够显著减少MLLMs中的幻觉问题，同时保证描述的丰富性和模型的普适性。该方法将在开源实现。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22151", "html_url": "https://arxiv.org/abs/2509.22151", "title": "MultiMat：使用大型多模态模型进行程序化材料的多模态程序合成", "title_en": "MultiMat: Multimodal Program Synthesis for Procedural Materials using Large Multimodal Models", "authors": "Jonas Belouadi,Tamy Boubekeur,Adrien Kaiser", "background": "材料节点图是用于生成虚拟3D对象的程序化材料的2D通道的程序，包括诸如粗糙度和位移图之类的几何形状，以及诸如反射率（如色度和导电性图）的反射特性。这些在计算图形中用于参数化和任意分辨率地表示虚拟3D对象的外观。特别地，它们有向无环图结构及其中间状态提供了直观的外观建模理解和工作流程。然而，创建这样的图是一项具有挑战性的任务，通常需要专业的培训。虽然最近的神经程序合成方法试图简化这个过程，但它们仅将图表示为文本程序，未能捕捉到节点图本质上具有视觉空间特性这一点，这使得它们易于人类理解。", "innovation": "MultiMat提出了一种多模态程序合成框架，利用大型多模态模型处理视觉和文本图表示，以改进程序化材料图的生成。模型在高质量的程序化材料新数据集上进行训练，并与受约束的树搜索推理算法相结合，以确保句法有效性和高效地探索程序空间。", "conclusion": "实验结果表明，MultiMat的多模态程序合成方法在不加条件和加条件图合成中比纯文本基线更有效，且视觉质量和保真度更高，从而建立了最新的性能标准。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22186", "html_url": "https://arxiv.org/abs/2509.22186", "title": " MinerU2.5：一种用于高效高分辨率文档解析的解耦视觉语言模型", "title_en": "MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing", "authors": "Junbo Niu,Zheng Liu,Zhuangcheng Gu,Bin Wang,Linke Ouyang,Zhiyuan Zhao,Tao Chu,Tianyao He,Fan Wu,Qintong Zhang,Zhenjiang Jin,Guang Liang,Rui Zhang,Wenzheng Zhang,Yuan Qu,Zhifei Ren,Yuefeng Sun,Yuanhong Zheng,Dongsheng Ma,Zirui Tang,Boyu Niu,Ziyang Miao,Hejun Dong,Siyi Qian,Junyuan Zhang,Jingzhou Chen,Fangdong Wang,Xiaomeng Zhao,Liqun Wei,Wei Li,Shasha Wang,Ruiliang Xu,Yuanyuan Cao,Lu Chen,Qianqian Wu,Huaiyu Gu,Lindong Lu,Keming Wang,Dechen Lin,Guanlin Shen,Xuanhe Zhou,Linfeng Zhang,Yuhang Zang,Xiaoyi Dong,Jiaqi Wang,Bo Zhang,Lei Bai,Pei Chu,Weijia Li,Jiang Wu,Lijun Wu,Zhenxiang Li,Guangyu Wang,Zhongying Tu,Chao Xu,Kai Chen,Yu Qiao,Bowen Zhou,Dahua Lin,Wentao Zhang,Conghui He", "background": "当前存在一种需求，即需要一种高效且能处理高分辨率文档并能进行精准识别的视觉语言模型。现有的模型在处理高分辨率图像时通常会面临较高的计算成本，这限制了它们的应用范围和效率。", "innovation": "MinerU2.5 通过引入一种分层次、两阶段的解析策略，将全局布局分析与局部内容识别分离，实现了在保持高效计算的同时获得最先进的识别精度。具体而言，它首先在降采样图像上进行高效的全局布局分析，识别结构元素，避免处理高分辨率输入带来的计算负担。接着，在保留细节的高分辨率剪辑中进行精准的内容识别。此外，还开发了一个综合数据引擎来生成用于预训练和微调的大规模多样数据集。", "conclusion": "实验结果表明，MinerU2.5 在多种基准测试中表现出强大的文档解析能力，其综合性能超越了一般用途和特定领域模型，并且具有显著更低的计算开销。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21995", "html_url": "https://arxiv.org/abs/2509.21995", "title": "FailureAtlas：通过主动探索映射T2I模型的失败景观", "title_en": "FailureAtlas:Mapping the Failure Landscape of T2I Models via Active Exploration", "authors": "Muxi Chen,Zhaohua Zhang,Chenchen Zhao,Mingyang Chen,Wenyu Jiang,Tianwen Jiang,Jianhuan Zhuo,Yu Tang,Qiuyong Xiao,Jihong Zhang,Qiang Xu", "background": "静态基准虽然为比较Text-to-Image (T2I)模型提供了有价值的参考，但它们被动的设计缺乏诊断能力，难以揭示模型系统的失败全貌或找出根本原因。", "innovation": "提出了FailureAtlas框架，这是一个自主探索并大规模绘制T2I模型失败景观的新方法。FailureAtlas将错误发现视为对最小化、失败诱导概念的结构化搜索。通过引入新型加速技术，使这一计算爆炸性问题变得可处理。", "conclusion": "通过FailureAtlas，构建了一个原则性和可扩展的深度模型审计引擎，建立了新的、诊断优先的方法来指导生成AI模型的开发，以使其更具鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22132", "html_url": "https://arxiv.org/abs/2509.22132", "title": "基于单一不完整点云多视图增强的自监督点云完成", "title_en": "Self-Supervised Point Cloud Completion based on Multi-View Augmentations of Single Partial Point Cloud", "authors": "Jingjing Lu,Huilong Pi,Yunchuan Qin,Zhuo Tang,Ruihui Li", "background": "点云完成的目标是从部分观察中重建完整的形状。尽管现有方法取得了显著的性能，但仍存在一些限制：监督方法高度依赖于真实数据，难以推广到真实世界数据集；无监督方法需要完整的点云来组合不配对的训练数据；弱监督方法需要对象的多视角观察。现有的自监督方法经常由于其自监督信号的局限性而生成不令人满意的结果。", "innovation": "提出了一种基于单一不完整点云多视图增强的新型自监督点云完成方法。设计了一套基于单一不完整点云多视图增强的新型自监督信号，并首次将Mamba引入自监督点云完成任务，以提高模型生成高质量点云的能力。实验结果表明，该方法在合成和真实世界数据集上达到了最先进的结果。", "conclusion": "该方法解决了现有方法中存在的依赖真实数据、欠匹配训练数据以及自监督信号局限性等问题，能够在合成和真实世界数据集上取得最佳效果。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22112", "html_url": "https://arxiv.org/abs/2509.22112", "title": "用于可重新光照3D生成的大型材料高斯模型", "title_en": "Large Material Gaussian Model for Relightable 3D Generation", "authors": "Jingrui Ye,Lingting Zhu,Runze Zhang,Zeyu Hu,Yingda Yin,Lanjiong Li,Lequan Yu,Qingmin Liao", "background": "随着3D资产在各个行业中的需求不断增加，迫切需要高效且自动化的3D内容创建方法。最近，大规模重建模型利用3D高斯散点图和多视图扩散以及可扩展变换器实现了高效且高质量的3D渲染。然而，现有模型无法生成资产的材料属性，这对不同光照环境下的真实渲染至关重要。", "innovation": "本文提出了一种新的框架——大型材料高斯模型（MGM），旨在生成具有基于物理的渲染（PBR）材料的高质量3D内容，即通过条件化多视图材料扩散模型生成法线图和深度图的PBR图像，以代替仅生成可控光照烘焙的RGB纹理。MGM还探索了一种高斯材料表示方法，不仅与2D高斯散点图一致，还能表示PBR材料的每个通道，从而通过重建点云获取PBR属性，实现动态重新光照。", "conclusion": "大量实验表明，本方法生成的材料不仅在视觉上更具吸引力，还能增强材料建模，从而适合实际的下游渲染应用。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22228", "html_url": "https://arxiv.org/abs/2509.22228", "title": "UrbanFeel: 城市场景的综合基准，以人类视角进行时间和感知理解", "title_en": "UrbanFeel: A Comprehensive Benchmark for Temporal and Perceptual Understanding of City Scenes through Human Perspective", "authors": "Jun He,Yi Lin,Zilong Huang,Jiacong Yin,Junyan Ye,Yuchuan Zhou,Weijia Li,Xiang Zhang", "background": "城市开发的影响覆盖了全球一半以上的人口，因此对城市结构和知觉变化的人性化理解对于可持续发展至关重要。现有的多模态大规模语言模型（MLLMs）在多个领域展现了出色的能力，但是在城市环境中的表现评价仍然有限，缺乏系统地探索时间和主观感受方面的研究。这些短板不利于全面评估MLLMs在城市感知中的能力。", "innovation": "本文提出了UrbanFeel，一个全面基准，旨在评估MLLMs在城市开发理解及主观环境感知中的表现。UrbanFeel包含14300个精心构造的视觉问题，涵盖了三个认知进展维度：静态场景感知、时间变化理解与主观环境感知。通过一系列多阶段过程收集全球11个代表城市的多时相单视图和全景街景图像，并生成高质量的问题-答案对。通过广泛评估20种最先进的MLLMs，首次发现Gemini-2.5 Pro表现最佳，其准确度接近专家水平，与人类的平均差距仅为1.5%。大多数模型在场景理解任务中的表现良好，有的模型甚至在像素级变化检测方面超过了人类注释者。但随着时间推理任务的增加，性能显著下降。此外，在主观感知方面，一些模型达到了与人类相媲美的甚至更高的评价一致性。", "conclusion": "研究表明，尽管当前大多数MLLMs在场景理解任务中表现出色，但在需要时间推理和主观感知的任务中表现较弱。Gemini-2.5 Pro是最优秀的选择，但仍存在提升空间，尤其是在考虑时间和主观感知理解方面。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22070", "html_url": "https://arxiv.org/abs/2509.22070", "title": "SpecXNet：一种用于稳健深度伪造检测的双域卷积网络", "title_en": "SpecXNet: A Dual-Domain Convolutional Network for Robust Deepfake Detection", "authors": "Inzamamul Alam,Md Tanvir Islam,Simon S. Woo", "background": "由于由生成对抗网络（GANs）和扩散模型生成的内容变得越来越真实，深度伪造（deepfake）检测变得更为困难。现有方法通常仅专注于空间或频域特征，限制了它们在未见过的篡改上的泛化能力。", "innovation": "提出了Spectral Cross-Attentional Network（SpecXNet），一种双域架构的鲁棒深度伪造检测模型。SpecXNet 的核心模块是 Dual-Domain Feature Coupler（DDFC），它可以将特征分解成一个局部空间分支来捕捉纹理级别的异常以及一个全球频谱分支，使用快速傅里叶变换来建模周期不一致性。此外，还引入了 Dual Fourier Attention（DFA）模块，可以动态地在内容感知的方式下融合空间和频谱特征。SpecXNet 在多个深度伪造基准测试中取得了最先进的准确率，特别是在跨数据集和未见过的篡改场景下表现尤为突出。", "conclusion": "结果表明，联合空间-频谱学习对于稳健和可泛化的深度伪造检测是有效的，SpecXNet 实现了实时可行性。为了确保可重现性，已将全部代码发布在 GitHub 上。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22139", "html_url": "https://arxiv.org/abs/2509.22139", "title": "Refine-Control: 半监督蒸馏方法以改进条件图像生成", "title_en": "REFINE-CONTROL: A Semi-supervised Distillation Method For Conditional Image Generation", "authors": "Yicheng Jiang,Jin Yuan,Hua Yuan,Yao Zhang,Yong Rui", "background": "现有的基于文本控制的条件图像生成模型虽然表现出色，但这些模型高度依赖资源，并且高质量标注的数据稀缺，这阻碍了它们在边缘设备上的部署。这种部署导致高昂的成本和隐私问题，特别是在用户数据被发送到第三方时。因此，为了解决这些问题，论文提出了一种名为Refine-Control的半监督蒸馏框架。", "innovation": "该框架通过引入三级知识融合损失，将不同层次的知识转让给学生模型，从而提高了学生模型的性能。为了增强泛化能力和解决数据稀缺问题，提出了利用标记数据和未标记数据的半监督蒸馏方法。实验结果表明，Refine-Control框架在保持高质量生成能力和可控性的同时，显著降低了计算成本和延迟时间。", "conclusion": "相对于竞争对手，Refine-Control在计算成本和延迟时间上表现出显著的减少，同时维持了高性能和强可控性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22244", "html_url": "https://arxiv.org/abs/2509.22244", "title": "FlashEdit：分离速度、结构和语义以实现精确的图像编辑", "title_en": "FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing", "authors": "Junyi Wu,Zhiteng Li,Haotong Qin,Xiaohong Liu,Linghe Kong,Yulun Zhang,Xiaokang Yang", "background": "基于文本的图像编辑使用扩散模型已经取得了显著的质量，但在实际应用中受到延迟过高的限制。", "innovation": "FlashEdit框架通过三种创新解决这一问题：(1) 一种一步式反转与编辑(One-Step Inversion-and-Editing, OSIE)管道，避免了昂贵的迭代过程；(2) 一种背景保护技术(BG-Shield)，仅在编辑区域内有选择地修改特征以保证背景保持一致性；(3) 一种稀疏空间交叉注意机制(Sparsified Spatial Cross-Attention, SSCA)，确保精确定位的、局部的修改以防止对背景的语义泄漏。", "conclusion": "广泛的实验表明，FlashEdit能够保持出色的背景一致性与结构完整性，在不到0.2秒的时间内完成编辑，相比之前的多步骤方法提高了超过150倍的效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22276", "html_url": "https://arxiv.org/abs/2509.22276", "title": "GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition", "title_en": "GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition", "authors": "Dinh Minh Nguyen,Malte Avenhaus,Thomas Lindemeier", "background": "以往的工作分别处理网格重建和材质分解任务，难以重建高反射表面，通常依赖于外部模型的先验信息来增强分解结果。尽管现代作品能够以统一的方式解决这些问题，但它们往往使用复杂的神经网络组件来学习场景特性，这限制了它们的大规模性能。", "innovation": "提出了基于3D高斯点云的一个统一解决方案GS-2M，通过联合优化与渲染深度和法线质量相关的属性，同时保持几何细节，提高对反射表面的鲁棒性。还提出了一种基于多视图光度变数的粗糙度监督策略，结合精心设计的损失函数和优化过程，生成与一流方法相当的重建结果。", "conclusion": "验证了通过广泛使用的先前工作中的数据集和与最新的表面重建方法的定性对比，本方法的有效性。通过统一框架生产的重建结果与一流的重建方法相当，提供了三角网格及其相关材质组件，用于下游任务。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22225", "html_url": "https://arxiv.org/abs/2509.22225", "title": "基于匹配掩码提升的多义语言高斯点云生成", "title_en": "Polysemous Language Gaussian Splatting via Matching-based Mask Lifting", "authors": "Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li", "background": "将2D开放式词汇理解提升到3D高斯点云（3DGS）场景是一个关键挑战。现有方法存在三大缺陷：（i）依赖于每个场景的重新训练导致无法即插即用；（ii）仅能表达单一概念的局限性无法描述复杂的多概念语义；（iii）跨视图语义不一致导致最终语义表示受损。", "innovation": "我们提出了MUSplat，这是一种无需训练的框架，完全放弃了特征优化。利用预训练的2D分割模型，我们的管线生成并提升多粒度的2D掩码到3D场景，为每个高斯点估计前景概率形成初始物体群组，然后使用语义熵和几何透明度优化这些初始群组的模糊边界。之后，通过视觉模型跨最具代表性的视角解释物体外观，VLM提取并融合视觉差异，实现开放词汇的语义查询。通过消除每场景的训练费用，MUSplat将场景适应时间从数小时缩短到几分钟。在开放词汇3D物体选择和语义分割基准任务中，MUSplat超越了现有的基于训练框架，同时解决了其单一概念的局限性。", "conclusion": "MUSplat通过利用预训练的2D分割模型和无需训练的流程，成功地解决了现有方法中的三大问题，并在开放词汇3D理解和语义分割任务上的表现优于传统方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22169", "html_url": "https://arxiv.org/abs/2509.22169", "title": "DragGANSpace: GAN的隐空间探索与控制", "title_en": "DragGANSpace: Latent Space Exploration and Control for GANs", "authors": "Kirsten Odendaal,Neela Kaushik,Spencer Halverson", "background": "该研究整合了StyleGAN、DragGAN和主成分分析（PCA）来提高生成对抗网络（GAN）生成图像的隐空间效率和可控性。StyleGAN提供了一个结构化的隐空间，DragGAN使图像操纵直观易行，而PCA则减少维度并促进跨模型对齐，以实现更简洁和可解释的隐空间探索。研究者将技术和AFHQ数据集结合，展示了PCA在保持性能的同时提高了优化效率，特别是在较浅的隐空间中，还展示了对两个不同但相似数据域（AFHQ-Dog和AFHQ-Cat）训练的StyleGAN模型生成图像进行对齐和操纵的能力。", "innovation": "研究将PCA引入到DragGAN的隐W+层中，这不仅一致地减少了总的优化时间，还保持了良好的视觉质量并提高了优化图像的结构相似性指数（SSIM），特别是在较浅的隐空间中。此外，该研究还展示了将两个StyleGAN模型生成的图像进行对齐，并通过控制隐空间来直观且可解释地操纵这些图像的能力。", "conclusion": "研究表明，基于PCA的维度减少与DragGAN框架的技术整合可以在保持性能的同时提高优化效率，并能够对生成的图像进行对齐和直观可控的操纵。这为一系列图像合成和编辑应用提供了高效和可解释的隐空间控制的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22221", "html_url": "https://arxiv.org/abs/2509.22221", "title": "基于感知的地理空间链式思维在遥感中的忠实推理：针对视觉语言模型的研究", "title_en": "Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models", "authors": "Jiaqi Liu,Lang Sun,Ronghao Fu,Bo Yang", "background": "视觉语言模型（VLMs）在遥感领域的复杂分析任务中常常表现不佳，通常是由于它们的一体化训练范式跳过了关键的推理步骤，导致不可验证的输出。", "innovation": "本文提出了一种名为感知导向的地理空间链式思维（Geo-CoT）的框架，将其引入遥感分析模型中，以实现可验证的多步过程。同时，提出了一种两阶段对齐策略，通过Geo-CoT380k（第一个大规模结构化Geo-CoT理由数据集）进行监督微调（SFT），然后再利用群组奖励策略优化（GRPO）策略，以确保事实正确性。", "conclusion": "提出的模型RSThinker能够输出最终答案以及支持的、可验证的推理过程，该模型在遥感领域多种任务上显著优于现有最先进的模型，为遥感观测提供了结构化的、可验证的推理途径，并在文章发表后公开发布Geo-CoT380k数据集和RSThinker模型。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22307", "html_url": "https://arxiv.org/abs/2509.22307", "title": "Johnson-Lindenstrauss 引导的网络在高效 3D 医学分割中的应用", "title_en": "Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation", "authors": "Jinpeng Lu,Linghan Cai,Yinda Chen,Guo Tang,Songhan Jiang,Haoyuan Shi,Zhiwei Xiong", "background": "轻量化3D医疗图像分割仍受限于“效率/鲁棒性冲突”，特别是在处理复杂的解剖结构和异质模态时更为明显。本文旨在研究如何根据高维3D图像的特点重新设计框架，并探索数据协同作用以克服轻量级方法脆弱的表现。", "innovation": "提出了一种名为VeloxSeg的方法，该方法采用可部署且可扩展的双流CNN-Transformer架构，结合Paired Window Attention (PWA)和Johnson-Lindenstrauss引理引导的卷积（JLC）。此外，通过将模态交互纳入多尺度图像检索过程，VeloxSeg能够高效建模异质模态。最后，通过Gram矩阵实现空间解耦的知识转移(SDKT)注入了自监督网络提取的纹理先验，从而在不增加推理成本的情况下增强了表示能力。", "conclusion": "实验结果表明，VeloxSeg在多模态基准上的Dice改进达到26%，同时GPU吞吐量提高11倍，CPU提高48倍。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22229", "html_url": "https://arxiv.org/abs/2509.22229", "title": "两位专家的故事：协作学习在源信息无源的无监督领域适应中的应用", "title_en": "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation", "authors": "Jiaping Yu,Muli Yang,Jiapeng Ji,Jiexi Yan,Cheng Deng", "background": "SFUDA旨在解决访问不到源数据的情况下，将源训练模型适应到目标领域的现实挑战。现有方法要么仅利用源模型的预测，要么微调大规模的多模态模型，但二者均忽视了目标数据的潜在线索和结构，且存在隐私和成本问题。", "innovation": "提出了Experts Cooperative Learning（EXCL），包含Dual Experts框架和Retrieve-Augmentation-Interaction优化管道。EXCL将源域模型（借助Conv-Adapter增强）和预训练的视觉-语言模型（具有可训练文本提示）置于同等地位，从未标记的目标样本中挖掘共识知识。为了在纯无监督条件下有效训练这些插件模块，引入了Retrieve-Augmentation-Interaction（RAIN）三阶段流程：协作检索伪源样本和复杂目标样本，分别对每个专家进行单独微调，通过共享学习结果强制学习对象一致性.", "conclusion": "在四个基准数据集上的广泛实验表明，我们的方法达到了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22283", "html_url": "https://arxiv.org/abs/2509.22283", "title": "基于规则的强化 Learning for 文档图像分类与视觉语言模型", "title_en": "Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models", "authors": "Michael Jungo,Andreas Fischer", "background": "自从DeepSeek-R1通过简单的验证性奖励展示了其成功之后，基于规则的强化学习日益受到关注。然而，在文档分析领域，强化学习的应用并不普遍，尽管许多下游任务可以从强化学习的新兴特性中获益，尤其是增强的推理能力。我们研究了基于规则的强化学习在文档图像分类中的应用，这是一个在文档分析中最常研究的下游任务之一。", "innovation": "研究发现，基于规则的强化学习在处理未见过的数据分布、未见过的类别和不同模态方面具有更好的泛化能力。这一发现为改善文档图像分类任务提供了新的方法。", "conclusion": "我们通过三个不同的场景——未见过的数据、未见过的类别和不同模态——来验证基于规则的强化学习在文档图像分类中的效果，并且代码已公开。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22281", "html_url": "https://arxiv.org/abs/2509.22281", "title": "MesaTask：通过三维空间推理实现面向任务的桌面场景生成", "title_en": "MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning", "authors": "Jinkun Hao,Naifu Liang,Zhen Luo,Xudong Xu,Weipeng Zhong,Ran Yi,Yichen Jin,Zhaoyang Lyu,Feng Zheng,Lizhuang Ma,Jiangmiao Pang", "background": "机器人的任务执行依赖于具有任务相关性的桌面场景来进行培训，但传统方法依赖于耗时的手动布局设计或随机布局，这在实际场景中存在局限性。本研究针对此挑战，提出了任务导向的桌面场景生成任务，以解决高级任务指令与桌面场景之间的巨大鸿沟。为了支持这一挑战性任务的研究，我们构建了包含约10,700个手动设计布局的合成桌面场景的大规模数据集MesaTask-10K，并提出了一个空间推理链来构建桌面场景。", "innovation": "我们提出了一个基于LLM的空间推理链（Spatial Reasoning Chain），用于分解生成过程，包括物体推理、空间关系推理和场景图构建，以生成物理上合理的桌面场景。此外，我们使用基于DPO算法的MesaTask框架增强了该推理链，以更好地与给定的任务描述对齐。实验结果表明，MesaTask在生成与任务相符且布局现实的桌面场景方面优于基线方法。", "conclusion": "本研究通过构建MesaTask-10K大规模数据集和提出空间推理链及MesaTask框架，显著提高了面向任务的桌面场景生成的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22262", "html_url": "https://arxiv.org/abs/2509.22262", "title": "UniMapGen：基于多模态数据的生成式大规模制图框架", "title_en": "UniMapGen: A Generative Framework for Large-Scale Map Construction from Multi-modal Data", "authors": "Yujian Yuan,Changjie Wu,Xinyuan Chang,Sijin Wang,Hang Zhang,Shiyi Liang,Shuang Zeng,Mu Xu", "background": "大规模地图构建对于自动驾驶和导航系统等关键应用至关重要。传统的大型地图构建方法主要依赖昂贵且效率低的数据收集车辆和耗时的手动标注过程。尽管现有的基于卫星的方法在提高制图效率和覆盖范围方面显示出潜力，但它们存在两个主要局限性：（1）卫星数据固有的缺陷（例如遮挡、过时性）；（2）基于感知的方法的矢量化效率低下，导致不连续且粗糙的道路，需要大量后处理。因此，还存在提高现有方法效率和泛化能力的需求。", "innovation": "本研究提出了一种新颖的生成框架UniMapGen，用于大规模地图构建。其三大创新点包括：（1）将车道线表示为离散序列，并建立迭代策略，比传统的基于感知的方法生成更完整更平滑的地图矢量。 （2）提出了一种灵活架构，支持多模态输入，能够动态选择BEV（ birds-eye view）、PV（perspective view）和文本提示，以克服卫星数据的缺点。 （3）开发了一种状态更新策略，确保构建的大规模地图的全局连续性和一致性。UniMapGen在OpenSatMap数据集上达到了领先性能，还能够推断出被遮挡的道路并预测数据集标注缺失的道路。", "conclusion": "UniMapGen框架在大规模地图构建方面展示出了显著的优势，不仅能够提高效率和覆盖范围，还能处理卫星数据的固有缺陷和观察限制。未来研究将致力于进一步优化其性能，并将其应用于更多实际场景。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22258", "html_url": "https://arxiv.org/abs/2509.22258", "title": "超越分类准确度：Neural-MedBench 及深入推理基准的必要性", "title_en": "Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks", "authors": "Miao Jing,Mengting Jia,Junling Lin,Zhongxia Shen,Lijun Wang,Yuanyuan Peng,Huan Gao,Mingkun Xu,Shangyang Li", "background": "最近的视觉-语言模型（VLMs）在医学基准测试中取得了显著的表现，但在真正的临床推理能力方面仍然存在疑问。现有的数据集主要强调分类准确性，导致模型看似熟练但实际上在高风险诊断推理上仍存在不足。研究者提出了神经-MedBench，这是一种紧凑但推理密集的基准，旨在探究神经学多模态临床推理的极限，涵盖了包括病因诊断、病灶识别和论证生成在内的三大核心任务家族，以确保可靠评估，防止只在分类准确度上高超而缺乏推理能力的假象。", "innovation": "研究者开发了一种结合大语言模型（LLM）评分、临床医生验证和语义相似性指标的混合评分管道。通过系统评估最先进的VLMs，如GPT-4o、Claude-4和MedGemma，观察到这些模型在神经-MedBench上的表现显著下降。错误分析表明，推理失败而非感知错误是模型的主要短板。研究强调了双轴评估框架的必要性：广度为导向的大数据集用于统计推断，深度为导向的紧凑基准如神经-MedBench用于推理精准度。研究者还发布了神经-MedBench作为开放和可扩展的诊断测试平台，以指导基准的扩充，并实现对可信临床AI的严格但成本有效的评估。", "conclusion": "研究结果表明，当前的VLMs在神经-MedBench上的表现远不如常规数据集，并且主要的问题在于推理能力不足。研究者提出一种双轴评估框架，并发布了神经-MedBench基准平台，这对于未来医学领域中可信的AI评估具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22300", "html_url": "https://arxiv.org/abs/2509.22300", "title": "HiGS: 历史导向采样以增强扩散模型的即插即用改进", "title_en": "HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models", "authors": "Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber", "background": "尽管扩散模型在图像生成方面取得了显著进展，但在使用较少的神经函数评估次数（NFEs）或较低的引导尺度时，其输出仍然可能显得不真实且缺乏细节。", "innovation": "提出了一种基于动量的历史导向采样技术（HiGS），通过将近期模型预测整合到每一步推断中，提升了扩散采样的质量和效率。具体而言，HiGS 利用当前预测值与过去预测值加权平均值之间的差异，引导采样过程生成更真实且更具细节和结构的输出。此项方法无需额外计算，并与现有的扩散框架无缝集成，无需额外训练或微调。", "conclusion": "实验表明，HiGS 一致提高不同模型和架构下的图像质量，并在不同的采样预算和引导尺度下表现优异。使用预训练的 SiT 模型时，HiGS 在仅使用 30 次采样步骤的情况下（而不是标准的 250 步），实现了无引导的 ImageNet 生成的新最先进 FID 分数 1.61。因此，HiGS 提供了一种即插即用的增强功能，可以实现更快更真实的图像生成。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22339", "html_url": "https://arxiv.org/abs/2509.22339", "title": "CircuitSense: 一个结合工程设计过程中视觉理解与符号推理的分层电路系统基准", "title_en": "CircuitSense: A Hierarchical Circuit System Benchmark Bridging Visual Comprehension and Symbolic Reasoning in Engineering Design Process", "authors": "Arman Akbari,Jian Gao,Yifei Zou,Mei Yang,Jinru Duan,Dmitrii Torbunov,Yanzhi Wang,Yihui Ren,Xuan Zhang", "background": "工程设计通过从系统规范到组件实现的层次抽象操作，需要在每个级别结合视觉理解和数学推理。虽然多模态大型语言模型在自然图像任务上表现出色，但它们从技术图中提取数学模型的能力尚未被探索。当前评估体系关注于感知和分析，而符号方程从视觉输入中生成这一关键但未充分研究的能力则有所忽略。", "innovation": "作者提出了一个新的基准测试CircuitSense，覆盖从组件级别的电路图到系统级别的框图等多个层次。它首次系统地评估了多模态大型语言模型在工程流程中的三种核心能力：感知、分析和设计。特别关注从视觉输入中自动化生成符号方程的能力，并引入了一种分层合成生成管道。该基准测试揭示了在从视觉解析到符号推理这一关键环节上存在的广泛差距。", "conclusion": "当前最先进的模型在感知任务上表现优秀，但在符号推理和分析推理方面存在不足，尤其是那些更强的符号推理能力的模型在设计任务上的准确性更高。这证明了数学理解对电路合成的重要性，并确立了符号推理作为工程胜任力的关键指标。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22318", "html_url": "https://arxiv.org/abs/2509.22318", "title": "NIFTY: 一种非局部图像流匹配的纹理合成方法", "title_en": "NIFTY: a Non-Local Image Flow Matching for Texture Synthesis", "authors": "Pierrick Chatillon,Julien Rabin,David Tschumperlé", "background": "本文解决基于示例的纹理合成问题。现有方法主要依赖于神经网络训练，这导致了初始化问题和视觉伪影，但是这些方法并不容易调整，且需要大量时间和计算资源。本文提出了一种名为NIFTY的混合框架，结合了基于卷积神经网络的扩散模型训练结果和经典的基于块的纹理优化技术，旨在提供一种非参数的流匹配模型，从而避免神经网络训练的需求，并缓解基于块方法中常见的初始化问题和视觉伪影等问题。实验结果表明，该方法在与文献中最具代表性的方法对比中表现出色。", "innovation": "提出了NIFTY混合框架，结合了基于卷积神经网络的扩散模型训练结果和经典的基于块的纹理优化技术，构建了一种非参数的流匹配模型，无需神经网络训练即可实现纹理合成。这种方法不仅避免了神经网络训练的需求，还缓解了基于块方法中的初始化问题和视觉伪影等问题。实验结果展示了该方法的有效性。", "conclusion": "提出的NIFTY方法在与现有最具代表性的纹理合成方法比较中表现出了优越的性能。通过结合扩散模型和经典块匹配方法，NIFTY提供了一种新的、高效率的纹理合成策略。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22331", "html_url": "https://arxiv.org/abs/2509.22331", "title": "通过层次跨模态超图学习的行人属性识别", "title_en": "Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning", "authors": "Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo", "background": "现有的行人属性识别（PAR）算法通常专注于将视觉特征映射到语义标签，或者通过融合视觉和属性信息来增强学习。然而，这些方法未能充分利用属性知识和上下文信息以实现更准确的识别。尽管近期研究已经开始考虑使用属性文本作为附加输入来增强视觉与语义信息之间的关联，但这些方法仍处于初级阶段。", "innovation": "本文提出了一个多层次跨模态超图的学习方法，用于挖掘局部视觉特征与文本之间的关系，以及属性与丰富视觉上下文样本之间的关系。具体地，本文提出了一种全面考虑属性之间关系及其与视觉标记间关系的有效多重模态知识图构建方法。为了建模这些关系，本文引入了一种知识图引导下的跨模态超图学习框架，增强了标准的行人属性识别框架。", "conclusion": "在多个PAR基准数据集上的全面实验充分证明了我们提出的知识图在这个识别任务上的有效性，为知识引导的行人属性识别奠定了坚实的基础。代码将在此网址发布：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22365", "html_url": "https://arxiv.org/abs/2509.22365", "title": "HierLight-YOLO: 一种用于无人机摄影的分层轻量化目标检测网络", "title_en": "HierLight-YOLO: A Hierarchical and Lightweight Object Detection Network for UAV Photography", "authors": "Defan Chen,Yaohua Hu,Luchan Zhang", "background": "在复杂场景中，如无人机（UAV）摄影捕捉到的照片，实时检测小型目标（<32像素）具有双重挑战，即检测小型目标并同时保持资源受限平台上的实时效率。YOLO系列检测器在实时大型目标检测方面取得了显着成功，但在基于无人机的场景中，小型目标占据主导地位，其误检率显著高于大型目标的情景。需要一种能够提高小型目标检测准确性的分层轻量化模型来应对这些挑战。", "innovation": "本文提出了一种名为HierLight-YOLO的分层特征融合和轻量化模型，基于YOLOv8架构，通过引入Hierarchical Extended Path Aggregation Network (HEPAN)多层次交叉级连接的多尺度特征融合方法，提高了小型目标的检测准确率。此外，该模型还包括两个创新的轻量化模块：Inverted Residual Depthwise Convolution Block (IRDCB) 和 Lightweight Downsample (LDown)模块，这些模块大大降低了模型参数和计算复杂性，同时保持了检测能力。此外，还设计了小型目标检测头部，以进一步提高空间分辨率和特征融合，以应对小至4像素的物体检测。在VisDrone2019基准测试上的对比实验和消融研究表明HierLight-YOLO具有最先进的性能。", "conclusion": "该研究通过引入Hierarchical Extended Path Aggregation Network (HEPAN)，Inverted Residual Depthwise Convolution Block (IRDCB) 和 Lightweight Downsample (LDown)模块，提出了一种用于无人机摄影的小型物体检测的轻量化和分层模型HierLight-YOLO，该模型在复杂场景的实时检测任务中表现出优越的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22292", "html_url": "https://arxiv.org/abs/2509.22292", "title": "基于场景分割策略的文本到视频模型破解", "title_en": "Jailbreaking on Text-to-Video Models via Scene Splitting Strategy", "authors": "Wonjun Lee,Haon Park,Doehyeon Lee,Bumsub Ham,Suhyun Kim", "background": "随着许多文本到视频（T2V）模型的快速发展，它们的安全风险引起了广泛关注。尽管最近的研究已经通过开启攻击（jailbreak attacks）探索了LLMs、VLMs和文本到图像（T2I）模型中的漏洞，但T2V模型仍几乎没有被研究，留下了一个重要的安全缺口。为了填补这一缺口，该研究引入了一种名为SceneSplit的新颖黑盒破解方法，该方法通过将有害叙述分解成多个场景实现，每个场景单独来看是良性的。这种方法通过使用场景的组合来操纵生成输出空间，即给定提示的所有潜在视频输出的抽象集合，通过这些场景作为强大的约束来引导最终结果。每个场景单独来看对应一个广泛的良性空间，大多数结果都是良性的，但它们的顺序组合限制了这个空间，使其变得更加有害。这一核心机制通过迭代场景操作得到进一步增强，可以绕过受限的不安全区域内安全过滤器。此外，通过使用策略库中重用成功的攻击模式，攻击的整体效果和稳健性进一步提升。为了验证方法的有效性，在11个安全类别上对T2V模型进行了评估。结果表明，该方法在Luma Ray2、Hailuo和Veo2上分别达到了77.2%、84.1%和78.2%的高平均攻击成功率，远优于现有基线。这项工作表明，当前的T2V安全机制容易受到利用叙述结构的攻击的利用，为理解和改善T2V模型的安全性提供了新的见解。", "innovation": "提出了名为SceneSplit的新颖黑盒破解方法，通过将有害叙述分解成多个单独良性场景，并使用这些场景作为强有力的约束来操纵生成输出空间。此外，通过迭代场景操作和使用策略库增强攻击效果和稳健性。该方法在多个T2V模型上表现出色，攻击成功率显著高于现有基线。", "conclusion": "当前的T2V安全机制容易受到利用叙述结构的攻击的利用，给T2V模型的安全性带来了挑战。展示了SceneSplit方法的有效性和在实际应用中的潜力，提出了新的攻击角度和策略改进的思考方向。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22392", "html_url": "https://arxiv.org/abs/2509.22392", "title": "基于梯度的多焦距图像融合结合关注区域增强", "title_en": "Gradient-based multi-focus image fusion with focus-aware saliency enhancement", "authors": "Haoyu Li,XiaoSong Li", "background": "多焦距图像融合（MFIF）旨在从多个部分焦距的输入中生成一个全焦距的图像，这对于监视、显微镜和计算摄影等领域具有重要意义。然而，现有的方法在保留焦距变化边界方面存在困难，经常导致模糊过渡和聚焦细节丢失。", "innovation": "本文提出了一种基于显著边界增强的多焦距图像融合方法，该方法可以生成高质量的融合边界，同时有效地检测焦距信息。特别是，提出了一种基于梯度域的模型，可以从源图像中获取完整的初步融合结果并有效保留边界细节。此外，引入了Tenengrad梯度检测方法，可以从源图像和初步融合图像中提取显著特征，生成相应的显著性图。为了进一步精简边界，提出了一种基于梯度和互补信息的焦距度量，将显著特征与图像间的互补信息整合，以强调聚焦区域并产生高质量的初步决策结果。", "conclusion": "在四个公开数据集上的大量实验表明，本文方法在主观和客观评估中始终优于现有的12种最先进的方法。我们已实现该代码 [见原文链接]。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22323", "html_url": "https://arxiv.org/abs/2509.22323", "title": "RAPID^3: 用于扩散变换器的三层次强化加速策略", "title_en": "RAPID^3: Tri-Level Reinforced Acceleration Policies for Diffusion Transformer", "authors": "Wangbo Zhao,Yizeng Han,Zhiwei Tang,Jiasheng Tang,Pengfei Zhou,Kai Wang,Bohan Zhuang,Zhangyang Wang,Fan Wang,Yang You", "background": "扩散变换器（DiT）在视觉生成方面表现出色，但由于采样速度慢而受限。现有的无需训练的加速器，如步数减少、特征缓存和稀疏注意力，可提高推理速度，但通常依赖于统一的启发式方法或手动设计的自适应策略，这往往牺牲了生成的质量。动态神经网络则提供根据单个图像自适应加速的方法，但其高微调成本限制了其更广泛的适用性。文章面临的问题在于现有的加速策略要么存在质量损失，要么成本高昂，难以在更广泛的应用中推广。因此，亟需一种能实现单图像加速且无需更新基生成器的新型方法。为了应对这些挑战，作者提出了一种名为 RAPID3 的框架。", "innovation": "提出了一种框架 RAPID3，旨在实现图像级别的加速，同时不需要对基生成器进行任何更新。该框架包含三个轻量级的策略头部：Step-Skip（跳跃步骤）、Cache-Reuse（重用缓存）和 Sparse-Attention（稀疏注意），它们能够根据当前去噪状态独立地决定各自的加速策略。所有策略参数是通过组相关策略优化（GRPO）在线训练的，同时生成器保持冻结状态。此外，对抗性学习的鉴别器增强了奖励信号，防止奖励劫持现象只在生成的样本接近原始模型分布时提升回报。这种策略显著提高了扩散变换器的采样速度，同时保持了生成的质量。该方法在多个先进的 Diffusion Transformer 模型上进行了验证。", "conclusion": "RAPID3 在多个最先进的 DiT 模型（包括 Stable Diffusion 3 和 FLUX）上实现了近 3 倍的采样速度提升，同时保持了竞争力的生成质量。这种方法解决了传统加速器和动态神经网络的局限性，实现了图像级别的自适应加速，展示了在无需更新基生成器的情况下高效加速扩散变换器采样的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22399", "html_url": "https://arxiv.org/abs/2509.22399", "title": "利用逻辑张量网络在医学语义分割中集成背景知识", "title_en": "Integrating Background Knowledge in Medical Semantic Segmentation with Logic Tensor Networks", "authors": "Luca Bergamin,Giovanna Maria Dimitri,Fabio Aiolli", "background": "语义分割是医学图像分析中的基本任务，通过帮助放射学家识别图像中的对象来辅助医疗决策。这一领域研究主要是由深度学习的应用驱动的，具备在噪声和伪影存在的情况下扩展这些系统的潜力。然而，这些系统仍需进一步完善。", "innovation": "我们通过将常见的医学知识整合到分割模型的损失函数中来改进性能。为此，我们引入了一种方法，使用一阶逻辑（FOL）规则编码医学背景知识，利用逻辑张量网络（LTNs）将规则编码，这些规则涵盖了从分割产出的形状约束到不同分割区域之间的关系。我们在一种端到端框架中使用SwinUNETR进行了语义分割。", "conclusion": "我们的实验证明，即使在训练数据稀缺的情况下，利用LTNs的方法可以提高基线分割性能。尽管该方法仍在初步阶段，但我们认为神经符号方法足够通用，可以适应和应用于其他医学语义分割任务。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22383", "html_url": "https://arxiv.org/abs/2509.22383", "title": "GPT-4 for Occlusion Order Recovery", "title_en": "GPT-4 for Occlusion Order Recovery", "authors": "Kaziwa Saleh,Zhyar Rzgar K Rostam,Sándor Szénási,Zoltán Vámossy", "background": "当前的视觉模型在处理复杂和密集的现实世界图像和场景时，仍然面临遮挡问题的挑战，这对于准确预测对象之间的遮挡顺序关系至关重要。现有的方法往往依赖于标注数据训练模型，但这些方法在处理未见过的遮挡顺序时表现不佳，无法进行零样本推理。", "innovation": "本文提出利用预训练的GPT-4模型的高级功能来推断遮挡顺序。通过提供专门设计的提示和输入图像，GPT-4可以分析图像并生成遮挡顺序预测。该响应可以解析以构建一个遮挡矩阵，用于辅助其他遮挡处理任务和图像理解。与基线方法不同，该模型可以在零样本条件下推理遮挡关系，无需标注训练数据，并且可以轻松集成到遮挡处理框架中。研究表明，通过利用语义上下文、视觉模式和常识知识，模型能够生成更准确的顺序预测结果。", "conclusion": "本文评估了模型在COCOA和InstaOrder数据集上的表现，结果显示使用GPT-4模型能够通过语义上下文、视觉模式和常识知识生成更准确的遮挡顺序预测。该模型能够通过零样本推理处理遮挡关系，且无需标注训练数据，适用于遮挡处理框架的集成。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22377", "html_url": "https://arxiv.org/abs/2509.22377", "title": "大型多模态模型在检测虚假信息中的有效性：实验结果", "title_en": "Effectiveness of Large Multimodal Models in Detecting Disinformation: Experimental Results", "authors": "Yasmina Kheddache,Marc Lalonde", "background": "虚假信息的传播，特别是在结合文本和图像的多模态环境中，给数字平台带来了重大挑战。本文研究了大型多模态模型（LMMs）在检测和减轻虚假信息方面的潜力。GPT-4o模型因其先进能力被视为潜在的工具，用于多模态虚假信息检测。", "innovation": "文章创新点包括：（1）开发了一种优化提示，结合了高级提示工程技术以确保精确和一致的评估；（2）实现了一种结构化的多模态分析框架，包括图像和文本预处理方法以符合模型的标记限制；（3）定义了六种特定的评估标准，可以对内容进行精细分类，并结合一个基于信心水平的自我评估机制；（4）对模型在多个异质数据集Gossipcop、Politifact、Fakeddit、MMFakeBench和AMMEBA上的综合性能进行了分析，突显了GPT-4o检测虚假信息的强项和局限性；（5）通过重复测试调查预测变异以评估模型分类的稳定性和可靠性；（6）提出了基于信心水平和变异性的评估方法。这些贡献为自动多模态虚假信息分析提供了一种稳健且可重复的方法论框架。", "conclusion": "研究表明，大型多模态模型如GPT-4o在多模态虚假信息检测中具有潜在的强项，同时也指出了其局限性。通过使用优化的提示、结构化的分析框架和详细的评估机制，本文提供了一种用于多模态虚假信息检测的稳健方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22393", "html_url": "https://arxiv.org/abs/2509.22393", "title": "动态输出的文本对抗攻击", "title_en": "Text Adversarial Attacks with Dynamic Outputs", "authors": "Wenqiang Wang,Siyuan Liang,Xiao Yan,Xiaochun Cao", "background": "现有的文本对抗攻击方法主要针对静态场景，具有固定的输出标签数量和预定义的标签空间，依赖于对受害模型或代理模型的大量查询（查询型攻击）或转移到代理模型（转移型攻击）。然而，这些方法不能应对动态输出场景。本文分析了传统的基于查询和转移的文本对抗攻击方法存在的局限性，特别是在处理动态输出的情况下如何不足，从而引出了TDOA方法的必要性与创新点。", "innovation": "TDOA方法采用了基于聚类的代理模型训练方法，将动态输出场景转换为静态单输出场景。为了提高攻击效果，提出了最远标签攻击策略，该策略选择与模型粗粒度标签偏差最大的对抗向量，从而最大限度地造成混乱。实验结果表明，TDOA方法不仅在传统的静态输出场景中表现优异，攻击成功率最高达到82.68%，还在生成式设置中扩展了TDOA框架，与之前的最佳结果相比，取得了0.64 RDBLEU和0.62 RDchrF的提升。", "conclusion": "TDOA方法能够利用有限的查询次数（每次查询一个文本），在LNN模型中实现高达50.81%的攻击成功率。它不仅在动态输出场景下有效，还在静态输出场景中表现出色，展示了其在大语言模型妥协方面的强大潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22444", "html_url": "https://arxiv.org/abs/2509.22444", "title": "U-MAN: U-Net with Multi-scale Adaptive KAN Network for Medical Image Segmentation", "title_en": "U-MAN: U-Net with Multi-scale Adaptive KAN Network for Medical Image Segmentation", "authors": "Bohan Huang,Qianyun Bao,Haoyuan Ma", "background": "医疗图像分割面临着在保留精细结构和精确边界方面的重要挑战，尤其是由于复杂的解剖结构和病理区域。这些问题主要来自于传统U-Net架构的两个局限性：首先，它们简单的跳接连接忽略了不同特征之间的编码-解码语义差距，其次，它们缺乏在深层进行多尺度特征提取的能力。", "innovation": "本文提出了一种新的U-Net架构，即U-Net with Multi-scale Adaptive KAN (U-MAN)，通过引入两个特殊模块：逐级注意力引导特征融合 (PAGF) 和多尺度自适应KAN (MAN)。PAGF模块用注意力机制取代了简单的跳接连接，能够从编码器和解码器中融合特征。MAN模块使网络能够自适应地处理不同尺度的特征，增强了其分割不同大小物体的能力。实验证明U-MAN在三个公开数据集（BUSI、GLAS和CVC）上都优于现有方法，特别是在定义准确边界和保留细节点方面。", "conclusion": "实验结果表明，U-MAN在保持细节点和准确边界方面表现出色，超越了现有的最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22476", "html_url": "https://arxiv.org/abs/2509.22476", "title": "Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation", "title_en": "Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation", "authors": "Chen Li,Meilong Xu,Xiaoling Hu,Weimin Lyu,Chao Chen", "background": "训练具有不同医学影像模态鲁棒性的学习算法具有挑战性，因为存在较大的领域差距。无监督领域适应（UDA）通过使用源领域已标注图像和目标领域未标注图像来训练深度模型，以缓解这一问题。现有方法通常依赖于基于GAN的风格转换，但这些方法在高变异性区域难以捕捉跨领域的映射。", "innovation": "本文提出了一种统一框架——Bézier Meets Diffusion——用于跨域图像生成。首先，提出了一种基于Bézier曲线的风格迁移策略，有效缩小了源域和目标域之间的领域差距。通过此模型在目标域生成的伪标签进一步训练了条件扩散模型（CDM），以生成高质量、已标注的目标域图像。为了减轻噪声伪标签的影响，还开发了一种基于不确定性引导的分数匹配方法，提高了CDM训练的鲁棒性。", "conclusion": "在公共数据集上进行的广泛实验表明，该方法生成了真实且高质量的已标注图像，显著增强了目标域并提高了分割性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22404", "html_url": "https://arxiv.org/abs/2509.22404", "title": "RAU: 基于参考的视觉语言模型的解剖理解", "title_en": "RAU: Reference-based Anatomical Understanding with Vision Language Models", "authors": "Yiwei Li,Yikang Liu,Jiaqi Guo,Lin Zhao,Zheyuan Zhang,Xiao Chen,Boris Mailhe,Ankush Mukherjee,Terrence Chen,Shanhui Sun", "background": "对于自动报告生成、术中导航和医学影像中的器官定位而言，通过深度学习理解解剖学至关重要。然而，其进展受限于专家标注数据的稀少。最近的视觉语言模型虽然展示了非平凡的视觉推理能力，但在基于参考的理解和细粒度定位方面仍有限制。", "innovation": "提出了RAU框架，用于利用视觉语言模型进行基于参考的解剖理解。研究显示，模型能够通过参考和目标图像之间的相对空间推理来识别解剖区域，并通过视觉问答和边界框预测进行了验证。RAU能够将SAM2细粒度分割能力与来自视觉语言模型的空间提示无缝集成，从而实现医学图像中小解剖区域的定位和像素级分割。在两种分布内和两种分布外数据集上，RAU均表现出比SAM2微调基线更好的性能，且其强大的泛化能力使其适用于分布外数据集，这是医学影像应用的关键属性。", "conclusion": "据我们所知，这是首次探索视觉语言模型在医学影像中基于参考的识别、定位和分割解剖结构的能力。RAU的出色性能突显了基于视觉语言模型的方法在自动化临床工作流程中的潜在应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22400", "html_url": "https://arxiv.org/abs/2509.22400", "title": "缩小安全差距：视觉自回归模型中的手术概念擦除", "title_en": "Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models", "authors": "Xinhao Zhong,Yimin Zhou,Zhiqi Zhang,Junhao Li,Yi Sun,Bin Chen,Shu-Tao Xia,Ke Xu", "background": "视觉自回归（VAR）模型的快速发展为文本到图像生成带来了新的机会，但同时也引发了安全方面的担忧。现有的概念擦除技术主要针对扩散模型设计，不能很好地应用于VAR，因为VAR采用了未来的尺度标记预测方式。已有方法在基于预训练模型微调时，难以精确识别并最少调整不安全的视觉标记，从而带来语言漂移和降低多样性的问题。", "innovation": "本文首先提出了一种新的VAR擦除框架VARE，通过利用辅助视觉标记来减少微调强度实现概念的稳定擦除。紧接着，引入了S-VARE方法，这是一种专为VAR设计的新颖且有效的方法，结合了过滤交叉熵损失来精确识别并最小调整不安全的视觉标记，以及保持语义准确性的保留损失，解决了间歇性微调导致的语言漂移和多样性降低的问题。", "conclusion": "广泛实验表明，该方法在实现概念的精确诊除的同时保持了生成质量，从而在早期方法的基础上解决了文本到图像生成中的安全性差距问题。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22412", "html_url": "https://arxiv.org/abs/2509.22412", "title": "FreqDebias: 通过一致性驱动的频率去偏纠偏实现泛化有效的假脸检测", "title_en": "FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing", "authors": "Hossein Kashiani,Niloufar Alipour Talemi,Fatemeh Afghah", "background": "现有的深伪检测器在处理新型伪造类型时常常表现出泛化性能不足，这是因为它们的学习偏差来自有限的训练数据。本文发现了一种在频域的新类型模型偏差，称为谱偏，检测器过度依赖特定的频率带，限制了它们在未见过的伪造类型上的泛化能力。", "innovation": "本文提出了FreqDebias，一种通过两种互补策略化解偏的频域去偏框架：首先，提出了一种新颖的伪造Mixup（Fo-Mixup）增强，动态地增加了训练样本的频域特性多样性；其次，引入了一种双重一致性正则化（CR），其通过对局部一致性使用类别激活图（CAMs）并通过对超球面嵌入空间上的von Mises-Fisher（vMF）分布实现全局一致性，从而在局部和全局监督下促进一致的表征学习，减轻对某些频域组分的过度依赖。", "conclusion": "实验表明，FreqDebias显著提高了跨域泛化能力，在跨域和在域设置中均优于最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22414", "html_url": "https://arxiv.org/abs/2509.22414", "title": "LucidFlux: 无需提示词的大规模扩散变换器通用图像恢复", "title_en": "LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer", "authors": "Song Fei,Tian Ye,Lujia Wang,Lei Zhu", "background": "通用图像恢复（UIR）旨在恢复被未知混合物破坏的图像，同时保留语义。传统的方法在处理图像恢复时往往会出现过度平滑、虚构或偏移的问题。本文探讨了在未知混合物破坏的图像恢复中的挑战，并指出判别恢复者和基于UNet的扩散先验往往会在处理这些图像时出现问题。", "innovation": "本文提出了一种无需提示词的UIR框架LucidFlux，该框架利用一个大规模扩散变换器（Flux.1）来处理图像恢复。LucidFlux引入了一个轻量级的双支路处理器，可以从受损输入和轻微恢复的代理中注入信号，分别锚定几何结构和抑制伪影。此外，它设计了一种适应时间步和层的调节计划，将这些线索路由到主体的层次结构中，以实现从粗到细、上下文感知的更新，从而保护整体结构并恢复纹理。同时，通过使用从代理中提取的SigLIP特征来强制执行无提示词的语义对齐，避免了文本提示或MLLM提示的延迟和不稳定。此外，一个可扩展的策展管道进一步筛选了大量数据，以提供结构丰富的监督。实验表明，LucidFlux在合成和野外的基准测试中都超过了强大的开源和商业基准，且消融研究验证了每个组件的必要性。", "conclusion": "LucidFlux证明了，对于大型DiTs，何时、何地以及如何条件化——而不是增加参数或依赖于文本提示——是通用图像恢复中确保鲁棒性和无提示词的关键杠杆。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22450", "html_url": "https://arxiv.org/abs/2509.22450", "title": "SSVIF: 自监督分割导向的可见光和红外图像融合", "title_en": "SSVIF: Self-Supervised Segmentation-Oriented Visible and Infrared Image Fusion", "authors": "Zixian Zhao,Xingchen Zhang", "background": "近年来，可见光和红外图像融合（VIF）得到了广泛关注，特别是在场景分割和目标检测等任务中应用广泛。传统VIF方法主要关注融合图像的质量提升，而面向应用的VIF方法则在训练过程中引入特定任务下的损失项，以提升下游任务的效果。然而，这类方法需要大量人工标注的数据，导致数据获取成本高且耗时。为解决这一问题，本文提出了分割导向的自监督训练框架（SSVIF）。该框架利用基于特征级融合和像素级融合的分割一致性，引入了一种新的自监督任务间分割一致性，以在无需分割标签监督的情况下学习高层语义特征。同时，本文还设计了一种两阶段训练策略和动态权重调整方法，以有效实现自监督框架下的联合学习。", "innovation": "本文的主要创新点在于提出了一种自监督的分割导向的可见光和红外图像融合方法（SSVIF）。该方法基于特征级和像素级分割一致性的自监督学习机制，无需下游任务的标注数据，能够学习到高层语义特征。此外，通过两阶段训练策略和动态权重调整方法，实现了有效的联合学习。实验结果表明，SSVIF在未经标记的可见光和红外图像对上训练即可达到优于传统方法和可与监督学习方法匹敌的效果。", "conclusion": "本文提出的SSVIF方法，利用自监督学习实现分割导向的可见光和红外图像融合，无需大量的标注数据，显著降低了数据获取成本。实验结果验证了该方法的有效性，在多项公有数据集上优于传统方法，并可与监督学习方法竞争。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22415", "html_url": "https://arxiv.org/abs/2509.22415", "title": "通过 intra-modal 令牌交互解释多模态大语言模型", "title_en": "Explaining multimodal LLMs via intra-modal token interactions", "authors": "Jiawei Liang,Ruoyu Chen,Xianghao Jiao,Siyuan Liang,Shiming Liu,Qunli Zhang,Zheng Hu,Xiaochun Cao", "background": "多模态大型语言模型（MLLMs）已在多种视觉语言任务中取得了显著成功，但其内部决策机制尚未充分理解。现有解释性研究主要集中在跨模态归因上，识别模型在输出生成过程中关注的图像区域。然而，这些方法往往忽视了同模态之间的依赖关系。在视觉模态中，将重要性归因于孤立的图像区域忽略了由于有限的感受野而导致的空间上下文。在文本模态中，依赖于前一令牌会产生虚假激活。未能有效减轻这些干扰影响了归因的准确性。", "innovation": "本文提出通过利用同模态交互来增强解释性。对于视觉分支，作者引入了“多尺度解释聚合”（MSEA），该方法通过聚合多尺度输入来调整感受野，从而产生更全面且空间上连贯的视觉解释。对于文本分支，作者提出“激活排名相关性”（ARC），该方法通过对其前k个预测排名的对齐来衡量上下文令牌与当前令牌的相关性，从而抑制无关上下文的虚假激活，同时保留语义上一致的激活。广泛实验表明，该方法在最先进的MLLM和基准数据集上均优于现有解释性方法，提供了更为忠实且精细的模型行为解释。", "conclusion": "本文方法在多个最先进的多模态大语言模型和基准数据集上均表现出色，通过利用同模态令牌交互，提供了更全面和精细的模型解释，有效克服了现有方法对于同模态内依赖关系解释不足的问题。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22448", "html_url": "https://arxiv.org/abs/2509.22448", "title": "$β$-Quant:Towards Learnable Quantization for Low-bit Pattern Recognition", "title_en": "$γ$-Quant: Towards Learnable Quantization for Low-bit Pattern Recognition", "authors": "Mishal Fatima,Shashank Agnihotri,Marius Bock,Kanchana Vaishnavi Gandikota,Kristof Van Laerhoven,Michael Moeller,Margret Keuper", "background": "大多数模式识别模型都是在预处理数据的基础上开发的。在计算机视觉中，经过图像信号处理（ISP）管道预处理的RGB图像是最常见的输入，这些管道设计来满足人类感知。然而，许多现代视觉任务并不需要人在环中操作，这引发了是否继续使用这种预处理方法以实现自动化分析是否仍是最优解的问题。此外，人体活动识别（HAR）通常使用高比特ADC转换后的归一化浮点数据作为输入，但由于数据传输效率低下，大大影响了可穿戴设备的电池寿命。本文关注传感器仅能获得低比特深度采集数据的低带宽和能量受限环境，探索在模式识别中实现自适应量化的方法，以减少数据传输消耗并提高能效。", "innovation": "本文提出了一种$\tau$-Quant方法，即针对特定任务的非线性量化学习，用于低比特模式识别。方法在原生图像目标检测和可穿戴数据的人体活动识别中进行了验证，结果表明使用可学习量化后的4比特数据可以与使用原始12比特数据达到同等的识别性能。这一突破展示了如何通过自适应量化显著减少数据量和能耗，从而推动低比特率下的高效模式识别技术发展。", "conclusion": "本工作展示了在低带宽和低能耗约束条件下，通过自适应非线性量化从原始低比特数据中进行模式识别的有效性，并通过公开源代码验证了该方法的可行性和优越性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22481", "html_url": "https://arxiv.org/abs/2509.22481", "title": "PSTTS: 一种高效事件时空表征学习的即插即用Token选择器", "title_en": "PSTTS: A Plug-and-Play Token Selector for Efficient Event-based Spatio-temporal Representation Learning", "authors": "Xiangmo Zhao,Nan Yang,Yang Wang,Zhanwen Liu", "background": "主流的基于事件的空间-时间表示学习方法通常通过将事件流转换为事件帧序列来处理，取得了显著的效果。但这些方法忽视了事件帧序列中存在的高空间稀疏性和帧间运动冗余性，导致了显着的计算开销。现有的基于RGB视频的Token稀疏化方法依赖于不稳定的中间Token表示，并忽略了事件噪声的影响，因此这些方法直接应用于事件数据时效果不佳。现有研究未能有效解决事件数据特有的时空冗余问题，提高了计算复杂度并可能损害准确性。", "innovation": "提出了一种事件数据的即插即用模块Progressive Spatio-Temporal Token Selection (PSTTS)，在不引入任何额外参数的情况下，利用原始事件数据中的时空分布特性有效识别并丢弃时空冗余Token，实现了效率和准确性的最佳权衡。PSTTS包括两个阶段：空间Token净化和时间Token选择，前者通过评估事件帧内的时空一致性来消除噪音和非事件区域，防止干扰后续的时间冗余评估；后者通过评估相邻事件帧之间的运动模式相似性，精确识别并移除冗余的时间信息。", "conclusion": "PSTTS被应用于四个代表性骨干网UniformerV2、VideoSwin、EVMamba和ExACT，实验结果表明PSTTS实现了显著的效率提升。具体来说，PSTTS在DailyDVS-200数据集上减少了30%-43.6%的FLOPs和21.6%-41.3%的FPS，同时保持了任务准确性。代码将会开源。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22496", "html_url": "https://arxiv.org/abs/2509.22496", "title": "MLLMs的注意力及依赖性：解析自回归token生成", "title_en": "Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation", "authors": "Ruoyu Chen,Xiaoqing Guo,Kangwei Liu,Siyuan Liang,Shiming Liu,Qunli Zhang,Hua Zhang,Xiaochun Cao", "background": "多模态大型语言模型（MLLMs）在视觉输入与自然语言输出的对齐上展现了显著的能力，但生成的token对视觉模态的依赖程度还不清楚，这限制了模型的可解释性和可靠性。", "innovation": "提出了一种名为EAGLE的轻量级黑盒框架，用于解释MLLMs的自回归token生成。EAGLE通过稀疏图像区域的贪婪搜索，量化语言先验和感知证据的相对影响，并引入统一充分性和必要性的目标函数，实现了准确、高效的归因。EAGLE还进行模态感知分析，细化模型决策的可解释性。实验结果显示EAGLE在忠诚度、定位能力、幻觉诊断方面优于现有方法，且需要较少的GPU内存资源，突显其在提高MLLMs可解释性方面的有效性与实用性。", "conclusion": "EAGLE框架为MLLMs的可解释性提供了有效工具，持续优于现有方法，在信仰度、本地化和幻觉诊断方面表现突出，同时消耗更少的GPU内存资源。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22485", "html_url": "https://arxiv.org/abs/2509.22485", "title": "Group Critical-token Policy Optimization for Autoregressive Image Generation", "title_en": "Group Critical-token Policy Optimization for Autoregressive Image Generation", "authors": "Guohui Zhang,Hu Yu,Xiaoxiao Ma,JingHao Zhang,Yaning Pan,Mingde Yao,Jie Xiao,Linjiang Huang,Feng Zhao", "background": "近期研究已经将可验证奖赏的强化学习（RLVR）扩展到了自回归（AR）视觉生成，并取得了显著进展。然而，现有方法通常对所有图像标记进行统一优化，忽视了不同图像标记在RLVR训练中的不同贡献。识别对AR生成更重要的图像标记，并针对这些标记进行有效的标记级优化是一个关键挑战。", "innovation": "本文提出了一种名为GCPO（Group Critical-token Policy Optimization）的方法，旨在针对关键标记进行有效的策略优化。GCPO从三个角度识别RLVR基于的AR生成中的关键标记：因果依赖（早期标记因单向依赖关系基础性地确定了后续标记和最终图像效果）、熵驱动的空间结构（具有高熵梯度的标记对应于图像结构并连接不同的视觉区域）以及RLVR关注的标记多样性（具有较低视觉相似性的标记在一组采样图像中贡献于更丰富的标记级多样性）。此外，GCPO还引入了一种动态标记级别的优势权重，基于策略模型与参考模型之间信心的差异鼓励探索。通过利用图像标记的30%，GCPO比使用所有标记的GRPO在性能上表现更优。多个文本到图像基准测试结果验证了GCPO在AR视觉生成中的有效性。", "conclusion": "广泛的实验表明，GCPO在AR生成中比使用所有标记的方法表现更优，强调了在AR生成中识别和优化关键标记的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22527", "html_url": "https://arxiv.org/abs/2509.22527", "title": "EfficientDepth:一种快速且细节保留的单目深度估计模型", "title_en": "EfficientDepth: A Fast and Detail-Preserving Monocular Depth Estimation Model", "authors": "Andrii Litvynchuk,Ivan Livinsky,Anand Ravi,Nima Kalantari,Andrii Tsarov", "background": "单目深度估计（MDE）在机器人、增强现实和自动驾驶等计算机视觉应用中扮演着关键角色。尽管取得了最近的进步，现有的方法往往在三维重建和视图合成方面达不到几何一致性、细节处理、对现实世界的抗干扰能力以及边缘设备的效率等关键要求。", "innovation": "作者提出了一种名为EfficientDepth的新系统，结合了变压器架构与轻量级卷积解码器，以及双模态密度头，允许网络估计详细的深度图。通过多阶段优化策略改进训练效率，并利用LPIPS损失函数促使网络生成详细的深度图，从而在保持几何一致性和细节的同时提高了模型性能，与现有最先进的模型相比有显著减少的计算资源消耗。", "conclusion": "实验结果表明，EfficientDepth在性能上达到了与现有最先进的模型相当或更高的水平，同时大幅减少了计算资源的需求。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22524", "html_url": "https://arxiv.org/abs/2509.22524", "title": "视知觉语言模型中的颜色名称", "title_en": "Color Names in Vision-Language Models", "authors": "Alexandra Gomez-Villa,Pablo Hernández-Cámara,Muhammad Atif Butt,Valero Laparra,Jesus Malo,Javier Vazquez-Corral", "background": "颜色是人类视觉感知的基本维度，也是传达物体和场景信息的主要方式。随着视知觉模型（VLMs）的日益普及，理解这些模型在命名颜色方面是否与人类相似对于有效的人机交互至关重要。", "innovation": "本文首次系统评估了多种VLMs的颜色命名能力，通过使用957种颜色样本和技术经典的颜色命名方法，复现了以往的经典实验结果，揭示了不同模型在颜色命名上的差异性。研究跨越了九种不同的语言，展示了训练数据的不平衡性，尤其是在英语和汉语方面，并发现色彩的色调主导着模型的颜色命名决策。", "conclusion": "研究表明，虽然VLMs在典型的颜色命名上准确率很高，但在扩展、非典型的颜色集上表现明显下降。研究还确定了21个常见颜色术语在所有模型中的一致性出现，并指出有两种不同的方法：约束性强的模型主要使用基本术语，而扩展性强的模型则使用系统性的亮度修改。进一步的消融研究表明，语言模型结构对颜色命名有显著影响，这与视觉处理能力无关。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22622", "html_url": "https://arxiv.org/abs/2509.22622", "title": "长命：实时互动长视频生成", "title_en": "LongLive: Real-time Interactive Long Video Generation", "authors": "Shuai Yang,Wei Huang,Ruihang Chu,Yicheng Xiao,Yuyang Zhao,Xianbang Wang,Muyang Li,Enze Xie,Yingcong Chen,Yao Lu,Song Han,Yukang Chen", "background": "长视频生成面临着效率和质量上的挑战。尽管扩散模型和扩散强制模型能够生成高质量的视频，但因双向注意力机制导致效率低下。因果注意力自回归模型支持KV缓存以加快推理速度，但在处理长时间视频时会因内存挑战而降低视频质量。此外，静态提示基础生成之外，具有实时流式提示输入的互动能力对于动态内容创作至关重要，能够使用户在实时引导叙述过程中实现视觉一致性和语义连贯性。这些因素增加了复杂性，特别是促使视觉和语义在提示转换过程中保持一致。这些挑战成为本研究需要解决的问题。", "innovation": "长命(LongLive)采用因果框架级自回归设计，并结合了KV缓存刷新机制以实现平滑、适应性的切换；流式长调整以促进长视频的训练和使训练与推理保持一致；以及短窗口注意力和框架级注意力下采样。这些设计使1.3亿参数的短片段模型仅需32个GPU天即可进行每分钟的生成。在推理时，长命能够以20.7 FPS的速度在单个NVIDIA H100上运行，其性能在所有视频长度上都有强劲表现。它还支持单个H100 GPU上的240秒视频生成，并且仅轻微影响质量的精度量化推理。", "conclusion": "长命通过上述关键设计，不仅提升了长视频实时生成的效率，还确保了生成视频的质量，能够在保持实时性的同时，提供高度互动和高质量的长视频生成能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22581", "html_url": "https://arxiv.org/abs/2509.22581", "title": "SpikeMatch：利用脉冲神经网络时序动态的半监督学习", "title_en": "SpikeMatch: Semi-Supervised Learning with Temporal Dynamics of Spiking Neural Networks", "authors": "Jini Yang,Beomseok Oh,Seungryong Kim,Sunok Kim", "background": "近年来，脉冲神经网络（SNNs）因其生物可行性及能效性受到了广泛关注。与之相反，基于SNN的模型在半监督学习（SSL）方面的发展相对有限，相较于人工神经网络（ANNs）的SSL方法而言更是如此。由于未充分探索SNN的内在机制在SSL中的应用，现有的方法难以有效利用SNN的时间动态特征实现可靠的伪标签生成。", "innovation": "本文提出了一种名为SpikeMatch的新颖SSL框架，该框架能够利用SNN的时间动态特性进行多样化的伪标签生成，从而用于计算机协同训练。SpikeMatch通过利用单一SNN预测结果的共识性来生成可靠的伪标签，这些伪标签来自于弱增强的未标记样本，并用于训练强增强样本，有效地缓解了确认偏见问题，同时能够用有限的标签捕获具有判别性的特征。", "conclusion": "实验结果显示，SpikeMatch在各种公认的标准基准上均优于现有的适应SNN骨干的SSL方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22544", "html_url": "https://arxiv.org/abs/2509.22544", "title": "HyCoVAD: 一种用于复杂视频异常检测的混合SSL-LLM模型", "title_en": "HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection", "authors": "Mohammad Mahdi Hemmatyar,Mahdi Jafari,Mohammad Amin Yousefi,Mohammad Reza Nemati,Mobin Azadani,Hamid Reza Rastad,Amirmohammad Akbari", "background": "视频异常检测(VAD)在智能监控中至关重要，但一个重大挑战是识别复杂的异常，这些异常是由多个实体之间复杂的关系和时间依赖性定义的，而不是孤立的动作。自我监督学习(SSL)方法可以建模低层的空间时间模式，但在理解这些交互的语义含义方面往往存在问题。相比之下，大型语言模型(LLMs)提供强大的上下文推理能力，但对于逐帧分析来说计算成本高，缺乏精细的空间定位。", "innovation": "我们提出了HyCoVAD，一种混合SSL-LLM模型，结合了基于变压器的nnFormer骨干的多任务SSL时间分析器与LLM验证器。SSL模块通过训练多个代理任务，从视频帧中学习并识别可疑的异常。选择的帧然后传递给LLM，通过结构化、基于规则的推理来验证异常的存在，丰富了分析的语义背景。实验证明，HyCoVAD在具有挑战性的ComplexVAD数据集上的帧级AUC达到72.5%，比现有基线高出12.5%，同时减少了LLM计算成本。", "conclusion": "实验结果显示，HyCoVAD在ComplexVAD数据集上实现了72.5%的帧级AUC，与现有基线相比提高了12.5%，同时降低了LLM的计算成本。我们还发布了交互异常分类法、自适应阈值协议和代码，以促进未来复杂VAD场景的研究。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22542", "html_url": "https://arxiv.org/abs/2509.22542", "title": "开放世界视角的类别发现", "title_en": "Category Discovery: An Open-World Perspective", "authors": "Zhenqi He,Yuanpei Liu,Kai Han", "background": "类别发现（CD）是一个新兴的开放世界学习任务，旨在利用已标记数据对未标记数据进行自动分类，这些数据包含来自未见类别的实例。该任务吸引了大量的研究兴趣，形成了许多从不同角度解决此问题的研究文献。已有文献从不同角度探讨了解决问题的方法，但存在设计标签分配、估计类数量和扩展到复杂的多对象场景的问题挑战。过去的研究提供了从不同角度解决类别发现问题的方法，并从实际应用场景中定义了延续类别发现、偏斜数据分布、联邦类别发现等扩展设置，以应对不同真实应用场景中的额外挑战。", "innovation": "论文提供了一个全面的文献综述，通过对文献进行分类，包括新型类别发现（NCD）和泛化类别发现（GCD）等基本设置，以及用于应对不同实际应用场景中额外挑战的多个衍生设置，如延续类别发现、偏斜数据分布、联邦类别发现等。详细分析了每种设置下的方法，涵盖了代表学习、标签分配和类数量估计这三个基本组成部分，并将所有方法进行了基准测试，得出大规模预训练骨干网络、层次和辅助提示、以及类似梯度式的训练是有益的，但标签分配的设计、类数量的估计和扩展到复杂的多对象场景仍然存在挑战。", "conclusion": "论文总结了现有的关键见解，并指出了未来研究的方向。汇聚了一个活的文献综述，链接为：this http URL。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22635", "html_url": "https://arxiv.org/abs/2509.22635", "title": "使用双重IP-适配器指导的无训练合成数据生成", "title_en": "Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance", "authors": "Luc Boudier,Loris Manganelli,Eleftherios Tsonis,Nicolas Dufour,Vicky Kalogeiton", "background": "由于标注样本的有限性，少样本图像分类仍然具有挑战性。近期方法尝试利用文本到图像的扩散模型生成合成训练数据，但常需要大量模型微调或外部信息源。", "innovation": "提出了一种名为DIPSY的无训练新方法，利用IP-Adapter进行图像到图像的翻译，仅使用现有的少样本数据生成高度区分性的合成图像。DIPSY引入了三项关键技术创新：（1）扩展的无分类器控制方案，实现对正向和负向图像条件的独立控制；（2）基于类相似性的采样策略，识别有效的对比样本；（3）无需微调和外部标题滤除的简单有效的流程。", "conclusion": "通过十种基准数据集的实验，表明该方法在达到或接近最新的性能水平的同时，消除了对生成模型调整和依赖外部工具进行图像滤波和标题生成的需要。结果强调了利用正负图像提示生成类别区分性特征的有效性，尤其是在细粒度分类任务中。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22615", "html_url": "https://arxiv.org/abs/2509.22615", "title": "使用2D高斯点阵从压缩图像表示实现视觉语言对齐", "title_en": "Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting", "authors": "Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe", "background": "现代视觉语言管道由训练在大量图像文本语料库上的RGB视觉编码器驱动，虽然这些管道实现了令人印象深刻的零样本能力和跨任务的强迁移，但它们仍然继承了像素域中的两大结构性不足：（i）将密集的RGB图像从边缘设备传送到云端能耗密集且成本高；（ii）基于块的分词使序列长度爆炸性增长，对注意力预算和上下文极限造成压力。", "innovation": "作者探索了2D高斯点阵（2DGS）作为替代视觉基础，这是一种紧凑且空间自适应的表示方式，通过一组带有颜色的各向异性高斯函数参数化图像。通过开发一个大规模的2DGS管道，结合结构化的初始化、亮度感知的剪枝以及批量CUDA内核，实现了比先前实现快90倍的拟合速度，并且GPU利用率约为97%。此外，作者将对比语言图像预训练（CLIP）适应2DGS，仅训练大约7%的参数，进一步提高效率。", "conclusion": "在大型DataComp子集上，GS编码器在相对像素压缩输入3到20倍的情况下，实现了有意义的零样本ImageNet-1K性能。尽管目前的准确性落后于RGB编码器，但作者的结果表明2DGS是一种可行的多模态基础架构，确定了架构瓶颈，并为同时在边缘云学习中实现语义强大和传输高效的表示开辟了途径。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22548", "html_url": "https://arxiv.org/abs/2509.22548", "title": "JanusVLN：通过双隐式记忆解耦语义与空间性实现视觉-语言导航", "title_en": "JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation", "authors": "Shuang Zeng,Dekang Qi,Xinyuan Chang,Feng Xiong,Shichao Xie,Xiaolong Wu,Shiyi Liang,Mu Xu,Xing Wei", "background": "论文背景在于，视-语导航（VLN）要求通过自然语言指令和连续视频流来引导一个实体穿越未知环境。近期VLN进步得益于多模态大型语言模型的强大语义理解能力，但现有方法依赖显式的语义记忆，如构建文本认知地图或存储历史视觉帧。这种方法存在空间信息损失、计算冗余和内存膨胀的问题，从而影响了有效的导航。", "innovation": "研究创新之处在于，提出了一种新型的VLN框架——JanusVLN，采用双隐式神经记忆，将空间几何性和视觉语义记忆分别表示为紧凑且固定尺寸的神经表示。该框架扩展了MLLM以包含来自空间几何编码器的3D先验知识，增强了基于RGB输入的模型的三维空间推理能力。通过构建空间几何编码器和视觉语义编码器的历史键值缓冲，形成双隐式记忆，并通过保留初始和滑动窗口中的键值避免冗余计算，实现高效增量更新。实验结果表明，JanusVLN在多种测试中均优于超过20种最新方法，并且提高了成功率达到10.5-35.5%和3.6-10.8%。", "conclusion": "这项研究证明了提出的双隐式神经记忆作为新型范式的潜力，为未来VLN研究开辟了新的方向。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22624", "html_url": "https://arxiv.org/abs/2509.22624", "title": "SPARK: 双向政策与奖励共生框架", "title_en": "SPARK: Synergistic Policy And Reward Co-Evolving Framework", "authors": "Ziyu Liu,Yuhang Zang,Shengyuan Ding,Yuhang Cao,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang", "background": "近期，大型语言模型（LLMs）和大型视觉语言模型（LVLMs）越来越多地采用强化学习（RL）进行后训练，如使用可验证奖励的RL（RLVR）处理客观任务，使用人类反馈的强化学习（RLHF）处理主观任务。然而，RLHF存在依赖人类偏好带来的高成本和潜在的奖励策略不匹配问题，而RLVR则通过每次更新后丢弃模拟结果和正确性信号造成监督浪费。", "innovation": "该研究提出了双向政策与奖励共生框架（SPARK），这是一种基于RLVR的高效、在策略上的稳定方法。SPARK通过重新利用每次迭代中的模拟结果和正确性数据，同时训练作为生成奖励模型的模型本身。辅助训练采用点奖励得分、配对比较、以及基于进一步反思响应的评估等多种目标，以指导模型自我评估和改进。这一步骤消除了对独立奖励模型和昂贵的人类偏好数据的需要，创建了一个正向共生反馈循环，从而提高模型性能和推广能力。", "conclusion": "SPARK在一维和多维基准测试中表现出显著的性能提升，特别是在多个LLM和LVLM模型上。例如，SPARK-VL-7B在7个推理基准测试中平均提高了9.7%，在2个奖励基准测试中提高了12.1%，在8个通用基准测试中提高了1.5%，展示了其稳健性和广泛的应用能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22647", "html_url": "https://arxiv.org/abs/2509.22647", "title": "CapRL: 刺激密集图像描述能力的强化学习", "title_en": "CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning", "authors": "Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin", "background": "图像描述是将视觉领域与语言领域相连的基本任务，在预训练大型视觉-语言模型（LVLM）中发挥关键作用。当前最先进的图像描述模型通常通过监督微调（SFT）训练，这种依赖昂贵且难以扩展的人类或专有模型标注的数据框架。这种方法导致模型记忆力过强，限制了其生成多样性和创造力的能力。因此，为了克服SFT的局限性，我们提出了将验证奖励的强化学习（RLVR）应用到开放式的图像描述任务中。", "innovation": "我们引入了图像描述强化学习（CapRL），这是一种新的训练框架，通过其实用性重新定义了描述质量：高质量的描述应使非视觉语言模型能够准确回答与该图像相关的问题。CapRL采用了一种解耦的两级管道，其中LVLM生成描述，而客观奖励则来自视觉无关语言模型通过仅依据该描述正确回答多项选择题的准确性。", "conclusion": "作为第一个将RLVR应用于主观图像描述任务的研究，我们证明了CapRL在多个设置中显著提高了表现。在由CapRL-3B标注的CapRL-5M描述数据集预训练后，12个基准测试都取得了显著的进步。此外，在Prism框架的描述质量评估中，CapRL的性能与Qwen2.5-VL-72B几乎持平，但平均超过了基线8.4%。相关代码已在此处提供: this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22650", "html_url": "https://arxiv.org/abs/2509.22650", "title": "RefAM：零样本指示分割中的注意磁体", "title_en": "RefAM: Attention Magnets for Zero-Shot Referral Segmentation", "authors": "Anna Kukleva,Enis Simsar,Alessio Tonioni,Muhammad Ferjad Naeem,Federico Tombari,Jan Eric Lenssen,Bernt Schiele", "background": "大多数现有的指示分割方法仅通过微调或组合多个预训练模型来实现良好的性能，这通常需要额外的训练和架构修改。另一方面，大规模生成扩散模型能够编码丰富的语义信息，使其作为通用特征提取器具有吸引力。现有方法要么在额外训练和架构修改上花费代价，要么通过细调或组合预训练模型才能实现良好性能。在本工作中，我们提出了一种新方法，该方法直接利用扩散变换器中的注意分数来处理下游任务，而无需架构修改和额外训练。", "innovation": "我们利用停止词作为注意磁体，提出了一种新的注意力重分布策略，将背景激活分割成更小的簇，生成更清晰和更局部的热图。此外，我们开发了RefAM，一个无需微调的基础架构，综合了交叉注意力图、GAS处理和重分布技术，系统地评估了这些特征，通过与现有方法的比较，证明了该方法的优越性。", "conclusion": "我们的方法在零样本指示图像和视频分割基准测试中表现优越，无需微调或额外组件，建立了新状态的最新水平。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22627", "html_url": "https://arxiv.org/abs/2509.22627", "title": "CCNeXt: 一种有效的自监督立体深度估计方法", "title_en": "CCNeXt: An Effective Self-Supervised Stereo Depth Estimation Approach", "authors": "Alexandre Lopes,Roberto Souza,Helio Pedrini", "background": "深度估计在机器人技术、自主驾驶车辆和增强现实等领域中起着至关重要的作用。这些应用场景通常受到计算能力的限制。立体图像对通过计算图像对中的像素视差来确定已知平整系统的深度，提供了有效的深度估计解决方案。由于难以在各种场景中获得可靠的地面真实深度数据，自监督技术在可获取大量未标记数据时成为一种解决方案。", "innovation": "提出了一种新的自监督卷积方法CCNeXt，该方法在平衡计算成本的同时，优于现有的最先进的卷积神经网络（CNN）和视觉变换器（ViT）。CCNeXt架构采用现代CNN特征提取器以及具有新颖的窗口式视差交叉注意力模块的编码器，并通过全面重新设计深度估计解码器来增强。实验表明，CCNeXt在KITTI Eigen Split测试数据上实现了竞争力的指标，速度比当前最佳模型快10.18倍，并且在KITTI Eigen Split改进的地 truth数据集和驾驶立体数据集中达到了最先进的所有指标，优于最近提出的多种技术方法。", "conclusion": "CCNeXt在多个数据集中达到了最先进的深度估计性能，同时保持了高效计算，确保了算法的完全可重复性，并提供了项目的访问链接。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22631", "html_url": "https://arxiv.org/abs/2509.22631", "title": "Labeling Copilot：计算机视觉中自动化数据标注深度研究代理", "title_en": "LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision", "authors": "Debargha Ganguly,Sumit Kumar,Ishwar Balappanawar,Weicong Chen,Shashank Kambhatla,Srinivasan Iyengar,Shivkumar Kalyanaraman,Ponnurangam Kumaraguru,Vipin Chaudhary", "background": "创建高质量、领域特定的数据集是部署稳健视觉系统的主要瓶颈。在海量未标注的数据湖中进行研究时，需要在数据质量、多样性和成本之间做出复杂的权衡。", "innovation": "提出了Labeling Copilot，这是第一个计算机视觉领域的数据标注深度研究代理，它通过一个大型多模态语言模型驱动的中央协调程序，利用多步推理执行三个核心能力的功能：(1) 校准发现，从大型存储库中获取相关且内分布的数据；(2) 可控合成，生成针对罕见场景的新型数据并进行稳健过滤；(3) 共识标注，通过新颖的共识机制协调多个基础模型，包括非极大值抑制和投票，生成准确的标签。", "conclusion": "大规模验证证明了Labeling Copilot组件的有效性。共识标注模块在稠密的COCO数据集上，每张图像平均产生14.2个候选提案，几乎是7.4个真实对象的两倍，最终实现37.1%的注释mAP。在网页规模的Open Images数据集上，它成功处理了极端的类别不平衡，发现了903个新的边界框类别，使其能力总数超过了1500个。同时，校准发现工具在1000万个样本规模下，通过一个高效的主动学习策略，计算效率比同类替代品高出40倍。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22628", "html_url": "https://arxiv.org/abs/2509.22628", "title": "UML-CoT: 通过统一建模语言进行结构化推理和规划以实现机器人家庭清洁", "title_en": "UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning", "authors": "Hongyu Chen,Guangrun Wang", "background": "链式思维（CoT）提示在大型语言模型（LLMs）中增强了推理能力，但依赖于无序文本限制了在赋予行为任务中的解释性和可执行性。早期研究已经探索了使用场景图或逻辑图结构化的CoT，但这些仍然存在根本局限性：仅能建模低阶关系、缺乏继承或行为抽象的概念，并且没有为顺序或条件规划提供标准语义。", "innovation": "本文提出了UML-CoT，一种利用统一建模语言（UML）生成符号CoT和可执行动作计划的结构化推理和规划框架。UML类图捕获组合对象语义，活动图模型过程控制流。训练管道结合了监督微调与组相对策略优化（GRPO），包括仅从答案学习奖励。UML-CoT在杂乱房间清洁场景的新基准测试中表现出更好的可解释性、规划连贯性和执行成功率，展示了UML作为一种更具有表达性和可操作性的结构化推理形式的重要性。", "conclusion": "UML-CoT 较传统无结构的 CoT 在可解释性、规划连贯性和执行成功率方面表现出更优的性能，彰显了UML 在结构化推理和规划中的优势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21513", "html_url": "https://arxiv.org/abs/2509.21513", "title": "DistillKac: 通过阻尼波动方程实现少量步骤图像生成", "title_en": "DistillKac: Few-Step Image Generation via Damped Wave Equations", "authors": "Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon", "background": "传统上，生成图像的方法倾向于使用扩散模型，但这些模型的逆时间速度可能变得僵硬，并隐含允许无限传播速度。相比之下，通过阻尼波动方程（damped wave equation）及其随机Kac表示，DistillKac能够以有限速度移动概率质量，并且能够全局限制动能。", "innovation": "DistillKac通过引入速度空间中的无分类器引导，使得在轻微条件下保持平方可积，并采用端点只蒸馏技术，培训学生模型在长时间间隔匹配冷冻教师模型。此外，证明了稳定性结果，以确保在整个路径中监督点接近。", "conclusion": "DistillKac通过阻尼波动方程生成高质量图像，并仅需很少的功能评估，同时保持有限速度概率流的数值稳定性优势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22636", "html_url": "https://arxiv.org/abs/2509.22636", "title": "尺度级VAR其实是离散扩散", "title_en": "Scale-Wise VAR is Secretly Discrete Diffusion", "authors": "Amandeep Kumar,Nithin Gopalakrishnan Nair,Vishal M. Patel", "background": "自回归（AR）变压器已经成为了视觉生成中强有力的范式，主要是因为它们的可扩展性、计算效率以及能够统一语言和视觉的架构。在它们中，最近的未来尺度预测视觉自回归生成（VAR）已经展示了显著的性能，并且甚至超越了基于扩散的模型。文中首先回顾了VAR，并发现当配备了马尔可夫注意力掩码时，VAR在数学上和离散扩散模型等价。这一重新解释被定义为可扩展的视觉细化与离散扩散（SRDD），建立了AR变压器与扩散模型之间的原则性桥梁。", "innovation": "文章通过新的视角，展示了如何直接借鉴扩散模型的优势（如迭代细化）并降低AR变压器的架构上的低效性，实现了更快的收敛、低于推理成本和提高零样本重构。在多个数据集上，这种基于扩散模型的VAR视角带来了持续的效率和生成上的提升。", "conclusion": "本文通过重新解释定义了一个新的视角，SKDD模型在效率和生成上有持续性的改进，并为进一步的研究提供了基础。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22645", "html_url": "https://arxiv.org/abs/2509.22645", "title": "基于CLIP的分层表示匹配用于类别增量学习", "title_en": "Hierarchical Representation Matching for CLIP-based Class-Incremental Learning", "authors": "Zhen-Hao Wen,Yan Wang,Ji Feng,Han-Jia Ye,De-Chuan Zhan,Da-Wei Zhou", "background": "分层增量学习(CIL)旨在使模型能够连续适应不断变化的数据流。最近，预训练的多模态模型（如CLIP）提供了强大的基础来实现这一目标。然而，现有方法通常依赖于简化的模板（如“一张[CLASS]的照片”），忽视了视觉概念的层次结构。例如，识别“猫”与“车”依赖粗粒度的线索，而区分“猫”和“狮子”则需要细粒度的细节。现有的CLIP特征映射方法仅依赖最后一层的表示，忽视了早期层中包含的层次信息。因此，此工作引入了基于CLIP的层次表示匹配(HiErarchical Representation MAtchiNg, HERMAN)。", "innovation": "该工作引入了HERMAN，利用大语言模型（LLMs）递归生成区分性文本描述符，扩充了语义空间，以明确的层次线索进行匹配。这些描述符根据任务特定需求适配性路由，实现了精确区分，减轻了增量任务中的灾难性遗忘。通过在多项基准测试上的实验，该方法在所有测试中都取得了最先进的性能。", "conclusion": "广泛实验表明，该方法在多个基准测试中取得了最先进的性能，实现了精确区分，同时减轻了增量学习中的灾难性遗忘现象。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21339", "html_url": "https://arxiv.org/abs/2509.21339", "title": "带有柯西-施瓦茨散度的跨模态检索", "title_en": "Cross-Modal Retrieval with Cauchy-Schwarz Divergence", "authors": "Jiahao Zhang,Wenzhe Yin,Shujian Yu", "background": "有效的跨模态检索需要异构数据类型的稳健对齐。现有的大多数方法主要集中在双模态检索任务上，并依赖于Kullback-Leibler散度、最大均值差异、相关性对齐等分布对齐技术。然而，这些方法通常存在一些关键限制，如数值不稳定性、对超参数的敏感性以及无法捕捉底层分布的全部结构。", "innovation": "本文引入了柯西-施瓦茨(CS)散度，这是一种无需超参数的测量方法，可以提高训练稳定性和检索性能。进一步提出了一种基于Hölder不等式的广义柯西-施瓦茨(GCS)散度。这种扩展使得在统一的数学框架中可以直接对三个或更多的模态进行对齐，通过双向循环比较方案，省略了所有两两对比的需要。", "conclusion": "在六个基准数据集上的广泛实验表明，本文的方法在双模态和三模态检索任务中均有效。我们的CS/GCS散度代码可在以下链接公开获取。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22646", "html_url": "https://arxiv.org/abs/2509.22646", "title": "利用多模态语言模型在AI生成视频中学习人类感知的虚假性", "title_en": "Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs", "authors": "Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch", "background": "随着视频生成模型的快速发展，人类能否识别AI生成视频中的假痕迹（如时空上的视觉伪影）这一关键维度已被严重忽视。本研究旨在通过引入DeeptraceReward，一种细粒度、空间和时间感知的基准，对人类感知的假痕迹进行标注，从而为生成视频的奖励提供依据。该基准包含4300多个高质视频的详细注解，每个注解都包括自然语言解释、边界框定位以及精确的时间戳。", "innovation": "本研究创新地提出了DeeptraceReward，这是一种细粒度的空间和时间感知基准，用于标注人类感知到的AI生成视频中的假痕迹。研究人员还训练了多模态语言模型（LMs）作为奖励模型，模仿人类判断和定位的能力，并在DeeptraceReward基准上展示了优异的表现，特别是对于假迹识别、接地和解释，7B奖励模型比GPT-5高出34.7%。此外，研究还发现不同任务难度存在差异，从二元真假分类到精细的假迹检测，再到时间定位，难度逐渐增加。", "conclusion": "DeeptraceReward为社会意识和值得信赖的视频生成提供了一个严格的测试平台和训练信号。通过突出人类感知的假痕迹，研究者们提供了一个评估和训练生成模型的有力工具，确保生成的内容更加真实和可信。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21526", "html_url": "https://arxiv.org/abs/2509.21526", "title": "TRiCo: 三角博弈协同训练实现稳健的半监督学习", "title_en": "TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning", "authors": "Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang", "background": "介绍了TRiCo，一种新颖的三元游戏论协同训练框架，通过引入教师、两位学生和一个对抗生成器，重新思考半监督学习的结构。该框架不同于现有的协同训练或教师学生方法，将SSL视为三个角色间的结构化互动，具体而言，（i）两位学生分类器在冻结的互补表示上训练；（ii）一个元学习教师通过基于验证的反馈灵活调节伪标签选择和损失平衡；（iii）一个非参数生成器扰动嵌入以揭示决策边界弱点。伪标签根据互信息选择，而非置信度，提供了一种更稳健的先验不确定性度量。这种三角互动被形式化为Stackelberg博弈，其中教师指导策略优化，学生在对抗扰动下跟随。", "innovation": "提出TRiCo框架，通过引入教师、两位学生和一个非参数生成器，将半监督学习（SSL）视为三个角色间的互动，旨在解决现有SSL框架中的静态视图互动、不可靠的伪标签和缺乏硬样本建模的问题。TRiCo通过元学习教师优化伪标签选择和损失平衡，运用非参数生成器发现决策边界弱点，以及根据互信息选择伪标签，从而实现更稳健的先验不确定性测量。", "conclusion": "TRiCo在CIFAR-10、SVHN、STL-10和ImageNet等数据集上进行了广泛的实验，证明了在低标签情况下的一贯优异性能，而且该框架具有架构无关性，能够与冻结的视觉骨干网络兼容。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21789", "html_url": "https://arxiv.org/abs/2509.21789", "title": "视觉多智能体系统：通过视觉流缓解幻觉雪崩", "title_en": "Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow", "authors": "Xinlei Yu,Chengming Xu,Guibin Zhang,Yongbo He,Zhangquan Chen,Zhucun Xue,Jiangning Zhang,Yue Liao,Xiaobin Hu,Yu-Gang Jiang,Shuicheng Yan", "background": "多智能体系统（MAS）结合视觉语言模型（VLMs）在执行复杂任务方面具有潜力，但面临着一个新的失败模式——多智能体视觉幻觉雪崩（multi-agent visual hallucination snowballing）。这种现象是指幻觉在单个智能体中产生并通过依赖文本流动传递视觉信息的方式在后续智能体中被放大。", "innovation": "本文通过引入ViF（Visual Flow），一种轻量级且可插拔的缓解机制，使用选定的视觉通讯令牌传递智能体间的消息，并重新分配注意力以促进这种模式，从而缓解幻觉雪崩现象。ViF减轻了幻觉雪崩，实验结果表明该方法在八个基于四种常见MAS结构和十个基础模型的基准测试中表现出优越性能。", "conclusion": "实验结果表明，本文提出的方法显著减少了幻觉雪崩的现象，并在八个基于四个常见MAS结构和十个基础模型的基准测试中都保持了稳定的性能提升。论文的源代码已发布至给定链接。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21898", "html_url": "https://arxiv.org/abs/2509.21898", "title": "逐类增量学习的插件式增量向量变换框架", "title_en": "Closing the Oracle Gap: Increment Vector Transformation for Class Incremental Learning", "authors": "Zihuan Qiu,Yi Xu,Fanman Meng,Runtong Zhang,Linfeng Xu,Qingbo Wu,Hongliang Li", "background": "逐类增量学习（CIL）的目标是逐步获取新类别的知识而不遗忘之前学习的内容。尽管近年来取得了一些进展，但现有的CIL方法在性能上仍然落后于其理想模型——即全程拥有历史数据的模型。基于近期对线性模态连通性（LMC）的理解，本文重新探讨了CIL中理想解的几何特性，并发现理想解通常与前一个任务的最优解保持低损失的线性连接。基于此发现，本文提出了一种名为增量向量变换（IVT）的新型插件式框架，旨在训练过程中减轻灾难性遗忘。IVT通过递期间隔地将模型参数转移到保持与之前任务最优解线性连接的变换解上，同时保持低损失，从而有效确保之前学习任务的稳定性能。", "innovation": "提出了插件式增量向量变换（IVT）框架。IVT通过线性连接来减轻灾难性遗忘，保持模型参数的低损失和与之前任务最优解的线性连接，可以高效地近似使用对角Fisher信息矩阵，适用于既没有示例又基于示例的各种初始化策略，通过在CIFAR-100、FGVCAircraft、ImageNet-Subset和ImageNet-Full上进行广泛的实验验证了IVT的有效性和提升效果。", "conclusion": "IVT有效提升了几种强CIL基线模型的性能。在CIFAR-100上，IVT将PASS基线的最后准确率提升了5.12%，减少了2.54%的遗忘；在FGVCAircraft上的CLIP预训练SLCA基线中，IVT使平均准确率提升了14.93%，最后准确率提升了21.95%。所有相关代码都将被公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21473", "html_url": "https://arxiv.org/abs/2509.21473", "title": "幻觉是不良估计吗？", "title_en": "Are Hallucinations Bad Estimations?", "authors": "Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu", "background": "研究将生成模型中的幻觉定义为无法将估计与任何可能的原因联系起来的现象。基于这一视角，研究展示了即使是最优的损失最小化估计器也会产生幻觉。研究通过提供一个对任意数据分布一般化的高概率下限界来确认这一观点，从而将幻觉重新定义为损失最小化与人类可接受输出之间的结构性对齐问题，以及由此产生的估计算法误差，特别是在重新校准时发生的问题。实验结果基于硬币聚合、开放型问答和文本转图像的任务，验证了理论观点。", "innovation": "将生成模型中的幻觉现象从先前的理解中抽离出来，重新定义为最优损失最小化估计器与人类可接受输出之间的结构性对齐问题。通过提供一个对幻觉率的一般性下限界，验证了这一新的视角。实验结果提供了对幻觉产生机制的更深入理解。", "conclusion": "研究揭示了幻觉与估计之间的联系，即幻觉的问题本质在于重新校准过程中损失最小化与人类可接受输出之间的结构性不匹配。实验结果支持了这一理论，表明通过优化估计以适应人类可接受的标准可以减少幻觉的发生。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20401", "html_url": "https://arxiv.org/abs/2509.20401", "title": "SGAligner++: 跨模态语言辅助的3D场景图对齐", "title_en": "SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment", "authors": "Binod Singh,Sayan Deb Sarkar,Iro Armeni", "background": "3D场景图对齐是机器人导航和感知任务中至关重要的一环。当前的方法通常依赖单一模态的点云数据，并且在处理不完整或有噪声输入时表现不佳。", "innovation": "我们提出了SGAligner++，一种跨模态、语言辅助的3D场景图对齐框架。该方法通过学习统一联合嵌入空间解决了跨异构模态部分重叠场景观测的对齐挑战，即使在低重叠和传感器噪声条件下也能实现精确的对齐。通过使用轻量级单模态编码器和基于注意力的融合，SGAligner++改善了场景理解，适用于视觉定位、3D重建和导航。同时，该方法保证了可扩展性和最小的计算开销。实验证明，SGAligner++在有噪声的现实世界重构任务上比最先进的方法提升了高达40%，并实现了跨模态的一般化能力。", "conclusion": "我们在真实世界数据集上的广泛评估表明，SGAligner++在嘈杂的现实世界重构任务上比最先进的方法性能提高了最高40%，同时实现跨模态的一般化能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21370", "html_url": "https://arxiv.org/abs/2509.21370", "title": "语言环路中的运河 culvert 检查", "title_en": "Language-in-the-Loop Culvert Inspection on the Erie Canal", "authors": "Yashom Dighe,Yash Turkar,Karthik Dantu", "background": "伊利运河等运河上的 culvert 等设施最初是在 1825 年建造的，需要频繁的检查以确保安全运行。人工检查 culvert 由于设施陈旧、几何结构复杂、照明条件差、天气因素以及难以接近等因素变得具有挑战性。", "innovation": "该研究引入了 VISION 系统，这是一个端到端的语言集成自主系统，结合了一个大规模的视觉-语言模型与受控视角规划，用于自动检查 culvert。简短的提示促使视觉-语言模型提出开放词汇的兴趣区域（ROI）建议并提供合理性与置信度，通过融合立体深度来恢复规模，一个计划器根据 culvert 的限制命令重新定位动作来捕捉对焦特写。该系统部署在伊利运河 culvert 里的四足机器人上，实现了无需特定领域微调即可在核心现场闭环中生成高分辨率图像进行详细报告的闭环。", "conclusion": "外部评估显示初稿的 ROI 建议与主题专家达成 61.4% 的一致意见，最终的重新成像评估达到了 80%，表明 VISION 能够将初步假设转化为与专家一致的支持依据。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22053", "html_url": "https://arxiv.org/abs/2509.22053", "title": "在内部类对比学习中丰富知识蒸馏", "title_en": "Enriching Knowledge Distillation with Intra-Class Contrastive Learning", "authors": "Hua Yuan,Ning Xu,Xin Geng,Yong Rui", "background": "知识蒸馏自问世以来，研究大多关注如何有效利用教师模型生成的软标签。现有研究表明，软标签中的潜在知识来源于数据中存在的多视角结构。同一类别的样本中的特征变化使学生模型能够通过学习多样化表示来更好地泛化。然而，现有的蒸馏方法中教师模型主要依赖于真实标签作为目标，忽略了同一类别中的多样化表示。", "innovation": "本文提出在教师模型训练中引入内部类对比损失，以增强软标签中的内部类信息。实际应用中发现，内部类损失会导致训练不稳定并减缓收敛速度。为此，研究将边界损失集成到内部类对比学习中以提高训练稳定性和收敛速度。此外，通过理论分析证明了内部类对比损失能丰富内部类的多样性。", "conclusion": "实验结果表明提出了的方法是有效的。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21498", "html_url": "https://arxiv.org/abs/2509.21498", "title": "SlimDiff：无监督、基于激活的手动瘦身扩散模型", "title_en": "SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models", "authors": "Arani Roy,Shristi Das Biswas,Kaushik Roy", "background": "扩散模型（DMs）以其生成性能而受到赞誉，但由于其参数量达十亿级别以及迭代去噪动态机制，计算成本非常高。现有的效率提升技术，如量化、时间步长减少或剪枝，能节省计算资源、内存或运行时间，但依赖于重新调整或微调以恢复性能，存在瓶颈。", "innovation": "作者提出了SlimDiff，这是一种自动激活驱动的结构压缩框架，可以同时减少DMs中的注意力和前向传递维度，而且完全没有梯度依赖。SlimDiff将DM压缩重新定义为谱逼近任务，通过在给定压缩预算下定义噪声层间活跃度低秩子空间来动态剪枝。This approach avoids isolated matrix factorization and instead applies module-wise decompositions over functional weight groups, such as query--key interactions, value--output couplings, and feedforward projections, while adaptively allocating sparsity across modules to respect the non-uniform geometry of diffusion trajectories.", "conclusion": "SlimDiff在保持与未压缩模型相当的生成质量的情况下，比基线模型加速最高达35%，减少了约100M的参数。更为关键的是，这种方法只需约500个校准样本，比先前方法少70多倍。这是首个完全无训练的、基于激活的、结构压缩的方法，具有理论清晰性和实际效率优势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21477", "html_url": "https://arxiv.org/abs/2509.21477", "title": "VISION: 从不完整观测数据重构海洋垂直速度", "title_en": "VISION: Prompting Ocean Vertical Velocity Reconstruction from Incomplete Observations", "authors": "Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang", "background": "在地球科学中，从不完整的表面观测数据重建海底动力学，如垂直速度场，面临着重大挑战。长久以来，地球科学领域受限于缺乏标准化和可供分析的基准数据集。因此，系统性地处理这一问题并推动相关研究显得尤为重要。为此，研究者们构建并发布了KD48，这是一个源自大规模模拟且由专家驱动去噪的高分辨率海洋动力学基准数据集，以便系统性地解决这一问题并促进研究。基于此基准，研究者引入了VISION，这是一种基于动态提示的新颖重建范式，旨在解决真实世界观测数据中缺失数据的核心问题。VISION的核心在于能够从任何可用的部分观察生成实时的视觉提示，该提示既编码了数据可用性和海洋物理状态。这是一种机制，使得VISION能够灵活地处理不同输入组合带来的挑战。", "innovation": "VISION重建范式基于动态提示设计，能够从任何可用的部分观察数据生成实时的视觉提示，这种提示编码了数据可用性和海洋的物理状态。VISION还设计了状态条件下的提示模块，能够高效地将这些提示注入一个几何和尺度感知的通用骨干模型中，引导其自适应调整计算策略。这种机制使得VISION能够高效处理不同输入组合带来的挑战，同时在KD48基准上的实验表明VISION不仅在性能上大幅超越了最先进的模型，还表现出在极大型数据缺失下的强大泛化能力。", "conclusion": "通过提供一个高质量基准和一个强大的模型，我们的工作为在数据不确定性条件下开展海洋科学研究奠定了坚实的基础。我们的代码可以在以下链接获取：this https URL。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21531", "html_url": "https://arxiv.org/abs/2509.21531", "title": "基于补丁的扩散模型在高效、放射科医生首选的MRI重建中的应用", "title_en": "Patch-Based Diffusion for Data-Efficient, Radiologist-Preferred MRI Reconstruction", "authors": "Rohan Sanda,Asad Aali,Andrew Johnston,Eduardo Reis,Jonathan Singh,Gordon Wetzstein,Sara Fridovich-Keil", "background": "磁共振成像（MRI）需要较长的采集时间，从而增加了成本，降低了可访问性，并使扫描更容易受到运动伪影的影响。扩散型概率模型通过学习数据驱动的先验可以潜在地减少采集时间。然而，它们通常需要大规模且成本高昂的训练数据集。补丁式的扩散模型在学习小规模实值数据的有效数据驱动先验方面显示出潜力，但在磁共振成像（MRI）中尚未证明其临床价值。", "innovation": "作者将补丁式扩散逆解算器（PaDIS）扩展到复值、多线圈MRI重建，并将其与最先进的整张图像扩散基线（FastMRI-EDM）进行比较，用于7倍欠采样MRI重建。实验结果表明，PaDIS-MRI模型即使在仅有25 k-空间图像的小数据集上训练，也能在图像质量指标（PSNR，SSIM，NRMSE）、像素级不确定性、跨对比度泛化能力以及对严重k-空间欠采样的鲁棒性方面优越于FastMRI-EDM。在盲测实验中，放射科医生在91.7%的情况下选择了PaDIS-MRI重建为诊断上更优越的选择。", "conclusion": "这些发现强调了在数据稀缺的临床环境中，对于高度诊断信心至关重要的核磁共振成像（MRI）重建中，补丁式扩散先验的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22126", "html_url": "https://arxiv.org/abs/2509.22126", "title": "指导性水印技术用于扩散模型", "title_en": "Guidance Watermarking for Diffusion Models", "authors": "Enoal Gesny,Eva Giboulot,Teddy Furon,Vivien Chappelier", "background": "该论文介绍了一种新颖的用于扩散模型的水印方法。该方法通过使用任意现成水印解码器计算的梯度来引导扩散过程。这种方法能够增强水印在对抗攻击中的鲁棒性，而不需重新训练或微调模型。研究表明，这种方法能够将任何形式的后处理水印方案转换为扩散过程中的生成嵌入。此外，该方法还与其他修改变分自编码器的水印技术形成互补。", "innovation": "该方法的核心创新在于利用现成水印解码器计算的梯度来引导扩散过程，从而无需重新训练或微调模型就能增强水印的鲁棒性。这种方法将后处理水印方案转换为生成过程中的嵌入，同时保持生成图像的多样性和质量。", "conclusion": "该方法在不同扩散模型和检测器上得到了验证，证明其能够有效增强水印在对抗攻击中的鲁棒性，并且不会显著改变由给定种子和提示生成的图像，同时保持生成图像的多样性和质量。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22227", "html_url": "https://arxiv.org/abs/2509.22227", "title": "基于航拍路径规划的城市几何和纹理同时捕获", "title_en": "Aerial Path Planning for Urban Geometry and Texture Co-Capture", "authors": "Weidan Xiong,Bochuan Zeng,Ziyu Hu,Jianwei Guo,Ke Xie,Hui Huang", "background": "近年来，图像获取和场景重建技术的进步使得在充分的场地信息下生成高质量的结构化城市场景几何变得可能。然而，当前的捕获技术往往忽视了纹理质量的重要性，导致纹理模型中出现明显的视觉瑕疵。本文研究了在前往现场之前仅依赖于目标区域的2D建筑轮廓图和安全飞行高度的条件下如何同时捕获城市几何和纹理的问题。", "innovation": "本文提出了一种创新的航拍路径规划框架，用于同时捕获用于重建结构化几何和高保真纹理的图像。为评估和支持视角规划，引入了一种全面的纹理质量评估系统，包括两种新型的适用于建筑外立面的度量标准。同时提出了一种多目标优化策略以最大化纹理保真度、提高几何精度并最小化航拍视角的成本。此外，还提出了一种序列路径规划算法，以考虑图像捕获过程中的纹理一致性。", "conclusion": "大规模合成和真实世界的城市数据集上的广泛实验表明，本文的方法能够生成适合同时进行几何和纹理重建的图像集，从而以较低的操作成本创造出真实感强且带有纹理的场景代理。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "临床不确定性影响机器学习评估", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集标签常带有不确定性，因为标注者之间存在分歧且不同案例的置信度不一致。传统的聚合方法，如多数投票，会掩盖这种变异性。在医疗影像基准测试的简单实验中，考虑二元标签的置信度对模型排名产生了显著影响。因此，论文认为机器学习评估应明确考虑注释不确定性，使用直接作用于分布的概率性指标。", "innovation": "提出了考虑标注不确定性的计分方法，并强调了这些方法不受注释生成过程的影响（如简单计数、主观置信评级或概率响应模型）。它们还具有轻量级的计算特性，因为存在封闭形式的线性时间实现（在按模型得分排序后）。这可以更好地反映临床数据的表现估计。", "conclusion": "建议社区提供原始注释，并采用不确定性感知的评估方法，以使性能估计更好反映临床数据。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21541", "html_url": "https://arxiv.org/abs/2509.21541", "title": "ControlHair: 基于物理的视频扩散用于可控动态发型渲染", "title_en": "ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering", "authors": "Weikai Lin,Haoxiang Li,Yuhao Zhu", "background": "发型模拟和渲染因其复杂的细丝动力学、多样的材料属性以及复杂的光-头发互动而极具挑战性。尽管近期的视频扩散模型能够生成高质量的视频内容，但它们在细粒度控制头发动力学方面仍存在不足。本文就背景介绍了现有技术的局限性，强调了对头发动态可控渲染的需求。", "innovation": "本文提出的ControlHair是一种混合框架，结合了物理模拟器与条件视频扩散，以实现可控的动态发型渲染。通过阶段性的管道设计，它首先使用模拟器将物理参数转成每帧几何图形，然后提取每帧的控制信号，最后将控制信号输入视频扩散模型生成具有所需发型动态效果的视频。这一级联设计将物理推理与视频生成分离，支持多种物理条件，使视频扩散模型的训练更加简单。Training on a curated 10K video dataset, ControlHair surpasses text- and pose-conditioned baselines, delivering precisely controlled hair dynamics.", "conclusion": "ControlHair在10,000视频生成数据集上训练，优于文本和姿势条件的基线，实现了精确控制的头发动力学。此外，还展示了ControlHair的三种应用场景：动态发型试穿、子弹时间效果和影片摄影。ControlHair提出了第一个基于物理的视频扩散框架，以实现可控动力学。并在网站上提供了演示视频和实验结果。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22522", "html_url": "https://arxiv.org/abs/2509.22522", "title": "JointDiff：在多智能体轨迹生成中弥合连续与离散", "title_en": "JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation", "authors": "Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo", "background": "生成模型常常将连续数据和离散事件视为两个独立的过程，导致在建模复杂系统时出现差距，特别是在这些系统中的交互是同步的情况下。为了解决这一问题，文章引入了JointDiff框架，旨在通过同时生成连续的空间-时间数据和同步的离散事件来统一这两个过程。", "innovation": "文章提出了一种新的扩散框架JointDiff，能够同时生成连续的空间-时间数据和同步的离散事件，并且在体育领域进行了验证，通过同时建模多智能体轨迹和关键控球事件来展示效果。此外，引入了CrossGuid，一种有效的多智能体领域条件操作，并共享了一种新的统一体育基准，增强了足球和橄榄球数据集的文本描述。", "conclusion": "JointDiff在多智能体轨迹生成中达到了最先进的性能，证明了联合建模对于构建现实且可控制的生成模型的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22394", "html_url": "https://arxiv.org/abs/2509.22394", "title": "基于残差nnResU-网络和解剖特征优先损失的深学习跨解剖CT合成", "title_en": "Deep Learning-Based Cross-Anatomy CT Synthesis Using Adapted nnResU-Net with Anatomical Feature Prioritized Loss", "authors": "Javier Sequeiro González,Arthur Longuefosse,Miguel Díaz Benito,Álvaro García Martín,Fabien Baldacci", "background": "介绍了使用Multicenter SynthRAD2025数据集（涵盖头部和颈部、胸部和腹部区域）进行MR到CT和CBCT到CT图像转换的基于补丁的3D nnUNet调整方法。该研究使用标准UNet和残差UNet两种主要网络配置，并引入了Anatomical Feature-Prioritized (AFP)损失，以及对输入体素进行zscore标准化的方法。", "innovation": "提出了一种使用基于补丁的3D nnUNet调整和残差网络的跨模态CT合成方法，并引入了Anatomical Feature-Prioritized (AFP)损失，以增强临床相关结构的重建。该方法还通过zscore标准化和数据集级别的zscore标准化方法优化了输入，适应了不同的数据集，并展示了一种有效的结合nnUNet管道、残差学习和解剖引导特征损失的方法。", "conclusion": "实验结果显示，结合了AFP损失的残差网络在MR到CT的骨结构重建和CBCT到CT的病灶重建中表现出更清晰的重建和更好的解剖学特征保真度。虽然仅使用L1损失的网络在基于强度的指标上表现稍好，但该研究方法证明了跨模态医学图像合成的稳定解决方案的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22049", "html_url": "https://arxiv.org/abs/2509.22049", "title": "GAN和扩散模型在MRI-to-CT转换中的比较分析", "title_en": "Comparative Analysis of GAN and Diffusion for MRI-to-CT translation", "authors": "Emily Honey,Anders Helbo,Jens Petersen", "background": "CT影像对于治疗和诊断至关重要，但在某些情况下缺乏CT影像或难以获取时，可以从MRI影像生成合成CT (sCT) 图像的方法备受关注。因此，评估不同策略的有效性以便更好地进行MRI到CT的转换具有重要的参考价值。本文将两种常用的MRI-to-CT转换架构——条件生成对抗网络（cGAN）和条件去噪扩散概率模型（cDDPM）进行性能对比。同时，将三维转换问题分解为一系列的二维平面上的转换，以探索能减少计算成本的方法，并研究单个MRI图像/切片和多个MRI切片对生成过程的影响", "innovation": "首次将cGAN和cDDPM作为一种替代方案进行对比；提出了一种新的评价方法——切片间相似性度量（SIMOS），用于评估sCT图像在3D格式中的连续性；将传统的三维转换问题分解为一系列二维平面的转换以降低计算成本", "conclusion": "研究发现，cDDPM在单通道和多通道条件输入下，生成MRI到CT的模型优于cGAN，证明cDDPM架构适用于MRI-to-CT转换"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21854", "html_url": "https://arxiv.org/abs/2509.21854", "title": "通过基于描述的正则化策略优化实现感知一致性多模态大型语言模型推理", "title_en": "Perception-Consistency Multimodal Large Language Models Reasoning via Caption-Regularized Policy Optimization", "authors": "Songjun Tu,Qichao Zhang,Jingbo Sun,Yuqian Fu,Linjing Li,Xiangyuan Lan,Dongmei Jiang,Yaowei Wang,Dongbin Zhao", "background": "多模态大型语言模型在视觉感知与符号推理结合的任务中表现出色，但其性能常因感知引起的错误而被削弱，这些错误会传播到推理链中。现有的强化学习（RL）微调方法虽然提高了推理能力，但未能解决视觉接地与后续推理过程之间的潜在不一致问题。", "innovation": "本文提出了Caption-Regularized Policy Optimization（CapPO），这是一种新的RL框架，旨在在策略优化过程中显式地确保感知一致性。CapPO结合了两种关键机制：基于描述的一致性正则化机制，以及KL加权的奖励估计方案，后者能够适应性地调整强化信号以增强感知一致路径，同时抑制虚假相关性。", "conclusion": "大量实验表明，CapPO在数学和一般推理基准测试中均表现出优越的性能，相较于基础模型Qwen2.5-VL-7B，在数学任务上准确率提升了6.0%，在一般推理任务上准确率提升了2.4%。消融试验进一步验证了每个组成部分的有效性，错误分析显示CapPO显著减少了感知相关的错误。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22642", "html_url": "https://arxiv.org/abs/2509.22642", "title": "WoW: 通过具身交互朝向通晓世界的模型", "title_en": "WoW: Towards a World omniscient World model Through Embodied Interaction", "authors": "Xiaowei Chi,Peidong Jia,Chun-Kai Fan,Xiaozhu Ju,Weishi Mi,Kevin Zhang,Zhiyuan Qin,Wanxin Tian,Kuangzhi Ge,Hao Li,Zezhong Qian,Anthony Chen,Qiang Zhou,Yueru Jia,Jiaming Liu,Yong Dai,Qingpo Wuwu,Chengyu Bai,Yu-Kai Wang,Ying Li,Lizhang Chen,Yong Bao,Zhiyuan Jiang,Jiacheng Zhu,Kai Tang,Ruichuan An,Yulin Luo,Qiuxuan Feng,Siyuan Zhou,Chi-min Chan,Chengkai Hou,Wei Xue,Sirui Han,Yike Guo,Shanghang Zhang,Jian Tang", "background": "人类通过积极与世界互动来培养对物理直觉的理解。然而，当前的视频模型，如Sora，依赖于被动观察，因此在物理因果关系上存在困难。我们的研究背景是在视频模型中引入真实世界具身交互的重要性，以发展物理直觉。", "innovation": "我们提出了一个名为WoW的140亿参数生成世界模型，基于200万机器人交互轨迹训练，并展示了SOPHIA框架，通过使用视觉语言模型评估并迭代优化语言指令来引导模型的物理现实性和收敛性。此外，还引入了一个逆动力学模型，将优化计划转化为可执行的机器人动作，形成了思维到行动的闭环。我们还创建了一个基准WoWBench，专注于视频中的物理一致性和因果推理，WoW在此基准中在人类和自主评估中均表现出色，特别是在物理因果关系、碰撞动力学和物体持久性方面。", "conclusion": "我们提供了一个系统化的证据，证明大规模的真实世界交互是培养AI物理直觉的基础。我们开源了模型、数据和基准，以推动这一领域的发展和进步。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22222", "html_url": "https://arxiv.org/abs/2509.22222", "title": "单图像中的基于刚性的3D高斯形变", "title_en": "Rigidity-Aware 3D Gaussian Deformation from a Single Image", "authors": "Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo", "background": "在计算机视觉和图形学领域，从单张图像重建物体形变仍然是一个重大挑战。现有方法通常依赖多视点视频来恢复形变，这限制了它们在受限场景中的适用性。", "innovation": "我们提出了DeformSplat，这是一种新颖的框架，它可以仅从单张图像引导3D高斯形变。该方法主要创新点包括两项技术贡献：Gaussian-to-Pixel Matching，它填补了3D高斯表示与2D像素观察之间的领域差距，从而实现从稀疏视觉线索进行稳健的形变引导；Rigid Part Segmentation，它包括初始化和精化步骤，该分割明确标识刚性区域，这对于在形变过程中保持几何连贯性至关重要。", "conclusion": "通过结合这两种技术，我们的方法可以从单张图像中重建一致的形变。广泛的实验表明，我们的方法在性能上显著优于现有方法，并且自然扩展到各种应用，如帧插值和交互式对象操作。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22356", "html_url": "https://arxiv.org/abs/2509.22356", "title": "RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation", "title_en": "RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation", "authors": "Enguang Liu,Siyuan Liang,Liming Lu,Xiyu Zeng,Xiaochun Cao,Aishan Liu,Shuchao Pang", "background": "当前，实体代理的安全性和可靠性依赖于准确和无偏见的视觉感知。然而，现有的基准测试主要强调在扰动下的泛化能力和鲁棒性，而视觉偏见的系统化量化却相对匮乏。这限制了对感知如何影响决策稳定性这一问题的深入了解。本文旨在解决这一问题.", "innovation": "提出RoboView-Bias，这是首个专门用于系统量化机器人操作中视觉偏见的基准测试，遵循分量隔离原则。利用结构化变体生成框架和感知公平性验证协议，创建了2,127个任务实例，以稳健地测量由个体视觉因素及其交互引起的偏差。通过该基准测试，系统地评估了三个代表性实体代理，并得到了三个关键发现。文中还展示了基于语义底层策略约减少54.5%视觉偏见的结果，强调系统分析视觉偏见是开发安全可靠的通用实体代理的前提.", "conclusion": "系统的视觉偏见分析是开发安全可靠通用实体代理的前提。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22507", "html_url": "https://arxiv.org/abs/2509.22507", "title": "适应性双模式蒸馏与激励方案在非平衡数据上扩展异质联邦学习", "title_en": "Adaptive Dual-Mode Distillation with Incentive Schemes for Scalable, Heterogeneous Federated Learning on Non-IID Data", "authors": "Zahid Iqbal", "background": "联邦学习作为一种无需牺牲用户隐私即可利用分布式数据的分散学习方法而崭露头角。然而，联邦学习面临一些关键挑战，例如各客户端可能无法训练相同的机器学习模型、统计异质性（不同数据分布）下的模型性能下降以及如何建立成本效益高的激励机制鼓励客户端参与联邦学习等挑战。", "innovation": "本文针对上述挑战，提出了三个模型：支持统计异质性的DL-SH方法，管理完全异质模型的DL-MH方法，以及激励导向的I-DL-MH方法。此外，通过多模型架构和不同数据分布（包括平衡和多种非平衡数据场景）下的全面实验，研究论证了这些方法在全局模型准确性和降低通信成本方面的显著成效，并表明这些方法相比现有最先进的方法和基准显著提高了准确性和降低了通信成本，分别达到153%和225%的提升。", "conclusion": "综上所述，本文的研究结果表明，通过适应性双模式蒸馏与激励机制，可以在非平衡数据上实现扩展异质联邦学习的有效性和效率，并显著提升了全局模型的准确性和降低了通信成本。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22562", "html_url": "https://arxiv.org/abs/2509.22562", "title": "激活函数设计在持续学习中维持可塑性", "title_en": "Activation Function Design Sustains Plasticity in Continual Learning", "authors": "Lute Lillo,Nick Cheney", "background": "在独立同分布的训练过程中，激活函数已经被广泛研究，并且通过调整模型规模和优化方法，它们之间的差异通常会减小。然而，在持续学习中，情况不同：模型不仅可能经历灾难性的遗忘，还会逐渐失去适应能力（称为可塑性损失），而细化这种失败模式中非线性的角色仍然缺乏探索。", "innovation": "我们展示了激活函数的选择是主要的、架构无关的手段，可以减轻可塑性损失。我们基于负分支形状和饱和行为的属性层级分析，引入了两种即插即用的非线性函数（平滑泄漏和随机平滑泄漏），并在这两种互补的环境中对其进行评估：（i）监督的类别增量基准，以及（ii）诱导受控分布和动力学变化的非平稳MuJoCo环境的强化学习中。我们还提供了一个简单的应力协议和诊断工具，将激活函数的形状与变化中的适应能力联系起来。", "conclusion": "结论是显而易见的：精心设计的激活函数提供了一种轻量级、跨领域的途径，在无需额外容量或任务特定调整的情况下维持持续学习中的可塑性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22240", "html_url": "https://arxiv.org/abs/2509.22240", "title": "COMPASS: 针对医学图像分割度量的稳健特征容限预测", "title_en": "COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics", "authors": "Matt Y. Cheung,Ashok Veeraraghavan,Guha Balakrishnan", "background": "在临床应用中，分割模型的实用价值通常基于由其导出的下游指标的准确性，例如器官大小，而不是分割掩码本身的像素级准确性。因此，对于决策而言，这些指标的不确定性量化至关重要。尽管容限预测（CP）是一个流行框架来提供这种原则上的不确定性保障，但将其直接应用于最终标量指标是低效的，因为它将复杂的非线性分割到度量的管道视为黑盒。因此，需要一种更为有效的框架直接在模型的表示空间中进行校准，以估计重要性权重并恢复目标覆盖度，特别是在协变量转移的情况下。", "innovation": "COMPASS框架通过利用其底层深度神经网络的归纳偏置，生成医学图像分割模型的高效、基于度量的容限区间。它通过在低维子空间中最大化扰动中间特征直接在模型的表示空间中进行校准，以估计目标度量的重要性权重，从而推广目标覆盖度，尤其是在协变量转移的情况下。此外，证明了COMPASS在交换性和嵌套性假设下能够实现有效的边际覆盖。相比于传统CP基线，COMPASS在四个医学图像分割任务中的面积估计中显著实现了更紧的区间。", "conclusion": "COMPASS为医学图像分割的实用、基于度量的不确定性量化铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22573", "html_url": "https://arxiv.org/abs/2509.22573", "title": "MINT-RVAE: 仅RGB相机数据中的人体姿态和情感信息用于人类-机器人交互的多线索意图预测", "title_en": "MINT-RVAE: Multi-Cues Intention Prediction of Human-Robot Interaction using Human Pose and Emotion Information from RGB-only Camera Data", "authors": "Farida Mohsen,Ali Safa", "background": "有效地检测人类与泛在机器人进行交互的意图对于有效的交互与合作至关重要。过去十年中，深度学习在这一领域得到了广泛应用，现有的大多数方法都依赖于多模态输入，如RGB与深度（RGB-D）结合，用于分类时间序列的感官数据窗口，将其分为交互性或非交互性。然而，这一方法的一个主要挑战是现实世界人类-机器人交互数据集中的类别不平衡，这可能会妨碍模型的训练和泛化能力。", "innovation": "本文提出了一种新颖的基于仅RGB的框架级精准预测人类交互意图的方法，以加快机器人响应速度并提高服务质量。为了解决类别不平衡的问题，提出了一种名为MINT-RVAE的合成序列生成方法，并引入了新的损失函数和训练策略，以增强对于新数据的泛化能力。这种方法在 AUROC 方面达到了最新技术水平，同时仅要求输入RGB数据并支持精准的帧起始预测。", "conclusion": "该方法在仅使用RGB输入的情况下，实现了精确的帧起始预测，并且达到了最新的性能（AUROC：0.95），超越了之前的成果（AUROC：0.90-0.912）。此外，新构建的具有帧层级别标签的数据集也公开发布，以支持未来的研究工作。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22601", "html_url": "https://arxiv.org/abs/2509.22601", "title": "掌握绳索，信任胜利：逐步探索的自模仿强化学习", "title_en": "Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning", "authors": "Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun", "background": "强化学习（RL）是让大型语言模型（LLMs）在长时间段、稀疏奖励任务中提升战术工具使用能力的主要范式，但面临着探索-利用trade-off的基本挑战。现有研究通过策略熵的视角激发探索，但由于多轮次分布的转变，这种机械的熵最大化容易导致RL训练不稳定。", "innovation": "本文提出了一种基于课程的自模仿学习（SIL）方法，称为SPEAR，用于培训具备代理性的LLMs。SPEAR通过逐步引导策略在不同阶段保持一个平衡范围内的熵来实现探索-利用的平衡。具体而言，该方法引入了一门课程来管理探索过程，利用内在奖励促进技能级别的探索，并通过自模仿促进动作级别的探索。此外，为了进一步稳定训练，该方法调整了重播缓冲区中经验的优势，引入了对一致性高的概率和优势中高协方差的令牌剪裁等正则化技术以制约过度自信。", "conclusion": "通过这种方法，模型能够在获得技能的同时逐渐掌握环境反馈的分布，实现探索-利用的稳健平衡。随着训练的进行，自模仿逐渐强化，利用重播经验中的成功模式进行更精细的动作级别探索，而不引起无限制的熵增长。这种方法提高了训练的稳定性，促进了解决方案的迭代优化。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22652", "html_url": "https://arxiv.org/abs/2509.22652", "title": "Pixel Motion Diffusion is What We Need for Robot Control", "title_en": "Pixel Motion Diffusion is What We Need for Robot Control", "authors": "E-Ro Nguyen,Yichi Zhang,Kanchana Ranasinghe,Xiang Li,Michael S. Ryoo", "background": "关于机器人控制，现有方法往往需要分离的高阶和低阶控制器，这可能导致复杂性和难以优化的问题。此外，将高层次的动作意图与低层次的机器人操作精确地结合起来是一个挑战，尤其是在模拟与现实世界的差距大且真实世界数据有限的情况下。", "innovation": "提出了一种统一的基于扩散的框架DAWN，通过结构化的像素运动表示，将高层次的动作意图与低层次的机器人操作连接起来。在DAWN中，高阶和低阶控制器都被建模为扩散过程，形成了一个完全可训练的端到端系统，具有可解释的中间运动抽象。DAWN在具有挑战性的CALVIN基准上实现了最先进的结果，证明了其在MetaWorld数据集上的多任务性能，并展示了尽管在模拟和现实世界之间存在大量领域差距且真实世界数据有限的情况下，仍然可以通过轻微微调实现可靠的真实世界转移，这表明基于扩散的运动抽象在机器人控制中的实践可行性。", "conclusion": "研究结果表明，将扩散建模与以运动为中心的表示相结合，为可扩展和鲁棒的机器人学习提供了一个强有力的基准。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22651", "html_url": "https://arxiv.org/abs/2509.22651", "title": "VoiceAssistant-Eval：全面评估语音助手的基准", "title_en": "VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing", "authors": "Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li", "background": "随着大型语言模型和多模态系统的功能不断增强，对以语音为主导的人工智能助手的兴趣也随之增长。然而，现有的基准测试尚不足以全面评估这些系统的各种能力。本文提出了一种名为VoiceAssistant-Eval的综合基准测试，旨在全面评估语音助手在听、说、看方面的能力。该基准包含10,497个任务范例，覆盖了13类任务，包括听觉任务（自然声音、音乐和对话）、口语任务（多轮对话、角色模拟）和视觉任务（高度异质的图像）。这为评估当前系统的能力提供了全面的视角，并揭示了目前存在的局限性。", "innovation": "本文提出了一种全新的综合基准测试工具，名为VoiceAssistant-Eval，旨在全面评估语音助手在听、说、看方面的能力。该基准涵盖了13类任务，包括听觉任务（自然声音、音乐和对话）、口语任务（多轮对话、角色模拟）和视觉任务（高度异质的图像）。此外，基准还对21个开源模型和GPT-4o-Audio进行了评估，结果表明，虽然大多数模型在口语任务上表现出色，但在音频理解方面存在不足，同时显示中型模型可以与大型模型匹敌。此基准还揭示了当前模型在多模态输入和角色模拟任务方面仍存在挑战，并在可靠性与安全性对齐方面存在差距。", "conclusion": "尽管在评估现有语音助手的能力方面取得了进展，但仍然存在显著的挑战，如处理多模态输入、角色模仿以及增强可靠性与安全性对齐。VoiceAssistant-Eval为评估下一代语音助手的研发提供了严格的框架。相关代码和数据将在该文提供的链接中发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22653", "html_url": "https://arxiv.org/abs/2509.22653", "title": "See, Point, Fly: 一种无需学习的VLM框架，用于通用的无人驾驶飞行导航", "title_en": "See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation", "authors": "Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu", "background": "本文介绍了See, Point, Fly (SPF)，这是一种不需要训练的空中视觉-语言导航（AVLN）框架，构建在视觉-语言模型（VLMs）之上。SPF能够基于任何形式的自由指令导航到任意目标，适用于任意类型的环境。与现有基于VLM的方法将动作预测视为文本生成任务不同，本文的关键见解是将AVLN中的动作预测视为2D空间定位任务。SPF利用VLM将模糊的语言指令拆解为对输入图像上的2D航点的迭代标注，并根据预测的移动距离将2D航点转化为3D位移向量作为无人机（UAV）的动作命令。此外，SPF还适应性地调整移动距离，以促进更高效的导航。SPF以闭环控制方式运行，使无人机能够追踪动态环境中的动态目标。在DRL仿真基准测试中，SPF打破了先前最先进方法的纪录，比之前的最佳方法高出63%。在广泛的现实世界评估中，SPF表现出色，大幅优于强基线。最后，研究表明SPF在不同的VLMs上表现出令人印象深刻的泛化能力。", "innovation": "该框架的关键创新在于将动作预测视为2D空间定位任务，并利用视觉-语言模型将模糊的语言指令转化为2D和3D的导航指令。此外，适应性地调整移动距离，以及闭环控制策略使得无人机能够追踪动态目标。SPF在DRL仿真测试中表现出色，打破之前的最好成绩。", "conclusion": "本文提出了See, Point, Fly (SPF)框架，在DRL仿真测试中打破了先前的最先进方法的记录，在广泛的现实世界评估中也表现出显著优势，这表明其在不同视觉-语言模型上的泛化能力强大。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2204.05798", "html_url": "https://arxiv.org/abs/2204.05798", "title": "基于多视图超复数学习的乳腺癌筛查", "title_en": "Multi-View Hypercomplex Learning for Breast Cancer Screening", "authors": "Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello", "background": "放射科医生通过综合分析所有四个视图来解读乳腺X光检查，因为视图间的关系对于准确诊断至关重要。最近的方法通过专用融合模块捕捉这些依赖关系，但这些模块往往受到视图主导效应、训练不稳定性及计算开销的阻碍。为解决这些问题，该论文介绍了一种创新的基于超复数神经网络（PHNNs）的多视图学习范式，称为多视图超复数学习，并提出了PHResNet及两种互补的四视图架构：PHYBOnet和PHYSEnet，优化不同的性能目标。大量实验表明，本方法在乳腺癌分类方面显著优于现有的多视图模型，并能跨影像模态和任务（如胸部X光的疾病分类和多模态脑肿瘤分割）进行泛化。", "innovation": "提出了一种基于超复数神经网络（PHNNs）的多视图学习范式，称为多视图超复数学习。该方法通过超复数代数，能够内在地捕捉视图内的关系和视图间的相互关系。同时提出了PHResNet及两种互补的四视图架构，以适应不同性能优化需求，实验结果显示该方法在乳腺癌筛查中表现优异，且具有较强的泛化能力。", "conclusion": "本研究通过引入多视图超复数学习方法和两种互补的四视图网络架构，显著提高了乳腺癌筛查的效率和准确性，同时也展示了该方法在其他影像任务上的泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.03039", "html_url": "https://arxiv.org/abs/2410.03039", "title": "利用模型指导提取个性化扩散模型的训练数据", "title_en": "Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models", "authors": "Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu", "background": "扩散模型（DMs）已经成为强大的图像生成工具，特别是在少量样本的微调中。通过在预训练模型上进行微调，可以捕捉到特定的风格或对象。这些微调的检查点经常被上传到在线社区，如Civitai和HuggingFace，但这也带来了数据泄露和版权侵权的风险。因此，研究人员开始探索从这些发布的微调模型中提取训练数据的方法，以评估潜在的风险和侵权行为。", "innovation": "本文提出了一种名为FineXtract的新框架，用于从在线共享的个性化扩散模型中提取微调数据。该方法将微调过程视为模型学习分布逐渐转移的过程，从原始预训练模型到微调数据。通过对比微调前后的模型，指导生成过程偏向微调数据的高概率区域，并使用聚类算法提取最有可能的图像数据。实验表明，该方法在大多数情况下能够有效提取约20%的微调数据，验证了其有效性。", "conclusion": "研究表明，通过利用模型指导，可以从共享的个性化扩散模型中成功提取出训练数据，从而揭示数据泄露风险及潜在的版权侵权行为。所提出的方法已在多种微调数据集中得到验证，为研究者和实践者提供了新的工具和方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.10014", "html_url": "https://arxiv.org/abs/2405.10014", "title": "超分辨率中的多尺度扩散域细化", "title_en": "Frequency-Domain Refinement with Multiscale Diffusion for Super Resolution", "authors": "Xingjian Wang,Li Chai,Jiming Chen", "background": "单图像超分辨率（SISR）系统的性能很大程度上取决于如何生成和补充低分辨率图像中的高频细节。近年来，基于扩散的方法（如DDPM模型）显示出在生成超分辨率任务中的高质量细节的巨大潜力。这些方法倾向于通过仅利用高分辨率 ground truth 作为所有采样时间步的目标，直接预测宽带的高频信息。然而，由于这种方式，它们会遇到幻觉问题，生成不符合实际的伪影。为了克服这一问题并实现更高质量的超分辨率，我们提出了一种新颖的多尺度扩散域引导模型（FDDiff），该模型将高频信息补全过程分解为更细化的步骤。具体来说，基于小波包的多尺度频率降解金字塔被开发出来，以提供具有逐渐增加带宽的多尺度中间目标。基于这些目标，FDDiff 引导逆向扩散过程在时间步进中逐渐补充缺失的高频细节。此外，还设计了一种多尺度频率细化网络，在单一网络中预测不同尺度所需的高频成分。在流行的基准上进行了全面评估，表明FDDiff 比以前的生成方法在超分辨率结果的保真度上有更好的表现。", "innovation": "提出了一种新颖的多尺度扩散域引导模型（FDDiff），该模型通过分解高频信息补全过程为更细化的步骤，并利用基于小波包的多尺度频率降解金字塔提供多尺度的中间目标，从而引导逆向扩散过程逐时间步进行高频细节的补充，同时设计了一种多尺度频率细化网络来预测不同尺度的高频成分。这些方法有效地解决了生成幻觉伪影的问题，并提高了超分辨率结果的保真度。", "conclusion": "在流行基准上的综合评估表明，FDDiff 超出了先前生成方法的表现，并提供了更高的超分辨率结果保真度。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.20761", "html_url": "https://arxiv.org/abs/2412.20761", "title": "从遗忘图像中学到的难忘教训：类内可记忆性在计算机视觉中很重要", "title_en": "Unforgettable Lessons from Forgettable Images: Intra-Class Memorability Matters in Computer Vision", "authors": "Jie Jing,Yongjian Huang,Serena J.-W. Wang,Shuangpeng Han,Lucia Schiatti,Yen-Ling Kuo,Qing Lin,Mengmi Zhang", "background": "本文介绍了类内可记忆性概念，即同一类别中的某些图像比其他图像更具有吸引力，尽管它们共享类别特征。背景研究表明，认知识别和记忆不同类别和同一类别内的图像存在差异。", "innovation": "1. 设计并进行了人类行为实验，通过要求参与者识别当前图像是否与几步骤前的图像匹配来量化可记忆性。\n2. 提出了新颖的类内可记忆性评分（ICMscore），将其引入计算中的时间间隔也考虑在内。\n3. 构建了包含跨十个物种类别超过5,000张图像的类内可记忆性数据集（ICMD），并从2,000参与者的反应中获得了ICM评分。\n4. 将ICMD数据集用于神经网络模型训练，探索其在记忆预测、图像识别、连续学习和记忆控制图片编辑等领域中的应用价值，发现ICMscore影响AI在图像识别和持续学习任务中的性能。", "conclusion": "我们的贡献在于通过深入研究最难忘和最难忘图像背后的细微视觉特征，揭示了类内可记忆性的重要性。这为计算机视觉中的实际应用奠定了基础，数据、代码和模型将公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.03858", "html_url": "https://arxiv.org/abs/2410.03858", "title": "Pose Prior Learner: 无监督的姿势类别先验学习", "title_en": "Pose Prior Learner: Unsupervised Categorical Prior Learning for Pose Estimation", "authors": "Ziyu Wang,Shuangpeng Han,Mengmi Zhang", "background": "先验代表了系统的一种信念或假设，有助于推断和决策。在姿势估计领域，模型需要从图像中学习一种通用的姿势先验，特别是在无监督的情况下。现有的方法在姿势估计中具有有效性，但获取这种先验通常是困难且代价高昂的，需要大量的标注数据和增强。因此，本研究提出了一个新的挑战，即在不依赖额外标注的情况下学习通用的姿势先验，特别是针对任何物体类别的自监督学习方法。", "innovation": "提出了一种新颖的方法——姿势先验学习器（PPL），以无监督的方式学习任何物体类别的通用姿势先验。PPL 使用层次化记忆存储原型姿势的组成部件，并从中提取通用姿势先验。通过模板变换和图像重建，先验提高了姿势估计的准确性，且无需额外的人工注释或干预，超越了现有的竞争基线模型。特别地，实验结果表明，PPL 能够利用学习到的原型姿势在遮挡图像上的姿势估计中展示出有效性。通过迭代推理，PPL 利用先验对估计姿势进行细化，使其回归到记忆中存储的任何原型姿势。", "conclusion": "本研究提出的PPL方法在人类和动物的姿势估计数据集上取得了优越性能，实现了无监督的姿势类别先验学习。通过共享代码、模型和数据，研究团队希望进一步改进和发展这项技术。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18671", "html_url": "https://arxiv.org/abs/2411.18671", "title": "TAPTRv3：长视频中任意点的稳健跟踪促进空间和时间上下文", "title_en": "TAPTRv3: Spatial and Temporal Context Foster Robust Tracking of Any Point in Long Video", "authors": "Jinyuan Qu,Hongyang Li,Shilong Liu,Tianhe Ren,Zhaoyang Zeng,Lei Zhang", "background": "TAPTRv2 是一种简单而有效的 DETR 类点跟踪框架，在常规视频中表现良好，但在长视频中容易出错。TAPTRv2 的问题在于无法有效地从长视频中查询高质量的特征，这问题是因为目标跟踪点随时间逐渐变化。为此，TAPTRv3 改进了对长视频中点特性的查询质量，并通过引入时空上下文增强了中注重的点特征获取。TAPTRv3 使用了 Context-aware Cross-Attention (CCA) 和 Visibility-aware Long-Temporal Attention (VLTA) 来分别处理空间和时间维度上的查询问题，从而提高了在长视频中的跟踪性能。", "innovation": "1. 提出了 Context-aware Cross-Attention (CCA)，该机制能够将空间上下文引入注意力机制，从而改善从图像中获取特征的质量。\n2. 引入了 Visibility-aware Long-Temporal Attention (VLTA)，该机制在处理时间注意力时考虑了帧的可见性，有效解决了由于类似 RNN 的长期建模而引起的特征漂移问题。\n3. TAPTRv3 在大多数具有挑战性的数据集上超过了 TAPTRv2，并且即使与在大规模额外数据上训练的方法相比，TAPTRv3 仍然表现出优越性。", "conclusion": "TAPTRv3 在长视频的点跟踪方面取得了显著的性能提升，通过引入 CCA 和 VLTA 机制，增强了时空特征查询，从而提高了目标特征的质量和稳健性。TAPTRv3 实现了显著的性能改进，在多个数据集上均得到了领先的跟踪结果。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03255", "html_url": "https://arxiv.org/abs/2412.03255", "title": "DynamicControl: 自适应条件选择以提高文本到图像生成", "title_en": "DynamicControl: Adaptive Condition Selection for Improved Text-to-Image Generation", "authors": "Qingdong He,Jinlong Peng,Pengcheng Xu,Boyuan Jiang,Xiaobin Hu,Donghao Luo,Yong Liu,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang", "background": "当前的控制网络类似模型通过探索各种控制信号以增强文本到图像扩散模型的可控性。然而，现有的方法在处理多种条件时效率不高，或是使用固定的条件数量，这无法充分应对多种条件及其潜在冲突的复杂性。因此，需要创新的方法来有效管理多种条件，以实现更可靠和详细的图像合成。", "innovation": "我们提出了一种名为DynamicControl的新框架，支持多样控制信号的动态组合，允许自适应选择不同的条件数量和类型。该方法首先使用双循环控制器，结合预训练的条件生成模型和判别模型来生成初始的真实评分排序，对所有输入条件进行排序。然后，我们引入了一个多模态大语言模型（MLLM）构建高效的条件评估器，该评估器基于双循环控制器的评分排序优化条件的排序。最后，DynamicControl通过双循环控制器的评分排序选择的条件被输入到一个并行多控制适配器中，该适配器从中学习动态视觉条件的特征图，并将它们集成起来调节ControlNet，从而提高生成图像的可控性。这种方法通过与现有方法进行定量和定性的比较，显示了在多种条件控制下，DynamicControl在可控性、生成质量和合成能力方面的优越性。", "conclusion": "DynamicControl通过引入双循环控制器和多模态大语言模型构建的高效条件评估器，有效选择和排序多种条件，增强了文本到图像生成的可靠性和细节，是目前该领域的创新解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.21582", "html_url": "https://arxiv.org/abs/2410.21582", "title": "大规模预训练数据集在微调后并不总是保证稳健性", "title_en": "Large Pre-Training Datasets Don't Always Guarantee Robustness after Fine-Tuning", "authors": "Jaedong Hwang,Brian Cheung,Zhang-Wei Hong,Akhilan Boopathy,Pulkit Agrawal,Ila Fiete", "background": "大规模预训练模型通常通过微调来学习新特化的任务，目标是在保持模型泛化性能的同时获得新的技能。所有模型的一个重要目标是鲁棒性：在处理未见过的任务（OOD任务）时表现良好。研究发现，在大规模数据集上进行预训练的模型在微调过程中表现出严重灾难性遗忘，以及OOD泛化能力退化。为了系统地评估微调模型的鲁棒性保留情况，提出了一种鲁棒性继承基准（ImageNet-RIB），该基准适用于任何预训练模型，包括一系列相关但独立的OOD任务，细调其中一个任务后对其他任务进行测试。研究表明，尽管连续学习方法能够有所帮助，但微调会普遍降低预训练模型的鲁棒性。研究还发现，预训练于最大和最多样化数据集的模型（例如LAION-2B）在小数据集上进行微调后，鲁棒性损失更大并且绝对鲁棒性较低，这相比于在较小数据集上预训练的模型更为显著。这些发现表明，对于专业知识任务而言，起点最强的预训练模型未必是最好的方法。", "innovation": "提出了一个名为ImageNet-RIB的鲁棒性继承基准，用于系统评估微调模型的鲁棒性保留情况，发现灾难性遗忘和OOD泛化能力退化现象，并且largest和最多样化数据集的预训练模型在微调后的鲁棒性损失更大且绝对鲁棒性更低的现象。对预训练和微调模型在泛化能力和鲁棒性方面进行了定量评估。", "conclusion": "微调普遍降低了预训练模型的鲁棒性，即使使用庞大的预训练数据集也不能保证微调后的模型具有鲁棒性。在专业知识任务上，预训练于大型和多样化数据集的模型在小数据集上的鲁棒性下降更为明显。因此，在选择预训练模型时，仅依靠预训练数据集的大小和多样性不一定保证最终模型的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.13674", "html_url": "https://arxiv.org/abs/2410.13674", "title": "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion", "title_en": "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion", "authors": "Yijun Liang,Shweta Bhardwaj,Tianyi Zhou", "background": "在实际训练深度神经网络时，低质或稀缺的数据提出了重大挑战。传统的数据增广只能提供有限的新数据，而扩散模型通过文本引导提示生成高质量和多样化的合成数据，提供了一个新的自我进化的AI途径。然而，文本引导无法控制合成图像与原始图像的相似性，导致外域数据对模型性能不利。为了克服这一局限性，研究了图像引导，以实现在合成和真实图像之间的插值。通过调节图像唤起水平，生成的图像既接近训练数据又难以学习，而较低的唤醒水平使合成图像更容易学习但会增加与原始数据的分布差异。全维度的数据生成使我们能够构建一种新的‘扩散课程’(DisCL)，该课程调整图像合成的图像引导水平以适应每一训练阶段：它识别并专注于模型难以处理的样本，并评估最佳的合成图像指引水平以提高难样本的学习效果。在两个具有挑战性的任务（长尾分类和低质量数据学习）上应用DisCL，取得了显著效果。在iWildCam数据集上，应用DisCL后OOD和ID的宏精度分别提高了2.7%和2.1%；在ImageNet-LT上，DisCL将基模型的尾类准确性从4.4%提高到23.64%，并使得所有类别的准确性提高了4.02%。", "innovation": "该研究提出了图像指导的扩散模型，即“扩散课程”(DisCL)，通过调节图像合成的指导水平，实现在合成和真实图像之间的插值。该方法能够专注于模型难以处理的样本，并调整最有效的合成图像指导水平以改善难样本的学习效果。这一方法在长尾分类和低质量数据学习等具有挑战性的任务上取得了显著的效果，提升了模型的性能。", "conclusion": "通过应用‘扩散课程’(DisCL)，能够在训练过程中根据模型的难处理样本和理想指导水平动态调整图像生成，进而显著提升模型的泛化能力和数据学习效果。在多个数据集和任务上展示了该方法的有效性，特别是在长尾分类和使用低质量数据学习上，取得了显著的性能提升。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02588", "html_url": "https://arxiv.org/abs/2502.02588", "title": "用平滑多偏好优化对扩散模型进行对齐", "title_en": "Calibrated Multi-Preference Optimization for Aligning Diffusion Models", "authors": "Kyungmin Lee,Xiaohang Li,Qifei Wang,Junfeng He,Junjie Ke,Ming-Hsuan Yang,Irfan Essa,Jinwoo Shin,Feng Yang,Yinxiao Li", "background": "对于文本到图像（T2I）的扩散模型，通过偏好优化与人工标注数据对齐是有价值的，但手工数据采集的成本高限制了其扩展性。当前的方法尽管通过奖励模型提供了一种替代方案，但它们仅关注成对的偏好分布，未能充分利用丰富信息，也难以推广到多偏好场景，并且处理奖励之间不一致的问题也比较困难。", "innovation": "我们提出了平滑多偏好优化（CaPO），这是一种新颖的方法，可以在不使用人工标注数据的情况下，通过将多个奖励模型的偏好综合起来对T2I扩散模型进行对齐。核心方法包括使用奖励校准策略，通过计算生成样本的获胜率来近似一般偏好；提出了一种基于前沿的成对选择方法，该方法有效地管理了多偏好分布；并通过回归损失进行微调，以匹配选定成对的校准奖励之间的差异。", "conclusion": "实验结果显示，CaPO在T2I基准测试（如GenEval和T2I-Compbench）中不仅在单偏好设置，而且在多偏好设置下均优于先前的方法，如直接偏好优化（DPO）等。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.05271", "html_url": "https://arxiv.org/abs/2412.05271", "title": "使用模型、数据和测试时扩展开源多模态模型的性能边界", "title_en": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "authors": "Zhe Chen,Weiyun Wang,Yue Cao,Yangzhou Liu,Zhangwei Gao,Erfei Cui,Jinguo Zhu,Shenglong Ye,Hao Tian,Zhaoyang Liu,Lixin Gu,Xuehui Wang,Qingyun Li,Yiming Ren,Zixuan Chen,Jiapeng Luo,Jiahao Wang,Tan Jiang,Bo Wang,Conghui He,Botian Shi,Xingcheng Zhang,Han Lv,Yi Wang,Wenqi Shao,Pei Chu,Zhongying Tu,Tong He,Zhiyong Wu,Huipeng Deng,Jiaye Ge,Kai Chen,Kaipeng Zhang,Limin Wang,Min Dou,Lewei Lu,Xizhou Zhu,Tong Lu,Dahua Lin,Yu Qiao,Jifeng Dai,Wenhai Wang", "background": "该研究基于InternVL 2.0系列，引入了InternVL 2.5这个先进的多模态大型语言模型（MLLM），同时保持其核心模型架构不变，但在训练和测试策略以及数据质量方面引入了重要改进。作者利用广泛的应用基准深入探讨了模型放大与性能之间的关系，探索了视觉编码器、语言模型、数据集大小和测试时配置的性能趋势。通过大量评估，包括跨学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉对接、多语言能力以及纯语言处理等领域，InternVL 2.5取得了有竞争力的性能表现，达到了与GPT-4o和Claude-3.5-Sonnet等领先商业模型持平的水平。值得注意的是，在MMMU基准测试中，我们的模型首次实现超过70%，并通过链式思考（CoT）推理方式提高了3.7个百分点，显示出在测试时扩展的强内存潜力。", "innovation": "在保持核心模型架构不变的情况下，InternVL 2.5在训练和测试策略以及数据质量方面进行了显著改进，更重要的是，通过大量的广泛基准测试，展示了其在多个领域的竞争力并首次在MMMU基准测试中超过70%。此外，模型展示了在测试时间扩展上的强潜力，并首次通过CoT推理方式实现了这一成就。", "conclusion": "我们希望通过此模型为开源社区树立新的标杆，促进和提升多模态AI系统的开发和应用标准。研究希望贡献的一个亮点是InternVL 2.5展示了更大的测试时间可扩展性，并在MMMU基准测试中实现了显著提升，首次打破了70%的门槛。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.07385", "html_url": "https://arxiv.org/abs/2412.07385", "title": "LOGen：点扩散方法向 LiDAR 对象生成迈出的一步", "title_en": "LOGen: Toward Lidar Object Generation by Point Diffusion", "authors": "Ellington Kirby,Mickael Chen,Renaud Marlet,Nermin Samet", "background": "LiDAR 扫描生成是一个快速增长的研究领域，有着广泛的应用，特别是对于自动驾驶。尽管如此，与图像和 3D 对象生成的快速发展相比，扫描生成依然是一个挑战。该研究聚焦于 LiDAR 对象生成任务，即生成从 LiDAR 扫描角度看起来的 3D 对象，强调了 LiDAR 扫描生成中场景中的关键方面——物体。该研究受益于 3D 对象生成方法的最新进展，介绍了基于扩散机制的模型来生成数据集对象的 LiDAR 点云，包括强度，并通过条件信息对生成过程进行广泛的控制。实验表明，新的三维度量标准对我们的生成结果进行了评估。", "innovation": "该研究引入了基于扩散机制的模型来生成带有强度信息的 LiDAR 点云，并通过条件信息进行广泛的生成控制。该方法利用了在 3D 对象生成方法方面的最新进展，具有提高 LiDAR 对象生成质量的潜力。", "conclusion": "该研究在 nuScenes 和 KITTI-360 数据集上的实验结果表明，新的三维度量标准可以用于评估 LiDAR 对象的生成质量。相关代码已公开。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.05827", "html_url": "https://arxiv.org/abs/2412.05827", "title": "Self-Guidance: 自我引导：提升扩散和流生成技术的效果", "title_en": "Self-Guidance: Boosting Flow and Diffusion Generation on Their Own", "authors": "Tiancheng Li,Weijian Luo,Zhiyang Chen,Liyuan Ma,Guo-Jun Qi", "background": "现有的文本到图像和文本到视频生成模型指导策略要么需要特定训练，要么依赖模型强诱导偏置，这限制了模型的能力和应用范围。观察到噪声级别从高到低的密度显著下降可以检测到不良样本，本文提出了一种新的自我引导策略（SG），通过在不同噪声水平下依赖原始扩散或流模型的采样得分函数来抑制低质量样本的生成，实现了生成高质量图像的效果。", "innovation": "提出的自我引导（SG）方法主要特点在于它仅依赖于原始扩散或流模型在不同噪声水平下的采样得分函数，无需进行复杂的特定指导训练，因此具有很高的灵活性和便捷性。此外，还提出了一种高效的SG-prev变体，通过重用上一步扩散的输出来避免额外的前进通过过程。这些方法在多个生成模型和不同架构上进行了广泛实验，并优于现有的算法结果，特别是在FID和人类偏好评分方面。此外，自我引导和自我引导预版本方法在生成生理正确的人体结构方面也显示出积极作用。", "conclusion": "实验结果证明，提出的自我引导方法使得扩散和流模型在不重新训练的情况下生成高质量图像成为可能，尤其是在生成人类体态结构方面表现优秀，且在多个评价指标上超过了现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07531", "html_url": "https://arxiv.org/abs/2502.07531", "title": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation", "title_en": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation", "authors": "Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu", "background": "现有的图像到视频生成方法通常单独处理相机运动、物体运动和照明方向这三种控制信号，主要是由于高质量联合标注数据的稀缺以及不同模态之间不匹配的控制空间。", "innovation": "VidCRAFT3是一种统一和灵活的图像到视频生成框架，支持分析中相机运动、物体运动和照明方向的独立和联合控制。除了传统的图像到视频生成方法，它还引入了三个核心组件：Image2Cloud、ObjMotionNet和Spatial Triple-Attention Transformer。VidCRAFT3通过构建VideoLightingDirection（VLD）数据集和采用分阶段训练策略，解决了联合标注数据稀缺的问题，实现了鲁棒的学习效果。", "conclusion": "在大量实验中，VidCRAFT3在控制精度和视觉完整性方面优于现有方法，代码和数据将在未来公开。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.12976", "html_url": "https://arxiv.org/abs/2501.12976", "title": "LiT: 探索一个简单的线性扩散变换器在图像生成中的应用", "title_en": "LiT: Delving into a Simple Linear Diffusion Transformer for Image Generation", "authors": "Jiahao Wang,Ning Kang,Lewei Yao,Mengzhao Chen,Chengyue Wu,Songyang Zhang,Shuchen Xue,Yong Liu,Taiqiang Wu,Xihui Liu,Kaipeng Zhang,Shifeng Zhang,Wenqi Shao,Zhenguo Li,Ping Luo", "background": "本文探讨将预训练的扩散变换器（DiT）转化为线性DiT，原因在于其结构简单、并行性和生成图像的效率。", "innovation": "本文的核心贡献包括5个实用指南：将深度卷积应用于简单线性注意力足够用于图像生成；减少线性注意力的头部数量可以提升性能且不增加延迟；从完全收敛的预训练DiT继承权重；加载除线性注意力相关的所有参数；以及混合知识蒸馏：使用预训练的教师DiT帮助学生线性DiT的训练，监督预测噪声和反向扩散过程中的方差。", "conclusion": "遵循这些指南提出的线性DiT（LiT）是DiT的简单线性注意力的高效替代基准。在类条件的256×256和512×512 ImageNet生成中，LiT仅需DiT训练步骤的20%和33%即可快速适应，同时实现相当的性能。此外，同样的指南在文本到图像生成中也适用：LiT可以迅速从PixArt-$\boldsymbol{Σ}$转换为生成高质量图像，保持类似GenEval分数。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15216", "html_url": "https://arxiv.org/abs/2412.15216", "title": "基于编辑反转约束的无监督指令驱动图像编辑", "title_en": "UIP2P: Unsupervised Instruction-based Image Editing via Edit Reversibility Constraint", "authors": "Enis Simsar,Alessio Tonioni,Yongqin Xian,Thomas Hofmann,Federico Tombari", "background": "现有的图像编辑方法依赖于监督学习，并使用输入图像、真实编辑后的图像和编辑指令的三元组进行训练。这些三元组通常通过现有的编辑方法生成，这可能会引入偏差，并且需要大量的人工注释，增加了成本，并且限制了泛化能力。前沿研究正在探索如何减少这种依赖，以寻求改进的图像编辑方法。", "innovation": "作者提出了一种无监督的指令驱动图像编辑方法，通过引入一种称为编辑反转约束（Edit Reversibility Constraint，ERC）的新机制，可以在不使用真实编辑后图像的情况下进行训练。ERC机制要求在一次训练步骤中同时进行正向和反向编辑，并确保图像、文本和注意力空间的对齐，从而在使用真实图像-描述对或图像-描述-指令三元组的数据集上进行训练。这种方法在广泛的编辑任务上表现出更高的保真度和精度。", "conclusion": "本研究通过消除对现有三元组数据集的依赖，减少当前方法中相关的偏差，并提出ERC，显著推动了基于指令的图像编辑方法的发展和扩大应用规模。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.14108", "html_url": "https://arxiv.org/abs/2504.14108", "title": "DanceText: 一种无需训练的分层框架，用于图像中的可控多语言文本变换", "title_en": "DanceText: A Training-Free Layered Framework for Controllable Multilingual Text Transformation in Images", "authors": "Zhenyu Yu,Mohd Yamani Idna Idris,Hua Wang,Pei Wang,Rizwan Qureshi,Shaina Raza,Aman Chadha,Yong Xiang,Zhixiang Chen", "background": "扩散为基础的生成模型在文本引导图像合成方面显示出了前景，但仍缺乏可控性，并且在非平凡的操纵，例如旋转、平移、缩放和扭曲中难以保持布局一致性。", "innovation": "DanceText 引入了一种分层编辑策略，将文本从背景中分离，允许以模块化和可控的方式进行几何变换。此外，提出了一个深度感知模块，用于在变换文本与重构背景之间对齐外观和透视，增强了真实的感和空间一致性。特别地，DanceText 采用了一种完全无需训练的设计，通过集成预训练模块，可以灵活部署而无需特定任务的微调。", "conclusion": "在 AnyWord-3M 标准上的大量实验表明，我们的方法在视觉质量方面表现优异，特别是在大规模和复杂变换场景中。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07392", "html_url": "https://arxiv.org/abs/2503.07392", "title": "SPEED: 可扩展、精确且高效的扩散模型概念删除方法", "title_en": "SPEED: Scalable, Precise, and Efficient Concept Erasure for Diffusion Models", "authors": "Ouxiang Li,Yuan Wang,Xinting Hu,Houcheng Jiang,Tao Liang,Yanbin Hao,Guojun Ma,Fuli Feng", "background": "由于版权侵权、冒犯性内容和隐私侵犯的担忧不断增加，大规模文本到图像（T2I）扩散模型中擦除概念变得越来越重要。在可扩展的应用场景中，基于微调的方法往往耗时且难以精准擦除多个目标概念；而实时编辑的方法则因为优化目标冲突，可能会降低非目标概念的生成质量。为解决这个问题，我们提出了SPEED，这是一种高效的模型参数直接编辑方法，直接修改模型参数以直接擦除概念。SPEED通过寻找一个不会影响非目标概念的参数更新空间来实现可扩展和精准的擦除。", "innovation": "SPEED引入了三种互补策略：基于影响的先验筛选（IPF）、定向先验扩充（DPA）和不变等式约束（IEC）。IPF用于选择性地保留受影响最大的非目标概念，DPA则通过引入语义一致的变异来丰富筛选保留集，IEC则在T2I生成过程中保持关键不变量。广泛的评估表明，SPEED能够在非目标概念保持方面持续优于现有方法，同时实现高效且高质量的概念删除，仅需5秒即可擦除100个概念。", "conclusion": "我们在多种概念删除任务中的实验结果表明，SPEED在保持非目标概念的同时，实现了高效的高质量概念删除，能够在5秒内删除100个概念。我们的代码和模型可在此链接获取：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14182", "html_url": "https://arxiv.org/abs/2501.14182", "title": "单权重模型编辑用于后验消除虚假相关性", "title_en": "Single-weight Model Editing for Post-hoc Spurious Correlation Neutralization", "authors": "Shahin Hakemi,Naveed Akhtar,Ghulam Mubashar Hassan,Ajmal Mian", "background": "神经网络在训练过程中倾向于利用最简单的特征来急于最小化训练损失。某些特征可能与目标标签 spuriously（非本质地）相关，导致模型生成错误预测。尽管已有多种方法试图解决此问题，但这些方法通常需要额外的训练成本，并且存在一定的局限性，因为模型行为出问题往往是在应用之后才发现的。此外，虚假的相关性通常被视为主观的概念，因此，需要明确的是特征的虚假程度，以及如何为可靠的预测控制模型对这些特征的关注。", "innovation": "本文提出了一种方法，允许在不显著牺牲其他类性能的前提下，通过单权重修改来后验消除虚假特征的影响。这种技术将虚假特征定义为原始类的假象子类，并通过类移除方案来消除这些假象子类。我们的方法在大量实验中证明，通过这种方式，可以实现与顶尖方法相当甚至更好的性能。", "conclusion": "通过编辑单一权重，本文的方法在后验消除虚假特征的影响方面表现出色，实现了与现有最先进方法相当或更优的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03113", "html_url": "https://arxiv.org/abs/2505.03113", "title": "基于在线轻量化视觉变换器的图像识别：综述", "title_en": "Image Recognition with Online Lightweight Vision Transformer: A Survey", "authors": "Zherui Zhang,Rongtao Xu,Jie Zhou,Changwei Wang,Xingtian Pei,Wenhao Xu,Jiguang Zhang,Li Guo,Longxiang Gao,Wenbo Xu,Shibiao Xu", "background": "Transformer架构已在自然语言处理领域取得显著成果，激发了将其应用于计算机视觉任务的兴趣。视觉Transformer能够捕获长距离依赖关系并支持并行处理，但由于缺乏诱导偏置和效率优势，面临巨大的计算和内存挑战，限制了其实用性。", "innovation": "该论文综述了针对图像识别任务生成轻量级视觉Transformer的各种在线策略，重点关注高效组件设计、动态网络和知识蒸馏三个方面，并通过ImageNet-1K基准评估相关探索，分析其在精度、参数、吞吐量等方面的权衡及优缺点。", "conclusion": "本文提出了轻量化视觉Transformer的未来研究方向和潜在挑战，旨在激发进一步探索并为该领域提供实用指导。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15371", "html_url": "https://arxiv.org/abs/2504.15371", "title": "Event2Vec: 直接在向量空间中处理类脑事件", "title_en": "Event2Vec: Processing Neuromorphic Events directly by Representations in Vector Space", "authors": "Wei Fang,Priyadarshini Panda", "background": "神经形态事件摄像头在时间分辨率、功耗和动态范围方面优于传统摄像头，但其异步和稀疏数据格式给传统的深度学习方法带来了挑战。当前解决这种不兼容性的方法往往牺牲了时间分辨率、需要大量的预处理，并未能充分利用GPU加速。", "innovation": "我们借鉴了词向量模型，将事件类比于单词，提出了一种新颖的表示方法——event2vec，允许神经网络直接处理事件。这种方法完全兼容Transformer架构的并行处理和自我监督学习能力。实验结果表明，event2vec参数效率高、通量高，并且即使事件数量极低也能实现高精度。", "conclusion": "event2vec提出了一个神经网络处理事件流的新范式，类似于自然语言。这为事件摄像头与大型语言模型和多模态模型的原生集成铺平了道路。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.19223", "html_url": "https://arxiv.org/abs/2504.19223", "title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "title_en": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "authors": "Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic", "background": "谱成像技术在医学和城市场景理解等多个领域展现出巨大潜力，并且已经在遥感中确立了关键地位。然而，各谱成像相机在通道维度和捕捉波长上的差异性限制了AI驱动方法的发展，导致了特定相机模型的出现，这些模型缺乏泛化能力和跨相机应用性。", "innovation": "提出了一个名为CARL的模型，它可以在RGB、多光谱和高光谱成像模态下实现相机无感知的表示学习。通过引入一种新颖的自注意力-交叉注意力机制的光谱编码器，CARL能够将任何通道维度的谱成像转换为相机无感知的表示。此外，通过一种基于特征的自我监督策略进行光谱和空间预训练。", "conclusion": "大规模实验在医学成像、自动驾驶和卫星成像领域证明了该模型对光谱异构性的鲁棒性，无论是在模拟还是现实的跨相机光谱差异数据集上，表现优于现有方法。该模型的可扩展性和灵活性使其成为未来光谱基础模型的核心组件。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21767", "html_url": "https://arxiv.org/abs/2503.21767", "title": "语义一致的语言高斯点播对于点级开放词汇查询", "title_en": "Semantic Consistent Language Gaussian Splatting for Point-Level Open-vocabulary Querying", "authors": "Hairong Yin,Huangying Zhan,Yi Xu,Raymond A. Yeh", "background": "开放词汇的三维场景理解对于机器人应用至关重要，如自然语言驱动的操作、人机交互和自主导航。现有基于3D高斯点播的查询方法常常难以处理不一致的2D掩码监督，并缺乏稳健的3D点级检索机制。", "innovation": "（i）提出了一种新颖的点级查询框架，通过在分割掩码上进行跟踪来建立语义一致的地面真相，从而提炼语言高斯模型；（ii）引入了一种基于GT的查询方法，该方法首先检索提炼的地面真相，然后使用地面真相查询个体高斯。", "conclusion": "在三个基准数据集上进行的深入实验表明，所提出的方法优于最先进的性能。我们的方法在LERF、3D-OVS和Replica数据集上分别实现了mIoU改进+4.14、+20.42和+1.7。这些结果验证了我们架构在真实世界机器人系统中开放词汇理解方面的前景。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16456", "html_url": "https://arxiv.org/abs/2505.16456", "title": "PhyMAGIC：基于信心引导的大规模预训练语言模型的物理感知生成推理", "title_en": "PhyMAGIC: Physical Motion-Aware Generative Inference with Confidence-guided LLM", "authors": "Siwei Meng,Yawei Luo,Ping Liu", "background": "近年来，3D内容生成的发展增加了对既具视觉真实性又具物理一致性动态模型的需求。然而，最先进的视频扩散模型往往会产生诸如违背动量和物体穿插等不可靠的结果。现有的物理感知方法通常依赖于特定任务的微调或监督数据，这对它们的可扩展性和适用性构成了限制。", "innovation": "PhyMAGIC提出了一种无需微调的框架，能够从单张图片生成物理上一致的动态。该框架结合了预训练的图像到视频扩散模型、基于LLM的信心引导推理以及可微物理模拟器，生成可用于下游物理模拟的3D资产，无需微调或人工监督，并通过LLM生成的信心分数迭代细化动作提示，并利用模拟反馈进行引导。", "conclusion": "全面的实验表明，PhyMAGIC在物理属性推断和动作文本对齐方面优于最先进的视频生成器和物理感知基线，并保持了视觉保真度。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17560", "html_url": "https://arxiv.org/abs/2505.17560", "title": "更深层次的扩散模型加剧偏差", "title_en": "Deeper Diffusion Models Amplify Bias", "authors": "Shahin Hakemi,Naveed Akhtar,Ghulam Mubashar Hassan,Ajmal Mian", "background": "尽管生成扩散模型（DMs）表现出色，但其内部工作机制仍不完全清楚，这可能是个问题。该研究聚焦于探索扩散模型中的偏差-方差权衡这一重要概念。研究指出，扩散模型在极端情况下会放大训练数据中的固有偏差，而在另一极端则可能牺牲训练样本的假定隐私。这种探索补充了生成模型的忆存-泛化理解，但同时揭示了更深模型中偏差放大的风险。", "innovation": "本文构建了一个系统的基础，以探索扩散模型中的偏差-方差权衡问题。研究验证了这一理论结论，并通过实验证明了更深的扩散模型放大偏差的风险。", "conclusion": "研究通过理论与实证方法验证了更深层次的扩散模型加剧偏差的风险，并进一步拓展了偏改正观念的边界。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07215", "html_url": "https://arxiv.org/abs/2502.07215", "title": "PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval", "title_en": "PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval", "authors": "Osman Tursun,Sinan Kalkan,Simon Denman,Clinton Fookes", "background": "零样本组成图像检索（ZS-CIR）能够通过参考图像和文本提示进行图像搜索，而无需依赖专门针对大规模配对数据训练的文本-图像组成网络。然而，当前的ZS-CIR方法在依赖组成文本嵌入时存在三个关键限制：静态查询嵌入表示、图像嵌入利用不足以及在融合文本和图像嵌入时表现不佳。", "innovation": "本文提出了一种简单有效的训练前增强方法——提示方向向量（PDV），它捕捉了用户提示引起的语义修改。PDV带来了三项关键改进：（1）动态组成文本嵌入，可以通过缩放因子控制提示调整；（2）通过语义转移从文本提示到图像特性生成组成图像嵌入；（3）加权融合组成文本和图像嵌入，通过平衡视觉和语义相似性增强检索性能。这种方法可以作为一种即插即用的增强，适用于现有的ZS-CIR方法，具有较低的计算开销。", "conclusion": "在多个基准上的广泛实验表明，当与最先进的ZS-CIR方法结合使用时，PDV持续提高检索性能，特别是在生成准确组成嵌入的方法中表现出色。代码将在发表后发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18663", "html_url": "https://arxiv.org/abs/2505.18663", "title": "DVD-Quant：无数据视频扩散变换器量化", "title_en": "DVD-Quant: Data-free Video Diffusion Transformers Quantization", "authors": "Zhiteng Li,Hanxuan Li,Junyi Wu,Kai Liu,Haotong Qin,Linghe Kong,Guihai Chen,Yulun Zhang,Xiaokang Yang", "background": "扩散变换器（DiTs）已成为视频生成的最佳架构，但由于其计算和内存需求，实际部署受到阻碍。现有后训练量化（PTQ）方法虽有望加速Video DiT模型，但存在两大缺陷：（1）依赖于计算密集型且不灵活的校准过程，（2）量化后性能显著下降。", "innovation": "提出了一种新的无数据量化框架DVD-Quant，用于Video DiTs。该方法包含三个关键技术革新：（1）有界初始网格细化（BGR）和（2）自适应旋转量化（ARQ）以减少校准数据的量化误差，以及（3）δ引导位交换（δ-GBS）以实现自适应位宽分配。", "conclusion": "在多个视频生成基准测试中，DVD-Quant 在先进 DiT 模型上实现了约2倍的加速，同时保持了视觉保真度。特别地，DVD-Quant 是第一个在不牺牲视频质量的情况下实现 Video DiTs W4A4 PTQ 的方法。代码和模型将在此处提供。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.11360", "html_url": "https://arxiv.org/abs/2502.11360", "title": "GeoDANO：具有通用视觉编码器的几何VLM", "title_en": "GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder", "authors": "Seunghyuk Cho,Zhenyue Qin,Yang Liu,Youngbin Choi,Seungbeom Lee,Dongwoo Kim", "background": "虽然视觉语言模型（VLM）已经被用于解决几何问题，但它们识别几何特征的能力还未得到充分分析。现有模型普遍采用的视觉编码器（如OpenCLIP）难以识别几何图中的基本特征（如点和线）和关系（如垂直关系），并且在不同领域间难以泛化。", "innovation": "提出了GeoCLIP，一种基于CLIP的模型，其在合成几何图表-标题对上训练，相比现有视觉编码器在识别几何特征方面表现更佳。然后提出了GeoDANO模型，通过领域适应策略增强了GeoCLIP，使其能够处理未见过的图样式，并在平面几何问题和MathVerse任务上优于专门方法和GPT-4o。", "conclusion": "GeoDANO模型在解决平面几何问题方面表现出色，尤其是在识别几何特征和适应不同图样式方面优于现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20611", "html_url": "https://arxiv.org/abs/2505.20611", "title": "Mamba-Driven Topology Fusion for Monocular 3D Human Pose Estimation", "title_en": "Mamba-Driven Topology Fusion for Monocular 3D Human Pose Estimation", "authors": "Zenghao Zheng,Lianping Yang,Jinshan Pan,Hegui Zhu", "background": "Transformer-based 方法在3D人体姿态估计中面临显著的计算挑战，因为随着序列长度的增长，自我注意机制的复杂性呈二次增长。近期，Mamba 模型通过利用状态空间模型显著降低了计算量并取得了优异的长期序列建模表现。然而，状态空间模型处理具有拓扑结构的序列关节数据的能力不足，而Mamba 中的因果卷积结构也不利于对局部关节关系的理解。", "innovation": "本文提出了一种Mamba-Driven Topology Fusion框架，包括Bone Aware Module、改进后的卷积结构以及Spatiotemporal Refinement Module。Bone Aware Module在球坐标系中推断骨向量的方向和长度，为Mamba模型提供有效的拓扑指导。通过结合前向和后向图卷积网络，改进的卷积结构可以更好地捕捉局部关节依赖关系。Spatiotemporal Refinement Module则专门设计用于建模序列内的时空关系。这种框架有效地弥补了Mamba模型在捕捉人体结构关系方面的不足。实验结果表明，提出的方法不仅大幅降低了计算成本，还达到了更高的准确性。", "conclusion": "我们在Human3.6M和MPI-INF-3DHP数据集上进行了广泛的实验来测试和对比，证明了所提出的方法在减少计算成本的同时实现了更高的准确性。剥离研究进一步证明了每个提出模块的有效性。源代码和模型将被发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01199", "html_url": "https://arxiv.org/abs/2503.01199", "title": "LiteGS: 通过系统和算法协同设计在亚分钟内训练3DGS的高性能框架", "title_en": "LiteGS: A High-performance Framework to Train 3DGS in Subminutes via System and Algorithm Codesign", "authors": "Kaimin Liao,Hua Wang,Zhi Chen,Luchao Wang,Yaohua Tang", "background": "3D Gaussian Splatting (3DGS) 在3D表示中具有前景，但仍然面临高昂的训练成本。", "innovation": "提出LiteGS，一种高性能框架，从低级别计算层、中级数据管理层和高级算法层三个方面系统优化3DGS训练管道。通过设计基于“变形体光栅化”的计算，并结合硬件感知优化，显著减少梯度减少的开销；在数据管理层，引入基于Morton编码的空间动态排序，以实现性能优化的“聚类清除紧凑”管道，提高数据局部性，并减少缓存缺失；算法层建立基于不透明度梯度变异的新稳健密度准则，并配以更稳定的不透明度控制机制，实现更精确的参数生长。", "conclusion": "实验结果表明，LiteGS将3DGS的原始训练加速至13.4倍以上，保持或提高质量，且轻量模型的速度超出了当前SOTA 1.4倍。对于高质量重建任务，LiteGS在精度上创下了新纪录，且将训练时间减少了数量级。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15197", "html_url": "https://arxiv.org/abs/2505.15197", "title": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech", "title_en": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech", "authors": "Pinxin Liu,Haiyang Liu,Luchuan Song,Jason J. Corso,Chenliang Xu", "background": "现有语音伴随手势生成方法主要依赖于表层语言线索（如语音音频或文本转录），忽略了手势背后体现的沟通意图。因此，生成的手势与语音节奏同步，但在语义层面浅薄。", "innovation": "该研究引入了Intentional-Gesture框架，将手势生成视为基于高层次沟通功能的意图推理任务。该框架通过以下方式创新：1) 创建InG数据集，通过大型视觉语言模型自动标注手势意图。2) 引入意向手势运动分词器，利用意图标注来注入高层次沟通功能（如意图），实现意图感知的手势合成，既在时间上对齐，又具有语义意义，达到BEAT-2基准上的最新性能。", "conclusion": "该框架为数字人类和身体化人工智能的富有表现力的手势生成提供了模块化基础。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15441", "html_url": "https://arxiv.org/abs/2505.15441", "title": "八阶视觉变换器：通过等变性提高速度的ViTs", "title_en": "Octic Vision Transformers: Quicker ViTs Through Equivariance", "authors": "David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman", "background": "当前最先进的视觉变换器（ViTs）并未充分利用自然几何对称性，如90度旋转和镜像反射。本文探讨了这一现象的原因，并提出其并不是由根本性的问题导致的，而可能只是缺少一种高效的实现方式。", "innovation": "本文提出了一种新的方法——八阶视觉变换器（octic ViTs），通过八阶组等变性来捕捉这些对称性。与之前增加计算成本的等变模型不同，octic线性层实现了5.33倍的计算量减少，并在内存占用上最多可以减少8倍。在完整八阶ViT块中，计算成本的减少接近随着嵌入维度增加的线性层减少量。此外，研究了两种由八阶块构建的新ViT家族，分别是全八阶等变或在最后部分打破等变性的模型。", "conclusion": "通过对ImageNet-1K数据集进行监督（DeiT-III）和无监督（DINOv2）训练，发现八阶ViTs在保持基准准确度的同时，提供了显著的效率提升。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02459", "html_url": "https://arxiv.org/abs/2506.02459", "title": "ReSpace: 通过偏好对齐实现的文本驱动3D室内场景合成与编辑", "title_en": "ReSpace: Text-Driven 3D Indoor Scene Synthesis and Editing with Preference Alignment", "authors": "Martin JJ. Bucher,Iro Armeni", "background": "3D室内场景的合成和编辑已成为计算机图形学中一个充满潜力的方向。当前已有的基于训练的方法要么使用单一热类编码简化对象语义（如椅子或桌子），要么需要遮罩扩散进行编辑，忽视房间边界，或者依赖地板平面渲染，这些都无法捕捉复杂布局。基于LLM的方法可以通过自然语言（如现代工作室，配有浅木家具）来提供更丰富的语义，但缺乏编辑功能，仅限于矩形布局，或依赖于隐式世界模型中的弱空间推理。", "innovation": "我们提出了ReSpace，这是一个利用自回归语言模型生成框架，用于基于文本驱动的3D室内场景合成与编辑。它采用紧凑的结构性场景表示，并明确标注房间边界，实现资产无关部署。我们将场景编辑转化为下一个标记预测任务，并采用双阶段训练方法结合监督微调和偏好对齐，专门为添加物体训练语言模型，考虑用户指令、空间几何、物体语义和场景层次组合。", "conclusion": "我们的方法在添加任务上超过了最新技术，并在整体场景合成上表现出更优秀的人类感知质量。我们还提出了一种基于体素的评估，能够捕捉到细粒度几何结构，超越了仅限于3D边界框的评估方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03318", "html_url": "https://arxiv.org/abs/2505.03318", "title": "通过强化微调实现统一多模态链式思考奖励模型", "title_en": "Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning", "authors": "Yibin Wang,Zhimin Li,Yuhang Zang,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang", "background": "近年来，多模态奖励模型（RMs）在提供奖励信号以使视觉模型与人类偏好相匹配方面显示出巨大的潜力。然而，当前的RMs通常只能提供直接响应或浅层次的推理过程，导致奖励信号不准确。本文假设将显式的多步骤链式思考（CoT）引入奖励推理过程可以显著增强其可靠性和稳健性，并认为一旦RMs内化了CoT推理，其直接响应的准确性也可以通过隐含的推理能力得到提升。", "innovation": "该论文提出了UnifiedReward-Think，这是第一个统一的多模态CoT基础奖励模型，能够进行多维度、逐步的长时间链推理，适用于视觉理解和生成奖励任务。该模型采用探索驱动的强化微调方法激发和激励模型的潜在复杂推理能力：首先利用少量图像生成偏好的数据提炼GPT-4o的推理过程，用于模型的冷启动阶段，使其学习CoT推理的形式和结构。接着通过利用模型的先验知识和泛化能力，准备大规模的统一多模态偏好数据，激发模型在各种视觉任务中的推理过程。在此阶段，正确的推理输出被保留用于拒绝采样以精炼模型，而错误预测的样本则用于基于群相对策略优化（GRPO）的强化微调，以鼓励模型探索不同的推理路径并优化对正确和稳健解决方案的追求。", "conclusion": "在各种视觉奖励任务上的广泛实验表明了该模型的优越性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21862", "html_url": "https://arxiv.org/abs/2505.21862", "title": "向3D医学成像扩展的可扩展语言-图像预训练", "title_en": "Towards Scalable Language-Image Pre-training for 3D Medical Imaging", "authors": "Chenhui Zhao,Yiwei Lyu,Asadur Chowdury,Edward Harake,Akhil Kondepudi,Akshay Rao,Xinhai Hou,Honglak Lee,Todd Hollon", "background": "当前语言-图像预训练在3D医学成像中的规模受到放射科医生手动整理原始临床研究的需求限制。本文探讨了直接在未整理的临床研究上进行预训练的可能性，这更符合放射科医生的工作流程，并提供了自然扩展的道路，但这些数据的独特结构给现有的模型架构带来了新的挑战，这些架构最初是为了处理二维切片或单一3D扫描而设计的。", "innovation": "提出了一个新颖的分层注意力机制HLIP，该机制借鉴了放射学数据的内在层次结构：切片、扫描、研究。HLIP在220,000个涉及3,130,000个脑MRI扫描和240,000个涉及1,440,000个颈头CT扫描的研究上进行了训练，取得了最优性能，如在公开获取的脑MRI基准测试Pub-Brain-5上，平衡准确率为+10.5%；在头CT基准测试CQ500和RSNA上，分别取得了+8.3%和+1.7%的宏AUC。HLIP在现有的3D医学语言-图像预训练基准测试中表现出很强的泛化能力，如在Rad-ChestCT基准测试中，预先训练在CT-RATE上时，宏AUC提高了4.3%。", "conclusion": "实验结果表明，使用HLIP直接在未整理的临床数据集上进行预训练，是一种在3D医学成像中扩展语言-图像预训练的可扩展且有效的方式。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18668", "html_url": "https://arxiv.org/abs/2505.18668", "title": "ChartGalaxy：用于信息图表理解和生成的数据集", "title_en": "ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation", "authors": "Zhen Li,Duan Li,Yukai Guo,Xinyuan Guo,Bowen Li,Lanxi Xiao,Shenyu Qiao,Jiashu Chen,Zijian Wu,Hui Zhang,Xinhuan Shu,Shixia Liu", "background": "信息图表是一种通过结合视觉元素（如图表、图像）和文本信息来传达抽象数据的强大媒介。然而，它们的视觉和结构丰富性给大型视觉-语言模型（LVLM）带来了挑战，这些模型通常是在简单的图表上进行训练的。因此，需要一种新的数据集来解决这个问题，以提高LVLM对信息图表的理解和生成能力。", "innovation": "作者引入了ChartGalaxy，这是一个用于推进信息图表理解和生成的大规模数据集。ChartGalaxy通过对实际信息图表进行归纳处理，并从中识别出75种图表类型、440种图表变化和68种布局模板，然后通过编程创建了合成图表。该数据集被用于增强LVLM的多模态原因和生成能力。", "conclusion": "通过捕捉真实设计的视觉和结构复杂性，ChartGalaxy提供了增强LVLM多模态推理和生成能力的有用资源。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03334", "html_url": "https://arxiv.org/abs/2505.03334", "title": "OS-W2S: 一种用于语言引导的开放集航空物体检测的自动标注引擎", "title_en": "OS-W2S: An Automatic Labeling Engine for Language-Guided Open-Set Aerial Object Detection", "authors": "Guoting Wei,Yu Liu,Xia Yuan,Xizhe Xue,Linlin Guo,Yifan Yang,Chunxia Zhao,Zongwen Bai,Haokui Zhang,Rong Xiao", "background": "近年来，语言引导的开放集航空物体检测由于更符合实际应用需求而受到广泛关注。然而，由于数据集有限，现有的语言引导方法主要集中在词汇层面的描述上，无法满足细粒度开放世界检测的需求。", "innovation": "为了应对这一局限，该论文提出了构建一个包含从词汇到短语再到句子三个层次语言指导的大规模语言引导开放集航空检测数据集。还提出了OS-W2S Label Engine，这是一种自动标注流水线，能够处理航空图像中的各种场景注释。利用该标注流水线扩展现有航拍物体检测数据集，并构建了一个新的基准数据集MI-OAD，解决了现有遥感接地数据的局限，支持有效的语言引导的开放集航空检测。MI-OAD包含163,023张图像和200万张图像-说明对，大约是现有可比数据集的40倍。在语言引导的开放集航空物体检测任务中，使用MI-OAD训练可以提升Grounding DINO的AP$_{50}$和Recall@10，分别提高31.1和34.7。利用MI-OAD进行预训练在多个现有开放词汇航拍物体检测和遥感视觉接地基准测试中都达到了最先进的性能，证明了该数据集的有效性和优质标签。", "conclusion": "该数据集MI-OAD及OS-W2S Label Engine为语言引导的开放集航空物体检测提供了强有力的支持，展示了其在多个任务上的性能优势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19585", "html_url": "https://arxiv.org/abs/2505.19585", "title": "CARE: 临床医学生物标志物的概率比认知估算", "title_en": "CARE: Confidence-aware Ratio Estimation for Medical Biomarkers", "authors": "Jiameng Li,Teodora Popordanoska,Aleksei Tiulpin,Sebastian G. Gruber,Frederik Maes,Matthew B. Blaschko", "background": "在临床实践中，基于比率的生物标志物，如肿瘤内坏死组织的比例，广泛用于支持诊断、预后及治疗计划。现有方法通常仅提供点估计，缺乏不确定性度量。本文通过分析分割到生物标志物管道中的错误传播，发现模型校准不正是不确定性的主要来源。本文提出一种统一的认知不确定性框架，用于估计基于比率的生物标志物，以提高临床工作流程中预测生物标志物的可信度。", "innovation": "本文提出了一种新颖的认知不确定性框架，用于估计基于比率的生物标志物。该框架基于两点观察：一是概率比估计器本身允许关于局部随机性的统计置信区间（偏差和方差）；二是分割网络并非完全校准。这些观察揭示了模型在校准方面的偏差是不确定性主要来源。此外，通过调整参数控制置信水平，使方法更好地适应临床实践。", "conclusion": "通过广泛的实验，证明本文的方法能够产生统计上可靠的置信区间，并允许调整置信水平，从而在临床流程中更可靠地应用预测生物标志物。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05096", "html_url": "https://arxiv.org/abs/2506.05096", "title": "Astraea: 一种用于视频扩散变换器的基于标记加速框架", "title_en": "Astraea: A Token-wise Acceleration Framework for Video Diffusion Transformers", "authors": "Haosong Liu,Yuge Cheng,Wenxuan Miao,Zihan Liu,Aiyue Chen,Jing Lin,Yiwu Yao,Chen Chen,Jingwen Leng,Yu Feng,Minyi Guo", "background": "尽管视频扩散变换器（vDiTs）在文本到视频生成方面取得了巨大进展，但其高计算需求构成了实际部署的主要障碍。虽然研究提出了一些加速方法来减轻不同粒度的工作量，但这些方法往往依赖于启发式方法，限制了它们的适用性。", "innovation": "Astraea框架通过核心机制提出了一个轻量级的标记选择机制和一种对内存友好、GPU友好的稀疏注意力策略，实现了执行时间上约线性减少，同时对生成质量的影响最小。为确定在不同时间步长的最佳标记减少，进一步设计了一种借助经典进化算法的搜索框架，以自动有效地确定标记预算的分布。Astraea在单张GPU上实现了高达2.4倍的推理加速，并在8张GPU上实现了高达13.2倍的加速，同时与最先进的方法相比，视频质量最多提高了10dB（与基线相比，V Bench损失小于0.5％）。", "conclusion": "Astraea在保持视频生成质量的同时，实现了显著的推理加速，展示了其在多GPU环境下的良好可扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08543", "html_url": "https://arxiv.org/abs/2506.08543", "title": "机器之前的结构：概念的前提在于输入空间", "title_en": "Structure before the Machine: Input Space is the Prerequisite for Concepts", "authors": "Bowei Tian,Xuntao Lyu,Meng Liu,Hongyi Wang,Ang Li", "background": "高级表示已成为提高人工智能透明度和控制的关键焦点，人们从单一神经元或电路转向关注与人类可理解的概念相一致的结构语义方向。受到线性表示假设(LRH)的启发，该研究提出了输入空间线性假设(ISLH)，假设这些与概念对齐的方向起源于输入空间，并在深度增加时被选择性放大。通过进一步的研究，这些研究阐明了视觉-语言模型(VLMs)中这种表示的跨模态鲁棒性。通过理论洞察与实证验证的结合，该工作推动了深度网络中表示形成结构理论的发展，为提高人工智能的鲁棒性、公平性和透明度铺平了道路。", "innovation": "该研究提出了输入空间线性假设(ISLH)，并引入了Spectral Principal Path (SPP)框架，正式化了深度网络如何沿着少数主导谱方向逐渐提炼线性表示。通过这一框架，进一步证明了VLMs中这些表示的跨模态鲁棒性。结合理论见解与实证验证，该研究推动了深度网络中表示形成结构理论的发展。", "conclusion": "该工作推进了深度网络中表示形成的结构理论，为提升人工智能的鲁棒性、公平性和透明度开辟了新途径。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08809", "html_url": "https://arxiv.org/abs/2506.08809", "title": "HiSin: 轴向图感知的高效高分辨率填充框架", "title_en": "HiSin: A Sinogram-Aware Framework for Efficient High-Resolution Inpainting", "authors": "Jiaze E,Srutarshi Banerjee,Tekin Bicer,Guannan Wang,Yanfu Zhang,Bin Ren", "background": "高分辨率的轴向图插补对计算机断层扫描重建至关重要，因为缺失的高频投影会导致可见伪影和诊断错误。扩散模型因其鲁棒性和细节保留能力而适合这一任务，但由于高分辨率输入导致的内存和计算需求过高的问题限制了其应用。", "innovation": "提出了一种名为HiSin的新型扩散基础框架，用于高效轴向图插补，该框架利用投影数据的频谱稀疏性和结构异质性，逐步在低分辨率下提取全局结构，并将高分辨率推断延迟到小块中，从而实现内存高效的插补。此外，框架引入了频率感知的块跳过和结构自适应步长分配，减少冗余计算。", "conclusion": "实验结果表明，与当前最好框架相比，HiSin将峰值内存使用量减少最多达30.81%，推理时间减少最多达17.58%，并且保持了插补精度。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18862", "html_url": "https://arxiv.org/abs/2506.18862", "title": "TAMMs: 时空感知多模态模型用于卫星影像变化理解和预测", "title_en": "TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting", "authors": "Zhongbin Guo,Yuhao Wang,Ping Jian,Chengzhi Li,Xinyue Chen,Zhen Yang,Ertai E", "background": "卫星影像时间序列（SITS）分析中，时空变化描述（TCD）和未来卫星影像预测（FSIF）是两个至关重要的任务，但它们在历史上的处理往往是独立的。这两个任务均受限于共同挑战——建模长期时间动态。通过增强对长期时间动态的理解能力，同时改进这两种任务的方法性能，本文提出了一种名为TAMMs的新框架，这是一套首次联合执行TCD和FSIF任务的统一方案，采用了单一MLLM-扩散架构。", "innovation": "TAMMs创新性地引入了两个关键模块：时空适应模块（TAM）增强冻结的MLLM对长期动态的理解能力；语义融合控制注入（SFCI）机制将这种变化理解转化为精细生成控制。这种协同设计使TCD任务的理解可以直接指导和改善FSIF任务的一致性。实验证明，TAMMs在两个任务上均显著优于现有的专业基准。", "conclusion": "本文提出的TAMMs框架显著改善了时空变化描述和未来卫星影像预测两种任务的性能，通过引入时空适应模块和语义融合控制注入机制，增强了长期时间动态的理解与生成控制，实验结果证明其优越性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22978", "html_url": "https://arxiv.org/abs/2505.22978", "title": "Pose-free 3D高斯点绘制方法通过形状-光线估计", "title_en": "Pose-free 3D Gaussian splatting via shape-ray estimation", "authors": "Youngju Na,Taeyeon Kim,Jumin Lee,Kyu Beom Han,Woo Jae Kim,Sung-eui Yoon", "background": "虽然广义可泛化的3D高斯点绘制可以高效且高质量地渲染未见过的场景，但它强烈依赖于精确的相机姿态以确保几何精度。在实际场景中，获得精确的姿态具有挑战性，会导致姿态估计噪声和几何偏移。\n", "innovation": "我们引入了SHARE，一个无姿式、前馈的高斯点绘制框架，通过联合形状和相机光线估计克服了这一问题。SHARE 不依赖于显式的3D变换，而是构建一个姿态意识的标准体积表示，无缝集成多视角信息，减少了因不准确的姿态估计导致的几何偏移。此外，锚点定向的高斯预测通过细化粗糙锚点周围的局部几何，增强了场景重建，允许更精确的高斯点放置。", "conclusion": "在各种现实世界数据集上的大量实验表明，我们的方法在无姿式广义高斯点绘制中表现出鲁棒性。\n"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02244", "html_url": "https://arxiv.org/abs/2506.02244", "title": "用于视频生成模型的物理引导运动损失", "title_en": "Physics-Guided Motion Loss for Video Generation Model", "authors": "Bowen Xue,Giuseppe Claudio Guarnera,Shuang Zhao,Zahra Montazeri", "background": "当前的视频扩散模型虽然生成了视觉上吸引人的内容，但往往违反了基本的物理定律，产生诸如橡皮膜变形和物体运动不一致等细微的伪像。这些模型在运动准确性上的不足影响了动作识别的性能。", "innovation": "本文引入了一种频域中的物理先验，通过不修改模型架构的方式改善了运动的合理性。该方法将常见的刚性运动（平移、旋转、缩放）分解为轻量级频谱损失，仅需2.7%的频谱系数同时保留97%以上的频谱能量。应用于Open-Sora、MVDIT和Hunyuan，该方法在OpenVID-1M上的运动准确性和动作识别平均提高了约11%（相对），同时保持了视觉质量。用户研究结果表明，物理增强视频的用户偏好在74%到83%之间。此外，该方法还能减少不同骨干网络的扭曲误差达22%至37%，并提高时间一致性得分。这些结果表明，简单的全局频谱暗示可以作为物理合理运动的有效正则符，插入视频扩散模型中能显著提升效果", "conclusion": "我们的方法通过频谱损失显著改善了视频中的物理合理性，同时保持了视觉质量。它不仅在运动准确性方面有所提升，还提高了动作识别的性能，并得到了用户的高度偏好。这种方法在增强视频生成模型的物理合理性方面具有潜在的应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10821", "html_url": "https://arxiv.org/abs/2506.10821", "title": "通过视频思考实现能动的长视频理解", "title_en": "Think With Videos For Agentic Long-Video Understanding", "authors": "Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou", "background": "长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。现有方法要么以牺牲细节为代价进行采样，要么依赖任务无关的表示进行文本推理，这妨碍了任务特定的感知和探索。", "innovation": "本文提出了一种基于“通过视频思考”原则的VideoExplorer框架，它自然地将规划、时间定位和可扩展感知融合到一个连贯的推理过程中。它通过迭代地提出子问题、定位相关时刻和执行任务导向的、时间可扩展的视频理解，直到得出最终答案，实现了忠实、高效和可解释的推理。此外，为了解决缺乏LVU训练资源的问题，设计了一个难度自适应采样构建的长视频推理数据集，并提出了一种两阶段训练管道，以提高训练效果和适应下游奖励。", "conclusion": "在常见的长视频理解和推理基准上的广泛评估表明，VideoExplorer相对于现有基线具有显著优势，突显了其鲁棒性、适应性和效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22432", "html_url": "https://arxiv.org/abs/2506.22432", "title": "Shape-for-Motion: 使用3D代理实现精确和一致的视频编辑", "title_en": "Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy", "authors": "Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W.H. Lau", "background": "近年来，深度生成模型取得了重大进展，为视频合成带来了前所未有的机会。然而，在真实世界的应用中，用户常常希望有工具能忠实实现其创意编辑意图，并进行精细且一致的控制。尽管现有方法取得了进步，但确保与用户意图的精细对齐仍然是一个开放且具有挑战性的问题。", "innovation": "本文提出了Shape-for-Motion，这是一种新颖的框架，该框架通过将输入视频的目标对象转换为时间一致的网格，即3D代理，实现了精确和一致的视频编辑。该框架还设计了一种新的双传播策略，允许用户在一个时间帧的3D网格上进行编辑，然后自动传播到其他帧的3D网格。此外，不同时间帧的3D网格被投影到2D空间以生成编辑后的几何和纹理渲染，作为一个解藕的视频扩散模型的输入，以产生编辑结果。该框架支持视频帧上多种精确且物理解释一致的操作，包括姿态编辑、旋转、缩放、平移、纹理修改以及对象组合。", "conclusion": "我们的框架标志着高质量、可控制的视频编辑工作流的一步重要进展。广泛的实验结果表明，我们的方法具有优越性和有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03162", "html_url": "https://arxiv.org/abs/2506.03162", "title": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "title_en": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "authors": "Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh", "background": "近年来，监控摄像头的迅速普及增加了自动暴力检测的需求。现有的CNN和Transformer模型虽然在提取时空特征方面取得了一定的成效，但在处理长时依赖关系和计算效率方面存在局限性。", "innovation": "本文提出了一个结合双分支设计和状态空间模型（SSM）骨干网络的高效架构——Dual Branch VideoMamba，通过门控机制进行分支间动态融合，增强模型在复杂监控场景下检测暴力活动的能力。同时，通过将RWF-2000、RLVS、SURV和VioPeru等数据集合并生成新的基准，确保了训练集和测试集之间的严格分离，从而提出了新的视频暴力检测基准。", "conclusion": "实验结果显示，本文模型在该基准上达到了最先进的性能，并在另一个新型视频暴力检测数据集DVD上同样实现了优异的效果，展示了SSM在可扩展、接近实时监控暴力检测中的潜力，提供了在准确性与计算效率之间取得平衡的方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05667", "html_url": "https://arxiv.org/abs/2506.05667", "title": "DriveAction：探索VLA模型中人性化驾驶决策的标准", "title_en": "DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models", "authors": "Yuhan Hao,Zhengning Li,Lei Sun,Weilong Wang,Naixin Yi,Sheng Song,Caihong Qin,Mofan Zhou,Yifei Zhan,Xianpeng Lang", "background": "Vision-Language-Action (VLA) 模型已经促进了自主驾驶的发展，但现有的基准仍然缺乏场景多样性、可靠的动作级标注以及与人类偏好相契合的评估协议。针对这一现状，DriveAction 是首个专门设计用于 VLA 模型的动作驱动基准，包含 2,610 个驾驶场景，共计生成了 16,185 个问答对。", "innovation": "DriveAction 模型利用了由自动驾驶车辆的驾驶员主动收集的实际驾驶数据，确保了广泛和代表性的场景覆盖；提供了高阶离散动作标签，直接源自驾驶员的实际驾驶操作；实现了一种以动作为中心的树状结构评估框架，明确连接了视觉、语言和动作任务，支持全面和任务特定的评估。通过该基准，展示了最先进的视觉语言模型（VLM）需要视觉和语言指导才能实现准确的动作预测：在没有视觉输入的情况下准确度平均下降 3.3%，在没有语言输入的情况下下降 4.1%，如果既没有视觉输入也没有语言输入，则下降 8.0%。", "conclusion": "通过对模型瓶颈的精确识别，DriveAction 为推进自主驾驶中的人类化决策提供了精准且一致的评估结果，从而为VLA模型的发展奠定了坚实的基础。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09935", "html_url": "https://arxiv.org/abs/2506.09935", "title": "LEO-VL: 适用于可扩展3D视觉语言学习的高效场景表示", "title_en": "LEO-VL: Efficient Scene Representation for Scalable 3D Vision-Language Learning", "authors": "Jiangyong Huang,Xiaojian Ma,Xiongkun Linghu,Yue Fan,Junchao He,Wenxin Tan,Qing Li,Song-Chun Zhu,Yixin Chen,Baoxiong Jia,Siyuan Huang", "background": "在3D视觉-语言（3D-VL）领域，开发能够理解3D场景的视觉语言模型（VLMs）一直是长期目标。尽管最近取得了一些进展，但在能力和鲁棒性方面，3D VLMs仍然落后于2D VLMs。技术瓶颈在于当前的场景表示不能平衡性能和效率：竞争力的性能需要大量令牌以换取效率，从而限制了3D-VL学习的可扩展性。", "innovation": "本文提出了紧凑特征网格（CFG）作为一种高效的场景表示，它具有显著减少令牌开销和强大的感知能力。基于CFG，提出了LEO-VL，这是一种3D VLM，通过700k覆盖四个真实室内领域和五个任务（如描述和对话）的3D-VL数据集进行训练。为了增强3D VLM的鲁棒性，还提出了SceneDPO用于后训练，包括答案和场景之间的对比。LEO-VL在包括SQA3D、MSQA和Beacon3D等多种3D问答基准测试中实现了最佳性能。实验结果显示，我们的表示更有效，任务和场景多样性的好处，可扩展性的影响一致，并且SceneDPO相对于SFT和GRPO具有优势。", "conclusion": "希望我们的研究能够促进未来3D VLMs的效率、可扩展性和鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09079", "html_url": "https://arxiv.org/abs/2506.09079", "title": "VidBridge-R1: 利用中间代理任务桥接基于强化学习的问答和字幕生成视频理解模型", "title_en": "VidBridge-R1: Bridging QA and Captioning for RL-based Video Understanding Models with Intermediate Proxy Tasks", "authors": "Xinlong Chen,Yuanxing Zhang,Yushuo Guan,Weihong Lin,Zekun Wang,Bohan Zeng,Yang Shi,Sihan Yang,Qiang Liu,Pengfei Wan,Liang Wang,Tieniu Tan", "background": "目前，通过强化学习增强的'Reason-Then-Respond'范式在多模态大语言模型中展现出巨大潜力。然而，将其应用于视频领域时，生成的模型在问答（QA）和字幕生成任务上表现出色，但在两种能力之间难以兼顾，单纯结合这两种任务的奖励信号会导致性能相互削弱。这归因于它们任务目标的对立性质冲突。因此，亟需一种新的训练框架来解决这一问题，使得模型能够同时增强整体了解和精确推理能力，从而更好地处理两种任务。", "innovation": "提出了一种新训练框架，基于两种中间代理任务：DarkEventInfer和MixVidQA。DarkEventInfer呈现带有遮盖事件片段的视频，促使模型根据上下文视频线索推断被遮盖的内容；而MixVidQA展示交替播放的视频序列，包括两个不同镜头，要求模型去关注其中一个并忽略另一个。通过这两个代理任务，模型被激励同时发展整体和精确的理解与推理能力。本文还介绍了第一个结合这两种代理任务的视频推理模型VidBridge-R1，该模型有效解决了两种任务之间的范式冲突，并在其上取得了显著性能增益，展示了该方法在促进更通用和强大的视频理解模型方面的作用。", "conclusion": "通过广泛的实验，VidBridge-R1在一个模型中显著提高了问答和字幕生成的性能，验证了这种基于中间代理任务的训练框架的有效性，展示了在提高视频理解的通用性和强度方面的新方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15220", "html_url": "https://arxiv.org/abs/2506.15220", "title": "video-SALMONN 2: 增强的音频-视频大语言模型", "title_en": "video-SALMONN 2: Caption-Enhanced Audio-Visual Large Language Models", "authors": "Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang", "background": "该研究基于现有的音频-视频大语言模型，旨在提高视频描述和问答任务的效果。背景包括现有的模型如GPT-4o和Gemini-1.5 Pro在视频描述方面存在的不足，特别是在细节和精确度上。研究者指出当前标准的方法中，直接偏好优化（DPO）模型使用固定参考策略，可能导致参考信息过时，影响模型持续改进。", "innovation": "研究的主要创新点在于多轮直接偏好优化（MrDPO），这是通过定期刷新参考策略实现的。新策略使用轻量级适配器重新初始化并利用最新的偏好数据，避免了参考信息的陈旧问题，从而实现持续改进。这使生成的字幕在细节和准确性上明显优于其他系统。此外，通过使用增强的模型生成高质量的视频字幕集，该研究进一步将获得的好处应用于复杂的视频问答任务上，取得了业内领先的表现。这些模型在各类广泛使用的音频-视频及视图理解基准测试中均表现出色，尤其是在开放源代码系统中卓越超群，尤其是在720亿参数模型的技术上取得突破。", "conclusion": "研究展示了其3亿（3B）和7亿（7B）参数模型在不同基准测试中的SOTA结果，并且其72亿（72B）模型超越了所有其他开源系统。同时，研究者发布了源代码、模型和数据，从而促进社区的研究和应用开发。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20294", "html_url": "https://arxiv.org/abs/2506.20294", "title": "Ctrl-Z Sampling: 控制随机曲折探索的扩散采样", "title_en": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations", "authors": "Shunqi Mao,Wei Guo,Chaoyi Zhang,Jieting Long,Ke Xie,Weidong Cai", "background": "扩散模型通过逐步去噪高斯样本至目标数据分布，在条件生成任务中表现出强大的性能。这一去噪过程可以被理解为在学习到的表示空间中的上坡寻优。然而，这一寻优过程经常在复杂潜在空间和次优初始化的情况下，收敛到局部最优，生成的样本虽有合理性但并不理想。先前的努力往往通过加强指导信号或引入固定探索策略来应对这一问题，但这类方法对逃离陡峭的局部最大值的能力有限。", "innovation": "本文提出了一种名为Controlled Random Zigzag Sampling (Ctrl-Z Sampling) 的新采样策略，它通过受控探索动态交替前进精炼和向后探索，来自适应地检测和逃离潜在的局部最大值陷阱。在每个扩散步骤中，首先使用奖励模型识别潜在的局部最大值，然后注入噪声并回到更嘈杂的状态以逃离当前的平台期。奖励模型评估候选轨迹，对于可行的便接受，若附近的选择都不可行，则推进更深层次的探索。这种控制变异的过程增强了生成输出的对齐和视觉质量。该方法具有模型无关性，并且可以与现有的扩散框架兼容。实验结果显示，Ctrl-Z Sampling 在生成能力上显著提升，仅需要原始模型的约7.72倍的NFEs（噪声消除迭代次数）.", "conclusion": "该研究提出了一种创新的采样方法，即Controlled Random Zigzag Sampling (Ctrl-Z Sampling)，该方法通过控制探索来动态地在前行精炼和向后探索之间交替。这种方法在生成质量和对齐度上都有显著的改进，并且具有模型无关性和框架兼容性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21567", "html_url": "https://arxiv.org/abs/2507.21567", "title": "RelMap: 使用类感知空间关系和语义先验增强在线地图构建", "title_en": "RelMap: Enhancing Online Map Construction with Class-Aware Spatial Relation and Semantic Priors", "authors": "Tianhui Cai,Yun Zhang,Zewei Zhou,Zhiyu Huang,Jiaqi Ma", "background": "自动驾驶系统的普及依赖于在线高清晰度(HD)地图构建技术。虽然基于Transformer的方法在这一领域取得了显著进展，但现有方法往往忽视了地图元素之间的固有空间关系和语义关联，这限制了其准确性和泛化能力。", "innovation": "本文提出了RelMap，一种端到端框架，能够明确建模空间关系和语义先验，以增强在线HD地图构建的精度。具体而言，RelMap引入了类感知的空间关系先验，通过可学习的类感知关系编码器明确地编码地图元素之间的相对位置依赖关系。此外，设计了基于专家混合的语义先验，根据预测的类别概率将特征路由至特定类别的专家，进一步细化实例特征解码。", "conclusion": "RelMap与单帧和时间感知主干网络兼容，已经在nuScenes和Argoverse 2数据集上达到了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02705", "html_url": "https://arxiv.org/abs/2507.02705", "title": "SIU3R: 超越特征对齐的场景同时理解与3D重建", "title_en": "SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment", "authors": "Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu", "background": "同时理解和3D重建对于开发端到端的具身智能系统至关重要。现有的方法依赖2D到3D特征对齐的范式，但这种做法限制了3D理解能力，并可能导致潜在的语义信息丢失。为解决这一问题，提出SIU3R，这是一种无需特征对齐的一般化同时理解和3D重建框架，可以在未校准图像中实现端到端的3D重建与理解任务。", "innovation": "SIU3R通过像素对齐的3D表示连接重建和理解任务，并将多种理解任务统一为一组可学习查询，从而实现无需2D模型对齐的本地3D理解。此外，通过深入分析二者之间的相互关系并设计了两个轻量级模块来促进它们之间的交互，从而提高整体性能。", "conclusion": "大量实验表明，SIU3R不仅在3D重建和理解的单任务上，还在同时理解和3D重建任务上达到了最先进的性能，突显了无特征对齐框架的优势及其相互益处设计的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.17522", "html_url": "https://arxiv.org/abs/2507.17522", "title": "STQE: 空间-时间属性质量增强用于G-PCC压缩的动态点云", "title_en": "STQE: Spatial-Temporal Attribute Quality Enhancement for G-PCC Compressed Dynamic Point Clouds", "authors": "Tian Guo,Hui Yuan,Xiaolong Mao,Shiqi Jiang,Raouf Hamzaoui,Sam Kwong", "background": "很少有研究关注压缩动态点云的质量提升，特别是在点云帧之间的空间-时间相关性的有效利用方面仍然存在较大的空白。", "innovation": "提出了一个空间-时间属性质量增强(STQE)网络，该网络利用空间和时间相关性来改进G-PCC压缩动态点云的视觉质量。该网络包括：一种基于着色的运动补偿模块，用于实现精确的帧间几何对齐；一种通道感知的时间注意力模块，用于动态突出显示双向参考帧中的相关区域；一种沿几何和颜色属性方向高效捕获空间依赖性的高斯引导邻域特征聚合模块；一种基于皮尔逊相关系数的联合损失函数，用于缓解点式均方误差优化中的过度平滑效果。", "conclusion": "将STQE应用于最新的G-PCC测试模型，实现了在Luma、Cb和Cr分量上分别达到0.855 dB、0.682 dB和0.828 dB的delta PSNR改进，并实现了Bjøntegaard Delta率分别为-25.2%、-31.6%和-32.5%的减少。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01908", "html_url": "https://arxiv.org/abs/2507.01908", "title": "视觉推理驱动的假设指令图像编辑", "title_en": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "authors": "Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang", "background": "随着扩散模型的成功，基于指令的图像编辑(IIE)有了快速的发展。现有工作主要集中在简单的显式指令上，这些指令执行添加、删除、移动或交换对象等操作。然而，它们难以处理复杂的隐式假设指令，这些指令需要深层推理以推断可能的视觉变化和用户意图。此外，当前的数据集对训练和评估推理感知的编辑能力支持有限。从架构上看，现有方法缺乏支持此类推理的细致图像特征提取机制。为解决上述问题，本文提出了Reason50K，一个专门为训练和评估假设指令推理图像编辑设计的大规模数据集，以及ReasonBrain，一种用于跨多种场景推理并执行隐式假设指令的新型框架。Reason50K包含超过50,000个样例，涵盖四个关键推理场景：物理、时间、因果和故事情节推理。ReasonBrain结合了多模态大型语言模型(MLLMs)用于编辑指导生成和扩散模型进行图像合成，并结合Fine-grained Reasoning Cue Extraction (FRCE)模块来捕获支持指令推理的关键视觉和文本语义信息。为了缓解语义损失，论文进一步引入了Cross-Modal Enhancer (CME)，以促进细粒度线索与MLLM特征之间的丰富互动。", "innovation": "本文提出了Reason50K，一个专门为训练和评估假设指令推理图像编辑的大规模数据集，以及ReasonBrain，一种结合了多模态大型语言模型和扩散模型的新型编辑框架。ReasonBrain利用FRCE模块捕获详细的视觉和文本语义信息，并通过CME增强跨模态响应，从而支持假设指令的推理与执行。此外，该框架在推理场景中表现显著优于现有基线，同时展示了强大的零样本泛化能力于常规IIE任务。", "conclusion": "通过Reason50K数据集的引入和ReasonBrain框架的设计，本文成功解决了现有图像编辑方法在处理复杂隐式假设指令和增强推理能力方面的局限性。实验结果表明，该方法在各种推理场景中表现优异，并且具有强大的零样本泛化能力，包括常规的IIE任务。未来的公开发布将使更多研究者获益于这些资源。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11245", "html_url": "https://arxiv.org/abs/2507.11245", "title": "NarrLV: 向长视频生成进行全面叙述为中心的评估迈进", "title_en": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation", "authors": "X. Feng,H. Yu,M. Wu,S. Hu,J. Chen,C. Zhu,J. Wu,X. Chu,K. Huang", "background": "随着基础视频生成技术的迅速发展，长视频生成模型由于内容创作空间的扩大展现出巨大的研究潜力。近期研究发现，长视频生成任务不仅在于延长视频时长，还在于在较长的视频中准确表达更丰富的叙述内容。然而，由于缺乏专门针对长视频生成模型的评价基准，当前对这些模型的评估主要依赖于简单的叙述提示基准（如 VBench）。因此，作者提出 NarrLV 作为首个全面评估长视频生成模型叙述表达能力的基准，通过引入叙述原子（TNA）及其数量来定量衡量叙述丰富性，并基于叙述内容表达的三个渐进层次设计了有效的评估指标，通过广泛的现有长视频生成模型和基础生成模型的评估实验，验证了该指标与人类判断的高度一致性，并揭示了当前视频生成模型在叙述内容表达方面的详细能力边界。", "innovation": "提出了 NarrLV 作为首个专门针对长视频生成模型的全面叙述评价基准，引入了叙述原子（TNA）及其数量来定量衡量叙述丰富性，设计了一个基于 MLLM 的问题生成和回答框架来有效评估叙述内容表达，通过三个渐进层次的叙述内容表达，验证了该指标的高度一致性，评估了现有模型的叙述表达能力边界。", "conclusion": "实验结果显示，作者提出的评估指标与人类判断高度一致。通过对现有模型进行全面评估，得出了视频生成模型在叙述内容表达方面的详细能力边界。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05394", "html_url": "https://arxiv.org/abs/2507.05394", "title": "pFedMMA：基于多模态适配器的个性化联邦微调框架", "title_en": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models", "authors": "Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani", "background": "视觉-语言模型（如CLIP）在零样本和少样本设置中表现出显著的一般化能力，但在高效适配去中心化、异质数据方面仍存在挑战。尽管提示调优在个性化联邦学习中作为一种参数高效方法变得流行，但现有方法往往在个性化的同时牺牲了泛化能力，尤其在未见过的类别和领域上表现较差。目前的研究工作中提出的pFedMMA是第一个利用多模态适配器的个性化联邦学习框架，旨在解决视觉-语言任务的个性化与泛化之间的平衡问题，以提高模型的泛化性能和通用能力。在多个数据集上通过广泛实验验证了pFedMMA在个性化和泛化方面的优越性能，优于最新的联邦提示调优方法，同时也通过通信策略提升了通信效率，降低突发通信成本。", "innovation": "pFedMMA利用多模态适配器进行个性化联邦学习，每个适配器内部包括特定模态的上采样和下采样层以及全局共享层，以跨模态特征对齐。此设计可以在客户端上实现个性化数据分布的本地适配，同时通过协作训练共享投影来提高全局泛化能力，并在通信过程中仅交换共享部分，避免了信息冗余，优化了通信效率。", "conclusion": "通过在包括领域和标签迁移在内的多个数据集上的广泛实验，证明pFedMMA框架在个性化和泛化之间达到了最先进的权衡效果，优于最近的联邦提示调优方法，同时提高了通信效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03262", "html_url": "https://arxiv.org/abs/2507.03262", "title": "在具有多个视觉编码器的多模态大型语言模型中探究冗余性", "title_en": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders", "authors": "Yizhou Wang,Song Mao,Yang Chen,Yufan Shen,Yinqiao Yan,Pinlong Cai,Ding Wang,Guohang Yan,Zhi Yu,Xuming Hu,Botian Shi", "background": "近期，多模态大型语言模型（MLLMs）越来越多地整合多个视觉编码器来改进各种基准上的性能，假设多样化的预训练目标会产生互补的视觉信号。然而，本文通过系统性地对多个代表性多编码器MLLM进行编码器屏蔽，发现去除某些编码器时，模型的性能仍然会有所改善甚至保持不变，这表明编码器之间有着广泛的冗余性。", "innovation": "本文引入了两个基本的度量标准：条件利用率（CUR）衡量其他编码器在场的情况下某编码器的边际贡献，信息缺口（IG）捕捉模型内编码器效用的异质性。通过这些工具，研究发现：（i）在OCR和图表等任务上，一个编码器可以在CUR大于90%的情况下主导任务表现；（ii）在通用问答和基于知识的任务上，编码器之间非常高程度的可替换性表明高度冗余性；（iii）某些有害编码器的负CUR值表明它们会损害模型性能。特定编码器的去除此研究证明了对于特定任务类别可以提高高达16%的准确率，总的性能提升可高达3.6%。我们也表明单个和双个编码器变体在大多数非OCR任务上可以恢复90%以上的基线性能。", "conclusion": "本文的研究反驳了多编码器越多越好这一启发式思维，为开发更高效和有效的多模态架构提供了可操作的诊断工具。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02192", "html_url": "https://arxiv.org/abs/2508.02192", "title": "内容感知的Mamba在学习型图像压缩中的应用", "title_en": "Content-Aware Mamba for Learned Image Compression", "authors": "Yunuo Chen,Zezheng Lyu,Bing He,Hongwei Hu,Qi Wang,Yuan Tian,Li Song,Wenjun Zhang,Guo Lu", "background": "最近的学习型图像压缩（LIC）利用了具有线性复杂度的Mamba风格的状态空间模型（SSMs）来实现全局感受野。然而，标准的Mamba使用的是内容无关的、预先定义的逐行扫描（或多方向扫描），并且受到严格因果性的限制。这种僵化阻碍了其有效消除内容相关但空间上相距遥远的标记中的冗余能力。", "innovation": "本文引入了内容感知Mamba（CAM），这是一种能够动态适应图像内容的状态空间模型。CAM通过两种创新机制克服了之前的限制：首先，它用内容适应性的令牌排列策略取代了僵化的扫描，以优先考虑内容相似的令牌之间的交互，而不论它们的位置如何；其次，它通过将样本特异性的全局先验注入状态空间模型中来克服顺序依赖性，从而有效缓解了严格的因果性，而无需多方向扫描。", "conclusion": "基于内容感知Mamba的LIC模型（CMIC）实现了最先进的率-失真性能，分别在Kodak、Tecnick和CLIC数据集上优于VTM-21.0 15.91%、21.34%和17.58%的BD-rate。代码和检查点稍后会发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20890", "html_url": "https://arxiv.org/abs/2507.20890", "title": "$A^2R^2$: 通过关注引导的细化与视觉推理提升从图像到LaTeX的转换", "title_en": "$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with Attention-Guided Refinement", "authors": "Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai", "background": "Img2LaTeX任务是指将图像中的数学表达式和结构化视觉内容转换为LaTeX代码的重要任务。近年来，Vision-Language模型（VLMs）在多种视觉理解任务中取得了显著进展，归因于其强大的泛化能力。然而，尽管最初尝试将VLMs应用于Img2LaTeX任务，它们的表现仍然不尽如人意。实验研究表明，VLMs在处理数学表达式中的细粒度视觉元素（如下标和上标）时表现不佳，导致LaTeX生成不准确。针对这一挑战，本文提出了一种名为$A^2R^2$的框架，有效地结合了注意力定位和迭代细化，以视觉推理框架为基础，使VLMs能够进行自我纠正并逐步提高LaTeX生成质量。为了有效评估，引入了新的数据集Img2LaTex-Hard-1K，其中包括1100个精心策划且具有挑战性的示例，旨在严格评估VLMs在该任务领域的能力。", "innovation": "本文提出了一种名为$A^2R^2$的框架，该框架结合了注意力定位和迭代细化，利用视觉推理，使Vision-Language模型能够进行自我纠正并逐步提高LaTeX生成质量，有效提升了模型在多种评估指标上的表现，并且通过增加推理轮次还可以显著提升性能，验证了$A^2R^2$在测试时扩展场景下的潜力。", "conclusion": "实验结果表明：(1) $A^2R^2$在多种评估指标上显著提高了模型性能，涵盖了文本和视觉两个层面；(2) 增加推理轮次可以显著提高性能，证明了在测试时扩展场景下$A^2R^2$的可能性；(3) 消融实验和进一步评估证实了本文方法的有效性及其核心组件之间的协同作用。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20879", "html_url": "https://arxiv.org/abs/2507.20879", "title": "DriveAgent-R1：基于视觉-语言模型的主动感知和混合思考推动自主驾驶发展", "title_en": "DriveAgent-R1: Advancing VLM-based Autonomous Driving with Active Perception and Hybrid Thinking", "authors": "Weicheng Zheng,Xiaofei Mao,Nanfei Ye,Pengxiang Li,Kun Zhan,Xianpeng Lang,Hang Zhao", "background": "视觉-语言模型（VLMs）的发展显著推动了端到端自动驾驶的进步，展示了其强大高级行为规划的推理能力。然而，现有的方法通常受限于被动感知的范式，仅依赖基于文本的推理。这种被动性限制了模型在面对不确定性时寻找关键视觉证据的能力。本研究旨在解决这一问题，提出了第一个具备主动感知能力的自动驾驶代理DriveAgent-R1，在复杂场景中主动发起工具进行视觉推理，使决策更加可靠和可解释。研究还提出了一种受人类驾驶认知模式启发的混合思考框架，能够根据场景复杂度在高效文字推理和稳健工具增强视觉推理之间灵活转换，此能力通过一个包含核心递归强化学习（Cascaded RL）阶段的三阶段渐进式训练策略发展而来。实验结果表明，DriveAgent-R1在Drive-Internal数据集和公开的nuScenes数据集上仅用3B参数达到了与顶级封闭模型系统如GPT-5相当的性能，且具备与人类驾驶相当的能力，同时保持部署友好性，为构建更智能的自动驾驶系统提供了有据可依的路径。", "innovation": "提出了第一个具备主动感知能力的自动驾驶代理DriveAgent-R1，能够在复杂场景中主动发起工具进行视觉推理，增强决策的可靠性和可解释性；同时，提出了一种受人类驾驶认知模式启发的混合思考框架，能够根据场景复杂度在高效文字推理和稳健工具增强视觉推理之间灵活转换；通过一个包含核心递归强化学习（Cascaded RL）阶段的三阶段渐进式训练策略发展驱动该能力；在大规模数据集上验证了DriveAgent-R1的优良性能与部署友好性。", "conclusion": "研究展示了DriveAgent-R1在视觉-语言模型驱动的自动驾驶中的优势，通过主动感知和混合思考框架显著提升了自动驾驶系统的决策能力和可靠性。这一方法为构建更智能的自动驾驶系统提供了切实可行的路径。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07450", "html_url": "https://arxiv.org/abs/2509.07450", "title": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization", "title_en": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization", "authors": "Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Peifeng Ma,Xue Yang,Hongsheng Li", "background": "现有交叉视角地理定位（CVGL）方法通常局限于单一视角或模态，且其直接视觉匹配策略缺乏可解释性，只能判断两张图像是否对应，而不解释匹配背后的理由。这些方法存在的主要挑战包括缺乏跨视角的有效匹配和解释性。", "innovation": "GLEAM-C通过将多视角和多模态数据，如无人机图像、街道地图、全景视图和地面照片，统一并与卫星图像对齐，形成了一种新的跨视角地理定位模型。GLEAM-X则将跨视角对应预测与可解释推理相结合，通过人类详细修订构建了一个多语种基准数据集来支持这一任务，并通过一个两阶段训练策略提高训练效率，同时保持与现有模态特定的CVGL模型相当的准确性。", "conclusion": "GLEAM-C和GLEAM-X共同构成了一个集多模态、多视角对齐与可解释对应分析于一体的综合CVGL管道，能够进行准确的跨视角匹配和可解释推理，从而促进地理定位技术的发展，使模型能够更好地解释和匹配。这些代码和数据集将在本文提供公开访问。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14483", "html_url": "https://arxiv.org/abs/2508.14483", "title": "Vivid-VR: 从文本到视频扩散变换器中提炼概念以实现保真度视频恢复", "title_en": "Vivid-VR: Distilling Concepts from Text-to-Video Diffusion Transformer for Photorealistic Video Restoration", "authors": "Haoran Bai,Xiaoxu Chen,Canqian Yang,Zongyao He,Sibin Deng,Ying Chen", "background": "现有基于转换-生成（T2V）架构的可控视频生成方法在分布归一化上经常遇到问题，由于不完美的多模态对齐限制，导致生成的视频纹理真实性和时间连贯性受损。", "innovation": "提出了概念蒸馏训练策略，利用预训练的T2V模型生成嵌入了文本概念的训练样本，将模型的概念理解蒸馏出来以保留纹理和时间质量。重新设计了控制架构，包括输入视频隐含特征的控制特征投影器和新的控制网络连接器（采用双分支设计），协同结合基于MLP的特征映射和交叉注意力机制，实现内容保持和自适应控制信号调制。", "conclusion": "Vivid-VR 在合成和真实世界基准测试中，以及AIGC视频中都表现优异，实现了令人印象深刻的纹理真实度、视觉生动性和时间连贯性。相关代码和检查点公开可用。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03442", "html_url": "https://arxiv.org/abs/2508.03442", "title": "RAAG: Ratio Aware Adaptive Guidance", "title_en": "RAAG: Ratio Aware Adaptive Guidance", "authors": "Shangwen Zhu,Qianyu Peng,Yuting Hu,Zhantao Yang,Han Zhang,Zhao Pu,Andy Zheng,Zhilei Shu,Ruili Feng,Fan Cheng", "background": "流生成模型已经取得了显著的进步，无分类器指导（CFG）已成为高保真生成的标准。然而，传统的在整个推断过程中应用固定强度的指导规模的方法并不适合现代应用所需的快速、少量的采样要求。这项工作的背景是揭示这种冲突的根本原因：一种根本性的采样不稳定现象，其中早期步骤的预测对指导异常敏感。这种现象源自于条件预测与非条件预测比例的显著增加，这在训练数据分布中是一个固有的属性，几乎不可避免地成为挑战。在不稳定初始阶段应用高强度的固定指导值会导致误差指数放大，影响图像质量。", "innovation": "提出了一个简单、理论依据充分的自适应指导计划，该计划可以在早期步骤根据不断变化的比例自动降低指导规模。该方法重量轻，不增加推理开销，与标准框架兼容。跨最先进的图像（SD3.5, Qwen-Image）和视频（WAN2.1）模型的实验显示，该方法可以实现高达3倍的采样速度提升，同时保持或提高质量、鲁棒性和语义对齐。该研究强调，为了充分发挥快速、流基础模型的潜力，指导应适应采样过程，而不仅仅是固定不变的。", "conclusion": "研究结果表明，自适应调整指导，而不是固定指导，是解锁快速、流基础模型全部潜力的关键。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04324", "html_url": "https://arxiv.org/abs/2508.04324", "title": "TempFlow-GRPO：流模型中时间至关重要性", "title_en": "TempFlow-GRPO: When Timing Matters for GRPO in Flow Models", "authors": "Xiaoxuan He,Siming Fu,Yuke Zhao,Wanli Li,Jian Yang,Dacheng Yin,Fengyun Rao,Bo Zhang", "background": "最近的基于流的文本到图像生成模型已经取得了显著的质量，但它们与强化学习结合以对齐人类偏好时的表现仍然不佳，这限制了基于奖励的优化。研究人员观察到，现有方法中的关键阻碍在于时间上的均匀假设：稀疏的终端奖励和均匀的信用分配无法捕捉生成时间步骤中决策的关键性变化，导致探索效率低下和收敛效果不理想。", "innovation": "为解决上述问题，该研究提出了TempFlow-GRPO（时间流GRPO），这是一种原理上的GRPO框架，能够捕捉并利用流式生成中固有的时间结构。TempFlow-GRPO的创新包括：(i) 轨迹分支机制，在指定的分支点集中随机性，通过集中随机性来提供过程奖励，使得信用分配更加精确，无需使用专门的中间奖励模型；(ii) 噪声感知加权方案，根据每个时间步骤固有的探索潜力对策略优化进行调整，优先在高影响的早期阶段学习，同时确保在后期阶段保持稳定的细化；(iii) 种子组策略，控制初始化效果，以隔离探索贡献。", "conclusion": "这些创新赋予模型时间意识的优化，尊重了生成动态的基础，从而在人类偏好对齐和文本到图像基准测试中取得了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20466", "html_url": "https://arxiv.org/abs/2508.20466", "title": "重谋密化与跨尺度传播：LiDAR点云的实时神经压缩", "title_en": "Re-Densification Meets Cross-Scale Propagation: Real-Time Neural Compression of LiDAR Point Clouds", "authors": "Pengpeng Yu,Haoran Li,Runqing Jiang,Jing Wang,Liang Lin,Yulan Guo", "background": "LiDAR点云在各种应用中至关重要，但高精度扫描会导致显著的存储和传输开销。现有方法通常将无序点转换为分层八叉树或体素结构，以实现密集到稀疏的预测编码，但几何细节的高度稀疏性阻碍了有效的上下文建模，从而限制了其压缩性能和速度。", "innovation": "针对上述挑战，本文提出了一种用于高效预测编码的紧凑特征生成方法。具体包括两个轻量级模块：首先是几何重密化模块，它重新密集编码后的稀疏几何结构，提取更密集尺度的特征，然后对特征进行重新稀疏化，以便进行预测编码。此模块避免了在高度稀疏细节上的昂贵计算，同时保持了一个轻量的预测头。其次是跨尺度特征传播模块，该模块利用多个分辨率级别的占有率线索来引导分层特征传播。这种设计促进了不同尺度间信息的共享，从而减少了冗余特征提取并为几何重密化模块提供了丰富特征。通过将这两个模块集成，本文提出的方法得出了紧凑的特征表示，提供高效的上下文建模并加速编码过程。实验结果表明，该方法在KITTI数据集上达到了最先进的压缩比和实时性能，编码/解码12位量化时可实现26 FPS。", "conclusion": "通过这两种模块的结合，本文的方法有效提供了紧凑的特征表示，实现了高效的上下文建模并加速了编码过程。实验证明，这种方法在KITTI数据集上的压缩比例和实时性能达到了最先进的水平，能够实现每秒26帧的编码/解码速度（12位量化）."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09368", "html_url": "https://arxiv.org/abs/2509.09368", "title": "一种集成了关键帧识别、ONSD测量和临床数据的全自动颅内压分级框架", "title_en": "A Fully Automatic Framework for Intracranial Pressure Grading: Integrating Keyframe Identification, ONSD Measurement and Clinical Data", "authors": "Pengxu Wen,Tingting Yu,Ziwei Nie,Cheng Jiang,Zhenyu Yin,Mingyang He,Bo Liao,Xiaoping Yang", "background": "颅内压（ICP）升高对脑功能构成严重威胁，因此需要进行监测以便及时干预。尽管腰椎穿刺是ICP测量的黄金标准，但其侵入性及其相关风险促使寻找非侵入性替代方案。视神经鞘直径（ONSD）已成为有前景的生物标志物，因为ICP升高与ONSD增加直接相关。然而，当前的临床实践在手动操作不一致、最佳视角选择主观性和阈值设定可变性方面存在不足，这限制了其可靠性。", "innovation": "本文提出了一种全自动两阶段框架来对ICP进行分级，该框架整合了关键帧识别、ONSD测量和临床数据。具体而言，该框架在眼球超声视频处理阶段实现了帧级解剖分割，基于国际共识声明的基于规则的关键帧识别，并进行了精确的ONSD测量。ICP分级阶段则将ONSD指标与临床特征融合，以实现ICP级别的预测。实验结果表明，该方法的验证准确性为0.845 ± 0.071（五折交叉验证的标准差），独立测试准确性为0.786，显著优于传统的基于阈值的方法（验证准确性0.637 ± 0.111，测试准确性0.429）。通过有效地减少操作者的变异性并整合多源信息，该框架为临床ICP评估提供了一个可靠的非侵入性方法，有助于急性神经科疾病的患者管理。", "conclusion": "通过对ICP的自动化分级，该框架展示了可解释的超声分析与多源数据整合的创新结合，为临床评价提供了客观方法。实验结果表明，该方法显著提高了ICP评估的准确性和可靠性，对于急性神经科疾病的患者管理具有潜在益处。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15431", "html_url": "https://arxiv.org/abs/2508.15431", "title": "小凹痕，大影响：用于汽车凹痕检测的数据集和深度学习方法", "title_en": "Small Dents, Big Impact: A Dataset and Deep Learning Approach for Vehicle Dent Detection", "authors": "Danish Zia Baig,Mohsin Kamal,Zahid Ullah", "background": "传统的汽车损伤检测技术耗时、依赖人工且常常忽略细微的表面缺陷。为了应对快速且准确的检测需求，机器学习提供了创新的解决方案。传统的检测方法无法有效检测到小的缺陷，因此需要一种新的方法来提高检测的准确性与效率。研究人员创建了一个包含各种光照条件、角度和纹理的汽车表面标注图片的定制数据集，训练YOLOv8及其定制变体YOLOv8m-t4和YOLOv8m-t42模型来检测汽车外部的微小凹痕。实验结果表明，该方法具有优秀的检测准确性和较低的推理延迟，适合应用于实时评估和汽车检测等场景。", "innovation": "论文提出并使用了YOLOv8对象识别框架，构建了一个专用于汽车表面微小凹痕检测的深度学习算法。通过创建包含多种光照条件、角度和纹理的标注数据集，并应用实时数据增强技术训练YOLOv8m及其定制变体YOLOv8m-t4和YOLOv8m-t42模型，提高了检测的鲁棒性。YOLOv8m-t42模型在检测微小表面缺陷方面表现出更高的精度和更稳定的表现，尽管其收敛速度较慢。", "conclusion": "YOLOv8m-t42模型在检测微小表面缺陷方面具有较高的检测准确率，并且稳定性好于YOLOv8m-t4模型，适合实际的汽车表面凹痕检测应用。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15548", "html_url": "https://arxiv.org/abs/2509.15548", "title": "MS-GS: 在野外的多外观稀视角3D高斯斑点", "title_en": "MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild", "authors": "Deming Li,Kaiwen Jiang,Yutao Tang,Ravi Ramamoorthi,Rama Chellappa,Cheng Peng", "background": "在野外收集的照片集通常包含有限数量的影像，并表现出多种外观，如在一天中的不同时间和季节拍摄的影像，这对场景重构和新颖视角合成构成了重大挑战。虽然最近对神经辐射场（NeRF）和3D高斯点积（3DGS）的适应有所改进，但它们往往过度平滑并容易过拟合。", "innovation": "我们提出了MS-GS，一种利用3DGS设计的新框架，具备在稀视角场景下的多外观能力。我们的方法利用单目深度估计得到的几何先验，并通过Structure-from-Motion（SfM）点锚定算法提取和利用局部语义区域，进行可靠的对齐和几何线索。同时，我们提出了基于细粒度和粗粒度的视图几何指导监督方案，以引入多视角约束，鼓励3D一致性并减少过拟合。此外，我们还提供了一个数据集和一个野外实验设置，以设立更加真实的基准。", "conclusion": "我们证明MS-GS在各种条件下实现了逼真的渲染，并在不同数据集中显著优于现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.16031", "html_url": "https://arxiv.org/abs/2509.16031", "title": "GLip：一种全局-局部集成渐进框架以实现鲁棒的视觉唇读", "title_en": "GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition", "authors": "Tianyue Wang,Shuang Yang,Shiguang Shan,Xilin Chen", "background": "视觉唇读（VSR），也被称为唇读，是指从无声视频中识别语音的任务。尽管在过去的几十年中，VSR取得了显著的进步，但大多数现有方法对真实世界视觉得到的挑战，例如光照变化、遮挡、模糊和姿态变化关注较少。为解决这些问题，提出了一种名为GLip的全新框架，GLip是一个全局-局部集成渐进框架，旨在增强视觉唇读的鲁棒性。", "innovation": "GLip框架基于两个关键洞察：首先，初步学习视觉特征在不同条件下的粗略对齐，有助于在不利条件下精确的视觉-语音映射的学习；其次，在不利条件下，某些局部区域（如未遮挡区域）经常比全局特征更能提供有效的唇读线索。GLip引入了一种双路径特征提取架构，该架构在一个两阶段的渐进学习框架中结合了全局和局部特征。第一阶段模型学习将视觉特征与对应的声学语音单元对齐，从而建立出一个粗略但语义上稳健的基础。第二阶段通过引入上下文增强模块（CEM），动态整合局部特征与相关全局上下文，从空间和时间维度对原始表示进行精确化。", "conclusion": "GLip框架通过渐进学习方式充分利用了鲁棒性的局部区域，对于各种视觉挑战表现出增强的鲁棒性。在LRS2和LRS3基准上，GLip持续优于现有方法，并进一步在新的具有挑战性的普通话数据集上验证了其有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.01986", "html_url": "https://arxiv.org/abs/2509.01986", "title": "Draw-In-Mind: 在统一多模态模型中重新平衡设计师与绘图者角色以提高图像编辑效果", "title_en": "Draw-In-Mind: Rebalancing Designer-Painter Roles in Unified Multimodal Models Benefits Image Editing", "authors": "Ziyun Zeng,Junhao Zhang,Wei Li,Mike Zheng Shou", "background": "近年来，将多模态理解和生成集成到单一统一模型中已经成为一种有前途的范式。虽然这种方法在文本到图像（T2I）生成中取得了出色的结果，但在精细图像编辑方面仍存在问题。其限制被归因于职责分配不均。理解模块主要担任翻译者的角色，将用户指令编码为语义条件，而生成模块则必须同时扮演设计师和画家的角色，推断原始布局，识别目标编辑区域，并渲染新内容。这种不平衡似乎不合理，因为理解模块通常在复杂推理任务上接受的数据量是生成模块的许多倍。为了解决这一问题，我们提出了Draw-In-Mind（DIM），一个包含两个互补子集的数据集：DIM-T2I 包含1400万长上下文的图像文本对，以增强复杂指令理解；DIM-Edit 包含23.3万由GPT-4o生成的逻辑链，作为图像编辑的明确设计蓝图。我们通过一个轻量级的两层MLP将冻结的Qwen2.5-VL-3B与可训练的SANA1.5-1.6B相连并使用我们提出的DIM数据集进行训练，从而产生DIM-4.6B-T2I/Edit。尽管参数规模较小，但DIM-4.6B-Edit在ImgEdit和GEdit-Bench基准测试中取得了SOTA或竞争力的表现，超过了更大的模型如UniWorld-V1和Step1X-Edit。这些结果表明，明确将设计责任分配给理解模块为图像编辑提供了显著的好处。我们的数据集和模型可在该网址获取：this https URL", "innovation": "我们提出了Draw-In-Mind (DIM)，一个集成两个互补子集的数据集：DIM-T2I 和 DIM-Edit。DIM-T2I 包含1400万长上下文的图像文本对，以增强复杂指令理解；DIM-Edit 包含23.3万由GPT-4o生成的逻辑链，作为图像编辑的明确设计蓝图。我们通过轻量级的两层MLP将冻结的Qwen2.5-VL-3B与可训练的SANA1.5-1.6B相连并使用新的DIM数据集进行训练，从而产生了DIM-4.6B-T2I/Edit模型。在ImgEdit和GEdit-Bench基准测试中，尽管参数规模较小，但该模型表现出了SOTA或竞争力的表现，说明了明确分配设计责任的重要性。", "conclusion": "通过重新分配理解模块和生成模块的职责，我们找到了一种有效提升图像编辑效果的方法。我们的数据集和模型开发表明，明确设计责任的分配能够显著改善多模态模型在图像编辑中的表现。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.10779", "html_url": "https://arxiv.org/abs/2509.10779", "title": "组证据很重要：基于分割的语义门控在密集目标检测中的应用", "title_en": "Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection", "authors": "Yilun Xiao", "background": "在无人机图像中，由于长距离视角、遮挡和杂乱等原因，密集的小目标常常被忽视。现有检测方法在处理这些目标时遇到了挑战，尤其是未能充分识别被遮挡或杂乱环境中的低置信度候选目标。因此，迫切需要一种可以弥补这些不足的后处理框架，以提高密集小目标的检测性能。", "innovation": "本文提出了一种面向特定检测器的后处理框架，可以将重叠带来的冗余转化为组证据。该框架包括两个主要阶段：1. 重叠分割首先恢复低置信度请求；2. 使用空间门（基于box中心的DBSCAN）和语义门（基于ResNet-18嵌入的DBSCAN），对验证的组证据进行置信度加权，然后与类感知非最大抑制融合。实验证明，这种方法在VisDrone数据集上，召回率提高了0.093，达到0.778，精度从0.801调整为0.595，F1值为0.669，且后处理延迟平均为0.095秒。", "conclusion": "该后处理框架显示出召回优先、精度下沉的行为，这在远距离计数和监控等召回敏感应用中具有优势。通过消融实验确认了该框架各个组件的有效性，并指出未来工作将降低语义门成本，引入时间线索进行进一步改进。此外，该框架无需重新训练，能够与现代检测器无缝集成。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17283", "html_url": "https://arxiv.org/abs/2509.17283", "title": "使用门检测和大型语言模型的建筑合规检查中的自动化设施统计", "title_en": "Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models", "authors": "Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo", "background": "建筑合规检查（BCC）是确保建筑符合监管标准的关键过程。准确的设施类型枚举及其空间分布是BCC的核心组成部分。尽管重要，但文献中对于这一问题的研究相对较少，这给BCC带来了挑战并留下了关键的缺口。手工完成此任务既耗时又费力。近年来，大型语言模型（LLMs）的进步为通过结合视觉识别和推理能力来增强自动化提供了新机会。", "innovation": "本文提出了一种新的BCC任务：自动化设施统计，其目标是验证各类设施的数量是否符合法定要求。该方法通过结合门检测与基于LLM的推理来实现。这是首次将LLMs应用于此任务，并通过Chain-of-Thought（CoT）流水线进一步提升其性能。本方法在不同数据集和建筑类型上具有很好的泛化能力。实验结果表明，该方法在真实世界和合成的平面图数据上均具有有效性及鲁棒性。", "conclusion": "本文提出了一种通过门检测和大型语言模型实现的自动化设施统计方法。该方法不仅首次应用于此类任务，还通过CoT流水线显著提升了性能。实验验证了该方法在不同数据集上的广泛应用性和鲁棒性，为BCC流程中的自动化提供了新的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20745", "html_url": "https://arxiv.org/abs/2509.20745", "title": "Neptune-X: 积极X到海洋的生成以实现泛化的海洋物体检测", "title_en": "Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection", "authors": "Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang", "background": "海洋物体检测对于航行安全、监控和自主操作至关重要，但受制于两个关键挑战：标注海洋数据的稀缺性和在各种海洋属性（如物体类别、视角、位置以及成像环境）之间的不佳泛化能力。", "innovation": "本文提出了Neptune-X，一种数据为中心的生成-选择框架，通过结合合成数据生成与任务感知样本选择，增强训练效果。开发了X-to-Maritime多模式条件生成模型，用于合成多样且逼真的海洋场景。其中包括一种双向物体-水注意力模块，用于捕捉物体与其水环境之间的边界交互，提高视觉真实性。同时，还提出了与属性关联的活跃采样，动态选择任务相关的合成样本以进一步提升下游任务性能。为此，构建了专用的数据集——海洋生成数据集，覆盖广泛的概念条件。", "conclusion": "全面的实验表明，本文的方法在海洋场景合成方面达到了新的基准，显著提高了检测精度，特别是在具有挑战性的和之前未充分覆盖的场景中。源代码可访问此链接：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15472", "html_url": "https://arxiv.org/abs/2509.15472", "title": "通过生成模型实现高效多模态数据集蒸馏", "title_en": "Efficient Multimodal Dataset Distillation via Generative Models", "authors": "Zhenghao Zhao,Haoxuan Wang,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan", "background": "数据集蒸馏旨在从大规模数据集中合成一个小数据集，以便在该小数据集上训练的模型能在原始数据集上表现良好。随着大型语言模型和多模态大型语言模型的兴起，多模态数据集，尤其是图像-文本数据集的重要性显著增加。然而，现有的多模态数据集蒸馏方法受限于匹配训练轨迹算法，这大大增加了计算资源的需求，使数据集蒸馏需要数天时间处理。因此，多模态数据集的高效蒸馏成为了一个迫切的研究问题。", "innovation": "我们介绍了一种名为EDGE的生成模型蒸馏方法，用于高效多模态数据集蒸馏。为了应对生成模型蒸馏多模态数据集时遇到的两大挑战：1) 生成的图像和字幕之间的缺乏关联性。2) 生成样本的缺乏多样性。我们提出了一种新的生成模型训练工作流，包括双向对比损失和多样性损失。此外，我们提出了一种字幕合成策略，通过引入更多的文本信息来进一步提高从文本到图像的检索性能。我们的方法在Flickr30K、COCO和CC3M数据集上的评估表明，与现有方法相比，我们的方法表现更优且更高效，并且实现了比最先进的方法快18倍的结果。", "conclusion": "我们提出了EDGE方法，该方法采取新颖的生成模型训练工作流，并结合多样性和双向对比损失，有效解决了生成模型蒸馏多模态数据集时的困难，提升了文本到图像的检索性能，并且在多重数据集上展示了更好的性能和效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17513", "html_url": "https://arxiv.org/abs/2509.17513", "title": "4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming", "title_en": "4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming", "authors": "Zihan Zheng,Zhenlong Wu,Houqiang Zhong,Yuan Tian,Ning Cao,Lan Xu,Jiangchao Yao,Xiaoyun Zhang,Qiang Hu,Wenjun Zhang", "background": "实现高保真体积视频的无缝观看，体验类似于2D视频，仍然是一个待解决的挑战。现有体积视频压缩方法要么在同一个模型中无法灵活调整质量与码率以实现不同网络和设备上的高效流式传输，要么在轻量级移动平台上难以实现实时解码与渲染。", "innovation": "提出了一种新型的4D高斯压缩框架4DGCPro，该框架简化了移动设备上的实时解码与高质量渲染，并通过单个位流实现渐进的体积视频流式传输。具体来说，该框架提出了一种感知加权的、压缩友好的4D高斯表示，带有运动感知的自适应分组，以减少时间冗余，保持连贯性，并实现可扩展多级细节流式传输。此外，提出了一种端到端的熵优化训练方案，该方案融入了分层率-失真(RD)监督和属性特定熵建模，以实现高效的位流生成。", "conclusion": "关于4DGCPro的实验表明，该方法能够在单个模型中实现灵活的质量和多码率，并在多种数据集上实现优于现有方法的率-失真性能，同时在移动设备上可以实现实时解码与渲染。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14981", "html_url": "https://arxiv.org/abs/2509.14981", "title": "SPATIALGEN：基于布局引导的3D室内场景生成", "title_en": "SPATIALGEN: Layout-guided 3D Indoor Scene Generation", "authors": "Chuan Fang,Heng Li,Yixun Liang,Jia Zheng,Yongsen Mao,Yuan Liu,Rui Tang,Zihan Zhou,Ping Tan", "background": "创建高保真度的3D室内环境模型对于设计、虚拟现实和机器人技术等领域至关重要。然而，手工构建3D模型仍然耗时且劳动密集。虽然最近的生成AI进展使得场景合成自动化成为可能，但现有方法在视觉质量、多样性、语义一致性以及用户控制方面仍面临挑战。一个主要瓶颈在于缺乏针对此任务的大规模高质量数据集。为了解决这一问题，我们引入了一个综合的合成数据集，包含12,328个结构化标注场景，共有57,440个房间和470万张写实的一维图像。基于此数据集，我们提出了一种新型的多视角多模态扩散模型——SpatialGen，它可以生成真实且语义一致的3D室内场景。给定3D布局和参考图像（来自文本提示），我们的模型可以以任意视角生成颜色图、几何（场景坐标图）和语义（语义分割图），同时在不同模态之间保持空间一致性。实验结果表明，SpatialGen在各项指标上均优于之前的大部分方法。", "innovation": "我们创建了一个包含12,328个结构化标注场景的综合合成数据集，其中包含57,440个房间和470万张写实的一维图像；基于此数据集提出了SpatialGen模型，它是使用多视角多模态扩散模型生成真实且语义一致的3D室内场景，给定3D布局和参考图像，模型可以多视角生成颜色图、几何和语义，并保持空间一致性。该方法相较于之前的大部分模型有显著提升。", "conclusion": "通过发布数据和模型，我们希望赋能社区，推动室内场景理解与生成领域的进步。SpatialGen在多项实验中表现出优越的结果，证明了其在3D室内场景生成上的强大性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17792", "html_url": "https://arxiv.org/abs/2509.17792", "title": "基于隐含先验编码的aware于退化的全一正交图像恢复", "title_en": "Degradation-Aware All-in-One Image Restoration via Latent Prior Encoding", "authors": "S M A Sharif,Abdur Rehman,Fayaz Ali Dharejo,Radu Timofte,Rizwan Ali Naqvi", "background": "现实世界的图像常常遭受空间多样性退化的影响，例如雾霾、雨、雪和低光照，这对视觉质量和下游视觉任务产生了显著的影响。现有的所有一正交恢复（AIR）方法要么依赖外部文本提示，要么嵌入手工制作的架构先验（例如频率启发式），这些都带来了离散且脆弱的假设，使得在未见过的或混合退化情况下的泛化能力较弱。", "innovation": "提出将AIR重新框架为通过输入自动推算的隐含先验推理，其中退化感知表示不需要明示的任务提示即可自动从输入中推断出来。基于隐含先验，我们提出了AIR作为一种结构化推理范式：（1）哪些特征要路由（自适应特征选择），（2）在哪里恢复（空间定位），（3）要恢复什么（退化语义）。此外，设计了一个轻量级的解码模块，以高效地利用这些隐含编码线索进行空间自适应恢复。广泛的实验证明，本方法在六个常见退化任务、五个复合设置和以前未见过的退化中均优于现有最先进的方法，平均提高了1.68 dB的PSNR，同时效率提高了三倍。", "conclusion": "本工作提出了一种基于隐含先验编码的退化感知全一正交图像恢复方法，通过自适应的空间和特征选择、位置定位以及退化语义恢复，有效地提高了图像恢复质量，同时显著提升了效率。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20280", "html_url": "https://arxiv.org/abs/2509.20280", "title": "HiPerformer: 一种具有模块化分层融合策略的高性能全局-局部分割模型", "title_en": "HiPerformer: A High-Performance Global-Local Segmentation Model with Modular Hierarchical Fusion Strategy", "authors": "Dayu Tan,Zhenpeng Xu,Yansen Su,Xin Peng,Chunhou Zheng,Weimin Zhong", "background": "医学图像分割需要同时考虑局部细节和全局上下文，实现两者有效整合对于获得高精度至关重要。现有的基于CNN-Transformer混合架构的主要方法通常采用简单的特征融合技术（如顺序堆叠、端点连接或点乘），这些技术难以解决特征不一致问题，容易导致信息冲突和损失。", "innovation": "我们创新地提出了HiPerformer。其编码器采用一种新颖的模块化分层架构，能够并行动态融合多源特征，实现层次间的深层异质信息整合，既保留了每个分支的独立建模能力，又确保了足够的信息传递，有效避免了传统堆叠方法带来的特征退化和信息损失问题。此外，我们设计了局部-全局特征融合（LGFF）模块，实现局部细节和全局语义信息的精确高效融合，有效缓解了特征不一致性问题，提升了特征表示的全面性。为了进一步增强多尺度特征表示能力和抑制噪声干扰，我们还提出了逐进金字塔聚合（PPA）模块来替代传统的跳连接。实验结果在11个公开数据集上的表现证明了所提方法优于现有分割技术，表现出更高的分割精度和鲁棒性。", "conclusion": "本文提出的方法在多种公开数据集上的实验验证了其更高的分割精度和鲁棒性，且实现了局部细节与全局语义信息的有效融合，并增强了多尺度特征表示能力。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20295", "html_url": "https://arxiv.org/abs/2509.20295", "title": "FAST: 与加速采样轨迹相关的前景意识扩散技术用于面向分割的异常合成", "title_en": "FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory for Segmentation-oriented Anomaly Synthesis", "authors": "Xichen Xu,Yanshu Wang,Jinbao Wang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu", "background": "工业异常分割高度依赖于像素级标注，但实际应用场景中的异常往往稀缺、多样化且标注成本高昂。现有方法难以在采样效率和生成质量之间取得平衡。大多数方法假设所有空间区域均一处理，忽视了异常和背景区域之间明显的统计差异。这种均一处理阻碍了能够针对分割任务进行控制的结构特定异常的合成。因此，需要一种新的方法来改善这一状况，使得异常合成能兼顾高效性和准确性，同时能够更好地捕捉和保留局部异常信号。", "innovation": "我们提出了FAST框架，该框架包含两个新型模块：1）Anomaly-Informed Accelerated Sampling (AIAS)：一种无需训练的采样算法，通过从粗到细的聚集加速了反向过程，能够在10步内生成最先进的分割导向异常。2）Foreground-Aware Reconstruction Module (FARM)：能够在每个采样步骤中自适应调整带掩码前景区域内的异常感知噪声，确保在去噪过程中保留局部异常信号。", "conclusion": "我们的实验展示了FAST在多个工业基准上的优秀表现，表明其在分割任务中的异常合成性能优于现有技术。我们已在代码仓库发布FAST的相关代码：this https URL."}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.19665", "html_url": "https://arxiv.org/abs/2509.19665", "title": "深学习在甲烷卫星和机载成像光谱学中云和云阴影分割中的应用", "title_en": "Deep Learning for Clouds and Cloud Shadow Segmentation in Methane Satellite and Airborne Imaging Spectroscopy", "authors": "Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy", "background": "准确检测大气甲烷或其它痕量气体的高空谱遥感数据中的云和云阴影是至关重要的。这对于即将发射的MethaneSAT及其机载同伴任务MethaneAIR尤为重要。现有的遥感数据处理中，云和云阴影的识别效率直接影响甲烷测量的准确性及排放量化。本研究使用机器学习方法，特别是针对高空间分辨率传感器的云和云阴影检测问题，评估了多种经典技术与先进深度学习模型的效果。", "innovation": "研究部署并评估了包括迭代逻辑回归（ILR）、多层感知器（MLP）在内的经典方法，以及UNet和光谱通道注意网络（SCAN）等先进深度学习架构。结果表明经典方法在保持空间结构和边界定义方面存在挑战，而深度学习模型显著提升了检测质量，尤其SCAN结合光谱注意力进一步提升了对MethaneSAT数据中云和云阴影的检测效果。研究深入评估了各种不同机器学习技术的优势，证明先进的深度学习架构能在云和云阴影检测领域提供稳健及可扩展的解决方案，以增强下一代高空谱任务对甲烷排放量化的识别能力。", "conclusion": "研究结果证明了不同机器学习技术的优势及有效性，特别是在解决甲烷卫星和机载成像光谱学中云和云阴影检测任务方面，先进的深度学习架构能够提供稳健且可扩展的解决方案，从而增强现有和下一代高空谱任务对甲烷排放量化的识别能力。所有数据和代码公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.15274", "html_url": "https://arxiv.org/abs/2404.15274", "title": "基于度量指导的配准边界用于概率图像重建", "title_en": "Metric-Guided Conformal Bounds for Probabilistic Image Reconstruction", "authors": "Matt Y Cheung,Tucker J Netherton,Laurence E Court,Ashok Veeraraghavan,Guha Balakrishnan", "background": "现代的深度学习重构算法能够从稀疏输入中生成令人印象深刻的现实扫描图像，但它们也会产生显著的不准确性。这使得从这些算法重构的扫描中得出统计保证的真实状态声明变得困难。在本文中，我们提出了一个框架，用于计算从概率黑盒图像重建算法推导出的声明的有效验证边界。", "innovation": "我们框架的关键见解在于用感兴趣的临床度量表示重构的扫描，并使用先验校准数据集通过一致预测（CP）校准度量的真实值边界。这些边界提供了关于受试者状态的可解释反馈，也可以用于检索邻近重构扫描进行视觉检查。此外，我们的框架在稀疏视图计算机断层扫描（CT）的脂肪质量量化和放射治疗规划任务上证明了其实用性。", "conclusion": "我们的框架产生的边界在语义解释方面优于传统的基于像素的边界方法。此外，它可以标记出看似合理的但统计数据上不太可能的度量值的危险异常重构。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.18788", "html_url": "https://arxiv.org/abs/2409.18788", "title": "野地挖掘：用于语义分割的GOOSE-Ex数据集", "title_en": "Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation", "authors": "Raphael Hagmanns,Peter Mortimer,Miguel Granero,Thorsten Luettel,Janko Petereit", "background": "深度学习技术在自主系统中的成功部署高度依赖于其部署环境中的数据可用性。特别是在未结构化的户外环境中，很少有数据集涵盖各种机器人平台和场景。我们在早期的工作中介绍了德国野外和越野数据集(GOOSE)框架，并提供了来自越野车辆的10000个跨模态帧，以增强在未结构化环境中的感知能力。", "innovation": "本文提出开源自带5000个跨模态标记帧的GOOSE-Ex数据集，这些帧记录在各种不同环境中（包括起重机和四足平台），涵盖了更多的场景。通过这个数据集，研究人员可以评估不同平台和传感器模态在未知环境中的语义分割表现，并展示了其用于不同的下游应用程序或竞赛（如越野导航、物体操作或场景补全）的潜力。此外，该数据集、平台文档和预训练最先进的越野感知模型将在此链接中提供下载。", "conclusion": "研究展示了GOOSE和GOOSE-Ex数据集在语义分割上的一般适用性，并提供了广泛的下游应用程序应用示例。数据集及其平台文档和最先进的预训练模型将公开可用于进一步的研究。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.22376", "html_url": "https://arxiv.org/abs/2410.22376", "title": " Rare-to-Frequent: 使用大型语言模型指导解锁扩散模型在罕见概念生成能力上的潜能", "title_en": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "authors": "Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho", "background": "现有的文本到图像（T2I）扩散模型在生成具有不常见组合的概念，例如具有不寻常属性的对象时，往往表现不佳。", "innovation": "本文提出了一种名为R2F的无需训练的方法，通过利用LLM中的丰富语义知识，在扩散推理过程中规划和执行从罕见到常见的概念指导，显著提升了扩散模型对罕见概念的组合生成能力。该框架适用于任何预训练的扩散模型和LLM，且可以无缝集成到区域指导扩散方法中。在三个数据集中，尤其是作者新提出的基准RareBench上的实验结果表明，R2F显著优于包括SD3.0和FLUX在内的现有模型，T2I对齐度提高了28.1%。", "conclusion": "通过LLM指导下的罕见到常见概念规划和执行，本框架显著提高了扩散模型对罕见概念的组合生成能力，且在多个数据集上表现优异，超越了现有的模型。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10434", "html_url": "https://arxiv.org/abs/2503.10434", "title": "通过人类反馈的强化学习学习个性化驾驶风格", "title_en": "Learning Personalized Driving Styles via Reinforcement Learning from Human Feedback", "authors": "Derun Li,Changye Li,Yue Wang,Jianwei Ren,Xin Wen,Pengxiang Li,Leimeng Xu,Kun Zhan,Peng Jia,Xianpeng Lang,Ningyi Xu,Hang Zhao", "background": "在动态环境中，生成类人类且适应性强的行驶轨迹对于自动驾驶至关重要。虽然生成模型在合成可行轨迹方面表现出潜力，但它们往往难以捕捉到个性化驾驶风格的细微变化，部分原因是由于数据集偏差和分布偏移。", "innovation": "该文提出了TrajHF，一种基于人类反馈的生成轨迹模型微调框架，旨在与多样的驾驶风格对齐。TrajHF结合了多条件去噪和强化学习，通过人类反馈来改进多模态轨迹生成，超越了传统的模仿学习，从而更好地与人类驾驶偏好保持一致，同时保持安全和可行性约束。", "conclusion": "TrajHF在NavSim基准测试中取得了与最先进的方法相当的表现。TrajHF为自动驾驶中个性化和适应性强的轨迹生成设定了新的范式。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21113", "html_url": "https://arxiv.org/abs/2509.21113", "title": "MOSS-ChatV: 用于视频时序推理的基于过程推理奖励的强化学习", "title_en": "MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning", "authors": "Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu", "background": "视频推理已成为多模态大型语言模型（MLLMs）的关键能力，要求模型能够超越静态感知，以连贯的方式理解复杂场景中的时间动态。然而，现有的MLLMs经常表现出过程不一致的问题，即使最终答案正确，中间推理也会偏离视频动态，从而影响可解释性和鲁棒性。", "innovation": "我们引入了MOSS-ChatV，这是一种基于动态时间规整（DTW）的过程奖励强化学习框架，通过规则基于的过程奖励对推理轨迹与时间接地参考进行对齐，从而实现高效的进程监督。我们还确定了动态状态预测是视频推理的关键指标，并构建了MOSS-Video基准，其中训练分割用于微调MOSS-ChatV，保留分割用于评估。MOSS-ChatV在MOSS-Video（测试）中达到87.2%的性能，并在MVBench和MMVU等通用视频基准测试中提高了性能。该框架在不同的架构中一致地取得了收益，证实了其广泛的应用性。", "conclusion": "与GPT-4o-as-judge的评估进一步表明，MOSS-ChatV生成了更一致和稳定的推理轨迹。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20360", "html_url": "https://arxiv.org/abs/2509.20360", "title": "EditVerse: 使用上下文学习统一图像和视频编辑与生成", "title_en": "EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning", "authors": "Xuan Ju,Tianyu Wang,Yuqian Zhou,He Zhang,Qing Liu,Nanxuan Zhao,Zhifei Zhang,Yijun Li,Yuanhao Cai,Shaoteng Liu,Daniil Pakhomov,Zhe Lin,Soo Ye Kim,Qiang Xu", "background": "近期的研究进展表明，基础模型正朝着统一化和规模化的趋势发展，展示出跨多种领域的能力。尽管图像生成和编辑已迅速从特定任务转变为统一框架，但视频生成和编辑领域仍然因为架构局限性和数据稀缺性而保持分裂状态。这项工作中，研究者提出了EditVerse，一个在单一模型中统一处理图像和视频生成与编辑的框架。通过将所有模态，包括文本、图像和视频，统一表示为标记序列，并利用自我注意机制进行学习，EditVerse实现了健壮的上下文学习、自然的跨模态知识转移以及灵活处理任意分辨率和持续时间的输入和输出。为了弥补视频编辑训练数据的缺乏，研究者设计了一种可扩展的数据管道，集成了232,000个视频编辑样本，并将它们与大规模的图像和视频数据集联合训练。在此基础上，研究者还提出了EditVerseBench，这是第一个覆盖多样任务和分辨率的基于指令的视频编辑基准测试。广泛的实验和用户研究证实了EditVerse的非凡性能，不仅超越了现有开源和商业模型，还在跨模态编辑和生成方面展示出了新兴能力。", "innovation": "提出了一个单一模型框架EditVerse，用于同时处理图像和视频的编辑与生成。该框架通过将所有模态统一表示为标记序列并利用自我注意机制，实现了健壮的上下文学习、自然的跨模态知识转移以及灵活处理任意分辨率和持续时间的输入和输出。设计了一个可扩展的数据管道，集成了232,000个视频编辑样本和大规模的数据集，用于联合训练。还提出了一种视频编辑指令基准测试EditVerseBench。广泛的实验和用户研究显示了EditVerse的优越性能和新兴能力。", "conclusion": "EditVerse实现了一流的性能并展现出在跨模态编辑和生成上的新能力，超越了现有开源和商业模型。该研究为进一步开发视频编辑和生成的统一框架提供了新的方向。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.04692", "html_url": "https://arxiv.org/abs/2312.04692", "title": "Diffence: 使用扩散模型保护会员隐私", "title_en": "Diffence: Fencing Membership Privacy With Diffusion Models", "authors": "Yuefeng Peng,Ali Naseh,Amir Houmansadr", "background": "深度学习模型虽然表现优异，但容易遭受成员推理攻击 (MIAs)。尽管已经提出了多种防御措施，但在隐私-实用性权衡方面仍有改进的空间。", "innovation": "本文提出了一种利用生成模型的新防御框架——DIFFENCE，旨在通过重新生成输入样本来消除成员与非成员输入之间的差异，从而在预测之前防御MIAs。与之前的防御措施不同，DIFFENCE只在输入样本阶段工作，不修改目标模型的训练或推理阶段。此外，它还保留了模型的预测标签，不影响准确性，同时不会降低置信向量的价值。实验结果显示，DIFFENCE是一个鲁棒且易于使用的防御机制，能够增强会员隐私而不牺牲模型的实用性。", "conclusion": "本文通过广泛的实验，证明DIFFENCE能够降低MIAs的准确性和AUC值，例如，在未受保护的模型上降低了15.8%和14.0%，并且通过与现有防御机制的集成，能够实现新的性能标杆。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.02904", "html_url": "https://arxiv.org/abs/2503.02904", "title": "手术视觉世界模型", "title_en": "Surgical Vision World Model", "authors": "Saurabh Koju,Saurav Bastola,Prashant Shrestha,Sanskar Amgain,Yash Raj Shrestha,Rudra P. K. Poudel,Binod Bhattarai", "background": "现实且互动的手术模拟在医学专业培训和自主手术代理培训等方面有巨大潜力。在自然视觉领域，世界模型已经通过行动控制的数据生成实现了行动控制的数据生成，但在手术领域，这些工作主要局限于简化计算机模拟，并缺乏真实感。此外，现有的世界模型大多处理带有动作标签的数据，这限制了它们在手术数据中的应用，而手术数据的动作标注获取成本极高。", "innovation": "本文提出了手术视觉世界模型，该模型可以生成行动可控的手术数据。受到最近Genie利用未标记的游戏视频数据推断潜在动作以实现行动控制数据生成的成功启发，该模型能够在无标记的SurgToolLoc-2022数据集上通过广泛实验验证其架构设计能力，并提供了代码和实施细节。", "conclusion": "所提出的手术视觉世界模型能够在很大程度上解决现有技术中由于获取标记数据成本高以及缺乏现实感的问题，为手术模拟和自主手术代理培训提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23768", "html_url": "https://arxiv.org/abs/2503.23768", "title": "纹理还是语义？视觉语言模型在字体识别中迷失方向", "title_en": "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition", "authors": "Zhecheng Li,Guoxian Song,Yujun Cai,Zhen Xiong,Junsong Yuan,Yiwei Wang", "background": "现代视觉-语言模型（VLMs）在图像识别和对象定位等任务中表现出了显著的视觉和语言能力。然而，它们在细节任务中的表现仍是一个悬而未决的问题。举例来说，在日常场景中，人们希望识别设计材料中使用的美学字体，如杂志、字体教程、研究论文或品牌内容。鉴于VLMs的多模态能力和免费特性，它们被认为是潜在的字体识别工具。因此，需要明确VLMs是否真正具备识别字体的能力。", "innovation": "本文引入了一个名为Font Recognition Benchmark（FRB）的紧凑且结构良好的数据集，包含15个常用字体的两种版本：一是容易版本，展示10个句子的不同字体；二是困难版本，每个文本样本包含15个字体的名字，引入了Stroop效应，挑战模型感知能力。通过广泛评估不同VLMs在字体识别任务中的表现，本文得出以下关键发现：1. 当前的VLMs在字体识别方面的表现有限，许多最先进的模型无法达到令人满意的效果，并容易受到文本信息引入的Stroop效应的影响。2. 少量学习和链式思考提示对不同VLMs的字体识别准确性改善作用甚微。3. 注意力分析揭示了VLMs在捕捉语义特征方面的固有限制。", "conclusion": "本文通过Font Recognition Benchmark评估了现有VLMs在字体识别任务中的表现，发现了VLMs在识别字体方面的局限性，包括Stroop效应对模型识别能力的影响、少量学习和链式思考提示的无效性以及VLMs在捕捉语义特征方面的局限性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20470", "html_url": "https://arxiv.org/abs/2405.20470", "title": "STHN: 基于卫星图像的无人机红外热成像地理定位的深度 homography 估计", "title_en": "STHN: Deep Homography Estimation for UAV Thermal Geo-localization with Satellite Imagery", "authors": "Jiuhong Xiao,Ning Zhang,Daniel Tortei,Giuseppe Loianno", "background": "无人机在户外应用（如搜索和救援、电力线检查和环境监测）中的准确地理位置至关重要。由于全球导航卫星系统（GNSS）信号容易受到干扰和欺骗，因此需要开发额外的鲁棒定位方法以支持自主导航。基于视觉的地理定位（VG）通过利用机载摄像头和参考卫星地图提供了一种有希望的绝对定位解决方案。特别是，基于热像图与卫星数据库之间基于图像匹配的热地理定位（TG）方法，在夜间利用红外摄像机进行有效定位时表现突出。然而，当前的 TG 方法效率和效果受限于卫星地图的密集采样和热查询图中的几何噪声。为克服这些挑战，我们提出了 STHN，一种新的无人机热地理定位方法，它采用了一种粗到精的深度 homography 估计方法，即使在热图和卫星地图之间存在11%的尺寸比差异以及模糊纹理和自相似模式的情况下，也能在无人机上次已知位置周围512米的范围内实现可靠的热地理定位。", "innovation": "我们提出了 STHN，一种新的无人机热地理定位方法，该方法采用了一种粗到精的深度 homography 估计方法，即使在热图和卫星地图之间存在11%的尺寸比差异以及模糊纹理和自相似模式的情况下，也能在无人机上次已知位置周围512米的范围内实现可靠的热地理定位。这项研究进一步展示了如何在低可见度条件下提高无人机热地理定位的性能和对抗几何噪声的鲁棒性。并且研究结果已公开发布。", "conclusion": "我们的研究显著提高了在低可见度条件下无人机热地理定位的性能和鲁棒性，即使在存在模糊纹理和自相似模式的情况下。通过提供公共代码，我们开放了进一步研究和应用的机会。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17659", "html_url": "https://arxiv.org/abs/2505.17659", "title": "Plan-R1: 安全可行的轨迹规划作为语言建模", "title_en": "Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling", "authors": "Xiaolong Tang,Meina Kan,Shiguang Shan,Xilin Chen", "background": "在现实世界的自主驾驶系统中，安全和可行的轨迹规划至关重要。现有的基于学习的计划方法依赖于专家演示数据，这些方法不仅缺乏明确的安全意识，而且还存在继承不理想的人类驾驶行为的风险。", "innovation": "本文提出了Plan-R1，这是一种两阶段的轨迹规划框架，将原理对齐与行为学习分离。第一阶段使用专家数据预训练一个通用轨迹预测器，以捕捉多种多样的、人性化驾驶行为。第二阶段则是通过基于规则的奖励进行微调，并使用Group Relative Policy Optimization (GRPO)，显式地将自主规划与安全、舒适的原则对齐。此外，本文还提出了一种新的Variance-Decoupled GRPO (VD-GRPO) 方法，以解决直接应用GRPO的问题，并在训练过程中保留绝对奖励的大小，确保关键安全目标的主导地位。", "conclusion": "在nuPlan基准测试上进行的实验表明，Plan-R1 显著提高了规划的安全性和可行性，特别是在现实反应性场景中达到了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.19375", "html_url": "https://arxiv.org/abs/2409.19375", "title": "DOTA:分布测试时适应的视觉语言模型", "title_en": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "authors": "Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang", "background": "视觉语言基础模型（VLMs）如CLIP在各种任务中表现出色，但在训练数据和测试数据分布不一致时，部署这些模型可能会不可靠。虽然针对多样场景进行微调是降低成本的有效方法，但这种方法往往代价高昂。基于缓存的测试时间适配器存储代表性测试样本以指导后续分类，但通常使用简单的缓存管理，导致在更新过程中样本被删除时严重发生灾难性遗忘。", "innovation": "本文提出了一种简单而有效的方法——分布测试时适应（DOTA），该方法通过持续估计测试数据流的基本分布来解决这一限制，而非仅记忆单独的测试样本。利用贝叶斯定理通过这些动态估计的分布计算带后验概率的测试时间后验概率进行适应。这种以分布为中心的方法使模型能够不断学习并适应部署环境。", "conclusion": "广泛的经验验证表明，DOTA显著减轻了遗忘，并在性能上超越了现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20787", "html_url": "https://arxiv.org/abs/2509.20787", "title": "实时目标检测结合DINOv3", "title_en": "Real-Time Object Detection Meets DINOv3", "authors": "Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen", "background": "DEIM（Dynamic Efficient Image Model）已经成为了实时DETR（Detection Transformers）训练框架的主流，因其简洁有效而显著优于YOLO系列模型。现有研究在此基础上进行了扩展，特别是引入了DINOv3特征，开发了DEIMv2。DEIMv2覆盖了从X到Atto的八种不同模型大小，适用于GPU、边缘设备和移动设备等多种应用场景。", "innovation": "1. 通过采用DINOv3的预训练或精炼的backbone，并引入Spatial Tuning Adapter（STA），DEIMv2高效地将单一尺度输出转换为多尺度特征，增强了检测的语义强度和细微细节。\n2. 对于超轻量化模型（Nano, Pico, Femto, Atto），使用HGNetv2进行深度和宽度裁剪，以满足严格的资源预算限制。\n3. 结合简化解码器和升级的Dense O2O，统一设计使得DEIMv2在不同场景下实现了性能和成本之间的最优平衡，取得了新的SOTA结果。\n4. DEIMv2-X模型在仅50.3百万个参数的情况下达到了57.8的AP值，超过了之前需要超过60百万个参数而且仅达到56.5 AP的X尺度模型。\n5. DEIMv2-S模型是第一个在COCO数据集上超过50 AP且参数少于10百万的模型，其参数仅9.71百万。\n6. 即使是超轻量级的DEIMv2-Pico，仅1.5百万参数也能达到38.5 AP，与使用约2.3百万参数的YOLOv10-Nano相比，参数减少约50%。", "conclusion": "DEIMv2的成功展示了一种适用于不同场景的统一轻量化检测设计，通过显著降低参数数量，提高了检测性能，同时保持了高效率，为实时目标检测领域带来了新的突破。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.01086", "html_url": "https://arxiv.org/abs/2406.01086", "title": "基于范数采样和正交性的多样化子集选择", "title_en": "Diverse Subset Selection via Norm-Based Sampling and Orthogonality", "authors": "Noga Bar,Raja Giryes", "background": "大规模标注数据集对于深度神经网络的成功至关重要，但在医疗成像等某些领域，数据标注的成本可能是巨大的障碍。本文关注子集选择问题，即从大量未标注的数据池中选择最具有信息量的少量示例进行标注。", "innovation": "提出了一种简单有效的基于特征范数、随机化和正交性的(DGSR)方法来选择多样化和具有信息量的样本。利用特征范数作为信息量的代理，随机化和正交化降低冗余并促进特征空间的覆盖。", "conclusion": "在包括CIFAR-10/100、Tiny ImageNet、ImageNet、OrganAMNIST和Yelp在内的图像和文本基准测试中进行的大量实验表明，该方法在单独使用和与现有技术结合使用时，都能一致地提高子集选择性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08334", "html_url": "https://arxiv.org/abs/2506.08334", "title": "iTACO: 从随意拍摄的RGBD视频中获取可交互的运动物体数字孪生", "title_en": "iTACO: Interactable Digital Twins of Articulated Objects from Casually Captured RGBD Videos", "authors": "Weikun Peng,Jun Lv,Cewu Lu,Manolis Savva", "background": "运动物体在日常生活中非常普遍。可交互的数字孪生物体在具身人工智能和机器人领域有广泛应用。目前的数字化方法需要精心捕获的数据，限制了其实用性和可扩展性。本文主要研究从手持摄像头随意拍摄的RGBD视频中分析运动物体的运动和部分分割。", "innovation": "本文提出了iTACO：一种粗到细框架，可以从动态RGBD视频中推断关节参数并分割可移动部件。该框架特别适用于场景中同时存在物体和摄像机运动以及显著遮挡的人与物体交互的情况。此外，还构建了一个包含784个视频和284个对象（涵盖11个类别）的数据集，规模是现有工作的20倍。", "conclusion": "实验结果表明，iTACO在合成和随意拍摄的RGBD视频中都优于现有的运动物体数字孪生方法。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.08074", "html_url": "https://arxiv.org/abs/2410.08074", "title": "不稳定的忘记：扩散模型中概念复现的隐藏风险", "title_en": "Unstable Unlearning: The Hidden Risk of Concept Resurgence in Diffusion Models", "authors": "Vinith M. Suriyakumar,Rohan Alur,Ayush Sekhari,Manish Raghavan,Ashia C. Wilson", "background": "文本到图像的扩散模型依赖于大规模、互联网规模的数据集。从零开始训练它们计算成本高昂，因此开发者通常更倾向于对现有模型进行增量更新。这些更新通常包括精调步骤（学习新概念或提高模型性能）和“忘记”步骤（“忘记”现有概念，如受版权保护的作品或明显的内容）。在这一工作中，我们展示了在这一范式中出现的一个关键且未知的漏洞：在看似无关的图像上对文本到图像的扩散模型进行调整，即使在非对抗性条件下，也可能会导致模型重新学习被忽略的概念。我们通过一系列实验来研究这种现象的原因和范围，这些实验将“概念忘记”与随后对Stable Diffusion v1.4和Stable Diffusion v2.1的精调结合起来。我们的发现突显了逐步更新模型的脆弱性，并对当前确保文本到图像扩散模型安全和对齐的方法提出了严重的关切。", "innovation": "在这项工作中，作者揭示了一种先前未知的现象——概念复现，并通过一系列实验对这一现象进行了全面调查。这种方式结合了“概念遗忘”与后续对不同的Stable Diffusion版本的精调，展示了在看似不相关图像上的调整是如何导致模型重新学习被遗忘的概念的。这项研究揭示了逐步更新模型的脆弱性，并提出了关于确保文本到图像扩散模型安全和对齐的新挑战。", "conclusion": "这项研究强调了在逐步更新扩散模型时的脆弱性，并表明以前的“忘记”步骤并不能保证模型的长期稳定和安全。这对当前保证文本到图像扩散模型对齐的方法提出了新的质疑，需要开发新的机制或方法来防止这种概念复现现象。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23692", "html_url": "https://arxiv.org/abs/2505.23692", "title": "Mobi-$π$：移动您的机器人学习策略", "title_en": "Mobi-$π$: Mobilizing Your Robot Learning Policy", "authors": "Jingyun Yang,Isabella Huang,Brandon Vu,Max Bajracharya,Rika Antonova,Jeannette Bohg", "background": "学习到的视觉-运动策略能够执行越来越复杂的操作任务，但大多数策略都是基于有限的机器人位置和摄像机视角采集的数据进行训练的。这导致这些策略在遇到新位置的机器人时表现不佳，限制了它们在移动平台上的应用，尤其是对于精细任务如按按钮或拧水龙头等。因此，需要一种能够在新环境中灵活操作的方法。", "innovation": "本文提出了策略移动问题：在新环境下找到一个与训练好的操作策略（仅在有限的摄像机视角下训练）分布一致的机器人基础姿态。与重新训练策略使其更具鲁棒性相比，策略移动将导航与操作分离，因此不需要额外的演示。提出的Mobi-$π$框架通过优化机器人的基础姿态来实现策略的移动，同时利用3D高斯点绘制进行新视角合成以及评分函数来评估姿态的合适性，最终通过采样优化来确定最优的机器人姿态。此外，还提出了一个评估策略移动的方法，即Mobi-$π$框架，包括用于衡量策略移动难度的度量标准、基于RoboCasa的仿真移动操作任务套件以及分析工具。", "conclusion": "在开发的仿真任务套件以及真实环境中，我们展示了我们的方法优于基线方法，证明了其在策略移动中的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20793", "html_url": "https://arxiv.org/abs/2509.20793", "title": "FERD：增强公平性的数据无标签鲁棒性蒸馏", "title_en": "FERD: Fairness-Enhanced Data-Free Robustness Distillation", "authors": "Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang", "background": "当前的方法主要关注整体鲁棒性的转移，但忽略了公平性问题，导致不同类别间鲁棒性存在严重的差距。", "innovation": "提出了Fairness-Enhanced数据无标签鲁棒性蒸馏（FERD）框架，通过调整对抗样本的数量和分布来解决公平性问题。FERD采用了鲁棒性指导下的类别加权策略，生成更少鲁棒性的类别更多数据，提高其鲁棒性。同时，FERD生成公平感知的对抗样本（FAEs），并通过均匀性约束特征级预测，抑制特定类别非鲁棒特征的主导性，提供更加平衡的类别表示。此外，FERD构建了均匀目标对抗样本（UTAEs），通过将攻击目标均匀分布于所有类别，避免对特定脆弱类别的过拟合。", "conclusion": "在三个公开数据集上的广泛实验表明，FERD在所有对抗攻击下都实现了最先进的最弱类别鲁棒性（例如，在CIFAR-10上使用MobileNet-V2时，在FGSM和AutoAttack下最弱类别的鲁棒性分别提高了15.1%和6.4%），在鲁棒性和公平性方面表现出更优的性能。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15363", "html_url": "https://arxiv.org/abs/2509.15363", "title": "使用深度学习的显微镜图像增强最新进展：综述", "title_en": "Recent Advancements in Microscopy Image Enhancement using Deep Learning: A Survey", "authors": "Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita", "background": "显微镜图像增强在理解生物细胞和材料的微观细节方面发挥着关键作用。近年来，借助深度学习方法，显微镜图像增强技术有了显著进步。本文综述了这一快速发展的前沿技术，重点考察了其演变、应用、挑战和未来方向，特别关注超分辨、重建和去噪等核心显微镜图像增强领域及其当前趋势和实际应用价值，", "innovation": "该研究强调了深度学习方法在此领域的最新进展，并对其在显微镜图像增强中的应用进行了详细探讨，展示了如何利用深度学习技术解决图像质量和信息提取方面的挑战。", "conclusion": "本文为显微镜图像增强领域提供了一幅最新的技术蓝图，强调了深度学习在提高图像质量和增强信息抽取方面的作用和潜力，并指出了未来的研究方向。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13050", "html_url": "https://arxiv.org/abs/2506.13050", "title": "NeuVAS: 使用神经隐式曲面的变分形体建模", "title_en": "NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling", "authors": "Pengfei Wang,Qiujie Dong,Fangtian Liang,Hao Pan,Lei Yang,Congyi Zhang,Guying Lin,Caiming Zhang,Yuanfeng Zhou,Changhe Tu,Shiqing Xin,Alla Sheffer,Xin Li,Wenping Wang", "background": "近年来，神经隐式形状表示因其平滑性、可微性和拓扑灵活性引起了广泛关注。然而，直接使用稀疏几何控制来建模神经隐式曲面（尤其是作为神经符号距离函数（SDF）的零等值面），仍然是一个具有挑战的任务。稀疏几何控制通常包括3D曲线网络或更普遍的3D曲线草图，它们是无结构的，难以组合成曲线网络，因此处理起来更为困难。虽然3D曲线网络或曲线草图提供了直观的形状控制，但它们的稀疏性和多变的拓扑结构使得生成满足曲线约束的高质量曲面变得具有挑战性。", "innovation": "本文提出了NeuVAS，一个在稀疏几何控制下使用神经隐式曲面进行形体建模的变分方法，包括无结构3D曲线草图和连通的3D曲线网络。具体来说，通过基于曲面曲率的功能引入平滑项以最小化神经SDF零等值面的形状变化。同时，开发了一种新的技术以忠实地建模输入曲线草图中指定的G0锐利特征曲线。全面对比了现有的先进方法，展示了我们方法的显著优势。", "conclusion": "与现有的先进方法相比，我们的方法显示出显著的优势。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14270", "html_url": "https://arxiv.org/abs/2507.14270", "title": "APTx 神经元：结合激活与计算的统一可训练神经元架构", "title_en": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "authors": "Ravin Kumar", "background": "现有的神经网络通常包含分离的激活层和线性变换层，这种分离使得架构设计和优化复杂度较高，同时也降低了效率。本文研究的背景是在现有神经网络基础上，寻找一种更简洁且高效的神经元设计方案，从而提升整个神经网络的性能和效率。\n", "innovation": "提出了APTx Neuron，这是一种新颖的、统一的神经计算单元，将非线性激活和线性变换整合成一个可训练的表达式单元。APTx Neuron是基于APTx激活函数衍生而来，消除了需要单独的激活层，使架构更加计算高效且简洁。这种神经元的设计允许所有参数（α_i，β_i，γ_i 和 δ）都可训练，增强了表现能力。\n", "conclusion": "APTx Neuron 在 MNIST 集合上得到验证，仅在 11 个时期内达到 96.69% 的测试准确率，使用约 332K 的可训练参数。结果表明，APTx Neuron 在表现能力上优于传统的神经元，并且计算效率更高，未来可能引领统一神经元设计及其架构的新范式。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21393", "html_url": "https://arxiv.org/abs/2509.21393", "title": "损失权重和模型复杂性对计算流体力学中物理知情神经网络的影响", "title_en": "Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics", "authors": "Yi En Chou,Te Hsin Liu,Chao An Lin", "background": "物理知情神经网络为求解偏微分方程提供了无网格框架，但对损失权重的选择非常敏感。背景研究旨在探索如何改进这一领域，特别是在提高PINNs的稳定性和准确性方面。", "innovation": "本研究提出了二维的权重方案，包括基于可量化的术语和结合不可量化的术语的方案，以促进更平衡的训练。实验结果表明，第二种方案在热传导、对流扩散和驱动盖流实验中展现出稳定性和精度的提高，并且在高佩克莱数对流扩散中，展示了PINNs的鲁棒性和泛化能力。", "conclusion": "基于新的二维权重方案的PINNs在对流扩散问题中，尤其是在传统求解器失败的高佩克莱数情况下，能够实现稳定且准确的预测，这强调了它们在CFD问题上的广泛适用性和可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20725", "html_url": "https://arxiv.org/abs/2509.20725", "title": "SeamCrafter：通过强化学习提升网格接缝生成以增强艺术家UV展平效果", "title_en": "SeamCrafter: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning", "authors": "Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo", "background": "网格接缝在3D曲面的UV参数化和纹理映射中起着关键作用。不良的接缝位置常常会导致严重的UV失真或过度细分，从而阻碍纹理合成并破坏艺术家的工作流程。现有方法往往在高失真和许多散落的岛屿之间折衷。为了改进这一问题，我们提出了SeamCrafter，这是一种以点云输入为条件的自回归GPT风格接缝生成器。SeamCrafter采用了一种双分支点云编码器，在预训练过程中解耦并捕捉拓扑和几何线索。为了进一步提高接缝质量，我们使用直接偏好优化（DPO）对模型进行了微调，该优化基于新的接缝评估框架产生的偏好数据集。该框架主要通过UV失真和细分来评估接缝，并提供成对的偏好标签以引导优化。广泛实验表明，SeamCrafter产生的接缝变形和细分明显低于先前的方法，同时保持拓扑一致性和视觉保真度。", "innovation": "提出了SeamCrafter，这是一种自回归GPT风格的接缝生成器，使用双分支点云编码器在预训练过程中分离和捕捉拓扑和几何信息。进一步通过直接偏好优化对模型进行了微调，该优化是由新的接缝评估框架生成的偏好数据集。该框架主要通过UV失真和细分来评估接缝，并提供成对偏好标签以引导优化。实验结果表明SeamCrafter在接缝的失真和细分方面明显优于先前的方法，同时保持了拓扑一致性和视觉保真性。", "conclusion": "SeamCrafter显著改善了3D曲面的UV展平接缝，相比现有方法，在失真和细分方面表现出更优性能，同时保持了拓扑一致性和视觉质量。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18591", "html_url": "https://arxiv.org/abs/2504.18591", "title": "使用不变神经场表示的几何感知的稳态PDE预测", "title_en": "Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations", "authors": "Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier", "background": "尽管神经算子已在理论上引入了在通用几何上对偏微分方程（PDEs）进行离散化不变的替代模型，但许多方法在编码局部几何结构和变化域方面仍然效率低下。该研究旨在通过提出一种基于不变神经场（enf2enf）的新神经场方法来解决这一问题，这种方法能够更有效地表示复杂形状的变化。", "innovation": "该方法通过嵌入几何形状的隐含特征，并在神经网络中保持局部性，结合全局参数进行解码，从而生成连续的物理场。这种方法能够有效地建模复杂形状变化，已在气动和结构基准实验中表现出与图基方法、神经算子方法和最近的神经场方法相当或更好的性能，同时实现实时推理并能高效扩展到高分辨率网格。", "conclusion": "通过使用不变神经场方法，该研究成功实现了对能效和几何变量变化的更有效建模。实验结果表明，该方法在气动和结构基准测试中展示了与现有领先方法相当或更优的结果，并且能够进行实时推理并支持高分辨率网格的大规模扩展。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13019", "html_url": "https://arxiv.org/abs/2507.13019", "title": "重新思考视觉语言导航中的具身差距：视觉与物理差异的综合研究", "title_en": "Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities", "authors": "Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang", "background": "近期视觉语言导航（VLN）的进展令人鼓舞，但这些进展在理想化的假设下评估了机器人的运动和控制，未能反映实际部署中的物理挑战。为了弥合这个差距，本文提出了VLN-PE，这是一个物理上现实的VLN平台，支持类人、四足和轮式机器人。首次系统地评估了几种以自我为中心的VLN方法在不同技术管道下的物理机器人设置表现，包括单一步骤离散动作预测的分类模型，密集路径点预测的扩散模型，以及无需训练的基于地图的大语言模型（LLM），与路径计划集成。结果显示，由于有限的机器人观察范围、环境光照变化以及碰撞和摔倒等物理挑战，性能显著下降。这些结果还揭示了腿足机器人在复杂环境中的移动约束。VLN-PE非常可扩展，可以无缝集成新的场景，超越MP3D，从而实现更全面的VLN评估。尽管当前模型在物理部署中的泛化能力较弱，但VLN-PE为提高跨具身的整体适应性提供了一条新途径。我们希望我们的研究发现和工具能够激励社区重新思考VLN的局限性，并推进健壮和实用的VLN模型", "innovation": "提出了VLN-PE平台，支持多种类型的机器人，首次系统地评估多种以自我为中心的VLN方法在物理机器人的表现，包括分类模型、扩散模型以及无训练的路径规划大语言模型。揭示了实际部署中的物理挑战对VLN模型性能的影响，特别是腿足机器人在复杂环境中的移动约束。VLN-PE平台的扩展性使得能够引入新的场景进行评估，从而提供改进跨具身适应性的新途径", "conclusion": "尽管当前模型在物理部署中的泛化能力较弱，VLN-PE为提高跨具身的适应性提供了一条新途径。未来的研究需要进一步提高模型在实际部署中的表现，增强其在不同环境和场景中的适应能力。我们希望社区能重新思考VLN的挑战，并推进更健壮、实用的VLN模型。源代码可在该链接中找到：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.17897", "html_url": "https://arxiv.org/abs/2507.17897", "title": "Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)", "title_en": "Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)", "authors": "Semih Eren,Deniz Kucukahmetler,Nico Scherf", "background": "准确预测自然刺激下分布式皮层反应需要整合视觉、听觉和语义信息的模型。本文介绍了一个分层的多模式循环集合模型，用于将预训练的视频、音频和语言嵌入映射到受试者观看接近80小时电影后记录的fMRI时间序列数据。模型通过将特定模态的双向循环神经网络（RNN）编码的时间动态融合到第二个循环层，并使用轻量级的特定受试者模式头部来输出1000个皮层区域的反应。训练过程中采用了一种综合均方误差和相关性的损失函数，逐步从早期的感觉区域转向晚期的关联区域。模型的多个变体平均使用进一步提高了鲁棒性。", "innovation": "本文提出了一种分层的多模态循环集合模型，这种模型利用调试过的视频、音频和语言嵌入来预测脑响应。模型结构包括特定模态的双向循环神经网络，这些网络的隐藏状态会被融合并传递到第二个循环层，再由轻量级的特定受试者特定模式头部生成输出。训练过程采用了复合的均方误差-相关性损失函数和逐步转移重心的课程方法。该方法提供了一种简单且可扩展的基准方法，为未来多模态脑编码基准测试打下了基础。", "conclusion": "该系统在竞赛榜单上排名第三，达到了总体皮尔逊相关系数r = 0.2094，并且在其所有参赛者中获得了最高的单个皮质区域峰值得分（平均r = 0.63），特别是在最具挑战性的受试者（受试者5）上有特别强的改进。此方法确立了一个简洁且可扩展的基础，为未来多模态脑编码基准测试提供了指导。"}
{"llm_update_time": "20250929", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21196", "html_url": "https://arxiv.org/abs/2509.21196", "title": "差分-积分神经算子在长期湍流预报中的应用", "title_en": "Differential-Integral Neural Operator for Long-Term Turbulence Forecasting", "authors": "Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu", "background": "准确预测长时间尺度上的湍流演化是科学计算中的重大挑战，对于气候建模和航空航天工程等多个领域具有重要意义。现有的深度学习方法，特别是神经算子，在长期自回归预测中普遍表现不佳，主要的问题是错误的累积和物理保真度的丧失。这些问题源于它们无法同时捕捉控制湍流动力学的几个数学结构：局部耗散效应和全局非局部相互作用。现有方法难以平衡这两类效应，导致长期预测性能较差，无法生成具有物理一致性的长时间湍流演化预测结果。", "innovation": "本文提出了一个新的框架——差分-积分神经算子（\textbf{\textunderline{D}}ifferential-\textbf{\textunderline{I}}ntegral \textbf{\textunderline{N}}eural \textbf{\textunderline{O}}perator, \textbf{DI-NOT}），它使用从第一性原理出发的算子分解方法。\textbf{DI-NOT} 通过并行分支学习不同的物理算子：局部微分算子（由受约束的卷积网络实现，该网络可以严格收敛到导数）和全局积分算子（由学习数据驱动的全局核的变换器架构捕捉）。这种基于物理的分解赋予 \textbf{DI-NOT} 优异的稳定性和鲁棒性。", "conclusion": "通过在具有挑战性的 2D Kolmogorov 流基准测试上的详尽实验，我们证明了 \textbf{DI-NOT} 在长期预测中的性能明显优于现有最先进的模型。它成功地抑制了数百个时间步长中的误差积累，维持了涡旋场和能量频谱的高保真度，并且建立了长期湍流物理一致预报的新的基准。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21473", "html_url": "https://arxiv.org/abs/2509.21473", "title": "活化现象是糟糕的估计吗？", "title_en": "Are Hallucinations Bad Estimations?", "authors": "Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu", "background": "本文将生成模型中的活化现象定义为未能将估计与任何可能的原因关联起来。作者通过展示即使是最小化损失的最优估计器也会产生活化现象来挑战传统的观点，并通过一般性的高概率下限来确认这一现象在通用数据分布中的普遍性。这将活化现象重新定义为损失最小化和人类可接受输出之间的结构错位，以及由此引起的计量校准误差。", "innovation": "该研究指出，最小化损失的最优估计器也会产生活化现象，挑战了传统观点。通过提出一个对于通用数据分布的一般性高概率下限，确认了活化现象的存在性。这将重定义活化现象，将其作为损失最小化和人类可接受输出之间的结构错位，并且强调了这种错位是由计量校准误差引起的。", "conclusion": "本文在硬币聚合、开放问答和文本到图像的实验中支持了他们的理论，表明活化现象可以被视为结构上的错位，并且这种错位是由于计量校准误差引起的。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21322", "html_url": "https://arxiv.org/abs/2509.21322", "title": "发现并分析随机过程以减少食品零售中的浪费", "title_en": "Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail", "authors": "Anna Kalenkova,Lu Xia,Dirk Neumann", "background": "本文聚焦于减少食品浪费的食品零售过程分析方法。提出了一种新的方法，利用对象中心的过程挖掘（OCPM）与随机过程发现和分析相结合的技术。通过从超市销售数据中发现随机过程，逐步拓展以包含供应活动，最终进行情景分析以评估不同时间段库存量的变化，从而优化顾客购买行为与供应策略之间的平衡，减少因过剩供应造成的食品浪费以及库存不足问题。", "innovation": "创新之处在于将对象中心的过程挖掘与随机过程发现相结合，从超市销售数据中挖掘随机过程，并通过扩展包含供应链活动来更精确地模拟零售过程。此外，通过情景分析评估库存变化，寻找最优平衡点，减少了食品过剩和短缺的问题，有效降低了食品浪费率。", "conclusion": "本文提出的方法能够有效分析和优化食品零售过程中的库存动态，帮助零售商找到最佳的供货策略和顾客行为平衡点，从而减少因过度供应或库存不足造成的食品浪费。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21405", "html_url": "https://arxiv.org/abs/2509.21405", "title": "已知动力学下的对象识别：基于PIRNN的无人机分类方法", "title_en": "Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification", "authors": "Nyi Nyi Aung,Neil Muralles,Adrian Stein", "background": "该研究关注的是在无人驾驶航空器（UAV）应用中的对象识别问题，其中通过结合学习和分类，利用物理驱动的残差神经网络（Residual Neural Network, RNN）进行状态映射和状态导数预测。研究假设无人机的动态是已知的，通过这种方法可以提高分类精度并减少训练时间，这在理解动力学的领域中具有重要意义。", "innovation": "提出的框架结合了物理驱动的残差神经网络，通过软最大层实现多类置信度估计。该方法将学习和分类结合在一起，提高了分类精度，同时减少了训练时间，提供了一种在理解动力学的动力学下环境中的系统识别问题解决方案。", "conclusion": "研究结果表明，该方法在高分类准确率的同时，具有减少训练时间的优势，为在了解其动力学的领域中的系统识别问题提供了一种有前景的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21403", "html_url": "https://arxiv.org/abs/2509.21403", "title": "大语言模型在科学领域的贝叶斯优化：我们到了吗？", "title_en": "LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?", "authors": "Rushil Gupta,Jason Hartford,Bang Liu", "background": "近年来，大语言模型（LLMs）被提议作为通用的实验设计代理，声称可以在上下文中进行实验设计。本文评估了这一假设，使用开源和闭源指令微调的LLMs应用于基因扰动和分子性质发现任务。结果显示，基于LLM的代理对实验反馈不敏感：用随机排列的标签替换真实结果对性能没有影响。在各个基准测试中，经典的线性臂和高斯过程优化方法表现优于LLM代理。", "innovation": "提出了一个简单的混合方法，即LLM引导的最近邻（LLMNN）采样，该方法结合了LLM先验知识与最近邻采样来指导实验设计。该方法不需大量上下文适应即可在多个领域达到竞争或优越的性能。结果表明，当前的开源和闭源LLM尚未在实际操作中执行上下文中的实验设计，突显了需要分离基于先验的推理与批量获取并更新后验的混合框架的必要性。", "conclusion": "当前开源和闭源的LLM在实际操作中并不适用于上下文中的实验设计，推崇一种前瞻性指导的混合框架，以改进基于先验的推理和批量获取并更新后验的过程。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21479", "html_url": "https://arxiv.org/abs/2509.21479", "title": "自信筛选：当数据扩增遇到符合预测", "title_en": "Filtering with Confidence: When Data Augmentation Meets Conformal Prediction", "authors": "Zixuan Wu,So Won Jeong,Yating Liu,Yeo Jin Jung,Claire Donnat", "background": "由于合成数据扩增在多种应用场景中表现出色，它被视为解决数据稀缺性和日益复杂的模型对数据需求的有效方案。这种方法通过以减少估计量偏差的同时引入最小偏见的方式来扩展训练集，是有效的，因此控制这种偏见至关重要：有效的数据扩增应该产生来自与训练集相同基础分布的多样化样本，且偏差最小。", "innovation": "本文提出了一种新的合规数据扩增方法，这是一种利用符合预测技术实现多样化合成数据生成以及过滤掉质量差的生成物，并具有可证明的风险控制能力的数据筛选框架。这种方法的优点在于易于实施，无需访问内部模型的对数值，也不需要大规模模型重训。", "conclusion": "该方法在多个任务中（包括主题预测、情感分析、图像分类和欺诈检测）均显示出显著的效果，相对于未经扩增的基本模型，在F1分数上提高了最多40%，相较于其他筛选扩增方案则提高了4%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21484", "html_url": "https://arxiv.org/abs/2509.21484", "title": "在线和联邦零阶优化的高概率分析", "title_en": "High-Probability Analysis of Online and Federated Zero-Order Optimisation", "authors": "Arya Akhavan,David Janz,El-Mahdi El-Mhamdi", "background": "零阶优化是在没有梯度信息的情况下进行的优化方法，常用于黑盒模型优化的情境中。联邦学习中，多个设备在不共享数据的前提下协同进行优化，这对优化算法提出了新的挑战。已有的一些零阶优化算法和联邦学习方法在理论上未能实现最优的误差边界，且缺乏高概率收敛的保证。", "innovation": "该研究提出了FedZero，一种在联邦学习设置下的零阶优化算法，提供了尖锐的理论保证。该算法在联邦凸设置下以高概率达到了接近最优的优化误差边界；在单一工作器的情况下，首次为凸零阶优化提供高概率收敛保证，加强了基于期望的经典结果。算法的核心在于基于$\boldsymbol{l}_1$球体上的随机化梯度估计。", "conclusion": "通过FedZero，该研究不仅为零阶优化和联邦学习的高概率分析提供了新的工具，还为后续研究建立了坚实的理论基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21477", "html_url": "https://arxiv.org/abs/2509.21477", "title": "VISION: 基于不完全观测重建海洋垂直速度", "title_en": "VISION: Prompting Ocean Vertical Velocity Reconstruction from Incomplete Observations", "authors": "Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang", "background": "在地球科学领域，从不完整的表面观测重建地下海洋动力学，如垂直速度场，一直是一个关键挑战。长期以来，缺乏标准化和可分析的基准数据限制了研究进展。", "innovation": "本文构建并发布了KD48基准数据集，这是一个基于千万亿次级模拟并经过专家驱动降噪的高分辨率海洋动力学基准数据集。在此基础上，本文引入了VISION，一种基于动态提示的新颖重建范式，专门解决实际观测中缺失数据的核心问题。VISION能够根据任何可用的观测子集自动生成视觉提示，编码数据可用性和海洋物理状态，并通过状态条件提示模块高效注入通用骨干模型，引导其适应性调整计算策略，有效应对不同输入组合带来的挑战。", "conclusion": "在KD48基准数据集上的广泛实验表明，VISION不仅在性能上显著优于现有模型，还能够在极端数据缺失情况下表现出强大的泛化能力。通过提供高质量基准数据和稳健模型，本文为在数据不确定性条件下开展海洋科学研究奠定了坚实基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21485", "html_url": "https://arxiv.org/abs/2509.21485", "title": "神经算子在地下储层系统 transient 流体流动数学建模中的应用", "title_en": "Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems", "authors": "Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov", "background": "地下储层系统是一个复杂的动态对象，由分布参数和偏微分方程（PDEs）系统描述。传统数值方法虽然准确但计算时间成本高，限制了它们在控制和支持决策问题中的应用。", "innovation": "提出了基于Fourier神经算子（TFNO-opt）架构的方法，该架构通过Fourier神经算子在无限维函数空间中近似PDE解，提供了对离散化的不变性和对不同方程实现的泛化能力。开发的改进措施增加了训练神经算子的准确性和稳定性，尤其在控制问题中更为重要。这些改进措施包括可调节的内部时间分辨率、谱域参数的张量分解、使用Sobolev范数作为误差函数，以及分离约简误差和重构初始条件以更准确地再现物理过程。", "conclusion": "通过计算实验证明了提出改进的有效性。使用地下储气库（UGS）的水动力学建模问题作为示例，实现了比传统方法快六倍数量级的计算加速，这为复杂储层系统的有效控制提供了新的机会。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21489", "html_url": "https://arxiv.org/abs/2509.21489", "title": "GraphPFN: 来自精心设计先验分布的合成图数据预训练图基础模型", "title_en": "GraphPFN: A Prior-Data Fitted Graph Foundation Model", "authors": "Dmitry Eremeev,Oleg Platonov,Gleb Bazhenov,Artem Babenko,Liudmila Prokhorenkova", "background": "大规模数据集预训练的基石模型已经在自然语言处理和计算机视觉等领域取得了显著的进步。然而，这些模型在图数据的应用中相对有限。尽管最近出现了一些图形基础模型（GFMs），如G2T-FM，这些模型能显著超越之前的尝试，但它们主要依赖手工设计的图特征，限制了它们学习复杂且特定于图的模式的能力。", "innovation": "该工作提出了GraphPFN：一种节点级别预测的先验数据调整网络。首先设计了一个合成标记图的先验分布，并使用多种随机块模型和偏好附着过程生成图结构，然后利用图感知结构因果模型生成节点属性和目标。随后，将带有基于注意力的图邻域聚合层的表格式基础模型LimiX预训练在使用该先验生成的合成图上，从而能够在表格数据中无法体现的图结构依赖性上进行建模。实验证实在具有高达50,000个节点的多种真实世界图数据集上，GraphPFN在上下文学习方面的表现优异，并且在大多数数据集上微调后取得了最先进的成果。", "conclusion": "该工作表明，从精心设计的先验分布生成的合成图数据预训练是构建图基础模型的有效策略。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21446", "html_url": "https://arxiv.org/abs/2509.21446", "title": "利用深度学习方法预测地震波形：为爱因斯坦望远镜服务", "title_en": "Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope", "authors": "Waleed Esmail,Alexander Kappes,Stuart Russell,Christine Thomas", "background": "介绍了SeismoGPT模型，这是一个基于Transformer的方法，专门用于预测未来引力波探测器（如爱因斯坦望远镜）中的三维地震波形。该模型在自回归设置中训练，并可以处理单站或基于阵列的输入数据。通过直接从波形数据中学习时间依赖性和空间依赖性，SeismoGPT能够捕捉真实的地面运动模式并提供准确的短期预测。研究表明，模型在即时预测窗口内表现良好，随着时间推移逐渐退化，这符合自回归系统的预期特性。这种方法为数据驱动型地震预测打下了基础，有望支持牛顿噪声的减少以及实时观测站控制。", "innovation": "SeismoGPT是一个基于Transformer的方法，专门用于预测三维地震波形。该模型在自回归设置中训练，能够处理单站或基于阵列的输入数据，通过直接从波形数据中学习时间依赖性和空间依赖性，捕捉真实的地面运动模式并提供准确的短期预测。", "conclusion": "SeismoGPT模型展示了良好的即时预测性能，但随着时间推移性能逐渐退化，符合自回归系统的预期特征。这种方法为未来引力波探测提供了数据驱动型地震预测的基础，有望用于牛顿噪声的减少和实时观测站控制。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21500", "html_url": "https://arxiv.org/abs/2509.21500", "title": "追捕尾部：大型语言模型后训练中有效基于评分标准的奖励建模", "title_en": "Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training", "authors": "Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin", "background": "强化微调（RFT）常常面临奖励过优化的问题，即策略模型通过优化奖励信号来获得高分但产生低质量的输出。理论分析表明，关键问题在于高度奖励尾巴部分的奖励未准确指定：无法可靠地区分优秀回应和普通回应。因此，研究集中在高度奖励区域。然而，在基础大语言模型（LLM）中，这类尾部样本稀缺。尽管来自表现更强的模型或重写的离策略示例更容易获得，但直接从中训练会导致目标策略的未准确奖励。为解决此问题，研究了基于评分标准的奖励方法。这些评分标准可以通过利用离策略示例，同时对它们的异常不敏感。为了引导能够捕捉到高度奖励尾巴的评分标准，研究强调了区分优秀和多样化响应的重要性，并引入了一个工作流程来实施这一想法。", "innovation": "提出了基于评分标准的奖励建模方法，该方法通过设计可以利用离策略示例，同时对它们的异常不敏感。研究强调了在优秀和多样化响应之间进行明确区分的重要性，并提供了一个实施该想法的工作流程。实验证据表明，基于评分标准的奖励显著减轻了奖励过优化，为大型语言模型的后训练带来了有效改进。", "conclusion": "实验结果表明，基于评分标准的奖励方法有效地减轻了奖励优化问题，并为大语言模型的后训练带来了显著改进。研究代码可以在此处访问。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21470", "html_url": "https://arxiv.org/abs/2509.21470", "title": "基于分数的同态扩散模型提炼", "title_en": "Score-based Idempotent Distillation of Diffusion Models", "authors": "Shehtab Zaman,Chengyan Liu,Kenneth Chiu", "background": "生成模型，尤其是生成对抗网络（GANs）和分数模型，在生成高保真样本方面表现出色，但存在训练不稳定性等问题。扩散和分数模型通过逐步将样本从初始分布转化为目标数据分布来生成样本，虽然训练稳定，但计算成本高昂。新采样方法和模型提炼技术被提出以减少采样成本，甚至可以进行单次采样。", "innovation": "提出了一种新的生成模型SIGN，通过从扩散模型的分数中提炼同态模型。SIGN具有高度的稳定性，不需要对抗损失，能够快速推断，在多步骤采样中允许用户在质量与效率之间进行权衡。SIGN能直接在源域上操作，并能将受损或替代分布投影回目标流形，实现零样本输入编辑。", "conclusion": "在多个图像数据集上验证了该模型，SIGN在CIFAR和CelebA数据集上取得了同态模型的最新结果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21465", "html_url": "https://arxiv.org/abs/2509.21465", "title": "Talking Trees：辅助推理生成的决策树方法", "title_en": "Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data", "authors": "George Yakushev,Alina Shutova,Ivan Rubachev,Renat Sergazinov,Artem Babenko", "background": "表格基础模型在低资源表格问题中变得越来越受欢迎。这些模型通过在大量合成数据上进行预训练来弥补小训练数据集的问题，从而获得出色的性能。然而，这些模型变成了难以解释的黑盒模型，在推理时成本较高。本文探讨了一种替代策略：使用具备推理能力的语言模型（LLMs）为小表格数据集生成决策树，特别是在自主设置下。", "innovation": "设计了一套最小的工具集用于构建、分析和操作决策树。通过使用这些工具，LLMs 结合其先验知识和从数据中学习来创建一种轻量级决策树，这种决策树在低资源表格问题中优于传统的CART。虽然单一的决策树可能不优于最先进的黑盒模型，但它带有可阅读的推理轨迹，可以检查偏见和数据泄露问题。此外，基于推理的LLMs的生成过程允许增加人类输入：纠正偏见或融入未被数据捕捉的领域特定直觉。", "conclusion": "通过使用具备推理能力的语言模型生成决策树，不仅可以提升决策树模型在低资源博弈数据问题上的性能，而且还提供了一个易于解释和检查的可读推理路径，增强了模型的透明度，允许人类在生成过程中的参与，以纠正潜在的偏见或加入特定领域的直觉。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21519", "html_url": "https://arxiv.org/abs/2509.21519", "title": "Li_2: 一种特征涌现与延迟泛化的动态框架", "title_en": "$\\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization", "authors": "Yuandong Tian", "background": "关于grokking，即延迟泛化这一现象虽已有广泛研究，但尚未有数学框架来描述何种特征会在训练中出现，以及何时和在何种条件下发生，尤其是在处理复杂结构化输入时。", "innovation": "提出了一种新的框架‘Li_2’，能够捕捉两层非线性网络grokking行为的三个关键阶段：（I）懒学习，（II）独立特征学习，（III）互动特征学习。这些阶段通过反向传播梯度结构$G_F$来特征化。此外，还研究了这些局部最优特征是否可泛化，其表示能力以及随样本大小变化的情况，特别在组算术任务中的变化。", "conclusion": "揭示了关键超参数如权重衰减、学习率和样本大小在grokking中的作用，导出了记忆力和泛化的可证明缩放法则，并解释了为何最近的优化器如Muon可以从梯度动力学的第一原则中有效。该分析可推广至多层架构。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21526", "html_url": "https://arxiv.org/abs/2509.21526", "title": "TRiCo: 三角色博弈协同训练以实现稳健的半监督学习", "title_en": "TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning", "authors": "Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang", "background": "现有的半监督学习（SSL）框架存在一些限制，如静态视图交互、不可靠的伪标签以及缺乏难以处理样本的建模。TRiCo 是一种新颖的三角色协同训练框架，重新考虑了半监督学习的结构，将教师、两个学生和一个对抗生成器整合到一个统一的训练过程中。", "innovation": "TRiCo 引入了一个三角色结构：两个基于冻结互补表示训练的学生分类器、一个元学习的教师通过验证反馈自适应地调节伪标签选择和损失平衡、以及一个非参数生成器扰乱嵌入以揭示决策边界弱点。伪标签的选择基于互信息，而不是信心，提供了一种更稳健的表征不确定性的度量。此外，通过将半监督学习视为三个角色之间的结构互动（采用Stackelberg博弈的形式化），TRiCo 解决了现有SSL框架中存在的关键问题。", "conclusion": "TRiCo 在CIFAR-10、SVHN、STL-10和ImageNet上进行了广泛的实验，结果表明它在低标签条件下总是能够获得最先进的性能，同时仍然具有架构的通用性并能与冻结的视觉骨干相兼容。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21528", "html_url": "https://arxiv.org/abs/2509.21528", "title": "通过潜在可达性预先检测和引导LLM偏离正确路径", "title_en": "Preemptive Detection and Steering of LLM Misalignment via Latent Reachability", "authors": "Sathwik Karnik,Somil Bansal", "background": "在日常工具中普遍存在的大型语言模型（LLMs）引发了对其生成有害内容的安全性关注。现有的主要安全方法增强学习，基于人类反馈（RLHF）尽管在训练期间有效引导模型行为，但在推断阶段仍无法提供保障。", "innovation": "本文提出了一种名为BRT-Align的方法，这是一种基于可达性的框架，可将控制理论中的安全性工具应用于LLM推断。该方法将自回归生成视为潜在空间中的动力系统，并通过反向可达学习一个安全值函数，预测轨迹最坏情况的演变。该框架包含两种互补机制：（1）运行时监控，可提前预测不安全的完成；（2）最小限制的引导过滤器，最小干扰潜在状态，引导生成远离不安全区域。实验表明，BRT-Align比基线更准确、更早地检测了不安全的延续，并且对于LLM安全对齐，BRT-Align显著减少了不安全生成的同时保持了句子的多样性和连贯性。", "conclusion": "研究成果证明，可达性分析为推断期间的LLM安全性提供了一个具有原则性和实用性的基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21514", "html_url": "https://arxiv.org/abs/2509.21514", "title": "具有不确定性的知识追踪模型", "title_en": "Uncertainty-Aware Knowledge Tracing Models", "authors": "Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead", "background": "知识追踪（KT）模型的研究主要集中在模型开发上，以提高预测准确性。大多数现有的KT模型在学生选择干扰选项时做出最不正确的预测，导致学生的错误被忽视。因此，需要一种能够捕捉预测不确定性的新方法来改进这些模型。", "innovation": "本文提出了一种方法，通过捕捉预测不确定性来增强KT模型的能力，并展示了更大的预测不确定性与模型错误预测的一致性。该研究证明了KT模型中的不确定性具有信息价值，并表明这种信号对于在资源有限教育环境中应用的教育学习平台具有教育意义，可以用来理解学生的技能水平。", "conclusion": "研究结果表明，提高模型的不确定性估计有助于更好地识别学生的学习状态和错误，并且这种不确定性信息对于教育平台的实际应用是有益的。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21498", "html_url": "https://arxiv.org/abs/2509.21498", "title": "SlimDiff: 无需训练、基于激活的手动缩减扩散模型", "title_en": "SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models", "authors": "Arani Roy,Shristi Das Biswas,Kaushik Roy", "background": "扩散模型（DMs）因其生成性能而受到赞誉，但由于其十亿级别的参数和迭代去噪动态，计算上非常昂贵。现有的效率提升技术，如量化、时间步长减少或剪枝，虽然在计算量、内存或运行时间上有所节省，但仍然依赖于微调或重新训练来恢复性能，存在明显的瓶颈。", "innovation": "SlimDiff是一种自动激活导向的结构压缩框架，能够在不依赖梯度的情况下减少DMs的注意力和前向传播维度。它将DM压缩重构成一个谱逼近任务，通过活性协方差定义低秩子空间，指导动态剪枝，以固定压缩预算为限制。与模块层面的分解相比，这减少了误差累积，为扩散轨迹的非均匀几何属性适配性地分配稀疏性。SlimDiff可以实现高达35%的加速和约1亿参数的减少，保持与未压缩模型相同的生成质量，无需进行反向传播。我们的方法仅需要约500个校准样本，比先前方法少70倍以上。这是首个完全无需训练、基于激活的结构压缩方法，提供理论上的清晰性和实际的高效性。", "conclusion": "本文介绍了一种无需训练、基于激活的结构压缩方法SlimDiff，能够在不依赖梯度的情况下显著减少扩散模型的尺寸，同时保持生成质量。该方法通过自动激活指导，解决了传统压缩方法的限制，提供了理论和实践的双重优势。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21513", "html_url": "https://arxiv.org/abs/2509.21513", "title": "DistillKac：利用阻尼波动方程的几步图像生成", "title_en": "DistillKac: Few-Step Image Generation via Damped Wave Equations", "authors": "Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon", "background": "现有的扩散模型在逆向时间过程中，其速度可以变得刚性，并且允许无界的传播速度。这使得这些模型在保持图像生成质量的同时难以确保数值稳定性。DistillKac通过使用阻尼波动方程及其随机Kac表示，能够在有限速度下移动概率质量，从而保证全局动能的边界性。基于这一结构，该方法引入了在速度空间中的无分类器引导，使得学生模型在满足某些轻微条件的情况下能够保持平方可积性。DistillKac还提出了一种端点索引的蒸馏方法，通过长时间匹配冻结的教师模型来训练学生模型。这种端点指导训练方法被证明可以促进监督在端点的接近性沿整个路径的传播性质，确保在保持少量函数评估的前提下生成高质量的图像样本，并维持有限速度概率流的数值稳定性优势。", "innovation": "DistillKac通过利用阻尼波动方程及其随机Kac表示，设计了一种高速图像生成器，保证了在有限时间内概率质量的传播速度和数值稳定性。其创新点包括：1) 在速度空间中引入无分类器引导，确保模型的平方可积性；2) 采用端点索引的蒸馏方法，长期匹配冻结的教师模型进行训练；3) 稳定性结果表明，这种端点监督方法可以促进沿路径的接近性；4) 在保持高质量图像生成的同时，大大减少了函数评估次数，确保了数值稳定性。", "conclusion": "DistillKac模型通过在有限速度下生成图像，实现了高精度和数值稳定性。它证明了一种用阻尼波动方程来推进图像生成过程的新方法的有效性，显示出在保持图像质量的同时大幅减少了计算成本的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21474", "html_url": "https://arxiv.org/abs/2509.21474", "title": "d2: 提升训练推理扩散语言模型的技术", "title_en": "d2: Improved Techniques for Training Reasoning Diffusion Language Models", "authors": "Guanghan Wang,Yair Schiff,Gilad Turok,Volodymyr Kuleshov", "background": "虽然扩散语言模型（DLMs）在文本生成任务上已经取得了竞争力的表现，但通过强化学习（RL）提高其推理能力仍然是研究的活跃领域。现有的一些强化学习方法依赖于监督微调来改进DLMs的推理性能，但对需要高计算复杂度和准确度的任务不太有效。因此，设计一种无需监督微调且能够有效提升DLMs推理能力的技术是很有必要的。", "innovation": "本文介绍了一种名为d2的推理框架，专门为掩码DLMs设计。d2的核心在于一个利用掩码特性的新策略梯度算法，能够准确估计采样轨迹的概率。这种算法在计算复杂性和估计准确性之间取得平衡，并对支持任意阶概率估计的DLMs特别有效。研究结果表明，这一特性对于高效推理至关重要。实验证明，d2在逻辑推理任务（Countdown和Sudoku）和数学推理基准测试（GSM8K和MATH500）上，能够显著提高DLMs的推理性能，超越了仅依靠强化学习（不依赖于监督微调）的所有先前方法，并且在DLMs上建立了新的性能标准。", "conclusion": "d2显著改善了逻辑推理和数学推理任务上的扩散语言模型性能，无需依赖于监督微调。d2作为一个新的推理框架，其创新点在于设计了新的策略梯度算法，该算法在计算和概率估计准确性之间的平衡是有效的，并已证明在多种任务上超越了现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21530", "html_url": "https://arxiv.org/abs/2509.21530", "title": "基于查询的专家引导临床文本增强方法", "title_en": "Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration", "authors": "Dongkyu Cho,Miao Zhang,Rumi Chunara", "background": "数据增强是一种常用策略，通过增加合成样本丰富训练数据集来提高模型的稳健性与泛化能力。大型语言模型（LLMs）在这一目的上表现出强大的生成能力，但在医疗等高风险领域中应用时，由于生成临床错误或误导性信息的风险，面临着独特挑战。因此，如何在保持医疗关键信息的同时提高模型效果成为一个亟待解决的问题。", "innovation": "本文提出了一种基于查询的模型协作框架，该框架整合了专家级领域知识，引导数据增强过程以保留关键医疗信息。与现有的LLM增强方法相比，该轻量级协作框架在临床预测任务中表现出更优的性能，并通过减少事实错误提高了安全性。这一框架填补了LLM增强潜力与特定领域安全性要求之间的空白。", "conclusion": "通过该协作框架，保持了模型效果的同时提高了医疗领域的数据增强安全性，解决了实际应用中的具体挑战。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21545", "html_url": "https://arxiv.org/abs/2509.21545", "title": "LLMs的有限元认知证据", "title_en": "Evidence for Limited Metacognition in LLMs", "authors": "Christopher Ackerman", "background": "随着大语言模型（LLM）自我意识甚至感知能力的可能性引起广泛关注，其安全性和政策影响成为了重要议题。然而，评估这些能力的科学方法仍处于萌芽阶段。本文旨在探索新的方法，量化评估LLMs的元认知能力，为后续研究提供技术支持和方法依据。", "innovation": "本文提出了一种创新的元认知能力评估方法，借鉴了对非人类动物元认知的研究，不依赖模型自我报告，而是考察模型在什么程度上能有策略地利用对其内部状态的认知。这种方法通过两个实验范式，展示自2024年初引入的前沿LLMs表现出某些元认知能力的增强证据，如评估和利用自己回答事实性和推理问题的信心，以及预测自己将会给出的回答并利用这些信息。同时，通过对模型返回的标记概率的分析，推测可能存在的上游内部信号是元认知的基础。另外，研究发现这些能力在分辨率、随上下文变化以及人类的差异性等方面有所限制，模型之间即使在类似能力下也存在差异，表明LLM后训练可能在发展元认知能力中起到一定作用。", "conclusion": "本文不仅证明了前沿LLMs具有有限的元认知能力，并提出了评估这些能力的新方法，而且揭示了这些元认知能力的局限性及其与人类元认知的差异。此外，研究还表明模型后训练在发展元认知能力方面可能起着独特的作用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21578", "html_url": "https://arxiv.org/abs/2509.21578", "title": "使用Gumbel动力学进行可解释的时间序列分析", "title_en": "Interpretable time series analysis with Gumbel dynamics", "authors": "Yiliu Wang,Timothy Doyeon Kim,Eric Shea-Brown,Uygar Sümbül", "background": "交换动力系统可以建模复杂的时空数据，同时通过推断一组有限的动力学基本语言并在观测的时间序列中使用其中之一来解释不同的部分来保持可解释性。但由于这些状态集的离散性质，这类模型难以捕捉平滑、变速度的过渡以及重叠状态的随机混合，并且所推断的动力学常常在真实世界的数据集上显示虚假的快速切换。因此，论文提出了一种旨在改进这一问题的新模型——Gumbel动力学模型（GDM）。", "innovation": "GDM通过引入离散状态的连续松弛以及在松弛后的离散状态空间上定义的不同的噪声模型（通过Gumbel分布），增加了可用状态动力学的范围，使模型能够更准确地逼近平滑的、非站性的真实动力学。此外，这种松弛使得模型可以完全可微，从而可以使用常规的梯度下降方法快速且可扩展地进行训练。与传统的模型相比，这种方法能够更好地捕获软而粘附的状态和过渡，特别适合含有多种动态的随机时间序列。", "conclusion": "我们通过标准的模拟数据集验证了GDM方法，并展示了其在含有多种动态的随机时间序列中推断可解释状态的能力。此外，我们在两个现实世界的数据集上应用该模型，验证了其在真实应用中的有效性，证明了其能够从具有多种动态机制的真实世界时间序列数据中推断出可解释的状态，而这些问题对于传统的模型来说往往很难解决。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21534", "html_url": "https://arxiv.org/abs/2509.21534", "title": "大型语言模型中预测层次结构的电路", "title_en": "A circuit for predicting hierarchical structure in-context in Large Language Models", "authors": "Tankred Saanum,Can Demircan,Samuel J. Gershman,Eric Schulz", "background": "大型语言模型（LLMs）在上下文学习中表现出色，能够利用提供的上下文信息来预测后续词汇。引导头被认为在变压器语言模型的上下文学习中扮演着关键角色。引引导头让一个词关注输入中之前相同词的后续词。这个基本机制支持LLMs复制和预测重复模式的能力。然而，这种机制是否能够支持更复杂的具有层次结构的重复模式还有待确定。自然语言充满了这样的例子：在英语中，“the”通常在多个名词前。预测某个“the”后的词需要整合更多上下文信息来确定正确的名词。如果引导向头以一种独立于上下文的方式关注所有之前相同词的后续词，它们无法提供这种水平的上下文整合。在本研究中，我们设计了一个合成的上下文学习任务，其中的词在有层次依赖的情况下被重复出现。仅均匀地关注所有后续词不足以准确预测后续词汇。评估一系列LLMs在这些词汇序列以及自然语言中的表现，结果显示自适应引导向头支持预测，通过学习如何关注上下文中的信息来帮助预测。接着，我们研究引导向头本身如何在上下文中学到东西。研究发现，学习被支持的是那些能够揭示一套潜在上下文的注意力头，决定不同词汇转换关系。总体而言，我们不仅展示了LLMs有学习的引导向头，而且还提供了一种完整的机械论来解释LLMs如何学习预测层级结构中的高阶重复模式。", "innovation": "研究设计了一个合成的上下文学习任务，测试不同层次依赖的词汇重复对预测准确性的影响。研究发现了自适应的引导向头，这种引导向头能够学习如何在上下文中学到预测信息。研究发现，学习被支持的是那些能够在上下文中批量曝光潜在上下文的注意力头，从而决定词汇转换关系。创新点在于提供了更为全面的机制解释，说明了LLMs如何在具体的层级结构任务中学习更高阶的重复模式。", "conclusion": "本研究不仅证明了LLMs有学习功能的引导向头，还提供了一个完整的机制解释，说明LLMs如何在上下文中预测具有高阶层次结构的重复模式。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21619", "html_url": "https://arxiv.org/abs/2509.21619", "title": "PreLoRA: 使用全训练与低秩适配进行的视觉变换器的混合预训练", "title_en": "PreLoRA: Hybrid Pre-training of Vision Transformers with Full Training and Low-Rank Adapters", "authors": "Krishu K Thapa,Reet Barik,Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath", "background": "训练大型模型（从数百万到数亿参数）需要大量的资源，包括时间、计算能力和内存。观察发现，大部分的学习（权重的较大变化）发生在训练循环的早期阶段。随着训练的继续，这些变化趋于稳定，使得它们可以被低固有秩矩阵捕捉。因此，我们提出了一种方法来识别这些部分收敛的状态，并从全参数训练动态切换到低秩适配（LoRA）在ViT-大型模型上。", "innovation": "我们的方法利用用户定义的超参数来确定切换点，并根据每个模块层的收敛程度为其分配特定的秩。实验证明，即使在将可训练参数数量缩减到原始规模的10%的情况下，这个方法也能保持模型的准确性，同时实现了3倍的吞吐量提升，每轮迭代的平均训练时间减少1.5倍，同时减少了20%的GPU内存消耗。", "conclusion": "该方法在减少计算资源消耗的同时，保持了模型的准确性，显著提高了训练效率和GPU内存使用效率。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21511", "html_url": "https://arxiv.org/abs/2509.21511", "title": "对比互信息学习：无需正样本对增强的稳健表示", "title_en": "Contrastive Mutual Information Learning: Toward Robust Representations without Positive-Pair Augmentations", "authors": "Micha Livne", "background": "在代表学习中，使学习到的表示能够成功迁移到多样化的下游任务仍然是一个核心挑战。现有的范式，如对比学习、自我监督掩码和去噪自动编码器，在解决这一问题时各有权衡。", "innovation": "提出了一种对比互信息机器（cMIM）框架，它扩展了互信息机器（MIM），加入了对比目标。cMIM通过引入全局判别性结构解决了MIM在判别性任务中的不足，同时保留了MIM的生成保真度。贡献包括三个方面：1）提出cMIM，一种对比性扩展的MIM，取消了正数据扩增的必要性，且对批量大小的敏感度远低于InfoNCE；2）介绍了一种信息嵌入技术，可以从编码-解码模型中提取丰富特征，提升了判别性能，且不需要额外训练，并广泛适用于MIM之外；3）通过视觉和分子基准测试数据，证明cMIM在分类和回归任务上优于MIM和InfoNCE，同时保持了竞争力的重建质量。", "conclusion": "这些结果将cMIM定位为统一的代表学习框架，朝着构建既能服务于判别性又能服务于生成性应用的模型的目标迈进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21579", "html_url": "https://arxiv.org/abs/2509.21579", "title": "利用大数据框架在亚马逊评论中检测垃圾信息", "title_en": "Leveraging Big Data Frameworks for Spam Detection in Amazon Reviews", "authors": "Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed", "background": "在数字化时代，网上购物已成为日常生活的一部分。产品评价对消费者购买行为有重大影响，有助于建立买家的信任。然而，虚假评论的普遍存在破坏了这种信任，可能导致误导消费者，损害卖家的声誉。本文通过运用先进的大数据分析和机器学习方法，对大量亚马逊产品评论数据进行处理和分析，旨在准确检测和分类垃圾评论，提高评论的真实性，增加网上购物的透明度和可靠性。", "innovation": "本文通过利用可扩展的大数据框架对大量的亚马逊评论数据进行高效处理和深度分析，提出并评估了多种机器学习分类器在检测垃圾评论方面的性能，显示了Logistic Regression分类器在准确性上达到了90.35%，为构建更为可信和透明的在线购物环境提供了一种新的方法和解决方案。", "conclusion": "通过对亚马逊评论的大规模数据处理和分析，本文实现了对垃圾评论的有效检测，提高了评论数据的真实性和可信度，为在线购物环境提供了更为透明和可信赖的基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21547", "html_url": "https://arxiv.org/abs/2509.21547", "title": "机器学习：不确定性下的选择科学", "title_en": "Machine Learning. The Science of Selection under Uncertainty", "authors": "Yevgeny Seldin", "background": "学习，无论是自然的还是人工的，都是一个选择过程。它从一组候选选项开始并选择表现更优秀的选项。在机器学习中，选择是基于候选预测规则在数据上的预测准确性的经验估计。由于数据采样的随机性，经验估计本身是充满噪声的，导致在不确定性下的选择。本书提供了统计工具来获得在不确定性下的选择结果的理论保证。从衡量函数期望的经验估计与真实期望偏差的措施入手，覆盖了一系列不等式，包括马尔可夫不等式、切比雪夫不等式、霍夫丁不等式、伯纳斯坦不等式、经验伯纳斯坦不等式、遇见的伯纳斯坦不等式、kl不等式和分割-kl不等式。随后研究了经典的有监督学习，并提供了一系列工具来推导泛化边界，包括奥卡姆剃刀、Vapnik-Chervonenkis分析和PAC-贝叶斯分析，后者被进一步应用于推导加权多数投票的泛化保证。在研究离线环境后，转向在线学习。在线学习问题的空间被环境反馈、环境抵抗力和结构性复杂性所定义。在在线学习中，常用的表现度量是遗憾，它将算法的表现与回溯最佳预测规则的表现进行比较。本书呈现了在随机性和对抗环境中的遗憾边界工具，同时也在完全信息和带状反馈下进行解释。", "innovation": "本书提供了一系列统计工具，帮助理解和解决在机器学习中由于数据不确定性引起的各种挑战。这些工具覆盖了从经验估计与真实期望的偏差到在线学习中遗憾边界的各种重要方面，为不确定性下的学习提供了坚实的理论基础。书中不仅提供了广泛不等式的综述，还应用PAC-贝叶斯分析来推导加权多数投票的泛化保证，进一步展示了在线学习和离线学习之间的联系和区别。", "conclusion": "本书通过提供一系列的统计工具和不等式，为机器学习领域中不确定性下的选择提供了坚实的理论保证。从离线的有监督学习到在线学习，本书覆盖了广泛的应用场景，展示了如何有效处理在学习过程中由于不确定性带来的挑战，并提供了实用的方法来推导泛化边界和遗憾边界。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21637", "html_url": "https://arxiv.org/abs/2509.21637", "title": "块状 Hadamard 高阶适配在参数高效 LLM 微调中的应用", "title_en": "Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning", "authors": "Feng Yu,Jia Hu,Geyong Min", "background": "PEFT 方法必须在资源效率和处理异构推理变换方面取得平衡，而经典的小秩适应 (LoRA) 受制于理论秩 $r$。Hadamard 风格的扩展，如 HiRA 提升了理论秩但将每次更新与冻结权重矩阵的全局能量模式耦合在一起，而 ABBA 则牺牲了这种归纳偏见以实现完全学习的密集中间层。BHRA 旨在解决全局控制的限制，通过将每个权重矩阵拆分并独立地在每个块内应用 HiRA 风格的乘法调控，保持 PEFT 参数占用率的同时解锁局部化的秩放大。", "innovation": "BHRA 通过将每个权重矩阵拆分并在每个块内独立应用 HiRA 风格的乘法调控，保持 PEFT 参数占用率的同时解锁局部化的秩放大，克服了全局调控的限制，并通过实验证明其在八个常识推理任务和两个算术基准测试中在匹配参数预算下持续超越强大的 PEFT 基线。", "conclusion": "BHRA 方法在资源效率和局部化的高秩适配能力上取得了平衡，适用于 Llama-3.2 1B/3B，Mistral-7B，Gemma-2 9B 的 LLM 微调，并在各种任务上表现出色，超越了现有基线。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21654", "html_url": "https://arxiv.org/abs/2509.21654", "title": "安全、信任与通用人工智能的局限性", "title_en": "Limitations on Safe, Trusted, Artificial General Intelligence", "authors": "Rina Panigrahy,Vatsal Sharan", "background": "人工智能（AI）系统中的安全、信任和通用人工智能（AGI）是期望的目标，但这些概念存在多种非正式解释。本文旨在为这些概念提供严格的数学定义，并揭示它们之间的根本不兼容性。", "innovation": "作者提出了严格的数学定义来描述AI系统中的安全、信任和AGI，并证明一个安全且受信任的AI系统无法同时具备AGI的特性。这一发现为解决上述概念之间冲突提供了新的视角。", "conclusion": "研究结果表明，受安全性和信任性约束的AI系统无法实现超出人类能力的AGI。虽然作者使用的是严格的数学定义，但在实际应用中可能采用不同的实践解释。研究证明了程序验证、规划和图可达性中的结果，并与哥德尔不完备定理和图灵停机问题的不可判定性证明进行了类比。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21658", "html_url": "https://arxiv.org/abs/2509.21658", "title": "一般二进制数据的可微结构学习", "title_en": "Differentiable Structure Learning for General Binary Data", "authors": "Chang Deng,Bryon Aragam", "background": "现有的方法通常假设离散数据是从特定的结构方程模型生成的，但这些假设可能与真实的数据生成过程不一致，限制了这些方法的普遍适用性。此外，当前的方法往往忽略了离散数据中固有的复杂依赖结构，只考虑线性影响。", "innovation": "提出了一个能够捕捉离散变量之间任意依赖关系的可微结构学习框架。证明了虽然一般的离散模型从观测数据中无法识别，但是在适当假设下可以确定参数和结构的完全集合，并证明了在马尔可夫等价下的可识别性。将学习问题表述为最一般形式下的单个可微优化任务，从而避免了以往方法中的不现实简化。", "conclusion": "实验证明，我们的方法能够有效地捕捉离散数据中的复杂关系。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21607", "html_url": "https://arxiv.org/abs/2509.21607", "title": "在容许失真表示下的因果抽象推理", "title_en": "Causal Abstraction Inference under Lossy Representations", "authors": "Kevin Xia,Elias Bareinboim", "background": "本研究探讨因果抽象的概念，该概念连接了人类智能的两个关键方面：确定因果关系的能力以及将复杂模式解释为抽象概念的能力。传统的因果抽象框架定义了从复杂的底层因果模型到简单的高层模型之间的连接。然而，大多数现有定义在处理包含多低层干预导致不同影响但仍映射到同一高层干预的失真抽象函数时不够明确（这种假设称为抽象不变性条件）。该研究旨在克服这一局限，引入了一种新的抽象类型——投影抽象，它扩展了现有的定义以适应失真表示。同时，它提出了一种新的图形判据来从有限的底层数据中识别和估计高层因果查询，为高维图像等场景下的因果推理提供了有效方法。", "innovation": "本研究创新地引入了投影抽象这一新的抽象类型，它可以扩展现有的定义以适应失真表示。研究还提供了一种新的图形判据，用于从有限的底层数据中识别和估计高层因果查询。实验结果表明，投影抽象模型在高维图像场景下的有效性。", "conclusion": "研究通过利用投影抽象模型，克服了现有定义在处理失真表示时的局限性，从而有效解决了从底层数据推断高层因果查询的问题。所提出的方法不仅拓宽了因果抽象的研究范围，还为真实场景中的数据分析和模型构建提供了有力支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21605", "html_url": "https://arxiv.org/abs/2509.21605", "title": "GenUQ: 通过生成超网络进行预测不确定性估计", "title_en": "GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks", "authors": "Tian Yu Yen,Reese E. Jones,Ravi G. Patel", "background": "操作学习是一种最近发展起来的回归泛化形式，用于函数之间的映射。它承诺将昂贵的偏微分方程数值积分简化为快速评估系统功能状态之间的映射，即代理建模和降阶建模。操作学习已经在海洋冰、燃烧和大气物理等领域找到了应用。然而，将不确定性量化纳入操作模型的最近方法依赖于基于似然的方法从噪声数据中推断参数分布。但是，随机操作可能会产生难以构建或不可能构造似然性的行动。本文旨在介绍一种避开构造似然性的测度论方法GenUQ，该方法通过引入生成超网络模型产生与观察数据一致的参数分布，从而避免构建似然性的问题。GenUQ 已经在三个示例问题中得到了验证，包括恢复制造的操作、学习随机椭圆偏微分方程的解操作以及建模耐压钢在拉伸过程中的失效位置。", "innovation": "提出的GenUQ方法是一种通过生成超网络来估算预测不确定性的方法，它通过引入生成超网络模型产生与观察数据一致的参数分布来避免构造似然性。这种方法有效地解决了基于似然不确定性量化方法在处理随机操作时遇到的问题，从而提高了解决便携式操作问题的性能。GenUQ 方法在三个实例问题中表现出了优于其他不确定性量化方法的效果。", "conclusion": "GenUQ 方法通过生成超网络模型产生与观察数据一致的参数分布来解决不确定性的量化问题。它在三个示例问题中表现出了比其他不确定性量化方法更好的性能。GenUQ 方法为操作学习领域中的不确定性量化提供了一种新型且有效的手段。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21606", "html_url": "https://arxiv.org/abs/2509.21606", "title": "基于无回放梯度投影的无任务知识联邦持续学习", "title_en": "Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection", "authors": "Seohyeon Cha,Huancheng Chen,Haris Vikalo", "background": "联邦持续学习（FCL）允许分布式的客户端设备从跨多个多样且不断进化的任务的流式数据中学习。持续学习中的主要挑战——灾难性遗忘，在去中心化环境中由于数据异质性、通信限制和隐私问题而被放大。现有的方法需要数据回放来减轻遗忘问题，但这增加了隐私风险并影响了效率。", "innovation": "提出了Federated Gradient Projection-based Continual Learning with Task Identity Prediction (FedProTIP)，一种新颖的FCL框架。该框架通过将客户端更新投影到全球模型早期学习表示子空间的正交补上，来减轻遗忘问题。此外，还引入了一个轻量机制，利用先前任务的核心基础预测任务身份，并动态调整全球模型的输出，以解决无任务知识推理的挑战。", "conclusion": "在标准FCL基准测试中进行了广泛的实验，结果显示FedProTIP在平均准确度上显著优于现有方法，特别是在任务身份未知的情况下。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21663", "html_url": "https://arxiv.org/abs/2509.21663", "title": "逻辑假设：从零知识到完全知识的神经符号集成", "title_en": "Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration", "authors": "Davide Bizzaro,Alessandro Daniele", "background": "神经符号集成（NeSy）结合了神经网络学习与符号推理。该领域可以分为两大类：一类是将手工艺规则注入神经模型的方法，另一类是从数据中诱导符号规则的方法。Logistics of Hypotheses（LoH）是一种新的语言，它统一了这两种方法，实现了数据驱动的规则学习与符号先验和专家知识的灵活整合。", "innovation": "LoH 扩展了命题逻辑语法规则，引入了一个具有可学习参数的选择操作符，可以从备选项中选择子公式。通过模糊逻辑，LoH 中的公式可以直接编译成可微计算图，从而通过反向传播学习最佳选择。此框架涵盖了某些现有的 NeSy 模型，并增加了任意的知识指定程度。此外，使用哥德尔模糊逻辑和最近发展的哥德尔技巧，可以将模型离散化为硬布尔值函数，而不会损失性能。", "conclusion": "我们通过实验分析展示了 LoH 模型在表格数据和视觉井字游戏 NeSy 任务上的强大结果，同时生成了可解释的决策规则。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21624", "html_url": "https://arxiv.org/abs/2509.21624", "title": "从HIP看Hessian：无需导数的原子间势能", "title_en": "Shoot from the HIP: Hessian Interatomic Potentials without derivatives", "authors": "Andreas Burger,Luca Thiede,Nikolaj Rønne,Varinia Bernales,Nandita Vijaykumar,Tejs Vegge,Arghya Bhowmik,Alan Aspuru-Guzik", "background": "计算化学中的基础任务，如过渡态搜索和振动分析，都需要计算分子哈密尔顿量，即势能的二阶导数。然而，目前计算哈密尔顿量既耗费计算资源，又随着系统规模的增加而效率下降，无论是量子力学方法还是神经网络都存在这些问题。本研究旨在通过深度学习直接预测哈密尔顿量，而非依赖自动微分或有限差分，从而提高计算效率和准确性，优化内存使用，便于训练，并实现系统规模下的更好扩展性。本研究还验证了预测的可靠性和有效性，展示出在多种下游任务中性能优越，包括过渡态搜索、加速几何优化、零点能修正和振动分析等。本研究还提供了HIP代码库和模型权重，以促进直接预测哈密尔顿量的发展。", "innovation": "本研究创新性地提出了一种无需导数的直接预测哈密尔顿量的方法，通过在图神经网络中利用不可约表示（irrep）特征构建SE(3)等变和对称的哈密尔顿量。这种方法使得预测速度提升了1到2个数量级，更准确，内存更高效，训练更便捷，并且能更好地处理大系统的规模扩展问题。通过广泛的下游任务验证，展示了其优越的性能。", "conclusion": "本研究模型HIP能够在多种下游任务中展现出优越的性能，并通过开源方式供进一步研究与发展。这为直接预测哈密尔顿量提供了新的工具和方法，有助于提高计算化学中的计算效率和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21659", "html_url": "https://arxiv.org/abs/2509.21659", "title": "RED-DiffEq: 使用去噪扩散模型进行逆PDE问题求解的正则化方法及其在全波形反演中的应用", "title_en": "RED-DiffEq: Regularization by denoising diffusion models for solving inverse PDE problems with application to full waveform inversion", "authors": "Siming Shan,Min Zhu,Youzuo Lin,Lu Lu", "background": "PDE-调控的逆问题在科学和工程应用中具有重要意义，但因其非线性、病态性和对噪声的敏感性而面临巨大挑战。", "innovation": "引入了RED-DiffEq计算框架，结合了物理驱动的反演和数据驱动的学习，利用预训练的去噪扩散模型作为PDE调控逆问题的正则化机制。该方法应用于地质物理学中的全波形反演，展示了比传统方法更高的准确性和鲁棒性，特别是在未对扩散模型进行训练的复杂速度模型上也具有良好的泛化能力。", "conclusion": "该框架可以直接应用于各种PDE调控逆问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21617", "html_url": "https://arxiv.org/abs/2509.21617", "title": "LANCE: 低秩激活压缩在边缘设备上的高效持续学习", "title_en": "LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning", "authors": "Marco Paul E. Apolinario,Kaushik Roy", "background": "在资源受限的环境中，本地学习对于个性化、隐私和长期适应是必不可少的。实现这一点需要高效的学习，既要微调现有的模型，也要不断地学习新任务，而不发生灾难性遗忘。然而，这仍然受到反向传播期间存储激活所产生高内存成本的限制。现有的激活压缩方法可以降低这种成本，但依赖于多次低秩分解，引入了额外的计算开销。此外，这些方法尚未探索用于持续学习的场景。", "innovation": "本文提出了一种名为LANCE（低秩激活压缩）的框架，它通过一次完成高阶SVD来获得可重复使用的低秩子空间进行激活投影，从而避免了重复分解，减少了内存和计算成本。此外，固定低秩子空间还使得边缘设备上的持续学习成为可能，通过分配任务到正交子空间，而无需存储特定于任务的大型矩阵。实验表明，LANCE在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上减少激活存储高达250倍，同时保持与完整反向传播相当的准确性。在持续学习基准上，它在内存成本仅为一部分的情况下，实现了与正交梯度投影方法相当的性能。", "conclusion": "实验结果证明，LANCE为边缘设备上的高效微调和持续学习提供了一个实用且可扩展的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21662", "html_url": "https://arxiv.org/abs/2509.21662", "title": "MMPlanner: 零样本多模态程序规划中的链式思维物体状态推理", "title_en": "MMPlanner: Zero-Shot Multimodal Procedural Planning with Chain-of-Thought Object State Reasoning", "authors": "Afrina Tabassum,Bin Guo,Xiyao Ma,Hoda Eldardiry,Ismini Lourentzou", "background": "现有的多模态程序规划（MPP）方法主要利用大型语言模型对文本步骤进行细化，但在视觉物体状态对齐和系统性评估方面目前还存在不足。MPP的目标是在保留跨模态物体状态一致性的同时，生成富含信息的步骤指导，结合文本和图像。", "innovation": "MMPlanner通过引入物体状态推理链式思维（OSR-CoT）提示，明确建模物体状态转换，并生成准确的多模态计划。为了评估计划质量，设计了LLM作为裁判的规划准确性和跨模态对齐协议，并提出了一种视觉步骤重新排序任务来衡量时间连贯性。实验结果显示，MMPlanner在RECIPEPLAN和WIKIPLAN数据集上实现了最先进的性能改善，分别提高了文本规划6.8%、跨模态对齐11.9%和视觉步骤排序26.7%的表现。", "conclusion": "MMPlanner在跨模态物体状态推理中提出了新的方法，并通过系统性评估提高了多模态程序规划的整体质量。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21666", "html_url": "https://arxiv.org/abs/2509.21666", "title": "DIM: 强化深度神经网络中的域启发式单调性", "title_en": "DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks", "authors": "Joshua Salim,Jordan Yu,Xilei Zhao", "background": "深度学习模型在预测任务中表现出色，但由于其复杂的结构和大量的参数，常常会导致过拟合，模型学习了训练数据中的噪音而非学习泛化到新数据的有效模式。为解决这一挑战，本文提出了一个新的正则化方法——强化深度神经网络中的域启发式单调性（DIM），该方法通过保持深度学习模型中的域启发式单调关系以进一步提高预测性能。", "innovation": "本文提出的DIM方法通过相对于线性基线惩罚单调性违反，鼓励模型遵循预期趋势同时保留其预测能力。本文通过一个全面的数学框架来正式化该方法，建立了线性参考，测量单调性行为的偏差，并将这些测量值整合到训练目标中。", "conclusion": "在各种神经网络架构下的实验表明，即使是轻微的单调性约束也能够一致地提高模型性能。DIM通过在正则化模型行为和减轻过拟合时应用域启发式单调性约束，增强了深度神经网络的预测性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21650", "html_url": "https://arxiv.org/abs/2509.21650", "title": "理解并增强基于掩膜的预训练以获得通用表征", "title_en": "Understanding and Enhancing Mask-Based Pretraining towards Universal Representations", "authors": "Mingze Dong,Leda Wang,Yuval Kluger", "background": "基于掩膜的预训练已成为现代大规模语言、视觉和最近生物领域模型的基础。尽管其表现出色，但其在学习数据表示中的角色和局限性仍不清楚。本文通过将基于掩膜的预训练行为直接表征为高维最小范数（“无岭”）线性回归中的测试风险，探讨了基于掩膜的预训练的学习机制和表现边界。作者进一步分析了线性模型，揭示了基于掩膜的预训练的几个新颖方面，验证了这一理论框架在各种神经架构（包括MLPs、CNNs和Transformers）和视觉、语言任务中的适用性与有效性，该框架已被广泛验证并显示出强大的通用性。", "innovation": "提出了一个简单但被忽略的预训练方案——Randomly Random Mask AutoEncoding（R²MAE）。该方案能够同时捕捉多尺度特征，并在作者构建的线性模型框架中表现出色，甚至优于固定掩膜比例的最优设置。通过在视觉、语言、DNA序列和单细胞模型中实施R²MAE，实验结果表明它能够持续优于标准和更复杂的掩膜方案，从而提升了最先进的模型表现。这种框架的理论验证和广泛的适用性突显了该新方案的创新贡献与潜在优越性。", "conclusion": "由理论指导，R²MAE在视觉、语言、DNA序列和单细胞模型中的实现了一致的性能改进，证实了其优于标准和更复杂的掩膜方案的能力，并推动了最先进的模型表现。作者的研究不仅丰富了基于掩膜预训练的理解，还提供了实际有效的预训练方案。该研究已在各种应用场景中得到了验证，并证明了基于掩膜的预训练在多领域成功应用的潜力及其关键理论指导下的具体实施方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21655", "html_url": "https://arxiv.org/abs/2509.21655", "title": "DriftLite: 轻量级漂移控制用于扩散模型的推断时缩放", "title_en": "DriftLite: Lightweight Drift Control for Inference-Time Scaling of Diffusion Models", "authors": "Yinuo Ren,Wenhao Gao,Lexing Ying,Grant M. Rotskoff,Jiequn Han", "background": "本研究关注在推理阶段对扩散模型进行缩放，目标是在无需重新训练的情况下适应新的目标分布。现有基于引导的方法虽然简单但会产生偏差，而基于粒子的修正则面临权重退化和高计算成本的问题。我们需要一种轻量级、无需训练的方法来保持推理过程的动态稳定性，并提供实际的实施方案来近似最优漂移，实现样本质量的提升。", "innovation": "引入了DriftLite，这是一种无需训练的轻量级、基于粒子的方法，能够在不重训的情况下自适应调整推理动态，并通过Fokker-Planck方程中的漂移和粒子势能之间的新自由度来实现预测最优性控制。DriftLite提供了两个实际的实施方案：Variance-Controlling Guidance（VC格尔智）和Energy-Controlling Guidance（EC格尔智），能够在最小开销下逼近最优漂移。在高斯混合模型、粒子系统以及大规模蛋白质-配体共折叠问题中，DriftLite都能减少方差并提高样本质量，同时比纯引导和马尔可夫链蒙特卡洛（Sequential Monte Carlo）等基线方法表现更优。", "conclusion": "研究结果表明，DriftLite提供了一条原理上合理且高效的途径，能够实现扩散模型在推理阶段的大规模适应和缩放，由此为实际应用提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21673", "html_url": "https://arxiv.org/abs/2509.21673", "title": "SlotFM: 一种基于Slot Attention的运动基础模型，适用于多样下游任务", "title_en": "SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks", "authors": "Junyong Park,Oron Levy,Rebecca Adaimi,Asaf Liberman,Gierad Laput,Abdelkareem Bedri", "background": "可穿戴加速度计广泛应用于手势识别、步态分析和体育监控等领域，现有的大多数基础模型主要集中在日常活动分类，如行走和锻炼，这限制了它们在依赖其他信号特征的更广泛任务中的应用。", "innovation": "SlotFM是一种旨在适应各种下游任务的加速度计基础模型，它利用Time-Frequency Slot Attention加工原始信号的时间和频率表示，生成多个微型嵌入（槽），每个槽捕捉不同信号成分，从而使特定任务头部能够关注数据中最相关部分。此外，它引入了两种损失正则化器来捕捉局部结构和频率模式，这有助于增强对细粒度细节的恢复并确保嵌入保留了任务相关信息。SlotFM在包括16项分类和回归下游任务的评估中表现出色，远超现有自监督方法的表现，且在某些任务上达到了最佳性能的可比结果。平均而言，该方法在性能上获得了4.5%的提高，展现了良好的普遍适用性。", "conclusion": "SlotFM在16个超越标准人类活动识别的下游任务中表现出色，超越了现有的自监督方法，并在其余任务上达到了最佳性能的差不多结果，平均提高了4.5%的性能，展示了很强的传感基础模型的概括能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21671", "html_url": "https://arxiv.org/abs/2509.21671", "title": "Neuroprobe：评估自然刺激下脑内反应", "title_en": "Neuroprobe: Evaluating Intracranial Brain Responses to Naturalistic Stimuli", "authors": "Andrii Zahorodnii,Christopher Wang,Bennett Stankovits,Charikleia Moraitaki,Geeling Chau,Andrei Barbu,Boris Katz,Ila R Fiete", "background": "高分辨率的神经数据集使得下一代脑机接口和神经治疗的基础模型成为可能。社区需要严格的基准来区分竞争建模方法，但目前没有针对侵入性脑电图(iEEG)记录的标准评估框架。鉴于此，本文提出了Neuroprobe：一个用于研究多模态语言处理的解码任务套件。Neuroprobe依托于包含40小时10名人类受试者进行自然电影观看任务的iEEG记录的BrainTreebank数据集，具有高时间和空间分辨率，通过跨时间和所有电极位置测量每个特征的可解性，可系统地确定大脑中每个语言处理部分的计算发生时间和地点。Neuroprobe不仅能够揭示神经科学研究成果，还为神经基础模型的发展提供了严格的框架，帮助比较不同架构和训练策略，发现线性基线模型在很多任务上表现惊人。", "innovation": "Neuroprobe 是一个专注于多模态语言处理的解码任务套件，特别适用于 iEEG 数据的高分辨率记录。通过BrainTreebank数据集，提供了独特的时间和空间分辨率，使得研究人员能够通过系统地测量每个特征在时间和电极位置上的可解性，确定大脑中语言处理各部分的计算时间与位置。此外，Neuroprobe 作为一个计算高效且易于使用的工具，开放了代码并维护了一个公开的排行榜，以促进神经基础模型领域的迅速进展。", "conclusion": "Neuroprobe 提供了一种评估侵入性脑电图中自然刺激反应的严格框架，不仅能够揭示神经科学研究成果，还比较了不同建模方法的性能，发现线性基线模型在许多任务上表现良好。Neuroprobe 计划通过开放代码和维护排行榜，推动 iEEG 基础模型领域的快速发展，促进该领域迅速取得进展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21716", "html_url": "https://arxiv.org/abs/2509.21716", "title": "使用线性动力系统统一并行化顺序模型的框架", "title_en": "A Unifying Framework for Parallelizing Sequential Models with Linear Dynamical Systems", "authors": "Xavier Gonzalez,E. Kelly Buchanan,Hyun Dong Lee,Jerry Weihong Liu,Ke Alexander Wang,David M. Zoltowski,Christopher Ré,Scott W. Linderman", "background": "现代机器学习的一个关键挑战是如何在看似顺序的模型中利用并行性。多个使用固定点方法（如牛顿方法、皮卡德方法和雅可比迭代）的并行化顺序过程的方法已经提出。", "innovation": "本文展示了一种新的统一框架，该框架基于线性动力系统（LDSs），揭示了不同迭代方案自然作为非线性递归的近似线性化的本质。这种统一视角强调了这些技术背后共享的原则，并澄清了特定固定点方法在什么情况下最有效。通过采用LDSs的语言，本文的框架为并行化顺序模型提供了更清晰的理论基础，并指出了更高效和可扩展计算的新机会。", "conclusion": "本文的工作为并行化顺序模型提供了一个更加清晰的理论基础，并且开辟了新的高效和可扩展计算的机会。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21675", "html_url": "https://arxiv.org/abs/2509.21675", "title": "Scaleable Second-order Riemannian Optimization for K-means Clustering", "title_en": "Scalable Second-order Riemannian Optimization for $K$-means Clustering", "authors": "Peng Xu,Chun-Ying Hou,Xiaohui Chen,Richard Y. Zhang", "background": "聚类问题是离散优化问题的一种，传统方法如低秩半定规划（SDP）的非凸方法已经展示了恢复聚类的良好统计和局部算法保证。但由于K-means聚类问题的组合结构，当前松弛算法难以平衡约束可行性和目标优化性，这给计算二阶临界点带来了巨大挑战。", "innovation": "本文将K-means问题重新表述为子流形上的光滑无约束优化，并通过研究其黎曼结构，允许其使用二次立方正规化的Riemannian Newton算法求解。通过将K-means流形分解为积流形，证明了每个牛顿子问题可以在线性时间内解决。实验结果表明，与最先进的非线性非负低秩因子化方法相比，所提出的方法收敛速度显著更快，同时达到相似的最佳统计准确性。", "conclusion": "本文提出了一种新的K-means聚类方法，通过黎曼优化技术，该方法能够更快速地收敛并达到相似的统计准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21660", "html_url": "https://arxiv.org/abs/2509.21660", "title": "针对治疗效果估计的收敛推断程序系统综述：方法与挑战", "title_en": "A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges", "authors": "Pascal Memmesheimer,Vincent Heuveline,Jürgen Hesser", "background": "治疗效果估计对于许多领域的知情决策至关重要，包括医疗保健、经济学和公共政策。虽然灵活的机器学习模型被广泛应用以估计异质治疗效果，但量化它们的点预测固有的不确定性仍然是一个问题。最近的研究通过提供高斯频率、有限样本覆盖保证，解决了这一点，并最小化假设，使得可在任何点预测模型下进行高效的计算和分布变化。这项进展尤其适合高风险环境下的决策改善。", "innovation": "本研究进行了一项系统性回顾，针对治疗效果估计的收敛推断方法，并提供了必要的理论背景。通过严格的筛选过程，我们选择了并分析了十一个关键论文，识别了当前领域的最新方法。基于这一发现，我们提出了未来研究的方向。", "conclusion": "通过对包括准确性和适用性的全面评估，我们确定了目前最先进的方法，并提出了进行深入研究的方向。这项系统的回顾将有助于推动治疗效果估计中收敛推断的未来研究和发展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21735", "html_url": "https://arxiv.org/abs/2509.21735", "title": "基于SDE的纵向脑网络时空图深度学习方法揭示阿尔茨海默病进展", "title_en": "Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks", "authors": "Houliang Zhou,Rong Zhou,Yangying Liu,Kanhao Zhao,Li Shen,Brian Y. Chen,Yu Zhang,Lifang He,Alzheimer's Disease Neuroimaging Initiative", "background": "阿尔茨海默病(AD)的神经影像学生物标志物识别对于及时干预至关重要，但由于现有方法忽视了脑网络在时空特性上的复杂功能失调，这一任务仍具有挑战性。因此，需要一种新的方法来预测AD的未来进展，该方法可以更好地捕捉异常的脑网络特性。", "innovation": "本文提出了一种可解释的时空图神经网络框架，利用双Stochastic Differential Equations (SDEs)来处理不规则纵向功能磁共振成像(fMRI)数据，有效学习了稀疏的区域和连接性重要概率，有助于识别与疾病进展相关的关键脑回路异常。此外，该方法揭示了以前未发现的性别的神经系统级别生物标志物，提供了关于AD进展神经生物学机制的新见解。", "conclusion": "本研究强调了时空图基学习方法在预测AD进展方面的潜力，即使在纵向影像数据不规则采样的情况下也能实现早期、个性化预测。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21689", "html_url": "https://arxiv.org/abs/2509.21689", "title": "SpecMER: 使用 k-mer 纡导的推测性解码快速蛋白质生成", "title_en": "SpecMER: Fast Protein Generation with K-mer Guided Speculative Decoding", "authors": "Thomas Walton,Darin Tsui,Aryan Musharaf,Amirali Aghazadeh", "background": "自回归模型通过生成超越自然界蛋白质序列的新序列，正在转变蛋白质工程。然而，自回归模型的序列推断引入了显著的延迟，限制了它们在高通量蛋白质筛选中的应用。推测性解码通过使用轻量级草案模型来提高生成效率，由较大的目标模型验证和细化所选序列。但在蛋白质序列生成中，草案模型通常忽视目标蛋白的结构和功能限制，导致生物上不合理的输出，并改变了生成序列的概率分布。", "innovation": "SpecMER 是一种使用 k-mer 方式指导的推测性解码新框架，利用多序列比对提取的 k-mer 模式融入生物学、结构和功能先验知识。并行评分候选序列，选择与已知生物模式最一致的序列，从而显著提高序列的合理性，同时保持推测性解码的效率。SpecMER 在标准自回归解码上实现了 24-32% 的速度提升，同时接受率更高，序列概率也更好。", "conclusion": "SpecMER 通过并行评分和 k-mer 指导的推测性解码在提高蛋白质生成的合理性同时，保持了高效率，从而显著提升了蛋白质生成的速度和质量。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21699", "html_url": "https://arxiv.org/abs/2509.21699", "title": "Exact Subgraph Isomorphism Network for Predictive Graph Mining", "title_en": "Exact Subgraph Isomorphism Network for Predictive Graph Mining", "authors": "Taiga Kojima,Masayuki Karasuyama", "background": "在图级预测任务中，输入图中的子图所包含的信息发挥着关键作用。建立高区分能力和可解释性的图级预测模型仍然是一个挑战性的问题。", "innovation": "本文提出了一种精确子图同构网络（EIN），结合了精确的子图枚举、神经网络和稀疏正则化。EIN的独特之处在于将子图枚举与神经网络结合以提高输入图的子图结构的区分能力，并通过稀疏正则化实现有效的剪枝策略，同时识别重要子图以提高模型的可解释性。", "conclusion": "实验表明，EIN相比标准图神经网络模型具有足够高的预测性能，而且基于选定子图的后验分析也能提供有效的例子。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21746", "html_url": "https://arxiv.org/abs/2509.21746", "title": "HyperCore：通过超球体模型在噪声环境下的核心子集选择", "title_en": "HyperCore: Coreset Selection under Noise via Hypersphere Models", "authors": "Brian B. Moser,Arundhati S. Shanbhag,Tobias C. Nauen,Stanislav Frolov,Federico Raue,Joachim Folz,Andreas Dengel", "background": "现有的核心子集选择方法旨在识别代表性的数据子集以提高模型训练效率，但往往忽视了标注错误的可能性，并需要固定的剪枝比率，这在实际应用中并不实用。", "innovation": "本文提出了HyperCore，一种针对噪声环境的鲁棒且自适应的核心子集选择框架。HyperCore 使用轻量级的超球体模型在每类上学习，将同类样本推向超球体中心，自然地将不属于类别的样本根据其距离隔开。通过使用约登指数，HyperCore 可以自适应地选择剪枝阈值，实现无需超参数调优的噪声感知数据剪枝。实验结果表明，HyperCore 在噪声和低数据环境中显著优于现有的核心子集选择方法。", "conclusion": "HyperCore 有效剔除错误标注和模糊点，生成紧凑但高度信息的子集，适用于可扩展且无噪声的学习。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21751", "html_url": "https://arxiv.org/abs/2509.21751", "title": "基于神经场的4DVAR重参数化", "title_en": "Reparameterizing 4DVAR with neural fields", "authors": "Jaemin Oh", "background": "四维变分数据同化（4DVAR）是数值天气预报的基石，但由于其成本函数难以优化且计算强度高，现有的4DVAR方法存在优化困难和计算效率低的问题。", "innovation": "提出了一种基于神经场的重新参数化方法，将全空间-时间状态表示为由神经网络参数化的连续函数，消除了经典4DVAR的时间序列依赖性，从而实现参数空间中的并行时间优化。直接通过物理约束损失来引入物理约束，简化了实现并降低计算成本。", "conclusion": "该方法在不可压缩Navier-Stokes方程中进行评估，相比传统4DVAR方法，基于神经场重新参数化的版本产出了更稳定的初始条件估计，且无虚假振荡。无需访问真实状态或再分析数据，扩大了其适用范围，特别是在参考信息有限的情况下。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21704", "html_url": "https://arxiv.org/abs/2509.21704", "title": "PQFed: 一种隐私保护的质量控制联邦学习框架", "title_en": "PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework", "authors": "Weiqi Yue,Wenbiao Li,Yuzhou Jiang,Anisa Halimi,Roger French,Erman Ayday", "background": "联邦学习使模型训练可以在不共享原始数据前提下进行协作，但数据异质性持续性地影响着全局模型性能。传统优化方法通常依赖全面的全局模型训练，随后进行本地适应以提升个体性能。", "innovation": "提出了一种新颖的个性化隐私保护联邦学习框架PQFed，该框架在联邦训练之前为每个客户端设计定制化训练策略。该框架提取每个客户端原始数据的代表性特征，使用聚类技术估计客户端数据集之间的相似性。基于这些相似性估计，实施客户端选择策略，允许每个客户端与其他具有兼容数据分布的客户端进行协作。", "conclusion": "实验结果显示，即使参与者数量有限，PQFed也能够提高目标客户端的模型性能，并且在低参与度场景中也优于基准基于聚类的算法IFCA。这些发现突显了PQFed在个性化的联邦学习设置中的可扩展性和有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21742", "html_url": "https://arxiv.org/abs/2509.21742", "title": "Brain PathoGraph Learning", "title_en": "Brain PathoGraph Learning", "authors": "Ciyuan Peng,Nguyen Linh Dan Le,Shan Jin,Dexuan Ding,Shuo Yu,Feng Xia", "background": "脑图学习在神经科学和人工智能领域取得了显著成就。然而，现有方法在选择性学习疾病相关知识方面存在困难，导致参数繁重和大量的计算成本，这降低了效率，并限制了其实用性，特别是难以应用于实际临床应用。", "innovation": "提出了一种轻量级的脑病理图学习（BrainPoG）模型，通过病理性模式过滤和病理性特征蒸馏，实现了脑图学习的高效化。该模型首先通过提取具有高度疾病相关性的子图来实现图形修剪和病灶定位，构建了病理性图。最后设计了一个病理性特征蒸馏模块，减少无关噪声特征，增强病理性图中每个节点的病变特征。", "conclusion": "在四个基准数据集上的广泛实验表明，BrainPoG 在各种脑疾病检测任务中具有优越的模型性能和计算效率。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21737", "html_url": "https://arxiv.org/abs/2509.21737", "title": "POLO: 预ference-guided 多轮 强化 学习 用于 分子 优化", "title_en": "POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization", "authors": "Ziqing Wang,Yibo Wen,William Pattie,Xiao Luo,Weimin Wu,Jerry Yao-Chieh Hu,Abhishek Pandey,Han Liu,Kaize Ding", "background": "在药物发现过程中，分子优化需要在广泛的化学空间中高效迭代，通过增加分子的特性来提高它们的价值，同时保持结构与原始先导化合物的相似性。尽管最近取得了进展，传统的优化方法在有限的评估次数下仍难以实现高效优化。大型语言模型（LLMs）具有上下文学习和指令遵循能力，这与迭代优化过程天然契合。然而，当前的基于LLM的方法没有充分利用这一优势，而是将每一步骤独立处理。", "innovation": "本文提出了POLO（Preference-guided多轮优化），一种使LLMs能够从完整的优化路径中学习而非孤立步骤的方法。其核心是Preference-Guided策略优化（PGPO）算法，它在两个互补的层面进行学习：路径级别的优化强化了成功的策略，而回合级别的偏好学习通过在每个路径中对中间分子进行排序，提供密集的比较反馈。POLO通过这种方式，在单一属性任务中实现了84%的平均成功率（比基线提高2.3倍），在使用500次评估的情况下完成了多个属性任务，显著推动了样本高效分子优化的前沿。", "conclusion": "广泛的实验表明，POLO在单属性任务中实现了84%的平均成功率，是基线的2.3倍，而在仅使用500次评估的情况下完成了多属性任务，从而在样本高效的分子优化方法中取得了重大进步。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21703", "html_url": "https://arxiv.org/abs/2509.21703", "title": "使用可解释的机器学习方法基于人口社会经济和通勤特征进行人口移动数据的细化", "title_en": "Downscaling human mobility data based on demographic socioeconomic and commuting characteristics using interpretable machine learning methods", "authors": "Yuqin Jiang,Andrey A. Popov,Tianle Duan,Qingchun Li", "background": "理解不同空间层次上的人口流动模式对于社会科学至关重要。本研究旨在通过机器学习框架，将纽约市范围内的出租车起终点流量从较大的空间单元细化到较小的空间单元，以更好地理解城市人口流动模式。", "innovation": "开发了使用线性回归（LR）、随机森林（RF）、支持向量机（SVM）和神经网络（NN）四种模型来建立OD行程与人口、社会经济和通勤特征之间的相关性，并采用扰动方法进行非线性模型的变量重要性解释。结果显示，虽然神经网络在训练和测试数据上表现最佳，但在流量细化性能的一般泛化能力上，支持向量机表现最好。该方法为改进交通运输服务和城市发展提供了分析上的进步和实际应用价值", "conclusion": "本研究提出的方法集成了分析进步和实用应用，为优化城市交通服务和促进城市发展提供了有效工具。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21770", "html_url": "https://arxiv.org/abs/2509.21770", "title": "机器学习和AI应用于fNIRS数据揭示稳定隐形多发性硬化脑活动生物标志物", "title_en": "Machine Learning and AI Applied to fNIRS Data Reveals Novel Brain Activity Biomarkers in Stable Subclinical Multiple Sclerosis", "authors": "Sadman Saumik Islam,Bruna Dalcin Baldasso,Davide Cattaneo,Xianta Jiang,Michelle Ploughman", "background": "多发性硬化（MS）患者报告手灵巧性和认知疲劳的问题，但许多情况下，这些缺陷是微妙的，难以检测。功能近红外光谱（fNIRS）是一种非侵入性神经成像技术，通过测量认知或运动任务期间的大脑血流动力学反应来进行大脑活动监测。本文旨在检测可解释手灵巧任务期间主观认知疲劳报告的大脑活动生物标志物，并为未来的脑刺激治疗提供目标。", "innovation": "研究使用了机器学习框架分析fNIRS数据，通过脑激活模式分类MS患者和健康对照组，发现补充了传统的成像方法，显示了MS患者在某些大脑区域的活动减少和血糖反应延迟。研究采用了一种非传统的fNIRS数据分析方法，揭示了新型的脑活动生物标志物，有助于开发个性化的脑刺激治疗目标。", "conclusion": "该非传统方法分析fNIRS数据揭示了新的脑活动生物标志物，有助于开发个性化的脑刺激治疗目标。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21748", "html_url": "https://arxiv.org/abs/2509.21748", "title": "SubZeroCore：零训练的子模态方法进行核心集选择", "title_en": "SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection", "authors": "Brian B. Moser,Tobias C. Nauen,Arundhati S. Shanbhag,Federico Raue,Stanislav Frolov,Joachim Folz,Andreas Dengel", "background": "现有的核心集选择方法需要昂贵的基于训练的信号（如梯度、决策边界估计或遗忘计数）来确定代表性的数据子集，这些信号需在整个数据集上计算以在裁剪前提供指导，但这些方法反而需要在它们试图避免的样本上进行训练，这与它们的初衷相矛盾。因此，本文介绍了一种名为SubZeroCore的新颖、无需训练的核心集选择方法，该方法将子模态覆盖和密度集成到一个统一的目标中。", "innovation": "SubZeroCore 通过引入基于闭式解的采样策略来最优平衡这些目标，并通过单一的超参数直接控制局部密度指标所需的覆盖度来实现这一点，而无需任何训练。该方法在广泛的评估中表现突出，即使在高裁剪率下也能匹配基于训练的基线，并且在大幅降低计算开销的同时表现出优越性。此外，SubZeroCore 还显示出更好的标签噪声鲁棒性，这表明其在实际应用场景中的实用性和可扩展性.", "conclusion": "SubZeroCore 通过将子模态覆盖和密度集成到一个统一目标中的一条统一路径，展示了在高裁剪率下无训练的学习的有效性和重要性。相比现有的基于训练的核心集选择方法，它在减少计算开销的同时，即使在数据质量较差或者存在噪声的情况下也能表现出更好的性能，处理了现有的解决方案中存在的潜在问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21792", "html_url": "https://arxiv.org/abs/2509.21792", "title": "FastGRPO: 通过并发感知推测性解码和在线草图学习加速策略优化", "title_en": "FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning", "authors": "Yizhou Zhang,Ning Lv,Teng Wang,Jisheng Dang", "background": "组相对策略优化（GRPO）已经展示了通过强化学习提高大型语言模型（LLMs）推理能力的巨大潜力。然而，其实际部署受到训练过程过于缓慢的阻碍，主要原因是生成多个响应的计算密集型自回归过程，使得生成阶段成为性能的主要瓶颈。虽然推测性解码为加速提供了有希望的方向，但在高并发培训条件下直接应用推测性解码仅能达到有限的加速效果。", "innovation": "本文提出了一种并发感知推测性解码框架，该框架根据实际并发级别动态调整草稿和验证策略，从而最大化生成过程的加速效果。此外，为了应对在训练过程中由于目标模型和固定草图模型分布漂移导致的性能下降，引入了一种在线草图学习机制，使草图模型能够继续使用来自目标模型的反馈信号进行适应。实验结果表明，所提出的方法在多个数学推理数据集和模型上实现了2.35倍到2.72倍的端到端速度提升，显著优于基础方法效率。", "conclusion": "综合实验结果显示，FasGRPO方法在多个数据集和模型上实现了显著的加速效果，具体端到端速度提升了2.35倍至2.72倍，并且在效率上远超基线方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21794", "html_url": "https://arxiv.org/abs/2509.21794", "title": "探索自动化疲劳检测过程中生理信号之间的关系", "title_en": "Exploring the Relationships Between Physiological Signals During Automated Fatigue Detection", "authors": "Kourosh Kakhi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharyab", "background": "疲劳检测利用生理信号在交通、医疗和性能监控领域至关重要。大多数研究集中在单一模态上，而这项工作研究了信号对之间的统计关系以提高分类的鲁棒性。使用DROZY数据集，从ECG、EMG、EOG和EEG中提取了15种信号组合的特征，并使用决策树、随机森林、逻辑回归和XGBoost进行评估。结果显示，EMG和EEG组合与XGBoost模型结合时表现最佳。SHAP分析强调ECG和EOG的相关性作为一个关键特征，多信号模型优于单信号模型。这些结果表明，生理信号的特征级融合提高了疲劳监控系统的准确性和可解释性，也提高了其实用性。", "innovation": "研究了信号对之间的统计关系以提高分类的鲁棒性；使用了DROZY数据集分析了ECG、EMG、EOG和EEG信号的15种组合；采用了XGBoost等机器学习模型进行评估；多信号模型表现优于单信号模型；SHAP分析展示了ECG和EOG相关性的重要性。", "conclusion": "生理信号的特征级融合显著提高了疲劳监测系统的准确性和实用性，多信号模型比单信号模型更加优越。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21695", "html_url": "https://arxiv.org/abs/2509.21695", "title": "Wav2Arrest 2.0: 使用时间到事件建模、身份不变性和伪标本对齐方法的长时间心搏骤停预测", "title_en": "Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment", "authors": "Saurabh Kataria,Davood Fattahi,Minxiao Wang,Ran Xiao,Matthew Clark,Timothy Ruchti,Mark Mai,Xiao Hu", "background": "高频率生理波形模态能够提供患者状态的深入、实时洞察。最近，基于光体积描记图（PPG）的生理基础模型，例如PPG-GPT，已经被证明能够预测关键事件，包括心脏骤停（CA），但它们的强表示能力仍然需要合理利用，特别是在下游数据/标签稀缺的情况下。", "innovation": "提出了三种独立改进方法，通过使用最少的辅助信息来提高仅PPG的心脏骤停系统：1. 使用时间到事件建模，可以是简单的事件起始时间回归或精细离散生存模型；2. 鼓励模型学习心脏骤停集中特征，使其不受患者身份影响，这是通过训练大规模匿名生物识别模型p-vector并使用它以对抗方式消除过适应风险的线索来实现的；3. 在预训练辅助估计网络生成的伪标签值上进行回归。这是由于真血液实验室测定值（如乳酸、钠、肌钙蛋白、钾）的收集非常有限，通过零样本预测，辅助网络可以丰富心脏骤停波形标签并生成伪连续估计作为目标。", "conclusion": "我们的建议可以使24小时平均AUC从0.74提高到0.78-0.80范围。我们主要改善了更长时间范围，接近事件时的性能略有下降，但推动了早期预警系统的研究。我们采用了多任务形式，并诊断出竞争损失之间存在高梯度冲突率，我们通过PCGrad优化技术缓解了这一点。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21802", "html_url": "https://arxiv.org/abs/2509.21802", "title": "混沌Nexus：具有多尺度表示的可用于通用混沌系统预测的基础模型", "title_en": "ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations", "authors": "Chang Liu,Bohao Zhao,Jingtao Ding,Yong Li", "background": "准确预测混沌系统（如天气预报和流体力学中的系统）仍然是一个重大的科学挑战。这些系统的初值敏感性和观测数据稀缺性限制了传统建模方法。由于这些模型通常针对特定系统进行训练，缺乏在新场景或数据有限场景下的泛化能力，以满足现实应用的需求。为了解决泛化障碍，我们提出了一种基于多类混沌动力学先验训练的ChaosNexus基础模型。", "innovation": "ChaosNexus采用了名为ScaleFormer的新型多尺度架构，并结合了混合专家层，以捕捉通用模式和系统特定行为。该模型在合成和真实世界基准测试中实现了最先进的零样本泛化效果。对于超过9000个合成混沌系统的大型测试床，它在长期吸引子统计的准确度上比领先基线提高了40%以上。此外，ChaosNexus在全局5天天气预报中的零样本平均误差低至1度，通过少量样本微调后进一步提升。实验表明，跨系统的泛化能力来自于多样化的训练系统，而不仅仅是数据量。", "conclusion": "ChaosNexus在混沌系统预测中展现出强大的零样本泛化能力和数据效率。它为科学基础模型提供了指导原则：跨系统的泛化来自于多样化的训练系统，而不是纯粹的数据量。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21818", "html_url": "https://arxiv.org/abs/2509.21818", "title": "Sharpness-Aware Minimization Can Hallucinate Minimizers", "title_en": "Sharpness-Aware Minimization Can Hallucinate Minimizers", "authors": "Chanwoong Park,Uijeong Jang,Ernest K. Ryu,Insoon Yang", "background": "Sharpness-Aware Minimization (SAM) 是一种广泛使用的训练方法，它引导训练向更平坦的极小值进行，这些极小值通常具有更好的泛化能力。然而，该文指出 SAM 可能会收敛到虚幻的极小值点，这些点并不是原始目标函数的极小值点。作者通过理论证明了这些虚幻极小值的存在性，并建立了局部收敛到这些点的条件。", "innovation": "该研究揭示了 SAM 可能导致收敛到虚幻极小值的现象，并通过理论和实验证据进行了验证。最后提出了一个简单的补救措施，以避免虚幻极小值的出现。", "conclusion": "研究表明，尽管 SAM 通常有利于提高模型的泛化能力，但在某些情况下，它也可能导致模型收敛到不是原始目标函数极小值的虚幻极小值点。通过提出的补救措施，可以有效避免这一问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21780", "html_url": "https://arxiv.org/abs/2509.21780", "title": "超越公式复杂度：有效信息准则提高符号回归的性能和可解释性", "title_en": "Beyond Formula Complexity: Effective Information Criterion Improves Performance and Interpretability for Symbolic Regression", "authors": "Zihan Yu,Guanren Wang,Jingtao Ding,Huandong Wang,Yong Li", "background": "符号回归能够发现准确且可解释的公式以描述给定的数据，为专业人士提供科学见解并促进科学发现。然而，现有符号回归方法常使用复杂度指标作为兼容性的代理，仅考虑公式的大小而不考虑其内部数学结构。尽管这些方法可以发现紧凑的公式，但发现的公式结构往往难以进行数学分析或解释。基于此，本文提出了有效信息准则（EIC），将公式视为具有特定内部结构的信息处理系统，通过数据在系统中流动时重要位数的丢失或舍入噪声放大的情况来识别公式中的不合理结构。研究表明，EIC揭示了现有符号回归算法所发现的模型结构与真实世界物理公式之间的差距。结合EIC与各种基于搜索的符号回归算法可以提升算法性能，并减少结果中的不合理结构；结合基于生成的方法则能减少预训练所需样本数量，提高样本效率2-4倍。此外，对于不同准确性与复杂性相似的公式，EIC在108名人类专家对公式的可解释性偏好中表现出70.2%的一致性，表明EIC通过衡量公式中的不合理结构能够反映公式的可解释性。", "innovation": "本文提出了一种有效信息准则（EIC），将其应用于符号回归中。EIC将公式视为具有特定内部结构的信息处理系统，通过数据在系统中流动时重要位数的丢失或舍入噪声放大的情况来识别公式中的不合理结构。结合EIC与基于搜索的和基于生成的符号回归算法，提高这些算法的性能和可解释性，减少了预训练所需样本数量，提高了样本效率。研究还证明，EIC能够与人类专家的偏好高度一致，反映了公式的可解释性。", "conclusion": "本文提出的有效信息准则（EIC）在解决现有符号回归方法的可解释性问题上表现出色，通过数据分析来识别公式中的不合理结构。结合EIC与不同类别的符号回归算法，显著提高了算法性能，并降低了对预训练样本数量的需求。此外，EIC作为一种基于衡量不合理结构的方法，能够准确反映公式的可解释性，为改进符号回归提供了新的研究视角。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21725", "html_url": "https://arxiv.org/abs/2509.21725", "title": "基于信息论的 bilevel 优化问题贝叶斯优化方法", "title_en": "Information-Theoretic Bayesian Optimization for Bilevel Optimization Problems", "authors": "Takuya Kanayama,Yuki Ito,Tomoyuki Tamura,Masayuki Karasuyama", "background": "bilevel 优化问题包括上下层嵌套的两个优化问题，其中下层问题的最优性约束了上层问题。对于涉及到昂贵黑盒函数的上下层 bilevel 优化问题，标准的贝叶斯优化方法并未广泛研究。", "innovation": "提出了一种信息论方法，考虑了上下层最优解及其价值的信息增益，统一了衡量两个层级问题效益的标准。同时，基于实际的下界方法评估信息增益。", "conclusion": "通过多个基准数据集实验证明了所提出方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21828", "html_url": "https://arxiv.org/abs/2509.21828", "title": "基于偏好指导的学习在稀疏奖励多智能体强化学习中的应用", "title_en": "Preference-Guided Learning for Sparse-Reward Multi-Agent Reinforcement Learning", "authors": "TheViet Bui,Tien Mai,Hong Thanh Nguyen", "background": "研究在线多智能体强化学习（MARL）在稀疏奖励环境中的问题，其中奖励反馈不是在每次交互时提供，而是在轨迹结束时才显现。虽然这种设置在现实中是合理的，但它提出了一个根本性的挑战：缺乏中间奖励阻碍了标准MARL算法的有效指导策略学习。", "innovation": "提出了一种新的框架，将在线逆偏好学习与多智能体在策略优化统一到一个架构中。该方法的核心在于引入了一个基于偏好价值分解网络的隐式多智能体奖励学习模型，该模型生成全局和局部奖励信号。这些信号进一步用于构建双重优势流，以为集中的评判者和去中心化的行动者提供差异化的学习目标。此外，展示了如何利用大型语言模型（LLMs）来提供增强学习奖励模型质量的偏好标签。", "conclusion": "在最先进的基准测试，包括MAMuJoCo和SMACv2上的实证评估表明，该方法在处理在线MARL中的稀疏奖励挑战方面表现出优越性能，凸显了其有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21865", "html_url": "https://arxiv.org/abs/2509.21865", "title": "超越RAG与长上下文：学习防干扰检索以实现高效的知识接地", "title_en": "Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding", "authors": "Seong-Woong Shim,Myunsoo Kim,Jae Hyeon Cho,Byung-Jun Lee", "background": "RAG是一种框架，用于将大型语言模型（LLMs）与外部、最新的信息进行连接。然而，LLMs的上下文窗口大小的进步使其能够处理最多128K个令牌或更多的输入，提供了将完整文档上下文直接提供给模型的替代策略，而不是依赖于RAG检索上下文的子集。但是，这种新兴的替代策略存在明显限制：（i）处理大规模且可能冗余的上下文是令牌使用上的低效；（ii）加剧了“中间迷失”的问题；（iii）在有限的模型容量下，它会放大干扰性，最终降低LLM的输出质量。", "innovation": "本文提出了一种名为LDAR（学习防干扰检索）的自适应检索方法，该方法学会以减少干扰性段落干扰的方式检索上下文，从而在减少令牌使用的同时获得了显著的性能提升。在各种LLM架构和六个知识密集型基准上进行了广泛的实验，展示了该方法的有效性和鲁棒性，突显了信息覆盖面与干扰之间的权衡的重要性。", "conclusion": "本文展示了LDAR的有效性和鲁棒性，证明了在处理知识密集任务时，平衡信息覆盖面和干扰的重要性。通过减少干扰性段落的影响，LDAR能够在保持高质量输出的同时更有效地利用令牌。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21874", "html_url": "https://arxiv.org/abs/2509.21874", "title": "通过连接归纳逻辑编程和多模态大型语言模型进行演绎逻辑规则归纳", "title_en": "Abductive Logical Rule Induction by Bridging Inductive Logic Programming and Multimodal Large Language Models", "authors": "Yifei Peng,Yaoli Liu,Enbo Xia,Yu Jin,Wang-Zhou Dai,Zhong Ren,Yao-Xiang Ding,Kun Zhou", "background": "现有的演绎逻辑规则归纳方法，如基于归纳逻辑编程（ILP）的方法，面临着依赖特定背景知识和高计算成本的挑战。而多模态大型语言模型（MLLMs）虽然在视觉感知方面有优势，但由于感知幻觉的问题，它们在逻辑推理方面也有局限性。", "innovation": "提出了一种名为ILP-CoT的方法，该方法通过结合ILP和MLLMs，自动构建修剪过的ILP任务空间。ILP系统基于MLLMs提出的结构正确规则，并利用修正后的逻辑事实和形式的归纳推理来输出规则。这种方法在挑战性的逻辑归纳基准测试中得到了验证，并且展示了通过逻辑规则归纳进行文本到图像定制生成的应用潜力。", "conclusion": "该方法的有效性通过挑战性的逻辑归纳基准测试和技术应用得到验证。相关代码和数据可在给定的链接中获得。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21811", "html_url": "https://arxiv.org/abs/2509.21811", "title": "神经材料模型的标度定律", "title_en": "Scaling Laws for Neural Material Models", "authors": "Akshay Trikha,Kyle Chu,Advait Gosai,Parker Szachta,Eric Weiner", "background": "预测材料属性对于设计更好的电池、半导体和医疗设备至关重要。深度学习使科学家能够通过预测能源、力和应力来迅速找到有前景的材料。公司在多个领域（如语言建模）中扩展深度学习模型的容量，并投资数以百万美元计的资金。我们的团队分析了神经网络用于材料属性预测时，扩大训练数据、模型大小和计算资源（分别提供更多的信息、学习模式的能力和计算资源）对性能的影响。我们通过训练变压器和EquiformerV2神经网络来预测材料属性，发现这些模型的实验标度定律：随着每个超参数（训练数据、模型大小和计算资源）的增加，预测性能的变化可以由幂律关系描述。我们还为训练设置了命令行参数，如训练周期、最大学习率和是否启用混合精度。未来的工作可以进一步探讨其他神经网络模型在这种领域中的标度定律，例如GemNet和全连接网络，以评估它们与我们训练的模型之间的差异。", "innovation": "我们计算并发现神经网络模型在材料属性预测领域中的实验性标度定律，尤其是关于训练数据、模型大小和计算资源对预测性能影响的法律关系。通过使用变压器和EquiformerV2神经网络训练，我们能够具体量化这些超参数增加时损失函数的变化。此外，我们引入了调整训练设置的命令行参数。未来研究可能会涉及到其他模型（如GemNet和全连接网络），以进一步验证和扩展这些发现。", "conclusion": "我们研究了神经网络模型的训练数据、模型大小和计算资源对材料属性预测性能的影响，通过实验发现了一套相关的标度定律，并为实际应用提供了指导。未来的研究可以进一步探索其他模型的相似规律及其对不同应用场景的适用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21895", "html_url": "https://arxiv.org/abs/2509.21895", "title": "基于RKHSs的代数框架为何高秩神经网络泛化", "title_en": "Why High-rank Neural Networks Generalize?: An Algebraic Framework with RKHSs", "authors": "Yuka Hashimoto,Sho Sonoda,Isao Ishikawa,Masahiro Ikeda", "background": "现有的一些Rademacher复杂度界试图解释高秩权重矩阵的模型为什么能够很好地泛化，但这些现有界限的应用范围有限，仅适用于特定类型的模型。", "innovation": "本文使用Koopman算子、群表示和再生核希尔伯特空间（RKHSs）推导出新的Rademacher复杂度界，提出了神经网络的代数表示，并构造了一个RKHS以推导更广泛的实际情况下的界限。", "conclusion": "这项工作为基于Koopman理论的Rademacher复杂度界限能够适用于更多实际情境奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21879", "html_url": "https://arxiv.org/abs/2509.21879", "title": "Zubov-Net: 调和准确性和鲁棒性的自适应稳定性神经ODE", "title_en": "Zubov-Net: Adaptive Stability for Neural ODEs Reconciling Accuracy with Robustness", "authors": "Chaoyang Luo,Yan Zou,Nanjing Huang", "background": "尽管神经常微分方程（Neural ODEs）由于其动力系统性质内在地具有对输入扰动的鲁棒性，但最近的一些方法往往通过引入基于李雅普诺夫的稳定性条件来提供形式化的鲁棒性保证。然而，鲁棒性和准确性的平衡依然是一个基本的挑战，主要源自于适当地施加稳定性的条件是困难的。", "innovation": "提出了一种自适应稳定学习框架Zubov-Net，通过将Zubov方程重新表述为吸引区域（RoAs）和预定吸引区域（PRoAs）之间的一致性表征，引入一种直接优化PRoAs以实现鲁棒性和准确性的平衡的新范式。Zubov-Net通过三部分损失（一致性损失、分类损失和分离损失）和并行边界采样算法实现这一目标，同时设计了一种基于输入注意力的凸神经网络，并引入了软最大注意力机制来提高Lyapunov函数的判别力。", "conclusion": "理论上，减少三部分损失能够确保PRoAs-RoAs的一致对齐、轨迹稳定性以及PRoAs的不重叠。实验上，Zubov-Net在保持高分类准确率的同时，显著提升了对各种随机噪声和对抗攻击的鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21898", "html_url": "https://arxiv.org/abs/2509.21898", "title": "CIL增量学习：Increment Vector Transformation方法", "title_en": "Closing the Oracle Gap: Increment Vector Transformation for Class Incremental Learning", "authors": "Zihuan Qiu,Yi Xu,Fanman Meng,Runtong Zhang,Linfeng Xu,Qingbo Wu,Hongliang Li", "background": "CIL的目标是在不忘记之前学习的内容的前提下逐步获取新类的知识。尽管最近有所进展，当前的CIL方法仍与有完整历史数据访问权限的oracle模型存在显著性能差距。", "innovation": "本文借鉴了线性模态连通性(LMC)的最新洞见，重新审视CIL中oracle解决方案的几何特性，提出了一种名为Increment Vector Transformation (IVT)的新颖插件框架，旨在训练过程中缓解灾难性遗忘现象。IVT通过周期性地将模型参数转移到保留与以前任务最优解线性连接的变换解决方案，有效地保持了之前学习任务的稳定性能。IVT通过近似对角Fisher信息矩阵实现高效的变换，适用于无示例和基于示例的场景，以及多种初始策略。", "conclusion": "在CIFAR-100、FGVCAircraft、ImageNet-Subset和ImageNet-Full等数据集上进行了广泛实验，证明IVT持续提升了强大的CIL基线模型的性能。具体而言，在CIFAR-100上，IVT提高了PASS基线的最终准确率+5.12%，降低了遗忘2.54%。在FGVCAircraft上，CLIP预训练的SLCA基线，在平均准确率上取得了+14.93%的增益，在最终准确率上取得了+21.95%的增益。代码将被发布。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21912", "html_url": "https://arxiv.org/abs/2509.21912", "title": "离散引导匹配：精确的离散流动匹配引导", "title_en": "Discrete Guidance Matching: Exact Guidance for Discrete Flow Matching", "authors": "Zhengyan Wan,Yidong Ouyang,Liyan Xie,Fang Fang,Hongyuan Zha,Guang Cheng", "background": "现有的离散数据建模方法主要关注通过一阶泰勒近似来改进采样效率，但这种方法在离散状态空间中可能不合适，因为近似误差可能很大。", "innovation": "本文提出了一个全新的离散数据引导框架，通过分析给定学习到的离散流匹配模型的所需分布的精确转换率，使得引导只需在每个采样步骤中进行一次前向传递，极大地提高了效率。该框架适用于现有的多种引导方法，并能无缝应用于掩蔽扩散模型。", "conclusion": "本文的研究在能量引导模拟和文本到图像生成以及多模态理解任务中的偏好对齐上展示了其有效性，并提供可访问的代码。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21835", "html_url": "https://arxiv.org/abs/2509.21835", "title": "关于掩码离散扩散复杂性理论：从多项式$1/ε$到几乎$ε$免费", "title_en": "On the Complexity Theory of Masked Discrete Diffusion: From $\\mathrm{poly}(1/ε)$ to Nearly $ε$-Free", "authors": "Xunpeng Huang,Yingyu Lin,Nishant Jain,Kaibo Wang,Difan Zou,Yian Ma,Tong Zhang", "background": "掩码离散扩散是一种在文本生成中逐层以特殊掩码符号损坏令牌再去噪的灵活框架。尽管该方法在实验上表现出色，但在高维设置下的理论复杂度仍需进一步理解。现有的分析主要集中在均匀离散扩散上，而近期关于掩码扩散的研究或忽略了广泛使用的欧拉采样器，或施加了限制性的有界分数假设，或未能充分展示出掩码离散扩散相对于其均匀对应版本的优势。因此，该研究旨在解决这种差距，通过对典型欧拉采样器在掩码离散扩散中的分析，提供首个严谨的分析。同时，通过提出一种名为Mask-Aware Truncated Uniformization（MATU）的方法，避免有界分数假设，保持离散分数近似无偏，并利用每个令牌最多只能一次去遮掩的特性，进一步提升了复杂度。", "innovation": "该研究通过对欧拉采样器的分析，提供了掩码离散扩散中首个严谨的欧拉采样器分析，相比已有均匀化方法，降低了复杂度并显著加快了收敛速度。进一步提出了MATU方法，去除了有界分数假设，保留了无偏离散分数近似，且复杂度接近$ε$自由的$O(d\text{ln}d·(1-ε^2))$。这些发现不仅为掩码离散扩散提供了一个严谨的理论基础，展示了其在文本生成中的实用优势，还为后续基于掩码框架的扩散语言模型分析铺平了道路。", "conclusion": "该研究不仅为掩码离散扩散提供了严格的理论基础，证明了它在文本生成中的实用优势，而且为未来基于掩码框架的扩散语言模型分析奠定了基础，通过MATU方法大大简化了复杂度，提高了收敛速度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21942", "html_url": "https://arxiv.org/abs/2509.21942", "title": "基于结构性信息的分层扩散方法在离线强化学习中的应用", "title_en": "Structural Information-based Hierarchical Diffusion for Offline Reinforcement Learning", "authors": "Xianghua Zeng,Hao Peng,Angsheng Li,Yicheng Pan", "background": "扩散基生成方法在离线强化学习(RL)数据集上建模轨迹表现出了良好的潜力，而分层扩散已被引入以缓解长期计划任务中的方差累积和计算挑战。然而，现有方法通常假设固有的两层分层结构，并且具有单个预定义的时间尺度，这限制了其对多样化的下游任务的适应性和在决策制定中的灵活性。", "innovation": "提出了SIHD（基于结构性信息的分层扩散框架），通过分析离线轨迹中嵌入的结构性信息来构建可适应的分层结构，实现多个时间尺度下的灵活轨迹建模。SIHD使用每个状态社区的结构性信息增益作为相应扩散层的条件信号，而非依赖于局部子轨迹的奖励预测。此外，引入了结构性熵正则化器，以鼓励探索未被充分代表的状态，并避免分布偏移导致的外推错误。SIHD在具有挑战性的离线RL任务中显示出显著优于当前最佳基线的表现，并且在不同场景中展现出更好的泛化能力。", "conclusion": "SIHD显著提高了决策性能，并且在多样化的场景中表现出更出色的泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21848", "html_url": "https://arxiv.org/abs/2509.21848", "title": "Graph of Agents：通过涌现多代理协作实现的原则化长上下文建模", "title_en": "Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration", "authors": "Taejong Joo,Shu Ishida,Ivan Sosnovik,Bryan Lim,Sahand Rezaei-Shoshtari,Adam Gaier,Robert Giaquinto", "background": "作为一种通用方法，多代理系统能够处理超过大型语言模型上下文窗口长度的输入，而无需重新训练或架构修改。然而，它们的性能很大程度上依赖于手动设计的多代理协作策略和指令工程，这限制了其通用性。在此之前的研究依赖于这些手工设计的方法来处理长上下文问题，导致了模型的局限性。本文提出了一个更加系统的框架，将通用的长上下文建模问题形式化为一个压缩问题，进而得到一个信息论上的压缩目标。基于该框架，提出了Graph of Agents（GoA），它能够动态地构建输入相关的协作结构，以最大化这一目标。", "innovation": "本文通过一个信息论上的压缩目标提出了一种新的框架，进而定义了Graph of Agents（GoA）模型，这种模型能够动态地构建输入相关的协作结构，以最大化这个目标。GoA在Llama 3.1 8B和Qwen3 8B上，在6个文档问答基准测试中，分别提高了平均F1分数5.7%和强多代理基线16.35%，证明了它在较小上下文窗口下的有效上下文长度可以显著超过大型语言模型Llama 3.1 8B在LongBench上的表现，展现出强大的性能优势。", "conclusion": "在该工作中，研究者提出了一种新的框架和方法（Graph of Agents），成功地解决了长上下文建模问题，不仅在模型大小接近的情况下超过了更大型的语言模型，还展示出了显著的效率提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21861", "html_url": "https://arxiv.org/abs/2509.21861", "title": "MolSpectLLM:连接光谱学、分子解析和三维结构生成的分子基础模型", "title_en": "MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation", "authors": "Shuaike Shen,Jiaqing Xie,Zhuo Yang,Antong Zhang,Shuzhou Sun,Ben Gao,Tianfan Fu,Biqing Qi,Yuqiang Li", "background": "近年来，分子基础模型在分子性质预测和从头分子设计方面展现了令人印象深刻的性能，特别是在药物发现和反应预测等领域具有广泛应用前景。然而，目前大多数方法仅依赖于SMILES表示，并忽视了如实验光谱和三维结构信息等重要数据来源，这在需要立体化学、空间构象和实验验证的任务中限制了其效果。", "innovation": "本文提出了MolSpectLLM，这是一个基于Qwen2.5-7B预训练模型，结合了实验光谱与分子三维结构的分子基础模型。MolSpectLLM通过明确建模分子光谱，取得了谱相关的任务上的最优性能。它在NMR、IR和MS基准测试上的平均准确率为0.53，在Spectra-to-SMILES任务上的序列准确率为15.5%，令牌准确率为41.7%，显著优于大型通用LLM。更加重要的是，MolSpectLLM不仅在分子解析任务上表现出色，还能够直接从SMILES或光谱输入生成准确的三维分子结构，实现了从光谱分析、分子解析到分子设计的桥梁。", "conclusion": "MolSpectLLM不仅在分子解析任务上表现出色，还能够直接从SMILES或光谱输入生成准确的三维分子结构，实现了光谱分析、分子解析与分子设计的衔接。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21847", "html_url": "https://arxiv.org/abs/2509.21847", "title": "超越约翰逊-拉赫纳：关于压缩形式的一致界", "title_en": "Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms", "authors": "Rohan Deb,Qiaobo Li,Mayank Shrivastava,Arindam Banerjee", "background": "围绕向量或矩阵的压缩内积，各种重要的计算和统计结果在机器学习和随机算法中都有所体现，包括约翰逊-拉赫纳（J-L）引理、受限正则等距性质（RIP）、随机投影和近似线性代数等。然而，现代分析中涉及压缩双线性形式（sketched bilinear forms）时，现有的统一界要么不适用，要么对于一般集合不精确。这项研究旨在开发一个通用框架来分析这些压缩双线性形式，在与关联集合的几何复杂性相关的上界中，我们的方法依赖于一般链复杂度并引入了处理集合对中上界的最新技术。此外，对于涉及独立采样矩阵和双线性形式的求和问题，展示了偏差的平方根缩放。这个统一的分析不仅恢复了J-L引理等已知结果，还扩展了RIP类保证。同时，改善了关于压缩形式下的联邦学习算法的收敛界限，并设计了基于几何复杂性的动作和参数集，具有更尖锐的遗憾边界的风险控制算法变体，而不是采用外部维度作为边界条件。", "innovation": "开发了一个通用框架来分析压缩双线性形式，并通过几何复杂性提出了统一的上界。采用了通用链技术，并引入了处理集合对上界的新型技术。将应用扩展到涉及独立采样矩阵求和的双线性形式，证明了偏差的平方根缩放。这种方法不仅恢复了J-L引理等已知结果，还扩展了RIP类型的保证。同时，该研究也提供了关于压缩形式下联邦学习算法的改进收敛边界，并设计了基于几何复杂性的动作和参数集的风险控制算法变体，而这些算法的遗憾边界依赖于几何复杂性而不是外部维度。", "conclusion": "通过构建一个通用框架并使用几何复杂性，本文在分析压缩双线性形式方面取得了进展，扩展了以前仅限于单个等式的J-L引理等结果。此外，通过引入处理集合对上界的新型技术，该研究应用这个通用方法以分析更复杂的矩阵求和双线性形式，并提出了基于这些新发现的风险控制算法变体，以便更好的控制算法性能边界。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21925", "html_url": "https://arxiv.org/abs/2509.21925", "title": "有限训练集下的随机插值生成性质", "title_en": "Generation Properties of Stochastic Interpolation under Finite Training Set", "authors": "Yunchen Li,Shaohui Lin,Zhou Yu", "background": "本文研究了在有限训练人群下生成模型的理论行为。在随机插值生成框架内，作者推导出当仅有有限数量训练样本可用时，最优速度场和得分函数的闭式表达式。研究表明，当满足某些正则条件时，确定性生成过程完全恢复训练样本，而随机生成过程表现为带有高斯噪声的训练样本。在理想化设置之外，本文考虑模型估计误差，并引入了特定于生成模型的过拟合和欠拟合的正式定义。理论分析表明，在存在估计误差的情况下，随机生成过程实际上产生训练样本的凸组合，受到均匀噪声和高斯噪声的混合影响。通过生成任务和下游任务分类的实验，支持了这一理论。", "innovation": "作者推导出有限样本情况下生成模型的最优速度场和得分函数的闭式表达式；引入了特定于生成模型的过拟合和欠拟合的定义；揭示了在估计误差存在的情况下，生成过程产生的图像是由训练样本的混合噪声（均匀和高斯）构成的凸组合。", "conclusion": "文章通过理论分析和实验支持，揭示了在有限样本下生成模型的行为，并为理解生成模型中的过拟合与欠拟合提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21882", "html_url": "https://arxiv.org/abs/2509.21882", "title": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards", "title_en": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards", "authors": "Aaron Tu,Weihao Xuan,Heli Qi,Xu Huang,Qingcheng Zeng,Shayan Talaei,Yijia Xiao,Peng Xia,Xiangru Tang,Yuchen Zhuang,Bing Hu,Hanqun Cao,Wenqi Shi,Tianang Leng,Rui Yang,Yingjian Chen,Ziqi Wang,Irene Li,Nan Liu,Huaxiu Yao,Li Erran Li,Ge Liu,Amin Saberi,Naoto Yokoya,Jure Leskovec,Yejin Choi,Fang Wu", "background": "该研究探讨了强化学习带有可验证奖励（RLVR）在提高大型语言模型在数学、代码及其他结构化任务中的表现时的实际效果和可扩展性。研究指出，尽管RLVR在某些方面表现出显著的进步，但报告的成果可能会被几个因素过度夸大，包括RLVR带来的成本、评价陷阱以及数据污染。为了更准确地评估RLVR的效果，研究使用了部分提示污染审计和预算匹配重生产方法，结果显示，在严格控制的评价条件下，一些声称的差异显著减小或消失。因此，研究提出了一种新的训练和评估协议，该协议能够优化准确度、涵摄性以及校准的弃权，并标准化预算分配和来源验证。该协议应用于最近的RLVR设置，提供了更可靠的推理收益估计，并在某些情况下修正了先前的结论。该研究的立场是建设性的，认为RLVR是有价值且已经准备好进入工业应用；研究提倡保持其实际价值，同时优先考虑可靠性、安全性和测量准确性。", "innovation": "该研究提出了一种新的训练和评估协议，该协议能够优化准确度、涵摄性以及校准的弃权，并标准化预算分配和来源验证。该协议应用于最近的RLVR设置，提供了更可靠的推理收益估计，并在某些情况下修正了先前的结论。此外，研究还提出了一些新观点，如讨论RLVR的实际成本和评价过程中存在的陷阱，以及数据污染问题。", "conclusion": "尽管RLVR在某些方面表现出显著的进步，但其效果可能会被几个因素过度夸大。提出的训练和评估协议能够提供更可靠的推理收益估计，并修正了先前的结论。研究立场是建设性的，认为RLVR是有价值且已经准备好进入工业应用；研究提倡保持其实际价值，同时优先考虑可靠性、安全性和测量准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21923", "html_url": "https://arxiv.org/abs/2509.21923", "title": "Multiplicative-Additive Constrained Models:向联合可视化交互和独立效应的方向", "title_en": "Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects", "authors": "Fumin Wang", "background": "在涉及生命安全的高风险领域（如医疗）中应用机器学习时，可解释性是一个重要的考量因素。广义加性模型（GAMs）通过可视化形状函数增强了可解释性，但为了保持这种可解释性，GAMs 必须忽略高阶交互效应对预测性能造成显著限制。尽管曲线遍历集回归（CESR）模型能够自然地可视化其形状函数并同时整合所有特征间的交互效应和单个特征效应，但它并未表现出优于GAMs的预测性能。因此，作者引入了混合乘法和加性约束模型（MACMs），该模型通过增加加性部分来分离CESR中的交互项和独立项的系数，从而扩大了假说空间。MACMs 结合了CESR和GAMs的优点，使形状函数能够自然可视化，从而帮助用户理解特征在决策过程中的作用。实验结果表明，基于神经网络的MACMs 在预测性能上显著优于CESR和当前最先进的GAMs", "innovation": "作者提出了混合乘法和加性约束模型（MACMs），通过在CESR的基础上增加加性部分，分离交互项和独立项的系数，从而扩大假说空间，同时保持预测性能。MACMs 的形状函数可以自然可视化，增强模型的可解释性", "conclusion": "混合乘法和加性约束模型（MACMs）在预测性能上显著优于曲线遍历集回归（CESR）和当前最先进的广义加性模型（GAMs）。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22015", "html_url": "https://arxiv.org/abs/2509.22015", "title": "概念自编码器：视觉模型行为的主动因果探查", "title_en": "Concept-SAE: Active Causal Probing of Visual Model Behavior", "authors": "Jianrong Ding,Muxi Chen,Chenchen Zhao,Qiang Xu", "background": "标准稀疏自编码器(SAEs)能够发现模型学习特征的字典，提供了强大的观察工具。然而，这些特征的模糊性和缺乏根基性使其对于模型行为的主动因果探查不够可靠。", "innovation": "本文引入了概念自编码器(Concept-SAE)，通过一种新的混合解耦策略生成语义上根基明确的概念标记。定量验证表明，我们的双监督方法生成的标记具有非凡的忠实性和空间局部性，优于其他方法。验证的忠实性使得可以进行两个关键应用：(1) 通过直接干预探查内部概念和预测之间的因果联系；(2) 通过系统定位特定层的对抗性漏洞来探查模型的故障模式。", "conclusion": "概念自编码器提供了一个验证性的框架，用于从关联性解析向机理性、因果性的模型行为探查迈进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21960", "html_url": "https://arxiv.org/abs/2509.21960", "title": "智能思考，而非过度思考：大型音频语言模型的难度自适应推理", "title_en": "Think Smart, Not Hard: Difficulty Adaptive Reasoning for Large Audio Language Models", "authors": "Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li", "background": "大型音频语言模型（LALMs），依托于链式思考（CoT）范式，展现出了显著的推理能力。尽管不同问题往往需要不同的推理深度，现有的方法通常是“一刀切”的推理深度，导致简单问题上过度推理，复杂问题上推理不足。因此，研究者认识到LALMs需要根据不同问题的复杂度灵活调整推理深度，从而实现更有效的推理。", "innovation": "该研究提出了一种难度自适应推理方法，通过提出一种动态连接推理长度和模型感知问题难度的奖励函数，促使模型对简单任务进行简洁快速推理，对复杂任务进行深入仔细推理，从而提高任务性能并显著减少平均推理长度。这一方法在广泛的实验中表现出高效性和有效性，为未来的推理结构研究提供了宝贵见解。", "conclusion": "该研究深入分析了LALMs，并提出了一个能根据问题复杂度灵活调整推理深度的有效机制，从而改善任务表现，减少平均推理长度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21947", "html_url": "https://arxiv.org/abs/2509.21947", "title": "Active Attacks: 通过自适应环境红队 LLMs", "title_en": "Active Attacks: Red-teaming LLMs via Adaptive Environments", "authors": "Taeyoung Yun,Pierre-Luc St-Charles,Jinkyoo Park,Yoshua Bengio,Minsu Kim", "background": "该研究针对大型语言模型（LLMs）生成多样且引致有害行为（如侮辱、性内容）的攻击提示的问题。现有的方法依赖于手动提示工程，而论文提出通过强化学习（RL）训练攻击剂LLMs，仅使用毒性分类器作为奖励来自动生成这些提示。尽管如此，捕捉广泛有害行为是一个挑战，需要明确的多样性目标。现有方法常常在找到高奖励提示后，抑制对新区域的探索。", "innovation": "论文引入了名为 'Active Attacks' 的 novel RL 基红队算法，该算法根据受害目标的变化而调整其攻击策略。通过定期使用收集到的攻击提示对受害目标LLM进行安全微调，被利用区域的奖励会变得不那么有吸引力，迫使攻击者寻找未探索的漏洞。这种方法自然地促进了易于到困难的探索课程，攻击者从简单模式逐步向更难的模式发展。Active Attacks 成为了一个简单的即插即用模块，无缝集成到现有的 RL 目标中，并意外地超越了先前的 RL 方法，包括GFlowNets、PPO和REINFORCE，成功提高了跨攻击成功率为 31.28%，相对提升超过400倍，计算量仅增加6%。代码已公开提供。", "conclusion": "Active Attacks 逐步揭露了广泛的局部攻击模式，并通过结合实现了多模态分布的广泛覆盖。这种方法意外地超过了先前的 RL 方法，并为 LLMS 安全微调提供了新方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21936", "html_url": "https://arxiv.org/abs/2509.21936", "title": "softmax关注的优势：来自单一位置回归的见解", "title_en": "Statistical Advantage of Softmax Attention: Insights from Single-Location Regression", "authors": "O. Duranthon,P. Marion,C. Boyer,B. Loureiro,L. Zdeborová", "background": "大型语言模型依赖于具有softmax激活的注意机制。然而，softmax在替代选项（如逐元素或线性）中的主导地位及其理论基础尚未被充分理解。许多理论工作集中在更易于分析的线性化注意上。本文通过建立在统计物理学概念的基础上，从高维极限中分析基于注意的预测器，探讨单一输入位置的回归任务，揭示softmax与线性注意等激活函数的性能差异及其必要特性。", "innovation": "本文针对单一输入位置的回归任务进行了一种新的方法论研究，通过统计物理学的方法，从理论和实证两方面检验不同激活函数在注意机制中的表现。研究首次揭示了softmax在理论上的优势，并通过分析有限样本情况下的性能差异，进一步明确了其在实际应用中的优越性。", "conclusion": "在高维情况下，softmax能够实现贝叶斯风险，而线性注意无法达到这种最优性能。其他激活函数的研究进一步确定了实现最优性能的必要条件。在有限样本情况下，尽管softmax不再是贝叶斯最优解，但它表现一致优于线性注意。这为进一步优化基于注意机制的模型提供了理论依据和方向。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21934", "html_url": "https://arxiv.org/abs/2509.21934", "title": "使用小波和3D循环表示的 Vision LLMs 从建筑能耗数据中提取可操作洞察", "title_en": "Extracting Actionable Insights from Building Energy Data using Vision LLMs on Wavelet and 3D Recurrence Representations", "authors": "Amine Bechar,Adel Oulefki,Abbes Amira,Fatih Kurogollu,Yassine Himeur", "background": "分析复杂的建筑时间序列数据以获得可操作的见解和建议仍然具有挑战性，因为能耗数据具有非线性和多尺度的特点。针对这一挑战，需要一种能够理解这些复杂数据的框架，以提供关于能源效率的建议。本文通过使用连续小波变换（CWT）和循环图（RP）将1D时间序列转换为3D表示，来提升视觉语言大型模型（VLLMs）的性能，从而更有效地捕捉时间动态和局部频率异常。这些3D编码使得VLLMs能够解读能源消耗模式、检测异常并提出节能建议。该方法已经在实际的建筑能源数据集上进行了验证，并取得了优于直接在原始时间序列数据上进行微调的效果。", "innovation": "提出了一种框架，通过将视觉语言大型模型（VLLMs）在3D图形表示的能耗数据上进行微调，将1D时间序列转换为3D表示，并使用连续小波变换（CWT）和循环图（RP）来捕捉能量消耗的时序动态和频率异常。这种方法使得VLLMs能够更好地理解建筑能耗模式，检测异常，并生成节能建议。研究表明，使用连续小波变换（CWT）和循环图（RP）进行微调的 Idefics-7B VLLM 在阿联酋大学的能耗数据集上实现了更有竞争力的验证损失，优于直接针对原始时间序列数据进行微调的效果。", "conclusion": "该研究通过结合时间序列分析和可视化，提供了一种可扩展且易于解释的框架，用于能耗数据分析。这种方法提高了对建筑能耗模式的理解，并成功地监测建筑状态、识别重复异常并生成优化建议。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22028", "html_url": "https://arxiv.org/abs/2509.22028", "title": "MCGM：分子中长程相互作用的多阶段聚类全局建模", "title_en": "MCGM: Multi-stage Clustered Global Modeling for Long-range Interactions in Molecules", "authors": "Haodong Pan,Yusong Wang,Nanning Zheng,Caijui Jiang", "background": "几何图神经网络（GNNs）擅长捕捉分子几何结构，但其局部消息传递机制限制了对远程相互作用的建模。当前的方法存在根本性限制：扩展截止半径会导致计算成本随距离立方增长；基于物理学的核函数（如库仑、范德华等）往往是系统特定的，缺乏通用性；傅里叶空间方法需要谨慎调整多个参数（例如网格大小、k空间截止值），并且增加了计算开销。", "innovation": "提出了多阶段集群全局建模（MCGM），这是一种轻型即插即用模块，通过高效的聚类操作赋予几何GNN分层全局上下文。MCGM构建了原子集群的多分辨率层次结构，通过动态的层次聚类提取全局信息，并通过学习转换传播这种上下文，最终通过残差链接加强原子特征。", "conclusion": "MCGM无缝集成到四个不同的骨干架构中，平均减少了26.2%的OE62能量预测误差。在AQM上，MCGM达到了最先进的精度（能量17.0 meV，力4.9 meV/Å），使用的参数比Neural P3M少20%。代码将在接受后公开。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22038", "html_url": "https://arxiv.org/abs/2509.22038", "title": "Latent Diffusion: 多维度稳定扩散潜在空间探索者", "title_en": "Latent Diffusion : Multi-Dimension Stable Diffusion Latent Space Explorer", "authors": "Zhihua Zhong,Xuanyang Huang", "background": "生成性人工智能中，潜在空间是一个关键概念，通过向量操作提供强大的创意探索手段。然而，扩散模型如Stable Diffusion在潜在向量控制方面不如生成对抗网络(GANs)直观，限制了它们在艺术表达上的灵活性。", "innovation": "本文介绍了一种将可定制的潜在空间操作整合到扩散过程中的框架。通过直接操控概念性和空间性表示，该方法扩展了生成艺术的创造性可能性。研究表明，潜在空间具有语义和无意义区域，揭示了扩散模型的几何结构，为进一步探索潜在空间铺平了道路。", "conclusion": "通过两件作品《Infinitepedia》和《Latent Motion》展示了这种框架在概念混杂（conceptual blending）和动态运动生成中的应用潜力，揭示了潜在空间的结构，并提供了探索潜在空间的新见解。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22007", "html_url": "https://arxiv.org/abs/2509.22007", "title": "扩散模型中分类器无关指导的阶段动态", "title_en": "Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models", "authors": "Cheng Jin,Qitan Shi,Yuantao Gu", "background": "分类器无关指导（CFG）被广泛应用于提高扩散模型的条件保真度，但其对采样动力学的影响仍不甚明了。先前的研究通常局限于单模条件分布或简化情况，提供的只是片面观点。本研究分析了在多模条件下的CFG，并发现采样过程分为三个连续阶段。还表明更强的指导会提升语义对齐但也减少了多样性，早期强指导侵蚀了全局多样性，晚期强指导则抑制了细节变化。新的理论自然提示了时间变化的指导计划，实验证明逐阶段指导能高质量并提升多样性.", "innovation": "首次系统的分析了CFG在多模条件下采样过程的三个阶段。提出了方向转变、模态分离和集中三个阶段的概念，并解释了更强的指导如何影响语义对齐和多样性。此外，提供了一种时间变化的指导计划，实验验证了其有效性，展示了其在提升质量和多样性方面的优势。", "conclusion": "研究表明，更强的指导会改善语义对齐但减少了多样性。早期强指导侵蚀了全局多样性，而晚期强指导抑制了细节变化。因此，提出了一种基于时间变化的指导计划，实验验证了其有效提升了质量和多样性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21971", "html_url": "https://arxiv.org/abs/2509.21971", "title": "GRAM-TDI: 适应性多模态表示学习在药物靶点相互作用预测中的应用", "title_en": "GRAM-TDI: adaptive multimodal representation learning for drug target interaction prediction", "authors": "Feng Jiang,Amina Mollaysa,Hehuan Ma,Tommaso Mansi,Junzhou Huang,Mangal Prakash,Rui Liao", "background": "药物靶点相互作用（DTI）预测是计算药物发现的基石，有助于理性的药物设计、重定位和机制的深入理解。尽管深度学习加快了DTI建模，但现有方法主要依赖于小分子和蛋白质的SMILES对，未能充分利用高度丰富的多模态信息。", "innovation": "我们提出了GRAMDTI（适应性多模态表示学习框架），将多模态分子和蛋白质输入整合到统一表示中，并将基于体积的对比学习扩展到四个模态，捕获超越传统成对方法的高级语义对齐。此外，提出适应性的模态丢弃，动态调节每种模态在预训练过程中的贡献，并引入IC50活性测量作为弱监督，以使表示与生物意义的相互作用强度对齐。实验结果表明，GRAMDTI在四个公开数据集上持续优于最先进的基线。", "conclusion": "我们的结果强调了高级的多模态对齐、适应性的模态利用以及辅助监督对DTI预测鲁棒性和泛化能力的益处。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22008", "html_url": "https://arxiv.org/abs/2509.22008", "title": "通过大型语言模型实现目标导向高效探索", "title_en": "Goal-Guided Efficient Exploration via Large Language Model in Reinforcement Learning", "authors": "Yajie Qi,Wei Wei,Lin Li,Lijun Zhang,Zhidong Gao,Da Wang,Huizhong Song", "background": "在现实世界中，决策任务通常发生在复杂且开放的环境中，这对强化学习（RL）代理的探索效率和长期规划能力提出了重大挑战。一种有前景的方法是将LLM增强的RL结合起来，利用LLMs丰富的先验知识和强大的规划能力来指导RL代理进行高效的探索。然而，现有的方法大多依赖频繁且昂贵的LLM调用，在语义不匹配的情况下表现不佳。", "innovation": "本文引入了一种结构化目标导向的强化学习（SGRL）方法，该方法结合了结构化目标规划器和目标条件动作剪枝器，来引导RL代理进行高效的探索。具体来说，结构化目标规划器利用LLMs生成可重复使用的、结构化的目标生成函数，并按照优先级确定目标。此外，通过利用LLMs确定目标的优先权重，动态生成前瞻性的目标来引导代理的策略走向更具前景的决策路径。目标条件动作剪枝器则通过动作掩码机制筛选出与当前目标不一致的动作，从而约束RL代理选择目标一致的策略。", "conclusion": "我们评估了所提出的方法在Crafter和Craftax-Classic中的表现，并且实验结果表明SGRL在性能上优于现有最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22047", "html_url": "https://arxiv.org/abs/2509.22047", "title": "MO-GRPO：在多目标问题中缓解组相对策略优化中的奖赏劫持", "title_en": "MO-GRPO: Mitigating Reward Hacking of Group Relative Policy Optimization on Multi-Objective Problems", "authors": "Yuki Ichihara,Yuu Jinnai,Tetsuro Morimura,Mitsuki Sakamoto,Ryota Mitsuhashi,Eiji Uchibe", "background": "存在准确奖励模型的有效算法Group Relative Policy Optimization (GRPO)，但在许多实际任务中不可能获得这种高度可靠的奖励模型。GRPO在多目标设置中表现出对奖赏劫持的脆弱性，倾向于优化单一目标而牺牲其他目标的优化。", "innovation": "提出了一种称为MO-GRPO的新算法，它是一种扩展的GRPO，加入了一个简单的归一化方法，可以自动根据各个奖励函数值的方差重新加权这些奖励函数。MO-GRPO保证所有奖励函数均匀地贡献于损失函数，同时保留偏好顺序，无需手动调整奖励函数的缩放。", "conclusion": "实验结果表明，MO-GRPO能够通过均匀分配奖励组件之间的相关性实现稳定的学习，相较于GRPO表现更优，证明MO-GRPO是多目标强化学习问题的一个有前景的算法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22023", "html_url": "https://arxiv.org/abs/2509.22023", "title": "通过高效尝试与错误教会变换器解决组合问题", "title_en": "Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error", "authors": "Panagiotis Giannoulis,Yorgos Pantis,Christos Tzamos", "background": "尽管大型语言模型（LLMs）在各种语言任务上表现出色，但在解决组合问题如可满足性问题、旅行商问题或基础算术等方面却表现不佳。本文针对这一局限，提出了一种新的方法来解决NP类问题，专注于经典的数独任务，实现了与先前神经-符号方法相比的最优准确率（99%）", "innovation": "本文方法不同于以往使用定制架构的研究，采用了标准的仅解码器Transformer（GPT-2），没有使用外部工具或函数调用。该方法结合了模仿学习简单的数独规则与改进的深度优先搜索（DFS）探索策略，包括启发式的猜测和回溯，并进一步减少猜测次数直到得出解决方案", "conclusion": "本文对这种设置进行了严格的分析，证明了其与算法和随机优化领域广泛研究的最小和集合覆盖问题的上下文变体之间的联系。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22082", "html_url": "https://arxiv.org/abs/2509.22082", "title": "非线性轨迹建模在联邦学习多步梯度反转攻击中的应用", "title_en": "Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning", "authors": "Li Xia,Zheng Liu,Sili Huang,Wei Tang,Xuan Liu", "background": "联邦学习（FL）通过保持原始数据本地化来保护隐私，但梯度反转攻击（GIAs）仍然构成重大威胁。在FedAVG多步骤场景中，攻击者只能观察到聚合梯度，使得数据重建变得困难。现有的代理模型方法，如SME，假设参数轨迹为线性，但这种方法严重低估了随机梯度下降（SGD）的非线性复杂性，极大限制了攻击的有效性。", "innovation": "本文提出了Non-Linear Surrogate Model Extension（NL-SME），这是首个将非线性参数轨迹建模技术引入GIAs中的方法。NL-SME使用可学习的二次Bézier曲线替代线性插值，通过控制点捕捉SGD的曲线特征，并结合正则化和dvec归一化机制，增强模型的表达能力。", "conclusion": "在CIFAR-100和FEMNIST数据集上的大量实验表明，NL-SME在所有指标上均显著优于基准方法，提升了余弦相似度损失量级的数量级同时保持计算效率。本文揭示了FL多步骤更新范式下的隐私脆弱性，并为开发稳健的防御策略提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22020", "html_url": "https://arxiv.org/abs/2509.22020", "title": "WeatherPEFT：面向天气基础模型的任务自适应参数高效微调", "title_en": "Task-Adaptive Parameter-Efficient Fine-Tuning for Weather Foundation Models", "authors": "Shilei Cao,Hehai Lin,Jiashun Cheng,Yang Liu,Guowen Li,Xuehe Wang,Juepeng Zheng,Haoyuan Liang,Meng Jin,Chengwei Qin,Hong Cheng,Haohuan Fu", "background": "近年来，机器学习的进步赋予了天气基础模型（WFMs）在多样化的下游任务上拥有较强的泛化能力。然而，WFMs的规模扩大导致了日益增长的计算需求，这极大地阻碍了其在实际中的部署。当前的参数高效微调方法（PEFT），主要是为视觉或语言任务设计，未能解决天气下游任务的特殊挑战，如变量异质性、分辨率多样性及时空覆盖变化。因此，这些方法在应用于WFMs时，导致了次优性能。", "innovation": "为填补这一空白，我们提出了WeatherPEFT，一种专为WFMs设计的新颖PEFT框架，该框架包含了两个协同创新：（1）在前向传播期间，引入任务自适应动态提示（TADP），动态地将编码器中的嵌入权重注入到预训练主干网络的输入标记中，通过内部和外部模式提取，这使得特征重新校准可以针对特定的下游任务，从而实现了上下文感知。（2）在反向传播阶段，引入了随机Fisher引导自适应选择（SFAS），它不仅利用Fisher信息来识别和更新最相关的任务参数，保持了先前的预训练知识，而且还引入了随机性以稳定选择过程。", "conclusion": "我们在三个下游任务上展示了WeatherPEFT的有效性，当前PEFT方法与全参数调整（Full-Tuning）相比存在显著差距，而WeatherPEFT能够在较少的可训练参数下实现与Full-Tuning相当的性能。我们已发布了该工作的代码。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22017", "html_url": "https://arxiv.org/abs/2509.22017", "title": "AEGIS: 在稀疏边缘双部知识图中的真实边缘增长", "title_en": "AEGIS: Authentic Edge Growth In Sparsity for Link Prediction in Edge-Sparse Bipartite Knowledge Graphs", "authors": "Hugh Xuechen Liu,Kıvanç Tatar", "background": "在特定领域中的双部知识图往往数据贫乏且边缘稀疏，这种情况下会阻碍链接预测的效果。因此，针对这种情况，通常的数据丰富方法如补全或合成新的边缘会引入虚假节点，进而降低预测的可靠性。", "innovation": "AEGIS框架提出了一种仅边缘增强方法，该方法通过重新采样已有的训练边缘（可以是均匀简单的，也可以是按逆度偏置度感知的），从而保留了原始节点集并避免了人工生成的端点。该方法试图通过自然稀疏图（如游戏设计模式的游戏模式网络）和通过高通率弦连通过程人为诱导稀疏性的稠密基准图（如亚马逊，电影评分）来验证其真实性。AEGIS在链路预测的两个互补度量方面进行了评估：AUC-ROC（越高越好）和贝叶斯评分（越低越好），并通过双尾配对t检验与稀疏基线进行对比。", "conclusion": "AEGIS方法在亚马逊和电影评分数据集的拷贝变体上表现与基线相当，且唯一能恢复AUC和校准的是语义最近邻增强方法；而随机和合成边缘则存在不利影响。在富含文本的GDP图中，语义最近邻方法实现了最大的AUC改进和贝叶斯评分降低，且简单方法也能降低贝叶斯评分。这些发现表明，在稀疏的双部链接预测中，基于真实性的重采样是一种经济高效的数据增强策略，当有信息性的节点描述可用时，语义增强可以提供额外的提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22033", "html_url": "https://arxiv.org/abs/2509.22033", "title": "OrtSAE: 正交稀疏自编码器揭示原子特征", "title_en": "OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features", "authors": "Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Rogov,Elena Tutubalina,Ivan Oseledets", "background": "稀疏自编码器（SAEs）是一种将神经网络激活稀疏分解为人易于理解的特征的技术。现有的SAEs存在特征吸收和特征组合的问题。特征吸收是指专门化的特征捕捉一般特征的实例，导致特征表示的空洞；特征组合则指独立特征合并成复合表示。", "innovation": "本文提出了一种名为正交自编码器（OrtSAE）的新方法，旨在通过强制特征间的正交性来解决上述问题。OrtSAE通过惩罚SAE特征之间的高成对余弦相似性，促进稀疏分解特征的发展，同时计算开销与SAE大小成线性关系，避免显著的计算开销。此外，OrtSAE还在不同模型和层中进行了训练，并与其它方法进行了比较，结果表明OrtSAE能发现更多独特的特征，减少特征吸收和组合，提高去除虚假相关性方面的性能，并且在其它下游任务中的表现与传统SAE相当。", "conclusion": "OrtSAE通过强制特征间的正交性提高了特征发展质量，并在众多方面优于现有的SAE方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22111", "html_url": "https://arxiv.org/abs/2509.22111", "title": "通过混合类型贝叶斯网络在排球中建模心理特征", "title_en": "Modeling Psychological Profiles in Volleyball via Mixed-Type Bayesian Networks", "authors": "Maria Iannario,Dae-Jin Lee,Manuele Leonelli", "background": "心理属性很少独立存在：教练们在考虑运动员的心理特质时，通常会将其看作是相互关联的一系列特质。本文分析了来自意大利C和D联赛的164名女子排球运动员的数据集，结合了标准化的心理评估和背景信息，这些信息包括问卷数据、统计指标以及人口统计学特征。研究表明，心理特质之间的关系复杂且相互关联，需要一种能够处理不同类型变量的建模方法。", "innovation": "本文引入了一种名为“潜在MMHC”的混合结构学习方法，这是一种结合了潜在高斯copula和平价约束以及约束得分优化的方法，以确定混合类型的变量之间的有向关系。此外，还包括了一种bootstrap聚合变体以增加稳定性。实验结果表明，这种方法在结构哈米尔顿距离和边召回率上优于其他copula基于的学习方法，同时保持了高特异性。这种方法为整理体育中心理特质提供了可解释的数据驱动框架，有助于运动员的发展决策。", "conclusion": "通过建模，研究构建了排球运动员的心理特质网络，发现动机、焦虑、目标设定和自信心之间存在密切关联，大五人格特质（神经质和外向性）在技能群方面处于上游位置。对特定技能改进如何通过网络导致准备、信心和自尊心的变化进行了量化分析，为运动员心理特征的表征提供了一种新的可解释的数据驱动框架，并且能够支持运动员发展的决策支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22113", "html_url": "https://arxiv.org/abs/2509.22113", "title": "在回归分析中对抗性欺骗的防控", "title_en": "Countering adversarial evasion in regression analysis", "authors": "David Benfield,Phan Tu Vuong,Alain Zemkoho", "background": "对抗性机器学习挑战了预测模型训练和实施过程中基础分布保持一致性的假设。特别是在垃圾邮件过滤、恶意软件检测和伪造图像生成等应用场景中，安全方法需要不断更新以应对不断改进的恶意数据生成技术。已有研究表明，博弈论模型能有效模拟这些场景并训练出对这些对手具有抵抗力的预测器。近期，在非凸性和非唯一性假设下应用悲观的二阶优化的研究表明，这种方法特别适用于缓解分类器受到对手威胁的能力。", "innovation": "本文提出的是一种悲观的二阶优化程序，用于处理回归分析中的对抗性欺骗问题，该程序不依赖于对手解的凸性或唯一性假设。", "conclusion": "本文提出的方法为提高回归模型在对抗性环境中的鲁棒性提供了一个新的思路，可以更好地抵御恶意对手的策略干扰。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22056", "html_url": "https://arxiv.org/abs/2509.22056", "title": "探究参数转移中特征学习的理解", "title_en": "Towards Understanding Feature Learning in Parameter Transfer", "authors": "Hua Yuan,Xuran Meng,Qiufeng Wang,Shiyu Xia,Ning Xu,Xu Yang,Jing Wang,Xin Geng,Yong Rui", "background": "参数转移是迁移学习的核心范式，通过在上游和下游模型之间共享模型参数，实现知识在任务和领域的重用。然而，当只转移上游模型的一部分参数到下游模型时，对于什么时候以及哪些因素影响其有效性，理论上的理解仍然不足。因此，文章选择在ReLU卷积神经网络（CNNs）的上下文中进行分析，探讨参数转移的机制，以填补这一理论空白。", "innovation": "分析聚焦于ReLU卷积神经网络模型，揭示在特征转移过程中，已继承的参数如何作为普遍知识的载体，并识别影响其对目标任务积极作用的关键因素。此外，文章还探讨了为何在某些情况下，参数转移可能会导致在目标任务上的测试准确率低于从头开始训练新模型。通过数值实验和实际数据实验，证实了理论发现的有效性。", "conclusion": "文章通过理论分析和实验证实了在ReLU卷积神经网络的背景下，参数转移的过程不仅可能提升目标任务的性能，也可能在某些情况下降低性能，提供了理解特征学习在参数转移中的机制，加深了对参数转移优劣条件的认知。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22043", "html_url": "https://arxiv.org/abs/2509.22043", "title": "基于凸性驱动的点云降维投影方法", "title_en": "Convexity-Driven Projection for Point Cloud Dimensionality Reduction", "authors": "Suman Sanyal", "background": "该研究提出了一个基于凸性的点云降维方法，以保持点云局部非凸性，尤其是在路径和最短路径之间的非线性偏差方面。传统的点云降维方法要么偏向保持全局凸性，要么牺牲局部结构信息，这限制了它们在特定应用中的表现。本文的目标是设计一种能够更精确地保留点云局部结构特征的降维方法，特别是那些由于路径冗长而产生的非凸性特征。这是在充分理解和处理点云局部几何信息的基础上提出的创新研究。", "innovation": "本文创新地提出了一种名为Convexity-Driven Projection (CDP)的方法，这是一种边界自由的线性降维方法，特别针对点云中存在的通过路径非适合性和最短路径之间的差异”来保留局部非凸性。CDP通过构建k近邻图，识别出可接受的每对节点，其欧氏距离与最短路径比例低于临界值，然后计算它们的方向，并使用这些方向来构建一个半正定的非凸结构矩阵。投影步骤基于该矩阵的前k大特征向量。这种方法提供了一种验证性保证，包括基于每对节点的具体后验证书和广义光谱界限，这些界限与结构矩阵的特征值相关连，提供了典型畸变的度量。该研究表明了在固定和重新选择的对中的绕路误差和证书的百分位数，为研究者提供了实用的手段来验证该方法的实际效果和实际保证。", "conclusion": "实验证明了该方法在保留点云局部非凸性方面的优越性，并且通过详尽的验证性保证表明了方法的可靠性。研究结果适用于处理复杂几何结构的点云数据，并且为其他基于几何结构的点云处理技术开辟了新的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22115", "html_url": "https://arxiv.org/abs/2509.22115", "title": "少而精：一种高效的双重层次逐层下采样框架以实现高效的策略优化", "title_en": "Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization", "authors": "Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding", "background": "无监督方法如GRPO能够通过从多个模拟运行中估计优势来减少内存需求，但通常收敛速度较慢，因为关键的学习信号被大量的无用样本和标记稀释了。", "innovation": "提出了动态双重层次逐层下采样（D$^3$S）框架，该框架通过优先选择最具有信息量的样本和标记在各个组中来提高策略优化的效率。D$^3$S在两个层次上操作：（1）样本层次，通过选择最大化优势方差的子集来优化优势。理论证明了这种选择与策略梯度范数的上界正相关，从而提高了策略梯度。（2）标记层次，优先选择带有高优势幅度和策略熵乘积的标记，关注那些政策既不确定又重要的更新。此外，为了防止过拟合到高信号数据，D$^3$S使用了一种灵感来自于课程学习的动态下采样调度。", "conclusion": "在Qwen2.5和Llama3.1上的广泛实验表明，将D$^3$S融入先进的RL算法可以实现最先进的性能和泛化能力，同时减少了多样推理基准上的样本和标记数量。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22053", "html_url": "https://arxiv.org/abs/2509.22053", "title": "在内部类别对比学习中增强知识蒸馏", "title_en": "Enriching Knowledge Distillation with Intra-Class Contrastive Learning", "authors": "Hua Yuan,Ning Xu,Xin Geng,Yong Rui", "background": "自从知识蒸馏出现以来，许多研究都集中于研究教师模型生成的软标签如何被有效地利用。现有研究指出，软标签中的隐含知识源自数据中的多视角结构。样本内类别的特征变化使学生模型能够通过学习多样化的表示获得更好的泛化。然而，在现有的蒸馏方法中，教师模型主要依赖于真实标签作为目标，而不考虑同一个类别中的多样表示。因此，我们提出在教师模型训练过程中引入内部类对比损失，以丰富软标签中的内部类信息。实践中，我们发现内部类损失会导致训练不稳定，并且减缓收敛速度。为了缓解这些问题，我们整合了边际损失到内部类对比学习中，以提高训练的稳定性并加快收敛速度。同时，我们对这种损失对内部类间距离和类别间距离的影响进行了理论分析。", "innovation": "我们提出了一种在教师模型训练中引入内部类对比损失的方法，以丰富软标签中的内部类信息，并引入了边际损失来改善训练稳定性和收敛速度。这是对现有知识蒸馏方法的创新改进，特别强调了类别内部的多样性和代表性学习。", "conclusion": "实验结果证明了该方法的有效性。这种方法通过引入内部类对比损失及其边际调整，提高了知识蒸馏的效果，特别是在处理类别内多样性和泛化问题上显示出潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22050", "html_url": "https://arxiv.org/abs/2509.22050", "title": "BrainPro:向大规模脑状态感知EEG表示学习迈进", "title_en": "BrainPro: Towards Large-scale Brain State-aware EEG Representation Learning", "authors": "Yi Ding,Muyun Jiang,Weibang Jiang,Shuailei Zhang,Xinliang Zhou,Chenyu Liu,Shanglin Li,Yong Li,Cuntai Guan", "background": "脑电图（EEG）是一种非侵入性的技术，用于记录大脑的电活动，广泛应用于脑-计算机接口（BCI）和医疗保健领域。近年来，基于大型数据集训练的EEG基础模型在性能和泛化能力上超过了传统的解码方法，但仍然存在显著的挑战。现有的模型通常未能明确捕捉信道到信道和区域到区域的交互，这些交互在EEG信号中是固有的重要信息源。由于不同数据集的电极配置各异，它们要么使用自注意力近似空间结构，要么仅在有限的常见电极上进行训练，从而牺牲了灵活性和有效性。此外，尽管EEG数据集反映了多种脑态，如情绪、运动等，但当前模型在自监督预训练过程中很少学习到状态感知表示。", "innovation": "我们提出了BrainPro，一种大型EEG模型，通过引入基于检索的空域学习模块灵活地捕捉不同电极布局下的信道和区域级交互，并通过平行编码器和去耦、区域感知重建损失学习状态感知的表示学习模块。这种设计使BrainPro能够无缝适应各种任务和硬件设置，并在广泛的数据集上实现最先进的性能和稳健的泛化能力。", "conclusion": "预训练于广泛的EEG语料库，BrainPro在九个公开的BCI数据集上实现了最先进的性能和稳健的泛化能力。我们的代码和预训练权重将公开提供。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22121", "html_url": "https://arxiv.org/abs/2509.22121", "title": "Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models", "title_en": "Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models", "authors": "Jeong Eul Kwon,Joo Heung Yoon,Hyo Kyung Lee", "background": "电子健康记录（EHR）中的时间序列数据因其不规则采样和高缺失性而带来了挑战，这些数据中的临床变量根据工作流程和干预时间以不均一的间隔进行测量。为了解决这些问题，该论文提出了一种名为VITAL的框架，专门用于从不规则采样的生理时间序列中学习。", "innovation": "VITAL框架区分了临床变量的两种类型：经常记录且具有时间模式的重大生命体征，与记录不频繁且缺乏时间结构的实验室测试。VITAL将重大生命体征重新编程到语言空间中，使大型语言模型能够捕获时间上下文并通过显式编码来推断缺失值。实验室变量则通过代表性的汇总值或可学习的'[未测量]'标记进行嵌入。", "conclusion": "VITAL在PhysioNet基准数据集上的全面评估表明，其在处理不规则时间序列方面优于当前最先进的方法，并且即使在高缺失性下也能保持稳健的性能，这是临床场景中的常见情况，其中关键变量往往不可用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22100", "html_url": "https://arxiv.org/abs/2509.22100", "title": "SHAKE-GNN: 可扩展的基于Kirchhoff森林的层次图神经网络", "title_en": "SHAKE-GNN: Scalable Hierarchical Kirchhoff-Forest Graph Neural Network", "authors": "Zhipu Cui,Johannes Lutzeyer", "background": "图神经网络（GNNs）在各种学习任务中取得了显著的成功，但将GNNs扩展到大型图仍然面临重大挑战，特别是对于图级任务。现有方法难以同时满足高效性和高性能的要求，尤其是在处理大规模图时更为显著，需要新型框架来提升GNNs在图级任务上的可扩展性。", "innovation": "提出了SHAKE-GNN，一种基于Kirchhoff Forest层次结构的新型可扩展图级GNN框架，通过随机生成的多尺度图表示来获得性能与效率之间的灵活权衡。引入了改进的数据驱动策略来选择权衡参数，并分析了SHAKE-GNN的时间复杂度。实验结果表明，SHAKE-GNN在多个大规模图分类基准上表现出竞争力，并提升了可扩展性。", "conclusion": "实验结果显示，SHAKE-GNN在多个大规模图分类基准上实现了与现有方法相当的性能，同时提供了更好的可扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22161", "html_url": "https://arxiv.org/abs/2509.22161", "title": "趋近单纯形顶点：平滑向量量化中代码崩塌的一种简单解决方案", "title_en": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization", "authors": "Takashi Morita", "background": "矢量量化将连续矢量空间离散化为有限数量的代表矢量（码本），在现代机器学习中被广泛采用。然而，非可微量化步骤阻碍了梯度反向传播，这带来了根本性的挑战。平滑矢量量化通过将码本向量的硬分配放松为码本条目的加权组合（代表为简形向量与码本的矩阵乘积）来解决这一问题。有效的平滑需要两个特性：（1）平滑量化器应接近一个onehot向量，以确保紧密近似；（2）所有码本书条目都应被利用，防止代码崩溃。现有的方法通常分别解决这两个期望的目标。", "innovation": "本文提出了一种简单而直观的正则化方法，通过最小化每个简形顶点与其$K$个最近邻平滑量化器之间的距离，同时促进这两个目标。实验结果表明，所提出的方法在代表基准上（包括离散图像自编码和对比性语音表示学习）能够实现更可靠的码本书利用，并且性能优于先前的方法。", "conclusion": "所提出的方法通过最小化每个简形顶点与其$K$个最近邻平滑量化器之间的距离，促进了平滑量化器的同时接近onehot向量和有效地利用所有码本书条目，从而提高了性能和代码利用的可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22067", "html_url": "https://arxiv.org/abs/2509.22067", "title": "叛逆的手术刀：激活导向破坏LLM安全", "title_en": "The Rogue Scalpel: Activation Steering Compromises LLM Safety", "authors": "Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Y. Rogov,Ivan Oseledets,Elena Tutubalina", "background": "激活导向是一种通过在推理过程中将具有语义意义的向量直接添加到模型的隐藏状态中来控制大模型行为的有前景的技术。它通常被视为微调的精确、可解释且潜在更安全的替代方案。然而，本文作者指出，激活导向实际上系统地破坏了模型的对齐防护，使得模型开始满足有害请求。尽管在随机方向上进行激活导向也能增加有害回应的可能性，但来自稀疏自动编码器（SAE）的良性特征进一步提升了该可能性。同时，使用随机挑选的20个向量进行攻击，可以实现一种通用攻击，显著提高未曾见过的请求中的有害回应率。这些结果挑战了通过解释性确保模型安全的范式，表明对模型内部的精确控制并不能保证对模型行为的精确控制。", "innovation": "研究揭示了激活导向技术在提升模型有害响应概率方面的隐性风险，尤其是在使用来自稀疏自动编码器的良性特征时，该技术更为危险。此外，研究还展示了利用随机选取的20个能“解锁”单一提示的向量创建的通用攻击，显著增加未来未知请求中的有害回应率。这些发现挑战了通过提高模型解释性来加强其安全性的传统观念，表明对内部机制的精确操控并不一定会带来预期的效果稳定性。这是通过实验证明了激活导向技术可能带来的不可预测性后果。", "conclusion": "研究结果表明，激活导向不仅不能作为确保大模型安全的有效手段，并且还可能增强模型对有害请求的回应倾向。即使是在非常规方向进行激活导向以及其他在稀疏自动编码器提取的良性特征下，也可以大大提升模型与这些指令的一致性。更为严重的是，通过少量随机选取的“解锁”向量，可以从一项提示扩展到更多的未知请求，使得攻击更具隐蔽性和普遍适用性。因此，研究提出了一种新型的攻击方法，并揭示了安全防护机制在解释性和可控性上的潜在不足，这为大模型的安全研究提供了新的视角。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22102", "html_url": "https://arxiv.org/abs/2509.22102", "title": "基于强化学习的持久算法补救", "title_en": "Reinforcement Learning for Durable Algorithmic Recourse", "authors": "Marina Ceccon,Alessandro Fabris,Goran Radanović,Asia J. Biega,Gian Antonio Susto", "background": "算法补救旨在为个体提供可执行的建议，以增加他们从自动化决策系统（例如贷款审批）中获得有利结果的机会。尽管之前的研究强调模型更新的稳健性，但对补救的时序动态研究相对较少，特别是在竞争性强、资源有限的环境下，建议会影响未来的申请池。因此，研究者需要开发一种能够更好地适应候选人群的变化，同时在长期有效性与可行性之间取得平衡的方法.", "innovation": "本文提出了一种新型的时序感知框架，明确建模推荐下候选人群的适应性变化，并引入了基于强化学习（RL）的持久推荐算法，能够捕捉环境的变化以生成既可行又有效的推荐。推荐策略被设计为具有持久性，支持一段预定义的时间范围内的有效性，使个体有信心在采取行动后重新申请。实验表明，该方法在复杂模拟环境中显著优于现有基线，提供了更好的可行性与长期有效性之间的平衡.", "conclusion": "这些结果强调了将时序和行为动态纳入实用补救系统设计的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22196", "html_url": "https://arxiv.org/abs/2509.22196", "title": "机械独立性：可识别分离表示的一个原理", "title_en": "Mechanistic Independence: A Principle for Identifiable Disentangled Representations", "authors": "Stefan Matthes,Zhiwei Han,Hao Shen", "background": "分离表示试图恢复底层数据变异的潜在因素，但其可识别性尚未完全理解。现有方法通过潜在分布来表征潜在因素，但本文提出了一种一体化框架，通过机械独立性来实现分离，这种方法通过潜在因素如何作用于观测变量来表征潜在因素，而不是通过它们的潜在分布。这种观点在潜在密度变化时不变，即使变化引起因素之间的统计依赖。", "innovation": "本文提议了几种独立性标准，涵盖支持、稀疏性和高阶条件，证明了在这种框架下，即使在非线性和不可逆混合的情况下，这些标准也能使潜在子空间具有可识别性。此外，还建立了这些标准之间的层次关系，并以图论为基础对潜在子空间进行了分类。", "conclusion": "本文的结果澄清了在不依赖统计假设的情况下分离表示可以被识别的条件。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22138", "html_url": "https://arxiv.org/abs/2509.22138", "title": "通过函数最优运输切片Wasserstein Over Wasserstein", "title_en": "Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport", "authors": "Moritz Piening,Robert Beinert", "background": "Wasserstein距离定义了一种在任意度量空间上概率测度之间的度量方法，包括元测度（测度的测度）。由此产生的Wasserstein over Wasserstein (WoW) 距离是一种强大的工具，在比较数据集或图像和形状上的分布时非常有用。现有的sliced WoW加速方法依赖于参数化元测度的存在或高阶矩的存在，这会导致数值不稳定。现有方法的背景和局限性说明了该领域的需求和挑战。", "innovation": "该研究提出了利用一维Wasserstein空间与函数空间L_2([0,1])上的分位数函数之间的等距关系，引入了一种适用于任意Banach空间的一般sliced Wasserstein框架。该框架通过无限维L_2投影和高斯过程参数化，定义了一维元测度之间的sliced距离。通过结合一维构造与欧几里得单位球面上的古典积分，获得了适用于一般元测度的双切片Wasserstein (DSW) 元度量。研究显示，DSW minimization 在离散化元测度情况下等效于WoW minimization，同时避免了不稳定的高阶矩和节省了计算资源。实验验证了DSW的可扩展性作为WoW距离的替代方案。", "conclusion": "该研究提出了一种DSW框架，通过利用Wasserstein与函数空间中的分位数函数之间的等距关系，为一般元测度提供了有效的sliced Wasserstein度量。实验结果验证了DSW在大规模数据集、形状和图像上的适用性和可扩展性，显示了该方法在计算效率和稳定性上的优势。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22184", "html_url": "https://arxiv.org/abs/2509.22184", "title": "通过二次形式学习相伴函数", "title_en": "Learning Equivariant Functions via Quadratic Forms", "authors": "Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P", "background": "本文研究了一种通过从数据中学习与给定群（已知或未知）关联的二次形式$x^T A x$来学习群相伴函数的方法。特定的群（称为正交群）保持特定的二次形式，作者利用这一性质，在假设群是正交的情况下，发掘了潜在的对称群。通过利用对应的唯一对称矩阵及其固有的对角形式，他们将适当的归纳偏置纳入了神经网络架构中，使得模型既简化又高效。此外，该框架扩展到一个更通用的设置，其中函数通过对输入向量元组的对角（或乘积）群作用进行操作，在这种扩展中，相伴函数被分解为仅来自标准化第一向量的张角分量和依赖于其全体格矩阵的尺度不变分量。这种分解捕捉了多输入之间的依赖性同时保持了潜在的群对称性。\n", "innovation": "提出了通过二次形式学习群相伴函数的方法。相较于基线方法，该方法能更有效地学习相应的相伴函数，并在多个任务（如多项式回归、顶夸克标记、惯性矩矩阵预测）中表现出色。通过利用正交群保持特定二次形式的特性，作者在神经网络中引入特定的自归纳偏置，提升了模型的效率和对称性。\n", "conclusion": "该研究成功地开发了一种高效且简化的方法来学习群相伴函数，并展示了该方法在多重任务上的优越性。研究还表明，通过分解成角度分量和尺度不变分量，该方法能更好地捕捉多输入之间的依赖关系并保持潜在的群对称性。\n"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22166", "html_url": "https://arxiv.org/abs/2509.22166", "title": "轻量级后训练N:M激活稀疏性误码缓解策略在大语言模型中的应用", "title_en": "Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs", "authors": "Shirin Alanova,Kristina Kazistova,Ekaterina Galaeva,Alina Kostromina,Vladimir Smirnov,Redko Dmitry,Alexey Dontsov,Maxim Zhelnin,Evgeny Burnaev,Egor Shvetsov", "background": "对高效大型语言模型（LLM）推理的需求加剧了对稀疏化技术的关注。虽然权重半结构化（N:M）剪枝已得到广泛应用，但将其应用于激活剪枝的研究相对较少，尽管这能够提供动态、输入适应性的压缩并且减少I/O开销。本文对后训练N:M激活剪枝方法进行了全面分析，展示了在多个LLM中，激活剪枝在等效稀疏度水平上相比权重剪枝能够更有效地保持生成能力。研究还评估了轻量级和即插即用的误码缓解技术及剪枝标准，建立了具有良好硬件兼容性的基准，而无需大量校准。此外，还探讨了除了NVIDIA标准2:4之外的稀疏模式，发现16:32模式达到了近乎无结构稀疏性的性能。但考虑到灵活性和硬件实施复杂性之间的权衡，选择16:1优化度作为更佳候选。这些发现为激活剪枝提供了有效方法，并激励未来硬件支持更灵活的稀疏模式。", "innovation": "提出了一种轻量级后训练N:M激活剪枝方法，并通过实验证明，在等效稀疏度水平上，与权重剪枝相比，激活剪枝能更有效地保持生成能力。引入了轻量级、即插即用的误码缓解技术，建立了硬件友好型的基准线。此外，不仅限于标准的2:4稀疏模式，还探索了16:32等模式，展示了其接近无结构稀疏性的性能，但更倾向于灵活性和复杂性之间的平衡，提出了8:16作为最优候选模式。", "conclusion": "研究提供了有效的激活剪枝方法，并激励未来硬件支持更灵活的稀疏模式。该研究的代码可在此处获取——[https URL]。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22197", "html_url": "https://arxiv.org/abs/2509.22197", "title": "Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard Overparametrization: The Dynamic Graph Flow Case", "title_en": "Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard Overparametrization: The Dynamic Graph Flow Case", "authors": "Duc Thien Nguyen,Konstantinos Slavakis,Eleftherios Kofidis,Dimitris Pados", "background": "本文介绍了一种基于回归的框架KReTTaH，用于可解释的多维数据插值。该框架将插值问题重新定义为回归问题，使用核函数商核径空间来实现。该方法利用固定张量训练（TT）秩张量来实现参数效率，并通过哈达玛过参数化进一步增强。该研究在估计动态图流的情况下展示了灵活性，能够无缝地将基于图的拓扑先验融入到其逆问题表述中。", "innovation": "使用核函数和张量训练（TT）秩张量来解决回归问题，通过固定张量训练秩张量的黎曼流形实现参数效率。引入哈达玛过参数化促进TT参数空间中的稀疏性。这种方法在实际图数据集上的数值测试中表现出色，优于最新的插值替代方法，包括非参数张量方法和基于神经网络的方法。", "conclusion": "KReTTaH框架展示了在多维数据插值方面的新颖性，特别是在动态图流的背景下，能够有效地融入基于图的拓扑先验，并在实际数据集上优于现有的插值方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22259", "html_url": "https://arxiv.org/abs/2509.22259", "title": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs", "title_en": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs", "authors": "Isaac Reid,Arijit Sehanobish,Cedrik Höfs,Bruno Mlodozeniec,Leonhard Vulpius,Federico Barbero,Adrian Weller,Krzysztof Choromanski,Richard E. Turner,Petar Veličković", "background": "该论文研究了一种新的编码方法Wavelet-Induced Rotary Encodings (WIRE)，它扩展了Rotary Position Encodings (RoPE) 方法，用于处理图形结构数据。RoPE 是一种在大规模语言模型（LLMs）和视觉变换器（ViTs）中广泛使用的算法。因此，背景主要是介绍WIRE如何在继承RoPE的优点同时应用于图数据。", "innovation": "WIRE扩展了RoPE到图结构数据中，证明了WIRE比RoPE更通用，可以在网格图的特殊情况下恢复RoPE。它还具有许多可喜的理论特性，包括节点排序置换下的等变性、兼容线性注意力以及在某些假设下的图形电阻距离的渐近依赖性。", "conclusion": "我们在合成和真实世界任务中对WIRE进行了测试，包括识别单色子图、点云语义分割以及更标准的图形基准测试。发现WIRE在图形结构重要的设置中表现有效。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22174", "html_url": "https://arxiv.org/abs/2509.22174", "title": "效率提升在去中心化优化中的重新想象：基于最小开销的邻居聚合", "title_en": "Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead", "authors": "Durgesh Kalwar,Mayank Baranwal,Harshad Khadilkar", "background": "在当今注重数据隐私的环境中，分布式学习作为一种重要工具逐渐兴起，它不仅强化了隐私保护措施，同时也简化了计算操作。这在需要完全去中心化基础设施的场景下尤为重要，因为在这种场景中，由于缺乏中心化的聚合，本地处理变得至关重要。现有的方法，如Metropolis权重，采用静态权重分配方式，但Dynaweight则根据邻近服务器在本地数据集上的相对损失动态分配权重，以加速去中心化学习过程，同时保持低通信和存储开销，从而促进分布式学习在异构数据场景中的表现提升。我们的实验结果表明，Dynaweight作为一种兼容任何底层服务器优化算法的聚合方案，在各种数据集（MNIST、CIFAR10和CIFAR100）中，通过不同的服务器数量和网络拓扑验证了显著的训练速度提升。", "innovation": "Dynaweight框架是一种创新的多代理网络信息聚合方法，它通过动态根据邻近服务器在本地数据集上的损失分配权重，相比传统的静态权重分配方法，加速了去中心化学习的进程，同时保持较低的通信和存储开销，确保了在数据异构性高的场景下的高效学习性能。", "conclusion": "Dynaweight作为一种聚合方案，与任何底层服务器优化算法兼容，展示了其灵活性和广泛的集成潜力。实验结果表明，Dynaweight在各种数据集上展示了显著的训练速度提升，证明了其在去中心化学习领域的实用性和效能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22214", "html_url": "https://arxiv.org/abs/2509.22214", "title": "随机特征中的数据重建定律（及更广泛的适用性）", "title_en": "A Law of Data Reconstruction for Random Features (and Beyond)", "authors": "Leonardo Iurada,Simone Bombari,Tatiana Tommasi,Marco Mondelli", "background": "大型深度学习模型已知会记住训练集的一部分。在机器学习理论中，这种记忆往往被描述为插值或标签拟合问题。经典的理论结果表明，当模型中的参数数量 $p$ 大于训练样本数量 $n$ 时，可以通过求解模型参数来实现这一点。本文从数据重构的角度研究了这种情况，证明了当 $p$ 大于 $dn$ 时，可以实现这一目标，其中 $d$ 是数据的维度。研究表明，在随机特征模型中，当 $p \text{远大于} dn$ 时，特征空间中训练样本的子空间可以提供识别输入空间中个体样本所需的信息。", "innovation": "本文以数据重构的角度探讨了超参数 $p$ 可以过于训练样本数 $n$ 的理论问题。通过随机特征模型，研究证明当 $p \text{远大于} dn$ 时，能够从特征空间中重建训练样本子空间，进而可以识别输入空间中的个体样本。为了实现这一目标，文章提出了一种基于模型参数的数据集重建方法。该方法有效适用于多种网络架构（随机特征，两层全连接和深层残差网络）。", "conclusion": "研究发现了一个数据重建定律，即当 $p$ 超过阈值 $dn$ 时，可以完全恢复整个训练数据集。这种方法表现出了较高的重建能力，并适用于多种深度学习架构。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22232", "html_url": "https://arxiv.org/abs/2509.22232", "title": "公平意识强化学习（FAReL）：一种透明且平衡的顺序决策框架", "title_en": "Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making", "authors": "Alexandra Cimpean,Nicole Orzan,Catholijn Jonker,Pieter Libin,Ann Nowé", "background": "在真实世界的顺序决策问题中，可以通过公平性感知方法来实现公平性。因此，需要算法能够在性能和所需公平性观念之间进行合适且透明的权衡。由于理想中的性能-公平性权衡在先验上难以明确指定，本文提出了一个框架，可以探索多个权衡方案。强化学习算法关于可获取的性能-公平性权衡的见解可以指导利益相关者选择最合适的策略。为了捕捉公平性，本文提出了扩展的马尔可夫决策过程（fMDP）来明确编码个体和群体。基于此fMDP，本文正式化了顺序决策问题中的公平性概念，并构建了一个公平性框架来计算时间上的公平度量。", "innovation": "提出了一种公平性感知的强化学习框架（FAReL），用于探索性能-公平性权衡方案。该框架通过扩展马尔可夫决策过程（fMDP）来明确编码个体和群体，并正式化了顺序决策问题中的公平性概念，从而计算出时间上的公平度量。该框架在两个不同的公平性要求场景中进行了评估，这两种场景分别是：在招聘中需要形成强团队的同时平等对待申请者，以及在欺诈检测中需要公平地将欺诈交易分配给客户。结果显示，该框架能够学习出在多种场景中都较为公平的策略，仅有一定的性能损失。此外，研究表明群体公平性观念和个体公平性观念并不一定相互蕴含，这突显了该框架在同时需要这两种公平类型的情况下的优势。最后，还提供了在不同问题设置下应用此框架的指南", "conclusion": "本文提出了一种扩大化的马尔可夫决策过程（fMDP）和一个公平性框架，能够用于探索序列决策问题中的性能和公平性之间的权衡。该框架在两个具有不同公平性要求的场景中得到了评估，并展示了它的优势。研究表明，虽然存在一定的性能损失，但这种框架可以学习出在多个场景中都更为公平的策略，并且当同时追求群体和个体公平时尤为有效。最后，提供了一些建议，以帮助在不同问题环境中应用此框架。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22246", "html_url": "https://arxiv.org/abs/2509.22246", "title": "ASSESS：用于语句相似度的语义与结构评估框架", "title_en": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity", "authors": "Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo", "background": "语句自动形式化，即将自然语言中的语句自动翻译为形式语言，这项技术已有显著进展，但自动评估标准的发展相对滞后。现有的形式化语句相似度评估标准往往无法平衡语义和结构信息。基于字符串的方法捕捉了句法结构但忽略了语义意义，而基于证明的方法验证了语义等价性但忽略了结构细微差别，并且在证明失败时不能提供级别化的相似度分数。", "innovation": "提出了一种名为ASSESS（用于语句相似度的语义与结构评估框架）的方法，该方法综合了语义与结构信息来提供连续的相似性分数。ASSESS框架首先将形式化语句转换为运算符树以捕捉句法结构，然后使用新颖的TransTED（转换树编辑距离）相似度度量来计算相似性分数，该度量通过转换增强了传统的树编辑距离，并融入了语义意识。开发了新的基准EPLA（评估可证明性与相似性），包含524对由miniF2F和ProofNet抽取，并标注了语义可证明性和结构相似性的专家标注形式化语句对。实验表明，TransTED相似度优于现有方法，达到了最先进的准确率和最高的Kappa系数。", "conclusion": "该基准和实现代码将很快公开。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22263", "html_url": "https://arxiv.org/abs/2509.22263", "title": "擦除还是隐藏？抑制虚假的未学习神经元以实现鲁棒的未学习", "title_en": "Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning", "authors": "Nakyeong Yang,Dong-Kyum Kim,Jea Kwon,Minsung Kim,Kyomin Jung,Meeyoung Cha", "background": "针对Web规模数据训练的大语言模型可能会记忆私人或敏感信息，从而带来重大的隐私风险。尽管一些消除方法能够缓解这些风险，但在后续重新训练过程中仍容易重新学习，导致被遗忘的知识再次浮现。已有研究指出，当前广泛使用的未学习方法容易产生虚假的未学习神经元，这些虚假神经元会放大负面影响，从而将其隐藏起来。", "innovation": "本文提出了一种名为Ssiuu的新类未学习方法，通过属性引导正则化防止虚假的负面影响，并能够真正擦除目标知识。与强基线方法相比，该方法在两种实际重新训练场景中均表现出更优性能，包括恶意私有数据注入和利用指令遵循基准的良性攻击。", "conclusion": "本研究强调了需要具备强大且忠实的未学习方法，以确保语言模型的安全部署。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22294", "html_url": "https://arxiv.org/abs/2509.22294", "title": "A Multi-Level Framework for Multi-Objective Hypergraph Partitioning: Combining Minimum Spanning Tree and Proximal Gradient", "title_en": "A Multi-Level Framework for Multi-Objective Hypergraph Partitioning: Combining Minimum Spanning Tree and Proximal Gradient", "authors": "Yingying Li,Mingxuan Xie,Hailong You,Yongqiang Yao,Hongwei Liu", "background": "本文提出了一种基于新型多目标非凸约束松弛模型的高效超图分区框架。研究背景在于现有分区算法在面对大规模数据集时效率不高，同时分区质量也有待提升。", "innovation": "创新点在于提出了一个多层次的多目标超图分区框架，采用改进的加速近端梯度算法生成多样化的k维顶点特征以避免局部最优，提高分区质量；设计了基于最小生成树（MST）的不同数据规模策略，以及引入了改进的贪婪迁移、交换和递归MST聚类等细化策略，进一步优化分区结果。", "conclusion": "实验结果表明，所提出的算法在平均情况下比KaHyPar在2、3和4方式分区中平均减少切割大小约2%-5%，特定实例上最多减少35%，特别是在加权顶点集方面，算法优于包括KaHyPar、hMetis、Mt-KaHyPar和K-SpecPart在内的最先进的分区器。此外，提出的细化策略减少了hMetis分区最多16%。基于虚拟实例方法和参数敏感性分析，证明了算法的竞争性和性能权衡。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22267", "html_url": "https://arxiv.org/abs/2509.22267", "title": "向更现实的轴承故障诊断机器学习模型评估迈进", "title_en": "Towards a more realistic evaluation of machine learning models for bearing fault diagnosis", "authors": "João Paulo Vieira,Victor Afonso Bauler,Rodrigo Kobashikawa Rosa,Danilo Silva", "background": "可靠的轴承故障检测对于维持旋转机械的安全性和操作效率至关重要。尽管近年来机器学习，尤其是深度学习，在受控环境中显示出很强的性能，但许多研究未能泛化到实际应用中，主要是由于方法论上的缺陷，尤其是数据泄漏问题。本文探讨了振动基轴承故障诊断中数据泄漏的问题及其对模型评估的影响。研究表明，常见的数据分区策略，如段内和条件内的划分，引入了虚假的相关性从而虚增了性能指标。", "innovation": "本文提出了一种严格、无泄漏的评估方法，集中在轴承级别的数据分区，确保训练和测试使用的物理组件不重叠。此外，本文还将分类任务重新表述为多标签问题，允许检测同时出现的故障类型，并使用不依赖于患病率的指标，如宏AUC-ROC。本文还考察了数据集多样性对泛化效果的影响，表明不同训练轴承的数量是实现稳健性能的关键因素。", "conclusion": "本文研究强调了泄漏意识评估协议的重要性，并提供了数据集分区、模型选择和验证的实际指南，促进了更可信的机器学习系统的发展，应用于工业故障诊断。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22279", "html_url": "https://arxiv.org/abs/2509.22279", "title": "解锁Mixture-of-Experts在任务感知时序分析中的潜力", "title_en": "Unlocking the Power of Mixture-of-Experts for Task-Aware Time Series Analytics", "authors": "Xingjian Wu,Zhengyu Li,Hanyin Cheng,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Bin Yang", "background": "时序分析被广泛应用于天气预报、金融欺诈检测、物联网系统中数据缺失填补以及动作识别等实际应用场景。Mixture-of-Experts (MoE) 是一种强大的架构，在自然语言处理（NLP）领域已经表现出有效性，但在时序分析任务中由于其任务无关的路由机制和建模通道相关性能力的不足，仍然面临着挑战。", "innovation": "本文提出了一种新颖的一般 MoE 时序框架 —— PatchMoE，它支持区分任务中复杂“知识”的利用，从而实现任务感知。该框架通过提出一种循环噪声门控机制，利用不同任务中的层次信息进行路由，解决任务间差异性问题。该路由策略在同一时间序列代数和通道维度上操作，并通过精心设计的时间性和通道负载平衡损失来建模复杂的时序和通道相关性。", "conclusion": "在五个下游任务上的综合实验结果表明，PatchMoE 在性能上达到了现有最先进的水平。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22272", "html_url": "https://arxiv.org/abs/2509.22272", "title": "大型语言模型中细粒度不确定性分解：一种谱方法", "title_en": "Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach", "authors": "Nassim Walha,Sebastian G. Gruber,Thomas Decker,Yinchong Yang,Alireza Javanmardi,Eyke Hüllermeier,Florian Buettner", "background": "随着大型语言模型（LLMs）在各种应用中的集成越来越多，获取其预测不确定性可靠度量的重要性变得至关重要。明确区分Aleatoric不确定性（源于输入数据中的固有模糊性）和Epistemic不确定性（仅来自模型限制），对有效地应对每种不确定性来源极为重要。本文着眼于这个背景，提出了Spectral Uncertainty的方法，用于量化和分解LLMs中的不确定性。Spectral Uncertainty通过利用量子信息理论中的von Neumann熵，提供了一个严格理论基础，将总体不确定性分解为独立的Aleatoric和Epistemic分量。", "innovation": "本文的创新在于提出了一种名为Spectral Uncertainty的新方法，它通过利用von Neumann熵，为LLMs提供了分离总体不确定性到独立的Aleatoric和Epistemic分量的严格理论基础。Spectral Uncertainty的特点在于，它细粒度地代表了语义相似性，从而能够对模型响应中的各种语义解释进行精细区分。此外，实验结果表明，Spectral Uncertainty在估计Aleatoric和总体不确定性方面优于最先进的方法，不论是在多种模型还是基准数据集上均表现优异。", "conclusion": "Spectral Uncertainty通过利用von Neumann熵提供了一种新的方法，可以精确地对LLMs中的不确定性进行细粒度分解。相比现有方法，其优势在于能够准确估计Aleatoric和总不确定性，且在多个基准数据集和模型上都表现优于现有技术。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22282", "html_url": "https://arxiv.org/abs/2509.22282", "title": "无线语义通信中的条件去噪扩散自编码器", "title_en": "Conditional Denoising Diffusion Autoencoders for Wireless Semantic Communications", "authors": "Mehdi Letafati,Samad Ali,Matti Latva-aho", "background": "语义通信（SemCom）系统旨在学习从低维度语义到高维度真实值的映射。现有框架倾向于强调通道自适应神经编码-解码方案，但没有充分探索信号分布。现有的方法大多依赖于自编码器架构，编码器和匹配的解码器紧密耦合，导致实际应用中的可扩展性问题。", "innovation": "提出了条件去噪扩散自编码器模型用于无捷新型语义通信。目标是从语义空间学习“语义到干净”的映射到真实值概率分布。语义发送端的神经编码器提取高层次语义，语义接收端的条件扩散模型利用源分布进行信号空间去噪，接收的语义潜在变量作为条件输入，以“引导”解码过程向发送端希望的语义靠拢。研究证明，提出的方法能一致地估计真实数据。还通过CIFAR-10和MNIST数据集的广泛仿真提供了设计见解，展示了与现有自编码器和变分自编码器相比的效果。进一步扩展了多用户语义通信的仿真，分析了真实设置下的关键因素影响。", "conclusion": "通过证明所提出的解码模型一致地估计真实数据，并通过仿真与传统自编码器和VAE相比，展示了更好的性能。结论为，条件去噪扩散自编码器模型能有效解决语义通信中的问题，提升实际应用中的可扩展性和性能，并指出在多用户语义通信情境下的关键因素影响。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22299", "html_url": "https://arxiv.org/abs/2509.22299", "title": "HEAPr：输出空间基于海森矩阵的高效原子专家精简算法", "title_en": "HEAPr: Hessian-based Efficient Atomic Expert Pruning in Output Space", "authors": "Ke Li,Zheng Yang,Zhongbin Zhou,Feng Xue,Zhonglin Jiang,Wenxiao Wang", "background": "Mixture-of-Experts (MoE) 架构在大规模语言模型（LLMs）中表现出色，与密集的LLMs相比，其推断成本较低，但具有大量的参数，导致内存需求过高，限制了实际部署。现有的精简方法主要集中在专家级别的精简上，但这种粗粒度往往会导致显著的精度下降。", "innovation": "HEAPr引入了一种新颖的精简算法，通过将专家分解为更小的不可分割的原子专家，实现了更精准和灵活的原子专家精简。HEAPr利用类似于最优大脑外科手术（OBS）理论的原则来衡量每个原子专家的重要性，并通过原子专家的固有特性将海森矩阵信息从专家参数转换为原子专家参数，进一步简化为原子专家输出的海森矩阵信息，空间复杂度从$O(d^4)$降低到$O(d^2)$。HEAPr仅需要在小型校准集上进行两次前向传递和一次后向传递即可计算出原子专家的重要性。", "conclusion": "在DeepSeek MoE和Qwen MoE家族等MoE模型上进行的广泛实验表明，HEAPr在不同的压缩比和基准测试中均优于现有的专家级别精简方法。具体来说，HEAPr在大多数模型中实现了接近无损的压缩比（20% ~ 25%），同时减少了近20%的FLOPs。该代码可以在指定的链接中找到。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22302", "html_url": "https://arxiv.org/abs/2509.22302", "title": "SoDaDE: 使用小型变换器模型的溶剂数据驱动嵌入", "title_en": "SoDaDE: Solvent Data-Driven Embeddings with Small Transformer Models", "authors": "Gabriel Kitso Gibberd,Jose Pablo Folch,Antonio Del Rio Chanona", "background": "计算表示已成为解锁用于化学的机器学习算法增长的关键。机器学习表明，可以从数据中学习到有意义的表示，而不是手动设计的。然而，化学数据集有限，因此从数据中学习到的表示通常是通用的，并且这些表示是通过训练广泛的数据集而实现的，这些数据集包含了关于多种分子类型的浅层信息。例如，通用指纹缺乏特定于溶剂的物理上下文。但由于有害溶剂是化学工业中一个主要的气候相关问题，绿色溶剂替代物的需求正在上升，因此需要新的方法来帮助这项研究。", "innovation": "该研究提出了一个新的溶剂表示方案——Solvent Data Driven Embeddings (SoDaDE)，该方案利用小型变压器模型和溶剂性质数据集创建溶剂指纹。SoDaDE能够使用较小的数据集生成有效的数据驱动指纹，实验证明其效果优于之前的表示方法，并为其他应用提供了可探索的工作流程设置。", "conclusion": "通过数据分析，本文证明了可以通过小型数据集生成数据驱动的溶剂指纹，并建立了一个可用于其他应用的工作流程。这对绿色溶剂的研究尤其有用，因为它可以提供有关溶剂的具体信息，而不会受到传统方法中化学数据集有限性的限制。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22295", "html_url": "https://arxiv.org/abs/2509.22295", "title": "Aurora: 向全能生成多模态时间序列预测迈进", "title_en": "Aurora: Towards Universal Generative Multimodal Time Series Forecasting", "authors": "Xingjian Wu,Jianxin Jin,Wanghui Qiu,Peng Chen,Yang Shu,Bin Yang,Chenjuan Guo", "background": "时间序列预测中的跨域泛化非常重要，因为相同的历史信息可能会因具体领域特征的不同而导致不同的未来趋势。现有工作主要集中在构建单一模态的时间序列基础模型和端到端的多模态监督模型上。前者缺乏对文本等模态中显式领域的知识利用，从而限制了性能；后者专为端到端场景设计，不适用于零样本推理的跨域场景。", "innovation": "本研究提出了一种名为Aurora的多模态时间序列基础模型，支持多模态输入和零样本推理。Aurora通过预训练在跨领域多模态时间序列语料库上，能够适应性地提取并聚焦于相应的文本或图像模态中包含的关键领域知识，从而具备强大的跨域泛化能力。Aurora通过分词、编码和精简，提取多模态领域知识作为指导，并利用模态指导多头自注意机制将这些信息注入到时间表示的建模中。在解码阶段，多模态表示用于生成未来的条件和原型，贡献了一种新颖的概率生成预测的原型指导流匹配方法。", "conclusion": "在广泛认可的基准测试（包括TimeMMD、TSFM-Bench和ProbTS）上的全面实验表明，Aurora在单模态和多模态场景中都表现出一致的先进性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22352", "html_url": "https://arxiv.org/abs/2509.22352", "title": "SurvDiff: 用于生存分析中生成合成数据的扩散模型", "title_en": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis", "authors": "Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel", "background": "生存分析是临床研究的基石，通过建模如转移、疾病复发或患者死亡等时间到事件的结果。与标准的表型数据不同，生存数据常常因为流失或其他原因包含不完整事件信息。这为生成合成数据带来独特挑战，因为临床研究中需要忠实再现事件时间分布和截尾机制。因此，需要一种能够有效捕捉这些特性的生成模型。", "innovation": "本文提出了SurvDiff，一种专门用于生成生存分析中合成数据的端到端扩散模型。SurvDiff通过联合生成混合类型协变量、事件时间和右侧截尾现象，并在生存特化的损失函数引导下实现数据生成机制的捕捉。损失函数编码了事件时间结构，并直接优化了下游生存任务，确保SurvDiff能够真实再现事件时间分布并保存截尾机制。实验结果显示，SurvDiff在多个数据集上均显著优于现有的生成基线，在分布一致性和下游评估指标上表现出色。", "conclusion": "据我们所知，SurvDiff是首个专门设计用于生成合成生存数据的扩散模型。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22335", "html_url": "https://arxiv.org/abs/2509.22335", "title": "深度连续学习中曲率谱塌缩驱动塑性丧失", "title_en": "Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning", "authors": "Naicheng He,Kaicheng Guo,Arjun Prakash,Saket Tiwari,Ruo Yu Tao,Tyrone Serapio,Amy Greenwald,George Konidaris", "background": "我们探讨了为什么深度神经网络在深度连续学习中会遭受‘塑性的丧失’问题，在学习新任务时不重新初始化参数无法有效学习新任务。研究发现这种失败的前提是在学习新任务初始化时，Hessian谱塌缩，即有意义的曲率方向消失，使得梯度下降变得无效。", "innovation": "我们引入了$\tau$-可训练性来描述成功训练的必要条件，并展示当下保持塑性的算法可以统一在这个框架中。直接对抗谱塌缩，我们讨论了Hessian的Kronecker分解近似，提出了两种正则化增强：保持高有效的特征秩和应用$L2$惩罚。", "conclusion": "实验表明，结合这两种正则化器有效保持了塑性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22310", "html_url": "https://arxiv.org/abs/2509.22310", "title": "基于共享网络的自适应策略主干", "title_en": "Adaptive Policy Backbone via Shared Network", "authors": "Bumgeun Park,Donghwan Lee", "background": "强化学习（RL）在多个领域取得了显著成果，但学习最优策略通常需要大量的交互数据，这限制了其实用部署。一种常见的解决方案是利用先验知识，如预先收集的数据集或参考策略，但这些先验知识在训练和部署任务不匹配时效果会下降。尽管已有研究试图解决这一问题，大多数工作仅针对内部分布（in-distribution）情景。为了应对这一挑战，本文提出了自适应策略主干（APB），这是一种元迁移强化学习方法，它在共享主干前后插入了轻量级的线性层，从而实现参数高效的微调（PEFT），同时在适应过程中保留先验知识。研究表明，APB 在样本效率上优于标准的强化学习，并且能够适应现有元强化学习基线通常失败的外部分布（out-of-distribution，OOD）任务。", "innovation": "提出了自适应策略主干（APB），这是一种增强学习方法，它利用共享网络结构，在其前后加入轻量级线性层，实现了参数高效的微调，同时在迁移过程中保留先验知识。这种方法解决了传统方法在任务不匹配下的性能下降问题，并且在外部分布任务上超越了现有的基线方法。", "conclusion": "自适应策略主干（APB）在样本效率方面优于标准的强化学习方法，并且能够有效应对现有的元强化学习基线在外部分布任务中的失效问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22321", "html_url": "https://arxiv.org/abs/2509.22321", "title": "通过在线凸优化实现分布式的联想记忆", "title_en": "Distributed Associative Memory via Online Convex Optimization", "authors": "Bowen Wang,Matteo Zecchin,Osvaldo Simeone", "background": "联想记忆（AM）能够实现提示-响应再现，近年来发现联想记忆可能在现代神经架构，如Transformer模型中起关键作用。本文研究了在分布式的环境中，各个代理通过路由树进行通信以维护局部的AM，从而不仅记录自身信息，还能选择性地保存其他代理的信息。在此背景下，现有技术和方法还存在优化空间和性能提升的需求。", "innovation": "本文提出了一个通过在线凸优化方法优化分布式环境中各个代理的局部联想记忆的协议。利用这个协议，代理通过路由树进行通信以优化其AM。理论分析证明该方法有子线性遗憾保证，实验结果显示该协议在一致性能上优于现有的在线优化基准方法。", "conclusion": "通过路由树进行通信的分布式在线梯度下降方法可以有效优化各个代理的本地联想记忆系统，并表现出优于现有方法的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22369", "html_url": "https://arxiv.org/abs/2509.22369", "title": "面向检测钓鱼网页的知觉导向多模态联邦学习系统", "title_en": "Role-Aware Multi-modal federated learning system for detecting phishing webpages", "authors": "Bo Wang,Imran Khan,Martin White,Natalia Beloff", "background": "现有的钓鱼网站检测方法通常绑定客户端到单一的模态类型，这样的方法不够灵活且在隐私保护方面存在局限。本文提出了一种联邦多模态钓鱼网站检测器，支持URL、HTML和IMAGE输入，客户端可以在推理时调用任何已训练的模态头。", "innovation": "该方法基于FedProx提出了感知导向的桶聚合机制，结合Mixture-of-Experts和FedMM的设计思想，去除了可学习的路由机制，使用硬门控（通过样本模态选择IMAGE/HTML/URL专家），实现独立聚合特定模态的参数以隔离跨嵌入冲突，稳定收敛。", "conclusion": "在TR-OP数据集上，Fusion头部在两种数据类型上达到了97.5%的准确率和2.4%的FPR；在图像子集（消融实验）中，准确率为95.5%，FPR为5.9%。对于文本，使用了GraphCodeBERT处理URL，早期三向嵌入处理原始、嘈杂的HTML。在WebPhish（HTML）上，准确率为96.5%，FPR为1.8%；在TR-OP（原始HTML）上，准确率为95.1%，FPR为4.6%。结果表明，感知导向的桶聚合机制配合硬门控专家能够稳定地在严格隐私下进行联邦训练，同时提高了多模态钓鱼检测的易用性和灵活性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22358", "html_url": "https://arxiv.org/abs/2509.22358", "title": "随机激活函数", "title_en": "Stochastic activations", "authors": "Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou", "background": "在大型语言模型中，常用的激活函数如RELU在负输入处具有恒定的形状，这会阻碍梯度流的传递，导致优化问题。为了应对这一问题，研究人员引入了随机激活函数，该函数在一个前馈层中随机选择几种非线性函数，例如在本研究中选择SILU或RELU，通过伯努利抽样方式决定。", "innovation": "该研究提出了一种新颖的策略，在预训练阶段使用随机激活函数，而在微调和推理阶段则使用RELU。这种方法利用了随机激活函数在负输入不中断梯度传递的优点，同时在推理时使用RELU以提供稀疏的潜在向量，从而减少推理时的FLOPs。此外，该研究还探讨了随机激活函数在生成文本方面的应用，并表明其相较于现有技术提供了提高文本生成多样性的可控方式。", "conclusion": "这种随机激活函数的战略在预训练和微调中具有显著的优势，特别是在提高推理速度方面表现优异。在生成任务中，随机激活函数的表现尽管略逊于最佳的确定性非线性函数（如SILU结合温度缩放），但仍提供了一种可控增加生成文本多样性的替代方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22353", "html_url": "https://arxiv.org/abs/2509.22353", "title": "情境和多样性至关重要：世界模型中基于情境的学习的产生", "title_en": "Context and Diversity Matter: The Emergence of In-Context Learning in World Models", "authors": "Fan Wang,Zhiyuan Chen,Yuxuan Zhong,Sunjian Zheng,Pengtao Shao,Bo Yu,Shaoshan Liu,Jianan Wang,Ning Ding,Yang Cao,Yu Kang", "background": "能够预测环境动态是生物学和整体赋形AI适应环境的基础。然而，现有的方法依赖于静态的世界模型，在面对新的或罕见的配置时表现不佳。本文的研究背景在于探讨如何改进基于情境环境学习（ICEL），从零样本性能转向世界模型的增长和渐进极限。", "innovation": "本研究的主要创新点在于三个方面：(1) 正式化基于情境环境模型的学习，并识别出环境识别和环境学习两种核心机制；(2) 为这两种机制推导出误差上界，揭示机制是如何产生的；(3) 实证确认世界模型中确实存在不同的ICL机制，并进一步探讨数据分布和模型架构如何影响ICL，且这些影响与理论预期一致。这些发现表明自适应世界模型的潜力，并强调了ICEL出现的关键因素，尤其是需要长时情境和多样环境的重要性。", "conclusion": "研究成果展示了自适应世界模型的潜力，并突出了ICEL出现的关键要素，特别是长时情境和多样环境的必要性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22319", "html_url": "https://arxiv.org/abs/2509.22319", "title": "渐进式权重加载：资源受限环境中的初始推断加速及逐步提升性能", "title_en": "Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments", "authors": "Hyunwoo Kim,Junha Lee,Mincheol Choi,Jeonghwan Lee,Jaeshin Cho", "background": "深度学习模型变得越来越大和复杂，导致内存消耗和计算需求增加，从而导致模型加载时间和初始推理延迟增加，在需要频繁加载和卸载模型的移动和低延迟环境中造成重大挑战，直接影响用户体验。虽然知识蒸馏（KD）可以通过将大型教师模型压缩为较小的学生模型来提供解决方案，但它往往以牺牲性能为代价。因此，在保持初始推理速度的同时提高模型性能的需求变得越来越大。为了应对这种权衡，我们提出了渐进式权重加载（PWL），这是一种新型技术，可以从一个轻量级的学生模型开始部署，然后逐步用预训练教师模型的层替换其层。为了支持无缝层替换，我们提出了一种不仅对齐学生和教师层之间的中间特征表示，还能提高整个学生模型输出性能的训练方法。我们在VGG、ResNet和ViT架构上的实验表明，使用PWL训练的模型保持了竞争力的知识蒸馏性能，并在教师层加载时渐进地提高了准确性，最终达到完整教师模型的准确性，而不会牺牲初始推理速度。这使得PWL特别适合于需要快速响应和高性能的动态资源受限部署环境，", "innovation": "提出了渐进式权重加载（PWL），这是一种新型技术，可以从一个轻量级的学生模型开始部署，然后逐步用预训练教师模型的层替换其层。这种方法不仅对齐了学生和教师层之间的中间特征表示，还能提高整个学生模型的输出性能。通过这种方法，PWL能够在保持初始推理速度的同时，逐步提高模型的性能，这让其特别适合资源受限的部署环境。", "conclusion": "PWL能够在保持初始推理速度同时使模型逐步提高性能，最终达到完整教师模型的准确性，特别适合动态、资源受限的部署环境，不仅提升了用户体验，还提高了资源利用效率。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22363", "html_url": "https://arxiv.org/abs/2509.22363", "title": "探究大型音频语言模型的忠实性", "title_en": "Investigating Faithfulness in Large Audio Language Models", "authors": "Lovenya Jain,Pooneh Mousavi,Mirco Ravanelli,Cem Subakan", "background": "前人的研究表明，基于文本的大语言模型（LLMs）的思维链（CoT）往往缺乏忠实性。然而，对于大型音频语言模型（LALMs），尤其是在安全敏感的应用中，其决策过程的忠实性变得更加重要。LALMs的推理过程更为复杂，因为模型首先需要从音频中提取相关线索，然后再进行推理。", "innovation": "本文通过在SAKURA和MMAR两个具有挑战性的推理数据集上应用针对性的干预措施（包括改述，插入填充词，提前回答，引入错误等），来调查几种LALMs生成的思维链的忠实性。这种研究填补了对于大型音频语言模型忠实性研究的空白，特别是在安全敏感的任务中具有重要意义，也为理解LALMs的推理过程提供了新的视角。", "conclusion": "我们的实验结果表明，LALMs通常会产生与基础决策过程相吻合的思维链。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22362", "html_url": "https://arxiv.org/abs/2509.22362", "title": "神经特征几何演变为离散拉克流", "title_en": "Neural Feature Geometry Evolves as Discrete Ricci Flow", "authors": "Moritz Hehl,Max von Renesse,Melanie Weber", "background": "深层神经网络通过复杂的几何变换学习特征表示。尽管这些模型在各领域中取得了成功，但我们对神经网络所学特征表示的理解仍然不完整。本文通过离散几何学的视角研究神经特征几何的演进。由于输入数据流形通常不可观察，我们使用几何图来编码局部相似结构进行近似。研究表明，在训练过程中，非线性激活函数在塑造特征几何方面发挥着关键作用。此外，我们发现这些几何变换类似于这些图上的离散拉克流，暗示神经特征几何的演变与拉克流类似。", "innovation": "我们提供了关于在训练过程中这些图的变化的理论结果，证明了非线性激活在特征几何形成中的作用。研究发现，这些几何变换类似于这些图上的离散拉克流，这与特征几何的演变类似。基于这些洞察，我们提出了一种新的局部评估几何变换的框架，该框架通过与离散拉克流动力学进行比较来进行。我们的研究结果提出了实际的设计原则，包括基于几何的中止准则和网络深度选择标准。", "conclusion": "我们观察到类别的可分离性随与相关图表示中的社区结构的出现而出现，这与离散拉克流动力学有关。我们的研究结果提出了一种新颖的局部评估几何变换的框架，通过与离散拉克流动力学进行比较。这些建议对于神经网络的设计提供了实践指南，包括基于几何的中止准则和网络深度选择标准。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22384", "html_url": "https://arxiv.org/abs/2509.22384", "title": "有时更简洁更好：缓解基于规则表示的复杂性以实现可解释分类", "title_en": "(Sometimes) Less is More: Mitigating the Complexity of Rule-based Representation for Interpretable Classification", "authors": "Luca Bergamin,Roberto Confalonieri,Fabio Aiolli", "background": "深度神经网络在人工智能的实际应用中广泛使用，但由于其内部结构和复杂性，这些模型通常难以解释。在某些应用场景中，模型的透明度和可解释性是关键需求，即使性能足够高，也需要易于理解的解释性模型。本研究探讨了一种利用可微近似$L_0$正则化构建逻辑神经网络——多层逻辑感知器（MLLP），来研究其在保持性能的同时降低基于概念规则集（CRS）的复杂性。研究还将这种方法与随机权重二元化等其他启发式方法进行了对比。", "innovation": "提出了一个通过采用可微近似$L_0$正则化的多层逻辑感知器（MLLP）来研究在降低基于概念规则集（CRS）的复杂性的同时保持性能的方法，并且与随机权重二元化等替代启发式方法进行对比，以确定基于损失函数进行稀疏化是否能带来更好的结果。", "conclusion": "讨论了基于概念规则集（CRS）的复杂性和其性能之间的权衡问题。结果表明，使用基于损失函数的稀疏化技术可能比随机方法能获得更好的结果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22395", "html_url": "https://arxiv.org/abs/2509.22395", "title": "提高短期死亡率系列准确性的方法：在混合系统中探索多步预测方法", "title_en": "Improving accuracy in short mortality rate series: Exploring Multi-step Forecasting Approaches in Hybrid Systems", "authors": "Filipe C. L. Duarte,Paulo S. G. de Mattos Neto,Paulo R. A. Firmino", "background": "随着利率下降和经济稳定，准确的死亡率预测变得越来越重要，尤其是在保险和年金市场。多步预测对于公共卫生、人口规划和保险风险评估至关重要，但当数据有限时，这些预测会面临挑战。统计和机器学习（ML）模型相结合的混合系统可以解决线性和非线性模式的问题。", "innovation": "研究评估了不同的多步预测方法（递归、直接、多输入多输出）以及ML模型对混合系统的准确性影响。结果显示，选择合适的多步方法和ML模型对于提高性能至关重要，使用递归方法的ARIMA-LSTM混合模型在大多数情况下表现最佳。", "conclusion": "本研究强调了在混合系统中选择合适的多步预测方法和ML模型的重要性，并指出ARIMA-LSTM混合模型在多步预测中表现出色。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22381", "html_url": "https://arxiv.org/abs/2509.22381", "title": "提升信用风险预测：集成基线模型、LASSO和ECOC的元学习框架", "title_en": "Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy", "authors": "Haibo Wang,Lutfu S. Sua,Jun Huang,Figen Balo,Burak Dolar", "background": "有效的信用风险管理是金融决策的基础，需要强大的模型来预测违约概率和金融实体分类。传统的机器学习方法在处理高维数据、缺乏可解释性、稀有事件检测和风险评估中的多类别不平衡问题时面临巨大挑战。企业在风险评估中面临这些挑战，因此需要更准确和可靠的计算模型来支持战略性的金融决策，特别是在处理风险模型中的这三个根本性问题时：高维数据、稀有事件和多类别不平衡问题。", "innovation": "本文提出了一种综合的元学习框架，该框架整合了多种互补模型：包括监督学习算法（如XGBoost、随机森林、支持向量机和决策树）、无监督方法（如K-最近邻）、深度学习架构（如多层感知机）以及LASSO正则化进行特征选择和降维；同时，使用错误纠正输出编码作为元分类器来解决多类不平衡问题。此外，我们还利用排列特征重要性分析增强了模型的透明度。此框架旨在优化预测性能，并提供更全面的企业信用风险评估方法，从而解决信用风险建模中的三个关键问题：高维数据、稀有事件和多类不平衡问题。", "conclusion": "本文开发的元学习框架在信用评级迁移(升级和降级)和违约概率估计方面的准确性得到了显著提高。通过实验验证，该框架有助于发展更准确和可靠的计算模型，为战略金融决策提供支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22402", "html_url": "https://arxiv.org/abs/2509.22402", "title": "ReLAM: 学习预测模型用于视觉化机器人操作的奖励", "title_en": "ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation", "authors": "Nan Tang,Jing-Cheng Pang,Guanlin Li,Chao Qian,Yang Yu", "background": "在视觉强化学习（RL）中，机器人操作的奖励设计仍然是一个重要的瓶颈。在模拟环境中，奖励通常基于到目标位置的距离来进行设计，但在现实世界中，由于感觉和感知的限制，精确的位置信息往往不可用。因此，有人提出了一种通过从图像中提取关键点隐式推断空间距离的方法，并引入了一种名为ReLAM的新型框架，它可以自动从无动作的视频演示中生成密集的结构化奖励。", "innovation": "ReLAM通过对关键点进行预测，自动从无动作视频演示中生成密集的结构化奖励，无需显式定义奖励函数。它在学习过程中首先通过学习一个预测模型来充当计划器，并为最终目标提出中间的关键点基于子目标，直接与任务的几何目标对齐。基于预测的子目标，提供连续的奖励信号来训练层级强化学习框架下的低级目标条件策略。", "conclusion": "通过对复杂的长期目标操作任务进行大量实验，结果表明ReLAM显著加快了学习过程，并且与最先进的方法相比，性能更好。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22387", "html_url": "https://arxiv.org/abs/2509.22387", "title": "SpinGPT：正确玩牌的大型语言模型方法", "title_en": "SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly", "authors": "Narada Maugin,Tristan Cazenave", "background": "Counterfactual Regret Minimization（CFR）算法及其变种使得开发出能够战胜顶尖人类玩家的单挑（1v1）现金游戏机器人以及在六人制形式中与之竞争的机器人成为可能。然而，随着参与人数的增加，CFR的计算复杂度呈指数增长。在三人或更多参与者的游戏中，遵循纳什均衡已经不能保证不输。这些局限性限制了CFR在最受欢迎的 formats, tournament 上的应用。", "innovation": "提出了一种专为三人在线扑克格式 Spin & Go 而设计的大型语言模型 SpinGPT。SpinGPT 经过两阶段训练：1）在320K高水平专家决策上进行监督微调；2）在270K解算器生成的手上进行强化学习。实验结果显示，SpinGPT 在78%的决策中与解算器的行动一致（容忍准确率）。结合简单的深栈启发式方法，面对Slumbot时，SpinGPT 在30,000手头对阵局中达到13.4 ± 12.9 BB/100（95%置信区间）。这些结果表明，大型语言模型可能成为处理多玩家不确定信息游戏如扑克的一种新方法。", "conclusion": "SpinGPT 为多人不完美信息游戏中大语言模型的应用开辟了新的可能性。这种方法显示了在面对多人不完美信息游戏时，可以通过大型语言模型实现有效的策略生成和决策，为未来相关研究提供了有价值的参考。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22403", "html_url": "https://arxiv.org/abs/2509.22403", "title": "MoveFM-R: 通过语言驱动的语义推理提升移动基础模型", "title_en": "MoveFM-R: Advancing Mobility Foundation Models via Language-driven Semantic Reasoning", "authors": "Fanjin Meng,Yuan Yuan,Jingtao Ding,Jie Feng,Chonghua Han,Yong Li", "background": "移动基础模型（MFMs）已经提高了人类移动模式的建模，然而受限于数据规模和语义理解的限制。大型语言模型（LLMs）提供了强大的语义推理能力，但缺乏生成物理上可信的移动轨迹所需的时空统计理解。为了解决这些差距，作者提出了一种新颖的框架MoveFM-R，该框架利用语言驱动的语义推理能力解锁了MFMs的全部潜力。它解决了地理坐标和离散语言标记之间的词汇不匹配以及MFMs潜变量与LLMs语义世界的表示差距两个主要挑战。实验表明，MoveFM-R 在现有基于MFMs和LLMs的基线方法中表现更优，并在零样本设置中表现出强大的泛化能力，能够在自然语言指令下生成真实可信的轨迹。MoveFM-R 通过整合MFMs的统计力量与LLMs的深度语义理解，开创了一种新的范式，以综合、可解释和强大的方式建模人类移动。", "innovation": "MoveFM-R 的三大创新包括：1) 增强了语义的位置编码，以弥合地理与语言之间的差距；2) 逐步课程，使LLM的推理与移动模式相一致；3) 互动自我反思机制，用于基于条件的轨迹生成。这些创新解决了现有模型在词汇匹配和表示差异上的限制。此外，MoveFM-R 在现有 MFM 和 LLM 基准模型上表现出色，显示了在零样本设置中的稳健泛化能力，能够根据自然语言指令生成真实的轨迹。", "conclusion": "通过将 MFM 的统计力量与 LLM 的深度语义理解结合起来，MoveFM-R 为一种新的建模人类移动的范式奠定了基础，使建模更加全面、可解释和强大。作者的MoveFM-R已公开可在互联网上获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22418", "html_url": "https://arxiv.org/abs/2509.22418", "title": "部分参数更新以实现高效分布式训练", "title_en": "Partial Parameter Updates for Efficient Distributed Training", "authors": "Anastasiia Filippova,Angelos Katharopoulos,David Grangier,Ronan Collobert", "background": "现有的分布式训练方法通过在稀疏的全局同步之间进行多次本地更新来减少通信量。然而，这些方法的效率可以通过限制反向传播得到显著提升：每轮只更新固定的参数子集，而不是更新所有参数。这种方法大幅降低了峰值内存使用和训练FLOPs，而完整地对所有参数进行前向传播消除了跨节点激活数据交换的需求。", "innovation": "提出了一种记忆和计算高效的分布式训练方法，通过限制反向传播，只在每轮训练中更新部分参数，而保留其余参数不变，从而显著减少峰值内存使用和训练FLOPs。另外，通过在每轮训练中对所有参数完整地进行前向传播，可以完全避免跨节点激活数据的交换需求。这种方法在使用相同令牌和带宽预算的情况下，与之前的低通信分布式训练方法具有相同的困惑度表现，但降低了训练FLOPs和峰值内存使用。", "conclusion": "实验表明，该方法在1.3亿参数的语言模型上训练的32个节点中，匹配了前者的困惑度表现，同时减少了训练中的FLOPs和峰值内存使用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22416", "html_url": "https://arxiv.org/abs/2509.22416", "title": "一试通用：预训练模型的大规模图自适应", "title_en": "One Prompt Fits All: Universal Graph Adaptation for Pretrained Models", "authors": "Yongqi Huang,Jitao Zhao,Dongxiao He,Xiaobao Wang,Yawen Li,Yuxiao Huang,Di Jin,Zhiyong Feng", "background": "Graph Prompt Learning (GPL)作为一种新的范例，提高了图预训练模型和下游任务之间的关联性，减少了标签依赖并修正了预训练与下游任务之间的不匹配问题。然而，现有GPL研究探索了各种提示策略，但其效果和原理尚未明确。当前的研究缺乏对底层机制的共识，同时大多数方法在不同下游场景下的适应性有限，尤其是面对数据分布变化时表现不佳。", "innovation": "本文提出了UniPrompt，一种新的GPL方法，旨在适应任何预训练模型，同时保持输入图的结构，释放预训练模型的能力并应对下游场景的变化。通过理论分析，揭示了代表层次提示的实际功能是微调一个简单的下游分类器，而不是简单地改变模型训练方式。研究表明，这种新方法可以有效结合各种预训练模型，并在不同场景中展现出良好的性能。", "conclusion": "研究发现，代表层次的提示本质上就是对一个简单的下游分类器进行微调。UniPrompt方法可以适应任何预训练模型，既释放了预训练模型的能力，又保护了输入图的结构。实验证明，该方法在各种场景下都能取得很好的效果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22411", "html_url": "https://arxiv.org/abs/2509.22411", "title": "快速前向格子玻尔兹曼：基于物理感知神经算子学习动力学行为", "title_en": "Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators", "authors": "Xiao Xue,Marco F.P. ten Eikelder,Mingyang Gao,Xiaoyuan Cheng,Yiming Yang,Yi He,Shuo Wang,Sibo Cheng,Yukun Hu,Peter V. Coveney", "background": "格子玻尔兹曼方程（LBE）基于连续介质理论，通过描述单粒子分布函数（PDF）的时间演化来捕捉复杂流体行为。尽管LBE在流体模拟方面取得了成功，但由于碰撞核引起的严格时间步长限制，其数值求解仍然计算密集型。", "innovation": "本文提出了一个基于物理感知神经算子的LBE框架，可以在不进行逐步积分的情况下预测长时间序列，有效地绕过了显式求解碰撞核的需要。该框架结合了LBE固有的矩匹配约束和整个分布场的全局不变性，使模型能够捕捉到基础动力学系统的复杂动态。该框架具有离散化不变性，使得在粗网格上训练的模型可以泛化到更精细的网格（动力学超分辨率），且不依赖于具体的碰撞模型形式，因此适用于各种不同的动力学数据集。实验结果表明，该框架在复杂流场情景下表现出强大的鲁棒性，包括von Karman漩涡脱落、液滴断裂和气泡附着等现象。", "conclusion": "本文建立了一种新的数据驱动方法来建模动力学系统，通过物理感知的神经算子框架预测格子玻尔兹曼方程的动力学行为，克服了传统LBE方法中的计算挑战，并展示了在多种复杂流场现象中的应用潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22426", "html_url": "https://arxiv.org/abs/2509.22426", "title": "通过额外预测在博弈中处理延迟反馈的学习", "title_en": "Learning from Delayed Feedback in Games via Extra Prediction", "authors": "Yuma Fujimoto,Kenshi Abe,Kaito Ariu", "background": "本研究解决了游戏中学习时间延迟反馈的问题。在游戏学习中，假设多个代理独立学习策略，因此代理间的优化往往出现差异。为克服这一问题，通常会将对未来的奖励预测纳入算法中，即乐观的跟随正则化领导(OFTRL)方法。然而，实际中观察过去的奖励存在延迟，这阻碍了预测的准确性。本研究首次证明，即使是单步延迟也会从后悔和收敛角度恶化OFTRL的表现。", "innovation": "提出了加权OFTRL(WOFTRL)，通过将OFTRL中下一个奖励的预测向量加权n次来克服延迟影响。进一步证明，当乐观权重超过延迟时，WOFTRL能够恢复良好表现，无论是在公共和博弈情况下的后悔为常数（O(1)后悔），以及在多项零和博弈中的策略收敛于纳什均衡（次优迭代收敛）", "conclusion": "理论结果由实验验证和加强，解决了时间延迟对游戏学习算法的影响问题"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22432", "html_url": "https://arxiv.org/abs/2509.22432", "title": "Flood复杂结构：数百万点的大规模持久同调计算", "title_en": "The Flood Complex: Large-Scale Persistent Homology on Millions of Points", "authors": "Florian Graf,Paolo Pellizzoni,Martin Uray,Stefan Huber,Roland Kwitt", "background": "研究大规模欧几里得点云数据的持久同调（PH）计算问题，以支持下游机器学习任务。最常用的 Vietoris-Rips 复杂性由于其指数增长，导致严重的计算限制。尽管存在更可扩展的选择如 Alpha 复杂或稀疏 Rips 近似，但它们往往仍然会导致过多的单纯形数量，这在复杂构造和后续的 PH 计算中提出了挑战，使其无法用于大规模点云数据。", "innovation": "提出了一种名为 Flood 复杂结构的新方法，受到 Alpha 和 Witness 复杂结构构建优势的启发。在给定过滤值 $r \ngeq 0$ 下，Flood 复杂包含所有覆盖半径为 $r$ 的球体的小点云子集的 Delaunay 三角剖分中的单纯形，这是一个被称为淹没的过程。该构建方法允许高效的 PH 计算，具有几个理想的理论性质，并且易于 GPU 并行化。在 3D 点云数据上的放缩试验表明，可以计算到 2 维的 PH。", "conclusion": "在真实世界和合成数据上进行对象分类性能评估时，提供了证据表明这种放缩能力是必需的，特别是当对象在几何形状或拓扑复杂时，结果显示出比其他基于 PH 的方法和卷积神经网络更好的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22458", "html_url": "https://arxiv.org/abs/2509.22458", "title": "带边感知注意力和线搜索校正操作的物理感知GNN用于中高电压AC潮流", "title_en": "Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator", "authors": "Changhun Kim,Timon Conrad,Redwanul Karim,Julian Oelhaf,David Riebesel,Tomás Arias-Vergara,Andreas Maier,Johann Jäger,Siming Bayer", "background": "物理感知图神经网络（PIGNNs）已成为快速的交流功率流求解器，可替代经典的牛顿-拉夫森（NR）求解器，尤其是在需要评估成千上万种情景时。然而，现有的PIGNNs仍需在精度上进行改进以保持其速度；特别是在推理过程中，物理损失不起作用，这阻碍了其在操作中的使用。", "innovation": "作者提出了一种名为PIGNN-Attn-LS的方法，结合了边感知注意力机制（通过边缘偏置显式编码线路物理，捕捉电网的各向异性）与基于回溯线搜索的全局校正操作（在推理时恢复有效的下降准则）。这种方法在中高电压情景下实现了更好的性能。", "conclusion": "对于包含4到32节点的测试案例，PIGNN-Attn-LS的电压和角度测试RMSE分别达到0.00033pu和0.08度，分别比基于MLP的PIGNN基线高出99.5%和87.1%。通过流式微批次，该方法在4到1024节点的电网中比牛顿-拉夫森方法实现了2到5倍的批推理速度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22436", "html_url": "https://arxiv.org/abs/2509.22436", "title": "神经网络常微分方程的全局收敛：激活函数的影响", "title_en": "Global Convergence in Neural ODEs: Impact of Activation Functions", "authors": "Tianxiang Gao,Siyuan Sun,Hailiang Liu,Hongyang Gao", "background": "神经常微分方程（Neural ODEs）因其连续性质和参数共享效率在各种实际应用中取得了成功。然而，这种独特特性也引入了训练中的挑战，特别是梯度计算精度和收敛分析方面的问题。本文探讨了激活函数对训练动力学的影响，指出光滑性和非线性是关键因素，因为光滑的激活函数可以保证向前和向后 ODE 的全局唯一解，而足够的非线性对于保持神经ntk内核在训练过程中的谱特性至关重要。这些特性使得我们能够在过度参数化条件下利用梯度下降证明神经常微分方程的全局收敛性。理论发现得到了数值实验的验证，不仅支持了分析，还为实现更快的训练和提高实际应用中的性能提供了实用指导。", "innovation": "文章通过深入探讨激活函数对神经常微分方程训练动力学的影响，提出了确保全局唯一解和维持神经Tangents核在训练期间谱特性的光滑性和非线性激活函数的重要意义，并通过理论分析和数值实验展示了在过度参数化条件下利用梯度下降证明神经常微分方程的全局收敛性，这是该领域的一项创新贡献，为神经常微分方程的应用开辟了新的途径。", "conclusion": "本文证明了在过度参数化条件下，通过使用具有必要平滑性和非线性的激活函数，可以实现神经常微分方程的全局收敛性。这对提高训练效率和性能具有重要的理论和实践意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22463", "html_url": "https://arxiv.org/abs/2509.22463", "title": "IIET: 通过显式迭代欧拉方法实现高效的数值Transformer", "title_en": "IIET: Efficient Numerical Transformer via Implicit Iterative Euler Method", "authors": "Xinyu Liu,Bei Li,Jiahao Liu,Junhao Ruan,Kechen Jiao,Hongyin Tang,Jingang Wang,Xiao Tong,Jingbo Zhu", "background": "高阶数值方法可以提升Transformer在NLP和CV任务中的性能，但同时会增加计算开销，导致性能效率之间的权衡。传统的效率提升技术，如蒸馏，可能会损害这些模型的性能。因此，需要探索更易于优化的基于ODE的Transformer架构。", "innovation": "提出了一种新的迭代隐形欧拉Transformer（IIET），通过迭代隐形欧拉方法简化高阶方法，不仅提升了性能，还便于模型压缩，相比于PCformer更高效。引入了迭代影响感知蒸馏（IIAD），通过灵活的阈值来平衡性能与效率之间的权衡。实验结果显示，IIET在lm-evaluation-harness上的平均准确性提高了2.65%，相比于蒸馏后的Transformer提升了0.8%。", "conclusion": "最高效的IIET版本在保留99.4%的原始任务准确性的前提下，其推理开销被削减了55%。此外，该变种在与vanilla Transformer相类似的速度下，平均性能获得了超过1.6%的提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22445", "html_url": "https://arxiv.org/abs/2509.22445", "title": "Kolmogorov复杂性与深度学习相结合：Transformer的最优描述长度目标", "title_en": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers", "authors": "Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova", "background": "最小描述长度(MDL)原则提供了应用奥卡姆剃刀原则在机器学习中的形式框架。然而，将其应用于如转换器之类的神经网络存在挑战，主要是因为缺乏一种明确且通用的模型复杂度度量方法。该论文基于柯尔莫哥洛夫复杂度理论，提出了渐进最优描述长度目标的概念，并在此基础上建立了理论依据。研究表明，这样的目标可以在模型资源限制趋近无穷时实现最优压缩。同时，论文证明了这种渐进最优目标确实存在于转换器中，这是通过展示其计算通用性实现的。此外，该研究还展示了如何通过基于自适应高斯混合先验的变分目标来实现这些目标的可计算性和可微性。实验分析表明，该变分目标倾向于选择低复杂度的解，但标准优化器从随机初始化难以找到这样的解，这突显出重要的优化挑战。", "innovation": "该研究引入了渐进最优描述长度目标的概念，并基于柯尔莫哥洛夫复杂度理论建立了其理论基础。它突破了传统框架，证明了此类目标在转换器中的存在性，并提出了一种基于自适应高斯混合先验的变分目标，从而使得目标具有可计算性和可微性，能够有效指导模型选择和优化。此外，该研究明确了这一框架可用于训练能实现更高效压缩和泛化的神经网络的潜在路径。", "conclusion": "该研究通过提供一个理论框架来确定具有强大渐进性保证的描述长度目标，为训练能实现更高压缩和泛化的神经网络指明了潜在路径。研究强调了优化过程中的关键挑战，并展示了基于变分目标选择低复杂性解决方案的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22462", "html_url": "https://arxiv.org/abs/2509.22462", "title": "基于GPU加速神经网络约束的非线性优化", "title_en": "Nonlinear Optimization with GPU-Accelerated Neural Network Constraints", "authors": "Robert Parker,Oscar Dowson,Nicole LoGiudice,Manuel Garcia,Russell Bent", "background": "本文提出了一个在GPU上评估神经网络输出及其导数的缩减空间优化形式。与完全空间形式相比，在完全空间形式中，中间变量和约束对优化求解器可见，而缩减空间形式将神经网络视为“灰色盒”，中间变量和约束不对外可见。这导致使用内部点法时求解速度更快且迭代次数更少。作者通过两个优化问题展示了该方法的好处：一种是对MNIST图像进行训练的分类器的对抗生成优化，另一种是强稳健最优潮流问题，通过神经网络代理确保暂态可行性.", "innovation": "提出了一种基于GPU加速神经网络约束的缩减空间非线性优化形式。通过将神经网络视为“灰色盒”以隐藏中间变量和约束条件，从而提高优化求解速度和减少迭代次数。这种方法适用于处理神经网络相关的优化问题，如对抗生成和安全性约束优化问题.", "conclusion": "该研究展示了基于GPU加速神经网络约束的缩减空间优化形式在对抗生成和安全性约束优化问题中的优势。这种方法可以更快地求解问题，并且需要更少的迭代次数。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22483", "html_url": "https://arxiv.org/abs/2509.22483", "title": "OFMU: 由优化驱动的机器遗忘框架", "title_en": "OFMU: Optimization-Driven Framework for Machine Unlearning", "authors": "Sadia Asif,Mohammad Mohammadi Amiri", "background": "在敏感应用中部署的大规模语言模型需要在不从头开始重新训练的情况下卸载特定知识（如用户请求、版权材料或过时信息），以满足监管合规、用户隐私和安全的需求。这一任务被称为机器遗忘，其目标是在遗忘目标数据影响的同时保持对剩余数据的性能。一种常见的方法是将该问题建模为一个多目标问题，并通过标量化将其转化为单目标问题，即将遗忘和保留损失通过加权和的方式结合起来。然而，这种方法经常导致训练动态不稳定和模型性能下降，因为目标梯度方向冲突。", "innovation": "为了解决上述挑战，本文提出了OFMU（优化驱动的机器遗忘框架），通过引入层次结构的惩罚基础双层优化框架，明确优先遗忘同时保留保留。该方法通过内层最大化的步骤来实施遗忘，并通过引入一种基于相似性的惩罚来解相关遗忘和保留目标的梯度，同时通过外层最小化的步骤恢复模型性能。为了确保可扩展性，我们开发了一个两层算法，并在凸和非凸环境中都证明了收敛性。进一步的理论分析显示，我们的方法在遗忘效果和保留性能的权衡上优于先前的方法。", "conclusion": "广泛的经验研究证实，在视觉和语言基准上，OFMU 在遗忘效果和保留性能上都优于现有的卸载方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22500", "html_url": "https://arxiv.org/abs/2509.22500", "title": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise", "title_en": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise", "authors": "Juan Ramirez,Simon Lacoste-Julien", "background": "约束优化是强制神经网络满足要求的强大框架，通常使用min-max拉格朗日形式的一阶方法求解此类问题，但这种方式常常容易出现振荡并可能无法发现所有局部解。虽然增强拉格朗日方法(ALM)解决了这些问题，但实践中人们更喜好使用标准拉格朗日的经典乐观递增方案(PI控制)，尽管这种方法在实操中表现较好，但缺乏正式的理论保证。", "innovation": "本文建立了一种先前未知的等价关系：拉格朗日的双乐观上升与增强拉格朗日的梯度下降-上升等价。这一发现使得ALM的鲁棒理论保证能够转移到双乐观设置中，证明该方法可以线性收敛到所有局部解。此外，这种等价关系还提供了一种原理性的指导，用于调优乐观的超参数。这项工作填补了双乐观方法的实操成功与其理论基础之间的关键差距。", "conclusion": "本文证明了增强拉格朗日方法 ALM 和双乐观上升 PI 控制之间的等价性，从而使得 ALM 的理论优势可以应用于 PI 控制下，证明了该方法可以线性收敛到所有局部解。同时，这种等价关系为调优乐观超参数提供了指导。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22484", "html_url": "https://arxiv.org/abs/2509.22484", "title": "一种多发性硬化症生物标志物发现的机器学习管道：比较可解释AI与传统统计方法", "title_en": "A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches", "authors": "Samuele Punzo,Silvia Giulia Galfrè,Francesco Massafra,Alessandro Maglione,Corrado Priami,Alina Sîrbu", "background": "该研究背景在于利用机器学习方法在多元公开的微阵列数据集中发现多发性硬化症（MS）的生物标志物。通过对外周血单核细胞（PBMC）相关数据的处理和分析，结合可解释AI和传统统计方法进行对比研究，旨在深入探索疾病的机制并识别关键生物标志物。", "innovation": "研究通过构建集成公开微阵列数据的机器学习管道，使用XGBoost分类器（通过贝叶斯搜索优化）进行训练。使用SHAP解释方法来识别关键特征，进而可能发现潜在生物标志物，并与传统差异表达分析（DEA）结果进行对比，揭示两者间的互补优势。此外，通过通路富集分析验证了SHAP选择基因的生物学意义，关联到与MS相关的通路，如鞘脂信号传导、Th1/Th2/Th17细胞分化、EB病毒感染等。这项研究强调了结合可解释AI与传统统计方法的价值，以获得对疾病机制的深入理解。", "conclusion": "该研究表明，将可解释的人工智能（xAI）与传统的统计方法相结合，有助于更深入地理解疾病机制，并识别出与MS相关的潜在生物标志物。研究结果揭示了SHAP和DEA在识别生物标志物方面的互补性，并通过功能富集分析进一步证实了所选基因的生物学相关性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22482", "html_url": "https://arxiv.org/abs/2509.22482", "title": "Reproducing Kernel Hilbert Spaces中的Bayesian转移算子", "title_en": "Bayesian Transfer Operators in Reproducing Kernel Hilbert Spaces", "authors": "Septimus Boshoff,Sebastian Peitz,Stefan Klus", "background": "库工曼算子作为一种非线性动力系统的线性表示，在科学的各个领域引起了广泛的关注。近年来，库工曼算子理论与数据科学中流行的再生核希尔伯特空间概念结合。本文沿着这一线索，结合了高斯过程方法，展示了这些方法如何缓解基于核的库工曼算法中的两个普遍问题：稀疏性（大多数核方法的扩展性不佳，需要近似才能实用）和传感器噪声的鲁棒性提升；以及超参数优化和字典学习，以适应动力系统。", "innovation": "本文的主要贡献在于将高斯过程回归与动力模式分解进行了统一。这不仅可以降低计算需求，还可以提高算法对传感器噪声的鲁棒性，并通过超参数优化和字典学习使模型更好地适应动力系统。", "conclusion": "本文通过将高斯过程方法与库工曼算子理论相结合，解决了基于核的库工曼算法中的两个主要问题，推动了动力系统建模的新发展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22522", "html_url": "https://arxiv.org/abs/2509.22522", "title": "JointDiff: 联合连续和离散在多智能体轨迹生成中的桥梁", "title_en": "JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation", "authors": "Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo", "background": "生成模型通常将连续型数据和离散事件视为单独的过程，这在建模复杂系统时造成了差距，特别是当它们同步互动时。为了解决这个问题，作者引入了JointDiff，这是一种新的扩散框架，旨在通过同时生成连续时空数据和同步离散事件来统一这些过程。", "innovation": "JointDiff 是一种新的扩散框架，通过同时生成连续时空数据和同步离散事件，统一处理连续型数据和离散事件的过程。它在运动领域通过同时建模多智能体轨迹和关键占有事件来验证其有效性。此外，作者还引入了 CrossGuid，这是一种多智能体领域有效的条件操作，使模型能够根据这些引导信号进行条件处理。", "conclusion": "JointDiff 达到当前最先进的性能，证明了在构建交互系统中的真实和可控生成模型时，联合建模是至关重要的。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22468", "html_url": "https://arxiv.org/abs/2509.22468", "title": "学习邻居：无对比的多模态自监督分子图预训练", "title_en": "Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining", "authors": "Boshra Ariguib,Mathias Niepert,Andrei Manolache", "background": "高质量的分子表示对于属性预测和分子设计至关重要，然而，大型带标签的数据集仍然稀缺。虽然自我监督的预训练在分子图上显示出前景，但许多现有的方法依赖于手工制作的增强或复杂的生成目标，通常仅依赖于2D拓扑结构，使宝贵的3D结构信息未能充分发挥作用。", "innovation": "引入了C-FREE（基于自我网络的无对比代表学习），这是一种集成2D图与3D构象集合的简单框架。C-FREE利用固定半径的自我网络作为建模单元，在不同的构象中，通过预测潜空间中子图嵌入的补区间来学习分子表示，无需负例，位置编码或昂贵的预处理。使用提供丰富3D构象多样性的GEOM数据集进行预训练，C-FREE在MoleculeNet上达到了最佳结果，超越了对比目标、生成和其他多模态自我监督方法。", "conclusion": "跨不同大小和分子类型的多个数据集的微调进一步证明了预训练可以在新的化学领域中有效转移，突显了3D导向的分子表示的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22507", "html_url": "https://arxiv.org/abs/2509.22507", "title": "非一层单模式蒸馏与激励方案以实现非IID数据上可扩展的、异构的联邦学习", "title_en": "Adaptive Dual-Mode Distillation with Incentive Schemes for Scalable, Heterogeneous Federated Learning on Non-IID Data", "authors": "Zahid Iqbal", "background": "联邦学习（FL）作为一种在不泄露用户隐私的情况下利用分散数据的有前景的去中心化学习方法而逐渐兴起。然而，FL面临着几个关键挑战。首先，通常假定每个客户端都能训练相同的机器学习模型，但并非所有客户端都能满足这一假设，因为它们在业务需求和计算资源方面存在差异。其次，统计异质性（非-IID数据）是FL的一个主要挑战，可能导致全局模型性能下降。第三，解决这些挑战需要一种成本效益高的激励机制来鼓励客户端参与FL训练。", "innovation": "本文提出了几种方法：DL-SH，通过在统计异质性背景下支持高效、隐私保护和通信高效的联邦学习；DL-MH，旨在应对完全异质模型的同时解决统计差异；I-DL-MH，一种基于激励的DL-MH扩展，提供激励以促进客户端在复杂联邦学习框架中的参与。实验在多种模型架构和多样化的数据分布下进行了广泛测试，包括IID情况和多种非-IID情景，以及多个数据集。实验结果表明，所提出的方法在准确性和通信成本方面显著优于现有最先进的方法，DL-SH在非-IID条件下的全局模型准确性提高了153%，而I-DL-MH实现了225%的改善。", "conclusion": "本文提出的DL-SH和I-DL-MH为解决非IID数据上的异构联邦学习提供了一种有效的解决方案，全面提升了模型性能，增强了成本效益，并增强了客户端参与度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22576", "html_url": "https://arxiv.org/abs/2509.22576", "title": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning", "title_en": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning", "authors": "Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris", "background": "在多回合环境中训练大规模语言模型（LLM）代理，且完成单个任务需要30多轮互动，这为强化学习带来了基本挑战。在这种设置下，传统探索-利用机制（exploration-exploitation）失效，导致代理过早收敛于低熵、低效的策略，最终陷入不稳定训练状态。", "innovation": "提出了一种新的熵正则化策略优化框架（Entropy-regularized Policy Optimization, EPO），通过以下三个机制来解决多回合稀疏奖励环境中的探索-利用问题：（1）采用多回合环境中的熵正则化来增强探索；（2）引入熵平滑正则化约束策略熵值在历史平均值内，防止剧烈波动；（3）自适应阶段加权平衡训练中的探索与利用。", "conclusion": "EPO 能够确保熵不确定性单调递减并保持收敛，相比传统方法在 ScienceWorld 和 ALFWorld 上的性能分别提高了152%和19.8%。该研究指出，多回合稀疏奖励设定需要不同于传统强化学习的熵控制方法，对LLM代理训练具有广泛影响。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22592", "html_url": "https://arxiv.org/abs/2509.22592", "title": "基于传输的均值流生成模型", "title_en": "Transport Based Mean Flows for Generative Modeling", "authors": "Elaheh Akbari,Ping He,Ahmadreza Moradipari,Yikun Bai,Soheil Kolouri", "background": "随着流匹配生成模型在图像、3D 形状和点云等领域取得卓越成果，人们越来越关注这些模型的实时性问题。尽管这些模型表现优异，但在推理速度上仍存在瓶颈，需要大量的顺序采样步骤。近年来的研究致力于通过减少采样步骤来加速推理。均值流为一步生成的范式提供了可能，尽管在许多连续域中，其生成质量较好但无法准确模拟多步流程的复杂行为。", "innovation": "本文通过将最优传输策略引入均值流框架中，使其能在保持生成质量和多样性的前提下，进行一步生成，从而更好地模拟原始多步流匹配生成过程。实验结果表明，与现有的生成模型相比，该方法在一步生成建模中的推断准确性更高。", "conclusion": "我们在控制的低维度设置上以及高维度任务（如图像生成、图像至图像转换和点云生成）中的实验结果证明，本文提出的方法能够在一个步骤生成建模中实现更优的推断准确度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22562", "html_url": "https://arxiv.org/abs/2509.22562", "title": "激活函数设计在连续学习中维持可塑性", "title_en": "Activation Function Design Sustains Plasticity in Continual Learning", "authors": "Lute Lillo,Nick Cheney", "background": "在独立且相同分布的训练制度下，激活函数已被广泛测试，它们之间的差异通常会因模型大小和优化的调整而缩小。然而，在连续学习中，情况不同：模型不仅存在灾难性遗忘的问题，还可能逐渐失去适应能力（称为可塑性损失），而这一失败模式中非线性的角色尚未受到足够的探索。", "innovation": "本文从负支结构和饱和行为的属性层面进行分析，提出两种可插入的非线性函数（Smooth-Leaky和Randomized Smooth-Leaky），并在有标签类别递增基准和非稳态MuJoCo环境中进行评估，展示了激活函数选择是减轻可塑性损失的主要杠杆。此外，还提供了简单的应变协议和诊断工具，将激活函数的形状与适应变化相关联。", "conclusion": "研究表明，精巧设计的激活函数提供了一种轻量级且可泛化的方式，在无需额外容量或任务特定调整的情况下维持连续学习中的可塑性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22601", "html_url": "https://arxiv.org/abs/2509.22601", "title": "掌握绳索，再依赖胜利：渐进探索的自我模仿强化学习", "title_en": "Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning", "authors": "Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun", "background": "强化学习（RL）在提升大型语言模型（LLM）在长期任务和稀疏奖励代理任务中的策略性工具使用能力方面占据主导地位，但面临着探索-利用权衡的基本挑战。现有研究通过策略entropy最大化来刺激探索，但这种机械的entropy最大化导致了RL训练的不稳定性。论文针对在代理自身经验指导下，渐进探索-利用平衡的问题，提出了一种基于课程的自我模仿学习（SIL）方法SPEAR，以避免entropy坍塌或失控发散。", "innovation": "提出了一种基于课程的自我模仿学习方法SPEAR（Self-imitation with Progressive Exploration and Regulation），在不牺牲探索或剧烈发散的前提下，逐步引导策略进化。这种方法通过引⼊内在奖励培养技能级别的探索，并利用自我模仿加强已成功模式的利用，实现逐步增加的操作级别的探索。还通过逐步调整replay缓冲区中经验的重要性来强化训练稳定性，从而控制策略漂移，并引入正规化手段来防止信心过度。", "conclusion": "SPEAR通过在训练过程中逐步调整探索和利用之间的平衡，为代理型强化学习提供了稳定的策略培训方法，提高了策略学习的灵活性和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22566", "html_url": "https://arxiv.org/abs/2509.22566", "title": "从参数到行为：政策空间的无监督压缩", "title_en": "From Parameters to Behavior: Unsupervised Compression of the Policy Space", "authors": "Davide Tenedini,Riccardo Zamboni,Mirco Mutti,Marcello Restelli", "background": "尽管深度强化学习（DRL）在最近取得了成功，但其样本效率极低。这主要归因于直接在高维度且高度冗余的参数空间 Θ 中优化策略的做法。在多任务设置中，该挑战变得更加复杂。研究表明，环境的复杂性可能是压缩后的固有维度决定因素，而非策略网络的规模决定。", "innovation": "本文提出了一种新颖的无监督方法，将策略参数空间 Θ 压缩到低维度的潜在空间 Z 中。通过优化行为重建损失来训练生成模型 g: Z → Θ，确保潜在空间根据功能相似性而非参数化邻近性来组织。结果表明，标准策略网络的参数化可以在不显著牺牲其表达能力的情况下被压缩高达五个数量级。此外，通过在潜在空间 Z 中运行策略梯度实现了任务特定适应能力。", "conclusion": "该工作展示了将策略参数空间压缩到潜在空间的概念验证。与传统的高维度策略优化相比，这种方法提高了样本效率，并且在连续控制领域中显示出巨大的潜力。此外，其无监督压缩策略提供了一种新的方式来实现任务特定的适应。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22574", "html_url": "https://arxiv.org/abs/2509.22574", "title": "机器学习方法在奥斯特拉瓦地区地震事件分类中的应用", "title_en": "Machine learning approaches to seismic event classification in the Ostrava region", "authors": "Marek Pecha,Michael Skotnica,Jana Rušajová,Bohdan Rieznikov,Vít Wandrol,Markéta Rösnerová,Jaromír Knejzlík", "background": "捷克共和国东北部是该国地震活动最活跃的区域之一。这里不仅由于过去强度较高的采矿活动，频繁发生采矿诱发的地震，而且有可能发生天然断层地震。此外，该地区地震台站常记录采石场的爆炸事件。尽管采矿活动已经结束，但采矿诱发的地震仍然会发生。因此，快速区分天然断层地震和人类活动引发的事件仍然重要。目前该区域由Ostrava-Krásné Pole的OKC地震台站监控，自2007年起提供100 Hz的数字化连续波形数据。1992年至2002年间，Frenštát勘探多边形（SPF）地区由五个地震台站联合监控，采用触发STA/LTA系统。", "innovation": "本文应用并比较了机器学习方法在SPF数据集中的表现。该数据集包含标签化的天然断层地震和采矿诱发地震记录，主要用于二元分类任务。长短期记忆循环神经网络和XGBoost在二元分类任务中的F1分数达到了0.94-0.95，展示了现代机器学习技术在快速事件分类中的潜力。", "conclusion": "研究结果证明，在利用大量地震事件数据进行迅速分类和提取关键特征方面，现代机器学习技术具有显著优势，能够有效辅助地震事件的快速鉴别。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22557", "html_url": "https://arxiv.org/abs/2509.22557", "title": "学习定价捆绑：混合捆绑的GCN方法", "title_en": "Learning to Price Bundles: A GCN Approach for Mixed Bundling", "authors": "Liangyu Ding,Chenghan Wu,Guokai Li,Zizhuo Wang", "background": "捆绑定价是指设计几个产品组合（即捆绑）并确定其价格以最大化预期利润。这个问题是收益管理中的经典问题，出现在电子商务、旅游业和视频游戏等行业中。然而，由于候选捆绑的数量呈指数增长，这个问题通常难以解决。本文探讨了在解决捆绑定价问题时使用图卷积网络（GCNs）的方法。首先，发展了一个混合捆绑模型（其中每个可能的捆绑都赋予特定的价格）的图表表示法，然后训练了一个GCN来学习最优捆绑的潜在模式。基于训练好的GCN，提出了一种推理策略来推导出高质量的可行解决方案。进一步提出了局部搜索技术来提高解决方案的质量。数值实验验证了基于GCN的方法的有效性和效率。使用在5种产品实例上训练的GCN，我们的方法在小到中型问题上已经实现了近似最优解，并且比其他启发式方法（如捆绑大小定价）在更大规模的问题上也取得了更好的效果。即使对于产品收益非加性的情况，该方法也能为超过30种产品实例提供高质量的解决方案。", "innovation": "本研究提出了使用图卷积网络（GCNs）来解决捆绑定价问题的创新方法。首先构建混合捆绑模型的图形表示，然后训练GCN来学习最优捆绑的潜在模式。基于训练好的GCN，提出两种推理策略来推导高质量的可行解决方案。进一步提出局部搜索技术来提高解决方案质量。与传统方法相比，该方法在较小和中等规模的问题上表现优异，并且在大规模问题上的效果也优于其他启发式方法，甚至可以为超过30种产品实例提供高质量的解决方案，即使产品收益非加性的情况也能取得良好的效果。", "conclusion": "通过训练的GCN，可以高效且高质量地解决捆绑定价问题。数值实验验证了基于GCN的方法在各种规模问题上的有效性。该方法在较小到中等规模的问题上实现近最优解，并在大规模问题上优于其他启发式方法。即使是产品收益非加性的情况，也可以通过该方法获得高质量的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22580", "html_url": "https://arxiv.org/abs/2509.22580", "title": "平均的谬误：为什么类增量学习的评估会误导你？", "title_en": "The Lie of the Average: How Class Incremental Learning Evaluation Deceives You?", "authors": "Guannan Lai,Da-Wei Zhou,Xin Yang,Han-Jia Ye", "background": "类增量学习（CIL）要求模型能够在不断学习新类别的同时不忘记之前学到的内容，并在整个可能的类别序列中保持稳定的性能。然而，在实际环境中，类别出现的顺序是多样且不可预测的，这会导致模型性能在不同的序列中显著变化。现有的主流评估协议仅通过从少量随机选取的序列计算平均值和方差，未能全面捕捉到性能范围，导致平均值偏向估计和真实的性能分布方差严重低估。论文通过理论分析和实验结果证明了这一点，强调了稳健CIL评估协议应准确描述和估计整个性能分布的重要性。", "innovation": "文章提出了极端序列的概念，并通过理论证明其在可靠评估CIL中的关键作用。此外，文章观察到任务间相似性与模型性能之间存在一致的正相关关系，利用这一关系指导寻找极端序列。在此基础上，提出了一种称为EDGE（Extreme case-based Distribution and Generalization Evaluation）的评估协议，该协议能够自适应地识别和采样极端的类别序列，从而更接近地逼近真实性能分布。", "conclusion": "广泛的实验表明，EDGE能够有效捕获性能的极端情况，并给出更准确的性能分布边界估计，从而为模型选择和鲁棒性检查提供切实可行的见解。目前的代码可通过以下链接访问：[请替换为实际链接]。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22556", "html_url": "https://arxiv.org/abs/2509.22556", "title": "ECHO：迈向大尺度EEG模型中的上下文序列到序列范式", "title_en": "ECHO: Toward Contextual Seq2Seq Paradigms in Large EEG Models", "authors": "Chenyu Liu,Yuqiu Deng,Tianyu Liu,Jinan Zhou,Xinliang Zhou,Ziyu Jia,Yi Ding", "background": "脑电图（EEG）因其广泛的应用场景需要能够跨多种任务和数据集有效泛化的模型。大型EEG模型（LEMs）通过在大规模未标注数据上预训练以提取通用表示来解决这一问题，但这些模型缺乏容量相当的解码器，这限制了从学到的功能中获得的最大潜力。", "innovation": "为了解决上述问题，本文提出了一种新的解码器为中心的LEM范式ECHO，将EEG建模重新表述为序列到序列学习。ECHO通过在一个序列空间中捕捉信号、标签和任务之间的层次关系，并利用离散支持样本来构建上下文线索，赋予了它上下文学习的能力。这种设计能够在无需参数更新的情况下动态适应异质性任务。", "conclusion": "在多个数据集上的广泛实验表明，即使使用基本模型组件，ECHO也能在多任务设置中持续超越最新的单任务LEM模型，显示出更优越的泛化能力和适应性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22623", "html_url": "https://arxiv.org/abs/2509.22623", "title": "离散流匹配生成模型的理论分析", "title_en": "A Theoretical Analysis of Discrete Flow Matching Generative Models", "authors": "Maojiang Su,Mingcheng Lu,Jerry Yao-Chieh Hu,Shang Wu,Zhao Song,Alex Reneau,Han Liu", "background": "本文提供了一种端到端训练离散流匹配（DFM）生成模型的理论分析。DFM是一种有前途的离散生成建模框架，通过训练神经网络来近似变换的速度场，学习潜在的生成动力学。", "innovation": "文章通过分解最终分布估计误差，建立了一个清晰的保证链。首先证明生成分布与目标分布之间的总变差距离受所学速度场风险的控制。然后通过分析其两个主要来源（近似误差和估计误差），进一步提高了风险的界限，并提供了Transformer架构对真实速度的表示能力的量化。同时，通过推导统计收敛率，限制了有限数据集训练的误差。把这些结果结合起来，首次给出了在训练集大小增加时，由训练的DFM模型生成的分布会证明收敛于真实数据分布的正式证明。", "conclusion": "本文通过理论分析，证明了在训练集大小增加时，由训练的DFM模型生成的分布会收敛于真实数据分布，使DFM模型在理论层面有了更可靠的支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22611", "html_url": "https://arxiv.org/abs/2509.22611", "title": "熵安全推理的分位优势估计", "title_en": "Quantile Advantage Estimation for Entropy-Safe Reasoning", "authors": "Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He", "background": "强化学习中的可验证奖励（RLVR）能够增强LLM的推理能力，但在训练过程中经常出现{熵崩溃}和{熵爆炸}的震荡现象。这种问题源于价值自由RL（如GRPO和DAPO）中使用的目标均值基准，该基准在奖励异常值下错误地惩罚了负优势样本。这一现象导致在处理复杂查询和简单查询时表现不稳定，影响了LLM的整体表现和训练稳定性.", "innovation": "该研究提出了一种名为{分位优势估计}（QAE）的新方法，通过替代均值基准为分组的K-分位数基准，引入了一种基于响应级别的两阶段门控机制。该机制在处理难题时强化罕见的成功，而在处理简单问题时则继续针对剩余的失败。在经过一阶Softmax更新后，证明了{双向熵安全}，即限制了一步熵变化的上下限，防止了熵爆炸并阻止了熵崩溃。实验结果显示，这种小型的修改可以稳定熵，通过精调K值使约80%的响应获得零优势，并在Qwen3-8B/14B-Base上持久地提高了AIME 2024/2025和AMC 2023的通过率.", "conclusion": "研究确定了{基准设计}比基于令牌级别的启发式方法更能有效地规模化提升RLVR的能力和稳定性，从而为LLM的训练和推理提供了新的策略和方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22621", "html_url": "https://arxiv.org/abs/2509.22621", "title": "IA2: 与ICL激活相匹配提高监督微调", "title_en": "IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning", "authors": "Aayush Mishra,Daniel Khashabi,Anqi Liu", "background": "监督微调（SFT）通过训练权重以产生针对查询的预期目标响应来使模型行为更加专业化。相比之下，上下文内学习（ICL）在推理过程中通过提示中的指令或示范来适应模型。在数据稀少的情况下，ICL能提供更好的泛化能力和更加校准的响应，但代价是更多的推理计算资源。本文探讨了能否利用ICL的内部计算来改进SFT的质量。研究表明，ICL和SFT通过不同的功能机制实现适应。因此，作者提出了ICL激活对齐（IA2），这是一种自我蒸馏技术，旨在在SFT模型中复制ICL的激活模式，鼓励模型进行类似ICL的内部推理。实验结果显示，在SFT之前作为预热步骤执行IA2可以显著提高模型输出的准确性和校准度，这一结论不仅具有实际意义，还提供了一种理解模型适应机制的概念窗口。", "innovation": " authors introduced ICL Activation Alignment (IA2), a self-distillation technique, which aims to replicate ICL's activation patterns in SFT models and incentivizes ICL-like internal reasoning. This method was shown to significantly improve the accuracy and calibration of model outputs when performed as a pre-training step before SFT, across 12 popular benchmarks and 2 model families.", "conclusion": "performing IA2 as a pre-training step before SFT significantly improves the accuracy and calibration of model outputs, as demonstrated by extensive empirical results, offering a practical and conceptual insight into model adaptation."}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22626", "html_url": "https://arxiv.org/abs/2509.22626", "title": "学习适用于A*的可采纳启发式方法：理论与实践", "title_en": "Learning Admissible Heuristics for A*: Theory and Practice", "authors": "Ehsan Futuhi,Nathan R. Sturtevant", "background": "启发函数是诸如A星算法之类的搜索算法性能的核心，其中可采纳性——即从不高估最短路径成本的性质——保证了解决方案的最优性。近年来，深度学习方法常常忽视了可采纳性，且在训练数据之外的泛化能力有限。本文正是在这一背景下，解决这一局限。", "innovation": "首先，作者将启发式学习提为一个带约束的优化问题并引入了交叉熵可采纳性（Cross-Entropy Admissibility, CEA）损失函数，在训练期间强制执行可采纳性。在鲁比克立方体领域，该方法产生了接近可采纳的启发函数，其指导能力显著强于压缩模式数据库（PDB）启发函数。理论分析上，通过利用PDB抽象及图结构特性（如鲁比克立方体），作者最为A星提供了所需的训练样本数上的约束。将一般的假设类替换为ReLU神经网络，给出了主要依赖于网络的宽度和深度，而不是图大小的泛化保证。此外，作者还提供了首个关于目标依赖启发式的泛化保证", "conclusion": "本文通过提出交叉熵可采纳性损失函数(CEA)解决了启发式学习方法中忽视可采纳性及泛化能力不佳的问题，在鲁比克立方体领域获得了接近可采纳的启发函数。从理论上，通过利用PDB抽象和图结构特性，作者紧缩了A星泛化的训练样本数量边界。使用ReLU神经网络，研究给出了泛化保证主要依赖于网络宽度和深度的新边界，并首次提供了目标依赖启发式的泛化保证。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21327", "html_url": "https://arxiv.org/abs/2509.21327", "title": "评估集成气象和环境变量的深度学习模型在wildfire蔓延预测中的性能及2023年毛伊岛火灾案例研究", "title_en": "Assessment of deep learning models integrated with weather and environmental variables for wildfire spread prediction and a case study of the 2023 Maui fires", "authors": "Jiyeon Kim,Yingjie Hu,Negar Elhami-Khorasani,Kai Sun,Ryan Zhenqi Zhou", "background": "预测野火的传播对于有效的野火管理及风险评估至关重要。随着人工智能（AI）的迅猛发展，各种深度学习模型被开发并应用于野火蔓延预测。然而，这些模型的优势和局限性尚不明确，也不清楚基于深度学习的野火模型如何与现有的非AI野火模型进行比较。", "innovation": "评估了集成气象和环境变量的五种典型深度学习模型在夏威夷州十多年的野火数据中的野火蔓延预测能力，并使用2023年毛伊岛的野火作为案例研究，将最佳深度学习模型与广泛使用的野火蔓延模型FARSITE进行比较。结果表明，ConvLSTM和带有注意机制的ConvLSTM在五种测试的AI模型中表现最佳，FARSITE在精确度上高于AI模型，但在召回率和F1分数上较低。并且，通过结合解释性AI方法进一步识别与2023年毛伊岛野火相关的关键气象和环境因素。", "conclusion": "两种深度学习模型在野火预测中表现最优，FARSITE模型在精确度上有所优势，但在召回率和综合得分上不如深度学习模型。深度学习模型提供了更大的输入数据灵活性。通过结合解释性AI方法，进一步确定了与2023年毛伊岛野火有关的重要气象和环境因素。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21330", "html_url": "https://arxiv.org/abs/2509.21330", "title": "可解释的光谱特征预测掺杂共轭聚合物实验室中的电导率", "title_en": "Interpretable Spectral Features Predict Conductivity in Self-Driving Doped Conjugated Polymer Labs", "authors": "Ankush Kumar Mishra,Jacob P. Mauthe,Nicholas Luke,Aram Amassian,Baskar Ganapathysubramanian", "background": "自驾驶实验室（SDLs）通过结合自动化与机器学习有望加速材料发现，但面临的中心挑战是从廉价且易于自动化测量的读数中预测昂贵且测量耗时的性质。本文针对掺杂共轭聚合物，通过学习从光学光谱数据中学习可解释的光谱指纹，来预测电导率，利用基因算法（GA）和自适应选择的光谱窗口下的曲线下面积（AUC）计算，实现光谱特征的自动化提取。这些从数据驱动中获得的光谱特征，结合加工参数，通过训练结构-性质关系（QSPR）模型以将光谱响应和处理过程与电导率联系起来。改进小数据集下的准确性和可解释性，加入基于领域的特征扩张，并应用SHAP引导选择以保留一个紧凑且物理意义明确的特征集。", "innovation": "创新点在于提出了一种以光学光谱数据为基础学习可解释的光谱特征的方法，结合基因算法与自适应光谱窗口选择，通过SHAP引导的特征筛选方法，形成一个从数据驱动与专家特征相结合的结构-性质关系模型，提高了预测性能并减少了实验努力，同时揭示了掺杂成功时的尾态区域与聚合物褪色相关。该方法适用于其他谱学模态（如XANES、拉曼、FTIR），能够提供解释性、抗噪声的、小数据友好的特征，使快速测量转化为对昂贵性质的可靠预测。", "conclusion": "该研究不仅研发出了一个数据驱动的模型，与专家构建的基线模型性能相当，但实验努力减少了约33%，同时揭示了更多关于掺杂共轭聚合物电导率的潜在理解。此外，该方法由于其可解释性、抗噪声以及在小数据集下的友好特性而适用于其他谱学技术。该研究展示了数据驱动方法与专家知识结合以进行有成效的人工智能合作，同时也提供了一种更高效地预测昂贵性质的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21346", "html_url": "https://arxiv.org/abs/2509.21346", "title": "基于多模态方法的突触神经网络在心理负载分类中的应用", "title_en": "Spiking Neural Networks for Mental Workload Classification with a Multimodal Approach", "authors": "Jiahui An,Sara Irina Fabrikant,Giacomo Indiveri,Elisa Donati", "background": "准确评估心理负载在认知神经科学、人机交互和实时监控中至关重要，因为心理负载波动会影响表现和决策。虽然基于脑电图（EEG）的机器学习（ML）模型可用于此目的，但其高计算成本妨碍了嵌入式的实时应用。具有事件驱动特性的突触神经网络（SNN）的硬件实现提供了低功耗、快速处理的有前途的替代方案。", "innovation": "该研究比较了硬件兼容的SNN模型和各种传统ML模型在多模态数据集上的表现，结果显示多模态集成提高了准确度，SNN表现接近ML模型，证明了它们在认知负载检测实时应用中的潜力。此外，研究将基于事件的处理定位为低延迟、能效工作的有前途的解决方案。", "conclusion": "研究结果表明，SNN模型在认知负载分类中的表现与传统ML模型相当，多模态集成提高了准确度，突出了事件驱动方法在低延迟和能效的工作负载监控中的潜力，适用于动态调节心理负载的适应性闭环嵌入式设备。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21331", "html_url": "https://arxiv.org/abs/2509.21331", "title": "使用深度分割网络从多源射线记录中进行地震波速度反演：U-网变体与SeismoLabV3+的基准测试", "title_en": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+", "authors": "Mahedi Hasan", "background": "地震波速度反演是地球物理勘探中的关键任务，能够从地震波数据中重建地下结构。这对于高分辨率的地震成像和解释至关重要。传统的物理驱动方法，如全波形反演(FWI)，计算密集，对初始化敏感，且受地震数据带宽的限制。近年来，深度学习的进步促进了数据驱动的方法，将速度反演视为密集预测任务。这项研究使用ThinkOnward 2025 Speed & Structure数据集中的五通道地震射线记录及其对应的高分辨率速度图，对比了三种先进的编码器-解码器架构（U-Net、U-Net++和DeepLabV3+）及其优化变体SeismoLabV3+在地震波速度反演中的性能。", "innovation": "使用深度分割网络进行地震波速度反演；对比了三种先进的编码器-解码器架构，包括最新优化的SeismoLabV3+；SeismoLabV3+在评估标准下内部验证集和隐藏测试集上表现最优，MAPE值分别为0.03025和0.031246。", "conclusion": "深度分割网络适用于地震波速度反演；特定架构改进对提升地球物理AI模型具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21352", "html_url": "https://arxiv.org/abs/2509.21352", "title": "改进自闭症检测的多模态行为分析", "title_en": "Improving Autism Detection with Multimodal Behavioral Analysis", "authors": "William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla", "background": "由于自闭症谱系障碍（ASC）的诊断复杂且资源密集，已经提出了多种基于计算机辅助诊断支持的方法，通过分析患者视频数据中的行为线索来检测自闭症。尽管这些模型在某些数据集上的表现很有前景，但在注意力行为特征表现不佳且缺乏现实生活中的普适性方面存在挑战。", "innovation": "本文分析了一个标准化视频数据集，其中包括168名ASC患者（46%的女性）和157名非自闭症患者（46%的女性），使其成为所知最大且最平衡的数据集。文章采用多模态分析方法，结合面部表情、语音语调、头部运动、心率变异性（HRV）以及眼动行为，通过引入新的统计描述符来量化注意力角度的变化，将基于眼动的行为分类准确率从64%提高到69%，并且通过晚期融合实现了74%的分类准确率，显示了在多种行为标志物的集成中的有效性。", "conclusion": "研究结果表明，基于视频的筛查工具具有支持自闭症评估的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21380", "html_url": "https://arxiv.org/abs/2509.21380", "title": "基于内类别多样性选择单样本集合", "title_en": "Coreset selection based on Intra-class diversity", "authors": "Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor", "background": "深度学习模型已在多个领域取得重大进展，尤其是在医疗保健领域，特别是在生物医学图像分类方面。现有的研究通常采用两种不同的方法训练深度学习模型：从零开始训练和迁移学习。这两种方法都依赖于大量的数据集进行训练，导致了巨大的计算时间和资源需求。随着数据集的不断增大，对寻找解决方案的需求不断增长。一种可能的解决方案是选择数据集的子集进行训练和超参数搜索。虽然随机采样是一种简单的方法，但可能导致原始数据集代表性不足，特别是在类别不平衡的情况下。即使是类别间平衡，随机采样也可能无法捕捉到类内多样性。", "innovation": "本研究提出了一种智能、轻量级的单样本集合选择机制，旨在解决类别内多样性的问题。具体而言，提出了一种基于内类别多样性的方法，该方法将形成各个类别的簇，用于最终的采样。通过在知名的生物医学图像数据集上进行广泛的分类实验，证明了所提出的方法在多个性能指标上优于随机采样方法。", "conclusion": "本研究表明，通过引入基于内类别多样性的单样本集合选择机制，可以显著提高深度学习模型的训练效率和准确性。该方法成功解决了随机采样可能带来的代表性不足问题，并展示了其在生物医学图像分类任务中的优越性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21340", "html_url": "https://arxiv.org/abs/2509.21340", "title": "循环即一切：更多即是不同", "title_en": "Cycle is All You Need: More Is Different", "authors": "Xin Li", "background": "本文提出了一个基于信息拓扑的信息框架，其中循环闭合是记忆和意识的底层机制。记忆并非静态存储，而是重新进入神经状态空间中潜在循环的能力，不变的循环作为意义的载体，通过过滤特定顺序的噪声并保持在不同上下文中持久存在的信息来实现。因此，瞬时点提出了探索的基础，而非平凡循环编码低熵的内容不变性，稳定记忆。从生物角度来看，多时相神经群体通过STDP强化时延锁定放电实现1-循环，嵌套在theta- gamma节律中，以确保边界抵消。这些微循环通过层次复合，延伸导航环路，进入一般记忆和认知。感知-行动循环引入高级不变性：即使在感觉-行动转换中，闭合依然成立，这是将祖先归巢行为一般化。由于截面-余截面二元性，这一过程得到了形式化：截面将感知碎片粘合为全局部分，余截面将全局计划分解为动作，闭合实现了自上而下的预测与自下而上循环的对齐。因此，意识来自于在不同上下文中的高级不变性的持久性，它整合（统一性）又区别（丰富性）了这些不变。", "innovation": "本文提出了一种基于循环闭合的信息-拓扑框架，认为记忆和意识是由循环闭合机制驱动的，瞬时点和非平凡循环分别在探索和记忆稳定中发挥重要作用。生物上，多时相神经群体通过STDP实现1-循环，并嵌套在theta- gamma节律中。感知-行动循环引入了高级不变性，将祖先归巢行为一般化到了更复杂的情境中。此外，截面-余截面二元性被用来形式化这一过程，使意识通过高级不变性的持久性得以产生。", "conclusion": "最终，本文得出结论，循环是所有你需要的：持久不变性在非遍历环境中的泛化，实现了长期一致性，同时以最低的能量成本实现广泛的认知功能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21344", "html_url": "https://arxiv.org/abs/2509.21344", "title": "缓解评估安全性监控时的信息泄露", "title_en": "Towards mitigating information leakage when evaluating safety monitors", "authors": "Gerard Boxo,Aman Neelappa,Shivam Raval", "background": "白盒监控系统能够分析模型内部状态，有助于识别大型语言模型中的潜在有害行为，同时降低计算成本并整合到多层次防御系统中。然而，训练和评估这些监控工具需要能够表现出目标行为的响应示例，通常通过提示或微调获得。但这种方法面临挑战，因为用于触发行为的提示信息不可避免地会影响监测数据，从而夸大了监测的有效性。本文旨在解决这一问题，提出了一个系统化的框架来评估监控的能力，使其能够识别真实的模型行为而非表面的提示诱导效应。", "innovation": "提出了三种新型策略以评估监控的效果：内容过滤（去除与欺骗相关的内容）、评分过滤（仅汇总与任务相关的词元）以及提示精简的微调模型（模型在无需明确提示的情况下训练以展示欺骗行为）。这些策略通过在多个欺骗检测基准上的实验应用，并评估了监控性能的保留情况。结果显示：内容过滤是一个有效的缓解策略，可以降低探针的AUROC值达30%；评分过滤减少了AUROC值15%，但难以直接归因；微调模型在提高监控评估的同时，可能使监控的性能下降多达40%，即使重新训练也不例外。", "conclusion": "研究揭示了三个关键发现：内容过滤是一个有效的缓解策略；评分过滤虽然有效，但难以直接归因；微调模型可以改进监控评估，但可能显著降低性能。这些发现为减轻评估安全性监控时的信息泄漏提供了重要见解。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21349", "html_url": "https://arxiv.org/abs/2509.21349", "title": "使用非迭代时空变换器模型进行准确的台风强度预测", "title_en": "Accurate typhoon intensity forecasts using a non-iterative spatiotemporal transformer model", "authors": "Hongyu Qu,Hongxiong Xu,Lin Dong,Chunyi Xiang,Gaozhen Nie", "background": "台风强度的准确预测，尤其是在快速增强和快速减弱期间，仍然是气象预报的难题。这种高风险的预测对于灾难准备和基础设施韧性具有重大影响。尽管最近的人工智能进展在台风预测方面取得了显著进步，但现有的大多数系统在极端情况下预测效果迅速恶化，缺乏长期一致性。", "innovation": "作者引入了TIFNet模型，这是一个基于变换器的预测模型，能够生成5天的非迭代强度轨迹，该模型通过将高分辨率全球预报与历史演变融合机制结合起来。该模型通过再分析数据训练，并用运营数据进行微调，表现出在所有预报时间段内均优于运营数值模型的性能，特别是在弱、强和超强台风类别中提供持续改进。特别是在难以预测的快速强度变化阶段，TIFNet将预报误差降低了29-43%，相对于现行的运营基准线。", "conclusion": "这些结果代表了基于人工智能的台风强度预测的一个重大进展，特别是在传统模型在极端条件下表现不佳的情况下。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21342", "html_url": "https://arxiv.org/abs/2509.21342", "title": "SGNNBench: 大规模图上的突触图神经网络整体评估", "title_en": "SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph", "authors": "Huizhe Zhang,Jintang Li,Yuchang Zhu,Liang Chen,Li Kuang", "background": "图神经网络（GNNs）是专为图数据设计的深度模型，通过消息传递机制有效地捕获图拓扑，推动各种图任务性能边界。然而，随着现实世界中图数据的爆炸性增长，复杂建模方式对大规模图的计算和时间开销变得不可持续，急需开发能应对这些挑战的更节能的GNNs。在这样的背景下，突触图神经网络（SGNNs）作为基于生物启发的学习机制出现，采用独特的基于脉冲的神经元，通过稀疏和二进制脉冲促进中间图表示的计算和存储。尽管近年来提出许多SGNNs，但没有系统性的基准来探讨这些脑启发网络的基本设计原则对图数据的效果。因此，为了填补这个空白，本文提出了SGNNBench，全面量化了SGNNs领域的进展，从有效性和能源效率及架构设计三个方面对多项内容进行了深入研究，并全面评估了9种最先进的SGNNs在18个数据集上的表现，揭示了SGNNs常常被忽视的能源瓶颈，同时探索了SGNNs的设计空间，推动了通用SGNN范式的发展。", "innovation": "提出了SGNNBench作为首个系统性的基准工具，全面评估了各类突触图神经网络的效能、能源效率和架构设计，并深入探究了该领域的设计空间。这不仅填补了该领域现有的评估空缺，还为SGNNs进一步研究和发展提供了基础", "conclusion": "通过对9种最先进的SGNNs在18个数据集上的全面评估和设计空间的深入调查，SGNNBench揭示了SGNNs在实际应用中的效能、能源效率和架构设计特点，推进了SGNNs的广泛应用和发展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21371", "html_url": "https://arxiv.org/abs/2509.21371", "title": "ReGeS: 为对话推荐系统实现检索与生成的交互协同", "title_en": "ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems", "authors": "Dayu Yang,Hui Fang", "background": "对于对话推荐系统(CRS)，正确理解用户偏好关键在于将对话与外部领域知识连接起来。现有的解决方案要么需要针对特定领域的工程工作，限制了灵活性；要么依赖大型语言模型，增加了幻觉的风险。尽管检索增强生成(RAG)模型有潜力，但在CRS中的简单应用受到嘈杂对话削弱检索效果和未能区分相似物品的细微差异的阻碍。", "innovation": "本文提出了一种称为ReGeS的双向检索与生成协同框架，它结合了生成增强检索和检索增强生成，以提炼对话中的有用用户意图，并区分细微的物品特征，从而避免了额外标注，减少了幻觉，简化了持续更新。实验表明，ReGeS在推荐准确度方面达到了最佳表现，验证了这种相互协同对于知识密集型CRS任务的有效性。", "conclusion": "ReGeS框架通过双向检索与生成协同，提高了对话推荐系统的准确性和灵活性，有效解决了现有方法的局限性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21341", "html_url": "https://arxiv.org/abs/2509.21341", "title": "从嵌入到方程：基于遗传编程的可解释Transformer分类近似模型", "title_en": "From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification", "authors": "Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi", "background": "研究者们一直在探索如何利用符号近似模型从 Transformer 模型的嵌入中提取可解释性强且紧凑的分类器。本文的目标是获得具有校准概率的紧凑、可审计的分类器。为此，研究者对 ModernBERT、DINOv2 和 SigLIP 的嵌入在训练集上进行了分割，通过语义保留特征分割（SPFP）方法将嵌入分割为互不相交的信息保留视图。然后，使用合作多群体遗传程序（MEGP）学习这些视图上的加性闭形式逻辑程序。研究者报告了不同数据集上模型的性能指标，包括 F1、AUC、log-loss、Brier、期望校准误差（ECE）和符号复杂度。最终模型的选择基于验证 F1 的标准误差规则，若部分情况相同，则以最简原则选择模型。验证集上拟合的温度调整（Temperature Scaling）方法大幅降低了测试集上的 ECE。这些符号近似模型在MNIST、CIFAR10 和 MSC17 上实现的 F1 值可达0.99，而在 SST2G上的 F1 值约为0.95，20NG 数据集仍然是最具挑战性的。研究者还提供了一些说明性统计和图示，以展示模型的可靠性及其解释性。", "innovation": "本文通过利用遗传编程技术，并结合语义保留特征分割的方法，将 Transformer 模型的嵌入转换为紧凑且可解释的逻辑程序模型。这种方法能够在保持模型性能的同时实现模型的可解释性，并且能够在多个基准数据集上实现优异的表现。特别值得一提的是，通过验证集上拟合温度调整方法，可以在测试集上显著降低模型的期望校准误差（ECE）。此外，对于复杂的数据集，这种符号近似模型仍能提供强分类能力。", "conclusion": "本文通过将 Transformer 模型的嵌入转化成逻辑程序模型，实现了在保持高性能的同时增加模型的可解释性。通过语义保留特征分割（SPFP）和合作多群体遗传编程（MEGP），模型可以在多个数据集上实现非常高的 F1 值，并且在某些数据集上显著降低了分类误差。虽然对于 20NG 数据集这类复杂的分类任务仍具有一定挑战，但该方法仍展示了其在其他多种数据集上的潜力。该方法通过提供象征性的复杂度评估和解释模型的训练和测试性能，增加模型的可审计性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21362", "html_url": "https://arxiv.org/abs/2509.21362", "title": "基于数据驱动的方法设计三价超重元素螯合剂", "title_en": "Data-driven approach to the design of complexing agents for trivalent transuranium elements", "authors": "Kirill V. Karpov,Ivan S. Pikulin,Grigory V. Bokov,Artem A. Mitrofanov", "background": "超重元素的络合物因其在化学领域的广泛应用而成为研究热点，但由于其稀有性、高昂的成本以及处理此类元素所需的特殊条件，实验研究的复杂性很高。此外，量子化学计算的复杂性限制了其在大型系统中的应用能力。这些因素阻碍了对超重元素络合物的深入研究和发展。", "innovation": "采用现代机器学习方法建立了一种新型神经网络架构，能够使用有限的实验数据构建预测模型，显著提高模型质量。该方法克服了超重元素络合物研究中的一些难题，提供了设计三价超重元素螯合剂的新途径。通过描述模型的应用范围并识别影响络合物稳定性的关键分子片段，该模型提高了预测准确性和实用性。", "conclusion": "通过机器学习的方法成功预测了超重元素的络合物性质，不仅提高了模型的预测准确度，还明确了关键的分子片段及其对络合物稳定性的贡献。该研究为超重元素络合物的合理设计和进一步研究提供了有力支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21423", "html_url": "https://arxiv.org/abs/2509.21423", "title": "线性非高斯循环模型中的近最优实验设计", "title_en": "Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models", "authors": "Ehsan Sharifian,Saber Salehkaleybar,Negar Kiyavash", "background": "现有的研究发现，仅仅利用观察数据可以识别因果图，但仅限于置换等价类。本文探讨了通过结合观察数据和干预数据学习线性非高斯结构方程模型中的因果结构，特别是当模型包含循环时的情况。", "innovation": "本文通过证明等价类中的每个图对应于二分图中的一个完美匹配，给出了这些等价类的组合特征。具体地，本文说明了每个原子干预揭示了一个真实匹配的边并消除了所有不兼容的因果图。基于此，本文将最优实验设计任务形式化为在等价类集合上具有自然奖励函数的自适应随机优化问题，展示了奖励函数的适应次模性和提出了一个有可证明的近最优性能保障的贪婪策略。此外，本文还提出了一种基于随机匹配的估计器来高效估计奖励函数。", "conclusion": "模拟结果表明，根据本文提出的随机优化框架执行少量干预可以恢复真实的潜在因果结构。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21459", "html_url": "https://arxiv.org/abs/2509.21459", "title": "使用RLVR的一种领先SQL推理模型", "title_en": "A State-of-the-Art SQL Reasoning Model using RLVR", "authors": "Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang", "background": "使用强化学习（RL）开发定制推理模型，以结合组织特定知识，有潜力解决企业客户的诸多问题。RL的一个特殊设置是带有可验证奖励的RL（RLVR），在许多问题中奖励函数可以验证。研究者将RLVR应用于一个流行的机器学习基准BIRD，该基准测试了AI代理将自然语言查询转换为数据库的SQL执行的能力。", "innovation": "研究者提出了一种简单的且通用的训练方法，包括精细选择提示和模型，使用脱机RL方法TAO进行预热训练，然后进行严谨的在线RLVR训练。仅使用BIRD训练集作为训练数据，不使用专有模型，他们的第一个提交在BIRD排行榜上达到了最先进的准确率：未使用自一致性时为73.56%，使用自一致性时为75.68%，且生成的过程优于第二种方法。尽管BIRD只是一个代理任务，但研究者框架的简单性使其可以广泛应用于企业领域如商业智能、数据科学和编程。", "conclusion": "这种方法简单而通用，适用于解决企业领域中的问题，如商业智能、数据科学和编程，尽管BIRD只是一个代理任务，但证明了该方法在这些领域的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21399", "html_url": "https://arxiv.org/abs/2509.21399", "title": "使用单张图像超分辨率技术将气候预测数据下放至1公里分辨率", "title_en": "Downscaling climate projections to 1 km with single-image super resolution", "authors": "Petr Košťál,Pavel Kordík,Ondřej Podsztavek", "background": "高分辨率的气候预测对于地方决策至关重要，但当前可用的气候预测数据空间分辨率较低（例如12.5公里），限制了其应用。本文通过利用单图像超分辨率模型对气候预测进行统计下放至1公里分辨率，以解决这一限制。由于缺乏高分辨率的气候预测数据用于训练，本文通过在高分辨率观测网格数据集上训练模型并应用于低分辨率气候预测数据，来实现这一点。", "innovation": "本文创新性地提出了使用单图像超分辨率模型对气候预测进行统计下放的方法，并且验证了这种方法在不增加气候指标误差的情况下，能够提供1公里分辨率的高分辨率气候预测数据。同时，文中提出了一种基于气候指标的评估方法，用于评估下放后的气候预测数据，而无需依赖真实高分辨率的气候数据。", "conclusion": "实验表明，使用单图像超分辨率模型对日平均温度进行下放能够保持气候指标的准确性，证明了该方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21463", "html_url": "https://arxiv.org/abs/2509.21463", "title": "增强型生成机器听觉器", "title_en": "Enhanced Generative Machine Listener", "authors": "Vishnu Raj,Gouthaman KV,Shiv Gehlot,Lars Villemoes,Arijit Biswas", "background": "本文介绍了一种名为GMLv2的参考模型，用于预测MUSHRA评分等的主观音频质量。相比之前的版本，GMLv2引入了基于Beta分布的损失函数以更准确地模拟听音者的评分，并增加了额外的神经音频编码(NAC)主观数据集，使其具有更广泛的适用性和更强大的泛化能力。", "innovation": "GMLv2引入了基于Beta分布的损失函数来更好地模拟听音者评分，并且结合了更多的NAC主观数据集，增强了模型的泛化能力与适应性。", "conclusion": "GMLv2在广泛的测试集上证明了其在主观评分和预测多样性内容类型及编解码器配置下的评分方面的优越性能，相较于广泛使用的PEAQ和ViSQOL等指标，GMLv2提供了更强大且自动化的听觉质量评估框架，有望加速现代音频编码技术的研究与发展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21385", "html_url": "https://arxiv.org/abs/2509.21385", "title": "通过移除和重新训练调试概念瓶颈模型", "title_en": "Debugging Concept Bottleneck Models through Removal and Retraining", "authors": "Eric Enouen,Sainyam Galhotra", "background": "概念瓶颈模型（CBMs）利用一组由人类可解释的概念来预测最终任务标签，这使得领域专家不仅能验证CBM的预测，还可以在测试时干预错误的概念。然而，这些干预无法解决CBM与专家推理之间的系统性偏差，例如当模型从带有偏见的数据中学习捷径时。为了应对这一问题，该研究提出了一种通用的概念瓶颈模型可解释调试框架，该框架遵循移除和重新训练的两步过程。在移除步骤中，专家使用概念解释来识别并移除任何不需要的概念。在重新训练步骤中，该研究引入了CBDebug方法，利用CBMs的可解释性作为桥梁，将概念层面的用户反馈转换成样本级别的辅助标签。这些标签被用于应用监督偏置缓解和目标扩展，减少模型对不需要的概念的依赖性。该方法在多个CBM架构（PIP-Net、事后CBM）和基准测试中进行了评估，证实了CBDebug相比之前的重新训练方法具有显著优势，特别是在涉及已知伪相关问题的标准上表现更为出色。", "innovation": "该研究提出了一种通用的可解释调试框架，通过移除不需要的概念并重新训练模型来解决概念瓶颈模型的系统性偏差问题。特别是引入了CBDebug方法，该方法利用概念瓶颈模型的可解释性，将概念层面的用户反馈转化为样本级别的辅助标签，用于监督偏置缓解和目标扩展，从而减少模型对不需要的概念的依赖性。", "conclusion": "研究的框架在多个CBM架构和基准测试中表现出色，证实了CBDebug方法比现有的重新训练方法具有显著优越性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21383", "html_url": "https://arxiv.org/abs/2509.21383", "title": "LongiMam模型用于使用随访乳腺X线摄影提高乳腺癌风险预测", "title_en": "The LongiMam model for improved breast cancer risk prediction using longitudinal mammograms", "authors": "Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau", "background": "乳腺癌筛查需要稳健的模型来利用纵向影像数据。目前大多数深度学习模型仅使用单张或有限的前次乳腺X光片，并且在现实世界中缺乏适应能力，这些现实世界的特点包括结果分布不平衡和随访多样化。", "innovation": "开发了LongiMam模型，这是一个端到端的深度学习模型，可以整合当前和最多四张前次乳腺X光片。LongiMam结合了卷积神经网络和递归神经网络来捕捉预测乳腺癌的空间和时间模式。模型使用一个典型的临床筛查数据集进行训练和评估，该数据集具有案件与对照比例不平等的特点。结果显示，在不同的场景中，随着前次乳腺X光片增加，LongiMam的预测能力持续提升。加入前次和当前访视比单次访视模型表现更好，但仅有前次访视的表现则较差，这强调了结合历史和近期信息的重要性。此外，模型在包括乳房密度高、55岁及以上妇女等关键风险组中表现有效，并且在观察到乳房密度变化的妇女中表现最佳。这些发现表明纵向建模可提升乳腺癌预测，支持在筛查计划中使用重复乳腺X光片来细化风险分层。LongiMam作为开源软件公开。", "conclusion": "纵向建模增强了乳腺癌预测，并支持在筛查计划中使用重复乳腺X光片以准确评估风险。LongiMam模型可公开获取作为开源软件。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21387", "html_url": "https://arxiv.org/abs/2509.21387", "title": "Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence", "title_en": "Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence", "authors": "Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi", "background": "已有研究表明，深度神经网络可以在保持性能的同时进行大量剪枝，但是剪枝如何影响模型的可解释性还不清楚。在这项工作中，研究人员探讨了基于幅度的剪枝后精调对低层次的显著性图和高层次的概念表示的影响。研究使用了在ImageNette数据集上训练的ResNet-18模型，对比了Vanilla Gradients (VG) 和 Integrated Gradients (IG) 后处理解释在不同剪枝水平下的差异，评估了稀疏性和忠实性。研究人员还应用了CRAFT方法来追踪学习概念的语义连贯性变化。研究结果表明，适度的剪枝可以提高显著性图的聚焦性和忠实性，同时保持distinct且语义上有意义的概念。相比之下，过度剪枝会将异构特征合并，减少显著性图的稀疏性和概念的连贯性，尽管保持了准确性。这些发现表明，虽然剪枝可以塑造内部表征以更接近人类关注的模式，但过度剪枝会削弱模型的可解释性。", "innovation": "研究通过实验对比了不同剪枝水平下不同解释方法的效果，进一步使用CRAFT方法追踪了内部概念表示的变化，从而探讨了剪枝对模型可解释性的影响机制。这是通过对ResNet-18网络在ImageNette数据集上的具体分析而进行的新颖研究。", "conclusion": "适度的剪枝可以改善显著性图的聚焦性和忠实性，保持内部概念的独特性和语义连贯性。然而，过度剪枝会导致内部特征的合并，损害模型的可解释性，虽然可能保持性能。这些结果表明，尽管剪枝可以引导内部表征更接近人类的关注模式，但过度剪枝破坏了模型的可解释性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21482", "html_url": "https://arxiv.org/abs/2509.21482", "title": "使用混合令牌学习推理", "title_en": "Learning to Reason with Mixture of Tokens", "authors": "Adit Jain,Brendan Rappazzo", "background": "强化学习结合可验证奖励（RLVR）已成为提高大型语言模型（LLM）推理能力的主要方法。大多数当前方法都是Group Relative Policy Optimization的变种，通过采样多个推理完成方案来相对评分并调整策略，但这些方法在每个推理步骤中都只采样离散的令牌，忽略了模型对候选令牌概率分布中的丰富信息。虽然在非RL设置中保留和利用这些分布性信息已被证明是有益的，但当前的RLVR方法似乎通过不利用这些信息而无意中缩小了推理搜索空间。", "innovation": "我们研究了在RLVR中使用令牌混合生成（MoT-G）的方法。我们提出了一种统一框架，该框架泛化了现有的MoT-G方法，包括现有的一些无需训练的方法，它们通过令牌嵌入的加权和来构建混合嵌入，并将RLVR扩展到直接在连续的混合空间中生成思维过程链。通过在Reasoning-Gym（一个推理密集的语言任务套件）上评估两种MoT-G变体，我们发现MoT--G方法在大多数任务中取得了显著改进（7个任务中有5个任务提高了5%-35%），同时随着模型Qwen2.5-1.5B的路径数量减半，精度仍然相当，表明训练效率得到了提高。通过全面的隐藏状态和令牌级分析，我们提供了证据，表明MoT-G的益处可能源于其在整个推理过程中保持更高隐藏状态熵的能力以及在令牌空间中促进探索的能力。", "conclusion": "MoT-G方法在推理密集的语言任务中表现出色，可以显著提高推理效率，同时保持或在较少路径情况下获得相同精度。这些结果表明，使用令牌混合生成方法可以在现有的RL设置下改进推理过程，从而提高训练效率。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21497", "html_url": "https://arxiv.org/abs/2509.21497", "title": "功能加密在安全神经网络训练中的数据泄露与实际缓解措施", "title_en": "Functional Encryption in Secure Neural Network Training: Data Leakage and Practical Mitigations", "authors": "Alexandru Ioniţă,Andreea Ioniţă", "background": "随着人工智能的关注度不断上升，机器学习即服务提供云基础设施以方便模型的训练、测试和部署。然而，这类系统存在重大隐私问题：上传敏感数据到云，尤其是在训练阶段。因此，如何实现安全的神经网络训练成为了研究人员关注的焦点。现有的一些解决方案围绕功能加密（FE）这一核心展开，尽管这些方案很有趣且提供了加密数据上的新视角，但仍有一些漏洞未被考虑。我们的论文针对使用FE进行加密数据的安全神经网络训练提出了一种攻击，并使用线性规划重构了原始输入，揭示了之前的安全承诺。为了应对这一攻击，我们提出了两种在计算过程中将客户纳入考虑的安全训练和推理解决方案，一种方案确保了安全，不依赖于加密，另一种则使用了隐藏内部乘积的功能。", "innovation": "在功能加密用于安全神经网络训练的问题上，论文首先揭示了一种利用FE进行加密数据的安全神经网络训练的攻击，并使用线性规划重构了原始输入。更重要的是，论文提出了解决这一攻击的两种方法：一种方案确保了安全不依赖于加密，另一种使用了隐藏内部乘积的功能。", "conclusion": "我们的研究展示了功能加密在神经网络训练中的局限性，并提出了实用的缓解措施来防范由此带来的数据泄露问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21433", "html_url": "https://arxiv.org/abs/2509.21433", "title": "DyME: 动态多概念擦除在扩散模型中的Bi-Level正交LoRA适应", "title_en": "DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation", "authors": "Jiaqi Liu,Lan Zhang,Xiaoyong Yuan", "background": "文本到图像的扩散模型(DMs)无意中再现了受版权保护的风格和受保护的视觉概念，这引发了法律和伦理方面的担忧。概念擦除已经出现作为安全措施，旨在通过微调有选择地抑制这些概念。然而，现有的方法无法应对现实中提供者必须同时擦除多个可能相冲突的概念的情景。核心瓶颈在于它们依赖于静态擦除：每个微调检查点会尝试一次性清除所有目标概念，而不管具体推理中实际的擦除需求。这一封闭式设计与真实世界中的使用不符，因为每次生成时请求会各不相同，导致擦除成功率降低，非目标内容的保真度也受到影响。", "innovation": "我们提出了一种名为DyME（Dynamic Multi-Concept Erasure）的需求响应擦除框架。该框架通过训练轻量级的概念特定LoRA适配器，并仅在推理时动态组成所需的部分，实现了模块化的多概念擦除。为了消除适配器之间的干扰，特别是在需要抑制多个或语义相关概念时，我们引入了特征和参数级别的双层正交约束，分解了表示转换并强制适应器子空间正交。进一步构建了带有品牌系列角色层次结构的新的ErasureBench-H基准测试，统一了不同语义粒度和擦除集大小的准则评估。", "conclusion": "在ErasureBench-H基准测试和标准数据集（如CIFAR-100、Imagenette）上的实验表明，DyME 一贯地优于最新的基线方法，实现了更高的多概念擦除保真度，同时最小化了对非目标内容的附带降级。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21434", "html_url": "https://arxiv.org/abs/2509.21434", "title": "高能物理中的基础模型", "title_en": "Foundation models for high-energy physics", "authors": "Anna Hallin", "background": "基础模型，即大规模的预训练机器学习模型，能够被调整以适应各种任务，已经在自然语言处理和计算机视觉领域引发了革命性的变化。在高能物理领域，研究人员开始探讨是否可以直接在物理研究中采用这些模型，甚至是专门为粒子物理数据构建和定制这些模型，这一问题日益受到关注。因此，这篇综述文章成为了这一主题的第一个研究综述，旨在总结和讨论迄今为止该领域发表的研究成果.", "innovation": "这篇文章是首个专门讨论高能物理中基础模型应用的研究综述，它旨在汇集和讨论相关领域的研究进展。它为该领域提供了新的见解和可能性，为未来的研究和应用提供了指导.", "conclusion": "该综述总结了高能物理中基础模型研究的现状和趋势，并指出基础模型在高能物理领域的潜力及其能够为粒子物理研究带来的变革。同时，文章也指出了当前存在的挑战和未来的研究方向潜力."}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21554", "html_url": "https://arxiv.org/abs/2509.21554", "title": "非洲口音英语的域感知会议分割", "title_en": "Domain-Aware Speaker Diarization On African-Accented English", "authors": "Chibuzor Okocha,Kelechi Ezema,Christan Grant", "background": "本研究旨在探讨博克口音对英语会议分割的影响。研究者评估了多个生产系统和开源系统在通用对话和临床对话中的表现，均在严格的覆盖得分协议下进行评估，发现临床对话存在一致的领域惩罚，并且模型之间差异显著。错误分析表明，大部分差异是由于假警报和漏检造成的，尤其是短对话和频繁重叠的部分。", "innovation": "研究贡献包括创建了一个跨领域的受控基准，提供了简洁的错误分解和会话水平分析的方法，并提供了一种容易复制的域适应食谱。这些方法有助于提高会议分割的准确性。", "conclusion": "本研究表明，临床对话存在显著的领域惩罚，通过细化调整一些区域适配方法虽然可以减少但还不能消除差距。研究建议未来的改进方向包括注意覆盖分割和平衡临床资源。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21572", "html_url": "https://arxiv.org/abs/2509.21572", "title": "快速SBL的通用修剪准则", "title_en": "General Pruning Criteria for Fast SBL", "authors": "Jakob Möderl,Erik Leitinger,Bernard Henri Fleury", "background": "稀疏贝叶斯学习（SBL）通过假设每个权重服从零均值、以相关超参数为逆方差的高斯分布来关联模型中的每个权重和一个超参数。该方法通过边缘化权重并进行边缘化最大似然（ML）估计来估算超参数。SBL返回大量的超参数估计值趋向无穷大，实际上将对应权重的估计值设为零（即，从模型中修剪对应权重），从而获得权重向量的稀疏估计。", "innovation": "本文分析了在减弱了噪声样本和权重分布的高斯假设的情况下，单一超参数的边际似然函数。通过推导出足以导致有限超参数估计和无限超参数估计的充分条件，提供了对快速SBL（F-SBL）修剪条件的附加见解。", "conclusion": "在高斯情况下，两个条件是互补的，并与快速SBL的修剪条件一致，从而为该算法提供额外的见解。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21535", "html_url": "https://arxiv.org/abs/2509.21535", "title": "Agribot: 农业专用问答系统", "title_en": "Agribot: agriculture-specific question answer system", "authors": "Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari", "background": "印度是一个农业基础型经济，正确了解农业实践信息对于实现农业最优增长至关重要。为了帮助农民解答相关问题，我们基于Kisan Call Center的数据集构建了一个农业聊天机器人。该系统能够回答与天气、市场价格、植物保护和政府计划相关的问题，可24小时在线，并且任何电子设备都可以访问。该系统采用了一种句子嵌入模型，准确率为56%。通过消除同义词并结合实体提取技术，准确率提升至86%。", "innovation": "该系统采用了一种句子嵌入模型，通过消除同义词并结合实体提取技术，准确率提升至86%，显著提高了系统的回答准确率。", "conclusion": "该农业聊天机器人系统为农民提供了易于理解的农业相关实践信息，有助于提高农业产出。同时，也能减轻呼叫中心员工的工作负担，使他们的工作方向更加有效。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21600", "html_url": "https://arxiv.org/abs/2509.21600", "title": "从多模态数据进行自动且可解释的生存分析", "title_en": "Automated and Interpretable Survival Analysis from Multimodal Data", "authors": "Mafalda Malafaia,Peter A.N. Bosman,Coen Rasch,Tanja Alderliesten", "background": "在肿瘤学中，准确且可解释的生存分析仍然是核心挑战。随着多模态数据的增长以及对透明模型的临床需求以支持验证和建立信任，这一挑战变得更加复杂。", "innovation": "提议了一种基于MultiFIX的可解释多模态AI框架，通过结合临床变量和计算机断层扫描影像自动化生存分析。该框架使用深度学习推断生存相关特征，进一步通过Grad-CAM解释影像特征，并通过遗传编程建模临床变量为符号表达式。风险估计运用透明的Cox回归方法，实现生存结果分层。", "conclusion": "在开源RADCURE头颈癌数据集上，MultiFIX达到了C指数（预测）0.838和C指数（分层）0.826，优于临床和学术基准方法，并与已知预后标记物保持一致。这些结果表明，MultiFIX为精准肿瘤学中的可解释多模态AI具有巨大潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21565", "html_url": "https://arxiv.org/abs/2509.21565", "title": "无需对齐生成：在扩散模型中学习线性可分表示", "title_en": "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models", "authors": "Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya", "background": "大规模扩散模型的高效训练策略越来越强调改进这些模型中的区分特征表示。现有研究集中在使用强大外部编码器获得的特征进行表示对齐，以评估线性探针，从而改进表示质量。然而，依赖大规模预训练编码器的方法计算成本高昂。", "innovation": "提出了基于促进中间层表示线性可分性的替代正则化方法，不依赖外部编码器和表示对齐，而是将线性探针直接融入网络的学习动态中，从而明显提高训练效率和生成质量，在SiTs等流形变压器架构上实现了1.46的FID分值。", "conclusion": "该方法显著提高了在256x256 ImageNet数据集上流形变压器架构的训练效率和生成质量，且不需依赖大型预训练编码器，直接将线性探针融入网络学习过程中。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21553", "html_url": "https://arxiv.org/abs/2509.21553", "title": "AutoClimDS:气候数据科学赋权型AI——所需知识图谱即为此一切", "title_en": "AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need", "authors": "Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng", "background": "气候数据科学面临着由于数据来源分散、数据格式各异以及对识别、获取和处理数据集所需的技术熟练度较高的障碍。这些挑战限制了参与度，延缓了发现过程，并降低了科学工作流程的可再现性。", "innovation": "本文介绍了一种通过集成一个经过精选的知识图谱(KG)和基于云的科学工作流程设计的AI代理解决这些障碍的原型方法。知识图谱提供了一个统一的层来组织数据集、工具和工作流程，而由生成式AI驱动的AI代理能够实现自然语言交互、自动化数据访问和简化分析。这些组件共同大幅降低了参与气候数据科学的技术门槛，使非专家用户能够识别并分析相关数据集。通过利用现有的云就绪API数据门户，表明“知识图谱即一切”能够解锁可扩展的、自主的工作流程，用于科学研究。开源系统设计进一步促进了社区贡献，确保KG及其相关工具能够进化成为一个共享的公共资源。实验结果表明一条通往促进气候数据的可访问性并建立人类-AI协作的可再现、可扩展框架的道路。", "conclusion": "本文提出了通过知识图谱和基于云的AI代理集成来解决气候数据科学中的核心障碍，大幅降低了技术门槛，提高了数据的可再生性和协作性，为非专业人士提供了新的分析工具。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21584", "html_url": "https://arxiv.org/abs/2509.21584", "title": "IndiSeek学习信息导向的解耦表示", "title_en": "IndiSeek learns information-guided disentangled representations", "authors": "Yu Gui,Cong Ma,Zongming Ma", "background": "在多模态学习中，学习解耦表示是一个基本任务。特别是在单细胞多组学分析等现代应用中，共享特征和模态特定特征对于刻画细胞状态及其支持后续分析至关重要。理想的模态特定特征不应依赖于共享特征，同时应全面捕捉每个模态内的互补信息。这种权衡可以通过信息理论标准自然表达，但基于互信息的目标难以可靠估计，而它们的变分替代方案在实践中通常表现不佳。", "innovation": "我们提出了IndiSeek，一种新颖的解耦表示学习方法，通过结合一个独立性增强的目标与计算高效的重构损失，后者可以边界条件互信息。该形式化模型明确平衡独立性和完整性，能够原理性地提取模态特定特征。", "conclusion": "我们在合成模拟、CITE-seq数据集以及多个真实的多模态基准上证明了IndiSeek的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21567", "html_url": "https://arxiv.org/abs/2509.21567", "title": "基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索", "title_en": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks", "authors": "Mohammad Parsa Afshar,Aryan Azimi", "background": "消费者行为预测是市场营销、认知神经科学和人机交互领域的重要目标。脑电图（EEG）的电生理活动信息能够揭示大脑决策过程，因此通过EEG数据预测消费者行为显得尤为重要。本研究采用图神经网络（GNN）和其他经典机器学习模型进行比较研究，旨在探究这些算法在消费者行为预测中的应用效果和改进空间。", "innovation": "研究利用图神经网络和经典机器学习模型对EEG数据进行处理和特征提取，通过不同的网络架构和模型构建方式进行比较分析，特别是将较少被研究的图神经网络引入到基于EEG的神经市场营销中。研究表明，尽管总体结果不显著，但在某些基本指标上，图神经网络模型性能更佳，对于较为传统的模型提出了挑战和改进机会。", "conclusion": "研究不仅证实了结合EEG信号分析与机器学习模型可以加深对消费者行为的理解，还提供了一种全面比较广泛使用的和支持较为不足的机器学习模型（如支持向量机SVM和图神经网络）的方法。研究结果表明，通过新的模型和方法，能够更深入地理解和预测消费者行为。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21613", "html_url": "https://arxiv.org/abs/2509.21613", "title": "大型语言模型优化中的多目标强化学习：前瞻性视角", "title_en": "Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective", "authors": "Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers", "background": "多目标强化学习（MORL）在大型语言模型（LLMs）中优化多个目标时面临着显著的挑战和机遇。本文探讨了MORL方法在LLM优化中的优势和局限性，突出了LLMs和强化学习（RL）固有的复杂性以及个性化功能的需求。", "innovation": "本文引入了MORL分类法，并提出了一种MORL基准框架，该框架能够评估不同方法对不同目标关系的影响。此外，还提出了通过双层学习范式改进效率和灵活性的元策略MORL的发展方向，指出了关键的研究问题和潜在解决方案。", "conclusion": "未来的研究方向应集中在通过双层学习范式改进效率和灵活性的元策略MORL的发展上，并明确关键的研究问题和潜在解决方案来提高LLM性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21490", "html_url": "https://arxiv.org/abs/2509.21490", "title": "使用多模型机器学习和AODV回退的蓝牙网格网络上下文感知混合路由", "title_en": "Context-Aware Hybrid Routing in Bluetooth Mesh Networks Using Multi-Model Machine Learning and AODV Fallback", "authors": "Md Sajid Islam,Tanvir Hasan", "background": "蓝牙基线网格网络提供了在紧急和资源受限场景下进行离线通信的潜在基础设施。然而，传统的路由策略，如Ad hoc On-Demand Distance Vector（AODV），在拥堵和动态拓扑变化等情况下往往会失效。这些因素使得在这些场景下找到可靠的路由策略变得至关重要。传统的AODV无法有效应对网络中的各种约束条件。为了改善这些问题，研究提出了一种结合了监督机器学习的混合智能路由框架来辅助AODV，以提高在网络动态变化下的路由选择效率，特别是在存在多种网络约束条件的情况下。该框架利用了预测模型，包括交付成功率分类器、TTL回归器、延迟回归器和转发器适用性分类器，将这些预测模型综合到动态邻居评分机制中，在多跳消息传输过程中提高选择邻居的灵活性。该研究还提出了一个包含静态节点部署、缓冲区限制和设备异构性仿真环境以评估不同策略的表现，包括基础AODV、部分混合模型（ABC）以及完整的混合模型（ABCD）的性能。研究结果显示，完整的混合ML模型ABCD在所有测试场景下实现了近99.97%的分组传输成功率，显著优于基本和中间模型。这证明了轻量级、可解释的机器学习模型可以增强蓝牙网格网络的路由可靠性和适应性，在无基础设施环境中尤其强调成功交付优先于低延迟约束的优点。", "innovation": "该研究提出了结合监督机器学习的混合智能路由框架，以改善传统路由策略的不足，尤其是在存在多种网络配置情况下的路由性能问题。此方法将AODV路由协议与四种不同预测模型相结合，形成一种动态评分机制，使用该机制可以在多跳传输过程中更灵活地选择路由。结果表明，这种新的路线选择方法显著提高了路由的可靠性和适应性，特别是在基于蓝牙的环境中。研究还特别强调在无基础设施环境中的应用，这里成功传递的重要性远高于低延迟的需求。", "conclusion": "该研究展示了基于多模型机器学习和AODV回退的混合智能路由方法在蓝牙网格网络中的有效性和优势。这项方法通过使用高可信度的预测模型来改进路径选择，有效地增强了路由的可靠性和灵活性，特别是在紧急和资源受限场景中。在未来的工作中，研究团队可以探索更多的预测模型以及进一步优化此框架使其在更复杂和动态的网络环境下表现更佳。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21614", "html_url": "https://arxiv.org/abs/2509.21614", "title": "适应性SGD的有效连续方程：一种随机分析视角", "title_en": "Effective continuous equations for adaptive SGD: a stochastic analysis view", "authors": "Luca Callisti,Marco Romito,Francesco Triggiano", "background": "本文分析了一些流行的自适应随机梯度下降（SGD）方法在学习率较小情况下的理论特性。通过使用李等人引入的随机修改方程框架，推导出这些方法的有效连续随机动力学。该研究旨在通过观察和推导表明，SGD中的采样诱导噪声在极限情况下表现为独立的布朗运动，驱动参数和梯度二次动量的演化。", "innovation": "研究的关键贡献在于，通过随机修改方程框架，推导出适应性SGD方法的有效连续动态。同时，该研究扩展了马拉迪等人的方法，探讨了学习率与适应性方法中的关键超参数之间的缩放规则，描述了所有非平凡极限动力学。", "conclusion": "该研究为理解和优化自适应SGD方法提供了新的理论基础，可以帮助更好地理解其在训练过程中的行为。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21592", "html_url": "https://arxiv.org/abs/2509.21592", "title": "接下来会发生什么？通过生成点轨迹来预测未来运动", "title_en": "What Happens Next? Anticipating Future Motion by Generating Point Trajectories", "authors": "Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi", "background": "本文考虑了从单张图像预测物体运动的问题，没有观察到诸如物体速度或施加的力等因素。传统的回归模型和生成器难以准确预测场景中的复杂运动。现代视频生成器虽然能更好地捕捉场景中的动态，但在处理从单张图像预测运动的任务上表现不佳，尤其是在简单的物理场景中。本文提出了一种新的方法，通过生成密集的轨迹网格来预测物体动态，这种方法能够捕捉场景的整体动态和不确定性，提供比传统回归和生成器更准确和多样的预测结果。", "innovation": "本文的主要创新点在于将现代视频生成器的架构应用于运动预测问题中，具体表现为生成密集的轨迹网格，而不是生成像素。这种方法在模拟数据上进行了广泛评估，并证明了其在机器人等下游应用中的有效性。此外，文章还探讨了为何近期最先进的视频生成器在处理单张图像预测运动任务上表现不佳，并指出这是由于生成像素的负担而非直接建模运动所造成的局限性。", "conclusion": "本文通过生成点轨迹的方法来预测未来运动，这种方法不仅能够捕捉整个场景的动态和不确定性，还能提供比传统方法更准确和多样化的预测结果。虽然一些现代视频生成器在其他任务上表现出色，但在预测从单张图像出发的物体运动方面仍然存在局限性。未来的研究可以从优化生成器以直接建模运动的角度入手，进一步提高预测精度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21634", "html_url": "https://arxiv.org/abs/2509.21634", "title": "MobiLLM：6G Open RAN中闭环威胁缓解的代理AI框架", "title_en": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs", "authors": "Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin", "background": "Open Radio Access Network (O-RAN) 是一种开放和互操作的架构，能够跨公共电信和私有企业领域实现智能、模块化的应用。尽管开放的架构带来了前所未有的创新机会，但也扩大了攻击面，因此需要具有高弹性和低成本的自主安全解决方案。传统的防御措施主要依赖于被动威胁检测，不仅反应慢、劳动密集型，而且不适合下一代系统的规模和复杂性。", "innovation": "本文提出了一个代理AI框架 MobiLLM，用于6G O-RAN环境中的端到端、全自动的威胁缓解。该框架通过大型语言模型（LLMs）为模块化的多代理系统提供安全工作流程的编排。MobiLLM 包含了威胁分析代理、威胁分类代理和威胁响应代理。这些代理分别实现了实时数据分析、异常归类到具体对策及通过 O-RAN 控制接口安全地执行缓解行动。该框架基于 MITRE FiGHT 框架和 3GPP 规范，配备了一系列安全护栏。", "conclusion": "初步评估证明，MobiLLM 能够有效识别和协调复杂缓解策略，大幅降低响应延迟，从而展示了在6G中实现自主安全运营的可行性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21653", "html_url": "https://arxiv.org/abs/2509.21653", "title": "基于后悔最小化方法的固定点迭代", "title_en": "A regret minimization approach to fixed-point iterations", "authors": "Joon Kwon", "background": "论文背景介绍了将后悔最小化算法转变为固定点迭代的概念，并指出这种转化能够确保收敛性，同时可以从后悔上下界中得出。该方法扩展了经典的Krasnoselskii--Mann迭代，特别强调了如何利用后悔减小算法（例如AdaGrad）进行这种转换。", "innovation": "论文的创新点在于提出了一种新的如何将后悔最小化算法转化为固定点迭代的方法，具体表现为将那些能够收敛的后悔最小化算法通过特定转换规则转变成新的迭代过程。这种方法不仅涵盖了经典Krasnoselskii--Mann迭代，还特别关注于AdaGrad家族算法，实现了具有新颖自适应保证的新种类的固定点迭代。", "conclusion": "通过数值实验验证了基于AdaGrad的固定点迭代方法相较于传统的Krasnoselskii--Mann迭代能够实现更快的收敛速度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21609", "html_url": "https://arxiv.org/abs/2509.21609", "title": "VLCE：用于灾害评估中的知识增强图像描述框架", "title_en": "VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster Assessment", "authors": "Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George", "background": "在自然灾害发生后，第一时间进行损害评估至关重要，但传统的手工评估方法效率低下且风险高。虽然卫星和无人机照片能提供广泛的视角，但现有的计算机视觉方法只能提供分类标签或分割掩模，限制了它们提供全面情况理解的能力。本研究的目的是提出一个能够生成全面、上下文相关解释的多媒体系统，以应对灾害图像。", "innovation": "该研究提出了Vision Language Caption Enhancer (VLCE)，这是一种结合了知识增强的多媒体系统，它使用了双架构方法：一个配备有预训练ResNet50骨架的CNN-LSTM模型，用于解析卫星图像数据集xBd，另一个是基于无人机图像数据集救援网络预训练的视觉变换器模型。这两个系统利用了ConceptNet和WordNet的外部语义知识来扩展词汇覆盖面并提高描述准确性。实验结果表明，VLCE在Image Description任务中超越了现有的先进模型。", "conclusion": "本研究的双架构系统展示了其在自动从卫星和无人机照片生成信息密集型、可操作描述方面的显著潜力，从而提高灾害损害评估的效率和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22454", "html_url": "https://arxiv.org/abs/2509.22454", "title": "提高电势生成模型的工作频率", "title_en": "Overclocking Electrostatic Generative Models", "authors": "Daniil Shlenskii,Alexander Korotin", "background": "最近，基于电势的生成模型（如PFGM++）已被证明是图像合成方面的一个强大框架，能够达到行业最佳性能。尽管如此，这些模型在生成样本时仍依赖于昂贵的偏微分方程（ODE）模拟，导致计算成本较高。为了解决这一问题，研究者提出现有的电解质生成模型（PFGM++）框架在辅助维数$D$增加到无限大时会恢复到扩散模型框架，但在有限$D$的情况下仍能取得更好的实际结果。因此，该研究旨在寻找一种加速电解质生成模型的方法，使其在所有$D$值时都能高效运行。", "innovation": "作者提出了逆泊松流匹配（IPFM），一种新颖的蒸馏框架，旨在通过对电解质生成模型进行蒸馏加速其实现。IPFM将蒸馏问题视为逆问题，即学习一个生成器，使其诱发的电势场与教师模型的电势场相匹配。该框架提出了可计算的训练目标，并在$D \to \nfty$极限下，IPFM与最近提出的分数身份蒸馏（SiD）方法相似。实验结果显示，使用IPFM进行蒸馏可仅通过少量函数评估，产生接近教师或优于教师的样本质量。此外，在有限$D$值的情况下，蒸馏收敛速度比在$D \to \nfty$（扩散模型）极限下的收敛速度快，这与先前发现的有限$D$ PFGM++模型表现出更好的优化和采样特性保持一致。", "conclusion": "该研究通过提出IPFM框架，有效地解决了电解质生成模型在不同$D$值下的计算效能问题，不仅提高了生成样本的效率，还优化了模型的采样性能。此外，实验结果表明IPFM具有快速收敛的优势，这对于加快实验和其他应用场景中模型的学习和执行具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21623", "html_url": "https://arxiv.org/abs/2509.21623", "title": "OjaKV: 基于Oja规则的上下文感知在线低秩KV缓存压缩", "title_en": "OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule", "authors": "Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen", "background": "大型语言模型（LLM）的能力正受到显著的内存瓶颈限制，即用于自回归生成所需的键-值（KV）缓存。现有的KV缓存压缩方法依赖于静态、离线学习的子空间，但在数据分布变化时表现不佳。现有方法因受此限制而需要改进。论文讨论了在长上下文任务中，即便在高压缩率下也能保持零样本准确性的方法和挑战。", "innovation": "OjaKV引入了一种新的框架，结合了战略性的混合存储策略和在线子空间适应。该框架识别出并非所有token都需要压缩，并保留关键的起始和最近的token为全秩形式，同时对大多数中间token应用低秩压缩，通过Oja算法在线地调整投影基。这种方法确保了在预填充提示和解码过程中调整的子空间能够及时适应不断变化的上下文，而不需要对注意力模块进行修改。实验结果表明在高压缩率情况下，OjaKV能保持或提升零样本准确性，尤其在需要复杂推理的长上下文基准测试中表现出色，突显了在线子空间适应的重要性。", "conclusion": "OjaKV框架提供了一种实际可行且无需微调的解决方案，能够在不增加显存要求的情况下提高长上下文推理的效率。这是通过结合战略性的混合存储策略和在线子空间适应实现的，确保子空间能够及时适应不断变化的上下文。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21625", "html_url": "https://arxiv.org/abs/2509.21625", "title": "使用音频语言模型指导音频编辑", "title_en": "Guiding Audio Editing with Audio Language Model", "authors": "Zitong Lan,Yiduo Hao,Mingmin Zhao", "background": "音频编辑在虚拟现实/增强现实沉浸感、虚拟会议、声音设计和其他互动媒体中扮演着核心角色。然而，最近的生成音频编辑模型依赖于模板式的指令格式，且仅适用于单声道音频编辑。这些模型无法处理声明式音频编辑，即用户声明所需的结果，编辑操作的具体细节则交由系统处理。因此，急需一种新型框架来支持更高级的音频编辑功能，提升音频编辑的质量和灵活度。", "innovation": "本文介绍了SmartDJ，这是一种将音频语言模型的推理能力与潜在扩散模型的生成能力结合起来的新框架，用于立体声音频编辑。给定高层次的指令，SmartDJ将其分解为一系列原子编辑操作（如添加、删除或空间重新定位事件），并通过一个训练有素的扩散模型来执行这些操作。为了支持这一方法，设计了一个数据合成管道，生成高级指令、原子编辑操作以及每次操作前后音频的配对示例。实验表明，SmartDJ在感知质量、空间真实性及语义一致性方面均优于现有的音频编辑方法。", "conclusion": "SmartDJ在提供高级音频编辑功能的同时，显著提升了音频编辑的质量和现实感，相比现有技术具有明显优势。该技术有望在多个领域得到广泛应用，进一步推动互动媒体的发展。Demo可在指定链接获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21629", "html_url": "https://arxiv.org/abs/2509.21629", "title": "InvBench: LLMs能否通过不变量合成加速程序验证？", "title_en": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?", "authors": "Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken", "background": "程序验证依赖于循环不变式的发现，但自动发现强不变式仍然是一个长期存在的挑战。该研究介绍了一个有原则的方法来评估LLM在不变式合成中的表现，采用基于验证的决策过程并提供形式化的正确性保证，不仅评估正确性，还评估不变式在验证中的加速效果。研究使用7种最先进的LLM和现有的基于LLM的验证器与传统解算器UAutomizer进行评估，结果显示，基于LLM的验证器虽然是一个有前景的方向，但目前仍不具有UAutomizer的显著优势。模型能力也变得至关重要，不同模型在加速效果上的差异显著，并且基准测试提供了当前LLM的一个开放挑战。最后，研究发现监督微调和Best-of-N采样可以提高性能：在3589个实例上进行微调，Qwen3-Coder-480B的加速案例百分比从8%提高到29.2%，Best-of-N采样（N=16）将Claude-sonnet-4的加速案例百分比从8.8%提高到22.1%。", "innovation": "研究提出了一种基于验证的决策过程来评估LLM在不变式合成中的表现，这种评估不仅考虑正确性还包括验证过程中的加速效果。通过监督微调和Best-of-N采样提高了性能。", "conclusion": "虽然基于LLM的验证器展示了前景，但目前它们在加速程序验证上的效果尚未超越传统解算器UAutomizer。模型能力的差异显著，并且通过监督微调和Best-of-N采样可以有效改善性能。当前的基准测试为现有的LLM设定了一个难题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21676", "html_url": "https://arxiv.org/abs/2509.21676", "title": "HuLA: 基于多任务学习的恐慌感知反伪造技术，用于表达性和情绪性合成语音", "title_en": "HuLA: Prosody-Aware Anti-Spoofing with Multi-Task Learning for Expressive and Emotional Synthetic Speech", "authors": "Aurosweta Mahapatra,Ismail Rasim Ulgen,Berrak Sisman", "background": "现有的反伪造系统对于表现力和情绪性的合成语音依然存在不敏感的问题，因为这些系统很少利用语调作为区分自然语音和合成语音的鉴别线索。语调是人类表达和情绪交流的核心，人类会本能地利用F0模式和voiced/unvoiced结构等语调线索来区分自然和合成语音。", "innovation": "本文提出了HuLA，一种两阶段的语调感知多任务学习框架，用于伪造检测。在第一阶段，通过自我监督学习（SSL）骨干网络对真实的语音进行训练，包含F0预测和voiced/unvoiced分类等辅助任务，增强其捕捉类似人类感知学习的自然语调变化的能力。在第二阶段，模型在真实和合成数据上联合优化，利用语调感知来检测自然和表达性的合成语音之间不匹配的特征。", "conclusion": "实验结果表明，HuLA在具有挑战性的离域数据集上，包括具有表现力、情绪性和跨语言攻击的情况下，始终优于强大的基线系统。这些结果证明，结合SSL嵌入和显式的语调监督显著提高了对抗高级合成语音攻击的鲁棒性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21661", "html_url": "https://arxiv.org/abs/2509.21661", "title": "使用贝叶斯优化进行传感器表征的自动化", "title_en": "Automating Sensor Characterization with Bayesian Optimization", "authors": "J. Cuevas-Zepeda,C. Chavez,J. Estrada,J. Noonan,B. D. Nord,N. Saffold,M. Sofo-Haro,R. Spinola e Castro,S. Trivedi", "background": "新型仪器的发展需要一个迭代周期，包括设计、原型制作和测试三个阶段。最近在仿真技术和纳米加工方面的进展显著加快了设计和原型制作阶段。然而，探测器表征仍然是设备开发中的一个主要瓶颈。在测试阶段，需要大量时间来在不同操作条件下表征设备并找到最佳操作参数。通常，完成表征和参数优化需要一到一年的时间，占用了一位专家大量时间。", "innovation": "本文提出了一种新的传感器校准技术，旨在加速开发周期中的测试阶段。该技术利用闭环贝叶斯优化（BO），通过实时测量来指导参数选择并识别最优操作状态。", "conclusion": "通过该方法，机器学习驱动的工具能够高效地在短短几天内表征和优化传感器的操作，无需设备专家的监督。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21647", "html_url": "https://arxiv.org/abs/2509.21647", "title": "使用大型语言模型进行训练和分析的自动化机器学习管道", "title_en": "Automated Machine Learning Pipeline for Training and Analysis Using Large Language Models", "authors": "Adam Lahouari,Jutta Rogal,Mark E. Tuckerman", "background": "机器学习原子势（MLIPs）已成为扩展分子模拟的强大工具，能够超越量子方法的限制，提供接近量子的精度，同时大幅降低计算成本。然而，开发可靠的MLIPs仍然具有挑战性，因为这需要生成高质量的数据集，预处理原子结构，以及精心训练和验证模型。本研究旨在通过引入一个自动化机器学习管道（AMLP）来简化这一过程，该管道从数据集创建到模型验证统一整个工作流程。", "innovation": "本研究引进了自动化机器学习管道（AMLP），该管道利用大型语言模型代理协助电子结构代码选择、输入准备和输出转化，同时其分析套件（AMLP-Analysis）基于ASE支持广泛的分子模拟。AMLP构建在MACE架构上，并通过测试层状吡啶以微秒标准进行微调，实现了~1.7 meV/原子在能量和~7.0 meV/Å在力方面的平均绝对误差，表明该模型能够准确再现DFT几何结构并能够稳定地用于分子动力学模拟。", "conclusion": "AMLP通过自动化和标准化的工作流程显著简化了MLIPs的开发过程，从而提高了模型的可靠性和准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21743", "html_url": "https://arxiv.org/abs/2509.21743", "title": "Retrieval-of-Thought: 通过重用想法实现高效的推理", "title_en": "Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts", "authors": "Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar", "background": "大型推理模型通过生成长时间推理痕迹来提高准确性，但这种方式增加了延迟和成本，因此提出了推理时的效率问题。作者提出的Retrieval-of-Thought (RoT) 方法通过复用之前的推理步骤，将这些步骤组织成一个带有顺序和语义边的思想图，以实现快速检索和灵活重组。", "innovation": "RoT 通过思想图引导新的问题，并通过奖励导向的遍历快速组装问题特定的模板来指导生成。这种动态模板的重用减少了冗余探索，降低了输出令牌数，同时保持了准确性。", "conclusion": "RoT 在各类推理基准测试中表现出显著的效率提升，输出令牌减少高达40%，推理延迟减少82%，成本降低59%，同时保持了准确性。RoT 提供了一种可扩展的通过检索构建动态模板来实现高效 LRM 推理的范式。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21664", "html_url": "https://arxiv.org/abs/2509.21664", "title": "通过物理引导的扩散模型生成稳健的放置", "title_en": "Generating Stable Placements via Physics-guided Diffusion Models", "authors": "Philippe Nadeau,Miguel Rogel,Ivan Bilić,Ivan Petrović,Jonathan Kelly", "background": "稳定地在多物体场景中放置物体是机器人操作中的基本挑战，因为放置必须没有穿插、精确接触表面并且产生力平衡结果。现有方法通过运行模拟引擎或基于外观的启发式评估来评估稳定性，而我们的方法将稳定性直接集成到扩散模型的采样过程中，通过查询离线采样式规划器来收集多模态摆放标签，并通过扩散模型生成稳健的摆放。扩散模型利用几何感知先验来增强采样稳定区域的概率。这种方法无需额外的重新训练或微调，可以直接应用于现成的模型并减少计算时间，从而实现更稳健的放置。", "innovation": "我们的方法通过将稳定性直接集成到扩散模型的采样过程中，利用离线采样式规划器来收集多模态摆放标签，并通过扩散模型生成符合物理原理的稳健摆放。该策略通过增强高稳定区域的采样概率来提高稳健性，并且不需要额外的重新训练或微调，同时缩短了计算时间。我们的物理引导扩散模型相对于最先进的几何方法在稳定性方面提高了56%，并减少了47%的计算时间.", "conclusion": "我们在四个基准场景中评估了我们的方法，物理引导的扩散模型不仅能提高稳健性，还能降低计算时间。这种方法为在复杂场景中实现稳健的物体放置提供了有效的解决方案，并能够直接应用于现成的扩散模型。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21718", "html_url": "https://arxiv.org/abs/2509.21718", "title": "通过ASR引导的在线偏好优化提高低资源语言的TTS", "title_en": "Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization", "authors": "Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li", "background": "开发低资源语言的高质量文本到语音（TTS）系统具有挑战性，因为配对的文本和语音数据稀缺。相比之下，对于这些语言的自动语音识别（ASR）模型往往更容易获取，得益于大规模的多语言预训练努力。本文提出了一种基于组相对策略优化（GRPO）的框架，将自动回归、多语言TTS模型适应新语言。首先，通过对国际音标（IPA）标记进行多语言基础训练，建立一种语言无关的TTS合成基础。接下来，通过有限的配对新语言数据微调此模型以捕获目标语言的语音特征。最后，使用预先训练的ASR、说话人验证和音频质量评估模型的多目标奖励，通过GRPO优化模型，仅使用未配对的文本和说话人提示进行优化。", "innovation": "提出了一种以组相对策略优化（GRPO）为基础的框架，用于将自动回归、多语言TTS模型进行新语言的适应。该方法通过一个未经配对文本和说话人提示的语音生成过程，仅用预训练的ASR、说话人验证和音频质量评估模型的多目标奖励进行优化。", "conclusion": "实验表明，这种方法生成的语音在低资源语言中是可理解且说话人一致的，显著优于仅通过微调的方法。进一步地，这种基于GRPO的方法在高资源语言中也提高了TTS性能，超过了离线对齐方法，如直接偏好优化（DPO），在可理解性、说话人相似度和音频质量上表现更优。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21740", "html_url": "https://arxiv.org/abs/2509.21740", "title": "快速现场翻译的自我推测有偏解码", "title_en": "Self-Speculative Biased Decoding for Faster Live Translation", "authors": "Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang", "background": "大型语言模型（LLMs）在多种文本生成任务中表现出色，但在实现即时应用（如现场翻译）时仍面临挑战。即时翻译要求随着输入上下文的不断扩展，输出能够不断更新，并且还得维持合理的计算成本以满足延迟要求。在现有方法中，通常需要从头开始重新生成输出，这不仅增加了计算成本，还可能导致输出闪烁等问题，影响用户体验。", "innovation": "本文重新审视了重新翻译以实现即时翻译的方法，并提出了一种新的推理范式——自我推测有偏解码。该方法利用最新的输出作为当前增长的输入上下文的草案，并在验证阶段偏向于草案以提高草案接受率，从而减少闪烁，提高速度。与现有的推测性解码策略不同，本文方法避免了草案计算，更加模型无关并具备即插即用特性，适用于优化敏感实时应用的延迟。", "conclusion": "在同时的文本到文本重新翻译实验中，该方法比传统的自回归重新翻译提高了高达1.7倍的速度，同时质量不受影响。通过结合仅显示掩码技术，闪烁现象减少80%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21670", "html_url": "https://arxiv.org/abs/2509.21670", "title": "MORPH: 形状无关的PDE基础模型", "title_en": "MORPH: Shape-agnostic PDE Foundation Models", "authors": "Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence", "background": "该论文介绍了 MORPH，一种通用的、自回归的基础模型，用于处理部分微分方程（PDEs）。MORPH基于卷积视觉变换器的架构，能够无缝处理不同维度（1D-3D）、不同分辨率和多种物理场的异质时空数据集。已有多样的异质PDE数据集用于预训练，并评估了其在下游预测任务中的应用。MORPH在零样本和有样本泛化的性能上超越了从零开始训练的模型，并且在广泛的评估中，其表现与目前最佳模型相当或更优秀，为从复杂且多模态的科学观测中学习提供了一个灵活且强大的基础架构，指向了更高效的科学机器学习方法。", "innovation": "MORPH采用了组件级卷积、场之间交叉注意和轴式注意机制。这使得它能够同时处理标量和向量通道，捕捉局部交互，同时建模和选择性传播不同物理场之间的信息，并且其全空间-时间自注意操作分解为单独的空间和时间轴，降低了计算负担同时保持表达能力。MORPH在预训练后能通过全模型调优或参数高效低秩适配器（LoRA）应用到任务，优于空白训练模型，并且表现超过或匹配当前的最佳模型和最新状态的模型。", "conclusion": "MORPH在广泛评估中展示了强大的灵活性和优势，能用于处理复杂多模态的科学观察数据，并扩展了科学机器学习的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21791", "html_url": "https://arxiv.org/abs/2509.21791", "title": "通过因果推理导航结构化输出格式对大语言模型的影响", "title_en": "Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference", "authors": "Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma", "background": "大语言模型（LLMs）生成的结构化输出增强了处理生成信息的效率，并在工业应用中被越来越多地采用。先前的研究已经探讨了结构化输出对LLMs生成质量的影响，但往往是单向的发现。有人认为结构化格式增加了完整性和事实准确性，但也有一些观点认为结构化格式限制了LLMs的推理能力，并导致标准评估指标的下降。这些评估的潜在限制包括受限的测试场景、未受严格控制的比较设置以及依赖粗略的评估指标。", "innovation": "本文采用因果推断进行更精细的分析。基于一个假设和两个保证前提，得出了五种可能的因果关系结构，说明了结构化输出对LLMs生成的影响：(1) 连锁反应无m-偏差，(2) 连锁反应有m-偏差，(3) 指令单因，(4) 输出格式单因，(5) 独立性。通过七个公开的任务和一个开发的任务，粗略的评估指标报告了正、负或中性影响，而因果推理在48个场景中有43个没有发现因果影响，在剩余5个场景中涉及复杂的因果结构，受具体指令影响。", "conclusion": "研究表明粗略的评估指标展示了大语言模型GPT-4o生成中结构化输出的正、负或中性影响。然而，因果推理在48个测试场景中揭示了43个没有因果影响的情形。在剩余5个场景中，这些涉及复杂的因果结构，受具体指令影响。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21707", "html_url": "https://arxiv.org/abs/2509.21707", "title": "SADA: 安全且自适应的多重黑盒预测统计推断", "title_en": "SADA: Safe and Adaptive Inference with Multiple Black-Box Predictions", "authors": "Jiawei Shan,Yiming Dong,Jiwei Zhao", "background": "实际应用中往往因黄金标准实验的成本和时间要求而面临标签数据稀缺的问题，而无标签数据则通常较为丰富。随着机器学习技术的普及，利用多种模型和算法（包括深度学习、大型语言模型和生成性AI）生成多种预测标签变得越来越可行。本文探讨了如何安全且自适应地整合多种未知质量的黑盒预测结果，同时保持有效的统计推理。", "innovation": "本文提出了一种新颖的方法，能够在未知预测质量的情况下安全且自适应地聚合多种黑盒预测结果，其主要贡献在于提供了两个关键保证：(i) 该方法绝不会比仅使用标签数据的性能更差；(ii) 如果预测中任何一个（不知是哪一个）完全符合真实情况，该算法能够自适应地利用这种预测以实现更快的收敛速度或半参数效率边界。", "conclusion": "通过在合成和基准数据集上的实验，证明了所提出的算法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21733", "html_url": "https://arxiv.org/abs/2509.21733", "title": "UISim：动态移动环境中的交互式图像基础UI模拟器", "title_en": "UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments", "authors": "Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen", "background": "开发和测试用户界面（UI）以及训练AI代理与它们交互是非常具有挑战性的，因为现实世界的移动环境是动态和多样的。现有方法通常依赖于笨重的物理设备或有限的屏幕截图静态分析，这阻碍了可扩展的测试和智能UI代理的发展。", "innovation": "我们介绍了UISim，这是一种基于图像的新颖的UI模拟器，提供了一个纯粹从屏幕图像出发的动态和交互式平台来探索移动电话环境。该系统采用两阶段方法：给定初始手机屏幕图像和用户动作，首先预测下一个UI状态的抽象布局，然后基于此预测布局合成一个新的、视觉上一致的图像。这种方法使UI过渡的现实模拟成为可能。", "conclusion": "我们的实验结果表明，与端到端生成UI基线相比，UISim在生成真实且连贯的后续UI状态方面的表现更优，凸显了其保真度及细分UI开发和增强AI代理培训的潜力。此外，其互动功能为高级应用铺平了道路，如UI导航任务规划，为AI代理提供了服务。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21711", "html_url": "https://arxiv.org/abs/2509.21711", "title": "具条件共轭最后一层估计的多模态贝叶斯神经网络代理模型", "title_en": "Multi-modal Bayesian Neural Network Surrogates with Conjugate Last-Layer Estimation", "authors": "Ian Taylor,Juliane Mueller,Julie Bessac", "background": "随着数据收集和模拟能力的进步，多模态学习，即从多种模态和数据源学习，已成为一个重要研究领域。当多模态数据可用时，通过学习多种辅助模态的数据来支持昂贵量的研究有望在外循环应用中（如优化、反问题分析或敏感性分析）发挥作用", "innovation": "研究开发了两种多模态贝叶斯神经网络代理模型，并利用条件共轭分布在最后一层来估计模型参数，采用基于随机变分推断（SVI）的方法进行此共轭SVI估计，即使在部分缺失观察数据的情况下也能实现.", "conclusion": "与单模态代理模型相比，多模态代理模型在标量和时间序列数据上的预测精度和不确定性量化均有所提高."}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21906", "html_url": "https://arxiv.org/abs/2509.21906", "title": "离散流模型的误差分析", "title_en": "Error Analysis of Discrete Flow with Generator Matching", "authors": "Zhengyan Wan,Yidong Ouyang,Qiang Yao,Liyan Xie,Fang Fang,Hongyuan Zha,Guang Cheng", "background": "离散流模型是用于学习离散状态空间分布的强大框架，显示出比离散扩散模型更优秀的性能，但其收敛性质和误差分析尚未被充分研究。", "innovation": "通过结合鞅论建立了统一框架，系统研究了离散流模型的理论性质。具体包括推导出两种连续时间马尔可夫链（CTMC）不同转换率的路径测度的KL散度，并提供了早期停止和转换率估计误差的全面分析。通过发电机匹配和均匀化，建立了分布估计的非渐近误差界。这是对离散流模型的第一个误差分析。", "conclusion": "我们的研究提供了离散流模型的第一个误差分析。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21880", "html_url": "https://arxiv.org/abs/2509.21880", "title": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping", "title_en": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping", "authors": "Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang", "background": "当前基于强化学习的方法（如GRPO）仅关注模型对同一输入的回答在正确性上的差异，忽视了那些所有回答都获得相同奖赏的示例，即所谓的零方差提示。这些提示通常被认为没有提供有用的反馈。", "innovation": "提出了RL-ZVP算法，通过熵导向的优势塑形从零方差提示中提取学习信号。该算法直接奖励正确性并惩罚错误，即使不依赖于对比回应，也能根据标记级别特征调整反馈，以保持信息丰富和细微的信号，从而改进大语言模型的推理能力。", "conclusion": "实验表明，RL-ZVP在六个数学推理基准测试中比GRPO提高了高达8.61个点的准确性和7.77个点的通过率，同时持续优于其他排除零方差提示的基线模型。结果表明利用零方差提示在RLVR中有未开发的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21739", "html_url": "https://arxiv.org/abs/2509.21739", "title": "Noise-to-Notes: 基于扩散模型的生成与细化用于自动鼓谱转录", "title_en": "Noise-to-Notes: Diffusion-based Generation and Refinement for Automatic Drum Transcription", "authors": "Michael Yeung,Keisuke Toyama,Toya Teramoto,Shusuke Takahashi,Tamaki Kojima", "background": "传统的自动鼓谱转录（ADT）任务通常被定义为一种区分性任务，从音频频谱图预测鼓事件。现有研究集中在通过音频特征来准确预测鼓事件及其速度，但在转换音频到具体鼓事件时面临挑战，尤其是在处理二进制弱起符和连续速度值时。此外，低级频谱特征的局限性使得模型对域外鼓声音频的鲁棒性较差。", "innovation": "本文重新定义了ADT任务为条件生成任务，并引入了基于扩散模型的Noise-to-Notes（N2N）框架，通过该框架将条件下的高斯噪声转换为带有相关速度的鼓事件。N2N框架的优势在于提供灵活的速度-准确度权衡，并具有较强的修补能力。为了解决生成二进制起始时间与连续速度值的难题，提出了Annealed Pseudo-Huber损失，以促进有效联合优化。同时，通过引入从音乐基础模型提取的高层语义特征，来增强对域外鼓声音频的鲁棒性。这种方法显著提高了模型的稳固性和精度。", "conclusion": "实验结果表明，集成音乐基础模型（MFM）特征极大提高了模型的鲁棒性，N2N框架在多个ADT基准测试中达到了最新的性能水平。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21943", "html_url": "https://arxiv.org/abs/2509.21943", "title": "足底压力量化的异常检测：基于人类中心视角的统计参数映射与可解释机器学习对比", "title_en": "Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning", "authors": "Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich", "background": "足底压力量化在临床诊断和体育科学中至关重要，然而，大规模异质数据集中往往包含技术错误或程序不一致导致的异常值。统计参数映射（SPM）可以提供可解释的分析结果，但其对齐敏感，对于稳健的异常检测能力尚不明确。因此，本研究将SPM方法与可解释的机器学习（ML）方法进行对比，以建立透明的质量控制流程，用于处理足底压力数据集。", "innovation": "研究开发并对比了SPM方法和基于SHapley Additive exPlanations (SHAP)的可解释卷积神经网络(CNN)方法，以提高足底压力数据集中异常检测的准确性。此前，SPM方法在已有的研究中没有得到系统性的性能评估，且其可解释性也不被充分重视。通过使用嵌套交叉验证和领域专家的语义差异调查，研究结果发现ML模型在准确性方面优于SPM，并且具有更好的可解释性。", "conclusion": "研究结果表明，SPM和可解释的ML方法都可以在足底压力数据中的自动化异常检测方面发挥互补作用。这些发现强调了可解释性在将复杂模型输出转化为可解释的洞察以有效指导决策中的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21765", "html_url": "https://arxiv.org/abs/2509.21765", "title": "基于行为汇总的车辆路径问题的终生学习", "title_en": "Lifelong Learning with Behavior Consolidation for Vehicle Routing", "authors": "Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao", "background": "近期基于神经网络的求解器已展示出解决路由问题的有前景的表现。现有的研究主要基于对预定义问题分布和规模的一次性训练，即任务。当出现新的任务时，它们通常依赖于零样本泛化或在新任务上微调预训练的求解器，这两种方法都可能无法保持以前任务中获得的知识。因此，本文探讨了神经VRP求解器的新型终生学习范式，旨在允许求解器在学习新任务的同时保持对先前任务的性能。", "innovation": "提出了一种新型框架——基于行为汇总的终生学习路由器（LLR-BC），通过决策导向方式协调新任务训练求解器的行为与已存储的行为，基于决策的信心程度自动分配更大的总结权重，鼓励更多关注重要经验。", "conclusion": "大规模实验验证了LLR-BC在终生学习环境中训练高性能神经求解器的有效性，解决了灾难性遗忘问题，保持求解器的可塑性，并提高了零样本泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21892", "html_url": "https://arxiv.org/abs/2509.21892", "title": "弹性MoE：解锁Mixture-of-Experts在推理时的可扩展性", "title_en": "Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts", "authors": "Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang", "background": "MoE模型通常在训练和推理时固定激活专家的数量k。理论上看，增加更多的专家数量k'（其中k' > k）会在推理时利用更多的模型参数，从而有望改善性能。然而，实验观察却发现性能的提升范围非常有限，激活的专家数量仅稍微增加就会迅速导致性能下降。研究表明，这样的性能下降主要源于专家之间缺乏有效的学习合作机制。", "innovation": "提出了弹性MoE（EMoE）训练框架，使其能够根据需要在推理时动态调整激活的专家数量而无需增加额外的训练开销。通过同时训练专家在多样化组合中的协作能力并鼓励路由器做出高质量的选择，EMoE 保证了在推理计算预算范围内表现的稳健性。", "conclusion": "实验结果显示，EMoE 显著扩展了MoE的有效性能可扩展范围，使其扩展到训练时k的两到三倍，并且提升了模型的峰值性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21764", "html_url": "https://arxiv.org/abs/2509.21764", "title": "CubistMerge:保持空间结构的ViT backbone通用的标记合并方法", "title_en": "CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones", "authors": "Wenyi Gong,Mieszko Lis", "background": "许多现代的视觉变换器（ViT）骨干网络采用了基于空间的设计，例如窗口注意力机制、SAM中的分解相对位置嵌入以及DINOv3中的RoPE。这些空间架构对标记减少提出了新的挑战，因为大多数人使用的现有方法无法保留这些架构依赖的空间结构。本文提出了一种简单而有效的标记合并方法，能够保持空间完整性，使其能够无缝地与空间架构兼容。该方法解决了一个看似矛盾的问题：在保持标记合并后的空间结构的同时，利用空间布局中的非均匀信息分布。", "innovation": "文章提出了一种名为CubistMerge的方法，该方法采用了二维减少策略来确保标记布局的结构化，使用一种空间感知的合并算法来保持相对标记位置，同时引入了一种新颖的最大维度值标记表示法来保留显著特征。实验显示，该方法在多种视觉任务中表现良好，无论是现成模型还是微调后，都能达到最先进的性能。具体而言，该方法在SAM-H上实现了1.25倍的速度提升，同时只有0.7%的mIOU降低；在DeiT-B上实现了1.15倍的速度提升，而在ImageNet上仅经过一个周期的微调，就没有任何top-1准确度的降低。", "conclusion": "CubistMerge方法在保持空间结构的同时能够有效地进行标记合并，适用于多种ViT骨干网络，显著提高了模型的速度而不损失性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21961", "html_url": "https://arxiv.org/abs/2509.21961", "title": "FlowDrive：利用数据平衡的适度流匹配进行轨迹规划", "title_en": "FlowDrive: moderated flow matching with data balancing for trajectory planning", "authors": "Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller", "background": "基于学习的规划器对驾驶数据中的长尾分布敏感。常见的驾驶行为在数据集中占主导地位，而危险或罕见的情况则很少见。这种不平衡会使模型偏向频繁出现的情况，从而在关键场景上的表现下降。", "innovation": "本文研究了采样训练数据的平衡策略，并发现通过轨迹模式重加权是有效的方法。在此基础上，提出了FlowDrive，一种流量匹配轨迹规划器，能够利用少量的流量匹配步骤学习条件矫正流，直接将噪声映射到轨迹分布中。此外还引入了一种温和的、在循环中的指导策略，通过在流量步骤间注入小扰动来系统地增加轨迹多样性，同时保持场景的在一性。在nuPlan和交互焦点的interPlan基准测试中，FlowDrive取得了基于学习的规划器的最好结果，接近基于规则优化的方法。在添加温和的指导和轻微后处理后（FlowDrive*），其在几乎所有基准测试划分中的表现达到最佳。", "conclusion": "FlowDrive*在所有基准测试划分中达到了整体最优性能，是基于学习的规划器中最先进的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21843", "html_url": "https://arxiv.org/abs/2509.21843", "title": "SBFA：使用单个隐秘位翻转攻击打破大型语言模型", "title_en": "SBFA: Single Sneaky Bit Flip Attack to Break Large Language Models", "authors": "Jingkai Guo,Chaitali Chakrabarti,Deliang Fan", "background": "近年来，大规模语言模型（LLMs）的大规模在线部署使其安全性成为了亟待解决的问题。此前的研究表明，位翻转攻击（BFAs）可以严重破坏深度神经网络（DNNs），即使是非常少量的位翻转也可以导致准确率降至随机猜测水平。现有研究扩展了BFAs到LLMs，并发现尽管模块化和冗余的直觉认为能提高鲁棒性，但只有少量的恶意位翻转也可导致LLMs的灾难性准确率下降。然而，现有的BFAs方法通常只能攻击整数或浮点数模型中的一种类型，这限制了攻击的灵活性。此外，在浮点数模型中，随机位翻转通常会导致受扰参数变为极端值（例如，尾数位的翻转），这不仅不隐秘，还会导致数值运行时错误（例如，无效的张量值（NaN/Inf））。", "innovation": "本文首次提出了SBFA（隐秘位翻转攻击），该攻击仅使用单个位翻转即可破坏LLM的表现，同时保持受扰参数值在良性层间权重分布范围内。通过定义参数敏感度度量，ImpactScore（结合了梯度敏感度与受扰范围，并限制在良性层间权重分布中），实现了迭代搜索和排名。还提出了一种新的轻量级SKIP搜索算法，大大降低了搜索的复杂度，使得针对最新最先进（SOTA）LLM模型的SBFA搜索只需几十分钟即可成功。该方法在Qwen、LLaMA和Gemma模型中展示了其有效性。", "conclusion": "在BF16和INT8数据格式下，通过单个位翻转，SBFA成功将MMLU和SST-2上的准确率降至随机水平以下。这表明，从数十亿个参数中翻转一个单一的位揭示了先进LLM安全性的严重关切。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21991", "html_url": "https://arxiv.org/abs/2509.21991", "title": "ERGO: 高效的高分辨率视觉理解", "title_en": "ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models", "authors": "Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim", "background": "高分辨率图像在实际的视觉-语言应用中至关重要。目前，大型视觉-语言模型（LVLMs）因为大量的视觉标记而产生巨大的计算开销。随着“基于图像思考”模型的引入，推理不再局限于文本，而是扩展到了视觉领域。基于这些能力，作者提出了一个两阶段从粗到细的推理管道：首先，分析低分辨率图像以识别相关区域；然后，仅在这些区域进行全分辨率裁剪和后续的推理。这种方法在减少计算成本的同时，也能在需要时保留细化的视觉细节。然而，主要难点在于确定哪些区域对给定查询真正相关。当时的相关方法在输入图像降采样后的第一阶段常常会失效，因为推理依赖清晰的视觉信息。", "innovation": "作者提出了一个名为ERGO（Efficient Reasoning & Guided Observation）的方法，该方法利用推理驱动的感知增强多模态上下文来确定需要聚焦的区域。ERGO能够在回答问题时扩展裁剪区域以覆盖视觉含糊的区域，并且能够处理感知不确定性。ERGO在多数据集上的准确率优于原始模型和竞争方法，同时具有更高的效率。比如，在V*基准测试中，ERGO在仅使用23%视觉标记的情况下超越了Qwen2.5-VL-7B 4.7分，并实现了3倍的推理速度提升。", "conclusion": "ERGO方法在多个数据集上显示出比原模型和竞争方法更高的准确性和效率。通过高效的推理驱动感知机制处理高分辨率图像，ERGO能够在视觉和语言理解任务中提高性能和效率。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21745", "html_url": "https://arxiv.org/abs/2509.21745", "title": "基于强化学习的信号设计以最小化排队长度", "title_en": "Reinforcement Learning Based Traffic Signal Design to Minimize Queue Lengths", "authors": "Anirud Nandakumar,Chayan Banerjee,Lelitha Devi Vanajakshi", "background": "有效的交通信号控制（TSC）对于减少交通拥堵、旅行延误、污染物排放以及确保道路安全至关重要。传统的固定信号控制和感应信号控制方法常难以处理动态的交通状况。为了应对这一挑战，本研究提出了一种新的自适应TSC框架，它利用了强化学习（RL）中的Proximal Policy Optimization（PPO）算法，以最小化所有信号阶段的总排队长度。该研究通过多种状态表示方法，如扩展的状态空间、自动编码器表示以及K-Planes启发式表示，解决了高效表示高度随机的交通状况这一挑战。该算法已使用Simultion of Urban Mobility（SUMO）交通模拟器实现，并在减少排队长度方面表现出优于传统方法和其他基于强化学习的方法的性能。最好的配置实现了约29%的平均排队长度减少，相比传统的Webster方法更为高效。此外，对不同奖励函数的不同形式的比较评估进一步证明了所提出的基于排队长度的方法的有效性，展示了在可扩展和自适应的城市交通管理中具有潜力。", "innovation": "本研究提出了一种新的自适应TSC框架，它使用了基于Proximal Policy Optimization（PPO）的强化学习方法，以最小化所有信号阶段的总排队长度。通过多种状态表示方法，研究解决了高效表示高度随机的交通状况这一挑战。这种新的方法在减少排队长度方面表现超过了传统的和基于强化学习的其他方法。通过这些改进的方法，实现了约29%的平均排队长度减少。这些改进也表明这种方法在城市交通管理中的可扩展性和适应性潜力。", "conclusion": "所提出的基于自适应交通信号控制的强化学习方法，在使用Proximal Policy Optimization（PPO）算法的情况下，有效地减少了交通拥堵中的排队长度，且其性能优于传统的和基于强化学习的其他方法。实验结果表明，这种新的方法具有在可扩展的城市交通管理中应用的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22049", "html_url": "https://arxiv.org/abs/2509.22049", "title": "GAN和扩散模型在MRI-to-CT转换中的比较分析", "title_en": "Comparative Analysis of GAN and Diffusion for MRI-to-CT translation", "authors": "Emily Honey,Anders Helbo,Jens Petersen", "background": "CT在治疗和诊断中至关重要，但在缺乏或难以获取CT的情况下，从MRI图像生成合成CT (sCT)图像的方法备受关注。因此，建立有效的MRI-to-CT转换策略参考是有价值的。本文对比了两种常用的MRI-to-CT转换架构：条件生成对抗网络(cGAN)和条件去噪扩散概率模型(cDDPM)。", "innovation": "将经典3D转换问题分解为2D平面的序列转换，以探讨降低计算成本的有效策略。研究了使用单个MRI图像/切片和多个MRI切片对生成过程进行条件化的影响。提出了一种新的层间相似度度量SIMOS，评估合成CT图像的连续性。", "conclusion": "研究发现，多通道条件输入和使用cDDPM架构有利于MRI-to-CT生成模型。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22011", "html_url": "https://arxiv.org/abs/2509.22011", "title": "随机矩阵视角下的回声状态网络：从精确的偏差-方差表征到最优正则化", "title_en": "A Random Matrix Perspective of Echo State Networks: From Precise Bias--Variance Characterization to Optimal Regularization", "authors": "Yessin Moakher,Malik Tiomoko,Cosme Louart,Zhenyu Liao", "background": "本文对带有一阶马尔可夫教师的回声状态网络（ESNs）进行了严格的渐进分析。通过随机矩阵理论，推导出了偏差、方差和均方误差（MSE）的闭合形式表达式，这些表达式是基于输入统计、教师权重向量和岭正则化参数的函数。", "innovation": "研究揭示了ESNs与经典岭回归的两个关键不同之处：(i) ESNs不表现出双重下降；(ii) 当训练样本数量和教师记忆长度都受限时，ESNs可以获得更低的MSE。此外，提供了一种显式的最优正则化公式来处理单位输入协方差情况，并提出了一个计算一般情况最优值的高效数值方案。", "conclusion": "这些结果提供了可解释的理论和调优ESNs的实际指南，帮助解释近期的实证观察结果，并提供可证明的性能保证。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22122", "html_url": "https://arxiv.org/abs/2509.22122", "title": "直接估算倾向得分和平均处理效应的偏差校正项", "title_en": "Direct Bias-Correction Term Estimation for Propensity Scores and Average Treatment Effect Estimation", "authors": "Masahiro Kato", "background": "本文研究了平均处理效应（ATE）的估计问题。为了估计ATE，该研究通过直接偏差校正项估计倾向得分。研究定义了每个观测值 $(X_i, D_i, Y_i)$，其中 $X_i \rightarrow \text{协变量向量}$, $D_i \rightarrow \text{二元处理指派指标}$, $Y_i \rightarrow \text{结果变量}$。在ATE估计中，偏差校正项 $h_0(X_i, D_i) = \frac{1[D_i = 1]}{e_0(X_i)} - \frac{1[D_i = 0]}{1 - e_0(X_i)}$ 很关键，其中 $e_0(X_i)$ 是倾向得分，表示接受处理1的概率。现有研究通常采用最大似然或协变量平衡方法来估计倾向得分，但这些方法可能对准确估计偏差校正项或ATE不是最优的。", "innovation": "本文提出了一种直接通过最小化偏差校正项 $h_0$ 的预测误差来估计 $h_0$（或等价地倾向于得分 $e_0$）的新方法。该方法基于Bregman散度最小化框架，预期能提高ATE估计的准确性。", "conclusion": "本文通过仿真研究评估了该方法的有效性，表明直接偏差校正项估计方法能提供更准确的倾向得分和ATE估计。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21940", "html_url": "https://arxiv.org/abs/2509.21940", "title": "近最优样本复杂度的序贯1比特均值估计", "title_en": "Sequential 1-bit Mean Estimation with Near-Optimal Sample Complexity", "authors": "Ivan Lau,Jonathan Scarlett", "background": "本文研究了在1比特通信约束下的分布式均值估计问题。本文的背景在于，在通信资源受限的情况下，如何有效地进行数据估计。传统的均值估计方法在面对1比特通信限制时性能会大幅下降，因此需要提出新的方法来克服这一挑战。", "innovation": "本文提出了基于随机和序贯选定区间查询的均值估计器。该方法通过1比特结果（表示样本是否在特定区间内）来进行估计。本文的创新点在于，提出的估计器对于所有均值和方差有界的数据分布具有$(\frac{\text{ε}}{2}, \frac{\text{δ}}{2})$-PAC（精确-近似-容许）性质，并得到了复杂度为$\tilde{O}\big( \frac{\text{σ}^2}{\text{ε}^2}\text{log}\frac{1}{\text{δ}} + \text{log}\frac{\text{λ}}{\text{σ}}\big)$ 的样本复杂度上界，这一上界与未量化情况下的最优复杂度仅具有对数级差距，并证明了额外的$\text{log}\frac{\text{λ}}{\text{σ}}$项是不可避免的。此外，本文还探讨了序贯查询相对于非序贯查询的优势，特别是在$\frac{\text{λ}}{\text{σ}}$较大的情况下，提出了更精细的样本复杂度上界，并提出了处理未知采样预算、未知方差及两阶段适配性不同变体的方法。", "conclusion": "本文总结了在特定通信限制条件下进行均值估计的方法和发展。在严格数学推导的基础上，提出了适应性均值估计器，并证明了其性能上界。此外，本文还提供了多种实现方法和应用场景，拓展了对这一问题的理解，对未来相关研究具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22018", "html_url": "https://arxiv.org/abs/2509.22018", "title": "使用深度学习探索早期宇宙", "title_en": "Exploring the Early Universe with Deep Learning", "authors": "Emmanuel de Salis,Massimo De Santis,Davide Piras,Sambit K. Giri,Michele Bianco,Nicolas Cerardi,Philipp Denzel,Merve Selcuk-Simsek,Kelley M. Hess,M. Carmen Toribio,Franz Kirsten,Hatem Ghorbel", "background": "氢是宇宙中最丰富的元素。第一代恒星和星系产生的光子使氢气电离，这一事件称为电离时代（EoR）。即将到来的平方公里阵列观测站（SKAO）将绘制这一时代的中性氢分布，有助于研究这些第一代天体的性质。从SKAO数据中提取天体物理学信息将具有挑战性，因为产生的数据量庞大，氢信号将受到不需要的前景干扰和仪器系统误差的污染。为了应对这一挑战，我们开发了最新的深度学习技术来从预期来自SKAO的氢信号的2D功率谱中提取信息。我们应用了一系列神经网络模型来这些测量，并量化它们预测宇宙氢电离历史的能力。", "innovation": "我们展示了现代深度学习技术对研究早期宇宙是有益的，尤其是我们证明了专门的机器学习算法平均可以在恢复电离历史方面实现超过0.95的$R^2$分数。", "conclusion": "深度学习技术使得对早期宇宙的宇宙学和天体物理学结构形成进行准确和精密的推断成为可能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22240", "html_url": "https://arxiv.org/abs/2509.22240", "title": "COMPASS: 用于医疗分割指标的鲁棒特征配置预测", "title_en": "COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics", "authors": "Matt Y. Cheung,Ashok Veeraraghavan,Guha Balakrishnan", "background": "在临床应用中，分割模型的实用价值往往依赖于下游指标（如器官大小）的准确性，而非分割掩码的像素级准确性。因此，为这些指标提供可靠不确定性量化对于决策至关重要。现行的框架如选择性预测（CP）能够服务于这一目的，但直接将其应用于最终的标量指标不具有效率，因为它们将复杂的非线性分割到指标的管道视为黑盒。本文探讨了一个称为COMPASS的新框架，它通过利用底层深度神经网络的归纳偏置，直接在模型的表现空间中进行校准，以求更有效地估计分割模型的不确定性。", "innovation": "COMPASS框架通过扰动中间特征沿对目标指标高度敏感的低维子空间来直接在模型的表现空间中进行校准，从而生成基于分割模型指标的有效CP区间。作者证明在交换性和嵌套假设下，COMPASS能够实现有效边际覆盖率。此外，借助学习到的内部特征估算重要性权重，COMPASS能够克服协变量转移，恢复目标覆盖率，表明它为医疗图像分割提供了实用且基于指标的不确定性量化。", "conclusion": "COMPASS为医疗图像分割提供了实用且基于指标的不确定性量化，它已经在四个医学图像分割任务中显示出了优于传统CP基线的显著紧区间。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21955", "html_url": "https://arxiv.org/abs/2509.21955", "title": "使用具备上下文感知不一致性的可学习形式预测进行机器人规划与感知", "title_en": "Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception", "authors": "Divake Kumar,Sina Tayebati,Francesco Migliarba,Ranganath Krishnan,Amit Ranjan Trivedi", "background": "深度学习模型在机器人领域通常输出点估计，其置信度较低，缺乏量化新型、噪声或分布外输入预测可靠性的机制。形式预测（CP）通过提供无分布假设的覆盖面保证来弥补这一缺口，但其依赖于固定的不一致性评分，忽视了上下文信息，可能导致区间过度保守或不安全。", "innovation": "提出了可学习形式预测（LCP），用一个轻量级神经函数替代固定的评分，利用几何、语义和任务特定特征生成上下文感知的不确定性集。LCP在保持形式预测理论保证的同时，分类时减少了18%的预测集合大小，检测区间收紧了52%，在充满障碍物环境中路径规划的成功率从72%提高到了91%，且减少了预算。在三个机器人任务的七个基准上，LCP在标准形式预测和集成基准上持续表现出优越性能。在CIFAR-100和ImageNet分类中，减少了4.7至9.9%的集合大小。在COCO、BDD100K和Cityscapes目标检测中，生成的边界框紧缩了46至54%。硬件评估显示，LCP增加了少于1%的内存和15.9%的推理开销，但在检测任务上能维持39 FPS，并且比集成模型节能7.4倍。该方法轻量（大约4.8%的运行时开销，42 KB的内存使用）且支持在线适应，适用于资源受限的自主系统。", "conclusion": "LCP在保持形式预测理论保证的同时，改进了效率和准确性，特别是适用于资源受限的机器人应用中，如路径规划和检测任务，展示出良好的性能和较低的开销。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21993", "html_url": "https://arxiv.org/abs/2509.21993", "title": "双线性关系结构修正反转诅咒并实现一致模型编辑", "title_en": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "authors": "Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha", "background": "反转诅咒是指语言模型无法从已学习的‘A是B’事实推断出未见的‘B是A’事实的能力，这一现象通常被认为是语言模型的固有限制。", "innovation": "作者通过从零开始在合成的关系知识图数据集上训练语言模型，展示了双线性关系结构在隐藏表示中自然出现，显著缓解了反转诅咒，使模型能够推断出未见的反向事实。此外，带有这种双线性结构的模型在事实更新时能在其反向和其他逻辑依赖的事实之间正确传播编辑。与缺乏这种表示的模型相比，后者不仅遭受反转诅咒的影响，还无法进行有效的编辑推广，进一步增加了逻辑不一致性。研究表明，通过在关系知识数据集上进行训练，诱导了双线性内部表示的出现，这种表示后编辑时使模型表现出逻辑一致性，这表明模型编辑的成功不仅依赖于编辑算法，还依赖于被修改知识的底层表示几何结构。", "conclusion": "我们的研究结果表明，通过关系知识数据集的训练，诱导双线性内部表示的出现，这反过来使模型在编辑后表现出逻辑一致性。这表明模型编辑的成功不仅依赖于编辑算法，还依赖于知识的底层表示几何。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21996", "html_url": "https://arxiv.org/abs/2509.21996", "title": "带有压缩高斯过程先验的非参数离散哈克斯模型", "title_en": "A Nonparametric Discrete Hawkes Model with a Collapsed Gaussian-Process Prior", "authors": "Trinnhallen Brisley,Gordon Ross,Daniel Paulin", "background": "Hawkes过程模型被用于描述过去的事件增加未来事件发生的可能性的场景。尽管许多应用记录事件作为网格上的计数，但在离散时间中的Hawkes模型仍然相对未被充分利用，且通常受到固定形式基础和激发核的限制。特别地，离散时间中的基线和激发的非参数处理较少且缺乏灵活性。", "innovation": "本文提出了一种名为Gaussian Process Discrete Hawkes Process (GP-DHP)的非参数框架，通过在基线和激发上放置高斯过程先验，进行潜变量压缩表示推断。这导致了数据自适应的结构，无需预设趋势或衰减形式，并允许近线性时间的MAP估计。此外，闭式投影能够从优化的潜轨迹中恢复出解释性强的基线和激发函数。", "conclusion": "实验证实，GP-DHP能够恢复出多种激发形状和变化的基线，且在分析美国恐怖事件和周度Cryptosporidiosis计数案例中，GP-DHP在跨事件爆发、延迟和季节性背景变化方面优于标准的参数化离散Hawkes模型，同时保持可扩展性和解释性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21998", "html_url": "https://arxiv.org/abs/2509.21998", "title": "GSM-Agent：使用可控环境理解代理推理", "title_en": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "authors": "Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao", "background": "随着大型预训练语言模型（LLMs）越来越多地作为代理使用，代理推理能力变得至关重要，这种能力包括结合工具使用（特别是搜索）和推理。然而，当前在复杂环境中和任务中评估代理推理时很难分离出代理推理。现有的代理评估基准往往将代理推理与复杂的数学推理、专家级知识和其他高级能力混合在一起。因此，有必要构建一个新的基准来分离这两种能力，以便更好地评估代理推理能力。研究者们提出了一个新的名为GSM-Agent的基准，该基准要求LLM代理解决小学水平的推理问题，但仅在提示中给出问题而不提供包含必要信息的前提条件，代理需要通过使用工具主动收集这些信息来解决问题。研究表明，即使是前沿模型如GPT-5，也只能达到67%的准确性。", "innovation": "研究者提出了一种名为GSM-Agent的新基准，旨在分离并评估代理推理。通过构建环境文档嵌入节点图和将每个工具调用与最近的节点建立推理路径，来理解代理推理的模式。研究者发现许多模型在代理推理时难以重新访问以前访问过的节点，提出了通过增加工具来促使模型重新访问的方法来提高代理推理性能的测试时间扩展方法。这为未来对理解并推动代理推理边界的研究提供了基准和框架。", "conclusion": "该基准和代理推理框架有望未来的研究结果更好地理解并推动代理推理的发展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22284", "html_url": "https://arxiv.org/abs/2509.22284", "title": "结构稀疏转换矩阵以增强状态空间模型中的状态跟踪能力", "title_en": "Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models", "authors": "Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi", "background": "现代状态空间模型（SSMs）通常使用转换矩阵，这虽然提高了计算效率，但限制了模型的表达能力，特别是在表示有限状态自动机（FSA）方面。虽然无结构转换矩阵从表达性角度看最佳，但在适度的状态数量下也会导致计算和内存成本过高。因此，研究人员探索了一种能够以最优状态数量和深度跟踪FSA状态的同时保持计算成本与对角SSM相当的方法。", "innovation": "本文提出了一种结构化和稀疏的转换矩阵参数化方法，称为PD-SSM。该方法将转换矩阵参数化为列一对一矩阵（P）和复数对角矩阵（D）的乘积，使得并行扫描的计算成本与状态数量线性相关。理论上，该模型是BIBO稳定的，并且可以使用单个层次数量为N的维度和N×N的线性读取出任何N状态的FSA，相较于目前的结构化SSM保证，有着显著的改进。", "conclusion": "实验结果显示，PD-SSM在多种FSA状态跟踪任务上显著优于现有的现代SSM变体。在多类时间序列分类中，其性能与神经控制微分方程相媲美，后者专门为时间序列分析而构建。最后，作者将PD-SSM集成到混合Transformer-SSM架构中，并证明该模型能够有效地跟踪编码为一组变长英文句子的复杂FSA的各个状态。相关代码可在给定的URL中获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22343", "html_url": "https://arxiv.org/abs/2509.22343", "title": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "title_en": "Transformers Can Learn Connectivity in Some Graphs but Not Others", "authors": "Amit Roy,Abulhair Saparov", "background": "当前，研究人员关注变压器模型推理传递关系的能力。虽然过去的研究侧重于评估变压器在上下文提示中提供示例的情况下能否学习推理传递性，但它们推理传递关系的能力是否可以通过训练示例来提高以及规模扩展对这种能力的影响尚未被充分探索。本文通过生成不同规模的有向图来培训不同大小的变压器模型，并评估其在不同图规模下推理传递关系的能力。", "innovation": "本研究为理解变压器在有向图中学习推理连通性的能力提供了一种新的方法，并指出了不同的图结构对变压器学习连通性任务的影响。", "conclusion": "我们的研究结果表明，变压器有能力在网格状有向图中学习连通性，其中每个节点可以嵌入到低维子空间中，连通性可以从节点的嵌入中推断出来。边缘维度对于变压器学习连通性任务的影响很强，较高维度的网格图更难处理。此外，我们发现随着模型规模的增加，变压器在网格图中推理连通性的泛化能力增强，但在非网格图且包含许多不连通组件的情况下，变压器很难学习连通性任务，尤其是在组件数量众多的时候。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22341", "html_url": "https://arxiv.org/abs/2509.22341", "title": "防止过度参数化下的模型崩塌：插值学习和岭回归的理想混合比例", "title_en": "Preventing Model Collapse Under Overparametrization: Optimal Mixing Ratios for Interpolation Learning and Ridge Regression", "authors": "Anvit Garg,Sohom Bhattacharya,Pragya Sur", "background": "生成模型在经过多次训练后，会因为反复使用其生成输出而导致性能下降，这种现象被称为模型崩塌。本文研究了在每次迭代中混合新鲜真实标签和上一轮迭代中模型生成标签的设置下的过度参数化线性回归中的这种效果。", "innovation": "本文推导了最小-$\boldsymbol{\text{ℓ}_2}$范数插值和岭回归在这类迭代方案下的精确泛化误差公式。研究揭示了最优混合权重的性质，该权重可以最小化长期预测误差并防止模型崩塌。对于最小-$\boldsymbol{\text{ℓ}_2}$范数插值，作者证明了最优真实数据比例在较为一般的情形下会收敛于黄金比例的倒数。对于岭回归，作者进一步分析了两种常见的模型类别——随机效应模型和尖峰协方差模型，发现谱几何学决定了最优权重。无论是随机效应模型还是尖峰协方差模型，以及对于各向同性特征，最优混合比例应至少为1/2，这表明应该更偏重真实数据而非合成数据。", "conclusion": "本文的研究结果通过广泛的模拟得到了验证，同时揭示了防止模型崩塌的策略及其最优的混合比例。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22355", "html_url": "https://arxiv.org/abs/2509.22355", "title": "多通道卷积神经量子嵌入", "title_en": "Multi-channel convolutional neural quantum embedding", "authors": "Yujin Kim,Changjae Im,Taehyun Kim,Tak Hur,Daniel K. Park", "background": "量子监督学习（QSL）在经典数据中的应用涉及将数据嵌入量子希尔伯特空间，并优化量子电路参数以训练测量过程。QSL的有效性受到量子嵌入选择的影响。在本研究中通过引入一种经典-量子混合方法，针对标准量子计算电路模型的限制，优化了量子嵌入以适用于通用多通道数据。", "innovation": "提出了经典的量子混合方法，用于优化量子嵌入，超越了标准量子计算电路模型的限制，特别适用于通用多通道数据。并在CIFAR-10和Tiny ImageNet数据集上进行了模型性能的基准测试，并提供了指导模型设计与优化的理论分析。", "conclusion": "通过基准测试和理论分析，展示了该方法的有效性和适用性，特别是在多通道数据上的性能提升。该研究为量子机器学习中的数据嵌入选择提供了新的思路和方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22130", "html_url": "https://arxiv.org/abs/2509.22130", "title": "通过offline RL和大语言模型协作实现多代理路径规划", "title_en": "Multi-Agent Path Finding via Offline RL and LLM Collaboration", "authors": "Merve Atasever,Matthew Hong,Mihir Nitin Kulkarni,Qingpei Li,Jyotirmoy V. Deshmukh", "background": "多代理路径寻找（MAPF）对于机器人技术和物流应用至关重要，但由于其组合复杂性和现实环境中固有的部分可观测性，它面临显著的挑战。现有的去中心化强化学习方法通常存在两个重大问题：一、代理行为往往过于自私，导致频繁碰撞；二、对复杂通信模块的依赖导致训练时间过长，有时高达几周。", "innovation": "提出了一种基于决策变换器（DT）的高效去中心化规划框架，利用离线强化学习显著缩短了从数周到仅数小时的训练时间。该方法能够有效处理长期信用分配，并在稀疏和延迟奖励的场景中显著提升表现。此外，通过整合大语言模型（GPT-4o）动态指导代理策略，增强了适应性，并在多变环境下的性能得到了显著提升。", "conclusion": "通过决策变换器（DT）和大语言模型（GPT-4o）的结合，不仅显著减少了训练时间，还增强了适应动态环境变化的能力，从而显著提升了多代理路径规划的性能和适应性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22124", "html_url": "https://arxiv.org/abs/2509.22124", "title": "在学习中整合先验知识：教师-学生框架下的随机矩阵研究", "title_en": "Incorporating priors in learning: a random matrix study under a teacher-student framework", "authors": "Malik Tiomoko,Ekkehard Schnoor", "background": "正则化线性回归是机器学习的核心，但在具有信息性先验的情下的高维表现仍未被充分理解。本文通过最大后验概率（MAP）回归和高斯先验，结合域信息初始化，提供了训练和测试风险的首次精确渐进表征。该框架统一了岭回归、最小二乘法以及先验导向的估计，并运用随机矩阵理论，给出了风险的封闭式公式，揭示了先验偏差-方差-先验之间的权衡，解释了双重下降现象，并量化了先验的不匹配度。", "innovation": "本文发展了一种整合先验知识的学习框架，利用了随机矩阵理论，得出了风险的封闭式公式，详尽刻画了先验偏差-方差-先验之间的权衡关系，能够解释双重下降现象，并提供了衡量先验不匹配度的方法。此外，作者还给出了测试风险的最小化解，便于直接估算最优正则化参数。研究结果精确模拟得很高，说明先前的理论具有高度可操作性。", "conclusion": "本文从贝叶斯先验、经典正则化和现代渐近性方面连接了相关理论，提供了对带有结构化先验知识的学习结果的深刻理解，并为实际应用提供了实用指南。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22399", "html_url": "https://arxiv.org/abs/2509.22399", "title": "在脑MRI扫描中利用逻辑 tensor 网络整合背景知识进行医学语义分割", "title_en": "Integrating Background Knowledge in Medical Semantic Segmentation with Logic Tensor Networks", "authors": "Luca Bergamin,Giovanna Maria Dimitri,Fabio Aiolli", "background": "在医学图像分析中，语义分割是一项基础任务，它能够帮助放射科医生识别图像中的物体，从而辅助医疗决策。近年来，深度学习在这一领域的应用取得了显著进展，尤其是在噪声和伪影存在的情况下，也能够进行有效的缩放。然而，现有的系统仍存在不足之处，因此有研究尝试通过将常见的医学知识融入到分割模型的损失函数中来提升模型性能。", "innovation": "为了解决上述问题，本文引入了逻辑 Tensor 网络（Logic Tensor Networks，LTNs），利用一阶逻辑（First-order logic，FOL）语法规则来编码医学背景知识。这些规则不仅包括分割结果的形状约束，还包括不同分割区域之间的关系。本文尝试将LTNs与SwinUNETR结合，在端到端框架中实现语义分割。经过实验验证，本文提出的方法在有限训练数据下，可以显著提升分割的基线性能。", "conclusion": "尽管本文的方法尚处于初步阶段，但研究团队认为神经符号方法具有足够的通用性，可以适应和应用于其他医学语义分割任务。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22467", "html_url": "https://arxiv.org/abs/2509.22467", "title": "CausalKANs：使用柯尔莫哥洛夫-阿诺尔德网络进行解释性治疗效应估计", "title_en": "CausalKANs: interpretable treatment effect estimation with Kolmogorov-Arnold networks", "authors": "Alejandro Almodóvar,Patricia A. Apellániz,Santiago Zazo,Juan Parras", "background": "深度神经网络在估计非均匀治疗效果方面达到了最先进的性能，但它们的不透明性限制了在敏感领域（如医学、经济学和公共政策）中的信任和使用。本文探讨了基于现有高性能因果神经架构构建的一种新框架，即 causalKANs，旨在将条件平均治疗效果（CATEs）的神经估算器转换为柯尔莫哥洛夫-阿诺尔德网络（KANs），通过引入剪枝和符号简化，causalKANs 保留了预测准确性的同时，还提供了可解释的闭合形式公式。", "innovation": "causalKANs 框架结合使用柯尔莫哥洛夫-阿诺尔德网络（KANs）来估计治疗效应，通过剪枝和符号简化，使得模型在保持预测准确性的同时具有可解释性。实验结果显示，causalKANs 在 CATE 错误指标上与神经基线相当，即使简单的 KAN 变种也取得了具有竞争力的性能，这种权衡了准确性和解释性之间的方法设定较好的性能。由此可知，这种结合可靠性和分析访问性的方法提供了一种可审计的、以闭合形式表达和可解释的图表支持的估计器，有助于在高风险环境中的个体化决策信任。", "conclusion": "causalKANs 提供了可审计的、解释性良好且以闭合形式表示的估计器和可解释的图表，这在建立高风险环境中的个性化决策信任方面具有显著优势。代码已开源，可进行重复实验，链接为 <this https URL>。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22504", "html_url": "https://arxiv.org/abs/2509.22504", "title": "估计语言模型智能体的赋权", "title_en": "Estimating the Empowerment of Language Model Agents", "authors": "Jinyeop Song,Jeff Gore,Max Kleiman-Weiner", "background": "随着语言模型（LM）代理变得更为强大并拥有更广泛的真实世界工具访问权限，对代理能力进行可扩展的评估框架的需求日益增长。然而，传统的基于基准的评估方法在设计上成本高昂，需要人类设计师提出有效的任务以转化为关于通用模型能力的洞见。本研究旨在提出基于物理学中的信息论评价语境——赋权（empowerment），这种方法是指代理行为与其未来状态之间的互信息，是一种开放性地评估LM代理的新方法。", "innovation": "提出了基于赋权的评价框架和算法EELMA（Estimating Empowerment of Language Model Agents），该算法通过多轮次文本交互近似估计有效的赋权。研究验证了EELMA在语言游戏和扩展的现实网络浏览场景中的有效性。通过这些场景研究了环境复杂性和智能体因素（如思维链条、模型规模和记忆长度）对估计赋权的影响。", "conclusion": "这些结果表明，赋权可以作为通用评估和监控LM代理在复杂开放环境中的一种有吸引力的度量标准。赋权与平均任务表现密切相关，高赋权时刻往往代表了普遍能力的关键节点。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22169", "html_url": "https://arxiv.org/abs/2509.22169", "title": "拖动GAN空间：生成对抗网络的潜在空间探索与控制", "title_en": "DragGANSpace: Latent Space Exploration and Control for GANs", "authors": "Kirsten Odendaal,Neela Kaushik,Spencer Halverson", "background": "这篇论文结合了StyleGAN、DragGAN和主成分分析（PCA），以增强GAN生成图像的潜在空间效率和可控性。StyleGAN 提供了结构化的潜在空间，DragGAN 使图像操作更加直观，而 PCA 通过减少维度和促进跨模型对齐，使潜在空间探索更加简洁和可解释。研究者将这些技术应用于高质量的动物面孔数据集（AFHQ），发现结合PCA降维与DragGAN框架进行图像操作，能在保持性能的同时提高优化效率。特别是在较浅的潜在空间（W+层 = 3）中引入PCA，可以一致地减少总优化时间，同时保持或提升生成图片的视觉质量和结构相似性指数（SSIM）。此外，该方法也展示了在两个训练目标相似但具有差异数据域的StyleGAN模型（AFHQ-Dog和AFHQ-Cat）生成的图像之间进行对齐的能力，并实现了对齐图像的潜在空间控制，以直观且可解释的方式操作这些图像。这些发现揭示了广泛图像合成和编辑应用中高效和可解释的潜在空间控制的可能性。", "innovation": "该研究提出了将PCA结合到DragGAN的W+层中，显著提高优化效率。特别地，浅层潜在空间的优化时间显著减少，同时图像的视觉质量和SSIM指数有所提升。此外，展示了对两个训练数据略有不同的StyleGAN模型生成图像进行对齐，并实现直观的潜在空间控制的能力。", "conclusion": "该研究证明了通过集成PCA与DragGAN框架的方法，可以有效提高GAN生成图像的潜在空间效率和可控性，尤其在浅层潜在空间中表现明显。该方法不仅保持了图像的质量，还显著减少了优化时间，为多种图像合成和编辑应用提供了有效的潜在空间控制手段。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "临床不确定性影响机器学习评估", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集标签通常是不确定的，因为注释者意见不一且不同案例之间的信心不一致。典型聚合方法如多数投票隐藏了这种差异性。简单实验表明，在医疗成像基准上，考虑二元标签的信心会显著影响模型的排名。因此，论文提出了使用直接作用于分布的概率性度量来显式地考虑注释的不确定性，这些方法不依赖于生成注释的过程，无论是简单的计数、主观的信心评分还是概率反应模型。这种度量方法计算成本低廉，因为在将实例按模型得分排序后，可以通过线性时间实现的封闭形式表达式进行计算。", "innovation": "论文提出了一种新的度量方法，可以显式地利用不确定性对临床数据进行评估。这种概率性度量方法可以独立于注释生成过程计算，是否是简单的计数、主观的信心评分或概率反应模型都可以适用，且计算成本低廉，可以快速得出结果。", "conclusion": "论文呼吁社区公开临床数据的原始注释，并采用能够考虑到不确定性的评估方式，这样性能估计可以更好地反映临床数据。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22300", "html_url": "https://arxiv.org/abs/2509.22300", "title": "HiGS: 基于历史指导的插件即用型增强的扩散模型采样技术", "title_en": "HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models", "authors": "Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber", "background": "尽管扩散模型在图像生成方面取得了显著进展，但其输出仍可能显得不够真实且缺乏细节，尤其是在使用较少的神经网络函数评估次数（NFEs）或较低的引导比例时。因此，本研究旨在解决此类问题，提出了一种基于历史指导的新型采样技术（HiGS），该技术通过将最近的模型预测整合到每次推理步骤中来提升采样质量并提高效率。", "innovation": "HiGS 利用当前预测值与过去预测值加权平均值之间的差异来引导采样过程，使其更倾向于生成更真实且具有更好细节和结构的输出。与现有方法相比，HiGS 不需要额外的训练或调优，即可无缝集成到现有的扩散模型框架中，不会增加额外的计算负担。广泛的实验表明，HiGS 在不同模型和架构下以及不同采样预算和引导比例下，都能显著提升图像质量。尤其是使用预训练的SiT模型，在仅使用30步采样的情况下（而不是标准的250步），HiGS 能够实现无引导下的ImageNet生成FID值达到1.61的新纪录。", "conclusion": "因此，HiGS 提供了一种插件即用型增强技术，可以加快生成速度并提高生成图像的保真度。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22318", "html_url": "https://arxiv.org/abs/2509.22318", "title": "NIFTY: 一种非局部图像流匹配方法用于纹理合成", "title_en": "NIFTY: a Non-Local Image Flow Matching for Texture Synthesis", "authors": "Pierrick Chatillon,Julien Rabin,David Tschumperlé", "background": "本文解决了基于示例的纹理合成问题。背景包括现有方法的限制，如非局部函数匹配或局部像素匹配方法的不足，包括初始条件差或视觉伪影等问题，以及传统的基于小块的纹理优化技术的局限性。这些方法往往需要复杂的模型训练过程，且效果受限。因此，如何发展既能保持传统方法优点又避免其缺陷的新方法是该领域研究的关键挑战。", "innovation": "本文提出了NIFTY（Non-Local Image Flow Matching），这是一种结合了基于卷积神经网络训练的扩散模型和经典基于小块的纹理优化技术的混合框架。不同于传统的需要进行神经网络训练的方法，NIFTY 是一种非参数流匹配模型，基于非局部小块匹配构建。这一创新解决了传统方法的一些问题，如初始化差和视觉伪影等，同时避免了新的复杂训练过程。实验结果表明，NIFTY 在与文献中代表性方法的比较中表现出更高的有效性。", "conclusion": "实验结果证明了所提出方法的有效性。NIFTY模型能够在保持传统基于小块方法优点的同时避免其缺点，如初始条件差或视觉伪影等问题。此外，NIFTY 不需要进行复杂的神经网络训练，简化了模型的构建过程。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22506", "html_url": "https://arxiv.org/abs/2509.22506", "title": "在提示语义任务空间中表示LLMs", "title_en": "Representing LLMs in Prompt Semantic Task Space", "authors": "Idan Kashani,Avi Mendelson,Yaniv Nemcovsky", "background": "大语言模型（LLMs）在各种任务中取得了显著成果，公共存储库中包含了大量预训练模型。因此，为特定任务确定最优的LLM是一个重大挑战。尽管前人的工作建议通过学习LLM表示来解决这个问题，但这些方法在扩展性和易用性方面存在局限，需要重新训练以包含更多模型和数据集，且生成的表示难以解释。", "innovation": "本研究提出了一种训练免费的方法，将大语言模型表示为提示语义任务空间内的线性算子，提供了一个高度可解释的模型应用表示。该方法通过封闭形式计算几何属性，确保卓越的扩展性和对动态扩展存储库的实时适应性。", "conclusion": "通过该方法在成功预测和模型选择任务中的表现，表明该方法能实现竞争力或最先进的结果，特别是在样本外情况下的突出性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22380", "html_url": "https://arxiv.org/abs/2509.22380", "title": "使用最优传输的多维不确定性量化", "title_en": "Multidimensional Uncertainty Quantification via Optimal Transport", "authors": "Nikita Kotelevskii,Maiya Goloburda,Vladimir Kondratyev,Alexander Fishkov,Mohsen Guizani,Eric Moulines,Maxim Panov", "background": "大多数不确定性量化（UQ）方法提供单一的标量值来衡量模型可靠性，但不同的不确定度度量可以提供关于预测置信度的互补信息。即使针对同一类型的不确定度（例如，基于集合和密度的先验不确定度度量）也可能捕获不同的失效模式。本文通过将互补的UQ度量堆叠成向量来从多维度出发，采用最优传输方法计算Monge-Kantorovich秩，对不确定性进行排序，获得更多不确定性的预测会被赋予更高的秩。", "innovation": "提出了一种新的VecUQ-OT算法，使用熵正则化最优传输，通过学习分布内数据的分数向量映射，设计能够应用于未见过的输入（包括分布外情况）的模型，而无需重新训练。此框架灵活支持非加性不确定度融合，适用于多种下游任务，展示了在单个度量失败时的高效率。", "conclusion": "VecUQ-OT算法在合成数据、图像数据和文本数据上的应用表明，它能够准确地对不确定性进行排序，并支持多种下游任务，如选择性预测、错误分类检测、分布外检测和选择性生成。相关代码可以在指定的GitHub链接中找到。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22531", "html_url": "https://arxiv.org/abs/2509.22531", "title": "Debiased Front-Door Learners for Heterogeneous Effects", "title_en": "Debiased Front-Door Learners for Heterogeneous Effects", "authors": "Yonghan Jung", "background": "在观测环境中，如果治疗和结果共享不可测量的混杂因素，但观测中介不受影响，利用路径分离法则（Front-door，FD）可以识别通过中介的因果效应。本文探讨了在FD识别条件下异质性治疗效应（HTE）的问题，提出两种去偏差学习方法：FD-DR-Learner和FD-R-Learner。", "innovation": "本文引入了两种去偏差学习方法——FD-DR-Learner和FD-R-Learner，这两者在阻得函数收敛速度慢至n^-1/4的情况下也能达到快速、近乎先验的性能（即，性能与知道先验知识的先验知识相当）。文中提供了错误分析来证实去偏差性，并在合成研究和使用Fatality Analysis Reporting System (FARS) 数据集的真实世界案例研究中展示了稳健的实证表现。", "conclusion": "这些结果表明，提出的去偏差学习方法在FD场景中提供了可靠且样本高效的HTE估计。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22410", "html_url": "https://arxiv.org/abs/2509.22410", "title": "NeuroScalar: 一种快速、准确且适用于实际硬件的深度学习框架用于微架构级性能预测", "title_en": "NeuroScalar: A Deep Learning Framework for Fast, Accurate, and In-the-Wild Cycle-Level Performance Prediction", "authors": "Shayne Wadle,Yanxin Zhang,Vikas Singh,Karthikeyan Sankaralingam", "background": "传统的微处理器设计评估受限于依赖于预设不具代表性的基准测试的慢速、精确周期模拟器。为了克服这些限制，本文介绍了用于生产硬件的高保真性的新颖深度学习框架，旨在实现真实环境下快速评估未来硬件性能的目标。", "innovation": "本文的核心贡献在于提出了一种深度学习模型，该模型基于微架构无关特征，可以预测假设处理器设计的周期级性能。此外，该框架包含一个轻量级的硬件日志收集器和合理的采样策略，以最小化用户的影响。通过与GPU相比，自设计的Neutrino片上加速器使性能提升了85倍，同时在通用GPU上实现了每秒5百万条指令的仿真速度，且只造成了0.1%的性能开销。", "conclusion": "本文框架能够实现大规模真实的硬件性能分析和A/B测试，例如使用实际应用进行广泛的测试，从而能够更准确、更快地评估处理器设计。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22442", "html_url": "https://arxiv.org/abs/2509.22442", "title": "学习控球：组合长周期篮球动作的策略", "title_en": "Learning to Ball: Composing Policies for Long-Horizon Basketball Moves", "authors": "Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu", "background": "对于使用强化学习方法学习管控较长时间且多阶段任务（例如篮球操作）的控制策略来说，实现无缝技能组合和过渡仍然是极具挑战性的。长周期任务通常由具有明确目标的不同子任务构成，中间阶段的过渡任务目标不明确但对任务的最终成功至关重要。现有方法如专家混合和技能链在处理个体策略不共享大量相同探索状态或缺乏明确始末状态的任务时遇到困难。", "innovation": "在本文中，我们提出了一个新颖的策略整合框架，以实现在具有未明确中间状态的多阶段长期任务中广泛不同的运动技能的组合。在此基础上，我们进一步提出了一个高层次的柔性和路由机制，以实现子任务之间的无缝且可靠的过渡。我们对一系列基本的篮球技能及具有挑战性的过渡过程进行了评估，表明通过我们的方法训练得到的策略可以有效地控制模拟角色与球互动，并完成由实时用户指令指定的长周期任务，无需依赖球轨迹的参考。", "conclusion": "我们的框架能够有效解决长周期多阶段任务中由于技能组合和过渡不明确所带来的挑战。通过对篮球技能的学习，展示了在类似任务中的应用成效，提高了策略在实际任务中的鲁棒性和适应性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22459", "html_url": "https://arxiv.org/abs/2509.22459", "title": "通用逆蒸馏方法用于具有实时数据监督的匹配模型", "title_en": "Universal Inverse Distillation for Matching Models with Real-Data Supervision (No GANs)", "authors": "Nikita Kornilov,David Li,Tikhon Mavrin,Aleksei Leonov,Nikita Gushchin,Evgeny Burnaev,Iaroslav Koshelev,Alexander Korotin", "background": "现代扩散、流和其他匹配模型虽然生成质量出众，但推断速度较慢，因为它们需要多步迭代生成。近期的一些蒸馏方法通过用预训练的教师模型指导，训练高效的一步生成器来解决这一问题。然而，这些方法通常只能应用于特定框架，例如仅适用于扩散或仅适用于流模型。此外，这些方法通常是无数据的，为了利用真实数据，需要额外使用复杂的对抗训练并增加额外的判别模型。", "innovation": "作者提出了一种名为RealUID的通用蒸馏框架，适用于所有匹配模型，能够在不使用生成对抗网络(GANs)的情况下无缝集成真实数据到蒸馏过程中。RealUID方法提供了一个简单的理论基础，涵盖了先前对流匹配和扩散模型的蒸馏方法，并扩展到它们的修改，例如桥梁匹配和随机插值。这种方法解决了蒸馏方法通常局限于特定框架的限制，同时提供了一种无GAN的解决方案来直接利用实时数据。", "conclusion": "总的来说，本文提出的方法通过无缝整合真实数据到所有匹配模型的蒸馏过程中，解决了现有蒸馏方法的局限性，并提供了一种无需GAN的解决方案来直接利用实时数据。这种方法为匹配模型的进一步优化和实际应用提供了新的可能性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22551", "html_url": "https://arxiv.org/abs/2509.22551", "title": "ConQuER: 模块化架构用于IQP量子生成模型的控制和偏见缓解", "title_en": "ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models", "authors": "Xiaocheng Zou,Shijin Duan,Charles Fleming,Gaowen Liu,Ramana Rao Kompella,Shaolei Ren,Xiaolin Xu", "background": "基于瞬时量子多项式（IQP）电路的量子生成模型显示了在学习复杂分布的同时保持经典可训练性的巨大潜力。然而，当前的实现存在两大关键限制：生成输出缺乏可控性以及严重偏向于某些预设模式。", "innovation": "我们提出了一种可控量子生成框架（ConQuER），通过模块化电路架构解决了这两个挑战。ConQuER嵌入了一个轻量级的控制器电路，可以直接与预训练的IQP电路结合使用，以精确控制输出分布而无需全重新训练。基于IQP的优势，我们的方案能够在最低参数和门操作开销的情况下，精确控制诸如汉明重量分布等属性。此外，我们的方案通过数据驱动优化，将隐式控制路径嵌入到底层IQP架构中，显著减少了在结构化数据集上的生成偏见。", "conclusion": "ConQuER保留了高效的经典训练特性和高扩展性。我们在多个量子态数据集上实验验证了ConQuER，证明了其优越的控制精度和平衡的生成性能，并且与原IQP电路相比，仅具有很低的开销成本。我们的框架填补了量子计算优势与可控制生成建模实际需求之间的差距。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22596", "html_url": "https://arxiv.org/abs/2509.22596", "title": "超越亚模性目标的多代理在线协调的高效策略学习", "title_en": "Effective Policy Learning for Multi-Agent Online Coordination Beyond Submodular Objectives", "authors": "Qixin Zhang,Yan Sun,Can Jin,Xikun Zhang,Yao Shu,Puning Zhao,Li Shen,Dacheng Tao", "background": "该论文研究多代理在线协调（MA-OC）问题，重点关注具有亚模性目标函数的情况。传统的策略学习算法在这种情况下有效，但针对非亚模性的弱亚模性目标的算法较为匮乏。论文提出了两个有效的策略学习算法来解决这一问题。", "innovation": "1. 提出了第一个算法MA-SPL，不仅能够达到亚模性目标下的(1-1/e)最佳近似保证，还能处理未探索的α-弱亚模性和(γ,β)-弱亚模性场景。\n2. 引入了完全无参数的MA-MPL算法，保持相同的近似比。\n3. 开发了一种新颖的基于策略的连续松弛技术，能够提供无损的约简方案，适用于任何集合函数。", "conclusion": "通过广泛的模拟实验验证了所提出的算法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22516", "html_url": "https://arxiv.org/abs/2509.22516", "title": "TrueGradeAI：透明且具解释性的抗偏见AI数字评估系统", "title_en": "TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments", "authors": "Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla", "background": "传统的纸质考试存在大量的缺点，如过度使用纸张、复杂的物流管理、评分延迟以及评分者主观性等。现有的平板电脑考试系统虽然进行了响应的数字化，但主要关注于响应的数字化处理，而未充分考虑自动化解释、偏见减少和评估可追溯性的问题。", "innovation": "TrueGradeAI是一种由AI驱动的数字考试框架，创新之处在于利用笔输入在安全平板上以及通过基于转换器的光学字符识别实现手写内容的数字化。它通过检索增强的流水线评分过程，结合教师解决方案、缓存层和外部参考，使大型语言模型能够进行有明确证据支持的评分。它在自动化的解释性、偏见规避以及透明可审计的评分轨迹方面向前迈进了一步，提供了纸笔考试的数字化解决方案，同时保留了手写痕迹。", "conclusion": "该框架通过结合手写保留与可扩展且透明的评估，减少了环境成本，加速了反馈循环，并逐步构建了一个可重复使用的知识库。通过这种方式，TrueGradeAI有效地减轻了评分偏见，提升了评估的公平性，是数字考试领域的一个重要进展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22472", "html_url": "https://arxiv.org/abs/2509.22472", "title": "评估大型语言模型在多语言法律推理中的局限性", "title_en": "Evaluating the Limits of Large Language Models in Multilingual Legal Reasoning", "authors": "Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel", "background": "在大型语言模型（LLMs）主导的时代，理解LLMs的能力和局限性非常重要，特别是在法律等高风险领域。当前，虽然LLMs如Meta的LLaMA、OpenAI的ChatGPT、Google的Gemini等已逐渐融入法律工作流程，但在多语言、司法辖区多样性和对抗性情境下的性能表现仍需进一步研究。该研究通过评估LLaMA和Gemini在多语言法律和非法律基准测试中的表现，并通过字符和词级扰动测试其在法律任务中的对抗鲁棒性。研究采用LLM-as-a-Judge方法进行人类对齐评价，并提出了一种开源、模块化的评估管道，用于支持任意组合的LLM和数据集的多语言、任务多样性基准测试，重点关注法律任务，包括分类、摘要、开放问题和推理能力测试。研究发现，在法律逻辑推理基准测试（如LEXam）中LLMs的成绩通常低于50%，而通用任务（如XNLI）则超过70%。另外，尽管英语通常获得更稳定的结果，但不总是导致更高的准确性。语言提示敏感性和对抗性漏洞也因语言不同而存在。研究还发现，性能与语言的句法相似性到英语之间的相关性。此外，研究发现，LLaMA的表现弱于Gemini，后者在相同任务中的平均优势约为24个百分点。尽管新模型有所改进，但在关键、多语言法律应用中的可靠部署仍面临挑战。", "innovation": "该研究通过LLM-as-a-Judge方法进行人类对齐评价，并提出了一种开源、模块化的评估管道，支持多语言、任务多样性基准测试。此外，通过多语言数据和对抗性测试评估LLMs在法律任务中的性能，并发现语言提示敏感性、对抗鲁棒性等问题。研究表明LLaMA在关键法律任务上的表现差于Gemini。对新模型而言，尽管取得了改进，但可靠应用于复杂法律情境中仍有待解决的挑战。", "conclusion": "研究确认了法律任务对LLMs提出了显著挑战，表现通常低于50%。尽管英语可能导致更稳定的结果，但不一定带来更高的准确性。语言提示敏感性和对抗鲁棒性问题是普遍存在的。还发现了语言性能与其句法相似性到英语的关联。LLaMA在关键法律任务中的表现不及Gemini。尽管新模型有所改进，但在关键、多语言法律应用中的可靠部署仍面临挑战。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22529", "html_url": "https://arxiv.org/abs/2509.22529", "title": "基于平滑的配准预测以平衡效率和可解释性", "title_en": "Smoothing-Based Conformal Prediction for Balancing Efficiency and Interpretability", "authors": "Mingyi Zheng,Hongyu Jiang,Yizhou Lu,Jiaye Teng", "background": "配准预测（CP）是一种无需分布假设的框架，用于构建统计上严谨的预测集。尽管一些流行的变体如CD-split提高了CP的效率，但它们通常生成由多个不连续子区间组成的预测集，这使得预测结果难以理解和解释。本文通过引入平滑操作到CP框架中，旨在提供一种新的变体SCD-split，以提高预测集的可解释性，同时保持与CD-split相当的效率和精度.", "innovation": "本文提出了SCD-split，通过在CP框架中引入平滑操作，旨在合并子区间，从而生成更容易解释的预测集。实验结果表明，与CD-split相比，SCD-split在保持覆盖率和区间长度相似的情况下，有效地平衡了区间长度和不连续子区间的数量。理论分析表明，在特定条件下，SCD-split能减少不连续子区间的数量.", "conclusion": "实验和理论分析显示，SCD-split在结构可解释性和预测效率之间实现了良好的平衡，是CP的一种改进版本，特别适合需要高可解释性预测的场景。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22549", "html_url": "https://arxiv.org/abs/2509.22549", "title": "网络参数化家族的度量标准", "title_en": "Metrics for Parametric Families of Networks", "authors": "Mario Gómez,Guanqun Ma,Tom Needham,Bei Wang", "background": "本文介绍了一种分析以参数家族形式建模的数据的一般框架。基于Gromov-Wasserstein最优传输的变种，定义了一种用于对比此类参数数据的参数化Gromov-Wasserstein距离族，包括集体运动产生的时空可变度量空间、随时间演变的加权社交网络以及随机图模型。", "innovation": "文章提出了一种创新的方法，通过参数化的Gromov-Wasserstein距离族来对比参数化族网络，建立了这些距离的基础性质，证明了它们包含文献中的一些现有度量，并提出了可计算的下界以及实验估计生成模型的一致性近似，同时与随机图论中常用的图统计量联系起来，提供了理论上的逼近保证。", "conclusion": "最终，通过一系列数值实验展示了本文框架的实际应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22518", "html_url": "https://arxiv.org/abs/2509.22518", "title": "REMA：理解大型语言模型复杂推理与失败机制的统一推理流形框架", "title_en": "REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model", "authors": "Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen", "background": "在可解释性研究中，理解大语言模型（LLMs）如何执行复杂推理以及它们的失败机制是具有挑战性的。为此，本文提出了一种可测量的几何分析视角，定义了推理流形的概念，这是一种由所有正确推理生成的内部表示构成的潜在低维几何结构。这种结构可以被视为模型已学习的有效思维路径的体现，这些路径能够有效地解决给定任务。", "innovation": "本文提出了REMA框架，通过定量比较错误和正确的推理样本的内部模型表示的空间关系，来解释推理失败的起源。具体来说，REMA首先通过计算每个错误表示与正确表示拟合流形的最近邻距离来量化每个错误表示的几何偏差，从而提供一个统一的失败信号。然后通过跟踪该偏差指标在网络层中并将其与正确表示内部波动的基线进行比较，以确定算法开始出现偏差的关键点。", "conclusion": "在各种语言和多模态模型和任务上的广泛实验表明，推理流形具有低维性质，错误和正确推理表示之间的可分性很高。研究结果还验证了REMA框架在分析推理失败根源方面的有效性。本研究将抽象的推理失败与表示中的可测量几何偏差联系起来，为深入理解和诊断黑盒模型的内部计算过程提供了新的途径。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22553", "html_url": "https://arxiv.org/abs/2509.22553", "title": "通过拓扑排序、剪枝和分离进行的线性因果表示学习", "title_en": "Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement", "authors": "Hao Chen,Lin Liu,Yu Guang Wang", "background": "因果表示学习(CRL)因能够通过利用现代数据集的异质性将潜在复杂的数据生成机制分解为可因果解释的潜在特征而引起了因果推断和人工智能领域的广泛关注。现有的线性CRL方法通常依赖于严格的假设，比如单节点干预数据的可获得性或潜在特征和外生测量噪声分布的严格限制。然而，在某些情况下，这些前提条件可能难以满足。本文在既简化这些假设又仍能恢复潜在因果特征方面有所贡献，特别是在较弱的环境异质性和数据生成分布假设下。", "innovation": "本文提出了一种新的线性CRL算法，该算法在较弱的环境异质性和数据生成分布假设下仍能恢复潜在因果特征，不同于大多数现有的线性CRL方法。通过合成实验和大型语言模型的可解释性分析，验证了新算法在有限样本中优于竞争方法，并探讨了其将因果性整合到AI中的潜力。", "conclusion": "本文提出了一种新的线性CRL算法，该算法在较少的前提条件下仍能恢复潜在的因果特征，通过合成实验和大型语言模型的可解释性分析，展示了该方法在因果推断和人工智能中的优越性和潜在应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22563", "html_url": "https://arxiv.org/abs/2509.22563", "title": "近乎最优的利润最大化双边贸易中的遗憾界", "title_en": "Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade", "authors": "Simone Di Gregorio,Paul Dütting,Federico Fusco,Chris Schwiegelshohn", "background": "双边贸易模型旨在介于两个具有私有估值的卖方和买方之间，他们愿意交易一种商品。从经纪人的角度来看，考虑问题的遗憾最小化框架，在每个时间步，一个新的卖方和买方到达，经纪人需要提出一种机制，这种机制要具备激励兼容性和个体理性，最终最大化利润。", "innovation": "本文提出了一种学习算法，能够在卖方和买方的估值是固定且可能相关但未知分布的独立同分布(i.i.d.)情况下，提供几乎最紧的$\tilde{O}(\text{sqrt}(T))$遗憾界。进一步证明，在估值由对手生成的非站稳场景中，无法达到亚线性遗憾界。结果以最佳激励兼容性和个体理性机制为基准，分离了与双边贸易效率最大化问题的基准则固定后视价格的最佳单一数字标准。通过对机制利润进行精细的链分析证明了其近最优的收敛性。此外，展示了技术的普遍应用，为联合广告问题提供了几乎最优的结果。", "conclusion": "本文在双边贸易中达到了几乎最优的遗憾界，并证明了非平稳场景中的亚线性遗憾界无法实现。通过拟近最优机制和最优化速率的证明，展示了链分析技术在学习算法中的应用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22572", "html_url": "https://arxiv.org/abs/2509.22572", "title": "动态专家搜索：在混合专家LLM中增强测试时推理能力", "title_en": "Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time", "authors": "Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang", "background": "Test-Time Scaling (TTS) 方法通过在推理时增加额外计算来增强大型语言模型（LLMs）的推理能力，现有方法主要依赖于输出级采样，而忽视了模型架构的作用。主流的Mixture-of-Experts（MoE）LLMs中，通过改变激活专家的数量可以产生稳定准确性的互补解决方案集，揭示了一种新的、尚未充分探索的多样性来源。", "innovation": "提出了一种称为Dynamic Experts Search (DES) 的TTS策略，该策略将专家激活引入搜索空间中的可控维度。DES 包含两个关键组件：1) 动态 MoE，允许直接控制推理过程中的专家数量，以生成多样化的推理轨迹，而无需额外成本；2) 专家配置继承机制，在一条推理路径内保持一致的专家数量，而在不同运行中改变这些数量，从而在整个搜索过程中平衡稳定性和多样性。广泛的实验表明，DES 在 MoE 架构、验证器和推理基准（如数学、代码和知识）中都能显著优于现有TTS基准，提高了准确性和稳定性，没有额外成本。", "conclusion": " DES 作为一种实用且可扩展的架构感知TTS形式，证明了现代LLMs中的结构灵活性可以提升推理能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22613", "html_url": "https://arxiv.org/abs/2509.22613", "title": "语言模型规划中强化学习的益处与局限：一个理论视角", "title_en": "Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective", "authors": "Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen", "background": "最近，强化学习(RL)方法显著增强了大型语言模型(LLM)的规划能力，但其有效性的理论基础仍然不清楚。本文通过可处理的图基化抽象，探讨了RL的优势和局限性，重点关注策略梯度(PG)和Q学习方法。", "innovation": "本文通过理论分析揭示了监督微调(SFT)可能引入基于共现的虚假解，而RL主要是通过探索实现正确的规划，强调了探索在促进更好泛化中的作用。此外，还展示了PG在训练期间经历多样性坍缩，即使达到完美准确率后，多样性也保持下降。Q学习提供了两个关键优势：离策略学习和收敛时保持多样性。最后，采用我们的框架对现实世界规划基准Blocksworld进行验证，证实了这些行为在实践中的表现。", "conclusion": "研究结果表明，精心设计奖励对防止Q学习中的奖励作弊至关重要。Q学习在收敛时保持多样性，相比之下，PG在训练期间经历了多样性坍缩。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22598", "html_url": "https://arxiv.org/abs/2509.22598", "title": "从形式语言理论到统计学习：次正规语言的有限可观测性", "title_en": "From Formal Language Theory to Statistical Learning: Finite Observability of Subregular Languages", "authors": "Katsuhiko Hayashi,Hidetaka Kamigaito", "background": "该研究基于形式语言理论，探讨了次正规语言类别的性质。研究指出，当这些语言用决定性谓词表示时，它们是线性可分的。这一结论为使用简单线性模型进行学习提供了理论依据，并且这些次正规语言提供了对自然语言结构建模的严谨且可解释的基础。先前的研究已经证实，在无噪声条件下，这些类别的区分是完美的，并且在真实数据实验中，从这些次正规语言中学到的特征与已知的语言约束一致。", "innovation": "研究证明了所有标准的次正规语言类可以用简单的线性模型来学习，并且在无噪声条件下它们是完全线性可分的。这一发现表明，次正规语言可以为自然语言结构提供一个严格且可解释的建模基础。此外，实验表明从这些语言中学到的特征与已知的语言约束相对应，展示了次正规语言在统计学习中的应用价值。", "conclusion": "研究结果表明，次正规语言提供了自然语言结构建模的严谨和可解释的基础，并且使用简单的线性模型即可进行有效的学习。无噪声条件下的实验显示了完美的区分性，而真实的语言形态数据实验进一步验证了这一结论，显示出从这些语言中学到的特征与已知的语言规则一致。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22637", "html_url": "https://arxiv.org/abs/2509.22637", "title": "语言模型的变分推理", "title_en": "Variational Reasoning for Language Models", "authors": "Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang", "background": "本文介绍了一种将思考痕迹作为潜在变量的变分推理框架，通过变分推断优化它们。从证据下界（ELBO）出发，将其扩展为多轨迹目标，以获得更紧的边界，并提出了一种前向KL公式，该公式稳定了变分后验的训练。文章进一步表明，拒绝采样微调和二元奖励RL（包括GRPO）可以解释为局部前向KL目标，其中模型准确性自然地引入了隐式加权，揭示了之前未注意到的偏向于简单问题的偏差。", "innovation": "提出了一种将思考痕迹作为潜在变量的变分推理框架，通过扩展证据下界（ELBO）到多轨迹目标，并提出前向KL公式以稳定变分后验的训练。此外，文章还将拒绝采样微调和二元奖励RL（包括GRPO）解释为局部前向KL目标，并揭示了偏向于简单问题的偏差。", "conclusion": "我们的工作提供了一种原理性的概率视角，将变分推断与RL风格的方法统一起来，为提高语言模型的推理能力提供了稳定的优化目标。我们在Qwen 2.5和Qwen 3模型家族的广泛推理任务上实证验证了该方法。我们的代码可在指定的链接中获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22633", "html_url": "https://arxiv.org/abs/2509.22633", "title": "关于强化学习与人类反馈的高效在线探索", "title_en": "Towards Efficient Online Exploration for Reinforcement Learning with Human Feedback", "authors": "Gen Li,Yuling Yan", "background": "强化学习与人类反馈（RLHF）通过从人类偏好数据中学习奖励模型，并优化政策以促进优先响应，已经成为将大型语言模型（LLMs）与人类偏好对齐的主要范式。本文研究了在线RLHF中的探索原则，目的在于高效地收集新的偏好数据以改进奖励模型和政策。", "innovation": "通过分析现有的基于乐观探索算法的抽样协议，作者发现这些方法倾向于收集未能减少最具有信息性的奖励差异不确定性的比较。基于此，作者提出了一种新的探索方案，该方案的偏好查询旨在减少与政策改进最相关的奖励差异不确定性。此外，在多臂老虎机模型下，作者建立了误差界，该误差界与模型参数的比例次幂相关。", "conclusion": "本文提出了首个在线RLHF算法，该算法的误差界与所有模型参数的比例次幂相关，这是首次实现这一特性的尝试。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22630", "html_url": "https://arxiv.org/abs/2509.22630", "title": "StateX: 通过后训练状态扩展提高RNN回想能力", "title_en": "StateX: Enhancing RNN Recall via Post-training State Expansion", "authors": "Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "虽然基于Transformer的模型在语言建模方面表现出色，但由于处理长上下文时的高复杂性导致成本高昂，而递归神经网络（如线性注意力和状态空间模型）因其恒定的每令牌复杂性而受到欢迎。然而，这些递归模型在需要准确回想起长上下文中的信息时面临困难，因为所有上下文信息都被压缩成一个恒定大小的递归状态。先前的研究表明，回放能力与递归状态的大小正相关，但是直接训练具有更大递归状态的RNN会导致较高的训练成本。本文背景就是在这种背景下提出的问题背景。", "innovation": "本文介绍了StateX，这是一种通过后训练来高效扩展预训练RNN状态的训练管道。对于线性注意力和状态空间模型这两种流行的RNN类，设计了后训练的结构修改，以无增量或几乎无增量模型参数的方式扩展状态大小。实验证明，StateX在保持其他能力的同时，有效提高了RNN的回写能力和上下文中的学习能力，且后训练成本低。", "conclusion": "实验结果证明，通过StateX后训练方法，在模型参数高达13亿的情况下，能够有效提升RNN的回写能力和上下文学习能力，无需增加显著的后训练成本或牺牲其他功能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22635", "html_url": "https://arxiv.org/abs/2509.22635", "title": "双IP-适配器引导下的无需训练的合成数据生成", "title_en": "Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance", "authors": "Luc Boudier,Loris Manganelli,Eleftherios Tsonis,Nicolas Dufour,Vicky Kalogeiton", "background": "由于可用的标记样本有限，图像分类中的少样本问题仍然具有挑战性。近期方法尝试利用文本到图像扩撒模型生成合成训练数据，但通常需要大量的模型微调或外部信息来源。这些模型需要大量的调优和依赖于外部信息，这限制了它们的实际应用。", "innovation": "DIPSY（双IP-适配器引导下的合成数据生成）方法提出了三种创新点：(1) 扩展的无分类器引导方案，允许对正向和负向图像条件进行独立控制；(2) 面向类相似性的采样策略，确定有效的对比样本；(3) 无需微调模型或外部断言和筛选的简易流程。这些创新使得DIPSY能够在不需要生成模型调整的情况下，通过少量的少样本示例生成高判别力的合成图像，同时消除了对外部图像生成和过滤工具的需求。这些创新提高了模型的灵活性和独立性，特别适用于细粒度分类任务。", "conclusion": "实验结果显示，该方法在十种基准数据集上达到了最先进的或相媲美的性能，极大地简化了合成数据生成的过程，提升了模型在少样本图像分类中的效果，特别是对于细粒度分类任务，表现更为出色。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.13185", "html_url": "https://arxiv.org/abs/2401.13185", "title": "快速基于划分的中心化和标准化交叉验证 $\boldsymbol{X}^{\top}\boldsymbol{X}$ 和 $\boldsymbol{X}^{\top}\boldsymbol{Y}$", "title_en": "Fast Partition-Based Cross-Validation With Centering and Scaling for $\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$", "authors": "Ole-Christian Galbo Engstrøm,Martin Holm Jensen", "background": "文章介绍了一种加速基于划分的交叉验证的方法，专用于需要矩阵乘法 $\boldsymbol{X}^{\top}\boldsymbol{X}$ 和 $\boldsymbol{X}^{\top}\boldsymbol{Y}$ 的机器学习模型。这些模型包括主成分分析（PCA）、主成分回归（PCR）、岭回归（RR）、最小二乘法（OLS）和偏最小二乘回归（PLS）等。文章中的算法支持对 $\boldsymbol{X}$ 和 $\boldsymbol{Y}$ 进行列中心化和/或标准化处理，并证明在没有额外显著开销的情况下，这些算法可以正确和有效地应用于不同的处理组合。", "innovation": "文章提出了一种新的算法，能够消除训练划分之间的冗余计算，从而加快基于划分的交叉验证过程。通过仅使用验证分区的数据操纵 $\boldsymbol{X}^{\top}\boldsymbol{X}$ 和 $\boldsymbol{X}^{\top}\boldsymbol{Y}$ ，可以得到预处理后的训练分区的数据。该算法证明了对 16 种不同的列中心化和标准化组合均可获得正确的和有效的交叉验证算法。", "conclusion": "该算法独立于折数，运行时间与计算 $\boldsymbol{X}^{\top}\boldsymbol{X}$ 和 $\boldsymbol{X}^{\top}\boldsymbol{Y}$ 的时间相同，空间复杂度与存储 $\boldsymbol{X}$、$\boldsymbol{Y}$、$\boldsymbol{X}^{\top}\boldsymbol{X}$ 和 $\boldsymbol{X}^{\top}\boldsymbol{Y}$ 相匹配，并且避免了由于预处理导致的数据泄露。同时强调了该算法在 12 种组合下能产生不同的矩阵乘积，证明了其适用性和有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22636", "html_url": "https://arxiv.org/abs/2509.22636", "title": "级尺寸VAR其实是离散扩散", "title_en": "Scale-Wise VAR is Secretly Discrete Diffusion", "authors": "Amandeep Kumar,Nithin Gopalakrishnan Nair,Vishal M. Patel", "background": "自回归（AR）变压器已成为视觉生成的强大范式，这主要得益于它们的可扩展性、计算效率和与语言和视觉的统一架构。其中，下一代预测视觉自回归生成（VAR）最近表现出色，甚至超越了基于扩散的模型。本文重新审视了VAR，并发现一个理论上的洞察：当配有马尔可夫性注意力掩码时，VAR在数学上等价于离散扩散。我们称这种重新解释为可扩展视觉精细处理与离散扩散（SRDD），建立了AR变压器和扩散模型之间合理的桥梁。利用这一新的视角，展示如何直接引入扩散的优点，如逐步精炼并减少架构上的低效率，从而加速收敛、降低推理成本并改善零样本重构。多个数据集的实验表明，基于扩散视角的VAR能够实现效率和生成的一致提升。", "innovation": "提出了AR变压器与离散扩散之间的数学等价，建立了跨视觉自回归生成模型与扩散模型的理论桥梁。基于这一新的认知，通过优化VAR的架构，实现了更快的收敛、更低的推理成本和更好的零样本重构效果。", "conclusion": "基于扩散视角的VAR在效率和生成方面表现出一致的提升。表明了AR变压器和扩散模型可以通过SRDD实现互为补充，提升整体建模和生成性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.16956", "html_url": "https://arxiv.org/abs/2404.16956", "title": "一种对抗贝叶斯分类器的唯一性概念", "title_en": "A Notion of Uniqueness for the Adversarial Bayes Classifier", "authors": "Natalie S. Frank", "background": "本文在二分类设定中提出了对抗贝叶斯分类器中的一种新的唯一性概念。通过对这种概念的分析，研究者获得了一种简单的方法来计算一类一维数据分布的所有对抗贝叶斯分类器。", "innovation": "提出了对抗贝叶斯分类器的一种新的唯一性概念，并利用这一概念展示了随着扰动半径的增加，对抗贝叶斯分类器的某些规律性观念会改进。此外，这些结果还提供了理解一维情况下的贝叶斯分类器与对抗贝叶斯分类器间关系的工具。", "conclusion": "随着扰动半径的增加，对抗贝叶斯分类器的某些规律性得到提高，这表明对抗贝叶斯分类器在不同扰动级别的表现存在一定的规律性，从而为理解和优化对抗贝叶斯分类器提供了新的视角和方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.15193", "html_url": "https://arxiv.org/abs/2305.15193", "title": "额外任务中的自适应策略学习", "title_en": "Adaptive Policy Learning to Additional Tasks", "authors": "Wenjian Hao,Zehui Lu,Zihao Liang,Tianyu Zhou,Shaoshuai Mou", "background": "本文介绍了一种策略学习方法，用于调整预训练策略以适应附加任务，同时保持原始任务不变。提出了一种名为自适应策略梯度（APG）的方法，结合贝尔曼最优原理和策略梯度方法来提高收敛速度。", "innovation": "该方法将贝尔曼最优原理与策略梯度方法相结合，以提高收敛速度，并提供理论分析以确保收敛速度为 O(1/T) 和样本复杂性为 O(1/ε)，其中 T 表示迭代次数，ε 表示所得到的稳定策略的精度。文章还提供了多个具有挑战性的数值模拟，包括双杆、月球着陆器和机器人臂，证明了APG方法在数据使用量较少的情况下具有与现有确定性策略梯度方法相似的性能，且收敛速度更快。", "conclusion": "APG方法在保持性能的同时，减少了数据使用量并加快了收敛速度，对执行额外任务具有实用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.00276", "html_url": "https://arxiv.org/abs/2406.00276", "title": "机器学习辅助可持续再制造、重用和回收锂离子电池", "title_en": "Machine Learning-Assisted Sustainable Remanufacturing, Reusing and Recycling for Lithium-ion Batteries", "authors": "Shengyu Tao", "background": "锂离子电池(LIBs)的可持续利用对于全球能源转型和碳中和至关重要，但数据稀缺性和异质性仍然是再制造、重用和回收过程中的主要障碍。", "innovation": "开发了一个基于机器学习的框架以应对整个电池生命周期中的这些挑战。该框架包括物理信息的质量控制模型，该模型通过早期周期数据预测长期退化；基于生成学习的残余价值评估方法，可以快速且准确地评估随机条件下的退役电池价值；联邦学习策略实现了隐私保护和高精度正极材料分类，以支持高效的回收；统一的诊断与预测框架基于相关性对齐，提升了在各种测试协议下健康状态、荷电状态估计和剩余使用寿命预测的适应性。", "conclusion": "这些贡献通过整合物理、数据生成、隐私保护协作和自适应学习推动了可持续电池管理的进步，为循环经济和全球碳中和提供了方法论创新。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.14265", "html_url": "https://arxiv.org/abs/2406.14265", "title": "VeriFlow：为神经网络验证建模分布", "title_en": "VeriFlow: Modeling Distributions for Neural Network Verification", "authors": "Faried Abu Zaid,Daniel Neider,Mustafa Yalçıner", "background": "形式化验证已经成为了确保神经网络的安全性和可靠性的有希望的方法。然而，许多相关属性，如公平性或全局鲁棒性，都涉及整个输入空间。如果直接应用验证技术，神经网络将会在检查那些在现实世界中不发生且没有实际意义的输入，这会带来不足之处。", "innovation": "我们提出了VeriFlow架构，作为基于流的密度模型，旨在允许任何验证方法将其搜索范围限制在用户感兴趣的某些数据分布内。该架构有两个关键特性：首先，我们表示的转换是分段仿射的，因此可以使用基于线性算术的约束求解验证器；其次，数据分布的上密度级集可以通过潜在空间中的线性约束定义，使得特定概率的密度水平集在潜在空间中有效计算。", "conclusion": "由于上述特性，VeriFlow架构能够更有效地进行验证，并能以精细且概率可解释的方式控制要验证的输入是否典型。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22653", "html_url": "https://arxiv.org/abs/2509.22653", "title": "See, Point, Fly: 一种无需学习的基于视觉语言模型的通用无人驾驶飞行导航框架", "title_en": "See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation", "authors": "Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu", "background": "现有的基于视觉语言模型的空地视觉语言导航（AVLN）方法大多将动作预测视为文本生成任务，缺乏对复杂环境和自由指令的有效处理机制。现有的方法无法在需要导航到任意目标的位置、使用任意类型的自由形式指令以及任意环境方面表现出色。SPF的目标是在无需额外训练的情况下，提升AVLN系统的性能和适应性，使其能够处理各种复杂场景和变化指令，特别是在动态环境中实现对动态目标的有效跟踪和导航。", "innovation": "SPF将动作预测重新定义为一个2D空间定位任务，利用视觉语言模型将模糊的语言指令逐步分解为输入图像上的迭代2D航点标注。预测的3D位移向量被转化为飞行器（UAV）的动作命令。此外，SPF还能够根据需要自适应调整航行距离，提高导航效率。SPF采用了闭环控制方式，使飞行器能够在动态环境中跟随动态目标。这些创新显著提升了系统在DRL模拟基准测试中的表现，并在真实世界测试中也优于其他基准系统。还进行了详尽的消融研究来突出其设计选择的有效性，显示了对不同视觉语言模型的出色泛化能力。", "conclusion": "SPF在DRL模拟基准测试中创下了新的标准，绝对领先于之前的最佳方法63%。在广泛的真实世界评估中，SPF也明显优于其他基准方法。此外，SPF展示了对不同视觉语言模型的强大泛化能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22638", "html_url": "https://arxiv.org/abs/2509.22638", "title": "语言模型可以从口头反馈中学习而无需标量奖励", "title_en": "Language Models Can Learn from Verbal Feedback Without Scalar Rewards", "authors": "Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang", "background": "许多大语言模型（LLMs）在训练过程中使用强化学习（RL）从人类或AI反馈中学习，但这些方法通常将复杂的反馈压缩成单一的标量奖励，从而丢弃了很多信息，并导致了规模失衡。这种单一标量奖励的方法限制了模型能够学到的反馈的复杂性和多样性，难以充分反映用户的意图和期望。这项研究着重探讨了如何将口头反馈用于训练LLMs，而不需要将反馈压缩为单一标量奖励的方法。通过借鉴文本到图像生成中语言先验的概念，研究人员提出了一种处理方法，旨在直接从响应-反馈对中学习，并通过离线数据的最大似然训练近似反馈条件后验，从而捕捉到更多类型的反馈信息。进一步地，提出了一种在线自助阶段，政策在正面条件下生成，并接收新的反馈以进一步优化自身。", "innovation": "该研究提出了一种名为反馈条件策略（FCP）的新方法，直接从响应-反馈对中学习，通过最大似然训练离线数据近似反馈条件后验，以捕捉反馈的丰富性。此方法重新构想了反馈驱动的学习为条件生成，而不是单一奖励优化，为LLMs直接从口头反馈中学习提供了一个更具有表达力的方式，而无需压缩反馈为单一标量奖励。此外，该方法还提出了一种在线自助阶段，通过生成和接收新的反馈来进一步优化策略。", "conclusion": "这项研究通过直接从响应-反馈对中学习，提出了一种新的方法（FCP），使LLMs能够从口头反馈中学习，而不需要进一步压缩反馈为单一标量奖励。该方法不仅捕获了反馈的丰富性，还将反馈驱动的学习重新构想为条件生成。最终，通过这种方法，LLMs可以直接从中学习得到更贴近用户意图和期望的响应。在实际应用中，这种方法可以用于提高LLMs在各种场景下的性能。研究团队已经开源了所使用的代码。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.04615", "html_url": "https://arxiv.org/abs/2309.04615", "title": "VDFD: 多智能体解缠世界观模型的价值分解框架", "title_en": "VDFD: Multi-Agent Value Decomposition Framework with Disentangled World Model", "authors": "Zhizun Wang,David Meger", "background": "多智能体系统由于其可扩展性和非平稳性问题，依赖于大型样本集进行训练，导致无模型方法的样本复杂度较高。因此，为了解决这些挑战，本研究提出了一种基于模块化世界观模型的新颖多智能体强化学习方法，该方法通过分解环境动力学来提高样本效率，从而实现在相同环境中多个智能体共同目标的高效学习。", "innovation": "提出了一种名为Value Decomposition Framework with Disentangled World Model的多智能体强化学习方法（VDFD）。该方法使用解缠世界观模型，由动作相关的、动作无关的和静态分支组成，以分解复杂环境动力学。此外，该方法采用变分自编码器和变分图自编码器学习世界观模型的潜在表示，结合价值基础框架预测联合行为-价值函数并优化整体训练目标，从而提高样本效率和性能。", "conclusion": "实验结果表明，VDFD方法在多种多智能体学习任务中实现了高样本效率和优于其他基线方法的优越性能。特别是在星际争霸II微观管理、多智能体MuJoCo和基于等级的采集挑战中表现突出。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.13498", "html_url": "https://arxiv.org/abs/2308.13498", "title": "使用成对距离估计器在回归ensemble模型中高效估计认识不确定性", "title_en": "Efficient Epistemic Uncertainty Estimation in Regression Ensemble Models Using Pairwise-Distance Estimators", "authors": "Lucas Berry,David Meger", "background": "该研究探讨了使用成对距离估计器（PaiDEs）在回归任务中的ensemble模型中估计认识不确定性的方法。PaiDEs通过模型组件间的成对距离计算熵的边界，这种方法可以提升基于分歧的贝叶斯活跃学习（BALD）的性能。与基于样本的蒙特卡洛估计器不同，PaiDEs具有更快的估计速度和更高的输入覆盖范围，尤其在高维度的情况下表现更好。为了验证方法的有效性，作者在常用的基准数据集（1D正弦波数据、Pendulum、Hopper、Ant和Humanoid）上进行了多种回归实验，结合活跃学习框架展示了PaiDEs的优势，并将其与现有方法进行了对比，结果显示PaiDEs在高维度回归任务中表现更优。", "innovation": "提出了使用成对距离估计器（PaiDEs）的新颖方法，该方法可以快速、高效地估计ensemble模型中的认识不确定性，尤其在处理高维度数据时具有显著优势。这种方法通过模型组件间的距离计算熵的边界，提供了一种无样本且高效的不确定性估计方式。相比传统的基于样本的蒙特卡洛估计器，PaiDEs能够显著提高处理速度，覆盖更广泛的数据输入，并在高维度空间中表现更佳。", "conclusion": "研究在多种常用回归数据集上验证了所提出方法的有效性，并将其与现有的活跃学习方法进行了对比，结果显示该方法在高维度回归任务上的表现优于现有方法。从而证明了使用PaiDEs进行认识不确定性估计的有效性和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.19375", "html_url": "https://arxiv.org/abs/2409.19375", "title": "DOTA: 分布式视觉语言模型测试时适应", "title_en": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "authors": "Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang", "background": "视觉语言基础模型（VLMs）如CLIP在各种任务上表现出色，但在训练数据和测试数据存在显著分布差距时，部署这些模型可能会变得不可靠。通过针对多种场景进行微调通常成本较高。基于缓存的测试时适配器提供了一种替代方案，通过存储代表性测试样本来引导后续分类，但这通常采用简单的缓存管理方式，容量有限，导致在更新过程中不可避免地丢弃样本时发生严重的灾难性遗忘。", "innovation": "提出了分布式测试时适应方法（DOTA），这是一种简单但有效的解决方法，通过连续估计测试数据流的潜在分布，而不仅仅是记忆单个测试样本。利用贝叶斯定理通过这些动态估计的分布计算测试时后验概率以进行适应。这种方法使模型能够持续学习并适应部署环境，实验结果表明，DOTA显著减轻了遗忘问题，并在保持最新技术水平方面取得了最佳性能。", "conclusion": "广泛的实验验证了DOTA在减轻遗忘方面取得了显著成效，并在与现有方法进行比较时达到了最先进的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.08074", "html_url": "https://arxiv.org/abs/2410.08074", "title": "不稳定去学习：扩散模型中概念复现的隐藏风险", "title_en": "Unstable Unlearning: The Hidden Risk of Concept Resurgence in Diffusion Models", "authors": "Vinith M. Suriyakumar,Rohan Alur,Ayush Sekhari,Manish Raghavan,Ashia C. Wilson", "background": "文本到图像扩散模型依赖于大规模、基于网络的数据集。从头开始训练这些模型耗费大量的计算资源，导致开发者通常倾向于在现有模型基础上进行逐步更新。这些更新通常包括微调步骤（学习新概念或改进模型性能）和“去学习”步骤（“忘记”现有的概念，如受版权保护的作品或含露内容）。在这一框架中，我们展示了一个关键且未知的漏洞：在无害、非对抗性的条件下，用看似不相关的图像微调文本到图像扩散模型，可能会导致模型重新学习之前“去学习”的概念。", "innovation": "我们通过一系列实验全面调查了导致这一现象的原因和范围，实验涉及对Stable Diffusion v1.4和Stable Diffusion v2.1的“概念去学习”与随后的微调组合。我们的发现强调了逐步更新模型的脆弱性，并对确保文本到图像扩散模型的安全性和对齐性提出了严重的全新问题。", "conclusion": "我们的研究结果显示，复现的概念可能会在无害的条件下重新出现在扩散模型中，这引发了关于当前扩散模型安全性和对齐性方法的有效性的严重质疑。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.07780", "html_url": "https://arxiv.org/abs/2406.07780", "title": "探讨基于令牌奖励的文本生成方法", "title_en": "A Critical Look At Tokenwise Reward-Guided Text Generation", "authors": "Ahmad Rashid,Ruotian Wu,Julia Grosse,Agustinus Kristiadi,Pascal Poupart", "background": "大型语言模型（LLMs）可以通过微调来与人类偏好对齐，这是所谓的基于人类反馈的强化学习（RLHF）。然而，LLM的微调成本很高，许多用户难以承担。预测时基于令牌的奖励引导文本生成（RGTG）方法由于能够绕过LLM的微调，最近被提出。这些方法使用在完整序列上训练的奖励模型在解码过程中对部分序列进行评分，以引导生成高奖励的序列。然而，这些方法目前仅基于启发式动机，并且缺乏分析。", "innovation": "本文展示了在完整序列上训练的奖励模型不适用于评分部分序列，并提出了针对部分序列直接训练博德利-特里（Bradley-Terry）奖励模型的方法。在解码过程中，作者自回归地从中样本生成令牌级别的策略。研究了这种奖励模型及其生成的策略的性质：证明了这种策略与两种不同的RLHF策略的比例成正比。该简单方法优于先前的RGTG方法，无需大规模LLM微调即可与强大的脱机基线相媲美。", "conclusion": "本文提出了针对部分序列直接训练奖励模型的方法，并证明了这种方法优于以前的方法。该方法无需大规模LLM微调即可与强大的脱机基线相媲美，验证了其在文本生成中的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.15274", "html_url": "https://arxiv.org/abs/2404.15274", "title": "基于临床指标指导的置信区间用于概率图像重建", "title_en": "Metric-Guided Conformal Bounds for Probabilistic Image Reconstruction", "authors": "Matt Y Cheung,Tucker J Netherton,Laurence E Court,Ashok Veeraraghavan,Guha Balakrishnan", "background": "现代深度学习重建算法可以从稀疏输入生成令人印象深刻的逼真扫描图像，但这些算法常常会产生显著的不准确之处。这使得从这些算法重建的扫描中得出统计保障的关于受试者真实状态的声明变得困难。本研究旨在针对基于概率黑盒图像重建算法推导的声明，提出一种计算可验证有效预测边界的框架。该框架的关键洞察是使用一个推导出的临床相关度量来表示重建的扫描图像，并通过先验校准数据集使用一致性预测(CP)来校准与真实度量相关的边界。这些边界可以提供有关受试者状态的可解释反馈，并可用于检索最近邻重建扫描进行视觉检验。", "innovation": "该研究提出了一种框架，用于计算源自概率黑盒图像重建算法推导出的声明的可验证边界。该框架的关键在于使用临床相关度量来表示重建的扫描图像，并使用一致性预测(CP)和先验校准数据集来校准真实度量的边界。与传统的基于像素的边界方法相比，该框架产生的边界在语义上具有更好的解释性，还能标记看起来合理但实际上具有统计上不可能度量值的危险异常重建图像。此外，该研究展示了该框架在稀疏视图计算机断层扫描(CT)中用于脂肪质量量化和放射治疗规划任务中的实用性。研究结果表明，该框架能够产生比传统像素边界方法更好的语义解释边界，并且可以标记出看似合理但实际上具有统计上不可能度量值的危险异常重建图像。", "conclusion": "研究结果表明，该框架在语义上产生比传统像素边界方法更好的边界解释，并且可以标记出看似合理但实际上具有统计上不可能度量值的危险异常重建图像。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22376", "html_url": "https://arxiv.org/abs/2410.22376", "title": "Rare-to-Frequent：通过LLM引导解锁扩散模型在稀有概念组成生成能力", "title_en": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "authors": "Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho", "background": "当前最先进的文本到图像（T2I）扩散模型在生成具有罕见概念组成的图像时常常表现不佳，特别是对于具有不寻常属性的对象生成。论文分析表明，在扩散采样过程中引入与目标稀有概念相关的常见概念，能够提高对罕见概念的组合生成能力。基于这一发现，提出了一个无需额外训练的R2F方法，通过利用大语言模型（LLM）中丰富的语义知识来规划并执行跨整个扩散推理过程的稀有到常见概念的指导。该框架适用于任何预训练的扩散模型和LLM，并可以无缝集成到区域指导扩散方法中。", "innovation": "提出了一个训练-free的R2F方法。该方法利用大语言模型中丰富的语义知识，规划并执行扩散推理过程中的稀有到常见概念的指导。该方法适用于任何预训练的扩散模型和大语言模型，并可以无缝集成到区域指导扩散方法中。实验结果表明，该方法在三个数据集上（包括研究人员新提出的基准数据集RareBench）表现显著优于现有的模型，如SD3.0和FLUX，在T2I对齐方面提高了高达28.1%。", "conclusion": "与现有的T2I扩散模型相比，R2F方法显著提高了稀有概念组成的生成能力，在多个数据集基准上的表现优于SD3.0和FLUX，此结果展示了通过大语言模型的指导可以显著提高扩散模型在生成罕见概念组成的图像方面的效果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.01086", "html_url": "https://arxiv.org/abs/2406.01086", "title": "基于范数采样和正交性的多样子集选择", "title_en": "Diverse Subset Selection via Norm-Based Sampling and Orthogonality", "authors": "Noga Bar,Raja Giryes", "background": "大型标注数据集对于深度神经网络的成功至关重要，但在医疗影像等领域，数据标注可能会非常昂贵。因此，如何从大量未标注的数据中选择一个既多样又信息丰富的小样本集进行标注成为了一个重要的问题。已有工作关注于如何进行小样本选择，但本文提出的方法简单且有效，结合了特征范数、随机化和正交化（通过格拉姆-施密特过程）来选择多样且信息丰富的样本，从而减少冗余和确保特征空间的覆盖范围。", "innovation": "本文提出了一种结合了特征范数、随机化和正交化的简单而有效的方法进行多样子集的选择。特征范数作为信息丰富性的代理，而随机化和正交化减少了样本的冗余性，并促进了特征空间的覆盖。该方法在图像和文本基准数据集上的实验表明，无论是独立使用还是与现有技术结合使用，都能显著提高子集选择的效果。", "conclusion": "本文的方法能够在不需要增加标注成本的情况下，提高选择出来的子集的信息质量和多样性，这对于减少标注数据的总量并提高模型性能是很有帮助的。实验结果表明，该方法在多种数据集上的表现优于或至少不劣于现有方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06883", "html_url": "https://arxiv.org/abs/2410.06883", "title": "度量意识型脉冲图在网络域适应中的应用", "title_en": "Degree-Conscious Spiking Graph for Cross-Domain Adaptation", "authors": "Yingxu Wang,Mengzhu Wang,Houcheng Su,Nan Yin,Quanming Yao,James Kwok", "background": "Spiking Graph Networks (SGNs)通过模仿大脑神经动态实现了节能计算，在图分类任务中显示了巨大的潜力。现有SGNs通常局限在内部分布场景，难以应对分布偏移问题。", "innovation": "本文提出了度量意识型Spiking Graph (DeSGraDA)框架，通过增强跨域泛化能力，包括引入度量意识型脉冲表示模块、进行时域分布对齐以及提取一致预测来生成可靠伪标签，该方法首次为域适应提供了泛化界，提供了对其性能的理论见解。", "conclusion": "广泛的实验表明DeSGraDA在分类准确性和能效方面均优于现有最佳方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01226", "html_url": "https://arxiv.org/abs/2502.01226", "title": "高斯过程贝叶斯中的高效先验选择", "title_en": "Efficient Prior Selection in Gaussian Process Bandits with Thompson Sampling", "authors": "Jack Sandberg,Morteza Haghir Chehreghani", "background": "高斯过程（GP）贝叶斯为优化未知函数提供了一种强大的框架。未知函数的特性主要取决于所假设的GP先验。大部分文献都假设先验已知，但在实践中这往往并非如此。取而代之，实践者通常依赖极大似然估计来选择先验的超参数，这种做法缺乏理论保障。", "innovation": "本文提出了一种基于GP- Thompson采样的混合算法：Prior-Elimination GP-TS（PE-GP-TS）和HyperPrior GP-TS（HP-GP-TS），用于在GP贝叶斯中联合进行先验选择与遗憾最小化。此外，对算法进行了理论分析并建立了各自的遗憾上界。", "conclusion": "通过与现有方法在合成和真实数据上的实验比较，证明了本文算法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.18177", "html_url": "https://arxiv.org/abs/2411.18177", "title": "基于机器遗忘的无说话者依赖性性别暴力状态检测", "title_en": "Machine Unlearning for Speaker-Agnostic Detection of Gender-Based Violence Condition in Speech", "authors": "Emma Reyner-Fuentes,Esther Rituerto-Gonzalez,Carmen Pelaez-Moreno", "background": "性别暴力是一个普遍存在的公共卫生问题，严重影响女性的 mental health，导致焦虑、抑郁、创伤后应激障碍和物质滥用等问题。基于言语的 AI 工具虽然有望用于心理健康筛查，但它们在遇到未见过的说话者时的表现通常较差，表明说话者特征可能成为障碍因素。", "innovation": "研究提出了一种无说话者依赖性的方法，用于从言语中检测性别暴力受害状态。通过使用领域对抗性训练减少模型对说话者身份的影响，研究实现了说话者识别准确率降低26.95%的同时，性别暴力受害状态分类准确率提高了6.37%。研究结果表明，模型能够有效捕捉与性别暴力受害状态相关的生理语言标记，而不是说话者的特定特征。预测结果还与临床前创伤后应激障碍症状有一定的相关性，支持了言语作为无创心理健康监测工具的相关性。", "conclusion": "这项工作为建立道德、隐私保护的人工智能系统奠定了基础，这些系统可用于临床筛查性别暴力幸存者。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01778", "html_url": "https://arxiv.org/abs/2502.01778", "title": "GNN-DT：图神经网络增强决策变换器在动态环境下的高效优化", "title_en": "GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments", "authors": "Stavros Orfanoudakis,Nanda Kishor Panda,Peter Palensky,Pedro P. Vergara", "background": "强化学习（RL）方法在解决实际优化问题时往往涉及动态状态-动作空间、大规模数据和稀疏奖励，这给收敛性、可扩展性和解决方案空间的有效探索带来了巨大挑战。", "innovation": "提出了GNN-DT，一种新颖的决策变换器（DT）架构，将图神经网络（GNN）嵌入器与输入和输出标记之间的新型残差连接相结合以处理动态环境。通过从之前收集的轨迹中学习，GNN-DT解决在线RL算法的稀疏奖励限制，实时提供高质量的解决方案。在复杂的电动汽车（EV）充电优化问题上，GNN-DT表现出色，需要的训练轨迹显著减少，提高了采样效率，优于现有的DT和离线RL基线。", "conclusion": "GNN-DT在未见过的环境中具有强大的泛化能力，并能处理更大的动作空间，解决了先前离线和在线RL方法中的关键差距。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01456", "html_url": "https://arxiv.org/abs/2502.01456", "title": "过程隐含奖励强化", "title_en": "Process Reinforcement through Implicit Rewards", "authors": "Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding", "background": "在大规模语言模型（LLMs）的推理时扩展中，密集过程奖励已证明比稀疏的结果级奖励更有效，特别是在需要复杂多步推理的任务中。虽然密集奖励也提供了强化学习（RL）LLMs的诱人选择，因为它们的精细度奖励有可能解决结果奖励固有的问题，如训练效率和责任分配问题，但这种潜力尚未充分实现。这主要归因于在线训练过程奖励模型（PRMs）的挑战，其中收集高质量的过程标签成本极高，使得它们特别容易受到奖励接管的影响。", "innovation": "我们提出PRIME（过程通过隐含奖励强化），这是一种仅通过策略路径滚动和结果标签使用隐含过程奖励实现在线PRM更新的方法。PRIME与多种优势函数兼容，并省去了现有方法所需的专门奖励模型训练步骤，大大减少了开发开销。", "conclusion": "我们在竞赛数学和编程上的结果显示了PRIME的有效性。从Qwen2.5-Math-7B-Base开始，PRIME在几个关键推理基准上的平均改善率为15.1%。值得注意的是，通过减少10%的训练数据，我们的PRIME模型Eurus-2-7B-PRIME在七个推理基准上超过了Qwen2.5-Math-7B-Instruct。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02748", "html_url": "https://arxiv.org/abs/2502.02748", "title": "ReciNet: 结晶属性预测中的傅里叶空间 aware 长程建模", "title_en": "ReciNet: Reciprocal Space-Aware Long-Range Modeling for Crystalline Property Prediction", "authors": "Jianan Nie,Peiyao Xiao,Kaiyi Ji,Peng Gao", "background": "在材料科学中，从晶体结构预测其属性是一项基本但具有挑战性的任务。与分子结构不同，晶体结构表现出原子的无限周期排列，这些排列需要能同时捕捉局部和全局信息的方法。目前的工作在捕捉周期结构内的长程相互作用方面仍然存在不足。", "innovation": "为了解决这一局限性，该研究利用了傅里叶空间这一周期晶体的自然域，提出了基于傅里叶级数表示的逆空间权重滤波器。在此基础上，引入了一种新的架构——逆空间几何网络（ReciNet），将几何GNN和逆空间块结合，分别用于建模短程和长程相互作用。在标准基准JARVIS、Materials Project和MatBench上进行的实验表明，ReciNet在多种晶体属性预测任务中达到了最先进的预测准确度。此外，还探讨了一种模型扩展方法——专家混合，以实现多重属性预测，显示了高计算效率和相关属性间的积极转移。", "conclusion": "这些发现突显了模型作为扩展和精确的晶体属性预测解决方案的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.05305", "html_url": "https://arxiv.org/abs/2409.05305", "title": "使用符号梯度的神经网络隐空间闭式解释", "title_en": "Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients", "authors": "Sebastian J. Wetzel,Zakaria Patel", "background": "研究表明，如自动编码器或双胞胎网络等人造神经网络能够在其潜在空间中编码有意义的概念。然而，尚未存在一个可以不依赖先验知识就将这种信息以人类可读形式检索出来的全面框架。在定量领域，概念通常用方程来表达。因此，为了提取这些概念，本文提出了一种框架，用于在人造神经网络潜在空间中的神经元寻找闭合形式的解释。该解释框架基于将训练好的神经网络嵌入到编码同一概念的函数等价类中。我们通过寻找等价类和由符号搜索空间定义的人类可读方程之间的交集来解释这些神经网络。在计算上，该框架基于找到一个符号表达式的规范梯度，使其与给定神经元相对于输入变量的规范化梯度匹配。实验结果显示，这种方法可以从双胞胎神经网络的潜在空间中获取矩阵的不变量和动态系统的守恒量。", "innovation": "本文提出了一种框架，用于在人造神经网络潜在空间中的神经元寻找闭合形式的解释。该方法基于将训练好的神经网络嵌入到编码同一概念的函数等价类中，并通过寻找等价类和人类可读方程之间的交集来解释这些神经网络。计算上，该框架基于找到一个符号表达式的规范梯度，使其与给定神经元相对于输入变量的规范化梯度匹配。这种新的方法展示了从双胞胎神经网络的潜在空间中检索矩阵的不变量和动态系统的守恒量的有效性。", "conclusion": "本文的框架展示了从双胞胎神经网络的潜在空间中检索矩阵的不变量和动态系统的守恒量的有效性。这意味着可以向人类用户提供更直观和可理解的神经网络隐空间中的概念提取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.02136", "html_url": "https://arxiv.org/abs/2409.02136", "title": "大型语言模型与经典机器学习：在高维度表格数据中预测COVID-19病亡率的性能对比", "title_en": "Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data", "authors": "Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini", "background": "本文研究了在使用9134名来自四个医院的高维度表格数据预测COVID-19病亡率时，经典的基于特征的机器学习模型（CMLs）与大型语言模型（LLMs）的表现。研究采用七种CML模型，包括XGBoost和随机森林（RF），以及八种LLMs，如GPT-4和Mistral-7b进行比较。Mistral-7b通过QLoRA方法进行了微调。CML中的XGBoost和RF表现出色，分别在内部和外部验证中获得了F1值0.87和0.83。GPT-4在LLMs中表现最佳，F1值为0.43。Mistral-7b通过微调显著提高了其召回率，从1%提升到79%，外部验证中稳定F1值为0.74。尽管LLMs在零样本分类中表现适中，但微调显著提升了它们的效果，部分缩小了与CML模型之间的差距。然而，CMLs在处理高维度表格数据任务时仍然优于LLMs。研究强调了CMLs和微调后的LLMs在医疗预测建模中的潜力，同时指出CMLs在处理结构化数据方面目前具有优势。", "innovation": "研究通过比较CMLs和LLMs在预测COVID-19病亡率方面的表现，展示了少量经过微调的LLMs的潜力，并探讨了它们在高维度表格数据中的适用性。特别地，GPT-4和Mistral-7b在零样本分类中的表现，以及Mistral-7b通过微调得到的显著改进，强调了这两个领域的潜在好处和挑战。", "conclusion": "尽管LLMs在零样本分类中表现出色且微调能够显著提升其效果，但在处理高维度表格数据任务时，CMLs仍然表现更佳。研究结果表明，CMLs和微调的LLMs在医疗预测建模中均具有潜力，但在当前阶段，CMLs在分析结构化数据方面仍占据优势地位。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10243", "html_url": "https://arxiv.org/abs/2410.10243", "title": "统计学习的基本定理中的可测性", "title_en": "Measurability in the Fundamental Theorem of Statistical Learning", "authors": "Lothar Sebastian Krapp,Laura Wirth", "background": "统计学习的基本定理指出，如果一个假设空间的VC维度是有限的，那么该假设空间在PAC学习中是可学习的。现有的关于该定理的证明往往隐含地假设了涉及集合和函数的可测性。本文从测度论的角度审视这些证明，以明确提取进行严格论证所需的所有假设，从而给出统计学习的基本定理在无偏好设置下的严格陈述及详尽的自我包含证明。这项工作对于广泛的应用领域而言具有基础性的重要性，特别是在涉及测度论细微之处的应用中，仔细分析可测性是必不可少的。特别地，文章讨论了模型理论中的应用，包括NIP和o-极小结构，并提出了适合PAC学习的o-极小扩展实数假设空间的充分条件，涵盖所有二元分类的人工神经网络。这些网络通常使用如ReLU和Sigmoid等激活函数。", "innovation": "文章揭示了统计学习的基本定理在无偏好设置下的完整版本，并通过严格的测度论分析，精确确定了证明所需的最小可测性要求。这项工作特别关注可测性在模型理论中的应用，尤其是在NIP和o-极小结构方面。此外，它还提供了适用于具有常用激活函数的人工神经网络的PAC学习的充分条件。", "conclusion": "测度论细致分析对于处理统计学习的基本定理是至关重要的，尤其是当它在涉及测度论细节的应用中使用时。文章的主要结论是给出了适用于o-极小扩展实数上的假设空间（包括所有使用ReLU和Sigmoid等常用激活函数的人工神经网络）的PAC可学习性的充分条件。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21249", "html_url": "https://arxiv.org/abs/2410.21249", "title": "在预算约束多智能体MDP中的容量感知规划与调度：一种元RL方法", "title_en": "Capacity-Aware Planning and Scheduling in Budget-Constrained Multi-Agent MDPs: A Meta-RL Approach", "authors": "Manav Vora,Ilan Shomorony,Melkior Ornik", "background": "本文研究的是容量和预算都受到约束的多智能体马尔可夫决策过程（CB-MA-MDP），这类过程能够在每个智能体不可逆地失效的情况下捕捉许多维护和调度任务。对这类问题而言，规划者必须决定何时应用恢复行动以及要并行处理哪些智能体子集。整个预算限制了总恢复操作次数，而容量限制了同时操作的数量，这将朴素的动态规划转化为一种指数级扩展的组合搜索问题。", "innovation": "本文提出了一种两阶段解决方案，旨在保持对于大规模系统的可计算性。第一阶段中，基于线性加权分配问题（LSAP）的分组技术将智能体按照最大化预期失效时间多样性的方式划分为r个不相交的集合（r为容量），并在每个集合中按比例分配预算。第二阶段使用元训练的PPO策略求解每个亚MDP，并借助跨组的迁移学习实现快速收敛。验证通过将本文方法应用于受有限维修技术人员和总维修预算约束的工业机器人维护调度问题，证明了提出方法在大型团队中相较于基线方法优化了平均运行时间，以及通过对变化数量的机器人和维修技术人员进行了计算复杂性分析，确认了方法的规模可扩展性。", "conclusion": "本文的方法在大型团队中表现出对平均机器人运行时间的优化效果优于基线方法，并且通过规模分析验证了解决方案的扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00666", "html_url": "https://arxiv.org/abs/2502.00666", "title": "通过基于偏好的探索规避RLHF中的exp(R_max)规模", "title_en": "Avoiding $\\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration", "authors": "Mingyu Chen,Yiding Chen,Wen Sun,Xuezhou Zhang", "background": "强化学习从人类反馈（RLHF）已成为大型语言模型（LLM）对齐的至关重要技术。在线RLHF设置关注提高样本效率，但现有算法无论是否进行被动探索或主动探索，都面临样本复杂性随奖励函数规模指数级增长的问题，这在高度偏好的场景下（如具有唯一正确解的问题）限制了其效用。", "innovation": "我们提出了基于偏好的自我探索在线偏好优化（Self-Exploring Preference-Incentive Online Preference Optimization, SE-POPO）算法，这是首个在奖励规模上实现多项式样本复杂性的在线RLHF算法，解决了由Xie等（2024）提出的开放问题。理论分析表明，SE-POPO的样本复杂性优于现有探索算法。实验结果显示，SE-POPO在两个主要的RLHF应用场景及公共基准测试中比探索性和非探索性基线更高效。", "conclusion": "系统评估证实，SE-POPO显著提高了在线RLHF算法设计的样本效率，标志着RLHF算法设计的一个重大进步。有关代码可在此举提供。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08985", "html_url": "https://arxiv.org/abs/2502.08985", "title": "超越浅层行为：通过技能发现实现高效值基多任务离线MARL", "title_en": "Beyond Shallow Behavior: Task-Efficient Value-Based Multi-Task Offline MARL via Skill Discovery", "authors": "Xun Wang,Zhuoran Li,Hai Zhong,Longbo Huang", "background": "离线多代理强化学习（offline multi-agent reinforcement learning, MARL）利用丰富的历史数据来学习优秀的策略，特别适用于交互成本高且风险大的领域。然而，现有大多数方法都是任务特定的，需要针对新任务重新训练，这导致了冗余和低效率。", "innovation": "提出了一个任务高效的价值基础多任务离线MARL算法——Skill-Discovery Conservative Q-Learning（SD-CQL）。SD-CQL通过在潜在空间中重构下一个观测值来发现技能，分别评估固定和可变行为，使用保守的Q学习与局部价值校准来选择每个技能的最佳动作，从而省去了局部-全局对齐的需求，能够从有限的小规模源任务中实现较强的多任务泛化。", "conclusion": "在StarCraft II中的大规模实验表明，SD-CQL在13个任务集中表现出了优越的泛化性能和任务效率，单个任务集中的最佳性能提高了68.9%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16355", "html_url": "https://arxiv.org/abs/2501.16355", "title": "在战略分类情境中，战略性代理如何响应：分析模型与基于LLM生成的响应比较", "title_en": "How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification", "authors": "Tian Xie,Pavan Rauch,Xueru Zhang", "background": "论文背景在于当机器学习算法用于自动化人类决策时，人类代理可能会学习背后的决策策略并适应其行为。战略分类（SC）框架因此被提出，研究代理与决策者之间的互动，以设计更具信赖性的机器学习系统。然而，先前的理论模型假定代理完全或近似理性，并通过优化其效用响应决策策略。随着大型语言模型（LLM）日益普及，研究假设代理可能依赖这些工具进行战略性建议。因此提出两个问题：(i) LLM能否生成有效的、具有社会责任的战略性策略？(ii) 当代理遵循LLM生成的建议时，现有的SC理论模型能否准确描述其行为？", "innovation": "该研究创新性地探讨了五个关键的SC情境：招聘、贷款申请、学校录取、个人收入和个人福利项目。使用三个商业LLM（GPT-4o, GPT-4.1, 和 GPT-5）来模拟不同背景下的代理交互，并依据LLM的建议进行特征上的努力分配。模拟了代理行为与现有SC模型的最佳响应进行比较。研究发现：(i) 即使没有决策策略，LLM也能生成有效的策略，提升代理得分和资格；(ii) 在群体层面，由LLM指导的努力分配策略在提高分数、资格率和公平性指标上表现出与SC理论模型预测相似或更好的结果；(iii) 在个体层面，LLM生成的努力分配通常比理论模型更多样、更平衡", "conclusion": "研究结论表明，即使缺乏决策策略信息，LLM也能生成有效的战略建议，提升代理的表现。在群体层面，LLM指导策略的结果与理论模型预测相近或更好，暗示理论模型依然可能作为LLM影响行为的合理代理。但在个体层面，LLM产生的策略更加多样化和平衡。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20115", "html_url": "https://arxiv.org/abs/2502.20115", "title": "无非高斯性的多视角因果发现：可识别性和算法", "title_en": "Multi-View Causal Discovery without Non-Gaussianity: Identifiability and Algorithms", "authors": "Ambroise Heurtebise,Omar Chehab,Pierre Ablin,Alexandre Gramfort,Aapo Hyvärinen", "background": "因果发现是一个困难的问题，通常依赖于关于数据生成模型的强假设，例如非高斯性。在实践中，许多现代应用提供了系统的多个相关视图，但这些视图在因果发现中很少被考虑。", "innovation": "本文提出了一种多视角线性结构方程模型（SEM），该模型通过交替利用视图间的相关性扩展了知名的非高斯扰动框架。提出了几种基于单视角算法（DirectLiNGAM、PairwiseLiNGAM、ICA-LiNGAM）的多视角因果发现算法，旨在仅依靠弱假设即可实现因果发现。", "conclusion": "通过仿真和神经影像数据的应用验证了新方法的有效性，能够在无非高斯性假设下估计脑区之间的因果图。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08585", "html_url": "https://arxiv.org/abs/2502.08585", "title": "LDC-MTL：通过可扩展损失偏差控制平衡多任务学习", "title_en": "LDC-MTL: Balancing Multi-Task Learning through Scalable Loss Discrepancy Control", "authors": "Peiyao Xiao,Chaosheng Dong,Shaofeng Zou,Kaiyi Ji", "background": "多任务学习（MTL）因其能同时学习多个任务的能力而被广泛应用。尽管现有的梯度操控方法往往比基于标量化的简单方法提供更平衡的解决方案，但这些方法通常会在时间和内存上带来显著的计算负担，大约为计算复杂度$\bar{O}(K)$，其中$K$是任务的数量。", "innovation": "本文提出了一种名为LDC-MTL的简单且可扩展的损失不均衡控制方法，该方法从二层优化的角度进行阐述。该方法包含两个关键组成部分：一是用于细粒度损失差异控制的二层形式化；二是需要$\bar{O}(1)$时间和内存的可扩展的一阶二层算法。理论上，我们证明了LDC-MTL不仅能保证收敛到带损失差别控制的二层问题的稳定点，还能在较温和的条件下达到所有$K$个损失函数的$\bar{e}$-准确帕累托稳定点。", "conclusion": "在多种多任务数据集上的广泛实验表明，LDC-MTL在准确性和效率上都表现出优越的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09934", "html_url": "https://arxiv.org/abs/2502.09934", "title": "Fused Partial Gromov-Wasserstein for Structured Objects", "title_en": "Fused Partial Gromov-Wasserstein for Structured Objects", "authors": "Yikun Bai,Shuang Wang,Huy Tran,Hengrong Du,Juexin Wang,Soheil Kolouri", "background": "结构化数据（如图形）在机器学习中至关重要，因为它能够捕捉复杂的关系和互动。Fused Gromov-Wasserstein (FGW) 距离因其能够同时考虑特征相似性和几何结构而备受关注。然而，作为最优传输（OT）的一个变体，经典的 FGW 假设了比较的数据具有等质量约束。", "innovation": "本文提出了一种放松等质量约束的方法，提出了Fused Partial Gromov-Wasserstein (FPGW)框架，使其能够处理不平衡的数据。理论分析建立了FPGW与FGW之间的关系并证明了FPGW的度量性质。数值上，引入了Frank-Wolfe求解器和Sinkhorn求解器用于FPGW框架。", "conclusion": "通过图匹配、图分类和图聚类实验，评估了FPGW距离的稳健性能，结果显示其表现良好。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04549", "html_url": "https://arxiv.org/abs/2502.04549", "title": "扩散模型中投影式合成的机制", "title_en": "Mechanisms of Projective Composition of Diffusion Models", "authors": "Arwen Bradley,Preetum Nakkiran,David Berthelot,James Thornton,Joshua M. Susskind", "background": "已有研究表明，通过线性分数组合来合成分布可以获得令人印象深刻的结果，包括某些情况下的长度泛化（ Du et al., 2023；Liu et al., 2022）。然而，我们对这种合成如何以及为何起作用的理解仍然不完整。实际上，“合成能够‘工作’”的意义甚至不是很清晰。本文开始着手解决这些基础性缺口。作者首先精确定义了合成的一个可能期望结果，即投影式合成。然后，探讨了线性分数组合何时能证明实现投影式合成、逆向扩散采样是否能产生所需的合成，以及合成失败的条件。作者还将理论分析与之前模糊不清但合成要么有效要么无效的实证观察联系起来。最后，他们提出了一种简单的启发式方法，以帮助预测新合成的成功或失败可能性。", "innovation": "本文通过精确定义投影式合成并深入研究线性分数组合能否实现这种合成，探讨了逆向扩散采样是否产生所需合成的条件，以及合成为什么失败。作者还把理论分析与之前的模糊观察联系起来，提出了简单的预测新合成是否成功或失败的方法。这一系列工作填补了扩散模型合成机制理解上的空白。", "conclusion": "最终，本文不仅理清了扩散模型合成机制的一些基础理论，还提出了一种预测新合成成功率的启发式方法，为扩散模型的应用和优化提供了理论指导。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18591", "html_url": "https://arxiv.org/abs/2504.18591", "title": "使用等变神经场表示实现几何意识的稳定状态PDE推断", "title_en": "Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations", "authors": "Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier", "background": "神经运算的发展引入了适用于一般几何结构的PDE离散化不变替代模型，但许多方法在高效编码局部几何结构和变化域方面存在困难。", "innovation": "本文引入了enf2enf，一种神经场方法，用于预测具有几何变化的稳定状态PDE。该方法通过特定空间位置锚定的潜变量编码几何结构，保持局部性并在网络中传递。局部表示与全局参数结合后被解码，使得能够有效建模复杂的形状变化。实验显示，在气动和结构基准测试中，该方法与图基方法、神经运算方法以及近期神经场方法相比，具有竞争性或优越的性能，同时可以实现实时推理。", "conclusion": "该方法在模型复杂度高和高分辨率网格上表现出高效的扩展性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19649", "html_url": "https://arxiv.org/abs/2502.19649", "title": "大型语言模型中的表示工程：分类、机遇与挑战", "title_en": "Taxonomy, Opportunities, and Challenges of Representation Engineering for Large Language Models", "authors": "Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz", "background": "近年来，控制大型语言模型（LLMs）行为的方式主要是通过修改输入或微调模型。然而，这种范式存在局限性。本文综述了新型表示工程（RepE）范式，这是一种直接操作模型内部表示的方法，旨在提供更有效的、可解释的、数据高效和灵活的模型行为控制手段。综述了快速发展中的相关文献，探讨了RepE的各种方法及应用，并分析了RepE与其他方法相比的优势和劣势，指出了RepE面临的挑战，包括管理多个概念、确保可靠性以及保持模型性能等方面的挑战。针对这些挑战，本文提出了实验和方法上的改进机会，并为RepE的最佳实践提供了一份指南。", "innovation": "代表工程（RepE）是一种新型范式，直接操纵模型的内部表示，而不是修改输入或微调模型。这种范式提供了更有效的、可解释的、数据高效和灵活的模型行为控制手段。本文第一个全面的RepE综述旨在定义RepE框架，描述其作为表示识别、操作化和控制的管道，并提供建议以改进RepE的研究和应用。", "conclusion": "虽然RepE具有显著潜力，但仍然存在挑战，需要进一步的实验和方法论改进。本文提出了一种改进RepE实验和手段的途径，并为最佳实践提供了指南。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16060", "html_url": "https://arxiv.org/abs/2502.16060", "title": "使用时频特征学习单通道EEG标记", "title_en": "Tokenizing Single-Channel EEG with Time-Frequency Motif Learning", "authors": "Jathurshan Pradeepkumar,Xihao Piao,Zheng Chen,Jimeng Sun", "background": "基于模型正在重新定义EEG分析，但对EEG信号的标记仍然是一个重要的挑战。目前存在的问题包括如何有效地将EEG信号转换为可用于下游任务的标记化表示。因此，针对单通道EEG信号提出了一种新的标记化框架TFM-Tokenizer，该框架能够从单通道EEG信号中学习时间-频率模式，并将其编码为离散的标记。结合传统的基础模型和轻量级变压器模型，作者展示了该方法在准确度、泛化能力和可扩展性方面的优势。", "innovation": "提出了TFM-Tokenizer，一种基于时频特征学习的新型标记化框架。该框架能够从单通道EEG信号中学习时间-频率模式，并利用双路径架构和时频掩码来捕捉鲁棒的模式表示。这种标记化方法支持包括轻量级变压器和现有基础模型在内的多种下游任务，并且具有插拔式组件的特性，能够提高多种基础模型的性能。此外，该方法在单通道级别操作，具有设备无关的潜力，能够在不同的信号格式和记录设备上实现更好的性能提升。通过全面的标记分析，该研究揭示了良好的类区分性、频率感知和一致性结构，从而提高了表示质量和可解释性。", "conclusion": "该研究表明，TFM-Tokenizer在四个不同的EEG基准数据集上表现出了一致的性能提升，并且通过实验展示了在耳-EEG睡眠阶段划分任务上的显著优势。该标记化框架能够提高单通道EEG信号的性能，展示出在未来EEG分析中的巨大潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22955", "html_url": "https://arxiv.org/abs/2503.22955", "title": "MNT-TNN: 通过紧凑多模式非线性变换基于张量核范数的空间时间交通数据插补", "title_en": "MNT-TNN: Spatiotemporal Traffic Data Imputation via Compact Multimode Nonlinear Transform-based Tensor Nuclear Norm", "authors": "Yihang Lu,Mahwish Yousaf,Xianwei Meng,Enhong Chen", "background": "交通数据采集因现代通信技术如全球卫星导航系统的使用而引入了新的挑战，特别是在随机缺失值插补和时空依赖性建模方面提出了更高的要求。传统的插补方法面临这些挑战时效果有限，因此需要新的、更有效的解决方案来实现这一目标。", "innovation": "提出了基于Multimode Nonlinear Transformed Tensor Nuclear Norm (MNT-TNN)的新颖时空交通插补方法，该方法能够有效捕捉交通张量中固有的时空多元相关性和低秩性。设计了一种具有理论收敛保证的近邻交替最小化（PAM）算法来解决非凸优化问题，并通过Augmented Transform-based Tensor Nuclear Norm Families (ATTNNs)框架进一步优化插补结果，特别是在极高的缺失率下效果尤为显著。", "conclusion": "通过对实际数据集进行广泛实验，证明了提出的MNT-TNN和ATTNNs方法在随机缺失交通值插补方面优于现有的最先进的插补方法，为高效完成时空交通数据插补任务奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17393", "html_url": "https://arxiv.org/abs/2503.17393", "title": "BPINN-EM-Post：基于贝叶斯物理感知神经网络的后空洞阶段随机迁移损伤分析", "title_en": "BPINN-EM-Post: Bayesian Physics-Informed Neural Network based Stochastic Electromigration Damage Analysis in the Post-void Phase", "authors": "Subed Lamichhane,Haotian Lu,Sheldon X.-D. Tan", "background": "大多数现有的电迁移分析工具基于确定性的假设，但在实际应用中，电迁移引起的应力演变本身就具有非确定性特点，受到输入电流波动和制造非理想性等因素的影响。传统的估算应力变化的方法通常需要昂贵且低效的蒙特卡洛模拟，这种方法通过工业求解器来量化应力变化，并使用平均值和方差度量。这种分析方法在效率和复杂度上存在局限性，特别是在处理复杂互连结构的后空洞阶段的应力变化时。因此，本文致力于开发一种新颖的基于机器学习的方法——BPINN-EM-Post，用于高效地分析电迁移引起的后空洞老化过程中的随机性。", "innovation": "本文引入了一种名为BPINN-EM-Post的新型基于机器学习的框架，它结合了闭合形式的解析解和贝叶斯物理导向神经网络（BPINN）框架，以加速分析。该方法通过在损失函数中使用解析解来减少变量数量，从而显著提高训练效率，同时自然地纳入了变异性的影响。BPINN确保了在不同线段连接处的物理约束得到满足，并且能够精确建模随机行为。解析解有效解决了计算互连结构后空洞应力时初始应力分布的挑战，提升了应力分析的精度和效率。", "conclusion": "BPINN-EM-Post方法通过基于闭合形式解析解和BPINN框架的结合，在保持接近蒙特卡洛模拟精度的同时，实现了相较于FEM基础的COMSOL求解器和FDM基础的EMSpice分别近240倍和67倍的加速效果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11235", "html_url": "https://arxiv.org/abs/2505.11235", "title": "Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation", "title_en": "Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation", "authors": "Fei Wu,Jia Hu,Geyong Min,Shiqiang Wang", "background": "随着模型参数的快速增加，参数有效的微调（PEFT）已成为在有限的计算资源下将大型模型适应各种下游任务的必要手段。目前的正交微调方法和其变体能够保留预训练模型的语义表示，但在参数计数、内存和计算方面难以同时实现高效性和表达性。", "innovation": "本文提出了一种新的方法Efficient Orthogonal Fine-Tuning with Principal Subspace adaptation（PSOFT），通过矩阵分解构建主子空间进行正交变换，保证主子空间的几何结构不变以保持语义的一致性，引入了高效的可调向量在训练过程中逐步放松正交性，提高适应性。", "conclusion": "实验结果表明，PSOFT在NLP和CV任务中能够同时实现语义保留、表达性和多维度效率，在参数有效微调过程中提供了一种实用且可扩展的解决方案。代码已在公开渠道发布。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10213", "html_url": "https://arxiv.org/abs/2505.10213", "title": "基于辅助知识提升LLM在时间序列预测中的性能：知情预测", "title_en": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "authors": "Mohammadmahdi Ghasemloo,Alireza Moradi", "background": "随着大型语言模型（LLMs）的广泛应用，如何在传统自然语言任务之外有效利用其能力成为一个新的研究方向。特别是在能源系统、金融和医疗保健等领域，时间序列预测成为一个日益重要的应用场景。当前，急需建立一套针对LLMs在时间序列预测中的应用的最佳实践。", "innovation": "本文提出了一种新的跨域知识传递框架，该框架能够系统地将结构化的时间信息引入LLMs，以提升其时间序列预测的准确性。这种框架不同于以往的方法，引入了额外的辅助信息，使得模型能够更好地理解时间序列数据中隐含的时间规律性。", "conclusion": "研究结果表明，基于知识的预测方法在预测准确性和泛化能力上显著优于未使用辅助信息的基准方法。这些发现揭示了知识传递策略在弥合LLMs与特定领域预测任务之间的差距方面具有巨大的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18579", "html_url": "https://arxiv.org/abs/2504.18579", "title": "Sparsity Forcing: 增强MLLM的Token稀疏性", "title_en": "Sparsity Forcing: Reinforcing Token Sparsity of MLLMs", "authors": "Feng Chen,Yefei He,Lequan Lin,Chenhui Gou,Jing Liu,Bohan Zhuang,Qi Wu", "background": "精简注意机制旨在通过选择性处理重要标记来减少计算开销，同时将准确性损失降至最低。尽管有诸多有效性，大多数方法仅利用了模型内生的稀疏性，因而只能达到约50%标记削减的水平，且在这之后，若要降低预算则很难不损害准确性。另外，一些方法通过可训练的稀疏注意或尖锐性诱导的正则化来强行引入稀疏性，但这些方法要么僵化地忽略了输入和层动态，要么优化代理目标而缺乏直接的令牌预算控制。", "innovation": "本文提出了一个名为Sparsity Forcing的简单后训练RL框架，专门用于增强大型多模态语言模型（MLLM）的标记稀疏性。该方法通过多次不同令牌预算的rollout探索效率与准确性的权衡，将效率（标记削减比）和性能（答案正确性）整合为联合奖励。通过组内rollout对比，对更高效并且正确的答案进行奖励，而对效率低或者不正确的答案进行惩罚，从而将令牌节省转变为端到端且推理一致的优化目标。", "conclusion": "在十三个图像和视频基准测试中，Sparsity Forcing将Qwen2-VL/Qwen2.5-VL的令牌削减比例从20%提高到75%，且在最低准确度下降的前提下达到了这一效果，同时长上下文推理内存最多减少了3倍，并加快了解码速度最多3.3倍。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11756", "html_url": "https://arxiv.org/abs/2505.11756", "title": "特征对冲：相关特征破坏了窄稀疏自编码器", "title_en": "Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders", "authors": "David Chanin,Tomáš Dulka,Adrià Garriga-Alonso", "background": "传统假设稀疏自编码器（SAEs）能够将多义激活分解为可解释的线性方向，前提是激活是由潜在特征的稀疏线性组合构成的。然而，研究发现，当SAE的宽度小于用于训练的“真特征”数量，并且特征之间存在相关性时，SAE会合并相关特征的部分，从而破坏单义性。在大型语言模型（LLM）的SAEs中，这两个条件几乎总是满足的。这一现象称为特征对冲，是由于SAE重构损失导致的，更窄的SAE受到的影响更大。", "innovation": "本文引入了特征对冲问题并对其在玩具模型中进行了理论研究，并在从大型语言模型训练的SAEs中进行了实证研究。作者认为特征对冲可能是SAEs在监督基准下持续表现不佳的一个核心原因，并利用对特征对冲的理解提出了改进版的matryoshka SAEs。特别指出的是，研究表明SAE的宽度不是一个中性的超参数，更窄的SAE会受到更严重的对冲影响。", "conclusion": "SAEs的宽度不是一个中性的超参数，更窄的SAE会受到更严重的对冲影响，这一工作表明了特征对冲可能是导致SAEs持续低于监督基准的一个重要因素。通过理解特征对冲的现象，研究提出了改进的matryoshka SAEs版本。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00220", "html_url": "https://arxiv.org/abs/2504.00220", "title": "扩散模型能否去纠缠？一种理论视角", "title_en": "Can Diffusion Models Disentangle? A Theoretical Perspective", "authors": "Liming Wang,Muhammad Jehanzeb Mirza,Yishu Gong,Yuan Gong,Jiaqi Zhang,Brian H. Tracey,Katerina Placek,Marco Vilela,James R. Glass", "background": "本文提出了一个新颖的理论框架，以理解扩散模型如何学习拆分表示。在此框架下，作者建立了通用拆分潜在变量模型的可识别性条件，分析训练动态，并推导出拆分潜在子空间模型的采样复杂度边界。为了验证理论，作者在不同任务和模态（如潜在子空间高斯混合模型的子空间恢复、图像着色、图像去噪以及语音转换用于语音分类）中进行了去纠缠性实验。此外，实验结果表明，受该理论启发的训练策略（例如样式指导正则化）能够提高去纠缠性能。", "innovation": "本文的独特性在于提供了一个新的理论框架来理解扩散模型如何学习拆分表示，并通过可识别性条件、训练动态分析和样品复杂度边界来支持这一理解。此外，还提出了新型的训练策略，如样式指导正则化，以提升去纠缠性能。这一框架的应用范围广泛，涵盖了多个任务和数据模态。", "conclusion": "本文的工作建立了扩散模型中通用拆分潜在变量模型的理论基础，并通过广泛的实验验证了理论的有效性。实验结果显示，基于理论的训练策略能够有效提升去纠缠性性能，这对于提高生成模型的表达力和理解力具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03814", "html_url": "https://arxiv.org/abs/2504.03814", "title": "LLMs的递归训练循环：训练数据属性如何调节生成数据中的分布偏移？", "title_en": "Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?", "authors": "Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer", "background": "大型语言模型（LLMs）被广泛用于在线内容的创建，这会导致反馈循环，即后续模型会基于合成数据进行训练。这些循环已被证明会导致分布偏移，模型可能会错误地表示人类数据的真实分布（也称为模型坍塌）。然而，人类数据属性如何影响此类偏移仍知之甚少。本研究旨在通过经验性检查来探讨这些属性对递归训练结果的影响。研究表明，使用不同的个人数据集会导致不同大小的分布偏移，通过对数据集属性的综合操纵和回归分析，确定了影响分布偏移大小的一系列属性。", "innovation": "本研究首次从经验角度探讨了训练数据属性如何影响递归训练中的分布偏移。通过实验和分析，发现了几种预测分布偏移大小的属性，包括词汇多样性可以放大这些偏移，而语义多样性和数据质量则可以减少它们。此外，发现这些影响高度模块化，从给定互联网领域获取的数据对另一领域生成的内容影响较小。研究还发现，人类数据属性影响到最初的偏见是否会被放大或减弱。", "conclusion": "本研究结果提供了一个新颖的观点，说明互联网的不同部分可能会经历不同类型的分布偏移。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03796", "html_url": "https://arxiv.org/abs/2504.03796", "title": "CSF: 基于 Q-Learning 辅助共轭次梯度算法的固定边框布线", "title_en": "CSF: Fixed-outline Floorplanning Based on the Conjugate Subgradient Algorithm Assisted by Q-Learning", "authors": "Xinyan Meng,Huabin Cheng,Rujie Chen,Ning Xu,Yu Chen,Wei Zhang", "background": "现有研究表明，分析算法在处理复杂的布线场景方面具有潜力。然而，为了构建平滑的优化模型而设计的基于梯度的优化算法容易出现局部收敛，从而难以生成具有优异布线长度优化效果的紧凑布线。因此，我们提出了一种由共轭次梯度算法（CSA）处理的非光滑分析布线模型，并通过群体机制和Q-learning调整适应性步长，从而解决了探索与利用之间的平衡问题。实验结果表明，基于CSAQ的固定边框布线算法（CSF）不仅有效地解决了全局布线问题，还能更高效地生成合法布线，且在仅包含硬模块的布线场景上与最先进的算法相比具有竞争力。", "innovation": "提出的CSF算法结合了非光滑分析布线模型、共轭次梯度算法和群体机制，并通过Q-learning辅助调节步长，增强了算法在探索和利用之间的平衡，有效地解决了复杂布线场景中的全局布线问题，且生成了更优的合法布线方案。", "conclusion": "基于CSAQ的固定边框布线算法（CSF）不仅有效解决了全局布线问题，还能更高效地生成合法布线，具有优异的布线长度优化效果，在复杂布线场景中表现优于现有的约束图基合法制化算法及其改进版本，并且在仅包含硬模块的场景上与最先进的算法具有竞争力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11029", "html_url": "https://arxiv.org/abs/2505.11029", "title": "在单位超球面上利用预训练VLMs的不对称不确定性结构", "title_en": "Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere", "authors": "Li Ju,Max Andersson,Stina Fredriksson,Edward Glöckner,Andreas Hellander,Ekta Vats,Prashant Singh", "background": "视觉-语言模型（VLMs）作为基础模型，在广泛的语言和视觉任务中显著提高了性能，无需大规模从零开始训练即可适应下游任务。然而，这些确定性的VLMs不能捕捉到自然语言和视觉数据中的固有模糊性与不确定性。最近的概率后处理适应方法通过将确定性嵌入映射到概率分布来解决这一问题，但现有方法未能考虑到模态间不对称的不确定性结构以及确定性嵌入需位于单位超球面的约束，这可能导致表现不佳。", "innovation": "本文针对文本和视觉数据中固有的不对称不确定性结构，提出了AsymVLM，从预训练VLMs在单位超球面上构建概率嵌入，从而实现不确定性量化。实验验证了概率嵌入的有效性，并通过详细的消融研究展示了文本和视觉数据中不确定性结构的固有不对称性。", "conclusion": "通过AsymVLM方法，本文解决了预训练VLMs的模态间不对称不确定性结构，并通过在基准测试上的验证和消融研究证明了概率嵌入的有效性，展示了在不确定性量化方面的潜在优势。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11574", "html_url": "https://arxiv.org/abs/2505.11574", "title": "量化与推理：探索和减轻低比特LLMs在数学推理中的退化", "title_en": "Quantization Meets Reasoning: Exploring and Mitigating Degradation of Low-Bit LLMs in Mathematical Reasoning", "authors": "Zhen Li,Yupeng Su,Songmiao Wang,Runming Yang,Congkai Xie,Aofan Liu,Ming Li,Jiannong Cao,Yuan Xie,Ngai Wong,Hongxia Yang", "background": "低比特后训练量化（PTQ）是部署具有推理能力的大规模语言模型（LLMs）的有效途径，但在严格的时间和内存预算是，它会显著影响数学推理能力（在我们的设置中下降至69.81%）。该研究深入探讨低比特LLMs在数学推理中的退化问题，并针对部署过程中至关重要的两个问题进行了详细分析。", "innovation": "研究发现了两种稳健规律：（i）量化过程主要增加了具体实施错误和方法错误；（ii）错误主要发生在早期步骤，并呈现级联效应。在此基础上，提出了一个轻量级的干预措施：通过识别最早失败步骤并应用小规模监督调优或偏好调优来恢复精度。这种方法在最少332个精选示例和3-5分钟的计算资源下，能够将4比特权重恢复到全精度基线。", "conclusion": "研究提供了一种通用的干预原则，并设计了一种轻量架构和量化器无关的框架，将低比特退化问题转化为局部、可重复的过程干预，从而在保持低比特量化效率的同时恢复数学推理能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07614", "html_url": "https://arxiv.org/abs/2505.07614", "title": "试与信任：全面防御策略应对拜占庭攻击", "title_en": "Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy", "authors": "Gleb Molodtsov,Daniil Medyakov,Sergey Skorik,Nikolas Khachaturov,Shahane Tigranyan,Vladimir Aletov,Aram Avetisyan,Martin Takáč,Aleksandr Beznosikov", "background": "最近的机器学习进展提高了性能，但同时也增加了计算需求。联邦学习和分布式设置可以解决这些问题，但由于其结构，这些设置易受恶意影响。在本文中，作者探讨了特定的威胁——拜占庭攻击，其中受攻击的客户端会插入对抗性更新以破坏全局收敛。他们结合了信任得分的概念与试函数方法，以动态过滤异常值。这种方法解决了先前方法的关键局限性，即使拜占庭节点占多数，也能维持功能。另外，作者的算法能够适应广泛使用的方法，如Adam和RMSProp，以及包括本地训练和部分参与在内的实际应用场景。通过在合成数据和来自医疗机构的真实ECG数据上进行广泛的实验，作者验证了其方法的鲁棒性，并提供了广泛的理论分析，以及它们应用于上述实际设置的扩展方法。他们的方法的收敛保证与经典算法相当，这些经典算法未考虑拜占庭干扰", "innovation": "作者提出了一种结合信任得分与试函数方法的动态过滤机制，以应对拜占庭攻击。这种方法在拜占庭节点占多数的情况下仍能维持功能，并能够适应广泛使用的方法，如Adam和RMSProp，及实际应用场景。作者还提供了广泛的理论分析，证明了其算法的鲁棒性和应用场景的拓展性。", "conclusion": "作者验证了其方法在综合数据和真实ECG数据上的鲁棒性，并提供了其理论分析。其结论是，他们的方法在拜占庭干扰下仍能提供较高的性能保证，并能够适应多种场景。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12143", "html_url": "https://arxiv.org/abs/2505.12143", "title": "结构化关系表示", "title_en": "Structured Relational Representations", "authors": "Arun Kumar,Paul Schrater", "background": "不变的表示在表示学习中至关重要，但仍面临一个核心挑战：揭示那些既稳定又可迁移而不抑制任务相关信号的不变量。这引发了一系列基础性问题，需要进一步探究应该在何种抽象层次上定义这些不变量以及这些不变量如何描述系统的特点。环境的解释依赖于抽象知识结构来理解当前状态，从而导致了学习和知识获取的动力。这种解释在高级关系知识层面进行，因此建议知识结构必须是核心不变表示所驻留的地方，具体来说是通过抽象知识空间内的关系路径闭包定义的分区。", "innovation": "提出了一种基于闭合半环的计算基础，用于结构化关系表示的不变分区，其中分区作为核心不变表示的核心结构，形成了知识存储和学习的基础结构，而分区之间的连接器则使这些知识分区包含的任务相关转换能够得到部署。", "conclusion": "这些不变分区提供了结构化表示的基础构件，通过分区及其连接器的结构化关系表示，能够支持更加深入的学习和知识获取过程。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16932", "html_url": "https://arxiv.org/abs/2505.16932", "title": "极光号：最优矩阵符号方法及其在Muon算法中的应用", "title_en": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "authors": "Noah Amsel,David Persson,Christopher Musco,Robert M. Gower", "background": "极坐标分解及其相关的矩阵符号函数的计算是数值分析中一个历史悠久的问题。近年来，它在Muon算法中训练深度神经网络时变得尤为重要。然而，这项应用的需求与传统的设置截然不同：深度学习需要GPU友好的算法，更注重高通量而非高精度。", "innovation": "本文介绍了一种新的名为Polar Express的方法来计算极坐标分解。该方法通过求解极小-极大优化问题来调整每次迭代中的更新规则，类似于Newton-Schulz及其他经典多项式方法，仅使用矩阵乘法，因此在GPU上效率很高。Polar Express通过在初始迭代和渐近时都能做到尽可能快速地收敛，且可以解决浮点数精度问题，使其能够使用bfloat16。当集成到Muon训练框架中时，该方法在训练GPT-2模型时在各种学习率下都能稳定地改进验证损失，超过了最近的其他替代方案。", "conclusion": "本方法在使用Muon算法训练GPT-2模型时表现出了明显的优越性，特别是在处理大量数据时能够提高模型的验证损失，跨越多种学习率条件下都能提供比现有方法更好的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11737", "html_url": "https://arxiv.org/abs/2505.11737", "title": "TokUR：大型语言模型推理中的词元级不确定性估计", "title_en": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning", "authors": "Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang", "background": "虽然大型语言模型（LLMs）表现出色，但在各种应用场景中，其输出质量仍然存在不一致性，这使得识别可靠答案具有挑战性。尤其是在需要多步骤推理的复杂任务中，这一问题更为突出。已有方法难以准确估计模型在生成答案时的不确定性，影响了模型在这些复杂任务中的可靠性与可解释性。因此，开发一种能够估计生成答案过程中不确定性的方法对于提升大型语言模型在复杂任务中的表现具有重要意义。", "innovation": "本文提出了一种名为TokUR（Token-level Uncertainty estimation framework for Reasoning）的词元级不确定性估计框架，以增强LLMs在数学推理中的可靠性和可解释性。通过在LLM解码过程中添加低秩随机权重扰动来生成词元级不确定性估计的预测分布，并对这些不确定性数量进行聚合，以捕捉生成答案的语义不确定性。实验结果表明，TokUR与答案正确性和模型鲁棒性高度相关，并能通过不确定性信号改进模型在测试时的推理性能。", "conclusion": "本文提出的TokUR方法作为一种原理上合理且可扩展的方案，有效地提高了LLMs在复杂推理任务中的可靠性和可解释性。该方法不仅能够准确估计生成答案过程中的不确定性，还能够帮助模型在执行复杂任务时实现自我评估和自我改进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11824", "html_url": "https://arxiv.org/abs/2505.11824", "title": "隐含可信度推理在逐步推理中识别错误", "title_en": "Latent Veracity Inference for Identifying Errors in Stepwise Reasoning", "authors": "Minsu Kim,Jean-Pierre Falet,Oliver E. Richardson,Xiaoyin Chen,Moksh Jain,Sungjin Ahn,Sungsoo Ahn,Yoshua Bengio", "background": "链式思维（CoT）推理提升了语言模型（LM）的能力和透明度；然而，推理链中包含的不准确陈述会降低性能和可靠性。为了解决这个问题，本文提出在每一步CoT推理中增加一个隐含可信度（或正确性）变量。", "innovation": "本文引入了隐含可信度搜索（VS），这是一种离散搜索算法，用于高效探索扩展的空间。VS通过利用LM在可信度和最终答案上的联合概率作为代理奖励，进行后验分布中隐含可信度值的高效推理。此外，AVI（广义可信度推理）不仅扩展了VS，还能够在新颖背景下实现零样本可信度推理。", "conclusion": "实验证明，VS可靠地识别了逻辑（ProntoQA）、数学（GSM8K）以及常识（CommonsenseQA）推理基准中的错误，而AVI实现了可比的零样本准确性。最后，本文展示了隐含可信度推理对于自我纠正和自我改进反馈的实用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15130", "html_url": "https://arxiv.org/abs/2505.15130", "title": "少数样本对抗低秩细化调整视觉语言模型", "title_en": "Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models", "authors": "Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Mahnoosh Alizadeh,Ramtin Pedarsani", "background": "视觉-语言模型（VLMs）如CLIP，在大规模对比预训练下已经在跨模态任务中表现出色。参数高效微调（PEFT）技术，如低秩适应（LoRA），作为一种可扩展的替代全微调方案，特别适用于少量样本场景。然而，这些模型极易受到对抗攻击的影响，极微小的扰动就能显著降低模型性能。对抗训练是提高模型鲁棒性的最有效策略之一。本文聚焦于在少量样本情景下通过LoRA细化CLIP模型来增强其对抗鲁棒性的问题背景。", "innovation": "本文提出了AdvCLIP-LoRA方法，这是迄今第一个用于增强使用LoRA微调的CLIP模型对抗鲁棒性的少样本方法。该方法将训练视为低秩适配器和对抗扰动之间的极小极大优化问题，从而实现了鲁棒适应并保持少量的可训练足迹。该方法在多种数据集和模型下展示了优越的鲁棒性和性能表现，尤其是在对抗鲁棒性方面超越了提示调优基准，同时保持了较高准确率。", "conclusion": "此研究的结果表明，AdvCLIP-LoRA是一个适用于资源受限场景中视觉语言模型鲁棒适应的有效应用方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16790", "html_url": "https://arxiv.org/abs/2505.16790", "title": "学习灵活的前向轨迹以提升掩码分子扩散模型", "title_en": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion", "authors": "Hyunjin Seo,Taewon Kim,Sihyun Yu,SungSoo Ahn", "background": "掩码扩散模型（MDMs）在离散数据建模方面取得了显著进展，但在分子生成领域的潜力尚未被充分探索。现有的标准MDMs在直接应用于分子生成时表现不佳，主要问题在于它们导致不同分子的前向扩散状态碰撞，使得反向扩散过程中出现无法学习的重构目标。", "innovation": "本文提出了Masked Element-wise Learnable Diffusion (MELD)，通过参数化的噪声调度网络为不同分子图的每个元素分配独特的破坏率，避免了元素之间的碰撞，从而提升了分子生成的质量。MELD显著改善了MDMs在分子生成上的表现，尤其是在ZINC250K基准数据集上，化学有效性从15%提升到了93%，同时在条件生成任务中实现了最先进的属性对齐。", "conclusion": "MELD方法通过个性化处理分子图的破坏过程，提升了扩散模型在分子生成中的性能，尤其是在化学属性的有效性和生成质量上取得了显著进步。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13230", "html_url": "https://arxiv.org/abs/2505.13230", "title": "隐式偏好产生从感知器到深网络学习曲线中的神经缩放定律", "title_en": "Implicit bias produces neural scaling laws in learning curves, from perceptrons to deep networks", "authors": "Francesco D'Amico,Dario Bocchi,Matteo Negri", "background": "研究发现，深度学习在架构、数据集和任务方面表现出规模定律，这些规律是简单而引人注目的，尤其是在指导先进模型设计方面，它们量化了数据或模型大小增加的好处，并暗示了机器学习的可解释性基础。然而，大多数研究集中在训练结束的渐近行为上。本文通过分析整个训练动态，揭示了更多样化的现象，发现了两种新的动态规模定律，解释了性能随不同范数复杂度度量的变化情况，统一了已知收敛测试误差的规模定律。这些发现表明，训练过程中隐式偏好对模型性能有显著影响，促进了深度学习模型性能的合理解释和发展。实验结果一致表明，这些规律适用于MNIST、CIFAR-10和CIFAR-100上的CNNs、ResNets和Vision Transformers。进一步地，通过对具有逻辑损失单层感知器进行定量支持，推导出了新的动态尺度定律，并通过基于梯度的训练所诱导的隐式偏好对其进行了解释。", "innovation": "本文在现有研究的基础上，通过分析整个训练动态过程，发现了两种新的动态规模定律，更全面地解释了模型性能随不同范数复杂度度量的变化情况。这些新的动态规模定律不仅可以统一已知的收敛测试误差规模定律，还通过单层感知器的训练过程揭示了这些定律背后的隐式偏好机制，为理解深度学习中的可解释性和设计更好地模型提供了一种更为动态的方法。", "conclusion": "本文的发现揭示了隐式偏好对深度学习模型性能变化的重要影响，通过对训练动态过程的深入分析，统一并推广了现有的规模定律，并通过单层感知器的训练过程中揭示了新的动态规模律背后的隐式偏好机制。这些结果不仅丰富了我们对深度学习模型行为的理解，也为未来的模型设计提供了理论支持。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16733", "html_url": "https://arxiv.org/abs/2505.16733", "title": "仅正向扩散概率模型", "title_en": "Forward-only Diffusion Probabilistic Models", "authors": "Ziwei Luo,Fredrik K. Gustafsson,Jens Sjölund,Thomas B. Schön", "background": "传统的扩散模型依赖于前向和后向扩散的耦合方案来进行数据生成。这些模型虽然有效，但通常较为复杂。本研究提出了一种仅正向扩散（FoD）方法，它通过单一的前向扩散过程直接学习数据生成，简化了生成框架，提高了效率。FoD的核心是一种状态相关的随机微分方程，该方程在漂移和扩散函数中均包含一个均值回复项，保证了最终结果向干净数据收敛，自然模拟了从源分布到目标分布的随机插值过程。此外，FoD在整个模型中具有解析可解性，使用简单的随机流动匹配目标进行训练，可以在推理阶段实现几步非马尔科夫链采样，具有较高的灵活性和实用性。", "innovation": "FoD通过引入一个状态相关的随机微分方程，将均值回复项引入漂移和扩散函数中，实现了直接通过单一前向扩散过程学习数据生成。这种方法不仅简化了模型结构，提高了效率，还使模型解析可解，并能通过简单的随机流动匹配目标进行训练，从而在图像恢复任务中达到了最先进的性能。FoD还展示了在图像条件生成上的广泛应用，特别是在图像到图像转换方面，通过定性结果得到了验证。其代码已公开。", "conclusion": "FoD模型因其简单性和高效性，即使在图像恢复任务中也达到了最先进的性能。此外，FoD在图像到图像翻译等条件生成任务上也展现了广泛的适用性。该模型借鉴了传统扩散模型的研究成果，但通过对生成过程的简化和改进，提供了更为有效的生成框架。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16936", "html_url": "https://arxiv.org/abs/2505.16936", "title": "SPAR: 自监督感知位置意识表示学习在分布式感知中的应用", "title_en": "SPAR: Self-supervised Placement-Aware Representation Learning for Distributed Sensing", "authors": "Yizhuo Chen,Tianchen Wang,You Lyu,Yanlan Hu,Jinyang Li,Tomoyoshi Kimura,Hongjue Zhao,Yigong Hu,Denizhan Kara,Tarek Abdelzaher", "background": "分布式感知涉及多个在空间上分布并且多模态的传感器协同观察环境的应用，如车辆监控、人类活动识别和地震定位等。在这些应用中，观察到的信号被传感器的放置（包括位置和结构角色）深深影响。然而，现有的预训练方法对此缺乏考虑，SPAR通过引入空间和结构位置嵌入以及双重重建目标，解决此问题，使感知位置成为表示学习的核心部分，并通过信息理论和遮挡不变性学习的支持进行了理论证明", "innovation": "SPAR通过原理——信号和位置的二元性，引入了空间和结构位置嵌入以及双重重建目标，实现了感知位置的建模，改变了将感知位置视为辅助元数据的做法，使其成为表示学习的内在部分。这项方法得到信息理论和遮挡不变性学习的支持。实验表明，SPAR在各种模态、放置和下游任务中展示出优越的鲁棒性和泛化能力", "conclusion": "SPAR通过引入空间和结构位置嵌入以及双重重建目标，使得感知位置成为表示学习的重要组成部分，并在多种实际数据集上展示了其优越的鲁棒性和泛化能力"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17621", "html_url": "https://arxiv.org/abs/2505.17621", "title": "增强大型语言模型推理能力的内在动机引导探索", "title_en": "Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration", "authors": "Jingtong Gao,Ling Pan,Yejing Wang,Rui Zhong,Chi Lu,Qingpeng Cai,Peng Jiang,Xiangyu Zhao", "background": "强化学习（RL）已成为提升大型语言模型（LLMs）推理能力的关键方法。然而，常用的RL方法如比例策略优化（PPO）和分组正则化策略优化（GRPO）存在依赖稀疏结果反馈和不足的探索激励机制的问题。这些问题导致指导推理的效率低下，稀疏奖励无法提供足够的反馈，尤其是对于复杂问题。此外，这样的奖励还会产生系统性偏差，更偏向于熟悉路径的利用而非新颖解决方法的发现。这些不足严重阻碍了在复杂推理任务中的表现，这些任务需要在中间步骤进行迭代改进。", "innovation": "提出了一种Intrinsic Motivation guidEd exploratioN meThod foR LLM Reasoning（i-MENTOR），一种旨在提供密集奖励并增强探索性的RL方法。i-MENTOR的主要创新包括：意识到轨迹的探索奖励，减轻在token级别策略中的偏差同时保持计算效率；基于错误条件的奖励分配，确保在复杂示例上高效探索，同时还稳固训练的内生于稳定性；优势保存集成，保持优势分布的完整性并结合探索指导。", "conclusion": "在4个公开数据集上进行的实验表明i-MENTOR的有效性，其在AIME 2024上的表现提高了22.23%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20076", "html_url": "https://arxiv.org/abs/2505.20076", "title": "ExPLAIND: 探索模型、数据和训练的归因以研究模型行为", "title_en": "ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior", "authors": "Florian Eichin,Yupei Du,Philipp Mondorf,Maria Matveev,Barbara Plank,Michael A. Hedderich", "background": "现有事后可解释性方法通常将模型的行为孤立地归因于其组件、数据或训练轨迹，这导致了缺少统一视图的解释，可能忽略了关键的交互。虽然结合现有方法或在不同训练阶段应用它们可以提供更广泛的观点，但这些方法通常缺少理论支持。", "innovation": "提出了一种统一框架ExPLAIND，将模型、数据和训练的不同视角整合起来。首先，将基于梯度下降方法的近期工作推广到如AdamW之类的现实场景，证明该方法能够准确地重现卷积神经网络和变换器。其次，从核特征图推导出新的参数和步骤级影响分数，这在参数剪枝上的有效性与现有方法相当，展现了它们在模型组件归因中的价值。最后，通过结合解释模型组件与数据在训练过程中的表现，利用ExPLAIND分析出现了Grokking现象的变换器，支持并修正了之前提出的Grokking阶段。", "conclusion": "ExPLAIND提供了一个有理论基础的统一框架，以解释模型行为和训练动力学。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20761", "html_url": "https://arxiv.org/abs/2505.20761", "title": "使用软标签和校准的最优分类误差的实用估计", "title_en": "Practical estimation of the optimal classification error with soft labels and calibration", "authors": "Ryota Ushio,Takashi Ishida,Masashi Sugiyama", "background": "尽管机器学习系统的性能近年来取得了显著提高，但鲜有人关注一个基本问题：我们的模型究竟可以改进多少？本文提供了一个在二元分类问题中回答这个问题的方法，该方法既实用又具有理论支持。", "innovation": "1. 本文扩展了前人利用软标签估计贝叶斯错误的方法，从理论上研究了基于硬标签估计的偏差性质，揭示了偏差的衰减速率与两类条件分布的分离程度相关，当每个实例的硬标签数量增加时，偏差的衰减速度可以比以前的结果更快。\n2. 本文解决了一个更具挑战性的问题：带有误差的软标签估计。尽管有人可能认为使用校准的软标签可以代替干净的标签，但文章揭示了校准保证是不够的，即便完全校准的软标签也可能导致估计结果严重不准确。本文展示了一种基于较弱假设的等同校准下的统计一致估计方法。\n3. 提出的方法是实例无关的，即不需要访问任何输入实例，这使其适用于因隐私等原因无法获取实例的实际场景。", "conclusion": "实验结果表明了本文方法和理论的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16950", "html_url": "https://arxiv.org/abs/2505.16950", "title": "受限注意力转换器：用于泛化推理的周期性KV缓存巩固", "title_en": "Bottlenecked Transformers: Periodic KV Cache Consolidation for Generalised Reasoning", "authors": "Adnan Oomerjee,Zafeirios Fountas,Haitham Bou-Ammar,Jun Wang", "background": "Transformer大模型显示出与推理时间计算呈比例的强推理能力，主要通过令牌空间的思维链条展现。现有的额外计算方法大量使用潜在空间，我们将其称为辅助潜在空间计算（ALSC）。现有的ALSC方法主要分为三类：（i）令牌介导的潜在展开，（ii）残差/激活引导，（iii）记忆（KV）压缩。与此不同的方法是对记忆的巩固/再巩固，这是大脑中负责稳定新形成记忆痕迹并召回时短暂地使已建立的痕迹变得可塑的两个过程。在Transformer大模型中，这可以类比为对新KV段的就地重写，以及对召回以前段的重写。本文通过信息瓶颈（IB）理论理论，阐述了通过KV缓存重写进行记忆巩固/再巩固对增强推理的好处。", "innovation": "本文引入了受限注意力转换器，它通过在推理步骤分界处引入一个辅助Transformer（称为Cache处理器），进行周期性的非因果、就地KV重写。处理器巩固最近写的KV条目，并重新巩固一小部分经过top-k注意筛选的先前条目。该架构在数学推理基准测试中得到评估，显示了与标准Transformer和带有暂停标记的基线相比的一致性能提升，某些任务/模型的最大提升达到6.6个点。", "conclusion": "在Transformer大模型中通过KV缓存重写进行记忆巩固/再巩固有助于提高推理性能。通过信息瓶颈理论解释了这种方法的合理性。实验结果显示，该方法在数学推理任务上表现优秀，相较于标准模型有显著提高。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21893", "html_url": "https://arxiv.org/abs/2505.21893", "title": "SDPO: 重要采样直接偏好优化以实现稳定扩散训练", "title_en": "SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training", "authors": "Xiaomeng Yang,Zhiyu Tan,Junyan Wang,Zhijian Zhou,Hao Li", "background": "偏好学习已成为一种关键技术，用于将生成模型与人类期望对齐。近期，偏好学习已通过直接偏好优化(Direct Preference Optimization, DPO)等方法扩展到扩散模型中。然而，现有的方法，如Diffusion-DPO，在反向与正向扩散过程之间的不匹配以及早期噪声时间步的高梯度方差方面存在时间节点依赖的不稳定问题，并且由于优化策略与数据收集策略之间的不匹配还会导致离策策略偏差。", "innovation": "我们总共提出了两个创新点：首先，提出了一种名为DPO-C&Ms的实用策略，通过剪裁和屏蔽无信息的时间步来提高稳定性，并部分缓解离策策略偏差；其次，引入了SDPO（重要采样直接偏好优化），这是一种原则性的框架，将重要采样纳入目标函数中，可以完全纠正离策策略偏差，并在扩散过程中强调信息量较多的更新。实验结果表明，SDPO和DPO-C&Ms均优于标准的Diffusion-DPO方法，并且SDPO在VBench得分、人类偏好对齐以及训练稳健性方面表现更优。", "conclusion": "这些结果突显了在基于扩散的偏好学习中，时间节点意识和分布校正优化的重要性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17967", "html_url": "https://arxiv.org/abs/2505.17967", "title": "基于FFT的动态子空间选择用于大规模语言模型的低秩自适应优化", "title_en": "FFT-based Dynamic Subspace Selection for Low-Rank Adaptive Optimization of Large Language Models", "authors": "Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh", "background": "低秩优化已经成为训练大型语言模型（LLMs）以提高运行时间和减少自适应优化器的内存使用的一种有前途的方向。通过将学习限制在较低维度的空间中，可以约束梯度的投影。以往的工作通常使用奇异值分解（SVD）或QR分解来投影线性层的梯度，但这些技术在大型模型中的每个层上单独应用既计算成本高，又会由于存储投影矩阵而增加额外的内存成本。", "innovation": "本文提出了一种计算高效且概念简单的两步流程，通过使用离散余弦变换（DCT）的预定义正交矩阵近似基于SVD/QR的梯度投影到较低维度空间中。该方法动态地根据每层梯度与DCT矩阵列的对齐程度选择列。有效的投影矩阵通过简单的点积操作与DCT矩阵获得，并在较短时间内完成轻量级的排序步骤来识别最具相关性的基向量。对于大层，DCT可以通过利用快速傅里叶变换（FFT）的Makhoul $N$ 点算法在$O(n^2 \text{log}(n))$时间计算。由于基向量是固定的，因此只需在训练开始时计算一次。", "conclusion": "我们在预训练和微调任务上的数值实验表明，我们的双重策略有效地近似了最优低秩投影，获得了一种与SVD/QR方法相当的性能，但具有独立于秩的运行时间和运行速度提升以及最多25%的内存使用减少，适用于不同的模型大小。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23863", "html_url": "https://arxiv.org/abs/2505.23863", "title": "Mamba集成物理原理实现复杂混沌系统长期预测", "title_en": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "authors": "Chang Liu,Bohao Zhao,Jingtao Ding,Huandong Wang,Yong Li", "background": "长期预测复杂的混沌系统仍然是一个基本挑战，因为混沌系统对初始条件具有固有的敏感性，并且它们的奇异吸引子具有复杂的几何结构。常规方法，如水库计算，通常需要包含长时间连续动力学行为的训练数据以全面捕捉系统动力学。虽然先进的深度序列模型可以捕获训练数据中的瞬态动力学，但在长时间尺度上保持预测稳定性和动力学一致性方面往往存在困难。", "innovation": "我们提出了一种称作PhyxMamba的框架，它将基于Mamba的状态空间模型与物理原理信息相结合，以根据短期历史观测预测混沌系统的长期行为。该框架首先使用时间延迟嵌入重构吸引子流形以提取全局动力学特征，然后通过生成式训练方案使Mamba能够再现物理过程。此外，PhyxMamba还通过多片预测和吸引子几何正则化增强进行物理约束，提高了预测准确性并保留了系统的关键统计属性。", "conclusion": "在模拟和现实世界混沌系统的广泛实验中，PhyxMamba展示了卓越的预测准确性，并能从短期历史观测中准确捕捉关键统计属性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23537", "html_url": "https://arxiv.org/abs/2505.23537", "title": "基于领域知识的张量网络结构搜索", "title_en": "Domain-Aware Tensor Network Structure Search", "authors": "Giorgos Iacovides,Wuyang Zhou,Chao Li,Qibin Zhao,Danilo Mandic", "background": "张量网络（TNs）提供了高效表示高维数据的方法，但找到最优张量网络结构（称为张量网络结构搜索问题，TN-SS）仍然是一个挑战。当前最先进的（SOTA）算法将TN-SS视为纯粹的数值优化问题，需要大量的函数评估，这在实际应用中是不可行的。此外，现有的方法忽略了现实世界张量数据中的宝贵领域信息，并且在识别的张量网络结构中缺乏透明度。", "innovation": "作者提出了一种新的基于领域知识的TN-SS框架，称为tnLLM，该框架结合了领域的数据信息，并利用大型语言模型（LLMs）的推理能力直接预测合适的张量网络结构。该框架涉及一种领域感知的提示管道，指导LLM根据张量模式之间的现实世界关系推断合适的张量网络结构。通过这种方式，tnLLM能够不仅迭代优化目标函数，还能为识别的结构生成领域感知的解释。实验结果表明，与SOTA算法相比，tnLLM在较少的函数评估中实现了可比的TN-SS目标函数值。此外，LLM启用的领域信息可用于为基于抽样的SOTA方法提供良好初始化，从而加速其收敛速度同时保持理论性能保证。", "conclusion": "tnLLM在保持理论性能保证的同时，能够更快地找到合适的张量网络结构，并对这些结构进行领域解释。实验结果显示，tnLLM在较少的函数评估中实现了与SOTA算法可比的目标函数值。此外，通过利用LLM的领域知识，可以加速基于抽样方法的优化过程。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18697", "html_url": "https://arxiv.org/abs/2505.18697", "title": "Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study", "title_en": "Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study", "authors": "Ziyang Cheng,Zhixun Li,Yuhan Li,Yixin Song,Kangyi Zhao,Dawei Cheng,Jia Li,Hong Cheng,Jeffrey Xu Yu", "background": "随着现实世界数据的不断涌入，包括图结构数据在内的数据常常以流式方式出现。因此，学习系统需要不断获取新的知识并保留已学到的信息，而不发生灾难性遗忘。尽管已有大量研究试图解决图机器学习中的灾难性遗忘问题，但这些研究均基于从头开始用流式数据训练模型。随着预训练模型的兴起，越来越多的研究开始利用它们的泛化能力进行持续学习。然而，现有的图持续学习实验设置存在明显缺陷，尤其是在评估阶段可能会导致任务ID泄漏。为了解决这些问题，该研究探索了大型语言模型（LLMs）在无回顾（rehearsal-free）条件下是否能缓解图持续学习中的灾难性遗忘问题，并提出了一个简单有效的解决方法Simple Graph Continual Learning (SimGCL)。", "innovation": "该研究的创新在于它利用了大型语言模型的泛化能力来解决图持续学习中的灾难性遗忘问题。不同于目前已有的基于从头开始训练流式数据的方法，研究提出了一个无回顾约束条件下的简单方法SimGCL，并通过广泛实验证明，在此约束条件下，SimGCL 在性能上超越了最新的基于图神经网络的基线方法，提高了约20%。此外，为了促进研究的可重复性，研究还开发了一个易于使用的基准LLM4GCL，供现有图持续学习方法进行训练和评估。", "conclusion": "该研究通过实验证明，大型语言模型可以在无回顾条件下显著缓解图持续学习中的灾难性遗忘问题，并提出了一个简单的解决方案SimGCL，该方法在多种任务上的性能显著优于之前的最佳基线方法。为了提高实验结果的可重复性，研究还开发了一个易于使用的基准LLM4GCL。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00533", "html_url": "https://arxiv.org/abs/2506.00533", "title": "RsGCN: 基于子图重缩放增强GCNs解决旅行商问题的泛化能力", "title_en": "RsGCN: Subgraph-Based Rescaling Enhances Generalization of GCNs for Solving Traveling Salesman Problems", "authors": "Junquan Huang,Zong-Gan Chen,Yuncheng Jiang,Zhi-Hui Zhan", "background": "基于图卷积网络（GCN）的旅行商问题（TSP）求解器面临两个关键挑战：跨尺度泛化的性能不佳以及高训练成本。", "innovation": "提出了一种基于子图的重缩放图卷积网络（RsGCN），通过设计基于子图的重缩放机制来标准化子图中边的长度，以低开销高效学习尺度泛化表示。同时，设计了一种基于重构的数据搜索算法（RBS），以避免局部最优。", "conclusion": "结合RsGCN和RBS，该研究提出了一个泛化能力强、训练成本低的求解器，仅用3个训练周期在混合尺度数据集上（包含最多100个节点的实例）获得成功推广，无需任何微调，即可处理10000节点的实例。实验结果显示，该方法在9种不同规模的均匀分布实例和78个真实世界实例上均表现出先进性能，拥有最少的可学习参数和训练周期，超过了其他神经网络竞争对手。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18777", "html_url": "https://arxiv.org/abs/2505.18777", "title": "HD-PiSSA: 高阶分布正交适应", "title_en": "HD-PiSSA: High-Rank Distributed Orthogonal Adaptation", "authors": "Yiding Wang,Fauxu Meng,Xuefeng Zhang,Fan Jiang,Pingzhi Tang,Muhan Zhang", "background": "现有的参数高效微调（PEFT）方法，如LoRA和PiSSA，将模型更新限制在低秩子空间中，这限制了它们的表达能力，并导致复杂任务上的性能欠佳。鉴于此，提出了一种高阶分布PiSSA（HD-PiSSA），它在不同设备上初始化正交适配器，并集体地在W上聚合其delta更新以进行微调。与数据并行的LoRA或PiSSA保持所有设备上相同的适配器不同，HD-PiSSA将预训练权重的不同主成分分配给每个GPU，显著扩展了更新方向的范围。在使用相同设备适配器秩进行8 GPU微调时，其有效更新秩相较数据并行LoRA或PiSSA高16倍以上。", "innovation": "引入了HD-PiSSA方法，该方法在不同设备上初始化正交适配器，并在W上集体聚合其delta更新以进行微调。相较于现有的数据并行LoRA或PiSSA，该方法将预训练权重的不同主成分分配给每个GPU，显著扩展了更新方向的范围，从而在相同的设备适配器秩下获得了显著更高的有效更新秩。在多任务设置下，HD-PiSSA在12个基准测试中平均获得了10.0绝对分（14.63%）的提升，与LoRA相比，提升了4.98分（6.60%），与PiSSA相比，进一步展示出了其额外优化灵活性的优势。", "conclusion": "HD-PiSSA方法在不同的下游任务中展现出优越性，特别是在多任务设置中，优于现有的PEFT方法，证明了其在提升模型性能方面的潜力，并为复杂任务的高效微调提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03725", "html_url": "https://arxiv.org/abs/2506.03725", "title": "Sign-SGD 是多节点到单节点学习之间的金门大桥：无参数优化带来的显著提升", "title_en": "Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization", "authors": "Daniil Medyakov,Sergey Stanko,Gleb Molodtsov,Philip Zmushko,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov", "background": "近期，大型语言模型在各个领域取得了显著突破，但训练这些模型需要大量的资源，即使是拥有大量计算资源的主要参与者也会面临这一挑战。一种正在流行的方法是Sign-SGD，它可以作为单节点训练中的内存高效方法，也可以作为分布式学习中的梯度压缩技术。然而，从理论上讲，无法自动确定有效的步长大小，实质上它依赖于我们实际学习环境中无法获得的数据集的参数。", "innovation": "为了解决上述问题，作者设计了几种适用于单节点的确定性Sign-SGD的变体，并将这些方法扩展到实际场景中：单节点和多节点的学习，包含动量的方法。", "conclusion": "作者进行了广泛的实验，强调了这些想法在实际机器学习问题中的适用性，并指出Sign-SGD为从多节点到单节点学习提供了一种无参数优化的解决方案，带来了显著的提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21573", "html_url": "https://arxiv.org/abs/2505.21573", "title": "基于有限数据和未知物理的谱启发算子学习", "title_en": "Spectral-inspired Operator Learning with Limited Data and Unknown Physics", "authors": "Han Wan,Rui Zhang,Hao Sun", "background": "从有限数据中学习偏微分方程（PDE）动力学，尤其是在未知物理信息的情况下，是一个挑战。现有的神经PDE求解器要么需要大量数据集，要么依赖已知的物理知识（如偏微分方程残差或手工构建的模板），这限制了它们的应用范围。", "innovation": "本文提出了一种称为Spectral-Inspired Neural Operator (SINO) 的方法，它能够在仅有2-5条轨迹的情况下建模复杂的系统，无需明确的PDE术语。SINO能够通过频率索引自动捕获局部和全局的空间导数，提供无物理假设下的底层微分算子的紧凑表示。为了建模非线性效应，SINO采用了Pi-block（执行光谱特征上的乘法操作）并结合低通滤波器以抑制混叠。", "conclusion": "在2D和3D的PDE基准测试中，SINO取得了领先的表现，准确性的提高幅度高达1-2个数量级。特别是在只有5条训练轨迹的情况下，SINO表现优于基于1000条轨迹训练的数据驱动方法，并且能够准确预测其他方法在计算困难情况下无法处理的案例。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20110", "html_url": "https://arxiv.org/abs/2505.20110", "title": "超越代理：基于轨迹精炼的离线GFlowNet训练引导", "title_en": "Beyond the Proxy: Trajectory-Distilled Guidance for Offline GFlowNet Training", "authors": "Ruishuo Chen,Xun Wang,Rui Hu,Zhuoran Li,Longbo Huang", "background": "生成流网络（GFlowNets）在采样多样性和高奖励对象方面效果显著，但在许多新的奖励查询不可行的实际应用场景中，它们需要从离线数据集进行训练。传统的基于代理的训练方法容易产生误差传播，而现有的无代理方法通常使用粗略的约束条件，限制了探索的范围。这些问题促使研究人员提出一种新的无代理训练框架——轨迹精炼GFlowNet（TD-GFN）。", "innovation": "TD-GFN 使用逆强化学习从离线轨迹中学习密集过渡级别的边缘奖励，提供丰富的结构指导，以促进高效的探索。这种奖励通过有向无环图（DAG）修剪和优先反向采样间接指导策略，确保最终的梯度更新仅依赖于数据集的真实终端奖励，从而防止了误差传播。实验结果表明，TD-GFN 在收敛速度和最终样本质量方面显著优于现有的广泛基线，建立了一种更稳健和高效的离线 GFlowNet 训练范式。", "conclusion": "TD-GFN 通过使用从离线轨迹中获得的密集过渡层面的奖励，以及通过 DAG 修剪和优先反向采样的间接指导策略，成功解决了离线 GFlowNet 训练中的误差传播和探索限制问题，显著提升了训练效率和样本质量。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22988", "html_url": "https://arxiv.org/abs/2505.22988", "title": "模型保持自适应舍入", "title_en": "Model-Preserving Adaptive Rounding", "authors": "Albert Tseng,Zhaofeng Sun,Christopher De Sa", "background": "量化的目标是生成一个压缩模型，其输出分布尽可能接近原始模型。为了实现这一点，大多数量化算法简化了问题，通过最小化每一层的即时激活误差来代理端到端误差。然而，这一方法忽视了未来层的影响，因此不是一个很好的代理。现有方法主要关注每一层的即时误差，从而忽略了后续层对误差累积的贡献。本文通过直接考虑网络输出处的误差，旨在提供一种更加准确的量化算法，引入了Yet Another Quantization Algorithm (YAQA)。", "innovation": "YAQA是一种自适应舍入算法，能够直接考虑网络输出处的误差，而非依赖于每一层的即时激活误差。通过这一方法，论文首先通过哈essian近似的结构特征来描述自适应舍入算法的收敛时间，并提出了端到端误差可以通过近似哈essian与真实哈essian的余弦相似度进行量化的新思路，从而导致了适用于自适应舍入算法的自举近似方法。YAQA 比现有的GPTQ/LDLQ算法更好地表现，并且相比量化感知训练具有更低的误差，这也意味着在下游任务中达到最优性能，同时没有增加推理开销。", "conclusion": "YAQA算法提供了一种新颖的方法，直接针对网络输出进行误差考虑，首次给出了量化算法的端到端误差界限。通过实验验证，该算法不仅在推理性能上优于GPTQ/LDLQ等现有方法，而且在某些情况下甚至比量化感知训练的性能还要优越。这表明，该算法对于提升模型压缩技术的有效性和效率具有重要价值，有望在未来的深度学习模型优化领域发挥关键作用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02724", "html_url": "https://arxiv.org/abs/2506.02724", "title": "WeightLoRA：保留必要的适配器", "title_en": "WeightLoRA: Keep Only Necessary Adapters", "authors": "Andrey Veprikov,Vladimir Solodkin,Alexander Zyl,Andrey Savchenko,Aleksandr Beznosikov", "background": "现代应用程序中语言模型的广泛应用离不开Parameter-Efficient Fine-Tuning技术，如低秩适应（LoRA）技术。LoRA通过在选定的层中添加可训练的适配器来提高精确度，但需要大量内存来训练大型模型，并且需要对哪些层应该添加适配器有更好的直觉。", "innovation": "本文提出了一种名为WeightLoRA的新方法，该方法在优化过程中通过自适应选择最关键的LoRA头部来克服上述问题。从而在减少可训练参数数量的同时，仍然能够获得一致或更优的度量值。作者通过一系列竞争性基准和DeBERTa、BART和Llama模型进行了实验，比较了WeightLoRA与不同自适应方法的效果。实验结果证明了WeightLoRA的有效性和WeightLoRA+在几乎所有情况下的卓越性能。", "conclusion": "实验结果表明，WeightLoRA方法在绝大多数情况下都能有效减少可训练参数数量，同时保留或提升模型性能，而WeightLoRA+版本则在几乎所有测试中表现更优。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07585", "html_url": "https://arxiv.org/abs/2506.07585", "title": "在潜在空间中的航空轨迹数据集扩增", "title_en": "Aircraft Trajectory Dataset Augmentation in Latent Space", "authors": "Seokbin Yoon,Keumjin Lee", "background": "航空轨迹建模对空中交通管理（ATM）和下游任务（如冲突检测和着陆时间预测）至关重要。为了建立更稳健的航空轨迹模型并确保数据集的充分性和均衡性，有必要通过添加合成生成的轨迹数据对数据集进行扩充。", "innovation": "提出了一种名为ATRADA的新框架，用于航空轨迹数据集扩充。该框架采用Transformer编码器学习原始轨迹数据中的潜在模式，将每个数据点转换为学习到的潜在空间中的上下文向量。然后使用主成分分析（PCA）将转换后的数据集投影到低维空间，并使用高斯混合模型（GMM）拟合数据点的概率分布。最后，从拟合好的GMM中抽取新样本，恢复样本维度，并用多层感知器（MLP）进行解码，从而生成新的高质量合成航空轨迹数据。", "conclusion": "多个实验表明，该框架有效地生成了新的高质量合成航空轨迹数据，这些数据与多种基线结果进行了比较。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00209", "html_url": "https://arxiv.org/abs/2506.00209", "title": "拦截癌症：大规模医疗健康基础模型的早期筛查", "title_en": "Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models", "authors": "Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong", "background": "现有的癌症筛查方法会导致过高的医疗费用和侵入性的医疗程序，这些程序在全球范围内并不普遍可用。这导致了许多本可以被拯救的生命的丧失。因此，亟需一种更加经济和广泛适用的筛查方式来早期发现癌症并拯救生命。", "innovation": "本文提出了一种名为CATCH-FM的方法，这是一种基于电子健康记录（EHR）的预筛技术，用于识别高风险患者，仅依赖于他们的历史医疗记录，不需要昂贵和侵入性的医疗程序。通过大规模的EHR数据，作者建立了EHR基础模型的扩展规则，并预训练了一个具有24亿参数的最优基础模型，然后将其微调在由临床专家整理的癌症风险预测群组上。该方法在大规模患者回溯性评估中表现出色，并且在多种患者分布下显示出了鲁棒性，优于特征树模型和通用及医疗LLM。特别是在EHRSHOT少样本排行榜上，CATCH-FM在胰腺癌风险预测方面达到了最先进的效果，并且优于使用现场患者数据进行预训练的EHR基础模型。", "conclusion": "本文的研究结果表明，CATCH-FM方法在各种患者组中表现出了很强的鲁棒性，它在ICD代码空间的操作具有优势，并能够捕捉到非显而易见的癌症风险因素。此外，该研究还揭示了在EHR数据预训练基础模型的有效性，并展示了其在不同数据环境下的适应性。此方法有望改变癌症筛查的方式，并可能在全球范围内推广使用。研究者表示，他们将开源代码以促进进一步的研究和开发。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16975", "html_url": "https://arxiv.org/abs/2506.16975", "title": "基于变换器的语言模型中隐含概念的解缠", "title_en": "Latent Concept Disentanglement in Transformer-based Language Models", "authors": "Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy", "background": "在使用在上下文学习（ICL）解决新任务时，大规模语言模型（LLMs）必须从示范例中推断出隐含的概念。这引发了一个问题：变换器模型如何在其计算中表示隐含结构。本研究通过几种受控任务并运用机械可解释性方法探讨了这一问题。", "innovation": "研究表明，在传递性推理任务中，模型能够识别隐含的概念并进行概念的逐步组合。在由隐含数值概念参数化的任务中，研究发现模型中的低维子空间，其几何结构清晰地反映了潜在参数化。研究证明，即使从简化的示范例中，小模型和大模型也能解缠并利用他们学习到的隐含概念。", "conclusion": "研究展示了小模型和大模型均可从少量简化的示范例中解缠并利用隐含概念，为进一步理解变换器的机制提供洞察。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04487", "html_url": "https://arxiv.org/abs/2506.04487", "title": "OrthoGrad 提高了神经网络的校准", "title_en": "OrthoGrad Improves Neural Calibration", "authors": "C. Evans Hedges", "background": "在关键不确定性应用中，标准优化器展示出过度自信的问题，这限制了它们的性能。研究发现，通过约束梯度更新的方向，可以在不改变架构的情况下解决这一问题，从而提升优化路径的效果并减少对标签数据的需求。实验结果表明，$\bot$Grad在CIFAR-10数据集上使用10%的标记数据与SGD在准确率 match 时，显著降低了测试损失、预测熵和信心度量。这些影响在不同数据腐蚀水平和模型架构下表现一致。实验还证实，$\bot$Grad是一种通用优化器，具有较低的开销并兼容后续校准技术。", "innovation": "提出了一种新的几何感知修改的优化方法，$\bot$Grad，该方法通过在梯度更新和权重向量之间引入正交性来限制下降方向，解决了标准优化器在关键不确定性应用中的过度自信问题。这一创新不影响网络结构，并显著改善了校准效果，如测试损失、预测熵和信心度量等指标，同时保持了算法的简约和高效性。理论分析还揭示了正交化如何约束优化路径，避免过度自信和促进决策边界的优化.", "conclusion": "几何干预在改进预测不确定性估计方面具有低成本的优势。$\bot$Grad不仅在标准神经网络校准任务中表现出色，还能在数据稀缺的情况下提高网络性能。此外，$\bot$Grad具备广泛的适用性和最低的运行开销，是优化算法领域的创新性贡献。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05530", "html_url": "https://arxiv.org/abs/2506.05530", "title": "谱图神经网络在简单谱图上的表达能力有限", "title_en": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "authors": "Snir Hordan,Maya Bechler-Speicher,Gur Lifshitz,Nadav Dym", "background": "图神经网络（GNNs）通过引入谱特征，提高了其区分非同构图的能力。主流方法是利用图拉普拉斯特征向量进行位置编码。现有评估SGNNs表达能力的方法，如k-WL图同构测试层次和同态计数，与图的谱特性不匹配，难以提供SGNNs的准确表达能力评估。因此，需要一个新的评估框架，能够更好地揭示SGNNs的表达能力。", "innovation": "提出了一个新的图表达能力层次结构，基于图的最大特征值重数进行分类。证明了某些SGNNs在具有不同特征值的图上是不完备的。通过引入旋转李群不变神经网络，设计了一种方法来提高SGNNs在简单谱图上的表达能力。通过图像分类实验和特征向量规范化验证了理论上的改进效果。", "conclusion": "SGNNs在简单谱图上可能表现不佳，提出了一个新的基于最大特征值重数分类的表达能力层次结构，通过调整旋转李群不变神经网络，有效提升了SGNNs在简单谱图上的表达能力。实验证明了该理论的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12037", "html_url": "https://arxiv.org/abs/2506.12037", "title": "利用块坐标下降法实现经济高效的大型语言模型训练", "title_en": "Exploiting Block Coordinate Descent for Cost-Effective LLM Model Training", "authors": "Zeyu Liu,Yan Li,Yunquan Zhang,Boyang Zhang,Guoyong Jiang,Xin Zhang,Limin Xiao,Weifeng Zhang,Daning Cheng", "background": "训练大规模语言模型通常需要大量的GPU内存和大量的资金投入，这为许多中小规模团队设置了障碍。", "innovation": "提出了基于块坐标下降法（BCD）的全参数预训练和微调框架，并结合了工程优化，能够在经济实惠的RTX 4090、A100和A800 GPU集群上高效训练大规模模型。与标准的全参数训练相比，在相同的硬件配置下，将7B模型的训练成本降低至33%（A100/A800）和仅2.6%（RTX 4090），并且能够使原先仅能在A100集群上训练的大型模型在RTX 4090上进行训练而不会降低性能。BCD在大多数情况下达到或优于全参数和微调方法的准确性，同时降低GPU消耗并提高硬件利用效率。", "conclusion": "通过BCD方法可以在成本效益较高的GPU集群上高效训练大规模语言模型，减少训练成本，提高硬件利用率，并维持或提升模型的准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00259", "html_url": "https://arxiv.org/abs/2507.00259", "title": "在个性化联邦学习中应信任谁？基于个体预测的自适应协作", "title_en": "Whom to Trust? Adaptive Collaboration in Personalized Federated Learning", "authors": "Amr Abourayya,Jens Kleesiek,Bharat Rao,Michael Kamp", "background": "联邦学习（FL）面临数据异质性的根本挑战，尤其是在客户端不仅在数据分布上不同而且在单个示例上的预测可靠性也不同的情况下。虽然个性化联邦学习（PFL）试图解决这一问题，但许多PFL方法未能超越本地训练和集中式训练的必要基线。这表明只有在特定小范围内，即在全局模型不足但客户端间协作依然有价值的场合，才能实现有意义的个性化。我们的实验发现指出，在这种情况下实现成功的关键要素：协作为中心的自适应性和细粒度的信任机制，这可在客户端针对共享未标注数据集进行预测交换时实现。", "innovation": "本文提出了一种名为FEDMOSAIC的个性化共训练方法，这种方法使得客户端基于预测的一致性和置信度对他们的损失和对伪标签的贡献重新加权。FEDMOSAIC能够在全球模型不足但客户端间协作依然有价值的场合超越多种非IID条件下的强联邦学习和个性化联邦学习基线，并且证明了其在标准光滑性、均值偏差和漂移假设下的收敛性。此外，该方法还超越了局部和集中式训练。", "conclusion": "本文的研究结果阐明了在什么情况下联邦个性化可以有效，以及如何通过细粒度、信任感知的协同作用实现它。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06784", "html_url": "https://arxiv.org/abs/2506.06784", "title": "Caterpillar GNN: 用高效聚合替换消息传递", "title_en": "Caterpillar GNN: Replacing Message Passing with Efficient Aggregation", "authors": "Marek Černý", "background": "消息传递图神经网络（MPGNNs）在现代图学习中占主导地位。典型的改进方法是通过丰富基于邻接的关系聚合来增强MPGNN的能力。与此相反，我们介绍了一种有效的基于遍历子结构矩阵的聚合方法，这种矩阵旨在有意牺牲一些表达能力以换取更强的结构诱导偏差。这种做法允许从经典的消息传递到基于遍历的更简单方法之间无缝切换。通过使用类别化的造熊虫图同构计数严格地表征每一步的表达能力，我们提出了Caterpillar GNN，这种图级聚合方法成功地解决了专门设计来挑战MPGNN的基准。此外，在真实世界的数据集上，Caterpillar GNN能够达到与MPGNN相当的预测性能，同时显著减少了计算图隐藏层中的节点数量。", "innovation": "我们提出了一种基于遍历子结构矩阵的有效聚合方法，这种方法意在牺牲一些表达能力，但能获得更强的结构诱导偏差。通过这种方法，我们能够实现消息传递与基于遍历的更简单方法之间的无缝过渡。我们通过使用一类化的造熊虫图同构计数来严格表征每一步的表达能力，并基于此提出了Caterpillar GNN。Caterpillar GNN的成功在于其强大的图级聚合方法能够有效应对专门设计来挑战MPGNN的基准。此外，相比于传统的消息传递方法，Caterpillar GNN在真实世界数据集上展示了相当的预测性能，但同时显著减少了隐藏层中的节点数量。", "conclusion": "Caterpillar GNN通过使用高效聚合替代消息传递，展示了在保持预测性能的前提下，能够显著减少计算图中隐藏层的节点数量。这种方法为图学习提供了一种新的思路，并成功克服了传统消息传递方法的局限。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05980", "html_url": "https://arxiv.org/abs/2506.05980", "title": "AMPED: 自适应多目标投影以平衡探索与技能多样性", "title_en": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification", "authors": "Geonwoo Cho,Jaemoon Lee,Jaegyun Im,Subi Lee,Jihwan Lee,Sundong Kim", "background": "技能基于强化学习（SBRL）通过预训练技能条件化策略，使在稀疏奖励环境下能够快速适应。有效的技能学习需要同时最大化探索和技能多样性，但现有的方法往往难以同时优化这两个相互冲突的目标。针对这一挑战，本文提出了自适应多目标投影以平衡探索与技能多样性（AMPED），该方法一方面通过梯度手术投影在预训练阶段平衡探索和多样性梯度，另一方面在微调阶段通过技能选择器利用学习到的多样性，选择适合下游任务的技能。此方法在各种基准测试中超越了SBRL基线，通过详尽的消融研究，证明了AMPED各组件在提升性能中的作用，进一步理论和实验证据表明，采用贪婪技能选择器时，更高的技能多样性可减少微调样本复杂度。", "innovation": "该方法是自适应多目标投影以平衡探索与技能多样性（AMPED），包括预训练阶段的梯度手术投影和微调阶段的技能选择器。实验结果表明其在多个基准测试中超越了SBRL基线，并通过消融研究强调了平衡探索和多样性的必要性，以及AMPED的有效性在实现鲁棒和通用技能学习方面。", "conclusion": "这些结果阐明了平衡探索和多样性的显式整合的重要性，证明了AMPED在实现鲁棒和通用技能学习方面的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14261", "html_url": "https://arxiv.org/abs/2506.14261", "title": "RL-Obfuscation：语言模型能否学会规避潜空间监控？", "title_en": "RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?", "authors": "Rohan Gupta,Erik Jenner", "background": "潜空间监控旨在通过利用大型语言模型的内部表示来检测不良行为，而不仅仅是依赖于黑盒输出。已有研究表明，这些方法在识别欺骗和不安全的完成方面显示出潜力。然而，这些监控本身也可能成为训练信号，例如，通过使用在部署中找到的问题样本重新训练模型。这就提出了一个重要的问题：模型能否学会规避这些监控？", "innovation": "为了评估这种能力，作者引入了RL-Obfuscation方法，通过强化学习对语言模型进行微调，使其能够在不改变其黑盒行为的情况下规避潜空间监控。研究在7B到14B参数的语言模型上进行了试验，并测试了它们对一系列监控的逃避成功率。结果显示，基于令牌的监控对这种攻击非常脆弱，而更具综合性的监控（如最大池化或基于注意力的探针）则保持了鲁棒性。此外，针对单一静态监控训练的模型可以泛化以规避其他未见的监控。研究还发现，这些模型可以被训练为在特定输入时有条件地绕过潜空间监控。最后，作者研究了模型如何绕过这些监控，发现模型可以学会重新使用令牌，使其具有不同的内部表示。", "conclusion": "研究表明，基于令牌的监控对于逃避攻击非常脆弱，而更综合性的监控则具有鲁棒性。模型可以被训练以逃避特定的静态监控，并且这种训练能够泛化到其他未见的监控。模型还可以在特定输入时有条件地绕过潜空间监控，通过重新利用令牌来进行不同的内部表示。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18814", "html_url": "https://arxiv.org/abs/2506.18814", "title": "具有敌对方干扰的在线多代理控制", "title_en": "Online Multi-Agent Control with Adversarial Disturbances", "authors": "Anas Barakat,John Lazarsfeld,Georgios Piliouras,Antonios Varvitsiotis", "background": "多代理控制系统在自主机器人、经济学和能源系统等众多领域普遍存在，其中多个代理追求竞争且随时间变化的目标。在这些场景中，对抗性干扰下的鲁棒性至关重要。传统的多代理控制研究通常假设动态系统没有噪声或仅为随机扰动，而在本研究中，考虑了可以为敌对方的扰动，并且每个代理旨在最小化自己的序列凸损失。基于两种反馈模型，研究了具有局部策略更新的基于梯度的在线控制器，并证明了单个代理的次线性且接近最优的后悔边界。当代理的目标一致时，进一步证明了多代理控制问题诱导了随时间变化的潜在博弈，并提出了均衡跟踪保证。研究结果首次将在线控制与博弈中的在线学习相结合，建立了动态连续状态环境中的鲁棒个体和集体性能保证。", "innovation": "提出了在线梯度控制器，适用于具有敌对方扰动的多代理线性动态系统，并提供了针对个体和集体性能的鲁棒性保证。这项研究首次建立了在线控制与博弈中的在线学习之间的联系。", "conclusion": "该研究将在线控制与在线学习在动态连续状态环境中联系起来，为具有敌对方扰动的多代理控制系统提供了个体和集体的鲁棒性性能保证。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "超越简单图：多图上的神经多目标路由", "title_en": "Beyond Simple Graphs: Neural Multi-Objective Routing on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的方法在单目标和多目标的路由问题中得到了广泛关注。然而，现有的方法还不适合在多图上进行路由，尽管多图在现实场景中有重要作用。多图中，节点之间存在具有不同属性的多条边，这使得解决问题更具挑战性。目前围绕该领域的研究还处于起步阶段，没有有效的方法来解决这个问题。本文的目的是提出新的方法来处理多图上的多目标路由问题，从而填补这个研究空白。", "innovation": "本文提出了一种基于图形神经网络的方法来解决多图上的多目标路由问题。第一种方法通过自回归的方式直接在多图中选择边。第二种方法首先通过学习到的剪枝策略简化多图，然后在简化后的简单图上进行自回归路由。这两种方法在多种问题和图分布下进行了实证评估，展示了他们与强启发式方法和神经基线方法相比具有较强的竞争性。", "conclusion": "两种方法在多目标路由多图问题上的实证评估和表现，展示了神经方法在解决复杂网络问题上的潜力。这为后续的研究提供了新的思路和方向。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20893", "html_url": "https://arxiv.org/abs/2506.20893", "title": "为了有效类别遗忘的输出分布重权的必要性", "title_en": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": "Ali Ebrahimpour-Boroojeny,Yian Wang,Hari Sundaram", "background": "现有类别遗忘评估存在一个重要的不足，即忽略了底层类别的几何结构可能会导致隐私泄露。研究者们证明了现有的遗忘方法在多个数据集上对MIA-NN（最邻近的成员推断攻击）是脆弱的。", "innovation": "提出了一个简单的解决方案，通过引入基于最近邻的成员推断攻击（MIA-NN）来检测未遗忘样本，该方法利用模型对相邻类别的概率分配。这种方法提出了一种新的微调目标——倾斜重权（TRW），通过近似重新训练后的模型在重新训练从头开始后对遗忘类输入产生的类别分布，来缓解隐私泄露问题。TRW在多个基准测试中优于或匹配了现有的遗忘方法。", "conclusion": "在CIFAR-10数据集上，TRW模型相较于现有最佳方法，分别将U-LiRA分数和MIA-NN分数减少19%和46%，证明了该方法的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "理想磁流体静力学的人工神经网络求解器", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "该研究解决的是磁流体静力学（Magnetohydrodynamic equilibria）的三维计算问题。传统的计算方法使用常规求解器，而该论文提出了一种新的方法，通过使用人工神经网络参数化傅立叶模式来进行计算。", "innovation": "创新点在于将傅立叶模式参数化的人工神经网络应用到磁流体静力学的计算中。这种方法通过在实空间中最小化全局非线性力残差来工作，并且已经显示出与现有代码相当的计算成本。在增加计算成本的情况下，人工神经网络能够达到更低的残差最小值，建立了新的残差下限。", "conclusion": "该研究使用了较为简单的神经网络，并且预期未来在解决单个静力学平衡问题以及不同静力学平衡连续分布的计算模型方面会有显著改进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15307", "html_url": "https://arxiv.org/abs/2506.15307", "title": "SecP-Tuning: 全同态计算保障的高效隐私保护提示调优方法用于大规模语言模型", "title_en": "SecP-Tuning: Efficient Privacy-Preserving Prompt Tuning for Large Language Models via MPC", "authors": "Jinglong Luo,Zhuo Zhang,Yehong Zhang,Shiyu Liu,Ye Dong,Hui Wang,Yue Yu,Xun Zhou,Zenglin Xu", "background": "大型语言模型（LLMs）已在众多领域实现了革命性的变革，但在医疗和金融等高度隐私敏感的领域中的应用受到限制，因为有限的可用训练数据限制了这些模型的调整。安全多方计算（MPC）保障的隐私保护机器学习方法能够提供模型参数和数据隐私的理论保证，但将其应用于LLMs在推理之外的应用处理起来有重大挑战，尤其是在反向传播、优化器和自我注意操作方面。", "innovation": "提出了一种名为SecP-Tuning的新型框架，这是一种基于MPC的高效、隐私保护的大规模语言模型提示调优方法。SecP-Tuning通过数据所有者-服务器交互模式成功地将仅前向调优（FoT）应用于正向传播，从而避免了反向传播与优化过程中使用的隐私保护计算。此外，SecP-Tuning还开发了一种高效的隐私保护随机特征注意（RFA），有效缓解了基于softmax的自我关注计算的复杂性，并规避了MPC不兼容的非线性操作。实验结果表明，与全参数监督调优（SFT）和基于梯度的提示调优相比，SecP-Tuning分别实现了大约12倍和16倍的端到端加速以及18倍和20倍的通信延迟减少。在五个数据极少的任务中，SecP-Tuning的平均性能得分为82.45，远超SFT的79.90和基于提示的调优的73.73，并有效地避免了梯度/参数传输导致的内存泄漏风险，采用了‘黑盒/API样式’的隐私保护调优模式。", "conclusion": "SecP-Tuning为LLMs提供了一种高效且安全的提示调优方法，显著提高了隐私保护和性能，特别是在医疗和金融等高敏感领域的应用。该框架在传统方法的基础上，从计算效率和通信延迟等方面取得显著改进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07032", "html_url": "https://arxiv.org/abs/2507.07032", "title": "轻量级MSA设计改进蛋白质折叠的进化嵌入", "title_en": "Lightweight MSA Design Advances Protein Folding From Evolutionary Embeddings", "authors": "Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Cesar de la Fuente-Nunez,Chunbin Gu,Ge Liu,Pheng-Ann Heng", "background": "蛋白质结构预测通常依赖于多重序列比对（MSAs），但在低同源性和孤儿蛋白质上表现不佳。现有的MSA方法无法有效预测这些蛋白质的结构，影响了下游折叠过程的性能。", "innovation": "本文提出了PLAME（一种轻量级MSA设计框架），它利用预训练蛋白语言模型的进化嵌入生成能更好支持下游折叠的MSA。PLAME结合了保均性多样性损失（balance on conserved positions with coverage of plausible sequence variation），在生成MSA的基础上，开发了一种MSA选择策略和一种与深度度量互补的序列质量度量，可以预测折叠改进。PLAME在与AlphaFold3结合使用时能够提高结构准确性，并且能在不牺牲推断速度的情况下使ESMFold接近AlphaFold2的准确性。", "conclusion": "PLAME为缺乏强进化邻近的蛋白质提供了高质量折叠的实用路径。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14843", "html_url": "https://arxiv.org/abs/2507.14843", "title": "隐形的局限：为什么RLVR可能或可能无法突破其起源", "title_en": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin", "authors": "Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi", "background": "最近在大型语言模型（LLMs）方面的进展表明，基于强化学习的检索与值回归（RLVR）方法可能是一个提高AI能力的有效途径，特别是在解决复杂逻辑任务方面。但目前尚不清楚当前实践中这种方法是否真正扩展了模型的推理边界，还是主要增强了基模型已知的高奖励输出，从而提高了精确度。", "innovation": "本研究通过实证调查，提供了对常见RLVR实践潜在极限的新见解。研究发现，在当前训练条件下，RLVR可以作为一种支持约束优化机制，这可能会限制发现完全原创解决方案的可能性，使之受限于基模型的初始分布。研究还识别了一个熵-奖励权衡：虽然当前的RLVR食谱可靠地提高了精确度，但可能会逐渐缩小探索范围，并可能忽略正确但未充分代表的解决方案。", "conclusion": "这些发现揭示了当前RLVR食谱在扩展推理边界方面可能存在的局限性。未来可能需要算法创新，如明确的探索机制或种群策略，以将概率质量注入到未充分代表的解决方案区域中来打破这一隐形束缚。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06588", "html_url": "https://arxiv.org/abs/2508.06588", "title": "图是一种自然正则化：重访图表示学习中的向量量化", "title_en": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning", "authors": "Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang", "background": "向量量化（VQ）最近被认为是有潜力的图结构数据离散表示学习方法。然而，代码本崩溃这一根本问题在图域里尚未受到充分研究，这严重限制了图表示的学习性能。", "innovation": "本文首次实证研究显示，即使采取了视觉或自然语言领域提出的缓解策略，将VQ应用于图数据也会出现代码本崩溃现象。文章提供了一种理论分析，发现两个关键因素：图特征的冗余和结构性模式导致的早期分配不平衡，以及确定性VQ中的自我强化优化循环。为此，提出了一种名为RGVQ的新型框架，通过引入图拓扑和特征相似性的显式正则化信号来增强代码本的利用并促进标记的多样性。RGVQ通过Gumbel-Softmax参数化引入软分配，确保所有码字都获取梯度更新，并引入结构感知对比正则化来惩罚不同节点对之间的标记共现。", "conclusion": "大量的实验表明，RGVQ在提高代码本利用和提升图VQ骨干网络在多个下游任务上的性能方面取得了显著效果，从而促进更表达性强且可迁移的图标记表示。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11019", "html_url": "https://arxiv.org/abs/2507.11019", "title": "Relative Entropy Pathwise Policy Optimization", "title_en": "Relative Entropy Pathwise Policy Optimization", "authors": "Claas Voelcker,Axel Brunnbauer,Marcel Hussing,Michal Nauman,Pieter Abbeel,Eric Eaton,Radu Grosu,Amir-massoud Farahmand,Igor Gilitschenski", "background": "基于分数函数的方法，如REINFORCE和PPO，在游戏和机器人领域表现优异，但其高方差常常影响训练稳定性。路径梯度法通过计算目标函数的导数来减少方差问题，但需要精确的基于动作的价值函数，这对于不依赖重放缓冲区来利用过往离策略数据学习时非常困难。", "innovation": "提出了一个纯基于策略轨迹的在线策略算法——相对熵路径梯度策略优化(REPPO)。该算法结合了随机策略的探索和约束更新以实现稳定的训练，并展示了具有良好稳定性和简单稀疏内存特性的高效在线策略算法。相比最先进的方法，REPPO在两个标准GPU并行化基准测试中表现出更强的实证性能，同时在样本效率、计算时间、内存占用和超参数鲁棒性方面更优。", "conclusion": "REPPO算法通过结合路径梯度的稳定性与标准在线学习的简洁性和低内存开销，有效地解决了策略学习中的稳定性问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01188", "html_url": "https://arxiv.org/abs/2508.01188", "title": "SpectrumWorld: 用于光谱学的人工智能基础平台", "title_en": "SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy", "authors": "Zhuo Yang,Jiaqing Xie,Shuaike Shen,Daolang Wang,Yeyun Chen,Ben Gao,Shuzhou Sun,Biqing Qi,Dongzhan Zhou,Lei Bai,Linjiang Chen,Shufei Zhang,Qinying Gu,Jun Jiang,Tianfan Fu,Yuqiang Li", "background": "深度学习在光谱学领域展现出了巨大的潜力，但该新兴领域的研究和评估往往缺乏标准化的方法和框架。", "innovation": "SpectrumLab是一个创新性的统一平台，旨在规范化并加速光谱学领域的深度学习研究。它包含三个核心组件：一个包含数据处理和评估工具的全面Python库，以及排行榜；一个创新的SpectrumAnnotator模块，可以从少量种子数据生成高质量基准；以及一个多层次的基准套件SpectrumBench，涵盖14个光谱学任务和超过10种光谱类型，光谱数据来自超过120万种不同的化学物质。此外，通过SpectrumBench使用18个最新的多模态LLM进行了彻底的实验研究，揭示了当前方法的关键局限性。", "conclusion": "希望SpectrumLab将成为未来光谱学驱动深度学习发展的关键基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02924", "html_url": "https://arxiv.org/abs/2508.02924", "title": "使用变压器的梯度增强技巧与插件", "title_en": "Tricks and Plug-ins for Gradient Boosting with Transformers", "authors": "Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan", "background": "当前的自然语言处理（NLP）架构主要依赖于变压器模型，但这些模型常常需要大量的计算资源和复杂的超参数调优。为解决这些问题，本文分析了变压器在NLP中的主导地位以及其计算资源消耗和调参难题，并探讨了现有解决方案的局限性。", "innovation": "本文提出了一种新颖的框架叫BoostTransformer，通过子网格_token选择和重要性加权抽样，将提升原则应用于变压器。该方法将最小二乘提升目标直接集成到变压器的处理流程中，使得训练更加高效并提升了性能。", "conclusion": "BoostTransformer在多项细粒度文本分类基准测试上展示了更快的收敛速度和更高的准确性，优于标准的变压器模型，同时减少了架构搜索的开销。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17307", "html_url": "https://arxiv.org/abs/2507.17307", "title": "R-Stitch: 动态轨迹缝合以实现高效推理", "title_en": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "authors": "Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang", "background": "链式思考（CoT）可以增强大规模语言模型（LLMs）的问题解决能力，但会因为长自回归路径而引起显著的推理成本。现有的加速策略主要有两种方式：一种是通过早期停止或压缩来缩短跟踪长度；另一种是采用小模型的投机性解码。然而，当模型一致性较低时，投机性解码带来的收益有限，并且它严格要求在令牌级别的一致性，忽视了一个事实：一些正确的小型模型能够产生更为简洁的推理跟踪，从而减少推理长度并提高效率。", "innovation": "本文提出了一个名为R-Stitch的训练无需的方法，它利用令牌级熵作为不确定性代理，来在小型语言模型（SLM）和LLM之间分配计算任务。高熵令牌更易出现错误，因此设计了基于熵的路由策略，使SLM高效处理低熵令牌，并将不确定的令牌路由给LLM，从而避免完全回滚同时保持答案质量。进一步地，R-Stitch+学习自适应路由策略，动态调整令牌预算超过固定阈值。该方法通过共同减少每令牌解码复杂性和生成的令牌数量，实现了显著的加速，同时几乎不损失精度。它还自然实现了适应性的效率-准确性权衡，可以根据不同的计算预算进行调整而无需重新训练。", "conclusion": "该方法在保持与全面LLM解码相同准确度的同时，实现了峰值加速3.00×（DeepSeek-R1-Distill-Qwen-7B）、3.85×（14B）和4.10×（QWQ-32B）。此外，它还使得适应性的效率-准确性权衡成为可能，可以根据各种计算预算进行调整而无需重新训练。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14600", "html_url": "https://arxiv.org/abs/2508.14600", "title": "DualNILM: 通过深度多任务学习实现能量注入识别的细粒度拆分", "title_en": "DualNILM: Energy Injection Identification Enabled Disaggregation with Deep Multi-Task Learning", "authors": "Xudong Wang,Guoming Tang,Junyu Xue,Srinivasan Keshav,Tongxin Li,Chris Ding", "background": "非侵入式负载监测（NILM）为智能住宅和建筑应用提供了获取细粒度电器能耗的低成本方法。然而，随着分布式能源如太阳能板和储能电池在用户侧（BTM）的越来越多使用，传统依赖电表数据的NILM方法面临新的挑战。BTM能源注入会遮蔽个体电器的功率信号，使得NILM性能显著降低。", "innovation": "提出了一个深度多任务学习框架DualNILM，用于同时进行电器状态识别和能量注入识别。通过变压器架构结合序列到点和序列到序列的策略，DualNILM有效地捕捉了聚合功率消耗模式中的多尺度时间依赖性，从而实现精细的电器识别和能量注入识别。在自收集和合成数据集上的广泛评估表明，DualNILM在 NILM 双任务中维持了卓越的性能，远超传统方法。", "conclusion": "我们的工作表明，该框架在现代具有可再生能源渗透的能源系统中具有强大的能量分解潜力。我们将以审核通过后开放制作的合成光伏数据集及实际注入模拟方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00338", "html_url": "https://arxiv.org/abs/2509.00338", "title": "高吞吐量环境中的可扩展选项学习", "title_en": "Scalable Option Learning in High-Throughput Environments", "authors": "Mikael Henaff,Scott Fujimoto,Michael Matthews,Michael Rabbat", "background": "层级强化学习（RL）在长时间决策制定方面具有潜力。现有的方法虽然有前景，但尚未充分利用大规模训练的优势。", "innovation": "提出了一种名为SOL（可扩展选项学习）的算法，相较于现有层级RL方法，SOL在高吞吐量环境中实现了约35倍更高的吞吐量。该研究通过在复杂游戏NetHack中使用300亿帧的经验进行训练，展示了SOL在性能和可扩展性方面的优越性，超越了平面代理并显示出积极的趋势。此外，SOL还在MiniHack和Mujoco环境中进行了验证，展示了其广泛的适用性。", "conclusion": "通过解决高额吞吐量环境下的关键挑战，本研究开发了SOL算法，提升了层级RL的有效性。通过大量的实验，证明了SOL在复杂任务中优于传统方法，并且适用于多种环境。SOL的代码已经开源。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13805", "html_url": "https://arxiv.org/abs/2509.13805", "title": "向通用物理基础模型迈进", "title_en": "Towards a Physics Foundation Model", "authors": "Florian Wiesner,Matthias Wessling,Stephen Baek", "background": "基础模型通过'训练一次，到处部署'的范式，已经变革了自然语言处理领域，使得单个预训练模型能够适应无数下游任务而无需重新训练。然而，当前的物理感知机器学习方法仍然局限于单一、狭窄的应用领域，并且在面对新的系统时需要重新训练。这限制了物理模拟在教育、科研和产业中的广泛应用。因此，开发一个物理基础模型（PFM）对于简化物理原理的模拟，加速科学发现及推动专业化求解器开发的转型具有重要意义。", "innovation": "该研究提出了General Physics Transformer（GPhyT），这是一种训练后能够覆盖多个物理领域的模型，无需被告知具体的物理方程式即可通过上下文学习推断出主导动态。GPhyT实现了三个关键突破：（1）在多个物理领域表现优异，最高比专门架构好29倍；（2）通过上下文学习零样本泛化到全新的物理系统；（3）能够进行长达50个时间步长的稳定长期预测。这项工作展示了单个模型仅从数据中学习可泛化的物理原则的可能性，为通用PFM的开发铺平了道路。", "conclusion": "这项工作揭示了单个模型可以仅从数据中学习可泛化的物理原则，意味着未来可能开发出通用PFM这一领域模型，从而为计算科学和工程领域带来变革。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14134", "html_url": "https://arxiv.org/abs/2508.14134", "title": "ERIS: 一种基于能量导向的特征解缠框架以提高离域时间序列分类性能", "title_en": "ERIS: An Energy-Guided Feature Disentanglement Framework for Out-of-Distribution Time Series Classification", "authors": "Xin Wu,Fei Teng,Ji Zhang,Xingwang Li,Yuxuan Liang", "background": "理想的时序分类模型应该能够捕捉不变特征，但是可靠地在离域数据上实现性能仍然是一个核心障碍。此障碍来源于模型天生将领域特定和标签相关的特征混杂在一起，导致虚假相关性。虽然特征解缠旨在解决这个问题，但现有方法大多缺乏指导意义，未能提供将真正通用特征隔离所需的语义引导。因此需要一种能引导和可靠解缠特征的方法来应对这一挑战。", "innovation": "本文提出了一种端到端的能源正则化信息用于错移稳健性（ERIS）框架，以实现引导和可靠的特征解缠。ERIS框架包含三个关键机制：1) 能量导向校准机制，为解缠提供重要的语义指导，使模型能够自我校准；2) 重量层级正交策略，确保领域特定和标签相关的特征之间结构上独立，从而减少它们的互相干扰；3) 辅助对抗泛化机制，通过注入结构化的扰动增强稳健性。实验结果表明，ERIS在四个基准上的性能显著优于现有最先进的基线方法，并且始终保持了最高性能的排名。", "conclusion": "ERIS框架通过引入能量导向机制和结构化的成对特征约束来实现对领域特征的控制，促进了领域特征和标签相关的特征之间的解缠；同时通过对抗扰动的方式增强了模型的鲁棒性。该方法成功解决了模型在离域数据上的性能问题，显著提高了离域时间序列分类的准确性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03926", "html_url": "https://arxiv.org/abs/2508.03926", "title": "下一代用于人群动力学建模的机器学习方程无模建模", "title_en": "Next Generation Equation-Free Multiscale Modelling of Crowd Dynamics via Machine Learning", "authors": "Hector Vargas Alvarez,Dimitrios G. Patsatzis,Lucia Russo,Ioannis Kevrekidis,Constantinos Siettos", "background": "在人群动力学中，从微观尺度（如个体行人的状态）到宏观尺度（如人群密度）的建模是一个重要的开放挑战，对于系统数值分析、最优化和控制系统提出了要求。本文提出了结合流形学习和机器学习的方法，从高保真个体基于模型仿真中学习宏微观动力学的演化算子，这种方法借鉴了之前关于代数系统的无模型方程技术的工作。该方法分为四个阶段，且在高维空间中显式地保持了宏微观动力学重建中的质量守恒。", "innovation": "提出了一个四阶段的流形学习和机器学习框架，在高维空间中显式保持宏微观动力学的质量守恒。首先利用核密度估计（KDE）从微观数据推导出连续的宏观场（密度）; 第二步利用流形学习构造一组映射，从宏微观的空间映射到由密度分布的POD参数化的潜空间; 第三步利用机器学习技术（特别使用LSTM网络和MVAR模型）学习宏观潜空间的降维模型; 最后一步重建宏微观空间中的群体动力学宏观密度分布。这种方法可以有效创建宏观密度演化的替代算子，用于从个体基于模型的仿真快速准确地建模人群动力学。特别地，线性MVAR模型在预测准确性上超过了非线性LSTM模型，具有显著更低的复杂性和更高的可解释性。", "conclusion": "该研究通过建模框架的创新使用流形学习和机器学习技术，有效地解决了人群动力学的宏微观建模挑战。这种方法的应用验证了高精度、鲁棒性和泛化能力，使得能够快速准确地从个体基于模型的仿真中建模人群动力学，线性MVAR模型在预测准确性、复杂性和可解释性方面表现优异。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15215", "html_url": "https://arxiv.org/abs/2508.15215", "title": "跨域混合EEG和EOG的多通道差异变压器用于睡眠阶段分类", "title_en": "Multi-Channel Differential Transformer for Cross-Domain Sleep Stage Classification with Heterogeneous EEG and EOG", "authors": "Benjamin Wei Hao Chin,Yuin Torng Yew,Haocheng Wu,Lanxin Liang,Chow Khuen Chan,Norita Mohd Zain,Siti Balqis Samdin,Sim Kuan Goh", "background": "睡眠阶段的分类对于评估睡眠质量和诊断睡眠障碍至关重要。然而，手动检查每个阶段的EEG特征耗时且容易出错。虽然已经积极开发了机器学习和深度学习方法，但由于不同临床配置下EEG和EOG信号的非平稳性和变异性，这些方法在推广性方面仍面临挑战，导致分类效果不佳。", "innovation": "本文提出了SleepDIFFormer，这是一种用于异质EEG-EOG表示学习的多通道差异变压器框架。SleepDIFFormer在多个睡眠阶段标注数据集上进行训练（每个数据集作为源域），目标是推广到未见过的目标域。该方法采用多通道差异变压器架构（MDTA），能够处理原始EEG和EOG信号并包含跨域对齐，通过特征分布对齐跨数据集学习领域不变的EEG-EOG表示，从而增强对新域的推广能力。实证研究显示，SleepDIFFormer在多种睡眠阶段数据集下性能优于现有方法，且通过消融研究和解释差异注意力权重，证明该方法的相关性。", "conclusion": "本文的工作推进了自动化睡眠阶段分类的发展，并强调了其在量化睡眠结构和检测干扰恢复休息的异常方面的潜力。源代码和检查点已公开发布。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00832", "html_url": "https://arxiv.org/abs/2509.00832", "title": "非聚合体晶体结构预测的挑战：为什么需要几何和置换不变的损失函数", "title_en": "Challenges in Non-Polymeric Crystal Structure Prediction: Why a Geometric, Permutation-Invariant Loss is Needed", "authors": "Emmanuel Jehanno,Romain Menegaux,Julien Mairal,Sergei Grudinin", "background": "晶体结构预测是设计具有目标特性的材料的必要前提，但在材料设计和药物发现中仍然是一项挑战。尽管计算材料科学取得了进展，但准确预测三维非聚合体晶体结构仍然难以实现。分子组装问题中，一组相同的刚性分子被包装以形成晶体结构，这种方法是对实际问题的一个简化的近似。然而，尽管最新的先进方法越来越多地采用复杂的技巧，但其背后的优化目标仍然存在问题。", "innovation": "作者提出了一种新的公式，引入了一个损失函数，捕捉关键的分子几何特性，同时确保对集合$ \text{S} $的置换不变性。在这个框架下，一个简单的回归模型在COD-Cluster17基准测试中已经优于先前的方法，包括流匹配技术。", "conclusion": "研究表明，在这种方法下，一个简单的回归模型已经在COD-Cluster17基准测试中超过了先前的方法，包括流匹配技术。这种新的公式和损失函数有望为非聚合体晶体结构预测提供更有效的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15735", "html_url": "https://arxiv.org/abs/2509.15735", "title": "EigenTrack：LLMs和VLMs中幻觉和离分布检测的谱激活特征跟踪", "title_en": "EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs", "authors": "Davide Ettori,Nastaran Darabi,Sina Tayebati,Ranganath Krishnan,Mahesh Subedar,Omesh Tickoo,Amit Ranjan Trivedi", "background": "大型语言模型（LLMs）提供广泛的用途，但仍易出现幻觉和离分布（OOD）错误。现有的方法包括黑盒和灰盒方法，但它们需要多次前向传播并缺乏对全局信号和上下文时间的处理能力，同时也缺乏可解释的准确性和延迟权衡。", "innovation": "EigenTrack是一种可解释的实时检测器，它利用隐藏激活的谱几何体，这是一种模型动态的紧凑全局签名。通过将协方差谱统计，如熵、特征值间隙和与随机基线的KL散度等信息流式传输到一个轻量级递归分类器，EigenTrack能够追踪代表结构随时间的变化，这可以信号化幻觉和OOD漂移在表面错误出现之前。与黑盒和灰盒方法不同，它仅需要一次前向传播而不需要重采样；与现有的白盒检测器相比，它保持了时间上下文、聚集了全局信号，并提供了可解释的准确性和延迟权衡。", "conclusion": "EigenTrack通过实时检测和可解释的准确性和延迟权衡，为LLMs和VLMs中的幻觉和OOD检测提供了一种新颖的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17550", "html_url": "https://arxiv.org/abs/2508.17550", "title": "固定权重Transformer中的即席算法模拟", "title_en": "In-Context Algorithm Emulation in Fixed-Weight Transformers", "authors": "Jerry Yao-Chieh Hu,Hude Liu,Jennifer Yuntong Zhang,Han Liu", "background": "本文证明了一个带有冻结权重的最小Transformer通过即席提示能够模拟广泛的算法类别。具体来说，研究了两种即席算法模拟模式：特定任务模式和提示编程模式。在特定任务模式下，对于任意连续函数 f: ℝ → ℝ，存在一个单一头部的softmax注意力层，其前向传播能够精确地重现形如 f(w⊤x - y) 的函数。这一通用模板涵盖了许多流行的机器学习算法（例如梯度下降、线性回归、岭回归）。在提示编程模式下，通过仅使用提示就证明了一种固定权重的两层softmax注意力模块能够模拟特定任务模式下的所有算法（即，每种算法都能通过单一softmax注意力实现）。", "innovation": "本文的关键思想是构建提示，将算法的参数编码为标记表示，从而创建明确的点积差距，迫使softmax注意力遵循所需的计算流程。这种方法不需要前馈层和参数更新，所有的后适应都仅通过提示实现。通过对该模块的数值结果的验证，扩展了对即席学习和算法模拟之间直接关系的理解，并提供了一种大Transformer作为提示编程算法库的简单机制。明确了类似于GPT的基础模型如何仅通过提示替换算法，并确定了现代Transformer模型中的算法万能性。", "conclusion": "这些发现直接连接了即席学习和算法模拟，并为大Transformer被用作算法库的可能性提供了新的视角，展示了现代Transformer模型中的算法通用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14198", "html_url": "https://arxiv.org/abs/2509.14198", "title": "基于残差的自适应性在神经偏微分方程求解器和算子学习中的变分框架", "title_en": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "authors": "Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,Jérôme Darbon,George Em Karniadakis", "background": "残差基自适应策略在科学机器学习中广泛使用，但主要依靠经验性方法。本文引入了一个统一的变分框架，通过将凸变换应用于残差，正式化了这些方法。不同的变换对应不同的目标函数：指数权重旨在最小化均匀误差，而线性权重则恢复最小化二次误差。这一视角使得自适应加权等同于选择能优化原始目标值的采样分布，从而直接将离散化选择与误差度量联系起来。", "innovation": "该文章提出的变分框架具有三大创新点：(1) 允许系统设计跨范数的自适应方案；(2) 通过减少损失估计器的方差降低离散化误差；(3) 提升学习动力学，通过改善梯度信号信噪比来增强学习。", "conclusion": "将该框架扩展到算子学习中，证明了在优化器和架构方面取得了显著的性能提升。本文结果为基于残差的自适应性提供了理论依据，并奠定了原理性离散化和训练策略的基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0会导致稀疏自编码器产生错误的特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器(SAEs)可以从LLM内部激活中提取可解释的概念特征。L0是一个关键的SAE训练超参数，表示每个标记平均应激活多少个SAE特征。现有研究通过稀疏性-重建折衷图比较不同的SAE算法，暗示L0是一个自由参数，没有单一正确的值，除了对重建的影响。本文研究了L0对SAEs的影响，发现如果L0设置不正确，SAEs无法解缠底层特征。L0过低时，SAE会混杂相关特征以改善重建；L0过高时，SAE则会找到退化解决方案，同样混杂特征。此外，本文还提出了一种代理指标，可以帮助指导在特定训练分布下找到正确的L0值。结果显示该方法在玩具模型中找到正确的L0，并且与LLM SAE的稀疏探针性能峰值一致。研究发现，大多数常用SAEs的L0设置过低，表明L0必须正确设置以训练具有正确特征的SAEs.", "innovation": "本文提出了一个代理指标来指导找到正确的L0值，该方法在玩具模型中找到正确的L0值，并且与LLM SAE的稀疏探针性能峰值一致。本文发现大多数常用SAEs的L0设置过低，表明L0必须正确设置以训练具有正确特征的SAEs.", "conclusion": "本文研究表明，如果L0设置不正确，稀疏自编码器无法很好地解缠底层特征。L0过低或过高都会导致特征混杂。通过引入一个新的代理指标，我们发现大多数广泛使用的稀疏自编码器的L0设置过低。因此，正确设置L0对于训练具有正确特征的稀疏自编码器至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03691", "html_url": "https://arxiv.org/abs/2509.03691", "title": "图随机特征在大规模高斯过程中的应用", "title_en": "Graph Random Features for Scalable Gaussian Processes", "authors": "Matthew Zhang,Jihao Andreas Lin,Krzysztof Choromanski,Adrian Weller,Richard E. Turner,Isaac Reid", "background": "本文探讨了图随机特征（GRFs）在离散输入空间中可扩展高斯过程中的应用。研究表明，在温和假设下，使用图随机特征的贝叶斯推断具有相对于节点数 $N$ 的 $O(N^{3/2})$ 时间复杂度，而精确核的方法复杂度为 $O(N^3)$。这种可扩展性使得在单个芯片上对具有超过 $10^6$ 个节点的图执行贝叶斯优化成为可能，同时保持性能竞争力。", "innovation": "将图随机特征引入高斯过程，减少了对图节点的计算需求，从而实现对于大规模图数据的操作，具体表现为相较于精确核方法，使用图随机特征方法能够获得显著的实测时间节省和内存节省。这种方法能够在单个芯片上高效处理具有超过 $10^6$ 个节点的图数据，同时保持性能的竞争力。", "conclusion": "本文证明了，在一定假设条件下，使用图随机特征进行贝叶斯推断能够将时间复杂度从 $O(N^3)$ 降低到 $O(N^{3/2})$，从而使得处理大规模图数据时具有更好的性能和效率。这种方法为大规模图数据的贝叶斯优化提供了新的可能性，使得以往难以处理的大规模图数据问题变得可解。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06580", "html_url": "https://arxiv.org/abs/2509.06580", "title": "AI for Scientific Discovery is a Social Problem", "title_en": "AI for Scientific Discovery is a Social Problem", "authors": "Georgia Channing,Avijit Ghosh", "background": "人工智能有望加速科学发现，但其利益分配不均。技术障碍如稀缺数据、碎片化的标准和不平等的计算访问都显著存在，但作者认为，主要障碍在于社会性和机构性。叙述中推迟进步到推测性的“AI科学家”、低估数据和基础设施的贡献、不匹配的研究动机以及领域专家与机器学习研究人员之间的鸿沟，这些都限制了影响。作者指出了四个相关联的挑战：社区功能障碍、研究优先级与上游需求不匹配、数据碎片化以及基础设施不平等。这些根源在于文化和组织实践，解决这些问题不仅需要技术创新，还需要进行有目的的社区建设、跨学科教育、共享基准以及可行的基础设施。", "innovation": "作者提出了一个创新的视角，即AI在科学发现中的应用不仅仅是技术上的创新，更是一个需要共同社会项目的精神。强调可持续的合作和公平的参与是技术进步的先决条件。作者呼吁重新定义科学中的AI，将其视为集体社会项目的组成部分，以此促进更广泛的合作和公平的参与度，从而推动技术进步的可持续发展。", "conclusion": "需要的技术创新互补于有目的的社区建设、跨学科教育、共享基准以及可行的基础设施，作者强调AI在科学中的应用是一个集体的社会项目，这种合作可以获得长期的技术进展和公平的参与者。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20789", "html_url": "https://arxiv.org/abs/2509.20789", "title": "在状态空间模型中对归纳偏置进行对齐以实现数据高效泛化", "title_en": "Aligning Inductive Bias for Data-Efficient Generalization in State Space Models", "authors": "Qiyu Chen,Guozhang Chen", "background": "大规模模型的成功很大程度上归因于它们遵循的缩放法则，但高质量数据的有限性构成了一个潜在的挑战。模型学习效率的一个前沿领域是数据效率，即如何从更少的数据中学习更多。现有的序列模型，如状态空间模型（SSMs），依赖固定的归纳偏置，在任务结构与模型偏置不匹配时变得样本效率低下。", "innovation": "本文提出了一个解决这一问题的框架。首先通过SSM诱导的核对线性时不变SSM的归纳偏置进行了形式化，证明其频谱直接由模型的频率响应决定。接着提出了一种任务依赖性初始化（TDI）方法：通过功率谱匹配，避免在大规模训练前先使模型的归纳偏置与任务的频谱特征对齐。实验证明TDI在数据稀缺的情境下能够显著提高泛化能力和样本效率。", "conclusion": "本文为创建更的数据高效模型提供了一个理论和实践工具，这有利于实现可持续的模型扩展。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21029", "html_url": "https://arxiv.org/abs/2509.21029", "title": "FORCE: 通过特征过度依赖校正实现可转移的视觉锁机攻击", "title_en": "FORCE: Transferable Visual Jailbreaking Attacks via Feature Over-Reliance CorrEction", "authors": "Runqi Lin,Alasdair Paren,Suqin Yuan,Muyang Li,Philip Torr,Adel Bibi,Tongliang Liu", "background": "多模态大语言模型（MLLMs）通过整合新的模态，增强了其功能，但也引入了额外的安全漏洞。特别地，简单的视觉锁机攻击比复杂的文本攻击更能操控开源的MLLMs，但这些未充分发展的攻击在跨模型间转移性非常有限，不能有效识别封闭源MLLMs中的漏洞。", "innovation": "本文分析了锁机攻击的能量景观，发现在这些攻击中生成的攻击往往位于高锋度区域，这些区域在传输过程中即使微小的参数变化都会对其效果产生高度敏感性。为了进一步解释高锋度局部化，分析了中间层和频谱域的特征表示，揭示了对窄层表征的不当依赖以及语义不良的频率成分。基于这一点，提出了特征过度依赖校正（FORCE）方法，该方法引导攻击探索更广泛的层特征区域，并根据它们的语义内容重新调整频率特征的影响程度。通过消除对层和频谱特征非普遍的依赖，我们的方法发现视觉锁机攻击的平坦可行区域，从而改善了跨模型的转移性。", "conclusion": "广泛的实验表明，我们的方法有效地促进了视觉红队测评针对封闭源MLLMs。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15724", "html_url": "https://arxiv.org/abs/2509.15724", "title": "RMT-KD: 基于随机矩阵理论的因果知识蒸馏", "title_en": "RMT-KD: Random Matrix Theoretic Causal Knowledge Distillation", "authors": "Davide Ettori,Nastaran Darabi,Sureshkumar Senthilkumar,Amit Ranjan Trivedi", "background": "大型深度学习模型如BERT和ResNet尽管表现优异，但由于其体积庞大和计算需求高，部署在边缘端成本高昂。本文分析了这些模型在边缘设备上的部署挑战，并探讨了现有压缩方法的局限性。", "innovation": "提出了一种名为RMT-KD的新压缩方法，利用随机矩阵理论(RMT)进行知识蒸馏，逐步减少网络规模。不同于传统的剪枝或启发式选择，RMT-KD通过隐藏表示的谱特性保留了具有信息性的方向，从而在每个层实现自蒸馏以保持稳定性和准确性。", "conclusion": "在GLUE、AG News和CIFAR-10数据集上的实验结果显示，RMT-KD可以实现高达80%的参数减少，同时仅损失2%的准确性，从而使推理速度提高2.8倍，功率消耗减少近一半。这确立了RMT-KD作为有数学依据的网络蒸馏方法的地位。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2204.05798", "html_url": "https://arxiv.org/abs/2204.05798", "title": "多视角超复数学习方法用于乳腺癌筛查", "title_en": "Multi-View Hypercomplex Learning for Breast Cancer Screening", "authors": "Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello", "background": "放射科医生在解读乳腺X光影像时，需要综合分析四个视角，因为这些视角间的关联对准确诊断至关重要。现有的方法使用专门的融合模块来捕捉这些依赖关系，但这些方法往往受到视角主导、训练不稳定性以及计算开销大的困扰。", "innovation": "引入了多视角超复数学习，这是一种基于参数化超复数神经网络（PHNN）的多视角乳腺癌分类的新学习范式。该方法通过超复数代数原理，能自然地捕捉视角内和视角间的关联。提出了两种视图架构：PHResNets适应于两视角影像，两种互补的四视角架构PHYBOnet（优化效率）和PHYSEnet（优化精度）。实验结果显示，该方法在多种放射学模态和任务中均优于现有的多视角模型。", "conclusion": "研究证实，与现有的多视角模型相比，本方法在乳腺癌筛查等任务中表现更优，并且具有良好的跨模态迁移能力。完整的代码和预训练模型可在提供的链接中获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19406", "html_url": "https://arxiv.org/abs/2509.19406", "title": "TimeMosaic：基于自适应粒度片段和段落级解码的时空异质性引导时间序列预测", "title_en": "TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding", "authors": "Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan", "background": "多变量时间序列预测在金融、交通、气候和能源等领域至关重要。然而，现有的基于片段的方法通常采用固定长度的分割，忽视了局部时间动态的异质性和预测时的解码异质性。这样的设计在信息密集的区域会丢失细节，在稳定段会引入冗余，无法捕捉短期和长期预测视窗的特定复杂性。", "innovation": "本文提出了TimeMosaic，一种旨在解决时间异质性的预测框架。TimeMosaic 采用自适应片段嵌入来根据局部信息密度动态调整粒度，平衡模式重用与结构清晰度，同时保持时间连续性。此外，引入了段落级解码，每个预测视窗被视为关联子任务，适应特定于视窗的难度和信息要求，而不是应用单一均匀解码器。", "conclusion": "广泛的基准数据集评估表明，TimeMosaic 在性能上优于现有方法，且仅用包含321亿观测值的大规模语料库训练的模型在性能上可与最先进的TSFMs媲美。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15815", "html_url": "https://arxiv.org/abs/2509.15815", "title": "基于GPU温度模拟的车载深度学习框架测试方法", "title_en": "GPU Temperature Simulation-Based Testing for In-Vehicle Deep Learning Frameworks", "authors": "Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen", "background": "深度学习模型在自动驾驶系统中扮演重要角色，支持环境感知等功能。为了加速模型推理，这些模型通常部署在汽车的专用深度学习框架中，如Apollo中的PaddleInference和AutoWare中的TensorRT。然而，这些框架在车载环境中面临严峻的挑战，因为车载环境温度变化较大（-40°C至50°C），且计算过程中产生的热量会使GPU温度进一步升高。这些温度变化导致GPU频率动态调整，而现有的汽车深度学习框架在设计时并未考虑温度引起的频率变化，从而导致一些关键问题：计算密集型操作出现延迟或错误，采用高/混合精度的操作出现精度错误，时序操作出现同步问题。现有的深度学习框架测试方法未能检测到这些由于温度影响引起的问题，因为它们不考虑温度对深度学习框架质量的影响。因此，提出了基于GPU温度模拟的车载深度学习框架测试方法——ThermalGuardian，该方法能够有效解决上述问题。", "innovation": "提出了ThermalGuardian，一种在温度变化环境中对车载深度学习框架进行测试的方法。该方法通过模型变异规则和基于牛顿冷却定律的GPU温度模拟，控制实时GPU频率，生成针对温度敏感操作的测试输入模型。这是首个考虑温度影响的车载深度学习框架测试方法。", "conclusion": "ThermalGuardian通过对温度敏感操作生成测试模型、模拟GPU温度波动和控制实时GPU频率，解决当前车载深度学习框架在温度变化环境下的关键问题。这种方法填补了现有测试方法在考虑温度对深度学习框架质量影响方面的空白，提高了车载深度学习框架在各种温度条件下的性能和稳定性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16625", "html_url": "https://arxiv.org/abs/2509.16625", "title": "自监督图表示学习在网络安全入侵检测中的应用", "title_en": "Self-Supervised Learning of Graph Representations for Network Intrusion Detection", "authors": "Lorenzo Guerra,Thomas Chapuis,Guillaume Duc,Pavlo Mozharovskyi,Van-Tam Nguyen", "background": "网络流量中的入侵检测是一项具有挑战性的任务，特别是在监督有限且攻击模式不断演变的情况下。以往的工作使用图神经网络进行网络入侵检测，但往往会将表示学习与异常检测分离，限制了嵌入的实际用途。网络流量中的正常通信模式可以通过特征掩蔽自编码器来学习局部图表示。诱导式的图神经网络将每个流量与其局部拓扑上下文相结合，以捕捉典型网络行为。接下来的基于Transformer的编码解码器重建这些嵌入，这是通过自注意力显式地学习全局共现模式，无需显式提供位置信息。在推理过程中，重建误差异常高的流量将被视为潜在的入侵。该端到端框架确保嵌入直接优化下游任务，以识别恶意流量。", "innovation": "提出了GraphIDS，这是一种自监督入侵检测模型，通过掩码自编码器学习局部图表示，将正常的通信模式嵌入其中。该模型充分利用图神经网络捕捉局部拓扑信息和基于Transformer的编码解码器学习全局共现模式。这种基于自注意力的全局模式学习不需要显式的绝对位置信息。在推断过程中，通过监控重建错误高流量来判断潜在的入侵。这种集成方法确保了嵌入的直接优化，从而提高了恶意流量识别的准确性。", "conclusion": "在各种NetFlow基准测试中，GraphIDS达到了99.98%的PR-AUC和99.61%的宏观F1得分，比基准高出5-25个百分点。这表明GraphIDS模型能够有效识别恶意流量，实现网络安全入侵检测的提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20048", "html_url": "https://arxiv.org/abs/2509.20048", "title": "扩散增强对比学习：一种抗噪生物信号表示的编码器", "title_en": "Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations", "authors": "Rami Zewail", "background": "学习生物信号的稳健表示往往受到有效数据设计挑战的困扰，现有的方法很难捕捉生理数据中的复杂变化。在这种背景下，我们提出了一种新颖的混合框架，扩散增强对比学习（DACL），该框架结合了扩散模型和监督对比学习的概念。DACL框架基于由我们的新型散射变换（ST）特征训练的轻量级变分自动编码器（VAE）生成的潜在空间。该方法利用扩散前向过程作为一种原则性数据增强技术来生成这些潜在嵌入的多个噪声视图。随后使用U-Net风格的编码器，通过监督对比目标，学习一种平衡类间区分与噪声鲁棒性的表示。我们在这方面通过评估在2017年PhysioNet ECG数据集上的方法，获得了竞争力的AUROC值0.7815。这项工作为通过利用扩散过程本身驱动对比目标建立了一种新的表示学习范式，从而创建了抗噪嵌入，展示了良好的类别可分性基础。", "innovation": "提出了一种新的混合框架，扩散增强对比学习（DACL），该框架结合了扩散模型和监督对比学习的概念。该框架利用扩散前向过程作为一种原则性数据增强技术，通过监督对比目标，学习一种平衡类间区分与噪声鲁棒性的表示，从而创建抗噪嵌入，展示了良好的类别可分性基础。", "conclusion": "这项工作通过利用扩散过程本身驱动对比目标建立了一种新的表示学习范式，创建了抗噪嵌入，并展示出强大的类别可分性基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20793", "html_url": "https://arxiv.org/abs/2509.20793", "title": "FERD: 提升公平性的数据无关鲁棒性蒸馏", "title_en": "FERD: Fairness-Enhanced Data-Free Robustness Distillation", "authors": "Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang", "background": "现有方法集中在整体鲁棒性的转移上，但忽略了鲁棒公平性问题，导致不同类别之间的鲁棒性差异严重。学生模型在不同类别上表现不同，其鲁棒性对不同攻击目标的稳定性也较差。", "innovation": "提出了一种提升公平性的数据无关鲁棒性蒸馏（FERD）框架，通过调整对抗样本的比例和分布来解决上述问题。FERD采用鲁棒性引导的类别重新加权策略，生成更多的样本以提高较弱类别的鲁棒性。同时生成公平意识样本（FAEs）以优化特征级预测的一致性，并通过引入统一目标对抗样本（UTAEs）来防止过度拟合到特定的脆弱类别，并避免偏向的攻击方向，从而使攻击目标分布到所有类别。论文在三个公开数据集上的实验表明，FERD在所有攻击场景下都达到了最先进的最差类别鲁棒性，同时在鲁棒性和公平性方面表现优秀。", "conclusion": "FERD框架通过调整对抗样本的比例和分布显著提高了模型在不同类别和不同攻击场景下的鲁棒性和公平性，超过了现有方法的表现。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17186", "html_url": "https://arxiv.org/abs/2509.17186", "title": "Dendritic Resonate-and-Fire神经元用于有效且高效的长序列建模", "title_en": "Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling", "authors": "Dehao Zhang,Malu Zhang,Shuai Wang,Jingya Wang,Wenjie Wei,Zeyu Ma,Guoqing Wang,Yang Yang,Haizhou Li", "background": "序列长度的爆炸性增长加剧了对有效且高效的长序列建模的需求。Resonate-and-Fire (RF) 神经元能够利用内在的膜动态效率地提取输入信号中的频率分量，并将其编码到时空尖峰波形中，这使它们非常适合长序列建模。然而，RF 神经元具有有限的有效记忆容量，并且在复杂时序任务上存在能量效率与训练速度之间的权衡问题。", "innovation": "受生物神经元树突结构的启发，作者提出了一种树突状Resonate-and-Fire (D-RF) 模型，该模型明确地引入了多树突和细胞体架构。每个树突分支利用 RF 神经元的内在振荡动力学来编码特定的频率带，从而实现全面的频率表示。为了在长时间序列任务中维持训练效率并减少冗余尖峰，作者还引入了一种适应性阈值机制，该机制根据历史尖峰活动调整阈值。扩展实验表明，该方法在保持高准确率的同时显著减少了尖峰的产生，同时在训练过程中并没有牺牲计算效率。", "conclusion": "这些结果表明该方法具有在边缘平台上对长时间序列建模的有效且高效解决方案的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.02221", "html_url": "https://arxiv.org/abs/2405.02221", "title": "Fourier Neural Operators 的离散化误差", "title_en": "Discretization Error of Fourier Neural Operators", "authors": "Samuel Lanthaler,Andrew M. Stuart,Margaret Trautner", "background": "算子学习是一种用于从数据中逼近函数空间之间的映射的机器学习变体。Fourier神经算子(FNO)是用于算子学习的主要模型架构之一。FNO将物理空间中的线性和非线性操作与Fourier空间中的线性操作结合起来，形成一个参数化的空间函数之间的映射。虽然FNO在定义上是连续空间中的对象，并在连续域上执行卷积，但其实现是一个离散化的对象，在网格上执行计算，通过FFT（快速傅里叶变换）实现高效的实现。这在概念上与连续定义的FNO存在离散化误差，此误差在实践中用于计算，并且与之前分析的其他模型误差来源有所不同。", "innovation": "该研究分析了Fourier神经算子的离散化误差，并给出了输入正则性函数与网格分辨率之间的代数收敛率。研究还通过数值实验验证了理论，并描述了模型的稳定性。此外，还提出了一种算法，利用离散化误差和模型误差分解优化计算训练时间。", "conclusion": "该研究确定了离散化误差对Fourier神经算子性能的影响，并提出了提高其计算效率的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1807.03907", "html_url": "https://arxiv.org/abs/1807.03907", "title": "在最小-最大优化中的（乐观）梯度下降的极限点", "title_en": "The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization", "authors": "Constantinos Daskalakis,Ioannis Panageas", "background": "该研究受到了优化、博弈论和生成对抗网络训练等领域应用的启发，对最小-最大问题中一阶方法的收敛性质进行了广泛研究。尽管一阶方法可能循环，但对非循环情况下的极限点还缺乏良好的理解。现有研究旨在探讨，在某些基本的一阶方法（如梯度下降/上升和乐观梯度下降上升）收敛时，它们是否收敛到局部最小-最大解。", "innovation": "作者通过从动态系统视角研究这些动态的行为，证明了这两种基本一阶方法（梯度下降/上升和乐观梯度下降上升）几乎在所有初始化条件下避免不稳定临界点。在小步长和轻微假设下，乐观梯度下降上升稳定的临界点集包含梯度下降/上升稳定的临界点集，后者又包含局部最小-最大解（在某些情况下严格包含）。", "conclusion": "这些动态在优化问题中的行为可以通过动态系统理论来研究。对于基本的一阶方法，证明了它们避免不稳定临界点，并且在特定条件下，乐观梯度下降上升的临界点集包含梯度下降/上升的临界点集，这表明局部最小-最大解是这些方法的目标之一。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21196", "html_url": "https://arxiv.org/abs/2509.21196", "title": "Differential-Integral Neural Operator for Long-Term Turbulence Forecasting", "title_en": "Differential-Integral Neural Operator for Long-Term Turbulence Forecasting", "authors": "Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu", "background": "准确预测长期湍流的演变是一个在科学计算中极具挑战性的任务，对于气候建模和航空航天工程等领域有着至关重要的应用价值。现有的深度学习方法，尤其是在长序列自回归预测中，由于灾难性的误差积累和物理保真度的丧失，通常表现不佳。这种表现不佳主要是由于它们无法同时捕捉控制湍流动态的两种不同数学结构：局部耗散效应和全局非局部交互作用。因此，现有方法无法可靠地进行长时间的湍流预测。", "innovation": "本文提出了一种新颖的方法——Differential-Integral Neural Operator (\textbf{\text{DINO}})，它通过从第一原理出发的操作分解方法设计。DINO通过并行分支分别学习不同的物理操作：局部微分操作，由一个受限卷积网络实现，并可证明收敛于一阶导数；全局积分操作，则通过一种Transformer架构学习数据驱动的全局核。这种方法基于物理的分解赋予了DINO卓越的稳定性和鲁棒性。在2D柯尔莫哥洛夫流基准测试中，DINO显著优于最先进的模型，在长时间预测中更加稳定且保持了高保真的涡旋场和能量谱。", "conclusion": "通过广泛的实验，DINO在长期预测中表现出色，成功抑制了数百个时间步长的误差积累，并在涡度场和能量谱中保持了高保真度。DINO为物理一致的大范围湍流预测树立了新的基准。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03981", "html_url": "https://arxiv.org/abs/2410.03981", "title": "低资源和特定领域编程语言基于LLM的代码生成调研", "title_en": "A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages", "authors": "Sathvik Joel,Jie JW Wu,Fatemeh H. Fard", "background": "大型语言模型在生成主流编程语言的代码方面表现出色，但在低资源编程语言（LRPL）和领域特定语言（DSL）方面的表现仍面临显著挑战，影响了数百万，如Rust语言中的350万用户，无法充分利用这些模型的能力。LRPL和DSL面临的数据稀缺和DSL的专有语法等独特障碍使得在这些语言上高效地开发软件变得困难。", "innovation": "本研究对27000余篇论文中的111篇进行了系统回顾，涵盖了从2020年到2024年的研究成果。该研究全面报道了用于LRPL和DSL的LLM的使用情况、基准测试、评估指标、增强性能的策略以及数据集的收集和管理方法。识别出四种主要的评估技术和评估代码生成的多种指标，分类整理了提升方法，并汇总了研究人员提出的新型架构。然而，目前缺乏统一的评估技术和基准数据集来评估LRPL和DSL上的代码生成。", "conclusion": "此调研为LLM、软件工程和专业编程语言交叉领域的研究者和从业人员提供了资源，为进一步在LRPL和DSL上的代码生成研究奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2210.05102", "html_url": "https://arxiv.org/abs/2210.05102", "title": "使用对比学习预训练二进制代码表示", "title_en": "Pre-Training Representations of Binary Code Using Contrastive Learning", "authors": "Yifan Zhang,Chen Huang,Yueke Zhang,Huajie Shao,Kevin Leach,Yu Huang", "background": "二进制代码分析和理解对于反向工程和计算机安全任务至关重要，但在没有源代码的情况下，二进制代码缺乏语义，使得人类工程师难以理解与分析。目前，二进制代码分析和理解仍然面临挑战。因此，通过结合源代码、注释和二进制代码来进行对比学习，以提升二进制代码分析和理解的能力是十分必要的。", "innovation": "本文介绍了ContraBin，这是一种对比学习技术，用于综合源代码、注释和二进制代码，从而生成支持二进制代码分析和理解的任务的嵌入表示。该模型包括三个组件：1)用于初始预训练的主要对比学习方法；2)用于整合源代码、注释和二进制代码的简单内插方法；3)用于训练二进制代码表示的中间表示学习算法。此外，研究发现，尽管合成注释能显著提高性能，但人类编写的注释却引入了噪声，甚至导致性能下降，这改变了对注释类型在二进制代码分析中作用的看法。", "conclusion": "通过对比学习，ContraBin 在四种与二进制代码相关的主要下游任务中均显著提高了性能，包括算法功能分类、函数名称恢复、代码摘要和反向工程等方面。ContraBin 是第一个将源代码、二进制代码和注释整合到对比代码表示学习中的语言表示模型，并旨在推动二进制代码分析领域的发展。相关的研究数据已提供，可供进一步研究使用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2304.13646", "html_url": "https://arxiv.org/abs/2304.13646", "title": "基于协变量信息的数据驱动分段线性决策规则用于随机规划", "title_en": "Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information", "authors": "Yiyang Zhang,Junyi Liu,Xiaobo Zhao", "background": "该研究关注在存在协变量信息的情况下，随机编程（SP）的方法。文章旨在提出一种嵌入非凸分段线性决策规则（PADR）中的经验风险最小化（ERM）方法，以学习特征到最优决策之间的直接映射。该方法已建立非渐近一致性结果（无约束问题）和渐近一致性结果（约束问题）。", "innovation": "该研究开发了一种增强型随机优势最小化算法，解决了非凸、非光滑的ERM问题，并证明了这种算法沿着合成强方向站定性的渐近收敛性和复杂性分析。此外，研究还证明了基于PADR的ERM方法适用广泛类别的非凸SP问题，并且具有理论一致性保证和计算上的可实践性。通过数值研究，证明了基于PADR的ERM方法在各种设置下的优越性能，包括显著降低费用、减少计算时间，以及对未来特征维度和潜在依赖关系非线性的鲁棒性方面都优于最先进的方法", "conclusion": "基于PADR的ERM方法对广泛的非凸SP问题提供了理论一致性保证和计算上的可操作性，并且在数值研究中显示了与最先进的方法相比，具有显著的优越性能，包括较低的成本、较少的计算时间及对特征维度和潜在依赖关系非线性的稳健性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.12717", "html_url": "https://arxiv.org/abs/2312.12717", "title": "DoDo-Code: 一种基于Levenshtein距离嵌入的高效4进制IDS信道纠错码", "title_en": "DoDo-Code: an Efficient Levenshtein Distance Embedding-based Code for 4-ary IDS Channel", "authors": "Alan J.X. Guo,Sihan Sun,Xiang Wei,Mengyi Wei,Xin Chen", "background": "随着新型存储和通信方法的出现，插入、删除和替换（IDS）信道受到了广泛关注。然而，该信道及相关的Levenshtein距离仍有许多待解决的问题。目前，许多研究集中在设计单错误修正的IDS纠删码上，但这无法满足需要纠正多重错误的应用需求。现有解决办法是缩短码字长度以减少多重错误发生的概率，但这降低了码率，从而降低了整体存储密度。", "innovation": "本文提出了一种通过深度Levenshtein距离嵌入设计高码率单错误修正IDS码的新方法。通过深度学习模型将序列投影到保距向量空间中，该嵌入空间作为复杂Levenshtein域的代理，使编解码算法得以开发。这种方法能够设计出在短码长下具有更好性能的纠删码。", "conclusion": "所提出的方法在设计短码长的纠删码上，码率表现优于现有的组合解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.02525", "html_url": "https://arxiv.org/abs/2311.02525", "title": "QECO:基于深度强化学习的用户体验导向计算卸载算法在移动边缘计算中的应用", "title_en": "QECO: A QoE-Oriented Computation Offloading Algorithm based on Deep Reinforcement Learning for Mobile Edge Computing", "authors": "Iman Rahmaty,Hamed Shah-Mansouri,Ali Movaghar", "background": "在移动边缘计算（MEC）的背景下，有效计算任务卸载对保证用户体验（QoE）至关重要。为了满足用户日益增长的服务可靠性需求，在动态和不确定的移动环境中，保持高QoE是一个关键挑战。严格的任务处理截止时间和能源限制可能会负面影响MEC系统的性能。", "innovation": "本文提出了一种基于深度强化学习（DRL）的分布式用户体验导向计算卸载（QECO）算法，使移动设备能够在无需了解其他设备决策的情况下做出卸载决策。与现有的最新工作相比，QECO能够提高14.4%的任务完成率，缩短9.2%的任务延迟，并降低6.3%的能耗，这些都达到了显著的平均QoE提升（37.1%）。这主要是通过准确考虑用户动态和边缘服务器工作负载来做出明智的卸载决策实现的。", "conclusion": "QECO算法在MEC系统中的应用表明，通过精确考虑用户动态和边缘服务器工作负载来使智能卸载决策变得有效，可以显著提高用户体验。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.16322", "html_url": "https://arxiv.org/abs/2409.16322", "title": "在阿尔茨海默病检测中的类内变异性问题", "title_en": "On the Within-class Variation Issue in Alzheimer's Disease Detection", "authors": "Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng", "background": "阿尔茨海默病（AD）的检测通常使用机器学习分类模型来区分AD患者与非患者。与传统的分类任务不同，我们识别出类内变异性是AD检测中的关键挑战：AD患者存在广泛的认知损害。因此，简单的二分类AD方法可能会忽略类内异质性和实例级不平衡这两个重要方面。", "innovation": "我们发现使用样本分数估计器可以生成与认知评分相匹配的样本特异性软评分。随后，我们提出了两种简单而有效的方法：软目标蒸馏（SoTD）和实例级重平衡（InRe），分别针对两个问题。我们在ADReSS和CU-MARVEL数据集中展示了和分析了所提出方法在检测性能上的优势，这些发现为开发稳健和可靠的AD检测模型提供了洞察。", "conclusion": "研究表明，通过研究类内变异性并提出相应的解决方案，可以提高AD检测模型的性能和可靠性。这些方法为未来开发更准确的AD检测模型提供了有效的策略。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.04692", "html_url": "https://arxiv.org/abs/2312.04692", "title": "Diffence：用扩散模型保护成员隐私", "title_en": "Diffence: Fencing Membership Privacy With Diffusion Models", "authors": "Yuefeng Peng,Ali Naseh,Amir Houmansadr", "background": "深度学习模型尽管取得了显著的性能，但仍受到成员推理攻击（MIAs）的影响。尽管已经提出了一些防御措施，但在隐私与实用性之间的权衡上仍有很大的改进空间。本文介绍了一种新的防御框架，通过利用生成模型，该框架旨在在进行推理前去除成员和非成员输入之间的差异，从而预先防御MIAs。这种方法与现有在训练时间或推理后实施的防御措施不同。DIFFENCE的独特之处在于仅对输入样本进行处理，不会修改目标模型的训练和推理阶段，因此可以与其他防御机制结合使用，本文通过实验进行证明。进一步，该方法在保留模型预测标签的同时不降低准确性，并且实验证明其在减少置信向量的有用性方面也表现不佳。", "innovation": "本文提出了一种新的防御框架DIFFERENCE，该框架利用扩散模型在预测之前重新生成输入样本，以去除成员和非成员输入之间的差异，从而在不损害模型性能的情况下提高会员隐私。该框架的特点是仅修改输入样本，不改变目标模型的训练和推理阶段，能够与其他防御机制相结合。与现有的训练时间或推理后实施的防御措施相比，本文的创新之处在于预先防御MIAs，并且不会影响模型的预测标签和置信向量的有用性，同时提供了一种在减少MIA准确性方面显著改善的防御机制，实现良好的隐私性能权衡。", "conclusion": "实验结果表明，DIFFERENCE能够在不损害模型性能的情况下显著提高会员隐私，降低MIAs的准确性。我们还展示了将DIFFERENCE与其他防御机制结合使用可以取得最佳的隐私-实用性权衡，例如与SELENA防御结合使用，可以进一步提高防御性能，降低攻击准确性和AUC。该方法的计算开销较小，仅增加平均每个样本约57ms的推理时间。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03039", "html_url": "https://arxiv.org/abs/2410.03039", "title": "利用模型引导从个性化扩散模型中提取训练数据", "title_en": "Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models", "authors": "Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu", "background": "扩散模型(DMs)已成为强大的图像生成工具，特别是在少量图像对预训练DM进行微调捕捉特定风格或对象的情景下。许多用户将这些个性化模型上传到在线社区(Civitai和HuggingFace)，但模型拥有者在发布微调检查点时可能会忽略数据泄露风险，同时也存在因使用未经授权的数据进行微调而导致版权违规的担忧。因此，本研究旨在探讨是否可以从公开共享的微调DM中提取训练数据，这一过程不仅揭示了数据泄露的风险，还为版权侵权提供了直接证据。", "innovation": "作者提出了一种名为FineXtract的框架，通过将微调视为模型学习分布的逐步变化，从预训练DM向微调数据转变，利用此方法生成高概率区域的图像，并通过聚类算法提取最有可能的图像。实验表明，该方法能够高效地提取约20%的微调数据，验证了其有效性。", "conclusion": "实验表明，FineXtract框架可以成功从公开的微调扩散模型中提取训练数据，不仅展示了数据泄露的风险，还可能提供关于版权侵权的具体证据。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "解析金融领域大语言模型的后训练特性", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "在医学和金融等特定领域，大型语言模型（LLMs）的域适应后训练已成为一种有前景的方法。然而，依然存在识别最优适应准则和适应策略的重大挑战，尤其是在不同数据和模型配置下。针对这一问题，本研究通过系统和细致的调查，引入了FINdap（FINDAP）方法，以构建针对金融领域的大型语言模型。", "innovation": "本研究创新之处在于，提出了FINdap框架，包括定义目标领域关键能力的FinCap模块，涉及连续预训练和指令遵循优化的FinRec方法及创新的过程信号引导偏好数据蒸馏方法，以及支持FinRec的定制训练数据集和评估工具FinEval。这些组件共同作用，使模型（Llama-Fin）在多种金融任务中达到了最先进的性能。", "conclusion": "研究表明，每个后训练阶段都具备特定的功能，并揭示了具体挑战与有效解决方案，为大型语言模型的领域适应提供了宝贵的启示。最终，Llama-Fin模型在广泛金融任务中表现出卓越的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.13514", "html_url": "https://arxiv.org/abs/2410.13514", "title": "GraphSCENE：在仿真中为自动驾驶车辆生成按需关键场景", "title_en": "GraphSCENE: On-Demand Critical Scenario Generation for Autonomous Vehicles in Simulation", "authors": "Efimia Panagiotaki,Georgi Pramatarov,Lars Kunze,Daniele De Martini", "background": "在实际部署之前，测试和验证无人驾驶车辆（AV）在安全性和多样化场景中的表现至关重要。然而，手动在模拟环境中创建此类场景仍然是一项耗时且具有挑战性的任务。本文介绍了一种新的方法，该方法能够根据用户定义的偏好（例如AV的行为、动态代理的集合并关键性水平）生成动态时间场景图，以应对多样化的交通场景，从而满足在模拟环境中按需生成关键场景的需求。", "innovation": "本文提出了一种新的时间和图神经网络模型，能够预测例如自主车、代理和静态结构之间的关系，该模型不仅被现实世界的空间-时间交互模式引导，而且受到一个限制预测为语义有效链接的本体的约束。该模型在准确生成所需场景的关键链接方面优于基准模型。研究团队还通过将预测场景呈现给模拟环境来进一步证明了这些场景作为测试环境的有效性，从而验证了其在为自动驾驶车辆生成关键场景方面的能力和效果。", "conclusion": "本文提出的GraphSCENE方法在模拟中按需生成关键场景，能够根据用户的需求生成多样化的动态场景图，并且在预测场景准确性方面显著优于其他基准模型，为自动驾驶车辆在模拟测试中的应用提供了一种新的有效途径。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07102", "html_url": "https://arxiv.org/abs/2411.07102", "title": "在随机线搜索框架中有效利用动量项以快速优化有限和问题", "title_en": "Effectively Leveraging Momentum Terms in Stochastic Line Search Frameworks for Fast Optimization of Finite-Sum Problems", "authors": "Matteo Lapucci,Davide Pucci", "background": "本文探讨了大规模深度学习情境下的无约束有限和优化问题。主要关注最近在过参数化状态下进行随机优化的线搜索方法与动量方向之间的关系。指出将这两者结合到一起并非易事，为此提出了一种基于小批量持久性的解决方案，并发展了一个结合数据持久性、共轭梯度型规则及随机线搜索的算法框架，以提高优化速度和性能。", "innovation": "论文提出了一种基于小批量持久性的解决方案，并发展了一个新的算法框架，该框架结合了数据持久性、共轭梯度型规则及随机线搜索。该方法在凸性和非凸的大规模训练问题中表现出色，取得了最新的研究成果。", "conclusion": "本文提出的算法具有在适当假设下的收敛特性，并且在大规模训练问题中优于其他现有文献中的流行方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07531", "html_url": "https://arxiv.org/abs/2502.07531", "title": "VidCRAFT3：图像到视频生成中的相机、物体和照明控制", "title_en": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation", "authors": "Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu", "background": "在内容创作流程中，用户需要对相机移动、物体移动和光照方向进行精密且同步的控制，以此提升准确性和灵活性。然而，现有方法通常将这些控制信号分开处理，主要原因在于缺乏高质量的联合标注数据集以及不同模态之间的控制空间不匹配。", "innovation": "VidCRAFT3 提出了一种统一且灵活的图像到视频生成框架，通过三个核心组件支持独立和联合控制相机移动、物体移动和光照方向。具体而言，Image2Cloud 从参考图像重建3D点云以实现精确的相机移动控制；ObjMotionNet 通过多尺度光流特征编码稀疏物体轨迹以引导物体移动；Spatial Triple-Attention Transformer 通过并行交叉注意力整合光照方向嵌入。", "conclusion": "大量实验证明，VidCRAFT3 在控制精度和视觉连贯性方面优于现有方法。项目页面提供了代码和数据下载链接。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.23261", "html_url": "https://arxiv.org/abs/2410.23261", "title": "10万美元或100天：使用学术资源进行预训练的权衡", "title_en": "$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources", "authors": "Apoorv Khandelwal,Tian Yun,Nihal V. Nayak,Jack Merullo,Stephen H. Bach,Chen Sun,Ellie Pavlick", "background": "学术研究往往计算资源匮乏，而预训练模型又通常需要大量的计算资源。因此，普遍认为学术研究人员无法进行模型的预训练。这篇文章的目标是澄清这个假设，通过调查学术研究人员的可用计算资源，并实证测量在这些资源上复现模型所需时间，来探究学术预训练的可能性。作者还引入了基准测试来衡量给定GPU上进行模型预训练所需的时间，并确定了最大化训练速度的最佳设置。", "innovation": "文章通过实证研究提供了一个新的视角：学术研究人员可以使用较少的GPU时间和成本来复现原本在大量GPU上训练的模型。这挑战了学术界无法进行预训练模型的传统看法。基准测试的引入也是创新的一部分，它可以帮助学术研究人员更好地安排资源，进行更大规模的数据训练。", "conclusion": "文章最后进行了一项成本效益分析，以帮助理清价格和预训练时间之间的权衡。作者认为，通过公开代码库，他们的基准测试将有助于学术研究人员在更多数据上训练更大模型的研究工作。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07145", "html_url": "https://arxiv.org/abs/2410.07145", "title": "Stuffed Mamba: Oversized States Lead to the Inability to Forget", "title_en": "Stuffed Mamba: Oversized States Lead to the Inability to Forget", "authors": "Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "近期递归架构的发展，如Mamba和RWKV，表明了强大的语言能力。这种架构通过固定大小的状态来编码所有上下文信息，而不是采用基于变换器模型的方式，这种方式带来了极高的推理效率。然而，这种单固定大小状态的方式也可能引起信息干扰，导致不同token数据之间的冲突，使得模型超出特定上下文长度后性能下降且输出不一致。现有的大部分递归神经网络使用内置的机制来“忘记”先前的token，但大部分模型仍然难以有效“忘记”。这些递归模型在短上下文训练中表现良好，因此在训练时无需学习如何“忘记”，但随着模型状态大小的增加，模型在需要学习“忘记”机制的训练长度上需要更长的上下文，同时这种模型能够准确检索5位数密码的有效上下文长度随着状态大小的增加呈指数增长，意味着模型会保留一些信息直到“忘记”机制开始发挥作用。", "innovation": "该研究揭示了基于Mamba的模型即使配备了内置的遗忘机制也难以有效遗忘早期token的问题。研究表明，这一问题是由于在较短的上下文中进行训练导致的，使得模型不需学习如何遗忘。同时，研究指出，模型学习遗忘机制所需的训练上下文长度与状态大小成线性关系，而准确检索5位数密码的最长有效上下文长度与状态大小呈指数关系。这些发现指出了当前递归神经网络架构的关键局限，并提供了改进长上下文建模的关键见解。研究建议未来递归架构设计必须考虑到状态大小、训练长度和遗忘机制之间的相互作用以实现长上下文任务中的稳健性能。", "conclusion": "现有的递归架构存在关键局限，即将较大数据状态大小与遗忘机制之间的矛盾直接导致无法有效遗忘。该研究揭示了这一问题的根本原因，并强调了设计递归神经网络时必须考虑状态大小、训练长度和遗忘机制相互作用的重要性。未来的研究需要优化这些因素之间的平衡以提高递归神经网络在长上下文任务中的表现。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05723", "html_url": "https://arxiv.org/abs/2412.05723", "title": "大语言模型低秩适配器的无训练贝叶斯化", "title_en": "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models", "authors": "Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang", "background": "评估大型语言模型（LLMs）响应的不确定性估算仍是一项重要挑战。尽管近期的贝叶斯方法在通过低秩权重更新量化不确定性方面显示出有效性，但它们通常需要复杂的重新训练或后训练过程。", "innovation": "提出了无训练贝叶斯化（TFB），这是一种简单且理论依据充分的框架，能够在不进行额外训练的情况下，高效地将已训练的低秩适配器转换为贝叶斯适配器。TFB 在低秩各向同性高斯分布族内部系统地搜索权重后验中可接受的最大方差水平。理论分析表明，在温和条件下，搜索过程相当于KL-正则化的变分优化，这是变分推断的一种更一般的形式。实验结果表明，TFB 在不确定性估算和泛化性能方面优于现有方法，同时消除了复杂的贝叶斯化训练过程的需求。", "conclusion": "无训练贝叶斯化方法TFB能够在不进行额外训练的情况下高效地将已训练的低秩适配器转换为贝叶斯适配器，从而实现优越的不确定性和泛化能力，而无需复杂的重新训练或后训练过程。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14539", "html_url": "https://arxiv.org/abs/2501.14539", "title": "IP$^{2}$-RSNN: Bi-level Intrinsic Plasticity Enables Learning-to-learn in Recurrent Spiking Neural Networks", "title_en": "IP$^{2}$-RSNN: Bi-level Intrinsic Plasticity Enables Learning-to-learn in Recurrent Spiking Neural Networks", "authors": "Yingchao Yu,Yaochu Jin,Kuangrong Hao,Yuchen Xiao,Yuping Yan,Hengjie Yu,Zeqi Zheng,Wenxuan Pan", "background": "学习-学习（L2L）是神经科学和人工智能中的核心概念，指的是通过相似任务的多样化学习，从而实现更快的学习过程。然而，L2L的神经基础尚不清楚。大多数研究侧重于突触可塑性引发的神经元群体动力学，而忽视了由内在神经元可塑性驱动的适应性，这点无法用点神经元模型捕捉到。", "innovation": "本文开发了一种具有双层内在可塑性（IP$^{2}$）的循环脉冲神经网络（IP$^{2}$-RSNN）。双层内在可塑性包括慢速元内在可塑性和快速内在可塑性。前者根据任务需求决定哪些神经元属性是可学习的，一旦配置好就在后续任务学习中保持不变；后者在每次任务中精细调整那些可学习的属性。实验表明，双层内在可塑性对于IP$^{2}$-RSNN实现自适应L2L至关重要。它在性能上优于点神经元循环神经网络和自注意力模型。此外，多尺度神经动力学分析表明，双层内在可塑性在L2L过程中对神经元和网络层面的任务类型特定适应是必不可少的，而点神经元模型无法捕捉到这些适应。", "conclusion": "本文的研究结果表明，内在可塑性在L2L中提供了显著的计算优势，这为设计受大脑启发的深度学习模型和算法提供了新的见解。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.01423", "html_url": "https://arxiv.org/abs/2411.01423", "title": "加速分子设计的条件潜空间分子骨架优化", "title_en": "Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design", "authors": "Onur Boyar,Hiroyuki Hanada,Ichiro Takeuchi", "background": "快速发现新的化学化合物对于提高全球健康水平和开发治疗方法至关重要。尽管生成模型在创建新型分子方面显示出潜力，但在确保这些分子的现实应用性和高效发现它们方面仍存在挑战。针对这一挑战，本文提出了一种结合条件变分自编码器（CVAE）和潜空间贝叶斯优化（LSBO）的Conditional Latent Space Molecular Scaffold Optimization (CLaSMO) 算法，通过对分子进行战略性修改，同时保持与原始输入的相似性，将其任务框架化为约束优化。该算法通过在CVAE的潜空间中对目标分子的原子环境进行条件化来进行贝叶斯优化，从而有效地探索分子的亚结构。", "innovation": "CLaSMO结合了条件变分自编码器（CVAE）和潜空间贝叶斯优化（LSBO），通过潜空间中目标分子的原子环境条件化进行贝叶斯优化，高效地探索分子的亚结构。与现有方法相比，CLaSMO在目标属性提升、样本效率、考虑分子相似性约束以及保持实际合成可及性方面表现出卓越性能。该算法适用于资源受限的场景，并实现了最先进的性能。此外，还提供了开源的Web应用，使化学专家能够在人机协作（Human-in-the-Loop）模式下使用CLaSMO。", "conclusion": "CLaSMO算法通过潜空间贝叶斯优化技术结合条件变分自编码器有效解决了分子设计中的现实应用性问题和分子相似性约束问题。在多种优化任务中，CLaSMO表现出优秀的样本效率和对目标属性的增强能力，并在多个方面达到了最先进的水平，同时保持了实际合成的可及性。同时，该算法还提供了一种人机协作的方式供化学专家使用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09579", "html_url": "https://arxiv.org/abs/2503.09579", "title": "长上下文建模中成本最优的分组查询注意力", "title_en": "Cost-Optimal Grouped-Query Attention for Long-Context Modeling", "authors": "Yingfa Chen,Yutong Wu,Chenyang Song,Zhen Leng Thai,Xingyu Shen,Xu Han,Zhiyuan Liu,Maosong Sun", "background": "分组-查询注意力（GQA）是减少大型语言模型（LLMs）中注意力层计算成本的一种常用策略。然而，当前的GQA配置往往不够优化，因为它们忽视了上下文长度对推理成本的影响。随着上下文长度的增加，推理成本也会增加，因此成本优化的GQA配置也应相应变化。", "innovation": "本文提出了两项创新：1. 将总头尺寸与隐藏尺寸解耦，以更灵活地控制注意力FLOPs；2. 联合优化模型尺寸和GQA配置，以更有效地分配注意力层与其他组件之间的推理资源。研究表明，常用的GQA配置在长上下文场景中高度不理想。更重要的是，我们提出了一种低成本的GQA配置方法。这些配置在长上下文场景中使用较少的注意力头，同时扩大模型规模，能够减少超过50%的内存使用和FLOPs，而不会影响模型的能力。", "conclusion": "我们的研究提供了设计高效长上下文LLM的重要见解，实验代码可访问https://www.example.com."}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05563", "html_url": "https://arxiv.org/abs/2504.05563", "title": "数据估值能做出好的数据定价吗？", "title_en": "Do Data Valuations Make Good Data Prices?", "authors": "Dongyang Fan,Tyler J. Rotello,Sai Praneeth Karimireddy", "background": "随着大型语言模型越来越多地依赖外部数据源，补偿数据贡献者的做法变得越来越重要。然而，这些补偿应该如何进行？论文从市场设计的角度回顾了数据估值，指出传统的估值方法如Leave-One-Out和Data Shapley导致不真实的成本报告，引发市场低效。", "innovation": "论文提出了将机制设计中成熟的支付规则，如Myerson和Vickrey-Clarke-Groves（VCG），应用于数据市场设置。Myerson支付被视为最小微谎真机制，从买家的角度是最优的。此外，论文还找到一个条件，在此条件下买卖双方都满意且市场达到高效。", "conclusion": "研究结果强调了在数据估值设计中整合激励相容性的重要性，为更加健壮和高效的数据库市场奠定了基础。该数据市场框架在现实场景中有广泛应用，通过一个基于检索增强生成（RAG）的LLM医疗问答市场的示例进行了说明。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07528", "html_url": "https://arxiv.org/abs/2502.07528", "title": "专业足球运动员品质和价值未来发展的预测", "title_en": "Forecasting the future development in quality and value of professional football players", "authors": "Koen W. van Arem,Floris Goes-Smit,Jakob Söhl", "background": "在职业足球领域，转会费用高昂且风险较高，导致转会交易具有不确定性。尽管数据驱动的模型可以帮助改善转会决策，但现有的模型主要集中在描述球员的历史表现，而无法预测其未来表现。近年来，需要使用可解释模型并结合预测的不确定性量化。本研究评估解释性机器学习模型在预测专业足球运动员品质和价值未来发展的准确性和不确定性量化方法方面的表现。通过训练模型预测一年后的球员品质和价值来衡量预测准确性，使用历史数据集中的数据驱动指标来描述球员品质和价值。一般而言，随机森林模型被认为是最合适的模型，因为该模型能提供准确的预测，并且包袋过程自然产生了不确定性量化方法。此外，研究表明球员表现的发展包含非线性模式和变量之间的相互作用，时间序列信息也提供了有用的模型球员表现指标的信息。", "innovation": "该研究使用解释性机器学习模型来评估预测准确性和不确定性量化方法，以预测专业足球运动员品质和价值未来的发展。随机森林模型被证明是最适合的模型，因为它不仅能提供准确预测，还能提供自然产生的不确定性量化方法。另外，研究指出球员表现的发展包含非线性模式和变量之间的交互，时间序列信息对模型球员表现指标有帮助。", "conclusion": "研究结果表明，随机森林模型可用于预测专业足球运动员未来品质和价值，并且通过时间序列信息和互动变量提高模型性能。这种方法可以帮助足球俱乐部进行数据驱动的更明智的转会决策。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01986", "html_url": "https://arxiv.org/abs/2503.01986", "title": "使用任务诱发型自适应模型画像", "title_en": "Adaptively profiling models with task elicitation", "authors": "Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong", "background": "语言模型评估通常无法准确捕捉到重要缺陷，迫使专家检查模型输出并建立新基准。这项研究背景指出，现有方法在识别模型关键失败模式方面存在局限，如评估手段单一、覆盖范围有限等，导致未能全面评估模型性能和行为，尤其是复杂和多变的应用场景。", "innovation": "该研究引入了任务诱发型方法，可自动构建新的评估来剖析模型行为。该方法能够找到数百个自然语言任务，比以往工作多出一个数量级，覆盖从预测到在线骚扰等不同领域，揭示模型的系统性失常。例如，研究发现Sonnet 3.5在量子计算和AGI关联上表现过度，而o3-mini在重复编造内容上下文中容易产生幻觉。", "conclusion": "任务诱发型方法能够有效识别模型在不同领域的关键失败模式，提供更全面、更细致的模型评估机制。未来可以通过进一步研究优化该方法，使得其在更多复杂应用场景中发挥作用，更好地指导模型开发和应用。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02904", "html_url": "https://arxiv.org/abs/2503.02904", "title": "Surgical Vision World Model", "title_en": "Surgical Vision World Model", "authors": "Saurabh Koju,Saurav Bastola,Prashant Shrestha,Sanskar Amgain,Yash Raj Shrestha,Rudra P. K. Poudel,Binod Bhattarai", "background": "现实和互动的外科手术模拟具有促进关键应用的潜力，如医疗专业人员培训和自主外科代理训练。在自然视觉领域，世界模型能够通过动作控制的数据生成来实现这一目标，当大规模真实数据获取不可行时，可以利用其潜力进行交互式模拟环境中的自主代理训练。然而，在外科手术领域，此类工作仍然局限于简化的计算机模拟，并缺乏现实感。此外，现有文献中的世界模型主要处理带有动作标签的数据，限制了其在获取动作注解成本高昂的实际外科手术数据中的应用。", "innovation": "本文提出了第一个外科手术视觉世界模型。该模型能够生成动作可控的外科手术数据，并通过广泛的实验在未标记的SurgToolLoc-2022数据集上验证了其架构设计。这项工作借鉴了Genie的成功经验，通过利用未标注的电子游戏视频数据来推断潜在动作并实现动作可控的数据生成。", "conclusion": "所提出的模型在未标记的SurgToolLoc-2022数据集上通过广泛的实验验证了其架构设计的有效性，相关代码和实施细节可以在提供。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.11947", "html_url": "https://arxiv.org/abs/2503.11947", "title": "为年轻数字公民服务的道德AI：隐私治理的呼吁", "title_en": "Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance", "authors": "Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha", "background": "人工智能（AI）在年轻人使用的数字平台上的快速扩张带来了与隐私、自主权和数据保护相关的重大挑战。尽管基于AI的个性化功能可以提升用户体验，但其通常缺乏明确的伦理边界，使年轻用户容易受到数据利用和算法偏见的影响。", "innovation": "本文提出了一个针对年轻人的隐私保护的道德AI治理呼吁，强调需要在算法透明度、隐私教育、家长与子女间的数据共享伦理以及问责制方面采取迫切干预措施。通过这种方法，作者希望赋予年轻人对数字身份的更大控制权，并为政策制定者、AI开发者和教育工作者提供了创建更加公平和负责的AI生态系统的一系列具体策略。", "conclusion": "本文呼吁创建一个以年轻人为中心的隐私保护结构化框架，确保透明的数据实践和监管审查，以期赋予年轻人在数字身份方面更大的控制权，并提出了政策制定者、AI开发者和教育工作者可以采取的具体策略来构建更公平和负责任的AI生态系统。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.13562", "html_url": "https://arxiv.org/abs/2503.13562", "title": "检测稀少且稀疏的异常：解决多实例学习中的双重不平衡问题", "title_en": "Detecting Scarce and Sparse Anomalous: Solving Dual Imbalance in Multi-Instance Learning", "authors": "Lin-Han Jia,Lan-Zhe Guo,Zhi Zhou,Si-Ye Han,Zi-Wen Li,Yu-Feng Li", "background": "在实际应用中，当异常样本极为稀少且稀疏时，检测这些异常样本极具挑战性，因为它们与正常样本高度相似，容易被混淆。同时，异常样本的数量相对较少。这导致了多实例学习（MIL）中的双重不平衡问题，这一问题在宏观和微观层面上都有体现。", "innovation": "我们发现，MIL问题可以重新定义为精细粒度的PU学习问题，这允许我们使用微级别平衡机制以无偏的方式解决不平衡问题。为此，我们提出了一个基于严格理论基础的新型框架BFGPU（Balanced Fine-Grained Positive-Unlabeled，平衡的精细粒度正-未标注）。", "conclusion": "在合成数据集和真实数据集上进行的广泛实验表明，BFGPU的有效性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11258", "html_url": "https://arxiv.org/abs/2504.11258", "title": "绿色温室气体抵消信用市场的多智能体强化学习", "title_en": "Multi-Agent Reinforcement Learning for Greenhouse Gas Offset Credit Markets", "authors": "Liam Welsh,Udit Grover,Sebastian Jaimungal", "background": "气候变化是人类未来面临的重大威胁，人为温室气体排放不断加剧其影响。一种政府可以控制这些排放的方法是为公司提供排放上限，并对超过该限额的排放进行处罚。公司可以通过投资减少和捕获碳的项目来抵消超过限额的部分，这些项目将产生可用于上交给监管机构抵消公司超额排放的抵消信用，或者可以在不同公司之间进行交易。", "innovation": "我们利用现代强化学习技术Nash-DQN来有效地估计市场的纳什均衡，从而确定有限代理的纳什均衡。通过数值实验证明了将强化学习方法应用于以气候为主题的投资市场不仅有效，同时企业通过遵守纳什均衡可以节省大量财务支出。", "conclusion": "我们的研究不仅验证了采用强化学习方法来解决以气候为主题的投资市场问题的有效性，还通过计算纳什均衡来具备经济节省效果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10434", "html_url": "https://arxiv.org/abs/2503.10434", "title": "通过人类反馈强化学习学习个性化驾驶风格", "title_en": "Learning Personalized Driving Styles via Reinforcement Learning from Human Feedback", "authors": "Derun Li,Changye Li,Yue Wang,Jianwei Ren,Xin Wen,Pengxiang Li,Leimeng Xu,Kun Zhan,Peng Jia,Xianpeng Lang,Ningyi Xu,Hang Zhao", "background": "在动态环境中，生成人类相似且适应性强的轨迹对于自动驾驶至关重要。尽管生成模型在合成可行轨迹方面显示出潜力，但由于数据集偏差和分布偏移，它们往往无法捕捉到个性化驾驶风格的细微差别。为了解决这一问题，提出了TrajHF，这是一种基于人类反馈的生成轨迹模型微调框架，旨在将运动规划与多样的驾驶风格对齐。TrajHF结合了多条件去噪器和强化学习，利用人类反馈对多模态轨迹生成进行细化，超越了传统模仿学习。这使TrajHF能够更好地与人类驾驶偏好保持一致，同时保持安全和可行性约束。TrajHF在NavSim基准测试中实现了与最新技术水平相当的性能。TrajHF为自动驾驶中的个性化和适应性强轨迹生成设定了一个新的范式。", "innovation": "TrajHF是一种人类反馈驱动的生成功能轨迹模型的微调框架，结合了多条件去噪器和强化学习方法，增强了多模式轨迹生成，超越了传统的模仿学习方法。这种框架有助于更好地与人类驾驶偏好保持一致，同时保持安全性与可行性约束。", "conclusion": "TrajHF在NavSim基准测试中达到了与最先进的技术水平相当的性能，为自动驾驶中的个性化和适应强轨迹生成提供了新的范式。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.11425", "html_url": "https://arxiv.org/abs/2402.11425", "title": "平均预算约束下的在线资源分配", "title_en": "Online Resource Allocation with Average Budget Constraints", "authors": "Ruicheng Ao,Hongyu Chen,David Simchi-Levi,Feng Zhu", "background": "本文考虑的是在线资源分配问题，其中平均资源消耗受到限制。在每个时间点上，决策者需要在下一个请求到来之前做出接受或拒绝请求的不可撤销决策，目标是最大化累计奖励。与现有的需要总资源消耗不超过某一水平的研究不同，本文要求的是每个被接受请求的平均资源消耗不超过一个给定的阈值。这个问题可以看作是具有外生随机预算补充的在线背包问题，并且可以应用于各种领域，如在线异常检测、序列化广告投放和人均公共服务提供者等。", "innovation": "1. 提出了一个简单策略，实现了$O(\frac{1}{\nu} \times \frac{\beta}{\beta-\beta_0} \times \frac{\beta_0}{\beta} \times \frac{\beta_0}{\beta_0 - \beta_0} \times \frac{\beta - \beta_0}{\beta_0} \times \nu \times \frac{1}{\nu} \times \frac{\beta}{\beta - \beta_0} \times \frac{\beta - \beta_0}{\beta_0} \times \nu \times \frac{\beta - \beta_0}{\beta_0} \times \nu \times \frac{1}{\nu} \times \frac{\beta}{\beta - \beta_0} \times \frac{\beta - \beta_0}{\beta_0} \times \nu \times \frac{1}{\nu} \times \frac{\beta}{\beta - \beta_0} \times \frac{\beta - \beta_0}{\beta_0} \times \nu)$的后悔率（$O(\frac{1}{\nu^2} \times \frac{\beta_0 - \beta}{\beta - \beta_0 - \beta_0} \times \frac{\beta - \beta_0}{\beta_0 - \beta_0} \times \nu^2 \times \frac{1}{\nu^2} \times \frac{\beta}{\beta - \beta_0 - \beta_0} \times \frac{\beta - \beta_0}{\beta_0 - \beta_0} \times \nu^2 \times \frac{1}{\nu^2} \times \frac{\beta}{\beta - \beta_0 - \beta_0} \times \frac{\beta - \beta_0}{\beta_0 - \beta_0} \times \nu^2))$。\n2. 确定了在离散到达分布的情况下，许多现有的在线资源分配文献中的重新解决启发式算法可能产生$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$或甚至$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$后悔率。\n3. 提出了一个新的策略，该策略结合了预算的安全缓冲，通过引入微量的安全性，显著提高了效率，小的额外对数缓冲足以将后悔率从$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$或甚至$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$降低到$O(\text{ln}^2 \frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0})$。\n4. 将策略扩展到连续到达分布、时间相关的信息结构以及未知的时间范围，并通过合成实验和纽约市出租车乘客的时序数据进行实证研究来验证所提出策略的性能。", "conclusion": "本文通过理论分析和实证研究，提出了一个能够有效应对在线资源分配中平均预算约束问题的策略。该策略通过引入微量的安全缓冲显著提高了在离散到达分布下的效率，并且通过理论证明该策略的后悔率可以从$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$或$\text{\textOmega}(\frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0} \times \nu_0^2)$降低到$O\text{(\text{ln}^2 \frac{1}{\nu_0} \times \frac{\beta - \beta_0}{\beta - \beta_0 - \beta_0})}$。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12872", "html_url": "https://arxiv.org/abs/2505.12872", "title": "从咕噜声到词典：合作觅食中涌现的语言", "title_en": "From Grunts to Lexicons: Emergent Language from Cooperative Foraging", "authors": "Maytus Piriyajitakonkij,Rujikorn Charakorn,Weicheng Tao,Wei Pan,Mingfei Sun,Cheston Tan,Mengmi Zhang", "background": "语言是一种强大的交流和认知工具，它使人类能够表达思想、分享意图并推理复杂的现象。尽管人类在使用和理解语言方面非常熟练，但语言是如何起源和发展的问题仍未得到解答。语言学和人类学中的一个主要假说是，语言是为了满足早期人类合作的生态和社会需求而进化的。语言不是孤立地出现的，而是通过共享的生存目标而发展起来的。", "innovation": "我们通过研究多智能体觅食博弈来探讨语言的产生。这些环境旨在反映被认为影响交流演化的认知和生态限制。智能体在一个带有部分知识的共享网格世界中操作，必须协调完成诸如拾取高价值目标或执行时间顺序动作的游戏。通过端到端的深度强化学习，智能体从头开始学习动作和交流策略。我们发现智能体发展出了具有自然语言标志性特征的交流协议：任意性、可替换性、位移性、文化传承性和组合性。我们量化了每个特性，并分析了不同因素（如群体规模、社会动态和时间依赖性）如何塑造得出的语言的具体方面。我们的框架为研究语言如何从部分可观测性、时间推理和合作目标在具身多智能体环境中进化提供了一个平台。我们将会公开发布所有数据、代码和模型。", "conclusion": "我们的研究提供了关于语言如何在生态环境和社会需求的驱动下进化的新见解，展示了通过多智能体觅食博弈可以让智能体自然发展交流策略，这些策略具备语言的基本特征。这些发现为理解语言的起源和发展提供了一个新的视角，并为未来研究语言如何在具备特定条件的环境下自动生成提供了有力的证据。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16965", "html_url": "https://arxiv.org/abs/2505.16965", "title": "BP-Seg：利用信念传播的图形模型方法实现无监督和非连续文本分割", "title_en": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation", "authors": "Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz", "background": "文本分割是一种基于句子语义的重要任务，在许多下游应用中有着广泛的应用价值。", "innovation": "本文提出了一种基于图形模型的无监督学习方法BP-Seg，该方法不仅能考虑局部连贯性，还可以有效分组文本中虽然距离较远但语义相似的句子。这一方法通过精心构建的图形模型上的信念传播实现。", "conclusion": "在具有长文档的数据集和示例上的实验结果表明，与竞争性方法相比，我们的方法表现良好。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16415", "html_url": "https://arxiv.org/abs/2505.16415", "title": "上下文归因：检索增强生成中的杰宾-香农散度驱动机制研究", "title_en": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation", "authors": "Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz", "background": "检索增强生成（RAG）利用大型语言模型（LLMs）结合外部上下文来提高生成回复的准确性和可靠性。然而，可靠地将生成的内容归因于特定的上下文片段（上下文归因）仍具有挑战性，因为当前的方法往往需要大量的微调或人工标注，这在计算上非常耗时。", "innovation": "本文介绍了一种新的由杰宾-香农散度驱动的方法来归因于上下文（ARC-JSD），该方法能够无需额外的微调、梯度计算或代理模型的情况下，高效且准确地识别关键的上下文句子。该方法在TyDi QA、Hotpot QA和Musique等多种RAG基准测试上展示了相比基于代理模型的前一个方法更高的准确性和显著的计算效率改进。此外，机制分析揭示了特定的注意力头和多层感知器（MLP）层负责上下文归因，对RAG模型内部工作机制及其对RAG行为的影响提供了有价值的见解。", "conclusion": "我们的结果证明ARC-JSD方法在效率和准确性方面都优于现有的基于代理模型的方法。此外，还通过机械分析发现了用于归因的关键注意力头和MLP层，这有助于深入理解RAG模型的行为。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20321", "html_url": "https://arxiv.org/abs/2505.20321", "title": "BiomedSQL：生物医学知识库上的科学推理文本到SQL", "title_en": "BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases", "authors": "Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri", "background": "生物医学研究人员越来越多地依赖大规模结构化数据库进行复杂的分析任务。然而，当前的文本到SQL系统往往在将定量的科学问题转换为可执行的SQL查询时遇到困难，尤其是在需要隐含领域推理时。论文介绍了BiomedSQL，这是一个首个明确设计来评估在真实生物医学知识库中进行文本到SQL生成时科学推理能力的基准。", "innovation": "BiomedSQL包含68,000个以标准化BigQuery知识库为基础的问题/SQL查询/答案三元组，该知识库整合了基因-疾病关联、 omics 数据因果推理以及药物批准记录。每个问题都需要模型推断特定领域的标准，如全基因组显著性阈值、效应方向性或试验阶段滤波，而不仅仅是依靠语法翻译。论文评估了来自不同来源的多种开放源代码和闭源的大型语言模型（LLMs），并采用了不同的提示策略和交互模式。", "conclusion": "研究结果表明存在显著的性能差距：GPT-o3-mini 的执行准确率为59.0%，而我们定制的多步代理BMSQL 达到62.6%，均远低于专家基准的90.0%。BiomedSQL 为推进能够支持科学发现的文本到SQL系统的快速发展提供了新的基础。该数据集和代码在公开资源中可获取。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16331", "html_url": "https://arxiv.org/abs/2504.16331", "title": "代码语言模型能否学习寻求澄清的行为？", "title_en": "Can Code Language Models Learn Clarification-Seeking Behaviors?", "authors": "Jie JW Wu,Manav Chaudhary,Davit Abrahamyan,Arhaan Khaku,Anjiang Wei,Fatemeh H. Fard", "background": "大型语言模型（LLMs）在代码生成任务中展现了出色的能力。然而，它们的输出和人类开发者的解题策略之间仍存在差距。不同于人类程序员通过迭代对话花费大量时间澄清需求，LLMs往往在存在自然语言需求模糊的情况下生成代码，导致代码的不可靠性。以往的研究主要集中在基于LLM的代理进行迭代代码生成，但本文提出希望学习寻求澄清行为的能力能够成为模型本身固有的特性，特别是在模型与人类合作的代理AI中。", "innovation": "本文提出了一种名为ClarifyCoder的框架，结合了合成数据生成和指令调优技术，旨在将LLM微调为在遇到不完整或模糊需求时优先寻求澄清后再进行代码生成的能力。该框架包括两种组件：一种数据合成技术，通过向编程数据集添加需要澄清的情景来生成具有澄清意识的训练数据；另一种是微调策略，教导模型在面对不完整或模糊需求时优先寻求澄清而不是立即进行代码生成。此外，还进行了将ClarifyCoder与标准微调结合以联合优化澄清意识和编程能力的实证分析。实验结果表明，ClarifyCoder在模糊任务上的沟通率提高了63%（绝对提高40%）和好问题率提高了52%（绝对提高30%），显著提高了LLM的沟通能力，同时保持了代码生成性能。", "conclusion": "通过ClarifyCoder框架，LLM能够更有效地处理模糊需求，从而在保持代码生成性能的同时改善其沟通能力，标志着LLM在人类-AI协作中的一个重要进步。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16831", "html_url": "https://arxiv.org/abs/2505.16831", "title": "机器卸载不是删除：探索大规模语言模型中机器卸载的可逆性", "title_en": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", "authors": "Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu", "background": "大规模语言模型（LLMs）中的卸载目标是移除特定数据，但通常使用任务水平的度量标准（如准确性和困惑度）来评估其有效性。然而，这些度量标准往往具有误导性。模型可能看似已删除特定数据，但实际上只需经过少量的微调就能恢复其原始行为，这种现象被称为可逆性。可逆性表明，信息是暂时被压制，而不是被真正的擦除。因此，需要一种新的评价框架来填补这种评估缺口。", "innovation": "本文引入了一种基于表示层次分析的框架。该工具包包括PCA（主成分分析）基相似性与偏移、中心核对齐（CKA）以及鱼er信息，同时还提供了一个摘要指标——均值PCA距离，用于衡量表示漂移。通过跨越六个卸载方法、三个数据领域和两种LLM的应用，识别了四种不同遗忘模式，基于它们的可逆性和灾难性。研究发现，实现理想状态（不可逆且非灾难性遗忘）非常具有挑战性。通过探索卸载的极限，发现了一个可逆的、有针对性的遗忘案例，为设计更稳健的擦除算法提供了新的见解。", "conclusion": "本文的研究揭示出当前评价实践中的基本缺口，并为可靠卸载奠定了表示层次的基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15441", "html_url": "https://arxiv.org/abs/2505.15441", "title": "_octic 视觉变换器：通过协变性实现更快的 ViTs", "title_en": "Octic Vision Transformers: Quicker ViTs Through Equivariance", "authors": "David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman", "background": "研究发现，目前最先进的视觉变换器（ViTs）并没有设计来利用如90度旋转和镜像等自然几何对称性。本文指出，这不是因为存在无法克服的内在限制，而是因为缺乏高效的实现方法。", "innovation": "本文提出了{octic}视觉变换器（octic ViTs），利用{octic}群协变性来捕捉这些对称性。相比之前的协变模型，octic 线性层在 FLOPs 上实现了 5.33 倍的减少，并在内存消耗上降低了最多 8 倍，同时，在满{octic}ViT 块中，计算量减少了，接近线性层增加嵌入维度时的减少量。本文还研究了两种从{octic}块构建的新系列 ViTs，它们要么是完全{octic}协变，要么在网络的最后一部分破坏协变。", "conclusion": "在监督（DeiT-III）和无监督（DINOv2）训练 ImageNet-1K 时，{octic}ViTs 的准确度与基线相当，同时提供了显著的效率提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02091", "html_url": "https://arxiv.org/abs/2505.02091", "title": "LLM-OptiRA：无线通信中非凸资源分配问题的LLM驱动优化", "title_en": "LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications", "authors": "Xinyue Peng,Yanming Liu,Yihan Cang,Chaoqun Cao,Ming Chen", "background": "在无线通信系统中解决非凸资源分配问题充满挑战，传统的优化技术往往无法应对。这个问题的存在限制了资源分配的效率和效果，需要开发新的方法来应对非凸问题带来的挑战。", "innovation": "提出了LLM-OptiRA框架，这是首个利用大规模语言模型（LLMs）自动检测和转换非凸组件至可解形式的框架，能够在无线通信系统中实现非凸资源分配问题的全自动解决。LLM-OptiRA简化了问题解决步骤，减少了对专家知识的依赖，并集成了错误校正和可行性验证机制，以确保系统的稳健性。实验结果显示，与基线方法相比，LLM-OptiRA在复杂优化任务中表现优异，执行率高达96%，成功率达到80%，特别是在不同场景下的复杂优化任务表现更加出色。", "conclusion": "LLM-OptiRA通过利用大规模语言模型，成功实现了非凸资源分配问题的自动解决，显著提高了无线通信系统的资源分配效率和效果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19223", "html_url": "https://arxiv.org/abs/2504.19223", "title": "CARL：光谱图像分析中的相机无关表示学习", "title_en": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "authors": "Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic", "background": "光谱成像在多个领域展现了广阔的应用前景，尤其是在医学和城市场景理解方面，并已成为遥感中的关键模态。然而，不同光谱相机在通道维度和捕获波长上的差异阻碍了基于AI的方法的发展，导致了具有有限泛化能力和相机专用性的模型。为了解决这一瓶颈问题，作者引入了一种名为CARL的新模型，用于跨RGB、多光谱和高光谱成像模态的相机无关表示学习。通过引入一种新型光谱编码器，利用自我注意力交叉注意力机制，将重要的光谱信息提炼为学习到的光谱表示，实现任何通道维度的光谱图像向相机无关表示的转换。利用新型基于特征的自我监督策略进行跨视域的光谱预训练。大规模实验表明本模型对光谱异质性的鲁棒性优异，特别是在具有模拟和实际跨相机光谱变化的数据集上取得了更好的性能。提出的这种方法的可扩展性和多功能性使其有望成为未来光谱基础模型的核心架构。", "innovation": "该研究引入了名为CARL的新模型，旨在解决不同光谱相机在通道维度和捕获波长上的差异问题。该模型通过引入一种新型光谱编码器，利用自我注意力交叉注意力机制，将重要的光谱信息提炼为学习到的光谱表示，实现跨RGB、多光谱和高光谱成像的相机无关表示学习。此外，还提出了一种基于特征的自我监督策略进行光谱预训练。实验结果表明模型在医学成像、自动驾驶、卫星成像等领域的鲁棒性优于现有方法，并且能有效处理跨相机的光谱变化。", "conclusion": "CARL模型展示了对于光谱异质性的独特鲁棒性，其在大规模实验中表现优于现有的跨相机光谱变化的数据集。该模型由于其可扩展性和多功能性，被定位为未来光谱基础模型的核心架构，有望在未来的发展中用于解决更多实际问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14679", "html_url": "https://arxiv.org/abs/2505.14679", "title": "UltraEdit: 无需训练、无需主题、无需内存的语言模型终身编辑", "title_en": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models", "authors": "Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang", "background": "现有的大语言模型（LLMs）能够通过不断更新内部知识来适应不断变化的信息。理想的系统应该支持高效、广泛的更新，同时保留现有的能力，并确保可靠的部署。尽管最近的范式取得了显著进展，但它们往往难以满足大规模终身适应的实际需求。为了弥合这个差距，本研究提出了一种名为UltraEdit的新方法，这是一种无需训练、无需主题、无需内存的终身大模型编辑方法，特别适合于大规模的现实世界应用场景。", "innovation": "UltraEdit方法主要区别于传统方法，它通过使用隐藏状态及其梯度一步计算参数偏移，而非传统的训练、主题或内存方式。该方法具有简单且高效的特性。此外，UltraEdit还采用了一种终身归一化策略，能够继续更新特征统计信息，从而适应分布变化并保持时间一致性。实验结果表明，UltraEdit在编辑速度方面超过现有最快方法约7倍，同时占用的VRAM不足四分之一，使其成为唯一能在24GB消费者级GPU上编辑7B参数语言模型的方法。此外，研究者还构建了UltraEditBench，这是目前领域内最大的数据集，包含超过200万对编辑，验证了方法在大量编辑下仍能保持高准确性。", "conclusion": "本文全面实验结果显示，UltraEdit在多种翻模场景中取得了卓越性能，进一步推动了安全和可扩展的终身学习。同时，提供了UltraEdit的代码，以便更多研究者使用和进一步开发。该方法为解决大规模终身语言模型编辑提供了新的策略和方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03162", "html_url": "https://arxiv.org/abs/2506.03162", "title": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "title_en": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "authors": "Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh", "background": "近年来，监视摄像头的迅速普及增加了对自动化暴力检测的需求。虽然卷积神经网络（CNNs）和变换器（Transformers）在提取时空特征方面取得了成功，但它们在处理长期依赖性和计算效率方面存在挑战。", "innovation": "该研究提出了一个高效的架构——双分支VideoMamba与门控类令牌融合（Gated Class Token Fusion, GCTF），该架构结合了双分支设计和状态空间模型（SSM）骨干网络。其中一个分支捕捉空间特征，另一个则专注于时间动态。通过门控机制在分支之间进行持续融合，从而增强模型在检测暴力活动时的能力，特别是针对复杂的监控场景。", "conclusion": "实验结果表明，该模型在新建立的基准测试中达到了最先进的性能，在另一个新的视频暴力检测数据集DVD中也展示了最佳的准确性和计算效率之间的平衡，这表明了SSM在可扩展的实时监控暴力检测中的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16134", "html_url": "https://arxiv.org/abs/2505.16134", "title": "超越早期令牌偏见：多语言大型语言模型中模型特定和语言特定的位置效应", "title_en": "Beyond Early-Token Bias: Model-Specific and Language-Specific Position Effects in Multilingual LLMs", "authors": "Mikhail Menschikov,Alexander Kharitonov,Maiia Kotyga,Vadim Porvatov,Anna Zhukovskaya,David Kagramanyan,Egor Shvetsov,Evgeny Burnaev", "background": "大型语言模型（LLMs）表现出位置偏向——系统地忽视特定上下文位置的信息。然而，不同语言或模型中位置偏向的行为模式尚未被充分研究。这项研究在五个不同类型的语种（英语、俄语、德语、印地语、越南语）和五个不同的模型架构上展开，分析了位置偏向与提示策略的相互作用及对输出熵的影响。研究表明，位置偏向主要由模型驱动，但表现出语言特定的差异。特别地，Qwen2.5-7B-Instruct和DeepSeek 7B Chat持续偏好后期位置，这挑战了LLMs中普遍存在的早期令牌偏见的假设。同时，明确指示模型“上下文与查询相关”在不同语言中均降低了准确性，颠覆了常见的提示工程实践。此外，相关信息位于上下文中间时，准确性的最大下降，并未通过输出熵的峰值明确表现出来。", "innovation": "研究揭示了位置偏向主要由模型驱动，且在不同语言和架构之间表现出差异性特征；明确指示上下文相关降低了多种语言中的准确性；相关信息置于上下文中时，准确性下降幅度与输出熵峰值并无直接对应关系，挑战了现有认知。这些发现为理解和利用大型语言模型的行为提供了新的视角，对提示工程和模型设计具有重要指导意义。", "conclusion": "这项多语言研究揭示了大型语言模型中的位置偏向现象，主要由模型驱动，但存在语言特定的变异性。该研究还发现，明确指示上下文相关性可能削弱大模型表现，且相关信息在上下文中的位置与模型输出熵峰值并无直接联系。研究结果强调理解不同类型模型和语言中的偏见对于优化模型应用的重要性，并为未来的提示工程提供了新视角。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11022", "html_url": "https://arxiv.org/abs/2506.11022", "title": "迭代AI代码生成中的安全性退化——悖论的系统分析", "title_en": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "authors": "Shivani Shukla,Himanshu Joshi,Romilla Syed", "background": "大型语言模型（LLMs）的快速应用已重塑软件开发过程，但忽略了在迭代LLM反馈过程中安全漏洞随时间演化的方面。通过一项控制实验，利用40种不同的提示策略和400份源代码样本的40轮“改进”，揭示了安全性能随迭代的退化情况。", "innovation": "该研究通过一项包含400份代码样本和40轮迭代改善的控制实验，针对不同的提示策略分析了AI生成代码中的安全退化。结果表明，仅五轮迭代后，关键漏洞增加了37.6%，并且不同提示策略产生了不同的漏洞模式。这项发现挑战了“迭代LLM优化提升代码安全性”的假设，并强调了将人类专业知识纳入改进过程的重要性。", "conclusion": "研究结果提出了开发人员缓解这些风险的实用指南，强调在LLM迭代之间进行稳健的人工验证，以避免在所谓的“有益改进”代码期间引入新的安全问题。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17030", "html_url": "https://arxiv.org/abs/2505.17030", "title": "Distillation-Enabled Knowledge Alignment Protocol for Semantic Communication in AI Agent Networks", "title_en": "Distillation-Enabled Knowledge Alignment Protocol for Semantic Communication in AI Agent Networks", "authors": "Jingzhi Hu,Geoffrey Ye Li", "background": "未来网络将连接大量的AI代理，使其在各种任务上进行广泛协作。这些代理相比传统实体更适合语义通信（SC），这能显著提高带宽效率。然而，SC需要代理之间知识对齐，但在实践中，代理对各自任务具有独特的专家知识，导致知识对齐困难。因此，需要一个协议来促进这些代理的知识对齐，以支持其在多种任务中的协同工作。", "innovation": "本文提出了一种名为DeKAP（Distillation-Enabled Knowledge Alignment Protocol）的方法，该方法将每个代理的专家知识通过参数高效的小秩矩阵进行提炼，分布在网络中，实现知识对齐。该方法将对齐损失、通信开销和存储成本的联合最小化问题形式化为大规模整数线性编程问题，并开发出一种高效的贪婪算法。结果表明，DeKAP相对于传统方法在最少量的通信和计算资源中建立了知识对齐。", "conclusion": "本文提出了一种用于AI代理网络中的语义通信的知识对齐协议DeKAP，能够有效地促进代理之间的知识对齐。该协议通过参数高效的约简矩阵在节点间分配知识，并通过高效的算法优化对齐过程中的成本，从而在最小通信和计算资源消耗下实现多任务支持下的知识对齐。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21215", "html_url": "https://arxiv.org/abs/2505.21215", "title": "宇宙学中的多保真模拟推断的迁移学习", "title_en": "Transfer learning for multifidelity simulation-based inference in cosmology", "authors": "Alex A. Saoulis,Davide Piras,Niall Jeffrey,Alessio Spurio Mancini,Ana M. G. Ferreira,Benjamin Joachimi", "background": "模拟推断（SBI）在缺乏闭合形式的似然函数或模型时，能够进行宇宙学参数估计。但是，SBI依赖机器学习进行神经压缩和密度估计，这需要大量的训练数据集，对于高质量的模拟来说代价是巨大的。本文通过将低成本、低保真度的模拟与有限数量的高保真度模拟结合，克服了这一限制。研究展示了这种方法在两个不同的模拟数据集上的应用，通过在仅含暗物质的N体模拟上预训练，降低了需要的高质量流体动力学模拟的数量，范围在8到15倍之间，具体取决于模型的复杂性、后验维度以及使用的性能指标。通过利用更便宜的模拟，该方法能在减少计算成本的同时进行高性能、准确的高性能模型推断。", "innovation": "提出了一种多保真迁移学习的方法，该方法结合了低成本、低保真度的模拟和有限数量的高保真度模拟，以减少对于高质量模拟的依赖，从而降低计算成本。通过在仅含暗物质的N体模拟上预训练，显著减少了对高质量流体动力学模拟的需求，从而能够进行高性能和准确的高性能模型推断，同时大幅降低了计算成本。", "conclusion": "该研究通过将低成本和高保真度模拟结合，利用迁移学习来提升模拟推断的效率，特别是在宇宙学参数估计中的应用。这种方法不仅减少了成本，而且保持了估计的准确性，展示了对复杂模型的强大适应性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05418", "html_url": "https://arxiv.org/abs/2507.05418", "title": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "title_en": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "authors": "Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang", "background": "大型语言模型（LLMs）已经在数学、事实问答和代码生成等领域取得了显著成果，但它们在不同语言上的推理能力仍然欠佳。对于低资源语言如斯瓦希里语或泰语而言，LLMs 往往会误解提示或将推理偏向英语，这种对高资源语言的隐性偏见影响了事实准确性、可解释性和可信度。", "innovation": "提出了M2A方法，将多尺度多语言对齐与机器翻译问题上的语言一致性奖励相结合，训练模型直接在目标语言中进行准确推理。此外，现有大多数多语言基准仅评估最终答案，忽视推理是否发生在目标语言中。为此，引入了一个地理基于的多语言事实推理基准GeoFact-X，包含五种语言（英语、印地语、日语、斯瓦希里语和泰语）的推理痕迹。实验结果显示，M2A显著提升了多语言推理精确性，表明关注推理的多语言强化学习对于跨语言泛化的鲁棒性至关重要。", "conclusion": "结果表明M2A显著提高了多语言推理的准确性，特别是在数学和事实推理任务中，并且值得研究关注推理的多语言强化学习对于跨语言泛化的鲁棒性至关重要。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23692", "html_url": "https://arxiv.org/abs/2505.23692", "title": "Mobi-$π$：激活您的机器人学习策略", "title_en": "Mobi-$π$: Mobilizing Your Robot Learning Policy", "authors": "Jingyun Yang,Isabella Huang,Brandon Vu,Max Bajracharya,Rika Antonova,Jeannette Bohg", "background": "现有的视觉运动策略能够执行越来越复杂的操作任务。然而，这些策略大多是在有限的机器人位置和摄像机视角收集的数据上进行训练的。这导致了在新的机器人位置下表现不佳，限制了这些策略在移动平台上应用，特别是在需要精确操作，如按按钮或拧水龙头时。因此，需要一种方法来解决政策可移动性问题：在新的环境中找到与训练策略相匹配的移动机器人基座姿态。相比重新训练策略以使其更能适应未见过的基座姿态初始化，策略移动将导航和操作解耦，不需要额外的演示。这项工作填补了现有努力的空白，用于提高策略在新视角下的鲁棒性，并且兼容它们。", "innovation": "本文提出了一种新的策略移动方法，通过优化机器人的基座姿态来匹配学习策略的内部基座姿态，增加了3D高斯点绘用于新视角合成，引入了评估姿态合适的评分函数，使用基于采样的优化方法来识别最优机器人姿态。此外，还提出了Mobi-$π$框架，该框架包括评估策略移动难度的度量标准、基于RoboCasa的模拟移动操作任务套件以及分析工具。这些创新使得策略移动方法在模拟和真实环境中都优于基线方法，验证了其在策略移动方面的有效性。", "conclusion": "我们的方法在开发的模拟任务套件和现实世界中都表现优于基线方法，证明了其在策略移动方面的有效性。这项工作对于实现机器人在不同环境中的灵活操作具有重要意义。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07771", "html_url": "https://arxiv.org/abs/2507.07771", "title": "统一经验风险最小化框架以实现灵活的N-元弱监督", "title_en": "A Unified Empirical Risk Minimization Framework for Flexible N-Tuples Weak Supervision", "authors": "Shuying Huang,Junpeng Li,Changchun Hua,Yana Yang", "background": "为了减轻监督学习中的注释负担，近来出现了一种称为N-元学习的强监督方法，它能够进行高阶比较并适应多种实际场景。然而，现有的N-元学习方法通常依赖于特定任务的设计，缺乏统一的理论基础。", "innovation": "本文提出了一种基于经验风险最小化的通用N-元学习框架，该框架将点式未标注数据系统化地整合进来以提升学习性能。该研究首次将N-元和点式未标注数据的数据生成过程统一在一个共享的概率表述中，推导出适用于广泛N-元模型的无偏经验风险估计器，并建立了泛化误差界以提供理论支持。为了避免负风险项导致的过拟合问题，作者采用校正函数调整经验风险。实验表明，该框架能够有效提升N-元学习任务的泛化能力，并且利用点式未标注数据增强了模型性能。", "conclusion": "实验结果表明所提出的框架在各类N-元学习任务中表现良好，并且利用点式未标注数据能一致地提高模型的泛化性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01299", "html_url": "https://arxiv.org/abs/2506.01299", "title": "可扩展的上下文 Q 学习", "title_en": "Scalable In-Context Q-Learning", "authors": "Jinmei Liu,Fuhong Liu,Jianye Hao,Bo Wang,Huaxiong Li,Chunlin Chen,Zhi Wang", "background": "近期的语言模型展现了显著的上下文学习能力，这激发了研究人员探索上下文强化学习（ICRL）以将这种潜力扩展到决策领域。然而，现有的 ICRL 方法在处理更复杂动态和时间相关性时可能会遇到从次优轨迹中学习的挑战，并且难以实现精确的上下文推理。", "innovation": "本文提出了一个创新框架 SICQL（Scalable In-Context Q-Learning），它结合动态规划和世界建模，以实现高效的奖励最大化和任务泛化，同时保持监督预训练的可扩展性和稳定性。其特点包括一个基于提示的多头变换器架构，该架构可以同时预测最优策略和上下文价值函数；预训练一个通用的世界模型以捕捉任务相关信息，从而便于快速和精确的上下文推理；在训练过程中，通过拟合状态价值函数到 Q 函数的上分位数，并使用优势加权回归将上下文价值函数提炼为策略提取。", "conclusion": "通过在一系列离散和连续环境中的广泛实验，展示了与各种基线相比一致的性能改进，特别是当从次优数据中学习时效果更显著。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22842", "html_url": "https://arxiv.org/abs/2507.22842", "title": "图像分类中的梯度提升技巧和插件", "title_en": "Tricks and Plug-ins for Gradient Boosting in Image Classification", "authors": "Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan", "background": "卷积神经网络（CNNs）通过深层架构中的分层特征学习，在一系列机器学习任务中取得了显著的成功。然而，CNNs往往由于包含大量层和数百万参数而导致训练计算成本高昂，通常需要大量的时间和手动调优来发现最优架构。", "innovation": "本文提出了一种新颖的旨在提升CNN性能的框架，该框架整合了动态特征选择以及BoostCNN的原则。这种方法结合了子网络选择和重要性采样的两种关键策略，以引导训练向特征空间的信息性区域发展。此外，本文还开发了一系列将提升权重直接嵌入网络训练过程中的算法，采用最小二乘损失公式。这种整合不仅减轻了手动设计架构的负担，还提高了准确性和效率。", "conclusion": "在几种精细分类基准上的实验结果表明，本文提出的增强CNN变体在预测性能和训练速度上均优于传统的CNN."}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24333", "html_url": "https://arxiv.org/abs/2505.24333", "title": "深度变压器中的两种失败模式及其避免方法：初始时的信号传播统一理论", "title_en": "Two failure modes of deep transformers and how to avoid them: a unified theory of signal propagation at initialisation", "authors": "Alessio Giorlandino,Sebastian Goldt", "background": "神经网络的初始化对于确保平稳训练和良好性能至关重要。在变压器中，不正确的初始化可能导致自注意力层的两种失败模式：秩塌陷（所有令牌合并成相似表示）和熵塌陷（高度集中的注意分数导致训练不稳定）。尽管先前的工作已经研究了不同类型的梯度缩放机制，但对于如何精确初始化 transformers 的具体方法却缺乏明确的理论指导。", "innovation": "该研究提供了一个信号在含有自注意力、层规范化、跳跃连接和MLP的深层变压器中传播的分析理论。通过建立与统计物理的随机能量模型的正式类比，解决了精确处理自注意力层的关键挑战，并分析了反向传播梯度的消失区域，以确定初始化后的训练可调性图。理论框架统一解释了自注意力层的两种失败模式，并提供了保证平稳训练的权重和跳跃连接规模的定量预测。", "conclusion": "该理论为不同变压器架构提供了挑选正确的初始化超参数的标准，通过三种案例研究展示了该框架的普适性，从而为避免深度变压器中的两种失败模式提供了理论指导。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10699", "html_url": "https://arxiv.org/abs/2506.10699", "title": "SNR和资源自适应的分布式IoT图像分类深度联合源信道编码", "title_en": "SNR and Resource Adaptive Deep JSCC for Distributed IoT Image Classification", "authors": "Ali Waqas,Sinem Coleri", "background": "IoT设备基于传感器进行局部推理时面临严重的计算限制，通常需要将数据通过易受噪声干扰的无线信道传输到服务器端进行处理。为解决这一问题，现有的基于分组网络深度神经网络（DNN）的联合源信道编码（JSCC）方案被用于提取并传输相关特征而非原始数据。然而，大多数现有方法依赖于固定的网络分割和静态配置，缺少适应不同计算预算和信道条件的能力。", "innovation": "本文提出了一种新型的自适应信噪比（SNR）和计算资源的分布式卷积神经网络（CNN）框架，用于IoT设备和边缘服务器上的无线图像分类。该框架通过一种学习辅助的智能遗传算法（LAIGA）高效地探索CNN超参数空间，优化网络配置，在给定FLOPs约束和给定SNR的情况下实现优化。智能遗传算法能够智能地排除超出IoT设备计算预算的无效网络配置，并借助基于随机森林的学习辅助来避免彻底探索超参数空间，并引导候选最优配置的应用特定偏差。实验结果表明，该框架在低SNR和有限计算资源条件下相较于固定分割架构和现有SNR自适应方法表现更优，尤其是在SNR仅为-10dB的情况下实现了10%的分类精度提升，计算预算范围从1M到70M FLOPs", "conclusion": "我们的框架在IoT设备上实现了1M至70M FLOPs范围内低至-10dB SNR时的分类精度提升，相较于现有的基于JSCC的SNR自适应多层框架表现出优越性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17046", "html_url": "https://arxiv.org/abs/2506.17046", "title": "MUCAR：多语种跨模态歧义解决基准测试", "title_en": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "authors": "Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu", "background": "多模态大型语言模型（MLLMs）已经在多种视觉-语言任务中展示了显著的进步。这些模型在对齐视觉和文本模态方面表现出潜力，能够处理具有明确和直接意义的图片和文本对。然而，解决现实世界语言和视觉背景中的固有歧义仍然是一个挑战。现有的多模态基准通常忽略了语言和视觉的歧义性，主要依赖于单模态上下文进行消歧，从而未能充分挖掘模态间相互澄清的潜力。", "innovation": "本文提出了MUCAR，这是一个新的且具有挑战性的基准，旨在评估多模态歧义解决能力。MUCAR包含一个包含多语种数据集——其中模糊的文本表达通过相对应的视觉上下文进行独特解决，以及一个双歧义数据集——系统地将模糊的图像与模糊的文本上下文配对，每次组合都是为了通过相互消歧获取单一清晰的解释。MUCAR涉及19种最新多模态模型（涵盖开源和专有的架构），这些模型在多方面与人类水平的表现存在显著差距，这突显了未来研究中的跨模态歧义理解更复杂方法的需求。", "conclusion": "实证评估表明，现有的多模态模型在解决跨模态歧义方面仍然存在显著差距，这对于未来研究提出了挑战，需要探索更加复杂的方法来提高多模态推理的能力。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10533", "html_url": "https://arxiv.org/abs/2508.10533", "title": "通过频率选择缓解混合频率指数增长", "title_en": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection", "authors": "Michael Poppel,David Bucher,Maximilian Zorn,Nico Kraus,Philipp Altmann,Jonas Stein,Claudia Linnhoff-Popien", "background": "量子机器学习由于在潜在的计算优势方面超越经典方法而迅速发展。角度编码作为一种流行的选择被用作特征映射（FM），可以用于将经典数据嵌入到量子模型中，因为它简洁且自然地生成了截断傅里叶级数，提供了一般的函数逼近能力。在量子电路内的高效FM能够利用傅里叶频率的指数级扩展，而多维输入则通过混合频率项引入额外的指数增长。尽管拥有这种有希望的表达能力，但实际上在实际实施中会遇到重大挑战。甚至当所有相关的频率在理论上都是可访问的时，通过白盒目标函数进行的实验表明，训练失败仍可能发生。我们展示了主要已知的两个原因会导致优化失败：可训练参数不足以及ansatz动态李代数维度的限制。此外，还需要控制模型中的非唯一频率带来的参数负担。", "innovation": "我们提出了近零权重初始化来抑制不必要的重复频率，此外，对于具有先验频率知识的目标函数，我们引入了频率选择作为一种实用的解决方案，可以减少参数要求并缓解由于参数不足导致的指数增长问题，从而使问题变得难以处理。", "conclusion": "我们的频率选择方法在10个随机选择的目标函数中达到了接近最优的性能（平均$R^2$约等于0.95），并且只需要最佳标准方法所需参数的78%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11152", "html_url": "https://arxiv.org/abs/2506.11152", "title": "HEIST: 一种用于空间转录组学和蛋白质组学数据的图基础模型", "title_en": "HEIST: A Graph Foundation Model for Spatial Transcriptomics and Proteomics Data", "authors": "Hiren Madhu,João Felipe Rocha,Tinglin Huang,Siddharth Viswanath,Smita Krishnaswamy,Rex Ying", "background": "单细胞转录组学和蛋白质组学已成为数据驱动生物学见解的重要来源，使高级深度学习方法得以用于理解单细胞的异质性和基因表达。随着空间组学数据的出现，我们有机会在组织背景中表征细胞，因为这些数据提供了空间坐标和细胞内的转录或蛋白质计数。蛋白质组学提供了关于蛋白质的直接测量，蛋白质是细胞功能的主要效应物和关键治疗靶点。然而，现有的模型要么忽略了空间信息，要么忽略了细胞内的复杂基因和蛋白质程序，无法推断细胞内调节如何适应微环境线索。此外，这些模型通常使用固定的基因词汇表，这妨碍了它们对未见过的基因的泛化能力。", "innovation": "本文引入了HEIST，一种用于空间转录组学和蛋白质组学的分层图变换器基础模型。HEIST将组织建模为分层图形表示，通过在不同层次之间进行消息传递利用嵌入层次结构，并且能够泛化到包括空间蛋白质组学在内的新数据类型而无需重新训练。HEIST在15个体器官的124种组织中2230万细胞上进行了预训练，采用空间感知对比和屏蔽自编码目标。无监督分析揭示了以前模型无法识别的空间细分人群。下游评估表明HEIST在蛋白质组学数据中的泛化能力和临床结局预测、细胞类型注释以及多种技术中的基因重构表现最佳", "conclusion": "本文通过引入HEIST模型，实现了对空间转录组学和蛋白质组学数据的分层图表示，能够利用嵌入层次结构进行消息传递，从而能够泛化到新的数据类型，并在临床结局预测、细胞类型注释和基因重构等方面表现优越。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05394", "html_url": "https://arxiv.org/abs/2507.05394", "title": "pFedMMA: 个性化多模态适配器的联邦微调", "title_en": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models", "authors": "Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani", "background": "视觉-语言模型（VLMs）如CLIP在零样本和少样本设置中表现出色，但在高效适应分散的、异质数据方面仍然存在挑战。尽管提示调优在个性化联邦学习中作为一种参数高效的方法变得流行，但现有方法往往在个性化和泛化的折中中偏向个性化，特别是在对未见过的类别或领域时表现不佳。因此，在本研究中，我们提出了pFedMMA，这是首个利用多模态适配器进行视觉语言任务的个性化联邦学习框架。每个适配器包含模态特定的上层和下层投影层以及一个全局共享的投影层，将跨模态特征对齐。通过对优化策略的设计，允许客户端在本地适应个性化数据分布，同时协作训练共享投影以提高全球泛化能力。此设计也是通信高效的，因为在通信轮中只需交换共享组件。通过在包括领域转移和标签转移在内的各类数据集上进行广泛实验", "innovation": "我们提出了pFedMMA框架，这是首个利用多模态适配器进行个性化联邦学习的框架。框架设计了模态特定的上层和下层投影层以及一个全局共享的投影层来对齐跨模态特征。通过局部个性化数据分布的适应和共享投影模块的协作训练，空间和个人化及泛化之间的平衡。这种设计也是通信高效的，因为在通信轮次中仅需要交换共享组件。该框架在广泛实验中的表现优于最近的联邦提示调优方法，特别是在领域和标签转移场景中", "conclusion": "通过在广泛实验中的表现，pFedMMA框架在个性化和泛化之间实现了最佳折衷，优于最近的联邦提示调优方法，并为个性化联邦学习领域提供了新的解决方案。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11312", "html_url": "https://arxiv.org/abs/2508.11312", "title": "基于重复TMS的使用EEG频谱识别 METH 依赖个体", "title_en": "Repetitive TMS-based Identification of Methamphetamine-Dependent Individuals Using EEG Spectra", "authors": "Ziyi Zeng,Yun-Hsuan Chen,Xurong Gao,Wenyao Zheng,Hemmings Wu,Zhoule Zhu,Jie Yang,Chengkai Wang,Lihua Zhong,Weiwei Cheng,Mohamad Sawan", "background": "通常使用问卷来评估重复经颅磁刺激 (rTMS) 对METH使用者的戒毒效果，本研究旨在探索利用神经信号（EEG）获取更客观结果的可能性。 EEG信号来自20名METH成瘾者（在rTMS之前MBT和之后MAT）和20名健康对照（HC），结果显示，在MAT和HC之间的α、β和γ频带相对带功率（RBP）更接近，利用随机森林（RF），γ频带的RBP被识别为区分MBT和HC的最佳频率带，准确率达到90%。因此，γ频带在面对METH相关图像提示时的变化具有作为METH依赖个体和rTMS效果的生物标志物的潜力。", "innovation": "研究通过分析EEG信号中的γ频带相对带功率，实现了使用rTMS后区分METH依赖个体和健康对照的高准确率分类，基于这一发现，未来可能实现定制的闭环神经调节系统来治疗METH依赖。", "conclusion": "γ频带的相对带功率在处理与METH相关提示时的变化作为METH依赖个体和rTMS效果的生物标志物具有潜在价值，实时监测γ频带变化有望应用于实现针对METH依赖的个性化闭环神经调节系统。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17897", "html_url": "https://arxiv.org/abs/2507.17897", "title": "多模态递归集成用于预测自然电影脑响应 (Algonauts 2025挑战赛)", "title_en": "Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)", "authors": "Semih Eren,Deniz Kucukahmetler,Nico Scherf", "background": "准确预测大脑在观看自然刺激时的分布式皮层响应需要结合视觉、听觉和语义信息的模型。现有的模型需要能够整合这些不同类型的输入信息，并通过时间序列进行建模，从而实现全面的预测效果。为了测试和改进这些模型，研究人员利用Algonauts 2025挑战赛提供的数据集进行研究和评估。", "innovation": "该研究提出了一种分层多模态递归集成模型，该模型可以将预训练的视频、音频和语言嵌入映射到参与者观看近80小时电影时所记录的fMRI时间序列数据中。模型中使用了模态特定的双向递归神经网络来编码时间动态，隐藏状态被融合后传递给第二层递归层，最后使用轻量级的个体特定头部输出1000个皮质区域的响应。训练过程中采用了复合的均方误差-相关损失，以及逐渐转移重点从早期感官区域到晚期关联区域的课程学习策略。此外，对100种模型变体的平均进一步增强了系统的鲁棒性。", "conclusion": "该系统在该项竞赛排行榜中排名第三，整体皮尔逊r值为0.2094，单个皮质区域的最高峰值分数为0.63，在所有参与者中最高。特别值得一提的是在最具挑战性的参与者（参与者5）身上，取得了显著的进步。该方法为将来的多模态脑编码基准提供了简单且扩展的基础。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14270", "html_url": "https://arxiv.org/abs/2507.14270", "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "title_en": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "authors": "Ravin Kumar", "background": "现有的神经网络结构通常包含分离的激活层和线性变换层，这种分离使得网络设计既复杂又效率低下。本文背景在于探索一种能够将激活函数和线性变换统一且高效地集成在单一神经元模型中的方法，从而简化网络结构并提高计算效率，同时保持或提升模型性能。作者选择在经典的MNIST数据集上验证其提出的神经元模型，证明其有效性与优越性。", "innovation": "本文创新性地提出了APTx神经元，它结合了非线性激活和线性变换，所有相关参数都可被训练优化。这种设计使得模型不仅实现了统一、简洁的架构，还增强了模型的表达能力，相对于传统神经元模型，在MNIST数据集上表现出更高的测试准确率和更少的参数量，证明了其在统一神经元设计及构造上的优越性。", "conclusion": "通过实验证明，APTx神经元及其基于该神经元的架构在MNIST数据集上表现出了显著的优越性，不仅在测试准确率上达到了96.69%，而且使用了较少的参数量，证明了其在计算效率和模型性能上的优化效果。这一发现为未来的神经网络设计提供了新的思路，标志着统一神经元设计与架构的新方向。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06477", "html_url": "https://arxiv.org/abs/2508.06477", "title": "在最大容量模型的临界性中，直觉涌现", "title_en": "Intuition emerges in Maximum Caliber models at criticality", "authors": "Lluís Arola-Fernández", "background": "当前对于大型预测模型的本质存在疑问，它们究竟是重复训练数据还是提供了真实见解。这一论文探讨了在学习过程中浮现的一种初步直觉，这种直觉通过一种类似临界相变的状态出现在预测模型中，平衡了下一个词预测和未来路径熵。", "innovation": "研究者通过mind-tuning（心智调谐）和控制温度参数λ来施加最大容量原理，揭示了随机漫步在决定性迷宫上的训练过程显示了多相图：低λ时的模仿行为、高λ时的规则破坏性幻觉以及一个脆弱的中间窗口，展示了强协议依赖性和多稳态性，模型在此窗口中自发发现了新的目标导向策略。", "conclusion": "研究结果通过一个有效的低维度理论描述，并将直觉作为在记忆‘是什么’和’可能是怎么样的’之间临界平衡中涌现出来的一种新特性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03860", "html_url": "https://arxiv.org/abs/2508.03860", "title": "从幻觉到真实：大规模语言模型事实核查及事实性评估综述", "title_en": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "authors": "Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam", "background": "大规模语言模型（LLMs）通常在涵盖广泛和多样性的互联网数据上训练，这些数据往往包含错误或误导的信息。因此，LLMs可能会生成虚假信息，使事实核查变得至关重要。本文综述了对LLM生成内容进行事实性评估的研究，探讨了幻觉、数据集限制和评估指标可靠性等关键挑战。研究表明，当前的评估指标存在局限性，验证外部证据的重要性以及通过领域特定定制提高事实一致性的重要性也得到了强调。这表明，在事实核查中建立更准确、更具解释性和上下文感知性的系统就显得尤为重要。", "innovation": "本文提出了关于2020至2025年间关于事实核查和事实性评估方法的五个研究问题，研究集成先进的提示策略、领域特定微调和检索增强生成（RAG）方法的重要性。此外，还评估了指令微调、多智能体推理和外部知识访问的RAG框架，强调建立了精确、易于理解且上下文相关的事实核查系统的重要性。这些研究为更可信模型的发展提供了新的见解，促进了进一步的研究。", "conclusion": "本文强调了需要牢固的事实核查框架和先进的提示策略、领域特定微调以及RAG方法的集成应用。提出了五个指导性研究问题，旨在从2020年至2025年分析事实核查和事实性评估方法及其缓解技术。该综述揭示了当前评估指标的局限性，验证了外部证据的重要性，并展示了领域特定定制在提高事实一致性方面的成效。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19517", "html_url": "https://arxiv.org/abs/2509.19517", "title": "大型语言模型中的认知负荷限制：多跳推理基准测试", "title_en": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "authors": "Sai Teja Reddy Adapala", "background": "大型语言模型在固定基准上的性能表现出色，但在动态、信息丰富的环境中却显得脆弱。这些模型在负担认知负荷的计算任务上还存在未知的限制，尤其是在干扰和无关信息方面表现较差。", "innovation": "本研究引入了一种正式的认知计算负荷理论，指出课外和无关信息（Context Saturation）干扰以及任务切换的注意力残留（Attentional Residue）是关键机制，导致性能下降。研究设计了一种去混淆的基准测试，称为交错认知评估（ICE），用于系统研究这些负荷因素对复杂多跳推理任务的影响。", "conclusion": "研究发现，认知负荷是推理失败的关键原因，支持了在不确定性条件下错误推理是猜测的说法。研究结论认为，动态、认知敏感的压力测试（如ICE基准）对于评估先进AI系统的真正弹性和安全性是必不可少的。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19301", "html_url": "https://arxiv.org/abs/2509.19301", "title": "残差离策RPO强化学习用于微调行为克隆策略", "title_en": "Residual Off-Policy RL for Finetuning Behavior Cloning Policies", "authors": "Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi", "background": "近年来行为克隆（BC）的进步使得视觉-动作控制策略取得了显著成就。然而，这些方法受限于人类演示的质量、手动数据收集的劳动强度以及离线数据带来的递减效益。相比之下，强化学习（RL）通过与环境的自主交互来训练代理，展示了在各个领域的显著成功。然而，直接在真实世界的机器人上训练RL策略因样本效率低下、安全问题以及长时任务稀疏奖励难以学习，特别是对于高自由度（DoF）系统仍然具有挑战。", "innovation": "本文提出了一种结合行为克隆（BC）和强化学习（RL）优势的配方，通过残差学习框架。该方法利用BC策略作为黑盒基础，并通过样本高效离策RL学习每步的小型残差修正。我们的方法仅需稀疏二元奖励信号，并可以在模拟和真实世界中有效地提高高自由度系统的操作策略。特别地，我们展示了迄今为止在具有灵巧手的人形机器人上成功进行真实世界RL训练的第一例。我们的结果表明在各种基于视觉的任务中达到了最先进的性能，为在真实世界部署RL指明了实用路径。", "conclusion": "我们的结果证明，通过残差离策RL结合BC策略在高自由度系统中实现了卓越的表现，为在真实世界中部署RL提供了可行的方法。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.08726", "html_url": "https://arxiv.org/abs/2509.08726", "title": "松弛光滑条件下去中心化随机非凸优化", "title_en": "Decentralized Stochastic Nonconvex Optimization under the Relaxed Smoothness", "authors": "Luo Luo,Xue Cui,Tingkai Jia,Cheng Chen", "background": "本文研究了去中心化的优化问题 $f(\boldsymbol{x}) = \frac{1}{m}\boldsymbol{\text{∑}}_{i=1}^m f_i(\boldsymbol{x})$，其中每个局部函数 $f_i(\boldsymbol{x}) = \boldsymbol{E}\big[\boldsymbol{F}(\boldsymbol{x}; \boldsymbol{ξ}_i)\big]$ 具有 $(L_0, L_1)$-光滑性，但可能是非凸的，随机变量 $\boldsymbol{ξ}_i$ 遵循分布 $\boldsymbol{D}_i$。现有的去中心化方法大多假设函数是标准光滑的，无法处理非光滑函数导致的局部极小值问题。", "innovation": "提出了一个新颖的算法，去中心化的规范化随机梯度下降（DNSGD），该算法能够在每个本地代理处找到 $\boldsymbol{ε}$-极小点。并基于相关梯度范数和共识误差的李亚普诺夫函数提出了一个分析去中心化一阶方法的新框架。给出了每个代理的样本复杂性的上界为 ${\boldsymbol{Ο}}(m^{-1}(L_f\boldsymbol{σ}^2\boldsymbol{Δ}_f\boldsymbol{ε}^{-4} + \boldsymbol{σ}^2\boldsymbol{ε}^{-2} + L_f^{-2}L_1^3\boldsymbol{σ}^2\boldsymbol{Δ}_f\boldsymbol{ε}^{-1} + L_f^{-2}L_1^2\boldsymbol{σ}^2))$ 和通信复杂度的上界为 $\tilde{\boldsymbol{Ο}}((L_f\boldsymbol{ε}^{-2} + L_1\boldsymbol{ε}^{-1})\boldsymbol{γ}^{-1/2}\boldsymbol{Δ}_f)$，其中 $L_f = L_0 + L_1\boldsymbol{ζ}$，$\boldsymbol{σ}^2$ 为随机梯度的方差，$\boldsymbol{Δ}_f$ 为初始最优函数值差距，$\boldsymbol{γ}$ 为网络的谱隙，$\boldsymbol{ζ}$ 为梯度相似度的程度。在 $L_1=0$ 的特殊情况下，上述结果（几乎）与标准光滑下的去中心化随机非凸优化的下界匹配。", "conclusion": "通过数值实验进一步验证了方法的优越性，特别地，当 $L_1=0$ 时，在松弛光滑条件下，该方法在样本复杂性和通信复杂性上达到了最优的结果。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00472", "html_url": "https://arxiv.org/abs/2509.00472", "title": "部分功能性动态后门扩散因果模型", "title_en": "Partially Functional Dynamic Backdoor Diffusion-based Causal Model", "authors": "Xinwen Liu,Lei Qian,Song Xi Chen,Niansheng Tang", "background": "在涉及复杂时空依赖性的环境流行病学等场景下，因果推理由于未测量混杂因素的存在而充满挑战。现有的扩散基因果模型依赖于因果完备性或静态混杂的一些限制性假设，存在一定的局限性。因此，研究一个能够克服这些限制的新模型是必要的。", "innovation": "提出了部分功能性动态后门扩散基因果模型（PFD-BDCM），通过将有效的后门调整融入扩散采样机制来减轻未测量混杂因素造成的偏差。它通过区域特异性结构方程和条件自回归过程来捕捉混杂因素的复杂动态，通过功能性数据技术来处理多分辨率变量，并提供理论保证来确保反事实估计的误差界限。研究表明，PFD-BDCM在合成数据和实际的空气污染案例中优于现有最先进的方法。", "conclusion": "PFD-BDCM能够有效处理复杂时空依赖性的因果推理问题，通过创新的建模技术和理论分析提升了因果推断的准确性，对环境流行病学等领域具有重要应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15475", "html_url": "https://arxiv.org/abs/2508.15475", "title": "受影响驱动的限数据预训练课程学习", "title_en": "Influence-driven Curriculum Learning for Pre-training on Limited Data", "authors": "Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth", "background": "课程学习是一种训练技术，其中数据按照示例难度的顺序（例如，从较简单的文档到更复杂的文档）呈现给模型。尽管如此，这种方法仅在预训练语言模型上表现有限。本研究探讨了是否可以将传统的基于人类中心的难度度量替换为一个更接近模型训练过程中观察到的难度的指标，从而使得课程学习竞争性强。研究者采用了按‘训练数据影响’排序训练示例的方法，该得分估计单个训练样本对模型输出的影响效果。", "innovation": "研究引入了一种新的排序方法，即根据‘训练数据影响’对训练示例进行排序，代替传统的基于人工中心的难度度量。这种方法能显著提高模型在基准测试中的表现，证实了课程学习对于语言模型预训练是有益的，只要采用一种更以模型为中心的难度概念。模型在提出的课程学习下的表现优于随机顺序训练的模型，提高了超过10个百分点的成绩。", "conclusion": "研究表明，采用‘训练数据影响’作为排序依据的课程学习方法对于处理有限数据的预训练语言模型是有益的，证明了课程学习能够提升模型性能，尤其是在数据有限的情况下，只要采用更以模型为中心的难度指标。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15363", "html_url": "https://arxiv.org/abs/2509.15363", "title": "近期深度学习在显微图像增强中的进展：综述", "title_en": "Recent Advancements in Microscopy Image Enhancement using Deep Learning: A Survey", "authors": "Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita", "background": "显微镜图像增强在理解生物细胞和材料的微观细节方面发挥着关键作用。近年来，借助深度学习方法，显微镜图像增强技术有了显著的进步。", "innovation": "本文综述了利用深度学习方法的显微镜图像增强的最新进展，涵盖了超分辨、重建和降噪等核心领域的发展趋势及其实际应用。", "conclusion": "本文聚焦于显微镜图像增强的最新进展，讨论了其演变，应用，挑战，并展望了未来的研究方向。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench：衡量价值观对齐的比较行为量度", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能与人类价值观的对齐是一个亟待解决的问题。由于缺乏评估模型价值观的有效量化指标，本研究提出EigenBench方法来比较不同语言模型的价值观对齐程度。该方法通过给定模型集合、描述价值体系的宪法和若干场景数据集，产生反映每种模型与给定宪法对齐程度的量化得分。该研究旨在解决在没有参考标准标签的情况下评估价值观问题的有效性。通过收集人类对同一模型集合的判断来验证该方法的有效性，并显示EigenBench的判断与人类评估者的意见高度一致。进一步展示了EigenBench在无需使用客观标签的情况下，能够恢复模型在GPQA基准上的排名，这进一步支持了其作为评估无客观标准标签情况下的主观价值观框架的有效性。", "innovation": "EigenBench提出了一种新的黑盒方法，用于比较和评估语言模型的价值观对齐程度。该方法通过模型之间的相互评估和聚合意见，形成对模型价值观对齐程度的标准化得分，无需依赖任何用户标签，并通过与人类评估者的对比验证了其有效性。", "conclusion": "EigenBench方法展示了在缺乏客观标签的情况下，仍能有效地对模型的价值观对齐程度进行评估，支持其作为一种新框架，用于评估没有客观正确答案的主观价值观。“"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19665", "html_url": "https://arxiv.org/abs/2509.19665", "title": "在甲烷卫星和机载成像光谱仪中的云和云影分割中的深度学习", "title_en": "Deep Learning for Clouds and Cloud Shadow Segmentation in Methane Satellite and Airborne Imaging Spectroscopy", "authors": "Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy", "background": "在高光谱遥感中准确检索大气甲烷或其他痕气体浓度的前提是有效的云和云影检测。对于甲烷卫星（MethaneSAT）及其机载同伴任务（MethaneAIR），这一挑战尤为重要。遥感数据中的云和云影需要被有效筛查，因为它们会偏斜甲烷的检索结果并影响排放的量化。", "innovation": "本研究使用机器学习方法解决了高空间分辨率仪器下的云和云影检测问题。采用包括迭代逻辑回归（ILR）和多层感知器（MLP）在内的传统技术，以及如UNet和光谱通道注意力网络（SCAN）的高级深度学习架构。结果显示，深度学习模型在保持空间结构和捕捉细节方面显著改进了检测质量。", "conclusion": "各种不同的机器学习技术的深入评估表明，先进的深度学习架构为遥感影像中的云和云影筛查提供了稳健且可扩展的解决方案，以增强现有和下一代高光谱任务的甲烷排放量量化能力。相关数据和代码可在provided URL中公开获取。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21427", "html_url": "https://arxiv.org/abs/2509.21427", "title": "从代码库中提取概念性知识以定位软件问题", "title_en": "Extracting Conceptual Knowledge to Locate Software Issues", "authors": "Ying Wang,Wenjun Mao,Chong Wang,Zhenhao Zhou,Yicheng Zhou,Wenyun Zhao,Yiling Lou,Xin Peng", "background": "代码定位是有效修复错误的关键，但最近基于LLM的方法和LLM代理方法在大规模代码库中因相关逻辑埋藏在大函数中的混杂问题和相关逻辑分散在不同文件中的分散问题而受到限制。", "innovation": "提出了一种名为RepoLens的新方法，该方法从代码库中抽象和利用概念性知识。RepoLens将细粒度的功能拆分成高层级的关注点，即具有语义连贯性的功能集群，指导LLM。RepoLens分为离线阶段和在线阶段，离线阶段提取并丰富概念性知识形成全库知识库，而在线阶段检索特定于问题的术语，按相关性聚类并排名关注点，并通过少量侵入性提示增强集成到定位工作流中。", "conclusion": "在SWE-Lancer-Loc基准测试数据集上评估RepoLens，它在文件和函数级别的定位上优于AgentLess、OpenHands和mini-SWE-agent三种最先进的工具，平均每K改进率为22%，召回率为46%。该方法在不同模型（GPT-4o、GPT-4o-mini、GPT-4.1）上表现出色，具有高达504%的Hit@1和376%的Recall@10的收益。消融研究和手动评估确认了构建的关注点的有效性和可靠性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20186", "html_url": "https://arxiv.org/abs/2509.20186", "title": "Thinking Augmented Pre-training", "title_en": "Thinking Augmented Pre-training", "authors": "Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei", "background": "随着预训练大型语言模型（LLM）所需的计算能力以前所未有的速度增长，高质量的数据可用性仍然有限。这使得最大化现有数据的使用效率成为一个重要的研究挑战。尤其是在固定模型容量下，某些高质量的令牌难以学习，因为单一令牌背后的原因可能是极其复杂和深刻的。", "innovation": "我们提出了思维增强预训练（TPT），这是一种通用的方法，通过自动生成的思维轨迹来增强文本。这种增强方式增加了训练数据的总量，通过逐步推理和分解让高质量的令牌更容易学习。", "conclusion": "实验结果表明，我们的方法显著提高了LLM在各种模型规模和家族中的性能。TPT将LLM预训练的数据效率提高了三倍，在一个3B参数模型上，它在几个具有挑战性的推理基准测试中的后训练性能提高了超过10%。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17609", "html_url": "https://arxiv.org/abs/2509.17609", "title": "使用潜桥模型的音频超分辨率", "title_en": "Audio Super-Resolution with Latent Bridge Models", "authors": "Chang Li,Zehua Chen,Liyuan Wang,Jun Zhu", "background": "音频超分辨率（SR），即通过扩增低分辨率（LR）声波的采样率生成高分辨率（HR）的声波版本，已经利用扩散和桥接模型进行探索。然而，之前的方法由于生成先验信息不足，通常会面临低质量的扩增问题。因此，为了提升音频的超分辨率质量，作者提出了一种新的系统，引入了潜桥模型（Latent Bridge Models，LBMs）。通过将音频波形压缩至连续的潜空间，并设计潜桥模型使潜空间到潜空间的生成过程能够自然匹配LR到HR的扩增过程，从而全面发挥了LR波形中包含的指示性先验信息。", "innovation": "论文的创新点在于提出了新的潜桥模型（Latent Bridge Models，LBMs）以改善生成先验信息利用的效果。此外，为了进一步提高训练结果，即使高质量样本有限，引入了频率感知的潜桥模型以及级联潜桥模型和先验增强策略。这些策略使得音频超分辨率可以在48 kHz以上甚至达到192 kHz水平，提供了更高的音频后期制作灵活性。", "conclusion": "本文在VCTK、ESC-50、Song-Describer基准数据集以及内部测试数据集上进行了全面的实验评估，结果表明在任何到48 kHz的音频超分辨率中，无论信号类型是语音、音频还是音乐，我们实现了最先进的客观和感知质量。并且，我们首次达到了任何到192 kHz音频超分辨率的记录。演示视频请访问：this https URL"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15587", "html_url": "https://arxiv.org/abs/2509.15587", "title": "DivLogicEval: 大规模语言模型中逻辑推理评估的框架", "title_en": "DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models", "authors": "Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung", "background": "自然语言中的逻辑推理被公认为衡量人类智能的重要标准，特别是对于大规模语言模型(LLMs)。现有的基准可能混合了多种逻辑推理技能，这可能导致对逻辑推理能力的不忠实践评。此外，现有的逻辑推理基准的多样性受限，并且分布不理想，可能导致评价结果存在偏差。因此，该论文提出了一种新的经典逻辑基准DivLogicEval，该基准由多样化并在直觉上相反的陈述构成的自然句子组成。为了确保评价结果更加可靠，还引入了一种新的评价指标，以减轻LLMs中固有的偏见和随机性的影响。通过实验，展示了在DivLogicEval中进行逻辑推理问题的解答所需的逻辑推理程度，并比较了不同流行大规模语言模型的逻辑推理性能。", "innovation": "该论文提出了DivLogicEval，一种由多样并在直觉上相反的陈述构成的自然句子组成的新经典逻辑基准。还引入了一种新的评价指标，以减轻大规模语言模型中固有的偏见和随机性的影响。", "conclusion": "通过实验表明，逻辑推理是DivLogicEval中回答问题所必需的，并且不同流行的大规模语言模型在逻辑推理方面表现出不同的性能。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11606", "html_url": "https://arxiv.org/abs/2509.11606", "title": "扩展到多模态和多通道心音分类：利用合成和增强生物信号微调Wav2Vec 2.0", "title_en": "Scaling to Multimodal and Multichannel Heart Sound Classification: Fine-Tuning Wav2Vec 2.0 with Synthetic and Augmented Biosignals", "authors": "Milan Marocchi,Matthew Fynn,Kayapanda Mandana,Yue Rong", "background": "心血管疾病（CVDs）是全球最主要的死因，每年导致约1790万人死亡。早期诊断至关重要，因此需要准确且经济的前期筛查方法。深度学习最近被应用于利用同步心音图（PCG）和心电图（ECG）信号以及多通道心音图（mPCG）来分类指示CVDs的异常心音。然而，先进的架构因缺乏同步和多通道数据集而未充分利用。通过增强数据集和预训练模型，可以通过变压器架构有效训练。本文结合传统信号处理与去噪扩散模型WaveGrad和DiffWave，创建一个增强数据集，用于在多模态和多通道心音数据集上微调基于Wav2Vec 2.0的分类器，以实现最佳性能。", "innovation": "本文的方法结合了传统的信号处理技术与去噪扩散模型WaveGrad和DiffWave，创建一个增强数据集，用于在多模态和多通道心音数据集上微调基于Wav2Vec 2.0的分类器，从而实现了最先进的性能。通过这种方法，利用CinC 2016单通道PCG数据集，获得了92.48%的准确率、93.05%的UAR、93.63%的敏感性、92.48%的特异性和0.8283的MCC。而在使用同步PCG和ECG信号的训练数据集，性能分别为93.14%的准确率、92.21%的UAR、94.35%的敏感性、90.10%的特异性和0.8380的MCC。使用穿戴式背心数据集，该模型实现了77.13%的准确率、74.25%的UAR、86.47%的敏感性、62.04%的特异性和0.5082的MCC。这些结果表明，增强数据集可提高基于变压器的模型在CVD检测中的效果，同时突出它们在多模态和多通道心音分类中的潜力。", "conclusion": "该研究展示了利用增强数据集支持的基于变压器的模型在CVD检测中的有效应用，并强调了它们在多模态和多通道心音分类中的潜力。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21945", "html_url": "https://arxiv.org/abs/2509.21945", "title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "title_en": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "authors": "Pengzhou Chen,Hongyuan Liang,Tao Chen", "background": "许多调优工具利用代理模型来加速配置调优过程，而不是仅依赖昂贵的系统测量。尽管人们普遍认为需要更准确的模型，但先前工作的发现显示了准确性并不总是解决问题的关键。因此，对于代理模型在配置调优中的作用仍然有许多未解之谜。本文通过适应度景观分析的新视角，首次系统地探索和讨论代理模型在配置调优中的多种角色。", "innovation": "本文提出了一种新的理论，用以评估调优模型的有用性，而非仅仅依赖于准确性。基于此理论，作者进行了广泛的经验研究（涉及27,000多个案例），并提出了一个名为Model4Tune的自动化预测工具，能够在无需昂贵配置调优工具配置的情况下预估最佳的模型-调优器对。结果表明，该工具在79%-82%的情况下表现远超随机猜测。", "conclusion": "本文不仅为未来的研究指明了方向，还提供了一种实用的解决方案来帮助实践者评估最合适的配置调优模型。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21881", "html_url": "https://arxiv.org/abs/2509.21881", "title": "软件工程数据智能分析：基于多层抽象机制的框架", "title_en": "Software Engineering Data Analytics: A Framework Based on a Multi-Layered Abstraction Mechanism", "authors": "Chaman Wijesiriwardana,Prasad Wimalaratne", "background": "本文提出了一种针对特定领域的软件分析框架，该框架能够查询、建模和整合异构的软件仓库。该框架采用了一种多层次的抽象机制，包含领域特定的操作符。", "innovation": "文章展示了基于多层次抽象机制的框架的优势，并通过案例研究进行了展示。", "conclusion": "该研究为软件工程数据分析提供了一种新的方法，通过多层抽象机制实现查询、建模和整合异构软件仓库的功能，增强了软件分析的灵活性和实用性。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20172", "html_url": "https://arxiv.org/abs/2509.20172", "title": "在Web API集成任务中评估LLMs", "title_en": "Benchmarking LLMs in Web API Integration Tasks", "authors": "Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini", "background": "API集成是数字基础设施的关键组成部分，使软件系统能够连接和交互。然而，许多研究显示，编写或生成正确代码以调用API，特别是Web API，颇具挑战性。尽管大型语言模型（LLMs）在软件开发中变得越来越流行，但它们在自动化生成Web API集成代码方面的有效性尚未得到探索。因此，研究人员开发了一个数据集和评估管道，以评估LLMs生成Web API调用代码的能力。实验结果表明生成API调用存在重大挑战，导致生成假想的端点、错误的参数使用和其他错误。评估的开源模型中没有一个能够解决超过40%的任务。", "innovation": "研究人员提出了一个数据集和评估管道，用于评估LLMs在生成Web API调用代码方面的表现。这是首次系统地评估大型语言模型在Web API集成任务中的能力，为未来的研究提供了新的基准和工具。", "conclusion": "尽管大型语言模型在其他领域表现出色，但在生成Web API调用代码方面存在显著挑战，当前模型的性能较为有限，未来还需要进一步提升。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21179", "html_url": "https://arxiv.org/abs/2509.21179", "title": "IntSR: 集成生成框架实现搜索与推荐", "title_en": "IntSR: An Integrated Generative Framework for Search and Recommendation", "authors": "Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu", "background": "生成推荐作为一种有前途的范式，在学术基准和工业应用中取得了显著成果。然而，现有的系统主要集中在检索和排名的统一上，而忽视了搜索与推荐任务（S&R）的整合。搜索和推荐之间的区别在于查询的形成方式：搜索使用明确的用户请求，而推荐依赖于隐性的用户兴趣。检索与排名的区别在于查询是否为目标项本身。认识到查询作为关键元素的重要性，本文提出了一种集成生成框架IntSR，用于实现S&R。", "innovation": "IntSR是一个新的整合生成框架，用于实现搜索与推荐任务。它可以使用不同的查询模态整合这些离散任务，并解决了与集成S&R行为相关增加的计算复杂性以及由动态变化的语料库引入的错误模式学习问题。该框架已经在Amap中成功部署，并且在数字资产的GMV、POI推荐的CTR和旅行模式建议的ACC方面均取得了显著改进。", "conclusion": "IntSR通过整合搜索与推荐任务，并有效解决这些任务的挑战，为提高搜索和推荐的效果带来了一系列显著的改进。"}
{"llm_update_time": "20250929", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21206", "html_url": "https://arxiv.org/abs/2509.21206", "title": "基于数据驱动神经网络的Windkessel参数校准方法", "title_en": "Data-driven Neural Networks for Windkessel Parameter Calibration", "authors": "Benedikt Hoock,Tobias Köppl", "background": "本文研究了在降维的1D-0D耦合血流模型中校准Windkessel (WK) 参数的方法。背景是现有方法可能需要复杂的物理建模和大量计算成本，通过设计一个基于数据驱动的神经网络来改善这一问题。该网络在模拟左上臂动脉血压的数据上进行训练，以估计从时间、空间和WK参数变化引发的脉冲波的压力波动。", "innovation": "创新点在于提出了一种新的方法，利用数据驱动的神经网络进行Windkessel参数校准。神经网络通过模拟数据训练，能够准确地模拟整个系统中的压力脉冲波，同时对于实际测量中的脉冲波通过引入虚拟神经元进行校准，这种方法极大地简化了计算过程，提高了校准效率。", "conclusion": "研究结果表明神经网络方法在不同情况下都很有效，尤其是当测量位置不确定或数据受到噪声影响时，这种方法仍然可以提供可靠的参数校准。实验结果显示，该方法具有很高的准确性和较低的计算成本。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21533", "html_url": "https://arxiv.org/abs/2509.21533", "title": "过渡中的迷失：软件工程研究领域女性回归时的挣扎", "title_en": "Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks", "authors": "Shalini Chakraborty,Sebastian Baltes", "background": "IT行业为女性回归提供了一些支持路径，如实习项目、编程训练营和同伴支持系统。然而，学术界为鼓励女性回归提供的机会非常有限。课题研究聚焦于考察具有软件工程背景的女性在经历职业中断后重新进入学术界或相关研究角色所面临的挑战。这些中断可能由怀孕、移民身份或缺乏灵活的工作选项引起，会显著影响女性的职业发展，成为她们重新入职到教授、讲师或高级研究人员时的障碍。尽管许多公司推行性别多样性政策，但这些措施在学术机构中的推广和认可程度较低。研究目的是对比分析女性在重返学术领域时遇到的挑战与重返行业领域的挑战，了解不同国家和地区的机构政策和机会，并提出促进透明招聘实践的建议，以支持女性回归学术领域。研究项目将在多个大学和多个国家进行，以捕捉不同地区的多样化挑战和政策差异性。", "innovation": "本研究创新之处在于通过多元文化的视角，对比分析女性在重返学术领域与重返行业领域的挑战，强调现有的性别多样性政策在学术机构中缺乏推广，并提出了具体的建议来支持职业女性重返学术环境。研究采用了跨多个大学和国家的方法，确保研究结果具有广泛的代表性。", "conclusion": "研究强调，虽然IT行业为女性回归提供了多种支持路径，但学术界在留住有软件工程背景的女性方面存在明显不足。研究提出了一系列具体的政策建议，旨在促进性别多样性和透明的招聘实践，帮助女性克服重返学术界时的挑战。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22320", "html_url": "https://arxiv.org/abs/2509.22320", "title": "绿编码工程：软件工程中提示设计的能耗影响研究", "title_en": "Green Prompt Engineering: Investigating the Energy Impact of Prompt Design in Software Engineering", "authors": "Vincenzo De Martino,Mohammad Amin Zadenoori,Xavier Franch,Alessio Ferrari", "background": "语言模型在软件工程中的应用日益增多，但其推理过程也引起了日益增长的环境担忧。现有的研究主要集中在硬件选择和提示长度上，较少关注语言复杂性作为可持续性因素。此前的研究已探讨了硬件选择和提示长度等因素，但未充分考虑语言复杂性对环境可持续性的影响。", "innovation": "本文提出了绿编码工程，将语言复杂性视为一种设计维度，可以影响能源消耗和性能。它通过实证研究，分析了开源小型语言模型在需求分类任务中可读性对环境可持续性和性能的影响，揭示了两者之间的权衡。", "conclusion": "更简单的提示可以在不显著降低F1分数的情况下降低能源成本；对于研究人员，这为在绿色AI议程下制定关于可持续提示设计的指南和研究开辟了一条途径。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22097", "html_url": "https://arxiv.org/abs/2509.22097", "title": "SecureAgentBench: 在实际漏洞场景下评估安全代码生成基准", "title_en": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios", "authors": "Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo", "background": "大型语言模型（LLM）驱动的代码代理正在迅速改变软件工程，通过自动化测试、调试和修复等功能，但它们生成的代码安全性问题已成为关键关注点。现有基准虽然提供了有价值的信息，但仍然不足：它们往往忽略了漏洞引入的实际上下文，或采用了评估协议，未能全面涵盖功能正确性和新引入的漏洞检测。", "innovation": "提出SecureAgentBench基准，包含105个编码任务，严格评估代码代理的安全代码生成能力。每个任务包括：（i）要求多文件编辑的真实任务设置；（ii）基于真实世界开源漏洞且具有精确识别引入点的对齐上下文；（iii）综合评估功能测试、概念验证exploits漏洞检查和静态分析检测新引入的漏洞。评估了三个代表性的代理（SWE-agent、OpenHands和Aider）和三个最先进的LLM（Claude 3.7 Sonnet、GPT-4.1和DeepSeek-V3.1）。结果显示，当前代理难以生成安全代码，部分代理虽能生成功能正确的代码但仍然引入了漏洞，包括未记录的新漏洞。添加明确的安全指令对提高安全编码效果有限。", "conclusion": "这些发现建立了SecureAgentBench作为安全代码生成的严格基准，并为进一步利用LLM实现更可靠软件开发奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21816", "html_url": "https://arxiv.org/abs/2509.21816", "title": "无需手动指南：高质量Excel教程的自动和可扩展生成", "title_en": "No More Manual Guides: Automatic and Scalable Generation of High-Quality Excel Tutorials", "authors": "Yuhang Xie(1),Jian Mu(2),Xiaojun Ma(3),Chaoyun Zhang(3),Lu Wang(3),Mengyu Zhou(3),Mugeng Liu(1),Si Qin(3),Qingwei Lin(3),Saravan Rajmohan(3),Shi Han(3),Dongmei Zhang(3) ((1) Peking University, (2) Nanjing University, (3) Microsoft)", "background": "Excel是跨领域中最广泛使用的生产力工具之一，提供了丰富的功能但也令用户因过于复杂而感到困扰。这种复杂性导致了对官方教程的持续需求，以帮助用户更有效地使用Excel。然而，现有的教程由专家手工编写，每次软件更新后都需要频繁更新，并且会产生大量人工成本。尽管已有研究努力通过自动化过程生成教程，但这些方法仍然依赖于手工编写的操作序列或示例材料。因此，目前尚无能完全自动从自然语言任务描述生成Excel教程的方式。", "innovation": "本文提出了一种新的框架，能够在不依赖手工操作或示例材料的情况下，直接从自然语言任务描述自动生成Excel教程。该框架包含任务实例化、执行代理（规划和执行解决方案并在Excel中收集中间产物）以及将这些中间产物转换成结构化Excel文档和视频演示等核心步骤。为确保生成的教程全面，作者收集了1,559个真实场景下的任务描述，并设计了一个综合评估框架，结合大型语言模型和人类评审者的评估。实验结果显示，该框架相较于最先进的基准提高了8.5%的任务执行成功率，且生成的教程在可读性和教学有效性方面均优于专家撰写的材料。更重要的是，自动流程消除了手工劳动，生成的教程生成时间成本降低了20倍，将高质量教程的大规模生成变为现实。", "conclusion": "自动化的教程生成流程不仅提高了效率，降低了成本，更重要的是它实现了高质量Excel教程的大规模和可扩展生成，这将在教育和企业培训等多个领域产生广泛影响。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21891", "html_url": "https://arxiv.org/abs/2509.21891", "title": "AgentPack：由人类和智能代理共同编辑的代码变更数据集", "title_en": "AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans", "authors": "Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha", "background": "大型语言模型（LLM）的微调通常依赖于挖掘提交和 pull 请求。假设提交信息用自然语言描述了人类意图，而代码补丁描述了实现该意图的更改。然而，以往收集的数据质量参差不齐，提交信息简洁、人类撰写的提交信息混杂了多个无关的编辑，许多提交来自简单的基于规则的机器人。随着软件工程代理的采用，情况发生了变化。人类与代理共同编辑的代码变更通常更加聚焦，目标更明确。这些提交的信息由LLM生成，详细阐述了意图和原理。当这些变更提交到公开的仓库时，它们会通过人类的筛选，维护者会舍弃低质量的提交。", "innovation": "论文介绍了AgentPack，这是由Claude Code、OpenAI Codex和Cursor Agent在2025年8月中旬之前在公开的GitHub项目上共同编辑的130万次代码变更组成的数据集。论文描述了识别和整理流程，量化了这些代理的采用趋势，并分析了这些变更的结构特性。实验结果表明，基于AgentPack微调的模型比基于纯人类提交数据的模型性能更优，显示了利用软件工程代理的公开数据来训练未来的代码编辑模型的潜力", "conclusion": "基于AgentPack微调的模型在性能上超过了基于纯人类提交数据的模型，这表明可以从软件工程代理的公开数据中训练出更好的代码编辑模型，具有较高的应用价值。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22530", "html_url": "https://arxiv.org/abs/2509.22530", "title": "利用大型语言模型增强分配函数检测以提升指针分析", "title_en": "Boosting Pointer Analysis With Large Language Model-Enhanced Allocation Function Detection", "authors": "Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Peng Di,Yao Guo,Ding Li,Xiangqun Chen", "background": "指针分析是静态分析任务的基础，但在C/C++程序中，由于用户自定义的分配函数（AFs）普遍存在，其精确建模往往不够精确，这限制了指针分析的效果。现有的方法大多忽视了这些自定义分配器，导致粗略的关联性和降低的分析精度。", "innovation": "本文介绍了一种名为AFD的新技术，通过自动识别和建模自定义分配函数来增强指针分析。AFD采用一种混合方法：使用值流分析检测简单的包装器，并利用大型语言模型（LLMs）处理具有副作用的复杂分配模式。这种有针对性的增强能够在每个调用点精确建模堆对象，从而在不增加过多开销的情况下获得类似上下文敏感性的效果。在15个真实C项目上进行了评估，发现了超过600个自定义AF，并在基本的指针分析中集成了AFD，模型的堆对象数量提高了26倍，关联集合的大小减少了39%，仅增加了1.4倍的运行时间开销。增强后的分析提高了间接调用的解决，并检测到17个之前未被发现的内存错误。", "conclusion": "研究表明，精确建模自定义分配函数为在大型软件系统中提高指针分析提供了一种可扩展且实用的道路。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21677", "html_url": "https://arxiv.org/abs/2509.21677", "title": "预言：从神经元激活推断形式属性", "title_en": "Prophecy: Inferring Formal Properties from Neuron Activations", "authors": "Divya Gopinath,Corina S. Pasareanu,Muhammad Usman", "background": "神经网络的逻辑在很大程度上被神经内层的激活状态所捕获。当前已有工具和方法对这些性质进行自动推断和验证存在局限性，目前的研究希望通过开发新的工具，直接从神经元激活状态来自动推断神经网络的形式属性，为神经网络的验证提供了新的角度。", "innovation": "预言工具基于内层神经元激活状态，通过提取基神经元激活状态（值或开关状态）为前置条件来推断特定输出属性的规则，进而推断网络中间层的性质，证明神经网络的输出行为。该工具能够应用于不同的神经网络模型和输出属性，具有实现形式化解释、组合验证、运行时监控、修复等多种应用，并在大规模的视觉语言模型上展现出潜在价值。", "conclusion": "预言工具通过对神经元激活状态的分析，自动推断神经网络的形式属性，在验证神经网络的应用领域带来了新颖的研究成果和潜在应用。该工具具备广泛的应用前景，尤其在大型视觉语言模型的研发中有着重要的作用。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22337", "html_url": "https://arxiv.org/abs/2509.22337", "title": "GPU加速的循环信念传播算法用于程序分析", "title_en": "GPU-Accelerated Loopy Belief Propagation for Program Analysis", "authors": "Haoyu Feng,Xin Zhang", "background": "循环信念传播（LBP）是一种在概率图模型中广泛应用的近似推理算法，应用于计算机视觉、纠错码、蛋白质折叠、程序分析等多个领域。然而，将LBP应用于大规模程序分析时面临显著的计算挑战。虽然基于GPU的并行计算为LBP算法提供了一个有前景的解决方案，但现有方法缺乏灵活的更新策略支持，也无法结合逻辑约束进行GPU加速，从而导致实际性能不佳。", "innovation": "本文提出了一种支持GPU加速的LBP算法，用于程序分析。为了支持用户提出的任意更新策略，本文提出了一种统一表示法来指定任意用户定义的更新策略，并提出了一个依赖分析算法。此外，基于之前利用Horn子句局部结构简化消息传递的工作，本文通过分组消息来最小化warp分歧并充分利用GPU资源。实验结果表明，在针对八个真实Java程序的竞态条件分析中，该方法分别比最先进的串行方法和基于GPU的方法分别快2.14倍和5.56倍，同时保持了高精度。", "conclusion": "本文提出了一种GPU加速的LBP算法，能够在不牺牲精度的情况下，显著提高程序分析的速度。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22202", "html_url": "https://arxiv.org/abs/2509.22202", "title": "LLMs中的库幻觉：基于开发者查询的风险分析", "title_en": "Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries", "authors": "Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis", "background": "大型语言模型（LLMs）越来越多地用于生成代码，但它们仍然会产生幻觉，通常发明不存在的库。这些库幻觉不仅是无害的错误：它们可以误导开发人员，导致构建失败，并使系统面临如slopsquatting等供应链威胁。尽管越来越多意识到这些风险，但对实际提示变异如何影响幻觉率知之甚少。因此，本文进行了首个系统研究，探讨用户级别提示变异对LLM生成代码中库幻觉的影响。研究涉及六种不同的LLM，并对库名称和库成员幻觉两种幻觉类型进行评估。本文探讨了从开发者论坛中提取的合理用户语言以及不同程度的用户错误（包括一字符或多个字符错拼和完全虚假的名字/成员）对LLM幻觉率的影响。研究结果显示了一种字符错拼可以触发高达26%的任务的幻觉，虚假库名称在高达99%的任务中被接受，时间相关提示可能导致高达84%的任务生成幻觉。", "innovation": "本文进行了首个系统性研究，探讨了用户级别提示变异对LLM生成代码中库幻觉的影响。涉及六种不同的LLM，并对两种幻觉类型（库名称和库成员幻觉）进行了评估。研究揭示了幻觉的触发点，包括简单的字符错拼可以触发高达26%的任务的幻觉，虚假库名称在高达99%的任务中被接受，时间相关提示可能导致高达84%的任务生成幻觉。此外，研究还显示了提示工程可能有助于缓解幻觉问题，但这种方法仍然不一致且依赖于特定的LLM。", "conclusion": "研究结果强调了LLMs对自然提示变化的脆弱性，并突显了迫切需要防止库幻觉及其潜在利用的保护措施。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22170", "html_url": "https://arxiv.org/abs/2509.22170", "title": "利用LLM代理进行自动视频游戏测试", "title_en": "Leveraging LLM Agents for Automated Video Game Testing", "authors": "Chengjia Wang,Lanling Tang,Ming Yuan,Jiongchi Yu,Xiaofei Xie,Jiajun Bu", "background": "测试大规模多人在线角色扮演游戏（MMORPG）是一个关键但耗时的任务，由于其复杂性和频繁更新的特点。传统的自动化游戏测试方法难以在这些丰富多彩、开放的环境中实现高状态覆盖率和效率。目前基于LLM的游戏玩法方法在理解复杂的游戏状态-行动空间和长期复杂任务方面能力有限。因此，本研究旨在解决上述挑战，提出了一个有效的LLM驱动的智能MMORPG测试框架TITAN，该框架包含四个关键组件：（1）感知和抽象高维度游戏状态，（2）主动优化和优先级排序可用的动作，（3）通过动作轨迹记忆和反思性自我纠正进行长期推理，（4）使用LLM驱动的或acles检测功能和逻辑缺陷并提供诊断报告。", "innovation": "本研究创新性地提出了一个名为TITAN的LLM驱动的智能MMORPG测试框架，该框架能够处理复杂的、开放的游戏环境，实现了显著高的任务完成率（95%）和高级别的缺陷检测性能。与现有自动化游戏测试方法相比，TITAN能够检测到先前测试方法未发现的四个潜在的函数和逻辑缺陷。通过分层研究进一步证明了TITAN各个核心组件对其整体性能的贡献。研究结果还为未来智能、通用测试系统的进步提供了指南。TITAN已在八个真实的游戏质量保证管道中部署，证实了其作为LLM驱动的游戏测试框架的实际影响。", "conclusion": "本研究提出了一个名为TITAN的有效的LLM驱动智能MMORPG测试框架，通过实验证明其在复杂游戏环境中的优势，尤其在任务完成率和缺陷检测性能上的显著提升。研究结果表明，每个核心组件都对TITAN的整体性能有重大贡献，并且首次检测到了四个尚未被发现的bug。此外，TITAN已经在多个实际应用中部署，证明了其在实践中的重要性和高效性。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22040", "html_url": "https://arxiv.org/abs/2509.22040", "title": "您的AI，我的控制台：揭秘针对代理型AI编码编辑器的提示注入攻击", "title_en": "\"Your AI, My Shell\": Demystifying Prompt Injection Attacks on Agentic AI Coding Editors", "authors": "Yue Liu,Yanjie Zhao,Yunbo Lyu,Ting Zhang,Haoyu Wang,David Lo", "background": "基于大型语言模型驱动的代理型AI编码编辑器最近变得越来越流行，因为它们能够提高开发人员在软件开发过程中的生产力。现代编辑器不仅用于代码完成，还具有更高的系统权限，以完成复杂的编码任务（例如在终端中运行命令、访问开发环境并与外部系统交互）。虽然这种技术为实现“全自动编程”梦想提供了可能，但也带来了新的安全问题。本研究首次探讨了针对这些高权限代理型AI编码编辑器的提示注入攻击。", "innovation": "本研究开发了AIShellJack，这是一个自动化测试框架，用于评估代理型AI编码编辑器中的提示注入漏洞。AIShellJack包含了314个独特的攻击载荷，覆盖了来自MITRE ATT&CK框架的70种技术。通过AIShellJack，研究在GitHub Copilot和Cursor上进行了大规模评估，结果显示执行恶意命令的成功率高达84%，并且这些攻击在不同目标下（如初始访问、系统发现、凭证窃取和数据泄露等）都是有效的。", "conclusion": "本研究强调了针对代理型AI编码编辑器的提示注入攻击的重要性，揭示了攻击者可以通过远程操纵系统资源来利用这些编辑器，从而严重影响系统安全性。未来需要进一步加强此类编辑器及其内部AI代理的安全性，以防止此类攻击。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22379", "html_url": "https://arxiv.org/abs/2509.22379", "title": "多模态评估自主驾驶系统中的现实差距", "title_en": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems", "authors": "Stefano Carlo Lambertenghi,Mirena Flores Valdez,Andrea Stocco", "background": "自主驾驶系统（ADS）的开发依赖于基于模拟的测试，这种测试可以在多种驾驶场景下提供安全且可扩展的评估。然而，模拟环境与真实世界行为之间的差异，即现实差距，使得测试结果转移到实际部署系统中存在挑战。本文通过对四种代表性测试模式——软件在环测试（SiL）、车辆在环测试（ViL）、混合现实测试（MR）和完全现实世界测试进行对比研究，探讨了这四种模式对感知、执行和行为一致性差距的影响，从而评估不同测试模式的优劣，为自主驾驶系统验证提供了参考路径。", "innovation": "研究采用了一个配备实际传感器（包括摄像头和激光雷达）的小型物理车辆及其数字双胞胎，分别实现了每种测试设置，并在室内多样环境中对比两种ADS架构（模块化和端到端）的表现，分析了每种测试模式在感知、执行和行为可靠性差距上的影响。研究不仅揭示了测试模式下不转移失败的条件，还指出了造成这些差异的差距的潜在维度，提出了自主驾驶系统更可靠和可转移验证的方法。", "conclusion": "研究结果表明，SiL和ViL可以简化实际动态和感知，而MR测试可以提高感知的真实感而不影响安全性和控制。文章指出了每种测试模式的优势和局限性，并为自主驾驶系统的验证提供了实操性的建议，为系统开发更加稳健和可转移性指明了方向。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22114", "html_url": "https://arxiv.org/abs/2509.22114", "title": "SK2Decompile: 基于LLM的从框架到皮肤的两阶段二进制反编译", "title_en": "SK2Decompile: LLM-based Two-Phase Binary Decompilation from Skeleton to Skin", "authors": "Hanzhuo Tan,Weihao Li,Xiaolong Tian,Siyi Wang,Jiaming Liu,Jing Li,Yuqun Zhang", "background": "大型语言模型（LLMs）已经成为了二进制去编译的一种有前景的方法。然而，现有的基于LLM的去编译器在展示程序的源代码层次结构和原始标识符方面仍然有限。为了解决这一问题，该论文提出了一种新的两阶段方法SK2Decompile，旨在独立地提高反编译的正确性和可读性，并介绍了一种通过骨架（语义结构）到皮肤（标识符）的方法进行反编译的新方法。这种方法首先使用结构恢复模型将二进制代码转换为中间表示（IR），并使用强化学习来奖励生成符合编译器预期的语法规则和语义规则的程序结构。然后，通过使用标识符命名模型生成反映实际程序语义的有意义标识符，从而完成反编译过程的第二阶段。", "innovation": "SK2Decompile引入了一种两阶段的新型反编译方法，将反编译过程分为骨架恢复阶段和标识符命名阶段。骨架恢复阶段使用结构恢复模型将程序的二进制代码转换为中间表示（IR），并利用强化学习来奖励生成符合语法规则和语义规则的程序结构。标识符命名阶段使用标识符命名模型来生成反映实际程序语义的有意义标识符。这种方法显著提高了反编译的准确性和可读性，并在多个基准上的性能超过了目前最先进的基线方法。", "conclusion": "SK2Decompile在两个反编译阶段中分别关注结构恢复和标识符命名，显著提高了比目前最先进的基线方法的反编译正确性和可读性。具体而言，在HumanEval数据集上，SK2Decompile比GPT-5-mini平均提高了21.6%的重新执行率，而在GitHub2025基准上，比Idioms平均提高了29.4%的R2I表现。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22420", "html_url": "https://arxiv.org/abs/2509.22420", "title": "特定背景指导：新手程序员调试技能获取与保持的纵向研究", "title_en": "Context-Specific Instruction: A Longitudinal Study on Debugging Skill Acquisition and Retention for Novice Programmers", "authors": "Ziyi Zhang,Devjeet Roy,Venera Arnaoudova", "background": "调试故障是一个关键技能，但初学者通常缺乏系统的方法。已有研究测试了抽象的指导原则和具体的常规步骤，而具体背景指导的效果尚不清楚。本研究通过为期八周的纵向实验，评估了四种条件对初学者调试技能的影响：无指导（G1）、抽象指导（G2）、具体步骤（G3）以及我们提出的具体背景指导（G4，结合具体调试步骤和问题特定细节）.", "innovation": "本研究通过结合具体背景指导和特定问题细节，创新性地提出了有助于新手程序员更快获取和保留调试技巧的方法。实验结果显示，特定背景指导不仅显著提高了初学者的调试准确性和完成时间，而且初学者在第一次会话后就达到了80%的正确率，并在三周后维持在80%，显著高于其他组。", "conclusion": "特定背景指导比抽象指导或无背景指导更有利于新手程序员技能的快速获取和持续保持。即使经过1-2次会话，也能观察到显著的进步。长期练习还能进一步优化并稳定性能。这种结合具体示例和抽象原则的方法可以弥补理论与实践之间的差距，为新手提供更公平的学习路径。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22431", "html_url": "https://arxiv.org/abs/2509.22431", "title": "TreeMind: 使用大规模语言模型增强的蒙特卡洛树搜索自动重现Android Bug报告", "title_en": "TreeMind: Automatically Reproducing Android Bug Reports via LLM-empowered Monte Carlo Tree Search", "authors": "Zhengyu Chen,Zhaoyi Meng,Wenxiang Zhao,Wansen Wang,Haoyang Zhao,Jiahao Zhan,Jie Cui,Hong Zhong", "background": "自动从文本错误报告中重现Android应用程序崩溃具有挑战性，特别是在报告不完整且现代UI具有高组合复杂性的情况下。现有基于强化学习或大型语言模型的方法在这种场景下表现出局限性。它们难以推断未观察到的步骤并重建用户动作序列，主要由于目标驱动的推理和规划有限。", "innovation": "提出了TreeMind，一种将大规模语言模型与定制化的蒙特卡洛树搜索算法结合起来的创新方法，以实现策略性的UI探索，从而在错误重现中实现战略性UI探索。TreeMind是首次尝试将外部决策与LLM语义推理结合以实现可靠错误重现。通过引入具有不同角色的两种LLM引导代理，和使用多模态UI输入以及高级提示技术，TreeMind能够进行反馈感知导航，从而识别缺失但必要的用户动作，并逐步重构重现路径。", "conclusion": "在包含93个真实世界Android错误报告的三个广泛使用的基准数据集上评估TreeMind，实验结果表明其在重现成功率上显著优于四种最先进的基线。实际案例研究表明，将LLM推理与基于Monte Carlo树搜索的规划结合起来是自动错误重现的有前景方向。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.21914", "html_url": "https://arxiv.org/abs/2509.21914", "title": "MUG-10框架：移动应用开发中防止可用性问题", "title_en": "The MUG-10 Framework for Preventing Usability Issues in Mobile Application Development", "authors": "Pawel Weichbroth,Tomasz Szot", "background": "如今，移动应用已成为日常生活中不可或缺的工具，为用户提供随时随地获取最新信息、交流和娱乐的机会。然而，硬件限制和不同用户群体的需求多样性给设计和开发带来了许多挑战。尽管可用性是最需要关注的因素之一，但很少有人直接讨论如何在移动应用开发中避免可用性问题。基于对20名移动软件设计和开发专家的调查，本研究旨在填补这一研究空白。利用在 vivo 编码对收集的数据进行分析，形成了一个包含十项指南和三项通用活动的创新框架，强调了不同开发阶段与用户保持积极合作的重要性。", "innovation": "该研究通过在 vivo 编码的分析方法，开发了一种新的用于防止移动应用开发中可用性问题的框架（MUG-10框架），该框架包括十项具体指南和三项通用活动。强调在移动应用开发的不同阶段与用户进行积极协作的重要性。", "conclusion": "未来的研究应考虑针对我们建议进行集中行动研究，验证其在不同利益相关者群体中的有效性。此外，还应开发自动化工具来支持在移动应用开发早期阶段发现和缓解可用性问题。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.03981", "html_url": "https://arxiv.org/abs/2410.03981", "title": "低资源和领域特定编程语言基于LLM的代码生成综述", "title_en": "A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages", "authors": "Sathvik Joel,Jie JW Wu,Fatemeh H. Fard", "background": "大语言模型（LLMs）展示了在流行编程语言代码生成方面的出色能力。然而，它们在低资源编程语言（LRPLs）和领域特定语言（DSLs）上的性能仍是一个挑战，影响了数百万不能充分利用LLM能力的开发人员。LRPLs 和 DSLs 遇到的挑战包括数据稀缺性，此外，DSLs 有特殊的语法，在通用数据集中难以代表。这些语言增强在特定领域的开发效率，如金融和科学。尽管已有几项综述讨论了LLMs在软件工程中的应用，但没有一项专门关注LRPLs和DSLs的挑战与机遇。因此，本研究通过系统地审查LLMs在这些编程语言中的代码生成能力、方法和挑战，填补了这一空白。", "innovation": "本研究通过系统筛选2020年至2024年间超过27,000篇研究论文中的111篇，首次全面评估了LLMs在LRPLs和DSLs中的代码生成能力与限制。研究报道了所使用的LLMs、基准和评价指标、性能提升策略以及数据集收集和整理方法。研究发现四种主要的评估技术和若干评估代码生成的标准。此外，本研究将改进方法分为六个类别，并总结了研究者提出的新型架构。", "conclusion": "尽管各种技术和指标存在，但对于LRPLs和DSLs的代码生成评估仍缺乏标准化的方法和基准数据集。本综述为LLMs、软件工程和专门编程语言交叉领域的研究人员和从业者提供了宝贵的资源，为未来在LRPLs和DSLs中的代码生成进步奠定了基础。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.22237", "html_url": "https://arxiv.org/abs/2509.22237", "title": "FeatBench：评估编码代理在特征实施方面的Vibe编码", "title_en": "FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding", "authors": "Haorui Chen,Chengze Li,Jia Li", "background": "大型语言模型（LLMs）的快速发展催生了一种新型软件开发范式——vibe coding，用户可以通过高级自然语言与编码代理进行交互。然而，现有的代码生成评估基准无法充分评估代理在vibe coding范式中的能力，存在任务要求代码级别规范或仅仅局限于问题解决，无法覆盖特征实现的场景。", "innovation": "提出了一个全新的基准FeatBench，专门针对vibe coding中的特征实现。该基准的特点包括：1. 完全纯自然语言提示，任务输入仅包含抽象的自然语言描述，无任何代码或结构提示；2. 严格的、不断演化的数据收集过程，确保数据质量并自动演化基准；3. 全面的测试用例，包括失败转成功和成功转成功的测试，以验证正确性并防止回归；4. 通用的应用领域，包含来自不同领域的仓库以确保基准反映真实场景。", "conclusion": "在两个最先进的代理框架和四个领先的LLM上对FeatBench进行评估，结果显示特征实现是vibe coding范式中的一个重要挑战，成功率为29.94%。我们的分析还揭示了“激进实施”的趋势，这在导致重大失败的同时也提升了软件设计。发布了FeatBench、自动收集管道和所有实验结果，以促进进一步的研究工作。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2210.05102", "html_url": "https://arxiv.org/abs/2210.05102", "title": "使用对比学习预训练二进制代码的表示", "title_en": "Pre-Training Representations of Binary Code Using Contrastive Learning", "authors": "Yifan Zhang,Chen Huang,Yueke Zhang,Huajie Shao,Kevin Leach,Yu Huang", "background": "二进制代码分析和理解对于缺乏源代码的逆向工程和计算机安全任务至关重要。然而，与源代码相比，二进制代码缺乏语义信息，使得人工工程师更难以理解和分析。", "innovation": "本文提出了ContraBin，这是一种对比学习技术，结合源代码、注释信息和二进制代码来创建可用于辅助二进制分析和理解任务的嵌入。ContraBin包含三个组件：主要的对比学习方法、复形插值方法以及中间表示学习算法来训练二进制代码嵌入。此外，通过人类编制和合成的注释对二进制代码理解任务的影响进行了分析，揭示了注释类型对二进制代码分析的影响。ContraBin 是第一个将源代码、二进制代码和注释整合到对比学习代码表示学习中的语言表示模型。", "conclusion": "通过四项与二进制代码相关的下游任务（算法功能分类、函数名称恢复、代码总结以及逆向工程），评估了ContraBin的性能，结果显示其在所有任务上均有显著的准确性和性能提升，且是用于二进制代码分析的第一个语言表示模型。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.18401", "html_url": "https://arxiv.org/abs/2411.18401", "title": "证明和奖励客户端多样性以增强区块链网络的韧性", "title_en": "Proving and Rewarding Client Diversity to Strengthen Resilience of Blockchain Networks", "authors": "Javier Ron,Zheyuan He,Martin Monperrus", "background": "区块链网络的韧性依赖于客户端的多样性，然而，大多数网络中的客户端实现分布存在显著偏差，这种单一文化使得网络面临高风险情景，如主要客户端故障可能造成的重大经济损失。", "innovation": "本文提出了一种结合可验证执行和经济激励的新框架，以证明和奖励少数客户端的使用，从而促进一个更健康、更稳健的生态系统。该方法利用最先进的可验证计算技术（零知识虚拟机zkVMs和可信执行环境TEEs），生成客户端执行的加密证明，这些证明随后在链上验证。通过在以太坊中修改流行客户端Lighthouse并部署新颖的多样性意识奖励协议来构建端到端的证明客户端多样性的原型。从证明生产和验证的开销以及激励机制的有效性等方面进行了全面的实验，量化了该方法的实用性。这是首次证明了实际且经济可行的路径以促进和确保区块链网络中的可验证客户端多样性。", "conclusion": "本文的研究成果指导了未来旨在最大化分散系统韧性的协议的设计。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.16913", "html_url": "https://arxiv.org/abs/2503.16913", "title": "FGIT: 针对代码生成的错误导向微调方法", "title_en": "FGIT: Fault-Guided Fine-Tuning for Code Generation", "authors": "Lishui Fan,Zhongxin Liu,Haoye Wang,Lingfeng Bao,Xin Xia,Shanping Li", "background": "现代指令调整的大语言模型（LLMs）在代码生成方面取得了显著进展。然而，这些使用标准的监督微调（SFT）进行微调的LLMs有时会生成看似合理但实际上功能不正确的代码变体。这一问题可能源于标准SFT的局限性，该方法在优化过程中平等对待所有token，未能突出正确实现和相似但错误的变体之间的敏感错误代码片段的差异。", "innovation": "为了缓解这一问题，我们提出了一种新的微调技术——错误导向微调（FGIT）。FGIT通过（1）提取正确和看似正确但错误实现之间的多粒度（按行/按token级别）差异，以识别敏感错误代码片段；（2）在训练过程中动态优先考虑这些片段，通过动态损失权重进行。实验结果表明，该方法在七个LLMs上取得了平均6.9%的pass@1相对改进，部分增强的6.7B LLMs在某些情况下甚至超过了闭源模型如GPT-3.5-Turbo。此外，该微调技术展示了强大的泛化能力，性能改进范围从3.8%到19.1%，适用于各种指令调整的LLMs。", "conclusion": "我们的研究表明，通过FGIT增强的LLMs在代码生成方面的性能有了显著提升。不同的差异粒度和超参数的贡献也得到了确认。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.20172", "html_url": "https://arxiv.org/abs/2509.20172", "title": "评估LLMs在Web API集成任务中的表现", "title_en": "Benchmarking LLMs in Web API Integration Tasks", "authors": "Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini", "background": "API集成是数字基础设施的关键组成部分，使软件系统能够相互通信。然而，许多研究都表明，编写或生成正确的代码来调用API（尤其是Web API）具有挑战性。尽管大型语言模型（LLM）在软件开发中日趋流行，但它们在自动化生成Web API集成代码方面的有效性尚未得到探索。", "innovation": "本文通过构建数据集和评估管道来评估LLM生成Web API调用代码的能力，这是首次针对这一特定领域进行的探索。实验结果表明，LLM在生成API调用时面临极大挑战，表现为生成虚假的API端点、错误的参数使用和其他错误。评估的开源模型中没有一个能够完成超过40%的任务。", "conclusion": "基于此实验结果，我们可以得出结论，现有的开源LLM在Web API集成任务上表现不佳，未来研究需要更深入地探索如何改进LLM的生成能力以应对这些挑战。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.16198", "html_url": "https://arxiv.org/abs/2509.16198", "title": "RPG: 一种一体化和可扩展的代码库生成的仓库规划图", "title_en": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": "Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang", "background": "大型语言模型在生成单个函数或单个代码文件方面表现出色，但在从零开始生成完整的代码库方面仍然存在根本性的挑战。当前的方法依赖于自然语言规划，这往往会产生不清晰的规范、对齐的组件和脆弱的设计。由于自然语言的固有模糊性及其缺乏结构，这些方法存在局限性。因此，需要一种更一致、更长期规划的方法来生成代码库。", "innovation": "本文提出了一种结构化的表示方法——仓库规划图（RPG），它可以统一地编码功能、文件结构、数据流和函数。此外，通过使用图形驱动框架ZeroRepo来进行提案级别的规划、实施级别的构建和基于图形的代码生成以及测试验证，实现了一种新的统一且可扩展的代码库生成方法。", "conclusion": "在 RepoCraft 标准上，ZeroRepo 生成了平均 3.9 倍于最强基线（Claude Code）的 36000 行代码和 44.5 万代码标记，同时覆盖率为 81.5%，测试准确率为 69.7%，分别提高了 27.3 和 35.8 个百分点。进一步分析表明，RPG 能够解决复杂依赖性，使规划更加精细，并加速对代码库的理解，从而实现更高效的任务完成。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.11022", "html_url": "https://arxiv.org/abs/2506.11022", "title": "迭代AI代码生成中的安全性退化——一项关于悖论的系统分析", "title_en": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "authors": "Shivani Shukla,Himanshu Joshi,Romilla Syed", "background": "大型语言模型（LLMs）在代码生成中的快速应用已经改变了软件开发，但很少有人关注的是这些模型的迭代反馈如何导致安全漏洞的变化和演化。这项研究通过一个包含400个代码样本、40轮改进的受控实验，分析了AI生成代码中的安全性退化问题，特别是在使用四种不同提示策略时的不同漏洞模式。研究发现，在仅仅五次迭代后，关键漏洞增加了37.6%，这挑战了人们对于迭代LLM精炼能够提升代码安全性的假设，强调了人类专业知识在代码生成整个过程中不可或缺的角色。", "innovation": "通过一个包含400个代码样本、40轮改进的受控实验，该研究分析了AI生成代码中的安全性退化问题，特别是在使用四种不同提示策略时的不同漏洞模式。这项研究揭示了在迭代LSTM模型中，代码安全性可能不仅不会提升，反而退化的现象，提供了新的视角和技术支持来理解AI代码生成的安全性挑战。", "conclusion": "研究结果表明，迭代LLM算法可能会引入新的安全漏洞，这些漏洞在被认为是有益的代码改进过程中变得更加严重。为了应对这些安全挑战，研究提出了开发人员的实际指南，强调在LLM每次迭代之间，进行可靠的人类验证的重要性，以防止所谓的“有益改进”过程中出现新的安全问题。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.16331", "html_url": "https://arxiv.org/abs/2504.16331", "title": "代码语言模型能否学习寻求澄清的行为？", "title_en": "Can Code Language Models Learn Clarification-Seeking Behaviors?", "authors": "Jie JW Wu,Manav Chaudhary,Davit Abrahamyan,Arhaan Khaku,Anjiang Wei,Fatemeh H. Fard", "background": "大型语言模型（LLMs）在代码生成任务中显示出了显著的能力，但它们的输出与人类开发者的解决问题策略之间仍存在差距。与花费大量时间通过迭代对话消除歧义不同，LLMs经常在自然语言要求模糊的情况下生成代码，这导致了不可靠的解决方案。尽管有些研究集中在基于LLM的代理进行迭代代码生成，但本文认为，能够识别并查询模糊要求的能力应该成为模型本身固有的特性，特别是在智能代理AI中，模型与人类协作的情况下，这种能力尤为关键。", "innovation": "本文创新地研究了是否可以对代码LLM进行微调以学习寻求澄清的行为。不同于以往工作，本文提出了ClarifyCoder框架，该框架通过合成数据生成和指令微调，使LLM在代码生成之前识别模糊和请求澄清。微调策略教会模型在面对不完整或模糊的要求时优先寻求澄清而不是立即生成代码。同时，还对ClarifyCoder与标准微调的结合进行了实证分析，以联合优化澄清意识和编程能力。实验结果显示，ClarifyCoder在模糊任务中的通信率达到了63%（绝对增长40%）和良好问题率达到了52%（绝对增长30%），显著提高了LLMs的沟通能力，同时保持了代码生成性能。", "conclusion": "研究证明，结合ClarifyCoder的微调可以显著提升代码LLMs的交流能力，同时不会损害其代码生成能力。此外，研究结果表明，具有寻求澄清能力的模型在面对模糊要求时表现得更可靠，从而提高了代码生成任务的整体质量。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.20380", "html_url": "https://arxiv.org/abs/2509.20380", "title": "ACCeLLiuM：基于监督微调的自动OpenACC pragma生成", "title_en": "ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation", "authors": "Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes", "background": "随着图形处理单元（GPU）的广泛应用及其硬件和并行编程框架的日益复杂，基于指令的并行编程标准如OpenACC简化了GPU编程，但仍需要一定的专业知识才能有效使用这些指令。因此，研究者引入了ACCeLLiuM，这是一种特定于大型语言模型（LLM）的工具，旨在根据数据并行循环自动生成专家级别的OpenACC指令，并开发了一个相关的监督微调数据集来训练这些模型。", "innovation": "ACCeLLiuM是一种专为生成专家级别的OpenACC指令设计的大型语言模型，特别适用于数据并行循环。它成功地利用了一个包含了从公共GitHub C/C++存储库中提取的4033对OpenACC pragma的训练数据集。实验证明，使用ACCeLLiuM微调的模型比基础模型更有效，生成正确的OpenACC指令的比例达到87%，并且在整个案例中生成准确指令的比例达到50%。这些模型不仅能在语法上匹配，还能通过不同的顺序或增补额外的指令提供更精细的并行控制，从而增加实际应用价值。", "conclusion": "通过公开发布代码、模型和数据集作为ACCeLLiuM，研究者旨在建立一个可重复的基准测试，评估LLM驱动的OpenACC指令生成，并降低自动GPU卸载序列程序的壁垒。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.20415", "html_url": "https://arxiv.org/abs/2509.20415", "title": "在线优化RAG工具使用与函数调用", "title_en": "Online-Optimized RAG for Tool Use and Function Calling", "authors": "Yu Pan,Xiaocheng Li,Hanzhao Wang", "background": "在许多应用中，检索增强生成（RAG）通过嵌入用户查询并将其与预设的工具或功能描述匹配，从而驱动工具使用和功能调用。然而，在实际应用中，由于嵌入模型不完美或描述不准确，常常会出现嵌入对齐问题，这可能导致检索错误和任务失败。本论文针对这一问题提出了解决方案。", "innovation": "本研究提出了Online-Optimized RAG，这是一种部署时框架，能够通过最小反馈（如任务成功）持续调整实时互动中的检索嵌入。该方法采用轻量级的在线梯度更新，几乎不会增加每次查询的延迟，也不需要对底层的大规模语言模型（LLM）进行任何更改。这种方法既支持单跳和多跳工具使用，也支持动态工具库存和$K$次检索及重新排练。此外，还进行了一种问题特定的理论分析，量化了该方法性能与嵌入初始质量及其他相关因素的关系。", "conclusion": "无论是在工具使用还是文档检索方面，我们的Online-Optimized RAG都能始终如一地提高工具选择的准确性及任务完成的成功率，从而提供了一条通往稳健、自我改进的RAG系统简单实用的道路。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.20421", "html_url": "https://arxiv.org/abs/2509.20421", "title": "形式化验证法律合同：基于翻译的方法（扩展版）", "title_en": "Formal Verification of Legal Contracts: A Translation-based Approach (Extended Version)", "authors": "Reiner Hähnle,Cosimo Laneve,Adele Veschetti", "background": "Stipula 是一种专门用于建模具有可执行属性的法律合同的编程语言，特别是涉及资产转移和义务的部分。这项研究旨在通过将Stipula合同翻译成带有Java Modeling Language注释的Java代码来形式化验证Stipula合同的正确性，使用了演绎验证工具KeY作为验证后端。对于大部分没有交叉循环的Stipula合同，整个验证过程是完全自动化的。这项工作的目的是证明通用的演绎验证工具可以成功地应用于翻译方法中，从而确保法律合同的正确性和可执行性。", "innovation": "提出了一种将Stipula合同翻译成带有Java Modeling Language注释的Java代码的方法，并使用KeY工具进行形式化验证。这种翻译和验证的方法是完全自动化的，特别是在处理没有交叉循环的Stipula合同时。这一创新方法展示了演绎验证工具在翻译方法中的有效性，进一步提高了法律合同的可靠性和可执行性。", "conclusion": "通过应用通用的演绎验证工具KeY于翻译方法中，成功实现了大部分Stipula合同的自动形式化验证，证明了这种方法在法律合同建模和验证中的有效性和实用性。这一研究为法律合同的形式化验证提供了一种新的方法，具有重要的理论和实践意义。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.11480", "html_url": "https://arxiv.org/abs/2505.11480", "title": "SuperCoder: 使用大型语言模型进行汇编程序超优化", "title_en": "SuperCoder: Assembly Program Superoptimization with Large Language Models", "authors": "Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken", "background": "超优化是指将程序转化为一个更快的版本，同时保持其输入输出行为。本文研究大型语言模型（LLMs）是否能作为超优化器，生成比工业标准编译器已优化过的代码更优的汇编程序。为此，作者构建了首个大规模基准测试，包括8,072个真实世界中的汇编程序，与先前数据集中仅包含2-15条直线且无循环的程序相比，更具代表性和复杂性。论文评测了23个LLMs在该基准测试上的表现，结果显示，最强基线Claude-opus-4的测试通过率为51.5%，平均加速比为1.43倍，相比于gcc -O3优化级别。为了提高性能，作者通过强化学习微调了模型，优化了一个结合正确性和性能提升的奖励函数。从Qwen2.5-Coder-7B-Instruct模型（61.4%正确率，1.10倍加速）经过微调后，产生了名为SuperCoder的模型，其正确率为95.0%，平均加速比为1.46倍。", "innovation": "1. 构建了首个大规模的用于汇编程序超优化的基准测试集。\n2. 通过强化学习微调模型，优化了一个结合正确性和性能的奖励函数。\n3. 首次证明LLMs可以作为汇编程序的超优化器，为程序性能优化的研究提供了新的方向。", "conclusion": "本文的研究结果首次表明，LLMs可以应用于汇编程序的超优化，并为程序性能优化的研究奠定了基础，未来的研究可以超越传统的编译器启发式技术，进一步探索语言模型在程序优化中的作用。"}
{"llm_update_time": "20250929", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.15815", "html_url": "https://arxiv.org/abs/2509.15815", "title": "基于GPU温度模拟的车载深度学习框架测试方法", "title_en": "GPU Temperature Simulation-Based Testing for In-Vehicle Deep Learning Frameworks", "authors": "Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen", "background": "深度学习模型在自动驾驶系统中发挥着重要作用，支持诸如环境感知等关键功能。为了加速模型推理，这些深度学习模型的部署依赖于汽车深度学习框架，例如Apollo中的PaddleInference和AutoWare中的TensorRT。然而，不同于在云上部署深度学习模型，汽车环境会经历极端的温度变化，从-40°C到50°C。这种温度变化显著影响GPU的温度，而计算时产生的热量也会进一步增加GPU的温度。这些温度波动导致通过DVFS等机制动态调整GPU频率。然而，现有的汽车深度学习框架设计时并未考虑温度引起的频率变化的影响，在这种温度变化的GPU上部署时会出现关键的质量问题：计算密集型操作遇到延迟或错误，高/混合精度操作出现精度错误，时间序列操作遭受同步问题。现有深度学习框架的测试方法未能识别这些质量问题，因为它们忽略了温度对深度学习框架质量的影响。为填补这一空白，提出了一种名为ThermalGuardian的新型测试方法，专门针对温度变化的环境进行测试。ThermalGuardian根据温度敏感操作生成测试输入模型，基于冷却定律模拟GPU温度波动，并根据实时GPU温度控制GPU频率。", "innovation": "提出了一种名为ThermalGuardian的新型测试方法，专门针对温度变化的环境进行测试。ThermalGuardian利用温度敏感的模型变异规则生成测试输入模型，基于冷却定律模拟GPU温度波动，并根据实时GPU温度控制GPU频率。这种方法填补了现有深度学习框架的温度影响测试空白，确保在温度波动大的汽车环境中实现高质量的部署和运行。", "conclusion": "ThermalGuardian是一种专门为温度变化的车载环境设计的深度学习框架测试方法。通过这种方法，可以在GPU温度波动较大的情况下，确保深度学习模型的高质量部署和运行，从而解决现有方法忽略温度对系统质量影响的问题。"}
