{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09182", "html_url": "https://arxiv.org/abs/2601.09182", "title": "LLM辅助同行评审的立场：通过指导和反馈缓解评审员缺口", "title_en": "Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback", "authors": "JungMin Yun,JuneHyoung Kwon,MiHyeon Kim,YoungBin Kim", "background": "人工智能研究的迅速扩展加剧了评审员缺口问题，威胁到同行评审的可持续性，并导致低质量的评价循环。", "innovation": "提出了一种以人为本的方法，包括：（i）LLM辅助的导师系统，旨在培养评审员长期的专业能力；（ii）LLM辅助的反馈系统，帮助评审员改进评审质量。这种方法旨在增强评审员的专业能力，并有助于构建更可持续的学术生态系统。", "conclusion": "本论文建议LLM应作为帮助和教育人类评审员的工具，强调以人类为中心的方法在构建可持续学术生态系统中的重要作用。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09032", "html_url": "https://arxiv.org/abs/2601.09032", "title": "代理能力的层次结构：在现实的RL环境中评估前沿模型", "title_en": "The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments", "authors": "Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen", "background": "大型语言模型（LLM）代理的发展使AI评估从单轮响应评估转变为在交互环境中多步骤任务完成的评估。本文通过在Surge提供的现实电子商环境中的150项职场任务上对前沿AI模型进行实证研究，探索了代理能力层次结构，为实际部署提供了评估标准。", "innovation": "文章提出了一个基于现实的电子商环境中的实证研究，揭示了代理能力的层次结构；引入了一种任务导向的设计方法；对弱模型和强模型的表现进行了详细分析，探讨了这些发现对代理开发的影响。", "conclusion": "当前前沿模型虽然能够展示连贯的多步骤行为，但在现实职场场景中的任务完成方面仍存在重大能力差距。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08950", "html_url": "https://arxiv.org/abs/2601.08950", "title": "ConvoLearn：基于建构主义的辅导生对话数据集", "title_en": "ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue", "authors": "Mayank Sharma,Roy Pea,Hari Subramonyam", "background": "在教育应用中，大语言模型（LLMs）存在一些基本的教育局限性，如倾向于直接提供答案而非支持对话式学习。为了克服这些局限，作者引入了一个名为ConvoLearn的数据集，该数据集基于知识建构理论，并具体化了六个核心的教育维度：认知参与、形成性评估、责任感、文化响应性、元认知以及权力动态。", "innovation": "ConvoLearn数据集包含1250个模拟的师生对话，每对对话有20个回合，通过受控方式由真人教师与模拟学生交互创建。作者使用QLoRA技术展示了训练在此数据集上的LLM能够在行为上更倾向于知识建构策略。人工评估显示，通过微调得到的Mistral 7B相较于基线版本和Claude Sonnet 4.5版本表现更好。", "conclusion": "这项工作为未来建构主义AI辅导框架的发展和评估提供了潜在的指导架构。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09072", "html_url": "https://arxiv.org/abs/2601.09072", "title": "临床预测模型的人工智能共设计", "title_en": "Human-AI Co-design for Clinical Prediction Models", "authors": "Jean Feng,Avni Kothari,Patrick Vossler,Andrew Bishara,Lucas Zier,Newton Addo,Aaron Kornblith,Yan Shuo Tan,Chandan Singh", "background": "临床预测模型（CPMs）的传统开发需要临床专家、数据科学家和信息技术专家之间的迭代合作，这个过程虽然能细化模型构建的关键细节，但极其耗时和资源密集，导致只有很少一部分CPMs能实际应用于临床。尤其是在团队试图整合大量未结构化的临床记录时，这一挑战更为突出。因此，需要一种新的方法来加速和优化CPM的开发过程。", "innovation": "HACHI是一种迭代的人工智能辅助框架，通过利用AI代理快速探索和评估临床记录中的潜在概念，再由临床专家和领域专家提供反馈来改进模型的学习过程，从而加速开发具有解释性的CPMs。HACHI使用简单的是非问题来定义概念，这有助于临床AI团队在每轮中透明地审查、改进和验证CPMs。HACHI在两个实际预测任务中优于现有方法，揭示了新的临床相关概念，并提高了模型在不同临床地点和时间范围内的泛化能力。", "conclusion": "HACHI强调了临床AI团队在概念探索和模型改进中的关键作用，不仅可以指导AI代理探索新的概念，还可以调整概念的粒度，改变目标函数以更好地与临床目标一致，并识别数据偏差和泄漏问题。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09097", "html_url": "https://arxiv.org/abs/2601.09097", "title": "编程超越思考：高效稳健的多约束规划", "title_en": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning", "authors": "Derrick Goh Xin Deik,Quanyu Long,Zhengyuan Liu,Nancy F. Chen,Wenya Wang", "background": "多约束规划涉及识别、评估并改进候选计划，同时满足多个可能相互冲突的约束条件。现有的大型语言模型（LLM）方法在这个领域存在根本局限性。单纯的推理方法依赖于长时间的自然语言链，容易出现不一致性、错误累积和成本过高的问题。相反，将LLM与编程或求解器策略结合的方法缺乏灵活性：它们往往从头开始生成特定问题的代码或依赖固定的求解器，无法适应多种问题的一般逻辑。", "innovation": "为了应对这些挑战，该研究引入了可扩展代码规划引擎（SCOPE），一种将查询特定的推理与通用代码执行分离的框架。通过将推理与执行分离，SCOPE生成了一致、确定性且可在查询之间重用的求解函数，仅需要对输入参数进行少量修改。SCOPE在性能、成本和延迟方面都达到了最新技术水平。例如，使用GPT-4o时，它在TravelPlanner上的成功率达到93.1%，相比最佳基线（CoT）提高了61.6%，同时降低了1.4倍的推理成本和约4.67倍的时间。", "conclusion": "SCOPE通过将查询特定的推理与通用代码执行分离，有效地解决了多约束规划中的挑战。该方法不仅提高了性能，还在成本和延迟方面实现了显著改进，为解决复杂问题提供了一种有效且稳健的方法。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08988", "html_url": "https://arxiv.org/abs/2601.08988", "title": "ART: 行动基于推理任务基准测试用于医疗AI代理", "title_en": "ART: Action-based Reasoning Task Benchmarking for Medical AI Agents", "authors": "Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji", "background": "可靠的临床决策支持需要能够进行安全的、多步逻辑推理并处理结构化电子健康记录(EHR)的医疗AI代理。虽然大型语言模型（LLMs）在医疗领域表现良好，但现有的基准测试未能充分评估涉及阈值评估、时间聚合和条件逻辑的行动任务性能。通过分析现有基准测试，我们确定了三项主要的错误类别：检索失败、聚合错误和条件逻辑误解。我们的四阶段管道—情景识别、任务生成、质量审核和评估—生产了多样的、基于真实患者数据的临床验证任务。", "innovation": "我们提出了ART（行动基于推理任务基准），它是针对医疗AI代理的一种新基准测试。ART从真实世界EHR数据中挖掘，创建了挑战性的任务，针对已知的推理弱点。ART通过对现有基准的分析，确定了三种主要的错误类别，并且采用了一种四阶段的管道来产生多样化的、临床验证的任务。这种基准测试通过暴露行动导向的EHR推理中的失败模式，推动实现更可靠的临床代理。", "conclusion": "评估GPT-4o-mini和Claude 3.5 Sonnet在600个任务上的结果显示，经过提示优化后接近完美的检索性能，但在聚合和阈值推理方面仍然存在显着差距。通过ART基准，暴露了行动导向的EHR推理中的失败模式，这为开发可靠的临床代理提供了必要的步骤，这些代理可以减轻认知负担和行政负担，支持高需求护理环境中的人力资源能力。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09113", "html_url": "https://arxiv.org/abs/2601.09113", "title": "人工智能海马体：我们离人类记忆还有多远？", "title_en": "The AI Hippocampus: How Far are We From Human Memory?", "authors": "Zixia Jia,Jiaqi Li,Yipeng Kang,Yuxuan Wang,Tong Wu,Quansen Wang,Xiaobo Wang,Shuyi Zhang,Junzhe Shen,Qing Li,Siyuan Qi,Yitao Liang,Di He,Zilong Zheng,Song-Chun Zhu", "background": "记忆在增强现代大型语言模型和多模态大型语言模型的推理、适应性和上下文可靠性方面发挥着基础性作用。随着这些模型从静态预测器转变为主要具备连续学习和个人化推理能力的互动系统，内存机制的融入已成为其架构和功能演变中的关键主题。本文综述了记忆在大型语言模型和多模态大型语言模型中的应用，从隐式、显式和自治型记忆三大范式对文献进行了系统的分类。文章详细阐述了三种主要的内存框架：隐式记忆涵盖面向预训练变压器的嵌入式知识，包括记忆、关联检索和上下文推理能力；显式记忆涉及外部存储和检索组件，通过动态、可查询的知识表示来增强模型输出，使信息源的交互具备可扩展性和可更新性；自治型记忆则包括持久时间内延的记忆结构，有助于多智能体系统中的长期规划、自我连贯性和协作行为。此外，该综述还探讨了多模态设置中内存的整合，强调视觉、语言、音频和动作等模态的连贯性问题。", "innovation": "本文综述了三种主要的内存框架：隐式记忆、显式记忆和自治型记忆，并对文献进行了系统的分类和分析，涵盖了内存嵌入、动态查询知识表示以及持久型长期记忆结构等方面的研究进展。文章不仅讨论了当前的架构进步和基准任务，还指出了跨系统的兼容性、事实一致性等开放性挑战。", "conclusion": "该综述为未来研究提供了指导，指出现有模型在记忆容量、对齐、事实一致性等方面仍面临诸多挑战，建议未来研究需要关注多模态整合、跨系统兼容性等问题，以推动内存机制在大型语言模型和多模态大型语言模型中的进一步发展。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09152", "html_url": "https://arxiv.org/abs/2601.09152", "title": "隐私Reasoner：大规模语言模型能否模拟人类般的隐私思维？", "title_en": "PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?", "authors": "Yiwen Tu,Xuan Liu,Lianhui Qin,Haojian Jin", "background": "本文介绍了PRA，一种用于模拟个人用户在面对真实世界新闻时形成隐私顾虑方式的人工智能代理设计。PRA超越了总体情感分析，结合隐私和认知理论，基于个人评论历史和情境提示模拟具体用户的隐私推理。代理重建每个用户的‘隐私思维’，通过模拟有限理性的情境过滤器动态激活相关隐私记忆，并生成反映用户可能对新隐私情景的反应的合成评论。", "innovation": "PRA创新性地结合了隐私理论和认知理论，能够在详细的个人和情境层面上进行隐私推理模拟。此外，还使用了一个LLM-as-a-Judge评估器，对生成的推理进行量化评价，并通过现实世界的数据实验展示了其在隐私注意力预测上的优越性和跨领域的适应性。", "conclusion": "PRA在现实世界 Hacker News 讨论中的实验结果表明，它远超基线代理在隐私顾虑预测任务中的表现，并且能够捕捉到可跨领域移植的推理模式，包括AI、电子商务和医疗保健领域。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09100", "html_url": "https://arxiv.org/abs/2601.09100", "title": "DScheLLM：通过细调双系统大型语言模型实现动态调度", "title_en": "DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model", "authors": "Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv", "background": "生产调度对动态干扰非常敏感，如加工时间的变化、机器可用性的改变以及意外任务的插入。传统的调度方法通常依赖于特定事件的模型和明确的分析公式，这限制了它们在面对前所未见的干扰时的适应性和泛化能力。", "innovation": "本文提出了一种动态调度方法DScheLLM，该方法利用了根据运营研究解算器获得的精确调度生成双向推理（快慢系统）架构中微调的大型语言模型。这种方法构建了一个统一的基于大型语言模型的框架来处理动态事件，并使用LoRA在混合推理框架下微调Huawei OpenPangu Embedded-7B模型。实验结果显示，快思模式可以高效生成高质量的调度方案，而慢思模式可以生成解算器兼容的格式良好的决策输入。", "conclusion": "据我们所知，这项工作是最早将大型语言模型应用于动态环境下的车间调度的研究之一，展示了它们在智能和自适应调度优化方面的巨大潜力。"}
{"llm_update_time": "20260116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.09105", "html_url": "https://arxiv.org/abs/2601.09105", "title": "AviationLMM：为航空业设计的大型跨模态基础模型", "title_en": "AviationLMM: A Large Multimodal Foundation Model for Civil Aviation", "authors": "Wenbin Li,Jingling Wu,Xiaoyong Lin.Jing Chen,Cong Chen", "background": "民航是全球运输和贸易的基石，确保其安全、高效以及客户满意度尤为重要。然而，现有的航空人工智能解决方案仍然是孤立和狭窄的，主要集中在单一任务或单一模态上。它们难以整合如语音通信、雷达跟踪、传感器流和文字报告等异构数据，限制了情况意识、适应性和实时决策支持。", "innovation": "本文介绍了AviationLMM的愿景，这是一个针对民航的大型跨模态基础模型，旨在统一民航的异构数据流，并实现理解和推理、生成以及代理应用功能。我们首先识别现有AI解决方案与需求之间的差距。然后描述了模型架构，该架构能够摄入如空地语音、监视、机上遥测、视频和结构化文本等多模态输入，进行跨模态对齐和融合，产生从情况总结、风险警告到预测诊断和多模态事故重现等多样化的输出。", "conclusion": "为了全面实现这一愿景，我们识别了一些亟待解决的关键研究机会，包括数据获取、对齐和融合、预训练、推理、可信度、隐私、对缺失模态的鲁棒性和合成场景生成。通过阐述AviationLMM的设计和挑战，我们旨在推动民航基础模型的进展，并激发统一、可信且隐私保护的民航AI生态系统的协同研究努力。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.03727", "html_url": "https://arxiv.org/abs/2601.03727", "title": "印尼语口吃意识自动语音识别", "title_en": "Stuttering-Aware Automatic Speech Recognition for Indonesian Language", "authors": "Fadhil Muhammad,Alwin Djuliansah,Adrian Aryaputra Hamzah,Kurniawati Azizah", "background": "自动语音识别系统在处理流利口语时取得了显著的性能，但在处理口吃口语时表现仍然逐渐恶化，这种情况在低资源语言如印尼语中尤为明显。由于缺乏专门的数据集，对这一领域的研究收到限制。", "innovation": "本文提出了一种数据增强框架，通过组合规则变换和大型语言模型向流利文本中注入重复和延长，生成合成口吃音频，解决了数据稀缺问题。利用这种合成数据微调预训练的印尼Whisper模型，能够让模型适应口吃的声音模式，无需大规模的真实世界录音资料。", "conclusion": "实验结果表明，通过这种针对性的合成数据增强，系统在处理口吃言语时的识别错误率降低，同时保持流利部分的性能水平，验证了合成数据管道在开发欠代表语言友好语音技术中的有效性。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.07348", "html_url": "https://arxiv.org/abs/2601.07348", "title": "Controlled Self-Evolution for Algorithmic Code Optimization", "title_en": "Controlled Self-Evolution for Algorithmic Code Optimization", "authors": "Tu Hu,Ronghao Chen,Shuo Zhang,Jianghao Yin,Mou Xiao Feng,Jingping Liu,Shaolei Zhang,Wenqi Jiang,Yuqi Fang,Sen Hu,Yi Xu,Huacan Wang", "background": "现有的自进化方法通过迭代的“生成-验证-修正”循环来增强代码生成，但这些方法存在探索效率低的问题。它们无法在有限的预算内找到具有优越复杂度的解决方案，主要是由于初始偏差导致进化被困在解决方案的较差区域，缺乏反馈导向的随机操作以及跨任务经验利用不足。", "innovation": "本文提出了一种名为Controlled Self-Evolution (CSE)的新方法，它包含三个关键组件：多样化规划初始化、遗传进化和层次进化学习记忆。CSE通过生成结构不同的算法策略、采用反馈导向机制以及捕捉跨任务和任务内层次的经验，解决了探索效率低的问题，表现出在不同LLM后端基准上的持续提升和早期迭代的高效性。", "conclusion": "实验结果显示，CSE在EffiBench-X上的一系列基准测试中始终优于所有基准方法，并且从早期迭代开始即保持较高效率并在进化过程中持续改进。源代码已公开发布。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.06037", "html_url": "https://arxiv.org/abs/2601.06037", "title": "TeleMem：构建有长期记忆和多模态能力的自主AI", "title_en": "TeleMem: Building Long-Term and Multimodal Memory for Agentic AI", "authors": "Chunliang Chen,Ming Guan,Xiao Lin,Jiaxu Li,Qiyi Wang,Xiangyu Chen,Jixiang Luo,Changzhi Sun,Dell Zhang,Xuelong Li", "background": "大规模语言模型（LLMs）在许多自然语言处理（NLP）任务中表现出色，但在长时间交互中由于注意力有限，难以处理延伸对话历史。检索增强生成（RAG）方法可以缓解这一问题，但缺乏有效的机制来更新或细化存储的回忆，导致模式驱动的胡言乱语、低效的写入操作，并且不能很好地支持多模态信息。", "innovation": "本文提出了TeleMem，一种统一的长期记忆和多模态记忆系统，通过叙事动态提取维持一致的用户档案，仅保留对话支撑的信息。TeleMem 进一步引入了一种结构化的写入流水线，该流水线能够批量、检索、聚类和巩固记忆条目，显著提高了存储效率，减少了 token 使用量，并加速了记忆操作。此外，通过结合 ReAct 风格的推理，多模态记忆模块使系统具备了观察、思考和行动的闭环过程，从而能够在长时间上下文中准确理解复杂的视频内容。", "conclusion": "实验结果显示，TeleMem 在 ZH-4O 长期角色扮演游戏基准测试中表现出色，相比当前最先进的 Mem0 基线模型，其准确率提高了 19%，token 使用量减少了 43%，速度提升了 2.1 倍。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.13529", "html_url": "https://arxiv.org/abs/2511.13529", "title": "向对话型匈牙利语语音识别迈进：介绍BEA-Large和BEA-Dialogue数据集", "title_en": "Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets", "authors": "Máté Gedeon,Piroska Zsófia Barta,Péter Mihajlik,Tekla Etelka Gráczi,Anna Kohári,Katalin Mády", "background": "自动语音识别（ASR）的进步得益于大量高资源语言的数据集，但像匈牙利语这样的语言由于缺乏自发和对话式语料库而未得到充分代表。因此，现有的语音技术在处理这类语言的对话式语音时仍然面临挑战。", "innovation": "本文提出了两个新的数据集——BEA-Large和BEA-Dialogue，分别包含255小时的自发性语音和85小时的自发对话。这些数据集纠正并扩展了之前未处理的匈牙利语音语料库BEA，具有详细的段级元数据，支持对话ASR和说话人变址的研究。通过使用公开可用的ASR模型，本文建立了可重复的基线，精调后的Fast Conformer模型在自发和重复语音上的词错误率分别低至14.18%和4.8%。此外，通过这些数据集和基线的发布，提高了在其他语言中构建自发和对话基准的方法学框架。", "conclusion": "本文研究成果突显了对话式ASR的持续难题，特别是由于脱节、重叠以及非正式的语音模式。通过提供这些数据集和基线，本文目的是推动匈牙利语音技术的发展，并为其他语言构建自发和对话基准提供方法学框架。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.22313", "html_url": "https://arxiv.org/abs/2511.22313", "title": "使用 DistilBERT 对虾皮产品评论进行情感分析", "title_en": "Sentiment Analysis Of Shopee Product Reviews Using Distilbert", "authors": "Zahri Aksa Dautd,Aviv Yuniar Rahman", "background": "随着数字商务的快速增长，各大在线平台积累了大量的消费者评论。作为东南亚最大的电商平台之一，虾皮每天收到数百万条产品评论，这些评论包含了客户满意度和偏好的大量有价值信息。手工分析这些评论效率低下，因此需要使用如情感分析等计算方法来处理。", "innovation": "本研究使用了一个轻型变体的深度学习模型——DistilBERT，用于分析和分类虾皮产品评论的情感。与基准模型BERT及SVM相比，DistilBERT表现出了更高的准确性（94.8%），虽然略低于BERT（95.3%），但在计算时间上降低了超过55%，且显著高于SVM（90.2%）。", "conclusion": "研究结果表明，DistilBERT在准确性和效率之间达到了最佳平衡，使其成为大规模电商平台上情感分析的理想工具。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.16682", "html_url": "https://arxiv.org/abs/2511.16682", "title": "Bench360: 从全方位评估本地LLM推理", "title_en": "Bench360: Benchmarking Local LLM Inference from 360 Degrees", "authors": "Linus Stuhlmann,Mauricio Fadel Argerich,Jonathan Fürst", "background": "本地运行大型语言模型（LLM）变得越来越普遍，但用户面临复杂的模型、量化级别、推理引擎和服务场景的设计空间。现有推理基准分散并且仅关注孤立目标，缺乏实际部署的指导。现有的基准测试在评估单一目标或特定方面有效，未能提供全面的综合评估。", "innovation": "提出了Bench360框架，能够在同一平台下评估本地LLM推理任务、使用模式和系统指标。Bench360支持自定义任务、集成多种推理引擎和量化格式，并报告任务质量和系统行为（如延迟、吞吐量、能量消耗和启动时间）。通过在四个NLP任务和三种GPU及四种引擎上的测试，展示了设计选择如何影响效率和输出质量，结果表明存在显著权衡，并且配置选择依赖于特定工作负载和约束条件。没有一种普遍适用的最佳方案。", "conclusion": "需要全面、面向部署的基准测试来更好地理解设计决策如何影响效率和输出质量。Bench360为研究者和从业者提供了一个强大的工具来优化本地LLM部署。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07801", "html_url": "https://arxiv.org/abs/2512.07801", "title": "协作因果感知：人类-人工智能决策支持中的互补性差距闭合", "title_en": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support", "authors": "Raunak Jain,Mudita Khurana", "background": "基于LLM的代理正越来越多地部署以支持专家决策，但在关键情况下的人机团队尚未可靠地超越个人。作者认为这种互补性差距反映了一种根本性的不匹配：当前的代理是作为答案引擎而不是作为协作感知过程中的合作伙伴来培训的，这是专家实际做出决策的过程。感知（集体构建因果解释、揭示不确定性并将目标适应变化的能力）是当前培训管道没有明确开发或评估的关键能力。当前的人机团队合作感知能力不足。", "innovation": "提出了一种名为协作因果感知（CCS）的研究议程，以从根源培养这一关键能力，涵盖新的促进协作思考的训练环境、用于共享人-机思维模型的表示以及以信任和互补性为中心的评估。这些方向将MAS研究从构建类似预言机的答案引擎转向培养能够与人类伙伴共同推理的AI队友，从而促进了有效的人机团队的设计。", "conclusion": "这些途径将促使MAS研究从构建类似预言机的答案引擎转向培养能够与其人类伙伴共同推理实现共享决策因果结构的AI队友，从而推进有效的人机团队设计。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05699", "html_url": "https://arxiv.org/abs/2601.05699", "title": "Afri-MCQA: 多模态文化问答数据集为非洲语言", "title_en": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages", "authors": "Atnafu Lambebo Tonja,Srija Anand,Emilio Villa-Cueva,Israel Abebe Azime,Jesujoba Oluwadara Alabi,Muhidin A. Mohamed,Debela Desalegn Yadeta,Negasi Haile Abadi,Abigail Oppong,Nnaemeka Casmir Obiefuna,Idris Abdulmumin,Naome A Etori,Eric Peter Wairagala,Kanda Patrick Tshinu,Imanigirimbabazi Emmanuel,Gabofetswe Malema,Alham Fikri Aji,David Ifeoluwa Adelani,Thamar Solorio", "background": "非洲拥有世界上超过三分之一的语言，但在人工智能研究中却严重不足代表。现有的多语言文化问答基准大多忽视了非洲语言和文化的具体需求。", "innovation": "提出了Afri-MCQA，这是第一个覆盖12个国家15种非洲语言的多模态文化问答基准。它包含7500多对问题-答案，并提供跨文本和语音模态的英非语言平行Q&A对，全部由原住民创建。研究表明，现有开源模型在跨文化和开放型视觉问答任务中的表现不佳，尤其是在用本地语言或语音查询时。”这些发现突显了评估语言能力和文化背景的具体需求，以及需要语言第一的方法、文化根基预训练和跨语言文化转移。", "conclusion": "为了推动非洲语言的包容性多模态AI发展，Afri-MCQA将学术许可或CC BY-NC 4.0协议在HuggingFace上开源发布。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.16401", "html_url": "https://arxiv.org/abs/2512.16401", "title": "导航现实差距：用于临床电话的隐私保护设备持续自适应ASR", "title_en": "Navigating the Reality Gap: Privacy-Preserving On-Device Continual Adaptation of ASR for Clinical Telephony", "authors": "Darshil Chauhan,Adityasinh Solanki,Vansh Patel,Kanav Kapoor,Ritvik Jain,Aditya Bansal,Pratik Narang,Dhruv Kumar", "background": "自动语音识别（ASR）在临床记录和患者报告生成方面具有极大的潜力，特别是在资源受限的地区。然而，由于实验室环境和实际临床环境间的巨大差距，且具有严格的隐私和资源限制，导致其当前应用受阻。这意味着ASR系统在临床电话系统中应用时，用户的言语具有高度变异性，语音识别错误将直接影响下游临床流程，因此适应性变得尤为重要。", "innovation": "该研究提出了一种基于低秩适应（LoRA）的隐私保护设备持续自适应框架，成功地在印度农村临床电话对话中保持了多语言模型（IndicWav2Vec）的性能。此外，研究发现多域经验重放（ER）策略为主要的性能提升策略，实现了17.1%的目标识别错误率的相对改进，并减少了55%的灾难性遗忘现象。还设计了一种稳定的重要估计策略（绝对费舍尔）来确保在临床电话语音中高方差梯度收敛的稳健性。", "conclusion": "语音适应是医疗保健环境中可使用性的基本前提，语言模型本身无法绕过这一要求。通过多领域经验回放和稳定的重要估计策略，该研究证明了在临床电话应用中的自适应改进是可行且有效的，从而推进ASR系统在医疗保健中的实际应用。"}
{"llm_update_time": "20260116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.13467", "html_url": "https://arxiv.org/abs/2511.13467", "title": "非线性评分模型在翻译质量评估中的应用", "title_en": "Non-Linear Scoring Model for Translation Quality Evaluation", "authors": "Serge Gladkoff,Lifeng Han,Katerina Gasova", "background": "传统的翻译质量评估(TQE)基于多维质量指标(MQM)，使用线性误差到处罚比例尺进行评分，通常针对1000-2000字的参考样本进行校准。然而，这种线性评估方法在不同长度样本上产生偏差，对短样本过度惩罚，对长样本则欠惩罚，导致与专家直觉产生偏差。", "innovation": "本文基于多范围框架，提出了一种非线性评分模型，该模型更好地反映了不同长度样本上人类内容消费者的翻译质量感知。通过三个大规模企业环境的数据实验证明，接受的错误数量随样本大小呈对数增长，而非线性增长。本文还提出了一个基于两个耐受度点的可调节双参数模型E(x) = a * ln(1 + b * x)，a, b > 0，该模型确保线性近似在相对误差±20%范围内，同时仅需动态调整耐受函数即可与现有评估流程集成。", "conclusion": "非线性评分模型提高了人类和AI生成文本翻译评估的可解释性、公平性和重评分者一致性。通过实现感知有效的评分范式，推动翻译质量评估朝着更准确且可扩展的评价发展。该模型还为AI驱动的文档级评估提供了更贴近人性判断的基础。最后，提出了CAT/LQA系统实施考虑及对人类和AI生成文本评估的影响。"}
