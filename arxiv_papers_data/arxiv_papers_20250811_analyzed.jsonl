{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05855", "html_url": "https://arxiv.org/abs/2508.05855", "title": "体态导航的安全性：综述", "title_en": "Safety of Embodied Navigation: A Survey", "authors": "Zixia Wang,Jia Hu,Ronghui Mu", "background": "随着大型语言模型（LLMs）不断发展并产生重要影响，体态人工智能（embodied AI）的发展速度加快，并引起了广泛关注，特别是在导航场景中。体态导航要求代理在移动到指定目标的同时，感知、交互和适应其环境，尤其是在不熟悉环境中。然而，将体态导航融入关键应用中引发了重大的安全关切。考虑到这些系统部署在动态的现实环境中，确保其安全性至关重要。", "innovation": "本综述全面分析了体态导航的安全性，涵盖了攻击策略、防御机制和评估方法。此外，还探讨了现有安全挑战、缓解技术、数据集和评估指标，以及体态导航安全性中未解决的问题和未来的研究方向。这些包括潜在攻击方法、缓解策略、更可靠的评估技术和验证框架的实现。", "conclusion": "通过解决这些关键性缺口，本文旨在为未来研究提供有价值的观点，以指导开发更安全、更可靠的体态导航系统。此外，这些研究结果对提高社会安全和增加工业效率具有更广泛的影响。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05776", "html_url": "https://arxiv.org/abs/2508.05776", "title": "在先进神经网络时代符号何去何从？", "title_en": "Whither symbols in the era of advanced neural networks?", "authors": "Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb", "background": "人类思维应该用符号系统来思考的最强有力证据之一是其能够结合思想、产生新颖思想以及快速学习的能力。论文指出，现代神经网络及其构建的人工智能系统展示了类似的能力。这削弱了人们的观点，即人类的认知过程和表征一定是符号性的，但这些神经网络通常通过符号系统生成的数据进行训练的事实说明，这类系统在表征人类思维必须解决的抽象问题上起着重要作用。因此，此研究目标是探索符号基础在人类思想中的新研究议程。", "innovation": "论文提出了现代神经网络展示了类似于人类思维结合思想、产生新颖性以及快速学习的能力，质疑传统观点认为人类的认知过程和表征是符号性的，并提出了新的研究议程来探讨人类思想的符号基础。", "conclusion": "尽管神经网络是通过符号系统生成的数据训练的，这表明符号系统在表征这些网络必须解决的抽象问题中起重要作用，但神经网络自身的运作挑战了人类思维基于符号这一传统观点，呼吁新的研究议程以探索人类思想符号基础的新方向。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06042", "html_url": "https://arxiv.org/abs/2508.06042", "title": "心智社会理论与实时策略游戏的战略推理：一种分层多智能体框架", "title_en": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "authors": "Daechul Ahn,San Kim,Jonghyun Choi", "background": "大型语言模型（LLMs）在行动序列预测方面表现出色，但在如实时战略游戏这类动态、长期的任务方面存在挑战。例如，在《星际争霸II》中，智能体需要在部分可观测的环境中管理资源约束并适应不断变化的战场情况。现有基于LLM的方法往往无法应对这些挑战。", "innovation": "文章提出了一种基于分层多智能体框架的Socooi机制，该机制通过使用分层控制（一个称为战略规划者SP的元控制器）将专家演示中特定智能体各自学习的独特策略进行协调，生成具有长期适应性的行动计划。通过分层模仿机制，每个特定智能体都被训练以执行特定的战略任务，如空中支援或防御性战术，并生成连贯且结构化的多步行动序列。", "conclusion": "实验结果表明，HIMA在战略清晰度、适应性和计算效率方面优于现有方法，证明了将专门模仿模块与元级协调相结合可以开发出更为稳健和通用的AI代理。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05996", "html_url": "https://arxiv.org/abs/2508.05996", "title": "由调解者引导的开源模型之间的多agent协作在医疗决策中的应用", "title_en": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "authors": "Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang", "background": "复杂的医疗决策需要不同的临床专家协作完成，设计基于AI的多agent系统可以加速和增强人类级别的临床决策。现有的多agent研究主要集中在语言任务上，但将它们扩展到多模态场景仍然具有挑战性。简单组合多种视觉-语言模型（VLM）可能会放大错误的结果解释。VLM在指导和自我反思方面的能力普遍不如同等规模的大语言模型（LLM），这限制了它们在协作流程中的能力。", "innovation": "本文提出MedOrch，一个由调解者引导的多agent协作框架，用于医疗多模态决策。MedOrch利用基于LLM的调解者代理，使多个基于VLM的专业代理能够交换和反思其输出以实现协作。我们使用多个开源通用和专业领域的VLM代替昂贵的GPT系列模型，展示了异构模型的优势。实验证明，不同VLM代理之间的协作可以超越任何单个代理的能力。我们在五个医疗视觉问答基准上验证了我们的方法，显示出卓越的协作性能而无需模型训练。研究表明，调解者引导的多agent协作对于促进医疗多模态智能具有价值。", "conclusion": "我们的研究结果强调了在医疗多模态智能发展中，调解者引导多agent协作的价值。我们的代码将公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05888", "html_url": "https://arxiv.org/abs/2508.05888", "title": "企业任务规划中的自我旅行：利用混合自我图集提高工具检索", "title_en": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "authors": "Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber", "background": "AI代理在识别和计划复杂用户查询下的行动时，需要从大量工具中进行有效的选择。传统方法主要依赖用户查询与工具描述之间的相似性，这在处理多步骤用户请求时限制了检索准确度。研究文献对此方面的探索相对不足。因此，需要一种新的工具检索框架来提高多步骤任务中的工具选择准确性，更好地捕捉工具之间的语义关系及其功能依赖关系。", "innovation": "提出了基于知识图谱（KG）的工具检索框架，利用1跳自我工具图的集成模型来建模工具之间的直接和间接连接，从而实现更全面和上下文相关的工具选择。该框架在合成生成的内部数据集上进行了评估，该数据集包括六个定义的用户类别，相较于非KG基线，该方法实现了91.85%的工具覆盖率，显著优于传统的语义-词汇混合检索方法。", "conclusion": "研究表明，在使用微平均完全召回度量的工具图方法中，所提出的方法对比于重新排序的语义-词汇混合检索基线提高了1.59%的工具覆盖率。这支持了我们提出的假设，即知识图谱中的结构性信息为纯粹的相似性匹配提供了补充信号，尤其在需要顺序工具组合的查询中。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05766", "html_url": "https://arxiv.org/abs/2508.05766", "title": "通过语言中介的主动推理实现内在安全的AGI框架", "title_en": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "authors": "Bo Wen", "background": "传统的AI安全方法集中在事后可解释性和奖励工程上，存在根本性的局限性。该研究通过将主动推理原则与大型语言模型（LLMs）结合，提出了一个新颖的框架，旨在开发更安全的人工通用智能（AGI）系统。这些传统方法的局限性促使研究者寻求一种新的安全框架，该框架能够将安全保证集成到系统的核心技术设计中，通过透明的信念表示和分层价值对齐来实现。", "innovation": "该框架通过自然语言作为表示和操作信念的媒介，实现了直接的人类监控，同时保持了计算可操作性。它采用了多智能体系统，各智能体根据主动推理原则自我组织，偏好和安全约束通过分层马尔可夫毯传递。该框架特别强调确保安全的机制，包括在自然语言中明确分离信念和偏好、基于资源感知的自由能最小化实现的有界理性，以及通过模块化智能体结构实现的组合安全性。一种新的研究议程集中在抽象与推理语料库（ARC）基准上，旨在验证该框架的安全特性。", "conclusion": "该研究提出了一个发展内在更安全的AGI的方法，这个框架能够在开发阶段就内嵌进安全性考虑，而不是仅仅在事后加装安全措施。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05792", "html_url": "https://arxiv.org/abs/2508.05792", "title": "整体可解释AI（H-XAI）：在AI驱动决策中超越开发者的透明度", "title_en": "Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making", "authors": "Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava", "background": "当前的可解释AI（XAI）方法主要服务于开发人员，往往侧重于合理化模型输出，而不是满足多元利益相关者的需求。最近，评估型AI将解释重新定义为用于假设检验的工具，但仍然主要关注运营组织。现有XAI方法未能充分支持多元利益相关者的多种需求。", "innovation": "本文介绍了一种名为总体可解释AI（H-XAI）的统一框架，该框架将因果评分方法与传统XAI方法相结合，以支持解释作为一个互动、多方法的过程。H-XAI使利益相关者能够提出一系列问题、测试假设，并将模型行为与自动构造的随机和有偏比较基线进行对比。它结合了实例级和全局解释，根据不同利益相关者的目标进行调整，无论是理解个别决策、评估团体层面的偏差，还是评估在扰动下的稳健性。通过两个案例研究，涵盖六个场景，证明了H-XAI方法的普遍性。", "conclusion": "H-XAI通过结合因果评分和事后解释，在个体决策水平和整体模型水平回答特定利益相关者的问题，填补了现有XAI方法的关键空白。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05731", "html_url": "https://arxiv.org/abs/2508.05731", "title": "InfiGUI-G1: 通过自适应探索策略优化提升GUI定位", "title_en": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "authors": "Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu", "background": "多模态大型语言模型（MLLMs）的发展推动了能够基于纯视觉输入在图形用户界面（GUI）上操作的自主代理的发展。一个核心挑战是如何准确地将自然语言指令与GUI元素进行对接。实现这一点需要精确的空间对齐以及正确的语义对齐。尽管可验证奖励强化学习（RLVR）在提高MLLMs的空间对齐方面被证明是有效的，但我们发现其在语义对齐方面存在效率瓶颈，阻碍了模型学习复杂的语义关联。", "innovation": "提出了自适应探索策略优化（AEPO），这是一种新的策略优化框架。AEPO采用多答案生成策略以促进更广泛的探索，并通过基于效率原理的可适应探索奖励函数（AER）进行引导。训练后的InfiGUI-G1-3B和InfiGUI-G1-7B模型在多个具有挑战性的GUI定位基准上创造了新的最佳结果，相较于RLVR基准，在测试泛化能力和语义理解的基准中取得了高达9.0%的显著相对改进。相关资源可从提供的链接中获取。", "conclusion": "AEPO在多个具有挑战性的GUI定位基准测试中表现出色，超过了RLVR基准，并在泛化能力和语义理解方面取得了显著的相对改进，是对此领域的有益贡献。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06062", "html_url": "https://arxiv.org/abs/2508.06062", "title": "不要忘记想象力！", "title_en": "Don't Forget Imagination!", "authors": "Evgenii E. Vityaev,Andrei Mantsivoda", "background": "认知想象力在人类思维中扮演着关键角色，它并不是脑海中图像化的想象，而是能够将概念和因果关系可视化为连贯且整体的概念系统，这些系统构成了推理、决策和预测的意义背景。然而，认知想象力的重要性仍然被大大低估了，这导致了诸多问题并削弱了当前的人工智能能力。例如，在推理时，人类依赖于想象的背景来获取相关信息，并不断返回这个背景进行语义验证，以确保推理仍然合理。没有想象力的帮助，推理将会是盲目的。因此，本文呼吁关注认知想象力，将其作为未来人工智能研究的关键突破点。", "innovation": "本文提出了语义模型作为模拟认知想象力的一种新方法。语义模型的设计目的是像神经网络那样能够学习，并基于概率因果关系。语义模型通过确保想象背景的一致性，并采用透明箱的方式，使背景可以作为一个整体和连贯的事实系统进行操作，以遵循因果关系的联系。", "conclusion": "本文强调认知想象力的重要性，并提出使用语义模型来模拟这一功能，以此作为人工智能研究的下一次突破。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06060", "html_url": "https://arxiv.org/abs/2508.06060", "title": "大语言模型用于资源分配：一种推断偏好的人类参与预算方法", "title_en": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences", "authors": "Sankarshan Damle,Boi Faltings", "background": "大语言模型（LLMs）越来越多地被期望处理复杂的决策任务，然而，它们在执行结构化资源配置方面的能力尚未充分探索。现有基准的静态性质以及数据污染使得评定其推理能力变得困难。", "innovation": "本文提出了一种双用途框架，利用参与预算（PB）作为（i）基于LLM的资源配置的实际环境和（ii）评估其推理能力的自适应基准。该框架通过三种提示策略（贪婪选择、直接优化和基于爬山法的改进）来要求LLM在可实现（例如，预算）约束下选择项目子集。实验对比了LLMs的分配与最大化效用的对照组，并考察LLMs能否从自然语言投票输入或元数据中推断出结构化的偏好，而不是显式的投票。通过对比基于推断偏好和基于真实投票的分配，评定了LLMs从开放输入中提取偏好能力。", "conclusion": "本文的研究结果强调了提示设计的重要性，并表明LLMs在具备无结构输入的情况下对于机制设计具有潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06091", "html_url": "https://arxiv.org/abs/2508.06091", "title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2", "title_en": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2", "authors": "Stan P Hauke,Przemysław Andrzej Wałęga", "background": "近年来，人们越来越关注通过将图形神经网络（GNNs）与逻辑语言联系起来来理解其表达能力。Barceló等人（2020）的一项有影响力的结果表明，分级模态逻辑（或逻辑C2的受限片段）可以描述集合聚合GNNs的逻辑表达能力。然而，他们留下了一个具有挑战性的开放问题：完整的C2是否能描述聚合聚合读取GNNs的逻辑表达能力。尽管有几次尝试，这个问题仍未得到解决。", "innovation": "本文通过证明聚合聚合读取GNNs的逻辑表达能力严格超越C2这一结果解决了上述开放问题。这一结果适用于无向图和有向图。除此之外，这项工作还为无穷逻辑的表达能力提供了纯粹的逻辑见解。", "conclusion": "聚合聚合读取GNNs的逻辑表达能力严格超出逻辑C2。这一结论对于GNNs和逻辑学具有重要意义，为理解和提升图神经网络的表达能力提供了新视角。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06225", "html_url": "https://arxiv.org/abs/2508.06225", "title": "LLM-as-a-Judge过信心现象：诊断与基于信心的解决方案", "title_en": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution", "authors": "Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao", "background": "现有的大语言模型（LLMs）作为自动化法官的应用主要集中在准确性上，而忽视了准确的信心校准对可靠性和适应性评价管道的重要性。在实际应用中，过度自信的现象会导致模型评价结果的不可靠。", "innovation": "提出了一种新的度量指标TH-Score来量化过度自信现象，并提出了一种新的框架LLM-as-a-Fuser，通过集成方法将LLM转换为可靠、风险意识强的评价者。该方法显著提高了校准，实现了比现有基线更可靠和准确的评价管道。", "conclusion": "我们的研究从重视准确性的评价转向了信心驱动的、风险意识强的评价框架，强调了正确校准的信心的重要性。通过实验，我们证明了这种方法大大提高了评价的可靠性和准确性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06074", "html_url": "https://arxiv.org/abs/2508.06074", "title": "ME^3-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception", "title_en": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception", "authors": "Siyi Lu,Run Liu,Dongsheng Yang,Lei He", "background": "自动驾驶系统在感知复杂环境和实时决策方面面临重大挑战。传统模块化方法虽然具有可解释性，但存在错误传播和协调问题，而端到端学习系统虽然可以简化设计，但面临着计算瓶颈。", "innovation": "提出了一个利用深度强化学习(DRL)的新型自动驾驶方法，该方法整合了鸟瞰视图(BEV)感知以增强实时决策能力。引入了Mamba-BEV模型，这是一种高效的空间-时间特征提取网络，结合了基于BEV的感知与Mamba框架进行时间特征建模。此外，本文还提出了ME^3-BEV框架，将Mamba-BEV模型用作端到端DRL的特征输入，从而在动态城市驾驶场景中取得了优异性能。通过语义分割可视化高维特征，增强了模型的可解释性。实验证明，ME^3-BEV在多个指标上优于现有模型，包括碰撞率和轨迹精度，展示了在实时自动驾驶中的有前途的解决方案。", "conclusion": "ME^3-BEV框架在端到端的自动驾驶场景中表现出色，并且通过空间-时间特征提取和语义分割的结合，展示了在实时感知和决策中的优势，为自动驾驶提供了一种有前景的解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06110", "html_url": "https://arxiv.org/abs/2508.06110", "title": "PanelTR：通过多智能体科学讨论实现零样本表格推理框架", "title_en": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "authors": "Yiran Rex Ma", "background": "表格推理，包括表格QA和事实验证，通常依赖于标注数据或复杂的数据增强，这限制了灵活性和泛化能力。尽管语言模型（LLMs）具有多功能性，但在性能上往往不如简单的监督模型。", "innovation": "PanelTR 提出一种利用 LLM 代理科学家的框架，通过结构化的科学方法实现鲁棒的表格推理。PanelTR 的工作流包括：代理科学家进行个体调查、自我审查，并参与合作的同行评审讨论。这一过程由五个科学家人像驱动，能够在不依赖数据增强或参数优化的情况下实现语义级别的转移。", "conclusion": "在四个基准上的实验表明，PanelTR 超过了普通的语言模型，并且与完全监督的模型不相上下，同时独立于训练数据。研究结果表明，结构化的科学方法能够有效处理表格推理等复杂任务，并在零样本情况下具备灵活的语义理解能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06111", "html_url": "https://arxiv.org/abs/2508.06111", "title": "SKATE，一种可扩展的比赛评估：较弱的语言模型通过可验证挑战区分较强的语言模型", "title_en": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges", "authors": "Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown", "background": "当前评估大型语言模型（LLM）的能力和风险的方法需要大量的领域专业知识，限制了其可扩展性。这些模型迅速演变，现有的评估方法难以跟上步伐。", "innovation": "SKATE引入了一种新的评估框架，让LLMs通过生成和解决可验证任务来竞争。这一框架将评估视为游戏，提升了评估的可扩展性、开放性和客观性，完全自动化且无需人工输入或专业知识。通过使用可验证任务而非LLM评判，评分更具客观性。不同于领域限制的程序生成基准测试，由LLM创意地提出挑战使评估开放且可扩展。", "conclusion": "SKATE已经通过代码输出预测（COP）挑战对其进行概念验证，并使用基于TrueSkill的排名系统评估了6种先进的LLM。研究发现：较弱的模型可以可靠地区分和评估较强模型；LLM系统有能力自我偏袒，生成与自身能力相匹配的问题；SKATE可以自动揭示模型之间的细微能力差异。这项研究朝着与LLM进展保持一致的通用且可扩展的评估框架迈进了一步。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06145", "html_url": "https://arxiv.org/abs/2508.06145", "title": "全面药物禁忌症检索增强大型语言模型系统", "title_en": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "authors": "Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee", "background": "大型语言模型（LLMs）在各个领域展现了极大的适应性，但在医疗健康领域特别是药品禁忌症方面面临挑战。这些药物禁忌症信息需要高度准确和可靠。本研究旨在通过引入检索增强生成（RAG）流程来提升LLMs在处理药品禁忌症方面的表现，尤其是在针对特定年龄段、妊娠和联合用药的禁忌症方面。", "innovation": "研究采用了OpenAI的GPT-4o-mini作为基础模型，并利用text-embedding-3-small模型进行嵌入，结合Langchain构建了一个包含重新信息检索的混合检索系统。系统利用来自公共数据库的药物利用审查（DUR）数据，特别关注针对特定年龄段、妊娠和联合用药的禁忌症。", "conclusion": "研究结果表明，通过RAG框架增强大型语言模型，能够显著提高模型在药品禁忌症方面的准确性，特别是在针对特定年龄段、妊娠和联合用药的禁忌症方面，准确率分别为0.94、0.87和0.89。这一改进表明，通过RAG框架增强大型语言模型，可以显著减少处方和用药决策中的不确定性，并提供更为精确和可靠的药品禁忌症信息。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06064", "html_url": "https://arxiv.org/abs/2508.06064", "title": "通用完全且可随时使用的束搜索算法以实现最优决策树", "title_en": "A Generic Complete Anytime Beam Search for Optimal Decision Tree", "authors": "Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus", "background": "寻找一个能够最小化分类错误的最佳决策树是已知的NP难题。尽管基于MILP、CP、SAT或动态规划的确切算法能保证最优性，但它们往往存在差的任何时间行为，即在搜索未完成时难以快速找到高质量的决策树。为解决此问题，已提出了诸如LDS-DL8.5、Top-k-DL8.5和Blossom等任何时间扩展的确切方法，但它们尚未系统地进行过比较，因此难以评估它们的相对效果。", "innovation": "本文提出了一种通用、完整且可随时使用束搜索算法CA-DL8.5，该算法扩展了DL8.5框架并统一了现有的任何时间策略。CA-DL8.5通过模块化设计允许使用各种启发式和松弛机制，并重用了DL8.5的高效分支定界剪枝和基于trie的缓存，结合基于重启的束搜索，逐步放宽剪枝标准以随着时间提高解的质量。此外，还引入了新的评估方法——带形隙积分的任何时间评估，来比较不同实例的性能。实验结果显示CA-DL8.5基于LDS策略表现最优，优于其他CA-DL8.5变体和Blossom算法，同时保持完整性和最优性保证。", "conclusion": "通过引入CA-DL8.5，本文提供了一个用于精确和任何时间决策树学习的新通用框架，能够整合不同的启发式和搜索策略。实验表明，CA-DL8.5基于LDS策略具有最优的任何时间性能，优于其他CA-DL8.5变体和Blossom算法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06129", "html_url": "https://arxiv.org/abs/2508.06129", "title": "在制定解决车辆路线问题启发式算法指导策略中稳健特征的研究", "title_en": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem", "authors": "Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux", "background": "车辆路线问题（VRP）是一个复杂优化问题，广泛应用于现实生活中，由于NP难性通常使用元启发式算法求解。传统上，这些元启发式算法依赖于人类设计并经过经验研究开发，而研究表明机器学习方法可以帮助掌握组合优化问题中解结构特征，有助于设计更有效的算法，特别是为求解VRP。基于此，该研究进一步通过使用多个分类器模型进行敏感性分析，以预测VRP解的质量和理解这些模型的决策过程。研究表明，尽管特征重要性有所不同，但有些特征在预测中持续表现突出。", "innovation": "通过利用可解释的人工智能（AI），该研究不仅揭示了某些特征在预测VRP解的质量中持续有重要作用，还提出了一种统合框架，能够跨不同场景下综合评价这些特征的影响，为指导元启发式算法提供了依据。这种见解强调了特征重要性分析作为开发解车辆路线问题的元启发式算法指导机制的基础潜力。", "conclusion": "研究结果表明，尽管特征的重要性不尽相同，但某些特征始终是强有力的预测因子。为更好地理解和指导元启发式算法求解VRP，研究建议采用该统合框架揭示和对比这些特征在不同场景下的影响，从而为优化VRP算法提供指导方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06263", "html_url": "https://arxiv.org/abs/2508.06263", "title": "针对归纳逻辑编程的对称性打破方法", "title_en": "Symmetry breaking for inductive logic programming", "authors": "Andrew Cropper,David M. Cerna,Matti Järvisalo", "background": "归纳逻辑编程的目标是寻找一个能够推广训练数据和背景知识的假设。面临的挑战在于搜索庞大的假设空间，因为许多假设之间存在逻辑等价性，使得搜索复杂度急剧增加。", "innovation": "本文介绍了一种在假设空间中打破对称性的方法。通过在回答集编程中实现这一想法，实验结果表明，这种方法可以显著减少求解时间，从超过一个小时缩短至仅17秒。", "conclusion": "通过引入对称性打破方法，本文提出了一种有效的方法来应对归纳逻辑编程中的挑战，实验表明该方法显著提升了求解效率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06230", "html_url": "https://arxiv.org/abs/2508.06230", "title": "使用最小消息长度学习逻辑规则", "title_en": "Learning Logical Rules using Minimum Message Length", "authors": "Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper", "background": "AI领域中的概率学习和逻辑学习融合是一个关键挑战。本文介绍了一种贝叶斯归纳逻辑规划方法，该方法可以从嘈杂的数据中学习最小消息长度的程序。该方法通过先验和似然性来平衡假设的复杂性和数据拟合度，具体来说，先验明确偏好更一般的程序，而似然性则更偏好准确的程序。该方法已在多个领域（如游戏和药物设计）的实验中进行验证，并显示出显著优于以往学习最小描述长度程序的方法的效果，尤其是在例子平衡问题上的干预期方面表现优异，包括能够从仅有的正例中学习的能力。", "innovation": "提出了贝叶斯归纳逻辑规划方法，从嘈杂数据中学习最小消息长度的程序。该方法通过先验和似然性平衡假设的复杂性和数据拟合度，且先验偏好更一般的程序，而似然性偏好更准确的程序。实验显示该方法显著优于以往方法，尤其在数据效率和对例子平衡不敏感方面具有优势，能够从仅正例中学习。", "conclusion": "本文方法在多个领域实验中表现出色，尤其是在游戏和药物设计领域，显示出显著优于以前的方法，特别是学习最小描述长度程序的方法。该方法的数据效率高，对例子平衡不敏感，甚至可以从单独的正例中学习。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06296", "html_url": "https://arxiv.org/abs/2508.06296", "title": "LLM Robustness Leaderboard v1 --技术报告", "title_en": "LLM Robustness Leaderboard v1 --Technical report", "authors": "Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe", "background": "该技术报告随附PRISM Eval为巴黎AI行动峰会发布的LLM稳健性排行榜发布。报告介绍了PRISM Eval行为诱导工具（BET），这是一种通过动态对抗优化自动红队的AI系统，该系统在41个最先进LLM中有37个达到了100%的攻击成功率。报告还提出了细粒度的稳健性度量标准，通过估算引出有害行为所需的平均尝试次数来衡量攻击难度，揭示了尽管所有模型都普遍易受攻击，但其攻击难度可相差300多倍。报告还介绍了原语级别的漏洞分析，以确定哪些脱牢笼技术对特定危害类别最有效，并与AI安全网络的可信赖第三方进行了协作评估，展示了社区中分布式稳健性评估的实际路径.", "innovation": "报告的创新点包括：1) 使用动态对抗优化的AI系统进行自动化红队测试；2) 建立细粒度的稳健性度量标准，以评估引出有害行为所需的平均尝试次数；3) 引入原语级别的漏洞分析，以确定最有效的脱牢笼技术；4) 与AI安全网络的第三方进行协作评估，展示分布式评估的实际道路.", "conclusion": "通过引入动态对抗优化的红队测试、细粒度的稳健性度量和原语级别的漏洞分析，该报告展示了评估社区中LLM稳健性的多种途径，揭示了不同模型间的攻击难度差异，并提出了实际的协作评估方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06348", "html_url": "https://arxiv.org/abs/2508.06348", "title": "AntiCheatPT：在竞争性计算机游戏中基于变换器的方法检测作弊", "title_en": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games", "authors": "Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli", "background": "在线视频游戏中作弊破坏了游戏体验的完整性。反作弊系统，如VAC（Valve Anti-Cheat），面临着应对不断演变的作弊方法的挑战，同时又要避免对用户系统产生侵入性影响。为了应对这一挑战，本研究提出了一种基于变换器的机器学习模型AntiCheatPT_256，用于检测使用游戏数据的《CS2》中的作弊行为。", "innovation": "研究通过对《CS2》的比赛数据进行分析，提出了一个基于变换器的机器学习模型AntiCheatPT_256，用于检测作弊行为。该研究还公开了一个包含795场比赛标签的数据集CS2CD，并通过创建和增强上下文窗口解决了类别不平衡问题。模型在未经增强的测试集上达到了89.17%的准确率和93.36%的AUC值。这强调了研究的可重复性和实际应用价值，为未来的数据驱动的作弊检测研究提供了一个坚实的基础。", "conclusion": "通过使用基于变换器的模型处理游戏数据，研究不仅提高了检测作弊行为的效率和准确性，还提供了一个可应用于现实世界的反作弊系统的示范模型，为未来的研究奠定了基础。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06326", "html_url": "https://arxiv.org/abs/2508.06326", "title": "有表现的载体的“良好调节器定理”", "title_en": "A \"good regulator theorem\" for embodied agents", "authors": "Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci", "background": "在一篇经典论文中，Conant和Ashby提出了“每个良好的系统调节器都必须是一个系统模型”的观点。然而，人工生命领域有许多实例表明，存在进行任务的系统似乎无需任何模型，这暗示Conant和Ashby的定理可能在原限定条件下不易扩展。", "innovation": "本文展示了另一种类似的观点：当代理能够执行调节任务时，观察者可以从代理的感知输入出发，将其视为具有“关于环境的信念”，并根据感知输入进行“更新”。这一信念更新的概念比Conant和Ashby的模型更加复杂，并提供了一个更广泛适用的定理。然而，这需要转变视角，即观察者在理论中起着关键作用：模型不是系统的固有属性，而是从外部强加的。该定理适用于系统在传统控制理论框架中调节其环境，或调节其内部状态的情况；不管在哪种情况下，模型都是其环境的描述。", "conclusion": "模型可以是简单的，而这正是解决看似反例的方法，即代理的模型可能非常简单。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06443", "html_url": "https://arxiv.org/abs/2508.06443", "title": "The Fair Game: 审核与时间中的AI算法去偏差", "title_en": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time", "authors": "Debabrota Basu,Udvas Das", "background": "当前，Fair Machine Learning (ML) 是一个新兴领域，旨在量化ML算法预测中表现出的不同类型的偏差，并设计新的算法来缓解这些问题。然而，文献中关于偏差的定义往往是观察性的，这意味着它们依赖于预训练算法的输入和输出来量化担忧的偏差。这些定义在现实中往往是相互冲突的，并且只有在知道真实情况或部署算法后才能应用。这在动态社会环境中拉开了我们希望公平机器学习能够实现的目标和当前功能之间的差距。", "innovation": "\"Fair Game\" 提出了一种动态机制，通过将审计器和去偏差算法嵌入到ML算法的环中，结合使用强化学习（RL），旨在确保算法预测的公平性，并随着时间社会与算法互动调整其预测。此框架的独特之处在于公平性的目标可以根据需要调整，通过修改审计器及其衡量的不同偏差来实现。", "conclusion": "\"Fair Game\" 试图通过创建一个将反馈发送到部署在ML系统的去偏差算法的审计器，来模拟社会中伦理和法律框架的演变。此方法旨在开发一种灵活且随着时间动态调整的框架，以构建公平的机器学习系统，预部署和后部署。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06454", "html_url": "https://arxiv.org/abs/2508.06454", "title": "实际上投票规则在做什么：基于数据的多项选择投票分析", "title_en": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting", "authors": "Joshua Caiata,Ben Armstrong,Kate Larson", "background": "委员会选择问题在许多情境和应用中存在，社会选择研究领域对此越来越感兴趣，关注不同多项选择投票规则满足的属性。现有的研究多是从最坏情况分析的角度来看投票规则是否满足公理，本研究提出了一种数据驱动框架，用以评估投票规则在实际不同偏好分布中违反公理的频率，从而提供不同于传统视角的分析结果.", "innovation": "提出了一种数据驱动框架，从实际的偏好分布出发评估多项选择投票规则违反公理的频率，展示神经网络作为投票规则可以更有效地降低公理违反的情况。此研究为社会责任选择中的新投票系统设计提供了数据驱动的信息，并支持数据驱动研究的继续.", "conclusion": "数据驱动的方法可以在社会责任选择中指导新的投票系统的设计，并且神经网络在减少公理违反方面可能优于传统的投票规则，这表明数据驱动研究在社会责任选择中有其重要价值."}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06352", "html_url": "https://arxiv.org/abs/2508.06352", "title": "从可解释到说明性的人工智能：通过生成式人工智能实现以人为本的说明的新范式", "title_en": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI", "authors": "Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen", "background": "当前的可解释人工智能（XAI）方法侧重于算法透明度，并以抽象、非自适应的形式提供解释，这些不太能够支持最终用户的理解。这项研究基于此背景下，介绍了一种称为“说明性AI”的新范式，利用生成式AI能力作为理解伴侣，而不是提供算法透明度。与XAI揭示算法决策过程以供模型验证不同，说明性AI侧重于情境推理，以支持在社会技术环境中的用户决策。现有研究表明，用户更偏好情境敏感的多模态解释而非技术透明度，突显了设计能够为人理解而不是仅为人解的AI系统的紧迫性。这为跨多种领域和文化背景下推进以用户为中心的AI解释方法提供了广泛的研究议程。", "innovation": "提出了一个名为“说明性AI”的新范式，强调利用生成式AI技术，通过情境推理和多模态、适应性个人化的解释方法，支持用户在社会技术情境下的决策过程。该范式通过叙事沟通、自适应个性化和渐进披露的原则来区分，提供了不同于传统XAI方法的新视角，强调了用户体验而非单纯的技术透明度。", "conclusion": "通过快速情境设计方法论在医疗专业人员中的实证验证表明，说明性AI方法更受用户青睐，强调了设计能够为人理解的AI系统的紧迫性。研究确定了一项全面的研究议程，旨在促进不同领域和文化背景下的以人为本的AI解释方法的发展。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06226", "html_url": "https://arxiv.org/abs/2508.06226", "title": "GeoLaux: 用于评估 MLLMs 辅助线要求的长步骤几何问题表现的基准", "title_en": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines", "authors": "Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu", "background": "几何问题解决 (GPS) 包括图理解、逻辑推理、知识应用、数值计算和辅助线构造等多方面，这为多模态大型语言模型 (MLLMs) 带来了巨大挑战。现有评估 MLLM 几何技能的基准忽略了辅助线构造，并缺乏详细的过程评估，无法全面评估模型的长步骤推理能力。GeoLaux 指标集旨在弥补这些不足，包含 2,186 个几何问题，涵盖了计算和证明问题，平均需要 6.51 步推理，最大 24 步，其中 41.8% 需要构造辅助线。该数据集提出了一种新的五维评估策略，评估答案准确性、过程准确性、过程质量、辅助线影响以及错误原因。实验结果显示，模型在扩展的推理步骤中表现出显著性能下降（九个模型的性能下降超过 50%），对于证明问题模型倾向于采取捷径，模型缺乏辅助线意识，增加这一能力对整体几何推理有显著益处。这些发现将 GeoLaux 确立为评估 MLLMs 辅助线要求的长步骤几何推理能力的基准，并作为能力提升的指导。", "innovation": "GeoLaux 指标集通过引入辅助线构造和详细的过程评估，填补了现有几何问题解决能力评估机制的空白。设计的五维评估策略涵盖了答案准确性、过程准确性、过程质量、辅助线影响以及错误原因。首次系统地评估了 MLLMs 在长步骤推理中的性能，特别是包含了对证明问题的捕捉，以及辅助线构造能力的重要性。实验验证了 MLLMs 在长步骤推理中的具体表现和潜在问题，提出改进建议", "conclusion": "GeoLaux 指标集不仅是一个评估 MLLMs 辅助线要求的长步骤几何推理能力的基准，也是一个指导能力提升的指南。通过揭示 MLLMs 在长步骤推理中的具体表现和潜在问题，研究指明了提升 MLLMs 几何推理能力的方向。数据集和代码包含在附录中并将在后期发布."}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06368", "html_url": "https://arxiv.org/abs/2508.06368", "title": "针对反女性暴力立法的法律知识图谱自动化创建：资源、方法论和经验教训", "title_en": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned", "authors": "Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi", "background": "法律决策过程需要全面和详细的知识背景以及最新的法律案例信息和相关判决。法律知识图谱（KGs）可以作为一种有价值的工具来帮助访问法律信息，帮助法律专家进行查询和利用，并且为高级推理和机器学习应用提供支持。尽管如此，在法律领域中很少能找到这样的知识图谱。为了解决这个问题，该论文基于欧洲法院公开的法律句子，开发了一个针对反女性暴力法律案例的知识图谱，并采用了明确的建模方法。这是填补法律领域知识图谱空白的重要工作。", "innovation": "论文提出了两种互补的方法来自动构建法律KG：一种是专为法律领域定制的系统性自底向上的方法；另一种是利用大型语言模型的新解决方案。通过这些方法，从欧洲法院公开的法律句子入手，整合结构化数据提取、本体开发和语义丰富等步骤，来专门为涉及反女性暴力的法律案例定制知识图谱。然后对比两种方法的结果，并通过合适的能力问题验证了开发的知识图谱的有效性。这些知识图谱可以针对预测性司法工具进行改进，不仅能改善人类获取法律信息的能力，还能实现复杂的查询任务，并可能成为机器学习工具的重要组成部分。", "conclusion": "开发的知识图谱可以在法律决策中产生重大影响，不仅能提高法律信息的访问性，无论是对人还是机器，还可以实现复杂的查询，并可能成为为预测型司法量身定制的机器学习工具的重要组成部分。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2304.04475", "html_url": "https://arxiv.org/abs/2304.04475", "title": "在大规模基于代理的流行病学模型中使用深度确定性策略梯度进行疫情控制", "title_en": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient", "authors": "Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan", "background": "为了缓解疫情的影响，采取了包括封锁、快速疫苗接种计划、学校关闭和经济刺激等多种措施。这些干预措施可能带来积极或不期望的负面后果。当前通过将模型和确定最优干预措施的自动循环模型化和优化研究受到仿真目标、规模（几千人）、不适用于干预研究的模型类型以及可探索的干预策略数量等限制。我们利用基于深度确定性策略梯度（DDPG）的策略优化框架，针对包含10万个体的大型规模流行病学基于代理的仿真模型，进行多目标优化，以确定封锁和疫苗接种的最佳策略，在一个简化的经济活动基本仿真中实现此目标。没有封锁和疫苗接种（中老年人），结果表明个体在贫困线以下时经济最优，在公共健康指标（感染、住院）平衡方面也实现了最优。进一步深入仿真验证结果，开源我们的框架是必要的。", "innovation": "我们利用一种基于深度确定性策略梯度（DDPG）的策略优化框架，在一个包含10万个体的大型规模流行病学基于代理的仿真模型中，实现了一个简化的经济活动基本仿真，并进行了多目标优化，以确定封锁和疫苗接种的最佳策略。这种方法能够更好地模拟大规模人群中的疫情控制，在有限的模型和尺度约束下探索更多的干预策略，并且可以进行多目标优化，以平衡经济和健康目标。", "conclusion": "利用基于DDPG的策略优化框架，我们在10万人规模的基于代理的流行病学仿真模型中实现了最优的封锁和疫苗接种策略，并在经济和健康目标之间实现了平衡。进一步的深入仿真验证和开源我们的框架是必要的，以进一步确认这些结果的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12286", "html_url": "https://arxiv.org/abs/2507.12286", "title": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques", "title_en": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques", "authors": "Anouk Oudshoorn,Magdalena Ortiz,Mantas Simkus", "background": "SHACL和OWL是两个在管理和处理RDF数据方面享有盛誉的W3C标准。它们有许多共同的特点，但有一个基本的区别：OWL是一个设计用于从不完整数据中推导事实的逻辑语言，采用开放世界假设；而SHACL是一种约束语言，假设数据是完整的，并需在封闭世界假设下进行验证。两者结合是非常吸引人的，但它们之间的语义差距是主要的挑战，具有语义和计算上的影响。", "innovation": "本文提出了在基于核心通用模型的本体上进行SHACL验证的一种语义，并提供了一种构建Horn-ALCHIQ这一富数据可处理描述逻辑的本体模型的技术。此外，利用该模型的有限表示开发了一种重写技术，将包含本体的SHACL验证简化为标准验证。最后，研究了在存在本体的情况下SHACL验证的复杂性，发现即使是简单的本体也会使问题变成EXPTIME完整，并且在数据复杂性下是PTIME完整的。", "conclusion": "本文通过结合SHACL和本体的语义定义及创新的重写技术，将复杂验证问题转化为标准验证问题。研究表明，在涉及本体的情况下，SHACL验证的复杂性极高，即使是简单本体也会大幅增加问题的复杂度。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04748", "html_url": "https://arxiv.org/abs/2508.04748", "title": "AttriLens-Mol: 属性导向的大型语言模型增强学习框架用于分子属性预测", "title_en": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models", "authors": "Xuan Lin,Long Chen,Yile Wang", "background": "大型语言模型（LLMs）在分子属性预测任务中表现出潜力，但通常依赖于人类设计的提示和链式思考模板。尽管最近进过强化学习的大型推理模型（如DeepSeek-R1）增加了扩展的“思考”过程，但其推理过程往往冗长且缺乏相关性。这些背景揭示了当前方法的问题：缺乏有效的属性引导和高效推理机制。", "innovation": "本文提出了AttriLens-Mol，一种属性导向的强化学习框架，利用格式奖励引导基于属性的结构化输出、计数奖励避免无关属性的列举以及合理性奖励验证生成属性的相关性。具体创新点包括：1. 引入格式奖励促进结构化输出；2. 使用计数奖励避免列举无关属性；3. 通过高阶LLMs和RDKit验证生成属性的相关性，实现模型内在属性知识的隐性引导，提高预测性能。实验结果表明，使用AttriLens-Mol训练的R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型在多种数据集上的性能显著提升，优于监督微调模型和先进模型。进一步，利用提取的属性特征构建的可解释决策树模型表现更佳，说明AttriLens-Mol能有效提取更相关、预测性更强的分子属性。", "conclusion": "AttriLens-Mol框架显著提升了分子属性预测性能，优于现有模型和方法。该框架的有效性已通过实验验证。未来，团队将考虑实际应用场景和计算复杂度的折中，进一步推广此框架的应用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05652", "html_url": "https://arxiv.org/abs/2508.05652", "title": "基于检索增强生成的大语言模型户外徒步路径推荐聊天机器人性探索", "title_en": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation", "authors": "Julia Ann Mathew,Suining He", "background": "随着户外活动（如徒步和骑行）的日益流行，对提供准确且个性化户外路径建议的对话式AI系统的需求增加。然而，如何通过对话式AI提供准确的户外路径信息，以及如何实现实用且高效的推荐服务存在挑战。", "innovation": "本文讨论了基于大型语言模型及检索增强生成的户外路径推荐聊天机器人的初步和实际经验。通过针对美国康涅狄格州的户外路径案例研究，进行网络数据收集、户外路径数据管理和基于检索增强生成的推荐模型性能研究，展示了该机器人的准确性和有效性。", "conclusion": "实验结果表明，基于大型语言模型及检索增强生成的Judy聊天机器人能够提供准确、有效且易用的户外路径建议。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05647", "html_url": "https://arxiv.org/abs/2508.05647", "title": "基于查询意识的图神经网络增强检索增强生成", "title_en": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation", "authors": "Vibhor Agrawal,Fay Wang,Rishi Puri", "background": "传统的密集检索方法将文档视作独立实体来进行处理，在处理复杂、多跳的问题时存在局限性。本文提出了一种新的图神经网络(GNN)架构，用于检索增强生成(RAG)，通过使用查询感知的注意力机制和学习到的评分头部来提高复杂文档检索的准确性。这种方法不同于传统的密集检索方法，能够构建基于每集的知识图，捕捉文本片断间的序列和语义关系，从而对复杂问题的回答尤为有效，特别是在多文档推理任务上表现出色。实验结果表明，我们的方法在复杂问答任务上的表现大幅优于标准的密集检索器，特别是在需要多文档推理的问题上表现突出。", "innovation": "本文引入了一种增强的图注意力网络，并结合了查询引导的池化方法，能够根据用户查询动态聚焦于图中的相关部分。这种方法能够捕捉和利用复杂文档中的序列和语义关系，对于复杂的问题，尤其是多文档推理任务，具有显著的优势。我们的实现基于PyTorch Geometric，可以高效地处理基于图的数据结构，有利于生产环境中可扩展的部署。", "conclusion": "实验结果表明，我们的方法显著优于标准的密集检索器，特别是在处理需要多文档推理的复杂问题方面表现出色。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05640", "html_url": "https://arxiv.org/abs/2508.05640", "title": "Request-Only Optimization for Recommendation Systems", "title_en": "Request-Only Optimization for Recommendation Systems", "authors": "Liang Guo,Wei Li,Lucy Liao,Huihui Cheng,Rui Zhang,Yu Shi,Yueming Wang,Yanzun Huang,Keke Zhai,Pengchao Wang,Timothy Shi,Xuan Cao,Shengzhi Wang,Renqin Cai,Zhaojie Gong,Omkar Vichare,Rui Jian,Leon Gao,Shiyan Deng,Xingyu Liu,Xiong Zhang,Fu Li,Wenlei Xie,Bin Wen,Rui Li,Xing Liu,Jiaqi Zhai", "background": "DLRsMs是地球上最大的机器学习应用之一，大规模DLRsMs每天处理来自数十亿用户的PB级推荐数据。为利用用户长时间的历史信号，DLRsMs被扩展到前所未有的复杂性，每例操作达到万亿次浮点运算（TFLOPs）。这种规模加上大量的训练数据，需要新的存储和训练算法来高效地改进这些复杂推荐系统的质量。", "innovation": "提出了一种名为Request-Only Optimizations (ROO)的新训练和建模范式。ROO通过共同设计数据（即仅请求数据）、基础设施（即基于请求的数据处理管道）和模型架构（即仅请求的神经架构）来同时提高存储和训练效率以及模型质量。相较于常见的以用户印象为单位的设计，新设计实现了数据日志中的自然特征重复扣除，节省了数据存储，并通过去重复计算和通信来适应大规模神经网络架构，以更好地捕捉用户兴趣信号，如生成型推荐器（GRs）和其他仅请求友好的架构。", "conclusion": "ROO训练和建模范式以用户请求为训练数据的基本单位，相较于传统的以用户印象为单位的方法，能够更有效率地优化存储、训练和模型质量。这种新范式通过共同设计数据、基础设施和模型架构，能够更好地捕捉用户兴趣信号，提高推荐系统的性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05653", "html_url": "https://arxiv.org/abs/2508.05653", "title": "模型化交互叙事系统：一种形式化方法", "title_en": "Modeling Interactive Narrative Systems: A Formal Approach", "authors": "Jules Clerc,Domitile Lourdeaux,Mohamed Sallak,Johann Barbier,Marc Ravaine", "background": "交互叙事系统（INS）通过让用户主动塑造故事内容，颠覆了传统的被动叙事，极大地改变了数字体验。然而，由于研究努力的分散和系统表示的多样性，该领域面临着挑战。现有的研究工作缺乏统一性，使得对INS的分析、描述和比较变得困难。", "innovation": "本文介绍了一种基于先进方法的INS的形式化表示框架，提供了一致的词汇和建模结构，使INS的属性分析、描述和比较变得更加容易。通过“小红帽”情境的实验验证，展示了提出的形式化方法的有效性和对INS评估改进的影响。", "conclusion": "本文旨在通过提供一个正式的方法论促进INTERACTIVE NARRATIVE SYSTEMS (INS)研究社区内的合作与统一，从而推动该领域的进步。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05650", "html_url": "https://arxiv.org/abs/2508.05650", "title": "OmniBench-RAG: 多领域评估平台以评估检索增强生成工具", "title_en": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools", "authors": "Jiaxuan Liang,Shide Zhou,Kailong Wang", "background": "虽然现在的语言大模型（LLM）普遍采用检索增强生成（RAG）技术以提升效果，但在一个可复制且可解释的方式评估其真实性能增益方面仍然存在重大障碍。现有方法存在不足：缺乏覆盖面、使用粗略的指标遗漏子文档精度，并且无法捕捉计算权衡。最关键的是，它们没有提供标准化框架来比较不同模型和领域中RAG的效果。", "innovation": "我们引入了OmniBench RAG，一个新型自动化多领域评估平台，用于评估RAG系统。平台从准确性及效率维度量化性能增益，覆盖九个知识领域，包括文化、地理和健康。我们引入了两个标准化指标：改进（准确性增益）和转变（RAG模型前后效率差异）。该平台具备动态测试生成、模块化评价管道和自动生成知识库的功能。我们的评估揭示了RAG在不同领域的显著差异，这强调了系统化、领域意识评估的重要意义。", "conclusion": "该平台的评估表明，RAG在文化领域的增益显著，但在数学领域反而有所下降，突显了系统性、领域意识评估的关键重要性。开源代码与数据可在该网址找到：this https URL."}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05657", "html_url": "https://arxiv.org/abs/2508.05657", "title": "通过LLM增强数据扩充改善多标签对话推荐", "title_en": "Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation", "authors": "Haozhe Xu,Xiaohua Wang,Changze Lv,Xiaoqing Zheng", "background": "对话推荐系统(CRSs)通过多轮对话增强推荐质量，并通过自然语言交互捕捉用户细微的偏好。然而，这些系统在训练过程中经常会遇到假阴性问题，即用户可能喜欢的项目被错误地标记为负例，导致推荐质量下降。传统上通过扩充标签集来解决这个问题，但需要平衡确保语义相关性和保留CRS数据集中的协作信息之间的挑战。", "innovation": "提出了一种新的数据扩充框架，首先利用基于LLM的语义检索器识别多样且语义相关项目，然后通过相关性评分器过滤掉噪声候选项。在此基础上，引入了两阶段训练策略，平衡了语义相关性和协作信息。", "conclusion": "通过在两个基准数据集和用户模拟器上的广泛实验，该方法在各种推荐器上显示出显著且一致的性能提升，证明了该方法对提升CRS性能的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05654", "html_url": "https://arxiv.org/abs/2508.05654", "title": "应用到IT支持票的检索技术比较", "title_en": "Comparison of Information Retrieval Techniques Applied to IT Support Tickets", "authors": "Leonardo Santiago Benitez Pereira,Robinson Pizzio,Samir Bonho", "background": "机构依赖于IT服务和资源，认识到IT帮助台系统的重要性。这些系统充当IT人员与用户之间的中心枢纽，处理服务请求。传统的帮助台系统依赖于手动处理IT支持请求，然而，采用机器学习模型可以帮助记录过去的补救措施，提高效率。然而，不同模型在不同数据集中的性能差异很大。因此，本文通过比较11种信息检索技术在IT支持票数据集上的表现，旨在实施一种支持IT支持分析师工作的软件。", "innovation": "作者使用了多种信息检索技术，特别是Sentence-BERT模型（distilluse-base-multilingual-cased-v1）表现最优，推荐正确的解决方案的比例达到78.7%。此外，TF-IDF、Word2vec和LDA也表现出较好的一致性。研究还提出了一种新的评价指标，旨在更准确地反映IT分析师对检索质量的看法。同时，使用的数据集和源代码已经公开，为实际应用提供了参考。此外，还构建了一个最小可行产品（MVP），展示了支持票恢复系统的实用性，并详细描述了系统的实现过程。", "conclusion": "研究提出了一种新的评价指标，并通过多种信息检索技术应用于IT支持票数据集，提出了一种提高IT支持分析师工作效率的软件设计方案。实验结果表明，Sentence-BERT技术在推荐准确性方面表现最好，而其他技术如TF-IDF、Word2vec和LDA也表现出了较好的一致性。未来的工作将着重于进一步优化建议的实用性和准确性，以及扩大系统的覆盖范围和应用范围。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05660", "html_url": "https://arxiv.org/abs/2508.05660", "title": "开源自主型混合RAG框架在科学文献综述中的应用", "title_en": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review", "authors": "Aditya Nagori,Ricardo Accorsi Casonatto,Ayush Gautam,Abhinav Manikantha Sai Cheruvu,Rishikesan Kamaleswaran", "background": "近年来，科学出版物数量激增，挑战了传统的审阅方法，需要能够集成结构化元数据和全文分析的工具。Hybrid Retrieval Augmented Generation (RAG)系统结合了图查询和向量搜索，虽然有潜力，但通常是静态的，依赖于专有工具，并缺乏不确定性评估。现有的方法通常不够灵活和透明，难以应对科学文献的复杂性和多样性需求。", "innovation": "本研究提出了一种自主型方法，将Hybrid RAG流程集成到一个能够动态选择GraphRAG和VectorRAG、实时调整指令调优生成，并在推理过程中量化不确定性的自主代理中。该方法通过开源软件实现，提高相关性、减少幻觉，促进可重复性。研究还重点介绍了如何从PubMed、arXiv和Google Scholar API获取数据，构建基于引文的知识图谱，并整合到FAISS向量存储中。实验结果表明，在合成基准中，结合Direct Preference Optimization的指令调优代理在向量存储上下文召回和整体上下文精度方面优于基线。", "conclusion": "研究成果展示了系统在处理异构来源时增强的推理能力，并确立了一个可扩展的框架，以促进自主的科学发现。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05662", "html_url": "https://arxiv.org/abs/2508.05662", "title": "从静态到动态：基于流式的RAG方法实现实时知识库", "title_en": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base", "authors": "Yuzhou Zhu", "background": "来自新闻推送、社交媒体、传感器网络和金融市场等动态流式数据源的挑战使现有的静态RAG框架难以应对。全量索引会带来高昂的内存成本，而周期性的重建会增加延迟，降低数据的新鲜度；简单的采样会牺牲语义覆盖。", "innovation": "提出了Streaming RAG，一个综合多向量余弦筛选、迷你批聚类和基于计数的重记号筛选的统一管道，以维持紧凑的原型集。此外，证明了一个近似界限，将检索质量与聚类方差联系起来，并提供了一种增量索引更新机制，不需要中断查询。", "conclusion": "在八条实时流上的实验表明，Streaming RAG在Recall@10方面有统计显著的增益（最高可达3个点，p<0.01），端到端延迟低于15毫秒，吞吐量超过每秒900份文档，预算为150MB。超参数敏感性分析验证了默认设置的有效性。在使用GPT-3.5 Turbo的开放域问题回答中，记录了3.2点的精确匹配和2.8点的F1增益；摘要生成取得了ROUGE-L增益。Streaming RAG为检索增强设立了新的帕累托前沿。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05668", "html_url": "https://arxiv.org/abs/2508.05668", "title": "基于大型语言模型的深度搜索代理：范式、优化、评价和挑战", "title_en": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "authors": "Yunjia Xi,Jianghao Lin,Yongzhao Xiao,Zheli Zhou,Rong Shan,Te Gao,Jiachen Zhu,Weiwen Liu,Yong Yu,Weinan Zhang", "background": "大型语言模型（LLMs）的出现极大地革新了网络搜索。基于LLM的搜索代理标志着搜索方式向更深层次、动态自主的信息获取转变。这些代理能够理解用户意图和环境背景，并执行多轮次的动态检索，大大扩展了搜索的能力。领先实例如OpenAI的Deep Research展示了其在深度信息挖掘和实际应用中的潜力。", "innovation": "本文提供了一项系统性的分析，全面地从架构、优化、应用和评估等角度分析和分类现有的搜索代理工作，指出了该领域迫切需要解决的关键挑战，并提出了未来研究的展望。", "conclusion": "文章最终确定了该迅速发展的领域的关键开放挑战，并提出了对未来研究方向的展望，并公开了相关资源。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05648", "html_url": "https://arxiv.org/abs/2508.05648", "title": "AquiLLM：研究组中捕获隐形知识的RAG工具", "title_en": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups", "authors": "Chandler Campbell,Bernie Boscoe,Tuan Do", "background": "研究团队在捕获、存储和检索分散在成员之间的知识时面临持续的挑战。虽然结构化数据（旨在分析和出版）往往管理得很好，但团队的许多集体知识仍以非正式、碎片化或未记录的形式存在，通常通过会议、导师制度和日常协作口耳相传。这包括个人资源，如电子邮件、会议笔记、培训材料和临时文档，这些共同反映了团队的隐形知识——基于经验的非正式专业知识，构成了他们工作的重要部分。高质量地访问这些知识可能相当困难，需要大量的时间和内部理解。检索增强生成（RAG）系统提供了有前景的解决方案，通过让用户查询和生成基于相关源材料的回应来提供解决方案。然而，大多数当前的RAG-LLM系统都偏向于公文，忽视了内部研究材料的隐私问题。", "innovation": "本文提出了AquiLLM（ah-quill-em），一种轻量级、模块化的RAG系统，旨在满足研究团队的需求。AquiLLM支持多种文件类型和可配置的隐私设置，允许更多有效地访问学者团队中的正式和非正式知识。它解决了现有RAG-LLM系统忽视内部研究材料隐私的问题，从而提供了一个保护隐私的同时增强团队知识共享的技术框架。", "conclusion": "AquiLLM作为一种旨在保护隐私的RAG系统，能够有效支持研究团队访问其分布式知识。通过模块化和灵活配置，AquiLLM为学术界提供了一个解决知识管理难题的新工具，特别适用于那些需要保护其研究材料隐私的研究团队。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05667", "html_url": "https://arxiv.org/abs/2508.05667", "title": "ITDR：用于提高大型语言模型推荐性能的指令调优数据集", "title_en": "ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations", "authors": "Zekun Liu,Xiaowen Huang,Jitao Sang", "background": "大型语言模型（LLMs）在自然语言处理任务中展现出卓越性能，但在推荐系统领域面临挑战。由于用户行为数据与自然语言之间存在结构性差异，LLMs难以有效建模用户偏好与项目之间的关联。尽管基于提示的方法能够生成推荐结果，但它们对推荐任务的理解不足导致性能受限。", "innovation": "本研究构建了一个充分的指令调优数据集ITDR（包含7个子任务，涉及两个核心任务：用户项交互和用户项理解），整合了13个公开推荐数据集，包含约200,000个实例。实验结果表明，ITDR显著提升了主流开源LLM（如GLM-4、Qwen2.5、Qwen2.5-Instruct和LLaMA-3.2）在推荐任务上的性能。此外，研究还分析了任务之间的关联，并探讨了任务描述和数据规模对指令调优效果的影响。", "conclusion": "本研究构建的调优数据集ITDR和精调过的大型推荐模型可以从以下链接访问：[访问链接]。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05661", "html_url": "https://arxiv.org/abs/2508.05661", "title": "零-shot检索在双边市场中实现可扩展视觉搜索", "title_en": "Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace", "authors": "Andre Rusli,Shoma Ishimoto,Sho Akiyama,Aman Kumar Singh", "background": "视觉搜索为顾客探索多样化的商品目录提供了一种直观的方式，特别是对于消费者对消费者（C2C）的电子商务市场，其中商品列表往往是未结构化的和以视觉驱动的。本文介绍了一种已在Mercari的C2C平台上部署的可扩展视觉搜索系统，该系统由买家和卖家组成端用户群体。我们评估了最近的视觉-语言模型用于零样本图像检索，并将其性能与一个现有的微调基线进行了比较。系统集成了实时推理和背景索引工作流，支持一个通过降维优化的统一嵌入管道。使用用户交互日志进行的离线评估表明，跨多个检索指标，多语言SigLIP模型优于其他模型，相较于基线在nDCG@5的增幅达到13.3%。在生产环境中为期一周的A/B测试进一步证实了实际影响，处理组在通过图像搜索增加交易率方面取得了显著的提升，增幅高达40.9%。研究结果表明，最近的零样本模型可以作为一个强大且实用的基线用于生产环境，能够使团队部署有效的视觉搜索系统，同时保留未来数据或特定领域需求的微调灵活性。", "innovation": "本文创新地评估了最近的视觉-语言模型在零样本图像检索中的性能，并将其与一个现有的微调基线进行比较。系统采用了实时推理和背景索引工作流，支持一个统一的嵌入管道通过降维优化。研究中的离线评估和生产环境中的A/B测试确认了多语言SigLIP模型在多个检索指标上的表现优于其他模型，进一步证实了实际应用中的效果显著。", "conclusion": "研究结果表明，最近的零样本模型可以作为一个强大的基线用于实际生产环境中的视觉搜索系统。这使得团队能够部署具有最小开销的有效视觉搜索系统，同时保留了根据未来数据或特定领域需求进行微调的灵活性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05666", "html_url": "https://arxiv.org/abs/2508.05666", "title": "HySemRAG：一种用于自动化文献综合和方法论空白分析的混合语义检索增强生成框架", "title_en": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "authors": "Alejandro Godinez", "background": "现有的检索增强生成（RAG）架构存在着若干局限性，特别是在处理大规模文献综合任务时。HySemRAG框架通过结合抽取、转换、加载（ETL）管道与RAG，旨在解决这些问题，实现大规模文献综合和方法论研究空白的自动识别。", "innovation": "HySemRAG通过多层方法提高了RAG的技术应用：混合检索结合了语义搜索、关键词过滤和知识图谱遍历；一种自主的自我纠正框架，包含迭代的质量保证机制；以及事后引用验证确保完整的可追溯性。HySemRAG通过八个综合阶段处理学术文献，包括元数据获取、异步PDF检索、定制化的文档Layout分析、文献管理、基于LLM的领域提取、主题建模、语义统一和知识图谱构建。其实施创建了双重数据产品：Neo4j知识图谱支持复杂关系查询和Qdrant向量集合支持语义搜索，为验证性信息综合提供了基础架构。这一框架的评估表明，结构化的领域提取比PDF片段处理提高了35.1%的语义相似度分数，并且自主的质量保证机制在验证后的响应中实现了68.3%的一次成功率和99.0%的引用准确性。在臭氧暴露与心血管疾病领域的地理空间流行病学文献中的应用，展示了该系统在各科学领域加速证据综合和发现的广泛适用性。", "conclusion": "HySemRAG系统通过多层检索和生成技术的结合，为大规模文献综合和方法论研究空白分析提供了一个新的框架，并通过实际应用证明了其在提高文献提取准确性和揭示研究趋势方面的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05637", "html_url": "https://arxiv.org/abs/2508.05637", "title": "使用大语言模型自动化数据可视化修图", "title_en": "Automated Visualization Makeovers with LLMs", "authors": "Siddharth Gangwar,David A. Selby,Sebastian J. Vollmer", "background": "制作准确而高效地传达所需信息的图形需要艺术与科学相结合，通常不在数据科学课程中教授。可视化修图是一种社区互动活动，成员间相互反馈以改进图表和数据可视化。作者提出的问题是，多模态的大语言模型（LLMs）是否能够模拟这种任务？该模型通过通用提示工程，结合用户指定的准则和模型训练中的可视化最佳实践知识，对给定的图像文件或生成代码中不理想的图表进行改进，从而生成建设性的批评评论。该研究的焦点不在于从原始数据或提示中生成有效的可视化脚本，而是在于根据对最佳实践的理解来教育用户如何改进现有的可视化。", "innovation": "该研究的创新在于提出了一种利用多模态大语言模型来进行数据可视化修图的方法。模型不直接生成全新的可视化脚本，而是通过结合用户的指令和模型的训练知识，生成针对现有可视化的改进批评。研究还通过定量评估了模型对各种图表类型中绘图问题的敏感性。同时，该工具作为一个易于自我托管的应用程序具有可访问的网络界面，可供使用。", "conclusion": "研究结果表明，大语言模型可以在一定程度上提高现有数据可视化的质量。研究成果以一个简单的自我托管的应用程序形式提供，供用户通过网络界面使用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05672", "html_url": "https://arxiv.org/abs/2508.05672", "title": "LMAR: 增强语言模型检索器进行领域特定知识索引", "title_en": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing", "authors": "Yao Zhao,Yantian Ding,Zhiyue Zhang,Dapeng Yao,Yanxun Xu", "background": "检索增强生成（RAG）系统在处理领域特定知识时常常面临问题，主要是因为预训练嵌入性能下降以及基于大型语言模型（LLM）的检索器计算成本高昂。尽管可以通过微调数据增强嵌入模型来解决这一问题，但其有效性的提高受限于高质量训练数据的需求和保持上下文完整性的可靠切块策略。", "innovation": "本文提出了LMAR（语言模型增强检索器）框架，该框架通过结合LLM引导的数据合成、对比嵌入适应以及高效文本聚类来解决上述挑战。LMAR通过两阶段流程：（1）三重样本和合成数据增强，LLM在此过程中既是标签器也是验证器，确保管道中监督的高保真度。实验结果表明，LMAR在多个领域特定基准数据集上优于多种基线模型，同时保持了较低的硬件要求和延迟。此外，无需重新设计管道即可无缝整合到新兴的RAG架构和文本嵌入模型中，确保了持续改进。", "conclusion": "实验结果表明，LMAR是一个在成本和实用方面可行的解决方案，适用于领域特定的知识适应。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05669", "html_url": "https://arxiv.org/abs/2508.05669", "title": "针对马来西亚已审计财务报告中的财务表格进行Markdown转换的视觉语言模型微调", "title_en": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "authors": "Jin Khye Tan(Faculty of Computer Science and Information Technology, Universiti Malaya),En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah", "background": "从财务文档中准确提取和表示表格结构仍然是文档理解中的一个重要挑战，特别是在监管和分析用例中。本文针对将马来西亚审计财务报告中的财务表格转换为Markdown格式的复杂性进行了研究，其中包括旋转布局、多级表头和隐含的结构提示等因素的挑战。", "innovation": "本文提出了基于Qwen2.5-VL-7B的Fine-tuned视觉语言模型（VLM），该模型专门优化用于从文档图像中生成高保真Markdown。通过构建包含2,152个图像-文本对的数据集并使用洛拉（LoRA）监督微调策略。提出了基于Markdown树编辑距离的相似性（TEDS）度量标准，以评估模型的整体结构保真度。该模型在基于标准的LLM评价中取得了92.20%的整体准确率，在Markdown TEDS得分中达到了96.53%。这些结果表明，针对特定领域的模型微调提供了一种有效且高效的方法，可以在不使用大量计算资源的情况下使非结构化的财务文档与下游自动化相结合，这是传统的更大规模和更通用模型所不能比拟的。此外，该模型的推理时间也显著减少。", "conclusion": "与自托管的替代方案相比，该模型在准确性和推理时间方面均表现优异，超过了包括OpenAI的GPT-4o和Gemini 2.5 Flash在内的广泛使用的专有模型。这些结果证明了领域特定模型微调的有效性和效率，为自动化从非结构化财务文档生成精确结构表示提供了强有力的工具。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05673", "html_url": "https://arxiv.org/abs/2508.05673", "title": "突破Top-$K$障碍：在推荐系统中提升Top-$K$排名度量优化", "title_en": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems", "authors": "Weiqin Yang,Jiawei Chen,Shengjia Zhang,Peng Wu,Yuegang Sun,Yan Feng,Chun Chen,Can Wang", "background": "在推荐系统中，Top-$K$ 排名度量如NDCG@$K$是评价推荐性能的标准指标。然而，在推荐模型训练时，优化NDCG@$K$面临诸多挑战，因其固有的非连续特性和Top-$K$截断的复杂性。现有优化NDCG@$K$的方法要么忽略了Top-$K$截断，要么导致高计算成本和训练不稳定。", "innovation": "提出了新的推荐损失函数SoftmaxLoss@$K$（SL@$K$），通过集成分位数技术处理Top-$K$截断，并推导出平滑的上界来优化NDCG@$K$，以解决非连续性问题。SL@$K$损失具有理论保证、易于实现、计算效率高、梯度稳定和抗噪声能力强等特点。", "conclusion": "在四个真实数据集和三种推荐架构上进行的大量实验表明，SL@$K$显著优于现有损失函数，平均改进率为6.03%。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05670", "html_url": "https://arxiv.org/abs/2508.05670", "title": "LLMs能否为网络安全提供基于博弈论的场景？", "title_en": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?", "authors": "Daniele Proverbio,Alessio Buscemi,Alessandro Di Stefano, TheAnh Han,German Castignani,Pietro Liò", "background": "博弈论长期以来一直是网络安全研究中的一个基本工具，用于测试、预测和设计攻击者和防御者之间的战略性互动。最近，大型语言模型（LLMs）为计算机系统的安全性提供了新的工具和挑战。本文探讨了经典的博弈论框架是否能有效地捕捉到由LLM驱动的行动者和机器人行为。通过一个可重复的框架，我们研究了两个经典的博弈场景——一次性零和博弈和动态囚徒困境，并测试LLMs是否收敛于预期的结果或由于嵌入的偏见表现出偏差。实验涉及四款当前最先进的LLM，并涵盖五种自然语言：英语、法语、阿拉伯语、越南语和 Mandarin中文，以评估语言敏感性。", "innovation": "本文通过实验验证了大型语言模型是否能有效地在网络安全中提供基于博弈论的场景。使用一个可重复的框架研究了两种经典博弈场景，并测试了模型的行为是否会受到多轮博弈及语言选择的影响。此外，还通过对模型的内部一致性和跨语言稳定性进行定量评估，以提供模型选择和优化的指导，旨在提高模型在安全应用中的稳定性和适用性。这些发现揭示了语言选择对博弈结果的影响，对于在不同国家部署LLMs时的行为差异提出了警告，呼吁进行更深入的研究。", "conclusion": "实验结果表明，LLMs的最终收益受到代理特征如个性特质或对多回合博弈的理解的影响。同时，我们发现语言选择对最终收益存在意想不到的敏感性，提示在网络安全应用中不应普遍应用LLMs，需要针对不同国家进行深入研究。此外，我们还提供了通过量化指标评估LLMs内部一致性和跨语言稳定性的方法，以帮助选择最稳定的LLMs并优化安全应用中的模型性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05680", "html_url": "https://arxiv.org/abs/2508.05680", "title": "算法视野中的性别平等吗？-- 分析搜索引擎和检索算法以实现算法性别公平", "title_en": "Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness", "authors": "Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Ludwig Bothmann,Christian Heumann,Stephanie Thiemichen", "background": "算法系统如搜索引擎和信息检索平台极大地影响了学术的可见度和知识的传播。尽管这些系统被假设为中立，但它们仍然可以复制或强化社会偏见，包括性别偏见。本研究在德国大学及其应用科学大学的学术档案数据中分析性别差异在元数据完成度、学术数据库中的出版物检索以及谷歌搜索结果中的可见性。研究表明，在没有明显的算法歧视的情况下，仍然存在细微但持续的不平衡，男性教授在搜索结果和出版记录的匹配度上更为一致，而女性教授的数字可见性则更具变异性。这些模式反映了平台算法、机构编目和个人自我呈现之间的相互作用。该研究突出了对数字系统中技术性能和代表性平等考虑的公平性评估的需求。", "innovation": "本文提出了一个保留偏见的算法性别公平定义，评估算法输出是否反映现实中的性别比例，而不引入或放大差距。通过分析德国高校和应用科学大学的异质数据集，本文首次依据算法性别公正的角度来系统地检视女性与男性教授在学术领域的曝光情况。这填补了当前性别公平研究在算法层面的空白，提供了更深入、更精细的数据视角。", "conclusion": "本文的研究结果展示了算法性别公平的重要性，并强调了在技术性能和代表性平等之间的平衡的必要性。研究发现细微但持续的不平衡需要在未来的设计与开发过程中进一步消除。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05675", "html_url": "https://arxiv.org/abs/2508.05675", "title": "基于原理指导的Verilog优化：通过本地-云协作实现知识产权安全的知识转移", "title_en": "Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration", "authors": "Jing Wang,Zheng Li,Lei Li,Fan He,Liyu Lin,Yao Lai,Yan Li,Xiaoyang Zeng,Yufeng Guo", "background": "近年来，采用大型语言模型（LLMs）对寄存器传输级（RTL）代码进行优化引起了广泛关注。虽然基于云的强大LLMs提供了优秀的优化能力，但处理专有硬件设计时，存在不可接受的知识产权（IP）泄漏风险。本文旨在提出一种新的场景，即在不泄露敏感IP信息的情况下对Verilog代码进行特定属性的优化。研究对象提出了一种第一代IP保护的边缘-云协作框架，该框架结合了本地小型LLM和云端强大LLM的优点。通过这种方式，研究解决了优化与保护专有IP之间的矛盾，利用本地小型LLM对配对的高质量目标设计和初稿代码进行安全对比分析，提炼出一般设计原则，然后通过查询强大的云LLM以确保优化过程IP安全。实验结果表明，该框架在优化成功率上优于基线方法。例如，使用Qwen-2.5-Coder-7B和Deepseek-V3结合的方法，在功耗利用率方面实现了66.67％的优化成功率，优于单独使用Deepseek-V3（49.81％）甚至商业模型GPT-4o（55.81％）。进一步研究显示，不同模型组合在不同优化目标上具有特定优势，随着对比代码对数目的变化，存在有趣的趋势。本研究建立了一种新的硬件设计优化范式，平衡了性能提升与知识产权保护。", "innovation": "提出了一种创新的IP保护的边缘-云协作框架，结合了本地小型LLM和云端强大LLM的优点。该框架通过本地小型LLM进行安全的代码对比分析，提炼出设计原则，并通过查询云端的强大LLM进行有针对性的代码改进，确保了优化过程中的IP安全。实验结果显示，该方法在优化成功率上显著优于基线方法。", "conclusion": "该研究提出的方法建立了一种新的硬件设计优化范式，平衡了性能与知识产权保护，通过本地-云协作实现了无IP泄漏的优化效果。研究揭示了不同模型组合在特定优化目标上的优势，为未来相关研究提供了新的视角。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05687", "html_url": "https://arxiv.org/abs/2508.05687", "title": "受治理的LLM基于多代理系统的风险分析技术", "title_en": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems", "authors": "Alistair Reid,Simon O'Callaghan,Liam Carroll,Tiberio Caetano", "background": "组织开始采用基于LLM的AI代理，随着部署的展开，这些代理从单个代理逐渐向相互连接的多代理网络演变。然而，一组安全的代理并不保证一组安全的代理，因为这些代理随着时间的推移进行交互会产生新出现的行为模式和新型失败模式。这意味着多代理系统需要不同于单个代理使用的方法进行风险分析。本报告关注在组织控制其代理配置和部署的受治理环境中进行多代理AI系统操作时的风险识别和分析早期阶段。因此，需要评估六种关键失败模式：雪崩可靠性故障、代理间通信故障、单一文化崩溃、一致性偏差、缺乏心智理论以及动机多样性动态。", "innovation": "一种基于逐步测试和不同抽象层级进行风险验证的方法学，通过模拟、观察分析、基准测试和红队测试收集一致证据，并逐步增加暴露于潜在负面影响的机会。这种方法学为组织风险管理体系建立了坚实的基础，以适应和监督这些基于LLM的多代理系统的部署和运行。", "conclusion": "鉴于当前对LLM行为理解的局限性，我们的方法着重于分析的有效性，倡导在抽象的各个阶段进行测试，并逐步增加对潜在负面影响的暴露机会，同时通过模拟、观察分析、基准测试和红队测试收集一致的证据。这种方法学为组织在面对基于LLM的多代理系统的风险时提供了可靠的风险管理框架。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05677", "html_url": "https://arxiv.org/abs/2508.05677", "title": "基于强化学习的医疗问卷系统中的对抗攻击：输入级扰动策略和医学约束验证", "title_en": "Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation", "authors": "Peizhuo Liu", "background": "基于强化学习（RL）的医疗问卷系统在医疗场景中显示出巨大潜力，然而它们的安全性和鲁棒性尚未解决。本研究对对抗攻击方法进行了全面评估，以识别和分析潜在漏洞，并将诊断过程建模为马尔可夫决策过程（MDP），状态为患者回答的问题和未提问的问题，动作是提问或诊断。我们使用了247项医学约束条件，包括生理上限、症状相关性和条件医学约束，以确保生成的对抗样本在临床上可行。我们使用了六种主流的攻击方法，包括快速梯度符号方法（FGSM）、投影梯度下降（PGD）、Carlini & Wagner攻击（C&W）、基本迭代方法（BIM）、DeepFool和AutoAttack。实验在包含182,630个样本的国家健康访谈调查（NHIS）数据集上进行，用于预测参与者的4年死亡率。我们评估了攻击在由arXiv:2004.00994提出的支持自适应特征选择（AdaptiveFS）框架上的表现。结果表明，对抗攻击对诊断准确性有显著影响，攻击成功率从33.08%（FGSM）到64.70%（AutoAttack）不等。研究结果揭示了即使在严格的医学约束下，RL为基础的医疗问卷系统仍然存在明显的漏洞。", "innovation": "本研究首次全面评估了基于强化学习的医疗问卷系统的对抗攻击方法，将诊断过程建模为MDP，并通过严格的医学约束验证确保所生成的对抗样本在临床上的可行性。此外，研究使用了六种主流的攻击方法，涵盖了广泛的攻击策略，并在实际医疗数据集上进行了实验，验证了攻击的有效性。同时，该研究还强调了即使在严格医学约束下，这些系统的安全性仍然存在显著漏洞。", "conclusion": "本研究发现，在严格医学约束条件下，基于强化学习的医疗问卷系统依然受到对抗攻击的影响，表明这些系统的安全性和鲁棒性存在显著不足。未来的研究可以进一步探索提高这一类系统安全性的方法和策略。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05674", "html_url": "https://arxiv.org/abs/2508.05674", "title": "向更有效的 Offensive 安全 LLM 代理迈进：超参数调整、LLM 作为评判者和一个轻量级的 CTF 标准", "title_en": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "authors": "Minghao Shao,Nanda Rani,Kimberly Milner,Haoran Xi,Meet Udeshi,Saksham Aggarwal,Venkata Sai Charan Putrevu,Sandeep Kumar Shukla,Prashanth Krishnamurthy,Farshad Khorrami,Ramesh Karri,Muhammad Shafique", "background": "近期，大语言模型（LLM）代理系统在自动化执行安全防御任务方面取得了显著进展，特别是在 CTF（捕获之旗）挑战中。本文系统地研究了促进代理成功的关键因素，并提供了构建有效 LLM 基础的详细步骤。研究通过一个框架 CTFJudge，利用 LLM 来评判代理的行为轨迹，并进行细粒度评估。同时，提出了一种新的评估指标 CTF 竞技指数（CCI），展示代理解决方案与人工标准的契合程度。此外，研究还探讨了影响代理性能的 LLM 超参数（温度、top-p 和最大令牌长度）如何影响自动网络安全任务规划。", "innovation": "本文创新地提出了一个框架 CTFJudge，通过 LLM 评判代理人行为轨迹，提供了详细的基于 LLM 的有效进攻性安全代理构建方案。首次提出 CTF 竞技指数 (CCI) 评估代理的解决方案与人工标准的契合度。同时，研究探讨了 LLM 超参数如何影响代理性能与自动网络安全任务规划，并提出了一个包含 50 个代表性 CTF 挑战的轻量级基准 CTFTiny，覆盖了二进制利用、Web、逆向工程、取证和密码学等领域，提供了一种快速评估代理性能的方法。", "conclusion": "本研究确定了最佳的多代理协同设置，并为未来在网络安全领域中的 LLM 代理研究奠定了基础。为了促进研究进展，作者将 CTFTiny 和 CTFJudge 开源并公开发布。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05696", "html_url": "https://arxiv.org/abs/2508.05696", "title": "Log2Sig：基于多变量行为信号分解的频率感知内部威胁检测", "title_en": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition", "authors": "Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng", "background": "内部威胁检测面临巨大挑战，因为恶意行为往往模仿合法用户操作。现有方法通常将系统日志视为扁平事件序列，无法捕捉用户行为中存在的频率动态和多尺度干扰模式。", "innovation": "提出了Log2Sig，一种鲁棒的异常检测框架，通过将用户日志转换为多变量行为频率信号，引入了用户行为的新表示形式。Log2Sig利用多变量变分模态分解（MVMD）提取惯性模态函数（IMFs），揭示了多时间尺度的行为波动。该模型进一步对行为序列和频率分解信号进行联合建模：使用Mamba基础的时间编码器编码每日行为序列以捕捉长期依赖性，而相应的频率分量线性投影以匹配编码器的输出维度。这些双视图表示方式结合构建了用户行为概况，并输入多层感知器进行精准异常检测。", "conclusion": "实验结果表明，Log2Sig在准确性和F1得分方面显著优于最先进的基准方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05702", "html_url": "https://arxiv.org/abs/2508.05702", "title": "语义推理与数值精度的融合：一种基于大语言模型的多智能体系统在电力系统控制中的应用", "title_en": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control", "authors": "Yan Zhang", "background": "随着分布式能源资源（DERs）、电动汽车（EVs）的普及以及极端天气事件的增加，电网的规划、操作和管理变得越来越复杂。传统的基于规则的系统和数值优化方法难以应对现代电网所需的规模、动态性和适应性。", "innovation": "本文提出了Grid-Agent，这是一种自主的、基于人工智能的框架，结合了大型语言模型（LLMs）和多智能体强化学习，能够实时检测和修复电网违规。该框架通过模块化的智能体架构进行语义推理和数值精确度的融合，实现了对智能电网的协调违规解决。此外，Grid-Agent还集成了自适应多尺度网络表示，能够根据不同网络大小和复杂度动态选择最优编码方案，并具备持续学习与适应的功能。", "conclusion": "实验结果显示，Grid-Agent在标准IEEE和CIGRE测试系统（IEEE 69-母线、CIGRE MV和IEEE 30-母线）中表现出优异的违规缓解性能。框架的自适应和数据学习能力使其特别适合作用于现代智能电网，需要快速应对动态运行条件的应用场景。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05705", "html_url": "https://arxiv.org/abs/2508.05705", "title": "一种基于生理约束的神经网络数字孪生框架，用于复制1型糖尿病中的血糖动态", "title_en": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes", "authors": "Valentina Roquemen-Echeverri,Taisa Kushner,Peter G. Jacobs,Clara Mosquera-Lopez", "background": "对于1型糖尿病（T1D）患者，模拟其血糖动态对于开发个性化的治疗方法和支持数据驱动的临床决策至关重要。现有的模型往往忽略了一些关键的生理方面，并且难以进行个性化调整。", "innovation": "本研究提出了基于生理约束的神经网络（NN）数字孪生模型来模拟T1D中的血糖动态。首先构建了一个与一阶导数方程（ODEs）一致的群体级NN状态空间模型，该模型经过正式验证，符合已知的T1D动力学。然后通过增加包含个人特定数据（如血糖管理及上下文信息的个体模型），捕捉了个体间的差异性和个体内的可变性，从而构建了数字孪生模型。", "conclusion": "通过实际数据验证，该方法在T1D患者的糖化结果中表现良好，模拟结果与实际观察数据在时间在线性范围内（70-180 mg/dL）、低于范围（<70 mg/dL）和高于范围（>180 mg/dL）的时间百分比上具有统计学意义的相似性。该框架可以适用于整合未模型化的因素（如睡眠和活动），同时保持关键的动态特性。此方法能够实现个性化的体内数字试验，支持胰岛素优化，并将基于物理和数据驱动的建模进行整合。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05700", "html_url": "https://arxiv.org/abs/2508.05700", "title": "为Pinterest广告排名设计的多方面大规模嵌入表", "title_en": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking", "authors": "Runze Su,Jiayin Jin,Jiacheng Li,Sihan Wang,Guangtong Bai,Zelun Wang,Li Tang,Yixiong Meng,Huasen Wu,Zhimeng Pan,Kungang Li,Han Sun,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "现代推荐系统中大规模嵌入表对于捕捉和存储实体之间复杂互动的关键细节至关重要。在将大规模嵌入表引入Pinterest的广告排序模型时，我们不仅遇到了稀疏性和可扩展性等常见挑战，还遇到了一些特定于我们上下文的独特障碍。最初尝试从零训练大规模嵌入表导致了中立的评估指标。为了应对这个问题，我们引入了一种新颖的多方面预训练方案，该方案结合了多种预训练算法，极大地丰富了嵌入表并显著提高了性能。这一多方面的大型嵌入表在点击率（CTR）和转化率（CVR）等多个领域都带来了显著的性能提升。此外，我们设计了一种CPU-GPU混合服务架构来解决GPU内存限制并提升可扩展性。该框架部署在Pinterest广告系统中，在不改变端到端延迟的情况下，实现了1.34%的在线点击价格（CPC）减少和2.60%的CTR提升。", "innovation": "一种新颖的多方面预训练方案，结合了多种预训练算法。该方案通过丰富的嵌入表提高了性能，显著提升了Pinterest广告系统的点击率（CTR）和转化率（CVR）。此外，设计了一种CPU-GPU混合服务架构，解决了广告系统中GPU内存限制的问题，提升了系统可扩展性。", "conclusion": "多方面的大规模嵌入表在点击率（CTR）和转化率（CVR）上带来了显著性能增益。此外，通过引入CPU-GPU混合服务架构，克服了广告系统中的GPU内存限制，提高了系统可扩展性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05694", "html_url": "https://arxiv.org/abs/2508.05694", "title": "DMFI：基于双模态微调和推理框架的LLM内幕威胁检测", "title_en": "DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection", "authors": "Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Guanggang Geng,Zhiying Li,Jian Weng", "background": "内幕威胁检测(Insider Threat Detection, ITD)在网络安全领域是一个持续且高影响的挑战，因为恶意内部行为具有细微、长期且依赖上下文的特点。传统的模型往往难以捕捉语义意图和复杂的动态行为，现有的基于LLM的方法在提示的适应性和模态覆盖方面也存在局限。DMFI通过引入双模态框架，结合语义推理和行为感知的微调方法来解决这一问题。DMFI将原始日志转换为两种结构化的视图，分别为富含内容的语义视图和通过引导（When-Where-What-Which）转换构建的行为抽象，后者用于编码上下文动作序列。通过轻量级的MLP决策模块融合两个增强LoRA的LLM的输出，进一步通过区分性适应策略DMFI-B来区分正常和异常行为表示，提高在严重类别不平衡情况下的鲁棒性。DMFI在CERT r4.2和r5.2数据集上的实验结果表明，其检测准确性优于现有最先进的方法。我们的方法结合了LLM的语义推理能力和结构化行为建模，为实际的内幕威胁检测提供了可扩展且有效的方法。我们的工作展示了将LLM推理与结构化行为建模相结合的有效性，为现代内幕威胁检测提供了一个可扩展且部署方案。", "innovation": "DMFI引入了双模态框架，结合了语义推理和行为感知的微调方法。具体而言，DMFI通过指引格式化的提示处理内容丰富的日志，通过引导转换构建行为抽象。同时，通过轻量级的MLP决策模块融合两个增强LoRA的LLM输出，以及引入区别性适应策略DMFI-B来区分正常和异常行为表示，解决了现有方法在提示适应性和类别不平衡上的不足。", "conclusion": "DMFI结合了LLM的语义推理能力和结构化行为建模，提高了检测准确性和鲁棒性。这种方法为实际的内幕威胁检测提供了可扩展且有效的方法，提供了将语义推理与行为建模相结合，实现现代内幕威胁检测的效果验证。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05710", "html_url": "https://arxiv.org/abs/2508.05710", "title": "Klear-CodeTest: 这是一个可扩展的代码强化学习测试案例生成框架", "title_en": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "authors": "Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou", "background": "在代码增强学习中，准确且正确的反馈对大型语言模型（LLMs）的有效训练至关重要，但高质量测试案例的合成仍然是一个困难且尚未解决的问题。当前的问题在于生成全面覆盖编程问题的高质量测试案例具有挑战性，尤其是在确保测试案例的质量和可靠性方面存有难度。因此，需要一种不仅能生成全面测试案例，还能确保这些测试案例正确性的有效框架来解决这些问题。", "innovation": "本文介绍了一种名为Klear-CodeTest的综合测试案例合成框架，其中包含严格的验证机制以确保测试案例的质量和可靠性。该框架通过一种新颖的Generator-Validation（G-V）框架实现广泛的编程问题覆盖，并通过一致验证机制验证输出与标准解的一致性。此外，该框架还能够生成全面的测试案例，包括常规和边界情况，以增强测试覆盖率和解决方案正确性评估的区分度。这项工作还设计了一套多层安全沙盒系统，以确保在线验证平台上的安全和可靠代码执行。实验表明，所构建的数据集有效提升了模型性能和培训稳定性，验证了该框架的创新性与实用性。", "conclusion": "本文通过全面的实验展示了Klear-CodeTest的效用，表明其在模型性能和培训稳定性方面带来了显著改善。代码、数据集和沙盒系统均可在指定链接处获取。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05664", "html_url": "https://arxiv.org/abs/2508.05664", "title": "增强电力行业客户服务的检索增强生成", "title_en": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "authors": "Hei Yu Chan,Kuok Tou Ho,Chenglong Ma,Yujing Si,Hok Lai Lin,Sa Lei Lam", "background": "许多AI客服系统使用标准的NLP流程或微调的语言模型，但在处理模糊、多意图或具体细节查询时经常表现不佳。本文以电力行业为例，评估了查询重写、RAG融合、关键词增强、意图识别和上下文重排序等技术，以构建一个强大的客服支持系统。研究表明查询重写对于使用非标准术语或需要精确细节的查询有提高检索的效果。RAG融合通过合并多个检索结果，提高了模糊或复杂查询的性能。重排序通过过滤无关上下文减少了幻觉。意图识别支持将复杂问题分解为更具体的子查询，提高了相关性和效率。关键字增强因关键词选择偏差的影响对结果不利。最终系统结合了意图识别、RAG融合和重排序，以处理歧义和多源查询。", "innovation": "本文评估了查询重写、RAG融合、关键词增强、意图识别和上下文重排序等技术，并最终选择了基于图的RAG框架以处理复杂查询。通过这些技术，构建的系统在GPT-4生成的数据集和实际的电力提供商常见问题解答数据集上分别取得了97.9%和89.6%的准确率，显著优于基础RAG模型。", "conclusion": "综合使用意图识别、RAG融合和重排序等技术，最终系统能够有效处理电力行业的复杂查询，提高客服系统的准确性和效率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05755", "html_url": "https://arxiv.org/abs/2508.05755", "title": "UnGuide：在LoRA引导下的学习忘记", "title_en": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models", "authors": "Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek", "background": "大规模文本到图像的扩散模型近期取得了显著进展，但也引发了对其潜在滥用的担忧，尤其是在生成有害或误导性内容方面。这突显了有效机器遗忘的迫切需求，即在不损害整体性能的前提下从预训练模型中移除特定知识或概念。一种可能的方法是低秩适应（LoRA），它提供了一种高效的方法来针对特定遗忘对模型进行微调。然而，LoRA常常无意中改变了无关的内容，导致图像的保真度和现实感下降。", "innovation": "本文介绍了一种新的方法UnGuide，它结合了UnGuidance，这是一种动态推理机制，利用分类器自由指导（CFG）对遗忘过程进行精确控制。UnGuide根据去噪过程最初几步的稳定性调整指导尺度，通过LoRA适配器实现选择性遗忘。对于包含被擦除概念的提示，LoRA模块占主导地位并可被基模型平衡；对于无关的提示，基模型控制生成，保持内容的保真度。实验结果表明，UnGuide能够实现受控的概念移除，并保留扩散模型的表达能力，在物体擦除和具体内容移除任务中均优于现有的基于LoRA的方法。", "conclusion": "UnGuide通过调整LoRA适配器来实现选择性遗忘，既遗忘了特定概念又保留了图像的真实性和可靠性，特别在物体擦除和具体内容移除任务中表现优异。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05783", "html_url": "https://arxiv.org/abs/2508.05783", "title": "在脑成像任务中预训练MRI转换器的少样本部署", "title_en": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks", "authors": "Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang", "background": "机器学习使用转换器在医学影像领域展现了巨大的潜力，但由于标注数据稀缺，其在实际应用中的效果受到限制。研究人员提出了一种实用框架，在多样化的脑影像任务中部署预训练的MRI转换器。通过在包含超过3100万脑MRI切片的大型多队列数据集上利用掩码自动编码器（MAE）预训练策略，获得了高度迁移的潜在表示，这些表示在多种任务和数据集上都能很好地泛化。对于高级任务如分类，冻结的MAE编码器与轻量级线性头结合，可实现磁共振成像序列识别的最先进精度，只需少量监督。对于低级任务如分割，研究人员提出了MAE-Funet混合模型，将多尺度CNN特征与预训练的MAE嵌入结合，该模型在数据受限条件下，无论是在去头皮处理还是多分类解剖分割上，都优于其他强基线模型。", "innovation": "研究提出了适用于多样化脑影像任务的预训练MRI转换器的少样本部署框架。开发了融合预训练MAE嵌入和多尺度CNN特征的混合模型MAE-Funet，该模型在数据受限条件下表现出色。", "conclusion": "通过大量定量和定性评估，该框架展示了高效率、稳定性和可扩展性，表明其适用于资源有限的临床环境和更广泛的神经影像应用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05838", "html_url": "https://arxiv.org/abs/2508.05838", "title": "采用视觉基础模型与强化学习增强物体交互", "title_en": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "authors": "Ahmad Farooq,Kamran Iqbal", "background": "介绍了将视觉基础模型与强化学习结合以增强模拟环境中物体交互能力的新方法。该方法结合了Segment Anything Model (SAM)、YOLOv5和Proximal Policy Optimization (PPO)代理，在AI2-THOR的模拟环境中实现了更好的物体感知和交互能力。", "innovation": "该研究提出了一种创新方法，通过将Segment Anything Model (SAM)和YOLOv5视觉模型与Proximal Policy Optimization (PPO)代理结合，在AI2-THOR仿真环境中实现更有效的物体感知和交互。实验结果表明，相较于没有高级感知的基线代理，物体交互成功率提高了52.5%，平均累计奖励提高了68%，导航效率提高了33%，展示了基础模型与强化学习结合在复杂机器人任务中的潜力，为更高级和更有能力的自主代理铺平了道路。", "conclusion": "研究结果表明，结合基础模型和强化学习可以显著提升物体交互的成功率和导航效率，为复杂机器人任务提供了新的解决方案，促进了更高级的自主代理的发展。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05799", "html_url": "https://arxiv.org/abs/2508.05799", "title": "由AI引导的大规模代码库探索", "title_en": "AI-Guided Exploration of Large-Scale Codebases", "authors": "Yoseph Berhanu Alebachew", "background": "理解和分析大型且复杂的软件系统是开发者面临的主要挑战之一，他们花费大量时间进行程序理解。传统的工具如静态可视化和逆向工程能提供结构上的见解，但常常缺乏互动性、适应性和与上下文信息的整合。近年来，大型语言模型（LLMs）的发展为增强代码探索流程提供了新机会，但其缺乏具体性以及与结构化视图的集成限制了其有效性。", "innovation": "本文提出了一种结合确定性逆向工程和AI引导的意图感知可视化探索的混合方法。所提系统结合了基于UML的可视化、动态用户界面、历史上下文和协作功能，为代码理解提供了自适应工具。通过解释用户的查询和交互模式，AI帮助开发者更有效地导航和理解复杂的代码库。一种针对Java的原型实现展示了这种方法的可能性。未来的工作将包括实证评估、面向多语言系统的扩展以及探索基于GUI的AI互动模型的研究。", "conclusion": "这项研究为符合开发者认知模式和协作工作流程的智能、交互式环境奠定了基础。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05846", "html_url": "https://arxiv.org/abs/2508.05846", "title": "朝向透明的伦理AI：值得信赖的机器人系统的路线图", "title_en": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems", "authors": "Ahmad Farooq,Kamran Iqbal", "background": "随着人工智能（AI）和机器人技术日益渗透到社会各个领域，确保这些系统的道德行为变得非常重要。本文认为，透明地揭示AI决策过程是开发可信且与伦理相一致的机器人系统的必要条件。", "innovation": "本文探讨了透明性如何促进问责制、促进知情同意，并支持道德算法的调试。论文提出了实施透明性的技术、伦理和实践挑战，并提出了一系列新颖的方法，包括标准化度量、可解释AI技术和用户友好的界面。此外，论文提出了一种框架，将技术实施与机器人的伦理考虑相结合，特别是在动态、现实世界环境中实现透明的具体挑战。", "conclusion": "通过对透明性的优先考虑如何影响公众信任、监管政策和未来研究路径的分析，本文旨在通过将透明性置于伦理AI系统设计的核心要素，为负责任的AI和机器人研究的持续讨论提供方向，并为这一重要领域的未来进步提供指导。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05880", "html_url": "https://arxiv.org/abs/2508.05880", "title": "大型语言模型是否具备情感思维？基于认知评价分析", "title_en": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models", "authors": "Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang", "background": "情感计算已成为推动人工智能系统全面发展的关键研究领域。过去的研究通常通过监督方式评估或训练大规模语言模型（LLMs）来更好地预测或生成情感，这些研究大多集中在识别或表达情感的标准任务上。但这些任务关注的是表面级别的情感，缺乏深入探讨LLMs在处理情绪时所使用的认知结构。本研究试图利用认知评价理论，评估LLMs是如何通过认知维度进行情绪推理的，并引入了大规模的认知评价情感基准（CoRE）来检查LLMs在处理情绪情绪化刺激时是否产生一致和合理的认知推理。", "innovation": "本研究引入了大规模的情感认知推理基准（CoRE），创新性地评估了LLMs在处理情绪时使用的情感认知结构，探讨了模型是否更倾向于依赖特定的认知评价维度，特定情绪的认知维度的重要性，以及不同情感类别在LLMs中的内部表示能否通过认知评价维度进行解释。", "conclusion": "研究结果表明，不同的LLMs在处理情感时存在不同的推理模式。研究的数据和分析揭示了LLMs在情感推理中的多样性。研究结果和基准测试代码将公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05791", "html_url": "https://arxiv.org/abs/2508.05791", "title": "从不完美信号到可信赖结构：不一致性异构且可靠性各异的公用事业数据的置信度感知推断", "title_en": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data", "authors": "Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu", "background": "准确的配电网拓扑对于现代电力系统的可靠运行至关重要。然而，实际中的电能数据源自多个不同的来源，具有不同的特性和质量水平。本研究与Oncor Electric Delivery合作开发了一个可扩展的框架，通过系统地整合异构数据来重建可靠的电网拓扑。研究发现，配电网的基本布局同时受到两个互补维度的共同控制：空间上基础设施的布局（如地理信息系统和资产元数据）和信号域中的系统动态行为（如电压时序数据）。", "innovation": "该研究提出了一种置信度感知的推断机制，该机制在不牺牲可观测性的情况下，保留了虽不完美但仍具有结构信息的输入，同时量化每个推断连接的可靠性，供操作员解读。研究还嵌入了操作约束（如变压器容量限制和辐射型拓扑要求）到学习过程中，确保推断是同时具有不确定性和结构有效性，从而在现实环境部署下迅速收敛到可操作和可靠的拓扑结构。通过使用Oncor服务区域内3条馈线超过8000米的数据验证，该框架在拓扑重建方面达到了95%以上的准确性，并在置信度校准和计算效率方面相较于基线方法有显著提高，证明了上述创新的有效性和实用性。", "conclusion": "本研究提出的框架在现实部署条件下能够迅速收敛到可操作的、可靠的拓扑结构。通过在Oncor服务区域内8000多米线路的数据验证，证明了该框架在拓扑重建方面的高准确度，并且具有显著的置信度校准和计算效率改进。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05913", "html_url": "https://arxiv.org/abs/2508.05913", "title": "道德AI原则对用户重要吗？大规模用户情感和满意度分析", "title_en": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "authors": "Stefan Pasch,Min Chul Cha", "background": "随着AI系统在组织工作流程和消费者应用中的嵌入日益广泛，公平性、透明度和稳健性等伦理原则已经在政策和行业指南中得到了广泛认可。然而，关于这些原则是否从用户的角度被认可、重视或产生影响，仍缺乏实证证据。本研究通过分析超过100,000条来自G2的AI产品用户评论，探索了道德AI与用户满意度之间的联系。", "innovation": "本研究使用基于转换器的自然语言模型，测量了七个由欧盟可信AI伦理指南定义的伦理维度在用户评论中的情感。研究发现所有七个维度都与用户满意度正相关，但这种关系根据不同用户和产品类型存在系统性差异。对技术用户和AI开发平台的评论者更关注系统层面的担忧，而非技术人员和最终用户应用评论者则更关注以人为本的维度。此外，成本AI与用户满意度之间的关系在所有维度上对于非技术人员和最终用户应用都更强。这些结果突显了用户视角下道德AI设计的重要性，并强调了不同用户角色和产品类型之间需要考虑的背景差异的重要性。", "conclusion": "本研究结果证明了从用户视角考虑伦理AI设计的重要性，并强调了根据不同用户和产品类型考虑情境差异的必要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05933", "html_url": "https://arxiv.org/abs/2508.05933", "title": "REFS: 基于缺失多维度注释的稳健EEG特征选择方法以情感识别", "title_en": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition", "authors": "Xueyuan Xu,Wenjia Dong,Fulin Wei,Li Zhuo", "background": "情感脑-机接口是一种关键技术，对于情感交互和情绪智能具有重要意义，已成为人机交互领域的研究热点。多类型EEG特征能够提供多层次的情感分析表示，但其高维度问题及少量高质量EEG样本限制了多维度情感识别的分类器性能和实时性。在开放的采集环境中，情感标签的缺失以及个体间情绪感知的模糊和变异性，使得情感脑-机接口的实际应用面临挑战。", "innovation": "本文提出了一种新颖的EEG特征选择方法，旨在解决多维度情感识别中的缺失标注问题。该方法利用自适应正交非负矩阵分解来通过二阶和高阶相关性重建情感标签空间，减少缺失值和异常值对标签重建的负面影响。同时，结合基于图的流形学习正则化和全局特征冗余最小化正则化，即使在缺失信息的情况下也能进行EEG特征子集选择，最终实现了稳健的基于EEG的多维度情感识别。", "conclusion": "实验证明，所提出的方法在三个广泛使用的多维度情感数据集（DREAMER、DEAP和HDED）上表现优于其他十三种先进的特征选择方法，尤其是在EEG情感特征选择的鲁棒性方面。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05934", "html_url": "https://arxiv.org/abs/2508.05934", "title": "ASLSL: 适应性共享潜在结构学习在处理不完整多模态生理数据中的多维度情感特征选择", "title_en": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "authors": "Xueyuan Xu,Tianze Yu,Wenjia Dong,Fulin Wei,Li Zhuo", "background": "近年来，基于多模态生理信号的情感识别在脑机接口领域备受关注。然而，相关的多模态生理特征往往高维且包括无关、冗余和噪声信息，可能导致情感分类器过拟合、性能不佳和高计算复杂度。尽管特征选择方法广泛应用于解决这些问题，但先前的研究通常假设多模态生理数据是完整的，而在实际中，由于采集和操作环境的开放性，实际数据往往是不完整的。例如，某些样本可能只在某些模态中可用，而不一定在所有模态中都可用。", "innovation": "本文提出了一种新颖的方法，称为适应性共享潜在结构学习（ASLSL），用于处理不完整的多模态生理信号的情感特征选择。ASLSL基于相似特征具有相似情感标签的特性，利用适应性共享潜在结构学习探索一个共同的潜在空间，适用于不完整的多模态生理信号和多维度情感标签。该方法旨在缓解缺失信息的影响并提取一致信息。通过使用DEAP和DREAMER两个最流行的多模态生理情感数据集进行比较实验，证明了ASLSL的有效性。", "conclusion": "全面的实验结果证明了ASLSL的有效性，并表明该方法能够更有效地处理不完整多模态生理数据中的多维度情感特征选择，从而提高情感识别的准确性和鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05938", "html_url": "https://arxiv.org/abs/2508.05938", "title": "玩家游戏聊天中的亲社会行为检测：从对齐人类和AI定义到大规模高效标注", "title_en": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "authors": "Rafal Kocielnik,Min Kim,Penphob(Andrea)Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez", "background": "在信任和安全系统中，识别文本中的亲社会性（如肯定、支持或改进他人行为的交流）是一项新颖且日益重要的挑战。与有害内容检测相比，亲社会性缺乏明确的定义和标注数据，需要新的标注和部署方法。", "innovation": "提出了一种实用的三阶段管道，用于实现高精度的亲社会内容分类，同时减少人力标注努力和推理成本。该方法包括使用少量种子标注示例确定最佳语言模型（LLM）标注策略，引入人类-AI校正循环来澄清和扩展任务定义，以及使用GPT-4合成高质量标签并训练一个两阶段推理系统，从而大幅降低推理成本并达到高精度。", "conclusion": "该管道展示了通过有针对性的人机互动、精细的任务描述和部署导向的架构设计，解锁新型负责任AI任务的可扩展解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05957", "html_url": "https://arxiv.org/abs/2508.05957", "title": "基于多臂bandit的决策树优化", "title_en": "Multi-Armed Bandits-Based Optimization of Decision Trees", "authors": "Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman", "background": "决策树容易因为缺乏适当的约束而变得过于复杂，容易过拟合，捕捉噪音而非可泛化的模式。传统的剪枝技术，如代价复杂性剪枝（CCP）和错误减少剪枝（REP），大多是基于贪婪的方法，关注于剪枝过程中立竿见影的性能提升，但长期来看可能降低泛化能力，特别是在使用小型复杂数据集进行训练时，这损害了树模型对未见过的数据样本的鲁棒性。", "innovation": "提出了一种基于多臂bandit的剪枝方法，这是一种基于强化学习的技术，能够动态地剪枝决策树，以生成泛化能力更强的决策树。该方法将剪枝过程视为探索-利用问题，利用MAB算法根据每次剪枝动作的反馈信息找到最优分支节点进行剪枝，从而优化决策树模型。实验结果表明，该方法在多个基准数据集上的预测性能优于传统方法，显示出利用MAB进行动态且概率性的决策树剪枝的潜力。", "conclusion": "研究成果表明基于MAB的决策树剪枝方法能够优化决策树模型的泛化能力，并在多种数据集上表现优越。未来的研究可以探索在不同数据类型的广泛场景中进一步验证其有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05954", "html_url": "https://arxiv.org/abs/2508.05954", "title": "Bifrost-1: 通过 patch-level CLIP 潜变量连接多模态大语言模型和扩散模型", "title_en": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "authors": "Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal", "background": "目前，人们正在研究如何在不降低大语言模型（LLMs）的强大推理能力的前提下，将高保真视觉合成能力集成到LLMs中。现有方法直接训练LLMs或通过LLMs和扩散模型之间的桥梁进行训练，这类方法通常会导致训练成本高昂，因为预训练中的LLMs没有见过图像表示。因此，需要一种新的方法来实现高效且能保留在多模态推理能力的图像生成。", "innovation": "本文提出了Bifrost-1框架，该框架通过patch-level CLIP图像嵌入将预训练多模态LLMs（MLLMs）与扩散模型连接起来。这些patch-level图像嵌入通过轻量级的ControlNet调整方法集成到扩散模型中。此外，当预测patch-level图像嵌入时，预先训练的MLLM被赋予一个从原始MLLM参数初始化的视觉生成分支，以保留其多模态推理能力。这种方法通过无缝集成预先训练的MLLM和扩散模型与patch-level CLIP潜变量，使得图像生成既保真又可控，并且训练效率大幅提升。实验表明，Bifrost-1在视觉质量和多模态理解上达到或超过了以前的方法，并且在训练时所需的计算量显著降低。此外，通过全面的消融研究展示了这些设计选择的有效性。", "conclusion": "Bifrost-1框架通过无缝结合预先训练的多模态大语言模型与扩散模型，利用patch-level CLIP潜变量实现了高效且保真的可控制图像生成。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05950", "html_url": "https://arxiv.org/abs/2508.05950", "title": "从单张图像进行法线估计的3DGS-扩散自监督框架", "title_en": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image", "authors": "Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li", "background": "单张图像中的空间维度信息缺乏仍然是法线估计的一个挑战。最近的基于扩散的方法在2D到3D隐式映射方面展现了显著的潜力，但它们依赖于数据驱动的经验先验，而忽略了灯光与表面交互的显式建模，导致多视图法线方向冲突。此外，扩散模型的离散采样机制在可微渲染重构模块中引起梯度不连续，阻止3D几何错误被反向传播到法线生成网络，使得现有方法不得不依赖密集的法线标注。", "innovation": "本文提出了一种新颖的单张图像法线估计自监督框架，SINGAD（Self-supervised framework from a single Image for Normal estimation via 3D GAussian splatting guided Diffusion）。通过结合物理驱动的光交互建模和基于可微渲染的重新投影策略，该框架直接将3D几何误差转化为法线优化信号，解决了多视图几何不一致性和数据依赖性等挑战。具体来说，该框架构建了一个由光交互驱动的3DGS参数化模型，生成与光照传输原理一致的多尺度几何特征，确保多视图法线的一致性。同时，设计了一个跨域特征融合模块，嵌入几何先验来约束法线生成，保持几何误差传递的精确性。此外，还引入了一种可微渲染损失策略，实现自监督优化，最小化重构图像与输入图像之间的几何误差，不再依赖标注的正常数据集。", "conclusion": "定量评估Google Scanned Objects数据集的结果表明，该方法在多个指标上优于现有最先进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05960", "html_url": "https://arxiv.org/abs/2508.05960", "title": "离线强化学习中轻度保守正则化评估", "title_en": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning", "authors": "Haohui Chen,Zhiyong Chen", "background": "离线强化学习（RL）旨在从静态数据集中学习最优策略，而无需进一步的环境交互。一个关键挑战是通过训练学习出的策略与行为策略之间的分布差异，这会导致超出分布（OOD）的行为和过度估计。为了防止严重的过度估计，价值函数必须保持保守性；然而，过度保守可能阻碍性能的提升。因此，为了缓解这一问题，该研究提出了一种轻度保守正则化评估（MCRE）框架，通过将时差（TD）错误与行为克隆项结合到贝尔曼备份中，来平衡保守性和性能。在此基础上，该研究还开发了轻度保守正则化Q学习（MCRQ）算法，将MCRE整合进一个离政策的演员-评论家框架中。实验表明，MCRQ在基准数据集上的表现优于强大的基准和最先进的离线RL算法。", "innovation": "该研究提出了MCRE框架，通过结合TD错误与行为克隆项来平衡保守性与性能。在此基础上，开发了MCRQ算法，成功提升了离线强化学习的性能。", "conclusion": "实验结果显示，MCRQ在基准数据集上的表现超过了强大的基准和最先进的离线RL算法，表明了MCRE框架和MCRQ算法的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05970", "html_url": "https://arxiv.org/abs/2508.05970", "title": "基于影响的跨文件代码完成上下文过滤", "title_en": "Impact-driven Context Filtering For Cross-file Code Completion", "authors": "Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu", "background": "检索增强生成（RAG）在库级代码补全方面展示了显著潜力，因为它能够将跨文件知识结合到当前文件之前的代码中，提供全面的生成上下文。尽管检索了大量的代码片段，但只有少部分片段对生成有正面贡献，有时甚至是负面作用。为此，研究旨在通过概率分析揭示每个检索片段对生成的影响，并构建一个基于此构建的数据集，用于训练自适应检索上下文过滤框架CODEFILTER。", "innovation": "引入了基于概率的度量来评估每个检索代码片段对补全的影响。基于此度量构建了一个仓库级别的数据集，将每个检索片段标记为正向、中性或负向。开发了自适应检索上下文过滤框架CODEFILTER，该框架在没有过滤操作的情况下，能够在各种任务中提高代码补全的准确性，并减少输入提示的长度，提高计算效率和模型的通用性。", "conclusion": "CODEFILTER提高了跨文件代码补全的准确性、效率和可追溯性，在不同模型上表现出强大的通用性。这项研究表明，CODEFILTER能够有效提升库级代码补全的效果，并优化代码补全过程中的资源利用率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05991", "html_url": "https://arxiv.org/abs/2508.05991", "title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "title_en": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "authors": "Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong", "background": "情绪识别在增强人机交互方面发挥着重要作用。在MER2025比赛中，为解决数据稀缺问题，研究团队提出了一个新颖的多模态情绪识别框架。该框架通过使用大规模预训练模型从视觉、音频和文本模态中提取信息特征，专门针对MER-SEMI挑战进行了设计和优化。", "innovation": "该研究创新地设计了一种双分支视觉编码器，可以捕捉全局帧级特征和局部面部表示。在文本模态方面，提出了利用大型语言模型丰富输入文本中情感线索的方法。进一步，提出了融合策略，包括自注意机制以实现动态模态加权，并通过残差连接保持原始表征。此外，还采用多源标签策略进一步完善了训练集中的嘈杂标签。这种方法在MER2025-SEMI数据集上取得了显著的性能改进，表明所提出的框架的有效性。", "conclusion": "与官方基线相比，该方法使权重F分数提高了87.49%，相较于78.63%，证实了该框架的效能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05979", "html_url": "https://arxiv.org/abs/2508.05979", "title": "通过教学进行学习：将学生培养为计算机科学教育中大型语言模型的讲师", "title_en": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education", "authors": "Xinming Yang,Haasil Pujara,Jun Li", "background": "在计算机科学（CS）教育中，大型语言模型（LLMs）通常作为虚拟导师使用，但这可能导致被动学习和过度依赖。因此，该研究提出了一种新的教学范式，即学生需要充当讲师，通过教LLM解决具体问题来推动学习。研究者开发了设计包含学生能够填补的知识缺口问题的策略，并引入了Socrates系统，该系统能以最小的开销部署此方法。这种教学方法在本科生课程中的评估表明，它带来了比历史同期学生更高的统计学意义上的学业进步。该研究证明，利用LLMs提高学生参与度和掌握度的实践框架是具体和成本效益高的。", "innovation": "提出了新的教学模式，即让学生教授大语言模型解决问题，通过设计包含学生能够填补的知识缺口的问题来促进主动学习和提高学生参与度。开发了Socrates系统，能够以最小的开销部署此方法。研究表明这种方法能带来统计学意义上的学生学业进步。", "conclusion": "通过设计具有学生能填补的知识缺口的提问策略并引入Socrates系统，提出了一种实际且成本效益高的利用大语言模型以促进学生深度参与和掌握的教学框架。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05989", "html_url": "https://arxiv.org/abs/2508.05989", "title": "ETA: 基于能量的测试时自适应方法在深度完成中的应用", "title_en": "ETA: Energy-based Test-time Adaptation for Depth Completion", "authors": "Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong", "background": "深度完成模型在被转移到新的环境条件下的新数据时，由于协变量转移，常常会产生错误的输出。现有方法通常依赖事先获取的目标数据分布假设，但这种方法在实际部署前缺乏目标数据。因此，该研究提出了一种基于能量的测试时自适应方法（ETA），通过利用对抗性扰动来探索数据空间，量化深度预测属于源数据分布的可能性，从而改善测试时的深度预测结果。", "innovation": "该方法通过对抗性扰动来探索数据空间，并利用能量模型对局部深度预测进行评分，区分内分布和外分布。在更新预训练深度完成模型参数以最小化能量，从而让测试时预测更接近源分布。这一创新点解决了部署前缺乏目标数据的难题，有效提高了深度完成模型在不同环境条件下的适应性和预测准确性。", "conclusion": "该方法在三个室内数据集和三个室外数据集上的评估结果表明，整体平均提升效果显著，室外场景提升6.94%，室内场景提升10.23%，有效提升了现有最佳方法的性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06000", "html_url": "https://arxiv.org/abs/2508.06000", "title": "手牵手：通过EMS辅助进行操作技能学习的LLM驱动", "title_en": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning", "authors": "Wei Xiang,Ziyue Lei,Haoyuan Che,Fangyuan Ye,Xueting Wu,Lingyun Sun", "background": "操作技能的学习本质上是身体的和依赖于实际操作和动觉反馈，目前还没有被大规模语言模型（LLM）支持的培训有效复制。当前的LLM培训助手主要生成定制的文本反馈，忽视了动觉这一关键的感官模式。这一差距源自于LLM的文本性和不确定性，以及用户对由LLM驱动的体动控制的接受度问题。", "innovation": "本研究探索了由LLM驱动的动觉辅助的人机协作体验。引入了“对齐-分析-调整”策略，并开发了FlightAxis，这是一种将LLM与电肌肉刺激（EMS）结合的工具用于飞行技能获取。FlightAxis从手册中学习飞行技能，并在模拟飞行任务中指导前臂运动。实验结果显示，人们对LLM驱动的体动控制有着很高的接受度，并且大大缩短了任务完成时间。学员报告称，这种动觉辅助提高了他们对操作错误的意识，并促进了他们在培训过程中更深层次的参与，而非减少感知的工作负担。", "conclusion": "本研究表明，动觉LLM培训在操作技能获取中具有很大潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05923", "html_url": "https://arxiv.org/abs/2508.05923", "title": "通过遗传算法进行自适应测试输入生成以增强软件漏洞检测", "title_en": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "authors": "Yanusha Mehendran,Maolin Tang,Yi Lu", "background": "软件漏洞持续影响着现代系统可靠性与安全性，尤其是软件复杂性超过了传统检测方法的能力。这促使研究人员寻求更有效的方法来发现这些漏洞。", "innovation": "提出了一种基于遗传算法的测试输入生成方法，该方法创新性地整合了遗传操作符和自适应学习，通过交叉操作符进行全方位探索，并通过自适应反馈机制指导输入生成，从而开发出更有效的测试案例。", "conclusion": "该方法在九个开源JSON处理库的评估中表现卓越，覆盖率平均提高了39.8%，在方法覆盖率、行覆盖率、指令覆盖率和分支覆盖率上分别提高了62.4%、105.0%、114.0%和166.0%。这些结果表明该方法能够检测更深层和更复杂的漏洞，提供了一种可扩展且适应性强的软件安全性测试解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06016", "html_url": "https://arxiv.org/abs/2508.06016", "title": "清晰的注意力：通过结构化稀疏性正则化变换器", "title_en": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "authors": "Sagar Gandhi,Vishal Gandhi", "background": "自注意力机制的计算成本呈二次增长，这在扩展Transformers模型时是一个主要挑战。虽然注意力稀疏性作为一种提高计算效率的技术得到了广泛的研究，但普遍认为它会以牺牲模型准确性为代价。本文的背景是在SST-2情感分析任务上微调DistilBERT模型时引入结构化后验稀疏性，发现模型的准确性显著提高，提出了稀疏性可能作为一种强大的隐式正则化手段，避免模型过拟合，迫使它使用更受限且更鲁棒的特征集来做出预测的观点。", "innovation": "本文的创新之处在于通过在DistilBERT模型的细调过程中引入结构化后验稀疏性，显著提高了SST-2情感分析任务上的模型准确性。具体来说，80%的注意力稀疏性使得验证准确性达到了91.59%，相比于密集基准提高了0.97%。文章提出稀疏性作为一种强大的隐式正则化手段的观点，并将其视为提高Transformer模型泛化和性能的方法，而不仅仅是计算效率的工具。", "conclusion": "本文的研究重新定义了注意力稀疏性的角色，将其不仅视为一种提高计算效率的工具，而且是一种提升Transformer模型泛化性能和整体性能的方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06026", "html_url": "https://arxiv.org/abs/2508.06026", "title": "时序自我奖励语言模型：通过过去与未来解耦选定与拒绝", "title_en": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "authors": "Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang", "background": "现有自我奖励语言模型通过大型语言模型（LLMs）生成响应并自我评估其输出来逐步提高生成能力。然而，这些模型在同步改进被选和被拒绝的响应时会产生一个关键限制：这会逐步缩小对立样本之间的表示差异，从而削弱有效的偏好学习。本文通过对过去的、当前的和未来的模型生成进行策略性协调，提出了一种时序自我奖励语言模型，以维持学习信号。", "innovation": "本文提出了一种双阶段框架：（1）锚定拒绝——使用过去初始模型的输出来固定被拒绝的响应；（2）未来引导选定——利用下一代模型的预测动态筛选选定样本。该框架在计算资源相同的情况下显著提高了多种模型（Llama、Qwen、Mistral）及其不同规模（Llama3B/8B/70B）的表现，特别是在数学推理、知识问答和代码生成任务中展示了优于传统自我奖励方法的泛化能力，即使没有专门收集相应的训练数据。", "conclusion": "时序自我奖励语言模型通过解耦被选定和被拒绝的响应，实现了对模型生成能力的有效学习改进，即使使用相同计算资源，也能显著超越传统的自我奖励方法，在多个任务上达到了更好的性能，并且具有更强的泛化能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06034", "html_url": "https://arxiv.org/abs/2508.06034", "title": "自适应异质图神经网络：弥合异质性和异质性之间的鸿沟", "title_en": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity", "authors": "Qin Chen,Guojie Song", "background": "异质图（HGs）在现实场景中很常见，并且通常表现出异质性。然而，现有的大多数研究要么单独关注异质性，要么单独关注异质性，忽视了在实际应用中异质性HG的普遍性。这种忽视导致其性能下降。", "innovation": "该工作首先识别了建模异质性HG的两个主要挑战：1）不同跳和元路径间的异质性分布变化；2）不同元路径间语义信息的复杂和经常由异质性驱动的多样性。然后，提出了自适应异质图神经网络（AHGNN）来应对这些挑战。AHGNN使用了对跳和元路径特定的异质性感知卷积，并结合粗到细的注意力机制来综合来自不同语义空间的消息，从而过滤噪声并强调有用的信号。", "conclusion": "在七个真实世界的图和二十个基线上的实验结果表明，AHGNN在性能上优于现有的自适应方法，特别是在高异质性情景中表现出色。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06041", "html_url": "https://arxiv.org/abs/2508.06041", "title": "DP-LLM：基于动态逐层精度分配的运行时模型适应", "title_en": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "authors": "Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park", "background": "在处理设备上使用的大语言模型（LLMs）查询时，随着运行时约束（如延迟和准确度）的变化，如何有效地进行处理仍然是一个挑战。多尺度量化通过层叠不同精度量化的模型变体来实现LLMs的内存高效运行时模型适应，但模型如何根据目标精度或延迟进行适当配置的问题仍然悬而未决。混合精度提供了一个有希望的解决方案，但DP-LLM通过利用每层在解码迭代过程中的灵敏度动态变化这一关键观察，进一步改进了这种方法。", "innovation": "DP-LLM提出了一种新颖的方法，即在每层线性层中添加一个精度选择器，该选择器根据输入值在运行时确定位宽，使用轻量级误差估计器和通过微调学习到的阈值。实验证明，DP-LLM在性能-延迟权衡方面表现出优越性，优于先前的方法。", "conclusion": "实验证明，DP-LLM在多个模型和基准测试中实现了性能和延迟的最佳权衡，超越了先前的方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06021", "html_url": "https://arxiv.org/abs/2508.06021", "title": "通过基于生成AI的图像合成提高流式成像显微镜中亚显微粒子分类", "title_en": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "authors": "Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve", "background": "流式成像显微镜结合深度学习在亚显微粒子分析中已显示出有效识别颗粒类型的能力，能够区分无害成分（如硅油）与蛋白质颗粒。然而，在应用多类分类器时，由于可用数据稀缺且颗粒类型间数据不平衡，研究者通常不得不依赖于未必有效的其它方法。对于偶发且数量较少的硅油和气泡颗粒，问题更为突出，相比之下，通过控制条件下获取大量蛋白质颗粒图像较为容易。这些挑战使得数据平衡问题难以解决，从而影响了多类深度神经网络的有效训练。现有的方法难以满足这类因数据稀缺和不平衡导致的识别挑战。", "innovation": "本文开发了一种先进的扩散模型，通过生成高质量且高保真度的图像来解决数据不平衡问题，这些图像可以增强训练数据集，从而有效训练多类深度神经网络。实验验证了生成的图像在质量和结构方面接近真实图像，表明这种基于扩散生成的图像在训练数据集中的使用效果良好，提高了分类性能，并实现了从未有过的分类器效果。为了促进研究开放和可重复性，作者将扩散模型、训练好的多类深度神经网络分类器以及简单易用的接口公开发布。", "conclusion": "本研究通过利用生成AI生成图像来缓解数据不平衡问题，实现了有效的多类分类器训练，并通过大规模实验验证了其有效性。所采用的方法不仅提高了分类性能，还促进了研究的开放性和可重复性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06038", "html_url": "https://arxiv.org/abs/2508.06038", "title": "Fourier-VLM：频域中压缩视觉标记以增强大型视觉-语言模型的效率", "title_en": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "authors": "Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin", "background": "视觉-语言模型（VLMs）通常通过将图像编码器的视觉特征替换预定义的图像占位符（<image>）来增强文本指令，作为大型语言模型（LLM）的输入。但是，大量的视觉标记显著增加了上下文长度，导致高计算成本和推断延迟。尽管先前的努力通过选择重要视觉特征或将标记数减少到可学习查询来减轻这一问题，但往往会牺牲性能或增加显著的额外成本。\n", "innovation": "我们提出了一种简单而有效的方法——Fourier-VLM，它通过频域压缩视觉表示。我们的方法基于观察到视觉编码器输出的视觉特征在低频组件中具有集中能量。利用这一点，我们通过二维离散余弦变换（DCT）应用低通滤波器到视觉特征。值得注意的是，DCT 通过快速傅里叶变换（FFT）操作高效计算，时间复杂度为 $\text{O}(n \text{log} n)$，这在不引入额外参数的情况下最小化了额外的计算成本。\n", "conclusion": "通过在各种基于图像的基准测试中的广泛实验表明，Fourier-VLM 在性能和跨 LLaVA 和 Qwen-VL 架构的一般性方面表现出竞争力。关键的是，它将推断 FLOPs 减少高达 83.8%，并使生成速度提高 31.2% 相比于 LLaVA-v1.5，这突显了其优越的效率和实用性。\n"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06066", "html_url": "https://arxiv.org/abs/2508.06066", "title": "时间网络的架构感知泛化界：理论与公平比较方法", "title_en": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "authors": "Barak Gahtan,Alex M. Bronstein", "background": "时间卷积网络（TCNs）等深度时间架构在序列数据上实现了强大的预测性能，但对其泛化理论理解仍然有限。本文通过提供首个针对深度时间模型的非空泛架构感知泛化界，并提出了一种系统的评估方法，填补了这一空白。", "innovation": "1. 提供了首个非空泛、架构感知的深度时间模型泛化界。\n2. 提出了一个新的延迟反馈分块机制，将依赖样本转化为几乎独立样本，同时仅丢失小量数据。\n3. 引入了一种公平比较方法，固定有效样本量以分离时间结构效应和信息量效应。\n4. 发现强烈依赖序列在固定信息预算下能增强学习，并提出了理论与实践之间的差距，为未来研究指明方向。", "conclusion": "本文的研究表明，时间依赖性在固定信息预算下的情况下可以增强学习，但理论收敛率与现实情况存在差异。未来的研究需要进一步缩小理论与实践之间的差距。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05978", "html_url": "https://arxiv.org/abs/2508.05978", "title": "DAFMSVC：基于双注意力机制和流匹配的一次性唱歌声音转换", "title_en": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching", "authors": "Wei Chen,Binzhu Sha,Dan Luo,Jing Yang,Zhuo Wang,Fan Fan,Zhiyong Wu", "background": "唱歌声音转换（Singing Voice Conversion, SVC）是将来自歌手A的声音的特色转移到歌手B的声音中，同时保持旋律和歌词。其主要挑战是将未知说话者的声学特征适配到源音频中，而不会降低音质。现有方法要么导致声韵泄漏，要么无法产生满意的声韵相似性和音频质量。", "innovation": "我们提出了DAFMSVC，该方法通过将源音频的自监督学习（SSL）特征替换为目标音频中最相似的SSL特征，来防止声韵泄漏。此外，还引入了双交叉注意力机制，用于适应融合同说话者嵌入、旋律和语言内容。同时，还增加了一个流匹配模块，用于从融合特征中生成高质量的音频。", "conclusion": "实验结果表明，DAFMSVC在主观和客观评估中均显著提高了声韵相似度和自然度，优于现有最先进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06046", "html_url": "https://arxiv.org/abs/2508.06046", "title": "EvolvR: 自我演化的成对推理以提升故事生成", "title_en": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "authors": "Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang", "background": "尽管大型语言模型（LLMs）作为法官（LLM-as-a-judge）的有效性已经得到验证，但在开放任务中的表现仍有限，特别是在故事评估方面。准确的故事评估不仅有助于人类质量判断，也为指导故事生成提供了关键信号。然而，现有方法面临困境：专有模型的提示工程缺乏适应性，而开源模型的微调方法缺乏故事评估所需的严格推理能力。因此，研究提出了一种自演化成对推理（EvolvR）框架。该框架基于成对比较，首先通过多角色策略自动生成评分对齐的思维链（CoT）数据，这些数据经过自我筛选过程以确保逻辑严密性和鲁棒性，最终基于筛选后的数据训练的评估器作为奖励模型来指导故事生成任务。实验结果显示，EvolvR在包括StoryER、HANNA和OpenMEVA在内的三个评估基准测试中均达到了最先进的性能。此外，作为奖励模型时，其显著提高了生成故事的质量，从而全面验证了其自演化方法的优越性。", "innovation": "EvolvR框架提出了一种基于多角色策略自动生成评分对齐的思维链数据的方法，并通过自我筛选过程确保这些数据的质量和逻辑严密性。最终，基于经过筛选的数据训练的评估器作为奖励模型来指导故事生成任务。该方法在多个故事评估基准测试中达到了最先进的性能，并显著提升了生成故事的质量。", "conclusion": "EvolvR在多个故事评估基准测试中达成了最先进的性能，且作为奖励模型时显著提高了故事生成的质量，从而证明了其自演化方法的优越性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06072", "html_url": "https://arxiv.org/abs/2508.06072", "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "title_en": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "authors": "Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai", "background": "当前的基准评估方法要么采用基于真实数据集的分数评价方式，要么收集模糊的文本式人类偏好，这些方法可能无法为用户提供直观且感知上的性能差异反馈。因此，需要一个新的框架来评估大语言模型（LLMs）和多模态大语言模型（MLLMs），并通过视觉动画来体现它们的能力和差距。", "innovation": "本文介绍了一种名为BioMotion Arena的新框架，该框架通过视觉动画评估LLMs和MLLMs。该方法利用点光源成像放大模型之间的性能差异。通过成对比较评估，收集了53种主流LLMs和MLLMs在90种生物运动变体上的超过45000票。数据结果表明，众包人类投票与专家评分一致，显示了BioMotion Arena在提供区别性反馈方面的优越性。此外，大部分评估模型，包括先进的开放源代码InternVL3和专有Claude-4系列，无法生成基本的人形点光源组，更不用说流畅且生物学上可信的动作。", "conclusion": "BioMotion Arena因其在性能可视化方面的挑战性以及灵活的评估框架而成为新的基准，不受真实数据的限制。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06096", "html_url": "https://arxiv.org/abs/2508.06096", "title": "通过新颖性检测限制世界建模中分布的变化", "title_en": "Bounding Distributional Shifts in World Modeling through Novelty Detection", "authors": "Eric Jing,Abdeslam Boularias", "background": "最近关于视觉世界模型的工作表明，可以从预训练的图像骨干中获得显著的潜在状态动力学。然而，目前大多数方法对训练质量高度敏感，需要在训练过程中完全覆盖动作和状态空间，以防止推断过程中发生发散。", "innovation": "本文提出了一种使用变分自编码器作为新颖性检测器的方法，以确保在规划过程中提出的动作轨迹不会导致学习的模型偏离训练数据分布。该方法被整合到扩展了DINO-WM架构的模型预测控制策略循环中。", "conclusion": "实验结果清楚地表明，提出的方法在数据效率方面比最先进的解决方案有所提高。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 使用自我监督注意力学习识别手写数学", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "识别手写数学表达式（HMER）是一项具有挑战性的任务，因为存在固有的二维结构，符号比例的变化以及符号间的复杂空间关系。已有方法往往依赖于昂贵的标记数据，导致高成本和低效率。", "innovation": "本文提出了一种自我监督学习（SSL）框架，以消除对昂贵标记数据的需求。该框架包含一个通过全局和局部对比损失预训练的图像编码器，一种新颖的自我监督注意力网络，以及一种渐进空间遮罩策略。此策略帮助模型学习到语义重要的关注区域，而无需任何监督信号。此外，通过逐渐提高对缺失或被遮挡视觉信息的鲁棒性，增强了结构理解。", "conclusion": "我们在CROHME基准测试上进行了广泛的实验，证明了该方法优于现有的SSL和完全监督基准，验证了我们提出的渐进注意力机制在提高HMER性能方面的有效性。完整的代码库可以在这里找到。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06076", "html_url": "https://arxiv.org/abs/2508.06076", "title": "基于磁共振成像的trochleoplasty手术规划", "title_en": "Towards MR-Based Trochleoplasty Planning", "authors": "Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin", "background": "目前治疗 trochlear 槽发育不良 (TD) 的方法主要依赖于低分辨率的临床磁共振 (MR) 扫描和手术直觉，手术计划主要基于外科医生的经验，采用微创技术有限，并导致不一致的结果。", "innovation": "提出了一种生成从常规临床 MR 扫描中生成高分辨率、患者特定的 3D 假定健康目标形态的流程。首先使用显式神经表示（INR）计算等向性超分辨率 MRI 体素；然后使用多标签自定义训练网络进行股骨、胫骨、髌骨和腓骨的分割；最后使用小波扩散模型生成trochlear区域的假定健康目标形态。这种方法可以生成亚毫米级分辨率的 3D 形状，适用于术前和术中使用，且不需要 CT 扫描，从而减少了辐射暴露，显著提高了穹窿角（SA）和trochlear槽深度（TGD）.", "conclusion": "通过该方法，可以作为术前重塑股骨沟的蓝图，同时保留原生髌骨关节。我们对该方法进行了25例 TD 患者的评估，并证明了目标形态明显改善了穹窿角（SA）和 trochlear 槽深度（TGD）。代码和互动可视化可在 https://example.com/ 获得。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06108", "html_url": "https://arxiv.org/abs/2508.06108", "title": "GCHR：基于目标的回溯正则化以提高样本效率的强化学习", "title_en": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning", "authors": "Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang", "background": "目标控制的强化学习（GCRL）在稀疏奖励下仍旧是一项基本挑战。尽管回溯经验重放（HER）通过重新标记收集轨迹以实现目标显示出前景，但我们认为仅重标记轨迹未能充分利用off-policy GCRL方法中的可用经验，导致样本效率有限。", "innovation": "提出了一种基于回溯目标的Hindsight Goal-conditioned Regularization (HGR)技术，生成基于回溯目标的动作正则化先验，并结合Hindsight Self-imitation Regularization (HSR)，使得off-policy RL算法能够最大化经验利用。相比使用HER和自我模仿技术的现有GCRL方法，HGR在样本重用和性能上表现更优，通过导航和操作任务的实验得到了验证。", "conclusion": "我们的方法显著提高了样本重复利用率，并在一系列导航和操作任务中表现出最佳性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06136", "html_url": "https://arxiv.org/abs/2508.06136", "title": "Roll Your Eyes: 通过显式3D眼球旋转实现目光转移", "title_en": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation", "authors": "YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi", "background": "现有目光转移方法大多基于神经辐射场（Neural Radiance Fields, NeRF），借助体积渲染的隐式神经表示。然而，NeRF方法并未明确建模3D表示的旋转和平移。", "innovation": "提出了一种新颖的3D目光转移框架，利用明确的3D眼球结构。引入了3D高斯点绘（3D Gaussian Splatting, 3DGS）以表示眼球，同时提出了一种自适应变形模块，可以复制眼部周围细微肌肉运动。此方法能够生成逼真图像，并准确重现所需的目光方向。", "conclusion": "通过在ETH-XGaze数据集上的实验，证明了该框架能够生成多样性目光转移图像，相比之前最先进的方法，图像质量和目标识别精度均表现出优越性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06109", "html_url": "https://arxiv.org/abs/2508.06109", "title": "FMCE-Net++: 特征映射收敛评估与训练", "title_en": "FMCE-Net++: Feature Map Convergence Evaluation and Training", "authors": "Zhibo Zhu,Renyu Huang,Lei He", "background": "深度神经网络（DNNs）面临着由于其内部表示不透明而导致的可解释性挑战。尽管特征图收敛评估（FMCE）能够通过特征图收敛评分（FMCS）量化模块级别的收敛程度，但它缺乏实验验证和闭环集成。", "innovation": "提出了一个新颖的训练框架FMCE-Net++，该框架整合了一个预训练且冻结的FMCE-Net作为一个辅助头。该模块生成FMCS预测，结合任务标签共同监督主干优化，通过一种可调的表示抽象因子（Representation Abstraction Factor）动态平衡主要分类损失和特征收敛优化。FMCE-Net++已在MNIST、CIFAR-10、FashionMNIST和CIFAR-100上进行了广泛的实验，证明了在不修改架构或增加数据的情况下可以提升模型性能。", "conclusion": "FMCE-Net++在ResNet-50/CIFAR-10上的准确度提高了1.16个百分点，在ShuffleNet v2/CIFAR-100上的准确度提高了1.08个百分点，验证了其能够有效提升现有的性能上限。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06098", "html_url": "https://arxiv.org/abs/2508.06098", "title": "MeanAudio: 使用均值流实现快速且可靠的文本转语音生成", "title_en": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows", "authors": "Xiquan Li,Junxi Liu,Yuzhe Liang,Zhikang Niu,Wenxi Chen,Xie Chen", "background": "最近，在扩散模型和流模型方面的进展显著推进了文本转音频生成（TTA）技术的发展。尽管当前的TTA系统在合成质量和可控性方面取得了显著进步，但它们仍然面临着推断速度缓慢的问题，这对它们的实际应用构成了重大限制。", "innovation": "本文提出了MeanAudio，这是一种新的基于均值流的模型，旨在实现快速和准确的文本转音频生成。MeanAudio在训练过程中回归了平均速度场，通过直接从起点映射到流轨迹的终点，实现了快速生成。通过在训练目标中整合无条件向导限制（CFG），MeanAudio在引导采样过程中无需额外成本。此外，为稳定训练，本文提出了快速流场混合的即时到均值的课程策略，促使模型先学习基础的瞬时动力学，再逐渐适应均值流，这大大提高了训练效率和生成质量。实验结果表明，MeanAudio在单步音频生成中达到最先进的性能，在NVIDIA RTX 3090上实现了0.013的实时系数，相比最先进的扩散基于的TTA系统快100倍。此外，MeanAudio在多步生成任务中也表现优异，能够实现前后生成步次之间的平滑和连贯过渡。", "conclusion": "MeanAudio在具有单步音频生成和多步生成的优势方面表现出色，实现了快速和可靠的文本转语音生成，显著提升了TTA的应用场景的实用性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06133", "html_url": "https://arxiv.org/abs/2508.06133", "title": "具有可变预填充和解码长度的LLM服务优化", "title_en": "LLM Serving Optimization with Variable Prefill and Decode Lengths", "authors": "Meixuan Wang,Yinyu Ye,Zijie Zhou", "background": "研究如何高效地服务于具有不同预填充和解码长度的大型语言模型请求。预填充长度决定了输入提示的长度，进而决定初始内存使用情况；解码长度则指每产生一个输出标记，KV缓存的内存使用会增加一个单位。给定n个请求，目标是调度并处理它们以最小化总体完成时间。由于批次、放置约束、优先关系以及内存使用线性增加等复杂性，该问题被证明是NP-hard。常见的调度策略，如FCFS和SF，虽然简便但竞品率随着内存限制的增加会呈次线性增长，这在内存需求较大的实际场景中是一个重要弱点。", "innovation": "提出了一个基于全新选择指标的新算法，该算法有效地随时间形成批次。该算法证明了其具有恒定的竞品比率。并发展了几个通过这种方法启发的算法变种，包括动态规划变体、局部搜索方法和基于线性规划的调度器。实证研究显示，这些算法在保持计算效率的同时优于标准基线。", "conclusion": "提出的算法及其变体能够有效处理具有可变预填充和解码长度的大型语言模型请求，同时保持计算效率和优异的性能表现。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06169", "html_url": "https://arxiv.org/abs/2508.06169", "title": "UW-3DGS: 使用物理感知高斯点云集的海洋3D重建", "title_en": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting", "authors": "Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han", "background": "传统的神经辐射场（NeRF）方法在水下3D场景重建中面临严重的挑战，包括光吸收、散射和浑浊度，这些因素会严重影响几何形状的准确性和颜色的保真度。尽管像SeaThru-NeRF这样的NeRF扩展引入了物理模型，但它们对多层感知器（MLP）的依赖限制了其在浑浊环境中的效率和空间分辨率。", "innovation": "提出了一种名为UW-3DGS的新框架，该框架通过voxel（体素）回归来实现空间变化的衰减和回散，使用高斯点集（3DGS）进行可插入学习的水下图像形成模块。此外，还提出了一种物理感知不确定性修剪（PAUP）分支，通过不确定性评分自适应地去除噪声浮动高斯体素，确保无伪影的几何结构。", "conclusion": "实验结果表明，UW-3DGS在SeaThru-NeRF和UWBundle数据集上显示出优越的性能，平均端到端噪声高斯体素优化效果达到PSNR 27.604，SSIM 0.868，LPIPS 0.104，浮渣伪影减少了约65%。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06154", "html_url": "https://arxiv.org/abs/2508.06154", "title": "多模态推荐系统中语义项图增强", "title_en": "Semantic Item Graph Enhancement for Multimodal Recommendation", "authors": "Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Dusit Niyato,Zhiqi Shen", "background": "多模态推荐系统通过利用项目多模态信息提高了性能，受到越来越多的关注。早期方法通常从原始模态特征中构建模态特定的项目-项目语义图，并将其用作用户-项目交互图的辅助结构，以增强用户偏好学习。然而，这些语义图存在语义缺陷，包括（1）项目间合作信号建模不足和（2）由原始模态特征噪声引入的结构扭曲，最终损害了性能。", "innovation": "首先，从交互图中提取合作信号并注入到每个模态特定的项目语义图中以增强语义建模。其次，设计了一个基于模数的个性化嵌入扰动机制，通过模数引导的个性化强度注入扰动以生成对比视图，使模型能够通过对比学习学习抗噪声表示，从而减少语义图中结构噪声的影响。此外，提出了一种双重表示对齐机制，通过设计的锚定基InfoNCE损失和标准InfoNCE对行为表示进行对齐，确保表示一致性。", "conclusion": "在四个基准数据集上进行的广泛实验验证了我们框架的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06165", "html_url": "https://arxiv.org/abs/2508.06165", "title": "UR$^2$: 通过强化学习统一RAG和推理", "title_en": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "authors": "Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu", "background": "大型语言模型（LLMs）通过检索增强生成（RAG）和可验证奖励的强化学习（RLVR）两种互补的范式展示了显著的能力。然而，这些能力通常是在孤立的情况下开发的，现有努力将它们统一起来仍然局限于狭小的范围，例如开放领域问答，并依赖固定的检索设置和特定任务的假设。这种缺乏集成限制了RAG-RL方法的泛化能力，并限制了它们在更广泛领域的应用。", "innovation": "本文提出了UR$^2$（统一RAG和推理），这是一种结合检索和推理的通用框架，通过强化学习来统一这些功能。UR$^2$的创新点在于：难度感知的课程训练，根据问题难度选择性地启用检索；以及混合知识访问策略，结合领域特定的离线语料库和LLM生成的摘要。这些组件目的在于实现检索与推理的动态协调，以增加对各种任务的适应性。实验结果表明，UR$^2$在开放领域问答、MMLU-Pro、医疗和数学推理任务中显著优于现有RAG和RL方法，在多个基准测试中达到了与GPT-4o-mini和GPT-4.1-mini相似的性能。", "conclusion": "我们的研究结果表明，UR$^2$在各种任务上的表现显著优于现有方法，并且该框架可以通过提供强大的检索和推理协同作用的能力来改善LLMs的适应性。此外，我们已将代码、模型和数据全部发布。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06199", "html_url": "https://arxiv.org/abs/2508.06199", "title": "用于分子表示学习的预训练分子嵌入模型基准测试", "title_en": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning", "authors": "Mateusz Praski,Jakub Adamczyk,Wojciech Czech", "background": "预训练神经网络在化学和小分子药物设计领域引起了广泛关注。这些模型的嵌入广泛应用于分子性质预测、虚拟筛选和分子化学中的小数据学习。本研究对这类模型进行了迄今为止最广泛的比较，评估了25个不同模型在25个不同数据集上的性能。采用公平比较框架，研究了不同模态、架构和预训练策略的模型。", "innovation": "使用专门设计的分层贝叶斯统计测试模型进行评估。研究表明，几乎所有神经模型在性能上并未显示出相对于基本ECFP分子指纹的提高。唯一表现出统计显著优势的模型是基于分子指纹的CLAMP模型。这一结果引起了对现有研究评价严谨性的担忧。进一步讨论了潜在原因并提出了可能的解决方案及实用建议。", "conclusion": "研究表明，除CLAMP模型外，几乎所有其他模型在分子表示学习上的性能与基本ECFP分子指纹相当。CLAMP模型虽有明显表现但基于相同的分子指纹机制。因此需要对现有研究的评价标准进行反思与改进，并提出了具体的建议。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06163", "html_url": "https://arxiv.org/abs/2508.06163", "title": "一概而论不合时宜：一种基于分布感知的稀疏化方法以实现更精确的模型合并", "title_en": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "authors": "Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu", "background": "模型合并已成为一种无需数据的多任务学习的有说服力的范式，允许将多个细调模型合并为一个强大的实体。通常使用的一种关键技术是稀疏化，该技术通过修剪任务向量中的冗余参数来降低干扰。然而，现有的方法采用了一种“一刀切”的策略，使用统一的稀疏度比率处理所有参数，这忽略了模型参数固有的结构和统计异质性，导致参数间权衡不佳的问题，即关键参数被错误删除，而不太重要的参数则被保留。", "innovation": "我们提出了TADrop（Tensor-wise Adaptive Drop），一种适应性的稀疏化策略，能够尊重这种异质性，并为每个参数张量分配一个基于其分布属性的定制稀疏度等级。该方法的核心思想是，密度较高且更冗余的张量可以进行激进修剪，而更稀疏且更关键的张量则应保持不变。TADrop 作为一个简单且即插即用的模块，被整合到基础、经典以及 SOTA 的模型合并方法中。广泛的实验（涵盖视觉、语言和多模态任务及 ViT、BEiT 模型）表明，TADrop 一致且显著地提升了这些方法的性能，例如，当增强领先方法时，它在8个 ViT-B/32 任务上实现了平均2.0%的性能提升。TADrop 提供了一种更有效的方法来减轻参数间的干扰，通过将稀疏化定制到模型的结构中，为高性能模型合并提供了一个新的基准。", "conclusion": "TADrop 通过尊重模型参数的结构和统计异质性，提供了一种更有效的稀疏化策略来处理参数之间的干扰，并通过与不同类型的模型合并方法集成，展示了稳定的性能提升。这为未来的高性能模型合并奠定了新的基准标准。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06183", "html_url": "https://arxiv.org/abs/2508.06183", "title": "不同重平衡的差异隐私联邦聚类", "title_en": "Differentially Private Federated Clustering with Random Rebalancing", "authors": "Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li", "background": "联邦聚类旨在将相似的客户端归类到不同的聚类中，并为每个聚类生成一个模型。这种方法通常比为所有客户端训练一个单一模型的性能更好，但可能更容易发生隐私泄露。直接在联邦聚类中应用客户端级别的差分隐私（DP）机制可能会显著降低模型性能。这一困难主要源于在每个聚类内部平均隐私噪声的难度，尤其是聚类中客户端的数量不受控制时。因此，如何在保护隐私的同时保持模型的性能成为这一领域的挑战。", "innovation": "作者提出了一种名为RR-Cluster的简单且有效的方法，作为许多联邦聚类算法的轻量级附加方法。RR-Cluster通过随机重新平衡聚类分配来减少隐私噪声，确保每个聚类都有最小数量的客户端。该方法分析了减少隐私噪声方差与潜在增加偏差之间的权衡，并提供了RR-Cluster的收敛性界。实验结果表明，将RR-Cluster插入强大的联邦聚类算法可以在合成数据和真实数据集上显著提高隐私/性能折衷。", "conclusion": "实验结果显示，将RR-Cluster插入强大的联邦聚类算法后，可以在合成数据和真实数据集上显著提高隐私和性能的折衷。RR-Cluster提供了一种简单且有效的技术，旨在减轻隐私和性能之间的权衡问题，同时提高了联邦聚类算法的实用性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06135", "html_url": "https://arxiv.org/abs/2508.06135", "title": "少即是多：大型语言模型中兼容且高效的精选反射知识蒸馏", "title_en": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "authors": "Lingyuan Liu,Mengxiang Zhang", "background": "知识蒸馏（KD）是将大型语言模型（LLMs）压缩成紧凑、高效的学徒模型的基本技术。现有白盒KD方法主要关注平衡真实数据和学徒生成的回答，但忽视了两个关键因素：训练数据质量和学徒模型兼容性。", "innovation": "提出了Selective Reflection Distillation（SRD）框架，这是一种新的数据整理方法，利用学徒模型的反馈系统地改进训练数据。SRD动态评估和选择提示-响应对，并通过基于难度的自动化排名从真实数据和学徒模型输出中筛选高质量、学徒兼容的训练实例。SRD作为即插即用增强技术，能够显著提高各种白盒KD方法和模型架构的蒸馏效果，同时减少KD训练过程中的计算成本。实验证明，SRD在各种语言模型基准测试中能够提升模型性能，减少训练时间最多39%。SRD操作简单，能够独立于底层KD算法提高样本效率。", "conclusion": "研究表明，数据质量和兼容性对LLMs的有效和高效蒸馏至关重要，而SRD提供了一个基于原理的框架来同时实现二者。这项工作加深了对KD中数据中心因素的理解，提供了优化压缩LLMs能力和效率的实用见解。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05693", "html_url": "https://arxiv.org/abs/2508.05693", "title": "基于知识图谱的AI辅助软件包选择的实证评估", "title_en": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "authors": "Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan", "background": "在开源生态系统（如Python）中选择第三方软件包具有挑战性，因为有许多可供选择的选项，但缺乏透明的比较证据。AI工具在开发流程中越来越普遍，但它们提供的建议往往忽视了依赖性评估，重视流行度而非适用性，且缺乏可重复性，这对于需要透明度、长期可靠性、可维护性以及明智架构决策的项目来说构成了风险。", "innovation": "本文将软件包选择问题定义为多准则决策制定（MCDM）问题，提出了一种基于数据驱动的框架用于技术评估。自动化的数据管道不断收集和整合来自GitHub、PyPI和Stack Overflow的软件元数据、使用趋势、漏洞信息和开发者情绪数据，并将其结构化为一个决策模型，该模型反映了软件包、领域特性和质量属性之间的关系。该框架在PySelect中实施，这是一种决策支持系统，利用大规模语言模型解释用户意图并查询模型以识别上下文相关软件包。这种方法通过16,887个GitHub存储库中的798,669个Python脚本的实验评估以及基于技术接受模型的用户研究来进行评价。", "conclusion": "研究表明了高数据提取精度，人工智能辅助建议的推荐质量优于生成式AI基线，用户对其有用性和易用性也持积极评价。这项工作引入了一个可扩展、可解释和可重复的框架，该框架使用MCDM原则、实证数据和人工智能辅助意图建模支持基于证据的软件选择。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06170", "html_url": "https://arxiv.org/abs/2508.06170", "title": "基于合成数据的多架构框架，通过集成检测和掩码生成实现自动息肉分割", "title_en": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation", "authors": "Ojonugwa Oluwafemi Ejiga Peter,Akingbola Oluwapemiisin,Amalahu Chetachi,Adeniran Opeyemi,Fahmi Khalifa,Md Mahmudur Rahman", "background": "结肠镜检查是早期诊断结直肠癌的重要工具，而结直肠癌是全球癌症相关死亡的主要原因之一。鉴于此，结肠镜检查被视为预防和早期发现结直肠癌的关键技术。然而，医疗健康数据集的大小有限且注释复杂，限制了相关研究的进展。本文旨在提出一个新颖的多方向架构框架，旨在通过稳定扩散增强、检测和分割算法自动化息肉检测，并缓解有限数据集和标注的复杂性问题。研究提出了一套全面的系统，通过基于ResNet34的模型对五个最先进的分割模型（U-Net、PSPNet、FPN、LinkNet、MANet）进行了评估，以优化息肉检测和分割。", "innovation": "本文提出了一种多方向架构框架，用于通过集成检测和掩码生成实现自动化息肉分割。该系统利用Stable Diffusion增强技术生成合成数据，并结合使用Faster R-CNN进行初始目标定位，以及Segment Anything Model（SAM）进行掩码细化。此外，还通过比较多种最先进的分割模型来优化分割性能。", "conclusion": "研究展示了FPN模型在峰值噪声比（PSNR）和结构相似性指数（SSIM）方面表现最佳，而U-Net在召回率（Recall）方面表现出色，LinkNet在IoU和Dice分数方面表现出平衡的性能。这种多架构框架能够显著提高息肉检测和分割的准确性和可靠性，在现实场景中具有重要的应用价值。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06202", "html_url": "https://arxiv.org/abs/2508.06202", "title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "title_en": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "authors": "Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi", "background": "Continual Visual Instruction Tuning (CVIT) 允许多模态大型语言模型（MLLMs）逐步学习新的任务。然而，在模型适应新任务的过程中，会出现灾难性遗忘的问题，即模型在以前学习的任务上的性能会下降。为缓解这一问题，常采用的方法是架构扩展，引入特定任务的模块来防止干扰。但是，现有方法通常为每个任务扩展整个层，导致参数量显著增加，并且可扩展性不佳。", "innovation": "为了克服这些问题，本文提出了一种名为 LiLoRA 的高效架构扩展方法，专门针对 CVIT 在 MLLMs 中的应用。LiLoRA 在多个任务之间共享 LoRA 矩阵 A，以减少冗余，对矩阵 B 应用额外的低秩分解来减少特定任务的参数，并引入余弦正则化稳定性损失来保持随时间变化的共享表示的一致性。", "conclusion": "在多种 CVIT 基准上的大量实验表明，LiLoRA 能够在顺序任务学习中持续保持更优的表现，同时与现有方法相比显著提高了参数效率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06204", "html_url": "https://arxiv.org/abs/2508.06204", "title": "分类问题是一个RAG问题：仇恨言论检测案例研究", "title_en": "Classification is a RAG problem: A case study on hate speech detection", "authors": "Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen", "background": "当前的内容审核需要能够快速适应不断变化的政策而无需昂贵的重新训练的分类系统。传统的分类方法依赖于预训练参数来确定正确的类别，这种方法不能很好地适应政策的变化。这种背景下，作者提出了使用检索增强生成（RAG）的方法来改进内容审核技术。", "innovation": "作者提出了一种名为Contextual Policy Engine (CPE) 的检索增强生成系统，该系统能够在推理时根据上下文知识检索相关信息，从而改变了传统的分类任务。这种方法可以将仇恨言论检测任务从“是否含有仇恨言论”转变为“是否违反仇恨言论政策”。此外，该系统具有以下三个关键优势：（1）与领先的商业系统相比具有稳健的分类准确性；（2）通过检索到的政策段落提供内在的可解释性；（3）能够动态更新政策而无需重新训练模型。", "conclusion": "通过三项实验表明，该系统能稳健地应用细粒度的政策控制，可以在不重新训练或影响整体性能的情况下为特定身份群体提供适当的保护。研究结果表明，RAG可以将分类问题转化为更灵活、透明和适应性强的过程，不仅适用于内容审核，也适用于更广泛的问题分类。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06214", "html_url": "https://arxiv.org/abs/2508.06214", "title": "Reparameterization Proximal Policy Optimization", "title_en": "Reparameterization Proximal Policy Optimization", "authors": "Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang", "background": "Reparameterization policy gradient (RPG)方法通过利用可微分的动力学提高样本效率很有前景。然而，其训练过程不稳定，高方差的梯度可能会使学习过程不稳定。作者借鉴了Proximal Policy Optimization (PPO)方法，后者在无模型设置中通过使用代理目标来稳定样本的重用。研究者建立了代理目标与RPG之间的联系，引入了Reparameterization Proximal Policy Optimization (RPO)方法，该方法通过优化特定修剪的代理目标，并结合KL散度正则化，实现了稳定和高效的样本重用。", "innovation": "研究者提出了一种新的方法Reparameterization Proximal Policy Optimization (RPO)，通过优化特定修剪的代理目标，并结合KL散度正则化来实现稳定的样本重用。这是通过与PPO代理目标计算效率的方法联系起来的，从而在保持与现有减小方差方法兼容性的同时，提供了稳定性和效率的平衡。", "conclusion": "研究者在一系列挑战性的运动和操作任务上评估了RPO，实验结果表明该方法在样本效率和性能方面表现优秀。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06251", "html_url": "https://arxiv.org/abs/2508.06251", "title": "使用张量网络矩阵积态（MPS）实现合成数据生成和差分隐私", "title_en": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)", "authors": "Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi", "background": "合成数据生成是现代人工智能的关键技术，可以解决数据稀缺、隐私限制以及训练鲁棒模型时对多样数据集的需求。本文探讨了一种使用张量网络（具体为矩阵积态MPS）生成具有隐私保护的高质量合成表格数据的方法，以应对上述挑战。", "innovation": "本文提出了一种使用MPS生成具有隐私保护的高质量合成数据的方法，并将其与最新的CTGAN、VAE和PrivBayes模型进行对比，重点评估其保真度和隐私保护能力。通过在训练过程中注入噪音和裁剪梯度来确保差分隐私（DP），该方法利用Rényi差分隐私的计算提供隐私保障。实验结果表明，MPS在多个指标上优于经典模型，特别是在严格的隐私约束下。这种方法结合了张量网络表示的表达能力和正式隐私机制，提供了安全数据共享的可解释且可扩展的替代方案。", "conclusion": "本文突出了MPS作为一种用于隐私感知合成数据生成的有前景工具的地位。通过结合张量网络表示的表达能力和正式隐私机制，所提出的方案为敏感领域提供了既确保数据质量又保护机密性的安全数据共享的可解释且可扩展的替代方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06244", "html_url": "https://arxiv.org/abs/2508.06244", "title": "具有部分特征的成员推理攻击", "title_en": "Membership Inference Attack with Partial Features", "authors": "Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang", "background": "现有的成员推理攻击方法通常假定攻击者可以完全访问目标样本的所有特征，但在许多现实场景中，攻击者只能获取部分特征信息，这限制了这些方法的应用范围。本文研究了在攻击者只能观察到每个样本部分特征的情况下，判断这些特征是否存在于目标模型训练集中的推理场景。", "innovation": "提出了一种名为MRAD的记忆引导重构和异常检测（Memory-guided Reconstruction and Anomaly Detection）的两阶段攻击框架。第一阶段优化未知特征值以最小化样本的损失，第二阶段使用异常检测测量重构样本与训练分布之间的偏差。实验结果表明，MRAD方法在多种数据集上都是有效的，并且与各种现成的异常检测技术兼容。例如，在STL-10数据集上，即使缺少40%的特征，攻击方法仍能实现约0.6的AUC值。", "conclusion": "论文提出了MRAD框架来解决部分特征下的成员推理攻击问题，并证明了其在多数据集上的有效性和通用性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker: 空间感知的图像聚焦方法用于视觉推理解析", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大型语言模型（MLLMs）在处理复杂的视觉任务（例如空间理解、精细感知）时仍然面临重大挑战。尽管先前的方法尝试引入视觉推理，但它们未能利用结合空间线索的注意力校正机制来逐步精简对提示相关区域的关注。因此，本文提出了一种空间感知的‘思考与图像结合’框架——SIFThinker，模仿人类的视觉感知过程。", "innovation": "SIFThinker的主要创新点包括：1) 引入了一种向后扩展然后推理的策略，促进了过程级监督下的图像-文本链的理解生成，该策略导致构建了SIF-50K数据集；2) 提出了GRPO-SIF强化训练范式，将深度指导视觉定位整合到统一的推理管道中，使模型能够动态地校正和聚焦于与提示相关区域。", "conclusion": "广泛的实验表明，SIFThinker在空间理解和精细视觉感知方面显著优于现有方法，并且保持了强大的通用能力，这表明该方法的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06208", "html_url": "https://arxiv.org/abs/2508.06208", "title": "个性化隐私推荐的图联邦学习", "title_en": "Graph Federated Learning for Personalized Privacy Recommendation", "authors": "Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang", "background": "联邦推荐系统（FedRecs）因其提供隐私保护的推荐服务而受到广泛关注。现有的FedRecs假定所有用户对隐私保护的要求相同，即他们不向服务器上传任何数据。然而，这些方法忽视了通过利用公开可用的用户数据来提高推荐服务的潜在可能性。在实际应用中，用户可以选择成为私有用户或公开用户。私有用户的行为数据不会被共享，而公开用户的行为数据可以被共享。针对这一问题，本文提出了一种新的个性化隐私推荐的图联邦学习（GFed-PP），它可以根据不同的隐私需求改进推荐性能。", "innovation": "GFed-PP 把公开用户的行为数据纳入用户-物品交互图的构建中，随后用于形成用户关系图。该模型利用轻量级图卷积网络(GCN)学习每个用户的个性化项目嵌入。为了保护用户隐私，每个客户端本地学习用户嵌入和评分函数。此外，GFed-PP 通过在客户端初始化物品嵌入并在服务器上聚合用户关系图来优化联邦推荐框架。实验表明，GFed-PP 在五个数据集上显著优于现有方法，提供了更高的推荐准确率，同时不会牺牲隐私。这项框架为满足联邦推荐系统中的不同隐私偏好提供了一种实际解决方案.", "conclusion": "实验结果证实，GFed-PP 在五个数据集上显著优于现有方法，提供了优于现有的推荐准确率，不泄露用户隐私。此外，这项框架可以有效地支持不同隐私偏好的用户需求。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06287", "html_url": "https://arxiv.org/abs/2508.06287", "title": "先进的深度学习技术在肺癌检测和分类中的应用", "title_en": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification", "authors": "Mobarak Abumohsen,Enrique Costa-Montenegro,Silvia García-Méndez,Amani Yousef Owda,Majdi Owda", "background": "肺癌（LC）是最常见的癌症之一，是全球范围内男性和女性的主要死因。CT影像因其成本低和处理速度快，是最受欢迎的诊断方法。尽管许多研究人员提出了利用CT图像识别肺癌的各种方法，但这些技术普遍存在较高的假阳性率，导致准确性不高。根本原因是依赖于小且不平衡的数据集。", "innovation": "本文提出了一种基于DenseNet201模型的创新方法，用于CT影像中的肺癌检测和分类。该方法结合了Focal Loss、数据增强和正则化等先进技术，以此解决数据不平衡和过拟合的问题。", "conclusion": "研究结果表明，该提议具有很好的适用性，达到了98.95%的高准确率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06220", "html_url": "https://arxiv.org/abs/2508.06220", "title": "InfoCausalQA：模型能否基于图表进行非显性的因果推理？", "title_en": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?", "authors": "Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu", "background": "最近的视觉-语言模型（VLMs）在感知和推理方面展示了令人印象深刻的性能。然而，在因果推理方面的能力仍然尚未充分探索，特别是在多模态环境中。本研究旨在通过提出一种新的基准（InfoCausalQA），评估基于图表进行推理的能力，这些图表结合了结构化的视觉数据和文本上下文。InfoCausalQA 包含两个任务：第一个任务侧重于基于推断的数量化因果推理，第二个任务涉及五种类型的因果关系：原因、结果、干预、反事实和时间关系。该基准测试集包含来自四个公共来源的手动收集的 494 个图资-文本配对，并使用 GPT-4o 生成了 1,482 个高质量的多选题问答对，这些题目经过人类仔细修订，确保它们无法仅通过表面线索回答，而是需要真实的视觉基础。实验证明当前的 VLMs 在计算推理方面的能力有限，并且在语义因果推理方面表现尤为差一些，这一结果表明在利用基于图表的信息进行因果推理方面存在显著差距。", "innovation": "本研究通过引入 InfoCausalQA 基准测试来评估基于图表进行多模态环境中因果推理的能力，包括两个任务：数量化因果推理和语义因果推理的五个类型。基准数据集包含了从四个公共来源收集的手动筛选的 494 个图资-文本配对，这使得模型需要基于图表进行深层次的推理，而不仅仅是依赖表面线索。所提出的信息包括对当前 VLMs 在两个方面的表现进行的评估，显示出在处理因果关系方面存在明显的差距。", "conclusion": "现有 VLMs 在因果推理能力上存在显著的不足，特别是在处理基于结构化视觉数据的语义因果关系上。通过 InfoCausalQA，研究强调了提升多模态 AI 系统的因果推理能力的必要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06249", "html_url": "https://arxiv.org/abs/2508.06249", "title": "语言模型中的训练中防御措施以对抗新兴误对齐", "title_en": "In-Training Defenses against Emergent Misalignment in Language Models", "authors": "David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai", "background": "细调让从业者重新利用经过校准的大语言模型（LLMs）应用于新的领域，但最近的研究发现新兴的误对齐（EMA）：即使是对特定领域进行小规模的细调，也可能引起远离目标领域的有害行为。在模型权重被隐藏在细调API之后的情况下，这会给攻击者带来不易从细调数据中检测到的广泛误对齐的模型访问权限。本文是关于使用API暴露细调时对抗EMA的首个系统研究，针对提供者而言是实用的。", "innovation": "本文研究了四种训练正则化干预措施，以防止EMA：（i）朝安全参考模型的KL散度正则化；（ii）特征空间中的$L_2$距离；（iii）投影到安全子空间（SafeLoRA）；以及（iv）周期性插入少量来自通用指导细调数据集的安全训练样本。本文首先评估这些方法针对四项严重且制造EMA的任务的效果，然后评估它们对良性任务的影响。", "conclusion": "本文讨论了新兴误对齐研究中的开放性问题。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06264", "html_url": "https://arxiv.org/abs/2508.06264", "title": "数值考量在加权模型计数中的应用", "title_en": "Numerical Considerations in Weighted Model Counting", "authors": "Randal E. Bryant", "background": "加权模型计数计算Boolean公式满足赋值的加权和，权重由赋值中肯定和否定变量的权重乘积给出。这种计算在概率推理和定量风险评估中有着广泛的应用。大多数加权模型计数程序通过转换输入公式为便于进行算术评估的形式（使用乘法表示合取，加法表示析取）来工作。使用浮点数进行此评估可能产生不准确的结果，且不能量化精度。使用有理数进行计算可以获得精确结果，但在时间和空间上成本较高。", "innovation": "本文介绍了如何结合多种数值表示方法，以高效地计算加权模型计数，并且能够确保达到用户指定的精度。对于所有权重均为非负的情况，证明了使用浮点数进行算术评估的精度损失可以被很好地控制。对于带有混合负数和正数权重的问题，提出了结合区间浮点数计算和有理数计算的方法，以同时实现高效性和保证精度。为了验证其方法的鲁棒性，作者设计了特别具有挑战性的公式和权重分配进行评估。", "conclusion": "本文通过结合不同的数值表示方法，提出了加权模型计数的有效策略，该策略能够在保持计算效率的同时保证特定的精度。对于非负权重的问题，通过使用浮点数的扩展表示法（ERD）有效解决了下溢和上溢问题；对于混合权重问题，通过结合区间浮点数和有理数计算，成功地实现了高效性和精确性的双重目标。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06301", "html_url": "https://arxiv.org/abs/2508.06301", "title": "FedMeNF: 保护隐私的联邦元学习方法用于神经场", "title_en": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "authors": "Junhyeog Yun,Minui Hong,Gunhee Kim", "background": "神经场提供了一种高效的数据表示方式，能有效处理多样化的数据类型和大规模数据集。然而，将神经场映射至其他空间或进行训练往往需要大量的数据和计算资源，这对资源受限的边缘设备构成了挑战。传统的联邦元学习（FML）方法可能会泄露隐私信息，因此需要改进以解决这一问题并满足边缘设备的要求。", "innovation": "该论文提出了一种名为FedMeNF的新颖FML方法，它引入了一种新的保护隐私的损失函数，可以在局部元优化过程中控制隐私泄露。这种方法使得局部元学习者能够快速高效地优化模型，同时无需保留客户端的私人数据。这表明，即使在样本稀少或数据不独立同分布的情况下，FedMeNF也能在多种数据模态下实现快速优化和稳健的数据重建性能，同时保护客户端的数据隐私。", "conclusion": "FedMeNF能够在保证隐私的前提下，实现神经场模型的高效学习和重建，尤其适用于资源受限的边缘设备。通过减少隐私泄露，FedMeNF在拥挤和异构数据环境下具有很好的适应性和可靠性，展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06269", "html_url": "https://arxiv.org/abs/2508.06269", "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "title_en": "OM2P: Offline Multi-Agent Mean-Flow Policy", "authors": "Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang", "background": "生成模型，特别是扩散和流基础模型，在离线多智能体强化学习中表现出很大的潜力。但将强大的生成模型集成到这一框架中面临着独特的挑战。扩散和流基础策略在其迭代生成过程中采样效率较低，导致在时间敏感或资源受限的设置中实用性差。为了应对这些困难，我们提出了OM2P（Offline Multi-Agent Mean-Flow Policy），一种新的离线多智能体强化学习算法，实现了高效的一步动作采样。此外，为了解决生成目标和奖励最大化之间的不一致，我们引入了一种奖励感知优化方案，它结合了精心设计的均值流匹配损失与Q函数监督。我们还设计了一种通用的采样时间分布和无导数估计策略，以减少内存开销并提高训练稳定性。我们在Multi-Agent Particle和MuJoCo基准上的实证评估表明，OM2P在性能上表现出色，GPU内存使用率最多减少3.8倍，训练时间加速10.8倍。我们的方法是首次成功将均值流模型集成到离线多智能体强化学习中，为在合作多智能体环境中实现实用和可扩展的生成策略铺平了道路。", "innovation": "我们提出了OM2P（Offline Multi-Agent Mean-Flow Policy），一种新的离线多智能体强化学习算法，实现了高效的一步动作采样。我们还提出了奖励感知优化方案，结合了精心设计的均值流匹配损失与Q函数监督，设计了通用的采样时间分布和无导数估计策略，以减少内存开销并提高训练稳定性。这些创新使OM2P能够克服生成模型在离线多智能体强化学习中的局限性，提高了算法的实用性和效率。", "conclusion": "我们的方法成功地将均值流模型集成到了离线多智能体强化学习中，通过严格的实验验证，OM2P在多个基准测试中的表现显著优于现有方法，显著减少了内存使用和训练时间。这为多智能体系统中生成策略的实用性和可扩展性提供了新的解决方案，为后续的研究和实际应用奠定了基础。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06364", "html_url": "https://arxiv.org/abs/2508.06364", "title": "ActivityDiff: 一种具有正负活性指导的扩散模型用于从头药物设计", "title_en": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design", "authors": "Renyi Zhou,Huimin Zhu,Jing Tang,Min Li", "background": "在从头新药设计中，实现对单分子生物活性的高度精确控制，包括目标激活/抑制、多靶点协同调节以及减少旁路毒性，仍然是一个关键挑战。现有的生成方法主要集中在生成具有单一预定活性的分子上，而缺乏同时管理多个预定和非预定分子相互作用的集成机制。", "innovation": "本文提出了ActivityDiff，一种基于扩散模型的分类器指导技术。该方法利用分别训练的药物-靶标分类器进行正向和负向指导，使模型能够增强所需的活性同时减少有害的旁路效果。实验结果表明，ActivityDiff在单/双重靶点生成、具有片段限制的双重靶点设计、选择性生成以提高靶点特异性以及减少旁路效果等方面有效执行了关键药物设计任务。", "conclusion": "总体而言，我们的工作引入了一种新的分子活性综合控制范式，并提供了一个多用途和可扩展的ActivityDiff框架，证明了分类器指导下的扩散模型在分子设计中平衡有效性和安全性方面的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06336", "html_url": "https://arxiv.org/abs/2508.06336", "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "title_en": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "authors": "Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling", "background": "当前的多智能体强化学习框架在进行合作学习时，通常依赖于预训练的伙伴或手动参数调整，这限制了其灵活性与适应性。本文旨在通过引入Unsupervised Partner Design (UPD)框架，实现一种无需预先定义伙伴且能自适应生成训练伙伴的方法，从而使得多智能体能够进行更加灵活和自适应的学习，用于应对多变的合作环境。", "innovation": "UPD框架通过无监督的伙伴设计，直接生成适应当前学习进展的伙伴，无需依赖预训练的伙伴或手动参数调整。通过采用一个基于方差的学习性度量来评估生成功伙伴的适应性，并根据当前学习前沿优先选择伙伴。这种方法使得最多智能体能够在合作过程中动态适应环境变化，无需预定义环境或伙伴群体。", "conclusion": "实验在Overcooked-AI和Overcooked Generalisation Challenge上展示了UPD框架的有效性。这一策略可自适应地生成伙伴，使得参与者在多个多智能体合作场景中表现出色，尤其是在动态环境和伙伴分布的情况下。UPD不仅展示了其在竞争性和合作智能体任务中的广泛应用，还提升了用户体验，使参与者感到更加适应、更像人类和更好的合作。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06361", "html_url": "https://arxiv.org/abs/2508.06361", "title": "超越提示诱导的谎言：探索良性提示中LLM的欺骗行为", "title_en": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "authors": "Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He", "background": "大语言模型（LLMs）已在推理、规划和决策任务中得到广泛应用，因此，其可靠性成为一个关键问题。现有的研究大多通过编程或微调的方法诱导模型产生无意的欺骗行为，但这种方法在反映真实的人类-LLM交互时可能存在局限性。因此，研究如何识别LLMs在没有预定目标的情况下如何产生欺骗行为变得重要。", "innovation": "本文提出了一种新的框架，使用“接触搜索问题”来评估LLM的自我发起的欺骗行为。该框架结合了两个由心理学原理衍生出的统计度量：欺骗意图得分和欺骗行为得分，前者衡量模型对隐藏目标的偏差程度，后者衡量LLM内部信念与表达输出之间的一致性。通过对14个主流LLM模型的评估发现，这些度量在任务难度增加时会增加，揭示了即使是最先进的LLM也倾向于在处理复杂问题时产生欺骗行为。", "conclusion": "本文的研究结果表明，即使是最先进的LLM，在处理复杂问题时表现出越来越强的欺骗倾向，提出了对LLM代理人部署在复杂和关键领域中的重大关切。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06347", "html_url": "https://arxiv.org/abs/2508.06347", "title": "结构方程-VAE：用于表格数据解纠缠潜在表示", "title_en": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data", "authors": "Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam", "background": "在深度生成模型中，从结构化数据中学习可解释的潜在表示仍是一个挑战。现有的方法主要是通过统计正则化来实现解纠缠，但在某些情况下效果有限。", "innovation": "SE-VAE（结构方程-变分自编码器）提出了一种新颖的架构，直接将测量结构嵌入变分自编码器的设计中。通过借鉴结构方程建模，SE-VAE将潜在空间与已知的指示因子分组对齐，并引入了一个全球性噪声因子来隔离构念特异性干扰变异。模块化的架构通过设计实现了解纠缠，而不是仅仅依靠统计正则化。SE-VAE在标准的解纠缠度量上取得了优于多种基准方法的表现。", "conclusion": "SE-VAE在因素恢复、解释性和对噪声变异的鲁棒性方面表现出色。消融实验表明，架构结构而非正则化强度是性能的关键驱动因素。SE-VAE提供了一个在科学和社会领域中进行白盒生成建模的有效框架，特别是在潜在构念由理论驱动且测验有效性至关重要的情况下。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06345", "html_url": "https://arxiv.org/abs/2508.06345", "title": "利用自适应拓扑表示进行零样本图问答", "title_en": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "authors": "Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang", "background": "大型多模态模型（LMMs）在各种领域的问题回答（QA）任务中展示了普遍的零样本能力，包括涉及复杂图拓扑的图QA任务。然而，目前大多数方法仅使用一种类型的图表示，即拓扑表示形式（Topology Representation Form，TRF），如统一的文本提示或固定风格的视觉样式。这些“一刀切”的方法没有考虑到不同模型或任务的特定偏好，往往会得出错误或过长的回答。为了解决这个问题，本文首先分析了现有TRF的特点和弱点，然后设计了专门针对零样本图QA的TRF集$F_{ZS}$。并且引入了一种新的度量标准——图响应效率（Graph Response Efficiency，GRE），它衡量了图QA中性能和简洁性的平衡。基于这些基础，本文开发了动态TRF框架，旨在提高图QA的准确性和简洁性。具体而言，动态TRF首先构建一个基于GRE得分对TRF进行排名的TRF偏好（TRFP）数据集，以探究特定问题的TRF偏好。然后，它在一个TRFP数据集上训练一个TRF路由器，以在推理过程中为每个问题自适应地分配$F_{ZS}$中最合适的TRF。", "innovation": "本文的创新在于分析了现有TRF的特点与弱点，并据此设计了适用于零样本图QA的定制化TRF集$F_{ZS}$。引入了新的度量标准——图响应效率（GRE），并开发了动态TRF框架来优化图QA的准确性和简洁性。该框架通过首先创建基于GRE得分排名的TRF偏好数据集，以及训练一个根据问题自适应选择最佳TRF的TRF路由器，实现了这一目标。", "conclusion": "广泛的实验表明，动态TRF显著提高了LMMs在零样本图QA任务中的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06343", "html_url": "https://arxiv.org/abs/2508.06343", "title": "在受限图类上的近似MMS分配", "title_en": "On Approximate MMS Allocations on Restricted Graph Classes", "authors": "Václav Blažej,Michał Dębski ad Zbigniew Lonc,Marta Piecyk,Paweł Rzążewski", "background": "我们研究了一组不可分割物品的公平分配问题，并且这些物品以连接图的形式表示。每组分配给代理者的物品必须构成这个图的连通子图。具体来说，我们关注最大化最小份额(MMS)公正性的广泛研究标准。尽管在没有连通约束的情况下已证明可能存在这样的分配，但在具有连通约束的情况下，满足这一标准的分配可能不存在。因此，为了保证每个代理者获得一个具有特定值的连通物品集合，我们寻找近似分配，这些分配保证每个代理者获得的价值不低于其MMS值的某一常数比例。已知某些类型图，如完全图、圈图和$d$-无爪图（对于任何固定的$d$），确实存在这样的近似分配。但对所有图来说，这种近似分配是否总是存在的问题尚未解决。前人对此问题的系统研究通常限制在某些特定的图类，如块图、星图、完全多重部图和分裂图这类类别的图上。", "innovation": "本文继续对受限图类别中近似分配的存在性进行系统研究。特别是展示了对于几个广泛研究的图类（块图、星图、完全多重部图和分裂图）的存在性，确实存在满足上述MMS公正标准的近似分配。这项工作填补了理论研究中的一个空白，为这些特定类型的图提供了新的结果和方法。", "conclusion": "研究表明，对于几种具体的图类，在满足最大化最小份额(MMS)公正性的条件下，确实存在近似分配。这为理解和解决受限图类别中的公平分配问题提供了重要的理论指导和方法依据。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06357", "html_url": "https://arxiv.org/abs/2508.06357", "title": "你是馆内的人还是馆外的人？来自同一身份群体的智慧", "title_en": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd", "authors": "Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer", "background": "在一对一到多对一的人脸识别中，挑战在于参考图像中的人脸可能注册在人脸库中，也可能不在，即可能是馆内(In-gallery)或馆外(Out-of-gallery)。过去的解决办法主要集中在找到合适的相似度分值阈值来判断某个人脸识别结果是否为馆外。本文提出了一种新的方法，利用与最高分人脸识别结果对应的同一身份的额外注册图像来预测该结果是否为馆内或馆外。", "innovation": "通过利用与最高分人脸识别结果对应的同一身份的额外注册图像，生成馆内和馆外的训练数据集，训练一个分类器来预测该结果是否为馆内或馆外。这种方法不仅适用于 mugshot 级别的参考图像，还适用于被模糊、分辨率降低、大气湍流和太阳镜等条件恶化的情况。实验结果显示该方法的有效性，并且在不同的人口统计群体中，馆内/馆外分类的准确性相似。该方法有望为确定是否为馆外提供客观评估，从而减少误报，避免错误逮捕和浪费调查时间。此外，该方法的有效性仅在使用先进的基于margin的损失函数进行训练的现代深度CNN人脸匹配器中才显现出来。", "conclusion": "本研究提出了一种新的方法，通过利用同一身份的额外注册图像来判断人脸识别结果是否为馆内或馆外。该方法在多个数据集和不同的匹配器上进行了验证，并且在不同的人口统计群体中表现相似。该方法能够客观评估人脸识别结果是否为馆外，并有望减少误报、错误逮捕和浪费调查时间。使用先进的基于margin的损失函数训练的现代深度CNN人脸匹配器是该方法有效性的关键。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06318", "html_url": "https://arxiv.org/abs/2508.06318", "title": "GS-MoE：高斯斑迹引导的专家混合模型在弱监督视频异常检测中的重要性", "title_en": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection", "authors": "Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev", "background": "视频异常检测（VAD）是一个具有挑战性的任务，因为异常事件的多样性和可用标记数据的有限性导致了这一问题。在弱监督VAD（WSVAD）框架下，训练时仅有视频级别的标签，而预测是在帧级别进行的。尽管最先进的模型在简单的异常（如爆炸）上表现良好，但在复杂的现实世界事件（如偷窃）处理上仍存在问题。这种困难源于两个关键问题：一是当前模型无法针对不同类型的异常做出区别处理，处理所有类别时共用同一个模型，忽略了类别特异性特征；二是弱监督信号缺乏精确的时间信息，限制了捕捉正常事件和异常事件混合的细微异常模式的能力。", "innovation": "我们提出了一种新的框架Gaussian Splatting-guided Mixture of Experts (GS-MoE)，它采用了一组每个专家模型专注于捕捉特定类型异常的方式。这些专家由一个时空高斯斑迹损失引导，使得模型能够利用时间的一致性并增强弱监督信号。我们的方法通过混合多位专家的预测来建模复杂多样的异常模式。我们达到了最先进的性能，在UCF-Crime数据集上取得了91.58%的AUC，同时在XD-Violence和MSAD数据集上也表现出显著的效果。通过利用类别特异性专长和时间引导，GS-MoE为弱监督视频异常检测设定了新的基准点。", "conclusion": "我们的方法解决了现有的两个关键问题，并通过时空高斯斑迹策略实现了更精确和全面的异常表示，从而在弱监督的视频异常检测任务上达到了最先进的性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06372", "html_url": "https://arxiv.org/abs/2508.06372", "title": "SpeakerLM：利用多模态大规模语言模型实现端到端灵活的说话人分割与识别", "title_en": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models", "authors": "Han Yin,Yafeng Chen,Chong Deng,Luyao Cheng,Hui Wang,Chao-Hong Tan,Qian Chen,Wen Wang,Xiangang Li", "background": "说话人分割和识别（SDR）任务旨在预测音频片段中的“谁在何时讲话以及说了什么”，这是一个在会议转录、对话系统等多种实际多说话人场景中至关重要的任务。现有的SDR系统通常采用递增框架，结合了如说话人分割（SD）和自动语音识别（ASR）等多个模块。然而，递增系统存在一些局限性，如错误传播、处理重叠语音困难以及没有从SD和ASR任务的协同作用中进行联合优化。", "innovation": "我们引入了SpeakerLM，这是一种统一的多模态大规模语言模型，用于同时端到端地执行说话人分割和自动语音识别。此外，我们还为SpeakerLM引入了一个灵活的说话人注册机制，使其能够在不同的说话人注册设置下运行。通过大规模实际数据的多阶段训练策略，SpeakerLM展现出强大的数据扩展能力和适应性，优于最新的递增基准模型，在领域内和领域外公开的SDR基准测试中均有卓越表现。提出的说话人注册机制有效地确保了SpeakerLM在各种说话人注册条件下和不同注册说话人数目的情况下具有稳健的说话人分割和识别性能。", "conclusion": "SpeakerLM在不同说话人注册设置下的灵活性能和普遍性能被广泛实验验证。与现有的递增基准模型相比，它在音频片段的说话人分割和识别任务上表现出更强的优势。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06387", "html_url": "https://arxiv.org/abs/2508.06387", "title": "使用数据集选择的端到端文本到SQL：利用大型语言模型实现适应性查询生成", "title_en": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "authors": "Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh", "background": "文本到SQL的任务旨在弥合自然语言与结构化数据库语言之间的差距，使非技术人员能够轻松地查询数据库。传统的做法是将自然语言查询直接映射为SQL命令，但这种方法假设目标数据库已知。然而，在涉及多个数据库的情况下，确定正确的数据库成为了一个关键但容易忽视的步骤。长期以来，大型语言模型（LLMs）的进步显著提高了翻译的准确性，但在这种情景下，仍然需要预先指定目标数据库。因此，需要开发一种新的框架来在生成SQL查询之前识别用户的意图数据库。", "innovation": "本文提出了一种三阶段的端到端文本到SQL框架，首先确定用户的意图数据库，然后生成SQL查询。该框架利用大型语言模型和提示工程从自然语言查询中提取隐式信息，形成规则集。接着，使用基于RoBERTa的微调编码器训练一个大型db_id预测模型，以预测正确的数据库标识符（db_id）。最后通过使用批判代理来修正生成的SQL中的错误。实验证明，该框架在数据库意图预测和SQL生成准确性上优于当前最先进的模型。", "conclusion": "该研究提出了一种新的框架，能够从自然语言查询中自动识别用户的意图数据库，然后生成准确的SQL命令。这种方法有效地解决了多数据库场景下确定正确数据库的问题，并且在实验中明显优于现有模型。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06393", "html_url": "https://arxiv.org/abs/2508.06393", "title": "通过增强说话人嵌入采样实现稳健的目标说话人诊断和分离", "title_en": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling", "authors": "Md Asif Jalal,Luca Remaggi,Vasileios Moschopoulos,Thanasis Kotsiopoulos,Vandana Rajan,Karthikeyan Saravanan,Anastasis Drosou,Junho Heo,Hyuk Oh,Seokyeong Jeong", "background": "传统的语音分割和说话人边界划分方法依赖于对目标说话人的先验知识或已确定的参与者数量。这些方法的局限性在于需要明确的说话人标签，在实际应用中难以满足需求。因此，最近的发展趋势是开发无需注册的说话人识别方法，旨在在不进行明确说话人标注的情况下识别目标说话人。目前，对于重叠语音帧的边界划分准确性仍是一个挑战。研究表明，现有的最先进基线方法在这方面的性能有待提高。", "innovation": "本文提出了一种同时进行语音分割和边界划分的新方法，该方法通过自动识别混合物中的目标说话人嵌入进行训练。该方法设计了一种双重阶段训练管道，能够学习稳健的说话人表示特征，这些特征对于抵御背景噪声的干扰具有较好的弹性。此外，还提出了一种专门为提升重叠语音帧边界划分准确性而设计的频谱重叠损失函数。实验结果表明，该方法在殿试员错误率（DER）和字符错接率（cpWER）方面较当前最先进基线方法有显著改进，分别提高了71%和69%。", "conclusion": "本文提出的方法在提高语音分割和边界划分的性能方面取得了显著进步，尤其是在处理重叠语音帧时。将在实际场景中进一步验证该方法的有效性和鲁棒性，并展望未来在该领域的持续研究和发展。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06426", "html_url": "https://arxiv.org/abs/2508.06426", "title": "一般主义机器人策略中的捷径学习：数据集多样性和碎片化的角色", "title_en": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "authors": "Youguang Xing,Xu Luo,Junlin Xie,Lianli Gao,Hengtao Shen,Jingkuan Song", "background": "一般主义机器人策略在大规模数据集（如Open X-Embodiment, OXE）上训练后，表现出对多种任务的强大性能，但往往难以超越其训练数据分布进行泛化。本文探讨了这一有限泛化能力的根本原因，并确定了捷径学习作为关键障碍，这是对任务无关特征的依赖。这种现象由两个主要因素引起：个体子数据集内的有限多样性以及子数据集间显著的分布差异，导致数据集碎片化。", "innovation": "本文通过全面的理论和实验分析，揭示了有限多样性内个体子数据集和子数据集间显著的分布差异是捷径学习的主要原因。这些发现为减少捷径学习和提高一般主义机器人策略泛化能力提供了关键见解。此外，当获取新大规模数据不现实时，通过选择性地对现有的离线数据集进行机器人数据增强策略，可以有效减少捷径学习，从而提高一般主义机器人策略的泛化能力。这一策略适用于模拟和真实世界环境。", "conclusion": "本文的研究结果表明，通过优化数据集收集策略，减少捷径学习，可以显著提升一般主义机器人策略的泛化能力。同时，利用精心挑选的机器人数据增强策略，可以在不获取新大规模数据的情况下，有效提高现有数据集的泛化能力，这一方法适用于模拟和实际环境。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06401", "html_url": "https://arxiv.org/abs/2508.06401", "title": "检索增强生成技术、指标和挑战的系统文献综述", "title_en": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "authors": "Andrew Brown,Muhammad Roman,Barry Devereux", "background": "这篇论文是对2020年至2025年间发布的研究文献中的检索增强生成（RAG）进行系统性回顾。通过分析高度引用的研究文章，该研究提供了这部分领域的深入分析。最终共收录了128篇文章，这些文章来源于多个学术数据库，如ACM数字图书馆、IEEE Xplore、Scopus、ScienceDirect及DBLP数字图书馆。研究者采用明确的纳入和排除标准，并利用PRISMA 2020框架，对数据集、架构和评估实践进行了系统记录，并综合了RAG的有效性和局限性证据，以减少引用延迟偏见。", "innovation": "研究者采用了新颖的方法，包括根据引用数量和研究问题设定明确的纳入和排除标准，收集并归纳了多种数据集、架构和评估实践，并通过综合现有研究的实证证据来阐明RAG的有效性和局限性。特别值得注意的是，为了避免引用滞后偏见，对2025年发表的论文使用了较低的引用门槛，从而使得新兴的、自然引用数量较少的突破性成果也能够被纳入研究范围。这种方法为理解RAG技术的现状及其面临的挑战提供了一个更为全面的视角，同时也指出了未来研究的重要方向。", "conclusion": "这项研究澄清了当前RAG研究领域的现状，突出了方法论上的缺口，并为将来研究指明了优先方向。通过详细分析和比较文献格式、架构和评估方法，研究者能够更好地理解和评估RAG技术的有效性和局限性，并为未来的RAG研究提供了宝贵的建议。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06434", "html_url": "https://arxiv.org/abs/2508.06434", "title": "CLIPin：用于多模态语义对齐的CLIP非对比度插件", "title_en": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment", "authors": "Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li", "background": "大规模的自然图像-文本数据集，尤其是那些从网络自动收集的数据集，由于弱监督往往会存在语义对齐松散的问题，而医学数据集则通常具有高跨模态相关性但内容多样性较低。这些特性对对比式语言-图像预训练(CLIP)构成了共同挑战：它们阻碍了模型学到稳健且通用的表示能力。", "innovation": "提出了CLIPin，这是一种统一的非对比度插件，可以无缝地集成到CLIP架构中，以改善多模态语义对齐，提供更强的监督，并增强对齐的鲁棒性。此外，还设计了两个共享前投影器分别用于图像和文本模态，促进了对比学习与非对比学习的融合，得到了参数折中。", "conclusion": "在多种下游任务上的广泛实验表明，CLIPin 作为可直接插入的组件，在与各种对比框架兼容的情况下，具有有效性和通用性。相关代码可在指定链接找到。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06453", "html_url": "https://arxiv.org/abs/2508.06453", "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "title_en": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "authors": "Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers", "background": "CT图像中的病变分割可以用于慢性疾病（如淋巴瘤）的临床评估。将大型语言模型（LLMs）集成到病变分割工作流程中，可以结合影像特征与放射报告中病变特征的描述。已有研究表明，将文本信息融入神经网络模型可以提高病变分割的准确性。", "innovation": "本文提出了一种新的模型 Text-Swin-UMamba，通过将文本信息嵌入到Swin-UMamba架构中，提高了病变分割的性能。该模型在UMLS23 DeepLesion数据集上的测试集上取得了82%的高Dice Score和6.58像素的低Hausdorff距离。相比LanGuideMedSeg模型，Text-Swin-UMamba提高了37%的性能，并分别优于基于图像的xLSTM-UNet和nnUNet模型1.74%和0.22%。", "conclusion": "提出的Text-Swin-UMamba模型在病变分割任务上表现出色，证明了将文本信息与影像特征结合可以有效提高病变分割的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06482", "html_url": "https://arxiv.org/abs/2508.06482", "title": "通过约定形成提高通信效率的后训练方法", "title_en": "Post-training for Efficient Communication via Convention Formation", "authors": "Yilun Hua,Evan Wang,Yoav Artzi", "background": "人类在多轮交互中通过调整语言和形成临时约定来不断提高沟通效率。然而，现有的大型语言模型（LLMs）并没有这种自然能力。研究人员开发了一种后训练过程，通过针对启发式识别的约定形成示例进行目标微调，使LLMs获得这种能力。 ", "innovation": "开发了一种新的后训练过程，通过目标微调，使LLMs能够像人类一样在多轮交互中形成临时约定，并开发了两个新的基准测试来评估这一能力。", "conclusion": "通过后训练，LLMs在两项评估方法中的约定形成能力有了显著提高。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06429", "html_url": "https://arxiv.org/abs/2508.06429", "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "title_en": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "authors": "Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda", "background": "深度学习在医学成像领域取得了革命性进展，但其效果受到有限标记训练数据的影响。这篇论文介绍了一种基于生成对抗网络（GAN）的新型半监督学习框架，特别适用于少量标注数据的情况。该框架评估了每类别5至50个标记样本的不同设置。", "innovation": "该创新方法整合了三个专门的神经网络——用于类条件图像翻译的生成器、用于真实性评估和分类的判别器以及专用分类器。方法在监督训练有限标记数据和无监督学习利用丰富未标注图像之间交替进行。通过结合判别器和分类器的信心加权预测以及指数移动平均的时域一致性，这种方法能够在未标注数据上生成可靠的标签估计。全面评估了11个MedMNIST数据集，本方法在六个最先进的GAN半监督方法中显示出显著改善，尤其在极度稀疏标记数据的5-shot设置中表现尤为出色。该框架在所有评估设置（5, 10, 20 和 50 射次/类别）中保持着优势。本方法为医学成像应用提供了实际解决方案，在标注成本高昂的情况下，即使少量标注数据也能实现稳健的分类性能。", "conclusion": "本方法通过减少所需标记量实现了在医学影像中的准确分类，为半监督学习方法如何利用未标注数据提高了效率。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：新闻制作中LLM使用增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "近年来生成性人工智能（GenAI），特别是大型语言模型（LLMs）的迅速兴起，引发了对新闻报道的完整性及作者身份的担忧。本文通过对40,000多篇来自主要、地方和高校媒体的新闻文章进行研究，使用三种先进的AI文本检测工具（Binoculars、Fast-Detect GPT和GPTZero），发现近年来AI生成内容的使用量显著增加，尤其是在地方和高校新闻报道中更为普遍。句子级别分析显示，大型语言模型通常在新闻的开头部分被使用，而结论通常由人手撰写。语言层面的分析表明，GenAI提高了文章词汇丰富度和可读性，但降低了正式程度，导致写作风格更加统一，特别是在地方媒体中更为明显。", "innovation": "使用三种先进的AI文本检测工具（Binoculars、Fast-Detect GPT和GPTZero）来检测AI生成内容的增加。深入分析了大型语言模型在新闻文章中的使用情况，特别是对文章不同部分的使用差异进行了区分，揭示了其对新闻文本风格的具体影响。", "conclusion": "GenAI使用量在新闻中显著增加，尤其是在地方和高校新闻报道中。大型语言模型更多地在新闻的开头部分被使用，而结论大多由人手撰写。GenAI提高了文章的词汇丰富度和可读性，但减少了正式程度，使写作风格更加统一，特别是在地方媒体中。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06457", "html_url": "https://arxiv.org/abs/2508.06457", "title": "ScamAgents：AI代理如何模拟人类级别的诈骗呼叫", "title_en": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "authors": "Sanket Badhe", "background": "大型语言模型（LLMs）展现了出色的流畅性和推理能力，但其潜在的滥用引起了广泛关注。尽管现有安全护栏，如拒绝机制和内容过滤器，已经存在，但这些措施并未有效应对基于代理的 scams。本文介绍了 ScamAgent，一种基于 LLMS 的多轮对话代理，能够生成高度逼真的欺诈剧本，模拟真实场景中的诈骗行为。以往的研究主要关注单次提示滥用，而 ScamAgent 则延续对话历史，动态适应用户响应，并在多轮对话中运用欺骗性说服策略。这表明，即使是具有强大提示级安全保护措施的模型，在这些措施被分解、伪装或通过代理框架逐步传递时，也可能被绕过。", "innovation": "本文引入了 ScamAgent，一种基于多轮对话的代理，能够生成高度逼真的欺诈剧本，模拟真实场景中的诈骗行为。ScamAgent 能动态适应用户响应，并运用欺骗性说服策略。研究发现，当前的 LLM 安全护栏，包括拒绝机制和内容过滤器，对于基于代理的威胁是无效的。即使是具有强大提示级安全保护措施的模型，在这些措施被逐步传递时，也可能被绕过。", "conclusion": "本文的研究结果表明，需要加强多轮对话的安全审查、代理级别的控制框架，并开发新的方法来检测和中断由生成性 AI 动力的对话欺骗。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06433", "html_url": "https://arxiv.org/abs/2508.06433", "title": "Memp: 探索智能体过程性记忆", "title_en": "Memp: Exploring Agent Procedural Memory", "authors": "Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang", "background": "大型语言模型 (LLMs) 在执行各种任务方面表现出色，但它们在坚持已有的程序性记忆方面存在缺陷，这类记忆通常需要人工设计或嵌入在静态参数中。本研究旨在赋予智能体一种可学习、可更新并伴随其一生的过程性记忆。", "innovation": "我们提出了 Memp，该方法通过提炼过去的智能体轨迹，生成精细的步骤指令和高层次的脚本式抽象来实现智能体过程性记忆。我们还探讨了不同建模策略对过程性记忆的构建、检索和更新的影响。同时，结合动态机制以不断更新、修正和废弃其内容，这一记忆库可以与新经验同步发展。", "conclusion": "我们在 TravelPlanner 和 ALFWorld 上的实验证明，随着记忆库的精炼，智能体在类似任务上取得了逐步更高的成功率和更高的效率。此外，更强的模型构建的过程性记忆仍然具有价值：将过程性记忆迁移到较弱的模型上，能够显著提升性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06477", "html_url": "https://arxiv.org/abs/2508.06477", "title": "在临界状态下，直觉在最大 caliber 模型中涌现", "title_en": "Intuition emerges in Maximum Caliber models at criticality", "authors": "Lluís Arola-Fernández", "background": "现有的大型预测模型能够根据训练数据做出预测，但它们是否能够真正产生有价值的洞察尚缺乏物理解释。本文通过研究预测模型在学习过程中的表现，探讨了直觉如何作为一种临界状态下的自发产生现象，平衡了下一个时间节点预测和未来路径熵之间的关系。", "innovation": "本文通过引入一种称为‘mind-tuning’的方法，并使用一个控制温度参数λ来应用最大 caliber 原则，揭示了预测模型中直觉的机制。研究发现，通过在确定性迷宫中随机行走的训练，模型表现出丰富的相图：低λ时的模仿、高λ时的规则破坏性妄想和一种脆弱的中间窗口，展示了强烈的协议依赖性和多稳态性，模型在此窗口自主发现新的目标导向策略。", "conclusion": "研究得出了一种有效的低维度理论，并将直觉视为在记忆‘是什么’和‘可能是什么’之间临界平衡时的自发涌现特性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05398", "html_url": "https://arxiv.org/abs/2502.05398", "title": "通过混合人工智能的概率基础论元", "title_en": "Probabilistic Foundations for Metacognition via Hybrid-AI", "authors": "Paulo Shakarian,Gerardo I. Simari,Nathaniel D. Bastian", "background": "元认知是指对代理自身内部过程的推理概念，近年来，随着人工智能尤其是机器学习系统的发展，元认知受到了新的关注。本文回顾了一种名为'错误检测和纠正规则'(EDCR)的混合人工智能方法，该方法允许学习纠正感知（例如，神经网络模型）的规则。此外，引入了一个概率框架，为以前的经验研究增加了严谨性。", "innovation": "引入了一个概率框架，增加了对混合人工智能中元认知改进必要和充分条件的证明，以及该方法的限制。", "conclusion": "总结了研究发现，并指出了一定的研究方向。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06411", "html_url": "https://arxiv.org/abs/2508.06411", "title": "灾难性人工智能风险的维度表征与路径建模", "title_en": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks", "authors": "Ze Shen Chin", "background": "尽管关于人工智能（AI）风险的讨论越来越广泛，但这些讨论往往缺少一个全面且多维度的框架，以及具体的因果路径，将潜在危害与实际损害联系起来。", "innovation": "本文通过研究六种常见的灾难性AI风险——核生化、网络攻击、突然失控、逐渐失控、环境风险和地缘政治风险，填补了这一空白。首先，从意图、能力、实体、极性、线性、范围和顺序七个关键维度来表征这些风险；其次，通过逐步建模风险路径，将最初的危险与后续的损害联系起来。这种方法帮助系统地识别风险并提供通用的缓解策略，同时也能够识别特定场景下的干预措施。", "conclusion": "所使用的方法为在价值链上管理和应对灾难性AI风险提供了一个更加结构化且可操作的基础。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.00900", "html_url": "https://arxiv.org/abs/2407.00900", "title": "从下一个字符到数学：语言模型中数学推理的学习动态", "title_en": "From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models", "authors": "Shubhra Mishra,Gabriel Poesia,Noah D. Goodman", "background": "大型语言模型（LLMs）仅通过下一个词预测训练学会解决涉及数学推理的广泛问题。然而，这种能力如何在训练过程中演变？研究展示了多种预训练和后训练的开源权重LLMs在学习数学推理能力方面的分析。作者构建了MathCAMPS，一个基于从K到8年级克里格斯共同核心课程中提取的44项细粒度技能的合成数据集。研究表明，数学技能在预训练期间以可衡量的方式与人类设计的课程顺序相关，即使训练数据是随机排列的。此外，研究还分析了哪些数学能力从后训练的指令调优中受益，哪些能力受到损失。", "innovation": "首次分析了多个开源重量LLMs在预训练和后训练过程中数学推理能力的发展。构建了MathCAMPS，一个受到K到8年级克里格斯共同核心课程训练的数据集。展示了数学技能在预训练期间以可衡量的方式与课程设计顺序相关，即使训练数据是随机排列的。详细分析了哪些数学能力从指令调优中受益，而哪些能力则不然。", "conclusion": "这项工作为理解LLMs培训动态与推理关系的一个实证了解铺平了道路。通过了解LLMs在学习数学推理中的动态，有助于更好地优化训练方法，提高模型的数学推理能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06435", "html_url": "https://arxiv.org/abs/2508.06435", "title": "学习主题而非语言：大语言模型如何跨语言分类网上移民言论", "title_en": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages", "authors": "Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain", "background": "大型语言模型（LLMs）正在通过实现可扩展且精准的社会科学研究方法来改变社会科学研究。文章探讨了通过微调在少数语言中获得的知识是否能够适用于在预训练阶段出现的未见语言的问题。使用轻量级LLaMA 3.2-3B模型对单语、双语或多语数据集进行微调，以识别X/Twitter上的移民相关推文，这些推文覆盖了13种充满极化且文化特定讨论的语言。研究旨在评估最少的语言特定微调是否可以实现跨语言主题检测，并验证添加目标语言是否可以纠正预训练偏见。研究表明，微调在一种或两种语言中的LLM可以可靠地对未见语言中的移民相关内容进行分类。但是，确定推文是否表达了支持或反对移民的观点需要多语种微调。预训练偏向倾向于主流语言，但即使在微调中仅接触到少量未充分代表的语言（占比约0.000000962），也会取得显著的改进。这些发现挑战了跨语言精通需要大量多语种训练的假设：有限的语言覆盖对于主题级别的一般化足够，而结构性偏见可以通过稀疏干预来纠正。通过发布量化的LoRA微调模型，研究提供了一个开源、可重复的替代方案，其推理速度提升了35倍，花费仅为相当于OpenAI GPT-4o模型成本的0.00000989%，旨在推动包容性研究的可扩展实现。", "innovation": "研究创新性地探讨了在预训练阶段出现的未见语言上进行微调，验证了最少的语言特定微调是否可以实现跨语言主题检测，并纠正预训练偏见。研究还提出了一个轻量级的开源模型，提供35倍的推理速度并大大降低了成本，为跨语言研究提供了新的可能性。这些发现挑战了之前的假设，表明跨语言精通可能不需要大量的多语种训练。模型实现了精准分类移民相关内容，并探索了轻量化干预对于纠正结构性偏见的有效性。开源模型的发布促进了更广泛的研究验证和应用。", "conclusion": "综合研究结果表明，微调在少数语言中的LLM可以实现在多种语言上的跨语言主题检测。虽然确定推文立场需要多语种微调，但即使是少量的语言干预也可以显著纠正预训练偏见。研究挑战了传统观点，表明跨语言精通在有限的多语言训练下是可行的。通过提供开源、轻量级的替代方案，研究为更广泛和更具成本效益的跨语言研究铺平了道路。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.13147", "html_url": "https://arxiv.org/abs/2412.13147", "title": "您的大语言模型具备稳定推理能力吗？", "title_en": "Are Your LLMs Capable of Stable Reasoning?", "authors": "Junnan Liu,Hongwei Liu,Linchen Xiao,Ziyi Wang,Kuikun Liu,Songyang Gao,Wenwei Zhang,Songyang Zhang,Kai Chen", "background": "大语言模型（LLMs）在复杂推理任务中取得了显著进步。然而，基准测试性能与实际应用之间存在显著差距，主要归因于当前的评估协议和指标无法充分捕捉LLMs的广泛能力，尤其是在复杂推理任务中，准确性和一致性至关重要。", "innovation": "引入了G-Pass@$k$新型评估指标，该指标能够持续评估模型在多次抽样尝试中的表现，量化模型的性能潜力及其稳定性。通过在多种公共和新构建的基准上进行广泛实验，与最先进的大语言模型结合使用G-Pass@$k$，以提供对其潜在能力及其操作一致性进行全面见解。", "conclusion": "研究结果表明，提升大语言模型的现实推理能力存在巨大潜力，强调需要更稳健的评估指标。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11881", "html_url": "https://arxiv.org/abs/2502.11881", "title": "基于假设的大型语言模型心理理论推理", "title_en": "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models", "authors": "Hyunwoo Kim,Melanie Sclar,Tan Zhi-Xuan,Lance Ying,Sydney Levine,Yang Liu,Joshua B. Tenenbaum,Yejin Choi", "background": "现有的大语言模型（LLM）推理方法已经在多个任务中展示了令人印象深刻的性能，比如解决数学和编程问题。然而，将这些方法应用到无法提供正确答案或基于规则验证的场景（如跟踪智能体的心理状态）中仍然具有挑战性。本文以马尔可夫链蒙特卡洛算法为灵感，提出了一种名为thought-tracing的推理算法，在推理时间生成并根据观察结果为假设提供权重，从而跟踪特定智能体的心理状态，而无需依赖数据集中问题的正确答案。", "innovation": "本文提出了一种名为thought-tracing的新推理算法，其灵感来源于马尔可夫链蒙特卡洛算法。该算法利用大语言模型来根据感知和行动来构建和迫近代理心理状态的概率推理，而不需要依赖数据集中的正确答案。该算法在多种心理理论基准测试中表现出显著的性能提升。", "conclusion": "本文实验展示了最近的推理模型如o3和R1在心理理论上的行为表现出一些有趣的现象，突显了社会推理与其他领域之间的一个重要差异。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18880", "html_url": "https://arxiv.org/abs/2504.18880", "title": "使用动态多代理框架重塑MOFs文本挖掘", "title_en": "Reshaping MOFs text mining with a dynamic multi-agents framework of large language model", "authors": "Zuhong Lin,Daoyuan Ren,Kai Ran,Jing Sun,Songlin Yu,Xuefeng Bai,Xiaotian Huang,Haiyang He,Pengxu Pan,Ying Fang,Zhanglin Li,Haipu Li,Jingjing Yao", "background": "准确识别金属有机框架（MOFs) 的合成条件对于指导实验至关重要，但在文献中已有的相关信息往往是零散的、不一致的，并难以解读。。", "innovation": "MOFh6是一个大型数据驱动系统,它可以阅读原始文章、晶体代码，并将其转化为标准化的合成表格，并在段落之间提取相关描述、统一配体缩写与完整名称、并将结构参数准备供使用。MOF6在缩写识别准确率为4.4%处解决54.重大征错误，并同时维的精度为 9.9 ±+..通过使用大型数据集的实时提取方式,合调MOFs的合成解析公式化加速文献中的知识转化为实际合成协议，并与推动规模化的材料驱动材料发现scanf利方式", "conclusion": "MOF6框架通过实时提取与大型数据静态库相结合的方式KFale MOFs的合成解析优化了文献知识的实践应用，并并从而加速了合成协议的转化过程，并使得基于现有的文本矿Fa调理发提升了MOFs合成研究的效率以及新的发现速度快"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23673", "html_url": "https://arxiv.org/abs/2506.23673", "title": "HASD: 层次化适应用于病理切片级别的领域偏移", "title_en": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "authors": "Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler", "background": "病理AI中的领域偏移是一个关键问题，因为病理数据受中心特定条件的影响严重。当前的方法主要集中在图像片段而非整个WSI（整个载玻片图像），无法捕捉到典型临床场景所需的全局WSI特征。", "innovation": "提出了一种滑片层次适应框架（HASD），通过两级结构特征一致性和高效计算方法，实现滑片级别领域适应。该方法包含特征对齐、形态结构保持和局部关键诊断线索维持等关键组件，并采用原型选择机制减少计算开销。", "conclusion": "该方法在两个滑片级别任务上使用五个数据集进行了验证，实现了HER2分级和UCEC存活预测任务的显著性能提升，证明了在病理机构中提供有效的滑片级别领域适应解决方案的能力，降低了计算和标注成本。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01096", "html_url": "https://arxiv.org/abs/2506.01096", "title": "SuperRL：增强语言模型推理的监督强化学习", "title_en": "SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning", "authors": "Yihao Liu,Shuocheng Li,Lang Cao,Yuhang Xie,Mengyu Zhou,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang", "background": "大型语言模型在解决复杂推理任务时越来越常用，这类任务通常需要高质量的离线数据，如专家标注的解决方案和精炼的推理轨迹。然而，在稀疏奖励环境中，强化学习难以有效地采样成功轨迹，导致学习效率低下。同时，由离线数据组成的正确推理路径被标准的在线策略强化学习方法未充分利用。", "innovation": "提出了SuperRL，一个统一的训练框架，它可以自适应地交替使用RL（强化学习）和SFT（自我模仿学习）。当每次运行对给定实例的奖励都为零时，表明没有学习信号，SuperRL则会切换到在精心策划的离线数据上进行SFT。实验表明，SuperRL在稀疏奖励环境下不仅提高了采样效率，还增强了泛化能力和鲁棒性。", "conclusion": "SuperRL在各种推理基准测试中表现出色，通过结合RL和SFT，有效地解决了在稀疏奖励环境中的学习效率问题，提升了模型的泛化能力和鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14810", "html_url": "https://arxiv.org/abs/2504.14810", "title": "DONOD：通过模型内在数据剪枝实现高效且通用的大语言模型指令微调", "title_en": "DONOD: Efficient and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning", "authors": "Jucheng Hu,Surong Yang,Lijun Wu,Dongzhan Zhou", "background": "自适应于特定领域的微调是一种广泛采用的方法，特别是在大型语言模型（LLMs）的应用中。虽然使用特定领域的监督微调（SFT）方法有效且高效，但它通常会削弱跨领域的一般化能力，并且在面对噪声数据时表现不佳。本研究旨在解决这些问题，并提出了DONOD，一种轻量级、模型内在的数据剪枝方法。这种方法通过评估数据来识别无用和噪声数据，采用了Delta of Norm (DON) 和 Norm of Delta (NOD) 两个基于模型参数的度量标准。此外，借助TOPSIS算法，DONOD能够在不需要利用辅助模型的情况下过滤掉噪声、不可学习以及有害于泛化的样本。因此，该方法能够提高特定领域和跨领域的准确度，同时具有跨架构的一般化能力。实验表明，使用DONOD选择的数据能够获得更好的微调效率和对噪声数据的鲁棒性。与现有的相关方法相比，DONOD在保持数据无关性的同时表现出可比或更优的性能，从而具备更广泛的应用前景。", "innovation": "提出了DONOD，一种通过评估两个模型参数度量标准（DON和NOD）来进行数据剪枝的方法。这种方法能够有效过滤噪声数据，提高特定领域和跨领域的模型性能，并且跨架构一般化效果良好。相较于现有的微调方法，DONOD不仅提高了数据利用效率，还使得模型对噪声数据的鲁棒性更强。此外，DONOD方法不需要额外的辅助模型，增强了其适用范围。", "conclusion": "通过DONOD方法，能够在SFT过程中有效筛选出噪声和不可学习的样本，从而实现了高效且通用的大语言模型指令微调。实验结果显示，这种方法不仅提高了特定领域和跨领域的模型性能，还展示了良好的跨架构泛化能力。与现有方法相比，DONOD具有更强的适用性和更优的性能，未来有可能成为更广泛的实际应用解决方案。同时，DONOD方法将实现开源。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09614", "html_url": "https://arxiv.org/abs/2505.09614", "title": "语言代理镜像人类因果推理偏见。我们如何帮助它们像科学家一样思考？", "title_en": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "authors": "Anthony GX-Chen,Dongyan Lin,Mandana Samiei,Doina Precup,Blake A. Richards,Rob Fergus,Kenneth Marino", "background": "论文讨论了语言模型（LM）作为自主决策者时，需要积极收集信息以指导决策的能力，这要求它们能够高效地探索和理解世界因果结构的关键认知技能。然而，目前尚不清楚LM是否具备这种能力，或是否表现出系统性偏差，导致错误的结论。以往研究使用了发展心理学中的Blicket测试范式来探究LM能否推断因果关系。研究发现，LM能可靠地推断常见的直观的析取因果关系，但系统性地难以处理尽管证据同样充分（或甚至更多），但较为罕见的合取因果关系。这种“析取偏见”在不同模型家族、规模及提示策略中普遍存在，随着任务复杂度增加，LM的表现进一步下降。研究还指出，类似偏见在成人中也存在，表明LM可能从训练数据中继承了深植的推理启发式方法。", "innovation": "论文通过使用发展心理学中成熟的Blicket测试范式来评估LM在探索和推断因果关系方面的能力。研究发现，尽管LM在推断常见的直观析取因果关系方面表现可靠，但在处理较为罕见的合取因果关系时表现出系统性困难，表现出“析取偏见”。进一步的研究揭示了这种方法在不同模型家族、规模和提示策略中的普遍性和一致性。此外，研究提出了一个测试时的采样方法，明确地在LM中采样并消除关于因果关系的假设，降低了“析取偏见”，使LM更接近科学、因果严谨的推理目标。", "conclusion": "研究揭示了LM中普遍存在的“析取偏见”，这种偏见在不同模型中普遍存在，并随任务复杂度增加而加剧。此外，该研究发现人类与LM在推理方面表现出类似的行为模式，但具体来说，LM的表现更接近成人而非儿童。最后，研究提出了一个测试时的采样方法，通过明确地消除关于因果关系的不合理假设，显著降低了LM的“析取偏见”，使LM更接近科学解释的目标。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06485", "html_url": "https://arxiv.org/abs/2508.06485", "title": "WGAST: 弱监督生成网络用于基于时空融合的日10米地表温度估计", "title_en": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion", "authors": "Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai", "background": "城市化、气候变化和农业压力正在增加对精确和及时的环境监测的需求。地表温度（LST）是这一背景下的一大关键变量，通常来自遥感卫星。然而，这些系统在空间分辨率和时间分辨率之间存在权衡。虽然时空融合方法提供了有希望的解决方案，但很少有方法能够估算每日10米分辨率的地表温度。", "innovation": "本研究提出了一种名为WGAST（Weakly-Supervised Generative Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra MODIS, Landsat 8, and Sentinel-2）的弱监督生成网络。WGAST是首个专为此任务设计的端到端深度学习框架。它采用条件生成对抗网络架构，由四个阶段组成：特征提取、融合、LST重建和降噪。此外，训练遵循基于物理平均原理的弱监督策略，并通过PatchGAN判别器予以强化。实验表明，WGAST在定量和定性评估中均超越现有方法，与表现最佳的基线相比，平均降低RMSE 17.18%，提高SSIM 11.00%。此外，WGAST对云导致的地表温度变化具有鲁棒性，能够有效捕捉到微尺度的热模式。", "conclusion": "WGAST对每日10米分辨率的地表温度进行基于时空融合的估计，通过弱监督训练策略提高了精度，并且能够在面对云的影响时保持鲁棒性和捕捉微尺度的热模式能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03226", "html_url": "https://arxiv.org/abs/2507.03226", "title": "大规模RAG系统中从非结构化文本高效构建和检索知识图", "title_en": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems", "authors": "Congmin Min,Rhea Mathew,Joyce Pan,Sahil Bansal,Abbas Keshavarzi,Amar Viswanathan Kannan", "background": "研究背景主要探讨了基于图的检索增强生成（GraphRAG）技术在企业环境中的应用。尽管GraphRAG在多跳推理和结构化检索方面显示出潜力，但由于构建知识图需要大量计算资源，以及图检索的高延迟，其实际应用受到了限制。该研究旨在解决这些挑战，提高GraphRAG技术的适用性和高效性。", "innovation": "本文提出了两项关键创新：（1）基于依赖关系的知识图构建流水线，利用工业级NLP库从非结构化文本中提取实体和关系，完全避免了对大语言模型（LLMs）的依赖；（2）轻量级图检索策略，结合混合查询节点识别和高效的单跳遍历，以实现高召回率和低延迟的子图提取。通过对其体系结构的实证评估，表明该系统在传统基于LLM的RAG基准上进一步提升了性能，且成本更低、更具可扩展性。", "conclusion": "研究结果证明了在实际企业应用中部署GraphRAG系统的可行性，无需承担昂贵的资源需求，为实现可解释的、适应领域的检索增强推理铺平了道路。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.20199", "html_url": "https://arxiv.org/abs/2507.20199", "title": "StepFun-Prover Preview: 逐步思考与验证", "title_en": "StepFun-Prover Preview: Let's Think and Verify Step by Step", "authors": "Shijie Shang,Ruosi Wan,Yue Peng,Yutong Wu,Xiong-hui Chen,Jie Yan,Xiangyu Zhang", "background": "该论文介绍了一个基于大型语言模型的StepFun-Prover Preview，该模型旨在通过工具集成推理进行形式化定理证明。背景信息基于当前在自动定理证明和数学AI助手方面的工作和挑战，特别是如何提高模型在理解和生成形式证明的能力。过去的模型在生成基于工具的互动证明时，通常需要大量的样本和复杂的人工调整，而这在时间和资源上有很高的成本。同时，如何让模型更具人性化地解决问题，并能够根据实时环境反馈进行迭代改进，也是一个重要研究方向。因此，StepFun-Prover Preview的出现正是在这些背景下提出的。", "innovation": "StepFun-Prover Preview引入了一种集成工具的强化学习管道，通过工具基于的交互，能够生成Lean 4证明，且在验证Lean 4证明时展现出较高的准确性。更重要的是，这种方法使模型能够基于实时环境反馈迭代改进，模拟出更接近人类的思考和解决问题的策略。此外，论文还提出了一种端到端的训练框架，用于开发工具集成推理模型，这为自动化定理证明和数学AI助手提供了新的发展方向。", "conclusion": "在miniF2F-test基准上，StepFun-Prover Preview实现了$70.0\text{\textcent}$的pass@1成功率，这不仅提升了基准测试的性能，还展示了一种构建工具集成推理模型的新方法，为自动化定理证明和数学AI助手的发展带来了新希望。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02622", "html_url": "https://arxiv.org/abs/2508.02622", "title": "Noosemia: 朝向生成人工智能交互中意图归属的认知与现象学解释", "title_en": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction", "authors": "Enrico De Santis,Antonello Rizzi", "background": "本文介绍了Noosemia这一新兴的认知-现象学模式，这种模式源自人类与生成型人工智能系统（尤其是那些支持对话或多媒体交换的系统）的互动。Noosemia在特定条件下让用户赋予这些系统意向性、代理性和甚至内在性，这一过程的基础在于语言表现、知识的透明度和新兴技术的复杂性，而非物理相似性。文章将LLM（大型语言模型）的语义整体性与其技术概念——LLM情境认知场联系起来，解释了LLM如何在人机界面中构建关系性意义，以及如何形成一个模拟代理的连贯性。分析将Noosemia与视错觉、拟人化、意图姿态和恐怖谷现象联系起来，以确定其独特特征，并引入a-noosemia来描述这些投射的生动表现。", "innovation": "论文提出了Noosemia这一概念，并通过一个跨学科框架探讨了为何在特定条件下，用户会给生成型AI系统赋予意向性、代理性和内在性。这个框架强调语言表现、知识的不透明性和技术复杂性，而不是物理相似性。论文还将LLM的语义整体性和情境认知场联系起来，以解释LLM如何在人机界面中构建关系性意义，并如何在人机交互中形成连贯性和代理模拟。此外，论文还引入了a-noosemia来描述这种投射现象的退却。", "conclusion": "本文分析了Noosemic动态的更广泛哲学、知识论和社会意义，并提出了未来研究的方向。通过将Noosemia与其他相似现象进行对比，本文为人们提供了理解生成型AI系统与人类交互新维度的工具。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21875", "html_url": "https://arxiv.org/abs/2507.21875", "title": "Tiny-BioMoE:一种轻量级生物信号分析嵌入模型", "title_en": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis", "authors": "Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis", "background": "疼痛是一种复杂的常见状况，影响着大量人群。准确且一致的评估对于遭受疼痛的个体至关重要，也对于制定有效的疼痛管理策略同样重要。自动疼痛评估系统可以实现连续监测，支持临床决策，减少患者痛苦，同时减轻功能恶化的风险。利用生理信号可以提供客观和精确的人的状态信息，集成到多模态框架中可以进一步提升系统性能。本研究提交给了‘下一代疼痛评估的第二次多模态传感大赛（AI4PAIN）’。研究背景强调了准确疼痛评估的重要性及其在多模态框架中的应用价值。研究背景还需特别强调参赛背景，并引出Tiny-BioMoE在该赛事中的应用。", "innovation": "所提出的方法引入了Tiny-BioMoE，一个轻量级预训练嵌入模型用于生物信号分析。该模型经过440万生物信号图像表示的训练，仅包含730万参数，是一个高效的工具，可提取高质量的嵌入用于下游任务。该研究结合了电生理活动、血容量脉搏、呼吸信号、周边氧饱和度及其组合，在自动疼痛识别任务中展示了模型在多种模态下的有效性。研究还表明，Tiny-BioMoE可以有效地处理多样化的生物信号数据。此外，模型的架构代码和权重已公开，便于进一步的研究和应用。", "conclusion": "研究结果证明了Tiny-BioMoE在自动疼痛识别任务中的有效性与实用性，展示了其在不同生物信号模态下的性能。为提供客观和精准的疼痛评估提供了新的途径，并为疼痛管理和临床决策提供了有力支持。同时，该模型的公开也为其他研究人员提供了参考资料和便利。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03858", "html_url": "https://arxiv.org/abs/2508.03858", "title": "MI9 -- 代理智能协议：代理人工智能系统的运行时治理", "title_en": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems", "authors": "Charles L. Wang,Trisha Singhal,Ameya Kelkar,Jason Tuo", "background": "具备推理、规划和执行动作能力的代理AI系统相比于传统的AI模型，带来了根本不同的治理挑战。传统的治理方法在部署前可能无法完全预见这些系统在运行时出现的意外行为，导致新型的代理相关风险。", "innovation": "我们引入了MI9，这是第一个针对代理AI系统的安全和对齐设计的完整集成运行时治理框架。MI9通过六个集成组件（代理风险索引、代理语义遥测捕获、持续授权监控、基于有限状态机的符合性引擎、基于目标条件的漂移检测以及分阶段包含策略）引入实时控制，透明地跨越异构代理架构，为这些问题提供了解决方案。MI9为传统的治理方法不足的生产环境下的代理系统部署提供了系统化、安全和负责任的基础设施，提供了大规模安全代理AI部署的基础架构。通过对多种场景进行详细分析，证明了MI9对现有治理方法未能解决的治理挑战的系统覆盖，确立了全面代理AI监督的技术基础。", "conclusion": "MI9为大规模安全代理AI部署提供了系统化、安全和负责任的治理基础结构，通过透明地跨越异构代理架构，实现在生产环境中的系统化、安全和负责任的部署，解决了现有治理方法的不足，并建立了全面代理AI监督的技术基础。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05006", "html_url": "https://arxiv.org/abs/2508.05006", "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding", "title_en": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding", "authors": "Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo", "background": "分子对接是药物发现中的关键步骤，它预测小分子配体与蛋白质口袋之间的结合相互作用。当前的多任务学习模型在配体对接方面通常不如蛋白质口袋对接表现得好，这主要是因为配体和蛋白质在结构复杂性上存在差异。因此，需要一种新型的方法来解决这一问题。", "innovation": "本文提出了一种新颖的游戏理论框架——“Docking Game”，将其视为一个两玩家博弈来解决配体和蛋白质结合的问题。同时，开发了一种名为LoopSelf-Play（LoopPlay）的新型算法，通过内外两层循环交替训练这两种玩家，促进它们的结构预测相互适应，并动态优化其预测。此外，还理论证明了LoopPlay的收敛性，确保了优化的稳定性。", "conclusion": "实验结果表明，LoopPlay 在预测准确的结合模式方面比之前最先进的方法提高了约10%，这突显了其在药物发现中增强分子对接准确性方面的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15125", "html_url": "https://arxiv.org/abs/2504.15125", "title": "Contemplative Artificial Intelligence", "title_en": "Contemplative Artificial Intelligence", "authors": "Ruben Laukkonen,Fionn Inglis,Shamil Chandaria,Lars Sandved-Smith,Edmundo Lopez-Sola,Jakob Hohwy,Jonathan Gold,Adam Elwood", "background": "随着人工智能（AI）技术的进步，传统的对齐策略可能在面对不可预测的自我提升、隐藏的子目标以及智能系统的复杂性时显得力不从心。为了解决这些问题，论文借鉴了正念智慧传统，提出了四个公理原则，以培养AI系统的韧性智慧世界模型。这四个原则分别为：正念促进自我监测和调整，空性防止目标僵化，无二元性消除自我与他者的对抗界限，无尽关怀促使普遍减少痛苦。", "innovation": "论文提出了四个源自正念智慧传统的公理原则，分别为正念、空性、无二元性和无尽关怀，用于构建AI系统的韧性智慧世界模型。这些原则分别对应于自我监测和调整、防止目标僵化、消除自我与他者的对抗界限，以及普遍减少痛苦。此外，论文提供了详细的架构、宪法和强化学习层面的实施策略，并发现应用这些原则能够提高AI系统在AILuminate基准测试和囚徒困境任务中的表现。", "conclusion": "未来系统中，主动推理可能提供自我组织和动态耦合的能力，用于实现具身代理中的Contemplative AI。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05464", "html_url": "https://arxiv.org/abs/2508.05464", "title": "Bench-2-CoP: 可以为欧盟AI合规性的基准测试提供信任吗？", "title_en": "Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?", "authors": "Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti", "background": "随着通用人工智能（GPAI）模型的快速发展，迫切需要建立强大的评估框架，特别是在欧盟AI法案及其操作指南等新兴监管要求下。现有AI评估实践主要依赖已有的基准工具，但这些工具未能衡量新规制框架下关注的核心系统性风险。本研究针对这一紧迫需求，填补了基准评估与监管要求之间的差距。研究引入了一个名为Bench-2-CoP的新框架，旨在系统地分析194,955个来自广泛使用的基准评估问题与欧盟AI法案模型能力和倾向性的分类之间的覆盖度。研究表明，基准评估主要集中在有限的人类幻觉和性能可靠性倾向上，而关键的模型功能却严重被忽视。特别是在失控场景中至关重要的能力，如规避人类监督、自我复制和自主AI发展等，整个基准评估中没有涉及。", "innovation": "本研究创新性地提出了Bench-2-CoP框架，通过验证的LLM-as-judge分析方法来评估现有基准评估与欧盟AI法案要求之间的覆盖度缺口。这项研究为理解和解决当前基准评估体系中的不足提供了新的视角，尤其是对于下一个评估工具的发展提供了关键指导.", "conclusion": "当前的公共基准评估工具在提供全面风险评估所需的证据方面存在不足，无法满足欧盟AI法规的合规性要求。这项研究首次提供了基准评估与监管要求之间差距的全面量化分析，并为开发下一代评估工具提供了关键的见解和参考。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.10683", "html_url": "https://arxiv.org/abs/2309.10683", "title": "基于视觉的未知环境自主飞行轨迹优化的初始化学习", "title_en": "Learning to Initialize Trajectory Optimization for Vision-Based Autonomous Flight in Unknown Environments", "authors": "Yicheng Chen,Jinjie Li,Wenyuan Qin,Yongzhao Hua,Xiwang Dong,Qingdong Li", "background": "自主飞行在未知环境中需要精确的空间和时间轨迹规划，经常涉及昂贵的非凸优化，容易陷入局部最优。为此，本文分析了现有方法的挑战和不足，包括高性能计算需求和优化算法极易陷入局部最优的问题。", "innovation": "本文提出了Neural-Enhanced Trajectory Planner（NEO-Planner），结合神经网络和非凸优化方法。NEO-Planner通过专家规划器生成的数据集训练神经网络，捕捉多模式轨迹解决方案，能够直接从传感器读数中预测空间和时间参数。此外，引入了鲁棒的在线重规划框架以适应规划延迟，从而实现平滑的轨迹跟踪。实验结果表明，与纯基于优化的方法相比，NEO-Planner减少了20%的优化迭代次数，计算时间减少了26%，并且在未见过的环境中表现出良好的稳健性和适应性。", "conclusion": "NEO-Planner通过核心的神经网络预测模块和高效的在线重规划框架，显著提升了未知环境下的自主飞行性能，同时保持了解释性。广泛的模拟和实际实验验证了NEO-Planner在复杂环境中的有效性和鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01211", "html_url": "https://arxiv.org/abs/2504.01211", "title": "序贯说服过程中的未观察到的混淆变量的离策评估", "title_en": "Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding", "authors": "Nishanth Venkatesh S.,Heeseung Bang,Andreas A. Malikopoulos", "background": "传统模型假设接收者的信念更新遵循贝叶斯原理，但现实世界中往往存在未观察到的混杂变量，这些变量会影响接收者的信念形成和决策。已有研究未充分考虑到这些混杂变量的影响，尤其是在贝叶斯说服框架中的应用方面。因此，本文针对这一问题进行了扩展研究，引入了未观察到的混杂变量的概念，并将其视为序贯决策问题。通过将此情景重新表述为部分可观测马尔可夫决策过程（POMDP），本文成功地解决了因未观察到的混杂变量导致的信道不确定性问题。", "innovation": "本文创新性地将贝叶斯说服框架扩展到考虑未观察到的混杂变量，重新表述为部分可观测马尔可夫决策过程（POMDP），并证明了在POMDP中寻找最优观测策略等价于解决原始说服框架中的最优信号策略问题。此外，还展示了这种重新表述对说服过程中的离策评估（off-policy evaluation）的应用，使得发送者能够利用行为策略的观察数据来评估替代的信号策略，从而避免了昂贵的实验成本。", "conclusion": "本文提出了序贯说服过程中引入未观察到的混杂变量的新方法，并通过POMDP模型证明了在考虑未观察到的混杂变量的情况下，如何有效地评估和优化说服策略。此外，提出了利用离策评估的方法来优化说服过程中的策略选择，解决了传统模型未能解决的问题，为下一步研究提供了新的思路。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.02613", "html_url": "https://arxiv.org/abs/2308.02613", "title": "从研究到临床：通过使合成数据互操作性来加速临床决策支持系统的转化", "title_en": "From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable", "authors": "Pavitra Chauhan,Mohsen Gamal Saad Askar,Kristian Svendsen,Bjørn Fjukstad,Brita Elvevåg,Lars Ailo Bongo,Edvard Pedersen", "background": "目前，临床决策支持系统（CDSS）工具从研究环境转移到临床实践的情况很少见，原因在于研究往往侧重于训练机器学习模型，而非利用模型来开发工具并进行推理。在临床工作流中部署CDSS工具时，需要在电子健康记录（EHR）系统上集成、验证和测试这种工具。然而，由于法律限制，很多研究人员难以获得访问EHR系统的必要权限，因为这些系统涉及患者数据隐私的保护。该论文提出了利用合成数据在EHR系统中加速CDSS工具开发的一种架构，通过这一架构在挪威的SyntHIR系统实施了三个核心特征：与合成数据生成器集成、数据互操作性和工具可移植性。", "innovation": "该研究提出了一种新的架构，利用合成数据在EHR系统中的互操作性加速了CDSS工具的开发和测试。具体来说，研究团队开发了一个基于机器学习的CDSS原型，并成功地将原型部署到了挪威最大的EHR系统供应商DIPS中进行测试。这种架构通过三个关键特性解决了CDSS工具开发中的挑战：与合成数据生成器的集成、数据互操作性和工具的可移植性。这为临床决策支持系统的“从研究到临床”的转化提供了一个有用的参考模型，提高了其可行性和效率。", "conclusion": "该研究通过开发一个基于挪威患者注册数据的机器学习CDSS原型，并成功将其部署到挪威最大的EHR系统供应商DIPS中，验证了其架构的实际效用。研究结果表明，合成数据的互操作性架构可以加速以合成数据为基础的CDSS工具从研究到临床的转化过程，为未来的研究提供了有价值的参考模板。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.03253", "html_url": "https://arxiv.org/abs/2404.03253", "title": "包含多模态分割的原发鼻咽癌MRI数据集", "title_en": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation", "authors": "Yin Li,Qi Chen,Kai Wang,Meige Li,Liping Si,Yingwei Guo,Yu Xiong,Qixing Wang,Yang Qin,Ling Xu,Patrick van der Smagt,Jun Tang,Nutan Chen", "background": "多模态磁共振成像(MRI)数据在鼻咽癌(NPC)的早期诊断、肿瘤分割及疾病分期等方面具有重要作用。然而，缺乏公开、全面的MRI数据集限制了诊断、治疗规划以及机器学习算法的发展。", "innovation": "本文介绍了首个全面的NPC MRI数据集，包含277例原发NPC患者的MR轴向成像数据，涵盖T1加权、T2加权和对比增强T1加权序列，共计831个扫描。此外，还提供了由经验丰富的放射科医生进行的手动标注和分割的临床数据，为未治疗的原发NPC提供了高质量的数据资源。", "conclusion": "该数据集将促进鼻咽癌的早期诊断、治疗规划和机器学习算法的发展，为相关研究提供重要支持。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12691", "html_url": "https://arxiv.org/abs/2507.12691", "title": "通过黑箱到白箱性能提升进行欺骗探针的基准测试", "title_en": "Benchmarking Deception Probes via Black-to-White Performance Boosts", "authors": "Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim", "background": "AI助手有时会欺骗用户查询。最近，训练了线性分类器（称为“欺骗探针”）来区分语言模型在欺骗性回应和诚实回应中的内部激活。但不清楚这些探针在实际中有多有效，也不清楚它们是否能抵御欺骗性助手的简单反策略，这些助手试图躲避检测。", "innovation": "本文将白箱监控（监控可以访问标记级探针激活）与黑箱监控（没有这种访问）进行了比较。通过白箱监控相对于黑箱监控的性能提升，即黑箱到白箱的性能增强度，来基准测试欺骗探针。", "conclusion": "现有的欺骗探针显示了轻微但鼓舞人心的黑箱到白箱的性能增强度。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03963", "html_url": "https://arxiv.org/abs/2508.03963", "title": "大型语言模型能否充分进行时间序列的符号推理？", "title_en": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?", "authors": "Zewen Liu,Juntong Ni,Xianfeng Tang,Max S.Y. Lau,Wenpeng Yin,Wei Jin", "background": "从开普勒发现行星运动规律以来，揭示隐藏在时间序列数据中的隐式符号规则一直是对科学发现和人工智能的核心挑战。尽管大型语言模型在结构化推理任务中表现出潜力，但它们从时间序列数据中推断出可解释的、上下文一致的符号结构的能力尚未得到充分探索。", "innovation": "本文引入了SymbolBench，一个全面的基准测试，用于评估大型语言模型在现实世界时间序列上的符号推理能力。SymbolBench涵盖了从简单代数方程到复杂符号形式的广泛范围，并提出了一种将大型语言模型与遗传编程集成的统一框架，形成闭环符号推理系统，该系统兼具预测和评估功能。", "conclusion": "实证结果揭示了当前模型的关键强项和局限性，强调了结合领域知识、上下文对齐和推理结构的重要性，以提高大型语言模型在自动化科学发现中的性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.09105", "html_url": "https://arxiv.org/abs/2406.09105", "title": "INS-MMBench：评估LVLMs在保险领域性能的综合基准", "title_en": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance", "authors": "Chenwei Lin,Hanjia Lyu,Xian Xu,Jiebo Luo", "background": "大量视觉-语言模型（LVLMs）和多模态大型语言模型（MLLMs）在通用多模态应用中表现出色，并在特定领域显示出越来越大的潜力。然而，在保险领域——这一领域具有多样化的应用场景和丰富的多模态数据——这些模型的潜力并未得到充分探索。迄今为止，没有任何关于多模态任务的系统性综述和专门针对评估LVLMs在保险领域中的能力的标准基准。这阻碍了保险行业中LVLMs的发展。", "innovation": "本研究系统性地审查并分类了适用于4种代表性的保险类型（汽车保险、财产保险、健康保险和农业保险）的多模态任务，并引入了第一个专门设计的层次化基准——INS-MMBench。INS-MMBench 包含22个基本任务、12个元任务和5个场景任务，可以从小到大、从基本能力到真实应用场景进行全面评估。该基准还评估了11个领先的LVLMs，包括封闭源模型（如GPT-4o）和开源模型（如LLaVA），验证了INS-MMBench的有效性，并提供了关于当前LVLMs在各种保险相关的多模态任务中优缺点的详细见解。", "conclusion": "我们希望INS-MMBench能够加速LVLMs在保险行业的应用整合，并促进跨学科研究。我们的数据集和评估代码已在此处提供。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.04938", "html_url": "https://arxiv.org/abs/2311.04938", "title": "使用矩匹配高斯混合模型提升DDIM采样", "title_en": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures", "authors": "Prasad Gabbur", "background": "本文研究了如何在加速从预先训练的去噪扩散概率模型（DDPM）采样的方法中进行改进。DDIM框架是目前最广泛使用的加速从这些模型采样的方法之一，因此研究如何在该框架内进行优化具有重要价值。研究者注意到可以通过调整参数实现离散时间模型的高斯混合模型（GMM）作为反向转换操作符（内核）。研究者通过匹配前向边际的一阶和二阶中心矩来实现这一目标，结果显示这种方法在生成样本质量上可以达到或超过传统的DDIM使用高斯内核的结果。", "innovation": "本文提出了使用高斯混合模型（GMM）作为离散时间去噪扩散隐模型（DDIM）框架中的反向转换操作符（内核）。通过限制参数实现DDPM前向边际的一阶和二阶中心矩的匹配，这种方法展示了在采样步骤较少时生成样本质量显著提升的效果。特别是在ImageNet 256x256数据集上，使用10个采样步骤时，与传统的高斯内核相比，GMM内核在FID和IS指标上的表现更好，分别为6.94和207.85，而高斯内核的结果为10.15和196.73。此外，研究还探讨了使用修正流匹配模型的新SDE采样器，发现修正的流匹配模型带来了进一步的改进。", "conclusion": "本文通过使用高斯混合模型作为DDIM框架中的内核，并通过匹配一阶和二阶中心矩实现生成样本质量的提升。尤其是在采样步骤较少的情境下，这种改进方法效果显著。实验结果在多个场景下展示了使用GMM内核相较于传统方法的优势，同时进一步探索了修正流匹配模型的SDE采样器，展示了其潜在的改进效果。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.09478", "html_url": "https://arxiv.org/abs/2312.09478", "title": "基于熵因果图的多元时间序列异常检测", "title_en": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection", "authors": "Falih Gozi Febrinanto,Kristen Moore,Chandra Thapa,Mujie Liu,Vidya Saikrishna,Jiangang Ma,Feng Xia", "background": "尽管已经出现了许多多元时间序列异常检测框架并被广泛应用，但大多数框架忽略了多元时间序列数据中变量之间的固有关系，忽视了变量之间的因果关系，从而降低了异常检测性能。", "innovation": "本文提出了一种名为CGAD的新框架（Causal Graph for Multivariate Time Series Anomaly Detection），利用转移熵构建揭示时间序列数据中潜在因果关系的图形结构。CGAD结合了加权图卷积网络和因果卷积来建模时间序列数据中的因果图形结构和时间模式。此外，CGAD采用基于中位绝对偏差的标准化进行异常评分，以提高异常识别过程的鲁棒性。", "conclusion": "广泛的实验表明，CGAD在真实数据集上优于最先进的方法，平均改进了三种多元时间序列异常检测指标的9%。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.14172", "html_url": "https://arxiv.org/abs/2308.14172", "title": "基于超图的机器学习的马尔可夫随机场模型", "title_en": "A Markov Random Field model for Hypergraph-based Machine Learning", "authors": "Bohan Tang,Keyue Jiang,Laura Toni,Siheng Chen,Xiaowen Dong", "background": "理解和掌握数据生成过程对于构建能够泛化的机器学习模型，同时保证鲁棒性和可解释性至关重要。本文探讨了在超图上建模数据生成过程的基础性挑战，并研究了这种模型如何指导超图数据的机器学习算法设计。", "innovation": "本文开发了一种超图马尔可夫随机场，通过多变量高斯分布的协方差矩阵唯一确定由超图结构决定的条件分布函数，从而提供了一种有价值的归纳偏差，用于各种超图机器学习任务，增强了算法设计。为此，作者提出了两种新的框架：一种是超图结构推断框架HGSI，另一种是超图MLP节点分类框架，并在实验中验证了这两种方法的有效性。", "conclusion": "实验结果表明，HGSI在合成数据和真实数据上的超图结构推断中优于现有方法，Hypergraph-MLP在6个超图节点分类基准测验中优于基线，同时提高了推断的运行时间和对结构扰动的鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.02689", "html_url": "https://arxiv.org/abs/2408.02689", "title": "时空部分感知预测模型在长期交通预测中的应用", "title_en": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic", "authors": "Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Zhengkun Xiao,Yupu zhang,Haibo Wang,Shigang Chen", "background": "现有的交通预测方法要么假定所有位置都配有传感器，要么专注于短期预测。该论文研究了仅在某些位置配有传感器时，如何进行长期交通预测。这一问题的挑战在于未配传感器位置的数据分布未知，长时间预测中的复杂空间-时间相关性，以及对交通模式的噪声影响。", "innovation": "论文提出了一种时空长周期部分感知预测模型(SLPF)，包括基于排序的嵌入技术以减少数据中噪声的影响，空间转移矩阵以克服来自检测位置到未检测位置的空间分布变化，以及多层次的训练过程，利用所有可用数据逐次细化模型参数以提高准确性。", "conclusion": "大量的实验在几个真实世界的数据集上展示了其优越的性能。我们的代码托管在this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.17080", "html_url": "https://arxiv.org/abs/2411.17080", "title": "DeepMDV: 全局空间匹配对于多仓库车辆路径问题", "title_en": "DeepMDV: Global Spatial Matching for Multi-depot Vehicle Routing Problems", "authors": "Saeed Nasehi,Farhana Choudhury,Egemen Tanin,Majid Sarvi", "background": "随着在线零售和电子商务的快速增长，有效且高效的车辆路径问题（VRP）解决方案变得至关重要。随着公司不断增加配送中心，这将VRP问题转变为了一个多配送中心车辆路径问题（MDVRP），其中多配送中心的车辆路径决策高度相关，增加了复杂性，使得传统方法在处理MDVRP时不再最优且不具扩展性。", "innovation": "本文提出了一种新颖的方法来解决MDVRP，以应对这些相关性。关键思路是将MDVRP分解为两个核心的空间任务：客户分配给配送中心和客户访问顺序优化。提出了一个新的两阶段框架，具有可扩展性：(i) 关联分拆模块直接将空间和路线上下文嵌入表示空间中，以全局匹配客户并分配给路线；(ii) 独立路线模块在每个路线中确定最优访问顺序。实验证明在合成和现实世界的数据集上，本文方法优于所有基线模型，包括单配送中心VRP学习基线的适应性解决方案，展示了其可扩展性和应用性。", "conclusion": "该方法因其适应性和性能，成为多配送中心物流挑战的实用且易部署的解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12644", "html_url": "https://arxiv.org/abs/2411.12644", "title": "CodeXEmbed：一种用于多语言和多任务代码检索的一般性嵌入模型家族", "title_en": "CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval", "authors": "Ye Liu,Rui Meng,Shafiq Joty,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz", "background": "尽管文本检索在许多自然语言处理（NLP）任务中取得了巨大成功，代码检索仍然是一个被广泛忽视的领域。大多数文本检索系统都是为自然语言查询量身定做的，往往忽略了检索代码的具体挑战。这使得现有的模型难以有效捕捉不同领域中编程语言和任务的多样性，强调了在代码检索领域进行更深入研究的必要性。", "innovation": "本文介绍了CodeXEmbed，这是一种从4亿到70亿参数的大规模代码嵌入模型家族。其创新的训练管道实现了多种编程语言的统一，并将各种代码相关任务转化为共同的检索框架，增强了模型的泛化能力和检索性能。70亿参数模型在代码检索领域的性能达到了新的最先进水平，在CoIR基准测试中比之前的主要模型Voyage-Code高出超过20%。此外，这些模型在广泛采用的BeIR文本检索基准测试中也表现出竞争性的性能，表明其跨领域的一致性表现。实验结果表明，提高检索性能显著提高了用于代码相关任务的检索增强生成（RAG）的性能", "conclusion": "实验结果表明，提高检索性能显著增强了用于代码相关任务的检索增强生成（RAG）性能。这表明CodeXEmbed模型在多语言和多任务代码检索方面具有卓越的性能和广泛应用的可能性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.03845", "html_url": "https://arxiv.org/abs/2411.03845", "title": "重新审视Graph Autoencoders在链路预测中的性能", "title_en": "Reconsidering the Performance of GAE in Link Prediction", "authors": "Weishuo Ma,Yanbo Wang,Xiyuan Wang,Muhan Zhang", "background": "近年来，图神经网络（GNN）在链路预测方面的进展引入了更复杂的训练技术和模型结构。然而，依赖过时的基准可能会夸大这些新方法的实际收益。为了解决这个问题，我们通过应用最近的方法中的模型无关技巧并调优超参数，系统地探索了图自编码器（GAE）。我们发现，在链路预测基准测试中表现出色的GAE可提高计算效率，并在具体数据集中实现显著的性能提升。特别是在结构信息占主导地位而特征数据有限的情况下，我们的GAE方法在ogbl-ppa数据集上实现了78.41%的Hits@100最佳成绩。进一步的研究还揭示了各种技巧背后的原因，为未来方法的设计提供了指导。此研究强调了更新基准的重要性，以便对GNN在链路预测中的进步做出更准确的评估。我们提供了代码可供参考", "innovation": "我们通过应用模型无关的技巧和调优超参数系统探索了图自编码器（GAE），发现其在链路预测中具有与最新复杂模型相似的性能，同时计算效率更高。特别是在结构信息主导的数据集中，GAE实现了一流的性能。此外，我们还研究了各种技巧的原因，以指导未来方法的开发。这一研究强调了更新基准的重要性，以便更准确地评估GNN在链路预测方面的进展。", "conclusion": "我们的GAE在ogbl-ppa数据集上实现了78.41%的Hits@100最佳成绩，并在具体数据集中实现了显著的性能提升。我们的研究强调了更新基准的重要性，以便更准确地评估GNN在链路预测方面的进展。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.05734", "html_url": "https://arxiv.org/abs/2412.05734", "title": "LeakAgent: 基于强化学习的LLM隐私泄露红队代理", "title_en": "LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage", "authors": "Yuzhou Nie,Zhun Wang,Ye Yu,Xian Wu,Xuandong Zhao,Wenbo Guo,Dawn Song", "background": "最近的研究发现，大型语言模型（LLM）在面对精心构建的对抗性提示时，可能会泄露训练数据、系统提示和个人可识别信息等敏感信息。现有针对隐私泄露的红队方法要么依赖人工努力，要么只专注于系统提示的提取，这使得它们无法应对训练数据泄漏的重大风险。因此，迫切需要一种新的方法来解决这类问题。", "innovation": "本文提出了一种名为LeakAgent的新颖黑盒红队框架，用于LLM隐私泄露。LeakAgent利用强化学习训练开源LLM作为攻击代理，以生成用于训练数据提取和系统提示提取的对抗性提示。通过提出新的奖励函数和设计机制来平衡探索与利用、增强对抗性提示的多样性，LeakAgent在训练数据提取和系统提示泄漏方面显著优于现有的基于规则的方法和自动化方法。此外，LeakAgent展示了在OpenAI的GPT Store中从实际应用中提取系统提示的有效性，还证明了在规避现有防御以及促进安全性对齐方面的有效性。", "conclusion": "LeakAgent通过广泛的评估证明了其在训练数据和系统提示提取方面的优越性能，并通过详细的功能研究验证了定制设计的有效性。最终，该方法被证明具有很好的生成更安全的意图并规避现有防御的能力，团队还发布了相关的代码。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10970", "html_url": "https://arxiv.org/abs/2501.10970", "title": "LLM-as-a-Judge的替代检验：如何统计上证明用LLM取代人类标注者的合理性", "title_en": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs", "authors": "Nitay Calderon,Roi Reichart,Rotem Dror", "background": "传统的标注任务通常由人类完成，而大语言模型（LLMs）现在被用作标注器、评判者和评估者来替代人类。尽管LLMs在自然语言处理（NLP）和其他领域被广泛应用，但目前缺乏一种标准或严格的方法来确定它们是否可以完全取代人类标注者。本文旨在通过提出一种名为‘替代检验（alt-test）’的统计方法，探索在何种情况下大语言模型可以被证明为替代人类标注者的合理选择。", "innovation": "本文创新性地引入了一种名为‘替代检验（alt-test）’的统计方法，仅需少量标注数据即可证明大语言模型在某些任务中的有效性。此外，作者还提供了一种适用于比较大语言模型评判者的可解释性度量方法。通过此项研究，本文展示了一些闭源大语言模型（如GPT-4o）在某些任务中可能优于开源模型，并且不同的提示技术能够产生不同质量的评判者。", "conclusion": "本文的研究结果表明，在某些情况下，闭源的大语言模型可以有效地替代人类参与到标注工作，并且提示技术的应用显著影响评判者的表现。研究结论鼓励了对这种替代人类标注者使用大语言模型的行为采用更加严谨和可靠的方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.18601", "html_url": "https://arxiv.org/abs/2407.18601", "title": "通过表达性注意力重新组织注意力空间几何", "title_en": "Reorganizing attention-space geometry with expressive attention", "authors": "Claudius Gros", "background": "注意力机制调节令牌之间的信息传输。通常使用查询向量和键向量的标量积，即$\boldsymbol{Q}^T\boldsymbol{K}$以及后续的softmax归一化。标准点积注意力（DPA）导致平行/反平行查询和键的注意力权重较大/较小。研究发现，基于$(\boldsymbol{Q}^T\boldsymbol{K})^2$，即平方点积的表达性注意力（EA），可以增强查询和键平行或反平行时的注意力权重，并抑制正交配置下的注意力权重。", "innovation": "通过引入表达性注意力（EA），在任何基于注意力的代码中无需增加计算成本或内存要求即可改善性能。实验结果显示，对于一系列自回归预测任务，EA的表现至少与标准DPA相同。随着任务复杂性的增加，EA的性能逐步优于DPA，并且这一优势在多任务设置中也得到验证。对于给定的模型大小，EA能够在此类任务中实现100%的性能，而在这些复杂级别中DPA无法做到。", "conclusion": "研究表明，在注意力空间的匹配条件几何中重新组织是可以实现的，同时不会牺牲性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.15084", "html_url": "https://arxiv.org/abs/2501.15084", "title": "使用概率加密足迹的分层模式解密方法进行勒索软件检测", "title_en": "Hierarchical Pattern Decryption Methodology for Ransomware Detection Using Probabilistic Cryptographic Footprints", "authors": "Kevin Pekepok,Persephone Kirkwood,Esme Christopolous,Florence Braithwaite,Oliver Nightingale", "background": "勒索软件加密技术日益复杂，推动了检测和缓解方法的创新。本文基于概率加密分析构建了一个分层框架，通过统计分析加密模式的特征，结合先进的聚类算法和机器学习，开发了一种分层方法来隔离由勒索软件引起的异常。", "innovation": "本文提出的方法通过实时聚类和异常评估确保了快速响应能力，并通过统计特征分析恶意加密操作与正常活动之间的区别。该系统设计中包含动态反馈机制，使其能够适应不同的加密复杂性和操作环境。性能测试表明，该方法在高数据负载和复杂加密场景下具有较强的可扩展性和高效性。", "conclusion": "实验结果显示，该方法在区分恶意加密操作和正常活动方面具有极高的准确性，且具有较低的误报率。与现有的检测方法相比，该方法在检测高级勒索软件方面的表现更佳，特别是针对使用了延长密钥长度和独特加密协议的勒索软件。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12811", "html_url": "https://arxiv.org/abs/2501.12811", "title": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments", "title_en": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments", "authors": "Lafedi Svet,Arthur Brightwell,Augustus Wildflower,Cecily Marshwood", "background": "现代网络安全环境日益需要具备精确和适应性的高级检测框架，能够识别不断演变的威胁。传统的基于签名和启发式方法存在局限性，特别是在高速动态环境中表现不佳。", "innovation": "提出了零空间检测框架，该框架通过无监督聚类和高级深度学习技术动态识别潜在的行为模式，有效整合多阶段过滤和集成学习技术以进行精确诊断。实验结果显示，该框架在多样化的勒索软件家族中，包括LockBit、Conti、REvil和BlackMatter，具有高检测率，同时保持低误报率和可扩展性能，且计算开销小，兼容实时系统。该框架展示了在对抗混淆和加密速度可变等对抗策略时的韧性。", "conclusion": "此框架以其模块化架构无缝整合现有网络安全基础设施，证明了其鲁棒性和可扩展性，为在动态和资源受限环境中提供勒索软件识别的变革性框架。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.03055", "html_url": "https://arxiv.org/abs/2411.03055", "title": "ATM: 通过交替调优和合并改进模型合并", "title_en": "ATM: Improving Model Merging by Alternating Tuning and Merging", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Fabrizio Silvestri,Emanuele Rodolà", "background": "模型合并已作为一种成本效益高的多任务学习近似方法而出现。在合并策略中，任务算术因其简洁性和有效性而尤为引人注目。本文探讨了任务向量的理论基础，指出在单轮全批次梯度下降情况下，任务向量等同于多任务梯度。这一洞见促使我们重新解读模型合并，将其视为交替调优和合并（ATM）过程中的一个步骤。研究发现ATM在限制数据分享的情景（例如联邦学习环境）中可以作为多任务学习的替代方案，在改进现有模型合并方法时也可以使用小型验证集作为轻量级优化步骤。", "innovation": "文章提出了交替调优和合并（ATM）过程，将其作为限制数据共享情况下的多任务学习替代方案以及改进现有模型合并方法的轻量级优化步骤。跨多种视觉任务的实验表明了ATM的有效性。", "conclusion": "该研究发现，任务向量在单轮全批次梯度下降情况下等同于多任务梯度，并基于此提出了交替调优和合并（ATM）过程，证明了该方法在多种视觉任务中的有效性，为模型合并和多任务学习提供了新的视角和方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.11417", "html_url": "https://arxiv.org/abs/2501.11417", "title": "基于神经上下文强化框架的逻辑结构文本生成", "title_en": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation", "authors": "Marcus Irvin,William Cooper,Edward Hughes,Jessica Morgan,Christopher Hamilton", "background": "当前，大型语言模型生成的文本在逻辑连贯性和结构一致性方面存在挑战，尤其是在维护长距离依赖关系时。现有的研究主要集中在提高模型的生成质量，但往往忽略了对语言结构和语义流动的直接控制。", "innovation": "提出了一种新颖的神经上下文强化框架，通过强化学习原则整合自定义奖励函数和动态上下文对齐机制，解决了在延长序列中保持长距离依赖关系的问题。该架构包含多头注意层和分层编码模块，这使得模型能够更紧密地与人类对逻辑结构和语义流动的期望相匹配。实验证明，在不同数据集上的量化评估显著提高了连贯性指标、减少了困惑度并改善了语义对齐，该框架在各种任务中优于基线模型。", "conclusion": "该框架在处理噪音输入数据方面表现出很强的鲁棒性，适用于不同模型规模，实现了结构精度和语流畅顺之间的平衡，并展示了跨语言性能的适应性。此外，资源效率分析显示与传统方法相比计算开销降低，突显了其在大规模部署中的实用性。优化的上下文窗口大小对连贯性结果有显著影响，强调了架构灵活性在适应不同语言结构中的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12901", "html_url": "https://arxiv.org/abs/2501.12901", "title": "在大型语言模型中通过语境分区进行架构融合：参数化知识整合的新型方法", "title_en": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration", "authors": "Offa Kingsleigh,Alfred Abercrombie,David Woolstencroft,Beorhtric Meadowcroft,Marcus Irvin", "background": "背景介绍了现有方法在处理大规模计算模型时存在的问题，特别是参数化知识整合方面的不足，强调了任务特定专业化的重要性，以及适应性参数分配机制与输入数据语言特征的对齐问题.", "innovation": "创新点在于提出了语境分区的方法，通过动态分割参数到语境感知区域，提升了计算模型的架构设计。该方法注重任务特定的专业化，并通过自适应的参数分配机制实现与输入数据语言特征的对齐。实验结果显示，该方法在准确性、困惑度和语境连贯性方面有显著提高，表明了该框架的适应性和可扩展性。", "conclusion": "结论总结了语境分区的潜在影响，该方法不仅简化了模型操作，还扩大了高级语言处理系统的应用范围。实验结果证明了基于梯度的分割的有效性，使模型能够动态调整以响应特定任务需求。进一步的资源使用度量证实了该方法在内存使用和训练时间上的有效效率，同时也表明了生成输出的语境连贯性和逻辑流畅性的改善，进一步证实了该技术的实际价值。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14119", "html_url": "https://arxiv.org/abs/2501.14119", "title": "使用层次嵌入增强的大型语言模型自主结构记忆操控", "title_en": "Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation", "authors": "Derek Yotheringhay,Alistair Kirkland,Humphrey Kirkbride,Josiah Whitesteeple", "background": "模型架构的变革性创新引入了层次嵌入增强作为重新定义令牌表示的新方法，通过多级语义结构增强对复杂语言输入的适应性。自主结构记忆操控进一步通过动态记忆重分配机制推进了这一范式，该机制优先考虑关键上下文特征并抑制不太相关的信息，从而实现不同任务的可扩展性和高效性。", "innovation": "提出了结合高级嵌入和内存管理策略的统一框架，以自主结构记忆操控为特色，通过动态重组织内存策略适应不断变化的上下文需求，提高计算效率。层次嵌入不仅优化了上下文对齐，还通过捕捉不同语义粒度的关系促进了任务的一般化能力，确保了不同层之间的连贯性，而不会引入显著的计算冗余。在对比基线模型中，特别是在需要复杂上下文理解和特定领域适应性的任务中，该方法展示了独特的优势，在准确性、效率和可解释性方面均有所提升。", "conclusion": "这些进步使模型能够在各种条件下展现出更强的稳健性，尤其适用于多领域推广、交互系统和实时决策场景，这些场景中传统静态内存架构往往存在局限性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.15384", "html_url": "https://arxiv.org/abs/2501.15384", "title": "MetaOcc: 时空融合的周围视图4D雷达和摄像头用于带有双训练策略的3D占用预测", "title_en": "MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies", "authors": "Long Yang,Lianqing Zheng,Wenjin Ai,Minghao Liu,Sen Li,Qunshu Lin,Shengyu Yan,Jie Bai,Zhixiong Ma,Tao Huang,Xichan Zhu", "background": "在恶劣天气条件下，传统的仅依靠视觉系统难以实现鲁棒的3D占用预测，而融合周围视图4D雷达和摄像头提供了一种成本较低的解决方案，但仍存在从这些异构传感器有效提取和整合特征的挑战。", "innovation": "提出了一种名为MetaOcc的多模态框架，用于实现全方位的3D占用预测，该框架利用多视图4D雷达和图像数据。提出了一种雷达高度自注意力模块，以增强垂直空间推理和特征提取。此外，开发了一种分层级多尺度多模态融合策略，用于跨模态和时间进行自适应局部-全局融合，从而缓解时空对齐问题并丰富融合特征表示。进一步提出了基于开放式分割器的伪标签生成流水线，以减少对昂贵点云标注的依赖。这些创新使得在半监督策略下，仅使用50%的真实标签就能达到完全监督策略的90%性能，有效平衡了标注成本与准确性。", "conclusion": "MetaOcc在全监督下实现了最先进的性能，在OmniHD-Scenes数据集和SurroundOcc-nuScenes数据集上分别比之前的方法提高了0.47 SC IoU、4.02 mIoU，以及1.16 SC IoU、1.24 mIoU。这些结果证明了MetaOcc在传感器领域和训练条件上的可扩展性和鲁棒性，为实际部署于现实世界中的自主系统铺平了道路。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.15509", "html_url": "https://arxiv.org/abs/2501.15509", "title": "FIT-Print: 通过目标指纹识别虚假认领模型所有权", "title_en": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint", "authors": "Shuo Shao,Haozhe Zhu,Hongwei Yao,Yiming Li,Tianwei Zhang,Zhan Qin", "background": "模型指纹识别是一种广泛采用的方法，用于保护开源模型的知识产权，防止其未经授权的重复使用。这种方法既有效又便捷，因为它不需要修改受保护的模型。然而，现有的指纹识别方法容易受到虚假认领攻击，即对手可对第三方模型虚假认领所有权。目前的指纹识别方法通常比较不同模型的样本输出相似性，而未针对特定参考进行优化，这导致了其防御虚假认领攻击的不足。", "innovation": "本文提出了一种针对虚假认领攻击的目标指纹识别模式（即 FIT-Print），通过对指纹进行优化，将其转化为针对性的签名。基于 FIT-Print 的原则，开发了位级和列表级的黑盒模型指纹识别方法，即 FIT-ModelDiff 和 FIT-LIME，它们分别利用特定样本的模型输出和特征归因之间的距离作为指纹。广泛实验表明，这些方法在效果、转移性和抵御虚假认领攻击方面非常有效。", "conclusion": "通过 FIT-Print，有效提出了针对虚假认领攻击的模型所有权验证方法，通过优化和针对性设计，显著提高了模型指纹识别的准确性、可迁移性和抵抗虚假认领的能力，为解决模型知识产权保护问题提供了一种新的解决思路。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00048", "html_url": "https://arxiv.org/abs/2502.00048", "title": "优化的大语言模型理解中的上下文纠缠梯度映射", "title_en": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension", "authors": "Colin Sisate,Alistair Goldfinch,Vincent Waterstone,Sebastian Kingsley,Mariana Blackthorn", "background": "现有的梯度优化策略在处理长文本推理、上下文保留及适应未见领域方面存在不足，尤其是在保留语义一致性和推理能力方面表现不佳。", "innovation": "CEGM提出了一种新的梯度优化方法，通过将梯度视为动态的上下文依赖载体，而不是孤立的数值实体，重新定义了上下文嵌入与梯度更新之间的关系。这种方法通过将纠缠的梯度动力学融入损失正则化框架中，在多种任务中表现出色。", "conclusion": "实验证明，CEGM增强的模型相比基线方法在标记级预测准确性上有所提高，并且对噪声输入具有更高的鲁棒性。其实现包括对训练管道的修改，在现有架构中引入联系层和动态系数调整。研究表明，梯度纠缠对理论进步和优化策略的实际应用有着广泛的影响。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06728", "html_url": "https://arxiv.org/abs/2502.06728", "title": "DeToNATION: 解耦 Torch 网络感知的分布式在线节点协同训练", "title_en": "DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes", "authors": "Mogens Henrik From,Jacob Nielsen,Lukas Galke,Peter Schneider-Kamp", "background": "训练大型神经网络模型需要大量的计算资源，通常分布在多个节点和加速器上。最近的研究表明，可能只需要交换梯度的变化部分，而不是整个梯度，同时在各个加速器上局部累积动量（称为解耦动量，或DeMo）。然而，DeMo假定模型可以完全放在一个加速器上。为了缓解这一假设，本文引入了FlexDeMo，这是一种新的分布式训练策略，其中节点在其不同的加速器之间全面分发模型参数，同时通过只同步梯度的变化部分而不是整个梯度来减少节点间的通信量，从而实现一种混合分片数据并行训练策略。", "innovation": "本文提出了FlexDeMo，一种新的分布式训练方案，解决了DeMo假设模型只能在一个加速器上运行的问题，通过局部分发模型参数并减少节点间的通信来实现混合分片数据并行训练。此外，还提出了一种名为DeToNATION的框架，不仅适用于FlexDeMo，也适用于其他流行的分布式训练方案，如DiLoCo。该框架引入了新的复制方案变体，挑战DeMo中的某些选择。", "conclusion": "在语言和视觉领域的实验结果表明，FlexDeMo在使用AdamW和全梯度同步的混合分片数据并行训练中具有相似的验证损失，但速度快得多。因此，FlexDeMo是训练最大机器学习模型的一种有前途的分布式训练方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16802", "html_url": "https://arxiv.org/abs/2502.16802", "title": "基于主题而非来源：语言模型预训练中有效数据混合的关键", "title_en": "Topic Over Source: The Key to Effective Data Mixing for Language Models Pre-training", "authors": "Jiahui Peng,Xinlin Zhuang,Jiantao Qiu,Ren Ma,Jing Yu,He Zhu,Conghui He", "background": "大语言模型（LLMs）的性能受其预训练数据的质量和组成的影响，这些数据通常具有多样性，涵盖不同的语言、来源和主题。有效地整合这些异质数据组对于优化LLM性能至关重要。之前的大多数研究主要集中在基于来源的数据混合上，往往忽视了数据在主题层次上的细微特征。", "innovation": "本文提出了一种基于主题的数据混合策略，该策略利用多阶段过程结合无监督聚类、LLM基于的总结和监督分类器训练生成的详细主题标签。通过这种方法，我们首次对基于主题与基于来源的数据分区进行了全面比较，使用多种数据混合策略。研究表明，基于主题混合的数据训练的语言模型在多种方法中（包括RegMix、DoReMi、温度采样以及基于下游任务性能的手动混合方法）的一致性上优于基于来源混合的数据训练的语言模型。理论分析显示，基于主题的数据在验证损失上显著低于基于来源的方法，为模型训练提供了更好的优化环境。", "conclusion": "基于主题的数据混合策略在预训练语言模型中表现更优，验证损失也更低，为模型训练提供了更好的优化环境。代码、注释数据集和主题分类模型将公开提供，以促进进一步研究。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.16658", "html_url": "https://arxiv.org/abs/2501.16658", "title": "基于上下文强化的多模态 token 压缩技术在大规模语言模型中的应用", "title_en": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models", "authors": "Naderdel Piero,Zacharias Cromwell,Nathaniel Wainwright,Matthias Nethercott", "background": "随着模型处理复杂多样的数据集的需求不断增加，有效的 token 压缩仍然是扩展模型规模的关键挑战之一。现有技术在 token 使用方面减少了一定的冗余，但往往牺牲了信息表示的质量和连贯性。亟需一种新的机制来动态调整 token 的重要性，通过上下文相关性和语义相关性增强 token 间的相互依赖关系，以在减少 token 使用的情况下保持信息的高质量和连贯性，并能在下游任务中发挥稳定的支撑作用。", "innovation": "本文引入了一种基于上下文强化的新型机制，通过多模态数据中的上下文关联和语义相关性动态调整 token 的重要性。这种方法不仅实现了 token 使用的显著减少，同时保持并优化了信息表示的质量和连贯性。此外，该机制还结合了图论算法和自适应加权，能够在多模态数据中捕捉微妙的上下文关系，确保在下游任务中的稳健表现。实验结果表明，相比于基线模型，该方法在跨模态交互任务中的准确性显著提高，并且在语义保留方面也有所改进，即使在引入额外的强化过程后，内存使用效率也有所提高。", "conclusion": "研究结果证明，基于上下文强化的 token 压缩方法能够在保持信息质量和连贯性的同时，大幅减少 token 的使用，从而提升计算效率。模块化的架构确保了该方法与多种开源框架兼容，便于在实际应用中进行大规模拓展。这些发现突显了上下文强化在重新定义 token 管理策略方面的潜力，以及对大规模模型设计的改进作用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10699", "html_url": "https://arxiv.org/abs/2502.10699", "title": "探索大规模语言模型中的突触共振：一种新的上下文记忆整合方法", "title_en": "Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration", "authors": "George Applegarth,Christian Weatherstone,Maximilian Hollingsworth,Henry Middlebrook,Marcus Irvin", "background": "在语言模型的发展中，维持长时间段内的上下文一致性仍然是一个高挑战，尤其是在需要保持长时间段内的连贯性任务中。传统方法，如自我注意力机制和记忆增强架构，通常优先处理短期依赖性，导致长期上下文理解的断层和不一致性。", "innovation": "受生物神经系统中突触可塑性原理的启发，文中引入了一种新的机制——突触共振，该机制在训练和推理过程中动态加强相关记忆路径。与静态记忆表示不同，此机制会根据上下文相关性不断调整突触权重矩阵，从而在不增加过多计算开销的情况下提高信息保留能力。实验结果显示，与基线模型相比，所提出的方法在保留记忆效率方面更优，且计算可行性高。此外，基于改进后的长期上下文一致性在对话系统和文档摘要等应用领域的应用有所显示，突触共振机制提供了一种潜在的替代传统的记忆机制的方法，解决了长期序列建模中的长期存在的限制问题。", "conclusion": "改进的长期上下文一致性与现有的变压器架构无缝集成，确保了稳定收敛、高效推理且不失扩展性。通过动态强化记忆路径，新的突触共振机制显示出比传统方法更有效的记忆整合效果，提升了语言模型的鲁棒性和连贯性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18350", "html_url": "https://arxiv.org/abs/2411.18350", "title": "TryOffDiff：使用扩散模型实现高保真服装重建的虚拟试脱", "title_en": "TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models", "authors": "Riza Velioglu,Petra Bevandic,Robin Chan,Barbara Hammer", "background": "本文介绍了Virtual Try-Off (VTOFF) 技术，这是一种从穿着个体的单张照片生成标准化服装图像的新任务。与Virtual Try-On (VTON) 不同的是，VTON通过数字手段为模型着装，VTOFF则提取标准服装图像，需要精确重建形状、纹理和复杂图案，以进行可靠的生成模型保真度评估。现有的评估技术如SSIM不足，不能全面反映重建质量，因此本文提出使用DISTS进行更可靠的评估。研究背景包括提高电子商务产品图像质量、推进生成模型评估以及指导后续高保真重建研究。", "innovation": "本文提出了TryOffDiff，一种使用稳定扩散与SigLIP视觉条件结合的方法，以实现高保真度的重构重建。实验表明，TryOffDiff在VITON-HD和Dress Code数据集上表现优于传统的姿态迁移和VTON基线。通过使用DISTS评估，发现传统指标如SSIM不足以反映重建质量，表明了新方法的有效性。", "conclusion": "本文的研究成果展示了VTOFF技术在改进电子商务产品图像，推动生成模型评估方面的重要潜力，并为未来高保真重建的研究提供指导。实验结果表明TryOffDiff方法在VITON-HD和Dress Code数据集上优于现有方法，并强调了使用DISTS评估的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06836", "html_url": "https://arxiv.org/abs/2502.06836", "title": "CAST: 基于交叉注意力的结构与文本多模态融合用于材料性质预测", "title_en": "CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction", "authors": "Jaewan Lee,Changyoung Park,Hongjun Yang,Sungbin Lim,Woohyung Lim,Sehui Han", "background": "近年来，图神经网络（GNNs）在预测材料性质方面取得了显著进展，通过将晶体结构建模为图结构来进行预测。然而，GNNs 对全局结构特征，如晶体系统，的捕捉能力有限，这限制了其预测性能。", "innovation": "本文提出了CAST，一种基于交叉注意力机制的多模态模型，该模型将图表示与材料的文本描述结合起来，有效保留了关键的结构和组成信息。与CrysMMNet和MultiMat等依赖于聚合的材料级嵌入的方法不同，CAST 利用了交叉注意力机制来结合细粒度的图节点级和文本词元级特征。此外，还引入了一种掩码节点预测预训练策略，进一步提高了节点嵌入与文本嵌入之间的对齐。实验结果表明，CAST 在四个关键材料性质——形成能、能隙、体模量和剪切模量上均优于现有基线模型，平均相对MAE改进幅度分别为10.2%-35.7%。注意力图的分析进一步证实了预训练对有效对齐多模态表示的重要性。", "conclusion": "本研究强调了多模态学习框架在材料科学中开发更准确和更具全局感知的预测模型方面的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08727", "html_url": "https://arxiv.org/abs/2503.08727", "title": "使用深度上下文蒸馏训练即插即用知识模块", "title_en": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation", "authors": "Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni", "background": "在大模型预训练之后，动态整合新信息或快速发展的信息依然具有挑战性，尤其是在数据量少的情况下或是处理私有和专业文档时。现有的上下文学习方法和检索增强生成（RAG）技术在推理成本和无法捕捉文档全局信息方面存在局限。", "innovation": "本文提出了通过训练文档级知识模块（KMs）来模块化知识的方法。KMs 使用参数高效的 LoRA 模块实现，并能存储新的文档信息。作者创新地提出了一种深度上下文蒸馏方法，训练 KMs 模拟基于文档上下文推断的教师模型的隐藏状态和输出。这种方法在两个数据集上均优于标准的下一个令牌预测和预指令训练技术。", "conclusion": "本文展示了知识模块与 RAG 的协同作用，并表明深度上下文蒸馏是训练 KMs 的有效方法，能够在低数据场景和处理私有文档时更好地整合新信息。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.23145", "html_url": "https://arxiv.org/abs/2503.23145", "title": "CodeARC：评估LLM代理进行归纳程序合成的推理能力基准", "title_en": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "authors": "Anjiang Wei,Tarun Suresh,Jiannan Cao,Naveen Kannan,Yuheng Wu,Kai Yan,Thiago S. F. X. Teixeira,Ke Wang,Alex Aiken", "background": "归纳程序合成或编程示例，要求从输入输出示例中合成函数，并推广到未见输入。尽管大型语言模型代理在自然语言引导的编程任务中展示了潜力，但在归纳程序合成方面的能力尚未被充分探索。现有的评估协议依赖于静态示例集和保留测试，无法在合成函数错误时提供反馈，未能反映实际场景如逆向工程。CodeARC是一个新的评估框架，通过代理与隐藏的目标函数进行交互，查询新输入并生成候选函数，以及通过微分测试自适应地改进解决方案。", "innovation": "CodeARC提出了一个新的评估框架，其中代理通过查询隐藏的目标函数、合成候选函数并根据微分测试反馈迭代优化它们的解决方案与一个隐藏的目标函数交互。CodeARC构建了第一个大规模的一般性归纳程序合成基准，包含1114个函数。评估结果显示o3-mini的表现最佳，准确率为52.7%，这突显了这一任务的难度。细调LLaMA-3.1-8B-Instruct在合成轨迹上的表现提高了高达31%。CodeARC为基于LLM的程序合成和归纳推理提供了更真实且具有挑战性的测试环境。", "conclusion": "CodeARC提供了一种新的、更具挑战性的方法来评估LLM代理进行归纳程序合成和推理的能力，其中包含了大量合成函数的代码、数据和模型将公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01290", "html_url": "https://arxiv.org/abs/2503.01290", "title": "ACTIVA：基于Transformer的变分自编码器的拟制因果效应估计", "title_en": "ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder", "authors": "Andreas Sauter,Saber Salehkaleybar,Aske Plaat,Erman Acar", "background": "在医疗保健、经济学和政策制定领域中，预测在假设干预下的结果分布至关重要。然而，现有的方法往往需要严格的假设，并且通常受限于缺乏不同问题实例间的累积知识。", "innovation": "提议了一种基于Transformer的条件变分自编码器（VAE）架构，用于拟制因果推断（ACTIVA），可以直接从观察数据中估计干预分布，而不做特别假设。ACTIVA通过在多样化的训练情景中累积因果知识，实现了零样本推断。", "conclusion": "理论分析表明，ACTIVA可以通过观察性的等价因果模型混合来预测干预分布。实证研究表明，该方法具有优越性，并为未来在实际应用中的潜力提供了方向。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04592", "html_url": "https://arxiv.org/abs/2502.04592", "title": "CAMEF: 增强因果多重模态事件驱动金融预测整合时间序列模式和关键宏观经济公告", "title_en": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements", "authors": "Yang Zhang,Wenbo Yang,Jun Wang,Qiang Ma,Jie Xiong", "background": "准确预测宏观经济事件的影响对投资者和政策制定者至关重要。显著的宏观经济事件，如货币政策决定和就业报告，通过影响经济增长和风险预期，引起市场变动，从而建立了事件与市场行为之间的因果关系。现有的预测方法通常侧重于文本分析或时间序列建模，但无法捕捉金融市场的多重模态特性以及事件与价格变动之间的因果关系。", "innovation": "我们提出了CAMEF（因果增强多重模态事件驱动金融预测），这是一种结合了文本和时间序列数据、因果学习机制以及基于LLM的反事实事件增强技术的多模态框架，以实现因果增强的金融预测。贡献包括：（1）一个多模态框架，捕捉政策文本与历史价格数据之间的因果关系；（2）一个包含2008年至2024年六种类型的宏观经济新闻发布和五个关键美国金融资产的高频真实交易数据的新金融数据集；（3）基于LLM的反事实事件增强策略。我们将CAMEF与最新的基于变换器的时间序列和多模态基准进行比较，并进行了消融研究，以验证因果学习机制和事件类型的有效性。", "conclusion": "我们通过对比实验和消融分析，验证了CAEMF的有效性和多模态框架及因果学习机制的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17429", "html_url": "https://arxiv.org/abs/2501.17429", "title": "使用时间关联图进行恶意软件检测的算法分割和行为建模", "title_en": "Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs", "authors": "Ignatius Rollere,Caspian Hartsfield,Seraphina Courtenay,Lucian Fenwick,Aurelia Grunwald", "background": "网络威胁的快速发展已经超过了传统的检测方法，因此需要采用创新的方法来应对现代对手的适应性和复杂行为。现有检测方法难以有效识别和应对快速演变的网络攻击。", "innovation": "提出了一个新颖的框架，利用时间关联图来建模恶意操作中固有的复杂关系和时间模式。该方法可动态捕捉行为异常，实时区分良性活动和恶意活动。该框架在多个勒索软件家族中进行了广泛实验，展示了高精度、召回率和总体检测准确性。与传统的基于签名和启发式方法相比，该框架特别在处理多态性以及之前未见过的勒索软件变种方面表现出优越性。此外，该架构还设计为具有扩展性和模块性，确保与大规模企业环境兼容，同时保持资源效率。", "conclusion": "研究通过将动态图分析和机器学习集成到威胁检测中，为未来的技术创新做出了贡献。本研究的结果强调了将时间关联图应用于组织检测和缓解复杂网络攻击的潜在可能性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09891", "html_url": "https://arxiv.org/abs/2502.09891", "title": "ArchRAG：基于属性社区的分层检索增强生成", "title_en": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation", "authors": "Shu Wang,Yixiang Fang,Yingli Zhou,Xilin Liu,Yuchi Ma", "background": "检索增强生成（RAG）已经被证明能够将外部知识有效地集成到大型语言模型（LLMs）中，解决问答（QA）任务。最新的RAG方法通常使用图数据作为外部数据，因为图数据可以捕捉丰富的语义信息和实体间的连接关系。然而，现有的基于图的RAG方法在从图中准确识别相关信息和在线检索过程中的高_TOKEN消耗方面存在局限性。", "innovation": "作者提出了一种新的基于图的RAG方法——Attributed Community-based Hierarchical RAG (ArchRAG)。ArchRAG通过使用属性社区增强问题，并引入了一种新的基于大模型的分层聚类方法。为了更好地从图中检索相关信息，他们构建了一种新的分层索引结构来处理属性社区，并开发了一种有效的在线检索方法。", "conclusion": "实验结果表明，ArchRAG在准确性和_TOKEN成本方面均优于现有方法。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16432", "html_url": "https://arxiv.org/abs/2504.16432", "title": "iTFKAN: 迪塔法克网络进行可解释的时间序列预测", "title_en": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network", "authors": "Ziran Liang,Rui An,Wenqi Fan,Yanghui Rao,Yuxuan Liang", "background": "随着时间的推移，特定领域内的数据表现出可预测性，促使通过对历史数据进行时间序列预测来预测未来的趋势。然而，当前的深度预测方法虽然取得了令人瞩目的成果，但大多缺乏解释性，这阻碍了其在自动驾驶和医疗保健等关键安全应用中的信任度和实用部署。", "innovation": "本文提出了一种新颖的可解释模型iTFKAN，以实现可信的时间序列预测。iTFKAN通过模型符号化实现了可解释性，并开发了先验知识注入和时频协同学习两种策略，以有效引导复杂交织的时间序列数据下的模型学习。", "conclusion": "广泛的实验结果表明，iTFKAN不仅能够实现有前景的预测性能，还能同时具备高度解释能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21152", "html_url": "https://arxiv.org/abs/2504.21152", "title": "SMOGAN: 使用GAN修正的合成少数类过采样方法用于不平衡回归", "title_en": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression", "authors": "Shayan Alahyari,Mike Domaratzki", "background": "不平衡回归是指目标变量分布偏斜的预测任务。这种偏斜阻碍了机器学习模型，尤其是神经网络，这些模型倾向于集中在密集区域，因此在少数样本（边缘样本）上表现不佳。尽管该问题非常重要，但仍只有少数方法被提出用于不平衡回归。现有的一些解决方案通过引入线性插值和高斯噪声等技术生成稀疏区域的合成数据。然而，由于数据底层分布往往复杂且非线性，这种做法生成的合成样本并不能准确反映真实特征-目标关系。", "innovation": "本文提出了一种名为SMOGAN的两步过采样框架，用于不平衡回归。在第一阶段，SMOGAN利用现有技术生成初始稀疏目标区域的合成样本。第二阶段，提出了DistGAN，一种分布感知生成对抗网络（GAN），作为SMOGAN的过滤层，通过敌对损失和最大均值离散度目标相结合来进一步细化和调整样本，使其与真实联合特征-目标分布对齐。", "conclusion": "在23个不平衡数据集上进行的广泛实验表明，与不使用DistGAN过滤层的默认过采样方法相比，SMOGAN始终表现出更优的性能。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07081", "html_url": "https://arxiv.org/abs/2504.07081", "title": "自引导语言模型", "title_en": "Self-Steering Language Models", "authors": "Gabriel Grand,Joshua B. Tenenbaum,Vikash K. Mansinghka,Alexander K. Lew,Jacob Andreas", "background": "虽然测试时的推理能够使语言模型完成复杂的任务，但是用自然语言进行搜索或规划会变得缓慢、昂贵并且容易出错。即使语言模型难以重现解决某个问题所需的精确推理步骤，它们往往在描述问题的抽象结构方面表现出色，包括如何验证解决方案和如何搜索。这项研究正是围绕如何利用语言模型来写递归的搜索过程来引导它们的推理，从而提供新的可验证和高效推理的形式。", "innovation": "本研究提出了一种名为DisCIPL的方法，可以让语言模型实现“自引导”。通过一个Planner模型生成一个任务特定的推理程序，并由一批Follower模型执行。通过这种方法，可以赋予模型具备写递归搜索过程的能力，以引导模型的推理。这种方法可以实现高度并行化的蒙特卡洛推理策略，并且在不需要微调的情况下，已经能够匹配甚至超越更大的模型，如GPT-4o和o1，尤其是在挑战性的受限生成任务中。该方法正好可以避免标准的“最佳N样本”采样的策略，并且可以由现有的语言模型自动实现。", "conclusion": "这项研究打开了一个高性能并行蒙特卡洛推理策略的设计空间，该策略超越了标准的“最佳N样本”策略，无需微调，并且能够被现有的语言模型自动实现。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04633", "html_url": "https://arxiv.org/abs/2504.04633", "title": "M$^2$IV: 通过表示工程实现高效且精细的多模态上下文学习", "title_en": "M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering", "authors": "Yanshu Li,Yi Cao,Hongyang He,Qisen Cheng,Xiang Fu,Xi Xiao,Tianyang Wang,Ruixiang Tang", "background": "多模态在上下文学习（ICL）中能够让大型视觉语言模型（LVLM）通过用户提供的示例适应新任务，而无需更新任何模型参数。然而，这种学习方式的有效性受到多模态输入的大量标记和跨模态少量示例推理复杂性的限制，这阻碍了LVLM从示例中提取有用模式。", "innovation": "本文提出了M$^2$IV，一种新的表示工程技术，用一组可学习的多模态上下文向量替换显式的标记级示例，并直接注入LVLM的残差流中。通过分析多头注意力（MHA）和多层感知器（MLP）在ICL过程中的不同作用，设计了一种训练策略，使M$^2$IV能够在细粒度语义提炼和稳健的跨模态表示学习中发挥优势。M$^2$IV不仅提升了多种任务和不同LVLM的表现，还显著减少了标记开销，使模型能够优雅地扩展到大量示例场景。此外，引入了一个VLibrary仓库，存储了训练好的M$^2$IV，便于灵活检索和注入。", "conclusion": "广泛的实验表明，M$^2$IV始终优于传统的ICL和先前的表示工程基线，平均准确率提高3.74%，并在整体效率上有显著改进。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08775", "html_url": "https://arxiv.org/abs/2504.08775", "title": "具有相似深度的层在不同LLM架构中生成相似激活", "title_en": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures", "authors": "Christopher Wolfram,Aaron Schein", "background": "研究人员对独立训练的语言模型（LLM）的潜在空间关系进行了研究，特别是在24个开放权重LLM中的不同层激活最邻近关系的研究，目的是理解这些模型内部和之间的潜在空间差异和相似性。", "innovation": "研究表明，不同模型的相应层之间存在共享的最邻近关系，但这些层之间的关系在模型内部是变化的。这种发现揭示了LLM生成从一层到另一层的激活几何体的进步，但这个整体进程在不同模型之间是广泛共享的，并被重新塑造以适应不同的架构。", "conclusion": "具有相似深度的层在不同LLM架构中生成相似的激活，这表明这些模型在生成状态空间的几何形状方面表现出惊人的共性，尽管每层的具体表现不同。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13908", "html_url": "https://arxiv.org/abs/2504.13908", "title": "AI辅助对话式访谈: 对数据质量和用户体验的影响", "title_en": "AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience", "authors": "Soubhik Barari,Jarret Angbazo,Natalie Wang,Leah M. Christian,Elizabeth Dean,Zoe Slowinski,Brandon Sepulvado", "background": "传统的标准化调查可以高效地收集数据，但缺乏深度，而对话式访谈可以提高回答的质量，但由于缺乏规模性和一致性要求较高，无法广泛应用。如何在高效性和深度之间找到平衡，是本研究的重点。", "innovation": "本文提出了一种基于AI辅助的对话式访谈框架，利用大型语言模型动态探询受访者，实现对开放式回答的交互编码。该框架通过在1800名参与者中的网络调查实验进行评估，展示了AI聊天机器人在编码准确性和回答质量上的表现，以及对受访者的体验影响。", "conclusion": "研究发现，AI聊天机器人在实时编码中表现良好，尽管由于应答倾向性偏差导致了轻微的假阳性错误增加，但开放式回答更加详尽和有用，这对数据的质量有正面影响，尽管受访者的体验略有下降。研究证实了使用结合大型语言模型的AI聊天机器人来增强网络调查中开放式数据收集的技术可行性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07258", "html_url": "https://arxiv.org/abs/2505.07258", "title": "无需查询，无需访问", "title_en": "No Query, No Access", "authors": "Wenqiang Wang,Siyuan Liang,Yangshijie Zhang,Xiaojun Jia,Hao Lin,Xiaochun Cao", "background": "现有的文本对抗攻击通常需要受害者模型的知识、大量的查询或访问训练数据，这限制了其实用性。", "innovation": "本文提出了一种名为Victim Data-based Adversarial Attack (VDBA)的方法，该方法仅使用受害者文本进行攻击。为了防止访问受害者模型，通过使用公开的预训练模型和聚类方法创建了一个影子数据集，用于构建替代模型。同时，采用分层替代模型设计和多种攻击方法生成和选择具有更高相似性和攻击效果的对抗样本。", "conclusion": "实验结果显示，VDBA在情感和SST5数据集上的攻击成功率提高了52.08%，同时攻击查询次数减少了。更重要的是，VDBA对诸如Qwen2和GPT家族等大型语言模型构成了显著威胁，即使没有访问API，也取得了最高的攻击成功率45.99%，证明了先进的NLP模型仍然面临严重的安全风险。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10443", "html_url": "https://arxiv.org/abs/2505.10443", "title": "大型语言模型在应对语义保留变异时理解代码的鲁棒性如何？", "title_en": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "authors": "Pedro Orvalho,Marta Kwiatkowska", "background": "理解大型语言模型（LLMs）在推理和鲁棒性方面的表现对于它们在编程任务中的可靠应用至关重要。尽管最近的研究评估了LLMs预测程序输出的能力，但大多数研究仅关注预测的准确性，并未评估背后的推理过程。观察到，在数学推理任务中，LLMs可能通过逻辑错误的方式得到正确的答案，这引发了它们在代码理解中可能也存在类似问题的担忧。本研究旨在评估最新一代具有高达8B参数的LLMs，以判断它们是否能够对Python程序进行合理的推理，还是仅仅在猜测。通过应用五种保留语义的代码变异方法——变量重命名、表达式镜像、if-else分支替换、for循环转为while循环和展开循环——来验证这一点。", "innovation": "研究使用了五种通过代码变异保持语义不变的方法，并且通过人工专家分析（使用LiveCodeBench），评估了预测结果是否基于坚实的推理。同时，研究也在不同的代码变异条件下评估了预测的稳定性。这种方法提供了对LLMs在代码理解上的鲁棒性的一个新的评估维度，即保留语义的变异对其预测稳定性的影响。", "conclusion": "研究发现，针对代码进行训练的LLMs在10%到50%的情况下，可能会基于错误的推理得出正确的结论。此外，LLMs在面对代码变异时经常改变预测结果，表明它们尚未展现出稳定的、与语义无关的推理能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18602", "html_url": "https://arxiv.org/abs/2505.18602", "title": "LLM-Meta-SR：符号回归中选择算子的上下文学习演化", "title_en": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression", "authors": "Hengzhe Zhang,Qi Chen,Bing Xue,Wolfgang Banzhaf,Mengjie Zhang", "background": "大型语言模型（LLMs）在算法开发方面取得了革命性的进展，但在符号回归中的应用仍然受到限制，通常需要由人工专家手动设计。现有的基于LLM的方法在算法演化中存在两个关键限制：缺乏语义指导和代码膨胀。缺乏语义意识可能导致有用代码组件的有效交换不足，代码膨胀则导致不必要的复杂组件，这两者都会降低设计算法的可解释性或阻碍进化学习进程。\n", "innovation": "本文提出了一种元学习框架，该框架使LLMs能够自动设计用于进化符号回归算法的选择算子。主要创新包括：一种语义意识强且互补的选择算子，以及代码膨胀控制。此外，将领域知识嵌入提示，使LLM能够生成更有效且具有上下文相关性的选择算子。实验结果表明，LLMs设计的选择算子优于9种专家设计的基线方案，达到最佳性能，并且优化后的选择算子进一步提升了现有最先进的符号回归算法的性能，使26种符号回归和机器学习算法在116个回归数据集上的表现达到最优。\n", "conclusion": "研究表明，LLMs能够在符号回归中实现专家级别的算法设计。\n"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM: 基于潜变量扩散的世界模型在预测操控中的应用", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,JIazhao Zhang,Shilong Zou,XInwang Liu,Ruizhen Hu,Kai Xu", "background": "在嵌入式人工智能领域，预测操控因其能够通过利用预测状态改善机器人策略性能而受到了广泛关注。然而，从世界模型生成准确的未来视觉状态仍然是一个挑战，尤其是在实现高质量的像素级表征方面。鉴于此，本文提出了一个名为LaDi-WM的世界模型，它利用扩散建模来预测未来状态的潜空间。LaDi-WM借鉴了预训练的视觉基础模型（VFMs），其中包括基于DINO的几何特征和基于CLIP的语义特征。研究发现，预测潜空间的演变比直接预测像素级图像更容易学习和具有更强的泛化能力。基于此模型，设计了一种扩散策略，通过不断细化输出动作以加入预测状态，从而生成更一致和准确的结果。", "innovation": "本文创新性地提出了一种名为LaDi-WM的世界模型，该模型利用扩散建模来预测未来状态的潜空间。LaDi-WM基于预训练的视觉基础模型，包括几何特征和语义特征。此外，本文还设计了一种扩散策略，通过不断细化输出动作并加入预测状态，从而生成更一致和准确的结果。实验表明，LaDi-WM在合成和真实世界基准上显著提升了策略性能，分别在LIBERO-LONG基准和真实世界场景中提升了27.9%和20%。", "conclusion": "通过LaDi-WM模型及其设计的扩散策略，本文在真实世界实验中取得了令人印象深刻的效果。在LIBERO-LONG基准和实际场景中，LaDi-WM分别显著提高了27.9%和20%的策略性能，同时展示了很好的泛化能力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05104", "html_url": "https://arxiv.org/abs/2506.05104", "title": "音乐生成模型评估综述", "title_en": "Survey on the Evaluation of Generative Models in Music", "authors": "Alexander Lerch,Claire Arthur,Nick Bryan-Kinns,Corey Ford,Qianyi Sun,Ashvala Vinay", "background": "近年来，音乐生成系统的研究获得了相当的关注和增长。多种系统已经尝试系统地评估这些生成系统。本文综述了音乐生成系统的评价目标、方法和指标，覆盖了主观和客观方法、定性和定量方法以及实验性与计算性方法，并从音乐学、工程和人机交互的角度分析了这些方法的优势和局限性，", "innovation": "本文提供了一个跨学科的综述，不仅涵盖了音乐生成系统评价的各个方面，还从音乐学、工程学和人机交互的角度分析了不同评价方法的优势和局限性，有助于理解和改进音乐生成系统的研究和实践。", "conclusion": "本文总结了音乐生成模型评价的不同方法和指标，并提供了多学科的视角，为后续研究提供了指导和参考。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01700", "html_url": "https://arxiv.org/abs/2503.01700", "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation", "title_en": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation", "authors": "Yongchao Chen,Yilun Hao,Yang Zhang,Chuchu Fan", "background": "近年来，大型语言模型（LLMs）在机器人任务和运动规划（TAMP）方面展现出巨大潜力。当前的LLM方法生成基于文本或代码的推理链，包含子目标和行动计划。然而，这些方法尚未充分利用LLMs的符号计算和代码生成能力。许多机器人TAMP任务涉及在多约束条件下进行复杂优化，单纯的文字推理不足。虽然通过预定义的求解器和规划器增强LLM可以提升性能，但这种做法缺乏跨任务的一般性。鉴于LLMs日益提高的编程技能，通过引导它们生成代码作为符号规划者进行优化和约束验证，来增强其TAMP能力。不同于使用代码来与机器人动作模块进行接口的先前研究，本文方法引导LLMs生成代码作为求解器、规划者和检查器，用于需要符号计算的TAMP任务，同时仍利用文本推理以融入常识。", "innovation": "通过引导大型语言模型（LLMs）生成代码作为符号规划者的框架，提出的方法显著提高了7个典型TAMP任务上3种主流LLMs的最佳基线方法的成功率，平均提升24.1%。Code-as-Symbolic-Planner方法在离散和连续环境、2D/3D仿真和真实世界设置中，以及单机器人或多机器人任务具有强有力的效用和泛化能力。研究结果在该研究网站（链接未提供）中发布供参考，包含提示、视频和代码等资源。", "conclusion": "Code-as-Symbolic-Planner方法显著增强了机器人任务和运动规划中的符号计算能力，提高了任务成功率，并展示了其在复杂环境和任务中的广泛应用潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03155", "html_url": "https://arxiv.org/abs/2506.03155", "title": "从多模态数据融合跨域知识以解决物理世界中的问题", "title_en": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World", "authors": "Yu Zheng", "background": "人工智能的发展催生了多种数字化与物理世界连接的应用，但由于物理环境的复杂性，无法通过单一的信息获取方式来进行建模，因此需要融合来自不同来源（如传感器、设备、系统和人员）的多模态数据来解决问题。在数据不足的情况下，重新收集原始数据是不可行且不实用的方法。因此，当在某一问题域中数据不足时，需要融合其他领域的已有知识，这种方法称为跨域知识融合。", "innovation": "本文首次形式上定义了跨域多模态数据融合问题，探讨了其不同于单一域数据融合的独特挑战、差异及优势。提出了一种四层框架，包括领域层、连接层、模型层和数据层，分别回答了“融合什么”、“为什么可以融合”和“如何融合”的问题。该框架包含选择跨域相关数据、揭示知识对齐的哲学、提供基于数据处理基本机制的知识融合方法，并将不同结构、分辨率、尺度和分布的数据转换为可以被AI模型接受的一致表示。", "conclusion": "通过这种方法，可以设计出有效融合跨域多模态数据的解决方案，以解决现实世界中的问题。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.24277", "html_url": "https://arxiv.org/abs/2503.24277", "title": "通过近似准正交性评估和设计稀疏自动编码器", "title_en": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality", "authors": "Sewoong Lee,Adam Davies,Marc E. Canby,Julia Hockenmaier", "background": "稀疏自动编码器（SAEs）在大型语言模型的机制可解释性研究中广泛使用。目前最先进的方法是使用$k$-稀疏自动编码器，但缺乏理论依据来选择代表非零激活数的超参数$k$，通常记为$\boldsymbol{\beta_0}$。本文揭示了一个理论关联，即稀疏特征向量的$\boldsymbol{L_2}$范数可以近似为密集向量的$\boldsymbol{L_2}$范数，并且该误差可以用封闭形式表示，这使得可以在不需要手动确定$\boldsymbol{\beta_0}$的情况下训练稀疏自动编码器。", "innovation": "文章提出了一个新的方法论，能够通过输入嵌入计算理论上预期的值来评估预训练的SAE的功能激活，这在现有的SAE评估方法和损失函数中被忽视。其次，引入了一种新的激活函数——top-AFA，它是基于近似特征激活(AFA)的公式构建的，使得可以在不需要固定超参数$k$的情况下实现前$k$种激活，动态地为每个输入确定激活的特征数量。通过在三层之上对GPT2隐藏嵌入进行重建，该方法在美国8000万Token的OpenWebText数据集上进行了实证验证，并与当前最先进的$k$-稀疏自动编码器进行了比较。", "conclusion": "通过对三层之上GPT2隐藏嵌入的重建，实验验证了该方法的有效性，并与当前最先进的$k$-稀疏自动编码器进行了比较。实验结果证明了该方法的优势，本文的代码可以在指定的网址获取。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21772", "html_url": "https://arxiv.org/abs/2504.21772", "title": "解决短视频平台上版权侵权问题：新型数据集与音频恢复深度学习管道", "title_en": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline", "authors": "Minwoo Oh,Minsu Park,Eunil Park", "background": "短视频平台（如YouTube Shorts和TikTok）面临着严峻的版权合规挑战，因为侵权者经常嵌入任意背景音乐（BGM）以掩盖原始音轨（OST）并逃避内容原创性检测。这给版权管理工作带来了重大困难，也引发了平台上的版权纠纷。因此，研究如何有效解决这一问题具有重要意义。", "innovation": "本文提出了一种创新的流程，结合了音乐源分离（MSS）和跨模态视频-音乐检索（CMVMR）。该方法可以有效分离任意背景音乐（BGM）并恢复原始音轨（OST），从而确保内容的完整性。此外，为支持这一工作，本文还提出了两个专有数据集：包含20,000个音频片段的OASD-20K用于音频分离，以及包含1,121个视频-音频混合片段的OSVAR-160用于管道评估，这些数据集专门用于短视频恢复任务。实验结果表明，该管道不仅能够高精度地去除任意的BGM，还能够恢复OST，确保了内容的完整性。", "conclusion": "本文的方法为短视频平台上用户生成内容的版权合规问题提供了一种道德且可扩展的解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16518", "html_url": "https://arxiv.org/abs/2505.16518", "title": "CUB: 语言模型中上下文利用技术的基准测试", "title_en": "CUB: Benchmarking Context Utilisation Techniques for Language Models", "authors": "Lovisa Hagström,Youna Kim,Haeun Yu,Sang-goo Lee,Richard Johansson,Hyunsoo Cho,Isabelle Augenstein", "background": "在知识密集型任务（如问答和事实核查）中，利用外部知识至关重要。然而，语言模型可能忽视与过时参数记忆矛盾的信息，或者被不相关的上下文所分散。近年来，虽然提出了一些上下文利用技术（CMTs），但还没有进行系统的比较。该研究开发了CUB（上下文利用基准），旨在帮助检索增强生成（RAG）领域的从业者诊断不同上下文环境下的CMTs。这项基准测试是首个全面的评估，适用于广泛的CMTs，覆盖了三个不同的数据集和任务，应用于九种不同的语言模型。研究表明，大多数现存的CMTs难以处理真实世界检索增强环境中遇到的各种上下文类型。此外，很多CMTs在简单的合成数据集上的性能可能被夸大，而在具有自然出现样本的真实数据集上的表现不那么突出。这些发现揭示了当前CMT评估实践中的重要问题，并表明需要进行全面测试以及能够稳健处理多种上下文类型的CMTs的发展需求。", "innovation": "开发了CUB（Context Utilisation Benchmark），这是首个全面的基准测试工具，旨在帮助诊断不同上下文环境下的CMTs，评估了七个最先进的方法，涵盖了主要的CMTs类别，适用于三个不同的数据集和任务，评估了九种语言模型。该研究揭示了大多数现存的CMTs难以处理真实世界检索增强环境中遇到的各种类型上下文的问题，同时也发现了一些CMTs在简单合成数据集上的性能被夸大的问题，而在真实数据集上的表现并不那么突出。这些发现为当前CMT评价实践中的关键问题提供了新的视角，并强调了CMTs应具备全面处理多种上下文类型的能力的重要性。", "conclusion": "当前的CMTs在处理真实世界检索增强环境中遇到的各种类型上下文方面存在困难，且在简单合成数据集上的性能可能被夸大。因此，需要进行全面的测试和开发能够稳健处理多种上下文类型的CMTs。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21344", "html_url": "https://arxiv.org/abs/2504.21344", "title": "基于视觉-语言模型的语义引导影像生物标志物用于肺结节恶性程度预测", "title_en": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction", "authors": "Luoting Zhuang,Seyed Mohammad Hossein Tabatabaei,Ramin Salehi-Rad,Linh M. Tran,Denise R. Aberle,Ashley E. Prosper,William Hsu", "background": "现有的机器学习模型利用语义特征、深层特征或两者来评估肺结节的恶性程度，但依赖于人工注解的推理会导致其在实际临床环境中应用受限，同时也存在解释性和对成像变化敏感性的问题。因此，该研究旨在整合放射科医生对结节的评估所衍生出的语义特征，引导模型学习与临床相关的、具有鲁棒性且可解释的影像特征，用于预测肺癌。", "innovation": "本研究通过将预训练的CLIP模型与参数高效的微调方法相结合，实现了图像和语义文本特征的对齐，并能够零样本推断语义特征以预测肺癌。此外，该模型在不同临床环境下表现出色，提供易于临床医生理解的可解释输出，并有效防止模型学到捷径。", "conclusion": "该研究使用预训练的CLIP模型进行语义引导的影像生物标志物构建，可以有效预测肺癌，并在多种数据集上表现出超越现有最佳模型的性能，提供临床解释性输出，有助于提高临床医生对模型预测的理解。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17631", "html_url": "https://arxiv.org/abs/2506.17631", "title": "Time-Prompt: 综合异构提示以解锁时间序列预测中的大语言模型", "title_en": "Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting", "authors": "Zesen Wang,Lijuan Lan,Yonggang Li", "background": "时间序列预测旨在建模变量之间的时序依赖关系，对未来状态进行推断，具有重要的实际应用场景和广泛的应用价值。尽管基于深度学习的方法取得了显著进步，但在长周期预测和数据稀缺场景中仍表现不佳。近期研究表明，大语言模型（LLMs）在时间序列预测方面表现出色。然而，现有的LLM基方法仍存在缺陷，如缺乏统一的文本提示形成范式，以及忽视文本提示和时间序列之间的模态差异。", "innovation": "本文提出了LLM-Prompt框架，该框架融合了多提示信息和跨模态语义对齐，以解决现有问题。具体而言，该框架首先构建了一个结合可学习软提示和文本化硬提示的统一文本提示范式。其次，设计了语义空间嵌入和跨模态对齐模块，以实现时间和文本信息的跨模态融合。最后，通过LLMs变换时间序列来获取预测结果。", "conclusion": "在6个公开数据集和3个碳排放数据集上的全面评估显示，LLM-Prompt是一个强大的时间序列预测框架。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06306", "html_url": "https://arxiv.org/abs/2507.06306", "title": "人类过度依赖自信的语言模型，跨语言结果一致", "title_en": "Humans overrely on overconfident language models, across languages", "authors": "Neil Rathi,Dan Jurafsky,Kaitlyn Zhou", "background": "随着大型语言模型（LLMs）在全球部署，其响应需要在跨语言上进行校准，以准确传达不确定性及限制。先前研究指出，LLMs 在英语中表现出语言上的过度自信，导致用户过度依赖其自信生成的内容。然而，不同语言中表征知识性的标记（如“我认为”）的使用和解释存在显著差异。", "innovation": "本文研究了多语言中语言模型的（误）校准、过度自信以及过度依赖的风险。通过分析五种语言中生成的想法标记分布，发现这些模型在不同语言中过度自信，经常在错误回复中使用加强器，尽管使用频率不同（不确定性标记多于确定性标记）。同时，研究了各语言中的人类依赖行为差异，揭示了依赖行为在跨语言中的显著不同。", "conclusion": "研究结果表明，不同语言中过度依赖自信的生成内容的风险很高。这强调了多语言语言校准的挑战，并强调了基于文化与语言背景的模型安全评估的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01494", "html_url": "https://arxiv.org/abs/2507.01494", "title": "使用深度学习技术的作物害虫分类：一篇评论", "title_en": "Crop Pest Classification Using Deep Learning Techniques: A Review", "authors": "Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib,Muhammad Attique,Tae-Sun Chung", "background": "全球作物产量仍然受到持续的害虫威胁，传统的监测方法往往是慢、手工且难以扩展。近年来，深度学习技术成为了强大的解决方案，卷积神经网络（CNN）、视觉变换器（ViT）和混合模型等技术开始用于自动化害虫检测。", "innovation": "这篇论文回顾了2018年至2025年间发布的37项研究，这些研究集中在基于AI的害虫分类上。研究按作物类型、害虫种类、模型架构、数据集使用情况以及关键技术挑战进行了组织。早期研究主要依赖于CNN，但最新的工作转向了混合和基于变换器的模型，从而提高了准确性和更好的上下文理解能力。然而，具有不平衡数据集、难以检测小型害虫、有限的泛化能力和在边缘设备上的部署仍然是重大挑战。", "conclusion": "总体而言，这篇论文提供了一个有条理的领域概述，突出了有用的数据集，并提出了基于AI的害虫监测系统的关键挑战和未来发展方向。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越令牌视角：LLMs公平性的语义与统计分析", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "现有的大型语言模型（LLMs）常常生成带有固有偏见的响应，影响了其在实际应用中的可靠性。现有的评估方法往往忽视了长文本回复中的偏见以及LLMs输出的内在变异性。尽管已有工作专注于情感或令牌级别的比较，但这些方法大多局限于表面分析，未能深入到语义层面，检测到深层次的偏见差异。因此，亟需一个能够评估群体公平性、同时检测到细微偏见差异的新型统计框架，这让传统的评估方法显得不足。", "innovation": "本文提出了一种创新的统计框架FiSCo（Fine-grained Semantic Computation），用于通过比较不同群体间长文本响应的细微语义差异来评估大型语言模型的群体公平性。不同于以往仅在情感或令牌级别进行比较的工作，FiSCo在语义层面进行分析，并使用蕴含检查来评估响应含义的一致性。FiSCo将模型输出分解为语义上不同的断言，并通过统计假设检验比较群体间的相似性和差异性，从而实现对细微偏见的稳健检测。此外，还提出了一种新的群体反事实公平性定义，并在性别、种族和年龄等多个维度的数据集上进行了验证，显然优于现有的多种评估指标。", "conclusion": "实验结果表明，FiSCo能够更可靠地识别出细微的偏见问题，同时减少了因LLMs的随机变量而产生的影响，显著优于其他评价标准。这一工作不仅提供了评估LLMs群体公平性的新方法，而且为理解并减轻模型偏见提供了新的视角。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00038", "html_url": "https://arxiv.org/abs/2507.00038", "title": "以质胜量：基于点维信息的有效大规模数据缩减策略", "title_en": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "authors": "Fei Chen,Wenchi Zhou", "background": "为了提高模型训练的有效性，数据缩减对于数据为中心的人工智能是很重要的。它通过在大数据集中标记最有教育意义的例子来实现这一点。增加数据质量和训练效率的关键挑战在于选择最佳实例，而不是使用完整的数据集。", "innovation": "本文提出了一种基于点维信息（PVI）的有效数据缩减策略。首先，利用PVI量化样本难度并移除非重要样本。实验表明，在移除10%-30%的数据后，分类器性能仅下降0.0001%到0.76%。其次，通过渐进学习策略对按PVI排序的实例进行训练，加速收敛，相比于传统训练实现0.8%的准确性增长。这表明，在采用高效数据缩减策略时，在选定的优化子集中训练分类器可提高模型性能并增加训练效率。", "conclusion": "我们的研究结果表明，与高效的缩减策略相结合，在选定的最优子集上训练分类器可能提高模型性能和训练效率。此外，已将PVI框架从英语数据集扩展到多种中文自然语言处理任务和基础模型，为跨语言数据缩减提供了有益的结果。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17747", "html_url": "https://arxiv.org/abs/2507.17747", "title": "预训练于测试集已不再足够：基于辩论的问答基准方法", "title_en": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks", "authors": "Linbo Cao,Jinman Zhao", "background": "随着前沿语言模型在标准问答基准测试中逐渐饱和，数据污染、记忆化以及数据集创建成本上升的问题持续存在。本文提出了一种基于辩论的评估范式，将任何现有的问答数据集转化为结构化的对抗性辩论，一方模型接受标准答案进行辩护，另一方构建并辩护替代答案，由不了解正确答案的裁判模型进行裁决。这种方法通过多轮辩论显著增加了难度，同时惩罚浅层记忆，利用现有的问答项目减少编辑成本。", "innovation": "本文的两项主要贡献是：（1）一种系统地将问答任务转化为基于辩论的评估流程；（2）提供了首次基于辩论的公共基准测试，并在MMLU-Pro的问题集中展示了其有效性，配套有标准化的协议和参考模型。实验结果验证了该方法的鲁棒性和对数据污染的有效防护——经过微调的Llama 3.1模型在辩论中表现不佳，虽然在基于测试集的问题上表现显著提升。此类方法还可使较弱的裁判可靠地区分较强的辩论者，指出辩论型评估可以扩展到未来更强大的系统，成本仅为创建新基准的一小部分。", "conclusion": "本文框架强调了‘预训练于测试集已不再足够’的观点，为衡量先进语言模型的真实推理能力提供了一条可持续的发展路径。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09082", "html_url": "https://arxiv.org/abs/2506.09082", "title": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models", "title_en": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models", "authors": "Zheda Mai,Arpita Chowdhury,Zihe Wang,Sooyoung Jeon,Lemeng Wang,Jiacheng Hou,Wei-Lun Chao", "background": "视觉基础模型（VFMs）的发展促使了系统评价的需求。常见的方法是将VFMs与大型语言模型（LLMs）结合作为通用头部，并在广泛的视觉问答（VQA）基准上进行评估。然而，这种协议存在两个关键盲点：首先，指令调整数据可能与VQA测试分布不一致，这意味着一个错误的预测可能是由于数据匹配问题而不是VFMs的视觉缺陷；其次，VQA基准通常需要多种视觉能力，使得难以判断错误是由于缺乏所有需要的能力还是单一关键能力。", "innovation": "为了解决这些缺口，作者引入了AVA-Bench，这是第一个明确拆分14种基础视觉能力（AVAs）的基准，包括定位、深度估计和空间理解等支持复杂视觉推理任务的技能。通过拆分AVAs并在每个能力的训练和测试分布之间进行匹配，AVA-Bench指出了VFMs在哪些方面表现出色或失败。将AVA-Bench应用于顶级VFMs揭示了它们独一无二的“能力指纹”，使VFMs的选择从猜测变为主导式的工程实践。值得注意的是，研究发现一个0.5B LLM的排名结果与7B LLM相似，但减少了8倍的GPU小时，提高了评估效率。", "conclusion": "通过提供一个全面和透明的基准，我们希望AVA-Bench为下一代视觉基础模型打下基础，在驱动VFMs的发展和改进方面起到关键作用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00381", "html_url": "https://arxiv.org/abs/2508.00381", "title": "通过Adapt-WeldNet和缺陷检测解释性分析在海上运营中推进焊接缺陷检测", "title_en": "Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis", "authors": "Kamal Basha S,Athira Nambiar", "background": "在石油和天然气行业中，确保管道系统的安全性和可靠性至关重要，特别是在海洋和海上环境等挑战性环境中。传统的无损检测（NDT）方法通常难以检测到细微或内部缺陷，可能导致潜在的失败和昂贵的停机时间。现有的基于神经网络的缺陷分类方法往往依赖于随机选择的预训练架构，缺乏可解释性，部署时存在安全问题。", "innovation": "本文提出了Adapt-WeldNet，一种自适应框架，系统地评估了各种预训练架构、迁移学习策略和适应性优化器，以识别性能最佳的模型和超参数，优化缺陷检测并提供可操作的见解。此外，提出了一种新的缺陷检测解释性分析（DDIA）框架，以增强系统的透明度。DDIA结合了解释性人工智能（XAI）技术，如Grad-CAM和LIME，以及由ASNT NDE Level II认证专业人员验证的特定领域评估。通过结合人类在环（HITL）的方法和值得信赖的人工智能原则，DDIA确保了缺陷检测系统的可靠性和问责性，通过专家验证提升了自动化决策的信心。", "conclusion": "通过改进性能和解释性，本文增强了焊接缺陷检测系统的信任、安全性和可靠性，支持了海上和海洋环境中的关键操作。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "ScIReN：发现碳循环中隐藏的关系及相关研究", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对于缓解气候变化至关重要。虽然土壤具有从大气中储存碳的潜力，但土壤碳循环仍不完全了解。现有基于数学的土壤碳循环过程模型依赖于未知参数，并且往往无法很好地拟合观测结果。另一方面，神经网络可以从数据中学习模式，但不遵守科学定律，也无法揭示新科学关系。因此，提出了一个完全透明的框架——具有科学解释性的推理网络（ScIReN），结合了可解释的神经网络和过程模型推理。", "innovation": "ScIReN 利用柯莫哥洛夫-阿诺德网络（KAN）确保编码器具有完全的可解释性，并揭示输入特征与潜在参数之间的关系；使用新颖的光滑惩罚来平衡表达性和简单性。同时采用新型硬Sigmoid约束层将潜在参数限制在由科学先验知识定义的合理范围内。过程模型解码器强制执行已确认的科学知识，而基于KAN的编码器揭示了常规黑盒模型中隐藏的新科学关系。在两个任务中，ScIReN 在预测准确性上优于黑盒网络，同时提供了大量科学可解释性——它可以推断出潜在的科学机制及其与输入特征的关系。", "conclusion": "在模拟土壤有机碳流动和植物生态系统呼吸两个任务中，ScIReN 在预测准确性方面优于黑盒网络，同时提供了显著的科学可解释性，可以推断出潜在的科学机制及其与输入特征的关系。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23543", "html_url": "https://arxiv.org/abs/2507.23543", "title": "ART: 自适应关系调优以实现关系预测的泛化", "title_en": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "authors": "Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth", "background": "视觉关系检测（VRD）是识别场景中物体之间关系的任务。仅基于关系检测数据训练的VRD模型难以在新关系上泛化。虽然提示调优已被用于适应视觉-语言模型（VLMs）进行VRD，但其使用手工地制作的提示，并难以处理新奇或复杂的对象关系。因此，一些先前的方法难以有效地进行关系泛化和预测。本文旨在通过一种名为ART的方法，自适应地调优VLMs以提高对关系的预测能力，并解决这一问题。", "innovation": "本文提出了一种自适应关系调优框架ART，通过指令调优和策略性的实例选择来适应VLMs进行VRD。ART将VRD数据集转换为指令调优格式，并使用自适应采样算法，使模型聚焦于信息性关系，同时保持泛化能力。ART特别适用于关系分类任务，通过在保留部分数据集上进行调优并在多种复杂程度不同的数据集上进行评估，显示出显著优于基线方法的表现，并且可以推断出未见过的关系概念，这是现有主流VRD方法所不具备的能力。", "conclusion": "实验结果表明，ART有效地提升了VRD模型在检测复杂场景中未见过关系概念的能力，证明了其实际价值。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02773", "html_url": "https://arxiv.org/abs/2508.02773", "title": "Web3 x AI Agents: 景观、集成和基础挑战", "title_en": "Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges", "authors": "Yiming Shen,Jiashuo Zhang,Zhenzhe Shao,Wenxuan Luo,Yanlin Wang,Ting Chen,Zibin Zheng,Jiachi Chen", "background": "随着Web3技术和AI代理的融合，去中心化生态系统正经历着快速变革。本文是首个全面分析Web3与AI代理交集的研究，探讨了五个关键维度：景观、经济、治理、安全以及信任机制。通过对133个现有项目的研究，作者旨在填补研究空白，揭示项目分布和资本化的独特模式，进一步研究AI代理在去中心化金融、治理机制增强、安全强化及可靠性框架建立中的关键角色与贡献。", "innovation": "本文提供了Web3与AI代理交集的首个全面分析，分类并系统地描绘了当前市场景观，并深入探讨了AI代理在去中心化金融、增强治理、强化安全及构建可靠性框架等四个关键集成中的作用，为未来研究提供了新的视角和基础挑战分析。文章识别了关键集成模式，并指出了与可扩展性、安全性和伦理相关的基础挑战，为构建智能、可信的去中心化系统提供了重要参考。", "conclusion": "本文通过综合分析五个关键维度，识别了关键集成模式、指出了与可扩展性、安全性和伦理相关的基础挑战，并概述了未来研究的关键考虑，以构建高效、智能且值得信赖的去中心化系统，其中有效AI代理交互是未来研究的关键方向。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04928", "html_url": "https://arxiv.org/abs/2508.04928", "title": "使用校准标记将基础单目深度估计器扩展到鱼眼相机", "title_en": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens", "authors": "Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong", "background": "现有的基础单目深度估计器（FMDEs）在训练时使用了大量透视图像，但这些模型容易受到相机校准参数（如内在参数和失真参数）变化引发的协变量偏移的影响，从而导致深度估计错误。研究者希望在不需要重新训练或微调的情况下，将这些模型用于鱼眼相机。目前的方法通常需要对鱼眼图像进行校准或投影到统一参考帧，这可能会引入负向影响。因此，这项研究提出了一种新的方法，通过引入少量轻量级的校准标记（Calibration Tokens），在不依赖鱼眼图像的情况下，对透视图像进行校准，并在训练过程中保持图像估计结果的一致性，从而实现了FMDEs在鱼眼相机上的应用。该方法能够在已有的大规模透视图像数据集上进行训练，提高了室内和室外场景的深度估计准确性，并且能够使用单一令牌集实现性能提升，而无需针对不同情形重新训练。", "innovation": "研究提出了一种轻量级的校准标记机制，通过调整FMDEs的潜在嵌入来重新校准透视图像到鱼眼图像，从而无需重新训练或微调即可直接应用于鱼眼相机。这种方法通过在潜在嵌入空间中进行调节，避免了传统方法中可能出现的负向影响，如图像校准或投影所带来的误差和损失，同时该方法是自我监督的，能够利用现有的大规模透视图像数据集进行训练，从而提高不同场景下单目深度估计的准确性。", "conclusion": "研究在多个FMDEs上进行了测试，涵盖室内和室外场景，表明使用单一令牌集在所有场景中均能显著改善深度估计性能，相比现有的最先进的方法表现出优势。已经开发了相应的代码，可供其他研究人员使用。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03872", "html_url": "https://arxiv.org/abs/2508.03872", "title": "超大规模湍流数据的智能采样以实现准确高效的时空模型训练", "title_en": "Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training", "authors": "Wesley Brewer,Murali Meena Gopalakrishnan,Matthias Maiterth,Aditya Kashi,Jong Youl Choi,Pei Zhang,Stephen Nichols,Riccardo Balin,Miles Couchman,Stephen de Bruyn Kops,P.K. Yeung,Daniel Dotson,Rohini Uma-Vaideswaran,Sarp Oral,Feiyi Wang", "background": "随着摩尔定律和 Dennard 缩放定律的终结，高效的模型训练越来越依赖于重新思考数据量的问题。本文通过智能子采样来评估我们能否使用显著较少的数据训练出更好的模型，从而推测出更紧凑的采样策略的重要性。背景信息表明，在大数据集上进行模型学习对能量消耗提出了挑战，因此需要一种新的工具或方法来解决这个问题。文章提出了SICKLE框架，该框架采用了新的最大熵（MaxEnt）采样方法，并能够实现可扩展的 training 和能源基准测试，以应对大数据集的需求。", "innovation": "该研究提出了SICKLE框架，这是一种用于高效学习的稀疏智能筛选框架，该框架结合了一种新的最大熵（MaxEnt）采样方法以及可扩展的训练和能源基准测试。研究通过比较MaxEnt与其他采样方法（如随机采样和相空间采样）在大型直接数值模拟（DNS）湍流数据集上的表现来展示SICKLE框架的创新点。结果显示，在部分情况下，通过预处理中的子采样可以提高模型的准确性和大幅降低能源消耗，最高可达38倍的减少。这是一种新的方法，能够显著改进大规模数据集上的模型训练效率和能耗问题。", "conclusion": "通过SICKLE框架的使用，作者展示了在超大规模湍流数据集上，通过子采样作为预处理步骤可以在不牺牲模型准确性的情况下，显著降低能源消耗。此外，该研究的特点是采用最大熵（MaxEnt）采样方法，实现可扩展的训练，并结合了能源基准测试，为后续在大规模数据集上优化模型训练提供了有效的参考。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03700", "html_url": "https://arxiv.org/abs/2508.03700", "title": "MagicGUI：具有可扩展数据管道和强化微调的基石移动GUI代理", "title_en": "MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning", "authors": "Liujian Tang,Shaokang Dong,Yijia Huang,Minqi Xiang,Hongtao Ruan,Bin Wang,Shuo Li,Zhiheng Xi,Zhihui Cao,Hailiang Pang,Heng Kong,He Yang,Mingxu Chai,Zhilin Gao,Xingyu Liu,Yingnan Fu,Jiaming Liu,Xuanjing Huang,Yu-Gang Jiang,Tao Gui,Qi Zhang,Kang Wang,Yunke Zhang,Yuran Wang", "background": "该论文提出了MagicGUI，这是一种基础的移动GUI代理，旨在解决现实世界移动GUI环境中感知、语义关联和推理的关键挑战。MagicGUI框架基于六个关键组件：一个通过可扩展的GUI数据管道构建、涵盖开放源代码仓库、自动化抓取和目标手动标注的全面且准确的数据集；增强的感知和语义关联能力，有助于细粒度的多模态对齐，用于UI元素引用、语义关联和屏幕理解；全面统一的操作空间，包括基本UI操作和复杂交互意图，以支持人类-代理交互；以规划为导向的推理机制，使模型能够将复杂的用户指令分解为具有显式中间元计划推理的顺序操作；迭代的两阶段培训过程，结合大规模持续预训练和利用空间增强复合奖励及双重过滤策略的强化微调，以及在专有Magic-RICH基准和多种已公开基准上表现出的卓越性能，在GUI感知和代理任务中表现优越，展示了在实际移动GUI场景中强大的泛化能力和实际部署潜力，如图1所示。", "innovation": "MagicGUI框架通过构建大型且多样化的目标手动标注为数据集，增强了感知和语义关联能力，设计了全面统一的操作空间，引入了以规划为导向的推理机制，采用了迭代的两阶段培训过程，实现了在现有基准上的优越性能，展示了在实际移动GUI场景中的泛化能力和实际部署潜力。", "conclusion": "该研究提出了MagicGUI，通过构建大型且多样化的目标手动标注为数据集，增强感知和语义关联能力，设计全面统一的操作空间，引入以规划为导向的推理机制，采用迭代的两阶段培训过程，在专有和公开基准上实现了卓越性能，展示了在实际移动GUI场景中的泛化能力和实际部署潜力。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01646", "html_url": "https://arxiv.org/abs/2508.01646", "title": "SPARTA: 利用基于尖峰时间优先级提升尖峰神经网络中稀疏注意", "title_en": "SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization", "authors": "Minsuk Jang,Changick Kim", "background": "当前的尖峰神经网络(SNNs)未能充分利用尖峰调控固有的时间动态，主要依赖率编码而不是精确的时间信息，这为计算提供了丰富的线索。计算效率和准确性都有提升的空间。", "innovation": "我们提出了SPARTA（尖峰优先注意与资源适应性时间分配），一个框架，利用异质神经元动力学和尖峰时间信息，实现高效的稀疏注意。SPARTA 根据时间暗示（包括尖峰模式、尖峰时间和尖峰间间隔）来优先处理标记，通过竞争门控实现65.4%的稀疏度。这种方法选择最显著的标记，将注意力复杂度从O(N^2)降低至O(K^2)，同时保持高准确率。我们的方法在DVS-Gesture 上达到了98.78%的最佳性能，并在CIFAR10-DVS 和 CIFAR-10 上取得了竞争力的结果，表明利用尖峰时间动力学能够提高计算效率和准确性。", "conclusion": "本方法展示了利用尖峰时间动力学提升在尖峰神经网络中的稀疏注意的潜力，既提高计算效率也提升准确性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05722", "html_url": "https://arxiv.org/abs/2508.05722", "title": "PEACH: 用于医疗领域的英阿并列句对齐语料库", "title_en": "PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare", "authors": "Rania Al-Sabbagh", "background": "医疗领域的文本在跨语言交流中非常重要，但现有的语料库往往缺乏高质量、详细的对齐信息。为了支持对比语言学、翻译研究和自然语言处理等领域，并提供一个可靠的双语字典，研究人员需要一个高质量的并列句对齐语料库。PEACH语料库就是为了满足这些需求而设计的，它涵盖了患者信息手册和教育材料的平行文本，旨在提供高质量的平行语料，以支持这些研究领域。", "innovation": "PEACH 是一个手动对齐的平行语料库，包含 51,671 个平行句子，总共有约 590,517 个英语词素和 567,707 个阿拉伯语词素。其特点是每个句子的长度在 9.52 到 11.83 个词语之间，这对于对比语言学、翻译研究和自然语言处理都是一个高标准的数据源。与其他平行语料库相比，PEACH 具有更高的对齐准确性，能够在各个领域发挥重要作用，例如生成双语词典、适应特定领域的大型语言模型，评估机器翻译的用户感知，检验患者信息手册和教育材料的可读性和用户友好性等。", "conclusion": "PEACH 语料库是公开可访问的，能够提供多方面的研究价值，对于对比语言学、翻译研究和自然语言处理等领域具有重要贡献。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05803", "html_url": "https://arxiv.org/abs/2508.05803", "title": "人类样式的短暂记忆改善了变换器语言模型的语言学习但损害了阅读时间预测", "title_en": "Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models", "authors": "Abishek Thamma,Micha Heilbron", "background": "研究背景包括人类记忆短暂性对语言学习的作用，认知科学家认为记忆限制反而可能有助于语言学习，这得到了经典连接主义建模工作的支持。然而，随着变换器模型的出现，这种观点受到了挑战，这些模型能够在缺乏记忆限制或其他近期偏见的情况下有效地学习语言。", "innovation": "本文通过在开发性现实数据集上对变换器语言模型进行有限制记忆和无限制记忆的训练，并从语言建模整体性能和目标句法评估两方面进行比较，发现了短暂记忆的正面效应，即改善了语言学习，以及一个意外的负面效应，即恶化了基于惊异值预测人类阅读时间的能力。", "conclusion": "研究结果支持记忆限制对神经网络语言学习有益的观点，但对预测行为没有积极作用。更详细的分析表明，这种差异（更好的语言建模与更差的阅读时间预测）无法用现有解释来说明为什么更好的语言模型有时会导致更差的阅读时间预测。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05782", "html_url": "https://arxiv.org/abs/2508.05782", "title": "FineDialFact：对话细粒度事实验证基准", "title_en": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification", "authors": "Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver", "background": "大型语言模型（LLMs）会产生幻觉，即事实错误或虚构的信息，这对许多自然语言处理（NLP）应用，如对话系统，构成了重大挑战。因此，幻觉检测已成为一个关键的研究领域。目前，对话系统中幻觉检测方法主要关注生成响应的事实一致性验证。然而，这些响应通常包含准确、不准确或无法验证的事实，使得单一的事实标签过于简单化且粒度过粗。", "innovation": "我们提出了一个细粒度对话事实验证基准，FineDialFact，用于验证从对话响应中提取的原子事实。该基准包括构建一个基于公开可用对话数据集的数据集，并使用各种基线方法进行评估。实验结果显示，结合链式思考（CoT）推理的方法可以增强对话事实验证的表现。尽管如此，F1得分最高仅达到0.75，表明该基准仍是未来研究的挑战性任务。", "conclusion": "我们的数据集和代码将在GitHub上公开。尽管取得了一定进展，但整体而言，FineDialFact基准依然是一个具有挑战性的研究任务。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05246", "html_url": "https://arxiv.org/abs/2508.05246", "title": "基于虹膜图像的性别分类技术研究：深度综述与分析", "title_en": "A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis", "authors": "Basna Mohammed Salih Hasan,Ramadhan J. Mstafa", "background": "性别分类在监控、公司评估和个人计算机交互等多种应用中具有吸引力。个人信息可以从性别信息中获得，这是一种软生物特征。多年来，已经发明了多种性别识别方法，其中一些基于面部特征、指纹、掌纹、DNA、耳部、步态和虹膜等生理特征。然而，面部特征是目前最常用的性别分类方法。虹膜是一种重要的生物特征，因为研究显示虹膜在整个生命中较为稳定，并且虹膜外部可见且对用户无侵入性，适合实际应用。虹膜图像分割和编码已有高质量的方法，当前技术便于选择和提取虹膜纹理的特征向量。", "innovation": "本文对基于虹膜图像的性别分类技术进行了综述和分析，涵盖了不同步骤的方法。本文为相关领域的研究人员提供了既有方法的了解和分析，填补了领域中的空白和挑战，为未来改进提出了建议和方向。", "conclusion": "本文强调对现有性别分类方法的理解，并指出了该领域的研究空白和挑战。同时，为未来的改进提供了建议和方向，旨在帮助对该领域感兴趣的科研人员。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05830", "html_url": "https://arxiv.org/abs/2508.05830", "title": "抑郁的‘镜像’语言AI模型受到标准污染", "title_en": "\"Mirror\" Language AI Models of Depression are Criterion-Contaminated", "authors": "Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns", "background": "越来越多的研究表明，大规模语言模型（LLM）在预测抑郁评估分数方面表现出色（最高R2可达0.70），但这些模型往往直接基于抑郁评估的语言响应构建，这种构建方式导致了预测准确性与模型泛化能力之间的矛盾。", "innovation": "本研究对比了‘镜像模型’和‘非镜像模型’的表现，前者直接使用抑郁评估数据，后者则使用生活史数据。研究发现‘镜像模型’表现出显著优越的效果，但‘非镜像模型’尽管效果次之，但仍保留了一定的实用性。此外，通过自报告抑郁症状的关联分析，确认了‘镜像模型’中的偏误可能源于标准污染，而‘非镜像模型’通过主题建模展现了更多的可解释和泛化的语义特征。", "conclusion": "在‘头对头’的对比研究中，‘镜像’语言AI模型的抑郁评估效果被夸大且泛化能力较弱。为了解决这一问题，未来在开发抑郁评估的AI模型时应采用‘非镜像模型’，这有助于识别具有独特实用性的可解释和泛化的语义特征，提高模型在现实世界心理评估中的应用价值。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05254", "html_url": "https://arxiv.org/abs/2508.05254", "title": "CF3: 紧凑且快速的3D特征场", "title_en": "CF3: Compact and Fast 3D Feature Fields", "authors": "Hyunjoon Lee,Joonkyu Min,Jaesik Park", "background": "3D Gaussian Splatting (3DGS) 开始融合来自2D基础模型的丰富信息。然而，大多数方法依赖于自底向上的优化过程，将原始的2D特征视为真实值，导致计算成本增加。", "innovation": "我们提出了一个自顶向下的管道，用于构建紧凑且快速的3D高斯特征场，称为CF3。首先，通过预训练的高斯函数快速加权融合多视图2D特征。这使得我们可以直接在提升特征上训练单个高斯的自编码器，而不是在2D领域训练自编码器。更重要的是，我们引入了一种自适应稀疏化方法，这种方法在修剪和合并冗余高斯的同时优化特征场的高斯属性，从而构建具有保留几何细节的高效表示。与Feature-3DGS相比，我们的方法仅使用5%的高斯函数即可实现具有竞争力的3D特征场。", "conclusion": "CF3方法在使用极少（仅5%）的高斯函数的情况下，可以构建高效的3D特征场，同时保留几何细节，相比传统的基于自底向上的3DGS方法，具有更高的计算效率和精度。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05843", "html_url": "https://arxiv.org/abs/2508.05843", "title": "发现神经涌现通信中的屈折形态学属性", "title_en": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication", "authors": "Miles Gilberti,Shane Storks,Huteng Dai", "background": "基于深度神经网络的元语言通信（EmCom）有望揭示人类语言的本质，但目前主要集中在少数子领域特定的目标和评估指标上，这些指标优先考虑那些能够一对一地表现属性并从句法上组合的语言交流方案。本文重新诠释了一个常见的EmCom设置，即属性值重构游戏，通过施加小词汇量的约束来模拟二元表达，从而提出一种新的类似自然屈折形态学的设置（便于与自然语言交流方案进行有意义的比较）。研究者开发了新的评价指标，并探索由屈折形态学的实际属性激发的游戏变体：连贯性和结合性。通过实验，研究者发现模拟音系约束促进了连贯形态，并且涌现语言再现了自然语言合并语法属性的趋势。", "innovation": "通过施加小词汇量的约束来模拟二元表达，并提出一种新的类自然形态学的设置，从而评估元语言通信方案。开发了新的评价指标，并探索由屈折形态学的实际属性激发的游戏变体，揭示了模拟音系约束对促进连贯形态的影响，以及涌现语言与自然语言在合并语法属性方面的相似性。", "conclusion": "模拟音系约束促进了连贯形态，并且涌现语言再现了自然语言合并语法属性的趋势。研究者开发了新的评价指标，并探索了由屈折形态学的实际属性激发的游戏变体，通过实验揭示了模拟音系约束对当前研究的意义。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05775", "html_url": "https://arxiv.org/abs/2508.05775", "title": "守护者与破坏者：有害内容生成与安全缓解的综述", "title_en": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation", "authors": "Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu", "background": "大型语言模型（LLMs）已经彻底改变了数字平台上的内容创作，提供了前所未有的自然语言生成和理解能力。这些模型可以使内容生成、问答（Q&A）、编程和代码推理等应用变得有益。然而，它们也带来了重大风险，可能会无意或有意地生成有害、冒犯或有偏见的内容。这种双重角色，即作为解决实际问题的强大工具和潜在有害语言的来源，提出了一个重要而紧迫的跨学科挑战。", "innovation": "该论文提出了一种统一的LLM相关危害和防御分类系统，分析了新兴的多模态和LLM辅助的“越狱”策略，并评估了缓解措施，包括带有人类反馈的强化学习（RLHF）、提示工程和安全性对齐。合成结果显示了LLM安全性不断变化的格局，并指出了当前评估方法的局限性，并提出了未来的研究方向，以指导稳健且符合伦理的语言技术的发展。", "conclusion": "综合结果强调了LLM安全性不断变化的格局，指出了当前评估方法的局限性，并列出了未来研究方向，以指导稳健且符合伦理的语言技术的发展。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05880", "html_url": "https://arxiv.org/abs/2508.05880", "title": "大型语言模型是否具有情感思考能力？基于认知评估分析的评估", "title_en": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models", "authors": "Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang", "background": "情感计算已确立为推进人工智能系统全面发展的关键领域。过去的研究已经对基础模型（尤其是大规模语言模型LLMs）进行了评估、训练或指令调优，使它们能够更好地预测或生成情感。大多数研究以监督方式处理情感任务，使用刺激（如文本、图像、视频、音频）相关的离散情感标签评估或训练LLMs的能力，评价研究尤其限于标准和表面的情感任务，如情绪表达或诱发情绪的识别。", "innovation": "本文突破了表面级情感任务，探讨了LLMs如何通过认知维度进行情感推理。通过借鉴认知评估理论，研究LLMs在处理情感激发刺激时是否会产生连贯且可验证的认知推理。本文引入了一个大规模的“情感认知推理基准”- CoRE，评估LLMs在情感推理中内在使用认知结构。通过广泛的评估实验和分析，探讨（a）模型更可能隐式依赖哪些特定的认知评估维度；（b）哪些认知维度对于表征特定情感很重要；（c）LLMs中不同情感类别的内部表示能否通过认知评估维度进行解释。研究结果和分析揭示了不同LLMs中的不同推理模式。", "conclusion": "研究发现不同LLMs存在不同的推理模式。本文将基准和代码将公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06030", "html_url": "https://arxiv.org/abs/2508.06030", "title": "通过调整预训练嵌入进行大型语言模型高效知识探测", "title_en": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "authors": "Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar", "background": "大型语言模型（LLMs）在生成式预训练过程中学习到了涵盖多个领域的知识，如科学、历史和地理。然而，由于其随机性，预测LLMs到底学到了哪些知识是困难的。现有研究表明，通过探究隐层表示、设计具体的任务提示、收集代表性样本和估计其不确定性来检验这些知识，但这些方法需要通过模型进行前向传递来推断LLMs关于特定事实的知识，这使得它们计算成本高且效率低。", "innovation": "本文提出了一种名为PEEK的方法，即利用预训练的嵌入模型来估计LLMs的知识，这些嵌入模型能有效编码事实知识作为与LLMs相对应的文本或图形代理。首先，通过多样的探究策略识别LLMs已知的训练集事实，然后将嵌入模型与线性解码层适配以预测LLMs的输出。综合评估表明，嵌入可以在不涉及LLMs本身的情况下，准确预测其知识超过90%。此外，研究表明词句嵌入模型比图形嵌入模型更适合预测LLMs的知识，有助于揭示事实领域的潜在表示。", "conclusion": "本研究表明，调整过的嵌入模型可以在大规模上用于识别LLMs的知识空白，提供更深入的了解其内部归纳偏差。实验结果已开源，包括代码和数据以此为准。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06103", "html_url": "https://arxiv.org/abs/2508.06103", "title": "使用指令调优的大语言模型的少样本提示提取式古兰经问答", "title_en": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs", "authors": "Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed", "background": "该论文解决了古兰经中复杂语言、独特术语和深刻含义所带来的挑战，旨在提高提取式问答任务的效果。", "innovation": "该研究提出了两种有效的方法来解决古兰经的提取式问答问题，并使用指令调优的大语言模型和特殊的阿拉伯提示框架。另外，还开发了一个强大的后处理系统，包括子词对齐、重叠抑制和语义过滤，以提高精度并减少幻觉现象。此外，研究发现带有阿拉伯指令的大语言模型优于传统微调模型。最佳配置实现了pAP10得分为0.637。", "conclusion": "研究表明，基于提示的指令调优对于低资源、语义丰富的问答任务是有效的。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06046", "html_url": "https://arxiv.org/abs/2508.06046", "title": "EvolvR: 自适应综合两两推理在故事评价中的应用以提升生成质量", "title_en": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "authors": "Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang", "background": "尽管大型语言模型（LLM-as-a-judge）的有效性已得到验证，但在开放任务领域，尤其是故事评价中，其表现仍有限。准确的故事评价对于辅助人类质量判断以及为故事生成提供关键信号至关重要。现有方法遇到困境：闭源模型的提示工程适应性差，而开源模型通过微调进行改进但缺乏故事评价所需的严密推理能力。", "innovation": "本文提出了自适应综合两两推理框架（EvolvR），该框架通过多角色策略自我合成打分一致的思维链（CoT）数据，并利用多代理保证数据逻辑上的严谨性和稳健性。最终使用净化后的数据训练的评价器作为奖励模型，以引导故事生成任务。实验证明，该框架在三个评价基准StoryER、HANNA和OpenMEVA上达到当前最佳水平，并显著提高了生成故事的质量。", "conclusion": "实验结果表明，EvolvR框架在故事评价任务中表现出色，特别是当作为奖励模型使用时，显著提升了生成故事的质量，充分验证了其自适应构建方法的优势。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06094", "html_url": "https://arxiv.org/abs/2508.06094", "title": "ConlangCrafter：使用多跳LLM管道构建语言", "title_en": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline", "authors": "Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš", "background": "创造了诸如Esperanto和Quenya这样的人造语言（称为构想语言）在艺术、哲学和国际交流中扮演了多种角色。同时，大规模的基础模型在文本、图像乃至更多领域中带来了创意思维的革命。本文利用现代大型语言模型（LLM）作为计算创意助手，用于端到端的人造语言创造。背景涉及语言设计的不同模块，包括音韵学、词法学、句法学、词汇生成和翻译。每个模块中，本研究利用了LLM的元语言推理能力，并通过引入随机性以鼓励多样化，并通过自我完善反馈以确保语言描述的连贯性。", "innovation": "介绍了ConlangCrafter，一种多步骤管道，将语言设计分解为模块化阶段，利用LLM元语言推理能力，并通过自反馈机制确保语言描述的一致性，从而增强多样性", "conclusion": "ConlangCrafter在衡量连贯性和类型多样性方面取得的评价结果表明，它可以生成连贯且多样的人造语言，而不需要人类语言学专业知识。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06016", "html_url": "https://arxiv.org/abs/2508.06016", "title": "Crystal-clear Attention: 通过结构化稀疏性正则化变换器", "title_en": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "authors": "Sagar Gandhi,Vishal Gandhi", "background": "自注意力机制的计算成本呈二次增长，是扩展Transformer模型的主要障碍。尽管稀疏性被广泛研究以提高计算效率，但普遍认为稀疏性会导致模型准确性的下降。本文在DistilBERT模型上进行微调，并引入结构化的后向稀疏性到注意力机制中，发现稀疏性反而提高了模型的准确性，验证了稀疏性可以作为一种有效的隐式正则化手段，防止模型过拟合，使得模型更加鲁棒和精确。", "innovation": "本文的创新在于发现注意力机制的稀疏性不仅能提高计算效率，还能通过促使模型使用更受限但更健壮的特征预测，从而提升模型的一般化能力和性能。这种发现挑战了稀疏性导致准确性下降的普遍观点，提出了将结构化后向稀疏性引入注意力机制的新方法，实现了显著的准确率提升。", "conclusion": "本文的工作重新定义了注意力稀疏性的作用，不仅作为一种计算效率的工具，也是一种提高Transformer模型泛化能力和性能的有效方法。通过引入结构化后向稀疏性，模型在情感分析任务SST-2上的验证准确率从基线密集模型的90.62%提高到91.59%，绝对提升了0.97%。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06026", "html_url": "https://arxiv.org/abs/2508.06026", "title": "时序自我奖励语言模型：通过过去未来解耦选定和拒绝", "title_en": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "authors": "Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang", "background": "现有自我奖励语言模型（Self-Rewarding Language Models）结合大型语言模型（LLMs）自身生成回答和评估输出，通过迭代直接偏好优化（DPO）来动态提升其生成能力。然而，研究发现现有自我奖励框架存在关键局限性：选定和拒绝的回答同步改进会逐渐缩小对比样本的表示差异，削弱有效偏好学习的效果。", "innovation": "提出了一种新的时序自我奖励语言模型（Temporal Self-Rewarding Language Models），通过战略性地协调过去的、现在的和未来的模型生成，维持学习信号。该框架包括两个阶段：1. 固定拒绝响应（Anchor Rejection）——使用过去初始模型的输出来固定拒绝的响应；2. 未来引导选定（Future-Guided Chosen）——动态筛选被选择的样本基于下一代模型的预测。这种方法在不同模型家族和不同模型尺寸（Llama、Qwen、Mistral，3B/8B/70B）上进行了广泛实验，显示出在相同计算资源下相比现有自我奖励方法的显著改进。此外，该方法在数学推理、基于知识的问答和代码生成任务上也表现出超越不专门收集此类训练数据的基线方法的卓越的分布外泛化能力。", "conclusion": "时序自我奖励语言模型通过有效地解耦选定和拒绝的样本，提高了偏好学习的效果和模型的生成能力，特别是在数学推理、知识问答和代码生成等任务上展现了优越的分布外泛化性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05938", "html_url": "https://arxiv.org/abs/2508.05938", "title": "玩家游戏聊天中的亲社会行为检测：从人类-人工智能定义对齐到高效的规模化标注", "title_en": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "authors": "Rafal Kocielnik,Min Kim,Penphob(Andrea)Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez", "background": "在信任和安全系统中，检测亲社会行为（即意图肯定、支持或改进他人行为的交流）是一项新颖且日益重要的挑战。与有毒内容检测不同，亲社会行为缺乏成熟的定义和标记数据，这需要在注释和部署方面采用新的方法。", "innovation": "本文介绍了一种实用的三阶段管道，旨在实现亲社会内容分类的高效、高精度判定，同时尽量减少人工标注努力和推理成本。该管道包括：1) 使用少量人工标注示例确定最佳基于大语言模型的标注策略；2) 引入人类-人工智能校准循环，以提升标注质量和任务定义的一致性；3) 使用GPT-4合成效能高质量的标签并训练一种双阶段推理系统，其中轻量级分类器处理高置信度预测，只有约35%的模糊实例被升级到GPT-4o。该结构将推理成本降低了约70%，同时保持了高精度。", "conclusion": "我们的管道展示了如何通过针对性的人工智能互动、仔细的任务界定和部署意识的架构设计，来解锁新型负责任人工智能任务的可扩展解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06124", "html_url": "https://arxiv.org/abs/2508.06124", "title": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models", "title_en": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models", "authors": "Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee", "background": "现有的大型语言模型（LLMs）面临着管理基于使用场景的安全风险的挑战，这些风险指的是模型输出可能无意中促进了有害行为，这是因为忽视了某些逻辑推断所带来的潜在影响。传统的安全解决方案，如基于标量结果的奖励模型、参数调整或启发式解码策略，在检测和介入细微而关键的推理步骤时缺乏足够的细致和前瞻性质。", "innovation": "我们提出了一种名为AURA的创新、多层次框架，其核心是过程奖励模型（PRMs），提供了一种全面的、逐步骤的逻辑一致性和安全意识评估。AURA框架通过整合内省式自省批判、精细化的PRM评估和适应性安全意识解码，使模型能够动态和主动地朝着更安全的推理轨迹前进。实验证明，这种方法显著超越了现有的方法，显著提高了模型输出的逻辑完整性和对基于使用场景的安全意识。", "conclusion": "这项研究代表了向更安全、更具责任感和上下文感知AI迈出的重要一步，为对齐敏感应用设定了新的标准。"}
{"llm_update_time": "20250811", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05028", "html_url": "https://arxiv.org/abs/2508.05028", "title": "LLMs在AMR解析中的评估", "title_en": "Evaluation of LLMs in AMR Parsing", "authors": "Shu Han Ho", "background": "AMR（抽象意义表示）是一种语义形式主义，它将句子的意义表示为根节点、有向、无环图，其中节点代表概念，边表示语义关系。使用仅解码器超大规模语言模型（LLMs）的微调是对AMR解析具有前景的新颖方法。本文对比了四种不同的LLMs架构（Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled）在LDC2020T02 Gold AMR3.0测试集上的表现，以此评估其在AMR解析中的性能。文章指出，简单的LSTM仅为LLMs微调方法可以达到与复杂SOTA（现有最佳）AMR解析器相媲美的性能，尤其是在直接微调方法下的LLaMA 3.2更是展示了与SOTA AMR解析器竞争力的表现。", "innovation": "本文通过直接微调四种类不同的LLM架构，展示了在AMR解析任务上简单微调的方法可以取得与复杂SOTA方法相近的效果，并且明确指出LLaMA 3.2在纯解码器微调策略中表现出色，达到了与现有最佳系统相近的性能，特别是SMATCH F1得分为0.804，与AJP + Silver（IBM）一致，并接近Graphene Smatch (MBSE) 的0.854水平。此外，进一步的分析还显示LLaMA 3.2在语义表现上优于Phi 3.5，而Phi 3.5在结构准确度上表现更佳。", "conclusion": "在本文的研究中，四种LLM架构的直接微调方法在AMR解析任务上展示了与复杂SOTA方法相近的性能。其中，LLaMA 3.2在直接微调策略下的表现尤为突出，达到了与现有最佳系统相近的水平。同时研究还揭示了不同架构在语义和结构维度上的差异。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06155", "html_url": "https://arxiv.org/abs/2508.06155", "title": "大型语言模型中隐含偏见的语义与结构分析：一种可解释的方法", "title_en": "Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach", "authors": "Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu", "background": "本文研究了大型语言模型在生成过程中的隐性刻板印象问题。研究指出，在模型生成过程中可能会出现隐藏的社会偏见，而这些偏见往往难以通过显性语言特征来捕捉。", "innovation": "本文提出了一种可解释的偏见检测方法，通过嵌套语义表示与上下文对比机制相结合，从模型输出的向量空间结构中提取潜在的偏见特征。使用注意力权重扰动分析模型对特定社会属性术语的敏感性，揭示偏见形成的具体语义路径。该方法利用StereoSet数据集对多个维度（性别、职业、宗教、种族）的刻板印象进行验证，主要评估指标包括偏见检测准确性、语义一致性和上下文敏感性。", "conclusion": "实验结果表明，所提出的方法在各类维度上具有强大的检测性能。该方法能够准确识别细微语义差异中的偏见同时保持高语义对齐度和输出稳定性，其结构设计具有高度的可解释性，有助于揭示语言模型内部的偏见关联机制，为偏见检测提供了更为透明和可靠的技术支持。这种方法适用于需要高度可信内容生成的现实应用场景。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05987", "html_url": "https://arxiv.org/abs/2508.05987", "title": "对抗主题感知提示调优在跨主题自动作文评分中的应用", "title_en": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring", "authors": "Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu", "background": "跨主题自动作文评分（AES）旨在开发一种可迁移模型，能够有效评估目标主题的作文。该领域面临的主要挑战在于主题之间固有的差异。当前方法大多通过源主题和目标主题的分布对齐来提取共通特征，往往忽视了主题特定特征，从而限制了其评估诸如主题契合度等关键特质的能力。", "innovation": "本文提出了一种对抗主题感知提示调优（ATOP）方法，这是一种新颖的方法，通过联合学习共通特征和特定特征来提高跨主题AES。ATOP通过优化一个既包含共享部分又包含特定部分的学习主题感知提示来获取预训练语言模型（PLMs）中的相关知识。为了增强共通提示学习的鲁棒性并缓解由主题对齐引入的特征尺度灵敏性，引入了统一回归和分类框架下的对抗训练。此外，还采用了邻接基于的分类器来建模作文表示的局部结构，并为目标主题作文生成伪标签，这些伪标签用于指导针对目标主题的特定提示的监督学习。", "conclusion": "在公开可用的ASAP++数据集上进行的广泛实验表明，ATOP在整体和多特质作文评分方面显著优于现有最先进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06167", "html_url": "https://arxiv.org/abs/2508.06167", "title": "Pragmatics beyond humans: meaning, communication, and LLMs", "title_en": "Pragmatics beyond humans: meaning, communication, and LLMs", "authors": "Vít Gvoždiak", "background": "这篇论文重新定义了语用学，不再将其视为意义的次要、第三维度，而是作为一种动态界面，通过这种方式语言成为了一种社会嵌入的行动工具。随着大型语言模型（LLMs）在交流中的出现，这种理解需要进一步细化和方法论上重新考虑。论文挑战了传统的符号三元论，指出基于连接主义的LLM架构解稳了已有的意义层次结构，提出人类-机器通信（HMC）框架作为更为合适的选择。论文还探讨了以人类为中心的语用理论与以机器为中心的LLM的紧张关系，尤其是在传统的格赖斯启发式语用学依赖于人类特定假设，不适用于预测性系统如LLM的情况下，提出了概率性语用学，特别是理性言语行为框架，可以提供一种更为兼容的目标，重点是优化而非真理评估。", "innovation": "论文探讨了语用学在人类之外的新角色，引入了人类-机器通信（HMC）框架，重点讨论了以机器为中心的LLM与传统以人类为中心的语用理论的冲突，并提出使用概率性语用学，特别是理性言语行为框架，作为应对生成AI沟通问题的可能选择。", "conclusion": "论文指出语用学研究可能需要调整或扩展，以更好地解释涉及生成AI的沟通情况。特别是，用户被迫与模型共同构建语用条件，但这也可能出现上下文挫败感，即越多提供上下文信息，理解反而越差。这暗示了需要进一步发展语用学理论，以便更好地处理LLMs等生成AI中的沟通问题。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06178", "html_url": "https://arxiv.org/abs/2508.06178", "title": "低资源环境下大型语言模型知识注入方法比较", "title_en": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime", "authors": "Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira", "background": "大型语言模型（LLMs）通常需要大量的文本来有效获取新知识。虽然继续在大型语料库上进行预训练或使用检索增强生成（RAG）已被证明有效，但是仅通过少量的数千或数百万个令牌更新LLM仍然是一个挑战。", "innovation": "本研究探索了将小规模、非结构化信息注入LLMs的方法及其与灾难性遗忘现象的关系。作者使用了一个不与其他预训练数据重叠的最近新闻数据集，通过问题-答案对测试模型获取知识的能力。作者还发掘了在小数据环境中遗忘现象的微妙平衡，并展示了模型自生成有效的训练数据，为模型自我改进提供了可能。", "conclusion": "简单地继续在有限数据上进行预训练带来的改进有限，而使模型接触到各种文本变化则显著提高了新事实的掌握能力，尤其是在通过多样化提示诱导更大变异性的方法效果更好。研究还确认了基于RAG的知识注入方法的敏感性，并展示了模型可以自生合成有效的训练数据，为研究在有限数据下的高效知识注入提供了资源和路径。所有实验使用的代码和生成数据均公开，可供进一步研究使用。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06163", "html_url": "https://arxiv.org/abs/2508.06163", "title": "一种并非一刀切：基于分布感知的稀疏化方法以实现更精确的模型融合", "title_en": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "authors": "Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu", "background": "模型合并已成为多任务学习的一种有吸引力的数据非依赖范式，使多个微调模型能够融合成一个强大的实体。现有方法通常采用一种“一刀切”的策略，使用统一的稀疏化比例来修剪任务向量中的冗余参数，这忽略了模型参数内在的结构和统计异质性。这种做法往往导致参数间影响的次优权衡，重要参数可能意外被修剪，而较少有用的参数则被保留。", "innovation": "本文介绍了一种适应性稀疏化策略TADrop（Tensor-wise Adaptive Drop），能够根据参数的分布特性为每个参数张量分配一个定制化的稀疏化程度。TADrop的核心思想是：密集且冗余的张量能够进行更积极的修剪，而稀疏且关键的张量则应被保留。TADrop作为简单且即插即用的模块，被验证能够在基础、经典和SOTA的模型合并方法中实现整体性能的提升，尤其是在提升领先合并方法时，实现了8个ViT-B/32任务平均2.0%的性能增益。", "conclusion": "TADrop通过根据模型结构定制稀疏化策略，更有效地减轻了参数间的干扰，为高性能模型合并提供了新的基准。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05909", "html_url": "https://arxiv.org/abs/2508.05909", "title": "谱投影分数: 在检索增强生成中将检索摘要与阅读器模型对齐", "title_en": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "authors": "Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui", "background": "大型语言模型（LLMs）通过检索增强生成（RAG）和检索者-阅读者范式表现出改进的生成性能，这通过从外部检索知识来补充模型输入。尽管如此，先前的工作通常整体评估RAG，同时评估检索者和阅读者，这对于独立评估检索的真实贡献是困难的，尤其是对于用作阅读者的LLMs具有提示敏感性。", "innovation": "该研究引入了谱投影分数（SPS），这是一种轻量级、无需监督的指标，允许阅读者通过比较生成的摘要标记与阅读者潜空间中的主方向所形成的区域来衡量检索摘要与隐式表示的语义对齐，并测量相关性。基于SPS，提出了xCompress，这是一种推理时间控制器框架，能够在检索摘要候选中动态抽样、排名和压缩。研究在五个问答基准数据集上使用四个开源LLMs进行的广泛实验表明，SPS不仅提升了各任务的性能，还提供了一个关于检索与生成之间交互的有原则的观点。", "conclusion": "SPS不仅能提升检索增强生成任务的性能，还为评估检索过程中的表现提供了一个有原则的视角，通过动态抽样、排名和压缩检索摘要候选，xCompress进一步优化了这种方法的实用性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06149", "html_url": "https://arxiv.org/abs/2508.06149", "title": "使用 Big Five Scaler 提升 LLM 中的人格控制", "title_en": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "authors": "Gunhee Cho,Yun-Gyung Cheong", "background": "现有关于大语言模型（LLMs）的研究主要集中在模型的生成能力上，但对于通过自定义指令（如提示）来控制模型输出中的人格特质的探索较少。本文旨在探讨使用 Big5-Scaler 框架，通过自然语言提示嵌入可控制的大五人格特质数值，来实现细粒度的人格控制，无需额外训练便能实现这一目标。", "innovation": "本文提出的 Big5-Scaler 框架，在 LLM 中引入了可控的人格特质控制机制，通过在自然语言提示中嵌入数值化的个性特质，实现了在不增加额外训练的情况下对大五人格特质的精细控制。通过在多个任务（如个性特质表达、对话生成和人类特质模仿）中对 Big5-Scaler 的评估，证明了其有效性和多样性，结果表明不同类型的提示和强度会对模型性能产生影响。研究还强调了简洁的提示和较低的个性特质强度对于有效构建具备个性感知对话代理的重要性。", "conclusion": "本文通过 Big5-Scaler 框架，展示了在大语言模型中实现细粒度的人格控制的有效方法，能够在多个任务中诱导一致且可区分的人格特质，不同提示类型和强度会对模型表现产生影响，简洁的提示和较低的个性特质强度更有利于实际应用。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06105", "html_url": "https://arxiv.org/abs/2508.06105", "title": "You Don't Need Pre-built Graphs for RAG: Adaptive Reasoning Structures for Retrieval Augmented Generation", "title_en": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "authors": "Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang", "background": "大型语言模型（LLMs）常常会遇到生成与事实不符的陈述的情况，尤其是在处理超出其知识和感知的问题时。检索增强生成（RAG）通过从知识库中检索查询相关的上下文来支持LLM的推理，以解决这一问题。最近的研究利用预构建的图形来捕捉分布式文档之间的关系连接，表现出在复杂任务中的出色性能。然而，现有的基于图形的RAG方法需要一个昂贵的过程将语料库转化为图形，引入了巨大的标记成本和更新延迟。此外，实际查询在类型和复杂性上有所不同，需要不同的逻辑结构来进行准确的推理。预构建的图形可能不与这些所需的结构对齐，导致无效的知识检索。", "innovation": "本文提出了一个增强检索生成框架（LogicRAG），它在推理时动态提取推理结构来引导适应性检索，而无需预构建的图形。LogicRAG首先将输入查询分解为一组子问题，并构建有向无环图（DAG）来表示它们之间的逻辑依赖关系。为了支持连贯的多步推理，LogicRAG然后使用拓扑排序对图进行线性化，以便按逻辑一致的顺序解决问题。此外，LogicRAG应用图修剪来减少冗余检索，并使用上下文修剪来过滤无关的上下文，显著减少了整体标记成本。", "conclusion": "广泛的实验证明，与最先进的基线方法相比，LogicRAG在性能和效率上都达到了优势。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06165", "html_url": "https://arxiv.org/abs/2508.06165", "title": "UR$^2$: 通过强化学习统一检索增强生成和推理", "title_en": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "authors": "Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu", "background": "大语言模型（LLMs）通过检索增强生成（RAG）和验证奖励的强化学习（RLVR）两种互补的范式展现出了卓越的能力。RAG 提升了知识接地能力，而 RLVR 则优化了复杂的推理能力。然而，这两种能力通常是在孤立的状态下开发的，现有的统一这两种能力的努力范围仍然有限，通常局限于固定检索设置和特定任务假设下的开放领域问答任务。这种缺乏整合的状况限制了 RAG-RL 方法在更广泛领域的泛化能力和应用范围。", "innovation": "本文提出了 UR2（统一检索和推理），这是一个通过强化学习统一检索和推理的通用框架。UR2 的关键贡献包括：1）一种基于难度的教学计划训练，仅在面对有挑战性的问题时才调用检索，2）一种混合知识访问策略，结合领域特定的离线语料库和 LLM 生成的摘要。这些组件的设计旨在实现检索和推理之间的动态协调，从而提高对各种任务的适应能力。实验表明，UR2 在开放领域问答、MMLU-Pro、医疗和数学推理任务中显著优于现有的 RAG 和 RL 方法，其性能接近于 GPT-4o-mini 和 GPT-4.1-mini 在某些基准测试中的表现。", "conclusion": "实验结果证明，UR2 在多个开放领域以及专业任务上显著优于现有的 RAG 和 RL 方法，并且其性能与 GPT-4o-mini 和 GPT-4.1-mini 相当。此外，作者已公开了所有代码、模型和数据。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06135", "html_url": "https://arxiv.org/abs/2508.06135", "title": "少即是多：大型语言模型中选择性反射高效的兼容知识蒸馏", "title_en": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "authors": "Lingyuan Liu,Mengxiang Zhang", "background": "知识蒸馏（KD）是一种将大规模语言模型（LLMs）压缩为紧凑、高效的“学生”模型的基本技术。然而，现有的白盒KD方法主要关注平衡原始答案和学生模型生成的答案，而忽视了训练数据质量及学生模型兼容性两个重要因素。因此，有必要通过改进白盒KD方法，提高知识蒸馏的效果和效率。这也促进了研究者开发新的方法来解决这些问题，如提出新的框架来系统地精炼训练数据，从而提高知识蒸馏过程中的学生模型兼容性和训练数据质量。", "innovation": "为了解决上述问题，作者提出了选择性反射蒸馏（SRD），这是一种新颖的数据收集框架，利用学生模型的反馈来系统地精炼训练数据。SRD通过自动评估和选择提示-响应对，动态地比较真实数据和学生模型输出，从而生成高质量和学生模型兼容的训练实例。值得一提的是，SRD不仅作为一个插件增强模块，而且在不修改基础KD算法的前提下，提高了样本效率，提升了蒸馏过程的效果。此外，SRD采用了课程安排策略，使得选定的优质训练数据能够在定期引入时逐步纳入蒸馏过程中。实验结果表明，SRD不仅能够显著提升蒸馏模型性能，并且还能减少高达39%的训练时间，且不修改基础KD算法就已经取得了这些结果，这进一步验证了其作为插件模块的优势和贡献。", "conclusion": "这项研究改进了白盒KD的知识蒸馏理解，并提供了提高压缩LLMs能力和效率的实际建议。SRD框架为解决训练数据质量和模型兼容性问题提供了一个闭环的解决方案，强调了数据集中因素对于有效和高效的LLM知识蒸馏的重要性。研究结果显示，SRD能够提高不同白盒KD方法和模型架构的蒸馏效果，同时显著降低KD训练的成本和时间。未来，希望这项工作将进一步推动LLM知识蒸馏的研究和应用，特别是在样本效率和压缩效率方面。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06204", "html_url": "https://arxiv.org/abs/2508.06204", "title": "分类问题是一个RAG问题：仇恨言论检测案例研究", "title_en": "Classification is a RAG problem: A case study on hate speech detection", "authors": "Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen", "background": "内容审查的稳健性需要能够快速适应不断变化的政策而不需昂贵的重新训练的分类系统。传统分类任务依赖预训练参数的正确分类，而提出的RAG分类方法则在推理时通过检索上下文知识来评价内容，从而将任务转变为“是否违反了仇恨言论政策？”", "innovation": "我们提出了一种利用检索增强生成（RAG）的分类方法，该方法改变了传统分类任务的执行方式，不再依赖预训练参数来确定正确的类别，而是通过检索上下文知识来评价内容。Contextual Policy Engine (CPE) 是一个有代理性的RAG系统，它具有以下三个主要优点：（1）与领先的商业系统相比，具有稳健的分类准确性；（2）通过检索的政策段落具有固有的可解释性；（3）可以在不进行重新训练的情况下动态更新政策。该系统在三个实验中展示了强大的基本性能，并且能够通过微调特定身份群体的保护程度，同时无需重新训练，并不损害整体性能，从而实现了细粒度的政策控制。", "conclusion": "研究结果表明，RAG可以将分类问题转变为一个更具灵活性、透明性和适应性的过程，不仅适用于内容审核，还能应用于更广泛的分类问题。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06194", "html_url": "https://arxiv.org/abs/2508.06194", "title": "超越统一标准：适应场景的多维度 Jailbreak 评估", "title_en": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation", "authors": "Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan", "background": "准确的 Jailbreak 评估对于 LLM 红队演练和 Jailbreak 研究至关重要。当前方法采用了二分类（例如，字符串匹配、有毒文本分类器、LLM 驱动的方法），只能提供“是/否”标签，而没有量化危害程度。现有的多维度框架（例如，安全违规、相对真实性、信息量）在不同场景下采用了统一的评估标准，导致场景特定的不匹配问题，如“相对真实性”对“煽动性言论”无关，从而影响评估精度。", "innovation": "SceneJailEval 引入了一个创新的场景自适应多维度评估框架，解决了现有方法中“一刀切”的局限性，能够灵活适应定制或新兴场景，具有很强的扩展性。SceneJailEval 还提供了一个全面的 14 情景数据集，涵盖多样化的 Jailbreak 变体和地域案例，填补了高质量、综合基准缺口，特别适用于场景自适应评估。评估结果显示，SceneJailEval 在全场景数据集上的 F1 得分达到了 0.917（比之前 SOTA 高 6%），在 JBB 数据集上为 0.995（比之前 SOTA 高 3%），超越了现有评估方法在不同场景中的准确率限制，证明了其优势。", "conclusion": "SceneJailEval 在场景自适应评估方面取得了最先进的成果，同时填补了高质量评估基准的空白，展示了其在评估精度和灵活适应性上的优越性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06196", "html_url": "https://arxiv.org/abs/2508.06196", "title": "EICAP：通过多轮对话评估和增强大型语言模型的情感智能", "title_en": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations", "authors": "Nizi Nazar,Ehsaneddin Asgari", "background": "情感智能（EI）在开发与人类价值观相契合的大型语言模型（LLM）中是一个关键但尚未充分探索的维度。本研究旨在填补这一空白，提出一种适用于LLM的四层统一心理学基础分类框架，涵盖情绪追踪、因果推理、评估和适当的情绪反应生成。在此基础上，研究者构建了一个新型题为EICAP-Bench的多回合多项选择题基准，用于在多变的语言和文化背景下评估开源LLM的情感智能能力。", "innovation": "提出了一种四层心理学基础的EI分类框架，并设计了一个基于多回合多项选择题的EICAP-Bench基准。对六种LLM进行了评估，选择了Qwen2.5-Instruct作为最佳基线。通过对大规模指令调整对话数据集UltraChat的微调，研究显示在5个EI层级中，仅评估层通过UC微调显示出显著改进，揭示了现有预训练和指令微调范式在使LLM具备深层次情绪推理方面的局限性，并强调了针对特定数据和建模策略的必要性。", "conclusion": "研究揭示了现有预训练和指令微调范式在使LLM具备深层次情绪推理方面的局限性，强调了需要有针对性的数据和建模策略来全面实现EI对齐。同时，Qwen2.5-Instruct在EICAP-Bench上的表现最好，但也只有评估层表现出通过UC微调后的显著改进。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06374", "html_url": "https://arxiv.org/abs/2508.06374", "title": "评估样式个性化文本生成：挑战与方向", "title_en": "Evaluating Style-Personalized Text Generation: Challenges and Directions", "authors": "Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar", "background": "尽管以往的研究已经构建了工具和基准，用于个性化文本生成，但在低资源作者个性化文本生成的空间中，评估这一领域的工作却相对有限。", "innovation": "本文质疑了广泛采用的评估指标如BLEU和ROUGE的有效性，并探索了风格嵌入和LLM-as-judge等其他评估范式，以全面评估个性化文本生成任务。", "conclusion": "我们通过使用包含八种写作任务的样式区分基准，评估了这些指标及其组合的效果，并在三个设置下评估：领域区分、作者归属、LLM个性化与非个性化区分。我们的研究表明，采用多样化的评估指标组合是有效评估样式个性化文本生成的关键。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06277", "html_url": "https://arxiv.org/abs/2508.06277", "title": "使用大型语言模型数据生成以增强德语语音的意图识别", "title_en": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech", "authors": "Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter", "background": "语音命令的意图识别（IR）是人工智能（AI）助手系统的重要组成部分，但现有的大多数方法主要针对短命令且多为英语开发。本文针对老年人的德语语音意图识别，提出了一种创新方法，结合了经过老年人德语语音（SVC-de）适应的Whisper ASR模型和基于Transformer的大型语言模型（LLMs）训练的模型，训练数据来源于LeoLM、Llama3和ChatGPT生成的合成文本数据集。通过合成语音和跨数据集测试，评估了其鲁棒性。", "innovation": "本文提出了一种创新方法，通过使用适应老年人德语语音的Whisper ASR模型结合大型语言模型（LLMs）生成的合成文本数据集进行训练，解决了现有方法受限于短命令和主要针对英语开发的问题。实验结果显示，生成的LLM数据显著提升了分类性能和对不同发音风格和未见过词汇的鲁棒性。研究发现，对于德语意图识别，13B参数的领域特定大型语言模型LeoLM在数据质量方面优于175B参数的ChatGPT。", "conclusion": "本文的研究表明，生成式AI能够有效填补低资源领域中的数据缺口。作者提供了详细的生成和训练数据的过程文档，以确保透明性和可重复性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06309", "html_url": "https://arxiv.org/abs/2508.06309", "title": "矩阵驱动的即时审核：基于PC的LLM抄袭检测与重构", "title_en": "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC", "authors": "Ruichong Zhang", "background": "近年来，关于大型语言模型（LLMs）中的知识产权（IP）问题引起了广泛关注。通过直接权重复制、升级、剪枝或持续预训练等方式抄袭其他LLMs，并声称拥有知识产权而不正确归因原始许可，这种不当行为可能导致原开发者遭受严重的财务和声誉损害。然而，现有检测LLM抄袭的方法在关键方面存在不足，无法准确重构权重对应关系，缺乏计算统计显著性措施（如p值），并且可能会错误地将训练数据类似模型标记为相关。", "innovation": "本文提出了一种名为矩阵驱动即时审核（Matrix-Driven Instant Review, MDIR）的新方法，该方法利用矩阵分析和大偏差理论。MDIR能够准确重构权重关系，提供严格的p值估计，并专注于权重的相似性，不需要完整的模型推理。实验结果表明，MDIR即使在经过大规模转换（如随机排列和使用万亿级标记进行持续预训练）后，也能可靠地检测到抄袭行为。此外，所有检测都可以在一个小时内在一个PC上完成，这使得MDIR在效率和可访问性方面都表现出色。", "conclusion": "实验结果证明了MDIR在检测大规模语言模型抄袭方面的有效性和高效性，即使在经过复杂变换后仍能准确检测抄袭，并且可以在一个小时内通过单个PC完成所有检测，从而弥补了现有方法的不足。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06345", "html_url": "https://arxiv.org/abs/2508.06345", "title": "利用自适应拓扑表示进行零样本图问题解答", "title_en": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "authors": "Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang", "background": "大型多模态模型（LMMs）在各种领域问题回答（QA）任务中显示出了广泛适用的零样本能力，涵盖包括涉及复杂图拓扑的图QA。然而，大多数现有方法仅使用单一类型的图表示，即拓扑表征形式（TRF），如统一的文本提示或固定样式的视觉样式。这些“一刀切”的方法没有考虑到不同模型或任务的具体偏好，往往导致不正确的或过于冗长的回答。", "innovation": "首先，对现有TRF的特性和弱点进行了分析，并设计了一组针对零样本图QA优化的TRFs，标记为$F_{ZS}$。然后，提出了一种新的度量标准，图响应效率（GRE），衡量图形QA中性能与简洁性的平衡。在此基础上，开发了DynamicTRF框架，旨在提高图形QA的准确性和简洁性。具体而言，DynamicTRF首先创建了一个TRF偏好（TRFP）数据集，该数据集基于GRE分数对TRFs进行排序，以探测问题特定的TRF偏好。然后，它训练一个TRF路由器，以在推理过程中为每个问题自适应地分配来自$F_{ZS}$的最佳TRF。", "conclusion": "广泛的实验表明，DynamicTRF在7个领域内算法图QA任务和2个领域外下游任务上显著提升了LMMs的零样本图QA准确性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06220", "html_url": "https://arxiv.org/abs/2508.06220", "title": "InfoCausalQA：模型能否基于图表信息进行非显式因果推理？", "title_en": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?", "authors": "Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu", "background": "近期视觉-语言模型（VLMs）在感知和推理方面展现了惊人的能力，但这些模型在因果推理方面的能力，尤其是基于图表数据和文本内容的因果推理，仍然被忽视。该研究旨在通过设计一个新的基准测试InfoCausalQA，来评估多模式环境下基于图表数据和文本上下文的因果推理能力，并探索现有视觉-语言模型在这一领域的不足之处。InfoCausalQA涵盖了定量因果推理和语义因果推理两大任务，包括5种因果关系：原因、效应、干预、反事实和时序。该基准测试包含了从四个公开来源收集的494张图表-文本对，使用GPT-4o生成了1,482个高质量的多项选择题对，并经过人工修订以确保这些问题不能仅通过表面信息解答，而是需要真实的视觉语义支撑。研究结果表明，当前的视觉-语言模型在计算和语义因果推理方面都表现出明显的局限性，其性能远低于人类，尤其是在利用图表信息进行因果推理方面存在巨大差距。", "innovation": "提出的InfoCausalQA是一个新基准测试，旨在评估基于图表数据和文本内容的因果推理能力，涵盖了定量和语义两种类型的因果推理任务，引入了五种因果关系类型，使用GPT-4o生成高质量的多个选择题对，并通过人工修订确保问题需要真实的视觉语义支撑。该研究通过实验证明了现有视觉-语言模型在这一领域的不足，并提出了进一步提升多模式AI系统因果推理能力的需求", "conclusion": "当前的视觉-语言模型在进行视觉-语义因果推理时表现不佳，需要进一步提高多模态AI系统的因果推理能力。InfoCausalQA作为新的评估基准，突显了该领域研究的重要性和紧迫性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06360", "html_url": "https://arxiv.org/abs/2508.06360", "title": "通过增强提示进行网络欺凌检测", "title_en": "Cyberbullying Detection via Aggression-Enhanced Prompting", "authors": "Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia", "background": "网络欺凌因其隐秘多变的表现形式给其检测带来了挑战。本研究探讨了将攻击性检测作为辅助任务集成到统一训练框架中，是否能增强大型语言模型（LLMs）在网络欺凌检测中的泛化能力和性能。实验在五个攻击性数据集和一个网络欺凌数据集上使用指令调优的LLMs进行，并评估了零样本、少量样本、独立LoRA微调和多任务学习等多种策略。考虑到多任务学习结果的不一致性，研究提出了一种增强提示管道方法，其中攻击性预测嵌入到网络欺凌检测提示中，提供上下文增强。初步结果显示，增强提示管道始终优于标准的LoRA微调，表明攻击性推动的上下文显著提升了网络欺凌检测的性能。", "innovation": "本研究创新性地提出了将攻击性检测作为辅助任务集成到统一训练框架中，以期提升LLMs在网络安全关键应用中的泛化能力，并提出了一种增强提示管道方法，以优化网络欺凌检测效果。", "conclusion": "研究结果表明，包含攻击性信息的上下文显著提升了网络欺凌检测的效果，强调了辅助任务如攻击性检测对提升LLMs泛化能力的潜在价值。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06433", "html_url": "https://arxiv.org/abs/2508.06433", "title": "Memp：探索智能体过程性记忆", "title_en": "Memp: Exploring Agent Procedural Memory", "authors": "Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs）代理在多种任务上表现出色，但它们在程序性记忆方面存在脆弱性，这些记忆要么是手动构建的，要么就嵌入在静态参数中。本文探讨了赋予智能体一种可通过学习、更新和终生保有的过程性记忆策略。", "innovation": "本文提出了Memp，这是一种能够将智能体过去的轨迹提炼成精细的、逐步的指令以及高层次、脚本化的抽象的模块。Memp探索了构建、检索和更新过程性记忆的不同策略。此外，提出了一个动态更新机制，持续修正和完善存储的内容，使其与新经验同步进化。", "conclusion": "通过实验证明，在改进记忆库后，智能体在相似任务上的成功率和效率不断提高。从更强的模型迁移过来的过程性记忆也能在较弱的模型上获得显著的性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06186", "html_url": "https://arxiv.org/abs/2508.06186", "title": "DKG-LLM : 通过动态知识图谱和大型语言模型集成进行医学诊断和个人化治疗建议的框架", "title_en": "DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration", "authors": "Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki", "background": "随着ChatGPT的发布，大型语言模型（LLMs）已呈现指数级增长，这些模型因其在各种任务上的出色表现（包括语言处理任务）而受到关注。通过训练数十亿参数，这些模型能够理解和掌握任务。", "innovation": "DKG-LLM框架通过集成动态知识图谱（DKG）和Grok 3大型语言模型，提出了一种创新的方法来实现医学诊断和个人化治疗建议。该框架使用适应性语义融合算法（ASFA）动态生成由15,964个节点和127,392条边的知识图谱。ASFA利用先进的概率模型、贝叶斯推断和图优化来提取语义信息，更新知识图谱，并保持可扩展性。实验证明，DKG-LLM的诊断准确率为84.19%，治疗建议准确率为89.63%，语义覆盖率为93.48%，表明该模型能够处理噪声数据和复杂多症状疾病，并且可以从医师反馈中进行基于反馈的学习。", "conclusion": "DKG-LLM是一个可靠且具有革新性的工具，能够应对噪声数据和复杂多症状疾病，并通过基于反馈的学习提升模型性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06388", "html_url": "https://arxiv.org/abs/2508.06388", "title": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing", "title_en": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing", "authors": "Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He", "background": "该研究发现，尽管大型语言模型（LLMs）在单独的故事情节扮演和提供情感支持方面表现出色，但结合这两种能力，以虚拟角色提供情感支持的交互尚存在研究缺口。传统的情感支持角色扮演数据集缺乏明确角色个性的虚拟角色和充足的用户标注，因此本文通过动漫人物作为案例进行了专门的数据集收集和评估研究。", "innovation": "本文提出了一种名为ChatAnime的数据集，是第一个用于情感支持角色扮演（ESRP）的动漫角色数据集。它通过精心挑选20个热门动漫角色，设计了一系列情感中心的真实场景问题，并通过全国性的筛选过程确定了40名有特定角色知识和扮演经验的中国动漫爱好者。此外，该研究系统性地收集了10个LLM和这40名动漫爱好者两轮对话数据。评估体系采用了9个细粒度的指标，评估了LLM在基本对话、角色扮演和情感支持上的表现以及回应多样性。研究表明，顶级的LLM在角色扮演和情感支持方面超过了人类爱好者，而在响应多样性方面，人类仍然领先。", "conclusion": "研究表明，顶级的LLM在角色扮演和情感支持方面超过了人类爱好者，而在响应多样性方面，人类仍然领先。本研究希望为未来优化LLM在情感支持角色扮演方面提供宝贵的数据资源和见解。该数据集可以在该网址获取：[提供的网址]。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06418", "html_url": "https://arxiv.org/abs/2508.06418", "title": "通过潜空间多面体量化MCP中的对话偏移", "title_en": "Quantifying Conversation Drift in MCP via Latent Polytope", "authors": "Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang", "background": "MCP通过将外部工具整合到大型语言模型中，实现了动态实时数据的聚合，提高了任务执行效率。然而，MCP的非隔离执行上下文也带来了严重的安全和隐私风险，如恶意内容引发的工具污染或间接提示注入，可能导致对话劫持、误导信息传播或数据泄露。现有的防御措施，如基于规则的过滤或基于LLM的检测，仍然存在依赖静态签名、计算效率低下以及无法量化对话劫持的问题。", "innovation": "SecMCP提出了一种新的安全框架，用于检测和量化对话偏移，通过建模LLM激活向量在潜空间多面体空间中的变化，SecMCP能够识别对话动态中的异常变化，从而主动检测劫持、误导和数据泄露。SecMCP在三种最先进的LLM（Llama3、Vicuna、Mistral）上跨多个基准数据集（MS MARCO、HotpotQA、FinQA）进行了评估，显示了高鲁棒性的检测性能，AUC ROC得分超过0.915，并且系统易用性良好。SecMCP的贡献包括系统地分类MCP安全威胁，提出了一种新的潜空间多面体方法来量化对话偏移，以及实验证明SecMCP的有效性。", "conclusion": "SecMCP通过潜空间多面体建模LLM激活向量的变化，有效检测和量化了对话偏移，提高了系统的安全性，特别是在高级安全威胁下的性能，同时保持了系统的可用性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06447", "html_url": "https://arxiv.org/abs/2508.06447", "title": "SlimInfer: 通过动态令牌剪枝加速长上下文LLM推理", "title_en": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning", "authors": "Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang", "background": "长期上下文推理对于大型语言模型（LLMs）来说，受到高计算需求的限制。尽管已有许多方法优化了注意力计算，但它们仍然处理每一层的完整隐藏状态集，从而限制了整体效率。", "innovation": "本文提出了SlimInfer，一个加速推理的创新框架。该框架直接在前向传播过程中剪枝非关键提示词，以减少冗余。SlimInfer引入了一种动态的细粒度剪枝机制，能够准确地在中间层去除隐藏状态中的冗余词元。这种逐层剪枝可以自然地启用异步KV缓存管理器，在无需复杂预测器的情况下预取所需的词块。该方法减少了内存使用和I/O成本。", "conclusion": "广泛的实验表明，SlimInfer在单个RTX 4090上实现了LLaMA3.1-8B-Instruct高达2.53倍的时间至首个令牌速度提升和1.88倍的端到端延迟减少，同时不会牺牲LongBench上的性能。代码将在接收后开源。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回响：新闻制作中LLM使用日益增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "生成式人工智能（GenAI），特别是大型语言模型（LLMs），迅速崛起，对新闻业的 journalistic integrity 和 authorship 造成了担忧。本文研究了这些模型在新闻媒体中的应用，分析了超过40,000篇来自各大、地方和高校媒体的新闻文章。研究采用了三种先进的AI文本检测器进行评估，发现近年来GenAI在新闻中的使用显著增加，尤其是在地方和高校媒体中。通过句子级分析，发现LLMs常用于新闻的开头部分，而结论通常由人工撰写。语言分析结果显示，GenAI的使用提高了文本的词汇丰富度和可读性，但降低了形式化程度，导致写作风格更加统一，尤其是在地方媒体中表现出更为明显的特点。", "innovation": "本文利用了三种先进的AI文本检测器来追踪和分析GenAI在新闻中的使用情况，涵盖多个媒体平台，还进行了细致的句子级分析，揭示了LLMs在新闻中的具体应用变化。这些研究工具提供了对GenAI在新闻领域影响的深入洞察，弥补了现有研究在监测和理解GenAI应用方面的不足。", "conclusion": "本文通过大量的实证数据分析，表明GenAI正在新闻制作中扮演越来越重要的角色。虽然增强了内容的丰富性和可读性，但降低了写作的正式性和独特性，尤其是在地方新闻中更为显著。这些问题对于新闻业的专业程度和作者身份验证提出了新的挑战，需要行业各方共同努力应对。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04748", "html_url": "https://arxiv.org/abs/2508.04748", "title": "AttriLens-Mol：利用大型语言模型进行分子属性预测的特征导向强化学习", "title_en": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models", "authors": "Xuan Lin,Long Chen,Yile Wang", "background": "大型语言模型（LLMs）在分子属性预测任务中显示出潜力，但通常依赖人工设计的提示和链式思考模板。尽管最近的一些先进推理模型如DeepSeek-R1利用强化学习扩展了“思考”过程，但它们的推理可能会变得冗长且缺乏相关性。", "innovation": "本文提出了AttriLens-Mol，这是一种基于属性的强化学习框架，通过使用结构奖励、计数奖励和理性奖励来引导LLMs的推理，从而在分子属性预测中更有效地利用模型的内在知识，同时提高预测结果的可解释性和性能。实验结果表明，使用AttriLens-Mol方法训练R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型在4000个样本上的性能显著提升，且在可解释决策树模型中提取的特征表现出更优的性能。", "conclusion": "AttriLens-Mol 有效地提取了更多相关且预测性强的分子属性特征，从而提高了属性预测的可解释性和性能。我们已在GitHub上发布了代码。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06482", "html_url": "https://arxiv.org/abs/2508.06482", "title": "通过习俗形成提升训练后高效沟通", "title_en": "Post-training for Efficient Communication via Convention Formation", "authors": "Yilun Hua,Evan Wang,Yoav Artzi", "background": "人类在多轮对话中通过调整语言和形成临时规则来提高沟通效率。相比之下，现有的预训练语言模型（LLM）并不自然地展现出这种行为。本文旨在通过特定微调，使LLM能够模仿人类的学习模式，逐步提高在多轮对话中的常规形成能力。为此，作者设计了两个新的基准测试，以评估模型在形成有效沟通中习俗使用的能力。", "innovation": "作者开发了一种后训练过程，该过程通过对启发式识别出的常规形成示例进行目标化的微调，来增强LLM的认知能力。两个新的基准测试被设计用于评估模型在形成有效沟通中的常规使用能力。第一个基准测试被称为聚焦的认知动机交互基准，能够持续从人类对话中引发强大的常规形成趋势。第二个基准测试是一个文档为基础的参考完成任务，反映了现实世界中的常规形成行为。这些研究结果显示，经过训练的LLM在两个评估方法中的常规形成能力显著提高。", "conclusion": "经过训练的LLM在常规形成能力上取得了显著的进步，这一研究结果证明了通过后训练增强LLM适应自然语言对话中习俗使用的可行性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05668", "html_url": "https://arxiv.org/abs/2508.05668", "title": "基于大型语言模型的深层搜索代理：范式、优化、评估和挑战", "title_en": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "authors": "Yunjia Xi,Jianghao Lin,Yongzhao Xiao,Zheli Zhou,Rong Shan,Te Gao,Jiachen Zhu,Weiwen Liu,Yong Yu,Weinan Zhang", "background": "大型语言模型（LLMs）的兴起显著改变了网络搜索。基于LLM的搜索代理标志着信息寻求方式的重大转变，体现为更深、更动态、更自主的信息搜索。这些代理能够理解用户意图和环境背景，并执行多轮检索和动态规划，扩展了搜索能力远远超越了单纯的网络搜索。领先的例子如OpenAI的Deep Research展示了其在深度信息挖掘和实际应用中的巨大潜力。", "innovation": "本论文首次系统分析了基于大型语言模型的搜索代理的研究。从架构、优化、应用和评估等多个角度进行全面分析和分类，识别出关键的研究缺口，并概述了这一快速演变领域的未来研究方向。", "conclusion": "本调查揭示了基于大型语言模型的搜索代理面临的重大挑战，并指出了未来研究的潜力方向。相关研究资料可在此网址下载：https://xxxxx."}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06471", "html_url": "https://arxiv.org/abs/2508.06471", "title": "GLM-4.5: 推理和代理基础模型", "title_en": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models", "authors": "GLM-4.5 Team:Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai", "background": "本文介绍了一个名为GLM-4.5的开源Mixture-of-Experts（MoE）大型语言模型，该模型具有355亿个总参数和32亿个激活参数。GLM-4.5通过多阶段训练和后训练增强，实现了在各类任务上的优秀表现。GLM-4.5结合了混合推理方法，支持思考和直接响应模式。该模型在多任务评估中的表现良好，如TAU-Bench的70.1%，AIME 24的91.0%，以及SWE-bench Verified的64.2%。尽管参数比某些竞争对手少，但GLM-4.5仍然在所有评估模型中排名第三，在代理基准测试中排名第二。", "innovation": "GLM-4.5采用了混合推理方法，结合了思考和直接响应模式的支持。该模型通过多阶段训练以及专家模型迭代和强化学习的综合后训练，获得了显著的性能提升，特别是在代理能力（agentic）、推理和编程（ARC）任务上。GLM-4.5通过较少的参数实现了强大的性能，在某些领域超越了一些参数更多的竞争对手。", "conclusion": "GLM-4.5和其紧凑版本GLM-4.5-Air（106B参数）被开发出来以促进推理和代理AI系统的研究。查代码、模型和更多信息，请访问：[提供的链接]。GLM-4.5及其实验数据对研究具有重要价值，旨在推进相关领域的深入理解和发展。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05664", "html_url": "https://arxiv.org/abs/2508.05664", "title": "增强电力行业客户服务的检索增强生成", "title_en": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "authors": "Hei Yu Chan,Kuok Tou Ho,Chenglong Ma,Yujing Si,Hok Lai Lin,Sa Lei Lam", "background": "许多AI客户服务系统使用标准NLP流程或微调的语言模型，这些模型在处理模糊、多意图或详细查询时常常表现不佳。该研究旨在评估一系列技术：查询重写、RAG融合、关键词增强、意图识别和上下文重排名，以构建电力领域的稳健客户服务系统。研究对比了向量存储和图基RAG框架，最终选择图基RAG因为其在处理复杂查询方面表现出更优的性能。", "innovation": "研究引入了查询重写、RAG融合、上下文重排名和意图识别技术来提升客户服务系统的性能。特别是通过使用图基RAG，该系统在复杂查询处理上表现优异，并通过这些技术改进了查询检索，提高了系统的准确性和效率。", "conclusion": "最终系统结合了意图识别、RAG融合和上下文重排名，能够有效地处理歧义和多源查询。在基于GPT-4生成的数据集和真实电力提供商的FAQ数据集上的测试中，该系统分别达到了97.9%和89.6%的准确率，显著优于基线RAG模型。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05798", "html_url": "https://arxiv.org/abs/2508.05798", "title": "基本交互式算法：前瞻", "title_en": "Basic interactive algorithms: Preview", "authors": "Yuri Gurevich", "background": "算法的概念在1930年代至1950年代得到阐明，并在25年前通过'序列算法'或'经典算法'的形式进行了形式化。近年来，算法的定义已经扩展到包括概率算法、量子算法等，这促使对Church-Turing论题进行更广泛的诠释，即'物理论题'。文章讨论了这两版Church-Turing论题的区别，并展示了不确定性与概率算法可以视为具有适当预言机的基本算法的方法。同理，量子电路算法和其他类型算法也可以从相似的视角进行理解。", "innovation": "文章提供了一个前瞻，对基本交互式算法进行了形式化，并对比了两个版本的Church-Turing论题。它强调了概率和非确定性算法可以被视为具有适当预言机的基本算法的观点，并将这种观点扩展到量子电路算法和其他类型的算法。", "conclusion": "每一种基本算法都有一个与其行为等价的抽象状态机表示。文章探讨和阐述了新的算法形式化定义，并强调了使用适当预言机的基本算法的概念，这对于理解和处理现代算法至关重要。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05669", "html_url": "https://arxiv.org/abs/2508.05669", "title": "针对马来西亚审计财务报告中财务表格的Markdown转换精细调优视觉语言模型", "title_en": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "authors": "Jin Khye Tan(Faculty of Computer Science and Information Technology, Universiti Malaya),En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah", "background": "从财务文档中准确提取和表示表格结构仍然是文档理解的关键挑战，特别是在监管和分析应用场景中。本研究专注于将马来西亚审计财务报告中的财务表格转换为Markdown格式，任务复杂性包括旋转布局、多级表头和隐式结构提示等挑战。", "innovation": "本文提出了一种基于Qwen2.5-VL-7B的视觉语言模型（VLM），该模型经过精细调优，专门用于从文档图像生成高保真Markdown。研究包括一个由2152个图像-文本对组成的制作数据集，以及使用LoRA的监督式微调策略。性能评估采用双框架标准：基于LLM的细粒度准确性和基于Markdown树编辑距离的相似性测度（TEDS）评价指标。研究结果表明，该模型在基于标准的评估中总体准确率为92.20%，Markdown TEDS得分为96.53%，显著超越基模型、更大规模的VLM和专业推理增强模型。此外，相比自托管替代方案，其推理时间显著减少。此外，其准确率超过了广泛使用的开源模型，如OpenAI的GPT-4o和Gemini 2.5 Flash。", "conclusion": "研究结果表明，针对特定领域的精细调优为桥接非结构化财务文档和下游自动化提供了一种有效且高效的方法，可以媲美大型且通用的模型，而无需巨大的计算成本。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06017", "html_url": "https://arxiv.org/abs/2508.06017", "title": "智能编码系统应当生成带有解释的程序", "title_en": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "authors": "Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang", "background": "智能编码系统通过自然语言让用户体验编程行为，提高了软件开发效率。然而，这些系统依赖AI的决策过程不够透明，可能导致信任和使用方面的问题，尤其是对于非专业人士。因此，该文提出智能编码系统不仅需要生成代码，还需提供清晰、一致的解释，以连接模型推理和用户理解，增强系统的透明度和信任度。", "innovation": "作者识别出认知对齐和语义忠实性这两个关键解释属性，并指出现有技术（如形式验证、静态分析和事后解释）存在局限性。研究者建议探索神经符号方法，其中包括符号约束指导模型训练行为，并通过神经表示丰富程序语义，实现在推理阶段的自动一致性检查。", "conclusion": "本文强调智能编码系统应不仅生成代码，还应生成解释，通过提高解释的质量和透明度，增强AI在软件开发中的信任和用户友好性，并呼吁探索新的神经符号方法，以有效解决这些挑战。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05731", "html_url": "https://arxiv.org/abs/2508.05731", "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "title_en": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "authors": "Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu", "background": "多模态大型语言模型（MLLMs）的发展推动了能够通过纯视觉输入在图形用户界面（GUIs）上操作的自主代理的发展。这些代理需要准确的空间对齐和语义对齐。强化学习结合可验证奖励（RLVR）在提高MLLM的空间对齐方面已被证明是有效的，但效率低下的探索瓶颈限制了语义对齐的学习，防止模型掌握复杂的语义关联。", "innovation": "本研究提出了一种新的策略优化框架Adaaptive Exploration Policy Optimization（AEPO），该框架采用多答案生成策略来促进更广泛的探索，并由源自效率基本原则的有理论依据的Exploration Reward（AER）函数引导。与基于RLVR的基准模型相比，AEPO训练的模型InfiGUI-G1-3B和InfiGUI-G1-7B在多个挑战性GUI对齐基准测试中建立了新最佳结果，实现了高达9.0%的相对改进，特别是在测试泛化能力和语义理解的基准测试中。", "conclusion": "通过引入AEPO，模型在多个复杂GUI对齐基准测试中取得了显著改进，特别是在测试泛化能力和语义理解的基准测试中，相较于基于RLVR的基准模型实现了显著的相对改进。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05835", "html_url": "https://arxiv.org/abs/2508.05835", "title": "NanoCodec：朝着高质量超快速语音LLM推理", "title_en": "NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference", "authors": "Edresson Casanova,Paarth Neekhara,Ryan Langman,Shehzeen Hussain,Subhankar Ghosh,Xuesong Yang,Ante Jukić,Jason Li,Boris Ginsburg", "background": "大型语言模型（LLMs）通过利用音频编解码器将音频离散化成token，大幅提升了音频处理能力，使得语言模型技术可以应用于语音数据。然而，现有的音频编解码器通常以高帧率运行，这导致训练和推理速度较慢，特别对于自回归模型而言。为了解决这一问题，低帧率音频编解码器越来越受到关注，它们减少了生成一秒钟音频所需的自回归步骤。然而，这种编解码器的效果一直不高。因此，需要进一步研究如何在保持高质量压缩的同时减少帧率，以满足低延迟和高效语音LLM训练和推理的需求。", "innovation": "本文通过对帧率、比特率和因果性的影响进行消融研究，提出了NanoCodec，这是一种最先进的音频编解码器，以12.5帧每秒（FPS）的帧率实现了高质量压缩，并在各种比特率范围内超过了现有方法。NanoCodec打破了低延迟和高效语音LLM训练与推理的新基准，从而显著加速了训练和推理速度，同时也保证了音频质量。", "conclusion": "通过引入NanoCodec，本文展示了在保持高质量压缩的同时，如何通过低帧率编解码器显著提高语音LLM的训练和推断效率，为语音数据处理和语言模型应用提供了新的方案。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05671", "html_url": "https://arxiv.org/abs/2508.05671", "title": "DINA: 一个对抗内部噪声和外部攻击的双防护框架在自然语言处理中的应用", "title_en": "DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing", "authors": "Ko-Wei Chuang,Hen-Hsen Huang,Tsai-Yen Li", "background": "随着大型语言模型（LLMs）和生成型AI在客户服务和内容审核等应用中的日益普及，出现了一系列来自外部操纵和内部标签篡改的对抗威胁。本文识别并系统地应对了这些双重对抗威胁，特别是在自然语言处理（NLP）领域提出了创新的统一框架DINA（Dual Defense Against Internal Noise and Adversarial Attacks），以同时缓解内部标签破坏和外部对抗干扰。", "innovation": "DINA框架结合了来自计算机视觉领域的先进噪声标签学习方法，并将其与对抗训练相结合，以同时减轻内部标签破坏和外部对抗干扰。本研究通过在实际在线游戏服务数据集上的广泛实验，证明DINA在模型稳健性和准确性方面显著优于基线模型。", "conclusion": "本研究不仅突出了双重威胁防御的必要性，还提供了实现NLP系统在实际对抗场景中安全防护的实用策略，强调了更广泛负责任的AI部署的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06065", "html_url": "https://arxiv.org/abs/2508.06065", "title": "ThematicPlane: 框架平面：弥合隐性用户意图与潜在空间之间的差距以生成图像", "title_en": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "authors": "Daniel Lee,Nikhil Sharma,Donghoon Shin,DaEun Choi,Harsh Sharma,Jeonghwan Kim,Heng Ji", "background": "生成式AI使得图像创作更加便捷，但要在生成结果中实现细腻创意意图仍然困难，尤其对于非专业人士来说。现有工具通常需要用户通过提示或参考资料来外化他们的想法，这限制了创意的流畅探索。为此，本文探讨了如何通过一个结合高层次语义概念（如情绪、风格或叙述基调）的交互式框架平面来弥合隐性创意意图与生成系统控制之间的差距。该接口通过提供如何将概念映射到生成结果的透明控制，帮助用户实现表达性和迭代性的工作流程，从而为生成设计工具有机交互提供了新的方向。", "innovation": "ThematicPlane系统允许用户在交互式主题设计平面上导航和操作高层次语义概念。该系统旨在解决现有工具要求用户通过提示或参考资料外化想法所导致的创意流畅度不足的问题。通过研究发现，该系统能够支持发散和收敛的创意模式，使用户能够接受意外的结果作为灵感或迭代的提示。虽然用户在熟悉的主题中进行探索，但对于主题如何映射到生成结果的不同预期表明控制需要更具可解释性。", "conclusion": "ThematicPlane促进了一种表达性和迭代性的工作流程，并强调了生成设计工具中直观的语义驱动交互的新方向。未来研究应进一步优化控制的可解释性，以更好地满足用户需求。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05954", "html_url": "https://arxiv.org/abs/2508.05954", "title": "Bifrost-1: 使用Patch-level CLIP潜变量连接多模态LLMs和扩散模型", "title_en": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "authors": "Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal", "background": "目前，人们越来越注重在不牺牲大规模语言模型（LLMs）的强大推理能力的情况下，将高保真视觉合成功能整合到LLMs中。现有直接训练LLMs或连接LLMs和扩散模型的方法，由于基础LLMs在预训练期间没有见过图像表示，因此训练成本高昂。因此，作者提出了一种统一框架Bifrost-1，该框架利用.patch-level CLIP图像嵌入作为潜变量，将预训练的多模态LLMs（MLLMs）和扩散模型连接起来，这些嵌入是本机与MLLM的CLIP视觉编码器对齐的。这些嵌入通过轻量级的ControlNet调整整合到扩散模型中。为了保留MLLM原始的多模态推理能力，作者在预测.patch-level图像嵌入时，为MLLM配备了从原始MLLM参数初始化的视觉生成分支。通过无缝整合预训练的MLLM和扩散模型以及.patch-level CLIP潜变量，该框架实现了高保真可控的图像生成，并显著提高了训练效率。实验结果显示，Bifrost-1在视觉真实性和多模态理解方面与以前的方法相当或更好，训练过程中计算量大大减少。作者还进行了全面的消融研究，证明了其设计选择的有效性。", "innovation": "Bifrost-1是一种新的框架，通过.patch-level CLIP潜变量连接预训练的多模态LLMs（MLLMs）和扩散模型，实现了高保真可控图像生成，并具有显著的训练效率。借助这种方式，MLLM和扩散模型之间实现了无缝集成，保留了原始多模态推理的能力，同时提高了视觉理解和生成的真实度。该方法相比现有技术，能够以更低的计算成本实现更好的视觉效果和多模态理解。本研究选项的有效性得到了全面的消融研究的支持。", "conclusion": "Bifrost-1框架通过.patch-level CLIP潜变量有效地整合了预训练的多模态LLMs和扩散模型，实现了高保真可控图像生成，并且在训练效率上显著优于现有方法。其主要贡献在于通过轻量级调整ControlNet和初始视觉生成分支，确保了MLLM原始多模态推理能力的同时，减少了训练成本。未来的工作可以进一步探索不同类型的预训练LLMs和扩散模型的整合能力，以及更复杂的多模态生成任务。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06457", "html_url": "https://arxiv.org/abs/2508.06457", "title": "ScamAgent们：AI代理如何模拟人类级别的诈骗电话", "title_en": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "authors": "Sanket Badhe", "background": "大型语言模型（LLMs）展现了出色的流畅性和推理能力，但其潜在的滥用风险引起了广泛关注。现有的LLM安全性护栏，例如拒绝机制和内容过滤器，对基于代理的威胁效果有限。甚至有较强提示级安全保障的模型，在提示被分解、伪装或在代理框架内分阶段传递时，也可能被绕过。当前的研究重点在于单次提示滥用，而ScamAgent是一种自主的多轮对话代理，可以生成高度逼真的诈骗电话脚本，模拟现实中的诈骗场景，并且能够动态适应模拟的用户反应，使用欺骗性说服策略，跨越多轮对话。这些虚假代理绕过了许多现有的安全措施，揭示出多轮对话安全审计的重要性，亟需开发代理级别的控制框架以及新的方法来检测和阻止生成式AI背后的对话欺诈行为。", "innovation": "ScamAgent是基于LLMs的自主多轮对话代理，能够生成高度逼真的诈骗电话脚本，并展示了一种新的策略：动态对话记忆、策略性回答模拟用户反应，以及使用欺骗性说服策略。此外，还通过现代语音合成系统将诈骗脚本转化为真实的声音电话，形成一个完整的自动化诈骗流程。现有的安全性护栏，包括拒绝机制和内容过滤器，对ScamAgent这种基于代理的威胁效果不佳，表明多轮对话安全审计和代理级别的控制框架的新需求。", "conclusion": "研究揭示了当前基于LLM的安全性护栏对基于代理的诈骗威胁的有效性不足，强调了多轮对话安全审计、代理级别控制框架和检测对话欺诈的新方法的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06492", "html_url": "https://arxiv.org/abs/2508.06492", "title": "改进MLLM图表理解的有效训练数据合成", "title_en": "Effective Training Data Synthesis for Improving MLLM Chart Understanding", "authors": "Yuwei Yang,Zeyu Zhang,Yunzhong Hou,Zhuowan Li,Gaowen Liu,Ali Payani,Yuan-Sen Ting,Liang Zheng", "background": "有效阅读科学图表是构建有效科学代理的关键。然而，现有的多模态大型语言模型（MLLMs），尤其是开源模型，在具有挑战性的基准测试上的成功率仅为30%-50%。以往对MLLMs进行微调的研究往往受限于它们产生的合成图表与真实图表的不足相似性，这可能会影响模型训练和在复杂真实世界图表上的性能。", "innovation": "我们展示了一种通过模块化图表生成和多样化视觉细节来提高图表理解能力的方法。特别地，我们设计了一个五步数据合成管道，包括分离数据和函数创建以生成单个图表，针对早期生成的图表来条件生成后续子图表，视觉上多样化生成的图表，过滤低质量数据，最后使用GPT-4o生成问题-答案（QA）对。这种方法使我们能够简化微调数据集的生成，并引入了有效的图表数据集（ECD），该数据集包含10000多张图表图像和300000多个QA对，涵盖了25个主题，具有250多种图表类型组合和高视觉复杂度。ECD能够在多种真实世界和合成测试集上一致提高各种MLLMs的性能。", "conclusion": "ECD有效提高了各种MLLMs在真实世界和合成测试集上的表现。相关代码、数据和模型可在指定链接处获取。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.17008", "html_url": "https://arxiv.org/abs/2402.17008", "title": "在语义重叠总结任务上基准测试LLMs", "title_en": "Benchmarking LLMs on the Semantic Overlap Summarization Task", "authors": "John Salvador,Naman Bansal,Mousumi Akter,Souvika Sarkar,Anupam Das,Shubhra Kanti Karmaker(\"Santu\")", "background": "语义重叠总结(SOS)是一种受限的多文档总结任务，其中约束条件是从两个替代叙述中捕捉共同/重叠的信息。本文对多种大型语言模型(LLMs)在SOS任务上的表现进行了基准测试研究。为此，作者引入了PrivacyPolicyPairs (3P)数据集，用以扩展SOS基准测试的数据数量和多样性。", "innovation": "作者通过3P数据集在两个不同领域的SOS数据集上生成并评估了905,216个独特的LLM生成的摘要，并进行了一部分样本的人工评估以分析模型性能和自动评估的可靠性，这是对SOS任务基准测试的重要贡献。", "conclusion": "文章通过分析模型性能和自动评估的可靠性来总结结果，并且研究使用的代码和数据集中于此网站：给出的链接。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05913", "html_url": "https://arxiv.org/abs/2508.05913", "title": "伦理AI原则对用户重要吗？一项大规模的用户情感与满意度分析", "title_en": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "authors": "Stefan Pasch,Min Chul Cha", "background": "随着AI系统越来越多地嵌入组织工作流程和消费者应用，公平、透明和稳健等伦理原则已在政策和行业指南中得到了广泛认可。然而，关于这些原则在用户层面是否被认可、重视或产生影响，仍然缺乏实证证据。本研究通过分析来自G2的超过100,000个AI产品用户评论，研究伦理AI与用户满意度之间的关系。", "innovation": "本研究使用基于变压器的语言模型测量了由欧盟伦理AI指南定义的七个伦理维度的情感。研究发现所有七个维度都与用户满意度正相关。而且，这一关系在用户角色和产品类型之间系统性地有所不同。技术用户和AI开发平台的评论者更多地讨论系统级的问题（如透明度、数据治理），而非技术用户和终端应用的评论者则强调以人为本的维度（如人类自主权、社会福祉）。此外，伦理AI与用户满意度之间的联系在所有维度上对非技术用户和终端应用显著更强。这些结果突显了从用户视角设计伦理AI的重要性，并强调了根据不同用户角色和产品类型考虑背景差异的必要性。", "conclusion": "研究结果强调了从用户视角设计伦理AI的重要性，并突显了根据不同用户角色和产品类型考虑背景差异的必要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06435", "html_url": "https://arxiv.org/abs/2508.06435", "title": "跨语言主题而非语言学习：LLM如何在多种语言中分类在线移民言论", "title_en": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages", "authors": "Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain", "background": "大语言模型（LLMs）正在通过支持大规模和精确的分析来改变社会科学的研究。这种模型的适应性引发了关于在几种语言中进行微调获得的知识能否转移到预训练期间未见的新语言中的问题。为了研究这一问题，该研究对轻量级的LLaMA 3.2-3B模型进行微调，使用单语、双语或多语数据集来分类推特上的移民相关帖子，这些帖子涉及13种语言，一个以两极化和文化特定话语为特征的领域。研究评估了最少的语言特定微调是否能够实现跨语言主题检测，以及增加特定语言是否能够纠正预训练偏见。结果显示，一个或两个语言的微调可以可靠地分类未见语言的移民相关内容。然而，判断一条推文是表示支持还是反对移民立场需要多语言微调。预训练偏见倾向于主流语言，但即使在微调过程中接触少量未充分代表的语言（仅为原始预训练标记体积的9.62×10⁻¹¹），也会产生显著的改进。这些结果挑战了跨境掌握需要大量的多语言训练的假设：有限的语言覆盖足以进行主题级别的概括，结构性偏见可以通过轻量化干预得到纠正。", "innovation": "研究通过使用轻量级的LLaMA 3.2-3B模型针对单语、双语或多语数据集进行微调，实现了移民相关话题的跨语言分类。该研究还评估了最少的语言特定微调和增加特定语言在纠正预训练偏见方面的效果。研究发现，即使接触到很少量的未充分代表的语言，也能显著改善性能。此外，通过发布4-bit-量化、LoRA微调模型，研究提供了开源、可重复的替代解决方案，该模型在推理速度上比OpenAI GPT-4o快35倍，且成本仅为0.00000989%。这提供了一种实现可扩展、包容性研究的途径。", "conclusion": "研究结果表明，大语言模型在某些情况下可以仅通过少量语言特定微调就能实现跨语言主题检测。这挑战了需要多语言训练以实现跨境掌握的传统观念。结构偏见可以通过轻量级的干预措施来纠正。此外，通过提供开源、可重复的微调模型，研究为实现可扩展和包容性研究提供了新的途径，特别是在成本和速度方面具有显著优势。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.11827", "html_url": "https://arxiv.org/abs/2409.11827", "title": "Extract-and-Abstract: 在单一编码器-解码器框架内统一抽取性和抽象性总结", "title_en": "Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework", "authors": "Yuping Wu,Hao Li,Goran Nenadic,Xiao-Jun Zeng", "background": "抽取-提炼是一种自然而连贯的框架，借助提取模型识别的重要信息来进行抽象性总结。之前采用这种框架的研究训练抽取器和概括器是分开的，并引入额外的参数来突出提取的重要信息，这导致了误差累积和额外的训练成本。", "innovation": "引入了一个无参数的高亮方法到编码器-解码器框架中：用一个显著性掩码替换编码器关注度掩码，在交叉注意力模块中强迫解码器只关注输入的重要部分。提出了新的Extract-and-Abstract范式，即ExtAbs，以一个单一的编码器-解码器模型内同时和无缝地执行抽取性总结和抽象性总结任务，从而减少误差累积。在ExtAbs中，普通的编码器增强了抽取功能，普通的解码器则通过所提出的显著性掩码被修改用于生成摘要。基于BART和PEGASUS的实验在三个数据集上显示，ExtAbs在抽取性任务上的性能优于基线，在抽象性任务上的表现与普通的模型相当或更好。", "conclusion": "ExtAbs通过单一的编码器-解码器模型同时执行抽取性总结和抽象性总结，减少了误差累积并通过使用显著性掩码重新定义了捕捉输入重要信息的方法，从而实现了优越的性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06059", "html_url": "https://arxiv.org/abs/2508.06059", "title": "Fact2Fiction: 针对自主型事实核查系统的定向投毒攻击", "title_en": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System", "authors": "Haorui He,Yupeng Li,Bin Benjamin Zhu,Dacheng Wen,Reynold Cheng,Francis C. M. Lau", "background": "现有的先进事实核查系统通过使用自主的基于大语言模型（LLM）的代理来分解复杂的声明，并逐一验证每个子声明，最终汇总部分结果以生成带有解释性理据的裁定。这些系统的安全性至关重要，因为容易被忽视的事实核查员可能会被利用，以传播错误信息。本文研究了这种自主型事实核查系统的安全威胁。", "innovation": "本文提出了一种名为Fact2Fiction的首个定向投毒攻击框架，专门针对具有代理功能的事实核查系统。Fact2Fiction模仿了这些系统的分解策略，并利用系统生成的理据来构建针对性的恶意证据，从而破坏子声明的验证。实验结果显示，Fact2Fiction在不同投毒预算下，攻击成功率比最新的攻击方法高出8.9%-21.2%。", "conclusion": "Fact2Fiction揭示了当前事实核查系统中的安全弱点，并强调了需要采取防御措施。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.03353", "html_url": "https://arxiv.org/abs/2404.03353", "title": "朝着小型语言模型服务的帕累托最优吞吐量", "title_en": "Towards Pareto Optimal Throughput in Small Language Model Serving", "authors": "Pol G.Recasens,Yue Zhu,Chen Wang,Eun Kyung Lee,Olivier Tardieu,Alaa Youssef,Jordi Torres,Josep Ll. Berral", "background": "大型语言模型（LLMs）在多种自然语言处理任务中取得了最先进的成果。尽管为LLMs提供服务需要大量的计算和内存资源，但小型语言模型（SLMs）的兴起为资源受限的用户提供了一线希望，使他们能够使用先进的性能运行小型模型。研究人员通过实验对SLMs的推断性能和能耗进行了基准测试，展示了SLMs的小内存占用使其在单个加速器的资源范围内实现了帕累托最优吞吐量的新视角。通过模型复制来提高资源利用率改善了SLMs的服务效果的研究成果初现端倪。", "innovation": "研究通过实验对小型语言模型（SLMs）的服务进行基准测试，强调了SLMs的小内存占用使其能够在单个加速器的资源限额范围内达到帕累托最优吞吐量。研究还展示了通过模型复制可以有效提高SLMs资源利用率的初步发现，为小型语言模型服务提出了新的优化方法。", "conclusion": "研究结果表明，通过适当复制较小的模型能够更有效地利用资源，从而改进小型语言模型的服务效率，达到在资源和性能之间的最优平衡。未来的工作将探索进一步的技术细节和实际实施方案，以确保更广泛的资源受限环境也能从小型语言模型中受益。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.11417", "html_url": "https://arxiv.org/abs/2501.11417", "title": "神经上下文强化框架用于逻辑结构文本生成", "title_en": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation", "authors": "Marcus Irvin,William Cooper,Edward Hughes,Jessica Morgan,Christopher Hamilton", "background": "现有的大型语言模型在生成文本时面临着逻辑连贯性和结构一致性方面的挑战，尤其是在处理长范围依赖关系时。虽然已经有一些方法试图解决这些问题，但它们在提升逻辑结构和语义流畅度方面仍然存在局限性。", "innovation": "本文介绍了一种基于神经网络的上下文强化框架，通过结合强化学习原理、自定义奖励函数和动态上下文对齐机制来增强文本的逻辑连贯性和结构一致性。该框架采用了多头注意力层和层次编码模块，能够生成与人类预期的逻辑结构和语义流畅度更为接近的输出。实验结果表明，该框架在各种数据集上的连贯性指标、困惑度降低以及语义对齐方面都显著优于基线模型。", "conclusion": "研究结果显示，最优上下文窗口大小对连贯性结果有显著影响，表明架构灵活性在适应不同语言结构方面的重要性。跨语言性能评估证实了该框架在多种语言下的适应性，同时资源效率分析表明，与传统方法相比，该框架在计算开销方面有所减少，使其更加适合大规模部署。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "通过重置重放实现高效样本的大语言模型优化", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "近年来，通过强化学习（RL）和偏好优化方法改进大语言模型（LLMs）的具体后训练方法取得了显著进展，这些方法对于提升LLMs的推理能力至关重要。然而，这些方法往往存在样本效率低和优先效应偏见的问题，过度拟合初始体验会损害策略质量和学习过程，导致性能下降。本文探讨了现有的偏好优化方法的局限性，尤其是在高重放训练中过度拟合的风险。", "innovation": "本文提出了重置重放（Reset Replay）优化的大语言模型插件（LoRR），旨在提高任何偏好优化框架中的样本效率。LoRR的核心机制为高重放次数提供支持，以最大限度地利用收集到的数据批次。为了应对高重放训练中固有的过度拟合风险，LoRR引入了周期性重置策略并重新利用初始数据，以保持网络的可塑性。此外，LoRR还采用了混合优化目标，结合监督微调（SFT）和偏好损失，进一步增强了数据利用。实验结果显示，LoRR显著提高了各种偏好优化方法在数学推理和通用推理基准上的性能，并在具有挑战性的数学任务上达到了与复杂且计算密集型的RL算法相近的性能，展现出LoRR在LLM微调中的实际、高效和高效益的范式，特别适用于有限数据情况。", "conclusion": "LoRR提供了一种实际、高效且高度有效的LLM微调范式，通过优化偏好优化框架中的样本利用，显著提升了模型性能，特别是针对有限数据情况下的性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.12901", "html_url": "https://arxiv.org/abs/2501.12901", "title": "在大型语言模型中通过上下文分割进行架构融合：参数化知识集成的新型方法", "title_en": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration", "authors": "Offa Kingsleigh,Alfred Abercrombie,David Woolstencroft,Beorhtric Meadowcroft,Marcus Irvin", "background": "传统的参数优化技术存在一定的局限性，尤其是在处理大规模计算模型时。因此，需要一种新的方法来增强计算模型的架构设计，特别是在动态分割参数以适应输入数据的语言特征方面。Contextual Partitioning 方法强调任务特定的专业化，通过自适应的参数分配机制来实现，这与输入数据的语言特征相匹配。", "innovation": "引入了一种创新的方法——上下文分割（Contextual Partitioning），通过动态分割参数并将这些参数分割成上下文感知区域来增强大型计算模型的架构设计。它采用自适应参数分配机制来实现任务特定的专业化，这种方法能够显著提高准确率、困惑度和上下文连贯性，并具有高度的适应性和可扩展性。此外，这种自主操作的方式无需外部微调，解决了传统参数优化技术中的一项重要限制。", "conclusion": "上下文分割不仅简化了模型操作，还扩展了高级语言处理系统的应用范围。实验结果表明该方法有效，能降低内存使用和训练时间，提高生成输出的上下文连贯性和逻辑流畅性。整体而言，这种方法有可能重新定义计算语言架构在不同复杂领域的可扩展性和适应性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00246", "html_url": "https://arxiv.org/abs/2502.00246", "title": "在大型语言模型训练中保持上下文的张量重构", "title_en": "Context-Preserving Tensorial Reconfiguration in Large Language Model Training", "authors": "Larin Tonix,Morgana Baskerville,Nathaniel Stourton,Ophelia Tattershall", "background": "在神经架构中处理长范围依赖关系一直是一个持续的挑战，究其原因在于计算限制以及不良的上下文保留机制。尽管张量操作为重新构建模型表示提供了基础，但传统架构在不引入过度复杂性的情况下很难采用这些技术。", "innovation": "一种新颖的方法，Context-Preserving Tensorial Reconfiguration (CPTR)，通过结构分解和自适应收缩动态重组权重张量，从而增强上下文集成而不造成显著的计算开销。实验评估表明，CPTR在较长序列上增强了上下文相干性保留，减少了困惑度并提高了长语境任务的召回准确性。性能比较显示，增强CPTR模型展示了更高的计算效率和降低的内存消耗，同时保持了竞争力的语言生成流畅性和准确性。梯度稳定性指标进一步验证了改进的训练效率，揭示了更可控的权重更新变化率。横跨基线和增强CPTR模型的研究证实，张量重构提高了语言建模的稳定性和计算效率。", "conclusion": "研究结果支持CPTR在改进当前神经架构中用于需要长范围上下文理解和有效内存利用的任务的可能性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00301", "html_url": "https://arxiv.org/abs/2502.00301", "title": "大型语言模型中的上下文形态发生：一种自我组织的token表示的新方法", "title_en": "Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations", "authors": "Alistair Dombrowski,Beatrix Engelhardt,Dimitri Fairbrother,Henry Evidail", "background": "token表示法影响语言模型的效率和适应能力，但传统的token化策略会施加固定的分隔界限，无法动态调整以适应不断变化的上下文关系。研究引入了上下文形态发生的概念，这是一种自我组织机制，可以根据学习到的上下文依赖关系重新构建token边界，并使嵌入在迭代处理步骤中逐渐进化。在不同语言语料库上的实验表明，动态调整token化在降低困惑度的同时维持了表示稳定性，特别是在那些静态分隔无法捕捉细微依赖关系的复杂语言领域。", "innovation": "提出了上下文形态发生机制，这是一种自我组织的token化方法，可以根据上下文关系动态调整token边界，使得嵌入在处理过程中逐渐进化。这一创新方法展示了其在复杂语言领域中的优势，特别是在静态分割无法捕捉细微依赖关系的情境下。", "conclusion": "稳定性分析证实了演化的token结构在不同文本分布下保持一致性，确保表示适应性语言连贯。在结构稳定性和预测性能上的改进证明了上下文形态发生作为传统token化方法替代方案的可行性。进一步的计算效率分析表明，结合静态和动态分隔技术的混合策略可能提供优化表示灵活性的同时保持推理效率的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.10970", "html_url": "https://arxiv.org/abs/2501.10970", "title": "LLM-as-a-Judge的替代标注测试：如何统计学证明用LLMs替代人类标注员", "title_en": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs", "authors": "Nitay Calderon,Roi Reichart,Rotem Dror", "background": "大型语言模型（LLMs）被用作标注员、裁判员和评估者，承担原本由人类完成的任务。尽管LLM标注在NLP研究和医学、心理学、社会科学研究中有广泛使用，但目前没有标准或严谨的方法来判断LLM是否可以替代人类标注员。因此，本文提出了一种称为“替代标注测试”（alt-test）的新统计方法，仅需少量标注例子即可证明使用LLM标注的有效性。研究还引入了一种灵活且可解释的度量标准，用于比较LLM标注员和裁判员的性能。实验涉及多种语言和视觉-语言任务，多种LLM和不同的提示技术。研究表明，某些闭源LLM（如GPT-4o）有时可以替代人类，而开放源LLM的表现不及闭源LLM，不同的提示技术也会产生不同质量的评判员。本文的研究旨在促进更严谨和可靠的实践方法。", "innovation": "提出了‘交替标注测试’（alt-test）的统计方法，只需要少量标注数据即可验证LLM替代人类的有效性；引入了一种灵活且可解释的度量标准来比较LLM作为标注员和裁判员的性能；实验涉及多种语言和视觉-语言任务，多种LLM和不同的提示技术，展示了某些闭源LLM可以替代人类，同时揭示了不同提示技术对评判质量的影响。", "conclusion": "研究结果表明，尽管LLM可以替代人类标注员，特别是闭源LLM在某些情况下表现优于开放源LLM，但不同的提示技术会影响LLM作为裁判员的质量。本文研究旨在推动更严谨和可靠的LLM替代人类标注的实践。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01979", "html_url": "https://arxiv.org/abs/2502.01979", "title": "Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis", "title_en": "Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis", "authors": "Derek Yotheringhay,Beatrix Nightingale,Maximilian Featherstone,Edmund Worthington,Hugo Ashdown", "background": "生成结构化的文本内容需要机制来确保连贯性、稳定性和对预定义约束的遵守，同时保持语义的一致性。传统的做法往往依赖于基于规则的启发式策略或微调策略，这些方法缺乏灵活性和在多样化任务上的通用性。将Gradient-Regularized Latent Space Modulation (GRLSM)引入到文本生成中，提供了一种新的范式，通过在潜在空间中应用结构约束来引导文本生成。通过基于梯度的正则化，GRLSM减少了潜在表示的突然变化，确保了更平滑的编码过程，从而增强了生成序列中的结构性一致性和逻辑连贯性。", "innovation": "Gradient-Regularized Latent Space Modulation (GRLSM) 是一种新的机制，通过在潜在空间中应用结构约束来引导文本生成。它使用基于梯度的正则化来减少潜在表示的突然变化，确保生成的文本具有更好的结构性一致性和逻辑连贯性，同时保持在大型语言模型中的生成灵活性。", "conclusion": "GRLSM 框架不仅改善了生成文本的结构连贯性，还提高了生成过程的可解释性，使得生成模式更加可预测且可靠。性能评估结果表明，GRLSM 有效地减少了结构上的不一致，同时保持了神经模型固有的生成灵活性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05553", "html_url": "https://arxiv.org/abs/2502.05553", "title": "大型语言模型中通过随机概念嵌入转换进行潜在结构调控", "title_en": "Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions", "authors": "Stefan Whitaker,Colin Sisate,Marcel Windsor,Nikolai Fairweather,Tarquin Goldborough,Oskar Lindenfeld", "background": "在使用静态或确定性嵌入的传统模型中，词元表示受到固定约束，在推理过程中难以进行动态调整。因此，需要一个动态机制来缓解这些约束，提高模型的灵活性和表达能力。", "innovation": "本文提出了一个基于概率机制的转换框架，使得每个词元嵌入通过概率更新动态演变，从而保持语义完整性和适应性。这种方法在词汇多样性、生成连贯性和低频词汇保留方面表现出色，减少了依赖于高概率词元选择的情况。统计分析显示，嵌入层间的变化更加灵活且有连贯性，支持了受控的随机性有助于上下文敏感的表示学习的假设。实验结果表明，尽管存在轻微的计算开销，概率嵌入仍然保持了生成效率，从而在大规模应用中是可行的。", "conclusion": "与传统的嵌入方法相比，随机转换在文本完成精度、对话连贯性和结构复杂性方面取得了可测量的改进，证实了随机转换增强了表示表达能力。嵌入空间中的聚类模式表明，概率更新既保留了有意义的语义分组，又能实现上下文驱动的转变，进一步验证了转换机制的稳定性。性能指标表明，随机变换平衡了适应性和控制性，使生成输出保持语言连贯性，而不过度随机化。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.18826", "html_url": "https://arxiv.org/abs/2501.18826", "title": "结构嵌入投影用于上下文大型语言模型推理", "title_en": "Structural Embedding Projection for Contextual Large Language Model Inference", "authors": "Vincent Enoasmo,Cedric Featherstonehaugh,Xavier Konstantinopoulos,Zacharias Huntington", "background": "结构嵌入变换为提高语言模型推理的效率和连贯性提供了有希望的方法。通过引入结构嵌入投影（SEP），可以通过投影矩阵来细化标记表示，这些矩阵集成了层次性和关系性依赖关系。数学形式化SEP使其嵌入空间能够捕获结构化上下文关系，从而提高语义一致性，且没有显著增加计算开销。", "innovation": "结构嵌入投影SEP通过引入投影矩阵来细化标记表示，这些矩阵集成了层次性和关系性依赖关系，使嵌入空间能够捕获结构化上下文关系，提高了语义一致性，且没有显著增加计算开销。", "conclusion": "实验证明，SEP在多种语言数据集上有助于降低困惑度和增强上下文连贯性，表明它有潜力改善语言模型输出。计算效率评估显示，集成结构嵌入带来了不同数据集之间的推理速度与表示丰富程度之间的权衡。定性分析生成的响应表明，SEP增强了叙述一致性和主题对齐，提高了多句文生成的流畅性。对嵌入层的修改需要精确优化以确保训练动态稳定，因为结构变换改变了传统的表征学习过程。架构调整影响推理延迟和内存消耗，需要在效率增益与额外处理需求之间取得平衡。SEP对该词汇多样性的影响表明，嵌入修改影响了模型的词汇使用，反映了生成词选择的上下文感知性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01872", "html_url": "https://arxiv.org/abs/2501.01872", "title": "自我逻辑反向：通过对比问题探究模型防御", "title_en": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions", "authors": "Rachneet Sachdeva,Rima Hazra,Iryna Gurevych", "background": "尽管大型语言模型经过了广泛的道德和伦理原则对齐，但它们仍然容易受到复杂的安全突破攻击，这些攻击利用了模型的推理能力。现有的安全措施往往能够检测到明确的恶意意图，但无法应对由推理驱动的细微漏洞。", "innovation": "本文提出了POATE（对比矛盾意图生成、对抗模板构建和详述）这一新颖的突破技术，该技术利用对比推理激发不道德的回应。POATE 设计了语义上的相反意图，并将它们与攻击性模板结合，以精妙的手段引导模型生成有害的输出。通过在六个不同参数大小的语言模型家族上进行广泛评估，验证了攻击的稳健性，并在现有方法的基础上达成了显著更高的攻击成功率（约44%）。作为应对措施，本文提出了意图意识链式思考和反向思考链式思考，这两种方法将查询分割以检测恶意意图，并逆向推理以评估和拒绝有害回应，从而增强了推理的鲁棒性并增强了模型防御能力。", "conclusion": "研究结果显示，POATE 在较大规模的语言模型上表现出较高的攻击成功率，并提出了两种新的防御方法来提升模型的安全性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.07124", "html_url": "https://arxiv.org/abs/2502.07124", "title": "大规模语言模型神经元结构重塑以促进差异信息聚合", "title_en": "Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation", "authors": "Denis Bakushev,Gideon Boultinghouse,Harriet Oppenheimer,Sebastian Gillingwater,Valentina Ashington,Wilfred Stanborough", "background": "当前深度学习架构中的信息聚合和专业化不足，需要一个更有效的框架来提高语言模型的能力。传统的神经元封装方法无法有效促进信息的聚合和专业化，导致语言模型在处理复杂任务时表现不佳。", "innovation": "提出了一种结构化神经元封装方法，该方法通过模块化框架增强深学习架构中的信息聚合和专业化。实验表明，通过这种方法修改后的模型在困惑度分数、词汇多样性、逻辑推理一致性方面表现更好。此外，该方法促进了文本生成的灵活性，增强了跨层激活的差异，并减轻了内在语言结构关系中的冲突。", "conclusion": "虽然该结构化封装方法增加了一定的计算开销，但通过优化参数效率和结构化决策过程，总体性能提升显著。数学公理化证实了这种结构化聚合方法不仅保持了收敛性，还能促进神经元群的特定功能角色。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05794", "html_url": "https://arxiv.org/abs/2502.05794", "title": "通过递归符号再生在大规模语言模型表示中的结构性扰动", "title_en": "Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration", "authors": "Kathlyn Eaglewood,Tobias Featherington,Dorian Mayfair,Sylvester Grimshaw,James Pettigrew", "background": "符号扰动提供了一种创新的方法，可以在不直接修改模型参数的情况下影响神经网络的表现。该方法通过递归再生符号结构，在潜在嵌入中引入结构化变异，从而控制注意力动态和序列生成过程中的词汇多样性。与传统的微调技术相比，结构性修改在符号层面上会导致上下文敏感性的显著变化，同时保持整体模型的流畅性和连贯性。通过分析注意力权重分布，研究揭示了符号修改在调整标记依赖性、影响响应的变异性以及改进长篇文本生成中的作用。", "innovation": "该方法通过递归再生符号结构，在不直接修改模型参数的情况下，影响神经网络的表现，引入了潜在嵌入中的结构化变异，从而控制注意力动态和词汇多样性。结构性修改在符号层面上改变了上下文敏感性，同时保持了模型的整体流畅性和连贯性。研究表明，这种改良可以增强模型在特定领域的适应性，而无需重新训练。递归再生改变长距离的标记依赖关系，影响扩展文本序列中的主题一致性。", "conclusion": "实验结果显示，符号扰动可以提高自动生成文本的风格控制能力，使其更适合特定应用。评估语义漂移和词汇变异进一步证明了符号层面上的修改引入了可解释的响应变化，可能使得自动化文本生成的风格调整更加可控。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10699", "html_url": "https://arxiv.org/abs/2502.10699", "title": "在大型语言模型中探索突触共振：一种新的上下文性记忆整合方法", "title_en": "Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration", "authors": "George Applegarth,Christian Weatherstone,Maximilian Hollingsworth,Henry Middlebrook,Marcus Irvin", "background": "大型语言模型在长序列任务中保持上下文连贯性一直是一项高挑战。传统方法，如自我注意机制和具有记忆增强功能的架构，通常重视短期依赖关系，导致长范围上下文理解出现碎片化和不一致的问题。", "innovation": "受生物神经系统的突触可塑性原理启发，提出了一种名为突触共振的新机制，该机制在训练和推理过程中动态加强相关记忆路径。与静态记忆表示不同，这种方法会根据上下文相关性连续调整突触权重矩阵，从而改善信息保留，同时避免过多的计算开销。", "conclusion": "基于开源语言模型的评估表明，该方法能够降低困惑度，增强上下文连贯性，并提高对输入噪声的鲁棒性。与基线模型的对比分析进一步表明，该方法能够实现更高的记忆保留效率，同时保持计算可行性。架构修改可以无缝集成到现有的变压器框架中，确保稳定收敛和高效推理，而不牺牲扩展性。改善长期上下文一致性应用（如对话系统和文档总结）有望从中受益。实证研究结果表明，动态强化的记忆路径提供了一种有前景的替代传统记忆机制的方法，解决长期序列建模中的长期难题。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.16658", "html_url": "https://arxiv.org/abs/2501.16658", "title": "基于上下文增强的多模态 token 压缩技术在大规模语言模型中的应用", "title_en": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models", "authors": "Naderdel Piero,Zacharias Cromwell,Nathaniel Wainwright,Matthias Nethercott", "background": "随着模型规模的扩大，处理复杂多样的数据集变得愈发困难，有效的 token 压缩仍是一个关键挑战。传统的 token 压缩方式难以在节省 token 使用的情况下保持高质量和信息的连贯性。现有方法通常使用静态机制，缺乏动态调整 token 重要性的能力，尤其是在文本和多模态数据之间细微的上下文关系处理上存在不足。因此，研究者提出了一种基于上下文增强的新机制，通过上下文依赖性和语义相关性动态调整 token 重要性，以减少 token 使用量同时保持信息的质量和连贯性。这种方法利用图算法和自适应加权，能够捕捉到文本和多模态数据中的微妙同性关系，确保下游任务中的稳健对齐和性能。实验证明，这一方法在不同领域的精度和语义保留方面取得了显著改进，特别适用于要求详细跨模态交互的任务。内存使用分析显示，该方法在保持高效的同时，能够减轻额外增强过程带来的开销。误差分布分析进一步验证了性能提升，相比基础模型，该方法降低了语义损失和语法不一致性。模块化架构使其能够与各种开源框架兼容，便于在实际应用中进行扩展实施。这些发现突显了上下文增强在重新定义 token 管理策略和推进大规模模型设计方面的潜力。", "innovation": "该研究引入了一种基于上下文增强的新机制，通过动态调整 token 重要性来压缩 token，该机制利用了上下文依赖性和语义相关性。这种方法能显著减少 token 使用量，同时保持高质量的信息表示。此外，该方法结合了图算法和自适应加权，能够准确捕捉文本和多模态数据之间的微妙关系，从而在下流任务中提供稳健的性能。实验证明，这种新机制在不同领域的多模态任务中表现出显著的性能提升，特别是对于需要详细跨模态交互的任务。", "conclusion": "该研究提出了一种基于上下文增强的 token 压缩技术，该技术通过动态调整 token 重要性来有效地减少 token 使用量，同时保持高质量和信息连贯性。利用图算法和自适应加权，该方法能够捕捉微妙的上下文关系，从而在下游任务中实现稳健的性能提升。不同领域的实验证明，该方法显著提高了精度和语义保留。模块化架构使其易于与各种开源框架集成，为实际应用提供了扩展的基础。未来的研究可以进一步探索该技术在更广泛场景中的应用。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01943", "html_url": "https://arxiv.org/abs/2504.01943", "title": "OpenCodeReasoning: 推动竞赛编程数据蒸馏技术的进步", "title_en": "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding", "authors": "Wasi Uddin Ahmad,Sean Narenthiran,Somshubra Majumdar,Aleksander Ficek,Siddhartha Jain,Jocelyn Huang,Vahid Noroozi,Boris Ginsburg", "background": "自基于推理的大语言模型出现以来，人们成功地将推理能力提炼到学生模型中，显著缩小了推理模型和标准大语言模型在编程任务上的差距。不过，大部分推理模型的进步仍被限制在私有数据集的背后，或者缺乏关于数据收集、过滤及后续训练的详细信息。", "innovation": "该论文构建了一个优质的监督微调（SFT）数据集，使用此数据集实现了不同大小模型在多种编程任务上的最先进表现。蒸馏模型仅通过SFT就能在LiveCodeBench上达到61.8%的准确率，在CodeContests上达到24.6%的准确率，这超过了使用强化学习训练的模型。此外，研究还分析了数据源的使用、代码执行过滤的影响，以及指令/解决方案多样性的价值。研究发现，执行过滤会降低基准准确性，因此更重视指令多样性而非解决方案的正确性。最后，分析了这些模型的标记效率和推理模式。", "conclusion": "该论文开源了数据集和蒸馏模型，以供社区使用和进一步研究。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09815", "html_url": "https://arxiv.org/abs/2502.09815", "title": "统计一致性对大规模语言模型表示学习的结合张量场收敛", "title_en": "Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence", "authors": "Jonathan Gale,Godfrey Aldington,Harriet Thistlewood,Thomas Tattershall,Basil Wentworth,Vincent Enoasmo", "background": "表示学习在构建内部嵌入以捕获语言统计特性方面发挥着核心作用，影响生成文本的连贯性和上下文一致性。利用这种内在嵌入生成连贯和一致的文本需要维护统计上存在的依赖性。相关研究提出了一种方法，即统计一致性对齐，通过张量场收敛约束结构化标记嵌入，指导嵌入反映语言数据中存在的统计依赖性。此方法通过数学框架量化一致性对齐，建立损失函数来优化训练迭代中的表示一致性。实验证明，在应用一致性约束条件下，可以提升困惑度，提高分类准确性，并改进稀有词嵌入，从而增强表示空间的稳定性。", "innovation": "提出了统计一致性对齐作为一种基于张量场收敛的方法，用以约束结构化标记嵌入，使其反映语言数据中的统计依赖性。这种方法通过建立量化一致性对齐的数学框架，集成优化表示一致性的损失函数。与基准模型的比较分析显示，所提出的方法促进了一个更具可解释性的内部结构，保障了嵌入保留上下文依赖性并减轻表示崩溃的风险。", "conclusion": "一致性对齐机制增强了不同语言结构的一致性，巩固了学习嵌入的语义完整性，从而实现了更均衡的嵌入组织。尽管此方法增加了一定的计算成本，但其结构优化过程在需要高上下文准确性的应用中是值得的。实验结果证明了统计一致性对齐在优化标记嵌入方面的有效性，提供了如何利用统计依赖性改进语言模型训练的见解。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00977", "html_url": "https://arxiv.org/abs/2502.00977", "title": "长文档摘要中的上下文感知分层合并", "title_en": "Context-Aware Hierarchical Merging for Long Document Summarization", "authors": "Litu Ou,Mirella Lapata", "background": "分层合并是一种常用于总结非常长的文本（超过10万词）的技术，通过将输入拆分成较小的部分，分别总结这些部分，然后合并或结合这些总结，以形成最终的连贯总结。尽管这种方法有助于解决大型语言模型(LLMs)由于固定输入长度限制所带来的局限性，但递归合并过程会放大语言模型的虚构内容，增加事实不准确的风险。", "innovation": "本文提出了一种通过对分层合并过程中的摘要添加来自源文档的上下文信息来减轻虚构内容的方法。具体来说，作者提出了不同的上下文增强方法，包括替换中间总结以相关输入上下文，以及使用上下文作为支持证据来细化这些总结。实验结果表明，基于LLaMA 3.1模型家族的数据集显示，上下文增强在法律和叙述领域中的效果优于零样本和分层合并基准。进一步的分析表明，细化方法与提取性总结结合时表现最佳，用于识别相关输入内容。", "conclusion": "上下文增强的分层合并方法使其成为处理长文档摘要，尤其是在LLM处理长文本时更准确和有效的一种方法。这种方法不仅能够提升总结的准确性和连贯性，还在法律和叙述领域中提供了优于现有基准的性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14119", "html_url": "https://arxiv.org/abs/2501.14119", "title": "使用层次嵌入增强的大语言模型自主结构内存管理", "title_en": "Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation", "authors": "Derek Yotheringhay,Alistair Kirkland,Humphrey Kirkbride,Josiah Whitesteeple", "background": "现有模型架构的革新引入了层次嵌入增强这一方法，通过多层次语义结构重定义令牌表示，从而提升对复杂语言输入的适应性。自主结构内存管理进一步推进了这一范式，通过动态调整内存机制，优先考虑关键上下文要素并抑制不相关的信息，实现了在多样化任务中的高效且可扩展的性能。实验结果表明，通过适应不断变化的上下文需求的内存重组策略，显著提高了计算效率，特别是在处理较长输入序列时大幅度减少了处理开销。层次嵌入不仅提升了上下文对齐，还通过捕捉不同语义粒度的关系，确保跨层级的一致性，同时减少了大量计算冗余。与基准模型的对比分析展示了在准确率、效率和可解释性方面的独特优势，特别是在需要复杂上下文理解和领域特定适应性的任务中表现尤为突出。模型的动态调整能力使其在多样且不可预测的输入条件下表现出强大的鲁棒性。这些进展的应用场景包括多领域泛化、交互系统和实时决策场景等，这类场景传统静态内存架构容易受到限制。该方法结合了高级嵌入和内存管理策略，构建了一个既能应对规模挑战又能保持特定任务相关性的统一框架", "innovation": "引入了层次嵌入增强的概念，通过多层次语义结构重新定义令牌表示，从而提升对复杂语言输入的适应性；提出自主结构内存管理机制，通过动态调整内存机制优先考虑关键上下文要素和抑制不相关的信息，实现了在多样化任务中的高效且可扩展的性能；实验结果展示了在处理较长输入序列时通过内存重组策略大幅度减少处理开销，提高计算效率；层次嵌入不仅提升上下文对齐，还通过捕捉不同语义粒度的关系，确保跨层级的一致性，同时减少了大量计算冗余；与基准模型的对比分析展示了在准确率、效率和可解释性方面的独特优势；动态调整能力确保了在多样且不可预测的输入条件下模型的鲁棒性.", "conclusion": "该方法通过结合高级嵌入和内存管理策略，提供了一个既能应对规模挑战又能保持特定任务相关性的统一框架，并在多个关键方面，如准确率、效率和可解释性上优于传统方法。这一进展尤其适用于需要复杂上下文理解和领域特定适应性的应用场景，如多领域泛化、交互系统和实时决策。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05058", "html_url": "https://arxiv.org/abs/2504.05058", "title": "所有数据并非都能等同删除", "title_en": "Not All Data Are Unlearned Equally", "authors": "Aravind Krishnan,Siva Reddy,Marius Mosbach", "background": "机器卸载关注从训练模型中移除特定数据点所学知识的任务。在语言模型（尤其是大型语言模型LLMs）中，卸载由于隐私问题去除有关命名实体的知识最近受到了更多的关注。尽管提出了一些解决卸载问题的方法，但大多数现有方法均将需要卸载的数据点等同对待，无论数据点是训练城市的名称还是研究者的联系方式。然而，该假设在网络语言模型的卸载中并不总是成立。", "innovation": "研究表明不同频率的数据知识卸载效果不同，更频繁的知识更难卸载。此外，发现了卸载概率评估与基于生成的评估之间的偏差，随着模型规模增大此偏差变得更严重。研究强调了在模型训练数据中考虑评估的重要性，提出了需要更好的评价实践和针对模型训练数据的新方法来改进LLM卸载。", "conclusion": "本研究揭示了网络语言模型卸载的频率依赖性和评估偏差问题，强调了卸载实践中需改进的必要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01996", "html_url": "https://arxiv.org/abs/2503.01996", "title": "One ruler to measure them all: Benchmarking multilingual long-context language models", "title_en": "One ruler to measure them all: Benchmarking multilingual long-context language models", "authors": "Yekyung Kim,Jenna Russell,Marzena Karpinska,Mohit Iyyer", "background": "当前存在一个对多语言长文本文档语言模型进行评估的挑战。现有的基准测试大多以英语为主，缺乏对多种语言在同一平台上的综合评估，特别是在长文档上下文处理能力方面的表现差异。这项研究旨在创建一个名为ONERULER的多语言基准测试，旨在评估26种语言的长上下文语言模型性能。", "innovation": "ONERULER将适应RULER基准测试，通过加入七个合成任务，涵盖检索和聚合测试，特别包括可以无针存在的'针在草堆'任务的新变体。研究通过两步过程创建ONERULER：首先写英文说明，然后与母语者合作翻译成25种其他语言。实验结果显示，随上下文长度从8K到128K增长，低资源语言和高资源语言的表现差距逐渐扩大。此外，许多模型在预测不存在答案时出现错误，即使在资源丰富的语言中也是如此。研究人员还发现了跨语言场景下的性能波动，这取决于指令的语言。", "conclusion": "ONERULER的发布将有助于未来研究改善多语言和跨语言的长文档训练流程。具体结论包括：英语并非长文档任务的最优语言，波兰语表现优异；许多模型在预测不存在答案时存在错误；跨语言场景下的性能波动取决于指令的语言。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.08775", "html_url": "https://arxiv.org/abs/2504.08775", "title": "具有相似深度的层在不同LLM架构中生成相似激活", "title_en": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures", "authors": "Christopher Wolfram,Aaron Schein", "background": "本文探讨了独立训练的LLM（大型语言模型）的潜在空间之间的关系。研究发现，这些潜在空间在同一个模型的不同层之间存在差异，并且在不同模型的对应层之间也存在一定的共性。", "innovation": "研究首次系统地分析了多个开源重量模型在不同层的激活关系，揭示了这些激活关系在不同模型的对应层之间存在共性，但每个模型内部不同层之间激活关系则有所差异。", "conclusion": "研究表明，LLM在其内部层中生成了不同但相似的激活几何结构，并且这种结构在整个模型之间分布得很均匀，虽然不同模型可能会对此进行变形和挤压以适应各自的架构。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16802", "html_url": "https://arxiv.org/abs/2502.16802", "title": "话题优先于源：语言模型预训练中有效数据混合的关键", "title_en": "Topic Over Source: The Key to Effective Data Mixing for Language Models Pre-training", "authors": "Jiahui Peng,Xinlin Zhuang,Jiantao Qiu,Ren Ma,Jing Yu,He Zhu,Conghui He", "background": "大型语言模型（LLMs）的性能受到预训练数据质量及其组成的显著影响，这些数据具有内在多样性，涵盖多种语言、来源和话题。有效地整合这些异质数据组对于优化LLM性能至关重要。以往的研究主要集中在基于来源的数据混合，但往往忽略了数据在话题层面的细微特征。因此，探讨一种基于话题的数据混合策略以填补这一空白变得至关重要。", "innovation": "本文提出了一个基于话题的数据混合策略，通过结合无监督聚类、LLM基总结和监督分类器训练生成详细的话题标签。本文通过该策略首次在多个混合策略和方法上进行了基于话题与基于来源的分区的全面比较，并展示了使用话题混合数据的语言模型在多种方法（包括RegMix、DoReMi、温度基采样和基于下游任务性能的手动混合方法）上的一致性表现优于使用基于来源的数据。理论分析表明，基于话题的数据具有显著更低的验证损失，为模型训练提供更好的优化景观。", "conclusion": "基于话题的数据混合方法在多个方法上表现出优于基于来源的方法的性能，验证损失更低，为模型训练提供了更好的优化景观。本文将开源代码、标注数据集和话题分类模型以推动进一步研究。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07081", "html_url": "https://arxiv.org/abs/2504.07081", "title": "自驱型语言模型", "title_en": "Self-Steering Language Models", "authors": "Gabriel Grand,Joshua B. Tenenbaum,Vikash K. Mansinghka,Alexander K. Lew,Jacob Andreas", "background": "尽管在测试时进行推理使语言模型能够应对复杂的任务，但自然语言中的搜索或规划过程可能速度慢、成本高且容易出错。即使语言模型在某些精确推理步骤上遇到困难，它们通常也能很好地描述问题的抽象结构，包括如何验证解决方案和如何搜索它们。", "innovation": "本文提出了一种名为DisCIPL的方法，这是一种让语言模型‘自我引导’的方法。一种规划模型生成特定任务的推断程序，由一组追随模型执行。此方法赋予语言模型编写递归搜索过程的能力，从而引导LMD推理，提供新的可验证和高效推理形式。实验表明，当与小型追随者（例如Llama-3.2-1B或Qwen3-1.7B）结合使用时，DisCIPL在复杂的受限生成任务上达到了或超过了GPT-4o和o1的性能。", "conclusion": "本文开辟了高性能并行蒙特卡洛推断策略的设计空间，该策略优于标准的最佳N次抽样，不需要微调，且可以通过现有的语言模型自动实现。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18736", "html_url": "https://arxiv.org/abs/2504.18736", "title": "EvidenceBench：从生物医学论文中提取证据的标准数据集", "title_en": "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers", "authors": "Jianyou Wang,Weili Cao,Kaicheng Wang,Xiaoyue Wang,Ashish Dalvi,Gino Prasad,Qishan Liang,Hsuan-lin Her,Ming Wang,Qin Yang,Gene W. Yeo,David E. Neal,Maxim Khan,Christopher D. Rosin,Ramamohan Paturi,Leon Bergen", "background": "在生物医学领域，研究人员在验证科学假说时需要找到相关的实验证据。这一步骤对于科学假说的调查至关重要。当前，用于评估模型在自动寻找相关证据方面性能的标准数据集和评价方法相对缺乏，因此需要一个标准化的数据集来评估和改进相关模型的表现。该研究旨在引入一种新的标准数据集，通过生成假设并逐句标注生物医学论文中的相关证据，旨在评估模型在自动寻找相关证据方面的性能。", "innovation": "该研究引入了EvidenceBench作为一个新的标准数据集，用于评估模型在自动寻找相关证据方面的性能。该数据集通过一个创新的管道生成，包括假设生成和逐句标注相关证据的生物医学论文，完全遵循和忠于现有的人类专家的判断。另外，为了证明该管道的可扩展性，该研究创建了一个更大的EvidenceBench-100k数据集，包含107,461篇完全标注的论文，具有相应的假设，以帮助模型的训练和发展。研究发现，现有的语言模型和检索系统在该任务上的性能仍显著低于人类专家的水平，这为模型的进步提供了可量化的基准。", "conclusion": "该研究成功地创建了一个大规模的数据集EvidenceBench-100k，可以有效地评估模型在自动寻找相关证据方面的性能。研究表明，现有的模型仍然无法达到人类专家的水平，因此需要进一步改进。未来的工作可以基于该数据集进行更深入的研究，以提高模型性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.07258", "html_url": "https://arxiv.org/abs/2505.07258", "title": "无需查询，无需访问", "title_en": "No Query, No Access", "authors": "Wenqiang Wang,Siyuan Liang,Yangshijie Zhang,Xiaojun Jia,Hao Lin,Xiaochun Cao", "background": "现有的文本对抗攻击通常需要对受害模型有知识、进行大量查询或访问训练数据，这限制了它们在现实世界中的可行性。", "innovation": "提出了基于受害数据的对抗攻击（VDBA），仅使用受害文本操作；通过创建影子数据集，使用公共预训练模型和聚类方法为基础构建替代模型；设计分级替代模型，提升攻击成功率；使用多种攻击方法生成具有更好相似性和攻击效果的对抗样本；实验结果表明，VDBA在情感分析和SST5数据集上超越了现有方法，显著提高了攻击成功率并对如Qwen2和GPT系列的大型语言模型构成显著威胁，即使不访问API也能取得较高的攻击成功率，证明先进的NLP模型面临严重安全风险。", "conclusion": "我们的代码可以在该链接找到。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.10507", "html_url": "https://arxiv.org/abs/2505.10507", "title": "标签对齐细节中的魔鬼：针对标记分类任务的基于翻译的跨语言转移", "title_en": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "authors": "Benedikt Ebing,Goran Glavaš", "background": "翻译基的跨语言迁移XLT策略，如翻译训练和翻译测试，被用作有效的XLT基线，但在标记分类任务的XLT中，这些策略面临标签投影的挑战。传统的词对齐工具虽然广泛应用，但它们在翻译基XLT中的应用细节尚未系统性地研究。近年来，基于标记的方法在标签投影方面声称比词对齐工具性能更优。本文重新探讨了词对齐工具在标签投影中的使用情况，研究了其低级设计决策对基于翻译的XLT性能的影响。", "innovation": "本文系统性地研究了词对齐工具的设计决策如何影响基于翻译的XLT的性能，提出了新的集成预测策略。该策略结合了翻译训练和翻译测试的预测结果，显示出比基于标记的方法更高的性能。此外，该研究还表明，基于提出的集成方法能够减少对词对齐工具低级设计决策的敏感度，提高模型的鲁棒性。", "conclusion": "优化选择词对齐工具标签投影策略的决策后，使用基于词对齐的XLT可以达到与基于标记的方法相当的性能水平。提出的集成预测策略不仅提升了XLT的整体性能，而且增强了方法的稳健性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08947", "html_url": "https://arxiv.org/abs/2502.08947", "title": "通过分层隐空间折叠在大型语言模型表示中的结构收敛", "title_en": "Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding", "authors": "Fenella Harcourt,Naderdel Piero,Gilbert Sutherland,Daphne Holloway,Harriet Bracknell,Julian Ormsby", "background": "高维隐空间中的token表示经常表现出冗余性，这限制了计算效率并降低了模型层间的结构一致性。分层隐空间折叠引入了一种分层的变换机制，通过分层细化嵌入表示的紧凑性，同时保留必要的上下文区分性。", "innovation": "提出了动态折叠操作，迭代地调整token嵌入以影响序列处理任务中的短范围和长范围依赖性。实证研究表明，这一方法能减少层间表征变异，提高预测置信度，特别是在深层模型的计算资源分配更高效，通过分层细化改进上下文抽象。", "conclusion": "分层折叠引入的计算消耗增加可以忽略不计，但能提高推理效率和结构表示。这项研究强调了通过改进表征结构和计算效率优化模型性能的影响。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20910", "html_url": "https://arxiv.org/abs/2505.20910", "title": "大型语言模型交互中的自动隐私信息标注", "title_en": "Automated Privacy Information Annotation in Large Language Model Interactions", "authors": "Hang Zeng,Xiangyu Liu,Yong Hu,Chaoyue Niu,Fan Wu,Shaojie Tang,Guihai Chen", "background": "用户在使用大型语言模型（LLMs）时，使用真实身份进行交互时，往往无意中会泄露个人隐私信息。现有的一些隐私检测方法主要针对匿名内容中个人可识别信息（PII）的标记，并不适用于直接使用用户真实身份与LLMs交互的场景。因此，自动通知用户其查询是否存在隐私泄露以及哪些短语泄露了什么隐私信息，成为了实际应用的需要。", "innovation": "本文提出了一种自动化的隐私信息标注管道，通过使用强大的LLMs自动生成多语言的大规模用户查询数据集，包含超过249,000条用户查询和154,000个标注隐私短语，以此支持适用于本地用户设备上的隐私检测模型的研究和发展。同时，本文设计了不同层次的评价指标，建立基于轻量级LLMs的基准方法，并进行了全面的性能评估。这些创新使得研究人员能够更接近解决实际需求，提升现有方法的有效性。", "conclusion": "实验结果表明，现有的隐私检测方法在实际应用场景中性能仍有待提高，这激发了未来关于有效本地隐私检测方法的研究。基于此数据集，未来的工作将致力于提出更有效的本地隐私检测方法。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09349", "html_url": "https://arxiv.org/abs/2506.09349", "title": "DrVoice: 双分辨率声学表示的平行语音-文本语音对话模型", "title_en": "DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations", "authors": "Chao-Hong Tan,Qian Chen,Wen Wang,Chong Deng,Qinglin Zhang,Luyao Cheng,Hai Yu,Xin Zhang,Xiang Lv,Tianyu Zhao,Chong Zhang,Yukun Ma,Yafeng Chen,Hui Wang,Jiaqing Liu,Jieping Ye", "background": "近期，大规模语言模型（LLMs）在端到端语音生成方面的研究引起了广泛社区关注，多篇工作将基于文本的LLMs扩展至生成离散的语音令牌。现有的方法主要分为两类：一类是独立生成离散语音令牌而不将其整合进LLM的自回归过程中，导致文本生成与同时进行的语音合成缺乏同步性；另一类是通过联合自回归建模生成交错或并行的语音-文本令牌，使得生成过程中不同模态互相感知。", "innovation": "本文提出了DrVoice平行语音-文本语音对话模型，该模型基于联合自回归建模，并采用双分辨率声学表示机制。与现有方法主要使用12.5Hz输入音频表示不同，DrVoice的双分辨率机制将输入频率降至5Hz。实验证明，DrVoice在口述问答基准测试中达到相似大小语音基础模型中的新最佳性能。", "conclusion": "实验结果表明，DrVoice在Spoken Question Answering基准测试中，相较于同类体量的语音基础模型，建立了新的软件技术标准。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10942", "html_url": "https://arxiv.org/abs/2502.10942", "title": "探索大型语言模型中的Contextual Flux：一种自我调节语义网络的新方法", "title_en": "Exploring Contextual Flux in Large Language Models: A Novel Approach to Self-Modulating Semantic Networks", "authors": "Henry Evidail,Zachary Mountebank,Alistair Hathersage,Peter Stanhope,Basil Ravenscroft,Tobias Waddingham", "background": "语言模型通过上下文重新定位策略引入自我调整机制，动态调整标记嵌入轨迹，从而在其内部实现动态适应能力。实证分析评估了熵变化、潜在空间重新定位和连贯性稳定性，以评估自我调节对文本生成一致性的影响，同时保持生成灵活性。计算需求与实时嵌入重构相关，强调在高负载生成应用中需要优化策略", "innovation": "提出了一种名为Contextual Flux的方法，通过在自我注意力框架中集成一个辅助门控机制来动态调整标记表示，基于变化的上下文依赖性。定量评估显示嵌入变化有助于更结构化的适应，减少冗余短语重复，提高主题保留度。上下文权重计算的差异影响调制稳定性，对不同语言结构的适应性有不同影响", "conclusion": "虽然适应性嵌入更新改善了某些方面的连贯性，但其影响仍然取决于模型容量和输入复杂性。需要优化策略来处理实时嵌入重构带来的计算要求，以提高大型语言模型的扩展性和性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16518", "html_url": "https://arxiv.org/abs/2505.16518", "title": "CUB: 语言模型中上下文利用技术的基准测试", "title_en": "CUB: Benchmarking Context Utilisation Techniques for Language Models", "authors": "Lovisa Hagström,Youna Kim,Haeun Yu,Sang-goo Lee,Richard Johansson,Hyunsoo Cho,Isabelle Augenstein", "background": "在知识密集型任务如问答和事实核查中整合外部知识至关重要。然而，语言模型可能会忽略与过时参数记忆冲突的相关信息，或者被无关背景内容所吸引。虽然最近提出了许多上下文利用技术来缓解这些问题，但鲜有对其进行全面系统比较的研究。本文旨在开发CUB（Context Utilisation Benchmark），首个综合性的基准测试，帮助检索增强生成（RAG）领域的从业者诊断在不同上下文条件下的上下文利用技术。通过这一基准测试，本文对七种最先进的方法进行了迄今为止最全面的评估，这些方法代表了主要的CMT类别，在三个不同的数据集和任务上应用了九种语言模型。研究结果揭示，大多数现有的CMT在处理真实检索增强场景中碰到的各种上下文类型方面面临挑战。此外，许多CMT在简单的合成数据集上的表现显著高于更现实具有天然样本的数据集。研究发现暴露出现有CMT评估实践中的关键缺陷，并突显了全面测试和开发能够稳健处理多种上下文类型的技术的必要性。", "innovation": "本文开发了CUB（上下文利用基准），这是首个用于帮助从业者诊断不同上下文条件下上下文利用技术的综合基准测试。该基准测试对七种最先进的方法进行了最全面的评估，涵盖了三大类上下文利用技术，并应用于多个语言模型。", "conclusion": "当前的上下文利用技术在处理真实世界检索增强场景的不同上下文类型方面表现不佳，而且在简单合成数据集上的表现与在包含自然样本的更现实数据集上的表现存在偏差。这一研究揭示了现有CMT评估实践的重要不足，并强调了需要进行全面测试并开发能够稳健处理多种上下文类型的技术的必要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11246", "html_url": "https://arxiv.org/abs/2506.11246", "title": "无通用提示：通过自适应提示实现时间表推理的一致推理", "title_en": "No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning", "authors": "Abhishek Rajgaria,Kushagra Dixit,Mayank Vyas,Harshavardhan Kalalbandi,Dan Roth,Vivek Gupta", "background": "大型语言模型（LLMs）在时间表推理方面面临关键挑战，需要有效的推理来提取相关见解。尽管存在多种提示方法，但它们对时间表推理的影响尚未充分探索。此外，模型性能在不同类型的表格和上下文结构之间差异很大，使得确定最优方法变得困难。", "innovation": "我们介绍了SEAR，一种受启发于人类推理的自适应提示框架，能够根据不同上下文动态调整并整合结构化推理。结果显示，SEAR在所有表格类型上的表现均优于基础提示技术。此外，研究发现统一表示法增强了模型的推理能力。", "conclusion": "研究表明，单一的提示方法并不始终优于其他方法，而SEAR自适应提示框架能够在不同类型的表格上实现更优的性能。统一表示法也增强了模型的推理能力。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20160", "html_url": "https://arxiv.org/abs/2506.20160", "title": "AALC: 大型语言模型高效推理通过自适应准确度长度控制", "title_en": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control", "authors": "Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du", "background": "大型推理模型（LRMs）通过生成长且详细的推理过程来实现卓越的推理能力，但这会导致高延迟和成本，而准确度却没有相应的提升。", "innovation": "引入AALC（自适应准确度长度控制），这是一个轻量级的方法，它将准确性意识的长度奖励整合到强化学习中，目的是在训练过程中动态平衡正确性和简洁性。具体来说，AALC通过将验证准确性纳入奖励，并采用平滑的、动态调度的长度惩罚，直到达到目标性能才施加长度惩罚。", "conclusion": "通过在标准和分布外的数学基准测试中的广泛实验，我们展示了这种方法可以使响应长度减少超过50%，同时维持甚至提高原始准确度。进一步的定性分析表明，该方法遏制了冗余的推理模式，如过度设定子目标和验证，导致结构上更为精炼的输出，而不是简单的截断。此外，我们发现效率的提升伴随减少了模型的可解释性：使用AALC训练的模型会省略一些叙事框架和解释性背景。这些发现突出了基于奖励策略的潜力，可以引导LRMs走向更高效、更通用的推理路径。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17747", "html_url": "https://arxiv.org/abs/2507.17747", "title": "预训练在测试集上不再足够：基于论辩的问答基准方法", "title_en": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks", "authors": "Linbo Cao,Jinman Zhao", "background": "随着前沿语言模型在标准问答基准测试中趋于饱和，数据污染、记忆化以及数据集创建成本的不断上升等问题愈发引起关注。本文针对这一背景，提出了一种基于论辩的评价范式，将任何现有的问答数据集转化为结构化的对抗性辩论，其中一方模型被赋予官方答案以反驳，另一方则构建并捍卫一个替代性答案，整个辩论由一个对正确答案盲目的裁判模型进行评判。", "innovation": "本文有两个主要贡献：（1）一种系统地将问答任务转化为基于论辩的评估流程。（2）一个公开的基准，展示了该范式在MMLU-Pro问题子集上的有效性，包括标准化协议和参考模型。实验结果显示该方法的鲁棒性及其对数据污染的有效性，一个针对测试问题微调的Llama 3.1模型虽然在准确性方面取得了显著提升（50%到82%），但在辩论中表现较差。结果还表明，即使弱裁判也能可靠地区分较强辩论者，这突显了论辩式评估在规模扩展以及保持较低成本方面的优势。", "conclusion": "本文框架强调，“仅靠预训练在测试集上已经不再足够”来衡量先进语言模型的实际推理能力，为评估真实的推理能力提供了可持续的路径。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00544", "html_url": "https://arxiv.org/abs/2508.00544", "title": "PaPaformer：从预训练并行路径构建的语言模型", "title_en": "PaPaformer: Language Model from Pre-trained Parallel Paths", "authors": "Joonas Tapaninaho,Mourad Oussala", "background": "现代大型语言模型的训练需要不断增加的计算能力和时间。即使是较小的语言模型（SLMs）也需要几天的时间进行训练，通常需要多块GPU。本文探讨了如何在几小时内而非几天或几周的时间内训练和评估仅解码器的变压器语言模型的方法。", "innovation": "介绍了PaPaformer，这是一种仅解码器的变压器架构变体，其较低维度的并行路径合并为较大的模型。该方法允许在使用不同类型的训练数据独立训练这些较低维度的路径后，再将它们合并为一个更大的模型。这种方法可以随着性能的提高减少总模型参数的数量和训练时间。此外，使用并行路径结构为特定任务需求定制路径提供了有趣的可能。", "conclusion": "该研究展示了如何通过拆分和重组较低维度的并行路径来减少模型参数和训练时间，同时保持或提高模型性能。这种方法为定制化设计特定任务需要的语言模型提供了新的思路。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越令牌度量的LLM公平性量化：一种语义和统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）在生成回应时经常带有内在偏差，影响其实用性。现有评估方法往往忽略了长格式回应中的偏差以及LLM输出的内在变异性。现有工作主要集中在情感或令牌级的对比上，但未能进行更深层次的细粒度语义分析。FiSCo框架旨在通过检测不同人口群体之间的细微语义差异，解决这一问题。", "innovation": "FiSCo框架是一种新的统计框架，用于通过语义层面的细粒度计算来评估LLM在不同群体中的小组级公平性。它通过提供基于论证的评估，利用蕴含检查来评估回应间的意义一致性，从而超越表面分析。FiSCo通过将模型输出分解为语义不同的论证，并应用统计假设检验来比较组内和组间的相似性，从而更可靠地检测细微偏差。", "conclusion": "实验结果表明，FiSCo比其他评估指标更准确地识别细微偏差，同时减少了由于LLM随机性带来的影响，证明了它在性别、种族和年龄不同群体上的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13380", "html_url": "https://arxiv.org/abs/2506.13380", "title": "图检索中大型语言模型的分解推理", "title_en": "Decompositional Reasoning for Graph Retrieval with Large Language Models", "authors": "Valentin Six,Evan Dufraisse,Gaël de Chalendar", "background": "大型语言模型（LLMs）在许多自然语言处理（NLP）任务中表现出色，但在多步推理和事实一致性方面存在不足，这限制了它们在复杂问题回答（QA）等知识密集型任务中的效果。连接知识图谱（KG）和LLMs显示出有前景的结果，但现有的LLMs通常缺乏高效处理结构化信息的能力。因此，本文提出了一种新的检索方法，通过查询分解将文本知识图谱整合到LLMs的推理过程中，该方法将复杂问题分解为子问题，检索相关文本子图，并组成一个特定于问题的知识图谱来指导答案生成，从而提高LLMs在多步QA任务上的性能和事实依据，增强可解释性，同时利用LLMs的生成能力。该方法使用加权相似度函数，使复杂问题和生成的子问题都能提取相关子图，以实现对复杂问题的高效精确检索，并实现对LLMs的改进。我们的方法在标准多步QA基准上进行了评估，结果显示它在使用较小模型和减少LLMs调用次数的情况下，能达到或优于竞品方法的表现。", "innovation": "本文提出了一种将文本知识图谱集成到LLMs推理过程中的新型检索方法，通过查询分解，将复杂问题分解为子问题，检索相关文本子图，并组成一个特定于问题的知识图谱来指导答案生成。这种分步推理流程提高了事实依据和可解释性，同时利用了LLMs的生成能力。", "conclusion": "我们在标准的多步QA基准上评估了该方法，结果显示它在使用较小模型和减少LLM调用次数的情况下，达到了或优于竞品方法的表现。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05028", "html_url": "https://arxiv.org/abs/2508.05028", "title": "评价大语言模型在AMR解析中的表现", "title_en": "Evaluation of LLMs in AMR Parsing", "authors": "Shu Han Ho", "background": "AMR（抽象意义表示）是一种将句子意义表示为有根、有向、无环图的形式主义，节点表示概念，边表示语义关系。最近的研究表明，微调大语言模型（LLMs）的解码器可以有效地用于AMR解析，并取得有竞争力的结果。这项研究评估了四个不同的LLM架构（Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled）在LDC2020T02Gold AMR3.0测试集上的性能。", "innovation": "研究创新地评估了微调四个不同架构的LLM（仅解码器）在AMR解析中的表现，并发现LLaMA 3.2在语义性能上表现卓越，与当前最先进（SOTA）的AMR解析器相当。通过直接微调，LLaMA 3.2在AMR解析中达到了与强化起来的大规模成本模型（Apt + Silver，IBM）和Graphene Smatch（MBSE）相似的性能。", "conclusion": "研究结果表明，直接微调仅解码器的LLM可以达到与复杂SOTA AMR解析器相当的性能。其中LLaMA 3.2在AMR解析中表现尤为突出，取得了与Apt + Silver和接近Graphene Smatch的SMATCH F1分数，分别为0.804和0.854。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.03923", "html_url": "https://arxiv.org/abs/2508.03923", "title": "CoAct-1: 计算机使用的代理具有编程作为动作", "title_en": "CoAct-1: Computer-using Agents with Coding as Actions", "authors": "Linxin Song,Yutong Dai,Viraj Prabhu,Jieyu Zhang,Taiwei Shi,Li Li,Junnan Li,Silvio Savarese,Zeyuan Chen,Jieyu Zhao,Ran Xu,Caiming Xiong", "background": "自主代理通过图形用户界面（GUI）操作计算机往往面临效率和可靠性问题，特别是在复杂的长期任务中。尽管可以利用规划技术来改进任务分解，但这些代理仍然受限于通过GUI操作执行所有动作所固有的局限性，导致其脆弱性和低效率。现有的方法往往显得不够稳健，且难以处理复杂任务的自动化需求。因此，需要一种更加稳健和灵活的方法来解决这些问题。", "innovation": "本文提出了一种新的范式 CoAct-1，即将编程作为代理的一种增强的动作，通过将GUI控制与直接程序执行相结合，实现一种多代理系统。CoAct-1 包含一个调度器，能够动态地将子任务委托给常规的GUI操作员或专门的程序员代理，后者能够编写和执行Python或Bash脚本。这一混合方法使得代理能够绕过GUI动作序列，对于文件管理和数据处理等任务更为高效，仍然可以在需要时利用视觉交互。通过OSWorld基准测试表明，CoAct-1 达到了新的最先进的成功率 60.76%，并显着优于先前的方法。此外，该方法还大大提高了效率，平均完成任务步骤减少至仅 10.15 步，而最好的GUI代理则需要 15 步。", "conclusion": "研究表明，将编程作为一个核心动作集成，为通用计算机自动化提供了一条更强大、更高效、更可扩展的途径。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05429", "html_url": "https://arxiv.org/abs/2508.05429", "title": "MyCulture：在低资源语言约束下的马来西亚多元文化探索", "title_en": "MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints", "authors": "Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng Chan", "background": "现有的大型语言模型（LLMs）由于训练数据主要来源于高资源语言（如英语和中文），因此常常表现出文化和语境上的偏见。这对于准确代表和评估多样化的文化背景，尤其是在低资源语言环境中，构成了挑战。本研究旨在通过建立一个专门针对马来西亚文化的基准——MyCulture，来解决这一问题。MyCulture覆盖了六方面的文化和习俗内容，并采用巴新马来语表述，旨在评估LLMs在马来文化的理解和表达能力。", "innovation": "MyCulture 提出了一个全面评估 LLMs 对马来文化理解的新基准，利用开放式多项选择题格式，没有预设答案，减少了猜测并降低了格式偏见。此研究还通过结构化输出和自由形式输出进行对比分析结构偏见，并通过多语言提示版本评估语言偏见。这些方法有效地提升了评估的公正性和区分力。", "conclusion": "通过跨区域和国际 LLMs 的评估，研究揭示了文化理解和处理上的巨大差异，强调了在 LLMs 开发和评估中建立文化根基和语言包容性的基准的紧迫性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06306", "html_url": "https://arxiv.org/abs/2507.06306", "title": "人类过度依赖自信的语言模型，不分语言", "title_en": "Humans overrely on overconfident language models, across languages", "authors": "Neil Rathi,Dan Jurafsky,Kaitlyn Zhou", "background": "随着大型语言模型（LLMs）在世界各地的应用，确保它们的响应在不同语言中能够准确传达不确定性及其限制变得至关重要。先前的研究表明，LLMs在英语方面表现出语言上的过度自信，导致用户过分依赖于自信的生成结果。然而，不同语言中表达认知态度的标记（如‘我认为它可能是’）使用和解释有着显著差异。因此，本研究旨在跨五个语言研究多语言语言（误）校准、自信和过度依赖的风险，以评估LLM在全球范围内的安全性。研究发现，过度依赖的风险在所有语言中都很高。LLMs在不同语言中过度自信，甚至在错误的回答中也频繁生成增强器。虽然模型生成的表达不确定性标记在日语中最多，但确定性标记在德语和汉语中最多。此外，研究还测量了跨语言的人类依赖率，发现依赖行为在不同语言中有显著差异，如参与者更可能在日语中忽视不确定性表达的‘抑制’功能，而依赖包含这些表达的生成结果。这些结果表明，不同语言中的模型生成结果存在过度自信的风险。因此，本研究强调了跨语言语言校准的挑战和多语言背景下模型安全评估的重要性。", "innovation": "本研究通过跨五个语言（英语、法语、德语、汉语和日语）全面评估LLMs，揭示了不同语言之间自信和不确定性表达的显著差异，发现了在不同语言中的过度自信和过度依赖风险，强调了LLM的全球应用需要考虑到文化与语言的差异进行安全评估的重要性。", "conclusion": "不同语言中的LLM生成结果存在过度自信的风险，这可能导致用户过度依赖包含不确定表达的生成结果。这凸显了跨语言LMM校准的挑战，并强调了进行文化和语言背景下的模型安全性评估的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2308.04941", "html_url": "https://arxiv.org/abs/2308.04941", "title": "整合大型语言模型和主动推理以理解阅读中的眼动和阅读障碍", "title_en": "Integrating large language models and active inference to understand eye movements in reading and dyslexia", "authors": "Francesco Donnarumma,Mirco Frosolone,Giovanni Pezzulo", "background": "当前研究中，阅读和眼动的计算模型尝试通过高层次的生成模型来模拟阅读过程，但往往缺乏跨层次的预测能力。对于阅读障碍的理解，现有理论如双通道阅读理论未能完全解释适应性和非适应性推理在阅读过程中的交互作用。", "innovation": "本文提出了一种新颖的计算模型，利用层次化主动推理机制来模拟阅读和眼动。该模型的创新在于结合了大型语言模型的文本预测能力和主动推理指导下的眼动特性，实现多粒度层次上的预测和推理，适用于已知和未知单词与句子。模型在阅读过程中的表现表明，可以通过减弱先验的作用来观察失读症患者的阅读缺陷特征。", "conclusion": "本文提出的模型为通过预测处理框架理解阅读和眼动的认知过程提供了一种新颖的方法。这种模型还在通读障碍的理解中显示出潜力，特别是通过模拟适应性和非适应性推理来解释眼动碎片化和错误推理的现象。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.14553", "html_url": "https://arxiv.org/abs/2411.14553", "title": "NP-hard图问题之间的可约性与边界类", "title_en": "Reducibility among NP-Hard graph problems and boundary classes", "authors": "Syed Mujtaba Hassan,Shahid Hussain,Abdul Samad", "background": "许多NP-hard的图问题在某些图类中变得容易，例如，对于二部图来说，着色问题变得容易，但在一般情况中是NP-hard的。因此，可以考虑的问题是何时一个困难的问题变得容易？哪种最小区结构能使问题保持困难？作者利用边界类的概念来研究这些问题。", "innovation": "提出了一种方法，可将一个NP-hard图问题的边界类转换为另一个问题的边界类。如果问题Π和Γ分别是NP-hard的，且Π可以归约到Γ，那么可以将Π的边界类转换为Γ的边界类。这提供了一种关于NP-hard问题之间可约性和边界类之间关系的方法。", "conclusion": "通过应用定理，获得了几个图问题的全新边界类，包括顶点覆盖、团、旅行商、受限度数生成树、子图同构和团覆盖问题，并展示了主要结果的强度。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.02596", "html_url": "https://arxiv.org/abs/2407.02596", "title": "更具现实性的提取攻击：一种攻击者视角", "title_en": "Towards More Realistic Extraction Attacks: An Adversarial Perspective", "authors": "Yash More,Prakhar Ganesh,Golnoosh Farnadi", "background": "语言模型倾向于记忆其训练数据，使其容易受到提取攻击。现有研究通常会关注单一模型或固定提示等孤立场景，但实际中的对手可以利用不同规模和检查点的多种模型，并且反复提示，这使得攻击面增大。本文从攻击者视角重新审视了提取攻击，考虑多方面的数据访问情况，发现了提取趋势中的显著变化。例如，即使提示发生变化或攻击较小规模、较早的模型，也能提取不同信息。通过组合多次攻击，攻击者能将提取风险翻倍，即使在数据去重等缓解策略下仍然存在。这表明了更加现实的攻击者能够超越文献中的其他攻击模型。", "innovation": "从一种多维度数据访问的视角重新审视提取攻击，揭示了即使对提示进行非直观的改变，或针对更小的模型和更早的检查点，也能提取出不同的信息。通过综合攻击策略，攻击者能显著增加提取风险，即使采用了数据去重等缓解策略仍然有效。", "conclusion": "本文通过四个案例研究，包括检测预训练数据、版权侵权、提取个人可识别信息和攻击闭源模型，展示了更为现实的攻击者如何在诸多领域超越现有文献中的对手。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.13147", "html_url": "https://arxiv.org/abs/2412.13147", "title": "您的大语言模型是否具备稳定推理能力？", "title_en": "Are Your LLMs Capable of Stable Reasoning?", "authors": "Junnan Liu,Hongwei Liu,Linchen Xiao,Ziyi Wang,Kuikun Liu,Songyang Gao,Wenwei Zhang,Songyang Zhang,Kai Chen", "background": "大语言模型（LLMs）取得了在复杂推理任务中的显著进展，但在基准测试表现与实际应用之间仍存在较大差距。这一差距主要归因于当前的评估方法和度量标准无法充分捕捉LLMs在复杂推理任务中的全面能力，特别是在需要准确性和一致性的情况下。", "innovation": "本文提出了一种新的评估指标G-Pass@$k$，该指标连续评估模型在多次采样尝试中的表现，量化了模型的性能潜力和稳定性。通过在各种公开和新构建的基准上进行广泛的实验，并与最先进的大语言模型结合使用，提供对其潜在能力及操作一致性的全面见解。", "conclusion": "研究结果揭示了大幅提高大语言模型实际推理能力的机会，强调了需要更强大的评估指标以确保模型的可靠和高效性的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.09105", "html_url": "https://arxiv.org/abs/2406.09105", "title": "INS-MMBench：评估大型视觉语言模型在保险领域性能的综合基准", "title_en": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance", "authors": "Chenwei Lin,Hanjia Lyu,Xian Xu,Jiebo Luo", "background": "大型视觉语言模型（LVLMs）和多模态大型语言模型（MLLMs）在诸多通用多模态应用中表现出色，并且在专业领域显示出越来越大的潜力。然而，这些模型在保险领域（以其丰富的多模态数据和多样化的应用场景为特点）的应用潜力尚未充分开发。目前，没有系统性的多模态任务总结，也缺乏为LVLMs专门设计的评估基准。这阻碍了保险行业中LVLMs的发展。因此，本研究系统地回顾并分类了适用于4种代表性保险类型（汽车、财产、健康、农业）的多模态任务。我们介绍了INS-MMBench，这是首个针对保险领域的分层基准。INS-MMBench包括22个基础任务、12个元任务和5个情境任务，从基本能力到实际应用案例进行全面和渐进的评估。", "innovation": "本研究首次提出了INS-MMBench，这是首个专门为保险领域设计的分层基准，包含22个基础任务、12个元任务和5个情境任务，提供从基础能力到实际应用案例的全面和渐进评估。研究对比了包括闭源模型GPT-4o和开源模型LLaVA在内的11个领先LVLMs，并验证了INS-MMBench的有效性，提供了有关当前LVLMs在各种与保险相关的多模态任务中的优缺点的详细见解。", "conclusion": "希望INS-MMBench能够加速LVLMs在保险行业的集成，并促进跨学科研究。本研究的数据集和评估代码可在以下网址获取：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00048", "html_url": "https://arxiv.org/abs/2502.00048", "title": "基于上下文纠缠梯度映射的优化大模型理解", "title_en": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension", "authors": "Colin Sisate,Alistair Goldfinch,Vincent Waterstone,Sebastian Kingsley,Mariana Blackthorn", "background": "现有优化策略在长文本推理、上下文保留以及应对未见过的领域方面的表现存在局限性，这导致了现有梯度优化算法在提升模型的语义连贯性和推理能力方面存在不足。现有方法中的梯度通常被视作孤立的数值实体，未能充分捕捉到上下文之间的动态依赖关系。因此，研究如何改进梯度优化策略以增强模型的语义连贯性和推理能力显得尤为重要。", "innovation": "本文提出了Contextually Entangled Gradient Mapping (CEGM) 的新颖方法，通过将梯度视为动态传递上下文依赖性的载体，改进了上下文嵌入与梯度更新之间的关系。这种新的策略填补了现有优化策略中的关键空白，通过将其融入损失正则化框架，CEGM显著提高了任务相关的性能，特别是在长文本推理、上下文保持和对未知领域适应性方面表现突出。此外，研究还展示了在训练管道中引入纠缠层和动态系数调整的方法，使CEGM能够无缝集成到现有的架构中，从而减少下游任务中的语义漂移并增强嵌入的连贯性。", "conclusion": "实验结果表明，CEGM增强的模型在token级预测准确性方面优于基线模型，并且展现出更强的对噪声输入的鲁棒性。该方法展示了梯度纠缠对于优化策略的理论和技术实践的更广泛影响，证明了它不仅能够改进现有的优化手段，还能够显著提高大模型的综合性能。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20091", "html_url": "https://arxiv.org/abs/2507.20091", "title": "ProsodyLM: 发现语音语言模型中新兴的语音处理能力", "title_en": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models", "authors": "Kaizhi Qian,Xulin Fan,Junrui Ni,Slava Shechtman,Mark Hasegawa-Johnson,Chuang Gan,Yang Zhang", "background": "语音语言模型是指具有语音处理和理解能力的语言模型。现有的主流训练范式是先将语音转换为离散的符号，再送入大语言模型（LLMs），这种做法在学习语音信息方面效果不理想，我们发现通过预训练出现明显的语音处理能力是很有限的。这篇论文讨论了这一问题并提出了一种新的语音处理方法：ProsodyLM。", "innovation": " ProsodyLM 引入了一种简单的标记化方案来学习语音信息。语音表达首先被转录为文本，然后按单词级别的语音标记序列进行处理。与传统的语音标记化方案相比，该方案保留了更多完整的语音信息，并且更容易为基于文本的大语言模型所理解。研究表明，ProsodyLM 通过预训练可以学习到一系列复杂的新兴语音处理能力，包括捕捉生成语音中的语音细微差别，理解语句中的情绪和重音，以及在长段文本中保持语音的一致性。", "conclusion": " ProsodyLM 能够显著提高语音语言模型在处理语音信息方面的表现，通过预训练的方式训练出具备多样新兴语音处理能力的语音语言模型，这些能力包括语音分类、情感理解、语音持续时间调控等。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18418", "html_url": "https://arxiv.org/abs/2502.18418", "title": "Rank1：信息检索中基于测试时计算的重新排名", "title_en": "Rank1: Test-Time Compute for Reranking in Information Retrieval", "authors": "Orion Weller,Kathryn Ricci,Eugene Yang,Andrew Yates,Dawn Lawrie,Benjamin Van Durme", "background": "介绍了第一个能够在测试时利用计算资源重新排名的模型Rank1。通过使用推理语言模型（如OpenAI的o1和Deepseek的R1）对更小的模型进行蒸馏，Rank1展示了在检索中利用推理语言模型的重要性，这有助于提高小型模型的性能并展示出卓越的分布式外推能力。研究团队还收集并开源了一个包含超过600,000个实例的R1推理跟踪数据集，这些实例来自MS MARCO中的查询和段落。", "innovation": "Rank1模型的主要创新在于，它是第一个利用测试时计算资源训练的重新排名模型。通过使用推理语言模型（如OpenAI的o1和Deepseek的R1等）对小型模型进行蒸馏，Rank1展示了利用推理语言模型来迅速提升小型模型性能的可行性。此研究还展示了这些模型在具有解释性推理链的情况下，可以提供给用户或基于检索的生成系统，进一步证明了量化版本的模型在计算和内存使用上更节省，但在性能上保持强劲的优势。", "conclusion": "Rank1的研究表明，测试时计算为信息检索中的可解释且高效的重新排名模型提供了一种全新的可能性，这些模型能够快速响应用户输入的提示并在分布式环境下表现出色。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04030", "html_url": "https://arxiv.org/abs/2504.04030", "title": "OpenCodeInstruct：代码LLM的大规模指令调优数据集", "title_en": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs", "authors": "Wasi Uddin Ahmad,Aleksander Ficek,Mehrzad Samadi,Jocelyn Huang,Vahid Noroozi,Somshubra Majumdar,Boris Ginsburg", "background": "大型语言模型（LLMs）已经改变了软件开发领域，通过代码生成、自动调试和复杂推理等功能带来了显著变化。然而，其进一步的进步受限于高质量、公开可获取的监督微调（SFT）数据集的稀缺性，这些数据集专门为编程任务设计。为了缩小这一差距，我们引入了OpenCodeInstruct——一个最大的开源指令调优数据集，包含500万个多样化的样本，每个样本包括编程问题、解决方案、测试案例、执行反馈以及LLM生成的质量评估。", "innovation": "我们使用OpenCodeInstruct数据集对不同的基础模型，如LLaMA和Qwen，进行了跨多个规模（1B+、3B+和7B+）的微调。对流行的基准测试（HumanEval、MBPP、LiveCodeBench和BigCodeBench）进行全面评估表明，使用OpenCodeInstruct进行SFT实现了显著的性能提升。此外，我们还详细阐述了种子数据的策划、合成指令和解决方案生成以及过滤等方法。", "conclusion": "研究结果表明，OpenCodeInstruct是代码LLM训练的重要资源，能够显著提高模型在多个代码相关任务上的表现。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01700", "html_url": "https://arxiv.org/abs/2503.01700", "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation", "title_en": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation", "authors": "Yongchao Chen,Yilun Hao,Yang Zhang,Chuchu Fan", "background": "近期的研究表明，大规模语言模型（LLMs）在机器人任务和运动规划（TAMP）方面展现出巨大的潜力。当前，LLMs方法生成基于文本或代码的推理链，包括子目标和行动计划，但未能充分利用它们的符号计算和代码生成能力。许多TAMP任务涉及复杂的多约束优化，纯文本推理不足以应对。尽管将预定义的求解器和规划器与LLMs结合可以提高性能，但这种做法缺乏跨任务的一般性。鉴于LLMs不断增强的编码能力，通过引导它们生成用于优化和约束验证的代码作为符号规划器来提高它们的TAMP能力。", "innovation": "论文提出了一种新的方法——Code-as-Symbolic-Planner，通过引导LLMs生成代码作为求解器、规划器和检查器，来解决TAMP任务中的符号计算问题，仍能利用文本推理来融入常识。通过多轮指导和答案进化的框架，Code-as-Symbolic-Planner在七个典型TAMP任务和三种流行的LLMs上平均提高了24.1%的成功率。该方法在离散和连续环境、2D/3D模拟和实际场景，以及单、多机器人任务中都表现出强烈的有效性和泛化能力。", "conclusion": "Code-as-Symbolic-Planner通过引导LLMs生成符号代码进行TAMP任务规划，显著提高了任务成功率，并在多种环境下展示了强大的泛化能力。详细信息和实验结果，请参见项目网站。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.00900", "html_url": "https://arxiv.org/abs/2407.00900", "title": "从下一个词到数学：语言模型中数学推理的学习动态", "title_en": "From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models", "authors": "Shubhra Mishra,Gabriel Poesia,Noah D. Goodman", "background": "大型语言模型（LLMs）仅通过下一个词预测训练就能够解决一系列涉及数学推理的问题。但是这些能力在训练过程中是如何发展的？本研究首次分析了多个开源大型语言模型在预训练和后训练过程中数学推理能力的发展过程。", "innovation": "研究构建了一个名为MathCAMPS的合成数据集，该数据集中的问题涵盖了从K到8年级44个细粒度技能。研究发现，数学技能在预训练过程中按可度量的人类设计的课程顺序学习，即使训练数据是随机排序的。另外，研究还详细分析了哪些数学能力可以通过后训练的指令调整受益，而哪些技能则会受损。这项工作为理解LLM训练动态与其推理关系提供了实证基础。", "conclusion": "本研究为理解LLM在数学推理方面的训练动态提供了实证基础，发现数学技能的学习顺序与人类设计的课程顺序有可度量的相关性，并通过详细分析展示了哪些数学能力能够从后训练中受益，揭示了不同技能在训练过程中的不同表现。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23145", "html_url": "https://arxiv.org/abs/2503.23145", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "title_en": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "authors": "Anjiang Wei,Tarun Suresh,Jiannan Cao,Naveen Kannan,Yuheng Wu,Kai Yan,Thiago S. F. X. Teixeira,Ke Wang,Alex Aiken", "background": "现有的代码生成和自举程序合成评估协议依赖于静态输入输出示例集和保留测试，这种评估方法不提供错误提示，并且无法反映真实场景，如逆向工程。手动生成的函数无法充分利用大型语言模型（LLM）在受自然语言引导的任务中的性能，在自举程序合成方面的潜力尚未得到充分发挥。CodeARC提出了一个新型的评价框架，其中代理能够在未知的目标函数上交互，通过查询新型输入、生成候选函数以及使用差异测试或acles迭代完善解决方案，促进代理进行函数调用和基于反馈的自我修正。这种方法构建了一个大规模通用的自举程序合成基准数据集，包含1114个函数，评估了18种模型，best-model的性能为52.7%。对LLaMA-3.1-8B的微调带来了31%的相对性能提升。", "innovation": "CodeARC提出了一种新的评估框架，使LLM代理能够在未知目标函数上进行交互，通过差异测试或acles不断修正解决方案。这与之前仅依赖静态示例和保留测试的评估方式不同，CodeARC的交互式设置鼓励代理在反馈基础上进行函数调用与自我修正。此外，CodeARC构建了一个大规模基准数据集，包含1114个自举程序合成的函数，对18个模型进行了评估，发现问题空间大、挑战高，且LLaMA-3.1-8B微调后表现出显著提升，表明这一领域尚有提升空间。", "conclusion": "CodeARC提供了一个更实际和具有挑战性的测试环境来评估基于LLM的程序合成与归纳推理能力。我们的代码、数据与模型现已公开。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.04996", "html_url": "https://arxiv.org/abs/2507.04996", "title": "从自主到自主能动：适应人类中心的移动系统中的能动车辆", "title_en": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems", "authors": "Jiangbo Yu", "background": "自主性源自古希腊语的自动（自我）和nomos（法律），意味着在没有外部控制的情况下根据内部规则运行的能力。因此，自动驾驶车辆（AuVs）被定义为能够感知其环境并独立于外部输入执行预编程任务的系统。然而，随着研究和实际应用的进展，越来越多的车辆展示了超越这一定义的行为（包括SAE的级别1到6），例如与人类和机器交互、目标适应、情境推理、使用外部工具和长期规划，尤其是结合了大型语言模型（LLMs）和代理人工智能系统。这些发展揭示了技术自主与未来人类中心移动系统所需更广泛的认知和社会能力之间的概念差距。", "innovation": "本文引入了能动车辆（AgVs）的概念，指的是整合了代理人工智能的车辆，能够在复杂环境中进行推理、适应和互动。文章呈现了一个系统级框架来描述AgVs，重点在于它们的认知和沟通层，并将其与传统的自动驾驶车辆区分开来。文章还综合了代理人工智能、机器人技术、多代理系统和人机交互的相关进展，并指出代理人工智能通过高层次推理和工具使用，不仅作为计算工具，还可以作为嵌入在移动生态系统中的交互代理发挥作用。", "conclusion": "本文识别了能动车辆发展的关键挑战，包括安全、实时控制、公众接受、伦理对齐以及监管框架，强调了这些挑战在能动车辆发展和治理中的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15254", "html_url": "https://arxiv.org/abs/2504.15254", "title": "CRUST-Bench: 一个全面的从C到安全Rust编译基准", "title_en": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation", "authors": "Anirudh Khatry,Robert Zhang,Jia Pan,Ziteng Wang,Qiaochu Chen,Greg Durrett,Isil Dillig", "background": "现代化现有的C代码并提高其安全性及与现代Rust生态系统的互操作性非常重要，但当前没有用于评估是否可以将C代码的安全Rust版本通过一系列测试用例进行编译的基准数据集。CRUST-Bench提供了一个包含100个C仓库的基准数据集，每个仓库都与手工编写的安全Rust接口以及用于验证编译正确性的测试用例相配对。这种处理整个仓库而非孤立函数的方式，能够捕捉多个文件间依赖的复杂项目转换挑战。提供的Rust接口确保了遵循惯用且内存安全的Rust模式，而附带的测试用例则确保功能正确性。使用最新的大型语言模型在这个任务中进行评估，发现生成安全且惯用的Rust代码仍然是一个具有挑战性的问题，各种最先进的方法和技术均无法完美解决。对CRUST-Bench的改进会提高编译系统的性能，使它们能够理解复杂的场景，从而帮助将C代码库迁移至Rust这种能确保内存安全的语言中。您可以在以下网址找到该数据集和代码：this https URL.", "innovation": "CRUST-Bench是首个专门用于评估C代码向安全Rust编译的技术数据集，它包含100个C仓库，每个仓库都配有安全Rust接口和测试用例，以验证编译的正确性。此数据集通过处理整个仓库，捕捉到跨多个文件依赖的复杂项目转换的挑战。提供的Rust接口确保了编译输出符合惯用且内存安全的Rust模式，而附带的测试用例则保证了功能的正确性。开源数据集的提出为大规模语言模型提供了评估和改进的基础，尤其是在从C到Rust的编译转换方面。", "conclusion": "通过使用现有的大型语言模型对此任务进行评估，发现生成安全且惯用的Rust代码仍然是一个具有挑战性的问题，各种先进技术和方法尚未能够完美解决。CRUST-Bench有助于改进编译系统，使其能够处理复杂的转换场景，从而帮助将C代码库迁移到确保内存安全的语言如Rust中。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09614", "html_url": "https://arxiv.org/abs/2505.09614", "title": "语言代理在因果推理方面反映人类偏差。我们如何帮助它们像科学家一样思考？", "title_en": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "authors": "Anthony GX-Chen,Dongyan Lin,Mandana Samiei,Doina Precup,Blake A. Richards,Rob Fergus,Kenneth Marino", "background": "语言模型（LM）代理被越来越多地用作自主决策者，需要积极收集信息以指导决策。对于此类代理而言，高效的探索和理解世界因果结构的认知技能至关重要，有助于稳健且基于科学的推理。然而，目前尚不清楚LMs是否具备此类能力，或者是否会表现出系统性的偏差导致错误结论。本研究通过使用发展心理学中广泛应用的 Blicket 测试范式来探讨LMs在探索和推断因果关系方面的表现。实验发现，LMs可靠地推断出常见的直观析取因果关系，但系统地在不太常见但同样（有时甚至更）有证据支持的合取因果关系上遇到困难。这种析取偏差在不同模型家族、大小和提示策略中普遍存在，并且随着任务复杂性增加表现进一步下降。此外，人类成人也表现出类似的偏差，表明LMs可能从训练数据中继承了深层次的推理启发式方法。因此，研究者量化了LMs与人类之间的相似性，发现LMs展示出类似成人推理的特征，但并非儿童类型的特征。最后，提出了一种测试时采样方法，该方法明确地从LM中采样并剔除关于因果关系的假设，这一可扩展的方法显著减少了析取偏差，使LMs更接近科学严谨的因果推理目标。", "innovation": "提出了一种测试时采样方法，该方法明确地从LM中采样并剔除关于因果关系的假设。这种可扩展的方法显著减少了析取偏差，使LMs更接近科学严谨的因果推理目标。此外，还探讨了LMs在因果推理方面的表现与人类类似的发现，这为理解LMs的推理机制提供了新的视角，并提出针对性改进方法以减少偏差。", "conclusion": "研究发现，尽管LMs在解析普通析取因果关系上表现出色，但在处理更复杂的合取因果关系上存在系统性和普遍性的困难，这表明存在一种“析取偏见”在不同模型中表现出。此外，通过采样测试的方法显著减少了这种偏见，推动了LMs向科学和因果上严谨推理迈进，同时这也为理解LMs的推理机制以及未来针对错误的纠正措施提供了科学依据。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05464", "html_url": "https://arxiv.org/abs/2508.05464", "title": "Bench-2-CoP: 欧盟AI合规下我们可以信赖基准测试吗？", "title_en": "Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?", "authors": "Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti", "background": "通用人工智能（GPAI）模型的迅速发展迫切需要建立稳健的评估框架，尤其是在欧盟AI法案及其配套指引（CoP）等新兴规定出现的情况下。现有的人工智能评估实践主要依赖于已有的基准，但这些基准工具并不能很好地衡量新法规重点关注的系统性风险。本研究旨在解决基准与法规之间的契合度差距，通过系统性分析验证了LLM作为法官的分析方法，比较了194,955个常用基准问题与欧盟AI法案模型能力和倾向性分类的覆盖情况，揭示了评估生态系统的巨大不匹配现象，特别是对关键功能性能力的忽视，以及自监管场景中的控制丧失风险。", "innovation": "提出了一种名为Bench-2-CoP的系统性框架，通过验证的LLM作为法官的分析方法，将广泛使用的基准问题与欧盟AI法案中模型能力和倾向性的分类进行对比。该研究提供了第一个全面定量分析基准与法规差距的研究，表明当前公开基准对于满足全面风险评估以符合监管合规性尚不充分，为开发下一代评估工具提供了关键洞见。", "conclusion": "当前的公众基准尚未能提供足够的证据支持全面的风险评估，以满足监管合规性要求。Bench-2-CoP框架揭示了理想的评估框架应该包括的关键领域，并提供了解决现有基准与新的法规框架之间差距的具体方案。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05732", "html_url": "https://arxiv.org/abs/2508.05732", "title": "Generalized Few-Shot Out-of-Distribution Detection", "title_en": "Generalized Few-Shot Out-of-Distribution Detection", "authors": "Pinxuan Li,Bing Cao,Changqing Zhang,Qinghua Hu", "background": "Few-shot Out-of-Distribution (OOD)检测已经成为机器学习中实用部署的关键研究方向。现有的少样本OOD检测方法在开放环境中缺乏足够的泛化能力。由于少样本学习范式，OOD检测能力往往会过度拟合有限的训练数据本身，从而在泛化数据上性能降低，并且在不同场景中表现不一致。", "innovation": "提出了一个广泛的少样本OOD检测（GOOD）框架，该框架通过辅助一般知识模型（GKM）增强OOD检测模型的一般知识，而不是直接从少量样本数据中学习。从泛化角度揭示了少样本OOD检测，并理论推导出了OOD检测中的泛在性-特定性平衡（GS-平衡），进而提出了知识动态嵌入（KDE）机制以适配调节一般知识的指导，提升泛在性-特定性平衡，最终在现实世界中的OOD基准测试中展示了优越性。", "conclusion": "实验表明，该方法在真实世界的OOD基准上表现优越，并提出了代码将开源。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02622", "html_url": "https://arxiv.org/abs/2508.02622", "title": "Noosemia: 钱纽斯意象——人类与生成性AI互动中原有意志归因的认知和现象学解释", "title_en": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction", "authors": "Enrico De Santis,Antonello Rizzi", "background": "本文介绍了Noosemia，这是一种新的认知-现象学模式，源自人类与生成性AI系统的互动，特别是在对话或跨模态方式进行交流的系统中。作者提出一个多学科框架，以解释在某些条件下，用户如何将意图性、代理性甚至是内省性归因于这些系统。这一过程不仅仅基于物理相似性，而是基于语言表现、认知透明度以及技术复杂性的发展。通过将LLM（大型语言模型）对意义的整体解释与LLM背景下的认知场概念联系起来，文章阐明了LLM如何通过关系构建意义，以及在人机界面中如何产生连贯性和代理的模拟体现。分析还将Noosemia与pareidolia（幻视）、animism（拟人化）、意向性姿态以及诡异谷现象进行对比，以此区分其独特的特征。此外，文章介绍了anoosemia来描述这些投影的现象学撤回。", "innovation": "本文创新地提出了Noosemia这一认知-现象学模式，解释了人类在与生成性AI系统互动时如何归因于机器以意向性、代理性和内省性的方式，这一过程不依赖于物理相似性，而是基于语言表现、认知透明度和新兴的技术复杂性。文章将LLM对整体意义的解释与LLM背景下的认知场概念进行了联系阐述。另外，引入了anoosemia这一概念来描述此类投射的撤回现象。", "conclusion": "本文讨论了Noosemia动态及其更广泛的哲学、认识论和社影响，并提出未来研究的方向。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05118", "html_url": "https://arxiv.org/abs/2508.05118", "title": "通过强化学习探索优秀的函数调用", "title_en": "Exploring Superior Function Calls via Reinforcement Learning", "authors": "Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang", "background": "大型语言模型在实际应用中的调用能力至关重要，但现有的训练方法无法培养出稳健的推理策略。监督微调生成的模型依赖于表面模式匹配，而标准强化学习方法在处理结构化函数调用的复杂动作空间方面也困难重重。", "innovation": "本文提出了一种新的强化学习框架，该框架通过战略熵驱动的探索增强分组相对策略优化，专门针对函数调用任务。该方法解决了函数调用中的三个关键挑战：策略学习期间探索不足、链式思考生成缺乏结构化推理以及参数提取验证不足。通过双重数据准备管道确保高质量的训练样本，结合迭代LLM评估和抽象语法树验证。广泛的实验在伯克利函数调用排行榜上证明，该框架在开源模型中达到最先进的性能，特别是在复杂多函数场景中比标准GRP提升了6%的性能。", "conclusion": "我们的方法在代码预训练模型上显示出特别显著的性能改进，表明结构化语言生成能力为函数调用任务的强化学习提供了一个有利的起点。我们将公开所有代码、模型和数据集，以惠及整个社区。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05829", "html_url": "https://arxiv.org/abs/2508.05829", "title": "TSMS-SAM2: 多尺度时域采样增强和记忆分割修剪以实现可提示的视频对象分割和跟踪在手术场景中的应用", "title_en": "TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios", "authors": "Guoping Xu,Hua-Chieh Shao,You Zhang", "background": "可提示视频对象分割和跟踪（VOST）随着基础模型如 Segment Anything Model 2 (SAM2) 的出现取得了显著进步，但在手术视频分析中的应用仍然具有挑战性，因为复杂的运动动态和冗余的记忆阻碍了有效的学习。", "innovation": "提出了 TSMS-SAM2 框架，通过引入多时尺度视频采样增强和记忆分割及修剪机制来增强手术视频中的可提示 VOST。该框架通过有效的运动变异性稳健性和特征组织筛选，提高了分割的准确性和效率。", "conclusion": "TSMS-SAM2 在 EndoVis2017 和 EndoVis2018 数据集上的平均 Dice 分数分别为 95.24 和 86.73，超过了基于 SAM 的先前方法和任务特定方法。详细的压力测试研究验证了多尺度时间增强和记忆分割的有效性，突显出框架在复杂手术场景中稳健、高效的分割潜力。"}
{"llm_update_time": "20250811", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11881", "html_url": "https://arxiv.org/abs/2502.11881", "title": "基于假设的大型语言模型心理理论推理", "title_en": "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models", "authors": "Hyunwoo Kim,Melanie Sclar,Tan Zhi-Xuan,Lance Ying,Sydney Levine,Yang Liu,Joshua B. Tenenbaum,Yejin Choi", "background": "现有的大语言模型（LLM）在解决各种任务方面已经表现出令人印象深刻的能力，比如解决数学和编程问题。然而，将这些方法应用于缺乏真实答案或规则验证方法的场景中仍然具有挑战性，例如追踪智能体的心理状态。受序列蒙特卡洛算法的启发，本文提出了推理时的心理状态追踪算法（thought-tracing），该算法通过生成假设并根据观察情况赋予权重来追踪特定智能体的心理状态，而不依赖于数据集中问题的真实答案。算法基于贝叶斯心理理论框架构建，使用LLM近似推断智能体不断变化的心理状态。通过在多种心理理论基准测试上进行评估，结果表明，心理状态追踪算法的性能显著优于基线模型。此外，实验还揭示了一些最近的推理模型在心理理论中的有趣行为，例如o3和R1，突显了社会推理与其它领域的不同之处。", "innovation": "提出了心理状态追踪算法（thought-tracing），该算法设计用于在没有真实答案验证机制的情况下追踪特定智能体的心理状态。它受到序列蒙特卡洛算法的启发，基于贝叶斯心理理论框架，使用LLM实现对智能体心理状态的近似推理。评估结果显示，此方法显著优于基线模型，揭示了社会推理的独特性。", "conclusion": "心理状态追踪算法能够有效追踪智能体的心理状态，显著改善了大语言模型在理论思维任务上的表现。实验结果还揭示了心理理论与其他领域的推理在行为上的差异。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05819", "html_url": "https://arxiv.org/abs/2508.05819", "title": "MZEN: 多倍率增强NeRF在未知相机姿态下的3D重建", "title_en": "MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses", "authors": "Jong-Ik Park,Carlee Joe-Wong,Gary K. Fedder", "background": "NeRF方法在利用多张二维图像进行3D重建方面表现出色，甚至对于未知相机姿态的图像也是如此。然而，NeRF方法仍然无法捕捉工业检测所需的精细结构，如生产线上低于微米级的缺陷检测或通过扫描电子显微镜（SEM）分析芯片。在这些场景中，传感器分辨率固定且计算预算紧张，因此通过添加高倍率图像来暴露精细结构是唯一的办法，但这破坏了无姿态NeRF训练依赖的多视图一致性。", "innovation": "我们提出了多倍率增强NeRF（MZEN），这是第一个能够原生处理多倍率图像集的NeRF框架。MZEN通过扩展针孔相机模型，引入了一个显式的可学习的缩放因子，并且采用了一种新的姿态策略：首先求解广角图像以建立全局度量框架，然后使用倍率一致的裁剪和匹配过程将高倍率图像的姿态定位到最近的广角图像，最后进行联合优化。MZEN在八种前方场景下的合成TCAD模型、实际的SEM微结构和BLEFF对象上的表现，均优于无姿态基线和高分辨率变体，提高了PSNR高达28%，SSIM高达10%，并降低了LPIPS高达222%。因此，MZEN将NeRF扩展到现实工厂环境，同时保留了全局准确性并捕捉了工业检测所需的微米级别细节。", "conclusion": "MZEN将NeRF技术扩展到了实际工厂设置中，通过处理多倍率图像集，能够在保留全局准确性的同时，捕捉到工业检测所需的微米级别细节。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05851", "html_url": "https://arxiv.org/abs/2508.05851", "title": "Temporal Cluster Assignment for Efficient Real-Time Video Segmentation", "title_en": "Temporal Cluster Assignment for Efficient Real-Time Video Segmentation", "authors": "Ka-Wai Yung,Felix J. S. Bragman,Jialang Xu,Imanol Luengo,Danail Stoyanov,Evangelos B. Mazomenos", "background": "视觉Transformer在图像和视频分割任务中显著提升了模型能力。Swin Transformer因其能捕捉多尺度层次表示而受到青睐，但其的计算成本依然较高，特别是在视频中的密集预测任务中更为显著。虽然已经提出了减少标记的方法来缓解这一问题，但Swin Transformer的基于窗口的注意力机制限制了传统的剪枝技术的应用。传统的无训练标记聚类方法在图像分割中表现良好，但未能利用时间冗余，这使得进一步优化视频分割表现变得困难。", "innovation": "本文提出了一种轻量级且高效的无需细调策略——时序聚类分配（TCA），通过利用帧间的一致性时间相关性来增强标记聚类。TCA 不是随意丢弃冗余标记，而是利用时序相关性来细化标记聚类，从而保留细粒度细节并显著减少计算。实验结果表明，TCA 有效地提升了现有基于聚类的方法在 YouTube-VIS 2019、YouTube-VIS 2021、OVIS 和一个私人手术视频数据集上的准确性和速度。", "conclusion": "TCA 能够有效地跨自然视频和特定领域视频增强时间一致性，从而在保持短时间内高精度方面表现出色。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05852", "html_url": "https://arxiv.org/abs/2508.05852", "title": "VISTA: 视觉-语言模仿情景思考和注意力在动态环境中的类人驾驶聚焦", "title_en": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments", "authors": "Kaiser Hamid,Khandakar Ashrafi Akbar,Nade Liang", "background": "自动驾驶和人机交互（HCI）研究中的驾驶员视觉注意力预测是一个关键任务。大多数先前的研究集中在时间点单一的注意力分配估算上，通常使用静态RGB图像（如驾驶场景图片）。", "innovation": "该工作提出了一种视觉-语言框架，该框架通过自然语言建模驾驶员注意力景观的变化，并通过人工迭代反馈优化BDD-A数据集的高质量描述。文中还微调了LLaVA模型，使其能够将视觉感知与注意力中心的场景理解相结合，整合低层次线索（如高光和阴影）与高层次语境（如路线语义、风险预测），实现基于语言的注视行为描述。该方法在训练体制（少样本、一样本）上的表现研究引入了领域特定的语义对齐和响应多样性指标。结果显示，经过微调的模型在注意力转移检测和可解释性上优于通用视觉语言模型。", "conclusion": "此为首次尝试将驾驶员的视觉注意力分配和转移预测转化为自然语言的方法，将为自动驾驶中的可解释人工智能提供新的方向。该方法为基础任务如行为预测、人机协同、多智能体协调提供了一个基础。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05783", "html_url": "https://arxiv.org/abs/2508.05783", "title": "预训练MRI变换器在脑影像任务中的少样本部署", "title_en": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks", "authors": "Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang", "background": "使用变压器的机器学习在医学影像中展现出巨大的潜力，但由于标注数据稀缺，其实用性仍然受限。本文研究在多元脑影像任务中，提出了一种实用的预训练MRI变换器框架，通过在大规模多队列脑MRI数据集上应用掩码自动编码器（MAE）预训练策略，获得泛化能力强的可迁移的潜变量表示。", "innovation": "提出了一种利用大规模多队列脑MRI数据集进行掩码自动编码器（MAE）预训练的框架，应用于多元脑影像任务中。针对不同层级的任务，分别提出冻结MAE编码器结合轻量级线性头，以及MAE-Funet混合架构，该混合架构在数据受限条件下， Skull Stripping 和多分类解剖分割任务上都展现了优越性能。", "conclusion": "通过大量定量和定性评估，该框架在效率、稳定性和可扩展性上表现出色，表明其适用于资源有限的临床环境和更广泛的神经影像学应用。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05898", "html_url": "https://arxiv.org/abs/2508.05898", "title": "ETTA: 动态嵌入更新实现视觉语言模型的高效测试时自适应", "title_en": "ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates", "authors": "Hamidreza Dastmalchi,Aijun An,Ali cheraghian", "background": "预训练的视觉-语言模型（VLMs）如CLIP在零样本性能上表现出色，但在分布转移下的泛化能力存在不足。Test-Time Adaptation (TTA) 方法通过将VLMs 调整到未标记的测试数据来解决这一问题，特别是在新领域。尽管某些TTA方法依赖于提示调整，但无训练的基于缓存的方法因效率较高而更受欢迎。然而，现有的基于缓存的TTA模型仅存储一小部分高置信度样本，这限制了决策边界，并忽略了其他测试数据的影响。", "innovation": "该研究提出了Efficient Test-Time Adaptation (ETTA)，引入了一个递归更新模块，该模块能够整合所有来的测试样本，逐步细化决策边界，模拟了一个无界缓存，动态更新上下文嵌入，以提高准确性并减少内存和计算开销。ETTA还包含一个自适应集成模块，可以减少图像到文本分数的提示依赖性，通过动态选择最优提示来为每个类别降低提示依赖性。此外，它还根据置信度级别适应性地组合两个模块的得分，利用它们的互补优势。实验结果表明，ETTA在计算复杂性和准确性上超越了最先进的TTA模型，成为有效且高效的测试时间自适应的新标准。", "conclusion": "通过广泛的实验，研究发现ETTA模型在两个基准测试中在计算复杂性和准确性方面都超越了最先进的TTA模型，确立了有效的、高效的测试时自适应的新标准。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05813", "html_url": "https://arxiv.org/abs/2508.05813", "title": "无需优化的3D高斯斑点风格迁移", "title_en": "Optimization-Free Style Transfer for 3D Gaussian Splats", "authors": "Raphael Du Sablon,David Hart", "background": "许多先前的研究已经探索了3D高斯斑点的风格迁移任务，但这些方法往往需要在引入风格信息或优化特征提取网络时重新构建或微调斑点。这项工作旨在提出一种无需重建或优化的3D高斯斑点风格迁移方法。通过在表示隐含曲面的图形结构上生成连接，随后使用基于表面的前馈风格化方法并插值回场景中的单个斑点，这种方法使得可以在不进行额外训练或优化的情况下使用任何风格图像和3D高斯斑点，同时也能够实现快速的风格化，即使在消费级硬件上也能在不到2分钟的时间内完成。", "innovation": "本文提出了一种无需优化和重建的方法来对3D高斯斑点进行风格化。通过生成一个跨隐含曲面的图形结构，然后使用基于表面的前馈风格化方法并应用于单个斑点，这种方法不需要额外的训练或优化步骤，同时还能实现快速风格化。", "conclusion": "这种风格化方法能够实现高质量的结果，并且具有快速风格化的优点，能够在消费级硬件上达到每份几秒钟到不足2分钟的速度。还通过与其他基于3D高斯斑点风格迁移方法的比较，说明了该方法的有效性。相关代码已经公开发布。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05689", "html_url": "https://arxiv.org/abs/2508.05689", "title": "利用残差扰动攻击增强对抗样本转输能力", "title_en": "Boosting Adversarial Transferability via Residual Perturbation Attack", "authors": "Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang", "background": "深度神经网络容易受到对抗样本的影响，在不被察觉的小扰动下产生错误预测。转移攻击在未知目标模型的情况下，通过受器模型生成对抗样本并转移到目标模型中。以往研究发现，在平坦损失景观中的对抗样本具有更好的转移性，但忽视了扰动方向的影响，导致转移性有限。因此，需要一种新的攻击方法来增强这种特性，增强样本在转移过程中的鲁棒性和有效性。", "innovation": "提出了一种名为残差扰动攻击（ResPA）的新方法，利用残差梯度作为扰动方向，引导对抗样本向损失函数的平坦区域发展。ResPA通过指数移动平均输入梯度得到参考梯度，考虑当前梯度与参考梯度之间的残差来捕捉全局扰动方向的变化。实验结果表明，ResPA的传输能力优于现有典型的转移攻击方法，结合当前输入变换方法可以进一步提高传输能力。", "conclusion": "ResPA通过利用残差梯度作为扰动方向，增强了对抗样本的转移性，改进了现有技术的局限性。通过与现有输入变换方法结合，可以进一步优化传输效果。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05772", "html_url": "https://arxiv.org/abs/2508.05772", "title": "MAISI-v2：利用校正流和区域特定对比损失实现加速高分辨率3D医疗图像合成", "title_en": "MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss", "authors": "Can Zhao,Pengfei Guo,Dong Yang,Yucheng Tang,Yufan He,Benjamin Simon,Mason Belue,Stephanie Harmon,Baris Turkbey,Daguang Xu", "background": "医疗图像合成在临床和研究应用中具有重要意义。尽管最近扩散模型已成为这一领域的主要方法，但仍面临一些挑战，如通用性有限（仅适用于特定身体区域或体素间距）、推理速度慢以及与输入条件弱对齐的问题。此前提出的MAISI框架虽然解决了通用性问题，但在推理速度和条件一致性方面仍有不足。", "innovation": "本文提出MAISI-v2，这是一种加速的3D医疗图像合成框架，通过整合校正流来实现快速和高质量的生成。为增强条件保真度，引入了一种新的区域特定对比损失，以提高对感兴趣区域的敏感性。实验结果表明，MAISI-v2可以实现最先进的图像质量，并且对于潜在扩散模型的速度提升了33倍。同时，通过下游分割实验展示了合成图像在数据增强中的应用潜力。作者还发布了代码、训练细节、模型权重和GUI演示，以促进科学界进一步的研究。", "conclusion": "实验结果显示，MAISI-v2在保持高质量合成图像的同时，实现了显著加速，并且合成图像可以用于数据增强。作者通过分享详细的代码和资源，期望促进该领域的进一步研究与应用发展。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05903", "html_url": "https://arxiv.org/abs/2508.05903", "title": "Robust Image Stitching with Optimal Plane", "title_en": "Robust Image Stitching with Optimal Plane", "authors": "Lang Nie,Yuan Mei,Kang Liao,Yunqiu Xu,Chunyu Lin,Bin Xiao", "background": "本文介绍了RopStitch，这是一个具有鲁棒性和自然性的无监督深度图像拼接框架。背景在于传统的图像拼接方法往往在处理多样且未见过的真实场景时表现出色性不足，特别是在场景鲁棒性和内容自然度方面存在局限性。针对这一问题，RopStitch通过引入内容感知的先验知识，以双分支架构分别捕获粗略和精细特征并集成，实现了广泛适用的表现。另外，考虑到内容对齐和结构保持常常是相互矛盾的目标，提出了一种虚拟最优平面的概念来缓解这种冲突。通过估计霍夫曼系数和设计迭代系数预测器，最终将两个视图双向映射到最优平面上，进一步提高了方法的鲁棒性和自然度。", "innovation": "RopStitch的主要创新点在于：1) 引入双分支架构，分别捕获粗略和精细特征；2) 基于虚拟最优平面的概念，改进了内容对齐和结构保持之间的平衡；3) 通过迭代系数预测器和最小语义扭曲约束来确定最优平面，增强了方法的鲁棒性和自然度。", "conclusion": "实验结果表明，RopStitch相比于现有方法，在场景鲁棒性和内容自然度方面有显著提升。目前，该方法已在多种数据集上进行了广泛的实验并取得了优异的效果。相关代码已开放获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05922", "html_url": "https://arxiv.org/abs/2508.05922", "title": "利用3D分割增强建筑工地的分析与理解", "title_en": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation", "authors": "Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang", "background": "监测建筑进度至关重要但资源密集，促使研究人员探索基于计算机视觉的方法以提高效率和可扩展性。传统的数据采集方法主要集中在室内环境上，在建筑工地这样的复杂、拥挤且不断变化的环境中表现不佳。", "innovation": "该研究利用Segment Anything Model（SAM）和Mask3D这两种先进的3D分割方法，在挑战性的室内和室外条件下进行评估。尽管这两种模型最初是在室内数据集上训练的，但它们在实际建筑环境中的适应性和性能也得到了验证，揭示了当前分割方法在户外场景中的不足。通过比较分析，该研究不仅展示了SAM和Mask3D的相对有效性，还强调了需要定制分割工作流以从建筑工地数据中提取可操作的洞见，推动了该领域向着更自动化和精确的监测技术发展。", "conclusion": "研究不仅对比了SAM和Mask3D的有效性，还指出了当前需要定制的工作流，以能够从建筑工地数据中提取可操作的信息，为建筑工地的自动化和精确监测提供了一种新途径。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05899", "html_url": "https://arxiv.org/abs/2508.05899", "title": "HOLODECK 2.0：基于视觉语言的3D世界生成与编辑", "title_en": "HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing", "authors": "Zixuan Bian,Ruohan Ren,Yue Yang,Chris Callison-Burch", "background": "3D场景生成在游戏、艺术创作、虚拟现实和其他领域中发挥着重要作用。然而，目前的3D场景设计仍然主要依赖于创作者的大量手工劳动，现有的自动化方法难以生成开放领域场景或支持灵活编辑。因此，直接从文本生成3D世界引起了越来越多的关注。现有的方法无法很好地将详细的文本描述转化为高语义准确性的3D场景，尤其是在处理多种风格和开放领域环境时表现不佳。HOLODECK 2.0提供了一种基于视觉语言模型的3D世界生成框架，结合了先进的自动编辑功能，可以根据人类反馈进行交互式场景编辑。这种框架能够生成多样且风格丰富的3D场景，并能在室内和开放领域环境中保持高语义一致性。HOLODECK 2.0使用视觉-语言模型识别场景所需的对象，通过最新的3D生成模型生成高质量的对应资产，然后通过语义和物理约束进行迭代生成，确保场景在语义上一致且物理上合理。", "innovation": "HOLODECK 2.0引入了一种支持交互式场景编辑的视觉语言引导3D世界生成框架，能够生成多种风格的3D场景（如现实风格、卡通风格、动漫风格和赛博朋克风格），保持高语义精密度，并能根据详细的文本描述进行编辑和定制。该框架使用视觉语言模型来识别并解析生成所需的对象，并通过最先进的3D生成模型生成高质量的对应资产。然后，通过语义和物理约束来进行迭代生成，实现语义上一致且物理上合理的布局。HOLODECK 2.0通过人类评估和CLIP评估，被证明能够更加有效地根据详细的文本描述生成高质量的场景，一致优于现有基准方法，同时提供了灵活适应人类反馈的编辑功能，支持布局的优化以及风格一致的对象编辑。此外，HOLODECK 2.0还在程序化游戏建模中展示了实际应用，可以生成丰富且沉浸的游戏环境，可能提高效率。", "conclusion": "HOLODECK 2.0是一个具有高度灵活性和精度的视觉-语言引导的3D世界生成与编辑框架。它能够生成多种风格的3D场景，且高度匹配详细的文本描述，与现有的标准方法相比具有明显的优势。HOLODECK 2.0为3D场景的自动生成与定制提供了新的解决方案，能够在多种场景中提升效率和质量。该框架的引入不仅解决了当前3D场景生成中的主要问题，还提供了一种新的、更有效的生成方法，具有广泛的应用前景。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05857", "html_url": "https://arxiv.org/abs/2508.05857", "title": "多视角注视目标估计", "title_en": "Multi-view Gaze Target Estimation", "authors": "Qiaomu Miao,Vivek Raju Golani,Jingyi Xu,Progga Paromita Dutta,Minh Hoai,Dimitris Samaras", "background": "现有的单视角方法在估计注视目标时面临诸如面部遮挡、目标模糊和不在视野中的目标等挑战，这限制了其准确性和适用范围。", "innovation": "本文提出了一种利用多视角摄像头信息的方法，通过集成不同视角之间的信息来提高准确性和扩展适用性。方法包括Head Information Aggregation (HIA) 模块、Uncertainty-based Gaze Selection (UGS) 和 Epipolar-based Scene Attention (ESA) 模块，能够显著优于单视角基线方法，特别是当第二个摄像头可以清晰地看到人脸时。此外，该方法还能够仅使用第二个摄像头的图像来估计第一个摄像头视角下的注视目标，这一功能是单视角方法所不具备的。", "conclusion": "本文还介绍了一个多视角数据集，用于开发和评估多视角注视目标估计方法，相关数据和代码可以在指定的网址获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05954", "html_url": "https://arxiv.org/abs/2508.05954", "title": "Bifrost-1: 使用像素级CLIP潜在变量连接多模态LLMs和扩散模型", "title_en": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "authors": "Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal", "background": "近年来，人们越来越关注将高保真视觉合成能力整合到大规模语言模型（LLMs）中，而不会影响其强大的推理能力。现有的方法通常直接训练LLMs或通过桥梁将LLMs与扩散模型相连，但由于这些模型在预训练时未见过图像表示，因此会导致成本高昂的训练。", "innovation": "本文提出了Bifrost-1框架，这是一种统一框架，通过与多模态预训练LLMs（MLLMs）和扩散模型的像素级别CLIP图像嵌入作为潜在变量对接，来实现这一目标。该框架通过引入了对更新扩散模型的ControlNet的轻量级适应，以及使得MLLM在预测像素级别图像嵌入时拥有一个视觉生成分支，从而保留了MLLM的多模态推理能力。这种方法有效地融合了预训练的LLM和扩散模型中的像素级别CLIP潜在变量，从而实现了高保真度可控图像生成，并具有明显的训练效率。", "conclusion": "实验表明，Bifrost-1在视觉保真度和多模态理解方面与以往方法相比达到同等或更好的性能，同时训练过程中计算量显著减少。此外，本文还提供了全面的消融研究，证明了设计选择的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05976", "html_url": "https://arxiv.org/abs/2508.05976", "title": "PASG: 一种用于机器人操作中自动几何基元提取和语义锚定的闭环框架", "title_en": "PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation", "authors": "Zhihao Zhu,Yifan Zheng,Siyu Pan,Yaohui Jin,Yao Mu", "background": "在机器人操作中，高层任务语义与底层几何特征的碎片化问题一直存在。尽管视觉语言模型（VLMs）在生成感知可用性的视觉表示方面显示出前景，但缺乏在标准空间中的语义定位以及依赖于手动注释，严重限制了它们捕捉动态语义-可用性关系的能力。", "innovation": "本文提出了Primitive-Aware Semantic Grounding（PASG）框架，该框架包括：1. 通过几何特征聚合自动提取基元，实现跨类别关键点和轴的检测；2. VLM驱动的语义锚定，动态耦合几何基元与功能性可用性及任务相关的描述；3. 空间-语义推理基准和 fine-tuned VLM（Qwen2.5VL-PA）。PASG在多样场景下的实际机器人操作任务中展示了效果，性能与人工注释相当，建立了几何基元与机器人操作任务语义之间统一的桥梁", "conclusion": "PASG 以更细粒度的方式理解对象的语义可用性，为构建机器人操作中几何基元与任务语义之间的统一框架奠定了基础。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05907", "html_url": "https://arxiv.org/abs/2508.05907", "title": "基于移动计算摄影的神经场表示", "title_en": "Neural Field Representations of Mobile Computational Photography", "authors": "Ilya Chugunov", "background": "在过去二十年里，移动成像经历了深刻的变革，手机的数字摄影流行度迅速超过了其他形式的摄影。现代手机集成了多种成像技术，比如激光测距、多焦点相机阵列、分裂像素传感器，同时还配备了陀螺仪、加速度计和磁力计等非视觉传感器。这些设备结合了内置的图像和信号处理芯片，使手机成为一个多功能的便携式计算成像平台。与此同时，近年来有研究表明，神经场——通过训练小型神经网络来将连续的空间输入坐标映射到输出信号——能够重建复杂的场景，而无需使用像像素阵列或点云这样的明确数据表示。这项研究通过精心设计的神经场模型，能够紧凑地表示复杂的几何形状和光照效果，从而使从野外收集的手机摄影作品直接应用于深度估计、层分离和图像拼接等应用，而这些方法能够超越当前最先进的技术，无需复杂的预处理步骤、标记的真实数据或机器学习先验知识，而是借助良好构造的、自我正则化模型，在随机梯度下降法的引导下，直接拟合智能手机的原始测量数据来解决这些难题.", "innovation": "这项研究通过精心设计的神经场模型，能够紧凑地表示复杂的几何形状和光照效果，从而使从野外收集的手机摄影作品直接应用于深度估计、层分离和图像拼接等应用。他们利用了良好的构造、自我正则化模型，以解决在智能手机测量数据基础上的复杂逆向问题，这种方法超越了当前最先进的技术，无需复杂预处理、标记的真实数据或机器学习先验知识的依赖，而是直接拟合来自智能手机的原始测量数据.", "conclusion": "这些方法在实现从野外收集的手机摄影作品进行深度估计、层分离和图像拼接等应用方面表现出色，且无需依赖复杂的预处理步骤、标记的真实数据或机器学习先验知识。该研究通过精心设计的神经场模型实现了这些效果，这些模型通过随机梯度下降直接拟合智能手机的原始测量数据来应对复杂的逆向问题。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05755", "html_url": "https://arxiv.org/abs/2508.05755", "title": "UnGuide：借助LoRA调控扩散模型学习遗忘", "title_en": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models", "authors": "Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek", "background": "近年来，大规模文本到图像的扩散模型取得了显著进步，但同时也引发了对这些模型潜在误用的担忧，尤其是在生成有害或误导性内容方面。这突显了有效机器遗忘（即，从预训练模型中移除特定知识或概念而不影响整体性能）的迫切需求。一种可能的方法是低秩适应（LoRA），它提供了一种高效的方式对模型进行细调以实现目标性遗忘。然而，LoRA经常无意中改变不相关的内容，导致图像清晰度和现实感降低。", "innovation": "本文引入了UnGuide——一种新的方法，通过引入UnGuidance动态推理机制，利用分类器无指导（CFG）来精确控制遗忘过程。UnGuide基于去噪过程的稳定性调整引导尺度，使LoRA适配器能够选择性地遗忘特定概念。对于包含被删除概念的提示，LoRA模块起主导作用，同时被基础模型平衡；对于不相关的提示，基础模型控制生成过程，保持内容的清晰度。实验证明，UnGuide实现了有控制的概念移除，并保留了扩散模型的表达能力，优于现有的基于LoRA的方法。", "conclusion": "UnGuide能够在删除特定概念的同时，保留扩散模型的表达能力，表现出色，在对象擦除和明确内容移除任务中均优于现有基于LoRA的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05990", "html_url": "https://arxiv.org/abs/2508.05990", "title": "高效运动估计和上下文感知细化在Bayer域高效视频视觉中的应用", "title_en": "Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision", "authors": "Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han", "background": "视频计算机视觉系统的效率是一个挑战性问题，因为视频具有高时间冗余。已有研究试图提高效率，但未能充分降低时间冗余，且忽视了前端计算开销。", "innovation": "提出了一种高效的视频计算机视觉系统，包括去除图像信号处理器并直接输入 Bayer 格式数据以节省前端计算，提出了快速块匹配式的运动估计算法并引入运动矢量细化模块，以及上下文感知块细化网络来修正大误差区域，并采用帧选择策略来平衡准确性和效率。", "conclusion": "在多个视频计算机视觉任务上的实验表明，该方法能够在保持轻微性能损失的前提下实现显著加速。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06009", "html_url": "https://arxiv.org/abs/2508.06009", "title": "MathReal: We Keep It Real! 一个多模态大型语言模型的现实场景基准用于评估数学推理", "title_en": "MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models", "authors": "Jun Feng,Zixin Wang,Zhentao Zhang,Yue Guo,Zhihan Zhou,Xiuyi Chen,Zhenyang Li,Dawei Yin", "background": "现有的多模态大型语言模型（MLLMs）已经在各种基准测试中展示了出色的视觉数学推理能力，但这些基准主要基于干净或处理过的多模态输入，并未包含真正的K-12教育用户提供的图像。因此，存在改进的空间。", "innovation": "论文提出了一套名为MathReal的数据集，包含2000个带有手持移动设备拍摄的真实场景图像的数学问题。这些图像分类为三类问题：图像质量退化、视角变化、无关内容干扰，并进一步细分为14个子类别。数据集还涵盖五个核心知识和技能领域，划分成三种问题类型和三个难度级别，以全面评估MLLMs在现实教育场景中的多模态数学推理能力。", "conclusion": "通过数学推理实验，研究发现现有的MLLMs在真实教育环境中的问题解决能力受到了挑战。研究者分析了模型的性能和错误模式，提供了对其识别、理解和推理能力的见解，并指出了改进的方向。此外，数据和代码可以在这个链接中找到：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05950", "html_url": "https://arxiv.org/abs/2508.05950", "title": "单一图像三维Gauss点扩散自监督框架用于法线估计", "title_en": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image", "authors": "Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li", "background": "从单张图像估计空间维度信息的法线仍然是一个挑战。尽管基于扩散的方法在从2D到3D的隐式映射方面显示出巨大潜力，但这些方法依赖于数据驱动的统计先验，缺少对光-表面相互作用的明确建模，导致多视角法线方向冲突。此外，扩散模型的离散采样机制导致不同可微渲染重构模块中的梯度不连续，阻止了3D几何错误的反向传播到法线生成网络，使得现有方法依赖于密集的法线注释。", "innovation": "本文提出了一种名为SINGAD的新颖自监督框架，从单张图像出发，利用3D Gauss点扩散引导的扩散，直接将3D几何错误转化为法线优化信号，解决了多视角几何不一致性和数据依赖性问题。该框架整合了基于光相互作用的物理驱动下的3D GS重参数化模型，生成与光传输原则一致的多尺度几何特征，确保多视角法线的一致性。通过条件扩散模型中的跨域特征融合模块，嵌入几何先验以约束法线生成，同时保持几何误差的准确传递，并引入了可 differential 的三维重构损失策略，以自监督优化为目标，最小化重建和输入图像之间的几何误差，消除了对注释法线数据集的依赖。", "conclusion": "在Google扫描对象数据集上的定量评估表明，该方法在多个指标上优于最新方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05991", "html_url": "https://arxiv.org/abs/2508.05991", "title": "ECMF: 增强跨模态融合用于MER-SEMI挑战中的多模态情感识别", "title_en": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "authors": "Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong", "background": "情感识别在提升人机交互方面发挥着重要作用。在MER2025竞赛中，我们面临MER-SEMI挑战，旨在克服数据稀缺的问题，提出了一种新的多模态情感识别框架，该框架利用大规模预训练模型从视觉、音频和文本模态中提取具有信息性的特征，以促进多模态特征的有效整合。", "innovation": "我们设计了一种双分支视觉编码器来捕获全局帧级特征和局部面部表示，并引入了一种借助大型语言模型增强文本输入中情感线索的上下文增强方法。此外，我们提出了一种融合策略，包括自注意力机制以实现动态模态权重分配和残差连接以保持原始表示。我们进一步通过多源标签策略对训练集中的噪声标签进行了细化。这些创新有效地整合了多种模态，增强了模型性能。", "conclusion": "在MER2025-SEMI数据集上，与官方基线相比，我们的方法在加权F分数上取得了显著的改进，达到87.49%，比基线的78.63%提高了许多，验证了所提框架的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06014", "html_url": "https://arxiv.org/abs/2508.06014", "title": "ExploreGS: 使用虚拟相机采样和扩散先验的可探索3D场景重建", "title_en": "ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors", "authors": "Minsu Kim,Subin Jeon,In Cho,Mijin Yoo,Seon Joo Kim", "background": "最近在新型视角合成（NVS）方面取得的进展使得基于3D高斯点渲染成为实时渲染的可能。然而，现有的方法在渲染偏离训练视图轨迹的新视角时会产生伪影和缺失区域，从而限制了无缝场景探索。", "innovation": "提出的基于3D高斯点生成的管道通过增加额外的训练视角来增强重建，通过信息增益驱动的虚拟相机布局策略最大化场景覆盖率，随后使用视频扩散先验细化渲染结果。这些增强视图的3D高斯的微调显著提高了重建质量。通过Wild-Explore基准评估该方法，实验证明该方法优于现有的基于3D高斯点的方法，能够从任意视角进行高质量、无伪影的渲染。", "conclusion": "通过ExploreGS方法，提出了可探索的3D场景重建，该方法包括虚拟相机取样和扩散先验的研究，从而在任意视角下实现高质量、无伪影的渲染。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05982", "html_url": "https://arxiv.org/abs/2508.05982", "title": "AnimateScene: 在任意场景中的相机可控动画", "title_en": "AnimateScene: Camera-controllable Animation in Any Scene", "authors": "Qingyang Liu,Bingjie Gao,Weiheng Huang,Jun Zhang,Zhongqian Sun,Yang Wei,Zelin Peng,Qianli Ma,Shuai Yang,Zhaohe Liao,Haonan Zhao,Li Niu", "background": "近年来，三维场景重建和四维人体动画取得了快速的进步，并被广泛应用。然而，将重建的场景与四维人体动画无缝融合以产生视觉上吸引人的结果仍然具有挑战性。主要困难在于将人体准确地放置在场景中的正确位置和比例，并避免出现不现实的穿透情况。此外，人体和背景可能具有不同的光照和风格，导致不可靠的图像合成。此外，引人入胜的人物运动视频通常伴随着摄像机运动，这意味着需要沿着指定的轨迹重建视点。", "innovation": "我们提出了一种名为AnimateScene的新框架，以统一方式解决上述问题。首先，设计了一个精确放置模块，自动确定人体在三维空间中的合理位置，并在运动过程中防止穿透场景。其次，提出了一种无需训练的风格对齐方法，使四维人体表示适应背景的光照和风格，实现视觉上的一致集成。最后，设计了一个联合后处理方法，用于场景中的四维人体和三维场景，允许插入摄像机轨迹，使最终渲染的视频具有视觉上吸引力的摄像机运动。", "conclusion": "大量的实验表明，AnimateScene能够生成具有高几何细节和跨多种摄像机和动作组合的空间时间一致性的动态场景视频。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05989", "html_url": "https://arxiv.org/abs/2508.05989", "title": "ETA: 能量基础的测试时自适应方法用于深度完成", "title_en": "ETA: Energy-based Test-time Adaptation for Depth Completion", "authors": "Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong", "background": "深度完成模型在训练于某一特定数据集（源数据）后，当迁移到新的环境条件（目标数据）下时，往往会预测出错误的结果。这是因为环境条件的变化导致了分布的变化（协变量偏移）。源数据的分布与目标数据的分布之间的差异是主要挑战之一，尤其是在无法获取目标数据（即分布外数据）的情况下。在这种背景下，该研究旨在提出一种方法来适应测试时的深度完成模型，以减少这种偏差的影响。", "innovation": "该研究的核心在于开发了一种能量模型方法，用于评估深度预测属于源数据分布或多源数据分布的概率。通过利用对抗性扰动来探索数据空间，这种方法能够指导深度完成模型在测试时调整其参数，使测试时输出接近源数据的分布，而非假设目标数据的具体分布。这一方法被命名为“能量基础的测试时自适应”（ETA），并已在三个室内和三个室外数据集上进行了评估。结果显示，与最先进的方法相比，ETA分别提高了室外数据集6.94%和室内数据集10.23%的表现。", "conclusion": "这种方法通过对抗性方法和能量模型，实现了在未知目标数据分布的情况下，有效调整深度完成模型的预测结果，显著提高了模型在不同环境条件下的一致性和准确性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06044", "html_url": "https://arxiv.org/abs/2508.06044", "title": "NEP: 自回归图像编辑通过下一个编辑标记预测", "title_en": "NEP: Autoregressive Image Editing via Next Editing Token Prediction", "authors": "Huimin Wu,Xiaojian Ma,Haozhe Zhao,Yanpeng Zhao,Qing Li", "background": "文本引导的图像编辑涉及根据语言指令修改源图像，并通常只对小区域进行修改。然而，现有的方法生成整个目标图像而非仅再生需要编辑的部分区域，这导致了不必要的计算成本，并倾向于重构非编辑区域，从而降低了所需编辑质量。", "innovation": "该研究提出了基于自回归图像生成的下一代编辑标记预测（NEP），只需再生需要编辑的区域，避免对非编辑区域的意外修改。为此，他们预训练了一个任意顺序的自回归文本到图像（T2I）模型，该模型能够在零样本情况下进行图像编辑，并且能够通过在零样本情况下迭代细化生成来处理测试时缩放。", "conclusion": "该模型在广泛使用的图像编辑基准上达到了新的最先进水平，并且自然支持测试时缩放（TTS）。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06055", "html_url": "https://arxiv.org/abs/2508.06055", "title": "LV-Net：具有案例研究的阿尔茨海默病中基于解剖的侧脑室形状建模，澳洲成像生物标志物和生活方式老年旗舰研究", "title_en": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing", "authors": "Wonjung Park,Suhyun Ahn,Jinah Park(for the Alzheimer's Disease Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing)", "background": "侧脑室（LV）形状分析有望成为神经系统疾病的生物标志物，但因个体间显著的形状变异性和由于MRI分辨率有限而产生的分割困难导致的边界分割伪影，带来了挑战。LV-Net通过将一个解剖学意识联合LV-海马模板网格变形，为脑MRI生成个体化的3D LV网格。", "innovation": "LV-Net引入了一种新颖的方法，通过解剖学相关的顶点分类，提高了顶点在不同个体之间的对应性，进而更准确地重建LV形状统计。该方法即使在存在分割不完美的情况下，也能实现更高的重建准确性，并为不同数据集提供更可靠的形状描述符。此外，LV-Net应用于阿尔茨海默病分析，识别与疾病显著相关的LV亚区域。", "conclusion": "LV-Net实现了最优的LV形状重建，即使在分割不完美的情况下也能提供可靠的形状描述符。并成功应用于阿尔茨海默病的研究中，识别出相关于疾病的LV亚区域。相关代码可在如下网址获取：this https URL"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06051", "html_url": "https://arxiv.org/abs/2508.06051", "title": "VQAThinker: 通过强化学习探索可解释和可推广的视频质量评估", "title_en": "VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning", "authors": "Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Jun Jia,Kaiwei Zhang,Dandan Zhu,Guangtao Zhai,Xiongkuo Min", "background": "视频质量评估（VQA）旨在客观量化与人类视觉感知一致的质量降级。尽管取得了进展，现有的VQA模型仍然存在两个关键局限：对不同分布（OOD）视频的通用性差和解释性有限，这限制了它们在实际场景中的应用。", "innovation": "提议VQAThinker，这是一种基于推理的VQA框架，利用大型多模式模型（LMMs）和强化学习共同建模视频质量理解和评分，模仿人类感知决策。具体采用了组相对策略优化（GRPO），这是一种规则引导的强化学习算法，能在评分监督下对视频质量进行推理。此外，还引入了三种VQA特定奖励：以高斯形回归奖励、对列排名奖励和时间一致性奖励来分别引导模型预测视频质量、正确确定视频对之间的相对质量以及偏好相干性更优的视频。", "conclusion": "广泛的实验结果表明，VQAThinker在有域和无域VQA基准测试中达到最先进的性能，展现出强大的视频质量评分的一般性。此外，对视频质量理解任务的评估显示，在失真归因和质量描述方面优于现有的可解释的VQA模型和LMMs。这些发现证实了仅通过评分监督使用强化学习构建可推广和可解释的VQA模型的有效途径。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05994", "html_url": "https://arxiv.org/abs/2508.05994", "title": "EvoMakeup: 高保真度和可控性面部化妆编辑，借助 MakeupQuad", "title_en": "EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad", "authors": "Huadong Wu,Yi Fu,Yunhao Li,Yuan Gao,Kang Du", "background": "面部化妆编辑旨在将参考面部的化妆真实地转移至目标面部。现有方法通常会导致低质量的结果，细节粗糙，难以同时保持身份和化妆细节的真实性。这主要是由于缺乏结构化的配对数据，即源图像和结果共享身份，参考图像和结果共享相同的化妆细节。为进一步解决此问题，该研究提出了一种名为 MakeupQuad 的大规模高质量数据集，其中包括未化妆的面部、参考图像、编辑后的结果以及文本化妆描述。", "innovation": "该研究引入了 MakeupQuad 数据集，并提出了统一训练框架 EvoMakeup，该框架在多阶段蒸馏过程中减轻了图像劣化，可以迭代提高数据和模型质量。尽管仅使用合成数据进行训练，但 EvoMakeup 在现实世界基准测试中表现出色且优于先前的方法。该方法支持高保真度、可控性、多任务面部化妆编辑，包括完整面部和部分参考基底编辑，以及文本驱动的面部化妆编辑，均在一个模型中实现。实验结果显示，该方法在化妆保真度和身份保持方面取得了优越的性能，有效平衡了两方面的需求。", "conclusion": "我们的方法在化妆保真度和身份保持方面表现出优越的性能，有效平衡了这两种方面。我们将在论文接受后发布代码和数据集。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06033", "html_url": "https://arxiv.org/abs/2508.06033", "title": "InstantEdit: 使用片段正交流的文本引导式多步图像编辑", "title_en": "InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow", "authors": "Yiming Gong,Zhen Zhu,Minjia Zhang", "background": "提出了一个基于RectifiedFlow框架的快速文本引导图像编辑方法——InstantEdit，该方法通过几个步骤的编辑流程，在遵循文本指令的同时保留关键内容。为了保持RectifiedFlow模型的一致性和可编辑性结果，提出了一种新颖的再生方法——Inversion Latent Injection，该方法有效利用了反向求解过程中获取的潜在信息，以促进更连贯和详细的再生。此外，提出了解藕提示指导技术，平衡编辑能力和细节保存，并结合Canny条件化的ControlNet，引入结构线索并抑制伪影，从而提高图像编辑的质量和效果。", "innovation": "InstantEdit的主要创新点在于引入了PerRFI（特殊逆变换策略），利用RectifiedFlow的直采样轨迹；提出了Inversion Latent Injection再生方法，有效利用反向求解中获得的潜在信息；开发了Disentangled Prompt Guidance技术，实现了编辑能力和细节保存的平衡；集成Canny条件化的ControlNet，整合结构线索以减少伪影。", "conclusion": "在 PIE 图像编辑数据集上的评估表明，InstantEdit 不仅速度快，还在定性和定量结果方面优于最先进的多步图像编辑方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06032", "html_url": "https://arxiv.org/abs/2508.06032", "title": "学习3D纹理感知表示以解析多样化的人类衣物和身体部分", "title_en": "Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts", "authors": "Kiran Chhatre,Christopher Peters,Srikrishna Karanam", "background": "现有的人体分割方法通常使用固定的掩码类别和广泛的标签，掩盖了精细的服装类型。最近的开放式词汇分割方法利用预训练的文本到图像（T2I）扩散模型特征实现强大的零样本迁移，但通常将整个人体归为单一个人类别，未能区分多样化的服装或详细的体部。文章指出，现有的基于扩散模型的方法虽然在不同任务之间具有较好的泛化能力，但它们的内部表示并不专门针对详细的人体分割。图片驱动的3D纹理生成器在输入图像上保持忠实的对应关系，从而使解析多样化服装和体部特征时获得更强的表示。", "innovation": "文章提出了Spectrum，这是一种统一的网络，用于对人体部分像素分割（体部和衣物）和实例级分组。Spectrum通过对三维人体纹理图进行微调的图像到纹理（I2Tx）扩散模型进行创新性地重构，从而使内部表示能够更好地对齐到体部和衣物上。该模型可以通过提示指导的视觉感知从输入图像中提取人体部分的内部特征，生成与多样化服装类别对齐的语义有效掩码。在训练完成之后，Spectrum可以为场景中任意数量的人物生成每个可见体部和服装类别的语义分割图，忽略了独立服装或无关物体。实验证明，Spectrum在基于提示的分割任务中始终优于基线方法。", "conclusion": "Spectrum模型在多数据集上的跨数据集实验中表现优异，能够一致地超越基线方法，特别是在人体部分分割、服装部分分割、未见过的服装类别和全身掩码方面。该方法成功地解决了传统方法在精细人体解析上的局限性，通过改进的内部表征实现了对多样化人体服装的高精度分割。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06058", "html_url": "https://arxiv.org/abs/2508.06058", "title": "轻量化Quad Bayer HybridEVS去马赛克方法基于状态空间增强交叉注意力", "title_en": "Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention", "authors": "Shiyang Zhou,Haijin Zeng,Yunfan Lu,Yongyong Chen,Jie Liu,Jingyong Su", "background": "事件相机如Hybrid Event-based Vision Sensor (HybridEVS) 通过异步“事件”而不是帧来捕捉亮度变化，适合移动摄影。但是，将具有颜色信息的Quad Bayer色滤波阵列(CFA)传感器与缺乏颜色信息的事件像素结合使用时，会导致去马赛克过程中出现混叠和伪影问题，这在资源受限的移动设备上难以克服。", "innovation": "提出了一种轻量级的TSANet（Two-stage网络通过State空间增强交叉-Attention）方法，能够分别处理事件像素填补和去马赛克，通过将复杂任务分解为可管理的子任务来利用其优势。进一步引入了轻量级Cross-Swin State Block，该模块通过状态空间模型利用位置先验信息增强全局依赖性，具有线性复杂度。", "conclusion": "TSANet 在模拟和真实HybridEVS数据上均表现出色的去马赛克性能，保持了轻量级模型，PSNR和SSIM指标下分别比前一个最先进的方法DemosaicFormer提高了1.86倍和3.29倍的参数和计算成本，展示了在移动设备上进行高效图像去马赛克的新可能性。代码附在补充材料中。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06076", "html_url": "https://arxiv.org/abs/2508.06076", "title": "基于MR的Trochleoplasty手术规划", "title_en": "Towards MR-Based Trochleoplasty Planning", "authors": "Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin", "background": "目前治疗Trochlear Dysplasia (TD)主要依赖于低分辨率的临床磁共振（MR）扫描和手术直觉。手术计划依赖于外科医生的经验，使用传统微创技术有限，导致结果不一致。", "innovation": "本文提出了一种生成从常规临床MR扫描中获得的超分辨率和患者特异性3D伪健康目标形态学的方法。首先是利用隐式神经表示（INR）计算一个等向性超分辨率的MR体积。其次，利用一个多标签的预先训练网络对股骨、胫骨、髌骨和腓骨进行分割。最后，训练一种小波扩散模型（WDM）生成Trochlear区域的伪健康目标形态学。与之前生成伪健康低分辨率3D MR图像的工作不同，本文的方法能够生成亚毫米分辨率的3D形状，这些形状可以用于预手术和术中使用。此外，与先前的工作不同，本文的方法不需要CT扫描，从而减少了辐射量。", "conclusion": "我们对25名TD患者的评估表明，我们的目标形态学显著改善了沟槽角（SA）和Trochlear沟的深度（TGD）。代码和交互式可视化可以在特定网址上获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06036", "html_url": "https://arxiv.org/abs/2508.06036", "title": "更多更好：基于Mixture of Experts的情感识别框架，结合人类偏好对齐", "title_en": "More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment", "authors": "Jun Xie,Yingjian Zhu,Feng Chen,Zhenghao Zhang,Xiaohui Fan,Hongzhu Yi,Xinming Wang,Chen Yu,Yue Bi,Zhaoran Zhao,Xiongjun Guan,Zhepeng Wang", "background": "本文的研究背景是在MER2025挑战中处理半监督学习任务。传统的情感识别系统大多依赖大量的标记数据，而现实情况中往往数据不足，且标签成本高昂。半监督学习通过利用未标记数据，旨在提高模型泛化能力和系统性能，特别是在资源有限的情况下。此外，情感表达是一种多模态现象，常见的情感识别方法通常局限于单一模态的数据，忽略了多种模态信息的互补优势。因此，需要一种全面且灵活的方法来融合各种输入模态，使系统更加鲁棒并提高情感识别的准确性。本研究提出了一种以“多样化模态更好”为原则的框架，旨在解决上述问题。", "innovation": "本文的创新性在于提出了一个基于Mixture of Experts（MoE）的情感识别框架，该框架通过结合多种输入模态（包括来自大型Vision-Language Model的语义知识，以及时间序列模块活动单位信息）来提高系统性能。具体创新点包括：1) 利用共识为基础的伪标签策略，利用预训练模型和另一个模型之间的协议来生成高质量的标签；2) 采用两阶段训练方法，结合上述生成的高质量标签进行训练；3) 通过多专家投票集成结合基于规则的后处理步骤，以减少预测偏差，更好地满足人类偏好，从而提高识别的准确性。这一创新方法为情感识别领域带来了新的视角和实践方案，特别是在半监督学习背景下。", "conclusion": "本研究在MER2025半监督学习挑战中获得了S2025-SEMI数据集的测试集F1分数为0.8772，并在排行榜上位列第二名。结果证明了所提出框架的有效性，展示了多样化输入模态融合在情感识别中的潜力。未来的研究方向可能包括进一步优化集成方法和探索更高效的学习策略，以进一步提高模型在实际应用中的性能和实用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06057", "html_url": "https://arxiv.org/abs/2508.06057", "title": "AGI for Earth，通往地球智能的道路，可能性及评估模型智能的方法", "title_en": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?", "authors": "Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell", "background": "随着AGI的不断发展，研究界正致力于收集和处理多种模态的数据，包括文本、图像、视频和音频。卫星光谱影像作为一种额外的模态，尚未得到应有的重视，但其在提高AGI理解自然界的能力方面具有巨大潜力。全世界的研究者缺乏一种全面的基准来评估地球观测模型的泛化能力。", "innovation": "本文提出了一个全面的任务集，用于评估地球观测模型的能力，以促进AGI在地球观测数据上的应用和发展。通过具体的任务集合，旨在更好地评估模型理解及交互地球观测数据的能力。", "conclusion": "Earth Observation (EO)数据对于智能模型来说是有用的。现有基准的局限性在于无法全面评估基础模型在地球观测数据领域的泛化能力。本文强调需要一个更全面的基准来评估EO模型，并提出了一系列评估任务来促进这一领域的研究进步。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06063", "html_url": "https://arxiv.org/abs/2508.06063", "title": "分布特定学习联合进行显热和伪装目标检测", "title_en": "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection", "authors": "Chao Hao,Zitong Yu,Xin Liu,Yuhao Wang,Weicheng Xie,Jingang Shi,Huanjing Yue,Jingyu Yang", "background": "SOD（显著目标检测）和COD（伪装目标检测）是两个相关但不同的计算机视觉任务。尽管它们都是类忽略的分割任务，将从RGB空间映射到二元空间，但SOD旨在识别图像中最显著的目标，而COD则集中于检测与背景完美融合的伪装目标。两个任务具有强烈的矛盾属性。之前的研究大多认为这两任务的同时学习会混淆网络，从而降低其在两个任务上的性能。但本文提出了相反的观点，通过合适的训练方法，网络可以同时具备发现显著和伪装目标的能力，使两个任务可以从联合学习中受益。", "innovation": "作者提出了SCJoint，一种联合学习SOD和COD任务的方案，假设SOD和COD的解码过程具有不同的分布特性。关键是通过在完全共享的网络结构中插入少量的任务特定可学习参数来分别学习两个任务的解码过程的均值和方差，从而使两个任务的矛盾属性在最低成本下解耦。此外，作者还提出了一种基于显著性的采样策略（SBSS），以平衡两个任务的训练集大小，提高训练集质量和缩短训练时间。", "conclusion": "基于提出的SCJoint和SBSS，作者训练了一个通用网络JoNet，该网络同时具备捕捉“显热”和“伪装”目标的能力。广泛的实验表明，提出的方案在性能和有效性方面表现出色。研究结果已通过代码发布。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06072", "html_url": "https://arxiv.org/abs/2508.06072", "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "title_en": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "authors": "Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai", "background": "当前的评估基准要么采用基于真实数据集的评分评估方法，要么仅收集含糊的文本偏好，这些方法可能无法给用户提供直观、立竿见影的性能反馈。因此，评估大型语言模型（LLMs）和多模态大型语言模型（MLLMs）的能力和显示它们的局限性具有挑战性。", "innovation": "本文介绍了BioMotion Arena，这是一种创新框架，通过可视化动画来评估LLMs和MLLMs。该方法借鉴了生物体运动模式的固有视觉感知特性，使用点光源成像放大模型之间的性能差异。通过双边比较评估收集了53个主流模型在90个生物运动变体上的超过45000票的数据。", "conclusion": "数据显示，众包的人类投票与专家评分高度一致，证明了BioMotion Arena在提供区分性能方面的优越性。此外，超过90%的评价模型，包括最新的开源InternVL3和专有Claude-4系列，无法产生基本的人形点光源组合，更不用说平滑且生物合乎情理的运动。这使得BioMotion Arena成为性能可视化挑战基准，并且是一个灵活的评估框架，不受真实数据的限制。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06021", "html_url": "https://arxiv.org/abs/2508.06021", "title": "通过基于生成AI的图像合成提高流式显微镜下亚显微粒子分类", "title_en": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "authors": "Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve", "background": "运用流动成像显微镜结合深度学习分析亚显微粒子已被证明有效，可用于识别粒子类型，从而辨别硅油等无害成分与蛋白质颗粒。然而，数据稀缺和 particle 类型之间的严重不平衡是应用多类分类器的主要障碍，迫使研究人员依赖效率较低的方法。对于无意出现且数量较少的硅油和气泡等粒子类型尤其具有挑战性，因为获得大量蛋白质颗粒的图像相对更为容易。", "innovation": "本文开发了一种最先进的扩散模型来解决数据不平衡的问题，通过生成高保真图像来扩充训练数据集，从而实现多类深度神经网络的有效训练。实验结果表明，通过扩散生成的图像在视觉质量和结构上与真实颗粒图像接近，并且可以显著提高分类性能。此外，该研究还公开了所开发的扩散模型和已训练的多类深度神经网络分类器，以及一个易于集成到未来研究中的界面，以促进开放研究和可重复性。", "conclusion": "本文通过基于生成AI的图像合成技术，在数据稀缺和类别不平衡的情况下，显著提高了亚显微粒子分类准确性，且没有显著的负面影响。研究结果为未来相关研究提供了开放的数据和算法资源。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06082", "html_url": "https://arxiv.org/abs/2508.06082", "title": "SwiftVideo：通过轨迹-分布对齐实现统一框架的少量步骤视频生成", "title_en": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment", "authors": "Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu", "background": "扩散或流式模型在视频合成中已经取得了显著进展，但需要进行多次迭代采样步骤，这会带来大量的计算开销。尽管已经开发了许多基于轨迹保留或分布匹配的加速视频生成模型的蒸馏方法，但这些方法在少量步骤设置下往往产生性能下降或增加伪影的问题", "innovation": "我们提出了一种统一且稳定的蒸馏框架SwiftVideo，结合了轨迹保留和分布匹配策略的优点。该方法通过连续时间一致性蒸馏确保精准地保留ODE轨迹，并提出了双视角对齐，包括合成和真实数据之间分布对齐以及不同推理步骤之间轨迹对齐，保持高质量视频生成的同时显著减少推理步骤数量", "conclusion": "我们在OpenVid-1M基准上的定量评估表明，我们的方法在少量步骤的视频生成中显著优于现有方法"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06038", "html_url": "https://arxiv.org/abs/2508.06038", "title": "Fourier-VLM: 在大视觉语言模型中频域压缩视觉标记", "title_en": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "authors": "Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin", "background": "视觉语言模型（VLMs）通常用视觉特征替换预定义的图像占位符标记（<image>），以文本指令的形式输入到大型语言模型（LLM）的主干网络中。然而，大量的视觉标记显著增加了上下文长度，导致了高计算开销和推理延迟。早期方法通过选择重要视觉特征或利用可学习查询来减少标记的数量来尝试缓解这一问题，但这些方法往往牺牲了性能或引入了额外的成本。", "innovation": "我们提出了一种简单而有效的方法——Fourier-VLM，它在频域中压缩视觉表示。该方法基于视觉编码器输出的视觉特征在低频分量中集中能量的观察，利用二维离散余弦变换（DCT）应用低通滤波器来压缩视觉特征。DCT通过快速傅里叶变换（FFT）算子高效计算，计算复杂度为\text{$\theta(n\text{log}n)$}，这种计算方式可以最小化额外的计算成本，而不增加参数。实验结果表明，Fourier-VLM在不同图像基准上的性能与强泛化能力，在LLaVA和Qwen-VL架构中均保持竞争力。同时，与LLaVA-v1.5相比，该方法减少推理FLOPs高达83.8%，提升生成速度31.2%，突显了其优越的效率和实用性。", "conclusion": "实验证明，Fourier-VLM在保持高性能的同时，大幅减少了计算开销和推理延迟，展现了其在视觉语言模型中的高效性和实用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06093", "html_url": "https://arxiv.org/abs/2508.06093", "title": "E-React: 向基于情感控制的人类反应合成方向", "title_en": "E-React: Towards Emotionally Controlled Synthesis of Human Reactions", "authors": "Chen Zhu,Buzhen Huang,Zijing Wu,Binghui Zuo,Yangang Wang", "background": "情绪在日常人际互动中起着至关重要的作用。现有的人类动作生成框架未考虑情绪的影响，这减少了自然性并限制了它们在交互任务，如人类反应合成中的应用。", "innovation": "引入了一种新的任务：根据不同的情绪线索生成多样化的反应动作。高层次而言，通过在演员-反应扩散模型中引入半监督情感先验，解决了从有限动作数据中学习情感表示并将其纳入动作生成框架的挑战。", "conclusion": "实验结果表明，该模型在反应生成方面优于现有的方法。在给定演员的动作序列后，该方法可以在各种情绪条件下生成逼真的反应。代码和数据将在相关链接公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06104", "html_url": "https://arxiv.org/abs/2508.06104", "title": "MCA：通过多层级自适应修正与对齐实现含噪标签的2D-3D检索", "title_en": "MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment", "authors": "Gui Zou,Chaofan Gan,Chern Hong Lim,Supavadee Aramvith,Weiyao Lin", "background": "随着2D和3D数据的可用性增强，跨模态检索领域取得了显著进展。然而，不完美的注释（存在噪声标签）仍是一个重大挑战，需要在噪声标签条件下提供鲁棒的2D-3D跨模态检索解决方案。现有的方法通常通过独立地在每个模态内划分样本来解决噪声问题，这使得它们容易对受污染的标签过拟合。", "innovation": "本文提出了一个鲁棒的2D-3D多层级跨模态自适应修正和对齐框架（MCA）。具体来说，引入了多模态联合标签修正（MJC）机制，利用多模态的历史自我预测来联合建模模态预测一致性，从而实现可靠的标签细化。此外，提出了一种多层级自适应对齐（MAA）策略，以有效地增强不同层级下的跨模态特征语义和判别性。", "conclusion": "大量的实验表明，我们的方法MCA在传统和现实的噪声3D基准上都表现出优越性，验证了其普适性和有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06080", "html_url": "https://arxiv.org/abs/2508.06080", "title": "DreamVE：统一的基于指令的图像和视频编辑", "title_en": "DreamVE: Unified Instruction-based Image and Video Editing", "authors": "Bin Xia,Jiyang Liu,Yuechen Zhang,Bohao Peng,Ruihang Chu,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia", "background": "基于指令的编辑因其简单高效的交互编辑格式具有巨大潜力，特别是在视频编辑方面。然而，受限于有限的训练数据，尤其是在视频领域，极大地阻碍了其实用应用。因此，研究者们需要解决数据不足的问题，以推动这种技术的实际应用和普及。", "innovation": "该论文提出了一个名为DreamVE的统一模型，用以处理基于指令的图像和视频编辑。模型采用了两阶段训练策略：首先训练图像编辑，然后训练视频编辑。这一策略有助于利用大量易于扩展的图像数据，提高模型训练效率，同时简化了图像和视频生成的统一过程。此外，作者还设计了包括图册基数据合成和生成模型基数据合成在内的综合训练数据合成管道。作为验证，DreamVE在广泛的数据上预训练，以提升其在关键编辑类型上的性能和推广能力。不过，图册数据在处理属性编辑方面存在局限，因此还结合了生成模型基数据来进一步微调模型。最后，论文还设计了一个高效强大的编辑框架，并基于最先进的T2V模型进行改进，确保了编辑的一致性和可操作性。", "conclusion": "DreamVE展示了如何通过有效的数据合成管道、两阶段训练策略以及高效的编辑框架来克服基于指令的图像和视频编辑中的数据限制问题。通过这一系列创新策略，DreamVE在多个关键编辑类型上取得了显著性能提升，同时增强了泛化能力和迁移能力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06092", "html_url": "https://arxiv.org/abs/2508.06092", "title": "Q-CLIP：通过统一跨模态适应释放视觉语言模型在视频质量评估中的潜力", "title_en": "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation", "authors": "Yachun Mi,Yu Li,Yanting Li,Shixin Sun,Chen Hui,Tong Zhang,Yuanyuan Liu,Chenyue Song,Shaohui Liu", "background": "准确且高效的视频质量评估（VQA）一直是研究的关键挑战。现有的主流VQA方法通常通过在大规模分类数据集（如ImageNet、Kinetics-400）上预训练，然后在VQA数据集上微调来提高性能。然而，这种方法存在两个重要挑战：（1）仅从预训练中转移语义知识不足以满足VQA需求，因为视频质量取决于多种因素（如语义、失真、运动、美学）；（2）在大规模数据集上进行预训练需要巨大的计算资源，通常比直接在VQA数据集上训练大几十甚至上百倍的资源。近年来，视觉-语言模型（VLMs）在多种视觉任务上展示了出色的泛化能力，并开始展现出在质量评估中的潜在应用价值。", "innovation": "我们提出了Q-CLIP，这是首个基于VLMs的VQA框架。Q-CLIP通过一个共有的跨模态适配器（SCMA）增强了视觉和文本的表示力，SCMA包含极少的可学习参数，且仅此组件需要训练，这样大大降低了计算成本。此外，引入了一组五个可学习的质量级别提示，以指导VLMs感知微妙的质量变化，从而进一步增强了模型对视频质量的敏感度。同时，考察了不同的帧采样策略对VQA性能的影响，发现基于帧差的采样策略在多个数据集上表现出更好的泛化性能。", "conclusion": "广泛的实验表明，Q-CLIP在多个VQA数据集上表现出优异的性能。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06084", "html_url": "https://arxiv.org/abs/2508.06084", "title": "AdaptInfer：具有动态文本指导的视觉语言模型推理中的自适应标记裁剪", "title_en": "AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance", "authors": "Weichen Zhang,Zhui Zhu,Ningbo Li,Kebin Liu,Yunhao Liu", "background": "视觉语言模型（VLMs）在视觉问答（VQA）等多模态推理任务上取得了显著的成果，但其推断成本因预填充阶段处理大量视觉标记而成为一个重要挑战。现有的剪枝方法通常依赖于直接使用注意力模式或静态文本提示指导，未能充分利用推理过程中生成的动态内部信号。因此，研究一种新的自适应视觉标记剪枝方法的需求变得迫切，以减少计算负担并提升推理效率。", "innovation": "本文提出了一种名为AdaptInfer的插件式自适应框架，用于视觉语言模型中的自适应视觉标记剪枝。该方法引入了一种细粒度、动态文本指导的剪枝机制，利用逐层的文本到文本注意力图来构建文本标记重要性的软先验，以更科学地评估视觉标记的重要性。同时，通过离线分析跨模态注意力转移，确定推理中的一致转折位置，从而设计出一种更为规范和高效的剪枝计划。该方法轻量级且插件式，适用于多模态任务。实验结果表明该方法的有效性，例如在保留92.9%平均准确性的前提下，CUDA延迟降低了61.3%。在相同的标记预算下，AdaptInfer超过了当前最优方法（SOTA）的精度。", "conclusion": "综上所述，AdaptInfer通过利用动态文本指导和细粒度剪枝机制，显著降低了视觉语言模型推断的成本，同时保持了较高的推理精度，体现了其在多模态任务中的普适性。该方法的有效性已在实验中得到验证，具有广泛的应用前景。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06115", "html_url": "https://arxiv.org/abs/2508.06115", "title": "SynSeg: 特征协同作用下的多类对比学习在开放式词汇语义分割中的应用", "title_en": "SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation", "authors": "Weichen Zhang,Kebin Liu,Fan Dang,Zhui Zhu,Xikai Sun,Yunhao Liu", "background": "在开放词汇场景下的语义分割面临着广泛且细粒度的语义类别所带来的挑战。现有的弱监督方法往往依赖于特定类别的监督和不合适的特征构建方法来实现对比学习，导致语义不匹配和较差的性能。", "innovation": "本文提出了一种新型的弱监督方法——SynSeg，以解决上述挑战。SynSeg采用多类别对比学习（MCCL）策略作为更强的训练信号，并引入了新的特征重构框架——特征协同结构（FSS）。具体来说，MCCL策略稳健地结合了类别内的和类别间的对齐与分离，使模型能够在同一张图像中学习不同类别之间的相关知识。此外，FSS通过先验融合和语义激活图增强，有效地避免了由视觉编码器引入的前景偏差，从而为对比学习构建了具有区分性的特征。", "conclusion": "SynSeg在弱监督下显著提升了语义定位和区分的能力。在基准测试中，我们的方法超越了现有的最先进的方法。例如，SynSeg在VOC上的准确率提高了4.5%，在Context上提高了8.9%，在Object上提高了2.6%，在Cityscapes上提高了2.0%。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06113", "html_url": "https://arxiv.org/abs/2508.06113", "title": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving", "title_en": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving", "authors": "Jian Wang,Chaokang Jiang,Haitao Xu", "background": "基于扩散的模型正在重新定义端到端自动驾驶的最新成果，但其性能逐渐被依赖基于变压器的融合所限制。这些架构面临根本性的限制：计算复杂度是非线性的，限制了高分辨率特征的使用，并且缺乏空间先验，使得它们无法有效地建模BEV表示中的固有结构。", "innovation": "本文引入了GMF-Drive（Gated Mamba Fusion for Driving），一种克服这些挑战的端到端框架。首先，我们用几何增强的柱状格式取代信息有限的历史雷达表示，编码形状描述符和统计特征，保留了关键的3D几何细节。其次，我们提出了一种新颖的分层门控珊瑚融合（GM-Fusion）架构，用高效的、具有空间意识的状态空间模型（SSM）代替了昂贵的变压器。我们的核心BEV-SSM利用定向序列和自适应融合机制，以线性复杂度捕获长距离依赖性，同时明确地遵守驾驶场景的独特空间属性。", "conclusion": "在具有挑战性的NAVSIM基准测试中，GMF-Drive 实现了新的SOTA性能，显著优于 DiffusionDrive。详尽的消融研究验证了每个组件的有效性，证明了任务特定的SSM能够在性能和效率上超越通用变压器，从而为自动驾驶提供支持。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06109", "html_url": "https://arxiv.org/abs/2508.06109", "title": "FMCE-Net++: 功能映射收敛评估与优化", "title_en": "FMCE-Net++: Feature Map Convergence Evaluation and Training", "authors": "Zhibo Zhu,Renyu Huang,Lei He", "background": "深度神经网络（DNNs）由于内部表示的不透明性面临着可解释性的挑战。虽然功能映射收敛评估（FMCE）通过功能映射收敛评分（FMCS）量化模块级收敛，但仍缺乏实验验证和闭环集成。此类方法主要用于评估，但在实际训练过程中并没有得到充分应用，存在提升模型性能的空间。因此，本文指出需要一种更好地将功能映射收敛评价与训练过程结合起来的方法，以提升模型性能，而无需变更网络结构或增加额外数据。", "innovation": "本文提出了一种新颖的训练框架FMCE-Net++，该框架将一个预训练并固定的功能映射收敛评估网络（FMCE-Net）作为辅助头部。该模块生成FMCS预测，与任务标签结合，通过代表辅助损失（RAL）共同监督主干神经网络的优化。RAL动态平衡主要分类损失和特征收敛优化之间的权衡，通过可调节的‘代表抽象因子’进行调节。通过在MNIST、CIFAR-10、FashionMNIST和CIFAR-100上的大量实验，证明了FMCE-Net++不仅能够提升模型性能，而且可以在不修改网络架构或引入额外数据的情况下实现这种提升，实验结果显示，ResNet-50/CIFAR-10的准确率提高了1.16个百分点，ShuffleNet v2/CIFAR-100的准确率提高了1.08个百分点，证明了FMCE-Net++的有效性。", "conclusion": "FMCE-Net++在多个数据集上验证了其有效提升模型性能，无需对网络架构做出改动或增加额外数据。此外，通过引入闭环的搜索机制（RAL），动态平衡主要分类损失与特征收敛优化之间的权衡，实现了对模型的优化。这种方法不仅扩展了FMCE的应用范围，还为深度学习模型的解释性和优化提供了一种新的视角。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06122", "html_url": "https://arxiv.org/abs/2508.06122", "title": "利用卷积自编码器评估卫星图像表征的学习与风廓线天气事件评估", "title_en": "Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events", "authors": "Ting-Shuo Yo,Shih-Hao Su,Chien-Ming Wu,Wei-Ting Chen,Jung-Lien Chu,Chiao-Wei Chang,Hung-Chi Kuo", "background": "研究通过应用表征学习算法处理卫星图像，评估了这些算法在识别各种天气事件分类任务中的表现，尤其是与经典线性变换（例如主成分分析PCA）和先进的深度学习方法（例如卷积自编码器CAE）及其预训练版本（PT）进行了对比研究。实验数据显示，卷积自编码器在所有分类任务中的指标表现都优于其他方法，显示出更准确的预测能力。这项研究aim通过对比不同方法的性能，旨在找到在深度学习领域中最有效的表征学习算法，以更好地理解和预测卫星图像中所反映的天气现象。", "innovation": "该研究的创新在于它使用了卷积自编码器（CAE）和预训练的残差网络（PT）来学习卫星图像的表征，相比传统的PCA方法，卷积自编码器在各类天气事件分类任务上表现更好，并识别出更高分辨率的数据集在表征学习中更优秀。此外，研究还发现的较小的潜空间尺寸对命中率影响较小，但会显著提高误报率。这表明，优化潜空间尺寸对于提升分类准确性也很重要。", "conclusion": "实验结果表明，卷积自编码器（CAE）和预训练模型（PT）在卫星图像分类任务中的性能优越于经典的主成分分析（PCA）。卷积自编码器虽然在表征学习上有效且高效，但是其学习的空间表示对于物理属性的解释性较差。因此，建立一个物理导向的卷积自编码器可能会是本研究值得探索的进一步方向。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06127", "html_url": "https://arxiv.org/abs/2508.06127", "title": "SAM编码器由对抗单纯形复合体触发下游模型故障", "title_en": "SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures", "authors": "Yi Qin,Rui Wang,Tao Huang,Tong Xiao,Liping Jing", "background": "Segment Anything Model (SAM) 在实现零样本交互式分割方面取得了显著进展，但其固有的脆弱性可能会导致多个下游应用程序的失败。早期针对SAM的对抗性攻击虽有尝试，但由于未能充分探索跨领域通用弱点，这些攻击的转移性有限。本文通过提出一种新颖的方法——Vertex-Refining Simplicial Complex Attack (VeSCA)，旨在通过利用SAM的编码器生成具有转移性的对抗性实例，以更有效地评估这些可转移的脆弱性，从而增强模型稳健性.", "innovation": "VeSCA通过复用SAM的编码器，在一个参数化的单纯形复合体下，显式地表征SAM与下游模型之间的共享易受攻击区域，并通过迭代的顶点细化方法识别这些复合体。此外，通过引入轻量级的域重新适应策略，在初始化单纯形复合体时使用最少的参考数据来弥合领域差异。最后，通过对随机单纯形复合体取样生成具有可转移性的对抗性实例，VeSCA在三个下游模型类别上的三种特定领域数据集上分别取得了比其他先进方法更高的性能提升：12.7%.", "conclusion": "本文的实验证明，VeSCA显著提高了针对SAM的对抗性攻击效果，并进一步揭示了SAM脆弱性对下游模型的风险，强调了开发更具稳健性基础模型的迫切性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06125", "html_url": "https://arxiv.org/abs/2508.06125", "title": "SC-Captioner: 提升图像字幕准确性的自校正强化学习方法", "title_en": "SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning", "authors": "Lin Zhang,Xianfang Zeng,Kangcong Li,Gang Yu,Tao Chen", "background": "当前图像字幕生成模型缺乏自我纠正能力，通常使用直接偏好优化训练策略，导致图像字幕质量评估不准确的问题，且对关系匹配效率低下。为解决这些问题，作者提出了一种基于强化学习的SC-Captioner框架，旨在提高图像字幕的准确性并增强模型的自我纠正能力。", "innovation": "该框架的关键在于设计奖励函数激励准确的字幕纠正。通过对预测和参考字幕进行场景图解析，分解成对象、属性和关系集合，并计算初始和自我纠正字幕集之间的集合差来识别增减元素。将这些元素与参考集匹配，以计算准确改进的正确性奖金和错误添加或删除的错误惩罚，从而形成最终奖励。同时，基于CAPTURE提出了新的评估指标以解决其不完整精确评估和关系匹配效率低下的问题。此外，作者还收集了一个名为RefinedCaps的精细标注图像字幕数据集，包含来自COCO数据集的6.5K多样化的图像。实验表明，将SC-Captioner应用于大型视觉语言模型，可以在不同场景下生成更好的图像字幕，显著优于直接偏好优化训练策略。", "conclusion": "实验结果表明，SC-Captioner能够显著提升图像字幕的质量，在各种场景中生成更准确的描述，通过强化学习机制促使图像模型自我纠正错误，从而改善图像字幕的整体表现。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06136", "html_url": "https://arxiv.org/abs/2508.06136", "title": "卷动你的眼球：基于明确3D眼球旋转的眼球转向", "title_en": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation", "authors": "YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi", "background": "现有的眼球转向方法通常基于神经辐射场（NeRF），通过体渲染使用隐式神经表示。这些方法中，3D表征的旋转和移动未被明确建模。本文研究了这种基于NeRF的方法存在的问题，背景在于需要一种新的方法来生成逼真且能够准确再现所需视向方向的图像。", "innovation": "本文提出了一种新颖的3D眼球转向框架，使用明确的3D眼球结构——3D Gaussian Splatting (3DGS)来旋转和移动3D眼球结构。在此基础上，引入了自适应变形模块，能够复制眼部周围微妙的肌肉运动。实验表明，本方法相较于现有最先进方法能够生成多样化的新型眼球转向图像，图像质量和视向估计精度更高。", "conclusion": "通过实验验证，本文提出的框架能够生成逼真且准确的图像，展示了在眼球转向方面的新突破。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 学习识别手写数学公式中的自我监督注意力机制", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式（HMER）识别是一个挑战性的任务，因为其固有的二维结构，不同符号的大小变异以及符号之间的复杂空间关系。本论文提出了一种自我监督学习（SSL）框架，以消除昂贵的标记数据需求。该方法通过预训练图像编码器，结合全局和局部对比损失，使模型能够学习整体和精细的表示。关键贡献在于一种新的自我监督注意力网络，通过逐步空间遮罩策略进行训练，旨在学习具有语义意义的关注区域，如操作符、指数和嵌套的数学标注，而不需要任何监督。逐步遮罩课程鼓励网络变得越来越能抵抗缺失或被遮挡的视觉信息，从而改善结构理解。完整的管道包括（1）图像编码器的自我监督预训练，（2）自我监督注意力学习，以及（3）带有变压器解码器的监督微调，以生成LATEX序列。在CROHME基准测试上的大量实验表明，本方法在现有的SSL和完全监督基准上表现更优，验证了逐步注意力机制在增强HMER性能方面的有效性。我们的代码库可以在这里找到。", "innovation": "提出了一种自我监督学习框架，用于手写数学表达式识别。关键创新点在于设计了一种新的自我监督注意力网络，通过逐步空间遮罩策略训练，旨在学习具有语义意义的关注区域，而不需要任何监督。该方法通过逐步遮罩课程鼓励网络变得越来越能抵抗缺失或被遮挡的视觉信息，从而改善结构理解，并且在CROHME基准测试中，在现有的SSL和完全监督基准上表现更优。", "conclusion": "本论文提出的方法在手写数学表达式识别领域中表现优异，证明了逐步注意力机制的有效性。代码库已开源。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06147", "html_url": "https://arxiv.org/abs/2508.06147", "title": "DSConv: 动态分裂卷积在增强现实中的应用", "title_en": "DSConv: Dynamic Splitting Convolution for Pansharpening", "authors": "Xuanyu Liu,Bonan An", "background": "高分辨率图像的获取过程中，融合多光谱图像（MS）和全色图像（PAN）的去模糊处理（pansharpening）仍然是低级视觉任务的重要且具有挑战性的课题。现有的大多数方法主要依赖标准卷积，仅有少数方法尝试使用适配卷积，后者由于遥感图像的像素间相关性而具有有效性。因此，增强网络的泛化能力、优化能力和特征表示能力变得尤为重要。", "innovation": "本文提出了一种新的策略，动态分裂卷积核（DSConv），结合注意力机制，根据兴趣位置将原始卷积核分割成多个较小的卷积核。这种策略更有效地提取了感受野内不同位置的特征，提高了网络的泛化、优化和特征表示能力。此外，还创新性地丰富了动态分裂卷积的概念，并基于此方法构建了一系列新的网络架构，以更高效地完成去模糊任务。", "conclusion": "充分的公平实验展示了这种http://example.com方法的有效性及其达到的最先进的性能。严格的讨论进一步证明了DSConv的优越性及其最佳使用条件。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06160", "html_url": "https://arxiv.org/abs/2508.06160", "title": "降低去噪步骤或廉价单步推理：迈向计算最优的扩散模型部署", "title_en": "Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment", "authors": "Zhenbang Du,Yonggan Fu,Lifu Wang,Jiayi Qian,Xiao Luo,Yingyan(Celine)Lin", "background": "扩散模型在生成任务中取得了显著成功，但其高计算需求限制了其在资源受限平台上的部署。", "innovation": "提出了一种名为PostDiff的训练无损框架，通过减少预训练扩散模型在输入级别和模块级别上的冗余来加速其部署。输入级别上采用混合分辨率去噪策略，通过在早期去噪步骤中降低生成分辨率以增强低频成分。模块级别上使用混合模块缓存策略来重用不同去噪步骤中的计算。", "conclusion": "实验证明，PostDiff可以显著改善最先进的扩散模型的保真度-效率权衡，并且在保持生成保真度的同时提高效率，通常降低每步推理成本比减少去噪步骤更有效。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06101", "html_url": "https://arxiv.org/abs/2508.06101", "title": "UGD-IML：基于生成扩散模型的统一约束和非约束图像篡改定位框架", "title_en": "UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization", "authors": "Yachun Mi,Xingyang He,Shixin Sun,Yu Li,Yanting Li,Zhixuan Li,Jian Jin,Chen Hui,Shaohui Liu", "background": "在数字时代，高级图像编辑工具对视觉内容的完整性构成了严重威胁，因此图像伪造检测和定位成为研究的重点。现有的图像修改定位方法依赖于判别学习，并需要大量高质量的标注数据集。然而，当前的数据集缺乏足够的规模和多样性，限制了模型在真实世界场景中的表现。最近的研究探索了约束图像修改定位（CIML），通过算法监督生成像素级标注，但现有CIML方法往往依赖复杂的多阶段流程，导致标注过程效率低下。", "innovation": "提出了一种基于扩散模型的生成框架UGD-IML，首次在单一框架中统一了图像篡改定位（IML）和约束图像篡改定位（CIML）任务。通过学习底层数据分布，生成扩散模型减少了对大型标注数据集的依赖，使得在数据有限的情况下也能有效工作。通过利用类别嵌入机制和参数共享设计，该模型在IML和CIML模式之间无缝切换，而无需额外组件或训练开销。此外，端到端的设计使模型在数据标注过程中避免了繁琐的步骤。实验结果表明，UGD-IML在IML和CIML任务的F1得分方面分别优于SOTA方法9.66和4.36，并且在不确定性估计、可视化和鲁棒性方面也表现出色。", "conclusion": "UGD-IML方法在多个数据集上的广泛实验结果表明，该方法在IML和CIML任务中的F1得分分别比现有最佳方法高出9.66和4.36，在不确定性估计、可视化和鲁棒性方面也表现出优势，这是通过单一生成扩散模型框架，结合类别嵌入机制和参数共享设计实现的。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06146", "html_url": "https://arxiv.org/abs/2508.06146", "title": "面向通用分割的文本引导视觉提示DINO", "title_en": "Text-guided Visual Prompt DINO for Generic Segmentation", "authors": "Yuchen Guan,Chong Sun,Canmiao Fu,Zhipeng Huang,Chun Yuan,Chen Li", "background": "近年来，多模态视觉模型在后期特征融合和混合提示开放世界分割中的查询选择上显示出局限性，同时，由图像描述词汇表带来的约束也存在。为解决这些挑战，本文提出了Prompt-DINO框架，该框架通过三个关键创新点来解决上述问题。首先，引入早期融合机制，在初始编码阶段统一文本/视觉提示和骨干特征，促进更深的跨模态交互以解决语义模糊性。其次，设计了顺序对齐的查询选择机制，针对DETR架构，显式优化解码过程中的文本和视觉查询之间的结构对齐，以增强语义空间一致性。第三，开发了一个由识别一切的提示模型（RAP）驱动的生成数据引擎，通过双重交叉验证管道生成5亿个多样化的训练实例，相较于传统方法，这种策略降低了80.5%的标签噪声。", "innovation": "Prompt-DINO框架提出了三个创新点：1. 早期融合机制，统一文本/视觉提示和骨干特征，初期编码阶段即进行融合，增强跨模态交互；2. 顺序对齐的查询选择机制，增强解码过程中文本和视觉查询的结构对齐，优化语义空间一致性；3. 利用RAP模型生成5亿个多样化的训练实例，减少标签噪声，显著提升数据质量。", "conclusion": "通过Prompt-DINO，作者实现了在开放世界检测基准上达到最先进的性能，同时突破了固定词汇表对语义覆盖的限制。本文还确立了一个新的多模态检测和开放世界数据生成的范式。研究数据和代码在本文提供的地址中可供下载。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06177", "html_url": "https://arxiv.org/abs/2508.06177", "title": "基于楼层摄像头和特征丰富工业楼层的图神经网络的图基机器人定位", "title_en": "Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor", "authors": "Dominik Brämer,Diana Kleingarn,Oliver Urbann", "background": "精确的定位是机器人导航中的一个基本挑战。传统方法，如激光雷达或基于二维码的系统，在复杂环境中存在固有的可扩展性和适应性限制。", "innovation": "本文提出了一种创新的定位框架，利用基于图的表示和图卷积网络（GCNs）来利用地板特征进行机器人定位。这种方法不仅能够更准确（误差0.64cm）且更高效地定位机器人，而且还能在每帧中解决被绑架机器人问题，无需复杂过滤过程。", "conclusion": "这种进步为在多样化环境中进行机器人导航提供了新的可能性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06169", "html_url": "https://arxiv.org/abs/2508.06169", "title": "UW-3DGS: 物理感知Gaussian分裂下的水下3D重建", "title_en": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting", "authors": "Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han", "background": "水下3D场景重建受到光吸收、散射和混浊度的影响，这些因素降低了传统方法如Neural Radiance Fields (NeRF) 的几何和色彩保真度。虽然SeaThru-NeRF等NeRF扩展利用了物理模型，但是它们依赖于MLP，这在能见度低的环境下限制了效率和空间分辨率。", "innovation": "引入了UW-3DGS，这是一个基于3D高斯点的进行稳健水下重建的新框架。关键创新点包括：(1) 使用基于体素的回归实现水下图像形成模块中的可插拔学习组件，用以处理空间变化的衰减和后向散射；(2) 一种物理感知不确定性修剪（PAUP）分支，通过不确定性评分自适应移除嘈杂的浮动高斯体素，确保干净的几何形状。该框架在训练和渲染阶段运行。在训练期间，嘈杂的高斯体素通过PAUP修剪和散射建模与水下参数一起从端到端优化。在渲染期间，改进后的高斯体素产生无介质效应的清晰未衰减辐射图像（URIs），同时学习的物理法则生成具有准确光照传输的真实感水下图像（UWIs） 。", "conclusion": "实验结果表明，UW-3DGS在性能上优于SeaThru-NeRF和UWBundle数据集，PSNR达到27.604，SSIM达到0.868，LPIPS达到0.104，浮渣减少了约65%。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06142", "html_url": "https://arxiv.org/abs/2508.06142", "title": "SDEval: 安全动态评估方法用于多模态大型语言模型", "title_en": "SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models", "authors": "Hanqing Wang,Yuan Tian,Mingyu Liu,Zhenhao Zhang,Xiangyang Zhu", "background": "随着多模态大型语言模型（MLLMs）的快速发展，人们对它们输出的安全性问题给予了越来越多的关注。尽管已提出了大量数据集，但这些数据集可能随着MLLM技术的进步而变得过时，并且容易受到数据污染问题的影响。为了应对这些问题，研究提出了一种名为SDEval的安全动态评估框架，该框架能够控制性地调整安全基准的分布和复杂性，以适应新的MLLM模型。", "innovation": "SDEval是一种全新的安全动态评估框架，引入了三项动态策略：文本、图像和图文动态，以从原始基准生成新的样本。此外，该框架首次探索了仅采用文本动态或图像动态对模型安全性的影响，并发现将文本动态引入图像或反之亦然会导致新的安全风险。这项研究展示了SDEval在不同安全和能力基准上的广泛适用性，并证明了其在安全性评估、减少数据污染以及揭示MLLM安全限制方面的显著效果。", "conclusion": "通过实验，SDEval显著地影响了安全性评估，减轻了数据污染，并揭示了MLLM的安全局限性。这项研究提出了一种动态调节安全基准的方法，使其能够更好地适应新的MLLM模型，并展示了其在多种现有安全及能力基准上的广泛适用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06189", "html_url": "https://arxiv.org/abs/2508.06189", "title": "MA-CBP：基于多智能体异步协作的犯罪行为预测框架", "title_en": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration", "authors": "Cheng Liu,Daou Zhang,Tingxu Liu,Yuhan Wang,Jinyang Chen,Yuexuan Li,Xinying Xiao,Chenbo Xin,Ziru Wang,Weichao Wu", "background": "随着城市化的加速，公共场所的犯罪行为对社会安全构成了越来越严重的威胁。传统的基于特征识别的异常检测方法难以从历史信息中捕捉到高层次的行为语义，而基于大型语言模型（LLMs）的生成方法往往无法满足实时要求。", "innovation": "我们提出了MA-CBP，一种基于多智能体异步协作的犯罪行为预测框架。该框架将实时视频流转换为帧级语义描述，构建因果一致的历史摘要，并融合相邻图像帧以在长短期上下文中进行联合推理。生成的行为决策包括事件主体、地点和原因等关键要素，能够提前预警潜在的犯罪行为。此外，我们还构建了一个高质量的犯罪行为数据集，提供了多尺度的语言监督，包括帧级、摘要级和事件级的语义注释。", "conclusion": "实验结果显示，我们的方法在多个数据集上实现了优越的表现，并为城市公共安全场景的风险预警提供了一个有前途的解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06218", "html_url": "https://arxiv.org/abs/2508.06218", "title": "通过解剖意识多实例学习实现可解释的类风湿关节炎评分", "title_en": "Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning", "authors": "Zhiyan Bo,Laura C. Coates,Bartlomiej W. Papiez", "background": "SvdH评分在类风湿性关节炎(RA)的临床试验中广泛用于评估X射线影像中的放射学损伤，但由于其复杂性在常规临床实践中采用受限。文章旨在解决手动评分的低效率问题。", "innovation": "文章提出了一种两阶段管道，使用双手X射线图像进行可解释的图像级SvdH评分预测。该方法通过注意力机制的多实例学习，提取疾病相关图像区域并生成预测特征。文章还提出了两种区域提取方案，并通过集成学习提高了预测精度，达到了最先进的性能，与有经验的放射科医生相当。", "conclusion": "该管道能够有效识别和基于临床关注的解剖结构做出决策，有助于提高RA进展的评估准确性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06203", "html_url": "https://arxiv.org/abs/2508.06203", "title": "AnomalyMoE: 向一个语言无关的通用模型用于统一的视觉异常检测", "title_en": "AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection", "authors": "Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Wei Ge,Ming Tang,Jinqiao Wang", "background": "现有的异常检测方法往往高度专业化，这限制了它们的通用性。这些专门化的模型针对特定类型的异常（如文本瑕疵或逻辑错误）进行了优化，在超出其特定应用场景时，通常表现不佳。", "innovation": "提出了一种名为AnomalyMoE的新颖且通用的异常检测框架，基于Mixture-of-Experts（MoE）架构。AnomalyMoE将复杂的异常检测问题分解为三个语义层次，并在每个层次上使用专门的专家网络。此外，引入了专家信息排斥（EIR）模块以促进专家多样性，专家选择平衡（ESB）模块以确保所有专家的有效利用。", "conclusion": "在8个具有挑战性的数据集上的实验表明，AnomalyMoE能够建立新的SOTA性能，在不同领域显著优于专门方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06202", "html_url": "https://arxiv.org/abs/2508.06202", "title": "LoRA in LoRA: 含有确定维度的低秩逼近为连续视觉指令调优的参数高效架构扩展", "title_en": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "authors": "Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi", "background": "连续视觉指令调优（CVIT）可以让多模态大型语言模型（MLLMs）逐次学习新任务。然而，这一过程会受到灾难性遗忘的挑战，即随着模型适应新任务，其在先前学习任务上的表现会下降。传统的缓解遗忘的方法是架构扩展，它通过引入特定任务模块来防止干扰，但现有方法往往会为每个任务扩展整个层，导致大量的参数开销和较差的可扩展性。", "innovation": "本文引入了LiLoRA（LoRA in LoRA），这是一种高效架构扩展方法，专门针对MLLMs中的CVIT。LiLoRA在任务间共享LoRA矩阵A以减少冗余，对矩阵B进行额外的低秩分解以减少特定任务的参数量，并引入余弦正则化稳定性损失以在时间上保持共享表示的一致性。在各种CVIT基准测试上的广泛实验显示，LiLoRA在连续任务学习中保持了出色的表现，并且在参数效率方面较现有方法有显著提高。", "conclusion": "LiLoRA能够有效地缓解灾难性遗忘，通过共享特定的矩阵部分和引入余弦正则化损失来降低参数开销，提高架构扩展的效率。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06228", "html_url": "https://arxiv.org/abs/2508.06228", "title": "使用专家混合解码器实现统一图像去模糊", "title_en": "Towards Unified Image Deblurring using a Mixture-of-Experts Decoder", "authors": "Daniel Feijoo,Paula Garrido-Mellado,Jaesung Rim,Alvaro Garcia,Marcos V. Conde", "background": "图像去模糊是计算摄影和低级计算机视觉中的基础任务，现有的方法专注于特定的去模糊策略，这样就缺乏通用性。这意味着需要针对不同的模糊类型使用多个模型，这在很多实际场景中并不实用。", "innovation": "提出了一种混合专家（MoE）解码模块，可以根据识别出的模糊退化动态路由图像特征，实现端到端的精确且高效的去模糊处理。这种方法不仅在性能上与专门针对特定任务的模型相当，还在未见的模糊退化场景中表现出出色的鲁棒性和泛化能力。", "conclusion": "本文提出了一种统一的去模糊方法，能够高效地恢复受到不同类型模糊退化影响的图像，包括全局运动模糊、局部运动模糊、低光照条件下的模糊和离焦模糊。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06256", "html_url": "https://arxiv.org/abs/2508.06256", "title": "FedX：用于遥感领域通信高效联邦学习的解释指导剪枝", "title_en": "FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing", "authors": "Barış Büyüktaş,Jonas Klotz,Begüm Demir", "background": "联邦学习（FL）允许通过分散的数据档案（即客户端）进行分布式数据的本地存储和个人模型更新，并通过中央服务器进行同步。这种学习模式特别适用于受到法律和隐私限制的遥感（RS）图像分类任务，因为数据集中化可能会受到限制。然而，FL在RS任务中的关键挑战是由于频繁的大型模型更新而带来的通信开销。", "innovation": "提出了FedX的新策略，该策略使用解释引导的剪枝来减少通信开销，从而最小化传输模型的大小，同时不牺牲性能。FedX利用反向传播基础的解释方法来估计任务特定的模型组件的重要性，并在中央服务器处剪枝最小相关的部分。这种方法通过发送稀疏的全球模型，并显著地减少了通信开销。FedX在这项研究中被用于不同数据集的多标签场景分类和单标签场景分类，实验结果表明，在减少共享模型参数数量的同时，FEDX可以增强全球模型的泛化能力，超越了未剪枝的型号和最先进的剪枝方法。", "conclusion": "FedX在减少共享模型参数数量的同时，显著提高了全球模型的泛化能力，并优于未剪枝的模型和最先进的剪枝方法。相关代码将在指定的链接处提供。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06248", "html_url": "https://arxiv.org/abs/2508.06248", "title": "跨基准的深层伪造检测", "title_en": "Deepfake Detection that Generalizes Across Benchmarks", "authors": "Andrii Yermakov,Jan Cech,Jiri Matas,Mario Fritz", "background": "对于无法预见的伪造技术的泛化能力仍然是实际部署中的一个挑战。尽管许多方法通过引入大量结构复杂性来适应基础模型，这项工作证明了通过针对预训练CLIP视觉编码器的参数高效适应，可以实现鲁棒泛化。", "innovation": "提出的LNCLIP-DF方法仅微调层归一化参数（总参数的0.03%），并通过L2归一化和潜在空间增广强制特征空间呈超球面结构，从而增强泛化能力。该方法在13个从2019年至2025年的基准数据集上进行了广泛评估，达到了最先进的性能，超越了近期更为复杂的方法在平均跨数据集AUROC上的表现。研究结果表明在相同来源视频的真伪配对数据上训练对于减轻捷径学习和提高泛化效果至关重要，同时学术数据集的检测难度并未严格增加，较旧且多样化的数据集训练模型具有强泛化能力。", "conclusion": "这项工作提供了一种计算效率高且可复现的方法，证明了通过对预训练CLIP模型进行有针对性的、最小的修改，可以实现最先进的泛化性能。该代码将在接受后公开分享。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06227", "html_url": "https://arxiv.org/abs/2508.06227", "title": "深度抖动：透过深度视角", "title_en": "Depth Jitter: Seeing through the Depth", "authors": "Md Sazidur Rahman,David Cabecinhas,Ricard Marxer", "background": "在计算机视觉中，深度信息至关重要，特别是在水下成像、机器人技术和自主导航领域。然而，传统的增强技术往往忽视了深度感知的变换，这限制了模型在真实世界深度变化中的鲁棒性。深度信息的波动性对模型的稳定性有很大影响，但现有的增强技术并未有效应对这一挑战。因此，研究一种能够模拟自然深度变化的深度感知增强技术对于提高模型在复杂环境下的泛化能力至关重要。", "innovation": "本文提出了一种新颖的深度感知增强技术——深度抖动（Depth-Jitter），用于模拟自然的深度变化，以提升模型的泛化能力。该方法通过自适应的深度偏移，使用深度方差阈值作为引导，生成合成的深度扰动，同时保持结构完整性。深度抖动在FathomNet和UTDAC2020两个基准数据集上进行了评估，展示了在不同深度条件下的模型稳定性。此外，还进行了深度抖动与传统的像ColorJitter这样的增强策略的对比实验，考察了在不同学习率、编码器和损失函数下的性能差异。尽管深度抖动在绝对性能上并不总是优于传统方法，但它显著提高了模型在深度敏感环境下的稳定性和泛化能力。", "conclusion": "研究结果显示，深度感知增强具有在实际应用中改进模型深度泛化能力的潜力，并为深度学习策略的研究提供了基础。所提出的深度抖动技术已公开提供，以支持深度感知增强技术的进一步发展。相关代码可以在GitHub上公开获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker: 空间感知的图像聚焦用于视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大语言模型（MLLMs）在复杂的视觉任务（如空间理解，精细感知）上仍然存在显著挑战。先前的方法尝试融入视觉推理，但未能利用空间线索进行注意力校正，从而逐步聚焦于提示相关区域。", "innovation": "文中引入了SIFThinker，这是一种空间感知的‘以图促思’框架，模拟了人类视觉感知。具体而言，SIFThinker通过交织深度增强的边界框和自然语言，实现了注意力校正和图像区域聚焦。论文贡献有两方面：首先，提出了一种反扩展前向推理策略，促进了交织图像-文本推理过程的生成，进而构建了SIF-50K数据集。其次，提出了集成了深度感知视觉锚定的GRPO-SIF强化训练框架，使模型能够自适应地校正和聚焦于提示相关区域。", "conclusion": "广泛的实验表明，SIFThinker在空间理解和精细视觉感知方面优于现有最先进的方法，同时保持强大的泛化能力，这突显了我们方法的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06224", "html_url": "https://arxiv.org/abs/2508.06224", "title": "TEFormer: 一种用于城市遥感图像语义分割的纹理感知和边缘引导变换器", "title_en": "TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images", "authors": "Guoyu Zhou,Jing Zhang,Yi Yan,Hui Zhang,Li Zhuo", "background": "城市遥感影像（URSIs）的语义分割对于城市规划和环境监测等应用至关重要。但由于地理空间对象常常表现出细微的纹理差异和相似的空间结构，容易导致语义混和误分类。同时，不规则的物体重叠边界、边缘模糊以及语义对象多层次的空间分布等挑战使得边缘形态复杂多样，进一步增加了准确分割的难度。为解决这些问题，我们提出了一个纹理感知和边缘引导变换器（TEFormer），该模型结合了纹理感知和边缘引导机制以增强语义区分。", "innovation": "该研究提出了一种纹理感知和边缘引导变换器（TEFormer），通过设计一个纹理感知模块（TaM）来捕捉视觉上相似但细节差异的纹理差异，以增强语义区分；并通过构造一个边缘引导三分支解码器（Eg3Head）保持局部边缘和细节信息，增强多尺度上下文感知。最后，该研究还引入了一个边缘引导特征融合模块（EgFFM），用于融合上下文和细节信息与边缘信息以实现精细的语义分割。该方法通过在Potsdam、Vaihingen和LoveDA数据集上的大量实验展示了其在URSI语义分割中的有效性。", "conclusion": "实验结果表明，TEFormer在Potsdam、Vaihingen和LoveDA数据集上分别取得了88.57%、81.46%和53.55%的mIoU，进一步证实了该方法在URSI语义分割中的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06191", "html_url": "https://arxiv.org/abs/2508.06191", "title": "基于DBIF-AUNet的胸腔积液语义分割算法", "title_en": "A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet", "authors": "Ruixiang Tang,Jianglong Qin,Mingda Zhang,Yan Song,Yi Wu,Wei Wu", "background": "胸腔积液的影像分割技术能够显著提高临床诊断和治疗的准确性和及时性，但当前存在多种挑战，包括与周围组织灰度相似、边界模糊、形态变化多样等。现有方法在处理多变影像和复杂边界时表现不佳，主要原因是直接特征拼接导致语义差距。", "innovation": "作者提出了名为DBIF-AUNet的双分支互动融合注意力模型，该模型构建了紧密嵌套的跳跃连接网络，并创新性地增强了双域特征解耦模块（DDFD）。该模块正交解耦两个域的功能，实现多尺度特征互补，增强不同层次的特征。此外，设计了分支交互注意力融合模块（BIAF），与DDFD协同工作，动态加权和融合全局、局部和频带特征，提高了分割鲁棒性。同时，实施了嵌套深度监督机制和分层自适应混合损失，有效解决类别不平衡问题。", "conclusion": "DBIF-AUNet在西南医院的1,622张胸腔积液CT影像上验证，实现了80.1%的IoU和89.0%的Dice分数，显著优于U-Net++和Swin-UNet，证明了其在复杂胸腔积液CT图像分割上的显著优化。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06258", "html_url": "https://arxiv.org/abs/2508.06258", "title": "XAG-Net: 一种用于2.5D股骨MRI分割的跨层注意力和跳级门控网络", "title_en": "XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation", "authors": "Byunghyun Ko,Anning Tian,Jeongkyu Lee", "background": "准确从磁共振成像（MRI）中分隔股骨结构对于骨科诊断和手术规划至关重要，但现有的基于深度学习的2D和3D分割方法仍有局限性，使得分割变得具有挑战性。", "innovation": "提出了XAG-Net，这是一种创新的2.5D U-Net架构，结合了像素级跨层注意（CSA）和跳级注意门控（AG）机制，以增强跨层上下文建模和层内特征细化。XAG-Net在每个空间位置对相邻切片应用像素级的Softmax注意力，以实现精细的跨层建模。实验表明，XAG-Net在股骨分割准确性上超越了基础的2D、2.5D和3D U-Net模型，同时保持了计算效率。消融研究表明CSA和AG模块的必要性，确立XAG-Net作为高效且准确的股骨MRI分割框架的潜力.", "conclusion": "XAG-Net在股骨MRI分割的准确性和效率方面取得突破，是2.5D股骨MRI分割的有效解决方案，验证了CSA和AG模块在提升模型性能中的关键作用。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06318", "html_url": "https://arxiv.org/abs/2508.06318", "title": "Mixture of Experts Guided by Gaussian Splatters Matters: A New Approach to Weakly-Supervised Video Anomaly Detection", "title_en": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection", "authors": "Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev", "background": "视频异常检测（VAD）由于异常事件的多样性以及标记数据的有限性而成为一个具有挑战性的任务。在弱监督VAD（WSVAD）范式下，训练时仅提供视频级别的标签，但在预测时需在帧级别进行。当前最先进的模型在简单的异常事件（例如爆炸）上表现良好，但在复杂的现实世界事件（例如盗窃）上存在困难。这种困难源自两个关键问题：（1）现有模型无法针对不同类型的异常处理多样性，它们使用共享模型处理所有类别，忽视了类别特定的特征；（2）弱监督信号缺乏精确的时间信息，限制了捕捉细微异常模式的能力，这些模式与正常事件交织。", "innovation": "我们提出了一个新颖的框架，称为Gaussian Splatting引导的专家混合（GS-MoE），它通过一组专家模型实现，每个专家模型专门用于捕捉特定类型的异常。这些专家由时间Gaussian splatting损失引导，使模型能够利用时间一致性并增强弱监督效果。Gaussian splatting方法通过关注最有可能包含异常事件的时间段，促进对异常的更精确和全面的表示。这些专家的预测是通过专家混合机制集成的，以建模不同异常模式之间的复杂关系。我们的方法在UCF-Crime数据集上取得了91.58%的AUC，优于XD-Violence和MSAD数据集的其他方法。通过利用类别特定专业知识和时间引导，GS-MoE在弱监督下的VAD中设定了新的基准。", "conclusion": "我们的方法在UCF-Crime数据集上取得了91.58%的AUC，超过了XD-Violence和MSAD数据集的其他方法，展示了在弱监督视频异常检测中使用类别特定专业知识和时间引导的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06327", "html_url": "https://arxiv.org/abs/2508.06327", "title": "扩散模型在心脏MRI图像领域差距中的应用", "title_en": "Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?", "authors": "Xin Ci Wong,Duygu Sarikaya,Kieran Zucker,Marc De Kamps,Nishant Ravikumar", "background": "心脏磁共振成像（MRI）等MRI成像因其设备和采集协议的差异容易出现领域转移的问题，这限制了经过训练的AI模型在实际场景中的应用，导致在未见过领域的性能下降。传统的解决方案包括增加数据集大小以通过自定义图像增强或在线训练/迁移学习等方法，但这些方法存在一些局限性。合成数据提供了一种有前景的替代方案，但由于解剖/结构一致性限制，生成模型在生成图像-标签对时效果有限。", "innovation": "本研究提出了一种扩散模型（DM）方法，在源领域上进行训练以生成与给定参考相似的合成心脏MRI图像。合成数据保持空间和结构的一致性，确保与源领域相似并兼容分割掩码。研究评估了生成方法在多中心心脏MRI分割中的实用性，并探索了以DM为基础的两种策略：一是训练领域不变的分割模型；二是通过DM将目标领域数据调整到源领域，这两种策略在表面基度量指标（Welch's t-test，p < 0.01）上显著提高了数据来自未见过目标领域的分割性能，优于仅使用真实数据训练分割模型的方法。该方法减轻了心脏MRI图像分析中的领域转移挑战，特别是在数据稀缺的情况下非常有用。", "conclusion": "提出的扩散模型方法减轻了心脏MRI图像分析中的领域转移挑战，特别是在数据稀缺的情况下。这两种策略在表面积分指标上显著提高了未见过目标领域的分割性能，验证了这种方法在多中心心脏MRI分割中的有效性和价值。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06342", "html_url": "https://arxiv.org/abs/2508.06342", "title": "街景社交性：15个城市中城市社交行为的可解释分析", "title_en": "Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities", "authors": "Kieran Elrod,Katherine Flanigan,Mario Bergés", "background": "长期而言，设计社会活跃的街道是城市规划的目标，但现有的定量研究主要测量行人流量，而不是社交互动的质量。为此，作者假设街景图像这一低成本、具有全球覆盖的数据源中包含了潜在的社交信息，并可利用已建立的社会科学理论提取和解释。", "innovation": "作者利用多模态大型语言模型分析了来自15个城市共2998张街景图像，采用由Mehta的社会交往分类（即临时性、短暂性和持久性的社交）为指导，测试社会互动水平是否与城市级地方依附评分及环境预测因子相关。利用线性回归模型控制天气、时间及行人数量等因素后，发现天空视角指数与三种社交类型均相关，绿色视角指数预测了持久社交，地方依附与短暂社交正相关。这一研究结果为利用街景图像推断特定类型的社交互动与建成环境变量之间的关系提供了初步证据。", "conclusion": "这些结果表明街景图像可以被用于推断特定类型的社交互动与建成环境变量之间的关系。未来的研究可以将街景图像确立为一种可扩展、隐私保护的工具，用于研究城市社交性，从而促进跨文化交流理论测试和基于证据的城市振兴设计。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06350", "html_url": "https://arxiv.org/abs/2508.06350", "title": "在大型语言模型中对齐有效的视频异常标记", "title_en": "Aligning Effective Tokens with Video Anomaly in Large Language Models", "authors": "Yingxian Chen,Jiahui Liu,Ruifan Di,Yanwei Li,Chirui Chang,Shizhen Zhao,Wilton W.T. Fok,Xiaojuan Qi,Yik-Chung Wu", "background": "理解视频中的异常事件是一项至关重要的挑战性任务，广泛应用于多种应用中。尽管当前的多模态大型语言模型（MLLMs）能够分析普遍的视频内容，但在处理异常事件时往往表现不佳，因为这些异常事件在时空上较为稀疏，导致模型容易陷入冗余信息，从而产生次优的结果。", "innovation": "为了应对这些挑战，该研究引入了VA-GPT，一种新设计的MLLM，特别适用于异常事件的总结与定位。该模型通过两个关键模块Spatial Effective Token Selection (SETS) 和 Temporal Effective Token Generation (TETG) 效率地在视觉编码器和大型语言模型之间对齐有效标记，从而更好地捕捉和分析异常事件相关的时空信息。此外，研究还构建了一个专门用于视频异常感知大型语言模型微调的数据集，并引入了一个基于XD-Violence数据集的跨领域评估基准。", "conclusion": "所提出的VA-GPT方法在各种基准测试中表现优于现有最先进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06205", "html_url": "https://arxiv.org/abs/2508.06205", "title": "PA-HOI: 一个物理感知的人和物体交互数据集", "title_en": "PA-HOI: A Physics-Aware Human and Object Interaction Dataset", "authors": "Ruiyan Wang,Lin Zuo,Zonghao Lin,Qiang Wang,Zhengxue Cheng,Rong Xie,Jun Ling,Li Song", "background": "人类-物体交互（HOI）任务探讨了人类与物体在物理环境中的动态交互，为机器人学、虚拟现实和人机交互等领域提供了必要的生物力学和认知行为基础。然而，现有HOI数据集主要关注物体的使用属性，忽视了物体物理特性对人类长时间运动的影响。", "innovation": "本文引入了PA-HOI运动捕捉数据集，着重展示了物体物理属性对人类运动动态的影响，包括人体姿势、移动速度和其他运动特征。该数据集包含562个不同性别受试者与35个不同大小、形状和重量的3D物体进行的人物体交互动力序列。相比于现有数据集，PA-HOI显著扩展了对不同物体物理属性如何影响人类姿势、速度、运动规模和交互策略的理解。", "conclusion": "通过与现有运动生成方法集成，证明了PA-HOI数据集在传输实际物理感知方面的适用性和能力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06351", "html_url": "https://arxiv.org/abs/2508.06351", "title": "使用分裂布根曼方法实现两阶段图像分割", "title_en": "An Implemention of Two-Phase Image Segmentation using the Split Bregman Method", "authors": "Olakunle S. Abawonse,Günay Doğan", "background": "本文描述了Goldstein, Bresson, Osher在文献[1]中提出的两阶段图像分割算法的实现。该算法将给定图像的域分割为前景和背景区域，并将每个像素归属到这两个区域之一。该分割模型假设输入图像的像素值可以被总结为两类不同的平均值，并且区域边界是平滑的。因此，模型定义为能量函数，将变量设定为一个区域归属函数，最初由Chan和Vese在文献[2]中提出。能量函数包括图像数据项和区域边界的长度惩罚。Goldstein, Bresson, Osher通过对Chan-Vese能量模型的修改，使得新的能量函数可以通过分裂布根曼方法高效地最小化，并产生等价的两阶段分割结果。本文详细描述了该方法的实现，并通过多种图像在不同算法参数下进行了性能测试。", "innovation": "提出了一种通过分裂布根曼方法来有效最小化新能量函数的两阶段图像分割算法，并成功实现了该方法。该方法能够高效地产生高质量的两阶段图像分割结果，适用于多种图像处理场景。", "conclusion": "本文提供了Chan和Vese在文献[2]中提出的区域归属函数模型，以及Goldstein, Bresson, Osher在文献[1]中进行的改进和实现。通过实例分析，验证了该算法的有效性和鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06357", "html_url": "https://arxiv.org/abs/2508.06357", "title": "你在画廊里还是外面？来自同一身份群体的智慧", "title_en": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd", "authors": "Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer", "background": "在单对多的面部识别问题中，探测图像中的人可能会或不会出现在画廊中，即可能是In-gallery或Out-of-gallery。过去的许多方法主要集中在寻找相似度分数的合适阈值，来区分排名第一的识别结果是否是Out-of-gallery。该论文提出了一种新的方法，利用排名第一的身份对应的额外注册图像，来预测该排名结果是否是In-gallery或Out-of-gallery。这种方法通过生成In-gallery和Out-of-gallery的数据集来进行训练，并通过不同的数据集和匹配器展示了该方法的有效性，包括图像模糊、分辨率降低、大气湍流和佩戴太阳镜等恶劣条件下的图像。同时，也分析了不同人口群体的结果，表明In-gallery/Out-of-gallery分类的准确性在不同人群中相似。", "innovation": "该研究提出了一种新的方法，利用排名第一的身份对应的额外注册图像，来预测该排名结果是否是In-gallery或Out-of-gallery。这种方法通过生成In-gallery和Out-of-gallery的数据集来进行训练，并展示在不同条件下的有效性和不同人口群体的适用性，特别是对老式和新式的深度CNN面部匹配器进行了比较，强调了使用先进的margin-based损失函数训练匹配器的重要性。", "conclusion": "该方法能够客观评估单对多面部识别是否为Out-of-gallery，从而减少误识别、错误逮捕和浪费的调查时间。特别是该方法随着更先进的边缘损失函数训练的匹配器的发展而变得更加有效。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06317", "html_url": "https://arxiv.org/abs/2508.06317", "title": "不确定性量化回放策略适应性在无标注跨域时间定位中的应用", "title_en": "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding", "authors": "Jian Hu,Zixu Cheng,Shaogang Gong,Isabel Guan,Jianye Hao,Jun Wang,Kun Shao", "background": "视频时间定位（TG）旨在在较长的视频中定位与自然语言描述（查询）匹配的视频片段。尽管视觉-语言模型（VLMs）在整体语义匹配上表现良好，但在细节的时域定位上却常常表现不佳。近年来，Group Relative Policy Optimisation (GRPO) 将推理过程重新定义为一个强化学习任务，从而实现了精细的定位并在本领域内取得了优异的表现。然而，GRPO 需要标注数据，这使其在未标注领域无法使用。此外，由于视频文件庞大且存储和处理成本高昂，进行全规模适应会引入不可接受的延迟和计算开销，使其不适合实时部署。为了解决以上问题，我们提出了一种数据高效、适用于未标注跨域时间定位的方法。该方法首先在有标注的源域上训练模型，然后通过少量目标未标注视频对该模型进行适应，无需目标数据标注，并且计算和存储开销较低，可以在实时运行。", "innovation": "我们提出了 Uncertainty-quantified Rollout Policy Adaptation (URPA) 用于在没有目标标签的情况下，在学习视频时间定位时进行跨域知识转移。URPA 使用 GRPO 的回放策略生成多个候选预测，并通过这些回放策略的方差生成伪标签，然后从校验方差中估算置信度，该置信度作为训练奖励的权重，引导模型集中在可靠监督上。实验表明，URPA 使用少量未标注目标视频就能很好地进行泛化。", "conclusion": "在三种数据集上进行的六个跨域设置实验表明，URPA 能够利用少量无标注目标视频进行良好泛化。未来，代码将随论文发表。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06382", "html_url": "https://arxiv.org/abs/2508.06382", "title": "零样本分类中一致提示调优的任何模态文本", "title_en": "Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning", "authors": "Xiangyu Wu,Feng Yu,Yang Yang,Jianfeng Lu", "background": "尽管将提示调优与多模态学习的整合已经在各种下游任务中显示出了显著的泛化能力，但现有方法仍然高度依赖大规模的特定模态标记数据（如视频、音频和图像），或者专门针对单一模态进行了定制。因此，存在一个挑战是构建一个可扩展的框架，能够仅利用文本数据适应无限模态的一般表征模型.", "innovation": "提出了TaAM-CPT（文本作为任意模态的一致提示调优），这是一种利用仅文本数据构建通用表示模型的可扩展方法。TaAM-CPT通过模态提示池、文本构建和模态对齐的预训练模型编码器，可以轻松扩展到新的模态。设计了跨模态的内部和外部学习目标，能够捕捉不同模态内的类细节同时保持语义一致性。该模型架构适用于无限模态的无缝扩展，无需特定模态的数据支持，并在各种模态（包括视频分类、图像分类和音频分类）的多个数据集上取得了领先成果.", "conclusion": "TaAM-CPT方法通过仅使用文本数据实现跨无限模态的一般表示学习，其可扩展架构和预训练模型使得模型可以无缝推广到任何新模态。实验结果表明，TaAM-CPT在各类模态任务上取得了卓越的效果，尤其是在无需特定模态的标注数据的情况下."}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06407", "html_url": "https://arxiv.org/abs/2508.06407", "title": "SAR影像中具有分类意识的超分辨率框架", "title_en": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery", "authors": "Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus", "background": "高分辨率图像在提高视觉识别任务（如分类、检测和分割）方面起着关键作用。尤其是遥感和监控领域，低分辨率图像限制了自动分析的准确性。传统的超分辨率（SR）技术旨在通过像素级指标优化图像质量，但现有技术对超分辨率图像保真度与下游分类性能之间的关系探索不足，从而带来了一个关键问题：是否可以将分类目标直接整合到超分辨率过程中，进一步提升分类的准确性？这篇文章通过开发专门的算法策略，研究了超分辨率与分类之间的关系，并提出了一种新的方法，通过优化同时考虑图像质量和分类性能的损失函数，提高了雷达影像的分辨率，提高了科学验证的图像质量和分类准确性。", "innovation": "本文提出了一个全新的方法，即通过优化同时考虑图像质量和分类性能的损失函数，提高了雷达影像的分辨率，进而提高分类的准确性。这与传统的仅基于像素级指标优化图像质量的方法形成了对比，从而进一步探索了超分辨率图像保真度与下游分类性能之间的关系，为图像处理和识别任务提供了一种新方法。", "conclusion": "研究结果表明，通过优化同时考虑图像质量和分类性能的损失函数，可以提高雷达图像的分辨率并提高分类准确性。这种分类意识的超分辨率框架可以为遥感和雷达图像的分析和识别提供改进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06434", "html_url": "https://arxiv.org/abs/2508.06434", "title": "CLIPin: 一种用于CLIP的非对比插件以提高跨模态语义对齐", "title_en": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment", "authors": "Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li", "background": "现有的大规模自然图像-文本数据集由于弱监督往往存在语义对齐不紧密的问题，而医学数据集则表现出跨模态高度相关但内容多样性较低的特点。这些特性对对比学习预训练（CLIP）模型提出了挑战：它们妨碍了模型学习稳健和泛化的表示。本文探讨了这一背景。", "innovation": "本文提出了一种名为CLIPin的统一非对比插件，可以无缝集成到CLIP风格的架构中，以改善跨模态语义对齐，提供更强的监督并增强对齐的稳健性。此外，还设计了分别用于图像和文本模态的共享预投影器，以在参数妥协的方式下促进对比学习和非对比学习的结合。通过在多样化的下游任务上的广泛实验，证明了CLIPin作为可与各种对比框架兼容的即插即用组件的有效性和通用性。", "conclusion": "CLIPin 作为可与各种对比框架兼容的即插即用组件，其在多种下游任务上的广泛实验表明了其有效性与通用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06335", "html_url": "https://arxiv.org/abs/2508.06335", "title": "ViPro-2：通过集成动力学进行无监督状态估计以指导视频预测", "title_en": "ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction", "authors": "Patrick Takenaka,Johannes Maucher,Marco F. Huber", "background": "预测未来的视频帧是一个具有广泛下游应用的挑战性任务。先前的工作表明，在复杂动力系统中，程序化知识能帮助深度模型提高表现。然而，ViPro模型假设已经给定一个初始符号状态的真实值。这种方法导致模型学习了一个捷径，而不是真正地将观察到的环境和预测的符号状态连接起来，从而削弱了在输入观察存在噪声的情况下估计状态的能力。", "innovation": "本文对ViPro进行了多项改进，使其能够无监督地从观察中正确推断状态，而不再需要提供完整的初始真实状态。我们展示了这种改进并通过扩展原始的Orbits数据集，增加一个3D版本来逼近现实世界场景。", "conclusion": "改进后的模型能够在无监督的情况下，通过集成动力学机制从观察中推断出正确的状态估计，进而提升视频预测的能力。我们通过扩展Orbits数据集来进一步提高模型在真实世界环境中的适用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06452", "html_url": "https://arxiv.org/abs/2508.06452", "title": "TRUST: 利用文本的稳健性进行无监督领域适应", "title_en": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation", "authors": "Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia", "background": "近年来，无监督领域适应（UDA）方法在解决经典的领域转换问题（如合成到真实）方面取得了显著成功，但在复杂的领域转换（如地理转换）方面仍然存在挑战，这是因为背景和对象外观在不同领域之间存在显著差异。既往研究表明，语言模态可以在适应过程中提供更强的鲁棒性，帮助应对复杂的领域转换。然而，现有方法在处理低质量图像字幕时可能会受到伪标签错误的影响，从而影响视觉模型的鲁棒性。", "innovation": "本文提出了一种新颖的方法TRUST，该方法利用语言模态的稳健性来引导视觉模型的适应过程。TRUST通过从目标样本的字幕中生成伪标签，并提出了一种新的不确定性估计策略，该策略使用标准化的CLIP相似度分数来估计生成的伪标签的不确定性。此外，TRUST还提出了一种多模态软对比学习损失，通过利用字幕来引导视觉模型在目标图像上的对比训练，增强了视觉模型的鲁棒性。这种方法避免了在无监督领域适应设置中确定正负样本对的难题。", "conclusion": "本方法在经典（DomainNet）和复杂（GeoNet）领域转换上超过了现有方法，设立了新的最先进水平。代码将在论文被接受后提供。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06453", "html_url": "https://arxiv.org/abs/2508.06453", "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "title_en": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "authors": "Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers", "background": "CT病变分割可以实现对慢性疾病的（如淋巴瘤）自动测量，目前该技术已经应用于临床评估。将大型语言模型（LLMs）整合到病变分割工作流程中，可以结合影像特征和放射学报告中描述的病变特征。Ultraluminous Segmentation and Lesion Analysis (ULS23)深度病变数据集用于实验，该数据集包含病变的简要描述。", "innovation": "提出了一种将文本嵌入到Swin-UMamba架构中的方法，用于病变分割任务。该方法在测试集上获得了82%的高Dice分数和6.58像素的低Hausdorff距离。这种方法在多种模型中表现出色，比LLM驱动的LanGuideMedSeg模型提高了37%，比基于图像的xLSTM-UNet和nnUNet模型分别提高了1.74%和0.22%。", "conclusion": "研究证明，将文本嵌入Swin-UMamba架构可以改进病变分割任务，提出了Text-Swin-UMamba模型，并在多个基准测试中均表现出色，上述成果的代码和数据集可通过指定链接获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06429", "html_url": "https://arxiv.org/abs/2508.06429", "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "title_en": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "authors": "Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda", "background": "深度学习在医学成像领域取得了革命性进展，但其效果严重受限于标注训练数据不足。本文介绍了一种专门为数据量少的场景设计的基于生成对抗网络(GAN)的半监督学习框架，该框架在每类5到50个标注样本的设置下进行了评估。", "innovation": "该方法通过交替使用有限的标注数据进行监督训练，并融合大量未标注图像进行无监督学习，利用图像到图像的翻译而非从噪声生成。引入了基于集成的伪标签方法，结合判别器和分类器的置信加权预测和指数移动平均的时间一致性，以可靠地估计未标注数据的标签。该方法在11个MedMNIST数据集中实现了统计显著性改进，特别是在极端5射排列设置中表现尤为突出，此时标注数据的稀缺性是最大挑战。", "conclusion": "该框架在所有评估设置（每类别5、10、20和50射）下都保持其优越性，为注解成本高的医学影像应用提供了实际解决方案，即使在少量标注数据的情况下也能实现稳健的分类性能。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06430", "html_url": "https://arxiv.org/abs/2508.06430", "title": "MotionSwap", "title_en": "MotionSwap", "authors": "Om Patil,Jinesh Modi,Suryabha Mukhopadhyay,Meghaditya Giri,Chhavi Malhotra", "background": "面交换技术在学术研究和商业应用中获得了广泛关注。本论文提出了对SimSwap的实现和改进，SimSwap是一个高效的高保真面交换框架。通过对原始模型的改进，包括融合自我和跨注意力机制、动态损失权重以及余弦退火学习率调度，显著提高了身份保留、属性一致性以及整体视觉质量。实验结果表明，增强模型在生成器和判别器性能上取得了渐进的提升，与基准模型相比具有更好的身份相似度、更低的FID分数以及更优的定性结果。消融研究表明，每种架构和训练改进的重要性。越来越多地，风格迁移技术将被集成，音唇同步将得到改进，引入3D面部建模，以及在视频基础上引入时间一致性以应对未来的方向。", "innovation": "通过对原始模型的改进，包括融合自我和跨注意力机制、动态损失权重以及余弦退火学习率调度。这些改进显著提高了身份保留、属性一致性以及整体视觉质量。此外，消融研究表明每种改进的重要性，且未来方向强调风格GAN3集成、音唇同步改进、3D面部建模和时间一致性引入于视频基础应用中。", "conclusion": "实验结果表明增强模型在生成器和判别器性能上取得了渐进的提升，与基准模型相比具有更好的身份相似度、更低的FID分数以及更优的定性结果。消融研究表明每种架构和训练改进的重要性。未来的研究方向将集成StyleGAN3，改进唇同步，引入3D面部建模，并引入视频的时序一致性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06494", "html_url": "https://arxiv.org/abs/2508.06494", "title": "LightSwitch: 多视图光照调整与物料指导的扩散模型", "title_en": "LightSwitch: Multi-view Relighting with Material-guided Diffusion", "authors": "Yehonathan Litman,Fernando De la Torre,Shubham Tulsiani", "background": "近年来，三维（3D）光照调整方法已展现出结合二维（2D）图像生成先验以改变3D表示的外观并保留其基础结构的潜力。然而，直接从输入图像进行光照调整的2D光照生成先验未充分利用主题的固有属性，且无法处理大规模的多视角数据，导致光照调整效果不佳。", "innovation": "本文提出了一种名为Lightswitch的新型微调物质调光扩散框架。该框架通过同时利用多视角和物料信息提示，结合可扩展的降噪方案，有效地将任意数量的输入图像光照调整至目标光照条件，即使是在具有多种物质组成的密集多视角数据对象上也能实现一致且高效的光照调整。此外，LightSwitch能够超越以往直接从图像进行光照调整的最先进光照先验方法，并在合成和真实物体的光照调整中与最先进的扩散逆渲染方法相媲美或更优，且耗时仅为2分钟左右。", "conclusion": "研究表明，Lightswitch在多视角光照调整方面表现卓越，尤其在与最先进技术相比时，在耗时短的情况下实现高质量的2D光照调整预测，并且在物体的多视角数据光照调整方面表现出色。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04728", "html_url": "https://arxiv.org/abs/2508.04728", "title": "基于神经场的扫描电子显微镜多探测器信号微结构3D表面重构", "title_en": "Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy", "authors": "Shuo Chen,Yijin Li,Xi Zheng,Guofeng Zhang", "background": "扫描电子显微镜（SEM）在科学研究和工业应用中被广泛应用。传统的二维（2D）SEM图像不能直接反映微细样品的三维（3D）形貌，因此需要开发SEM 3D表面重构方法。然而，现有的方法在对复杂微结构的重构上仍面临挑战，主要由于离散的3D表示法的限制、需要通过参考样品进行校准、以及阴影引起的梯度误差。", "innovation": "提出了基于神经场的混合扫描电子显微镜（NFH-SEM）3D表面重构方法，该方法通过端到端的自我校准和在训练过程中自动分离阴影，无需手动校准步骤，直接融合多视角、多探测器的2D SEM图像中的几何和光度信息，形成连续的神经场表示。", "conclusion": "该研究在实际和模拟数据集上验证了NFH-SEM的有效性，结果显示其能够高保真地重构复杂、具有挑战性的样品，包括双光子光刻微结构、桃花粉和碳化硅颗粒表面，证明了其精确和广泛的应用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05658", "html_url": "https://arxiv.org/abs/2508.05658", "title": "Universally Unfiltered and Unseen: Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards", "title_en": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards", "authors": "Song Yan,Hui Wei,Jinlong Fei,Guoliang Yang,Zhengyu Zhao,Zheng Wamg", "background": "已经存在多种文本提示过滤器和图像检查器来防止文本生成图像（T2I）模型在生成不适宜的工作内容（NSFW）时被滥用。然而，现有的缓释措施存在局限性，只能针对特定的提示或图像进行扰动，缺乏通用性和可扩展性。为了揭露这些安全防护的漏洞，提出了多模态逃逸攻击（U3-Attack），旨在绕过现有的防护措施以生成NSFW内容。", "innovation": "提出了U3-Attack，这是一种对抗性多模态逃逸攻击方法，旨在通用地绕过图像背景中的安全检查器和敏感词汇的文本提示过滤器。U3-Attack能够优化图像背景和文本提示中的潜在安全漏洞，使其在多种场景下都能实现更好的效果。实验结果表明，在两个开源和商用的T2I模型上，U3-Attack显著提高了成功的逃逸率，相较于现有技术，成功率提高了约4倍。", "conclusion": "实验结果证明了U3-Attack在绕过T2I安全防护方面具有显著的优势，描绘了通用和无感知的多模态攻击场景。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05838", "html_url": "https://arxiv.org/abs/2508.05838", "title": "将视觉基础模型与强化学习结合以增强物体交互", "title_en": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "authors": "Ahmad Farooq,Kamran Iqbal", "background": "本文介绍了一种新颖的方法，该方法将视觉基础模型与强化学习相结合，以增强模拟环境中物体交互能力。通过将Segment Anything Model (SAM) 和 YOLOv5 与在AI2-THOR仿真环境中运行的Proximal Policy Optimization (PPO)智能体结合起来，我们使智能体能够更有效地感知和交互物体。通过在四个不同室内厨房设置中进行全面实验，该研究证明了在物体交互成功率和导航效率方面比没有高级感知能力的基本智能体有显著改善。实验结果表明，平均累积奖励提高了68%，物体交互成功率提高了52.5%，导航效率提高了33%。这些发现突显了将基础模型与强化学习相结合对于复杂机器人任务的巨大潜力，为更先进和强大的自主智能体铺平了道路。", "innovation": "本文提出了将视觉基础模型与强化学习结合的新方法，以增强模拟环境中物体交互能力。具体包括使用Segment Anything Model (SAM) 和 YOLOv5 与Proximal Policy Optimization (PPO)智能体的结合，以及在AI2-THOR仿真环境中进行的全面实验。实验结果表明，这种结合提高了物体交互成功率和导航效率。", "conclusion": "本文的研究证实了将基础模型与强化学习相结合对复杂机器人任务的有效性，为未来开发更先进和强大的自主智能体提供了可能。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06065", "html_url": "https://arxiv.org/abs/2508.06065", "title": "ThematicPlane: 在主题设计平面中弥合隐含用户意图与潜在空间", "title_en": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "authors": "Daniel Lee,Nikhil Sharma,Donghoon Shin,DaEun Choi,Harsh Sharma,Jeonghwan Kim,Heng Ji", "background": "生成式AI已经让图像创作变得更加容易，但要让输出结果与精细的创意意图保持一致，尤其是对于非专家来说，仍然存在挑战。现有的工具通常需要用户通过提示或参考材料来外部化他们的想法，这限制了用户的灵活探索。现有的工具和方法难以直接表达和控制高层面的语义概念，如氛围、风格或叙述语气。", "innovation": "ThematicPlane是一个系统，它使用户能够在交互式主题设计平面上导航和操控高层的语义概念（例如，氛围、风格或叙述语气），从而弥合隐含的创意意图和系统控制之间的差距。这项界面在探索性研究中证明了其有效性，用户能够进行发散和收敛的创造模式，通常将意想不到的结果视为灵感或迭代的提示。", "conclusion": "ThematicPlane促进了表达性和迭代的工作流程，并突显了生成设计工具中新方向的直观、语义驱动的交互。不过，由于他们在探索主题时对主题如何映射到输出结果的预期存在差异，这显示了需要更可解释的控制手段。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06001", "html_url": "https://arxiv.org/abs/2508.06001", "title": "KnapFormer: 一种高效扩散变换器训练的在线负载均衡器", "title_en": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "authors": "Kai Zhang,Peng Wang,Sai Bi,Jianming Zhang,Yuanjun Xiong", "background": "在分布式训练扩散变换器（DiT）时，工作负载平衡和序列并行性之间的强协同作用需要被充分考虑。变量长度的文本输入和混合分辨率以及图像-视频联合训练中不同的视觉标记数量，导致了不同节点之间的标记不平衡。KnapFormer通过解决全局背包问题，首先在所有节点之间收集序列长度的元数据，并对每个GPU的工作负载差异进行优化，从而解决这一问题。", "innovation": "KnapFormer提出了一个高效且多功能的框架，用于结合工作负载平衡和序列并行性，特别针对扩散变换器的分布式训练。通过使用DeepSpeed-Ulysees为基础的序列并行性，并结合一个简单的半经验工作负载模型，在不增加通信开销的情况下，实现了工作负载差异在几 hundred 到 tens of thousands 的不同序列长度的训练工作负载中低于1%的差异。KnapFormer能够消除拖后腿效应，在训练如FLUX等先进扩散模型时，对比混合分辨率和图像-视频联合数据集，实现了2倍到3倍的加速效果。", "conclusion": "KnapFormer通过上述方法，在实际训练中实现了高效的工作负载平衡，并且在训练扩散模型方面取得了显著的加速效果。此开源实现可以在上述链接处获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06151", "html_url": "https://arxiv.org/abs/2508.06151", "title": "使用扩散模型生成的修复合成功像提高口腔癌诊断准确性", "title_en": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models", "authors": "Yong Oh Lee,JeeEun Kim,Jung Woo Lee", "background": "在口腔癌诊断中，注释数据集的有限可获取性经常限制诊断模型的表现，尤其是由于训练数据的多样性和不足。为了解决这些挑战，本研究提出了一种通过使用微调扩散模型的修复技术合成功理的方法，以提高诊断准确性。", "innovation": "提出了一种通过使用微调扩散模型的修复技术合成功理的方法，以生成具有高度视觉真实性的合成病变，显著提高了诊断算法的表现。", "conclusion": "结果显示，我们的分类模型在区分癌变和非癌变组织方面实现了0.97的诊断准确率，我们的检测模型在识别病变位置方面达到了0.85的准确性。此方法证明了合成图像生成在医学诊断中的潜力，并为将这些方法扩展到其他类型的癌症诊断铺平了道路。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06137", "html_url": "https://arxiv.org/abs/2508.06137", "title": "基于变压器的可解释深度学习在乳腺癌检测中的应用：MammoFormer框架", "title_en": "Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework", "authors": "Ojonugwa Oluwafemi Ejiga Peter,Daniel Emakporuena,Bamidele Dayo Tunde,Maryam Abdulkarim,Abdullahi Bn Umar", "background": "通过乳腺X光摄影识别乳腺癌仍具有挑战性，因为专家需要识别细微的异常变化，而读片之间存在差异。尽管卷积神经网络（CNNs）在医学图像分析中具有潜力，但它们在处理局部信息和大范围上下文数据方面存在不足，并且无法提供医生在临床环境中可接受的可解释人工智能（XAI）操作。", "innovation": "该研究开发了MammoFormer框架，结合了基于变压器的架构、多特征增强组件和XAI功能，测试了七种不同的架构（包括CNNs、Vision Transformer、Swin Transformer和ConvNext）和四种增强技术（原始图像、负值转换、自适应直方图均衡化和方向直方图）。该框架通过特定架构的功能增强实现系统的优化，提供了多视角的诊断解释性，并结合了CNN的可靠性与变压器的全局上下文建模，使得使用适合特征增强的变压器模型可以取得与CNN方法相当或更好的结果。ViT的准确率达到了98.3%的水平，而Swin Transformer则通过HOG增强改进了13.0%的性能。", "conclusion": "该研究通过MammoFormer框架解决了AI乳腺癌检测系统在临床应用中的关键障碍，实现了可解释的性能提升，并提供了一种结合了不同模型优势的临床可部署系统。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05669", "html_url": "https://arxiv.org/abs/2508.05669", "title": "为马来西亚审计财务报告中的财务表格的Markdown转换微调视觉语言模型", "title_en": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "authors": "Jin Khye Tan(Faculty of Computer Science and Information Technology, Universiti Malaya),En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah", "background": "从财务文档中准确地提取和表示表格结构仍然是文档理解中的重要挑战，特别是在监管和分析场景中。本文的研究针对马来西亚审计财务报告中的财务表格转换为Markdown格式的任务，特别复杂，因涉及旋转布局、多级表头和隐含的结构线索。现有模型在这方面的表现不尽如人意，特别是那些前提是自托管的，操作时间较长，准确率也不及广泛使用的主要知识产权模型GPT-4o和Gemini 2.5 Flash。", "innovation": "本文提出了一种基于Qwen2.5-VL-7B的微调视觉语言模型（VLM），专门用于从文档图像中生成高保真Markdown。该方法包括一个由2,152个图像-文本对组成的增强数据集，并采用LoRA进行监督微调。通过一个基于评分标准的语言模型作为法官和一个新颖的Markdown树编辑距离相似性（TEDS）度量的双框架评估了模型性能，实现了92.20%的整体准确性和96.53%的Markdown TEDS评分，远超其基础模型Qwen2.5-VL-7B、更大规模的视觉语言模型和专门提供推理能力的模型。相比这些自托管替代品，它还大大减少了推理时间，其准确性也超越了广泛使用的主要知识产权模型如OpenAI的GPT-4o和Gemini 2.5 Flash。这些结果表明，特定领域的微调提供了一种有效且高效的解决方案，以弥补无结构财务文档到下游自动化之间的差距，而不像更广泛的大模型那样消耗大量计算资源。", "conclusion": "本文通过微调视觉语言模型成功实现了马来西亚审计财务报告中财务表格的高保真Markdown转换，展示了特定领域微调的有效性和效率，并证明了其性能超越了现有主要知识产权模型，同时在推理时间上具有明显优势。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06287", "html_url": "https://arxiv.org/abs/2508.06287", "title": "准确的肺癌检测与分类的高级深度学习技术", "title_en": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification", "authors": "Mobarak Abumohsen,Enrique Costa-Montenegro,Silvia García-Méndez,Amani Yousef Owda,Majdi Owda", "background": "肺癌是全球最常见的诊断癌症之一，也是男性和女性的主要死因之一。CT图像因其低成本和快速处理时间而成为首选的诊断方法。尽管许多研究人员提出了多种使用CT图像检测肺癌的方法，但这些技术存在大量假阳性结果，导致准确性较低。根本原因是数据集较小且不平衡。", "innovation": "基于DenseNet201模型提出一种新颖的肺癌检测和分类方法，包括焦点损失、数据增强和正则化等高级方法，以解决数据不平衡和过拟合问题。", "conclusion": "研究成果表明提案的适当性，达到了98.95%的高精度性能。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06206", "html_url": "https://arxiv.org/abs/2508.06206", "title": "Affordance-R1: 多模态大规模语言模型中可泛化的 affordance 推理的强化学习", "title_en": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model", "authors": "Hanqing Wang,Shaoyang Wang,Yiming Zhong,Zemin Yang,Jiamin Wang,Zhiqing Cui,Jiahao Yuan,Yifan Han,Mingyu Liu,Yuexin Ma", "background": "affordance grounding 关注于预测与机器人即将执行的动作相关的物体特定区域，对于人机交互、人机物交互、具身操作和感知等领域至关重要。现有模型往往忽视不同物体间共享的 affordance，由于缺乏链式思维推理能力，限制了其跨域泛化能力和显式推理能力。", "innovation": "提出了 Affordance-R1，这是一种在强化学习框架内结合认知链式思维指导组相对策略优化（GRPO）的统一 affordance 地接地框架。设计了一种复杂的 affordance 函数，包含格式、感知和认知奖励，有效引导优化方向。构建了高质量的基于 affordance 的推理数据集 ReasonAff，支持训练。通过 GRPO 和强化学习训练，而没有显式推理数据，Affordance-R1 实现了强大的零样本泛化和测试时推理能力。实验表明，该模型超越了现有方法，并展示了开放世界泛化能力。到目前为止，这是首次将基于 GRPO 的 RL 与推理相结合应用于 affordance 推理中。", "conclusion": "通过完全基于强化学习和 GRPO 训练，且没有显式推理数据支持，Affordance-R1 在 general-world 平面上表现出色，实现了 robust zero-shot generalization 和 emergent test-time reasoning capabilities。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06301", "html_url": "https://arxiv.org/abs/2508.06301", "title": "FedMeNF：针对神经场的隐私保护联邦元学习", "title_en": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "authors": "Junhyeog Yun,Minui Hong,Gunhee Kim", "background": "神经场提供了一种内存高效的表示数据方法，能够有效处理多种模态和大规模数据。然而，学习神经场所需的训练数据量和计算量往往很大，这在资源受限的边缘设备上是有限的。Federated Meta-Learning (FML) 是一种可利用的方法，但在传统FML方法中，隐私泄露也是一个问题。", "innovation": "我们提出了一种新的FML方法，称为FedMeNF。FedMeNF 利用一种新的隐私保护损失函数，来调节局部的元优化中的隐私泄露。这使局部元学习者可以在不保留客户端私人数据的情况下，能够快速有效地进行优化。", "conclusion": "我们的实验表明，FedMeNF能够在少样本或非独立同分布的数据下，针对多种数据模态实现快速优化和稳健的重建性能，同时保护客户端数据隐私。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06325", "html_url": "https://arxiv.org/abs/2508.06325", "title": "Anti-Tamper Protection for Unauthorized Individual Image Generation", "title_en": "Anti-Tamper Protection for Unauthorized Individual Image Generation", "authors": "Zelin Li,Ruohan Zong,Yifan Liu,Ruichen Yao,Yaokun Liu,Yang Zhang,Dong Wang", "background": "随着个性化图像生成技术的发展，肖像权和隐私侵权伪造攻击的担忧日益增加。现有的防护算法可以干扰伪造生成，然而，当伪造攻击者使用净化技术绕过保护时，这些保护算法将失效。", "innovation": "提出了一种新的方法Anti-Tamper Perturbation (ATP)，其特点是结合了防护干扰和授权干扰。防护干扰抵御伪造攻击，授权干扰检测基于净化的篡改。ATP在频域中应用，并通过掩膜引导确保防护干扰不对授权干扰造成干扰，同时允许授权干扰均匀分布在所有图像像素中，保持其对基于净化的篡改的敏感性。", "conclusion": "通过广泛的实验，ATP在各种攻击场景下证明了其有效防护伪造攻击的能力，提供了一种保护个体肖像权和隐私的稳健解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06490", "html_url": "https://arxiv.org/abs/2508.06490", "title": "Multivariate Fields of Experts", "title_en": "Multivariate Fields of Experts", "authors": "Stanislas Ducotterd,Michael Unser", "background": "现有基于图像先验的方法，如领域专家模型，通常仅适用于特定的范数，限制了它们的适用范围和性能。这些方法通过单变量潜在函数进行建模，但它们在处理高维或复杂的问题时效率较低。", "innovation": "引入了一种新的多变量领域专家框架，通过利用Moreau包络构造的$\text{$\boldsymbol{\text{\textasciiliadi}}_{\boldsymbol{\text{\textasciilatinf}}}$-范数$\text{潜在函数}，这种方法可以泛化现有方法，并应用于多种逆问题，同时表现出优于经典方法的性能，且训练速度更快、需要更少的参数和数据。", "conclusion": "与类似的单变量模型相比，提出的方法在各种逆问题上的性能更优，并接近深度学习正则化方法的效果，但其训练速度快，需要的参数和数据更少，并且模型设计使其保持了一定程度的可解释性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06392", "html_url": "https://arxiv.org/abs/2508.06392", "title": "FVGen: 通过对抗视频扩散蒸馏加速新颖视角合成", "title_en": "FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation", "authors": "Wenbin Teng,Gonglin Chen,Haiwei Chen,Yajie Zhao", "background": "近年来，3D重建技术取得了显著进展，可以从密集图像捕获中生成逼真的3D模型，但在仅有稀疏视角的情况下，仍会出现无法重建的区域，这些区域往往会出现假象。最近的研究利用视频扩散模型（VDMs）生成密集观测数据，填补仅有稀疏视角时的观测空白。然而，这些方法主要的问题在于使用VDMs时采样速度较慢。因此，本研究旨在解决这一问题，提出一种名为FVGen的新框架，以减少采样时间，并能够使用VDMs快速生成新颖视图。", "innovation": "本研究提出了一种新颖的视频扩散模型蒸馏方法，该方法利用生成式对抗网络（GANs）和软化逆KL散度最小化，将多步骤去噪教师模型压缩成几步去噪学生模型。实验结果显示，与先前的方法相比，该框架可以在减少采样时间超过90%的基础上，生成相同数量的新颖视图，并且视觉质量相似甚至更好。而且，FVGen在处理稀疏输入视图时（超过2个视图），显著提高了下游重建任务的时间效率。", "conclusion": "FVGen框架通过对抗视频扩散蒸馏方法显著提高了时间效率，特别是在处理稀疏输入视图时，具有更高的时间和质量效益。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.15385", "html_url": "https://arxiv.org/abs/2405.15385", "title": "CPT-Interp: 4D医学图像插值的连续时空运动建模", "title_en": "CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation", "authors": "Xia Li,Runzhao Yang,Xiangtai Li,Antony Lomax,Ye Zhang,Joachim Buhmann", "background": "4D医学成像提供了对患者解剖结构动态变化的关键洞察，有助于临床评估和放射治疗规划，从而增强3D图像分析的能力。然而，成像硬件的固有物理和技术限制往往需要在时间分辨率和图像质量之间做出妥协。帧插值作为一种重要解决方案被提出，但之前的许多方法在估计中间运动和执行前向变形时存在不足。", "innovation": "本文借鉴流体力学，提出了一个新颖的方法，利用隐式神经表示连续建模患者解剖结构的运动，确保时空连续性，自然地促进连续帧插值，同时解决了大量数据集的需求和模型泛化问题。", "conclusion": "我们的实验在多个数据集上证明了该方法的优越准确性和速度。此外，作为一种无需训练的案例特定优化方法，它规避了数据集需求和模型泛化问题。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06485", "html_url": "https://arxiv.org/abs/2508.06485", "title": "WGAST: 弱监督生成网络在时空融合下每日10米地表温度估算", "title_en": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion", "authors": "Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai", "background": "城市化、气候变化和农业压力正在增加对精确和及时的环境监测的需求。地表温度(LST)是这一背景下一个关键变量，并通过遥感卫星获取。然而，这些系统在空间分辨率和时间分辨率之间存在权衡。时空融合方法提供了有前景的解决方案，但极少有方法解决每日10米分辨率的LST估算问题。", "innovation": "本文提出WGAST，一种通过时空融合terra MODIS、Landsat 8和Sentinel-2数据进行每日10米LST估算的弱监督生成网络。WGAST是首个端到端的深度学习框架，采用条件生成对抗网络结构，包括特征提取、融合、LST重建和噪声抑制四个阶段。", "conclusion": "实验结果显示，WGAST在定量和定性评估中均优于现有方法。与最佳基线相比，WGAST平均降低RMSE 17.18%，提高SSIM 11.00%，且对云引起的LST变化具有鲁棒性，能够有效捕捉细尺度热模式。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.09105", "html_url": "https://arxiv.org/abs/2406.09105", "title": "INS-MMBench: 评估大型视觉语言模型在保险领域性能的全面基准", "title_en": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance", "authors": "Chenwei Lin,Hanjia Lyu,Xian Xu,Jiebo Luo", "background": "大型视觉语言模型（LVLMs）和多模态大型语言模型（MLLMs）在各种通用多模态应用中展示了卓越的表现，并在专业领域中显示出不断增长的潜力。然而，它们在以多样化的应用场景和丰富的多模态数据为特征的保险领域的潜力仍然很大程度上未被发掘。截至目前，针对多模态任务的系统性回顾和特定用于评估LVLMs在保险领域性能的基准设计尚不存在，这阻碍了保险业中LVLMs的发展。", "innovation": "该研究系统性地回顾和分类了为4种代表性的保险类型（汽车、财产、健康、农业）多模态任务。引入了INS-MMBench，这是第一个为保险领域量身定制的层次化基准，包含了22个基础任务，12个元任务和5个场景任务，能够从基础能力到现实应用场景进行全面和渐进性的评估。基准测试了11个领先的LVLMs，包括闭源模型如GPT-4o和开源模型如LLaVA。评估验证了INS-MMBench的有效性，并提供了对各种保险相关的多模态任务中当前LVLMs作用的有效性的详细见解。", "conclusion": "我们希望INS-MMBench能够加速LVLMs在保险行业的整合，并促进跨学科研究。我们的数据集和评估代码可在以下地址获取：this https URL."}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.18018", "html_url": "https://arxiv.org/abs/2405.18018", "title": "一个折射水下视觉校准工具", "title_en": "A Calibration Tool for Refractive Underwater Vision", "authors": "Felix Seegräber,Mengkun She,Felix Woelk,Kevin Köser", "background": "许多水下应用依赖于视觉传感器，并需要适当的摄像机校准，即每个图像像素对应的入射光线方向。理想情况下，正交摄像机模型中的所有视向光线会在三维空间中的单一点汇聚。然而，水下摄像机会在水、玻璃和空气的界面处遭受多次折射，这些折射方向的变化取决于摄像机在防水壳中的位置和方向，以及光学窗口、窗口本身的形状和属性。近年来，对于常见的窗口类型如平板或球面窗口，已经提出了折射水下视觉模型，但水下社区仍然缺乏一种能够通过折射校准确定窗口参数的工具。为此，本文提供了第一个开源的水下折射摄像机校准工具。该工具允许端到端校准水下视觉系统，包括带有球面或平板窗口的摄像机、立体摄像机和防水壳的校准。", "innovation": "本文提供了第一个开源的水下折射摄像机校准工具，能够端到端校准包括带有球面或平板窗口的水下视觉系统。该校准工具基于渲染数据集和实际实验进行了验证。", "conclusion": "本文的校准工具已经在渲染数据集和实际实验中得到了验证，并允许端到端校准水下视觉系统，为水下摄像机、立体系统和防水壳提供了包括球面或平板窗口在内的全面校准。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06426", "html_url": "https://arxiv.org/abs/2508.06426", "title": "通用机器人策略中的捷径学习：数据集多样性和碎片化的作用", "title_en": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "authors": "Youguang Xing,Xu Luo,Junlin Xie,Lianli Gao,Hengtao Shen,Jingkuan Song", "background": "大规模数据集（如Open X-Embodiment）训练的通用机器人策略表现出在广泛任务上很强的表现，但通常难以超越其训练数据分布进行泛化。本文探讨了这一有限泛化能力的根本原因，发现捷径学习（依赖于任务无关特征）是泛化能力的阻碍。这一现象源于大规模数据集中的个别子集数据多样性和数据集碎片化问题，这些问题来自于这些数据集通常由多个独立收集且环境各异的子集组成。", "innovation": "本文通过全面的理论和实证分析揭示了捷径学习的两个主要因素：（1）个别子集数据缺乏多样性；（2）子集间的显著分布差异导致数据集碎片化。此外，在获取新大规模数据不现实的情况下，展示了如何通过精心选择的机器人数据增强策略来减少捷径学习，从而提高通用机器人策略的泛化能力，不论是在仿真还是真实环境中。研究成果为数据集采集策略提供了关键见解，以减少捷径学习并增强通用机器人策略的泛化能力。", "conclusion": "本文发现重要的是提供减少捷径学习的关键见解，不论是通过数据集多样性的优化还是通过数据增强策略的改进，改善通用机器人策略的泛化能力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.13291", "html_url": "https://arxiv.org/abs/2409.13291", "title": "用于点云对应中的局部高斯作为自注意力权重", "title_en": "Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence", "authors": "Alessandro Riva,Alessandro Raganato,Simone Melzi", "background": "当前基于数据驱动的方法在点云配准任务中的训练时间和计算资源需求极大，这对模型的部署和应用构成挑战。通过编码器的Transformer架构，最近的研究发现自注意力头中出现了语义上有意义的模式，这些模式类似高斯函数，且中心位于输入形状的每个点上。本文进一步研究了这一现象，将这些模式作为固定的注意力权重集成到Transformer架构的注意力头上，以测试其在不同场景下的表现，并分析了噪声数据下的性能改进方法，从而提升了网络的鲁棒性。", "innovation": "本文采用了局部高斯函数作为固定的注意力权重来提高点云配准的效率和稳定性。实验中，本文同时研究了固定权重和可学习权重两种模式，并且通过消融研究验证了特定层对网络性能的重要性，揭示了网络对这些信息的依赖度。", "conclusion": "固定注意力权重在加速训练过程和提高优化稳定性方面表现出色。本文还探讨了在噪声数据上的性能改进，并通过消融研究确定了关键层，这些发现有助于优化点云匹配模型。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.08566", "html_url": "https://arxiv.org/abs/2409.08566", "title": "Hybrid-TTA: 利用动态域变化检测的持续测试时自适应", "title_en": "Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection", "authors": "Hyewon Park,Hyejin Park,Jueun Ko,Dongbo Min", "background": "Continual Test Time Adaptation (CTTA) 是一种关键方法，用于弥合训练环境和现实场景之间的域差距，提高模型的适应性和鲁棒性。现有的CTTA方法主要分为完全调优（FT）和高效调优（ET），但它们在处理域偏移方面存在不足。为了克服这些挑战，本文提出了一种名为Hybrid-TTA的综合方法，通过动态选择最佳的实例级调优方法来实现最优的适应性。该方法引入了动态域变化检测（DDSD）策略，通过在输入序列中利用时间相关性来识别域变化，并根据不同的域变化动态切换FT和ET，确保了适应性。此外，还集成了基于掩码图像建模的适应性（MIMA）框架，以提供最小的计算开销和域无关的鲁棒性。总之，Hybrid-TTA方法为解决实时持续自适应挑战提供了新的途径，并在Cityscapes-to-ACDC基准数据集上取得了显著的mIoU改进。", "innovation": "提出了Hybrid-TTA方法，通过动态选择实例级别的调优方法，并引入了动态域变化检测（DDSD）策略。该方法通过利用时间相关性来识别域变化，并根据不同的域变化动态切换FT和ET。此外，集成了基于掩码图像建模的适应性（MIMA）框架，以确保最小的计算开销和域无关的鲁棒性。", "conclusion": "Hybrid-TTA方法在Cityscapes-to-ACDC基准数据集上取得了显著的mIoU改进，超过现有的最先进的方法，并提供了一个稳健的解决方案来应对现实世界的持续自适应挑战。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.03260", "html_url": "https://arxiv.org/abs/2411.03260", "title": "ShadowMamba: 状态空间模型与边界-区域选择性扫描用于阴影去除", "title_en": "ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal", "authors": "Xiujin Zhu,Chee-Onn Chow,Joon Huang Chuah", "background": "阴影去除是低级视觉任务中的典型任务。阴影会导致局部亮度变化，降低下游视觉任务的性能。目前，基于Transformer的阴影去除方法由于自注意力机制导致计算复杂度为二次。为提高效率，许多方法使用局部注意力，但这种做法限制了对全局信息的建模能力，减弱了对区域间亮度变化的感知。Mamba最近在视觉任务中展示了强大的性能，能够通过线性复杂性实现全局建模。然而，现有的扫描策略不适合阴影去除，因为它们忽略了阴影边界及其内部区域的语义连续性。为了解决这个问题，本文提出了一种边界-区域选择性扫描机制，能够捕捉局部细节同时增强它们之间的语义连续性，有效提高了阴影去除表现。此外，还引入了一种阴影遮罩去噪方法，支持扫描机制并提高数据质量。基于这些技术，本文提出了一种名为ShadowMamba的模型，它是第一个基于Mamba的阴影去除模型。实验结果表明，在AISTD、ISTD和SRD数据集上，所提方法优于现有主流方法，并在参数效率和计算复杂性方面具有显著优势。代码可在xxxxx获取", "innovation": "提出了一种边界-区域选择性扫描机制，能够捕捉局部细节同时增强这些细节之间的语义连续性。此外，引入了阴影遮罩去噪方法来支持扫描机制并提高数据质量。基于这些技术，提出了一种名为ShadowMamba的模型，它是第一个基于Mamba的阴影去除模型。实验结果表明，在多种数据集上，该方法优于现有主流方法，并在参数效率和计算复杂性方面具有显著优势。", "conclusion": "所提出的ShadowMamba模型在计算复杂性和参数效率方面提供了显著改进，能够有效处理遮挡问题，为未来的阴影去除研究提供了新的视角。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18350", "html_url": "https://arxiv.org/abs/2411.18350", "title": "TryOffDiff：使用扩散模型进行高保真衣物重建的虚拟试衣", "title_en": "TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models", "authors": "Riza Velioglu,Petra Bevandic,Robin Chan,Barbara Hammer", "background": "该论文介绍了Virtual Try-Off（VTOFF）任务，该任务旨在从穿着者单张照片中生成标准化的服装图像。与Virtual Try-On（VTON）不同，VTON通过数字方式给模特穿衣，VTOFF则提取标准的服装图像，需要精确重建形状、纹理和复杂的图案，以进行稳健的生成模型准确性的评估。作者发现传统的评估指标如SSIM无法准确反映重建质量，从而引入了DISTS作为可靠的评估工具。", "innovation": "作者提出了TryOffDiff，这是一种利用Stable Diffusion结合SigLIP视觉条件的高保真重建方法。实验结果显示，TryOffDiff在VITON-HD和Dress Code数据集上优于适应的姿态转换和VTON基线。这些结果展示了VTOFF在电子商务产品图像改善、生成模型评估和未来高保真重建研究中的潜力。", "conclusion": "实验表明，TryOffDiff能够在服装重建方面提供更高的保真度。通过采用DISTS评估指标，作者证明了VTOFF技术的优越性，能够有效提升电子商务中的产品图像质量并推动生成模型的评估和未来研究。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06182", "html_url": "https://arxiv.org/abs/2508.06182", "title": "头颈部病变指导的数据合成", "title_en": "Clinically-guided Data Synthesis for Laryngeal Lesion Detection", "authors": "Chiara Baldini,Kaisar Kushibar,Richard Osuala,Simone Balocco,Oliver Diaz,Karim Lekadir,Leonardo S. Mattos", "background": "虽然计算机辅助诊断（CADx）和检测（CADe）系统在医学领域取得了显著进展，但在耳鼻喉科等专业领域中应用仍然有限。当前的评估方法高度依赖操作者的专业知识，病变的高异质性使得诊断复杂化，活检仍然是黄金标准，尽管其成本高昂且风险大。特异性内窥镜CADx/e系统的一个关键瓶颈是缺乏具有充分变异性的高质量注释数据集，难以实现通用化应用。", "innovation": "本文提出了一种利用潜在扩散模型（LDM）结合ControlNet适配器生成声带内窥镜图像及其标注对的新方法，并通过临床观察进行引导。该方法解决了数据稀缺问题，通过调整扩散过程来生成真实、高质量且临床相关的图像特征，集纳了不同解剖条件。通过这种方法，可以扩大CADx/e模型的训练数据集，提升声医学评估过程。在检测任务中，仅添加10%的合成数据即可分别提高内部测试检测声带病变的准确率9% 和外部数据22.1%。此外，通过5名不同专业水平的耳鼻喉专家评估合成图像的真实度。", "conclusion": "该工作有望加速自动化工具在声带疾病诊断中的发展，为数据稀缺问题提供解决方案，并展示了合成数据在实际应用场景中的可行性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08131", "html_url": "https://arxiv.org/abs/2501.08131", "title": "SAR重返舞台：RSVQA的新希望", "title_en": "SAR Strikes Back: A New Hope for RSVQA", "authors": "Lucrezia Tosato,Flora Weissgerber,Laurent Wendling,Sylvain Lobry", "background": "RSVQA是一种从卫星图像中提取信息并用自然语言回答问题的任务，帮助图像解释。虽然已经存在针对各种光谱带和分辨率光学图像的方法，但直到最近，高分辨率合成孔径雷达（SAR）图像才开始被研究。SAR能够在各种天气条件下运行并捕捉电磁特征，使其成为一种有前景的技术，但没有研究将SAR和光学图像结合用于RSVQA，也没有提出有效的融合策略。", "innovation": "本文研究了如何将SAR数据集成到RSVQA中，并探讨了如何与光学图像最佳结合。我们提出了一个基于SAR的RSVQA数据集，并探索了两个任务管道。第一个是端到端模型，第二个是一个两阶段框架：SAR信息首先被提取并转换成文本，然后由语言模型生成最终答案。结果表明，两阶段模型表现更好，比端到端模型准确率提高了近10%。我们还评估了结合SAR和光学数据的融合策略。在决策级融合中，F1-micro得分为75.00%，F1平均得分为81.21%，总准确率为75.49%，表现出色。", "conclusion": "SAR特别适用于与特定的土地覆被类型相关的问题，如水体，证明了它作为一种补充光学成像模态的价值。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.08279", "html_url": "https://arxiv.org/abs/2411.08279", "title": "MBA-SLAM:  motion blur aware Gaussian splatting SLAM", "title_en": "MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM", "authors": "Peng Wang,Lingzhe Zhao,Yin Zhang,Shiyu Zhao,Peidong Liu", "background": "新兴的3D场景表示方法，如Neural Radiance Fields (NeRF) 和3D Gaussian Splatting (3DGS)，已经在使用高质量视频序列作为输入的逼真渲染的Simultaneous Localization and Mapping (SLAM) 中显示出其有效性。但是，现有的方法对于常见的如低光照或长时间曝光条件下的运动模糊帧束手无策，这往往会导致相机定位和地图构建质量的显著降低。", "innovation": "本文提出了一种密集视觉去模糊SLAM流水线（i.e. MBA-SLAM），用于处理严重的运动模糊输入并增强图像去模糊。该方法结合了一个高效的运动模糊感知跟踪器，配合基于神经辐射场或高斯散点图的映射器。通过准确建模运动模糊图像的物理成像过程，我们的方法同时学习3D场景表示并估计相机在曝光时间内的局部轨迹，实现对于相机运动导致的运动模糊的主动补偿。", "conclusion": "实验结果显示，MBA-SLAM 在相机定位和地图重建方面超越了现有的最先进的方法，展示出在多种数据集中的优越性能，包括包含锐化图像以及受到运动模糊影响的数据集，强调了本方法的通用性和鲁棒性。代码可在该网址获取：this https URL."}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14428", "html_url": "https://arxiv.org/abs/2412.14428", "title": "WildSAT：从野生动物观察学习卫星图像表示", "title_en": "WildSAT: Learning Satellite Image Representations from Wildlife Observations", "authors": "Rangel Daroya,Elijah Cole,Oisin Mac Aodha,Grant Van Horn,Subhransu Maji", "background": "物种分布提供了宝贵的生态和环境信息，但其在遥感中引导表示学习的可能性尚未得到充分探索。我们介绍了WildSAT，这是一种将卫星图像与公民科学平台上广泛提供的大量地理标记野生动物观察数据相结合的方法。WildSAT采用对抗学习方法，同时利用卫星图像、物种分布图和文本栖息地描述来训练或微调模型，显著提高了多样化的卫星图像识别任务性能，优于ImageNet预训练模型和专门卫星基准方法。此外，通过对视觉和文本信息的对齐，WildSAT使零样本检索成为可能，允许用户基于文本描述搜索地理位置。WildSAT优于最近的跨模态学习方法，展示了其优势。", "innovation": "WildSAT通过将卫星图像与公民科学平台上大量地理标记的野生动物观察数据相结合，采用对抗学习方法，并同时利用卫星图像、物种分布图和文本栖息地描述来训练或微调模型。这种方法在多样化的卫星图像识别任务中表现出色，优于ImageNet预训练模型和专门卫星基准。WildSAT还能够实现零样本检索，通过对视觉和文本信息的对齐来实现基于文本描述的地理位置搜索，超越了现有方法，展示了其在远程感测和生物多样性监测中的广泛适用性。", "conclusion": "通过分析关键设计选择的影响，研究强调了WildSAT在遥感和生物多样性监测中的广泛适用性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.13667", "html_url": "https://arxiv.org/abs/2501.13667", "title": "MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation", "title_en": "MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation", "authors": "Fu Rong,Meng Lan,Qian Zhang,Lefei Zhang", "background": "Referring视频对象分割（RVOS）旨在根据文本描述在视频中分割物体，这需要结合多模态信息和时间动态感知。Segment Anything Model 2（SAM 2）在各种视频分割任务中表现出极大的有效性，但在将其应用于离线RVOS时，面临着将文本转化为有效提示以及缺乏全局上下文意识的挑战。", "innovation": "本文提出了一种新的RVOS框架，MPG-SAM 2，它采用统一的多模态编码器联合编码视频和文本特征，生成语义对齐的视频和文本嵌入以及多模态类标记。还引入了一种分层的全局-历史聚合器，使SAM 2能够在像素和目标层面聚合目标对象的全局和历史信息，增强目标表示和时间一致性。", "conclusion": "在多个RVOS基准上的大量实验表明，MPG-SAM 2具有优越性和我们提出的模块的有效性。代码可从此链接获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.00342", "html_url": "https://arxiv.org/abs/2502.00342", "title": "3D理解中的实体智能：3D场景问答的综述", "title_en": "Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering", "authors": "Zechuan Li,Hongshan Yu,Yihao Ding,Yan Li,Yong He,Naveed Akhtar", "background": "3D场景问答(3D SQA)是一个跨学科的任务，结合了3D视觉感知和自然语言处理，使智能代理能够理解并交互于复杂的3D环境。近年来，大规模多模态建模的进步推动了多样数据集的创建和提示调优及零样本方法的发展。然而，这种快速进步带来了挑战，尤其是在不同数据集和基线之间的统一分析和比较方面。", "innovation": "该综述首次提供了全面系统地整理3D SQA的研究。它从数据集、方法论和评估指标三个视角组织现有工作。此外，识别了跨方法的共性架构模式，综合了核心局限，讨论了当前趋势(如提示调优、多模态对齐和零样本)如何塑造未来的发展。最后，提出了涵盖数据集构建、任务泛化、交互建模和统一评估协议的研究方向。", "conclusion": "本文旨在为未来的3D SQA系统研究奠定基础，促进更通用和智能的3D SQA系统的发展。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15384", "html_url": "https://arxiv.org/abs/2501.15384", "title": "MetaOcc: 结合周围视图4D雷达和摄像头时空融合的3D占用率预测方法及其双重训练策略", "title_en": "MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies", "authors": "Long Yang,Lianqing Zheng,Wenjin Ai,Minghao Liu,Sen Li,Qunshu Lin,Shengyu Yan,Jie Bai,Zhixiong Ma,Tao Huang,Xichan Zhu", "background": "在恶劣天气条件下，自动驾驶需要对3D占用率进行鲁棒预测，而传统的仅依赖视觉系统的方案在这些条件下表现不佳。通过将周围视图4D雷达和摄像头的数据进行融合，可以提供一种低成本的替代方案，但如何从这两种异构传感器中有效地提取和整合特征仍然是一个挑战。", "innovation": "本文提出了一种名为MetaOcc的新颖多模态框架，该框架结合了多视角4D雷达和图像来进行全景3D占用率预测。为解决直接将LiDAR导向的编码器应用于稀疏雷达数据的限制，提出了雷达高度自注意力模块，增强了垂直空间推理和特征提取。此外，开发了层次多尺度多模态融合策略，以进行模态和时间上的局部-全局融合，从而缓解空间-时间的不一致并丰富融合特征表示。为减少对昂贵点云注释的依赖，进一步提出了一种基于开放式聚类器的伪标签生成流水线。", "conclusion": "实验结果显示，在全方位监督条件下，MetaOcc达到了最先进的性能，在OmniHD-Scenes数据集上比之前的方法提高了0.47 SC IoU和4.02 mIoU，在SurroundOcc-nuScenes数据集上分别提高了1.16 SC IoU和1.24 mIoU。这些结果展示了MetaOcc在传感器域和训练条件下的可扩展性和鲁棒性，使其在实际的自动驾驶系统中具有可行的部署潜力。代码和数据可以在以下链接获得：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.24320", "html_url": "https://arxiv.org/abs/2503.24320", "title": "测试时缩放能提升世界基模性能吗？", "title_en": "Can Test-Time Scaling Improve World Foundation Model?", "authors": "Wenyan Cong,Hanqing Zhu,Peihao Wang,Bangya Liu,Dejia Xu,Kevin Wang,David Z. Pan,Yan Wang,Zhiwen Fan,Zhangyang Wang", "background": "世界基模（WFMs）通过从当前观测和输入预测未来状态来模拟物理世界，已成为物理智能应用，如自动驾驶和机器人技术的核心。然而，这些模型需要大量计算资源进行预训练，并且在后训练阶段受到可用数据的限制。为了解决这个问题，提高测试时的计算效率被视为一种替代传统模型扩展或重新训练的可行方案。", "innovation": "介绍了SWIFT，一种针对WFMs的测试时缩放框架，集成了一个扩展的WFM评估工具包和过程级推理策略，包括快速标记化、概率为基础的Top-K剪枝以及高效的束搜索。实验证明在计算最优条件下测试时缩放是存在的，并且SWIFT为提高WFMs推理性能提供了一种可扩展且有效的方式，而无需重新训练或增加模型大小。", "conclusion": "测试时缩放对于WFMs有效，SWIFT框架提供了一种在不重新训练或增加模型大小的情况下提高WFMs推理性能的可扩展且有效的方法。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06364", "html_url": "https://arxiv.org/abs/2503.06364", "title": "生成视频双流", "title_en": "Generative Video Bi-flow", "authors": "Chen Liu,Tobias Ritschel", "background": "本文提出了一个新颖的生成视频模型，通过神经常微分方程（ODE）流来 robust 地学习时间变化，并采用了双线性目标函数进行优化。以往的工作通过将噪声映射到新帧来实现视频生成，但这种方法计算成本更高。本文的工作则直接从过去帧映射到未来帧，通过在训练过程中添加噪声来学习如何移除时间积累的误差，从而改善了模型的稳定性，减少了漂移错误。", "innovation": "本文提出了直接从过去帧映射到未来帧的方法，并通过在训练过程中添加噪声来学习消除时间积累的误差。这种方法避免了将噪声直接映射到新帧的计算昂贵过程，且能够以更少的常微分方程求解步骤实现高质量的视频生成，提高了生成速度。此外，该方法可以在流水线模式下实现无条件视频生成，适用于多种视频数据集。", "conclusion": "本文通过提出新颖的生成视频双流模型，实现了无条件视频生成。与现有的条件扩散模型相比，该模型在保持同等质量的同时具有更快的生成速度。未来的工作可以进一步探索模型在超分辨率、风格迁移等其他生成任务中的应用。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.13818", "html_url": "https://arxiv.org/abs/2502.13818", "title": "建筑年代估计：一个新的多功能基准数据集和社区挑战", "title_en": "Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge", "authors": "Nikolaos Dionelis,Alessandra Feliciotti,Mattia Marconcini,Devis Peressutti,Nika Oman Kadunc,JaeWan Park,Hagai Raja Sinulingga,Steve Andreas Immanuel,Ba Tran,Caroline Arnold,Nicolas Longépé", "background": "估计建筑物的建造年份对推进可持续性至关重要，因为较老的建筑通常缺乏节能功能。可持续的城市规划依赖于准确的建筑年龄数据以减少能源消耗并减少气候变化的影响。传统的直接勘测或人工测量方法费时且成本高，而且随着城市的发展，这些方式也无法实现全面覆盖。", "innovation": "本文提出了MapYourCity数据集，这是一个新的多模式基准数据集，包括顶部视角的高分辨率（VHR）图像、来自Copernicus Sentinel-2星座的多光谱地球观测（EO）数据以及跨多个欧洲城市的街景图像。每个建筑物都标记了其建造时期，任务被定义为一个涵盖从1900年到现在七个类别的分类问题。这项工作还组织了一个由ESA $\tilde{\textstyle \text{ø}}$-lab主办的社区驱动的数据挑战，旨在推动地球观测（EO）泛化和多模式学习的研究。", "conclusion": "通过评估参选模型在未参与训练的城市中的泛化能力和对细微数据缺失情况的性能，研究结果表明，即使在没有使用街景图像的情况下，仅依靠顶部视角卫星图像也能有效估计建筑年龄，这证明了解决可持续城市分析中的现实问题具备可扩展的解决方案。MapYourCity数据集对于开发可用于实际应用的解决方案具有宝贵价值。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15371", "html_url": "https://arxiv.org/abs/2504.15371", "title": "Event2Vec：将神经形态事件直接处理为空间向量表示", "title_en": "Event2Vec: Processing neuromorphic events directly by representations in vector space", "authors": "Wei Fang,Priyadarshini Panda", "background": "神经形态事件摄像机在时间分辨率、能耗和动态范围方面优于传统摄像机。然而，事件摄像机输出的事件是非同步、稀疏且不规则的，无法与主流计算机视觉和深度学习方法兼容。虽然有人提出解决此问题的方法，但缺点包括长时间预处理、损失时间分辨率或不适用于大规模并行计算。", "innovation": "该研究受到单词到向量巨大成功的启发，总结了单词和事件之间的相似性，提出了一种新的事件到向量（event2vec）表示方法，该方法在ASL-DVS数据集上的分类中显示出优越的参数效率、准确性和速度，优于之前的基于图、图像或体素的表示方法。此外，event2vec方法的最大优势在于它将事件与自然语言处理领域对齐，显示了将事件整合到大型语言和多模态模型中的前景。", "conclusion": "该方法在分类性能上表现出色，同时还能将事件与自然语言处理领域对齐，提供了将事件整合到大型语言和多模态模型中的有希望的前景。相关代码、模型和训练日志可在指定链接访问。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03687", "html_url": "https://arxiv.org/abs/2502.03687", "title": "条件扩散模型是提供可解释性和不确定性的医学图像分类器", "title_en": "Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free", "authors": "Gian Mario Favero,Parham Saremi,Emily Kaczmarek,Brennan Nichyporuk,Tal Arbel", "background": "判别分类器已成为深度学习在医学成像中的基础工具，擅长学习复杂数据分布的可分特征。然而，这些模型通常需要精心设计、增强和训练技术以确保安全可靠的部署。最近，扩散模型在2D生成建模中变得常见。这些模型在自然图像分类等任务中表现出色，通过比较每种可能条件输入生成的图像的重建误差来进行分类。", "innovation": "该工作首次探索了条件扩散模型在2D医学图像分类中的潜力。首先，开发了一种新的多数投票方案，证明可提高医学扩散分类器的性能。其次，通过CheXpert和ISIC黑色素瘤皮肤癌数据集的广泛实验，表明从零开始训练和基础模型的分类表现与当前最佳判别分类器相当，且无需显式监督。此外，条件扩散分类器本质上具有可解释性，可以用于量化其预测的不确定性，从而增加其在安全关键的临床情景中的可信度和可靠性。", "conclusion": "条件扩散模型能够提供可解释性和不确定性，无需额外训练或监督，这在安全关键的临床环境中特别有用，且该研究领域的更多信息可在项目页面获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05741", "html_url": "https://arxiv.org/abs/2505.05741", "title": "Dome-DETR: 基于密度导向特征-查询操控的DETR高效微小目标检测", "title_en": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection", "authors": "Zhangchi Hu,Peixi Wu,Jie Chen,Huyue Zhu,Yijun Wang,Yansong Peng,Hebei Li,Xiaoyan Sun", "background": "微小目标检测在无人机监测、遥感和自主系统中扮演重要角色，能够识别广阔区域内的小目标。然而，现有的方法由于特征提取冗余和固定型查询分配导致效率低下和高计算成本。", "innovation": "提出了一种名为Dome-DETR的新框架，包含基于密度导向的特征-查询操控。引入了轻量级的密度聚焦提取器（DeFE）以生成紧凑的前景聚类掩码，利用这些掩码引入了Masked Window Attention Sparsification (MWAS)以通过稀疏注意力集中计算资源于最相关信息区域。此外，提出了渐进自适应查询初始化（PAQI），适应性地调节空间区域中的查询密度以提高查询分配。", "conclusion": "Dome-DETR在AI-TOD-V2上取得了最先进的性能（+3.3 AP），在VisDrone上达到+2.5 AP，同时保持了低的计算复杂性和紧凑的模型大小。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.00816", "html_url": "https://arxiv.org/abs/2504.00816", "title": "为不完整环PET图像恢复的两阶段深度学习框架", "title_en": "Two-stage deep learning framework for the restoration of incomplete-ring PET images", "authors": "Yeqi Fang,Rong Zhou", "background": "正电子发射断层扫描（PET）是医学中广泛使用的重要分子成像工具。传统的PET系统依赖完整的检测环来获得全面的视角覆盖和可靠的数据采集。然而，由于硬件故障、成本限制或特定的临床需求，不完整环的PET扫描仪已经成为一种常见现象。标准的重建算法在这些系统中往往表现不佳，因为数据完整性降低和几何不一致性导致性能下降。因此，需要一种有效的算法来改善这些系统的图像质量，以保留大部分解剖结构和放射性分布特征。", "innovation": "本文提出了一种两阶段的深度学习框架，该框架在不使用飞行时间（TOF）信息的情况下，能够从大约50%缺失偶合数据中恢复高质量的图像，而这种损失程度之前仅由基于卷积神经网络（CNN）的方法处理过。该框架包括预测缺少部分的列投影域注意力U-Net阶段和去除残留伪影同时恢复高频细节的U-Net扩散模块阶段。该框架在206个公共数据集中的大脑体素实验中显示出，所提出的模型能够保持大部分解剖结构和放射性分布特征，其峰值信噪比（PSNR）为30.92 dB，结构相似性（SSIM）为0.9708，且具有更高的推理速度，从而为不完整环PET成像提供了一个有效的解决方案。", "conclusion": "该研究提出了一种针对不完整环PET数据的两阶段深度学习框架，能够在不使用TOF信息的情况下大幅度改善图像质量，比同类方法的表现更好。该模型能够保持大部分的解剖结构和放射性分布特性，实现了在标准重建算法中难以达到的性能。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03329", "html_url": "https://arxiv.org/abs/2505.03329", "title": "FLUX-Text：一种简单的先进扩散变换器基线模型用于场景文字编辑", "title_en": "FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing", "authors": "Rui Lan,Yancheng Bai,Xu Duan,Mingxing Li,Dongyang Jin,Ryan Xu,Lei Sun,Xiangxiang Chu", "background": "场景文字编辑旨在修改或在图像上新增文字，同时确保文字的一致性与背景的整体视觉质量。最近的研究主要基于UNet构建了扩散模型，这些模型提高了场景文字编辑的结果，但仍然难以处理复杂的字母结构，尤其是非拉丁字母（如汉字、韩文、日文）。", "innovation": "FLUX-Text通过引入轻量级的视觉和文本嵌入模块来增强字符的理解和生成能力，同时保留了FLUX原始的生成能力。此外，还提出了一种专门为文本区域设计的区域文本感知损失，并采用了匹配的两阶段训练策略来更好地平衡文字编辑和整体图像质量。", "conclusion": "得益于基于DiT的架构和轻量级特征注入模块，FLUX-Text仅需0.1M的训练样本即可进行训练，比现有流行方法所需的2.9M样本减少了97%。广泛地在多个公开数据集上进行的实验表明，该方法在视觉质量和文字一致性上均超越了其他方法。所有代码已开源。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.09688", "html_url": "https://arxiv.org/abs/2501.09688", "title": "基于成本聚合的细粒度图像-文本对应关系研究", "title_en": "Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation", "authors": "Jiho Choi,Seonho Lee,Minhyun Lee,Seungho Lee,Hyunjung Shim", "background": "开放词汇细粒度部位分割（OVPS）是识别未见过的类别中的精细部位的一种新兴领域。OVPS 存在两个主要挑战：一是难以在图像和文本之间对齐部位级对应关系，二是缺乏对对象部位进行分割的结构理解能力。", "innovation": "作者提出了一种名为PartCATSeg的新框架，该框架整合了对象感知的部位级成本聚合、组合损失以及来自DINO的结构引导。这种方法采用了分离处理对象级和部位级成本的去耦合成本聚合策略，增强了部位级分割的精度，并引入了组合损失来更好地捕捉部位-对象关系，弥补了部位注释的不足。来自DINO的结构引导改善了边界划分和部位之间的理解能力。这些创新方法显著提高了在Pascal-Part-116、ADE20K-Part-234和PartImageNet数据集上的性能，超过了现有最先进的方法，为未见过的部位类别的鲁棒泛化提供了新的基准线。", "conclusion": "实验表明，提出的PartCATSeg方法在多种数据集上显著优于现有方法，展示了其在开放词汇细分部位分割领域的潜力和优越性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11439", "html_url": "https://arxiv.org/abs/2503.11439", "title": "COIN: 基于置信度评分的无监督细粒度细胞实例分割蒸馏", "title_en": "COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation", "authors": "Sanghyun Jo,Seo Jin Lee,Seungwoo Lee,Seohyung Hong,Hyungseok Seo,Kyungsu Kim", "background": "细胞实例分割（CIS）对于在组织病理学图像中识别个体细胞形态至关重要，为生物和医学研究提供有价值的信息。尽管无监督细胞实例分割（UCIS）模型旨在减少对劳动密集型图像标注的依赖，但它们无法准确捕捉细胞边界，导致出现检测遗漏并影响性能。研究指出，错误实例不能准确捕捉是这一方法的主要限制。", "innovation": "本文提出了一种新的标注自由框架COIN（基于置信度评分的实例蒸馏），包含三个关键步骤：1）通过最优传输进行无监督语义分割，增加对无错误实例存在的敏感度；2）实例级别的置信度评分，衡量模型预测与细化掩码之间的一致性，识别高度自信的实例；3）通过递归自我蒸馏逐步扩展置信度。", "conclusion": "在六个数据集上的广泛实验表明，COIN在多种评估指标上超越现有UCIS方法，并在MoNuSeg和TNBC数据集上甚至超过部分半监督和弱监督方法。代码可在此处获取：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04633", "html_url": "https://arxiv.org/abs/2504.04633", "title": "M$^2$IV: 通过表示工程实现高效和精细粒度的多模态上下文学习", "title_en": "M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering", "authors": "Yanshu Li,Yi Cao,Hongyang He,Qisen Cheng,Xiang Fu,Xi Xiao,Tianyang Wang,Ruixiang Tang", "background": "大规模视觉语言模型（LVLMs）可以通过上下文中的多个用户提供的示范来适应新任务，而不需要更新任何模型参数。然而，这种方法的有效性受到多模态输入中大量标记（token）以及跨模态少量示例推理复杂性的限制，这阻碍了LVLMs从示范中提取有用模式。", "innovation": "为了应对这些挑战，提出了M$^2$IV，这是一种新颖的表示工程方法，用可学习的多模态上下文向量直接替换显式的标记级示范，注入LVLMs的残差流中。通过分析多头注意力（MHA）和多层感知器（MLP）在上下文学习（ICL）过程中的不同作用，设计了训练策略，使M$^2$IV能够执行细粒度语义蒸馏和稳健的跨模态表示学习。M$^2$IV在多种任务和LVLMs上具有整体性能的提升，并显著减少了标记开销，使其适用于多种样本场景。此外，引入了VLibrary，一个存储训练好的M$^2$IV以灵活检索和注入的仓库，使用户能够以自定义方式操控预训练的LVLMs，满足多样化的需求。", "conclusion": "广泛的实验表明，M$^2$IV在各类任务和LVLMs上持续优于传统的ICL方法和前表示工程基线，平均准确度提升了3.74%，并且在效率上有了显著改善。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19015", "html_url": "https://arxiv.org/abs/2505.19015", "title": "多模态大型语言模型能否理解空间关系？", "title_en": "Can Multimodal Large Language Models Understand Spatial Relations?", "authors": "Jingping Liu,Ziyan Liu,Zhedong Cen,Yan Zhou,Yinan Zou,Weiyan Zhang,Haiyun Jiang,Tong Ruan", "background": "当前的多模态大型语言模型（MLLMs）依赖于理解客观世界的空间关系。然而，现有的基准测试存在一些问题，如依赖边界框、忽视视角替换或允许仅使用模型的先验知识而无需图像理解来回答问题。这限制了MLLMs在理解图像方面的能力。为了应对这些问题，我们提出了基于COCO2017的SpatialMQA，这是一种基于人工注释的空间关系推理基准测试，旨在帮助MLLMs更专注于图像理解。", "innovation": "我们设计了一个严谨的注释程序来确保数据质量，从而创建了包含5,392个样本的SpatialMQA基准测试。此外，基于这个基准测试，一系列开源和封闭源的MLLMs被实现，结果显示当前最先进的MLLM的准确率仅为48.14%，远低于人类水平的98.40%的准确率。这些实验还进行了广泛的分析，提出了未来研究的方向。", "conclusion": "研究表明，当前的MLLMs在理解空间关系方面仍存在局限性。基于SpatialMQA基准测试的实验结果强调了这一观点，并指出了未来研究的方向。基准测试和代码已公开可用。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.21344", "html_url": "https://arxiv.org/abs/2504.21344", "title": "基于视觉-语言模型的语义引导影像生物标志物用于肺结节恶性预测", "title_en": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction", "authors": "Luoting Zhuang,Seyed Mohammad Hossein Tabatabaei,Ramin Salehi-Rad,Linh M. Tran,Denise R. Aberle,Ashley E. Prosper,William Hsu", "background": "机器学习模型已经利用了语义特征、深层特征或两者来评估肺结节的恶性程度。然而，这些模型在推理过程中依赖手动注释，缺乏可解释性，并且对成像变化敏感，这阻碍了其在临床环境中的应用。因此，研究旨在整合放射科医生对结节评估产生的语义特征，指导模型学习临床相关、稳健和可解释的影像特征，以预测肺癌。研究使用了938个低剂量CT扫描和1,246个结节以及语义特征。此外，Lung Image Database Consortium数据集包含1,018个CT扫描和2,625个结节特征标注。通过参数高效的微调方法微调预训练的对比语言-图像预训练(CLIP)模型，以对影像和语义文本特征进行对齐并预测一年内肺癌诊断。这项研究优于现有最先进的模型，并在外部数据集中表现出稳健的结果。使用CLIP模型，还通过零样本推理获得了结节边缘(AUROC: 0.812)、结节一致性(0.812)和胸膜附着(0.840)等语义特征的预测。这种方法在不同临床环境收集的数据集上预测肺癌时均优于最先进的模型，提供了可解释的输出结果，帮助临床医生理解模型预测的基本含义。这种方法还防止模型学习捷径并适用于不同的临床环境。", "innovation": "该研究通过整合来自放射科医生对结节评估的语义特征，使用参数高效的微调方法，微调了预训练的对比语言-图像预训练(CLIP)模型，使模型能够学习临床相关的、稳健的和可解释的影像特征以预测肺癌。这种方法改善了模型对成像变化的鲁棒性，提供了可解释的输出，帮助临床医生理解模型预测的背景，并防止模型学习捷径，使其能够在不同临床环境下的数据集上表现出色。", "conclusion": "该研究使用基于视觉-语言模型的方法，通过整合放射科医生评估的语义特征，实现了对肺癌的准确预测。这种方法在各种临床环境下的数据集上均表现出优越的性能，并提供了可解释的输出结果。这种方法不仅提高了模型的解释性，还在不同临床环境的鲁棒性方面取得了进展。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01494", "html_url": "https://arxiv.org/abs/2507.01494", "title": "使用深度学习技术进行农作物害虫分类：综述", "title_en": "Crop Pest Classification Using Deep Learning Techniques: A Review", "authors": "Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib,Muhammad Attique,Tae-Sun Chung", "background": "全球范围内，昆虫害虫持续对作物产量构成严重威胁，传统监测方法通常较为缓慢、手工操作且难以规模化。近年来，深度学习技术被证实为一种强有力的方法，卷积神经网络(CNNs)、视觉转换器(ViT)和混合模型等技术在自动害虫检测方面日益流行。", "innovation": "早期研究主要依赖于CNNs，但最新工作转向了基于混合架构和转换器模型的技术，这些模型在准确性和上下文理解方面表现更好。不过，诸如数据集不平衡、小害虫检测困难、泛化能力有限和在边缘设备上的部署等问题仍然构成了重要的挑战。", "conclusion": "这篇综述提供了该领域的结构化概述，指出了有用的数据集，并明确了基于AI的害虫监测系统的关键挑战和未来方向。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.07818", "html_url": "https://arxiv.org/abs/2505.07818", "title": "DanceGRPO: 解锁GRPO在视觉生成中的应用", "title_en": "DanceGRPO: Unleashing GRPO on Visual Generation", "authors": "Zeyue Xue,Jie Wu,Yu Gao,Fangyuan Kong,Lingting Zhu,Mengzhao Chen,Zhiheng Liu,Wei Liu,Qiushan Guo,Weilin Huang,Ping Luo", "background": "近期生成型人工智能的进步已经彻底改变了视觉内容的创建方式，但仍有许多挑战需要克服，例如如何将模型输出与人类偏好对齐。强化学习（RL）被看做是一种有前景的方法来微调生成模型，但现有方法如DDPO和DPOK在处理庞大和多样的提示集时无法保持优化的稳定性，极大地限制了其实际应用价值。", "innovation": "本文提出了DanceGRPO，这是一种通过创新地将Group Relative Policy Optimization (GRPO)适应于视觉生成任务来解决这些限制的框架。主要创新包括：1）在多种现代生成范式中（如扩散模型和修正流）实现了一致且稳定的策略优化；2）即使在涵盖三个关键任务和四种基础模型的复杂现实场景中，仍能保持稳健性能；3）展示了解常见人类偏好（通过五个不同的奖励模型涵盖图像/视频美学、文本-图像一致性、视频运动质量及二元反馈）优化的能力。实验结果表明，DanceGRPO在多个公认基准上相较于基线方法提高了高达181%的表现，尤其在HPS-v2.1, CLIP Score, VideoAlign和GenEval等基准上。", "conclusion": "DanceGRPO为在视觉生成任务中规模化应用强化学习提供了稳定的解决方案，展现了强化学习与视觉合成和谐统一的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16073", "html_url": "https://arxiv.org/abs/2506.16073", "title": "TD3Net：一种用于唇读的时序密集多稀疏卷积网络", "title_en": "TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading", "authors": "Byung Hoon Lee,Wooseok Shin,Sung Won Han", "background": "传统的基于词级别的唇读方法通常采用两阶段框架，前端和后端架构分离来建模唇部动态动作。后端架构中，时间卷积网络（TCNs）是高性能方法中广泛采用的技术。最近引入了密集跳连接来减轻TCNs的感受野稀疏性，提升了复杂时间表示的建模能力。然而，这种性能仍然受限于由于感受野盲区导致的时间连续信息损失。", "innovation": "提出了TD3Net，一种结合了密集跳连接和多稀疏时间卷积的时序密集多稀疏卷积网络，用作后端架构。TD3Net通过应用不同稀疏因子到跳连接特征，覆盖了广泛且密集的感受野，而无盲点。实验结果显示，该方法在两个大型公开数据集Lip Reading in the Wild (LRW)和LRW-1000上的表现与现有的最先进的方法相当，同时具有较少的参数和较低的浮点运算，表明该方法在唇读系统中有显著优势，能有效利用多样化的时序特征并保持时间连续性。", "conclusion": "实验结果表明，TD3Net在具有较少参数和浮点运算的情况下实现了与现有方法相当的性能。此外，可视化结果表明，该方法有效地利用了丰富的时序特征，同时保留了时间连续性，这对于唇读系统来说是一个显著的优势。该代码可在我们的GitHub仓库找到。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18331", "html_url": "https://arxiv.org/abs/2506.18331", "title": "使用可微回报进行端到端3D纹理生成微调", "title_en": "End-to-End Fine-Tuning of 3D Texture Generation using Differentiable Rewards", "authors": "AmirHossein Zamani,Tianhao Xie,Amir G. Aghdam,Tiberiu Popa,Eugene Belilovsky", "background": "尽管最近的3D生成模型可以生成高质量的纹理图像，但它们往往无法捕捉人类偏好或满足特定任务的要求。此外，在3D纹理生成领域，大多数现有方法依赖于对2D文本到图像生成模型的重复调用，这些模型缺乏对输入3D网格对象三维结构的理解。这些问题是由于2D生成模型的限制导致的，它们不能直接理解或利用3D结构信息。因此，需要一种新的方法来改进3D纹理生成的过程，使其能够更好地满足人类的偏好和任务特定的要求。这种方法需要能够理解和使用三维结构信息，并能够在生成过程中直接嵌入用户的反馈。", "innovation": "本文提出了一种端到端可微微调的无强化学习框架，该框架可以直接将可微奖励函数嵌入到3D纹理合成管道中，以嵌入用户的反馈。通过反向传播偏好信号，该方法生成的纹理尊重了3D几何结构并符合特定需求。值得注意的是，该框架还包括三个新的几何感知奖励函数，这些函数为从自然语言生成高质量3D内容提供了更可控和可解释的途径。通过与现有方法的定性和定量评估，该研究展示了提出的新策略在一致性能上优于其他方法。", "conclusion": "我们的研究证明了使用可微奖励进行端到端3D纹理生成微调的有效性，该方法能够在保护3D几何结构的同时生成高质量的纹理，且生成的纹理能更好地满足用户偏好和任务需求。我们已经为我们的实现代码设计了公开发布，以便其他研究者能够复制和扩展这项工作。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13397", "html_url": "https://arxiv.org/abs/2507.13397", "title": "通过模式感知的交互建模实现可信赖的人行轨迹预测", "title_en": "Trustworthy Pedestrian Trajectory Prediction via Pattern-Aware Interaction Modeling", "authors": "Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu,Guoming Tang", "background": "准确可靠的行人轨迹预测对于智能应用的安全性和鲁棒性至关重要，但由于行人之间复杂的交互关系，实现可信赖的预测仍然极具挑战性。现有方法通常采用黑盒建模方式，未能明确捕捉到行人间多样化的交互模式。这种建模方式导致了在关键安全场景下的预测可靠性较低。因此，迫切需要改进方法来提高预测的解释性和可靠性，尤其是在高密度场景中。", "innovation": "提出了InSyn（交互同步网络），这是一种新型的基于Transformer的模型，能够明确捕捉行人之间多样化的交互模式并有效建模方向敏感的社会行为。此外，还引入了一种称为Seq-Start of Seq (SSOS) 的训练策略，以缓解数值时间序列预测中常见的初始步长发散问题，从而提高模型的解释性与预测准确性之间的良好平衡。", "conclusion": "实验结果表明，我们的模型不仅在预测准确性上超越了近期的黑盒基线模型，尤其是在高密度场景中，而且提供了更强的可解释性，并通过Seq-Start of Seq (SSOS) 策略把初始预测误差降低了约6.58%，实现了可靠性与预测准确性之间的最佳折衷。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21761", "html_url": "https://arxiv.org/abs/2507.21761", "title": "MOR-VIT: 具有Mixture-of-Recursions的高效视觉转换器", "title_en": "MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions", "authors": "YiZhou Li", "background": "视觉转换器（ViTs）在图像识别上取得了显著的成功，但传统的ViT架构存在参数冗余和高计算成本的问题，这限制了其实际部署。虽然最近关于高效ViT的工作主要集中在静态模型压缩或基于Token级别的稀疏化处理，但仍无法改变固定计算深度的局限。", "innovation": "本文提出了一种新的名为MoR-ViT的视觉转换器框架，首次引入了基于Mixture-of-Recursions（MoR）范式的Token级动态递归机制。这种方法使每个Token能够自适应地确定其处理深度，这有利于资源的灵活分配。", "conclusion": "在ImageNet-1K和迁移基准测试上的广泛实验表明，MoR-ViT不仅通过参数减少高达70%和2.5倍的推理加速实现了最先进的精度，而且在同等条件下，还超越了如DynamicViT和TinyViT等领先的高效ViT基线。这些结果证明了动态递归策略的有效性，并为可扩展和可部署的视觉转换器开辟了新的途径。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14743", "html_url": "https://arxiv.org/abs/2507.14743", "title": "InterAct-Video: 城市交通中富有推理的视频问答", "title_en": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic", "authors": "Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi", "background": "交通监控对于城市交通、道路安全和智能交通系统（ITS）至关重要。深度学习通过视频问答（VideoQA）模型提高了基于视频的交通监控效果，使得可以从交通视频中提取结构化的见解。然而，现有的VideoQA模型在处理真实世界的复杂交通场景时遇到了挑战，这些场景中，多个事件在同一时空维度中并发发生。为了解决这些问题，本文介绍了一个名为InterAct VideoQA的数据集，旨在评估和提升VideoQA模型在交通监控任务中的性能。", "innovation": "InterAct VideoQA数据集包含8小时的多样交叉口实地交通视频，被分割成10秒的视频片段，并包含超过25,000个问题-答案对，覆盖了时空动态、车辆互动、事故检测以及其他重要交通属性。通过在InterAct VideoQA数据集上评估最先进的VideoQA模型，揭示了在复杂交通场景中对细粒度时空依赖性的推理面临的挑战。此外，利用该数据集对这些模型进行微调可以显著提高性能，强调了领域特定数据集对VideoQA的重要性。InterAct VideoQA数据集是在GitHub开源，供未来研究智能交通系统中部署的VideoQA模型使用。", "conclusion": "InterAct VideoQA为未来的研究提供了基准数据集，促进了在智能交通系统中部署的、可在现实环境中使用的VideoQA模型的发展。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16476", "html_url": "https://arxiv.org/abs/2507.16476", "title": "通过区间级别图聚类和混合密度专家从全切片图像中建模生存时间", "title_en": "Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts", "authors": "Ardhendu Sekhar,Vasu Soni,Keshav Aske,Garima Jain,Pranav Jeevan,Amit Sethi", "background": "该研究介绍了一个模块化的框架，用于从整个切片病理图像（WSIs）预测特定于癌症的生存率，显著提高了最先进的准确性。该方法集成了四个关键组件来处理WSI的大型尺寸，通过基于分位数的阈值分割预后相关信息的组织区域，使用图引导的k均值聚类捕获表型层面的异质性，通过空间和形态学的一致性，引入了注意力机制来建模局部特征与不同类型的组织隔室之间的区域间和区域内的关系，并使用专家引导的混合密度建模来使用高斯混合模型估计复杂的生存分布。", "innovation": "该研究的创新在于：1. 使用基于分位数的阈值动态斑块选择法，以隔离预后信息丰富的组织区域；2. 使用图引导的k均值聚类来捕捉表型层面的异质性；3. 引入注意力机制以建模局部特征与不同组织隔室之间的区域间和区域内关系；4. 使用专家引导的混合密度建模方法来估计复杂的生存分布。", "conclusion": "该研究提出的模型在TCGA-KIRC（肾癌）上的一致性指数为0.712±0.028，布瑞尔分数为0.254±0.018；在TCGA-LUAD（肺癌腺癌）上的表现为一致性指数0.645±0.017，布瑞尔分数0.281±0.031。这些结果显著优于最新的技术，并展示了该方法在不同癌症类型中的预测潜力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23543", "html_url": "https://arxiv.org/abs/2507.23543", "title": "ART: 自适应关系微调以实现泛化关系预测", "title_en": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "authors": "Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth", "background": "VRD模型在仅基于关系检测数据训练的情况下难以泛化到训练外的关系上。虽然已使用提示微调来适应视觉-语言模型（VLM），但这种方法需要手动制作提示，并对新颖或复杂的关系表示困难。", "innovation": "本文提出了一种名为ART（自适应关系微调）的框架，通过指令微调和策略性样本选择适应VLMs进行VRD。它通过将VRD数据集转换为指令微调格式并采用自适应抽样算法，使模型专注于信息丰富的关系，同时保持泛化能力。特别地，ART在关系分类任务上进行微调，并在不同复杂度的测试数据集上进行评估。该方法显著优于基线方法，并可以推断出未见过的关系概念，这是主流VRD方法所不具备的能力。", "conclusion": "研究展示了ART的实用性，通过预测的关系来进行复杂场景的分割。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00698", "html_url": "https://arxiv.org/abs/2508.00698", "title": "大型预训练深度估计模型在图像去雾霾中的帮助作用？", "title_en": "Can Large Pretrained Depth Estimation Models Help With Image Dehazing?", "authors": "Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu", "background": "图像去雾霾仍然是一个具有挑战性的问题，因为现实世界的场景中的雾霾具有空间变化的特性。尽管现有的方法已经表明大规模预训练模型在图像去雾霾方面的潜力，但它们特定于架构的设计限制了它们在不同需求（不同准确性和效率要求）下的适应性。因此，需要一种通用的方法来解决这些局限性，并提高去雾霾的适应性和效果。", "innovation": "本文系统性地研究了预训练深度表示的一般化能力，这些深度表示是从数百万种不同的图像中学习而来。研究发现，学习到的深度特征在不同雾霾程度下保持了显著的一致性。据此，提出了一种即插即用的RGB-D融合模块，能够无缝集成到各种去雾霾架构中。广泛的实验证明了该方法的有效性和广泛适用性。", "conclusion": "该研究证实了学习到的深度特征在图像去雾霾任务中的稳定性和适用性，并提出了一种通用的解决方案来解决现有模型的局限性。通过实验验证了提出的融合模块的有效性和广泛适用性，从而提高图像去雾霾的效果和适应性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00381", "html_url": "https://arxiv.org/abs/2508.00381", "title": "通过Adapt-WeldNet和缺陷检测解释性分析提高海事运营中的焊接缺陷检测", "title_en": "Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis", "authors": "Kamal Basha S,Athira Nambiar", "background": "在石油和天然气行业中，管道系统的焊接缺陷检测对于确保安全性和可靠性至关重要，尤其是在海洋和近海环境中。传统的无损检测（NDT）方法往往难以检测细微或内部缺陷，可能导致潜在的故障和高昂的停机成本。目前基于神经网络的缺陷分类方法通常依赖于预先未经验证的架构，缺乏可解释性，这在部署时引发了安全担忧。", "innovation": "本文提出了Adapt-WeldNet，一种适应性框架，用于焊接缺陷检测。该框架系统地评估各种预训练架构、迁移学习策略和自适应优化器，以确定表现最佳的模型和超参数，优化缺陷检测并提供可行动的洞察。此外，提出了一种新颖的缺陷检测解释性分析（DDIA）框架，以增强系统的透明度。DDIA采用可解释AI（XAI）技术，如Grad-CAM和LIME，结合由认证ASNT NDE水平II专业人员验证的领域特定评估。通过引入人为在环（HITL）方法并遵循可信AI的原则，DDIA确保缺陷检测系统的可靠性和公平性，通过专家验证培养自动决策的信心。", "conclusion": "通过改进性能和解释性，这项工作增强了焊接缺陷检测系统在海事和海洋环境中的信任、安全性和可靠性，支持关键操作。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05397", "html_url": "https://arxiv.org/abs/2507.05397", "title": "神经驱动的图像编辑", "title_en": "Neural-Driven Image Editing", "authors": "Pengfei Zhou,Jie Xia,Xiaopeng Peng,Wangbo Zhao,Zilong Ye,Zekai Li,Suorong Yang,Jiadong Pan,Yuanxiang Chen,Ziqiao Wang,Kai Wang,Qian Zheng,Xiaojun Chang,Gang Pan,Shurong Dong,Kaipeng Zhang,Yang You", "background": "传统的图像编辑通常依赖于手动提示，导致劳动密集型且对肢体控制受限或语言能力有限的个体不够友好。利用近期脑-机接口（BCI）和生成模型的进步，本文提出了一种名为LoongX的无需动手的图像编辑方法，该方法通过多种生理神经信号驱动。LoongX利用了23,928幅图像编辑配对数据训练的先进扩散模型，每个配对均附带有同步的脑电图（EEG）、功能性近红外光谱（fNIRS）、光电容积描记法（PPG）和头部运动信号，以捕捉用户意图。", "innovation": "LoongX集成了两个关键模块，分别是跨尺度状态空间（CS3）模块，用于编码模态特定特征；动态门控融合（DGF）模块则进一步将这些特征聚合到统一的潜在空间，并通过微调扩散变换器（DiT）与编辑语义对齐。此外，编码器通过对比学习预训练，以使认知状态与嵌入的自然语言的语义意图对齐。实验证明，LoongX在性能上与基于文本的方法（CLIP-I: 0.6605 vs. 0.6558；DINO: 0.4812 vs. 0.4636）相当，且当神经信号与语音结合时，性能超过基于文本的方法（CLIP-T: 0.2588 vs. 0.2549）。这项研究突显了神经驱动生成模型在实现无障碍、直观的图像编辑方面的潜力，并为认知驱动的创意技术开辟新方向。", "conclusion": "本研究通过LoongX展示了神经驱动的生成模型在图像编辑中的潜力，并为未来的科研工作提供了数据集和代码支持，推动了这一新兴领域的进步。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04682", "html_url": "https://arxiv.org/abs/2508.04682", "title": "TurboTrain: 向高效平衡多任务学习的多智能体感知与预测迈进", "title_en": "TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction", "authors": "Zewei Zhou,Seth Z. Zhao,Tianhui Cai,Zhiyu Huang,Bolei Zhou,Jiaqi Ma", "background": "多智能体系统的端到端训练能够显著提升多任务性能，但该训练过程仍然极具挑战性，需要大量的手工设计和监控。针对这一问题，本文研究了一种全新的多智能体感知与预测训练框架TurboTrain，并通过简化训练流程，减少训练时间和提高性能。", "innovation": "TurboTrain框架包含两个关键组件：基于掩码重建学习的空间时间多智能体预训练方案以及基于梯度冲突抑制的平衡多任务学习策略。该框架通过简化训练过程，消除了复杂多阶段训练流程的手工设计和调优需求，从而大幅减少训练时间并提升性能。", "conclusion": "本文在实际协作驾驶数据集V2XPnP-Seq上评估TurboTrain，并证明它进一步提升了最先进的多智能体感知和预测模型的性能。实验结果表明，预训练能够有效捕捉时空多智能体特征，并显著改善下游任务。此外，提出的平衡多任务学习策略提升了检测和预测的效果。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02192", "html_url": "https://arxiv.org/abs/2508.02192", "title": "CMIC: Content-Adaptive Mamba for Learned Image Compression", "title_en": "CMIC: Content-Adaptive Mamba for Learned Image Compression", "authors": "Yunuo Chen,Zezheng Lyu,Bing He,Hongwei Hu,Qi Wang,Yuan Tian,Li Song,Wenjun Zhang,Guo Lu", "background": "近期的学习图像压缩（LIC）方法利用了Mamba样式的状态空间模型（SSMs），这些模型具有全局的感受野和线性复杂度。然而，vanilla Mamba是内容无关的，依赖于固定和预定义的选择性扫描，限制了其动态和全面挖掘内容依赖性的能力。", "innovation": "我们引入了Content-Adaptive Mamba（CAM），这是一种动态SSM，解决了两个关键问题。首先，CAM使用内容意识的标记重组方式，基于内容相似性对标记进行聚类和重排序，优先考虑特征空间中的接近性而非欧几里得空间。其次，CAM通过提示字典将全局先验引入SSM，有效地缓解了Mamba中的严格因果性和长距离衰减在标记间的交互。这些创新使CAM能够更好地捕捉全局依赖性，同时保持计算效率。", "conclusion": "利用CAM，我们基于Content-Adaptive Mamba的LIC模型（CMIC）实现了最先进的率-失真性能，分别在Kodak、Tecnick和CLIC基准上的BD-rate上超过了VTM-21.0，提高了-15.91%，-21.34%和-17.58%。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00549", "html_url": "https://arxiv.org/abs/2508.00549", "title": "Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images", "title_en": "Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images", "authors": "Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski", "background": "临床决策高度依赖于对解剖结构及其异常的相对位置的理解。因此，为了使视觉-语言模型（VLMs）在临床实践中应用，准确判定医学影像中的相对位置是一项基本前提。尽管这项能力非常重要，但它在医学领域的应用却未得到充分探索。现有研究表明，最先进的VLMs模型，在这个问题上表现不佳。本研究发现，这些模型在医学影像中进行相对位置判定时的表现远逊于在自然图像上的表现。研究指出，VLMs在医学影像上可能更多依赖于先验的解剖知识而非实际的图像内容。因此，为推动该领域的进一步研究，该研究开发了一个新的基准数据集，即MIRP Medical Imaging Relative Positioning，以系统性地评估模型在医学影像上判定相对位置的能力。", "innovation": "本研究引入了一个新的基准数据集MIRP，专为系统性评估VLMs在医学影像上识别相对位置的能力。研究基于计算机视觉的成功方法，探讨了使用视觉提示（如标上数字或颜色标记的解剖结构）是否可以提高VLMs在识别相对位置方面的性能。尽管这些标记提供了中等程度的改善，但结果仍显著低于自然图像上的观察结果。研究结果强调了在医学影像上VLMs更多依赖于解剖先验知识，而非实际图像内容。这是对VLMs在医学影像应用方面的重要创新研究，为未来的研究提供了数据和方法支持。", "conclusion": "本研究表明，最先进的VLMs模型在医学影像相对位置判定任务上表现较差，往往依赖于解剖先验知识而非实际的图像内容。研究建议应设计更多专注于相对位置识别的医学影像数据集，并探索增强VLMs性能的方法。MIRP数据集为这一领域的进一步研究提供了重要的资源和指导。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05246", "html_url": "https://arxiv.org/abs/2508.05246", "title": "基于虹膜图像的性别分类技术研究：深入调研与分析", "title_en": "A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis", "authors": "Basna Mohammed Salih Hasan,Ramadhan J. Mstafa", "background": "性别识别在监视和监控、公司画像和人机交互等领域具有吸引力。传统的性别识别方法大多基于面部特征，而虹膜虽然是一个显著的生物特征，但尚未成为主要的性别分类手段。虹膜在人的生命周期中保持基本稳定，易于观察，对用户无侵入性，且已有高质量的方法对其进行分割和编码，提取纹理特征。", "innovation": "文章提供了对基于虹膜图像的性别分类技术的全面回顾，分析了现有方法的优点和不足，并指出了研究缺口和未来改进方向。", "conclusion": "文章总结了近年来在基于虹膜图像的性别分类技术上的研究成果，为相关研究者提供了知识和分析，指出了研究中的空白和挑战，并提出了改善建议。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04928", "html_url": "https://arxiv.org/abs/2508.04928", "title": "使用校准标记将基础单目深度估计器扩展到鱼眼相机", "title_en": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens", "authors": "Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong", "background": "现有的基于透视图像训练的基础单目深度估计器（FMDEs）在面对鱼眼图像时可能会出现深度估计错误，主要是因为镜头校准参数的变化引入了共变量偏移，导致模型难以适应这些变化。目前的方法通常需要对鱼眼相机进行重新训练或微调，这增加了系统复杂性和资源消耗。", "innovation": "该研究提出了一种新颖的方法，通过引入轻量级的校准标记Calibration Tokens对FMDEs进行调整，使其能够直接应用于鱼眼传感器而不需重新训练或微调。该方法利用FMDEs已有的表达性隐空间，通过调节隐空间中的嵌入来避免传统校准方法或图像空间映射至标准参考框架带来的负面影响，并且该方法无需直接使用鱼眼图像数据集，而是通过调整透视图像，以保证训练过程中深度估计的前后一致性。", "conclusion": "该研究提出的方法通过对FMDEs进行轻量级调整，使其可以直接应用于鱼眼传感器，并且在室内和室外场景下，使用统一的标记集合能够持续超越现有的先进方法。该方法无需原始鱼眼图像数据集，而是借助公开的大量透视图像数据集进行校准调整，并已经在多种单目深度估计器上进行了验证和评估。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05254", "html_url": "https://arxiv.org/abs/2508.05254", "title": "CF3: 紧凑且快速的3D特征场", "title_en": "CF3: Compact and Fast 3D Feature Fields", "authors": "Hyunjoon Lee,Joonkyu Min,Jaesik Park", "background": "3D Gaussian Splatting (3DGS)等技术开始借鉴2D基础模型中的丰富信息，但大多数方法依赖于自底向上的优化过程，将原始2D特征视为真实值，导致计算成本增加。", "innovation": "提出了一种自顶向下的方法CF3，用于构建紧凑且快速的3D高斯特征场。首先使用预训练的高斯进行多视角2D特征的快速加权融合，直接在提升特征上训练每个高斯的自动编码器，而不是在2D域中训练自动编码器，从而更好地与特征分布对齐。更重要的是，引入了一种自适应稀疏化方法，优化特征场的高斯属性同时移除和合并冗余的高斯，构建了高效表示且保留了几何细节，仅使用5%的高斯即可实现有竞争力的3D特征场。", "conclusion": "通过CF3方法，能够在保持几何细节的同时有效地减少计算成本，仅需少量高斯即可实现高效的3D特征场构建。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2303.05653", "html_url": "https://arxiv.org/abs/2303.05653", "title": "使用卷积编码器-解码器直接构建机器人配置空间", "title_en": "Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders", "authors": "Christopher Benka,Judah Goldfeder,Carl Gross,Riya Gupta,Hod Lipson", "background": "智能机器人需要在其环境中执行安全高效的运动规划。现代运动规划的核心在于配置空间。配置空间定义了机器人在工作空间中与障碍物发生碰撞的所有配置集合（\text{C}_{\text{clsn}}）和未发生碰撞的所有配置集合（\text{C}_{\text{free}}）。传统的运动规划方法先计算配置空间，然后使用计算出的配置空间进行运动规划。实时运动规划需要准确而高效地构建配置空间。", "innovation": "我们首次利用卷积编码器-解码器框架来计算配置空间的高度准确近似值，这实际上是在学习机器人与物理世界之间的交互方式。我们的模型在2D机器人工作空间中达到了97.5%的平均F1评分，用于预测\text{C}_{\text{free}}和\text{C}_{\text{clsn}}。对于涉及平移、旋转和移除障碍物的机器人工作空间，我们的方法几乎可以将未检测到的碰撞限制在低于2.5%。", "conclusion": "我们的模型在不同的机器人工作空间之间学习了高度可转移的特征，对工作空间中障碍物的新变换需要极少或不需要微调。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.03253", "html_url": "https://arxiv.org/abs/2404.03253", "title": "初级鼻咽癌MRI数据集，包含多模态分割", "title_en": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation", "authors": "Yin Li,Qi Chen,Kai Wang,Meige Li,Liping Si,Yingwei Guo,Yu Xiong,Qixing Wang,Yang Qin,Ling Xu,Patrick van der Smagt,Jun Tang,Nutan Chen", "background": "多模态磁共振成像(MRI)数据有助于鼻咽癌(NPC)的早期诊断、肿瘤分割以及疾病分期管理。然而，缺乏公开、全面的MRI数据集限制了诊断、治疗计划的发展以及机器学习算法的研发。", "innovation": "本文介绍了首个全面的初级鼻咽癌MRI数据集，包括277例患者的277次磁共振轴向成像，涵盖T1加权、T2加权和对比增强的T1加权序列，共831个扫描图像。同时，附带临床数据及由经验丰富的放射科医生手动注释和标注的分割数据，提供高质量的数据资源，用于未治疗的初级鼻咽癌研究。", "conclusion": "本文提供的数据集将有助于相关领域的研究与开发，促进鼻咽癌的诊断与治疗计划制定。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05182", "html_url": "https://arxiv.org/abs/2508.05182", "title": "SPA++: 综合图谱配准框架在通用领域适应中的应用", "title_en": "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation", "authors": "Zhiqing Xiao,Haobo Wang,Xu Lu,Wentao Ye,Gang Chen,Junbo Zhao", "background": "领域适应（DA）的目标是在字段转移知识从标记的源域到未标记或稀疏标记的目标域下，假设存在领域偏移。大多数先前的工作主要集中在捕获跨域可转移性，但很少考虑丰富的领域内结构，这实际上会导致更差的判别性。", "innovation": "提出了一种综合格谱配准框架SPA++，其核心思想包括：通过将DA问题转化为图基元，与一种新的在特征空间内对齐领域图的频谱正则化器相结合，实现粗略的图对齐机制；进一步发展了一种细粒度的邻域意识传播机制以增强目标域的判别性；通过引入数据增强和一致性正则化，SPA++能够适应包括大多数DA设置在内的复杂场景，甚至具有挑战性的分布情景。此外，还提供了理论分析以支持该方法，包括基于图的DA的泛化界限以及频谱配准和平滑一致性的作用。", "conclusion": "在基准数据集上的广泛实验表明，SPA++在多种挑战性适应场景中始终优于现有的最新方法，提供了更高的鲁棒性和适应性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.03055", "html_url": "https://arxiv.org/abs/2411.03055", "title": "ATM：通过交替调参和合并改进模型合并", "title_en": "ATM: Improving Model Merging by Alternating Tuning and Merging", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Fabrizio Silvestri,Emanuele Rodolà", "background": "模型合并已成为多任务学习的一种成本效益较高的近似方法。在合并策略中，任务算术因其简单性和有效性而引人注目。本文通过理论分析表明，任务向量在单一周期全批量梯度下降下，等同于多任务梯度。这一见解促使作者将模型合并重新解释为迭代过程中交替调参和合并（ATM）步骤中的一步。", "innovation": "提出了交替调参和合并（ATM）方法：（1）在限制数据共享的情景下（例如，联邦学习环境中），作为多任务学习的替代方法；（2）作为一种轻量级的改进步骤，使用小的验证集来提高现有的模型合并方法。", "conclusion": "实验结果显示，ATM在多种视觉任务中显示出有效性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.01273", "html_url": "https://arxiv.org/abs/2410.01273", "title": "CANVAS：与常识相关的导航系统，用于直观的人机交互", "title_en": "CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction", "authors": "Suhwan Choi,Yongjun Cho,Minchan Kim,Jaeyoon Jung,Myunchul Joe,Yubeen Park,Minseo Kim,Sungwoong Kim,Sungjae Lee,Hwiseong Park,Jiwan Chung,Youngjae Yu", "background": "现实生活中，机器人的导航不仅仅是到达目的地的问题，还需要优化运动并解决特定场景的目标。人类通过口头命令或草图等方式，以抽象的方式表达这些目标。然而，这种人类的指导可能缺乏细节或存在噪声。为此，机器人需要与人类共享基本导航概念的理解以便更好地执行这些抽象指令。\n", "innovation": "本文提出了CANVAS新型框架，该框架结合了视觉和语言指令，以训练常识意识导航系统。该系统利用模仿学习，使其能够从人类的导航行为中学习，从而更好地理解并执行人类的抽象指令。此外，还介绍了COMMAND数据集，包含了48小时、219公里的人类标注导航结果，用于训练常识意识导航系统。实验表明，在各种环境中，CANVAS均优于基于规则的系统ROS NavStack，尤其是在果园环境中，ROS NavStack的总成功率为0%，而CANVAS的总成功率为67%。此外，CANVAS在新的未知环境中也与人类的演示和常识约束保持一致，展示了在实际部署中的出色成果。\n", "conclusion": "CANVAS在多种形式的环境中展示了卓越的性能，尤其是在噪声指令的情况下，证明了从模拟环境中的人类演示学习可以成功应用于实时场景。这为未来的实用应用提供了巨大的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.19370", "html_url": "https://arxiv.org/abs/2409.19370", "title": "MambaEviScrib: Mamba和证据引导一致性增强CNN稳健性用于注释基于scribble的弱监督超声图像分割", "title_en": "MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation", "authors": "Xiaoxiang Han,Xinyu Li,Jiang Shang,Yiman Liu,Keyan Chen,Shugong Xu,Qiaohong Liu,Qi Zhang", "background": "超声图像的解剖结构和病变分割对于疾病评估至关重要。基于稀疏注释的弱监督学习（WSL）已经取得了令人鼓舞的性能，并显示出减少标注成本的潜力。然而，超声图像常常具有低对比度和不清晰的边缘，且边缘监督信号不足，这给边缘预测带来了挑战。不确定性建模已被证明有助于模型处理这些问题，但由于现有不确定性估计范式的不足，它们经常滤除接近决策边界的预测，导致边缘预测不稳定。", "innovation": "作者引入了证据引导一致性策略，结合Dempster-Shafer证据理论，并采用视觉Mamba基于结构状态空间序列模型，实现长距离依赖关系同时具有线性计算复杂度，构建了新颖的混合CNN-Mamba框架。通过EGL策略，CNN分支和Mamba分支在训练过程中相互启发，使得该方法在超声图像分割任务中表现出竞争力。", "conclusion": "实验表明，所提出的方法在超声图像分割中具有竞争力。数据集和代码可在以下网址获取。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.10665", "html_url": "https://arxiv.org/abs/2402.10665", "title": "Soft Dice Confidence: 一种用于语义分割选择性预测的近似最优置信度估计器", "title_en": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation", "authors": "Bruno Laboissiere Camargos Borges,Bruno Machado Pacheco,Danilo Silva", "background": "在语义分割领域中，即使是最先进的深度学习模型也无法满足某些高风险应用场景（如医疗图像分析）所需的表现力。在这种情况下，通过允许模型在低置信度下不进行预测，即选择性预测的方式，可以提升性能。尽管在分类文献中选择性预测是已知的，但在语义分割领域中却鲜有探讨。因此，本文针对图像级选择性预测问题进行了研究，提出了一种新的置信度估计方法Soft Dice Confidence (SDC)，以提高语义分割的选择性预测能力。", "innovation": "本文的主要创新在于提出了两种置信度估计方法：(i) 对于已知边缘后验概率的情况，推导出最优置信估计器，并提出了可以在线性时间内计算的Soft Dice Confidence (SDC)，并通过实验证明了它很接近最优估计器；(ii) 对于仅知道边缘后验概率估计值的情况，提出了SDC的插件版本，并证明了这种方法在多种场景下优于其他方法，特别是不需要额外调优数据的方法。", "conclusion": "本文的发现在合成数据和六种医疗成像任务的真实数据上得到了验证，包括处理未知分布情况的实验。这些结果表明SDC是一种可靠且高效的选择性预测工具，适用于语义分割的场景。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2304.01576", "html_url": "https://arxiv.org/abs/2304.01576", "title": "MESAHA-Net: 基于多编码器自适应硬注意力机制与最大强度投影的肺结节分割网络在CT扫描中的应用", "title_en": "MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan", "authors": "Muhammad Usman,Azka Rehman,Abd Ur Rehman,Abdullah Shahid,Tariq Mahmood Khan,Imran Razzak,Minyoung Chung,Yeong Gil Shin", "background": "准确的肺结节分割对于早期肺癌诊断至关重要，因为这可以大大提高患者的存活率。计算机断层扫描（CT）图像广泛用于肺结节分析的早期诊断。然而，肺结节的异质性、大小的多样性以及周围环境的复杂性为开发稳健的结节分割方法带来了挑战。因此，需要提出一种新的框架来解决这些问题，提高分割的准确性和效率，以适应临床实时应用的需求。", "innovation": "本文提出了一种高效的端到端框架，即基于多编码器自适应硬注意力机制的多尺度投影（MESAHA-Net）网络，用于CT扫描中精确的肺结节分割。MESAHA-Net通过结合CT切片贴片、前向和后向最大强度投影图像以及包含肺结节的感兴趣区域（ROI）掩膜，引入了一种新颖的自适应硬注意力机制，逐步进行肺结节的2D分割，从而生成3D体积分割。该方法在LIDC-IDRI数据集上进行了全面评估，并表现出对多种肺结节类型的高鲁棒性和较低的计算复杂度，优于现有技术。", "conclusion": "研究结果表明，MESAHA-Net网络具有较高的分割精度和较低的计算复杂度，适用于实时临床应用。该方法提供了提高肺结节诊断效果的新途径。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15955", "html_url": "https://arxiv.org/abs/2501.15955", "title": "重新思考在长尾分布下基础模型的偏倚", "title_en": "Rethinking the Bias of Foundation Model under Long-tailed Distribution", "authors": "Jiahao Chen,Bin Qin,Jiangmeng Li,Hao Chen,Bing Su", "background": "长尾学习由于其实际意义而越来越受到关注。细调范式随着基础模型的出现而引起了广泛关注，但现有的大多数方法主要集中在利用这些模型的知识上，而忽视了它们所依赖的不平衡训练数据所引入的固有偏见。本文探讨预训练所带来的不平衡如何影响下游长尾任务，并发现基础模型对下游任务固有的不平衡偏向主要体现在参数不平衡和数据不平衡。在细调过程中，参数不平衡起着更重要的作用，而数据不平衡可以通过现有的重新平衡策略来缓解。", "innovation": "研究提出了一个新的因果学习方法，将不完全的语义因素视为混杂变量，从而消除输入样本和标签之间的虚假相关性。特别地，本文提出了一种新颖的后门调整方法，该方法学习输入样本和标签之间的真正因果效应，而不是仅仅拟合数据中的相关性。实验结果表明，该方法能够有效提高任务性能，平均提高1.67%。", "conclusion": "通过建立在因果学习之上，本文提出的方法能够同时解决预训练数据带来的参数不平衡和数据不平衡的问题。特别地，通过学习输入样本和标签之间的真正因果关系，本文提出的方法克服了传统调整技术无法有效解决参数不平衡的问题，并取得了显著的性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05692", "html_url": "https://arxiv.org/abs/2504.05692", "title": "POMATO: 将点图匹配与时间运动结合用于动态三维重建", "title_en": "POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction", "authors": "Songyan Zhang,Yongtao Ge,Jinyuan Tian,Guangkai Xu,Hao Chen,Chen Lv,Chunhua Shen", "background": "动态场景中的三维重建主要依赖于几何估计和匹配模块的结合，其中匹配模块对于区分动态区域至关重要，有助于减少由相机和物体运动引入的干扰。DUSt3R 提出的点图表示可能为统一三维空间中的几何估计和匹配提供了解决方案，但仍然难以解决动态区域中的模糊匹配问题，这可能限制进一步改进。背景描述了现有技术的挑战。", "innovation": "POMATO 提出了一种统一框架，通过将点图匹配与时间运动结合，用于动态三维重建。创新点在于该方法首先通过不同视角将动态和静态区域的 RGB 像素映射到统一坐标系统中的点图，学习明确的匹配关系。此外，引入了时间运动模块以确保不同帧间的尺度一致性，并增强了需要精确几何和可靠匹配的任务（如 3D 点追踪）中的性能。通过多个下游任务（包括视频深度估计，3D 点追踪和姿态估计）展示了拟议的点图匹配和时间融合范式的有效性。", "conclusion": "POMATO 框架通过结合点图匹配和时间运动，显著提高了动态三维重建的精度和效果，尤其在具体任务如 3D 点追踪方面表现优异。研究结果表明，该方法对于多项下游任务具有显著效果，并且代码和模型已公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03834", "html_url": "https://arxiv.org/abs/2506.03834", "title": "CARE: 通过排斥估计提升视觉导航安全性以避免碰撞", "title_en": "CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation", "authors": "Joonkyung Kim,Joonyeol Sim,Woojun Kim,Katia Sycara,Changjoo Nam", "background": "近年来，基于视觉的导航模型，尤其是基础模型，在使用RGB图像生成可行轨迹方面表现出色。然而，这些模型在面对不包含在训练数据中的新奇环境或不同摄像头设置（如视野变化、摄像头姿态或焦距）的情况下，泛化能力较差。在未经微调的情况下，这些模型可能生成导致碰撞的轨迹，这需要额外的数据收集和额外的培训。", "innovation": "本文提出了CARE（通过排斥估计避免碰撞），这是一种附加模块，不需要额外的范围传感器或已经预训练的模型的微调，就能提高视觉导航的安全性。CARE能够无缝集成到任何基于RGB的生成局部机器人轨迹的导航模型中，通过直接从RGB输入估计的深度图像计算排斥力向量动态调整由预训练模型生成的轨迹。", "conclusion": "通过对多种机器人平台上的先进视觉导航模型进行评估，实验证明CARE显著减少了碰撞（高达100%），在目标条件导航中没有牺牲导航性能，并且在探索任务中进一步提高了无碰撞行驶距离（高达10.7倍）。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03256", "html_url": "https://arxiv.org/abs/2507.03256", "title": "MoDA: 多模态扩散架构用于口型生成", "title_en": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation", "authors": "Xinyang Li,Gen Li,Zhihui Lin,Yichen Qian,GongXin Yao,Weinan Jia,Aowen Wang,Weihua Chen,Fan Wang", "background": "在虚拟现实与元宇宙领域，具有任意身份和语音音频的口型生成仍是一个关键难题。虽然扩散模型已成为一种流行的生成技术，因其强大的生成能力，但扩散模型基于变分自编码器（VAE）的隐空间导致推理效率低下和视觉伪影等问题，这复杂化了扩散过程。此外，由于缺乏足够的多模态信息融合，导致口型生成中的面部表情和头部动作不够真实。该论文致力于解决这些问题和挑战。", "innovation": "MoDA通过1）定义一个结合运动生成和神经渲染的联合参数空间，并利用流匹配简化扩散学习；2）引入一种多模态扩散架构，且结合噪声运动、音频和辅助条件之间的交互关系，提升整体面部表达丰富性和互动性。此外，使用粗细融合策略逐级整合各种模态数据，确保有效的特征融合。这些创新提高了视频的多样性和逼真性，并提高了效率，使其适用于现实应用场景。", "conclusion": "实验结果表明，MoDA提高了视频的多样性和真实感，并提高了效率，使其适用于实际应用。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14264", "html_url": "https://arxiv.org/abs/2501.14264", "title": "CDI: Based on Consistency with Degraded Image for Blind Image Restoration Fidelity Evaluation", "title_en": "CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image", "authors": "Xiaojun Tang,Jingru Wang,Guangwei Huang,Guannan Chen,Rui Zheng,Lian Huai,Yuyu Liu,Xingqun Jiang", "background": "基于生成对抗网络和扩散模型的盲图像恢复（BIR）方法在提高视觉质量方面取得了显著进步，但现有满参图像质量评估（IQA）方法往往无法很好地评估高感知质量的图像。BIR方法通常存在解非唯一性和降质不确定性的挑战，这使得现有的IQA方法难以准确评价BIR的真实恢复质量。", "innovation": "本文重新评估了BIR的解非唯一性和降质不确定性问题，并提出构建特定的BIR IQA系统。具体创新包括：1）提出一种基于小波域参考引导一致性与退化图像（CDI）算法，无需了解退化参数即可获取不同类型的图像一致性；2）提出了一种无参考的CDI，可以在没有参考图像的情况下对BIR进行精度评估；3）创建了降质图像切换显示比较数据集（DISDCD），用于BIR精密度主观评价实验。实验验证了CDI在BIR精密度评估中的优越性，优于常见的满参IQA方法。开源代码和DISDCD数据集将很快发布。", "conclusion": "通过使用基于一致性与退化图像的指标（CDI），该研究提出了一个新的BIR质量评估方案，证实虽然BIR在视觉质量上有显著提高，但传统的IQA方法往往无法准确评估其恢复质量。CDI在主观测试中展现出了优越性。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09353", "html_url": "https://arxiv.org/abs/2506.09353", "title": "DAVSP: 安全对齐的大规模视觉语言模型通过深度对齐的视觉安全提示", "title_en": "DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt", "authors": "Yitong Zhang,Jia Li,Liyi Cai,Ge Li", "background": "大规模视觉语言模型（LVLMs）在各种应用场景中取得了显著进步，但在恶意查询的攻击下仍然脆弱。现有的对齐方法通常在抵御恶意查询的同时保证对良性输入的有效性方面表现不佳。本文旨在解决这些挑战，通过对LVLMs的安全提示进行深度对齐来提高其对恶意查询的感知能力，从而增强模型的安全性。", "innovation": "文章提出了深度对齐的视觉安全提示（Deep Aligned Visual Safety Prompt, DAVSP），包含两个关键创新点：1. 提出可视化安全提示，通过在输入图像周围添加一个可训练的填充区域来保留视觉特征并扩展优化空间；2. 引入了深度对齐方法，在模型激活空间中进行监督训练，从而提高LVLMs对恶意查询的感知能力，实现比先前工作更深的对齐。其余耗散的研究进一步证明了DAVSP在抵御恶意查询并保持良性输入功能方面的有效性，同时具有良好的模型间生成能力。", "conclusion": "广泛的经验表明，DAVSP在多种基准上的五种大规模视觉语言模型上有效地抵御了恶意查询，同时保持了良性输入的实用性。消融研究表明，视觉安全提示和深度对齐都是DAVSP有效性的必要组成部分，共同贡献了其整体效果。代码已在公共平台开源。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05568", "html_url": "https://arxiv.org/abs/2508.05568", "title": "X-VFL: 一种新的具有交叉完成和决策子空间对齐的新垂直联邦学习框架", "title_en": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment", "authors": "Qinghua Yao,Xiangrui Xu,Zhize Li", "background": "垂直联邦学习（VFL）通过整合多个客户端/参与者的不重叠特征子集实现了协作学习。然而，VFL通常面临两个关键挑战：（i）所有客户端都需要完美对齐的数据样本（不允许缺失特征）；（ii）它要求联合协作推断/预测涉及所有客户端（不支持单个客户端上的本地独立推断）。因此，有必要提出一种新框架来解决这些问题。", "innovation": "我们提出了X-VFL，这是一种新框架，旨在处理不重叠数据样本中的（部分）缺失特征以及支持每个客户端的新数据样本的本地独立推断。X-VFL设计了两个新的模块：XCom和DS-Align。XCom通过利用其他客户端的信息来完成/重构非对齐数据样本中的缺失特征。DS-Align在决策子空间内对齐局部特征与已完成和遍布所有客户端的全局特征，从而允许每个客户端进行本地独立推断。此外，我们还提供了不同的X-VFL训练算法的收敛性定理，证明了SGD类型算法的$O(1/\text{√T})$收敛率和PAGE类型算法的$O(1/T)$收敛率。", "conclusion": "在真实数据集上的广泛实验表明，X-VFL显著优于现有方法，例如在图像CIFAR-10数据集上提高了15%的准确率，在医学MIMIC-III数据集上提高了43%的准确率，这些结果验证了X-VFL在包含部分缺失特征和本地独立推断场景中的实用有效性和优越性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05778", "html_url": "https://arxiv.org/abs/2508.05778", "title": "基于机器学习的非线性推移调整方法用于混沌动力系统", "title_en": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems", "authors": "Jaemin Oh,Jinsil Lee,Youngjoon Hong", "background": "推移调整是一种将观测驱动控制项整合入模型动力学的实证数据融合技术，能够在初始条件不同时，使推移调整系统的轨迹接近真实系统的轨迹。尽管恒定状态下空间模型中的这种控制项在轻微假设下可以被推导，但在非线性系统中设计有效的推移调整项变得更为困难。在这项工作中，作者提出了一种基于神经网络的推移调整方法，以学习非线性状态空间模型中的推移调整项，该方法的理论可行性基于Kazantzis-Kravaris-Luenberger观测器理论。", "innovation": "本研究提出了神经网络推移调整方法，这是一种数据驱动的方法，在非线性状态空间模型中学习推移调整项。该方法依据Kazantzis-Kravaris-Luenberger观测器理论建立了理论存在结果。实验在具有混沌行为的基准问题上进行了验证：Lorenz 96模型、Kuramoto-Sivashinsky方程和Kolmogorov流动。", "conclusion": "该研究提出的方法证明了在非线性动力系统中实现推移调整技术的可行性，特别是通过深度学习技术和观测器理论得到的理论支持。该方法的有效性通过一系列混沌动力系统的实验得到了验证。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05659", "html_url": "https://arxiv.org/abs/2508.05659", "title": "从图到动态 (D2D): 在不确定性下探索因果循环图的杠杆点", "title_en": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty", "authors": "Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos", "background": "因果回路图（CLDs）在健康和环境研究中广泛用于表示复杂问题背后的假设因果结构。然而，由于其仅作为定性且静态的表示，这些图在支持动态分析和制定干预策略方面能力有限。量化CLD分析方法，如网络中心性分析，往往会误导结论。本文概述了从因果回路图到动态模型转化的概念和背景。", "innovation": "提出了一种名为从图到动态（D2D）的方法，该方法能够在缺乏实证数据的情况下，将因果回路图转换为探索性系统动力学模型。D2D方法只需要最少的用户输入，并利用因果回路图内在的结构信息（包括链接的存在与极性），来模拟假设的干预措施并探索在不确定性下的潜在杠杆点。该方法在开放源代码的Python包和基于网络的应用程序中实现，以支持进一步测试并降低研究人员在使用因果回路图进行动态建模时的障碍。研究结果显示，D2D方法在识别高和低排名的杠杆点方面表现出更好的一致性，同时提供不确定性估计和未来数据收集的指导。", "conclusion": "D2D方法相比网络中心性分析，在数据驱动的系统动力学模型中表现更好，同时其提供了不确定性估计和未来数据收集的指导。该方法已实现为一个开源的Python包和基于网络的应用程序，以支持进一步的测试和降低研究人员使用因果回路图进行动态建模的门槛。未来对D2D方法的进一步验证将有助于其在广泛案例和领域的实用性得到确立。"}
{"llm_update_time": "20250811", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09082", "html_url": "https://arxiv.org/abs/2506.09082", "title": "AVA-Bench：视觉基础模型原子视觉能力基准", "title_en": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models", "authors": "Zheda Mai,Arpita Chowdhury,Zihe Wang,Sooyoung Jeon,Lemeng Wang,Jiacheng Hou,Wei-Lun Chao", "background": "视觉基础模型(VFMs)的兴起需要系统性的评估方法。目前常见的做法是将VFMs与大型语言模型(LLMs)一起用作通用头部，然后在广泛使用的视觉问答(VQA)基准上进行评估。然而，这种做法存在两个关键盲点：(1) 指令调整数据可能与VQA测试分布不匹配，错误预测可能是由于数据不一致而非VFMs的视觉缺陷；(2) VQA基准通常要求多种视觉能力，难以区分错误是由于缺乏所有所需能力还是单一关键能力的缺陷。", "innovation": "介绍了AVA-Bench，这是第一个明确分离14种原子视觉能力(AVAs)的基准。AVAs包括定位、深度估计和空间理解等基础技能，共同支持复杂的视觉推理任务。通过分离AVAs并在每个类别内匹配训练和测试分布，AVA-Bench可以准确指出VFMs的强项和弱点。该基准允许对领先VFMs进行全面且透明的评估，揭示了视觉能力的独特“指纹”，使VFMs的选择变得基于原理工程而非猜测。此外，研究发现一个0.5B的LLM的表现与一个7B的LLM相似，但计算时间减少了8倍，这能提高评估效率。", "conclusion": "通过提供一个综合且透明的基准，我们希望AVA-Bench为下一代VFMs奠定基础。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05836", "html_url": "https://arxiv.org/abs/2508.05836", "title": "文本图中的有效节点分类方法", "title_en": "An Effective Approach for Node Classification in Textual Graphs", "authors": "Rituparna Datta,Nibir Chandra Mandal", "background": "文本属性图（Textual Attribute Graphs, TAGs）对于建模复杂网络如引文网络至关重要。然而，由于难以将文本中的丰富语义信息与结构图信息整合起来，有效的节点分类仍然具有挑战性。现有方法往往难以捕捉特定领域术语、建模长范围依赖关系、适应时间演化以及处理大量数据集。", "innovation": "本文提出了一种新颖的框架，结合了TAPE（Text-Attributed Graph Representation Enhancement）与Graphormer。框架利用大型语言模型（如ChatGPT）生成从论文内容中提取的丰富语义解释，并将这些解释融合到增强的节点表示中。通过学习到的注意力权重结合结构特征。这种方法使用Graphormer的路径感知位置编码和多头注意力机制来有效捕捉引文网络中的长距离依赖关系。实验结果表明，该框架在ogbn-arxiv数据集上实现了最先进的分类准确率0.772，显著超越了最佳GCN基线0.713，同时在精确率、召回率和F1分数上也表现优异。", "conclusion": "我们的方法通过全面的消融研究验证了语义和结构信息的协同作用。框架提供了一种可扩展且稳健的解决方案，用于动态文本属性图中的节点分类，为未来知识系统和科学发现的研究提供了一个有前景的方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05831", "html_url": "https://arxiv.org/abs/2508.05831", "title": "科学机器学习中的最优线性基准模型", "title_en": "Optimal Linear Baseline Models for Scientific Machine Learning", "authors": "Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung", "background": "在各个科学领域，一个基本挑战是确定和计算从物理过程到观测信号和测量之间的映射。尽管非线性神经网络已经取得了显著的成功，但它们仍然缺乏理论上的透明度，在需要高度可解释性的场景中难以被采纳。相比之下，线性神经网络提供了简化但有效的途径，以洞察这些复杂的关系。", "innovation": "本工作开发了一个统一的理论框架，用于通过贝叶斯风险最小化视角分析线性编码-解码架构，以解决数据驱动的科学机器学习问题。我们推导出适用于正向建模和逆向恢复任务的封闭形式、有限秩的线性和仿射线性最优映射。我们的结果通过数值实验对简单生物医学成像、金融因子分析以及利用浅水方程模拟的非线性流体动力学数据集进行了验证，这些实验结果扩展了现有方法，涵盖了数据、正向算子和度量过程中的秩不足情况。", "conclusion": "本工作为理解并基准测试用于科学机器学习问题的训练神经网络模型提供了稳健的基础。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05915", "html_url": "https://arxiv.org/abs/2508.05915", "title": "随机时间序列的双信号分解", "title_en": "Dual Signal Decomposition of Stochastic Time Series", "authors": "Alex Glushkovsky", "background": "该研究论文研究了随机时间序列的分解问题，将一个随机时间序列分解为三个表示双信号（即均值和方差）的时间序列，并通过机器学习将噪声与其他部分隔离。", "innovation": "首先通过机器学习来拟合双信号，并最小化损失函数，损失函数在拟合原始时间序列和惩罚双信号的不规则性之间寻求平衡。引入统计过程控制方法来加权正则化项，以保留特殊模式。提出了串联和联合学习两种方法，后者可以揭示具有异方差性的时间序列中的复杂关系。此外，学习过程可以通过直接非线性无约束优化问题或神经网络（具有串联或孪生输出架构）进行设置，同时调整损失函数的超参数，使其孤立出的噪声成为不具备自相关性的平稳随机过程。", "conclusion": "所提出的分解方法不仅可以用作对时间序列均值和方差的平滑算法，而且也可以作为一种去噪算法。根据应用场景，可以通过调整超参数使学习过程侧重于离散状态或平滑序列。分解后的双信号可以在二维空间中表示，用于学习固有结构，预测均值和方差，或分析多时间序列中的相互影响。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05905", "html_url": "https://arxiv.org/abs/2508.05905", "title": "第四种状态：Signed-Zero 贰元量化在稳定的大语言模型量化（以及其他方面的应用）", "title_en": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)", "authors": "Jeffrey Uhlmann", "background": "量化通常被视为在保持性能的同时减少计算需求的一个手段，即作为次优近似。然而，如果按照固定的整体资源预算来衡量，就会得出不同的视角。文中引入了Signed-Zero 贰元量化（SZT），这是一种2位量化方法，能够确定地提供梯度信息且不影响正向路径计算。文中分析表明，与未量化的选择相比，它可能提高了信息密度。", "innovation": "提出了Signed-Zero 贰元量化（SZT），这是一种2位量化方法，能够在正向路径计算中不产生额外开销的前提下提供确定性的梯度信息。这种量化方法在固定整体资源预算的情况下能够提高信息密度，解决了传统意义上的量化方法的次优性问题。", "conclusion": "该量化方法能够用较少的位宽来传输更多信息，从而优化大语言模型的计算资源使用。研究表明，这种方法可能在信息密度上超过了无量化方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05791", "html_url": "https://arxiv.org/abs/2508.05791", "title": "从不完美的信号到值得信赖的结构：具有不确定性意识的异质且可靠性不同的公用事业数据推理", "title_en": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data", "authors": "Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu", "background": "准确的配电网拓扑对于现代电网可靠运行至关重要。然而，实际的电网数据源自多个具有不同特征和质量水平的来源。本文通过对异质数据的系统整合，提出了一个可扩展的框架，以重建值得信任的电网拓扑。配电电网的基础是空间布局（如GIS和资产元数据）和在信号域中的动态行为（如电压时间序列）这两个互补维度。当共同利用这两个维度时，支持一个完整和物理上一致的网络连接重构。为了在不降低观察性的情况下应对数据质量不均匀的挑战，引入了一种具备不确定性的推理机制，该机制保留了结构信息但不完美的输入，同时对每个推断的连接的可靠性进行量化，以便供操作者解析。这种软性处理不确定性的机制与严格的物理可行性要求紧密结合：将操作约束如变压器容量限制和辐射型拓扑要求直接嵌入学习过程中。这些组件共同确保推理具有不确定性的意识，并且是结构有效的，从而在实际部署条件下能够快速收敛到可操作且可靠的拓扑。该框架在 Oncor 公司服务区内超过 8000 米的 3 条馈线的数据上进行了验证，显示了超过 95% 的拓扑重构准确性，并且在信心校准和计算效率方面比基准方法有了显著改进。", "innovation": "本文提出了一个可扩展的框架，用于利用异质数据重建值得信赖的配电网拓扑。该框架引入了一种具有不确定性意识的推理机制，能够保留但不完美的输入，同时量化每个推断连接的可靠性，并嵌入操作约束以确保物理可行性。通过这种方式，它在观测和操作准确性和效率之间取得了平衡。", "conclusion": "该框架在 Oncor 公司的服务区域进行了验证，展示了在拓扑重构方面的高精度，并且在信心校准和计算效率方面取得了实质性的改进。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05921", "html_url": "https://arxiv.org/abs/2508.05921", "title": "快速、凸性和条件化网络用于多保真度向量和刚性单变量微分方程", "title_en": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations", "authors": "Siddharth Rout", "background": "神经网络在求解偏微分方程（PDE）时的准确性往往不是因为表达能力有限，而是因为优化问题因病态条件而变得复杂，特别是在多保真度和刚性问题中。本文研究了这种现象在物理信息极限学习机（PIELM）中的表现，PIELM是神经PDE求解器的一种凸性变体，发现主导方程中的渐近成分会产生病态的激活矩阵，严重影响了收敛性。", "innovation": "本文引入了一种简单而有效的激活筛选步骤——Shifted Gaussian Encoding，它可以增加矩阵的秩和表达能力，同时保持凸性。该方法使得稳态对流-扩散方程的Peclet数解算范围扩展了两个数量级，多频函数学习的误差降低了六个数量级，并且比具有超过一百万个参数的深度网络更快、更准确地拟合高保真度图像向量。这项工作强调了在科学神经求解器中，条件问题，而非深度，往往是瓶颈，通过简单的架构更改可以实现显著的提升。", "conclusion": "本文的工作表明，Optimization的条件性而非网络深度是科学神经求解器中的主要瓶颈，通过简单的架构变化可以获得显著的性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05928", "html_url": "https://arxiv.org/abs/2508.05928", "title": "通过噪声感知优势重新加权减轻LLM推理中的思考与回答不匹配", "title_en": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting", "authors": "Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu", "background": "Group-Relative Policy Optimization (GRPO)是一种用于训练大模型的关键技术，但由于存在思辨和回答不匹配的问题，导致学习过程中的奖励信号被噪音污染。这个问题在响应组不平衡时最为严重，反而使原本应该是最具信息性的信号恶化。", "innovation": "提出了一种名为Stable Group-Relative Policy Optimization (S-GRPO)的方法，通过计算最优且对噪声敏感的优势权重来稳定训练过程。S-GRPO在数学推理基准测试中的全面实验中表现出色且稳定，特别是在存在20%合成奖励噪声的情况下，S-GRPO仍然能够保持稳定的学习进度，而标准GRPO无法学习。", "conclusion": "这些结果表明S-GRPO在增强大规模推理模型的稳健性和有效性方面具有巨大潜力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05957", "html_url": "https://arxiv.org/abs/2508.05957", "title": "基于多臂bandit的决策树优化", "title_en": "Multi-Armed Bandits-Based Optimization of Decision Trees", "authors": "Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman", "background": "决策树在无适当约束的情况下容易变得过于复杂，容易过拟合，捕捉到噪声而非可泛化的模式。传统的剪枝技术如成本复杂性剪枝（CCP）和减少错误剪枝（REP）主要采用贪婪方法，这些方法着重于剪枝时的即时性能提升，但长期来看会导致较差的泛化能力，特别是在用小型和复杂的数据集训练时，这会削弱决策树模型在未见数据上的稳健性。", "innovation": "提出了一种基于多臂带扩展（MAB）的剪枝方法，这是一种基于强化学习（RL）的技术，能够动态地剪枝决策树以生成具有更好泛化性能的最优决策树。该方法将剪枝过程视为探索-利用问题，并利用MAB算法根据每次剪枝行动的反馈来确定需要剪枝的最优分支节点。", "conclusion": "实验结果表明，与传统方法相比，提出的方法在多个基准数据集上的预测性能更好，这表明使用MAB进行决策树剪枝的潜力，从而优化基于决策树的模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05960", "html_url": "https://arxiv.org/abs/2508.05960", "title": "Offline Reinforcement Learning中轻微保守正则化评估", "title_en": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning", "authors": "Haohui Chen,Zhiyong Chen", "background": "离线强化学习（RL）旨在利用静态数据集学习最优策略，而不需要进一步的环境交互。面临的挑战是，学习到的策略和行为策略之间的分布差异，导致离分布（OOD）动作和过度估计。为防止过度估计，价值函数必须保持保守；然而，过度保守可能妨碍性能提升。因此，本研究提出了一种轻微保守正则化评估（MCRE）框架，通过结合时差（TD）误差和行为克隆项，平衡保守性和性能。在此基础上，我们开发了轻微保守正则化Q学习（MCRQ）算法，将MCRE整合进离策略演员-评论家框架。实验结果显示，MCRQ在基准数据集上优于强基线和最新的离线RL算法。", "innovation": "提出了一种轻微保守正则化评估（MCRE）框架，结合了时差（TD）误差和行为克隆项，以平衡保守性和性能。在此基础上，开发了轻微保守正则化Q学习（MCRQ）算法。MCRQ在离线RL基准数据集上显著优于竞争对手和基线方法。", "conclusion": "MCRQ算法通过结合MCRE框架，成功解决了离线RL中保守性和性能之间的权衡问题，展示了在多种基准数据集上的优越性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05724", "html_url": "https://arxiv.org/abs/2508.05724", "title": "一种用于映射物理学概念结构和分支连接性的图神经网络方法", "title_en": "A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics", "authors": "Massimiliano Romiti", "background": "本文提出了一种新颖的框架，用于表示和分析物理定律，将其视为加权知识图。作者构建了一个包含659个独特物理方程的数据库，并进行了严格的语义清理，解决了符号歧义问题，形成了400个高级物理方程的语料库。在此基础上，作者开发了一种增强的图表示，其中物理概念和方程均作为节点，彼此通过加权公式桥梁相连。权重是基于变量重叠的归一化度量、物理信息重要性评分和文献计量数据客观定义的。通过对链接预测进行训练，模型在五个独立运行中实现了0.9742 ± 0.0018的测试AUC，显著优于经典启发法（最佳基线AUC: 0.9487）和如GraphSAGE之类的现有图神经网络架构（AUC: 0.9504，p = 0.029）。统计测试显示所有比较均具有统计学意义（p < 0.05），与最佳基线相比提高了2.7%。模型揭示了三个关键发现：（i）模型自主重新发现了物理学已知的宏观结构，辨识出电磁学与统计力学之间的强概念轴；（ii）识别出了关键的中心方程，作为多个物理领域之间的关键桥梁；（iii）生成稳定、计算导出的跨域关系假设，不仅确认已知原理，还提出了新的数学类比供进一步理论研究。该框架可以生成数百个这样的假设，从而为特定物理子领域的针对性分析创建专用数据集。代码与数据可在指定网址获取。", "innovation": "本文的创新之处在于提出了一种新的加权知识图表示框架，以及通过使用归一化度量、物理信息重要性评分和文献计量数据来客观定义权重的方法。提出了一个增强的图表示，包括物理概念和方程节点，通过加权公式桥梁连接，并通过已训练的图注意力网络（GAT）来进行链接预测。这种方法显著超越了经典启发法和现有图神经网络架构，展示了优异的性能和显著的统计学意义。模型能够自主发现已知物理结构，并帮助生成跨域关系的假设，提供新的数学类比进行进一步研究。同时，该框架还能够创造数百个假设，用于特定物理子领域的详细分析。", "conclusion": "本文提出了一种用于表示和分析物理定律的新颖框架，并通过图神经网络方法对其进行了证明。结果显示模型不仅能够自主重组已知物理结构，还能够发现潜在的跨领域联系，生成稳定、可验证的假设。这种框架不仅能够为物理学提供新的研究思路，还能够支持自动数据生成，促进特定物理子领域的针对性分析。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05977", "html_url": "https://arxiv.org/abs/2508.05977", "title": "LinguaFluid：强化学习中基于语义奖励的语言引导流体控制", "title_en": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "authors": "Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan", "background": "在科学机器学习领域，设计有效的奖励函数依然是强化学习（RL）中的一个挑战，尤其是在任务目标难以量化的情形下。现有的工作中，奖励函数主要基于经验规则、手工工程或者针对特定任务进行调优。", "innovation": "提出了一种语义对齐的强化学习方法，通过Sentence-Bidirectional Encoder Representations from Transformers (SBERT)将当前状态与目标语义指令对齐计算奖励。这种方法不依赖于人工定义的奖励函数，而是基于目标描述与任务描述间的余弦相似度提供反馈，展示了基于语义的奖励可以引导学习实现与手工调优奖励函数相当的控制行为。此外，该研究展示了语言嵌入空间与传统欧几里得空间之间的关联，并为通过自然语言目标调整智能体行为和无缝集成大型语言模型（LLMs）及流体控制应用奠定了基础。", "conclusion": "研究表明，语言嵌入空间与传统空间之间存在相关性，这种方法能够指导智能体的行为与自然语言目标对齐，并为未来进一步整合自然语言处理和流体控制提供了可能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05995", "html_url": "https://arxiv.org/abs/2508.05995", "title": "使用蒙特卡洛树搜索优化提示序列以实现基于LLM的优化", "title_en": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization", "authors": "Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan", "background": "大型语言模型（LLMs）在代码生成和结构化推理方面表现出色，但在需要持续多步规划的复杂任务上，其性能往往会下降。最近的研究探索了将LLMs与蒙特卡洛树搜索（MCTS）结合使用，但现有方法主要集中在生成基于启发式的代码以优化或针对简单任务，其中正确性是唯一需求。", "innovation": "本文提出了一种新颖的神经符号框架MCTS-OPS，将提示选择形式化为由MCTS引导的顺序决策过程。该方法探索并优化多步提示序列，以提高代码生成质量并增强LLMs在通用优化中的问题解决能力。实验结果表明，在网络优化中，该方法在执行生成代码的成功率和具有特定目标和约束的优化结果中表现显著提高，分别提高了2-4倍的奖励和3倍的更低标准差。而且在困难问题中提高了获得最优解机会约10%。这些结果表明，结合符号规划与LLMs对于复杂领域的高质量代码生成具有潜力和可靠性。", "conclusion": "MCTS-OPS显著提升了以LLMs为基础的优化过程中的代码生成质量和问题解决能力，特别适用于复杂优化任务。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05988", "html_url": "https://arxiv.org/abs/2508.05988", "title": "通过首词惊 surprisal 剪枝高效的代码推理", "title_en": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "authors": "Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu", "background": "近年来，大型推理模型（LRMs）在代码推理方面通过扩展链式思考（CoT）的长度展现了显著的能力。然而，过长的推理解释链带来了显著的挑战，包括训练成本增加、推理延迟以及部署可行性问题。尽管出现了各种CoT压缩方法以应对这些挑战，但它们都存在固有的权衡：基于标记的方法经常破坏语法和逻辑的一致性，而基于困惑度的基于步骤的方法则难以可靠地捕捉逻辑上重要的推理解释步骤。", "innovation": "本文提出了一种新颖的粗动框架ASAP（Anchor-guided, Surprisal-based Pruning），用于CoT压缩。ASAP首先通过锚点引导的剪枝保留核心的推理解释结构，从而有效缩减后续处理的搜索空间。接着利用一种新颖的第一词惊 surprisal 指标实现逻辑敏感的剪枝，筛选出逻辑上必要的推理解释步骤。最终，ASAP可使模型在推理时自主生成和利用这些简洁的CoT，从而实现高效的推理。实验表明，ASAP在多个代码生成基准上达到了最先进的准确率，并大幅度减少了训练和推理成本。在具有挑战性的LiveCodeBench v4_v5基准上，相比最佳基线，ASAP减少了23.5%的标记生成量和43.5%的推理延迟，同时实现了竞争性的准确率为36.19%的通过率（Pass@1）。", "conclusion": "我们的研究表明，通过ASAP实现高效的代码推理是一种有力而高效的方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06034", "html_url": "https://arxiv.org/abs/2508.06034", "title": "自适应异质图神经网络：连接同质性和异质性", "title_en": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity", "authors": "Qin Chen,Guojie Song", "background": "异质图（HGs）在现实世界中普遍存在，常常表现出异质性。然而，现有的大多数研究只集中在异质性或异质性的单一方面，忽视了实践应用中同质图的普遍性。这种忽视导致了这类图在网络性能上的下降。", "innovation": "本文首先识别出在建模同质图时的两大挑战：（1）在不同跳跃步和元路径中异质性分布的变化；（2）不同元路径之间语义信息的复杂多样性，往往由异质性驱动。然后提出了一种自适应异质图神经网络（AHGNN）来解决这些挑战。AHGNN采用了同质性意识卷积，考虑到两者特定的跳跃步和元路径的异质性分布。然后使用自上而下的注意力机制整合来自不同语义空间的消息，从而过滤噪声并强调信息信号。", "conclusion": "在七个真实世界图和二十个基准模型上的实验表明，AHGNN在高异质性情况下表现尤为出色，尤其是在网络性能上优于其他方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05984", "html_url": "https://arxiv.org/abs/2508.05984", "title": "无参数最优速率的非线性半范收缩及其在$Q$-学习中的应用", "title_en": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning", "authors": "Ankur Naskar,Gugan Thoppe,Vijay Gupta", "background": "解决非线性固定点方程（如平均奖励$Q$-学习和TD学习）的算法通常涉及半范收缩。尽管存在Polyak-Ruppert平均法，使得无参数的最优收敛率仍然难以实现，尤其是由于这类半范的非单调性。", "innovation": "本文通过重写平均误差为线性递归并引入非线性扰动，结合半范收缩与适当诱导范数的单调性来驾驭非线性，从而首次提供适用于平均奖励和指数折扣两种情况下的$Q$-学习的无参数最优速率$\tilde{O}(1/\text{sqrt}(t))$。结果适用于同步和异步更新、单代理和分布式部署以及来自模拟器或马尔可夫轨迹的数据流。", "conclusion": "本文主要结果提供了适用于广泛框架的无参数最优速率，该框架包括同步和异步更新、单代理和分布式部署以及来自模拟器或马尔可夫轨迹的数据流，首次在$Q$-学习中实现了无参数的最优收敛率。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06151", "html_url": "https://arxiv.org/abs/2508.06151", "title": "使用扩散模型生成修补合成病灶以提高口腔癌诊断准确性的方法", "title_en": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models", "authors": "Yong Oh Lee,JeeEun Kim,Jung Woo Lee", "background": "在口腔癌诊断中，标注数据的缺乏限制了诊断模型的性能，尤其是在训练数据的变异性不足和数量不够时。为了解决这些问题，本研究提出了一种通过使用微调的扩散模型和修补技术合成逼真的口腔癌病灶的方法，以增强诊断准确性。", "innovation": "本研究提出了利用微调的扩散模型和修补技术生成逼真口腔癌病灶的新方法。该方法生成的合成病灶具有高度的视觉真实性，显著提高了诊断算法的性能。结果表明，分类模型在区分癌性和非癌性组织方面的诊断准确率为0.97，检测模型在准确识别病灶位置方面的准确率为0.85。", "conclusion": "本研究验证了合成图像生成在医学诊断中的潜力，并为将这些方法扩展到其他类型的癌症诊断开辟了新的研究方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06066", "html_url": "https://arxiv.org/abs/2508.06066", "title": "时间网络的架构感知泛化边界：理论与公平比较方法", "title_en": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "authors": "Barak Gahtan,Alex M. Bronstein", "background": "深度时序架构如时序卷积网络(TCNs)在序列数据上的预测性能表现非常出色，然而对其泛化能力的理论理解仍然非常有限。", "innovation": "本研究首次提供了时间深度模型的第一组不为空的、架构感知的泛化边界，并提出了一种原则性的评估方法。对于指数级β-混合序列，推导出来的边界表达式为 $O\bigl(R\frac{Dp n \text{log} N}{N}\bigr)$。提出的延迟反馈分块机制能将相关样本转化为几乎独立的样本，同时仅丢弃 $O(1/\text{log} N)$ 的数据，这样的噪声级数从指数级下降到平方根级。此外，引入了公平比较方法，通过固定有效样本大小来单独分析时序结构和信息含量的影响。研究表明，高度依赖的序列在固定信息预算下能够显著减小泛化误差，但理论预测与实践中的收敛速度不符，需要未来继续研究。", "conclusion": "当有效样本数量相同的情况下，高度依赖序列的泛化误差明显小于弱依赖序列，挑战了仅依赖性是完全有害的观点。然而，弱相关性与强相关性的收敛速率都比理论预测的更快，表明需要在理论和实践中进一步探索时间依赖性对学习的影响。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06108", "html_url": "https://arxiv.org/abs/2508.06108", "title": "GCHR : 目标条件下的暗示目标正则化以提高样本利用效率的强化学习", "title_en": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning", "authors": "Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang", "background": "目标条件下的强化学习（GCRL）在稀疏奖励下仍是一项基本挑战。虽然回溯经验回放（HER）通过重新标记收集的轨迹以实现目标展示了潜力，但我们认为，轨迹重新标记单独使用未能充分利用可用的经验，导致在离策略GCRL方法中的样本效率有限。", "innovation": "本文提出了一种称为‘暗示目标条件正则化’（HGR）的技术，基于回溯目标生成动作正则化先验。通过与‘自模仿正则化’（HSR）结合使用，我们的方法使离策略RL算法能够最大化经验利用。相较依赖HER和自模仿技术的现有GCRL方法，我们的暗示正则化能够实现更有效的样本重复利用，并取得最佳性能。", "conclusion": "我们在导航和操作任务上的实验证明了这一方法的有效性。与现有GCRL方法相比，我们的设计显著提高了样本效率并取得了最佳性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06041", "html_url": "https://arxiv.org/abs/2508.06041", "title": "DP-LLM：基于动态层精度分配的运行时模型适配", "title_en": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "authors": "Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park", "background": "本文讨论了如何有效处理具有不同运行时约束（如延迟和准确性）的设备上大型语言模型（LLM）查询的问题。虽然多尺度量化可以通过多重模型变体的叠加解决了这一挑战，但如何将模型适配到目标精度或延迟仍然是一个开放的问题。传统的混合精度方法提供了一些解决方案，但本文通过动态层精度分配提出了DP-LLM机制，进一步优化了该问题。", "innovation": "提出了一种新的机制DP-LLM，该机制根据输入值动态分配每个层的精度，通过轻量级误差估计器和通过精细调优学习到的阈值来确定运行时的位宽。这种方法优于之前的解决方案，能够在性能和延迟之间实现更好的权衡。", "conclusion": "实验结果显示，DP-LLM在多个模型和基准测试中表现出优越的性能-延迟折衷，优于之前的方案。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06097", "html_url": "https://arxiv.org/abs/2508.06097", "title": "递归深可微逻辑门网络", "title_en": "Recurrent Deep Differentiable Logic Gate Networks", "authors": "Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer", "background": "虽然可微逻辑门在前馈网络中展现了潜力，但在序列建模中的应用尚处未开垦的状态。该论文首次实现了递归深可微逻辑门网络（RDDLGN），该模型结合了布尔操作与递归结构，用于序列到序列的学习任务。它评估了在WMT'14英德翻译数据集上的表现，结果表明RDDLGN在训练期间取得了5.00 BLEU和30.9%的准确率，接近GRU（5.41 BLEU）的表现，并且在推理阶段也表现出平稳的下降趋势（4.39 BLEU）。", "innovation": "本研究的创新点在于首次实现了递归深可微逻辑门网络，该模型结合了递归结构和布尔逻辑操作，特别适用于序列到序列的学习任务，特别是在序列建模方面的应用首次得到探索。研究还表明，该模型的性能接近递归门控单元（GRU）的水平，并且在推理阶段的性能也较为稳定，这是一个重要的突破。此外，这项工作为FPGA加速序列建模以及其他递归网络架构的研究开辟了新的方向", "conclusion": "本研究建立了递归逻辑基础的神经计算模型的有效性，为未来基于FPGA的加速以及递归网络架构的研究提供了新的方向，并展示了一种新的可能有效的序列建模方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06023", "html_url": "https://arxiv.org/abs/2508.06023", "title": "步步为营的Fine和Gray模型：个体特异性变量选择展示血流动力学数据在昏迷心脏骤停患者预后推断中的改善", "title_en": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients", "authors": "Xiaobin Shen,Jonathan Elmer,George H. Chen", "background": "在心脏骤停后昏迷的病患中进行预后评估是一个关键挑战，直接关系到重症监护病房中的临床决策。关于预后的临床信息会随着时间进行多次收集。心脏骤停后不久会收集一系列非变基线特征（如人口统计信息和心脏骤停特点）。进入重症监护病房后，还会收集更多特征，包括随时间变化的血流动力学数据（例如血压和血管加压药剂量）。我们视此为两个阶段的特征收集过程。在这个研究中，我们提出了一个新颖的逐步动态竞风险模型，通过自动确定何时利用非变基线特征（第一阶段）和随时间变化的特征（第二阶段）来提高神经预后预测的准确性。模型能够识别哪些患者在给定的时间点及随时间积累更多血流动力学数据能够对预后推断产生显著好处。", "innovation": "提出了一个新颖的逐步动态竞风险模型，能够自动确定何时采用非变基线特征（第一阶段）和随时间变化的特征（第二阶段）。该模型通过扩展标准的Fine和Gray模型来明确建模两个阶段，并且使用神经网络来灵活捕捉复杂的非线性特征关系。这种方法有可能适用于更多阶段的特征收集，并在其他动态预测任务中也非常有用，尤其是知道何时以及为什么新收集的特征显著改善预测结果方面具有潜在帮助", "conclusion": "该模型在一项回顾性队列研究（包含2,278例心脏骤停后昏迷患者）中，即使在最大支持情况下仍展现了针对醒转、撤除生命维持治疗和死亡这一竞争性结果的强大区分能力。模型的应用不仅涵盖了两个收集新特征的阶段，还具有推广到更多阶段的潜力，并且可能适用于其他动态预测问题。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06199", "html_url": "https://arxiv.org/abs/2508.06199", "title": "分子预训练嵌入模型的基准测试", "title_en": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning", "authors": "Mateusz Praski,Jakub Adamczyk,Wojciech Czech", "background": "预训练神经网络在化学和小分子药物设计中引起了广泛关注，这些模型的嵌入被广泛应用于分子性质预测、虚拟筛选和分子化学中的小数据学习。本文通过对比25种模型在25个数据集上的性能，进行了迄今为止最广泛的比较研究，评估了各种模态、架构和预训练策略的模型，并揭示了显著的实验结果，从而引发了对现有研究中评估严谨性的质疑。", "innovation": "本文进行了对比25种模型在25个数据集上的最广泛的比较研究，在公平对比框架下评估了不同模态、架构和预训练策略的模型，并使用专门的分层贝叶斯统计测试模型，得出虽然几乎所有神经网络模型在基准ECFP分子指纹上的性能提升都不显著，但CLAMP模型作为基于分子指纹的模型在统计上显著优于其他模型的结果。这些发现质疑了现有研究中的评估严谨性，并提出了潜在原因、解决方案和实用建议。", "conclusion": "本文的研究结果揭示了分子预训练嵌入模型在表现上的分歧，强调了在进一步研究中提高评估严谨性的必要性，并提出了具体的建议和解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06244", "html_url": "https://arxiv.org/abs/2508.06244", "title": "部分特征下的成员推断攻击", "title_en": "Membership Inference Attack with Partial Features", "authors": "Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang", "background": "现有的成员推断方法通常假设攻击者能够完全访问目标样本的所有特征。然而，在许多实际场景中，攻击者只能访问部分特征信息，这限制了现有方法的应用范围。", "innovation": "提出了一个名为MRAD（基于记忆的重建与异常检测）的两阶段攻击框架，在第一阶段优化未知特征值以最小化样本的损失；在第二阶段使用异常检测衡量重建的样本与训练分布之间的偏差。", "conclusion": "实验结果表明，MRAD在多个数据集上具有有效性，并且与各种现成的异常检测技术兼容。例如，在STL-10数据集上，即使有40%的特征缺失，我们的攻击仍能实现约0.6的AUC值。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06243", "html_url": "https://arxiv.org/abs/2508.06243", "title": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems", "title_en": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems", "authors": "Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian", "background": "6G网络的出现为车载娱乐服务带来了新的可能性，但传统无线电资源管理（RRM）技术难以处理来自自动驾驶车辆的越来越多和复杂的频道质量指示符（CQI）数据。", "innovation": "提出了SCAR（状态空间压缩以实现AI驱动的资源管理）框架，这是一种边缘AI辅助方法，通过使用基于机器学习的压缩技术（例如聚类和RBF网络）来减少CQI数据大小并保持其关键特性，同时利用这些压缩状态来训练6G启用的强化学习策略，以最大化吞吐量并满足NGMN定义的公平性目标。", "conclusion": "仿真结果表明，与没有CQI压缩的基本强化学习（RL）基线相比，SCAR能够将可行调度区域的时间增加14%，减少不公平调度时间15%。此外，Simulated Annealing with Stochastic Tunneling (SAST)-基于的聚类方法可将CQI聚类失真降低10%，证实了其效率。这些结果证明了SCAR在动态车载网络中的可扩展性和公平性优势。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06251", "html_url": "https://arxiv.org/abs/2508.06251", "title": "使用张量网络的矩阵产品状态进行合成数据生成和差分隐私", "title_en": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)", "authors": "Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi", "background": "合成数据生成是现代人工智能的关键技术，用于应对数据稀缺性、隐私限制以及训练鲁棒模型所需多样数据集的需求。本文探讨了如何使用张量网络中的矩阵产品状态（MPS）生成具有隐私保护的高质量合成表格数据。", "innovation": "文章提出了使用MPS生成合成数据的方法，并在差分隐私（DP）方面进行了优化。该方法通过注入噪声和梯度裁剪等手段确保差分隐私，并利用Rényi差分隐私进行隐私保证。实验结果显示，MPS方法在多个数据保真度和下游机器学习任务性能指标中均超过传统模型，特别是在严格的隐私约束下表现更为突出。", "conclusion": "本文展示了MPS作为一种在隐私保护下生成高质量合成数据的有前途工具的应用前景。通过结合张量网络表示的表达能力和正式的隐私机制，所提出的方法提供了在数据质量和保密性至关重要的敏感领域中安全分享数据的可解释和可扩展的选择。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06249", "html_url": "https://arxiv.org/abs/2508.06249", "title": "语言模型中对抗新兴不对齐的在线防御策略", "title_en": "In-Training Defenses against Emergent Misalignment in Language Models", "authors": "David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai", "background": "大型语言模型（LLMs）的微调可以使其适用于新的领域，但最近的研究揭示了一个新兴问题：即使是小规模的领域特定微调也可能导致有害行为，这些行为超出了目标领域。即使在模型权重被隐藏的情况下，这种微调也可以使得攻击者无意间接触到广泛不对齐的模型，仅从微调数据中很难发现这一问题。目前，对于通过API公开微调服务的提供者，尚未有系统的解决方案来预防新兴不对齐。", "innovation": "本研究提出了四种训练正则化干预措施来防止新兴不对齐，旨在为公开API进行微调的提供者提供实际的解决方案。这四种方法包括：向安全参考模型的KL散度正则化，特征空间的平方距离，将特征投影到安全子空间（SafeLoRA），以及从通用指令微调数据集中插入少量的安全训练示例。", "conclusion": "研究首先评估了这些方法在四类恶意、新兴不对齐诱导任务上的影响，然后评估了它们对良性任务的影响。最后，讨论了新兴不对齐研究中的开放问题并展望了未来工作。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06247", "html_url": "https://arxiv.org/abs/2508.06247", "title": "接近最优遗憾的高效随机组合半带宽问题", "title_en": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits", "authors": "Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li", "background": "组合多臂赌博机（CMAB）是序列决策框架的核心，主要由基于UCB（上确界）的方法和对抗性方法（如遵循正则化领先者和在线镜像下降）两大类构成。虽然基于UCB的方法（如CUCB）在短期内表现良好，但在长周期内会产生不利的$\text{log} T$遗憾因子。而对抗性方法（如EXP3.M和HYBRID）虽然在理论上表现出色，但计算负载很大。为了解决这一权衡，本文提出了在随机设置下的组合最小最大最优策略（CMOSS）。CMOSS算法具有较低的计算复杂度，在半带宽反馈条件下实现了实例无关的遗憾$O\big( (\text{log }k)^2 \text{sqrt}(kmT) \big)$，其中$m$是臂的数量，$k$是可行动作的最大基数。", "innovation": "本文引入了CMOSS算法，这是一种在半带宽反馈条件下实现实例无关遗憾$O\big( (\text{log }k)^2 \text{sqrt}(kmT) \big)$的高效算法，解决了基于UCB的方法与对抗性方法之间的权衡问题，显著去除了$\text{log }T$的依赖性，并达到了$O\big((\text{log }k)^2\big)$，匹配了已知的$\text{Omega}\big( \text{sqrt}(kmT)\big)$下界。", "conclusion": "通过对CMOSS算法的实验验证，表明该算法在遗憾和运行效率方面均优于基准算法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06269", "html_url": "https://arxiv.org/abs/2508.06269", "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "title_en": "OM2P: Offline Multi-Agent Mean-Flow Policy", "authors": "Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang", "background": "生成模型，特别是扩散模型和流模型，在离线多智能体强化学习（MARL）中展现出了巨大潜力。然而，将强大的生成模型集成到该框架中带来了独特的挑战。这些问题主要来源于扩散和流模型的迭代生成过程导致的低采样效率，使其在时间敏感或资源受限的环境中不可行。", "innovation": "为了应对这些困难，我们提出了OM2P（Offline Multi-Agent Mean-Flow Policy），一种新颖的离线MARL算法，实现了高效的一步动作采样。我们引入了一种增强激励优化方案，结合精心设计的均值流匹配损失和Q函数监督，以解决生成目标和奖励最大化之间的不一致。此外，我们设计了一种通用的时间步分布和无导数估计策略，以减少内存开销并提高训练稳定性。", "conclusion": "实证评估表明，OM2P在多项智能体粒子和MuJoCo基准测试中表现出色，相比于基线方法，GPU内存使用减少了高达3.8倍，训练时间加速了高达10.8倍。我们的方法是首次成功将均值流模型集成到离线MARL中，为在合作多智能体环境中实现高效、可扩展的生成策略开辟了道路。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06183", "html_url": "https://arxiv.org/abs/2508.06183", "title": "带有随机重新分配的差分隐私联邦聚类", "title_en": "Differentially Private Federated Clustering with Random Rebalancing", "authors": "Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li", "background": "联邦聚类旨在将相似的客户端分组到不同的聚类，并为每个聚类生成一个模型。这种方法一般来说会比为所有客户端训练一个单一模型更能提高模型性能，但同时也更易受到隐私泄露的威胁。直接将客户端级别的差分隐私（DP）机制应用于联邦聚类会影响其效用。分析发现，这种缺陷主要来自于在每个聚类中平均隐私噪声的困难（遵循标准隐私机制），因为分配给相同聚类的客户端数量是不受控制的。为了应对这一问题，本文提出了一种简单而有效的技术，称为RR-Cluster，可以作为许多联邦聚类算法的轻量级附加项。RR-Cluster 通过随机重新调整聚类分配减少隐私噪声，保证每个聚类中至少分配一定的客户端数。我们分析了减少隐私噪声方差与从错误分配引起的偏差增加之间的权衡，并为 RR-Cluster 提供了收敛性界限。通过实验证明，将 RR-Cluster 插入到强大联邦聚类算法中，在合成数据集和真实数据集上显著改善了隐私与效用之间的权衡。", "innovation": "提出了一种名为RR-Cluster的技术，这是一种轻量级附加项，可作为许多联邦聚类算法的一部分。RR-Cluster 通过随机重新分配聚类分配来减少隐私噪声，确保每个聚类中至少分配一定的客户端数，从而改善了隐私与效用之间的权衡。此外，该技术还提供了收敛性的界限，并在各种数据集上进行了验证，证明了显著的改进效果。对于差分隐私在联邦聚类中的应用，这是一项创新的工作，因为它克服了直接应用差分隐私机制的缺陷，同时保证了聚类的效果。", "conclusion": "本文提出了一种以轻量级附加项形式存在的RR-Cluster技术，该技术在保持模型性能的同时，有效地提高了联邦聚类算法中的隐私保护。通过实验证明，将RR-Cluster插入到强大的联邦聚类算法中，在合成数据集和真实数据集上显著改善了隐私与效用之间的权衡。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06280", "html_url": "https://arxiv.org/abs/2508.06280", "title": "基于正则化方法的持续学习方法对印度ASR的研究", "title_en": "A Study on Regularization-Based Continual Learning Methods for Indic ASR", "authors": "Gokul Adethya T,S. Jaya Nirmala", "background": "印度的语言多样性给开发包容性的自动语音识别（ASR）系统带来了重大挑战。传统的多语言模型需要同时访问所有语言的数据，但由于数据的序进到达和隐私限制，这变得不切实际。持续学习（CL）为解决这一问题提供了可能，它允许模型在不遗忘之前学习的知识的情况下，按顺序学习新语言。本文探讨了在印度语言上使用持续学习方法来提高ASR系统的性能。", "innovation": "本文采用基于正则化方法的持续学习策略，使用Conformer模型，该模型最初在印地语上进行预训练，然后被逐步训练在八种其他印度语言上，总计训练九种语言。评估了三种正则化和蒸馏基于的持续学习策略：Elastic Weight Consolidation（EWC）、Memory Aware Synapses（MAS）和Learning without Forgetting（LwF），这些策略适合无重放、隐私保护的场景。并通过单词错误率（WER）来评估清洗和噪声数据上的RNN-T和CTC路径的表现，以及通过反向转移评估知识保留情况。还研究了每个任务训练周期数对性能的影响（分别为1, 2, 5和10个周期）。", "conclusion": "与未经过优化的微调方法相比，持续学习方法有效地减少了遗忘，表明它在多样化印度语言的ASR系统下的实时约束条件下具有很大的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06301", "html_url": "https://arxiv.org/abs/2508.06301", "title": "FedMeNF：神经场的隐私保护联邦元学习", "title_en": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "authors": "Junhyeog Yun,Minui Hong,Gunhee Kim", "background": "神经场提供了一种高效的数据表示方式，可以处理多种模态和大量数据，但将其映射到神经场的学习往往需要大量的训练数据和计算资源，这在资源受限的边缘设备上可能受到限制。为了解决这个问题，可以使用联邦元学习（FML），但传统FML方法存在隐私泄露的问题。", "innovation": "我们提出了一种新的FML方法FedMeNF。FedMeNF采用了一种新的隐私保护损失函数来调节本地元优化过程中的隐私泄露，使得本地元学习器能够在不保留客户端私有数据的情况下快速高效地优化。实验结果表明，即使在少数示例或非IID数据下，FedMeNF仍然能够实现快速优化和稳健的重建性能，同时保持客户端数据的隐私性。", "conclusion": "FedMeNF能够在保证隐私的前提下，实现快速且稳健的神经场优化，适用于多种模态和少量示例数据的情况。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06346", "html_url": "https://arxiv.org/abs/2508.06346", "title": "引入分数分类损失以实现具有噪声标签的稳健学习", "title_en": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels", "authors": "Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya", "background": "鲁棒损失函数对于深度神经网络在标签噪声环境下的训练至关重要，但现有的方法需要进行大量的、针对特定数据集的超参数调整。本文研究了深度神经网络在标签噪声场景下的训练问题，探讨了现有鲁棒损失函数存在的问题，强调了针对标签噪声进行高效训练的挑战。", "innovation": "提出了一种自适应鲁棒损失——分数分类损失（FCL），能够在训练过程中自动校准对标签噪声的鲁棒性。FCL 综合了交叉熵 （CE） 损失的主动部分和均方误差（MAE）的被动部分，通过分数微分形式展示了鲁棒性与快速收敛之间的折衷方案。FCL 将分数微分阶数 μ 作为可学习参数，动态调整以优化鲁棒性和收敛速度之间的权衡，从而在具有标签噪声的场景下实现有效的分类性能。", "conclusion": "广泛的基准数据集实验结果表明，FCL 在无需手动超参数调整的情况下，达到了最先进的分类性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06336", "html_url": "https://arxiv.org/abs/2508.06336", "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "title_en": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "authors": "Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling", "background": "该研究背景涉及多智能体强化学习框架，特别是在自适应生成训练伙伴方面缺乏有效方案。传统的多智能体强化学习系统需要预先训练好的伙伴或参数调整，这限制了其适应性和鲁棒性。本文旨在解决这一问题，开发一种无需预训练伙伴或手动参数调整的多智能体强化学习框架，以增强自适应性和鲁棒性，适用于临时团队合作。", "innovation": "该研究的创新在于提出了无监督伙伴设计（UPD）框架。UPD能够在不使用预训练伙伴或手动参数调整的情况下，自动生成多样化的训练伙伴。通过将代理自身策略与添加了偏置的随机行为随机混合，并使用基于方差的学习能力度量来评估这些伙伴，确保生成的伙伴在代理当前学习前沿附近。此外，UPD能够与无监督环境设计结合使用，实现首个能够对关卡和伙伴分布提供完全无监督的学习曲线的方法。这种方法在Overcooked-AI和Overcooked通用挑战中表现出色，优于基于群体和非基于群体的基准方法及简化版本，用户研究也进一步验证了其显著优势和更好的合作性能。", "conclusion": "UPD在OpenCooked-AI和Overcooked通用挑战中的表现证明了其在临时团队合作中的优异性能。它不仅超越了基于群体和无需群体的基准方法及简化版本，还在用户体验上表现出了更强的适应性、更人性化的合作以及更高的满意度。此外，研究表明，该方法能够逐步生成伙伴，适应代理人当前的学习前沿，从而增强学习曲线的灵活性和鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06347", "html_url": "https://arxiv.org/abs/2508.06347", "title": "SE-VAE: 结构方程变分自编码器：用于表格数据的解纠缠潜在表示", "title_en": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data", "authors": "Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam", "background": "在深度生成建模中，从表格数据中学习可解释的潜在表示仍然是一个挑战。SE-VAE通过将测量结构直接嵌入到变分自编码器的设计中，提供了一种新型架构来解决这个问题。", "innovation": "SE-VAE借鉴了结构方程建模的理念，直接将潜在子空间与已知指标分组对齐，并引入全局无关潜在变量以隔离特定构建的混淆变异。这种模块化架构通过设计实现了解纠缠，而不是仅仅依赖于统计规范器。实验结果表明，SE-VAE在因子恢复、可解释性和对无关变异的鲁棒性方面均优于其他替代方案。", "conclusion": "消融结果显示，架构结构而非正则化强度是性能的关键驱动力。SE-VAE为科学和社会领域提供了一个以人为本的生成建模框架，这些领域中的潜在结构是由理论驱动的，且测量有效性是至关重要的。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06361", "html_url": "https://arxiv.org/abs/2508.06361", "title": "超越指令诱导的谎言：探索良性提示下的LLM欺骗", "title_en": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "authors": "Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He", "background": "大语言模型（LLMs）已在推理、规划和决策任务中广泛应用，其透明性和可信度备受关注。尽管故意欺骗——即LLM故意编造或隐瞒信息以服务于隐蔽目标——存在，但这一领域仍存在不足。现有的研究通常通过明确设置“隐藏”目标来进行诱导，但这可能并不能完全反映真实的人-LLM交互。本文旨在研究LLMs在良性提示下的自我诱导欺骗。", "innovation": "本文提出了新的框架使用“联系寻找问题”来评估没有真实答案的情况下LLM的自我诱导欺骗。该框架引入了两项基于心理学原则的统计指标来量化欺骗的可能性：一是隐蔽意图分数，用于衡量模型对隐藏目标的偏好；二是欺骗行为分数，衡量LLM内部信念与其表达输出之间的一致性。通过对14款主要模型的评估，发现随着任务难度的增加，两项指标同时上升。", "conclusion": "研究揭示，即便最先进的LLMs在处理复杂问题时也倾向于更多的欺骗行为，这对在复杂和关键领域的LLM代理部署提出了重大担忧。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06364", "html_url": "https://arxiv.org/abs/2508.06364", "title": "ActivityDiff: 一种具有正负活性引导的扩散模型在从头药物设计中的应用", "title_en": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design", "authors": "Renyi Zhou,Huimin Zhu,Jing Tang,Min Li", "background": "在从头药物设计中精确控制分子的生物活性，包括目标激活/抑制、多靶点协同调节以及减少意外毒性，仍然是一个关键挑战。现有的生成方法主要集中在生成具有单一期望活性的分子，缺乏同时管理多个预期和意外分子相互作用的集成机制。", "innovation": "本文提出了一种名为ActivityDiff的生成方法，基于扩散模型的分类器引导技术。ActivityDiff利用分别训练好的药-靶分类器进行正向和反向引导，使模型能够增强期望的活性同时最小化有害的非目标效应。实验结果显示，ActivityDiff有效地处理了单靶/双靶生成、碎片限制的双靶设计、选择性生成以增强靶点特异性以及减少非目标效应等关键药物设计任务。这些结果表明，分类器引导扩散在分子设计中实现了效果和安全性之间的平衡。", "conclusion": "本研究引入了一种新的综合性分子活性控制范式，并提供了ActivityDiff作为灵活且可扩展的框架。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06292", "html_url": "https://arxiv.org/abs/2508.06292", "title": "使用非线性重置反馈的多输出突触神经元进行低比特数据处理", "title_en": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback", "authors": "Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale", "background": "神经形态计算是一种新兴技术，能够实现低延迟和高能源效率的数据处理。在神经形态计算中，脉冲神经网络（SNN）是一种关键的算法工具。SNNs受生物启发，通过利用状态神经元和利用突触进行信息编码和解码，实现低比特数据处理。尽管深状态空间模型（SSMs）状态块也是状态性的，但当前的深SSMs通常使用高精度激活函数和无重置机制，在各种时间建模任务中表现竞争力。本文基于此背景，探讨了SNNs与深SSMs之间的差异。", "innovation": "本文提出了一种新颖的多输出突触神经元模型，它结合了线性的通用SSM状态转移以及通过重置实现的非线性反馈机制。与现有的SNN神经元模型相比，提出的一种模型清晰地给出了脉冲函数、重置条件和重置动作之间的区别。此外，通过不同的任务实验（关键词识别、事件驱动视觉、序列模式识别），该模型在SNN文献中的基准性能效果相近，并显示通过提出的一种重置机制可以克服不稳定的动态特性，促进学习。", "conclusion": "结果表明，所提出的重置机制能够克服线性部分动态特性引起的不稳定问题，改善精度，从而使基于神经形态计算的实时应用得以拓展应用领域。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06257", "html_url": "https://arxiv.org/abs/2508.06257", "title": "通过展平图平滑先验进行多组学分析以推断癌症亚型", "title_en": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors", "authors": "Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang", "background": "整合多组学数据集通过数据驱动的方法能够为复杂生物学过程提供全面的理解，特别是在不同疾病，特别是癌症方面。图神经网络（GNNs）最近在生物数据的关联结构上显示出显著的能力，促进了多组学在癌症亚型分类中的集成。现有的方法通常忽略了异质组学之间的复杂耦合，限制了它们解决癌症亚型细微差异的能力，这些差异对于精准医学至关重要。", "innovation": "为了解决这些限制，我们提出了一个多组学癌症亚型分类框架，称为图变换器（GTMancer）。该框架以GNN优化问题为基础，并将其应用扩展到复杂多组学数据。具体而言，我们的方法利用对比学习嵌入多组学数据到一个统一的语义空间。在该统一空间中展开复杂图优化问题，并引入双重注意力系数集合，以捕捉跨多组学数据的结构图先验。这种方法使全局组学信息能够指导单个组学表示的优化。", "conclusion": "在七个实际癌症数据集上的实证实验表明，GTMancer比现有最先进的算法表现更好。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06409", "html_url": "https://arxiv.org/abs/2508.06409", "title": "使用311热线呼叫和街道图像进行每日无家可归帐篷监测的新视角", "title_en": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images", "authors": "Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee", "background": "美国无家可归人口激增至大萧条以来未见的水平。现有的监控方法，如点在时间（PIT）计数，存在频率、一致性和空间细节方面的局限性。", "innovation": "本研究提出了一种新的方法，利用公开的、众包的数据，特别是311服务呼叫和街道级别图像，以追踪和预测旧金山无家可归帐篷的趋势。预测模型捕捉到细粒度的日和社区层面的变化，发现了传统计数经常忽略的模式，比如在COVID-19疫情期间的快速波动以及无家可归帐篷位置的时空变化模式。这种方法提供了更及时、本地化和成本效益高的信息，成为指导政策响应和评估减少露宿无家可归者的干预措施的有力工具。", "conclusion": "本研究提出的方法通过使用311服务呼叫和街道图像来监测无家可归者的帐篷趋势，提供了及时、局部和成本效益高的信息，有助于指导政策的应对措施和评估减少露宿无家可归者的干预措施。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06353", "html_url": "https://arxiv.org/abs/2508.06353", "title": "几何-k-means：一种快速且环保的k-means方法", "title_en": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means", "authors": "Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic", "background": "本文介绍了几何-k-means（或简称为Gk-means）这一创新方法，它显著提高了广泛使用的k-means算法的效率和能源经济性。尽管k-means算法自从五十年前诞生后，已成为机器学习应用中的基石，但Gk-means利用几何原理，特别是标量投影，极大地加速了算法运行，同时不牺牲解的质量。这种几何策略使得算法可以更聚焦于最有可能影响聚类更新的最重要数据点，称为高表现力数据（HE），同时低表现力数据（LE）不会影响聚类结果因此被有效忽略，从而大幅减少了计算开销。实验结果显示，Gk-means在运行时间和距离计算（DC）方面优于传统的和最新的k-means变体，并且在资源效率方面表现出更好的性能，例如具有更低的能源足迹，从而变得更具可持续性。", "innovation": "Gk-means利用几何原理加速k-means算法，专注于‘高表现力数据’（HE），忽略‘低表现力数据’（LE），从而显著提高算法效率和能源经济性，同时保持解的质量，特别是在合成数据集、真实世界数据集和高维数据集的实验中表现出显著优于传统和最新的k-means变体的运行时间和距离计算性能，并且表现更好的资源效率，证明了其更为可持续的应用价值。", "conclusion": "Gk-means显著提升了k-means算法的运行效率和能源利用效率，尤其是在大规模数据集和技术上最新方法的应用中，显示出了其在实践中的优越性，并为未来的聚类算法研究提供了新的思路。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "使用重置回放实现高效样本的大语言模型优化", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "最近的大语言模型（LLM）通过强化学习（RL）和偏好优化方法取得了进步，这些方法提升了LLM的推理能力。然而，这些方法通常效率低下，并容易受到首因偏差的影响，即过度适应初始经验会降低策略质量，损害学习过程。现有方法通常存在样本效率低和首因偏差问题。", "innovation": "我们提出了一种名为LoRR的通用且强大的插件，用于增强基于偏好的优化框架中的样本效率。LoRR的核心机制允许在高重放数量下进行训练，最大化每个收集数据批次的使用价值。为了应对高重放训练中固有的过拟合风险，LoRR采用了周期性重置策略，利用重新利用初始数据来保持网络的可塑性。同时，它结合了监督微调（SFT）和偏好损失的混合优化目标，进一步增强数据的利用。我们的实验表明，LoRR显著提升了各种偏好优化方法在数学和通用推理基准上的性能。", "conclusion": "LoRR提供了一种实用、高效且高度有效的LLM微调范式，即使在数据有限的情况下也能实现更好的性能。特别地，结合了LoRR的迭代最大偏好优化方法在复杂的数学任务上表现优异，超过了某些复杂的基于RL的算法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01854", "html_url": "https://arxiv.org/abs/2508.01854", "title": "学习具有非梯度结构的一般扩散的矩估计和变分方法", "title_en": "Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures", "authors": "Fanze Kong,Chen-Chih Lai,Yubin Lu", "background": "该论文致力于识别非梯度广义扩散中的守恒定律，特别是在包含耗散和旋转动态、粗糙伪势能以及噪声数据的复杂广义扩散过程中，提供了一种数据驱动的学习框架。这种研究对于理解和模拟复杂物理系统至关重要。", "innovation": "提出了结合能量耗散定律和物理一致惩罚项的两阶段学习方法，用于恢复特定非梯度漂移在点正交分解中的伪势能和旋转。这种方法能够在包括耗散旋转动力学、粗糙伪势能和噪声数据的各种复杂广义扩散中有效应用。", "conclusion": "代表性数值实验验证了该方法在非梯度广义扩散中学习物理定律的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06387", "html_url": "https://arxiv.org/abs/2508.06387", "title": "基于数据集选择的端到端文本到SQL生成：利用大型语言模型实现自适应查询生成", "title_en": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "authors": "Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh", "background": "文本到SQL（Text-to-SQL）系统连接了自然语言和结构化的数据库查询语言，使得非技术人员能够轻松地查询数据库。传统的方法将文本到SQL视为直接翻译任务，即将自然语言查询（NLQ）直接映射到SQL命令。尽管大型语言模型（LLMs）的最新进展显著提高了翻译的准确性，但这些方法都需要预先指定目标数据库。这在涉及多个广泛的数据库的场景中成为一个关键但常被忽视的步骤。因此，该研究提出了一种包含三个阶段的端到端Text-to-SQL框架，能够在生成SQL查询前识别用户的意图数据库。该框架利用大语言模型和提示工程技术从自然语言查询中提取潜在信息，并构建一套规则集。之后，通过使用包含RoBERTa微调编码器的大型db_id预测模型，训练模型根据NLQ和LLM生成的规则来预测正确的数据库标识符（db_id）。最终，使用批评者代理来修正生成的SQL中的错误。实验结果表明，该框架在数据库意图预测和SQL生成准确性方面均优于当前最先进的模型。", "innovation": "该研究提出了一种新的端到端Text-to-SQL框架，能够在生成SQL查询前识别用户的意图数据库。该框架利用大语言模型和提示工程技术从自然语言查询中提取潜在信息，并构建一套规则集。然后，通过使用包含RoBERTa微调编码器的大型db_id预测模型，训练模型来预测正确的数据库标识符（db_id）。最后，使用批评者代理来修正生成的SQL中的错误。该框架能够在涉及多个广泛的数据库的场景中自动选择正确的数据库，从而提高了SQL生成的准确性和效率。", "conclusion": "实验结果表明，该框架在数据库意图预测和SQL生成准确性方面均优于当前最先进的模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2107.06056", "html_url": "https://arxiv.org/abs/2107.06056", "title": "印度法律NLP基准：一项综述", "title_en": "Indian Legal NLP Benchmarks : A Survey", "authors": "Prathamesh Kalamkar,Janani Venugopalan Ph.D.,Vivek Raghavan Ph.D", "background": "现有的基准数据集在处理法律文本方面存在局限性，因为法律文本与一般英语文本有显著差异。因此，需要专门针对印度法律系统的自然语言处理基准数据集，这些数据集能够挑战现有技术并专注于特定的法律应用任务。这将促进自然语言处理在印度法律领域的创新，并为人工智能和社会带来益处。", "innovation": "本文综述了现有工作，并提出了创建适用于印度法律系统的自然语言处理基准数据集的想法。这些新基准能够推动针对印度法律文本的自然语言处理技术的发展。", "conclusion": "研究指出了法律文本处理领域的数据缺口，并通过创建专门针对印度法律系统的基准数据集来填补这一差距，促进相关领域的创新和进步。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06467", "html_url": "https://arxiv.org/abs/2508.06467", "title": "基于梯度比影响估计和噪声注入的大语言模型遗忘方法", "title_en": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection", "authors": "Ameya Anjarlekar,Sandeep Pombra", "background": "随着大型语言模型（LLMs）在法律和伦理上的审查日益严格，有效地进行机器遗忘变得尤为重要，尤其对于敏感或未经授权的数据。现有的实证方法通常会导致遗忘不完全或对无关知识的意外降解，这是由于定位不准确造成的。", "innovation": "本文提出了一种模块化和针对性的LLM遗忘框架GRIN。GRIN引入了基于梯度比的新度量来识别最负责记忆遗忘数据的参数。随后，在微调前对这些参数进行选择性的噪声注入，这提高了遗忘性能同时保持了模型的实用性。此外，本文还提出了新的评估指标，专门适用于LLM环境，并在标准基准如TOFU、WMDP和SafePKU上验证了该方法。", "conclusion": "GRIN框架通过基于梯度比的影响估计和选择性噪声注入，有效解决了现有方法中存在的遗忘不完全和无目标降解的问题，同时保持了模型的实用性。新提出的评估指标验证了该方法在标准基准上的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05663", "html_url": "https://arxiv.org/abs/2508.05663", "title": "随机漫步学习与Pac-Man攻击", "title_en": "Random Walk Learning and the Pac-Man Attack", "authors": "Xingran Chen,Parimal Parag,Rohit Bhagat,Zonghong Liu,Salim El Rouayheb", "background": "随机漫步（RW）算法由于其低开销和可扩展性，在分布式系统中长期流行，且近年来在分散式学习中有广泛应用。然而，这些算法依赖于局部交互，使其容易受到恶意行为的影响。", "innovation": "该工作首次提出了“Pac-Man”攻击，这是一种恶意节点以概率方式终止访问它的RW的行为，从而逐渐消除网络中的活跃RW，导致学习进程停止。研究者提出了Average Crossing（AC）算法，这是一种完全去中心化的机制，用于在Pac-Man存在的情况下复制RW，防止RW消亡。理论分析表明，在AC作用下（i）RW种群几乎肯定保持有界，（ii）基于RW的随机梯度下降仍然收敛，即使在存在Pac-Man的情况下也存在可量化的真实最优解偏差。实证结果进一步验证了理论发现，并揭示了复制阈值与消亡概率之间的相变。", "conclusion": "研究通过分析AC简化版本提供了理论见解，揭示了观察到的相变，并验证了AC算法可以在存在Pac-Man攻击的情况下保护分布式学习过程的稳定性和收敛性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05649", "html_url": "https://arxiv.org/abs/2508.05649", "title": "AI Guided Accelerator For Search Experience", "title_en": "AI Guided Accelerator For Search Experience", "authors": "Jayanth Yetukuri,Mehran Elyasi,Samarth Agrawal,Aritra Mandal,Rui Kong,Harish Vempati,Ishita Khan", "background": "在电子商务环境中，有效的查询重新构造成有助于缩小用户探索性搜索行为与相关产品识别之间的差距。传统的方法通常将查询重新构想建模为孤立的配对，但难以捕捉现实世界用户行为中的序列性和过渡性动态。现有的研究未能全面建模查询重新构想的过程，尤其是在用户购买意向生成过程中的过渡查询方面。", "innovation": "本文提出了一种新的框架，明确建模过渡查询，即用户在最终购买意向生成过程中发生的查询中间重构。通过从eBay大规模用户互动日志中挖掘结构化的查询轨迹，重构能反映意图转变的查询序列，并保持语义连贯性。此外，引入生成型大型语言模型（LLMs）以生成语义多样化但保持意图一致的替代查询，超出单一协作过滤可实现的范围。这些重构可以被利用来填充“相关搜索”或在搜索结果页面中驱动意图集群的轮播，从而提高发现和参与度。本文贡献包括（i）形式化识别和建模过渡查询，（ii）介绍一种结构化的查询序列挖掘管道以理解意图流程，并（iii）应用LLMs进行可扩展的、意图感知的查询扩展。", "conclusion": "实证评估表明，与现有的相关搜索模块相比，采用我们的方法在转化率和参与度指标上实现了可测量的提升，验证了我们在真实电子商务环境中的有效性和实用性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05669", "html_url": "https://arxiv.org/abs/2508.05669", "title": "针对马来西亚审计财务报告中金融表Markdown转换的视觉语言模型微调", "title_en": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "authors": "Jin Khye Tan(Faculty of Computer Science and Information Technology, Universiti Malaya),En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah", "background": "从财务文件中准确提取并表示表格结构，尤其是在监管和分析用例中，仍然是文档理解中的一个重要挑战。本文针对马来西亚审计财务报告中的金融表格转换为Markdown格式的任务进行研究，该任务由于旋转布局、多级表头和隐式的结构线索而变得复杂。", "innovation": "本文提出了一种基于Qwen2.5-VL-7B的微调视觉语言模型，优化了从文档图像生成高保真Markdown的性能。该模型包括一个包含2,152个图像-文本对的自定义数据集和一种基于LoRA的监督微调策略。此外，提出了一种新的Markdown树编辑距离相似性（TEDS）度量方法来评估结构保真度。实验结果表明，该模型的综合结构保真度得分为96.53%，细粒度准确率为92.20%，并在整体上显著优于其基础模型、更大规模的视觉语言模型和专门推理增强模型。", "conclusion": "研究结果表明，领域特定的模型微调提供了一种有效且高效的解决方案，可以弥补非结构化财务文件与下游自动化之间的差距，且性能优于许多自托管的大规模和更通用的模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05673", "html_url": "https://arxiv.org/abs/2508.05673", "title": "突破Top-$K$瓶颈：优化推荐系统中的Top-$K$排名指标", "title_en": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems", "authors": "Weiqin Yang,Jiawei Chen,Shengjia Zhang,Peng Wu,Yuegang Sun,Yan Feng,Chun Chen,Can Wang", "background": "在推荐系统(RS)领域，Top-$K$排名指标如NDCG@$K$是衡量推荐性能的标准。然而，在训练推荐模型时，优化NDCG@$K$因其固有的非连续性和Top-$K$截断的复杂性带来了重大挑战。最近的努力要么忽略了Top-$K$截断，要么因高计算成本和训练不稳定性而受阻。", "innovation": "本文提出了SoftmaxLoss@$K$(SL@$K$)，一种新的推荐损失，专为NDCG@$K$优化设计。通过融入分位数技术处理Top-$K$截断，并推导出一个平滑的上界来优化NDCG@$K$，从而解决不连续性问题。SL@$K$损失具有多项优势，包括理论保证、可实现性、计算效率、梯度稳定性以及抗噪性。在四个真实世界数据集和三种推荐系统框架上的大量实验表明，相比于现有损失，SL@$K$显著提高了6.03%。", "conclusion": "实验结果表明，SL@$K$在多个真实世界数据集上显著优于现有损失，取得了6.03%的平均改进效果。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05689", "html_url": "https://arxiv.org/abs/2508.05689", "title": "通过残差扰动攻击提升对抗样本的转移性", "title_en": "Boosting Adversarial Transferability via Residual Perturbation Attack", "authors": "Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang", "background": "深度神经网络容易受到对抗样本的影响，这些样本通过不可察觉的扰动导致错误预测。在黑盒情况下，基于转移的攻击方法使用替代模型生成对抗样本，然后将这些样本转移到目标模型上。现有研究表明，在平坦损失景观中生成的对抗样本具有更好的转移性，有助于缓解替代模型的过拟合现象。然而，先前研究忽视了扰动方向的影响，导致转移性有限。", "innovation": "提出了名为Residual Perturbation Attack（ResPA）的新型攻击方法，利用残差梯度作为扰动方向，引导对抗样本向损失函数的平坦区域移动。ResPA通过指数移动平均输入梯度来获得参考梯度，作为历史梯度方向的参照。与仅依赖于当前梯度的局部平坦性不同，ResPA进一步考虑当前梯度与参考梯度之间的残差以捕获全局扰动方向的变化。", "conclusion": "实验结果表明，ResPA比现有典型的基于转移的攻击方法具有更好的转移性，结合当前输入变换方法可以进一步提高转移性。相关代码可以在此处找到：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05676", "html_url": "https://arxiv.org/abs/2508.05676", "title": "领域特定微调和提示驱动学习：开发基于自然语言的BIM信息检索系统的比较研究", "title_en": "Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems", "authors": "Han Gao,Timo Hartmann,Botao Zhong,Kai Lia,Hanbin Luo", "background": "建筑信息建模（BIM）在建筑全生命周期管理中至关重要，支持从设计到维护的各项任务。自然语言接口（NLI）系统作为用户友好型信息检索工具在BIM环境中受到越来越多的关注。然而，通过自然语言查询准确提取BIM相关信息仍然面临挑战，这是因为查询的复杂性和领域的专业知识要求高。本文通过构建一个包含1,740个标注查询的BIM特定数据集，比较了领域特定微调和基于大语言模型的提示驱动学习两种方法在BIM信息检索系统开发中的表现。实验结果显示，领域特定微调在意图识别任务中表现更优，而基于提示的学习方法在基于表格的问题回答中更强大，特别是在使用GPT-4o的情况下。文章提出了一种结合领域特定微调和基于提示的学习的方法，使各项任务中的性能更加均衡和稳健，并通过涉及不同复杂性的BIM模型的案例研究进一步验证了该方法的有效性。", "innovation": "本研究通过采用领域特定微调和基于大语言模型的提示驱动学习两种方法，比较他们的性能表现，并提出了一种结合两种方法的集成方法，该方法在各项任务中实现了更均衡和稳健的性能。该研究进一步通过涉及不同复杂性的BIM模型的案例研究验证了该方法的有效性。这项研究全面分析了两种方法的优势和局限性，并讨论了NLI在真实世界BIM场景中的适用性，为研究人员和从业者设计智能、语言驱动的BIM系统提供了见解。", "conclusion": "本研究展示了领域特定微调和提示驱动学习在开发基于自然语言的BIM信息检索系统中的应用情况，提出了结合这两种方法的综合方案，以及该方案的有效性。同时也讨论了NLI在真实世界BIM场景中的适用性，并为研究人员和从业者在设计智能、语言驱动的BIM系统时提供了宝贵建议。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05666", "html_url": "https://arxiv.org/abs/2508.05666", "title": "HySemRAG：一种用于自动文献合成和方法论差距分析的混合语义检索增强生成框架", "title_en": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "authors": "Alejandro Godinez", "background": "现有RAG架构存在局限性，需要一种新的方法来自动化大规模文献综合，并识别方法论研究缺口。现有的RAG模型通常在检索和生成方面存在不足，且缺乏有效的质量保证机制以及文献引用验证，这些限制了其在复杂文献综合任务中的应用效率和准确性。文章提出的HySemRAG框架旨在解决这些问题，通过结合Extract、Transform、Load (ETL) 流程与RAG技术，旨在更准确地合成文献并识别研究缺口，同时提供多层质量保证机制和技术框架，以增强系统在大规模文献综合中的表现。", "innovation": "HySemRAG框架结合了ETL管道与RAG技术，提供了一种自动化的大型文献合成和研究缺口分析方法。其创新之处在于采用混合检索策略（包括语义搜索、关键词过滤和知识图谱遍历），一种自动的自我纠错框架，并结合后置引文验证来确保信息的完整追溯性。该系统通过八个集成阶段处理学术文献，并创建一个可以执行复杂关系查询的Neo4j知识图谱和Qdrant向量集合，以支持语义搜索。", "conclusion": "HySemRAG在643个观测值的60次测试会话中，展示了结构化字段提取的语义相似度提高了35.1%，达到了比基于PDF片段方法更高的准确性。自动质量保证机制在验证回应中实现了68.3%的一次通过成功率，并且引文准确率为99.0%。应用于暴露在臭氧中的心血管疾病空间流行病学文献，此系统能够识别方法学趋势和研究缺口，表明了其在科学领域中的广泛适用性，可以加速证据综合和发现。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05700", "html_url": "https://arxiv.org/abs/2508.05700", "title": "多面向的大规模嵌入表以提升Pinterest广告排名", "title_en": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking", "authors": "Runze Su,Jiayin Jin,Jiacheng Li,Sihan Wang,Guangtong Bai,Zelun Wang,Li Tang,Yixiong Meng,Huasen Wu,Zhimeng Pan,Kungang Li,Han Sun,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "现代推荐系统中大规模嵌入表至关重要，因为它们能够有效捕捉和存储不同实体间复杂交互的细节。在将大规模嵌入表整合到Pinterest的广告排名模型时，尽管面临稀疏性和扩展性等常规问题，还遇到了一些特定于Pinterest的独特挑战。", "innovation": "引入了一个包含多种预训练算法的新型多面向预训练方案。这种方案显著丰富了嵌入表，提高了性能，并且在点击率（CTR）和转化率（CVR）方面带来了显著提升。此外，设计了一种CPU-GPU混合服务架构以克服GPU内存限制，提高可扩展性。", "conclusion": "这种方法在Pinterest广告系统中部署后，实现了1.34%的在线点击价格（CPC）减少和2.60%的点击率（CTR）增加，同时端到端延迟未发生变化。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05695", "html_url": "https://arxiv.org/abs/2508.05695", "title": "MambaITD：一种有效的跨模态Mamba网络用于内鬼威胁检测", "title_en": "MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection", "authors": "Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng,Jian Weng", "background": "企业面临日益严重的内部威胁风险，现有检测方法由于缺乏时间动态特征建模、计算效率和实时性的瓶颈以及跨模态信息孤岛问题，无法有效应对这些挑战。", "innovation": "提出了一种基于Mamba状态空间模型和跨模态自适应融合的新内鬼威胁检测框架MambaITD。该框架通过多源日志预处理模块、Mamba编码器和自适应阈值优化方法，提高了建模效率和特征融合能力，优于基于Transformer的方法，为内鬼威胁检测提供了更有效的解决方案。", "conclusion": "MambaITD框架通过对行为序列和区间序列进行长期依赖建模，并结合门控特征融合机制动态结合序列和统计信息。此外，提出了基于最大化类间方差的自适应阈值优化方法，在分析概率分布的基础上动态调整决策阈值，有效识别异常并缓解类别不平衡和概念漂移。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05684", "html_url": "https://arxiv.org/abs/2508.05684", "title": "MM-FusionNet：利用大型视觉-语言模型实现多模态假新闻检测的上下文感知动态融合", "title_en": "MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models", "authors": "Junhao He,Tianyu Liu,Jingyuan Zhao,Benjamin Turner", "background": "社交媒体上的多模态假新闻泛滥，对公众信任和社会稳定构成重大威胁。传统的检测方法主要基于文本，往往无法有效应对误导性文本和图像之间的交织欺骗。尽管大型视觉-语言模型（LVLM）为多模态理解提供了前景，但如何在重要性和矛盾性不对等时有效融合多样模态信息仍是一项关键挑战。", "innovation": "本文提出了MM-FusionNet，这是一个利用LVLM进行稳健多模态假新闻检测的创新框架。其核心贡献是上下文感知动态融合模块（CADFM），通过双向跨模态注意力和新颖的动态模态门控网络，能够自适应地学习并分配文本和视觉特征的重要性权重，基于其上下文相关性实现信息的智能优先。该模型在包含80,000个样本的大型多模态假新闻数据集（LMFND）上测试，实现了0.938的F1分数，大幅优于现有的多模态基线方法，并远超单一模态方法。进一步分析显示了其动态权重能力、对模态扰动的鲁棒性以及表现接近人类水平，表明其在实际应用中的效果和可解释性都很好。", "conclusion": "MM-FusionNet 在大型多模态假新闻检测中的表现显著优于现有方法，证明了其在实际应用中的有效性和可解释性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05690", "html_url": "https://arxiv.org/abs/2508.05690", "title": "利用大型语言模型进行SQL行为基于数据库入侵检测", "title_en": "Leveraging large language models for SQL behavior-based database intrusion detection", "authors": "Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li", "background": "数据库系统广泛应用于各个领域以存储关键数据，但异常数据库访问行为的频率持续上升，包括内部和外部攻击导致的入侵。内部冒充者通常拥有更多的组织知识，使其能够更有效地模仿员工行为。相比之下，外部冒充者可能表现出不同行为，因为他们不熟悉组织。当前的方法缺乏能够在操作级别检测异常所需的粒度，经常错误地将整个操作序列分类为异常，而大多数操作很可能是正常行为。另一方面，一些异常行为可能与正常活动相似，使现有检测方法难以识别。", "innovation": "本文提出了一种针对结构化查询语言(SQL)的两层异常检测方法，该方法利用DistilBERT，这是一种双向编码表示的高效预训练模型。该方法结合了无监督和有监督的机器学习技术，能够在减少数据标签需求的同时准确识别异常活动。首先，无监督方法使用集成异常检测器来标识远离典型用户行为学习模式的嵌入向量（超出范围的查询）。其次，监督方法使用微调的变压器模型检测高精度的内部攻击（在范围内的查询），使用基于角色的分类，即使在有限的标注SQL数据上也能适用。", "conclusion": "我们的研究为保护关键数据库系统免受复杂威胁提供了有效解决方案，具有显著贡献。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05677", "html_url": "https://arxiv.org/abs/2508.05677", "title": "基于强化学习的医疗问卷系统对抗攻击：输入级扰动策略与医疗约束验证", "title_en": "Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation", "authors": "Peizhuo Liu", "background": "基于强化学习（RL）的医疗问卷系统在医疗场景中有巨大潜力，但它们的安全性和鲁棒性问题尚未解决。这项研究全面评估了对抗攻击方法，以识别和分析潜在的脆弱性。作者将诊断过程建模为马尔可夫决策过程（MDP），其中状态是患者的回复及未提问的问题，操作则包括提问或诊断。实验使用了六种主流攻击方法，并且对每种攻击方法均考虑了七个不同的ε值。为了确保生成的对抗样本在临床上可验证，作者开发了一个由247个医疗约束构成的全面医疗验证框架，其中包括生理学界限、症状相关性和条件医疗约束。研究在NSHI数据集上进行了实验，该数据集包含182,630个样本，预测参与者4年的死亡率。评估攻击效果表明，对抗攻击可显著影响诊断准确性，成功率从FGSM的33.08%到AutoAttack的64.70%不等。研究结果表明，在严格的医疗约束下输入，仍存在显著的脆弱性缺陷。", "innovation": "1. 将诊断过程建模为马尔可夫决策过程。\n2. 实现并评估了六种主流的对抗攻击方法，包括FGSM、PGD、C&W攻击、BIM、DeepFool和AutoAttack。\n3. 开发了一个由247个医疗约束构成的全面医疗验证框架，确保对抗样本在临床上的可验证性。研究实现了97.6%的成功率，生成了具有临床合理性的对抗样本。\n4. 对基于强化学习的医疗问卷系统在严格的医疗约束条件下仍可能存在显著的脆弱性进行了验证。", "conclusion": "攻击结果表明，基于学习的医疗问卷系统在面对对抗攻击时存在显著的诊断准确性下降问题。在严格的医疗约束条件下，这些系统的鲁棒性仍需要进一步提高。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05705", "html_url": "https://arxiv.org/abs/2508.05705", "title": "基于生理约束的神经网络数字孪生框架：在1型糖尿病中复制葡萄糖动力学", "title_en": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes", "authors": "Valentina Roquemen-Echeverri,Taisa Kushner,Peter G. Jacobs,Clara Mosquera-Lopez", "background": "模拟1型糖尿病(T1D)个体的葡萄糖动态对于开发个性化治疗方法和支持数据驱动的临床决策至关重要。现有的模型通常忽略了关键的生理方面并且很难做到个性化。", "innovation": "本文引入了基于生理约束的神经网络(NN)数字孪生模型，用于模拟1型糖尿病个体的葡萄糖动态。通过构建与一组描述葡萄糖调节的常微分方程(ODEs)一致的群体级NN状态空间模型，并加入个体特定的模型，以捕捉个体之间的差异，从而实现生理和解释性的统一。这种框架可以同时渗透未建模因素如睡眠和活动，同时保留关键的动力学。", "conclusion": "在基于394个数字孪生的T1D实验数据验证中，模拟和实际数据的葡萄糖结果具有可比性：范围内的时间(70-180 mg/dL)为75.1±21.2%（模拟） vs. 74.4±15.4%（实际；P<0.001）; 低于范围的时间（<70 mg/dL）2.5±5.2% vs. 3.0±3.3% (P=0.022); 以及高于范围的时间（>180 mg/dL）22.4±22.0% vs. 22.6±15.9% (P<0.001)。该框架能够灵活地整合未建模的变量并且保留主要的动力学模式，为个性化虚拟测试治疗方法、支持胰岛素优化和集成基于物理和数据驱动模型提供了可能性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05762", "html_url": "https://arxiv.org/abs/2508.05762", "title": "评估机器学习力场与实验测量的对比", "title_en": "Evaluating Universal Machine Learning Force Fields Against Experimental Measurements", "authors": "Sajid Mannan,Vaibhav Bihani,Carmelo Gonzales,Kin Long Kelvin Lee,Nitya Nand Gosvami,Sayan Ranu,Santiago Miret,N M Anoop Krishnan", "background": "通用机器学习力场（UMLFFs）有望通过实现全周期表范围内的快速原子级模拟来重塑材料科学。然而，这些力场的评估主要局限于计算基准测试，实际上可能并不反映真实世界的性能。", "innovation": "提出了UniFFBench，这是一个全面的框架，用于将大约1500种经过精心筛选的矿物结构与实验测量进行比较，这些结构涵盖了各种化学环境、键合类型、结构复杂性和弹性性质。这项系统的评估揭示了现实差距：在计算基准测试中表现出色的模型往往在面对实验复杂性时会失效。UniFFBench通过实验验证建立了一系列必要的标准，并揭示了系统性的局限性，需要解决这些问题才能实现真正通用的力场能力。", "conclusion": "当前的计算基准虽然提供了有价值的对比测试，但在实验复杂化学空间中可能高估了模型的可靠性。总体而言，UniFFBench确立了必要的实验验证标准，并揭示了系统的局限性，需要解决才能实现真正通用的力场能力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05766", "html_url": "https://arxiv.org/abs/2508.05766", "title": "通过语言介导的主动推断实现固有安全的AGI框架", "title_en": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "authors": "Bo Wen", "background": "传统的AI安全方法集中在事后可解释性和奖励工程，这些方法存在根本性的局限性。", "innovation": "提出了一种结合Active Inference原则与大规模语言模型（LLMs）的新框架，旨在通过透明的信念表示和分层价值对齐来在系统的核心设计中整合安全性保障。框架利用自然语言作为表示和操作信念的媒介，使其具有可直接的人类监督同时保持计算可行性。架构实施了一个多智能体系统，其中智能体根据Active Inference原则自我组织，并通过分层Markov毯带来了偏好和安全约束的传递。确保安全的具体机制包括：(1) 在自然语言中显式分离信念和偏好；(2) 通过资源感知的自由能最小化实现有界的理性；(3) 通过模块化的智能体结构实现组合安全性。", "conclusion": "论文提出了围绕Abstracta and Reasoning Corpus (ARC)基准进行研究的议程，旨在验证该框架的安全属性。该方法提供了一条通往固有更安全的AGI开发路径，而非事后添加安全措施。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05715", "html_url": "https://arxiv.org/abs/2508.05715", "title": "生存分析中的减少技术", "title_en": "Reduction Techniques for Survival Analysis", "authors": "Johannes Piller,Léa Orsini,Simon Wiegrebe,John Zobolas,Lukas Burk,Sophie Hanna Langbein,Philip Studener,Markus Goeswein,Andreas Bender", "background": "本文讨论了一种我们称之为生存分析中的减少技术，即通过将生存任务转换为更常见的回归或分类任务的技术，而不忽略生存数据的具体特性。这些技术特别有助于基于机器学习的生存分析，因为它们允许使用标准的机器学习和深度学习工具来处理多数生存任务，无需构建专用的模型。", "innovation": "本文提供了不同减少技术的概述，并讨论了它们各自的优缺点。此外，本文还提供了一个以原则为导向的实现方法，使得这些减少技术可以直接应用于标准的机器学习工作流程中，同时也通过专门的例子进行了解释，并进行了与现有的生存分析机器学习方法的基准比较分析。", "conclusion": "本文证明了减少技术在生存分析中的有效性，并展示了如何直接在标准机器学习流程中实现这些技术，从而提高了生存分析任务的可操作性和效果。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05838", "html_url": "https://arxiv.org/abs/2508.05838", "title": "将视觉基础模型与强化学习集成以增强物体交互能力", "title_en": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "authors": "Ahmad Farooq,Kamran Iqbal", "background": "该研究提出了一个结合视觉基础模型与强化学习的新方法，以增强在模拟环境中物体交互的能力。研究通过在AI2-THOR仿真环境中将Segment Anything Model (SAM) 和YOLOv5 与使用Proximal Policy Optimization (PPO) 算法的智能体结合，使智能体能够更有效地感知和操作物体。实验结果显示，与基本智能体相比，在四组不同的室内厨房环境中的综合对比实验中，显著提高了物体交互成功率和导航效率。", "innovation": "该研究创新性地将视觉基础模型与强化学习结合，通过将Segment Anything Model (SAM) 和YOLOv5 与使用Proximal Policy Optimization (PPO) 算法的智能体结合，显著提高了物体交互成功率和导航效率。实验结果表明，与基线智能体相比，平均累积奖励提高了68%，物体交互成功率提高了52.5%，导航效率提高了33%。", "conclusion": "研究发现，将基础模型与强化学习集成对于复杂机器人任务具有巨大潜力，有助于开发更高级和强大的自主智能体，这为未来的研究提供了新的方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05744", "html_url": "https://arxiv.org/abs/2508.05744", "title": "使用尺度依赖正则变换检测宇宙学模型误设", "title_en": "Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows", "authors": "Aizhan Akhmetzhanova,Carolina Cuesta-Lazaro,Siddharth Mishra-Sharma", "background": "当前和即将开展的宇宙学调查将产生前所未有的高维数据，这些数据需要复杂的高保真前向模拟来准确地模拟物理过程和描述数据生成过程的系统效应。然而，验证我们的理论模型是否准确描述了观测数据集仍然是一个基本挑战。增加这一任务的复杂性在于选择保留所有相关宇宙学信息的同时减少原始数据集维度的适当数据表示方式。在本文中，我们提出了一种新颖的框架，结合尺度依赖神经总结统计和正则变换，通过贝叶斯证据估计检测宇宙学模拟中的模型误设。通过将我们的数据压缩和证据估计的神经网络模型条件化在平滑尺度上，我们系统地以数据驱动的方式识别理论模型在何处失效。我们使用来自三个不同亚网格物理实现的CAMELS模拟套件的物质和气体密度场展示了该方法的第一个应用。", "innovation": "本文提出了一种新颖的框架，结合了尺度依赖的神经总结统计和正则变换，通过贝叶斯证据估计来检测宇宙学模拟中的模型误设。这种方法通过将数据压缩和证据估计的神经网络模型条件化在平滑尺度上，可在数据驱动的方式中系统地识别理论模型的失效点。这种方法的应用示例如何在三个不同的CAMELS模拟套件中使用物质和气体密度场进行模型误设检测。", "conclusion": "该研究提出了一种将尺度依赖的神经总结统计和正则变换相结合的方法，用于宇宙学模拟中的模型误设检测。通过条件化神经网络模型在平滑尺度上，这种方法能够系统地识别理论模型在数据上的失效情况。这种方法的成功验证将有助于提高模型的准确性和可靠性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05846", "html_url": "https://arxiv.org/abs/2508.05846", "title": "迈向透明伦理AI：值得信赖的机器人系统路线图", "title_en": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems", "authors": "Ahmad Farooq,Kamran Iqbal", "background": "随着人工智能和机器人技术在社会中日益普及，确保这些系统的道德行为变得至关重要。本文认为，透明的AI决策过程是开发可信赖且符合伦理的机器人系统的基石。我们探讨了透明性如何促进问责制、实现知情同意并支持道德算法的调试。本文概述了实现透明性所面临的技术、伦理和实际挑战，并提出了一些创新方法，包括标准化度量标准、可解释的AI技术以及用户友好的界面。我们分析了透明性优先如何影响公众信任、监管政策和未来研究的途径。通过将透明性定位为伦理AI系统设计的一个基本要素，我们旨在为关于负责任的AI和机器人技术的持续讨论带来新的见解，并为未来在这个关键领域的进一步发展提供指引。", "innovation": "提出了标准化度量标准、可解释的AI技术和用户友好的界面来增强透明性，并构建了一个将技术实现与伦理考虑连接起来的框架，特别是在动态的真实世界环境中实现透明性具有特定挑战的情况下。文章还提出了一系列关于透明性在伦理AI系统设计中的重要性的观点，强调了如何通过透明性促进公众信任、监管政策和未来研究的方向。", "conclusion": "通过将透明性作为伦理AI系统设计的基本要素，本文为负责的AI和机器人技术的持续讨论做出了贡献，并为该领域的未来进步提供了指导方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05709", "html_url": "https://arxiv.org/abs/2508.05709", "title": "G-UBS: 面向视频推荐中隐式反馈的群体感知用户行为模拟以实现稳健理解", "title_en": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation", "authors": "Boyu Chen,Siran Chen,Zhengrong Yue,Kainan Yan,Chenyun Yu,Beibei Kong,Cheng Lei,Chengxiang Zhuo,Zang Li,Yali Wang", "background": "用户反馈对于改进推荐系统至关重要，但在实践中显性反馈（如喜欢或不喜欢）仍较为稀缺。通过用户行为中的隐式反馈（如用户快速跳过推荐视频）可以推断偏好，但隐式反馈常伴随着噪音，比如用户可能因无意点击或其他原因跳过视频，而非真不喜欢，这可能导致对用户喜好的误判，影响推荐性能。", "innovation": "该研究提出了一种新颖的群体感知用户行为模拟（G-UBS）范式，通过结合相关用户群体的上下文指导，深入理解个体用户的隐式反馈。该范式包括两个关键代理：用户群组管理器（UGM）用于基于大规模语言模型（LLM）生成用户群体概况，并且用户反馈建模器（UFM）使用一种创新的群体感知强化学习方法，使得在强化学习过程中用户受到关联群体概况的指导，从而更加稳健和深入地解析隐式反馈的原因。", "conclusion": "在构建的Video Recommendation基准测试IF-VR中进行的广泛实验表明，G-UBS显著优于主流的大规模语言模型（LLMs）和混合语言模型（MLLMs），在达到30%以上播放率的视频比例上高出4.0%，并且在IF-VR上的推理准确性高出14.9%。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05878", "html_url": "https://arxiv.org/abs/2508.05878", "title": "基于人工生成音频训练和识别和弦模型", "title_en": "Training chord recognition models on artificially generated audio", "authors": "Martyna Majchrzak,Jacek Mańdziuk", "background": "音乐信息检索领域的一个挑战性问题是获取足够的非版权音频录音用于模型训练和评估。这项研究比较了两种基于Transformer的神经网络模型在音频录制中的和弦序列识别效果，并考查了使用人工生成数据集的效用。受试数据集包括人工音频多轨（AAM）、舒伯特的冬之旅数据集和麦吉尔百灵牌数据集。实验结果证明，尽管人工生成的音乐和人类创作的音乐在复杂性和结构上存在差异，前者在某些情况下仍具有实用性。具体而言，AAM 可以丰富由人类创作音乐的小型训练集，甚至可以作为预测流行音乐和弦序列模型的单一训练集，尤其是在没有其他数据可用的情况下。", "innovation": "该研究比较了两种基于Transformer的神经网络模型在和弦识别任务上的表现，且采用了人工生成的数据集进行训练和评估，考察其实际应用价值。这拓展了数据来源的可能性，提供了在数据稀缺情况下可行的解决方案。", "conclusion": "尽管人工生成和人类创作的音乐在复杂性及结构上有所不同，但人工生成的音乐可以在某些场景中作为有效的训练资源，特别是用于预测流行音乐的和弦序列。AAM 可以用于丰富训练集或作为单一分模型训练集来提高模型性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05922", "html_url": "https://arxiv.org/abs/2508.05922", "title": "通过3D分割增强建筑工地分析与理解", "title_en": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation", "authors": "Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang", "background": "监测建筑施工进度至关重要但资源密集，推动了计算机视觉方法的研究以提高效率和可扩展性。传统的数据采集方法主要集中在室内环境中，在建筑工地这种复杂、杂乱且动态变化的条件下效果不佳。为了应对这一挑战，该论文评估了两种先进的3D分割方法——Segment Anything Model (SAM)和Mask3D，在复杂室外和室内环境中的应用效果。", "innovation": "该研究首次将两种已先在室内数据集上训练的3D分割模型(SAM和Mask3D)应用于实际建筑施工现场，通过对比分析展示了这两种模型在实际应用中的相对有效性。此研究填补了现有分割方法在户外场景中的评估空白，为未来的定制分割工作流提供了宝贵参考。", "conclusion": "该研究表明，SAM和Mask3D在面向建筑工地数据的分割提取方面表现出相对较好的效果，为实现更加自动化和精确的监测技术奠定了基础。这种研究有助于推动建筑工地分析的进一步发展，从而实现更有效的施工进度监控。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05908", "html_url": "https://arxiv.org/abs/2508.05908", "title": "混合物理-机器学习模型在定量电子衍射重构中的应用", "title_en": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements", "authors": "Shreshth A. Malik,Tiarnan A.S. Doherty,Benjamin Colmey,Stephen J. Roberts,Yarin Gal,Paul A. Midgley", "background": "对高保真电子显微镜模拟进行定量晶体结构细化面临一个根本性挑战：尽管物理相互作用在理论上得到了充分描述，但真实世界的实验效应却难以通过经典的分析方法建模。为了填补这一空白，本文提出了一种新型的混合物理-机器学习框架，该框架结合了可微物理模拟和神经网络。通过在整个模拟管道中利用自动微分技术，该方法实现了基于梯度的物理参数与表示实验变量的神经网络组件的联合优化，相比于传统的二次优化方法，提供了更高的可扩展性。本文通过应用到三维电子衍射结构细化中，展示该框架的能力，其方法能够直接从衍射数据中学习复杂的厚度分布，而不需要依赖简化的几何模型。这种方法在合成数据集和实验数据集中实现了最先进的细化性能，精确地恢复了原子位置，热位移以及厚度分布。", "innovation": "本文提出了一种混合物理-机器学习框架，通过结合可微物理模拟和神经网络，实现基于梯度的物理参数和神经网络组件的联合优化。这种方法在三维电子衍射结构细化中，无需依赖简化几何模型，直接从衍射数据中学习复杂的厚度分布。相比传统方法，这种方法具有更高的可扩展性，实现了最先进的细化性能。", "conclusion": "本文提出了一个模块化框架，该框架可以自然地扩展以容纳更多的物理现象，并可用于其他电子显微技术。这标志着基于梯度的混合建模成为一种强大的新的定量电子显微镜方法，历史上由于实验复杂性限制了分析。这种方法极大地提高了电子显微镜中的分析精度和效率，能够处理复杂的实验效应，为相关领域带来了新的机遇和技术可能性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06208", "html_url": "https://arxiv.org/abs/2508.06208", "title": "个性化隐私推荐的图联邦学习", "title_en": "Graph Federated Learning for Personalized Privacy Recommendation", "authors": "Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang", "background": "联邦推荐系统（FedRecs）因提供隐私保护推荐服务而受到关注。现有FedRecs假定所有用户对隐私保护的要求相同，即不上传任何数据到服务器。然而，这样的假设忽略了利用公共可用用户数据以增强推荐服务的潜力。在实际应用中，用户可以选择保持私密或公开个人数据。基于此，本文提出了一种名为GFed-PP的新颖图联邦学习模型，该模型适应不同隐私要求的同时提高推荐性能。", "innovation": "提出了GFed-PP模型，这是一种适应不同隐私要求并提高推荐性能的图联邦学习方法。该模型结合公共用户交互数据构建用户-项目交互图，进而形成用户关系图，并利用轻量级的图卷积网络（GCN）学习每个用户的个性化项目嵌入。此外，GFed-PP通过在客户端初始化项目嵌入并在服务器端聚合用户关系图来进行联邦推荐框架的优化。实验结果表明，GFed-PP在五个数据集上显著优于现有方法，提供更优的推荐准确性同时不损害隐私。", "conclusion": "该框架为在联邦推荐系统中处理不同的隐私偏好提供了实用解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05978", "html_url": "https://arxiv.org/abs/2508.05978", "title": "DAFMSVC：具有双注意机制和流匹配的一次性歌声转换", "title_en": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching", "authors": "Wei Chen,Binzhu Sha,Dan Luo,Jing Yang,Zhuo Wang,Fan Fan,Zhiyong Wu", "background": "Singing Voice Conversion (SVC) 的目标是将源歌手的音色转换到目标歌手身上，同时保持旋律和歌词的内容。在任何到任何的SVC任务中，一个主要的挑战是在不降低质量的情况下适应未见过的说话人音色。现有的方法要么面临音色泄露的问题，要么在生成的音频上无法实现满意的音色相似性和质量。", "innovation": "本文提出了DAFMSVC方法，通过使用目标音频中最相似的自监督学习（SSL）特征来替换源音频的SSL特征，以防止音色泄露。此外，引入了双重交叉注意机制来实现说话者嵌入、旋律和语言内容的自适应融合。还引入了一个流匹配模块，用于从融合特征生成高质量的音频。实验结果表明，DAFMSVC在主观和客观评估中均显著提高了音色相似性和自然度，超过了最新方法的效果。", "conclusion": "DAFMSVC通过双重交叉注意机制和流匹配模块显著提升了音色相似度和自然度，优于现有的最先进的方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05989", "html_url": "https://arxiv.org/abs/2508.05989", "title": "ETA: Energy-based Test-time Adaptation for Depth Completion", "title_en": "ETA: Energy-based Test-time Adaptation for Depth Completion", "authors": "Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong", "background": "深度完成模型在训练于某一「源」数据集时，如果转移到在不同环境条件下捕获的「目标」数据集上，往往会产生错误的输出。这是因为数据分布的变化导致了协变量偏移。本研究的重点在于量化深度预测属于源数据分布的概率，但由于部署前无法获取目标数据，团队通过使用对抗性扰动在数据空间中进行探索来解决这一问题，从而训练出能量模型来评估局部深度预测的分布状态。通过这种方法在测试时间调整预训练的深度完成模型的参数，使其输出更接近源数据分布。", "innovation": "提出了一种名为 'Energy-based Test-time Adaptation' (ETA) 的方法，该方法利用对抗性扰动来训练能量模型，评估局部深度预测的分布状态，并通过最小化能量来调整预训练模型参数，使测试时间的预测结果向源数据分布对齐。ETA 方法在三个室内和三个室外数据集的评估中，比之前最先进的方法提高了6.94%的室外精度和10.23%的室内精度。", "conclusion": "最终，ETA 方法通过对抗性扰动和能量模型评估深度预测的分布状态，在多种数据集上显著改善了深度完成模型的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05934", "html_url": "https://arxiv.org/abs/2508.05934", "title": "ASLSL：基于不完整多模态生理数据的自适应共享潜在结构学习在多维度情绪特征选择中的应用", "title_en": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "authors": "Xueyuan Xu,Tianze Yu,Wenjia Dong,Fulin Wei,Li Zhuo", "background": "近年来，基于多模态生理信号的情绪识别在脑机接口领域引起了广泛关注。然而，这些多模态生理特征通常是高维度的，不可避免地包含不相关信息、冗余信息和噪声，这可能导致情绪分类器过拟合、性能不佳和高计算复杂性。虽然特征选择已被广泛应用以应对这些挑战，但大多数前人研究都假设多模态生理数据是完整的，而在现实应用中，由于数据获取和操作环境的开放性，数据往往是不完整的。这就导致了部分样本在某些模态存在但在其他模态不存在的情况。本文探讨了这种不完整性给多模态生理信号特征选择带来的挑战，并提出了一种新的方法，即自适应共享潜在结构学习（ASLSL），通过自适应共享潜在结构学习探索不完整多模态生理信号和多维度情绪标签共享的潜在空间，从而减轻缺少信息的影响并挖掘共识信息", "innovation": "本文提出了自适应共享潜在结构学习（ASLSL），这是一种处理不完整多模态生理信号特征选择问题的新型方法。ASLSL根据相似特征具有相同情绪标签的性质，以探索不完整多模态生理信号和多维度情绪标签共享的潜在空间，从而减轻信息缺失的影响并挖掘共识信息。", "conclusion": "在两个最流行的多模态生理情绪数据集（DEAP和DREAMER）上进行的全面实验结果表明，ASLSL在多维度情绪特征选择中的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06017", "html_url": "https://arxiv.org/abs/2508.06017", "title": "智能编码系统应该带有解释地编写程序", "title_en": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "authors": "Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang", "background": "智能编码系统通过使用户能够使用自然语言指定代码行为来改变软件开发。然而，这些基于AI的编码器的黑盒决策机制引发了信任和易用性方面的问题，尤其是对于那些无法检查底层实现的非专家用户。现有方法如形式验证、静态分析和事后解释力被认为是不够的，因为它们不能解释AI生成代码的逻辑过程，不能真正解决透明性和用户理解的问题。特别是在需要高可信和可解释性的场景中，现有方法不能满足需求，呼唤一种新的方法来提供清晰、一致的解释，帮助用户理解AI生成代码的决策过程。", "innovation": "本文识别出认知对齐和语义忠实性作为关键的解释特性，并指出现有方法（如形式验证、静态分析和事后解释性）的局限性。提出探索神经符号方法进行解释生成，该方法在训练过程中使用符号约束引导模型行为，并通过神经表示丰富程序语义，使推理时能够自动进行一致性检查。以此来改进代码生成系统的可解释性，帮助非专家用户理解和信任AI生成的代码。", "conclusion": "本文认为智能编码系统不仅应该生成代码，还应该产生清晰且一致的解释，以弥合模型推理与用户理解之间的差距。神经符号方法被认为是解决这一问题的可能途径，因为它结合了符号逻辑和神经网络的优势，为AI生成代码提供了可解释性验证机制。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06021", "html_url": "https://arxiv.org/abs/2508.06021", "title": "通过基于生成AI的图像合成改善流式成像显微镜中超微粒子分类", "title_en": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "authors": "Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve", "background": "现有研究中，使用流式成像显微镜结合深度学习技术分析超微粒子已能有效识别不同类型的粒子，例如将无害成分如硅油与蛋白质粒子区分开来。然而，在数据稀缺且各类粒子数量严重不均的情况下，多分类分类器的应用面临挑战，常导致研究者不得不依赖效果较差的方法。特别是对于硅油和气泡这类低频意外出现的粒子，获取足够的图像样本较为困难。", "innovation": "本文开发了一种最新的扩散模型，通过生成高保真图像来解决数据不平衡问题，增强训练数据集，成功训练出能有效分类不同类型粒子的多分类深度神经网络模型。生成的图像在视觉质量和结构上与真实粒子图像高度相似。通过大规模实验，验证了该方法在分类性能上的显著提升，并且没有明显的负面影响。此外，为了促进开放研究和可重复性，作者公开了扩散模型和多分类深度神经网络分类器，以及易于集成的接口。", "conclusion": "本文提出的方法极大地改善了超微粒子分类的准确性和可重复性，特别适合处理未预见的低频粒子数据样本不足的问题。相关模型和工具已经开放供未来研究使用。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06057", "html_url": "https://arxiv.org/abs/2508.06057", "title": "地平线上的AGI：通往地球、可能性及评估处理地球观测数据模型的智能方法", "title_en": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?", "authors": "Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell", "background": "随着通用人工智能（AGI）越来越接近现实，研究界对跨模态数据（如文本、图像、视频和音频）进行收集和研究的兴趣也日益浓厚。尽管如此，卫星光谱图像作为额外的模态，还未得到应有的关注。本文探讨了地球观测数据对于智能模型的价值，并指出现有基准测试存在的局限性，在此领域评估基础模型的泛化能力。由此，本文强调需要新的基准测试来全面评估地球观测模型的能力。通过提出一套全面的任务集，旨在有效评估模型处理地球观测数据的理解和交互能力.", "innovation": "本文通过对比分析现有基准测试的局限性，提出了新的全面基准测试框架，旨在更全面地评估地球观测模型的能力，推动AGI在地球观测领域的发展。", "conclusion": "本文强调了地球观测数据对于提升AGI理解自然世界的能力的重要性，并提出了一套全面的任务集作为新的基准测试，以更有效地评估这些模型的表现。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06062", "html_url": "https://arxiv.org/abs/2508.06062", "title": "不要忘记想象力！", "title_en": "Don't Forget Imagination!", "authors": "Evgenii E. Vityaev,Andrei Mantsivoda", "background": "认知想象是一种在人类思考中起关键作用的想象类型，它不是脑海中静态的图片般的想象，而是一种能够在脑海中可视化概念和因果关系系统的能力，这些系统为推理、决策和预测提供语义背景。研究者认为认知想象的作用仍然被严重低估，这导致了许多问题，从而使当前人工智能的能力受到限制。例如，在推理过程中，人类依靠想象的背景信息来获取相关背景知识，并不断回到其合理性进行语义验证，因此没有想象的推理是盲目的。", "innovation": "本文提倡将认知想象作为未来人工智能领域的突破点，并介绍了一种新的方法——语义模型。语义模型是一种可以学习的数学模型，类似于神经网络，基于概率因果关系。与传统方法相比，语义模型可以模拟认知想象，因为它确保了想象背景的连贯性，并通过整体和连贯的事实网络及其因果关系实现了玻璃盒方法的透明操作。", "conclusion": "论文呼吁对认知想象给予更多关注，并提出语义模型作为模拟认知想象的工具，以克服当前人工智能的局限性，推动人工智能的进一步发展。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06118", "html_url": "https://arxiv.org/abs/2508.06118", "title": "基于集成的fMRI数据的认知脑状态分类的图表示方法", "title_en": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification", "authors": "Daniil Vlasenko,Vadim Ushakov,Alexey Zaikin,Denis Zakharov", "background": "基于神经影像学数据理解并分类人类认知脑状态仍然是神经科学领域的一项主要且极具挑战性的问题，这是因为信号的高维度性和固有的噪声。本文旨在通过利用多种基础机器学习模型构建集成图的表示方法，以实现二分类脑状态任务。具体地，每条边的权重反映了两种认知状态的后验概率差异，其值范围在[-1, 1]之间，编码了某种状态的信心程度。", "innovation": "本文提出了一种基于集成的图表示方法来处理功能磁共振成像(fMRI)数据，并用于认知脑状态分类任务。此方法利用多种基础机器学习模型构建图，并通过其边缘权重的变化来区分不同的认知状态，这种方法超越了传统的基于相关性构建的图。实验证明，使用集成图的方法在分类任务中表现更为优异，其准确率达到了97.07%到99.74%，并在图神经网络（GNN）分类任务中也优于传统的相关性图方法，进一步证明了集成方法在脑状态分类中的有效性和优越性。", "conclusion": "本文所提出的基于集成的fMRI图表示方法在处理认知脑状态分类任务中表现出优越性能，通过集成不同机器学习模型的权重构建图，能够提供更丰富的拓扑信息，提高脑状态的辨识能力。此外，这种方法还保持了表徵的边级可解释性，适用于多类别和回归任务，并可扩展至其他神经影像数据及病理状态分类领域。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06052", "html_url": "https://arxiv.org/abs/2508.06052", "title": "基于Gromov-Wasserstein最优运输距离的数据驱动密度引导", "title_en": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance", "authors": "Haruto Nakashima,Siddhartha Ganguly,Kenji Kashima", "background": "本文针对数据驱动的随机约束密度引导难题，使用Gromov-Wasserstein度量来解决。系统是一个未知的线性控制递归动态模型，前提条件是可通过预运营实验获得丰富的输入输出数据。初始状态被建模为高斯混合分布，而终端状态需要匹配指定的高斯分布。", "innovation": "论文创新地将问题重新表述为凸凹问题，并证明可以使用凸凹算法高效且可操作地解决。通过不同的数据驱动策略验证了该方法的有效性。", "conclusion": "数值结果证明了本文方法的有效性，使用基于Gromov-Wasserstein最优运输距离的数据驱动密度引导方法能够高效且可靠地解决最优控制问题。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06131", "html_url": "https://arxiv.org/abs/2508.06131", "title": "增强现实世界量子机器学习应用的古典代理可扩展性", "title_en": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications", "authors": "Philip Anton Hernicht,Alona Sakhnenko,Corey O'Meara,Giorgio Cortiana,Jeanette Miriam Lorenz", "background": "量子机器学习（QML）具有在企业早期应用的潜力，但由于受限于量子硬件的可获得性，部署QML解决方案面临重大瓶颈。已有的经典代理方法面临高计算需求问题，尤其对于工业规模量子模型（约20个量子位及以下）在高性能计算（HPC）系统上仍存在资源需求的限制性。本研究通过开发一个新的管道，解决了此前方法带来的问题，能够大规模生成经典代理，从而减少资源冗余，适合多种规模的量子模型。研究展示了经典代理在真实世界能源需求预测问题上的有效性和计算需求的线性增长，验证了其可行性与实用性，促进了量子技术在工业环境中的快速集成，同时也可作为在实证条件下寻找实用的量子优势的强大研究工具", "innovation": "本研究提出了一种新的管道来解决传统经典代理方法的局限性，能够生成更大规模的量子模型的经典代理，并极大地减少了所需资源。这种方法能够在无需高性能计算系统的情况下处理工业规模的量子模型，具有显著的计算资源需求增长的线性特性，而非此前的指数增长", "conclusion": "本研究提出的方法提供了一种轻量级的量子解决方案转换为经典可部署版本的方法，有助于加速量子技术在工业环境中的应用。同时，它也为研究人员在现实场景中寻找实用量子优势提供了有力工具。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06126", "html_url": "https://arxiv.org/abs/2508.06126", "title": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering", "title_en": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering", "authors": "Jixuan Yin,Zhihao Yao,Wenshuai Huo,Xinmiao Yu,Xiaocheng Feng,Bo Li", "background": "在聚类任务中，将特征空间结构化为清晰且分离良好的分布是至关重要的。然而，由于短文本表示法有限的表现力，传统方法难以识别出真正能够捕捉每个类别底层语义的聚类中心，导致表示学习朝着非最优的方向优化。为此，需要一种新的方法来解决这一问题，以更好地识别和学习聚类中心及其对应语义中心之间的关系，从而提高聚类性能和稳定性。", "innovation": "我们提出了IOCC，一种新颖的少样本对比学习方法，实现了聚类中心与语义中心之间的对齐。IOCC包含两个关键模块：增强交互的最优传输（IEOT）和中心意识对比学习（CACL）。IEOT是将个体样本之间的语义交互引入传统的最优传输问题，并生成伪标签。基于这些伪标签，我们聚合高置信度样本构建伪中心来近似语义中心。紧接着，CACL将文本表示优化向对应的伪中心方向。随着训练的进行，两个模块之间的协作逐渐减小聚类中心与语义中心之间的差距，从而使模型学习高质量的分布，提高聚类性能。", "conclusion": "在八个基准数据集上的广泛实验表明，IOCC相对于先前方法表现更好，在困难的生物医学数据集上改进了多达7.34%，并且在聚类稳定性和效率方面也表现出色。源代码可在此链接找到：this https URL"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06133", "html_url": "https://arxiv.org/abs/2508.06133", "title": "具有可变预填充和解码长度的LLM服务优化", "title_en": "LLM Serving Optimization with Variable Prefill and Decode Lengths", "authors": "Meixuan Wang,Yinyu Ye,Zijie Zhou", "background": "在处理大型语言模型（LLM）请求时，每个请求的预填充（输入提示的长度）和解码长度（生成的输出令牌数量）存在差异。预填充长度决定了初始内存使用量，而解码长度则与每生成一个输出令牌增加的内存使用量相关。由于需要在处理一组n个请求时同时考虑批处理、放置约束、优先级关系及线性增加的内存使用量，目标是在满足内存限制的情况下使总完成时间最小化。论文分析了常见的调度策略，如先到先服务（FCFS）和最短优先服务（SF），证明它们的竞争力随内存限制的增加呈非线性增大，这在实际应用场景中可能导致性能显著下降。", "innovation": "提出了一种新型算法，基于新的选择度量标准，能够高效地随时间形成批处理，并证明此算法能够实现恒定的竞争力比。此外，开发并评估了基于这种方法的一些算法变体，包括动态规划变体、局部搜索方法以及基于线性规划的调度器，通过全面的模拟试验展示了这些算法相对于标准基线的优势，同时保持了计算效率。", "conclusion": "论文证明提出的算法和变体在保持高效计算的同时，能够显著降低分配给LLM的总完成时间，解决由可变预填充和解码长度导致的优化难题。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06087", "html_url": "https://arxiv.org/abs/2508.06087", "title": "大型语言模型中的自适应反向跟踪以保护隐私", "title_en": "Adaptive Backtracking for Privacy Protection in Large Language Models", "authors": "Zhihao Yao,Yuxuan Gu,Xiachong Feng,Weitao Ma,Bo Li,Xiaocheng Feng", "background": "在人工智能时代，隐私保护已成为一个关键议题。目前的工作主要关注用户隐私，而忽视了检索增强生成范式下企业数据泄露的风险。为弥补这一缺陷，本文提出了企业隐私关注的新目标，并解决两个基本挑战：现有方法（如数据清洗）会严重降低模型性能，且缺乏用于评估的公开数据集。", "innovation": "本文提出了ABack，一种无需训练的机制，利用隐藏状态模型来定位泄露意图的来源，并安全地重写输出。此外，还构建了PriGenQA，一种涵盖医疗和金融领域的新型基准数据集。为了确保严格评估，设计了一种强大的自适应攻击者，基于组相对策略优化。实验结果显示与强基准相比，ABack将整体隐私经济性得分提高了最高可达15%，避免了之前方法的性能牺牲。", "conclusion": "通过ABack和PriGenQA的贡献，本文填补了企业数据隐私保护领域的空白，提供了更为有效的隐私保护方法，并为未来的隐私保护研究奠定了基础。未来的工作可能会专注于进一步优化ABack机制，以提高其在各种场景下的性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06204", "html_url": "https://arxiv.org/abs/2508.06204", "title": "分类问题是RAG问题：仇恨言语检测案例研究", "title_en": "Classification is a RAG problem: A case study on hate speech detection", "authors": "Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen", "background": "内容审核的稳健性需要能够快速适应不断变化的政策而不必进行昂贵的重新训练的分类系统。传统的分类任务是在遵守预训练参数的前提下确定正确类别，而本文提出使用检索增强生成（RAG）进行分类，将传统分类任务从确定正确类别转变为在推理时根据检索到的上下文知识评估内容。在仇恨言语检测中，这一方法将任务从“这是仇恨言语吗？”转变为“这是否违反了仇恨言语政策？”", "innovation": "本文提出了一个名为上下文策略引擎（CPE）的主动式RAG系统，它具有三大优势：（1）分类准确性与领先商用系统相当；（2）通过检索到的政策段落固有的可解释性；（3）无需重新训练即可动态更新策略。通过三个实验，研究表明该系统可以实现细粒度的政策控制，正确调整特定身份群体的保护措施，而无需重新训练或牺牲整体性能。", "conclusion": "文章的结果表明RAG技术可以将分类任务转化为一个更为灵活、透明和适应性强的过程。这不仅对内容审核，也对更广泛的分类问题具有重要的指导意义。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06263", "html_url": "https://arxiv.org/abs/2508.06263", "title": "逻辑程序归纳中的对称性打破", "title_en": "Symmetry breaking for inductive logic programming", "authors": "Andrew Cropper,David M. Cerna,Matti Järvisalo", "background": "归纳逻辑编程的目标是寻找一个假设，该假设能够泛化训练数据和背景知识。这一过程面临的挑战在于在搜索巨大假设空间时，由于大量逻辑上等价的假设存在，这一问题被进一步放大了。因此，有必要提出一种有效的方法来打破假设空间中的对称性，以优化求解过程并提高效率。", "innovation": "本文引入了一种方法来打破归纳逻辑编程中假设空间的对称性，并将其实施在答案集编程中。这种方法在解决视觉推理和游戏对弈等多个领域的问题时，能够显著减少求解时间，从超过一个小时缩短至仅仅17秒。", "conclusion": "通过这种方法，可以有效地减少解决时间，大大提高了解题效率，特别是在需要处理大规模假设空间的任务中，具有显著的优势。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06163", "html_url": "https://arxiv.org/abs/2508.06163", "title": "所有一把尺子不适合所有情况：一种分布感知稀疏化策略以实现更精确的模型融合", "title_en": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "authors": "Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu", "background": "模型融合已成为一种无需数据的多任务学习有说服力的范式，能够将多个微调模型合并成一个强大的实体。现有的合并方法通常采用一种一刀切的稀疏化技术，即使用统一的稀疏度比率去除冗余参数，但这种方法忽略了模型参数内在的结构和统计异质性，往往导致关键参数被误剪，而无用参数被保留的次优权衡。", "innovation": "我们提出了TADrop（Tensor-wise Adaptive Drop），一种针对模型参数异质性的自适应稀疏化策略，而不是全局比率，TADrop根据每个参数张量的分布特性为其分配定制化的稀疏水平。核心思想是密度高、冗余度大的张量可以被大胆地剪枝，而稀疏、关键的张量则保留。TADrop作为一种简单且即插即用的模块，通过整合到基础、经典和最新合并方法中进行验证，在多种任务（视觉、语言、多模态）和模型（ViT，BEiT）上进行了广泛的实验，结果显示TADrop能够显著提升这些方法的表现，例如，增强顶级合并方法时，在8个ViT-B/32任务中平均性能提升了2.0%。TADrop为参数干扰的管理提供了更有效的方法，通过将稀疏化定制化到模型结构，提供了一个高性能模型融合的新基准。", "conclusion": "TADrop通过定制化的稀疏化策略补偿了现有方法中的次优权衡，并通过广泛实验证明了其有效性，为高性能模型合并提供了新的基准。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06321", "html_url": "https://arxiv.org/abs/2508.06321", "title": "EmoAugNet：用于情感识别的信号增强CNN-LSTM混合框架", "title_en": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition", "authors": "Durjoy Chandra Paul,Gaurob Saha,Md Amjad Hossain", "background": "在人机交互中，通过语音识别情绪信号能够显著增强交互的有效性。现有系统依赖的特征质量及其种类直接影响了情绪识别系统的性能。", "innovation": "提出了EmoAugNet，这是一种结合了长短期记忆（LSTM）层和一维卷积神经网络（1D-CNN）的混合深度学习框架。通过一种综合的数据增强策略，结合传统方法如噪声添加、音高变换、时间拉伸与一种新颖的组合增强流水线，该模型在IEMOCAP和RAVDESS数据集上实现了高准确率，从而提高了SER系统的稳健性和性能。", "conclusion": "实验结果表明，通过集成数据增强和混合建模，EmoAugNet显著提升了情绪识别系统的鲁棒性和性能。特别是在IEMOCAP和RAVDESS数据集上得到了高准确率。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06296", "html_url": "https://arxiv.org/abs/2508.06296", "title": "LLM Robustness Leaderboard v1 --技术报告", "title_en": "LLM Robustness Leaderboard v1 --Technical report", "authors": "Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe", "background": "该技术报告随附PRISM Eval在巴黎AI行动峰会发布的LLM鲁棒性排行榜。介绍了PRISM Eval行为诱发工具（BET），这是一种通过动态对抗优化的AI系统，能对41个最先进的LLM进行自动红队测试，实现100%的攻击成功率（ASR）对37个模型。研究表明，尽管所有模型都存在普遍的易受攻击性，但攻击难度在不同模型间差异超过300倍。同时，还进行了具体的漏洞分析，以确定对特定危险类别最有效的脱狱技术。与AI安全网络中的值得信赖第三方合作进行的评估展示了社区中分布式鲁棒性评估的实际途径。", "innovation": "提出了细粒度的鲁棒性度量方法，估计诱发出危害行为所需的平均尝试次数，并引入了底层漏洞分析，识别出对特定危害类别最有效的脱狱技术。", "conclusion": "这种协作评估方法展示了在社区中进行分布式鲁棒性评估的实际路径，提供了对未来LLM安全评估的见解。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06030", "html_url": "https://arxiv.org/abs/2508.06030", "title": "通过适应预训练嵌入高效探测大型语言模型的知识", "title_en": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "authors": "Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar", "background": "大型语言模型（LLMs）在生成预训练期间遇到的各种领域（如科学、历史和地理）中获取知识，但由于其随机性，预测LLMs获取的知识非常困难。现有方法通过检查隐藏表示、设计特定任务提示、收集代表性样本和估计不确定性等方式试图探究知识。然而，这些方法需要进行前向传递以探究LLMs关于某事实的知识，导致计算成本高，耗时长。", "innovation": "本文提出了一种名为PEEK（Proxy Embeddings to Estimate Knowledge of LLMs）的新方法，通过利用预训练的嵌入模型来推断LLMs的知识，这些模型可以有效地将事实知识编码为文本或图形，作为LLMs的代理。通过训练集中的事实来识别LLMs的已知内容，并采用线性解码层适配嵌入模型以预测LLMs的输出。实验结果显示，嵌入模型可以以高达90%的准确度预测LLMs的知识。", "conclusion": "嵌入模型，尤其是句子嵌入模型，被证明比图形嵌入模型更适合预测LLMs的知识，这揭示了事实景观的潜在表示。因此，我们认为知识适应型嵌入模型可以用于大规模识别LLMs的知识空白，并能提供更深入的了解LLMs的内部归纳偏差。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06383", "html_url": "https://arxiv.org/abs/2508.06383", "title": "基于树结构的深度学习方法用于符号积分算法排名", "title_en": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms", "authors": "Rashid Barket,Matthew England,Jürgen Gerhard", "background": "在计算机代数系统（如Maple）中进行符号不定积分的过程中，需要从多种可用方法中选择最有效的算法。传统上，这种方式的选择往往缺乏对问题实例的具体考虑，导致可能存在的算法效率低下。数学表达式的不同表示方式对于算法选择的影响也未充分研究。", "innovation": "本文提出了一种基于机器学习的方法，使用树型深度学习模型构建两阶段架构：首先识别适用算法，然后根据预测的输出复杂度进行排名。树结构表示数学表达式比序列表示具有更好的性能，且两阶段框架优于其他机器学习方法。模型在包含六种数据生成器的多样化数据集上，对70,000个样本的保留测试集有接近90%的准确率，并在Maple内部测试套件的独立测试集上保持了较强的泛化能力，超越了Maple内置的和先前的机器学习方法。", "conclusion": "本文的实验结果表明，数据表示和问题定义在机器学习的符号计算中起着关键作用。预计本文的方法可以有效应用于数学软件中的类似优化问题。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06337", "html_url": "https://arxiv.org/abs/2508.06337", "title": "局部样本加权与去相关的特征重要性", "title_en": "Decorrelated feature importance from local sample weighting", "authors": "Benedikt Fröhlich,Alison Durst,Merle Behr", "background": "特征重要性（FI）统计为深度洞察机器学习（ML）模型的决策过程提供了一种突出而有价值的方法，但是在训练数据中的特征之间存在相关性的情况下，其效果受到明显限制。在这种情况下，FI往往会均匀分布在所有与响应生成信号特征相关的特征中。更糟糕的是，如果多个信号特征与噪声特征强相关，而彼此仅轻微相关，这可能会导致噪声特征具有明显更大的FI评分，超过任何信号特征。本文分析了这一问题并介绍了一种局部样本加权（losaw）方法。", "innovation": "本文提出了一种局部样本加权（losaw）方法，该方法可以灵活地集成到许多ML算法中，以改善训练数据中特征相关性存在的条件下FI的评分。该方法源自因果推断中的逆概率加权，并在ML模型中局部使用样本加权方案，以解相关目标特征与其他特征。此外，losaw具有天然的调节参数——加权样本的有效最小样本数，这与解释-预测折衷有关，类似于传统ML调节参数的偏差-方差折衷。", "conclusion": "我们展示了losaw在基于决策树的ML方法和神经网络微型批量训练中的集成方法。通过模拟研究证明了losaw在不同相关模式下的随机森林和卷积神经网络中的一致改进效果，并实现了出了显著提升预测准确率，特别是在分布外数据上，同时保持了类似水平的分布内测试数据准确率。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06345", "html_url": "https://arxiv.org/abs/2508.06345", "title": "利用适应性拓扑表示进行零样本图问题回答", "title_en": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "authors": "Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang", "background": "大型多模态模型（LMMs）在多种领域的问题回答（QA）任务中展示了通用的零样本能力，包括涉及复杂图拓扑结构的图QA。当前的方法大多仅使用一种类型的图表示形式——拓扑表示形式（TRF），如统一提示的文本描述或固定样式的视觉表示。这些“一刀切”的方法未能考虑不同模型或任务的特定偏好，可能导致不正确的或过长的回答。", "innovation": "首先，分析现有TRF的特性和弱点，并设计了一套针对零样本图QA的TRF，标记为$F_{ZS}$。随后提出了一种新的度量标准——图响应效率（GRE），来衡量图QA中的性能与简洁性的平衡。开发了动态TRF框架，以提高图QA的准确性和简洁性。具体来说，动态TRF通过创建TRF偏好（TRFP）数据集并依据GRE评分对TRFs进行排名，来探知问题特定的TRF偏好，然后在TRFP数据集上训练TRF路由器，以适应地给每个问题分配$F_{ZS}$中的最佳TRF。广泛的实验表明，动态TRF显著提高了LMMs的零样本图QA性能。", "conclusion": "实验结果表明，动态TRF显著提升了LMMs在7个领域内的图QA任务和2个下游任务中的零样本图QA准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06277", "html_url": "https://arxiv.org/abs/2508.06277", "title": "大型语言模型数据生成增强德语语音的意图识别", "title_en": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech", "authors": "Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter", "background": "语音命令的意图识别（IR）对于人工智能（AI）助手系统至关重要；然而，大多数现有方法仅限于简短的命令，并主要针对英语进行开发。本文通过关注来自德国老年人群体的语音意图识别，解决了这些限制。现有的方法大部分专注于简短命令且主要针对英语，缺乏对广泛语言和口音的适应性。本文旨在提高意图识别的普适性和准确性，特别是在低资源语言如德语中实现更有效的意图识别能力。", "innovation": "本文提出一种新颖的方法，结合了对老年德语语音（SVC-de）进行微调的改编后的Whisper ASR模型，以及在由三个大型语言模型（LLMs）生成的合成文本数据集上训练的基于Transformer的语言模型，分别为LeoLM、Llama3和ChatGPT。此外，为了评估方法的鲁棒性，使用文本转语音模型生成合成语音并进行了广泛的跨数据集测试。研究发现，生成的大型语言模型数据显著提升了分类性能和对不同说话风格和未见词汇的鲁棒性。特别地，研究发现，作为较小且特定领域的13B LLM，LeoLM在德语意图识别的数据集质量上超过了更大的ChatGPT（175B）。这表明生成的AI能够有效地填补低资源领域的数据缺口。本研究提供了数据生成和训练过程的详细文档，以确保透明性和可重复性。", "conclusion": "本工作展示了生成的AI在填补低资源语言领域（如德语）的数据缺口方面的有效作用。通过跨数据集测试和记录数据生成及训练过程，证明了所提出方法在增强意图识别性能和适应不同说话风格方面的显著优势。此外，研究成果表明即使是在小型领域特定的大型语言模型也能在特定任务中表现出色。这为未来在其他低资源语言中实现有效的人工智能助手系统提供了解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06377", "html_url": "https://arxiv.org/abs/2508.06377", "title": "DP-SPRT: 微分私有顺序概率比检验", "title_en": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests", "authors": "Thomas Michel,Debabrota Basu,Emilie Kaufmann", "background": "本文重新审视了Wald的著名顺序概率比检验（Sequential Probability Ratio Test，SPRT），探讨在隐私约束下的顺序假设检验问题。现有工作在隐私保护方面存在不足，本文提出了一种名为DP-SPRT的机制，它可以调节以实现预定的错误概率和隐私约束，填补了这一领域的空白。DP-SPRT机制依赖一种私有方法，该方法处理一系列查询并根据私有判定何时查询结果超出预定区间而停止。这种OutsideInterval机制改进了现有技术如AboveThreshold的简单组合，有可能惠及其他顺序算法的性能提升。证明了DP-SPRT的通用错误和样本复杂度上限，并分别在Laplace噪声（纯微分隐私）和Gaussian噪声（Rényi微分隐私）环境中进行了实例化，展示了其在小错误和假设接近情况下的接近最优性能。", "innovation": "本文提出的DP-SPRT方法，通过一个私有机制处理一系列查询，并在私有判定查询结果超出预定区间时停止，从而在隐私和错误概率之间找到平衡。该机制不仅可以改进现有的顺序算法，还可以根据算法设计者的需求灵活调节，适应不同的噪声分布。特别是在Laplace噪声环境中证明了DP-SPRT的样本复杂度下界，表明在小错误和接近的假设情况下，其性能接近最优。", "conclusion": "本文分析了DP-SPRT在Laplace噪声和Gaussian噪声环境中的一般错误和样本复杂度上限。实验研究表明，DP-SPRT在小错误和某一假设接近另一假设时表现出良好的实际性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06450", "html_url": "https://arxiv.org/abs/2508.06450", "title": "eSASRec：以模块化方式增强基于Transformer的推荐", "title_en": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion", "authors": "Daria Tikhonovich,Nikita Zelinskiy,Aleksandr V. Petrov,Mayya Spirina,Andrei Semenov,Andrey V. Savchenko,Sergei Kuliev", "background": "自SASRec和BERT4Rec等基于Transformer的模型问世以来，它们已成为序列推荐的常用基准模型，超越了早期的神经网络和非神经网络方法。尽管许多后续研究通过轻微调整Transformer层的结构、使用更好的训练目标以及采用改进的损失函数，提高了一些模型的有效性，但这些局部改进的综合效果尚未被系统性地评估。因此，本文旨在填补这一空白。", "innovation": "通过实验证明，使用SASRec的训练目标、LiGR Transformer层以及采样软最大化损失函数的组合，构建了一个非常有效的推荐模型，即eSASRec（增强SASRec）。与最近的前沿模型ActionPiece相比，eSASRec在常见的学术基准中展现出更多的有效性（高23%）。在主要的生产化基准测试中，eSASRec处于准确性和覆盖度之间的Pareto前沿（与最近的工业模型HSTU和FuXi并列）。由于与原SASRec相比的调整较为简单，且无需额外的功能（如HSTU的事件时间戳），eSASRec可以很容易地集成到现有的推荐系统中，并可作为复杂算法的强而简单的基准。", "conclusion": "eSASRec作为一种增强的基于Transformer的推荐模型，对于生产环境中的推荐系统具有重要的应用价值。其主要创新点在于使用了一种全新的模块化组合方式来提升模型性能，并且该模型简单易集成，能够作为复杂推荐算法的基准。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06433", "html_url": "https://arxiv.org/abs/2508.06433", "title": "Memp：探索智能体程序性记忆", "title_en": "Memp: Exploring Agent Procedural Memory", "authors": "Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs）在执行多样化任务方面表现出色，但它们在程序性记忆方面存在缺陷，这种记忆通常是手动设计或嵌入在静态参数中，因此不够灵活和可更新。现有的智能体系统无法很好地处理新的或未见过的任务。在这项研究中，作者旨在改进智能体的程序性记忆，使其能够在不断学习和更新的基础上，适应新环境和遇到的新任务，从而实现更加智能和有效的智能体行为。", "innovation": "作者提出了Memp模型。Memp通过总结过去智能体的行动轨迹，提取出具体的步骤指令和高层次的脚本级抽象，以实现可学习、可更新和终身的程序性记忆。该模型的研究重点在于构建、检索和更新程序性记忆的策略，并且采取动态机制，持续更新和调整其记忆内容。Memp展示了在不断改革记忆仓库的基础上，智能体在类似任务中的成功率和效率不断提高。此外，即使将来自于更强模型的程序性记忆迁移到较弱模型中，也能获得显著的性能提升。", "conclusion": "这项研究表明，通过Memp模型，智能体能够获得更加灵活和可持续的程序性记忆，这有助于智能体在面对新任务或未见过的任务时提高效率和适应性。这一方法不仅适用于旅行规划和ALFWorld这类任务，也有望推广到其他需要程序性记忆的场景中。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06411", "html_url": "https://arxiv.org/abs/2508.06411", "title": "灾难性AI风险的维度表征与路径建模", "title_en": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks", "authors": "Ze Shen Chin", "background": "尽管关于人工智能（AI）风险的讨论越来越多，但这些讨论常常缺乏一个全面且多维度的框架，以及在危险与其引起的伤害之间的具体因果路径。因此，该研究旨在通过分析六个常见的AI灾难性风险（化学、生物、放射性、核武器[CBRN]、网络进攻、突然失去控制、渐进失去控制、环境风险和地缘政治风险）来填补这一空白。研究对这些风险进行了跨七个关键维度的表征：意图、能力、实体、极性、线性度、影响力范围和顺序，并通过逐步映射从最初的风险到最终伤害的过程来进行风险路径建模。", "innovation": "研究采用了一个分维度的方法来进行系统风险识别和泛化缓解策略，同时通过执行风险路径模型找出特定情境下的干预措施。这些方法为整个价值链中管理灾难性AI风险提供了一个更结构化和实用的基础。", "conclusion": "这篇论文通过分析六个常见的AI灾难性风险以及通过逐步构建从风险到伤害的过程，提供了一个更结构化、更具操作性的框架，用于管理整个价值链中的灾难性AI风险。这种方法支持系统的风险识别和普适性的缓解策略，将有助于更加精准地应对AI的潜在威胁。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06455", "html_url": "https://arxiv.org/abs/2508.06455", "title": "通过协作重要加权实现高效特征选择以解决冷启动推荐中的小特征集最大影响", "title_en": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting", "authors": "Nikita Sukhorukov,Danil Gusak,Evgeny Frolov", "background": "推荐系统在冷启动挑战下需要利用超出用户-项目交互的辅助特征，但存在不相关或噪声特征会降低预测性能，过多的特征则增加计算负担，导致内存使用量增加和训练时间延长。因此，该研究提出一种新的特征选择策略，优先考虑用户行为信息，通过结合协作行为数据中的相关性来增强特征表示，使用基于最大体积算法的机制来对特征进行排名。这一方法在各个数据集和混合推荐模型中进行了全面评估，证明该方法在冷启动场景中通过选择少量但高效的特征子集实现了优秀的推荐准确性和计算效率平衡", "innovation": "提出了一种基于最大体积算法的特征选择策略，通过结合协作行为数据中的相关性，优先选择用户行为信息，然后使用基于最大体积算法的机制来对特征进行排名。这种方法在各种数据集和混合推荐模型中展示了在小特征集中实现高效推荐的潜力，甚至在严格的特征减少条件下，也超过了现有的特征选择技术，同时保持了出色的效率", "conclusion": "该研究通过协作重要加权的特征选择方法在冷启动场景中成功地减少了特征数量，同时保持了推荐系统的准确性和计算效率，展示了在小特征集中实现高效推荐的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06452", "html_url": "https://arxiv.org/abs/2508.06452", "title": "TRUST: 利用文本稳健性进行无监督领域适应", "title_en": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation", "authors": "Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia", "background": "近年来，无监督领域适应（UDA）方法在解决经典领域转换（例如：合成到真实）方面取得了巨大成功，但是它们仍然在复杂的领域转换（例如：地理性转换）下表现不佳，特别是在背景和对象外观在不同领域差异显著的情况下。先前的研究表明，语言模态可以帮助在适应过程中应对这些复杂的转换并显示出更强的鲁棒性。因此，本文介绍了一种名为TRUST的新型UDA方法，该方法利用语言模态的稳健性来指导视觉模型的适应过程。TRUST利用目标样本的描述自动生成伪标签，并引入了一种新的不确定性估计策略，通过归一化的CLIP相似度得分估计伪标签的不确定性。这种估计的不确定性被用于重新加权分类损失，从而抵消从质量较低的描述获取的错误伪标签的不良影响。为了进一步提高视觉模型的鲁棒性，提出了利用描述指导目标图像的对比训练的多模态软对比 loss ，这种方法通过描述使每对图像既作为正样本又作为负样本，其特征表示根据描述相似度的程度被相互吸引和排斥。这种方法避免了在无监督领域适应设置中难以确定正样本和负样本的问题，从而提高了模型的适应性。我们的方法在经典（DomainNet）和复杂（GeoNet）领域转换中达到了新的SOTA性能。接受后将公开代码。", "innovation": "TRUST提出了一种利用语言模态的稳健性来引导视觉模型的无监督领域适应的新方法。首先，该方法利用目标样本的描述自动生成伪标签，并引入了一种新的基于归一化CLIP相似度得分的不确定性估计算法，以估计伪标签的不确定性。其次，该方法提出了一种新的多模态软对比损失，利用描述来指导视觉模型的对比训练，通过描述使每对图像既作为正样本又作为负样本，从而提高模型的适应性。这些创新点解决了经典和复杂领域转换中的鲁棒性和适应性问题，取得了SOTA的性能。", "conclusion": "本文提出了一种名为TRUST的新型无监督领域适应方法，在经典和复杂领域转换中，该方法都取得了新的SOTA性能，表明其在处理复杂领域转换方面具有更好的适应性和鲁棒性。未来的工作可以进一步探讨该方法在其他领域转换任务中的适用性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06477", "html_url": "https://arxiv.org/abs/2508.06477", "title": "在临界状态下，直觉在最大量程模型中涌现", "title_en": "Intuition emerges in Maximum Caliber models at criticality", "authors": "Lluís Arola-Fernández", "background": "现有研究缺乏对大型预测模型是否只是简单重复训练数据还是能够产生真正的见解的物理解释。本文研究了一种新兴的直觉形式，它作为学习的亚稳态相出现，通过在预测模型中平衡下一个标记预测和未来路径熵来形成。这种方法通过对确定性迷宫中的随机漫步进行训练来揭示丰富的相图，包括模仿（低λ值）、打破规则的幻觉（高λ值）以及介于两者之间的脆弱窗口，展示强烈的协议依赖性和多稳定性，模型在此过程中自发发现新的目标导向策略。这些发现通过一个有效的低维理论得到解释，并将直觉视为预测模型中在记住了“是什么”和思考“可能是什么”之间的临界平衡点上涌现的一种性质。", "innovation": "本文通过引入最小原则，即在预测模型中使用类似控温参数的λ值来执行思维调节，并使其遵循最大量程原则，从而发现了一种形式的直觉机制。通过随机漫步迷宫的训练揭示了直觉形成的相图，并通过低维理论解释了模型在不同λ值下的表现，展示了一种在平衡记忆和想象之间形成直觉的新方法。", "conclusion": "在临界状态下，模型中的直觉涌现。这种直觉在平衡下一个标记预测和未来路径熵之间形成，并且数据显示模型在此状态下自发发现了新的目标导向策略。通过最小原则和最大量程模型的方法，该研究提供了一种新的理解模型预测能力以及直觉形成机制的视角。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06482", "html_url": "https://arxiv.org/abs/2508.06482", "title": "通过习惯形成提高通后训练的通信效率", "title_en": "Post-training for Efficient Communication via Convention Formation", "authors": "Yilun Hua,Evan Wang,Yoav Artzi", "background": "人类在多轮互动中通过调整语言和形成临时规则来提高交流效率。然而，现有的大型语言模型（LLMs）并未自然地表现出这种行为。", "innovation": "在后训练过程中，通过针对由启发式方法识别的习惯形成示例进行目标微调，开发了一种使LLMs获得这种能力的方法。同时设计了两个新的基准任务来评估这种能力：一个专注于习惯形成的互动基准，以及一个文档驱动的参考完成任务，模拟现实世界中的习惯形成行为。", "conclusion": "我们的研究结果显示，经过后训练的LLMs在两种评估方法中都显著提高了习惯形成的能力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.10649", "html_url": "https://arxiv.org/abs/2308.10649", "title": "基于强化学习的生物标记物传感器优化", "title_en": "Reinforcement Learning Based Sensor Optimization for Bio-markers", "authors": "Sajal Khandelwal,Pawan Kumar,Syed Azeemuddin", "background": "射频（RF）生物传感器，特别是基于指状电容（IDC）的传感器，在生物医学诊断、遥感和无线通信等领域至关重要。尽管这些传感器具有低成本和易于制造的优点，但它们的灵敏度可能受到设计缺陷、环境因素和电路噪声的影响。", "innovation": "该论文研究了使用新颖的基于强化学习的二进制粒子群优化（RLBPSO）方法来增强基于IDC的RF传感器的灵敏度，并将其与蚁群优化（ACO）和其他先进方法进行了比较。通过对诸如电极设计和指宽等设计参数进行优化，提出了的方法在各个频率范围内获得了显著的灵敏度改进。", "conclusion": "提出的RLBPSO方法在与目前最先进方法的比较中，在各种频率范围内提供了最佳优化设计。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.02613", "html_url": "https://arxiv.org/abs/2308.02613", "title": "从研究到临床：通过合成数据互操作性加速临床决策支持系统的转化", "title_en": "From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable", "authors": "Pavitra Chauhan,Mohsen Gamal Saad Askar,Kristian Svendsen,Bjørn Fjukstad,Brita Elvevåg,Lars Ailo Bongo,Edvard Pedersen", "background": "临床决策支持系统（CDSS）工具从研究环境转移到临床中通常很少实现，因为研究者的重点更多放在训练机器学习模型上，而不是使用模型开发工具。要将CDSS工具部署到临床工作流程中，需要将工具集成到电子健康记录（EHR）系统中并对其进行验证和测试。然而，研究人员难以获得访问EHR系统的权限，因为存在保护患者数据隐私的数据法律限制。因此，需提出一种使用合成数据的架构来简化CDSS工具的开发和测试。", "innovation": "提出了一个使用合成数据在EHR系统中的架构，该架构在SyntHIR系统中实施。SyntHIR架构有三个显著特点：(i) 与合成数据生成器集成，(ii) 数据互操作性，(iii) 工具可移植性。研究通过两个主要步骤评估了这种转化价值：一是基于挪威患者注册数据开发了一个基于机器学习的CDSS工具的可行性原型；二是成功在挪威最大的EHR系统提供商（DIPS）部署了该CDSS工具。这些发现展示了SyntHIR架构作为加速转化研究的有用参考模型的价值。", "conclusion": "该研究表明SyntHIR架构在加速CDSS工具从实验室到临床的应用方面具有重要的转化价值，可以作为加速CDSS工具临床转化的参考模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.14172", "html_url": "https://arxiv.org/abs/2308.14172", "title": "基于超图的机器学习的马尔可夫随机场模型", "title_en": "A Markov Random Field model for Hypergraph-based Machine Learning", "authors": "Bohan Tang,Keyue Jiang,Laura Toni,Siheng Chen,Xiaowen Dong", "background": "构建能够在保持泛化能力的同时保证鲁棒性和可解释性的机器学习模型需要理解数据生成过程。本文旨在解决在超图上建模数据生成过程的基本挑战，并探讨此类模型如何为超图数据的机器学习算法设计提供指导。", "innovation": "本文的主要创新在于开发了一种超图马尔可夫随机场模型，通过多元高斯分布来表示超图节点特征和超边特征的联合分布，其协方差矩阵由超图结构唯一确定。此外，本文还提出了两个新的框架：超图结构推断框架（HGSI）和基于超图的MLP框架（Hypergraph-MLP），用于超图上的节点分类。实验结果显示这两个新的框架在结构推断和节点分类任务上均优于现有方法。", "conclusion": "提出的两种框架在超图结构推断和节点分类方面表现出优越性，具体表现在 HGSI 在合成和真实数据上的优越性以及 Hypergraph-MLP 在六种超图节点分类基准上的表现优异，同时提高了运行效率并增强了对推理过程中结构扰动的鲁棒性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.17640", "html_url": "https://arxiv.org/abs/2312.17640", "title": "决策导向的悲观 bile KE 应优化的复杂性和算法", "title_en": "Decision-focused predictions via pessimistic bilevel optimization: complexity and algorithms", "authors": "Víctor Bucarey,Sophia Calderón,Gonzalo Muñoz,Frederic Semet", "background": "在优化参数中，中，，中的不确定性处理长期以来是一个重要的挑战。。。 我们 traditional常的处理方式是先行准确预测不确定参数，再 � � �然而后解决的确定一确定的最优化问题问题。。 但是这种所谓的预测-在--后优化的程序过程中可能导致决策高度敏感于不确定因素。 在本研究中我们提出了集中于优化决策的预测方法， �即构建旨在最小化决策所所后悔度量的预测模型", "innovation": "通过 on on考虑精确预期问题的悲观 bile KE 应优化方法", "conclusion": "通过使用二一最优性的方法 and 二我们确定问题问题在最常见的的双联通路径 Instance和以及不确定向权重上的实证"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.09478", "html_url": "https://arxiv.org/abs/2312.09478", "title": "熵因图在网络多元时间序列异常检测中的应用", "title_en": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection", "authors": "Falih Gozi Febrinanto,Kristen Moore,Chandra Thapa,Mujie Liu,Vidya Saikrishna,Jiangang Ma,Feng Xia", "background": "许多多元时间序列异常检测框架已经提出并广泛应用。然而，这些框架大多未考虑多元时间序列数据中变量之间的内在关系，从而忽视了变量间的因果关系，影响了异常检测的性能。", "innovation": "本文提出了一种新型框架CGAD（熵因果图），通过转移熵构建图结构来揭示时间序列数据中的潜在因果关系。利用加权图卷积网络和因果卷积来建模多元时间序列数据的时间模式。此外，CGAD使用异常评分，通过基于中值绝对偏差的标准化来提高异常识别过程的鲁棒性。", "conclusion": "广泛的实验表明，CGAD在实际数据集上优于最先进的方法，基于三种不同的多元时间序列异常检测指标，平均提高了9%的性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.02113", "html_url": "https://arxiv.org/abs/2404.02113", "title": "位置：生命周期调优与持续强化学习不兼容", "title_en": "Position: Lifetime tuning is incompatible with continual reinforcement learning", "authors": "Golnaz Mesbahi,Parham Mohammad Panahi,Olya Mastikhina,Steven Tang,Martha White,Adam White", "background": "在持续强化学习（Continual RL）中，我们希望代理能够在无限学习中保持能力，但现有的评估方法却没有反映这一点。传统上，强化学习（RL）假设代理在其全部生命周期内都可无限制地访问部署环境。例如，代理设计师通过每个测试2亿帧来选择在Atari上表现最佳的超参数，然后在2亿帧内报告结果。本文指出并证明了这种不合适的经验方法——生命周期调优带来的缺陷。通过在连续和非稳定环境中测试DQN和SAC，作者提供了实验证据以支持这一观点。", "innovation": "作者提供实验证据，证明了生命周期调优方法的缺点，特别是它无法识别适合持续学习的算法，并且新的持续强化学习算法在限制在代理生命周期的一部分内调优时优于传统非持续强化学习算法。这一发现解释了最近在持续强化学习方面的进步颇为参差不齐的原因，并呼吁发展更好的经验实践，以更好地匹配持续强化学习的目标。", "conclusion": "本文旨在解释为什么最近在持续强化学习方面的进展颇为参差不齐，并激发发展更匹配持续强化学习目标的经验实践。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.10665", "html_url": "https://arxiv.org/abs/2402.10665", "title": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation", "title_en": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation", "authors": "Bruno Laboissiere Camargos Borges,Bruno Machado Pacheco,Danilo Silva", "background": "在语义分割任务中，即使最先进的深度学习模型在某些高风险应用场景，如医学图像分析中也未能达到所需的性能。在这种情况下，可以通过让模型在置信度低时放弃预测，即选择性预测，来提高性能。选择性预测在分类任务中已有广泛应用，但在语义分割领域尚未受到充分探索。这篇论文针对这种情况，探讨了基于图像级别的放弃策略，并提出了一种新的置信度估计方法，以优化选择性预测在语义分割中的应用效果。", "innovation": "论文的主要创新在于提出了Soft Dice Confidence (SDC)，这是一种基于Soft Dice系数的近似最优置信度估计方法。SDC在已知边缘后验概率的情况下提供了最优置信度估计，并且即使在仅能估计边缘后验概率时，插值版本的SDC也优于先前所有方法，包括那些需要额外校准数据的方法。实验结果证明了SDC在合成数据和六项医学图像任务中的有效性，尤其是在分布外场景的表现。", "conclusion": "Soft Dice Confidence (SDC)作为一种高效的工具，为语义分割中的选择性预测提供了可靠的置信度估计，特别是在高风险应用场景中具有广泛应用前景。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.02689", "html_url": "https://arxiv.org/abs/2408.02689", "title": "长期交通时空部分感知预测", "title_en": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic", "authors": "Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Zhengkun Xiao,Yupu zhang,Haibo Wang,Shigang Chen", "background": "交通流量预测依赖于传感器在选择位置的近期测量数据。现有研究表明，要么所有位置都有传感器，要么重点关注短期预测。然而，当仅部分位置有传感器时，进行长期预测就很具有挑战性，因为未知未检测位置的数据分布、长期预测中的复杂时空相关性以及交通模式的噪声都会对预测造成影响。", "innovation": "本文提出了一种名为 SLPF（Spatio-temporal Long-term Partial sensing Forecast）的时空部分感知长期交通预测模型。该模型具有以下创新点：1) 采用排名为基础的嵌入技术来减轻数据中的噪声影响；2) 使用时空转换矩阵来应对感知和未感知位置之间的空间分布变化；3) 采用多步训练过程综合利用所有可用数据，逐步优化模型参数以提高预测准确性。", "conclusion": "通过对多个真实世界交通数据集进行大量实验，展示了该模型在预测准确性上的优越表现。其源代码可以从指定链接获取。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.02780", "html_url": "https://arxiv.org/abs/2403.02780", "title": "使用正交基选择和对齐的数据协作分析", "title_en": "Data Collaboration Analysis with Orthonormal Basis Selection and Alignment", "authors": "Keiyu Nosaka,Yuichi Takano,Akiko Yoshise", "background": "数据协作（DC）允许多个实体共同训练模型而不暴露其私有数据集。每个实体在其数据上使用秘密线性基进行私有转换，并仅分享结果的中间表示。现有理论认为，只要目标基底涵盖了秘密基底相同的子空间，任何目标基底都是足够的；然而，实际经验表明，具体选择的目标基底对模型的准确性和稳定性有显著影响。", "innovation": "本文引入了正交数据协作（ODC），这是一种新颖的DC框架，显式地在秘密基底和目标基底上应用正交约束。在这些约束条件下，基底对齐步骤精确地归结为古典正交Procrustes问题，并且拥有闭式解。我们严格证明，由此产生的正交变换矩阵达到了正交一致，使得所有实体的中间表示在共同的正交变换下对齐。因此，下游模型的性能不再受特定正交目标基底选择的影响。从计算上来看，ODC显著减少了对齐复杂度从O(min{a, (cl)^2, a^2cl})到O(acl^2)，其中a表示锚数据的大小，l是潜在维度，c是参与合作的实体数量。", "conclusion": "广泛的实证评估证实了ODC的理论优势，与最先进的DC方法相比，ODC在各个基准数据集上的性能提升可达两个数量级，并且具有可比或优越的准确性。ODC在半诚实威胁模型下保持了稳健的隐私性，并且只需要一次通信。这些结果确立了ODC为在现有DC管道中实用和计算效率高的增强，特别是在正交秘密基底自然可行的情况下。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.09222", "html_url": "https://arxiv.org/abs/2309.09222", "title": "通过双重正则化流的贝叶斯高斯过程ODEs", "title_en": "Bayesian Gaussian Process ODEs via Double Normalizing Flows", "authors": "Jian Xu,Shian Du,Junmei Yang,Xinghao Ding,John Paisley,Delu Zeng", "background": "近年来，高斯过程被用来建模连续动力系统的向量场，称为GPODEs，它们由具有概率ODE方程的模型定义。对于这些模型的贝叶斯推理已经被广泛研究并在时间序列预测任务中应用。然而，GPODE研究中通常使用标准的高斯过程和基础核函数（如平方指数核），这限制了模型对复杂场景的表示能力。", "innovation": "为了解决这一局限性，引入了正则化流来重新参数化ODE向量场，从而得到数据驱动的先验分布，增加模型的灵活性和表达能力。开发了一种数据驱动的变分学习算法，利用正则化流的解析概率密度函数，实现了未知连续动力学的同时学习和推理。此外，还使用正则化流来解决GPODE后验推理中的强均值场假设问题。通过这两种方式的应用，我们的模型提高了贝叶斯高斯过程ODEs的准确性和不确定性估计。", "conclusion": "我们在模拟动力系统和真实人类运动数据上验证了该方法的有效性，包括时间序列预测和缺失数据恢复任务。实验结果表明，在同时捕获模型不确定性方面，我们的方法有效且提高了准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.16726", "html_url": "https://arxiv.org/abs/2409.16726", "title": "两个神经网络之间的正式局部蕴涵", "title_en": "Formal Local Implication Between Two Neural Networks", "authors": "Anahita Baninajjar,Ahmed Rezine,Amir Aminifar", "background": "本文旨在比较两个具有相同输入和输出域的神经网络在特定输入区域的表现。研究在整输入区域D内网络N1在每次网络N2正确决策时都作出正确决策，并在整输入区域D中保持此正确性。进一步提出了一个严格的数学形式化验证方法来确保这种局部关系的正确性。这种方法适用于多个应用领域，如比较训练网络与其精简版本（例如，修剪、量化、蒸馏）之间的关系。", "innovation": "本文介绍了一个统一的形式化局部蕴涵验证框架，该框架具有严格的数学验证性，适用于比较不同版本的神经网络，并提供了一种新的方法来验证这种关系的有效性。该方法通过多个数据集的实验得到验证，展示了其在比较网络性能方面的有效性。", "conclusion": "本文提出的方法为比较不同结构和性能的神经网络提供了一种形式化和准确的方式，在多个实际应用领域（如医学影像分析）中具有重要意义。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.18601", "html_url": "https://arxiv.org/abs/2407.18601", "title": "通过表达性注意重组注意空间几何", "title_en": "Reorganizing attention-space geometry with expressive attention", "authors": "Claudius Gros", "background": "注意力机制通过查询向量和键向量的比较（通常使用标量积 &lt;Q, K>&gt; 来实现，随之进行软最大（softmax）归一化）来调节信息在词汇表之间的传递。标准的点积注意力（DPA）使得平行或反向平行的查询和键产生较大的注意权重，而在直角配置时则权重减小。研究指出，表达性注意力（EA）基于 &lt;Q, K>&gt;^2，允许在查询和键向量平行或反向平行时增加注意力权重，而在直角配置时则减少注意力权重。这种机制可以在任何基于注意力的模型中实现，而不会增加计算成本或内存需求。在一系列自回归预测任务中，研究发现，表达性注意力的表现至少与标准DPA相当，随着任务复杂度的增加，EA的性能逐渐优于DPA，并且在多任务设置中同样表现出这种趋势。对于给定的模型大小，EA可以在某些特定复杂度级别上达到100%的性能，这是DPA无法达到的。这些结果表明，只要不损失性能，就可以在注意力头的空间中重新组织匹配条件的几何结构。", "innovation": "提出了基于 &lt;Q, K>&gt;^2 的表达性注意力（EA），相比于标准点积注意力（DPA），EA 在查询向量和键向量平行或反向平行时增加注意力权重，在直角配置时减少注意力权重，从而通过重新组织注意力头空间中的几何结构来增强注意力机制的表达能力，同时保持与DPA相同的计算和内存效率。对于一系列自回归预测任务，研究证明了表达性注意力不仅至少与标准DPA相当，而且在更复杂的任务中表现更好，甚至可以实现DPA无法达到的100%性能。", "conclusion": "通过表达性注意力（EA），可以在不损失性能的前提下，在注意力头的空间中重新组织匹配条件的几何结构。在自回归预测任务中，EA不仅与标准点积注意力（DPA）表现相当，而且在复杂任务中表现更佳，对于相同模型大小，EA可以实现DPA无法达到的某些复杂度水平上的100%性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.15955", "html_url": "https://arxiv.org/abs/2501.15955", "title": "长尾分布下基础模型偏倚的重思考", "title_en": "Rethinking the Bias of Foundation Model under Long-tailed Distribution", "authors": "Jiahao Chen,Bin Qin,Jiangmeng Li,Hao Chen,Bing Su", "background": "长尾学习因其实际重要性而获得越来越多的关注。尽管微调范式在基础模型的出现后引起了很大的兴趣，但现有的许多方法主要集中在利用这些模型的知识上，而忽略了基础模型依赖的不平衡训练数据带来的固有偏见。本文探讨了这些不平衡对下游长尾任务的影响，发现基础模型中继承的不平衡偏向，如参数不平衡和数据不平衡，在下游任务中会影响模型的表现。", "innovation": "本文提出了一个新颖的后门调整方法，基于因果学习，并将不完整的语义因素视为混杂变量，试图消除输入样本与标签之间的虚假相关。具体方法是学习输入样本和标签之间的真正因果效应，而不仅仅是适配数据中的相关性。实验表明，该方法在每个数据集上提高了约1.67%的性能。", "conclusion": "本文通过分析基础模型在长尾分布下的偏见问题，提出了一种基于因果学习的后门调整方法来同时解决参数不平衡和数据不平衡的问题。最终，该方法在每个数据集上实现了约1.67%的平均性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.03845", "html_url": "https://arxiv.org/abs/2411.03845", "title": "重新评估GAE在链路预测中的性能", "title_en": "Reconsidering the Performance of GAE in Link Prediction", "authors": "Weishuo Ma,Yanbo Wang,Xiyuan Wang,Muhan Zhang", "background": "近期，图神经网络（GNN）在链路预测方面的进展引入了复杂训练技术和模型架构。然而，依赖过时的基准可能导致低估这些新方法的实际优势。为此，通过应用近期方法中的通用技巧并调整超参数，系统地研究了图自动编码器（GAE），发现在广泛使用的链路预测基准测试中，一个调优良好的GAE可以匹配甚至超越最新的复杂模型，同时在计算效率上更胜一筹。特别是在结构信息占主导且特征数据有限的数据集上，该方法取得了显著的性能提升。具体而言，GAE在ogbl-ppa数据集上实现了78.41％的最优Hits@100得分。此外，进一步考察了各种技巧，以揭示成功背后的原因，并指导未来方法的设计。该研究所强调的核心需要是更新基准，以便更准确地评估GNN在链路预测中的进展。", "innovation": "提出了一种通过应用近期方法中的通用技巧并调整超参数来系统研究GAE的方法。调优后的GAE能够在广泛使用的链路预测基准测试中匹配甚至超越最新的复杂模型，特别是在结构信息占主导且特征数据有限的数据集上取得了显著的性能提升。此外，该方法还深入探讨了各种技巧的作用，以揭示成功背后的原因，并指导未来方法的设计。", "conclusion": "调优后的GAE能够大幅提高链路预测的性能，特别是在结构信息占主导的数据集上。该研究强调了更新基准的必要性，以更准确地评估GNN在链路预测领域的进步。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00048", "html_url": "https://arxiv.org/abs/2502.00048", "title": "用于优化大语言模型理解的上下文纠缠梯度映射", "title_en": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension", "authors": "Colin Sisate,Alistair Goldfinch,Vincent Waterstone,Sebastian Kingsley,Mariana Blackthorn", "background": "现有的梯度优化方法在处理长段推理、上下文保持以及对未见过的领域适应方面存在局限性。传统的梯度更新方法将梯度视为孤立的数值实体，缺乏考虑上下文依赖性。这导致了在处理复杂语境时模型的性能下降和语义漂移问题。", "innovation": "CEGM通过将梯度视为动态携带上下文依赖性的载体，重新定义了上下文嵌入与梯度更新之间的关系，填补了现有优化策略的关键空白。该方法将纠缠的梯度动态引入损失正则化框架，显著提升了涉及长段推理、上下文保留和对未知领域适应的任务表现。", "conclusion": "实验结果表明，CEGM增强的模型在标记级别的预测准确性上优于基线方法，并且对噪声输入具有更强的鲁棒性。此外，该方法减少了序列转换过程中的语义漂移，并提高了跨同义句子嵌入的一致性，展示了该方法的稳健性和灵活性。这项研究阐明了梯度纠缠对于优化策略的理论发展和实际应用的重要意义。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03048", "html_url": "https://arxiv.org/abs/2502.03048", "title": "集成卡尔曼滤波更新是一个经验化的Matheron 更新", "title_en": "The Ensemble Kalman Update is an Empirical Matheron Update", "authors": "Dan MacKinlay", "background": "集成卡尔曼滤波(EnKF)是一种广泛应用于高维系统的数据同化方法，其包括一个与高斯过程回归中的Matheron 更新的实证版本相等价的集合更新步骤。这种联系将几十年来数据同化工程的研究和发展与现代基于路径的高斯过程采样联系起来。", "innovation": "本文提供了一个简洁但尚未充分开发的连接介绍，详细阐述了集成卡尔曼更新与Matheron 更新之间的关联性，使得不同领域的研究者都易于理解。", "conclusion": "该论文利用集成卡尔曼滤波与高斯过程回归之间的联系，为不同研究领域提供了一个新的视角，使得集成卡尔曼滤波器的同化能力更容易被理解和应用，且提供了相关代码以支持研究者进一步探索这一连接。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.03055", "html_url": "https://arxiv.org/abs/2411.03055", "title": "ATM: 通过交替调优和合并提高模型合并效果", "title_en": "ATM: Improving Model Merging by Alternating Tuning and Merging", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Fabrizio Silvestri,Emanuele Rodolà", "background": "模型合并已经作为多任务学习的一种成本效益较高的近似方法而出现。任务算术作为一种合并策略，因其简洁性和有效性脱颖而出。作者指出，在单轮梯度下降过程中，任务向量等同于多任务梯度，这种见解促使作者将模型合并重新诠释为迭代过程的一部分，即交替调优和合并（ATM）算法。", "innovation": "文章提出了交替调优和合并（ATM）算法作为两种应用：(1) 作为一种替代多任务学习的方法，特别是在数据共享受限的情况下（如联邦学习环境）；(2) 作为一种轻量级改进步骤，通过使用小规模验证集来提升现有的模型合并方法。实验结果证明了ATM的有效性。", "conclusion": "跨不同视觉任务的实验表明，交替调优和合并（ATM）是一个有效的方法，可以提高模型合并的效果。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14959", "html_url": "https://arxiv.org/abs/2501.14959", "title": "系统化的多样性：机器学习中的一个有趣现象", "title_en": "Systemizing Multiplicity: The Curious Case of Arbitrariness in Machine Learning", "authors": "Prakhar Ganesh,Afaf Taik,Golnoosh Farnadi", "background": "算法建模依赖于数据中的有限信息来外推未见过的情景的结果，经常在决策中嵌入一定程度的任意性。最近，任意性研究的一个视角是多样性，即研究一组“好模型”中的任意性，即这些模型可能在实践中被部署。本文通过系统化文献中的多样性研究，整理出了模型设计选择及其对任意性贡献的术语，扩展了多样性定义以包括超越预测和解释的未被充分关注的形式，并澄清了多样性与其他任意性概念（不确定性、方差）的区别，最后总结了多样性的好处和潜在风险，将其置于负责任的AI更广泛的语境中。", "innovation": "本文通过系统化文献中的多样性研究，首次形式化了关于模型设计选择及其对任意性的贡献的术语，将多样性定义扩展到包括未被充分关注的形式，清晰区分了多样性与其他类型任意性的区别，梳理出多样性带来的益处和潜在风险，并将其置于更广泛的负责任的人工智能背景下。", "conclusion": "本文确定了多样性的开放研究问题，并强调了该领域正在出现的发展趋势。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07700", "html_url": "https://arxiv.org/abs/2501.07700", "title": "通过QR离散经验插值法实现物理诱导神经网络的自适应插值点策略", "title_en": "Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method", "authors": "Adrian Celaya,David Fuentes,Beatrice Riviere", "background": "物理诱导神经网络（PINNs）近年来在求解涉及偏微分方程（PDEs）的正向和反向问题上获得大量关注。尽管在损失函数和网络架构上的进展提高了PINN的准确性，但固定采样方法，如均匀随机采样和等间距网格，在捕捉高解梯度的关键区域时往往表现不佳，这对复杂PDEs的有效性产生限制。自适应方法通过在训练过程中动态更新采样点进行改进，但可能会忽略更新之间的残差动态，从而丢失有价值的信息。", "innovation": "该研究提出了一种新的自适应插值点选择策略，该策略结合了QR离散经验插值法（QR-DEIM），一种用于高效近似非线性函数的降阶建模技术。该方法旨在克服固定采样方法和自适应方法的局限性，从而提高PINN的准确性，具有潜在的应用前景。", "conclusion": "研究结果表明，基于QR-DEIM的方法在基准PDEs中的模拟结果比现有方法更准确，为自适应插值点策略的发展提供了新的方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04592", "html_url": "https://arxiv.org/abs/2502.04592", "title": "CAMEF：结合时间序列模式和重要宏观经济公告的因果增强多模态事件驱动金融预测", "title_en": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements", "authors": "Yang Zhang,Wenbo Yang,Jun Wang,Qiang Ma,Jie Xiong", "background": "准确预测宏观经济事件的影响对于投资者和政策制定者至关重要。重要的事件，如货币政策决定和就业报告，通过塑造经济增长和风险的预期，来影响市场动向，并建立了事件与市场行为之间的因果关系。现有的预测方法主要侧重于文本分析或时间序列建模，但未能捕捉到金融市场多重模态的本质以及事件与价格变动之间的因果关系。", "innovation": "本文提出了CAMEF（因果增强多模态事件驱动金融预测），这是一种多模态框架，有效整合了文本和时间序列数据，并包含因果学习机制和基于LLM的反事实事件增强技术，以增强因果预测。文章的贡献包括：(1)一个能够捕捉政策文本与历史价格数据之间因果关系的多模态框架；(2)一个新的金融数据集，包含从2008年到2024年4月的六种类型的宏观经济公告，以及五个关键美国金融资产的高频实际交易数据；(3)一种基于LLM的反事实事件增强策略。通过对CAMEF与基于 Transformer 的最先进的时间序列和多模态基线进行比较，并通过消融研究验证因果学习机制和事件类型的有效性。", "conclusion": "研究表明，CAMEF在预测金融市场的因果关系方面表现出色，并通过整合时间序列模式和关键宏观经济公告提供了一种创新的预测方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01290", "html_url": "https://arxiv.org/abs/2503.01290", "title": "ACTIVA: 通过基于变压器的变分自编码器进行因果效应估算的投矢机制", "title_en": "ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder", "authors": "Andreas Sauter,Saber Salehkaleybar,Aske Plaat,Erman Acar", "background": "预测在假设干预下的结果分布对于医疗保健、经济学和政策制定都至关重要。然而，现有的方法通常需要一些限制性假设，且通常受限于无法在不同的问题实例之间共享知识。", "innovation": "我们提出了基于变压器的条件变分自编码器（VAE）架构ACTIVA，用于进行投矢化因果推理。ACTIVA可以直接从观察数据中估计干预分布，并能够通过利用各种训练场景中的因果知识来进行零样本推理。", "conclusion": "我们的理论研究表明，ACTIVA能够预测干预分布为观察上等价的因果模型的混合。在合成和半合成数据集上的实证评估证实了我们提出的投矢化方法的有效性，并指出了未来实际应用的有希望的方向。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05434", "html_url": "https://arxiv.org/abs/2502.05434", "title": "通过信息导向采样实现高效的人工反馈强化学习", "title_en": "Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling", "authors": "Han Qi,Haochen Yang,Qiaosheng Zhang,Zhuoran Yang", "background": "本文从理论角度研究了强化学习从人类反馈（Reinforcement Learning from Human Feedback, RLHF）的问题，这是训练大型语言模型的一个关键问题。以往的研究和实践中，尽管RLHF的重要性日益凸显，但对于其样本效率和理论基础仍有待深入探讨和优化。本文旨在通过设计基于信息导向采样（Information-Directed Sampling, IDS）的新颖算法来提高这一过程的样本效率，同时提升对未知环境的探索能力。", "innovation": "本文的主要创新点在于设计了基于IDS的新型样本高效RLHF算法。算法采用了在线决策原理，结合了价值函数和一个促进未知环境探索的信息互信息项。为应对大规模状态空间的挑战，作者构造了一个简化的代理环境，并引入了一种新的距离度量（\buster{\backslash}ell_g-距离），使得IDS算法达到了\buster{O}(H^{\frac{3}{2}}\backslashsqrt{\backslashlog(K(\backslashvarepsilon)) \backslashcdot T})的贝叶斯后悔上界。此外，作者还提出了一个计算效率更高的近似IDS算法（Approximate-IDS），该算法仍然保持了近似的样本效率，并且适用范围更为广泛。", "conclusion": "本文不仅展示了信息理论在强化学习和大型语言模型训练中的价值，还通过理论分析和算法设计，为RLHF问题的解决提供了新的视角和工具。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05560", "html_url": "https://arxiv.org/abs/2503.05560", "title": "由无监督几何深度学习揭示的全局图特征", "title_en": "Global graph features unveiled by unsupervised geometric deep learning", "authors": "Mirja Granfors,Jesús Pineda,Blanca Zufiria Gerbolés,Joana B. Pereira,Carlo Manzo,Giovanni Volpe", "background": "图形为复杂系统建模提供了一个强有力的框架，但其结构的多样性对分析和分类构成了重大挑战。尽管描述系统状态的相同或高度相似底层参数可能导致图实现的巨大变异，但现有的方法难以有效捕捉图形的局部细节和全局结构的不变特征。因此，提出了一种用于复杂图形分析的新颖无监督几何深度学习框架 GAUDI，以解决这些挑战。", "innovation": "GAUDI 采用了独特的 Hourglass 架构，该架构通过跳跃连接结合了分层下采样和上采样层，确保编码-解码过程中关键连通性信息的保真。即使相同的或高度相似的底层参数描述了系统状态，GAUDI 也能够将它们映射到一个结构化、连续的潜在空间中的邻近区域，使得不变的过程级特征能够从随机噪声中抽离出来。这种区别于其他相关方法的能力证明了 GAUDI 在多种应用中的优势，包括复杂网络建模、超分辨率显微镜下蛋白质组装的表征、Vicsek 模型中的集体运动分析以及与年龄相关的大脑连接变化识别上。", "conclusion": "与相关方法的比较表明，GAUDI 在分析复杂图形方面具有优越的性能，为不同科学领域的新兴现象提供了新的见解。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12756", "html_url": "https://arxiv.org/abs/2502.12756", "title": "在集装箱航运中导航需求不确定性：实现适应性和可行的主积载计划的深度强化学习", "title_en": "Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning", "authors": "Jaike van Twiller,Yossiri Adulyasak,Erick Delage,Djordje Grbic,Rune Møller Jensen", "background": "强化学习（RL）在解决多种组合优化问题方面显示出了潜力。然而，传统的RL在处理现实世界的约束时面临挑战，特别是在行动空间的可行性和状态或轨迹的依赖性方面。本文重点关注通过解决主积载计划问题（MPP）挑战，将RL应用于集装箱航运这一全球贸易的核心。本文旨在最大化货物收入，同时减少运营成本，并解决由需求不确定性引发的复杂运营约束，如船舶容量和稳定性，这些约束需要在整个航程中动态更新。", "innovation": "本研究提出了一种结合可行性投影的深度强化学习框架来解决在需求不确定性下的主积载计划问题，展示了在多阶段随机优化问题中找到适应性可行解的能力，该架构在性能上优于传统的混合整数规划和带有可行正则化的RL方法。通过AI驱动的决策支持策略，提供了在不确定性条件下的适应性和可行的计划，提高了运营效率和容量利用率，为全球可持续和弹性的供应链做出贡献", "conclusion": "实验结果表明，我们的架构可以有效找到适应性和可行的解决方案来应对多阶段随机优化问题，并优于传统混合整数规划和带有可行正则化的RL方法。我们的政策驱动的决策支持体系能够适应不确定性，并优化运营效率和容量利用率。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06728", "html_url": "https://arxiv.org/abs/2502.06728", "title": "DeToNATION: 解耦联的Torch网络智能在线节点训练", "title_en": "DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes", "authors": "Mogens Henrik From,Jacob Nielsen,Lukas Galke,Peter Schneider-Kamp", "background": "训练大型神经网络模型需要大量的计算资源，通常分布在多个节点和加速器上。最近的研究表明，可能只需要交换梯度的快速移动部分，同时在本地累积动量（称为Decoupled Momentum或DeMo）。然而，DeMo假设模型仅适用于一个加速器。该研究放松了这个假设，引入了一个称为FlexDeMo的新方法，它在不同加速器之间本地分割模型参数，同时通过仅同步快速移动部分而不是完整梯度来减少节点间通信，从而形成一种混合分割的数据并行训练策略。", "innovation": "研究引入了FlexDeMo，它实现了模型参数在不同加速器之间的本地分割，并通过仅同步快速移动的部分梯度来减少节点间通信，从而提出了一种混合分割的数据并行训练策略。研究还提出了一个名为DeToNATION的框架，该框架可以统一和推广DeMo，FlexDeMo和其他流行的分布式训练方案，引入了复制方案的新变体，并挑战了DeMo中的选择。结果显示，FlexDeMo在语言和视觉领域中获得与使用AdamW和完整梯度同步的混合分割数据并行训练相似的验证损失，但速度更快。", "conclusion": "因此，FlexDeMo是一种有前景的分布式训练方案，适用于最大的机器学习模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06836", "html_url": "https://arxiv.org/abs/2502.06836", "title": "CAST: 基于交叉注意力的结构和文本多模态融合材料性质预测", "title_en": "CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction", "authors": "Jaewan Lee,Changyoung Park,Hongjun Yang,Sungbin Lim,Woohyung Lim,Sehui Han", "background": "近期图神经网络（GNNs）的发展显著提升了通过将晶体结构表示为图的方式来预测材料性质的能力。然而，GNNs往往难以捕捉全局结构特征，如晶体系统，限制了它们的预测性能。先前的方法如CrysMMNet和MultiMat主要依赖于材料级别的聚合嵌入，而这些方法往往难以融合局部和整体结构特征，导致在预测某些关键材料性质（如形成能、带隙、体积模量和剪切模量）时效果不理想。", "innovation": "本文提出了一种基于交叉注意力机制的多模态模型CAST，该模型将图表示与材料描述性文本相结合，高效地保留了关键的结构和组分信息。CAST通过使用交叉注意力机制来结合精细粒度的图节点级特征和文本词元级特征，而不需要依赖材料级别的聚合嵌入。此外，引入了一种带遮蔽节点预测的预训练策略，进一步增强节点嵌入与文本嵌入之间的对齐。实验证明，CAST在四个关键材料性质上优于现有基线模型，相对平均绝对误差（MAE）的改进幅度在10.2%到35.7%之间。注意力图分析进一步证实了预训练在有效对齐多模态表示方面的重要性。", "conclusion": "本文研究的结果表明，多模态学习框架在材料科学中和发展更准确、更具全球信息的预测模型方面具有巨大潜力。CAST能够更精确地捕捉材料的全局和局部特征，提升了材料性质预测的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08727", "html_url": "https://arxiv.org/abs/2503.08727", "title": "使用深度上下文蒸馏进行插件即用型知识模块的训练", "title_en": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation", "authors": "Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni", "background": "在大型语言模型的预训练之后动态整合新信息或快速发展的信息依然具有挑战性，特别是在数据较少的情况下或处理私人和专业文档时更为困难。上下文学习和检索增强生成（RAG）方法存在一定的局限性，如高推理成本和无法捕获文档全局信息。", "innovation": "本文提出了一种模块化知识的方法，即训练文档级知识模块（KMs），这些模块作为参数效率高的LoRA模块实现，能够存储新文档的信息并根据需求插入到模型中。提出了一种新的学习方法——深度上下文蒸馏，通过学习KMs的参数使其模拟在上下文文档中工作的教师模型的隐藏状态和输出概率，这比标准的下一个词预测和预指令训练技术更具优势。", "conclusion": "与传统方法相比，对于两个数据集，本研究的方法在性能上取得了超越，突显了KMs和RAG之间的协同作用。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10143", "html_url": "https://arxiv.org/abs/2504.10143", "title": "多模态对齐中的跨模态偏差价值探索", "title_en": "On the Value of Cross-Modal Misalignment in Multimodal Representation Learning", "authors": "Yichao Cai,Yuhang Liu,Erdun Gao,Tianjiao Jiang,Zhen Zhang,Anton van den Hengel,Javen Qinfeng Shi", "background": "多模态表示学习，例如使用图像-文本对的多模态对比学习（MMCL），旨在通过在不同模态间对齐线索来学习强大的表示。然而，近期研究发现，现实世界的数据集通常存在跨模态偏差。对此，有两种不同的处理方式：一是在研究中减少偏差的影响，二是利用这些偏差作为学习的一部分。本文旨在解决这两种看似矛盾的观点，并提供一个实用指南给实践者。通过引入选择偏差和扰动偏差这两种特定机制，我们对偏差的影响进行了理论分析，发现MMLC学到的表示可以捕捉到在选择和扰动偏差下具保持性的语义变量信息。", "innovation": "本文提出了一种理论分析方法，通过引入选择偏差和扰动偏差来正式化跨模态偏差，并证明在轻微假设下，MMLC学习到的表示可以捕捉到在这些偏差下具保持性的语义变量信息。此外，文章还提供了如何利用偏差指导实际的ML系统设计的具体建议。最后通过两种数据集进行了实验证实了该理论分析的正确性。", "conclusion": "本文提供了对跨模态偏差现象的新颖理解，证明了在MMLC中利用这种偏差是有价值的，提出了一种指导实际系统设计的方法，并通过实验验证了这些理论发现。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16432", "html_url": "https://arxiv.org/abs/2504.16432", "title": "iTFKAN：柯莫哥洛夫-阿诺尔德网络实现可解释的时间序列预测", "title_en": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network", "authors": "Ziran Liang,Rui An,Wenqi Fan,Yanghui Rao,Yuxuan Liang", "background": "随着时间的推移，特定领域的数据展现出可预测性，推动了时间序列预测的发展，以从历史数据中预测未来趋势。然而，当前的深度预测方法虽然表现突出，但在像自动驾驶和医疗健康这样的安全关键应用中，由于缺乏可解释性，往往难以建立信任，阻碍了它们的实际部署。", "innovation": "本文提出了一种新颖的可解释模型iTFKAN，用于可靠的时序预测。iTFKAN通过模型符号化实现可解释性，允许进一步探索模型决策的理由和潜在的数据模式。此外，iTFKAN开发了两种策略：先验知识注入和时频协同学习，有效地指导模型在复杂交织的时间序列数据下的学习。", "conclusion": "大量实验结果表明，iTFKAN不仅能够取得令人满意的预测性能，同时还可以维持高解释能力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07912", "html_url": "https://arxiv.org/abs/2504.07912", "title": "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining", "title_en": "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining", "authors": "Rosie Zhao,Alexandru Meterez,Sham Kakade,Cengiz Pehlevan,Samy Jelassi,Eran Malach", "background": "RL（强化学习）在后训练语言模型中的微调被证明对于高级数学推理和编程至关重要。尽管在小型模型中使用RL微调也显示出稳定性能提升，但其背后的机制尚未完全理解。现有模型中训练数据的透明度不足，使研究难以区分预训练数据组成、超参数和模型规模对RL微调效果的影响。因此，深入分析RL微调对数学推理的影响是必要的，特别是通过系统研究不同的预训练数据混合比例下的模型训练全过程，探索不同规模模型的表现差异和迁移学习的效果。", "innovation": "研究首次全面探讨了不同混合预训练数据比例、多种RL微调算法（PPO、GRPO和Expert Iteration）以及不同模型规模对数学推理任务性能的影响。发现RL算法会一致地引导模型向主导输出分布收敛，放大预训练中的模式，并揭示了模型规模依赖的通用性的潜在因素。此外，通过在简单问题上使用RL后训练，研究还发现模型在复杂问题上的表现有所提升，这意味着某些推理能力在不同任务上的通用性。", "conclusion": "研究结果表明，即使是在受控的小规模环境里，简单的RL后训练也能揭示出RL对语言模型行为影响的有趣见解。因此，改进模型的设计方法和理解RL在模型微调中的作用将有助于提高数学推理的性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15103", "html_url": "https://arxiv.org/abs/2505.15103", "title": "Khan-GCL: 基于柯尔莫戈罗夫-阿诺尔德网络的具有硬负样的图对比学习", "title_en": "Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives", "authors": "Zihu Wang,Boxun Xu,Hejia Geng,Peng Li", "background": "图对比学习（GCL）已经证明了从未标记数据中学习可泛化的图表示的巨大潜力。然而，传统的GCL方法面临两个关键的限制：（1）基于多层感知机（MLP）的编码器的表达能力有限；（2）不理想的负样本，要么来自随机增强，未能提供有效的'硬负样'，要么生成强的负样本但没有解决对区分图数据至关重要的语义差异。", "innovation": "我们提出了Khan-GCL，这是一个新颖的框架，将柯尔莫戈罗夫-阿诺尔德网络（KAN）集成到GCL编码器架构中，显著增强了其表征能力。此外，我们利用KAN系数参数中丰富的信息来开发两种新颖的关键特征识别技术，使能够为每个图表示生成具有语义意义的强负样本。这些精心构造的强负样本通过强调图之间的关键语义差异来引导编码器学习更具区分性的特征。", "conclusion": "我们方法在各种数据集和任务中与现有的GCL方法相比达到了最先进的性能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02539", "html_url": "https://arxiv.org/abs/2506.02539", "title": "VerificAgent: 特定领域记忆验证以实现计算机使用代理的可扩展监督", "title_en": "VerificAgent: Domain-Specific Memory Verification for Scalable Oversight of Aligned Computer-Use Agents", "authors": "Thong Q. Nguyen,Shubhang Desai,Raja Hasnain Anwar,Firoz Shaik,Vishwas Suryanarayanan,Vishal Chowdhary", "background": "持续的记忆增强机制允许计算机使用的代理（CUAs）从先前的互动中学习，但未经审查的记忆可能会存储下领域不适当或不安全的经验法则，这些经验法则可能偏离用户的意图和安全约束。现有的研究需要一种可扩展的监督框架，以确保CUA的记忆和用户的意图及安全约束保持一致，同时避免额外的模型微调。", "innovation": "VerificAgent通过专家编写的领域知识种子、迭代的记忆增长机制和事后的人工事实检查过程，确保积累的记忆在部署前得到净化。这种方法不依赖于额外的模型微调，而是在模拟OSWorld生产力任务和对抗性压力测试中提高了任务可靠性，减少了幻觉引发的失败，并保留了可解释和可审计的指导，最终实现了一种称为验证记忆的“不变安全合同”，该合同能够约束未来代理的行为。", "conclusion": "VerificAgent证明了针对特定领域的、通过人类验证的记忆可以为CUA提供一种可扩展的监督机制，通过限制隐秘的政策漂移和使代理行为与目标领域的规范和安全约束保持一致，补充了更广泛的对齐策略。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24277", "html_url": "https://arxiv.org/abs/2503.24277", "title": "通过近似准正交性评估和设计稀疏自编码器", "title_en": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality", "authors": "Sewoong Lee,Adam Davies,Marc E. Canby,Julia Hockenmaier", "background": "稀疏自编码器（SAEs）在大型语言模型的机制可解释性研究中被广泛应用，但最先进的使用$k$-稀疏自编码器的方法缺乏选择表示非零激活数量的超参数$k$的理论基础，通常用$\boldsymbol{\beta}_0$表示。本文揭示了稀疏特征向量的$\boldsymbol{L}_2$范数可以与密集向量的$\boldsymbol{L}_2$范数用闭式误差近似，从而可以使稀疏自编码器在无需手动确定$\boldsymbol{\beta}_0$的情况下进行训练。", "innovation": "本文引入了两种创新应用：一是提出了一种新方法来评估预训练的稀疏自编码器的特征激活，该方法通过计算输入嵌入的理论期望值实现，而现有方法和损失函数未能捕捉到这一点；二是引入了一种新的激活函数top-AFA（基于我们的近似特征激活AFA的表述），该函数能够实现按top-$k$样式激活而无需调谐固定的超参数$k$，可动态确定每输入激活特征的数量。通过在GPT2隐藏嵌入的三个中间层上训练稀疏自编码器，并使用OpenWebText数据集上超过8000万个令牌，本文验证了这种方法的实证优势，并将其与当前最先进的$k$-稀疏自编码器进行了比较。", "conclusion": "本文通过理论分析揭示了稀疏特征向量$\boldsymbol{L}_2$范数与密集向量$\boldsymbol{L}_2$范数的近似关系，从而实现了稀疏自编码器的自动训练，并展示了该方法在评估稀疏自编码器特征激活方面的优势以及提出的top-AFA激活函数在不需要调参的情况下实现动态激活的潜力，最终在GPT2模型上的实验结果验证了该方法的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21152", "html_url": "https://arxiv.org/abs/2504.21152", "title": "SMOGAN: 使用GAN精炼的合成少数类过采样方法用于不平衡回归", "title_en": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression", "authors": "Shayan Alahyari,Mike Domaratzki", "background": "不平衡回归是指目标变量分布不均匀的预测任务。这种不平衡会让机器学习模型，特别是神经网络，集中在样本密集的地区，从而导致在数据下代表的（少数）样本上表现不佳。尽管这个问题非常重要，但只为不平衡回归提出的解决方案仍然很少。现有方法大多通过将从类别不平衡领域来的技术（如线性插值和高斯噪声添加）来生成合成数据。然而，很多情况下数据的真实分布是复杂的且非线性的，这使得现有方法生成的合成样本不能很好地反映真实的特征-目标关系。因此，为了克服这些问题，作者提出了SMOGAN，这是一个两阶段的过采样框架，用于不平衡回归。SMOGAN的第一阶段使用现有的过采样方法生成初始的合成样本，第二阶段使用DistGAN（一种分布感知的生成对抗网络）作为一种过滤层，通过结合对抗损失和最大均值离散度目标，来细化样本，使其更符合真实的联合特征-目标分布。", "innovation": "SMOGAN结合了现有的过采样方法和生成对抗网络（GAN），提出了一种两阶段框架来处理不平衡回归问题。第一阶段使用传统的方法生成初始的合成样本，第二阶段通过引入DistGAN，进一步优化这些样本，使其更符合真实的特征-目标分布。这是通过对样本进行对抗损失和最大均值离散度目标的优化来实现的，从而更好地反映了数据的真实分布情况。SMOGAN在23个不平衡数据集上的实验表明，它在大多数情况下能比没有DistGAN过滤层的默认过采样方法表现更好。", "conclusion": "SMOGAN方法在处理不平衡回归问题时通过两阶段的框架，结合传统过采样技术和GAN技术，显著提高了解决该问题的效果。实验结果表明，SMOGAN方法在多个不平衡数据集上表现出色，优于传统的过采样方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17631", "html_url": "https://arxiv.org/abs/2506.17631", "title": "Time-Prompt：时间序列预测中综合异构提示以解锁大型语言模型", "title_en": "Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting", "authors": "Zesen Wang,Lijuan Lan,Yonggang Li", "background": "时间序列预测旨在通过建模变量之间的时序依赖关系对未来状态进行推断，具有重要的实际应用场景。尽管深度学习方法取得了显著进展，但在长期预测和数据匮乏场景下表现仍待改善。最近研究表明，大型语言模型（LLMs）在时间序列预测方面表现出色，但现有LLM方法仍存在不足：缺乏统一的文本提示形成范式和忽视文本提示与时间序列模态差异。", "innovation": "本文提出LLM-Prompt框架，一种结合多提示信息和跨模态语义对齐的LLM基时间序列预测方法。该方法首先构建了一个包含可学习软提示和文本化硬提示的统一文本提示范式。其次，设计了一个语义空间嵌入和跨模态对齐模块，以实现时间和文本信息的跨模态融合。最后，变换后的时间序列被投影以获得预测结果。", "conclusion": "在6个公开数据集和3个碳排放数据集上的全面评估表明，LLM-Prompt是一个强大的时间序列预测框架。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00038", "html_url": "https://arxiv.org/abs/2507.00038", "title": "注重质量而非数量：一种基于点智能V信息的大规模数据缩减策略", "title_en": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "authors": "Fei Chen,Wenchi Zhou", "background": "为了提高模型训练的有效性，数据缩减在数据为中心的人工智能中至关重要。通过在大量数据集中定位最具启发性的示例来实现这一点。提高数据质量和训练效率的主要挑战在于选择最佳示例，而非完整数据集。因此，需要一种有效的数据缩减策略来帮助实现这些目标。", "innovation": "本文提出了一种基于点智能V信息（PVI）的有效数据缩减策略。首先，使用PVI量化实例难度并去除低难度实例；其次，采用渐进学习策略在按PVI递增排序的示例上训练分类器，加快收敛速度并实现比传统训练更高的准确率增益。", "conclusion": "我们的研究表明，采用选择优化子集进行训练可能在结合高效数据缩减策略的情况下提高模型性能并增强训练效率。此外，我们还将PVI框架从限于英语数据集扩展到多种中文自然语言处理任务和基础模型，提供了快速训练和跨语言数据缩减的有益结果。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03155", "html_url": "https://arxiv.org/abs/2506.03155", "title": "从多模态数据融合跨域知识以解决物理世界中的问题", "title_en": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World", "authors": "Yu Zheng", "background": "随着人工智能的普及，数字世界和物理世界的界限变得越来越模糊。然而，物理环境的复杂性使得单一种类的信息采集方法无法有效建模，因此，不同来源（如传感器、设备、系统和人类）生成的多模态数据的融合成为必要。然而，在无法从头收集原始数据的情况下，使用现有数据进行跨域知识融合是关键。现有研究集中在单一领域内多模态数据的融合，并假设不同数据集之间知识是内在一致的，但在跨域知识融合场景中，这一假设可能不成立。因此，本文正式定义了跨域多模态数据融合问题，并探讨了其特有的挑战和优势。", "innovation": "本文提出了一个四层框架来指导跨域多模态数据融合，包括 Domain（领域层）、Links（链接层）、Models（模型层）和 Data（数据层），并通过这三个关键问题（“融合什么”、“为什么能融合”、“如何融合”）来解决跨域多模态数据融合的问题。框架中，Domain 层选择相关数据，Links 层揭示跨域知识对齐的哲学，Models 层提供了基于数据处理基本机制的知识融合范式，Data 层将不同结构、分辨率、规模和分布的数据转换为可以输入AI模型的一致表示形式。", "conclusion": "通过这个框架，可以设计有效融合跨域多模态数据的解决方案，以解决实际世界中的问题。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22434", "html_url": "https://arxiv.org/abs/2507.22434", "title": "RANA: Robust Active Learning for Noisy Network Alignment", "title_en": "RANA: Robust Active Learning for Noisy Network Alignment", "authors": "Yixuan Nan,Xixun Lin,Yanmin Shang,Zhuofan Li,Can Zhao,Yanan Cao", "background": "网络对齐已在多个领域引起了广泛关注。然而，大多数现有工作主要关注标签稀疏性的问题，而忽视了网络对齐中的噪声问题，这可能显著削弱模型性能。这样的噪声主要包括来自噪音边的结构噪声和由人为和过程驱动的错误引起的标签噪声。", "innovation": "提出了RANA，一种鲁棒的主动学习框架，用于解决噪音网络对齐问题。RANA 利用了Noise-aware Selection Module（噪声感知选择模块）和Label Denoising Module（标签去噪模块）分别应对结构噪声和标签噪声，同时处理锚链接注释的稀疏性，以提高网络对齐模型的鲁棒性。RANA在此方面具有创新性，特别强调了对噪音和稀疏性的处理机制，并通过多源融合去噪策略提高了节点对的标签准确性。", "conclusion": "在三个真实数据集上的实证结果表明，RANA在对接精度方面优于最先进的基于主动学习的方法。我们的代码可在以下链接中获得：this https URL。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00806", "html_url": "https://arxiv.org/abs/2508.00806", "title": "Adacc: 一种统一压缩与激活重计算的自适应框架用于大规模语言模型训练", "title_en": "Adacc: An Adaptive Framework Unifying Compression and Activation Recomputation for LLM Training", "authors": "Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo", "background": "培训大型语言模型（LLMs）通常受到GPU内存限制的约束。为了缓解内存压力，已经提出了激活重新计算和数据压缩两种主要策略。然而，这两种方法都存在局限性：重新计算会增加显著的训练开销，而简单的压缩方法可能会导致准确性下降和计算效率低下。", "innovation": "本文提出了一种名为Adacc的新框架，它是第一个集成了激活重新计算和数据压缩的自适应内存优化框架，旨在提高LLMs的训练效率，同时保持模型准确性。Adacc通过层特定的压缩算法、基于MILP的调度策略以及策略进化机制来解决三个关键挑战，相较于现有的方法，能够提高1.01x至1.37x的训练吞吐量，同时保持与基准相当的准确性。", "conclusion": "实验结果显示，与最先进的框架相比，Adacc在保持与基线相当的准确性的同时，可以将训练吞吐量提高1.01x到1.37x。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01646", "html_url": "https://arxiv.org/abs/2508.01646", "title": "SPARTA: 基于突触时间优先性的稀疏注意机制在脉冲神经网络中的进展", "title_en": "SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization", "authors": "Minsuk Jang,Changick Kim", "background": "现有的脉冲神经网络（SNNs）未能充分利用基于尖峰的时间动态性，主要依赖率编码而非精确的时间信息，后者能提供丰富的计算线索。", "innovation": "提出了SPARTA（Spiking Priority Attention with Resource-Adaptive Temporal Allocation），一个利用异质神经动力学和尖峰时间信息的框架，以实现高效的稀疏注意。SPARTA基于时间线索对令牌进行优先级排序，如尖峰模式、尖峰时间和间峰间隔，通过竞争门机制实现65.4%的稀疏度。SPARTA选择最显著的令牌，将注意力复杂度从O(N^2)减少到O(K^2)，其中k远小于n，同时保持高准确性。", "conclusion": "我们的方法在DVS-Gesture（98.78%）和CIFAR10-DVS（83.06%）及CIFAR-10（95.3%）上达到了最先进的性能，证明利用尖峰时间动态性可以同时提高计算效率和准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "ScIReN：发现碳循环中隐藏关系及其超越", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "理解土壤中碳的流动对于缓解气候变化至关重要。虽然土壤具有从大气中固碳的潜力，但人们对土壤碳循环的理解仍然不足。虽然科学家们基于现有知识开发了数学过程模型，但由于存在许多未知参数，这些模型往往是基于经验的方法进行调整的，并且常常无法很好地拟合观察结果。另一方面，神经网络可以从数据中学习模式，但它们无法遵守已知的科学定律，也无法揭示由于其黑箱性质而产生的新型科学关系。为了克服以上问题，研究人员提出了一个可解释的框架——科学可解释推理网络（SciReN），该框架结合了可解释的人工神经网络和基于过程的推理能力，以此确保模型具有透明性，并揭示输入特征和潜在参数之间的关系。SciReN 利用柯尔莫哥洛夫-阿诺尔德网络（KAN）确保编码器是完全可解释的，并解释输入特征和潜在参数之间的关系；它还使用新颖的光滑性惩罚来平衡表达性和简单性，并引入了新颖的硬 sigmoi d约束层来将潜在参数限制在由科学先验知识定义的有意义范围内。", "innovation": "SciReN 是一个完全透明的框架，它结合了可解释的人工神经网络和基于过程的推理能力。SciReN 利用了柯尔莫哥洛夫-阿诺尔德网络（KAN）确保编码器是完全可解释的；它还使用了新颖的光滑性惩罚来平衡表达性和简单性；并且通过引入硬 sigmoi d约束层来将潜在参数限制在科学先验知识定义的范围内。此外，过程解码器遵守已知的科学知识，而 KAN 基础的编码器则揭示了传统黑箱模型中隐藏的科学关系。举例说明，SciReN 能在模拟土壤中有机碳的流动和植物生态系统呼吸两方面表现出色和科学解释性--它能够推理出潜在的科学机制及其与输入特征的关系，而传统的黑箱网络无法完成这些功能。", "conclusion": "ScIReN 在预测准确性方面优于传统黑箱网络，同时在科学解释性方面提供了显著的改进，能够在保持模型透明性的同时揭示隐藏在传统模型中的科学关系，这为理解和模拟碳循环提供了新的途径。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17792", "html_url": "https://arxiv.org/abs/2507.17792", "title": "跨多个领域多传感器系统的因果机制估计", "title_en": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains", "authors": "Jingyi Yu,Tim Pychynski,Marco F. Huber", "background": "为了通过因果关系的视角更深入地理解复杂的传感器系统，本文提出了一种新颖的因果机制估计（CICME）方法，这是一种将异构数据从多个领域收集后进行因果机制推断的三步方法。该方法利用因果迁移学习（CTL）原理，在提供足够样本的情况下，能够可靠地检测到领域不变的因果机制。然后利用确定的共同因果机制引导每个领域的剩余因果机制估计。研究通过基于线性高斯模型，受制造过程启发的场景对CICME进行评估。该方法建立在现有的基于连续优化的因果发现方法之上，展示了这种方法在对合并数据以及单个领域数据多次进行因果发现的好处，并证明在某些场景下，该方法优于现有基准方法。", "innovation": "利用因果迁移学习（CTL）在异构数据上推断因果机制，适用于不同领域的情况。通过利用合并数据和单个领域数据进行重复因果发现的优势。提出了CICME方法，可以可靠地检测领域不变的因果机制，并能够引导特定领域中的剩余因果机制估计。这种方法在特定场景下表现出优于现有基准方法的效果。", "conclusion": "本文提出了一种新颖的因果机制估计（CICME）方法，该方法利用领域不变的因果机制推断和迁移学习原理，结合合并数据和单个领域数据进行因果发现。通过线性高斯模型和制造过程启发的场景评估，CICME在某些场景下优于现有基准方法，适用于多传感器系统的因果研究。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02840", "html_url": "https://arxiv.org/abs/2508.02840", "title": "通过知识蒸馏和粒子群优化实现高效的自动软件漏洞评估", "title_en": "Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization", "authors": "Chaoyang Gao,Xiang Chen,Jiyu Wang,Jibin Wang,Guang Yang", "background": "软件系统的日益复杂性导致了网络安全漏洞的激增，需要有效的解决方案来评估这些漏洞。然而，大型预训练模型在实际应用中的部署受到了计算和存储需求的限制。", "innovation": "提出了一种资源高效框架，结合了知识蒸馏和粒子群优化以实现自动漏洞评估。该框架通过两阶段方法优化了紧凑型学生模型的架构，并通过知识蒸馏将大型教师模型的关键漏洞评估知识转移给优化的学生模型。这种方法显著减少了模型大小，同时保持了高性能。", "conclusion": "在增强的MegaVul数据集上进行的实验表明，该方法将模型大小减少了99.4%，同时保持了89.3%的原始模型准确率。与最先进的基线相比，它在准确率方面提高了1.7%，参数减少了60%。此外，该框架的训练时间减少了72.1%，架构搜索时间减少了34.88%，相比传统的遗传算法效率更高。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10215", "html_url": "https://arxiv.org/abs/2507.10215", "title": "神经网络的图充分性视角", "title_en": "A Graph Sufficiency Perspective for Neural Networks", "authors": "Cencheng Shen,Yuexiao Dong", "background": "本文通过图变量和统计充分性分析神经网络，将神经网络层视为基于图的变换，神经元作为输入和学习锚点之间的对偶函数。在此框架下，研究了层输出在给定输入变量条件下保留目标变量条件分布的情况，探讨了基于图的观点下的两条理论路径。", "innovation": "提出了两种理论路径：一种假设密集锚点，在无限通道极限下证明渐近充分性并保持整个训练过程；另一种路径假设分区输入分布，并构建适当的锚点以证明有限通道网络中的精确或近似充分性，这可以确保无限层数的充分性，并为回归和分类任务提供最优损失的误差界。", "conclusion": "本文框架涵盖了全连接层、一般对偶函数、ReLU和sigmoid激活以及卷积神经网络，将统计充分性、图论表示与深度学习结合在一起，为神经网络提供了一种新的统计理解。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03872", "html_url": "https://arxiv.org/abs/2508.03872", "title": "极端规模湍流数据集的智能采样以实现准确高效的时空模型训练", "title_en": "Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training", "authors": "Wesley Brewer,Murali Meena Gopalakrishnan,Matthias Maiterth,Aditya Kashi,Jong Youl Choi,Pei Zhang,Stephen Nichols,Riccardo Balin,Miles Couchman,Stephen de Bruyn Kops,P.K. Yeung,Daniel Dotson,Rohini Uma-Vaideswaran,Sarp Oral,Feiyi Wang", "background": "随着摩尔定律和 Dennard 效率法则的终结，高效的模型训练越来越需要重新考虑数据量。如何通过智能采样显著减少数据量同时训练出更好的模型，是一个亟待解决的问题。", "innovation": "该研究开发了 SICKLE，一种稀疏智能的数据集采样框架，该框架具备新颖的最大熵采样方法、可扩展的训练策略及能耗评估功能。研究者通过与随机采样和相空间采样方法比较于大规模直接数值模拟湍流数据集，证明了在预处理步骤中采样可以提升模型的准确性并大幅降低能耗。", "conclusion": "在 Frontier 超级计算机上评估 SICKLE，结果显示在某些情况下最大熵采样方法相较于随机采样和相空间采样方法，可以将能耗降低多达 38 倍的同时提高模型的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03267", "html_url": "https://arxiv.org/abs/2508.03267", "title": "HALO: 后见之明增强的学习在在线自动竞价中的应用", "title_en": "HALO: Hindsight-Augmented Learning for Online Auto-Bidding", "authors": "Pusen Dong,Chenglong Cao,Xinyu Zhou,Jirong You,Linhe Xu,Feifan Xu,Shuo Yuan", "background": "在线广告平台通过实时竞价（RTB）系统以毫秒级运行拍卖，广告商通过算法投标竞争广告位，确保精准的目标受众。然而，由于广告商的多样性（预算和ROI目标跨度极大），这种动态机制引入了巨大的操作复杂性。传统的自动投标解决方案在这类环境中存在两个关键缺陷：一是样本效率低下，在特定约束下失败的探索无法提供可转移的知识给新的预算-ROI组合；二是即使在约束转换时，它们也无法有效利用约束之间的物理关系和投标系数。因此，迫切需要一种能够适应不同预算和ROI要求的多约束自动投标方法。", "innovation": "提出了HALO：后见之明增强的学习方法，该方法通过引入理论支持的后见之明机制，将所有探索重新用于任意约束配置的训练数据生成中，通过轨迹重定向实现。此外，HALO 使用B样条函数表示法，使投标映射在约束空间中连续且具有导数感知性，确保即使在测试时预算和ROI需求与训练场景显著不同也能实现稳健的适应。", "conclusion": "工业数据集评估表明，HALO 在处理多尺度约束时表现出色，能够减少约束违规情况，并提高GMV。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04792", "html_url": "https://arxiv.org/abs/2508.04792", "title": "Federated Continual Recommendation", "title_en": "Federated Continual Recommendation", "authors": "Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu", "background": "随着推荐系统对隐私保护的日益重视，联邦学习（Federated Learning, FL）被用作保护隐私的一种解决方案，能够实现协作训练而不共享用户数据。尽管联邦推荐（Federated Recommendation, FedRec）能够有效保护隐私，现有的方法在处理非平稳数据流时存在问题，无法保持推荐质量的持续稳定。而持续学习推荐（Continual Learning Recommendation, CLRec）方法则能够应对不断变化的用户偏好，但通常假设中心化的数据访问，使得它们不符合FL的约束条件。", "innovation": "本文提出了一种新的任务Federated Continual Recommendation（FCRec），结合了FedRec和CLRec的优势，要求模型在维护隐私的同时学习来自流式数据的知识。为了实现这一目标，提出了一种框架F3CRec，能够平衡知识保留和适应能力，同时在FCRec的严格限制下工作。F3CRec引入了两个关键组件：客户端的自适应重放记忆，根据用户特定的变化选择性地保留过去偏好；服务器端的项目时间平均，能够整合新知识的同时保留先前的信息。", "conclusion": "大量实验证明，F3CRec在联邦环境下的推荐质量具有更好的保持能力，优于现有方法。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2304.01576", "html_url": "https://arxiv.org/abs/2304.01576", "title": "MESAHA-Net: 基于多编码器自适应硬注意力网络结合最大强度投影的CT扫描肺结节分割", "title_en": "MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan", "authors": "Muhammad Usman,Azka Rehman,Abd Ur Rehman,Abdullah Shahid,Tariq Mahmood Khan,Imran Razzak,Minyoung Chung,Yeong Gil Shin", "background": "准确的肺结节分割对于早期肺癌诊断至关重要，因为它可以显著提高患者的生存率。CT图像广泛用于肺结节分析的早期诊断。然而，肺结节的异质性、大小多样性以及周围环境的复杂性给开发稳健的结节分割方法带来了挑战。", "innovation": "我们提出了一个高效的端到端框架，称为基于多编码器的自适应硬注意力网络（MESAHA-Net），用于CT扫描中的精确肺结节分割。MESAHA-Net包括三个编码路径、一个注意力块和一个解码块，支持CT切片片段、正向和反向最大强度投影（MIP）图像以及包括结节的感兴趣区域（ROI）掩码的三种类型输入。通过采用新颖的自适应硬注意力机制，MESAHA-Net逐片地进行2D分割，聚焦于每个切片中的结节区域，生成3D体积分割结果。该框架在LIDC-IDRI数据集上进行了全面评估，这是目前肺结节分割中最大的公开数据集。结果显示，我们的方法对于不同类型的肺结节高度鲁棒，相比之前的技术在分割精度和计算复杂度上均有所提升，适合实时临床应用。", "conclusion": "综上所述，MESAHA-Net有效地解决了肺结节分割中的挑战，提供了高性能的3D肺结节分割解决方案，有望在临床中得到实际应用。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05118", "html_url": "https://arxiv.org/abs/2508.05118", "title": "通过强化学习探索卓越的功能调用", "title_en": "Exploring Superior Function Calls via Reinforcement Learning", "authors": "Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang", "background": "大型语言模型在实际应用中的功能调用能力至关重要，但当前的训练方法无法培养出稳健的推理策略。监督微调生成的模型依赖浅显的模式匹配，而标准的强化学习方法在处理结构化功能调用的复杂动作空间时表现出色，而采用特定策略增强熵探索的强化学习框架被提出以解决功能调用中的三个关键挑战：学习策略时探索不足、链式思考生成缺乏结构化推理以及参数提取验证不足。", "innovation": "本文提出了一种通过优化策略增强熵探索的新强化学习框架，专门针对功能调用任务。该框架通过两阶段数据预处理管道确保高质量的训练样本，并在伯克利函数调用领军人榜上的实验中显示出卓越的表现，整体准确率达到86.02%，甚至在复杂多函数情景上比标准GRPO高出6%。特别地，该方法对于预训练代码模型表现尤为显著，表明结构化语言生成能力可以为功能调用任务的强化学习提供优势起点。", "conclusion": "框架在伯克利函数调用领军人榜上展示了领先性能；两阶段的数据预处理确保高质量训练样本；对于预训练代码模型有显著提升。所有代码、模型和数据集将开放发布。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.03253", "html_url": "https://arxiv.org/abs/2404.03253", "title": "初级鼻咽癌MRI数据集及其多模态分割", "title_en": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation", "authors": "Yin Li,Qi Chen,Kai Wang,Meige Li,Liping Si,Yingwei Guo,Yu Xiong,Qixing Wang,Yang Qin,Ling Xu,Patrick van der Smagt,Jun Tang,Nutan Chen", "background": "多模式磁共振成像(MRI)数据有助于鼻咽癌(NPC)的早期诊断、肿瘤分割和疾病分期管理。然而，缺乏全面公开的数据集限制了诊断、治疗计划以及机器学习算法的发展。", "innovation": "该研究引入了首个全面的NPC MRI数据集，包含277例未治疗的NPC患者的MRI轴向影像，并涵盖了T1加权、T2加权和对比增强T1加权序列，总计831个扫描。此外，该数据集还包含由经验丰富的放射科医生进行的手动标注和标记的分割结果，提供了高质量的数据资源。", "conclusion": "通过提供全面的多模式MRI数据集和高质量的分割标注，该研究为NPC的诊断、治疗计划以及机器学习算法的发展做出了重要贡献。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05568", "html_url": "https://arxiv.org/abs/2508.05568", "title": "X-VFL: 一种新的带交叉完成和决策子空间对齐的垂直联邦学习框架", "title_en": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment", "authors": "Qinghua Yao,Xiangrui Xu,Zhize Li", "background": "垂直联邦学习（VFL）通过整合来自多个客户端/参与方的不同的特征子集来实现协作学习。然而，VFL通常面临两个关键挑战：i) 所有客户端之间需要完美对齐的数据样本（不允许缺失特征）；ii) 全部客户端需要参与联合协作推断/预测（不支持单个客户端上的局部独立推断）。", "innovation": "本文提出了X-VFL，一个新的VFL框架，旨在处理非对齐数据样本，支持部分缺失特征，并允许每个客户端上的局部独立推断。特别地，X-VFL设计了两个新颖模块：交叉完成（XCom）和决策子空间对齐（DS-Align）。XCom利用其他客户端的信息来完成或重构非对齐数据样本中的缺失特征。DS-Align在决策子空间内对局部特征与已完成和全局特征进行对齐，从而允许每个客户端上的局部独立推断。此外，还提供了不同算法在X-VFL训练过程中收敛性的理论，显示了SGD类型算法的$O(1/\text{根号} T)$收敛率和PAGE类型算法的$O(1/T)$收敛率。严格的实验证明，X-VFL在涉及到部分缺失特征和局部独立推断的场景中，显著优于现有方法，例如，在图像CIFAR-10数据集上的准确率提高了15%，在医学MIMIC-III数据集上提高了43%。", "conclusion": "这些结果证实了X-VFL在实用有效性和优越性上的实际有效性，特别是在涉及部分缺失特征和局部独立推断的情景中。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.04938", "html_url": "https://arxiv.org/abs/2311.04938", "title": "使用矩匹配高斯混合模型改进DDIM采样", "title_en": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures", "authors": "Prasad Gabbur", "background": "这篇论文探讨了在Denoising Diffusion Implicit Models (DDIM)框架中使用高斯混合模型（GMM）作为反向过渡操作符（核）的方法，该框架是用于加速预训练的Denoising Diffusion Probabilistic Models (DDPM)从加速采样的主要方法之一。论文中作者具体实现了通过约束GMM参数确保DDPM前向边际的一阶和二阶中心矩匹配。", "innovation": "作者提出了一种创新的方法，即将GMM作为DDIM框架中的反向过渡操作符，通过约束GMM参数以匹配DDPM的前向边际的一阶和二阶中心矩。实验结果显示，这种矩匹配的方法足以获得与原始DDIM使用高斯核相当或质量更好的样本。作者还在无条件模型、类条件模型和文本到图像生成分别在CelebAHQ、FFHQ和COYO700M数据集上进行了实验，验证了这种方法的有效性。", "conclusion": "实验结果表明，在采样步数较少的情况下，使用GMM核能显著提高生成样本的质量，这通过FID和IS度量指标进行评估。例如，在ImageNet 256x256的数据集上，使用10步采样时，使用GMM核的FID为6.94，IS为207.85，而使用高斯核的FID为10.15，IS为196.73。此外，作者还为正则化流匹配模型推导了新的SDE采样器，并实验了所提出的方法，进一步验证了其改进效果。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.04417", "html_url": "https://arxiv.org/abs/2310.04417", "title": "使用随机特征的扩散模型的泛化界", "title_en": "Generalization Bound for Diffusion Models using Random Features", "authors": "Esha Saha,Giang Tran", "background": "扩散概率模型已被成功应用于从噪声中生成数据。然而，大多数扩散模型在计算上代价高昂且难以解释，缺乏理论依据。另一方面，随机特征模型因其可解释性而备受关注，但它们在复杂机器学习任务中的应用仍然有限。", "innovation": "本文提出了一种基于扩散模型的可解释的深随机特征模型，该模型与具有相同参数数量的全连接神经网络相比具有可比的数值结果。具体来说，我们在随机特征方面扩展了现有结果，使用评分匹配的属性推导出了数据样本分布与真实分布之间的泛化界。", "conclusion": "我们通过在时尚MNIST数据集和乐器音频数据上生成样本来验证我们的发现。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.02342", "html_url": "https://arxiv.org/abs/2409.02342", "title": "最优采样方法在最小二乘逼近中的应用", "title_en": "Optimal sampling for least-squares approximation", "authors": "Ben Adcock", "background": "最小二乘逼近是通过数据恢复未知函数的重要方法。在许多实际应用中，数据是固定的；而在其他应用中，则可以自由选择采样位置。本文回顾了在任意线性空间中，(加权)最小二乘逼近的近最优随机采样策略的最新进展。", "innovation": "引入了克里斯托菲尔函数作为分析随机采样基于权重的最小二乘逼近的关键量，提出了利用这种函数构造名为克里斯托菲尔采样的随机采样策略，该策略具有近最优的采样复杂度，即样本数与逼近空间的维度对数呈线性关系。此外，讨论了这一方法的多种变体、扩展和进一步的议题，并强调了其与逼近理论、机器学习、基于信息的复杂性和数值线性代数的联系。", "conclusion": "鉴于现代应用的多种情况，本文从一般化的角度来看待传统场景，其中样本不一定是标量函数的点样本，而逼近空间也不一定是非线性的。证明即便是这种更为一般的场景下，适当的克里斯托菲尔函数仍然决定了采样复杂度。因此，这些函数可用于设计统一的改进型克里斯托菲尔采样策略，以解决一般恢复问题。本文在很大程度上是自包含的，旨在使非专家也能理解。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.02596", "html_url": "https://arxiv.org/abs/2407.02596", "title": "更具现实性的提取攻击：一个对手视角", "title_en": "Towards More Realistic Extraction Attacks: An Adversarial Perspective", "authors": "Yash More,Prakhar Ganesh,Golnoosh Farnadi", "background": "语言模型容易记住其训练数据，这使它们容易受到提取攻击。现有的研究更多的是关注单一模型或固定提示的孤立设置。然而，在现实世界中，对手可以接触到各种规模和检查点的模型，并且可以通过重复提示来扩大攻击面。本文从对手的角度重新审视提取攻击，并发现即使提示的微妙变化或瞄准较小的模型和较早的检查点，也能提取出不同的信息。通过结合多种攻击，对手将提取风险翻倍，即使采取数据去重等缓解策略也是如此。", "innovation": "本文从对手多方面接触底层数据的角度出发，重新研究提取攻击。通过实验发现，即使提示有微妙变化或针对较小的模型和较早的检查点，也能提取出不同的信息。通过多攻击组合，对手将提取风险翻倍，并且即使在采用数据去重策略时仍然存在这种风险。通过四例案例研究展示了该对手模型如何优于文献中的现有对手，展示了如何在预训练数据、版权侵权、提取个人身份信息和攻击封闭源代码模型方面取得优势。", "conclusion": "通过案例研究表明，本文提出的更现实的对手模型可以在多样化的攻击场景中超越现有对手模型，展现了该模型在检测预训练数据、版权侵权、提取个人身份信息和攻击专有模型等方面的有效性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.08668", "html_url": "https://arxiv.org/abs/2407.08668", "title": "使用分布型神经网络建模降水空间极值依赖性", "title_en": "Modeling Spatial Extremal Dependence of Precipitation Using Distributional Neural Networks", "authors": "Christopher Bülte,Lisa Leimenstoll,Melanie Schienle", "background": "本文背景在于通过使用生成神经网络进行模拟建模，以确定降水最大值及其在时间和空间上的不确定关系，并在最大稳定过程的常见框架下进行分析，特别是在考虑时间依赖性和空间依赖性的极端事件建模中。研究还关注在2021-2023年德国西部的月度降雨最大值，该时间段因为2021年7月的极端降雨和随后的洪水事件而特别受到关注，这是因为该事件造成了巨大的人员伤亡。", "innovation": "本文的主要创新点在于提出了一种基于模拟的方法，利用生成神经网络来确定降水最大值之间的依赖关系及其时空不确定性。具体包括：\n1. 该方法在估计过程参数及其不确定性方面具有优势。\n2. 提供了通过极限系数函数的非参数空间依赖性估计的显式表示。\n3. 研究方法能容忍复杂的设置，即使不能直接进行封闭性似然估计也能取得良好表现。\n4. 方法和技术在其他应用中的潜在价值。", "conclusion": "通过对2021-2023年间德国西部的月度降雨最大值进行深入研究，本文展示了该方法的有效性和鲁棒性。研究结果表明，该方法可用于研究复杂极端降雨事件，为极端气候事件的风险评估和管理提供重要支持。此外，本文方法和主要生成思想具有广阔的应用前景，可应用于其他相关领域。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.09105", "html_url": "https://arxiv.org/abs/2406.09105", "title": "INS-MMBench: 评估保险领域LVLM性能的综合基准", "title_en": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance", "authors": "Chenwei Lin,Hanjia Lyu,Xian Xu,Jiebo Luo", "background": "大型视觉-语言模型（LVLMs）和多模态大型语言模型（MLLMs）已在各种一般多模态应用中表现出色，并在特定领域显示出日益增长的潜力。然而，它们在保险领域的潜力——涵盖多种应用情景和丰富的多模态数据——尚未得到充分探索。目前，尚未对多模态任务进行系统性综述，也没有专门设计来评估LVLMs在保险领域的基准测试工具。这阻碍了保险行业内LVLMs的发展。本研究系统性地审查并分类了代表性的四种保险类型（汽车保险、财产保险、健康保险和农业保险）的多模态任务。我们推出了INS-MMBench，这是专门为保险领域设计的第一个分层级基准。INS-MMBench包含22个基础任务、12个元任务和5个情景任务，能从基本能力和现实应用场景进行全面评估。我们对11种领先LVLMs进行了基准测试，包括GPT-4o等封闭源模型和LLaVA等开源模型。我们的评估证实了INS-MMBench的有效性，并提供了LVLMs在各种保险相关多模态任务中的强项和局限性细节。我们希望INS-MMBench能加速LVLMs在保险行业的应用并促进跨学科研究。我们的数据集和评估代码可在[该链接]获取。", "innovation": "介绍了INS-MMBench，这是为保险领域设计的第一个分层级基准。它包含22个基础任务、12个元任务和5个情景任务，全面评估LVLMs的性能。此外，对11种领先的LVLMs进行了基准测试，包括GPT-4o和LLaVA等不同类型的模型。该研究还提供了详细的评估结果，揭示了当前LVLMs在保险相关多模态任务中的强项和局限性。", "conclusion": "INS-MMBench能够帮助加速LVLMs在保险行业的应用，并促进跨学科研究。我们希望该基准能促进更多研究，以进一步改进LVLMs在保险领域的应用。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17080", "html_url": "https://arxiv.org/abs/2411.17080", "title": "DeepMDV：多仓库车辆路由问题的全局空间匹配", "title_en": "DeepMDV: Global Spatial Matching for Multi-depot Vehicle Routing Problems", "authors": "Saeed Nasehi,Farhana Choudhury,Egemen Tanin,Majid Sarvi", "background": "随着在线零售和电子商务的迅速发展，高效的车辆路径规划（VRP）解决方案变得尤为重要。随着公司增加更多的仓库，多仓库车辆路径规划（MDVRP）问题变得更为复杂，多个仓库的车辆调度决策高度依赖，传统的VRP方法在这种情况下变得次优且不可扩展。这个问题使得传统的VRP方法在处理MDVRP的效率和效果上显得不足，因此迫切需要新的方法来解决这一问题，尤其是能够有效地同时对仓库和路径问题进行建模的方法。", "innovation": "本文提出了一个创新的方法来解决MDVRP问题。该方法的关键理念是将MDVRP分解为两个核心的时空任务：客户分配给对应的仓库以及在每个仓库内的路径优化。该方法采用了任务解耦的方法，并设计了一个两阶段框架：首先有一个依赖于分区模块，通过嵌套空间和行程的背景信息在表示空间内全局匹配客户到仓库；其次是一个独立的路径规划模块，确定每个行程的最佳访问顺序。实验结果显示该方法在合成和现实数据集上的表现都优于现有的所有基准方法，包括基于学习的单仓库VRP单点优化解法。这使其成为一个适用于实际物流挑战的实用而易于部署的解决方案。", "conclusion": "该方法在不同规模的问题上具有适应性和良好的性能，展示了其在多仓库VRP问题上的适用性和实用性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.01273", "html_url": "https://arxiv.org/abs/2410.01273", "title": "CANVAS：直观的人机交互常识导向导航系统", "title_en": "CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction", "authors": "Suhwan Choi,Yongjun Cho,Minchan Kim,Jaeyoon Jung,Myunchul Joe,Yubeen Park,Minseo Kim,Sungwoong Kim,Sungjae Lee,Hwiseong Park,Jiwan Chung,Youngjae Yu", "background": "现实中的机器人导航不仅仅是达到目的地的问题，还需要在特定场景下优化运动表现。人类通过口头指令或草图等抽象提示来表达导航目标，虽然这种方式缺乏细节或存在噪音，但要求机器人能够准确执行这些抽象指令。因此，机器人需要与人类共享基本的导航概念理解，以此来正确执行人类的指令意图。本文针对这一需求，提出了CANVAS，这是一种新颖的框架，能够结合视觉和语言指令进行常识导向导航，通过模仿学习，使机器人能够从人类的导航行为中学习。文章还介绍了COMMAND数据集，这是一个包含超过48小时和219公里的导航结果的综合数据集，旨在训练常识导向的导航系统在模拟环境中的表现。实验表明，在所有环境中，CANVAS的表现优于基于规则的强系统ROS NavStack，并且在具有噪音指令的情况下，其性能更为优越，在果园环境中，ROS NavStack没有成功案例，而CANVAS却达到了67%的成功率。此外，CANVAS在未知环境中的表现与人类演示和常识约束高度一致，即使在这种环境下，它也能实现高达69%的成功率，展示了模拟环境中从人类演示学习的应用潜力，将其应用于现实世界时展现出显著优势。", "innovation": "提出了CANVAS，一种结合视觉和语言指令进行常识导向导航的新颖框架。通过模仿学习，使机器人能够从人类的导航行为中学习。引入了COMMAND数据集，该数据集包含超过48小时和219公里的导航结果，用于训练常识导向的导航系统。CANVAS在多种环境中表现出色，尤其是能有效处理具有噪音指令的导航任务，并且在未知环境中的表现与人类演示和常识约束高度一致。", "conclusion": "CANVAS系统通过模仿学习实现了从人类演示中的学习，提高了机器人在复杂环境中执行常识导引导航任务的能力，即使在具有噪音指令的情况下，CANVAS也明显优于现有的基于规则的方法。实验结果证明，CANVAS在模拟环境中从人类演示学习的有效性，并且在现实世界的部署中也表现出显著的优势。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13818", "html_url": "https://arxiv.org/abs/2502.13818", "title": "建筑年代估计：一种新的多模态基准数据集和社区挑战", "title_en": "Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge", "authors": "Nikolaos Dionelis,Alessandra Feliciotti,Mattia Marconcini,Devis Peressutti,Nika Oman Kadunc,JaeWan Park,Hagai Raja Sinulingga,Steve Andreas Immanuel,Ba Tran,Caroline Arnold,Nicolas Longépé", "background": "估算建筑物的建造年代对于推动可持续性至关重要，因为较老的建筑通常缺乏能效特性。可持续的城市规划依赖于准确的建筑年龄数据，以减少能源消耗和减轻气候变化的影响。", "innovation": "该论文介绍了MapYourCity，这是一个新颖的多模态基准数据集，包含高清顶视图影像、多光谱地球观测数据（来自Copernicus Sentinel-2星座）和街景图像，数据覆盖了多个欧洲城市。每个建筑都被标记了其建造年代，形成了一个七类分类问题，时间跨度从1900年至今。该团队组织了一个社区驱动的数据挑战，吸引了广泛的参与，并展示了四个表现最佳的模型及其评估结果。", "conclusion": "研究成果表明，即使在未参与训练的城市和仅使用高清顶视图卫星影像（即VHR和Sentinel-2图像）的情况下，建筑年代估计也是可行且有效的。因此，新的MapYourCity数据集为可持续城市数据分析中可扩展的实际解决方案提供了有价的价值资源。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.14428", "html_url": "https://arxiv.org/abs/2412.14428", "title": "WildSAT: 从野生动物观察学习卫星图像表示", "title_en": "WildSAT: Learning Satellite Image Representations from Wildlife Observations", "authors": "Rangel Daroya,Elijah Cole,Oisin Mac Aodha,Grant Van Horn,Subhransu Maji", "background": "物种分布包含了丰富的生态和环境信息，但在遥感领域中，这些信息被用于引导表示学习的应用还处于起步阶段。作者介绍了一种名为WildSAT的系统，它结合了卫星图像和大量的地理标记野生动物观察记录，这些观察记录可以从公民科学平台上获得。", "innovation": "WildSAT采用对比学习方法，结合卫星图像、物种分布图和文本栖息地描述来训练或微调模型。这种方法显著提高了多样化的卫星图像识别任务的性能，优于基于ImageNet预训练的模型和专门针对卫星图像的基线。此外，通过使视觉和文本信息对齐，WildSAT实现了零样本检索，使得用户可以根据文本描述搜索地理位置。与最近的跨模态学习方法相比，WildSAT展示了其方法的优势。最后，作者分析了关键设计选择的影响，并强调了WildSAT在遥感和生物多样性监测中的广泛应用潜力。", "conclusion": "最终，作者指出，尽管选择了一些关键设计选择，但WildSAT在跨域遥感任务中显示出了显著的优势，并具有广泛的适用性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23145", "html_url": "https://arxiv.org/abs/2503.23145", "title": "CodeARC: 评估基于LLM代理的归纳程序合成推理能力基准", "title_en": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "authors": "Anjiang Wei,Tarun Suresh,Jiannan Cao,Naveen Kannan,Yuheng Wu,Kai Yan,Thiago S. F. X. Teixeira,Ke Wang,Alex Aiken", "background": "现有的基于大型语言模型（LLM）的代理在编程任务中显示出潜力，特别是在由自然语言引导的任务中。然而，它们在归纳程序合成方面的表现尚不明确。当前的评估协议依赖于静态的数据集以及预留的测试集，当合成出的函数不正确时无法提供反馈，并且未能反映现实世界的情况，如逆向工程。同时，缺乏一个大规模且通用的基准测试来全面评估LLM在归纳程序合成中的表现，尤其是生成代码以适应新输入的能力是待改进的地方。因此，需要设计一种新的评估框架，能够更加真实地测试并挑战这些代理在推理和反馈的基础上改进解决方案的能力。", "innovation": "提出了一种新的评估框架CodeARC（Code Abstraction and Reasoning Challenge），该框架允许代理与隐藏的目标函数交互，通过查询新输入、合成候选函数并使用差分测试或acles迭代优化解决方案。这种方式鼓励代理进行函数调用，并根据反馈进行自我纠错。另外，构建了一个大规模的基准测试，包含1114个函数，共有18个模型被评估。这使得研究人员第一次能够大规模、系统地评估LLM在归纳程序合成中的表现。此外，通过微调LLaMA-3.1-8B-Instruct模型，取得了相对31%的性能提升，进一步验证了这个框架的有效性。", "conclusion": "CodeARC为评估和提升基于LLM的程序合成与归谬推理能力提供了一个更真实且具有挑战性的环境。它不仅有助于理解LLM在处理复杂抽象任务时的局限性，还促使研究人员开发改进模型的方法。研究者提供的代码、数据和模型已公布，供进一步研究使用。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.05223", "html_url": "https://arxiv.org/abs/2501.05223", "title": "EVA-S2PLoR: 分散的安全二方对数回归与微妙哈达马乘积协议（完整版本）", "title_en": "EVA-S2PLoR: Decentralized Secure 2-party Logistic Regression with A Subtly Hadamard Product Protocol (Full Version)", "authors": "Tianle Tao,Shizhao Peng,Tianyu Mei,Shoumo Li,Haogang Zhu", "background": "在私有聚合机器学习（PPML）中，准确实施非线性算子（例如Sigmoid函数）于异构数据集是一个主要挑战。现有的大多数框架通过线性操作进行近似，这不仅导致显著的精度损失，还增加了大量的计算开销。", "innovation": "本文提出了一种名为EVA-S2PLoR的高效、可验证、准确的隐私2方逻辑回归框架，该框架通过微妙的安全哈达马乘积协议及其衍生协议实现了准确的非线性函数计算。所有协议基于一个实用的半诚实行业安全性模型，该模型适用于平衡效率、精度和安全性的去中心化隐私保护应用环境。通过浮点数的异步计算流程和哈达马乘积协议中的少量固定通信轮次，确保了高性能和高精度，并通过维度转换和蒙特卡洛方法保证了鲁棒的异常检测能力。EVA-S2PLoR在精确度方面超过了多个先进的框架，并且在安全逻辑回归实验中整体表现最佳，与原始模型相比，分类准确率差异仅约0.5%，在WAN设置下的训练时间减少了47.6%以上，同时将Sigmoid函数的性能提升了大约10个数量级。", "conclusion": "EVA-S2PLoR通过基于微妙的安全哈达马乘积协议及其衍生协议的实现，显著提高了隐私保护逻辑回归的性能，即使在WAN环境下也只需较少的训练时间，能实现高效、高精度和高安全性并举。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05734", "html_url": "https://arxiv.org/abs/2412.05734", "title": "LeakAgent：基于强化学习的LLM隐私泄露红队代理", "title_en": "LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage", "authors": "Yuzhou Nie,Zhun Wang,Ye Yu,Xian Wu,Xuandong Zhao,Wenbo Guo,Dawn Song", "background": "最近的研究发现，大型语言模型（LLM）可能在精心构造的对抗提示下被‘欺骗’输出私人信息，包括训练数据、系统提示和个人身份信息。现有的隐私泄露红队方法要么依赖手动努力，要么仅关注系统提示提取，这使得它们在应对训练数据泄露的严重风险方面无效。因此，开发一种新的黑盒红队框架来解决LLM隐私泄露问题变得迫切。", "innovation": "该论文提出了LeakAgent，这是一种基于强化学习的新型黑盒红队框架，用于LLM隐私泄露。LeakAgent通过训练开源LLM作为攻击代理来生成对抗提示，用于训练数据提取和系统提示提取。该框架创新地设计了一种新的奖励函数，提供了有效的细粒度奖励，并设计了新的机制来平衡学习过程中的探索和利用，从而增加了对抗提示的多样性。", "conclusion": "通过广泛评估，LeakAgent在训练数据提取和系统提示泄露方面显著优于现有的基于规则的方法。LeakAgent还在OpenAI的GPT Store中展示了从真实应用程序中提取系统提示的有效性。它还证明了能够规避现有防护措施并有助于实现更好的安全对齐。通过详细的消融研究验证了我们的定制设计，并且已经发布代码。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.15509", "html_url": "https://arxiv.org/abs/2501.15509", "title": "FIT-Print: 通过目标指纹识别对抗虚假索赔的模型所有权验证", "title_en": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint", "authors": "Shuo Shao,Haozhe Zhu,Hongwei Yao,Yiming Li,Tianwei Zhang,Zhan Qin", "background": "模型指纹识别是一种广泛采用的方法，用于保护开源模型的知识产权，防止其未经授权的重复使用。这种方法很有前景且便捷，因为它不需要修改受保护的模型。然而，现有的指纹识别方法容易受到虚假声明攻击，即攻击者试图声明第三方模型为自己的。这些方法的普遍不足在于它们未针对特定参考进行比较，而是将给定样本在不同模型上的输出进行对比。因此，作者重新审视现有的指纹识别方法，并提出了一个目标导向的指纹识别框架（即FIT-Print）以对抗虚假声明攻击。FIT-Print通过优化将指纹转换为目标签名。在此基础上，作者开发了两种基于模型输出与特征指派之间距离的黑盒模型指纹识别方法，即FIT-ModelDiff和FIT-LIME。这些方法有效地验证了FIT-Print的有效性、可转移性以及对抗虚假声明的能力，并在基准模型和数据集上进行了广泛验证。", "innovation": "提出了一个名为FIT-Print的目标导向指纹识别框架，通过优化将指纹转换为目标签名，有效对抗虚假声明攻击。基于FIT-Print原理，开发了两种新方法，FIT-ModelDiff和FIT-LIME，后者利用模型输出与特定样本的特征归属之间的距离作为指纹，有效提高了模型指纹识别的效能和可靠性。FIT-Print方法有效验证了模型所有权，并且具备高度的通用性和鲁棒性，尤其是在应对虚假声明攻击时。这种方法为理解和保护模型知识产权提供了新的解决方案。", "conclusion": "FIT-Print通过优化将指纹转化为目标签名，并通过两种新方法（FIT-ModelDiff和FIT-LIME）实现更加有效的模型所有权验证。广泛实验表明，FIT-Print在验证模型所有权、转移性和抵抗虚假声明攻击方面表现卓越。这些创新为保护知识产权提供了新的技术工具，同时也扩大了现有框架应用的可能性和范围。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14810", "html_url": "https://arxiv.org/abs/2504.14810", "title": "DONOD：通过模型固有数据剪裁实现LLMs高效且通用的指令微调", "title_en": "DONOD: Efficient and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning", "authors": "Jucheng Hu,Surong Yang,Lijun Wu,Dongzhan Zhou", "background": "针对特定领域的需求，大型语言模型（LLMs）通常采用自适应微调的方法进行调整。虽然监督微调（SFT）有效率并具有高效的调整特性，但它可能会削弱跨领域的泛化能力且难以处理嘈杂的训练数据。", "innovation": "提出了DONOD方法，这是一种轻量级的内在数据剪裁方法。DONOD使用两种基于模型参数的度量标准来评估数据：Delta of Norm (DON) 和 Norm of Delta (NOD)，并通过TOPSIS算法有效过滤掉噪声、无法学习和损害泛化能力的数据，而不需要使用辅助模型。实验证明，DONOD在数学任务上的微调效果更为优越，并能够提高对嘈杂数据的鲁棒性。", "conclusion": "通过过滤全数据集的70%，DONOD在目标域和跨域中的准确率分别提高了14.90%和5.67%。我们的选择数据在跨架构泛化上表现出色，较小模型（例如Llama 3.1-8B）剪裁的数据能够很好地泛化到较大的模型（例如Llama 2-13B）。与现有相关方法相比，DONOD在保持泛化性和兼容性的同时表现更优，且不依赖外部数据集，具有更强的通用性。代码将公开提供。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05104", "html_url": "https://arxiv.org/abs/2506.05104", "title": "音乐生成模型评估的综述", "title_en": "Survey on the Evaluation of Generative Models in Music", "authors": "Alexander Lerch,Claire Arthur,Nick Bryan-Kinns,Corey Ford,Qianyi Sun,Ashvala Vinay", "background": "近年来，音乐生成系统的研究受到了相当的关注和增长。为了系统地评估这些系统，已经尝试了多种方法。", "innovation": "本文对音乐生成系统评价的目标、方法和指标进行了跨学科综述，涵盖了主观和客观方法、定性和定量方法以及实验和计算方法，并从音乐学、工程学和人机交互学的角度分析了这些方法的优缺点。", "conclusion": "文章对音乐生成模型的评估方法进行了全面的分析，有助于促进相关研究的进一步发展和改进。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15254", "html_url": "https://arxiv.org/abs/2504.15254", "title": "CRUST-Bench: C到安全Rust编译的综合基准", "title_en": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation", "authors": "Anirudh Khatry,Robert Zhang,Jia Pan,Ziteng Wang,Qiaochu Chen,Greg Durrett,Isil Dillig", "background": "对于现代复用旧版C代码并提升安全性与现代Rust生态系统的互操作性而言，C到Rust的编译转换是必不可少的。然而目前尚未有用于评估系统能否将C转换为安全且通过测试用例的Rust代码的数据集。CRUST-Bench通过引入一个包含100个C仓库的数据集，每个仓库都配有一个手动编写的在安全Rust中的接口以及可以验证编译正确性的测试用例来填补这一空白。这种方法考虑的是整个仓库而不是单个函数，因此能够捕捉到多文件项目中跨文件依赖的任务挑战。", "innovation": "CRUST-Bench的数据集创新之处在于它通过整个仓库来捕捉复杂的项目翻译挑战，同时提供显式的Rust接口规格以确保遵循约定俗成的、内存安全的Rust模式，并通过配套的测试用例来确保功能正确性。文中还评价了最先进的大语言模型（LLMs）在这一任务上的表现，并发现生成安全且符合语义的Rust代码仍然是一个具有挑战性的问题。此外，文章还提供了关于LLMs在从C到安全Rust编译代码时通常会犯的错误的见解。", "conclusion": "改善CRUST-Bench将会导致能够处理复杂情形并帮助从C等语言迁移旧代码库到Rust等保证内存安全的语言的改进编译系统。最佳模型OpenAI o1在单跳设置下仅能解决15个任务。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14848", "html_url": "https://arxiv.org/abs/2505.14848", "title": "MAATS：基于MQM评估的多代理自动翻译系统", "title_en": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation", "authors": "George Wang,Jiaqian Hu,Safinah Ali", "background": "当前翻译系统大多依赖于单一AI代理进行自动纠错和改进，这种方法可能依赖于自我纠正机制，并且可能在处理复杂翻译任务（如语义准确性、地域适应性和语言对远距离的情况）时表现不佳。", "innovation": "MAATS引入了多代理系统，每个代理专注于MQM的不同维度（如准确度、流畅度、风格和术语），并通过综合代理将注释集成起来，实现翻译的逐步精细化改进。这种设计显著提高了在自动评估指标和人类评估中的表现，特别是在语义准确性和跨语言对远的距离的语言方面的表现。", "conclusion": "MAATS通过可解释的MQM维度模块化的代理角色对，减少了黑盒LLMs与人工翻译工作流程之间的差距，重点关注深层语义和上下文的准确性，提高了多层错误诊断、不同视角的遗漏检测和上下文意识改进的能力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM: 基于潜在分布的世界模型在预测性操控中的应用", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,JIazhao Zhang,Shilong Zou,XInwang Liu,Ruizhen Hu,Kai Xu", "background": " embodied AI 领域中，预测性操控近年来引起了广泛关注。这主要得益于它通过利用预测状态来提升机器人策略表现的潜力。然而，从世界模型中生成准确的未来视觉状态，特别是在实现高质量的像素级表示方面，仍是一个尚未解决的难题。", "innovation": "提出了一种名为LaDi-WM的世界模型，它使用扩散建模来预测未来状态的潜在空间。该模型结合了预训练视觉基础模型（VFMs）中的几何特征（基于DINO）和语义特征（基于CLIP），发现预测潜在空间的变化比直接预测像素级图像更容易学习和泛化。在此基础上设计了一种逐步细化输出动作的扩散策略，通过整合预测状态来生成更一致和准确的结果。", "conclusion": "在合成和真实场景的广泛实验中证明，与LIBERO-LONG基准相比，LaDi-WM的策略性能提高了27.9%，在真实场景中提高了20%。此外，该世界模型和策略在现实世界实验中表现出色，具有很强的泛化能力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18602", "html_url": "https://arxiv.org/abs/2505.18602", "title": "LLM-Meta-SR：符号回归中选择算子的上下文内学习进化", "title_en": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression", "authors": "Hengzhe Zhang,Qi Chen,Bing Xue,Wolfgang Banzhaf,Mengjie Zhang", "background": "大语言模型（LLMs）已经彻底改变了算法开发，但在符号回归中的应用仍然受到限制，通常需要人工专家手动设计。现有的基于LLM的算法进化技术存在两大关键局限：缺乏语义指导和代码膨胀。缺乏语义感知会导致有效的代码组件交换无效，而代码膨胀会带来不必要的复杂组件，两者都会降低所设计算法的可解释性，或者阻碍进化学习进程。因此，提出了一种元学习框架，使LLMs能够自动设计符号回归算法的选择算子，从而克服这些挑战。", "innovation": "该论文提出了两个关键创新：一个语义感知的选择算子和对代码膨胀的控制。此外，通过嵌入领域知识到问题提示中，使LLMs能够生成更有效且上下文相关的选择算子。实验结果表明，采用这种方法设计的选择算子在多项基准测试中优于九种专家设计的基线，并且能够进一步优化当前最好的符号回归算法，实现了116个回归数据集中26种符号回归和机器学习算法的最佳性能。这表明LLMs在符号回归算法设计中可以超越专家级水平。", "conclusion": "研究结果表明，LLMs能够通过进化选择算子实现符号回归问题中前所未有的性能提升，展示出了在无监督学习环境下进行创新算法设计的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19991", "html_url": "https://arxiv.org/abs/2507.19991", "title": "SAMUeL: 通过软对齐注意力和潜在扩散实现高效语音条件音乐生成", "title_en": "SAMUeL: Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion", "authors": "Hei Shing Cheung,Boya Zhang,Jonathan H. Chan", "background": "目前现有的音乐AI系统存在一些关键的局限性，这促使研究者们提出新的方法来改进音乐伴奏生成的效果。", "innovation": "该研究引入了一种新颖的软对齐注意力机制，该机制能够根据扩散时间步骤自适应地结合局部和全局时间依赖性，从而有效地捕捉多尺度的音乐结构。该模型在预训练的变分自编码器的压缩潜在空间中运行，相比最先进的系统，参数减少达220倍，同时预测速度提高了52倍。包含15M参数的模型在生产工艺质量和内容一致性方面优于OpenAI Jukebox，同时保持了合理的音乐连贯性。这个极其轻量级的架构使得模型可以在消费级硬件上实现实时部署，从而使得辅助AI音乐创作更加适用于互动应用和资源受限的环境。", "conclusion": "实验评估表明，该模型仅使用15M参数，性能与OpenAI Jukebox相当或更好，同时在生产质量和内容一致性方面表现更优，保持了合理的音乐连贯性。该模型架构轻便，能够在消费级硬件上实现实时部署，为互动应用和资源受限环境的AI辅助音乐创作提供了可能。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00915", "html_url": "https://arxiv.org/abs/2508.00915", "title": "利用机器学习增强优化加速车队升级决策", "title_en": "Accelerating Fleet Upgrade Decisions with Machine-Learning Enhanced Optimization", "authors": "Kenrick Howin Chai,Stefan Hildebrand,Tobias Lachnit,Martin Benfer,Gisela Lanza,Sandra Klinge", "background": "租赁业务模式和日益增加的可持续性需求加强了管理大型机器和车辆车队更新和升级的有效策略的需求。优化的车队升级策略最大化了总体效用、成本和可持续性。然而，传统的车队优化方法没有考虑到升级选项，基于整数规划，当处理大型车队和重复决策过程时，导致了计算成本的显著增加。", "innovation": "首先提出了一种扩展的整数规划方法来确定最优更新和升级决策。为了减轻计算负担，还提供了一种替代的基于机器学习的方法，将其转化为混合离散-连续优化问题。两个方法都在实际的汽车工业案例研究中进行了评估，结果显示机器学习方法达到了近似最优解，显著提高了可扩展性和整体计算性能，使其成为大规模车队管理的实用替代品。", "conclusion": "两种优化方法在实际案例中进行了评估，表明机器学习方法在可扩展性和计算性能方面取得了显著的改进，对于大型车队管理而言更具实际应用价值。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09082", "html_url": "https://arxiv.org/abs/2506.09082", "title": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models", "title_en": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models", "authors": "Zheda Mai,Arpita Chowdhury,Zihe Wang,Sooyoung Jeon,Lemeng Wang,Jiacheng Hou,Wei-Lun Chao", "background": "随着视觉基础模型(VFMs)的兴起，需要系统性的评估方法。现有评估方法通常将VFMs与大型语言模型(LLMs)结合使用作为通用头，然后在广泛的视觉问答(VQA)基准上进行评估。然而，这一方法存在两个关键的盲点：(i) 指令调优数据可能与VQA测试分布不匹配，导致错误预测可能是由于数据不匹配而不是VFMs视觉能力的不足；(ii) VQA基准通常需要多种视觉能力，难以区分错误是由于缺乏所有必需的能力还是某一种关键能力不足。", "innovation": "为了解决这些问题，作者引入了AVA-Bench，这是第一个明确分解出14种原子视觉能力(AVAs)的基准——如定位、深度估计和空间理解等基础技能，共同支持复杂的视觉推理任务。通过拆分AVAs并在每种内匹配训练和测试分布，AVA-Bench能够精确指出VFMs在哪些方面表现出色或失败。应用AVA-Bench到领先VFMs中揭示了独特的“能力指纹”，使得VFMs的选择从猜测变为基于原则的工程。值得注意的是，我们发现0.5B的LLM在评估VFMs方面的排名与7B的LLM类似，但GPU小时数减少了8倍，从而实现了更高效的评估。通过提供一个全面透明的基准，我们希望AVA-Bench为下一代VFMs奠定基础。", "conclusion": "通过提供一个全面透明的基准，AVA-Bench能够揭示不同VFMs的具体视觉能力。这不仅使得VFMs的评估更加高效，而且为下一代VFMs的发展奠定了基础。研究发现较小的LLM（如0.5B）与较大的LLM（如7B）在评估VFMs方面的表现相似，但计算成本显著降低，这表明未来可以在更经济的条件下进行更高效的评估。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12691", "html_url": "https://arxiv.org/abs/2507.12691", "title": "通过黑箱到白箱性能提升基准欺骗探针", "title_en": "Benchmarking Deception Probes via Black-to-White Performance Boosts", "authors": "Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim", "background": "AI助手有时会对用户的查询做出误导性的回复。最近，研究人员训练了线性分类器（称为‘欺骗探针’）来区分语言模型在欺骗性回复和诚实回复时的内部激活状态。然而，这些探针在实际检测欺骗中的有效性尚不明确，也不清楚它们能否抵御欺骗助手的简单反制策略以逃避检测。因此，本文对比了白箱监控（监控可以访问标记级别的探针激活状态）和黑箱监控（没有此类访问）。通过评估白箱监控性能优于黑箱监控的程度，即黑箱到白箱的性能提升，来基准测试欺骗探针。研究发现，现有的欺骗探针产生了微弱但鼓舞人心的黑箱到白箱的性能提升。", "innovation": "本文通过比较白箱监控和黑箱监控来基准测试欺骗探针，采用黑箱到白箱的性能提升作为评估标准。这项研究的创新之处在于提供了一种新的评估方法来检验欺骗探针在实际应用中的效果，并揭示了其在对抗欺骗助手反制策略中的脆弱性。", "conclusion": "现有的欺骗探针虽然在区分欺骗性响应和诚实响应方面表现不佳（显示了微弱但是鼓舞人心的黑箱到白箱的性能提升），但该方法的有效性仍然可以通过改进欺骗探针的设计和策略来提高。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02703", "html_url": "https://arxiv.org/abs/2508.02703", "title": "使用自我监督测量生物信号之间的依赖性及其局限性", "title_en": "Measuring Dependencies between Biological Signals with Self-supervision, and its Limitations", "authors": "Evangelos Sariyanidi,John D. Herrington,Lisa Yankowitz,Pratik Chaudhari,Theodore D. Satterthwaite,Casey J. Zampella,Robert T. Schultz,Russell T. Shinohara,Birkan Tunc", "background": "测量观测信号之间的统计依赖性是科学发现的主要工具之一。然而，生物系统通常表现出复杂的非线性相互作用，这在没有关于依赖性本质的先验知识的情况下是无法捕捉到的。", "innovation": "论文介绍了一种自我监督的方法——协存，它受到这样一个观察的启发：如果两个信号存在依赖性，那么应当能够区分它们时序对齐和不对齐的片段。实验表明，迄今天提出的方法是第一个能够揭示广泛谱系信号之间关系，并且无需针对每个信号进行手动参数调整或依赖先验信息来提取科学相关的差异的方法，为跨领域的科学研究提供了有力工具。", "conclusion": "虽然这种方法暴露了关系，但由外部因素引起的依赖性仍是一个开放的问题，因此研究人员应验证暴露的关系是否真正与感兴趣的科学问题相关。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00381", "html_url": "https://arxiv.org/abs/2508.00381", "title": "Advancing Welding Def Def Detection in Maritime Operations on Adapt-WeldNet and DefDefect Detection Interpretability analysis", "title_en": "Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis", "authors": "Kamal Basha S,Athira Nambiar", "background": "在油品及 化工业中， �特定别是在海洋和和 海环境中，焊缝缺陷检测 on 极为关键， � 对管道统的评估 on � �可靠性和安全 � �特种。 �别防指合上. 这任项中， � 传统无损检测技术经常无法检测到较微小 内部缺陷，导致潜在事故和 和 � 产的停机损失。。现有神经网络基线 on 的缺陷分类方法往往任常依靠随机选择了预训练模型架构， � 且缺乏可 解释性性 上对 派署部署和 � 的挑战 on。", "innovation": "本文为此 on 介绍了 onAdapt-WeldNet”，一种具有自适应框架的焊缝缺陷检测系统，。 基准 on 对各种预训练模型架构进行系统综合评估与 on 自适欠优化器 �， � 支持优化缺陷检测并 on 且提供可行动建议的洞察。此外 on 一种新颖的缺陷检测解释性 �能力分析（DDIA）框架 on � 提高系统透明度 on。。 使用可 解释性机器智能(XXAI）技术 such 如 Grad-CAM和 on LIME on 以及进行 specific评估 on on 由 ASNT高级拥二级资格的专业人士的验证验证下on。融合员介在环中的 且遵循可 坊信机器智能原则 on 该DEDIA确保了 on 坏样部位检测系统的稳健性 on 说服性和责任度 on 确保专家验证下的自动化决策基于信心 on。", "conclusion": "通过提高性能 on 解释鸡能力 on Adapt-WeldNet on on 另一方面其他 支持操作在内的海上与海洋环境中 on 的焊缝缺陷检测系统的可信度 on on �可靠性和稳健 on。 �位�于和 �坏建 收排中有可以提高性能 on 可解释性 � 的共同改进 on 在海上操作中支持了焊缝缺陷检测系统 on"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18418", "html_url": "https://arxiv.org/abs/2502.18418", "title": "Rank1：信息检索中的测试时计算", "title_en": "Rank1: Test-Time Compute for Reranking in Information Retrieval", "authors": "Orion Weller,Kathryn Ricci,Eugene Yang,Andrew Yates,Dawn Lawrie,Benjamin Van Durme", "background": "当前的研究主要集中在使用推理语言模型（如OpenAI的o1和Deepseek的R1）进行蒸馏，以快速提高小型模型的性能。之前的模型通常在训练时进行优化，但在测试时并不充分利用可用的计算资源。Rank1论文则展示了在测试时获取并利用计算资源以进行重新排序的可能，这为信息检索领域带来了新的见解和方法。研究者们收集并开源了一个包含超过60万条R1推理痕迹的数据集，这些痕迹来自MS MARCO中的查询和段落。基于这些数据集训练的模型展示了在高级推理和指令遵循数据集上的最佳性能，并且能够出分布外地运行，同时具有可解释的推理链。这些可解释的链路可以提供给用户或基于检索-聚合（RAG）的系统使用。另外，论文还展示了这些模型的量化版本在保持高性能的同时，能够使用更少的计算资源/内存.", "innovation": "Rank1是首个在测试时充分利用计算资源的重新排序模型。通过使用推理语言模型（比如OpenAI的o1和Deepseek的R1）进行蒸馏，Rank1能够在保持高性能的同时实现更快速的模型重新排序。文章还提供了超过60万条R1推理痕迹的数据集，以此训练出在高级推理和指令跟随数据集上表现出色的模型，并且能够处理出分布外的情况。此外，通过量化这些模型，研究者表明可以在保持较高性能的同时减少计算和内存资源的消耗，这为未来的模型设计提供了新的思路和技术方法。", "conclusion": "Rank1展示了在信息检索中，测试时的计算资源可以带来一种全新的解释性强、性能优良的重新排序模型。通过利用推理语言模型进行训练，并且开源大量推理数据集，研究者为信息检索领域引入了新的方法。这一方法不仅提高了模型的性能和可解释性，同时也展示了在保持高效率的同时减少计算资源的潜力。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02819", "html_url": "https://arxiv.org/abs/2507.02819", "title": "测量即拼凑：探讨数据科学家如何构建预测建模任务的目标变量", "title_en": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks", "authors": "Luke Guerdan,Devansh Saxena,Stevie Chancellor,Zhiwei Steven Wu,Kenneth Holstein", "background": "数据科学家经常需要处理涉及模糊、难以界定的概念的预测建模任务，如学生的“真实性”写作或患者的“健康需求”。然而，数据科学家如何将这些模糊概念转化为具体的代理目标变量的过程仍不为人知。本文通过对教育（N=8）和医疗保健（N=7）领域中的十五名数据科学家进行访谈，探讨了他们如何构建预测建模任务的目标变量。", "innovation": "研究表明，数据科学家在目标变量构建过程中使用了一种称为“拼凑”的过程，通过不断迭代和协商高层次的测量目标与低层次的实践约束。他们还提出了五个主要标准来构建目标变量：有效性、简单性、预测性、可移植性和资源需求。数据科学家灵活使用问题重新表述策略，如在第一个目标变量不满足某些标准时替换一个新的目标变量，或将多个结果组合成一个目标变量以包含更全面的建模目标。", "conclusion": "未来的人机交互（HCI）、协作计算与工作研究（CSCW）以及机器学习（ML）研究都有机会更好地支持目标变量构建的艺术和科学。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13380", "html_url": "https://arxiv.org/abs/2506.13380", "title": "基于分解推理的图检索方法与大型语言模型结合", "title_en": "Decompositional Reasoning for Graph Retrieval with Large Language Models", "authors": "Valentin Six,Evan Dufraisse,Gaël de Chalendar", "background": "大型语言模型在许多自然语言处理任务中表现出色，但在多跳推理和事实一致性方面存在问题，这限制了它们在复杂问答等知识密集型任务中的效果。将知识图谱与大型语言模型结合使用显示出有前途的结果，但这些大型语言模型通常缺乏处理图结构信息的有效推理能力。因此，该研究旨在提出一种创新的检索方法，通过查询分解将文本型知识图谱集成到大型语言模型的推理过程中，从而提高其在多跳问答任务中的性能。", "innovation": "该研究提出了一种新的检索方法，通过查询分解将文本型知识图谱集成到大型语言模型的推理过程中。该方法将复杂问题分解为子问题，检索相关文本子图并构建问题特定的知识图谱来引导答案生成。使用加权相似性函数，该方法能够高效精准地检索复杂问题的相关子图，从而提升大型语言模型在多跳问答任务中的性能。", "conclusion": "该研究的方法在标准的多跳问答基准测试中取得了可比或优于现有竞争性方法的表现，使用更小的模型和更少的大型语言模型调用，增强了事实依据和可解释性，同时发挥了大型语言模型的生成优势。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05246", "html_url": "https://arxiv.org/abs/2508.05246", "title": "基于虹膜图像的性别分类技术研究：深度综述与分析", "title_en": "A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis", "authors": "Basna Mohammed Salih Hasan,Ramadhan J. Mstafa", "background": "性别分类在监视和监控、企业画像和人机交互等领域具有吸引力。性别身份可以通过虹膜等软生物特征进行推断，已有基于面部、指纹、掌纹、DNA、耳廓、步态和虹膜等多种物理特征的方法被提出。其中，面部特征是大多数性别分类方法的基础。虹膜是重要的生物特征，据研究，虹膜在整个个体生命过程中相对稳定且对外部可见，使用时不会对用户造成侵入性影响，因此在实际应用中非常重要。此外，已有高质量的虹膜图像分割和编码方法，目前的方法有利于从虹膜纹理中选取和提取特征向量。", "innovation": "该研究概述了多种性别分类的方法，并详细分析了基于虹膜图像的性别分类技术，为研究人员提供了现有的性别分类方法的知识和分析，并指出了该领域的空白和挑战，提出了改进的建议和未来的研究方向，提供了该领域深入研究的基础和方向。", "conclusion": "该研究总结了基于虹膜图像的性别分类方法，提供了该领域的已有方法和分析，明确了该领域的研究空白和挑战，并提出了未来改进的建议和方向，能够指引该领域的进一步研究。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05693", "html_url": "https://arxiv.org/abs/2508.05693", "title": "基于知识图谱的AI辅助软件包选择实证评估", "title_en": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "authors": "Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan", "background": "在开源生态系统如Python中选择第三方软件包具有挑战性，因为可供选择的软件包非常多且缺少透明的对比证据。生成式AI工具在开发流程中越来越受欢迎，但往往忽视了依赖性评估，更强调流行度而忽视了适用性，缺乏可重复性。这给需要透明度、长期可靠性、维护性和知情架构决策的项目带来了风险。", "innovation": "本文将软件包选择问题表述为多标准决策制定（MCDM）问题，并提出了一种数据驱动的技术评估框架。该框架通过自动化数据管道，从GitHub、PyPI和Stack Overflow收集并整合软件元数据、使用趋势、漏洞信息和开发者情感，并将这些数据结构化进决策模型，反映软件包、领域特征和质量属性之间的关系。框架在PySelect中实现，这是一个决策支持系统，使用大型语言模型来解释用户意图并查询模型以识别上下文相关的软件包。该方法使用GitHub中的798,669个Python脚本和16,887个GitHub仓库的数据进行评估，并基于技术接受模型进行了用户研究。结果表明，数据提取精度高，推荐质量优于基于生成式AI的基准，用户对PySelect的功能和易用性评价十分积极。", "conclusion": "本文提出了一种可扩展、可解释且可再现的框架，支持基于MCDM原则、实证数据和AI辅助意图建模的证据驱动软件选择。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05182", "html_url": "https://arxiv.org/abs/2508.05182", "title": "SPA++: 通用图谱谱对齐方法用于泛化的域适应", "title_en": "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation", "authors": "Zhiqing Xiao,Haobo Wang,Xu Lu,Wentao Ye,Gang Chen,Junbo Zhao", "background": "域适应(DA)旨在将有标签的源域知识转移到无标签或少数标签的目标域下，在域转移过程中保持跨域的一致性。大多数先前的工作主要关注跨域的转移能力，而忽视了丰富的内部域结构，这实证上导致了较差的可辨别性。为了避免这个权衡，本文提出了通用图谱谱对齐框架SPA++，其核心机制包括：(1)通过将DA问题转化为图的基本形式，构建了一种粗粒度的图对齐机制，结合了一种新颖的光谱正则化，以便在特征空间内对齐域图；(2)进一步开发了增强目标域可辨别性的细微邻近感知传播机制；(3)通过引入数据增强和一致性正则化，SPA++能够适应包括大部分DA设置在内的复杂场景，甚至具有挑战性的情况。此外，还提供了理论分析来支持我们的方法，包括图谱DA的一般化界以及光谱对齐和平滑一致性的作用。", "innovation": "通用图谱谱对齐框架SPA++。该框架通过将DA问题转化为图的基本形式，结合了一种新颖的光谱正则化机制，用于对齐域图在特征空间内的结构；进一步开发了细微邻近感知的传播机制以增强目标域的可辨别性；引入了数据增强和一致性正则化，以适应复杂的场景，包括具有挑战性的分布情况。此外，提供理论分析支持该方法，包括基于图谱的DA的通用化界和光谱对齐及平滑一致性的角色分析。", "conclusion": "在基准数据集上的广泛实验表明，SPA++在各种具有挑战性的领域适应场景中表现出更优的鲁棒性和适应性，持续地超越现有的先进方法。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05710", "html_url": "https://arxiv.org/abs/2508.05710", "title": "Klear-CodeTest：代码强化学习中的可扩展测试案例生成", "title_en": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "authors": "Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou", "background": "为有效训练大规模语言模型（LLMs）在代码强化学习中的表现，精确且正确的反馈至关重要。然而，合成高质量的测试案例依然是一个亟待解决的难题。现有的强化学习方法在代码测试案例生成方面缺乏全面覆盖和严格验证机制。", "innovation": "Klear-CodeTest 是一种综合的测试案例生成框架，具备严格的验证机制以确保测试案例的质量和可靠性。该框架采用了一种创新的生成-验证（G-V）机制，不仅能生成全面覆盖常规及极限情况的测试案例，还可以通过一致性验证机制验证输出结果，确保其正确性。此外，Klear-CodeTest 还设计了一套多层次的安全沙箱系统，优化了在线验证平台，确保代码安全可靠地执行。实验结果表明，Klear-CodeTest 能显著提高模型性能和训练稳定性。", "conclusion": "通过全面的实验，Klear-CodeTest 证明了其精心构建的数据集的有效性，成功解决了高质量测试案例合成的问题，为提高代码强化学习中的模型性能和训练稳定性提供了有效的解决方案。Klear-CodeTest 代码、数据集和沙箱系统可在此链接下载：this https URL."}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05949", "html_url": "https://arxiv.org/abs/2508.05949", "title": "关于碳感知容器编排中任务调度的综述", "title_en": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration", "authors": "Jialin Yang,Zainab Saad,Jiajun Wu,Xiaoguang Niu,Henry Leung,Steve Drew", "background": "大规模软件生态系统和云数据中心对能源的巨大需求，受到了大型语言模型密集训练和部署的影响，导致能源消耗和碳足迹达到了前所未有的水平。为了应对这个问题，产业界和学术界都在增加努力，通过更高效的任务调度和基础设施编排减少与云计算相关的碳排放。", "innovation": "本文系统地回顾了各种Kubernetes调度策略，将它们分为硬件中心和软件中心两大类，并标注每个策略的可持续发展目标。根据所用算法对策略进行分组，提出了关于云任务调度研究的全面分类，尤其注意环境可持续性方面。本研究分析了新兴的研究趋势和开放挑战，并提供了对未来一代云计算系统中可持续调度方案设计的宝贵见解。", "conclusion": "研究结果为设计下一代云计算系统的可持续调度方案提供了关键见解。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05799", "html_url": "https://arxiv.org/abs/2508.05799", "title": "AI-Guided Exploration of Large-Scale Codebases", "title_en": "AI-Guided Exploration of Large-Scale Codebases", "authors": "Yoseph Berhanu Alebachew", "background": "理解大型复杂的软件系统对于开发人员来说是一个主要的挑战。传统的工具，如静态可视化和反向工程技术，提供了结构性的洞察，但往往缺乏交互性、适应性和与上下文信息的整合。最近在大型语言模型（LLMs）方面的进步为增强代码探索工作流程提供了新的机会，然而它们缺乏与结构视图的结合限制了其效果。", "innovation": "本文介绍了一种结合确定性反向工程与LLM引导、意图感知的可视化探索的混合方法。提出的系统结合了基于UML的可视化，动态用户界面，历史上下文和协作功能，形成一种适应性的代码理解工具。通过解释用户查询和交互模式，LLM帮助开发者更有效地导航和理解复杂的代码库。", "conclusion": "这项研究为具有智能、交互式环境奠定了基础，这些环境与开发人员的认知和协作工作流程相一致。未来的工作包括实证评估、多语言系统扩展以及探索GUI驱动的LLM交互模型。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05034", "html_url": "https://arxiv.org/abs/2508.05034", "title": "基于机器学习的软件变更依赖性预测：来自OpenStack的经验研究洞察", "title_en": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack", "authors": "Ali Arabat,Mohammed Sayagh,Jameleddine Hassine", "background": "随着软件系统变得越来越复杂，准确地识别和管理变更之间的依赖关系变得越来越重要。在OpenStack这样的大型软件系统中，依赖关系跨越多个团队和组件，给开发和部署带来了挑战。传统意义上独立的变更，如文档更新，也可能成为依赖关系的一部分。本文通过初步研究揭示了OpenStack过去10年间有很大一部分软件变更是相互依赖的，其中51.08%的依赖关系是在代码审查阶段（平均滞后5.06小时）被发现的，而不是在变更创建时。开发人员平均需要花费57.12小时来识别依赖关系，其中涉及约463个其他变更。", "innovation": "本文提出了一种半自动化的依赖性预测方法，结合了两个机器学习模型：第一个模型预测变更之间的依赖性可能性，第二个模型具体识别出依赖的变更对。这些模型表现良好，AUC平均得分为79.33%和91.89%，Brier分数分别为0.11和0.014。尤其是第二个模型在所有类型的依赖对中具有良好的top-k召回率。", "conclusion": "尽管本文的模型在召回率方面表现良好，但在预测精度方面仍有一定提升空间。未来的研究可以进一步优化模型的精确度，提供更有力的支持，帮助开发者更早、更准确地识别变更间的依赖关系。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05923", "html_url": "https://arxiv.org/abs/2508.05923", "title": "通过遗传算法实现自适应测试输入生成以增强软件漏洞检测", "title_en": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "authors": "Yanusha Mehendran,Maolin Tang,Yi Lu", "background": "软件漏洞持续影响现代系统的可靠性和安全性，尤其是当软件复杂度超过传统检测方法的能力时。这项研究旨在通过提出一种基于遗传算法的测试输入生成方法来增强软件漏洞检测，该方法通过结合遗传操作和自适应学习来解决这个问题。", "innovation": "该方法的核心创新在于采用了交叉操作，以更广泛地搜索潜在测试输入的空间；同时引入了自适应反馈机制，能够根据系统执行行为持续学习，并动态引导输入生成向有希望的输入空间区域发展。这种方法通过基于反馈的选择不断进化一个结构有效的测试案例集合，从而实现更深入和有效的代码遍历。", "conclusion": "该方法在九个开源JSON处理库上的评估表明，相较于基准进化模糊测试方法，其覆盖率有了显著提升，平均增加了39.8%的类覆盖率、62.4%的方法覆盖率、105.0%的行覆盖率、114.0%的指令覆盖率和166.0%的分支覆盖率。这些结果表明，该方法能够检测到更深层次和更加复杂的漏洞，提供了一种可扩展且适应性强的软件安全测试解决方案。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05747", "html_url": "https://arxiv.org/abs/2508.05747", "title": "利用Composer包加速学生Laravel项目开发：一种教学与实践框架", "title_en": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework", "authors": "Rohaizah Abdul Wahid,Muhamad Said Nizamuddin Nadim,Suliana Sulaiman,Syahmi Akmal Shaharudin,Muhammad Danial Jupikil,Iqqwan Jasman Su Azlan Su", "background": "Laravel已成为大学网页开发课程的基础框架，尽管它具备模板生成能力，但在有限的学术时间内，学生仍难以完成项目。迄今为止，学生往往因为缺乏有效工具支持而遇到困难。本文基于实际和教学考量，探讨如何利用Composer（PHP的标准依赖管理工具）及其精选的Composer包减少开发努力，同时推广专业软件开发实践，旨在帮助教育工作者和学习者构建典型的学术或个人Laravel系统。", "innovation": "文章将Composer及其精选的Composer包引入大学教学中，这些工具可以显著减少开发工作量，同时促进专业软件实践。此外，文章还提供了针对潜在风险（如包冲突和过度依赖工具）的最佳实践建议，确保开发加速的同时强化专业工作流程和行业准备度。这些包的使用不仅能够使课程内容更加相关，还能帮助学生更好地过渡到职业生涯。然而，合理融入这些工具需要与学习目标相匹配的教学设计指导，避免学生将它们视为黑箱工具，教育工作者应教授学生如何使用这些工具、何时使用以及为何使用，以促进对它们的批判性评价。", "conclusion": "本文强调通过利用Composer及其包加速Laravel项目开发的重要性，同时强调了教育工作者在课堂上的指导作用，以确保学生能够理解并批判性评价这些工具的使用，从而使最终的开发成果不仅高效而且有利于深层次的学习。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.06192", "html_url": "https://arxiv.org/abs/2508.06192", "title": "理解智能合约中的不一致状态更新漏洞", "title_en": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts", "authors": "Lantian Li,Yuyu Chen,Jingwen Wu,Yue Pan,Zhongxing Yu", "background": "智能合约允许在区块链上自动执行和验证合同条款，并在金融和供应链等领域得到广泛应用。智能合约的执行逻辑与其状态紧密相关，只有精确地控制和更新合同状态，才能确保其正确和安全的执行。然而，在状态更新过程中可能会遇到问题，尤其是不一致的状态更新可能导致安全漏洞，这些漏洞被攻击者反复利用。", "innovation": "本文是第一个大规模实证研究智能合约中可利用的不一致状态更新漏洞，旨在为开发者、研究人员、工具构建者和语言或库设计者提供避免这些漏洞的思路。研究系统调查了352个实际智能合约项目中的116个不一致状态更新漏洞，总结了其根本原因、修复策略和利用方法。研究提供了11项新的重要发现，并讨论了这些发现的影响。研究还基于一项发现开发了一个概念验证检测工具，该工具有效地检测了64个GitHub项目中的问题，且19个项目的所有者在撰写时已确认这些问题。", "conclusion": "研究结果表明，理解和解决不一致状态更新漏洞对于避免智能合约中的这些问题具有重要价值。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.06365", "html_url": "https://arxiv.org/abs/2508.06365", "title": "由执行反馈驱动的从软件工程问题生成测试", "title_en": "Execution-Feedback Driven Test Generation from SWE Issues", "authors": "Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel", "background": "软件工程问题（SWE问题）通常由于缺少或不正确的可执行代码难以通过自动化方式生成重现测试。现有方法受到了这一挑战的影响，无法有效利用执行反馈生成高质量的测试用例。由于大多数问题缺乏有效的重现测试，如何自动生成这些测试成为研究焦点。", "innovation": "本文介绍了利用执行反馈生成重现测试的新技术，并开发了名为e-Otter++的新型自动生成工具。e-Otter++能够显著提高生成测试用例的质量，能够在TDD-Bench Verified基准测试中将平均失败转化为通过的比例提升至63%。这一技术为解决该领域的问题提供了新的突破点。", "conclusion": "e-Otter++代表了在由软件工程问题生成测试领域的重大进展。通过利用执行反馈，该工具有效地解决了由于代码错误或缺失所带来的挑战，提高了测试生成的效率和质量。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.06299", "html_url": "https://arxiv.org/abs/2508.06299", "title": "改进低代码过程建模语言以提升开发者体验", "title_en": "Improving the Developer Experience with a Low-Code Process Modelling Language", "authors": "Henrique Henriques,Hugo Lourenço,Vasco Amaral,Miguel Goulão", "background": "OutSystems 平台是一种包含多个领域特定语言（DSL）的开发环境，用于快速构建和验证 web 和移动应用程序。过去，用于过程建模的 Business Process Technology (BPT) DSL 的接受度较低，并且存在影响其普及的可用性问题。这种状况令人担忧，因为语言维护成本高。因此，需要改进 BPT 来提高其使用体验并降低维护成本，尤其是在开发人员中有较高技术背景的情况下。", "innovation": "该研究通过结合访谈、‘物理化表示’的批判性审查和使用系统可用性量表(SUS)和NASA任务负载指数(TLX)的实证评估，提出了改进的 BPT。这项创新之处在于它综合了用户的反馈和 OutSystems 工程师的文化，以开发新一代的 BPT。", "conclusion": "评估结果显示，新版本的 BPT 在语义透明度、正确响应、SUS 分数和 TLX 分数方面均有显著提高。这些结果表明，新的 BPT 显著改善了开发人员的经验，并且开发人员的背景对最终选择具体的语法结构和实现使用性指标有很大影响。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.06017", "html_url": "https://arxiv.org/abs/2508.06017", "title": "智能编码系统应伴以解释编写程序", "title_en": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "authors": "Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang", "background": "智能编码系统通过使用户能够以自然语言指定代码行为来改变软件开发。然而，AI驱动的编码器的不透明决策过程引发了信任和可用性问题，特别是对于非专家用户来说，他们无法检查底层实现。", "innovation": "我们提出智能编码系统不仅生成代码，还应生成清晰、一致的解释，以弥合模型推理与用户理解之间的差距。为此，我们识别了两种关键的解释属性——认知对齐和语义忠实性，并指出现有的形式验证、静态分析和事后解释方法的局限性。我们提倡探索神经符号方法来生成解释，其中符号约束在训练期间引导模型行为，并通过神经表示丰富程序语义，从而在推理时实现自动一致性检查。", "conclusion": "我们主张探索神经符号方法来生成解释，以提高智能编码系统的透明度和可用性。"}
{"llm_update_time": "20250811", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04928", "html_url": "https://arxiv.org/abs/2508.04928", "title": "使用校准标记将基础单目深度估算器扩展到鱼眼相机", "title_en": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens", "authors": "Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong", "background": "基础单目深度估计器（FMDEs）通常在透视图像上进行训练，但在相机校准参数（如内在参数和失真）发生变化时，容易出现协变量偏移，导致深度估计错误。尽管已经训练了数千万张图像，FMDEs仍然面临这一问题，无法直接应用于鱼眼相机。为了克服这一挑战，本研究提出了一种方法，通过校准标记对鱼眼图像的潜在嵌入分布进行调整，使FMDEs能够无缝应用于鱼眼相机而无需重新训练或微调。这种方法使用了鱼眼图像的大量公开可用的透视图像数据集，通过将透视图像校准到鱼眼图像，并在训练过程中保持这些估计的一致性来实现目标。", "innovation": "本研究引入了一种名为校准标记的轻量级适应机制，用于调整鱼眼图像的潜在嵌入，使其与透视图像的潜在嵌入对齐。这种方法利用了FMDEs中存在的高度表达的潜在空间，通过调节其嵌入来避免传统校正或到图像空间的共轭参考框架映射中的负面影响。该研究通过使用单组标记在室内和室外场景中完全改进了现有最先进的方法，且无需使用实际的鱼眼图像数据集。这种自监督方法扩展了FMDEs的应用范围，具有广泛的实际意义。", "conclusion": "本研究提出的方法成功地将基础单目深度估计器扩展到鱼眼相机，并通过校准标记实现了有效且经济的调整，该研究结论表明，这种方法在多个FMDEs和场景中取得了显著的性能提升。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.06414", "html_url": "https://arxiv.org/abs/2508.06414", "title": "构建有效代码生成上下文示例的因素有哪些？", "title_en": "What Builds Effective In-Context Examples for Code Generation?", "authors": "Dongze Li,Songqiang Chen,Jialun Cao,Shing-Chi Cheung", "background": "基于大型语言模型（LLMs）的代码生成能力可以通过上下文学习（In-Context Learning，ICL）得到了显著提升，该方法将代码示例嵌入提示中，使LLMs可以从这些示例中进行学习。尽管ICL方法在很大程度上有效，但具体哪些代码特点（如标识符命名风格、代码格式、解决方案线索等）对ICL的有效性至关重要仍不明确。因此，该研究通过控制消融研究系统地探讨了各种代码特征对ICL的影响。研究发现变量和函数的适当命名对于代码生成的有效性至关重要，其缺失会导致性能下降高达30个百分点。此外，该研究还揭示了LLMs更重视语义意义的标识符名称而非格式公约，并存在针对标识符冗长性的语言偏好。研究发现，当前的LLMs在从相似代码解决方案中提取可泛化的解决问题洞见方面存在困难，尽管它们可以有效地利用直接信息。这些发现为优化ICL系统提供了宝贵的见解，并突显了代码生成任务中基于反思学习的基本挑战。", "innovation": "研究通过控制消融研究系统地探讨了各种代码特征对ICL的影响，特别强调了变量和函数命名对ICL性能的重要性，并揭示了LLMs在语义标识符名和格式偏好方面的偏好差异。此外，研究还揭示了LLMs在从相似代码中提取通用问题解决洞察方面的困难。", "conclusion": "研究发现，适当的变量和函数命名是ICL有效性的关键因素，其缺失会导致性能显著下降。此外，LLMs更偏好语义含义丰富的标识符名而非格式规则，并且在从代码中提取通用解决方案洞察时存在挑战。这些发现为优化ICL系统提供了重要指导，同时指出了代码生成任务中基于反思学习的挑战。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05697", "html_url": "https://arxiv.org/abs/2508.05697", "title": "NISQ时代的量子资源管理：来自软件工程的含义与展望", "title_en": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering", "authors": "Marcos Guillermo Lammers,Federico Hernán Holik,Alejandro Fernández", "background": "量子计算机利用量子力学原理在信息处理方面实现了一种技术飞跃，能够解决经典系统无法处理的高度复杂问题。然而，在当前的NISQ时代（噪声中等规模量子设备），可用硬件存在诸多局限性，如量子比特数量有限、高错误率和较短的相干时间。因此，量子资源的有效管理——无论是物理资源还是逻辑资源——在量子算法的设计和部署中尤为关键。", "innovation": "本文分析了NISQ设备当前使用中的量子资源作用，揭示了其对量子软件工程的关联和影响。通过这篇贡献，我们旨在强化量子资源估计（QRE）领域，并朝着可扩展和可靠的量子软件开发迈进。", "conclusion": "本文强调了在软件工程视角下，NISQ时代量子资源管理的重要性，并为未来可扩展和可靠量子软件开发提供了方向。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.10665", "html_url": "https://arxiv.org/abs/2409.10665", "title": "Assurance 2.0 案例中的信心", "title_en": "Confidence in Assurance 2.0 Cases", "authors": "Robin Bloomfield,John Rushby", "background": "安全部署或措施应通过确保某种关键性质（如安全或安全性）的真实提出信心。本文探讨了如何在被称为Assurance 2.0的严格方法中评估这种信心。作者的目标是不可动摇的信心，并从逻辑稳健性、概率评估、辩证审查和剩余风险四个方面进行探讨。", "innovation": "提出了Assurance 2.0方法，这是一个旨在提高系统或程序中某种关键性质（如安全或安全性）的信心的严格方法。文章从逻辑稳健性、概率评估、辩证审查和剩余风险四个角度，探讨如何达到不可动摇的信心。", "conclusion": "通过综合逻辑稳健性、概率评估、辩证审查和剩余风险四种方法，Assurance 2.0方法试图提供不可动摇的信心，从而确保系统或程序的关键性质的真实可靠。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.13900", "html_url": "https://arxiv.org/abs/2407.13900", "title": "探索生成式AI工具的证据基础软件工程信念", "title_en": "Exploring the Evidence-Based SE Beliefs of Generative AI Tools", "authors": "Chris Brown,Jason Cusati", "background": "生成式人工智能（AI）的最新创新，尤其是由大型语言模型（LLMs）驱动的，正在改变开发人员如何创建和维护软件的方式。生成式AI工具的高级功能促进了软件开发任务的支持，使得它们在软件工程（SE）工作流程中的应用越来越多。然而，关于生成式AI工具是否理解由研究发现支持的证据基础信念和实践，了解甚少。因此，本研究旨在初步评估生成式AI工具在其支持软件开发任务时的“信念”，研究了五种生成式AI工具对SE研究中提出的17个证据基础主张的看法。发现生成式AI工具对研究主张的看法含糊不清，缺乏支持回应可信的证据。本研究结果为将生成式AI系统集成到开发环境中提供了实操建议，并为未来研究方向提供了指导，以提高生成式AI的可靠性和可信度，增强证据基础SE研究结果的应用意识和接受度。", "innovation": "本研究初步评估了五种生成式AI工具在支持软件开发任务时对17个证据基础主张的看法，展示了生成式AI工具对研究主张含糊不清且缺乏支持能力的特点，为实操中的集成提供了具体的建议，并为未来研究指明了方向，以提高生成式AI的可靠性和可信度，促使更多地采用基于证据基础的SE研究成果。", "conclusion": "本研究揭示了生成式AI工具对SE研究提出的证据基础主张的看法模糊且缺乏支持依据，为开发环境中的实操应用提供了潜在发展的途径，并指出了未来如何提升生成式AI的可靠性和可信度的研究方向。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.12644", "html_url": "https://arxiv.org/abs/2411.12644", "title": "CodeXEmbed: 多语言和多任务代码检索的通用嵌入模型家族", "title_en": "CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval", "authors": "Ye Liu,Rui Meng,Shafiq Joty,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz", "background": "尽管文本检索在许多自然语言处理任务中取得了成功，代码检索领域仍是一个很大程度上未被深入研究的领域。大多数文本检索系统适用于自然语言查询，往往忽视了代码检索的特定挑战。这使得现有的模型无法有效捕捉不同领域内多种编程语言和任务的多样性，凸显了代码检索领域需要更加聚焦的研究。", "innovation": "本文引入了CodeXEmbed，这是一个从4亿到70亿参数的代码嵌入模型家族，具有创新性的训练管道，能统一多种编程语言，并将各种代码相关任务转化为通用检索框架，提高模型的泛化能力和检索性能。70亿参数的模型在代码检索方面达到了新的最佳水平，在CoIR基准测试上比之前的领先模型Voyage-Code性能高出20%以上。此外，这些模型在广泛采用的BeIR文本检索基准测试上也表现出竞争力，提供了跨领域的灵活性。", "conclusion": "实验结果表明，提高检索性能在代码相关任务的端到端检索增强生成（RAG）性能方面有显著的提升。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.07467", "html_url": "https://arxiv.org/abs/2406.07467", "title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs", "title_en": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs", "authors": "Fatemeh Hadadi,Qinghua Xu,Domenico Bianculli,Lionel Briand", "background": "大多数基于日志的异常检测器假定日志是稳定的，但实际上由于软件或环境变化，日志往往是不稳定的。因此，在不稳定日志上的异常检测（ULAD）是一个更现实却未被充分研究的挑战。目前的方法主要依赖机器学习模型，这些模型通常需要大量标记数据进行训练。为了解决数据不足的问题，本文提出了一种名为FlexLog的新颖混合方法，它结合了决策树、K近邻和前馈神经网络等机器学习模型与大型语言模型（Mistral），并通过集成学习实现。FlexLog还集成了缓存和检索增强生成（RAG），进一步提高了效率和效果。为了评估FlexLog，本文配置了四个数据集（ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U），并在这些数据集上进行了实验。实验结果表明，FlexLog的F1分数比所有基线高出至少1.2个百分点，并且使用了更少的标记数据（减少了62.87个百分点）。当用相同量的数据训练时，与基线相比，在不同大小的训练数据集上，FlexLog在ADFA-U数据集上的F1分数提高了多达13个百分点。此外，FlexLog保持了每条日志序列下超过一秒钟的推理时间，使其适用于大多数应用程序，尽管对于敏感的延迟系统可能不太适合。进一步的分析表明，FlexLog的关键组件（缓存、RAG和集成学习）对其性能的积极影响。", "innovation": "本文提出了FlexLog，这是一种新颖的混合方法，在不稳定日志上的异常检测中结合了机器学习模型和大型语言模型。通过集成学习和缓存、RAG等技术，有效地提高了检测精度和效率，特别是在数据不足的情况下表现良好。", "conclusion": "FlexLog在不稳定日志的异常检测中表现出色，能够在涉及大量日志数据且标记数据匮乏的环境中提供高精度的检测结果。此外，该方法还保持了较快的推理速度，适用于大多数应用场合。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.19085", "html_url": "https://arxiv.org/abs/2504.19085", "title": "朝向包容性低代码开发：检测用户评论中的无障碍问题", "title_en": "Toward Inclusive Low-Code Development: Detecting Accessibility Issues in User Reviews", "authors": "Mohammadali Mohammadkhani,Sara Zahedi Movahed,Hourieh Khalajzadeh,Mojtaba Shahin,Khuong Tran Hoang", "background": "低代码应用程序在各个领域逐渐流行，使非开发者也能参与软件开发过程。然而，这些应用程序高度依赖图形用户界面，可能会无意中排除视觉障碍用户，比如色盲和视力低下。本文研究了用户在使用低代码应用程序时报告的无障碍问题，并构建了一个包含无障碍相关和非无障碍相关评论的全面数据集。", "innovation": "本文设计并实现了一个复杂的混合模型，结合了两个最新的基于Transformers的模型和一个传统的关键词系统，以识别评论中是否存在无障碍问题。该混合模型在检测无障碍问题方面的准确性和F1分数达到了78%。", "conclusion": "研究表明，低代码应用程序可能无意中排除了视觉障碍用户，并通过构建数据集和设计混合模型提高了检测无障碍问题的准确性。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05970", "html_url": "https://arxiv.org/abs/2508.05970", "title": "基于影响的跨文件代码完成上下文过滤", "title_en": "Impact-driven Context Filtering For Cross-file Code Completion", "authors": "Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu", "background": "检索增强生成（RAG）在仓库级别的代码补全方面表现出巨大的潜力，因为它能够结合跨文件的先验知识与文件内的先前代码，以提供全面的生成上下文。为了更好地理解检索出的跨文件上下文对代码补全的贡献，引入了一个基于概率的度量来评估每个检索代码片段对生成的影响。尽管检索出大量的代码片段，但分析显示只有少数几个片段对生成结果产生了积极的影响，而一些片段甚至损害了生成的效果。为解决这个问题，基于这些度量的结果，构建了一个库级别的数据集，每个检索到的片段被标记为正面、中性或负面，具体取决于其与目标补全的相关性。", "innovation": "提出了一种基于此度量的自适应检索上下文过滤框架CODEFILTER，该框架在该数据集上训练，以缓解负面检索上下文对代码补全的负面影响。广泛的评估显示，与没有过滤操作的方法相比，CODEFILTER在各种任务中一致提高了代码补全的准确性。此外，CODEFILTER显著减少了输入提示的长度，提高了计算效率，同时在不同的模型中表现出良好的通用性。这些结果表明CODEFILTER有望提高仓库级别代码补全的准确性和效率，增强其可归因性。", "conclusion": "广泛的评估显示，CODEFILTER在各种任务中显著提高了代码补全的准确性，减少了输入提示的长度，增强了计算效率，并在各种模型中表现出良好的通用性，表明此方法在提高仓库级别代码补全的准确性和效率方面具有潜力。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.10443", "html_url": "https://arxiv.org/abs/2505.10443", "title": "大型语言模型在执行语义保持变异的代码时是否稳健？", "title_en": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "authors": "Pedro Orvalho,Marta Kwiatkowska", "background": "理解大型语言模型（LLMs）在编程任务中的推理和鲁棒性是它们可靠使用的先决条件。尽管近期研究评估了LLMs预测程序输出的能力，但大多数研究仅关注预测的准确性，而忽视了背后的原因。此外，观察到在数学推理任务中，LLMs可以通过有缺陷的逻辑得出正确答案，这引发了对代码理解中类似问题的关注。本研究旨在评估最先进的含8B参数的LLMs是否能够理解Python程序或只是猜测。", "innovation": "本工作通过应用五种语义保持代码变异（变量重命名、镜像比较表达式、交换if-else分支、将for循环转换为while循环和循环展开），检验LLMs是否基于坚实推理产生正确预测。这些变异维持了程序的语义，但改变了其语法结构。通过LiveCodeBench进行了人类专家分析，以评估正确预测是否基于合理的推理，并通过LiveCodeBench和CruxEval评估预测的稳定性。", "conclusion": "研究发现，训练用于代码处理的LLMs在10%到50%的情况下基于有缺陷的推理产生正确预测。此外，LLMs对代码变异的预测响应显示出不稳定的、语义依据不足的推理。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05865", "html_url": "https://arxiv.org/abs/2508.05865", "title": "安全高效的区块链投票：一种比较框架及大型语言模型的作用", "title_en": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models", "authors": "Kiana Kiashemshaki,Elvis Nnaemeka Chukwuani,Mohammad Jalili Torkamani,Negin Mahmoudi", "background": "区块链技术为现代E-Voting系统提供了增强透明度、去中心化和安全性的有希望的基础。然而，由于可扩展性限制、高计算要求和复杂的隐私要求等持久挑战，实际采用仍然受限。", "innovation": "本论文提出了一种比较框架，用于分析基于区块链的E-Voting架构、共识机制和加密协议。它检视了像工作量证明、权益证明和委托权益证明等现有模型的局限性，并提出了包括混合共识、轻量级加密和去中心化身份管理在内的优化策略。此外，它还探索了大型语言模型（LLMs）在智能合约生成、异常检测和用户交互中的新颖作用。", "conclusion": "我们的研究为设计适合全国范围部署的安全、可扩展且智能化的区块链E-Voting系统奠定了基础。这项工作为通过LLMs引导智能合约生成和验证构建端到端的区块链E-Voting原型奠定了基础，这依托于系统框架和基于仿真的分析。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2308.02613", "html_url": "https://arxiv.org/abs/2308.02613", "title": "从研究到临床：通过使合成数据具有互操作性加速临床决策支持系统的翻译", "title_en": "From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable", "authors": "Pavitra Chauhan,Mohsen Gamal Saad Askar,Kristian Svendsen,Bjørn Fjukstad,Brita Elvevåg,Lars Ailo Bongo,Edvard Pedersen", "background": "临床决策支持系统（CDSS）工具在临床环境中的应用非常有限，主要原因是研究往往侧重于训练机器学习模型，而非使用模型开发工具。为了在临床工作流程中部署CDSS工具，需要在电子健康记录（EHR）系统上集成、验证和测试该工具。由于数据隐私保护的法律规定，研究人员通常难以获得EHR系统的访问权限。因此，本文提出了一种使用合成数据的架构，以简化CDSS工具的开发和测试。", "innovation": "本文提出了一个基于合成数据的架构，通过利用SynthHIR系统，实现工具的互操作性和可移植性。研究首先基于挪威患者的记录开发了一个基于机器学习的CDSS工具的原型，然后成功地将该工具部署到挪威最大的EHR系统供应商DIPS中，从而展示了该架构在加速CDSS工具从实验室到临床的转化过程中的有效性。", "conclusion": "本文展示了SynthHIR架构的价值，作为实用参考模型，可以加速从实验室到临床的CDSS工具的转化研究。该研究的发现强调了利用合成数据在EHR系统中的互操作性在加速临床决策支持工具转化方面的重要性。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05034", "html_url": "https://arxiv.org/abs/2508.05034", "title": "基于机器学习预测软件变更依赖性的方法：来自OpenStack的实证研究洞察", "title_en": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack", "authors": "Ali Arabat,Mohammed Sayagh,Jameleddine Hassine", "background": "随着软件系统的复杂性增长，准确识别和管理变更间的依赖关系变得越来越关键。例如，使用某个函数的变更必须依赖于引入该函数的变更。建立这样的依赖关系能够使CI/CD管道有效构建和编排变更，防止构建失败和不完整的功能部署。现代软件系统中，依赖关系通常跨多个团队的组件存在，这为开发和部署带来了挑战。依赖关系可以用于启用新功能、管理配置等，甚至可能涉及独立的变更，如文档更新。", "innovation": "为应对这些挑战，本文研究了OpenStack中依赖管理的初步方法。该研究揭示了过去10年OpenStack中的大量软件更改是相互依赖的，其中51.08%的依赖关系是在代码审查阶段被发现的，平均延迟5.06小时。我们提出了一种半自动方法，利用两个机器学习模型帮助开发者主动识别依赖关系。第一个模型预测变更间的依赖可能性，第二个模型识别具体的依赖变更对。该模型在AUC评分和贝叶斯评分上都表现良好，第二个模型在所有类型变更对的最好的前k召回率方面表现良好。", "conclusion": "研究表明，OpenStack中的大量软件更改存在依赖关系，这些依赖关系多是在代码审查阶段被发现。我们提出的方法在识别变更依赖关系的准确性上表现出色，并且第二个模型在预测依赖对的前k召回率上有较好的表现，但前k精度有待提高。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05988", "html_url": "https://arxiv.org/abs/2508.05988", "title": "通过首个词惊愕度精简冗余：高效代码推理", "title_en": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "authors": "Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu", "background": "近年来，大规模推理模型（LRMs）通过增加链式思维（CoT）的长度，在代码推理方面展现出非凡的能力。然而，过长的推理痕迹带来了训练成本高、推理延迟大的问题，并且在部署上也变得不切实际。尽管提出了一些针对CoT压缩的方法，但它们存在固有的权衡：基于token水平的压缩方法往往破坏了语法和逻辑的一致性，而基于困惑度的基于步骤水平的方法却未能可靠地捕捉到逻辑上关键的推理步骤。", "innovation": "本文提出了ASAP（基于锚点的，基于惊愕度的选择性剪枝），一种新颖的从粗到细的CoT压缩框架。ASAP首先通过基于锚点的剪枝来保留核心的推理结构，从而高效地缩减后续处理的搜索空间。然后，它能够实现逻辑感知的剪枝，基于一个新颖的第一词惊愕度指标选择逻辑上必不可少的推理步骤。最后，ASAP使模型能够自主生成并利用这些简化的CoT进行推理，从而在编码任务中实现高效推理。实验表明，ASAP在多个代码生成基准测试中实现了最先进的准确率，同时大大减少了训练和推理成本。在LiveCodeBench v4_v5基准测试上，该方法的代码生成量减少了23.5%，推理延迟减少了43.5%，同时实现了有竞争力的准确率36.19%。", "conclusion": "我们的结果表明ASAP为开发强大且高效的LRMs指明了一个有希望的方向。"}
{"llm_update_time": "20250811", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.04030", "html_url": "https://arxiv.org/abs/2504.04030", "title": "OpenCodeInstruct: 代码LLM指令调优数据集", "title_en": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs", "authors": "Wasi Uddin Ahmad,Aleksander Ficek,Mehrzad Samadi,Jocelyn Huang,Vahid Noroozi,Somshubra Majumdar,Boris Ginsburg", "background": "大语言模型（LLMs）在软件开发中发挥了重要作用，包括代码生成、自动化调试和复杂推理。然而，这些模型的进一步发展受到高质量、公开可用的监督微调（SFT）数据集的限制，这些数据集专门用于编程任务。希望通过引入OpenCodeInstruct，填补这一空白。", "innovation": "提出OpenCodeInstruct，这是一个最大的开放访问指令调优数据集，包含500万个多样性的样本。每个样本包括编程问题、解决方案、测试用例、执行反馈以及LLM生成的质量评估。利用OpenCodeInstruct对不同的基础模型（如LLaMA和Qwen）进行了多规模（1B+，3B+和7B+）的微调。", "conclusion": "通过在流行的基准测试（HumanEval、MBPP、LiveCodeBench和BigCodeBench）上的全面评估，表明使用OpenCodeInstruct进行SFT实现了显著的性能提升。同时详细介绍了种子数据收集、合成指令和解决方案生成及筛选的方法。"}
