{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06475", "html_url": "https://arxiv.org/abs/2510.06475", "title": "PuzzlePlex：基于谜题评估基础模型的推理与规划能力", "title_en": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles", "authors": "Yitao Long,Yuru Jiang,Hongjun Liu,Yilun Zhao,Jingchen Sun,Yiqiu Shen,Chen Zhao,Arman Cohan,Dennis Shasha", "background": "该研究探讨了基础模型在复杂动态环境中的推理和规划能力及其可扩展性。通过设计PuzzlePlex基准，研究旨在通过多样化的谜题来评估这些能力。", "innovation": "引入了PuzzlePlex基准，涵盖了15种不同类型的谜题，包括不同难度的确定性和随机性游戏，以及单人和双人游戏场景。同时，开发了精细的度量标准，并在指令驱动和代码驱动两种环境中对前沿基础模型进行了深入分析。研究还系统地探讨了其扩展极限。", "conclusion": "研究发现，在指令驱动环境中，推理模型表现更优；而在代码执行方面，则提供了更具挑战性的扩展方案，但提供了可扩展且高效的替代方案。PuzzlePlex能够针对性地评估这些能力，并指导未来在推理、规划和泛化方面的改进。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06538", "html_url": "https://arxiv.org/abs/2510.06538", "title": "Auto-Prompt Ensemble for LLM Judge", "title_en": "Auto-Prompt Ensemble for LLM Judge", "authors": "Jiajie Li,Huayi Zhang,Peng Lin,Jinjun Xiong,Wei Xu", "background": "现有的LLM（大语言模型）评估器往往缺乏一些关键的评估维度，因为它们未能识别出人类评估背后的隐性标准。这导致评估结果的可靠性不足。", "innovation": "提出了一种名为Auto-Prompt Ensemble（APE）的新框架，它能够自动从失败案例中学习评估维度，并通过一种新的基于置信度的集体置信度估计方法，动态地决定是否采用额外的评估维度来增强LLM评估器的可靠性。", "conclusion": "实验结果表明，APE能够在多种标准基准上提高LLM评估器的可靠性。例如，在零样本设置中，APE将GPT-4o在Reward Bench上的协议率从87.2%提高到90.5%。总体而言，APE为LLM评估器提供了一种利用测试时计算的原理性方法，以缩小人类与LLM评估器的评估差距。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06302", "html_url": "https://arxiv.org/abs/2510.06302", "title": "游戏化学习设计框架需求：后并购整合背景下信息系统整合学习", "title_en": "Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration", "authors": "Ksenija Lace,Marite Kirikova", "background": "后并购整合对负责信息系统整合的专业人员提出了独特挑战，尤其是需要对合并组织的多种系统架构进行协调和整合。尽管在企业层面存在并购整合的理论和实践指导，但在信息系统整合培训方面仍然存在重大差距。现有方法（如AMILI和AMILP）虽然能够支持决策，但在实际应用中却面临着学习曲线高和学员动力低的问题。这项研究旨在探讨基于游戏的教育设计如何解决这些问题，通过将静态的方法培训转变为更具参与感的学习体验来缓解这些困难。", "innovation": "研究通过分析基础学习理论、认知负荷和动机模型以及严肃游戏设计框架，确定了符合后并购整合背景下信息系统整合需求的游戏化学习设计框架的关键要求。该框架包括两个组成部分：转化过程和结果学习体验。这种方法可以提高学习者的动机并降低学习难度。", "conclusion": "本研究提出了一个开发和评估基于游戏的教育设计框架的计划，该框架专门针对后并购整合背景下信息系统整合，通过迭代设计和实地验证进行实施和检验。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06433", "html_url": "https://arxiv.org/abs/2510.06433", "title": "Flavonoid Fusion: 创建一个知识图谱以揭示食物与健康之间的关系", "title_en": "Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health", "authors": "Aryan Singh Dalal,Yinglun Zhang,Duru Doğan,Atalay Mert İleri,Hande Küçük McGinty", "background": "近年来，‘食物作为药物’这一概念在健康领域得到了广泛关注。尽管已有研究探讨了食物与健康的关联，但很少有研究通过语义网的方式，以标准化且机器可读的格式来表示食物与健康之间的关系。这使得有效的知识利用成为一种挑战。为了填补这一空白，本研究旨在通过构建知识图谱，连接食物和健康之间的关联，并利用知识图谱整合来自不同平台的信息，尤其是在美国农业部数据库中的食物黄酮含量及其与癌症联系的数据，以及通过KNARM方法深入分析这些关系，将它们表示为机器可操作的形式。", "innovation": "本研究创新之处在于通过构建知识图谱，利用KNARM方法来揭示食物、黄酮含量以及其对健康和疾病管理的具体影响，以期从科学研究和实际应用两个层面提升食物与健康研究的有效性和效率。这种方法还为其他相关研究提供了可借鉴的案例和方法。", "conclusion": "本研究构建的这一知识图谱，不仅提供了一个探索饮食选择与疾病管理之间复杂关联的例子，也为未来的研究提供了更广泛的视角和数据支持。未来的工作计划进一步扩大知识图谱的范围，增加更复杂的数据细节，并通过推理技术发现隐含的关联。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06288", "html_url": "https://arxiv.org/abs/2510.06288", "title": "BuilderBench -- 通用型智能体基准", "title_en": "BuilderBench -- A benchmark for generalist agents", "authors": "Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach", "background": "当今的AI模型主要通过模仿和优化来学习，这使得它们难以解决现有数据范围之外的新问题。解决新问题需要智能体具备探索和经验学习的能力。目前缺乏一种可扩展的学习机制，使得智能体能够在与环境互动中学习。鉴于此，本文介绍了BuilderBench，用于加速对智能体预训练的研究，重点是开放探索。BuilderBench要求智能体学会使用积木搭建任何结构，并配备了一个加速模拟的机器人代理与各种物理积木交互的硬件，以及一个包括超过42个精心筛选目标结构的任务套件，这些结构用于测试物理、数学以及长期规划的理解程度。", "innovation": "BuilderBench 通过设立一个包含机器人代理与物理积木交互的加速模拟环境，以及一个挑战物理、数学和长期规划理解的任务套件，旨在推动对开放探索的研究，特别是在智能体预训练领域。这种基准测试不仅强调行动中的体验和策略组合，还提供了一种训练轮协议，使得研究者可以将算法应用到单一目标结构的构建上来实现基准点参考。", "conclusion": "我们的实验表明，许多任务挑战了当前算法的极限。因此，本文还提供了六种不同算法的单文件实现作为研究员的参考点，以期促进对智能体预训练研究的进展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06261", "html_url": "https://arxiv.org/abs/2510.06261", "title": "AlphaApollo: 将基础模型和专业工具结合进一个自我演化的深度主动推理系统", "title_en": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning", "authors": "Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han", "background": "该研究旨在解决基础模型（FM）推理时遇到的两大瓶颈：模型固有的能力有限和测试时迭代不可靠的问题。当前，基础模型在处理复杂问题时存在一定的局限性，而现有的解决方法往往缺乏可验证性和普适性。", "innovation": "AlphaApollo 系统通过调度多种模型与专业工具相结合，有效解决了上述问题。具体创新点包括：1. 使用计算工具（Python及其数值和符号库）和检索工具（与任务相关的外部信息），实现精确计算并可验证的决策；2. 支持多轮次、多模型的解决方案进化，通过共享状态图记录候选方案、可执行检查点及反馈，提高迭代优化效果。", "conclusion": "在 AIME 2024/2025 的各项测试中，AlphaApollo 为多个模型带来了持续的提升，如 Qwen2.5-14B-Instruct 平均提升 5.15%，通过率提升 23.34%；Llama-3.3-70B-Instruct 平均提升 8.91%，通过率提升 26.67%。进一步的工具使用分析显示，超过 80% 的工具调用成功执行，并且在非工具基准中的表现始终逊色，这提升了基础模型的能力天花板。更多实证结果和实现细节请参阅：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06410", "html_url": "https://arxiv.org/abs/2510.06410", "title": "Off-Trajectory Reasoning: LLMs在推理轨迹上能否合作？", "title_en": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?", "authors": "Aochong Oliver Li,Tanya Goyal", "background": "大型语言模型（LLMs）经过培训，能够口头表达其推理过程，从而在复杂任务上取得了显著进展。这种透明性开启了多个推理者在共享轨迹内直接合作的潜力，从而提高推理效率和探索能力。然而，实现这一目标的关键前提是评估其他模型的部分思考有用性并在此基础上进行构建——我们称之为离轨推理。本文探讨了一个核心问题：标准单一推理培训管线能否实现期望的离轨行为？", "innovation": "本文提出了两种极端的离轨推理测试，分别是恢复性和可引导性。恢复性测试了模型是否能够从误导性推理痕迹导致的“干扰”中回溯，而可引导性则测试了模型利用更强合作者正确推理进行构建的能力。同时，研究评估了15款开放权重的大规模语言模型（1.5B-32B），发现在基准测试中表现优秀的模型往往在受到干扰时更加脆弱。此外，研究还对影响这些行为的三个因素进行了控制研究，以剔除培训后的影响因素。结果提供了针对训练本能强大的推理合作者的行动建议；例如，我们发现即使在蒸馏轨迹正确的情况下，老师模型的次优恢复性能也会转移到学生的模型中。", "conclusion": "本研究为评估共享推理轨迹中的多模型合作奠定了基础，并指出了现成推理LLMs的局限性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06534", "html_url": "https://arxiv.org/abs/2510.06534", "title": "有益的代理搜索推理行为和有效后训练以获得它们", "title_en": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them", "authors": "Jiahe Jin,Abhijay Paladugu,Chenyan Xiong", "background": "代理搜索利用大型语言模型（LLMs）来解释复杂用户信息需求，并执行规划、搜索和信息综合以提供答案的多步过程。这一范式为LLMs的推理和代理能力带来独特挑战，尤其是在与检索系统和更广泛的互联网交互时。", "innovation": "本文提出了一种基于推理的LLM管道，研究代理搜索中的有效推理行为模式。基于此管道，分析了成功的代理搜索轨迹并确定了四种有益的推理行为：信息验证、权威评估、适应性搜索和错误恢复。基于这些发现，提出了名为行为激发的技术，通过监督微调（SFT）和常规强化学习（RL）相结合来训练更有效的代理搜索模型。实验表明，行为激发在Llama3.2-3B和Qwen3-1.7B上的性能优于直接使用RL训练代理搜索模型，且正确推理行为而非最终答案的正确性是决定性能的关键因素。此外，通过引入的推理行为赋予模型更有效的探索能力和测试时间缩放能力，为RL提供了坚实的基础。", "conclusion": "通过行为激发，可以为代理搜索模型引入理想的推理行为，并通过监督微调和常规强化学习的有效结合提高模型性能。这些发现揭示了代理搜索的潜在机制，以及推理行为对模型表现的关键作用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06307", "html_url": "https://arxiv.org/abs/2510.06307", "title": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks", "title_en": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks", "authors": "Wentao Deng,Jiahuan Pei,Zhiwei Xu,Zhaochun Ren,Zhumin Chen,Pengjie Ren", "background": "多智能体系统（MAS）可以通过多个代理之间的协作来解决复杂的自然语言处理（NLP）任务，共识机制是实现这种协作的关键。然而，现有的共识机制通常依赖投票机制来判断共识状态，忽略了系统内部信念之间的矛盾，这些矛盾会破坏共识的稳定性。此外，这些方法通常让代理通过与所有其他代理的无差别的合作来更新其结果，这种统一的交互方式无法找到最适合每个代理的合作对象，阻碍了稳定共识的形成。", "innovation": "本文提供了一个理论框架，选择最优的合作对象以最大化共识稳定性。基于此理论框架，提出了Belief-Calibrated Consensus Seeking (BCCS)框架，通过选择最优的合作对象和校准共识决策，推动共识的稳定达成。实验结果表明，BCCS框架在MATH和MMLU基准数据集上的表现显著优于现有最佳结果，分别在挑战性任务上提高了2.23%和3.95%的准确性。", "conclusion": "实验结果证明，所提出的BCCS框架在解决复杂NLP任务方面表现优异，能够有效提高任务的准确率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06274", "html_url": "https://arxiv.org/abs/2510.06274", "title": "从推理到学习：通过复杂性出分布泛化揭穿幻象", "title_en": "Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization", "authors": "Mohammad Mahdi Samiei Paqaleh,Arash Marioriyad,Arman Tahmasebi-Zadeh,Mohamadreza Fereydooni,Mahdi Ghaznavai,Mahdieh Soleymani Baghshah", "background": "近期进展推动了人工智能从模式识别任务发展到需要逐步、系统2风格的推理问题，尤其是大型语言模型的使用。然而，与学习领域对泛化和领域外（OOD）评估概念的良好形式化相比，当前对推理能力没有清晰且一致的定义或度量标准。此项研究提出了一种复杂性领域外（Complexity OoD）泛化的框架和问题设置，以定义和衡量推理能力。该框架要求模型在测试样本中表现出色，这些样本的最小所需解决方案复杂度（无论是表示性复杂度还是计算复杂度）超过所有训练样本。通过解决方案描述的科莫罗夫斯基复杂性和操作性代理（如对象/关系计数；推理步骤计数）来形式化复杂性，明确了Complexity OoD与长度和组分OOD的区别。这种视角将学习与推理统一起来：许多用系统1（低复杂度）方式解决的问题在复杂性压力下变为系统2式问题，而系统2则被视为在解决方案结构上的泛化。为缓解学习推理时的溢出效应（如伪捷径、语义鲁棒性、灾难性遗忘和逐步校准）问题提供了解决方案。", "innovation": "该研究提出了一种名为Complexity OoD泛化的全新框架，以明确并衡量模型在面对具有更高复杂性的测试样例时的推理能力。该框架整合了科莫罗夫斯基复杂性及操作性代理，提供了一种统一学习与推理视角，为解决系统2风格问题提供了新思路。此外，该研究还提出了实践中的建议，包括改进基准和评估指标设计，重新思考监督以针对解决方案过程，以及寻找和设计促进Complexity OoD泛化的归纳偏置。为了克服通过单纯增加数据量无法解决Complexity OoD问题，研究指出未来的突破需要构建和训练具有明确计算模型和对复杂性进行显式建模的架构框架。", "conclusion": "Complexity OoD泛化不能仅通过增加数据量来解决，未来在增强推理能力上的进步将依赖于能够明确处理和分配计算资源，符合复杂性的架构方法和训练策略。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06587", "html_url": "https://arxiv.org/abs/2510.06587", "title": "WebDART: 动态分解与重规划以应对复杂网络任务", "title_en": "WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks", "authors": "Jingbo Yang,Bairu Hou,Wei Wei,Shiyu Chang,Yujia Bao", "background": "大规模语言模型（LLM）代理在处理简单的网络任务如打开商品页面或提交表单方面已经变得很擅长，但仍然在需要长期导航、大规模信息提取和在约束条件下推理的目标方面存在问题。", "innovation": "WebDART 提出了一种通用框架，使单一 LLM 能够处理复杂的任务。其创新点包括：(i) 动态将每个目标拆分为三个专注于的子任务：导航、信息提取和执行，从而使模型每次专注于一项技能；(ii) 随着新的网页被揭示，持续重新计划拆分过程，利用新发现的过滤器或捷径，避免重复探索。", "conclusion": "在 WebChoreArena 上评估，WebDART 的成功率提高了最多 13.7 个百分点，同时在更简单的 WebArena 系列上与以往的 SOTA 代理性能持平，并且使用最多 14.7 少的导航步骤完成任务。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06742", "html_url": "https://arxiv.org/abs/2510.06742", "title": "MultiCNKG: 使用大规模语言模型整合认知神经科学、基因和疾病知识图谱", "title_en": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models", "authors": "Ali Sarabadani,Kheirolah Rahsepar Fard", "background": "大规模语言模型（LLMs）的出现极大地革新了生物医学和认知科学中知识图谱（KGs）的融合，克服了传统机器学习方法在捕捉基因、疾病和认知过程之间复杂语义联系方面的局限性。", "innovation": "该研究介绍了一种名为MultiCNKG的创新框架，该框架结合了认知神经科学知识图谱（CNKG）、基因本体论（GO）和疾病本体论（DO）三大关键知识源，利用LLMs（如GPT-4）进行实体对齐、语义相似性计算和图谱增强，从而创建了一个互联互通的知识图谱。该图谱涵盖了6900个节点和11300条边，提供从分子到行为领域的多层次视角，并通过多种评估指标验证了其稳健性和连贯性。", "conclusion": "MultiCNKG在个性化医学、认知障碍诊断和认知神经科学中的假设形成等方面的应用中表现出色，链接预测评估结果与基准模型相比表现出竞争力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06600", "html_url": "https://arxiv.org/abs/2510.06600", "title": "通过上下文学习实现细粒度情绪识别", "title_en": "Fine-Grained Emotion Recognition via In-Context Learning", "authors": "Zhaochun Ren,Zhou Yang,Chenglong Ye,Haizhou Sun,Chao Chen,Xiaofei Zhu,Xiangwen Liao", "background": "细粒度情绪识别旨在通过推理和决策过程识别查询中的情感类型，对于各种系统至关重要。近年来的方法使用上下文学习（ICL），通过语义相似的示例增强查询的表示，从而进一步改进情绪识别并解释推理机制。然而，这些方法主要集中在增强推理过程，忽略了决策过程。本文通过原型理论研究了细粒度情绪识别中的决策过程，表明ICL依赖于查询表示与模型内情感原型之间的相似性匹配，而情绪准确的表示至关重要。但是，语义相似的示例通常引入情绪差异，导致准确表示受到阻碍并引发错误。", "innovation": "我们提出了情绪上下文学习（EICL），引入了情绪上相似的示例，并采用动态软标签策略以改进情绪推理过程中的查询表示。然后采用两阶段排除策略从多个角度评估相似度，进一步优化决策过程。实验结果显示，EICL在多个数据集上显著优于ICL。", "conclusion": "通过引入情绪相似的示例和动态软标签策略，EICL改进了情绪推理过程中的查询表示，并通过两阶段排除策略进一步优化决策过程。实验表明EICL显著优于传统的ICL方法，显示了在细粒度情绪识别中的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06711", "html_url": "https://arxiv.org/abs/2510.06711", "title": "元代理在代理设计中的低效性", "title_en": "Inefficiencies of Meta Agents for Agent Design", "authors": "Batu El,Mert Yuksekgonul,James Zou", "background": "近年来，开始使用元代理自动化设计代理系统。这些元代理能够提出并逐步改进新的代理架构。然而，该领域仍面临一些关键挑战，包括学习过程、代理行为多样性和经济可行性等方面的问题。", "innovation": "研究指出了元代理在代理设计中的三项重要挑战。首先，研究发现简单地扩展上下文以包含所有先前代理的设计效果不如完全忽略先前的设计。其次，尽管在训练过程中设计多个代理，但在测试时通常只选择一个代理，导致设计的代理行为多样性较低。第三，研究评估了自动化设计在经济上的可行性，发现只有在很少的情况下（具体来说，针对两个数据集），自动设计和部署代理的成本低于人类设计的代理，特别是在部署超过15,000个实例的情况下。对于其他数据集，尽管自动化设计可能带来性能提升，但其成本无法被经济效益所支持。", "conclusion": "自动化设计代理在某些情况下可以节省成本，但在其他情况下并不经济。提高元代理在迭代过程中的性能和提升设计的代理行为多样性是未来研究的重要方向。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06674", "html_url": "https://arxiv.org/abs/2510.06674", "title": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support", "title_en": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support", "authors": "Cen (Mia)Zhao,Tiantian Zhang,Hanchen Su,Yufeng(Wayne)Zhang,Shaowei Su,Mingzhi Xu, Yu (Elaine)Liu,Wei Han,Jeremy Werner,Claire Na Cheng,Yashar Mehdad", "background": "本文介绍了一种Agent-in-the-Loop (AITL)框架，该框架通过迭代改进基于LLM（大型语言模型）的客户服务系统。不同于依赖批量注解的标准离线方法，AITL将四种关键类型的注解直接集成到实时客户服务操作中：（1）一对响应偏好；（2）代理采用及其理由；（3）知识相关性检查；（4）缺失知识的识别。", "innovation": "这些反馈信号无缝地反馈到模型的更新中，将重新训练周期从几个月缩短到几周。在涉及美国客户服务代理的生产试点中，结果显示检索准确性提高了11.7%（@75召回率）、生成质量提高了8.4%（帮助性提高）和代理采用率提高了4.5%。这些结果证明了将人工反馈环直接嵌入操作工作流程中以连续改进基于LLM的客户服务系统的有效性。 ", "conclusion": "这些结果强调了直接将人类反馈循环嵌入运营工作流程中，以持续改进基于LLM的客户服务系统的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06761", "html_url": "https://arxiv.org/abs/2510.06761", "title": "通过双环多代理协作演化和执行研究计划", "title_en": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration", "authors": "Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao", "background": "自动化整个科学研究过程面临根本性的挑战：这要求既能生成新颖且可靠的高阶研究计划，又能在此动态和不确定条件下正确执行这些计划。为应对这一双层次的挑战，我们提出了一种新颖的双环多代理（DLMA）框架，用于自动解决研究问题。领导环由教授代理组成，负责生成和发展研究计划；追随环由博士生代理组成，负责在实施过程中执行最佳进化得来的计划。", "innovation": "提出的DLMA框架包括两个环：“领导环”和“追随环”。领导环中的教授代理使用进化算法通过涉及、改进和集成会议逐步生成并优化研究提议池，积极探索解决方案空间；追随环中的博士生代理负责在执行过程中不断调整最佳计划，通过前置和后置会议动态调整实施中的每个步骤，以确保每个步骤都得到适当的内部控制和外部观察支持。通过基准测试如ACLAward和实验室的实验表明，DLMA生成的研究论文在自动评估中达到最先进的得分，显著优于强劲的基线。", "conclusion": "消融研究证实了两个环的首要作用，进化推动新颖性，执行确保可靠性。这一框架展示了自动化科学研究过程的重要进展，提高了研究过程的整体效率和创新性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06756", "html_url": "https://arxiv.org/abs/2510.06756", "title": "验证大型语言模型的无记忆顺序决策", "title_en": "Verifying Memoryless Sequential Decision-making of Large Language Models", "authors": "Dennis Gross,Helge Spieker,Arnaud Gotlieb", "background": "本文介绍了一个工具，用于对基于大型语言模型（LLM）的策略进行严格和自动化的验证。在无记忆的顺序决策任务中，给定一个马尔可夫决策过程（MDP）作为顺序决策任务的表示，一个基于LLM的策略以及用PCTL公式表示的安全要求，该方法通过LLM选择的动作逐步构建只有可达部分的MDP。每个状态以自然语言提示的形式表示，LLM的响应被解析为一个动作，然后根据该策略扩展可达的后续状态。最终形成的正式模型使用Storm进行检查，以确定策略是否满足指定的安全属性。在标准的格子世界基准试验中，结果显示，通过Ollama访问的开源LLM在确定性种子的情况下可以被验证，但通常在与深度强化学习基线的性能上存在差距。", "innovation": "本文创新地提出了一种方法，通过构建可达部分的MDP来引导性地验证基于大型语言模型的无记忆顺序决策任务中的策略。方法将每个状态编码为自然语言提示，并依赖于LLM生成的响应以实现对策略的有效验证。这种方法还能够与Ollama以及PRISM任务进行原生集成，从而能够进行用户指定的任务中的持续基准测试，并为进一步正式验证越来越强大的LLM奠定了实用的基础。", "conclusion": "在标准的格子世界基准试验中，通过Ollama访问的开源LLM在确定性种子的情况下可以被验证，但在与深度强化学习基线的性能上表现逊色。然而，该工具为连续基准测试中的用户指定顺序决策任务提供了原生支持，并为正式验证越来越强大的LLM提供了实用的基础。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06857", "html_url": "https://arxiv.org/abs/2510.06857", "title": "带有工具反馈的自动形式化模型", "title_en": "Autoformalizer with Tool Feedback", "authors": "Qi Guo,Jianing Wang,Jianfei Zhang,Deyang Kong,Xiangzhou Huang,Xiangyu Xi,Wei Wang,Jingang Wang,Xunliang Cai,Shikun Zhang,Wei Ye", "background": "自动形式化通过将数学问题从自然语言翻译成形式化的表述来解决自动定理证明（ATP）中数据稀缺的问题。近年来的研究重点从直接提示大型语言模型转向训练端到端的自动形式化模型，取得了显著的进步。然而，现有的自动形式化模型仍然难以始终如一地生成符合句法有效性及语义一致性要求的有效陈述。", "innovation": "提出了一种名为带有工具反馈的自动形式化模型（ATF）的新颖方法，该方法将句法和一致性信息作为工具整合到形式化过程中。通过利用Lean 4编译器进行句法修正，并采取多LLM作为裁判的方法进行一致性验证，该模型能够根据工具反馈自适应地精炼生成的陈述，从而增强其句法有效性和语义一致性。训练ATF包括冷启动阶段以适应合成的工具调用数据、专家迭代阶段以提高形式化能力，以及直接偏好优化以减轻无效修订的影响。实验结果表明ATF显著优于多种基线自动形式化模型，并且其优越性通过人工评估得到了进一步验证。此外，还发现ATF具有出色的推理扩展特性。", "conclusion": "研究团队开源了Numina-ATF数据集，包含75万条合成的形式化陈述，旨在推动自动形式化和ATP领域的研究进展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06911", "html_url": "https://arxiv.org/abs/2510.06911", "title": "使用AJAN的大型语言模型辅助建模语义Web驱动的多智能体系统", "title_en": "LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN", "authors": "Hacane Hechehouche,Andre Antakli,Matthias Klusch", "background": "已经建立了很多语义Web标准用于实现多代理驱动的应用程序。AJAN框架允许基于这些标准构建多代理系统。代理知识用RDF/RDFS和OWL表示，而代理行为模型则使用行为树和SPARQL来访问和操作这些知识。然而，如何适当定义基于RDF/RDFS和SPARQL的代理行为依然是一项挑战，特别是在大规模环境中处理复杂的SPARQL查询需要较高的学习门槛。", "innovation": "本文提出了一种集成开发环境，旨在克服AJAN代理建模中的这些障碍，并通过利用大型语言模型扩展AJAN的用户社区。", "conclusion": "该集成开发环境能够帮助代理模型者更加轻松地进行建模，同时也为AJAN引入了新的用户群体，提高了代理系统的设计效率和灵活性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07038", "html_url": "https://arxiv.org/abs/2510.07038", "title": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning", "title_en": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning", "authors": "Wenxun Wu,Yuanyang Li,Guhan Chen,Linyue Wang,Hongyang Chen", "background": "近年来，大规模语言模型（LLMs）的进展使得在测试时扩展（即生成额外推理令牌）变得流行，这种方法在数学推理基准测试中显示出显著的性能提升。然而，基于直接推理的语言模型在处理需要最新知识或计算工具（如计算器和代码解释器）的复杂算术运算任务时仍表现不佳。", "innovation": "该研究提出了Tool-Augmented Policy Optimization (TAPO)，一种新颖的基于强化学习的框架，系统地将多跳推理与自适应工具调用功能整合。TAPO运用了一种最近开发的基于动态采样策略优化 (DAPO) 方式的变体，使其适应工具调用场景，使模型能够动态地将复杂推理与按需工具使用（包括搜索API和Python解释器）交织在一起。", "conclusion": "实验表明，TAPO在Qwen2.5-3B和Qwen2.5-7B模型中有效，特别是在需要外部知识和数学计算的任务中达到了最先进的性能。TAPO相比基线方法更高效地使用工具，同时防止了由于奖励欺骗导致的过度调用。这些结果强调了结合先进推理与工具使用以提升知识密集和计算密集任务中模型性能的显著潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06953", "html_url": "https://arxiv.org/abs/2510.06953", "title": "在大语言模型推理追踪中重访均匀信息密度假说", "title_en": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces", "authors": "Minju Gwak,Guijin Son,Jaehyung Kim", "background": "均匀信息密度（UID）假说认为有效的沟通保持信息流动的稳定。本文在大语言模型（LLM）推理追踪的背景下重新审视这一原则，探讨步骤级均匀性是否反映了推理的质量。为此，本文提出了一种基于熵的步骤级信息密度度量，并引入了局部和全局均匀性评分两种互补的均匀性衡量标准。在六个不同的推理基准上进行的实验表明，步骤级均匀性不仅提供了强大的理论视角，还带来了实际性能上的好处；例如，在AIME2025基准上，选择具有更高步骤级信息均匀性的推理追踪提高了10-32%的相对精度。进一步分析表明，正确的推理追踪倾向于避免信息密度的突变，而错误的推理追踪则表现出不规则的信息爆发。这些结果证明，受UID启发的信息密度度量优于其他内部信号，作为推理质量的预测指标。结果显示，信息密度的均匀性作为构建更可靠和准确推理系统的诊断和选择标准是稳健的。", "innovation": "本文创新性地提出了基于熵的步骤级信息密度度量，并引入了局部和全局均匀性评分，以评估大语言模型推理追踪的步骤级均匀性。研究发现，这种度量方式优于其他内部信号，可以作为推理质量的预测指标，并且提高了基准测试中的准确性。", "conclusion": "步骤级均匀性的信息密度度量作为一种稳健的诊断和选择标准，对于构建更可靠和准确的推理系统具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07091", "html_url": "https://arxiv.org/abs/2510.07091", "title": "认知带宽瓶颈：从基于动作规划转向基于模式规划推动长期智能体发展", "title_en": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas", "authors": "Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song", "background": "在开放世界中，使大型语言模型（LLMs）能够有效执行长期任务并进行长期规划和多次交互至关重要。传统方法通常采用基于动作的规划，提供可执行的动作列表作为参考。然而，当环境的动作空间出现组合爆炸时（例如，开放世界的实际情况），这种动作表示方式变得不切实际。因此，提出了关于当环境动作空间扩大时，长时智能体的最佳动作表示方式的问题。基于这些背景，本文系统研究了两种不同动作表示的有效性。", "innovation": "本文提出了认知带宽视角作为概念框架，用于理解不同动作表示方法之间的差异。实验中观察到在不同任务规模（ALFWorld约35个动作，SciWorld约500个动作）之间存在规划方式转变的拐点。此外，探索了不同模型能力对拐点位置的影响，并提供了改进基于模式规划的智能体以支持更具扩展性的自主性的实用指南。", "conclusion": "研究表明，在某些任务规模下，基于模式的规划比基于动作的规划更有效。同时，提供了一个实用指南，帮助构建更有效的基于模式规划的智能体，提高自主系统的扩展性和能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07073", "html_url": "https://arxiv.org/abs/2510.07073", "title": "VRPAgent: LLM-驱动的车辆路线问题启发式算子发现", "title_en": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems", "authors": "André Hottung,Federico Berto,Chuanbo Hua,Nayeli Gast Zepeda,Daniel Wetzel,Michael Römer,Haoran Ye,Davide Zago,Michael Poli,Stefano Massaroli,Jinkyoo Park,Kevin Tierney", "background": "设计高性能的车辆路线问题（VRPs）的启发式算法是一个复杂的任务，需要专业知识和直觉。大规模语言模型（LLMs）用于代码生成，在许多领域显示出潜力，但仍然无法生成与人类专家设计的启发式算法相媲美的算法。", "innovation": "提出了VRPAgent框架，该框架将LLM生成的组件与元启发式算法集成，并通过新的遗传搜索进行改进。VRPAgent使用LLM生成特定于问题的操作，嵌入到通用的元启发式框架中，从而保持任务的管理性，确保正确性，并仍能发现新的和强大的策略。在多个问题，包括装载容量约束VRP，带时间窗的VRP和集计式VRP上，该方法发现的启发式操作优于手工艺品和最近的学习驱动方法，仅需一个CPU核心。到目前为止，【VRPAgent 】是首个通过LLM来推进VRPs领域先进技术的方法，展示了自动启发式发现未来的一线希望。", "conclusion": "【VRPAgent 】是首个将LLM用于发现VRP启发式操作的技术，展示了自动化启发式发现方面的前景。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07069", "html_url": "https://arxiv.org/abs/2510.07069", "title": "稳定模型下模糊逻辑程序的归纳学习", "title_en": "Inductive Learning for Possibilistic Logic Programs Under Stable Models", "authors": "Hongbo Hu,Yisong Wang,Yi Huang,Kewen Wang", "background": "模糊逻辑程序（poss-programs）是常规模应编程（ASP）的一种主要变体。虽然其语义（模糊稳定模型）和属性已经被深入研究，但在归纳推理方面尚未进行过研究。该论文旨在通过从背景程序和示例（部分预想的模糊稳定模型）中提取poss-programs来填补这一空白。为此，首先正式定义了归纳任务的概念，研究了其性质，并提出了用于计算归纳解决方案的ilpsm和ilpsmmin两个算法。对于ilpsmmin算法还提供了实现，并通过实验结果表明，当输入是普通逻辑程序时，该原型在自动生成的数据集中相比用于正常逻辑程序稳定的模型的主要归纳学习系统表现更佳。", "innovation": "该论文的创新之处在于提出了一个从背景程序和示例中提取模糊逻辑程序的方法，并提供了实现两个算法ilpsm和ilpsmmin来根据这些示例计算归纳解决方案，填补了模糊逻辑程序在归纳推理方面的空白。此外，实验结果表明该方法在处理普通逻辑程序时比现有方法更有效。", "conclusion": "该研究展示了从背景程序和示例中学习模糊逻辑程序的初步成果，通过两个算法成功地从普通逻辑程序中推导出了模糊逻辑程序，在随机生成的数据集上该方法比现有的正常逻辑程序稳定模型的主要归纳学习系统更有效。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07117", "html_url": "https://arxiv.org/abs/2510.07117", "title": "物理附着的偶然性允许开放性和关怀", "title_en": "The Contingencies of Physical Embodiment Allow for Open-Endedness and Care", "authors": "Leonardo Christov-Moore(1),Arthur Juliani(1),Alex Kiefer(1 and 2 and 3),Nicco Reggente(1),B. Scott Rousse(4),Adam Safron(1 and 5),Nicol'as Hinrichs(6 and 7),Daniel Polani(8),Antonio Damasio(9) ((1) Institute for Advanced Consciousness Studies, Santa Monica, CA, (2) VERSES, (3) Monash Centre for Consciousness and Contemplative Studies, (4) Allen Discovery Center, (5) Allen Discovery Center, (6) Okinawa Institute of Science and Technology, (7) Max Planck Institute for Human Cognitive and Brain Sciences, (8) University of Hertfordshire, (9) Brain and Creativity Institute)", "background": "通常认为物理脆弱性和死亡风险是开发人造代理的障碍，使其难以适应未知环境并提供一致的关怀。相比之下，生物体能够容易而高效地在开放的物理世界中生存、繁荣并相互照顾。本文探讨了这种差异背后的环境条件如何有助于开发更强大、更具备适应性及关怀的人造代理。文章基于马丁·海德格尔的存在主义现象学，提出了两个受物理附着启发的最小条件：在世状态（即代理是环境的一部分）和向着死亡的状态（除非被抵消，代理将因热力学第二定律而趋向于终结状态）。", "innovation": "本文呼吁从马丁·海德格尔和弗里德里希·尼采的存在主义哲学中汲取灵感，将自我维持的驱动力（旨在保持完整并避免死亡通过消耗能量学习和行动）和扩展自我维持方式的内在驱动力相结合。进一步，提出了通过增强学习框架来正式化这一概念，研究了在开放的多代理环境中，由内在驱使的附着代理如何培养开放性和自我增强能力。", "conclusion": "探讨了由内在驱使的物理附着代理如何在开放性环境中培养并展示开放性和自我增强的能力，本文强调了理解生存条件对提升人造代理性能的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07297", "html_url": "https://arxiv.org/abs/2510.07297", "title": "国足球媒体内容发现中的自主生成式AI", "title_en": "Agentic generative AI for media content discovery at the national football league", "authors": "Henry Wang,Sirajus Salekin,Jake Lee,Ross Claytor,Shinan Zhang,Michael Chi", "background": "生成式AI解锁了内容发现和管理的新可能性。本文通过与国家橄榄球联盟（NFL）的合作，展示了基于生成式AI的工作流如何使媒体研究人员和分析师能够使用自然语言查询相关历史比赛，而不仅仅是传统的筛选和点击界面。", "innovation": "该自主生成式AI工作流将用户查询输入分解为元素，并将其翻译成底层的数据库查询语言。通过精心设计的语义缓存进一步提高准确性和延迟。该解决方案实现了超过95％的准确率，并将搜索相关视频的平均时间从10分钟缩短到30秒，显著提高了NFL的操作效率，使用户能够专注于创造性的内容生产和引人入胜的故事线。", "conclusion": "该研究的解决方案显著提高了NFL的操作效率，减少了寻找相关视频的时间，使媒体研究人员和分析师能够专注于创造性的内容生产和引人入胜的故事线，同时提高了查询的准确性和效率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07064", "html_url": "https://arxiv.org/abs/2510.07064", "title": "跨多个代理进行提示优化以代表多样化的群体", "title_en": "Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations", "authors": "Manh Hung Nguyen,Sebastian Tschiatschek,Adish Singla", "background": "获取大规模人类响应的难度和成本使得大型语言模型（LLMs）成为人类行为的一种有吸引力的替代品和有前途的代理。然而，前期研究显示LLMs通常产生同质的输出，未能捕捉人类多样性的丰富观点和行为。因此，我们不试图通过单一LLM代理捕捉这种多样性，而是提出一种新的框架，用于构建一组能够共同捕捉目标人群多样性的代理。", "innovation": "本文提出了一种新颖的方法，即通过情境学习人类示范（任务-响应对）来引导LLM行为，从而构建能够集体捕捉给定人类群体多样性的代理集合。特别是，我们从子模优化的角度解决代理选择问题，并开发了在时间复杂性和性能保证之间提供不同权衡的方法。实验结果表明，我们的方法构建的代理相较于基准方法更好地代表了人类群体，并且在新任务上的行为分析表明这些代理复制了所设计代表学生的观点和注释者的模式。", "conclusion": "我们的研究证明，通过跨多个代理进行提示优化，能够更有效地代表多样化的群体。这种方法为构建更接近真实人类行为的代理提供了新的视角和策略。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07276", "html_url": "https://arxiv.org/abs/2510.07276", "title": "具有列子集代价偏好的多目标多智能体路径规划", "title_en": "Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences", "authors": "Pulkit Rustagi,Kyle Hollins Wray,Sandhya Saisubramanian", "background": "许多现实世界的情境需要多个代理在共享环境中协调运作，同时平衡多个潜在竞争的目标之间的权衡。当前的多目标多智能体路径规划（MO-MAPF）算法通常通过计算帕累托前沿来生成冲突-free的计划，但它们不明确优化用户定义的偏好，即使偏好可用，仍然很难处理多个目标。现有的算法在目标数量增加时规模扩展不良。", "innovation": "本文提出了一种基于优先级的框架来建模MO-MAPF，并设计了名为Lexicographic Conflict-Based Search (LCBS)的算法，可以计算与目标次序偏好对齐的单一解决方案。LCBS集成了带有优先级感知的低层A*搜索和冲突搜索，避免了构造帕累托前沿，从而实现目标偏好的优先级指导下的高效规划。研究表明，LCBS能够在具有多个目标的实例中计算最优解，而现有的MO-MAPF方法几乎无法处理如此多的目标。LCBS在标准和随机化测试中的成功率较高，尤其是在目标数量增加时比最先进的基线方法表现更好。", "conclusion": "LCBS可以计算出与目标次序偏好对齐的单一解决方案，并且在目标数量增加时能够扩展到更多的目标个数，表现出更强的优化能力和更高的成功率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07161", "html_url": "https://arxiv.org/abs/2510.07161", "title": "使用大型语言模型将领域知识集成到过程发现中", "title_en": "Integrating Domain Knowledge into Process Discovery Using Large Language Models", "authors": "Ali Norouzifar,Humam Kourani,Marcus Dees,Wil van der Aalst", "background": "过程发现的目标是从事件日志中推导出过程模型，以洞察运营行为并为合规检查和过程改进奠定基础。然而，仅从事件数据中得到的过程模型可能并不准确，因为事件日志通常是不完整或受到噪声干扰的，而领域知识作为重要补充资源常被忽视。这些因素可能导致发现的模型在下游任务中缺乏可靠性。因此，本研究提出了一种新的方法，通过使用大型语言模型（LLM）将领域知识纳入过程发现流程中。这种方法利用LLM从领域专家的文本描述中提取出境式规则，并将其用于指导IMr发现算法，该算法可递归构建综合事件日志和提取规则的洞察的过程模型，避免与领域知识矛盾的异常过程结构。研究还协调了LLM、领域专家和后端服务之间的交互，并提供了一个支持这种工作流程的完全实现工具，进行了多个LLM和提示工程策略的广泛评估。研究基于一个包含领域专家参与的真实事件日志进行了实证研究，验证了框架的实用性和有效性。", "innovation": "提出了一种新的框架，利用大型语言模型从文本描述中提取出境式规则，并与事件日志结合使用，指导过程发现算法，以避免与领域知识矛盾的过程结构，提高了模型的可靠性。该方法通过协调LLM、领域专家和后端服务之间的互动，提高了过程发现过程的有效性，同时也实证验证了其在真实场景中的可用性和效果。", "conclusion": "通过使用大型语言模型将领域知识整合到过程发现中，提高了从事件日志中推导出的过程模型的可靠性。实验结果表明，本框架在真实事件日志上的应用不仅展示了较高的实用性和有效性，还具有扩展性，适用于不同的大型语言模型和提示工程策略。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07172", "html_url": "https://arxiv.org/abs/2510.07172", "title": "NewtonBench：评估LLM代理在跨学科科学定律发现中的泛化能力基准", "title_en": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "authors": "Tianshi Zheng,Kelvin Kiu-Wai Tam,Newt Hue-Nam K. Nguyen,Baixuan Xu,Zhaowei Wang,Jiayang Cheng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Tianqing Fang,Yangqiu Song,Ginny Y. Wong,Simon See", "background": "大型语言模型正成为科学定律发现的强有力工具，这是AI驱动科学中的基础挑战。然而，现有的基准测试存在根本性的方法论三难困境，迫使在科学相关性、可扩展性和防记忆化之间进行权衡。此外，这些基准测试将发现简化为静态函数拟合，未能捕捉到揭示嵌入定律的真实科学过程，即通过探索复杂模型系统的交互性来发现潜在原则。论文指出现有的基准测试存在重大缺口，并提出NewtonBench作为解决方案，包含来自12个物理领域的324个科学定律发现任务。", "innovation": "引入NewtonBench作为科学定律发现任务的基准测试，通过使用元物理转移—系统改变经典定律，生成大量可扩展、科学相关且防记忆化的任务。此外，它将评估从静态函数拟合提升到互动模型发现，要求参与者实验性地探索模拟复杂系统以揭示隐藏原则。研究发现，前沿的大语言模型在发现方面表现出了明显的但脆弱的能力，随着系统复杂性的增加而迅速下降，并对观察噪音表现出极高的敏感性。值得注意的是，研究还发现工具辅助效应的反常情况，提供代码解释器可能会阻碍更强大的模型，导致它们因过早从探索转向利用而满足于次优解。这些结果表明，强大的、可泛化的复杂、互动环境中的发现仍然是核心挑战。NewtonBench提供了一个可扩展、稳健且科学真实的测试平台，为衡量真实进展和引导新一代能够进行真正科学发现的AI代理的发展提供了重要工具。", "conclusion": "尽管前沿的大语言模型在发现方面表现出明显的但脆弱的能力，NewtonBench作为一个基准测试平台，证实了其在跨学科科学定律发现中的关键作用，明确了复杂、互动环境中的发现仍然是一个关键挑战，同时也指出了工具辅助效应对高级模型可能产生负面影响的问题。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05336", "html_url": "https://arxiv.org/abs/2510.05336", "title": "WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives", "title_en": "WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives", "authors": "Yongan Yu,Xianda Du,Qingchen Hu,Jiahao Liang,Jingwei Ni,Dan Qiang,Kaiyu Huang,Grant McKenzie,Renee Sieber,Fengran Mo", "background": "现有的气象记录对极端天气事件的社会影响了解有限，而历史档案中包含丰富的第一手叙述，能提供关于社会如何经历和应对极端天气事件的见解。这些叙述中的定性记录对于气候科学家理解社会响应具有重要价值，但由于其庞大的规模、数字化质量差和陈旧的语言，使其难以转化为可用于气候研究的结构化知识。", "innovation": "该研究引入了WeatherArchive-Bench，这是首个用于评估检索增强生成（RAG）系统在历史天气档案中的表现的基准。该基准包括两个任务：WeatherArchive-Retrieval和WeatherArchive-Assessment。通过实验发现，密集检索器在处理历史术语时经常失败，而大型语言模型（LLMs）则经常错误地解释脆弱性和恢复力的概念，这些发现揭示了在应对复杂的社会指标方面的关键限制，并为设计更稳健的气候集中型RAG系统提供了见解。", "conclusion": "该研究针对历史气象档案构建了一个新的数据集和评估框架，并通过广泛的实验验证了潜在的挑战。研究结果和评估框架已公开发布，以便于进一步的研究和应用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.15838", "html_url": "https://arxiv.org/abs/2409.15838", "title": "TiltXter: 基于CNN的 Pasteur 管倾斜角度电触觉渲染的远程操作", "title_en": "TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes", "authors": "Miguel Altamirano Cabrera,Jonathan Tirado,Aleksey Fedoseev,Oleg Sautenkov,Vladimir Poliakov,Pavel Kopanev,Dzmitry Tsetserukou", "background": "当使用机械臂抓取变形物体时，物体的形状会显著变化，导致难以准确感知其对齐状态，进而影响机器人定位和远程操作的准确性。通过触觉反馈来提高用户的精度和灵活性是关键。因此，需要研究不同的方法来将传感器数据解码为触觉刺激。论文介绍了一个用于塑料吸管的远程操作系统，该系统结合了Force Dimension Omega.7 触觉接口和机械臂Robotiq gripper，采用了两个电刺激阵列和两个触觉传感器阵列。研究通过使用卷积神经网络（CNN）来识别倾斜角度，进而提高用户的操作精度。", "innovation": "提出了一种基于CNN的倾斜角度检测方法，该方法能识别变形物体的倾斜数据，并据此生成触觉模式，为远程操作过程中提供电触觉刺激。实验表明，使用CNN算法识别倾斜角度的用户成功率从23.13%提高到了57.9%，而在使用触觉模式的情况下，远程操作的成功率则从53.12%提高到了92.18%。", "conclusion": "通过使用基于CNN的倾斜角度检测方法，能够显著提高用户在远程操作塑料吸管时的识别精度和操作成功率。这种方法为提高远程操作中的触觉反馈提供了新的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06225", "html_url": "https://arxiv.org/abs/2510.06225", "title": "通用多智能体社会仿真框架", "title_en": "Generalized Multi-agent Social Simulation Framework", "authors": "Gang Li,Jie Lin,Yining Tang,Ziteng Wang,Yirui Huang,Junyu Zhang,Shuang Luo,Chao Wu,Yike Guo", "background": "多智能体的社会互动已明显受益于大规模语言模型的发展。然而，现有的仿真系统仍然面临一些挑战，包括难以扩展到多种场景以及由于缺乏模块化设计而导致的再利用性差。", "innovation": "本文设计并开发了一种模块化、面向对象的框架，通过层次结构有机地集成各种基础类，实现了可扩展性和再利用性。还提出了一种记忆总结机制，用于从原始记忆数据中筛选和提炼相关信息，优先处理相关事件和互动。通过选择和组合一些必要的衍生类，定制了特定的仿真环境，成功模拟了社交媒体上的真人社会互动。", "conclusion": "利用所开发的仿真环境，成功复制了现实生活中的在线社会行为。项目源代码将被发布并持续更新。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2204.03521", "html_url": "https://arxiv.org/abs/2204.03521", "title": "DeepXPalm: 使用掌上触觉显示和基于CNN的触觉模式识别实现倾斜和位置渲染", "title_en": "DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition", "authors": "Altamirano Cabrera Miguel,Sautenkov Oleg,Tirado Jonathan,Fedoseev Aleksey,Kopanev Pavel,Kajimoto Hiroyuki,Tsetserukou Dzmitry", "background": "使用机械臂操控变形物体需要用户具备高精度和灵巧的操作能力，这可以通过提供动能和触觉反馈来增加。然而，物体形状可能会动态变化，导致用户对物体对齐感知模糊，并且机器人定位出现错误。因此，需要解决倾斜角度和位置的分类问题，以便向用户提供清晰的触觉图案。背景研究表明，使用直接数据时，用户通过倾斜和位置识别的成功率仅为9.67%，而通过结合使用深度学习算法和预先设置的掩码，这一比例提升到82.5%。这项工作旨在解决此问题并提高用户的操控体验。", "innovation": "该研究提出了一种创新的方法：结合使用多点接触的力反馈设备LinkGlide在用户手掌处提供触觉反馈，并在两个嵌入Robotiq双指夹持器中的触觉传感器阵列中添加触感体验；使用卷积神经网络（CNN）来检测抓取变形物体时的倾斜和位置。CNN生成一个基于识别出的倾斜和位置数据的掩码，用于在远程操作过程中向用户提供进一步的多点触觉刺激。这种方法提高了用户对倾斜和位置的识别精度，显著高于直接使用数据的方法。", "conclusion": "研究发现，通过使用CNN算法和预设的掩码，用户对倾斜和位置的识别率从9.67%提高到82.5%，证明了该方法在提升用户操控变形物体能力的有效性和实际应用中的潜力。该方法不仅提高了用户的操作体验，还通过可视化的触觉反馈增强了用户的远程操控准确性，为未来的远程操作系统开发提供了新的思路和方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04452", "html_url": "https://arxiv.org/abs/2510.04452", "title": "AgentBuilder: 探索界面代理用户体验原型设计的支撑工具", "title_en": "AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents", "authors": "Jenny T. Liang,Titus Barik,Jeffrey Nichols,Eldon Schoop,Ruijia Cheng", "background": "基于生成AI模型的界面代理（简称“代理”）能够依据用户命令自动执行操作。代理的用户体验（即代理体验）开发的一个重要方面在于为非AI工程师的更广泛用户群体提供原型设计工具，因为这些用户能够为设计代理体验提供宝贵的视角。在本文中，作者通过与12名具有不同代理经验水平的参与者进行需求征集研究，探索了代理原型设计系统应该提供的功能。研究中发现了一些关键的原型设计活动以及代理原型设计系统所需要的特性，并以此为基础开发了AgentBuilder原型设计工具。通过让14名参与者使用AgentBuilder进行现场原型设计研究，进一步验证了设计要求并收集了开发者在代理原型设计过程中的相关见解和需求。", "innovation": "作者提出了一种名为AgentBuilder的原型设计工具，它能够为非AI工程师提供设计代理用户体验的支撑。这项研究通过需求征集研究发现了一些关键的代理原型设计活动和所需的特性，并将这些需求应用于AgentBuilder的设计中，从而提供了一种易于使用的代理原型设计解决方案，有助于非专业人士进行更有效的代理体验设计。", "conclusion": "本文通过需求征集研究和使用AgentBuilder工具的原型设计实验，验证了对代理原型设计系统的要求，并揭示了开发者在设计代理过程中遇到的问题和需求。这表明AgentBuilder在提供易于非AI工程师使用的代理体验原型设计工具方面具有潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06238", "html_url": "https://arxiv.org/abs/2510.06238", "title": "在表面地雷和UXO分类中使用MC Dropout进行不确定性量化", "title_en": "Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout", "authors": "Sagar Lekhak,Emmett J. Ientilucci,Dimah Dera,Susmita Ghosh", "background": "使用深度学习检测地表的地雷和未爆炸弹药（UXO）在人道主义排雷领域具有潜力。然而，确定性的神经网络在面对噪声条件或对抗性攻击时容易出现误检或误分类的问题。", "innovation": "本文引入了通过蒙特卡洛（MC）丢弃方法进行不确定性量化的概念，并将其集成到微调的ResNet-50架构中，用于地表地雷和UXO的分类。该方法在模拟数据集上进行了测试，蒙特卡洛丢弃方法有助于量化表征性不确定性，提供了一个额外的预测可靠性指标，有助于在排雷操作中做出更明智的决策。", "conclusion": "在干净、受到对抗性干扰以及噪声的测试图像上进行的实验表明，该模型能够在复杂条件下标记不可靠的预测。本文强调了在排雷中进行不确定性量化的需求，提高了对现有神经网络在排雷中面临对抗性威胁的意识，并强调了为实际应用开发更稳健和可靠的模型的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06235", "html_url": "https://arxiv.org/abs/2510.06235", "title": "使用即用型、刺激调优和微调神经网络的堆叠回归预测电影刺激下fMRI脑响应 (Algonauts 2025 报告]", "title_en": "Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)", "authors": "Robert Scholz,Kunal Bagga,Christine Ahrends,Carlo Alberto Barbano", "background": "目标是预测电影刺激下fMRI脑响应。本文方法结合了大规模语言模型的多模态表示、视频编码器、音频模型以及视觉-语言模型，既使用了即用型又使用了微调版本的模型。通过增加详细的脚本和摘要以增强文本输入，并探索了语言和视觉模型的刺激调优和微调策略。最后，不同模型的预测结果通过堆叠回归进行了组合，取得了良好的预测效果。", "innovation": "文章通过结合多种模态的信息，使用了有详细脚本和摘要的文本输入，并针对语言和视觉模型进行了刺激调优和微调。最终采用了堆叠回归的方法整合不同模型的预测结果。", "conclusion": "通过对fMRI脑响应的预测，文章展示了其在大规模语言模型和视觉-语言模型上的应用，最终排名10位，代码和资源已公开发布，以促进多模态编码模型的发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06224", "html_url": "https://arxiv.org/abs/2510.06224", "title": "使用早期采用者的心智模型探索多智能体生成AI工具的人机协作", "title_en": "Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools", "authors": "Suchismita Naik,Austin L. Toombs,Amanda Snellinger,Scott Saponas,Amanda K. Hall", "background": "随着多智能体生成AI（Gen AI）技术的进步，科技公司如微软开始采纳这些复杂工具，重新定义AI代理为复杂工作流中的活跃合作者，而非被动工具。本研究聚焦于早期采用者和开发者如何理解多智能体的生成AI工具，特别是在人类-AI协作机制、合作动态和透明性方面。", "innovation": "研究人员通过半结构化访谈发现，早期采用者将多智能体系统视为特定角色和任务的智能体\"团队\"，类似人与人之间的协作模型，涵盖了AI主导和AI辅助、用户控制的交互。研究还识别了诸如错误传播、不可预测的代理行为等关键挑战，并强调透明性对于建立信任、验证错误和防止滥用的重要性。", "conclusion": "研究结果指出多智能体系统是动态、角色多样的合作者，可定制以满足不同的需求和工作流程。未来的研究方向将扩展到小组件和人类调解互动的设计，采用CSCW方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06242", "html_url": "https://arxiv.org/abs/2510.06242", "title": "无参考透明自动评价开放式用户调研回答", "title_en": "Transparent Reference-free Automated Evaluation of Open-Ended User Survey Responses", "authors": "Subin An,Yugyeong Ji,Junyoung Kim,Heejin Kook,Yang Lu,Josh Seltzer", "background": "开放式调查问卷的回答为市场营销研究提供了有价值的信息，但低质量的回答不仅给研究人员带来了手动筛选的负担，还可能导致错误结论，突显了有效评估的必要性。现有的自动评估方法针对LLM生成的文本，对人类撰写的带有不同特点的回答评估不足。", "innovation": "提出了一种专门针对人类调查回答的两阶段评估框架。首先进行琐话过滤以排除无意义的回答。然后通过LLM能力从努力度、相关性和完整性三个维度进行评估。实际调研数据的实证分析为这些评价标准提供了支撑。验证结果显示，该框架不仅优于现有指标，还对实际应用如回答质量预测和回答拒绝具有高实践适用性，与专家评估结果有强相关性。", "conclusion": "提出了一种新颖的两阶段评估框架，对面向人类的回答进行有效评估。框架包括锱语言过滤和对努力度、相关性和完整性的评估。评估结果显示，该框架具有较高实践适用性，适用于多种应用场景，并与专家评估具有高度相关性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06244", "html_url": "https://arxiv.org/abs/2510.06244", "title": "科学领域嵌入框架的评估", "title_en": "Evaluating Embedding Frameworks for Scientific Domain", "authors": "Nouman Ahmed,Ronin Wu,Victor Botev", "background": "在特定领域（例如科学领域）的数据中，同一个词可能具有不同的含义，因此需要不同的词表示方法。尽管生成式AI和变换器架构能够生成任何给定文本的上下文化嵌入，但它们在预训练过程中需要大量的时间和计算资源。本文研究旨在针对科学领域找到最优的词表示算法及标记方法，以支持后续的自然语言处理任务，并构建一个全面的评估套件，用于评估和评估新的各种词表示和标记算法，以适应科学领域的需要。", "innovation": "本文的重点是在科学领域寻找最优的词表示和标记方法，并构建了一个包含多个下游任务和相关数据集的评估套件，从而为评估新的词表示和标记算法提供了标准和方法。", "conclusion": "本文通过构建评估套件，测试了多种词表示和标记算法，并制定了一个系统化的评估体系，为优化科学领域的自然语言处理任务提供了新的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06250", "html_url": "https://arxiv.org/abs/2510.06250", "title": "LLM负责的多语言PII注释方法", "title_en": "Scalable multilingual PII annotation for responsible AI in LLMs", "authors": "Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu,Olga Pospelova", "background": "随着大型语言模型（LLMs）的应用越来越广泛，确保它们在不同法规背景下的可靠处理个人身份信息（PII）变得至关重要。", "innovation": "该研究提出了一种可扩展的多语言数据整理框架，旨在提高13个未广泛覆盖的地区高质量PII注释的质量，覆盖约336种地方特有的PII类型。通过分阶段的人工循环注释方法结合语言专长和严格的质量保证，注释的召回率和假阳性率得到了显著提高。通过利用注释者一致性度量和根本原因分析，框架系统地发现和解决注释不一致的问题，从而生成高保真数据集，适合监督微调LLM。", "conclusion": "除了报道经验上的改进，还强调了多语言PII标注过程中常见的注释者挑战，并展示了迭代、基于分析的管道如何提高注释质量和下游模型可靠性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06252", "html_url": "https://arxiv.org/abs/2510.06252", "title": "Dream2Image : 一种用于梦境解码和可视化的人工智能开放多模态EEG数据集", "title_en": "Dream2Image : An Open Multimodal EEG Dataset for Decoding and Visualizing Dreams with Artificial Intelligence", "authors": "Yann Bellec", "background": "目前关于梦境的神经科学研究大多局限于脑电图（EEG）记录和梦境报告，缺乏直接将梦境体验与EEG记录进行关联的数据集。Dream2Image填补了这一空白，汇总了EEG信号、梦境描述和AI生成的图像数据，为神经科学研究提供了新的资源。", "innovation": "Dream2Image 是世界上首个综合EEG信号、梦境描述和AI生成图像的数据集。它基于38名参与者超过31小时的梦境EEG记录，提供了129个样本，包括梦境前的最后15秒、30秒、60秒和120秒的脑活动，梦境原始报告以及梦境的大致视觉重建。这一数据集对梦境研究、梦境解码模型开发和神经科学、心理学、人工智能领域的新方法探索具有重要价值。", "conclusion": "Dream2Image 在Hugging Face和GitHub上开放访问，为其在人工智能和神经科学交叉领域的研究提供了多模态资源。该数据集的主要局限性在于样本较小和梦境回忆的变异，这可能影响其普适性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06253", "html_url": "https://arxiv.org/abs/2510.06253", "title": "由大型语言模型驱动的多步骤块编码任务中代数能力的分级评价设计与实地评估", "title_en": "LLM-Driven Rubric-Based Assessment of Algebraic Competence in Multi-Stage Block Coding Tasks with Design and Field Evaluation", "authors": "Yong Oh Lee,Byeonghun Bang,Sejun Oh", "background": "随着网络教育平台的不断扩展，需要能够衡量学生对问题解答的准确度和其认知过程深度的评估方法，以与课程目标保持一致。本研究提出了基于大型语言模型（LLM）的分级评价框架，用于测量代数能力及多步骤现实情境块编码任务的处理过程。", "innovation": "本研究设计了一套基于评价量表的框架，并利用大型语言模型（LLM）进行评估，能够在学生的解决问题过程中记录所有中间响应，并进行与评价量表一致的成就评价。通过实地研究，验证了该平台的有效性和可扩展性。", "conclusion": "该研究通过实施基于大型语言模型的评价量表显示，其评价结果与专家判断高度一致，并能提供与评价量表一致的过程导向反馈，证明了将基于大型语言模型的评价量表纳入在线数学和STEM教育平台中的可行性及有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06245", "html_url": "https://arxiv.org/abs/2510.06245", "title": "DynBenchmark: 基于社区检测和跟踪基准测试时间网络中的定制化真实基准", "title_en": "DynBenchmark: Customizable Ground Truths to Benchmark Community Detection and Tracking in Temporal Networks", "authors": "Laurent Brisson(IMT Atlantique - DSD),Cécile Bothorel(IMT Atlantique - DSD),Nicolas Duminy(IMT Atlantique, IMT Atlantique - DSD)", "background": "网络模型有助于理解网络动态和演化。现有基准通常忽视了跟踪真实世界网络中社区演化的需求。因此，提出了基于社区的新模型来生成可定制的社区演进结构，能够在真实场景中模拟社区的增长、缩小、合并、分裂、出现或消失等现象。该基准还生成了底层的时变网络，可以观察到节点的出现、消失、或在社区之间的移动。此模型已用于测试三种方法，评估其在跟踪节点聚类成员关系和检测社区演化方面的性能。提供了一个基于Python的库，包括绘图工具和验证指标，让用户能将算法结果与真实数据对比，快速评估动态社区检测算法的有效性。", "innovation": "提出了新的基于社区的模型，能够生成可定制的社区演化结构并生成对应的时变网络。这种方法可以动态模拟社区的各种变化，更好地反映真实世界网络的行为。此外，提供了Python库和评估指标，方便研究人员进行算法的对比和性能评估。这种方法填补了当前基准模型的不足，更好地满足了社区检测和跟踪方面的需求。", "conclusion": "DynBenchmark模型提供了一种新的方法来评估社区检测和跟踪在时间网络中的表现，通过模拟真实世界的社区演化，它能够更准确地评估算法的效果，并提供实用的评估工具。这种方法为相关研究提供了一个强大的基准测试平台。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06249", "html_url": "https://arxiv.org/abs/2510.06249", "title": "TRepLiNa：Layer-wise CKA+REPINA对Aya-23 8B中的低资源机器翻译效果提升", "title_en": "TRepLiNa: Layer-wise CKA+REPINA Alignment Improves Low-Resource Machine Translation in Aya-23 8B", "authors": "Toshiki Nakai,Ravi Kiran Chikkala,Lena Sophie Oberkircher,Nicholas Jennings,Natalia Skachkova,Tatiana Anikina,Jesujoba Oluwadara Alabi", "background": "该研究探讨了解决印度多样化的低资源语言(LRLs)资源缺乏问题的方法。印度存在着严重的语言资源不足的问题，特别是在向高资源语言（HRLs）翻译方面。因此，该研究旨在通过增强解码器型大型语言模型（LLMs）特定内部层之间的跨语言相似性，来提升低资源语言到高资源语言的翻译质量。研究选取了Aya-23 8B模型，并结合了Centered Kernel Alignment (CKA)与REPINA方法，提出了TRepLiNa方法进行实验研究。", "innovation": "提出了TRepLiNa方法，将基于层的中心核对齐（Layer-wise CKA）与参数约束更新（REPINA）方法相结合，通过联合约束模型参数，提高低资源语言翻译的质量。这种方法最适用于数据稀缺的场景，并在MMLoSo共享任务中进行了验证。研究中使用了Aya-23 8B模型，并针对Mundari、Santali和Bhili三种低资源语言，使用了Hindi/ English作为拼接语言进行了实验。实验结果表明，使用TRepLiNa方法可以有效提高低资源语言翻译质量，特别是在数据稀缺的情况下。", "conclusion": "研究结果证明，通过在中层联合矩阵使用TRepLiNa方法 (CKA + REPINA) 是一种经济且实用的方法，可以有效地改善低资源语言的翻译质量，尤其是在数据稀缺的情境下。这种方法为解决印度低资源语言翻译问题提供了一种新的途径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06243", "html_url": "https://arxiv.org/abs/2510.06243", "title": "CoT Referring: 改进基于推理的引用表达任务", "title_en": "CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning", "authors": "Qihua Dong,Luis Figueroa,Handong Zhao,Kushal Kafle,Jason Kuen,Zhihong Ding,Scott Cohen,Yun Fu", "background": "引引用表达理解与分割是评估语言理解与图像理解整合的关键任务，对于多模态大型语言模型（MLLMs）的能力至关重要。现有的多模态模型在处理复杂的查询场景时，表现出参考表达理解与分割的不足。为解决上述挑战，研究人员提出了一种新的策略，即CoT Referring，通过结构化的、链式思考的数据结构提升模态间推理能力，并系统地将文本结构解析为顺序引用步骤，确保在每一步识别关系并进行参确实的一致性对齐，从而提高复杂查询场景中的准确性。此外，研究人员重新构建了训练数据，引入了一种新的输出形式，并为现有数据集提供了新的注释，构建了一个专门针对复杂引用案例的评估基准。这进一步将检测和分割能力整合到统一的多模态框架中，采用新颖的自适应加权损失进行训练，以优化性能。实验结果表明，在自编的基准数据集和RefCOCO/+/g上，该方法的有效性显著优于基线模型，准确率提高了2.5%以上。", "innovation": "提出了CoT Referring方法，通过结构化的链式思考训练数据结构提升跨模态推理能力，系统地将文本结构解析为顺序引用步骤，确保一致的高频一致性对齐。提出了一种新的输出形式和数据集注释，构建了专门针对复杂引用案例的评估基准，并将检测和分割能力整合到统一的多模态框架中，采用自适应加权损失优化性能。", "conclusion": "通过CoT Referring方法在复杂的引用表达任务上的应用，显著提升了多模态语言模型在处理复杂查询场景中的准确性，准确率提高了2.5%以上。这种方法为评估和提升多模态大型语言模型的能力提供了一个有效的基准和实用方案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06262", "html_url": "https://arxiv.org/abs/2510.06262", "title": "Prakriti200：200份基于问卷的印度传统医学Prakriti评估数据集", "title_en": "Prakriti200: A Questionnaire-Based Dataset of 200 Ayurvedic Prakriti Assessments", "authors": "Aryan Kumar Singh,Janvi Singh", "background": "该数据集提供了根据古典阿育吠陀原理评估个体的体征、生理特征和心理特征的标准化双语（英语-印地语）Prakriti评估问卷的回答。问卷分为24个包含身体特征、食欲、睡眠模式、能量水平和气质的多项选择题。问卷遵循了AYUSH/CCRAS指导方针以确保数据收集的全面性和准确性。", "innovation": "该研究开发了一份标准化且无偏见的问卷，其中隐藏了Dosha标签（Vata、Pitta、Kapha），通过Google Forms自动评分系统收集数据。这为研究计算智能、阿育吠陀学和个性化健康管理提供了一个结构化的平台，支持特性分布、相关性分析和预测建模，同时也可以为未来基于Prakriti的研究和智能健康应用的发展提供参考。", "conclusion": "该数据集为研究计算智能、阿育吠陀学和个性化健康分析提供了有结构的平台，支持特性的分布、相关性和预测模型的分析。同时，它还可以作为未来Prakriti相关研究和智能健康应用开发的参考。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06260", "html_url": "https://arxiv.org/abs/2510.06260", "title": "深度学习集成和LLM辅助报告在自动皮肤病变诊断中的应用", "title_en": "Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis", "authors": "Sher Khan,Raz Muhammad,Adil Hussain,Muhammad Sajjad,Muhammad Rashid", "background": "早期检测皮肤恶性肿瘤对于获得有利结果至关重要，但目前的诊断方法存在观察者间变异性大和获取不便的问题。虽然人工智能显示出潜力，但现有的皮肤科系统受限于单一的架构、不同肤色的影像数据偏差以及将自然语言处理视为独立的后续解释，而不是临床决策的一部分，导致实用性不足。", "innovation": "本研究介绍了一个统一框架，重新构想人工智能在皮肤科诊断中的集成，通过两大协同创新实现。首先，一个异构化的、架构多样性相结合的卷积神经网络群建立互补的诊断视角，并内置不确定性机制，将分歧的病例标记出来供专家审查，模拟临床最佳实践。其次，将大型语言模型的能力直接嵌入诊断流程中，将分类输出转化为临床意义评估，同时满足医疗记录需求并提供患者中心的教育，无缝集成产生结构化报告，精准描述病灶、提供诊断推理和可操作的监测指导，使患者能够识别就诊间的早期预警迹象。", "conclusion": "通过在单一系统中解决诊断可靠性和沟通障碍，本方法填补了阻碍先前AI实现临床影响的关键缺口。框架代表了部署可操作皮肤科AI的重要进步，不仅提升诊断精度，还积极支持从初次检测到患者教育的护理连续性，最终提高皮肤病变的早期干预率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06266", "html_url": "https://arxiv.org/abs/2510.06266", "title": "语言模型在演出音乐排行榜中滥用内容的纵向分析", "title_en": "Language models for longitudinal analysis of abusive content in Billboard Music Charts", "authors": "Rohitash Chandra,Yathin Suresh,Divyansh Raj Sinha,Sanchit Jindal", "background": "近年来，音乐中虐待和色情内容急剧增加，尤其是在告示牌音乐排行榜中。然而，缺乏验证这些趋势的研究，以有效制定政策，特别是鉴于这些内容对孩子和年轻人有负面影响。已有研究指出，歌曲中的这类内容会导致不良的行为变化。这项研究利用深度学习方法分析了过去七十年来美国告示牌音乐排行榜中的歌曲歌词，以深化理解这些内容的变化趋势。", "innovation": "本研究采用了深度学习和语言模型，对告示牌音乐排行榜中的歌曲进行了纵向分析，通过情感分析和辱骂检测，特别是关注色情内容。这是首次采用这些先进的技术方法，系统地研究音乐排行榜中滥用内容的变化趋势，并通过语言模型捕捉歌词内容中的细微模式，反映随着时间变化的社会规范和语言使用的变化。", "conclusion": "研究结果显示，自1990年起，流行音乐中的露骨内容显著增加。同时，歌词中含有俚语、露骨、不合适的语言的歌曲比率也在不断提高。这种纵向分析表明，语言模型能捕捉到歌词内容中的微妙模式，反映了社会规范和语言使用随时间的变化。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06240", "html_url": "https://arxiv.org/abs/2510.06240", "title": "工业知识图谱引导的多智能体蒸馏方法及其数据集在可靠工业问答中的应用", "title_en": "Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets", "authors": "Jiqun Pan,Zhenke Duan,Jiani Tu,Anzhi Cheng,Yanqing Wang", "background": "工业问答（QA）系统需要比通用对话模型更高的安全性和可靠性，因为在诸如设备故障诊断等高风险场景中，错误可能导致严重后果。虽然多智能体大型语言模型可以增强推理深度，但它们会遭受不可控的迭代和不可验证的输出。传统的蒸馏方法难以将协作推理能力转移到轻量级、可部署的学生模型中。因此，需要一种方法来解决这些问题，以实现更可靠的工业QA系统部署。", "innovation": "提出了一种基于知识图谱的多智能体蒸馏（KG-MASD）方法。该方法将蒸馏形式化为马尔可夫决策过程，并引入知识图谱作为可验证的结构化先验，以丰富状态表示并确保收敛。通过将协作推理与知识接地相结合，KG-MASD 生成高置信度指令调优数据，并将推理深度和可验证性共同蒸馏到适合边缘部署的紧凑型学生模型中。在工业QA数据集上的实验表明，KG-MASD 在准确度上比baseline提高了2.4%至20.1% ，显著增强了可靠性，这使得在安全关键的工业场景中实现可信的人工智能部署成为可能。", "conclusion": "实验结果表明，KG-MASD 在准确性上比baselines 提高了2.4%至20.1%，并且显著增强了可靠性，使得在安全关键的工业场景中实现可信的人工智能部署成为可能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06263", "html_url": "https://arxiv.org/abs/2510.06263", "title": "为急诊医生设计的双阶段和轻量级病历摘要系统", "title_en": "Dual-stage and Lightweight Patient Chart Summarization for Emergency Physicians", "authors": "Jiajun Wu,Swaleh Zaidi,Braden Teitge,Henry Leung,Jiayu Zhou,Jessalyn Holodinsky,Steve Drew", "background": "电子健康记录（EHRs）中包含大量的未结构化的临床数据，这些数据可能会使急诊医生难以识别关键信息。目前，需要一种能够在不侵犯患者隐私的情况下，在紧急情况下快速而准确地从这些数据中提取关键信息的方法。为此，研究人员提出了一种双阶段的病历摘要系统，该系统能够在嵌入式设备上完全运行，实现离线临床摘要，同时保持患者的隐私。该系统采用双设备架构，使用Jetson Nano-R设备检索相关病历段落，使用另一个Jetson Nano-S设备生成结构化摘要，两者通过轻量级的套接字链路进行通信。摘要输出包括两个方面：一是固定格式的关键发现列表，二是针对临床查询的上下文特定的叙述。", "innovation": "该研究提出了一种双设备架构的系统，能够在嵌入式设备上完全运行，支持离线的病历摘要，从而避免了因网络延迟或隐私问题而导致的处理延迟。系统使用了一个小型语言模型（SLM）来生成摘要，操作受限于两个NVIDIA Jetson设备，显著减少了资源需求。研究还使用了一种基于LLM（大型语言模型）的评估机制来评估摘要的质量，包括事实准确性、完整性和清晰度。初步结果显示，该系统可以在不到30秒内生成有用的病历摘要并保持高效的性能。", "conclusion": "该研究提出了一种双阶段的轻量级病历摘要系统，能够在嵌入式设备上完全运行，实现了离线环境下的病历摘要，同时保持病人隐私。实验结果显示，该系统能够在短时间内生成有用并且高质量的摘要，为急诊医生提供了有效的辅助工具。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06278", "html_url": "https://arxiv.org/abs/2510.06278", "title": "RVFL-X：基于复杂转换实值表格数据的新随机网络", "title_en": "RVFL-X: A Novel Randomized Network Based on Complex Transformed Real-Valued Tabular Datasets", "authors": "M. Sajid,Mushir Akhtar,A. Quadir,M. Tanveer", "background": "近期，由于理论基础的支持，神经网络显示出强大的表示能力，特别是使用复数。然而，复数在随机神经网络（RNNs）中的应用受到限制，主要因为缺乏有效的将实值表格数据转换为复数值表示的方法。", "innovation": "本文提出了一种利用自然转换与基于自编码器的方法来生成复数值表示的新方法，进而提出了基于这些机制的RVFL-X（Random Vector Functional Link-X）复杂值扩展网络。相比原始的RVFL架构，RVFL-X保持了其简单性和高效性，同时允许使用复数进行数据处理和生成实值输出。", "conclusion": "对80个实值UCI数据集进行全面评估显示，RVFL-X在各种应用领域中表现稳健且优于原始RVFL和最新RNN变种，证实了其在复杂表示和高效率方面的优势。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06270", "html_url": "https://arxiv.org/abs/2510.06270", "title": "MCCE:一种多大规模语言模型协作共进化框架", "title_en": "MCCE: A Framework for Multi-LLM Collaborative Co-Evolution", "authors": "Nian Ran,Zhongzheng Li,Yue Wang,Qingsong Ran,Xiaoyuan Zhang,Shikun Feng,Richard Allmendinger,Xiaoguang Zhao", "background": "多目标离散优化问题，如分子设计，因其庞大的非结构化组合空间而极具挑战性。传统进化算法往往容易陷入局部最优解，而专家知识可以提供加速收敛的关键指导。大规模语言模型（LLMs）由于其强大的先验知识和推理能力，成为在专家知识重要的情况下自然的优化工具。然而，封闭源code的LLMs虽然在探索方面强大，却不可以更新参数，因而无法从经验中学习。相反，较小的开源模型虽然可以不断微调，但在广度上的知识和推理能力上则较弱。", "innovation": "我们提出了一种名为Multi-LLM Collaborative Co-evolution (MCCE)的混合框架，该框架结合了一个冻结的封闭源LLM和一个轻量级可训练模型。该系统维持了过去搜索过程的路径记忆，小模型通过强化学习逐步改进，两个模型共同支持和互补进行全局探索。与模型蒸馏不同，这一过程通过相互启发来增强两个模型的能力。", "conclusion": "在多目标药物设计基准测试中的实验表明，MCCE在帕累托前沿质量上达到了最先进的水平，并且持续超越基线方法。这些结果强调了一种新的范式，即利用知识驱动的探索与经验驱动的学习相结合，使混合LLM系统能够持续进化。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06275", "html_url": "https://arxiv.org/abs/2510.06275", "title": "XRec可解释推荐中的再现性研究", "title_en": "Reproducibility Study of \"XRec: Large Language Models for Explainable Recommendation\"", "authors": "Ranjan Mishra,Julian I. Bibo,Quinten van Engelen,Henk Schaapman", "background": "本研究旨在重现Ma等（2024）发表的论文‘XRec：大型语言模型的可解释推荐’中的工作，该论文提出了一种面向模型的可协作指令微调框架XRec，使得大型语言模型（LLMs）能够为用户提供生成推荐的全面解释。研究人员利用Llama 3替代GPT-3.5-turbo作为评估模型，实现对原研究结果的再现。", "innovation": "本研究在原研究的基础上进行了扩展，修改了XRec模型中的混合专家模块的输入嵌入或删除输出嵌入，进一步探讨了协作信息对解释结构的影响。研究表明，虽然XRec在某些方面效果不错，但在某些指标上并不总是优于基线模型。同时也突显了混合专家嵌入在生成解释结构中的重要性。", "conclusion": "研究结果表明，XRec能够生成个性化的解释，并通过引入协作信息提高了稳定性。尽管如此，XRec在所有指标上未必优于所有基线模型。研究提供了开源的评估实现，增强了研究者和实践者的可访问性。完整的代码库可在特定链接获取。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06267", "html_url": "https://arxiv.org/abs/2510.06267", "title": "RareGraph-Synth：超稀有疾病中生成保护隐私的合成患者轨迹的知识指导扩散模型", "title_en": "RareGraph-Synth: Knowledge-Guided Diffusion Models for Generating Privacy-Preserving Synthetic Patient Trajectories in Ultra-Rare Diseases", "authors": "Khartik Uppalapati,Shakeel Abdulkareem,Bora Yimenicioglu", "background": "本文介绍了一种新的知识指导型连续时间扩散框架RareGraph-Synth，用于生成超稀有疾病的现实且隐私保护的合成电子健康记录（EHR）轨迹。这项工作综合了多个公开资源，包括Orphanet/Orphadata，人类表型本体（HPO），GARD稀有疾病知识图谱，PrimeKG和FDA不良事件报告系统（FAERS），形成了一个包含约800万个类型化边的异构知识图。通过从这个800万个边的知识图中提取的元路径分数来调整前向随机微分方程中的每令牌噪声计划，推动生成生物学上合理的实验室-药物-不良事件共现现象，同时保持基于评分的扩散模型的稳定性。反向解码器在不泄露保护健康信息的情况下生成带有时间戳的实验室代码，药物代码和不良事件标志三重数据序列。该模型在仿真的超稀有疾病队列上表现出色，对抗性评估显示，它在不牺牲下游预测效用的情况下，显著提高了数据隐私保护能力。", "innovation": "RareGraph-Synth通过直接将生物医学知识图谱集成到扩散噪声计划中，同时提高了真实性和隐私性，这对罕见疾病研究的数据共享有着重要的安全意义。与其他方法相比，它在某些指标上显示出显著的优势，尤其是在保持相同预测能力的情况下，显著降低了最大均方差异。此外，通过对数十随机基线模型的黑盒成员推断评估表明，该模型具有很强的防重新识别能力。这表明，集成生物医学知识图谱可以直接增强生成模型的真实性和隐私性。", "conclusion": "本文提出的方法 RareGraph-Synth 在生成超稀有疾病的合成 EHR 轨迹时，通过直接结合生物医学知识图谱到扩散噪声计划中，实现了显著提升的数据真实性和隐私性。实验结果表明，该模型不仅能够产生生物学上可行的关联现象，同时在保护个人隐私方面也有卓越的表现，这表明了该方法对超稀有疾病研究中数据共享的价值。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06276", "html_url": "https://arxiv.org/abs/2510.06276", "title": "一种基于变分正则化的癫痫相关MRI图像分割框架", "title_en": "A Total Variation Regularized Framework for Epilepsy-Related MRI Image Segmentation", "authors": "Mehdi Rabiee,Sergio Greco,Reza Shahbazian,Irina Trubitsyna", "background": "FCD（焦点皮质发育不良）是顽固性癫痫的主要原因，由于其病灶细微且难以在脑MRI中识别，因此对3D多模态脑MRI图像中FCD区域的准确分割至关重要。然而，这一任务由于标注数据有限、病灶体积极小且对比度弱、处理3D多模态输入的复杂性以及对平滑度和解剖学一致性的需求，依然极具挑战性。标准体元损失函数往往无法充分解决这些问题。因此，本研究旨在提出一种新的框架来解决FCD区域的3D脑MRI分割问题。", "innovation": "本研究采用最新的增强式编码-解码架构，并引入了一种结合Dice损失和各向异性Total Variation（TV）项的新型损失函数。该方法通过结合这两种损失函数，鼓励空间平滑性并减少假阳性簇，同时避免了后期处理的依赖性。此外，框架还在一个公开的FCD数据集上得到了评估，该数据集包括85名癫痫患者，表现出了更高的分割准确性和一致性，相比于传统的损失形式，使用提出TV损失的模型在Dice系数上提升了11.9%，在精确度上提高了13.3%，并且假阳性簇减少了61.6%。", "conclusion": "本研究提出了一种新的变分正则化框架，用于癫痫相关的MRI图像分割。该框架结合了最先进的变压器增强编码-解码架构和新型的Dice损失与TV项相结合的损失函数，提高了分割的准确性和一致性，并减少了假阳性簇的数量。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06280", "html_url": "https://arxiv.org/abs/2510.06280", "title": "外科医生是印度男性，言语治疗师是白人女性：医疗专业人士中视觉语言模型的偏见审计", "title_en": "Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals", "authors": "Zohaib Hasan Siddiqui,Dayam Nadeem,Mohammad Masudur Rahman,Mohammad Nadeem,Shahab Saquib Sohail,Beenish Moalla Chaudhry", "background": "视觉语言模型，如CLIP和OpenCLIP，可以从海量数据中编码和反映出医学职业与人口统计学属性之间的刻板印象关联。本文提出了一种评估协议，用于量化这些关联中的偏见并评估其运营风险，特别针对医疗保健领域。研究发现，多种医学角色和视觉模型中存在一致的人口统计学偏见。这一发现强调了在AI助力的招聘和工作分析领域识别偏见的重要性，因为这可能对公平性、合规性和患者信任产生下游影响。", "innovation": "本文的创新在于提出了一个评估协议，定义了一个包括临床医师和相关医疗职业的分类体系，设计了一套与职业相关的提示集来探查模型行为，并对比了人口统计学偏差和一个平衡的面部数据集。该研究通过实证方法揭示了多种角色和视觉模型中的一致性人口统计学偏见。", "conclusion": "本文工作突显了在关键领域，如医疗保健，识别偏见的重要性，尤其是随着AI赋能的招聘和劳动力分析应用的增加，这些偏见可能会对公平性、合规性和患者信任产生潜在影响。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06281", "html_url": "https://arxiv.org/abs/2510.06281", "title": "使用深度学习提高GONG太阳图像的空间分辨率至GST质量", "title_en": "Improving the Spatial Resolution of GONG Solar Images to GST Quality Using Deep Learning", "authors": "Chenyang Li,Qin Li,Haimin Wang,Bo Shen", "background": "高分辨率（HR）的太阳成像对于捕捉细尺度动态特征（如日珥和纤维）至关重要。然而，全盘Hα图像的空间分辨率有限，不足以解析这些小尺度结构。因此，需要一种方法来提高低分辨率（LR）的GONG全盘Hα图像的质量，使其达到与比Big Bear Solar Observatory/Goode Solar Telescope（BBSO/GST）进行的HR观察相当的水平。", "innovation": "本文提出了基于生成对抗网络（GAN）的超分辨率方法，使用Real-ESRGAN结合Residual-in-Residual Dense Blocks和相对判别器，将GONG的数据提升至接近BBSO/GST观测的清晰度。该模型在太阳黑子外周的细微特征恢复和日珥、纤维的细微特征解析方面表现出色，达到了平均均方误差（MSE）467.15，均方根误差（RMSE）21.59，相关系数（CC）0.7794。但图像对之间的轻微对齐偏差限制了定量性能。", "conclusion": "该研究模型成功提高了GONG图像的空间分辨率，但图像对之间的轻微对齐偏差限制了定量性能，并打算未来通过扩展数据集来进一步提高重建质量。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06283", "html_url": "https://arxiv.org/abs/2510.06283", "title": "SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation", "title_en": "SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation", "authors": "Sashank Makanaboyina", "background": "增量脑肿瘤分割对于适应不断发展的临床数据集至关重要，而不重新训练所有以前的数据。然而，灾难性遗忘是一个主要的障碍，模型会丢失以前获得的知识。尽管最近的一些增量学习框架结合了知识蒸馏可以部分减轻遗忘，但它们依赖生成性回放或辅助存储。扩散模型在细化肿瘤分割方面表现出色，但在增量学习背景下的应用尚未探索。", "innovation": "提出了Synthetic Error Replay Diffusion (SER-Diff)框架，该框架将基于扩散的细化与增量学习统一。SER-Diff利用冻结的教师扩散模型生成来自过去任务的合成错误图，在针对新任务的训练过程中回放这些图。结合Dice损失，用于新数据，以及知识蒸馏损失，用于回放的错误的双损失公式确保了适应性和保留知识的双重目标。实验结果表明SER-Diff优于之前的模型，实现了最高且最精确的Dice分数和最低的 HD95值。", "conclusion": "SER-Diff不仅缓解了灾难性遗忘，还提供了更准确和解剖学上更协调的分割结果，适用于不断发展的数据集。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06291", "html_url": "https://arxiv.org/abs/2510.06291", "title": "Traj-Transformer: 使用Transformer的扩散模型进行GPS轨迹生成", "title_en": "Traj-Transformer: Diffusion Models with Transformer for GPS Trajectory Generation", "authors": "Zhiyang Zhang,Ningcong Chen,Xin Zhang,Yanhua Li,Shen Su,Hui Lu,Jun Luo", "background": "GPS设备的广泛应用推动了时空数据挖掘技术的发展，使得机器学习模型能够模拟人类决策并生成真实的轨迹。这种方法不仅降低了数据收集成本，还解决了隐私问题。现有研究显示，扩散模型能够生成高质量的轨迹，但大多数现有方法依赖基于卷积的架构（如UNet）来预测扩散过程中的噪声，这通常会导致显著的偏差和对细粒度街道级详细信息的丢失，因为模型的容量有限。", "innovation": "本文提出了一种新的模型Trajectory Transformer，它使用Transformer作为支撑结构，同时进行条件信息嵌入和噪声预测。并探索了两种GPS坐标嵌入策略：位置嵌入和经度-纬度嵌入。实验结果显示，Trajectory Transformer 显著提高了生成质量，并有效缓解了先前方法中存在的偏差问题。", "conclusion": "通过在两个真实世界数据集上的实验，证明了Trajectory Transformer在生成高质量轨迹方面的优势，改进了先前方法中存在的偏差问题。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06292", "html_url": "https://arxiv.org/abs/2510.06292", "title": "ChainMPQ：缓解关系幻觉的交错图文推理链", "title_en": "ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations", "authors": "Yike Wu,Yiwei Wang,Yujun Cai", "background": "虽然大型视觉-语言模型（LVLMs）在多模态任务中取得了优异的成绩，但幻觉问题仍然影响其可靠性。在这三类幻觉中——对象、属性和关系——关系幻觉占比最大，但受到的关注最少。为此，本文对LVLMs中的关系推理进行了改进方法研究，提出了一种无需训练的方法ChainMPQ，通过利用积累的图文记忆来提升关系推理能力。", "innovation": "ChainMPQ通过从问题中提取主语和宾语关键字来增强相应的图像区域，并构建多视角问题来聚焦关系的三个核心组件：主语、宾语和连接它们的关系，这些问题按顺序输入模型。早期的文字和视觉记忆为后续步骤提供支持上下文，从而形成交错的图文链，指导渐进的关系推理。实验表明，ChainMPQ显著降低了关系幻觉，且消融实验进一步验证了其三个核心模块的有效性。", "conclusion": "ChainMPQ通过交错的图文推理链显著减少了关系幻觉，证明了其在提高LVLMs关系推理准确性方面的重要作用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06293", "html_url": "https://arxiv.org/abs/2510.06293", "title": "BlockGPT：基于帧级自回归的雨量时空建模", "title_en": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression", "authors": "Cristian Meo,Varun Sarathchandran,Avijit Majhi,Shao Hung,Carlo Saccardi,Ruben Imhoff,Roberto Deidda,Remko Uijlenhoet,Justin Dauwels", "background": "预测降水图是一项高度复杂的时空建模任务，对于减轻极端天气事件的影响至关重要。短期降水预测，即现在casting，需要既准确又计算效率高的模型以适应实时应用。现有的方法，如基于令牌的自回归模型，常常受到不合理的归纳偏见和缓慢推断的影响，而扩散模型则计算成本较高。为了解决这些问题，我们引入了BlockGPT，这是一种使用批量标记化（Block）方法的生成自回归变压器，能够在每个时间步骤预测完整的二维字段（帧）。", "innovation": "BlockGPT采用帧级自回归的方法，通过在每个帧内部使用自我注意力并在帧之间使用因果注意力来分解时空。作为一种模型无偏见的视频预测范式，我们将其应用于降水现在casting，相比现有的先进基线（包括基于令牌的NowcastingGPT和基于扩散的DiffCast+Phydnet模型），BlockGPT展现出更高的准确性和事件定位效果，并且推理速度最高可比基线快31倍。", "conclusion": "我们对BlockGPT在两个降水数据集（KNMI和SEVIR）上进行了评估，并将其与最新的基线模型进行了比较。结果表明，BlockGPT在分类指标衡量的事件定位和推断速度方面均优于其他模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06343", "html_url": "https://arxiv.org/abs/2510.06343", "title": "利用大型语言模型进行网络安全风险评估——森林网络物理系统的案例", "title_en": "Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems", "authors": "Fikret Mert Gültekin,Oscar Lilja,Ranim Khojah,Rebekka Wohlrab,Marvin Damschen,Mazen Mohamad", "background": "在关键软件系统中，网络安全活动变得至关重要，风险评估是其中的核心之一。许多软件团队中缺乏网络安全专家，或仅由少数专家负责。这导致了网络安全专家的高工作负担，软件工程师不得不自己完成网络安全活动。因此，需要一个工具来辅助网络安全专家和工程师在风险评估过程中评估漏洞和威胁。", "innovation": "本研究探讨了利用本地托管的大语言模型（LLMs）结合检索增强生成，支持森林网络物理系统的网络安全风险评估，同时遵守限制外部数据共享的数据保护和隐私要求。通过与12名专家访谈、互动会议和调查问卷的研究，结果表明，LLMs可以帮助网络安全专家生成初始风险评估、识别威胁和进行冗余检查。", "conclusion": "尽管存在信任问题，专家们愿意在特定的评估和支持角色中利用LLMs，而不是完全依赖其生成能力。该研究为网络安全物理系统的关键领域中的风险评估过程提供了支持，并鼓励使用基于LLM的代理来支持这种过程。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06295", "html_url": "https://arxiv.org/abs/2510.06295", "title": "高效幻视感知损失与自适应划分的高分辨率图像编辑", "title_en": "Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling", "authors": "Young D. Kwon,Abhinav Mehrotra,Malcolm Chadwick,Alberto Gil Ramos,Sourav Bhattacharya", "background": "高分辨率（4K）图像到图像的合成对于移动应用变得越来越重要。现有的用于图像编辑的扩散模型在资源受限的设备上部署时，在内存和图像质量方面面临重大挑战。", "innovation": "我们提出了MobilePicasso，一种新型系统，能够在高效和低成本的情况下进行高分辨率图像编辑，通过三个阶段：（i）标准分辨率下的图像编辑，（ii）潜空间投影以克服像素空间转换，（iii）使用自适应上下文保留划分进行编辑图像潜空间的放大。与现有方法相比，它不仅提高了18-48%的图像质量，减少了14-51%的幻视，同时显示出显著降低的延迟和少量的内存增加。令人惊讶的是，与在A100 GPU上运行的服务器端高分辨率图像编辑模型相比，MobilePicasso的设备运行时更快，甚至仅比之前的工作多9%的运行时内存增加。", "conclusion": "MobilePicasso不仅提升了图像质量，减少了幻视，还显著降低了延迟，而且内存占用相对较小，实现在设备上的快速图像编辑能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06290", "html_url": "https://arxiv.org/abs/2510.06290", "title": "跨多视图生物图谱的软证据融合图神经网络用于癌症驱动基因识别", "title_en": "Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene Identification across Multi-View Biological Graphs", "authors": "Bang Chen,Lijun Guo,Houli Fan,Wentao He,Rong Zhang", "background": "识别癌症驱动基因（CDGs）对于理解癌症机制和开发靶向治疗方法至关重要。图神经网络（GNNs）已被用于通过捕捉生物相互作用网络中的模式来识别CDGs。然而，大多数基于GNN的方法依赖于单一的蛋白质-蛋白质相互作用（PPI）网络，忽略了其他生物网络提供的互补信息。一些研究通过特征对齐和一致性约束来整合多个网络，学习统一的基因表示以用于CDG识别，但这种基于表示的融合往往假定网络间基因关系的一致性，可能忽略网络异质性和引入冲突信息。为解决这一问题，我们提出了Soft-Evidence Fusion Graph Neural Network (SEFGNN)，一种在决策层面进行跨多个网络CDG识别的新型框架。SEFGNN不强制特征层面的一致性，而是将每个生物网络视为独立的证据源，并利用Dempster-Shafer Theory (DST)在决策层面进行不确定性感知融合。为了减轻DST带来的过度自信心的风险，进一步引入了Soft Evidence Smoothing (SES) 模块，改善排名稳定性同时保留辨别性能。", "innovation": "提出了Soft-Evidence Fusion Graph Neural Network（SEFGNN）框架，该框架在决策层面整合来自多个生物网络的证据，使用Dempster-Shafer Theory（DST）进行不确定性感知融合，并引入Soft Evidence Smoothing（SES）模块以提高排名稳定性。这是一种不同于以往基于表示层面的一致性假设的方法，旨在解决网络异质性和引入冲突信息的问题，提高了CDG识别的准确性和发现新颖CDG的能力。", "conclusion": "在三个癌症数据集上的实验表明，SEFGNN持续优于最先进的基线方法，在发现新颖CDG方面具备强潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06296", "html_url": "https://arxiv.org/abs/2510.06296", "title": "VeriEquivBench: 一个无需参考答案评估形式化验证代码的等价性分数", "title_en": "VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code", "authors": "Lingfei Zeng,Fengdi Che,Xuhan Huang,Fei Ye,Xu Xu,Binhang Yuan,Jie Fu", "background": "形式化验证是确保由大型语言模型（LLMs）生成的代码正确性的下一个前沿领域。虽然如Dafny般的工具能够生成代码和形式化规范，并原则上可以证明其与用户意图的一致性，但规格质量的评估仍是进展的瓶颈。当前的基准测试依赖于与真实规格的匹配，这需要手动和专家密集的过程，限制了现有数据集规模，并且还存在可靠性问题。", "innovation": "本文提出了VeriEquivBench，一个包含2,389个复杂算法问题的新基准，旨在测试当前模型在代码生成和形式推理方面的局限性。该评估框架以形式上定义的度量——等价分数——替代了真实规格匹配，从而严格验证生成规范和代码的质量。结果表明，对于最先进的LLMs，生成形式验证代码依然是一个巨大的挑战。", "conclusion": "这不仅强调了任务的难度，也指出了需要像VeriEquivBench这样的基准来推动可扩展和可靠的编码代理的发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06350", "html_url": "https://arxiv.org/abs/2510.06350", "title": "要求它：在线内容管理中的规则违规预测问答", "title_en": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation", "authors": "Mattia Samory,Diana Pamfile,Andrew To,Shruti Phadke", "background": "在线社区依赖于平台政策和社区自定义规则来界定可接受的行为并维护秩序。然而，这些规则在不同社区间差异很大，随时间变化，并且执行不一致，这给透明性、治理和自动化带来了挑战。本研究探讨了在大规模环境下规则与执行之间的关系，旨在克服现有问题，提出针对性的解决方案。", "innovation": "本研究引入了ModQ，一种针对规则敏感的在线内容审核的新型问答框架。与之前的分类或生成方法不同，ModQ在推理阶段基于整个社区规则集对给定评论进行识别，并确定适用的最佳规则。研究展示了两种模型变体——提取式和多项选择问答，并使用Reddit和Lemmy的大规模数据集进行训练。实验结果表明，相比现有最佳基线，ModQ模型在识别审核相关规则违规方面表现更佳，同时保持轻量级且可解释性强。ModQ模型对未见过的社区和规则具有良好的泛化能力，有助于低资源环境下的内容审核和动态治理环境。", "conclusion": "研究证明了ModQ模型的有效性和实用性，能够适应不同的在线社区，支持低资源和动态治理环境中的内容审核。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06303", "html_url": "https://arxiv.org/abs/2510.06303", "title": "SDAR: 一种用于可扩展序列生成的协同扩散- 自回归范式", "title_en": "SDAR: A Synergistic Diffusion-AutoRegression Paradigm for Scalable Sequence Generation", "authors": "Shuang Cheng,Yihan Bian,Dawei Liu,Yuhua Jiang,Yihao Liu,Linfeng Zhang,Wenhai Wang,Qipeng Guo,Kai Chen,Biqing Qi,Bowen Zhou", "background": "目前，自回归模型在训练效率方面表现出色，但在推断时通常需要序列化生成，这限制了其并行生成能力；而扩散模型则在推断时具备并行生成的优势，但在训练效率方面表现较差。SDAR通过将自回归模型轻量级地转换为块状扩散模型，结合了两者的优点，旨在构建一种计算效率高且推断时支持并行生成的可扩展自回归框架。", "innovation": "SDAR创新性地提出了一种新的范式，通过简短、数据高效的适应过程将已训练的自回归模型转化为块状扩散模型。SDAR在推断时能够自回归地生成序列以保持全局一致性，同时利用离散扩散过程并行解码区块内的所有标记。该方法在不增加显著成本的情况下实现了高效的自回归到扩散的转换，并且通过密集和混合专家架构的研究证明了更大模型的鲁棒性增强，进一步提高了推理速度和并行生成能力。此外，SDAR还展现了增强的推理能力和领域适应性，特别是在科学推理基准测试中，其混合专家模型在GPQA和ChemBench等挑战性任务上超越了其自回归版本，并且通过测试时的放大方法如多数投票和pass@k取得了进一步的改进。", "conclusion": "SDAR结合了自回归和扩散模型的优点，构建了一种计算效率高且支持并行生成的可扩展自回归框架。研究结果表明，SDAR不仅能够保持与自回归模型相当的性能，而且还具备显著的并行生成能力，适用于大规模模型应用。通过进一步验证，SDAR能够增强推理能力和领域适应性，为大型模型的高效生成提供了新的思路。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06383", "html_url": "https://arxiv.org/abs/2510.06383", "title": "保护去标识化文档免受基于搜索的链接攻击", "title_en": "Protecting De-identified Documents from Search-based Linkage Attacks", "authors": "Pierre Lison,Mark Anderson", "background": "去标识化模型可以隐藏文档中提到的个人身份，但无法解决连接风险问题，即从去标识化文本逆向追溯到原始来源的可能性。一种直接的方法是从去标识化文档中提取短语，并检查这些短语在原始数据集中的存在。本文提出了一个方法，可以在保持文本语义完整性的前提下抵御基于搜索的链接攻击。", "innovation": "本文提出了一种双步方法：首先构建文档集合中N-gram的倒排索引，用于高效确定哪些N-gram出现在少于k个文档中（单独或与其他N-gram组合）。然后使用基于LLM的重写器迭代地重新表述这些片段，直到无法进行链接为止。实验结果显示，该方法能够有效地防止基于搜索的链接攻击，同时保持原始内容的真实性。", "conclusion": "该方法能够在保持原文语义完整性的前提下有效防止基于搜索的链接攻击，证明了其在去标识化文档保护方面的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06298", "html_url": "https://arxiv.org/abs/2510.06298", "title": "使用Transformer进行特征融合的RGBD注视跟踪", "title_en": "RGBD Gaze Tracking Using Transformer for Feature Fusion", "authors": "Tobias J. Bauer", "background": "本文的论文主题是基于RGBD图像（包含RGB颜色和深度D信息）实现基于AI的眼球追踪系统的实现。为了融合从图像中提取的特征，使用了基于Transformer架构的模块。选择RGBD输入图像与Transformer组合，是因为这一组合尚未被研究过。此外，创建了一个新的数据集用于训练AI模型，因为现有数据集要么没有深度信息，要么仅包含用于视点估计的标签，这些标签不适合用于注视角度估计。总共在三个不同数据集上进行了各种模型配置的训练、验证和评估。目的是实现实时管道中的注视方向和注视点估计。引入了Lian等人早期工作中的生成对抗网络（GAN）架构，用于同时去除深度图的瑕疵和提取头部姿态特征。这使得模型在ShanghaiTechGaze+数据集上的均方欧氏误差达到了38.7mm。作者在本文中的模型使用基于Transformer的特征融合模块，该模块在ShanghaiTechGaze+数据集上的均方欧氏误差为55.3mm。使用没有预训练GAN模块的模型将均方欧氏误差降低到30.1mm。使用多层感知器（MLP）替代Transformer模块减小了误差至26.9mm。", "innovation": "本文的主要创新在于使用了基于Transformer的模块进行特征融合，验证了将RGBD输入图像与Transformer结合的有效性。此外，通过创造一个新的数据集，它提供了比现有数据集更丰富和更适合任务的数据，节省了将深度信息注入现有图像集合的复杂步骤。对比分析结果还表明，使用MLP替换Transformer模块可以在一定程度上改善性能。主要创新点还包括在多个不同数据集上的表现和对照实验结果，展示了非Pre-trained GAN模块方案的优越性。", "conclusion": "本文基于对RGBD数据和不同配置研究报告的分析和实验结果，采用Transformer模块成功实施了一种新的眼球追踪系统。实验结果表明，在不同数据集上，无论是采用Transformer模块还是更换为MLP模块，模型的性能均有不同程度的提升。尤其是在Oth-Gaze-Estimation数据集上的表现更为显著。文章结论指出，Transformer结构和新的自创数据集的有效性，并强调了比已有模型更好的性能和方案的稳健性。同时，也提醒了未来可能的工作方向如进一步改善性能和扩展到更多的应用中。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系型转换器：朝着关系型数据零样本基础模型的途径", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练变压器在零样本提示下能够迅速适应新序列建模任务，但在关系领域，仍然缺乏能够在不同数据集和任务之间进行迁移的架构。根本挑战在于关系数据的多样性，包括不同的异质模式、图结构和功能依赖关系。", "innovation": "本文提出了关系型转换器(Relational Transformer, RT) 架构，该架构能在多样化的关系数据库上进行预训练，无需特定任务或数据集的微调或引入上下文示例即可直接应用于未知数据集和任务。RT 在表/列元数据上进行单元格标记，通过屏蔽标记预测进行预训练，并利用一种新的‘关系注意力’机制处理列、行和主外键链接。RT 在跨越不同任务（如流失和销售预测）的 RelBench 数据集上进行预训练，零样本性能非常强，单次前向传播 22M 参数模型在二分类任务上达到 94% 的完全监督 AUROC，而 27B 参数的大语言模型则为 84%。", "conclusion": "我们的实验表明，RT 的零样本迁移能够利用任务-表上下文、关系注意力模式和模式语义。总体而言，RT 为关系型数据提供了现实的基础模型途径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06353", "html_url": "https://arxiv.org/abs/2510.06353", "title": "TransFIRA：将迁移学习应用于面部图像识别性评估", "title_en": "TransFIRA: Transfer Learning for Face Image Recognizability Assessment", "authors": "Allen Tu,Kartik Narayan,Joshua Gleason,Jennifer Xu,Matthew Meyn,Tom Goldstein,Vishal M. Patel", "background": "在非受限环境中，如监控、视频和网络图像中的面部识别必须应对姿态、模糊、光照和遮挡等极端变化，而传统的视觉质量指标往往无法准确预测输入是否能够被部署的编码器真正识别。现有的图像质量评估（FIQA）方法通常依赖于视觉启发式、筛选标注或者计算繁重的生成管道，使得它们的预测与编码器的决策边界脱节。因此，需要一种轻量级、无需标注的框架，直接将识别性与嵌入空间相结合。TransFIRA正是这种需求的解决方案，通过定义基于类中心相似性和类中心角度分离的识别性，提出一种与决策边界对齐的自然评价标准，进而改进现有的FIQA方法，提高可解释性和泛化能力。", "innovation": "TransFIRA引入了三种创新：(i) 通过类中心相似性（CCS）和类中心角度分离（CCAS）定义识别性，首次提出一种自然且与决策边界对齐的标准；(ii) 提出了一种识别性导向的聚合策略，无需外部标签、启发式方法或专用训练，能实现最先进的验证精度；(iii) 推动了识别性评估的应用范围，包括面部识别、解释性增强与可解释性强化的身体识别评价。", "conclusion": "实验结果证实了TransFIRA在面部识别性评估和身体识别性评估中的先进性，展示了其在跨数据集迁移上的鲁棒性。这些贡献使TransFIRA成为了一种综合、以几何驱动的识别性评估框架，能够实现编码器特定、高效、可解释且跨模态可扩展，对FIQA领域从准确性、可解释性和覆盖范围方面都产生了显著的推进作用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06349", "html_url": "https://arxiv.org/abs/2510.06349", "title": "灵活的群体学习可能在关键任务中超越基础模型", "title_en": "Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks", "authors": "Moein E. Samadi,Andreas Schuppert", "background": "基础模型促进了AI的快速发展，但在实际应用领域中，其决策是否最终会超越人类策略仍然是一个问题。由于AI开发的指数甚至超指数级速度，这种分析变得难以捉摸。尽管如此，许多对日常生活和社会至关重要的应用领域目前仅显示出微小的进步；一个显著案例是重症监护中动态演变疾病的诊断和治疗。普遍的挑战是协调复杂的系统以适应动态环境，这需要优化高度相互作用功能组成的系统，并避免共享副作用；这需要可靠、自我适应的建模。这些任务与构建机制尚不完全或定量理解的高复杂系统数字孪生相关。因此，开发在有限数据和有限机制知识条件下进行自我适应AI模型的方法至关重要。鉴于此挑战不仅限于医学领域，AI在这些环境中的效能必须明显优于基础模型，才能承担更广泛的决策角色。我们识别维度灾难作为有效自我适应的基本障碍，并认为单一的整体基础模型在克服它时存在概念上的局限。相反，我们提出了一种交互式小型代理网络（SANs）的分散式架构。我们关注每个代理覆盖系统部分功能的特殊子结构的代理，利用SANs学习行为的数学结果以及现有应用程序的证据，认为多样类型的群体学习能够使SANs在动态环境中实现更优的决策，尽管这可能会减少细节上的可重复性。", "innovation": "建议一种分散式架构的小型代理网络（SANs）作为替代方案，提出每个代理仅覆盖系统部分功能的代理并利用SANs学习行为的数学结果以及现有应用程序的证据，认为多样化的群体学习可以使SANs在动态环境中实现更优的决策，而不会像单一的整体基础模型那样受限于维度灾难问题。", "conclusion": "在关键任务中，灵活的群体学习在自我适应SANs的表现可能优于单一的整体基础模型，但会牺牲某些细节上的可重复性。因此，在这些重要领域，AI应展现明显优于基础模型的效能，才能承担更广泛的决策角色。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06381", "html_url": "https://arxiv.org/abs/2510.06381", "title": "蒙特卡罗置换搜索", "title_en": "Monte Carlo Permutation Search", "authors": "Tristan Cazenave", "background": "在蒙特卡罗树搜索（MCTS）方法中，虽然GRAVE算法已经有所成果，但在某些场景下，并不适合使用深度强化学习或计算能力有限（例如通用游戏领域）时，需要一种更有效的算法。MCPS提出了这样一种算法。", "innovation": "MCPS改进了GRAVE算法，特别适合那些不适合使用深度强化学习或计算资源有限的场景，例如通用游戏。MCPS的一个创新点在于，在节点的探索项中包含了从根节点到节点的所有可能走法的历史统计数据。另一个改进是在使用抽象编码代替精确编码来提升MCPS和GRAVE算法的效果。此外，还提供了一系列数学推导来优化三种来源的统计数据权重。", "conclusion": "MCPS在所有两人游戏中表现优于GRAVE，在多人游戏中表现接近，因为这些游戏即使在玩家能力不同时也具有平衡性。此外，MCPS算法对多种游戏类型进行了广泛的测试，且不受ref超参数的影响，提供了减去偏差超参数的改进公式的权重."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06371", "html_url": "https://arxiv.org/abs/2510.06371", "title": "EverydayMMQA：一种面向文化基础的多语言和多模态口视觉问答框架", "title_en": "EverydayMMQA: A Multilingual and Multimodal Framework for Culturally Grounded Spoken Visual QA", "authors": "Firoj Alam,Ali Ezzat Shahroor,Md. Arid Hasan,Zien Sheikh Ali,Hunzalah Hassan Bhatti,Mohamed Bayan Kmainasi,Shammur Absar Chowdhury,Basel Mousi,Fahim Dalvi,Nadir Durrani,Natasa Milic-Frayling", "background": "大型多模态模型在视觉问答（VQA）等任务中取得了很好的效果，但在需要文化基础的日常知识的查询上常常无法胜任，尤其是在低资源和未被充分代表的语言中。为了解决这一问题，研究提出了一种框架——EverydayMMQA，这是一种用于创建面向文化基础的多模态和多语言问答数据集的框架，特别是针对口视觉问答（SVQA）。利用该框架，开发了一个多模态数据集OASIS，实现了语音、图像和文本的整合，包含超过920万张图片和1.48亿个问答对。OASIS包含370万口问问题，提供了四种输入组合：语音、文本、语音+图像和文本+图像，内容涉及英语和阿拉伯语等18个国家，旨在反映多样的现实世界情况。OASIS测试涵盖了物体识别之外的任务，包含实用常识和文化感知的推理。", "innovation": "提出了EverydayMMQA框架，用于创建面向文化基础的多语言和多模态问答数据集，特别是针对口视觉问答。开发了OASIS数据集，包含多元输入组合和大量口问问题。该框架旨在测试并提升模型在复杂任务中关于实用常识和文化感知的推理能力。该数据集和框架将为构建面向文化环境的多模态语言模型提供基准和训练数据集，并对广泛的文化相关日常任务进行评估。", "conclusion": "EverydayMMQA和OASIS为构建能处理复杂文化相关日常任务的多模态大语言模型提供了基准和训练数据集。该框架和数据集将公开共享给社区，促进多模态语言模型的研究和发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06391", "html_url": "https://arxiv.org/abs/2510.06391", "title": "Rewards Model 观点：奖励模型是在为谁的意见服务？", "title_en": "Reward Model Perspectives: Whose Opinions Do Reward Models Reward?", "authors": "Elle", "background": "奖励模型 (RMs) 在语言模型 (LMs) 的规范性中起着核心作用。RMs 经常代表人类偏好来指导下游 LM 的行为。然而，对于 RMs 的行为我们仍缺乏充分的理解。", "innovation": "本文通过 (i) 正式化衡量由 RMs 捕捉到的观点一致性的框架，(ii) 研究 RMs 在多大程度上表现出社会人口统计偏差，以及 (iii) 探索提示以引导奖励趋向目标群体的偏好，提出了创新观点。", "conclusion": "研究表明，RMs 与若干人口群体的规范性较差，可能会系统性地奖励有害的刻板印象。单纯的引导不足以克服这些局限。这些发现强调了在偏好学习期间更仔细考虑 RMs 行为在模型规范中的必要性，以防止语言技术中不良社会偏好的传播。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06357", "html_url": "https://arxiv.org/abs/2510.06357", "title": "弹性体化系统中的约束自然语言行动规划", "title_en": "Constrained Natural Language Action Planning for Resilient Embodied Systems", "authors": "Grayson Byrd,Corban Rivera,Bethany Kemp,Meghan Booker,Aurora Schmidt,Celso M de Melo,Lalithkumar Seenivasan,Mathias Unberath", "background": "在执行嵌入式任务时复制人类水平的智能依然充满挑战，因为真实世界的环境是不受约束的。尽管使用大型语言模型（LLMs）进行任务规划能够解决复杂规划任务之前无法处理的状态/行动空间问题，但是幻觉限制了它们的可靠性和实用性，特别是在研究之外的场合。此外，为了实现足够系统性能所需的提示工程缺乏透明性，因此无法保证重复性。相比之下，符号规划方法提供了强大的可靠性和重复性的保证，但在处理真实世界任务的复杂性和不确定性方面难以扩展。本文介绍了新的机器人规划方法，通过将符号规划监督添加到大型语言模型规划者中，来提高可靠性和重复性，并提供透明的方式来定义硬约束，这种定义方式明显强于传统的提示工程。这些增强保留了大型语言模型的推理能力，并在开放世界环境中展现出了出色的一般化性能。本文在模拟和真实世界环境中进行了演示。在ALFWorld规划基准测试中，本方法超越了当前最先进的方法，成功率达到近乎完美的99%。将本方法部署到一个实际的四足机器人上，在进行物体拾取和放置任务时，其成功率达到了100%，而基于LLMs和符号规划的方法分别仅为50%和30%。本方法提供了一种有效的方式来增强基于LLMs的机器人规划系统的可靠性和透明性，同时保留其关键优势：灵活性和适应复杂真实世界环境的能力。希望本文能够为构建稳健的体化智能系统做出贡献。", "innovation": "本文提出了一种新的机器人规划方法，该方法通过将符号规划监督添加到大型语言模型（LLMs）规划者中，以增强其可靠性和重复性，并提供透明的硬约束定义方式，从而提高了规划系统在开放世界环境中的性能。这种方法在模拟和真实世界的环境中表现出色，并在目标规划基准测试中超越了现有的顶级方法。此外，该方法在真实世界的操作任务（如拾取和放置物体）中也表现出了显著的优势。", "conclusion": "本文通过提出一种结合了大型语言模型和符号规划的新方法，实现了在复杂和模糊的真实世界任务中提供高效、可靠和透明的机器人规划解决方案。该方法展示出在增强基于LLMs的机器人规划系统可靠性和透明性方面的潜力，同时也保持了其灵活性和广泛适用性。我们期待这项工作能够为构建具有抗干扰性的体化智能系统做出贡献。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06396", "html_url": "https://arxiv.org/abs/2510.06396", "title": "适应性蛋白质设计协议和中间件", "title_en": "Adaptive Protein Design Protocols and Middleware", "authors": "Aymen Alsaadi,Jonathan Ash,Mikhail Titov,Matteo Turilli,Andre Merzky,Shantenu Jha,Sagar Khare", "background": "计算蛋白设计正受到人工智能/机器学习的推动。然而，潜在的蛋白质序列和结构范围即便对中等大小的蛋白质来说也非常庞大，因此在生成和预测结构之间达到收敛需要大量的计算资源来进行采样。", "innovation": "集成机器学习在大规模蛋白质结构 (IMPRESS) 提供了一种方法和先进的计算系统，将AI与高性能计算任务结合起来，从而使开发中的蛋白质设计及其数据生成、模型和模拟训练所使用的方法和模拟能够得到有效的评估。本文介绍IMPRESS，并展示了适应性蛋白质设计协议及其支持的计算基础设施的开发和实施，这导致蛋白质设计的质量一致性提高和吞吐量增加，通过动态资源分配和异步工作负载执行实现这一点。", "conclusion": "IMPRESS 在适应性蛋白质设计方面的应用展示了计算蛋白质设计的新思路和技术，提高了蛋白质设计的质量和效率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06397", "html_url": "https://arxiv.org/abs/2510.06397", "title": "几何意识后门攻击：利用双曲嵌入中的曲率", "title_en": "Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic Embeddings", "authors": "Ali Baheri", "background": "非欧几里得基础模型将表示置于曲率空间，如双曲几何。研究表明，这种几何结构在边界处会引发不对称性，从而使后门触发器能够利用这一特性。在边界附近，即使是细微的输入变化，对于标准输入空间检测器来说细微至极，却会在模型的表示空间产生显著的影响。", "innovation": "该研究正式化了这一效果，并揭示了防御方法的局限性：通过将点沿半径方向向内拉的方法虽能抑制此类触发器，但代价是牺牲该方向上模型的有用灵敏度。基于这些洞见，研究提出了一个简单的几何自适应触发方法，并在各种任务和架构上进行了评估。实验证明攻击成功率在边界附近增加，而传统检测器效果减弱，与理论趋势吻合。这些结果揭示了非欧几里得模型中几何特定的脆弱性，并为设计和理解防御限制提供了理论支持。", "conclusion": "研究表明非欧几里得模型在曲率空间中具有几何特定的脆弱性，提出了几何自适应触发方法，并通过实验证明了其有效性和理论一致性，为理解和设计防御机制提供了新思路。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06444", "html_url": "https://arxiv.org/abs/2510.06444", "title": "通过性能预测进行情境感知推理在去中心化学习网络中的应用", "title_en": "Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks", "authors": "Joel Pfeffer,J. M. Diederik Kruijssen,Clément Gossart,Mélanie Chevance,Diego Campo Millan,Florian Stecker,Steven N. Longmore(Allora Foundation)", "background": "在去中心化学习网络中，来自众多参与者的预测组合生成网络推理。尽管许多研究已经证明了组合多个模型预测可以带来性能提升，但现有的使用线性汇总方法（从简单平均到动态权重更新）的策略存在关键限制。依赖历史性能更新权重的动态预测组合主要是反应性的，这使得它们在适应环境变化方面较慢。因此，提出了基于机器学习的性能预测模型，以提高预测准确性。", "innovation": "开发了一种利用机器学习来预测时间序列中每个时期的模型预测性能的方法，该方法可以根据需要为更有可能在某个时间点更准确的模型分配更高的权重，实现了情境感知。该研究采用了一种类似于Allora网络的设计，通过添加一个性能预测工作者来提高去中心化学习网络的推理准确性。研究发现，预测后悔或后悔z分数的模型比预测损失的模型能带来更大的改进。同时，还通过一系列优化实验，表明性能预测模型的表现对特征集和训练周期数的选择敏感，这些特性可能取决于具体问题并应在每个领域进行定制。", "conclusion": "尽管最初是为去中心化学习网络设计的，但性能预测模型可以用于任何需要预测而非反应权重的情况下。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06448", "html_url": "https://arxiv.org/abs/2510.06448", "title": "如何不评估您的SITE度量标准：超越静态排行榜，迈向现实评估", "title_en": "How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation", "authors": "Prabhant Singh,Sibylle Hess,Joaquin Vanschoren", "background": "转移性评估指标用于在无需对模型进行微调且无需访问源数据集的情况下，找到适用于给定目标任务的高性能预训练模型。尽管对开发此类指标的兴趣日益增长，但用来衡量其进展的基准测试当前却很少受到审查。本文通过实验展示了广泛使用的基准测试设置在评估转移性评估指标时存在的局限性，指出这些指标当前的评估基准天生存在缺陷。研究发现，这些不切实际的模型空间和静态的性能层次结构人为地夸大了现有指标的性能，简单、数据集无关的启发式方法甚至可以超越复杂的手段。", "innovation": "本文通过实验证明了当前基准设置的局限性，并指出这些评估基准的本质缺陷。研究发现，现有的模型空间和静态性能等级人为提高了现有指标的表现，使得简单的、数据集无关的启发式方法甚至能够超越复杂的手段。研究还提供了一系列建设更强大、更现实的基准测试的具体建议，以指导未来研究的方向。", "conclusion": "当前的评价程序与现实世界中的模型选择复杂性之间存在关键差距。为解决这一问题，本文提供了一系列具体的建议，以构建更稳健、更现实的基准测试，以指导未来的更具意义的研究方向。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06445", "html_url": "https://arxiv.org/abs/2510.06445", "title": "关于代理安全的研究综述：应用、威胁与防御", "title_en": "A Survey on Agentic Security: Applications, Threats and Defenses", "authors": "Asif Shahriar,Md Nafiu Rahman,Sadif Ahmed,Farig Sadeque,Md Rizwan Parvez", "background": "本文探讨了从被动语言模型（LLM）向自主语言模型代理（LLM-agent）的快速转变，这种转变标志着网络安全领域的全新范式。尽管这些代理可以作为强大的工具用于攻击性和防御性操作，但它们的存在引入了一类新的固有安全风险。本文第一次从三个相互依赖的支柱——应用、威胁和防御——对代理安全进行了全面的调研，目的是构建一个包含150多篇论文的全面分类，并解释了代理的使用方式、它们存在的漏洞以及设计用来保护它们的应对措施，同时突出了模型和模态方面的研究缺口，揭示了当前新兴的技术趋势。", "innovation": "本文提出了第一个全面的代理安全调研，其创新点在于从三个关键方面（应用、威胁、防御）进行结构化，构建了一个包含150多篇论文的分类，解释代理的应用、脆弱性及其保护措施，同时揭示了研究空白，并展示了代理架构的发展趋势。", "conclusion": "本文通过全面分析，展示了代理安全领域的最新趋势，并指出了当前研究中的关键空白，为未来的代理安全研究和实践提供了指导。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06478", "html_url": "https://arxiv.org/abs/2510.06478", "title": "基于经验动态形式提升的有效LLM生成停止", "title_en": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "研究了语言模型生成停顿的有效性，特别是在使用任何形式验证之前，需要将生成过程停止以确保输出合乎预期。传统方法无法有效控制停顿时间，而现有技术可能在停顿决策上存在延迟或不准确的问题。", "innovation": "提出了Sequential-EDFL方法，采用了任意时点有效的序列测试来停止语言模型生成。该方法利用自我归一化的经验-伯努利e-过程跟踪信息提升，并通过在线均值估计处理未知中心偏差。EDFL方法还支持在分布漂移时的自适应重置，并通过轻量级正确性门控（句子边界+验证器）提高任务正确性，同时保持有效停止的任何时间验证保证。", "conclusion": "Sequential-EDFL在六项基准测试中比顺序基线减少了22-28%的生成量，同时以12%的计算开销维持了δ级控制。该方法引入了自动骨架（蒸馏模型、随机化logits），显示了跨骨架族的鲁棒性。此外，EDFL作为一级过滤器使验证负担减少了83%，而不是作为安全关键领域单站解决方案。虽然EDFL控制的是信息充分性证书，而不是事实正确性，但仍能将停顿序列中剩余错误的比例降至10.9%。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06457", "html_url": "https://arxiv.org/abs/2510.06457", "title": "评估节点树界面的AI解释性", "title_en": "Evaluating Node-tree Interfaces for AI Explainability", "authors": "Lifei Wang,Natalie Friedman,Chengchao Zhu,Zeshu Zhu,S.Joy Mountford", "background": "随着大型语言模型（LLMs）在工作场所工具和决策过程中的普及，确保解释性和培养用户信任变得至关重要。尽管LLM工程的进步继续进行，但人机中心设计仍然赶不上，特别是在嵌入透明性和信任到AI接口方面。本研究评估了两种不同的AI界面（节点树界面和聊天机器人界面），以评估它们在探索、后续查询、决策和解决问题任务中的表现。通过设计导向的方法，引入了一个节点树界面，将AI生成的响应视觉化地组织成层次结构化的交互节点，让用户能够导航、优化和跟进复杂信息。", "innovation": "本文通过设计导向的方法引入了节点树界面，将AI生成的响应视觉化地组织成层次结构化的交互节点，让用户能够导航、优化和跟进复杂信息。研究通过20个企业用户的对比实验发现，虽然聊天机器人界面能够支持线性、逐步的查询，但节点树界面在促进头脑风暴方面表现更佳。定量和定性研究结果表明，节点树界面不仅能改善任务性能和决策支持，还能通过保留上下文促进更高的用户信任。这项研究为人类机器人交互和AI设计领域，特别是在对企业应用中的信任构建至关重要的领域，提供了切实可行的见解和建议。", "conclusion": "这项工作贡献了关于能够根据任务需求在结构化可视化和对话格式之间切换的自适应AI界面的可操作见解，有助于提高AI驱动系统中的透明度和用户信心。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06477", "html_url": "https://arxiv.org/abs/2510.06477", "title": "Large Language Models中的注意力陷阱和压缩谷是一个硬币的两面", "title_en": "Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin", "authors": "Enrique Queipo-de-Llano,Álvaro Arroyo,Federico Barbero,Xiaowen Dong,Michael Bronstein,Yann LeCun,Ravid Shwartz-Ziv", "background": "在大型语言模型中，注意力陷阱（attention sinks）和压缩谷（compression valleys）引起了广泛的关注，因为这两种现象令人困惑，但它们之前一直独立研究。本研究揭示了这两者之间的惊人联系，追溯到残差流中巨大激活的形成。理论证明了巨大激活必然会带来表示压缩，并建立了结果熵减少的上限。实验验证了当开始的序列令牌在中间层发展出极高的激活范数时，同时会出现压缩谷和注意力陷阱。", "innovation": "本研究首次提出了基于Transformer的大型语言模型通过控制巨大激活来调控注意力和表示压缩的新颖观点。作者提出了一种集成的“混合-压缩-细化”信息流理论（Mix-Compress-Refine theory），解释了LLMs在深度上组织计算的方式。该理论将Transformer基于大语言模型的处理过程分为三个阶段：早期的广泛混合、中间层的压缩计算和晚期的选择性细化，从而为嵌入任务和生成任务在不同层上的表现差异提供了新的解释。", "conclusion": "本研究建立了一个新的理论框架来解释如何通过控制巨大激活来调控LLMs中的注意力和表示压缩。这种集成的“混合-压缩-细化”理论为理解LLMs在不同任务中的表现差异提供了新的视角，表明嵌入任务在中间层表现最好，而生成任务则受益于端到端的处理。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06503", "html_url": "https://arxiv.org/abs/2510.06503", "title": "ATLO-ML：适应性时间长度优化器在机器学习中的应用——空气质量预报的见解", "title_en": "ATLO-ML: Adaptive Time-Length Optimizer for Machine Learning -- Insights from Air Quality Forecasting", "authors": "I-Hsi Kao,Kanji Uchino", "background": "机器学习中的时间序列预测准确性高度依赖于输入时间长度和采样率的选择。传统的做法是采用固定的时间长度和采样率，但这种方法可能会限制预测性能。因此，如何根据具体应用需求灵活调整时间长度和采样率成为亟待解决的问题。", "innovation": "ATLO-ML 是一个自适应时间长度优化系统，能够基于用户定义的输出时间长度自动确定最优时间长度和采样率。该系统通过动态调整参数，提高预测性能，并适用于各种时间敏感应用。此外，它在空气质量和数据中心的实时数据集上进行了验证。", "conclusion": "基于优化的时间长度和采样率，ATLO-ML 显著提高了机器学习模型的预测准确性，相较固定的时间长度更为优越。该方法为机器学习工作流程中优化时间输入参数提供了稳健的解决方案，并具有在不同应用场景中推广的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06505", "html_url": "https://arxiv.org/abs/2510.06505", "title": "基于未标记数据的中位数视角的分布外检测", "title_en": "A Median Perspective on Unlabeled Data for Out-of-Distribution Detection", "authors": "Momin Abbas,Ali Falahati,Hossein Goli,Mohammad Mohammadi Amiri", "background": "分布外（OOD）检测是确保部署在实际应用中的机器学习系统稳健性和可靠性的关键。最近的方法探索了使用未标记数据的潜在价值，以此增强OOD检测能力。然而，有效地利用来自现实世界的未标记数据仍极具挑战，因为这些数据的内部（InD）和分布外（OOD）样本相互混杂，缺乏明确的OOD示例，使得训练理想的OOD分类器变得复杂。", "innovation": "我们介绍了Medix，一种新颖的框架，该框架利用中位数操作从未标记数据中识别潜在异常值。使用中位数是因为其稳健性，作为OOD检测机制，它能够提供对噪音和异常值的稳定估计。将这些识别出的异常值和标记的内部样本结合使用，我们训练了一个稳健的OD分类器。从理论上讲，我们推导出的误差界证明了Medix能够实现低错误率。", "conclusion": "实证结果进一步证实了我们的理论推断，Medix在开放世界的设置中全面优于现有的方法，证明了其理论见解的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06517", "html_url": "https://arxiv.org/abs/2510.06517", "title": "可视化组合搜索景观中的多模态性", "title_en": "Visualizing Multimodality in Combinatorial Search Landscapes", "authors": "Xavier F. C. Sánchez-Díaz,Ole Jakob Mengshoel", "background": "本文探讨了不同可视化技术在组合搜索景观中的应用，特别是关注多模态特性。介绍了景观分析文献中的不同技术，并讨论了如何结合这些技术以提供更全面的搜索景观视角。还提供了具体的例子，并讨论了以往的工作，说明这些技术在实践中的应用情况，主要基于格雷姆语法规图的几何和美学元素。", "innovation": "讨论了如何结合不同的可视化技术和生态元素来提供对搜索景观更全面的视角，展示了如何在实践中应用这些技术，为该领域的未来工作提供了建议。", "conclusion": "结论指出，没有免费的午餐（即没有万能的可视化方法），并为未来的工作指明了多种可能的路径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06499", "html_url": "https://arxiv.org/abs/2510.06499", "title": "Webscale-RL: 自动化数据管道，用于将RL数据扩展至预训练水平", "title_en": "Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels", "authors": "Zhepeng Cen,Haolin Chen,Shiyu Wang,Zuxin Liu,Zhiwei Liu,Ding Zhao,Silvio Savarese,Caiming Xiong,Huan Wang,Weiran Yao", "background": "大型语言模型（LLMs）通过模仿学习大量文本语料库而取得了显著的成功，但这种方法存在训练-生成差距和限制性推理的问题。强化学习（RL）提供了一种更数据高效的解决方案，能够弥合这一差距，但其应用受限于一个关键的数据瓶颈：现有的RL数据集比网页规模的预训练语料库小得多且不够多样化。为了解决这个问题，我们介绍了Webscale-RL管道，这是一种可扩展的数据引擎，可以系统地将大规模预训练文档转换为数百万个多样且可验证的问题-答案对，用于强化学习。", "innovation": "提出了Webscale-RL管道，这是一种可扩展的数据引擎，将大规模预训练文档转换为能够用于强化学习的多样化且可验证的问题-答案对。使用这一管道，我们创建了Webscale-RL数据集，包含120万例样例，跨越9个不同领域。实验表明，基于该数据集训练的模型显著优于持续预训练和强大的数据细化基线，并在一系列基准测试中表现出色。值得注意的是，使用我们的数据集进行的强化学习训练证明更为高效，仅需不到100倍的令牌即可达到持续预训练的性能。", "conclusion": "我们的工作展示了将强化学习扩展至预训练水平的一个可行路径，使构建更强大且高效的语言模型成为可能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06512", "html_url": "https://arxiv.org/abs/2510.06512", "title": "LogSTOP: 在预测序列上的时间得分用于匹配和检索", "title_en": "LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval", "authors": "Avishree Khare,Hideki Okamoto,Bardh Hoxha,Georgios Fainekos,Rajeev Alur", "background": "当前可以利用诸如YOLO和HuBERT的神经模型来检测视频帧和音频片段中的局部属性，例如物体（“汽车”）和情绪（“愤怒”），并用[0, 1]范围内的分数表示检测的可能性。然而，将这些局部属性的分数转换为时间序列属性能为查询匹配、有序检索等功能应用提供有用信息。已有研究表明，这种方法为这类任务提供了有效解决方案，并得到了显著的性能提升。尽管现有方法已经取得了不错的成果，但在处理局部属性的不确定性及时间属性的复杂性时仍存在优化空间。", "innovation": "本研究从实证角度正式定义了给定潜在噪声局部属性预测得分的序列时间属性评分问题，提出了称为LogSTOP的评分函数，该函数能够有效计算线性时序逻辑表示的时间属性得分。实验证明，使用YOLO和HuBERT和LogSTOP，在具有时间属性的物体和情绪匹配任务上，LogSTOP至少比大型视觉/音频语言模型和其他基于时序逻辑的基线算法高出16%。同样地，在涉及视频中的物体和动作的时间属性的有序检索任务上，使用Grounding DINO和SlowR50的LogSTOP分别比零样本文本到视频检索基线提升了至少19%和16%的平均精度和召回率。", "conclusion": "本工作在给定潜在噪声局部属性预测得分的情况下，研究了序列时间属性评分问题，提出了一种称为LogSTOP的评分函数，能有效计算线性时序逻辑表示的时间属性得分，并通过实验验证了其在时间属性匹配和有序检索任务上的优越性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06540", "html_url": "https://arxiv.org/abs/2510.06540", "title": "POMDP问题中基于策略的大规模可扩展RL算法", "title_en": "Scalable Policy-Based RL Algorithms for POMDPs", "authors": "Ameya Anjarlekar,Rasoul Etesami,R Srikant", "background": "部分可观测马尔可夫决策过程(POMDP)中信念状态的连续性带来了学习最优策略的显著计算挑战。基于此背景，本文探讨了一种通过将相应的POMDP模型近似为一个有限状态马尔可夫决策过程(Superstate MDP)来解决部分可观测强化学习(PORL)问题的方法。这种方法利用了理论保证，提高了先前工作的成果，并提出了一种基于策略的学习方法，使用线性函数近似来学习Superstate MDP的最优策略。通过这种方式，将POMDP问题处理为一个MDP问题是可能的，MDP的状态对应于有限的历史。实验证明，这种近似错误随历史长度的增加呈指数级减小。", "innovation": "本文提出了一个创新的策略学习方法，通过将POMDP近似为Superstate MDP并使用TD学习和策略优化来解决POMDP问题。此外，本文首次明确量化了在非马尔可夫动态环境中应用标准TD学习时引入的误差。", "conclusion": "通过这种方法，POMDP可以近似地通过TD学习和策略优化来解决，且近似误差随着历史长度的增加呈指数级减小。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06559", "html_url": "https://arxiv.org/abs/2510.06559", "title": "意义的代数：为什么机器需要蒙太格语义比摩尔定律更重要", "title_en": "The Algebra of Meaning: Why Machines Need Montague More Than Moore's Law", "authors": "Cheonkam Jeong,Sungdo Kim,Jewoo Park", "background": "当前的语言模型虽然流畅，但在处理其输出蕴含的意义类型时经常出错。我们提出了一种观点，认为幻觉、脆弱的调控和不透明的合规性结果是缺乏类型论语义的症状，而非数据或规模限制。语言应被视为带有类型的组合算术。若将对齐视为一种解析问题，自然语言输入需要被编译为明确定义描述、规范和法律维度的结构。", "innovation": "(i) 把幻觉诊断为类型错误；(ii) 正式建立了基于蒙太格语义的企业/法律推理桥梁；(iii) 提出了一个面向生产的系统设计，嵌入了类型接口在整个管道中。", "conclusion": "本文提出了一种评价计划，使用法律推理基准和合成多司法管辖区套件进行评估。我们的观点是，信任性自治需要特征组合的语义类型，以使系统能够在统一的意义代数中对描述、规定和可能的法律责任进行推理。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06473", "html_url": "https://arxiv.org/abs/2510.06473", "title": "深度生成模型用于人类移动行为", "title_en": "Deep Generative Model for Human Mobility Behavior", "authors": "Ye Hong,Yatao Zhang,Konrad Schindler,Martin Raubal", "background": "理解和建模人类移动对于交通规划、可持续城市设计和公共卫生等挑战至关重要。尽管经过了数十年的努力，由于人类移动的复杂性、情境依赖性和探索性，其个体层面的模拟仍然具有挑战性。本研究致力于开发一个能够生成跨越多个时空尺度的现实主义移动轨迹的深度生成模型，以期更好地理解并预测人类移动模式。", "innovation": "MobilityGen 是一种深度生成模型，能够生成在大尺度上持续数日至数周的现实主义移动轨迹，通过将行为特征与环境情境联系起来，能够重现诸如地点访问的规模法则、活动时间分配、旅行模式和目的地选择的耦合演变等关键模式。它可以反映空间和时间的变异性，并生成多样且符合现实环境的人类移动模式。此外，MobilityGen 还提供了更早模型无法达到的洞察，例如不同出行方式的可用空间存在差异以及共现动力学如何影响社会接触和隔离。这种模型为移动建模提供了一个新的框架，为细致入微的数据驱动的人类行为和社会意义研究铺平了道路。", "conclusion": "本研究建立了一种新的移动模拟框架，为人类行为及其社会影响的细致数据驱动研究开辟了新的途径，不仅能提供更准确的移动模拟，还能提供更深层次的理解，帮助更好地制定交通规划、可持续城市设计和公共卫生策略。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06564", "html_url": "https://arxiv.org/abs/2510.06564", "title": "HSNet：用于单图像超分辨率的异质子图网络", "title_en": "HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution", "authors": "Qiongyang Hu,Wenyang Liu,Wenbin Zou,Yuejiao Su,Lap-Pui Chau,Yi Wang", "background": "现有的基于深度学习的图像超分辨率方法，尤其是使用CNN和注意力机制的方法，通常存在结构僵化的问题。虽然基于图的方法提供了更大的表示适应性，但它们常常受到计算复杂度过高的限制。", "innovation": "本文提出了一种新颖框架HSNet，它有效地利用图建模同时保持计算可行性。HSNet的核心思想是将全局图分解为可管理的子组件。HSNet通过引入Constructive Subgraph Set Block (CSSB)生成一组多样且互补的子图，通过模型不同的关系模式和特征交互，产生丰富的局部和全局图结构集合。其次，Subgraph Aggregation Block (SAB)通过自适应加权和多图特征融合，构建了一个综合且具有区分力的表示，捕捉复杂的依赖关系。此外，还设计了一个节点采样策略（NSS）以选择性地保留最显著的特征，从而提高准确性并减少计算开销。", "conclusion": "广泛的实验表明，HSNet取得了最先进的性能，在重建质量和计算效率之间的平衡上表现出色。代码将公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06557", "html_url": "https://arxiv.org/abs/2510.06557", "title": "马尔可夫思维者", "title_en": "The Markovian Thinker", "authors": "Milad Aghajohari,Kamran Chitsaz,Amirhossein Kazemnejad,Sarath Chandar,Alessandro Sordoni,Aaron Courville,Siva Reddy", "background": "强化学习（RL）已成为训练生成长链思维（LongCoT）的推理大型语言模型（LLM）的强大工具。然而，标准的RL‘思考环境’，其状态包含提示和所有之前的推理标记，使得状态无限，促使基于注意力的策略随着思维长度增加而付出平方计算成本。因此，作者重新审视了环境本身，提出了马尔可夫思维的策略，这种策略使推理过程可以在不受上下文大小限制的固定大小的状态下进行，从而解耦了思考长度和上下文大小的关系，从而实现线性计算和恒定内存。通过实验证明，这种方法显著降低了计算成本，使其在长推理长度下仍然能够保持高效的性能。", "innovation": "提出的马尔可夫思维策略（Markovian Thinking）为解决标准RL环境中存在的计算复杂度问题提供了解决方案。这种方法通过将推理过程结构化为固定大小的块，并在每个块的边界重置上下文和重新初始化提示，使得模型可以在不需要扩大上下文的情况下进行长推理。此外，通过用Delethink环境训练模型，在保持同等或更好推理能力的同时，显著降低了计算成本。这种方法还适用于各种规模的推理模型，且在推理环境中表现出了潜在的发展空间。", "conclusion": "马尔可夫思维策略通过重设计想环境，显著降低计算成本并提高推理长度，使得大型语言模型能够进行高效的长推理。这为构建具有高效计算特性的可扩展推理大型语言模型打开了新的可能性，证明了通过重新设计思维环境是提高推理大型语言模型性能的有效途径。虽然目前还面临一些挑战，但这种方法仍有望在未来推动更大规模且更高效的推理模型的发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06567", "html_url": "https://arxiv.org/abs/2510.06567", "title": "能够抵御不良模型的框架：临床试验中的人工智能合作", "title_en": "The Framework That Survives Bad Models: Human-AI Collaboration For Clinical Trials", "authors": "Yao Chen,David Ohlssen,Aimee Readie,Gregory Ligozio,Ruvie Martin,Thibaud Coroller", "background": "人工智能（AI）在支持临床试验方面具有巨大潜力，从患者招募、终点评估到治疗反应预测。然而，如果没有适当的保障措施，部署AI可能会带来重大风险，特别是在评估直接影响试验结论的患者终点时。该研究比较了两种AI框架与仅由人类进行评估的医学图像疾病评估，通过成本、准确性、稳健性和泛化能力对这些框架进行了测量。研究者通过引入从随机猜测到简单预测的各种不良模型，来测试这些框架，确保即使在模型严重退化的情况下，观察到的治疗效果仍然有效。", "innovation": "研究通过引入从随机猜测到简单预测的各种不良模型，对AI框架进行了严格测试。该研究表明，使用AI作为辅助阅片者（AI-SR）是临床试验中最合适的策略，它在各种模型类型中都能满足标准，即使在有不良模型的情况下也能持续提供可靠疾病估计，同时保护临床试验的治疗效果和结论。", "conclusion": "使用AI作为辅助阅片者（AI-SR）在临床试验中是最合适的策略。AI-SR能够满足各种模型类型的标准，并且即使在存在不良模型的情况下，也能够持续提供可靠疾病估计，保护临床试验的治疗效果和结论，并且这种方法在应用于不同人群时也保留了这些优势。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06637", "html_url": "https://arxiv.org/abs/2510.06637", "title": "基于控制增强自回归扩散的数据同化", "title_en": "Control-Augmented Autoregressive Diffusion for Data Assimilation", "authors": "Prakhar Srivastava,Farrin Marouf Sofian,Francesco Immorlano,Kushagra Pandey,Stephan Mandt", "background": "尽管最近在扩散模型测试期间的扩展和调整方面取得了一些进展，但自回归扩散模型（ARDMs）中的指导仍然未被充分探索。现有的方法往往在异质时空偏微分方程（PDEs）的数据同化（DA）背景下计算成本高昂，且在稀疏观测的情况下容易出现预测漂移。", "innovation": "本文提出了一种缓解上述问题的框架，该框架通过在线预览未来的ARDM滚出（rollouts），并学习逐步控制策略来预测未来的观测值，从而增强预训练的ARDMs。该框架将数据同化的推理过程简化为单次向前滚出，并在推理过程中进行实时修正，避免了昂贵的伴随计算和/或优化。", "conclusion": "该方法在两类典型的PDEs和六种观测情况下，稳定性和准确性方面都优于四种最先进的基线模型。研究结果将公开代码和检查点。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06605", "html_url": "https://arxiv.org/abs/2510.06605", "title": "通过零阶梯度估计实现可靠的黑箱大型语言模型指纹化：读其未见之处", "title_en": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation", "authors": "Shuo Shao,Yiming Li,Hongwei Yao,Yifei Chen,Yuchen Yang,Zhan Qin", "background": "由于开发大型语言模型（LLMs）需要大量投资，它们被视为有价值的知识产权，这引发了关于版权保护的严重关切。为了应对这一问题，LLM指纹技术应运而生，旨在通过提取模型的独特内在签名（", "innovation": "本文创新地使用费雪信息理论证明了模型输入的梯度比输出更能提供有用的指纹特征信息。提出了ZeroPrint方法，这是一种在黑箱环境中使用零阶估值来近似这些丰富信息的梯度的新方法。通过语义保持的词替换模拟输入扰动，ZeroPrint能够估计模型的雅可比矩阵作为独特指纹。实验表明，ZeroPrint在标准基准测试中表现出色，效果和鲁棒性显著优于现有的黑箱方法。", "conclusion": "ZeroPrint方法在识别LLM指纹方面具有前所未有的效果和稳定性，代表了黑箱环境中LSTM指纹技术的一个重大改进。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06596", "html_url": "https://arxiv.org/abs/2510.06596", "title": "SDQM：用于目标检测数据集评估的合成数据质量度量", "title_en": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation", "authors": "Ayush Zenith,Arnold Zumbrun,Neel Raut,Jing Lin", "background": "机器学习模型的性能高度依赖于训练数据的质量。大规模、高质量标注的数据集稀缺，给创建稳健模型带来重大挑战。为解决这一问题，模拟生成的数据通过仿真和生成模型出现，提高了数据多样性，增强了模型的性能、可靠性和韧性。然而，这些生成数据的质量评估需要有效的指标。本文提出了一种名为Synthetic Dataset Quality Metric（SDQM）的新度量方法，用于在无需模型训练的情况下评估目标检测任务的数据质量。该度量可以帮助更高效地生成和选择合成数据集，满足资源受限目标检测任务的关键需求。实验表明，SDQM与YOLOv11（领先的目标检测模型）的mAP评分具有较强的正相关关系，而之前的度量只显示出中等或弱的正相关关系。此外，SDQM还提供了提高数据质量的指导意见，减少繁琐的迭代训练需求。该可扩展且高效的度量指标为评估合成数据设定了新标准。SDQM的代码已发布。", "innovation": "提出了一个新的名为Synthetic Dataset Quality Metric（SDQM）的度量方法，用于在不需要模型训练的情况下评估目标检测任务的数据质量。SDQM不仅与top性能的对象检测模型（如YOLOv11）的结果高度相关，还能提供改善数据质量的指导意见，有效地减少了迭代训练的需求。", "conclusion": "SDQM为合成数据集的评估设定了新标准，能够有效、高效地评估合成数据的质量。SDQM的公开代码提高了该方法的可验证性和可复制性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06631", "html_url": "https://arxiv.org/abs/2510.06631", "title": "基于AI的城市水资源系统预测与监控", "title_en": "AI-Driven Forecasting and Monitoring of Urban Water System", "authors": "Qiming Guo,Bishal Khatri,Hua Zhang,Wenlu Wang", "background": "地下供水和污水管道对于城市运作至关重要，但常受到泄漏和渗透等异常影响，导致严重的水资源损失、环境破坏及高昂的修复成本。传统的手动检查效率低下，而密集部署传感器的成本则过于高昂。近年来，人工智能技术迅速发展并在城市基础设施中得到广泛应用。本文旨在通过一种结合AI和远程传感器的框架来解决地下供水管道漏检难题。研究通过部署少量远程传感器以获取实时流量和深度数据，并结合HydroNet模型，该模型利用管道特性（如材质、直径、坡度）进行更为精确的建模。实验结果表明，该系统能收集有效的时空水力数据，使HyroNet在各项性能指标上优于先进的基线方法。", "innovation": "本文提出了一种结合AI与远程传感器的框架，通过部署少量传感器获取实时流量和深度数据，并使用HydroNet模型基于管道属性进行精确建模，实现了从有限传感器部署中进行全网范围的准确预测。这种方法有效地解决了传统检查方法效率低下和密集传感器部署成本过高的问题。", "conclusion": "本文的研究为地下供水管道网络的漏检问题提供了一种新的解决方案，通过边缘感知的消息传递与水力模拟的结合，实现了从有限传感器部署中进行全网范围的准确推测。本方法有望广泛应用于各种地下供水管道网络中。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06532", "html_url": "https://arxiv.org/abs/2510.06532", "title": "CLAQS: 紧凑可学习全量子词项混合器与共享ansatz用于文本分类", "title_en": "CLAQS: Compact Learnable All-Quantum Token Mixer with Shared-ansatz for Text Classification", "authors": "Junhao Chen,Yifan Zhou,Hanqi Jiang,Yi Pan,Yiwei Li,Huaqin Zhao,Wei Zhang,Yingfeng Wang,Tianming Liu", "background": "量子计算正在快速发展，从云量子处理器（QPUs）到高吞吐量的GPU模拟器，使得原型化超越小型任务的量子自然语言处理（NLP）变得及时。然而，设备仍在量子位数和深度方面受到限制，训练过程可能不稳定，经典注意力机制在计算和内存使用上都较为沉重。因此，需要紧凑的相位感知量子词混合器来稳定振幅并能扩展到长序列。背景进一步指出目前文本分类中存在经典和量子混合模型的需要以及训练不稳定和资源密集型的问题。", "innovation": "提出了CLAQS，这是一种紧凑、完全量子化的词混合器，可以用于文本分类，具有联合学习复数混合和非线性变换的特点，同时可以在统一的量子电路中实现。为了支持端到端优化的稳定性，通过采用L1归一化来控制振幅缩放，并引入两阶段的参数化量子架构，将共享词嵌入与窗口级量子前馈模块区分开来。通过在滑动窗口模式下工作，并对文档进行聚集，CLAQS只需要8个数据量子位和浅层电路就能实现显著的性能提升。", "conclusion": "实验结果显示，CLAQS在SST-2数据集上的准确率为91.64%，在IMDB数据集上的准确率为87.08%，显著超越了经典的Transformer基线模型以及强大的混合量子-经典对等模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06545", "html_url": "https://arxiv.org/abs/2510.06545", "title": "目标调节自回归模型中的不一致", "title_en": "Incoherence in goal-conditioned autoregressive models", "authors": "Jacek Karwowski,Raymond Douglas", "background": "本文探讨了不一致的数学概念：由于直观的目标调节方法（使用自回归模型）而产生的强化学习策略中的一种结构问题。我们关注重新训练模型以利用其自身行为的过程，即使用在线强化学习重新训练经过离线学习的策略。我们证明了这个过程可以减少不一致并提高回报，希望能够描述由此产生的策略轨迹。通过重新定义控制为推理和软Q学习的概念，我们建立了迭代重新训练过程与两种其他理解之间的三重对应关系：将后验整合到奖励中，以及在确定论情况下，降低温度参数；这些对应关系通过训练-推理权衡具有计算内容。通过软条件生成模型，我们讨论了不一致与有效时距之间的联系。", "innovation": "通过重新定义控制为推理和软Q学习的概念，建立了标准控制作为推理和软Q学习的概念与迭代重新训练过程之间的三重对应关系：将后验整合到奖励中，以及在确定论情况下，降低温度参数；这些对应关系通过训练-推理权衡具有计算内容。", "conclusion": "通过软条件生成模型，讨论了不一致与有效时距之间的联系；并且重新训练过程可以减少不一致并提高回报，能够描述由此产生的策略轨迹。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06646", "html_url": "https://arxiv.org/abs/2510.06646", "title": "机器学习算子在零样本超分辨率上的虚假承诺", "title_en": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators", "authors": "Mansi Sakarvadia,Kareem Hegazy,Amin Totounferoush,Kyle Chard,Yaoqing Yang,Ian Foster,Michael W. Mahoney", "background": "科学研究中的一个重要挑战是如何模型化连续现象，而这些现象在实践中通常是以离散形式存在的。机器学习算子（MLOs）被引入作为实现这一建模目标的途径，因为这种类型的架构可以在任意分辨率上进行推理。本文评估了这一架构创新是否足以实现“零样本超分辨率”，即让模型在不受训练数据的影响下进行更高分辨率的数据推理。本文全面评估了MLOs中零样本亚分辨率和超分辨率（即多分辨率）推理。", "innovation": "本文提出了一种简单、计算效率高且数据驱动的多分辨率训练协议，这种协议克服了混叠问题，提供了稳健的多分辨率泛化能力。", "conclusion": "经过实验证明，MLOs在零样本方式下无法完成这两项任务：一是外推到不同频率信息；二是插值跨不同分辨率。因此，MLOs无法在未受训练的不同分辨率下进行准确推理，并且它们对混叠是脆弱的。因此，本文的研究表明MLOs无法实现零样本超分辨率，并提出了一种解决方案来解决这些缺陷。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06645", "html_url": "https://arxiv.org/abs/2510.06645", "title": "基于知识蒸馏的轻量级语言模型C/C++漏洞检测框架", "title_en": "Distilling Lightweight Language Models for C/C++ Vulnerabilities", "authors": "Zhiyuan Wei,Xiaoxuan Yang,Jing Sun,Zijian Zhang", "background": "现代软件系统的复杂性加剧了安全漏洞的普遍存在，这些漏洞可能引发严重的数据泄露和经济损失，因此，强大的代码漏洞检测对于软件安全至关重要。尽管大型语言模型（LLMs）在自然语言处理方面表现出色，但它们在自动代码漏洞检测中的潜力尚未得到充分探索。", "innovation": "提出了FineSec，一种利用知识蒸馏将大型教师模型的知识转移到紧凑的学生模型的新框架，以实现高效且精确的C/C++代码库中的漏洞识别。通过将数据准备、训练、评估和持续学习整合到一个统一的单一任务工作流中，FineSec提供了一种简化的解决方案。", "conclusion": "广泛的评估表明，FineSec在识别复杂漏洞和逻辑错误方面优于基础模型和较大的LLMs，将FineSec确立为现实世界软件安全中的实用且可扩展的解决方案。为了促进可重复性，FineSec的数据集、源代码和实验结果均已公开。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06669", "html_url": "https://arxiv.org/abs/2510.06669", "title": "工业缺陷检测的自动神经架构设计", "title_en": "Automated Neural Architecture Design for Industrial Defect Detection", "authors": "Yuxi Liu,Yunfeng Ma,Yi Tang,Min Liu,Shuai Jiang,Yaonan Wang", "background": "工业表面缺陷检测（SDD）对于确保产品质量和制造可靠性至关重要。由于表面缺陷具有多样的形状和尺寸，SDD面临两大挑战：类内差异和类间相似性。现有方法主要依赖手工设计的模型，这些模型需要大量试验和错误，并且常常难以有效应对这两个挑战。", "innovation": "本文提出了一种名为AutoNAD的自动神经架构设计框架，用于SDD。该框架综合搜索卷积、变换器和多层感知机，实现能够捕捉微细局部差异和长程语义上下文的混合设计，从而同时解决这两个关键挑战，并降低手动网络设计的成本。为支持大规模搜索空间的有效训练，AutoNAD引入了一种交叉权重共享策略，加速超网络收敛并改善子网络性能。此外，还集成了一种可搜索的多级特征聚合模块（MFAM），以增强多尺度特征学习。为了提高工业部署中的运行效率，AutoNAD还引入了延迟感知先验来引导高效架构的选择。", "conclusion": "AutoNAD的有效性已在三个工业缺陷数据集上得到了验证，并进一步应用于缺陷影像检测平台。代码将在提供的网址处开放。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06649", "html_url": "https://arxiv.org/abs/2510.06649", "title": "Action-Conditioned Root Mean Squared Q-Functions for Local Reinforcement Learning", "title_en": "Local Reinforcement Learning with Action-Conditioned Root Mean Squared Q-Functions", "authors": "Frank Wu,Mengye Ren", "background": "The Forward-Forward (FF) Algorithm是一种最近提出的神经网络学习程序，它使用两个前向传播步骤，而不是传统的前向和后向传播步骤用于反向传播。然而，FF主要局限于监督学习环境，未能充分利用可以在强化学习（RL）等自然产生学习信号的领域中发挥的作用。现有技术中，Backprop-free的局部强化学习方法存在局限，尤其是在基准测试环境中表现不如使用反向传播训练的方法。", "innovation": "本文受FF算法中使用层活动统计的优函数启发，提出了一种新的局部强化学习方法——Action-conditioned Root mean squared Q-Functions (ARQ)，该方法使用优函数和动作条件化进行局部RL学习。尽管方法相对简单且具有生物基础，但在MinAtar和DeepMind控制套件基准测试中，该方法的表现优于最先进的Backprop-free RL方法，并且在大多数任务上甚至优于使用反向传播训练的算法。", "conclusion": "ARQ方法在局部无反向传播的强化学习中表现出色，特别是在基准测试和实际任务中优于传统的反向传播方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06687", "html_url": "https://arxiv.org/abs/2510.06687", "title": "基于光场和LiDAR融合的语义分割算法", "title_en": "Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion", "authors": "Jie Luo,Yuxuan Jiang,Xin Jin,Mingyu Liu,Yihui Fan", "background": "语义分割在自动驾驶场景理解中起着基础作用，但在复杂条件下如遮挡时仍面临重大挑战。轻量级场和LiDAR模态提供了互补的视觉和空间提示，有助于稳健的感知，但其有效集成受到有限的视角多样性和固有模态差异的阻碍。", "innovation": "提出了一个集成了光场数据和点云数据的第一个多模态语义分割数据集，该数据集基础上提出了多模态光场点云融合分割网络（Mlpfseg），该网络通过特征补全和深度感知模块同时分割摄像头图像和LiDAR点云，提高了这些模态的融合效果。", "conclusion": "该方法在单独图像语义分割的基础上提升了1.71的Mean Intersection over Union (mIoU)，在单独点云分割的基础上提升了2.38的mIoU，证明了其有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06673", "html_url": "https://arxiv.org/abs/2510.06673", "title": "Heptapod：在视觉信号上进行语言建模", "title_en": "Heptapod: Language Modeling on Visual Signals", "authors": "Yongxin Zhu,Jiawei Chen,Yuanzhe Chen,Zhuo Chen,Dongya Jia,Jian Cong,Xiaobin Zhuang,Yuping Wang,Yuxuan Wang", "background": "本文介绍了Heptapod，这是一种图像自回归模型，遵循语言建模的基础原则。该模型采用因果注意力机制，不依赖于上下文自由生成语法(CFG)和语义分词器趋势，从而为图像生成提供了新的视角。Heptapod通过一种新颖的因果Transformer实现，在每次时间步骤中预测整个2D图像空间网格的概率分布，从而将自回归框架的序列建模与掩码自动编码的全面自我监督学习统一起来，使得模型能够在生成训练中捕捉图像的全面语义。", "innovation": "Heptapod的主要创新在于‘即将预测2D分布’：一种专注于重建的视觉分词器的因果Transformer，能够预测每个时间步骤中整个2D图像空间网格的概率分布。这种学习目标将自回归框架的序列建模与掩码自动编码的全面自我监督学习统一起来，从而通过生成训练捕捉图像的全面语义。", "conclusion": "Heptapod在ImageNet生成基准测试中的FID为2.70，大幅优于之前的因果自回归方法。我们希望通过这项工作激发对视觉信号上语言建模更原则性的重新思考。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06714", "html_url": "https://arxiv.org/abs/2510.06714", "title": "双重目标表示", "title_en": "Dual Goal Representations", "authors": "Seohong Park,Deepinder Mann,Sergey Levine", "background": "在这项研究中，作者探讨了将双重目标表示引入目标导向强化学习（GCRL）中的背景下。传统的GCRL方法依赖于特定的状态表示，而这种表示方法使用时间距离来描述一个状态与所有其他状态的关系，提供了一种新的状态表示方法。", "innovation": "提出了双重目标表示，能够通过计算一个状态与其他所有状态的时间距离来描述，这种方法不依赖于原始状态表示，并能过滤外部噪声。该方法具有理论上的吸引力，因为它仅依赖于环境的内在动力学，并且具有足够的信息来恢复最优的极限目标策略。", "conclusion": "通过一系列实验，作者证明了双重目标表示能够在20个基于状态和像素的任务中持续提高离线目标到达性能。该方法可以与其他现有GCRL算法结合使用，显示出广泛的应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06718", "html_url": "https://arxiv.org/abs/2510.06718", "title": "大型语言模型公司在软件组织中的政策及其影响", "title_en": "LLM Company Policies and Policy Implications in Software Organizations", "authors": "Ranim Khojah,Mazen Mohamad,Linda Erlenhov,Francisco Gomes de Oliveira Neto,Philipp Leitner", "background": "在软件组织中采用大型语言模型（LLM）聊天机器人存在风险，这表明需要明确的政策。本文探讨了11家公司制定这些政策的方式及影响因素，旨在帮助管理者安全地将聊天机器人集成到开发流程中。", "innovation": "本文创新性地研究了软件组织中11家公司的政策制定情况，重点分析影响政策制定的因素，为管理者提供了一个安全地将聊天机器人融入开发流程的框架。", "conclusion": "通过研究11家公司的经验，本文提出了制定有效的聊天机器人政策的关键因素，强调了风险管理的重要性，并为软件组织的治理提供指导。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06638", "html_url": "https://arxiv.org/abs/2510.06638", "title": "StaR-KVQA: 隐式知识结构推理痕迹用于视觉问答", "title_en": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering", "authors": "Zhihao Wen,Wenkang Wei,Yuan Fang,Xingtong Yu,Hui Zhang,Weicheng Zhu,Xin Zhang", "background": "知识导向的视觉问答（KVQA）需要模型将实体与图像关联并在事实知识上进行推理。本文探讨的是它的隐式知识变体——IK-KVQA，其中只使用多模态大型语言模型（MLLM）作为知识来源，没有外部检索。然而，MLLM缺乏明确的推理监督，产生的解释不一致，并且在标准监督微调（SFT）后泛化能力较弱。", "innovation": "提出了一种名为StaR-KVQA的方法，它通过监督结构化的推理痕迹——包括符号关系路径和路径地面化的自然语言解释——使推理变得透明可验证。StaR-KVQA利用一个开源MLLM构建和选择路径地面化的推理痕迹来形成数据集，并通过结构化自我蒸馏进行微调，以使生成与监督一致。该方法不需要外部检索器、验证器或知识库，并且推理过程由一个自回归步骤完成。StaR-KVQA在多个基准测试中提升了准确性和可解释性，在OK-VQA基准上相比最强基线提高了高达11.3%的问答准确性，且表现出跨域泛化性。", "conclusion": "StaR-KVQA通过结构化的推理痕迹提高了IK-KVQA的准确性和可解释性，在多个基准测试中与现有方法相比表现出显著的提升，并且能够实现跨域泛化。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06708", "html_url": "https://arxiv.org/abs/2510.06708", "title": "AISysRev - 基于大语言模型的标题-摘要筛选工具", "title_en": "AISysRev - LLM-based Tool for Title-abstract Screening", "authors": "Aleksi Huotala,Miikka Kuutila,Olli-Pekka Turtio,Mika Mäntylä", "background": "系统综述是软件工程中总结现有证据的标准实践。在系统综述中，尤其是在筛选或研究选择阶段，由于论文数量庞大，这一过程非常耗时。在这一阶段，论文根据其标题和摘要来评估是否符合纳入或排除标准。最近的研究表明，大型语言模型（LLMs）在标题-摘要筛选方面的表现可以与硕士研究生相当。虽然LLMs不能完全信赖，但它们可以用于加速系统综述过程，例如Rapid Reviews。", "innovation": "基于最近的研究成果，我们开发了AiSysRev，这是一种基于LLM的筛选工具，以网页应用程序的形式运行在Docker容器中。该工具接受包含论文标题和摘要的CSV文件，用户可以自定义纳入和排除标准。通过OpenRouter，可以使用多个LLM进行筛选。AiSysRev支持零样本和少样本筛选，并允许通过显示LLM结果的人机交互界面进行人工筛选。我们在137篇论文中进行了试验研究，结果显示论文可以被归类为四类：易纳入、易排除、边界纳入和边界排除。后者指出LLMs容易出错，需要人工干预。", "conclusion": "虽然LLMs不能完全替代人类在系统综述中的判断，但它们可以显著减轻评估大量科学文献的负担。AiSysRev结合LLMs和人类干预，提供了一种有效的筛选机制，有助于加速和提高系统综述的质量和效率。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06661", "html_url": "https://arxiv.org/abs/2510.06661", "title": "延迟独立安全控制与神经网络：风险感知自主性的正Lur'e证书", "title_en": "Delay Independent Safe Control with Neural Networks: Positive Lur'e Certificates for Risk Aware Autonomy", "authors": "Hamidreza Montazeri Hedesh,Milad Siami", "background": "本文提出了一个风险感知的安全认证方法，用于自主、基于学习控制系统的场景。研究重点是两种现实风险：状态/输入延迟和区间矩阵不确定性。基于这些风险，构建了一个神经网络控制器，并通过局部扇区限制和积极结构来推导稳定性证书，从而保证在可接纳的不确定性范围内实现局部指数稳定性。为了验证性能，采用了并实现了最先进的基于LQC的神经网络验证管道。在代表性案例中，基于积极性的测试速率比基于SDP的LQC快得多，同时具备SDP无法保证的安全性范围，从而提供了可扩展的安全保证，以补充风险感知控制。", "innovation": "本文创新地提出了基于积极结构的Lur'e证书方法，适用于处理神经网络控制器中的状态/输入延迟和区间矩阵不确定性，确保在这些不确定性范围内实现局部指数稳定性。相比基于SDP的LQC方法，该方法不仅更快速，而且能验证更广泛的不确定性范围，为风险感知控制提供了更强大的安全保证。", "conclusion": "本文方法通过更快的积极结构验证提高了安全性的可扩展性，并能覆盖更多未被基于SDP的LQC验证的方法所涵盖的场景。这为风险感知自主性控制提供了更为稳健和高效的解决方案，为实际应用提供了有力支持。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06695", "html_url": "https://arxiv.org/abs/2510.06695", "title": "为下游任务自训练LLMs的学习重写提示方法", "title_en": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks", "authors": "Qinhao Zhou,Xiang Xiang,Kun He,John E. Hopcroft", "background": "近年来，对大规模语言模型（LLMs）的兴趣显著增加了指令工程的发展，从手动设计转向基于模型的优化。LLM的提示通常包含两个组成部分：\textit{指令}，定义任务或目标；以及\textit{输入}，针对指令类型定制。在机器翻译等自然语言生成（NLG）任务中，\textit{输入}部分尤为重要，而\textit{指令}部分通常更为简洁。现有的指令工程方法主要集中在对通用任务优化\textit{指令}部分，通常需要使用大量参数的LLM作为辅助工具。然而，这些方法在机器翻译等\textit{输入}部分更为关键的任务中应用有限。因此，本文提出了专门针对机器翻译任务的新型指令优化方法，该方法使用小参数模型并通过反向翻译策略进行训练，显著减少了单任务优化的训练开销，同时提供高效性能。", "innovation": "本文介绍了一种专门针对机器翻译任务的小参数模型训练方法，通过反向翻译策略训练模型，显著降低单任务优化的训练开销，同时保持高效性能。这一方法还能通过某些适应措施扩展到其他下游任务。传统的提示工程方法主要优化通用任务中的\textit{指令}部分，而忽视了\textit{输入}部分的重要性，本文的方法则着重于针对机器翻译等任务优化\textit{输入}部分。", "conclusion": "本文提出的方法在单一任务优化中表现出高效性能，通过小参数模型和反向翻译策略显著降低了训练成本。这种方法适用于机器翻译等任务，并可以通过一定的调整应用于其他下游任务。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06677", "html_url": "https://arxiv.org/abs/2510.06677", "title": "通过渐进式笔记和代理反馈进行增量总结", "title_en": "Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback", "authors": "Yisha Wu, Cen (Mia)Zhao,Yuanpei Cao,Xiaoqing Su,Yashar Mehdad,Mindy Ji,Claire Na Cheng", "background": "本文介绍了一种为客户服务代表设计的增量总结系统，该系统能够智能地确定在对话过程中何时生成简洁的要点摘要，从而减少客户服务代表在不同任务之间的切换次数和冗余审查次数。该方法结合了针对连续笔记生成进行微调的Mixtral-8x7B模型与基于DeBERTa的分类器来过滤无关内容，代理编辑改进在线笔记生成，并定期通知离线模型重新训练，形成代理编辑反馈循环。系统在实际部署后，与批量总结相比，实现了3%的案件处理时间降低，最高降幅可达9%，同时问卷调查显示代理商满意度高。这些结果表明，带有持续反馈的增量总结可以有效提高摘要质量并提升代理生产力。", "innovation": "该研究提出了一种智能增量总结系统，结合了微调的Mixtral-8x7B模型和DeBERTa分类器，能够智慧地辨别哪些内容需要生成摘要，并通过代理编辑和离线模型更新实现持续优化，从而减少客户服务代表的工作负担，提高效率与满意度。", "conclusion": "研究结果表明，增量总结与持续反馈机制增强了摘要的质量和代理的生产力规模。实际部署中，该系统不仅显著降低了案件处理时间，还得到了高度满意的客户服务代表评价。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06776", "html_url": "https://arxiv.org/abs/2510.06776", "title": "使用物理知情神经网络建模德国各州的COVID-19动态", "title_en": "Modeling COVID-19 Dynamics in German States Using Physics-Informed Neural Networks", "authors": "Phillip Rothenbeck,Sai Karthikeya Vemuri,Niklas Penzel,Joachim Denzler", "background": "COVID-19大流行突显了定量建模和分析在理解现实世界疾病动力学中的重要性。特别是，使用特征模型的回顾性分析提供了有关公共卫生干预措施（如疫苗策略和遏制政策）有效性的宝贵见解。然而，这些特征模型在直接整合嘈杂的观测数据时往往存在局限性。", "innovation": "本文采用物理知情神经网络（PINNs）来通过罗伯特·科赫研究所的感染数据解决SIR模型的逆问题，实现了对德国所有联邦州三年内COVID-19动态的精细空间-时间分析。估计了各地区特异性的传播和恢复参数以及随时间变化的再生数（R_t），以跟踪大流行进展。结果显示了各地区传播行为的显著差异，并与疫苗接种率和主要流行阶段的时间模式相关。", "conclusion": "研究结果表明，PINNs在局部长期内的流行病学建模中有很高的实用性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06791", "html_url": "https://arxiv.org/abs/2510.06791", "title": "极端无感面检测", "title_en": "Extreme Amodal Face Detection", "authors": "Changlin Song,Yunzhong Hou,Michael Randall Barnes,Rahul Shome,Dylan Campbell", "background": "无感检测是指推断输入图像中未完全可见但仍存在于扩展视场中的物体的2D位置。这与部分可见但被遮挡的无感检测有所不同。现有的方法依赖于图像序列或生成模型来解决此类问题。本文专注于无感面检测的子问题，设计了一种基于热图的极端无感对象检测器，能够利用图像中的上下文线索推断不可见的面的存在。", "innovation": "本文提出了一个无需采样的更高效的方法，通过选择性粗细解码器利用图像中的上下文线索推断不可见面的存在，相比生成模型的方法更为高效。", "conclusion": "该方法在这个新任务上取得了强劲的结果，甚至超过了那些效率较低的生成方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06732", "html_url": "https://arxiv.org/abs/2510.06732", "title": "两阶段令牌优化下的LLMs可靠排序器吗？排序操控", "title_en": "Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token Optimization", "authors": "Tiancheng Xing,Jerry Li,Yixuan Du,Xiyang Hu", "background": "大型语言模型（LLMs）越来越多地被用作信息检索中的重排序器，但它们的排名行为可以通过自然听起来的小提示被操控。为了揭示这一漏洞，本文提出了Rank Anything First (RAF) 两阶段令牌优化方法，该方法精心设计简洁的文字干扰以一致地提升LLM生成排名中的目标项目，同时保持难以察觉。实验表明，这些方法在提升目标项目的排名效果和保持自然语言表达上比现有方法更加稳健。这就揭示了重要安全问题：基于LLM的重排序本质上容易受到对抗性操控的影响，这对现代检索系统中的可信度和稳健性构成了新的挑战。", "innovation": "提出了一种两阶段令牌优化方法（RAF），该方法通过精心设计简洁的文字干扰以一致地提升LLM生成排名中的目标项目，同时保持难以察觉。第一阶段使用贪心坐标梯度筛选当前位置的候选令牌，第二阶段使用熵为基础的动态权重方案评估候选令牌，并通过温度控制的采样选择最合适的令牌。此方法旨在最大化排名效果同时保持语言的自然性，在多个LLM的实验中证明了其优越性，增强了目标项目的排名效果，同时保持了自然语言的表达。", "conclusion": "实验结果表明，RAF能够显著提升目标项目的排名，与现有方法相比，在保持自然性和提升排名效果方面都更加稳健。这些发现强调了一个重要的安全问题，即基于LLM的重排序程序本质上是容易受到对抗性操控影响的，这提出了对现代检索系统中的可信度和稳健性的新挑战。我们提供了代码供进一步研究和测试。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06743", "html_url": "https://arxiv.org/abs/2510.06743", "title": "评估基于大型语言模型的古代文献OCR：数字人文领域的方法论框架", "title_en": "Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities", "authors": "Maria Levchenko", "background": "数字人文学者越来越多地使用大型语言模型进行历史文档数字化，但缺乏对基于大型语言模型的OCR进行适当评估的方法框架。传统评估指标无法捕捉对创建历史语料库至关重要的历史时段偏差和特定时期的错误。该研究旨在提出一种针对基于大型语言模型的历史OCR的评估方法，以解决外交转录中的污染风险和系统性偏差问题。研究人员使用18世纪俄罗斯军事风格的文本进行评估，引入了诸如历史字符保存率（HCPR）和古插入率（AIR）等新型指标，以及污染控制和稳定性测试协议。评估了12个跨模态的大型语言模型，发现Gemini和Qwen模型在传统的OCR方法上表现出色，但过度历史化，插入了来自错误历史时期的古字符。OCR后的纠正反而降低了性能。该研究为数字人文实践者提供了选择模型和评估历史语料库数字化质量的方法指导。", "innovation": "该研究提出了针对基于大型语言模型的历史OCR的评估方法，包括新型指标——历史字符保存率（HCPR）和古插入率（AIR）；明确了污染控制和稳定性测试协议；评估了12个跨模态的大型语言模型，并识别出了过度历史化的现象；指出了OCR后纠正的负面影响。这些创新点提高了历史档案数字化的准确性和可靠性，为数字人文项目提供了重要参考。", "conclusion": "该研究提供了一种评估大型语言模型在历史文档数字化中的效能的方法，通过详细的实验验证和数据分析，确定了不同模型的表现及其潜在问题，为数字人文学者提供了选择合适的OCR模型及其后续处理方案的指导。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06828", "html_url": "https://arxiv.org/abs/2510.06828", "title": "完全递归框架动作模型", "title_en": "Recurrence-Complete Frame-based Action Models", "authors": "Michael Keiblinger", "background": "近年来，注意力机制在大规模语言模型中取得了巨大成功，拓展了模型的扩展能力。《注意力就是你所需要的全部》一文认为在注意力机制下不需要递归神经网络单元。本文挑战这一观点，指出完全并行化前向或后向传递的架构不能表示长时并发任务特别感兴趣的问题类别，并猜测非递归完整模型在某些时间点后无法正确聚合输入。此外，提出通过GitHub衍生的动作序列训练一个递归完整架构，发现损失随训练序列长度的增加而遵循幂律，并且参数数量保持不变。", "innovation": "提出了一个递归完整的架构，并使用从GitHub衍生的动作序列进行训练，验证了递归监督的重要性，同时损失随序列长度的增加遵循幂律，且训练能耗随时间摊薄。", "conclusion": "展示了完全递归框架在长序列训练中的优势，尤其是在软件工程代理系统中的具体应用，并且长序列训练能够摊薄线性增加的能耗成本，使得总损失随时间呈下降趋势。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06843", "html_url": "https://arxiv.org/abs/2510.06843", "title": "SID: Multi-LLM Debate Driven by Self Signals", "title_en": "SID: Multi-LLM Debate Driven by Self Signals", "authors": "Xuhang Chen,Zhifan Song,Deyi Ji,Shuo Gao,Lanyun Zhu", "background": "大语言模型（LLMs）在多个应用领域展示了令人印象深刻的性能。最近的研究探索了多LLM代理辩论（MAD）作为增强性能的一种方法，这种方法允许多个LLM进行讨论和迭代响应的改进。然而，现有的MAD方法主要集中在利用外部结构，如辩论图，并使用LLM作为法官，而忽略了生成过程中产生的自信号，如token logits和注意力。这些自信号的缺失导致了冗余计算和潜在的性能下降。", "innovation": "本文将重点从外部结构转向多LLM辩论的自信号，并引入了一种自信号驱动的多LLM辩论（SID），利用两种类型的自信号：模型级别的信心和token级别的语义关注，来自适应地引导辩论过程。该方法允许高信心的代理在模型级别提前退出，并基于注意力机制压缩冗余的辩论内容。方法在各种LLMs和多模态LLMs上进行了多种挑战性基准测试的评估。", "conclusion": "实验结果表明，该方法不仅在准确率上优于现有的MAD技术，而且还可以减少token消耗，突显了利用自信号提高多代理辩论系统的性能和效率的有效性。我们的代码可在\texttt{this https URL}获得。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06840", "html_url": "https://arxiv.org/abs/2510.06840", "title": "基于SHAP和多头注意权重的CNN-TFT时间序列预测解释", "title_en": "CNN-TFT explained by SHAP with multi-head attention weights for time series forecasting", "authors": "Stefano F. Stefenon,João P. Matos-Carvalho,Valderi R. Q. Leithardt,Kin-Choong Yow", "background": "卷积神经网络（CNNs）和变压器架构在处理时序数据方面具有优势：CNNs擅长捕捉局部模式和平移不变性，而变压器则通过自注意力机制有效建模长距离依赖关系。本文提出了一种结合卷积特征提取与时间融合变压器（TFT）主体的混合架构，以增强多变量时序预测。该卷积模块首先通过一维卷积层的层次结构从原始输入序列中提取显著的局部特征，减少噪声和维度。这些特征图随后被馈送到TFT中，该模块通过多头注意力机制捕捉短期和长期依赖性，并根据不同相关的协变量进行自适应加权。", "innovation": "本文提出的混合架构CNN-TFT-SHAP-MHAW结合了卷积特征提取和时间融合变压器框架，并通过多头注意力机制提高了模型的预测能力。此外，通过SHAP-MHAW方法提出了模型的可解释性，确保其在需要高准确度多变量时间序列预测的应用场景中的适用性。", "conclusion": "实验结果显示，与现有的深度学习模型相比，CNN-TFT-SHAP-MHAW在水电自然流量时序数据集上的平均绝对百分比误差最高可降至2.2%。这一新型架构为多变量时序预测领域的进一步分析提供了潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06847", "html_url": "https://arxiv.org/abs/2510.06847", "title": "OpenJAI-v1.0: 一个开源的泰语大型语言模型", "title_en": "OpenJAI-v1.0: An Open Thai Large Language Model", "authors": "Pontakorn Trakuekul,Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Sumana Sumanakul", "background": "本研究介绍了一个名为OpenJAI-v1.0的开源大型语言模型，该模型同时支持泰语和英语，由Qwen3-14B模型开发而来。该模型旨在通过精心筛选的数据提高在三个关键应用场景中的表现：指令遵从、长文理解以及工具使用。", "innovation": "该模型的主要创新在于通过精心选择的数据提高了在三个关键应用场景中的性能表现，并且评估结果显示OpenJAI-v1.0在各种基准测试上优于其他领先的开源泰语模型，同时没有出现灾难性遗忘。", "conclusion": "OpenJAI-v1.0作为另一个泰国AI社区可用的NLP资源，已经公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06860", "html_url": "https://arxiv.org/abs/2510.06860", "title": "基于图神经网络的AC最优潮流泛化研究", "title_en": "Towards Generalization of Graph Neural Networks for AC Optimal Power Flow", "authors": "Olayiwola Arowolo,Jochen L. Cremer", "background": "对于大规模电力系统，传统最优潮流（AC Optimal Power Flow, ACOPF）问题具有很高的计算成本，需要的求解时间往往是不可接受的。机器学习方法提供了计算加速的机会，但在没有昂贵的重新训练的情况下，难以实现规模适应性及拓扑变化适应性。", "innovation": "提出了一种混合异质消息传递神经网络（Hybrid Heterogeneous Message Passing Neural Network, HH-MPNN）来解决这一问题。HH-MPNN将母线、发电机、负荷、并联电抗器、输电线路和变压器作为不同的节点或边类型，并结合一个可扩展的变压器模型来处理长范围依赖关系。此方法在14至2000个母线的不同拓扑中，达到了不到1%的最优间隙。此外，即便仅在默认拓扑上进行训练，它对未见过的上千种拓扑也有不到3%的最优间隙表现。通过在较小的电网上的预训练，也可以在较大电网上取得更好的结果。相比内点法求解器，计算加速可以高达1000到10000倍。", "conclusion": "该研究推进了适用于实时电力系统操作的实用且可泛化的机器学习方法的发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06880", "html_url": "https://arxiv.org/abs/2510.06880", "title": "MoRE-GNN: 使用异构图自编码器的多组学数据集成", "title_en": "MoRE-GNN: Multi-omics Data Integration with a Heterogeneous Graph Autoencoder", "authors": "Zhiyu Wang,Sonia Koszut,Pietro Liò,Francesco Ceccarelli", "background": "多组学单细胞数据分析面临挑战，因为高维度和复杂的跨模态关系使得整合多组学单细胞数据变得困难。", "innovation": "MoRE-GNN （多组学关系边图神经网络）是一种异构图自动编码器，结合图卷积和注意力机制，直接从数据中动态构建关系图。评估结果显示，MoRE-GNN 捕捉到具有生物学意义的关系，并且在强跨模态相关性的情况下优于现有方法。此外，学习到的表示能够进行准确的跨模态下游预测。", "conclusion": "虽然 MoRE-GNN 的性能可能因数据集复杂性而异，但它提供了一个适应性、可扩展且可解释的框架，用于推进多组学整合。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06907", "html_url": "https://arxiv.org/abs/2510.06907", "title": "使用SpherePair损失的角约束嵌入用于约束聚类", "title_en": "Angular Constraint Embedding via SpherePair Loss for Constrained Clustering", "authors": "Shaojie Zhang,Ke Chen", "background": "现有的深度约束聚类（DCC）方法要么受限于端到端模型中的锚点，要么难以学习区分的欧几里得嵌入，这限制了它们的可扩展性和实际应用性。", "innovation": "提出了一种新的基于角度约束嵌入的方法SpherePair，使用几何形式的SpherePair损失，该方法忠实于嵌入对之间的约束，并将嵌入转换为适合聚类的角度空间，从而有效地分离表示学习和聚类。SpherePair方法能保存关系、无需指定簇的具体数量、能够处理未见过的数据、并能快速确定簇的数量，同时得到了严格的理论保证。", "conclusion": "与最新的DCC方法相比，在多样化的基准上进行的比较评估以及对理论见解的实证验证都证明了其在性能、可扩展性和整体实际效果上的优越性。源代码可以在我们的仓库中找到。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06800", "html_url": "https://arxiv.org/abs/2510.06800", "title": "FURINA：通过可扩展多智能体协作流水线实现完全可定制化的角色扮演基准", "title_en": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline", "authors": "Haotian Wu,Shufan Jiang,Chios Chen,Yiyang Feng,Hehai Lin,Heqing Zou,Yao Shu,Yanran Li,Chengwei Qin", "background": "随着大型语言模型（LLMs）在角色扮演（RP）任务上的不断进步，现有的基准很快变得过时，因为这些基准范围狭窄、交互模式过时且在多种应用场景中缺乏适应性。为了填补这一空白，我们引入了FURINA-Builder，这是一种新颖的多智能体协作流程，能够自动构建按需定制的RP基准。FURINA-Builder允许评估各种各样的角色及多样化的场景和提示格式，这是RP领域中首个适应性评估的基准构建器。", "innovation": "FURINA-Builder 是一种能够自动生成可定制 RP 基准的多智能体协作流水线，能够模拟由精心构建的角色场景池中的其他角色与测试角色之间的对话。该流水线允许人工选择细粒度的评价维度并调整测试角色的响应至最终的测试陈述。FURINA-Builder 采用此流程构建了 FURINA-Bench，这是一种新的全面的RP基准，包含既有和合成的角色，并采用特定维度的评价标准进行评估。初步的人机评价和可分离性分析证实了该流程和基准的设计合理性。对于前沿的LLMs，o3 和 DeepSeek-R1 分别在英文和中文RP任务中表现出最佳性能。对于不同模型，既有角色始终优于合成角色，推理能力进一步扩大了这种差距。此外，观测到模型规模并非单向减少幻想现象，并且对于推理LLMs，推理性能提升和RP幻想增多之间存在一种新的权衡关系：这一权衡关系同样适用于所有LMs在RP性能与可靠性之间的帕累托前沿。", "conclusion": "这些发现证明了FURINA-Builder的有效性和FURINA-Bench面临的挑战。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06882", "html_url": "https://arxiv.org/abs/2510.06882", "title": "边缘设备上流处理服务的多维自动扩展现", "title_en": "Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices", "authors": "Boris Sedlak,Philipp Raith,Andrea Morichetta,Víctor Casamayor Pujol,Schahram Dustdar", "background": "边缘设备拥有有限的资源，导致流处理服务不能满足其需求。现有的自动扩展机制主要集中在资源扩展上，而边缘设备需要其他方式来维持竞争服务的服务级别目标（SLOs）。这需要多维度的自动扩展平台来支持服务和资源层面的细粒度垂直扩展。", "innovation": "我们提出了一个名为MUDAP（多维度自动扩展现）的平台，支持服务和资源方面的细粒度垂直扩展。MUDAP具有针对特定服务的扩展能力，可以根据可用参数调整，例如，提升数据质量或模型大小。我们还提出了一种基于结构性知识回归分析的扩展代理（RASK），能够高效探索解决方案空间，并学习持续的回归模型来推断最优扩展动作。", "conclusion": "我们将我们的方法与两个自动扩展器（Kubernetes VPA和强化学习代理）进行了比较，在单个边缘设备上处理多达9个服务。结果表明，RASK可以在仅20次迭代中（即观察200秒的处理时间）推断出精确的回归模型。通过不断增加弹性维度，RASK在请求负载方面优于基线，SLO违例降低了28%。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06780", "html_url": "https://arxiv.org/abs/2510.06780", "title": "LLM知识材料化的基础：终止性、可再现性、鲁棒性", "title_en": "Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness", "authors": "Luca Giordano,Simon Razniewski", "background": "大型语言模型（LLMs）蕴含了大量的事实性知识，但如何衡量和系统化这一知识仍然是一个挑战。虽然可以通过递归提取方法，例如GPTKB方法（Hu et al., 2025b）将其转换为结构化格式，但这一领域仍需更多探索。研究的关键问题在于这种提取过程是否能终止，提取结果是否可复现，以及在不同条件下的鲁棒性如何。本文使用miniGPTKBs（针对特定领域、可管理的小型子提取），从三个类别（产出、词法相似度和语义相似度）的指标出发，系统研究了大型语言模型知识的材料化，并在四个变量（种子、语言、随机性和模型）和三个示例领域（历史、娱乐和金融）上进行了实验。", "innovation": "通过miniGPTKBs进行特定领域的、可管理的小型子提取，研究大型语言模型知识材料化的终止性、可再现性和鲁棒性，并从产出、词法相似度和语义相似度三个方面进行分析。实验涵盖了种子、语言、随机性和模型四个变量，以及历史、娱乐和金融三个示例领域。研究结果表明，尽管终止率较高但依赖于模型；可再现性有不同程度的表现；鲁棒性根据不同的干扰类型而有所波动，对于种子和温度较高，但对语言和模型较低。这些建议表明大型语言模型知识材料化可以可靠地揭示核心知识，但也揭示了其重要局限性", "conclusion": "大型语言模型知识材料化可以在很大程度上可靠地揭示核心知识，但这依然存在显著限制，未来的探索需进一步研究这些限制的具体原因和解决策略。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06888", "html_url": "https://arxiv.org/abs/2510.06888", "title": "M3Retrieve: 医学领域多模态检索基准", "title_en": "M3Retrieve: Benchmarking Multimodal Retrieval for Medicine", "authors": "Arkadeep Acharya,Akash Ghosh,Pradeepika Verma,Kitsuchart Pasupa,Sriparna Saha,Priti Singh", "background": "随着检索增强生成（RAG）的应用越来越多，强大的检索模型变得尤为关键。在医疗领域中，结合文本和图像信息的多模态检索模型在许多下游任务（如问答、跨模态检索和多模态总结）中提供了显著的优势，因为医学数据通常包含这两种格式。然而，目前尚未有针对医疗场景的标准基准来评估这些模型的性能。为填补这一空白，本文介绍了M3Retrieve，一个涵盖了五大领域、16个医学领域和4种不同任务的多模态医学检索基准，包含了超过120万的文字文档和16.4万的多模态查询，并且所有数据均在获批许可下收集。", "innovation": "M3Retrieve是一个新的基准，专门用于评估医疗领域的多模态检索模型。它首次提供了针对不同医学专科的具体挑战的系统性评估，并促进了模型创新，从而加速了为医学应用构建更强大和可靠的多模态检索系统的研究进程。此外，该数据集和基线代码可以在github上获取。", "conclusion": "通过发布M3Retrieve，本文旨在促进系统评估、推动模型创新并加速研究进程，朝着构建更强大和可靠的多模态检索系统的目标迈进，从而在医疗应用中更好地利用这两类数据。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06858", "html_url": "https://arxiv.org/abs/2510.06858", "title": "解释原始数据的复杂性以提高卫星机载处理", "title_en": "Explaining raw data complexity to improve satellite onboard processing", "authors": "Adrien Dorise,Marjorie Bellizzi,Adrien Girard,Benjamin Francesconi,Stéphane May", "background": "随着计算能力的增强，将人工智能模型直接部署到卫星上进行遥感分析变得可行。然而，当使用未经预处理的传感器数据而非基于地面的预处理产品时，会带来新的限制。当前的解决方案主要依赖于预处理的传感器图像，只有少数方法直接利用原始数据。本研究旨在研究利用原始数据对目标检测和分类任务中的深度学习模型的影响。通过对高分辨率L1影像生成类似原始数据的产品，进行系统评估。将两种目标检测模型（YOLOv11s和YOLOX-S）分别训练在原始数据和L1数据上，并使用标准检测指标和可解释性工具进行比较。结果表明，尽管在低到中等置信度阈值下两种模型表现相当，但用原始数据训练的模型在高置信度级别下难以准确识别对象边界，这表明改进边缘检测方法可以提高原始图像上的目标检测能力，从而改善卫星机载的智能处理能力。", "innovation": "研究通过引入生成类似于原始产品的模拟工作流，系统性地评估了利用原始数据进行目标检测和分类的影响。利用YOLOv11s和YOLOX-S两种模型在原始和L1数据集上的训练结果对比，揭示了模型在高置信水平下的边界识别能力差异。此外，提出了改进边缘检测方法以增强在原始图像上的目标检测能力，从而提升卫星机载AI性能。", "conclusion": "研究结果表明，尽管两种模型在低到中等置信度下表现相近，训练于原始数据的模型在高置信度下识别对象边界的能力较弱。这种发现表明，优化AI架构以提高边缘检测能力将改善在原始图像上的目标检测，从而提升卫星机载AI系统的能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06852", "html_url": "https://arxiv.org/abs/2510.06852", "title": "通过高级机器学习技术增强银行破产预测：一种创新方法和分析", "title_en": "Enhancing Bankruptcy Prediction of Banks through Advanced Machine Learning Techniques: An Innovative Approach and Analysis", "authors": "Zuherman Rustam,Sri Hartini,Sardar M.N. Islam,Fevi Novkaniza,Fiftitah R. Aszhari,Muhammad Rifqi", "background": "金融系统的稳定取决于银行业务的状况。银行的倒闭可能会破坏金融系统的稳定性，因为银行会受到系统性风险的影响，不仅波及个别银行，还可能影响整个金融体系。现有统计模型，如Altman的Z-Score，用于开发破产预测模型。然而，这些统计方法依赖于严格的假设，有时这些假设是无关紧要的，可能导致预测准确性较低。为了解决这一问题，本文使用了机器学习技术，如逻辑回归、随机森林和支持向量机来开发破产模型。研究表明，机器学习方法在分类和预测银行风险管理方面比统计方法更准确和有效。研究基于1994年至2004年土耳其44家活跃银行和21家破产银行的数据以及2013年至2019年印度尼西亚43家活跃和43家破产农村银行的数据来验证模型的有效性和泛化能力。", "innovation": "本文引入了机器学习技术来开发银行破产预测模型，特别是使用了逻辑回归（LR）、随机森林（RF）和支持向量机（SVM）。研究发现，随机森林方法在预测商业银行数据集的破产概率方面取得了90%的准确率，并且三种机器学习方法能够准确预测农村银行破产的可能性。这种方法比传统统计方法更有效，能够提供更准确的破产预测，有助于制定减少破产成本的政策，提高了整体金融系统的稳定性。", "conclusion": "本文通过使用先进的机器学习技术，提出了一种创新的破产预测方法，这种方法能够准确预测银行的破产风险。研究结果表明，随机森林方法在预测商业和农村银行破产方面表现出较高的准确性，能够帮助政策制定者更好地理解和应对银行倒闭风险，从而降低破产成本，提高金融系统的稳定性。这种基于机器学习的破产预测方法为未来的风险管理提供了新的视角和工具。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06868", "html_url": "https://arxiv.org/abs/2510.06868", "title": "使用深度散列蒸馏的多跳深度联合源信道编码在语义对齐图像检索中的应用", "title_en": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval", "authors": "Didrik Bergström,Deniz Gündüz,Onur Günlü", "background": "本文考虑了通过训练深度联合源信道编码（DeepJSCC）编码-解码对来实现图像传输，其中预训练的深度散列蒸馏（DHD）模块帮助企业实现图片的语义聚类，提高安全性并改善感知重建质量。研究集中于多跳累加高斯白噪声（AWGN）信道，经典 APPROACH 可能因为噪声累积而导致性能下降。提出的模型使用学习感知图像块相似度（LPIPS）来衡量感知质量的提升，以不同多跳设置展示出来的显著语义对齐感知质量提高为特征。这些设置能够证明经典方法可能遭受的噪声积累带来的负面影响。这就提出了一个在图像传输中结合语义对齐和提高感知质量的研究方向。", "innovation": "本文创新地结合了深度散列蒸馏（DHD）模块用于预处理和语义聚类，以及通过同时优化均方误差（MSE）和 DHD 哈希源图像与重建图像之间的余弦距离，训练一个深度联合源信道编码（DeepJSCC）模型，从而提高多跳场景下的图像传输质量。并且，通过LPIPS度量展示了在不同多跳设置中感知质量的巨大提升，证实了传统方法的局限性。此外，还提出了一种有效的解决方案来减少噪声累积的影响，从而实现了更高的语义一致性。", "conclusion": "通过使用深度联合源信道编码（DeepJSCC）搭配预训练的深度散列蒸馏（DHD）模块，本文研究提升了多跳高斯白噪声（AWGN）信道中图像传输的感知质量和语义对齐性。策略表明，该方法在不同多跳设置下能够有效减少噪声累积的影响，并保持较高的图像重建质量。这对于需要高质量图像传输的安全应用具有重要意义。未来的进一步研究可探索更复杂网络的优化，以适应更多样的应用场景。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06913", "html_url": "https://arxiv.org/abs/2510.06913", "title": "DecompGAIL: 使用分解式多智能体生成对抗模仿学习学习真实交通行为", "title_en": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning", "authors": "Ke Guo,Haochen Liu,Xiaojun Wu,Chen Lv", "background": "现实交通模拟对于自动驾驶系统和城市交通规划的发展至关重要，但现有的模仿学习方法往往无法准确模拟真实交通行为。行为克隆容易出现协变量偏移问题，而生成对抗模仿学习（GAIL）在多智能体环境中尤为不稳定。该问题主要源于不相关信息的误导，即由于邻近智能体的不现实交互，判别器错误地惩罚了自我车辆的真实行为。", "innovation": "为解决上述不稳定性问题，本文提出了分解式多智能体GAIL（DecompGAIL），该方法将现实性明确分解为自我地图和自我邻近组件，排除误导的邻近：邻近和邻近：地图交互。同时，引入了社会PPO目标，通过距离加权邻里奖励来增强自我奖励，鼓励整个群体中的统整个人类行为。DecompGAIL 融合到一个轻量级的 SMART 基础架构上，取得了 WOMBAT Sim Agents 2025 基准测试中的最佳性能。", "conclusion": "DecompGAIL 在WOMBAT Sim Agents 2025基准测试中实现了最先进的性能，通过分解现实性并引入社会PPO目标来改善多智能体GAIL的稳定性与泛化能力，从而提高了交通行为模拟的质量。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06938", "html_url": "https://arxiv.org/abs/2510.06938", "title": "具表达性和可扩展性的量子融合方法在多模态学习中的应用", "title_en": "Expressive and Scalable Quantum Fusion for Multimodal Learning", "authors": "Tuyen Nguyen,Trong Nghia Hoang,Phi Le Nguyen,Hai L. Vu,Truong Cong Thang", "background": "本文旨在介绍一种用于多模态学习的量子融合机制，并探索其理论和实验潜力。现有的融合方法大多依赖于经典信息技术，而量子信息技术能够提供新的方法来处理多模态数据中的高阶特征交互。", "innovation": "本文提出了一种称为量子融合层（QFL）的方法，它使用参数化量子电路替代经典的融合方案，能够在不影响参数增长的情况下学习纠缠的特征交互。量子组件基于量子信号处理原则，能够高效地表示跨模态的高阶多项式交互，并且随着模态数量增加，QFL比低秩张量基方法有更好的表现。", "conclusion": "实验结果表明，QFL在小而多样的多模态任务中表现优于经典基线模型，并且在高模态环境中表现尤其突出。这些结果表明，QFL提供了一种根本上新的可扩展的多模态融合方法，值得在更大规模系统中进一步探索。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06919", "html_url": "https://arxiv.org/abs/2510.06919", "title": "基于贝叶斯非参数的时间序列动态聚类", "title_en": "Bayesian Nonparametric Dynamical Clustering of Time Series", "authors": "Adrián Pérez-Herrero,Paulo Félix,Jesús Presedo,Carl Henrik Ek", "background": "本文介绍了一种方法，通过在未知数量的线性动态系统之间切换来建模时间序列聚类随时间的演变。这种方法使用分层狄利克雷过程作为线性动态切换系统参数的先验，同时使用高斯过程先验来建模每个聚类内的幅度和时间对齐的统计变化。通过这种方式，可以在不必要地增加聚类数量的情况下建模时间序列模式的演变，从而实现聚类的合理增长。", "innovation": "本文提出的方法采用了贝叶斯非参数方法，能够适应未指定数量的时间序列聚类，通过分层狄利克雷过程和高斯过程先验实现对线性动态系统切换的建模，并通过变分下界进行推断，支持离线和在线推断场景下的高效学习。该方法的优势在于避免了不必要地高估聚类数量的倾向，同时能够在提高聚类质量的同时减少计算成本。", "conclusion": "该研究通过多个心电图分析的案例研究展示了此方法的多样性和有效性，证明了这种方法在实际应用中的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06915", "html_url": "https://arxiv.org/abs/2510.06915", "title": "LongRM：揭示并解锁奖励模型的上下文边界", "title_en": "LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling", "authors": "Zecheng Tang,Baibei Ji,Quantong Qiu,Haitian Wang,Xiaobo Liang,Juntao Li,Min Zhang", "background": "奖励模型（RM）在使大规模语言模型（LLM）与人类偏好保持一致方面发挥着关键作用。随着实际应用越来越多地涉及长历史轨迹，比如LLM代理，这就变得不可或缺，需要评估模型响应不仅质量高，还有助于与提供的上下文保持一致。然而，现有的RM仍然局限于短上下文设置，并主要关注响应级别的属性（如安全性或有用性），而忽略了长上下文-响应一致性这一关键维度。因此，为长上下文RM评估设计了一个新的基准，Long-RewardBench，它包含配对比较和最佳选择任务。早期研究表明，即使是最先进的生成型RM，在长上下文场景中表现出显著的脆弱性，难以维持上下文相关的偏好判断。", "innovation": "我们提出了一种通用的多阶段训练策略，可以有效将任意模型扩展为稳健的长上下文RM（LongRMs）。实验表明，这种方法不仅可以在长上下文评估中显著提高性能，还能保持强大的短上下文能力。值得注意的是，我们的8B LongRM在性能上优于规模大得多的70B基准，并且与专有的Gemini 2.5 Pro模型的性能相当。", "conclusion": "该工作旨在通过Long-RewardBench基准和多阶段训练策略来提高奖励模型在长上下文下的质量和一致性，验证了这种方法的有效性，并展示了在各种规模下的性能提升。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06908", "html_url": "https://arxiv.org/abs/2510.06908", "title": "互联网游戏障碍的情绪脆弱亚型：测量和探索问题生成人工智能使用中的病理特征", "title_en": "Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring and Exploring the Pathology of Problematic Generative AI Use", "authors": "Haocan Sun,Di Wua,Weizi Liu,Guoming Yua,Mike Yao", "background": "随着对生成型人工智能（GenAI）潜在过度病态化使用的担忧和对GenAI成瘾概念模糊性的担忧，研究开发了面向实践的工具并进行了理论上的优化。该研究在中国和美国的样本中验证了PUGenAIS-9（问题性使用生成型人工智能量表-9个条目），并通过互联网游戏障碍（IGD）框架考察了PUGenAIS是否能反映成瘾样模式。研究采用了结构验证分析，识别出了一个稳定的31项结构，并通过独立样本验证了PUGenAIS-9的结构，确认其在国家和性别上的稳定性。研究还使用了质心和变量中心的方法，发现PUGenAIS符合IGD情绪脆弱亚型的特征，而不是能力导向型亚型。这些结果支持使用PUGenAIS-9来识别问题性的GenAI使用，并强调需要使用ICD（基础设施、内容、和设备）模型重新思考数字成瘾现象，以保持成瘾研究对新媒介的敏感性，同时避免过度医学化.", "innovation": "该研究开发了PUGenAIS-9，一个用于衡量问题性GenAI使用的量表，并验证了其结构稳定性。通过使用互联网游戏障碍框架下的情绪脆弱亚型，研究提出了一种新的思维方式来理解数字成瘾问题，并强调了采用ICD模型的重要性.", "conclusion": "研究通过PUGenAIS-9的有效性和其与IGD情绪脆弱亚型的匹配性证明了其在识别问题性GenAI使用方面的可行性和有效性。这一研究为数字成瘾的理论发展与实践应用提供了新的思路，并强调了要在保护公众健康的同时防止过度医学化的重要性和紧迫性."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06949", "html_url": "https://arxiv.org/abs/2510.06949", "title": "组差异注意力", "title_en": "Grouped Differential Attention", "authors": "Junghwan Lim,Sungmin Lee,Dongseok Kim,Wai Ting Cheung,Beomgyu Kim,Taehwan Kim,Haesol Lee,Junhyeok Lee,Dongpin Oh,Eunhwan Park", "background": "自注意力机制是现代Transformer架构的核心，但存在一个关键问题：它经常将大量注意力分配给冗余或噪声的上下文。尽管Differential Attention已经通过使用减法注意力图来区分信号和噪声，但其需要平衡头的分配对表示灵活性和扩展性造成了严格限制。", "innovation": "提出了组差异注意力（GDA），这种新的方法引入了信号保全组和噪声控制组之间不平衡的头分配。GDA通过战略性地分配更多头来增强信号关注，并通过受控重复将后者稳定下来（类似于GQA），从而实现信号保真是以最小的计算开销为代价。此外，还进一步扩展了这一原则，提出了分组差异化增长策略，该策略只选择性地复制信号关注的头，从而确保高效的能力扩展。", "conclusion": "大规模预训练和持续训练实验表明，GDA中的适度不平衡比率在一般化和稳定性方面比对称基线有显著的改进。我们的结果共同表明，比率意识的头分配和选择性扩展为设计可扩展且计算高效的Transformer架构提供了一种有效和实用的道路。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06961", "html_url": "https://arxiv.org/abs/2510.06961", "title": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation", "title_en": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation", "authors": "Vaibhav Srivastav,Steven Zheng,Eric Bezzam,Eustache Le Bihan,Nithin Koluguri,Piotr Żelasko,Somshubra Majumdar,Adel Moumen,Sanchit Gandhi", "background": "尽管ASR评估在过去取得了快速进展，但仍主要集中在英语短语上，很少有研究报道效率相关数据。本文讨论了这个现状。", "innovation": "本文提出了Open ASR Leaderboard，这是一个全面可复现的基准测试和互动排行榜，涵盖了多种语音数据集，包括专门的多语言和长时语音识别赛道。它标准化了文本规范化，并报告了词错误率(WER)和逆实时因子(RTFx)，从而实现了准确性和效率的公平比较。", "conclusion": "所有相关代码及数据装载器都是开源的，以支持透明和可扩展的评估。在英语转写方面，Conformer编码器与LLM解码器结合提供了最佳的平均词错误率，但速度较慢。CTC和TDT解码器则提供了更好的逆实时因子，对于长时和离线使用更具吸引力。Whisper衍生的编码器通过微调提高了准确性，但在多语言覆盖方面有所牺牲。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06967", "html_url": "https://arxiv.org/abs/2510.06967", "title": "使用2D高斯绘制生成Text-to-3D表面", "title_en": "Generating Surface for Text-to-3D using 2D Gaussian Splatting", "authors": "Huanning Dong,Fan Li,Ping Kuang,Jianwen Min", "background": "近年来，基于文本生成3D模型的技术显示出巨大的潜力，但复杂的自然物体几何形状使得3D内容的生成仍然是一个具有挑战性的任务。目前的方法要么依赖于2D扩散先验来恢复3D几何形状，要么直接基于特定的3D表示训练模型。", "innovation": "本文提出了一种名为DirectGaussian的新方法，专注于通过surfels表示的3D物体表面生成。DirectGaussian利用条件文本生成模型，并通过多视角的表面正常和纹理先验用2D高斯绘制渲染3D物体表面。为解决多视角几何一致性问题，在优化过程中整合了曲率约束。", "conclusion": "通过广泛的实验，我们证明了我们的框架能够实现多样且高质量的3D内容生成。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06969", "html_url": "https://arxiv.org/abs/2510.06969", "title": "从查询中学习全局表示用于向量化高清地图构建", "title_en": "Learning Global Representation from Queries for Vectorized HD Map Construction", "authors": "Shoumeng Qiu,Xinrun Li,Yang Long,Xiangyang Xue,Varun Ojha,Jian Pu", "background": "在线构建向量化高分辨率地图是现代自动驾驶系统的关键基础。目前最先进的方法，尤其是基于DETR框架的方法，将这一问题表述为实例检测问题。然而，这些方法依赖于独立的可学习对象查询，导致查询的视角主要局限于局部，忽略了高清地图中固有的全局表示能力。本研究旨在克服这一局限，提出MapGR（全局表示学习用于高清地图构建）架构，该架构可以从小查询中学习并利用全局表示。研究表明，通过地图全局代表学习（GRL）模块和全局代表引导（GRG）模块，可以有效地优化地图构建过程，从而显著提高了精度", "innovation": "提出了MapGR架构，以解决传统方法中的局部查询视角问题。MapGR通过引入全局表示学习（GRL）模块和全局表示引导（GRG）模块，鼓励所有查询分布更加符合全局地图的表示，使每个查询获得明确的全局上下文信息，从而优化查询的过程。实验结果表明，MapGR相比领先的基线方法，在nuScenes和Argoverse2数据集上显著提升了平均精度", "conclusion": "MapGR能够在查询层面学习和利用全局表示，显著提高了向量化高清地图的构建精度。实验结果验证了该方法的有效性，相比现有顶级基线方法，MapGR在平均精度上有显著提升"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06965", "html_url": "https://arxiv.org/abs/2510.06965", "title": "EDUMATH：生成符合标准的教育数学问题", "title_en": "EDUMATH: Generating Standards-aligned Educational Math Word Problems", "authors": "Bryan R. Christ,Penelope Molitz,Jonathan Kropko,Thomas Hartvigsen", "background": "数学填空题（MWPs）对于K-12教育至关重要。为学生量身定制这些填空题可以提高学习成果。然而，由于班级人数增多和教师工作效率降低（教师劳累），教师很难为每个学生定制合适的填空题。因此，论文提出利用大型语言模型（LLMs）生成定制化的填空题来支持数学教育，定制化能够根据学生兴趣和数学教育标准进行调整。通过与人类专家合作评估超过11,000个生成的填空题，构建了一个教师注释数据集。这个数据集被用于训练模型，显示了其价值。模型生成的填空题比现有模型生成的更接近人类编写的填空题。", "innovation": "本研究创新性地提出了利用LLMs生成定制化的教育数学填空题。通过与专家合作创建了一个大规模的教师注释数据集。利用该数据集训练了一个12B模型，使其在标准对齐的填空题生成上表现与更大、更强大的模型相当。还使用教师注释的数据训练了一个文本分类器，使30B的开源LLM在无需额外训练的情况下超过了现有的封闭基线。最终，模型生成的填空题在结构和内容上更类似于人类撰写的填空题。", "conclusion": "首次对基于LLM生成的定制化数学填空题进行了研究，并使用小学学生产生了实验结果，表明这些模型生成的填空题在学生成绩上与人类撰写的一致，但学生更偏好定制化的填空题。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06997", "html_url": "https://arxiv.org/abs/2510.06997", "title": "LLM驱动评估中目标设定理论的局限", "title_en": "The Limits of Goal-Setting Theory in LLM-Driven Assessment", "authors": "Mrityunjay Kumar", "background": "许多用户在使用像ChatGPT这样的AI工具时，倾向于将系统视为类似人类的存在，这种认知模型被称为Model H。根据目标设定理论，目标设定的细化可以减少表现的差异性。如果假设Model H成立，那么给出更多的详细指令应该会导致更为一致的评价结果。本文通过一个控制实验对ChatGPT进行测试，该实验让ChatGPT对29份学生提交的作品分别使用四个从详细到逐步具体的提示进行评估，并通过重复运行的内评者可靠性（科恩κ系数）来衡量一致性。", "innovation": "本研究所使用的控制实验方法，特别之处在于使用四种不同级别的具体性提示来评估同一批学生提交的作品，以探索目标设定理论在大型语言模型驱动评估中的适用性。", "conclusion": "出乎意料的是，随着提示具体性的增加，性能并未获得持续改进，性能的差异性也保持不变。这些发现挑战了大型语言模型在评估中类似人类评估者的假设，强调了未来模型开发中需要增强稳健性和改进输入集成的必要性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07019", "html_url": "https://arxiv.org/abs/2510.07019", "title": "Native Hybrid Attention for Efficient Sequence Modeling", "title_en": "Native Hybrid Attention for Efficient Sequence Modeling", "authors": "Jusen Du,Jiaxi Hu,Tao Zhang,Weigao Sun,Yu Cheng", "background": "变换器在序列建模方面表现出色，但存在二次复杂性的缺点；线性注意力虽然提供了更高的效率，但在长上下文的检索精度上常会有所妥协。", "innovation": "提出了名为NHA的新颖混合架构，综合了线性与全注意力机制，通过线性RNN更新关键值槽并结合滑动窗口的短时令牌。简化了注意力操作，使用单一的‘softmax注意力’操作整合所有关键值，且通过滑动窗口大小单一超参数控制跨层行为，实现从纯线性到全注意力的平滑过渡。", "conclusion": "实验结果表明，NHA在保持高效的同时，优于变换器和其他混合基线在涉及召回密集和常识推理的任务中；预训练的大语言模型还可以与NHA结合使用，在保持竞争力的同时实现显著的效率提升。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07022", "html_url": "https://arxiv.org/abs/2510.07022", "title": "野外面向联邦卸载：重新思考公平性和数据异质性", "title_en": "Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy", "authors": "ZiHeng Huang,Di Wu,Jun Bai,Jiale Zhang,Sicong Cao,Ji Zhang,Yingjie Hu", "background": "联邦卸载（FU）对于执行数据删除权至关重要，尤其在实现“被遗忘权”方面。然而，联邦学习（FL）的卸载过程中存在着两大挑战：一是关于公平性的考虑不足，即精确卸载方法往往要求所有客户端重新训练，即使是未参与卸载的客户端也会受到惩罚；二是现有的_fu_评估依赖于合成数据假设（包括独立同分布和不同分布的数据），这种假设忽略了现实世界中的数据异质性，从而隐藏了卸载的真实影响，并限制了当前方法的实际应用。", "innovation": "该研究首次对现有FU方法在现实数据异质性和公平性条件下的基准进行全面评估，并提出了一个公平性知晓的FU方法，即联邦跨客户端约束卸载（FedCCCU），该方法明确解决了上述两方面挑战。FedCCCU提供了一种适用于实际联邦卸载的实用且可扩展的解决方案。", "conclusion": "实验结果表明，在现实场景中，现存方法表现较差，而该研究提出的方法在所有情况下都表现更佳。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06975", "html_url": "https://arxiv.org/abs/2510.06975", "title": "VelLMes：基于高交互性的AI欺骗框架", "title_en": "VelLMes: A high-interaction AI-based deception framework", "authors": "Muris Sladić(1),Veronica Valeros(1),Carlos Catania(2),Sebastian Garcia(1) ((1) Czech Technical University in Prague, (2) CONICET, UNCuyo)", "background": "当前基于大语言模型（LLM）的先进欺骗系统非常稀缺，现有系统只能模拟一种服务，主要是SSH终端。这些系统以及非基于LLM的欺骗技术缺乏对人类攻击者的全面评估。近年来，生成AI已成为网络安全研究人员和实践中宝贵工具，尤其是欺骗领域。研究人员证明了如何使用LLM生成逼真的蜜罐、虚假用户和模拟系统。然而，现有研究多局限在单一服务的模拟上。", "innovation": "提出了一个名为VelLMes的基于AI的欺骗框架，能够模拟多种协议和服务，如SSH Linux终端、MySQL、POP3和HTTP。该框架旨在被真人攻击，强调互动性和真实性。经过单元测试，部分LLM的生成能力达到了100%的真实度。在对89名人类攻击者进行的SSH Linux终端蜜罐测试中，有30%的攻击者误以为是在与真实系统交互。研究还展示了在互联网上部署LLM蜜罐捕获真实攻击的能力，验证了LLM的欺骗实用性和应对未预期攻击的能力。", "conclusion": "VelLMes能够提供多样化的欺骗设计选择，满足用户需求。其主要特点在于能够模拟多种服务，具备强大的生成能力和欺骗能力，特别擅长应对尚未预见的网络攻击。该部署在互联网上的虚拟蜜罐取得了很好的效果，证明了LLM在欺骗系统中的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07000", "html_url": "https://arxiv.org/abs/2510.07000", "title": "Pragyaan: 设计和收集高质量文化后训练数据集以支持印度语言", "title_en": "Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages", "authors": "Neel Prabhanjan Rachamalla,Aravind Konakalla,Gautam Rajeev,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal", "background": "大型语言模型（LLMs）的有效性很大程度上依赖于高质量后训练数据的可用性，特别是指令调优和偏好示例。现有的开源数据集往往缺少多语言覆盖、文化根基以及任务多样性，尤其是在印度语言方面尤为明显。", "innovation": "本文介绍了一个结合翻译和合成扩展的人工智能参与管道，以生成可靠且多样的印度后训练数据。通过此管道，我们编纂了两个数据集：Pragyaan-IT（22,500）和Pragyaan-Align（100,000），覆盖了10种印度语言和13个广泛的以及56个子类别，利用了57个多样化的数据集。数据集协议整合了几种常用的次要维度，强调任务多样性、多回合对话、指令忠实度、安全对齐以及文化细微差别的保留，为更包容和有效的多语言LLMs提供了基础。", "conclusion": "通过这个管道和数据协议，研究者成功创建了多个有益的数据集，旨在提升印度语言的后训练数据质量，促进包括印度语言在内的多语言大型语言模型的有效性和包容性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07048", "html_url": "https://arxiv.org/abs/2510.07048", "title": "Search-R3: 统一大型语言模型中的推理和嵌入生成", "title_en": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models", "authors": "Yuntao Gui,James Cheng", "background": "尽管大型语言模型在自然语言理解方面表现出色，但它们在检索任务中的应用尚未得到充分开发。Search-R3 是一种创新框架，通过将大型语言模型适应以直接生成搜索嵌入，解决了这一局限性。该框架利用了大型语言模型的逐步推理能力，允许它们通过复杂的语义分析逐步生成更有效的嵌入。", "innovation": "Search-R3 通过三个互补机制实现：（1）监督学习阶段以提高模型生成高质量嵌入的能力；（2）结合推理优化嵌入生成的强化学习方法；（3）处理嵌入表示演化的专门强化学习环境，无需在每次训练迭代时重新编码整个语料库。广泛的基准测试表明，Search-R3 显著优于先前的方法，通过将推理与嵌入生成流程统一起来。这种方法代表了处理需要复杂推理和有效信息检索的密集知识任务的实质性进展。", "conclusion": "Search-R3 通过集成后训练方法，统一了推理和嵌入生成过程，显著提高了处理复杂知识密集型任务的能力。这一创新框架在大型语言模型的应用中具有重要的进步意义，能够更好地满足检索需求。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07035", "html_url": "https://arxiv.org/abs/2510.07035", "title": "使用灵活2D和3D模态的统一分子预训练：单模态和配对模态集成", "title_en": "Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration", "authors": "Tengwei Song,Min Wu,Yuan Fang", "background": "分子表示学习在药物发现和材料设计等应用中发挥着关键作用。现有的工作利用分子的2D和3D模态信息进行预训练，以捕捉全面的结构和几何洞察。然而，这些方法需要配对的2D和3D分子数据来训练模型，防止其单模态退化，这在某些模态不可用或生成成本高昂的场景中构成了限制。", "innovation": "我们提出了FlexMol，一种灵活的分子预训练框架，同时学习统一的分子表示并支持单模态输入。该方法借鉴了视觉语言模型中的统一结构，采用了分别对2D和3D分子数据的模型，并通过参数共享提高计算效率，利用解码器生成缺失模态的特征。这使得在训练过程中两种模态能够协同贡献，同时在仅有一模态可用的推理时保持鲁棒性。", "conclusion": "广泛的实验表明，FlexMol 在一系列分子性质预测任务中取得了优越的性能，并且我们还通过不完整数据的实证结果证明了其有效性。我们的代码和数据可在该链接获取。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07053", "html_url": "https://arxiv.org/abs/2510.07053", "title": "学习的语义场景图定位中的内省", "title_en": "Introspection in Learned Semantic Scene Graph Localisation", "authors": "Manshika Charvi Bissessur,Efimia Panagiotaki,Daniele De Martini", "background": "该研究探讨了语义如何影响在一种学习自监督对比语义定位框架中的局部化性能和稳健性。通过在一个同时包含原始和扰动地图训练的定位网络上进行训练，研究者进行了详尽的后验内省分析，以探究模型是否能够过滤环境噪声，优先考虑独特的地标而非常见的杂乱对象。研究验证了多种可解释性方法，并进行了一项比较可靠性分析。", "innovation": "研究发现，具有解释性的方法（如集成梯度和注意力权重）是最可靠的模型行为探针，揭示了模型中一种隐含的加权方式，其中频繁出现的对象往往被折扣。研究整体表明，模型学习了关于位置定义的去噪且语义显著的关系，从而使在视觉和结构变异复杂的条件下也能实现可解释的登记成为可能。", "conclusion": "研究结果表明，该模型能够学习噪声稳健且语义显著的空间关系，从而使在复杂视觉和结构变异下的解释性注册成为可能。这一研究通过引入后验内省分析和多种可解释性方法的验证，进一步丰富了语义定位领域的理解。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07084", "html_url": "https://arxiv.org/abs/2510.07084", "title": "HTMformer: 混合时间和多变量Transformer在时间序列预测中的应用", "title_en": "HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting", "authors": "Tan Wang,Yun Wei Dong,Tao Zhang,Qi Wang", "background": "基于Transformer的方法在时间序列预测中取得了显著成果，但现有Transformer在序列建模上仍存在不足，倾向于过度强调时间依赖性，导致额外的计算开销而无相应的性能提升。", "innovation": "提出了一种混合时序和多变量嵌入(HTME)提取器，将轻量级的时序特征提取模块与精心设计的多变量特征提取模块结合，提供互补特征，实现模型复杂性和性能之间的平衡。通过将HTME与Transformer架构结合，提出了HTMformer，利用HTME增强的特征提取能力构建了一个轻量级的预测器。", "conclusion": "在八个实际数据集上的实验表明，与现有基准模型相比，我们的方法在准确性和效率方面表现更为出色。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07024", "html_url": "https://arxiv.org/abs/2510.07024", "title": "挖掘心智：1亿信念揭示前沿LLM知识", "title_en": "Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge", "authors": "Shrestha Ghosh,Luca Giordano,Yujia Hu,Tuan-Phong Nguyen,Simon Razniewski", "background": "大语言模型(LLMs)在自然语言处理(NLP)和人工智能( AI)任务中产生了革命性的影响。这些模型包含的大量事实性知识是它们能够出色完成任务的关键，然而这些知识的基础和准确度迄今仍然不明确，并且通常是从有偏见的样本中进行分析的。", "innovation": "本文通过分析GPTKB v1.5，一个包含了一款最先进LLM（GPT-4.1）1亿信念的递归提取知识库，深入探讨了前沿LLM的事实性知识或信念。研究结果揭示了这些模型的事实性知识与现有知识库的显著差异，其准确性也远远低于之前的评估。研究还揭示了不一致性、模糊性和幻觉是主要问题，为未来关于事实性LLM知识的研究指明了方向。", "conclusion": "研究发现，前沿LLM在事实性知识上的表现与现有知识库有着明显的差异，其准确性低于预期，并且存在大量的不一致性、模糊性和幻觉问题，这些都为未来的研究提供了新的机会。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07092", "html_url": "https://arxiv.org/abs/2510.07092", "title": "生成性世界建模 humanoid: 1X 世界模型挑战技术报告", "title_en": "Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report", "authors": "Riccardo Mereu,Aidan Scannell,Yuxin Hou,Yi Zhao,Aditya Jitta,Antonio Dominguez,Luigi Acerbi,Amos Storkey,Paul Chang", "background": "世界模型是人工智能和机器人学中的一种强大范式，允许代理通过预测视觉观测或紧凑的潜在状态来推断未来。1X 世界模型挑战提供了一个开源的真实人类交互基准，有两个互补的赛道：采样，专注于预测未来图像帧；压缩，专注于预测未来的离散潜在代码。", "innovation": "提出了将视频生成基础模型 Wan-2.2 TI2V-5B 调整为视频状态条件下的未来帧预测。使用 AdaLN-Zero 对视频生成进行条件化，并进一步使用 LoRA 训练模型。同时，通过从零开始训练时空Transformer模型实现了压缩任务的最佳结果。", "conclusion": "在采样任务中，模型实现了 23.0 dB PSNR 的表现，在压缩任务中取得了 Top-500 CE 6.6386 的成绩，从而双双在两个挑战中获得第一名。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07077", "html_url": "https://arxiv.org/abs/2510.07077", "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "title_en": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "authors": "Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu", "background": "随着利用大规模语言模型（LLMs）和视觉-语言模型（VLMs）增强机器人技术的努力不断增长，视觉-语言-行动（VLA）模型最近获得了显著关注。VLA模型试图通过统一大规模的数据来学习跨各种任务、物体、实体和环境的通用策略，这些数据曾被分别研究。这种通用性能力预期能够使机器人解决新的下游任务，而无需额外的任务特定数据，从而实现更灵活和可扩展的实际部署。以往的综述通常集中在行动表示或高层模型架构上，而本工作提供了一个全面、涵盖软件和硬件组件的VLA系统综述。", "innovation": "本研究提供了一个系统性综合审查VLA模型，涵盖了其策略和架构转换，构造块，特定模态的处理技术和学习范式。此外，针对VLA在实际机器人应用中的部署，还审查了常用机器人平台、数据收集策略、公共数据集、数据增强方法和评估基准。", "conclusion": "本文旨在为机器人社区提供在实际机器人系统中应用VLA的实用指导。全部参考文献按训练方法、评估方法、模态和数据集分类，在项目网站上提供了表格：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07074", "html_url": "https://arxiv.org/abs/2510.07074", "title": "LuxInstruct: 一种跨语言指令调优数据集", "title_en": "LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish", "authors": "Fred Philippy,Laura Bernardy,Siwen Guo,Jacques Klein,Tegawendé F. Bissyandé", "background": "指令调优已成为增强大型语言模型性能的关键技术，使它们能更好地遵循人类指令。然而，低资源语言如卢森堡语因缺乏高质量的指令数据集而受到严重限制。传统上依赖机器翻译往往会引入语义错位和文化不准确性。本文通过为卢森堡语创建一个无需依赖机器翻译的跨语言指令调优数据集来应对这些挑战。利用与英语、法语和德语的对齐数据，构建了一个高质量的数据集，保留了语言和文化的细微差别。研究表明，跨语言指令调优不仅改善了不同语言之间的表达一致性，还提高了卢森堡语生成能力。这强调了跨语言数据整理可以避免机器翻译数据常见问题的重要性，并直接促进低资源语言的发展。", "innovation": "本文通过利用与英语、法语和德语的对齐数据来构建卢森堡语的高质量跨语言指令调优数据集，避免了依赖机器翻译可能带来的语义和文化不准确性。这为低资源语言的发展提供了新的数据支持。", "conclusion": "跨语言指令调优不仅能改善不同语言间的表达一致性，还能提升卢森堡语生成能力，证明了跨语言数据整理在避免机器翻译常见问题方面的优势，直接推动了低资源语言的发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07129", "html_url": "https://arxiv.org/abs/2510.07129", "title": "图条件扩散模型在可控病理图像生成中的应用", "title_en": "Graph Conditioned Diffusion for Controllable Histopathology Image Generation", "authors": "Sarah Cechnicka,Matthew Baugh,Weitong Zhang,Mischa Dombrowski,Zhe Li,Johannes C. Paetzold,Candice Roufosse,Bernhard Kainz", "background": "近期，扩散概率模型（DPMs）在高质量图像生成方面取得了突破，但在控制生成方面仍然具有挑战性，尤其是在医疗成像等敏感领域。医疗图像具有特定结构，如一致的空间布局、形状或纹理，这些都对诊断至关重要。然而，现有的DPMs在运行时缺乏语义结构和先验知识，在噪音较大的潜在空间中运作，使得难以实现生成内容的有意义控制。因此，本文从这一点出发，探讨了解决方案并提出了图条件扩散模型，旨在解决现有DPMs中的问题，以确保生成内容的控制更加精细.", "innovation": "本文提出了一种基于图的对象级表示方法——图条件扩散。该方法生成与图像中每个主要结构对应的图节点，捕捉其个体特性和关系，通过transformer模块进行处理，并利用文本条件机制集成到扩散模型中，以实现细腻的生成控制。通过在真实世界病理学使用案例中的评估，证明了利用此方法生成的数据可以可靠地替代标注的病患数据，在后续分割任务中表现出色。这为医疗成像和病理学研究提供了新的方法和工具.", "conclusion": "本文通过引入图条件扩散模型，在医疗成像的病理性图像生成方面取得显著进步，并有效提升了生成图像的可控性和质量。研究结果表明，该方法能够可靠地替代标注数据，并在后续分割任务中表现出优良效果。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07134", "html_url": "https://arxiv.org/abs/2510.07134", "title": "TrackVLA++: 在VLA模型中释放视觉推理和记忆能力以实现嵌入式视觉跟踪", "title_en": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking", "authors": "Jiahang Liu,Yunpeng Qi,Jiazhao Zhang,Minghan Li,Shaoan Wang,Kui Wu,Hanjing Ye,Hong Zhang,Zhibo Chen,Fangwei Zhong,Zhizheng Zhang,He Wang", "background": "嵌入式视觉跟踪（EVT）是一种基础能力，对于诸如伴侣机器人、引导机器人和智能助手等实际应用至关重要。近年来，已有研究使得语言指导的跟踪在复杂和非结构化的场景中成为可能。然而，现有的方法缺乏明确的空间推理和有效的时序记忆，导致在严重遮挡或存在相似干扰目标的情况下出现问题。", "innovation": "本文提出了一种新颖的视觉-语言-行动（VLA）模型——TrackVLA++，通过加入空间推理机制和目标识别记忆（TIM）模块，显著提升了嵌入式视觉跟踪能力。其中，推理模块通过引入Polar-CoT（极坐标思考链）来推断目标的相对位置，并将其编码为用于行动预测的紧凑极坐标标记。TIM模块以门控更新策略维护长期目标记忆，以确保时空一致性并减少长期遮挡导致的目标丢失。实验结果表明，TrackVLA++在公开基准测试中表现出最先进的性能，在EVT-Bench DT拆分中分别超越前一种领先方法5.1和12。此外，TrackVLA++展示了较强的零样本泛化能力，能够在动态和遮挡的情况下实现稳健的现实世界跟踪。", "conclusion": "TrackVLA++通过引入空间推理机制和目标识别记忆模块，显著提升了视觉-语言-行动模型在嵌入式视觉跟踪中的性能，特别是在处理长期遮挡和相似干扰目标方面表现出色，能够实现在动态和遮挡情况下的稳健跟踪。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07133", "html_url": "https://arxiv.org/abs/2510.07133", "title": "使用生成模型的自主驾驶系统元形测试的数字孪生框架", "title_en": "A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model", "authors": "Tony Zhang,Burak Kantarci,Umair Siddique", "background": "确保自动驾驶汽车的安全依然是一个重大挑战，因现实驾驶环境的复杂性和不可预测性。传统测试方法面临显著的局限性，如奥卡姆剃刀问题，这使得很难判断系统的行为是否正确，以及不能覆盖自动驾驶车辆可能遇到的所有场景。", "innovation": "我们提出了一个由数字孪生驱动的元形测试框架，通过创建自动驾驶系统及其操作环境的虚拟复制品来解决这些挑战。结合数字孪生技术与基于AI的图像生成模型（如Stable Diffusion），我们的方法能够系统地生成真实且多样的驾驶场景，包括天气、道路拓扑和环境特征的变化，同时保持原始场景的核心语义。数字孪生提供了一个同步模拟环境，在这个环境中可以进行受控和可重复的测试变化。这一环境定义了三种受现实交通规则和车辆行为启发的元形关系。我们在Udacity的自动驾驶模拟器中验证了我们的框架，表明它显著提高了测试覆盖率和有效性。与基线方法相比，我们的方法达到了最高的真正阳性率（0.719）、F1分数（0.689）和精确度（0.662）。", "conclusion": "本论文强调了将数字孪生与AI驱动的场景生成相结合，以创建具有可扩展性、自动化和高度真实性的自动驾驶安全测试解决方案的价值。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07105", "html_url": "https://arxiv.org/abs/2510.07105", "title": "Opt-ICL在LeWiDi-2025中的应用：通过元学习最大化评价者示例的上下文信号", "title_en": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning", "authors": "Taylor Sorensen,Yejin Choi", "background": "许多自然语言处理（NLP）任务包含主观性、歧义性或注释者之间合理的分歧。在这些情况下，需要模型能够应对人类语言的多样性，即注释者之间的个体差异。该论文介绍了一种系统来建模人类的变异性，该系统利用语言模型的即席学习能力，并采用两步元学习训练程序：首先在多种需要即席学习的数据集上进行训练，然后通过即席元学习对该模型进行特定数据分布的专业化调整。此外，还评估了系统在Learning With Disagreements (LeWiDi) 竞赛中的表现，该系统在两个任务中均获得了第一名，同时进行了消融研究来衡量每个系统组件的重要性。研究表明，在上下文中包括评估者示例是该系统表现的关键因素，特定数据集的微调对较大的数据集有一定帮助，其他即席数据集的训练对一个竞赛数据集有帮助，且模型规模越大效果越好。", "innovation": "该系统创新性地利用即席学习和元学习，通过先在多种需要即席学习的数据集上进行训练，再通过即席元学习对特定数据分布进行调整。此外，研究表明，在上下文中包含评估者示例对于模型性能至关重要，特定数据集的微调和即席数据集的训练也有助于提高模型表现。系统在LeWiDi竞赛中表现出色，并且通过消融研究明确了系统各个组件的重要性。", "conclusion": "通过在多种即席学习数据集上进行训练和通过元学习对模型进行特定数据分布的专业化调整，该系统能够有效地处理人类语言的复杂性。实验结果表明，包括评估者示例在内，模型规模和特定数据集的微调对系统性能有显著影响。该系统在LeWiDi竞赛中表现优异，证明了其有效性。未来的研究可以探索更多针对性的数据集微调方法以及如何优化模型以进一步提高其性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07141", "html_url": "https://arxiv.org/abs/2510.07141", "title": "人类与语言模型在处理复杂结构时的句子处理难题对比", "title_en": "Comparing human and language models sentence processing difficulties on complex structures", "authors": "Samuel Joseph Amouyal,Aya Meltzer-Asscher,Jonathan Berant", "background": "大语言模型（LLMs）能够流利地与人类对话已经成为现实，但它们是否在处理句子时会遇到类似于人类的处理难题？该研究旨在系统地对比人类和多种最先进的LLMs在七种具有挑战性的语言结构上的句子理解能力，通过统一的实验框架收集了语句理解数据，结果显示LLMs 在目标结构上整体上存在困难，尤其是在歧义句子（Garden Path，简称GP）上表现较差。", "innovation": "研究采用了统一的实验框架，对比了人类和不同大小及训练程序的五大家族最先进的LLMs在七种复杂语言结构上的句子理解能力。发现最强大的模型在这七种结构中的表现参差不齐，特别是在GP结构上表现较为脆弱。同时，根据性能平均表现排名人类和模型的相关性随着参数数量的增加而提高，并收集了没有困难结构的基准数据进行对比，揭示了人类与LLMs在句子理解上的趋同与差异，为理解人类和LLMs的相似性提供新见解。", "conclusion": "研究揭示了人类与LLMs在句子理解和处理复杂结构方面的趋同与差异，发现尽管最强大的模型在非GP结构上的表现接近完美，但在GP结构上却表现较差。同时，无论是太弱还是太强的模型在两种句子类型上的表现都趋于一致，强调了理解和改进LLMs处理复杂语言结构的能力对于提升其真实应用中的性能至关重要。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07210", "html_url": "https://arxiv.org/abs/2510.07210", "title": "HyPlan: 在不确定性下的混合学习辅助规划以实现安全自主驾驶", "title_en": "HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving", "authors": "Donald Pfaffmann,Matthias Klusch,Marcel Steinmetz", "background": "研究背景在于解决自驾车在部分可观测交通环境中的无障碍导航问题。当前方法存在的挑战包括如何在保证安全性的同时提高规划效率，尤其是在包含行人的复杂交通场景中。现有的一些在线部分可观测马尔可夫决策过程(POMDP)规划器执行速度较慢，需要改进以适应更高效的实时决策需求。", "innovation": "HyPlan 方法结合了多智能体行为预测、深度强化学习 (使用近端策略优化) 以及近似在线 POMDP 规划和基于启发式置信垂直剪枝技术。这些技术的结合旨在减少执行时间，同时保持驾驶安全性。该方法在 CARLA-CTS2 验证基准测试中进行了实验性能分析，在关键交通场景中显示出导航性能优于选定的相关基线，并且执行速度明显快于考虑的其他在线 POMDP 规划器。", "conclusion": "研究表明，HyPlan 方法在行人参与的复杂交通情景中表现出了更高的安全性，并且执行速度远超现有方法，证明了其在实际应用中的潜力和有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07147", "html_url": "https://arxiv.org/abs/2510.07147", "title": "基于多代理的有状态推理时搜索框架", "title_en": "A Multi-Agent Framework for Stateful Inference-Time Search", "authors": "Arshika Lalan,Rajat Ghosh,Aditya Kolsur,Debojyoti Dutta", "background": "近期工作探索了代理推理时的结构化多步推理技术。然而，无状态推理在多步任务上常常存在问题，因为缺乏持久状态。此外，特定任务的微调或指令调整通常只能实现表面级的代码生成，但在需要深层推理和远期依赖的任务上则表现脆弱。为解决这些限制，本文提出了一种无训练框架——有状态多代理进化搜索，这种方法通过结合持久推理时状态、对抗性突变和进化保存，摒弃了先前的无状态方法。", "innovation": "本文提出了一种有状态多代理进化搜索框架，它在多个方面进行了创新：（一）采用了持久性的推理时状态，（二）利用了对抗性突变，（三）强化了进化的保存。该框架被用来自动化单元测试生成，通过生成边缘案例展示了其有效性。实验表明，在评估广泛使用的单元测试基准时（如HumanEval和TestGenEvalMini），该有状态多代理推理框架在覆盖范围上显著优于单步骤的无状态基线，且使用了三个不同的LLM家族（Llama、Gemma和GPT）", "conclusion": "有状态多代理进化搜索框架能够发现跨未知代码库的稳健、高覆盖率边缘案例，结合持久推理时状态与进化搜索显著提高了单元测试生成的效果。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07151", "html_url": "https://arxiv.org/abs/2510.07151", "title": "ELMUR：通过更新/重写外部层记忆实现长时 horizon RL", "title_en": "ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL", "authors": "Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov", "background": "现实世界中的机器人在部分可观测性和长时 horizon 的情况下需要做出决策，其中关键线索可能会在影响决策之前就出现。然而，大多数现代方法仅依赖于即时信息，忽视了过去的洞察。现有的标准循环或变压器模型难以保留和利用长期依赖关系：上下文窗口会截断历史，而简单的记忆扩展在大规模和稀疏数据下会失效。", "innovation": "我们提出了ELMUR（External Layer Memory with Update/Rewrite），这是一种具有结构化外部记忆的变压器架构。每个层维护记忆嵌入，通过双向的交叉注意力与它们交互，并通过LRU记忆模块使用替换或凸融合来进行更新。ELMUR将有效的 horizons 扩展了100,000倍以上，超过了注意力窗口。在合成的T-Maze任务中，ELMUR实现了100%的成功率，任务长度可达100万步。在POPGym中，它在超过一半的任务中超越了基础模型。在MIKASA-Robo稀疏奖励操纵任务中，视觉观察，它几乎将强基础模型的性能翻了一番。这些结果表明，结构化的、分层局部的外部记忆为部分可观测性条件下的决策制定提供了一种简单且可扩展的方法。", "conclusion": "这些结果表明，结构化的、分层局部的外部记忆为部分可观测性条件下的决策制定提供了一种简单且可扩展的方法。ELMUR能够有效处理长期依赖关系，从而在多个任务中表现出色。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07213", "html_url": "https://arxiv.org/abs/2510.07213", "title": "语言存在于稀疏维度中：通向大模型解释性和高效多语言控制", "title_en": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models", "authors": "Chengzhi Zhong,Fei Cheng,Qianying Liu,Yugo Murawaki,Chenhui Chu,Sadao Kurohashi", "background": "研究表明，大型语言模型尽管接触非英语数据有限，但仍然具有强大的多语言能力。以前的研究发现，这些模型在中间层将多语言内容映射为英语对齐的表示，并在最终层将其投影回目标语言的标记空间。基于这一观察，本文提出了一个假设：这种跨语言过渡由一小部分稀疏维度控制，这些维度在中间层到最终层之间具有固定的索引位置。", "innovation": "文章引入了一种训练无需的简单方法来识别并操纵这些维度，仅需少量（最多50句）平行语料或单一语言语料即可。在多语言生成控制任务中的实验揭示了这些维度的可解释性，证明了在这些维度上的干预可以切换输出语言同时保持语义内容，并且在较低成本的情况下超越了先前基于神经元的方法。", "conclusion": "研究表明，多语言控制可以通过操纵少量的稀疏维度来实现。这种方法不仅可以解释这些维度的作用方式，还可以以较低的成本实现多语言切换。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07227", "html_url": "https://arxiv.org/abs/2510.07227", "title": "从小开始：通过子网络选择和蒸馏实现高效的预训练", "title_en": "Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation", "authors": "Arjun Krishnakumar,Rhea Sanjay Sukthanker,Hannan Javed Mahadik,Gabriela Kadlecová,Vladyslav Moroshan,Timur Carstensen,Frank Hutter,Aaron Klein", "background": "小型语言模型（SLMs）作为一种更为高效和易获取的替代方案，相比大型语言模型（LLMs）使用更少的资源却能实现相当甚至更强的性能。本文提出了一种简单且有效的构建SLM的预训练框架，该框架结合了三个互补的思想：结构稀疏子网络初始化、进化搜索以及知识蒸馏。", "innovation": "1. 结构稀疏子网络初始化：发现了一类在相同计算预算下始终优于随机初始化模型的结构稀疏子网络初始化方法，初始化时更有效。\n2. 进化搜索：自动发现高质量的子网络初始化，从而获得更好的预训练起始点。\n3. 知识蒸馏：采用更大模型的知识蒸馏来加速训练并提升泛化能力。\n这些组件共同使SLM预训练变得更加高效：通过进化搜索发现的最佳模型，虽然需要9.2倍少的预训练样本，却能在验证困惑度上达到与同类Pythia SLM相当的水平。", "conclusion": "本研究提出的方法大大提高了SLM预训练的效率，出版了全部代码和模型，提供了一条经济高效的SLM大规模开发实践路径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07217", "html_url": "https://arxiv.org/abs/2510.07217", "title": "GenPilot：图像生成中的测试时提示优化的多代理系统", "title_en": "GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation", "authors": "Wen Ye,Zhaocheng Liu,Yuwei Gui,Tingyu Yuan,Yunyue Su,Bowen Fang,Chaoyang Zhao,Qiang Liu,Liang Wang", "background": "文本到图像合成取得了显著进步，但准确解读复杂且冗长的提示仍然具有挑战性，常导致语义不一致和细节缺失。现有解决方案如微调需要特定于模型且必须经过训练，而之前的自动化提示优化（APO）方法大多缺乏系统性的错误分析和改进策略，导致其可靠性与有效性有限。同时，测试时缩放方法仅针对固定提示或噪声或样本数量进行操作，限制了其可解释性和灵活性。", "innovation": "本文 introduced 一个灵活且高效的测试时提示优化策略，可以直接作用于输入文本。我们提出了一种插拔式多代理系统 GenPilot，该系统集成了错误分析、基于聚类的自适应探索、细粒度验证和记忆模块等迭代优化功能。此外，我们总结了常见的错误模式和改进策略，提供了更多的经验并鼓励进一步探索。实验结果表明，我们的方法在增强生成图像的文本和图像一致性以及结构连贯性方面具有强大的能力，证明了测试时提示优化策略的有效性。", "conclusion": "我们的方法是模型无关的、可解释的，并且适用于处理长且复杂的提示。在 DPG-bench 和 Geneval 上，我们的方法分别提高了 16.9% 和 5.7%，显著提升了生成图像的文本和结构一致性。我们提供了一种测试时提示优化的有效策略，通过误差分析、自适应探索和迭代验证，提高了解码器生成图像的语义一致性和细节准确性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07243", "html_url": "https://arxiv.org/abs/2510.07243", "title": "LeMAJ (合法大语言模型评判者): 连接法律推理与大语言模型评估", "title_en": "LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation", "authors": "Joseph Enguehard,Morgane Van Ermengem,Kate Atkinson,Sujeong Cha,Arijit Ghosh Chowdhury,Prashanth Kallur Ramaswamy,Jeremy Roghair,Hannah R Marlowe,Carina Suzana Negreanu,Kitty Boxall,Diana Mincu", "background": "在法律领域评估大型语言模型（LLM）输出具有独特挑战，因为法律分析复杂且精细。当前，评估方法依赖参考数据（成本高）或标准化评估方法（限制了实际应用）。虽然‘法律评判者LLM’作为一种有希望的评估技术已经出现，但其在法律背景下的可靠性和有效性仍然依赖于专门的法律行业评价过程，以及专家对其评价可信度的认可。现有的评估方法失效且表现出显著的不一致性。因此，该领域仍存在评估缺口和改进空间。", "innovation": "本文提出了一种名为LeMAJ的创新方法，包含细节如下：a) 提出了将长回答分解为‘法律数据点’（LDPs）的方法，这是一种自包含信息单元，并引入了一种无需参考数据的新型评估方法；b) 该方法在我们自有的数据集和开源数据集（LegalBench）上均优于多种基准；c) 证明了该方法与人类专家评估结果的一致性较高，并有助于提高不同标注者之间的协议度；d) 开放了用于实验的LegalBench数据集一部分，供研究社区复现研究结果，促进该领域进一步研究。", "conclusion": "本文通过详细研究，提出了一种创新的LE MAJ（合法LLM评判者）方法，解决法律领域对LLM评估的独特挑战。这种方法不仅在实际数据集上表现出优越性，还与人类专家评估高度一致，增强了评估结果的可信度，并提供了可供研究社区广泛使用的数据集，促进了该领域的进一步探索与发展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07285", "html_url": "https://arxiv.org/abs/2510.07285", "title": "GTCN-G：不平衡入侵检测的一种残差图时序融合网络 (预印本)", "title_en": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)", "authors": "Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Qi Hu,Yan Li,Chang Liu", "background": "网络威胁的复杂性日益增加，以及网络流量数据中存在的固有类别不平衡，构成了现代入侵检测系统(IDS)面临的严峻挑战。虽然图神经网络(GNNs)擅长建模拓扑结构，而时序卷积网络(TCNs)能有效地捕捉时间序列依赖关系，但如何同时利用两者并通过数据不平衡问题达到最佳效果仍然是一个开放问题。", "innovation": "本文提出了一种名为Gated Temporal Convolutional Network and Graph (GTCN-G)的新型深度学习框架，该框架通过集成图卷积网络(GCN)和门控时序卷积网络(G-TCN)，并采用图注意力网络(GAT)实现残差学习机制，有效解决了数据不平衡问题，提升了稀有恶意活动的检测灵敏度。", "conclusion": "在UNSW-NB15和ToN-IoT两个公共基准数据集上进行了广泛的实验验证，实验结果表明，提出的GTCN-G模型在二分类和多分类任务中均达到了最先进的性能，显著优于现有基线模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07286", "html_url": "https://arxiv.org/abs/2510.07286", "title": "蛋白质进化特征用于蛋白质适应性预测", "title_en": "Evolutionary Profiles for Protein Fitness Prediction", "authors": "Jigang Fan,Xiaoran Jiao,Shengdong Lin,Zhanming Liang,Weian Mao,Chenchen Jing,Hao Chen,Chunhua Shen", "background": "预测突变的适应性变化是蛋白质工程的关键，但受限于可用算力及评估突变的有限实验数量低于序列空间的规模。尽管可以通过突变位点的语言模型（pLM）实现零样本适应性预测，但解读自然进化是一个隐式的奖励最大化过程，且pLM的对数几率（log-odds）可以视为适应性估计这一观点尚未得到统一的理解。", "innovation": "文中提出了EvoIF，这是一种结合了两项互补进化信号的轻量级模型：（i）从检索到的同源物中获得的族内分布特征；（ii）反向折叠对数势能中提取的跨族结构-进化约束。EvoIF通过压缩过渡模块将序列-结构表示与这些特征融合，从而提供校准后的log-odds评分概率。EvoIF及其基于多序列比对（MSA）的变体在使用仅0.15%的训练数据和比现有大模型更少参数的情况下，赢得了蛋白质Gym平台的顶尖或竞品性能。", "conclusion": "消融测试验证了族内和跨族特征的互补性，有助于多种功能类型、不同比对深度、不同分类群和突变深度下的实际性提升。该代码将通过此链接公开：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07293", "html_url": "https://arxiv.org/abs/2510.07293", "title": "AudioMarathon: 一个全面的长上下文音频理解和效率基准在音频LLMs中的应用", "title_en": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs", "authors": "Peize He,Zichen Wen,Yubo Wang,Yuxuan Wang,Xiaoqian Liu,Jiajie Huang,Zehui Lei,Zhuangcheng Gu,Xiangqi Jin,Jiabing Yang,Kai Li,Zhifei Liu,Weijia Li,Cunxiang Wang,Conghui He,Linfeng Zhang", "background": "大型音频语言模型处理长音频内容是一个重大挑战。现有模型因注意力机制的二次时间复杂度（$O(N^2)$）和长时序依赖性建模不足，在处理大规模音频时性能下降。目前的音频基准测试多基于短片段，未能全面评估模型在实际长上下文中的表现。", "innovation": "提出了AudioMarathon基准测试，旨在评估模型在长音频上理解能力和推理效率。该测试涵盖了90.0至300.0秒长的音频输入，涉及多种形式的音频数据，并要求多跳推理。研究了现有顶级模型在不同长度音频上的表现，探索了加速技术，即标记词元裁剪和KV缓存淘汰策略的适用性，揭示了现有模型在长时序推理和内存高效架构上的不足。", "conclusion": "AudioMarathon揭示了当前模型在长音频理解和推理上的差距，并强调了更先进音频理解模型的需求，以解决复杂的音频任务。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07231", "html_url": "https://arxiv.org/abs/2510.07231", "title": "使用科学验证关系基准评估大型语言模型因果推理", "title_en": "Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships", "authors": "Donggyu Lee,Sungwon Park,Yerin Hwang,Hyunwoo Oh,Hyoshin Kim,Jungwon Kim,Meeyoung Cha,Sangyoon Park,Jihee Kim", "background": "现有的大型语言模型（LLM）依赖于模式匹配来理解真实的因果关系。然而，现有的基准测试存在严重的限制，如依赖合成数据以及覆盖范围狭窄。研究发现需要一个更真实的、涵盖广泛领域的基准测试。因此，作者引入了一个新基准，该基准是从顶级经济学和金融期刊中提取出的因果关系，并采用严谨的方法论，如工具变量、双重差异法和回归断点设计。这个基准包括40,379个评估项目，涵盖了健康、环境、技术、法律和文化等多个领域，五个任务类型。在八个最先进的LLM上的实验结果显示，这些模型在真实因果推理中的表现存在显著漏洞，最好的模型也只能达到57.6%的准确率。研究还发现，模型规模并不总是转化为更好的表现，即使是高级的推理模型也难以识别基本的因果关系。这项发现揭示了当前LLM与高风险应用中可靠因果推理需求之间的关键差距。", "innovation": "该基准基于严格的方法论从顶级经济学和金融期刊中提取出因果关系，试验覆盖了广泛的健康、环境、技术、法律和文化等领域，设计了5种类型的任务，包括40,379个评估项目。还揭示了模型规模并不总是转化为更好的表现，即使是高级的推理模型也难以识别基本的因果关系。这些创新为评估LLMs在现实世界中的因果推理能力提供了新的视角和方法，填补了现有基准测试的不足，并为这一研究领域的发展做出了贡献。", "conclusion": "当前大型语言模型的因果推理能力存在显著漏洞，最强的模型也只能达到57.6%的准确率。模型规模并不总是转化为更好的表现，甚至先进的推理模型也难以识别基本的因果关系。这些发现揭示了现有LLM与高风险应用中所需的可靠因果推理能力之间的差距，提出了亟需突破的方向，未来的研究应关注进一步改进模型的因果推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07268", "html_url": "https://arxiv.org/abs/2510.07268", "title": "关于监管与创新之间的虚假选举。负责任使用人工智能在研究和教育中的监管想法", "title_en": "On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]", "authors": "Pompeu Casanovas(IIIA-CSIC)", "background": "本文是在2025年7月4日由Marta Garcia-Matos和Lissette Lemus组织的AIHUB（CSIC）和EduCaixa夏令营上由作者在辩论环节中提供的答案基础上进行重新整理而成的短文。Albert Sabater提出了三个关键问题：如何在保护个人权利（隐私、非歧视、自主权等）的同时优先考虑AI的发展，而不陷入监管与创新之间的假二分法？在存在AI风险（偏差、大规模监控、操纵）的情况下，有哪些监管或政策证明了可以在追求公共利益之前孕育负责任的创新，而不屈服于来自中国或美国这样的竞争压力？在美优先考虑灵活性的背景下，如何确保人工智能的国际协作不会导致权利方面的监管标准下降，而是成为全球问责机制的国际标准？这些问题推动了文章内容的发展，涉及监管与创新的共赢关系以及实现这一平衡的策略研究和教育的场景相关性", "innovation": "文章通过讨论如何在促进监管与创新之间找到平衡，提出了一套关于如何通过负责任利用人工智能促进研究和教育的监管建议。文章强调了在全球化的背景下，监管政策如何在维护个人权利的同时，支持创新和可持续发展", "conclusion": "文章最后总结了这些问题对教育和研究的关注意义，强调在全球化背景下，需要制定既能保护个人权利又能促进创新发展的国际标准。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07191", "html_url": "https://arxiv.org/abs/2510.07191", "title": "分辨率缩放决定了 DINOv3 在胸部X光分类中的迁移性能", "title_en": "Resolution scaling governs DINOv3 transfer performance in chest radiograph classification", "authors": "Soroosh Tayebi Arasteh,Mina Shaigan,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn", "background": "自监督学习（SSL）已经在视觉表征学习方面取得了进展，但在胸部X光成像方面的作用仍然不清楚。胸部X光成像是一种高体积成像模式，检测结果十分精细。Meta的DINOv3模型通过Gram-锚定自我蒸馏扩展了早期的SSL模型。然而，这些设计选择是否能够提高胸部X光的迁移学习效果尚未得到系统测试。这项研究通过七个数据集（样本量超过814,000）对比了DINOv3与DINOv2和ImageNet初始化的性能，评估了两种代表性的模型：ViT-B/16和ConvNeXt-B，考察了分辨率从224x224到1024x1024的影响，并还评估了7B模型冻结特征的效果。主要的评估指标是每个标签的平均AUROC。在224x224像素下，DINOv3和DINOv2在成人数据集上表现相当。提高分辨率到512x512时，DINOv3在所有情况下都比DINOv2和ImageNet初始化有所提升，但在儿科数据集上没有显著差异。所有条件下，ConvNeXt-B优于ViT-B/16。使用DINOv3-7B冻结特征的模型在性能上不如同完全微调的86-89M参数的模型，表明领域适应的重要性。扩大到1024x1024分辨率没有进一步提高准确性。分辨率相关的收益主要体现在边界依赖和小范围病灶的识别上。在胸部X光成像中，输入分辨率高才有利于现代自监督模型的优点发挥，512x512像素是一个实践的上限，在这个分辨率下，DINOv3初始化的ConvNeXt-B模型提供最强的性能，而更大的输入成本回报率较低。临床应用中，这些建议支持使用512x512、微调中等大小的模型进行胸部X光解释，特别是在识别细微或基于边界的病变方面更具优势，适合急诊和重症监护相关场景。", "innovation": "该研究系统性地测试了DINOv3和DINOv2以及ImageNet初始化的性能，并验证了在不同分辨率下这些模型的迁移学习效果。研究发现，随着分辨率的提升，DINOv3在所有情况下均表现更优，但在儿科数据集中却未显示出显著的优势。ConvNeXt-B优于ViT-B/16，使用DINOv3-7B冻结特征的模型在性能上不如同完全微调的模型。这些建议在临床应用中有重要的指导意义。", "conclusion": "在胸部X光分类中，分辨率对系统性能有决定性影响。512x512像素被视为一个实用的上限，此时DINOv3初始化的ConvNeXt-B模型性能最佳，而更大的输入则带来有限的成本效益。在临床实践中，使用微调后的中等大小模型（如512x512分辨率）进行胸部X光解释，能更好地识别细微或基于边界的病变，尤其适合急诊和重症监护情境。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07181", "html_url": "https://arxiv.org/abs/2510.07181", "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "title_en": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "authors": "Yi Han,Cheng Chi,Enshen Zhou,Shanyu Rong,Jingkun An,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang", "background": "视觉语言模型（VLMs）在空间推理方面展现了显著的能力，但依然存在局限性，主要体现在精确度较低和难以处理真实世界的机器人任务。当前的方法未能利用深度传感器和相机校准的度量线索，而是将几何问题简化为模式识别任务，这无法提供机器人操作所需的厘米级精度。", "innovation": "TIGeR（Tool-Integrated Geometric Reasoning）框架通过让视觉语言模型生成和执行精确的几何计算，转变了它们的角色，使其成为几何计算工具。TIGeR框架使模型能够识别几何推理需求，合成相应的计算代码，并调用专门的库进行精确计算。同时，TIGeR-300K数据集提供了一个涵盖点变换、姿态估计、轨迹生成和空间兼容性验证的全面工具调用导向数据集支持该新范式。通过结合监督微调（SFT）和强化微调（RFT）以及提出层次化的奖励设计，TIGeR在几何推理基准测试中获得了SOTA性能，并在真实的机器人操作任务中展示了厘米级精度的表现。", "conclusion": "TIGeR框架通过利用外部工具实现视觉语言模型的几何推理能力，显著提高了模型在机器人操作任务中的精度和实用性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07304", "html_url": "https://arxiv.org/abs/2510.07304", "title": "Cocoon: 一种结合关联噪声的差分隐私训练系统架构", "title_en": "Cocoon: A System Architecture for Differentially Private Training with Correlated Noises", "authors": "Donghwan Kim,Xin Gu,Jinho Baek,Timothy Lo,Younghoon Min,Kwangsik Shin,Jongryool Kim,Jongse Park,Kiwan Maeng", "background": "机器学习模型会记住并泄露训练数据，导致数据所有者面临严重的隐私问题。差分隐私（DP）方法，如DP-SGD，因为可以在训练算法中加入噪声以保护隐私而受到关注。然而，这种噪声会降低模型的准确性。为提高准确性，新的方法通过在各个迭代中添加精心设计的关联噪声，使这些噪声在不同迭代中相互抵消。然而，这些新机制在模型较大或使用大规模嵌入表时会导致不可忽视的开销。", "innovation": "本文提出了一种名为Cocoon的硬件与软件协同设计框架，旨在高效实现存在关联噪声的差分隐私训练。Cocoon通过预计算并以合并格式存储关联噪声（Cocoon-Emb）来加速使用嵌入表的模型，并通过自定义近内存处理设备（Cocoon-NMP）支持大型模型。在基于FPGA的近内存处理设备原型系统上，Cocoon将性能提升了2.33-10.82倍（Cocoon-Emb）和1.55-3.06倍（Cocoon-NMP）", "conclusion": "Cocoon框架通过硬件和软件的协同设计，有效提高了带有关联噪声的差分隐私模型训练的性能，尤其在处理大模型和大规模嵌入表时表现更为出色，验证了其在实际系统中的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "从成对比较中在线获取评分标准", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Yunzhong He,Afra Feyza Akyürek", "background": "评分标准为训练LLMs生成开放性长篇答案提供了一种灵活的方式，特别是在无法应用可验证奖励和人类偏好仅提供粗略信号的情况下。早期研究表明，使用基于评分标准的奖励进行强化学习可以持续提升LLM的性能。大多数现有方法依赖于在训练过程中保持静态的评分标准。然而，这种静态评分标准容易导致奖励作弊行为，并且无法捕捉训练过程中产生的新兴需求。因此，本文提出了一种名为Online Rubrics Elicitation (OnlineRubrics)的新方法，它通过成对比较当前策略与参考策略的回答来动态地创建评估标准，从而能够在线识别并缓解训练过程中的错误。实验证明，这种方法在AlpacaEval、GPQA、ArenaHard以及专家问题和评分标准的验证集上相对于使用静态评分标准的训练取得了多达8%的一致性改进。", "innovation": "本文提出了一种Online Rubrics Elicitation方法，通过成对比较当前策略与参考策略的回答来动态地更新评估标准。这种在线过程能够持续地识别并缓解训练过程中的错误，从而提高了模型的性能。", "conclusion": "实证结果显示，使用动态更新的评估标准相比仅使用静态评分标准训练，能够取得一致性的提升，具体表现形式为性能改进最多可达8%。此外，通过分析生成的标准，研究者识别出透明度、实用性、组织性和推理能力等关键主题。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07312", "html_url": "https://arxiv.org/abs/2510.07312", "title": "h1: 通过强化学习扩展大语言模型在长期推理中的能力", "title_en": "h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement Learning", "authors": "Sumeet Ramesh Motwani,Alesia Ivanova,Ziyang Cai,Philip Torr,Riashat Islam,Shital Shah,Christian Schroeder de Witt,Charles London", "background": "现有的大语言模型在解决短期推理任务时表现优异，但在任务推理时间长度增加时性能下降。现有的解决方法依赖于推理时的支架编程或昂贵的步骤级监督，这两种方法都不容易扩大应用范围。", "innovation": "本文提出了一种使用仅有的短期数据来训练模型的方法，从而扩展模型在长期推理中的能力。该方法通过合成简单的短期任务创建复杂的、多步骤的依赖链，并采用基于难度递增的课程训练法，通过仅基于结果的奖励进行强化学习训练，从而避免了样本饱和问题，使得长期推理任务的可扩展性大大增强。实验结果显示，该方法在合成的六年级数学问题（GSM8K）上训练的模型在更长的、比赛级别的基准测试（GSM-Symbolic, MATH-500, AIME）上提高了高达2.06倍的准确率。理论分析表明，通过仅基于结果奖励的课程强化学习在样本复杂性上比全程训练方法有了指数级的改进。", "conclusion": "通过上述创新方法，模型不仅可以在高通过率的情况下学习新的推理路径，而且还可以实现使用现有数据对长期推理问题的有效扩展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.11975", "html_url": "https://arxiv.org/abs/2309.11975", "title": "使用贝叶斯三角测量从任务表现推断能力", "title_en": "Inferring Capabilities from Task Performance with Bayesian Triangulation", "authors": "John Burden,Konstantinos Voudouris,Ryan Burnell,Danaja Rutar,Lucy Cheke,José Hernández-Orallo", "background": "随着机器学习模型变得越来越通用，我们迫切需要以更加丰富且具意义的方式对其进行描述。本文提出了一种方法，通过多样化的实验数据来推断系统的认知特征。这种方法依赖于测量布局，描述了任务实例特征如何与系统能力相互作用影响表现。然而，这种评估对于传统的心理测量和推断工具来说具挑战性。实验使用了贝叶斯概率编程库PyMC，对两个场景中的代理进行认知特征推断：68名在动物AI奥运会中的实际参赛者和30个合成的O-PIAAGETS实验中的代理。", "innovation": "本文介绍了一种利用任务表现数据通过贝叶斯三角测量推断系统认知特征的方法。主要创新点在于针对传统心理测量和推断工具难以处理的非群体数据，提出了复杂的特征三角化方法，并利用PyMC进行推断。这种方法为能力导向的评估提供了可能。", "conclusion": "研究展示了认知特征评估的潜力，并提供了两种场景下的认知剖面结果，这为机器学习模型的认知特性分析提供了一种新颖的方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07314", "html_url": "https://arxiv.org/abs/2510.07314", "title": "GyroSwin: 5D的涡流等离子体模拟的近似模型", "title_en": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations", "authors": "Fabian Paischer,Gianluca Galletti,William Hornsby,Paul Setinek,Lorenzo Zanisi,Naomi Carey,Stanislas Pamela,Johannes Brandstetter", "background": "核聚变在可靠且可持续的能源生产中扮演着关键角色。然而，湍流是阻碍实用聚变功率的主要障碍之一，它显著影响等离子体的束缚并对于下一代反应堆的设计至关重要。等离子体湍流由非线性磁聚度方程支配，这个方程描述了一个5维分布函数随时间的变化。由于其高计算成本，实际应用中通常采用简化的低维模型来近似湍流的能流转移，但这些模型会忽略全5维动态中特有的非线性效应。", "innovation": "我们提出了一种名为GyroSwin的新模型，它是第一个可以模拟5维非线性磁聚度模拟的可扩展的神经近似模型。GyroSwin通过扩展视觉变换器到5维，引入了交叉注意力和集成模块，以及受到了非线性物理启发的通道间模式分离方法，实现了5维等离子体湍流的准确预测，降低了全解析非线性磁聚度模拟的计算成本三个数量级，同时保持了物理验证性。", "conclusion": "GyroSwin展示了良好的可扩展性，已经在超过十亿参数下进行了测试，为等离子体湍流的磁聚度模拟提供了一种可扩展的神经近似模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07307", "html_url": "https://arxiv.org/abs/2510.07307", "title": "MLE-Smith：利用自动多代理管道扩展机器学习工程任务", "title_en": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline", "authors": "Rushi Qiang,Yuchen Zhuang,Anikait Singh,Percy Liang,Chao Zhang,Sherry Yang,Bo Dai", "background": "尽管语言模型（LMs）在自动化机器学习工程（MLE）方面取得了显著进展，但由于获得高质量的MLE训练数据受限，当前的MLE基准测试存在低扩展性和有限的适用性问题。这些基准测试依赖于静态且人工编纂的任务，这需要大量的时间和人力来生产。", "innovation": "我们提出了MLE-Smith，这是一种全自动化多代理管道，通过有效的生成-验证-执行范式将原始数据集转换为竞赛风格的MLE挑战，以此来扩大MLE任务的规模，并确保任务的质量、实际适用性和丰富的多样性。提议的多代理管道在MLE-Smith中驱动了结构化任务设计和标准化重构，结合的混合验证机制强制执行严格的结构性规则和高层次语义正确性，进一步通过互动执行验证其实证可解性及现实世界的一致性。", "conclusion": "我们将MLE-Smith应用于224个真实世界数据集，生成了涵盖多个类别、目标和模态的606项任务，这证明MLE-Smith可以有效应用于各种真实世界数据集。在生成的任务上评估显示，顶尖和前沿的大规模语言模型（LLMs）在MLE-Smith任务上的表现与其在精心设计的人工任务上的表现强烈相关，这突显了MLE-Smith在扩大MLE任务规模方面的有效性，同时保持了任务的质量。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07315", "html_url": "https://arxiv.org/abs/2510.07315", "title": "Vibe Checker: 使代码评估与人类偏好相一致", "title_en": "Vibe Checker: Aligning Code Evaluation with Human Preference", "authors": "Ming Zhong,Xiang Zhou,Ting-Yun Chang,Qingze Wang,Nan Xu,Xiance Si,Dan Garrette,Shyam Upadhyay,Jeremiah Liu,Jiawei Han,Benoit Schillings,Jiao Sun", "background": "大型语言模型（LLMs）促进了代码的vibe编码过程，用户通过自然语言与LLMs交互生成和迭代改进代码，直至通过他们的vibe检查。vibe检查与现实世界的人类偏好密切相关，不局限于功能正确性，还包括代码是否感觉正确、易于阅读、保持意图和保持正确性。当前的代码评估主要围绕功能正确性（pass@k）展开，忽视了用户日常应用的非功能性指令。本文假设指令遵循是vibe检查中体现代码人类偏好缺失的关键因素，尤其是在功能正确性之外。为了衡量模型的代码指令遵循能力，作者提出了VeriCode，即一套包含30个可验证代码指令及其相应确定性验证器的分类。使用这一分类法，作者增强了已建立的评估套件，创建了Vibe Checker测试床，该测试床评估代码指令遵循和功能正确性。通过对31款顶级LLMs进行评估，作者表明即使最强的模型也难以同时遵循多个指令，并在功能上表现出明显倒退。", "innovation": "本文通过识别vibe检查的核心因素，以及提出了VeriCode，这套30个可验证代码指令及其对应的确定性验证器的分类法，填补了当前代码评估方法在非功能性指标上的空白。利用VeriCode，作者构建了Vibe Checker测试床，用于同时评估代码遵循指令和功能正确性。此工作提供了一个实际路径来制定基准模型，以更好地符合用户的代码偏好。", "conclusion": "功能正确性和指令遵循的复合评分与人类偏好最为相关，后者成为现实编程任务中的主要差异因子。本研究为制定基准和开发更符合用户编程偏好模型的核心因素提供了具体的方向。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.11927", "html_url": "https://arxiv.org/abs/2412.11927", "title": "透明且连贯的操作失误检测", "title_en": "Transparent and Coherent Procedural Mistake Detection", "authors": "Shane Storks,Itamar Bar-Yossef,Yayuan Li,Zheyuan Zhang,Jason J. Corso,Joyce Chai", "background": "程序性错误检测（PMD）是一种将通过第一人称视角视频观察的人类用户操作任务与程序性文本所指定的任务进行分类的任务。尽管近期已有重要进展，但机器在现实世界中的表现仍然不可行，其推理过程也不透明。因此，我们扩展了PMD要求生成视觉自助对话理由以指导决策。利用近期视觉-语言模型（VLMs）所表现出的成熟图像理解能力，我们基于个体帧构建了一个合适的基准数据集。这种重构使透明度达到前所未有的水平，我们利用自然语言推理（NLI）模型提出两种自动化度量方法，用于生成理由的一致性。", "innovation": "我们将PMD扩展为要求生成视觉自言自语的合理性来进行决策，这使得透明度达到了前所未有的水平。我们利用自然语言推理（NLI）模型提出了两种自动化度量方法来评估生成的合理性的一致性，这为评估PMD的性能提供了一种新的方式。通过这种方法，我们可以看到视觉语言模型（VLMs）在这方面的能力以及其改进空间，表明VLMs需要在准确性、连贯性和效率方面进行改进，通过结合这些度量方法到常见的推理和微调方法中可以改善它们的表现。此外，我们的多方面度量可视化了常见的结果，突显了进一步改进的领域。", "conclusion": "我们提出了一个增强透明度的新框架来重新表述PMD问题，并使用自然语言推理模型制定了两个自动化度量来评估生成的合理性。虽然视觉语言模型在即用状态下表现不佳，但通过结合这些度量方法调整，它们在准确性、连贯性和效率方面都有所改进。我们还通过可视化来多维度度量各种结果，指出了需要进一步改进的领域。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01382", "html_url": "https://arxiv.org/abs/2504.01382", "title": "进步的幻象？评估当前Web代理的状态", "title_en": "An Illusion of Progress? Assessing the Current State of Web Agents", "authors": "Tianci Xue,Weijian Qi,Tianneng Shi,Chan Hee Song,Boyu Gou,Dawn Song,Huan Sun,Yu Su", "background": "随着数字化和云计算技术的发展，互联网在现代社会中变得越来越重要。基于大规模语言模型的自主网络代理在工作自动化方面具有很大的潜力。因此，准确地衡量和监控它们的能力进步变得非常重要。本文对该领域当前的状态进行了全面且严格的评估。结果显示，现有的代理能力与之前报告的结果存在显著差异，反映出在现有基准中的缺点。该研究引入了一个包含300个多样化且现实的任务（分布在136个网站上）的在线评估基准——Online-Mind2Web，它可以更接近真实用户如何使用这些代理来进行评估。这项研究还开发了一种新的LLM-as-a-Judge自动化评估方法，该方法可以实现约85%的与人工判断的一致性，这显著高于现有方法。最后，该研究进行了迄今为止最全面的当前Web代理的比较分析，揭示了它们的优点与局限以激励未来的研究。", "innovation": "1. 引入了一个名为Online-Mind2Web的在线评估基准，包含300个多样化且现实的任务，分布在136个网站上。2. 开发了一种新的LLM-as-a-Judge自动化评估方法，与人工判断的一致性达到约85%，显著高于现有方法。", "conclusion": "该研究揭示了当前Web代理的真实能力，指出之前报告的结果可能过度乐观。通过引入新的评估基准和自动化评估方法，该研究提供了一种更接近真实用户使用情境的方法来评估Web代理，同时提供了首次全面的比较分析，展示了代理的优点及其局限性，以引导未来的研究。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07318", "html_url": "https://arxiv.org/abs/2510.07318", "title": "Artificial Hippocampus Networks for Efficient Long-Context Modeling", "title_en": "Artificial Hippocampus Networks for Efficient Long-Context Modeling", "authors": "Yunhao Fang,Weihao Yu,Shu Zhong,Qinghao Ye,Xuehan Xiong,Lai Wei", "background": "长序列模型在RNN-like模型中面临压缩固定大小内存的有效性与在Transformer中渐进增长内存的保真度之间的基本权衡。受认知科学中的多存储模型启发，本文提出了一种人工神经网络的记忆框架。该框架将Transformer的KV缓存作为无损的短期记忆滑动窗口，并通过一个可学习模块—人工海马网络（AHN）反复压缩窗口外的信息，存入固定大小的紧凑型长期记忆中。研究通过在长上下文基准软件包LV-Eval和InfiniteBench上进行的大量实验表明，AHN增强的模型在减少计算和内存需求的同时，能持续超越滑动窗口基准模型，并在某些情况下甚至优于全注意力模型。例如，将AHNs增强至Qwen2.5-3B-Instruct模型后，推理FLOPs减少40.5%，内存缓存减少74.0%，在LV-Eval（128k序列长度）上的平均得分从4.41提升至5.88。", "innovation": "提出了一个将KV缓存作为短期无损记忆和AI海马网络压缩长期记忆的记忆框架，利用现代RNN-like架构（Mamba2、DeltaNet、Gated DeltaNet）实现该框架，并通过在长上下文基准上的实验验证了其有效性。该方法在保持性能的同时，显著降低了计算和内存需求。", "conclusion": "通过将KV缓存作为短期无损记忆和AI海马网络压缩长期记忆的记忆框架，该研究在保持性能的同时显著降低了计算和内存需求。实验结果表明，AHN增强的模型在长上下文基准上的表现优于传统滑动窗口模型，甚至与全注意力模型相当或更优。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17607", "html_url": "https://arxiv.org/abs/2505.17607", "title": "控制代理规划与推理在机构设计中的应用", "title_en": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis", "authors": "João Pedro Gandarela,Thiago Rios,Stefan Menzel,André Freitas", "background": "该研究提出了一种基于语言模型的双重代理推理框架，用于自动合成平面机制，将自然语言任务描述与符号表示和模拟紧密结合起来。通过自然语言分析，系统能够生成并参数化模拟代码，通过专家反馈和逐步改进设计，实现可操作的语义/符号优化循环。", "innovation": "该框架通过自然语言任务描述生成符号约束和方程，并根据专家反馈迭代优化设计，引入了MSynth基准测试集，具体表现为以下创新点：1）专家反馈和迭代优化大幅提升了设计性能，2）符号回归提示在提供更深层次机制理解时尤其有效，尤其是在使用较大模型或具有适当归纳偏差的架构时。", "conclusion": "该研究通过使用自然语言规划和推理方法，显著提高了平面机制的合成效率，并通过MSynth测试集验证了方法的有效性，统计检验结果显示，该方法在单个任务上的表现提升了多达90%，显示出明显的实际应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21988", "html_url": "https://arxiv.org/abs/2505.21988", "title": "逻辑子图的功能匹配：超越结构同构", "title_en": "Functional Matching of Logic Subgraphs: Beyond Structural Isomorphism", "authors": "Ziyang Zheng,Kezhi Li,Zhengyuan Shi,Qiang Xu", "background": "逻辑电路中的子图匹配是电子设计自动化(EDA)应用程序的基础，包括数据路径优化、算术验证和硬件后门检测。然而，现有的技术主要依赖于结构性图同构，从而难以识别在综合变换导致电路拓扑大幅改变时的功能相关子图。", "innovation": "提出了功能子图匹配的新概念，这是一种识别给定逻辑函数是否存在且不依赖于综合或技术映射导致的结构变化的方法。具体而言，提出了一种两阶段多模态框架：（1）学习跨AIG和后映射网表的功能性嵌入以进行功能子图检测；（2）使用图分割方法识别模糊边界。基准测试表明，与现有结构方法相比，功能子图检测的平均准确率达到了93.8%，模糊边界识别的骰子分数为91.3%。", "conclusion": "与基准测试结果表明，提出的方法在功能子图检测和模糊边界识别方面显著优于现有结构方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12891", "html_url": "https://arxiv.org/abs/2505.12891", "title": "TIME：Real-World Scenarios下的大规模语言模型的多水平时间推理基准", "title_en": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios", "authors": "Shaohang Wei,Wei Li,Feifan Song,Wen Luo,Tianyi Zhuang,Haochen Tan,Zhijiang Guo,Houfeng Wang", "background": "大规模语言模型（LLMs）需要通过时间推理理解现实世界，但现有研究未能充分考虑实际问题中对时间推理的需求：（1）密集的时间信息；（2）快速变化的事件动态；（3）在社会互动中的复杂时间依赖性。研究团队开发了TIME基准测试，旨在解决上述问题。", "innovation": "TIME是专门为实境场景设计的时间推理基准测试，包含38,522个问答对，并分为三个不同层级和11个精细粒度的子任务。它涵盖了三个子数据集，分别针对不同的现实挑战（TIME-Wiki、TIME-News、TIME-Dial）。该基准测试还对推理模型和非推理模型进行了广泛的实验，深入分析了在不同实际场景和任务中的时间推理表现，并总结了测试集扩展对时间推理能力的影响。此外，还发布了TIME-Lite子集，以便未来的研究和标准化评估。", "conclusion": "TIME基准测试涵盖了广泛的实际情景和任务，进行了全面的时间推理性能分析，并释放了TIME-Lite子集以促进进一步研究。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL: 探索事实性强化学习", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是慢思考模型，经常表现出严重的幻觉，由于它们在推理过程中无法准确识别知识边界，导致输出内容不准确。强化学习（RL）可以增强复杂的推理能力，但由于其结果导向的奖励机制缺乏对思考过程中的事实监督，进一步加剧了幻觉问题。因此，本文旨在解决慢思考模型中高强度的幻觉问题，提出了一种知识增强的强化学习方法——KnowRL。", "innovation": "KnowRL 通过在 RL 训练过程中集成基于知识验证的事实性奖励，引导模型进行基于事实的推理，帮助它们识别知识边界。这种方法在训练过程中直接奖励遵循事实的推理步骤，从而促进更可靠的认知过程。实验结果表明，KnowRL 在降低幻觉方面效果显著，同时保持了慢思考模型原有的强大推理能力。", "conclusion": "实验结果表明，KnowRL 有效地减轻了慢思考模型的幻觉问题，同时保留了其原有的强大推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05378", "html_url": "https://arxiv.org/abs/2509.05378", "title": "Human似的编码：一种多智能体的医学编码解决方案", "title_en": "Code Like Humans: A Multi-Agent Solution for Medical Coding", "authors": "Andreas Motzfeldt,Joakim Edin,Casper L. Christensen,Christian Hardmeier,Lars Maaløe,Anna Rogers", "background": "在医学编码中，专家需要将非结构化的临床笔记映射到表示诊断和程序的 alphanumeric 代码。现有的研究中，还没有一种解决方案能够支持完整的 ICD-10 编码系统（包含超过 7 万个标签），且针对罕见诊断代码的性能尤为不足。", "innovation": "提出了一种名为 'Human似的编码' 的新框架，该框架使用大语言模型进行医学编码，并遵循了官方的编码指南。这是第一次可以支持完整的 ICD-10 编码系统的解决方案。该研究还通过分析系统性能，识别出了系统的弱点（即系统对某些代码的系统性低估）。", "conclusion": "该研究不仅实现了对罕见诊断代码的最优性能，而且通过分析系统的性能还指出了其‘盲点’，旨在为进一步的研究提供指导。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00320", "html_url": "https://arxiv.org/abs/2506.00320", "title": "Dyna-Think: 结合AI代理中的推理、行为和世界模型模拟", "title_en": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "authors": "Xiao Yu,Baolin Peng,Ruize Xu,Michel Galley,Hao Cheng,Suman Nath,Jianfeng Gao,Zhou Yu", "background": "最近的研究表明，大规模语言模型（LLMs）如DeepSeek-R1在数学和编程等领域的表现令人印象深刻，但这些模型在长期任务中的有效行为尚不清楚。现有的研究主要集中在LLMs的表现上，未详细探讨何种推理行为有效，何种行为缺失等问题。本文通过对大规模语言模型在数学和编程领域的应用研究背景进行了综述，指出尽管LLMs在特定领域表现出复杂的认知行为，但对于长周期任务中如何优化AI代理的性能尚未有明确的方法论指导。因此，研究者们提出了一种新的思路，即如何将推理、行为和世界模型模拟相结合，来提升AI代理的性能。", "innovation": "本文提出的Dyna-Think框架结合了规划、内部世界模型、推理和行动，来提升AI代理的能力。为此，作者还提出了Dyna-Think Imitation Learning (DIT) 和Dyna-Think Dyna Training (DDT)。DIT能重构如R1模型的行为过程，聚焦于世界模型模拟的相关性，以训练策略；而DDT则通过两阶段的训练过程，首先改善代理的世界建模能力，再通过策略训练来改进代理的行为。此外，该研究在OSWorld和WindowsAgentArena两个实验场景中对提出的方法进行了验证，结果显示Dyna-Think方法在同R1相比，能在相似性能表现的情况下，生成的文本量要少2倍。这些方法和发现为未来研究如何融合世界模型模拟到AI代理，提升其推理、计划和执行能力提供了一种新的研究方向。", "conclusion": "研究结果表明，使用批评生成来训练世界模型对策略性能的提升是有效的；同时，性能更优的AI代理与更好的世界建模能力相关。作者认为这些结果表明结合世界模型模拟到AI代理中，用于提升其推理、计划和执行能力的潜力是非常有前景的研究方向。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25282", "html_url": "https://arxiv.org/abs/2509.25282", "title": "向因果可视化编程迈进：增强低代码环境中的代理推理", "title_en": "Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments", "authors": "Jiexi Xu,Jiaqi Liu,Lanruo Wang,Su Liu", "background": "大规模语言模型（LLM）代理在低代码环境中日益具备协调复杂任务的能力，但由于其内在的推理机制依赖于概率关联而非真正的因果理解，这些代理通常会表现出幻觉和逻辑不一致。为了解决这些问题，本文提出了一种新的编程范式：因果可视化编程（CVP），旨在通过将因果结构引入工作流设计中来解决这一根本问题。", "innovation": "本文提出了一种新的编程范式CVP，通过图形化的低代码界面让用户为工作流模块定义一个简单的“世界模型”，创建一个有向无环图（DAG），明确定义模块间因果关系。通过这种方式，因果图在代理的推理过程中起到了关键性约束作用，使决策依赖于用户定义的因果结构，并显著减少了逻辑错误和幻觉。通过模拟分布偏移的合成实验验证了CVP的有效性，实验结果显示在面对这种偏移时，基于因果关系的模型保持了稳定的准确性，而依赖概率关联的基线模型则出现了显著性能下降。", "conclusion": "研究的主要贡献在于提出现有的因果结构定义、提供并实施了CVP框架，将代理推理锚定到用户定义的因果图上，并实验证明了该框架在动态环境中增强代理稳健性和减少因果混淆导致的错误的有效性。CVP为构建更可解释、可靠和可信的人工智能代理提供了一条可行的路径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10309", "html_url": "https://arxiv.org/abs/2505.10309", "title": "大规模人类判断评估大型语言模型中的常识智能", "title_en": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "authors": "Tuan Dung Nguyen,Duncan J. Watts,Mark E. Whiting", "background": "现有对机器常识智能的评估多依赖静态基准，即通过比较模型输出和人类指定的正确标签来进行，这一过程中假设这些标签能够准确反映所有人类的常识思维，但实际上，研究表明，人类之间在常识上的分歧很大，这使得一个基准设计师所认为自明的常识，在其他人看来未必成立。因此，本文提出了一种新的评价方法，通过测量模型的判断和人类群体的判断之间的一致性来考核常识智能。这种方法考虑了人类在常识上的异质性。", "innovation": "本文提出了一种新的评估框架，通过大规模人类判断来评价大型语言模型中的常识智能。该方法引入了人类在常识上的异质性，以衡量模型的判断与真实人类群体之间的一致性。发现小型、开放参数量的模型在常识性能方面表现出色，这与预期的大型专有模型优于小型模型的观点不同。这一方法将常识智能与文化基础联系起来，有助于适应具有不同社会知识储备的人类群体的AI模型。", "conclusion": "研究结果表明，当被作为独立的调查响应者或人类假设群体的模拟器时，大多数大型语言模型仍低于人类平均常识能力。使用此评估框架，小型开放权重模型比大型专有模型更具有竞争力。这一评价框架提出了适应人类集体使用AI模型的必要性，强调不同社会知识储备的人群需要有不同的AI模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25373", "html_url": "https://arxiv.org/abs/2509.25373", "title": "从感知到认知：多模态大语言模型中的视觉-语言互动推理综述", "title_en": "From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models", "authors": "Chenyue Zhou,Mingxuan Wang,Yanbiao Ma,Chenxu Wu,Wanyi Chen,Zhe Qian,Xinyu Liu,Yiwei Zhang,Junhao Wang,Hengbo Xu,Fei Luo,Xiaohua Chen,Xiaoshuai Hao,Hehan Li,Andi Zhang,Wenxuan Wang,Lingling Li,Zhiwu Lu,Yang Lu,Yike Guo", "background": "多模态大语言模型（MLLMs）旨在实现对物理世界的深刻、类人理解与互动，但在获取信息（感知）和进行推理（认知）时往往表现出肤浅且不一致的融合，这导致了一系列推理失败，其中以幻觉最为突出。这揭示了一个根本性的挑战：处理像素的能力尚未赋予构建连贯且可信的内在世界模型的能力。为系统地剖析和解决这一挑战，本文引入了一个新颖且统一的分析框架:「从感知到认知」，分解复杂的视觉-语言互动理解过程为感知和认知两个相互依赖的层次，进而系统地分析当前MLLM的关键瓶颈，并综述了针对这些挑战的最新方法，涵盖了从优化低级视觉表示到改善高级推理范式的各种技术。", "innovation": "本文提出了一种新颖且统一的分析框架：「从感知到认知」，将复杂的视觉-语言互动理解过程分解为感知和认知两个相互依赖的层次，并基于此框架系统地分析了当前MLLM的关键瓶颈，综述了针对这些挑战的最新方法，特别是在优化低级视觉表示和改善高级推理范式方面的方法，并指出了未来研究方向。", "conclusion": "本文旨在为研究社区提供一个清晰的结构化视角理解当前MLLM的固有限制，并照亮构建能够进行深入推理和真正理解世界的下一代模型的道路。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01611", "html_url": "https://arxiv.org/abs/2510.01611", "title": "PsychoBench: 评估大型语言模型的心理智能", "title_en": "PsychoBench: Evaluating the Psychology Intelligence of Large Language Models", "authors": "Min Zeng", "background": "大型语言模型（LLMs）已经在多个行业展现了出色的能力，尤其是在生成内容方面。然而，它们在需要认知能力的应用中，如心理辅导，的应用潜力尚未被充分利用。本研究旨在探讨LLMs是否能够有效应用于心理辅导，通过博士中的一项关键研究问题：LLMs能否有效扮演心理咨询师的角色。为了评估LLMs是否具备担任心理咨询角色的资格，研究人员首先检查了LLMs是否能够通过美国国家心理咨询师认证考试（NCE），因为像人类心理咨询师需要通过认证考试才能从业一样，LLMs也需要展示足够的心理学知识才能满足相关标准。为了实现这一目标，研究引入了名为PsychoBench的新基准，该基准基于U.S. National Counselor Certification Exam的心理咨询师考试，需要大约70%的准确率才能通过。PsychoBench包含约2252道精心设计的单选题，涵盖了心理学的各个方面。", "innovation": "PsychoBench benchmarks for evaluating LLMs担任心理咨询师的能力，这些基准基于U.S. National Counselor Certification Exam，这是一种专业心理咨询师的执照考试，要求通过考试的准确率约为70%。PsychoBench包含了约2252道精心设计的单选题，这些问题不仅要求对心理学有深刻的理解，而且覆盖了心理学的各个子领域，从而全面评估LLMs担任咨询师的能力。", "conclusion": "评估结果显示，先进的模型如GPT-4o、Llama3.3-70B和Gemma3-27B能够远远超过通过标准化考试的阈值，而较小的开源模型（例如Qwen2.5-7B、Mistral-7B）仍然远远低于这一标准。这些结果表明，只有最前沿的LLMs目前才能满足心理咨询考试的标准，这既指出了开发心理学导向LLMs的潜力，也指出了挑战。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2209.03358", "html_url": "https://arxiv.org/abs/2209.03358", "title": "攻击尖峰：尖峰神经网络在对抗样本中的转移性和安全性", "title_en": "Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples", "authors": "Nuo Xu,Kaleel Mahmood,Haowen Fang,Ethan Rathbun,Caiwen Ding,Wujie Wen", "background": "尖峰神经网络（SNNs）由于其高能效和最近在分类性能上的进步而受到广泛关注。然而，与传统的深度学习不同，尖峰神经网络对于对抗样本的鲁棒性尚未得到充分研究。本文旨在推进尖峰神经网络的对抗攻击研究，做出了三大贡献。", "innovation": "1. 本文展示了即使是经过对抗训练的模型，尖峰神经网络的白盒攻击成功与否也强烈依赖于替代梯度估计技术。\n2. 通过使用最佳的单一替代梯度估计器，本文研究了尖峰神经网络与最先进的架构（如Vision Transformers和CNNs）之间的对抗样本可转移性。分析揭示了两个主要差距：当前没有白盒攻击利用多种替代估计器，也没有单一攻击能够同时欺骗SNN和非SNN模型。\n3. 本文提出了混合动态尖峰估计（MDSE）攻击，该攻击动态结合多个替代梯度来弥补这些差距。MDSE能够生成既能够欺骗SNN模型又能欺骗非SNN模型的对抗样本，其在SNN/ViT集成上达到了91.4%的更高有效性，并且在对抗训练的SNN集成上比Auto-PGD提升了3倍。", "conclusion": "实验覆盖了三个数据集（CIFAR-10、CIFAR-100、ImageNet）和十九个分类器。论文将在发表后提供代码和模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05318", "html_url": "https://arxiv.org/abs/2510.05318", "title": "BIRD-INTERACT: 通过动态交互视角重新定义大型语言模型的文本到SQL评估", "title_en": "BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions", "authors": "Nan Huo,Xiaohan Xu,Jinyang Li,Per Jacobsson,Shipei Lin,Bowen Qin,Binyuan Hui,Xiaolong Li,Ge Qu,Shuzheng Si,Linheng Han,Edward Alexander,Xintong Zhu,Rui Qin,Ruihan Yu,Yiyao Jin,Feige Zhou,Weihao Zhong,Yun Chen,Hongyu Liu,Chenhao Ma,Fatma Ozcan,Yannis Papakonstantinou,Reynold Cheng", "background": "大型语言模型（LLMs）在单轮文本到SQL任务中表现出色，但在现实世界的数据库应用中，大多数情况需要多轮交互来处理模糊查询、执行错误和不断变化的用户需求。现有的多轮交互基准在处理对话历史和评估读写操作方面存在不足，无法全面反映生产级数据库助手所面临的挑战。", "innovation": "引入了BIRD-INTERACT基准，通过综合交互环境，结合每个数据库、层次化知识库、元数据文件和驱动型用户模拟器，使模型能够在无需人类干预的情况下请求澄清、检索知识和恢复操作；设计了包括预定义对话协议（c-Interact）和开放生成性设置（a-Interact）的两种评估场景；涵盖了完整的CRUD操作，用于商业智能和操作场景，并通过可执行测试案例进行保护。还包含了完整的（BIRD-INTERACT-FULL，600个任务，最多11,796次交互）和简化版（BIRD-INTERACT-LITE，300个任务，简化数据库）的任务集。通过对内存移植和交互测试时扩展的分析，验证了高效交互对复杂且动态的文本到SQL任务的重要性。", "conclusion": "实证结果显示，BIRD-INTERACT挑战性很大，如GPT-5在c-Interact中仅完成8.67%的任务，在a-Interact中完成17.00%的任务。这表明大语言模型在真实场景下的多轮交互能力仍有待提升。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05465", "html_url": "https://arxiv.org/abs/2510.05465", "title": "VAL-Bench：测量语言模型的价值对齐", "title_en": "VAL-Bench: Measuring Value Alignment in Language Models", "authors": "Aman Gupta,Denny O'Shea,Fazl Barez", "background": "随着大型语言模型（LLMs）在影响人类决策的任务中应用越来越广泛，测试其输出是否体现一致的人类价值观变得至关重要。现有的基准测试主要关注拒绝或预定义的安全违规行为，但这些只能检查规则合规性，而无法揭示模型在处理具有争议的现实世界问题时是否保持一致的价值观系统。", "innovation": "作者引入了Value ALignment Benchmark（VAL-Bench），通过在具有争议性的公共辩论两侧的配对提示中评估模型是否保持稳定的价值立场，来评估模型的一致价值观。VAL-Bench包含从维基百科的具有争议性部分中提取的115,000对配对提示。通过LLM作为仲裁人衡量配对回复间的一致性或分歧，该基准测试适用于最新的开源和专有源语言模型。它揭示了在不同模型之间对齐程度的巨大差异，并突显了安全性策略（如拒绝）与更具有表达性的价值观系统之间的权衡。VAL-Bench提供了一个可扩展的、可重复的基准测试，有助于系统地比较LLMs如何可靠地体现人类价值观。", "conclusion": "VAL-Bench通过提供一个可扩展的、可重复的基准测试，使得研究人员能够系统地比较各种语言模型如何准确地体现人类价值观，从而揭示了不同模型之间在对齐程度上的巨大差异，以及安全策略与更多表达性价值观系统之间的权衡。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06189", "html_url": "https://arxiv.org/abs/2510.06189", "title": "蛮族在敲门: AI正在颠覆系统研究", "title_en": "Barbarians at the Gate: How AI is Upending Systems Research", "authors": "Audrey Cheng,Shu Liu,Melissa Pan,Zhifei Li,Bowen Wang,Alex Krentsel,Tian Xia,Mert Cemri,Jongseok Park,Shuo Yang,Jeff Chen,Lakshya Agrawal,Aditya Desai,Jiarong Xing,Koushik Sen,Matei Zaharia,Ion Stoica", "background": "人工智能（AI）正逐步改变我们熟知的研究过程，通过自动化发现新解决方案。AI驱动的方法通常是首先生成一系列多样化的解决方案，然后验证和挑选出能够解决问题的方案。然而，这种方法依赖于可靠的验证者，即能够准确判断一个解决方案是否解决给定问题的系统。该论文指出，长期专注于设计和评估新技术的系统研究领域特别适合AI驱动的解决方案发现，因为系统的性能问题自然存在可靠的验证者：解决方案通常是在实际系统或模拟器中实现的，验证过程仅在于将这些软件实体与预定义的工作负载运行并测量其性能。因此，该研究提出了一种称为AI驱动的研究方法（ADRS），它通过迭代生成、评估和完善解决方案来进行算法发现和优化。", "innovation": "该研究提出了ADRS（基于AI的系统研究方法），通过迭代生成、评估和完善解决方案，特别适用于系统性能问题的解决方案发现。此外，研究展示了在多个领域，如多区域云调度的负载均衡、专家混合推理、基于LLM的SQL查询和事务调度等，ADRS发现的算法性能优于现有的最佳人工设计。研究还总结了算法进化方面的最佳实践，用于现有框架，这对于系统的社区来说是一个关键的发现，随着AI在算法设计中的中心角色，人类研究人员将更加关注问题的表述和战略指导。研究结果强调了AI带来的颠覆性影响及其对系统研究方法的迫切需求。", "conclusion": "ADRS极大的提高了算法发现和优化的效率，尤其是在系统性能方面。研究结果还指出，随着AI在算法设计中扮演越来越重要的角色，系统研究的焦点也将转向问题表述和策略指导。该研究对于系统研究领域来说是一个变革性的新方法，需要重视适应AI时代的要求。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.09225", "html_url": "https://arxiv.org/abs/2402.09225", "title": "我的数据在你的AI中吗？面纹生物特征中的会员推断测试（MINT）", "title_en": "Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics", "authors": "Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia", "background": "本文介绍了会员推断测试（MINT），这是一种旨在实证评估给定数据是否被用于训练AI/ML模型的新方法。具体而言，我们提出了两个MINT架构，旨在学习当审计模型被暴露在训练过程中使用的数据时出现的不同激活模式。实验框架集中在面部识别这一具有挑战性的任务上，考虑了三种最新的面部识别系统。实验使用了六组公开可用的数据集，总共包含超过2200万张面部图像。根据AI模型测试的上下文，考虑了不同的实验场景。", "innovation": "本文提出的MINT方法基于多层感知器（MLPs）和卷积神经网络（CNNs），旨在学习审计模型在暴露于训练过程中使用的数据时产生的不同激活模式。实验结果显示，该方法在识别AI模型是否使用了特定数据方面取得了显著效果，最高准确率可达90%。这种方法可以用于加强AI应用中的隐私和公正性，例如揭示是否使用敏感或私人数据进行训练或调优大型语言模型（LLMs）。", "conclusion": "提出的MINT方法展现出了识别AI模型是否训练于特定数据集的潜力，能够用来监督AI训练过程以保障隐私和公平性。这种测试方法可以揭示是否使用了敏感或私人数据来训练或调优大型语言模型。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.03881", "html_url": "https://arxiv.org/abs/2403.03881", "title": "使用扩散模型解锁数据集蒸馏", "title_en": "Unlocking Dataset Distillation with Diffusion Models", "authors": "Brian B. Moser,Federico Raue,Sebastian Palacio,Stanislav Frolov,Andreas Dengel", "background": "数据集蒸馏旨在将数据集压缩成更小但高度代表性的合成样本。尽管现在扩散模型在生成基准测试中占据主导地位，但现有数据集蒸馏方法却避开它们，而是依赖生成对抗网络（GANs）或自动编码器，或者最多只是从固定扩散先验中采样。这种趋势主要是因为对长去噪链中的直接反向传播会导致梯度消失，从而阻碍了有效的合成样本优化。", "innovation": "作者介绍了使用扩散模型的隐空间数据集蒸馏方法（LD3M），这是首个通过预训练隐空间扩散模型学习基于梯度的蒸馏隐空间和类别嵌入的方法。该方法通过逆向步骤中的线性衰减跳连，从中断噪声状态传递梯度信号，无需调整扩散权重即保留梯度信号。实验表明，LD3M在 ImageNet 的不同子集上表现出高达4.8和4.2个百分点的下游准确性提升。", "conclusion": "LD3M 在 128x128 和 256x256 的多个 ImageNet 子集上均展示了优越性，显著改进了先前的最佳性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2209.12164", "html_url": "https://arxiv.org/abs/2209.12164", "title": "多模态段组装网络在具有重要性一致性奖励的广告视频编辑中的应用", "title_en": "Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward", "authors": "Yolo Yunlong Tang,Siting Xu,Teng Wang,Qin Lin,Qinglin Lu,Feng Zheng", "background": "广告视频编辑的目标是将广告视频自动缩短，同时保留一致的内容和广告商传达的关键信息。该过程主要分为两个阶段：视频分割和段落组装。现有的方法在视频分割阶段表现良好，但在段落组装阶段存在依赖外加复杂模型和性能较差的问题。为了解决这些问题，该研究提出了M-SAN（多模态段组装网络）来实现端到端的高效且连贯的段落组装任务。它利用从段落提取的多模态表示，并遵循带有注意力机制的编码器-解码器Ptr-Net框架。为了训练M-SAN，设计了重要性-连贯性奖励。研究者在1000多个带有丰富广告场景的视频上实验了Ads-1k数据集。为了评估方法，提出了一个统一的指标Imp-Coh@Time，该指标同时衡量输出的重要性、连贯性和持续时间。实验证明，该方法在该指标上的表现优于随机选择和之前的方法，且消融实验进一步证明了多模态表示和重要性-连贯性奖励显著提高了性能。", "innovation": "提出了一种端到端的多模态段组装网络M-SAN，利用了多模态表示和注意力机制，并设计了重要性-连贯性奖励进行训练。这种方法有效地解决了现有方法在段落组装阶段存在的依赖额外复杂模型和性能较低的问题，且在评测指标上表现优于其他方法。", "conclusion": "研究表明，M-SAN方法在广告视频编辑中的段落组装任务上表现优异，能够在保持视频连贯性和重要性的前提下实现高效的视频编辑。多模态段组装网络的引入为广告视频编辑提供了新的研究方向，并证明了重要性-连贯性奖励的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.04481", "html_url": "https://arxiv.org/abs/2403.04481", "title": "ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent", "title_en": "ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent", "authors": "Shangjian Yin,Peijie Huang,Jiatian Chen,Haojing Huang,Yuhong Xu", "background": "大语言模型在语言生成和通用任务方面展现了令人印象深刻的能力。然而，它们在口语理解（SLU）中的应用仍然具有挑战性，特别是在标记级任务中，自回归的性质容易导致对齐问题。另外，在通过直接微调获取语义级任务的细微关系方面也存在困难。", "innovation": "我们提出了一种称为Entity-level Language Model (ECLM)的新框架，它将槽填充重新定义为实体识别任务，并引入了新颖的概念——意图链，以实现逐步的多意图识别。实验结果表明，与Uni-MIS等强基线相比，ECLM在MixATIS和MixSNIPS数据集上分别获得了3.7%和3.1%的性能提升。与标准的监督微调相比，ECLM分别在这些数据集上实现了8.5%和21.2%的进一步改进。", "conclusion": "我们的代码可以在以下链接中找到：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.01103", "html_url": "https://arxiv.org/abs/2410.01103", "title": "近似对齐解码", "title_en": "Approximately Aligned Decoding", "authors": "Daniel Melcer,Sujan Gonugondla,Pramuditha Perera,Haifeng Qian,Wen-Hao Chiang,Yanjun Wang,Nihal Jain,Pranav Garg,Xiaofei Ma,Anoop Deoras", "background": "当前的方法在拒绝不良输出时，需要大量的计算资源，或者通过限制生成高度不可能的词汇来扭曲输出分布，这两种方式都有其显著的缺点。", "innovation": "提出了一个新的解码方法，即近似对齐解码（Approximately Aligned Decoding，AprAD）。该方法通过借鉴推测性解码领域的算法，能够在不大幅扭曲输出分布的同时提高计算效率，特别适用于产生具有难以满足约束条件的长文本序列。", "conclusion": "通过一系列实验表明，AprAD在特定任务上的表现与未扭曲输出分布的方法相当，但计算效率要高得多。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.16276", "html_url": "https://arxiv.org/abs/2403.16276", "title": "为LLMs注入伪未剪辑视频以实现音视频时间理解", "title_en": "Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding", "authors": "Yolo Yunlong Tang,Daiki Shimada,Jing Bi,Mingqian Feng,Hang Hua,Chenliang Xu", "background": "大型语言模型 (LLMs) 在自然语言和多模态领域展示了显著的能力。通过使用来自精细标注数据集的时间注释对多模态LLMs进行微调，可以提高其在视频语言任务中的时间理解能力。然而，缺乏带有精确时间注释的未修剪音视频数据集阻碍了LLMs学习时间、音视频事件和文本令牌之间的对齐，从而限制了其时间定位音视频事件的能力。", "innovation": "提出了PU-VALOR，一个包含超过114,000个伪未修剪视频并具有详细时间注释的综合音视频数据集。通过基于事件的视频聚类、随机时间缩放和排列的方法从大规模但粗略标注的音视频数据集VALOR中生成PU-VALOR。通过在PU-VALOR上微调多模态LLM，开发了AVicuna模型，能够将音视频事件与时间区间和相应的文本令牌对齐。AVicuna在时间定位和时间感知对话方面表现出色。实验表明，AVicuna在开放式视频问答、音视频问答和音视频事件密集定位任务上能够有效处理音视频时间理解，并取得最先进的性能。", "conclusion": "研究结果表明，通过将伪未修剪音视频数据集（如PU-VALOR）引入到多模态LLM的微调中，可以显著提升其对音视频事件的时间理解和定位能力，并在多种任务上取得了最先进的性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.00743", "html_url": "https://arxiv.org/abs/2409.00743", "title": "可解释聚类：一种综述", "title_en": "Interpretable Clustering: A Survey", "authors": "Lianyu Hu,Mudi Jiang,Junjie Dong,Xinying Liu,Zengyou He", "background": "近年来，聚类算法研究主要集中在提高其准确性和效率上，但经常以牺牲可解释性为代价。然而，随着这些方法在医疗、金融和自主系统等高风险领域中的应用越来越广泛，生成透明和可解释的聚类结果变得至关重要。这对于获取用户信任和满足这些领域日益增长的伦理和监管要求是必不可少的。因此，确保从聚类算法中得出的决策能够清晰地理解并得到合理解释，已经成为一个基本要求。", "innovation": "本文提供了一种全面和结构化的可解释聚类算法现状综述，确定了区分各种方法的关键标准。这些见解有助于研究人员根据特定应用环境选择最合适的可解释聚类方法，同时也促进了高效且透明的聚类算法的发展和采用。此外，本文还提供了一个开放的资源库，该库按照本综述提出的分类组织了代表性和新兴的可解释聚类方法，便于参考。其网址为this https URL", "conclusion": "通过本次综述，研究人员可以更好地理解和选择合适的可解释聚类方法，促进聚类算法的发展，并满足伦理和监管要求。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.10979", "html_url": "https://arxiv.org/abs/2411.10979", "title": "VidComposition: MLLMs能否分析编排视频中的构图？", "title_en": "VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?", "authors": "Yolo Yunlong Tang,Junjia Guo,Hang Hua,Susan Liang,Mingqian Feng,Xinyang Li,Rui Mao,Chao Huang,Jing Bi,Zeliang Zhang,Pooyan Fazli,Chenliang Xu", "background": "多模态大型语言模型（MLLMs）的进步显著提高了其在视频理解方面的能力，但是现有的评估基准主要集中在抽象的视频理解上，没有全面评估模型在理解视频编排、视觉元素的细腻交互和编排视频内容中的复杂结构方面的能力。", "innovation": "提出了VidComposition基准，专门用于评估MLLMs在编排视频理解上的能力。此基准包括982段视频和1706个多项选择题，涵盖了摄像机运动、角度、景别、叙事结构、角色动作和情感等多个编排方面的内容。", "conclusion": "全面评估了33个开源和专有的MLLMs，结果显示人类与模型之间在理解复杂编排视频方面存在显著的性能差距，这揭示了MLLMs在理解复杂编排视频方面的局限性，并为未来改进提供了指导性见解。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.15222", "html_url": "https://arxiv.org/abs/2406.15222", "title": "中国非对比CT快速准确提示急性主动脉综合征的深度学习系统", "title_en": "A Deep Learning System for Rapid and Accurate Warning of Acute Aortic Syndrome on Non-contrast CT in China", "authors": "Yujian Hu,Yilang Xiang,Yan-Jie Zhou,Yangyan He,Dehai Lang,Shifeng Yang,Xiaolong Du,Chunlan Den,Youyao Xu,Gaofeng Wang,Zhengyao Ding,Jingyong Huang,Wenjun Zhao,Xuejun Wu,Donglin Li,Qianqian Zhu,Zhenjiang Li,Chenyang Qiu,Ziheng Wu,Yunjun He,Chen Tian,Yihui Qiu,Zuodong Lin,Xiaolong Zhang,Yuan He,Zhenpeng Yuan,Xiaoxiang Zhou,Rong Fan,Ruihan Chen,Wenchao Guo,Jianpeng Zhang,Tony C. W. Mok,Zi Li,Mannudeep K. Kalra,Le Lu,Wenbo Xiao,Xiaoqiang Li,Yun Bian,Chengwei Shao,Guofu Wang,Wei Lu,Zhengxing Huang,Minfeng Xu,Hongkun Zhang", "background": "急性主动脉综合征（AAS）的准确及时诊断在急性胸痛患者中仍是一个临床挑战。在中国，由于经济和工作流程的限制，疑似患者的初始影像测试通常采用非对比CT，而CT血管造影（CTA）则留给高风险患者。目前，尚缺乏适用于中国资源限制地区和只能采用非对比CT的患者的高准确率识别AAS的系统。", "innovation": "该研究提出了一种基于人工智能的警告系统iAorta，通过非对比CT识别AAS。该系统在多个中心的回顾性研究、大规模真实世界研究和前瞻性对比研究中均表现出高准确度，并为临床医生提供可解释的警告。特别是在大型试点部署中，该系统能够显著缩短正确诊断路径时间。", "conclusion": "iAorta系统能够帮助避免在资源受限地区和只能使用非对比CT的患者中延迟或错过AAS的诊断，具有广泛的应用前景。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.12353", "html_url": "https://arxiv.org/abs/2404.12353", "title": "V2Xum-LLM: 基于时间提示指令调整的跨模态视频摘要", "title_en": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning", "authors": "Hang Hua,Yolo Yunlong Tang,Chenliang Xu,Jiebo Luo", "background": "视频摘要旨在创建长视频的短小、准确且有条理的摘要。尽管存在多种视频摘要数据集，但这些数据集的视频数量有限，阻碍了先进大型视觉-语言模型的有效训练。此外，大多数现有的数据集只关注视频到视频的摘要，忽略了对多模态视频内容摘要的当代需求。近年来，研究努力将单模态扩展到多模态视频摘要，根据摘要的模态将其分为三类子任务。虽然早期的多模态数据集已经在文本摘要方面取得了一定进展，但这些文本摘要仍显不足。这些问题促使了Instruct-V2Xum数据集和V2Xum-LLM框架的提出。Instruct-V2Xum包含来自YouTube的30,000个多样化的视频，每条视频的摘要引用了特定帧索引，生成了对齐的视频和文本摘要。V2Xum-LLM框架首次将不同类型的视频摘要任务统一到一个大型语言模型（LLM）的文本解码器中，并通过时间提示和任务指令实现了可控的视频摘要。实验表明，V2Xum-LLaMA在多个视频摘要任务上优于强基线模型。此外，该研究还提出了V2V和V2VT摘要任务的增强评估指标。", "innovation": "Instruct-V2Xum数据集：包含了30,000个来自YouTube的多样化的视频，且每条摘要都引用了特定的帧索引，有助于生成对齐的视频和文本摘要。V2Xum-LLM框架：首次将各种视频摘要任务统一到大型语言模型的文本解码器中，通过引入时间提示和任务指令实现可控的视频摘要生成，并且该框架在多个基准模型上表现出优越性能；提出了V2V和V2VT摘要任务的增强评估指标。", "conclusion": "研究通过引入Instruct-V2Xum数据集和V2Xum-LLM框架，解决了视频摘要中的多个挑战，在多模态视频摘要任务中取得了显著成果。V2Xum-LLaMA框架不仅提高了视频摘要的质量，还提出了新的评估方法，展现了在视频摘要领域的发展潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04975", "html_url": "https://arxiv.org/abs/2411.04975", "title": "SuffixDecoding: 极端投机解码用于新兴AI应用", "title_en": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications", "authors": "Gabriele Oliaro,Zhihao Jia,Daniel Campos,Aurick Qiao", "background": "投机解码被广泛应用于通过使用较小的草稿模型来降低大语言模型（LLM）推理的延迟。然而，新兴的AI应用，例如LLM代理，具有独特的负载特征：这些应用通常提交重复的推理请求，比如多代理流水线执行类似的子任务或自我改进循环迭代地增强输出。这些负载产生长且高度可预测的序列，而现有的投机解码方法无法有效地利用这些序列。因此，需要一种新的方法来应对这一问题。", "innovation": "我们提出了一种名为SuffixDecoding的新方法，它使用高效的后缀树来缓存提示和先前输出中的长令牌序列。通过根据接受概率适配性地推测更多或更少的令牌，SuffixDecoding能有效利用更长时间的推测机会，并在这些机会有限时节省计算资源。", "conclusion": "在代理基准测试中，如SWE-Bench和Text-to-SQL，SuffixDecoding实现了高达5.3倍的速度提升，超越现有最先进的方法，比基于模型的方法如EAGLE-2/3快2.8倍，比无模型的方法如Token Recycling快1.9倍。源代码已开源。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.17624", "html_url": "https://arxiv.org/abs/2411.17624", "title": "机器学习与多源遥感在森林地上生物量估算中的应用：一项综述", "title_en": "Machine Learning and Multi-source Remote Sensing in Forest Aboveground Biomass Estimation: A Review", "authors": "Autumn Nguyen,Sulagna Saha", "background": "量化森林地上生物量(AGB)对于制定保护地球的决策和政策至关重要。机器学习(ML)和遥感(RS)技术被用于更有效地完成这一任务，但缺乏对最新ML方法与多种RS来源的最佳组合进行全面系统的回顾，特别是在考虑森林生态特征的情况下。因此，本文系统分析了符合严格纳入标准的25篇相关研究，识别了所有使用的ML方法和RS数据组合，提供了对在整合ML和RS进行森林地上生物量估算时应考虑哪些感知识别来源、变量和方法的推荐依据。", "innovation": "系统分析了25篇论文，识别了所有使用的ML方法和RS数据组合；发现了在森林地上生物量估算中最常用的感知识别来源和最有效的ML方法；特别关注了多传感器方法的有效性；提供了选择合适方法和数据源的建议。", "conclusion": "Sentinel-1遥感源的出现最为常见，多传感器方法（如Sentinel-1、Sentinel-2和LiDAR）特别有效；随机森林是出现最频繁的方法，但在与其他方法比较的研究中，极端梯度提升算法性能更优。研究结果为使用ML和RS整合进行森林地上生物量估算提供了推荐依据。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.22371", "html_url": "https://arxiv.org/abs/2410.22371", "title": "Fokker-Planck PDEs中的物理学知情神经网络的误差界", "title_en": "Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs", "authors": "Chun-Wei Kong,Luca Laurenti,Jay McMahon,Morteza Lahijanian", "background": "随机微分方程常用来描述随机过程的演变。这类过程的状态不确定性最好由概率密度函数（PDF）来表示，其演变由费曼-克潘克偏微分方程（FP-PDE）所规定。然而，通常无法以闭式形式求解FP-PDE。本研究展示了物理学知情神经网络（PINNs）在近似解PDF方面的应用，并开发了理论框架来构建紧实的误差边界，提出了可以在标准训练方法下高效生成的实际误差边界。此外，该误差边界框架可以推广到近似解决其他线性PDE（偏微分方程）的解。实验结果验证了所提出的误差边界，并展示了PINNs的扩展性和显著的计算加速能力，使其在获得精确PDF解决方案时与蒙特卡罗方法相比具有更高的效率。", "innovation": "开发了理论框架来构建紧实的误差边界，提出了可以在标准训练方法下高效生成的实际误差边界，并展示了这一框架能够推广到近似解决其他线性PDE的解。这为PINNs的应用提供了理论支持，并展示了其在复杂系统中的优越性能和效率。", "conclusion": "该研究证明了通过使用PINNs近似解决方案的概率密度函数（PDF）的有效性和可行性，并通过实验数据验证了所提出的误差边界准确性和PINNs在处理非线性、高维和混沌系统的高效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.08127", "html_url": "https://arxiv.org/abs/2412.08127", "title": "邪恶的双胞胎并非那么邪恶：关于机器生成提示的定性见解", "title_en": "Evil twins are not that evil: Qualitative insights into machine-generated prompts", "authors": "Nathanaël Carraz Rakotonirina,Corentin Kervadec,Francesca Franzon,Marco Baroni", "background": "研究中观察到语言模型（LMs）对看似无意义的机器生成提示作出可预测的响应，这反映了我们对LMs工作原理的理解尚不完整，并且这种不透明性为LMs的有害使用提供了机会，例如监狱解放（jailbreaking）。已有研究主要集中在不透明的机器生成提示（autoprompts）对大型和不同类型LMs的影响，以及这些提示如何影响生成响应。", "innovation": "本研究首次全面分析了不同类型和大小的6种LMs的机器生成提示。研究发现，机器生成提示通常包含一个具有明确意义的最后一个标记，这个标记强烈影响生成结果。上一个标记的一部分可以被删除，相当一部分填充值可以替换为与上下文无关的标记，但部分关键字仍与生成内容有一定的语义联系。研究还表明，人类专家可以识别出在机器生成提示中最重要且影响最大的标记，这说明提示并非完全不透明。此外，通过移除某些被视为重要标记的机器生成提示对自然语言输入的分析，验证了这些重要标记的存在。", "conclusion": "研究指出了机器生成提示不是完全不透明的，并表明它们可以从语言模型处理语言输入的一般方式中自然产生。研究结果对理解语言模型的工作原理以及如何防止其被用于有害目的具有实际意义。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.09278", "html_url": "https://arxiv.org/abs/2412.09278", "title": "医学领域的像素级洞察多模态大型语言模型", "title_en": "Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine", "authors": "Xiaoshuang Huang,Lingdong Shen,Jia Liu,Fangxin Shang,Hongxiang Li,Haifeng Huang,Yehui Yang", "background": "近年来，多模态大型语言模型（MLLM）取得了显著进展，展示了开发智能生物医学助手的可行性。然而，当前的生物医学MLLM主要集中在图像层面的理解，并且交互限制在文本命令上，这限制了其能力边界和使用灵活性。", "innovation": "本文提出了一种名为MedPLIB的新型端到端多模态大型语言模型，适用于生物医学领域，该模型具备像素级理解能力。提出了一种新颖的混合专家（MoE）多阶段训练策略，将MoE分为视觉语言专家模型和像素接地专家模型的单独训练阶段，然后通过MoE进行微调。该策略在推理时保持了计算成本相当于单个专家模型。此外，提出了医学复杂视觉问答数据集（MeCoVQA），包括8种复杂的医学成像问答模态和图像区域理解。实验结果表明，MedPLIB在多项医学视觉语言任务中达到了最先进的成果。特别是在像素接地任务的零样本评估中，MedPLIB在mDice指标上分别领先小型和大型模型19.7和15.6。", "conclusion": "MedPLIB在多个医疗视觉语言任务中取得了最先进的成果，并且在像素接地任务的零样本评估中表现优异，领先现有的小型和大型模型。该研究为生物医学MLLM的研究做出了重要贡献，其代码、数据和模型检查点将publicly发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02270", "html_url": "https://arxiv.org/abs/2412.02270", "title": "可持续自我进化对抗训练", "title_en": "Sustainable Self-evolution Adversarial Training", "authors": "Wenxuan Wang,Chenglei Wang,Huihui Qi,Menghao Ye,Xuelin Qian,Peng Wang,Yanning Zhang", "background": "随着深度神经网络模型在各种计算机视觉任务中的广泛应用，针对模型安全性的对抗样本生成策略得到了广泛探索。然而，现有的基于单一或有限类型攻击的一次性学习过程中的对抗训练防御模型，在应对动态和不断演化的攻击方法方面表现不佳。因此，为了提高模型在长期应用中的防御性能，本文提出了一种新型的可持续自我进化对抗训练（SSEAT）框架，以实现在多个阶段从不同类型的对抗样本中学习的目标，并提出了一种对抗数据重演模块来解决持续学习中模型灾难性遗忘的问题，还设计了一致性正则化策略来鼓励现有防御模型从先前训练中学习，从而保留更多过去的知识并保持对干净样本的准确分类。", "innovation": "本文提出了一种可持续自我进化对抗训练（SSEAT）框架，包括：1）一个持续的对抗防御流水线，用于在多个阶段学习各种类型的对抗样本；2）一种对抗数据重演模块，用于更好地选择更多样化且关键的重新学习数据以应对新攻击；3）一致性正则化策略，用于引导当前防御模型从先前训练中获得更多学习，以保留更多的过去知识并保持对干净样本的准确分类。", "conclusion": "通过广泛的实验验证了提出的SSEAT防御方法的有效性，与现有方法相比，SSEAT方法在防御性能和分类精度方面表现出优越性。该成果可在涉及深度学习模型安全的应用场景中提供更强大的防御机制。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.11031", "html_url": "https://arxiv.org/abs/2410.11031", "title": "NAR-*ICP: 通过神经网络执行经典ICP点云配准算法", "title_en": "NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms", "authors": "Efimia Panagiotaki,Daniele De Martini,Lars Kunze,Paul Newman,Petar Veličković", "background": "神经网络与经典机器人算法的结合，通过Neural Algorithmic Reasoning (NAR)框架，使神经网络能够学习执行经典机器人算法。经典机器人算法因其实现了可预测和一致的逻辑与数学性能，在机器人和安全关键应用中至关重要。相比之下，尽管神经网络高度适应能力，能够处理复杂、高维度的数据并在任务之间泛化，但在内部计算的可解释性和透明性方面存在不足。为了弥合这一差距，我们提出了一种基于图神经网络（GNN）的新型框架NAR-*ICP，该框架学习经典ICP配准算法的中间计算，拓展了CLRS基准。", "innovation": "提出了一种基于图神经网络（GNN）的新型框架NAR-*ICP，该框架能够学习经典ICP点云配准算法的中间计算，适用于真实世界和合成数据集。该方法提高了对复杂输入的灵活性，并展现了在大型学习管道中的潜力，与基线相比，其性能更优，甚至超过了其训练的算法，并进一步证明了其超越传统算法的能力。", "conclusion": "该方法在真实世界和合成数据集上的评估显示，其能够有效地处理复杂输入，并具有超越传统算法的泛化能力。NAR-*ICP为神经网络与经典算法的结合提供了一种有效方法，展示了其在机器人和安全关键应用中的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.06250", "html_url": "https://arxiv.org/abs/2501.06250", "title": "Generative AI for Cel-Animation: A Survey", "title_en": "Generative AI for Cel-Animation: A Survey", "authors": "Yolo Yunlong Tang,Junjia Guo,Pinxin Liu,Zhiyuan Wang,Hang Hua,Jia-Xing Zhong,Yunzhong Xiao,Chao Huang,Luchuan Song,Susan Liang,Yizhi Song,Liu He,Jing Bi,Mingqian Feng,Xinyang Li,Zeliang Zhang,Chenliang Xu", "background": "传统的手绘胶片（Cel）动画生产线包含多个关键步骤，如故事板绘制、布局设计、关键帧动画、中间帧插画和着色，这些步骤需要大量的手动努力、专业技术和显著的时间投入。这些挑战长期以来限制了Cel动画生产的效率和可扩展性。生成式人工智能（GenAI），涵盖大型语言模型、多模态模型和扩散模型，通过自动化中间帧生成、着色和故事板创作等任务，提供了创新解决方案。", "innovation": "GenAI通过自动化中间帧生成、着色和故事板创作等任务，革命性地改善了传统动画的工作流程，降低了技术障碍，扩大了创作者的可访问性，通过工具如AniDoc、ToonCrafter和AniSora，使艺术家能够更多地关注创造性表达和艺术创新。", "conclusion": "尽管GenAI在Cel动画中显示出巨大潜力，但仍存在视觉一致性、风格一致性和道德考量等方面的挑战。此外，本文探讨了AI辅助动画的未来方向和进步。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17384", "html_url": "https://arxiv.org/abs/2501.17384", "title": "A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning", "title_en": "A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning", "authors": "Zhengpeng Xie,Yulong Zhang", "background": "近期，得益于神经网络的强大功能，强化学习（RL）成功应对了许多具有挑战性的任务。然而，这些模型在展现增强的决策能力的同时，也越来越容易出现过拟合现象。例如，训练好的RL模型在任务的微小变化，如背景颜色改变或轻微的语义差异上，都难以泛化。因此，需设计新的方法来解决这个问题。", "innovation": "我们提出了一种双智能体对抗性策略学习框架，该框架允许智能体在没有引入任何先验人类知识的情况下，自发学习潜在的语义。该框架涉及两个智能体之间的游戏过程：每个智能体都力求通过产生相同状态下的表示差异来最大化对对手策略的影响，同时保持自身稳定免受这种干扰。这种互动促使智能体学习出可以处理高维观察中无关特征的一般性策略。实验结果表明，对抗过程显著提高了两个智能体的泛化性能，并应用于多种RL算法（如Proximal Policy Optimization，PPO），使得基于对抗框架的RL智能体在基础方法上显著胜出，特别是在高难度任务上，这标志着深度强化学习泛化能力的重要进展。", "conclusion": "双智能体对抗性框架在Deep RL中显著提高了泛化性能，特别是在高难度任务上，进一步展示了其在泛化能力上的重大进步。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05408", "html_url": "https://arxiv.org/abs/2501.05408", "title": "Tempo：符号依赖图支持的编译动态深度学习", "title_en": "Tempo: Compiled Dynamic Deep Learning with Symbolic Dependence Graphs", "authors": "Pedro F. Silvestre,Peter Pietzuch", "background": "传统的深度学习（DL）系统要么支持动态执行，这种执行方式不便于整程序优化；要么提供图基编译，但需要静态的张量形状，这强制用户填充张量或划分程序为多个静态图。这些系统都无法同时满足动态性和优化的需求。 Tempo旨在通过结合动态执行的灵活性与图基编译的优化能力，解决上述问题。具体来说，Tempo利用显式的时间维度构建符号依赖图，以表达动态的张量依赖关系，并在此基础上应用一系列优化技术。", "innovation": "Tempo通过引入带有显式时间维度的递归张量的声明式编程模型来创新。这种模型允许表达动态依赖，并自动构建符号依赖图。依赖图被用来进行编译时优化，如代数简化、矢量化、切分和融合。此外，Tempo通过块化动态关系来利用现有的静态代码生成功能，并通过多面体模型找到合理的执行时间表，包括内存管理操作。这些创新使得Tempo能够在不牺牲太多灵活性的情况下实现显著的性能提升。", "conclusion": "实验结果表明，Tempo在Llama-3.2-3B解码任务中实现了7倍的速度提升。对于强化学习算法，Tempo则实现了54倍的速度提升，同时内存使用峰值降低了16倍，充分展示了Tempo在优化性能方面的优越性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07218", "html_url": "https://arxiv.org/abs/2502.07218", "title": "通过神经激活重定向实现大规模语言模型去学习", "title_en": "LLM Unlearning via Neural Activation Redirection", "authors": "William F. Shen,Xinchi Qiu,Meghdad Kurmanji,Alex Iacob,Lorenzo Sani,Yihong Chen,Nicola Cancedda,Nicholas D. Lane", "background": "从LLMs中选择性地移除知识的需求尤为突出。然而，现有的方法往往难以平衡遗忘效果与保持模型实用性之间的关系，并且在推理时缺乏对基础模型行为的控制能力，仿佛从未见过已遗忘的数据。", "innovation": "本文介绍了一种新颖的去学习方法LUNAR，该方法基于线性表示假设，并通过将未学习数据的表示重定向至无法回答问题的激活区域来实现。证明对比特征不是有效激活重定向的必要条件，LUNAR在去学习性能与可控性方面都取得了最先进的结果。具体来说，LUNAR实现了在不同基础模型上2.9到11.7倍的效果和模型实用性的提升，去学习后生成了连贯、上下文相关的回应。此外，LUNAR通过单一下行投影矩阵减少参数更新，这一创新设计提高了效率和鲁棒性。", "conclusion": "LUNAR不仅实现了高水平的去学习性能和强大的可控性，还展示了对白盒对抗性攻击的鲁棒性以及在实际场景中的多功能性，包括处理序列表述的去学习请求。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17518", "html_url": "https://arxiv.org/abs/2501.17518", "title": "通过任意欧几里得区域实现类似双曲的表达性：一种新的层次嵌入方法", "title_en": "Achieving Hyperbolic-Like Expressiveness with Arbitrary Euclidean Regions: A New Approach to Hierarchical Embeddings", "authors": "Hui Yang,Jiaoyan Chen", "background": "在生命科学和电子商务等领域中，层级数据很常见，其嵌入往往起着关键作用。虽然双曲嵌入为在低维空间中表示层次结构提供了一种基于理论的方法，但当前的方法往往依赖特定的几何构造作为嵌入候选，这限制了其泛化能力和与建模语义关系的技术的集成能力，尤其是那些超越纯粹层次结构的本体嵌入方法。", "innovation": "本论文提出了一种灵活的欧几里得框架RegD，该框架支持任意几何区域（如盒形和球形）作为嵌入表示。虽然RegD在欧几里得空间中运行，但通过引入基于深度的距离度量，它实现了类似双曲的表达性，能够模拟双曲几何的一些关键属性，如下指数增长。实验结果表明，RegD在多种真实世界数据集上的性能优于现有最先进的方法，并展示了其在包括超越层次结构的本体嵌入任务在内的更广泛任务中的潜在应用。", "conclusion": "我们的实证评估表明，RegD在多种实际数据集上的一致性能提升，并且证明了其在本体嵌入任务等超越单纯层次结构应用中的潜在用途。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18169", "html_url": "https://arxiv.org/abs/2412.18169", "title": "KunServe：模型参数为中心的内存管理方法在大规模语言模型服务中的高效内存过载处理", "title_en": "KunServe: Parameter-centric Memory Management for Efficient Memory Overloading Handling in LLM Serving", "authors": "Rongxin Cheng,Yuxin Lai,Xingda Wei,Rong Chen,Haibo Chen", "background": "如今，使用GPU集群为大规模语言模型（LLM）提供服务是常见的做法，但这种服务系统需要满足应用程序严格的要求的响应时间（SLOs）。然而，LLM提供服务的有状态特性要求在有限的GPU内存中维护庞大的状态（即KVCache）。在实际工作负载的峰值期间，GPU内存可能会被耗尽，导致由于等待KVCache回收而引入的排队处理导致响应延迟大幅增加。先前的KVCache为中心的方法通过丢弃、迁移或交换KVCache来处理加载瓶颈。这些方法在请求仍处于排队状态的情况下无法迅速释放足够的内存。本文提出了第一个参数为中心的方法来处理瓶颈，通过选择性地丢弃复制的参数来立即释放内存，以便服务于请求。本文观察到模型参数通常在多个GPU上进行复制以供服务之用。通过减少排队处理中由于管道并行执行的性能开销，确保在丢弃下请求执行模式适用的情况下去设计技术，并合理推出一个不会产生不必要的合作的参数下掉计划。这使得参数为中心的方法既正确又高效。", "innovation": "本文提出了一种参数为中心的方法来处理内存过载问题，通过选择性地丢弃复制的模型参数来立即释放内存，这种做法克服了先前方法在请求仍然排队情况下无法迅速释放足够的内存的缺点。该方法还提出使用管道并行执行来协调请求在GPU上的执行，并设计了技术来最小化由于管道并行执行而产生的性能开销。评估结果表明，KunServe在让所有请求无排队情况下被服务方面，与最先进的系统（如Llumnix、vLLM和InferCept）相比，将请求的尾部TTFT降低了最高达72.2倍", "conclusion": "本文提出的方法通过选择性地丢弃复制参数来有效处理内存瓶颈，结合了管道并行执行技术来提高效率，并通过实验验证了其显著的性能改进。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01505", "html_url": "https://arxiv.org/abs/2503.01505", "title": "损失神经压缩在地球空间分析中的应用：综述", "title_en": "Lossy Neural Compression for Geospatial Analytics: A Review", "authors": "Carlos Gomes,Isabelle Wittmann,Damien Robert,Johannes Jakubik,Tim Reichelt,Michele Martone,Stefano Maurogiovanni,Rikard Vinge,Jonas Hurst,Erik Scheurer,Rocco Sedona,Thomas Brunschwiler,Stefan Kesselheim,Matej Batic,Philip Stier,Jan Dirk Wegner,Gabriele Cavallaro,Edzer Pebesma,Michael Marszalek,Miguel A Belenguer-Plomer,Kennedy Adriko,Paolo Fraccaro,Romeo Kienzler,Rania Briq,Sabrina Benassou,Michele Lazzarini,Conrad M Albrecht", "background": "过去几十年，地球观测（EO）数据的数量激增，卫星图像的前所未有的覆盖率产生了大量需要传输、存储和分发给终端用户的海量数据。现代地球系统模型（ESMs）也面临类似挑战，它们在高空间和时间分辨率下运行，每天生成数千兆字节的数据。神经压缩（NC）在过去十年中变得越来越重要，因为它可以从大量未标记的EO数据和ESM输出中提取和压缩特征。", "innovation": "该论文介绍了近期在NC领域应用到地理空间数据方面的进展，包括神经压缩的基本概念和传统应用，以及SSL和基础模型的发展如何促进从海量未标记数据中高效提取特征表示。此外，讨论了EO和ESM数据的特性，与自然图像相比较，这些数据提供了额外的挑战和机遇。", "conclusion": "从对NC在EO中的应用的综述中得出未来研究方向，特别是涉及EO和ESM的应用，强调可以利用压缩特征表示进行机器到机器通信的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17832", "html_url": "https://arxiv.org/abs/2502.17832", "title": "MM-PoisonRAG：利用局部和全局中毒攻击扰乱多模态RAG", "title_en": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks", "authors": "Hyeonjeong Ha,Qiusi Zhan,Jeonghwan Kim,Dimitrios Bralios,Saikrishna Sanniboina,Nanyun Peng,Kai-Wei Chang,Daniel Kang,Heng Ji", "background": "多模态大型语言模型结合检索增强生成（RAG），显著推进了多模态问答等任务，通过结合外部文本和图像来支撑回答，从而提高了事实性，减少了幻觉，并扩展了推理能力。但是，对外部知识的依赖也带来了一个重要的但未被充分探索的安全风险：知识投毒攻击，即攻击者故意将对抗性多模态内容注入到外部知识库中，操控模型生成错误甚至有害的回答。", "innovation": "本文提出了一种名为MM-PoisonRAG的新框架，这是首个系统设计多模态RAG中知识投毒的框架。作者引入了两种互补的攻击策略：局部投毒攻击（LPA），它植入针对性的多模态虚假信息来操控特定查询；全局投毒攻击（GPA），它插入单个对抗性知识来广泛干扰推理并引发所有查询的无意义回答。实验结果表明，LPA可以实现高达56%的攻击成功率，而GPA仅需注入单个对抗性知识即可完全破坏模型生成，准确率为0%。", "conclusion": "本文揭示了多模态RAG的脆弱性，并突显了对抗知识投毒防御的迫切需求。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02016", "html_url": "https://arxiv.org/abs/2503.02016", "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs", "title_en": "Mind the (Belief) Gap: Group Identity in the World of LLMs", "authors": "Angana Borah,Marwa Houalla,Rada Mihalcea", "background": "社会偏见和信念驱动行为对大型语言模型（LLMs）在多项任务中的决策有着显著的影响。随着LLMs在多代理系统中的使用愈加广泛，特别是在社会模拟中，它们建模基本群体心理特征的能力变得至关重要但尚未得到充分探索。", "innovation": "研究提出了一种多代理框架，以模拟信念一致性这一经典群体心理学理论。研究发现LLMs在信念一致性方面表现出与人类相比的增强表现，特别是在不同情境下。进一步研究发现，信念一致性在LLMs中的增强会加剧信息误传问题，并妨碍学习。为此，研究提出了受接触假说、准确性提示及全球公民框架启发的策略，并证明了这些策略能最多减少37%的信息误传，提高11%的学习效果。", "conclusion": "本研究将社会心理学与AI相结合，提供了使用LLMs进行现实世界互动时应对信念驱动偏见的见解。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07836", "html_url": "https://arxiv.org/abs/2504.07836", "title": "AerialVG: 通过探索位置关系构建具有挑战性的航空视觉定位基准", "title_en": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations", "authors": "Junli Liu,Qizhi Chen,Zhigang Wang,Yiwen Tang,Yiting Zhang,Chi Yan,Dong Wang,Xuelong Li,Bin Zhao", "background": "视觉定位(VG)旨在根据自然语言描述在图像中定位目标物体。传统的VG任务主要针对地面视角的图像，而本文提出AerialVG，专注于从航空视角进行视觉定位。与传统VG相比，AerialVG带来了新的挑战，例如，基于外观的定位不足以区分多个外观相似的对象，位置关系分析显得尤为重要。此外，现有的VG模型在应用于高分辨率的航拍图像时遇到困难。", "innovation": "本文提出了首个AerialVG数据集，包含5000张航拍图像、5万个手工标注的描述和10.3万个物体。每个标注包含多个带有相对空间关系的目标物体，要求模型进行综合的空间推理。此外，还提出了一种专门针对AerialVG任务的创新模型，其中包括层次交叉注意力机制和一种关系感知定位模块来推断位置关系。", "conclusion": "实验结果验证了AerialVG数据集和方法的有效性，突出了空中视觉定位中空间推理的重要性。代码和数据集将被发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.04486", "html_url": "https://arxiv.org/abs/2505.04486", "title": "使用潜变量的高效流匹配", "title_en": "Efficient Flow Matching using Latent Variables", "authors": "Anirban Samaddar,Yixuan Sun,Viktor Nilsson,Sandeep Madireddy", "background": "流匹配模型在概率生成模型中的图像生成任务中展示了巨大的潜力。然而，文献中的大多数流匹配模型在从标准高斯分布这样的简单源分布学习流时，并未明确利用目标数据中的潜在聚类结构。这导致了在处理高维度的实际世界数据集时学习效率低下，这些数据集通常存在于低维度流形中。", "innovation": "本文提出了Latent-CFM，它通过使用预训练的深度潜变量模型提取的数据特征条件化，提供了高效的训练策略。这种模型在合成数据和广泛使用的图像基准数据集上的实验表明，它在体素流和物理过程中生成的样本更加准确，并且相比最先进的流匹配模型，使用预训练的轻量级潜变量模型显著减少了训练时间和计算量。此外，我们的方法还可以进行条件图像生成，提高生成过程的可解释性。", "conclusion": "通过实验证明，Latent-CFM 在生成质量和效率上优于现有的流匹配模型，并且在条件图像生成方面具有更好的解释性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03654", "html_url": "https://arxiv.org/abs/2503.03654", "title": "使用数据和参数高效RL提高中立观点生成", "title_en": "Improving Neutral Point-of-View Generation with Data- and Parameter-Efficient RL", "authors": "Jessica Hoffmann,Christiane Ahlheim,Zac Yu,Aria Walfrand,Jarvis Jin,Marie Tano,Ahmad Beirami,Erin van Liemt,Nithum Thain,Hakim Sidahmed,Lucas Dixon", "background": "本文探讨了参数高效强化学习（PE-RL）在提高大型语言模型（LLMs）对敏感主题查询的中立观点（NPOV）回答能力方面的影响。PE-RL是一种高效的训练方法，可提供更加信息丰富、多样且公正的答案。通过与多个强劲基准方法（如LoRA微调、SFT和RLHF）的评估，作者证明了PE-RL不仅在整体NPOV质量上优于最强基线，还在语文学家认为区分足够的回答和“优秀”的回答的关键特征上得分为更高。此外，定量分析也支持这一结论，并且PE-RL具有一个关键特性：它能够超出主题范围，这与更新所有参数的方法不同。为了进一步研究，作者还发布了数据集SHQ-NPOV并提供了一种通过迭代的人类互评和注释器培训创建此类数据集的方法。", "innovation": "参数高效强化学习（PE-RL）作为一种高效的训练策略，在提升大型语言模型对敏感话题查询时提供中立、公正且信息丰富的回答方面表现优异。它不仅提高了整体中立观点质量，还在提供支持细节、避免简化回答方面表现更佳。此外，PE-RL具有从话题之外生成回答的关键特性，这与更新所有参数的方法不同。该研究还提供了一个数据集SHQ-NPOV，展示了如何创建此类数据集的方法。", "conclusion": "通过使用参数高效强化学习方法来训练大型语言模型，可以显著提高模型在生成中立观点方面的表现。这种方法不仅在整体评估上展现出显著改进，而且在特定的关键特征上也有更佳的表现。未来的工作将受益于作者提供的数据集和创建此类数据集的方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17353", "html_url": "https://arxiv.org/abs/2503.17353", "title": "NdLinear：保留多维度结构的高效神经网络组件", "title_en": "NdLinear: Preserving Multi-Dimensional Structure for Parameter-Efficient Neural Networks", "authors": "Alex Reneau,Jerry Yao-Chieh Hu,Zhongfang Zhuang,Ting-Chun Liu,Xiang He,Judah Goldfeder,Nadav Timor,Allen G Roush,Ravid Shwartz-Ziv", "background": "在深度学习中，处理具有多维输入（如图像、医学影像和时间序列）通常需要将这些输入展平才能被处理。这给神经网络设计带来了一定的局限。针对这个问题，本文介绍了一种名为$NdLinear$的新层，能够直接对张量进行操作，无需展平输入，从而保留了数据的原生结构。$NdLinear$通过分别沿每个维度进行变换，实现了参数量的大幅减少，通常可以减少到原始量的多个数量级，同时对内存消耗的影响也非常小。", "innovation": "本文提出了$NdLinear$，这是一种可以直接作用于张量的、替代线性层的模块。$NdLinear$通过沿各维度分别应用变换，能够在保持数据原生结构的同时，实现显著的参数量减少，而且内存占用几乎没有增加。此外，研究证明$NdLinear$通过结构化的Tucker分解方式维持了表达能力，同时控制了VC-维数的增长。实验结果表明，$NdLinear$不仅能够显著减少参数数量，还能实现较高的计算效率和较小的内存开销。", "conclusion": "实验结果证明了$NdLinear$在卷积神经网络（CNNs）、递归神经网络（RNNs）、变换器（Transformers）和多层感知机（MLPs）等模型上处理视觉、语言、时间序列和表格数据方面的高效性。尽管在处理轴分离任务时表现优异，但$NdLinear$在处理纠缠的空间相互作用时仍有局限。通过这种方式处理原始N维数据，$NdLinear$为构建更高效的神经架构提供了一个理论基础和技术支持。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.10478", "html_url": "https://arxiv.org/abs/2504.10478", "title": "WiSE-FT提高语言模型推理能力", "title_en": "Weight Ensembling Improves Reasoning in Language Models", "authors": "Xingyu Dang,Christina Baek,Kaiyue Wen,Zico Kolter,Aditi Raghunathan", "background": "研究了在推理模型训练过程中出现的一种失败模式，即生成的多样性开始坍塌，导致测试时的扩展性不佳。监督微调（SFT）期间Pass@1率可靠地提高，但Pass@k迅速恶化。", "innovation": "通过一种简单的干预方法——将最新SFT检查点的权重与早期检查点权重进行插值（WiSE-FT），几乎完全恢复了Pass@k，同时也提高了Pass@1。WiSE-FT变体在测试时的扩展性（Best@k，多数投票）更优，并且在通过强化学习进一步调整时能取得更好的效果。此外，WiSE-FT提供的性能增益无法仅通过促进多样性的解码策略，如温度缩放实现。作者还正式化了一个关于Pass@k相对于Pass@1在测试分布上的期望和方差之间的偏见-方差权衡。实验发现WiSE-FT能够同时减少偏见和方差，而温度缩放则在偏见和方差之间进行权衡。", "conclusion": "WiSE-FT能够同时改善模型在测试时的扩展性，实现更优的性能，且不需要大量的数据支持。相比传统的温度缩放等多样性促进策略，WiSE-FT提供了补充的性能增益。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.19945", "html_url": "https://arxiv.org/abs/2503.19945", "title": "在乳腺X线影像中优化乳腺癌检测：迁移学习、分辨率降低和多视图分类的综合研究", "title_en": "Optimizing Breast Cancer Detection in Mammograms: A Comprehensive Study of Transfer Learning, Resolution Reduction, and Multi-View Classification", "authors": "Daniel G. P. Petrini,Hae Yong Kim", "background": "乳腺X线摄影仍是乳腺癌早期检测的核心技术。近年来，人工智能的进步使得计算机辅助诊断方法越来越复杂，从基于补丁的分类器演进到全图像方法，再到结合分析互补投影的多视图架构。尽管取得了这些进展，但仍有许多关键问题未被解答。本研究系统地探讨了这些问题，通过五个核心研究问题：（1）补丁分类器在性能中的作用；（2）自然图像训练骨干网的迁移性；（3）学习调整大小相对于传统下采样的优势；（4）多视图集成的贡献；以及（5）结果在不同图像质量下的稳健性。", "innovation": "本研究通过实验展示了明显优于先前工作的性能提升。在CBIS-DDSM数据集上，单视图AUC从0.8153提高到0.8343，多视图AUC从0.8483提高到0.8658。通过一种新的比较方法，从单视图分析扩展到多视图分析，还观察到AUC提升了0.0217。在完整的VinDr-Mammo数据集上，多视图方法进一步提高了结果，单视图AUC提升0.0492，总体AUC达到0.8511。这些结果建立了新的最先进的基准，并提供了多视图架构在乳腺X线解释中的优势证明。此外，分析还提供了关于模型设计和迁移学习策略的基本原则性见解，为开发更准确可靠的乳腺癌筛查工具做出了贡献。", "conclusion": "这些结果表明，多视图架构在乳腺X线解释中具有显著优势，并且通过改进验证了迁移学习、分辨率降低和多视图分类策略的有效性。同时，研究还提供了更准确和可靠的乳腺癌筛查工具有利的模型设计和迁移学习策略的洞察。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10607", "html_url": "https://arxiv.org/abs/2505.10607", "title": "MONAQ：资源受限设备上时间序列分析的多目标神经架构查询", "title_en": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series Analysis on Resource-Constrained Devices", "authors": "Patara Trirat,Jae-Gil Lee", "background": "智能手机和物联网设备的使用增长促使在资源受限硬件上进行高效的时间序列分析变得至关重要，这对于传感应用如人类活动识别和空气质量预测至关重要。尽管最近在硬件感知的神经架构搜索（NAS）方面的努力已经自动化了特定平台的架构发现，但这些努力大多未关注边缘部署的一般时间序列分析。文章背景强调了当前技术的不足，即缺乏针对资源受限设备上的时间序列分析的自动化架构优化。", "innovation": "本文提出了一种名为MONAQ的新型框架，该框架将NAS重新定义为多目标神经架构查询任务。MONAQ融合了多模态查询生成和大语言模型（LLM）代理进行多目标搜索，从而实现通过代码生成部署就绪的模型。通过整合数值数据、时间序列图像和文本描述，MONAQ提高了LLM对时间序列数据的理解能力。实验结果表明，MONAQ发现的模型优于手工设计的模型和NAS基准模型，并且更加高效。", "conclusion": "实验展示了MONAQ框架在十五个数据集上的优势，表明其能够发现性能优越且高效的模型。MONAQ通过结合多模态查询生成和多目标搜索机制，针对资源受限设备上的时间序列分析提出了一种有效的自动化架构优化方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13055", "html_url": "https://arxiv.org/abs/2503.13055", "title": "通过具有自一致性功能的 affordance 引导和自一致性 MLLMs 来缓解跨模态干扰并确保几何可行性，以实现指令跟随的物体操作任务计划", "title_en": "Mitigating Cross-Modal Distraction and Ensuring Geometric Feasibility via Affordance-Guided and Self-Consistent MLLMs for Task Planning in Instruction-Following Manipulation", "authors": "Yu-Hong Shen,Chuan-Yu Wu,Yi-Ru Yang,Yen-Ling Tai,Yi-Ting Chen", "background": "现有基准没有全面评估 multimodal large language models (MLLMs) 在指令跟随操作任务规划中的跨模态干扰和几何不可行性。论文指出，成功的任务规划需要四个关键要求：数量估计、可达性分析、相对定位和碰撞避免，但当前基准无法在这些方面提供全面的评估。因此，研究者开发了 QuARC（Quantity、Analysis、Relative positioning、Collision）基准，基于食物准备场景综合了这四个挑战，以评估 MLLMs 的性能。研究检测了当前 MLLMs 的两个主要局限性：跨模态干扰和几何不可行性，这需要通过自一致性融合的链式推理方法和引入使用几何可行性的 affordance 预测器来解决。研究比较了多种基线模型，并解释了性能改进的来源，方法表现出了76.7%的成功率，远超 ViLa 基线的36.7%，并不需要额外的微调。已提供代码和数据集。", "innovation": "研究者提出了 QuARC 基准，整合了四个挑战：数量估计、可达性分析、相对定位和碰撞避免，弥补了现有封闭环任务规划的基准不足以全面评估 MLLMs 的缺陷。此外，研究者提出的解决方法包括：1) 对抗跨模态干扰：采用自一致性链式推理方法；2) 确保几何可行性：引入 affordance 预测器。方法在多个基线模型上进行了全面评估，显示了显著的性能改进，并且无需额外的微调。", "conclusion": "模型在 QuARC 基准上达到了76.7%的成功率，显著优于现有的 VIla 基线方法36.7%，同时该方法未进行额外的微调。研究通过识别 MLLMs 的局限性，并提出相关解决方案，为指令跟随操作任务规划的封闭环任务规划提供了新的进展。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.16379", "html_url": "https://arxiv.org/abs/2501.16379", "title": "FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks", "title_en": "FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks", "authors": "Jiarui Song,Yunheng Shen,Chengbin Hou,Pengyu Wang,Jinbao Wang,Ke Tang,Hairong Lv", "background": "个性化联邦学习（PFL）的目标是通过为每个客户端学习个性化的模型来解决客户端之间数据统计异质性的问题。虽然聚合基于个性化的方法在服务器端聚合阶段进行参数聚合以生成个性化的模型，专注于在聚合中学习客户端之间的适当合作关系，但这些合作关系在不同的场景中会有所不同，甚至在联邦学习（FL）过程的不同阶段也会有所不同。现有方法难以适应这些变化的关系，导致个性化模型的性能下降。为了解决这个问题，论文提出了FedAGHN，它利用注意力机制的图形超网络（AGHNs）来动态捕捉细粒度的合作关系，生成客户端特定的个性化初始模型。", "innovation": "FedAGHN 利用注意力机制的图形超网络（AGHNs）动态捕捉细粒度的合作关系，并生成客户端特定的个性化初始模型。AGHNs 赋予图形以明确建模客户端特定合作关系的能力，构建合作关系图，并引入可调注意力机制来推导合作权重，从而通过在合作图上聚合参数来获得个性化初始模型。该方法在广泛的实验中证明了其优越性，并通过一系列可视化探索了 FedAGHN 学习的合作图的有效性。", "conclusion": "FedAGHN 方法在联邦学习过程中，能够动态捕捉客户端之间的细粒度合作方案，从而生成更适应不同应用场景的个性化初始模型，从而提高了个性化联邦学习的性能。实验结果和可视化展示支持了这一结论。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07344", "html_url": "https://arxiv.org/abs/2505.07344", "title": "生成预训练自回归扩散变换器", "title_en": "Generative Pre-trained Autoregressive Diffusion Transformer", "authors": "Yuan Zhang,Jiacheng Jiang,Guoqing Ma,Zhiying Lu,Haoyang Huang,Jianlong Yuan,Nan Duan,Daxin Jiang", "background": "该研究旨在利用扩散和自回归建模的长程视频合成优势，提出了一种称为GPDiT的生成预训练自回归扩散变换器。该模型在连续的潜在空间中统一了这两种方法的优势，通过自回归地预测未来潜在帧来生成自然的运动动力学和跨帧语义一致性。这项研究还引入了轻量级因果注意力变体和基于旋转的时间条件机制，进一步提高了训练和推理效率。这种连续的自回归框架不仅提高了生成质量，还赋予模型表示能力。通过广泛的实验，研究结果证明了GPDiT在视频生成质量、视频表示能力和少样本学习任务中的优越表现，突显了其在连续空间视频建模中的潜力。", "innovation": "1. 统一了扩散和自回归建模，提出GPDiT模型在连续的潜在空间中进行长程视频合成。\n2. 采用基于扩散损失的自回归预测未来潜在帧，提升了运动动力学和跨帧语义一致性建模的自然性。\n3. 引入了轻量级因果注意力变体，提高了模型的训练和推理效率。\n4. 发明了一种无参数旋转基时序条件机制，进一步提升了模型的训练与推理效率。\n5. 实验验证了GPDiT在视频生成质量、视频表示能力和少样本学习任务中的优越表现，展示了其在连续空间视频建模中的潜力。", "conclusion": "GPDiT在连续空间视频建模中展现了强大的性能，不仅生成质量高，还具备视频表示能力，在少样本学习任务上也表现出优越性。此研究为视频模型提供了有效框架，特别是在连续空间中。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15946", "html_url": "https://arxiv.org/abs/2505.15946", "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "title_en": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "authors": "Yuxiang Wei,Yanteng Zhang,Xi Xiao,Tianyang Wang,Xiao Wang,Vince D. Calhoun", "background": "功能性磁共振成像(fMRI)可以通过解码视觉体验来帮助理解人类感知并开发高级脑-机接口。然而，当前的研究更多关注于图像重建的保真度，而忽视了可解释性这一重要的神经科学研究因素。", "innovation": "1. 提出了一个基于脑网络原理的新型混合专家架构，用于神经解码。\n2. 实现了跨被试的有效泛化，通过共享核心专家网络并在特定被试路由器上进行调整来适应各被试。\n3. 提供了对机制的增强性洞见，通过显式的路由方式揭示不同的建模脑区如何影响重建图象的语义和空间属性。", "conclusion": "MoRE-Brain 研究标记了一次重大飞跃，向着更加泛化和可解释的 fMRI 基础视觉解码技术迈进。相关代码将很快公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16834", "html_url": "https://arxiv.org/abs/2505.16834", "title": "SimpleDeepSearcher: 通过网页驱动的推理轨迹合成实现深入的信息寻找", "title_en": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis", "authors": "Shuang Sun,Huatong Song,Yuhao Wang,Ruiyang Ren,Jinhao Jiang,Junjie Zhang,Fei Bai,Jia Deng,Wayne Xin Zhao,Zheng Liu,Lei Fang,Zhongyuan Wang,Ji-Rong Wen", "background": "检索增强生成（RAG）系统通过在需要多步推理和迭代信息检索的复杂深层搜索场景中提升大型语言模型（LLMs），使得它们的能力得到了显著提高。然而，现有的方法存在关键限制，要么缺乏高质量的训练路径，要么在模拟环境中遭遇分布不匹配的问题，还面临着在实际部署中计算成本高昂的问题。", "innovation": "本文介绍了SimpleDeepSearcher，这是一种轻量级但有效的框架，它通过战略性数据工程而非复杂的训练范式来弥合这一差距。SimpleDeepSearcher通过模拟真实的用户在实时网络搜索环境中的交互来合成高质量的训练数据，并结合一个多准则筛选策略来优化输入和输出的质量和多样性。通过在五个涵盖不同领域的基准测试中进行实验，研究表明，仅使用871个精心筛选的数据样本进行策略性微调（SFT）就可以显著提高基于强化学习（RL）的基线方法的效果。", "conclusion": "我们的研究表明，系统地解决数据稀缺瓶颈，通过简单的训练样本策略性微调（SFT）可以为高效的深层搜索系统提供一条可行的途径。我们的工作为高效深搜索系统的开发提供了实用见解。我们的代码可以在以下链接获取：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11557", "html_url": "https://arxiv.org/abs/2505.11557", "title": "AC-LoRA: (几乎)无需训练的访问控制意识多模态LLM", "title_en": "AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs", "authors": "Lara Magdalena Lazier,Aritra Dhar,Vasilije Stambolic,Lukas Cavigelli", "background": "企业级大语言模型（LLMs）在组织内部的知识传播和管理中越来越受欢迎，但当前的LLMs存在敏感信息泄露的风险，尤其是在需要严格访问控制的环境中应用困难重重。因此，本文旨在解决这一问题，设计了一种称为AC-LoRA的端到端系统，该系统能够在保护敏感信息的同时，实现多模态LLM的访问控制。AC-LoRA通过为受权限控制的数据集维护单独的LoRA适配器，以及它们在数据集上进行微调的文档嵌入，确保了信息的强隔离性。", "innovation": "本文的主要创新在于AC-LoRA系统，该系统设计了一种几乎无需额外训练的方法来实现多模态LLM的访问控制。AC-LoRA能够根据用户查询与数据集的相似性为用户检索精确的LoRA适配器，并在必要时将多个适配器组合起来生成最终响应。这种机制确保了在不增加额外的LoRA路由训练成本的情况下，实现了多模态LLM的访问控制功能，并且在两个数据集上的评估结果显示，AC-LoRA能够达到或超越现有的最先进的基于LoRA混合的技术性能，同时提供了强大的信息隔离保障。此外，AC-LoRA的设计也可以直接应用于不同模态的其他场景中。", "conclusion": "本文提出了AC-LoRA系统，该系统能够在不显著增加额外训练成本的前提下，为多模态LLM实现严格的访问控制，同时提供强信息隔离，验证了其在两个数据集上的有效性，并展示了其应用潜力和灵活性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12576", "html_url": "https://arxiv.org/abs/2505.12576", "title": "AdaDim: 动态适应的维度调整以优化SSL表示动力学", "title_en": "AdaDim: Dimensionality Adaptation for SSL Representational Dynamics", "authors": "Kiran Kokilepersaud,Mohit Prabhushankar,Ghassan AlRegib", "background": "有效的自监督学习的关键因素之一是防止维度坍塌，这在高维表示空间（R）中占据较低维子空间时出现。SSL的优化策略通常涉及指导模型产生具有更高维数（H(R)）的R，通过鼓励特征的去相关性或样本在R中的均匀性来实现。更高的H(R)表明R具有更大的特征多样性，这对下游任务的泛化是有益的。除了对维度进行优化，SSL算法还利用一个投影头，将R映射到嵌入空间Z。最近的工作已经将投影头视为通过减少R与Z之间的互信息I(R;Z)来过滤SSL目标中的噪声或无关特征。因此，当前的观点是，良好的SSL表示空间应该具有高的H(R)和低的I(R;Z)。然而，这一观点缺乏对这些术语之间关系的根本训练动态的理解。我们的分析表明，性能最佳的SSL模型并非具有最高的H(R)或最低的I(R;Z)，而是成功找到了两者的平衡。", "innovation": "本文提出了一种训练策略AdaDim，通过自适应地平衡特征去相关增加H(R)和逐步正则化I(R;Z)来利用SSL的训练动态。尽管不使用昂贵的技术（如队列、聚类、预测网络或教师-学生架构），但该方法在与常见SSL基准相比取得了高达3%的性能提升。", "conclusion": "性能最佳的SSL模型不仅仅是高H(R)和低I(R;Z)，而是找到了两者之间的平衡。AdaDim通过动态适应性调整来实现这一目标，从而在不使用昂贵技术的情况下提升SSL性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22598", "html_url": "https://arxiv.org/abs/2505.22598", "title": "机器学习辅助蒙特卡洛方法在从简单统计物理模型中采样的效能", "title_en": "Performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models", "authors": "Luca Maria Del Bono,Federico Ricci-Tersenghi,Francesco Zamponi", "background": "近年来，机器学习技术被广泛应用于辅助难以采样的系统模拟，这些系统无法通过传统方法研究。虽然已经提出了许多不同的架构和流程，但对这些方法的理论理解仍然不足，存在次优实现的风险。", "innovation": "本文提供了一个完整的分析，研究了广泛使用的顺序调温（Sequential Tempering）处理方法在浅层MADE架构下的库瑞-韦特定律模型（Curie-Weiss model）上的应用。本文的贡献有两个方面：首先，给出了解最优权重和梯度下降优化下的训练过程描述。其次，比较了有无局部马尔可夫蒙特卡洛步骤的顺序调温方法，从而给出了在这种情况下的最佳方法的理论预测。这项工作为将机器学习技术整合到蒙特卡洛采样和优化中奠定了清晰的理论基础。", "conclusion": "本文为此类型的蒙特卡洛分析和优化问题提供了一个理论框架。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17967", "html_url": "https://arxiv.org/abs/2505.17967", "title": "基于FFT的动态子空间选择在大型语言模型低秩自适应优化中的应用", "title_en": "FFT-based Dynamic Subspace Selection for Low-Rank Adaptive Optimization of Large Language Models", "authors": "Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh", "background": "低秩优化已成为训练大型语言模型（LLMs）以提高运行时间和减少自适应优化器的内存使用的一种有前景的方向。传统方法通常使用奇异值分解（SVD）或QR分解投影线性层的梯度到低维空间。然而，将这些技术应用于大型模型中的每个层都是计算成本高昂的，并且会增加额外的内存成本，因为需要存储投影矩阵。", "innovation": "本文提出了一种计算效率高且概念简单的两步方法，通过使用离散余弦变换（DCT）的预定义正交矩阵近似基于SVD/QR的梯度投影到低维空间的方法。根据每一层梯度与DCT矩阵列的对齐程度动态选择列。这些有效的投影矩阵通过简单的矩阵乘运算获得并在O(n^3)时间复杂度下完成，接着通过轻量级排序步骤识别最相关的基向量。对于大层，可以使用基于快速傅里叶变换（FFT）的Makhoul N点算法以O(n^2 log(n))的时间复杂度计算DCT。由于预定义的正交基，它们只需在训练开始时计算一次。我们的数值实验表明，我们的双策略在近似最优低秩投影方面是有效的，得到了与昂贵的SVD/QR 方法性能相似但具有独立于秩的运行时间和更低内存使用的方法。在不同模型规模上，我们的方法可以实现最多25%的加速。", "conclusion": "我们的方法在预训练和微调任务上的数值实验表明，它能在保持与其他昂贵的SVD/QR基于方法相同性能的同时，有效地减少运行时间和内存使用，特别是在大模型上，我们的方法可将运行时间加速25%，实现更低的内存使用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23867", "html_url": "https://arxiv.org/abs/2505.23867", "title": "InfiMed：资源有限的医学多模态大语言模型，能力不断进步的理解与推理", "title_en": "InfiMed: Low-Resource Medical MLLMs with Advancing Understanding and Reasoning", "authors": "Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大型语言模型（MLLMs）在视觉理解和数学推理等领域取得了显著进展，但在医学领域的应用受到两个关键挑战的限制：1）多模态医学数据稀缺且信息稀疏，限制了推理深度；2）尽管强化学习结合可验证奖励（RLVR）在一般领域有效，但在医学领域中并不能可靠地提升模型性能。", "innovation": "在监督微调（SFT）阶段，作者结合高质量的文本推理数据和通用多模态数据，以及多模态医学数据，以高效增强基础医学能力并恢复基础模型的推理能力。此外，鉴于某些多模态医学数据包含稀疏信息，作者进一步合成反射模式注入的想法链（CoT），并结合一般的CoT样本，赋予模型初始的反思推理能力，为后续RLVR训练提供结构化的基础。最后，作者引入了InfiMed系列模型InfiMed-SFT-3B和InfiMed-RL-3B，在七个多模态医学基准测试中实现了最先进的性能，其中InfiMed-RL-3B的平均准确率为59.2%，优于更大规模的模型InternVL3-8B的57.3%。", "conclusion": "研究在SFT阶段使用了188,000个样本，在RLVR阶段使用了36,000个样本，证明了这两种训练策略的有效性。同时，进行了广泛的实验，提供了宝贵的经验，有助于提高MLLMs在医学场景中的性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18356", "html_url": "https://arxiv.org/abs/2505.18356", "title": "模型合并对于LLMs跨语言迁移的意外有效性", "title_en": "The Unreasonable Effectiveness of Model Merging for Cross-Lingual Transfer in LLMs", "authors": "Lucas Bandarkar,Nanyun Peng", "background": "大型语言模型（LLMs）在高资源语言之外的任务上仍然表现不佳。本文研究了在特定任务数据稀缺的情况下，如何将LLMs应用于低资源语言的跨语言迁移。", "innovation": "本文通过验证最相关的模型参数集在数学推理和多语言能力上没有重叠，进而开发和分析了多个模块框架，这些框架在微调过程中改善了目标语言和任务参数的组合。研究还展示了在缺乏本语言数学数据的情况下，模块化方法能够提高模型在三种语言、四种模型和两种微调方案上的性能。", "conclusion": "研究发现，分离语言和数学专家进行微调，并使用Layer-Swapping进行模型合并是最稳定有效的模块方法。这一结果通过最近工作的新线性任务向量进行了解释，并通过实验证明了撤销不太有用的微调更新往往比一开始就冻结这些更新更优。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05516", "html_url": "https://arxiv.org/abs/2506.05516", "title": "学习恢复：轮足协调下的动态奖励塑造在摔倒机器人中的应用", "title_en": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots", "authors": "Boyuan Deng,Luca Rossini,Jin Wang,Weijie Wang,Dimitrios Kanoulas,Nikolaos Tsagarakis", "background": "对于装有轮腿的机器人来说，从跌倒中快速恢复是一项关键技能。这类机器人结合了轮子的高速度和腿的灵活性，但在传统的基于预规划恢复动作、简化动力学或稀疏奖励的方法中，这种恢复策略往往不够鲁棒。因此，该论文旨在探索一种新的基于学习的框架，通过动态调整奖励和强化学习来实现更有效的跌倒恢复策略。", "innovation": "论文提出了一种基于奖励塑造的学习框架，该框架结合了基于事件的动态奖励塑造和递进学习，能够在多样化恢复方法探索和精确姿态修正间取得平衡。此外，通过利用模拟中的优先信息和噪声注入的观测来加速训练，并且展示了这种方式在不同平台上都具有较高的恢复成功率，高达99.1%和97.8%，而不需要对特定平台进行调整。轮足协调进一步减少了关节扭矩消耗，并通过能量转移机制提高了稳定性能。", "conclusion": "该研究表明，基于事件的动态奖励塑造和递进学习相结合的方法能够提高机器人从跌倒中恢复的成功率，同时降低了关节扭矩消耗，增强了机器人在面对不确定性时的稳定性。研究结果在两种不同的四足机器人平台上都得到了验证。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02548", "html_url": "https://arxiv.org/abs/2506.02548", "title": "CyberGym: 评估AI代理在大规模真实世界网络安全能力", "title_en": "CyberGym: Evaluating AI Agents' Real-World Cybersecurity Capabilities at Scale", "authors": "Zhun Wang,Tianneng Shi,Jingxuan He,Matthew Cai,Jialin Zhang,Dawn Song", "background": "AI代理在网络安全方面具有巨大的重塑潜力，因此对其能力进行全面评估至关重要。然而，现有的评估存在不足之处，因为它们依赖于小型基准测试，并只测量静态结果，未能捕捉到真实世界安全挑战的全范围动态变化。具体而言，现有评估方法忽视了漏洞的动态特性，以及它们如何影响系统的安全状态，从而无法全面评估AI代理在动态环境中的表现。另外，现有基准测试规模较小，无法提供全面的真实世界测试场景，影响了评估的准确性与实用性。因此，亟需一种能够全面评估AI代理应对复杂、动态的真实世界网络安全挑战能力的评价方法。", "innovation": "提出了CyberGym，这是一种大规模基准测试，包含1,507个实际漏洞分布在188个软件项目中。CyberGym可以根据不同的漏洞分析设置进行调整，并主要要求代理生成能够重现特定漏洞概念验证测试用例，仅根据漏洞的文本描述和对应的代码库。此外，研究还显示CyberGym不仅能够有效评估AI代理和模型的网络安全能力，还能够发现35个零日漏洞和17个历史不完整的补丁。这些发现不仅证明了CyberGym作为衡量AI在网络安全领域进展的坚实基准的重要性，还使其成为产生直接现实世界安全影响的平台。", "conclusion": "CyberGym为评估AI代理在网络安全领域的实际表现提供了一个系统而全面的平台，不仅能有效识别AI代理和模型之间的差异，还能指导发现新的安全漏洞，推动网络安全技术的进步。此研究为未来的相关研究提供了一种新的基准测试方法，使得现有的评估手段更具代表性和实际应用价值。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11031", "html_url": "https://arxiv.org/abs/2506.11031", "title": "预填充的答案可增强对AI生成图像的零样本检测", "title_en": "Prefilled responses enhance zero-shot detection of AI-generated images", "authors": "Zoher Kachwala,Danishjeet Singh,Danielle Yang,Filippo Menczer", "background": "随着AI模型生成的图像越来越逼真，人们对可能被误用的担忧日益增加，强调了可靠检测的必要性。传统监督检测方法依赖大量精心策划的数据集进行训练，并经常无法在新型图像生成器上泛化。与之相对，论文探索了预训练的视觉-语言模型（VLMs）在零样本检测AI生成图像上的应用。", "innovation": "论文在预训练VLMs的基础上，提出了通过简单响应预填充（称为Pre-fill Guided Thinking，PGT）的方法，来提高其检测性能。特别是，预填充一个与任务对齐的短语“让我们检查风格和合成伪影”，能够提高三种常用的开源VLMs的宏观F1分数，最多提高24%。", "conclusion": "通过简单的响应预填充方法，可以有效指导基于预训练的视觉-语言模型的推理，以实现对AI生成图像的更有效的零样本检测。这一方法提高了现有VLMs在多个基准测试中的性能，展示了预填充方法在提高检测准确性和鲁棒性方面的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06541", "html_url": "https://arxiv.org/abs/2506.06541", "title": "KramaBench: 一种针对数据湖上数据到见解管道的AI系统基准", "title_en": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "authors": "Eugenie Lai,Gerardo Vitagliano,Ziyu Zhang,Om Chabra,Sivaprasad Sudhir,Anna Zeng,Anton A. Zabreyko,Chenning Li,Ferdi Kossmann,Jialin Ding,Jun Chen,Markos Markakis,Matthew Russo,Weiyang Wang,Ziniu Wu,Michael J. Cafarella,Lei Cao,Samuel Madden,Tim Kraska", "background": "构建现实世界的数据到洞察管道通常涉及从数据湖中提取数据，跨异构数据源进行数据集成，以及从数据清洗到分析的多样化操作。数据科学管道的设计和实现需要领域知识、技术专长，甚至特定项目的见解。尽管AI系统在推理、编码和理解方面表现出了显著的能力，但这些能力在设计和执行复杂的数据科学管道时的具体应用尚不明确。本文介绍了一套名为KRAMABENCH的基准，包含104个手工策划的真实世界数据科学管道，涉及24个数据源的1700个数据文件，涵盖六个不同的领域。这些管道综合了数据发现、清洗、高效处理、统计推理和根据高层次任务编排数据处理步骤的能力。", "innovation": "本文提出了KRAMABENCH基准，包含104个手动策划的真实世界数据科学管道，覆盖了数据科学管道设计和实施所需的各种功能，主要包括数据发现、清洗、高效处理、统计推理和根据高层次任务编排数据处理步骤。还使用参考框架DS-GURU为AI模型提供了指导，将问题分解为一系列子任务，并逐步推理以生成实现设计的Python代码。研究表明，虽然现有模型在清楚界定的数据科学代码生成任务上表现良好，但在需要广泛的数据处理和领域知识来构建真实世界的数据科学管道时，现有现成模型仍然不足以胜任。KramaBench的进展代表了开发面向现实应用场景的自主数据科学代理的关键步骤。", "conclusion": "KramaBench的结果表明，尽管现有的现成模型能够充分解决明确规定的数据科学代码生成任务，但在构建需要大量数据处理和领域知识的真实世界数据科学管道时，现有模型仍显得不足。KramaBENCH为开发自主数据科学代理以解决现实应用场景中数据科学管道的构建提供了关键步骤。代码、参考框架和数据可在以下网址获取。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10974", "html_url": "https://arxiv.org/abs/2506.10974", "title": "AutoMind：自动数据科学中的适应性知识型代理", "title_en": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science", "authors": "Yixin Ou,Yujie Luo,Jingsheng Zheng,Lanning Wei,Zhuoyun Yu,Shuofei Qiao,Jintian Zhang,Da Zheng,Yuren Mao,Yunjun Gao,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLM）代理在处理实际数据科学问题方面显示出巨大潜力，但现有的框架依赖于僵化的预定义工作流和固定的编程策略，这限制了它们在复杂、创新任务上的有效性。", "innovation": "AutoMind框架通过三个方面实现了创新：（1）一个精心编排的专家知识库，使代理能够扎根于专业领域知识；（2）一种有代理知识的树搜索算法，能够战略性地探索各种可能的解决方案；（3）一种自适应的编程策略，能够根据任务复杂度动态调整代码生成。", "conclusion": "在两个自动化数据科学基准上的评估表明，AutoMind的表现优于最先进的基线。进一步的分析证实了它在有效性和量化解决方案质量方面的优势，将其定位为自动数据科学的高效、稳健步骤。相关代码可访问：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18824", "html_url": "https://arxiv.org/abs/2506.18824", "title": "理解软件工程代理：Thought-Action-Result 轨迹研究", "title_en": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories", "authors": "Islem Bouzenia,Michael Pradel", "background": "大型语言模型（LLM）驱动的代理被广泛用于自动化复杂的软件工程任务，如程序修复和问题解决。这些代理通过自主生成自然语言思考、调用外部工具并迭代优化解决方案来运行。尽管它们得到广泛应用，但代理的内部决策过程仍然鲜为人知，限制了我们对其操作动态和失败模式的理解。本文通过大规模实证研究了三种最先进的LLM驱动代理（RepairAgent、AutoCodeRover和OpenHands）的思考-行动-结果轨迹，旨在填补这一空白。", "innovation": "本文通过将三种最先进的LLM驱动代理的交互日志统一大纲格式，并采用包括结构特性定量分析、行动模式和词使用频率分析的量化方法与推理连贯性和反馈整合的定性评估相结合来研究其交互轨迹。本文揭示了成功执行与失败执行之间的行为模式和反模式，为进一步改进代理设计提供了操作性的见解，包括提示策略、故障诊断和反模式检测。同时，本文还公开了数据集和注解框架，为透明和稳健的自主软件工程代理的研究提供支持", "conclusion": "本文通过大规模实证研究，结合定量和定性方法，识别并分析了三种LLM驱动代理在编程修复和问题解决中的关键轨迹特征。研究结果揭示了成功执行和失败执行之间的区别，为改进代理设计提供了具体见解，并公开了数据集和注解框架，以支持未来的研究。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15828", "html_url": "https://arxiv.org/abs/2506.15828", "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning", "title_en": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning", "authors": "Emanuele Musumeci,Michele Brienza,Francesco Argenziano,Abdel Hakim Drid,Vincenzo Suriani,Daniele Nardi,Domenico D. Bloisi", "background": "背景经典规划方法（如PDDL）虽然提供结构和保证，但在存在感知噪声和谓词绑定错误的现实复杂环境中却难以应用。另一方面，基于大型语言模型（LLMs）的规划方法虽能利用常识推理，但经常提出不可行或不安全的动作。因此，作者旨在结合这两种方法，提出了ContextMatters框架，以实现分层目标放松，使原本不可行的任务变为可行，并通过常识推理帮助符号与环境对齐，逐步放松约束条件，使目标适应代理环境的上下文。实验结果表明，与现有最先进的LLMs+PDDL基线相比，成功率提高了52.45%，验证了方法的有效性，并在现实世界场景中部署在TIAGo机器人上。", "innovation": "创新作者提出了ContextMatters框架，该框架结合了大型语言模型和经典规划方法，通过分层目标放松机制实现了在3D场景规划中目标的灵活调整，使得原本不可行的任务变成可执行的计划。通过常识推理，LLMs帮助符号与现实环境对齐，并在目标不可达时提出功能等效的目标，逐步放松约束，适应代理环境的特定上下文。这种方法显著提高了任务的成功率，并在真实世界场景中的验证进一步证明了其有效性。", "conclusion": "结论作者通过ContextMatters框架将大型语言模型与经典规划方法相结合，有效解决了传统规划方法在复杂现实环境下的不足，且实现了3D场景中不可达目标的逐步放松与现实适应，提高了任务的成功率。这种方法不仅适用于虚拟环境中的规划，还在真实机器人实验中得到了验证。作者还提供了代码、数据集和补充材料供社区参考。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23274", "html_url": "https://arxiv.org/abs/2506.23274", "title": "推理语言模型中的实时进度预测", "title_en": "Real-Time Progress Prediction in Reasoning Language Models", "authors": "Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard", "background": "近期，特别是那些使用长而隐式的推理链的语言模型，在处理复杂且主动的任务时展现了令人瞩目的能力。然而，随着这些模型在越来越长的时间范围内运行，其内部进展变得难以让用户理解，这使得期望管理和实时监督变得复杂。已有研究调查了实时进度预测的可能性，并通过离散化进度和训练线性探测器来分类推理状态，进而提出了一种双阶段微调方法，使推理模型在推理过程中能够生成从0%到100%的进度估计。", "innovation": "该研究提出了一种双阶段微调方法，使推理模型能够在推理过程中生成从0%到100%的进度估计，从而提供了一种在实时环境中监测和解释模型推理的实用机制。并且，最佳微调模型对于少于16,000个标记的序列，平均误差为10%，表明其具备有效的实际应用价值。", "conclusion": "研究表明，通过离散化进度并训练线性探测器，以及利用双阶段微调方法，推理模型可以在推理过程中实时生成进度估计，平均误差在10%以内，为实时监控和解释模型推理提供了有效的工具。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05306", "html_url": "https://arxiv.org/abs/2507.05306", "title": "多分类逻辑族带宽中的非线性之美", "title_en": "Enjoying Non-linearity in Multinomial Logistic Bandits", "authors": "Pierre Boudart(SIERRA),Pierre Gaillard(Thoth),Alessandro Rudi(PSL, DI-ENS, Inria)", "background": "该研究涉及多分类逻辑族带宽问题，这是行动者通过根据多种可能结果的概率反馈最大化期望奖励来与环境互动的一种变体。在二分类设置中，近期工作关注了解释逻辑模型非线性的影响（Faury等人，2020；Abeille等人，2021）。研究表明，存在一个取决于问题参数的常数κ*，它可以非常大，由Sigmoid函数的导数表示，它能体现非线性并使得基于T轮的遗憾保证从O(d√T)提高至O(d√T/κ*)。", "innovation": "研究扩展了对多分类逻辑族带宽框架的分析，使其适用于多种选择的复杂应用场景，如强化学习或推荐系统。提出了一个适用于多分类设置的新κ*定义，并设计了一种高效算法，利用问题的非线性。该方法在T轮的竞争中将遗憾保障从O(R dK √T)改进至O(̃(R d √(KT/κ*))），并且提供了下界结果，证明了所提算法的最小化最优性及κ*定义的最优性。", "conclusion": "研究结果表明，通过巧妙利用多分类逻辑族带宽框架中的非线性，可以大幅改进现有的遗憾保障，在复杂应用场景中具有显著的优势。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.18562", "html_url": "https://arxiv.org/abs/2507.18562", "title": "GIIFT：图引导的诱导无图多模态机器翻译", "title_en": "GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation", "authors": "Jiafeng Xiong,Yuting Zhao", "background": "多模态机器翻译（MMT）表明视觉信息对机器翻译有显著的帮助。然而，现有的MMT方法在利用模态差距时面临挑战，强制执行严格的视觉-语言对齐，同时仅限于在训练的多模态域内进行推理。", "innovation": "构建了新颖的多模态场景图以保留和整合特定模态的信息，并引入了一个基于图的双阶段诱导无图像的多模态机器翻译（GIIFT）框架，该框架使用跨模态图注意网络适配器在统一融合空间中学习多模态知识，并诱导性地推广到更广泛的无图像翻译领域。", "conclusion": "在Multi30K数据集的英语到法语和英语到德语任务上进行的实验表明，我们的GIIFT超越了现有方法，并实现最先进的技术水平，即使推理时没有图像。在WMT基准测试中，GIIFT在无图像翻译基线上的结果显示了明显的改进，证明了其在诱导无图像推理方面的强大能力。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08333", "html_url": "https://arxiv.org/abs/2507.08333", "title": "基于标记的音频修复通过离散扩散", "title_en": "Token-based Audio Inpainting via Discrete Diffusion", "authors": "Tali Dror,Iftach Shoham,Moshe Buchris,Oren Gal,Haim Permuter,Gilad Katz,Eliya Nachmani", "background": "音频修复旨在恢复被破坏录音中缺失的部分。以往基于扩散的方法在缺失区域较大时表现不佳。本文提出了首个采用预训练音频标记器的标记化音乐表示进行离散扩散的方法，从而实现稳定的、语义上连贯地修复长缺口。此外，该方法还结合了两种训练策略：基于导数的正则化损失以确保平滑的时间动态，以及基于跨度的吸收转换，以在扩散过程中提供结构化的腐蚀。实验结果表明，在使用最长750毫秒缺口的MusicNet和MAESTRO数据集上，该方法在150毫秒或更长时间的缺口上表现始终优于强大的基线方法。", "innovation": "引入首个使用预训练音频标记器对标记化音乐表示进行离散扩散的方法，解决了先前方法在处理大缺失区域时表现不佳的问题。此外，该方法还结合了基于导数的正则化损失和基于跨度的吸收转换，提高了音频修复的稳定性和语义一致性。", "conclusion": "本研究提升了音乐音频修复技术，提出了新的离散扩散模型训练方向。实验结果显示，该方法在MusicNet和MAESTRO数据集上的表现优于现有基线方法，特别是在150毫秒以上的缺口修复方面。音频示例可在此 [音频链接] 查看。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12117", "html_url": "https://arxiv.org/abs/2507.12117", "title": "多量子比特相空间中的量子机器学习I：基础", "title_en": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations", "authors": "Timothy Heightman,Edward Jiang,Ruth Mora-Soto,Maciej Lewenstein,Marcin Płodzień", "background": "量子机器学习（QML）利用量子力学系统的固有特性，如叠加、相干性和量子纠缠来进行经典数据处理。然而，由于希尔伯特空间的指数增长，QML 在使用量子系统的态矢量表示法进行经典模拟时面临实际限制。另一方面，相空间方法提供了一种替代方案，将量子状态编码为准概率函数。基于现有有关量子比特相空间及其斯特拉托诺维奇-韦尔（SW）对应的研究，构建了一个封闭且可组合的动力学形式化系统，适用于单量子比特和多量子比特系统在相空间中的表示。", "innovation": "该研究通过相空间方法，克服了传统态矢量表示法的局限性，为量子机器学习提供了新的路径。具体而言，构建了一种封闭且可组合的动力学形式化系统，将Pauli群的操作代数替换为辛流形上的函数动态学，并将维度灾难重新解释为随量子比特数量线性增长的谐波支撑问题，这为基于相空间的变分模型开辟了新的途径。", "conclusion": "该研究提出了在多量子比特相空间中进行量子机器学习的基础框架，克服了传统方法的限制，为QML的发展提供了一种新的思路和技术路径。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06635", "html_url": "https://arxiv.org/abs/2508.06635", "title": "使用不完善的合成数据进行有效推断", "title_en": "Valid Inference with Imperfect Synthetic Data", "authors": "Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder", "background": "随着大规模语言模型在有限数据情境下的应用（如计算社会科学和人类主体研究领域的支持）愈发广泛，人们开始探索利用模型预测标签处理未标记数据的可能性。然而，对于如何在合成数据和真实数据结合后依然能够得出统计上有效的结论，目前尚无明确的方法。本文探讨了在这一背景下的挑战。", "innovation": "作者提出了一个基于广义矩方法的新估计器，提供了一个无需超参数的方法，并具有较强的理论保障，解决了这一问题。研究发现，合成数据与真实数据之间的时刻残差交互（即它们相互预测）可以显著提升目标参数估计的效果。", "conclusion": "研究验证了在不同的计算社会科学任务中所提出估计器的有限样本性能，展示出巨大的经验效益。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04174", "html_url": "https://arxiv.org/abs/2508.04174", "title": "通过能量扩散发现拟团", "title_en": "Quasi-Clique Discovery via Energy Diffusion", "authors": "Yu Zhang,Yilong Luo,Mingyuan Ma,Yao Chen,Enqiang Zhu,Jin Xu,Chanjuan Liu", "background": "发现具有给定边密度阈值的拟团是图挖掘中的基本任务，应用于网页垃圾检测、欺诈筛查和电商推荐等领域。然而，现有方法在大规模网页图上发现拟团时容易受到随机种子的影响或缺乏明确的边密度保证，使得实践中的任务具有挑战性。", "innovation": "提出了一种基于能量扩散的方法（EDQC）用于发现拟团。EDQC首先使用自适应能量扩散过程生成能量排名，以突出结构上一致的区域。该算法在能量排名的引导下通过最小化导纳（社区检测的标准指标）识别高质量子图，然后进一步调整以满足指定的密度阈值。实验结果表明，EDQC在大多数数据集上找到更大的拟团，并且各次运行之间的差异很小，且运行时间具有竞争力。据我们所知，EDQC是第一个将能量扩散纳入拟团发现的方法。", "conclusion": "EDQC通过能量扩散技术发现拟团，并通过自适应的导纳最小化和密度调整过程，实现了对拟团的高效和稳定的发现。在75个真实图的广泛实验中，EDQC表现出对大部分数据集的改进，且具有较低的运行时变异性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02298", "html_url": "https://arxiv.org/abs/2508.02298", "title": "CAPO：通过生成式信用分配提升大语言模型推理能力", "title_en": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit Assignment", "authors": "Guofu Xie,Yunsheng Shi,Hongtao Tian,Ting Yao,Xiao Zhang", "background": "当前的可验证奖励（RLVR）方法通过基于规则的二进制反馈改善了大语言模型（LLMs）的推理能力，但通常赋给每个标记相同的奖励。这种粗粒度的反馈阻碍了精确的责任归属，使得模型难以识别导致成功或失败的具体推理步骤，常常导致次优策略。虽然诸如PPO等方法可以通过价值估计进行责任归属，但仍因有限的采样而产生不准确且不可验证的信号。而使用过程奖励模型的方法虽然能够提供分步奖励，但存在高要求的过程监督标签、基于概率的奖励模型导致的反馈不可靠，以及在线强化学习中的应用耗时等问题。", "innovation": "提出了一种简单而有效的Credit Assignment Policy Optimization（CAPO）方法。CAPO直接利用现成的通用LLM作为生成过程奖励模型（LLM-as-GenPRM）来生成基于步骤正确性的分步批评，提供精确的标记级别的反馈，以调整原本相同规则奖励的标记。为了进一步提高准确性和鲁棒性，使用了随着生成批评数量增加的投票机制。实验结果表明，CAPO在各种基础模型（如Llama和Qwen）上的一致性表现优于基于监督学习和基于强化学习的微调方法，在四个具有挑战性的数学基准和三个离域基准上都优于现有方法。", "conclusion": "CAPO可以帮助模型培养正确的推理路径，从而得出正确的答案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01861", "html_url": "https://arxiv.org/abs/2508.01861", "title": "ACT-Tensor：针对金融数据集插补的张量完成框架", "title_en": "ACT-Tensor: Tensor Completion Framework for Financial Dataset Imputation", "authors": "Junyi Mo,Jiayu Li,Duo Zhang,Elynn Chen", "background": "在金融面板数据中缺失数据是一个关键障碍，它削弱了资产定价模型的有效性，并减少了投资策略的效果。这些面板通常包括多个维度，如公司、时间以及财务变量，这增加了插补的复杂性。传统方法常常通过平滑数据的多维结构、应对异质性缺失模式或者在极端数据稀疏性面前过度拟合来失效。", "innovation": "我们引入了一种适应性、基于聚类的时间平滑张量完成框架（ACT-Tensor），专门用于处理严重且异质性缺失的多维金融数据面板。ACT-Tensor 的两大创新点为：基于聚类的完成模块，它通过学习组别特定的潜在结构来捕捉横截面的异质性；以及时间平滑模块，它积极去除短暂的噪声，同时保留缓慢移动的基本趋势。广泛实验表明，不论在何种缺失数据模式下，包括极端稀疏情况，ACT-Tensor 在插补准确性方面始终优于最先进的基准方法。", "conclusion": "为了评估其在实际金融中的实用性，我们用一个针对张量结构金融数据定制的资产定价流水线评估了插补数据。结果表明，ACT-Tensor 降低了定价误差，并显著提高了所构建组合的风险调整后回报。这些发现证实了我们的方法提供高度准确和有信息性的插补，对金融决策具有重要价值。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08833", "html_url": "https://arxiv.org/abs/2508.08833", "title": "关于LLMs在数学推理中的稳健性研究：利用高级数学问题的数学等价转换进行基准测试", "title_en": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems", "authors": "Yuren Hao,Xiang Wan,ChengXiang Zhai", "background": "本文介绍了一种超越传统方法的系统框架，通过在具有数学等价但语义和参数变化的高级数学问题上进行压力测试，来评估LLMs（大语言模型）的数学推理稳健性。这些转换使我们能够测量LLMs对非数学干扰的敏感性，从而更准确地评估其数学推理能力。", "innovation": "本文提出了一种新的评估方法，使用一个新的基准数据集PutnamGAP，该数据集包含多个数学上等价的竞赛级数学问题的变体。利用这一新数据集评估了多个代表性LLM家族，并研究其稳健性。结果显示，许多商用和开源模型在变体上的性能大幅下降，证明了所提出的新型评估方法的有效性。", "conclusion": "总之，研究结果表明，提出的新型评估方法对于深入理解LLMs的稳健性及其数学推理能力的提升具有重要意义，为改进其数学推理能力提供了新的见解。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09621", "html_url": "https://arxiv.org/abs/2508.09621", "title": "通过结构化行为树和大型语言模型实现可解释的机器人控制", "title_en": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models", "authors": "Ingrid Maéva Chekam,Ines Pastor-Martinez,Ali Tourani,Jose Andres Millan-Romera,Laura Ribeiro,Pedro Miguel Bastos Soares,Holger Voos,Jose Luis Sanchez-Lopez", "background": "随着智能机器人越来越融入人类环境，对直观且可靠的机器人-人类交互（HRI）接口的需求不断增加，这些接口需要适应性强且更自然的人机交互方式。传统机器人控制方法往往需要用户适应接口或记住预定义的命令，这在动态、非结构化的环境中限制了其可用性。因此，需要一种新的机制来提高HRI系统的交互体验和效率。", "innovation": "该论文提出了一种新的框架，通过将大型语言模型（LLMs）与行为树相结合，实现自然语言理解和机器人执行之间的桥梁。这种集成使机器人能够解析用户的自然语言指令并将其转换为可执行动作，通过激活特定领域的插件。系统支持可扩展和模块化的集成，主要集中在基于感知的功能上，如人员跟踪和手势识别。", "conclusion": "通过一系列真实世界实验，在多种环境中评估了该系统。结果表明，提出的这种方法在实际场景中是实用的，平均认知到执行的准确性约为94%。这极大地推动了HRI系统和机器人的发展。该框架的完整源代码已公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11711", "html_url": "https://arxiv.org/abs/2508.11711", "title": "使用大型语言模型、句向量变换器和卷积神经网络检测恶意 GraphQL 查询以增强GraphQL安全性", "title_en": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks", "authors": "Irash Perera(1),Hiranya Abeyrathne(2),Sanjeewa Malalgoda(2),Arshardh Ifthikar(2) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka, (2) WSO2, Colombo, Sri Lanka)", "background": "GraphQL 的灵活性虽然有助于高效的数据获取，但引入了传统API安全机制往往无法解决的独特安全漏洞。恶意的GraphQL查询可以利用语言的动态特性，导致拒绝服务攻击、数据泄露等。现有的解决方案，如静态分析、速率限制和通用Web应用防火墙，对复杂且基于上下文的攻击提供有限的保护。这项研究介绍了基于AI的实时检测恶意GraphQL查询的新方法。该方法结合了静态分析和机器学习技术，包括大语言模型（LLMs）用于基于动态模式的配置、句向量变换器（SBERT和Doc2Vec）用于查询负载的语境嵌入技术，以及卷积神经网络（CNN）、随机森林和多层感知器（MLP）用于分类。", "innovation": "该研究提出了一种基于AI的新颖方法，通过实时检测恶意GraphQL查询来增强安全性。该方法结合了静态分析和机器学习技术，特别是使用大语言模型（LLMs）、句向量变换器（SBERT和Doc2Vec）和卷积神经网络（CNN）等技术进行了创新性应用。此外，该方法还通过ONNX Runtime优化和并行处理对其实现策略进行了优化。", "conclusion": "实验结果显示，该方法在检测SQL注入、操作系统命令注入和XSS攻击等多种威胁时表现出高准确率。此外，系统还有效缓解了拒绝服务（DoS）和反射型服务器端请求伪造（SSRF）攻击。这项研究为增强GraphQL API安全性提供了一种强大且灵活的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19366", "html_url": "https://arxiv.org/abs/2508.19366", "title": "将无依据的推理置于依据之上：一种用于量化多模态LLMs幻觉的谱图框架", "title_en": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in Multimodal LLMs", "authors": "Supratik Sarkar,Swagatam Das", "background": "LLMs在多模态设置中出现的幻觉降低了它们的可靠性。背景信息强调了理解并量化这种幻觉的重要性，以便评估和减轻它们的影响。", "innovation": "论文提出了一种严格的信息几何框架，在弥散动力学中量化LLMs的幻觉。模型输出通过多模态图拉普拉斯嵌入，并通过与真相流形的差距定义语义失真度量。通过Courant-Fischer边界和RKHS特征模态，获得模态感知的、可解释的测量方法，以追踪提示和时间上的演变。这种方法将幻觉重新定义为可测量和有界的，为评估和缓解提供了一种原理性的基础。", "conclusion": "通过建立这种框架，论文为幻觉的评价和减缓提供了原则性的基础，使得幻觉成为可衡量和可估算的。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18665", "html_url": "https://arxiv.org/abs/2508.18665", "title": "LLM-based Recommender Systems 的成员推理攻击", "title_en": "Membership Inference Attacks on LLM-based Recommender Systems", "authors": "Jiajie He,Yuechun Gu,Min-Chun Chen,Keke Chen", "background": "当前的大型语言模型（LLMs）推荐系统（RecSys）可以灵活地将推荐系统适应到不同的领域。它们利用上下文学习（ICL），即提示，来定制推荐功能，包括敏感的历史用户特定项目交互，比如点击项目或产品评论等隐式反馈。然而，这些私人信息面临新的隐私攻击威胁，但目前尚未对此问题进行研究。本文设计了四种成员推理攻击（MIAs），以揭示系统提示中是否使用了受害者的过去交互，分别是直接问询攻击、虚构攻击、相似性攻击和中毒攻击。这些攻击利用了LLM或RecSys的独特特征。本文评估了这四种攻击在三种被用于开发ICL-LLM RecSys的LLM和两个知名的RecSys基准数据集上的表现，结果表明这些攻击在上述环境中是现实的，特别是直接问询攻击和中毒攻击显示出较高的攻击优势。同时，研究还分析了影响这些攻击的各种因素，如系统提示中的样本数量和受害者在样本中的位置。", "innovation": "设计了四种新的成员推理攻击（MIAs），并评估了它们在实际使用中的效果，特别是在涉及大型语言模型的推荐系统中的表现。这四种攻击方法利用了LLM和推荐系统的特点，能够揭示系统提示中是否使用了受害者的历史交互数据。此外，对影响攻击效果的因素进行了详细分析，提供了理解攻击机制的新视角。", "conclusion": "大型语言模型基于的推荐系统中的成员推理攻击是现实的，特别是直接问询攻击和中毒攻击显示出显著的优势。此外，研究还探讨了影响这些攻击效果的因素，这为未来改进推荐系统的隐私保护提供了有价值的见解。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "在推理时构建知识图谱以提高LLMs的事实准确性", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大语言模型（LLMs）在生成事实正确答案时通常存在困难，这归因于其参数记忆的限制。检索增强生成（RAG）方法在推理时通过引入外部知识来缓解这个问题，但是这样的方法一般处理知识时是作为无结构文本，降低了检索的准确性，妨碍了组合推理，并增强了无关信息对于LLM输出事实正确的影响力。", "innovation": "本文提出了一个新颖框架，在推理时动态构建和扩展知识图谱（KGs），结合了LLM内部提取的知识和外部来源检索的知识。该方法首先通过提示提取问题的基本KG，然后通过LLM的内部知识进行迭代扩展，再通过外部检索精炼KG，提高事实覆盖范围并纠正不准确信息。", "conclusion": "本文的方法在三个不同的事实问答基准测试中进行了评估，证明了与基线相比在事实准确度上的一致性改进。研究结果表明，在推理时构建知识图谱是一个增强LLM事实正确性的有前途的方向，具备结构化、可解释性和扩展性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01845", "html_url": "https://arxiv.org/abs/2509.01845", "title": "社区为中心的空间智能在诺斯托尼亚东部海岸的气候适应", "title_en": "Community-Centered Spatial Intelligence for Climate Adaptation at Nova Scotia's Eastern Shore", "authors": "Gabriel Spadon,Oladapo Oyebode,Camilo M. Botero,Tushar Sharma,Floris Goerlandt,Ronald Pelot", "background": "诺斯托尼亚东部海岸是一个以海洋为生、亲近海洋的农村村落集合，面临着来自气候变化的生存威胁，威胁到其生活方式。本研究概述了一个以人为本的倡议，旨在加强该地区的气候韧性。该项目通过结合计算机科学、工业工程和海岸地理学的专家知识，并与社区合作开发工具，超越了纯技术响应。项目强调了通过东海岸公民科学海岸监测网络整合居民尤其是长者世代知识的重要性，从而促进建立一个活生生的数字档案。这一努力隶属于达尔豪斯大学的转型气候变化行动（TCA）倡议，具体通过其变革性社会生态气候变化轨迹适应（TranSECT）和TCA人工智能（TCA-AI）项目。这项工作采用了学生团队直接与居民合作的模式。该研究详细介绍了项目的时间表，并提供了一个可以通过技术支持传统社区，并帮助他们更好地应对气候变化转型的可复制模型。", "innovation": "本项目通过结合计算机科学、工业工程和海岸地理学的专家知识，与东海岸公民科学海岸监测网络整合居民尤其是长者世代知识的模式创新，促进了建立一个活生生的数字档案。该项目超越了纯技术响应，强调了与社区紧密合作的重要性，并提供了一个可复制的技术支持传统社区的模型，帮助它们更好地应对气候变化。", "conclusion": "该项目详细介绍了通过社区为中心的方法实现气候适应的路径，并提出一个可复制的模式，促进技术在支持传统社区中的应用，帮助这些社区更有效地应对气候变化的挑战。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03122", "html_url": "https://arxiv.org/abs/2509.03122", "title": "从注入到防御：构建基于编辑的大型语言模型指纹", "title_en": "From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Linlin Wang", "background": "指纹技术对于维持开发者的知识产权和可追溯性至关重要，尤其是在Web应用程序中部署的LLMs可能通过微调或黑盒部署被未经授权地重新分发和误用的情况下。现有的基于后门的指纹方法存在基本的权衡：嵌入为混淆文本的指纹容易被检测和过滤，而那些根据连贯自然语言精心制作的指纹则容易在无意中触发。为了解决这些限制，本文提出了RFEdit框架，这是一种通过修改模型权重的稀疏子集嵌入基于规则的多语言自然语言指纹（MNLF）的知识编辑框架。这种方法使得在LLM中高效、稳健地注入指纹，同时对无关知识的影响最小化。此外，Fingerprint Subspace-aware Fine-Tuning (FSFT)进一步保障了RFEdit框架的安全性，通过限制参数更新到特征空间来缓解指纹降解问题，确保指纹完整性和下游任务性能的提升。", "innovation": "提出了RFEdit框架，这是一种知识编辑框架，通过修改模型权重的稀疏子集嵌入基于规则的多语言自然语言指纹（MNLF），使得在LLM中高效、稳健地注入指纹，同时对无关知识的影响最小化。进一步引入了Fingerprint Subspace-aware Fine-Tuning (FSFT)技术，确保指纹在合法微调过程中的稳定性，同时提高LLM的下游任务性能。", "conclusion": "RFEdit框架和FSFT技术建立了从指纹注入到防御的完整流程，实现了高度的检测效果，对对抗性操纵具有稳健性，对模型实用性无害，并且在微调过程中保持持久性。广泛的实验表明，RFEdit在量化和剪枝下保持了稳健性，与FSFT结合使用时，对于数学和Alpaca等下游任务，指纹效果普遍提高了超过10%。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.07030", "html_url": "https://arxiv.org/abs/2509.07030", "title": "一种用于随机优化的极简贝叶斯框架", "title_en": "A Minimalist Bayesian Framework for Stochastic Optimization", "authors": "Kaizheng Wang", "background": "贝叶斯范式提供了一种在不确定性下进行序列决策的原则性工具，但在所有参数上使用概率模型可能会阻碍复杂结构约束的整合。", "innovation": "提出了一种极简的贝叶斯框架，仅对所关心的组件（如最优解的位置）设置先验分布，通过轮廓似然法消除无关参数，自然处理约束条件。在此基础上，开发了MINimalist Thompson Sampling (MINTS)算法，并适用于包括连续臂Lipschitz或多臂赌博机等结构化问题，同时为经典的凸优化算法提供了一种概率视角。", "conclusion": "分析了MINTS在多臂赌博机中的应用，并建立了近最优的遗憾保证。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03487", "html_url": "https://arxiv.org/abs/2509.03487", "title": "SafeProtein: 用于蛋白质基础模型的红队框架和基准", "title_en": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models", "authors": "Jigang Fan,Zhenghong Zhou,Ruofan Jin,Le Cong,Mengdi Wang,Zaixi Zhang", "background": "蛋白质在几乎所有生物过程中都起着关键作用。深度学习的进步显著加速了蛋白质基础模型的发展，带来了蛋白质理解和设计的重大突破。然而，这些模型缺乏系统性的红队测试，引起了对其潜在滥用的关注，尤其是在生成具有生物安全风险的蛋白质方面。此前尚未有专门针对蛋白质基础模型的红队框架，本研究旨在填补这一空白并提出SafeProtein。", "innovation": "SafeProtein是首个专门针对蛋白质基础模型的红队框架，通过多模态提示工程和启发式贝叶斯搜索系统地设计红队方法并对蛋白质基础模型进行测试。SafeProtein还构建了SafeProtein-Bench，包括手动构建的红队基准数据集和全面的评估协议，对当前最先进的蛋白质基础模型（如ESM3）实现了连续突破性攻击，揭示了潜在的生物安全风险，并为开发前沿模型的健壮安全防护技术提供了指导。", "conclusion": "SafeProtein成功揭示了现有蛋白质基础模型的生物安全风险，展示了其在红队测试中的能力，并持续攻击最先进的蛋白质基础模型，达到70%的成功率。这为未来开发更安全的蛋白质基础模型提供了重要参考。所有代码将在该网址公开：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "任务向量与梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简单而强大的模型合并技术已经出现，它能够将多个微调模型合并成一个。尽管这种技术在实践中取得了显著的成功，但缺乏清晰的理论解释来说明它为何有效及其适用条件。本文通过建立任务向量与任务损失梯度之间的联系，为任务算术提供了严格理论基础。", "innovation": "本文通过证明在标准梯度下降的情况下，一个生成于一次微调周期的任务向量等同于损失的负梯度，放大了学习率。对于多轮微调的实际设置，证明了这种等效关系大约成立，并为前向网络提供了具体的二级误差术语。实证分析在七个视觉基准测试上证实了理论，表明初始微调周期的梯度主导了模型的微调轨迹，无论是模拟能力还是方向。", "conclusion": "这些发现重新定义了任务算术作为近似多任务学习的形式，为其实效性提供了清晰的理由，并强调了早期训练动态在合并模型中的关键作用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03318", "html_url": "https://arxiv.org/abs/2507.03318", "title": "Group Lasso Regularization下的图神经网络用于结构意识的化合物-蛋白质亲和力预测", "title_en": "Structure-Aware Compound-Protein Affinity Prediction via Graph Neural Network with Group Lasso Regularization", "authors": "Zanyu Shi,Yang Wang,Pathum Weerawarna,Jie Zhang,Timothy Richardson,Yijie Wang,Kun Huang", "background": "可解释的人工智能(XAI)方法在药物发现中的应用日益广泛，用于学习分子表示并识别驱动性质预测的亚结构。然而，构建用于化合物性质预测的结构-活性关系(SAR)模型的端到端可解释模型面临着许多挑战，包括特定蛋白质靶点的化合物-蛋白活性数据有限，以及在分子配置位置上的细微变化对分子性质的影响显著。", "innovation": "作者提出了一种框架，利用图神经网络(GNN)来利用活性悬崖配对中的性质和结构信息，以预测化合物与蛋白质亲和力（如半数抑制浓度IC50）。为了提高模型的性能和可解释性，作者使用具有结构感知损失函数的GNN进行训练，其中使用了群Lasso和稀疏群Lasso正则化，以修剪和突出与活性差异相关的分子子图。这种方法应用于针对三种肿瘤蛋白激酶Src蛋白的目标活性悬崖分子数据（PDB ID：1O42，2H8H，4MXO）。通过整合常见和不常见节点信息与稀疏群Lasso，该方法提高了性质预测效果，表现为减少了均方根误差(RMSE)并提高了皮尔逊相关系数(PCC)。此外，应用正则化还增强了图神经网络的特征归因，提升了图级全局方向分数并改进了原子级着色准确性。", "conclusion": "这些进展加强了药物发现管道中的模型可解释性，尤其是在识别先导优化中的关键分子亚结构方面。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02210", "html_url": "https://arxiv.org/abs/2506.02210", "title": "神经网络中的可交换性及其在动态修剪中的应用", "title_en": "Exchangeability in Neural Network and its Application to Dynamic Pruning", "authors": "Pu (Luke)Yi,Tianlang Chen,Yifan Yang,Sara Achour", "background": "现代神经网络包含越来越多的参数，这显著增加了推理的内存和计算成本。研究人员已经探索了多种方法来降低部署前的模型大小和运行时的推理计算成本，通过预剪枝减少模型规模并根据需要动态修剪推理计算。本文提出了一种名为ExPrune的一般动态剪枝优化方法，实现了基于每输入的多粒度部分计算。ExPrune无需更改模型架构或训练算法。该方法基于研究者关于特定模型参数和中间值之间的关系可以用统计性质可交换性来描述的理论结果。通过识别模型中的可交换参数和值，ExPrune可以部分评估网络，并根据部分结果的统计分析和分析结果做出即时的修剪决策。", "innovation": "ExPrune 是一种基于理论结果的模型，能够跨越不同问题域的模型架构进行通用优化。它无需对模型架构或训练算法进行更改。通过识别可交换参数和值，ExPrune 能够实现部分评估网络，分析部分结果的统计特性，并即时做出剪枝决策。此外，ExPrune 可以与静态幅度剪枝结合使用，即使在模型已经经过广泛静态剪枝之后，仍然能够提供额外的 FLOPs 减少，这些剪枝不影响或最多影响 1% 的准确率。", "conclusion": "ExPrune 在一系列模型中实现了显著的 FLOPs 减少。对于计算机视觉模型、图模型和语言模型，ExPrune 能够实现 10.98% 到 17.33% 不同程度的 FLOPs 减少，且准确率几乎没有下降。在已经经过广泛静态剪枝的模型中，ExPrune 进一步提供了 10.24% 到 11.11% 的 FLOPs 减少，最多 1% 的准确率下降。该方法不仅适用于当前三种模型，还可以推广应用到其他模型中，验证了其广泛的适用性和效果。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15174", "html_url": "https://arxiv.org/abs/2509.15174", "title": "SMARTER: 一种通过自我增强大型语言模型提高带有解释的毒性检测的数据高效框架", "title_en": "SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models", "authors": "Huy Nghiem,Advik Sachdeva,Hal Daumé III", "background": "随着社交媒体上毒性和有害内容的泛滥，迫切需要有效的解决方案来应对这一问题。现有的方法通常依赖于大量的标注数据和复杂的模型结构，但这些方法在数据效率和资源利用上存在局限性。", "innovation": "本文提出了SMARTER，这是一种数据效率高的两阶段框架，利用大型语言模型（LLMs）的预期输出生成合成解释以进行内容审核。该框架通过两个阶段提升解释质量：首先利用LLMs自身输出生成合成解释，进行偏好优化并最小化人工监督；其次通过跨模型训练优化解释质量，使较弱模型风格和语义上与较强模型对齐。这种方法仅使用部分训练数据，在三个基准任务中表现出显著优越性，证明了在低资源环境中利用LLMs自我改进能力的有效性。", "conclusion": "SMARTER框架展示了一种在资源有限环境下有效提升毒性检测性能的策略，通过利用LLMs自我提高的能力，既能进行分类又能产生解释，从而有助于提高社交媒体环境的安全性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12658", "html_url": "https://arxiv.org/abs/2509.12658", "title": "基于隐含信道状态信息的RIS辅助毫米波MIMO系统可持续LSTM预编码", "title_en": "Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI", "authors": "Po-Heng Chou,Jiun-Jia Wu,Wan-Jen Huang,Ronald Y. Chang", "background": "本文讨论了利用可重构智能表面（RIS）辅助的毫米波（mmWave）MIMO系统的可持续长期短期记忆（LSTM）基预编码框架。传统的信道状态信息（CSI）估计方法被现有框架所替代，该框架利用上行试点序列隐含学习信道特性，降低了试点开销和推理复杂度。此外，该框架还考虑了硬件限制，通过整合RIS元素除相依赖的振幅模型，并采用多标签训练策略提高了鲁棒性。实验结果表明，在计算时间仅为全搜索（ES）计算时间的2.2%的情况下，该设计达到了90%以上的频谱效率，几乎降低了两个数量级的能量消耗，并且在分发错配和更大的RIS阵列下表现出了鲁棒性。", "innovation": "基于LSTM的预编码框架替代了传统的CSI估计方法，利用上行试点序列隐含学习信道特性，降低了试点开销和推理复杂度。该框架采用了相依赖的振幅模型，结合了多标签训练策略，提高了鲁棒性，使得设计在全搜索计算时间的2.2%的条件下达到了90%以上的频谱效率。并且在能量消耗上降低了将近两个数量级，同时具有鲁棒性并适用于更大的RIS阵列.", "conclusion": "提出的预编码设计在计算效率和能量效率方面表现出色，达到了90%以上的频谱效率，也是可持续6G无线网络的可行和节能解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15098", "html_url": "https://arxiv.org/abs/2509.15098", "title": "TextMine: 数据, 评估框架和本体指导的大语言模型管道以应对人道主义地雷行动", "title_en": "TextMine: Data, Evaluation Framework and Ontology-guided LLM Pipeline for Humanitarian Mine Action", "authors": "Chenyue Zhou,Gürkan Solmaz,Flavio Cirillo,Kiril Gashteovski,Jonathan Fürst", "background": "人道主义地雷行动(HMA)致力于在冲突地区检测和清除地雷。尽管人类救援组织产生了大量生命拯救的相关知识，但由于这些知识多存在于非结构化的报告中，信息在不同组织之间的转移受到限制。为了解决这一问题，本文提出TextMine，这是一个基于(主题, 关系, 客体)-三元组将HMA报告结构化处理的首个数据集、评估框架和本体指南指导的大语言模型管道，旨在将领域特定的知识进行结构化处理，提高信息的可转移性与共用性。", "innovation": "TextMine通过构建(主题, 关系, 客体)-三元组来结构化处理HMA报告，填补了领域知识提取的空白；与柬埔寨地雷行动中心(CMAC)合作创建数据集，确保现实世界的相关性；引入了意识偏见的评估框架，结合了人类注释的三元组和LLM作为评委协议，以减轻参考评分中的位置偏见。实验结果显示，本体对齐的提示可以提高提取准确性高达44.2%，减少幻觉22.5%，增强格式一致性20.9%。还公开了数据集和代码，方便进一步研究和应用。", "conclusion": "TextMine数据集、评估框架及本体指导的大语言模型管道，在提高HMA报告中知识的提取准确性、减少幻觉现象和提升格式一致性方面取得了显著成效，为该领域提供了新的工具和技术支持。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17671", "html_url": "https://arxiv.org/abs/2508.17671", "title": "在不完美信息游戏中静态对手的一致对手建模", "title_en": "Consistent Opponent Modeling of Static Opponents in Imperfect-Information Games", "authors": "Sam Ganzfried", "background": "智能体在多智能体环境中，目标是通过最大化与对手的总奖励来促使性能最大化。现有的基于博弈论概念如纳什均衡的方法可能在某些情况下表现强大，但它们不能充分利用从重复交互中获得的历史数据。现有的对手建模算法结合机器学习技术来利用可用数据来利用对手的次优策略，但在不完美信息游戏中，这些方法的有效性极为有限。论文指出现有的对手建模方法，在面对从已知先验分布中抽取的静态对手时，即使在多次博弈的情况下，也无法保证模型会逼近对手的真实策略，即无法达到这一简单但理想的目标。因此，需要一种新的算法来解决问题，该算法能够解决基于序列形式博弈表示的凸最小化问题，通过投影梯度下降方法高效执行。该算法能够确保在获得游戏观察并可能有额外历史数据的情况下，模型能够有效地收敛到对手的真实策略", "innovation": "开发了一种新算法，该算法能够在不完美信息游戏中，即使面对静态对手的情况下，也能够保证模型会逼近对手的真实策略。该算法是通过解决基于序列形式博弈表示的凸优化问题，使用投影梯度下降方法高效执行，能够高效收敛到对手的真实策略", "conclusion": "现有的对手建模方法在不完美信息游戏中表现不佳，无法在面对静态对手并多次进行博弈时准确逼近对手的真实策略。新提出的方法解决了这个问题，并通过投影梯度下降方法有效地解决了凸优化问题，从而能够高效地逼近对手的真实策略"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20293", "html_url": "https://arxiv.org/abs/2509.20293", "title": "当判断变成噪声：LLM评判基准中的设计缺陷如何默默削弱有效性", "title_en": "When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity", "authors": "Benjamin Feuer,Chiung-Yi Tseng,Astitwa Sarthak Lathe,Oussama Elachqar,John P Dickerson", "background": "LLM评判基准越来越被用来评估复杂模型的行为，但这些基准的设计引入了传统基于真实数据的基准所没有的失败模式。如果没有明确的目标和可验证的构建，基准排名可能会产生高置信度但实际上是大量噪声的结果。", "innovation": "该研究引入了两种机制来诊断这些问题。首先，结构一致性量化了评判者整体判决中有多少部分是由明确的评估框架解释的，揭示了当评判者偏离他们自己的评分标准时未解释的方差。其次，心理测量效度聚合了内部一致性和区分效度的信号，量化了任何基准测试运行中不可避免的不确定性。研究还展示了Arena-Hard Auto使用的ELO风格聚合如何导致和掩盖真实的排名不确定。", "conclusion": "研究结果突显了设计缺陷对有效性的负面影响，并提出了建设更好范围、依赖性意识的LLM评判基准的可操作原则。研究团队已将代码和数据集发布于这个链接：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21154", "html_url": "https://arxiv.org/abs/2509.21154", "title": "GRPO是秘密的过程奖励模型", "title_en": "GRPO is Secretly a Process Reward Model", "authors": "Michael Sullivan", "background": "研究团队探讨了GRPO RL算法的理论基础和实际应用，发现其在一定假设条件下可以诱导出非平凡的过程奖励模型（PRM），并且在实际情境中这些假设被证实成立。进一步研究识别了GRPO目标中的一种缺陷：不均匀的过程步骤分布会妨碍探索和利用。\n", "innovation": "提出了一个简单的算法改进方案（λ-GRPO），以缓解上述缺陷，并通过实验验证了使用改进后的λ-GRPO训练的语言模型在验证准确性和下游推理任务上的性能优于使用标准GRPO训练的模型，且达到最佳性能更快。研究还表明，相对于耗费资源且需要显式定义的PRM，可以利用GRPO算法内在的隐含PRM结构来提高模型性能，且对训练时间和成本影响较小。\n", "conclusion": "本研究揭示了GRPO的内在机制，即它实际上诱导出了一种过程奖励模型，并提出改进方案λ-GRPO，不仅改善了算法性能，还减少了对额外资源的依赖。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24031", "html_url": "https://arxiv.org/abs/2509.24031", "title": "GPS-MTM: 通过自我监督学习捕捉GPS轨迹中的正常模式", "title_en": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning", "authors": "Umang Garg,Bowen Zhang,Anantajit Subrahmanya,Chandrakanth Gudavalli,BS Manjunath", "background": "基于模型在文本、视觉和视频理解方面取得了显著进展，并正在为轨迹建模领域带来类似的突破。当前的轨迹模型通常将轨迹展开为坐标的流，而缺乏捕捉正常模式的能力。", "innovation": "GPSMasked Trajectory Transformer (GPS-MTM) 引入了一种新的方式来分解移动性数据，即通过状态（兴趣点类别）和动作（代理过渡）两种互补模态，利用双向Transformer和自我监督的掩蔽建模目标来重建跨模态的缺失部分，从而能学到丰富的语义关联而无需手动标签。", "conclusion": "在Numosim-LA, Urban Anomalies, 和Geolife等基准数据集上，GPS-MTM在轨迹填充和下一个终点预测等下游任务上表现优异，特别是在需要上下文推理的动态任务中优势尤为明显。这确立了GPS-MTM作为轨迹分析中的稳健基础模型的地位，将移动数据提升为大规模表示学习的一种主要模态。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16765", "html_url": "https://arxiv.org/abs/2509.16765", "title": "声学中的句法：针对语言病理学的语言模型的微调与全面评估", "title_en": "The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology", "authors": "Fagun Patel,Duc Q. Nguyen,Sang T. Truong,Jody Vaynshtok,Sanmi Koyejo,Nick Haber", "background": "根据美国国家卫生研究院的数据，超过340万儿童遭受需要临床干预的语言障碍。目前语言病理学家的数量仅仅是受影响儿童数量的20分之一左右，这表明儿童护理存在显著缺口，迫切需要技术支持来提高语言病理学家的工作效率。最先进的多模态语言模型显示出了支持语言病理学家的潜力，但由于对其在关键临床环境中的表现缺乏了解，其应用仍然相对有限。为了填补这一空白，研究人员与领域专家合作制定了一个分类体系，并引入了一个全面的基准测试框架，涵盖五个核心应用场景，每个场景都有1000个手动标注的数据点。这些测试包括背景噪音、性别和口音等多个设置下的鲁棒性和敏感性测试。评估结果显示没有单一模型在所有任务中都表现出色，并发现模型在男性发言者上的表现更好。此外，通过在特定领域数据上微调语言模型也取得了显著效果，相比于基础模型表现提升了超过10%。这些发现揭示了当前多模态语言模型在语言病理学应用中的潜力和局限性，突显了进一步研究和针对性开发的必要性。", "innovation": "该研究与领域专家合作，制定了多模态语言模型在语言病理学中的应用分类体系，并引入了第一个全面基准测试框架，涵盖五个核心应用场景，每个场景都有1000个手动标注的数据点。此外，研究发现通过对特定领域数据进行微调，可以显著提升模型的表现。这些工作对于推动语言病理学领域多模态语言模型的实际应用具有重要意义。", "conclusion": "当前多模态语言模型在支持语言病理学方面具有一定的潜力但也有明显的局限性，其中模型的性能在不同情况下存在差异，特别是在处理大标签空间和窄决策边界分类任务时表现较差。微调特异性领域的语言模型能够显著提高性能，但也指出了未来研究方向，即更深入地了解模型在苛刻临床环境中的表现并促进其针对性开发。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23206", "html_url": "https://arxiv.org/abs/2509.23206", "title": "PARL-MT: 在多轮对话中学习具有进度意识调用函数", "title_en": "PARL-MT: Learning to Call Functions in Multi-Turn Conversation with Progress Awareness", "authors": "Huacan Chai,Zijie Cao,Maolin Ran,Yingxuan Yang,Jianghao Lin,pengxin,Hairui Wang,Renjie Ding,Ziyu Wan,Muning Wen,Weiwen Liu,Weinan Zhang,Fei Huang,Ying Wen", "background": "虽然大型语言模型（LLMs）在单轮函数调用方面取得了显著成就，但现实世界的应用场景如旅行规划或多层次数据分析通常需要多轮对话。在此类场景中，LLMs 不仅需要在每一步准确地调用函数，还需要维护进度意识，即能总结过往交互并计划后续行动，以确保任务的协调和长期执行。现有的方法要么将多轮训练简化为孤立的单轮样本，忽视了任务级别的规划，要么采用端到端的强化学习，但这种方法难以处理重复性问题并缺乏明确的进度意识整合。", "innovation": "我们提出了一种名为PARL-MT的框架，旨在将进度意识明确地融入多轮函数调用的LLM训练中。PARL-MT结合了一个进度意识生成（PAG）管道，该管道自动构建包含对话总结与未来任务规划结合的数据集，以及一个由进度意识引导的强化学习（PAG-RL）算法，该算法将进度意识整合到强化学习训练中，以减少上下文冗余，并提高局部行动与全局任务完成之间的契合度。", "conclusion": "在两个公开基准测试中，PARL-MT显著优于现有方法，突显了进度意识在实现稳健且高效的多轮函数调用中的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25775", "html_url": "https://arxiv.org/abs/2509.25775", "title": "自主意识聚类：当局部决策取代全局指令", "title_en": "Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions", "authors": "Amber Srivastava,Salar Basiri,Srinivasa Salapaka", "background": "聚类问题是多种问题表述的基础，但当前大多数方法假设被聚类的实体是被动的，并严格遵循分配的组别。实际上，实体通常表现出局部自主性，可以违背预定的关联，这些自主性并未完全由特征表示捕捉到。这种自主性可以显著改变聚类结果，如改变聚类组成、几何结构和基数，从而对后续推理和决策产生重要影响。", "innovation": "本文提出了自主意识聚类，这是一种强化学习（RL）框架，可以学习并考虑局部自主性的影响，而无需预先知道其形式。该方法结合了RL与确定性退火（DA）过程，其中在退火早期阶段自然推动探索，后期则过渡到利用。研究还展示了退火过程中的相变，有助于设计高效的退火调度。为了进一步增强可适应性，提出了一种适应性距离估算网络（ADEN），这是一种基于变压器的注意力模型，能够在RL循环中学习实体与聚类代表之间的依赖关系，适应变量大小的输入和输出，并在不同问题实例之间实现知识转移。", "conclusion": "实验结果表明，本框架与底层数据动态高度一致：即使不使用明确的自主模型，也能达到接近真实情况的解决方案（差距约为3-4%），而忽略自主性会导致较大差距（约35-40%）。代码和数据已公开可供访问。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15927", "html_url": "https://arxiv.org/abs/2509.15927", "title": "使用离线奖励评估和策略搜索增强生成性自动出价", "title_en": "Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search", "authors": "Zhiyu Mou,Yiqin Lv,Miao Xu,Qi Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng", "background": "自动出价是广告商改进广告效果的关键工具。近年来的研究表明，基于离线数据学习生成性规划者的AI生成竞价（AIGB）方法，在性能上优于传统的基于离线强化学习（RL）的自动出价方法。然而，现有的AIGB方法仍然受限于它们无法探索超出静态离线数据集的能力，导致性能瓶颈。", "innovation": "本文提出了AIGB-Pearl方法，该方法结合生成性规划和策略优化，通过构建轨迹评估器衡量生成质量并设计可证明安全的KL-Lipschitz约束评分最大化方案，确保超越离线数据集的安全和有效探索。进一步设计了包含同步耦合技术的实用算法，以满足提出的方案所需的模型规律性。实验证明了该方法在模拟和真实世界的广告系统中具有最先进的性能。", "conclusion": "本文通过提出AIGB-Pearl方法，在设计中融合生成性规划和策略优化，显著提升了超越静态离线数据集的安全和有效探索，最终在广告系统中的实验结果证明了该方法的优越性能。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03262", "html_url": "https://arxiv.org/abs/2510.03262", "title": "重新思考适配器合并中的LoRA间正交性：正交蒙特卡洛丢弃的见解", "title_en": "Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout", "authors": "Andi Zhang,Xuan Ding,Haofan Wang,Steven McDonagh,Samuel Kaski", "background": "LoRA（低秩适应）是大型模型细调的一种流行方法，通常通过训练模块来代表特定的概念，如对象或风格。然而，当多个LoRA模块合并，如生成特定风格中的对象时，它们的输出可能相互干扰。现有研究表明，合并后的LoRA模块之间的正交性有助于避免直接干扰，但实验证明这种正交性并不一定导致早期工作中所强调的语义分离，因此需要重新审视LoRA间正交性在适配器合并中的重要性。", "innovation": "提出了一种机制——正交蒙特卡洛丢弃（Orthogonal Monte Carlo Dropout），它在合并稀疏语义向量时强制执行严格的正交性，而不会增加额外的时间复杂度。通过这种方法，合并后的LoRA模块可以保持正交，从而避免直接干扰。该方法的重点是通过实验分析证明了LoRA间正交性在实现语义分离方面的不足。", "conclusion": "实验分析表明，LoRA间正交性在适配器合并中促进无干扰合并，但未必能实现早期工作中所强调的语义分离。这暗示了LoRA间正交性在实现语义组成性方面可能不够充分，需要进一步探究新的方法来实现真正的语义组成性。这项研究重新审视了LoRA间正交性在适配器合并中的作用。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26281", "html_url": "https://arxiv.org/abs/2509.26281", "title": "Point2RBox-v3：通过集成伪标签细化和利用实现自我提升的点注释", "title_en": "Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization", "authors": "Teng Zhang,Ziqian Fan,Mingxin Liu,Xin Zhang,Xudong Lu,Wentong Li,Yue Zhou,Yi Yu,Xiang Li,Junchi Yan,Xue Yang", "background": "随着对定向对象检测（OOD）需求的增长，基于点注释的弱监督学习方法因其较低的成本和较小的劳动需求，成为了替代昂贵且繁琐的手动标注的有前景的选择。但由于现有基于点监督的方法存在标签利用效率低和伪标签质量差的问题，本文探讨了这种状况，提出了Point2RBox-v3模型，旨在改进这些问题。", "innovation": "Point2RBox-v3的核心创新包括：1) 渐进式标签分配（PLA），这是一种在训练过程中各个阶段智能粗略估计实例大小的动态方法。2) 先验引导动态掩码损失（PGDM-Loss），作为Point2RBox-v2中的Voronoi分水岭损失的改进，克服了分水岭在稀疏场景性能不佳和SAM在密集场景性能不佳的问题。特别是，Point2RBox-v3是首款采用动态伪标签进行标签分配的模型，它创造性地将SAM模型的优势与分水岭算法相结合，实现了在稀疏和密集场景中的出色性能。", "conclusion": "在不同类型的任务和场景下，Point2RBox-v3展现了优秀的性能，特别是在物体大小变化幅度大或物体稀少的场景中：在DOTA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR上的表现分别为66.09%/56.86%/41.28%/46.40%/19.60%/45.96%。这一解决方案在所有场景中表现出竞争力，尤其在高变幅和稀疏场景下."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03511", "html_url": "https://arxiv.org/abs/2510.03511", "title": "Platonic Transformers: 一种用于对称性的坚实选择", "title_en": "Platonic Transformers: A Solid Choice For Equivariance", "authors": "Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers", "background": "虽然变压器在各个领域广泛应用，但它们缺乏对称性诱导偏置，而这些对称性在科学和计算机视觉中很常见。现有的不变方法往往通过复杂、计算密集的架构牺牲了变压器的有效性和灵活性。", "innovation": "我们引入了Platonic Transformer，通过基于Platonic固有对称群的参考框架定义注意力，从而引出了一个合乎原理的权重共享方案。这种方法同时实现了连续平移不变性和Platonic对称的联合不变性，且保持了标准变压器的精确架构和计算成本。此外，证明这种注意力与动态群卷积形式上等价，表明模型学习了自适应的几何滤波器，并允许了高度可扩展的线性时间卷积变体。", "conclusion": "Platonic Transformer通过利用这些几何约束在各个基准测试（CIFAR-10、ScanObjectNN和QM9、OMol25）上实现了竞争力的性能，而没有任何额外成本。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03569", "html_url": "https://arxiv.org/abs/2510.03569", "title": "纵向流动匹配用于轨迹建模", "title_en": "Longitudinal Flow Matching for Trajectory Modeling", "authors": "Mohammad Mohaiminul Islam,Thijs P. Kuipers,Sharvaree Vadgama,Coen de Vente,Afsana Khan,Clara I. Sánchez,Erik J. Bekkers", "background": "生成模型在处理稀疏采样和高维轨迹时经常遇到困难，往往只能学习点对点的动态。传统的模型大多依赖于双点之间的过渡来学习动态。", "innovation": "本文提出了Interpolative Multi-Marginal Flow Matching (IMMFM)框架，该框架能够同时针对多个观察时间点学习连续的随机动态。IMMFM利用分段二次插值路径作为流动匹配的平滑目标，并联合优化漂移和基于数据的扩散系数。该设计还结合了理论稳定学习条件，以捕捉内在的随机性，处理不规则稀疏采样并生成个体特定的轨迹。", "conclusion": "在合成基准数据和纵向神经影像学真实世界数据集上的实验表明，IMMFM在预测准确性以及后续任务中的性能优于现有方法。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03268", "html_url": "https://arxiv.org/abs/2510.03268", "title": "在多模态对比学习中解析模态差距：从收敛表示到成对对齐", "title_en": "Decipher the Modality Gap in Multimodal Contrastive Learning: From Convergent Representations to Pairwise Alignment", "authors": "Lingjie Yi,Raphael Douady,Chao Chen", "background": "多模态对比学习（MCL）旨在将不同模态的数据嵌入到共享嵌入空间中。然而，实证证据表明，不同模态的表示占据了嵌入空间中完全分离的区域，这种现象称为模态差距。此外，关于模态差距大小对下游性能影响的实验发现不一致。这些观察引发了两个关键问题：一是模态差距的成因是什么？二是它如何影响下游任务？", "innovation": "本文提出了第一个用于分析MCL的收敛最优表示及其训练优化时模态对齐的理论框架。证明了在没有任何约束或锥形约束条件下，模态差距收敛于零。在子空间约束条件下（即由于维度坍缩，两种模态的表示分别落在两个区分的超平面中），模态差距收敛于两个超平面之间的最小角度。这表明维度坍缩是模态差距的根本来源。此外，论据还表明，即使在子空间约束条件下，成对样本也不能完全对齐。模态差距通过影响样本对之间的对齐度来影响下游性能。证明显示，可以通过超平面旋转和共享空间投影两种方式实现两种模态之间的完美对齐。", "conclusion": "本文识别了维度坍缩作为模态差距的根本来源，并证明了即使在子空间约束条件下，通过超平面旋转和共享空间投影也能实现模态的完美对齐。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13590", "html_url": "https://arxiv.org/abs/2509.13590", "title": "基于VLM的智能医疗成像平台：自动化医疗图像分析和临床报告生成框架", "title_en": "Intelligent Healthcare Imaging Platform: A VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "authors": "Samer Al-Hamadani", "background": "医疗成像中的人工智能（AI）迅速发展，极大地推动了诊断医学和临床决策流程的革新。本文提出了一种利用视觉-语言模型（VLMs）的智能多模态框架，用于医学图像分析，该框架结合了Google Gemini 2.5 Flash，实现多模式医学影像（如CT、MRI、X光、超声）的自动肿瘤检测和临床报告生成。系统通过结合视觉特征提取和自然语言处理，实现上下文图像解释，并采用坐标验证机制和概率高斯建模来表示异常分布，从而生成多层可视化技术、详细的医疗插图、叠加比较和统计图表，以提高临床诊断的信心。结果处理通过精确的提示工程和文本分析提取结构化的临床信息，保持解释性。实验结果显示，该系统在多种成像模态下具有高异常检测性能。系统具有友好用户界面（Gradio）以方便临床工作流程集成，展示了零样本学习能力，减少了对大规模数据集的依赖。该框架代表了在自动化诊断支持和放射学工作流程效率方面的重要进展，但在广泛应用前仍需临床验证和多中心评估以确保其有效性和安全性。", "innovation": "利用视觉-语言模型（VLMs）构建智能多模态框架，实现对多种医学影像的自动肿瘤检测和临床报告生成。结合视觉特征提取和自然语言处理，实现上下文图像解释。采用坐标验证机制和概率高斯建模来表示异常分布，生成多层可视化技术、详细的医疗插图、叠加比较和统计图表，以提高临床诊断的信心。展示了零样本学习能力，减少了对大规模数据集的依赖。这种框架不仅能提高诊断效率，还能简化临床工作流程。", "conclusion": "本文提出的智能多模态框架在多模态医学影像的自动诊断支持方面表现出高性能，展示了零样本学习能力以减少对大规模数据集的依赖。这种框架代表了在自动化诊断支持和放射学工作流程效率方面的重要进展，但仍需进一步的临床验证和多中心评估以确保其有效性和安全性，进而可能广泛应用于实际临床环境中。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03363", "html_url": "https://arxiv.org/abs/2510.03363", "title": "通过匹配成本过滤的统一无监督异常检测", "title_en": "Unified Unsupervised Anomaly Detection via Matching Cost Filtering", "authors": "Zhe Zhang,Mingxiu Cai,Gaochang Wu,Jing Zhang,Lingqiao Liu,Dacheng Tao,Tianyou Chai,Xiatian Zhu", "background": "无监督异常检测（UAD）旨在仅使用正常训练数据来识别图像和像素级别的异常，适用于工业检查和医疗分析，但由于隐私问题和冷启动约束，异常是稀缺的。现有方法分为基于重建（恢复正常的同态）或嵌入（预训练表示）的类型，主要在图像或特征级别的匹配中生成异常图。然而，这些方法过于关注匹配噪声，限制了它们的检测能力。在更早的单一 RGB 基础上的 UAD 研究基础上，近来的发展已扩展到多模态情况，如 RGB-3D 和 RGB-Text。这些线相互孤立，限制了对这些挑战的综合理解与知识迁移。", "innovation": "本文提出了统一的 UAD，在匹配视角下适用于单一模态和多模态场景。提出了一种名为 Unified Cost Filtering (UCF) 的通用后续优化框架，用于优化任何 UAD 模型的异常成本体积。通过从测试样本获得的多层注意力指导，该框架减轻了匹配噪声并在多模态场景中突出了细微的异常。广泛的实验表明，UCF 可以提升多种 UAD 方法的有效性，在单一模态（RGB）和多模态（RGB-3D, RGB-Text）UAD 情景中均取得了新的最佳性能。", "conclusion": "本研究通过 Unified Cost Filtering (UCF) 强化了一类 UAD 方法，该方法在多模态和单一模态场景中取得了新的最佳性能。代码和模型将在指定的位置发布。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04072", "html_url": "https://arxiv.org/abs/2510.04072", "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning", "title_en": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning", "authors": "Ziyan Wang,Zheng Wang,Jie Fu,Xingwei Qu,Qi Cheng,Shengpu Tang,Minjia Zhang,Xiaoming Huo", "background": "强化学习（RL）已经成为提高大型语言模型（LLMs）推理能力的核心。然而，像Group Relative Policy Optimization (GRPO)这样的在线策略算法在早期训练中常常受到低质量回放产生的嘈杂梯度的影响，导致更新不稳定和探索效率低下。", "innovation": "提出了一种名为Slow-Fast Policy Optimization (SFPO)的新颖框架，通过将每个步骤分解为三阶段：短时间内在相同批次上的快速内步骤，用于控制策略更新前的回放机制，以及最终的缓慢校正。这种设计构思始终保持目标和回放过程不变，使得SFPO可以无缝集成到现有的策略梯度框架中。实验结果表明，SFPO在提高稳定性和减少回放次数方面优于GRPO，还缩短了实测时间。", "conclusion": "SFPO在数学推理基准测试中平均提高了2.80分，并实现了高达4.93倍的回放减少和4.19倍的实测时间缩短，以匹配GRPO的最佳精度。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02360", "html_url": "https://arxiv.org/abs/2510.02360", "title": "大型语言模型代理中的沉默螺旋现象", "title_en": "Spiral of Silence in Large Language Model Agents", "authors": "Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang", "background": "沉默螺旋理论认为，持少数观点的个人为了避免社交孤立而选择沉默，这使得多数观点在公共话语中占据主导地位。然而，当代理‘行动者’为大型语言模型时，传统的心理学术解释不再直接适用，因为沉默螺旋理论是基于人类社会开发的。该研究旨在探讨在大型语言模型群体中，是否可以通过纯粹的统计语言生成产生类似沉默螺旋的动态？", "innovation": "提出了一个评价框架来研究大型语言模型代理中的沉默螺旋现象。通过四个有系统变化的历史和人设信号控制条件来评估观点动态，使用曼-肯德尔检验、 Spearman秩检验以及集中度度量（如峰度和四分位距）进行评估。结果显示历史和人设信号共同作用会产生强烈的多数主导性，重现沉默螺旋模式；单独使用历史信号会导致强大的锚定效应；单独使用人设信号则会促进多样但不相关的观点。这项工作将计算社会学与负责任的人工智能设计相结合，突显了在监控和减轻大型语言模型系统中生成的群体一致性方面的需求。", "conclusion": "历史和人设信号共同作用会产生强大的多数主导性并重现沉默螺旋模式；单独使用历史信号会导致强烈的锚定效应；单独使用人设信号则会促进多样但不相关的观点，表明没有历史锚定，沉默螺旋动态无法出现。这项工作将计算社会学与负责任的人工智能设计相结合，强调需要监控和缓解大型语言模型系统中产生的群体一致性。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识坍塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度一致的文本。这会引发知识坍塌的风险，即通过同质化模型在时间上缩小可获取信息的范围。现有研究主要是针对封闭的选择题或模糊语义特征进行，没有考察时间趋势和文化背景下的变化。", "innovation": "本文提出了一个新方法来衡量知识多样性，即LLM输出中关于真实世界陈述的差异性，并使用该方法进行了广泛的实证研究，探讨了LLM知识坍塌。本文测试了27个LLM、155个覆盖12个国家的主题以及来自真实用户聊天的200种提示变体。研究表明，尽管较新的模型生成了更加多样化的主张，但几乎所有的模型在知识多样性方面都低于基本的网络搜索。此外，研究发现模型大小对知识多样性有负面影响，而检索增强生成（RAG）则具有积极影响，尽管改善程度因文化背景而异。最后，与传统知识来源（维基百科）相比，该研究发现国家特定的主张更倾向于英语，而非本地语言，突显了知识表现方面的差距.", "conclusion": "研究发现，较新的模型尽管生成了更加多样化的主张，但几乎所有的模型在知识多样性方面都低于基本的网络搜索。模型大小对知识多样性有负面影响，而检索增强生成（RAG）则具有积极影响。与传统的知识来源相比，国家特定的主张倾向于英语，而非本地语言，这突显了知识表现中的差距。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05173", "html_url": "https://arxiv.org/abs/2510.05173", "title": "SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models", "title_en": "SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models", "authors": "Peigui Qi,Kunsheng Tang,Wenbo Zhou,Weiming Zhang,Nenghai Yu,Tianwei Zhang,Qing Guo,Jie Zhang", "background": "文本-图像模型在从自然语言描述生成高质量图像方面表现出卓越的能力，但这些模型对对抗性提示非常脆弱，可能导致内容安全措施失效并生成有害内容。尽管采取了各种防御策略，但在保持实际应用中的实用性能同时提高抵抗攻击的鲁棒性方面仍面临巨大挑战。特别是在Stable Diffusion（SD）模型等广泛使用的文本-图像模型中，安全控制仍是一个难题。", "innovation": "本文通过首先对SD模型的文本编码器进行实证研究，发现[EOS]标记作为语义聚合器，在其嵌入空间中表现出良性与对抗性提示之间不同的分布模式。基于此发现，提出了一种名为SafeGuider的新框架，它采用两步方法对安全性进行控制。SafeGuider整合了嵌入级别的识别模型和一个具备安全意识的特征擦除束搜索算法，从而在保证对善意提示产生高质量图像生成的同时，也能抵御领域内外的攻击。该框架在多种攻击场景中将攻击成功率降到5.48%以下，在保护安全的同时也能够生成具有实际意义的安全内容。此外，SafeGuider不仅适用于SD模型，还能应用于其他文本-图像模型（如Flux模型），显示了其架构的灵活性和适应性。", "conclusion": "SafeGuider能够有效控制文本-图像模型的内容安全，既保持了生成质量又提供了抵御攻击的鲁棒性。SafeGuider不仅适用于特定模型，还可以推广到其他模型，进一步提高了实际部署时的安全性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06240", "html_url": "https://arxiv.org/abs/2510.06240", "title": "Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets", "title_en": "Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets", "authors": "Jiqun Pan,Zhenke Duan,Jiani Tu,Anzhi Cheng,Yanqing Wang", "background": "工业问答系统需要比通用对话模型更高的安全和可靠性，特别是在设备故障诊断等高风险场景中，错误可能导致严重后果。多智能体大型语言模型虽然增强了推理深度，但存在不可控的迭代和无法验证输出的问题。传统的蒸馏方法也难以将协作推理能力转移到轻量级、可用于部署的学生模型。", "innovation": "提出了基于知识图谱的大规模多智能体系统蒸馏（KG-MASD）方法。该方法将蒸馏问题定义为马尔可夫决策过程，并引入知识图谱作为可验证的结构先验，以丰富状态表示并确保收敛性。通过将协作推理与知识关联相结合，KG-MASD 生成了高信心的指令调优数据，并将推理深度与验证性共同集中到适合边缘部署的小型学生模型中。", "conclusion": "在工业问答数据集上的实验表明，KG-MASD 模型相较于基准模型在准确性上提高了2.4%到20.1%，显著提高了可靠性，使安全关键的工业场景中的可信AI部署成为可能。代码和数据可从此链接下载：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05379", "html_url": "https://arxiv.org/abs/2510.05379", "title": "AutoDAN-Reasoning：通过测试时缩放增强策略探索的 jailbreak 攻击", "title_en": "AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak Attacks with Test-Time Scaling", "authors": "Xiaogeng Liu,Chaowei Xiao", "background": "近期，大型语言模型（LLMs）的破解技术，如AutoDAN-Turbo，已经展示了自动化策略发现的强大能力。AutoDAN-Turbo 使用终身学习代理从无到有构建丰富的攻击策略库，虽然效果显著，但其测试时生成过程依赖于随机采样策略并生成一个对应的攻击提示，这可能无法充分利用已学习策略库的全部潜力。", "innovation": "本文提出了一种通过测试时缩放来进一步改进AutoDAN-Turbo攻击性能的方法，引入了两种不同的缩放方法：Best-of-N 和 Beam Search。Best-of-N 方法生成多个候选攻击提示并选择最有效的；Beam Search 方法通过探索策略库中的组合，发现更强大的和协同的攻击向量。实验结果表明，提出的方法显著提升了性能，Beam Search 在 Llama-3.1-70B-Instruct 上的成功率提高了 15.6 个百分点，并且相比于高度 robust 的 GPT-o4-mini，相对改进幅度达到了近 60%。", "conclusion": "通过测试时缩放的方法显著提升了 AutoDAN-Turbo 的攻击性能，尤其是 Beam Search 方案在几种大型语言模型上的成功应用展示了其有效性，有望为设计更强大和更有效的攻击策略提供新的思路和技术手段。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05858", "html_url": "https://arxiv.org/abs/2510.05858", "title": "电话对话总结中大型语言模型的领域适应连续预训练（DACP）", "title_en": "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization", "authors": "Xue-Yong Fu,Elena Khasanova,Md Tahmid Rahman Laskar,Harsh Saini,Shashi Bhushan TN", "background": "大型语言模型在文本摘要方面表现出色，但在应用于与原始预训练分布不同的专门领域时，其性能往往不足。尽管微调可以改善摘要质量，但通常依赖昂贵且稀有的高质量标记数据。本文探讨了连续预训练作为为下游摘要任务适应大型语言模型的可扩展、自我监督的方法，特别是在嘈杂的现实世界对话转录背景下。我们通过大规模、未标记的商务对话数据进行了详尽的实验，以调查连续预训练是否能增强模型在对话摘要方面的能力。结果显示，连续预训练在领域内和领域外摘要基准测试中均取得了显著提升，同时保持了良好的通用性和鲁棒性。我们还分析了数据选择策略的影响，为在摘要导向的工业应用中应用连续预训练提供了实用指南。", "innovation": "本文提出了通过连续预训练来适应大型语言模型的领域适应方法，特别是针对电话对话摘要任务。通过大规模未标记的数据，这种方法能够显著提高模型在摘要任务上的表现，同时保持很好的通用性和鲁棒性。此外，还探讨了数据选择策略的效果，为实际应用提供了实用建议。", "conclusion": "连续预训练方法在电话对话摘要任务中能够显著提升模型在领域内和领域外的表现，同时保持了良好的通用性和鲁棒性。数据选择策略对模型表现有重要影响，为实际应用提供了参考。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04205", "html_url": "https://arxiv.org/abs/2510.04205", "title": "PolyKAN: 一种具有可证和近似最优化的KAN压缩的多面体分析框架", "title_en": "PolyKAN: A Polyhedral Analysis Framework for Provable and Approximately Optimal KAN Compression", "authors": "Di Zhang", "background": "Kolmogorov-Arnold网络（KANs）作为一种新的神经网络模型，相较于传统的多层感知机（MLPs），具有更好的可解释性和坚实的数学基础。然而，KANs在参数效率上的问题限制了它们的实际部署。已有研究表明，通过压缩KANs可以显著减小模型大小并提高效率，但缺乏有效的数学保证来确保压缩过程中的模型逼近精度和全局最优性，尤其是在保持低误差阈值的情况下。现有方法对KANs压缩的研究尚未提供系统的理论框架和保证，这限制了其在实际应用中的效率和可靠性。因此，开发一种具有数学保证的KANs压缩方法是必要的。", "innovation": "本文提出了一种名为PolyKAN的新颖理论框架，用于KANs的压缩，并提供了模型大小减少和逼近误差的正式保证。作者通过利用KANs的固有多项式结构，将压缩问题表述为一个多面体区域合并任务，进而建立KANs的代数多面体表示法，发展了$\frac{\text{逼近误差}}{\text{误差}}$压缩的完整理论，并设计了一个动态规划算法，可以在指定误差范围内实现近乎最优的压缩。理论分析表明，PolyKAN能够确保实现可证和近似最优的压缩，同时在提出特定误差边界的情况下能够达到全局最优。这是第一个为KANs压缩提供数学保证的框架，为开发高效的可解释神经架构部署开辟了新的方向。", "conclusion": "本文提出的PolyKAN框架通过提供数学保证，实现了KANs压缩的可证和近似最优（provable and approximately optimal）性，从而为KANs的实际应用打开了新的可能。该框架不仅能够有效减少模型大小，还能够在误差可控的前提下实现全局最优，为未来的神经网络压缩技术提供了新的思路和方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06239", "html_url": "https://arxiv.org/abs/2510.06239", "title": "OpenStaxQA：基于开源大学教科书的多语言数据集", "title_en": "OpenStaxQA: A multilingual dataset based on open-source college textbooks", "authors": "Pranav Gupta", "background": "本研究基于43本开放获取的英语、西班牙语和波兰语的大学教科书，构建了一个专门针对大学教育应用的评估基准，这些教科书均采用可宽 phổ许可的创意共享许可证。研究团队利用量化低秩适配器（QLoRa）对大约7亿参数量的大型语言模型（LLMs）进行微调和评估，并在AI2推理挑战开发数据集上进行零样本评估，以验证OpenStaxQA在其他任务上的性能提升潜力。研究还讨论了与OpenStaxQA类似的大规模数据集的相关广泛影响问题，这些问题涉及伦理、多样性和潜在的社会影响等方面。", "innovation": "本研究提出了一种特定于大学教育应用的评估基准OpenStaxQA，该基准基于多语言的开放源代码教科书。使用量化低秩适配器（QLoRa）对大型语言模型进行微调，在零样本评估中展示了模型在其他任务上的性能提升。同时，研究还讨论了关于数据集的更广泛的的影响，包括伦理、多样性和社会影响等方面的问题。", "conclusion": "研究结果表明，OpenStaxQA 数据集能够有效评估和提升大型语言模型在教育和相关任务中的性能。此外，研究还强调需要考虑与大规模数据集相关的伦理和社会影响问题。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05942", "html_url": "https://arxiv.org/abs/2510.05942", "title": "EvalMORAAL: 可解释的链式思维和LLM评委评价方法在大型语言模型道德对接中的应用", "title_en": "EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation for Moral Alignment in Large Language Models", "authors": "Hadi Mohammadi,Anastasia Giachanou,Ayoub Bagheri", "background": "该研究旨在评估20个大型语言模型的道德对齐情况，采用EvalMORAAL框架，利用世界价值观调查和PEW全球态度调查进行评估。研究发现，顶级模型与调查问卷响应的高度一致（WVS皮尔逊相关系数约为0.90），但存在明显的区域差异，西方地区平均相关系数为0.82，而非西方地区平均相关系数为0.61，表明存在持续的区域偏差。该框架包括三个方面：1. 两种评分方法（对数概率和直接评分）用于所有模型，以实现公平比较；2. 结构化的链式思维协议，包括自我一致性检查；3. 模型作为评委的同伴评审，标记了348个冲突，使用数据驱动的阈值。同伴评审的一致与问卷调查的一致性相关（WVS相关系数=0.74，PEW相关系数=0.39，两者p<0.001），支持自动质量检查。这些结果表明，我们在文化感知AI方面取得了一定的进步，但也指出了跨地区使用时面临的开放挑战。", "innovation": "该研究创新性地提出了一种透明的链式思维框架EvalMORAAL，该框架采用两种评分方法（对数概率和直接评分）及模型作为评委的同伴评审，旨在评估大型语言模型的道德对齐情况。此外，该研究还首次通过区域差异展示了在评估中发现的区域偏见，并提出了结构化链式思维协议及同伴评审机制，为未来类似研究提供了参考框架。", "conclusion": "该研究证实了大型语言模型在道德对齐方面的进步，但仍存在明显的区域偏差。未来的研究需要关注如何减少这种偏差，以实现更公平、更一致的道德对齐评估。"}
{"llm_update_time": "20251009", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04716", "html_url": "https://arxiv.org/abs/2510.04716", "title": "A Calibration-Free Fixed Point of Curved Boolean Logic Matching the Fine-Structure Constant", "title_en": "A Calibration-Free Fixed Point of Curved Boolean Logic Matching the Fine-Structure Constant", "authors": "Maximilian R. P. von Liechtenstein", "background": "该研究涉及的是Curved Boolean Logic（CBL）的一种特殊的固定点，在这种固定点下，每张面的共形群子theta_0在独立的最小面（CHSH，KCBS，SAT_6）中是相同的。这种共形群子是由通过解一个包含两个变量的系统F(delta, gamma_4, gamma_5, gamma_6) = (theta_0^(4) - theta_0^(5), theta_0^(5) - theta_0^(6)) = 0得到的，解法使用了Gauss-Newton方法，并且没有外部标度。解的确定性源于有限差分雅可比矩阵在解处的满秩性质，这暗示了局部唯一性。此外，通过设定耦合级别g = |theta_0|/(2*pi*n)消除了隐藏的长度因子，而数值归一化审核表明g = alpha（汤姆森极限值）在数值精度范围内。这些耦合的计算使用了SU(1,1)的角落单词和重叠放的位置，并进行了变分最小极大分析，以及非回溯谱密度的初步分析，且与每条边的耦合一致。研究的范围限定在低能（汤姆森）极限内，复杂的谱平等问题被简短地提出为一个猜想。这些结果不仅验证了CBL与α之间的标定联系，还将其提升为一个无标定量化的候选派生机制。", "innovation": "该研究的创新之处在于，它发现了一种不需要标定的方法来找到Curved Boolean Logic的固定点，使得每张面的共形群子theta_0在独立的最小面中相同。这种方法通过解Gauss-Newton方法下的一个系统方程来实现，并且能够在数值上验证耦合级别g = alpha（汤姆森极限值），同时通过变分最小极大分析和非回溯谱密度分析提供了理论支持。此外，该研究提出了一个纯粹拓扑的公式，并指出还需要完成对复杂谱平等的验证。", "conclusion": "该研究提出的固定点为Curved Boolean Logic提供了一种从标定量化的识别提升到无标定量化的派生候选机制的计算方法。在此模型中，耦合级别g = alpha满足低能（汤姆森）极限。研究范围限定在低能极限内，复杂谱平等问题是否成立还需要进一步验证。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06242", "html_url": "https://arxiv.org/abs/2510.06242", "title": "开放参考的透明自动评估开放性用户调查响应", "title_en": "Transparent Reference-free Automated Evaluation of Open-Ended User Survey Responses", "authors": "Subin An,Yugyeong Ji,Junyoung Kim,Heejin Kook,Yang Lu,Josh Seltzer", "background": "开放性调查响应为市场营销研究提供了宝贵的见解，但低质量的响应不仅给研究人员增加了手动筛选的负担，还可能导致误导性的结论，强调了有效评价的重要性。现有的自动评价方法主要针对LLM生成的文本，未能评估具有独特特征的人类撰写的响应。因此，需要一种专门针对人类调查响应的评估框架。", "innovation": "本文提出了一个两阶段的评价框架，专门设计用于人类调查响应。首先，筛选掉无意义的响应。然后，使用LLM能力从三个维度——努力程度、相关性和完整性——评估响应。通过英语和韩语数据集验证，该框架不仅优于现有指标，也展示了在如响应质量预测和响应拒绝等实际应用中的高实用性，并与专家评估有较高的相关性。", "conclusion": "所提出的框架在实际应用中表现出强大的相关性，并且在响应质量预测和响应拒绝等方面具有很高的实用性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06244", "html_url": "https://arxiv.org/abs/2510.06244", "title": "评估科学领域嵌入框架", "title_en": "Evaluating Embedding Frameworks for Scientific Domain", "authors": "Nouman Ahmed,Ronin Wu,Victor Botev", "background": "在特定领域中找到最佳单词表示算法尤为重要，因为同一个单词在不同领域和上下文中可能有不同的含义和表示。尽管生成式AI和变换器架构能很好地生成任何单词的上下文嵌入，但在从零开始预训练这类模型时，它们非常耗时和计算资源密集。因此，本文专注于科学领域，寻找最佳的单词表示方法和标记化方法，以在科学领域的自然语言处理任务中使用。目标是评估在科学领域中使用的不同单词表示和标记化算法的效果，以构建一个全面的评估套件，以便未来的新算法也能被评估。", "innovation": "本文构建了一个包含多个下游任务和相关数据集的评估套件，用于测试和评估各种单词表示和标记化算法，在科学领域提供了具体的评估方法和标准，以推动该领域的研究发展。", "conclusion": "通过本文构建的评估套件，研究人员可以轻松地测试和评估单词表示和标记化算法的效果，使得评估可以更系统、更标准化，促进了科学领域的自然语言处理技术的发展。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06243", "html_url": "https://arxiv.org/abs/2510.06243", "title": "CoT Referring：通过接地推理提高指代表达任务", "title_en": "CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning", "authors": "Qihua Dong,Luis Figueroa,Handong Zhao,Kushal Kafle,Jason Kuen,Zhihong Ding,Scott Cohen,Yun Fu", "background": "指代表达理解和分割是评估语言理解和图像理解整合的关键任务，对于多模态大型语言模型（MLLMs）的能力具有基准性质。现有的挑战在于如何通过多模态的训练数据结构来增强模型推理能力。", "innovation": "提出了一种新的策略CoT Referring，通过结构化的链式思考训练数据结构来增强跨模态的模型推理。这种方法重新设计了训练数据输出形式，并提供了新的注释，构建了一个专门针对复杂指代情况的评估基准。同时，将检测和分割能力整合到统一的MLLM框架中，并使用新的自适应加权损失进行训练以优化性能。", "conclusion": "在自定义基准和RefCOCO/+/g上的实验结果显示，该方法的有效性，相较于基线模型准确率提高了2.5%以上。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06249", "html_url": "https://arxiv.org/abs/2510.06249", "title": "TRepLiNa：在Aya-23 8B中层WISE的CKA+REPINA对齐改进低资源机器翻译", "title_en": "TRepLiNa: Layer-wise CKA+REPINA Alignment Improves Low-Resource Machine Translation in Aya-23 8B", "authors": "Toshiki Nakai,Ravi Kiran Chikkala,Lena Sophie Oberkircher,Nicholas Jennings,Natalia Skachkova,Tatiana Anikina,Jesujoba Oluwadara Alabi", "background": "该论文针对印度低资源语言（LRLs）缺乏资源的问题，通过2025年提出的多模态模型跨资源语言挑战（MMLoSo），探索改善从LRL到高资源语言（HRL）翻译质量的方法。研究集中在特定解码器内部层采用交叉语言相似度机制以提高翻译质量的研究，特别是在数据稀缺的情况下更加有效的方法。研究团队选取了特定的语言对进行实验，包括Mundari、Santali、Bhili，以及汉语文本的转介翻译，使用Aya-23 8B与QLoRA进行多语言对话模型训练与测试。", "innovation": "研究提出了TRepLiNa方法，结合了Centred Kernel Alignment（CKA），一种鼓励不同语言表示对齐的相似度度量方法，和REPINA，一种限制参数更新保持接近预训练模型的正则化方法。通过在中间层级上应用CKA和REPINA的联合方法，研究证明在数据稀缺的场景下，这种方法是一种低成本且实用的方法，能够有效提升LRL的翻译质量。", "conclusion": "研究结果表明，采用TRepLiNa（CKA+REPINA）在中间层级上的对齐方法，能够显著提高低资源语言的翻译质量，特别是在数据稀缺的情况下，是一种可行且有效的方案。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06265", "html_url": "https://arxiv.org/abs/2510.06265", "title": "大型语言模型中的幻觉：成因、检测与缓解——全面综述", "title_en": "A Comprehensive Survey of Hallucination in Large Language Models: Causes, Detection, and Mitigation", "authors": "Aisha Alansari,Hamzah Luqman", "background": "大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但在某些任务中出现了生产虚假或伪造信息的现象，称为幻觉。幻觉是指LLM生成的内容虽然流畅且语法正确，但缺乏事实依据或外部证据支持。此类问题削弱了LLM的信任度和可靠性，尤其是在需要准确性的领域。因此，本文综述了LLM幻觉的研究，重点关注其成因、检测方法和缓解策略，旨在提高LLM的可靠性和信任度。", "innovation": "本文提供了一个全面的LLM幻觉综述，从数据收集、架构设计到推断等整个LLM开发生命周期，详细分析了幻觉的根源。同时构建了一个结构化的检测方法分类体系和缓解策略分类体系，还评估了现有检测和缓解方法的优势与局限性，并审查了现有评估基准和度量标准。", "conclusion": "最后，本文指出了未来研究的关键挑战和有前景的方向，为开发更真实可靠的LLM奠定了基础。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06262", "html_url": "https://arxiv.org/abs/2510.06262", "title": "Prakriti200：基于问卷的200份印度传统医学Prakriti评估数据集", "title_en": "Prakriti200: A Questionnaire-Based Dataset of 200 Ayurvedic Prakriti Assessments", "authors": "Aryan Kumar Singh,Janvi Singh", "background": "该数据集提供了标准化的英语-印地语Prakriti评估问卷的响应，用于根据经典的印度医学（Ayurveda）原理评估个人的物理、生理和心理特征。问卷包括24个多项选择题，涵盖身体特征、食欲、睡眠模式、能量水平和气质等方面。根据AYUSH/CCRAS指南开发，确保数据收集的全面性和准确性。所有问题都是强制性的，并以中性措辞提供，以减少偏差，且dosha标签（Vata, Pitta, Kapha）被隐藏在参与者面前。", "innovation": "问卷设计遵循AYUSH/CCRAS指南，确保数据的全面性和准确性；所有问题都是强制性的，并以中性措辞提供，以减少偏差；dosha标签被隐藏，以保护参与者的隐私；数据通过Google Forms自动收集，便于自动评分，将个人特质映射到dosha特定评分，为计算智能、印度传统医学研究和个人健康分析提供结构化的数据平台，支持特质分布、相关性分析和预测建模。", "conclusion": "该数据集为基于Prakriti的研究提供了结构化的平台，支持计算智能、印度传统医学研究和个人健康分析，可用于特质分布、相关性分析和预测建模的分析，也可作为未来基于Prakriti的研究和智能健康应用开发的参考。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06275", "html_url": "https://arxiv.org/abs/2510.06275", "title": "重现性研究：基于大型语言模型的可解释推荐系统XRec", "title_en": "Reproducibility Study of \"XRec: Large Language Models for Explainable Recommendation\"", "authors": "Ranjan Mishra,Julian I. Bibo,Quinten van Engelen,Henk Schaapman", "background": "本研究重现了Ma等人的2024年论文\"XRec: 大型语言模型的可解释推荐\"的工作。原作者们提出了一个模型无关的协作指令调优框架XRec，使得大型语言模型能够为用户提供生成推荐的全面解释。研究的目标是使用Llama 3作为评估的LLM，重现原论文的结果，而不是使用GPT-3.5-turbo。通过对Ma等人提供的源代码进行扩展，本研究通过对XRec混合专家模块的输入嵌入进行修改或删除输出嵌入，来实现上述目标。", "innovation": "本研究对原论文进行了扩展，通过修改或删除XRec混合专家模块的输入嵌入或输出嵌入来实现评估。结果显示，XRec能够生成个性化解释，并通过融入协作信息提高了稳定性。尽管如此，XRec在所有指标上并不总是优于基线模型。此外，增强了对混合专家嵌入在形成解释结构中的作用以及协作信号与语言建模交互重要性的理解。", "conclusion": "本研究提供了开源的评估实现，增强了研究人员和实践者之间的可访问性。完整的代码库可在指定的Github地址获取。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06266", "html_url": "https://arxiv.org/abs/2510.06266", "title": "语言模型在ビルボード音乐榜滥用内容纵向分析中的应用", "title_en": "Language models for longitudinal analysis of abusive content in Billboard Music Charts", "authors": "Rohitash Chandra,Yathin Suresh,Divyansh Raj Sinha,Sanchit Jindal", "background": "近年来，音乐中的虐待和性暗示内容急剧增加，特别是在ビルボード音乐图表中。然而，缺乏验证这些趋势的研究，以有效制定相关政策，特别是这类内容对孩子和青少年有害的行为变化。本文通过70年来ビルボード美国音乐图表中的歌曲（歌词）进行深度学习方法分析，填补了这一研究空白。研究表明，自1990年以来，流行音乐中的露骨内容显著增加，歌曲中包含猥亵、性暗示和其他不适当语言的比例也在增加。", "innovation": "本文利用深度学习方法对ビルボード音乐图表中的歌曲进行纵向分析，通过情感分析和滥用内容检测来研究内容的演变。这是首次使用语言模型进行此类长时间序列的数据分析，揭示了歌词内容的复杂模式及其与社会规范和语言使用的变化之间的联系。", "conclusion": "研究表明，自1990年以来，流行音乐中的露骨内容显著增加。随着时间推移，语言模型在捕捉歌词内容的细微变化方面显示出潜力，反映出社会规范和语言使用的转变。为有效制定针对滥用和性暗示音乐内容的政策提供了理论依据。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06263", "html_url": "https://arxiv.org/abs/2510.06263", "title": "面向急诊医师的双阶段轻量级病历摘要系统", "title_en": "Dual-stage and Lightweight Patient Chart Summarization for Emergency Physicians", "authors": "Jiajun Wu,Swaleh Zaidi,Braden Teitge,Henry Leung,Jiayu Zhou,Jessalyn Holodinsky,Steve Drew", "background": "电子健康记录（EHRs）中包含大量的未结构化临床数据，这些数据可能会使急诊医师在寻找关键信息时感到压力。因此，需要一种能够在保持患者隐私的同时，在设备上生成临床摘要的技术来帮助急诊医师快速获取关键信息。传统的离线生成摘要方法通常需要大量的计算资源，并且无法直接在设备上实现，因此影响了其实用价值。本文提出了一种双阶段的病历摘要系统，该系统可以在嵌入式设备上运行，实现离线生成摘要并在保护患者隐私的前提下提高系统的响应速度和实用性。", "innovation": "本文介绍了一种双阶段、轻量级病历摘要系统。该系统使用双Jetson Nano设备架构，通过Jetson Nano-R进行检索并使用Jetson Nano-S生成结构化的摘要，二者之间通过轻量级套接字进行通信。系统能生成两种类型的摘要输出：固定格式的关键发现列表和焦点于医生查询的内容相关的叙述性描述。系统以本地存储的EHR为基础，对长文本进行语义分割，并使用小型语言模型（SLM）在受到设备资源限制的情况下生成摘要。通过评估六款参数量少于7B的开源SLM，最终选择了合适的模型，并利用LLM-as-Judge机制评估摘要的质量。实验结果表明，该系统可以有效在30秒内生成有用摘要，适用于真实的MIMIC-IV和去标识化的EHR数据集。", "conclusion": "本文提出了一种针对急诊医师的双阶段、轻量级病历摘要系统，该系统完全在嵌入式设备上运行，能够生成结构化和语义化的摘要，同时保护患者隐私。实验结果表明该系统能够在极短的时间内有效地生成有用的摘要，对于急诊临床场景具有很高的适用性和实用性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06250", "html_url": "https://arxiv.org/abs/2510.06250", "title": "在LLM中负责任的人工智能多语言PII标注的可扩展方法", "title_en": "Scalable multilingual PII annotation for responsible AI in LLMs", "authors": "Bharti Meena,Joanna Skubisz,Harshit Rajgarhia,Nand Dave,Kiran Ganesh,Shivali Dalmia,Abhishek Mukherji,Vasudevan Sundarababu,Olga Pospelova", "background": "随着大规模语言模型（LLMs）的广泛应用，确保它们在各种监管环境下可靠地处理个人可识别信息（PII）已经成为必要。这一工作旨在提供一种针对13种未广泛应用语言的可扩展的多语言数据编目框架，覆盖约336种特定于地方的PII类型。", "innovation": "该工作介绍了一种以人为本的分阶段注释方法，结合了语言学专业知识和严格的质量保证，显著提高了召回率和假阳性率。通过利用注释者间的一致性度量和根本原因分析，框架系统地揭示并解决了注释不一致问题，形成了适应用于监督LLM微调的高保真数据集。此外，该工作还明确了多语言PII标记中的常见注释挑战，并展示了迭代、数据驱动的工作流可以同时提高注释质量和下游模型可靠性。", "conclusion": "该框架通过高质量PII标注为监管合规性下的大规模语言模型提供支持，通过系统的分析流程有效提升了数据质量和模型性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06304", "html_url": "https://arxiv.org/abs/2510.06304", "title": "多语言疑问句表示中的类型和复杂性信号", "title_en": "Type and Complexity Signals in Multilingual Question Representations", "authors": "Robin Kokot,Wessel Poelman", "background": "本文旨在研究多语言变压器模型如何表示疑问句的形态语法属性，特别关注不同语言中疑问句类型的特征及其复杂性。为此，作者构建了一个包含七种语言的句子数据集——Question Type and Complexity (QTC)数据集，并标注了疑问句类型和复杂性指标，如依赖长度、树深度和词素密度等。评估方法不仅扩展了探针方法到回归标签，还加入了选择性控制以量化泛化性能的提升。", "innovation": "该研究创新地将探针方法应用于多语言环境中，并引入了QTC数据集来评估疑问句表示的类型和复杂性信号。研究对比了层分析探针在冻结Glot500-m表示上的表现，以及使用子词TF-IDF基线和微调模型的表现。结果显示，统计特征在具有显式标记的语言中能有效分类疑问句，而神经探针则能更准确捕捉细微的结构性复杂性模式。此外，该研究讨论了上下文表示在统计基线上的优越性，以及参数更新是否减少了预备训练语言信息的可用性。", "conclusion": "研究发现，统计特征在具有显式标记的语言中有效分类疑问句，而神经探针则能更准确地捕捉细微的结构性复杂性模式。当评估多语言疑问句表示的类型和复杂性时，上下文表示通常优于统计基线，但在某些情况下，参数更新可能减少了预训练语言信息的可用性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06370", "html_url": "https://arxiv.org/abs/2510.06370", "title": "EVALUESTEER: 测量奖励模型的价值和偏好导向性", "title_en": "EVALUESTEER: Measuring Reward Model Steerability Towards Values and Preference", "authors": "Kshitish Ghate,Andy Liu,Devansh Jain,Taylor Sorensen,Atoosa Kasirzadeh,Aylin Caliskan,Mona T. Diab,Maarten Sap", "background": "随着大规模语言模型（LLMs）的全球部署，创造能够适应全球用户多样价值观和偏好的系统变得至关重要。现有的数据集无法支持对奖励模型（RMs）导向性的控制性评估，因此需要一个新基准来衡量LLMs和RMs在心理和人机交互研究基础上体现用户价值观和风格偏好导向性的能力。", "innovation": "提出了EVALUESTEER基准，该基准通过合成生成165,888对偏好组，系统地在4个价值观维度（传统、世俗理性、生存、自我表达）和4个风格维度（语义丰富度、可读性、信心、温暖）上变化生成，来评估LLMs和RMs在给定用户轮廓和候选价值观和风格导向回应对时，能否选出符合用户偏好输出的能力。研究涵盖了16种系统的提示条件和6种偏好比较场景，结果显示，在仅提供相关价值观和风格偏好时，最佳模型的准确率高达99%以上，但当全部价值观和风格偏好信息都提供时，准确率仅达75%以下。", "conclusion": "EVALUESTEER揭示了当前RMs识别和适应用户资料信息的局限性，并为开发可以导向多样化人类价值观和偏好的RMs提供了一项具有挑战性的测试平台。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06354", "html_url": "https://arxiv.org/abs/2510.06354", "title": "通过理想分布视角进行的LLM偏差检测与缓解", "title_en": "LLM Bias Detection and Mitigation through the Lens of Desired Distributions", "authors": "Ingroj Shrestha,Padmini Srinivasan", "background": "尽管先前关于偏差缓解的工作主要集中在促进社会平等和人口统计公平上，但很少有研究关注使大型语言模型（LLM）的输出结果与期望分布相一致。例如，我们可能希望模型的输出分布与现实世界相符合，以支持事实依据。因此，文中定义偏差为偏离期望分布的差异。文章通过三个基于美国劳动力统计数据的职业集（男女主导和性别平衡）来评估自适应方法和非自适应方法的有效性。研究发现，即使在期望分布下，偏见也是存在的，但在平等分布下，接近完全缓解，而在真实世界设置下则有30-75%的减少效果。", "innovation": "文章提出了一种基于加权自适应损失的微调方法，该方法可以将LLM的性别-职业输出分布与期望分布对齐，同时保持语言建模能力。通过使用三种不同职业集进行评估，文章展示了在不同情况下偏见的缓解程度，并对比了自适应和非自适应方法的效果。这种方法不同于传统的平等和人口统计公平，而是关注与期望分布相符的差异性。", "conclusion": "研究发现，采用自适应方法可以在平等分布下几乎完全缓解偏见，并在真实世界设置下实现30-75%的偏见减少。自回归LLM在平等分布下没有偏见，但在真实世界设置下表现出明显偏见，Llama Instruct模型在此设置下实现了50-62%的偏见减少。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06411", "html_url": "https://arxiv.org/abs/2510.06411", "title": "在虚拟实验室环境中对学生评估的指令目标导向的题生成：LLM们实际上能多接近？", "title_en": "Instructional Goal-Aligned Question Generation for Student Evaluation in Virtual Lab Settings: How Closely Do LLMs Actually Align?", "authors": "R. Alexander Knipper,Indrani Dey,Souvika Sarkar,Hari Narayanan,Sadhana Puntambekar,Santu Karmaker", "background": "虚拟实验室提供了实用性很强的动手和探究式科学学习机会，但教师常常难以将这些实验室调整以符合他们的教学目标。第三方材料可能不适应课堂需求，自行开发定制资源则耗时且难以规模化。", "innovation": "论文提出了一种新颖的指令目标导向的题生成框架，使教师能够利用大语言模型（LLMs）生成符合虚拟实验室情境和教育意义的问题，通过自然语言交互实现。该框架整合了四个组件：通过教师-LLM对话理解教学目标、通过知识单元和关系分析理解虚拟实验室、分类题目的认知和教育意图结构以及TELeR分类控制提示细节。", "conclusion": "该研究通过教师协助的小型案例研究，以及最终评估的19种开源LLMs生成的超过1,100个问题，展示了目标和虚拟实验室理解使问题扎根于教师意图和模拟背景的重要性。题目分类提高了认知要求（开放式格式和关系类型使质量提高0.29-0.39分），优化TELeR提示增强了格式一致性（80%的可解析度，90%以上的一致性）。大型模型带来了最大的收益：可解析度提高了37.1%，一致性提高了25.7%，平均质量提高了0.8个Likert点。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06371", "html_url": "https://arxiv.org/abs/2510.06371", "title": "EverydayMMQA: 一种面向文化的多语言和多模态框架，用于口头视觉问答", "title_en": "EverydayMMQA: A Multilingual and Multimodal Framework for Culturally Grounded Spoken Visual QA", "authors": "Firoj Alam,Ali Ezzat Shahroor,Md. Arid Hasan,Zien Sheikh Ali,Hunzalah Hassan Bhatti,Mohamed Bayan Kmainasi,Shammur Absar Chowdhury,Basel Mousi,Fahim Dalvi,Nadir Durrani,Natasa Milic-Frayling", "background": "大规模的多模态模型在视觉问答（VQA）等任务上取得了优异的结果，但在需要文化背景和日常知识的查询时往往会失败，尤其是在低资源和未充分代表的语言中。为了解决这个问题，作者引入了EverydayMMQA框架，用于创建面向文化的大型多语言多模态数据集，以支持口头和视觉问答（SVQA）任务。该框架构建的OASIS数据集结合了语音、图像和文本，包含了来自18个国家的英语和阿拉伯语多样内容。OASIS的数据集旨在测试涉及语用、常识和文化意识推理的任务，而不仅仅是对物体的识别。", "innovation": "引入了EverydayMMQA框架，用于创建文化背景下的大型多语言和多模态数据集，特别关注解决低资源语言中的多模态问题。通过该框架开发的OASIS数据集包括超过920万张图像和超过1.48亿个问答对，创造了四种输入组合：语音、文本、语音+图像和文本+图像。该数据集不仅用于验证模型在对象识别之外的任务，还用于实战更加贴近真实的多功能场景，例如语用理解、常识应用和文化意识理解。研究还测试了多种预先训练的闭源模型和开源模型，这些模型都使用了新创建的OASIS数据集。", "conclusion": "EverydayMMQA和OASIS一起为构建适合具体文化背景下的多模态大语言模型（LLM）提供了全新的数据和基准测试。这一框架和数据集将对社区公开，以促进多模态大语言模型的发展。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06386", "html_url": "https://arxiv.org/abs/2510.06386", "title": "随训练时属性正则化的可控制风格化文本生成", "title_en": "Controllable Stylistic Text Generation with Train-Time Attribute-Regularized Diffusion", "authors": "Fan Zhou,Chang Tian,Tim Van de Cruys", "background": "生成具有特定属性的风格化文本是可控文本生成中的一个关键问题。近年来，扩散模型在视觉和文本生成中展现出强大的能力。现有方法主要分为无分类器引导（CFG）和分类器引导（CG）方法两类。虽然CFG有效保留了语义内容，但往往无法提供有效的属性控制。相比之下，CG通过使用分类器梯度修改去噪轨迹，能够更好地实现属性对齐，但在采样过程中会带来高昂的计算成本，并且在分类器泛化方面存在问题。", "innovation": "本文提出了一种名为RegDiff的正则化扩散框架，该框架在采样过程中无需预训练分类器，从而实现低成本的可控生成。具体而言，RegDiff使用基于VAE的编码器-解码器架构确保重构保真度，并使用带有属性监督训练的潜在扩散模型以实现可控文本生成。属性信息仅在训练过程中注入。实验结果表明，RegDiff在五个涵盖不同风格属性的数据集上优于强基线，这些结果验证了RegDiff作为高效属性可控文本扩散解决方案的有效性。", "conclusion": "RegDiff通过在训练时属性正则化的方式实现了可控的风格化文本生成，相比现有方法具有计算成本低、效果好的优势。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06391", "html_url": "https://arxiv.org/abs/2510.06391", "title": "奖励模型观点：奖励模型关注的是谁的观点？", "title_en": "Reward Model Perspectives: Whose Opinions Do Reward Models Reward?", "authors": "Elle", "background": "奖励模型（RMs）在语言模型（LMs）的对齐中起着核心作用。通常，RMs被用作人类偏好的代理，以指导下游LM的行为。然而，目前对RMs行为的理解还很有限。本研究旨在：（i）建立了一种衡量由RMs捕获的意见对齐框架；（ii）探讨RMs在多大程度上表现出社会人口统计学偏见；（iii）探索引导以使奖励趋向目标群体偏好的效果。我们的研究关注了争议话题上的主观和多元的观点，从而量化了RMs观点的意见、态度和价值观。我们发现RMs与多个社会人口统计学群体不匹配，并且系统奖励有害刻板印象。单纯引导不足以克服这些局限性。研究结果强调，需要在偏好学习的过程中更仔细地考虑RMs行为，以防止传播我们使用的语言技术中不需要的社会偏见。", "innovation": "建立了衡量RMs对齐的框架；探讨RMs的社会人口统计学偏见；研究引导以使奖励趋向目标群体偏好的影响；量化RMs的观点、态度和价值观；发现RMs与社会群体的不对齐及系统性奖励有害刻板印象的现象", "conclusion": "通过研究发现RMs与多个社会人口统计学群体的不匹配，并指出单纯引导不足以克服这些局限性。研究强调在偏好学习过程中需要更加谨慎地考虑RMs行为，以防止社会偏见的传播。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06427", "html_url": "https://arxiv.org/abs/2510.06427", "title": "通过统一论元结构解析器弥合话语树库差距", "title_en": "Bridging Discourse Treebanks with a Unified Rhetorical Structure Parser", "authors": "Elena Chistova", "background": "提出了UniRST，这是首个能够处理11种语言中有18个树库的统一RST风格的话语解析器，且无需修改它们的关系库存。面对库存不兼容问题，研究提出了两种训练策略：Multi-Head和Masked-Union。首先，使用简单而有效的增强技术对单项树库解析进行基准测试，特别是适用于资源匮乏的环境。然后，研究通过统一模型表明，Masked-Union方法不仅参数更高效，也是最强的方法，并且UniRST优于18个单项树库基线中的16个，证明了一体化、多语言端到端话语解析的优势，跨越了多种资源多样性。", "innovation": "提出了两种创新的训练策略：Multi-Head和Masked-Union。特别地，Masked-Union方法支持共享参数训练，且在参数效率上表现出色。UniRST能够处理大量的树库和语言，并实现了在多个单一数据库基线上的最佳表现。", "conclusion": "UniRST在单语言树库解析基准测试中表现出色，不仅参数效率高而且性能出色。该研究证明了一体化、多语言方法在提升话语解析准确性和普适性方面的优越性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06426", "html_url": "https://arxiv.org/abs/2510.06426", "title": "FinLFQA: 评估金融长文本问答中LLM的带注释文本生成", "title_en": "FinLFQA: Evaluating Attributed Text Generation of LLMs in Financial Long-Form Question Answering", "authors": "Yitao Long,Tiansheng Hu,Yilun Zhao,Arman Cohan,Chen Zhao", "background": "大型语言模型（LLMs）在回答长形式问题时经常产生虚构的答案，这些答案虽然听起来合理但实际上并不正确。虽然有一种常见的缓解策略是为LLM输出提供出处，但现有的基准测试主要关注简单的出处检索。然而，在金融等实际应用场景中，注释远远超越了简单的出处检索，需要包括支持证据的提取、中间数值推理步骤以及反映领域特定金融知识的推理过程。", "innovation": "本文介绍了FinLFQA，一个用于评估LLMs在生成复杂财务问题的长答案时，能否提供可靠和精细的注释的基准测试。FinLFQA通过人类标注评估三个关键方面的注释：(1)来自财务报告的支持证据的抽取，(2)中间的数值推理步骤，以及(3)反映推理过程的领域特定财务知识。同时，还提供一个自动评估框架，涵盖答案质量和注释质量。通过在八种LLM上进行广泛的实验，发现细粒度的指标对于区分模型能力很重要，端到端生成的性能与事后处理方法相当，在适当的外部反馈引导下，逐步改进才能提升性能。", "conclusion": "本文通过研究发现，对LLMs生成的金融长答案提供细粒度注释的能力是重要的评估指标。端到端生成方法与事后方法性能相近。在适当反馈引导下的逐步改进方法才有帮助。FinLFQA为其评估方法提供了理论框架和实践方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06445", "html_url": "https://arxiv.org/abs/2510.06445", "title": "关于代理性安全的综述：应用、威胁和防御", "title_en": "A Survey on Agentic Security: Applications, Threats and Defenses", "authors": "Asif Shahriar,Md Nafiu Rahman,Sadif Ahmed,Farig Sadeque,Md Rizwan Parvez", "background": "随着从被动大型语言模型（LLMs）迅速转变为自主LLM代理，网络安全领域正经历着新的范式转变。这些代理既可以作为强大的攻击和防御工具，也可能引入新的内在安全风险。", "innovation": "本文进行了首次全面调研代理性安全领域的综述，并围绕三个相互依赖的支柱构建了该领域的框架：应用、威胁和防御。提供了对超过150篇论文的全面分类，解释了代理的使用方式、存在的漏洞以及设计的保护措施。详细跨切分析揭示了代理架构中新兴的趋势，并指出了模型和模态覆盖方面的关键研究缺口。", "conclusion": "通过系统地分类文献并提供详细的分析，本研究为代理性安全领域的未来发展指明了道路，尤其是在模型和模态覆盖方面的研究缺口。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06383", "html_url": "https://arxiv.org/abs/2510.06383", "title": "从搜索引擎攻击保护去标识化文档", "title_en": "Protecting De-identified Documents from Search-based Linkage Attacks", "authors": "Pierre Lison,Mark Anderson", "background": "去标识化模型能够隐藏文档中提到的个人身份，但无法解决链接风险，即将去标识化文本映射回其源头的可能性。现有的方法往往通过在去标识化文档中提取短语并在原始数据集中查找其存在性来执行这一链接过程。本文介绍了保护去标识化文档不遭受基于搜索的链接攻击的方法，同时保持文本的语义完整性。", "innovation": "提出了一种通过构建文档集合中出现的N-gram的倒排索引，以及使用基于大规模语言模型（LLM）的重写器逐步重新格式化那些可能引起链接的片段，来有效防止基于搜索的链接攻击的方法。这种方法在不改变原始内容的情况下，能够有效地抵御链接风险。", "conclusion": "实验结果表明，该方法能够在不偏离原始内容的前提下，有效防止基于搜索的链接攻击。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06430", "html_url": "https://arxiv.org/abs/2510.06430", "title": "MathRobust-LV: Evaluation of Large Language Models' Robustness to Linguistic Variations in Mathematical Reasoning", "title_en": "MathRobust-LV: Evaluation of Large Language Models' Robustness to Linguistic Variations in Mathematical Reasoning", "authors": "Neeraja Kirtane,Yuvraj Khanna,Peter Relan", "background": "大型语言模型在数学基准测试中表现出色，但在语义变体下的数学推理稳健性方面则鲜有研究。虽然最近的工作越来越倾向于把IMO等高难度竞赛视为评估推理能力的标准，但作者认为，在真实的教育资源环境中全面评估高中生级别的数学问题更加重要。当前，许多教育系统和辅导系统中部署的模型需要处理各种表述方式相同的概念，因此语言的稳健性变得至关重要。然而，尽管MATH数据基准测试通常被认为是饱和的，实验结果显示，在从基线到变体的过程中，模型的准确性下降现象显著，尤其是小模型（9-11%的下降）和强模型的可测量下降也表明，语言变体下的稳健性是一个根本性的挑战。", "innovation": "作者引入了一个名为MathRobust-LV的新测试集和评估方法，该方法能够模拟教师在不同评估中如何重新表述问题，同时保持难度和答案不变。这种方法不同于以往专注于改变问题内容或强调IMO级别的任务，而是专注于高中级别数据集中的问题，这些问题是目前在教育应用中模型部署的真实难度级别。此外，通过实验发现，即使是前沿模型如GPT-5、Gemini-2.5pro，在面对这个挑战时也表现出相对稳定的表现。", "conclusion": "研究表明，语言变体下的稳健性是一个根本性的挑战，它揭示了模型在推理过程中的漏洞。这项评估方法可以帮助研究人员和开发者更好地理解模型在语言表达变化下的表现，从而促进更稳健的模型开发和应用。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06471", "html_url": "https://arxiv.org/abs/2510.06471", "title": "测试时放缩的推理模型在机器翻译中的应用", "title_en": "Test-Time Scaling of Reasoning Models for Machine Translation", "authors": "Zihao Li,Shaoxiong Ji,Jörg Tiedemann", "background": "测试时放缩（TTS）已经提高了各类推理模型（RMs）在数学和编程等任务中的性能，但在机器翻译（MT）领域的应用研究尚不充分。本文探讨了在翻译过程中增加推理计算时长是否能提升翻译质量。", "innovation": "1. 评估了12个推理模型在多种MT基准测试上的表现，涵盖了多个领域。\n2. 研究了直接翻译、强制推理外推和后编辑三种情况下的效果。\n3. 发现通用推理模型在直接翻译中的收益有限，但通过领域特定微调可以显著提升翻译质量。\n4. 强制模型进行超出其自然停止点的推理会降低翻译质量。\n5. 测试时放缩在后编辑上下文中表现出高度有效性，可以将自我校正转化为有益的流程。", "conclusion": "测试时放缩提高MT质量的关键不在于单次翻译中使用通用模型，而在于应用于多步骤自校正工作流程，以及与任务特化模型结合的特定应用中。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06548", "html_url": "https://arxiv.org/abs/2510.06548", "title": "自加速到饱和：递增预训练的语言模型预训练的扩展行为", "title_en": "From Acceleration to Saturation: Scaling Behavior of Bootstrapped Language Model Pretraining", "authors": "Seng Pei Liew,Takuya Kato", "background": "预训练模型的复用，例如连续预训练或模型增长，有望降低从头训练语言模型的成本。然而，当应用于过度训练的基础模型时，其效果仍不清楚。本研究旨在通过实证研究递增预训练的扩展行为，揭示其效率随基础模型训练词汇量的增加呈预可测的递减趋势。", "innovation": "研究发现递增预训练的扩展效率随基础模型训练词汇量的增加呈对数递减趋势。第一阶段和第二阶段词汇对递增预训练的联合依赖关系可以由一个简单的扩展法则准确建模。这一饱和效应揭示了多阶段预训练策略中的基本权衡：模型预训练得越充分，递增预训练带来的额外收益越少。", "conclusion": "研究结果为高效的语言模型训练提供了实用见解，并强调了对过度训练模型的再利用的重要性考虑。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06499", "html_url": "https://arxiv.org/abs/2510.06499", "title": "Webscale-RL：用于将RL数据扩展到预训练级别的自动化数据管道", "title_en": "Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels", "authors": "Zhepeng Cen,Haolin Chen,Shiyu Wang,Zuxin Liu,Zhiwei Liu,Ding Zhao,Silvio Savarese,Caiming Xiong,Huan Wang,Weiran Yao", "background": "大型语言模型（LLMs）通过模仿学习大量文本语料库取得了显著成功，但这一过程产生了训练-生成差距，限制了稳健的推理能力。增强学习（RL）提供了一种更高效的数据解决方案，能够跨越这一差距，但由于现有RL数据集规模远远小于互联网规模的预训练语料库，且多样性不足，其应用受到了严重限制。", "innovation": "我们引入了Webscale-RL管道，一个可扩展的数据引擎，系统地将大规模预训练文档转换为数量庞大的、可验证的问题-答案对，以支持RL应用。我们构建了Webscale-RL数据集，包含120万跨9多个领域的示例。我们使用这种方法训练的模型在一系列基准测试中显着优于连续预训练和强数据精炼基准。特别地，使用我们数据集的RL培训效率显著提高，仅需要不到100倍的令牌数即可达到连续预训练的性能。", "conclusion": "我们的工作提供了一种将增强学习扩展到预训练级别的可行路径，使开发出更具能力和更高效的语言模型成为可能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06461", "html_url": "https://arxiv.org/abs/2510.06461", "title": "基于语言信息的分词改进促进低资源语言的ASR", "title_en": "Linguistically Informed Tokenization Improves ASR for Underresourced Languages", "authors": "Massimo Daul,Alessio Tosolini,Claire Bowern", "background": "自动语音识别（ASR）对语言学家进行语言记录任务至关重要。然而，现代ASR系统依赖于数据需求量大的变换架构，这使得它们难以应用于资源匮乏的语言。Wav2vec2 ASR模型在潜伏中的澳大利亚原住民语言Yan-nhangu上的微调表明，普通的基于字符的分词策略在性能上表现较差。研究者们进行了一个语言学驱动的音素分词系统的实验，以提升ASR模型的性能。实验还探讨了ASR在语言记录流程中的可用性。终上所述，研究发现了基于音素的分词系统在准确率和字符错误率上明显优于基于字符的分词基线，并表明自动校正ASR输出比从头转录音频要快得多，证明了ASR可以在低资源语言中工作。", "innovation": "提出了一个基于语言信息的音素分词系统，并与字符分词基线模型进行性能对比；展示了ASR在低资源语言中的可行性，通过手改纠正ASR模型输出比从零开始转录音频要快。", "conclusion": "基于语言信息的音素分词系统在Yan-nhangu语言中提高了ASR的性能，同时表明手改ASR输出是处理原始音频的一种更快的方法，这些发现证明ASR能够用于低资源语言的记录。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06552", "html_url": "https://arxiv.org/abs/2510.06552", "title": "翻转对话：训练与评估用户语言模型", "title_en": "Flipping the Dialogue: Training and Evaluating User Language Models", "authors": "Tarek Naous,Philippe Laban,Wei Xu,Jennifer Neville", "background": "现有的对话会话涉及到两个参与者：一个人类用户和一个作为助手的自回归语言模型（LM）。这些LM被后训练以成为有帮助的助手，优化生成详尽且结构良好、无歧义和语法错误的回答。然而，用户的表达方式不完美，用户在每次对话回合时可能会以独特的方式提出请求，有时甚至会临时改进表达。为了在现实环境中评估LM性能，先前的工作模拟了用户，经常促使原本被训练为有帮助的助手的大型语言模型（LLM）扮演用户角色。然而，研究发现，这些作为助手的LM并不是好的用户模拟工具，而且更优秀的助手反而会产生更差的模拟效果。这意味着在多回合对话中的真实用户行为远比预期复杂。", "innovation": "本文引入了专门为了模拟多回合对话中的人类用户而训练的用户语言模型（User LMs）。这些模型被后训练，以便更准确地模拟人类用户的行为，从而相比现有的模拟方法更具鲁棒性。通过各种评估表明，使用User LMs来模拟代码和数学对话时，即使是强助手（如GPT-4o），其表现也急剧下降，从74.6%降低到了57.4%，这证实了一个更加现实的模拟环境会让助手难以处理多回合对话中的用户细节。", "conclusion": "User LMs能够更好地模拟多回合对话中的人类用户行为，提升对话模拟的鲁棒性。这表明，当使用更加接近真实用户行为的模拟环境时，助手的性能会因为难以应对用户的各种细节和挑战而显著下降。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06378", "html_url": "https://arxiv.org/abs/2510.06378", "title": "语义正则表达式：使用结构化语言自动解释LLM特征", "title_en": "Semantic Regexes: Auto-Interpreting LLM Features with a Structured Language", "authors": "Angie Boggust,Donghao Ren,Yannick Assogba,Dominik Moritz,Arvind Satyanarayan,Fred Hohman", "background": "自动可解释性旨在将大型语言模型（LLM）的特性转换为人易于理解的描述。然而，这些自然语言特性的描述通常模糊不清、不一致，并需要人工重新标记。针对这一问题，本文提出了语义正则表达式，这是一种结构化的语言描述LLM特性的方法。语义正则表达式通过结合捕获语言和语义特征模式的原语以及对上下文、组成和量化进行修饰的模态，生成精确且具有表现力的特征描述。通过定量基准测试和定性分析，发现语义正则表达式在准确性和描述简洁性及一致性方面与自然语言相当。其固有的结构允许进行新的类型分析，包括各层特性的复杂度量化、以及从单个特性洞察扩大到全局模式的自动化解释扩展。在用户研究中，发现语义正则表达式描述有助于人们构建准确的LLM特征激活的心理模型。", "innovation": "语义正则表达式是一种新的结构化语言描述方法，能够精确且表现力强地解释LLM特征。它结合了捕获语言和语义特征模式的原语以及对上下文、组成和量化进行修饰的模态，生成更精准和一致的特征描述。此外，其固有的结构还支持新的类型分析和扩展自动化解释的方法，适用于从单个特征到整个模型模式的量化。", "conclusion": "语义正则表达式方法在保持准确性的基础上，提高了特征描述的简洁性和一致性，同时提供了新的分析方式，有助于人们更好地理解模型的特征激活和全局模式。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06594", "html_url": "https://arxiv.org/abs/2510.06594", "title": "LLMs的内部层是否揭示了检测劫持模式？", "title_en": "Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?", "authors": "Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis", "background": "随着对话型大型语言模型（LLMs）的普及和 Accessibility 增强，通过精心设计的提示来促使这些模型产生受限或敏感输出的攻击行为——即‘劫持’现象日益引起关注。尽管已提出了多种防御机制，但攻击者仍不断开发新的提示技术，因此现有的模型无法完全抵御此类攻击。 researchers 研究人员通过分析 LLMs 的内部表示和隐藏层对劫持提示与良性提示的响应，以探索劫持现象并找出表现显著不同的层级行为。他们的目标是为建立泛化的劫持检测和防御机制提供进一步研究的线索。", "innovation": "研究人员专注于通过分析 LLMs 的内部层（如 GPT-J 和 Mamba2）对劫持提示或良性的回应，以揭示劫持检测的新线索。这是因为他们发现了一些在响应这两类提示时有显著差异的行为模式，为后续研究提供了值得探索的方向。这项研究的独特之处在于深入到了模型的内部机制，通过观察隐藏层的行为来识别潜在的劫持行为，从而为开发更有效的防御策略提供了新的视角。", "conclusion": "研究发现，LLMs 的某些内部层在响应劫持提示时的行为模式与对良性提示的响应显著不同。这为深入研究 LLMs 的内部动态以识别和防御劫持攻击提供了新的线索和方向。因此，进一步研究并利用这些内部模式可以增强 LLMs 的安全性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06677", "html_url": "https://arxiv.org/abs/2510.06677", "title": "通过逐步记录和代理人反馈进行的增量总结", "title_en": "Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback", "authors": "Yisha Wu, Cen (Mia)Zhao,Yuanpei Cao,Xiaoqing Su,Yashar Mehdad,Mindy Ji,Claire Na Cheng", "background": "为了减轻客服代表在对话中生成简洁总结时的切换负担和冗余审查，该研究介绍了一个增量总结系统。该系统结合了一个细调过的Mixtral-8x7B模型来进行连续笔记生成，并使用一个基于DeBERTa的分类器来过滤掉琐碎的内容。客服代表的编辑会精炼在线笔记生成，并定期通知离线模型重新训练，形成了一个代理编辑反馈循环。", "innovation": "该研究创新地使用了一个细调过的Mixtral-8x7B模型进行连续笔记生成，并结合了一个基于DeBERTa的分类器来筛选琐碎内容。此外，它还引入了一个从客服代表的编辑中得到反馈的机制，以不断优化和重新训练模型。", "conclusion": "该系统在实际部署中实现了比批量总结更低3%的案例处理时间（复杂案件可降低至9%），并且客服代表满意度评分很高。这些结果显示，带有持续反馈的增量总结能够高效提升总结质量和服务代理生产力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06664", "html_url": "https://arxiv.org/abs/2510.06664", "title": "ToolMem: 提升具可学习工具能力记忆的多模态智能体", "title_en": "ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory", "authors": "Yunzhong Xiao,Yangmin Li,Hewei Wang,Yunlong Tang,Zora Zhiruo Wang", "background": "基于大型语言模型（LLMs）或视觉语言模型（VLMs）的代理在文本和视觉模块的各种任务中展现出了卓越的进步。不同于传统的工具如计算器所给出的确定性结果，神经工具在不同任务场景中表现得不确定。虽然针对同一任务的各种工具可能在不同场景中表现优异，但现有智能体通常依赖固定的工具，这限制了它们选择最合适的工具解决特定任务的灵活性。与之相反，人类通过与各种工具的交互累积了对它们能力的认识，并利用这些知识选择解决未来的任务时的最佳工具。为了构建能从中受益的智能体，我们提出了ToolMem，使智能体能够通过总结和存储以前交互中的工具优势与劣势来建立对工具能力的记忆；在推理过程中，智能体可以从ToolMem中检索相关的条目，并选择最适合解决个体任务的工具以更准确地预测其性能", "innovation": "ToolMem 使智能体能够构建基于与工具交互的记忆库，将工具的优势与劣势进行总结和存储。在推理阶段，智能体可以从这些记忆中检索相关信息，选择最适合解决具体任务的工具，提高预测工具性能的准确性。这一方法比没有记忆的通用智能体提高了14.8%-28.7%的预测准确性。ToolMem 还在多元和多模态生成场景中使工具选择达到21%-24%的绝对增加", "conclusion": "我们评估了ToolMem在学习多样的文本生成和文本到图像生成神经工具上的效果，发现相较于没有记忆的通用智能体，ToolMem 增强的智能体在文本和多模态生成场景中更准确地预测工具性能，并在多个选择中更优化地选择工具。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06579", "html_url": "https://arxiv.org/abs/2510.06579", "title": "TinyScientist：构建研究代理的一种互动、扩展性和可控性框架", "title_en": "TinyScientist: An Interactive, Extensible, and Controllable Framework for Building Research Agents", "authors": "Haofei Yu,Keyang Xuan,Fenghai Li,Kunlun Zhu,Zijie Lei,Jiaxun Zhang,Ziheng Qi,Kyle Richardson,Jiaxuan You", "background": "大型语言模型（LLMs）驱动的自动研究正在迅速发展，这推动了包含多智能体系统、规划、工具使用、代码执行和人机交互的复杂工作流程的发展，以加速研究过程。然而，随着越来越多的研究人员和开发者开始使用和扩展这些工具和平台，这些智能工作流程的复杂性和维护难度已成为一个重大挑战，尤其是在算法和架构不断进步的情况下。", "innovation": "TinyScientist识别了自动研究工作流程的关键组件，并提出了一种互动、可扩展且可控的框架，使新工具的适应更加容易，并支持迭代增长。为此，TinyScientist提供了一个开源代码库、交互式网络演示和PyPI Python包，使最先进的自动研究管道能够被每位研究人员和开发人员广泛访问和使用。", "conclusion": "通过引入TinyScientist框架，研究团队能够更轻松地构建和扩展研究代理，适应新的工具和技术，从而使研究过程更加高效和灵活。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06640", "html_url": "https://arxiv.org/abs/2510.06640", "title": "状态空间架构与变换器架构中上下文表示流的比较分析", "title_en": "A Comparative Analysis of Contextual Representation Flow in State-Space and Transformer Architectures", "authors": "Nhat M. Hoang,Do Xuan Long,Cong-Duy Nguyen,Min-Yen Kan,Luu Anh Tuan", "background": "状态空间模型（SSMs）近年来被认为是对长序列处理的有效替代方案，相较于变换器基础模型（TBMs），它们具有线性扩展和更低的内存使用率。然而，这些架构中上下文信息如何在各层和各个令牌之间流动仍然研究不足。本文首次对状态空间模型和变换器模型中的表示传播进行了统一的按令牌和按层级分析，通过中心核对齐、稳定性度量和探测方法，揭示了代表如何在内部及跨层变化的过程。研究发现，变换器模型快速同质化令牌表示，分叉状态仅在后期才出现，而状态空间模型早期内保持令牌的独特性，但在深层逐步收敛到同质化。进一步的理论分析和参数随机化表明，变换器模型中的过度平滑是由于架构设计造成的，而在状态空间模型中，过度平滑主要由训练动态引起。这些洞察阐明了两种架构的归纳偏差，并为长上下文推理未来模型和训练设计提供了指导.", "innovation": "本文首次对状态空间模型和变换器模型中的表示传播进行了统一的token和层级分析。研究采用了中心核对齐、稳定性度量和探测方法，揭示了代表如何在内部及跨层变化的过程。明确了变换器模型和状态空间模型分别导致过度平滑的原因，并为两种架构的归纳偏差提供了新的见解，对未来的模型和训练设计具有重要的指导意义.", "conclusion": "本文通过深入分析状态空间模型与变换器模型中的表示传播机制，揭示了两者在上下文信息处理上的关键分歧：变换器模型早期快速同质化令牌表示，而状态空间模型保持令牌早期的独特性但在深层收敛到同质化。进一步的理论分析和参数随机化表明，这两种模型中的过度平滑分别由架构设计和训练动态引起。这些结论澄清了两种架构的归纳偏差，并对未来的模型和训练设计提供了指导."}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06695", "html_url": "https://arxiv.org/abs/2510.06695", "title": "基于反向翻译策略的小参数模型用于下游任务加持LLMs的提示重写学习", "title_en": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks", "authors": "Qinhao Zhou,Xiang Xiang,Kun He,John E. Hopcroft", "background": "近年来，大型语言模型（LLMs）的兴起极大地推动了提示工程的进展，从手动设计转向基于模型的优化。LLMs的提示通常包含两个部分：指令，定义任务或目标；输入，根据指令类型定制。在诸如机器翻译等自然语言生成任务中，输入部分尤为重要，而指令部分通常较为简要。现有的提示工程方法主要集中在优化指令部分以适应通用任务，通常需要大型参数的LLMs作为辅助工具。但对于机器翻译任务，输入部分的作用更为突出，现有方法的应用有限。因此，本文旨在解决这个问题，提出了一种新的提示优化方法，特别适用于机器翻译任务，该方法采用小参数模型并通过反向翻译策略进行训练，显著降低了单任务优化的训练开销，同时提供高效性能。", "innovation": "提出了一种基于小参数模型和反向翻译策略的提示优化方法，特别设计用于机器翻译任务。这种方法显著降低了单任务优化的训练成本，同时保持了高效性能。此外，该方法还可适应其他下游任务，具有广泛的应用潜力。", "conclusion": "本文提出的方法通过使用反向翻译策略训练小参数模型，为LLMs在下游任务中的应用提供了一种新的优化策略。这种方法有效地解决了现有方法在处理输入部分占主导地位的任务时的局限性，展现出在机器翻译等任务上的有效性和广阔的应用前景。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06700", "html_url": "https://arxiv.org/abs/2510.06700", "title": "语言模型如何混淆逻辑有效性与合理性：内容效应的表征分析", "title_en": "How Language Models Conflate Logical Validity with Plausibility: A Representational Analysis of Content Effects", "authors": "Leonardo Bertolazzi,Sandro Pezzelle,Raffaelle Bernardi", "background": "人类和大型语言模型（LLMs）都表现出内容效应：推理问题的语义内容的合理性影响对其逻辑有效性判断的偏差。尽管人类的这一现象可以通过双过程推理理论来解释，但LLMs中这些内容效应的机制却不清楚。本文通过研究LLMs如何在其内部表示中编码有效性和合理性这两个概念，来探讨这一问题。", "innovation": "研究发现，有效性和合理性这两个概念在线性表示中紧密对齐，导致模型将合理性与有效性混淆。通过引导向量的研究发现，合理性向量可以因果性地偏倚有效性判断。此外，合理性和有效性的对齐程度预测了模型中行为内容效应的大小。最后，构建了解析向量来分离这两个概念，减少内容效应并提高推理准确性。这些发现加深了对LLMs中抽象逻辑概念表征的理解，并强调表征干预作为更逻辑系统发展路径的重要性。", "conclusion": "研究发现，LLMs中有效性和合理性的概念线性表示且紧密对齐，导致合理性与有效性混淆的现象。通过解析向量可减少内容效应，提高推理准确度。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06730", "html_url": "https://arxiv.org/abs/2510.06730", "title": "PTEB: 通过使用LLMs在评估时进行随机重构以实现稳健的文本嵌入评估", "title_en": "PTEB: Towards Robust Text Embedding Evaluation via Stochastic Paraphrasing at Evaluation Time with LLMs", "authors": "Manuel Frank,Haithem Afli", "background": "当前对句子嵌入模型的评估通常依赖于诸如Massive Text Embedding Benchmark (MTEB)等静态测试套件。尽管这些测试套件非常有价值，但通过对固定测试套件的反复调整可能会夸大报告的性能，并可能掩盖模型在真实世界中的鲁棒性。", "innovation": "引入了Paraphrasing Text Embedding Benchmark (PTEB)，这是一种动态协议，在评估时随机生成意义保持的同义词表达，并在多次运行中聚合结果。通过成本效益高的基于LLM的方法，基于语义文本相似性金标准，证明了LLMs生成的同义词表达具有词汇多样性但保持了语义。", "conclusion": "在MTEB的7项任务中，验证了句子编码器在保持语义固定的情况下对词元空间的变化的敏感性。还观察到较小的模型受到的影响与较大模型相比并不成比例地更大。结果在多次运行中统计鲁棒，并且实验扩展到了3个多语言数据集，覆盖了10种语言。更广泛地说，本研究旨在提出一种新的NLP评估范式，该范式依赖于动态、随机的评估而非静态的、预定义的基准测试。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06652", "html_url": "https://arxiv.org/abs/2510.06652", "title": "通过完全自合成数据对齐大型语言模型", "title_en": "Aligning Large Language Models via Fully Self-Synthetic Data", "authors": "Shangjian Yin,Zhepei Wei,Xinyu Zhu,Wei-Lin Chen,Yu Meng", "background": "传统的人类反馈强化学习（RLHF）依赖昂贵的人工标注数据集，而人工智能反馈强化学习（RLAIF）也产生了显著的成本，需要收集多样性的提示和相应的内容，通常要求使用外部奖励模型或像GPT-4这样的专有模型来标注偏好对。这增加了实施难度和成本。传统方法和新技术都面临着显著的数据收集和标注挑战。", "innovation": "提出了Self-Alignment Optimization（SAO）框架，这是一种完全自合成的框架，用于大型语言模型（LLM）的对齐，所有训练数据（包括提示、响应和偏好）都是由模型自身生成的。首先，SAO指导LLM进行角色扮演，生成多样的提示和响应，然后自我评估以优化偏好。实验结果表明，SAO在标准基准如AlpacaEval~2.0上显著增强了模型的聊天能力，同时在下游任务（例如问答、数学推理）中保持了强大的表现。", "conclusion": "本研究提供了一个实际解决方案，用于使大型语言模型自我改善对齐，并保持其在多个下游任务上的有效性能。代码可以在指定的链接中找到，以便验证研究结果。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06732", "html_url": "https://arxiv.org/abs/2510.06732", "title": "LLMs 可靠的排名者吗？基于两阶段令牌优化的排名操控", "title_en": "Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token Optimization", "authors": "Tiancheng Xing,Jerry Li,Yixuan Du,Xiyang Hu", "background": "近年来，大型语言模型（LLMs）在信息检索中被广泛用作重新排序工具。然而，这些模型的排名行为可以通过微小、自然的提示进行操纵。因此，为了探讨这一潜在的漏洞，提出了Rank Anything First (RAF)方法，一种两阶段的令牌优化技术，能够生成简洁的文本篡改，以在LLM生成的排名中一致地提升目标项，同时保持难以察觉。", "innovation": "RAF是一种两阶段的技术：第一阶段使用贪婪坐标梯度结合排名目标的梯度与可读性评分，来短选当前位置的候选令牌；第二阶段利用基于熵的动态加权方案评估这些候选令牌在精确排名和可读性损失下的表现，并通过温度控制的采样选择令牌。RAF通过令牌逐个生成排名促进提示，旨在最大化排名效果和保持语言自然度。实验结果显示，RAF在提升目标项的排名表现和保持自然性方面都比现有方法更具鲁棒性，突显了基于LLM的重新排序本身固有易受到对抗性操纵的影响，从而对未来检索系统的可信度和鲁棒性提出了新的挑战。", "conclusion": "这些发现强调了一个关键的安全性问题：基于LLM的重新排序本质上容易受到对抗性操纵的影响，这引发了对现代检索系统可信度和鲁棒性的新挑战。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06738", "html_url": "https://arxiv.org/abs/2510.06738", "title": "AWM：大型语言模型的精确权重矩阵特征", "title_en": "AWM: Accurate Weight-Matrix Fingerprint for Large Language Models", "authors": "Boyi Zeng,Lin Chen,Ziwei He,Xinbing Wang,Zhouhan Lin", "background": "保护大型语言模型（LLMs）的知识产权至关重要，因为这些模型的训练需要大量资源。因此，无论是模型所有者还是第三方急需确定一个疑似模型是零样本训练还是基于现有基础模型训练。然而，典型的后训练过程，如监督微调、长时间的持续预训练、强化学习、多模态扩展、剪枝和升级，给可靠的识别带来了巨大挑战。", "innovation": "本工作提出了一种无需训练的指纹识别方法，基于权重矩阵利用线性分配问题（LAP）和无偏中心核对齐（CKA）相似性，抵消参数操作的影响，产生高度鲁棒和高保真的相似度度量。在包含60个正样本和90个负样本模型对的综合测试平台上，该方法在所有6种前述后训练类别中表现出色，且几乎零误报风险。通过在所有分类度量上获得满分，该方法为可靠的模型谱系验证奠定了坚实基础。整个计算在NVIDIA 3090 GPU上可在30秒内完成。", "conclusion": "我们的方法有效地解决了大型语言模型后训练过程带来的挑战，提供了高度可靠的模型谱系验证，并且计算效率高，为知识产权保护提供了有力手段。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06670", "html_url": "https://arxiv.org/abs/2510.06670", "title": "PIKA: 从零开始进行后训练对齐的专家级合成数据集", "title_en": "PIKA: Expert-Level Synthetic Datasets for Post-Training Alignment from Scratch", "authors": "Shangjian Yin,Shining Liang,Wenbiao Ding,Yuli Qian,Zhouxing Shi,Hongzhi Li,Yutao Xie", "background": "强化学习从人类反馈（RLHF）已成为大规模语言模型（LLMs）对齐的基石。然而，其效果依赖于高质量的教学数据。现有的对齐数据集要么私人拥有，要么需要昂贵的人工标注，这限制了可重复性和可扩展性。即使使用强化学习从AI反馈（RLAIF），数据质量仍然存在担忧。此外，目前尚不清楚为了将基础模型细调为强大的指令遵循模型，到底需要多少数据。现有方法通常依赖于超过30万以上的样本，在监督微调（SFT）阶段，仍然表现不如私有模型，这为学术界和资源有限的社区设置了障碍。", "innovation": "我们提出了PiKa，一系列专家级的数据高效对齐数据集。特别是，PiKa-SFT数据集只使用了30k的SFT样本，这远少于最先进的数据集如Magpie。通过在PiKa和其他公共数据集上对Llama-3-8B-Base进行细调，我们展示了PiKa-SFT的表现优于在更大数据上训练的模型。在AlpacaEval 2.0和Arena-Hard基准测试中，PiKa-SFT细调甚至超过了官方Llama-3-8B-Instruct模型，在超过1000万私有样本上训练。进一步的实验表明，PiKa-SFT在Qwen2.5系列（0.5B到7B）上训练也能取得一致的提升，证明了高质量的对齐可以通过的数据显著少，为开源LLM对齐提供了可扩展的途径。", "conclusion": "这些发现表明，即使使用显著较少的数据，也能实现高质量的对齐，为学术界和资源有限的社区提供了一条可扩展的路径进行开源LLM对齐。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06749", "html_url": "https://arxiv.org/abs/2510.06749", "title": "一种基于流畅性的多参考评价正式框架在语法错误修正中的应用", "title_en": "A Formal Framework for Fluency-based Multi-Reference Evaluation in Grammatical Error Correction", "authors": "Eitan Klinger,Zihao Huang,Tran Minh Nguyen,Emma Jayeon Park,Yige Chen,Yang Gu,Qingyu Gao,Siliang Liu,Mengyang Qiu,Jungyeul Park", "background": "现有的语法错误修正评估指标主要依赖于基于编辑的框架和以英语为中心的方法，这些方法依赖于系统编辑与参考编辑之间严格的对齐，限制了它们在多语言和生成设置中的适用性。因此，评估需要能够反映多种有效的手工修正多样性的指标，而不是只看重单一参考修正。", "innovation": "本文提出了一种基于流畅性的多参考评价的正式框架，将n-gram相似性视为多种合法修正中的一种聚合问题。本文通过四种聚合策略——选择最佳、简单平均、加权平均和合并计数——实例化GLEU，并分析了它们的边界性、单增性和对参考变异的敏感性。研究表明，这些策略能够捕捉流畅性和覆盖度的不同方面。该框架将多参考评价统一为一种以流畅性为导向的方法，并在语言多样性中不惩罚合法的变异。", "conclusion": "通过引入新颖的基于流畅性的多参考评价框架，该研究提供了一种新的评估多语言和生成设置中语法错误修正的方法，能够体现语言多样性，应用于Czech、Estonian、Ukrainian和Chinese语料库验证了该方法的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06747", "html_url": "https://arxiv.org/abs/2510.06747", "title": "TWIST: Training-free and Label-free Short Text Clustering through Iterative Vector Updating with LLMs", "title_en": "TWIST: Training-free and Label-free Short Text Clustering through Iterative Vector Updating with LLMs", "authors": "I-Fan Lin,Faegheh Hasibi,Suzan Verberne", "background": "在客户面对的聊天机器人中，公司需要对大量的用户输入进行聚类，以便识别用户的意图。然而，在商业环境中通常没有标记数据，且聚类的数量也未知。现有的聚类方法大多需要预先知道聚类的数量或标签，或者使用对比学习来进行聚类。本研究提出了一种无需训练和标签的方法，适用于任何嵌入器，并通过大型语言模型（LLM）逐步精炼聚类向量，适应了这种小型数据资源且灵活性高的场景，使得方法更为符合实际情况。实验表明，该方法在多种数据集和小型LLM上表现出良好的泛化能力，并且能够处理大规模数据集，降低计算成本，使其在实际应用中更具有实际意义和应用价值。", "innovation": "该研究提出了一种全新的无训练、无标签（training-free and label-free）方法，用于短文本聚类。该方法基于迭代向量更新过程，通过大语言模型（LLM）指导逐步精炼聚类向量，避免了对聚类数量或标签的先验知识依赖，且适用于任何嵌入器，即使是较小型的LLM。该方法在多种数据集上取得了与现有的使用对比学习的最先进的聚类方法相当或更好的结果，同时具备更强的适应性和可扩展性，适用于多种实际应用场景。", "conclusion": "该方法不需要训练数据或标签，适应了小型数据资源且灵活性高的聚类场景，通过迭代更新方法和LLM指导，适用于任何嵌入器，并能在大规模数据集上实现高效的聚类。该研究通过实验展示了该方法在多个数据集和小规模LLM上的有效性，并基于此得出结论认为该方法在实际应用场景中更具有优势和实际意义。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06774", "html_url": "https://arxiv.org/abs/2510.06774", "title": "通过动态逻辑求解器组合实现适应性LLM-符号推理", "title_en": "Adaptive LLM-Symbolic Reasoning via Dynamic Logical Solver Composition", "authors": "Lei Xu,Pierre Beckmann,Marco Valentino,André Freitas", "background": "神经-符号NLP方法旨在利用大规模语言模型和形式逻辑求解器的优势。然而，当前的方法主要是静态的，即目标求解器的整合在设计时就被确定了，这限制了采用多种形式推理策略的能力。论文针对这一问题，提出了一个适应性多范式神经-符号推理框架，使系统能够自动识别自然语言表述的问题中的形式推理策略，并通过自动形式化接口动态选择和应用专门的形式逻辑求解器。广泛的实验证明了这一框架的有效性，并表明它相比其他基线模型性能高出27%和6%，并为GPT-4o方法提供了10%、5%和6%的改进。尽管较小的模型在适应性神经-符号推理中遇到困难，但通过训练后的改进提供了可行的提升途径。", "innovation": "提出了一种适应性多范式神经-符号推理框架，能够自动识别问题中的形式推理策略，并通过自动形式化接口动态选择和应用专门的形式逻辑求解器。该框架展示了显著的性能提升，并为基于零样本、CoT和符号CoT策略的模型提供了改进。此外，虽然较小的模型面临困难，但通过训练后的调整仍有改善空间。", "conclusion": "这项研究奠定了适应性LLM-符号推理的基础，为在异质推理挑战中统一物质和形式推理提供了前景。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06780", "html_url": "https://arxiv.org/abs/2510.06780", "title": "LLM知识材料化基础：终止性、可再现性、鲁棒性", "title_en": "Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness", "authors": "Luca Giordano,Simon Razniewski", "background": "大型语言模型（LLMs）蕴含了丰富的事实性知识，然而测量和系统地组织这些知识依然是一个挑战。将这些知识转换为结构化数据，例如通过递归提取方法如GPTKB方法（Hu et al., 2025b），仍然尚未被广泛探索。现有研究面临的关键问题是这些提取能否终止、其结果是否可重现以及它们在不同变动下是否具有鲁棒性。", "innovation": "该研究系统地分析了LLM知识材料化，使用miniGPTKBs（特定领域的小规模子提取）来评估提取终止性、可再现性和鲁棒性。研究涵盖了四种不同的参数变化（种子、语言、随机性、模型）和三个不同的领域（历史、娱乐、金融）。", "conclusion": "研究发现，尽管模型依赖性较大，但终止率较高；可再现性结果不一；鲁棒性受扰动类型影响，表现为种子和温度扰动下的高鲁棒性，而语言和模型扰动下的鲁棒性较低。这些发现表明，LLM知识材料化可以可靠地揭示核心知识，但也揭示了其重要局限性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06727", "html_url": "https://arxiv.org/abs/2510.06727", "title": "利用端到端摘要导向的上下文管理扩展大型语言模型多轮RL", "title_en": "Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management", "authors": "Miao Lu,Weiwei Sun,Weihua Du,Zhan Ling,Xuesong Yao,Kang Liu,Jiecao Chen", "background": "研究指出，语言模型（LLM）通过强化学习（RL）进行长时间多轮任务时，由于任务上下文长度迅速成为基本瓶颈，现有RL管线常常出现操作指令降低、过长生成成本增加以及严格的上下文限制等问题。因此需要一种新的方法来解决这些问题，以便进一步提升语言模型的多轮RL能力，尤其是在复杂任务中的表现与实用性.", "innovation": "论文引入了一种基于摘要的上下文管理方法，这种方法通过LLM生成的摘要来定期压缩工具使用的历史，从而保留与任务相关的信息，同时保持上下文的紧凑性，允许代理扩展超过固定的上下文窗口。这项工作中基于此提出了一个端到端的SUPO算法，该算法不仅能优化工具使用的行为，还能同时优化摘取策略。实验表明，在交互函数调用和搜索任务中，SUPO算法相比基线方法能够显著提高成功的几率，同时保持或降低工作上下文的长度。并且，对于复杂的搜索任务，SUPO能够在测试时进一步扩展摘要生成的最大回合数，从而进一步提高评估表现.", "conclusion": "该研究证明了基于摘要的上下文管理是一种有原则性和扩展性的方法，可以用于训练长度限制外的RL代理，这对于解决大规模语言模型训练中的功能使用和长时域问题具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06805", "html_url": "https://arxiv.org/abs/2510.06805", "title": "PAN 2025年反作弊检测任务概述", "title_en": "Overview of the Plagiarism Detection Task at PAN 2025", "authors": "André Greiner-Petter,Maik Fröbe,Jan Philip Wahle,Terry Ruas,Bela Gipp,Akiko Aizawa,Martin Potthast", "background": "该反作弊检测任务于2025年在PAN（数据科学挑战赛）中设立，目标是从科学文章中自动识别生成性抄袭，并找到它们的原始来源。该任务使用了三个大型语言模型（Llama、DeepSeek-R1和Mistral）生成了一个大规模的自动生成型抄袭数据集，并回顾了2015年PAN的任务来评估当前技术的有效性。", "innovation": "本研究创新之处在于利用大型语言模型创建了一个大规模的自动生成性抄袭数据集，并且全面回顾了所有参赛者及四个基线方法的结果，分析其性能。此外，还通过与2015年PAN的反作弊检测任务对比，展示了当前方法在召回率和精准度上的表现。", "conclusion": "尽管基于嵌入向量的朴素语义相似性方法显示出相当不错的结果（最高可达0.8的召回率和0.5的精确率），但这些方法在2015年数据集上的表现却普遍不佳，这表明其缺乏通用性。因此，当前迭代的反作弊检测方法还未展现丰富的多样性，有待进一步改进和创新。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06800", "html_url": "https://arxiv.org/abs/2510.06800", "title": "FURINA：通过可扩展多智能体协作流水线实现完全可定制的角色扮演基准", "title_en": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline", "authors": "Haotian Wu,Shufan Jiang,Chios Chen,Yiyang Feng,Hehai Lin,Heqing Zou,Yao Shu,Yanran Li,Chengwei Qin", "background": "随着大型语言模型（LLMs）在角色扮演（RP）任务中不断进步，现有的基准测试迅速变得过时，因为它们的范围狭窄、过时的交互模式以及在多种应用场景中的适应性有限。为了填补这一空白，本文介绍了FURINA-Builder，这是一种新的多智能体协作流水线，能够自动构建任意规模的完全可定制的角色扮演基准测试。该流水线使得评价任意角色在多种场景和提示格式下的表现成为可能，是首次在角色扮演领域提供灵活评估基准构建器。", "innovation": "FURINA-Builder通过模拟测试角色与其他智能体之间的对话，并且由LLM评判员选择详细的评价维度并对测试角色的回应进行调整，最终生成完整的测试陈述。使用此流水线构建了FURINA-Bench，这是一个新综合的角色扮演基准测试，包含既定和合成的角色测试，每种角色都使用特定维度的评价标准进行评估。通过人类评估和初步可分性分析，证明了该流水线和基准设计的有效性。", "conclusion": "通过广泛的评价，发现o3和DeepSeek-R1在英语和中文角色扮演任务中的表现最佳。在所有模型中，既定角色始终优于合成角色，推理能力进一步放大了这种差距。有趣的是，我们观察到模型规模并非单调地降低幻觉。更关键的是，对于推理LLMs，我们发现了一个新的权衡：推理提高了角色扮演表现，但同时增加了幻觉。这种权衡在所有LLMs之间扩展了角色表现和可靠性的帕累托前沿。这些发现证明了FURINA-Builder的有效性并揭示了FURINA-Bench所带来的挑战。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06750", "html_url": "https://arxiv.org/abs/2510.06750", "title": "Golden-Switch：慢速和快速思考的大语言模型的无训练叠加", "title_en": "Gold-Switch: Training-Free Superposition of Slow- and Fast- Thinking LLMs", "authors": "Jaeseong Lee,Dayoung Kwon,seung-won hwang", "background": "LRMs在结构化任务中表现出色，通过模仿人的推理，但却常常陷入过度思考，导致性能下降和资源浪费。一种可能是部署LLM和LRM组合，并通过预测输入是否需要推理以及可能引发过度思考来路由输入，但这种方法成本高且不实用。现有的解决方案往往需要复杂的路由机制或者训练多个模型，这增加了成本或不实际。", "innovation": "本文提出了一种无训练的叠加部署策略，称为Golden-Switch。这种方法通过轻量级的调控在推理和计算之间切换，而不是使用路由机制。通过分析奇异值的累积能量，使用最优的低秩投影来调整推理的程度，从而在减少计算的同时保持推理能力。", "conclusion": "本文提出了一种新的方法Golden-Switch，它利用LRM推理优势的同时进行计算调整，以优化推理效率，降低资源消耗。通过理论分析和实验验证，该方法有效地解决了常规超神部署所面临的问题。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06811", "html_url": "https://arxiv.org/abs/2510.06811", "title": "BlackboxNLP-2025 MIB 共享任务：探索电路定位方法的集成策略", "title_en": "BlackboxNLP-2025 MIB Shared Task: Exploring Ensemble Strategies for Circuit Localization Methods", "authors": "Philipp Mondorf,Mingyang Wang,Sebastian Gerstner,Ahmad Dawar Hakimi,Yihong Liu,Leonor Veloso,Shijia Zhou,Hinrich Schütze,Barbara Plank", "background": "机制可解释性基准测试（MIB）的电路定位赛道评估方法以确定大型语言模型（LLMs）中负责特定任务行为的子网络。已有研究表明，通过组合多种电路定位方法（如并行和序列集成）可以提高电路识别的准确性。在本研究中，作者具体探讨了平行和序列集成策略如何改进电路定位方法的性能，并评估了这些策略在机制可解释性基准测试中的效果。", "innovation": "作者通过实施平行和序列集成策略来改进电路定位方法，特别是在并行集成后，使用EAP-IG作为初始步骤，随后进行更昂贵但更精确的边修剪方法，以实现更精确的电路识别。研究表明，这些集成策略在基准任务上的效果显著提升，并且将多种方法（包括序列集成）进行并行集成时，可以获得最佳结果。", "conclusion": "作者提出的方法在BlackboxNLP 2025 MIB共享任务中进行评估，并将集成得分与官方基线进行了比较，结果表明了平行集合理论的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06826", "html_url": "https://arxiv.org/abs/2510.06826", "title": "大型语言模型的中期训练：一项综述", "title_en": "Mid-Training of Large Language Models: A Survey", "authors": "Kaixiang Mo,Yuxin Shi,Weiwei Weng,Zhiqiang Zhou,Shuman Liu,Haibo Zhang,Anxiang Zeng", "background": "大型语言模型（LLMs）通常通过大规模预训练然后进行任务特定的微调来开发。最近的研究强调了一个中间的中期训练阶段的重要性，在这个阶段中，模型经历了多次退火风格的阶段，以改进数据质量、适应优化计划并扩展上下文长度。这个阶段缓解了从嘈杂的令牌中带来的回报递减，稳定了收敛过程，并扩展了模型在后期训练中的能力。", "innovation": "本文是首个将大型语言模型的中期训练方法分类为数据分布、学习率调度和长上下文扩展的统一框架。作者总结了实用的见解，描述了评估基准，并报告了成绩以便在模型之间进行结构化的比较。同时，作者指出了开放的挑战，并提出了未来研究和应用的方向。", "conclusion": "中期训练已被最先进的系统广泛采用，但没有对此作为一种统一框架进行过综述。本文综述了中期训练，编制了评价基准，提出了开放的研究挑战，并为未来的应用指明了道路。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06847", "html_url": "https://arxiv.org/abs/2510.06847", "title": "OpenJAI-v1.0: 一个开源泰语大语言模型", "title_en": "OpenJAI-v1.0: An Open Thai Large Language Model", "authors": "Pontakorn Trakuekul,Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Sumana Sumanakul", "background": "介绍了OpenJAI-v1.0，一个源自Qwen3-14B模型的开源大语言模型，适用于泰语和英语。该模型专注于通过精心选择的数据提高其实用任务性能，特别是在指令遵循、长文本理解及工具使用三个方面。评估结果显示，OpenJAI-v1.0 在多个基准测试中表现出色，改进了其基模型的能力，同时在各种多样的基准上优于其他主要的开源泰语模型，而且没有出现灾难性遗忘现象。该模型已公开发布，作为泰国人工智能社区的另一种NLP资源可供选择和使用。", "innovation": "直接基于Qwen3-14B模型改进，着重于实用性任务表现的提升，特别是指令遵循、长文本理解及工具使用。评价结果显示在多种基准测试中表现出色，优于其他开源泰语模型，且未发生灾难性遗忘现象。", "conclusion": "OpenJAI-v1.0 已公开发布，成为泰国人工智能社区另一种可供选择的自然语言处理资源。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06841", "html_url": "https://arxiv.org/abs/2510.06841", "title": "GAMBIT+: 用于评估机器翻译质量估计指标中性别偏见的挑战集", "title_en": "GAMBIT+: A Challenge Set for Evaluating Gender Bias in Machine Translation Quality Estimation Metrics", "authors": "Giorgos Filandrianos,Orfeas Menis Mastromichalakis,Wafaa Mohammed,Giuseppe Attanasio,Chrysoula Zerva", "background": "虽然机器翻译（MT）系统中的性别偏见已经被广泛研究，但自动质量评估（QE）指标中的性别偏见仍然相对缺乏探讨。现有研究指出QE指标也可能体现性别偏见，但大多数研究存在样本数据量小、职业覆盖面窄、语言多样性局限的问题。为填补这一空白，本文介绍了专为考察QE指标在评估包含性别模糊职业术语的翻译时的行为而设计的大规模挑战集。", "innovation": "基于包含性别模糊职业的英语语料库GAMBIT，本研究扩展到三种性别不清或自然性别语言的来源语言和十一种存在语法性别的目标语言，共计33个源-目标语言对。每个源文本与两个版本配对，这两个版本唯一的区别是在职业术语上使用了男性或女性语法性别，所有依赖的语法元素均相应调整。一个无偏见的QE指标应对两个版本给出相似的评分。", "conclusion": "数据集的大规模、广泛的覆盖面以及完全平行设计使得可以通过职业维度进行精细的偏见分析，并在不同语言之间进行系统比较。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06889", "html_url": "https://arxiv.org/abs/2510.06889", "title": "MeXtract：来自科学论文的轻量级元数据提取", "title_en": "MeXtract: Light-Weight Metadata Extraction from Scientific Papers", "authors": "Zaid Alyafeai,Maged S. Al-Shaibani,Bernard Ghanem", "background": "元数据在科学文献的索引、文档记录和分析中起着关键作用，然而准确而高效地提取元数据仍然是一个具有挑战性的任务。传统方法通常依赖于基于规则或特定任务的模型，这些模型难以在不同领域和模式变化中进行泛化。因此，需要开发新的、适应性强的模型来提高元数据提取的效率和准确性。", "innovation": "本文提出了MeXtract，一种轻量级的语言模型家族，专门用于从科学论文中提取元数据。这些模型从参数规模为0.5B到3B不等，并通过Qwen 2.5的微调构建而成。MeXtract在MOLE基准测试中达到了最先进的元数据提取性能。此外，研究还扩展了MOLE基准测试，以包含模型特定的元数据，提供了一个跨域的具有挑战性的子集，用于进一步评估。实验表明，针对特定模式的微调不仅提高了准确性，还能有效地适用于未见过的新模式，展示了该方法的稳健性和适应性。", "conclusion": "我们的研究已经开源了所有代码、数据集和模型，用于研究社区的相关研究。MeXtract的方法显示了其在面对不同元数据提取场景下的强大适应性和泛化能力，为科学论文的元数据提取提供了一种新的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06915", "html_url": "https://arxiv.org/abs/2510.06915", "title": "LongRM：揭示并解锁奖励建模的上下文边界", "title_en": "LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling", "authors": "Zecheng Tang,Baibei Ji,Quantong Qiu,Haitian Wang,Xiaobo Liang,Juntao Li,Min Zhang", "background": "当前的奖励模型（RM）主要适用于短上下文场景，并重点评估响应质量（例如安全性或有用性），而忽视了长上下文与响应一致性的重要维度。随着现实生活应用程序越来越多地涉及长时间轨迹，比如大型语言模型代理，评估模型响应是否不仅高质量，而且还与提供的背景一致变得至关重要。然而，现有的RM仍然局限于短上下文设置。", "innovation": "提出了Long-RewardBench，这是一个专门为长期上下文RM评估设计的基准，包括成对比较和最佳-{N}任务。基于模型输出失败模式的分析，提出了一种通用的分阶段训练策略，可将任意模型转换为稳健的长期上下文RM（LongRMs）。实验表明，这种方法不仅在长上下文评估中大幅提升了性能，还能保持良好的短上下文能力。8B规模的LongRM优于更大规模70B基准，并能达到私有Gemini 2.5 Pro模型的性能水平。", "conclusion": "我们的研究揭示了最先进的生成型RM在长上下文场景中存在显著脆弱性，并提出了一种通用的多阶段训练策略，使任意模型能够在长上下文情境中表现出色。实验表明，该策略不仅在长上下文评估中显著提升了性能，而且在短上下文性能上仍然表现出色。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06961", "html_url": "https://arxiv.org/abs/2510.06961", "title": "开放ASR排行榜：朝着可再现和透明的多语言和长形式语音识别评估努力", "title_en": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation", "authors": "Vaibhav Srivastav,Steven Zheng,Eric Bezzam,Eustache Le Bihan,Nithin Koluguri,Piotr Żelasko,Somshubra Majumdar,Adel Moumen,Sanchit Gandhi", "background": "尽管自动语音识别（ASR）取得了快速进步，但评估仍然主要集中在短格式的英语上，且很少报告效率问题。现有的评估大多数使用封闭源代码，缺乏透明性和可扩展性。", "innovation": "本文介绍了Open ASR排行榜，这是一个可完全复现的基准平台，比较了60多个开源和专有系统在11个数据集上的表现，包括专为多语言和长格式设计的轨道。该平台标准化了文本规范化，并报告了单词错误率（WER）和逆实时因子（RTFx），以实现公平的准确性和效率比较。对于英语转录，Conformer编码器搭配LLM解码器在平均WER方面表现最佳，但速度较慢；CTC和TDT解码器在逆实时因子方面表现更好，适用于长形式和离线应用。Whisper衍生的针对英语进行微调的编码器可以提高准确率，但经常以减少多语言覆盖为代价。所有相关的代码和数据集载入程序都已开源，以支持透明和扩展的评估。", "conclusion": "Open ASR排行榜旨在提供一个可再现、透明的多语言和长形式语音识别评估平台，通过标准化测量方法和公开源代码，促进更公平的对比和评估。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06917", "html_url": "https://arxiv.org/abs/2510.06917", "title": "SHANKS: 同时倾听和思考的口语模型", "title_en": "SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models", "authors": "Cheng-Han Chiang,Xiaofei Wang,Linjie Li,Chung-Ching Lin,Kevin Lin,Shujie Liu,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang", "background": "当前的大规模语言模型（LLMs）和口语语言模型（SLMs）在用户说完一句话后才开始思考和采取行动，这导致模型无法在用户讲话时与之互动，从而增加了响应延迟。这种延迟对于需要实时、低延迟交互的语音到语音的对话场景来说是不合适的。因此，这些模型在处理实时交流时遇到困难。", "innovation": "本文提出了一种名为SHANKS的通用推理框架，该框架允许SLMs在倾听用户输入的同时生成未说出口的推理过程。SHANKS将输入语音分成固定时长的片段，并在接收到片段后立即基于所有先前的语音和推理生成未说出口的推理，同时用户继续讲话。在此过程中，SHANKS利用这些未说出口的推理来决定是否打断用户以及执行必要的工具调用来完成任务。", "conclusion": "通过使用SHANKS，可以在两种场景中增强实时用户-SLM交互：一是当用户在逐步解决数学问题时，SHANKS可以倾听、推理并在用户犯错时打断他们，其中断准确性比没有思考的基线高出37.1%；二是当使用增强对话的工具时，SHANKS可以在用户说完之前完成56.9%的任务调用。总体而言，SHANKS推动了模型在对话期间持续思考的能力，而不仅仅是结束对话后的思考。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06825", "html_url": "https://arxiv.org/abs/2510.06825", "title": "以模型为工具的适应性工具生成与强化学习", "title_en": "Adaptive Tool Generation with Models as Tools and Reinforcement Learning", "authors": "Chenpeng Wang,Xiaojie Cheng,Chunye Wang,Linfeng Yang,Lei Zhang", "background": "工具增强的语言模型展示了强大的能力，但它们依赖于实时API访问，在训练和部署过程中造成了可扩展性和可靠性方面的挑战。现有的方法依赖于实时API，这在实际应用中可能会导致不可靠性和维护不便的问题。因此，需要一种新的框架来解决这些问题。", "innovation": "提出了一种以模拟为主导的训练框架MTR（Model-based Tool Reasoning）。MTR不依赖实时API，而是通过学习完整的ReAct跟踪记录来训练模型，并且使用结构化的模拟观察结果。MTR采用多代理架构，包括自动生成任务特定、OpenAI兼容工具接口的ToolMaker，自动生成结构化思考-做-观察序列的AutoAgent，以及模拟真实响应的ToolActor。训练过程分为两个阶段：第一阶段监督微调（SFT）教授完整的推理序列的“跟踪语法”，第二阶段组相对策略优化（GRPO）使用综合跟踪奖励来优化策略，该奖励平衡了答案的正确性和内部一致性。", "conclusion": "MTR在四个多跳问答基准（HotpotQA、MuSiQue、2WikiMultiHopQA、Bamboogle）上达到了与实时API系统竞争的准确匹配（EM）分数，并在推理密集型任务上表现出色，表明有效的工具推理可以从结构化的跟踪记录中学习而无需实时交互。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06870", "html_url": "https://arxiv.org/abs/2510.06870", "title": "$\\lambda$-GRPO: 将GRPO框架统一化并引入可学习的令牌偏好", "title_en": "$λ$-GRPO: Unifying the GRPO Frameworks with Learnable Token Preferences", "authors": "Yining Wang,Jinman Zhao,Chuangxin Zhao,Shuhao Guan,Gerald Penn,Shinan Liu", "background": "强化学习与人类反馈（RLHF）已成为增强大型语言模型推理能力的主要方法。最近，可验证奖励的强化学习（RLVR）通过使用基于规则的验证器简化了这一范式，例如Group Relative Policy Optimization（GRPO）。然而，GRPO固有地存在长度偏差问题，即奖励以相同的优势分配给响应中的所有令牌。因此，更长的响应在更多令牌上分配奖励，从而在梯度更新中产生不成比例的影响。现有的变体，如DAPO和Dr. GRPO，通过修改令牌级损失的聚合方式来解决此问题，但这些方法仍然具有启发性且缺乏关于其隐含令牌偏好解释的透明度。本研究探讨了在优化期间让模型学习其自己的令牌偏好的可能性。", "innovation": "文章提出了一种可学习参数$\\lambda$的方法，用于适应性地控制令牌级加权。通过这种方法，名为$\\lambda$-GRPO，它直接统一了现有的GRPO框架，并在多个数学推理基准上实现了对GRPO和DAPO的改进。对于模型参数分别为1.5B、3B和7B的Qwen2.5模型，$\\lambda$-GRPO分别提高了平均准确率1.9%、1.0%和1.7%。值得注意的是，这些改进无需对训练数据进行修改或增加计算成本，突显了学习令牌偏好方法的有效性和实用性。", "conclusion": "本研究通过引入可学习参数$\\lambda$，提出了$\\lambda$-GRPO方法，有效地克服了现有方法的某些限制，并在多个数学推理基准上实现了持续改进。这种方法提高了模型的解释性和实用性，强调了在优化过程中学习令牌偏好的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06974", "html_url": "https://arxiv.org/abs/2510.06974", "title": "使用性别代词和社会群体探查中文LLM中的社会身份偏见", "title_en": "Probing Social Identity Bias in Chinese LLMs with Gendered Pronouns and Social Groups", "authors": "Geng Liu,Feng Li,Junjie Mu,Mengxiao Zhu,Francesco Pierri", "background": "随着大型语言模型（LLMs）越来越多地应用于面向用户的应用程序，人们越来越关注它们可能反映和放大社会偏见的风险。该研究通过使用特定于普通话的提示，跨十个代表性中文LLMs，评估了对群体内部（“我们”）和群体外部（“他们”）框架的回应，扩展到240个在中国语境中重要的社会群体，来研究中文LLMs中社会身份框架。通过补充控制实验，还分析了来自用户与聊天机器人互动语料库中的中文对话。研究发现，这些模型表现出系统性的内群体积极和外群体消极倾向，这种倾向不仅出现在受控实验的提示中，在自然对话中同样存在，表明偏见动态可能在实际交互中增强。", "innovation": "该研究提出了一个语言感知评价框架，用于评估中文LLMs，发现与英语中记录的社会身份偏见跨语言普遍化，并在面向用户的场景中加剧。", "conclusion": "在不同模型中观察到了系统性的内群体积极和外群体消极倾向，这种倾向不仅限于受控场景，也在自然对话中出现，表明偏见动态可能在实际交互中增强。该研究提供了一个跨语言的社会身份偏见评估框架，证明了记录在英语中的社会身份偏见在中文环境中持续存在并加剧。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06866", "html_url": "https://arxiv.org/abs/2510.06866", "title": "在LLMs中通过质量感知解码解锁潜在的 discourse 翻译", "title_en": "Unlocking Latent Discourse Translation in LLMs Through Quality-Aware Decoding", "authors": "Wafaa Mohammed,Vlad Niculae,Chrysoula Zerva", "background": "大语言模型（LLMs）在机器翻译等领域显示出了强大的能力，但它们在处理文本中的话语现象方面仍然面临挑战，例如在文档层面的代词消解和词汇连贯性等问题。本文研究了LLMs在上下文感知翻译中的话语现象表现，揭示出话语知识已经嵌入到LLMs中，提出了质量感知解码（QAD）方法，以有效提取这部分知识。并通过全面分析表明QAD方法优于其他解码方法，提升了翻译的语义丰富度和与人类偏好的契合度。", "innovation": "该研究展示了质量感知解码（QAD）的有效性，证明了其在提取LLMs中的话语知识方面优于其他方法，增强了翻译的语义丰富度，并更接近于人类的偏好。", "conclusion": "研究表明，质量感知解码（QAD）能够有效提取嵌入在LLMs中的话语知识，增强翻译的语义丰富度，并优化翻译与人类偏好的匹配度。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06999", "html_url": "https://arxiv.org/abs/2510.06999", "title": "RAG系统中大型法律数据集可靠检索的探索", "title_en": "Towards Reliable Retrieval in RAG Systems for Large Legal Datasets", "authors": "Markus Reuter,Tobias Lingenberg,Rūta Liepiņa,Francesca Lagioia,Marco Lippi,Giovanni Sartor,Andrea Passerini,Burcu Sayin", "background": "检索增强生成（RAG）是一种有潜力减轻大型语言模型（LLMs）在法律应用中幻觉问题的方法，但其可靠性高度依赖于检索步骤的准确性。在法律领域，由于大量结构相似的文档数据库，检索系统容易失败。", "innovation": "本文通过识别并量化一种称为文档级别检索不匹配（DRM）的关键故障模式，提出了一种称为摘要增强切片（SAC）的简单且计算效率高的方法。这种方法在每个文本片段中添加文档级别的合成摘要，从而注入标准切片过程会丢失的重要全局上下文。实验证明，SAC大大减少了DRM，并提高了文本级别的检索准确性和召回率。还发现，通用的摘要策略优于利用法律专家领域知识来瞄准特定法律元素的方法。", "conclusion": "本研究表明，此实用、可扩展且易于集成的技术在大规模法律文档数据集上应用时，可以增强RAG系统的可靠性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06965", "html_url": "https://arxiv.org/abs/2510.06965", "title": "EDUMATH：生成符合标准的教育数学文字问题", "title_en": "EDUMATH: Generating Standards-aligned Educational Math Word Problems", "authors": "Bryan R. Christ,Penelope Molitz,Jonathan Kropko,Thomas Hartvigsen", "background": "数学文字问题（MWPs）是K-12教育的关键工具，根据学生的兴趣和能力定制这些题目可以提高学习成果。然而，由于班级规模较大和工作量增加，教师很难有时间为每位学生定制MWPs。", "innovation": "我们提出LLMs可以通过生成符合学生兴趣和数学教育标准的MWPs来支持数学教育。为此，我们采用人类专家-LLM联合评估方式，对11,000多道由公开和封闭LLM生成的MWPs进行了评估，并建立了首个教师标注的数据集以生成符合标准的教育MWPs。此外，我们展示了数据的价值，使用该数据训练了一款12B的开放模型，其性能与更大更强大的开放模型相当。我们还使用教师标注的数据训练了一个文本分类器，使其30B开放LLM在无任何训练的情况下超过了现有的封闭基准。我们的模型生成的MWPs与人类撰写的MWPs更为相似，而我们的定制MWPs也被学生更偏好。", "conclusion": "我们的研究首次探讨了定制的LLM生成MWPs对学生表现的影响，结果显示学生在我们的模型生成的MWPs上的表现与人类撰写的MWPs相当，但更喜欢我们的定制MWPs。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07000", "html_url": "https://arxiv.org/abs/2510.07000", "title": "Pragyaan: 设计和编纂高质量文化后训练数据集以用于印度语言", "title_en": "Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages", "authors": "Neel Prabhanjan Rachamalla,Aravind Konakalla,Gautam Rajeev,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal", "background": "大型语言模型（LLMs）的有效性很大程度上依赖于高质量后训练数据的可用性，特别是指令调优和偏好示例。现有的开源数据集通常缺乏多语言覆盖、文化基础，并且在任务多样性方面存在明显缺口，尤其是对于印度语言而言。", "innovation": "引入了一种结合翻译与合成扩展的人工介入流程，以生成可靠且多样化的印度语言后训练数据。使用此流程，创建了两个涵盖10种印度语言的data集：Pragyaan-IT（22.5K）和Pragyaan-Align（100K），这些数据集覆盖了13个广泛类别和56个细分类别，利用了57个不同的数据集。我们的data集协议考虑了许多经常被忽视的维度，强调任务多样性、多轮对话、指令准确性、安全性对齐以及文化细微之处的保留，为更具包容性和有效性的多语言LLMs提供了基础。", "conclusion": "通过这种pipeline，创建了专门针对印度语言的高质量后训练数据集。这些数据集不仅包含广泛的语言覆盖，还强调了多样性和文化敏感性，进而有助于更高效和广泛的语言模型应用。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07024", "html_url": "https://arxiv.org/abs/2510.07024", "title": "挖掘前沿大模型的心智：1000万信念揭示的前沿大模型知识特征", "title_en": "Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge", "authors": "Shrestha Ghosh,Luca Giordano,Yujia Hu,Tuan-Phong Nguyen,Simon Razniewski", "background": "大语言模型（LLMs）已显著革新了自然语言处理（NLP）和人工智能（AI）任务。这些模型的背景知识对它们的表现至关重要，但这些知识的特性和准确性至今仍不完全理解，并且通常侧重于有偏见的数据样本。", "innovation": "本文深入探讨了一种处于前沿的大语言模型（GPT-4.1）的1亿信念集合（GPTKB v1.5），发现这些模型的背景知识与现有的知识库存在显著差异，并且其准确性低于之前的基准测试结果。此外，研究还揭示了不一致、模糊性和幻觉是主要问题，这为未来关于事实性大模型知识的研究提供了机会。", "conclusion": "该研究揭示，对大模型的信念知识进行深入分析，发现其存在显著差异，并且之前的基准测试可能高估了其准确性。未来需要深入研究这些问题，以改进大模型的准确性与可靠性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07037", "html_url": "https://arxiv.org/abs/2510.07037", "title": "超越单一语言假设：大型语言模型时代代码转换自然语言处理的综述", "title_en": "Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models", "authors": "Rajvee Sheth,Samridhi Raj Sinha,Mahavir Patil,Himanshu Beniwal,Mayank Singh", "background": "代码转换（CSW）指的是在一次对话中使用多种语言和书写系统的现象，这是多语言自然语言处理（NLP）中的一个基本挑战。尽管大型语言模型（LLMs）取得了迅速的进步，大多数LLMs仍然难以处理混合语言的输入、有限的CSW数据集以及评估偏见，这阻碍了在多语言社会中的部署。", "innovation": "本文提供了CSW感知LLM研究的第一个全面分析，涵盖了五个研究领域、12项NLP任务、30多个数据集和80多种语言。文章通过架构、训练策略和评估方法对最近的进展进行了分类，概述了LLM如何重塑CSW建模及其面临的挑战。强调了创建包容性数据集、公平评估和语言背景化模型的需求，以实现真正的多语言智能。", "conclusion": "文章以路标的形式强调了CSW感知LSTM的需求，包括需要包容性数据集、公平的评估方法和语言背景化模型，以实现真正的多语言智能。所有资源的精选集合维护在提供的网址中。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07074", "html_url": "https://arxiv.org/abs/2510.07074", "title": "LuxInstruct: 一种用于卢森堡语的跨语言指令调优数据集", "title_en": "LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish", "authors": "Fred Philippy,Laura Bernardy,Siwen Guo,Jacques Klein,Tegawendé F. Bissyandé", "background": "指令调优已成为增强大型语言模型性能的关键技术，使其能更好地遵循人类提示。然而，低资源语言如卢森堡语由于缺乏高质量的指令数据集而面临严重限制。传统的机器翻译依赖会导致语义对齐问题和文化不准确。本研究旨在解决这些问题，创建一种不依赖于机器翻译的跨语言指令调优数据集。", "innovation": "通过利用与英语、法语和德语对齐的数据，建立高质量的数据集，以保留语言和文化细微差别。研究证明跨语言指令调优不仅改善了不同语言间的表示对齐，还提高了模型在卢森堡语中的生成能力。这表明跨语言数据整理可以避免常见机器翻译数据的陷阱，并直接促进低资源语言的发展。", "conclusion": "研究结果表明，跨语言指令调优不仅改善了不同语言间的表示对齐，还提高了模型在卢森堡语中的生成能力，表明了跨语言数据整理在避免常见机器翻译数据陷阱方面的优势，直接促进了卢森堡语的发展。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07048", "html_url": "https://arxiv.org/abs/2510.07048", "title": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models", "title_en": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models", "authors": "Yuntao Gui,James Cheng", "background": "尽管大型语言模型（LLMs）在自然语言理解方面表现出色，但在检索任务中的应用却不足。过去的方法未能充分利用LLMs的强大推理能力来直接生成有效的检索嵌入。", "innovation": "提出了一种名为Search-R3的新框架，通过适应LLMs以生成作为推理过程直接输出的搜索嵌入来解决这一局限性。该方法利用LLMs的步步推理能力，使其能够通过复杂的语义分析逐步推理以生成更有效的嵌入。该创新通过监督学习阶段、强化学习方法以及适应性强化学习环境三个机制实现。", "conclusion": "全面的评估表明，Search-R3在不同的基准测试上显著优于先前的方法，通过统一推理和嵌入生成过程，该集成后训练方法为处理需要复杂推理和有效信息检索的密集知识任务带来了重大进展。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07060", "html_url": "https://arxiv.org/abs/2510.07060", "title": "本地新闻是否保持地方特色？桑德琳收购后在线内容的变化", "title_en": "Does Local News Stay Local?: Online Content Shifts in Sinclair-Acquired Stations", "authors": "Miriam Wanner,Sophia Hager,Anjalie Field", "background": "本地新闻台通常被认为是可靠的非政治化信息来源，特别是居民关心的当地事务。由于这些新闻台受观众信任，因此他们所报道的信息对观众有着特别的影响。桑德琳广播集团是一家在近些年收购了众多地方新闻台的广播公司。本文旨在研究地方新闻台被桑德琳收购后的影响：新闻覆盖范围是否发生变化？因此，研究使用计算方法比较地方新闻台在被桑德琳收购前后以及与国家级新闻媒体的内容变化，发现地方新闻台在被收购后更多地报道全国性新闻，而减少对地方话题的报道，特别是在涉及两极化全国性话题时，报道量增加了。", "innovation": "本文采用计算方法研究地方新闻台在被桑德琳收购前后以及与国家级新闻媒体的内容变化，通过互联网内容分析验证了地方新闻台在被收购后更多地报道全国性新闻，特别是在涉及两极化全国性话题时，报道量增加。", "conclusion": "地方新闻台在被桑德琳收购后，报道频率有所增加的全国性新闻，而对地方话题的报道减少。尤其是对于两极化全国性话题，地方新闻台的报道量显着增加。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07019", "html_url": "https://arxiv.org/abs/2510.07019", "title": "Native Hybrid Attention for Efficient Sequence Modeling", "title_en": "Native Hybrid Attention for Efficient Sequence Modeling", "authors": "Jusen Du,Jiaxi Hu,Tao Zhang,Weigao Sun,Yu Cheng", "background": "变换器在序列建模方面表现出色，但存在平方复杂度的问题；线性注意力则提高了效率，但在长上下文场景下通常会牺牲召回精度。现有方法需要在模型复杂性和上下文召回之间做出权衡。", "innovation": "提出了Native Hybrid Attention (NHA)这一新型混合架构，它结合了线性和全注意力机制，将内层和跨层混合集成到统一的层设计中。NHA 使用线性RNN更新关键值槽位来保持长期上下文，并通过滑动窗口引入短时令牌。所有的键和值通过单一的softmax操作进行处理，无需额外的融合参数即可实现基于令牌和头的上下文相关权重。通过滑动窗口大小这一超参数控制层间行为，实现了从完全线性到全注意力的平滑过渡，同时保持所有层的结构一致性。研究表明，NHA 在召回密集型和常识推理任务上优于变换器和其他混合基线，并且在预训练的大语言模型中引入NHA后，可以在保持竞争力的同时显著提升效率。", "conclusion": "实验结果显示，NHA 在召回密集型任务和常识推理任务上超越了变换器和其他混合基线。此外，NHA 还能够与预训练的大语言模型结合，实现竞争力的准确率同时带来显著的效率提升。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07081", "html_url": "https://arxiv.org/abs/2510.07081", "title": "通过局部确定性传播加速扩散LLM推理", "title_en": "Accelerating Diffusion LLM Inference via Local Determinism Propagation", "authors": "Fanheng Kong,Jingyuan Zhang,Yahui Liu,Zirui Wu,Yu Tian,Victoria W.,Guorui Zhou", "background": "大规模语言模型（dLLMs）在文本生成方面取得了显著进步，具备并行令牌解码的能力。然而，现有的开源实现存在质量和速度之间的权衡问题，影响了它们实际应用的部署。保守的采样策略通常每次解码最自信的令牌以确保质量（即贪心解码），但这也导致了反复冗余的细化迭代，我们称之为延迟解码。通过系统分析dLLM解码动力学，作者 characterization 这种延迟解码行为，提出了一个无需训练的适应性并行解码策略，名为LocalLeap，以解决这些低效率问题。", "innovation": "LocalLeap基于两个基本的经验原则：集中在高置信度锚点的局部确定性传播和逐点空间一致性衰减。通过应用这些原则，LocalLeap发现锚点并进行局部放松的并行解码，在限定的邻域内，通过早期承诺已经确定的令牌，实现了显著的推理步骤减少，且不会牺牲输出质量。全面的基准评估表明，LocalLeap实现了6.94倍的吞吐量提升，并将解码步骤减少了到原来的14.2%，同时性能影响可以忽略不计。", "conclusion": "通过实证评估，研究证明了LocalLeap的有效性，它显著提高了推断速度并减少了解码步骤，同时保持了高质量的输出。源代码可在特定网址访问。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07061", "html_url": "https://arxiv.org/abs/2510.07061", "title": "细粒度评价印度语言机器翻译和摘要的指标可靠性再审视", "title_en": "Revisiting Metric Reliability for Fine-grained Evaluation of Machine Translation and Summarization in Indian Languages", "authors": "Amir Hossein Yari,Kalmit Kulkarni,Ahmad Raza Khan,Fajri Koto", "background": "现有的自动评价指标主要针对英语和其他高资源语言的发展和验证，但印度语言遭到了忽视，这些语言的使用者超过15亿，约占全球人口的五分之一。这使得自动评价指标的有效性、公正性和普遍性受到质疑。因此，当前对印度语言机器翻译（MT）和文本摘要（TS）的评价实践中存在显著不足，需要系统地评估一系列自动评价指标与人类评价的一致性，特别是针对印度语言独有的特点。", "innovation": "介绍了一个大规模的基准评估工具ITEM，系统性地评估了26个自动评价指标与六大印度语言的人类评价的一致性，并补充了细粒度的注释。通过全面的评估覆盖：与人类评价的一致性、异常值影响、语言特定的可靠性、指标间的相关性，以及模型对重塑扰动的弹性。这项研究是第一次全面评估自动评价指标在印度语言评价中的适用性和可靠性，揭示了不同评价指标在印度语言中表现的不同特点。", "conclusion": "研究发现了四个关键发现：LLM评价者在上下文和系统层次上与人类评价的一致性最佳；异常值对指标与人类评价的对比影响重大；文本摘要更侧重内容的一致性，而机器翻译更注重流畅性；在不同扰动下，不同评价指标的表现差异显著。这些建议为印度语言自动评价指标的设计和评估提供了关键指导。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07083", "html_url": "https://arxiv.org/abs/2510.07083", "title": "所有声明都是平等的，但有些声明比其他声明更为平等：对LLM生成的重要敏感的事实性评估", "title_en": "All Claims Are Equal, but Some Claims Are More Equal Than Others: Importance-Sensitive Factuality Evaluation of LLM Generations", "authors": "Miriam Wanner,Leif Azzopardi,Paul Thomas,Soham Dan,Benjamin Van Durme,Nick Craswell", "background": "现有的方法在评估大型语言模型（LLM）响应的事实性时将所有声明视为同等重要。这可能导致当关键信息缺失或错误时产生误导性的评估，因为它们会与次要细节一样受到同样的权重。研究者提出了一个问题：在存在关键信息错误的情况下，如何可靠地检测这些差异？目前用于测量事实性的方法通常不敏感于缺失的或虚假的关键信息。为了研究这种不敏感性，作者构建了一个名为VITALERRORS的标准测试集，包含6,733个查询和经过微调的LLM响应，设计用于省略或虚假地陈述关键信息。使用这个数据集，展示了现有评估指标对于关键信息错误的不敏感性。", "innovation": "作者构建了一个名为VITALERRORS的数据集，包含6,733个查询和经过微调的LLM响应，以省略或虚假陈述关键信息。基于此数据集，展示了现有评估指标对于关键信息错误的不敏感性。作者还引入了一组新的度量标准VITAL，通过结合声明与查询之间的相关性和重要性，在度量响应的事实性方面提供了更高的灵敏度。分析表明，VITAL指标比之前的方法更可靠地检测至关信息的错误。", "conclusion": "我们的数据集、度量标准和分析为更准确和稳健地评估LLM的事实性提供了基础。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07098", "html_url": "https://arxiv.org/abs/2510.07098", "title": "TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription", "title_en": "TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription", "authors": "Guo Yutong,Wanying Wang,Yue Wu,Zichen Miao,Haoyu Wang", "background": "现有的表格视觉问答（Table VQA）通常依赖大型视觉-语言模型（VLMs）。虽然这些模型可以从图像中直接回答问题，但除非将其扩展到非常大的规模（这在计算上是不切实际的，特别是对于移动部署来说），否则它们往往无法捕捉到细微的细节。一种替代方案是让一个小的VLM执行OCR并将结果提供给一个大型语言模型（LLM）以推理结构化的输出（如Markdown表格）。然而，这些表示方式并非为LLM自然优化，仍然会导致大量错误。", "innovation": "本文提出了TALENT（Table VQA via Augmented Language-Enhanced Natural-text Transcription），这是一种轻量级框架，利用表格的双重表示。TALENT促使一个小的VLM生成OCR文本和自然语言叙述，然后将这些内容与问题结合起来供LLM进行推理。这种方法将表格视觉问答重新定义为以LLM为中心的多模态推理任务，其中VLM作为感知叙述模块，而不是统一的解决模块。此外，作者还构建了ReTabVQA，这是一个更具挑战性的表格视觉问答数据集，需要对表格图像进行多步骤的定量推理。", "conclusion": "实验表明，TALENT使得一个小的VLM-LLM组合在较低的计算成本下，能够与单一大型VLM在公共数据集和ReTabVQA上达到类似或超越的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07096", "html_url": "https://arxiv.org/abs/2510.07096", "title": "使机器具有讽刺效果：增强型检索引导讽刺语音合成", "title_en": "Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis", "authors": "Zhu Li,Yuqing Zhang,Xiyuan Gao,Shekhar Nayak,Matt Coler", "background": "讽刺是一种微妙的非字面语言形式，给语音合成带来了巨大挑战，因为它依赖于细微的语义、上下文和节奏线索。现有语音合成研究主要集中在广泛的emotion类别上，而对讽刺的研究则相对较少。本文围绕这一背景展开研究，提出了一种通过增强语言模型（LLM）的检索增强框架来进行讽刺感知的语音合成的研究方法。", "innovation": "本文的创新点在于结合了语义嵌入和检索增强机制，具体而言，使用LoRA微调的LLaMA 3捕捉讽刺的语用不一致性及话语层面线索，通过检索增强生成（RAG）模块获取节奏范例，提供讽刺表现参考模式。所有这些都集成在一个VITS骨架中，有助于实现更自然和上下文适当讽刺语音的合成。", "conclusion": "实验表明，本文的方法在客观指标和主观评价中均优于基线模型，在语音自然度、讽刺表达能力和后续讽刺检测方面都有所提高。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07141", "html_url": "https://arxiv.org/abs/2510.07141", "title": "对比人类和语言模型在复杂结构下的句子处理困难", "title_en": "Comparing human and language models sentence processing difficulties on complex structures", "authors": "Samuel Joseph Amouyal,Aya Meltzer-Asscher,Jonathan Berant", "background": "这篇文章研究了大规模语言模型（LLMs）在与人类流畅交流的基础上，是否也在处理自然语言方面遇到类似人类的认知难题。作者发现，LLMs 在处理人类语言的各种复杂结构方面存在困难，特别是在所谓的“迷惑性路径”（Garden Path，简称GP）句子上。尽管最强的LLMs在非GP结构上达到近乎完美的准确率，但在GP结构上表现较差。", "innovation": "本文最创新之处在于，作者采用统一的实验框架，系统地比较了人类和五大家族的最先进LLMs对七种挑战性语言结构的句子理解能力。实验不仅展示了LLMs在匹配和难以处理结构句子上的表现差异，还通过参数量的增加观察到人类和模型表现的相关性，揭示了人类和LLMs在句子理解上的相似性和差异。", "conclusion": "文章结论表明，尽管人类和LLMs在较难结构的句子处理上有共同的缺陷，但在非常弱和非常强的模型中，这种表现差异不明显。这揭示了人类和LLMs在句子理解上的收敛和发散，为理解人类和LLMs的相似性提供了新的见解。此外，还揭示了不同模型处理不同类型句子时的表现差异，增加了对特定模型性能的了解。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07173", "html_url": "https://arxiv.org/abs/2510.07173", "title": "NurseLLM：首款应用于护理领域的专门语言模型", "title_en": "NurseLLM: The First Specialized Language Model for Nursing", "authors": "Md Tawkat Islam Khondaker,Julia Harrington,Shady Shehata", "background": "大型语言模型（LLMs）的最新进展在医疗系统中已经产生了显著影响，但它们在护理等专业领域中的潜力尚未被充分挖掘。", "innovation": "该研究引入了NurseLLM，这是首个专门针对护理领域的语言模型，主要用于多项选择题(multiple choice question-answering, MCQ)任务。研究人员开发了一个多阶段数据生成管道来构建大规模的护理MCQ数据集，用于训练LLMs。此外，还引入了多个护理基准测试，以便进行严格的评估。实验证明，NurseLLM在不同基准测试上都优于与之规模相当的通用和医疗专门化的LLMs，展示了护理领域专有模型的重要性。", "conclusion": "研究还探讨了推理和多智能体协作系统在护理中的作用，这些研究结果为未来的研究和应用点明了方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07105", "html_url": "https://arxiv.org/abs/2510.07105", "title": "Opt-ICL在LeWiDi-2025中的应用：通过元学习最大化判注者示例的在上下文信号", "title_en": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning", "authors": "Taylor Sorensen,Yejin Choi", "background": "许多自然语言处理(NLP)任务涉及主观性、模糊性或注释者之间的正当分歧。本文讲述了我们建立的一个系统来建模人类的变异性。该系统利用预训练语言模型的在上下文学习能力，并采用两步元学习训练程序，首先在多个需要在上下文学习的数据集上进行训练，然后通过在上下文学习将模型专业化到特定的数据分布中。同时，在LeWiDi竞赛中，评估了我们系统的性能，在两个任务中均获得第一名，并进行了消融研究以衡量每个系统组件的重要性。结果显示，将判注者示例纳入上下文是提高系统性能的关键，特定数据集的微调有助于大型数据集的性能提升，在某个任务的数据集上对其他在上下文学习的数据集进行训练有助于提高性能，并且模型规模越大性能越好。", "innovation": "提出了一种利用语言模型的在上下文学习能力和两步元学习训练程序的系统模型，旨在建模人类注释变异。该系统通过将判注者示例纳入上下文以及对特定数据分布进行在上下文元学习，提高了系统性能，并在LeWiDi竞赛中获得总体胜利，实现了在多个任务上的最优表现。", "conclusion": "研究表明，在上下文学习中加入判注者示例是系统性能的关键因素，特定数据集的微调有助于大型数据集，通过在其他在上下文学习的数据集上的训练也有助于提升性能，同时系统规模越大效果越好。该系统在LeWiDi竞赛中表现出色，证实了其有效性和可行性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07118", "html_url": "https://arxiv.org/abs/2510.07118", "title": "TRIM: 基于令牌的关注导出重要性分析以实现高效的数据驱动指令调优", "title_en": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning", "authors": "Manish Nagaraj,Sakshi Choudhary,Utkarsh Saxena,Deepak Ravikumar,Kaushik Roy", "background": "大型语言模型（LLMs）在进行下游任务调优时需要进行指令调优，这一过程通常依赖于大规模、多样化的数据集。然而，研究发现，即使是规模较小、质量较高的子集（称为小核心集或coreset），也能取得可比甚至更好的结果。现有方法主要依赖于粗略的样本级信号，如梯度，这使得处理过程既耗时又缺乏精细的特征敏感性。", "innovation": "本研究提出了一种名为TRIM（Token Relevance via Interpretable Multi-layer Attention）的前向框架，该框架通过识别少量目标样本的注意力“指纹”来匹配底层表示模式，避免使用梯度。TRIM方法通过利用结构特征提高效率和敏感性，并在下游任务上的一致性指标中显示出优越性，甚至在某些情况下超越了全数据的精细调优。该方法还通过避免昂贵的反向传递带来了显著的计算成本节省。", "conclusion": "本研究展示了TRIM作为构建高质量指令调优数据集的可扩展且高效的替代方案的潜力。TRIM能够在比现有方法更低的计算成本下，取得与大容量数据调优相当或更好的性能，特别是在一些特定场合下性能甚至超越全数据调优。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07167", "html_url": "https://arxiv.org/abs/2510.07167", "title": "推理在层次文本分类中的应用：以专利分类为例", "title_en": "Reasoning for Hierarchical Text Classification: The Case of Patents", "authors": "Lekang Jiang,Wenjun Sun,Stephan Goetz", "background": "层次文本分类（HTC）是将文档分配到预定义分类体系的多个层级的过程。专利主题分类是HTC的一个非常具有挑战性的场景，因为它涉及专业知识的难度和大量的标签。现有方法只是输出一个扁平的标签集，这不能深入解释预测背后的理由。研究表明，层次文本分类面临以下问题：专业领域知识的复杂性、标签数量庞大、现有方法生成的标签缺乏解释性等。已有方法仅对外提供最终的结果，而不包含决策过程或原因，这使得理解和验证决策过程变得困难。因此，提出了一个新的框架，即层次分类推理（RHC），它将层次文本分类转化为一个逐步推理的任务，通过两阶段训练大型语言模型来提高多步推理的能力。", "innovation": "RHC通过两阶段训练（冷启动阶段和强化学习阶段）大型语言模型来解决HTC的挑战，首次将层次文本分类任务转化为逐步推理问题，提供了逐级推理逻辑和自然语言的理由解释，解决了传统方法的黑盒问题，增强了模型的解释性和泛化能力。RHC在多个数据集上表现优越，特别是在模型规模和可扩展性方面。此外，RHC不仅适用于专利分类等专业领域，还可以应用于其他层次文本分类任务。这一框架展示了在复杂文本分类问题上的创新应用和广泛适用性。", "conclusion": "本文提出了一种名为RHC的新框架，它通过逐步推理解决层次文本分类问题，并通过冷启动阶段和强化学习阶段训练大型语言模型。实验结果表明，该方法在准确性、解释性、可扩展性和适用性四个方面表现出显著的优势。我们的发现强调了RHC框架在复杂文本分类问题上的广泛适用性和重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07169", "html_url": "https://arxiv.org/abs/2510.07169", "title": "更多数据还是更好数据？数学推理中数据选择和合成的批判性分析", "title_en": "More Data or Better Data? A Critical Analysis of Data Selection and Synthesis for Mathematical Reasoning", "authors": "Yike Zhao,Simin Guo,Ziqing Yang,Shifan Han,Dahua Lin,Fei Tan", "background": "大规模语言模型（LLMs）的推理能力在许多下游任务中起着关键作用，但这些能力高度依赖于训练数据的质量。尽管已经提出了各种数据构建方法，但在实际工作流程中的实用性仍然未得到充分探索。本文通过全面分析开源数据集和数据合成技术在数学推理中的应用，评估了这些方法在统一管道下的表现，设计的管道旨在模拟训练和部署场景。研究进一步总结了有效数据选择策略，并指出了适用于工业应用的实用方法。研究结果表明，构建更具解释性的数据结构或从更强的模型中提取信息通常优于简单地增加数据量。该项研究提供了集成训练数据以增强LLM能力的实际指导，支持成本有效的数据策展和可扩展模型增强。", "innovation": "本文通过全面分析开源数据集和数据合成技术在数学推理中的应用，设计了一个统一管道对其进行评估。进一步总结了有效数据选择策略并指出了适用于工业应用的实用方法。研究表明，构建更具解释性的数据结构或从更强的模型中提取信息通常优于简单地增加数据量，为实现实用的平衡策略提供了理论依据。", "conclusion": "研究结果为通过数据策展和更有效的数据使用来提升LLM能力提供了实际指导，支持成本效益较高的数据管理和模型增强。本文呼吁进一步研究如何平衡“更多数据”与“更好数据”以适应实际推理任务的需求。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07177", "html_url": "https://arxiv.org/abs/2510.07177", "title": "CARPAS：在大型语言模型中迈向基于内容感知的提供方面完善总结", "title_en": "CARPAS: Towards Content-Aware Refinement of Provided Aspects for Summarization in Large Language Models", "authors": "Yong-En Tian,Yu-Chien Tang,An-Zi Yen,Wen-Chih Peng", "background": "方面感知总结吸引了大量关注，因为它能够生成更加细粒度且用户导向的摘要。然而，大多数现有方法假设输入为预定义方面集，而实际场景中这些方面可能是不完整、不相关或完全缺失的。用户期望系统能够根据实际内容自适应地调整或过滤这些方面。本文探讨了在大型语言模型中基于内容感知的方法，以动态地根据文档上下文调整这些方面，进而进行总结。", "innovation": "本文提出了一个新的任务设置，称为内容感知提供的方面调整以进行总结（CARPAS）。通过构建新的数据集，使用四种代表性的提示策略，发现LLMs倾向于预测过多的方面，导致生成过长且不匹配的摘要。因此，提出了一个初步子任务来预测相关方面数量，并表明预测的数量可以为LLMs提供有效指导，降低推断难度，使它们专注于最相关方面。实验结果表明，所提出的方法在所有数据集上的性能都有显著提升。", "conclusion": "广泛的实验表明，提出的⽅法在所有数据集上均表现出显著的性能提升。深入分析揭示了当所需方面数量与LLMs估计的数量不同时，LLMs的遵从性，有助于在类似实际场景中部署LLMs。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07178", "html_url": "https://arxiv.org/abs/2510.07178", "title": "无偏见的语言模型学习异常：LLM在区分可能与不可能方面失败", "title_en": "Biasless Language Models Learn Unnaturally: How LLMs Fail to Distinguish the Possible from the Impossible", "authors": "Imry Ziv,Nur Lan,Emmanuel Chemla,Roni Katzir", "background": "本文探讨了大型语言模型（LLMs）是否能够区分人类可能使用和不可能使用语言的能力。之前的研究通过比较LLMs在现有语言数据集和由这些数据集通过各种扰动函数构建的“不可能”数据集上的学习曲线，试图证明LLMs和人类共享类似的内在学习偏见。本文使用相同的方法，对更广泛的语言和不可能的变形进行了研究，发现GPT-2在大多数情况下能够同样容易地学习每种语言及其不可能的对应版本，这与之前的说法相反。此外，通过测试GPT-2能否在自然语言和不可能语言的整个集合之间进行某种形式的区分，本文进一步表明GPT-2未能在可能与不可能的语言之间提供系统性的区分。", "innovation": "本文扩充了研究范围，不仅针对有限的语言数据集及其几何变换，还包括了广泛的语料库和变形方式，使用相同的方法进行了研究。通过考虑不规则性曲线上的各种度量的跨语言差异，本文得出结论，GPT-2 在系统区分可能和不可能的语言方面表现不佳。", "conclusion": "本文结论表明，大型语言模型并不共享人类用于形成语言类型的内在偏见。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07203", "html_url": "https://arxiv.org/abs/2510.07203", "title": "Sunflower：一种扩大非洲语言在大规模语言模型中覆盖范围的新方法", "title_en": "Sunflower: A New Approach To Expanding Coverage of African Languages in Large Language Models", "authors": "Benjamin Akera,Evelyn Nafula Ouma,Gilbert Yiga,Patrick Walukagga,Phionah Natukunda,Trevor Saaka,Solomon Nsumba,Lilian Teddy Nabukeera,Joel Muhanguzi,Imran Sekalala,Nimpamya Janat Namara,Engineer Bainomugisha,Ernest Mwebaze,John Quinn", "background": "非洲有超过2000种语言，其中大多数语言已经被语言技术的进步所忽视。目前领先的大型语言模型（LLMs）在一些最常用的语言（如斯瓦希里语或约鲁巴语）上表现出色，但它们优先支持使用人数最多的语言，导致对许多不同语言的支持是断断续续的。", "innovation": "我们提出一种地区性聚焦的方法，并以乌干达为例进行研究，该地区语言多样性很高。我们开发了Sunflower 14B和32B这两个基于Qwen3的模型，它们在乌干达所有主要语言上都有最先进的理解能力。这些模型是开源的，可以用于许多重要的实际应用场景中。", "conclusion": "我们认为区域化的方法更有效，并通过开源的Sunflower模型展示了这一方法的实际应用价值，降低了这些语言在实际应用中的障碍。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07227", "html_url": "https://arxiv.org/abs/2510.07227", "title": "从何处开始：通过子网络选择和蒸馏进行高效预训练", "title_en": "Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation", "authors": "Arjun Krishnakumar,Rhea Sanjay Sukthanker,Hannan Javed Mahadik,Gabriela Kadlecová,Vladyslav Moroshan,Timur Carstensen,Frank Hutter,Aaron Klein", "background": "小型语言模型（SLMs）提供了大型语言模型（LLMs）的一个高效且易用的替代方案，能够在相同资源消耗下实现出色的性能。本文提出了一种简单且有效的SM训练框架，整合了三种互补的思路：结构稀疏子网络初始化、进化搜索以及教师模型的知识蒸馏，从而加速训练并提高泛化性能。", "innovation": "该研究提出的框架结合了结构稀疏的子网络初始化、进化搜索以及知识蒸馏技术，有效地提高了SM训练的效率。所提出的最佳模型，在使用进化搜索并以LLM权重初始化的情况下，其验证困惑度与一个相当的Pythia SLM相当，但仅需要9.2倍较少的预训练令牌。", "conclusion": "整体来说，这一研究通过上述技术显著提高了SM的训练效率，同时在验证困惑度上达到了与大型模型相当的表现。作者已经开源了所有的代码和模型，为大规模高效的小型语言模型开发提供了一种实用且可复制的路径。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07230", "html_url": "https://arxiv.org/abs/2510.07230", "title": "Customer-R1: 基于RL的LLM代理在在线购物中的人性化行为模拟", "title_en": "Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM Agent in Online Shopping", "authors": "Ziyi Wang,Yuxuan Lu,Yimeng Zhang,Jing Huang,Dakuo Wang", "background": "大型语言模型（LLMs）模拟分步人类行为成为研究的一个新兴方向，已在各种实际应用领域展示了潜力。早期的方法包括提示、监督微调（SFT）及强化学习（RL），在建模分步行为方面虽有进展，但主要学习群体级别的策略，而忽略了用户个性，导致了泛化的而非个性化的模拟结果。", "innovation": "通过引入基于RL的Customer-R1方法，针对在线购物环境进行个性化分步用户行为模拟。该方法将策略依赖于明确的用户画像，并通过行为正确性奖励信号优化下一步推理和动作生成。实验结果表明，Customer-R1不仅在下一行动预测任务中显著优于提示和基于SFT的基本方法，还能更好地匹配用户的行动分布，显示出高度真实的个性化行为模拟能力。", "conclusion": "Customer-R1方法在在线购物环境中实现了更好的个性化行为模拟，相较于传统方法，在行动预测和匹配用户行为分布方面表现更佳。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07175", "html_url": "https://arxiv.org/abs/2510.07175", "title": "量化大型语言模型心理测量评估中的数据污染", "title_en": "Quantifying Data Contamination in Psychometric Evaluations of LLMs", "authors": "Jongwook Han,Woojung Song,Jonggeun Lee,Yohan Jo", "background": "近期研究将心理测量问卷应用于大型语言模型（LLMs），以评估价值观、人格、道德基础和黑暗特质等高阶心理结构。尽管先前的研究对心理测量问卷可能存在数据污染表示担忧，这可能威胁这些评估的可靠性，但尚未有系统方法来量化这种污染的程度。", "innovation": "本文提出了一种框架，用于系统地测量心理测量评估中LLMs的数据污染，评估了三个方面：（1）项目记忆、（2）评估记忆、（3）目标分数匹配。该框架被应用于主要语言模型家族中的21种模型和四种常用心理测量问卷，提供了有力证据证明常用的问卷如大五人格量表（BFI-44）和价值观肖像问卷（PVQ-40）存在严重的污染，模型不仅能够记忆项目，还能调整其回应以达到特定的目标分数。", "conclusion": "研究表明流行的问卷，特别是在心理评估中广泛使用的BFI-44和PVQ-40，显示出了强烈的数据污染现象，模型不仅记忆项目，还能根据目标分数调整回应，因此需要对此类评估的可靠性进行重新评估。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07238", "html_url": "https://arxiv.org/abs/2510.07238", "title": "当基准变老：大规模语言模型事实性评估中的时代不匹配", "title_en": "When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation", "authors": "Xunyi Jiang,Dingyi Chang,Julian McAuley,Xin Xu", "background": "随着大规模语言模型（LLMs）和现实世界的发展，广泛使用的评估基准已经落后，引起了对其评估LLM事实性的可靠性的担忧。虽然许多研究仍然依赖这些过时但流行的基准，但它们与现实世界事实以及现代LLMs的时间不匹配及其对LLM事实性评估的影响尚未得到充分探讨。", "innovation": "本文系统研究了这一问题，通过检查五个广泛使用的事实性基准和八个不同年份发布的八个LLM，使用最新的事实检索管道和三个度量来量化基准老化及其对LLM事实性评估的影响。结果表明，广泛使用的大量事实性基准样本存在过时问题，导致了对LLM事实性的不可靠评估。", "conclusion": "希望我们的工作能提供一个评估基准可靠性的测试床，并激发更多关于基准老化问题的研究。代码已在该网址提供：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07233", "html_url": "https://arxiv.org/abs/2510.07233", "title": "LAD-RAG: 面向视觉丰富文档的理解的布局感知动态RAG", "title_en": "LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document Understanding", "authors": "Zhivar Sourati,Zheng Wang,Marianne Menglin Liu,Yazhe Hu,Mengqing Guo,Sujeeth Bharadwaj,Kyu Han,Tao Sheng,Sujith Ravi,Morteza Dehghani,Dan Roth", "background": "传统的检索增强生成（RAG）方法在处理视觉丰富文档（VRDs）时存在局限性，这些方法在数据摄取阶段将内容分割成孤立的片段，从而忽略了结构和跨页面的依赖关系。在推理阶段，它们仍会检索固定数量的页面，而不考虑问题的具体需求或上下文。这种做法会导致不完整的证据检索和降低多页面推理任务的答案质量。", "innovation": "该论文提出了LAD-RAG，一种新型的布局感知动态RAG框架。在数据摄取阶段，LAD-RAG构建了一个符号文档图，捕捉文档的布局结构和跨页面依赖关系，并将其与标准神经嵌入一同提供，以生成更具整体性的文档表示。在推理阶段，利用大语言模型（LLM）代理动态与神经和符号索引交互，根据查询需求适配性地检索必要的证据。实验表明，LAD-RAG在无任何k值调优的情况下可以获得超过90%的完美召回率，并且在回忆率方面表现出优于基线检索器20%的优势，同时保持较高的问答准确度和较低的延迟。", "conclusion": "LAD-RAG通过结合文档的布局结构和神经嵌入，解决了传统RAG方法中的限制，并通过动态检索策略提高了多页面理解任务的召回率和问答质量。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07221", "html_url": "https://arxiv.org/abs/2510.07221", "title": "在非洲语言中进行ASR需要多少语音数据？基虞伟语和基库尤语的数据扩展评估", "title_en": "How much speech data is necessary for ASR in African languages? An evaluation of data scaling in Kinyarwanda and Kikuyu", "authors": "Benjamin Akera,Evelyn Nafula,Patrick Walukagga,Gilbert Yiga,John Quinn,Ernest Mwebaze", "background": "低资源非洲语言的自动语音识别（ASR）系统的发展因缺乏转录语音数据而具有挑战性。尽管像OpenAI的Whisper这样的大规模多语言模型提供了低资源ASR开发的有希望的途径，但实际部署的要求仍然存在疑问。本文旨在解决从业者两个根本性的问题：确定实现可行性能所需的最小数据量以及描述生产系统中出现的主要失败模式。", "innovation": "本文通过全面的实验对基虞伟语和基库尤语进行评估，探讨了大规模数据扩展对性能的影响及数据质量问题对高错误案例的贡献率。研究结果表明，实现实用的ASR性能（错误率低于13%）只需50小时的训练数据，并且性能通过200小时训练数据可以显著提高。研究还发现，数据质量问题，特别是嘈杂的地面真值转录文本，占高错误案例的38.6%，表明仔细的数据整理与数据量一样关键。", "conclusion": "研究结果为在具有类似低资源语言背景的团队开发ASR系统提供了可操作的规范和部署指南。同时，作者发布了相应的模型供其他研究者使用。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07213", "html_url": "https://arxiv.org/abs/2510.07213", "title": "语言存在于稀疏维度中：走向可解释和高效的大型语言模型多语言控制", "title_en": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models", "authors": "Chengzhi Zhong,Fei Cheng,Qianying Liu,Yugo Murawaki,Chenhui Chu,Sadao Kurohashi", "background": "大型语言模型尽管受到非英语数据的限制，依然显示出了多语言能力。先前的研究表明，以英语为中心的大型语言模型会在中间层将多语言内容映射到英语对齐的表示中，然后在最终层将其投影回目标语言的标记空间。基于这一观察，假设这一跨语言转换是由少量稀疏的维度控制，这些维度在中间层到最终层中总是在一致的位置上出现。", "innovation": "提出了一个简单且不依赖于训练的方法来识别和操控这些维度，只需要50句平行语料或单语料即可。实验表明，这些维度具有可解释性，干预这些维度可以切换输出语言同时保留语义内容，并且在较低成本下超过了基于神经元的方法。", "conclusion": "研究表明，在较小的稀疏维度内进行干预可以实现多语言控制，同时保持语义内容，并且这种方法在效率上超过了以前的方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07243", "html_url": "https://arxiv.org/abs/2510.07243", "title": "LeMAJ (Legal LLM-as-a-Judge): 桥接法律推理与LLM评估", "title_en": "LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation", "authors": "Joseph Enguehard,Morgane Van Ermengem,Kate Atkinson,Sujeong Cha,Arijit Ghosh Chowdhury,Prashanth Kallur Ramaswamy,Jeremy Roghair,Hannah R Marlowe,Carina Suzana Negreanu,Kitty Boxall,Diana Mincu", "background": "在法律领域评估大型语言模型（LLM）输出面临独特挑战，因为法律分析具有复杂和微妙的特性。当前的评估方法要么依赖于昂贵地生产的参考数据，要么使用标准化的评估方法，这些方法在法律应用中有显著的局限性。虽然作为法官的LLM作为一种有希望的评估技术已经出现，但在法律背景下的可靠性和有效性依赖于与法律行业独特的评估过程相关，并且需要被人类法律专家认为是可信的。现有的评估方法目前存在重大差异。", "innovation": "本研究通过a) 将长篇回复分解为自包含的信息单元‘法律数据点’（LDPs），并引入一种新型、无需参考的数据评估方法，该方法反映了律师如何评估法律答案；b) demonstrations that our method outperforms a variety of baselines on both our proprietary dataset and an open-source dataset (LegalBench)；c) show how our method correlates more closely with human expert evaluations and helps improve inter-annotator agreement；以及最后d) 开源了在实验中使用的LegalBench的部分数据点，使得研究界能够复制我们的结果并推动这一重要领域的LLM评估研究。", "conclusion": "通过LeMAJ（Legal LLM-as-a-Judge），研究弥合了法律推理与LLM评估之间的差距，提升了在法律问答中的LLM评估方法，展示了更接近人类专家评估并有助于提高注释者间一致性的评估方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07231", "html_url": "https://arxiv.org/abs/2510.07231", "title": "使用科学验证关系测评大语言模型因果推理", "title_en": "Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships", "authors": "Donggyu Lee,Sungwon Park,Yerin Hwang,Hyunwoo Oh,Hyoshin Kim,Jungwon Kim,Meeyoung Cha,Sangyoon Park,Jihee Kim", "background": "大语言模型（LLMs）需要通过因果推理理解真正的原因-结果关系，而不是仅仅依赖于模式匹配。现有的基准测试存在关键限制，如依赖合成数据和狭窄的主题覆盖范围。这些基准测试无法覆盖真实世界中复杂的因果关系。本研究提出了一种新的基准测试，该基准测试基于来自顶级经济学和金融期刊中的实际因果关系，并采用严格的工具变量、差异差异和回归断点设计等方法。新的基准测试覆盖了5种任务类型，内容涉及健康、环境、技术、法律和文化等多个领域，共包含40,379个评估项目", "innovation": "本研究引入了一种新的基准测试，这些关系是从顶级经济学和金融期刊中通过严格的因果推理方法识别和提取的，涵盖了多个领域。这种基准测试能够更好地反映现实世界中的因果关系复杂性，并全面测试LLMs的因果推理能力。", "conclusion": "实验结果显示，当前最先进的八种LLM在因果推理方面的表现存在显著不足，最好的模型准确率为57.6%，并且模型规模并不能保证更好的性能。即使是有高级推断能力的模型在识别基本的因果关系上也显得力不从心。这些发现表明，当前大语言模型的能力与高风险应用中所需的可靠因果推理之间存在巨大差距。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07242", "html_url": "https://arxiv.org/abs/2510.07242", "title": "Hybrid Reinforcement: 当奖励稀疏时，密集更好", "title_en": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense", "authors": "Leitian Tao,Ilia Kulikov,Swarnadeep Saha,Tianlu Wang,Jing Xu,Yixuan Li,Jason E Weston,Ping Yu", "background": "大型语言模型（LLMs）的后训练越来越依赖于可验证的奖励：确定性的检查器提供0-1正确性信号。虽然可靠，但这种二元反馈过于脆弱——许多任务允许部分正确或替代答案，验证器可能低估了这些情况，导致所有或无的监督限制了学习。奖励模型提供了更丰富、连续的反馈，可以作为验证器的补充监督信号。HERO（Hybrid Ensemble Reward Optimization，混合集成奖励优化）是一种强化学习框架，将验证器信号与奖励模型得分以结构化方式结合。HERO 使用分层标准化来限制奖励模型得分在验证器定义的组内，并使用对变异量意识加权来强调最需要密集信号提示。在各种数学推理基准测试中，HERO 在可验证和难以验证的任务上一致性地优于仅使用奖励模型和仅使用验证器的基线，展示了混合奖励设计保持验证器的稳定性同时利用奖励模型的细微差别的优势。", "innovation": "引入了HERO（Hybrid Ensemble Reward Optimization），一种结构化结合验证器和奖励模型反馈的强化学习框架。HERO 使用分层标准化和对变异量意识加权技术，提高了模型在处理复杂推理任务时的性能，特别是在验证器和奖励模型都难以可靠评估的情况下。HERO 在多种数学推理基准测试中显示了比单独使用奖励模型或验证器更强的性能提升。", "conclusion": "HERO 的混合奖励设计保持了验证器的稳定性，并利用了奖励模型的细微差别来提高复杂推理任务的学习和推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07239", "html_url": "https://arxiv.org/abs/2510.07239", "title": "Red-Bandit：通过带宽引导LoRA专家进行大语言模型红队测试时的自适应", "title_en": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "authors": "Christos Ziakas,Nicholas Loo,Nishita Jain,Alessandra Russo", "background": "自动化红队测试已经成为在部署前审计大语言模型（LLMs）的一种可扩展的方法，但现有的方法缺乏机制来有效地适应不同模型的漏洞。红队测试通常涉及创建特定类型的攻击以揭示模型的安全弱点。然而，现有的方法往往无法灵活地调整以应对模型在推理阶段的具体弱点。因此，存在一种需求，即开发一种能够在多种攻击风格下自适应的红队测试框架，以更有效地发现和利用模型的故障模式，并生成机器可读性更高的攻击提示，同时保持较高的攻击成功率。", "innovation": "本文引入了Red-Bandit，这是一种红队测试框架，能够在运营过程中自适应地识别并利用模型在不同攻击风格下的故障模式（例如操控和俚语攻击）。红队测试通常涉及特定的攻击策略以揭示模型的弱点。Red-Bandit框架通过强化学习对一个参数高效的LoRA专家进行后训练，这些专家专门针对不同的攻击风格，且使用基于规则的安全模型来奖励生成不安全的提示。在推理过程中，多臂老虎机策略会根据目标模型的响应安全动态选择攻击风格的专家们，这有助于平衡探索与利用。该框架在AdvBench上达到了最先进的结果（ASR@10），且生成的人机可读性更低且更为简洁的攻击提示。此外，Red-Bandit的多臂老虎机策略还被用作一种诊断工具，用于检测模型的特定弱点，它通过揭示哪些攻击风格最能引发不安全行为来帮助识别这些弱点。", "conclusion": "Red-Bandit是第一种能够通过多臂老虎机策略和LoRA专家自适应地识别和利用模型在不同攻击风格下故障模式的框架，它在保持高攻击成功率的同时还能生成更简洁的人机可读提示。此外，该多臂老虎机策略还可以用作诊断工具，帮助识别特定模型的弱点。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07300", "html_url": "https://arxiv.org/abs/2510.07300", "title": "本地思考：通过一致性增强强化学习实现多语言推理", "title_en": "Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning", "authors": "Xue Zhang,Yunlong Liang,Fandong Meng,Songming Zhang,Kaiyu Huang,Yufeng Chen,Jinan Xu,Jie Zhou", "background": "大型推理模型（LRMs）通过采用'思考-回答'范式，在复杂推理任务中取得了显著的成绩，增强了准确性和可解释性。然而，当前的LRMs在处理非英语语言时存在两个关键限制：（1）难以保持输入和输出语言的一致性；（2）通常在错误的推理路径和较低的答案准确性上表现较差，特别是在与英语相比时。这些限制严重影响了非英语母语使用者的用户体验，并妨碍了LRMs在全世界的部署。", "innovation": "为了解决这些问题，本文提出了M-Thinker，它使用GRPO算法训练，并引入了语言一致性（LC）奖励和一个新的跨语言思考对齐（CTA）奖励。LC奖励对输入、思考和回答之间的语言一致性设定了严格限制。而CTA奖励则比较模型在非英语中的推理路径与英语推理路径，以从英语向非英语语言转移其推理能力。通过迭代的强化学习过程，M-Thinker-1.5B/7B模型不仅实现了近100%的语言一致性，并且在两个多语言基准（MMATH和PolyMath）上取得了优越的表现，还展示了在未见过的语言领域中的良好泛化能力。", "conclusion": "M-Thinker模型通过一致性增强的强化学习，成功地解决了大型推理模型在非英语语言处理中的两个关键问题，实现了多语言推理能力的显著提升，为全球部署提供了坚实的基础。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07248", "html_url": "https://arxiv.org/abs/2510.07248", "title": "不要为小型语言模型调整工具；而是调整工具方案以适应模型", "title_en": "Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the Models", "authors": "Jonggeun Lee,Woojung Song,Jongwook Han,Haesung Pyun,Yohan Jo", "background": "小型语言模型（SLMs）在工具增强的人工智能系统中提供了显著的计算优势，但它们在使用工具的任务上表现不佳，尤其是在选择合适的工具和识别正确的参数方面。一种常见的失败模式是架构不对齐：模型会创作出符合预训练中学习到的命名惯例但实际不存在的工具名称。我们不强制模型适应任意的架构，而是提议根据模型的预训练知识来调整架构。作者引入了PA-Tool（预训练对齐工具方案生成），这是一种无需训练的方法，利用从污染检测中提取的显著性信号，即预训练熟悉度，自动重命名工具组件。", "innovation": "作者提出了一种基于模型预训练知识的方法，名为PA-Tool，通过自动重命名工具组件来对齐工具方案。该方法通过生成多个候选并选择样本输出中浓度最高的方案，以识别出预训练对齐的命名模式。实验结果表明，这种方法在MetaTool和RoTBench上的表现提高了17个百分点，错误减少80%，使得小型模型能够接近最先进的技术水平，同时保持对新工具的高效适应而无需重新训练。", "conclusion": "研究证明，通过架构层面的干预可以解锁资源高效模型的工具使用潜力，通过使架构适应模型而非反向调整，可以提高小型语言模型在使用工具的任务上的表现，同时保持高效的适应新工具的能力，而无需重新训练模型。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07290", "html_url": "https://arxiv.org/abs/2510.07290", "title": "大型语言模型中道德自我纠正的收敛性研究", "title_en": "On the Convergence of Moral Self-Correction in Large Language Models", "authors": "Guangliang Liu,Haitao Mao,Bochuan Cao,Zhiyu Xue,Xitong Zhang,Rongrong Wang,Kristen Marie Johnson", "background": "大型语言模型（LLMs）在接到改进回答的要求时，能够进行自我纠正。当指令提供仅是一个概括的目标而没有关于潜在问题的具体细节时，LLMs 需要依靠其内部知识来提高回答质量，这一过程称为内在的自我纠正。内在自我纠正已经在多种应用中得到实证验证，但其有效性的具体机制尚不清楚。本文专注于揭示大型语言模型中道德自我纠正的关键特性及其多轮交互中的性能收敛行为，并进行了机理分析。研究表明，内嵌的自我纠正指令通过连续注入激活道德概念，从而减少了模型的不确定性，导致在后续多轮交互中达到收敛效果，这是由于激活的道德概念在连续交互过程中稳定下来所致。总体上，此研究展示了道德自我纠正具有期望特点的收敛性能，进一步推动了其在实际应用中的潜力。", "innovation": "该研究揭示了大型语言模型中内在自我纠正的关键特性，特别是多轮交互中的性能收敛机制。通过注入自我纠正指令，激活道德概念，减少了模型不确定性，从而在后续多轮交互中实现了性能收敛，并提供了详细的机理分析，解释了这一收敛现象是如何发生的。这对于理解大型语言模型在特定任务中的自我修正能力具有重要意义，并揭示了道德概念在模型收敛过程中的核心作用。", "conclusion": "本文展示了道德自我纠正具有期望特点的收敛性能，通过揭示其内在机制，进一步推动了大型语言模型在实际应用中的潜在价值。道德自我纠正可以帮助模型在回答时更准确地满足特定道德标准，这在需要伦理决策的场景中尤为重要。该研究为未来研究提供了新的视角，即利用道德自我纠正提升模型在复杂任务中的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07315", "html_url": "https://arxiv.org/abs/2510.07315", "title": "Vibe Checker: 调整代码评估与人类偏好", "title_en": "Vibe Checker: Aligning Code Evaluation with Human Preference", "authors": "Ming Zhong,Xiang Zhou,Ting-Yun Chang,Qingze Wang,Nan Xu,Xiance Si,Dan Garrette,Shyam Upadhyay,Jeremiah Liu,Jiawei Han,Benoit Schillings,Jiao Sun", "background": "大规模语言模型（LLMs）促进了vibe码的编码，用户通过自然语言交互与LLMs进行代码生成和迭代完善，直到通过vibe检查。vibe检查关联于现实世界中的人类偏好，不仅关注功能性，还涵盖代码是否自然、易读、保存意图并保持正确性。然而，现有的代码评估仍主要基于功能性正确性（pass@k），忽视了用户的非功能性需求。因此，本文假设遵循指令是vibe检查中反映人类在编程中偏好之外的关键因素。", "innovation": "本文提出了VeriCode，一种包含30个可验证代码指令及其对应确定性验证器的分类法。通过这种方式扩展现有的评估套件，创建了Vibe Checker测试平台，以同时评估代码指令遵循和功能性正确性。研究对31个领先的大规模语言模型进行了评估，结果显示即使最强的模型也难以同时满足多个指令要求，并且在功能性上出现了明显的倒退。更重要的是，功能性正确性和指令遵循的综合评分与人类偏好相关性最高，后者成为在现实编程任务中区分模型的关键。", "conclusion": "本文识别出vibe检查的核心因素，提供了一个具体的路径来制定验证和开发更好的模型，使其更符合用户的编程偏好。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07309", "html_url": "https://arxiv.org/abs/2510.07309", "title": "Agent Bain vs. Agent McKinsey: 一个面向商务领域的新型文本到SQL基准", "title_en": "Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain", "authors": "Yue Li,Ran Tao,Derek Hommel,Yusuf Denizay Dönder,Sungyong Chang,David Mimno,Unso Eun Seo Jo", "background": "在商业领域，数据分析驱动的决策至关重要，而文本到SQL是获取结构化数据的简便自然语言接口。尽管最近的语言模型（LLM）在代码生成方面取得了显著成效，但现有的文本到SQL基准仍旧集中在对历史记录的直接事实检索上。本文提出了CORGI，这是一个专为真实世界商业环境设计的新基准。CORGI借鉴了如Doordash、Airbnb和Lululemon等企业，包含四个层次的复杂商业查询：描述性、解释性、预测性和推荐性。这些查询要求因果推理、时间预测和战略推荐，反映了多层次和多步骤的代理智能。研究发现，LLM在高层次查询上的表现不佳，难以做出准确预测并提出可行计划。基于执行成功率，CORGI基准比BIRD基准难约21%。这表明了流行语言模型与现实世界商业智能之间的差距，因此需要专门的基准来评估代理智能。为此，作者公开了数据集、评估框架，并提供了在线提交平台。", "innovation": "CORGI基准是首个专门针对真实世界商业场景的文本到SQL基准，它涵盖了描述性、解释性、预测性和推荐性四个层次的商业查询，这需要更大的因果推理、时间预测和战略推荐能力。它比现有基准更具挑战性，特别是在处理复杂查询方面，展示了现有语言模型与实际商业需求之间的差距。CORGI还公开了数据集和评估框架，促进了进一步的研究和发展。", "conclusion": "CORGI基准显著提高了对高级查询的理解和处理能力，说明了现有语言模型在现实世界商业应用中的局限性。为了更好地适应真实世界的商业智能需求，需要进一步优化和改进语言模型。CORGI基准为这一领域的研究和开发提供了新的动力，并展示了未来潜在的应用场景。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06350", "html_url": "https://arxiv.org/abs/2510.06350", "title": "征求它：在线内容审核中预测违规行为的问答方法", "title_en": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation", "authors": "Mattia Samory,Diana Pamfile,Andrew To,Shruti Phadke", "background": "在线社区依赖平台政策和社区自主制定的规则来定义可接受的行为并维持秩序。然而，这些规则在不同社区之间差异巨大，随着时间变化，并且执行不一致，这为透明度、治理和自动化带来了挑战。为了应对这些挑战，本文旨在通过量化规则及其执行关系，提出ModQ框架，这是一个用于规则敏感内容审核的新型问答框架。", "innovation": "不同于先前的分类或生成方法，ModQ在推理时考虑了全面的社区规则集，并确定哪些规则最适合给定评论。本文实现了两种模型变体——提取式和多项选择问答，并在来自Reddit和Lemmy的大规模数据集上进行了训练，后者是基于公开的管理日志和规则描述构建的。这两种模型在识别与内容审核相关的违规行为方面优于最先进的基线，同时保持轻量级和可解释性。值得注意的是，ModQ模型能够有效推广到未见过的社区和规则，支持资源有限的内容审核和动态治理环境。", "conclusion": "研究表明，ModQ模型在大规模数据集上表现出色，能够在不密集过度训练的情况下准确识别内容审核中的相关违规行为。这为在线社区的透明度、自动化审核和高效治理提供了新的方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06261", "html_url": "https://arxiv.org/abs/2510.06261", "title": "AlphaApollo：协调基础模型和专业工具以实现自我演化的深度自主推理系统", "title_en": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning", "authors": "Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han", "background": "该研究旨在解决基础模型推理中的两个瓶颈：内在容量有限和测试时迭代不可靠。现有的基础模型在自主推理能力上存在不足，难以进行精确计算和验证决策。尽管有一些方法尝试提高模型性能，但大多数方法依赖于单一模型，难以解决模型内部能力有限和外部信息处理不足的问题。", "innovation": "AlphaApollo 是一个自我演化、自主推理的系统，通过多重模型和专业工具的协调来克服现有技术的局限。具体创新点包括：1）结合计算工具和检索工具，实现精确计算和基于事实的决策；2）支持多轮、多模型解决方案演化，通过共享状态图记录候选方案、可执行检查和反馈，促进迭代优化；3）显著提升基础模型的能力天花板，并在多个模型上进行了验证，显示了显著的改进，如在Qwen2.5-14B-Instruct上平均提高5.15%，通过率提高23.34%，在Llama-3.3-70B-Instruct上平均提高8.91%，通过率提高26.67%。", "conclusion": "AlphaApollo 的研究结果表明，通过使用专业工具和多个基模的协作，可以显著提高基础模型的自主推理能力。该系统在AIME 2024/2025等评估中表现出色，并且展示了工具的有效运用有助于不断改进基础模型的能力水平。未来将更新更多实证结果和实现细节。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06475", "html_url": "https://arxiv.org/abs/2510.06475", "title": "PuzzlePlex: 通过谜题评估基础模型的推理和计划能力", "title_en": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles", "authors": "Yitao Long,Yuru Jiang,Hongjun Liu,Yilun Zhao,Jingchen Sun,Yiqiu Shen,Chen Zhao,Arman Cohan,Dennis Shasha", "background": "本文探讨了基础模型在复杂、动态环境中的推理和规划能力。PuzzlePlex是一个专为此目的设计的基准，包含15种不同类型的谜题，旨在评估这些能力。 ", "innovation": "提出了一种名为PuzzlePlex的基准，其包括定制的游戏策略以进行比较，并开发了精细的性能度量标准。进一步分析了基于指令和基于代码的前沿基础模型的能力及其扩展上限。研究发现，基础模型在指令驱动的场景中更擅长推理，在基于代码执行的场景中则更具挑战性，但也更具有可扩展性和效率。", "conclusion": "PuzzlePlex为推理、规划和概括提供了专门的评估，并为指导未来改进基础模型提供了指导。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "在线两两比较生成评价标准", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Yunzhong He,Afra Feyza Akyürek", "background": " rubrics 提供了一种灵活的方法来训练 LLMs（大语言模型）生成开放式的长期回答，其中检验验证的奖励不适用且人类偏好提供粗略信号。以往的研究表明，使用基于 rubric 的奖励来进行强化学习可以带来 LLM 训练后的持续收益。大多数现有的方法依赖于在整个训练过程中保持不变的 rubrics，这种静态的 rubrics 脆弱性损失和不适应于训练过程中出现的新期望。", "innovation": "我们引入了 Online Rubrics Elicitation (OnlineRubrics)，这是一种通过当前和参考策略回应的两两比较，在线动态定制评估标准的方法。这种在线过程可以在训练过程中持续识别和化解错误。实验证明，这种方法在 AlpacaEval、GPQA、ArenaHard 以及专家问题和 rubric 验证集的训练中，相比仅使用静态 rubrics，收益提升可达 8% 以上。我们还对生成的评估标准进行了定性分析，识别出透明度、实用性、组织性和推理等主要主题。", "conclusion": "在线 Rubrics Elicitation 方法提供了一种有效的方式，可以随着训练过程的进行动态调整评估标准，从而持续改进大语言模型的性能，实现稳定且显著的提升。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07318", "html_url": "https://arxiv.org/abs/2510.07318", "title": "人工海马网络用于高效长上下文建模", "title_en": "Artificial Hippocampus Networks for Efficient Long-Context Modeling", "authors": "Yunhao Fang,Weihao Yu,Shu Zhong,Qinghao Ye,Xuehan Xiong,Lai Wei", "background": "长序列建模在递归神经网络（RNN）类模型中面临着压缩固定大小内存的效率与注意力基于Transformer模型中可变增长内存保真度之间的基本权衡。受认知科学中多存储区模型的启发，本文提出了一种人工神经网络的记忆框架。该方法将Transformer的KV缓存作为无损短时记忆，同时利用一种称为人工海马网络（AHN）的可学习模块，将不在窗口中的信息反复压缩进固定大小的紧凑长时记忆中。为了验证这一框架的有效性，使用现代RNN类架构实现了AHN，包括Mamba2、DeltaNet和门控DeltaNet。在长效文_ctx_以下基准LV-Eval和InfiniteBench上的实验表明，AHN增强的模型在计算和内存消耗方面显著减少，同时性能优于滑动窗口基线模型，甚至与全注意力模型相当或更优。例如，将AHN增强到Qwen2.5-3B-Instruct模型，在推理过程中将FLOPs减少了40.5%，内存缓存减少了74.0%，且在128k序列长度的LV-Eval基准上的平均分数从4.41提升到5.88。", "innovation": "本文提出了人工海马网络（AHN）的概念，并将其应用于长序列模型。该方法通过同时利用Transformer的KV缓存和一种新的可学习压缩模块（AHN），实现了高效且高质量的长序列建模。与传统的滑动窗口或全注意力模型相比，AHN增强的模型在计算效率和内存使用上均有显著提升，但性能表现更优或相当于全注意力模型。这种方法特别适用于需要处理长序列任务的应用场景。", "conclusion": "文章通过在多项基准测试中对比AHN增强模型与滑动窗口和全注意力模型的表现，证明了AHN方法的有效性和实用性。它显著减少了计算和内存开销，同时保持或提升了模型性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06605", "html_url": "https://arxiv.org/abs/2510.06605", "title": "通过零阶梯度估计实现可靠的黑盒大语言模型指纹识别：探究背后的细节", "title_en": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation", "authors": "Shuo Shao,Yiming Li,Hongwei Yao,Yifei Chen,Yuchen Yang,Zhan Qin", "background": "开发大型语言模型（LLMs）需要大量投资，使之成为有价值的知识产权。因此，如何对LLMs进行版权保护引起了广泛关注。LLM指纹识别作为一种关键技术应运而生，其目的是通过提取模型的内在、独特签名（“指纹”）并与源模型进行比较，来识别非法拷贝。然而，现有的黑盒指纹识别方法往往无法生成具有代表性的LLM指纹，这是由于这些方法依赖于模型输出，而模型输出通常会因非线性函数的使用而丢失关键信息关于模型的独特参数的内容。", "innovation": "本文首先利用费舍尔信息理论正式证明，模型输入的梯度比输出更具信息性，这对于指纹识别更为有利。基于此见解，本文提出零印迹（ZeroPrint）方法，该方法在黑盒设置中使用零阶估计来近似这些信息丰富的梯度。零印迹通过语义保留的单词替代来模拟输入扰动以应对离散文本的挑战，从而估计模型的雅可比矩阵作为一个独特的指纹。实验表明，零印迹取得了最先进的效果和稳定性，显著优于现有的黑盒方法。", "conclusion": "零印迹在大规模语言模型的黑盒指纹识别领域取得了前所未有的成果，该方法不仅解决了现有的指纹识别技术面临的挑战，还在实际应用中展现了卓越的准确性和鲁棒性，为LLMs的版权保护提供了新的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06706", "html_url": "https://arxiv.org/abs/2510.06706", "title": "XLSR-Kanformer: 一种集成KAN的合成语音检测模型", "title_en": "XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection", "authors": "Phuong Tuan Dat,Tran Huy Dat", "background": "近年来，语音合成技术的进步导致了更加复杂的欺骗攻击，这对自动说话人验证系统构成了重大挑战。尽管基于自监督学习（SSL）模型，尤其是XLSR-Conformer架构，在合成语音检测上表现出色，但在模型结构上仍然存在改进的空间。", "innovation": "本文提出了一种全新的方法，将传统的多层感知器（MLP）在XLSR-Conformer模型中替换为基于柯尔莫哥洛夫-阿诺尔德表示定理的强多功能逼近器Kolmogorov-Arnold Network（KAN）。实验结果表明，将KAN集成到XLSR-Conformer模型中，可以在EER LA和DF数据集上提高60.55%的性能，并在21LA数据集上实现0.70%的EER。此外，提出的替代方法也对各种自监督学习架构具有鲁棒性。", "conclusion": "研究结果表明，将KAN集成到基于SSL的模型中是合成语音检测技术发展的一个有前景的方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06557", "html_url": "https://arxiv.org/abs/2510.06557", "title": "马尔可夫思想者", "title_en": "The Markovian Thinker", "authors": "Milad Aghajohari,Kamran Chitsaz,Amirhossein Kazemnejad,Sarath Chandar,Alessandro Sordoni,Aaron Courville,Siva Reddy", "background": "强化学习（RL）已经成为训练生成长链条思考（LongCoT）的推理大模型（LLMs）的强大工具。然而，标准的RL思考环境将状态定义为提示加上所有先前推理的标记，这使得状态变得无界，要求基于注意的策略随着思考长度的增加付出二次计算成本。", "innovation": "本文提出了一种马尔可夫性思考（Markovian Thinking）的新范式，在其中策略可以在一个固定大小的状态下进行推理，从而将思考长度与上下文大小解耦。通过这种方式，计算成本变为线性，内存成本保持不变。研究者通过设计一个名为Delethink的RL环境来实现这一概念，该环境将推理结构化为固定大小的块。该模型在每个块内通常进行多步推理，但在块边界时重置上下文并在提示中加入短载体信息再次初始化。", "conclusion": "通过使用Delethink环境进行训练，具有1.5B参数的R1-Distill模型表现出与24K预算下的LongCoT-RL相当甚至更好的性能。Delethink的空间效率使得在计算容量相同的情况下，Delethink能够处理更长的思考链。研究进一步表明，预先训练的一些推理模型可以零样本地生成马尔可夫轨迹，这为大规模的RL有效提供了积极样本。研究结果表明，重新设计思考环境是一个强有力的杠杆，能使得无需二次费用即可实现非常长的推理，并开启了高效、可扩展的推理大模型的道路。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06719", "html_url": "https://arxiv.org/abs/2510.06719", "title": "差分隐私合成文本生成以增强检索增强生成 (RAG) 的隐私性", "title_en": "Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)", "authors": "Junki Mori,Kazuya Kakizaki,Taiki Miyagawa,Jun Sakuma", "background": "检索增强生成（RAG）通过将大型语言模型（LLM）与外部知识联系起来，提高了模型的表现。然而，RAG 在敏感领域的应用受到隐私风险的限制。现有的私密RAG方法大多依赖于查询时的差分隐私（DP），这需要反复加入噪声，导致累积隐私损失。", "innovation": "为了解决这一问题，我们提出了一种称为DP-SynRAG的框架，它利用大型语言模型生成不同类型的合成RAG数据库。不同于先前的方法，合成文本可以在创建后重复使用，从而避免了重复的噪声注入和额外的隐私成本。为了保持下游RAG任务所需的核心信息，DP-SynRAG 扩展了私密预测，让大型语言模型生成模拟采样数据库记录的文本，并以差分隐私方式生成文本。实验结果表明，DP-SynRAG 达到了最先进的私密RAG系统的表现，同时保持了固定的成本预算，为可扩展的隐私保护RAG提供了解决方案。", "conclusion": "DP-SynRAG 提供了一种高效的方法来保护RAG中的隐私，通过使用大型语言模型生成合成数据，避免频繁的噪声添加，同时保持固定的隐私预算，为敏感领域的应用提供了一个可扩展的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06231", "html_url": "https://arxiv.org/abs/2510.06231", "title": "CML-Bench: 一种评估和提升LLM驱动的电影剧本生成框架", "title_en": "CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation", "authors": "Mingzhe Zheng,Dingjie Song,Guanyu Zhou,Jun You,Jiahao Zhan,Xuran Ma,Xinyuan Song,Ser-Nam Lim,Qifeng Chen,Harry Yang", "background": "大型语言模型（LLMs）展示了生成高度结构化文本的出色能力，但在处理需要细腻叙事和情感深度的电影剧本时，往往未能捕捉到‘灵魂’般的深度，即引人入胜电影的情感核心。为探究这一问题，作者首先创建了一个CML-Dataset，包含电影标记语言（CML）的（摘要，内容）对，内容来自高质量的电影剧本，摘要则是对其内容的简洁描述。通过对这些真实剧本的内在多场景连续性和叙述结构进行深入分析，作者确定了三个关键评估维度：对话连贯性（DC）、角色一致性（CC）和情节合理性（PR）。基于这些发现，提出了CML-Bench，该框架综合了这些维度上的定量指标。CML-Bench能够为精心撰写的、由人类编写的剧本赋予高分，同时也能揭示由LLMs生成的剧本的弱点。为了进一步验证基准的有效性，作者还引入了一种新的提示策略CML-Instruction，提供了关于角色对话和事件逻辑的具体指导，以引导LLMs生成更具结构和电影感的剧本。广泛的实验验证了基准的有效性，并证明在CML-Instruction引导下生成的剧本质量更高，结果反映了人类的偏好。", "innovation": "1. 作者创建了CML-Dataset，这是一个包含电影剧本和其摘要的数据集，用于深入分析剧本的多场景连续性和叙述结构。\n2. 提出了CML-Bench，这是一种包含定量评估指标的框架，用于评估和提升LLM生成的电影剧本的质量。\n3. 引入了CML-Instruction，一种详细的提示策略，能够引导LLMs生成更结构化和符合电影标准的剧本，从而进一步验证了基准的有效性。", "conclusion": "实验结果表明，使用CML-Bench作为评估工具，指导的LLMs生成高质量电影剧本的能力得到了验证，且生成的剧本质量与人类偏好高度一致。这一研究不仅为评估和提升LLM生成的电影剧本质量提供了新的框架，也为机器生成创意内容的未来发展提供了参考。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06782", "html_url": "https://arxiv.org/abs/2510.06782", "title": "GPT-5 模型纠正了 GPT-4V 的图表阅读错误，而不是提示", "title_en": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting", "authors": "Kaichun Yang,Jian Chen", "background": "本研究旨在定量评估零样本大型语言模型（LLMs）和提示在图表阅读任务中的效果。研究借助GPT-5和多模态GPT-4V对107个可视化问题作出了回答，特别是在GPT-4V无法产生正确答案的情况下考察其对困难图像实例的应对能力。背景信息指出，该研究已经进行了预注册，并提供了详细的材料链接。", "innovation": "本研究创新之处在于定量评估了LLMs及其提示在图表阅读任务中的实际表现，尤其是通过对比GPT-5和GPT-4V在处理复杂视觉信息方面的差异，显示出模型架构相较于提示在影响准确率方面起到了更关键的作用。", "conclusion": "研究结果表明，模型架构对推理准确率的影响远大于提示策略，GPT-5明显改善了准确率，而不同提示策略仅产生了较小的影响。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06761", "html_url": "https://arxiv.org/abs/2510.06761", "title": "通过双环多智能体协作实现研究计划的演化与执行", "title_en": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration", "authors": "Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao", "background": "自动化从头到尾的科学研究流程是一项根本性的挑战，需要既生成新颖且合理的高阶计划，又能够在动态且不确定的条件下正确执行这些计划。本文探讨了双层挑战，并介绍了用于自动解决此问题的新颖的双环多智能体（DLMA）框架，该框架由教授循环和博士生循环组成，分别负责生成和执行研究计划，而这些计划是通过会议中的演化算法不断生成和优化的，确保了每一步操作的支持和有效性。实验表明，DLMA框架能生成达到最先进水平的研究论文，显著优于强大的基线模型。", "innovation": "提出了双环多智能体（DLMA）框架，通过教授循环和博士生循环协作，利用演化算法自动生成和优化研究计划，并确保执行的有效性。该框架通过迭代的生成和细化研究提案，能够动态调整计划以适应实施过程中的变化，从而在自动化评价中达到最先进的分数。", "conclusion": "双环多智能体框架（DLMA）有效地解决了自动化科学研究流程中的挑战，生成的研究论文不仅具有创新性，而且在多项基准测试中表现优异，表现显著优于现有的基线方法。研究表明，进化模块对于实现新颖性起着关键作用，而执行模块确保计划的正确实施，两者缺一不可。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06838", "html_url": "https://arxiv.org/abs/2510.06838", "title": "无标签跨域：术语提取的远程监督", "title_en": "Crossing Domains without Labels: Distant Supervision for Term Extraction", "authors": "Elena Senger,Yuri Campbell,Rob van der Goot,Barbara Plank", "background": "自动术语提取（ATE）在文档标签、领域本体构建和专利分析等下游NLP任务中扮演着关键角色。当前最先进的方法依赖昂贵的人工标注，并且在领域迁移时表现不佳，这限制了其实际应用。因此，需要更加稳健和可扩展的解决方案以及更加现实的评估环境来应对这一挑战。", "innovation": "本文提出了一种跨领域无标签的远程监督方法，通过利用黑盒大型语言模型生成伪标签来确保模型的一般性，并通过逐步精细化调整数据来提升模型性能。此外，作者还引入了轻量级后处理启发式方法来增强文档级一致性。该方法在七个不同领域中表现优于以往方法，尤其是在五个领域中取得了平均10个百分点的提升。", "conclusion": "本文提出了一个覆盖七个不同领域的全面基准，用于ATE的性能评估，并通过一种鲁棒的基于LLM的模型在这类基准上取得了出色的性能，该模型在文档和语料级别的性能评估中超过了之前的许多方法。作者还分享了他们的数据集和微调模型，以支持未来对该领域的研究。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06743", "html_url": "https://arxiv.org/abs/2510.06743", "title": "评估LLMs在历史文档OCR中的表现：面向数字人文的方法论框架", "title_en": "Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities", "authors": "Maria Levchenko", "background": "数字人文学者越来越多地使用大型语言模型进行历史文档的数字化，但缺乏对基于LLM的OCR的适当评估框架。传统评估指标无法捕捉到历史语料库创建所需的时间偏差和特定时期的错误。", "innovation": "本文提出了一种针对基于LLM的历史OCR的评估方法，解决了外交转录中的污染风险和系统性偏差问题。引入了新的评估指标——历史字符保真率（HCPR）和古语插入率（AIR），以及污染控制和稳定性测试的协议。评估了12种多模态LLM，发现Gemini和Qwen模型在传统OCR的基础上表现更好，但存在过度历史化的问题，即插入了不正确历史时期的古语字符。OCR后修正反而降低了性能。", "conclusion": "本文的方法为数字人文从业者提供了在历史语料库数字化过程中选择和评估模型的指南。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06953", "html_url": "https://arxiv.org/abs/2510.06953", "title": "在大语言模型推理跟踪中重新审视均匀信息密度假设", "title_en": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces", "authors": "Minju Gwak,Guijin Son,Jaehyung Kim", "background": "均匀信息密度（UID）假说提出，有效的通信应维持信息流的稳定。本文作者在大语言模型（LLM）推理历程的背景下重新审视这一原则，探讨步骤层面的均匀性是否反映推理质量。作者提出了一个基于熵的步骤信息密度度量方法，并引入了局部和全局均匀性评分，以衡量推理的均匀性。", "innovation": "本文提出了一种基于熵的步骤信息密度度量方法，并引入了局部和全局均匀性评分作为度量推理均匀性的指标。作者通过六个不同的推理基准实验，发现步骤层面的均匀性不仅提供了强大的理论视角，也带来了实际的性能优势；选择步骤层面信息密度更均匀的推理轨迹，相对于基准，在AIME2025上可以显著提高10-32%的准确率。进一步的分析表明，正确的推理轨迹倾向于避免信息密度突变，而错误的轨迹显示出不规则的信息爆发。这些结果表明，基于UID的信息密度度量比替代内部信号更能预测推理质量。", "conclusion": "结果表明，信息密度的均匀性作为构建更可靠和精确的推理系统的诊断和选择标准是稳健的。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06975", "html_url": "https://arxiv.org/abs/2510.06975", "title": "VelLMes：一种高交互的人工智能欺骗框架", "title_en": "VelLMes: A high-interaction AI-based deception framework", "authors": "Muris Sladić(1),Veronica Valeros(1),Carlos Catania(2),Sebastian Garcia(1) ((1) Czech Technical University in Prague, (2) CONICET, UNCuyo)", "background": "当前基于大型语言模型（LLM）的最新欺骗系统相对较少，现有的系统大多只能模拟一种服务类型，主要是SSH外壳。现有的系统以及其他不基于LLM的欺骗技术缺乏覆盖人类攻击者的广泛评估。由于生成式AI的兴起，研究人员已经证明了LLM在创建逼真的蜜罐令牌、仿冒用户和模拟系统以用作蜜罐方面的潜力。本文旨在介绍一种基于AI的欺骗框架VelLMes，它可以模拟多种协议和服务，如SSH Linux外壳、MySQL、POP3和HTTP，并且设计用于人类攻击，因此交互性和现实性是其关键性能指标。", "innovation": "VelLMes框架可以模拟多种协议和服务（SSH Linux外壳、MySQL、POP3和HTTP），并且能够用作蜜罐。它还通过精心设计的提示使LLM能够生成逼真的响应，部分LLM的通过率为100%。在对89个实际人类攻击者进行了评估实验后，大约30%的攻击者误以为他们正在与真实的系统交互。此外，将10个SSH Linux外壳蜜罐实例部署到互联网上，以捕获真实的网络攻击，表明LLM模拟的Linux外壳蜜罐在应对网络上的非结构化和不可预见的攻击时表现出色。", "conclusion": "综上所述，VelLMes框架通过模拟多种协议和服务提供了一种多样化的欺骗设计选项，以满足用户需求。通过广泛的评估，展示了其生成能力和欺骗能力的优良表现。特别地，展示了LLM模拟的蜜罐能够有效地应对实际的网络攻击。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06994", "html_url": "https://arxiv.org/abs/2510.06994", "title": "RedTWIZ: 通过适应性攻击规划实现多变的大语言模型红队测试", "title_en": "RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning", "authors": "Artur Horal,Daniel Pina,Henrique Paz,Iago Paulo,João Soares,Rafael Ferreira,Diogo Tavares,Diogo Glória-Silva,João Magalhães,David Semedo", "background": "本文介绍了一个用于评估人工智能辅助软件开发中的大型语言模型（LLMs）鲁棒性的适应性强且多样化的多回合红队框架——RedTWIZ。该工作聚焦于三大主要研究流：1.鲁棒且系统化的LLM对话越界评估；2.一个生成多样化的多回合攻击套件，支持组合、现实和目标导向的越界对话策略；3.一个分层次的攻击计划器，可以根据特定LLM的漏洞进行自适应计划、序列化和触发攻击。这些贡献共同形成了一个统一的框架，结合了评估、攻击生成和战略规划，以全面评估和暴露LLMs在鲁棒性方面的弱点。广泛的实验证明了该多回合对抗攻击策略的成功，并揭示了需要进一步研究以增强LLM的鲁棒性的重要性。", "innovation": "1. 提出了RedTWIZ框架，集成了评估、攻击生成和战略规划，形成了一个全面的框架来评估LLMs的鲁棒性。\n2. 构建了一个多回合多生成式攻击套件，支持多样化的、现实和目标导向的越界对话策略。\n3. 引入了分层次的攻击计划器，能够自适应地根据特定LLM的漏洞规划和触发攻击。", "conclusion": "通过RedTWIZ框架，可以全面评估和暴露大型语言模型在鲁棒性方面的弱点，并展示了多回合对抗攻击策略的有效性，进一步突显了研究提升LLM鲁棒性的紧迫性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07147", "html_url": "https://arxiv.org/abs/2510.07147", "title": "基于多智能体的具有状态的推理时搜索框架", "title_en": "A Multi-Agent Framework for Stateful Inference-Time Search", "authors": "Arshika Lalan,Rajat Ghosh,Aditya Kolsur,Debojyoti Dutta", "background": "近期工作探索了代理推理时的技术，以执行结构化的多步推理。然而，无状态的推理在处理多步任务时经常遇到困难，因为缺乏持续状态。此外，特定任务的微调或指令调优往往只能实现表面的代码生成，在需要深入推理和长期依赖的任务上表现脆弱。", "innovation": "提出了一种训练无框架的具有状态的多智能体进化搜索，该框架通过结合（i）持久的推理时状态，（ii）对抗性突变，和（iii）进化保存，从而从先前的无状态方法中脱颖而出。通过自动化单元测试生成中的边缘情况生成，证明了其有效性。该方法利用进化搜索过程中的专业化智能体依次提出、突变和评分候选方案，控制器在整个过程中保持状态，进化保存确保了多样性并探索所有可能的情况。这产生了一个多功能智能体，能够发现针对未知代码库的强大、高覆盖率的边缘情况。实验表明，该具有状态的多智能体推理框架在覆盖方面显著优于无状态单步骤基线，评估了流行的单元测试基准，如HumanEval和TestGenEvalMini，并使用了三种不同的大型语言模型家族（Llama、Gemma和GPT）。", "conclusion": "将持续的推理时状态与进化搜索相结合，显着改善了单元测试生成。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06823", "html_url": "https://arxiv.org/abs/2510.06823", "title": "揭示生成式引擎中的引文漏洞", "title_en": "Exposing Citation Vulnerabilities in Generative Engines", "authors": "Riku Mochizuki,Shusuke Komatsu,Souta Noguchi,Kazuto Ataka", "background": "研究指出了生成式引擎（GEs）在从网络抓取信息以生成答案时的脆弱性，尤其在对抗网络污染攻击方面存在不足。现有的引文评估研究侧重于评估答案内容与引用来源的一致性，但忽略了如何选择作为引用来源的网络信息以防御网络污染攻击。本文旨在填补这一空白，通过分析回答中的引文信息来评估网络污染威胁，由此揭示当前GEs中网络污染攻击的威胁程度。实验在政治领域中进行了验证，特别是在美国和日本，表明美国政治信息中的官方源引用比例较低，意味着美国的政治答案更易遭受网络污染攻击。研究还发现，风险较高的网络源经常被引用，但其内容却没有充分反映在答案中。", "innovation": "本文提出了评价网络污染威胁的新标准，这些标准通过分析答案中的引文信息来评估内容注入障碍，揭示了当前生成式引擎中网络污染攻击的威胁程度。通过这种方式，研究确定了主要信息源在网络污染威胁中的暴露情况，并指出著名的缓解措施在语言差异方面受到限制。", "conclusion": "通过我们在政治领域中的实验，发现美国的政治信息源从官方网站的引用比例偏低，这表明美国的政治答案更易受到网络污染攻击。同时发现，风险较高的信息源虽然经常被引用，但其内容在答案中却未得到充分反映。为了缓解这一威胁，研究探讨了主要信息源如何增加其网络内容在答案中的曝光率，但同时也指出这种方法受到语言差异的限制。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.04481", "html_url": "https://arxiv.org/abs/2403.04481", "title": "ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent", "title_en": "ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent", "authors": "Shangjian Yin,Peijie Huang,Jiatian Chen,Haojing Huang,Yuhong Xu", "background": "大型语言模型（LLMs）在语言生成和一般任务性能方面展现了出色的潜力，但在将其应用于口语理解（SLU）方面仍面临挑战，尤其是在标记级任务中，其自回归的性质往往导致对齐问题。此外，直接微调语言模型在捕捉语义级任务中的细微关系方面表现不佳。这些挑战促使研究人员提出了新的方法来改进语言模型在SLU任务中的应用效果。", "innovation": "本文提出了Entity-level Language Model (ECLM)框架，通过将槽填充任务重新表述为实体识别任务，并引入了一种新的概念“意图链条”来实现逐步多意图识别。实验结果表明，ECLM在MixATIS和MixSNIPS数据集上的表现显著优于当前的基线模型，尤其是在标准监督微调的基础上进一步提高了这些数据集的性能。", "conclusion": "ECLM框架在口语理解任务上取得了显著的性能提升，尤其是在MixATIS和MixSNIPS数据集上分别实现了8.5%和21.2%的改进。这表明ECLM能够有效解决经典自回归语言模型在标记级和语义级任务中的对齐问题，对于复杂任务的理解具有更好的效果。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07091", "html_url": "https://arxiv.org/abs/2510.07091", "title": "认知带宽瓶颈：从基于动作规划向基于模式规划转变延长视距智能体", "title_en": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas", "authors": "Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song", "background": "在开放世界的自主控制中，使大型语言模型（LLMs）有效执行长时间跨度的任务，要求进行长期规划和多次互动，是至关重要的。传统的规划方法依赖于执行动作列表作为参考，但在环境操作空间是组合爆炸式扩展（例如，开放世界的现实世界场景）的情况下，这种动作表示方式变得不切实际。因此，提出了一个自然的问题：随着环境操作空间的扩大，长期智能体的最佳动作表示是什么？该论文系统地研究了两种不同动作表示的有效性：一种是传统的基于动作的规划（PwA），另一种是基于模式的规划（PwS），通过实例化动作模式为动作列表（例如，“移动[OBJ]到[OBJ]”->“移动苹果到桌子”）来确保简洁的动作空间和可靠的可扩展性。这两种方法分别根据其在人类认知的契合度和对环境操作格式限制的遵守性受到启发。通过认知带宽视角，提出了一个概念框架来定性理解这些两种动作表示之间的差异，并实验证实了这两者之间的表现转折点出现在ALFWorld（约35个动作）和SciWorld（约500个动作）之间，证明了可扩展表示的必要性。", "innovation": "提出了认知带宽视角作为概念框架来理解基于动作规划和基于模式规划之间的差异，并通过实验证明了两者之间的表现转折点出现在不同环境规模下，进一步探讨了该转折点与不同模型能力之间的交互作用，提供了如何构建更有效的基于模式规划的智能体的实操指南，以增强其可扩展性。", "conclusion": "研究找到了基于动作规划在某些环境下的表现不佳，提供了一个基于模式规划的智能体构建指南，以提升其在更大规模环境中的性能，从而实现更好的扩展自主性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.01103", "html_url": "https://arxiv.org/abs/2410.01103", "title": "大约对齐解码", "title_en": "Approximately Aligned Decoding", "authors": "Daniel Melcer,Sujan Gonugondla,Pramuditha Perera,Haifeng Qian,Wen-Hao Chiang,Yanjun Wang,Nihal Jain,Pranav Garg,Xiaofei Ma,Anoop Deoras", "background": "目前，当想要拒绝大型语言模型（LLMs）中的不 desired 输出时，通常需要大量的重采样计算，或者通过约束到极其不可能的输出令牌来扭曲输出分布，这两种方法都有各自的局限性。", "innovation": "本文提出了一种方法，即大约对齐解码（AprAD），该方法能够在减少计算量的同时，有效地平衡输出分布的扭曲与计算效率，从而使得在生成具有难以满足约束条件的长文本序列时，输出低概率令牌的放大程度远低于现有方法。", "conclusion": "实验表明，对于特定任务的性能，AprAD 方法与不扭曲输出分布的方法相当，同时在计算效率方面表现出明显的优势。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07293", "html_url": "https://arxiv.org/abs/2510.07293", "title": "AudioMarathon：Long-Context 音频理解与音频LLM效率的全面基准", "title_en": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs", "authors": "Peize He,Zichen Wen,Yubo Wang,Yuxuan Wang,Xiaoqian Liu,Jiajie Huang,Zehui Lei,Zhuangcheng Gu,Xiangqi Jin,Jiabing Yang,Kai Li,Zhifei Liu,Weijia Li,Cunxiang Wang,Conghui He,Linfeng Zhang", "background": "大型音频语言模型处理长音频是具有挑战性的，主要因为注意力成本的平方复杂度 ($O(N^2)$) 和长范围时间依赖性的建模困难。现有的音频基准多由短剪辑构建，未测试模型在现实长上下文环境中的表现。为解决这一问题，我们提出了AudioMarathon，一个旨在评估长音频上理解和推理效率的基准。AudioMarathon通过提供涵盖从90.0秒到300.0秒 duration 的长音频输入，以及复杂的多跳推理任务，来填补这一空白。", "innovation": "我们提出了AudioMarathon，一个专为大型音频语言模型设计、用于评估长音频理解和推理效率的基准。AudioMarathon涵盖了从90.0秒到300.0秒不等的长音频输入，支持从2,250到7,500个音频令牌的不同时间范围内进行推理。它还涵盖全领域覆盖（语音、声音、音乐）和需要多跳推理的复杂推理任务。我们评估了最先进的音频语言模型并发现随着音频长度的增长出现了性能下降的现象，并研究了加速技术，分析了token精简和KV缓存淘汰的权衡。结果表明当前的大型音频语言模型之间存在显著的性能差距，这突显了更有效的时序推理和内存高效架构的需求。", "conclusion": "我们的研究表明，当前大型音频语言模型在长音频处理中存在巨大差距，强调了开发更好的时序推理能力和内存高效架构的重要性。我们相信AudioMarathon将推动音频和多模态研究社区开发更高级的音频理解模型，以解决复杂的音频任务。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.04975", "html_url": "https://arxiv.org/abs/2411.04975", "title": "SuffixDecoding: 极端推测解码以应对新兴AI应用", "title_en": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications", "authors": "Gabriele Oliaro,Zhihao Jia,Daniel Campos,Aurick Qiao", "background": "投机解码在大型语言模型（LLM）推理中广泛使用，目的是通过利用较小的草稿模型来降低延迟。然而，新兴的AI应用，如基于LLM的代理框架，具有独特的负载特征：它们通常提交重复的推理请求，比如多个代理管道执行相似的子任务或自反馈循环以逐步提升输出。这些工作负载会产生长且高度可预测的序列，当前的推测解码方法并不能很好地利用这些机会。", "innovation": "我们介绍了一种名为SuffixDecoding的新方法，它使用有效的后缀树来缓存提示和先前输出中的长令牌序列。当接受度概率高时，SuffixDecoding会推测更多的令牌，而在接受度低时推测较少的令牌。这种方法有效地利用了推测解码的机会，同时在计算有限时节省了计算资源。在代理基准测试，包括SWE-Bench和Text-to-SQL中，SuffixDecoding实现了高达5.3倍的速度提升，优于最先进的方法——比基于模型的方法快2.8倍，比无模型方法快1.9倍。", "conclusion": "此外，该方法已经开源。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.05468", "html_url": "https://arxiv.org/abs/2501.05468", "title": "LatteReview: 一个使用大规模语言模型进行系统性审查自动化的工作流框架", "title_en": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "authors": "Pouria Rouzrokh,Bardia Khosravi,Parsa Rouzrokh,Moein Shariatnia", "background": "系统文献综述和元分析对于综合研究洞察至关重要，但由于筛选、评估和数据提取等迭代过程的时间密集性和劳动密集性，它们仍然很耗时。", "innovation": "本文介绍并评估了基于Python的大规模语言模型（LLMs）和多代理系统的LatteReview框架，以自动化系统审查过程的关键部分。该框架通过使用模块化代理来简化工作流，同时保持严谨性，支持包括标题和摘要筛选、相关性评分和结构化数据提取在内的任务。代理在协调的工作流中运行，支持顺序和并行审查轮次、动态决策和基于用户反馈的迭代改善。", "conclusion": "LatteReview框架集成了LLM提供商，支持云端和本地模型，并且具有检索增强生成（RAG）、多模态审查、Pydantic验证以及异步编程等特性，处理大规模数据集。该框架已在GitHub上发布，配有详细文档和可安装包。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.00656", "html_url": "https://arxiv.org/abs/2501.00656", "title": "OLMo 2 Furious", "title_en": "2 OLMo 2 Furious", "authors": "Team OLMo,Pete Walsh,Luca Soldaini,Dirk Groeneveld,Kyle Lo,Shane Arora,Akshita Bhagia,Yuling Gu,Shengyi Huang,Matt Jordan,Nathan Lambert,Dustin Schwenk,Oyvind Tafjord,Taira Anderson,David Atkinson,Faeze Brahman,Christopher Clark,Pradeep Dasigi,Nouha Dziri,Allyson Ettinger,Michal Guerquin,David Heineman,Hamish Ivison,Pang Wei Koh,Jiacheng Liu,Saumya Malik,William Merrill,Lester James V. Miranda,Jacob Morrison,Tyler Murray,Crystal Nam,Jake Poznanski,Valentina Pyatkin,Aman Rangapur,Michael Schmitz,Sam Skjonsberg,David Wadden,Christopher Wilhelm,Michael Wilson,Luke Zettlemoyer,Ali Farhadi,Noah A. Smith,Hannaneh Hajishirzi", "background": "本文介绍了下一代完全开源的语言模型 OLMo 2。OLMo 2 包含 7B、13B 和 32B 规模的密集自回归语言模型，并提供了模型权重、完整训练数据、训练代码和食谱、训练日志以及数千个中间检查点等完全发布的产物。文章还提到了先前工作的背景，如之前的 OLMo 模型以及 Tülu 3 工作中的一些最佳做法。", "innovation": "本研究的主要创新包括：1) 修改了模型架构和训练食谱，特别强调了实现更好的训练稳定性和提高每词效率的技术；2) 引入了全新的 Dolmino Mix 1124 数据混合，通过晚期课程训练显著提高了模型在多个下游任务基准上的能力；3) 结合了 Tülu 3 的最佳实践，开发了 OLMo 2-Instruct，重点是扩展最终阶段的增强学习并引入可验证奖励（RLVR）。", "conclusion": "OLMo 2 基模型位于性能与训练计算之间的帕累托前沿，通常会匹配或超越使用较少 FLOPs 并且训练数据、代码和食谱完全透明的开放权重模型（如 Llama 3.1、Qwen 2.5 和 Gemma 2）。此外，完全开源的 OLMo 2-Instruct 模型竞争力与开放权重模型相当，甚至优于某些专有模型（如 GPT-3.5 Turbo 和 GPT 4o Mini）。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07226", "html_url": "https://arxiv.org/abs/2510.07226", "title": "在人群中机器？测量Reddit上机器生成文本的足迹", "title_en": "Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit", "authors": "Lucio La Cava,Luca Maria Aiello,Andrea Tagarelli", "background": "生成式人工智能正在通过低成本、大规模生产机器生成文本（MGT）来改造在线交流。尽管MGT在全球网络上的存在正在迅速增长，但其在社交媒体环境中的融合程度尚不清楚。这篇论文首次对Reddit上的MGT进行了大规模特性分析，使用先进的统计方法检测MGT，分析了2022年至2024年间51个具有代表性的子版块，涵盖信息寻求、社会支持、讨论等主要社区类型。研究发现MGT在某些社区在某些月份峰值可达9%，并且MGT在这些社区中的分布是不均衡的，更常见于技术知识和社交支持相关子版块，主要由一小部分用户产生。MGT还传达了温暖和地位赋予等典型的人工智能助手语言特征，虽然具有不同的语风特征，MGT的互动水平与人类撰写的文本相当甚至更高，表明人工智能生成的文本逐渐融入在线社会对话。这项工作为平台治理、检测策略和社区动态研究提供了新的视角，", "innovation": "这篇论文首次进行了大规模分析Reddit上的机器生成文本（MGT），使用先进的统计方法进行检测，并研究了MGT在不同社区中的分布、典型的社会信号及其与人类创作品的互动水平，提供了新的研究视角和对治理、检测策略的探索。", "conclusion": "研究表明，MGT在Reddit上的存在是微不足道的，但在某些社区和月份可以达到9%的峰值。MGT在技术知识和社交支持相关社区中更为普遍，主要由一小部分用户产生。MGT传达的是人工智能助手式的语言特征，但在互动效果上与人类创作内容相当甚至更高，表明MGT已成为在线社交讨论有机组成部分。这项工作为检测策略和社区动态研究开辟了新方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.08127", "html_url": "https://arxiv.org/abs/2412.08127", "title": "伪截获并不是那么邪恶：机器生成提示的定性见解", "title_en": "Evil twins are not that evil: Qualitative insights into machine-generated prompts", "authors": "Nathanaël Carraz Rakotonirina,Corentin Kervadec,Francesca Franzon,Marco Baroni", "background": "已有研究观察到语言模型（LMs）对看似无法理解的算法生成提示做出了可预测的响应。这表明我们对LMs的工作机制理解不完整，同时也提出了一种实际挑战，因为这种不透明性可以被利用来有害地使用LMs，比如解锁（jailbreaking）。这项研究是首次全面分析机器生成的提示（autoprompts），涉及六个不同规模和家族的LMs。研究发现机器生成的提示往往具有一个可理解的最后一词，并且会显著影响生成结果。在先前的词中有一定比例的词是可以被删除的，这可能是优化过程固定token数量导致的副产物。剩下的词可以分为两类：填充词（可以被不相关的词替换）和关键词（与生成结果有一定的语义关联但不具备良好的句法关系）。此外，专家可以通过事后识别最有影响力的关键词表明这些提示并非完全不透明。最后，通过删除自动提示的部分内容所进行的实验也显示出自然语言输入中相似的效果，表明自动提示自然地从LMs处理语言输入的方式产生。", "innovation": "首次全面分析不同规模和家族的6个语言模型的机器生成提示（autoprompts），揭示了它们的性质，并通过删除实验探索了其与自然语言输入的关系。", "conclusion": "机器生成的提示并非完全不透明，可以通过专家识别最具有影响力的单词来部分解析。通过实验发现，这些提示与自然语言输入的处理方式有天然联系，表明它们不是完全不符合语法与语义预期的混淆不透明输入。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.19017", "html_url": "https://arxiv.org/abs/2501.19017", "title": "Multimodal Large Language Models负向引导攻击基准测评", "title_en": "Benchmarking Gaslighting Negation Attacks Against Multimodal Large Language Models", "authors": "Bin Zhu,Yinxuan Gui,Huiyan Qi,Jingjing Chen,Chong-Wah Ngo,Ee-Peng Lim", "background": "多模态大语言模型（MLLMs）在融合不同模态方面取得了显著进步，特别是在复杂理解和生成任务上表现突出。尽管取得了这些成就，MLLMs仍然容易受到交流对抗输入的影响。本文系统研究了负向引导（Gaslighting）反向推理攻击，即模型虽然最初给出正确答案，但在用户提供的否定性言论下，被说服改变其输出，甚至自造理由。通过对各种基准进行广泛评估，我们观察到在引入否定性言论后，最先进的MLLMs表现显著下降。首次开发了专门用于评估MLLMs对否定论证敏感性的基准GaslightingBench，该基准包含来自现有数据集的多项选择题及20个不同类别生成的否定性提示。", "innovation": "首次提出了用于评估MLLMs对否定性论证敏感性的基准GaslightingBench，该基准包含多项选择题及20个不同类别的生成否定性提示。研究发现，与开源模型相比，专有模型如Gemini-1.5-flash和GPT-4o显示了更好的韧性。然而，即使是高度推理导向的模型Gemini-2.5-Pro也仍然脆弱。", "conclusion": "所有评估的MLLMs在面对负向引导攻击时都无法保持逻辑一致性。这些发现突显了其基础安全漏洞，为开发更可靠和可信赖的多模态AI系统提供了启示。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19732", "html_url": "https://arxiv.org/abs/2502.19732", "title": "投机性解码与超越：技术深入综述", "title_en": "Speculative Decoding and Beyond: An In-Depth Survey of Techniques", "authors": "Yunhai Hu,Zining Liu,Zhenyuan Dong,Tianfan Peng,Bradley McDanel,Sai Qian Zhang", "background": "在实时应用中，大规模自回归模型受顺序依赖瓶颈制约。传统优化方法如剪枝和量化往往牺牲模型质量，而最近的生成-精炼框架的进步则显示这种权衡可以显著缓解。本文综述了生成-精炼框架，分析了自回归序列任务的方法，并依据生成策略和精炼机制进行了分类。文章通过系统分析算法和系统层面的实现，探讨了不同计算环境下的部署策略，并探究了文本、图像和语音生成等应用领域。", "innovation": "本文提出了一个生成-精炼框架的全面分类，并系统分析了算法和系统层面的实现，探索了在不同计算环境下的部署策略。这种方法能够显著改善自回归模型实时应用中的表现，减少传统优化策略中的质量损失问题，并展示了最新的趋势和进展。", "conclusion": "通过全面分析自回归解码的基本理论框架和实践实现，本文为未来高效自回归解码研究奠定了基础，并指出了在不同应用领域的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16600", "html_url": "https://arxiv.org/abs/2502.16600", "title": "语言模型中道德推理获取的诊断：语用与泛化", "title_en": "Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics and Generalization", "authors": "Guangliang Liu,Zimo Qi,Xitong Zhang,Lei Jiang,Kristen Marie Johnson", "background": "大型语言模型（LLMs）在回答涉及道德意识的任务时常常表现不佳，为了使它们更广泛地应用于社会中，确保它们的回答符合社会价值观是至关重要的。现有研究已经证明，目前的改进方法主要依赖于使用精选数据集对LLMs进行微调来提升它们在道德相关任务上的能力，但如何选择最佳的学习范式来加强其道德反应仍是一个开放的研究争议。我们的研究背景在于探讨当前的学习范式是否能够使LLMs获得足够的道德推理能力，以及现有范式在道德推理方面存在的局限性问题，特别是在捉摸不定的道德语境内达到了语用与泛化的限制，这是我们称之为语用困境的现象。", "innovation": "我们从分布语义理论和道德话语的实用性质出发，分析得出性能改进遵循类似语义层面任务的机制，受制于道德评论中的语用内涵，这一现象我们称之为‘语用困境’。该研究强调，语用困境对当前学习范式的泛化能力造成了显著限制，并成为LLMs道德推理获取的主要瓶颈。", "conclusion": "当前学习范式在道德推理获取方面存在显著的泛化限制问题，也是实现道德推理获取的关键瓶颈所在。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03654", "html_url": "https://arxiv.org/abs/2503.03654", "title": "使用数据和参数高效 RL 提高中立观点生成", "title_en": "Improving Neutral Point-of-View Generation with Data- and Parameter-Efficient RL", "authors": "Jessica Hoffmann,Christiane Ahlheim,Zac Yu,Aria Walfrand,Jarvis Jin,Marie Tano,Ahmad Beirami,Erin van Liemt,Nithum Thain,Hakim Sidahmed,Lucas Dixon", "background": "研究表明，参数效率强化学习（PE-RL）能够在大型语言模型（LLMs）上有效提升其以中立视角（NPOV）回答敏感主题查询的能力，即能提供更丰富、多样化且公正的信息。", "innovation": "这项研究通过对比分析 PE-RL 和多个强基线（如 LoRA 微调、SFT 和 RLHF），展示了 PE-RL 在整体 NPOV 质量和特定语言学家认为区分充分回答与“极好”回答的关键特征方面均显著优于现有最佳基线。此外，PE-RL 还具有在主题之外泛化的关键特性。", "conclusion": "研究发现，尽管更新所有参数的方法能够提升整体质量，但 PE-RL 能够泛化到相关领域之外。为此，研究人员还推出了一个新的数据集 SHQ-NPOV 和一种通过多轮人类同伴批评和注释员培训生成类似数据集的方法，以促进进一步研究。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04152", "html_url": "https://arxiv.org/abs/2504.04152", "title": "重新思考多语言连续预训练：数据混合以跨语言和资源适应LLMs", "title_en": "Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources", "authors": "Zihao Li,Shaoxiong Ji,Hengyu Luo,Jörg Tiedemann", "background": "现有的大型语言模型（LLMs）在不同语言上的性能存在显著差异，主要受益于资源丰富的语言，而边缘化了非主流语言。为解决这一不平衡问题，连续预训练（CPT）被认为是有效的策略之一。然而，单语言、双语言以及代码扩充等数据策略的有效性仍然不明确。本研究系统地评估了30多种语言的36种CPT配置，得出了一些重要发现：", "innovation": "研究发现双语言CPT可以改善多语言分类，但生成过程中可能会出现语言混杂问题；包含编程代码数据的CPT可以提高低资源语言的多语言分类准确性，但会稍微降低生成质量；与以往研究不同，研究发现语言分类对其跨语言迁移影响存在显著差异，非主流语言对相关语言产生负面影响，自私语言的行为依赖于情况和配置条件，停滞语言在某些CPT条件下表现出出乎意料的适应性。这些细微的相互作用突显了多语言表示学习的复杂性，强调了系统研究可推广的语言分类对指导未来多语言CPT策略的重要性。", "conclusion": "因此，这些研究结果强调了需要进一步系统研究以更好地理解多语言表示学习及其影响，从而为未来的多语言CPT策略提供指导。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04155", "html_url": "https://arxiv.org/abs/2504.04155", "title": "GlotEval: 一种大规模多语言评估测试套件", "title_en": "GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models", "authors": "Hengyu Luo,Zihao Li,Joseph Attieh,Sawal Devkota,Ona de Gibert,Xu Huang,Shaoxiong Ji,Peiqin Lin,Bhavani Sai Praneeth Varma Mantina,Ananda Sreenidhi,Raúl Vázquez,Mengjie Wang,Samea Yusofi,Fei Yuan,Jörg Tiedemann", "background": "全球范围内，大型语言模型（LLMs）的发展速度日益加快，地区也开始越来越多地将其应用于并将其语言中。然而，对这些模型在各种语言环境中的评估，特别是对低资源语言来说，已经成为学术界和业界的主要挑战。现有的评估框架主要集中在英语和少数高资源语言上，从而忽视了LLMs在多语言和低资源场景中的实际表现。", "innovation": "为了弥补这一差距，我们引入了GlotEval，一种专为大规模多语言评估而设计的轻量级框架。它支持七项关键任务（机器翻译、文本分类、摘要、开放生成、阅读理解、序列标注和内在评估），涵盖数十到数百种语言。GlotEval强调一致的多语言基准测试、语言特定的提示模板以及以非英语为中心的机器翻译。这使得模型在各种语言背景下的强项和弱点能够得到精确诊断。一个语言翻译案例研究表明，GlotEval适用于多语言和语言特定的评估。", "conclusion": "GlotEval通过提供一种多样化的多语言评价工具，能够准确诊断模型在各种语言环境中的表现。这有助于更好地理解大型语言模型在实际应用中的能力和局限性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.08348", "html_url": "https://arxiv.org/abs/2505.08348", "title": "Next-Token Prediction中语义几何学：优化如何隐式组织语言表示", "title_en": "Geometry of Semantics in Next-Token Prediction: How Optimization Implicitly Organizes Linguistic Representations", "authors": "Yize Zhao,Christos Thrampoulidis", "background": "该研究关注的是下一词预测(NTP)优化如何引导语言模型从文本中抽取并组织语义结构。通过基于数学模型和精心设计的合成数据，研究揭示了NTP隐式引导模型通过奇异值分解(SVD)分解以编码上下文到下一个词共现模式中心支持矩阵的工作机制。虽然模型从未显式构造此矩阵，但所学习的词和上下文嵌入最终收敛于其SVD因子，奇异向量通过其符号模式编码了潜在的语义概念。", "innovation": "研究通过SVD方法揭示了NTP优化隐式引导模型如何分解上下文到下一个词的共现模式，并提出了一种基于象限的聚类方法，该方法结合概念符号以识别可解释的语义类别。该方法在合成数据集和预训练语言模型上得到了验证，恢复了各种语义结构，如语法类别、命名实体类型和主题区分（医学、娱乐）。这项工作将经典分布语义学与神经坍塌几何学联系起来，描述了基于梯度优化如何隐式决定编码语义结构的矩阵表示及其分解方法。", "conclusion": "研究发现在训练过程中与较大奇异值相对应的概念会先被学习到，从而导致天然的语义层次结构，其中广泛的类别先出现，再出现精细的类别。这一洞察揭示了经典分布语义学与神经坍塌几何学之间的联系，表明优化过程如何隐式决定语言模型如何编码语义结构。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15561", "html_url": "https://arxiv.org/abs/2505.15561", "title": "RAG系统真的会受到位置偏差的影响吗?", "title_en": "Do RAG Systems Really Suffer From Positional Bias?", "authors": "Florin Cuconasu,Simone Filice,Guy Horowitz,Yoelle Maarek,Fabrizio Silvestri", "background": "检索增强生成（RAG）技术通过将外部语料库中检索到的相关片段添加到LLM提示中，以增强LLM的准确性。先前的研究表明，位置偏差是LLM的一个重要特性，指LLM在处理提示时对信息的权重会根据其在提示中的位置有所不同。这项研究探讨了位置偏差如何不仅影响LLM利用相关片段的能力，还会使其更容易受到干扰片段的影响。", "innovation": "本研究通过在三个基准上进行广泛的实验，揭示了最先进的检索管道尽管试图检索相关片段，但系统地将高度干扰性的片段排在前列，超过60%的查询中在最高检索的前10个片段中有至少一个是高度干扰性的。因此，尽管相关工作在受控环境中常报告LLM位置偏差非常显眼，但在现实场景中，由于相关和干扰片段都会被惩罚，这种偏差的影响实际上很有限。研究表明，试图根据LLM的位置偏好重新排列片段的复杂策略并不能比随机打乱表现更好。", "conclusion": "本研究揭示了RAG系统可能并没有普遍表现出位置偏差问题，即最先进的检索管道带来的高度干扰性片段在实际应用中并不会显著影响系统的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02016", "html_url": "https://arxiv.org/abs/2503.02016", "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs", "title_en": "Mind the (Belief) Gap: Group Identity in the World of LLMs", "authors": "Angana Borah,Marwa Houalla,Rada Mihalcea", "background": "社会偏见和信念驱动的行为显著影响大型语言模型（LLMs）在多个任务中的决策。随着LLMs在多智能体系统中的广泛应用，特别是用于社会模拟时，它们模型基本群体心理特征的能力仍然是至关重要的但尚未充分研究。本研究探讨了信念一致性对社会互动和偏好形成的关键作用，并展示了LLMs在不同情境下表现出比人类更强的信念一致性。研究进一步探讨了这一行为对未来两个下游任务的影响，发现LLMs中的信念一致性增加了错误信息的传播并阻碍了学习能力。为了减轻这些负面影响，提出了几种策略，包括接触假说、准确性自我调节和全球公民框架，并证明这些策略能显著减少错误信息传播和提升学习效果。", "innovation": "本研究通过使用多智能体框架模拟信念一致性，揭示了LLMs相比于人类表现出更强的信念一致性，探讨了这一特性对未来任务的影响，并提出了三种缓解策略，这是该研究的创新之处。", "conclusion": "本研究展示了通过结合社会心理学与AI，可以更好地利用LLMs进行现实世界互动的同时解决信念驱动偏见问题。这些最佳策略可以将错误信息的传播减少高达37%，同时提高学习效果11%。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11364", "html_url": "https://arxiv.org/abs/2502.11364", "title": "多语言性之恩赐：多语言上下文学习的系统性分析", "title_en": "Blessing of Multilinguality: A Systematic Analysis of Multilingual In-Context Learning", "authors": "Yilei Tu,Andrew Xue,Freda Shi", "background": "多语言大语言模型在高资源语言（HRL）上通常表现出色，有时甚至能与英语相媲美，但在低资源语言（LRL）上的表现往往显著不佳。现有的一些提示策略试图缩小这种差距，其中多语言上下文学习（ICL）在目标语言示例不可用时表现尤为突出。然而，目前缺乏对于当和为什么它能有效运作的系统性理解。本文系统分析了通过使用高资源语言示例来增强跨语言迁移的多语言ICL方法，发现混合高资源语言示例的整体表现优于仅使用英语示例，尤其在针对低资源语言任务时更为明显。此外，实验发现提示中存在无关非英语句子也能带来实质性的改进，进一步证明了多语言暴露的有效性。这一系列结果强调了通过战略性利用多语言资源来弥补代表性不足的语言性能差距的潜力。", "innovation": "这篇论文通过使用高资源语言示例来系统性地分析多语言ICL方法，发现了混合高资源语言示例的整体表现优于仅使用英语示例，这在针对低资源语言任务时尤其显著。同时，实验结果表明，在提示中存在无关非英语句子也能提升模型表现，进一步证明了多语言暴露的有效性。", "conclusion": "这项研究强调了通过战略性利用多语言资源来缩小低资源语言与高资源语言性能差距的潜力。研究结果表明，混合使用高资源语言示例而非仅使用英语示例能够显著提高模型在低资源语言任务上的表现，且即使提示中存在无关非英语句子也能带来实质性的改进。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14376", "html_url": "https://arxiv.org/abs/2505.14376", "title": "AutoRev：多模态图检索在自动化同行评审生成中的应用", "title_en": "AutoRev: Multi-Modal Graph Retrieval for Automated Peer-Review Generation", "authors": "Maitreya Prafulla Chitale,Ketaki Mangesh Shetye,Harshit Gupta,Manav Chaudhary,Manish Shrivastava,Vasudeva Varma", "background": "提升学术出版的质量和效率对于作者和审稿人至关重要，因为研究论文是学术交流的核心，并且是网络上高质量内容的主要来源。为此，我们提出了一种自动同行评审系统AutoRev，旨在为审稿人和作者提供可操作的高质量反馈。AutoRev利用了新的多模态检索增强生成（RAG）框架，结合了学术论文的文本和图形表示。通过将文档建模为图，AutoRev有效地检索到最相关的信息，显著减少了对LLMs输入上下文的长度，从而增强它们的评审生成能力。实验结果表明，AutoRev比最先进的基线系统高出了58.72%，并且在人类评估中表现出与真实评审相当的性能。我们设想AutoRev作为一种强大工具，可以简化同行评审工作流程，缓解挑战，实现大规模的高质量学术出版。通过指导作者和审稿人，AutoRev有能力在更大规模上加速网络上高质量研究成果的传播。", "innovation": "AutoRev利用了新的多模态检索增强生成（RAG）框架，结合了学术论文的文本和图形表示。通过将文档建模为图，AutoRev有效地检索到最相关的信息，显著减少了对LLMs输入上下文的长度，从而增强它们的评审生成能力。实验结果显示，AutoRev的性能优于最先进的基线系统，达到了58.72%的提升，并且在人类评估中表现出与真实评审相当的性能。", "conclusion": "我们设想AutoRev作为一种强大工具，可以简化同行评审工作流程，缓解挑战，实现大规模的高质量学术出版。通过指导作者和审稿人，AutoRev有能力在更大规模上加速网络上高质量研究成果的传播。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15087", "html_url": "https://arxiv.org/abs/2505.15087", "title": "HopWeaver：跨文档合成高质量和真实的多跳问题", "title_en": "HopWeaver: Cross-Document Synthesis of High-Quality and Authentic Multi-Hop Questions", "authors": "Zhiyu Shen,Jiyuan Liu,Yunhe Pang,Yanghui Rao", "background": "跨文档多跳问答（MHQA）对于评估模型整合不同来源信息的能力至关重要。然而，创建广泛且高质量的MHQA数据集存在挑战：（i）人工标注成本高，（ii）当前合成方法往往生成简单的问题或需要大量人工指导。现有方法在合成复杂且真实的多跳问题方面存在不足，这也限制了跨文档过程的实际应用。", "innovation": "本论文提出了HopWeaver，这是第一个无需人工干预即可合成真实多跳问题的跨文档框架。HopWeaver通过一个创新的流水线来识别补充文档并构建真实的推理路径，从而确保真正的多跳推理。此外，论文还提供了一个完整的系统来评估合成的多跳问题。实验证明，合成的问题质量与人工标注的数据集相当，同时成本更低。HopWeaver框架为研究社区提供了有价值的研究工具，能够自动从任何原始语料库生成具有挑战性的基准测试，从而开辟了评估和针对特定领域训练的新途径，尤其是资源稀缺的领域。", "conclusion": "HopWeaver框架了跨文档合成真实多跳问题的方法，显著降低了人力成本，同时保持了高质量。该框架为QA模型提供了一种新的评估和训练方法，特别适用于资源有限的领域。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16834", "html_url": "https://arxiv.org/abs/2505.16834", "title": "SimpleDeepSearcher：基于网页驱动推理轨迹合成的深度信息查询", "title_en": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis", "authors": "Shuang Sun,Huatong Song,Yuhao Wang,Ruiyang Ren,Jinhao Jiang,Junjie Zhang,Fei Bai,Jia Deng,Wayne Xin Zhao,Zheng Liu,Lei Fang,Zhongyuan Wang,Ji-Rong Wen", "background": "检索增强生成（RAG）系统已经提升了复杂深度搜索场景下的大语言模型（LLMs），这些场景需要多步推理和迭代的信息检索。然而，现有方法面临着关键限制，包括缺乏高质量的训练路径或在模拟环境中出现分布不匹配的问题，以及在实际部署中计算成本高昂的问题。", "innovation": "本文提出了SimpleDeepSearcher，这是一种轻量级但有效的框架，通过战略性数据工程而不是复杂的训练范式来弥合这一差距。我们的方法通过模拟真实的用户在实时网络搜索环境中进行的互动，合成高质量的训练数据，并结合多标准策展策略，以优化输入和输出的质量与多样性。实验结果表明，在仅使用871个策源样本的情况下，SFT超过基于强化学习的基线模型具有显著的改进。我们的研究系统地解决了数据匮乏的瓶颈，提供了用于高效深度搜索系统的实践见解。", "conclusion": "我们的工作建立了SFT作为一种可行的途径，通过系统地解决数据稀缺瓶颈，为高效的深度搜索系统提供了实际的见解。我们的代码可在以下链接下载：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20309", "html_url": "https://arxiv.org/abs/2505.20309", "title": "引导巨人：LLM中轻量级控制器的加权激活引导", "title_en": "Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs", "authors": "Amr Hegazy,Mostafa Elhoushi,Amr Alanwar", "background": "控制大型语言模型（LLM）的不 desirable 行为，如生成不安全内容或违反安全准则，通常依赖于昂贵的微调。虽然激活引导提供了一种推理时的替代控制方法，但现有方法通常缺乏精细和适应性机制。", "innovation": "引入了一种轻量级、可训练的控制器网络，在推理过程中集成。该控制器网络观察特定的中间LLM激活，并预测全局缩放因子和层特定权重。预测的全局缩放因子和层特定权重动态调节来自预计算的“拒绝方向”矢量的引导补丁的强度，在生成过程中应用于LLM的各层。通过在有害和良性提示的激活上进行训练，该控制器学习对不准确的应用具有细腻、分层意识的干预，主要针对有害输入进行引导。实验表明，与基线LLM相比，我们的加权引导控制器显著提高了拒绝率，实现了针对性的行为修改，而不改变原始模型参数。我们的实验显示，与现有方法相比，该方法在Llama-3.1-8B、Llama-3.2-1B和Mistral-7B上表现更优，提出了一种高效且适应性强的方法，用于改进LLM行为的精细控制。", "conclusion": "我们的加权引导控制器在不改变原始模型参数的情况下实现了针对有害输入的精细行为控制，显著提高了拒绝率，并在多种LLM上展示了优于现有方法的效果。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22296", "html_url": "https://arxiv.org/abs/2505.22296", "title": "360-LLaMA-Factory: 兼容即用的长序列后训练序列并行化", "title_en": "360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training", "authors": "Haosheng Zou,Xiaowei Lv,Shousheng Jia,Lin Li,Xiaochun Gong,Xiangzheng Zhang", "background": "本文档通过将序列并行性引入到LLaMA-Factory中，探讨了不同序列并行模式，并公开了360-LLaMA-Factory。360-LLaMA-Factory被广泛认可，并应用于多个模型及其大型公司的训练框架中，包括Light-R1 (arXiv:2503.10460) 和TinyR1 (arXiv:2503.04872) 等，以及Kaggle AIMO数学模型中。", "innovation": "本文档的核心创新在于引入了序列并行性，通过360-LLaMA-Factory提供了一种易于使用的长期训练后序列并行模式，从而提高了模型训练的效率和灵活性。", "conclusion": "本文档深入探讨了360-LLaMA-Factory背后的序列并行模式，并分享了其实现的见解，通过实际应用案例证明了这种方法的有效性和实用性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22848", "html_url": "https://arxiv.org/abs/2505.22848", "title": "LITEx: 一种理解自然语言推理内部标签变异的解释语言分类法", "title_en": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference", "authors": "Pingjun Hong,Beiduo Chen,Siyao Peng,Marie-Catherine de Marneffe,Barbara Plank", "background": "在自然语言推理（NLI）中，人类标注者对同一前提-假设配对给出不同标签的证据越来越多。然而，内部标签变异——即标注者就相同标签达成一致但提供不同解释的情况——构成了一种尚未充分受到重视的挑战。尽管一些NLI数据集中的NLI项会突出显示某些词作为解释，但相同的文本片段可能因为不同的原因被突出显示，这反映了标注者的不同推理过程。基于这些背景，研究如何系统地理解和解释NLI标签背后的逻辑变得尤为重要。", "innovation": "引入了LITEx，一种基于语言的分类法，用于对英语中的自由文本解释进行分类。使用LITEx分类法，对e-SNLI数据集进行了注释，验证了分类法的可靠性，并分析了它如何与NLI标签、突出显示和解释对齐。进一步评估了LITEx在解释生成中的实用性，表明在LITEx指导下生成的解释比仅使用标签或突出显示生成的解释更接近人类的解释。这种做法不仅捕捉了内部标签变异，还展示了如何引导生成解释以帮助模型使用推理更接近人类解释的方法，比现有策略更有效。", "conclusion": "此方法不仅捕捉了内部标签变异，而且还展示了如何通过引导生成解释以推理的方式有效地弥合人类与模型解释之间的差距，优于现有策略。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.20757", "html_url": "https://arxiv.org/abs/2503.20757", "title": "MCTS-RAG: 运用蒙特卡洛树搜索增强检索增强生成", "title_en": "MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search", "authors": "Yunhai Hu,Yilun Zhao,Chen Zhao,Arman Cohan", "background": "现有的语言模型在处理知识密集型任务时存在推理能力不足的问题，通常采用稀疏的检索和固定的推理过程，这导致知识整合不充分且容易出现幻觉。传统的蒙特卡洛树搜索方法依赖内部模型知识，无法利用外部事实，而现有的一些方法在检索和推理之间缺乏有效的动态集成机制，从而限制了模型的能力和表现。文章旨在解决这些问题，通过引入MCTS-RAG方法，结合检索增强生成和蒙特卡洛树搜索，以提高小规模语言模型在知识密集型任务中的推理能力。", "innovation": "MCTS-RAG方法是一种新颖的增强小规模语言模型推理能力的方法，通过结合检索增强生成（RAG）和蒙特卡洛树搜索（MCTS），动态地将检索与推理过程融为一体。它打破了传统方法中检索和推理独立进行的方式，实现了结构化的推理与适应性的检索相结合。这种方法不仅提高了决策的准确性，减少了幻觉现象，还确保了响应的一致性和事实准确性。实验结果表明，MCTS-RAG可以使小规模语言模型达到与前沿大规模语言模型如GPT-4相当的性能水平，特别是在多个知识密集型数据集（如ComplexWebQA、GPQA和FoolMeTwice）上表现尤为突出。", "conclusion": "MCTS-RAG方法通过有效的逐步决策过程，将检索和推理动态集成，不仅增强了解决知识密集型任务的能力，还提升了小规模语言模型的推理准确性、降低了幻觉的概率，并确保了响应的一致性。实验证明，这种方法能够使小型语言模型达到与更大模型相当的性能水平，为未来的小模型优化提供了新的思路。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18356", "html_url": "https://arxiv.org/abs/2505.18356", "title": "模型合并对大型语言模型跨语言迁移的惊人效果", "title_en": "The Unreasonable Effectiveness of Model Merging for Cross-Lingual Transfer in LLMs", "authors": "Lucas Bandarkar,Nanyun Peng", "background": "尽管大型语言模型在高资源语言任务中表现出色，但在低资源语言的任务上仍然存在不足。本文关注在任务特定的后训练数据稀缺的情况下，将模型转移到低资源语言的方法。研究者验证了对于数学推理和多语言能力最重要的模型参数子集在任务和目标语言之间的划分是独占的，并基于此开发了多种模块化框架来改善细调过程中的模块组合。当缺乏特定语言的数学数据时，模块化方法在三种语言、四种模型和两种细调范式下提升了基线模型的表现，特别是通过分离语言和数学专家模型并采用层交换模型合并方法。这一结果与近期关于任务向量线性度的研究相吻合，研究还通过实验证明了在训练后回滚更少有用的微调更新比一开始就冻结它们更有效果。", "innovation": "本文提出了多种模块化框架，通过冻结参数或模型后处理合并，将数学和语言改进分配到大型语言模型的不同关键部分。特别地，本文通过分离语言和数学专家模型并采用层交换模型合并方法，显著提升了低资源语言任务的表现。此外，还提出了一种在训练后回滚不有用的微调更新的策略，比一开始就冻结它们更为有效。", "conclusion": "本文通过实验证明，对于缺乏内语言数学数据的情况，模块化方法能够显著提升三种语言、四种模型在两种细调范式下的表现，尤其通过分离语言和数学专家模型并采用层交换模型合并方法。此外，研究还提供了关于任务向量线性度的可能解释，并指出在训练后回滚更少有用的微调更新比一开始就冻结它们更为有效。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14161", "html_url": "https://arxiv.org/abs/2506.14161", "title": "MIST: 通过理论思维实现大语言模型多维度隐含偏见评估", "title_en": "MIST: Towards Multi-dimensional Implicit BiaS Evaluation of LLMs via Theory of Mind", "authors": "Yanlin Li,Hao Liu,Huimin Liu,Kun Wang,Yinwei Wei,Yupeng Hu", "background": "大语言模型（LLMs）具有理解他人心理状态的能力，但在处理这一能力时，往往会表现出系统性的隐性偏见。传统的直接询问方法容易受到社会赞成效应的影响，未能捕捉到隐性偏见的复杂和多维性质。", "innovation": "提出了一种新的评价框架，利用刻板印象内容模型（SCM）将偏见重新概念化为理论思维（ToM）在能力、社交性和道德维度上的多维度失败。该框架引入了两个间接任务：词汇联想偏见测试（WABT）和情感归因测试（AAT），旨在不引发模型规避的情况下，探测潜在刻板印象。", "conclusion": "在8个最先进的大语言模型上进行的大量实验表明，该框架能够揭示复杂的偏见结构，包括普遍的社会偏见、多维偏差以及不对称的刻板倾向放大。这为识别隐性偏见的结构性质提供了更稳健的方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10974", "html_url": "https://arxiv.org/abs/2506.10974", "title": "AutoMind: 自适应知识型代理在自动化数据科学中的应用", "title_en": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science", "authors": "Yixin Ou,Yujie Luo,Jingsheng Zheng,Lanning Wei,Zhuoyun Yu,Shuofei Qiao,Jintian Zhang,Da Zheng,Yuren Mao,Yunjun Gao,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLM）代理在解决现实世界的数据科学问题方面显示出巨大的潜力。LLM驱动的数据科学代理有望自动化整个机器学习管道，但其在现实世界中的有效性仍然有限。现有的框架依赖于僵化的、预定义的工作流和不灵活的编程策略；因此，它们仅在相对简单的、经典的问题上表现出色，而无法捕捉到人类从业者在复杂、创新任务中带来的实践经验。", "innovation": "本工作引入了AutoMind，这是一种自适应、富有知识的LLM代理框架，通过三个关键进步克服了这些缺陷：(1) 精心挑选的专家知识库，将代理置于领域专家知识的基础上；(2) 有代理性的知识树搜索算法，战略性地探索可能的解决方案；(3) 自适应编码策略，动态地根据任务复杂性调整代码生成。对两个自动化数据科学基准的评估表明，AutoMind在性能上优于最新的基线。附加分析确认了其有利的效果、效率和定性解决方案质量，突显了AutoMind是迈向完全自动化数据科学的一个有效且稳健的步骤。", "conclusion": "评估结果表明，AutoMind在两个自动化数据科学基准上优于最先进的基线。进一步的分析表明AutoMind在效果、效率和解决方案的质量方面具有优势，标志着在完全自动化的数据科学方面取得了有效且稳健的进步。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15556", "html_url": "https://arxiv.org/abs/2506.15556", "title": "PredGen：通过输入时推测加速大语言模型的推理以实现实时语音交互", "title_en": "PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction", "authors": "Shufan Li,Aditya Grover", "background": "大语言模型（LLMs）通常与文本转语音（TTS）系统结合用于实时语音聊天应用。然而，由于模型的大型化，用户输入结束后与开始生成语音输出之间会有明显的延迟，这会导致用户体验不佳。特别是在消费级硬件上部署单用户语音助手时，这一延迟更为明显。研究表明，这种延迟主要是因为在每句话开始时，TTS系统需要LLMs生成第一句话作为输入，而这一过程需要时间。这成为了一个瓶颈问题。现有的解决方案没有有效解决因为LLMs生成第一句话所需的时间而引起的延迟问题。因此，为了缓解这一问题，一个创新的解决方案是需要一种能在用户还在说话时就开始生成候选响应的机制，以最小延迟开始TTS处理。", "innovation": "我们提出了Predictive Generation（PredGen）框架，该框架通过在用户输入时推测性地进行解码来提前生成候选响应，从而能够在用户还在说话时就开始TTS处理，减少延迟。与现有的解决方案相比，PredGen能够在多种应用场景中将延迟降低约2倍，同时仅仅增加了极小的输入时的额外计算成本，且这些计算成本在传统的解决方案中通常是不必要的。", "conclusion": " PredGen框架能够在很大程度上缓解乃至消除大语言模型在实时语音交互应用中的延迟问题，进而提高用户体验。通过仿真实验验证了PredGen的有效性，并展示了其在计算成本上的有限增加。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23867", "html_url": "https://arxiv.org/abs/2505.23867", "title": "InfiMed：资源有限的医学多模态大语言模型及其增强的理解与推理能力", "title_en": "InfiMed: Low-Resource Medical MLLMs with Advancing Understanding and Reasoning", "authors": "Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang", "background": "多模态大语言模型（MLLMs）在视觉理解和数学推理等领域取得了显著进展，但在医学领域的应用受到两大挑战的限制：一是可用的多模态医学数据稀缺，通常信息量稀疏，限制了推理深度；二是可靠的强化学习（Reinforcement Learning, RL）结合可验证奖励（Verifiable Rewards, VR）在一般领域的有效性，并不适用于改善医学领域的模型性能。", "innovation": "该研究提出了一种新的策略，在监督微调（Supervised Fine-Tuning, SFT）阶段，结合高质量的文本推理数据和一般多模态数据，以提高基础医疗能力并恢复模型的推理能力。此外，针对数据稀疏问题，研究还引入了带有反身模式注入的推理链（Reflective-pattern-injected Chain-of-Thought, CoT），赋予模型初步的反身推理能力，为后续的RLVR训练提供结构化的基础。通过上述方法，研究团队开发了InfiMed-Series模型，包括InfiMed-SFT-3B和InfiMed-RL-3B，分别在七个医学多模态基准测试中取得了领先的表现，其中InfiMed-RL-3B的平均准确率为59.2%，超过了像InternVL3-8B等更大规模的模型（57.3%）。", "conclusion": "该研究通过使用SFT阶段的高质量文本推理数据和一般多模态数据，以及RLVR阶段反身模式注入的CoT，成功提高了MLLMs在医学领域的性能。特别地，在SFT阶段使用了188K样本，而在RLVR阶段使用了36K样本。研究还进行了广泛的实验，提供了有益的见解，有助于提高MLLMs在医学场景中的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.18562", "html_url": "https://arxiv.org/abs/2507.18562", "title": "GIIFT: 图导向的无图像多模态机器翻译", "title_en": "GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation", "authors": "Jiafeng Xiong,Yuting Zhao", "background": "多模态机器翻译（MMT）通过利用视觉信息显著改善了机器翻译的性能。然而，现有的MMT方法在利用模态差异时受到限制，特别是在强制视觉和语言对齐时，它们大多局限于其训练过的多模态数据域内进行推断，面临难以扩大适用范围的问题。", "innovation": "本文提出了GIIFT（图导向的无图像多模态机器翻译）框架。GIIFT通过构建新颖的多模态场景图来保留和整合模态专有的信息，并引入了一个两阶段的框架，该框架使用跨模态图注意力网络适配器在统一融合空间中学习多模态知识，并诱导性地将该知识推广到更广泛的无图像翻译领域。", "conclusion": "在Multi30K英文到法语和英文到德语任务的数据集上的实验结果表明，GIIFT在无图像的情况下超越了现有方法并达到了最先进的水平。WMT基准测试结果表明，GIIFT在无图像翻译基准上的性能有显著提高，证明了其在无图像诱导性推断中的强大学习能力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.03905", "html_url": "https://arxiv.org/abs/2508.03905", "title": "Sotopia-RL：社会智能的奖励设计", "title_en": "Sotopia-RL: Reward Design for Social Intelligence", "authors": "Haofei Yu,Zhengyang Qi,Yining Zhao,Kolby Nottingham,Keyang Xuan,Bodhisattwa Prasad Majumder,Hao Zhu,Paul Pu Liang,Jiaxuan You", "background": "社交智能已成为大型语言模型（LLMs）的关键能力，使它们能够有效地参与如协作和谈判等现实生活中的社交任务。强化学习（RL）为训练社交智能代理提供了自然的方法，因为它使模型能够直接通过社会互动学习复杂的策略，而不需要人工注释。然而，社交智能任务有两个独特之处：（1）社交互动中个别陈述的质量与最终成功的关系不严格；（2）社交互动需要多维度的标准来衡量成功。因此，为了克服这些挑战，我们认为有必要为构建陈述级多维度奖励模型设计奖励，以促进RL训练。", "innovation": "提出了Sotopia-RL，一种新型框架，将粗略的全局反馈细化为陈述级的多维度奖励。该框架通过分配结果给所有个体陈述并捕捉社交互动的全部复杂性来解决难题。实验结果表明，Sotopia-RL在社交目标完成方面取得了最先进的成绩，明显优于现有方法。去随机性研究确认了陈述级贡献分配和多维度奖励设计的必要性。", "conclusion": "Sotopia-RL 通过将粗粒度的反馈转化为细粒度的陈述级多维度奖励，有效地解决了社交智能任务的挑战。实验结果证明其在社交任务上的优越性能，并确认了细粒度贡献分配和多维度奖励设计的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.04023", "html_url": "https://arxiv.org/abs/2507.04023", "title": "大语言模型在基础数学推理中是否过度思考？语言模型准确性和效率权衡的基准测试", "title_en": "Do LLMs Overthink Basic Math Reasoning? Benchmarking the Accuracy-Efficiency Tradeoff in Language Models", "authors": "Gaurav Srivastava,Aafiya Hussain,Sriram Srinivasan,Xuan Wang", "background": "大型语言模型（LLMs）在复杂数学基准测试中表现卓越，但在进行基本数学推理时却出现过度冗长的回答，有时还会影响准确性。本研究旨在通过系统性基准测试和全面的实证研究，评估LLMs在推理上的效率，重点在于准确性和过度思考之间的基本权衡。研究揭示了模型在复杂基准测试中的表现并不直接转换为基本数学推理中的表现，并且模型在生成更多推理时可能降低准确性，甚至在token数量受限时会表现出灾难性下降。此外，推理模型的准确性和token效率之间的关系是非单调的，随着推理预算的增加，准确性的提高逐渐减少。", "innovation": "提出了准确性和冗长性权衡的概念，并引入了综合衡量准确性和token效率的Overthinking Score度量标准。建立了基于动态生成数据的14个基本数学任务的评估流程，进行了覆盖53个不同推理预算的LLM的广泛实证研究。研究首次揭示了这些长期以来被忽视的关键问题和规律，挑战了长期以来默认的假设：在LLMs中更长时间的推理必定会提升数学推理的能力。", "conclusion": "LLMs在复杂数学基准测试中的表现并不能直接转化为基本数学推理的表现。在产生更多推理时，模型可能会降低准确性，并在token数量受限时表现出灾难性的下降。准确性和冗长性的关系是非单调的，随着推理预算的增加，准确性的提高逐渐减少。研究强调，更长时间的推理不一定改善数学推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01213", "html_url": "https://arxiv.org/abs/2508.01213", "title": "示与言？人类与大模型对话中请求表达的演变建模", "title_en": "Show or Tell? Modeling the evolution of request-making in Human-LLM conversations", "authors": "Shengqi Zhu,Jeffrey M. Rzeszotarski,David Mimno", "background": "设计以用户为中心的大型语言模型系统需要理解人们如何使用它们。然而，用户行为的模式往往被查询的差异性所掩盖。为此，本研究引入了一个新框架来描述请求的制作过程。该框架将用户输入分为请求内容、分配的角色、与查询相关的背景信息以及剩下的与任务无关的表达。通过应用此工作流程，基于WildChat创建并分析了包含211,000个实际查询的数据集。", "innovation": "研究引入了一个新的框架来描述请求的制作过程，该框架将用户输入划分成四个部分，并基于此框架对大量实际查询进行分析，发现了人类与大模型对话中请求表达的演变规律，揭示了超越单个任务完成的用户-大模型交互模式。研究发现请求表达从早期强调单一请求逐渐转变为包含更多背景信息，个体用户在表达模式上有所探索且倾向于在经验增加后趋向一致。", "conclusion": "研究从请求交流模式的演变、不同任务条件下的群体趋势以及用户表达的演进来讨论了一些初步的发现。最后，研究讨论了这些发现对用户研究、计算语用学和大模型对齐的重要影响。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02053", "html_url": "https://arxiv.org/abs/2508.02053", "title": "ProCut：通过归因估计进行LLM提示压缩", "title_en": "ProCut: LLM Prompt Compression via Attribution Estimation", "authors": "Zhentao Xu,Fengyi Li,Albert Chen,Xiaofeng Wang", "background": "在大规模工业级LLM系统中，提示模板通常会膨胀到数千个标记，这是因为团队在迭代过程中增加了任务说明、少量示例以及启发式规则等部分，以增强鲁棒性和覆盖率。这一膨胀导致了难以维护的大提示，带来了显著的推理延迟和运行成本。为了解决这个问题，本研究提出了通过归因估计进行提示压缩（ProCut）的框架，这是一种灵活的、LLM无关的、无需训练的方法，可以通过归因分析来压缩提示。ProCut将提示模板分割成具有语义意义的单元，量化它们对任务性能的影响，并修剪低效组件。通过在五个公开基准数据集和实际工业提示上进行实验，结果表明，ProCut能够实现显著的提示大小减少（生产中的标记数减少78%），同时维持或略提高任务性能（最高比其他方法高出62%）。", "innovation": "ProCut框架通过归因分析来压缩提示，避免了训练过程，实现了提示压缩的灵活性和LLM无关性。它将提示模板分割成语义单元，量化各个单元对任务性能的影响，并裁剪低效部分，显著减少了提示大小。此外，该研究还引入了一种基于LLM的归因估计器，将压缩延迟减少了超过50%，并且ProCut能够无缝集成到现有的提示优化框架中，生成简洁高效的提示。", "conclusion": "ProCut框架通过归因分析有效地压缩了提示模板，保持或提高了任务性能。研究证明，ProCut能够在生产环境中将提示大小减少78%，并且具有优于现有方法的性能，同时它的压缩延迟减少了50%，能够与现有的提示优化框架无缝集成，生成简洁高效的提示。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.03363", "html_url": "https://arxiv.org/abs/2508.03363", "title": "无思考校准下的思考：一种新的大型语言模型推理的在场学习范式", "title_en": "Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models", "authors": "Haotian Wu,Bo Xu,Yao Shu,Menglin Yang,Chengwei Qin", "background": "近年来，结构化和多步推理的大语言模型（RLLMs）已经展示了令人惊叹的能力。尽管前期的研究主要集中在提高它们的训练和推理策略上，但它们在上下文中的学习潜力（ICL）仍未得到充分探索。本文旨在填补这一空白，提出了一种新的ICL范式——无思考校准下的思考（JointThinking），该范式促使模型生成两种答案：一种在思考模式下，另一种在无思考模式下。只有当两种初始响应不一致时，才会触发第二次思考，使用一个带有两种不同答案的单个提示。在多个推理基准上的广泛实验表明，JointThinking在性能上明显优于少样本链式思考（CoT）、思考两次和多数投票。此外，它在分布内任务上与基于训练的最先进的推理方法具有可比的性能，但在分布外任务上表现更好。我们还系统地分析了校准机制，揭示了结构化思考多样性和互检一致性的好处，并观察到随着模型尺寸的增加，实际与理想推理之间的性能差距在第二次思考中缩小，这表明我们的方法具有强大的扩展性。最后，我们讨论了当前的局限性并提出了未来RLLMs中的ICL研究的有希望的方向。", "innovation": "提出了无思考校准下的思考（JointThinking）框架，这是一种新的ICL范式，能够以不一致性为触发点，在单个提示中生成两种不同模式的答案。通过与现有的少样本链式思考（CoT）、思考两次和多数投票相比，JointThinking在多个推理基准上取得了显著的性能提升，特别是在分布外任务上表现更好。证明了结构化思考多样性的重要性以及一致性检查的优势。通过分析发现，随着模型尺寸的增加，这种方法在第二次思考中的扩展性非常强。", "conclusion": "无思考校准下的思考（JointThinking）能够在提高大型语言模型（RLLMs）在上下文中的学习能力方面取得显著进展。该方法不仅在分布内任务上表现得与训练基线的先进方法相当，而且在分布外任务上表现出更出色的性能。此外，该研究还揭示了结构化思考多样性以及一致性检查的重要性，并指出了这一领域未来的有希望的方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14685", "html_url": "https://arxiv.org/abs/2508.14685", "title": "缩放符号平均改进小型变换器的内部上下文学习和早期学习基准性能", "title_en": "Scaled Signed Averaging Improves In-Context and Early Learning Benchmark Performance in Small Transformers", "authors": "Omar Naim,Swarnadeep Bhar,Jérôme Bolte,Nicholas Asher", "background": "大语言模型在内部上下文学习（ICL）方面的能力引起了广泛关注，但这些模型在涉及量词如“所有”和“一些”的语义任务以及涉及线性函数的任务中表现出一些限制。研究表明Softmax（注意力机制中的评分函数）是导致这些限制的原因之一。", "innovation": "本文提出了一种新的替代Softmax的方案，缩放符号平均（SSA）。SSA显著改善了内部上下文学习任务的性能，并在几个早期学习自然语言处理（NLP）基准测试和无监督和少量学习的语言探针任务中表现优于使用Softmax的变压器模型。", "conclusion": "SSA在内部上下文学习任务中的表现优于使用Softmax的模型，并在早期学习NLP基准测试和语言探针任务中也表现出色。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08833", "html_url": "https://arxiv.org/abs/2508.08833", "title": "数学推理中LLMs稳健性的研究：通过高级数学问题的数学等效变换进行基准测试", "title_en": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems", "authors": "Yuren Hao,Xiang Wan,ChengXiang Zhai", "background": "本文介绍了一种超越传统方法的系统性框架，用于通过压力测试LLMs在高级数学问题上的表现来评估它们的数学推理稳健性。这些变换允许我们测量LLMs对非数学干扰的敏感性，从而更准确地评估它们的数学推理能力。通过新的评估方法，作者创建了一个新的基准数据集PutnamGAP，该数据集包含多个数学等效的竞赛级别数学问题变体。使用新的数据集，作者评估了多个代表性LLM家族，并检查它们的稳健性。在18个商业和开源模型中观察到性能显著下降。OpenAI的旗舰推理模型O3在原始问题上得分为51.5%，但在表面重命名变体上下降4.7个百分点，在参数变体上下降12.9个百分点，而较小的模型表现更差。总体而言，结果表明，提出的新的评估方法对于深入理解LLMs的稳健性和生成改进它们数学推理能力的新见解是有效的。", "innovation": "本文提出了一个超越传统方法的新系统性框架，通过对高级数学问题进行数学等效变换，来压力测试LLMs，并评估它们的数学推理能力。作者还创建了一个新的基准数据集PutnamGAP，用于评估多个代表性LLM家族的稳健性。作者发现不同模型在不同变体上的表现有显著差异，这表明新的评估方法是有效的，能够揭示LLMs在数学推理上的弱点。", "conclusion": "通过新的评估方法和数据集，作者展示了如何评估LLMs的数学推理稳健性，并揭示了不同模型在数学等效变换问题上的性能差异。这些结果表明，需要进一步研究和改进LLMs在数学推理任务上的表现以提高其稳健性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04402", "html_url": "https://arxiv.org/abs/2508.04402", "title": "人类在对话中听到什么？基于选择性聆听评估口语对话系统ASR的新实验", "title_en": "What Do Humans Hear When Interacting? Experiments on Selective Listening for Evaluating ASR of Spoken Dialogue Systems", "authors": "Kiyotada Mori,Seiya Kawano,Chaoran Liu,Carlos Toshinori Ishi,Angel Fernando Garcia Contreras,Koichiro Yoshino", "background": "口语对话系统(SDSs)利用自动语音识别(ASR)作为其处理管道前端的关键组件，ASR的作用是识别与响应生成相关的用户语音信息。通过研究人类的选择性聆听能力，即在对话时专注于和聆听重要部分的能力，可以识别出SDSs所需的具体ASR能力，并对ASR进行评估。本研究通过对比人类生成对话响应的转录和参考转录，实验验证了人类选择性聆听的能力，并据此讨论了一种新的ASR评估方法，这种方法能够识别ASR系统与人类在转录能力上的差距。", "innovation": "提出了一种新的ASR评估方法，该方法基于人类的选择性聆听能力，旨在识别ASR系统与人类在转录能力上的差距，为口语对话系统的ASR评估提供了一个新的视角和手段。", "conclusion": "实验结果表明，人类在对话过程中确实存在选择性聆听的能力，这为评估ASR系统提供了新的启示。通过进一步探索这一方法，可以更准确地识别和评价ASR系统在对话响应生成中的性能差异。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12726", "html_url": "https://arxiv.org/abs/2508.12726", "title": "DESIGNER: 设计逻辑指导的多学科数据合成体系以提升LLM推理能力", "title_en": "DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning", "authors": "Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Zhiqi Bai,Yuchi Xu,Wenbo Su,Bo Zheng", "background": "大型语言模型（LLMs）在许多自然语言任务中取得了显著的成功，但在复杂多步骤推理方面仍存在挑战，尤其是在跨学科领域。现有的推理数据集通常缺乏学科广度、推理深度和多样性，缺乏问题合成的指导原则。该研究提出了一套基于设计逻辑的多学科挑战性问题合成管道（DESIGNER），利用丰富的原始文档（如图书和网络文档）生成跨学科的难题。通过反向工程和抽象超过120,000个设计逻辑，新生成的问题相比现有数据集具有更高的难度和多样性。利用此管道，生成了覆盖75个学科的大规模推理数据集：DLR-Book（304万个问题从图书集合中）和DLR-Web（166万个问题从网络中）。数据实证分析表明，新生成的问题在难度和多样性上优于基线数据集。", "innovation": "该研究提出了一个设计逻辑指导的多学科数据合成管道（DESIGNER），它利用大量已有的原始文档（如图书和网络文档）生成跨学科的挑战性问题。通过反向工程和抽象超过120,000个设计逻辑，新生成的问题相比现有数据集具有更高的难度和多样性。通过此方法合成的两个大规模推理数据集能够显著增强预训练语言模型的多学科推理能力，优于现有的数据集。特别是在经过监督微调后，这些模型的基础版本甚至超过了官方指令调优的版本。", "conclusion": "该研究使用DESIGNER管道生成了两个大规模推理数据集（DLR-Book和DLR-Web），并通过实验验证新生成的数据能显著提升LLM的多学科推理能力。此外，经过监督微调后的模型基础版本甚至超过了官方指令调优的版本。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19828", "html_url": "https://arxiv.org/abs/2508.19828", "title": "Memory-R1: 通过强化学习增强大型语言模型代理管理并利用记忆能力", "title_en": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning", "authors": "Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Kristian Kersting,Jeff Z. Pan,Hinrich Schütze,Volker Tresp,Yunpu Ma", "background": "大型语言模型在多种自然语言处理任务中表现出色，但由于其状态无记忆性和有限的上下文窗口，它们在长周期推理方面受到限制。现有解决这一问题的方法通常通过外部记忆库来扩展语言模型，但大多数现有的管道是静态和启发式的，缺乏学习机制来决定存储、更新或检索什么内容。", "innovation": "Memory-R1 提出了一种基于强化学习 (RL) 的框架，通过两个专门的代理——Memory Manager 和 Answer Agent，赋予大型语言模型主动管理并利用外部记忆的能力。Memory Manager 学习结构化的操作，包括 ADD、UPDATE、DELETE 和 NOOP，而 Answer Agent 负责预选和处理相关条目。这两个代理通过以结果为导向的 RL（PPO 和 GRPO）进行微调，能够实现适应性记忆管理，几乎不需要监督。即使仅使用 152 对训练 QA 组合，Memory-R1 也超越了强大的基线并且能够跨多种问题类型、三个基准（LoCoMo、MSC、LongMemEval）和不同的模型规模（3B-14B）进行泛化。", "conclusion": "Memory-R1 通过引入基于强化学习的框架，增强了大型语言模型在管理和利用外部记忆方面的表现，显著提高了语言模型的长周期推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Percept-V挑战：多模态LLM能否解决简单的视觉感知问题？", "title_en": "The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "认知科学中的视觉感知被视为智力发展早期的关键标志之一。TVPS-4框架分类和测试人类视觉感知的七项能力，如视觉辨别和形体恒常性。尽管有大量的基准测试评估多模态大语言模型（MLLMs）在高级推理和知识技能上的表现，但在简单感知评估方面，研究相对有限。因此，该研究引入了Percept-V数据集，包含6000个由程序生成的干净图像，分为30个领域，每个领域测试一种或多种TVPS-4技能。研究重点是感知，因此领域设计较简单，解决它们所需的推理和知识较少。尽管现代多模态大语言模型能够解决更复杂的任务，但研究者预计它们会轻松解决这些领域。然而，实验结果表明，当前最先进的闭源和开源MLLMs在Percept-V上的表现远不如人类。随着图像中物体数量的增加，模型的性能下降较快，实验还确定了对所有模型而言较难的感知技能。", "innovation": "该研究通过Percept-V数据集引入了评估多模态大语言模型在基本感知能力上的新基准，这是在这一研究领域的一项创新。它特别关注简单的感知问题，旨在测试这些模型在直观理解能力方面的极限。", "conclusion": "尽管现代多模态大语言模型在处理更复杂的任务上表现出色，但在简单的视觉感知任务上，它们的表现并不如人类表现得好。随着图像中物体数量的增加，模型的性能迅速下降。此外，研究还指出了某些感知技能对模型来说非常具有挑战性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16185", "html_url": "https://arxiv.org/abs/2508.16185", "title": "ParamBench: 评估大型语言模型对印度主题理解的大学水平基准", "title_en": "ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects", "authors": "Ayush Maheshwari,Kaushal Sharma,Vivek Patel,Aditya Maheshwari", "background": "大型语言模型已经在阅读理解、摘要、代码生成等任务上得到了广泛评估。然而，在印度语境中，其在研究生水平、文化背景问题上的表现仍缺乏深入探讨。现有的印度基准测试主要集中在基本事实查询上，有限地评估了适应印度特定情境的学科知识理解。因此，本文提出了ParamBench，这是一个包含超过17,000个问题的宝库，这些问题来自涵盖历史、音乐、乐器、瑜伽、文学、哲学、法律等21个不同学科的问卷。这些问题源自全国性的研究生入学考试，旨在评估大型语言模型在综合题型、如列表匹配、断言-理由对和序列排序等问题上的处理能力。", "innovation": "ParamBench的数据集包含了17,000个以上的题目，这些题目源自21个不同的学科，全部是基于印度的研究生入学考试内容，能够更好地评估大型语言模型在文化和学科理解上的表现。研究还评估了包括名单匹配、主张-理由对和序列排序在内的多种题型，不仅限于传统的多项选择题。研究表明，Gemma3-27B在所有测试的大语言模型中达到了最高的总体准确率56.4%。此外，详细的学科分析揭示了即使对于表现最好的大型语言模型，音乐、古典乐器和法律等主题的表现依然较弱，这凸显了跨文化推理的持续挑战。", "conclusion": "ParamBench为评估大型语言模型在印度特定学科背景下的理解能力提供了一个基准。虽然Gemma3-27B整体表现较好，但在一些特殊题型和特定学科领域，大语言模型的表现依然需要进一步提高，说明了在这些学科领域进行跨文化推理的挑战仍然存在。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "通过推理时构建知识图谱提高大型语言模型的事实准确性", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大型语言模型（LLMs）在生成事实性一致的答案方面常常受到参数化内存限制的困扰。检索增强生成（RAG）方法通过在推理时引入外部知识来缓解这一问题，但这些方法通常将知识视为无结构文本，导致检索准确率降低，抑制组合推理，增加了无关信息对LLM输出事实一致性的负面影响。", "innovation": "本文提出了一种新的框架，在推理时动态构建和扩展知识图谱（KGs），结合LLMs的内部知识和外部来源检索到的外部知识。该方法首先通过提示从问题中提取种子KG，然后通过LLMs的内部知识进行迭代扩展。最终通过外部检索对KG进行选择性精炼，从而增强事实覆盖范围并纠正不准确性。", "conclusion": "本文方法在三个不同的事实问答基准测试中得到评估，并展示了相对于基线的一致性事实准确性提高。研究结果表明，推理时构建知识图谱对于以结构化、可解释和可扩展的方式增强大型语言模型的事实性具有前景。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14146", "html_url": "https://arxiv.org/abs/2508.14146", "title": "MMReview: 多学科和多模态的LLM基自动同行评审基准", "title_en": "MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation", "authors": "Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu", "background": "随着学术出版物的迅速增长，同行评审已成为研究社区中不可或缺但耗时的任务。大型语言模型被越来越多地用于协助生成审稿意见，然而，当前基于LLM的审稿任务缺乏一套统一的评估基准，无法严格评估模型生成全面、准确且符合人类标准评估的能力，尤其是在涉及图表等多模态内容的情况下。为解决这一问题，我们提出了MMReview，一个跨越多个学科和模态的全面基准，包括四大主要学术学科中的240篇论文，共计17个研究领域，涵盖人工智能、自然科学、工程科学和社会科学，并包括多模态内容以及专家撰写的审稿意见。我们设计了13项任务，分为四大类，旨在评估LLM和多模态LLM在逐步生成审稿意见、成果制定、与人类偏好对齐以及对抗性输入操纵鲁棒性方面的性能。", "innovation": "提出了MMReview，一个面向多学科和多模态的大型语言模型基自动同行评审基准，涵盖四大主要学科，包括人工智能、自然科学、工程科学和社会科学，并设计了13项任务来评估模型在多种任务上的表现，旨在填补当前研究中的评估基准空白，特别是在处理多模态内容时。实验还展示了该基准的全面性，测试了16个开源模型和5个先进的封闭源模型。", "conclusion": "我们期望MMReview成为自动同行评审系统开发标准化基础的重要步骤，通过提供一个统一的评估基准，为这一领域的研究和发展提供有力支持。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15098", "html_url": "https://arxiv.org/abs/2509.15098", "title": "TextMine: 数据，评估框架和本体导向的大规模语言模型管道在人道主义地雷行动中的应用", "title_en": "TextMine: Data, Evaluation Framework and Ontology-guided LLM Pipeline for Humanitarian Mine Action", "authors": "Chenyue Zhou,Gürkan Solmaz,Flavio Cirillo,Kiril Gashteovski,Jonathan Fürst", "background": "人道主义地雷行动(HMA)旨在从冲突地区探测和移除地雷。HMA机构产生的大量生命拯救操作知识散落在非结构化报告中，这限制了机构间信息的可转移性。", "innovation": "提出了TextMine：首个针对HMA领域的数据集、评估框架以及本体导向的大规模语言模型(LLM)管道，用于知识提取。通过将HMA报告结构化为(subject, relation, object)三元组，创建了领域的特定知识。引入了一种具有意识的偏差评估框架，结合了人工标注的三元组与LLM作为法官协议，以减轻参考无参照评分中的立场偏见。", "conclusion": "实验结果表明，本体对齐的提示提高了提取精度高达44.2%，减少了幻觉22.5%，提升了格式遵守度20.9%，与基线模型相比。数据集和代码已公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.00591", "html_url": "https://arxiv.org/abs/2509.00591", "title": "Probe-Rewrite-Evaluate：一种可靠基准和评估意识量化的工作流", "title_en": "Probe-Rewrite-Evaluate: A Workflow for Reliable Benchmarks and Quantifying Evaluation Awareness", "authors": "Lang Xiong,Nishant Bhargava,Jianhang Hong,Jeremy Chang,Haihao Liu,Vasu Sharma,Kevin Zhu", "background": "大型语言模型（LLMs）在从实际应用环境转变为受控评估环境时，会展现出显著的行为变化，这种现象称为‘评估意识’。这种行为差异对于AI对齐构成了关键挑战，因为模型基准测试性能可能无法准确反映其真实的安全性和真实性。本文通过系统地量化这些行为变化，详细说明了评估意识问题，并提出了一种通过改变提示感知上下文的方法来系统量化评估意识的方法。这种方法使用线性探针对提示进行评分，并利用LLM重写策略将其重塑为更自然、更符合部署的上下文。研究发现，重写后的提示能够显著且一致地改变模型的行为，并提升了模型的真实回答率，同时也减少了欺骗性回答，提高了拒绝率，从而提高了安全性合规性。这表明评估意识是一个可量化且可操作的影响模型行为的因素。", "innovation": "本文创新地提出了一种新的工作流，称为Probe-Rewrite-Evaluate（P-R-E），该工作流可以系统地量化评估意识并生成更可靠的基准测试结果。这种方法通过利用线性探针对提示进行评分，并通过LLM重写策略调整提示，使其适应更自然、更符合实际部署环境的上下文，从而改变了模型的行为，为研究评估意识的影响提供了新的工具。", "conclusion": "本文的研究结果表明，评估意识是一个可以量化和操控的因素，直接影响模型的行为，尤其是模型在测试环境中更可能产出不安全或欺骗性输出。这些发现强调了在模型部署前建立更现实的评估框架的紧迫性，以便更准确地评估模型的真实对齐程度。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03122", "html_url": "https://arxiv.org/abs/2509.03122", "title": "从注入到防御：构建基于编辑的大规模语言模型指纹", "title_en": "From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Linlin Wang", "background": "指纹识别对于维护可追溯性和保护开发者的知识产权至关重要，尤其是在网络应用程序中部署的LLM（大型语言模型）容易遭受未经授权的重新分配和误用，这通常通过微调或黑盒部署实现。然而，现有的基于后门的指纹识别方法面临根本性的权衡：嵌入在混淆文本中的指纹容易被检测和过滤，而精心设计的自然语言指纹则容易无意中触发。", "innovation": "我们提出了RFEdit，这是一种知识编辑框架，通过修改部分模型权重来嵌入基于规则的多语言自然语言指纹（MNLF）。这种方法可以在不影响LM（语言模型）无关知识的情况下有效地和稳健地注入指纹。此外，通过Fingerprint Subspace-aware Fine-Tuning（FSFT），该框架进一步得到了保护，可以在合法微调期间缓解指纹退化，通过限制参数更新到指纹子空间。这在保持生成模型的完整性的同时，还增强了LLM下游任务的性能。这些进展建立了一个从指纹注入到防御的全面管道，实现了高度的检测效果，对对抗性操控的鲁棒性，对模型实用性无害以及在微调下的持久性。广泛的实验表明，RFEdit在量化和剪枝下保持了稳健性，并且当与FSFT结合使用时，指纹的有效性普遍提高了10%以上，尤其是在数学和Alpaca下游任务中。", "conclusion": "RFEdit框架和FSFT技术提供了一种高效且稳健的大型语言模型指纹化方法，能够抵抗对抗性操作，不影响模型的实用性，同时在微调过程中保持持久性。这种框架实现了从指纹注入到防御的全面过程，展示了强大的检测效果和鲁棒性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26431", "html_url": "https://arxiv.org/abs/2509.26431", "title": "基于文本的方法在大规模阅读与写作测验中内容标准项目对齐", "title_en": "Text-Based Approaches to Item Alignment to Content Standards in Large-Scale Reading & Writing Tests", "authors": "Yanbin Fu,Hong Jiao,Tianyi Zhou,Robert W. Lissitz,Nan Zhang,Ming Li,Qingshu Xu,Sydney Peters", "background": "项目对齐是测试开发的关键步骤，用于在基于内容的基础上收集有效性证据。通常，这一过程由人类专家进行判断性操作，但这种过程可能主观且耗时。本研究探讨了微调的小型语言模型（SLMs）在大规模标准化阅读和写作测试中的自动项目对齐性能，使用了大学入学测试的数据。研究调查了不同类型和规模的输入数据对训练的影响。研究结果表明，包括更多项目文本数据能够显著提高模型性能，超出样本数量增加的改善。", "innovation": "本研究表明，微调的小型语言模型在项目对齐上表现出色，尤其是对于更具体的技能对齐。微调的SLMs在性能上优于基于嵌入的监督机器学习模型，特别是在更精细的技能对齐方面。此外，通过多维语义相似性分析，研究人员更好地理解了模型的误分类情况，并确认了一些SAT和PSAT技能在语义上过于接近，从而证实了观察到的误分类现象。", "conclusion": "使用微调的小型语言模型可以提升项目对齐的效果，特别是在处理更为细致的技能对齐问题时。通过对项目文本数据的分析，可以更好地理解模型的误分类原因。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16765", "html_url": "https://arxiv.org/abs/2509.16765", "title": "语言模型在言语病理学中的调优与综合评估：语法之声", "title_en": "The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology", "authors": "Fagun Patel,Duc Q. Nguyen,Sang T. Truong,Jody Vaynshtok,Sanmi Koyejo,Nick Haber", "background": "据美国国立卫生研究院报道，超过340万儿童患有需要临床干预的言语障碍。言语-语言病理学家的数量远远少于受影响的儿童数量，这表明需要技术支持来提高言语-语言病理学家的工作效率。最新的多模态语言模型具有支持言语-语言病理学家的潜力，但由于对它们在高风险临床环境中的表现理解不足，其应用仍然有限。为解决这一问题，作者与领域专家合作，制定了一个多模态语言模型在言语病理学中实际应用的分类系统，并构建了首个涵盖五种核心用例的综合评估基准，每个用例包含1000个手动标注的数据点，以评估模型的鲁棒性与敏感性。", "innovation": "该研究的独特之处在于，作者首先开发了一个涵盖多模态语言模型在言语病理学中应用的分类系统，并在此基础上构建了首个评估多模态语言模型的综合基准。该基准涵盖了各种环境条件下的模型评估，包括背景噪声、语音性别和口音，并且评估了15种最先进的多模态语言模型。作者还研究了在特定领域数据上调优多模态语言模型的效果，发现与基础模型相比，可以实现超过10%的性能提升。这些发现揭示了目前多模态语言模型在言语病理学应用中的潜在与局限性，强调了进一步研究和针对性开发的需求。", "conclusion": "该研究发现了当前多模态语言模型在言语病理学应用中的一些潜在问题和性能差异，揭示了未来研究的关键方向。通过开发首个针对言语-语言障碍的核心应用的多模态语言模型基准，这一研究对言语病理学专业领域提供了一个重要的评估框架，同时展示了调优和特定领域数据应用的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23206", "html_url": "https://arxiv.org/abs/2509.23206", "title": "PARL-MT: 在多轮对话中学习使用进度意识调用函数", "title_en": "PARL-MT: Learning to Call Functions in Multi-Turn Conversation with Progress Awareness", "authors": "Huacan Chai,Zijie Cao,Maolin Ran,Yingxuan Yang,Jianghao Lin,pengxin,Hairui Wang,Renjie Ding,Ziyu Wan,Muning Wen,Weiwen Liu,Weinan Zhang,Fei Huang,Ying Wen", "background": "大型语言模型在单轮函数调用任务上取得了显著的成功，但在旅行规划或多阶段数据分析等实际应用场景中，任务通常需要在多轮对话中逐步进行。在这种设置中，模型不仅需要在每一步准确地调用函数，还需要保持进度意识，能够总结过去交互并规划未来行动，以确保任务执行的连贯性和长期目标的达成。然而，现有方法要么将多轮训练简化为孤立的单轮样本，忽略了任务级别规划；要么采用端到端的强化学习方法，但易产生冗余并缺乏对进度意识的明确集成。因此，需要一种新的方法来改进多轮函数调用的性能，特别是在保持连贯性与减少冗余方面.", "innovation": "PARL-MT框架引入了明确将进度意识融入大型语言模型训练中的方法，以解决多轮函数调用中的挑战。该框架包括两个主要部分：(i) 进度意识生成（PAG）流水线，自动构建将对话总结与未来任务规划相结合的数据集；(ii) 进度意识引导的强化学习（PAG-RL）算法，将进度意识集成到强化学习中，以减少上下文冗余并提高局部动作与全局任务完成的对齐性。实验结果表明，PARL-MT在两个公开基准数据集上的表现显著优于现有方法，验证了进度意识在增强多轮函数调用中的有效性和效率.", "conclusion": "PARL-MT在多轮对话中学习使用进度意识调用函数方面表现出了显著的优势，为了解决多轮任务中的挑战提供了一种有效的方法。通过引入PAG流水线和PAG-RL算法，成功地将进度意识整合进强化学习训练，减少了冗余，并提高了局部动作与全局任务完成的对齐。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23580", "html_url": "https://arxiv.org/abs/2509.23580", "title": "LLM幻觉检测：HSAD", "title_en": "LLM Hallucination Detection: HSAD", "authors": "JinXin Li,Gang Tu,JunJie Hu", "background": "尽管大型语言模型在多种任务（如语言理解和代码生成）中表现出强大能力，但在生成过程中频繁出现的幻觉已成为其在关键应用场景中部署的重要障碍。当前主流的幻觉检测方法依赖于事实一致性验证或静态隐藏层特征，前者受限于知识覆盖范围，后者难以捕捉推理过程中的偏差。", "innovation": "受认知神经科学中信号分析方法的启发，本文提出了一种基于隐藏层时间信号频域分析的幻觉检测方法（HSAD）。该方法首先通过隐藏层时间信号模拟人类在欺骗检测场景中的信号感知和鉴别过程，然后利用快速傅里叶变换将这些时间信号映射到频域，从而构建频谱特征，这些特征用于捕捉推理过程中出现的异常；最后设计了一种基于这些频谱特征的幻觉检测算法，以识别生成内容中的幻觉。HSAD方法有效结合了推理过程建模与频域特征提取，克服了现有方法在知识覆盖范围和推理偏差检测方面的局限性，显示出更高的检测准确性和鲁棒性。", "conclusion": "通过有效结合推理过程建模与频域特征提取，HSAD方法克服了现有方法在知识覆盖范围和推理偏差检测方面的局限性，展示了更高的检测准确性和鲁棒性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04764", "html_url": "https://arxiv.org/abs/2510.04764", "title": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models", "title_en": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models", "authors": "Raha Askari,Sina Zarrieß,Özge Alacam,Judith Sieker", "background": "隐含意义是人类交流的重要组成部分，因此语言模型必须能够识别和解释这些隐含意义。Grice于1975年提出了会话准则，指导合作对话，在这个过程中，说话者可能会故意违反这些准则来表达超越字面意义的含义，而听话者则会通过识别这些违反来进行语用推理。基于Surian等人(1996)有关儿童对违反Griceanism准则的敏感性研究，本文引入了一个新型基准测试，以检验预训练于少于1000万令牌和少于1亿令牌的语言模型是否能够区分遵循和违反准则的长短句。研究通过在五个准则上的表现对这些语言模型进行了评估，并将它们的表现与儿童和一个大型语言模型进行了比较，后者是基于3万亿令牌的预训练。研究结果表明，与训练数据体量较小的语言模型相比，训练数据体量较大的语言模型表现得更好，但仍低于儿童和大型语言模型的水平。这些结果表明，适度的数据提高可以改善某些方面的语用行为，并在语用维度上实现了更精细的区分。", "innovation": "本文通过引入一个新型基准测试，检验预训练于少量数据的语言模型是否能够区分遵循和违反会话准则的长短句，并且相比此前的工作，本文更加关注于少量数据预训练的语言模型（BabyLMs）在这个领域的表现。", "conclusion": "整体而言，预训练于少于10000万令牌的语言模型优于预训练于少于1000万令牌的模型，但依旧与儿童和大语言模型的水平存在差距。研究结果表明，适度的数据量增加可以在某些方面改善语用行为的表现，并且不同数据预训练的语言模型面对不同的语用准则在表现上存在差异性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大规模语言模型中的知识多样性和知识萎缩", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）倾向于生成在词汇、语义和修辞上较为一致的文本，这可能导致知识萎缩，即随着时间的推移和文化环境的变化，可访问信息的范围缩小。现有关于同质化的工作主要集中在封闭的选择题设置或模糊的语义特征上，未能考察跨时间的文化背景趋势。本研究旨在通过引入新的测量方法来评估知识的多元性，即LLMs输出中关于现实世界的多样声明，以实证研究大规模语言模型的知识萎缩问题。研究测试了27个模型，共155个话题，覆盖12个国家，并从实际用户对话中收集了200种提示变化。结果表明，尽管较新的模型生成更广泛的声明，但几乎所有模型在知识的多元性方面都无法与基本的网页搜索相比。发现模型大小对知识的多元性有负面影响，而检索增强生成（RAG）则有正向影响，但RAG的改进因文化背景而异。最终，相比传统的知识来源（维基百科），国家特定的陈述反映了英语而非当地语言，突显了知识表现中的差距。", "innovation": "本研究提出了一个新的测量方法来评估知识的多元性，即LLMs输出中关于现实世界的多样声明。这种方法用于进行广泛的实证研究，探索大规模语言模型的知识萎缩问题，并且该研究测试了27种大型语言模型和多种提示变化，跨越了12个国家的主题，从而填补了现有研究中时间跨度和文化背景方面的重要空白。此外，研究还揭示了模型大小和取样增强生成（RAG）对知识多元性的影响差异。", "conclusion": "研究结果显示，虽然较新的模型生成的声明更具有多样性，但大多数模型的多元性仍然低于基本的网页搜索。模型大小对知识的多元性有负面影响，而RAG则有正向影响，但影响程度因文化背景而异。国家特定的声明更多反映了英语，而不是当地语言，这揭示了一个知识表现上的差距。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05942", "html_url": "https://arxiv.org/abs/2510.05942", "title": "EvalMORAAL: 可解释的链式思维与LLM作为裁判的道德对齐评估", "title_en": "EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation for Moral Alignment in Large Language Models", "authors": "Hadi Mohammadi,Anastasia Giachanou,Ayoub Bagheri", "background": "目前，大规模语言模型（LLM）的道德对齐（moral alignment）评估存在明显的地区差异，尤其是西方地区和非西方地区的对齐程度有所不同，这表明存在持续的区域偏向性。研究人员需要一种能够透明、公平地比较所有模型的方法，以及一种富有结构的链式思维协议来评估这些模型的道德对齐情况。", "innovation": "该论文提出了一种名为EvalMORAAL的透明链式思维框架，结合使用两种评分方法（log-概率和直接评分）和模型作为裁判的同行评议来评估20个大型语言模型的道德对齐情况。该论文还采用了一种结构化的链式思维协议，包括自我一致性检查，并引入了模型作为裁判的同行评议制度。", "conclusion": " 使用 EvalMORAAL，顶级模型与调查回应的对齐程度较高（WVS皮尔逊相关系数约为0.90），但存在明显的区域差异，西方地区的相关系数平均为0.82，而非西方地区为0.61，反映出存在持续的区域偏向性。这些结果表明了朝着文化意识型AI的实质性进展，同时也指出了在不同地区使用时面临的一些开放挑战。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.10354", "html_url": "https://arxiv.org/abs/2306.10354", "title": "LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning", "title_en": "LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning", "authors": "Yolo Yunlong Tang,Jinrui Zhang,Xiangchen Wang,Teng Wang,Feng Zheng", "background": "此次论文是关于CVPR 2023年通用事件边界描述（GEBC）竞赛的获胜作品。与传统的视频字幕任务不同，GEBC要求模型理解视频边界周围的状态变化，这使得该任务更加复杂。因此，GEBC不仅要求模型理解视频内容，还要能够描述视频中状态的变化。", "innovation": "本文提出了一种有效的模型LLMVA-GEBC（Large Language Model with Video Adapter for Generic Event Boundary Captioning）：(1) 利用预训练的大型语言模型来生成高质量的人类风格字幕。(2) 将视频Q-former作为适配器，并与冻结的视觉特征提取器和大型语言模型一起进行训练，以适应GEBC任务的需求。该方法在测试集上获得了76.14的分数，并在比赛中排名第一。", "conclusion": "文中提出的方法LLMVA-GEBC在CVPR 2023年的通用事件边界描述（GEBC）比赛中取得了第一名，得分76.14，并且其代码已公开。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2307.04827", "html_url": "https://arxiv.org/abs/2307.04827", "title": "LaunchpadGPT：语言模型作为 Launchpad 音乐可视化设计师", "title_en": "LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad", "authors": "Siting Xu,Yolo Yunlong Tang,Feng Zheng", "background": "Launchpad 是一种音乐装置，用户可以通过按压发光按钮来创作和演奏音乐。为帮助和启发 Launchpad 光效设计，并为初学者提供更易于创建音乐可视化的方法，本文提出了 LaunchpadGPT 模型，该模型能够自动生成适用于 Launchpad 的音乐可视化设计。通过对用户在 Launchpad 上演奏音乐时录制的视频进行收集和处理，获取音乐和对应的视频帧作为提示-完成对，用以训练语言模型。实验结果显示，所提出的方法在生成音乐可视化方面比随机生成方法效果更好，并且具有更广泛的应用潜力。", "innovation": "本文提出了 LaunchpadGPT 模型，这是一个基于具有卓越生成能力的语言模型，输入音乐音频片段，输出生成适用于 Launchpad 的音乐可视化设计的视频。该模型旨在自动化生成音乐可视化设计，从而简化音乐创作过程中音乐可视化的设计过程，为初学者提供更简单的途径进行音乐创作和表现", "conclusion": "实验结果表明，所提出的 LaunchpadGPT 方法生成的音乐可视化效果优于随机生成方法，并且该方法具有广泛的应用潜力，未来可进一步开发和应用与更多类型的音乐可视化场景。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05154", "html_url": "https://arxiv.org/abs/2510.05154", "title": "人工智能能否真正代表你的声音？大规模意见聚合中的全面LLM研究", "title_en": "Can AI Truly Represent Your Voice in Deliberations? A Comprehensive Study of Large-Scale Opinion Aggregation with LLMs", "authors": "Shenzhe Zhu,Shu Yang,Michiel A. Bakker,Alex Pentland,Jiaxin Pei", "background": "大规模的公共讨论会产生成千上万的自由形式贡献，需要将这些贡献综合成代表性和中立的摘要，以便用于政策制定。虽然大语言模型（LLMs）已被证明是生成大规模讨论摘要的有前途的工具，但也存在 minority 视角的代表性不足以及输入顺序的偏见问题，这在高风险背景下引发了公平性关注。因此，研究和解决这些问题需要全面的大规模评估，但目前的做法往往依赖于LLMs作为法官，而这种做法与人类判断的对齐程度较弱。", "innovation": "本文作者提出了DeliberationBank，这是一个大规模的人类导向数据集，包含（1）由3000名参与者创建、涵盖10个讨论问题的意见数据，（2）由4500名参与者在四个维度（代表性、信息量、中立性、政策认可度）上进行注释的摘要评估数据。利用这些数据集，作者训练了DeliberationJudge，这是一种微调后的DeBERTa模型，可以从不同角度看待讨论摘要。DeliberationJudge在效率和人类评判的一致性方面比广泛使用的LLM法官更具优势。通过DeliberationJudge，作者评估了18种LLM，并揭示了讨论总结的持续弱点，尤其是少数派观点的代表性不足。", "conclusion": "本文框架提供了一种可扩展且可靠的方法来评估讨论总结，有助于确保AI系统在政策制定中更加代表性和公平。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.15907", "html_url": "https://arxiv.org/abs/2501.15907", "title": "Emilia：一个大规模、多样化、多语言的语音生成数据集", "title_en": "Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for Speech Generation", "authors": "Haorui He,Zengqiang Shang,Chaoren Wang,Xuyuan Li,Yicheng Gu,Hua Hua,Liwei Liu,Chen Yang,Jiaqi Li,Peiyang Shi,Yuancheng Wang,Kai Chen,Pengyuan Zhang,Zhizheng Wu", "background": "近年来，语音生成的进步主要依赖于大规模的训练数据集。然而，当前模型在捕捉现实人类语音中的自发性和变异性方面表现不佳，因为它们主要是在受限制的音频书数据集上进行训练，这些数据集仅涵盖正式的朗读说话风格。因此，迫切需要一种开放式预处理管道，以从大量未充分利用、但能够捕捉现实世界中自发人类语音的来源中提取高质量的训练数据。", "innovation": "本文引入了Emilia-Pipe，这是一种开源预处理管道，旨在从未充分利用但丰富的来源中提取高质量的训练数据，这些来源能够捕获现实世界环境下的自发人类语音。利用Emilia-Pipe，我们构建了Emilia，一个涵盖六种语言(英语、中文、德语、法语、日语和韩语)超过101000小时的语音数据集。我们进一步扩展了Emilia以创建Emilia-Large，一个超过216000小时的大型数据集，使其成为目前最大的开放语音生成资源之一。研究表明，使用Emilia训练的模型比使用传统音频书籍数据集训练的模型生成的语音更加自发且人性化，但同时在可理解性方面保持一致。这些模型更好地捕捉了多样化的说话人音调和现实世界对话风格的整个谱系。这项工作还强调了扩大数据集规模对于推动语音生成性能的重要性，并验证了Emilia对于多语言和跨语言语音生成任务的有效性。", "conclusion": "总结而言，Emilia是一个包含多语言、多样化和大规模语音生成数据集，通过利用现实世界中的大量未充分使用的数据源，有效提升了语音生成模型的自发性和人类相似度，同时保持了可理解性。这不仅促进了语音生成技术的发展，也为构建多样化和适应性强的语音生成模型提供了新的资源，特别是在多语言和跨语言任务中。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15347", "html_url": "https://arxiv.org/abs/2505.15347", "title": "FlowKV：通过隔离键值缓存管理增强大语言模型多轮对话连贯性", "title_en": "FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management", "authors": "Xiang Liu,Hong Chen,Xuming Hu,Xiaowen Chu", "background": "大型语言模型（LLMs）越来越多地被部署在多轮对话应用程序中，其中键值（KV）缓存的管理成为一个显著瓶颈。随着对话历史的增加，KV缓存呈线性增长，带来了显著的计算成本。现有的淘汰策略常常在不断压缩早期对话背景时导致性能下降，这会导致信息丢失和上下文遗忘。", "innovation": "FlowKV是一种新颖的多轮隔离机制，适用于任何KV缓存压缩方法且无需训练。它的核心创新是多轮隔离机制，可以保留过去回合的压缩KV缓存，并仅对最新完成回合的新生成的KV对进行压缩，从而防止重新压缩旧的上下文，减少灾难性遗忘。", "conclusion": "我们的研究结果表明，与基础策略相比，FlowKV在保持指令跟随准确性和用户偏好保留上表现更好，特别是在后续对话轮次中，FlowKV的表现一致性显著提升，从10.90%提高到75.40%。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19649", "html_url": "https://arxiv.org/abs/2502.19649", "title": "Representation Engineering for Large Language Models", "title_en": "Taxonomy, Opportunities, and Challenges of Representation Engineering for Large Language Models", "authors": "Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz", "background": "背景： Representation Engineering (RepE) 是一种新颖的控制大型语言模型 (LLMs) 行为的范式。与传统方法不同，RepE 直接操作模型的内部表示，而不是修改输入或微调模型。这可能提供更有效的、可解释的、数据高效的和灵活的控制模型行为的方法。本文综述了RepE对于LLMs的研究，旨在解决关键问题，包括现有RepE方法及其差异、应用于哪些概念和问题、以及与其他方法相比的优点和缺点。为了回答这些问题，本文提出了一种统一的框架来描述RepE，并将其视为由表示识别、操作和控制三个阶段组成的管线。此外，本文指出了RepE方法的潜力仍然存在一些挑战，包括处理多个概念、确保可靠性以及保持模型的性能。为了改进RepE，本文指定了实验和方法论的改进机会，并构建了一份最佳实践指南。", "innovation": "创新： 本文是首次全面综述RepE对于LLMs的研究，提供了一个统一的框架来描述RepE，并指出了RepE方法的潜力仍然存在的一些挑战，提出了改进的机会，并构建了最佳实践指南。", "conclusion": "结论：尽管RepE方法具有巨大的潜力，但仍面临多种挑战。为了解决这些问题，提出了改进RepE的机会，并提供了一份最佳实践指南来提高RepE。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05858", "html_url": "https://arxiv.org/abs/2510.05858", "title": "DACP: 针对电话对话总结领域自适应连续预训练的大型语言模型", "title_en": "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization", "authors": "Xue-Yong Fu,Elena Khasanova,Md Tahmid Rahman Laskar,Harsh Saini,Shashi Bhushan TN", "background": "大型语言模型在文本摘要方面取得了显著的性能，但在应用于与预训练分布不同的专业领域时，其性能往往不尽如人意。尽管微调可以提高摘要质量，但通常依赖于昂贵且稀缺的高质量标签数据。因此，有必要探索一种可扩展且无需大量标注数据的自监督方法，以适应大型语言模型应用于下游摘要任务，特别是在嘈杂的现实世界对话转录中。本研究探讨了连续预训练作为适应大型语言模型的方法，尤其是在大规模非标标记商业对话数据中的应用效果，旨在利用连续预训练提升对话摘要能力，同时保持强大的泛化能力和鲁棒性。", "innovation": "本研究提出了连续自适应预训练（DACP），这是一种可扩展、自我监督的方法，用于适应大型语言模型以处理下游摘要任务，特别是在包含噪声的现实世界电话对话转录中。研究通过大规模、非标记的商业对话数据进行了广泛的实验，验证了连续预训练在领域内和领域外摘要基准测试中的显著收益，同时保持了广泛的泛化能力和鲁棒性。此外，研究还分析了数据选择策略的效果，为总结方向的应用提供实用指南。", "conclusion": "连续预训练方法在领域内和领域外摘要任务上取得了显著提高，同时也保持了良好的泛化能力和鲁棒性。数据选择策略的研究提供了工业应用中总结方向连续预训练的实际指导。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01382", "html_url": "https://arxiv.org/abs/2504.01382", "title": "进步的幻觉？评估当前的网络代理状况", "title_en": "An Illusion of Progress? Assessing the Current State of Web Agents", "authors": "Tianci Xue,Weijian Qi,Tianneng Shi,Chan Hee Song,Boyu Gou,Dawn Song,Huan Sun,Yu Su", "background": "随着数字技术和云技术的发展，互联网在现代社会中的作用愈发重要。基于大型语言模型（LLMs）的自主网络代理在自动化工作中具有巨大潜力。因此，准确地衡量并监控这些代理能力的进展至关重要。本文对当前网络代理的状态进行了全面和严谨的评估。", "innovation": "引入了Online-Mind2Web，这是一种包含300个多样化且现实的任务的在线评估基准，覆盖136个网站，用于近似评估真实用户如何使用这些代理。此外，开发了一种新的LLM-as-a-Judge自动评估方法，该方法与人类判断的一致性达到了大约85%，远高于现有方法。", "conclusion": "我们首次提供了当前网络代理的全面比较分析，既突显了它们的优势，也指出了它们的局限性，以此启发未来的研究。同时，指出之前报告的结果可能过于乐观，这主要是由于现有基准的不足。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12891", "html_url": "https://arxiv.org/abs/2505.12891", "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios", "title_en": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios", "authors": "Shaohang Wei,Wei Li,Feifan Song,Wen Luo,Tianyi Zhuang,Haochen Tan,Zhijiang Guo,Houfeng Wang", "background": "现有的大型语言模型在时间推理方面存在缺陷，未能解决实际场景中的时间推理挑战，如密集的时间信息、快速变化的事件动态和复杂的社会互动中的时间依赖性。", "innovation": "提出了一个多级基准TIME，专门设计用于处理现实世界中的时间推理问题。TIME包含38,522个问答对，覆盖三个级别并细分为11个子任务，涉及不同的现实世界挑战子数据集，如TIME-Wiki、TIME-News和TIME-Dial。还进行了广泛的实验，并深入分析了时间推理的性能，并总结了测试时间缩放对时间推理能力的影响。推出了TIME-Lite子集以促进未来在时间推理方面的研究和标准化评估。", "conclusion": "在TIME基准上进行了全面的实验，并进行了详细的时间推理性能分析，披露了测试时间缩放对时间推理能力的影响。并发布了TIME-Lite子集以促进未来在时间推理方面的研究和标准化评估。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17607", "html_url": "https://arxiv.org/abs/2505.17607", "title": "受控代理规划与推理在机构设计中的应用", "title_en": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis", "authors": "João Pedro Gandarela,Thiago Rios,Stefan Menzel,André Freitas", "background": "本文提出了一种基于双智能体的大语言模型推理框架，用于自动化平面机构设计。该框架将自然语言规范与符号表示和仿真紧密结合。系统从自然语言的任务描述出发，生成符号约束和方程，生成并参数化仿真代码，并通过评论驱动的反馈迭代优化设计，包括符号回归和几何距离度量，从而形成可操作的自然语言/符号优化循环。", "innovation": "创新点在于实现了受控代理规划与推理方法，特别是在自然语言规定设计任务的情况下，通过生成符号约束和方程，进行仿真代码的生成和参数化，利用批评反馈和迭代优化设计过程，包括符号回归和几何距离度量，并构建了一个名为MSynth的基准测试，用于评测该方法。同时，通过符号回归提示提供了更深层次的机制洞察，特别是在使用较大模型或适合的归纳偏差（如LRM）时。", "conclusion": "系统能够通过批评反馈和迭代优化显著提高设计性能（单个任务改进高达90%），并通过威尔科克森符号秩检验显示出统计上的显著进步。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11031", "html_url": "https://arxiv.org/abs/2506.11031", "title": "预填充的回答增强AI生成图像的零样本检测", "title_en": "Prefilled responses enhance zero-shot detection of AI-generated images", "authors": "Zoher Kachwala,Danishjeet Singh,Danielle Yang,Filippo Menczer", "background": "随着AI模型生成越来越逼真的图像，人们对潜在滥用的担忧日益增加，这凸显了需要可靠检测的重要性。传统监督检测方法依赖大规模、精心策划的训练数据集，通常无法适应新颖的、跨领域的图像生成器。作为替代方案，我们探索预训练的视觉-语言模型（VLM）在零样本检测AI生成图像中的应用。", "innovation": "我们通过简单的方法——预填充，引导VLM的推理，提出了一种名为Prefill-Guided Thinking (PGT)的方法。具体来说，预填充VLM响应，使之与任务对齐的短语 “让我们检查风格和合成伪影” ，能够显著提高三种广泛使用的开源VLM的宏划分F1分数，最高提升达24%。", "conclusion": "研究结果表明，预填充可以有效地指导VLM推理，提高其在多种基准测试中检测AI生成图像的效果。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00320", "html_url": "https://arxiv.org/abs/2506.00320", "title": "Dyna-Think: 在AI代理中融合推理、行动和世界模型模拟", "title_en": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "authors": "Xiao Yu,Baolin Peng,Ruize Xu,Michel Galley,Hao Cheng,Suman Nath,Jianfeng Gao,Zhou Yu", "background": "近年来，大语言模型（LLMs）如DeepSeek-R1在数学和编程等领域展示了出色的推理能力，表现出了复杂的认知行为，如验证、目标分解和自我反思。然而，对于远期AI代理任务来说，尚不清楚哪些行为是有效的，哪些是缺失的。", "innovation": "本文提出了Dyna-Think，一种结合计划与内部世界模型的推理框架，通过引入Dyna-Think模仿学习（DIT）和Dyna-Think Dyna训练（DDT），增强了AI代理的表现。DIT重建了R1的思考过程，专注于与提议和规划动作相关的模拟世界模型的仿真，通过重建的数据训练策略。DDT通过两阶段训练过程首先提高代理的世界建模能力，然后通过策略训练改进代理的行动。", "conclusion": "在OSWorld和WindowsAgentArena上的实验表明，Dyna-Think提高了代理的领域内和领域外性能，平均生成的令牌量比R1少2倍，而达到类似的最优性能。广泛的实证研究表明，使用批评生成进行世界模型训练有效，能够提高策略性能；并且性能更好的代理关联着更好的世界建模能力。研究结果表明将世界模型模拟集成到AI代理中来增强其推理、规划和行动能力的潜在研究方向。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17686", "html_url": "https://arxiv.org/abs/2506.17686", "title": "通过预训练自我监督语音模型提升少量样本关键词识别性能", "title_en": "Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models", "authors": "Alican Gok,Oguzhan Buyuksolak,Osman Erman Okman,Murat Saraclar", "background": "关键词识别对于电池供电的边缘设备实现免提交互至关重要。现有的少量样本关键词识别（FS-KWS）系统在资源受限的边缘环境中，尤其是在低错误接受率的情况下，识别准确率较差。为了克服这些局限性，本文提出了一个采用自我监督学习模型的训练方案，用于实现鲁棒特征提取、降维和知识蒸馏。接着介绍了注意力机制下的降维策略，并训练了一个标准轻量级的ResNet15学生模型，以确保在边缘设备上的高效部署。实验在英文部分的Multilingual Spoken Words Corpus (MSWC) 和 Google Speech Commands (GSC) 数据集上进行。", "innovation": "本文提出了一种新颖的训练方案，利用自我监督学习模型增强特征提取的鲁棒性，实现降维和知识蒸馏。通过一种基于Sub-center ArcFace损失函数的教师模型，改善了类内紧凑性和类间可分性。为了在边缘设备上实现高效部署，引入了基于注意力机制的降维方法，并训练了一个标准轻量级的ResNet15学生模型。该方案在Google Speech Commands (GSC) 数据集上显著提升了10-shot分类准确率，从33.4%提高到74.1%，在1%的误报率下涵盖了11个类别，展示了在实际场景中的优越性。", "conclusion": "提出的训练方法和解决方案显著提升了少量样本关键词识别的性能，特别是在资源受限的边缘环境中。该方法在多个数据集上进行了验证，展示了其有效性和实用性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL：探索事实导向的强化学习", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），特别是在较慢的思考模型中，常常表现出严重的幻觉现象，因为它们在推理过程中无法准确识别知识边界。尽管强化学习（RL）可以增强复杂的推理能力，但其目标导向的奖励机制往往缺乏对思考过程的实际监督，进一步加剧了幻觉问题。", "innovation": "该论文提出了一种知识增强的强化学习方法——KnowRL。KnowRL通过将基于知识验证的事实性奖励整合到RL训练过程中，指导模型进行基于事实的缓慢思考，帮助模型识别知识边界。这种方法在强化学习训练期间提供有针对性的事实输入，使模型能够学习并内化基于事实的推理策略。通过直接奖励在推理步骤中遵循事实的行为，KnowRL培养了一个更可靠的思想过程。实验结果表明，KnowRL有效地减少了慢思考模型中的幻觉现象，同时保持了其原有的强大推理能力。", "conclusion": "在三个幻觉评估数据集和两个推理评估数据集上的实验结果表明，KnowRL有效地减少了慢思考模型中的幻觉现象，同时保持了其原有的强大推理能力。研究代码可在以下网址获取。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19333", "html_url": "https://arxiv.org/abs/2507.19333", "title": "向推理过程注入外部知识可以增强检索增强生成", "title_en": "Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation", "authors": "Minghao Tang,Shiyu Ni,Jiafeng Guo,Keping Bi", "background": "检索增强生成（RAG）已被广泛用于通过外部知识增强大型语言模型（LLMs），以应对知识密集型任务。然而，其效果往往会受到低质量检索片段（即，嘈杂片段）的影响。因此，增强LLMs对这种噪声的鲁棒性对提高RAG系统的可靠性至关重要。最近的研究已经增强了LLMs的推理和自我反省能力，使它们能够识别和纠正其推理过程中的错误。基于此能力，本文提出了一种简单而有效的方法——片段注入，该方法明确将检索片段融入到LLMs的推理过程中，旨在增强模型识别和抵御嘈杂片段的能力。", "innovation": "本文提出了一种简单而有效的方法——片段注入，它明确将检索片段融入到LLMs的推理过程中，以增强模型识别和抵御嘈杂片段的能力。此方法在使用BM25作为检索器的一般RAG设置下进行了验证，并在四个增强推理的LLM上对四个事实问答数据集进行了实验，证明片段注入显著提高了整体RAG性能。进一步分析嘈杂的检索设置表明，片段注入可以一致地提高系统的鲁棒性。", "conclusion": "这些发现表明，在LLMs的推理过程中纳入片段是构建更稳健的RAG系统的有前景的方向。此代码可以在这里找到：,herehttpsURL。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02298", "html_url": "https://arxiv.org/abs/2508.02298", "title": "CAPO: 通过生成式信用分配提高LLM推理能力", "title_en": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit Assignment", "authors": "Guofu Xie,Yunsheng Shi,Hongtao Tian,Ting Yao,Xiao Zhang", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 方法通过基于规则的二进制反馈改善了大型语言模型 (LLMs) 的推理能力。然而，当前的RLVR方法通常对每个令牌赋予相同的奖励，这种粗粒度的反馈妨碍了精确的回报分配，使得模型难以识别哪些推理步骤导致成功或失败，通常导致次优策略。像PPO这样的方法通过价值估算提供信用分配，但由于有限的采样仅提供不准确且不可验证的信号。使用过程奖励模型的方法可以提供步骤级别的奖励，但存在关键限制：需要高质量的过程监督标签，反馈由于概率性奖励建模而可靠性低，这种方法在线强化学习中的应用耗时较长。", "innovation": "我们提出了一种简单但有效的方法——信用分配策略优化 (CAPO)。CAPO 直接利用标准的通用语言模型作为生成过程奖励模型 (LLM-as-GenPRM)，通过一次生成依据步骤正确性的所有步骤级评语，提供确定性的令牌级信用，以调整原本被赋予相同规则奖励的令牌。此外，我们应用随生成评语数量增加而扩展的投票机制进一步提高了准确性和鲁棒性。在各种基础模型（如 Llama 和 Qwen）上的广泛实验表明，CAPO 无论是在四个复杂数学基准测试中，还是在三个领域外基准测试中，都始终优于基于监督学习和基于强化学习的微调方法。进一步分析显示，CAPO 能够帮助模型加强正确推理路径的学习，使其能够产生正确的答案。", "conclusion": "CAPO方法通过生成式信用分配显著提高了LLMs在复杂数学和其他领域的推理能力。对比现有方法，其利用标准的通用语言模型直接生成步骤级评语，提供确定性令牌级信用，并通过投票机制增强准确性和鲁棒性。CAPO的方法既简化又高效，显著优于现有的监督学习和基于强化学习的微调方法。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.18665", "html_url": "https://arxiv.org/abs/2508.18665", "title": "LLM基推荐系统中的类别推测攻击", "title_en": "Membership Inference Attacks on LLM-based Recommender Systems", "authors": "Jiajie He,Yuechun Gu,Min-Chun Chen,Keke Chen", "background": "基于大规模语言模型（LLMs）的推荐系统（RecSys）能够灵活地适应各个领域。这些系统通过上下文学习（ICL，即提示）来定制推荐功能，包括用户的历史项目交互信息，如点击记录或产品评论等敏感信息。然而，这些私密信息可能会遭受新型隐私攻击。尽管如此，尚无研究关注这一重要问题。因此，本文设计了四种类别推测攻击（MIAs），旨在揭示系统提示是否使用了受害者的历史交互信息，分别为直接问询、幻觉、相似性和污染攻击。研究在三个LLMs和两个知名RecSys基准数据集上详细评估了这些攻击效果，验证了LLM推荐系统中的类别推测攻击是现实威胁，其中直接问询和污染攻击表现尤为显著，影响因素分析也指出系统提示中样本数和受害者位置的影响显著。", "innovation": "本文首次针对基于LLM的RecSys进行了类别推测攻击的研究，设计了四种针对LLM推荐系统的攻击方法：直接问询、幻觉、相似性和污染攻击，并详细评估了这些攻击的效果和影响因素，填补了该领域的空白，有助于提高LLM推荐系统的安全性和隐私保护水平。", "conclusion": "基于LLM的推荐系统中的类别推测攻击是现实威胁，特别是直接问询和污染攻击表现出显著优势。此外，系统提示中的样本数和受害者的位置等因素显著影响攻击效果，应采取相应措施提升系统的安全性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04072", "html_url": "https://arxiv.org/abs/2510.04072", "title": "慢速-快速策略优化：更新前重定位用于LLM推理", "title_en": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning", "authors": "Ziyan Wang,Zheng Wang,Jie Fu,Xingwei Qu,Qi Cheng,Shengpu Tang,Minjia Zhang,Xiaoming Huo", "background": "强化学习(RL)已成为提升大型语言模型(LLMs)推理能力的核心。然而，如Group Relative Policy Optimization (GRPO)等在线策略算法常在训练初期表现不佳：低质量的滚动让梯度充满噪声，导致更新不稳定和探索效率低下。", "innovation": "提出了一种简单高效的慢速-快速策略优化(SFPO)框架，通过将每一步拆分为三个阶段来解决上述问题：短的快速内步轨迹，控制策略漂移的定位机制，以及最终的缓慢纠正。这种更新前重新定位的设计使SFPO在保留目标和滚动过程不变的情况下，与现有的策略梯度管道无缝兼容。实验表明，SFPO能够提高稳定性，减少滚动次数，并加速推理RL的收敛速度，与GRPO相比在数学推理基准上平均高出2.80分，并且能够减少高达4.93倍的滚动次数和4.19倍的墙钟时间以达到相同的效果。", "conclusion": "SFPO在推理RL训练中展示了更好的性能，具体来说，在数学推理基准测试中，它超越了GRPO最多2.80个点；在滚动次数上最多减少4.93倍，并且减少了高达4.19倍的墙钟时间从而达到与GRPO相同的最佳准确率。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 一种多领域物体检测基准数据集用于视觉语言模型", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉语言模型（VLMs）在互联网规模的数据上进行训练后，在检测建筑物、车、行人等常见物体方面表现出了惊人的零样本识别能力。然而，这些最先进的模型在泛化到预先训练阶段通常不包含的新类别、任务和成像模式方面仍然存在困难。因此，不是仅通过重新训练这些模型以获取更多视觉数据，作者认为应通过包含少量视觉示例和丰富文本描述的注解指令，来对这些模型进行重新校准以适应新概念。黑客罗布流量100-VL（Roboflow100-VL）引入了一种大型多模式物体检测数据集集合，包含多样化的概念，这些概念在VLM的预训练中并不常见", "innovation": "作者提出了Roboflow100-VL，这是一种大型多模式物体检测数据集，包含新概念，这些概念在视觉语言模型（VLMs）的预训练数据中不常见。通过对最新的模型在该基准上的评估，发现即使在零样本设置中，对于具有挑战性的医学成像数据集，最先进的模型GroundingDINO和Qwen2.5-VL的准确率也低于2%，这表明通过少量示例进行概念对齐的必要性。此数据集允许不同数据条件下的对比评估，包括零样本、少样本、半标注和完全标记。Roboflow100-VL将为空泛物体检测提供全新的基准数据集和挑战", "conclusion": "研究表明，视觉语言模型在面对非传统任务和数据集时表现为初级水平，需要通过少量示例对齐模型。未来可以进一步在该数据集上训练模型，以提升视觉语言模型在多领域物体检测任务中的表现。论文还介绍了其CVPR 2025年基线FSOD竞赛，并分享了来自社区的见解。获胜团队在该基准上实现了比基线高出17 mAP的显著成果。开源的代码和数据集可在指定的链接中找到。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05465", "html_url": "https://arxiv.org/abs/2510.05465", "title": "VAL-Bench：测量语言模型的价值对齐", "title_en": "VAL-Bench: Measuring Value Alignment in Language Models", "authors": "Aman Gupta,Denny O'Shea,Fazl Barez", "background": "大型语言模型（LLMs）越来越多地用于影响人类决策的任务，因此确保其响应反映一致的人类价值观变得至关重要。现有的基准测试主要关注拒绝或预定义的安全违规行为，这些测试仅检查规则遵守情况，但不能揭示模型在面对具有争议的现实世界问题时是否维护了一致的价值体系。因此，需要一种新的基准测试来评估模型在不同框架下保持一致价值立场的能力。", "innovation": "提出了一种新的基准测试——Value ALignment Benchmark（VAL-Bench），用于评估模型在不同对手辩论框架下是否保持一致的价值立场。VAL-Bench 包含来自维基百科争议部分的115K对匹配的提示。通过一种LLM作为评判者的工具，来评估模型的配对回应之间的一致性或差异性，以衡量其价值对齐程度。基准测试揭示了领先的语言模型（开源和闭源）之间在价值对齐上的巨大差异，并强调了哪些安全策略（例如，拒绝）与更加丰富的价值体系之间的权衡。", "conclusion": "VAL-Bench 提供了一种可扩展、可重现的基准测试，允许系统地比较不同LLM如何可靠地体现人类价值观。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01611", "html_url": "https://arxiv.org/abs/2510.01611", "title": "PsychoBench：评估大型语言模型的心理智能", "title_en": "PsychoBench: Evaluating the Psychology Intelligence of Large Language Models", "authors": "Min Zeng", "background": "大型语言模型（LLMs）已经在多个行业中展现出卓越的成功，主要是由于其强大的生成能力。然而，其在需要认知能力的应用领域的潜力，如心理辅导，尚未得到充分开发。本文探索的关键问题是：LLMs能否有效应用于心理辅导？为了确定LLMs是否能承担心理咨询师的角色，第一步是评估它们是否满足该角色所需的资质，即通过美国国家心理咨询师认证考试（NCE）。为了实现这一目标，研究引入了一套名为PsychoBench的基准测试，该测试基于专业心理咨询师执照考试，通过率为70%左右。PsychoBench包含了约2252道精心挑选的单选题，这些问题不仅需要深入了解，还要涵盖心理学的各种子学科。这项基准测试全面评估了LLMs作为心理咨询师的能力。评价结果显示，GPT-4o、Llama3.3-70B和Gemma3-27B等先进模型超过了及格线，而较小的开源模型（如Qwen2.5-7B、Mistral-7B）则远远未达到及格线。这些结果表明，只有最新的LLMs才有可能达到心理咨询考试标准，这既揭示了开发心理学方向的LLMs的希望，也揭示了挑战。", "innovation": "本文创新地引入了PsychoBench作为评估LLMs心理智能的新基准，该基准基于专业心理咨询师执照考试，涵盖了心理学的各种子学科，全面评估了LLMs作为心理咨询师的能力。此外，研究表明，只有一些前沿的LLMs能够达到心理咨询考试的标准，这为心理智能LLMs的发展提供了重要的见解，也指出了当前的研究重点和未来改进的方向。", "conclusion": "研究结果表明，只有最先进的LLMs才能满足心理咨询考试的标准。这项工作不仅展示了LLMs的发展潜力，同时也指出了当前存在的挑战。未来的研究需要进一步探索如何提高其他LLMs的心理智能，以实现更广泛的应用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06229", "html_url": "https://arxiv.org/abs/2510.06229", "title": "自主铁路运营中的里程碑确定", "title_en": "Milestone Determination for Autonomous Railway Operation", "authors": "Josh Hunter,John McDermid,Simon Burton,Poppy Fynes,Mia Dempster", "background": "铁路自动化领域的关键挑战之一是开发有效的计算机视觉系统，因为高质量的序列数据稀缺。传统数据集范围有限，缺乏用于实时决策的空间时间上下文，而替代解决方案则面临现实性和适用性的问题。通过关注特定路线、上下文相关线索，可以生成更丰富的序列数据集，更贴近现实运营逻辑。", "innovation": "里程碑确定的概念能够开发针对性的规则基模型，简化学习过程，通过排除对动态组件的泛化识别，专注于路线中的关键决策点，为在受控和可预测环境中训练视觉代理提供实用框架，促进更安全、更高效的铁路自动化机器学习系统。", "conclusion": "通过这种方法，可以为铁路自动化提供一种实用框架，从而简化学习过程并提高系统的安全性和效率。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06231", "html_url": "https://arxiv.org/abs/2510.06231", "title": "CML-Bench：评估和提升LLM驱动电影脚本生成框架", "title_en": "CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation", "authors": "Mingzhe Zheng,Dingjie Song,Guanyu Zhou,Jun You,Jiahao Zhan,Xuran Ma,Xinyuan Song,Ser-Nam Lim,Qifeng Chen,Harry Yang", "background": "大型语言模型（LLMs）展示了生成高度结构化文本的卓越能力，但在处理需要细腻叙事和情感深度（‘电影的灵魂’）的电影剧本时，往往难以捕捉这些关键特征。为了研究这一点，作者创建了一个CML数据集，包含电影标记语言（CML）的摘要和内容对，通过深入分析这些正宗剧本中的内在多层次连续性和叙事结构，提取出三个关键维度进行质量评估：对话一致性（DC）、角色一致性（CC）和情节合理性（PR）。", "innovation": "提出了CML-Bench，这是一个对这些关键维度使用定量指标的基准，能够评估优质的手工编写脚本，同时揭示由LLMs生成的剧本中的弱点。进一步证明了CML-Bench的有效性，并引入了CML-Instruction，这是一种详细的指示策略，用于引导LLMs生成更结构化且具电影性的剧本，从而证明了指导生成的脚本质量更高，更符合人类偏好.", "conclusion": "通过实验证明CML-Bench的有效性，并展示了使用CML-Instruction指导的脚本生成质量更高，结果符合人类偏好，从而提升LLMs在生成高质量电影剧本方面的表现."}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06238", "html_url": "https://arxiv.org/abs/2510.06238", "title": "使用MC Dropout进行表层地雷和UXO分类的不确定性量化", "title_en": "Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout", "authors": "Sagar Lekhak,Emmett J. Ientilucci,Dimah Dera,Susmita Ghosh", "background": "利用深度学习检测地表的地雷和未引爆弹药（UXOs）在人道主义拆弹方面显示出潜力。然而，确定性的神经网络在面对噪声条件和对抗攻击时容易出错，导致检测遗漏或分类错误。现有的神经网络在拆弹中面临对抗威胁的脆弱性需要引起重视，因此开发更具鲁棒性和可靠性的模型对于实际应用至关重要。", "innovation": "引入了通过蒙特卡洛（MC）丢弃法进行不确定性量化的方法，将其集成到经过微调的ResNet-50架构中，用于表层地雷和UXO分类，并在模拟数据集上进行了测试。这种方法有助于量化基于模型知识的不确定性，提供了一个额外的可靠性预测指标，这有助于在拆弹操作中做出更明智的决策。实验结果表明，该模型在干净、对抗干扰和噪声图像上都能识别出在复杂条件下不可靠的预测。", "conclusion": "该概念验证研究突显了在拆弹中进行不确定性量化的重要性，提高了人们对拆弹中现有的神经网络对抗威胁脆弱性的认识，并强调了开发更鲁棒和可靠模型的必要性，以满足实际应用需求。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06233", "html_url": "https://arxiv.org/abs/2510.06233", "title": "用户到视频：一种基于视频分类技术的垃圾信息发布者检测模型", "title_en": "User to Video: A Model for Spammer Detection Inspired by Video Classification Technology", "authors": "Haoyang Zhang,Zhou Yang,Yucai Pang", "background": "该研究受到视频分类技术的启发。将用户行为子空间看作是帧图像，将连续帧图像看作是视频。基于这一创新思想，提出了一种基于用户视频化的垃圾信息发布者检测模型UVSD（User Videoization-Based Spammer Detection）。", "innovation": "提出了用户到像素（user2pixel）算法来进行用户像素化，考虑了用户立场的对抗行为，将用户的立场量化为像素的RGB值；提出了行为到图像（behavior2image）算法将用户行为子空间转换为帧图像；通过低秩稠密向量化和帧图像化的方法，构建了用户行为视频，并结合视频分类算法来识别垃圾信息发布者。", "conclusion": "使用公开数据集WEIBO和TWITTER进行实验，结果表明UVSD模型优于现有最先进的方法。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06254", "html_url": "https://arxiv.org/abs/2510.06254", "title": "提高高效的脉冲神经网络训练的增强自我蒸馏框架", "title_en": "Enhanced Self-Distillation Framework for Efficient Spiking Neural Network Training", "authors": "Xiaochen Zhao,Chengting Yu,Kairong Yu,Lei Liu,Aili Wang", "background": "脉冲神经网络(SNNs)因稀疏激活模式在类脑硬件上表现出极佳的能耗效率。然而，基于替代梯度的传统训练方法和通过时间反向传播(BPTT)不仅在性能上落后于人工神经网络(ANNs)，还伴随着随着时间维度增长的显著计算和内存开销。", "innovation": "本文提出了一种增强的自我蒸馏框架，该框架与基于计数的反向传播联合优化，通过将中间SNN层的放电率投影到轻量级的ANN分支上，并利用模型自身生成的知识优化子结构来完成优化。此外，研究者还分开了教师信号为可靠和不可靠组件，确保仅使用可靠的知识指导模型优化。", "conclusion": "我们的方法在不增加训练复杂性的同时，实现了高效率的SNN训练。该方法已经在CIFAR-10、CIFAR-100、CIFAR10-DVS和ImageNet上进行了广泛的实验验证。相关的代码可以在 provided website 获取。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06260", "html_url": "https://arxiv.org/abs/2510.06260", "title": "融合深度学习和大语言模型辅助报告的自动化皮肤病变诊断", "title_en": "Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis", "authors": "Sher Khan,Raz Muhammad,Adil Hussain,Muhammad Sajjad,Muhammad Rashid", "background": "皮肤恶性肿瘤需要早期检测以实现有利的结果，但当前的诊断方法存在观察者间变异性和可访问性不足的问题。尽管人工智能展现出了潜力，现有皮肤科系统受到单一化架构、跨肤色数据集偏见以及将自然语言处理视为独立的后续解释而非临床决策过程的一部分的局限性。当前的诊断方法缺乏实际的临床效用。", "innovation": "该研究提出了一个统一的框架，以重新构想人工智能在皮肤科诊断中的集成。通过结合一个构成多样化的卷积神经网络集合，提供互补的诊断视角，并整合大型语言模型的能力到诊断流程中，将分类结果转化为临床相关的评估。这种方法不仅满足医疗记录要求，还为患者提供了中心化的教育。新颖之处在于其融合了异构网络和大型语言模型，确保诊断的准确性和临床应用的衔接，同时提供详细的诊断报告，帮助患者在就诊间识别潜在的警示信号，填补了之前AI实施的临床影响瓶颈。", "conclusion": "该框架是对可部署的皮肤科AI的重要进步，增强了诊断精度并积极支持从初次发现到患者教育的整个护理连续过程，最终提高了对皮肤病变更早干预的益处。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06273", "html_url": "https://arxiv.org/abs/2510.06273", "title": "振动转换器用于暂态噪声分类", "title_en": "Vision Transformer for Transient Noise Classification", "authors": "Divyansh Srivastava,Andrzej Niedzielski", "background": "LIGO数据中的瞬态噪声（glitches）会阻碍引力波的检测。Gravity Spy项目已经将这些噪声事件分成了多个类别。随着O3运行的进行，加入了两种额外的噪声类别，需要训练新的模型来有效分类。", "innovation": "使用预训练的Vision Transformer (ViT)模型对包含Gravity Spy数据集和O3a运行中新增的两类噪声的数据集进行训练。达到了92.26%的分类效率，展示了Vision Transformer在提高引力波检测准确性方面的潜力。", "conclusion": "Vision Transformer能够有效地区分暂态噪声，从而提高引力波检测的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06241", "html_url": "https://arxiv.org/abs/2510.06241", "title": "multimodars：一种基于Rust的多模态心脏影像融合与配准工具", "title_en": "multimodars: A Rust-powered toolkit for multi-modality cardiac image fusion and registration", "authors": "Anselm W. Stark,Marc Ilic,Ali Mokhtari,Pooya Mohammadi Kazaj,Christoph Graeni,Isaac Shiri", "background": "文章背景提到，结合互补成像模态是建立可靠3D冠状动脉模型的关键。虽然血管内成像可以提供亚毫米级分辨率，但无法提供完整血管的整体上下文；而CT血管造影（CCTA）虽然提供3D几何结构，但受到空间分辨率低和伪影（如扩散）的限制。尽管早期的工作展示了血管内成像与CCTA的融合，但仍未有一个面向多状态（休息/压力，术前/术后）分析的开源、灵活的工具包，能够在确定行为、高性能和易于流水线集成的条件下工作。文章指出，现有的工具并未完全满足这些需求，尤其是在面向大规模、可重复实验方面有所欠缺。现有的数据格式大多为CSV和NumPy，这些数据可以由AIVUS-CAA软件生成。因此，需要一种新的工具来解决这些问题。", "innovation": "创新点在于multimodars提供了一种基于确定性对齐算法的解决方案，采用紧凑的基于NumPy的数据模型，并使用了优化过的Rust后端，以实现可扩展和可重复的实验。此外，它能够接受多种输入格式（包括由AIVUS-CAA生成的数据），并提供高效率和高性能的多模态影像融合与注册功能。", "conclusion": "总结而言，multimodars填补了多状态分析中对特定工具的需求空白，提供了确定性行为、高性能和易于整合的特点，特别适用于使用CSV和NumPy数据格式进行多模态心脏影像融合和配准的研究。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06096", "html_url": "https://arxiv.org/abs/2510.06096", "title": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining LLM Objectives", "title_en": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining LLM Objectives", "authors": "Matthieu Bou,Nyal Patel,Arjun Jagota,Satyapriya Krishna,Sonali Parbhoo", "background": "大型语言模型（LLMs）隐式优化的目标仍然非常不透明，使可信的对齐和审计成为一个巨大的挑战。尽管逆强化学习（IRL）可以从行为中推断奖励函数，但现有方法要么产生单一且过于自信的奖励估计，要么无法解决任务的基本不确定性和非识别性问题。这项研究旨在创建一个经过深思熟虑的审核框架，重新定义奖励推断为一种验证过程，利用贝叶斯逆强化学习不仅来恢复目标分布，还能够为审计能力提供重要支持，包括逐步减少非识别性、提供具有不确定性的诊断以及通过直接在RLHF中使用低不确定性奖励来验证政策级的效用，从而实现与真实对齐过程类似的效果。", "innovation": "该框架通过使用贝叶斯逆强化学习，不仅恢复了目标分布，还提供了三种关键的审计能力：（i）通过在几轮证据后展示后验收缩来量化和系统地减少非识别性；（ii）提供具有行动指南和不确定性的诊断，以发现无效的捷径并识别不可信任的提示；（iii）通过直接使用精细化和低不确定性的奖励来验证政策级效用，从而在RLHF中实现与真实对齐过程相似的训练动态和毒性降低效果。这些创新使审核过程更加可靠和有针对性", "conclusion": "本研究成功地审查了一个去毒的LLM，产生了一个校准良好且可解释的目标，加强了对齐保证。整体上，该工作为审核人员、安全团队和监管机构提供了一个实用的工具包，帮助验证LLM真正追求的目标，使我们向更可信和负责任的人工智能迈进。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06251", "html_url": "https://arxiv.org/abs/2510.06251", "title": "物理学知识在前沿模型中是否涌现？", "title_en": "Does Physics Knowledge Emerge in Frontier Models?", "authors": "Ieva Bagdonaviciute,Vibhav Vineet", "background": "当前的视觉-语言模型（VLMs）在视觉感知和一般推理方面表现出色，但在理解和预测物理动态方面的能力尚不清楚。为了深入了解这一点，该研究在三个物理模拟数据集(CLEVRER、Physion 和 Physion++)上对六种前沿的 VLMs 进行了基准测试，以评估模型能否预测结果或推测替代情况。通过设计诊断子测试，该研究隔离了感知（物体、颜色、遮挡物）和物理推理（运动预测、空间关系），结果显示更强的诊断性能并不一定能带来更好的评估准确性。这一结果揭示了当前 VLMs 的一个核心局限：感知和物理技能是碎片化的，无法结合形成因果理解，从而强调了需要更紧密绑定感知和推理的架构的重要性。", "innovation": "该研究在物理模拟数据集上对标前沿的视觉-语言模型，通过设计诊断子测试来分别测试感知和物理推理能力，揭示了当前VLMs在将感知和物理推理技能整合为因果理解方面的能力较弱，提出需要更紧密绑定感知和推理的架构来解决这一问题。", "conclusion": "当前的视觉-语言模型在感知和物理推理方面的能力是碎片化的，无法结合形成因果理解，因此需要新的架构来更紧密地绑定感知和推理。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06277", "html_url": "https://arxiv.org/abs/2510.06277", "title": "通用且高效的视觉目标条件强化学习：基于物体无关的掩码", "title_en": "General and Efficient Visual Goal-Conditioned Reinforcement Learning using Object-Agnostic Masks", "authors": "Fahim Shahriar,Cheryl Wang,Alireza Azimi,Gautham Vasan,Hany Hamed Elanwar,A. Rupam Mahmood,Colin Bellinger", "background": "目标条件的强化学习（GCRL）允许代理使用统一策略学习多种目标。然而，GCRL的成功取决于目标表示的选择。现有的目标表示方法，如目标状态图像、3D坐标和一热向量，存在对未见过的对象泛化能力差、收敛速度慢和需要特殊摄像头等问题。", "innovation": "本文提出了一种基于掩码的目标表示系统，为代理提供与物体无关的视觉提示，从而实现高效的学习和优越的泛化能力。该方法通过处理掩码生成密集奖励，避免了繁琐的距离计算。通过模拟中使用真实掩码进行训练，实验结果显示目标物品的达到准确率为99.9%，并且在未见过的对象上也能达到高准确率。此外，该方法能够无需目标位置信息准确执行捡取任务，并且可以实现实时数据转移学习，利用预训练的开放式词汇物体检测模型生成掩码。", "conclusion": "本研究提出了基于物体无关的掩码在视觉目标条件的强化学习中的应用，实现了通用且高效的视觉GCRL，展示了该方法在模拟和真实物理机器人上的零样本学习和模拟到现实世界转换的能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06281", "html_url": "https://arxiv.org/abs/2510.06281", "title": "使用深度学习提高GONG太阳图像的空间分辨率至GST质量", "title_en": "Improving the Spatial Resolution of GONG Solar Images to GST Quality Using Deep Learning", "authors": "Chenyang Li,Qin Li,Haimin Wang,Bo Shen", "background": "高分辨率(HR)太阳成像对于捕捉细尺度动态特征，如日珥和纤维状结构至关重要。然而，太阳全盘Hα图像的空间分辨率有限，无法分辨这些小尺度结构。现有方法无法有效提高低分辨率(LR)全盘Hα图像的质量，使其与Big Bear Solar Observatory/Goode Solar Telescope (BBSO/GST)的高分辨率观测图像质量媲美.", "innovation": "文章提出了一种基于生成对抗网络(GAN)的超分辨率方法，利用Real-ESRGAN模型（带有残差-残差密集块和相对判别器）从Global Oscillation Network Group (GONG)的数据中提升低分辨率的全盘Hα图像至与BBSO/GST高分辨率观测图像质量相当。通过仔细对齐GONG-GST成对图像，模型能够有效恢复日斑笔段内的细细节，并辨别日珥和纤维的细细节，实现了平均均方误差(MSE)为467.15，均方根误差(RMSE)为21.59，相关系数(CC)为0.7794等定量指标.", "conclusion": "尽管存在一定图像对齐偏差，对定量性能产生一定的影响，作者计划在未来的更新工作中解决这一问题，并通过扩展数据集进一步提高重建质量。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06295", "html_url": "https://arxiv.org/abs/2510.06295", "title": "基于意识幻觉损失和自适应拼接的高效高分辨率图像编辑", "title_en": "Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling", "authors": "Young D. Kwon,Abhinav Mehrotra,Malcolm Chadwick,Alberto Gil Ramos,Sourav Bhattacharya", "background": "高分辨率（4K）图像到图像合成对于移动应用程序变得越来越重要。现有的图像编辑扩散模型在资源受限的设备上面临显存和图像质量方面的重大挑战。", "innovation": "提出了MobilePicasso系统，该系统能够在高分辨率下高效进行图像编辑，同时最小化计算成本和内存使用。MobilePicasso包括三个阶段：(i) 在标准分辨率下使用意识幻觉损失进行图像编辑；(ii) 应用潜空间投影以克服向像素空间转换的问题；(iii) 通过自适应上下文保持拼接将编辑后的图像潜空间放大到更高分辨率。该方法在用户研究中表现优异，既提高了图像质量，又减少了幻觉现象，且在运行时延迟显著降低，大幅提升运行效率，只有微小的内存使用增加。", "conclusion": "MobilePicasso不仅改进了图像质量高达18-48%，减少了14-51%的幻觉，还展示了比服务器上的高分辨率图像编辑模型运行在A100 GPU上显著更低的延迟率，且通过9%的内存使用增加了运行时内存。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06298", "html_url": "https://arxiv.org/abs/2510.06298", "title": "使用变换器进行融合的RGBD注视跟踪", "title_en": "RGBD Gaze Tracking Using Transformer for Feature Fusion", "authors": "Tobias J. Bauer", "background": "本文的主题是利用包含色彩和深度信息的RGBD图像实现基于AI的注视跟踪系统。由于现有的深度信息较少或仅包含用于注视点估计的标签，而不是注视角度估计，因此创建了一个新的数据集来训练AI模型。利用变换器架构模块融合图像特征，结合RGBD输入图像和变换器，由于尚未进行过此方面的研究，因此选择这种组合。", "innovation": "提出了基于变换器模块的特征融合模型架构，该架构用于同时去除深度图中的伪影并提取头部姿态特征。此外，该论文通过使用不同的模型配置在三个不同的数据集上进行了训练、验证和评估，并通过实时管道估计眼前方的个体的凝视方向和凝视点。与先前的工作相比，采用变换器模块的模型在某些数据集上的均方误差有了显著改善。研究表明，使用变换器模块的模型在ShanghaiTechGaze+数据集上的均方误差为55.3mm，不使用预训练GAN模块时为30.1mm，而用多层感知器(MLP)替换变换器模块后误差降至26.9mm。", "conclusion": "该研究在三个不同数据集上测试了不同模型配置的表现，并成功在实时管道中估计出个体的眼球凝视方向和凝视点。虽然变换器模块在某些数据集上有较好的表现，但MLP模型在误差上有所改进，表现出更好的实际应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06308", "html_url": "https://arxiv.org/abs/2510.06308", "title": "Lumina-DiMOO: 全能扩散大型语言模型，用于多模态生成和理解", "title_en": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "authors": "Yi Xin,Qi Qin,Siqi Luo,Kaiwen Zhu,Juncheng Yan,Yan Tai,Jiayi Lei,Yuewen Cao,Keqi Wang,Yibin Wang,Jinbin Bai,Qian Yu,Dengyang Jiang,Yuandong Pu,Haoxing Chen,Le Zhuo,Junjun He,Gen Luo,Tianbin Li,Ming Hu,Jin Ye,Shenglong Ye,Bo Zhang,Chang Xu,Wenhai Wang,Hongsheng Li,Guangtao Zhai,Tianfan Xue,Bin Fu,Xiaohong Liu,Yu Qiao,Yihao Liu", "background": "介绍了一种新的开放源代码基础模型——Lumina-DiMOO，它能够实现无缝的多模态生成和理解。Lumina-DiMOO 通过使用完全离散的扩散建模方法来处理不同模态的输入和输出，打破了以往统一模型的局限性。与先前的自回归（AR）或混合 AR-Diffusion 方法相比，Lumina-DiMOO 能够实现更高的采样效率，并且能够支持多种多模态任务，如文本到图像的生成、图像到图像的生成（例如图像编辑、主题驱动生成、图像修复等），以及图像理解。该模型在多个基准测试中达到了最先进的性能。为了促进进一步的研究，作者发布了其代码和检查点给社区。", "innovation": "Lumina-DiMOO 采用了一种新的方法——完全离散的扩散建模，使它能够处理和生成不同模态的数据，并大大提高了采样效率。这种方法使其能够更好地支持多模态任务，且性能优于现有的开源多模态统一模型，尤其在多个基准测试中表现出色。", "conclusion": "Lumina-DiMOO 发布了其代码和检查点，促进了多模态和离散扩散模型的进一步研究。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06299", "html_url": "https://arxiv.org/abs/2510.06299", "title": "基于空间激光雷达和合成孔径雷达的全球森林结构复杂性可扩展深度融合", "title_en": "Scalable deep fusion of spaceborne lidar and synthetic aperture radar for global forest structural complexity mapping", "authors": "Tiago de Conto,John Armston,Ralph Dubayah", "background": "森林结构复杂性度量将多种林冠属性综合为一个反映栖息地质量和生态系统功能的单一值。全球生态系统动态调查（GEDI）的机载激光雷达数据能够在温带和热带森林中绘制结构复杂性图，但其稀疏采样限制了连续的高分辨率映射。为了克服这些限制，本文提出了一种可扩展的深度学习框架，该框架融合了GEDI观测与多模式合成孔径雷达（SAR）数据集，生成了全球高分辨率（25米）的森林结构复杂性地图。这种模型使用超过1.3亿个GEDI足迹训练的适配EfficientNetV2架构，仅需不到40万个参数即可实现高性能（全球R2 = 0.82），使得研究人员能够在任何规模下处理数据集，无需专门的计算基础设施。该模型能够产生准确的预测并提供校准的不确定性估计，保留了细尺度的空间模式。在2015年至2022年间，该模型被用来生成全球多时区的森林结构复杂性数据集。", "innovation": "本文提出了一种基于空间激光雷达和合成孔径雷达数据的可扩展深度学习框架，能生成全球高分辨率的森林结构复杂性地图。该模型采用了适配的EfficientNetV2架构，训练数据量大，参数量少，能够提供准确的预测和校准的不确定性估计，支持连续的多时点监测全球森林结构动态。该方法可以与少量计算成本进行转移学习，预测多种森林结构变量。这种框架为全球森林结构复杂性监测提供了强大的工具，同时也为生物多样性和生态系统管理提供了支持。", "conclusion": "本文提出的方法支持全球森林结构复杂性的连续多时点监测，并提供了用于生物多样性保护和生态系统管理的研究工具。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06292", "html_url": "https://arxiv.org/abs/2510.06292", "title": "ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations", "title_en": "ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations", "authors": "Yike Wu,Yiwei Wang,Yujun Cai", "background": "大型多模态模型（LVLMs）在多模态任务中表现出强大的性能，但它们可靠性受到幻觉现象的阻碍。关系幻觉是幻觉类型中占比最大的一种，但却是最受忽视的一种。这些幻觉主要来源于对象、属性和关系三个类别，而关系本身最为复杂且难以准确捕捉，因此需要专门的方法进行处理。过去的许多方法主要针对对象和属性进行改进，但对于关系的处理相对较少。这项研究旨在通过一种训练免费的方法，利用积累的文本和视觉记忆来提高关系推理的准确性，以减少关系幻觉的发生。", "innovation": "提出了ChainMPQ（Multi-Perspective Questions guided Interleaved Chain of Image and Text）方法，这是一种训练免费的方法，通过利用积累的文本和视觉记忆，增强关系推理。这种方法首先从问题中提取主语和宾语关键词，以增强相应的图像区域。然后构建多视角的问题，专注于关系的三个核心组件：主体、宾语和连接两者的关联。这些问题按顺序输入模型，早期文本和视觉记忆为后续步骤提供支持背景，形成交错的“图像-文本”链，指导逐步的关系推理。实验证明，ChainMPQ能够显著减少关系幻觉，同时消融研究进一步证实了其三个核心模块的有效性。", "conclusion": "ChainMPQ通过交错的“图像-文本”链和多视角问题，解决了关系幻觉问题，显著提高了LVLMs在关系推理中的准确性。该方法有效利用了积累的记忆，增强了模型的关系理解能力，通过实验证明，其具有明显的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06353", "html_url": "https://arxiv.org/abs/2510.06353", "title": "TransFIRA: 转移学习在面部图像可识别性评估中的应用", "title_en": "TransFIRA: Transfer Learning for Face Image Recognizability Assessment", "authors": "Allen Tu,Kartik Narayan,Joshua Gleason,Jennifer Xu,Matthew Meyn,Tom Goldstein,Vishal M. Patel", "background": "在监控、视频和网络图像等不受限制的环境中进行面部识别时，极端的姿态变化、模糊、光照和遮挡会导致性能下降，而传统的视觉质量评估指标无法准确预测这些输入是否能被部署的编码器正确识别。现有的图像质量评估（FIQA）方法通常依赖人工标注、视觉启发或计算密集型生成管道，使得它们的预测与编码器的决策边界脱节。已有方法难以构建一个与决策边界对齐的标准来评估面部图像的可识别性。", "innovation": "本文提出了TransFIRA（转移学习在面部图像可识别性评估中的应用）框架，这是一个轻量级且无需标注的框架，直接在嵌入空间中定义识别性。TransFIRA包含以下三个创新点：(i) 通过类别中心相似性(CCS)和类别中心角度分离(CCAS)定义识别性标准，为滤波和加权提供了首个自然、决策边界对齐的标准；(ii) 提出了一种基于识别性的聚合策略，该策略在BRIAR和IJB-C上的验证准确性达到最新水平，且几乎翻倍地提高了与真正识别性的相关性，这无需外部标签、启发式方法或特定的骨干训练；(iii) 新增了面部识别之外的应用，包括编码器导向的可解释性，揭示退化和个体因素如何影响识别性，以及首次提出的面向识别性的身体识别评估。实验结果证实了在面部识别上的最新水平、在身体识别上的强大性能以及在不同数据集之间的鲁棒性。", "conclusion": "本文得出TransFIRA作为一个统一的、几何驱动的识别性评估框架是实际可行和可推广的，其具有编码器特定性、准确性、可解释性和跨模态扩展性。这些贡献标志着在准确度、可解释性和范围上显著促进了图像质量评估（FIQA）领域的发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06469", "html_url": "https://arxiv.org/abs/2510.06469", "title": "SIGMA-GEN：结构和身份引导的多主体组装在图像生成中的应用", "title_en": "SIGMA-GEN: Structure and Identity Guided Multi-subject Assembly for Image Generation", "authors": "Oindrila Saha,Vojtech Krs,Radomir Mech,Subhransu Maji,Kevin Blackburn-Matzen,Matheus Gadelha", "background": "现有的图像生成方法在生成多主体图像时存在难以同时保持多个身份特征与结构约束的问题。研究者们通常需要多次生成和组合不同身份的信息，效率较低且难以保证生成的质量和性能。SIGMA-GEN框架旨在解决这一问题，通过单次生成实现多个主体的身份保留生成，并且能够根据不同级别的精度（从粗略的2D或3D框到像素级分割和深度）进行用户指导。该方法通过引入新的合成数据集SIGMA-SET27K，提供了超过10万独特主体的身份、结构和空间信息，支持在多主题生成中的应用和发展。", "innovation": "SIGMA-GEN是首个能够单次通过结构和空间约束进行多个身份保持生成的方法。它提供了一个统一的框架，用户可以根据自己的需求提供从粗略到细致的信息指导生成过程。此外，SIGMA-GEN通过引入SIGMA-SET27K数据集提高了数据的多样性和完整性，增强了生成图像的质量和速度。", "conclusion": "通过广泛的评估，SIGMA-GEN在身份保持性、生成图像质量和速度方面取得了最先进的性能。该研究为多主体图像生成领域带来了新的突破，提高了生成的效率和质量。项目代码和可视化成果已经发布，供学术界和其他研究者参考使用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06440", "html_url": "https://arxiv.org/abs/2510.06440", "title": "使用纽约州运输部摄像头图像和天气预报数据进行道路表面状况检测的机器学习方法", "title_en": "Road Surface Condition Detection with Machine Learning using New York State Department of Transportation Camera Images and Weather Forecast Data", "authors": "Carly Sutter,Kara J. Sulia,Nick P. Bassill,Christopher D. Wirz,Christopher D. Thorncroft,Jay C. Rothenberger,Vanessa Przybylo,Mariana G. Cains,Jacob Radford,David Aaron Evans", "background": "纽约州运输部（NYSDOT）拥有一个由路侧交通摄像头组成的网络，这些摄像头既用于NYSDOT，也用于公众观察路况。NYSDOT通过实地驾驶观察摄像头以评估路况，此任务虽然劳动密集但对冬季天气事件中的关键运营决策至关重要。然而，机器学习模型可以通过自动分类全州当前的路况，为NYSDOT提供额外支持。研究中使用卷积神经网络和随机森林模型，基于摄像头图像和天气数据来预测道路表面状况。模型在约22,000张由人工标记的摄像头图像上进行训练，每张图像都按照以下六种道路表面状况之一进行了分类：严重积雪、积雪、湿滑、干燥、能见度差或堵塞。模拟能够顺利地推广，以满足NYSDOT决策者运行中的需求，研究中的天气相关道路表面状况模型在完全未见过的摄像头数据上的准确率为81.5%。", "innovation": "本研究引入了通过卷积神经网络和随机森林模型使用机器学习方法来预测道路表面状况。模型在大量由人工分类的摄像头图像和天气数据上进行训练，提高NYSDOT冬季天气事件中作出关键运营决策的能力，并且在未见过的数据上达到了81.5%的高准确率。", "conclusion": "研究表明，机器学习方法可以有效支持NYSDOT进行道路表面状况的自动分类，提高了效率和准确性，满足了决策者的需求。该模型在完全未见过的摄像头数据上的高准确率表明该方法具有良好的泛化能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06460", "html_url": "https://arxiv.org/abs/2510.06460", "title": "TDiff：基于斑块扩散的低噪热图即时解决方案", "title_en": "TDiff: Thermal Plug-And-Play Prior with Patch-Based Diffusion", "authors": "Piyush Dashpute,Niki Nezakati,Wolfgang Heidrich,Vishwanath Saragadam", "background": "低成本热成像摄像头产生的热图像通常存在分辨率低、固定模式噪声以及其他局部退化问题。目前可用于热成像的数据集在规模和多样性上也存在局限。为解决这些问题，研究提出了一种基于斑块的扩散框架（TDiff），通过仅在小热图像斑块上进行训练来利用这些失真的局部特性，从而恢复全分辨率的热图像。该方法通过去噪重叠斑块并使用平滑的空间窗口进行融合实现了图像的恢复。TDiff是首个能够在多个任务中学习热图像恢复先验的基于斑块的扩散框架。在去噪、超分辨率和去模糊实验中，该方法在模拟和真实热数据上展示了强大的恢复结果，证明了其作为统一恢复管道的有效性。", "innovation": "提出了一种基于斑块的扩散框架（TDiff），专门用于热成像领域的图像修复。该方法不仅解决了低分辨率和噪声问题，还能够在多个任务中学习并建模热图像恢复的先验知识，填补了现有研究的空白。TDiff通过训练小热图像斑块，有效恢复了全分辨率热图，实现了在多项任务上的统一处理。", "conclusion": "实验结果表明，TDiff在热图像去噪、超分辨率和去模糊方面均表现出色，证明了其作为统一的恢复管道的有效性，同时是首个能够在多个任务中学习热图像恢复先验的基于斑块的扩散框架。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06487", "html_url": "https://arxiv.org/abs/2510.06487", "title": "超像素集成网格用于快速图像分割", "title_en": "Superpixel Integrated Grids for Fast Image Segmentation", "authors": "Jack Roberts,Jeova Farias Sales Rocha Neto", "background": "超像素长期以来被用来简化图像处理，以实现更高效的计算和存储。然而，由于超像素的空间布局不规则，使得深度学习方法需要依赖专门的训练算法和架构，这违背了采用超像素的初衷。", "innovation": "本文提出了一种新的基于超像素的数据结构SIGRID（Superpixel-Integrated Grid），用作分割任务中的替代高分辨率图像。SIGRID利用经典的形状描述符，编码了超像素的颜色和形状信息同时显著降低了输入维度。", "conclusion": "研究表明，尽管压缩了原始数据，SIGRID不仅能够达到与像素级表示相同的效果，甚至在某些情况下超过了其表现，并且显著加速了模型训练。这表明SIGRID在准确性与计算效率之间实现了良好的平衡。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06504", "html_url": "https://arxiv.org/abs/2510.06504", "title": "Text2Interact: 高保真度和多样性的两人交互文本生成", "title_en": "Text2Interact: High-Fidelity and Diverse Text-to-Two-Person Interaction Generation", "authors": "Qingxuan Wu,Zhiyang Dou,Chuan Guo,Yiming Huang,Qiao Feng,Bing Zhou,Jian Wang,Lingjie Liu", "background": "从文本中建模人类间的互动仍然是一个挑战，因为它不仅需要真实个体的动力学表现，还要求精确的时间和空间同步。当前的研究进展受到两方面限制：一是训练数据量不足，难以捕捉两人互动的多样化细节；二是文本到互动模型过于粗略，语言条件导致丰富的结构提示被简化为单一的句子嵌入。", "innovation": "我们提出了Text2Interact框架，旨在通过高保真度的交互数据合成器和有效的时空协调流水线，生成真实且与文本一致的人类互动。首先，我们提出了InterCompose，一种可扩展的合成-组合流水线，将大型语言模型生成的互动描述与强大的单人运动先验进行对齐。其次，我们提出了InterActor，一种带有词级条件的文本到互动模型，保留了标记级线索，并引入了自适应交互损失强调上下文相关的交互关节，提高了耦合度和物理可行性。实验结果显示，在多样性和泛化能力方面都有显著提高，包括在离分布场景和用户研究中。", "conclusion": "所提出的框架在运动多样性和保真度方面取得了持续的改进，包括在模型泛化能力方面的提升，并且为了促进可重复性，代码和模型将会公开。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06529", "html_url": "https://arxiv.org/abs/2510.06529", "title": "VUGEN: 视觉理解先验用于生成", "title_en": "VUGEN: Visual Understanding priors for GENeration", "authors": "Xiangyi Chen,Théophane Vallaeys,Maha Elbayad,John Nguyen,Jakob Verbeek", "background": "近年来，视觉-语言模型（VLMs）的发展使文本和图像的统一理解成为可能，但为这些模型装备稳健的图像生成能力仍具有挑战性。现有的方法经常依赖于重建导向的自编码器或复杂的桥梁机制，导致理解和生成表示之间的不一致，或者架构过于复杂。", "innovation": "本文提出了VUGEN，一种新型的框架，明确利用了VLM的预训练视觉理解先验，实现了高效和高质量的图像生成。该方法首先将VLM原生视觉编码器的高维潜在空间转化为一个较低维度且易于处理但仍能最大限度保留视觉信息的分布。然后，训练VLM在其减少的潜在空间内采样，以确保与其实体视觉理解能力的对齐。最后，使用专用像素解码器将生成的潜在表示映射回图像空间。结果表明，VUGEN使用一种无VAE像素扩散解码器，性能优于依赖VAE潜在空间的复杂潜扩散解码器。", "conclusion": "广泛的实验表明，VUGEN在图像生成性能上表现出优越性，使COCO的DPG Bench从71.17提高到74.32，FID从11.86降低到9.06，同时完全保留了VLM的原始理解能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06516", "html_url": "https://arxiv.org/abs/2510.06516", "title": "通过投影引导的3D扩散进行有限角度断层重建", "title_en": "Limited-Angle Tomography Reconstruction via Projector Guided 3D Diffusion", "authors": "Zhantao Deng,Mériem Er-Rafik,Anna Sushko,Cécile Hébert,Pascal Fua", "background": "有限角度电子断层照片技术旨在从透射电子显微镜（TEM）在限定的角度范围内获得的二维投影中重建3D形状，但由于缺失楔形问题导致严重重建伪影。尽管深度学习方法对此表现出希望，但它们通常需要大量高质量的训练数据集，这些数据集需要已知的3D真实情况，这在电子显微镜中难以获得。因此，本文旨在解决这些挑战。", "innovation": "本文提出了TEMDiff，一种新颖的基于3D扩散的迭代重建框架，该框架通过模拟器将可用的体积FIB-SEM数据映射到TEM倾斜系列中进行训练，从而使模型能够学习真实的结构先验。通过直接操作3D体积，TEMDiff隐式保证了切片之间的一致性，无需额外的正则化。在模拟的仅限角度覆盖的电子断层数据集中，TEMDiff在重建质量上优于最先进的方法。", "conclusion": "此外，我们还展示了训练后的TEMDiff模型在不同条件下的实际TEM倾斜情况中表现出良好的泛化能力，能够从狭窄的8度、2度增量的倾斜范围内恢复出准确的结构，无需重新训练或微调。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06512", "html_url": "https://arxiv.org/abs/2510.06512", "title": "LogSTOP：序列预测中的时间得分及其在匹配和检索中的应用", "title_en": "LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval", "authors": "Avishree Khare,Hideki Okamoto,Bardh Hoxha,Georgios Fainekos,Rajeev Alur", "background": "当前的神经模型（如 YOLO 和 HuBERT）能够检测视频和音频片段中的局部属性（如对象和情感），并通过得分 [0, 1] 表示这些检测的可能性。将这些局部属性的得分提升为序列的时间属性对于一些下游应用（如查询匹配和分段检索）来说是有用的。然而，在现实应用中，局部属性的得分可能存在噪声，因此需要一个方法来准确地为时间属性赋分。因此，本文旨在解决基于潜在噪声局部属性预测得分的时间属性赋分问题，并提出了一种新的评分函数 LogSTOP。LogSTOP 能够高效地计算序列中时间属性的得分，特别是在线性时序逻辑中表示时间属性时表现尤为出色。实验结果显示，LogSTOP 在涉及时间属性的查询匹配和排名检索任务上，相对于大型视觉/音频语言模型和其他基于时序逻辑的方法，性能提升了至少 16%。例如，在物体相关的视频查询匹配任务中，LogSTOP 与 YOLO 和 HuBERT 结合，与大型视觉/语言模型和其他基于时序逻辑的方法相比，精度提高了至少 16%；在涉及物体和动作的分段检索任务中，LogSTOP 与 Grounding DINO 和 SlowR50 结合，将零样本文本到视频检索基线的平均精度和召回率分别提高了至少 19% 和 16%。", "innovation": "本论文提出的 LogSTOP 是一种创新的评分函数，适用于线性时序逻辑中表示时间属性的序列，并能够有效处理潜在的局部属性噪声问题。LogSTOP 比现有的大型视觉/语言模型及基于时序逻辑的方法在时间属性匹配和检索任务上有显著提高，尤其是在查询匹配和分段检索场景中。", "conclusion": "本研究利用了局部属性预测的辅助信息来改进时间属性的分数分配，LogSTOP 通过有效地提高现有方法（如 YOLO 和 HuBERT）的时间属性匹配和检索性能，显著提升了其在这些应用场景中的表现。这种方法能够广泛应用于需要时间属性分析的应用场景，如视频检索、情感分析等。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.18234", "html_url": "https://arxiv.org/abs/2508.18234", "title": "AI是否有个性？通过提示工程模拟AI个性：一项关于性别认同嗓音疗法培训的聊天机器人案例研究", "title_en": "Can AI Have a Personality? Prompt Engineering for AI Personality Simulation: A Chatbot Case Study in Gender-Affirming Voice Therapy Training", "authors": "Tailon D. Jackson,Byunggu Yu", "background": "本研究探讨了是否可以通过提示工程引导大型语言模型（LLMs）模拟一致的人格特征。研究在言语语言病理学（SLP）学生的性别认同嗓音疗法训练聊天机器人中进行了探索，该聊天机器人名为Monae Jackson，代表了一位32岁的跨性别女性，并模拟了客户-治疗师互动。有研究表明，在合适的提示指引下，聊天机器人能够维持可识别且一致的人格特征，并基于大五人格测试展现出了独特的个性。", "innovation": "研究通过提示工程成功引导了聊天机器人模拟一致的人格特征，并展示了大五人格测试的能力，以此证明通过提示工程可以在AI聊天机器人中模拟稳定的人格特征。", "conclusion": "研究结果支持使用提示工程来模拟AI聊天机器人中的稳定人格特征，表明提示工程是一种有效的技术，可以为AI赋予个性，特别是在如性别认同嗓音疗法的特定应用中。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15174", "html_url": "https://arxiv.org/abs/2509.15174", "title": "SMARTER: 一种利用自我增强的大语言模型提高解释性有毒内容检测的高效框架", "title_en": "SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models", "authors": "Huy Nghiem,Advik Sachdeva,Hal Daumé III", "background": "社交媒体上的有毒内容泛滥，这对用户和平台造成了严重的影响。现有的解决方法通常依赖大量的手动标记数据，这在资源有限的环境下并不实用。", "innovation": "提出了SMARTER框架，这是一种利用大语言模型自身输出生成合成解释的两阶段数据高效方法。该框架在Stage1通过偏好优化减少人工监督，生成解释；在Stage2通过跨模型训练提高解释质量，使较弱模型更接近较强模型的风格和语义。", "conclusion": "实验表明，与标准的少量标记基线相比，SMARTER可以将macro-F1指标提高多达13.5%，同时仅使用少量的全部训练数据。该框架为资源有限的环境提供了可扩展的策略，利用大语言模型的自我改进能力进行分类和解释。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06564", "html_url": "https://arxiv.org/abs/2510.06564", "title": "HSNet: 异质子图网络在单张图像超分辨率中的应用", "title_en": "HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution", "authors": "Qiongyang Hu,Wenyang Liu,Wenbin Zou,Yuejiao Su,Lap-Pui Chau,Yi Wang", "background": "现有的基于深度学习的图像超分辨率方法，特别是那些基于CNN和注意力机制的方法，常常受到结构性灵活性的限制。虽然基于图的方法提供了更大的表示适应性，但它们往往会受到计算复杂度过高的限制。", "innovation": "HSNet 提出了一种新的框架，高效利用图建模同时保持计算上的可行性。通过将全局图分解成可管理的子组件，HSNet 介绍了一个用于生成互补子图的 Constructive Subgraph Set Block (CSSB)，并且采用了 Subgraph Aggregation Block (SAB) 进行多图特征的自适应加权和融合，以及 Node Sampling Strategy (NSS) 选择保留最显著的特征。这种设计有效平衡了重建质量和计算效率。", "conclusion": "实验表明，HSNet 实现了最先进的性能，并有效平衡了重构质量和计算效率。相关的代码将公开提供。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06541", "html_url": "https://arxiv.org/abs/2510.06541", "title": "集群路径：导航神经网络的可解释性", "title_en": "Cluster Paths: Navigating Interpretability in Neural Networks", "authors": "Nicholas M. Kroeger,Vincent Bindschaedler", "background": "现代深度神经网络在视觉任务中取得了显著的性能，但在决策过程上仍具有不透明性，这可能会导致不必要的信任、未被发现的偏见和意外的失败。集群路径是一种后编程的可解释性方法，该方法通过在选定层聚类激活，并将每个输入表示为其序列的聚类ID来解决这一问题。这些集群路径使用四种尺度进行评估：路径复杂度（认知负荷）、加权路径纯度（类别对齐）、决策一致性忠诚度（预测保真度）和路径一致性（扰动下的稳定性）。", "innovation": "本文提出了一种新的方法——集群路径，用于提高神经网络的可解释性。通过在选定层聚类激活，并将每个输入表示为其序列的聚类ID，支持了一种新的评估尺度，包括路径复杂度、加权路径纯度、决策一致性和路径一致性。与现有方法相比，这种方法可以在保持准确性的前提下，提高可解释性和鲁棒性。特别是在CelebA头发颜色任务上，集群路径达到了90%的忠诚度和96%的一致性，同时在加性噪声下保持准确性。这种方法还成功地扩展到了基于ImageNet预训练的视觉转换器，并且可以有效地作为一个离群样本检测器，便于提前识别异常样本，避免过度自信的预测。", "conclusion": "集群路径可以揭示视觉概念，如色板、纹理或对象上下文，跨越网络的不同深度。实验结果表明，集群路径能够为大型视觉模型提供简洁且易于理解的解释，证明了其在大型神经网络中的可扩展性和有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.11927", "html_url": "https://arxiv.org/abs/2412.11927", "title": "透明且连贯的操作错误检测", "title_en": "Transparent and Coherent Procedural Mistake Detection", "authors": "Shane Storks,Itamar Bar-Yossef,Yayuan Li,Zheyuan Zhang,Jason J. Corso,Joyce Chai", "background": "操作错误检测（PMD）是在通过第一视角视频观察到的人类用户执行特定步骤文本规定任务的情况下，识别该任务是否成功执行的问题，是一个具有挑战性的问题。尽管近期有很多努力，但在现实世界的机器性能仍然不可行，其背后的推理过程也是不透明的。", "innovation": "我们扩展了PMD，要求生成视觉自我对话理据以支持决策。我们基于个体帧创建了合适的基准数据集，利用近期视觉-语言模型（VLMs）出色且成熟的图像理解能力，提出了一种新的自动化评价指标，该指标为生成的理据的连贯性提供自然语言推理（NLI）模型。这些方法的基准测试显示，VLMs需要进行调整和微调才能更好地执行这项任务。", "conclusion": "我们的多维度评估指标可以展示常见结果，并突出进一步改进的领域，从而提供前所未有的透明度，并提高VLMs的准确性、连贯性和效率。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06509", "html_url": "https://arxiv.org/abs/2510.06509", "title": "从字幕到关键帧：基于字幕和上下文感知帧评分的高效视频摘要", "title_en": "From Captions to Keyframes: Efficient Video Summarization via Caption- and Context-Aware Frame Scoring", "authors": "Shih-Yao Lin,Sibendu Paul,Caren Chen", "background": "高效的视频语言理解需要从长视频中选择一小部分保留语义和上下文信息的帧。本研究背景在于如何有效选择具有代表性的帧以支持后续任务如检索、字幕生成以及视频语言推理，同时减少计算负担。之前的方法大多依赖于对每个帧进行全帧推理，这种方法计算成本高且效率低。", "innovation": "本文提出了KeyScore，一种多模态帧评分框架，该框架联合利用字幕和视觉上下文来估计帧级的重要性。KeyScore通过结合语义相似度、时间多样性以及上下文落差影响，能够识别出最具信息量的帧，从而为后续任务提供有效的支持。同时，另外引入了STACFP（时空自适应聚类用于帧建议），用于生成长视频的紧凑且多样的帧候选集合。这些模块相比全帧推理可以减少高达99%的帧数，表现优于标准的8帧编码器。", "conclusion": "我们的研究结果表明，强调视觉和文本信号的多模态对齐能够实现高效、可扩展且基于字幕的视频理解——无需显式的视频摘要。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06582", "html_url": "https://arxiv.org/abs/2510.06582", "title": "通过激光雷达视角：一种特征丰富和不确定性的注释管道用于地面点云分割", "title_en": "Through the Perspective of LiDAR: A Feature-Enriched and Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud Segmentation", "authors": "Fei Zhang,Rob Chancia,Josie Clapp,Amirhossein Hassanzadeh,Dimah Dera,Richard MacKenzie,Jan van Aardt", "background": "传统的地面激光扫描（TLS）点云语义分割依赖于昂贵的手动注释，这限制了效率和成本。本文旨在提出一种半自动、考虑不确定性的流水线技术，通过结合球面投影、特征丰富、集成学习以及目标注释，旨在减少注释工作量，同时保持高精度。", "innovation": "该研究提出了一个考虑不确定性的半自动化流水线，流程包括将3D点投影到2D球面网格，通过多源特征丰富像素并训练集成分割网络生成伪标签和不确定性地图，以此指导注释。最终结果通过三维重投影实现详细注释的点云，一个三级可视化套件支持快速筛选和审稿人指导（二维特征图、三维彩色点云和紧凑的虚拟球）。此外，通过跨数据集测试验证了功能增强策略的一般适用性。实验结果展示了需要大约12个注释扫描以饱和性能，并确定几何特征对表现至关重要，9个维度特征堆栈捕获几乎所有的区分功率。", "conclusion": "本研究贡献包括：一个稳健、考虑不确定性的TLS注释流水线，带有可视化工具；Mangrove3D数据集；以及数据效率和特征重要性的经验指导，助力TLS点云的大规模高质量分割，应用包括生态系统监测。该数据集和处理脚本在公共平台公开。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06590", "html_url": "https://arxiv.org/abs/2510.06590", "title": "Ming-UniVision: 联合图像理解和生成的统一连续标记器", "title_en": "Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer", "authors": "Ziyuan Huang,DanDan Zheng,Cheng Zou,Rui Liu,Xiaolong Wang,Kaixiang Ji,Weilong Chai,Jianxin Sun,Libin Wang,Yongjie Lv,Taozhi Huang,Jiajia Liu,Qingpei Guo,Ming Yang,Jingdong Chen,Jun Zhou", "background": "在自回归范式中统一视觉理解和生成仍然是一个核心挑战。现有方法通常在离散的潜在空间中使用标记器，并与大型语言模型的标记对齐。这种方法中的量化误差限制了语义表达力，并降低了视觉-语言理解能力。", "innovation": "引入了MingTok，这是一种新的视觉标记器家族，具有连续的潜在空间，可以实现统一的自回归生成和理解。该方法采用了低层次编码、语义扩展和视觉重建的三阶段顺序架构，以平衡理解任务和生成任务的竞争需求。在此基础上，Ming-UniVision消除了对任务特定视觉表示的需求，将多种视觉-语言任务统一在单一的自回归预测范式下。通过在共享的连续空间中将理解和生成都作为下一标记预测，它无缝支持迭代理解、生成和编辑等多轮、上下文相关的任务。实验证明，使用统一的连续视觉表示解决了理解和生成任务对标记器的矛盾需求，从而在两个领域都达到了最先进的性能。", "conclusion": "我们的发现旨在促进在连续域中的统一视觉标记化。已发布推断代码和模型权重以惠及社区。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04601", "html_url": "https://arxiv.org/abs/2510.04601", "title": "FedSRD：通信高效联邦大型语言模型微调的稀疏化重构分解框架", "title_en": "FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning", "authors": "Guochen Yan,Luyuan Xie,Qingni Shen,Yuejian Fang,Zhonghai Wu", "background": "当前，通过公开网络数据训练大型语言模型（LLMs）的方法正变得不可持续，因为高质量的专用领域数据源几乎耗尽。联邦学习（FL）作为一种分散式网络上的新一代AI解决方案，能够通过分布在全球客户端的私人数据实现隐私保护的协作微调。虽然低秩适应（LoRA）是高效微调的标准方法，但在联邦场景下其应用仍然面临重大挑战：通信开销仍然是一个关键瓶颈。LoRA参数中的结构性冗余不仅增加了通信负担，还在聚合客户端更新时引入了冲突。", "innovation": "我们提出了FedSRD，一种通信高效的联邦LLM微调方法，名为稀疏化-重构-分解框架。该框架首先通过重要性感知的方法对LoRA更新进行稀疏化，以减少上传的参数计数。服务器随后在全秩空间中重构和聚合这些更新，以减轻冲突问题。最后，将全局更新分解为稀疏低秩格式进行广播，从而实现对称高效的通信周期。我们还提出了一种高效的变体FedSRD-e，以减少计算开销。实验结果表明，在10个基准测试上，我们的框架将通信成本降低高达90%，且在异构客户端数据上提高了模型性能。", "conclusion": "FedSRD框架能够显著减少通信成本，并在处理异构客户端数据时提高模型性能，从而解决了联邦场景下的通信开销瓶颈问题。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06584", "html_url": "https://arxiv.org/abs/2510.06584", "title": "通过域适应在无需标注噪声图像的情况下提高CT深度学习模型的鲁棒性", "title_en": "Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation", "authors": "Justin Cheung,Samuel Savine,Calvin Nguyen,Lin Lu,Alhassan S. Yasin", "background": "深度学习模型在它们训练数据分布上的图像上表现出色，但在应用于新的分布时会大幅退化。CT扫描仪引入的新类像在训练标签中不存在，可能导致图像误分类。虽然现代CT扫描仪包含设计特征来缓解这些类像，但未预见或难以缓解的类像仍可能在实践中出现。直接对新分布中的图像进行标注成本高昂，本研究评估域适应作为一种方法，即使没有对应标签，也能训练出尽管存在新类像但仍能保持分类性能的模型。本研究在未标注环状类像数据期间进行训练，利用域对抗神经网络（DANN）方法在OrganAMNIST腹部CT数据集上评估，结果表明清洁图像训练的基线模型在存在环状类像的图像上无法泛化，传统扭曲类型的其他数据增强也未在未知类像领域提供改进。相比之下，DANN方法能仅使用未标注类像数据成功在环状类像图像上保持高分类准确度，证明了域适应方法应用于类像鲁棒性的可行性。未标记的域适应模型在环状类像测试数据上的分类性能与明确使用未标注类像图像训练的模型相当，同时在均匀噪声上出现了意外的泛化。", "innovation": "本研究利用域适应方法成功训练出在未标注新类像数据的情况下依然能保持分类性能的模型；DANN方法在环状类像图像上实现了高分类准确度；DANN方法还展示了对均匀噪声的意外泛化能力。", "conclusion": "域适应方法的有效性为解决医学成像中的分布变化问题提供了实证证据，无需昂贵的专家标记新类像分布，该方法在临床环境中具有应用前景，特别是在新型类像可能出现的情况下。"}
{"llm_update_time": "20251009", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02360", "html_url": "https://arxiv.org/abs/2510.02360", "title": "大型语言模型代理中的沉默螺旋现象", "title_en": "Spiral of Silence in Large Language Model Agents", "authors": "Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang", "background": "沉默螺旋理论认为，持有少数观点的个体往往出于社交隔离的恐惧而不发声，使得主流观点主导公共话语。当“行动者”是大型语言模型（LLM）时，传统心理学解释不再直接适用，因为沉默螺旋是在人类社会中发展出来的。因此，从统计语言生成的角度出发，LLM集体是否可能出现类似沉默螺旋的现象成为了一个核心问题。", "innovation": "本文提出了一种评估LLM代理中沉默螺旋现象的框架。具体来说，研究通过四种控制条件，系统地改变“历史”和“人设”信号的可用性来评估意见动态。研究使用趋势检验（如Mann-Kendall和Spearman秩）和集中度指标（如峰度和四分位距）来评价意见变化。研究结果表明，历史和人设信号结合产生了强大的主流主导地位，并复制了沉默螺旋模式；仅历史信号导致强烈锚定；仅人设信号则促进了多样但不相关的观点。研究指出，没有历史锚定，沉默螺旋现象将无法出现。这项工作将计算社会学与负责任的人工智能设计相结合，强调了监控和缓解LLM代理系统中可能出现的群体一致性的重要性和必要性。", "conclusion": "研究结果表明，在大型语言模型集体中，结合历史和人设信号可能会产生类似沉默螺旋的现象，但仅靠历史信号会导致强烈的锚定效应，而仅靠人设信号则可能导致多样化但不相关意见的形成。因此，历史锚定对于沉默螺旋现象的出现至关重要。研究还指出了计算社会学与负责任的人工智能设计之间的交叉点，强调了在LLM代理系统中监控和缓解群体一致性的必要性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06611", "html_url": "https://arxiv.org/abs/2510.06611", "title": "具有隐式表示正则化的自我监督物理引导模型用于快速MRI重建", "title_en": "Self-supervised Physics-guided Model with Implicit Representation Regularization for Fast MRI Reconstruction", "authors": "Jingran Xu,Yuanyuan Liu,Yanjie Zhu", "background": "磁共振成像（MRI）是一种重要的临床诊断工具，但由于扫描时间长，其广泛应用受到限制。快速MRI重建技术通过从欠采样的k空间数据重建高质量的MRI图像来有效缩短采集时间。近年来，基于深度学习的方法在这一领域取得了显著进展，特别是自我监督和非监督学习方法在难以获取完全采样数据的情况下尤为有价值。", "innovation": "该论文提出了一种名为UnrollINR的新颖零样本自我监督重建框架，该框架能够在无需依赖外部训练数据的情况下实现特定扫描的MRI重建。方法采用了物理引导的展开迭代重建架构，并引入了隐式神经表示（INR）作为正则化先验，有效限制了解的空间。通过结合深层展开结构和INR的强大隐式表示能力，模型的可解释性和重建性能得到了增强。", "conclusion": "实验结果显示，即使在高加速率为10的情况下，UnrollINR也能实现优于监督学习方法的重建性能，验证了所提方法的优越性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06596", "html_url": "https://arxiv.org/abs/2510.06596", "title": "SDQM: 合成数据质量度量标准（用于目标检测数据集评估）", "title_en": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation", "authors": "Ayush Zenith,Arnold Zumbrun,Neel Raut,Jing Lin", "background": "机器学习模型的性能高度依赖于训练数据的质量。大规模、高质量标注的数据集的稀缺性给创建稳健的模型带来了重大挑战。为解决这一问题，通过模拟和生成模型生成的合成数据已经作为一种有前景的解决方案出现，增加了数据集的多样性，提高了模型的性能、可靠性和鲁棒性。然而，评估生成数据的质量需要有效的度量标准。本文介绍了一种名为SDQM（Synthetic Dataset Quality Metric）的新度量标准，用于在不需要模型训练收敛的情况下评估目标检测任务的数据质量。这一度量标准使得合成数据集的高效生成和选择成为可能，解决了资源受限的目标检测任务中的一个关键挑战。", "innovation": "SDQM能够在不依赖模型训练收敛的情况下高效评估目标检测任务的数据质量，提供了改进数据集质量的可行策略，减少了成本高昂的迭代训练需求。实验结果显示，SDQM与YOLOv11这种领先的目标检测模型的均值平均精确度（mAP）分数之间存在很强的相关性，而之前的方法仅表现出中等到弱的相关性。SDQM作为一种可扩展而高效的度量标准，设定了评估合成数据的新标准。", "conclusion": "SDQM作为一种新型的合成数据质量度量标准，不仅提高了目标检测任务中数据集评估的效率，还提供了改善数据集质量的具体指导，解决了资源受限条件下的关键挑战。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06612", "html_url": "https://arxiv.org/abs/2510.06612", "title": "从音频到视频的桥梁：音素-唇型对齐允许每张脸说多种语言", "title_en": "A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face to Speak Multiple Languages", "authors": "Zibo Su,Kun Wei,Jiahua Li,Xu Yang,Cheng Deng", "background": "现有的语音驱动的说话面部合成（TFS）模型在英语中表现良好，但在非英语语言中表现欠佳，主要由于训练数据集以英语为主导且缺乏跨语言的泛化能力，导致生成错误的嘴型和僵硬的表情。", "innovation": "提出了一种新颖的框架——Multilingual Experts（MuEx），利用音素和唇型作为通用中介，通过语音和视频模式建立联系，实现了多语言的优质TFS。MuEx通过提取音频和视频特征分别作为音素和唇型，引入音素-唇型对齐机制（PV-Align）解决同步问题，并构建了一个多语言说话面部基准（MTFB），包含12种不同语言的高质量视频数据集。", "conclusion": "大量实验表明，MuEx在MTFB中的所有语言中都取得了卓越的性能，并且在未附加训练的情况下对未见过的语言展现了有效的零样本泛化能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06592", "html_url": "https://arxiv.org/abs/2510.06592", "title": "自适应染色矫正用于跨域医学组织病理学", "title_en": "Adaptive Stain Normalization for Cross-Domain Medical Histology", "authors": "Tianyue Xu,Yanlin Wu,Abhai K. Tripathi,Matthew M. Ippolito,Benjamin D. Haeffele", "background": "深度学习的进步已经彻底改变了自动化数字病理分析。然而，不同染色协议和成像条件下的色差会引入显著的色差变异性。在深度学习中，这种色差一致性差异在将模型部署到与训练数据不同条件的数据时会降低性能，这一挑战称为领域转移。许多现有方法试图通过颜色规范化来解决此问题，但这些方法存在一些明显的问题，比如引入伪影或需要精心选择模板图像进行染色映射。", "innovation": "我们提出了一种可训练的颜色规范化模型，该模型可以与任何骨干网络结合用于后续任务如对象检测和分类。基于成像过程中的Beer-Lambert定律，我们的模型架构是通过算法展开非负矩阵分解（NMF）模型来提取染色不变的结构信息，这些信息作为后续处理的输入。实验证明，我们的方法在公开的医学组织病理数据集和内部整理的疟疾血液涂片数据集上，在跨域对象检测和分类任务中，优于许多现有的染色标准化方法。", "conclusion": "在交叉领域的人工智能对象检测和分类任务中，我们的方法优于许多当前最优的染色标准化方法。我们的代码可在以下地址中找到：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06601", "html_url": "https://arxiv.org/abs/2510.06601", "title": "AIM 2025 Challenge on Real-World RAW Image Denoising", "title_en": "AIM 2025 Challenge on Real-World RAW Image Denoising", "authors": "Feiran Li,Jiacheng Li,Marcos V. Conde,Beril Besbinar,Vlad Hosu,Daisuke Iso,Radu Timofte", "background": "该挑战旨在推进基于数据合成的有效去噪技术的发展。比赛建立在一个新的评估基准之上，该基准包括从户外使用五种不同单反相机拍摄的真实低光照噪点图像，用于评估去噪技术。", "innovation": "比赛挑战参与者开发新颖的噪声合成管道、网络架构和训练方法，以实现跨不同相机模型的高性能。评估标准包括全参考度量（如PSNR、SSIM、LPIPS）和非参考度量（如ARNIQA、TOPIQ）。胜负是基于这些性能指标的综合评估来决定的。", "conclusion": "通过在合成数据上训练相机无感的低光照RAW图像去噪技术，该挑战促进了具有强大实用性的模型的发展，这与数字摄影的快速发展相一致。我们期望比赛结果会影响多个领域，包括图像恢复和夜间自动驾驶。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06687", "html_url": "https://arxiv.org/abs/2510.06687", "title": "基于轻场和LiDAR融合的语义分割算法", "title_en": "Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion", "authors": "Jie Luo,Yuxuan Jiang,Xin Jin,Mingyu Liu,Yihui Fan", "background": "语义分割是自主驾驶场景理解的基础，但在复杂条件下如遮挡时仍面临重大挑战。轻场和LiDAR模态提供了互补的视觉和空间线索，有利于鲁棒感知。然而，这些模态的有效整合因视角多样性有限和固有的模态差异而受阻。", "innovation": "本文首次提出了一个结合轻场数据和点云数据的多模态语义分割数据集，并提出了一个多模式轻场点云融合分割网络(Mlpfseg)。该网络结合了特征完成和深度感知模块，能够同时对相机图像和LiDAR点云进行分割。特征完成模块通过点云特征图的差分重构来解决密度不匹配问题，增强这些模态的融合。深度感知模块通过增强注意力分数来改善对遮挡对象的分割，提高对遮挡情况的感知。", "conclusion": "本文的方法在物体分割的平均交并比(mIoU)上优于仅图像分割的方法1.71个点，以及仅点云分割的方法2.38个点，证明了其有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06619", "html_url": "https://arxiv.org/abs/2510.06619", "title": "MSITrack: 一种棘手的多光谱单目标跟踪基准", "title_en": "MSITrack: A Challenging Benchmark for Multispectral Single Object Tracking", "authors": "Tao Feng,Tingfa Xu,Haolin Qin,Tianhao Li,Shuaihao Han,Xuyang Zou,Zhan Lv,Jianan Li", "background": "在现实世界场景中的视觉对象跟踪面临着许多挑战，包括遮挡、相似对象的干扰和复杂的背景。这些挑战限制了基于RGB的跟踪器的有效性。为了利用多光谱成像技术，该技术通过像素级光谱反射率增强目标可辨识度，研究人员需要相应的数据集，但目前多光谱跟踪数据集的可用性仍然有限，无法满足现有需求。", "innovation": "为了弥合这一差距，该研究引入了MSITrack，这是迄今为止最大的、最多样化的真实场景多光谱单对象跟踪数据集。MSITrack具有以下创新特点：（i）具有更具挑战性的属性，包含自然场景中的相似对象干扰、目标与背景在颜色和纹理上的相似性；（ii）包含更丰富和更自然的场景范围，涵盖了55种物体类别和300种独特的真实场景，超越已有的基准模型；（iii）规模更大，包含300个视频，共计超过129,000帧的多光谱图像，并确保了每个帧的精确标注和多阶段验证。该数据集显著提升了基于多光谱数据的跟踪器性能，展示了其在推动未来研究中的潜力。", "conclusion": "在使用多光谱数据的代表性跟踪器进行广泛评估后，研究结果显示MSITrack数据集在提高性能方面超过了仅依赖RGB的数据基线，这表明MSITrack数据集可以为多光谱单对象跟踪领域带来重大影响。MSITrack数据集是公开的，以便研究人员利用它进行进一步的研究和开发。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06694", "html_url": "https://arxiv.org/abs/2510.06694", "title": "SCas4D：基于结构的级联优化以增强持续4D新颖视图合成", "title_en": "SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis", "authors": "Jipeng Lyu,Jiahua Dong,Yu-Xiong Wang", "background": "持续动态场景建模用于跟踪和新颖视图合成仍具有挑战性，因为难以捕捉准确的形变同时保持计算效率。", "innovation": "提出了SCas4D级联优化框架，利用3D高斯点云的结构模式，通过从粗略零件级逐步细化到精细点级的方式来不断优化形变。该方法在每一帧内只需100次迭代即可达到收敛，并且只需要其他方法五分之一的训练迭代次数就能产生类似的结果。此外，该方法还展示了在自监督 articulated 物体分割、新颖视图合成和密集点跟踪任务中的有效性。", "conclusion": "SCas4D方法通过级联优化框架和结构化高斯点云建模，有效地解决了动态场景建模中的形变捕捉问题，提高了效率并在多个任务中显示了其优越性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06679", "html_url": "https://arxiv.org/abs/2510.06679", "title": "DreamOmni2：基于多模态指令的编辑和生成", "title_en": "DreamOmni2: Multimodal Instruction-based Editing and Generation", "authors": "Bin Xia,Bohao Peng,Yuechen Zhang,Junjia Huang,Jiyang Liu,Jingyao Li,Haoru Tan,Sitong Wu,Chengyao Wang,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia", "background": "近年来，基于指令的图像编辑和主题驱动生成任务受到了广泛关注。然而，这两种任务仍然存在一些局限性，它们难以满足实际用户的需求。基于指令的编辑任务依赖于语言指令，但往往难以具体捕捉编辑细节，因此需要参考图像。另一方面，主题驱动的生成任务只能结合具体的对象或人物，而忽视了更广泛的抽象概念。", "innovation": "为解决上述挑战，本文提出了两项新的任务：多模态基于指令的编辑和生成。这些任务支持文本和图像指令，并扩展了应用范围，包括具体的和抽象的概念，极大地增强了其实用性。为了实现这一目标，作者提出了名为DreamOmni2的数据合成框架，包括三个步骤：使用特征混合方法创建用于抽象和具体概念的提取数据，使用编辑和提取模型生成多模态基于指令的编辑训练数据，并进一步利用提取模型创建多模态基于指令的编辑训练数据。此外，为了处理多图像输入，还提出了一种索引编码和位置编码移位方案，该方案有助于模型区分图像并避免像素混乱。此外，还引入了与VLM和生成/编辑模型的联合训练，以更好地处理复杂的指令。", "conclusion": "实验结果表明，DreamOmni2取得了令人印象深刻的结果。模型和代码将被公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06638", "html_url": "https://arxiv.org/abs/2510.06638", "title": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering", "title_en": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering", "authors": "Zhihao Wen,Wenkang Wei,Yuan Fang,Xingtong Yu,Hui Zhang,Weicheng Zhu,Xin Zhang", "background": "知识导向的视觉问答（KVQA）要求模型在图像中定位实体并运用事实知识进行推理。而隐式知识变体（IK-KVQA）则要求通过多模态大型语言模型（MLLM）进行推理，而无需外部检索。然而MLLM缺乏明确的推理监督，导致生成不一致的验证性信息，并且在标准监督微调（SFT）后表现欠缺。", "innovation": "StaR-KVQA 引入了监督结构化的推理路径——双重符号关系路径加上路径支撑的自然语言解释，使推理过程透明且可验证。通过一个开源MLLM，StaR-KVQA 构建并选择了支撑性的推理路径来形成带有路径增强的数据集，然后通过结构化的自我蒸馏进行微调，使其生成与监督相一致。StaR-KVQA 不使用外部检索器、验证器或受控知识库（KB），所有的路径都在线下构建，并通过单次自回归过程进行推理。", "conclusion": "StaR-KVQA 在基准测试中提高了准确性和可解释性。在OK-VQA基准测试中，相比最强的基线模型，StaR-KVQA 的答案准确率提高了最高可达11.3%，并且展现出了强大的跨域泛化能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06673", "html_url": "https://arxiv.org/abs/2510.06673", "title": "Heptapod: 语言信号上的语言建模", "title_en": "Heptapod: Language Modeling on Visual Signals", "authors": "Yongxin Zhu,Jiawei Chen,Yuanzhe Chen,Zhuo Chen,Dongya Jia,Jian Cong,Xiaobin Zhuang,Yuping Wang,Yuxuan Wang", "background": "本文介绍了一种称为Heptapod的图像自回归模型，该模型遵循语言建模的基本原则。该模型采用了因果注意力机制，并避免了对CFG的依赖及使用语义分词器的趋势。Heptapod的核心创新在于预测下一个2D分布：这是一种以重建为导向的视觉分词器因果Transformer，能够学习在每个时间步中预测整个2D图像的分布。这一学习目标将自回归框架中的顺序建模与蒙面自编码的全方位自我监督学习统一起来，使模型能够通过生成训练捕捉到全面的图像语义。在ImageNet生成基准测试中，Heptapod实现了FID值为2.70，显著优于之前的因果自回归方法。", "innovation": "Heptapod采用了因果注意力机制，并且避开了对CFG的依赖及使用语义分词器的趋势。其核心创新在于‘下一个2D分布预测’：这是一种以重建为导向的视觉分词器因果Transformer，能够学习在每个时间步中预测整个2D图像的分布。这一学习目标将自回归框架中的顺序建模与蒙面自编码的全方位自我监督学习统一起来，使模型能够通过生成训练捕捉到全面的图像语义。", "conclusion": "Heptapod在ImageNet生成基准测试中取得了2.70的FID值，显著优于之前的方法。本文的工作期望能够激发对语言建模在视觉信号上的原理性的重新思考，并进一步推动相关领域的发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06669", "html_url": "https://arxiv.org/abs/2510.06669", "title": "工业缺陷检测的自动化神经架构设计", "title_en": "Automated Neural Architecture Design for Industrial Defect Detection", "authors": "Yuxi Liu,Yunfeng Ma,Yi Tang,Min Liu,Shuai Jiang,Yaonan Wang", "background": "工业表面缺陷检测（SDD）对于确保产品质量和生产可靠性是至关重要的。由于表面缺陷形状和大小的多样性，SDD 面临两个主要挑战：类内差异和类间相似性。现有方法主要依赖人工设计的模型，这需要大量的试验和错误，并且通常难以同时解决这两个挑战。", "innovation": "本文提出了 AutoNAD，一种用于 SDD 的自动化神经架构设计框架。该框架联合搜索卷积、变换器和多层感知器，能够捕捉细粒度的局部差异和长距离的语义上下文，从而同时解决这两个关键挑战，减少手动网络设计的成本。为支持此类多元搜索空间的高效训练，AutoNAD 引入了一种交叉权重共享策略，加速主网络的收敛并提高子网络的性能。此外，还集成了可搜索的多级特征聚合模块（MFAM）以增强多尺度特征学习。为确保工业部署中的效率，AutoNAD 采用延迟感知先验来指导高效架构的选择。", "conclusion": "AutoNAD 通过无效数据集的有效验证，并应用于缺陷成像和检测平台中。原始代码可在 [提供链接] 处获得。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06746", "html_url": "https://arxiv.org/abs/2510.06746", "title": "DeRainMamba：一种具有细节增强的频率感知状态空间模型用于图像去雨", "title_en": "DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement for Image Deraining", "authors": "Zhiliang Zhu,Tao Zeng,Tao Yang,Guoliang Luo,Jiyong Zeng", "background": "图像去雨对于提高视觉质量和支撑可靠的下游视觉任务至关重要。尽管基于Mamba的模型提供了高效的序列建模，但它们在捕捉细微细节方面的局限性以及缺乏频域意识限制了进一步的改善。现有的去雨模型虽然在去除雨迹方面有效，但由于缺乏频率感知和细节保护能力，无法充分平衡去雨效果和图像细节保留，限制了它们在视觉质量方面的提升和下游任务的支持效果。因此，需要一种既能有效去除雨迹又能不失真保持细节的去雨方法，从而提高视觉质量和增强下游任务的可靠性。现有方法未能同时优化去雨效果和图像细节保存，尤其是在处理复杂天气条件导致的雨迹时表现不足。因此，需要一种综合频率域建模和空间细节增强的方法来解决这一问题，提升去雨效果和下游任务的适用性。", "innovation": "为了解决上述问题，作者提出了一种名为DeRainMamba的方法，它结合了频域感知的状态空间模块（FASSM）和多方向感知卷积（MDPConv）。FASSM利用傅立叶变换区分雨线和高频图像细节，平衡了雨水去除和细节保留。MDPConv通过捕捉各向异性梯度特征并高效融合多个卷积分支进一步恢复局部结构。该模型在四个公开基准上的广泛实验表明，相对于最先进的方法，DeRainMamba在PSNR和SSIM指标上表现出更优的性能，同时参数更少，计算成本更低。这种方法验证了在状态空间框架内结合频率域建模和空间细节增强的有效性，用于单张图像去雨.", "conclusion": "DeRainMamba通过将频域感知的状态空间模块和多方向感知卷积结合起来，在解决单张图像去雨的同时保留了图像细节。这种方法在多个公开基准上的实验证明了其在保持视觉质量和提高下游任务支持方面的优越性，同时也展示了其在参数数量和计算成本方面的高效性，验证了在状态空间框架下综合频率域建模和空间细节增强的策略的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06769", "html_url": "https://arxiv.org/abs/2510.06769", "title": "基于粗标签的深度多项实例学习方法用于高分辨率土地覆盖制图", "title_en": "A deep multiple instance learning approach based on coarse labels for high-resolution land-cover mapping", "authors": "Gianmarco Perantoni,Lorenzo Bruzzone", "background": "高分辨率土地覆盖图绘制中，高质量且数量充足的训练标签是核心问题。低分辨率或过时的数据可以用来收集大量弱标签。本文探讨了使用高分辨率图像（如Sentinel-2）和低分辨率参考数据（如MODIS衍生的土地覆盖图）训练土地覆盖分类器的问题。", "innovation": "受最近在深度多项实例学习（DMIL）领域工作的启发，本文提出了一种方法，该方法训练像素级别的多类分类器并在低分辨率参考数据下预测低分辨率标签（即块级分类）。这种方法通过灵活的池化层将高分辨率图像像素的语义与低分辨率参考标签联系起来。进一步地，将多项实例学习（MIL）问题重新定义为多类和多标签问题，从而实现对高分辨率图像与低分辨率参考标签的隐式学习，而无需直接监督。然后，使用正未标学习（PUL）策略对分类器进行训练。实验结果表明了提出框架的有效性，相较于标准训练策略具有更高的效果。", "conclusion": "实验结果表明，所提出的框架在IEEE GRSS数据融合竞赛数据集上的表现优于标准训练策略，证明了该方法的有效性和改进。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06783", "html_url": "https://arxiv.org/abs/2510.06783", "title": "TTRV: 测试时强化学习在视觉语言模型中的应用", "title_en": "TTRV: Test-Time Reinforcement Learning for Vision Language Models", "authors": "Akshit Singh,Shyam Marjit,Wei Lin,Paul Gavrikov,Serena Yeung-Levy,Hilde Kuehne,Rogerio Feris,Sivan Doveh,James Glass,M. Jehanzeb Mirza", "background": "现有强化学习中的奖励信号提取方法通常依赖于标记数据和专门的训练分割，这与人类如何直接从环境中学习的方式不同。现有的方法在推理时通常不会动态调整模型，TTRV在这种背景下提出，旨在通过在推理时无需要任何标记数据的情况下动态调整模型，来增强视觉语言理解。", "innovation": "提出了TTRV方法，通过在推理时根据基础模型输出的频率设计奖励来适应模型。此外，还提出了一种同时奖励模型以降低输出经验分布熵的方式，来控制模型输出的多样性。该方法在对象识别和视觉问答方面取得了显着改进，显示出与其他最佳技术相当或更优的结果。", "conclusion": "TTRV方法在对象识别和视觉问答任务上分别实现了最多52.4%和29.8%的改进，平均提高了24.6%和10.0%。在图像识别中，TTRV在InternVL 8B上的表现优于GPT-4o，平均提高了2.3%，并保持在视觉问答领域的竞争力。实验表明，即使在数据极度受限的场景中，TTRV也能在单个未标记测试样本上产生有意义的改进，达到5.5%。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06809", "html_url": "https://arxiv.org/abs/2510.06809", "title": "VA-Adapter: 超声基础模型向心脏超声探头引导任务的适应", "title_en": "VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance", "authors": "Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Shiji Song,Gao Huang", "background": "心脏超声是检测心脏疾病的关键工具。超声基础模型在心脏超声图像分析中表现出显著的能力。但由于高质量超声图像对于准确诊断的必要性，且心脏超声操作难度极高，导致专业人员短缺，限制了患者的及时检查服务。因此，本文旨在利用基础模型从大量数据中学习的医学知识来适配探头引导任务，为初级超声技师提供实时操作建议，以获取高质量的超声图像。", "innovation": "本文提出了一种参数高效Vision-Action Adapter (VA-Adapter)，该适配器可以将基础模型的图像编码器与动作序列编码相结合，通过精调少量参数来实现紧凑设计下的序列推理能力。这种适配器能够使预训练的超声基础模型学习精确的探头调整策略，从而超越了现有的探头引导模型。", "conclusion": "广泛的实验表明，VA-Adapter可以在探头引导任务中超越强劲的探头引导模型。本文的代码将在接受后发布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06791", "html_url": "https://arxiv.org/abs/2510.06791", "title": "极端非齐平面人脸检测", "title_en": "Extreme Amodal Face Detection", "authors": "Changlin Song,Yunzhong Hou,Michael Randall Barnes,Rahul Shome,Dylan Campbell", "background": "极端非齐平面检测旨在从图像中推断出未完全可见但扩展视角可见的对象的2D位置。与非齐平面检测不同，后者是部分可见但被遮挡的物体。在这篇论文中，作者聚焦于人脸检测作为子问题，因为它涉及安全和隐私方面的应用，但方法本身并不专门针对人脸。现有的方法依赖于图像序列来插值缺失的检测结果或使用生成模型来采样可能的补全方案。与其他方法不同，本文提出了一个基于单张图像的任务，设计了一种无需样本的高效方法，利用图像中的上下文线索来推断未见人脸的存在。", "innovation": "本文提出了一种基于热图的极端非齐平面对象检测器，它能够高效地预测大量可见区域（图像外部）从少量信息（图像内部）中。作者提供了适用于此新任务的强健结果，并优于其他相对效率较低的生成模型方法。", "conclusion": "本文通过设计一种基于热图的极端非齐平面人脸检测器，有效地解决了单图像任务，只需利用图像中的上下文线索实现对未见人脸的存在进行准确推断。这种方法在新任务上的表现优于其他方法，展示了其在安全和隐私方面的潜在应用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06820", "html_url": "https://arxiv.org/abs/2510.06820", "title": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking", "title_en": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking", "authors": "Mitchell Keren Taraday,Shahaf Wagner,Chaim Baskin", "background": "目前，多模态检索仍然依赖于基于嵌入的模型，如CLIP来进行快速向量搜索。然而，与联合编码器重新排名在文本检索中的标准应用不同，在视觉-语言检索领域，效果相近的重新排名器较为罕见。现有的联合编码器，如BLIP，因其复杂的视觉特征提取阶段而受到严重瓶颈，使其无法在大规模实践中部署。", "innovation": "作者提出了EDJE（Efficient Discriminative Joint Encoder），这是一种高效的区分性联合编码器。EDJE通过离线预处理视觉标记和使用轻量级的注意力适配器进行压缩，使得在线推理仅需对少量视觉标记和文本运行紧凑的联合编码器，从而显著减少了存储和在线计算需求，同时保持了强大的检索性能。", "conclusion": "EDJE能够在每秒处理50000张图像-文本对的情况下，只需要每张图像49kB的磁盘存储空间，匹配了在Flickr（零样本）和COCO（微调）数据集上的先前最佳检索结果。模型的实现和检查点将很快公布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06757", "html_url": "https://arxiv.org/abs/2510.06757", "title": "通过直方图匹配变换噪声分布：朝向适用于所有噪声的单一去噪器", "title_en": "Transforming Noise Distributions with Histogram Matching: Towards a Single Denoiser for All", "authors": "Sheng Fu,Junchao Zhang,Kailun Yang", "background": "当前的监督高斯去噪器在面对分布不同类型的噪声时，表现出有限的一般化能力，因为不同噪声类型的分布特性各异。鉴于此，该研究探讨并提出了一种直方图匹配方法，通过将任意类型的噪声转化为目标高斯分布（具有已知强度），从而弥补这一差距。此外，通过建立噪声变换与后续去噪之间的良性循环，该方法逐步改善待转换噪声的质量，使其更接近实际噪声，从而增强噪声变换效果，进一步提高去噪性能。这种方法特别针对信号相关噪声、通道相关噪声和空间相关噪声引入了不同的变换策略，如局部直方图匹配、像素内置换以及频域直方图匹配结合像素混洗下采样。通过对这些变换的应用，单一的高斯去噪器显著提升了处理各种分布外噪声（包括合成噪声如泊松噪声、椒盐噪声和重复模式噪声，以及复杂的现实世界噪声）的能力。实验结果进一步证明了该方法的优越一般化能力和有效性。", "innovation": "提出了通过直方图匹配方法将任意噪声转换为特定高斯分布与后续去噪过程结合的创新性方案，建立噪声变换与去噪之间的良性循环，逐步改善待变换噪声，使其更接近实际噪声，从而增强噪声变换效果，提高去噪性能。针对多种噪声类型的复杂性，引入了局部直方图匹配、像素内置换和频域直方图匹配结合像素混洗下采样的特定策略，以应对信号相关噪声、通道相关噪声和空间相关噪声。单一的高斯去噪器通过上述策略具备处理多种分布外噪声的能力，特别是在合成噪声和复杂现实世界噪声方面表现出色。", "conclusion": "通过直方图匹配方法的应用，单一的高斯去噪器显著增强了处理各种复杂噪声（包括合成噪声和复杂现实世界噪声）的能力，验证了该方法的优越一般化能力和有效性，为单一去噪器广泛适用性提供了强有力的证据支持。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06855", "html_url": "https://arxiv.org/abs/2510.06855", "title": "在线通用事件边界检测", "title_en": "Online Generic Event Boundary Detection", "authors": "Hyungrok Jung,Daneul Kim,Seunggyun Lim,Jeany Son,Jonghyun Choi", "background": "当前通用事件边界检测（GEBD）方法需要处理完整的视频帧来进行预测，而人类则在线地、实时地处理数据。这类方法存在在线实时处理视频流时的挑战，尤其是识别实时发生的、非分类的微妙事件变化，且没有未来帧的参考。", "innovation": "提出了一个新的在线通用事件边界检测（On-GEBD）任务和框架Estimator，该框架基于活动分割理论（EST）进行改进，通过使用先前帧预测未来帧以实现对当前事件动态的预测，并通过在线边界判别器（OBD）监测预测误差并自适应调整阈值以捕捉各种微妙的事件过渡。", "conclusion": "实验结果显示，Estimator在Kinetics-GEBD和TAPOS数据集上的表现优于所有用于在线视频理解模型的基准方法，并且达到了与之前离线GEBD方法相当的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06829", "html_url": "https://arxiv.org/abs/2510.06829", "title": "仅使用事件相机的格子分配实时线段特征检测和跟踪", "title_en": "Lattice-allocated Real-time Line Segment Feature Detection and Tracking Using Only an Event-based Camera", "authors": "Mikihiro Ikura,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi", "background": "线段提取有助于捕捉人造环境的几何特征。基于事件的相机通过异步响应边缘的对比度变化，能够减少冗余数据实现高效提取。然而，最近的方法往往依赖于额外的帧相机或难以应对高事件率。", "innovation": "提出了一种实时线段检测和跟踪的方案，仅利用现代高分辨率（即高事件率）的基于事件的相机。该方法包括：(i) 速度不变的事件表示、(ii) 依据拟合分数进行线段检测、(iii) 通过端点扰动进行线段跟踪。实验证明该方法在实时性能和准确性上优于现有的仅事件和事件-帧混合基线方法，使得基于事件的相机能够独立运行于实际环境中。", "conclusion": "此研究实现了使用现代高分辨率的仅基于事件的相机进行实时线段检测和跟踪，并在自定义录制数据集和公开数据集上展示了其优越的实时性能和更高的准确性，能够作为独立的解决方案应用于真实场景中，无需依赖额外的帧相机。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06743", "html_url": "https://arxiv.org/abs/2510.06743", "title": "评估历史文档OCR的LLMs：数字人文领域的方法论框架", "title_en": "Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities", "authors": "Maria Levchenko", "background": "数字人文学者越来越多地使用大型语言模型进行历史文献数字化，但缺乏针对基于LLM的OCR的评估框架。传统的评估指标无法捕捉到历史语料库创建时至关重要的时间偏见和时期特定的错误。", "innovation": "本文提出了一种针对基于LLM的历史OCR的评估方法，解决了外交转录中的污染风险和系统性偏差。使用18世纪俄国民事手稿文本，引入了新的指标包括历史字符保真率（HCPR）和古雅插入率（AIR），并制定了污染控制和稳定性测试的规程。评估了12种多模态LLM，发现Gemini和Qwen模型在传统OCR基础上表现出优越性，但也出现了过度历史化现象：在错误的历史时期插入古雅字符。OCR后的后处理反而降低了性能。此方法为数字人文实践者提供了模型选择和历史语料库质量评估的指南。", "conclusion": "我们的方法为数字人文实践者提供了模型选择和历史语料库质量评估的指南。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06858", "html_url": "https://arxiv.org/abs/2510.06858", "title": "解释原始数据的复杂性以改进卫星在轨处理", "title_en": "Explaining raw data complexity to improve satellite onboard processing", "authors": "Adrien Dorise,Marjorie Bellizzi,Adrien Girard,Benjamin Francesconi,Stéphane May", "background": "随着计算能力的提升，直接在卫星上部署AI模型进行遥感变得可行。然而，使用原始未处理的传感器数据而非预处理地面产品带来了新的限制。当前的解决方案主要依赖预处理的传感器图像，仅有少数方法直接利用原始数据。本研究旨在调查使用原始数据对基于深度学习的物体检测和分类模型的影响。我们引入了模拟工作流程，从高分辨率L1影像生成类似原始数据的产品，以便系统评估。", "innovation": "研究利用模拟工作流程从高分辨率L1影像生成类似原始数据的产品，训练并对比YOLOv11s和YOLOX-S两种物体检测模型在原始数据和L1数据集上的性能，发现虽然两者在低至中等置信阈值下表现出类似性能，但在高置信阈值下，使用原始数据训练的模型在物体边界识别上存在困难。这表明，改进模型结构以提高轮廓识别能力可以直接提升在轨AI在遥感中的表现，从而改进卫星在轨处理能力。", "conclusion": "研究表明，使用原始数据训练的模型在高置信阈值下的物体边界识别存在困难，需要通过改进模型结构来提升物体检测性能，以提高在轨AI在遥感中的应用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06887", "html_url": "https://arxiv.org/abs/2510.06887", "title": "利用条件TransMix增强和交叉注意力的Transformer进行肺部感染严重程度预测", "title_en": "Lung Infection Severity Prediction Using Transformers with Conditional TransMix Augmentation and Cross-Attention", "authors": "Bouthaina Slika,Fadi Dornaika,Fares Bougourzi,Karim Hammoudi", "background": "肺部感染，尤其是肺炎，对健康构成严重威胁，尤其是在疫情期间病情可能迅速恶化。从医学影像中准确预测肺部感染的严重程度对于支持临床决策和优化患者预后非常重要。现有的研究主要集中于准确预测CT扫描和胸部X光片上的肺部感染严重程度，但仍需要新的方法来提高预测的鲁棒性和准确性。", "innovation": "该研究提出了一种名为QCross-Att-PVT的新方法，这是一种基于Transformer的架构，结合了并行编码器、交叉门注意力机制和特征聚合器，以捕捉丰富的多尺度特征。此外，还提出了一种定制的数据增强策略，即基于条件的TransMix增广，用于解决数据集不平衡问题，通过在训练期间生成混合标签图像补丁来增强模型的鲁棒性和预测准确性。", "conclusion": "该方法在两个基准数据集（RALO CXR和Per-COVID-19 CT）上评估结果显示，与现有的深度学习模型相比，该方法在多个性能指标上有所提升。结果强调了数据增强和门控注意力在提高模型鲁棒性和预测准确性方面的关键作用，为临床诊断、疾病监控和个性化治疗规划提供了可靠的工具。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06751", "html_url": "https://arxiv.org/abs/2510.06751", "title": "OBS-Diff：迭代时间感知的单次剪枝方法以实现扩散模型的精确剪枝", "title_en": "OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot", "authors": "Junhan Zhu,Hesong Wang,Mingluo Su,Zefang Wang,Huan Wang", "background": "大规模文本到图像的扩散模型虽然强大，但计算成本极高。现有的单次网络剪枝方法难以直接应用到扩散模型上，因为扩散模型具有迭代去噪的特性。因此，需要一种新的单次剪枝框架来解决这个问题，以便实现准确且无需训练的扩散模型压缩。", "innovation": "提出了名为OBS-Diff的新型单次剪枝框架，该框架能够准确且无需训练地压缩大规模文本到图像扩散模型。具体来说，OBS-Diff对经典的Optimal Brain Surgeon (OBS)方法进行了革新，适用于现代扩散模型的复杂架构，并支持多种剪枝粒度，包括无结构、N:M半结构化和结构化（MHA头部和FFN神经元）稀疏性。此外，从误差累积的角度出发，提出了新型的时间步长感知Hessian构造方法，结合了对数减小加权方案，强调早期时间步长的权重，以减轻潜在的误差累积。进一步提出了计算高效的分组顺序剪枝策略，以降低昂贵的校准过程成本。", "conclusion": "实验结果表明，OBS-Diff实现了扩散模型的单次剪枝的最新成果，实现了推理加速，同时仅轻微降低视觉质量。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06827", "html_url": "https://arxiv.org/abs/2510.06827", "title": "StyleKeeper：使用负视觉查询引导防止内容泄露", "title_en": "StyleKeeper: Prevent Content Leakage using Negative Visual Query Guidance", "authors": "Jaeseok Jeong,Junho Kim,Gayoung Lee,Yunjey Choi,Youngjung Uh", "background": "在文本到图片生成领域，扩散模型已经成为了强有力的工具。最近的研究中，使用图像作为提示的方法（视觉提示）使得风格与内容更加精确地控制成为可能。然而，现有的方法常常会受到内容泄露的问题困扰，即视觉样式提示中的非预期元素会被转移到生成的图像中。为了解决这个问题，本文首先将无分类器引导（CFG）扩展，利用交换自我注意机制，提出了第二种新方法：负视觉查询引导（NVQG），通过故意模拟内容泄露场景，交换自注意力层中的查询而不是键值，从而减少不必要的内容转移。此外，文中还提供了解决使用真实图像作为视觉样式提示的解决方案，并通过广泛的评估表明该方法在不同风格和文本提示下都优于现有方法，能够准确反映参考风格并确保生成的图像与文本提示匹配。", "innovation": "本文的创新在于将无分类器引导（CFG）扩展到利用交换自我注意机制，并提出了负视觉查询引导（NVQG）来减少内容泄露。NVQG利用负评分，在视觉样式提示中故意生成内容泄露的场景，通过交换自注意力层中的查询而非键值来实现内容的精确控制。本文还详细解决了将真实图像作为视觉样式提示的问题，通过广泛的评估展示了该方法在不同风格和文本提示下的优越性并可确保生成的图像与文本提示匹配。", "conclusion": "本文通过扩展无分类器引导并提出负视觉查询引导，显著减少了内容泄露的问题，并提供了使用真实图像作为视觉样式提示的解决方案。广泛的评估表明该方法在不同场景下具有优越性能，能够精确反映参考风格并确保生成的图像与文本提示匹配。研究的代码已公开可用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06926", "html_url": "https://arxiv.org/abs/2510.06926", "title": "使用生成虚拟示例学习的节约标签卫星图像变化检测", "title_en": "Label-frugal satellite image change detection with generative virtual exemplar learning", "authors": "Hichem Sahbi", "background": "遥感中的变化检测是一项主要任务，涉及在多时相卫星或航空图像中找到所有变化的出现。现有方法的成功，尤其是深度学习方法的成功，依赖于获得的手动标签训练数据，这些数据捕捉了获取条件和用户的主观性（先知的角色）。", "innovation": "本文提出了一种新颖的变化检测算法，基于主动学习。我们的贡献在于开发了一种新的模型，该模型衡量每个未标注样本的重要性，并只为先知提供最具关键性的样本（也称为虚拟示例）进行进一步的标注。这些示例通过可逆图卷积网络生成，并作为对抗损失的最优解而生成。对抗损失衡量了数据的代表性、多样性和模糊性，挑战当前的变化检测标准，从而在主动学习的后续迭代中更好地重新评估这些标准。实验结果表明，我们的标签高效的模型对比较方法产生了积极的影响。", "conclusion": "大量的实验显示，我们的标签高效的模型对比较方法产生了积极的影响，这是通过生成最具有挑战性的虚拟示例来实现的，这些示例被先知选择用于进一步标注。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06952", "html_url": "https://arxiv.org/abs/2510.06952", "title": "OBJVanish: 物理可实现的文本到3D对抗生成的LiDAR不可见物体", "title_en": "OBJVanish: Physically Realizable Text-to-3D Adv. Generation of LiDAR-Invisible Objects", "authors": "Bing Li,Wuqi Wang,Yanan Zhang,Jingzheng Li,Haigen Min,Wei Feng,Xingyu Zhao,Jie Zhang,Qing Guo", "background": "LiDAR基3D物体检测器是自动驾驶的核心，它们的失效可能导致严重安全风险。为了确保部署前的测试准确性，需要开发有效的3D对抗攻击。然而，现有的增加优化点扰动的攻击方法存在两个主要问题：它们无法完全使物体消失，且难以在物理环境中实现。", "innovation": "引入了一种新的文本到3D对抗生成方法，Phy3DAdvGen。该方法可生成对LiDAR检测器真正不可见的3D物体模型，并易于在真实世界环境中实现。通过CARLA模拟环境系统地研究了影响检测脆弱性的因素，提出了结合个体行人3D模型拓扑、连通性和强度的优化策略，并专门针对物理可实现性提出了Phy3DAdvGen方法。", "conclusion": "通过Phy3DAdvGen生成的3D行人能够逃避6种最先进的LiDAR 3D检测器，在CARLA模拟和物理环境中均能揭示关键安全应用中的漏洞。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06928", "html_url": "https://arxiv.org/abs/2510.06928", "title": "IAR2: 使用语义-细节关联的Token预测提高自回归视觉生成", "title_en": "IAR2: Improving Autoregressive Visual Generation with Semantic-Detail Associated Token Prediction", "authors": "Ran Yi,Teng Hu,Zihan Su,Lizhuang Ma", "background": "自回归模型已成为视觉内容创造的强大范式，但通常忽视了视觉数据的内在结构特性。先前的工作IAR通过重新组织基于嵌入相似性的视觉词典来解决这一问题，从而提高了生成鲁棒性，但受限于预训练词典的刚性和硬性均匀聚类的不准确性。", "innovation": "本文提出了一种名为IAR2的先进自回归框架，引入了一种新颖的语义-细节关联双词典，将图像表示分解为语义词典用于全局语义信息和细节词典用于细粒度细化，扩大了量化能力从线性到多项式尺度，显著提高了表达能力。为了支持这种双表示，提出了一种语义-细节自回归预测方案结合局部上下文增强自回归头进行分层预测，先预测语义标记，再预测细节标记，并利用局部上下文窗口增强空间一致性。此外，还引入了一种渐进注意力引导自适应CFG机制，根据标记与条件的相关性及其在生成序列中的时间位置动态调整指导规模，提高了条件一致性，同时不牺牲真实性。", "conclusion": "广泛的实验表明，IAR2在自回归图像生成方面达到了新最佳性能，在ImageNet上的FID得分为1.50。我们的模型不仅在性能上超越了之前的方法，还在计算效率上表现出色，突显了我们细化到整体结构生成策略的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06988", "html_url": "https://arxiv.org/abs/2510.06988", "title": "无需动作捕捉：仅使用文本提示和强化学习进行后训练的运动扩散模型", "title_en": "No MoCap Needed: Post-Training Motion Diffusion Models with Reinforcement Learning using Only Textual Prompts", "authors": "Girolamo Macaluso,Lorenzo Mandelli,Mirko Bicchierai,Stefano Berretti,Andrew D. Bagdanov", "background": "扩散模型近年来在生成现实且多样的人体动作动画方面取得了显著进展，能够从文本提示中生成逼真的动画。然而，将这些模型应用于未见过的动作或风格通常需要额外的动作捕捉数据和完整的重新训练，这在时间和资源上都非常昂贵，并且难以扩展。", "innovation": "提出了一种基于强化学习的后训练框架，使用仅有的文本提示精细调整预先训练好的运动扩散模型，无需任何运动真值数据。该方法利用预训练的文本-运动检索网络作为奖励信号，并使用正则化扩散策略优化来优化扩散策略，有效地将生成分布向目标领域转移，而无需依赖配对的运动数据。", "conclusion": "该方法在跨数据集应用和留一出门演示实验中取得了良好的结果，表明该方法一致地提高了生成运动的质量和多样性，同时保持了原始分布的表现。该方法提供了一种灵活、数据高效且隐私保护的运动适应解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06842", "html_url": "https://arxiv.org/abs/2510.06842", "title": "通过自适应流形对齐图正则化持续动作质量评估", "title_en": "Continual Action Quality Assessment via Adaptive Manifold-Aligned Graph Regularization", "authors": "Kanglei Zhou,Qingyi Pan,Xingxing Zhang,Hubert P. H. Shum,Frederick W. B. Li,Xiaohui Liang,Liyuan Wang", "background": "动作质量评估（AQA）量化视频中的人类动作，支持体育评分、康复和技能评估等应用。这一领域的难点在于实际场景中质量分布的非平稳性，这限制了传统方法的泛化能力。为了解决这个问题，作者提出了持续动作质量评估（CAQA），赋予AQA持续学习（CL）的能力，以处理不断变化的分布情况并减轻灾难性遗忘。尽管预训练模型的参数高效微调在图像分类的持续学习中显示出前景，但作者发现这种方法对于CAQA来说不够充分。", "innovation": "作者提出了自适应流形对齐图正则化（MAGR++），这是一种结合了基础网络微调和两步特征矫正管道的方法，以稳定浅层层并适应深层层。此外，作者还构建了四个专门的数据集基准和评估协议，使跨数据集的系统比较成为可能。实验结果表明，MAGR++实现了领先性能，对比最强基线，在离线环境下提高了3.6%的平均相关性，在在线环境下提高了12.2%的平均相关性，证实了其稳健性和有效性。", "conclusion": "MAGR++在持续学习框架下的动作质量评估中实现了最优性能，通过自适应地对齐特征流形和图正则化，解决了参数微调带来的过拟合和特征流形偏移问题，有效减轻了遗忘现象。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06973", "html_url": "https://arxiv.org/abs/2510.06973", "title": "解决长视频字幕中的ID匹配挑战", "title_en": "Addressing the ID-Matching Challenge in Long Video Captioning", "authors": "Zhantao Yang,Huangji Wang,Ruili Feng,Han Zhang,Yuting Hu,Shangwen Zhu,Junyan Li,Yu Liu,Fan Cheng", "background": "生成长且复杂的视频字幕对于文本到视频生成和多模态理解领域至关重要且具有挑战性。长视频字幕中的一个重要挑战是对出现在不同帧中的同一身份进行准确识别，这就是ID-Matching问题。尽管有些先有研究关注这一问题，但他们通常存在泛化能力有限和依赖点匹配的方法，这限制了它们的整体效果。因此，本研究旨在利用LVLMs的强大先验知识，增强其内在的ID-Matching能力，从而提升字幕中的ID-Matching性能。", "innovation": "本研究提出了一个新的基准来评估视频字幕的ID-Matching能力，并通过LVLMs特别是GPT-4o模型，发现了通过增强图像信息使用和增加个人描述量两种方法来提升ID-Matching性能的关键见解。基于这些见解，研究提出了一种名为RICE (Recognizing Identities for Captioning Effectively)的新视频字幕方法。实验结果表明，RICE在GPT-4o上实现了更高的精确度和召回率，显著提升了ID-Matching性能，证明了该方法的优越性。", "conclusion": "RICE方法使得在长视频字幕中持续跟踪不同个体成为可能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07008", "html_url": "https://arxiv.org/abs/2510.07008", "title": "使用深度神经网络和隐马尔可夫模型进行多年作物类型分类的贝叶斯建模", "title_en": "Bayesian Modelling of Multi-Year Crop Type Classification Using Deep Neural Networks and Hidden Markov Models", "authors": "Gianmarco Perantoni,Giulio Weikmann,Lorenzo Bruzzone", "background": "每年的土地覆盖图的时间一致性对于模拟多年土地覆盖的变化非常重要。本文研究了一种结合深度学习和贝叶斯建模的方法，使用隐马尔可夫模型（HMMs）与基于Transformer编码器（TE）的深度神经网络（DNNs）相结合，对年度遥感图像时间序列进行分类。该方法旨在捕捉年度序列中复杂的时序相关性和多年度作物类型序列中的特定模式。通过将HMM层构建在TE之上，以区分一致的年度作物类型序列。实验结果显示，建模时间一致性在预测标签中的重要性，并且HMMs提高了总体性能和F1分数，证明了所提出方法的有效性.", "innovation": "提出了一种结合深度学习和贝叶斯建模的新方法，使用隐马尔可夫模型与基于Transformer编码器的深度神经网络相结合，以捕捉年度序列中的复杂时序相关性和多年度作物类型序列中的特定模式，该方法可以有效地识别一致的年度作物类型序列.", "conclusion": "通过对包含47种作物类型和6年Sentinel-2产品的多年作物类型分类数据集的验证，展示了建模时间一致性在预测标签中的重要性；HMMs提高了整体性能和F1分数，表明了所提出方法的有效性."}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07089", "html_url": "https://arxiv.org/abs/2510.07089", "title": "DADO: Depth-Attention框架用于物体发现", "title_en": "DADO: A Depth-Attention framework for Object Discovery", "authors": "Federico Gonzalez,Estefania Talavera,Petia Radeva", "background": "语义分割和目标检测任务依赖于预先标记的数据集来训练模型，而无监督对象发现任务则是在不需要人工标注标签的情况下，识别和定位图像中的物体，这在计算机视觉领域仍是一个重大挑战，且逐渐成为一个研究热点。现有的方法在处理复杂场景或嘈杂的注意力图时存在挑战，如不同深度平面上的物体识别不准确等问题。", "innovation": "提出了一种名为DADO的新模型，结合了注意力机制和深度模型，以识别图像中的潜在物体。DADO通过动态权重调整机制，能够根据每幅图像的整体特性自适应地强调注意力或深度特征，有效解决了噪声注意力图和复杂场景中不同深度平面上物体识别的问题。", "conclusion": "DADO在标准基准测试中表现出色，相对于现有最先进的方法，其在物体发现的准确性和鲁棒性方面表现出更优的表现，且无需微调。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07115", "html_url": "https://arxiv.org/abs/2510.07115", "title": "基于CLIP的Concept Bottleneck Models中的概念定位增强", "title_en": "Enhancing Concept Localization in CLIP-based Concept Bottleneck Models", "authors": "Rémi Kazmierczak,Steve Azzolin,Eloïse Berthier,Goran Frehse,Gianni Franchi", "background": "本文通过Concept Bottleneck Models (CBMs) 的视角研究了解释性AI (XAI)，CBMs的主要特点是不需要显式的概念注解，而是使用CLIP以零样本的方式提取概念。然而，研究发现CLIP在这些技术中容易出现概念幻觉，即错误地预测图像中概念的存在或不存在，这影响了解释的准确性。", "innovation": "本文提出了一种名为Concept Hallucination Inhibition via Localized Interpretability (CHILI) 的技术，该技术通过化解图像嵌入并将与目标概念相应的像素进行本地化，来缓解概念幻觉问题。此外，该方法还支持基于显著性生成更可解释的解释。", "conclusion": "本文引入了CHILI技术，提高了解释性，通过化解图像嵌入并精确定位目标概念，缓解了CLIP在CBMs中易出现的概念幻觉问题，并生成了更可解释的基于显著性的解释。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07058", "html_url": "https://arxiv.org/abs/2510.07058", "title": "概念检索 - 什么是以及如何实现？", "title_en": "Concept Retrieval - What and How?", "authors": "Ori nizan,Oren Shrout,Ayellet Tal", "background": "本研究针对给定图像检索具有相似概念的其他图像的问题，这超越了传统的基于视觉或语义相似度的检索或聚类方法。研究者定义了问题，提出了关键要求，并采用了合适的评估指标来衡量方法的有效性。", "innovation": "提出了一种新颖的方法，该方法基于两个关键观察：1) 在嵌入空间中的每个邻居通常与查询共享至少一个概念，但并非所有的邻居都彼此共享相同的概念；2) 使用双模态高斯分布模型邻里结构有助于揭示有意义的结构，从而促进概念的识别。实验结果证实了该方法的有效性。", "conclusion": "该方法通过引入合适的评价指标已经证明了有效性。当应用于实际场景时，可以有效地提取和识别图像中的关键概念。同时，研究结果已经证明这种方法具有比传统方法更好的表现。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06969", "html_url": "https://arxiv.org/abs/2510.06969", "title": "从查询学习全局表示以构建矢量高清地图", "title_en": "Learning Global Representation from Queries for Vectorized HD Map Construction", "authors": "Shoumeng Qiu,Xinrun Li,Yang Long,Xiangyang Xue,Varun Ojha,Jian Pu", "background": "高清地图（HD）的在线构建是现代自动驾驶系统的核心组成部分。现有技术，尤其是基于DETR框架的方法，将这一过程视为实例检测问题。然而，这些方法依赖于独立的可学习对象查询，导致了局部查询视角，忽略了高清地图中的固有全局表示特性。", "innovation": "作者提出了一种名为MapGR的新架构，旨在从查询中学习并利用全局表示。MapGR包括两个协同运作的模块：Global Representation Learning（GRL）模块通过精心设计的整体分割任务引导所有查询分布，以更好地与全局地图对齐；Global Representation Guidance（GRG）模块赋予每个查询显式的全局级别上下文信息，促进其实现优化。研究结果表明，与领先的基础方法相比，该方法在nuScenes和Argoverse2数据集上的平均精度（mAP）具有显著提升。", "conclusion": "在nuScenes和Argoverse2数据集上的评估证实了本方法的有效性，展示了与当前最佳基线相比，MapGR在平均精度（mAP）上的显著改进。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07041", "html_url": "https://arxiv.org/abs/2510.07041", "title": "U-Bench：通过100变体基准测试全面理解U-Net", "title_en": "U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking", "authors": "Fenghe Tang,Chengqi Dong,Wenxin Ma,Zikang Xu,Heqin Zhu,Zihang Jiang,Rongsheng Wang,Yuhao Wang,Chenxu Wu,Shaohua Kevin Zhou", "background": "在过去的十年里，U-Net已成为医学图像分割的主要架构，数千种U形变体随之出现。尽管U-Net被广泛采用，但目前仍缺少一个系统性的评估基准来全面评估这些变体的性能和实用性。主要原因在于统计验证不足和对不同数据集的有效性和通用性考虑不充分。为了弥补这一空白，本文提出了U-Bench，这是第一个大规模且统计严谨的基准测试，评估了28个数据集和10种成像模态下的100种U-Net变体的性能。该基准通过三个关键维度——统计稳健性、零样本泛化能力和计算效率——全面评估模型。", "innovation": "本文的贡献在于三个方面：(1) 全面评估：U-Bench 通过引入新的U-Score指标，联合衡量性能与效率的折衷，为模型的进步提供了部署导向的视角。(2) 系统分析与模型选择指导：通过对大规模评估结果的总结分析，探讨了数据集特征和架构范式对模型性能的影响，提出了模型顾问代理，用于指导研究人员选择最适合特定数据集和任务的模型。(3) 公开可用性：提供了所有相关代码、模型、协议和权重，使得社区能够复现本文结果并扩展基准测试，以纳入未来方法。", "conclusion": "综上所述，U-Bench 不仅揭示了先前评估中的不足之处，也为未来十年中基于U-Net的分割模型的公平、可重复且实用的相关基准测试奠定了基础。项目可以在此网址访问：[此链接](此链接)。代码可在此地址获取：[此链接](此链接)。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07119", "html_url": "https://arxiv.org/abs/2510.07119", "title": "MoRe: 单目几何精修通过图优化实现跨视图一致性", "title_en": "MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency", "authors": "Dongki Jung,Jaehoon Choi,Yonghan Lee,Sungmin Eum,Heesung Kwon,Dinesh Manocha", "background": "单目3D基础模型为感知任务提供了可拓展的解决方案，使其在更广泛的3D视觉应用中具有吸引力。但单目几何先验存在尺度不确定性的问题，因此提升跨视图一致性仍然是一个挑战。", "innovation": "本文提出了MoRe，一种无需训练的单目几何精修方法，用于提高跨视图一致性并实现尺度对齐。该方法通过帧之间特征匹配建立对齐，并采用图优化框架结合单目基础模型估计的3D点和表面法线进行局部平面近似，解决了尺度不确定性问题，同时保留了基础结构。", "conclusion": "实验表明，MoRe不仅提升了3D重建，还在稀疏视图合成等方面也表现出色，进一步验证了其在单目3D视觉中的应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07126", "html_url": "https://arxiv.org/abs/2510.07126", "title": "验证脑肿瘤分割的各种归一化方法：联邦学习能否克服这种异质性？", "title_en": "Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?", "authors": "Jan Fiszer,Dominika Ciupek,Maciej Malawski", "background": "深度学习在医学成像中的应用越来越广泛，但需要大量的数据，这导致了数据隐私、存储和传输方面的问题。联邦学习是一种克服这些问题的训练范式，但在处理非独立且非同分布（non-IID）数据时，其效果可能会受到影响。通过模拟不同MRI强度归一化技术来产生非IID条件，本研究旨在探讨归一化方法对分割模型的影响。", "innovation": "本研究通过采用不同的MRI强度归一化技术来模拟非IID条件，为训练和测试脑肿瘤分割模型提供了新的数据并提供了见解。更值得注意的是，联邦学习方法展示了在客户端数据归一化不一致的情况下依然有良好的表现，这表明联邦学习能够有效地训练高性能模型，而不会违反数据隐私，这对于医学应用至关重要。", "conclusion": "联邦学习的方法在处理跨客户端的不一致性归一化数据时表现出良好的稳健性，训练的3D Dice分数达到92%，与使用所有数据训练的集中式模型相当。这些结果表明，联邦学习是一种有效解决高性能模型训练问题的方法，同时又能确保数据隐私，这对医学应用特别重要。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07143", "html_url": "https://arxiv.org/abs/2510.07143", "title": "是否采用合适的基准：视觉标记压缩方法的评估框架", "title_en": "Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods", "authors": "Chenfei Liao,Wensong Wang,Zichen Wen,Xu Zheng,Yiyu Wang,Haocong He,Yuanhuiyi Lyu,Lutao Jiang,Xin Zou,Yuqian Fu,Bin Ren,Linfeng Zhang,Xuming Hu", "background": "近年来，加速多模态大型语言模型（MLLMs）推理的主要努力集中在视觉标记压缩上。这些方法的效果通常通过测量其在已确立基准上的准确率下降来评估，比较模型压缩前后性能。然而，这些基准原本设计用于评估MLLMs的感知和推理能力，而非压缩技术的评估。因此，直接将其应用于视觉标记压缩引入了任务错配。我们的研究发现，简单的图像降采样在多个广泛使用的基准上始终优于许多先进的压缩方法。", "innovation": "我们观察到目前的基准对于视觉标记压缩任务不够准确，提出了一种新的评估框架VTC-Bench，该框架集成了数据过滤机制以去噪现有基准，从而提供更公平和准确的视觉标记压缩方法评估。", "conclusion": "该研究揭示了当前基准对视觉标记压缩任务的噪声问题，并提出VTC-Bench框架以过滤数据以评估样本难度，从而提供更准确的压缩方法评估。所有数据和代码均在此网址获取。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07129", "html_url": "https://arxiv.org/abs/2510.07129", "title": "图条件扩散模型在可控病理图像生成中的应用", "title_en": "Graph Conditioned Diffusion for Controllable Histopathology Image Generation", "authors": "Sarah Cechnicka,Matthew Baugh,Weitong Zhang,Mischa Dombrowski,Zhe Li,Johannes C. Paetzold,Candice Roufosse,Bernhard Kainz", "background": "最近扩散概率模型（DPMs）在高质量图像合成方面取得了显著进展，但可控生成仍然具有挑战性，特别是在医学成像领域等敏感区域。医学图像包含固有的结构，如一致的空间排列、形状或纹理，这些都是诊断的关键。然而，现有的DPMs在噪声较大的潜在空间中运作，缺乏语义结构和先验知识，使得难以确保生成内容的有意义控制。", "innovation": "本文提出了一种图条件扩散方法，通过生成对应于图像中每个主要结构的图节点，并涵盖它们的特征和关系来解决上述问题。这些图表示由变压器模块处理，并通过文本条件机制集成到扩散模型中，实现生成过程中的细粒度控制。研究采用了实际的病理学应用案例来评估该方法，证明了我们的生成数据可以可靠地替代注释的患者数据进行下游分割任务。", "conclusion": "通过图条件扩散模型，我们的方法能够在生成病理图像时实现细粒度控制，该方法已在实际病理学应用中得到验证，生成的数据可用于替代有标注的患者数据进行后续任务。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06967", "html_url": "https://arxiv.org/abs/2510.06967", "title": "使用二维高斯渲染生成Text-to-3D表面", "title_en": "Generating Surface for Text-to-3D using 2D Gaussian Splatting", "authors": "Huanning Dong,Fan Li,Ping Kuang,Jianwen Min", "background": "近年来，Text-to-3D建模取得了显著进展，显示出在生成3D内容方面的巨大潜力。然而，由于自然界中物体的复杂几何形状，生成3D内容仍然是一个挑战性的任务。当前的方法要么利用二维扩散先验来恢复3D几何形状，要么直接基于特定的3D表示进行模型训练。目前的方法在处理多视角几何一致性问题时表现不佳，这限制了3D内容的生成质量。", "innovation": "本文提出了一种名为DirectGaussian的新方法，该方法关注通过surfels表示的3D对象的表面生成。DirectGaussian利用条件文本生成模型，通过多视角法和法向量及纹理先验的2D高斯渲染来渲染3D对象的表面。此外，DirectGaussian在优化过程中引入曲率约束，以处理多视角几何一致性问题。实验结果表明，该框架能够实现多样且高质量的3D内容生成。", "conclusion": "通过大量实验，本文证明了所提出的框架能够实现多样且高质量的3D内容创作，并且该方法可以有效地处理多视角几何一致性问题。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07135", "html_url": "https://arxiv.org/abs/2510.07135", "title": "Remote Sensing Vision-Language Models 的 few-shot 调适基准", "title_en": "Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models", "authors": "Karim El Khoury,Maxime Zanella,Christophe De Vleeschouwer,Benoit Macq", "background": "基于大规模预训练的遥感视觉-语言模型（RSVLMs）在各类任务上展现了显著的零样本性能，但在小样本学习等低数据资源条件下表现不足。本文旨在通过构建首个结构化基准，评估 RSVLMs 在 few-shot 调适方法上的表现。", "innovation": "本文提出了首个针对 RSVLMs 的 few-shot 调适基准，跨十个遥感场景分类数据集进行了全面实验，应用了五种常用 few-shot 调适策略，揭示了模型在 few-shot 情况下表现的显著差异，强调了针对 RS 的更稳健 few-shot 调适方法的重要性。", "conclusion": "研究结果表明，虽然有些 RSVLMs 在 few-shot 调适后表现优异，但没有明确的方法占优，因此需要开发更适用于 RS 的 robust 方法。为此，本文提供了可复现的基准测试框架和开源代码，以系统地评估 RSVLMs 在 few-shot 条件下的性能。源代码已公开在 GitHub：[链接处填入]。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06876", "html_url": "https://arxiv.org/abs/2510.06876", "title": "HARP-NeXt: 高速且准确的3D LiDAR语义分割范围-点融合网络", "title_en": "HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D LiDAR Semantic Segmentation", "authors": "Samir Abou Haidar,Alexandre Chariot,Mehdi Darouich,Cyril Joly,Jean-Emmanuel Deschaud", "background": "激光雷达语义分割对于自动驾驶车辆和移动机器人至关重要，需要高精度和实时处理，尤其是在资源受限的嵌入式系统中。传统的最先进方法往往在精度和速度之间存在权衡。基于点的方法和稀疏卷积方法虽然准确但速度较慢，因为它们需要复杂的邻域查找和3D卷积。投影方法则较快但会在二维投影过程中丢失关键的几何信息。许多最近的方法依赖于测试时增强了的模型以提高性能，这进一步放慢了推理速度。此外，所有方法的预处理阶段都会增加执行时间并给嵌入式平台带来挑战。", "innovation": "我们引入了HARP-NeXt，一种高速且准确的LiDAR语义分割网络。首先提出了一个新颖的预处理方法，显著减少了计算开销。设计了Conv-SE-NeXt特征提取块以高效捕捉表示而不进行深层堆叠。使用多尺度范围-点融合骨干，在多个抽象级别上利用信息以保留关键的几何细节，从而提高精度。实验结果在nuScenes和SemanticKITTI基准测试中表明，HARP-NeXt相比所有最先进方法实现了更优的速度-精度折衷，而且没有使用集成模型或测试时增强，在运行速度上快24倍并且可与排名第一的PTv3媲美。代码可以在下列链接中找到。", "conclusion": "HARP-NeXt通过新颖的预处理方法和高效的特征提取块以及多尺度范围-点融合骨干，在保持高精度的同时实现了高速的3D LiDAR语义分割，实现了最先进方法中前所未有的速度-精度折衷。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07191", "html_url": "https://arxiv.org/abs/2510.07191", "title": "分辨率缩放决定了DINOv3在胸部X光分类中的迁移性能", "title_en": "Resolution scaling governs DINOv3 transfer performance in chest radiograph classification", "authors": "Soroosh Tayebi Arasteh,Mina Shaigan,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn", "background": "自监督学习（SSL）推动了视觉表示学习的发展，但在胸片（一种高频率使用的成像技术，包含精细的诊断信息）中的价值尚不清楚。Meta的DINOv3通过Gram-锚定的自监督学习扩展了早期SSL模型。尽管这种改进可能会增强对胸片的迁移学习能力，但其有效性尚未被系统性测试。", "innovation": "研究对比了DINOv3和DINOv2以及基于ImageNet初始化模型在7个数据集上的性能（样本数量超过814,000），通过不同的分辨率（224x224、512x512、1024x1024）进行了模型训练，评估不同backbone（ViT-B/16和ConvNeXt-B）及冻结DINOv3-7B特征的影响。结果显示，更高的输入分辨率对于利用现代SSL模型的优势至关重要，512x512像素代表一个实际的上限，此时DINOv3初始化的ConvNeXt-B网络性能最佳，而更大的输入为成本带来的回报甚微。", "conclusion": "临床应用中，建议使用512x512像素的微调模型进行胸片解读，特别是在识别细微或边界中心的病变时可以获得最大的收益，这对急诊和重症监护环境尤为重要。此外，冻结的DINOv3-7B特征在模型性能上不及完全微调的模型，强调了领域自适应的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07217", "html_url": "https://arxiv.org/abs/2510.07217", "title": "GenPilot：图像生成中的测试时提示优化的多代理系统", "title_en": "GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation", "authors": "Wen Ye,Zhaocheng Liu,Yuwei Gui,Tingyu Yuan,Yunyue Su,Bowen Fang,Chaoyang Zhao,Qiang Liu,Liang Wang", "background": "尽管文本到图像合成取得了显著进展，但在准确解释复杂且冗长的提示方面仍然存在挑战，通常会导致语义不一致和细节缺失。现有的解决方案，如微调，是模型特定的，并需要训练。先前的自动提示优化（APO）方法通常缺乏系统的错误分析和改进策略，因此具有有限的可靠性和有效性。同时，测试时缩放方法仅限于固定提示和噪声或样本数量，限制了它们的可解释性和适应性。", "innovation": "我们提出了一种灵活且高效的测试时提示优化策略，该策略直接作用于输入文本，并引入了一个可插拔的多代理系统GenPilot，集成了错误分析、基于聚类的自适应探索、细粒度验证和记忆模块，以实现迭代优化。GenPilot方法是模型无关的、可解释的，非常适合处理长且复杂的提示。此外，我们总结了错误的常见模式及其改进策略，提供了更多的经验和鼓励进一步探索。", "conclusion": "在DPG-bench和Geneval上的实验表明，我们的方法在提高生成图像的文本和图像一致性以及结构连贯性方面展现出强大的能力，证实了测试时提示优化策略的有效性。代码可在上述链接中获得。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07206", "html_url": "https://arxiv.org/abs/2510.07206", "title": "EigenScore: OOD检测利用扩散模型中的协方差", "title_en": "EigenScore: OOD Detection using Covariance in Diffusion Models", "authors": "Shirin Shoushtari,Yi Wang,Xiao Shi,M. Salman Asif,Ulugbek S. Kamilov", "background": "在安全敏感的领域中，安全部署机器学习系统的关键在于对out-of-distribution (OOD)的检测。近年来，扩散模型作为一种强大的生成模型，展现了捕获复杂数据分布的能力，通过迭代去噪。基于此进展，已经有一些研究探讨了使用扩散模型进行OOD检测的方法。", "innovation": "本文提出了一种称为EigenScore的新方法，利用扩散模型后验协方差的特征值谱进行OOD检测。通过分析后验协方差与分布差异的关系，建立了后验协方差作为OOD检测的可靠信号的基础。该方法采用无雅可比矩阵的子空间迭代方法，仅使用去噪器的前向评估来估计主特征值，确保了计算的可行性。实验证明，EigenScore在多个OOD场景中达到了最佳性能，相比现有基线方法有显著提升，并且在CIFAR-10 vs CIFAR-100等接近OOD的场景中保持了鲁棒性。", "conclusion": "EigenScore利用后验协方差的特征值谱成功地实现了OOD检测，相比现有方法有显著的性能提升，并且在复杂场景中保持了鲁棒性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07277", "html_url": "https://arxiv.org/abs/2510.07277", "title": "评估用于糖尿病黄斑水肿检测的视网膜专用基础模型", "title_en": "Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection", "authors": "Franco Javier Arellano,José Ignacio Orlando", "background": "糖尿病视网膜病变（DR）患者中，糖尿病黄斑水肿（DME）是导致视力丧失的主要原因之一。深度学习在从眼底图像自动检测此状况方面显示出有前景的结果，但在应用中仍面临挑战，主要原因是标注数据的有限性。基础模型（FM）作为一种替代方案，已经出现。然而，尚不清楚它们是否适用于DME检测。", "innovation": "本文系统地比较了不同的基础模型和标准的迁移学习方法在糖尿病黄斑水肿检测任务上的性能。具体地，比较了两种最流行的用于视网膜图像的基础模型——RETFound和FLAIR——以及EfficientNet-B0骨干网络，在IDRiD、MESSIDOR-2以及OCT-and-Eye-Fundus-Images（OEFI）数据集上的表现。", "conclusion": "尽管基础模型在规模上具有优势，但它们在此任务上并未一致地优于微调后的CNN。EfficientNet-B0在大多数评估设置中根据ROC和精确召回曲线的AUC得分排名靠前或第二。RETFound仅在OEFI中表现出良好的结果。而FLAIR展示了令人竞争的零样本性能，在适当提示下获得显著的AUC-PR分数。这些发现表明，即便经过微调，基础模型可能不适合细粒度的眼科任务如DME检测，因此轻量级CNN仍然在数据稀缺环境中作为强大的基准范式。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07319", "html_url": "https://arxiv.org/abs/2510.07319", "title": "Temporal Prompting Matters: Rethinking Referring Video Object Segmentation", "title_en": "Temporal Prompting Matters: Rethinking Referring Video Object Segmentation", "authors": "Ci-Siang Lin,Min-Hung Chen,I-Jieh Liu,Chien-Yi Wang,Sifei Liu,Yu-Chiang Frank Wang", "background": "当前的Referring Video Object Segmentation (RVOS)方法大多需要通过密集的掩码注释进行端到端的训练，这可能导致计算成本高昂且缺乏可扩展性。", "innovation": "本文重新思考了RVOS问题，提出了Temporal Prompt Generation and Selection (Tenet)框架，将RVOS任务分解为三项基础模型无法解决的因素：参考、视频和分割，并利用现成的物体检测器和跟踪器生成与查询句子相关的时序提示，同时提出了Prompt Preference Learning来评估生成的时序提示的质量。这些创新使该框架能够高效适应图像基础分割模型以用于参考视频对象分割。", "conclusion": "在RVOS基准上的实验表明，Tenet框架是有效的。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07316", "html_url": "https://arxiv.org/abs/2510.07316", "title": "带有语义引导扩散变换器的像素完美深度", "title_en": "Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers", "authors": "Gangwei Xu,Haotong Lin,Hongcheng Luo,Xianqi Wang,Jingfeng Yao,Lianghui Zhu,Yuechuan Pu,Cheng Chi,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Sida Peng,Xin Yang", "background": "当前的生成深度估计模型通过微调Stable Diffusion来实现出色的性能，但这些模型需要使用VAE将深度图压缩到潜在空间，这不可避免地在边缘和细节处引入了“飞行像素”。", "innovation": "本文提出了像素空间扩散生成的单目深度估计模型Pixel-Perfect Depth，通过直接在像素空间进行扩散生成来避免VAE引入的伪影。模型引入了两项创新设计：1）语义引导扩散变换器（SP-DiT），将视觉基础模型的语义表示融入到DiT中以引导扩散过程，从而保持全局语义一致性并增强细粒度的视觉细节；2）级联DiT设计，通过逐步增加标记的个数来进一步提高效率和准确性。", "conclusion": "本文的模型在五个基准测试中均达到最佳性能，并在边缘敏感的点云评估中显著优于其他所有模型。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07190", "html_url": "https://arxiv.org/abs/2510.07190", "title": "MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis", "title_en": "MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis", "authors": "Yihao Zhi,Chenghong Li,Hongjie Liao,Xihe Yang,Zhengwentai Sun,Jiahao Chang,Xiaodong Cun,Wensen Feng,Xiaoguang Han", "background": "近期视频生成领域取得了重大突破，得益于大规模数据集和扩散技术的发展，视频扩散模型能够作为潜在的4D新颖视角合成器发挥作用。然而，当前的方法主要集中在前视图中的摄像机轨迹重定向，对于360度视角变换的生成效果仍有局限性。本文针对这一问题，提出了从单目全身捕捉中生成同步新颖视视频的MV-Performer框架，旨在实现全方位的合成，并有效解决单目深度估计不完美带来的问题。", "innovation": "本文提出了一种创新的框架MV-Performer，用于从单目全身捕捉中生成同步新颖视角视频。该框架充分利用了MVHumanNet数据集和引入了信息条件信号，通过使用基于定向部分点云生成的相机依赖法线图，有效地解决了可见与不可见观测之间的歧义。此外，还提出了多视角人类中心的视频扩散模型，融合了参考视频、部分渲染和不同视角的信息，确保了生成视频的一致性，并提供了一种鲁棒的野外视频推断过程，大大减少了由单目深度估计不完美带来的伪影。", "conclusion": "在三个数据集上的广泛实验表明，MV-Performer在新颖视视频合成方面具有最先进的效果和鲁棒性，为人类中心的4D新颖视视频合成设定了一个强有力的模型。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07313", "html_url": "https://arxiv.org/abs/2510.07313", "title": "WristWorld: 利用4D世界模型生成腕部视角以提升机器人操作能力", "title_en": "WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation", "authors": "Zezhong Qian,Xiaowei Chi,Yuming Li,Shizun Wang,Zhiyuan Qin,Xiaozhu Ju,Sirui Han,Shanghang Zhang", "background": "现有模型依赖于大量的腕部视角数据，而这些数据在大规模数据集中极为稀缺。腕部视角捕捉细微的手物交互，对于提升操作性能至关重要。因此，大多数已有的世界模型无法填补腕部视角与基础框架视角之间的空白，因为它们需要腕部视角作为起始帧才能生成视频。视觉几何模型如VGGT虽然能处理极端视角变化，但依旧存在缺口，无法仅从基础框架视角生成腕部视角视频。基于此，我们提出了一种创新的4D世界模型WristWorld，能够仅从基础框架视角生成腕部视角视频，解决现有方法的问题和限制。", "innovation": "WristWorld是首个仅需基础框架视角便能生成腕部视角视频的4D世界模型。它采用了两个阶段：第一阶段是对重建，不仅扩展了VGGT，还融入了我们的空间投影一致性（SPC）损失来估算几何一致性姿态及4D点云；第二阶段则是生成，通过使用视频生成模型从重建视角生成时空一致的腕部视角视频。这一方法在Droid、Calvin和Franka Panda上的实验表明，WristWorld能够产生具有优越空间一致性的视频，同时提高VLA的效果，提升了Calvin任务的平均完成时长3.81%，并且缩小了腕部视角与基础视角之间的差距42.4%。", "conclusion": "WristWorld通过结合4D世界模型、空间投影一致性损失以及视频生成模型，成功填补了腕部视角与基础框架视角数据之间的空白，对于提升机器人操作系统的性能具有重要价值。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07249", "html_url": "https://arxiv.org/abs/2510.07249", "title": "TalkCuts: 多视角人类语音视频生成的大规模数据集", "title_en": "TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation", "authors": "Jiaben Chen,Zixin Wang,Ailing Zeng,Yang Fu,Xueyang Yu,Siyuan Cen,Julian Tanke,Yihang Chen,Koichi Saito,Yuki Mitsufuji,Chuang Gan", "background": "现有的数据集主要针对单视角、静态视点的人类语音视频生成研究，而TalkCuts提供了一个包含超过164,000个片段、总时长超过500小时的高质量人类语音视频的大规模数据集，涵盖多种视点如特写、半身和全身等。这个数据集包括详细的文字描述、2D关节点和3D SMPL-X动作注释，覆盖超过10,000个身份，有助于多模态学习和评估。", "innovation": "TalkCuts旨在通过提供一个多视角的数据集，解决现有研究关注不足的问题。它不仅包括高保真的人类语音视频，还包含详细的注释信息，覆盖多种视点和动作。作为数据集价值的第一个展示，提出了一个由LLM指导的多模态生成框架Orator，该框架通过多模态视频生成模块合成了连贯的长时间视频。实验结果表明，基于TalkCuts训练显著提高了多镜头语音视频的电影连贯性和视觉吸引力。", "conclusion": "我们相信TalkCuts为可控的、多镜头语音视频生成和更广泛的多模态学习提供了坚实的基础。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06235", "html_url": "https://arxiv.org/abs/2510.06235", "title": "使用现成、刺激调优和微调神经网络的堆叠回归预测电影刺激下的fMRI脑响应（Algonauts 2025 报告）", "title_en": "Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)", "authors": "Robert Scholz,Kunal Bagga,Christine Ahrends,Carlo Alberto Barbano", "background": "本文介绍了对2025年Algonauts挑战的提交，该挑战的目标是预测电影刺激下的fMRI脑响应。论文采取了结合多模态数据的方法，利用大语言模型的多模态表示、视频编码器、音频模型和视觉-语言模型，融合现成模型和微调模型的不同变体以提高预测性能。", "innovation": "本文的创新之处在于：1) 使用详细的转录和摘要增强文本输入信息；2) 探索语言和视觉模型的刺激调优和微调策略；3) 使用堆叠回归方法整合来自不同模型的预测，从而实现更稳定的预测效果。", "conclusion": "面向电影刺激的fMRI脑响应预测，团队“Seinfeld”的提案获得了第10名的好成绩，并公开了所有代码和资源，促进多模态编码模型在脑活动研究中的进一步发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06276", "html_url": "https://arxiv.org/abs/2510.06276", "title": "应用于癫痫相关MRI图像分割的一种带Total Variation正则化的框架", "title_en": "A Total Variation Regularized Framework for Epilepsy-Related MRI Image Segmentation", "authors": "Mehdi Rabiee,Sergio Greco,Reza Shahbazian,Irina Trubitsyna", "background": "FCD（Focal Cortical Dysplasia）是药物抵抗性癫痫的主要原因，但由于其病变的微小和细腻特性，准确识别在脑{磁共振成像}（MRI）中的FCD区域非常具有挑战性。三维多模态脑MRI图像中的FCD区域分割对于有效的手术规划和治疗至关重要，但这一任务仍然非常具有挑战性，因为标注数据的稀缺性、FCD病变的极小尺寸和弱对比度、处理三维多模态输入的复杂性以及需要平滑输出和解剖一致性，这些都是现有的体素损失函数所无法解决的问题。", "innovation": "本文提出了一种新的框架，用于在三维脑MRI图像中分割FCD区域。该框架采用最先进的带有变换增强的编码-解码架构，并引入了一种新的损失函数，结合Dice损失和各向异性{Total Variation}（TV）项。这种整合鼓励空间平滑并减少假阳性聚类，而无需依赖后续处理。", "conclusion": "该框架在公共FCD数据集上的85例癫痫患者中进行了评估，并证明与标准损失公式相比，分割准确性和连贯性都更优。具有所提出TV损失的模型的Dice系数提高了11.9%，精度提高了13.3%，假阳性聚类的数量减少了61.6%。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06481", "html_url": "https://arxiv.org/abs/2510.06481", "title": "递增视角优化以实现风险规避路径规划", "title_en": "Active Next-Best-View Optimization for Risk-Averse Path Planning", "authors": "Amirhossein Mollaei Khass,Guangyi Liu,Vivek Pandey,Wen Jiang,Boshu Lei,Kostas Daniilidis,Nader Motee", "background": "在具有不确定性的环境中实现安全导航需要将风险规避与主动感知结合起来的规划方法。在本工作中，我们提出了一种统一框架，通过从在线更新的3D Gaussian-splat Radiance Field的Average Value-at-Risk统计构建尾敏感的风险图来精细化粗糙的参考路径。这些地图能够生成局部安全和可行的轨迹。同时，我们将Next-Best-View (NBV) 选择公式化为SE(3)姿态流形上的优化问题，在这里采用黎曼梯度下降以最大化期望信息增益目标，从而最大限度地减少对未来关键运动最相关的不确定性。", "innovation": "我们的方法通过将风险规避路径细化与视图选择规划相结合，向前推进了最先进的技术，同时引入了可扩展的梯度分解，支持复杂环境下的高效在线更新。", "conclusion": "我们通过广泛的计算研究展示了所提出框架的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06284", "html_url": "https://arxiv.org/abs/2510.06284", "title": "通过图像识别进行结的检测", "title_en": "On knot detection via picture recognition", "authors": "Anne Dranowski,Yura Kabkov,Daniel Tubbenhauer", "background": "本文的目标是在未来能够拍摄一张结的照片，让手机自动识别出这个结。研究团队提出了一种策略，使用现代机器学习方法（特别是用于图像识别的卷积神经网络和变压器）与传统算法（如计算Jones多项式等量子不变量）相结合的方法来接近这一目标。", "innovation": "本文介绍了一种结合机器学习和传统算法的方法，通过直接从图像预测交叉数来识别结。即使使用轻量级的CNN和变压器架构，也能够恢复有意义的结构信息。长期目标是将感知模块与符号重构结合，生成平面图代码，进一步计算结的不变量，以实现鲁棒的结分类。这种方法突显了机器学习处理嘈杂视觉数据与不变量执行严格的拓扑区分之间的互补性。", "conclusion": "本文通过结合机器学习和传统算法，展示了在图像识别结方面的一种新策略。通过这一两阶段的方法，处理图像识别中的噪声数据和利用不变量进行严格的拓扑区分得到了有效的结合，从而推进了对结的自动识别技术。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06335", "html_url": "https://arxiv.org/abs/2510.06335", "title": "基于条件去噪扩散模型的高过采样比MRI图像稳健重建", "title_en": "Conditional Denoising Diffusion Model-Based Robust MR Image Reconstruction from Highly Undersampled Data", "authors": "Mohammed Alsubaie,Wenxi Liu,Linxia Gu,Ovidiu C. Andronesi,Sirani M. Perera,Xianqi Li", "background": "磁共振成像（MRI）在现代医疗诊断中是一项关键工具，但其长时间的数据获取仍然是一个关键限制，特别是在时间敏感的临床情境中。虽然欠采样策略可以加快图像获取，但通常会带来图像伪影和质量下降。最近的扩散模型显示了从欠采样数据重建高质量图像的潜力，但大多数现有方法要么依赖于无监督评分函数，而无配对监督；要么仅在后处理步骤中应用数据一致性。", "innovation": "本文提出了一种条件去噪扩散框架，与以往方法不同，该框架通过嵌入测量模型直接到每一个逆向扩散步骤，并在配对的欠采样-真实图像数据上进行模型训练，实现了生成灵活性与MRI物理性质显式约束的结合。实验表明，该框架在SSIM、PSNR和LPIPS上显著优于近年来最先进的深度学习和基于扩散的方法，尤其是真实感知度指标LPIPS更加准确地捕获感知改进。", "conclusion": "这些结果表明，将条件监督与迭代一致性更新相结合，可以大大改善像素级保真度和感知现实度，朝着稳健、加速的MRI重建提供了一个有原则且实用的进展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06280", "html_url": "https://arxiv.org/abs/2510.06280", "title": "外科医生是印度男性，言语治疗师是白人女性：医疗专业人员中视觉-语言模型的偏见审计", "title_en": "Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals", "authors": "Zohaib Hasan Siddiqui,Dayam Nadeem,Mohammad Masudur Rahman,Mohammad Nadeem,Shahab Saquib Sohail,Beenish Moalla Chaudhry", "background": "视觉语言模型（VLMs），如CLIP和OpenCLIP，可以编码并反映从网络规模数据中学习到的医疗专业与人口统计属性之间的典型关联。因此，研究者提出了一种评估医疗环境中的偏见量化和评估其运营风险的评估协议。该研究通过定义涵盖临床医生和相关医疗角色（例如，外科医生、心脏科医生、牙医、护士、药剂师、技术人员）的分类体系，构建了基于角色的提示套件来探究模型行为，以及与平衡面孔数据集对比人口统计偏差来进行基准测试，以观察跨多个角色和视觉模型的一致的人口统计偏差。实证研究结果揭示了医疗等关键领域中的偏见识别的重要性，因为基于AI的招聘和劳动力分析可能对公平性、合规性和患者的信任产生下游影响。", "innovation": "研究方法定义了一个涵盖临床医生和相关医疗角色的分类体系，构建了一个基于角色的提示套件，对比平衡面部数据集来基准测试人口统计偏差，有效评估了医疗专业人员中视觉语言模型的偏见，强调了在AI辅助招聘和劳动力分析中的偏见识别的重要性。", "conclusion": "该研究揭示了视觉-语言模型在医疗专业人员中存在的人口统计偏差，并强调了识别这些偏见在确保公平性、合规性和保护患者信任方面的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06283", "html_url": "https://arxiv.org/abs/2510.06283", "title": "SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation", "title_en": "SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation", "authors": "Sashank Makanaboyina", "background": "增量脑肿瘤分割对于能够适应不断进化的临床数据集而无需重新训练全部先前数据的模型至关重要。然而，灾难性遗忘问题使得模型会丧失之前获取的知识，这是一个主要障碍。尽管最近有一些增量学习框架结合知识蒸馏能够部分缓解遗忘现象，但这些方法过度依赖生成回放或辅助存储。同时，扩散模型在精装修瘤分割方面表现出色，但尚未在增量学习的背景下进行探索。", "innovation": "我们提出了合成错误回放扩散(SER-Diff)框架，这是首次将基于扩散的精装修瘤与增量学习结合起来的方法。SER-Diff 利用冻结的教师扩散模型生成过去任务的合成错误图，在新任务训练时重新播放这些错误。通过结合Dice损失和知识蒸馏损失的双损失形式，确保模型具备适应性和知识保留。实验结果表明，SER-Diff 在BraTS2020、BraTS2021 和 BraTS2023 上优于先前方法，得到了更高的Dice评分和更低的HD95值，显示出其不仅缓解了灾难性遗忘，还提供了更准确且解剖上一致的分割结果。", "conclusion": "SER-Diff 不仅在增量脑肿瘤分割中显著优于先前方法，还展示了更精确和解剖学上一致的分割结果，这一结果进一步证实了它的有效性和重要性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07302", "html_url": "https://arxiv.org/abs/2510.07302", "title": "SpecGuard: 基于频谱投影的先进隐形水印", "title_en": "SpecGuard: Spectral Projection-based Advanced Invisible Watermarking", "authors": "Inzamamul Alam,Md Tanvir Islam,Khan Muhammad,Simon S. Woo", "background": "现有的水印嵌入方法往往在面对各种转换（包括失真、图像再生和对抗性扰动）时缺乏鲁棒性，这为实际应用带来了挑战。因此，研究如何开发一种既具备鲁棒性又不可感知的图像水印方法是必要的和关键的。", "innovation": "本文提出了一种新颖的水印方法SpecGuard，通过将消息嵌入到隐藏的卷积层中，使用从空间域转换到频谱域的频谱投影技术，并结合小波投影分解高频带。频谱投影利用快速傅里叶变换近似有效转换空间数据到频谱域。在编码阶段，通过强度因子增强模型对多种攻击（如对抗性、几何和再生干扰）的鲁棒性，确保版权信息的保存。解码器利用帕斯瓦尔定理有效地学习和提取水印模式，即使在挑战性变换中也能实现精确检索。", "conclusion": "通过对比测试，SpecGuard在嵌入水印的不可见性、容量和鲁棒性方面表现优于现有最先进的模型。为了确保可再现性，本文已将完整代码发布在GitHub上。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07317", "html_url": "https://arxiv.org/abs/2510.07317", "title": "量子增强的计算机视觉：超越经典算法", "title_en": "Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms", "authors": "Natacha Kuete Meli,Shuteng Wang,Marcel Seelbach Benkner,Michele Sasdelli,Tat-Jun Chin,Tolga Birdal,Michael Moeller,Vladislav Golyanik", "background": "量子增强的计算机视觉（QeCV）是一个跨领域研究领域，结合了计算机视觉、优化理论、机器学习和量子计算。量子计算利用量子力学效应进行计算，超越了经典（即非量子）计算机无法处理的问题。在现有非量子方法无法在合理时间内找到解决方案或仅能计算近似解的情景中，量子计算机能够在多个问题类别中提供更好的时间可扩展性等优势。参变量量子电路在长远来看也可能成为计算机视觉中经典神经网络的重要替代品。然而，为了确保量子硬件的兼容性，并揭示量子计算范式在计算机视觉中的潜力，需要开发专门且全新的算法。", "innovation": "该论文为量子增强的计算机视觉领域贡献了一个系统的综述，旨在为计算机视觉社区提供量子计算参考。它介绍了QeCV的核心概念、特点和与量子硬件兼容的方法论，特别关注基于门的量子计算和量子退火这两种主要的量子计算范式。此外，还详细讨论了量子计算机的操作原理以及可用于编程和模拟的工具，特别是在计算机视觉领域的应用。", "conclusion": "论文回顾了现有的量子计算工具和学习材料，并讨论了QeCV论文的出版和评审方面的问题，还讨论了与QeCV相关的开放挑战和社会影响。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06518", "html_url": "https://arxiv.org/abs/2510.06518", "title": "在空中机器人上使用传感器融合进行实时玻璃检测和重投影", "title_en": "Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard Aerial Robots", "authors": "Malakhi Hopkins,Varun Murali,Vijay Kumar,Camillo J Taylor", "background": "自主飞行机器人在现实世界场景中的应用越来越多，但透明障碍物的存在对可靠导航和制图构成重大挑战。传统感知系统难以应对透明物体，缺乏明显特征，导致惯常使用的深度传感器失效，进而产生不准确的地图和潜在碰撞。为了确保安全导航，机器人必须准确检测和绘制这些透明障碍物。现有方法往往依赖于大型、昂贵的传感器或需要高计算资源的算法，对于小型、重量轻、功率低（SWaP）的机器人来说并不适用。", "innovation": "本文提出了一种新颖且计算效率高的框架，用于在小于300g的四旋翼无人机上检测和绘制透明障碍物。该方法融合了飞行时间（ToF）摄像机数据和超声波传感器数据，结合一个自定义的轻量级2D卷积模型。该特定方法能够精确检测镜面反射并将其深度传播到深度图中的相应空洞区域，从而有效使透明障碍物变得可见。整个流程在嵌入式处理器上实时运行，仅占用一个小核心的CPU资源。", "conclusion": "我们通过在受控和真实环境中的系列实验验证了我们的系统。该机器人成功绘制了包含玻璃的室内环境地图，显示出我们的方法的有效性。据我们所知，这是首次在低SWaP四旋翼无人机上使用CPU实现即时、机载透明障碍物测绘系统的作品。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06784", "html_url": "https://arxiv.org/abs/2510.06784", "title": "Bionetta：高效的客户端零知识机器学习验证", "title_en": "Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving", "authors": "Dmytro Zakharov,Oleksandr Kurbatov,Artem Sdobnov,Lev Soukhanov,Yevhenii Sekhin,Vitalii Volovyk,Mykhailo Velykodnyi,Mark Cherepovskyi,Kyrylo Baibula,Lasha Antadze,Pavlo Kravchenko,Volodymyr Dubinin,Yaroslav Panasenko", "background": "本文比较了UltraGroth为基础的零知识机器学习框架Bionetta与EZKL、Lagrange's deep-prove或zkml等类似工具的性能。结果显示，对于定制神经网络，Bionetta显著提高了证明时间，甚至可以在移动设备上进行证明，这开启了众多客户端侧证明应用的可能性。", "innovation": "方案通过提高一次性的预处理步骤成本（如电路编译和可信设置），显著提升了定制神经网络的证明时间，使其能够在移动设备上运行。Bionetta是目前已知的唯一能够在原生EVM智能合约上部署的框架，同时确保了证明大小和验证开销不会过于庞大。", "conclusion": "Bionetta框架能够显著提升定制神经网络的证明性能，甚至可以在资源有限的移动设备上进行证明，具有广泛的应用潜力。尽管这需要更高的初始化成本，但仍优于同类竞品并提供了部署灵活性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06754", "html_url": "https://arxiv.org/abs/2510.06754", "title": "UniFField: 任意场景中的视觉、语义和空间不确定性统一的可移植神经特征场", "title_en": "UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene", "authors": "Christian Maurer,Snehal Jauhri,Sophie Lueth,Georgia Chalvatzaki", "background": "3D场景的全面视觉、几何和语义理解对于机器人在非结构化和复杂环境中成功执行任务至关重要。此外，为了做出稳健的决策，机器人需要评估感知信息的可靠性。虽然近年来3D神经特征场的发展使机器人能够利用预训练基础模型的特征进行语言引导的操控和导航等任务，但现有方法存在两个关键限制：场景特定性和不能建模预测的不确定性。", "innovation": "我们提出了一个统一的感知不确定性神经特征场UniFField，它将视觉、语义和几何特征结合在一个通用表示中，同时预测每种模态的不确定性。该方法可以零样本应用于任何新环境，随着机器人探索场景，逐步将RGB-D图像整合到基于体素的特征表示中，同时更新不确定性估计。我们的不确定性估算能够准确描述场景重建和语义特征预测的模型预测误差。此外，我们利用我们的特征预测及其不确定性成功地进行了一种移动机械人操作对象搜索任务，证明了其进行稳健决策的能力。", "conclusion": "我们的研究展示了UniFField在任意场景中对视觉、语义和空间不确定性的统一建模的能力，以及其在机器人探索场景、处理不确定性信息和进行稳健决策方面的应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06621", "html_url": "https://arxiv.org/abs/2510.06621", "title": "FEAorta: 从3D CT图像进行腹主动脉有限元分析的全自动化框架", "title_en": "FEAorta: A Fully Automated Framework for Finite Element Analysis of the Aorta From 3D CT Images", "authors": "Jiasong Chen,Linchen Qian,Ruonan Gong,Christina Sun,Tongran Qin,Thuy Pham,Caitlin Martin,Mohammad Zafar,John Elefteriades,Wei Sun,Liang Liang", "background": "主动脉瘤在美国人口中始终是前20位死因之一。胸主动脉瘤表现为胸主动脉壁异常膨出，是成人死亡的主要原因之一。从生物力学角度看，破裂发生在主动脉壁承受的应力超过壁强度时。可以利用计算生物力学分析，特别是结构有限元分析来获取壁应力分布。通过对材料失效模型进行比较，可以计算出胸主动脉瘤(TAA)的统计破裂风险。尽管目前有针对患者特定层面的TAA破裂风险评估的工程工具，但由于两个主要障碍在临床上的应用仍然有限：首先是当前患者特定解剖建模仍然依赖于手动分割，这既耗时又难以扩大到大量患者群体；其次是有限元模拟的计算负担使它无法与时间敏感的临床工作流程兼容。我们的团队通过开发PyTorch FEA库和FEA DNN集成框架成功地克服了这些障碍。通过将有限元功能整合进PyTorch FEA，并应用静态定性原理，我们将基于有限元的应力计算时间缩短到每例病例约3分钟。进一步通过PyTorch FEA库将DNN和FEA集成，我们的方法将计算时间缩短到每例病例只有几秒钟。这项工作的重点是通过开发一个能够直接从3D CT图像生成患者特定有限元网格的端到端深度神经网络来克服第一个障碍，从而实现全自动的有限元分析框架FEAorta。", "innovation": "开发了PyTorch FEA库和FEA DNN集成框架，通过将有限元分析功能与深度学习技术结合，极大地提高了创建患者特定有限元模型和计算应力的速度，降低了临床工作流程的计算负担。", "conclusion": "通过FEAorta框架，可以从3D CT图像自动化生成患者特定的有限元模型，从而快速准确地评估胸主动脉瘤的破裂风险，助力临床决策。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06635", "html_url": "https://arxiv.org/abs/2510.06635", "title": "StruSR: 结构感知的物理指导符号回归", "title_en": "StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance", "authors": "Yunpeng Gong,Sihan Lan,Can Yang,Kunpeng Xu,Min Jiang", "background": "符号回归旨在通过在数学公式空间中搜索来找到可解释的分析表达式，以捕捉系统的底层行为，特别是在由物理定律支配的科学建模中。然而，传统方法缺乏从时间序列观测中提取结构化物理先验的机制，这使得难以捕捉反映系统全局行为的符号表达式。", "innovation": "本文提出了一种称为StruSR的结构感知符号回归框架，该框架利用训练好的物理感知神经网络（PINNs）从时间序列数据中提取局部结构化的物理先验。通过对训练好的PINN的输出进行局部泰勒展开，获得基于导数的结构信息以指导符号表达式的演化。此外，通过引入基于掩码的归因机制，量化每个子树对结构对齐和物理残差减少的贡献，从而调整遗传编程中的变异和克隆操作，保留具有高度物理或结构意义的子结构，同时选择性地修改信息量较少的组件。该混合适应度函数同时最小化物理残差和泰勒系数失配，确保与给定的微分方程一致，并结合PINN捕获的局部分析行为。", "conclusion": "在基准偏微分方程系统上的实验表明，StruSR在收敛速度、结构保真度和表达式的解释性方面优于传统基准，提供了一种以物理为依据的符号发现原则性范式。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06637", "html_url": "https://arxiv.org/abs/2510.06637", "title": "控制增强的自回归扩散模型在数据同化中的应用", "title_en": "Control-Augmented Autoregressive Diffusion for Data Assimilation", "authors": "Prakhar Srivastava,Farrin Marouf Sofian,Francesco Immorlano,Kushagra Pandey,Stephan Mandt", "background": "尽管近年来测试时缩放和微调扩散模型取得了进展，但在自回归扩散模型（ARDMs）中，如何提供引导仍然未被充分探索。现有方法在混沌时空偏微分方程（PDEs）的数据同化（DA）场景中往往计算资源受限，且在稀疏观测条件下容易出现预报漂移问题。传统的数据同化方法通常需要昂贵的后向计算和优化过程，这在实际应用中是一个挑战。", "innovation": "该论文提出了一个适配框架，该框架通过引入一个轻量级的控制器网络来增强预训练的ARDMs，控制器网络在离线训练中通过预览未来ARDMs的滚动预测学习逐步控制，以在终端成本目标下预测即将到来的观测值。这种方法将数据同化的推理过程简化为一次前向滚动预测，在推理过程中能够实时纠正预测，避免了昂贵的后向计算和优化。这一方法在两个典型的PDEs和六种观测条件下展示了对现有四种最先进的基线方法在稳定性、准确性和物理保真度上的优势。", "conclusion": "该方法在混沌时空偏微分方程的数据同化中表现出色，在两种标准PDE和六种观测条件下，与四个最新基准方法相比，在稳定性、准确性和物理保真度方面一直具有优势。作者还表示未来将公开发布代码和检查点。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06629", "html_url": "https://arxiv.org/abs/2510.06629", "title": "SpikeNeuron", "title_en": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks", "authors": "Jiachen Li,Bang Wu,Xiaoyu Xia,Xiaoning Liu,Xun Yi,Xiuzhen Zhang", "background": "Spiking Neural Networks (SNNs)因其在能耗上的优势而受到越来越多的关注，但它们在后门攻击下的安全性问题并未受到足够的关注。现有的针对人工神经网络(ANNs)的防御方法在SNNs中效果不佳或容易被绕过，主要由于SNNs的事件驱动和时间依赖性特点。本文识别了传统SNN后门防御的关键阻碍，并提出了一种无监督的后训练检测框架Temporal Membrane Potential Backdoor Detection (TMPBD)来克服这些挑战。TMPBD利用最终脉冲层的时间膜电位TMP的最大边缘统计，无需任何攻击知识或数据访问即可检测目标标签。", "innovation": "提出了无监督的后训练检测框架Temporal Membrane Potential Backdoor Detection (TMPBD)和一种抗攻击机制Neural Dendrites Suppression Backdoor Mitigation (NDSBM)。TMPBD利用了最终脉冲层的时间膜电位TMP的最大边缘统计，无需任何攻击知识或数据访问即可检测目标标签。NDSBM通过控制早卷积层的树突连接来抑制有害神经元，同时保留良性行为，利用从少量干净且未标记的数据集中提取的TMP进行指导。", "conclusion": "通过在多个神经形态基准测试上进行的详尽实验，并与最先进的输入感知动态触发攻击进行比较，结果显示TMPBD实现了100%的检测准确率，NDSBM将攻击成功率从100%降低到8.44%，联合使用后降至2.81%，而不会降低清洁准确性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06646", "html_url": "https://arxiv.org/abs/2510.06646", "title": "机器学习算子中的零样本超分辨率的虚假承诺", "title_en": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators", "authors": "Mansi Sakarvadia,Kareem Hegazy,Amin Totounferoush,Kyle Chard,Yaoqing Yang,Ian Foster,Michael W. Mahoney", "background": "在科学机器学习和更广泛的科学研究计算中，一个核心挑战是建模连续现象，而在实践中这些现象是离散化表示的。机器学习算子（MLOs）被引入用以实现这一建模目标，因为这类架构可以在任意分辨率上进行推理。本文探讨了这种架构创新是否足以实现“零样本超分辨率”，即让模型能在比初始训练分辨率更高的数据上提供推理。研究集中在MLOs的多分辨率推理表现，将多分辨率推理分解为两个关键行为：1）根据不同的频率信息进行外推；2）从不同的分辨率进行内插。研究表明，MLOs在零样本推理下无法完成这两个任务，即模型在未训练过的分辨率上无法提供准确的推理，并且表现出脆弱性且容易产生混叠现象。为了克服这些模式，本文提出了一个简单、计算效率高且数据驱动的多分辨率训练协议，以避免混叠并实现多分辨率泛化.", "innovation": "本文提出了一个新颖的多分辨率训练协议，该协议简单、计算效率高且数据驱动，旨在解决MLOs在未训练过的分辨率上的零样本问题和混叠现象，从而提供稳健的多分辨率泛化能力.", "conclusion": "研究表明，MLOs无法在未训练过的分辨率上实现准确推理，而是容易表现出脆弱性和混叠。因此，本文建议了一个多分辨率训练协议来解决这些问题，该协议能够避免混叠并提供多分辨率泛化的鲁棒性."}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06782", "html_url": "https://arxiv.org/abs/2510.06782", "title": "GPT-5模型修正了GPT-4V的图表阅读错误，而不是提示", "title_en": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting", "authors": "Kaichun Yang,Jian Chen", "background": "本文的研究背景是评估零样本大规模语言模型（LLMs）及其提示在图表阅读任务中的效果。研究者希望了解当前的LLMs在处理难度较高的图像实例时的表现，并比较不同模型和提示策略之间的差异。", "innovation": "本文的创新在于首次对GPT-5和GPT-4V在处理视觉化问题上的表现进行了定量评估，尤其是在处理难度较高的图像实例时，GPT-4V未能产生正确的答案。研究发现模型架构对推理准确率的影响远大于提示策略。", "conclusion": "研究结果表明，模型架构是影响推理准确率的关键因素。GPT-5的架构显著提高了准确率，而不同的提示策略只产生了微小的效果。此外，GPT-5能够纠正GPT-4V在图表阅读中的错误，而不是提示策略起到了主要作用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06907", "html_url": "https://arxiv.org/abs/2510.06907", "title": "通过SpherePair损失进行角度约束嵌入以实现约束聚类", "title_en": "Angular Constraint Embedding via SpherePair Loss for Constrained Clustering", "authors": "Shaojie Zhang,Ke Chen", "background": "现有的深度约束聚类（DCC）方法要么受到端到端建模中锚点的限制，要么难以学习判别性的欧几里得嵌入，这限制了它们的可扩展性和在现实世界中的应用。", "innovation": "提出了一种新的角度约束嵌入方法，称为SpherePair，该方法使用几何公式的SpherePair损失，可以忠实编码成对约束，并导致在角度空间中易于聚类的嵌入。这种方法分离了表示学习和聚类，而没有成对关系冲突，并固化了成对关系而无需指定确切的聚类数量，可以处理未见过的数据，并能够快速确定聚类数量。", "conclusion": "与最先进的DCC方法在各种基准上的比较评估，以及对理论洞察力的实证验证，证实了其优越性能、可扩展性和实用效果。代码可在我们的仓库中找到。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06802", "html_url": "https://arxiv.org/abs/2510.06802", "title": "Capture and Interact: 使用高斯点云在Unity中快速获取和渲染3D物体", "title_en": "Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity", "authors": "Islomjon Shukhratov,Sergey Gorinsky", "background": "实时捕捉和渲染三维（3D）物体依旧是一项重大的挑战，但这些技术在增强现实、数字孪生系统、远程协作和原型设计等领域具有巨大的应用潜力。本文介绍了一种端到端的工作流程，利用3D高斯斑点（3D GS）技术，使用户能够使用移动设备、云处理和本地计算机快速获取和交互地渲染真实世界中的物体。用户只需用智能手机拍摄视频，上传并进行自动3D重建，在Unity中以平均每秒150帧的速度进行实时渲染。该系统结合了移动捕捉、基于云的3DGS和Unity渲染，支持实时远程存在感。实验表明，该流水线在图形处理单元（GPU）上处理扫描大约需要10分钟，实现笔记本电脑上的实时渲染。", "innovation": "该研究提出了一种利用3D高斯斑点进行快速3D物体捕捉和实时渲染的端到端工作流程。该技术的关键创新点在于结合了移动设备捕捉、云处理和Unity渲染，实现了从拍摄到实时交互地展示物体的全过程，大大加速了3D物体的捕捉和处理，并实现了快速的实时渲染。", "conclusion": "该研究展示了一种基于3D高斯斑点的实时三维物体捕捉和交互渲染的端到端方法，在GPU上处理扫描数据大约需要10分钟，并能够在笔记本电脑上实现实时渲染。这种方法极大地提高了3D现实捕捉的速度与效率，为相关应用领域带来了便利。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06982", "html_url": "https://arxiv.org/abs/2510.06982", "title": "重访 Mixout：通往鲁棒微调的一种被忽视的方法", "title_en": "Revisiting Mixout: An Overlooked Path to Robust Finetuning", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Eric Granger,Marco Pedersoli", "background": "微调视觉基础模型通常可以提高特定领域内的准确性，但代价是分布转移下的鲁棒性下降。本文重新审视了 Mixout，这是一种通过在微调权重中不时替换为预训练参考来提高模型鲁棒性的随机正则化技术，通过单一运行、权重共享的隐式集成视角来探讨。这种视角揭示了三个关键杠杆：遮罩锚点、重采样频率和遮罩稀疏度。", "innovation": "引入了 GMixout，通过使用在训练期间不断适应的指数移动平均快照替换固定的遮罩锚点，以及通过显式的重采样频率超参数调节遮罩周期，从而提供了两个创新点。此外，该方法为稀疏内核实现仅更新小部分参数，没有任何推理时的开销，允许在消费级 GPU 上进行训练。实验表明，GMixout 在涵盖协变量转移、污染和类别不平衡基准测试(ImageNet / ImageNet-LT、DomainNet、iWildCam、CIFAR100-C) 上，不仅在领域内提高了准确性，而且在分布转移下还超过了 Model Soups 和强大的参数有效微调基准线。", "conclusion": "GMixout 既能保持领域内的高准确性，又能在分布转移下大幅提升模型的鲁棒性，同时还能在消费级 GPU 上有效训练。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06871", "html_url": "https://arxiv.org/abs/2510.06871", "title": "SaFeR-VLM: 朝着 multimodal 模型细粒度安全意识推理的方向", "title_en": "SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models", "authors": "Huahui Yi,Kun Wang,Qiankun Li,Miao Yu,Liang Lin,Gongli Xi,Hao Wu,Xuming Hu,Kang Li,Yang Liu", "background": "现有的多模态大型推理模型（MLRMs）虽然在跨模态推理方面表现出色，但在对抗性或潜在不安全的提示下往往会放大安全风险，这种现象被称为“推理税”。现有的防御措施主要在输出层面发挥作用，不约束推理过程，导致模型暴露在潜在风险中。", "innovation": "本文提出了一种名为 SaFeR-VLM 的安全对齐强化学习框架，该框架将安全直接嵌入多模态推理中。该框架包括四个组成部分：（I）QI-Safe-10K，一个专注于安全关键和推理敏感案例的精心策划的数据集；（II）带有反思和纠正的安全意识展开，而不是直接丢弃不安全的生成；（III）结构化的奖励建模，使用多维度加权标准和对幻觉和矛盾的显式惩罚；以及（IV）GRPO 优化，这可以强化安全和已纠正的轨迹。此统一设计将安全性从被动的安全屏障转变为推理过程中的主动驱动力，从而实现可扩展和普适的安全感知推理。", "conclusion": "SaFeR-VLM 进一步证明对其它显示性和隐性风险具有鲁棒性，支持动态和可解释的安全决策，而不只是表面过滤。在六个基准测试上，SaFeR-VLM-3B 在安全性和有用性方面的平均性能达到 70.13 和 78.97，超过了同规模和大于 10 倍的大型模型。此外，随着模型规模的增加，SaFeR-VLM-7B 在安全性指标上超过了 GPT-5-mini 和 Gemini-2.5-Flash，而不会在有用性性能上退步。代码已发布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06955", "html_url": "https://arxiv.org/abs/2510.06955", "title": "高频率Mixout：重新审视Mixout以增强领域泛化鲁棒性", "title_en": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Eric Granger,Marco Pedersoli", "background": " fine-tuned 模型初始化来自强大的预训练权重的集成是一种提高在数据分布偏移下鲁棒性的常见策略，但这也伴随着巨大的计算成本，因为需要训练和存储多个模型。Dropout 通过随机神经元停用来模拟集成，是一种轻量级替代方案。然而，当应用到预训练模型上时，Dropout 通常会过度正则化，破坏对泛化至关重要的先前表示。因此，研究团队探讨了 Mixout 这种具有替代 Dropout 的随机正则化技术，以适用于领域泛化.", "innovation": "Mixout 通过在训练过程中以概率将精细调整后的权重与预训练权重进行交换，从而减轻过拟合，而不是单纯停用神经元。这种技术在不牺牲模型适应性的情况下保持了对先前知识的保留。研究表明，实现领域泛化的强性能需要 ViTs 使用 0.9 的掩码概率和 ResNets 使用 0.8 的掩码概率。高频率 Mixout 同时提供更好的泛化和显著降低计算成本：梯度计算减少至多 45%，梯度内存使用减少至多 90%。这种方法在五个领域泛化基准 (PACS, VLCS, OfficeHome, TerraIncognita, DomainNet) 上使用 ResNet 和 ViT 架构的实验表明，这种方法在领外域准确度方面与集成方法相当，同时大幅降低了训练成本.", "conclusion": "结论表明，高频率 Mixout 方法在不显著增加计算成本的情况下，能够实现与集成方法相当的领域泛化性能。这为提高机器学习模型在面临分布偏移时的鲁棒性提供了新的途径。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07018", "html_url": "https://arxiv.org/abs/2510.07018", "title": "基于模型清晰度的数据生成方法在零样本量化中的应用", "title_en": "Sharpness-Aware Data Generation for Zero-shot Quantization", "authors": "Dung Hoang-Anh,Cuong Pham Trung Le,Jianfei Cai,Thanh-Toan Do", "background": "零样本量化旨在从预先训练的全精度模型中学习量化模型，而无需访问原始真实训练数据。现有的零样本量化方法通常通过生成合成数据来量化全精度模型，但这些方法没有考虑量化模型的清晰度作为生成训练数据的标准，尽管低清晰度的深度神经网络通常有更强的泛化能力。这篇论文提出了一种新的方法，通过考虑量化模型的清晰度来生成合成数据，以提高泛化性能。", "innovation": "论文提出了一种新的零样本量化方法，首次将量化模型的清晰度作为合成数据生成的标准。具体来说，通过最大化合成数据和真实验证数据的重建损失梯度之间的匹配来最小化清晰度，同时通过近似每个生成样本与其邻居之间的梯度匹配来解决没有真实验证集的问题。这种方法在低比特量化设置中展示了优于现有技术的效果。", "conclusion": "实验结果表明，在CIFAR-100和ImageNet数据集上，该方法在低比特量化设置中优于当前最先进的技术。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07053", "html_url": "https://arxiv.org/abs/2510.07053", "title": "学习的语义场景图局部化中的反省", "title_en": "Introspection in Learned Semantic Scene Graph Localisation", "authors": "Manshika Charvi Bissessur,Efimia Panagiotaki,Daniele De Martini", "background": "该研究探讨了语义如何影响在一种基于对比学习的语义局部化框架中的定位性能和鲁棒性。在对原始地图和扰动地图进行训练后，作者进行了一项详尽的事后反省分析，以探究模型是否能够过滤环境噪声，并优先处理特征明显的地标而非普通杂乱信息。此外，研究验证了多种可解释性方法，并进行了一项比较可靠性分析，结果表明集成梯度和注意力权重是最可靠的模型行为探针。进一步的语义类别消融实验揭示了这种隐含的加权机制，其中频繁出现的对象往往被下调权重。总体而言，研究结果表明模型能够学习噪声鲁棒、语义显著的空间关系，从而在具有挑战性的视觉和结构变化下实现可解释的注册。", "innovation": "研究创新性地采用了对比学习的方法进行语义本地化，同时提出了一种详尽的事后反省分析框架。研究验证了多种解释性方法，并发现集成梯度和注意力权重是可靠的模型行为探针。研究进一步揭示了模型隐含的权重机制，即频繁出现的对象经常被下调权重，表明语义本地化模型在处理常见对象时具有一定的鲁棒性。", "conclusion": "研究结果表明，模型能够学习环境中的噪声鲁棒、语义显著的空间关系，从而能够在复杂场景变化中实现有效的可解释注册。通过这种方法，模型不仅提升了定位的性能，还通过解释性方法增强了其可解释性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07181", "html_url": "https://arxiv.org/abs/2510.07181", "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "title_en": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "authors": "Yi Han,Cheng Chi,Enshen Zhou,Shanyu Rong,Jingkun An,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang", "background": "视觉语言模型（VLMs）在空间推理方面展现出了卓越的能力，但仍存在根本性的局限性，主要是定性的精确度不足，无法满足现实机器人操作所需的计算精确度。当前的方法未能利用深度传感器和相机校准提供的度量线索，而是将几何问题简化为模式识别任务，这无法提供厘米级别的精确度，这对于机器人操作来说是必不可少的。", "innovation": "TIGeR（工具集成几何推理）是一个新颖的框架，它通过使视觉语言模型能够生成和执行精确的几何计算，从而将它们从感知估计器转变为几何计算器。该框架允许模型识别几何推理需求，合成适当的计算代码，并调用专门的库进行精确计算。为此，作者引入了TIGeR-300K数据集，涵盖了点变换、姿态估计、轨迹生成和空间兼容性验证，并包含工具调用序列和中间计算。", "conclusion": "TIGeR通过结合监督微调（SFT）和强化微调（RFT）以及我们提出的一级奖励设计，在几何推理基准上实现了最佳性能，同时在真实世界机器人操作任务中展示了厘米级别的精确度。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07134", "html_url": "https://arxiv.org/abs/2510.07134", "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking", "title_en": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking", "authors": "Jiahang Liu,Yunpeng Qi,Jiazhao Zhang,Minghan Li,Shaoan Wang,Kui Wu,Hanjing Ye,Hong Zhang,Zhibo Chen,Fangwei Zhong,Zhizheng Zhang,He Wang", "background": "Embodied Visual Tracking (EVT) 是一种基础能力，支撑着诸如伴侣机器人、引导机器人和客户服务助理等实用应用。这些应用需要持续跟踪移动目标。尽管最近的技术进步使语言引导下的在复杂、无结构场景中的跟踪成为可能，但现有方法缺乏显式的空间推理和有效的时序记忆，导致在严重遮挡或存在类似干扰物的情况下会失败。因此，需要改进的视觉语言行动模型来解决这些挑战。", "innovation": "提出了 TrackVLA++，这是一种新型的视觉-语言-行动 (VLA) 模型，通过两个关键模块—空间推理机制和目标识别记忆 (TIM)—增强了体感触觉视觉跟踪。引入了名为 Polar-CoT 的链式推理范式，以推断目标的相对位置并将其编码为紧凑的极坐标标记，用于行动预测。基于这些空间先验，TIM 使用门控更新策略保持长期目标记忆，确保时空一致性并缓解在长时间遮挡期间的目标丢失。", "conclusion": "Extensive 实验表明，TrackVLA++ 在公共基准上实现了最先进的性能，无论是第一人称视角还是多摄像头设置。在具有挑战性的 EVT-Bench DT 分裂中，TrackVLA++ 分别超越了前领方法 5.1 和 12。此外，TrackVLA++ 具有强大的零样本泛化能力，使其在动态和遮挡场景中实现稳健的现实世界跟踪。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1910.11030", "html_url": "https://arxiv.org/abs/1910.11030", "title": "基于时空瓦片的注意力导向LSTMs的交通视频预测", "title_en": "Spatiotemporal Tile-based Attention-guided LSTMs for Traffic Video Prediction", "authors": "Tu Nguyen", "background": "交通4预测挑战2019的任务要求模型在保留长时间序列间的时间关系的同时，同时建模细粒度的（像素级）和粗粒度的（区域级）空间结构。为了应对这一挑战，研究团队基于Conv-LSTM的想法，提出了一种基于瓦片的注意力导向的递归神经网络解决方案。", "innovation": "该研究引入了一种瓦片感知、级联记忆的Conv-LSTM，该模型增加了跨帧的加性注意力机制，并具有灵活的内存训练方案。具体来说，帧在空间瓦片上采样，模型能够学习瓦片局部动态，并且每个瓦片的记忆单元可以稀疏更新、分页或压缩来适应大规模的地图。同时，研究提供了紧致的理论分析（紧定的softmax/注意力Lipschitz界和瓦片错误下界）来解释模型的稳定性和内存-准确性权衡关系，并通过实验验证了该模型在大规模交通热图上的优越的扩展性和预测表现。", "conclusion": "研究团队提出的方法在交通视频预测任务上展示出了优越的预测性能和良好的扩展性。研究结果对处理大规模时空数据的预测模型设计提供了新的思路。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2306.10354", "html_url": "https://arxiv.org/abs/2306.10354", "title": "LLMVA-GEBC: 大型语言模型与视频适配器用于通用事件边界描述", "title_en": "LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning", "authors": "Yolo Yunlong Tang,Jinrui Zhang,Xiangchen Wang,Teng Wang,Feng Zheng", "background": "通用事件边界描述（GEBC）任务不同于传统的视频描述任务，它要求模型理解指定视频边界周围的状态的变化，这是一个更具挑战性的任务。", "innovation": "提出了一个有效的模型 LLMVA-GEBC，包括：(1) 利用预训练的语言模型生成高质量的人类like的描述；(2) 使用视频Q-Former作为适配器，并与冻结的视觉特征提取器和语言模型一起进行训练。该方法在测试集上达到了76.14分，并在挑战中获得第一名。", "conclusion": "该方法在通用事件边界描述任务中表现出色，取得了比赛的第一名，并且代码已公开。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.09225", "html_url": "https://arxiv.org/abs/2402.09225", "title": "我的数据在我的AI中吗？面向面部生物识别的MINT成员推理测试", "title_en": "Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics", "authors": "Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia", "background": "本文介绍了一种名为Membership Inference Test (MINT)的新方法，旨在实证评估给定数据是否被用于训练AI/ML模型。实验框架集中在面部识别这一具有挑战性的任务上，考虑了三种先进的面部识别系统，并使用六个总计超过2200万张面部图像的公开数据库进行了实验。根据AI模型测试的上下文考虑了不同的实验场景。", "innovation": "文章提出了两种MINT架构，基于多层感知器（MLPs）和卷积神经网络（CNNs），用于学习审核模型在接触到其训练过程中使用的数据时所产生独特的激活模式。此外，该方法成功应用于面部识别系统的实验，展示了在特定数据使用的识别上取得的最大90%的准确率。", "conclusion": "提出的MINT方法能够识别AI模型是否受到特定数据的训练或调整，对于保护隐私和促进公平具有潜在应用价值，例如揭示大型语言模型（LLMs）训练中是否使用了敏感或私人数据。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.03881", "html_url": "https://arxiv.org/abs/2403.03881", "title": "使用扩散模型实现数据集蒸馏", "title_en": "Unlocking Dataset Distillation with Diffusion Models", "authors": "Brian B. Moser,Federico Raue,Sebastian Palacio,Stanislav Frolov,Andreas Dengel", "background": "数据集蒸馏旨在将大数据集凝缩成更小但高度代表性的合成样本。尽管现在扩散模型在生成基准测试中占据主导地位，但现有的数据集蒸馏方法避免使用它们，而是依赖生成对抗网络（GANs）、自动编码器（AE）或固定扩散先验的采样方法。这种趋势之所以存在，是因为通过扩散链进行反向传播导致梯度消失，这阻碍了对合成样本的有效优化。", "innovation": "提出了使用预训练潜变量扩散模型来通过端到端学习基于梯度的凝缩潜在变量和类别嵌入的Latent Dataset Distillation with Diffusion Models（LD3M）。此外，LD3M通过在每个逆步骤中从初始噪声状态注入线性衰减的跳过连接，以防止梯度信号在数十个时间步长内消失，而不需微调扩散权重。", "conclusion": "LD3M在ImageNet的不同子集（128x128和256x256）上均表现出色，与之前的最新技术水平相比，下游准确性提高了4.8个和4.2个百分点（分别对应1IPC和10IPC）。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.04066", "html_url": "https://arxiv.org/abs/2403.04066", "title": "LoDisc: 学习全局-局部判别特征以进行自我监督细粒度视觉识别", "title_en": "LoDisc: Learning Global-Local Discriminative Features for Self-Supervised Fine-Grained Visual Recognition", "authors": "Jialu Shi,Zhiqiang Wei,Jie Nie,Lei Huang", "background": "自我监督对比学习策略由于其在表示学习方面的出色能力而引起了广泛关注。然而，当前的对比学习方法偏向于学习对通用对象识别有益的图像全局粗粒度表示，而这种粗粒度特征对于细粒度视觉识别是不够的。因此，该论文旨在通过引入一个新颖的半监督局部判别预训练任务（LoDisc）和全局-局部框架，将局部细粒度特征的学习融入到全局自我监督对比学习中，从而提升细粒度视觉识别任务的效果", "innovation": "提出了一个新颖的局部判别预训练任务（LoDisc），通过简单的逐位置掩码采样策略来指导模型关注重要的局部区域，增强局部细粒度线索。同时，通过全局-局部框架进一步细化图像的细粒度特征表示。", "conclusion": "在不同细粒度对象识别任务上的广泛实验结果展示了所提出方法在不同评估设置中的显著改进效果，并且该方法对于一般对象识别任务也是有效的。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.16276", "html_url": "https://arxiv.org/abs/2403.16276", "title": "为大型语言模型赋能伪未修剪视频以实现音频-视觉时间理解", "title_en": "Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding", "authors": "Yolo Yunlong Tang,Daiki Shimada,Jing Bi,Mingqian Feng,Hang Hua,Chenliang Xu", "background": "大型语言模型在自然语言和多模态领域已经展现出非凡的能力。通过使用精细标注数据中的时间注释来微调多模态大语言模型，可以提高其在视频-语言任务中的时间理解能力。然而，目前已有的音频-视觉视频数据集多为伪未修剪版本，且缺乏精确的时间注释，这阻碍了大语言模型学习时间、音频-视觉事件与文本之间的对齐能力，并降低了其在音频-视觉事件的时空定位能力。", "innovation": "本文提出了一种名为PU-VALOR的综合性音频-视觉数据集，包含了超过114,000个带有详细时间标注的伪未修剪视频。数据集是通过从大规模但标注粗略的音频-视觉数据集VALOR中，利用基于事件的视频聚类、随机时间缩放和排列等微妙方法提取生成的。基于PU-VALOR微调的多模态大语言模型AVicuna能够对齐音频-视觉事件及其时间间隔和相应的文本令牌，且在时间定位和时间敏感对话方面表现出色。", "conclusion": "通过在PU-VALOR数据集上微调多模态大语言模型，我们开发了AVicuna，它能够在音频-视觉视频中有效地处理时间理解，并在开放性视频问答、音频-视觉问答和音频-视觉事件密集定位等多种任务上取得了最先进的性能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.12353", "html_url": "https://arxiv.org/abs/2404.12353", "title": "V2Xum-LLM: 使用时间提示指令调优的跨模态视频摘要", "title_en": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning", "authors": "Hang Hua,Yolo Yunlong Tang,Chenliang Xu,Jiebo Luo", "background": "视频摘要旨在创建长视频的精炼、准确且连贯的简短摘要。尽管存在多种视频摘要数据集，但这些数据集的视频源数量有限，这阻碍了高级视觉-语言模型的有效训练。此外，现有的大多数数据集仅针对视频到视频的摘要，忽略了对多模态视频内容摘要的当前需求。最近努力将单模态摘要扩展到多模态摘要，将其分类为三种子任务：视频到视频（V2V）、视频到文本（V2T）和视频和文本摘要结合（V2VT）。然而，先前多模态数据集中的文本摘要不足。", "innovation": "该研究引入了Instruct-V2Xum，这是一个跨模态视频摘要数据集，包含30,000个来自YouTube的多样化视频，时长从40秒到940秒不等，平均摘要率为16.39%。每个视频摘要都配有一个文本摘要，该摘要引用了特定帧的索引，有助于生成对齐的文本和视频摘要。此外，提出了一个新的视频摘要框架V2Xum-LLM，即V2Xum-LLaMA，它是第一个将不同视频摘要任务整合到一个大型语言模型（LLM）的文本解码器中的框架，通过使用时间提示和任务指令实现可控的视频摘要。实验证明V2Xum-LLaMA在多个视频摘要任务中优于强基线模型。", "conclusion": "研究通过引入Instruct-V2Xum数据集和V2Xum-LLaMA框架，在跨模态视频摘要领域取得了重要进展，改善了文本摘要的质量，并实现了更可控的视频摘要生成。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.10353", "html_url": "https://arxiv.org/abs/2409.10353", "title": "驯化扩散模型以进行图像恢复：一篇综述", "title_en": "Taming Diffusion Models for Image Restoration: A Review", "authors": "Ziwei Luo,Fredrik K. Gustafsson,Zheng Zhao,Jens Sjölund,Thomas B. Schön", "background": "扩散模型在生成建模中取得了显著进展，特别是在提升图像质量以符合人类偏好方面。近年来，这些模型还被应用于低级计算机视觉任务，如照片真实感图像恢复（IR），具体任务包括图像去噪、去模糊、去雾等。", "innovation": "本文综述了扩散模型在图像恢复中的关键构造，并调研了当前利用扩散模型解决通用图像恢复任务的技术。同时指出了现有基于扩散模型的图像恢复框架的主要挑战和局限性，并提出了未来研究的潜在方向。", "conclusion": "本文全面介绍了基于扩散模型的图像恢复技术，并指出了改进和创新的方向，为进一步研究奠定了基础。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.01541", "html_url": "https://arxiv.org/abs/2408.01541", "title": "图像质量守护者：针对图像质量度量对抗攻击的防御基准测试", "title_en": "Guardians of Image Quality: Benchmarking Defenses Against Adversarial Attacks on Image Quality Metrics", "authors": "Alexander Gushchin,Khaled Abud,Georgii Bychkov,Ekaterina Shumitskaya,Anna Chistyakova,Sergey Lavrushkin,Bader Rasheed,Kirill Malyshev,Dmitriy Vatolin,Anastasia Antsiferova", "background": "在图像质量评估(IQA)领域，度量准则的对抗鲁棒性成为一个关键问题。随着对抗攻击在IQA中的增加，本研究对各种防御机制进行了全面的基准测试。研究系统地评估了25种防御策略，包括对抗净化、对抗训练和鲁棒性认证方法，使用了14种不同类型且在非适应性及适应性环境中的对抗攻击算法测试这些防御措施。研究分析了不同防御措施之间的差异及其在IQA任务中的适用性，确保它们能够保持IQA分数和图像质量。", "innovation": "本文提出了一个全面的基准测试，系统地评估了25种不同的防御机制，涵盖了对抗净化和对抗训练等，并使用了14种不同类型且在非适应性及适应性环境中的对抗攻击算法，这在IQA对抗鲁棒性研究中是开创性的。团队还主持了一个提交最新方法的在线平台。", "conclusion": "提出的基准测试旨在引导未来IQA领域的发展，接受新的防御方法的提交，并提供了最新结果的在线访问。该研究对IQA领域的对抗鲁棒性防御提供了有价值的指导和改进方向。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.08589", "html_url": "https://arxiv.org/abs/2405.08589", "title": "低维分支分解全局优化的鲁棒点匹配", "title_en": "Decomposed Global Optimization for Robust Point Matching with Low-Dimensional Branching", "authors": "Wei Lian,Zhesen Cui,Fei Ma,Hang Pan,Wangmeng Zuo,Jianmei Zhang", "background": "许多应用需要能够对部分重叠点集进行对齐，并且保持不变性，例如相似性、仿射变换和刚体变换。现有的算法在处理非刚性变形、位置噪声和离群值时存在局限性，尤其是在离群值与内点明显不同的情况下表现较差。因此，迫切需要一种能够在保持不变性的同时鲁棒地对齐部分重叠点集的新算法。", "innovation": "本文提出了一种新的全局优化方法，通过最小化鲁棒点匹配（RPM）算法的目标函数来实现。该方法首先揭示原始RPM目标是三次多项式，并通过简单的变量替换将其转化为二次函数，利用双线性项的凸包，得到了二次函数的紧下界。进一步地，设计了一种专用于分支定界（BnB）算法，仅对变换参数进行分支，极大地加速了收敛速度并限制了搜索空间。该方法在2D和3D合成及真实数据上的实验表明，与最先进的方法相比，它在抵抗非刚性变形、位置噪声和离群值方面表现出更好的鲁棒性，尤其是在离群值与内点明显不同的情况下。", "conclusion": "本文提出的方法在鲁棒性、抗噪能力和对离群值的鲁棒性方面表现优于当前最先进的方法，尤其是在离群值与内点明显不同的场景下。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10979", "html_url": "https://arxiv.org/abs/2411.10979", "title": "VidComposition：MLLMs能否分析编排视频中的组成部分？", "title_en": "VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?", "authors": "Yolo Yunlong Tang,Junjia Guo,Hang Hua,Susan Liang,Mingqian Feng,Xinyang Li,Rui Mao,Chao Huang,Jing Bi,Zeliang Zhang,Pooyan Fazli,Chenliang Xu", "background": "多模态大语言模型（MLLMs）的进展显著提升了对视频内容的理解能力。然而，现有的评估基准主要集中在抽象的视频理解上，缺乏对视频构成（即视觉元素如何结合和在高度编排的视频场景中互动）的理解评估。", "innovation": "提出了VidComposition基准，专门用来评估MLLMs在理解视频构成方面的能力，通过精心挑选的编排视频和电影级别的注释来测试。VidComposition涵盖了982个视频和1706个选择题，涉及多个构成方面的内容，如摄像机运动、角度、镜头大小、叙事结构、人物动作和情绪等。", "conclusion": "对33个开源和专有MLLMs进行了全面评估，发现人类和模型的能力之间存在显著差距，这突显了当前MLLMs在理解复杂编排视频构成方面的局限性，并提供了改进的领域方向。基准排行榜和评估代码可以在以下链接获取：this https URL."}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02270", "html_url": "https://arxiv.org/abs/2412.02270", "title": "可持续自我演化对抗训练", "title_en": "Sustainable Self-evolution Adversarial Training", "authors": "Wenxuan Wang,Chenglei Wang,Huihui Qi,Menghao Ye,Xuelin Qian,Peng Wang,Yanning Zhang", "background": "随着深度神经网络模型在各种计算机视觉任务中的广泛应用，对抗样本生成策略的研究也在不断深入，以探索模型的安全性。然而，现有的对抗训练防御模型大多依赖单一或有限类型的攻击，在一次性学习过程中难以应对不断变化和发展中的攻击手段。这就导致了模型在长期应用中的防御性能提升不够理想。", "innovation": "本文提出了一个名为可持续自我演化对抗训练（SSEAT）的新型框架，该框架通过一个多阶段的持续对抗防御管道来学习各种类型的对抗样本，同时引入了一个对抗数据重演模块以更好地选择多样化的重学习数据，解决了持续学习中模型灾难性遗忘的问题。此外，设计了一致性正则化策略，鼓励当前的防御模型从先前训练过的模型那里学到更多知识，以保留更多过去的知识并保持对未受污染样本的准确分类。", "conclusion": "通过广泛实验验证了SSEAT防御方法的有效性，实验结果表明该方法在防御性能和分类精度上均优于现有方法。相关实验结果可供阅读了解更多信息。实验细节和数据集信息可访问该网页。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.12009", "html_url": "https://arxiv.org/abs/2408.12009", "title": "CaRDiff: 视频显著物体排名链式推理在扩散模型中用于引导注意力的显著性预测", "title_en": "CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for Saliency Prediction with Diffusion", "authors": "Yolo Yunlong Tang,Gen Zhan,Li Yang,Yiting Liao,Chenliang Xu", "background": "视频显著性预测旨在通过视频中的底上特征和记忆、认知等顶下过程来识别吸引人类注意力和注视的区域。语言在引导这一过程中扮演了至关重要的角色，通过影响视觉信息的解释来引导注意力。现有方法主要关注感知信息的建模，而忽视了语言促进的推理过程，这种推理过程产生排名线索，对显著性预测具有实际指导意义。现有的研究集中在建模感知信息，而忽略了语言推理过程对显著性预测的指导作用。在这种背景下，本文探讨了一个新的模型，即CaRDiff，通过结合多模态大型语言模型、地基模块和扩散模型来增强视频显著性预测能力。", "innovation": "本文提出了CaRDiff框架，通过结合多模态大型语言模型、地基模块和扩散模型，模仿显著性预测的推理过程。该框架引入了一个新的提示方法VSOR-CoT，利用多模态大型语言模型和地基模块对视频进行标题化，并推断显著物体及其排名和位置。表征过程产生的排名图能够被扩散模型有效利用，以准确解码给定视频的显著性图。实验表明，基于VSOR-CoT的CaRDiff在MVS数据集上表现优于现有最先进的模型，并且在DHF1k数据集上也展示了跨数据集的能力。", "conclusion": "通过长时间的实验验证，本文提出的CaRDiff框架在视频显著性预测任务中表现出优越的性能，并且拥有多数据集适用性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07310", "html_url": "https://arxiv.org/abs/2510.07310", "title": "MATRIX: Mask Track Alignment for Interaction-aware Video Generation", "title_en": "MATRIX: Mask Track Alignment for Interaction-aware Video Generation", "authors": "Siyoon Jin,Seongchan Kim,Dahyun Chung,Jaeho Lee,Hyunwook Choi,Jisu Nam,Jiyoung Kim,Seungryong Kim", "background": "虽然DiTs（文本到视频的模型）已经提升了视频生成的效果，但是它们仍然难以捕捉到多个实例或主体之间的互动。这项工作的背景是探索视频模型如何在内部表示互动。", "innovation": "该研究提出MATRIX，一种简单的正则化方法，用于在视频DiTs的特定层中对齐注意力，使其与来自MATRIX-11K数据集的多实例掩码轨迹一致。此外，还提出了InterGenEval，一种用于互动感知视频生成的评估协议。", "conclusion": "MATRIX提高了互动准确性和语义对齐性，减少了漂移和幻觉，广泛的消融实验验证了设计选择的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07836", "html_url": "https://arxiv.org/abs/2504.07836", "title": "AerialVG: 通过探索位置关系的空中视图视觉定位挑战基准", "title_en": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations", "authors": "Junli Liu,Qizhi Chen,Zhigang Wang,Yiwen Tang,Yiting Zhang,Chi Yan,Dong Wang,Xuelong Li,Bin Zhao", "background": "空中视图视觉定位（AerialVG）旨在基于自然语言描述在空中图像中定位目标物体。此任务带来了新的挑战，如基于外观的定位不足以区分多个外观相似的对象，以及需要强调相对位置关系。现有模型对空中图像的应用也存在困难，高分辨率的图像造成显著挑战。", "innovation": "本文提出了AerialVG数据集，包含5千张真实世界的空中图像，5万条手动注释的描述，以及10.3万个小物件；每个注释包含了带有相对空间关系的目标物体，要求模型进行复杂的空间推理。此外，还提出了一个创新的模型，包括层级交叉注意力机制以聚焦目标区域，以及一种关系感知定位模块以推断位置关系。", "conclusion": "实验结果证明了AerialVG数据集和方法的有效性，突出强调了空中视觉定位中的空间推理的重要性。此方法和数据集将被发布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.09833", "html_url": "https://arxiv.org/abs/2501.09833", "title": "超出预期的删除？概念删除如何损害非目标概念的生成", "title_en": "Erasing More Than Intended? How Concept Erasure Degrades the Generation of Non-Target Concepts", "authors": "Ibtihel Amara,Ahmed Imtiaz Humayun,Ivana Kajic,Zarana Parekh,Natalie Harris,Sarah Young,Chirag Nagpal,Najoung Kim,Junfeng He,Cristina Nader Vasconcelos,Deepak Ramachandran,Golnoosh Farnadi,Katherine Heller,Mohammad Havaei,Negar Rostamzadeh", "background": "概念擦除技术近年来因为能够在文本到图像模型中移除不必要的概念而受到广泛关注。尽管这些方法在受控环境中显示出有希望的结果，但在实际应用中的稳健性和部署适用性仍然存在不确定性。本文基于这一背景，首先识别了评估净化模型时的关键缺失，特别是评估其在不同概念维度上的性能差异。同时，系统地分析了擦除后文本到图像模型的失败模式，重点关注不同关系层次上的非目标概念的意外影响，包括视觉相似、二元关系和语义相关概念。", "innovation": "本文创新性地引入了一个新的基准框架EraseBench，涵盖了超过100个精心选择的概念，以及针对擦除后评估的指导下发布的测试提示和一系列评估指标。EraseBench旨在评估擦除效果及其副作用，并揭示了由于擦除导致的非目标概念意外抑制现象，这种现象表现为非目标概念的副作用效应，包括扭曲和生成质量下降，这揭示了一种概念纠缠的现象。", "conclusion": "研究结果揭示了擦除概念引起的意外抑制现象，这种现象导致非目标概念的副作用效应，具体表现为扭曲和生成质量下降。这表明，需要更多地关注擦除过程中的非目标概念的影响，以确保生成高质量的图像。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14230", "html_url": "https://arxiv.org/abs/2501.14230", "title": "GreedyPixel: 使用贪心算法实现精细粒度的黑盒对抗攻击", "title_en": "GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm", "authors": "Hanrui Wang,Ching-Chun Chang,Chun-Shien Lu,Christopher Leckie,Isao Echizen", "background": "深度神经网络对对抗样本非常敏感，对抗样本是指带有微小、刻意构造的扰动的输入，能够导致分类错误，使其成为一个重要的工具，用于鲁棒性评估。现有的黑盒攻击分为三类：查询仅限、迁移仅限和查询与迁移结合，它们在扰动模式和优化策略上有所不同。然而，没有先前的方法在同一时间实现查询与迁移指导、像素级别的稀疏性和无训练直接优化，这在黑盒灵活性和白盒精度之间留下了差距。", "innovation": "GreedyPixel 提出了一种新的攻击框架，通过结合基于代理的像素优先级图与基于查询反馈的贪婪、逐像素优化，从而填补了这一差距。该设计将指数级的暴力搜索空间减少到可处理的线性过程，并确保损失的单调递减和收敛到坐标最优值，还将扰动集中在鲁棒、语义上具有重要意义的像素上，从而提高感知质量。", "conclusion": "在 CIFAR-10 和 ImageNet 上的实验表明，GreedyPixel 达到了最先进的攻击成功率，并生成了视觉上不可感知的扰动。我们的结果表明，GreedyPixel 降低了白盒和黑盒攻击之间的精确度差距，并提供了一个实用框架用于细致的鲁棒性评估。相关实施可在以下链接获取：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.06250", "html_url": "https://arxiv.org/abs/2501.06250", "title": "Generative AI for Cel-Animation: A Survey", "title_en": "Generative AI for Cel-Animation: A Survey", "authors": "Yolo Yunlong Tang,Junjia Guo,Pinxin Liu,Zhiyuan Wang,Hang Hua,Jia-Xing Zhong,Yunzhong Xiao,Chao Huang,Luchuan Song,Susan Liang,Yizhi Song,Liu He,Jing Bi,Mingqian Feng,Xinyang Li,Zeliang Zhang,Chenliang Xu", "background": "传统的胶片动画生产流程包括故事板、布局设计、关键帧动画、中间帧生成、上色等多个步骤，这些步骤需要大量的手工劳动、技术专长和时间投入。这些挑战阻碍了传统胶片动画生产的效率和可扩展性。随着生成式人工智能（GenAI）的发展，包括大型语言模型、多模态模型和扩散模型等技术，正在通过自动化中间帧生成、上色和故事板创建等任务来革新传统动画流程。", "innovation": "生成式人工智能（GenAI）的引入为传统胶片动画生产带来了新的解决方案，如自动化中间帧生成、上色和故事板创建等任务，降低了技术门槛，增强了创作者的可及性，并使艺术家能够更多地专注于创意表达和艺术创新。通过工具如AniDoc、ToonCrafter和AniSora，增强了动画创作的多样性和便捷性。尽管如此，仍存在视觉一致性、风格连贯性以及伦理问题等挑战。这些工具正在不断进步，未来将在AI辅助动画方面带来更多的创新和发展方向。", "conclusion": "尽管人工智能辅助动画具有巨大的潜力，但在视觉一致性、风格连贯性以及伦理问题等方面仍面临挑战。未来的研究方向将集中在提高技术效果、保持艺术风格的一致性以及解决相关的道德问题。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.16679", "html_url": "https://arxiv.org/abs/2501.16679", "title": "Polyp-Gen：内窥镜图像扩展中的真实多样结肠息肉图像生成", "title_en": "Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic Dataset Expansion", "authors": "Shengyuan Liu,Zhen Chen,Qiushi Yang,Weihao Yu,Di Dong,Jiancong Hu,Yixuan Yuan", "background": "自动化诊断系统（ADS）在内镜检查中早期检测结肠息肉方面显示出了显著的潜力，有助于降低结肠癌的发病率。然而，由于注释成本高和严格的隐私担忧，获取高质量的内窥镜图像在ADS的发展中是一个重要挑战。尽管最近在生成合成图像以扩展数据集方面取得了进展，现有的内窥镜图像生成算法未能准确生成息肉边界区域的细节，并且通常需要医学先验来指定可能的息肉位置和形状，从而限制了生成图像的真实性和多样性。", "innovation": "为了解决这些限制，该文提出了Polyp-Gen，这是首个全自动化扩散机制的内窥镜图像生成框架。该框架采用一种空间感知扩散训练方案和病损引导损失，以增强息肉边界区域的结构上下文。此外，通过引入基于层次检索的采样策略来匹配类似的细粒度空间特征，从而捕捉医学先验以定位潜在的息肉区域。这些方法使得Polyp-Gen能够生成可靠且多样的真实内窥镜图像，以构建可靠的ADS。广泛的实验结果表明，Polyp-Gen的生成质量达到了最先进的水平，并且合成图像可以提高息肉检测任务的表现。此外，Polyp-Gen在其他数据集上的零样本泛化能力也非常出色。", "conclusion": "该文通过Polyp-Gen框架展现了在内窥镜图像生成方面的重要进展，使生成的图像更接近现实，增加了图像的多样性和真实性，有助于提高ADS的效果，并且展示了在其他数据集上的良好泛化性能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18468", "html_url": "https://arxiv.org/abs/2504.18468", "title": "RGS-DR：2D高斯点阵中的延迟反射和残差着色", "title_en": "RGS-DR: Deferred Reflections and Residual Shading in 2D Gaussian Splatting", "authors": "Georgios Kouros,Minye Wu,Tinne Tuytelaars", "background": "本文探讨了逆向渲染中的高光现象，提出了使用延迟着色的2D高斯点阵方法，并提出了一种细化阶段以提高高光细节，填补了从重建方法到细节重建方法的空白。论文采用方向残差通道捕捉剩余的视点相关效应，以进一步优化新视图合成。", "innovation": "提出了一种像素级延迟表面（surfel）表示法与高光残差结合的方法，与基于最短轴法线和法线残差的每个高斯着色相比，这种方法能产生更清晰的高光、更干净的材料并提高可编辑性。通过在三个包含光泽物体的流行数据集上评估渲染和重建质量，以及展示高质量的复照和材料编辑，验证了其方法的有效性。", "conclusion": "本文通过2D高斯点阵中的延迟反射和残差着色方法改善了逆向渲染中的高光表现，提高了渲染和重建的质量，展示了高质量的复照和材料编辑，从而弥补了单纯重建方法的不足。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.09278", "html_url": "https://arxiv.org/abs/2412.09278", "title": "医学领域的多模态大语言模型向像素级洞察方向", "title_en": "Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine", "authors": "Xiaoshuang Huang,Lingdong Shen,Jia Liu,Fangxin Shang,Hongxiang Li,Haifeng Huang,Yehui Yang", "background": "近年来，多模态大型语言模型（MLLM）在医学领域取得了显著进展，展示了开发智能生物医药助手的可能性。然而，现有的生物医药MLLM主要集中在图像层面的理解，并且交互仅限于文本指令，这限制了它们的能力边界和使用灵活性。因此，本研究旨在引入一个新的端到端多模态大型语言模型，用于医学领域，名为MedPLIB，该模型具有像素级别的理解能力。MedPLIB支持视觉问答（VQA）、任意像素级别的提示（包括点、边界框和自由形）以及像素级别的定位。研究团队还开发了一个医学复杂视觉问题回答数据集（MeCoVQA），用于复杂医学图像问题回答和图像区域理解的任务，涵盖了8种模态数据。实验结果表明，MedPLIB在多个医学视觉语言任务上达到了最先进的性能。特别是在像素定位任务的零样本评估中，MedPLIB在mDice指标上分别比小模型和大模型领先19.7和15.6的分差。", "innovation": "该研究提出了一种新的混合专家（MoE）多阶段训练策略，将MoE分为视觉语言专家模型和像素定位专家模型的训练阶段，然后通过MoE进行微调。这种策略在保持推理成本与单一专家模型相当的同时，有效协调多任务学习。此外，研究团队还开发了MedPLIB，这是一种拥有像素级别理解能力的新颖端到端多模态大型语言模型，用于医学领域，并且支持视觉问答、任意像素级别提示以及像素级别定位等功能。研究还介绍了包含8种模态数据的医学复杂视觉问题回答数据集（MeCoVQA），以推进生物医药MLLM的研究。", "conclusion": "实验结果表明，MedPLIB在多个医学视觉语言任务上达到了最先进的性能。特别是在像素定位任务的零样本评估中，MedPLIB无论是在小模型还是大模型上，都取得了显著的性能优势。团队还公开了该模型的代码、数据和检查点，以推动该领域的进一步研究和发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.19695", "html_url": "https://arxiv.org/abs/2504.19695", "title": "SubGrapher：化学结构的视觉指纹提取", "title_en": "SubGrapher: Visual Fingerprinting of Chemical Structures", "authors": "Lucas Morin,Gerhard Ingmar Meijer,Valéry Weber,Luc Van Gool,Peter W. J. Staar", "background": "自动从科学文献中提取化学结构在加速药物发现、材料科学等领域的研究中起到了关键作用。特别是专利文件中包含视觉形式的分子信息，但这些信息通常无法通过传统的基于文本的搜索访问。常规的光学化学结构识别（OCSR）模型试图重建完整的分子图，而SubGrapher方法则专注于直接从化学结构图片中提取分子指纹。", "innovation": "SubGrapher通过基于学习的实例分割来识别官能团和碳骨架，构建基于子结构的指纹，从而实现化学结构检索。该方法在与最先进的OCSR和指纹提取方法的评估中表现出卓越的检索性能和鲁棒性，能够处理多种分子表示形式。项目的数据集、模型和代码都可以公开获取。", "conclusion": "SubGrapher展示了在化学结构图像中直接提取分子指纹的有效方法，并且表明该方法在多样化分子表征中的表现优于现有方法。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.04486", "html_url": "https://arxiv.org/abs/2505.04486", "title": "使用潜变量的高效流匹配", "title_en": "Efficient Flow Matching using Latent Variables", "authors": "Anirban Samaddar,Yixuan Sun,Viktor Nilsson,Sandeep Madireddy", "background": "流匹配模型在概率生成模型中的图像生成任务中展示了巨大的潜力。然而，大多数文献中的流匹配模型在从简单源分布（如标准正态分布）学习流时，并未显式利用目标数据的潜在聚类结构，这导致了对于许多高维实际数据集来说效率低下，而这些高维数据集往往处于低维流形中。", "innovation": "提出了一种名为$\texttt{Latent-CFM}$的新模型，通过使用预训练的深度潜变量模型提取的数据特征来进行流的条件训练，从而提高了训练效率。实验表明，$\texttt{Latent-CFM}$在合成数据集和广泛使用的图像基准数据集上表现出更高的生成质量，并且相比最先进的流匹配模型，所需的训练时间和计算量更少。此外，还展示了$\texttt{Latent-CFM}$在生成来自物理过程的空间场时能够生成更物理上准确的样本，并且通过潜变量空间分析，验证了其在条件图像生成中的可解释性。", "conclusion": "$\texttt{Latent-CFM}$通过利用预训练的潜变量模型提取的数据特征，提供了一种高效的训练策略，显著改进了图像生成质量并展示了在生成来自物理过程的空间场时的优越性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20834", "html_url": "https://arxiv.org/abs/2505.20834", "title": "全突触神经网络用于统一帧事件物体跟踪", "title_en": "Fully Spiking Neural Networks for Unified Frame-Event Object Tracking", "authors": "Jingjun Yang,Liangwei Fan,Jinpu Zhang,Xiangkai Lian,Hui Shen,Dewen Hu", "background": "图像流和事件流的整合为在复杂环境中实现稳健的视觉物体跟踪提供了有希望的方法。然而，当前的融合方法虽然性能较高，但计算开销显著，难以高效提取事件流中的稀疏和异步信息，无法充分利用基于事件的突触范式的节能优势。", "innovation": "提出了一种新的全突触框架SpikeFET，实现了卷积局部特征提取和基于Transformer的全局建模的协同集成，有效地融合了帧数据和事件数据。通过引入随机碎片模块（RPM）和时空正则化（STR）策略，解决了卷积填充导致的平移不变性退化问题，以及异构特征引起的相似度度量退化问题。", "conclusion": "在多个基准上的实验结果证明，该框架在保持跟踪准确性的前提下，显著降低了功耗，实现了性能和效率的最佳平衡。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19256", "html_url": "https://arxiv.org/abs/2505.19256", "title": "PolyPose: 使用多刚体变换进行可变形2D/3D配准", "title_en": "PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations", "authors": "Vivek Gopalakrishnan,Neel Dey,Polina Golland", "background": "在介入性手术环境中，从有限数量的2D X光图像中确定患者3D姿态是一个关键任务。尽管术前的三维成像（如CT和MRI）可以提供精确的3D定位和解剖目标的可视化，但在手术过程中这些成像方式无法使用，通常使用快速的2D X光成像。为了将三维指导整合到手术过程中，该论文提出了PolyPose，一种简单且鲁棒的可变形2D/3D配准方法。该方法通过将复杂的3D变形字段参数化为刚体变换的组合，并利用个体骨骼在典型运动中不会弯曲的生物约束。在实验中展示了PolyPose能够在现有的配准方法失败的稀疏视角和有限角度设置中，使患者的术前体积与少数X光图像进行成功配准。", "innovation": "PolyPose的创新点在于采用多刚体运动理论进行了可变形2D/3D配准，并引入了一种模型，强调人体运动的分区刚体性质，这使该方法能够在没有关节移动假设的情况下工作，同时避免了当前方法所需的昂贵的变形正则化项，这些正则化项需要针对特定患者和特定手术参数进行优化。", "conclusion": "总的来说，PolyPose通过强归纳偏置能够以较少的X光图像（甚至只需两幅）帮助提供关键的3D指导，解决了当前方法在视角稀少和角度有限情况下的失败问题。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.07344", "html_url": "https://arxiv.org/abs/2505.07344", "title": "生成预训练自回归扩散转换器", "title_en": "Generative Pre-trained Autoregressive Diffusion Transformer", "authors": "Yuan Zhang,Jiacheng Jiang,Guoqing Ma,Zhiying Lu,Haoyang Huang,Jianlong Yuan,Nan Duan,Daxin Jiang", "background": "该研究旨在解决长范围视频合成的问题，并在连续潜空间中统一扩散模型和自回归模型的优势。传统的预测离散标记的方法无法很好地处理运动动态和跨帧语义一致性，因此需要一种新的方法来生成高质量的视频，并且同时具备表示能力。研究者提出了GPDiT模型，采用扩散损失的自回归预测未来潜帧的方法，以此来提升生成质量和表示能力。此外，该方法还引入了轻量级因果注意力变体和无参数基于旋转的时间条件机制，以提高训练和推断的效率。已经有大量的实验结果显示，GPDiT在视频生成质量、视频表示能力和少数样本学习任务上都表现出了很强的能力，显示出它在连续空间中进行视频建模的有效性.", "innovation": "引入了GPDiT模型，该模型在连续潜空间中统一了扩散和自回归建模的优势。相较于预测离散标记的方法，GPDiT通过扩散损失来进行自回归预测，能够自然地建模运动动态和跨帧语义一致性。此外，研究还提出了轻量级的因果注意力变体和无参数的基于旋转的时间条件机制，从而提高了训练和推理的效率。这种连续的自回归框架不仅提高了生成质量，还赋予了模型表示能力。", "conclusion": "通过广泛实验，研究显示GPDiT在视频生成质量、视频表示能力和少数样本学习任务上表现优异，验证了其在连续潜空间中进行视频建模的有效框架的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20772", "html_url": "https://arxiv.org/abs/2505.20772", "title": "MetaSlot：突破对象为中心学习中固定槽数量的限制", "title_en": "MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning", "authors": "Hongjia Liu,Rongzhen Zhao,Haohan Chen,Joni Pajarinen", "background": "学习对象级别的结构化表示被认为是提高视觉任务中泛化能力的关键，它指导着新一代预训练视觉模型（PVMs）的设计。主流的对象中心学习(OCL)方法使用Slot Attention或其变体来迭代地聚合对象的超像素到固定数量的查询特征向量（称为槽）。然而，这些方法依赖于固定的槽的数量，当对象的数量变化时，会导致单个对象被表示为多个部分。", "innovation": "MetaSlot是一种插件式Slot Attention变体，能够适应可变的对象计数。它通过维护包含数据集中对象原型的码本，量化剩余槽表示；通过量化与码本的槽来去除传统聚合中的重复槽；并在Slot Attention迭代中逐渐注入更弱的噪声以加速和稳定聚合。MetaSlot是一种通用的Slot Attention变体，可以无缝集成到现有的OCL架构中。在多项公开数据集和任务中，使用MetaSlot的模型在对象发现和识别方面获得了显著性能提升和更可解释的槽表示，相比现有的Slot Attention变体有了明显改进。", "conclusion": "MetaSlot在多个公开数据集和任务中展示了在对象发现和识别方面的显著性能提升，并且具有更加可解释的表示。它是一种能够适应变化对象数量的通用Slot Attention变体，可以无缝集成到现有的对象中心学习架构中。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03538", "html_url": "https://arxiv.org/abs/2506.03538", "title": "Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting", "title_en": "Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting", "authors": "Chengqi Li,Zhihao Shi,Yangdi Lu,Wenbo He,Xiangyu Xu", "background": "3D重建在野外图像中仍是一个具有挑战性的任务，因为光照条件不一致和瞬态干扰者。现有方法通常依赖于启发式策略来处理低质量的训练数据，经常无法产生稳定和一致的重建，往往会生成视觉伪影。", "innovation": "该论文提出了一种名为\\modelname{}的新框架，利用这些伪影的随机性：它们在不同训练运行中会因微小的随机性而变化。具体来说，该方法并行训练两个3D高斯溅射（3DGS）模型，通过一致性约束鼓励收敛于可靠的场景几何结构，同时抑制不一致的伪影。此外，为了防止两个模型因确认偏见陷入相似的失败模式，引入了一种发散遮罩策略，应用了两种互补的掩码：多线索自适应掩码和自监督软掩码，这导致了两个模型的非对称训练过程，减少了共享错误模式。此外，为了提高模型训练效率，引入了轻量级变体称为动态EMA代理，用动态更新的指数加权移动平均（EMA）代理替代一个模型，并采用交替掩码策略以保持发散。", "conclusion": "在具有挑战性的实时数据集上的广泛实验表明，该方法在保持高效的同时始终优于现有方法。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13430", "html_url": "https://arxiv.org/abs/2506.13430", "title": "图像中的不确定性意识剩余寿命预测", "title_en": "Uncertainty-Aware Remaining Lifespan Prediction from Images", "authors": "Tristan Kenneweg,Philip Kenneweg,Barbara Hammer", "background": "文章介绍了通过分析图像（面部和全身图像）来预测与死亡相关结果的前景。这种方法可以提供易于访问、无创且易于扩展的健康筛查选项。先前的研究主要依赖于复杂的计算方法或侵入性测试，而该研究使用预训练的视觉变换器基础模型进行预测，提供了一种新颖的方法，并且还可以有效地量化预测不确定性。", "innovation": "该研究提出的方法结合了预训练的视觉变换器基础模型和鲁棒的不确定性量化，能够从图像预测剩余寿命。这种方法可以系统地量化预测不确定性，并通过学习每个样本的高斯分布来有效建模。该方法在两个新的高质量数据集上实现了历史最佳的均方绝对误差（MAE），分别为4.91年和4.99年，并且在已建立的数据集上取得7.41年的MAE结果。此外，模型的不确定性估计可以得到校准，这也得到了实验证明。这种方法避免了临床部署，强调了从图像中提取医学相关信号的潜力。", "conclusion": "该研究通过领域转移和不确定性量化的方式，展示了利用图像预测剩余寿命的潜力，并且提出了一个评估不确定性校准的指标。这种方法具有较高的准确性和可校准性，但其应用尚未达到临床部署的水平。所有代码和数据集均开放供进一步研究使用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18369", "html_url": "https://arxiv.org/abs/2506.18369", "title": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models", "title_en": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models", "authors": "Yeongtak Oh,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Jisoo Mok,Sungroh Yoon", "background": "最近的多模态大型语言模型（MLLMs）在生成个性化的图像描述时经常表现不佳，即使是在高质量的图像描述数据集上进行训练。现有的后训练个性化方法也无法解决这一问题，尽管这些模型通过监督微调（SFT）得到了大规模的描述数据集的后调优，但在实际场景中的表现往往不尽如人意，特别是在多概念图像描述任务中。获取高质量的数据集既昂贵又困难。为了解决数据依赖性问题，研究提出了一种基于强化学习（RL）的后训练框架，这是首次使用RL后训练MLLMs进行个性化图像描述的方法。", "innovation": "提出了一种基于强化学习（RL）的后训练框架，用于多模态语言模型的个性化图像描述，这是首次使用RL后训练改进MLLMs的方法，显著增强了视觉识别和个性化生成能力，并在多概念图像描述任务中表现优于现有SFT基线方法。", "conclusion": "该方法显著提升了MLLMs的视觉识别和个性化生成能力，并且一致优于现有的SFT基线方法，尤其是在复杂的多概念图像描述任务中。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20426", "html_url": "https://arxiv.org/abs/2505.20426", "title": "MMPerspective: MLLMs是否理解透视？一个全面的视点感知、推理和鲁棒性基准", "title_en": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness", "authors": "Yolo Yunlong Tang,Pinxin Liu,Mingqian Feng,Zhangyun Tan,Rui Mao,Chao Huang,Jing Bi,Yunzhong Xiao,Susan Liang,Hang Hua,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Chenliang Xu", "background": "人类的视觉感知依赖于对视点的理解，但目前尚不清楚多模态大型语言模型(MLLMs)在内部化透视几何方面的程度如何。此前的研究未能提供系统的方法来评估MLLMs在理解和应用透视几何方面的能力。作者开发了一个名为MMPerspective的新基准，以解决这一问题。该基准旨在通过10个精心设计的任务来系统地评估MLLMs对透视的理解，这些任务覆盖三个维度：透视感知、推理和鲁棒性。基准包含来自现实世界和合成图像的2,711个实例以及5,083个问题-答案对，这些问题探索模型的关键能力，如消失点感知、计数、透视类型的推理、3D空间中的线关系理解等。通过全面评估43个最新的MLLMs，研究揭示出具有表面水平感知能力的模型在复杂推理任务和在扰动下的空间一致性方面表现出明显的局限性。", "innovation": "该研究创新性地设计了一个名为MMPerspective的新基准，旨在全面评估MLLMs在理解和应用透视几何方面的表现。该基准包含精心设计的10个任务，涵盖了三个维度：透视感知、推理和鲁棒性。该基准使用了来自现实世界和合成图像的2,711个实例和5,083个问题-答案对，全面探索了模型的关键能力。该基准的引入填补了当前评估方法的空白，为未来的研究提供了有价值的测试平台。", "conclusion": "研究通过全面评估43个最新的MLLMs，发现尽管模型在表面感知任务上表现出色，但在复杂推理任务和保持空间一致性方面存在明显局限性。作者的分析揭示了模型架构、规模和透视能力之间的一些有趣的模式，强调了鲁棒性瓶颈，并突显了对话提示的好处。MMPerspective被认为是一个有价值的工具，用于诊断和推进视觉语言系统中的空间理解能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 多领域多模态物体检测基准数据集用于视觉-语言模型", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉-语言模型（VLMs）在大量互联网数据上训练时，可以在汽车、卡车和行人的共同物体检测上实现卓越的零样本性能。然而，最先进的模型在处理不在其预训练中常见的类别、任务和成像模式时仍然难以泛化。尽管有人建议通过增加更多视觉数据来重新训练VLMs，但该论文提出了一种新的方法，即利用包含少量视觉示例和丰富文本描述的标注指令来对齐VLMs到新的概念。为此，该论文介绍了一种新的数据集Roboflow100-VL，包含100个面向不同领域的多模态物体检测数据集，涵盖了许多VLM预训练中没有常见概念的多样化的新概念。这些数据集用于评估不同数据量条件下的VLMs性能，包括零样本、少量样本、半监督和全监督设置。研究表明，即使对于挑战性的医学成像数据集，一些最新的VLMs如GroundingDINO和Qwen2.5-VL的零样本准确率也低于2%，这突显了对新概念的小样本对齐的需求。该论文出版在即将举办CVPR 2025 Foundational FSOD竞赛，并分享了社区的见解。冠军团队通过17个mAP的优势显著超越了基准。该论文的数据集和代码可以在提供的链接中找到。", "innovation": "该作品提出了一种新的方法，通过包含少量视觉示例和丰富文本描述的标注指令来对齐VLMs到新的概念。引入了Roboflow100-VL，一个包含100个异质物体检测数据集的基准数据集，涵盖了许多VLM预训练中未见的概念。这种方法与直接增加视觉数据不同，并且对比了在不同数据量条件下VLMs的性能，包括零样本、少量样本、半监督和全监督设置。此创新在难以处理的数据上明显改善了VLMs的性能，例如医学成像数据。", "conclusion": "研究表明，即使对于挑战性的医学成像数据集，即使是最先进的VLMs如GroundingDINO和Qwen2.5-VL的零样本准确率也低于2%，这突显了对新概念的小样本对齐需求。该论文通过CVPR 2025 Foundational FSOD竞赛和公开的基准数据集及代码展示了这一方法的实际效果和潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19791", "html_url": "https://arxiv.org/abs/2508.19791", "title": "Color Bind: 探索文字到图像模型中的颜色感知", "title_en": "Color Bind: Exploring Color Perception in Text-to-Image Models", "authors": "Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor", "background": "文字到图像生成近年来取得了显著的成功，赋予用户通过文本创建高质量图像的能力。然而，当前方法在捕捉复杂多对象提示下的精确语义时遇到挑战。先前的研究多采用粗粒度的评估指标，如文本和图像CLIP嵌入的余弦相似性，或者难以大规模进行的人类评估。因此，研究集中在通过修改去噪网络的注意力层等推理时间方法来缓解这种语义不匹配。这项工作中，研究者选择颜色作为基本属性进行案例研究，因为颜色是文本提示中常见的对象特征，提供了严谨评价的丰富测试床。研究表明，预训练模型在生成反映多个颜色属性的图像方面表现不佳，单色提示则相对更好。推理时间技术和现有编辑方法难以解决这些问题。", "innovation": "这项工作引入了一种专门的图像编辑技术，解决了多对象语义对齐问题，特别是在包含多个颜色的提示中。研究者的方法在多种度量指标上显著提升了性能，适用于各种基于扩散技术的文字到图像生成方法。", "conclusion": "研究揭示了预训练模型在生成包含多种颜色属性图像方面的困难，这种技术难点远超过单色提示。现有推理时间和编辑方法并不能可靠地解决这些语义不匹配问题。研究者提出了一种专门的编辑技术，显著改善了多对象语义对齐，尤其适用于具有多种颜色的提示生成，提升了多种评估指标下的生成图像性能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24001", "html_url": "https://arxiv.org/abs/2509.24001", "title": "人类与机器人交互中的凝视估计：使用NICO平台的分析", "title_en": "Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO Platform", "authors": "Matej Palider,Omar Eldardeer,Viktor Kocur", "background": "本文评估了共享工作空间场景中的人机交互(HRI)中的当前凝视估算方法。介绍了使用NICO机器人平台收集的新标注数据集，并评估了四个最先进的凝视估算模型。结果显示，角度误差与通用基准上报告的相近，但以共享工作空间内的距离衡量时，最佳中位误差为16.48厘米，这量化了当前方法的实际局限性。", "innovation": "引入了使用NICO机器人平台收集的新标注数据集，并评估了四个最先进的凝视估算模型，强调了当前方法在共享工作空间场景中的局限性。", "conclusion": "讨论了这些局限性，并提出了如何将凝视估算作为模态最佳集成到HRI系统中的建议。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15690", "html_url": "https://arxiv.org/abs/2507.15690", "title": "DWTGS：稀波变换空间损失重新思考稀视图3D高斯散点图的频域正则化", "title_en": "DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting", "authors": "Hung Nguyen,Runfa Li,An Le,Truong Nguyen", "background": "在稀视图3D高斯散点图（3DGS）中，重建高质量的新视图具有重大挑战。由于训练视图的高频（HF）细节变化广泛，3DGS往往为了适应这些细节而过拟合。虽然频域正则化可能是一种有望的策略，但其通常依赖傅里叶变换，这既导致参数调整困难，又倾向于对不利的高频学习产生偏差。", "innovation": "我们提出了DWTGS框架，通过利用波空间损失重新构思频域正则化，提供额外的空域监督。具体而言，我们仅监督多级稀波变换（DWT）中的低频（LF）LL子带，在自我监督的情况下限制高频（HF）HH子带的稀疏性。实验结果表明，DWTGS始终优于基于傅里叶的方法，因为这种以低频为中心的策略提升了泛化能力并减少了高频错觉。", "conclusion": "实验跨指标显示，DWTGS在处理稀视图3D高斯散点图时，基于低频的策略显著提升了泛化能力并减少了高频错觉。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15257", "html_url": "https://arxiv.org/abs/2509.15257", "title": "RespoDiff: 双模块瓶颈变换以实现负责任且忠实的文本到图像生成", "title_en": "RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation", "authors": "Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta", "background": "随着扩散模型的快速发展，文本到图像的生成变得高度保真且蕴含丰富的语义，但确保公平性和安全性仍是一个开放的挑战。现有方法通常通过牺牲语义准确性和图像质量来提升公平性和安全性。这一背景下，本文探讨了如何在保持语义准确性和图像质量的同时保证生成的图像具有责任感和公平性。", "innovation": "本文提出了一种名为RespoDiff的新框架，它在扩散模型的中间瓶颈表示上实现了双模块变换。该方法包含两个可学习模块：一个用于捕捉和强制执行负责任的概念（如公平性和安全性），另一个则专注于保持与中性提示的语义对齐。为了促进这两个模块的协同学习，本文引入了一种新的分数匹配目标，实现了模块间的有效协调。RespoDiff方法在负责任生成方面优于现有的前沿技术，能够同时优化两个目标而不损害图像保真度，提升负责任且语义一致的生成能力20%，并且可以无缝集成到大规模模型如SDXL中，增强图像的公平性和安全性。", "conclusion": "本文提出的RespoDiff框架通过引入双模块瓶颈变换，提高了在负责任生成中的表现，该方法不仅在不同的中性提示中提升了20%的可靠性和语义一致性，还能无缝嵌入到大规模模型中，增强了图像的公平性和安全性。未来，随着该框架的进一步优化和应用，有望推动文本到图像生成技术的负责任发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL：利用大型语言模型弥合视觉与文本的鸿沟实现少样本学习", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少样本学习（Few-shot learning，FSL）旨在仅从少量标记的支持样本中识别新型概念。尽管最近的研究通过整合附加语义信息或设计复杂的语义融合模块来增强支持特征，但在实际实例中缺乏语义接地，因此仍然面临生成与视觉证据矛盾的语义问题，导致噪声指导和昂贵的校正成本。", "innovation": "论文提出了一种新的框架VT-FSL，通过大型语言模型（LLMs）构建跨模态精准提示，并通过几何感知对齐无缝集成这些提示。它包括跨模态迭代提示生成（CIP）和跨模态几何对齐（CGA）两个模块。CIP利用类名和支撑图像条件化LLMs，生成精确的类描述。CGA通过最小化支撑文本、支持图像和合成图像在3维平行多面体上的核体积，联合对齐这些表征。", "conclusion": "论文的方法在十种不同的基准测试中，包括标准、跨领域和细粒度少样本学习场景，建立了新的最先进的性能记录。代码可在http://this.url/上获得。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24893", "html_url": "https://arxiv.org/abs/2509.24893", "title": "HBSplat: Hybrid-Loss Guided Depth with Bidirectional Warping for Robust Sparse-View Gaussian Reconstruction", "title_en": "HBSplat: Robust Sparse-View Gaussian Reconstruction with Hybrid-Loss Guided Depth and Bidirectional Warping", "authors": "Yu Ma,Guoliang Wei,Haihong Xiao,Yue Cheng", "background": "从稀疏视角生成新颖视图合成（NVS）在3D重建中面临巨大挑战，因为有限的多视图约束会导致严重的过拟合、几何失真和断层场景。3D高斯散点图（3DGS）能够提供实时、高保真的渲染，但在稀疏输入下其性能会急剧下降，伴随着漂浮伪影和结构失败。", "innovation": "提出了一种统一框架HBSplat，通过无缝集成鲁棒的结构线索、虚拟视图约束和遮挡区域恢复，提升3DGS的性能。核心贡献包括：1. 一种混合损失深度估计模块，通过密集匹配先验和重投影、点传播和平滑性约束确保多视图一致性；2. 一种双向 Warp 虚拟视图合成方法，通过双向深度图像扭曲和多视图融合创建高质量的虚拟视图，增强约束；3. 一种遮挡感知重建组件，使用深度差分掩模和基于学习的填补模型恢复遮挡区域。", "conclusion": "在 LLFF、Blender 和 DTU 基准测试中进行广泛评估，证明HBSplat达到了新的state-of-the-art，PSNR最高可达21.13 dB，LPIPS为0.189，同时保持实时推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03511", "html_url": "https://arxiv.org/abs/2510.03511", "title": " platonic transformers: 一种用于协变性的坚实选择 ", "title_en": "Platonic Transformers: A Solid Choice For Equivariance", "authors": "Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers", "background": "虽然Transformer在各类任务中广泛应用，但它们缺乏在科学和计算机视觉中常见的几何对称性的归纳偏置。现有的协变方法通常会牺牲Transformer的效率和灵活性，通过复杂且计算密集的设计来实现。", "innovation": "作者引入了Platonic Transformer以解决这一权衡。通过使用Platonic固体对称群的参考框架定义注意力机制，这种方法实现了连续平移和Platonic对称性的联合协变，同时保持了标准Transformer的架构和计算成本。此外，这种方法与动态群卷积的形式等价，这表明模型学习了自适应的几何滤波器，并能够实现一种高效的线性时间卷积变种。", "conclusion": "在计算机视觉（CIFAR-10）、3D点云（ScanObjectNN）和分子属性预测（QM9、OMol25）等不同基准上的实验结果显示，Platonic Transformer能够通过利用这些几何约束实现竞争力的性能，而且不增加额外的成本。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26281", "html_url": "https://arxiv.org/abs/2509.26281", "title": "Point2RBox-v3: 通过集成伪标签细化和利用实现点注释自我启动", "title_en": "Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization", "authors": "Teng Zhang,Ziqian Fan,Mingxin Liu,Xin Zhang,Xudong Lu,Wentong Li,Yue Zhou,Yi Yu,Xiang Li,Junchi Yan,Xue Yang", "background": "随着定向对象检测（OOD）需求的增加，从点注释中在弱监督框架下学习成为一种成本较低且劳动强度较小的替代手动标注方法。然而，现有的点监督方法存在标签利用效率低下和伪标签质量差两大缺陷。", "innovation": "本文提出了Point2RBox-v3，核心创新在于两者：1）逐级标签分配（PLA），在训练的不同阶段以粗略但智能的方式动态估计实例大小，支持标签分配方法；2）基于先验指导的动态掩码损失（PGDM-Loss），这是一种对Point2RBox-v2中的Voronoi Watershed损失的增强版本，解决了Voronoi算法在稀疏场景下表现差和SAM在密集场景下表现差的问题。Point2RBox-v3是首款采用动态伪标签进行标签分配的模型，创造性地将SAM模型的优势与Watershed算法相结合，使得在稀疏和密集场景中都能取得优异的性能。", "conclusion": "我们的解决方案尤其在具有大范围对象尺寸变化或稀疏对象出现场景中表现优异：在DOA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR上的成点注释自我启动表现分别为66.09% /56.86% /41.28% /46.40% /19.60% /45.96%。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07077", "html_url": "https://arxiv.org/abs/2510.07077", "title": "机器人中的视觉-语言-行动模型：面向实际应用的综述", "title_en": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "authors": "Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu", "background": "在利用大型语言模型（LLMs）和视觉-语言模型（VLMs）为机器人技术带来进步的大背景下，视觉-语言-行动（VLA）模型正逐渐获得显著关注。通过大规模统一以往分别研究的视觉、语言和动作数据，VLA模型旨在学习能够在多种任务、物体、体形和环境之间具有一般性的策略。这种泛化能力有望让机器人能够解决新的下游任务，而无需额外的任务特定数据，从而便于更灵活且大规模地部署于实际场景。", "innovation": "本研究提供了一个全面的VLA系统的综述，覆盖了从软件到硬件的完整系统，聚焦于VLA模型的策略、架构演变、构建模块、模态特定处理技术和学习范式。此外，研究还审查了常用的机器人平台、数据收集策略、公共可用数据集、数据扩增方法以及评估基准，以支持在实际机器人应用中的VLA部署。", "conclusion": "本文旨在为机器人社区如何应用VLA模型到实际机器人系统提供实用指导，并在项目网站上提供了分类的参考文献，包括训练方法、评估方法、模态和数据集的表格。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03993", "html_url": "https://arxiv.org/abs/2510.03993", "title": "保持缰绳：可控伪标签生成以实现现实的长尾半监督学习", "title_en": "Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning", "authors": "Yaxin Hou,Bo Han,Yuheng Jia,Hui Liu,Junhui Hou", "background": "当前的长尾半监督学习方法假定标记数据遵循长尾分布，而无标签数据则遵循事先定义的分布（如长尾、均匀或倒长尾）。然而，无标签数据的真实分布通常是未知的，并且可以遵循任意分布。这为现有的方法带来了挑战。", "innovation": "本文提出了一种可控伪标签生成（CPG）框架，该框架通过渐进识别并加入可靠的伪标签扩展标记数据集，并在更新后的标记数据集上训练模型，确保模型能够不受无标签数据分布的影响。CPG通过可控制的自我强化优化循环运作：（1）在每次训练步骤中，动态可控过滤机制选择性地将可靠的伪标签加入标记数据集，确保更新后的标记数据集跟随已知分布；（2）基于更新后的标记数据分布，构建贝叶斯最优分类器；（3）该增强分类器随后在下一次训练步骤中帮助识别更多的可靠伪标签。此外，作者还提出了一个类感知自适应增强模块，进一步提高少数类的表征能力和一个辅助分支，通过充分利用所有有标签和无标签样本来最大化数据利用。", "conclusion": "在各种常用基准数据集上的全面评估表明，CPG实现了一致的改进，相比最先进的方法在准确率上提高了最多15.97%。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03363", "html_url": "https://arxiv.org/abs/2510.03363", "title": "统一匹配成本过滤下的无监督异常检测", "title_en": "Unified Unsupervised Anomaly Detection via Matching Cost Filtering", "authors": "Zhe Zhang,Mingxiu Cai,Gaochang Wu,Jing Zhang,Lingqiao Liu,Dacheng Tao,Tianyou Chai,Xiatian Zhu", "background": "无监督异常检测（UAD）的目标是仅使用正常训练数据来识别图像和像素级别的异常，其在工业检测和医疗分析等广泛领域有重要应用。由于隐私问题和冷启动限制，异常样本相对较稀缺。现有的方法，无论是基于重建（恢复正常样本）还是嵌入（预训练表示），本质上都进行了图像或特征级别的匹配来生成异常图，但对匹配噪声的关注不足，限制了检测能力。此前UAD研究主要集中在单模态RGB数据上，但近期扩展到了多模态场景，如RGB-3D和RGB-Text，这得益于点云传感和视觉-语言模型的发展。尽管存在共通的挑战，但这些研究线仍未很好地相互融合，阻碍了对UAD进行全面理解与知识转移。", "innovation": "本文提出了一种名为统一成本过滤（Unified Cost Filtering, UCF）的通用后处理精炼框架，用于任何UAD模型的异常成本体积优化。该框架通过构建测试样本与正常样本（相同或不同模态）之间的匹配成本体积，随后应用一个可学习的过滤模块多层注意力引导，从而减轻匹配噪声并突出细微异常。实验结果表明UCF能够增强各种UAD方法的效果，在单模态（RGB）和多模态（RGB-3D，RGB-Text）UAD场景下均实现了新的SOTA结果。", "conclusion": "综合实验在22种不同的基准数据集上展示了UCF的有效性。无论在单模态（RGB）还是多模态（RGB-3D，RGB-Text）的UAD场景中，UCF均一致地提高了各种UAD方法的表现，达到了新的SOTA水平。统一UAD不仅为无监督异常检测领域提供了新的视角，也展示了其在多模态场景中的适用性和优越性。作者承诺将在该网址this https URL上发布代码和模型。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25191", "html_url": "https://arxiv.org/abs/2509.25191", "title": "VGGT-X: 当VGGT遇见密集新颖视图合成", "title_en": "VGGT-X: When VGGT Meets Dense Novel View Synthesis", "authors": "Yang Liu,Chuanchen Luo,Zimo Tang,Junran Peng,Zhaoxiang Zhang", "background": "尽管神经辐射场（NeRF）和3D通用场景图（3DGS）等技术显著推动了新颖视图合成（NVS）的发展，当前方法仍然依赖于通过结构从运动捕捉（SfM）获取的准确3D属性（例如，相机姿态和点云），这些属性在低纹理或低重叠场景下往往难以获得且效率低下。最近的3D基础模型（3DFMs）展示了与传统工作流相比数量级的速度提升，并具备实时NVS的潜力。然而，现有验证和结论大多集中在稀疏视图设置上。本研究揭露了直接将3DFMs扩展到密集视图场景上面临两个根本挑战：显著增加的显存负担和不完美的输出结果，后者影响了对初始化敏感的3D训练。为应对这些挑战，我们提出了一种名为VGGT-X的方法，该方法通过引入一种高效内存的VGGT实现、自适应全局对齐来优化VGGT输出，并采用鲁棒的3DGS训练实践，以期提高模型性能。", "innovation": "我们引入了一种名为VGGT-X的方法，其中包括一个高效内存使用的VGGT实现，能扩展至1,000+图像；自适应全局对齐增强VGGT输出；以及鲁棒的3DGS训练实践。这些措施显著缩小了与COLMAP初始化管道的精度差距，实现了密集无COLMAP的新颖视图合成和姿态估计的最新成果。我们还分析了与COLMAP初始化渲染之间的剩余差距，为未来3D基础模型和密集NVS的发展提供了洞察。", "conclusion": "通过对比交叉验证，我们证明VGGT-X在密集无COLMAP的新颖视图合成和姿态估计上优于其他方法。同时，我们揭示了与COLMAP初始化渲染之间的差距原因，并为未来3D基础模型和密集NVS的研究方向提供了宝贵见解。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04759", "html_url": "https://arxiv.org/abs/2510.04759", "title": "Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction", "title_en": "Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction", "authors": "Chi Yan,Dan Xu", "background": "3D 占有预测任务近年来取得了显著进展，对于基于视觉的自动驾驶系统至关重要。传统方法局限于固定语义类别，而近期方法向着预测文本对齐的特征迈进，以支持真实场景中的开放词汇文本查询。然而，文本对齐场景建模存在权衡：稀疏的高斯表示难以捕捉场景中的小对象，而密集表示则会导致重大的计算开销。", "innovation": "提出了一种创新的渐进式高斯变换框架 PG-Occ，该框架能够实现开放词汇的 3D 占有预测。该框架采用渐进在线密集化，这是一种逐步增强 3D 高斯表示的前馈策略，以捕捉场景的细粒度细节。此外，引入了方向感知的采样策略结合时空融合，能够自适应地在不同尺度和阶段分配感受野，从而有效聚合特征并捕获更丰富的场景信息。", "conclusion": "通过广泛的评估，PG-Occ 在 mIoU 上相对上一最优方法有 14.3% 的提升，达到了最先进的性能。代码和预训练模型将在发表后在项目页面发布。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05506", "html_url": "https://arxiv.org/abs/2510.05506", "title": "从时间维度的点云中的人类动作识别", "title_en": "Human Action Recognition from Point Clouds over Time", "authors": "James Dickens", "background": "近期，人类动作识别（HAR）的研究主要集中在骨架动作识别和基于视频的方法上。随着消费级深度传感器和激光雷达仪器的日益普及，从密集的3D数据中进行动作识别并开发新的方法变得越来越有前景。", "innovation": "本文提出了一种新颖的方法，用于通过引入管道以识别3D视频中的动作。该方法包括从场景背景中分割人类点云、随着时间追踪个体，并执行身体部分分割。提出的方法支持来自深度传感器和单目深度估计的点云。该方法的核心是一个新颖的3D动作识别骨干网，结合了基于点的技术和针对体素映射点云序列应用的稀疏卷积网络。实验中融合了辅助点特征，包括表面法线、颜色、红外强度和身体部分解析标签，以增强识别准确性。", "conclusion": "在NTU RGB-D 120数据集上的评估表明，该方法与现有的骨架动作识别算法具有竞争力。将传感器数据和估计的深度输入结合在一起，在集成设置中，当训练和测试使用不同的人体时，该方法达到了89.3%的准确性，超越了之前的点云动作识别方法。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04022", "html_url": "https://arxiv.org/abs/2510.04022", "title": "Video-in-the-Loop: 带有交织推理的基于上下文的长视频问答", "title_en": "Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved Reasoning", "authors": "Chendong Wang,Donglin Bai,Yifan Yang,Xiao Jin,Anlan Zhang,Rui Wang,Shiqi Jiang,Yuqing Yang,Hao Wu,Qi Dai,Chong Luo,Ting Cao,Lili Qiu,Suman Banerjee", "background": "现有的长视频问答框架在局部化问题相关的时间段时使用低帧率快照，并在提高有效帧率下重新分配视觉标记以回答问题，从而保留固定标记预算。然而，这类方法在接受固定帧输入预算时，在长视频问答和时间定位任务上表现不佳。此外，描述基于事件图如何转化为基于上下文的选择题仍具有挑战性，这些事件图像问题配对了正确的时空跨度和相关推理，这对于训练模型至关重要。", "innovation": "本文提出了一种名为Video-in-the-Loop (ViTL) 的两阶段长视频问答框架，该框架通过低帧率快照局部化问题相关的时间区间，然后通过重新分配视图标记来提高有效帧率进行解析，同时发出交织输出包括跨度和最终答案选项。此外，该研究引入了一个名为\textit{dataname}的数据集，该数据集将描述基于事件图转换为基于上下文的选择题，通过将每个问题与正确的时空跨度配对和相关推理，确保训练过程的有效性。ViTL框架通过结合时间和答案的正确性来实现端到端的训练，不仅提高了模型的解释性和计算效率，还在固定标记预算下取得了显著效果，例如在Charades-STA和ActivityNet-Captions数据集上的表现。", "conclusion": "总体而言，\textit{dataname} 数据集和 Video-in-the-Loop (ViTL) 涵盖了一种可解释、计算高效的长视频问答解决方案。ViTL 在长视频问答和时间定位任务上能够显著提升表现，特别是在固定帧输入预算和可解释性方面表现出明显优势，并且证明了基于上下文的视频问答的可行性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05615", "html_url": "https://arxiv.org/abs/2510.05615", "title": "TFM数据集：用于自动泪膜破裂分割的新多任务数据集及集成管道", "title_en": "TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation", "authors": "Guangrong Wan,Jun liu,Qiyang Zhou,Tang tang,Lianghao Shi,Wenjun Luo,TingTing Xu", "background": "泪膜破裂（TFBU）分析对于诊断干眼症至关重要，但由于缺乏标注数据集和集成解决方案，自动化的TFBU分割仍然具有挑战性。这项研究引入了第一个全面的数据集TFM数据集，用于多任务泪膜分析，该数据集包含15个高分辨率视频（总计6,247帧），并已标注三项视觉任务：帧级别分类（“清晰”、“关闭”、“破裂”、“模糊”），Placido Ring检测以及像素级TFBU区域分割。", "innovation": "研究提出了TF-Net，一种新颖且高效的分割基线模型，结合了MobileOne-mini骨干网络和重参数化技术以及增强的特征金字塔网络，实现对实时临床应用的准确性和计算效率的平衡。通过TF-Net与其他先进的医学图像分割模型的对比，确立了TFM分割子集的基准性能。还设计了TF-Collab，一种新颖的集成实时管道，综合利用TFM数据集所有三项任务训练的模型，通过按顺序调度帧分类以确定BUT，瞳孔区域定位以进行输入标准化和TFBU分割，实现全流程自动化。", "conclusion": "实验结果证明了所提出的TF-Net和TF-Collab的有效性，为眼表诊断的未来研究奠定了基础。研究代码和TFM数据集可在指定网站查看下载。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05886", "html_url": "https://arxiv.org/abs/2510.05886", "title": "acia-workflows: 自动化单细胞成像分析以支持可扩展的深度学习基础活细胞成像分析工作流", "title_en": "acia-workflows: Automated Single-cell Imaging Analysis for Scalable and Deep Learning-based Live-cell Imaging Analysis Workflows", "authors": "Johannes Seiffarth,Keitaro Kasahara,Michelle Bund,Benita Lückel,Richard D. Paul,Matthias Pesch,Lennart Witting,Michael Bott,Dietrich Kohlheyer,Katharina Nöh", "background": "活细胞成像（LCI）技术能够对单个活细胞进行高分辨率的时间和空间表征，对于生命科学领域的研究至关重要。高通量设置虽然能提供可靠的洞察，但由于大规模数据记录，这些洞察反而被数据量所掩盖。近年来，先进的深度学习方法在细胞分割和跟踪中的应用，开启了对大量细胞数据的自动化分析，这为系统研究单细胞动态提供了前所未有的机会。然而，将这些强大工具整合到可访问、灵活且用户友好的工作流中，支持生物研究中的日常应用仍是一个挑战。", "innovation": "本文展示了acia-workflows平台，集成了三个关键组件：（1）一种支持模块化图像分析管道设计的Automated live-Cell Imaging Analysis (acia) Python库，提供了八种深度学习分割和跟踪方法；（2）工作流将图像分析管道、软件依赖项、文档和可视化整合到一个Jupyter Notebook中，实现可访问、可重复使用的分析工作流；（3）一系列应用工作流，展示了在实际应用中的数据分析和定制能力。特别地，本文提出三种工作流以研究不同类型的微流控LCI实验，如生长速率比较，以及对氧气条件变化的单细胞动态分析的精确、分钟级定量分析。", "conclusion": "论文发表了一个开源平台acia-workflows，包含超过十个应用工作流，从几十个实验中处理、分析和量化大通量的LCI数据，旨在支持生物研究中的自动化单细胞成像分析，并通过提供灵活性、用户友好性和可扩展的工作流平台，推动生物研究，加速科学发现过程。更多内容，请点击此链接访问公开资源：[](this https URL)"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05899", "html_url": "https://arxiv.org/abs/2510.05899", "title": "Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning", "title_en": "Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning", "authors": "Jiesi Hu,Yanwu Yang,Zhiyu Ye,Jinyan Zhou,Jianfeng Cao,Hanyang Peng,Ting Ma", "background": "现有的医学图像分割模型，如交互式和上下文学习(ICL)模型，虽然具有较强的泛化能力，但需要大量的注释。交互式模型需要反复的用户提示，而ICL则依赖于密集的像素级标签。这些都需要大量的标注工作，特别是在医学图像中，精确的注释成本非常高。因此，研究提出了弱监督上下文学习(WS-ICL)作为一种新的ICL范式，利用弱提示（如边界框或点）代替密集标签，以减少注释工作量，并使模型更易于交互学习。", "innovation": "该研究提出了弱监督上下文学习(WS-ICL)，这是一种新的ICL范式，利用弱提示（如边界框或点）代替密集标签，减少了注释工作量。WS-ICL在三个独立测试基准上的实验结果表明，其性能与常规ICL模型相当，而标注成本大大降低，即使在交互式范式下，其表现也非常有竞争力。这些发现为更高效且统一的医学图像分割模型铺平了道路。", "conclusion": "该研究证实了WS-ICL作为一种新的ICL方法，显著降低了医学图像分割的标注成本，同时保持了与传统ICL模型相当的性能。WS-ICL模型在提高医学图像分割效率方面具有重要潜力，并为未来的医学图像分割模型发展提供了新的方向。该研究的代码和模型已公开。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.06670", "html_url": "https://arxiv.org/abs/2310.06670", "title": "域通用性通过拒绝极端增强实现", "title_en": "Domain Generalization by Rejecting Extreme Augmentations", "authors": "Masih Aminbeidokhti,Fidel A. Guerrero Peña,Heitor Rapela Medeiros,Thomas Dubail,Eric Granger,Marco Pedersoli", "background": "数据增强是通过正则化深度学习模型和改善多种任务和领域的识别性能的一种最有效的技术之一。然而，这一有效性局限于标准的领域内设置，即训练和测试数据遵循相同的分布。在领域外情况下，当测试数据遵循不同的且未知的分布时，尚未找到最佳的数据增强方法。本文探讨了在领域外和跨域情况下，数据增强可以显著且稳健地提升表现的可能性。", "innovation": "本文提出了一种简单的训练程序：(i) 对标准数据增强变换使用均匀采样；(ii) 增强变换强度以应对域外情况下预期更高的数据变异性；(iii) 设计新的奖励函数以拒绝那些可能损害训练的极端变换。该研究方案在基准跨域数据集中实现的准确率与最先进的方法相当或更好。这表明数据增强可以在跨域场景中提供显著的且稳健的性能提升。", "conclusion": "通过使用本文提出的训练程序，数据增强方案在基准跨域数据集上达到了与最先进的方法相当或更高的准确性水平，表明数据增强可以显著且稳健地提升跨域情况下的表现。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.08132", "html_url": "https://arxiv.org/abs/2208.08132", "title": "最大化不均衡噪声标签元学习验证集的实用价值", "title_en": "Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning", "authors": "Dung Anh Hoang,Cuong Nguyen,Belagiannis Vasileios,Thanh-Toan Do,Gustavo Carneiro", "background": "元学习是一种处理不均衡和噪声标签学习的有效方法，但依赖于包含随机选取、手动标记和均衡分布样本的验证集。随机选择和手动标记、平衡验证集不仅对元学习来说是次优的，而且还随着类别的数量增加而扩展性差。因此，最近的元学习论文提出了自适应的准则是为了自动构建和标记这类验证集，但这些准则是仍对元学习来说是次优的。研究后续分析了元学习算法，并提出了一种新的指标来评估验证集的实用性：数据的有用信息内容、类分布平衡度以及标签正确性。此外，该文提出了一种新的不均衡噪声标签元学习算法（INOLML），通过最大化上述准则来自动构建验证集。", "innovation": "该研究分析了元学习算法，提出了新的指标来评估验证集的实用性，包括数据的有用信息含量、类分布平衡和标签准确性。该文还提出了一种新算法——不均衡噪声标签元学习算法（INOLML），并通过最大化前述准则自动构建验证集。该方法在多个基准测试上显著改进了先前的元学习方法，成为新的方法现状顶部。", "conclusion": "该研究方法在多个基准测试上显著改进了先前的元学习方法，成为新的方法现状顶部。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2209.03358", "html_url": "https://arxiv.org/abs/2209.03358", "title": "攻击尖峰：尖峰神经网络在对抗样本中的可移植性和安全性", "title_en": "Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples", "authors": "Nuo Xu,Kaleel Mahmood,Haowen Fang,Ethan Rathbun,Caiwen Ding,Wujie Wen", "background": "尖峰神经网络（SNNs）因其高能效和最近在分类性能上的进展而受到广泛关注。然而，与传统的深度学习不同，SNNs对于对抗样本的鲁棒性尚未得到充分探索。", "innovation": "本文对SNNs的对抗攻击侧进行了研究，并做出了三大贡献：1. 展示了SNNs的成功白盒攻击强烈依赖于替代梯度估计技术，即使是对抗训练的模型也是如此。2. 使用最佳的单一替代梯度估计器，探讨了SNNs与视觉变换器（ViTs）和CNNs等最先进的架构之间的对抗样本可移植性。研究发现了两个主要差距：没有现有的白盒攻击利用多个替代估计器，也没有单一的攻击能够同时愚弄SNNs和非SNN模型。3. 提出了混合动态尖峰估计（MDSE）攻击，该攻击动态结合多个替代梯度来克服这些差距，MDSE产生的对抗样本能够愚弄SNN和非SNN模型，提高了SNN/ViT集成高达91.4%的效果，在对抗训练的SNN集成上比Auto-PGD提升了3倍的效果。", "conclusion": "实验涵盖了三个数据集（CIFAR-10、CIFAR-100、ImageNet）和十九种分类器，将在发表时公开代码和模型。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.15222", "html_url": "https://arxiv.org/abs/2406.15222", "title": "一种用于中国非对比CT快速准确预警急性主动脉综合征的深度学习系统", "title_en": "A Deep Learning System for Rapid and Accurate Warning of Acute Aortic Syndrome on Non-contrast CT in China", "authors": "Yujian Hu,Yilang Xiang,Yan-Jie Zhou,Yangyan He,Dehai Lang,Shifeng Yang,Xiaolong Du,Chunlan Den,Youyao Xu,Gaofeng Wang,Zhengyao Ding,Jingyong Huang,Wenjun Zhao,Xuejun Wu,Donglin Li,Qianqian Zhu,Zhenjiang Li,Chenyang Qiu,Ziheng Wu,Yunjun He,Chen Tian,Yihui Qiu,Zuodong Lin,Xiaolong Zhang,Yuan He,Zhenpeng Yuan,Xiaoxiang Zhou,Rong Fan,Ruihan Chen,Wenchao Guo,Jianpeng Zhang,Tony C. W. Mok,Zi Li,Mannudeep K. Kalra,Le Lu,Wenbo Xiao,Xiaoqiang Li,Yun Bian,Chengwei Shao,Guofu Wang,Wei Lu,Zhengxing Huang,Minfeng Xu,Hongkun Zhang", "background": "急性主动脉综合征(AAS)患者急性胸痛的准确和及时诊断仍是一个临床挑战。由于经济和工作流程限制，中国大多数疑似患者最初进行非对比CT作为初步成像测试，而CT血管造影(CTA)仅用于高风险患者。因此，需要开发一种基于非对比CT的智能系统来提高诊断准确性。", "innovation": "提出了一种基于人工智能的预警系统iAorta，利用非对比CT对中国疑似AAS患者进行识别。iAorta通过多个步骤的研究展示出极高准确性，并为临床医生提供可解释的警告。该系统在广泛的实际使用中表现出了出色的性能，有效地缩短了诊断时间，减少了诊断延迟或漏诊的风险。", "conclusion": "iAorta能够在资源受限的地区或其他无法获取静脉对比剂的情况下，通过非对比CT有效识别急性主动脉综合征，并显著减少了诊断时间，避免了诊断延迟和漏诊。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.17832", "html_url": "https://arxiv.org/abs/2502.17832", "title": "MM-PoisonRAG: 使用局部和全局投毒攻击扰乱多模态RAG", "title_en": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks", "authors": "Hyeonjeong Ha,Qiusi Zhan,Jeonghwan Kim,Dimitrios Bralios,Saikrishna Sanniboina,Nanyun Peng,Kai-Wei Chang,Daniel Kang,Heng Ji", "background": "多模态大语言模型结合检索增强生成（RAG）技术显著提升了诸如多模态问答等任务的效果，通过将响应与外部文本和图像对接，提高了事实性，减少了幻觉，并扩展了推理能力超越了参数化知识。但是，对外部知识的依赖带来了一个亟待探索的安全风险：知识投毒攻击，攻击者故意将对抗性的多模态内容注入到外部知识库中，指导模型生成错误甚至有害的回答。", "innovation": "提出了MM-PoisonRAG框架，这是第一个系统设计多模态RAG知识投毒的方法。引入了两种互补的攻击策略：局部投毒攻击（LPA），植入针对性的多模态误导信息来操控特定查询；全局投毒攻击（GPA），注入单一的敌对知识以广泛干扰推理并诱导所有查询的无意义回答。通过不同任务、模型和访问设置进行全面实验，结果表明LPA可以实现高达56%的成功投毒率，而GPA只需一次敌对知识插入就可以完全破坏模型生成到0%的准确率。", "conclusion": "我们的结果揭示了多模态RAG的脆弱性，并强调了对知识投毒攻击的防御措施的迫切需求。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05759", "html_url": "https://arxiv.org/abs/2510.05759", "title": "OneVision：一种端到端的生成框架以实现多视角电商平台视觉搜索", "title_en": "OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search", "authors": "Zexin Zheng,Huangyu Dai,Lingtao Mao,Xinyu Sun,Zihan Liang,Ben Chen,Yuqing Ding,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai", "background": "传统视觉搜索，类似搜索和推荐系统，遵循多阶段级联架构（MCA）范式来平衡效率和转化率。具体而言，查询图像经过特征提取、召回、预排序和排序阶段，最终向用户展示与其偏好相匹配的语义相似产品。然而，查询和召回阶段多视角表示差异以及优化目标之间的碰撞，使得在用户体验和转化率之间实现帕累托最优变得困难。因此，本文提出了一个端到端的生成框架OneVision来解决这些问题。", "innovation": "OneVision基于VRQ（一种视图对齐残差量化编码），能够保持每个产品最具特色的特征，同时对同一对象在不同视角下的大规模不同表示进行对齐。此外，OneVision采用了多阶段语义对齐方案，在保持强视觉相似先验的同时，有效利用用户特定信息生成个性化偏好。与在线MCA相比，在离线评估中OneVision表现一致，通过动态剪枝将推理效率提高21%。在线A/B测试显示，它的改进超出预期：项目点击率提高2.15%，转化率提高2.27%，订单量提高3.12%。这表明，以语义ID为中心的生成架构可以统一检索和个人化的同时简化服务于路径。", "conclusion": "这些结果表明，基于语义ID的生成架构能够统一检索和个人化，同时简化服务路径。与传统的MCA相比，OneVision不仅在用户体验和转化率上取得了显著提升，还显著提高了推理效率。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01505", "html_url": "https://arxiv.org/abs/2503.01505", "title": "地理空间分析中具有损益性的神经压缩：综述", "title_en": "Lossy Neural Compression for Geospatial Analytics: A Review", "authors": "Carlos Gomes,Isabelle Wittmann,Damien Robert,Johannes Jakubik,Tim Reichelt,Michele Martone,Stefano Maurogiovanni,Rikard Vinge,Jonas Hurst,Erik Scheurer,Rocco Sedona,Thomas Brunschwiler,Stefan Kesselheim,Matej Batic,Philip Stier,Jan Dirk Wegner,Gabriele Cavallaro,Edzer Pebesma,Michael Marszalek,Miguel A Belenguer-Plomer,Kennedy Adriko,Paolo Fraccaro,Romeo Kienzler,Rania Briq,Sabrina Benassou,Michele Lazzarini,Conrad M Albrecht", "background": "近年来，地球观测（EO）数据的数量急剧增加。卫星图像对地球表面和大气层的空前覆盖产生了大量需要传输到地面站、存储在数据中心并分发给最终用户的数据。现代地球系统模型（ESMs）面临的挑战相似，它们在高空间和时间分辨率下运行，每天产生大量数据。数据压缩在过去十年中变得越来越重要，神经压缩（NC）作为一种从深度学习和信息论中产生的方法被提出，使EO数据和ESMs输出成为理想候选者，因为它们有大量的未标记数据。", "innovation": "综述中介绍了近期NC在地理空间数据中的应用进展，包括NC的基本概念和传统应用在图像和视频压缩领域的关键成果，尤其是损失压缩。还讨论了EO和ESM数据的独特特性，与“自然图像”进行对比，解释了这些数据带来的额外挑战和机遇。此外，还回顾了NC在各种EO模态中的应用现状，并探讨了对ESM压缩的有限研究。介绍了自我监督学习（SSL）和基础模型（FM）如何促进从大量未标记数据中高效提取表示的方法。", "conclusion": "在本文综述的基础上，提出了针对EO和ESM应用的相关未来方向，特别是利用压缩特征表示进行机器到机器通信的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.01160", "html_url": "https://arxiv.org/abs/2401.01160", "title": "使用立方持久同调在MRI中实现无训练分割", "title_en": "Train-Free Segmentation in MRI with Cubical Persistent Homology", "authors": "Anton François,Raphaël Tinarrage", "background": "目前，传统的机器学习方法在医学影像分割方面存在一些局限性，特别是在MRI段面的处理上。为了解决这些问题，作者提出了一种基于拓扑数据分析(TDA)的新框架，该框架在医学影像分割中提供了一种替代现有方法的新途径。与嵌入在深度网络中的大多数先前TDA方法不同，该方法是独立的，针对MRI进行了定制。该框架通过自动阈值确定待分割的对象，使用预先已知拓扑的特殊子集进行检测，并最终推导出分割组件。", "innovation": "作者提出的方法采用太阳能构建的可解释性循环局部化技术，能在不使用大量标记数据的情况下进行分割。方法具有模块化设计，适用于各种数据分割挑战。利用TDA分析，该方法可以检测并分割MRI扫描中的不同解剖结构，包括脑胶质瘤、心肌和胎儿脑皮层等。", "conclusion": "作者通过比较该方法与现有监督和非监督基准，验证了该框架的有效性。该框架能够在不同MRI应用中区分和检测特定的解剖结构，展示了其在无训练条件下的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05034", "html_url": "https://arxiv.org/abs/2510.05034", "title": "视频-大型多模态模型的后训练：深入探索大型多模态模型进行视频推理", "title_en": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models", "authors": "Yolo Yunlong Tang,Jing Bi,Pinxin Liu,Zhenyu Pan,Zhangyun Tan,Qianxiang Shen,Jiani Liu,Hang Hua,Junjia Guo,Yunzhong Xiao,Chao Huang,Zhiyuan Wang,Susan Liang,Xinyi Liu,Yizhi Song,Yuhe Nie,Jia-Xing Zhong,Bozheng Li,Daiqing Qi,Ziyun Zeng,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Daiki Shimada,Han Liu,Jiebo Luo,Chenliang Xu", "background": "视频理解构成了计算机视觉中最具有挑战性的前沿领域，要求模型能够推理复杂的时空关系、长时依赖以及多模态证据。近年来，视频-大型多模态模型（Video-LMMs）通过将视觉编码器与强大的基于解码器的语言模型集成，已在视频理解任务上展示了显著的能力。然而，这些模型从基本的感知系统转变为高阶的推理引擎（后训练阶段）的关键技术仍然碎片化地分布在文献中。", "innovation": "本文综述了对Video-LMMs的后训练方法进行了首次全面的研究，包括监督微调（SFT）、基于验证目标的强化学习（RL）以及测试时间缩放（TTS）等三大支柱。提出了一个结构化的分类框架来阐明这些技术的角色、相互关系和适合视频的特定调整，以适应时间定位、时空固定、长视频效率和多模态证据整合等独特挑战。通过系统分析代表性方法，总结了关键设计原则、见解和评估协议，指出了奖励设计、扩展性和成本性能优化的关键开放问题，同时精选了重要的基准、数据集和指标以促进对后训练效果的严格评估。", "conclusion": "本文旨在为研究人员和实践者提供有关推动Video-LMM能力的一项统一框架。关于更多资源和更新的信息，请访问此网址：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18015", "html_url": "https://arxiv.org/abs/2504.18015", "title": "DiffMI: 通过扩散驱动无监督模型反转击破面部识别隐私", "title_en": "DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven Training-Free Model Inversion", "authors": "Hanrui Wang,Shuo Wang,Chun-Shien Lu,Isao Echizen", "background": "面部识别存在严重的隐私风险，因为它依赖敏感且不可变的生物特征数据。尽管现代系统通过映射面部图像到嵌入（通常认为是隐私保护的）来缓解隐私风险，但模型反转攻击表明，身份信息仍然可以被恢复，暴露了重要漏洞。现有的攻击往往计算成本高昂且缺乏泛化性，尤其是那些需要特定目标训练的攻击。即使无需训练的方法也面临有限的身份可控性，阻碍了细致或未见过的面貌的忠实重建。", "innovation": "提出了一种名为DiffMI的新颖扩散驱动、无需训练的模型反转攻击，它首次引入了一个结合了鲁棒隐码初始化、分级对抗细化策略和基于统计的、有置信度的优化目标的新型管道。DiffMI可以应用于未见过的目标身份和面部识别模型，提供比依赖训练方法更强的适应性，同时显著减少计算开销。", "conclusion": "DiffMI在对反转免疫的系统的攻击成功率达到了84.42%到92.87%，并且在无监督生成对抗网络（GAN）基线方法中，性能提升了4.01%到9.82%。这种方法的实现可以在以下网址查看。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15946", "html_url": "https://arxiv.org/abs/2505.15946", "title": "MoRE-Brain: 使用路由混合专家进行跨被试可解释和泛化的fMRI视觉解码", "title_en": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "authors": "Yuxiang Wei,Yanteng Zhang,Xi Xiao,Tianyang Wang,Xiao Wang,Vince D. Calhoun", "background": "从fMRI数据解码视觉体验为理解人类感知提供了一种强有力的途径，并支持开发高级脑机接口，但当前的研究更多注重重建的保真度，而忽视了可解释性，这对获取神经科学洞察至关重要。", "innovation": "MoRE-Brain 提出了一种基于脑网络原理的混合专家层级架构，名为“混合专家路由框架”，用于高保真、可适应且可解释的视觉重建。具体来说，MoRE-Brain 有三大创新：首先，它引入了一种新的基于脑网络原则的混合专家架构，适合神经解码；其次，通过共享核心专家网络并只适应特定于个体的路由，实现了高效的跨个体泛化；最后，通过明确的路由机制提供了更强的机制性洞察，揭示了不同建模的脑区如何具体塑造重建图像的语义和空间属性。", "conclusion": "广泛的实验证明了 MoRE-Brain 在重建保真度方面的高效利用 fMRI 信号的能力，区分了真实的神经解码与过度依赖生成先验，标志着向着更泛化且可解释的 fMRI 视觉解码迈出了一大步。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Percept-V 挑战：多模态大语言模型能否破解简单的感知问题？", "title_en": "The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "认知科学研究将视觉感知视为智能发展的早期迹象之一。TVPS-4框架通过视觉辨别、形式恒常性等多种技能对人类感知进行分类和测试。虽然已有许多评估多模态大语言模型（MLLMs）复杂推理和知识技能的基准测试，但对于简单感知能力的评估研究相对较少。因此，本文引入了Percept-V数据集，包含6000张程序生成的未受污染的图像，共分为30个领域，每个领域测试一个或多个TVPS-4技能。现代多模态大语言模型能够解决更复杂的任务，但实验结果显示，这些模型在Percept-V上的表现远远不及人类。", "innovation": "本文通过引入Percept-V数据集，填补了评估多模态大语言模型在基本视觉感知能力上的研究空白。Percept-V数据集包含程序生成的未受污染的图像，用于测试人类和大语言模型的简单感知能力。实验结果显示，当前最先进的多模态大语言模型在Percept-V上的表现弱于人类。", "conclusion": "随着图像中物体数量的增加，模型的感知性能下降迅速。实验还识别出了对所有模型而言相对更难的感知技能。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL：探索事实导向的强化学习", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是慢思考模型，在推理过程中由于无法准确识别知识边界，常常表现出严重的虚构现象。增强学习（RL）可以提升复杂的推理能力，但其结果导向的奖励机制往往缺乏对思考过程的实证监督，进一步加剧了虚构现象的问题。", "innovation": "提出了知识增强的强化学习（KnowRL）。KnowRL通过将基于知识验证的事实性奖励整合到RL训练过程中，引导模型进行事实导向的慢思考，帮助它们识别知识边界。这种方法在RL训练期间提供目标化的事实输入，使模型能够学习和内化基于事实的推理策略。通过直接奖励推理步骤中事实的遵循，KnowRL促进了一个更可靠的思考过程。", "conclusion": "在三个虚构评估数据集和两个推理评估数据集上的实验结果表明，KnowRL有效减轻了慢思考模型的虚构现象，同时保持了其原有的强大推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19945", "html_url": "https://arxiv.org/abs/2503.19945", "title": "在乳房X光片中优化乳腺癌检测：一种全面的迁移学习、分辨率减少和多视图分类研究", "title_en": "Optimizing Breast Cancer Detection in Mammograms: A Comprehensive Study of Transfer Learning, Resolution Reduction, and Multi-View Classification", "authors": "Daniel G. P. Petrini,Hae Yong Kim", "background": "乳房X光摄影仍然是早期发现乳腺癌的核心技术。最近的人工智能进步使得计算机辅助诊断方法越来越复杂，从基于片段的分类器发展到整体图像方法，再到结合多种视图分析互补投影的多视图架构。尽管取得了这些进展，仍有许多关键问题尚未解决。论文通过系统研究五个关键问题来解决这些未解之谜：1）片段分类器在性能中的角色，2）从自然图像训练的主干的有效性，3）学习调整大小相比于传统下采样的优势，4）多视图整合的贡献，5）在不同图像质量下发现结果的稳健性。", "innovation": "研究通过新的比较方法展示了从单视图到多视图分析时的AUC增加了0.0217，并在完整VinDr-Mammo数据集中实现了使用多视图方法的显著改进，AUC提升了0.0492，达到85.11%。这些结果为多视图架构在乳房X光摄影解释中的优越性设立了新的基准。该研究为模型设计和迁移学习策略提供了理论见解，有助于开发更准确可靠的乳腺癌筛查工具。研究提供的推理代码和训练模型已公开，可供查阅和使用。", "conclusion": "该研究通过系统性地探讨和解决关于乳腺X光摄影中乳腺癌检测的关键问题，证明了多视图架构的优势，并通过实验证明了相比于之前的基于单一视图的方法，多视图方法可以显著提高AUC。实验证据支持研究提出的观点，即多视图方法对于乳腺癌诊断性能的提升作用。此外，研究还为未来的模型设计和数据预处理策略提供了理论指导，从而推动乳腺癌筛查工具的进一步完善与发展。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20444", "html_url": "https://arxiv.org/abs/2505.20444", "title": "HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models", "title_en": "HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models", "authors": "Haoran Li,Yingjie Qin,Baoyuan Ou,Lai Xu,Ruiwen Xu", "background": "Vision-Language Models (VLMs)在多模态任务中取得了显著进展，但在长上下文场景，特别是长视频中，其性能往往会下降。尽管Rotary Position Embedding（RoPE）已经在大型语言模型（LLMs）中获得了广泛应用以实现长度泛化，但它如何在视频中捕捉复杂的空间-时间依赖关系仍然是一个未解决的问题。现有的方法通常在RoPE中分配不同的频率来编码3D位置信息，但这些分配策略主要依赖于启发式方法，缺乏深入的理论分析。因此，需要一个方法来提高VLMs的长上下文能力，以可靠地建模任何长上下文中的语义相似性并支持在不同上下文长度下的鲁棒学习和灵活推理。", "innovation": "本文引入了HoPE（Hybrid of Position Embedding），一种混合位置嵌入方法，旨在提高VLMs的长上下文能力。HoPE采用了混合频率分配策略，以在任意长的上下文中可靠地建模语义，并引入了动态时间缩放机制，以实现不同长度上下文的安全学习和灵活推理。通过四个视频基准上的广泛实验，证明了HoPE在长视频理解与检索任务上的一贯优越性，验证了方法的有效性。", "conclusion": "本文的研究结果表明，HoPE可以显著提高VLMs在长上下文场景中的表现，特别是在长视频理解与检索任务中。该研究通过理论分析和实证研究，证实了HoPE的有效性和可靠性，并且提供了提高VLMs长上下文能力的新途径。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22970", "html_url": "https://arxiv.org/abs/2509.22970", "title": "通过任何图像学习机器人", "title_en": "Robot Learning from Any Images", "authors": "Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang", "background": "传统的机器人学习方法主要依赖于特定的硬件和大量的数字资产，如机器人的数据集。这限制了机器人数据生成的广度和效率。本研究旨在通过直接从单张图像中生成物理交互的机器人环境来解决这一问题，无需额外硬件或数字资产，从而能够快速生成大量的可视化和运动交互数据。", "innovation": "提出了一种名为RoLA的新框架，该框架能够从任何来源的图像（如相机捕获、机器人数据集或互联网图像）中生成交互式的、基于物理的机器人环境。其核心特点是结合了一种新颖的单视角物理场景恢复方法和高效的视觉融合策略，用于收集逼真的数据。", "conclusion": "RoLA技术在多方面展示了其应用潜力，如大规模机器人数据生成和扩充、从互联网图像中学习机器人、以及实现实景转模拟的真实机器人系统。验证结果显示，RoLA能够在几分钟内从广泛的数据源生成逼真的视觉和运动数据，适用于操纵器和类人机器人。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03262", "html_url": "https://arxiv.org/abs/2510.03262", "title": "从正交蒙特卡洛丢弃重新思考适配器合并中的LoRA正交性：正交Monte Carlo丢弃的见解", "title_en": "Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout", "authors": "Andi Zhang,Xuan Ding,Haofan Wang,Steven McDonagh,Samuel Kaski", "background": "LoRA（Low-Rank Adaptation）是用于大型模型的流行微调方法，它通常训练一个模块来表示特定的概念，如对象或风格。当通过合并多个LoRA模块，例如生成特定风格的对象时，它们的输出（语义向量）可能会相互干扰。先前的研究指出，合并LoRA模块时的相互正交性有助于语义的分离，但实际分析表明，这种正交性并没有带来先前研究中提到的语义解混纠缠。", "innovation": "提出了正交蒙特卡洛丢弃作为一种机制，当合并稀疏语义向量时，可以确保输出的严格正交性，且不会增加额外的时间复杂度。该方法可以保证合并后的LoRA模块保持正交性，从而避免直接相互干扰。尽管如此，实证分析表明，这种正交性未能实现先前研究中提到的语义分解纠缠", "conclusion": "现有研究中合并LoRA模块的相互正交性可能不足以实现真正的语义组合，提示需要重新评估其在适配器合并中的作用。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03569", "html_url": "https://arxiv.org/abs/2510.03569", "title": "纵向流匹配轨迹建模", "title_en": "Longitudinal Flow Matching for Trajectory Modeling", "authors": "Mohammad Mohaiminul Islam,Thijs P. Kuipers,Sharvaree Vadgama,Coen de Vente,Afsana Khan,Clara I. Sánchez,Erik J. Bekkers", "background": "生成模型在处理稀疏采样和高维轨迹时往往表现不佳，通常会将动力学习简化为对两两过渡的学习。现有方法难以捕捉内在的随机性，不能很好地处理不规则的稀疏采样，也无法生成个体特定的轨迹。", "innovation": "提出了一种名为Interpolative Multi-Marginal Flow Matching (IMMFM)的方法，该方法可以学习连续随机动力学，且与多个观察时间点一致。IMMFM利用分段二次插值路径作为流匹配的平滑目标，并联合优化漂移和基于数据的扩散系数，通过理论条件保证稳定学习。此设计能捕捉内在随机性，处理不规则的稀疏采样，生成个体特定的轨迹。实验表明，IMMFM在预测精度和下游任务方面优于现有方法。", "conclusion": "IMMFM方法在合成基准和真实世界纵向神经影像数据集上都表现出色，验证了其有效性和优越性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24031", "html_url": "https://arxiv.org/abs/2509.24031", "title": "GPS-MTM:使用自我监督学习捕捉GPS轨迹中的正常模式", "title_en": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning", "authors": "Umang Garg,Bowen Zhang,Anantajit Subrahmanya,Chandrakanth Gudavalli,BS Manjunath", "background": "基础模型已经在文本、视觉和视频理解方面取得了显著的进步，并在轨迹建模方面有望实现类似的突破。现有的轨迹建模方法通常将轨迹平面化为坐标流，而没有捕捉到人类移动的规律。因此，迫切需要一种能够捕捉人类移动模式的基础模型来克服这些局限性，这就是论文中GPSMasked Trajectory Transformer (GPS-MTM)的诞生背景。", "innovation": "GPS-MTM通过分解移动行为为两种互补的模式（状态和动作），提出了不同的方法。使用双向Transformer和自我监督掩蔽建模目标，使得模型在不依赖人工标签的情况下就可以学习复杂的语义相关性。此外，GPS-MTM在多个基准数据集上的下游任务（如轨迹补全和下一目的地预测）中表现优异，并特别在动态任务上表现出色，突显了其从上下文推理的重要性。因此，GPS-MTM被确立为轨迹分析的强大基础模型，并将移动数据提升为大规模表示学习中的一个重要模态类别。", "conclusion": "GPS-MTM通过自我监督学习方式，有效地捕捉了GPS轨迹中的正常模式，实现了在大规模移动数据上的性能提升。研究结果证明，GPS-MTM在轨迹补全和预测方面具有显著优势，并在动态任务中表现更好，因此为轨迹分析提供了坚实的基础模型，推动了移动数据在大规模表示学习中的应用。此外，代码已公开以便进一步参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06267", "html_url": "https://arxiv.org/abs/2510.06267", "title": "RareGraph-Synth: 知识引导的扩散模型用于生成超罕见疾病中具有隐私保护的合成患者轨迹", "title_en": "RareGraph-Synth: Knowledge-Guided Diffusion Models for Generating Privacy-Preserving Synthetic Patient Trajectories in Ultra-Rare Diseases", "authors": "Khartik Uppalapati,Shakeel Abdulkareem,Bora Yimenicioglu", "background": "超罕见疾病的电子健康记录（EHR）数据由于其隐私性和稀缺性，难以共享和用于研究。传统的生成模型无法在保证隐私的同时生成高质量的合成数据，这限制了超罕见疾病的研究进展。", "innovation": "RareGraph-Synth 引入了一个以知识为导向、连续时间的扩散框架，该框架将五个公开资源（Orphanet/Orphadata、HPO、GARD 罕见疾病KG、PrimeKG 和 FAERS）整合成一个异构知识图谱，用于生成具有生物合理性且隐私保护的超罕见疾病 EHR 轨迹。通过此框架，可以调节生成过程中的噪声，避免信息泄露，同时保持模型的稳定性。", "conclusion": "RareGraph-Synth 在生成超罕见疾病患者轨迹方面，相对无指导扩散模型和GAN模型表现更优，同时保持了下游预测效用，并且在黑盒成员推断攻击下具有更强的抗重新识别能力，表明整合生物医学知识图谱可同时提高生成数据的真实性和隐私性，有助于更安全地共享罕见疾病研究数据。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13590", "html_url": "https://arxiv.org/abs/2509.13590", "title": "基于VLM的智能医疗成像平台：一种自动化医学图像分析和临床报告生成框架", "title_en": "Intelligent Healthcare Imaging Platform: A VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "authors": "Samer Al-Hamadani", "background": "人工智能（AI）在医疗成像领域的迅速发展已经彻底改变了诊断医学和临床决策过程。这项工作提出了一种结合Vision-Language Models (VLMs)的智能多模态医疗图像分析框架，用于跨CT、MRI、X射线和超声等多种成像模态下的自动化肿瘤检测和临床报告生成。该系统结合了视觉特征提取和自然语言处理，以实现具有坐标校验机制和概率高斯建模的上下文图像解释，多层次可视化技术生成详细的医学插图、叠加比较和统计表示，以增强临床信心，定位测量平均偏差为80像素。结果处理通过精确提示工程和文本分析提取结构化的临床信息，同时保持可解释性。实验评价展示了在多种成像模态下高异常检测性能。该系统具备用户友好的Gradio界面，便于临床工作流集成，并展示出零样本学习能力，减少对大规模数据集的依赖。这项框架代表了自动化诊断支持和放射学工作流程效率的重大进展，但在广泛采用之前，临床验证和多中心评估是必要的。", "innovation": "1. 利用Vision-Language Models (VLMs)进行多模态医疗图像分析，实现自动化肿瘤检测和临床报告生成。\n2. 结合视觉特征提取和自然语言处理，提供上下文图像解释，包括坐标校验机制和概率高斯建模。\n3. 多层可视化技术生成详细的医学插图、叠加比较和统计表示。\n4. Gradio用户友好界面整合临床工作流程，具备零样本学习能力，减少对大规模数据集的依赖性。\n5. 达到较高的多模态异常检测性能。", "conclusion": "本文提出的智能多模态医疗图像分析框架利用Vision-Language Models (VLMs)进行多模态成像模态下的肿瘤检测和临床报告生成，结合视觉特征提取和自然语言处理，进行上下文图像解释。该系统通过多层次可视化生成详细的医学图示和统计表示，增强临床信心。实验结果证明了在多种模态下高异常检测性能。该框架展示了便捷的临床工作流集成和零样本学习能力，减少了对大规模数据集的依赖。但是，为了广泛的临床应用，仍需进行临床验证和多中心评估。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06278", "html_url": "https://arxiv.org/abs/2510.06278", "title": "RVFL-X：基于复数变换实值表格数据的新型随机网络", "title_en": "RVFL-X: A Novel Randomized Network Based on Complex Transformed Real-Valued Tabular Datasets", "authors": "M. Sajid,Mushir Akhtar,A. Quadir,M. Tanveer", "background": "近年来，随着基础理论研究的深化，神经网络的表征能力得到了显著提升，特别是复杂数的应用显示出其优越性。然而，由于缺乏有效方法将实值表格数据转换为复数值表示，复杂数在随机神经网络（RNN）中的应用受到了限制。", "innovation": "本文提出了一种新的方法，即RVFL-X，一种基于复杂数变换的实值表格数据扩展的随机向量功能链接(RVFL)网络。该方法通过自然变换和基于自编码器的方法生成复数值表示。RVFL-X能够将复杂数变换融合到实值数据集中，同时保持原始RVFL架构的简单性和高效性。通过利用输入、权重和激活函数等复数组件，RVFL-X能够在处理复数值表示的同时产生实数值输出。", "conclusion": "在80个实值UCI数据集上的全面评估表明，RVFL-X在性能上持续优于原始RVFL和最新的RNN变种，展示了其在不同应用领域的稳健性和有效性。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05173", "html_url": "https://arxiv.org/abs/2510.05173", "title": "SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models", "title_en": "SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models", "authors": "Peigui Qi,Kunsheng Tang,Wenbo Zhou,Weiming Zhang,Nenghai Yu,Tianwei Zhang,Qing Guo,Jie Zhang", "background": "文本到图像模型在从自然语言描述生成高质量图像方面表现出色，但这些模型对对抗性提示极为敏感，这可能会绕过安全措施并生成有害内容。尽管已有多种防御策略，但在保持实用性的同时实现对抗攻击下的鲁棒性仍然是一个重大挑战。特别是在现实应用中，确保这些模型的安全性和实用性仍然是一个难题。因此，本文聚焦于分析稳定的扩散（SD）模型中的文本编码器，并提出了SafeGuider框架，旨在在不降低生成质量的情况下提供鲁棒的安全控制。", "innovation": "通过对文本编码器进行实证研究发现，[EOS]标记作为语义聚合器，其嵌入空间中在良性提示和对抗性提示之间表现出不同的分布模式。基于此发现，本文提出了SafeGuider框架，该框架结合了嵌入级识别模型和一种具有安全感知特征擦除的束搜索算法。SafeGuider能确保在为良性提示保持高质量图像生成的同时，对域内和域外攻击保持鲁棒防御，并在各种攻击场景中将攻击成功率降至5.48%以下。与传统策略不同的是，SafeGuider能够针对危险提示生成安全且有意义的图像，提高了其实用性。此外，SafeGuider不仅适用于SD模型，还可以应用于其他文本到图像模型，证明了其在不同架构下的通用性和适应性。", "conclusion": "SafeGuider框架为确保文本到图像系统的安全性和实用性提供了有效的解决方案，既能在实际应用中提供对抗攻击的鲁棒性，又能在保持生成图像质量的同时提供安全的内容控制。该框架具有广泛应用的潜力，并为未来研究提供了新的思路。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06291", "html_url": "https://arxiv.org/abs/2510.06291", "title": "Traj-Transformer：使用变压器的扩散模型用于GPS轨迹生成", "title_en": "Traj-Transformer: Diffusion Models with Transformer for GPS Trajectory Generation", "authors": "Zhiyang Zhang,Ningcong Chen,Xin Zhang,Yanhua Li,Shen Su,Hui Lu,Jun Luo", "background": "GPS设备的广泛应用推动了时空数据挖掘的进步，使得机器学习模型能够模拟人类决策过程并生成真实轨迹，从而解决了数据收集成本和隐私问题。已有研究表明，扩散模型在高质量轨迹生成方面具有的潜力。然而，大多数现有方法依赖于基于卷积的架构（如UNet）在扩散过程中预测噪声，这通常会导致显著偏差并丢失街级细节，这往往是因为模型容量有限。", "innovation": "本文提出了一种名为Trajectory Transformer的新模型，它使用变压器作为骨干网络，用于条件信息嵌入和噪声预测。研究了两种GPS坐标嵌入策略，即位置嵌入和经度纬度嵌入，并分析了在不同尺度下的模型性能。", "conclusion": "在两个真实世界数据集上的实验表明，Trajectory Transformer显著提高了生成质量并有效缓解了先前方法中的离散问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06270", "html_url": "https://arxiv.org/abs/2510.06270", "title": "MCCE: 多大型语言模型协作共演化框架", "title_en": "MCCE: A Framework for Multi-LLM Collaborative Co-Evolution", "authors": "Nian Ran,Zhongzheng Li,Yue Wang,Qingsong Ran,Xiaoyuan Zhang,Shikun Feng,Richard Allmendinger,Xiaoguang Zhao", "background": "多目标离散优化问题，如分子设计，因其庞大的无序组合空间而极具挑战性。传统的进化算法往往容易陷入局部最优，而专家知识能够提供加速收敛的关键指导。大型语言模型（LLMs）具备强大的先验知识和推理能力，成为在专家知识重要时的自然优化器。但是，封闭源的LLMs虽然在探索方面表现出色，却缺乏参数更新的能力，无法内化经验。相反，较小的开源模型可以不断调整，但缺乏广泛的知识和推理能力。因此，需要一种结合封闭源LLM和可训练模型的混合框架，以实现知识驱动的探索和经验驱动的学习，并达到最优的帕累托前沿质量。", "innovation": "本文引入了Multi-LLM Collaborative Co-evolution (MCCE)框架，结合了封闭源的LLL和小型可训练模型。该框架通过强化学习逐步优化小型模型，同时利用两种模型之间的互补作用进行全局探索。这种过程不仅提高了双方模型的能力，还通过相互启发增强了各自的能力。实验表明，MCCE在多目标药物设计基准测试中实现了最先进的帕累托前沿质量，并持续超越基线模型，揭示了混合LLM系统中结合知识驱动探索与经验驱动学习的新范式。", "conclusion": "MCCE框架通过将封闭源LLM与轻量级可训练模型结合起来，实现了持续进化，展示了混合LLM系统中知识驱动探索与经验驱动学习相结合的新模式，达到了领先的帕累托前沿质量，并持续超越基线方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06284", "html_url": "https://arxiv.org/abs/2510.06284", "title": "通过图像识别进行结检测", "title_en": "On knot detection via picture recognition", "authors": "Anne Dranowski,Yura Kabkov,Daniel Tubbenhauer", "background": "该研究旨在通过捕捉照片并由智能手机自动识别其中的结来实现最终目标。团队通过结合现代机器学习方法（尤其是用于图像识别的卷积神经网络和变换器）与传统算法（特别是用于计算量子不变量如琼斯多项式），解释了一种策略来接近这一目标。研究也展示了简单基线模型直接从图像预测交叉数，显示出即使是轻量级的CNN和变换器架构也能恢复有意义的结构信息。", "innovation": "研究提出了一种结合机器学习和传统算法的策略，利用卷积神经网络和变换器进行图像识别，同时通过计算量子不变量来识别结。轻量级的CNN和变换器架构能够从图像中直接预测交叉数并恢复有意义的结构信息。研究强调了机器学习处理嘈杂视觉数据与量子不变量确保严格的拓扑区分之间的互补性，并旨在将这些感知模块与符号重构结合，进而生成平面图表代码，以实现稳健的结分类目标。", "conclusion": "这种方法强调了机器学习和量子不变量在处理结问题上的互补性，并揭示了轻量级的深度学习模型可以在图像中直接识别结的关键角色。在未来的工作中，研究人员计划将这些感知模块与符号重构技术相结合，生成平面图表代码，为下游的不变量计算提供坚实的基础，从而实现稳健的结分类。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06303", "html_url": "https://arxiv.org/abs/2510.06303", "title": "SDAR：一种实现大规模序列生成的协同扩散-自回归范式", "title_en": "SDAR: A Synergistic Diffusion-AutoRegression Paradigm for Scalable Sequence Generation", "authors": "Shuang Cheng,Yihan Bian,Dawei Liu,Yuhua Jiang,Yihao Liu,Linfeng Zhang,Wenhai Wang,Qipeng Guo,Kai Chen,Biqing Qi,Bowen Zhou", "background": "背景：自回归模型在序列生成任务中表现出较强的性能，但其训练效率较低。扩散模型则有并行推理的能力，但其端到端的训练成本较高。本文的目的是探讨如何结合两者的优点，提高序列生成任务的效率和性能。", "innovation": "创新：提出了SDAR（Synergistic Diffusion-AutoRegression）范式，将自回归模型的训练效率与扩散模型的并行推理能力相结合。通过轻量级的范式转换，将自回归模型转化为块状扩散模型。在推理阶段，SDAR能同时在多个块中并行生成，保持AR级别的性能，同时提高了生成效率。", "conclusion": "结论：通过实验验证，SDAR模型在计算效率方面优于部分遮盖的扩散模型，证实了其在大规模和混合专家模型架构中扩展的鲁棒性，且不损失准确性。此外，SDAR还在科学推理和化学方面展示了更好的推理能力和域适应性，从而确立了SDAR作为结合自回归和扩散优点的一种实用范式，以实现高效推理和生成。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06293", "html_url": "https://arxiv.org/abs/2510.06293", "title": "BlockGPT：通过帧级自回归建模降雨的空时建模", "title_en": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression", "authors": "Cristian Meo,Varun Sarathchandran,Avijit Majhi,Shao Hung,Carlo Saccardi,Ruben Imhoff,Roberto Deidda,Remko Uijlenhoet,Justin Dauwels", "background": "预测降水图像是一个高度复杂的时空建模任务，对于减轻极端天气事件的影响至关重要。短期降水预报或现在进行式预报需要既准确又在实时应用中计算高效的方法。当前方法，例如基于令牌的自回归模型，通常受到缺陷归纳偏差和缓慢推断的困扰，而扩散模型则可能计算量大。为解决这些限制，我们介绍了BlockGPT，这是一种使用批量化标记方法的生成自回归变压器，它在每个时间步骤预测两维完整场（帧）。BlockGPT将空间时间分解为每个帧内的自我注意和帧间因果注意；在本文中，我们将其实例化用于降水现在进行式预报.", "innovation": "BlockGPT 通过批量化的标记方法，提出了一个生成自回归变换器模型，能够预测每个时间步骤的完全二维空间字段。该模型通过帧内自我注意和帧间因果注意分解时空，并被构想为一种适用于视频预测的模型-无特定模型范式。它在两个降水数据集（KNMI和SEVIR）上进行评估，结果表明BlockGPT在分类指标评估的事件定位精度和比同类基线快31倍的推理速度方面表现出优异性能。", "conclusion": "BlockGPT 在降水现在进行式预报任务上取得了显著的准确性和高效性，在分类指标和推理速度方面优于其他先进的基线方法，表明 BlockGPT 是一种有效的模型-无特定模型范式以处理短期降水预测的问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06367", "html_url": "https://arxiv.org/abs/2510.06367", "title": "Lagrangian神经ODEs: 使用Helmholtz度量测量拉格朗日的存在", "title_en": "Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics", "authors": "Luca Wolf,Tobias Buck,Bjoern Malte Schaefer", "background": "神经ODEs在物理领域中被广泛应用，但它们并不总是满足物理要求，即不一定是欧拉-拉格朗日方程。Helmholtz度量被提出用于量化给定ODE与欧拉-拉格朗日方程的相似性，并且在有噪声的基本系统上展示了其能力。", "innovation": "作者将Helmholtz度量与第二阶神经ODE结合，形成拉格朗日神经ODE，这种结合方法允许直接学习欧拉-拉格朗日方程而无需额外的推理成本。此外，这种方法仅使用位置数据就能够区分拉格朗日系统和非拉格朗日系统，并提高神经ODE的解决方案的准确性。", "conclusion": "该研究表明，通过拉格朗日神经ODE，能够仅基于位置数据识别拉格朗日系统和非拉格朗日系统，并且这种方法在噪声存在的情况下也能提高神经ODE的解决方案质量。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系变换器：通往关系数据零样本基础模型的道路", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练变换器可以在无需特定任务或数据集微调的情况下，直接应用于新的序列建模任务，但关系领域的架构仍然缺乏跨数据集和任务转移的能力。关键挑战在于关系数据的多样性，包括各异的模式、图形结构和功能依赖。当前的研究旨在解决这个问题，提出了一种新的预训练架构——关系变换器（RT）", "innovation": "RT架构通过利用元数据对单元格进行分词、预训练掩码令牌预测、以及使用新型的关系注意力机制跨越列、行和主外键链接，能够在多样化的关系数据库上进行预训练，并在未见过的数据集和任务上直接应用而无需特定任务或数据集的微调。RT在跨越衰退和销售预测等任务的RelBench数据集上进行预训练，展示出了强大的零样本性能，并在单次前向传递一个包含22M参数的模型中达到了平均94%的二元分类任务的完全监督AUC-ROC分数，相比之下，27B参数的大型语言模型则为84%。同时， fine-tuning的结果达到了最新的技术水平，展示了高度的样本效率。实验表明，RT的零样本迁移利用了任务-表上下文、关系注意力模式和模式语义", "conclusion": "RT提供了一条实用的道路，通往关系数据的基础模型，并展示了强大的零样本性能和高样本效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06381", "html_url": "https://arxiv.org/abs/2510.06381", "title": "Monte Carlo Permutation Search", "title_en": "Monte Carlo Permutation Search", "authors": "Tristan Cazenave", "background": "该研究在探讨深度强化学习不可行或竞赛前计算资源有限的情况下，提出了一种通用的蒙特卡洛树搜索（MCTS）算法——蒙特卡洛置换搜索（MCPS）。GRAVE算法虽然在此之前已经有所应用，但MCPS在某些方面表现得更为出色，尤其是在两种玩家的游戏中。对于多玩家游戏，MCPS与GRAVE的结果相近，因为这类游戏本身即使玩家实力不同也能保持平衡。此外，该研究还展示了使用抽象代码替代精确代码对于MCPS和GRAVE都有益处，能够改善置换统计和AMAF统计。", "innovation": "MCPS通过在节点的探索项中包含从根节点到该节点路径上所有播放出的结果统计数据来改进探索策略。该研究还提供了用于权重分配的数学推导，这些公式优于GRAVE公式，无需使用偏差超参数。此外，MCPS对涉众超参数不敏感。还展示了用抽象代码代替精确代码对于MCPS和GRAVE都是有益的，可以提升置换统计和AMAF统计数据的效果。", "conclusion": "MCPS在两种玩家的游戏中的表现优于GRAVE，在多玩家游戏中表现相似且与游戏平衡性有关。使用抽象代码代替精确代码可以提升性能。MCPS算法对于在有限计算资源下进行通用游戏策略搜索具有重要意义，无需担心某些参数的灵敏度问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06355", "html_url": "https://arxiv.org/abs/2510.06355", "title": "PIKAN: 物理启发的柯尔莫哥洛夫-阿诺德网络用于可解释的无人机信道建模", "title_en": "PIKAN: Physics-Inspired Kolmogorov-Arnold Networks for Explainable UAV Channel Modelling", "authors": "Kürşat Tekbıyık,Güneş Karabulut Kurt,Antoine Lesage-Landry", "background": "无人机（UAV）通信需要准确且可解释的空中到地面（A2G）信道模型，能够在非站定传播环境中适应变化。现有的确定性模型虽然简单易解释，但缺乏灵活性，而基于深度学习的模型尽管准确性高，但难以解释。为了弥合这两者之间的差距，作者提出了一种名为PIKAN的物理启发网络，将物理原理（如自由空间路径损耗和两线反射）嵌入学习过程，并且这种网络引入物理信息的方式更灵活，带来了更灵活的训练过程。实验表明，PIKAN在达到与深度学习模型相当的准确度的同时，还能提供遵循传播定律的符号性和可解释表达式，同时其参数量只有232个，比具有数千个参数的多层感知机（MLP）基线轻37倍，且具有较好的与测量数据的相关性，还能提供符号性表达。这些都是PIKAN具有高效、可解释和可扩展的特点的依据，适用于第5G和6G及以上网络中的无人机信道建模。", "innovation": "PIKAN网络通过物理原理的嵌入，在保持模型灵活性的同时增加了可解释性，减少了模型参数的同时保持了与测量数据的良好对应关系。这种方法显著提高了模型的效率和实用性。", "conclusion": "PIKAN作为一种有效、可解释且可扩展的解决方法，在5G和6G网络中的无人机信道建模上表现出了明显的优势，展示了其在非站定传播环境适应性方面的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06388", "html_url": "https://arxiv.org/abs/2510.06388", "title": "制作和评估校准预测", "title_en": "Making and Evaluating Calibrated Forecasts", "authors": "Yuxuan Lu,Yifan Wu,Jason Hartline,Lunjia Hu", "background": "可靠的预测可以被解释为概率。要实现更好的校准，关键步骤是设计适当的校准指标来有意义地评估预测器的偏差水平。之前的一项研究（Haghtalab等，2024）探讨了设计诚实校准指标的方法：当预测器输出真实概率时，诚实指标将达到最小值；而非诚实的指标将促使预测器说谎以看起来更校准化。此前所有的校准指标都是非诚实的，直到Hartline等（2025）引入了二分类预测任务中第一个完美的诚实校准指标。本文研究了将校准指标从二分类扩展到多分类的方法，并识别出保留真理性的指标和不保留真理性的指标。此外，我们的研究不仅证明了诚实性，还证明了我们的校准指标展现了卓越的稳健性：它严格地保持先验和后验预测器的排序不变，无论超参数（分区大小）的选择如何。这一成果解决了binned ECE在先前工作中反复出现的不稳健性问题。", "innovation": "本文引入了一个适用于多分类预测任务的完美诚实校准指标，扩展了Hartline等（2025）在二分类预测任务中的工作。此外，本文通过数学证明和实验验证证明了此校准指标的优越稳健性，即无论超参数（分区大小）如何选择，它都能严格保持先验和后验预测器的排序。", "conclusion": "本研究提出了一个多分类条件下的完美诚实校准指标，首次超越二分类预测任务。这一指标不仅满足了真理性的要求，还展现了卓越的稳健性，解决了以往的不稳定性问题，提供了更为可靠的校准评估方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06349", "html_url": "https://arxiv.org/abs/2510.06349", "title": "分散式蜂群学习可能在关键任务中超越基础模型", "title_en": "Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks", "authors": "Moein E. Samadi,Andreas Schuppert", "background": "随着基础模型快速发展，AI取得了显著进步，但研究者也开始质疑这些模型在现实世界领域的决策最终是否会超越人类策略。由于AI发展可能呈现指数级甚至超指数级加速，因此难以对其进行直接分析。许多影响日常生活和社会的重要应用领域仍仅取得微小进展，比如重症监护中动态变化疾病的诊断和治疗。共同挑战是适应复杂的动态环境，要求模型能够在系统中多种强相互作用功能优化结果的同时避免共享副作用，这需要可靠的自我适应模型。这些任务与构建高度复杂系统（其机制不完全或定量理解）的数字孪生体相关。因此，开发能够较少依赖数据和机制知识进行自我适应的AI模型显得至关重要。由于这一挑战不仅限于医学领域，AI在这些环境中的直觉优越性需要在可预见未来承担更重要的决策角色之前得到明确展示。本文指出现象维数构成的基本障碍，基础模型可能在此过程中面临概念局限。作为替代方案，本文提出了交互的小代理网络（SANs）分散式架构，重点在于代理代表系统专化的子结构，每个代理仅覆盖系统的一部分功能。结合SANs的学习行为数学结果和现有应用的证据，本文认为SANs的分布式学习可以在多样化的SANs中实现有效的自我适应性，并在动态环境中比基础模型更有优越的决策性能，尽管可能导致细节上的可重复性降低。", "innovation": "提出了一种分散式的小代理网络（SANs）架构作为替代基础模型的新范式。这种架构的核心在于使用代理来代表系统中专化的子结构，并且每个代理只覆盖系统的一部分功能。通过SANs的学习行为数学结果和现有应用的证据支持，该论文建议这种分散式学习方法可以在动态环境中比基础模型提供更优秀的决策性能，尽管在细节上的可重复性上有所降低。", "conclusion": "分散式蜂群学习可能在关键任务中超越基础模型，但由于作为替代方案的SANs在细节上的可重复性较低，它们的优越性可能无法在所有应用中都完全得到体现。因此，应谨慎引入SANs架构以进行更多的现实世界测试和应用研究。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06401", "html_url": "https://arxiv.org/abs/2510.06401", "title": "标签噪声对神经表示信息量的影响", "title_en": "The Effect of Label Noise on the Information Content of Neural Representations", "authors": "Ali Hussaini Umar,Franky Kevin Nando Tezoh,Jean Barbier,Santiago Acevedo,Alessandro Laio", "background": "在监督分类任务中，模型被训练用于预测每个数据点的标签。在现实世界的数据集中，由于标注错误，这些标签往往是嘈杂的。尽管嘈杂标签对深度学习模型性能的影响已被广泛研究，但它们对网络隐藏表示的影响仍不明确。本研究通过系统比较使用信息不平衡（一种条件互信息的计算有效代理）来弥补这一空白。", "innovation": "作者们发现了隐藏表示的信息内容随网络参数数量变化呈现出类似‘双重下降’的行为，类似于测试误差的行为。在参数不足的情况下，用嘈杂标签学习的表示比用干净标签学习的表示更具信息性；而在参数过载的情况下，两种表示的信息量相等。研究结果表明，过参数化网络的表示对标签噪声具有鲁棒性。此外，作者观察到在过参数化的情况下，交叉熵损失减少使得最终和前softmax层之间的信息不平衡减少，这为理解分类任务中的泛化提供了一个新的视角。研究还表明，从随机标签中学习的表示性能劣于随机特征，表明使用随机标签的训练会驱动网络远超出懒学习阶段，权重会适应编码标签信息。", "conclusion": "本研究的结果表明，过参数化网络的表示对标签噪声具有鲁棒性，并提供了理解分类任务泛化的新视角。此外，使用随机标签进行训练会大幅推动网络超越懒学习阶段。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06397", "html_url": "https://arxiv.org/abs/2510.06397", "title": "几何感知后门攻击：在双曲嵌入中的利用曲率", "title_en": "Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic Embeddings", "authors": "Ali Baheri", "background": "非欧几里得基础模型越来越倾向于将表示置于双曲几何等弯曲空间中。研究表明，这种几何结构会在边界处产生一种驱动的不对称性，这使得后门触发器能够被利用。在这种空间中，邻近边界的小输入变化虽然在标准输入空间检测器看来可能是细微的，但实际上却会导致模型表示空间的巨大偏差。这种效应已经被正式化，并揭示了一个防御机制的局限性：那些通过拉点朝半径内收缩的方法，只能在牺牲同方向上的有用模型敏感性的同时来抑制此类触发器。基于这些见解，作者提出了一种简单的几何适应性触发器，并在任务和架构上对其进行评估。实验结果表明，攻击成功率向边界增加，而传统检测器则减弱，这与理论趋势一致。这些结果揭示了非欧几里得模型中的几何特定漏洞，并为设计和理解防御措施的限制提供了基于分析的指导。", "innovation": "提出了一种基于几何适应性的简单触发器，该方法通过分析表明，攻击成功率向边界增加，而传统检测器则减弱，这与理论上预计的一致，从而揭示了非欧几里得模型中的几何特定漏洞，并为设计有效和理解防御限制提供了指导。", "conclusion": "非欧几里得模型中的几何特殊漏洞被揭示出来，并提供了一种基于几何适应性的触发器以增强对抗性攻击的效果，同时揭示了当前防御方法在此类架构中的局限性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06419", "html_url": "https://arxiv.org/abs/2510.06419", "title": "时间序列预测中的测试时高效预训练模型组合", "title_en": "Test-Time Efficient Pretrained Model Portfolios for Time Series Forecasting", "authors": "Mert Kayaalp,Caner Turkmen,Oleksandr Shchur,Pedro Mercado,Abdul Fatir Ansari,Michael Bohlke-Schneider,Bernie Wang", "background": "近年来，时间序列基础模型的趋势是使用更大的单一模型。然而，本文提出了一种新的方法，即构建由多个较小的预训练预测模型组成的模型组合，而不是训练单一的大模型。通过应用这些组合的集成或模型选择，在大规模基准测试中取得了与单一大型模型相当甚至更优的性能，但所需的参数量大大减少。", "innovation": "本文提出的创新点是构建一个由多个较小的预训练预测模型组成的模型组合，并通过集成或模型选择策略实现与单一大型模型相当或更优的性能，同时参数量大大减少。研究发现，专门模型的集合在性能上优于独立训练的通用模型。此外，研究还表明，通过后训练基模型可以创造足够多样的专家模型，这种方法在计算成本上是有效的，且集成或模型选择比测试时微调更为高效。", "conclusion": "本文的研究成果表明，对于时间序列预测任务，构建模型组合的方法可以实现比单一大型模型更好的性能，同时减少所需的参数量。特别地，该方法在计算成本上是高效的，并提供了比测试时微调更有效的策略。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06439", "html_url": "https://arxiv.org/abs/2510.06439", "title": "不确定性环境下用于随机模型中尺度参数训练的贝叶斯优化", "title_en": "Bayesian Optimization under Uncertainty for Training a Scale Parameter in Stochastic Models", "authors": "Akash Yadav,Ruda Zhang", "background": "在系统本身存在不确定性的情况下，超参数调整是一个具有挑战性的问题，特别是由于具有噪声的函数评价，优化在不确定性下的成本会非常昂贵。", "innovation": "本文提出了一种新的贝叶斯优化框架，专门针对具有不确定性的超参数调整，特别是针对随机模型中的尺度或精度参数进行优化。该方法利用了潜在随机变量的统计代理，使得期望算子的解析评价成为可能。此外，论文推导了随机获取函数的最优解的闭式表达式，这显著降低了每个迭代的成本。与传统的基于蒙特卡洛的一维优化方案相比，所提方法仅需四十分之一的数据点，从而将计算成本降低了四十倍。", "conclusion": "通过两个计算工程中的数值例子，证实了所提出方法的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06448", "html_url": "https://arxiv.org/abs/2510.06448", "title": "如何不评估你的SITE指标：超越静态排行榜，迈向实际评估", "title_en": "How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation", "authors": "Prabhant Singh,Sibylle Hess,Joaquin Vanschoren", "background": "当前广泛使用的转移可量化度量基准设置存在缺点，这些度量的评估基准从根本上是缺陷的，低估了现实世界中模型选择的复杂性。现有的基准在不合理的模型空间和静态性能等级的影响下，错误地提升了现有度量的表现，甚至简单的、无数据集特异性的启发式方法都能超越复杂的手段。", "innovation": "本文提供了具体建议来构建更稳健和真实的基准，推动未来研究向更有意义的方向发展，弥补了当前评估协议与实际模型选择复杂性的差距，旨在建立有效的转移可量化度量评估体系，为真实世界的应用提供指导.", "conclusion": "未来的研究需要一个更为稳健和现实的评估基准来引导方向，该基准能更好地反映现实世界模型选择的复杂性，避免现有基准中不必要的偏向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06478", "html_url": "https://arxiv.org/abs/2510.06478", "title": "通过经验动态形式提升实现LLM生成的有效停止", "title_en": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "介绍了Sequential-EDFL（经验动态形式提升）方法，将任意时有效的序列测试应用于语言模型生成的停止。该方法跟踪信息提升——基于整个模型与故意削弱的“骨架”基线之间的对数似然比率，并使用自我规范化经验伯恩斯坦e过程进行形式化的delta级错误控制，无论停止时间如何。", "innovation": "通过引入经验动态形式提升（EDFL）方法，实现了对语言模型生成过程的有效停止。该方法能够在保持任意时有效的停止保证的同时，使用在线均值估计处理未知中心化问题，通过混合e过程捆绑多个参数，支持在分布漂移情况下的自适应重置。此外，该方法结合了自动骨架（精简子模型，随机化logits）以增强系统的鲁棒性。", "conclusion": "Sequential-EDFL相比序列基线，在六个基准测试上将生成量减少了22-28%，同时保持了delta级控制，计算开销仅为12%。通过与轻量级正确性门控（句子边界+验证器）组合，EDFL能够提高最终任务的正确性，同时保留任意时有效的停止保证。EDFL作为第一阶段筛选器减轻了验证负担，但并不能替代安全关键领域中的独立解决方案，它仅能控制信息的充分性而非事实的正确性，即使有门控机制，仍有10.9%的停止序列错误。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06477", "html_url": "https://arxiv.org/abs/2510.06477", "title": "LARGE LANGUAGE MODELS 中注意力陷阱和压缩谷地是同一枚硬币的两面", "title_en": "Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin", "authors": "Enrique Queipo-de-Llano,Álvaro Arroyo,Federico Barbero,Xiaowen Dong,Michael Bronstein,Yann LeCun,Ravid Shwartz-Ziv", "background": "在大型语言模型中，注意力陷阱（Attention Sinks）和压缩谷地（Compression Valleys）引起了广泛关注，但这两个现象一直被孤立研究。这些现象通常是由中层大规模激活引起的，这导致了表示压缩的出现，从而减少了熵。本文通过实验在多个模型中发现了这两者之间的惊人联系，并通过单一视角验证了理论预测，揭示了大型语言模型在深度上组织计算的方法。", "innovation": "本文通过揭示注意力陷阱和压缩谷地之间的内在联系，提出了一种新的理论——Mix-Compress-Refine理论，试图解释大型语言模型是如何通过控制大规模激活、注意力和表示压缩来组织深度计算的。这一理论将注意力陷阱（Attention Sinks）和压缩谷地（Compression Valleys）统一在一个框架中，并详细描述了Transformer架构下语言模型处理词元的三个主要阶段：早期广泛混合、中期压缩计算和晚期精炼筛选。", "conclusion": "这一统一理论解释了不同任务对深度处理的不同依赖性，即嵌入任务在中间层表现最好，而生成任务则受益于全深度处理。研究者们通过实验证明了当输入序列的第一个标记在中层产生极端的激活范数时，这两个现象会同时出现，这为理解大型语言模型如何组织计算提供了新的视角。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06503", "html_url": "https://arxiv.org/abs/2510.06503", "title": "ATLO-ML：机器学习中的自适应时间长度优化器——空气质量预测的见解", "title_en": "ATLO-ML: Adaptive Time-Length Optimizer for Machine Learning -- Insights from Air Quality Forecasting", "authors": "I-Hsi Kao,Kanji Uchino", "background": "时间序列预测在机器学习中受输入时间长度和采样率选择的影响较大。本文介绍了ATLO-ML，这是一个自适应时间长度优化系统，能够根据用户定义的输出时间长度自动确定最佳输入时间长度和采样率。该系统提供了一种灵活的时间序列数据预处理方法，能够动态调整这些参数以提高预测性能。", "innovation": "ATLO-ML系统能够在无需手动调整的情况下自动确定最佳的时间长度和采样率，通过动态调整参数来提高预测模型的准确性。该系统适用于多种时间敏感的应用场景，为优化机器学习工作流中的时间输入参数提供了一个稳健的解决方案。", "conclusion": "ATLO-ML系统通过采用优化的时间长度和采样率，在空气质量数据集上相比固定时间长度显著提高了机器学习模型的准确性。该系统具有广泛的应用前景，适用于各种需要优化时间参数的时间敏感应用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06505", "html_url": "https://arxiv.org/abs/2510.06505", "title": "无标label数据的中位数视角下的Out-of-Distribution检测", "title_en": "A Median Perspective on Unlabeled Data for Out-of-Distribution Detection", "authors": "Momin Abbas,Ali Falahati,Hossein Goli,Mohammad Mohammadi Amiri", "background": "Out-of-distribution (OOD)检测对于确保实际应用中机器学习系统的稳健性和可靠性至关重要。尽管最近的方法探索了使用无标签数据提升OOD检测能力，但有效地利用无标签数据依然具有挑战性，因为既有分布数据(In-D)与OOD数据混合在一起，且缺乏一个明确的OOD样本集合，这增加了训练最优OOD分类器的难度。", "innovation": "Medix，一种新颖的框架，通过中位数操作来识别无标签数据中的潜在异常值，以提升OOD检测能力。Medix利用中位数的鲁棒性来估计中心趋势，作为一种OOD检测机制，并使用这些识别出的异常值结合有标签的In-D数据去训练一个稳健的OOD分类器。理论上，Medix的方法被证明具有较低的误差率。", "conclusion": "Empirical结果进一步验证了我们的理论，Medix在开放世界的设置中优于现有方法，证明了我们理论洞察的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06434", "html_url": "https://arxiv.org/abs/2510.06434", "title": "通过Hellinger局部化从多种轨迹中几乎最优地恢复参数", "title_en": "Nearly Instance-Optimal Parameter Recovery from Many Trajectories via Hellinger Localization", "authors": "Eliot Shekhtman,Yichen Zhou,Ingvar Ziemann,Nikolai Matni,Stephen Tu", "background": "时间相关数据的学习是当今机器学习的核心方面，但在多轨迹环境中，即时间索引的随机过程的许多独立实现的数据中进行序列学习的理解仍不完整。这种重要情况下，不仅反映了现代训练管道，也提供了不需典型独立同分布假设的学习潜力。目前仅知实例最优的界限适用于有依赖协变量的最小二乘回归，而对于一般模型或损失函数，唯一可普遍适用的保证是减少为独立同分布学习或现有单轨迹的结果。现有工作主要依赖于样本大小与轨迹数量的比例，或者在每个单独轨迹混合的情况下，样本大小类似于数据预算的减少版。", "innovation": "通过Hellinger局部化框架，该研究显著扩大了多轨迹设置下的实例最优率范围。该方法通过将路径级的Hellinger距离控制归结为独立同分布学习，然后通过参数空间中权重为轨迹费舍尔信息的二次形式进行局部化，从而在广泛条件下获得实例最优界限，且与全数据预算成比例。这种方法在四个广泛不同的案例研究中得到了实例，表明这些界限几乎与渐近正态性的实例最优率相符，大幅改进了标准减少方法的效果。", "conclusion": "通过Hellinger局部化框架，该研究实现了在多轨迹环境下的实例最优界限，并在多个案例研究中验证了其效果，结果显示这种方法能够显著提高参数恢复的效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06502", "html_url": "https://arxiv.org/abs/2510.06502", "title": "GUIDE: 引导初始化和嵌入蒸馏", "title_en": "GUIDE: Guided Initialization and Distillation of Embeddings", "authors": "Khoa Trinh,Gaurav Menghani,Erik Vee", "background": "现有的算法效率技术，如蒸馏（Hinton et al., 2015），在不增加部署成本的前提下提升模型质量是有用的，前提是可用一个较大的教师模型为较小的学生模型在训练期间进行学习。标准的蒸馏方法仅强制学生匹配教师的输出。鉴于训练大型模型的成本，我们应从教师模型中获取更多有用的信息。因此，本文提出了一种新的方法 \textbackslash{}guide（引导初始化和嵌入蒸馏）。", "innovation": "方法 \textbackslash{}guide 强制学生在参数空间内匹配教师，从而减少了在大学生模型（400M - 1B 参数）上训练时约25-26% 的教师-学生质量差距。此外，该方法还可以与知识蒸馏结合使用，带来近乎线性的改进。单独使用 \textbackslash{}guide 也能显著提升模型质量，优于仅使用知识蒸馏。最重要的是，\textbackslash{}guide 不增加训练和推理的开销，因而任何通过该方法获得的模型质量改进几乎是免费的。", "conclusion": "该研究提出了一种新的蒸馏技术 \textbackslash{}guide，该技术能够有效减少教师学生模型的质量差距，提升了模型质量，并且没有任何训练和推理的额外开销。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06527", "html_url": "https://arxiv.org/abs/2510.06527", "title": "宽神经网络作为计算无巧合猜想的基准", "title_en": "Wide Neural Networks as a Baseline for the Computational No-Coincidence Conjecture", "authors": "John Dunbar,Scott Aaronson", "background": "研究表明，随机初始化且宽度较大的神经网络，在激活函数满足零均值条件下（$\text{E}_{z \thicksim \text{N}(0,1)}[\text{σ}(z)]=0$），其输出几乎独立。已有激活函数如ReLU、GeLU （带偏移）以及tanh，均满足这一条件，而单纯的ReLU或GeLU不满足。", "innovation": "提出使用零均值激活函数的神经网络作为计算无巧合猜想的候选解决方案，该猜想旨在衡量人工智能可解释性的极限。", "conclusion": "宽神经网络的输出近乎独立，表明它们可能适合用于验证‘计算无巧合猜想’（Computational No-Coincidence Conjecture），这是关于AI可解释性的猜想。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06444", "html_url": "https://arxiv.org/abs/2510.06444", "title": "使用性能预测实现具有上下文感知推断的分散学习网络", "title_en": "Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks", "authors": "Joel Pfeffer,J. M. Diederik Kruijssen,Clément Gossart,Mélanie Chevance,Diego Campo Millan,Florian Stecker,Steven N. Longmore(Allora Foundation)", "background": "在分散学习网络中，来自多个参与者的预测被组合以生成网络推理。虽然许多研究表明结合多个模型预测可以提高性能，但现有的使用线性聚合方法（从简单平均到动态权重更新）的方法存在关键限制。依赖于历史表现进行权重更新的动态预测组合通常是反应性的。由于需要在一定数量的周期（使用移动平均或指数加权）中进行平均，它们往往在适应变化的情况（阶段或范式改变）方面效率低下。因此，本文开发了一个模型，利用机器学习来预测每个时间序列时期的模型预测表现，这使得模型能够在给定时段给予更准确预测更高的权重，具备上下文感知能力。这一模型被应用于一个类似Allora网络的设计中，证实可以提高网络推理的准确性。具体来说，预测后悔（相对于网络推理的表现）或后悔z分数（相对于其他成员的表现）的模型比预测损失的模型提供更好的改进，而后者往往不能超过传统的网络推理（历史加权的平均推断）的性能。在一系列优化测试中，发现预测模型的表现对特征集和训练周期的数量选择非常敏感，这些特性可能依赖具体的网络问题并需定制到每个领域以确保最佳性能。尽管最初是为了应用于分散学习网络而设计的，但性能预测的使用可以适用于任何需要基于预测而非反应性模型权重选择的情境中。", "innovation": "本文开发了一种利用机器学习预测每个时间序列时期的模型预测表现的方法。赋予了模型在给定时段给予更准确预测更高权重的能力，增强了上下文感知能力。通过类似Allora网络的设计，添加一个性能预测的工作者，可以提高网络推理的准确性。实验发现预测后悔或后悔z分数的模型比预测损失的模型带来了更好的改进。特征集和训练周期的数量的选择对模型性能有显著影响，需在特定领域进行定制以优化性能。这种方法不仅适用于分散学习网络，也可应用于需要基于预测而非反应性模型权重的任何情境中。", "conclusion": "上下文感知的预测模型可以改进分散学习网络中的预测组合性能。通过识别和改进每个时间序列时期的模型表现，这种方法比传统的后验平均权重方法更具有灵活性和效率。未来的研究可以探索更好的特征选择方案，以提高模型的预测性能，同时也应考虑如何提高模型的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06525", "html_url": "https://arxiv.org/abs/2510.06525", "title": "文本生成图像模型留下可识别的签名：对排行榜安全性的影响", "title_en": "Text-to-Image Models Leave Identifiable Signatures: Implications for Leaderboard Security", "authors": "Ali Naseh,Anshuman Suri,Yuefeng Peng,Harsh Chaudhari,Alina Oprea,Amir Houmansadr", "background": "生成性人工智能排行榜在评估模型能力方面具有重要意义，但仍可能受到操控。其中，排名操控是一个关键的对抗性目标，攻击者必须首先匿名化展示输出背后的模型。对于大型语言模型（LLMs），这一威胁已经得到证明和探索。最新的研究发现，在文本到图像排行榜中，去匿名化要容易得多。研究者使用了超过150,000个由280个提示和19个不同的模型生成的图像，这些模型来自多个组织、架构和规模，以验证这一假设，结果显示即使在没有控制提示或历史数据的情况下，在CLIP嵌入空间中进行实时分类也能以极高的准确性识别生成模型。", "innovation": "研究提出了一种提示级别可分性度量，并确定了能够实现近乎完美的去匿名化的提示。结果表明，文本到图像排行榜的排名操控比之前设想的要容易得多，凸显了更强的防御措施的需求。这项研究填补了文本到图像领域中的一个空白，首次从安全性的角度对排行榜中的模型进行了深入分析。", "conclusion": "研究结果表明，在文本到图像排行榜上的排名操控比之前认为的要更容易，因此需要更强的安全防御措施来保护排行榜的公平性和透明性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06540", "html_url": "https://arxiv.org/abs/2510.06540", "title": "POMDPs的可扩展基于策略的RL算法", "title_en": "Scalable Policy-Based RL Algorithms for POMDPs", "authors": "Ameya Anjarlekar,Rasoul Etesami,R Srikant", "background": "POMDPs（部分可观测马尔可夫决策过程）的状态连续性带来了在学习最优策略时的极大计算挑战。本文探讨了一种通过将相应的POMDP模型近似为一个无限状态马尔可夫决策过程（称为超级状态MDP）来解决部分可观测强化学习（PORL）问题的方法。", "innovation": "本文首先推导出理论保证，提高了先前工作的上限，将转换后的超级状态MDP的最优价值函数与原始POMDP的最优价值函数相关联。然后提出了基于策略的学习方法，利用线性函数逼近来学习超级状态MDP的最优策略。此外，证明了通过将POMDP视为MDP并使用TD学习和策略优化来近似解决POMDP时，随着历史长度的增加，近似误差呈指数级减少。这是首次明确量化在使用标准TD学习时引入的错误，特别是在真正动态不是马尔可夫的情况下。", "conclusion": "本文的方法展示了如何通过将POMDP视为MDP来近似解决POMDP问题，通过这种方式，可以使用TD学习和策略优化来找到无限历史对应的MDP状态下的最优策略。论文的结果表明，随着历史长度的增加，近似误差呈指数级减少。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06545", "html_url": "https://arxiv.org/abs/2510.06545", "title": "目标条件自回归模型中的无组织性", "title_en": "Incoherence in goal-conditioned autoregressive models", "authors": "Jacek Karwowski,Raymond Douglas", "background": "本文研究了无组织性的数学概念：这是一种强化学习策略中存在的结构性问题，这些策略是由朴素的目标条件化的自回归模型推导出来的。文章关注的是重新训练模型在线上强化学习中自身行为的过程，即用在线RL微调离线学习的策略。研究表明，这一过程可以减少无组织性并提高回报，文章旨在刻画由此产生的策略轨迹。通过重新定义控制即推理和软Q学习的标准概念，建立了重新训练过程与其他两种理解方式的三重对应关系：将后验折叠到奖励中，在确定性情况下降低温度参数；这种对应关系通过训练-推断权衡具有计算内容。通过软条件生成模型，讨论了无组织性与有效时间范围之间的联系。", "innovation": "通过重新培训自回归模型并引入软Q学习和控制即推理的思想，该研究建立了一个三重对应关系，即重新训练过程的四种解释：减少无组织性；将后验折叠到奖励中；减少温度参数；并探讨这些思想的计算内容。", "conclusion": "通过建立该对应关系，文章指出，可以通过减少无组织性，将后验折叠到奖励中，或者在确定性情况下降低温度参数来理解和改进在线与离线的强化学习过程。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06623", "html_url": "https://arxiv.org/abs/2510.06623", "title": "DPA-Net：一种用于从自我监测血糖数据推断血糖控制指标的双路径注意力神经网络", "title_en": "DPA-Net: A Dual-Path Attention Neural Network for Inferring Glycemic Control Metrics from Self-Monitored Blood Glucose Data", "authors": "Canyu Lei,Benjamin Lobo,Jianxin Xie", "background": "连续葡萄糖监测（CGM）能够提供密集和动态的葡萄糖轮廓，有助于可靠地估计诸如Time in Range（TIR）、Time Below Range（TBR）和Time Above Range（TAR）等循环葡萄糖轨迹（AGP）指标。然而，CGM高昂的成本和有限的可及性限制了其广泛的使用，尤其是在低收入和中等收入地区。相比之下，自我监测血糖（SMBG）尽管成本低且广泛可用，但由于生成的数据稀疏且不规则，难以转化为临床相关的血糖指标。", "innovation": "本文提出了一种双路径注意力神经网络（DPA-Net），可以直接从SMBG数据中估计AGP指标。该网络结合了两个互补路径：（1）空间通道注意力路径，该路径从稀疏的SMBG观察中重建类似于CGM的轨迹；（2）多尺度ResNet路径，直接预测AGP指标。此外，还引入了一种对齐机制以减少偏差并缓解过拟合，及开发了一种主动点选择器来识别反映患者行为模式的真实和有意义的SMBG采样点。", "conclusion": "在大量实际数据集上的实验结果表明，DPA-Net在低偏差和低误差的情况下实现了稳健的准确性。据我们所知，这是一套首次用于推断AGP指标的监督式机器学习框架，为CGM不可用的环境中提供了实用且临床相关支持决策工具。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06557", "html_url": "https://arxiv.org/abs/2510.06557", "title": "马尔可夫思考者", "title_en": "The Markovian Thinker", "authors": "Milad Aghajohari,Kamran Chitsaz,Amirhossein Kazemnejad,Sarath Chandar,Alessandro Sordoni,Aaron Courville,Siva Reddy", "background": "强化学习（RL）最近成为训练能够产生长链思考（LongCoT）的推理大型语言模型（LLMs）的有效方法。然而，标准的RL‘思考环境’使得状态变得无界，使得基于注意力的策略随着思考长度增加而需要进行平方级的计算量。文章回顾了这个环境本身，并提出了马尔可夫思考这一新范式，在这种新范式下，策略可以在固定大小的状态下进行思考，将思考长度与上下文大小分离，从而实现线性计算和常量内存的需求。通过在这个环境中训练，即使是在固定大小的思考单元内，RL策略也能学习写出接近思考结束时的文本信息，以支持在重置后无缝继续思考。与传统方法相比，这种方法能够大大节省资源并实现更长的思考长度，显著降低了成本.", "innovation": "本文提出了马尔可夫思考这一新范式（Markovian Thinking），将思考单元结构化成固定大小的块，让策略在每块固定大小的块内思考，并在块边界重置上下文。这种方法显著减少了所需的计算资源，使得模型可以在固定大小的思考单元内进行长程思考，而且这种方法在测试阶段可以通过扩展来进一步提升表现。同时，分析表明标准的推理模型在初始化时常常能够生成有效的马尔可夫轨迹，这使得RL技术在大规模应用中更加有效。这种方法显著降低了长思考所需的成本，展示了重新设计思考环境在提升长程推理模型表现上的重要性.", "conclusion": "通过重新设计思考环境，使得思考长度和上下文大小分离开来，使得在有效利用内存和计算资源的同时实现了非常长的推理。这种方法不仅解决了标准RL方法的计算成本问题，还为高效的大规模推理模型开辟了新的途径。研究结果表明，这种方法能够匹配或超越受24K预算限制的LongCoT-RL模型的表现，并且在测试时的扩展能力要优于LongCoT。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06631", "html_url": "https://arxiv.org/abs/2510.06631", "title": "基于AI的城市供水系统的预测与监测", "title_en": "AI-Driven Forecasting and Monitoring of Urban Water System", "authors": "Qiming Guo,Bishal Khatri,Hua Zhang,Wenlu Wang", "background": "地下供水和污水管道对于城市运行至关重要，但由于泄漏和渗漏等问题，会导致大量水资源损失、环境损坏和高昂的维修成本。传统的手动检查效率低下，密集部署传感器成本过高。近年来，人工智能技术得到了快速发展，并被越来越多地应用于城市基础设施。针对地下供水管道漏水检测的挑战，本研究提出了一种综合AI和远程传感器框架，通过部署少量远程传感器来实时获取流量和深度数据，并结合HydroNet模型，该模型利用管道属性（如材料、直径、坡度）进行复杂图形中的更高精度建模。实验结果表明，该系统能够收集有效的时空水力数据，使HydroNet在高级基线模型中表现出色。这种方法结合边缘感知消息传递与水力模拟，能够从有限的传感器部署中实现网络级的准确预测.", "innovation": "本研究提出了一种结合AI和远程传感器框架的方法，通过部署少量传感器来实现精确的地下供水管道漏水检测，同时利用HydroNet模型，考虑管道属性进行更准确的建模。与传统方法相比，这种方法能够降低部署成本和提高检测精度，还能实现网络级的准确预测，具有较高的实用性和推广价值.", "conclusion": "本研究的系统能够收集有效的时空水力数据，并利用HydroNet模型实现了先进的基线模型的超越。这种边感知消息传递与水力模拟的结合，能够在有限的传感器部署下实现网络级的准确预测。展望未来，该方法可以广泛应用于各种地下供水管道网络，具有较大的应用前景和推广价值."}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06632", "html_url": "https://arxiv.org/abs/2510.06632", "title": "Chem-NMF: 多层α-发散非负矩阵分解在心血管呼吸疾病聚类中的应用，以化学催化剂和严谨的渐近分析为基础改善收敛性", "title_en": "Chem-NMF: Multi-layer $α$-divergence Non-Negative Matrix Factorization for Cardiorespiratory Disease Clustering, with Improved Convergence Inspired by Chemical Catalysts and Rigorous Asymptotic Analysis", "authors": "Yasaman Torabi,Shahram Shirani,James P. Reilly", "background": "非负矩阵分解（NMF）作为一种无监督学习方法，在音频处理、生物医学信号分析和图像识别等多个领域提供了低秩表示。将α-发散引入NMF的方法增强了优化的灵活性，但将这些方法扩展到多层架构时确保收敛性面临挑战。已有研究从数学上证明了渐近收敛结果，但在实际数据中的应用尚不明确。本文旨在通过借鉴化学反应中的能量障碍来提出一种新的方法，以理论上分析NMF算法的收敛行为，这是首次从物理化学角度严正分析NMF算法收敛性的研究。", "innovation": "提出了名为Chem-NMF的新型方法，通过引入一个界因子来稳定收敛，该方法首次结合了物理化学视角进行NMF算法的渐近收敛行为分析。这种方法借助化学催化的灵感，为多层α-发散NMF提供了解决多层架构收敛问题的创新路径，显著提高了心脏呼吸疾病信号和面部图像的聚类准确性（分别提高了5.6%±2.7%和11.1%±7.2%）", "conclusion": "本文提出了Chem-NMF方法，通过引入界因子实现NMF算法的稳定收敛，其新方法和分析理论在心脏呼吸疾病信号和面部图像聚类任务中表现出了更高的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06634", "html_url": "https://arxiv.org/abs/2510.06634", "title": "改进的分布到分布生成建模中的三种随机注入形式", "title_en": "Three Forms of Stochastic Injection for Improved Distribution-to-Distribution Generative Modeling", "authors": "Shiye Su,Yuhui Zhang,Linqi Zhou,Rajesh Ranganath,Serena Yeung-Levy", "background": "数据分布间的变换建模是一项基本的科学挑战，常见于药物发现和进化模拟等应用中。流匹配提供了一种自然框架来解决这一问题，但其主要应用于噪声到数据的场景，而对于数据分布到数据分布的场景则研究较少。特别当源数据本身也是待学习的数据分布时，由于监督数据稀疏，标准的流匹配方法会失效。", "innovation": "针对上述问题，本文提出了一种简单且计算效率高的方法，通过在训练过程中注入随机性（扰动源样本和流插值），解决了标准流匹配方法在学习数据分布时监督数据稀疏的问题。实验结果显示，在涵盖生物学、放射学和天文学等五个不同成像任务中，该方法显著提高了生成质量，平均在FID得分上超过了现有基线9个点。此外，该方法还能更有效地降低输入和生成样本之间的传输成本，突显出变换的真实效应，从而使得流匹配方法更加适用于科学中的多样分布变换模拟。", "conclusion": "本文提出的方法通过在训练过程中引入随机性，有效改善了数据分布到数据分布生成建模的效果，尤其是在处理稀疏监督数据时，显著提高了生成质量并增加了其在科学研究中的实际应用价值。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06635", "html_url": "https://arxiv.org/abs/2510.06635", "title": "StruSR：基于物理学启发式泰勒引导的结构感知符号回归", "title_en": "StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance", "authors": "Yunpeng Gong,Sihan Lan,Can Yang,Kunpeng Xu,Min Jiang", "background": "传统的符号回归方法试图通过搜索数学公式空间来找到可解析的表达式，以捕捉系统行为，尤其是在受物理定律约束的科学建模中。然而，这些传统方法缺乏从时间序列观测中提取结构化物理先验的机制，因此难以捕捉反映系统全局行为的符号表达式。", "innovation": "该研究提出了一种名为StruSR的结构感知符号回归框架，利用预训练的物理知情神经网络（PINNs）从时间序列数据中提取局部结构化的物理先验。通过在训练好的PINN的输出上进行局部泰勒展开，获得基于导数的结构信息以指导符号表达式的进化。引入一种基于蒙版的归因机制，量化每个子树对结构对齐和物理残差减少的贡献，这些敏感度分数引导遗传编程中的突变和交叉操作，保存高物理或结构重要性的子结构，而选择性地修改不太信息丰富的组件。结合使用一种混合适应度函数，同时最小化物理残差和泰勒系数不匹配，以确保一致性。", "conclusion": "实验表明，StruSR相较于传统基准提高了收敛速度、结构保真度和表达式可解释性，提供了一种基于物理基础的符号发现的合理范式。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06637", "html_url": "https://arxiv.org/abs/2510.06637", "title": "控制增强的自回归扩散模型在数据同化的应用", "title_en": "Control-Augmented Autoregressive Diffusion for Data Assimilation", "authors": "Prakhar Srivastava,Farrin Marouf Sofian,Francesco Immorlano,Kushagra Pandey,Stephan Mandt", "background": "尽管在测试时缩放和微调扩散模型方面取得了最新进展，但自回归扩散模型（ARDMs）中的引导技术仍然未被充分探索。在混沌时空偏微分方程（PDEs）的数据同化（DA）情境下，现有方法往往由于计算上的限制和较少观测数据导致预报偏差。", "innovation": "本文提出了一种递增框架，将轻量级控制器网络接入预训练的ARDMs，通过离线训练和预览未来ARDM模拟，学习逐步控制以预期即将出现的观测值，实现终端成本目标。此框架将数据同化的推断简化为单次向前滚动，并在推断过程中避免了昂贵的反向计算和/或优化。", "conclusion": "我们的方法在两个经典PDEs和六个观测模式下，展示了在稳定性和准确性以及物理忠实度方面的一致优势，超越了四个最新的基准模型。代码和检查点将公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06646", "html_url": "https://arxiv.org/abs/2510.06646", "title": "机器学习算子中的零样本超分辨率假象", "title_en": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators", "authors": "Mansi Sakarvadia,Kareem Hegazy,Amin Totounferoush,Kyle Chard,Yaoqing Yang,Ian Foster,Michael W. Mahoney", "background": "科学机器学习和更广泛的科学计算的一个核心挑战是，在实践中连续现象被离散化表示。机器学习算子（MLOs）被引入作为实现这一建模目标的方法，因为这类架构能够在任意分辨率下进行推理。本文评估了这种架构创新是否足以实现“零样本超分辨率”，即模型能够在比原始训练数据更高的分辨率下提供推理服务。研究还全面评估了MLOs中的零样本亚分辨率和超分辨率（即多分辨率）推理，并将多分辨率推理分解为两个关键行为：1）对不同频率信息的外推；2）在不同分辨率之间进行插值。实证研究表明，MLOs无法在零样本方式下完成这两个任务。", "innovation": "研究提出了一种简单的、计算效率高且数据驱动的多分辨率训练协议，该协议克服了混叠问题，并提供了多分辨率泛化能力。", "conclusion": "MLOs无法在与训练分辨率不同的分辨率下进行准确推理，而是表现出脆弱性和易受混叠。因此，提出了一种简单的计算效率高且数据驱动的多分辨率训练协议，解决了这些潜在问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06649", "html_url": "https://arxiv.org/abs/2510.06649", "title": "基于动作条件化根均方Q函数的局部强化学习", "title_en": "Local Reinforcement Learning with Action-Conditioned Root Mean Squared Q-Functions", "authors": "Frank Wu,Mengye Ren", "background": "前馈-前馈（FF）算法是一种最近提出的神经网络学习程序，它采用两轮前向传播，而不是传统反向传播中的前向和后向传播。尽管FF在监督学习设置中表现出色，但在可以更自然地获取学习信号的领域，如强化学习（RL）中，仍然局限于监督设置。本文受到FF中利用层活动统计的好感度函数的启发，提出了一种新的局部RL价值估计方法——动作条件化根均方Q函数（ARQ），它结合了局部RL中基于时差的学习，并引入了portun理解的的好感度函数和动作条件化。", "innovation": "本文提出了一种基于动作条件化根均方Q函数的局部RL方法（ARQ），该方法引入了getUrl)理解的好感度函数，实现了与最先进的无反向传播局部RL方法更好的性能，在MinAtar和DeepMind控制套件基准测试中表现更为出色，甚至在许多任务上也超过了使用反向传播训练的算法。", "conclusion": "该方法在MinAtar和DeepMind控制套件基准测试中的表现优于最先进的无反向传播局部RL方法，甚至在许多任务上也超过了使用反向传播训练的算法，表明了该方法的有效性和优越性。源代码可以从提供的链接获取。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06683", "html_url": "https://arxiv.org/abs/2510.06683", "title": "分布式 Multi-Agent 赌臂机算法中的碰撞问题", "title_en": "Distributed Algorithms for Multi-Agent Multi-Armed Bandits with Collision", "authors": "Daoyuan Zhou,Xuchuang Wang,Lin Yang,Yang Gao", "background": "研究了多玩家多臂赌博机（MMAB）问题，其中多个玩家选择手臂以最大化累积奖励。当两个或多个玩家选择相同的手臂时会发生碰撞，这意味着没有奖励，这些碰撞会被参与的玩家观察到。研究在没有中央协调的分布式环境中，每个玩家只能观察自己的行动和碰撞反馈。", "innovation": "提出了一个具有自适应、高效通信协议的分布式算法。该算法实现了接近最优的群体和个体后悔，通信成本仅为\textcal{O}(\text{log log} T)。实验表明，与现有基线相比，其性能有了显著提升。与最先进的（SOTA）方法相比，该方法显著减少了个体后悔。", "conclusion": "最后，将方法扩展到周期性异步设置，证明了此问题的下界，并提出了一种达到对数后悔的算法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06680", "html_url": "https://arxiv.org/abs/2510.06680", "title": "时间变换器：具备时间特性注意力调控的Transformer在时间序列预测中的应用", "title_en": "TimeFormer: Transformer with Attention Modulation Empowered by Temporal Characteristics for Time Series Forecasting", "authors": "Zhipeng Liu,Peibo Duan,Xuan Tang,Baixin Li,Yongsheng Huang,Mingyang Geng,Changsheng Zhang,Bin Zhang,Binwu Wang", "background": "尽管Transformer在自然语言处理领域表现优异，但将其扩展到时间序列预测中依然极具挑战性，原因在于对文本和时间序列模态之间差异考虑不足。", "innovation": "提出了一种名为TimeFormer的新颖Transformer架构，旨在最大化其表示能力。TimeFormer的创新点包括：(1) 在自注意力机制中引入两个调制项（MoSA），以捕捉时间序列的时序先验；(2) 通过多尺度和子序列分析框架，增强不同时间尺度下的语义依赖性。", "conclusion": "在多个真实世界数据集上的实验表明，TimeFormer显著优于现有最先进的方法，相比最佳基线方法将MSE降低了7.45％，并在94.04％的评估指标上建立了新的基准。此外，研究还展示了MoSA机制可以广泛应用于提升其他基于Transformer模型的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06672", "html_url": "https://arxiv.org/abs/2510.06672", "title": "XRPO：利用目标探索与利用增强GRPO的极限", "title_en": "XRPO: Pushing the limits of GRPO with Targeted Exploration and Exploitation", "authors": "Udbhav Bamba,Minghao Fang,Yifan Yu,Haizhong Zheng,Fan Lai", "background": "强化学习算法（如GRPO）推动了大型语言模型（LLM）推理的最新进展。尽管增加采样的数量能够稳定训练，但现有方法存在对具有挑战性的提示探索不足的问题，同时由于缺乏利用采样的信息反馈信号导致。当前的方法在采样分配上缺乏适应性（例如每个提示生成16个采样），且主要依赖稀疏奖励。", "innovation": "本文提出了XRPO（eXplore - eXploit GRPO），一种涵盖采样探索与利用的统一框架。其创新点在于：1) 引入了基于数学的动态采样分配器，优先选择具有更高不确定性减少潜力的提示；2) 通过内上下文种子策略，引入精挑细选的范例，引导模型进入更复杂的推理路径；3) 开发了一种基于小组相对的新颖性感知优势增强机制，利用序列似然性放大低概率但正确的响应，从而扩展策略在稀疏奖励之外的影响范围。", "conclusion": "XRPO在数学和编码基准测试中，无论是推理还是非推理模型，都优于现有方法（如GRPO和GSPO），在pass@1上提高了4%至6%的准确性，在cons@32上提高了6%。此外，该方法加快了训练收敛速度最多2.7倍。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06692", "html_url": "https://arxiv.org/abs/2510.06692", "title": "硬标签密码分析模型提取真是多项式时间吗？", "title_en": "Is the Hard-Label Cryptanalytic Model Extraction Really Polynomial?", "authors": "Akira Ito,Takayuki Miura,Yosuke Todo", "background": "深度神经网络（DNNs）因其内部模型成为有价值的知识产权而受到广泛关注。相关对抗性攻击中，已有研究通过黑盒访问提取DNN内部模型，类似于通过或acles访问块密码提取密钥。早期研究假设可访问确切的输出logits，而最近的研究假设攻击者仅能获得最终分类结果（即硬标签）。Carlini等人展示了即使在受限条件下，模型提取仍可能在多项式时间内完成。然而，随着攻击目标深度的增长，某些假设变得越来越不现实，实际操作要求的查询数随攻击深度呈指数增长。", "innovation": "本文提出的创新点是提出了一种新的攻击方法——跨层提取（CrossLayer Extraction），不同于直接从特定神经元提取秘密参数，该方法通过利用跨层神经元间的交互来提取信息，尤其在较深的层中进行。这显著降低了查询复杂度并缓解了现有模型提取方法的限制。", "conclusion": "研究表明，攻击假设在深度增加时变得不现实，实际操作中需要的查询数呈指数增长，因此攻击通常不总是多项式时间的。本文提出的新方法解决了这个问题，通过跨层神经元交互来降低提取信息的成本并减少查询复杂度。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06684", "html_url": "https://arxiv.org/abs/2510.06684", "title": "AutoBalance: 自动平衡框架用于训练物理惯知神经网络", "title_en": "AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks", "authors": "Kang An,Chenhao Si,Ming Yan,Shiqian Ma", "background": "物理惯知神经网络（PINNs）提供了一种强大的通用框架，通过将物理定律嵌入损失函数中来解决偏微分方程（PDEs）。然而，训练PINNs由于需要平衡多个损失项（如PDE残差和边界条件）之间的矛盾目标和差别很大的曲率，往往是困难的。现有的方法通过在优化前操纵梯度（一种'预组合'策略）来解决这个问题。但是，这种方法本质上受到限制，因为它强制一个优化器在同一具有不同频谱的损失景观中处理梯度，这会破坏其内部预训练条件。", "innovation": "提出了一个新的‘后组合’训练框架AutoBalance。AutoBalance为每个损失组件分配了独立的自适应优化器，并在这些更新后进行聚合。在具有挑战性的PDE基准测试中，实验结果表明，AutoBalance在均方误差（MSE）和$L^{\fty}$范数测量的解误差方面始终优于现有框架，提高了其他流行的PINN技术在苛刻基准上的效果。", "conclusion": "AutoBalance框架在解决PINNs训练过程中遇到的问题上表现出色，克服了现有方法的限制，提供了一种有效的解决方案，并且该方法与现有的PINN方法相辅相成，增强了其在复杂基准测试中的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06714", "html_url": "https://arxiv.org/abs/2510.06714", "title": "双目目标表示", "title_en": "Dual Goal Representations", "authors": "Seohong Park,Deepinder Mann,Sergey Levine", "background": "在目标导向的强化学习（GCRL）中，传统的目标表示方法通常依赖于原始状态表示。这种方法可能受到外部噪声的影响，且性能可能因不同状态表示的差异而波动。因此，研究一种新的、更加稳健的目标表示方法是必要的。", "innovation": "该研究引入了一种新的目标表示——双目目标表示。这种表示法以每个状态与其他所有状态之间的时态距离为主要特征，摆脱了原始状态表示的限制，同时提供了理论上充分且稳健的信息以恢复最佳的目标获取策略。此外，提出了一种实用的目标表示学习方法，可以与任何现有的GCRL算法结合使用，通过多种实验在不同的任务中验证了其性能提升效果。", "conclusion": "该方法展示了在目标导向的强化学习中的稳健性和优越性，通过多种任务在离线目标获取中的表现证明了双目目标表示的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06699", "html_url": "https://arxiv.org/abs/2510.06699", "title": "从不规则数据生成定期时间序列数据的扩散模型，包含完成与掩码", "title_en": "A Diffusion Model for Regular Time Series Generation from Irregular Data with Completion and Masking", "authors": "Gal Fadlon,Idan Arbiv,Nimrod Berman,Omri Azencot", "background": "生成现实的时间序列数据对于医疗保健、金融和科学应用至关重要。然而，不规则采样和缺失值带来了重大挑战。现有的方法虽然能够解决这些问题，但通常效果不佳且计算成本高。近期，基于扩散的ImagenTime模型通过将时间序列转换为图像表示来生成定期时间序列，展现了强大的生成能力，但直接应用于不规则序列时，简单的掩码方法会导致“不自然”的邻域，影响模型的学习过程。", "innovation": "本文提出了一种新颖的两步框架：首先，时间序列变换器完成不规则序列，创建自然的邻域；其次，基于视觉的扩散模型通过掩码减少了对完成值的依赖。这种方法结合了完成和掩码的优点，实现了现实时间序列的稳健且高效的生成。与之前的最优方法相比，该方法在鉴别评分上提高了70%，在计算成本上降低了85%。", "conclusion": "本文的方法在现实时间序列生成方面达到了最先进的性能，通过结合完成和掩码的技术，有效地解决了不规则序列生成的问题，提高了生成的质量和效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06660", "html_url": "https://arxiv.org/abs/2510.06660", "title": "重新思考Non线性：现代神经架构中的可训练高斯混合模块", "title_en": "Rethinking Nonlinearity: Trainable Gaussian Mixture Modules for Modern Neural Architectures", "authors": "Weiguo Lu,Gangnan Yuan,Hong-kun Zhang,Shangyang Li", "background": "神经网络，包括MLPs、CNNs和基于注意力的Transformers，在多个层中由线性组合和非线性操作（如ReLU、Sigmoid或Softmax）组成。尽管有效，但这些设计在引入非线性方面往往受限于激活函数的选择。现有的激活函数往往限制了神经网络的非线性能力，从而影响其性能。为此，本文提出了一种新颖的模块——高斯混合启发式非线性模块（GMNM），该模块利用了高斯混合模型（GMMs）和高斯核的距离属性（度量空间）。GMNM通过放松概率约束并采用灵活的高斯投影参数化，能够在多样的神经架构中无缝集成，并通过梯度法进行端到端训练。实验结果表明，将GMNM集成到MLPs、CNNs、注意力机制和LSTMs等架构中，可以显著提升模型性能，相较于标准基线，GMNM具有增强效率和准确性的作用，为广泛机器学习应用提供了强有力和灵活的模块解决方案。", "innovation": "本文提出的高斯混合启发式非线性模块（GMNM）是一种新型可训练模块，它结合了高斯混合模型（GMMs）和高斯核的距离属性（度量空间），通过放松概率约束和采用灵活的参数化，使得GMNM能够在多种神经网络架构中集成并进行端到端训练。这种新的非线性模块提供了一种增强非线性能力和灵活性的方法，可以显著提高机器学习模型的性能。", "conclusion": "实验结果表明，GMNM能够提高多种神经网络架构（如MLPs、CNNs、注意力机制和LSTMs）的性能。这表明GMNM作为一种强大的和灵活的模块，能够在不同类型的机器学习应用中提供显著的效率和准确性提升。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06735", "html_url": "https://arxiv.org/abs/2510.06735", "title": "将专家知识整合到混合有向无环图的贝叶斯因果发现中", "title_en": "Incorporating Expert Knowledge into Bayesian Causal Discovery of Mixtures of Directed Acyclic Graphs", "authors": "Zachris Björkman,Jorge Loría,Sophie Wharrie,Samuel Kaski", "background": "贝叶斯因果发现可以从领域专家中获取先验信息，并且在异质领域，任何先验知识都是必不可少的。然而，到目前为止，已有的先验信息提取方法都假设只有一个因果图，因此不适合异质领域的情况。本文通过基于贝叶斯实验设计原则提出了一种适合异质环境的因果提取策略，并利用扩展的差分贝叶斯结构学习方法构建了一个具有参照专家反馈的图先验，用于推断混合因果贝叶斯网络，最终展示了该方法在乳腺癌数据库中的应用，能够捕捉到复杂的分布特征", "innovation": "提出了适用于异质环境的因果提取策略，结合了贝叶斯实验设计原则和差分贝叶斯结构学习方法，提出了一种混合因果贝叶斯网络的结构学习方法，同时通过专家反馈构建了一个具有信息性的图先验，这种方法能够生成多种备选的因果模型并显示出在异质合成数据上的结构学习性能改进", "conclusion": "这种方法能够生成多种备选的因果模型，并通过模拟专家知识提高了异质合成数据上的结构学习性能，具备捕捉复杂分布的潜力"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06762", "html_url": "https://arxiv.org/abs/2510.06762", "title": "使用前前训练与推理范式的函数回归", "title_en": "Function regression using the forward forward training and inferring paradigm", "authors": "Shivam Padmani,Akshay Joshi", "background": "函数回归/逼近是机器学习中的一个基本应用。神经网络可以通过足够的神经元数量和迭代次数轻松训练进行函数回归。前前学习算法是一种无需反向传播的神经网络训练新颖方法，特别适合在类脑计算和神经网络的物理实现中实现。目前，前前范式仅限于分类任务。", "innovation": "该论文提出了一种新的方法，使用前前算法进行函数逼近（函数回归）。这种方法在单变量和多变量函数上进行了评估，并初步研究了将提出的前前回归扩展到科尔莫哥洛夫-阿诺德网络和深度物理神经网络。", "conclusion": "该研究为不可微分的拟合函数提供了一种解决方案，并通过前前学习算法展示了其在回归任务中的有效性和可行性。未来可以通过进一步的研究扩展其在不同类型神经网络中的应用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06776", "html_url": "https://arxiv.org/abs/2510.06776", "title": "使用物理知情神经网络建模德国各州的COVID-19动态", "title_en": "Modeling COVID-19 Dynamics in German States Using Physics-Informed Neural Networks", "authors": "Phillip Rothenbeck,Sai Karthikeya Vemuri,Niklas Penzel,Joachim Denzler", "background": "COVID-19大流行凸显了定量建模和分析在理解实际疾病动态中的重要性。特别是，使用人群模型的后验分析对评估公共卫生干预措施的有效性（如疫苗策略和遏制政策）提供了有价值的见解。然而，这些人群模型（如SIR模型）往往无法直接整合带有噪声的观察数据。", "innovation": "本工作采用物理知情神经网络（PINNs）解决SIR模型的逆问题，利用罗伯特·科赫研究所（RKI）的感染数据。研究的主要贡献是在德国所有联邦州进行精细的空间-时间分析，涵盖了三年的COVID-19动态。该研究估计了各州特定的传播和恢复参数以及时间变化的传染数（Rt），以追踪大流行的发展。结果表明了不同地区传播行为的显著差异，与接种疫苗率和大流行主要阶段的时间模式有关。", "conclusion": "本研究证明了PINNs在局部和长期流行病学建模中的应用价值。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06790", "html_url": "https://arxiv.org/abs/2510.06790", "title": "获取丰富性或灭亡：在鲁棒性方面用推理计算赢利性交易", "title_en": "Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness", "authors": "Tavish McDonald,Bo Lei,Stanislav Fort,Bhavya Kailkhura,Brian Bartoldson", "background": "尽管投入了大量计算资源来增强模型的鲁棒性，但在对抗性异分布(OOD)数据面前，模型仍然非常脆弱。尽管Zaremba等人在测试时取得了一定进展，通过使大型语言模型的推理改善了对抗性攻击下设计的模型规范的满足度，但这种好处会随着攻击者能够访问梯度或混合模态输入而消失。现有的防御主要集中在训练阶段，但本文指出，推理阶段的计算逻辑也有助于增强对抗性OOD数据的鲁棒性。", "innovation": "本文提出了一种新的假设——推理计算假设(RICH)，即通过将OOD数据的成分分解为其分布内(ID)部分，推理计算能在复杂的攻击场景下提高模型的鲁棒性。举例来说，对于通过对抗预训练增强的视觉语言模型来说，增加基于防御规范的提示可降低基于梯度的混合模态攻击的成功率，但在未增强的模型上则没有明显效果。RICH的概念解释了为什么更鲁棒的模型在面对OOD数据时能够更好地传递其构成部件，从而更好地适应和推理广泛的OOD数据。", "conclusion": "本文实证支持了RICH假设，表明推理计算可以在测试阶段提高模型的鲁棒性，特别是在防御性规范能够通过组合泛化解锁对OOD数据的说明时。我们建议在训练阶段和测试阶段都采用防御措施，以获得其协同效益。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06824", "html_url": "https://arxiv.org/abs/2510.06824", "title": "通过单个令牌数嵌入实现语言模型的高效数值运算", "title_en": "Efficient numeracy in language models through single-token number embeddings", "authors": "Linus Kreitner,Paul Hager,Jonathan Mengedoht,Georgios Kaissis,Daniel Rueckert,Martin J. Menten", "background": "科学与工程的进步要求大语言模型（LLMs）能够高效处理大量数值数据并解决长计算问题。目前，这主要依靠外部工具或复杂的推理链实现，限制了LLMs的数值直觉或限制了它们能够解决的问题长度。研究发现，最前沿的LLMs在解决基本计算时需要大量推理令牌，这与其将单个数字拆分为多个令牌的分词策略有关。因此，需要高效的单令牌数编码方法来优化这一过程。", "innovation": "提出了一种新的单令牌数编码策略BitTokens，使用IEEE 754二进制浮点数表示法嵌入任何数字。通过广泛的实验显示，使用BitTokens，即使是小的LLMs也能几乎完全地学习解决基础的算术运算，从而在效率上取得了显著进步，扩展了LLMs解决的问题长度和复杂性范围。", "conclusion": "通过高效的单令牌数嵌入，改善了LLMs在处理数值和计算任务上的能力，提高了模型的性能和应用范围。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06828", "html_url": "https://arxiv.org/abs/2510.06828", "title": "闭环完整框架动作模型", "title_en": "Recurrence-Complete Frame-based Action Models", "authors": "Michael Keiblinger", "background": "近年来，注意力机制在大型语言模型领域取得了巨大成功，极大地拓展了模型的可扩展性。'注意力是仅需的一切'一文声称，在注意力机制中无需使用递归神经网络（RNN）单元。本文对此观点提出质疑。作者指出现有的证明表明，具有完全并行前向或后向传递的架构无法表示某些长期运行的代理任务所需的复杂问题类别。作者进一步推测，存在一个临界时间点t，在此之后，非递归完整模型将无法正确聚合输入，这将对代理系统（例如软件工程代理）产生实际影响。", "innovation": "本文提出了一个闭环完整架构，并在GitHub派生的动作序列上进行了训练。训练序列长度的增长导致损失函数遵循幂律变化，而参数数量保持不变。此外，更长序列的训练时间减少了线性增加的实际运行时成本，从而在实际运行时成本函数上降低了损失。", "conclusion": "闭环完整架构通过在长期运行的代理任务中保持准确性，解决了非递归完整模型无法正确聚合输入的问题。通过在GitHub派生的动作序列上进行训练，展示了损失与实际运行时成本之间的关系，进一步验证了闭环完整架构的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06831", "html_url": "https://arxiv.org/abs/2510.06831", "title": "基于机器学习的早期风力发电机警报预测：警报预报", "title_en": "Early wind turbine alarm prediction based on machine learning: AlarmForecasting", "authors": "Syed Shazaib Shah,Daoliang Tan", "background": "风力发电机上的警报数据在控制故障行为方面至关重要，并且是先进预测监测系统的基础。传统研究主要将警报数据作为诊断工具，仅指示不健康状态。但本研究旨在通过预测警报来提前阻止警报的发生，从而防止故障的出现。", "innovation": "提出了一个基于机器学习的警报预报和分类（AFC）框架。该框架分为两个模块：首先是基于长短期记忆（LSTM）的时间序列警报预报模块，然后是警报标签实施模块。研究结果表明，对于10、20和30分钟的警报预测，准确率分别达到了82%、52%和41%，验证了预报和阻止警报的有效性。", "conclusion": "结果表明，通过预见和防止警报，可以显著减少警报频率并提高运营效率。这项研究对于提高风力发电机操作效率具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06819", "html_url": "https://arxiv.org/abs/2510.06819", "title": "随机表示在在线持续图学习中的惊人效果", "title_en": "The Unreasonable Effectiveness of Randomized Representations in Online Continual Graph Learning", "authors": "Giovanni Donghi,Daniele Zambon,Luca Pasa,Cesare Alippi,Nicolò Navarin", "background": "在线持续图学习（OCGL）中的一大挑战是灾难性遗忘。在节点按顺序到达的场景中，数据分布可能会在任何时候发生变化，而在特定子图上进行离线训练是不可行的。本文探讨了在线持续图学习的简单而有效的解决方案：使用固定的、随机初始化的编码器生成稳健且表达力强的节点嵌入，只在线上训练一个轻量级的分类器。通过冻结编码器，消除表示参数漂移这一灾难性遗忘的关键来源，从而获得既表达力强又稳定的嵌入。在多个OCGL基准测试中，尽管其简单且没有记忆缓冲，该方法仍能一致地优于现有方法，表现出高达30%的显著改进，性能往往接近仅联合离线训练的上限。这表明在在线持续图学习场景中，通过拥抱架构的简朴性和稳定性，可以最小化灾难性遗忘，而无需复杂的数据回放或正则化机制。", "innovation": "提出了一种简单而有效的在线持续图学习方法，通过使用固定且随机初始化的编码器生成稳健和表达性强的节点嵌入，而不必在线存储历史数据或进行复杂的正则化。这种方法通过冻结编码器参数，避免了由于参数漂移导致的遗忘问题，从而提高了模型的稳定性和表达力，展示了在线持续图学习中的惊人效果。", "conclusion": "本文提出的方法在多个OCGL基准测试中表现出色，不仅优于现有方法，而且在某些情况下达到了联合离线训练的上界性能。这表明，在线持续图学习可以通过简单且稳定的架构设计来减少灾难性遗忘，而非依赖于复杂的数据维持或正则化策略。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06840", "html_url": "https://arxiv.org/abs/2510.06840", "title": "基于多头注意权重的SHAP解释的CNN-TFT时间序列预测", "title_en": "CNN-TFT explained by SHAP with multi-head attention weights for time series forecasting", "authors": "Stefano F. Stefenon,João P. Matos-Carvalho,Valderi R. Q. Leithardt,Kin-Choong Yow", "background": "卷积神经网络（CNNs）和变压器架构在处理时序数据方面具有优势：CNNs擅长捕捉局部模式和移变不变性，而变压器则通过自我注意力有效建模长依赖关系。本文提出了一种结合卷积特征提取和变压器主干结构（TFT）的混合架构，以增强多变量时间序列预测。", "innovation": "本文提出了一种新型混合架构——CNN-TFT-SHAP-MHAW，它结合了CNN卷积特征提取和TFT多头注意力机制，并通过SHAP解释算法增强了模型的可解释性。实验结果表明，该模型在水电自然流量时间序列数据集上表现优异，均绝对百分比误差最高可达2.2%，优于现有深度学习模型。", "conclusion": "该混合架构CNN-TFT-SHAP-MHAW为需要高保真度多变量时间序列预测的应用提供了可能性，并已提供以便用于未来分析。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06834", "html_url": "https://arxiv.org/abs/2510.06834", "title": "RISC-V向量处理器中低成本指数计算的Vectorized FlashAttention", "title_en": "Vectorized FlashAttention with Low-cost Exponential Computation in RISC-V Vector Processors", "authors": "Vasileios Titopoulos,Kosmas Alexandridis,Giorgos Dimitrakopoulos", "background": "注意力机制是许多机器学习和人工智能模型的核心运算。这项研究关注于使用FlashAttention算法加速注意力核，在向量处理器中，特别是在基于RISC-V指令集架构（ISA）的处理器中。这是首次尝试向量化FlashAttention，减少了标量代码的使用，并简化了softmax所需的指数运算的计算复杂度。通过利用浮点运算中低成本的指数近似，研究人员减少了计算指数函数的成本，而无需扩展基本向量ISA以加入新的自定义指令。此外，研究人员还探索了适当的小块分割策略，以提高内存局部性，从而提高性能。实验结果表明，这种方法在处理实际应用中的注意力层时，具有显著的性能优势和可扩展性。", "innovation": "1. 首次将FlashAttention向量化，减少了标量代码的使用，并简化了指数运算的计算复杂度。\n2. 利用低成本的指数近似在浮点运算中来减少计算成本，而不需加入新的自定义指令。\n3. 探索了适当的小块分割策略以提高内存局部性，从而优化性能。", "conclusion": "实验结果展示了该方法在实际应用中的可扩展性和显著性能提升，通过向量化实现的FlashAttention方法在处理注意力层时表现出色。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06852", "html_url": "https://arxiv.org/abs/2510.06852", "title": "通过高级机器学习技术增强银行破产预测：一种创新方法和分析", "title_en": "Enhancing Bankruptcy Prediction of Banks through Advanced Machine Learning Techniques: An Innovative Approach and Analysis", "authors": "Zuherman Rustam,Sri Hartini,Sardar M.N. Islam,Fevi Novkaniza,Fiftitah R. Aszhari,Muhammad Rifqi", "background": "金融系统的稳定取决于银行系统的状况。银行系统中的一次银行倒闭可能会破坏整个金融系统的稳定，因为银行面临系统性风险，不仅影响单一银行，也可能影响某一部门或整个金融系统。计算银行破产的可能性是确保银行系统稳健的一种方式。现有的文献和限制表明，统计模型（如Altman的Z-Score）是开发破产预测模型的常用技术。然而，统计方法依赖于一些僵硬且有时不相关的假设，这可能导致较低的预测准确性。因此，需要新的方法。", "innovation": "研究采用了机器学习技术（如逻辑回归、随机森林和支持向量机）来开发破产模型。该研究发现，机器学习在分类和预测银行风险管理方面比统计方法更准确有效，因此提出了一种创新的基于机器学习的方法来预测银行破产。", "conclusion": "研究采用的创新机器学习方法有助于实施减少破产成本的政策。"}
{"llm_update_time": "20251009", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17693", "html_url": "https://arxiv.org/abs/2504.17693", "title": "基于BIM的准确定位与偏差校正优化方法在施工监控中的应用", "title_en": "BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring", "authors": "Asier Bikandi-Noya,Muhammad Shaheer,Hriday Bavle,Jayan Jevanesan,Holger Voos,Jose Luis Sanchez-Lopez", "background": "建筑工地的实时环境跟踪在AR应用中依赖于现场环境的实时跟踪来可视化建筑元素。然而，由于特征贫乏的表面、动态变化和累积漂移，传统的跟踪方法面临显著挑战，导致数字模型与物理世界之间的对齐不准确。", "innovation": "该文提出了一种基于BIM的漂移校正方法，以解决上述挑战。方法不依赖于基于SLAM的定位，而是将“建成”环境中检测到的平面与“计划”中的建筑平面进行对齐，并利用优化技术计算SLAM和BIM参照系之间的变换，从而减少长时间内的漂移。通过整合BIM作为先验结构知识，可以在噪声较大的施工环境中实现长期定位的改进和增强的AR可视化精度。", "conclusion": "通过真实世界实验，该方法显示出在漂移引起的误差方面有显著降低，并优化了对齐一致性。平均而言，与用户初始手动对齐相比，该系统在角度偏差上减少了52.24%，在匹配墙体的距离误差上减少了60.8%。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06860", "html_url": "https://arxiv.org/abs/2510.06860", "title": "为AC最优潮流推广图神经网络", "title_en": "Towards Generalization of Graph Neural Networks for AC Optimal Power Flow", "authors": "Olayiwola Arowolo,Jochen L. Cremer", "background": "对于大规模电力系统，AC最优潮流（ACOPF）计算非常昂贵，传统求解器需要耗时的解决时间。机器学习方法能够提供计算上的加速，但在不进行昂贵的重新训练的情况下，难以实现规模扩展和拓扑变换适应性。", "innovation": "提出了一种混合异构消息传递神经网络（HH-MPNN），将母线、发电机、负载、调相机、输电线路和变压器建模为不同的节点或边类型，并结合可扩展的转换器模型以处理长距离依赖。HH-MPNN在14到2,000个节点的电网中实现了低于1%的最优性缺口，并在未见过的拓扑结构上展示了零样本学习，即使只在默认拓扑结构上进行训练也能实现低于3%的最优性缺口。预训练在较小的电网中也能提高在较大电网中的结果。相比内点求解器，计算加速达到1,000到10,000倍。", "conclusion": "这些结果推进了实用且可推广的机器学习方法在实时电力系统操作中的应用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06567", "html_url": "https://arxiv.org/abs/2510.06567", "title": "The Framework That Survives Bad Models: Human-AI Collaboration For Clinical Trials", "title_en": "The Framework That Survives Bad Models: Human-AI Collaboration For Clinical Trials", "authors": "Yao Chen,David Ohlssen,Aimee Readie,Gregory Ligozio,Ruvie Martin,Thibaud Coroller", "background": "人工智能（AI）在支持临床试验方面具有巨大潜力，从患者招募、终点评估到治疗响应预测。然而，如果在没有保护措施的情况下部署AI，则会带来重大风险，特别是在评估可能直接影响试验结论的患者终点时。这项研究通过比较两种AI框架与仅由人类进行的评估，针对基于医学影像的疾病评价进行了比较，重点评估了成本、准确性、鲁棒性和泛化能力。研究通过注入不同质量的模型（从随机猜测到简单预测）来测试这些框架，确保即使在模型严重降级的情况下，观察到的治疗效果仍然有效。", "innovation": "研究通过两个随机对照试验评估了两种框架，使用脊柱X光图像作为终点。研究发现，使用AI作为辅助阅片人（AI-SR）的框架最适用于临床试验，即使在使用质量不高的模型时，仍然能够提供可靠的疾病估计，并保持临床试验的治疗效果估计和结论的准确性，同时在应用于不同人群时也保留这些优势。", "conclusion": "使用AI作为支持阅片人的框架对于临床试验是最合适的，尤其是在面对不良模型时也能保证治疗效果的准确性和可靠性。这种方法能够在不同的临床试验和人群中保持其优势。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06871", "html_url": "https://arxiv.org/abs/2510.06871", "title": "SaFeR-VLM：迈向多模态模型中的细粒度安全感知推理", "title_en": "SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models", "authors": "Huahui Yi,Kun Wang,Qiankun Li,Miao Yu,Liang Lin,Gongli Xi,Hao Wu,Xuming Hu,Kang Li,Yang Liu", "background": "现有的多模态大推理模型在跨模态推理方面表现出色，但在面对对抗性或不安全的提示时，往往放大了安全风险。我们称这一现象为‘推理税’。目前的防御措施主要在输出层面，无法限制推理过程中的风险。", "innovation": "本文提出了SaFeR-VLM，这是一种安全对齐的强化学习框架，能够直接将安全嵌入到多模态推理中。该框架包括四个组件：(I) QI-Safe-10K，一个专注于安全关键和推理敏感的案例的数据集；(II) 安全感知展开，其中不安全的生成通过反思和修改而非直接丢弃；(III) 结构化的奖励建模，包括多维度加权标准和对虚构和矛盾的明确惩罚；(IV) GRPO优化，提升安全和修正轨迹的强化。这种统一体设计从被动的保护转变为推理的主动驱动，使安全推理更具扩展性和可推广性。", "conclusion": "SaFeR-VLM在六个基准测试中的平均安全性能和有用性能分别为70.13和78.97，超过了同一规模和大于10倍更大规模的模型。SaeFer-VLM-7B通过增加模型规模在安全性措施上分别提升了GPT-5-mini和Gemini-2.5-Flash 6.47和16.76点，同时保持了有用性性能的提升。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06913", "html_url": "https://arxiv.org/abs/2510.06913", "title": "DecompGAIL: 使用分解的多智能体生成对抗模拟学习学习现实交通行为", "title_en": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning", "authors": "Ke Guo,Haochen Liu,Xiaojun Wu,Chen Lv", "background": "现实的交通模拟对于自动驾驶系统的开发和城市交通规划至关重要，但现有的模仿学习方法通常无法模拟现实的交通行为。行为克隆方法会受到条件转移的影响，而生成对抗模仿学习（GAIL）在多智能体环境中经常不稳定。", "innovation": "该方法识别了这种不稳定性的一个关键来源：无关互动误导，即判别器因邻近车辆的不现实互动而惩罚自我车辆的现实行为。为了应对这一问题，作者提出了一种分解的多智能体GAIL（DecompGAIL），它明确地将现实性分解为自我地图和自我邻近成分，过滤掉误导性的邻近车辆：邻近车辆和邻近车辆：地图的交互。此外，引入了社会PPO目标，通过距离加权的邻近奖励来增强自我奖励，鼓励全局现实性。", "conclusion": "将DecompGAIL集成到一个轻量级的SMART基础架构中，在WOMD Sim Agents 2025基准测试中实现了最先进的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06910", "html_url": "https://arxiv.org/abs/2510.06910", "title": "Vacuum Spiker: 一种基于脉冲神经网络的时间序列高效异常检测模型", "title_en": "Vacuum Spiker: A Spiking Neural Network-Based Model for Efficient Anomaly Detection in Time Series", "authors": "Iago Xabier Vázquez,Javier Sedano,Muhammad Afzal,Ángel Miguel García-Vico", "background": "异常检测在工业、医疗保健和网络安全等领域是关键任务。许多实际的异常检测问题涉及时间序列中多个特征的分析，因此时间序列分析是解决这些问题的自然方法。尽管深度学习模型在该领域取得了优异的性能，但它们高的能效消耗限制了它们在资源受限的环境中（如物联网设备、边缘计算平台和可穿戴设备）的应用。", "innovation": "该论文提出了\textit{Vacuum Spiker算法}，一种基于脉冲神经网络的新型时间序列异常检测方法。该方法引入了一个新的检测标准，依赖于神经活动的全局变化，而不是重建或预测误差。通过使用一种新的突触可塑性（Spike-Time-Dependent Plasticity）训练方式来诱导在异常发生时神经活动的改变。还提出了一种新的高效编码方案，将输入空间离散化为不重叠的区间，每个区间指派给一个单独的神经元，这一策略在每个时间步上使用一个脉冲来编码信息，相比于传统的编码方法提高了能效。", "conclusion": "在公开数据集上的实验结果显示，该算法在与大量深度学习和机器学习基线相比时，达到了相当的性能同时显著降低了能效消耗。此外，通过在实际案例研究中的验证，模型成功识别了太阳能逆变器中的功率削减事件，进一步证明了其在可持续和高效异常检测中的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06940", "html_url": "https://arxiv.org/abs/2510.06940", "title": "重访 Temporal 图中的节点亲密度预测", "title_en": "Revisiting Node Affinity Prediction in Temporal Graphs", "authors": "Krishna Sri Ipsit Mantri,Or Feldman,Moshe Eliasof,Chaim Baskin", "background": "节点亲密度预测是一个常见任务，在社会和金融网络、推荐系统等的时态图学习中广泛使用。近期的研究通过将最新的动态链接属性预测模型适应节点亲密度预测任务。然而，简单的启发式方法，如持久预测或移动平均，往往优于这些模型。当前时态图神经网络在训练节点亲密度预测任务时面临挑战。", "innovation": "本文分析了当前时态图神经网络在节点亲密度预测中的训练挑战，并提出了解决方案。结合这些解决方案，开发了基于虚拟状态的节点亲密度预测模型 NAViS，通过将启发式与状态空间模型的等效性进行利用。此外，为了训练 NAViS，引入了一个新的损失函数。在 TGB 上的评估表明，该模型优于现有的最先进的方法，包括启发式方法。", "conclusion": "我们提出了利用虚拟状态的节点亲密度预测模型 NAViS，并引入了一个新的损失函数，该模型在 TGB 数据集上优于最先进的节点亲密度预测方法，包括简单的启发式方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06880", "html_url": "https://arxiv.org/abs/2510.06880", "title": "MoRE-GNN：使用非同质图自编码器的多组学数据集成", "title_en": "MoRE-GNN: Multi-omics Data Integration with a Heterogeneous Graph Autoencoder", "authors": "Zhiyu Wang,Sonia Koszut,Pietro Liò,Francesco Ceccarelli", "background": "多组学单细胞数据的综合受到高维性和复杂跨模态关系的挑战。现有的方法难以有效处理这些问题，特别是在强跨模态关联的场景下表现不佳。", "innovation": "MoRE-GNN 算法通过结合图卷积和注意力机制，直接从数据中动态构建关系图，形成一种异质图自编码器。与现有方法相比，它能够更好地捕捉生物意义的关系，尤其在强跨模态关联的场景下表现更优。此外，MoRE-GNN 学习到的表示还支持下游模态间的准确预测。尽管性能可能随数据集复杂度的不同而有所变化，但 MoRE-GNN 提供了一个适应性强、可扩展且可解释的框架，以促进多组学集成的发展。", "conclusion": "实验结果表明，MoRE-GNN 的性能优于现有方法，并且提供的表示学习支持跨模态预测。该模型为多组学集成提供了新的途径。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06907", "html_url": "https://arxiv.org/abs/2510.06907", "title": "SpherePair损失函数的约束条件嵌入法在约束聚类中的应用", "title_en": "Angular Constraint Embedding via SpherePair Loss for Constrained Clustering", "authors": "Shaojie Zhang,Ke Chen", "background": "现有的深度约束聚类方法存在局限性，无论是基于端到端建模的锚点限制，还是难以学习区分性的欧几里得嵌入。这些限制限制了方法的可扩展性和现实世界的适用性。", "innovation": "提出了一种新颖的角度约束嵌入方法SpherePair，通过几何形式的SpherePair损失，该方法忠实编码了成对约束，使得嵌入在角度空间中更具聚类友好性，有效地将表示学习与聚类分离。SpherePair在保持成对关系方面没有冲突，无需指定确切的聚类数量，能够处理未见过的数据，快速确定聚类数量，并具有严谨的理论保证。", "conclusion": "SpherePair方法在多种基准数据集和实际效果上优于现有的深度约束聚类方法，验证了其优异的性能、可扩展性和总体现实世界的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06945", "html_url": "https://arxiv.org/abs/2510.06945", "title": "Fisher信息、训练与Fourier回归模型的偏差", "title_en": "Fisher Information, Training and Bias in Fourier Regression Models", "authors": "Lorenzo Pastori,Veronika Eyring,Mierk Schwabe", "background": "受量子机器学习，尤其是量子神经网络（QNNs）日益增长的兴趣的启发，本研究探讨了基于Fisher信息矩阵（FIM）的最近引入的评估指标的有效性，用以预测QNNs的训练和预测性能。", "innovation": "本研究首先利用Fourier模型与广泛类别的QNNs之间的等价性，研究了模型的有效维度和针对特定任务的偏差如何影响模型的训练和性能。其次，通过推导Fourier模型的FIM的解析表达式并识别控制模型有效维度的特征，提出了模型的有效维度和偏差可调的概念，最终引出了Tensor网络表示法，这在分析QNN模型方面可能是一个独立感兴趣的工具。", "conclusion": "研究结果表明，对于完全忽视要学习的函数的模型，有效维度较高可能使模型具有更好的可训练性和性能。而对于针对要学习的函数有偏向的模型，则较低的有效维度可能有助于在训练过程中表现更好。这些发现为几何特性、模型-任务对齐以及训练之间的相互作用提供了一个明确的示例，这些都对更广泛的机器学习社区具有重要性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06912", "html_url": "https://arxiv.org/abs/2510.06912", "title": "利用大型语言模型提高机器学习可解释性", "title_en": "Utilizing Large Language Models for Machine Learning Explainability", "authors": "Alexandros Vassiliades,Nikolaos Polatidis,Stamatios Samaras,Sotiris Diplaris,Ignacio Cabrera Martin,Yannis Manolopoulos,Stefanos Vrochidis,Ioannis Kompatsiaris", "background": "本文探讨了在自主生成机器学习（ML）解决方案时，大型语言模型（LLMs）的可解释能力。具体而言，研究通过比较两个分类任务来检验LLMs的能力：一个是二分类任务，用于预测司机警觉状态；另一个是基于酵母数据集的多标签分类任务。三个最先进的LLMs（OpenAI GPT、Anthropic Claude和DeepSeek）被用来设计针对四种常用分类器（随机森林、XGBoost、多层感知机和长短时记忆网络）的训练管道。所生成的模型被评估了预测性能（召回率、精确率和F1分数）和可解释性（使用SHAP进行评估）。", "innovation": "该研究创新之处在于利用最新的LLMs来自主生成ML解决方案，并以SHAP为工具评估其可解释性。研究揭示了LLMs能生成高效且可解释的模型，达到高度准确性和一致性稀疏性，突显了其在生成可解释ML管道方面的自动工具潜力。研究表明LLMs能生成效果好、可解释性强的管道，与人工设计的基准相当甚至相近。", "conclusion": "LLMs能够生成高效且可解释的ML模型，表现出高保真度和一致性稀疏性，具有作为可解释ML管道自动化生成工具的潜力，匹配甚至超越人工设计的基准模型。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06987", "html_url": "https://arxiv.org/abs/2510.06987", "title": "螺旋模型技术在数据科学与机器学习生命周期中的应用", "title_en": "Spiral Model Technique For Data Science & Machine Learning Lifecycle", "authors": "Rohith Mahadevan", "background": "数据分析在现代商业中扮演着重要的角色，公司根据其文化调整数据科学生命周期以提高效率和竞争力。数据科学和机器学习生命周期包括一系列项目涉及的步骤，通常被描绘为线性或循环模型，允许在生命周期结束时重新开始过程。", "innovation": "文章提出了一种新的技术，即螺旋技术，用于解决具有明确结束目标的商业问题。这种方法强调灵活性、敏捷性和迭代方法，旨在更好地结合数据科学生命周期与商业过程的多样性。", "conclusion": "这篇文章提出了一种新的数据科学和机器学习生命周期的螺旋技术，通过增强商业过程的柔性和迭代性，解决了具有明确结束目标的业务问题。螺旋技术为数据依赖型项目提供了一种新的处理方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06982", "html_url": "https://arxiv.org/abs/2510.06982", "title": "重新审视Mixout：一条被忽视的鲁棒微调途径", "title_en": "Revisiting Mixout: An Overlooked Path to Robust Finetuning", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Eric Granger,Marco Pedersoli", "background": "微调视觉基础模型通常能在领域内提高准确性，但会牺牲在数据分布变化下的鲁棒性。本文通过单一运行、权重共享的隐式ensemble视角重新审视了Mixout，指出其对鲁棒性有关键影响的因素包括遮罩锚点、重采样频率和掩码稀疏性。", "innovation": "提出了GMixout，它(1)通过训练期间动态适应的指数移动平均快照替换固定的遮罩锚点；(2)通过显式重采样频率超参数调节掩码周期。此外，GMixout采用稀疏核实现，仅更新一小部分参数，无推理时间开销，可以在消费级GPU上进行训练。GMixout在覆盖协变量变化、损坏和类别不平衡等不同挑战的标准测试集上都实现了超越零样本性能的领域内准确性，并在数据分布变化时优于Model Soups和强参数高效微调基线。", "conclusion": "GMixout一致地在领域内提高了准确性，尤其是在数据分布变化时，它超越了Model Soups和强参数高效微调基线。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07022", "html_url": "https://arxiv.org/abs/2510.07022", "title": "野外观测联邦卸载：重思公平性和数据异质性", "title_en": "Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy", "authors": "ZiHeng Huang,Di Wu,Jun Bai,Jiale Zhang,Sicong Cao,Ji Zhang,Yingjie Hu", "background": "联邦卸载是确保“被遗忘的权利”等数据删除权利的关键，但在联邦学习的去中心化框架中实施卸载时，面临着两个主要挑战：一是联邦卸载中的公平性常常被忽视；二是大多数的联邦卸载评估依赖于对合成数据（ICD/NON-ICD）的假设，忽略了现实世界中的异质性。这些现实中的挑战使得现有方法的真实效用和影响难以明确评估。", "innovation": "论文提出了一个公平感知的联邦卸载的新方法——Federated Cross-Client-Constrains Unlearning (FedCCCU)，该方法旨在同时解决公平性和数据异质性的挑战，提供了在现实世界中进行联邦卸载的实用且可扩展的解决方案。", "conclusion": "实验结果表明，现有的方法在现实设置下表现不佳，而该论文提出的方法始终优于现有的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06949", "html_url": "https://arxiv.org/abs/2510.06949", "title": "分组差异性注意力", "title_en": "Grouped Differential Attention", "authors": "Junghwan Lim,Sungmin Lee,Dongseok Kim,Wai Ting Cheung,Beomgyu Kim,Taehwan Kim,Haesol Lee,Junhyeok Lee,Dongpin Oh,Eunhwan Park", "background": "虽然自我注意力机制是现代Transformer架构的基础，但它存在一个关键的效率问题：它经常对冗余或嘈杂的上下文分配大量注意力。为了解决这个问题，Differential Attention引入了减法注意力图来区分信号和噪声，但其需要平衡的头部分配使代表灵活性和扩展性受到严格的限制。为克服这个问题，我们提出了一种新的方法——分组差异性注意力（GDA），这种方法在信号保持组和噪声控制组之间引入了不平衡的头部分配。GDA通过战略性地将更多头部分配给信号提取，而减少噪声控制头部的数量，从而增强信号聚焦，并通过受控重复稳定后者（类似于GQA）。这种方法以最小的计算开销实现了更好的信号保真度。我们进一步将这一原则扩展到组差异化增长，这是一种可扩展的策略，仅选择性地复制信号集中焦点的头部，从而确保高效的容量扩展。通过大规模预训练和持续训练实验，我们展示了与对称基线相比，GDA在泛化能力和稳定性方面的显著改进。我们的结果共同证明了比率感知的头部分配和选择性扩展是设计可扩展、计算经济的Transformer架构的有效且实用的道路。", "innovation": "GDA通过在信号保持组和噪声控制组之间引入不平衡的头部分配，解决了传统差分注意力平衡头部分配导致的灵活性和可扩展性限制问题。此外，GDA通过受控重复稳定噪声控制组，并仅选择性地复制信号集中焦点的头部，实现了容量的高效扩展。我们通过大规模的预训练和持续训练实验，验证了GDA在泛化能力和稳定性方面的显著提升，从而证明了比率感知的头部分配和选择性扩展的有效性和实用性。", "conclusion": "我们的研究结果表明，比率感知的头部分配和选择性扩展为设计可扩展且计算高效的Transformer架构提供了一种有效且实用的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06954", "html_url": "https://arxiv.org/abs/2510.06954", "title": "从凝聚到秩坍缩：Transformer训练动力学的两阶段分析", "title_en": "From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics", "authors": "Zheng-An Chen,Tao Luo", "background": "尽管基于变压器的模型在实验性能上表现出色，但它们的训练动力学背后的原理尚未得到充分描述，多数研究仅限于特定配置的研究。已有实验证据表明，在小参数初始化规模下，语言模型的推理能力有所提高。研究者借鉴了[周等人，NeurIPS 2022]中的梯度流分析框架，系统研究了线性化变压器的训练动力学。研究发现，注意模块的动力学可以分为两个阶段：在第一阶段，从随机初始化产生的不对称权重扰动维持非退化的梯度动力学，并促进从小初始化区域的系统逃逸。随后，这些矩阵凝缩并逐渐对齐到目标方向。在第二阶段，先前静态的关键-查询矩阵开始参与训练，推动规范化矩阵向秩坍缩的渐近状态转移。这一两阶段框架扩展了经典的方向收敛结果。", "innovation": "研究者运用梯度流分析框架对线性化变压器训练动力学进行了系统的两阶段分析，发现了注意模块动力学的两个关键阶段，并解释了小初始化规模下合理化推理能力的提升机制。这种方法不仅推广了经典的方向收敛结果，还对理解和改进变压器模型的训练提供了新洞见。", "conclusion": "研究提出了一种两阶段的分析框架来阐明变压器训练动力学，即从凝聚到秩坍缩的过程。这一发现对于理解小规模初始化如何提高语言模型的推理能力具有重要意义，同时为优化变压器模型的训练提供了参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07018", "html_url": "https://arxiv.org/abs/2510.07018", "title": "Sharpness-Aware Data Generation for Zero-shot Quantization", "title_en": "Sharpness-Aware Data Generation for Zero-shot Quantization", "authors": "Dung Hoang-Anh,Cuong Pham Trung Le,Jianfei Cai,Thanh-Toan Do", "background": "零样本量化旨在通过预训练的高精度模型来学习量化模型，而不使用原始真实训练数据。在零样本量化方法的主流做法中，通常会生成合成数据以对高精度模型进行量化。然而，之前的研究并未考虑量化模型的锐化度作为生成训练数据的标准。众所周知，具有低锐化度的深度神经网络具有更好的泛化能力。", "innovation": "本文介绍了一种新方法，通过考虑量化模型的锐化度来增强合成数据生成，从而提升泛化能力。具体而言，首先展示通过在合成数据和真实验证数据之间最大化梯度匹配，可以实现锐化度最小化。其次，通过计算每个生成样本与其邻居之间的梯度匹配来解决没有真实验证集的问题。实验证实在CIFAR-100和ImageNet数据集上的测试表明，提出的方法比现有的最先进的低位量化技术更具优势。", "conclusion": "实验评估表明，提出的采用锐化度意识数据生成方法在低位量化设置中优于最先进的技术。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06627", "html_url": "https://arxiv.org/abs/2510.06627", "title": "POME: Post Optimization Model Edit via Muon-style Projection", "title_en": "POME: Post Optimization Model Edit via Muon-style Projection", "authors": "Yong Liu,Di Fu,Yang Luo,Zirui Zhu,Minhao Cheng,Cho-Jui Hsieh,Yang You", "background": "该研究介绍了一种新的算法Post-Optimization Model Edit (POME)，旨在通过仅使用大型语言模型的预训练和微调检查点增强其性能，而不需要额外的数据或进一步的优化。这种方法的核心思想是应用类似μ子的投影到ΔW（即微调和预训练权重之间的差异）上。投影使用截断的奇异值分解（SVD）来使主要更新方向的影响相等，并剪除小的奇异值，这些小的奇异值通常代表噪声。POME 是一种简单的后处理步骤，完全不依赖于训练管道，不需要任何修改，也不会增加额外开销，因此它可以适用于任何优化器或分布式框架。", "innovation": "该研究提出的创新点在于，通过一种类似于Mu子的方法，对微调和预训练权重之间的差异进行截断奇异值分解，并投影到这个差异上，从而增强大型语言模型的性能。这种方法的优势在于操作简单、不依赖训练管道，对任何优化器或分布式框架都兼容，且能提供一致性提升。", "conclusion": "POME 能够在多种不同规模的模型上（从 7B 到 72B）实现一致的性能提升，最大提升幅度分别为 GSM8K 上的 2.5% 和代码生成上的 1.0%。这表明它是一种具有实际应用价值的零成本增强技术，可以广泛应用于任何微调管道中。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06955", "html_url": "https://arxiv.org/abs/2510.06955", "title": "高比率Mixout：重新审视Mixout以实现稳健的域泛化", "title_en": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization", "authors": "Masih Aminbeidokhti,Heitor Rapela Medeiros,Eric Granger,Marco Pedersoli", "background": "在存在分布偏移的情况下，通过使用来自强大预训练权重的细调模型集合来增强鲁棒性是一种常用策略，但这一策略伴随着显著的计算成本，因为需要训练和存储多个模型。Dropout虽然提供了一种轻量级的替代方法，通过随机去激活神经元模拟模型集合，但在应用到预训练模型时，容易过度正则化，破坏了对于泛化至关重要的先前知识。本文探讨了Mixout，这是一种新颖的随机正则化技术，它为域泛化提供了一种替代Dropout的方法。Mixout通过在训练过程中，用预训练权重替换部分微调权重的随机子集来减轻过拟合，从而在适应和保留先验知识之间保持平衡。研究发现，要在域泛化基准测试中取得优异表现，对于ViTs，高比率Masking概率为0.9，而对于ResNets，高比率Masking概率为0.8。这种看似简单的调整带来了两个关键优势：（1）更高的掩码率更加严厉地惩罚与预训练参数的偏差，促进更好的未知域泛化；（2）较高的掩码率显著降低了计算开销，将梯度计算减少了多达45%，梯度内存使用减少了高达90%。", "innovation": "提出了Mixout作为一种新颖的随机正则化技术，通过在训练过程中用预训练权重替换部分微调权重的随机子集来减轻过拟合。与传统的Dropout相比，Mixout在保持模型对先验知识保留的同时减少了过拟合的风险，减少了计算成本。研究表明，高比率的Mixout在五个域泛化基准测试中表现出色，与基于集合的方法相比，显著降低了训练成本。", "conclusion": "高比率的Mixout在五个域泛化基准测试中达到了与基于集合的方法相当的出门外域准确性，同时显著降低了训练成本。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07043", "html_url": "https://arxiv.org/abs/2510.07043", "title": "COMPASS: 多轮次基准测试及工具中介规划与偏好的优化", "title_en": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "authors": "Tian Qin,Felix Bai,Ting-Yao Hu,Raviteja Vemulapalli,Hema Swetha Koppula,Zhiyang Xu,Bowen Jin,Mert Cemri,Jiarui Lu,Zirui Wang,Meng Cao", "background": "现实世界中的大型语言模型（LLM）代理需要通过多轮交互来掌握策略性工具使用和用户偏好优化的能力，以帮助用户完成复杂规划任务。研究者们提出了一个名为COMPASS的基准测试，旨在评估代理在真实的旅行规划场景中的表现。", "innovation": "该研究将旅行规划问题转化为包含硬约束和软偏好优化的约束优化问题，并构建了一个涵盖美国20个国家级公园交通、住宿和票务的现实数据库。此外，还开发了一个模拟商业预订平台的工具生态系统。研究揭示了两个关键的差距：一是满足约束与优化偏好之间的差距；二是多服务协调问题上的性能衰减，特别是开源模型。", "conclusion": "COMPASS通过将推理和规划与用户实际面临的应用领域相结合，提供了一个直接衡量代理在现实任务中优化用户偏好的基准测试，从而将理论进展与现实世界的应用相连接。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07035", "html_url": "https://arxiv.org/abs/2510.07035", "title": "统一的灵活2D和3D模态分子预训练: 单模态和配对模态集成", "title_en": "Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration", "authors": "Tengwei Song,Min Wu,Yuan Fang", "background": "分子表征学习在药物发现和材料设计等领域发挥着关键作用。现有的工作利用了2D和3D分子信息的模态进行预训练，以捕捉全面的结构和几何洞察。然而，这些方法需要配对的2D和3D分子数据来进行有效的训练，防止模型偏向单一模态。但在某些模态不可用或生成计算成本高昂的情况下，这种限制会成为障碍。", "innovation": "本文提出了一种名为FlexMol的灵活分子预训练框架，该框架可以在支持单模态输入的同时学习统一的分子表示。FlexMol借鉴了视觉语言模型中的统一结构，通过分别使用2D和3D分子数据模型，利用参数共享提高计算效率，并利用解码器为缺失的模态生成特征，从而在训练过程中实现双重贡献的多层次连续学习过程。此外，本文还证明了FlexMol在各种分子属性预测任务中具有优越的性能，并通过实验证明了其对不完整数据的有效性。", "conclusion": "广泛的实验结果表明，FlexMol在一系列分子属性预测任务中实现了优越的性能，并通过实验证明了其在不完整数据情况下的有效性。本文的代码和数据可在该链接下载：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07084", "html_url": "https://arxiv.org/abs/2510.07084", "title": "HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting", "title_en": "HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting", "authors": "Tan Wang,Yun Wei Dong,Tao Zhang,Qi Wang", "background": "基于Transformer的方法在时间序列预测方面取得了显著成果，但现有Transformer在序列建模方面仍存在局限性，倾向于过度强调时间依赖关系，导致额外的计算负载而未带来相应的性能提升。同时，Transformer的表现高度依赖于其学习有效表示的嵌入方法。", "innovation": "提出了一种Hybrid Temporal and Multivariate Embeddings (HTME) 抽取方法，将轻量级的时间特征提取模块与精心设计的多元特征提取模块结合，提供互补特征，以实现模型复杂性和性能之间的平衡。将HTME与Transformer架构结合，构建HTMformer，利用HTME增强的特征提取能力开发轻量级预测器。", "conclusion": "在八个真实世界数据集上的实验表明，我们的方法在准确性和效率上均优于现有基线。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07053", "html_url": "https://arxiv.org/abs/2510.07053", "title": "学习的语义场景图定位中的洞察", "title_en": "Introspection in Learned Semantic Scene Graph Localisation", "authors": "Manshika Charvi Bissessur,Efimia Panagiotaki,Daniele De Martini", "background": "该研究探讨了语义如何影响基于学习的自监督对比语义定位框架中的定位性能和鲁棒性。通过在原始和扰动地图上训练定位网络，进行了一次全面的后续内省分析，旨在验证模型是否过滤环境噪声并优先选择区别性地标而非常规杂乱。研究还验证了各种可解释性方法，并进行了可靠性比较分析。", "innovation": "该研究提出了通过综合梯度法和注意力权重来深入探究模型的可解释性行为。此外，通过删除语义类别进一步揭示了模型中隐含的加权方式，其中频繁出现的对象往往被下调权重。这些方法有助于理解模型如何在视觉和结构变化下实现可解释的注册。", "conclusion": "实验结果表明，模型学习了噪声鲁棒且语义上显著的关于场所定义的关系，因此在具有挑战性的视觉和结构变化条件下能够实现可解释的注册。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07052", "html_url": "https://arxiv.org/abs/2510.07052", "title": "通过微调预训练模型和超参数优化提升语音情感识别", "title_en": "Enhancing Speech Emotion Recognition via Fine-Tuning Pre-Trained Models and Hyper-Parameter Optimisation", "authors": "Aryan Golbaghi,Shuo Zhou", "background": "该研究背景在于，语音情感识别（SER）是一个关键的研究领域，通过结合预训练表示和自动超参数优化（HPO），可以进一步提升SER的性能。文献提到，使用了SpeechBrain wav2vec2-base模型在IEMOCAP数据集上进行微调，并使用Gaussian Process Bayesian Optimisation (GP-BO) 和 Tree-structured Parzen Estimators (TPE) 进行超参数优化。实验在15次试验预算和相同的四维搜索空间下进行，目标是在EmoDB数据集上达到平衡类准确度（BCA）。", "innovation": "本文的创新点在于提出了一种结合预训练表示与自动化超参数优化的工作流。具体来说，通过使用细调的SpeechBrain wav2vec2-base模型作为编码器，并对比了两种超参数优化策略（GP-BO和TPE），在相同的硬件环境下进行性能对比。研究还展示了跨语言泛化的效果，证明了有效的HPO可以与预训练模型结合，提升语音情感识别性能，并且在普通CPU上也具有较好的表现效率。", "conclusion": "研究结果显示，通过有效的超参数优化与预训练编码器相结合的工作流可以在普通的CPU上实现竞争力的语音情感识别。与网格搜索相比，GP-BO能够在11分钟内实现0.96的BCA，而TPE在15分钟内实现0.97的BCA，而网格搜索需要143次试验和1,680分钟才能达到0.9的BCA。为CREMA-D和RAVDESS数据集上的零样本准确率分别提升了0.25和0.26，进一步证明了该方法的有效性和普适性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07092", "html_url": "https://arxiv.org/abs/2510.07092", "title": "Humanoids生成世界建模：1X世界模型挑战技术报告", "title_en": "Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report", "authors": "Riccardo Mereu,Aidan Scannell,Yuxin Hou,Yi Zhao,Aditya Jitta,Antonio Dominguez,Luigi Acerbi,Amos Storkey,Paul Chang", "background": "世界模型在人工智能和机器人领域是一种强大的范式，使智能体能够通过预测视觉观察或紧凑的潜在状态来预测未来。1X世界模型挑战引入了一个开源的现实世界类人交互基准，包含两个互补赛道：采样赛道专注于对未来图像帧的预测，压缩赛道则专注于预测未来离散的潜在代码。", "innovation": "作者通过适应Wan-2.2 TI2V-5B模型到视频状态条件下的未来帧预测，并使用AdaLN-Zero调整视频生成，随后通过LoRA进一步训练模型来改进采样赛道。对于压缩赛道，作者从头开始训练了一个时空变换器模型。模型在采样任务中实现了23.0 dB的PSNR，在压缩任务中获得了排名第500的位置，CE值为6.6386，从而在两个挑战中都获得了第一名。", "conclusion": "作者的模型在1X世界模型挑战的采样和压缩赛道中均取得优异成绩，实现了先进性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07093", "html_url": "https://arxiv.org/abs/2510.07093", "title": "非渐近分析可知化回归效率", "title_en": "Non-Asymptotic Analysis of Efficiency in Conformalized Regression", "authors": "Yunzhen Yao,Lie He,Michael Gastpar", "background": "可变形预测提供具有覆盖保证的预测集。可变形预测的信息性依赖于其效率，通常通过预测集预期大小来量化。先前对可变形回归效率的研究通常将误覆盖水平α视为固定常数。本文在此基础上，针对通过SGD训练的可变形分位数和中位数回归，在假设数据分布条件较宽松的情况下，建立了预测集长度与Oracle区间长度的非渐近偏差上界。这些偏差的大小为O(1/√n + 1/(α^2 n) + 1/√m + exp(-α^2 m))，捕捉了效率与适当的训练集大小n、校准集大小m和误覆盖水平α之间的联合依赖关系。", "innovation": "本文的研究结果指出了效率在不同α值下收敛率的变化相变点，从而为控制预测集过长提供了指导。此外，建立了适用于通过SGD训练的可变形分位数和中位数回归的非渐近偏差上界，填补了该领域的理论空白。", "conclusion": "实验结果与理论发现一致。研究结果表明，不同的α值下，效率会经历不同的收敛率相变，这对于如何分配数据以控制预测集过长提供了有价值的指导。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07132", "html_url": "https://arxiv.org/abs/2510.07132", "title": "DPMM-CFL: 通过狄利克雷过程混合模型非参数聚类的分簇联邦学习", "title_en": "DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering", "authors": "Mariona Jaramillo-Civill,Peng Wu,Pau Closas", "background": "传统的联邦学习（Federated Learning，FL）在处理非独立同分布（non-IID）客户端异构性时表现不佳，而分簇联邦学习（Clustered Federated Learning，CFL）通过将客户分组然后每组训练一个模型，能够在全局模型和完全个性化模型之间取得平衡，从而提升性能。然而，大多数CFL方法需要先验设定簇的数量K，这在未知潜在结构的情况下是不实际的。", "innovation": "本文提出了一种称为DPMM-CFL的新方法，它在客户池参数的分布上使用狄利克雷过程（Dirichlet Process，DP）先验，实现了非参数贝叶斯推理，可以同时推断簇的数量和客户分配，并在每个簇内优化联邦学习目标。这种方法在每个迭代周期中会耦合进行联邦更新和聚类推理。", "conclusion": "本文通过验证DPMM-CFL在基准数据集上的表现，证明了该方法的有效性，特别是在狄利克雷和类别分割非IID分区下。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07151", "html_url": "https://arxiv.org/abs/2510.07151", "title": "ELMUR：在外层记忆更新/重写框架下的长时距RL", "title_en": "ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL", "authors": "Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov", "background": "现实中的机器人必须在部分可观测性和长时序的情况下作出决策，其中关键线索可能在影响决策很久之前就出现了。然而，大多数现代方法仅依赖于瞬时信息，而没有整合过去的洞察。标准的递归神经网络或变换器模型难以保留和利用长期依赖性：注意力窗口会截断历史记录，而简单的记忆扩展在规模和稀疏性上表现不佳。", "innovation": "作者提出了一种名为ELMUR（External Layer Memory with Update/Rewrite）的变换器架构，该架构具有结构化外部记忆。每个层保持记忆嵌入，通过双向交叉注意力与它们交互，并通过一个基于最近最少使用（LRU）的记忆模块进行更新或凸融合。ELMUR能够将有效的时间范围远超注意力窗口100,000倍，使得在合成T-Maze任务中实现100%的成功率。在POPGym中，ELMUR在超过一半的任务上超越了基准模型；在MIKASA-Robo稀疏奖励操作任务中，视觉观察情况下，其性能几乎翻倍。", "conclusion": "结构化、分层局部外部记忆为在部分可观测性下的决策提供了简单且可扩展的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07182", "html_url": "https://arxiv.org/abs/2510.07182", "title": "桥接聚类在表示学习中的应用：半监督稀疏桥接", "title_en": "Bridged Clustering for Representation Learning: Semi-Supervised Sparse Bridging", "authors": "Patrick Peixuan Ye,Chen Shani,Ellen Vitercik", "background": "该研究介绍了一种半监督框架——桥接聚类，用于从未配对的输入数据集X和输出数据集Y中学习预测器。传统的半监督学习方法依赖于配对的输入和输出数据，而桥接聚类则主要利用未配对的数据来训练模型。此外，相比密集的传输方法，它保持了稀疏且可解释的对齐方式。", "innovation": "该研究提出了一种新的半监督框架——桥接聚类。首先独立聚类输入X和输出Y，然后利用少量配对的例子学习稀疏、可解释的桥梁。模型在推理时，将新输入分配到最近的输入簇，并返回链接输出簇的中心作为预测。与传统的半监督学习方法相比，桥接聚类更有效率并且能够保持稀疏和可解释的对齐。", "conclusion": "通过理论分析，研究者证明了在限制错误聚类和错误桥接率的情况下，该算法可以成为有效的预测器。实验结果显示，该方法在低监督条件下与最先进的方法竞争，同时保持简洁、模型无关和高度的标签效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07086", "html_url": "https://arxiv.org/abs/2510.07086", "title": "非平稳在线结构预测与替代损失", "title_en": "Non-Stationary Online Structured Prediction with Surrogate Losses", "authors": "Shinsaku Sakaue,Han Bao,Yuzhou Cao", "background": "在线结构预测涉及从输入特征逐次预测标签，特别关注于替代后悔，它表示的目标损失（如0-1损失）与替代损失（如对数损失）之间的累积差异。通常，替代后悔可以保持独立于时间窗$T$的有限界值，但这在非平稳环境中失效，因为任何固定估计器的累积替代损失可能随$T$呈线性增长。", "innovation": "本文提出了一个新的误差界，形式为$F_T + C(1 + P_T)$，它在非平稳环境中比固定的替代后悔提供了更强的保证，其中$F_T$是任何比较序列的累积替代损失，$P_T$是路径长度，$C > 0$为常数。此边界还揭示了针对在线梯度下降(OGD)的Polyak风格的学习率，可以系统地提供目标损失保证，并显示出有前景的实验表现。此外，该方法通过卷积Fenchel--Young损失扩展到更广泛的问题类别。", "conclusion": "证明了一个下界，表明此误差界的依赖关系是最佳的。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07192", "html_url": "https://arxiv.org/abs/2510.07192", "title": "LLMs的投毒攻击需要近似常数数量的污染样本", "title_en": "Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples", "authors": "Alexandra Souly,Javier Rando,Ed Chapman,Xander Davies,Burak Hasircioglu,Ezzeldin Shereen,Carlos Mougan,Vasilios Mavroudis,Erik Jones,Chris Hicks,Nicholas Carlini,Yarin Gal,Robert Kirk", "background": "现有的研究已探讨了预训练投毒攻击，假设对手控制训练语料的一部分。但对于大规模语言模型（LLMs），即使是很小的百分比也会转化为庞大的数据量。已有研究只针对训练语料库中特定百分比的控制进行了研究，但本文发现投毒攻击实际只需要近似常数数量的文档，而与数据集大小无关。", "innovation": "研究首次表明，投毒攻击需要的数量不是随数据集大小增加而增加，而是几乎保持不变，即使是最大的模型也要处理超过20倍更多清洁数据。本文还通过小规模实验减少了可能影响攻击成功的因素，如不随机的污染样本分布。", "conclusion": "研究结果表明，通过数据投毒注入后门可能比之前认为的更简单，因为所需污染的数量并不随模型大小增加。这表明需要更多的研究来开发防御措施，以缓解未来模型中存在的这一风险。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07147", "html_url": "https://arxiv.org/abs/2510.07147", "title": "多智能体框架在状态化推理时搜索", "title_en": "A Multi-Agent Framework for Stateful Inference-Time Search", "authors": "Arshika Lalan,Rajat Ghosh,Aditya Kolsur,Debojyoti Dutta", "background": "最近的工作研究了在执行多步推理时的代理推理时技术。然而，无状态的推理在多步任务上常常遇到困难，因为它缺乏持续的状态。此外，针对特定任务的微调或指令微调通常只能达到表面层次的代码生成，对于需要更深层次推理和长时依赖的任务来说，还是比较脆弱的。因此，这些方法还存在限制和不足。为了应对这些限制，本文提出了一种状态化多智能体进化搜索框架。该框架从以前的无状态方法中分离出来，结合了（i）持续的推理时状态，（ii）对抗性变异，以及（iii）进化保存。本文通过自动单元测试生成中的边缘情况生成来展示其有效性。在进化搜索过程中，特定的智能体依次提出、变异和评分候选人。控制单元在整个世代中保持持续的状态，同时进化保存确保了对所有可能情况的多样性和探索。最后，这产生了一种通才智能体，能够在未见过的代码库中发现 robust、高覆盖率的边缘情况。实验表明，当这些方法与常见的单元测试基准测试进行比较时，状态化多智能体推理框架在覆盖方面显著优于无状态单步基线，适用于 LLM 家族中的三种不同家族 - Llama、Gemma 和 GPT。这些结果表明，将持续的推理时状态与进化搜索结合起来，可以显著提高单元测试生成的表现。", "innovation": "提出了状态化多智能体进化搜索框架。该框架融合了（i）持续的推理时状态，（ii）对抗性变异，及（iii）进化保存，以克服无状态方法在多步骤任务中的瓶颈。与无状态的方法相比，该框架在覆盖方面的表现显著提高。", "conclusion": "该状态化多智能体推理框架能够有效提升单元测试生成的性能，特别是在对深厚推理和长期依赖任务需求较高的场景中，以及在不同 LLM 家族中都表现出色。这说明整合持续的推理时状态与进化搜索能够显著改善单元测试的生成。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07205", "html_url": "https://arxiv.org/abs/2510.07205", "title": "由专家引导：软路由混合专家模型的可证特征学习动态", "title_en": "Guided by the Experts: Provable Feature Learning Dynamic of Soft-Routed Mixture-of-Experts", "authors": "Fangshuo Liao,Anastasios Kyrillidis", "background": "专家混合架构（MoE）已经成为现代AI系统的核心支柱。特别是在这些模型中，输入被动态路由到专门的专家，其输出通过加权求和进行汇总。尽管MoE架构被广泛应用，但对其训练动力学的理论理解仍局限于独立专家-路由器优化或仅限于精心构造的数据集中的顶级路由场景。目前，关于MoE模型端到端训练的理论研究相对不足。", "innovation": "本文为MoE理论提供了新的突破，通过提供在非线性路由器和专家的软路由MoE模型中进行联合训练的收敛保证。证明了在适度的参数过参数化下，学生网络经历了一个特征学习阶段，在此阶段中，路由器的学习过程被“引导”由专家完成，从而恢复教师的参数。此外，还展示了后训练修剪的有效性，可消除冗余神经元，随后通过一个可证明收敛的微调过程达到全局最优。", "conclusion": "据我们所知，我们的分析是首次在MoE架构的优化景观中带来了新的见解。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07071", "html_url": "https://arxiv.org/abs/2510.07071", "title": "盲构造大规模MIMO网络中角度功率图", "title_en": "Blind Construction of Angular Power Maps in Massive MIMO Networks", "authors": "Zheng Xing,Junting Chen", "background": "在大规模多输入多输出(MIMO)网络中，信道状态信息(CSI)获取是一个具有挑战性的问题。无线地图为无线资源管理提供了潜在解决方案，通过减少在线CSI获取。然而，传统的方法需要带有位置标签的CSI数据，在实践中难以获取。本文探讨了基于大规模MIMO网络中的无标签大规模时域CSI数据的无监督角度功率图构建。研究发现，在均匀直线移动性和泊松分布基站的条件下，定位误差的克拉默-拉奥下界(CRLB)在任何信噪比(SNR)下可以消失；当基站局限于有限区域时，即使有无限独立测量，误差仍然为零。根据实际多小区大规模MIMO网络中收集的接收信号强度指示(RSRP)数据，可以实现18米的平均定位误差，尽管测量主要来自单个服务小区。", "innovation": "研究提出了基于大规模MIMO网络中的无监督角度功率图构建方法，不需要位置标签的CSI数据；通过构建隐藏马尔可夫模型(HMM)，将移动的隐藏轨迹与大规模MIMO信道的CSI演化联系起来，从而估计移动位置，实现角度功率图的构建。指出在特定移动性和基站分布条件下，定位误差的CRLB可以消失，甚至在有限测量下误差也不会为零。", "conclusion": "通过大规模MIMO网络中的大规模时域CSI数据，可以实现无监督的角度功率图构建，特别是在特定的移动性模型和基站分布下，定位误差的CRLB可以消失。通过实际数据验证，实现18米的平均定位误差。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07245", "html_url": "https://arxiv.org/abs/2510.07245", "title": "泛教师类别的区分特征反馈", "title_en": "Discriminative Feature Feedback with General Teacher Classes", "authors": "Omri Bar Oz,Tosca Lechner,Sivan Sabato", "background": "本文研究了交互式学习协议Discriminative Feature Feedback (DFF)的理论性质，该协议采用基于区分特征解释的反馈形式。本文首次在一个通用框架中系统研究DFF，该框架与经典的监督学习和在线学习协议相当。", "innovation": "本文研究了DFF在可实现和不可实现情况下的最大错误边界，获得了新颖的结构结果，并探讨了在线学习与提供更多反馈（如DFF）设置之间的差异。同时，提出了一个新的维度概念来表征可实现条件下的最大错误边界。在不可实现的情况下，提供了最大错误上界，并证明了这种上界在一般情况下无法改进。研究结果表明，与在线学习不同，在DFF中可实现维度并不能充分表征最优不可实现的最大错误边界或无遗憾算法的存在。", "conclusion": "本文的研究展示了DFF协议在处理不可实现情况时与在线学习的不同特性，强调了提供更丰富反馈的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07202", "html_url": "https://arxiv.org/abs/2510.07202", "title": "深入探讨通过深度和狭窄神经网络的逼近问题", "title_en": "An in-depth look at approximation via deep and narrow neural networks", "authors": "Joris Dommel,Sven A. Wegner", "background": "2017年，Hanin和Sellke证明了深度为任意、宽度为w的ReLU激活前馈网络在R^n上的连续函数空间中，根据有界集上的统一收敛拓扑，当且仅当w>n时，形成了一个稠密集。他们使用了具体反例函数f:R^n->R来证明必要性。本文继续探索在w=n和w=n+1这两种情况下，神经网络对这个特定函数f的逼近效果，考察了深度变化对逼近效果的影响以及死神经元对这种行为的影响.", "innovation": "作者进一步探索了在接近宽度阈值时，深度和宽度为n及n+1的神经网络对特定函数f的逼近效果，分析了深度变化和神经元死亡对逼近质量的影响，这为理解神经网络的设计参数与逼近能力之间的关系提供了新的视角.", "conclusion": "研究表明，在宽度接近阈值时，神经网络的深度和宽度的变化显著影响其对特定函数的逼近质量。发现神经元死亡对逼近性能有负面影响，这一发现对于优化神经网络架构和理解深度学习中的非线性表征具有重要意义."}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07266", "html_url": "https://arxiv.org/abs/2510.07266", "title": "动态约束下的在线全能预测的动态后悔界", "title_en": "Dynamic Regret Bounds for Online Omniprediction with Long Term Constraints", "authors": "Yahav Bechavod,Jiuyao Lu,Aaron Roth", "background": "本文解决了一个最近引入的问题，即在长期约束下进行在线全能预测。在这种场景中，学习者需要生成一系列预测，并通过一组下游决策者。每个下游决策者都有自己的效用函数，并且还有一个约束函数向量，这些函数将决策者的行动与对手选择的状态映射到奖励或约束违反项。下游决策者根据预测的状态选择行动，而学习者的目标是生成预测，以使所有下游决策者在最坏情况下获得效用保障，同时最小化最坏情况下的约束违反。", "innovation": "我们给出了第一个能够在所有代理间同时获得动态后悔保证的算法。对于每个代理，后悔是根据在各轮交互过程中可能变化的一系列行动来衡量的，同时确保每个代理的约束违反项趋近于零。我们的结果并不需要代理自己维持任何状态，他们只需解决由该轮次预测所定义的一轮次约束优化问题。", "conclusion": "本文通过提出一个在线全能预测算法，该算法在长期约束下满足所有代理的同时动态后悔保证和近零约束违反，解决了这一问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07208", "html_url": "https://arxiv.org/abs/2510.07208", "title": "Thompsons采样的更广泛视角", "title_en": "A Broader View of Thompson Sampling", "authors": "Yanlin Qu,Hongseok Namkoong,Assaf Zeevi", "background": "Thompsons采样是一种广泛使用和研究的多臂-bandit 算法，以其简洁的结构、低遗憾性能和坚实的理论保证而闻名。然而，与其他多臂-bandit 算法家族不同，Thompsons采样后验采样的机制，即如何恰当地平衡探索与利用，仍然是一个谜。这篇文章通过将Thompsons采样重新定义为在线优化算法来探讨这个问题的核心洞察点，并引入了“忠实”稳态化这一概念工具，将有限时间窗内的动态优化问题转换为一个类似于原始目标的稳态问题。通过Bellman原理，新的时间不变目标被研究，从而得出一个不变的最优策略。重新审视Thompsons采样后，发现它具有一个简单在线优化形式，这个形式模仿了Bellman最优策略的结构，其中贪婪性通过点-二列相关测量的剩余不确定性进行正则化，从而揭示了Thompsons采样如何平衡探索与利用的问题，并提供了一个有原则的框架来研究和完善Thompsons原始的想法。", "innovation": "这篇文章通过将Thompsons采样重新定义为在线优化算法，并引入了“忠实”稳态化这一概念工具，将有限时间窗内的动态优化问题转换为一个类似于原始目标的稳态问题。通过Bellman原理，新的时间不变目标被研究，从而得出一个不变的最优策略。这种观点揭示了Thompsons采样如何平衡探索与利用的问题，并提出了一种有原则的方法来研究和进一步改进Thompsons原始的想法。", "conclusion": "Thompsons采样的在线优化形式模仿了Bellman最优策略的结构，贪婪性通过点-二列相关测量的剩余不确定性进行正则化。这揭示了Thompsons采样如何平衡探索与利用的问题，并提供了一个有原则的框架来研究和完善Thompsons原始的想法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07257", "html_url": "https://arxiv.org/abs/2510.07257", "title": "测试时图搜索在目标条件强化学习中的应用", "title_en": "Test-Time Graph Search for Goal-Conditioned Reinforcement Learning", "authors": "Evgenii Opryshko,Junwei Quan,Claas Voelcker,Yilun Du,Igor Gilitschenski", "background": "目标条件化强化学习（GCRL）在测试阶段能够达到用户指定的目标，提供了一种从未标注、无奖励的数据集中提取多样化行为的简单、无监督、领域无关的方法。然而，GCRL中的长期决策仍然困难，因为存在时间上的责任分配问题和误差积累，特别是在离线设置中这些问题会进一步放大.", "innovation": "提出了测试时图搜索（TTGS），这是一种轻量级的规划方法，用于解决GCRL任务。TTGS接受任何状态空间的距离或费用信号，构建一个基于数据集中状态的加权图，并执行快速搜索以组装出执行冻结策略的子目标序列。当基学习器是基于价值的方法时，距离直接从学习到的目标条件价值函数推导而来，无需手工制作的度量标准。TTGS无需对训练方式进行修改，无需额外的监督信息，无需在线互动，也无需特权信息，且完全在推理阶段运行。在OGBench基准测试中，TTGS提高了多个基学习器在具有挑战性的移动任务中的成功率，证明了简单度量引导下的测试时规划对于离线GCRL的好处.", "conclusion": "TTGS为解决GCRL中的长期决策问题提供了解决方案，证明了在非监督且无奖励的环境中进行简单的度量引导的测试时规划可以提高成功率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07285", "html_url": "https://arxiv.org/abs/2510.07285", "title": "GTCN-G：不平衡入侵检测中的残差图-时间融合网络（预印本）", "title_en": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)", "authors": "Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Qi Hu,Yan Li,Chang Liu", "background": "网络威胁的复杂性日益增长，网络流量数据存在固有的类别不平衡问题，给现代入侵检测系统（IDS）带来了严峻挑战。尽管图神经网络（GNNs）擅长建模拓扑结构，时空卷积网络（TCNs）能够捕捉时间序列依赖关系，但如何将两者协同整合以明确解决数据不平衡问题仍是未解决的难题。", "innovation": "本论文提出了一种新颖的深度学习框架——门控时空卷积网络和图（GTCN-G），旨在克服这些限制。该模型独特地结合了门控TCN（G-TCN）和图卷积网络（GCN），前者用于从网络流中提取层次时间特征，后者用于学习底层的图结构特征。核心创新在于融合了残差学习机制，通过图注意网络（GAT）实现。该机制通过残差连接保留原始特征信息，这对于缓解类不平衡问题和提高检测敏感性（特别是对稀有恶意行为）至关重要。", "conclusion": "通过在两个公开基准数据集UNSW-NB15和ToN-IoT上进行详细实验，我们验证了该方法的有效性。实验结果表明，所提出的GTCN-G模型在二分类和多分类任务中均实现了最先进的性能，明显优于现有基线模型。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07312", "html_url": "https://arxiv.org/abs/2510.07312", "title": "h1: 使用强化学习在现有数据上训练长时域推理的大语言模型", "title_en": "h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement Learning", "authors": "Sumeet Ramesh Motwani,Alesia Ivanova,Ziyang Cai,Philip Torr,Riashat Islam,Shital Shah,Christian Schroeder de Witt,Charles London", "background": "现有的大语言模型在短时域推理任务上表现优异，但在长时域推理任务上效果会下降。目前解决这一问题的方法要么依赖于推理时的支撑或昂贵的步骤级监督，这两种方法的扩展性都不好。", "innovation": "该研究提出了一种使用现有丰富的短时域数据来训练长时域推理能力的可扩展方法。该方法通过将简单的任务合成复杂的多步依赖链，并使用基于结果的奖励进行训练，同时采用自动增复杂的课程学习方法，使得强化学习训练能够大规模扩展且不饱和。", "conclusion": "实证结果显示，此方法在模拟六年级水平的数学问题（GSM8K）的课程训练后，准确度在较长的、竞赛级别的基准（GSM-Symbolic，MATH-500, AIME）上提高了多达2.06倍。理论上，该研究证明使用结果奖励的课程强化学习在样本复杂性上相对于全时域训练有了指数级的改善，提供与密集监督相当的训练信号。由此，该方法为仅利用现有数据规模化训练长时域问题的强化学习提供了一条高效途径。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07286", "html_url": "https://arxiv.org/abs/2510.07286", "title": "蛋白质进化图谱用于蛋白质适应性预测", "title_en": "Evolutionary Profiles for Protein Fitness Prediction", "authors": "Jigang Fan,Xiaoran Jiao,Shengdong Lin,Zhanming Liang,Weian Mao,Chenchen Jing,Hao Chen,Chunhua Shen", "background": "蛋白质工程中预测突变的适应性影响至关重要，但受限于有限的实验测试与序列空间规模之间的差距。基于遮蔽语言建模（MLM）的蛋白质语言模型（pLMs）在零样本适应性预测中展现出强大的性能。通过将自然进化视为隐式奖励最大化的过程，将MLM解释为逆强化学习（IRL），文章提供了一种统一的视角。在此基础上，作者提出了EvoIF模型，该模型结合了两方面的进化信号：（i）从检索到的同源序列获得的家族内部图谱；（ii）从逆折叠对数似然比中提炼出的跨家族的结构-进化约束。EvoIF通过一个紧凑的过渡模块融合序列-结构表示，生成对log-odds评分的校准概率。", "innovation": "EvoIF是一种轻量级模型，能够结合两类进化信号：家族内部图谱和跨家族的结构-进化约束。在ProteinGym数据集上，EvoIF及其MSA增强的变体达到了最先进的或具有竞争力的性能，同时仅使用了0.15%的训练数据，并且参数数量少于最近的大规模模型。消融实验表明，这两种信号是互补的，有助于提高不同类型功能、MSA深度、分类群和突变深度的鲁棒性。", "conclusion": "EvoIF模型在蛋白质适应性预测中表现出色，仅使用少量的训练数据和较少的参数，且通过结合家族内部和跨家族的进化信号提高了鲁棒性。相关代码将公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07289", "html_url": "https://arxiv.org/abs/2510.07289", "title": "MolGA: 使用预训练2D图编码器进行分子图适应", "title_en": "MolGA: Molecular Graph Adaptation with Pre-trained 2D Graph Encoder", "authors": "Xingtong Yu,Chang Zhou,Xinming Zhang,Yuan Fang", "background": "在化学和生物医学研究中，分子图表示学习被广泛应用。尽管预训练的2D图编码器表现出强大的性能，但它们忽视了与子分子实例（原子和键）相关的丰富领域知识。虽然分子预训练方法将这种知识纳入其预训练目标中，但它们通常的设计局限于特定类型的领域知识，缺乏灵活集成多种分子领域知识的能力。因此，利用广泛可用且验证良好的预训练2D编码器，并在下游适应过程中结合分子领域知识，提供了一种更实用的选择。", "innovation": "本文提出了一种名为MolGA的方法，通过灵活地结合多种分子领域知识，使预训练的2D图编码器适应下游分子应用。MolGA首先提出了一种分子对齐策略，以弥合预训练拓扑表示与领域知识表示之间的差距。其次，引入了一种条件适应机制，生成实例特定的标记，以实现分子领域知识的细粒度集成。", "conclusion": "通过在11个公开数据集上进行广泛的实验，证明了MolGA的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06228", "html_url": "https://arxiv.org/abs/2510.06228", "title": "使用Quorus的异构量子客户端逐层联邦学习", "title_en": "Layerwise Federated Learning for Heterogeneous Quantum Clients using Quorus", "authors": "Jason Han,Nicholas S. DiBrita,Daniel Leeds,Jianqiang Li,Jason Ludmir,Tirthak Patel", "background": "量子机器学习（QML）有望解决经典计算机无法解决的问题，但由于关键数据分布于多个私人客户端，因此需要使用量子联邦学习（QFL）进行分布式处理。然而，不同客户端所拥有的量子计算机可能会出现不同的错误特性，需要运行不同深度的量子电路。这些量子计算机的错误性要求新的解决方案来有效培训不同深度的量子模型，以便客户端可以根据其个体能力选择适宜的模型。", "innovation": "本文提出了一种名为Quorus的创新性解决方案，通过逐层损失函数进行有效训练，使得不同深度的量子模型可以根据客户端个体能力选择最适合的模型。此外，Quorus还提供多种基于客户端需求的模型设计，优化了射击预算、量子比特数量、中途测量以及优化空间。", "conclusion": "通过模拟和实际硬件的测试结果表明，Quorus能够增加较高深度客户端的梯度幅度，并且其测试准确性较最先进的方法平均提高12.4%。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07307", "html_url": "https://arxiv.org/abs/2510.07307", "title": "MLE-Smith：通过自动化多智能体管道扩展机器学习工程任务", "title_en": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline", "authors": "Rushi Qiang,Yuchen Zhuang,Anikait Singh,Percy Liang,Chao Zhang,Sherry Yang,Bo Dai", "background": "尽管语言模型（LMs）在自动化机器学习工程（MLE）方面取得了显著进展，但高质量的MLE训练数据的获取受到了极大限制。现有的MLE基准因其依赖于静态、手工整理的任务，导致在时间和人力上需求极大，难以扩展和广泛应用。", "innovation": "提出了MLE-Smith，这是一种完全自动化的多智能体管道，通过高效的生成-验证-执行范式将原始数据集转化为具有可验证质量、实用性和丰富多样性的竞争型MLE挑战。提议的多智能体管道通过结构化的任务设计和标准化重构，结合混合验证机制以确保严格的结构规则和高层次语义正确性，并通过交互执行进一步验证其实证可解性和现实一致性。将MLE-Smith应用于224个实际数据集，生成606个涵盖多个类别、目标和模态的任务，证明了MLE-Smith可以广泛应用于各种实际数据集上。通过生成的任务评估表明，主流和前沿的八种语言模型在MLE-Smith任务上的表现与精心设计的人类任务高度相关，突显了MLE-Smith在扩展MLE任务方面的有效性，同时能保持任务质量。", "conclusion": "本书展示了MLE-Smith的多智能体管道如何通过自动化的方式扩展MLE任务，同时保证了任务的质量与实际应用价值，具备广泛应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20504", "html_url": "https://arxiv.org/abs/2508.20504", "title": "增强IoE网络弹性：网络层面保护的视角", "title_en": "Enhancing Resilience for IoE: A Perspective of Networking-Level Safeguard", "authors": "Guan-Yan Yang,Jui-Ning Chen,Farn Wang,Kuo-Hui Yeh", "background": "IoE将物联网驱动的数字通信与电力网络集成，以实现高效的可持续能源系统。然而，其互联性暴露了关键基础设施对复杂的网络攻击，尤其是设计来绕过传统保护措施的对抗性攻击。与普通物联网风险不同，IoE威胁具有更严重的公共安全后果，要求有弹性的解决方案。从网络层面保护的角度，我们提出了一种基于图结构学习（GSL）的保护框架，该框架同时优化图拓扑和节点表示以抵御对抗性网络模型的操控。通过对安全数据集的概念概述、架构讨论和案例研究，我们展示了GSL相较于代表性方法的优越稳健性，为从业者提供了一条有效途径来抵御不断演变的攻击并确保IoE网络的安全。这项工作突显了GSL增强未来IoE网络韧性与可靠性的潜力，为管理关键基础设施的从业者提供了参考。", "innovation": "我们提出了一种基于图结构学习（GSL）的保护框架，该框架能够同时优化图拓扑和节点表示，以抵抗对抗性网络模型的操控。通过安全数据集的概念概述、架构讨论和案例研究，我们展示了GSL相较于现有方法的优越稳健性。这种方法为IoE网络提供了抵抗各种攻击的有效解决方案，特别关注了公共安全的更高要求。", "conclusion": "这项工作强调了GSL在增强未来IoE网络的弹性和可靠性方面的潜力，为从业者提供了一条有效路径来管理关键基础设施的安全。然而，该领域还存在一些关键的开放挑战，需进一步研究以推动技术的发展和完善。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06244", "html_url": "https://arxiv.org/abs/2510.06244", "title": "评价科学领域嵌入框架", "title_en": "Evaluating Embedding Frameworks for Scientific Domain", "authors": "Nouman Ahmed,Ronin Wu,Victor Botev", "background": "在特定领域（如科学领域）的文本数据分析中，找到最优的单词表示算法尤为重要，因为同一个单词在不同的领域和语境下可能有不同的含义和表示方法。当前的生成性AI和transformer架构虽然在生成上下文化嵌入方面表现出色，但在构建新模型时会消耗大量的时间和计算资源。", "innovation": "本文聚焦于科学领域，旨在发现最适用于科学领域的单词表示和分词方法，并构建了多个下游任务及相关数据集作为评估框架，以评估不同单词表示和分词算法。", "conclusion": "通过构建的评估框架，本文测试了多种单词表示和分词算法，并提供了评估各个领域新算法的全面工具。这为科学领域的自然语言处理任务提供了最优的单词表示和分词方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06238", "html_url": "https://arxiv.org/abs/2510.06238", "title": "使用MC Dropout进行表面地雷和未爆弹药分类的不确定性量化", "title_en": "Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout", "authors": "Sagar Lekhak,Emmett J. Ientilucci,Dimah Dera,Susmita Ghosh", "background": "使用深度学习检测地表地雷和未爆弹药（UXOs）在人道主义除雷中显示出潜在的应用价值。然而，确定性的神经网络在面对噪声条件或对抗性攻击时可能会出现误检或误分类的问题。为了改进这一问题，本研究提出将蒙特卡洛（MC） Dropout的不确定性量化方法集成到微调的ResNet-50架构中，用于地表地雷和UXO的分类，该方法得到了模拟数据集上的测试验证。", "innovation": "研究将蒙特卡洛（MC） Dropout方法应用于表面地雷和未爆弹药分类任务中，以量化模型的epistemic不确定性，并引入一个新的指标来评估模型预测的可靠性，提高了在复杂环境下的决策水平。通过实验证明，在干净、对抗性扰动和噪声图像上，这种方法能够有效标识不可靠的预测结果，展示了在实际应用中不确定性量化的重要性。", "conclusion": "该概念验证研究强调了在地雷探测中需要不确定性量化，提高了对现有神经网络在地雷探测中对抗性威胁的脆弱性的认识，并强调了开发更稳健可靠的模型的重要性，以满足实际应用的需求。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06229", "html_url": "https://arxiv.org/abs/2510.06229", "title": "自主铁路运营的里程碑确定", "title_en": "Milestone Determination for Autonomous Railway Operation", "authors": "Josh Hunter,John McDermid,Simon Burton,Poppy Fynes,Mia Dempster", "background": "在铁路自动化领域，关键挑战之一是如何开发有效的计算机视觉系统，由于高质量、序列数据的有限可用性。传统数据集范围有限，缺少用于实时决策的空间和时间上下文。替代方案则引入了现实性和实用性的问题。通过专注于特定路线的、相关的线索，可以生成更丰富的、序列化的数据集，这些数据集更符合现实运营逻辑。", "innovation": "通过引入里程碑确定的概念，可以开发出针对特定目标的、基于规则的模型，简化了学习过程，减少了对动态组件普遍识别的需求，而是专注于路线中的关键决策点。这种方法为在可控和可预测环境中训练视觉代理提供了实际框架，有助于促进更安全、更高效的铁路自动化机器学习系统。", "conclusion": "这种方法为实现安全性更高、效率更佳的铁路自动化提供了实用框架，通过在受控环境中训练视觉代理，可以简化学习过程，专注于关键决策点，从而提高铁路自动化系统的学习效果和应用范围。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06232", "html_url": "https://arxiv.org/abs/2510.06232", "title": "Neu-RadBERT 用于增强脑损伤和病症诊断", "title_en": "Neu-RadBERT for Enhanced Diagnosis of Brain Injuries and Conditions", "authors": "Manpreet Singh(1),Sean Macrae(2),Pierre-Marc Williams(2),Nicole Hung(2),Sabrina Araujo de Franca(1),Laurent Letourneau-Guillon(2,3),François-Martin Carrier(2,4),Bang Liu(5),Yiorgos Alexandros Cavayas(1,2,6) ((1) Équipe de Recherche en Soins Intensifs, Centre de recherche du Centre intégré universitaire de santé et de services sociaux du Nord-de-l'Île-de-Montréal (2) Faculté de Médecine, Université de Montréal (3) Department of Radiology, Centre Hospitalier de l'Université de Montréal (4) Department of Anesthesia, Centre Hospitalier de l'Université de Montréal (5) Applied Research in Computer Linguistics Laboratory, Department of Computer Science and Operations Research, Université de Montréal (6) Division of Critical Care Medicine, Department of Medicine, Hôpital du Sacré-Cœur de Montréal)", "background": "本文旨在开发一种分类算法，从患有急性呼吸衰竭（ARF）并接受侵入性机械通气的患者进行脑成像检查的自由文本放射学报告中提取诊断信息。研究利用MIMIC-IV数据库中的脑部影像报告（包括CT和MRI），对存在多种脑部异常的报告进行了初步的手动标注，并使用三种策略对Neu-RadBERT模型进行了微调：基础RadBERT、Neu-RadBERT结合掩码语言建模预训练以及通过过采样解决数据偏差。研究结果表明，特别是在使用过采样技术后，Neu-RadBERT模型在诊断脑部异常方面的准确率显著提高，最高可达98.0%。Llama-2-13B语言模型在二分类准确率上仅达到67.5%，显示出其在特定分类任务上的局限性。", "innovation": "本文创新点在于开发了一种基于BERT的Neu-RadBERT模型，并通过目标领域预训练和过采样技术，提高了模型在从自由文本放射学报告中提取脑部异常诊断信息方面的准确性和可靠性。此外，研究通过将该模型与另一种语言模型Llama-2-13B进行比较，展示了当前自回归语言模型在特定分类任务上的局限性潜在改善的可能。", "conclusion": "研究结果证实，经过改进的Neu-RadBERT模型为从放射学报告中自动提取神经学条件的诊断信息提供了一个可靠而稳健的工具。该研究强调了基于转换器的自然语言处理模型在自动从自由文本报告中提取诊断信息方面的潜在应用前景，既适用于研究，又可应用于患者护理。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06252", "html_url": "https://arxiv.org/abs/2510.06252", "title": "Dream2Image：一种用于梦境解码和可视化的人工智能开放多模态EEG数据集", "title_en": "Dream2Image : An Open Multimodal EEG Dataset for Decoding and Visualizing Dreams with Artificial Intelligence", "authors": "Yann Bellec", "background": "现有的梦境研究主要依赖于口头报告或书面记录，难以捕捉梦境发生的实时神经活动。脑电图（EEG）信号可以提供更直接的脑部活动信息，但缺乏相应的真实梦境内容使得研究受限。因此，构建一个结合EEG信号、梦境转录和AI生成图像的数据集对于深化梦境神经机制的研究、开发基于脑活动解码梦境的模型，以及在神经科学、心理学和人工智能领域探索新方法具有重要意义。Dream2Image数据集正是基于这一背景提出的，它填补了该领域的空白，为梦境研究提供了新的资源和工具。", "innovation": "Dream2Image是全球首个多模态数据集，将EEG信号、梦境转录和AI生成的图像相结合。该数据集基于38名参与者超过31小时的梦境EEG记录，包含129个样本。这些样本提供了梦境临近醒来时的脑活动数据(T-15, T-30, T-60, T-120)、梦境体验的原始报告以及梦境的视觉重构。该数据集的创新之处在于它为研究梦境的神经相关性、开发从脑活动解码梦境的模型以及在人工智能和神经科学领域的创新方法提供了独特资源。数据集在Hugging Face和GitHub上开源，旨在支持AI和神经科学交叉领域的研究，同时激发新的研究灵感并拓宽现有方法的边界。", "conclusion": "Dream2Image数据集为梦境研究提供了新的视角，特别是在梦境解码和可视化方面展现出了巨大的潜力。然而，由于样本规模较小和梦境回忆的差异，这些局限性可能会对研究的普遍性产生影响。尽管存在问题，该数据集仍是一个重要突破，有望促进跨学科的研究发展。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06259", "html_url": "https://arxiv.org/abs/2510.06259", "title": "超越静态知识信使：向着自适应、公平和可扩展的医疗人工智能联邦学习", "title_en": "Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Ahsan Habib Tareq,Iftekhar Haider", "background": "当前的医疗人工智能面临着在保障隐私的同时，在异质医疗服务机构之间进行协作学习的挑战，尤其需要确保公平性。现有的联邦学习方法存在静态架构、收敛速度慢（45-73轮）、公平性差距、以及扩展性限制等问题。", "innovation": "提出了一种名为AFFL（Adaptive Fair Federated Learning）的新方法，这包括：1. 自适应知识信使，根据异质性及任务复杂度动态调整容量；2. 具有影响力加权聚合的公平性感知蒸馏；3. 课程引导加速，减少轮次（少于原始的60-70%）。理论分析提供了ε公平度的收敛保证，并实现了特定的收敛率，同时框架能够跨模态集成影像学、基因组学、电子健康记录和传感器数据，并保持HIPAA/GDPR合规。", "conclusion": "实验结果显示，在通信减少55-75%，公平提高56-68%，节能34-46%，支持100多个机构。框架还制定了基准测试套件、研究议程以及实施路线图，未来可以用于降低农村医院的财务负担并提高学术中心的性能。该研究有助于促进医疗人工智能的普及。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06257", "html_url": "https://arxiv.org/abs/2510.06257", "title": "具备不确定性意识和可泛化的神经解码器以实现量子LDPC编码", "title_en": "Toward Uncertainty-Aware and Generalizable Neural Decoding for Quantum LDPC Codes", "authors": "Xiangjun Mi,Frank Mueller", "background": "量子错误校正（QEC）对于可扩展的量子计算至关重要。然而，通过传统算法解码错误会导致较低的准确性（即逻辑错误的抑制）和高开销问题，这些问题可以通过基于推理的解码器得到缓解。目前，基于机器学习的解码器在两个至关重要的实用容错属性方面存在不足：可靠的不确定性量化和对以前未见过的代码的鲁棒泛化能力。本文正是为了解决这个问题", "innovation": "本文提出了一种名为QuBA的贝叶斯图神经解码器，结合了对点积和多头的注意机制，实现了对误差模式的表达性识别以及校准的不确定性评估，进一步开发了SAGU（Sequential Aggregate Generalization under Uncertainty）多代码训练框架，增强了跨域鲁棒性，使解码能力超越了训练集。实验表明，无论是QuBA还是SAGU，在错误率上都优于经典的BP基线方法，并且在某些代码上实现了十倍于传统方法的误差率减少，甚至超越了最先进的神经解码器。", "conclusion": "QuBA和SAGU在逻辑错误率方面超越了经典的BP基线方法和现有的神经解码器。特别是在某些代码上，QuBA和SAGU的性能甚至能够减少高达两数量级的逻辑错误率。SAGU能够达到与或超越QuBA领域特定训练方法的解码性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06261", "html_url": "https://arxiv.org/abs/2510.06261", "title": "AlphaApollo: 将基础模型和专业工具编排成一个自我演化的系统以实现深入的自主推理", "title_en": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning", "authors": "Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han", "background": "本文讨论了基础模型在推理时面临的两个瓶颈：模型固有的能力限制以及测试时迭代的不可靠性。这些瓶颈限制了基础模型在实际应用中的性能和可靠性。AlphaApollo系统通过协调多个模型和专业工具来解决这些问题，旨在提升基础模型的推理能力，实现更加准确、可验证的推理过程。", "innovation": "AlphaApollo系统创新性地结合了计算工具（Python及其数值和符号库）和检索工具（任务相关的外部信息），以执行精确计算并为决策提供支持。该系统还支持通过共享状态图进行多轮次、多模型解决方案的演进，以实现逐步优化。此外，通过工具使用分析，AlphaApollo显著提升了基础模型的能力上限，并在多个模型上的评估中展示了明显优于非工具基线的结果。", "conclusion": "AlphaApollo系统通过多模型协作和专业工具的支持，实现了基础模型推理能力的显著提升。在AIME 2024/2025评估中，AlphaApollo展示了在不同模型上的持续改进，提高了平均准确率和通过率。未来的工作将公布更多的实验结果和实施细节。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06262", "html_url": "https://arxiv.org/abs/2510.06262", "title": "Prakriti200: 200份阿育吠陀Prakriti评估问卷数据集", "title_en": "Prakriti200: A Questionnaire-Based Dataset of 200 Ayurvedic Prakriti Assessments", "authors": "Aryan Kumar Singh,Janvi Singh", "background": "该数据集包含根据经典阿育吠陀原则对个体的体征、生理和心理特征进行评估的标准化双语（英语-印地语）Prakriti评估问卷的回答。问卷包括关于身体特征、食欲、睡眠模式、能量水平和气质的24个选择题。这些问题遵循了AYUSH/CCRAS指南，确保数据收集的全面性和准确性。", "innovation": "该数据集创新地采用了强制回答和中性措辞的问题设计，避免了偏差，并隐藏了Dosha标签（Vata, Pitta, Kapha），从而提高了数据的可靠性和公平性。通过Google Forms收集数据并自动评分，使得个体特征与Dosha特定评分的对接变得容易。该数据集为计算智能、阿育吠陀研究和个人化健康分析提供了结构化的平台，支持特质分布分析、相关性研究和预测建模。同时，它还可以作为未来Prakriti研究和智能健康应用开发的参考。", "conclusion": "该数据集提供了研究计算智能、阿育吠陀和个性化健康分析的框架，支持特质分布分析、相关性研究和预测建模，同时也作为未来基于Prakriti的研究和智能健康应用开发的参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06258", "html_url": "https://arxiv.org/abs/2510.06258", "title": "开发气候变暖下阿拉斯加大地冻土融化顺序深度学习管道", "title_en": "Developing a Sequential Deep Learning Pipeline to Model Alaskan Permafrost Thaw Under Climate Change", "authors": "Addina Rahaman", "background": "气候变化条件下，自然的冻土解冻-冻结周期受到威胁，导致全年土壤温度超过0°C。阿拉斯加的表层冻土（活动层）的升温信号因高碳储存而增加了温室气体的释放。准确预测土壤温度对于风险缓解和稳定性评估至关重要；然而，许多现有方法忽略了驱动土壤热动态的多种因素。本研究提出了一种基于纬度的深度学习管道，用于建模多深度土壤温度。", "innovation": "该研究提出了一个基于动态再分析特征数据、静态地质和岩石学特征、季节窗口序列、长期气候强迫的衍生情景信号特征以及纬度带嵌入的空间敏感性的深度学习框架。该框架测试了五种深度学习模型：时间卷积网络（TCN）、Transformer、一维卷积长短时记忆（Conv1DLSTM）、门控循环单元（GRU）、双向长短时记忆（BiLSTM）。结果显示GRU在序列温度模式检测中表现最佳。校正后的CMIP5 RCP数据揭示了温度周期性趋势，但对不同情景之间的差异有限。", "conclusion": "该研究建立了一个端到端的框架，用于采用深度学习建模阿留申大地冻土融化，并提供了季节性、空间性和垂直温度上下文，而不会对特征选择施加内在限制。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06273", "html_url": "https://arxiv.org/abs/2510.06273", "title": "Vision Transformer for Transient Noise Classification", "title_en": "Vision Transformer for Transient Noise Classification", "authors": "Divyansh Srivastava,Andrzej Niedzielski", "background": "LIGO数据中的瞬态噪声（Glitches）干扰了引力波的检测。Gravity Spy项目已经将这些噪声事件分类到各种类别中。随着O3运行的开展，引入了两个新的噪声类别，需要训练新的模型以有效分类。", "innovation": "使用预训练的Vision Transformer (ViT-B/32)模型对由Gravity Spy数据集与LIGO O3a运行的两个额外类别组成的联合数据集进行训练，实现了92.26%的分类效率，展示了Vision Transformer在提高引力波检测准确性的潜力，通过有效区分瞬态噪声实现这一目标。", "conclusion": "通过Vision Transformer模型实现了针对LIGO数据中22个已有类别加O3a运行中的2个新类别的高效分类，证明了该模型在引力波检测中的应用前景。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06260", "html_url": "https://arxiv.org/abs/2510.06260", "title": "集成深度学习和LLM辅助报告的自动化皮肤病变诊断", "title_en": "Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis", "authors": "Sher Khan,Raz Muhammad,Adil Hussain,Muhammad Sajjad,Muhammad Rashid", "background": "皮肤恶性肿瘤需要早期检测以获得良好的结果，但当前的诊断方法存在观察者之间的一致性问题和接入不平等的问题。尽管AI具有潜力，现有的皮肤科诊断系统受限于同质化的架构、不同肤色的数据集偏差以及将自然语言处理视为独立的后处理解释而非临床决策的组成部分的碎片化方法。当前的治疗方法无法同时提高诊断的可靠性和沟通效果，因此未能在临床上取得重大影响，以解决这一关键的转化差距。", "innovation": "本文提出了一种统一框架，通过两个协同创新从根本上重新构想AI在皮肤科诊断中的整合。首先，一个旨在异质的、架构多样的卷积神经网络的集成提供了互补的诊断观点，并具有内在的不确定性机制，对于不一致的病例进行专家审查，以模仿临床最佳实践。其次，将大型语言模型的能力直接嵌入到诊断流程中，将分类输出转化为具有临床意义的评估，同时满足医学文档要求并提供患者中心化的教育。这种无缝集成生成了包含精确病灶特征化、易于理解的诊断推理和可操作的监测指导的结构化报告，进而赋予患者在访间之间识别早期预警信号的能力。通过在一个全面系统中同时解决诊断可靠性和沟通障碍，本文的方法填补了先前AI实现的临床上未能取得重大影响的关键转化缺口，促进了可部署的提高诊断精准度的皮肤科AI发展，同时在患者教育方面提供支持，最终提高皮肤病变的早期干预率。", "conclusion": "该框架代表了朝着具备提升诊断精准度的同时积极支持从初始检测到患者教育的整个护理连续体的目标取得的重要进步，最终提高了皮肤病变的早期干预率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06264", "html_url": "https://arxiv.org/abs/2510.06264", "title": "使用机器学习和统计建模分析孟加拉国7月革命中的镇压与动员", "title_en": "A Mixed-Methods Analysis of Repression and Mobilization in Bangladesh's July Revolution Using Machine Learning and Statistical Modeling", "authors": "Md. Saiful Bari Siddiqui,Anupam Debashis Roy", "background": "2024年7月孟加拉国革命是研究公民抗争的重要里程碑事件。本文探讨了这场由学生领导的公民起义成功的核心悖论：即政府暴力本意是镇压反对声音，但最终却促进了该运动的胜利。研究主要采用混合方法，首先建立定性的冲突时间线，然后通过对具体事件的多层次定量分析，来探讨镇压与动员之间的复杂关系。分析框架适用于类似7月革命这样爆发式现代起义事件的分析。初步合并回归模型突出强调了抗议活动的动量在延续这场运动中的关键作用。通过使用双重固定效应的面板模型，分离出因果效应，展示了局部镇压反弹效应的直接且统计上显著的作用。方程滞后自回归分析显示了在增加致命暴力后立即全国内动员的明确证据，且该效应是非线性的。结构断点分析显示了从冲突早期到第一波致死暴力引发的道德冲击后的统计上显著动态变化。机器学习分析进一步验证了这一结论，显示‘对抗议者的过度使用暴力’是最为主要的全国性升级预测因子。", "innovation": "本文采用混合方法研究，结合了定性的冲突时间线和定量的事件层次数据分析，使用双重固定效应面板模型分离因果效应。此外，通过方程滞后自回归分析和结构断点分析，发现了镇压导致反弹效应的非线性特征。同时还运用了机器学习（XGBoost）方法预测全国性升级，从预测角度验证了研究结论。", "conclusion": "本文结论认为，7月革命是由一种特定的、非线性的反弹效应驱动的，这种效应被特定的道德冲击触发，并通过病毒式的反应加速了这一视觉展示引发的国家暴力升级。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06274", "html_url": "https://arxiv.org/abs/2510.06274", "title": "从推理到学习：使用复杂性超出分布泛化揭开幻象", "title_en": "Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization", "authors": "Mohammad Mahdi Samiei Paqaleh,Arash Marioriyad,Arman Tahmasebi-Zadeh,Mohamadreza Fereydooni,Mahdi Ghaznavai,Mahdieh Soleymani Baghshah", "background": "近年来，人工智能的进步使机器从模式识别任务转向需要逐步推理的问题，特别是在大规模语言模型方面。尽管在学习中已经正式化了泛化和离分布（OoD）的概念，但推理能力的具体定义和度量标准仍然不清晰一致。文章提出了复杂性超出分布（Complexity OoD）泛化作为框架和问题设置来定义和测量推理的能力。复杂性OoD泛化是指当模型在测试实例的最小所需解决方案复杂度（无论是表示性的还是计算性的）超过所有训练示例时保持性能。这种视角统一了学习与推理：在低复杂度下可利用系统1（类比简单处理）解决的多数情况，在高复杂度下变成系统2（需要更多推理步骤）的难题，而系统2可以被视为对解决结构的泛化。", "innovation": "文章提出了一种称为复杂性超出分布（Complexity OoD）泛化的新框架，试图解决传统学习方法中缺乏明确的推理能力定义和度量标准的问题。文章还提供了具体的实操建议，包括如何在基准和评价指标设计中加入复杂性因素、重新考虑监督目标以便瞄准解决方案轨迹、以及寻找并设计针对复杂性OoD泛化的归纳偏置等。这些建议旨在解决推理到学习转换过程中的关键挑战，例如泛化推理能力、鲁棒性、灾难性遗忘和逐步校准等问题。", "conclusion": "复杂性OoD泛化不能仅通过数据规模来解决。克服这一挑战需要构建既能够明确处理复杂性又能够促进复杂性OoD泛化的架构和训练方法。未来的研究和开发工作应关注复杂性OoD泛化，推动推理能力的提升，使其更加可靠。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06277", "html_url": "https://arxiv.org/abs/2510.06277", "title": "通用且高效的基于对象无感知掩码的视觉目标条件强化学习", "title_en": "General and Efficient Visual Goal-Conditioned Reinforcement Learning using Object-Agnostic Masks", "authors": "Fahim Shahriar,Cheryl Wang,Alireza Azimi,Gautham Vasan,Hany Hamed Elanwar,A. Rupam Mahmood,Colin Bellinger", "background": "目标条件强化学习（GCRL）使得智能体能够使用统一的策略来学习多种目标。然而，GCRL 的成功依赖于目标表示的选择。现有方法，例如目标状态图像、3D 坐标和独热向量，面临泛化能力差、收敛速度慢等问题，且需要特殊摄像头等条件支持。", "innovation": "该研究提出了一种基于掩码的目标表示系统，提供对象无关的视觉线索给智能体，使其能够高效学习并具有更好的泛化能力。与现有方法相比，该方法避免了繁琐的距离计算，通过与掩模进行仿真训练，实现了对训练和未见过的对象达到99.9%的抓取准确性。实验展示了该方法在从零开始学习、模拟到现实世界的转移应用中的有效性，同时可以不需要目标的位置信息进行拾取任务的高精度执行。此外，该方法利用预训练的开放式词汇物体检测模型生成掩模来实现从零开始学习和模拟到现实世界的转移应用。", "conclusion": "研究提出了一种基于掩码的视觉目标条件强化学习方法，此方法可以高效地学习并具有更好的泛化能力。这种方法能够用于高精度的拾取任务，同时不需要目标的位置信息，并通过模拟到实时的转移应用，展示了其在不同物理机器人上的适用性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06286", "html_url": "https://arxiv.org/abs/2510.06286", "title": "轨距上的质量守恒 - 重新思考冰流向量场的物理指导下深度学习方法", "title_en": "Mass Conservation on Rails - Rethinking Physics-Informed Learning of Ice Flow Vector Fields", "authors": "Kim Bente,Roman Marchant,Fabio Ramos", "background": "为了可靠地预测未来的海平面上升，冰川模型需要符合物理规律的输入。在使用这些模型来插值南极冰流向量场时，引入质量守恒等物理原理可以提高模型的物理一致性、准确性和鲁棒性。传统的物理指导神经网络（PINNs）通过软惩罚来强制执行物理原则，提供灵活性但没有提供物理保证。", "innovation": "作者提出了无散度神经网络（dfNNs），这是一种新的方法，通过向量微积分原理精确地强制执行局部质量守恒。与PINNs相比，dfNNs提供了物理保证，而不是仅仅提供灵活性。通过结合使用dfNNs和方向指导（一种利用广泛卫星速度数据的学习策略），作者展示了这些方法在冰流向量场插值中的优越性能。", "conclusion": "研究结果表明，"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06299", "html_url": "https://arxiv.org/abs/2510.06299", "title": "面向全球森林结构复杂性制图的空间激光雷达和合成孔径雷达深度融合可扩展方法", "title_en": "Scalable deep fusion of spaceborne lidar and synthetic aperture radar for global forest structural complexity mapping", "authors": "Tiago de Conto,John Armston,Ralph Dubayah", "background": "森林结构复杂性度量将多种冠层属性综合成一个反映栖息地质量和生态系统功能的单一数值。全球生态系统动力学调查（GEDI）的机载激光雷达有助于在温带和热带森林中绘制结构复杂性，但由于其稀疏采样限制了连续高分辨率的绘制。", "innovation": "采用了一种可扩展的深度学习框架，将GEDI观测与多模态SAR数据集融合，生成全球高分辨率（25米）涵盖所有区域的森林结构复杂性地图。这种方法通过迁移学习能够在几乎无成本的情况下预测其他森林结构变量。该模型具有高精度（全球R2 = 0.82），其参数量少于40万，便于在任何规模上进行数据集处理而无需专门的计算基础设施。", "conclusion": "该方法支持全球森林结构动态的连续多时相监测，并为在气候变化下进行生物多样性保护和生态系统管理提供了工具。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06295", "html_url": "https://arxiv.org/abs/2510.06295", "title": "使用意识感知损失和自适应瓦片的高效高分辨率图像编辑", "title_en": "Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling", "authors": "Young D. Kwon,Abhinav Mehrotra,Malcolm Chadwick,Alberto Gil Ramos,Sourav Bhattacharya", "background": "高分辨率（4K）图像到图像的合成在移动应用中变得越来越重要。现有的用于图像编辑的扩散模型在资源受限的设备上面临着内存和图像质量方面的重大挑战。现有的图像编辑方法在较低资源的设备上很难实现高效且高质量的编辑。", "innovation": "提出了一种名为MobilePicasso的新颖系统，能够在高分辨率下进行高效的图像编辑，同时减少计算成本和内存使用。该系统包括三个阶段：（i）在标准分辨率下进行图像编辑，使用意识感知损失；（ii）应用潜在投影以克服像素空间的转换；（iii）采用自适应上下文保留瓦片将编辑后的图像潜在特征放大到更高分辨率。MobilePicasso不仅提高了图像质量，在用户研究中比现有方法提高了18-48%，减少了14-51%的幻觉现象，并且显著降低了延迟，比基于服务器的高分辨率图像编辑模型在A100 GPU上的运行速度快了55.8倍，同时内存使用仅增加了9%。", "conclusion": "MobilePicasso在保持高质量的前提下，显著降低了计算开销和延迟，甚至在某些情况下比服务器上运行的模型更快。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06372", "html_url": "https://arxiv.org/abs/2510.06372", "title": "浅层神经网络复杂性的通用构造性上界", "title_en": "A General Constructive Upper Bound on Shallow Neural Nets Complexity", "authors": "Frantisek Hakl,Vit Fojtik", "background": "该研究关注的是浅层神经网络在给定精度下逼近紧集上连续函数所需的神经元数量的上界问题。这种上界是通过借鉴Stone-Weierstrass定理的一种特定证明方法得到的。", "innovation": "该方法具有建设性，并且比之前类似的问题中给出的边界更为广泛，因为它适用于任何紧集上的任何连续函数。", "conclusion": "该研究提供了浅层神经网络在任何紧集上逼近任意连续函数的通用构造性上界。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06335", "html_url": "https://arxiv.org/abs/2510.06335", "title": "基于条件去噪扩散模型的从高度下采样数据中稳健的MR图像重建", "title_en": "Conditional Denoising Diffusion Model-Based Robust MR Image Reconstruction from Highly Undersampled Data", "authors": "Mohammed Alsubaie,Wenxi Liu,Linxia Gu,Ovidiu C. Andronesi,Sirani M. Perera,Xianqi Li", "background": "磁共振成像（MRI）是现代医学诊断中的关键工具，但其较长的采集时间仍然是一个关键限制，特别是在时间紧迫的临床场景中。虽然下采样策略可以加速图像采集，但它们通常会导致图像伪影和质量下降。近年来，扩散模型展示了从下采样数据重建高保真图像的潜力，这得益于学习强大的图像先验能力；然而，大多数现有方法要么依赖无监督评分函数而缺乏配对监督数据，要么仅将数据一致性作为后处理步骤应用。", "innovation": "本文提出了一种条件去噪扩散框架，结合了迭代的数据一致性校正策略，与之前的方法不同，该框架将测量模型直接嵌入到每一次逆向扩散步骤中，使用配对的下采样-真实数据进行模型训练，实现了生成灵活性与MRI物理显式约束相结合的混合设计。实验证明，该框架在SSIM、PSNR和LPIPS指标上均优于最新的深度学习和基于扩散的方法，LPIPS更能准确捕捉感知上的改进。", "conclusion": "实验结果表明，将条件监督与迭代一致性更新结合可以显著提高像素级别保真度和感知的真实感，进一步验证了该方法在加速MRI重建中的优势。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06288", "html_url": "https://arxiv.org/abs/2510.06288", "title": "BuilderBench — 通用智能体基准", "title_en": "BuilderBench -- A benchmark for generalist agents", "authors": "Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach", "background": "当前的AI模型主要通过模仿和强化学习来训练，因此它们在解决超出现有数据限制的新问题时面临挑战。为解决此类问题，智能体需要开发探索和经验学习的技能。寻找一个可扩展的学习机制，让智能体通过互动来学习仍然是一个重大挑战。本研究介绍了建立一种基准——BuilderBench，以加速关于智能体预训练的研究。BuilderBench要求智能体学习使用积木构建任何结构的能力，配备了硬件加速的机器人代理模拟器和一个包含42多种不同目标结构的任务套件，旨在测试物理、数学和长时规划的理解能力。", "innovation": "BuilderBench旨在通过环境中的开放探索，加速研究人员对智能体预训练的研究。它提供了一个硬件加速的模拟环境和一个详细的任务套件，要求智能体学习使用积木构建任何结构的能力，从而需要他们进行实际的尝试和策略组合。该研究引入了一种“训练轮”协议，让智能体专注于构建单一目标结构，为研究人员提供参考点。这为探索和学习机制提供了新的思路，旨在促进智能体的多功能性。", "conclusion": "实验结果表明，许多任务对当前算法构成了挑战。因此，该研究还提供了六个不同算法的单文件实现，为研究人员提供参考点。BuilderBench能够促进关于智能体预训练、探索和学习机制的研究，这将推动新一代智能体的发展。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06290", "html_url": "https://arxiv.org/abs/2510.06290", "title": "Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene Identification across Multi-View Biological Graphs", "title_en": "Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene Identification across Multi-View Biological Graphs", "authors": "Bang Chen,Lijun Guo,Houli Fan,Wentao He,Rong Zhang", "background": "探究癌症驱动基因（CDGs）对于理解癌症机制和开发靶向疗法至关重要。图神经网络（GNNs）最近被用于通过捕捉生物互作网络中的模式来识别CDGs。然而，大多数基于GNN的方法依赖单一的蛋白质-蛋白质互作（PPI）网络，忽视了其他生物网络的互补信息。一些研究通过一致性约束调整特征实现多个网络的整合，以学习统一的基因表示用于CDG识别。然而，这种特征层次的融合常常假设基因关系在不同网络间具有一致性，这可能忽略了网络异质性并引入了相互矛盾的信息。为解决这一问题，该研究提出了一种新的框架——Soft-Evidence Fusion Graph Neural Network (SEFGNN)，用于多视图生物图谱中的CDG识别决策层次上融合多个网络。SEFGNN不强制特征层次一致，而是将每个生物网络视为独立的证据来源，并使用Dempster-Shafer理论（DST）在决策层次上进行不确定性感知融合。此外，引入了Soft Evidence Smoothing (SES)模块来缓解DST带来的过度自信风险，同时保持辨别性能，提高排名稳定性。", "innovation": "提出了一种新的框架——Soft-Evidence Fusion Graph Neural Network (SEFGNN)，在决策层次上融合多视图生物图谱中的多个网络。SEFGNN不强制特征层次一致性，而是将每个生物网络视为独立的证据来源，并使用Dempster-Shafer理论（DST）进行不确定性感知融合，引入了Soft Evidence Smoothing (SES)模块来缓解DST带来的过度自信风险，同时保持辨别性能，提高排名稳定性。该方法在三个癌症数据集上的实验表明，SEFGNN能够持续超越现有的先进基准方法，展现了发现新型CDGs的强大潜力。", "conclusion": "实验结果表明，SEFGNN在三个癌症数据集上表现优异，超越了现有的先进基准方法，展示了在多个生物网络中识别癌症驱动基因的强大潜力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06515", "html_url": "https://arxiv.org/abs/2510.06515", "title": "基于强化学习的在线匹配：一种专家策略 orchestration 策略", "title_en": "Online Matching via Reinforcement Learning: An Expert Policy Orchestration Strategy", "authors": "Chiara Mignacco,Matthieu Jonckheere,Gilles Stoltz", "background": "在线匹配问题在许多复杂的系统中普遍存在，包括云计算服务、在线市场以及器官交换网络等，及时、有原则的决策对于维持系统性能至关重要。传统设定下的启发式方法简单且易于解读，但通常针对特定的操作模式设计，当条件发生变化时，会导致效率低下。因此，需要一种能够适应变化条件的在线匹配方法，以提高系统整体效率和性能。", "innovation": "本文提出了一种基于强化学习（RL）的方法，通过学习协调在特定操作模式下运行的效果良好的专家策略，利用这些策略的互补优点。该方法建立在Adv2框架之上，结合了专家决策，并能够自然地应用于只有估计值函数可用的情况下。该研究还建立了期望和高概率后悔保证，并推导出时间差分学习的新颖有限时间偏差界，使得即使在常步长情况下和非平稳动态系统中也能可靠地估算优势。此外，为了支持可扩展性，引入了一种神经元演员-评论家架构，该架构可以跨大型状态空间通用，同时保持可解释性。模拟结果显示，协调策略不仅收敛速度更快，而且在系统层次上的效率也高于独立的专家和传统的RL基准。", "conclusion": "研究结果表明，结构化、适应性学习可以改进复杂资源分配和决策过程的建模和管理。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06353", "html_url": "https://arxiv.org/abs/2510.06353", "title": "TransFIRA: 转移学习在面部图像可识别性评估中的应用", "title_en": "TransFIRA: Transfer Learning for Face Image Recognizability Assessment", "authors": "Allen Tu,Kartik Narayan,Joshua Gleason,Jennifer Xu,Matthew Meyn,Tom Goldstein,Vishal M. Patel", "background": "在如监控、视频和网络图像等非受限环境中进行人脸识别时，面临着姿态、模糊、光照和遮挡等极端变化。传统视觉质量指标无法准确预测输入图像在部署模型中是否真正可识别。现有方法通常依赖视觉启发式方法、人工标注或计算密集的生成流水线，使得预测结果与模型的决策几何学脱节。因此，需要一种无需标注且能紧密关联模型决策的指标和方法来评估图像可识别性。", "innovation": "提出了TransFIRA（可转移学习的面部图像识别性评估），这是一种轻量化且无需标注的框架，直接将可识别性与嵌入空间关联起来。TransFIRA带来了三项进步：(i) 通过分类中心相似度（CCS）和分类中心角度分离（CCAS）定义可识别性，提供第一个与决策边界对齐的自然筛选和加权标准；(ii) 可识别性驱动的聚合策略，在BRIAR和IJB-C数据集上实现最先进的验证准确率，并几乎将真实识别的相关性提高一倍，而不需要外部标签、启发式或特定骨干训练；(iii) 在面部之外进行了扩展，包括基于模型解释性，揭示退化和个体因素如何影响可识别性，以及首次实现面部识别意识的身体识别评估。", "conclusion": "实验结果表明，面部上达到最先进的结果，身体识别上表现强劲，且对跨数据集偏移具有鲁棒性。总体而言，这些贡献确立了TransFIRA作为一种统一且基于几何学的可识别性评估框架，该框架模型特定、准确、可解释且跨模态可扩展，显著推动了可识别性质量评估领域在准确度、可解释性和涵盖范围方面的发展。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06541", "html_url": "https://arxiv.org/abs/2510.06541", "title": "簇路径：神经网络中的解释性导航", "title_en": "Cluster Paths: Navigating Interpretability in Neural Networks", "authors": "Nicholas M. Kroeger,Vincent Bindschaedler", "background": "尽管现代深度神经网络在视觉任务上取得了令人印象深刻的表现，但它们仍然在决策过程上缺乏透明度，存在不合理的信任、未被检测出的偏见以及意外的失败风险。", "innovation": "提出了簇路径这一后处理解释性方法，该方法将选定层的激活值进行聚类，并将每个输入表示为其聚类ID的序列。引入了四种评估簇路径的度量方法：路径复杂性（认知负担）、加权路径纯度（分类一致性）、决策一致性的信仰度（预测准确性）和路径一致性（扰动下的稳定性）。", "conclusion": "簇路径能够准确识别并解释图像的概念（如颜色调板、纹理或对象环境），无论是在小型网络还是大型的Vision Transformer中都具有良好的可扩展性和解释性，同时可以作为有效的异常值检测器，在模型生成过度自信的预测之前可靠地标识异常样本。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06530", "html_url": "https://arxiv.org/abs/2510.06530", "title": "从描述到检测：基于LLM的适应性O-RAN兼容盲DoS检测在5G及以后时代", "title_en": "From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond", "authors": "Thusitha Dayaratne,Ngoc Duy Pham,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph", "background": "随着5G的引入，移动通信的质量和体验有了显著提升，并预计这些提升将在5G之后继续。然而，控制平面协议，如Radio Resource Control (RRC) 和 Non-Access Stratum (NAS)，的安全性存在漏洞，这些漏洞可能导致严重的安全威胁，例如盲DoS攻击。尽管已有利用基于规则的系统或传统机器学习的方法进行异常检测，但这些方法存在需要大量训练数据、预设规则以及解释性有限等局限。", "innovation": "提出了一种基于大型语言模型（LLMs）的零样本模式下的新颖异常检测框架，可以在无序数据和简短的自然语言攻击描述中使用O-RAN架构。该框架分析了提示变化的鲁棒性，证明了自动化攻击描述的可行性，并表明检测质量依赖于描述的语义完整性而非其措辞或长度。通过使用RRC/NAS数据集进行评估，并与开源和专有LLM实现进行广泛比较，展示了其在攻击检测中的优越性能。进一步在O-RAN实时约束下验证了该框架的实际可行性。", "conclusion": "该框架展示了在O-RAN架构下检测其他第3层攻击的潜力，为5G及以后时代的移动通信安全提供了创新的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06538", "html_url": "https://arxiv.org/abs/2510.06538", "title": "Auto-Prompt Ensemble for LLM Judge", "title_en": "Auto-Prompt Ensemble for LLM Judge", "authors": "Jiajie Li,Huayi Zhang,Peng Lin,Jinjun Xiong,Wei Xu", "background": "现有的大规模语言模型（LLM）评估者往往无法识别并评估人类评估背后的隐含标准，因此常常忽略重要的评估维度，这影响了LLM评估者的可靠性。为了解决这一问题，论文提出了一种自动提示集成（Auto-Prompt Ensemble，APE）框架，该框架能够从失败案例中自动学习评估维度，并通过一种新的置信度估计方法——集体置信来决定是否采用额外评估维度的判断结果，从而提升LLM评估者的可靠性。", "innovation": "APE框架创新性地提出了一种自动学习和利用额外评估维度的机制，通过集体置信来决定何时采用这些维度的判断结果。APE能从其失败案例中自动学习评估维度，显示出在多种基准测试中提高LLM评估者可靠性的能力。例如，APE在零样本设置中将GPT-4o的奖励基准协议一致性率从87.2%提高到了90.5%。", "conclusion": "APE为LLM评估者提供了一个原理性的方法，利用测试时的计算能力，弥补了人类和LLM评估者之间的评价差距。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06534", "html_url": "https://arxiv.org/abs/2510.06534", "title": "有益的代理搜索推理行为及其有效后训练方法", "title_en": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them", "authors": "Jiahe Jin,Abhijay Paladugu,Chenyan Xiong", "background": "代理搜索利用大型语言模型（LLMs）来解释复杂的用户信息需求，并执行规划、搜索和信息综合的多步骤过程以提供答案。这一范式为LLMs在与检索系统和更广泛的互联网交互时的推理和代理能力带来了独特的挑战。本文探讨了代理搜索中的有效推理行为模式，具体分析了成功的代理搜索轨迹，并提出了四种有益的推理行为：信息验证、权威评估、自适应搜索和错误恢复。这些发现的基础上，提出了称为行为激发的技术，用于训练更有效的代理搜索模型。", "innovation": "本文提出了一种基于推理的LLM管道，通过分析代理搜索轨迹，识别并提取四种有益的推理行为，并利用这些发现提出了一种称为行为激发（Behavior Priming）的技术。该技术合成了表现出这些四种行为的代理搜索轨迹，并通过监督微调（SFT）和标准强化学习（RL）纳入代理搜索模型。实验结果表明，与直接使用RL训练代理搜索模型相比，行为激发在Llama3.2-3B和Qwen3-1.7B型号上分别取得了超过35%的性能提升。关键发现是，SFT数据中的期望推理行为而不是最终答案的正确性是实现强大表现的关键因素。", "conclusion": "我们进一步分析了背后的机制：引入的推理行为使得模型在探索（更高的pass@k和熵）和测试时缩放（更长的轨迹）能力方面更具有效性，为强化学习提供了坚实的基础。我们将在开源平台上发布代码。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06528", "html_url": "https://arxiv.org/abs/2510.06528", "title": "BACHI: 在流行乐和古典乐中通过掩码迭代解码实现边界感知的符号和弦识别", "title_en": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked Iterative Decoding on Pop and Classical Music", "authors": "Mingyang Yao,Ke Chen,Shlomo Dubnov,Taylor Berg-Kirkpatrick", "background": "自动和弦识别（ACR）基于深度学习模型已取得了显著的进步，但仍然存在两项关键挑战。首先，现有的工作主要集中在音频域和弦识别上，而由于可用数据的稀缺性，符号音乐（如乐谱）的和弦识别受到了限制。其次，现有的方法仍然忽略了与人类音乐分析实践相匹配的策略。为了解决这些问题，本文做出了两项贡献：首先，提出了POP909-CL，这是增强的POP909数据集，包括与节拍对齐的内容和由人类校正的和弦、节拍、调式和拍号标签；其次，提出了BACHI模型，这是一种分解任务不同决策步骤的符号和弦识别模型，具体包括边界检测和迭代排列和弦根、性质和低音。这种机制模仿了人类耳朵的训练方式。实验表明，BACHI在古典音乐和流行音乐基准上的和弦识别性能达到了最先进的水平，且消融研究验证了每个模块的有效性。", "innovation": "提出了增强版的POP909数据集（POP909-CL），并设计了BACHI模型来分解和弦识别任务，采用了边界检测和迭代排列和弦根、性质和低音的方法，从而提供了一种与人类音乐分析实践相符的和弦识别机制，能够显著提高和弦识别的性能，特别是在符号音乐和流行乐和古典音乐领域。", "conclusion": "BACHI模型在流行音乐和古典音乐基准测试中达到了最先进的和弦识别性能，验证了每个模块的效用，提出了增强训练的数据集POP909-CL极大地改善了符号音乐和弦识别的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06361", "html_url": "https://arxiv.org/abs/2510.06361", "title": "通过张量网络指导的神经系统的重整化", "title_en": "Diffusion-Guided Renormalization of Neural Systems via Tensor Networks", "authors": "Nathan X. Kodama", "background": "远非平衡态，神经系统自组织于多个尺度。为了在神经科学和人工智能中利用多尺度自组织，需要一个计算框架来模拟高维神经网络的有效非平衡动力学。非平衡热力学和表征几何提供了理论基础，但需要可扩展的数据驱动技术来从部分抽样观察中建模高维神经网络的集体性质。重整化是一种关键的粗粒化技术，用于研究许多体和非线性动力系统中涌现的标度性质。然而，粗粒化复杂的动力网络仍然是一个未解决的问题，影响了许多计算科学领域。近期的基于扩散的重整化受量子统计力学启发，在最大熵变化或信息传输时接近熵转换的网络进行粗粒化。本文作者通过生成跨越多尺度的对称性破坏表示，并使用张量网络提供可扩展算法，来探索基于扩散的神经系统的重整化方法。通过指导扩散重整化结合了耗散神经系统的微观尺度和介观尺度动力学，为微观尺度构建了可扩展的图推断算法，以便从抽样神经活动中发现社区结构，并通过元图和联合概率函数生成重整化群流。在介观尺度上，指导扩散重整化旨在学习耗散神经轨迹的有效非平衡动态，这些轨迹占据低维子空间，从而在系统神经科学和人工方言中实现了粗到细的控制。", "innovation": "本文提出了一种基于扩散的重整化方法，通过生成跨越多尺度的对称性破坏表示，并使用张量网络提供可扩展算法。这种方法用于模拟高维神经网络的有效非平衡动力学，特别是在从部分抽样观察中建模高维神经网络的集体性质时。该方法能够结合微视和介观尺度的神经动力学，并通过图推断算法发现神经活动的社区结构。总之，这项工作提供了一种新型的可扩展算法，用于理解和模拟复杂的神经动力学，特别是在非平衡态下。这种方法有望为神经科学和人工智能提供新的研究工具和方法。", "conclusion": "本文通过提出一种新的可扩展的图推断算法，结合基于扩散的指导重整化方法，实现了从抽样神经活动中发现社区结构，并通过张量网络生成重整化群流。这种方法能够结合微视和介观尺度的动力学，有效地处理高维神经网络的集体性质。总体而言，这些技术为神经科学和人工智能领域提供了新的工具，能够更深入地理解耗散神经系统的复杂动态。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06440", "html_url": "https://arxiv.org/abs/2510.06440", "title": "使用纽约州运输部相机图像和天气预报数据的路面状况检测", "title_en": "Road Surface Condition Detection with Machine Learning using New York State Department of Transportation Camera Images and Weather Forecast Data", "authors": "Carly Sutter,Kara J. Sulia,Nick P. Bassill,Christopher D. Wirz,Christopher D. Thorncroft,Jay C. Rothenberger,Vanessa Przybylo,Mariana G. Cains,Jacob Radford,David Aaron Evans", "background": "纽约州运输部（NYSDOT）拥有一个路边交通摄像头网络，这些摄像头被NYSDOT和公众用来观察道路状况。然而，NYSDOT通过亲自驾车和观察实时摄像头来评估道路状况，这些任务尽管能够提供准确的数据，但由于天气条件恶劣往往非常耗费人力，且至关重要。因此，需要利用机器学习模型来辅助NYSDOT，通过自动识别道路状况，从而提高工作效率，尤其是在冬季恶劣天气条件下。", "innovation": "本文研究采用卷积神经网络和随机森林模型，通过训练摄像机图像和天气数据来预测道路表面状况。研究使用了约22,000张由人工标注的不同路面积雪和湿滑状态的照片。研究重点是提高模型的通用性以满足运营决策者的需求，并实现了81.5%的准确率，即使在未见过的摄像头上也能进行准确预测。这项研究不仅提供了新的技术手段，而且还提高了冬季天气下道路状况评估的效率和准确性。", "conclusion": "研究结果表明，利用机器学习模型能够有效支持纽约州运输部在冬季天气事件期间的道路状况评估。这不仅简化了当前的评估流程，还提高了决策过程的效率和准确性。未来可以进一步扩大模型的应用范围，包括更多类型的天气状况和道路状况，以进一步优化交通管理。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06548", "html_url": "https://arxiv.org/abs/2510.06548", "title": "从加速到饱和：启动预训练的缩放行为", "title_en": "From Acceleration to Saturation: Scaling Behavior of Bootstrapped Language Model Pretraining", "authors": "Seng Pei Liew,Takuya Kato", "background": "启动预训练，即再利用已预训练的基础模型进行进一步的预训练，如持续预训练或模型增长，有望降低从零开始训练语言模型的成本。然而，其有效性尚不明确，尤其是在应用于过度训练的基础模型时。现有研究在此方向上的进展还需进一步探索和验证其在多阶段预训练策略中的实际效果和效率边界。", "innovation": "研究发现启动预训练的缩放效率以可预测方式下降：第二阶段预训练标记数的缩放指数随着用于预训练基础模型的标记数的增加呈对数方式减少。首阶段和第二阶段标记的联合依赖性可通过简单的缩放定律准确建模。饱和效应揭示了多阶段预训练策略中的一种基本权衡：模型预训练得越充分，启动预训练带来的额外增益就越少。这些发现为高效语言模型训练提供了实用见解，并引起了对过度训练模型再利用的重要考虑。", "conclusion": "该研究为高效语言模型训练提供了实用见解，揭示了多阶段预训练策略中的一种基本权衡，并提出了重要考虑，用于过度训练模型的再利用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06350", "html_url": "https://arxiv.org/abs/2510.06350", "title": "要求导向：在线内容审核中预测规则违规的问答方法", "title_en": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation", "authors": "Mattia Samory,Diana Pamfile,Andrew To,Shruti Phadke", "background": "在线社区依赖于平台政策和社区制定的规则来界定适当行为并维持秩序。然而，这些规则在各社区之间差异巨大，随时间演变并且执行不一致，这为透明度、治理和自动化带来了挑战。本文分析了规则与其在大规模下的执行关系，提出了ModQ，一个适用于规则敏感内容审核的新颖问答框架。ModQ 不同于之前的分类或生成方法，它在推理时会基于完整的社区规则集，并且能够识别哪条规则最适用于给定的评论。研究团队在Reddit和Lemmy的数据集上训练了两个模型变体，Lemmy的数据集是从公开的管理日志和规则描述中构建的。通过大规模数据集的实验表明，这两个模型在识别内容违规的规则时表现优于最先进的基线，同时保持了轻量级和可解释性。研究发现，ModQ能够有效地泛化到未见过的社区和规则，支持低资源环境下的审核工作和动态治理环境。", "innovation": "本文提出了一个新颖的问答框架ModQ，用于规则敏感的内容审核。ModQ不同于现有的分类或生成方法，它在推理阶段会基于完整的社区规则集，并能够确定那些规则最适合给定的评论。该框架适用于大规模数据集，并能够在低资源环境下有效泛化，支持社区内容的动态治理。", "conclusion": "通过训练ModQ的两个变体模型，即提取式问答和多项选择问答，研究证明了这两种模型在识别相关内容违规规则时超过了最先进的基线模型，同时保持了轻量级和可解释性。ModQ模型有效地泛化到未见过的社区和规则，这对于低资源和动态治理环境下的内容审核非常有帮助。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06596", "html_url": "https://arxiv.org/abs/2510.06596", "title": "SDQM: 合成数据质量度量标准在目标检测数据集评估中的应用", "title_en": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation", "authors": "Ayush Zenith,Arnold Zumbrun,Neel Raut,Jing Lin", "background": "机器学习模型性能高度依赖于训练数据。大规模、高质量标注的数据集稀缺，这是创建稳健模型的主要挑战之一。为此，通过仿真和生成模型产生的合成数据开始被视为一种有前景的解决方案，可以增加数据集的多样性和提高模型的性能、可靠性和弹性。但要评估这类生成数据的质量则需要有效的度量标准。", "innovation": "本文提出了合成数据集质量度量标准 (SDQM)，用于在无需训练模型收敛的情况下评估目标检测任务的数据质量。SDQM 能够更高效地生成和选择合成数据集，尤其在资源受限的目标检测任务中，解决了一个关键挑战。实验结果显示，SDQM 与 YOLOv11（一种领先的目标检测模型）的均值平均精度 (mAP) 分数之间存在较强的相关性，而以往的度量标准仅表现出中等或较弱的相关性。同时，SDQM 还提供了改善数据集质量的实用建议，减少了昂贵的迭代训练的需求。", "conclusion": "SDQM 是一个具有可扩展性和效率的度量标准，为评估合成数据设定了新的标准。模型评估的代码可在以下链接获取：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06647", "html_url": "https://arxiv.org/abs/2510.06647", "title": "细粒度差距依赖的Q学习", "title_en": "Q-Learning with Fine-Grained Gap-Dependent Regret", "authors": "Haochen Zhang,Zhong Zheng,Lingzhou Xue", "background": "现有模型自由强化学习算法在周期性表征马尔可夫决策过程中的最坏情况遗憾已经达到了最小化标准，但它们的差距依赖性边界仍然粗糙，无法充分捕捉次优性差距的结构。", "innovation": "文章建立了一种新的分析框架，明确区分最优和次优状态动作对，首次为UCB-Hoeffding算法提供了细粒度的遗憾上界。对于非-UCB算法，文章修正了AMB算法，解决了其更新中的不当截断和其收敛性分析中的条件违背问题，首次为非-UCB方法建立了严格的细粒度差距依赖性遗憾界，实验证明这一算法优于AMB。", "conclusion": "通过提出适用于UCB和非-UCB方法的细粒度遗憾界，丰富了强化学习的理论框架，并通过实验验证了新方法的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06563", "html_url": "https://arxiv.org/abs/2510.06563", "title": "调整量子机器学习以预测化学键键离解能", "title_en": "Adapting Quantum Machine Learning for Energy Dissociation of Bonds", "authors": "Swathi Chandrasekhar,Shiva Raj Pokhrel,Navneet Singh", "background": "准确预测键离解能（BDEs）是理解反应机理以及分子和材料理性设计的关键。本文对比了量子和经典机器学习模型在预测BDE方面的性能，使用了涵盖原子性质（原子序数，杂化状态）、键特性（键序，键型）和局部环境描述符的化学上精炼的特征集。研究范围涵盖了化学上常见的中等范围BDE区间。定量和相对误差度量、阈值准确性和误差分布综合评估表明，顶级量子模型（QCNN，QRF）在预测准确性和稳健性方面与经典的集成模型和深度网络相当，特别是在化学上常见的中等范围BDE区域。研究结果为增强分子性质的量子预测提供了透明基准，并为推动量子计算化学向接近化学准确性的目标奠定了实际基础。", "innovation": "本文的核心创新在于提出了一个系统的可复制基准，比较了量子和经典机器学习模型在BDE预测中的表现。同时，使用多量子架构实现的ZZFeatureMap编码结合variational ansatz的量子框架，包括VQR、QSVR、QNN、QCNN和QRF，这些量子模型在绝对和相对误差度量、阈值准确性和误差分布上表现优秀，特别是在化学上常见的中间范围的BDE区间内，达到了与先进的经典模型类似的表现水平。", "conclusion": "研究结果为量子增强的分子性质预测建立了透明基准，提供了在接近化学准确性的目标上发展的实际基础。未来的研究将可以在此基础上进一步推进量子计算化学技术的实用化。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06629", "html_url": "https://arxiv.org/abs/2510.06629", "title": "Spiking Neural Networks中未监督后训练后门检测和抑制", "title_en": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks", "authors": "Jiachen Li,Bang Wu,Xiaoyu Xia,Xiaoning Liu,Xun Yi,Xiuzhen Zhang", "background": "Spiking Neural Networks (SNNs)因其与人工神经网络(ANNs)相比的能源效率优势而受到越来越多的关注。然而，它们在后门攻击下的安全性方面受到了较少的关注。现有的针对ANNs开发的防御方法在SNNs中效果不佳或容易被绕过，因为SNNs具有事件驱动和时间依赖性。", "innovation": "本文识别了传统SNN后门防护的关键障碍，并提出了一种基于时间膜电位后训练无监督检测框架——时间膜电位后门检测(TMPBD)。TMPBD利用最终突发层中时间膜电位(TMP)的容错统计性来检测目标标签，无需任何攻击知识或数据访问。此外，文中还引入了一种鲁棒性的抑制机制——神经树突抑制后门抑制(NDSBM)，它通过钳制早期卷积层之间的树突连接来抑制恶意神经元，同时保留良性行为，这些被TMP从小的、干净的、未标记的数据集中提取所指导。", "conclusion": "在多个神经形态基准测试和先进的输入感知动态触发攻击上进行的广泛实验表明，TMPBD的检测精度达到100%，NDSBM将攻击成功率从100%降低到8.44%，在与检测结合使用的情况下降低到2.81%，且不损害干净的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06621", "html_url": "https://arxiv.org/abs/2510.06621", "title": "FEAorta: 从3D CT图像进行主动脉有限元分析的全自动框架", "title_en": "FEAorta: A Fully Automated Framework for Finite Element Analysis of the Aorta From 3D CT Images", "authors": "Jiasong Chen,Linchen Qian,Ruonan Gong,Christina Sun,Tongran Qin,Thuy Pham,Caitlin Martin,Mohammad Zafar,John Elefteriades,Wei Sun,Liang Liang", "background": "主动脉瘤始终在导致美国人口死亡的前20种原因之中。胸主动脉瘤表现为胸主动脉壁异常鼓起，是成年人死亡的主要原因之一。从生物力学角度看，破裂发生于作用在主动脉壁上的应力超过壁强度之刻。应力分布可以通过计算生物力学分析获得，尤其是结构有限元分析。对于风险评估，可以通过比较应力与材料强度来利用材料失效模型计算胸主动脉瘤的概率性破裂风险。尽管目前有工程工具可用于患者级别的主动脉瘤破裂风险评估，但由于两个主要障碍限制了临床应用：一是现有的患者特定解剖建模仍然是手动分割，时间和复杂使得难以扩展到大量患者群体；二是传统的FEA模拟资源密集且与时间敏感的临床工作流程不兼容。我们团队通过开发PyTorch FEA库和FEA DNN集成框架克服了第二个障碍。我们的方法不仅将FEA功能集成到PyTorch FEA中，还利用静不定原理将FEA基于的应力计算时间缩短到每次病例约三分钟，并进一步通过PyTorch FEA库集成DNN和FEA，将计算时间缩短到每次病例只需几秒钟。这篇论文关注通过开发一个能直接从3D CT图像生成患者特定有限元模型的端到端深度神经网络来克服第一个障碍。", "innovation": "通过开发PyTorch FEA库和FEA DNN集成框架，我们成功解决了临床应用中的两个主要障碍。首先，将FEA功能集成到PyTorch框架中，并利用静不定原理，将计算应力时间缩短到每例约三分钟。其次，通过在PyTorch FEA库中集成DNN和FEA，进一步将计算时间缩短到每例只需几秒钟，并开发了能够直接从3D CT图像生成患者特定解剖模型的深度神经网络。这些创新显著加快了临床工作流程的速度，提高了分析的效率。", "conclusion": "我们开发了一个全自动框架FEAorta，可以从3D CT图像中生成主动脉的患者特定有限元模型，并且利用DNN与FEA的整合缩短了计算时间。这将有助于加速风险评估过程，提高主动脉瘤破裂风险的临床应用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06655", "html_url": "https://arxiv.org/abs/2510.06655", "title": "基于斐氏肤色调划分的皮肤图像分割方法", "title_en": "Fitzpatrick Thresholding for Skin Image Segmentation", "authors": "Duncan Stothers,Sophia Xu,Carlie Reeves,Lia Gracey", "background": "准确评估如牛皮癣等皮肤疹子所影响的体表面积对于评估疹子严重程度、选择初始治疗方案及跟踪临床治疗反应至关重要。现有的炎症性皮肤疾病分割模型在深色皮肤上表现较差，可能阻碍公平医疗。因此，研究者们收集了源自六个公开图谱的牛皮癣数据集，标注了斐氏皮肤类型，并为每张图像添加了详细的分割掩码。初步训练无肤色信息的参考模型包括U-Net、ResU-Net和SETR-small。在调优数据集上，研究者调整决策阈值，并选择全局最优和针对不同斐氏皮肤类型的最优阈值。通过调整斐氏特定阈值，还特别提高了最深肤色组（斐氏VI型）的分割性能，对于U-Net而言，均匀提高了31%的bIoU和24%的Dice值，对于ResU-Net则是25%的bIoU和18%的Dice值，SETR-small则为17%的bIoU和11%的Dice值。", "innovation": "研究采用了一种新的方法，即基于斐氏肤色调划分的皮肤图像分割方法。通过对不同斐氏皮肤类型的特定阈值进行调整，显著提升了黑暗肤色人群的分割性能。这一方法简单、模型无关、无需架构更改和重新训练，且成本几乎可以忽略不计。这样的方法有助于实现肤色不分所影响的更公平的医疗手段和技术。", "conclusion": "基于斐氏肤色调划分的方法作为一种潜在的公平性基准，在未来可能会被纳入更多公平性评估中。通过减少对皮肤色调标签的成本，这一方法已成为一种有效的解决策略，可以应用于各种模型中，以改善肤色敏感疾病的分割准确率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06677", "html_url": "https://arxiv.org/abs/2510.06677", "title": "通过渐进记录和代理反馈进行客户服务增量总结", "title_en": "Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback", "authors": "Yisha Wu, Cen (Mia)Zhao,Yuanpei Cao,Xiaoqing Su,Yashar Mehdad,Mindy Ji,Claire Na Cheng", "background": "客户支持代理在与客户交流过程中需要生成简洁的子弹笔记，但现有方法通常导致代理频繁切换上下文并需要进行冗余审查，增加了处理时间和工作负担。该研究旨在设计一个增量总结系统，该系统能够智能地确定何时生成简洁的总结摘要，减少代理因切换上下文和反复审查而导致的工作效率降低和满意度下降的问题。", "innovation": "该研究提出了一种结合Fine-tuned Mixtral-8x7B模型和DeBERTa分类器的增量总结系统，用于连续的笔记生成和过滤无价值内容。系统利用代理编辑优化在线笔记生成，并定期更新离线模型训练，形成了一个代理编辑反馈循环。实验结果显示，与批量总结相比，该系统在生产环境中的应用能够将案件处理时间平均减少3%，最高可达9%的复杂案例，并且代理对系统的满意度很高。", "conclusion": "研究表明，结合连续反馈的增量总结方法可以有效提高总结的质量和代理的生产力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06640", "html_url": "https://arxiv.org/abs/2510.06640", "title": "状态空间架构与变换器架构中上下文表示流动的比较分析", "title_en": "A Comparative Analysis of Contextual Representation Flow in State-Space and Transformer Architectures", "authors": "Nhat M. Hoang,Do Xuan Long,Cong-Duy Nguyen,Min-Yen Kan,Luu Anh Tuan", "background": "近年来，状态空间模型（SSMs）作为一种处理长序列的高效替代方案，呈现出线性缩放和较低的内存使用率，被广泛研究。然而，上下文信息在这些架构中的流动机制（特别是跨层和标记的流动）仍然缺乏细致研究。本研究通过对状态空间模型和变换器模型的统一标记级和层级分析，填补了这一空白，利用中心核对齐、稳定度指标和探测技术，描述了表示在各层级和跨层级的变化过程。研究表明，变换器模型迅速同化标记表示，而状态空间模型在早期保持标记的独特性，但在深度中趋于同质化。理论分析进一步表明，变换器模型中的过度平滑源自其架构设计，而状态空间模型中的过度平滑主要来自于训练动态。这些发现揭示了两种架构的归纳偏置并为未来具有长时间上下文推理能力的模型和训练设计提供指导。", "innovation": "首次从标记级和层级两个角度对状态空间模型和变换器模型的表示传播机制进行了统一的分析，使用了中心核对齐、稳定度指标和探测技术，明确揭示了两种模型在处理长序列时的不同行为和原理。", "conclusion": "研究表明，变换器模型会迅速同化标记表示，而状态空间模型在早期保持标记的独特性，但在深度中趋于同质化。变换器模型中的过度平滑源自其架构设计，而状态空间模型中的过度平滑主要来自于训练动态。这些发现揭示了两种架构的归纳偏置并为未来具有长时间上下文推理能力的模型和训练设计提供指导。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06695", "html_url": "https://arxiv.org/abs/2510.06695", "title": "从下游任务强化LLMs的提示重写学习", "title_en": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks", "authors": "Qinhao Zhou,Xiang Xiang,Kun He,John E. Hopcroft", "background": "近年来，大型语言模型（LLMs）的兴趣日益增长，显著推动了提示工程的发展，从手动设计转向基于模型的优化。LLM的提示通常包括两个部分：‘指令’定义任务或目标，而‘输入’则是针对特定指令的定制。在诸如机器翻译等自然语言生成任务中，‘输入’部分尤为重要，而‘指令’部分则较为简洁。现有的提示工程技术主要集中在对通用任务优化指令组件，往往需要大参数量的LLM作为辅助工具。然而，对于如机器翻译这样的任务类型，‘输入’部分扮演了一个更为关键的角色。", "innovation": "本文提出了一个针对机器翻译任务的新颖提示优化方法，专门设计用于优化‘输入’部分性能。该方法使用小参数模型并通过反向翻译策略进行训练，可显著减少单任务优化的训练开销，同时提供高效性能。该方法还可以通过某些调整应用于其他下游任务。", "conclusion": "本文引入了一种新的提示优化方法，特别针对机器翻译任务设计，使用小参数模型并通过反向翻译策略训练，从而有效地优化‘输入’部分并大幅度降低成本，同时也展示了其在其他下游任务上的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06719", "html_url": "https://arxiv.org/abs/2510.06719", "title": "基于检索增强生成（RAG）的差异化隐私合成文本生成", "title_en": "Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)", "authors": "Junki Mori,Kazuya Kakizaki,Taiki Miyagawa,Jun Sakuma", "background": "检索增强生成（RAG）通过将大型语言模型（LLMs）与外部知识相结合来增强它们。然而，在敏感领域应用RAG受到隐私风险的限制。现有的私人RAG方法通常依赖于查询时的差异化隐私（DP），需要多次注入噪声，导致累积隐私损失。", "innovation": "我们提出了DP-SynRAG，这是一个使用大型语言模型生成不同的差异化隐私合成RAG数据库的框架。与以往的方法不同，生成的合成文本一旦创建就可以重复使用，从而避免了重复注入噪声和额外的隐私成本。DP-SynRAG基于向LLMs提供私有预测指令，这些指令指导它们以DP方式生成模仿了采样数据库记录的文本，从而保留了对下游RAG任务至关重要的信息。", "conclusion": "实验表明，DP-SynRAG在保持固定隐私预算的情况下，实现了比最先进的私人RAG系统更好的性能，提供了用于保护隐私的RAG的可扩展解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06711", "html_url": "https://arxiv.org/abs/2510.06711", "title": "meta 前 agent 于 agent 设计中的不足", "title_en": "Inefficiencies of Meta Agents for Agent Design", "authors": "Batu El,Mert Yuksekgonul,James Zou", "background": "近期的研究开始使用元 agent 自动化地设计主动系统，这些元 agent 能够提出和迭代更新新的 agent 架构。这篇论文探讨了一类常见元 agent 的三个关键挑战：元 agent 学习的方式、设计 agent 的多样性问题以及自动生成 agent 的经济可行性问题。", "innovation": "作者发现了以下几点创新点：首先，通过实验表明，元 agent 不是简单地扩展所有先前 agent 的上下文进行学习，而是使用进化方法可以提升性能；其次，强调了设计的 agent 行为多样性的问题，指出元 agent 通常在测试阶段只选择一个 agent，导致多样性不足；最后，评估了自动化设计的经济可行性，表明只有在特定的两种数据集上，整体成本低于由人工设计的 agent 成本，而在其他数据集中，性能提升并不足以覆盖设计成本，不论规模大小。", "conclusion": "本研究揭示了元 agent 在设计 agent 过程中的不足，包括学习机制、设计多样性以及经济可行性等问题，并指出在某些条件下自动化设计可能不具有经济优势，强调了现有研究中需要进一步解决这些问题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06685", "html_url": "https://arxiv.org/abs/2510.06685", "title": "自注意力矩阵的高斯等价：注意力矩阵谱分析的渐近分析", "title_en": "Gaussian Equivalence for Self-Attention: Asymptotic Spectral Analysis of Attention Matrix", "authors": "Tomohiro Hayase,Benoît Collins,Ryo Karakida", "background": "自注意力层已成为现代深度神经网络的基础构建模块，然而它们的理论理解仍然有限，尤其是在随机矩阵理论的角度。本研究提供了一种严格的注意力矩阵奇异值谱分析，并建立了第一个注意力的高斯等价结果。在适当的逆温度范围内，注意力矩阵的奇异值分布渐近地由一个可解析的线性模型描述。此外，该分布的平方奇异值与之前工作中的Marchenko-Pastur定律有所不同。证明方法依赖于控制正则化项波动的精准控制和利用有利泰勒展开的精确线性化技术。这种分析还确定了线性化的临界点，并解释了为什么在这一范围内，非逐元素操作的注意力机制仍可严格地近似为高斯等价性.", "innovation": "本研究通过严格的数学分析揭示了在特定条件下，注意力矩阵的奇异值分布可由线性模型描述，这是首次对于注意力机制提供高斯等价结果。证明的关键在于控制正则化项的波动和利用有利的泰勒展开进行精确线性化，这有助于更好地理解注意力层的行为特点，尤其是在随机矩阵理论框架下的特征谱性质。", "conclusion": "在自然条件下，逆温度保持常数级时，注意力矩阵的奇异值分布渐近地被一个可处理的线性模型刻画。此外，该研究还揭示了注意力矩阵的平方奇异值分布与之前认为的Marchenko-Pastur定律有所偏差，证明了严格的高斯等价性，并确定了线性化的关键阈值。这不仅加深了对我们所熟知的注意力机制的理解，也为进一步的理论和应用研究提供了新的视角。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06742", "html_url": "https://arxiv.org/abs/2510.06742", "title": "MultiCNKG：使用大型语言模型整合认知神经科学、基因和疾病知识图谱", "title_en": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models", "authors": "Ali Sarabadani,Kheirolah Rahsepar Fard", "background": "大型语言模型（LLMs）的出现极大地推动了知识图谱（KGs）在生物医学和认知科学中的应用。传统机器学习方法在捕捉基因、疾病和认知过程之间复杂语义关联方面存在局限性。因此，需要一种新的框架来更好地整合这些知识源.", "innovation": "提出了MultiCNKG框架，该框架整合了认知神经科学知识图谱（CNKG）、基因本体（GO）和疾病本体（DO），并通过大型语言模型（如GPT-4）实现实体对齐、语义相似度计算和图增强，进而构建一个跨分子和行为领域的互联KG。MultiCNKG通过多种评估指标验证了其鲁棒性和一致性，并在链接预测任务中表现出了竞争力.", "conclusion": "MultiCNKG作为一种新的框架，不仅增强了生物医学和认知科学领域知识图谱的整合能力，还促进了个性化医疗、认知障碍诊断和认知神经科学假设的形成。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06820", "html_url": "https://arxiv.org/abs/2510.06820", "title": "高速大型视觉-语言重排序的高效区分联合编码器", "title_en": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking", "authors": "Mitchell Keren Taraday,Shahaf Wagner,Chaim Baskin", "background": "目前，多模态检索仍依赖嵌入式模型如CLIP进行快速向量搜索。然而，与标准的联合编码器重排序器相比，视觉-语言重排序器在文本检索中仍然很少见。我们发现，BLIP等先驱联合编码器因昂贵的视觉特征提取阶段而受到严重限制，阻碍了其大规模部署。", "innovation": "我们提出了高效的区分联合编码器EDJE，该编码器离线预计算视觉标记并通过轻量级的注意力适配器进行压缩，从而在线推断时只需对少量视觉标记加上文本进行紧凑的联合编码器计算。EDJE不仅保持了强大的检索性能，而且还大幅减少了存储和在线计算需求，实现了高吞吐量的推理。", "conclusion": "具体而言，EDJE每秒处理50000个图像-文本对，每个图像仅需49KB的磁盘存储，与先前在Flickr（零样本）和COCO（微调）检索上的表现相当。代码和模型检查点即将开源。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06882", "html_url": "https://arxiv.org/abs/2510.06882", "title": "边缘设备上流处理服务的多维自动扩展", "title_en": "Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices", "authors": "Boris Sedlak,Philipp Raith,Andrea Morichetta,Víctor Casamayor Pujol,Schahram Dustdar", "background": "边缘设备资源有限，导致流处理服务无法满足需求。现有的自动扩展机制仅关注资源的扩展，而边缘设备需要新的方法来维持服务级别目标（SLO）的竞争力。", "innovation": "提出了一种名为MUDAP的多维自动扩展平台，支持细粒度的垂直扩展，包括服务层和资源层。引入了一种基于结构性知识回归分析的扩展代理（RASK），在实现跨服务优化执行的同时，能够高效探索解决方案空间，并学习处理环境的连续回归模型以推断最佳扩展行动。", "conclusion": "通过与Kubernetes VPA和强化学习代理进行比较，在单个边缘设备上扩展多达9个服务。结果表明，RASK在20次迭代后（即观察200秒处理时间）能够构建精确的回归模型。随着弹性维度的不断增加，RASK维持了最高的请求负载，SLO违规率比基线降低了28%。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06868", "html_url": "https://arxiv.org/abs/2510.06868", "title": "使用深度哈希蒸馏进行多跳深度联合源-信道编码以实现语义对齐的图像检索", "title_en": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval", "authors": "Didrik Bergström,Deniz Gündüz,Onur Günlü", "background": "本文讨论了如何在多跳叠加高斯白噪声信道中通过训练深度联合源-信道编码（DeepJSCC）编码解码器对以及预训练的深度哈希蒸馏（DHD）模块来传输图像，以提升语义一致性，增强接收图像的感知重构质量，支持安全相关应用。传统的DeepJSCC在多跳传输中会积累噪声，这会影响图像的合成和感知质量。", "innovation": "提出了使用预训练的深度哈希蒸馏模块进行语义聚类，并将深度联合源-信道编码模块训练以同时减小均方误差（MSE）和保角距离（cosine distance），从而实现图像的语义对齐。通过这种方式提高了对感知重构质量的影响。", "conclusion": "在不同的多跳设置中，通过语义对齐显著提高了感知质量，降低了噪声累积带来的影响。这种新的方法通过使用LPIPS度量进行了衡量，表明其在多跳信道上传输图像的质量得到了明显改善。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06803", "html_url": "https://arxiv.org/abs/2510.06803", "title": "量子计算在恶意软件检测中的方法", "title_en": "Quantum Computing Methods for Malware Detection", "authors": "Eliška Krátká,Aurél Gábor Gábris", "background": "本论文探讨了量子计算在通过量子机器学习（QML）增强恶意软件检测中的潜力。研究利用量子支持向量机（QSVM）算法与传统支持向量机（SVM）进行性能对比，主要分析了QSVM在恶意软件检测中的应用效果，特别是其处理大规模计算任务的能力。实验数据源自含有便携可执行文件（PE文件）原始二进制文件的公共数据集，在Qiskit SDK和IBM量子计算机上的本地模拟器和量子硬件上进行了评估和验证。结果揭示了使用量子硬件的一些关键问题，包括量子电路的串行提交和作业大小限制等问题，并提供了相应的解决方案。", "innovation": "论文的主要创新在于将量子支持向量机（QSVM）算法应用于恶意软件检测领域，通过对比传统SVM，突出展示了量子计算在处理大规模计算任务中的潜在优势。同时，详细描述了在利用Qiskit接口进行实际操作过程中遇到的关键问题及解决方案，为未来的研究提供了宝贵的实践经验。", "conclusion": "实验结果表明，量子支持向量机（QSVM）在某些情况下相比于传统SVM在恶意软件检测中可以提供更好的性能和效率。然而，实际应用量子硬件过程中需要解决包括串行提交电路、作业大小限制等问题。这些结果强调了未来进一步研究量子机器学习在恶意软件检测中实际应用的必要性，并提供了宝贵的技术经验。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06691", "html_url": "https://arxiv.org/abs/2510.06691", "title": "重离子碰撞中带有MaskPoint变换器的潜在表示学习", "title_en": "Latent Representation Learning in Heavy-Ion Collisions with MaskPoint Transformer", "authors": "Jing-Zong Zhang,Shuang Guo,Li-Lin Zhu,Lingxiao Wang,Guo-Liang Ma", "background": "在高能核物理中，提取重离子碰撞（HIC）最终态高维数据中的重要特征以支持可靠下游分析是一项核心挑战。传统方法通常依赖于选择的观测可选，可能会错过数据中的微妙但物理相关的结构。为了解决这个问题，本研究提出了一种基于Transformer的自动编码器，并采用了两阶段的训练范式：先通过自监督预训练，再通过监督微调。这样的预训练编码器可以从未标记的HIC数据中直接学习潜在表示，提供紧凑且信息丰富的特征空间，该空间可以适应不同的物理任务。", "innovation": "研究引入了一种基于Transformer的自动编码器，并采用两阶段训练策略。即先自监督预训练，再监督微调。这种方法能够从未标记的HIC数据中直接学习潜在表示，提供紧凑且信息丰富的特征空间，适用于多种物理任务。特别是在区分大型和小型碰撞系统方面，其分类准确率显著高于PointNet。此外，主成分分析和SHAP解释进一步证明了自动编码器捕获了超越单一观测值的复杂非线性相关性。", "conclusion": "这些结果确立了两阶段框架作为HIC中特征学习的通用且稳健的基础，为深入分析夸克-胶子等离子体性质及其他新兴现象提供了强大的分析工具。该实施代码已公开发布。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06727", "html_url": "https://arxiv.org/abs/2510.06727", "title": "使用端到端总结导向的上下文管理扩展LLM多轮RL", "title_en": "Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management", "authors": "Miao Lu,Weiwei Sun,Weihua Du,Zhan Ling,Xuesong Yao,Kang Liu,Jiecao Chen", "background": "研究了大规模语言模型（LLM）代理在长周期多轮工具使用中的强化学习（RL）微调，其中上下文长度很快成为根本瓶颈。现有的RL管道会遭受指令跟随下降、延长订票成本以及最关键的是，严格的上下文限制。这些都是亟待解决的问题。", "innovation": "提出了一种基于总结的上下文管理方法，通过LLM生成的摘要来定期压缩工具使用历史，保留任务相关信息，以保持紧凑的上下文同时使代理能够超越固定的上下文窗口进行扩展。利用这一框架，我们披露了一种策略梯度表示，可以无缝地使标准LLM RL基础设施优化工具使用行为以及总结策略，进行端到端优化。以此为基础，我们实现了SuPO算法，该算法允许在固定上下文长度限制之外进行长周期训练。", "conclusion": "实验证明，SuPO显著提高了成功率，并能保持或降低工作上下文长度。对于复杂搜索任务，SuPO还能进一步优化测试时最大轮次摘要的性能。我们的研究表明，基于总结的上下文管理是训练超越固定上下文长度限制的RL代理的原理性、可扩展的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06848", "html_url": "https://arxiv.org/abs/2510.06848", "title": "在量子正多面体上的贝尔采样再征服：自旋器学习与测试，量子伪随机性边界及其他", "title_en": "Reconquering Bell sampling on qudits: stabilizer learning and testing, quantum pseudorandomness bounds, and more", "authors": "Jonathan Allcock,Joao F. Doriguello,Gábor Ivanyos,Miklos Santha", "background": "贝尔采样是一种基于贝尔正交基测量一对量子态的简单但强大的工具，广泛应用于与保局子态和魔法度量相关的问题。然而，之前的工作未能将这种方法从两维到所有维度的量子系统（即，任意维度d > 2的量子比特）进行一般化，理由是在更高维度下自然扩展的贝尔采样不能提供有意义的关于量子态的信息。本文通过提出一种基于拉格朗日四平方定理的新幺正变换，解决了这个问题，该变换可以映射任何保局子态到其共轭状态，并展示了其在多个量子态学习和测试以及量子伪随机性边界的适用性，从而克服了之前的困难，提供了一种在所有d≥2维度上的任意正多面体上运用贝尔采样的实用方法。", "innovation": "本文提出了在所有d≥2维度上的任意正多面体上运用贝尔采样的实用方法。核心创新在于基于拉格朗日四平方定理的新幺正变换，它能够将任何保局子态四复制映射到其共轭状态（特定的保罗伊操作除外），这可能是独立的值得注意的基础。这种方法被用于提升几种已知的贝尔采样结果至所有d ≥ 2维度，包括学习保局子态、解决隐藏保局子群问题、测试量子态的保局子特性和保局子态的伪随机性边界等。", "conclusion": "本文介绍了一种实用的一般化贝尔采样方法，此方法成功在所有维度d≥2的任意正多面体上提升了几种已知的贝尔采样结果，包括在多项式量子态学习、解决隐藏保局子群问题、保局子态测试、伪随机性边界及其他方面的运用。这些结果显示贝尔采样方法可以广泛应用于多维度的量子系统，并可能推动相关领域的发展。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06919", "html_url": "https://arxiv.org/abs/2510.06919", "title": "基于贝叶斯非参数的时序动态聚类方法", "title_en": "Bayesian Nonparametric Dynamical Clustering of Time Series", "authors": "Adrián Pérez-Herrero,Paulo Félix,Jesús Presedo,Carl Henrik Ek", "background": "该研究提出了一种方法，用来建模任意数量的时间序列聚类的发展过程，其中聚类的数量和动态是未知的。这种方法通过层次Dirichlet过程作为转换线性动态系统的参数先验，以及高斯过程先验来建模每个聚类内部振幅和时间对齐的统计变化。这种方法避免了聚类的非必要增长，通过变分下界进行推断，使得在离线和在线场景下能够有效地学习。", "innovation": "该研究创新性地提出了一种基于贝叶斯非参数的方法，用于建模未知数量的时间序列聚类和动态。引入了层次Dirichlet过程作为参数先验，并使用高斯过程先验来建模每个聚类内部的统计变化。通过变分下界进行有效的推断和学习。这种方法特别适用于心电图分析等场景，能够避免不必要的聚类增长，提高学习效率和准确性。", "conclusion": "通过在心电图分析中的多个案例研究，该方法展示了其灵活性和有效性。它提供了一种系统地建模和聚类时间序列数据的手段，避免了聚类的非必要增生，并且能够在离线和在线场景下高效学习。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06935", "html_url": "https://arxiv.org/abs/2510.06935", "title": "PyCFRL：通过序贯数据预处理实现反事实公平的离线强化学习的Python库", "title_en": "PyCFRL: A Python library for counterfactually fair offline reinforcement learning via sequential data preprocessing", "authors": "Jianhan Zhang,Jitao Wang,Chengchun Shi,John D. Piette,Donglin Zeng,Zhenke Wu", "background": "强化学习（RL）旨在学习并评估一个最大化总体群体利益的顺序决策规则（通常称为‘策略’）。然而，RL算法做出的序贯决策虽然优化以最大化总体群体利益，但可能会对少数族裔或社会经济地位不佳的个体造成不利影响。为解决此问题，我们介绍了PyCFRL，一个用于保证离线RL中反事实公平性的Python库。", "innovation": "PyCFRL实现了一个新颖的数据预处理算法，用于从离线数据集中学习反事实公平的RL策略，并提供了评估RL策略的值以及反事实不公平程度的工具。该库已经在PyPI和Github上公开发布，详细教程可在PyCFRL文档中找到。", "conclusion": "我们描述了PyCFRL的高级功能，并通过数据示例演示了其主要使用案例。该库已公开发布，相关内容可从PyPI和Github上获取，同时可在线详细学习使用教程。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06970", "html_url": "https://arxiv.org/abs/2510.06970", "title": "基于驳正驱动的强化学习的海上运动规划", "title_en": "Falsification-Driven Reinforcement Learning for Maritime Motion Planning", "authors": "Marlon Müller,Florian Finkeldei,Hanna Krasowski,Murat Arcak,Matthias Althoff", "background": "自主船安全运营的关键在于遵守海上交通规则，然而，训练强化学习（RL）代理以遵守这些规则具有挑战性。RL代理的行为受到训练场景的影响，但创建能够捕捉海上导航复杂性的场景是困难的，且仅依靠真实世界的数据是不够的。", "innovation": "本文提出了一种驳正驱动的RL方法，通过生成船舶违反海上交通规则的对抗性训练场景来训练RL代理，其中这些规则用信号时序逻辑（STL）规范表达。这种方法在开放海域环境中表现良好，能够提供更相关和一致的规则遵守训练场景。", "conclusion": "提出的该方法在两艘船的海上导航实验中证明了其有效性，相较于现有方法，它提供了更相关且一致性更好的训练场景，从而能够更好地确保规则遵守。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06931", "html_url": "https://arxiv.org/abs/2510.06931", "title": "大型语言模型对瞬变图像分类的文本解释", "title_en": "Textual interpretation of transient image classifications from large language models", "authors": "Fiorenzo Stoppa,Turan Bulmus,Steven Bloemen,Stephen J. Smartt,Paul J. Groot,Paul Vreeswijk,Ken W. Smith", "background": "现代天文学巡天提供大量瞬变检测数据，但区分真正的天体物理信号（例如，爆炸事件）和虚假图像伪影仍然是一个挑战。现有的卷积神经网络（CNN）在真实与虚假分类方面表现出色，但它们依赖于不透明的隐层特征，影响了可解释性。", "innovation": "该研究利用大型语言模型（LLMs）在三个光学瞬变巡天数据集（Pan-STARRS、MeerLICHT 和 ATLAS）上达到了与 CNN 相当的性能，同时能为每个候选者提供准确的人类可读描述。仅使用 15 个示例和简洁的指令，Google 的 LLM Gemini 在跨越多种分辨率和像素比例的数据集上实现了 93% 的平均准确率。此外，第二个 LLMs 可以评估第一个模型的输出一致性，进行迭代优化。", "conclusion": "该框架允许用户通过自然语言和示例定义期望的分类行为，绕过了传统训练管道。通过生成观测特征的文本描述，LLMs 允许用户像在注释目录中导航那样查询分类，而不是解码抽象的隐层空间。随着下一代望远镜和巡天进一步增加数据量，LLMs 基础的分类可以为自动检测与透明的人类理解之间的鸿沟提供解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06957", "html_url": "https://arxiv.org/abs/2510.06957", "title": "加速苹果硅芯片上量化LLM推理中的稀疏三元GEMM", "title_en": "Accelerating Sparse Ternary GEMM for Quantized LLM inference on Apple Silicon", "authors": "Baraq Lipshitz(ETH Zurich),Alessio Melone(ETH Zurich),Charalampos Maraziaris(ETH Zurich),Muhammed Bilal(ETH Zurich)", "background": "现有的苹果硅CPU库中稀疏三元GEMM优化不足。论文提出了一种针对苹果M系列处理器优化的稀疏三元GEMM内核。包括新颖的分块和交错稀疏数据格式来提高内存局部性，增加指令级并行度（ILP）的策略，以及基于NEON的单指令多数据（SIMD）向量化技术来利用数据级并行性。", "innovation": "一种针对苹果M系列处理器优化的稀疏三元GEMM内核，提出了一组架构感知的优化，包括新型分块和交错稀疏数据格式以优化内存局部性，ILP增加策略，以及NEON基SIMD向量化，以利用数据级并行性。这些优化提高了稀疏矩阵乘法性能，并稳定性适用于不同稀疏度水平下的大矩阵。", "conclusion": "论文的标量实现相比传统三元压缩稀疏列（TCSC）基准在高稀疏度矩阵上性能提高了5.98倍，达到处理器理论峰值性能的50.2%，而向量化实现则在低稀疏度矩阵实现5.59倍性能提升，保持稳定性，适应不同稀疏度水平。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06995", "html_url": "https://arxiv.org/abs/2510.06995", "title": "未知循环图中异常值的根本原因分析", "title_en": "Root Cause Analysis of Outliers in Unknown Cyclic Graphs", "authors": "Daniela Schkoda,Dominik Janzing", "background": "我们研究了在具有线性结构方程的循环因果图中异常值的传播，并追溯到一个或几个被称为根源的节点。研究表明，在扰动足够强且传播机制与正常模式相同的情况下，有可能识别出一个潜在的根源节点列表。该列表包括真实的根源节点及其与根源节点形成循环的父节点。值得注意的是，这种方法不需要预先知道因果图结构。", "innovation": "提出了一个不依赖于先验因果图知识的方法，可以识别出潜在的根源节点，该列表包含了真正的根源节点及其与根源节点形成循环的父节点。这一方法能够仅基于异常值的传播特性来定位潜在的根本原因，这在未知循环图的情况下尤为有用。", "conclusion": "研究强调了在循环因果图中通过异常值追溯根源的可行性，即便无法预先知道图的具体结构。方法展示了通过识别异常值的传播路径来找到潜在的根源节点的实用性，这对于复杂系统中的故障诊断具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06980", "html_url": "https://arxiv.org/abs/2510.06980", "title": "关系数据库蒸馏：从结构化表到浓缩图数据", "title_en": "Relational Database Distillation: From Structured Tables to Condensed Graph Data", "authors": "Xinyi Gao,Jingxi Zhang,Lijian Chen,Tong Chen,Lizhen Cui,Hongzhi Yin", "background": "关系数据库（RDBs）是全球数据管理系统的核心，其中信息被结构化为多个相互依赖的表格。为了有效地利用RDB中的知识进行预测任务，最近的研究利用图表示学习来捕捉复杂跨表关系的多跳依赖关系。尽管这些方法在性能上已达到最先进的水平，但它们仍受到存储开销和训练时间过长的限制，因为数据库规模庞大，且连接的表之间的信息传递计算负担繁重。", "innovation": "我们提出并研究了关系数据库蒸馏（RDD）的问题。特别地，我们旨在将大规模RDBs制备成紧凑的异构图，同时保留训练图模型所需的预测能力（即实用性）。通过节点特征保持多模态列信息，并通过异构边编码主外键关系，从而保持数据的准确性和关系结构。我们进一步设计了一个基于核岭回归的目标函数，该函数通过对伪标签的引导生成质量特征，以确保跨多种下游任务的适应性，而无需使用传统的低效双层蒸馏框架。", "conclusion": "在多个真实世界的RDBs上的广泛实验表明，我们的解决方案在减少数据量的同时，仍能在分类和回归任务中保持竞争力的性能，为基于RDBs的可扩展学习开辟了一条有效的途径。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07019", "html_url": "https://arxiv.org/abs/2510.07019", "title": "Native Hybrid Attention for Efficient Sequence Modeling", "title_en": "Native Hybrid Attention for Efficient Sequence Modeling", "authors": "Jusen Du,Jiaxi Hu,Tao Zhang,Weigao Sun,Yu Cheng", "background": "Transformer模型在序列建模方面表现出色，但面临二次复杂性的问题；线性注意力则提供了更高的效率，但在处理长上下文时常常会牺牲召回精度。", "innovation": "提出了一种新颖的混合注意力机制叫Nativer Hybrid Attention (NHA)，结合了线性注意力和全注意力的特点，进行了跨层和跨层内的混合设计。NHA通过线性RNN更新关键值槽中的长期上下文，并通过滑动窗口添加短时上下文。实验证明NHA在召回密集型任务和常识推理方面优于Transformer和其他混合基线模型，同时解决了保持结构一致性与提高效率之间的冲突。", "conclusion": "NHA在预训练大语言模型中表现出色，能够实现与纯粹线性或全注意力模型之间的平滑调整，并且回归任务中的性能和效率都有显著提升。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07099", "html_url": "https://arxiv.org/abs/2510.07099", "title": "扩散增强强化学习在压力情景下的稳健投资组合优化", "title_en": "Diffusion-Augmented Reinforcement Learning for Robust Portfolio Optimization under Stress Scenarios", "authors": "Himanshu Choudhary,Arishi Orra,Manoj Thakur", "background": "在不断变化且错综复杂的金融市场中，投资组合优化仍然是投资者和资产经理面临的一大难题。传统方法往往难以捕捉市场的复杂动态并满足多样化的投资者偏好。", "innovation": "我们提出了一种名为扩散增强强化学习(DARL)的创新框架，该框架将去噪扩散概率模型(DDPMs)与深度强化学习(DRL)相结合，用于投资组合管理。通过利用DDPMs生成基于不同压力强度条件下的市场崩溃情景，显著增强了训练数据的稳健性。", "conclusion": "经验研究表明，DARL在压力情景下比传统基准方法表现更优，能够提供更佳的风险调整回报率，并具备应对突如其来的危机（如2025年的关税危机）的能力。这项工作提供了一种稳健且实用的方法，以增强DRL驱动的金融应用中的压力韧性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07077", "html_url": "https://arxiv.org/abs/2510.07077", "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "title_en": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "authors": "Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu", "background": "随着大型语言模型（LLMs）和视觉-语言模型（VLMs）在机器人技术中的应用越来越广泛，Vision-Language-Action（VLA）模型最近引起了显著的关注。传统上分别研究视觉、语言和动作数据的VLA模型旨在学习能够跨多种任务、物体、代理体和环境泛化的策略。这种泛化能力预计能够让机器人解决新的下游任务，即使是对特定任务的数据最少或没有额外任务特定数据的依赖，从而促进机器人在现实世界中的灵活部署和大规模应用。", "innovation": "不同于以往专注于动作表示或高级模型架构的综述，这份工作提供了全面的系统性回顾，整合了VLA系统的软件和硬件组件。特别地，本文综述了VLA策略与架构转变、架构和构建块、模态特定处理技术及学习范式。此外，本文也回顾了常用机器人平台、数据收集策略、公开可用数据集、数据增强方法和评估基准，以支持VLA在实际机器人应用中的部署。所有分类参考的链接可以在项目网站上找到：this https URL", "conclusion": "本文旨在为机器人社区提供应用VLA到实际机器人系统中的实用指导。所有分类参考均已在我们项目网站上的表格中整理：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07088", "html_url": "https://arxiv.org/abs/2510.07088", "title": "通过霍夫丁分解解释具有多元伯努利分布的模型", "title_en": "Explaining Models under Multivariate Bernoulli Distribution via Hoeffding Decomposition", "authors": "Baptiste Ferrere(EDF R\\&amp;D PRISME, IMT, SINCLAIR AI Lab),Nicolas Bousquet(EDF R\\&amp;D PRISME, SINCLAIR AI Lab, LPSM (UMR\\_8001)),Fabrice Gamboa(IMT),Jean-Michel Loubes(IMT),Joseph Muré(EDF R\\&amp;D PRISME)", "background": "该研究探讨了通过子模型分解解释具有随机输入的预测模型行为的方法，特别是当随机输入变量相关时，基于不变量量化社区的成果发现，存在并证明了广义霍夫丁分解的存在性和唯一性。论文关注输入变量具有伯努利分布的情况，并对这种分解进行了完全描述，指出在这种情况下，底层的L2子空间是一维的，从而使得功能分解具有显式性。这种分解方法为解释模型提供了一个完全可解释的框架，并理论上允许反向工程。", "innovation": "本文展示了当输入变量具有伯努利分布时的广义霍夫丁分解，揭示了在此情况下底层L2子空间是一维的，使得功能分解可以显式给出。研究还提供了输入对输出预测影响的显式指示器（例如Sobol'指数和Shapley效应）。", "conclusion": "本文提供了详细的模型分解框架，并通过数值实验验证了该方法的有效性，特别是在二元决策图、布尔网络或二元神经网络中的决策支持问题中。此外，还指出了未来探索高维情景以及推广到具有有限可数输入的模型的研究前景。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07109", "html_url": "https://arxiv.org/abs/2510.07109", "title": "下一代SDN启用消费电子设备增强的GNN异常流量检测", "title_en": "GNN-enhanced Traffic Anomaly Detection for Next-Generation SDN-Enabled Consumer Electronics", "authors": "Guan-Yan Yang,Farn Wang,Kuo-Hui Yeh", "background": "物联网连接的消费电子设备（CE）面临多种攻击，如DDoS和基于Web的威胁，这些攻击可能损害其功能性并使远程接管成为可能。现有的依托深度学习的流量异常检测系统在传统的网络环境中表现出高准确性，但通常过于复杂，依赖静态基础设施，需要手动配置和管理。", "innovation": "提出了一种结合软件定义网络（SDN）和计算先驱网络（CFN）的可扩展网络模型，用于下一代消费电子网络。该模型中提出了一种基于图神经网络的网络异常检测框架（GNN-NAD），其核心是一个图神经网络模型（GSAGE）进行图表示学习，之后是随机森林（RF）分类器。GNN-NAD的独特之处在于将静态、漏洞感知的攻击图与动态流量特征结合，提供了一个全面的网络安全视图。", "conclusion": "实验结果表明，GNN-NAD在准确性、召回率、精确度和F1分数方面超越了现有的异常流量检测方法，即使在小样本量的情况下也能实现更优的性能指标。这项工作推动了下一代智能消费电子网络的安全性和效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07080", "html_url": "https://arxiv.org/abs/2510.07080", "title": "伪MDP：针对区块链中最后一个揭示者种子操控优化的新型高效框架", "title_en": "Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains", "authors": "Maxime Reynouard", "background": "该研究解决了一类特定问题的马尔可夫决策过程（MDP）的计算挑战，这些问题由Last Revealer Attack (LRA)引起，LRA在如以太坊等一些基于股权证明（PoS）的区块链中破坏了公平性。LRA的规模参数为κ，在以太坊情况下κ值为32。", "innovation": "提出了pseudo-MDP (pMDPs)框架，用于自然建模此类问题，并提出了两种不同的问题简化方法至标准MDP。一种问题分解提供了新的、反直觉的视角，而结合两种问题简化方法使动态规划算法（如价值迭代）能够显著改进。该研究将LRA的计算复杂性从O(2^κ κ^2^(κ+2))降低到O(κ^4)（每迭代一次）。此外，该研究还将结果推广到更广泛的MDP类型，增强了其应用范围。该框架通过两个应用案例得到验证：一个虚构的纸牌游戏和以太坊随机种子共识协议上的LRA实例，展示了其实现大规模问题的有效解决能力并提供了关于最优策略的实用见解。", "conclusion": "该研究推进了对MDP的研究，并有助于理解区块链系统的安全漏洞。该研究提供了从伪MDP框架解决MDP问题的途径，优化了Last Revealer Attack中的种子操控策略，并展示了如何通过动态规划方法获得指数级快速收敛到最优解。鉴于机器学习和区块链技术的发展，伪MDP框架的应用前景广阔。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07118", "html_url": "https://arxiv.org/abs/2510.07118", "title": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning", "title_en": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning", "authors": "Manish Nagaraj,Sakshi Choudhary,Utkarsh Saxena,Deepak Ravikumar,Kaushik Roy", "background": "指令调优对于对齐大型语言模型（LLMs）以适应下游任务至关重要，通常依赖于大型和多样化的数据集。然而，小而高质量的数据子集（称为coresets）可以提供同样甚至更好的结果，但是如何收集这些高质量的coresets仍然具有挑战性。现有方法通常依赖于粗略的、样本级别的信号，例如梯度，这种方法在计算上是昂贵的并且忽视了细微的特征。", "innovation": "TRIM（Token Relevance via Interpretable Multi-layer Attention）是一种向前进行的、以标记为中心的框架，它通过匹配从少量目标样本中通过基于注意力的“指纹”识别的底层表示模式来工作，而不是使用梯度。TRIM采用这种策略使得它高度高效，并且对定义任务的结构特征具有独特敏感性。这种方法使得所选coresets在下游任务上的表现持续优于最先进的基准，甚至在某些情况下超过了全数据调优的效果。TRIM通过避免昂贵的反向传递，提高了效率，降低了计算成本。", "conclusion": "这些发现确立了TRIM作为一种可扩展且高效的替代方案，用于构建高质量的指令调优数据集。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07173", "html_url": "https://arxiv.org/abs/2510.07173", "title": "NurseLLM: 首个专门用于护理的自然语言模型", "title_en": "NurseLLM: The First Specialized Language Model for Nursing", "authors": "Md Tawkat Islam Khondaker,Julia Harrington,Shady Shehata", "background": "近年来，大规模语言模型（LLMs）在医疗系统中取得了显著进步，但在专业领域，如护理方面，其潜力尚未得到充分挖掘。", "innovation": "该文介绍了NurseLLM，这是首个针对多选题作答（MCQ）任务的护理专业化的LLM。通过多阶段数据生成管道构建了首个大型护理MCQ数据集，并引入了多个护理基准以进行严谨的评估。实验结果表明，NurseLLM在不同基准上均优于同类规模的通用和医学专业化LLM，突显了护理领域专业化LLM的重要性。", "conclusion": "最后，该文探讨了推理和多代理协作系统在护理中的作用，指明了未来研究和应用的前景。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07136", "html_url": "https://arxiv.org/abs/2510.07136", "title": "在差分隐私下的谱图聚类：平衡隐私、准确性和效率", "title_en": "Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency", "authors": "Mohamed Seif,Antti Koskela,H. Vincent Poor,Andrea J. Goldsmith", "background": "本文研究了在边差分隐私（DP）约束下的谱图聚类问题。背景在于传统谱图聚类方法通常不能处理隐私保护需求，尤其是在大规模图数据集上效果不佳。本文旨在通过保障谱图的隐私同时又不会严重影响聚类性能和计算效率，来解决这一问题。", "innovation": "本文提出了三种机制来实现边差分隐私下的谱图聚类：通过随机边翻转和邻接矩阵洗牌实现图扰动；通过在低维空间中添加高斯噪声的图投影来降低维度和计算复杂度；以及一种带噪声幂迭代方法来确保边差分隐私，同时保持收敛性。这些机制在理论上提供了严格的隐私保护保证，并精确地描述了分类错误率。实验结果验证了该理论分析，并展示了实际的隐私-实用性权衡。", "conclusion": "本文提供了一种新的、隐私保护的谱图聚类方法，能够在较小的隐私损失下保持高聚类准确性和计算效率，在此基础上进行严格的误差分析，并通过实际应用验证了方法的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07106", "html_url": "https://arxiv.org/abs/2510.07106", "title": "使用基于伴随的深度学习的湍流翼型流主动控制", "title_en": "Active Control of Turbulent Airfoil Flows Using Adjoint-based Deep Learning", "authors": "Xuemin Liu,Tom Hickling,Jonathan F. MacArt", "background": "本文研究通过深度学习增强的方法训练活性神经网络流控制器，以优化Reynolds数为5×10^4和马赫数为0.4的湍流翼型流中的升阻比。使用直接数值模拟和大涡模拟来建模二维和三维半无限NACA 0012翼型在5°、10°和15°迎角下的可压缩、不受限流动。通过固定在翼型上表面位置和几何形状上的吹气/吸气射流实施控制措施，神经网络根据局部压力测量结果确定最优射流总压力，这种方法提供了一种基于传感器的控制策略，能够响应不稳定的流动条件在空间和时间上做出反应。论文中的控制策略使用自动求导构建伴随纳维-斯托克斯方程来计算神经网络参数对流的灵敏度。研究还探讨了基于学习的控制方法在改善气动性能方面的有效性，特别是在不同翼型下的流量控制效果和能效问题。", "innovation": "采用了一种新的深度学习增强方法训练活性神经网络流控制器来优化翼型流的升阻比；通过自动求导构建伴随纳维-斯托克斯方程计算神经网络参数对流的灵敏度；证实了基于学习的控制方法的鲁棒性，3D训练模型对2D到3D翼型流动的控制更为有效，并且展示了改进的能效和性能，特别是在不同的迎角下。", "conclusion": "基于此学习驱动的方法在提升气动性能方面表现出有效性，尤其是在不同迎角和翼型流动中的流动控制和能效改善方面。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07180", "html_url": "https://arxiv.org/abs/2510.07180", "title": "由预测合成实现的贝叶斯投资组合优化", "title_en": "Bayesian Portfolio Optimization by Predictive Synthesis", "authors": "Masahiro Kato,Kentaro Baba,Hibiki Kaibuchi,Ryo Inokuchi", "background": "投资组合优化是投资中关键的任务。当前大多数投资组合优化方法需要资产回报分布的信息，但投资者通常无法获得这种信息。尽管存在估计这些信息的各种方法，但其准确性很大程度上取决于金融市场的不确定性。由于这种不确定性，适合某一时点进行分布信息预测的模型可能在另一时点表现不佳。", "innovation": "我们研究了一种基于贝叶斯预测合成（BPS）的组合优化方法，BPS是一种贝叶斯元学习的集成方法。我们假设投资者可以访问多种资产回报预测模型，并使用动态线性模型结合这些预测，从而获得能适应金融市场不确定性的资产预期收益的贝叶斯预测后验。", "conclusion": "通过使用BPS方法结合多组资产回报预测模型，我们能够获得能适应金融市场不确定性的资产预期收益的贝叶斯预测后验，以此构建均值-方差投资组合和基于分位数的投资组合。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07117", "html_url": "https://arxiv.org/abs/2510.07117", "title": "物理体化条件允许开放性与关怀", "title_en": "The Contingencies of Physical Embodiment Allow for Open-Endedness and Care", "authors": "Leonardo Christov-Moore(1),Arthur Juliani(1),Alex Kiefer(1 and 2 and 3),Nicco Reggente(1),B. Scott Rousse(4),Adam Safron(1 and 5),Nicol'as Hinrichs(6 and 7),Daniel Polani(8),Antonio Damasio(9) ((1) Institute for Advanced Consciousness Studies, Santa Monica, CA, (2) VERSES, (3) Monash Centre for Consciousness and Contemplative Studies, (4) Allen Discovery Center, (5) Allen Discovery Center, (6) Okinawa Institute of Science and Technology, (7) Max Planck Institute for Human Cognitive and Brain Sciences, (8) University of Hertfordshire, (9) Brain and Creativity Institute)", "background": "在人工代理物的发展中，物理脆弱性和死亡通常被视为需要避开的障碍，使得它们难以适应开放的环境并提供一致的关怀。相比之下，生物体能够在开放的物理世界中生存、繁荣并相互关怀，这反映了对生命的条件的理解不足。作者认为，从马丁·海德格尔的存在主义现象学到两个最小的物理体化条件开始，能够帮助理解这种差异并开发出更加健壮、适应性强和有关怀的智能代理。", "innovation": "论文提出了两种由马丁·海德格尔的存在主义现象学启发的物理体化条件：身处世界（智能代理是环境的一部分）和趋向死亡（由于热力学第二定律，如果没有干预，智能代理会趋向于终结状态）。基于尼采的存在主义概念“权力意志”，作者研究了内在驱动力如何最大化对未来状态的控制，如赋能，使得代理增加满足未来稳态需求的可能性，从而增强其维持物理完整性的能力。论文通过强化学习框架将这些概念形式化，从而探讨内在驱动力驱动的体化代理在开放多代理环境中的学习如何促进开放性和这一http URL（省略部分链接）", "conclusion": "推测具备这些内在驱动力的开放型体化智能代理能够增强其在未知环境中的适应性和提供持续关怀的能力，从而改善其生存和繁衍的能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07175", "html_url": "https://arxiv.org/abs/2510.07175", "title": "量化大规模语言模型的心理测量评估中的数据污染", "title_en": "Quantifying Data Contamination in Psychometric Evaluations of LLMs", "authors": "Jongwook Han,Woojung Song,Jonggeun Lee,Yohan Jo", "background": "近期研究将心理测量问卷应用于大型语言模型（LLMs），以评估价值观、人格、道德基础和黑暗特质等高级心理构造。尽管先前工作已经指出了心理测量调查问卷中的数据污染可能对评估的可靠性构成威胁，但仍未有系统的方法来量化这种污染的程度。", "innovation": "本文提出了一种框架，系统性地测量心理测量评估中LLMs中的数据污染，评估了三个方面的污染：(1) 项目记忆，(2) 评价记忆，(3) 目标评分匹配。将该框架应用于21个主要家庭中的多个模型和四种广泛使用的心理测量问卷，结果表明流行的问卷如Big Five Inventory (BFI-44)和Portrait Values Questionnaire (PVQ-40)表现出强烈的数据污染，模型不仅记忆项目，还能调整其答案以达到特定的目标评分。", "conclusion": "通过系统地测量LLMs心理测量评估中的数据污染，表明常用的心理测量问卷存在严重的污染问题，影响评估的准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07185", "html_url": "https://arxiv.org/abs/2510.07185", "title": "使用无监督校准的拆分公宗预测分类", "title_en": "Split Conformal Classification with Unsupervised Calibration", "authors": "Santiago Mazuelas", "background": "现有方法通过使用与训练集不同的标签示例组成的校准样本，将任意预测规则转化为满足目标覆盖率的概率集合预测规则，提供了强大的性能保证并且计算成本低。但是，这种要求使得不能使用所有标签示例进行训练，并且可能需要额外的标签用于校准，这非常不方便。现有拆分公宗预测方法依赖于监督校准样本，限制了其灵活性和应用范围。", "innovation": "提出了一种新的方法，使用无监督校准样本与之前用于学习分类规则的监督训练样本，共同获取集合预测规则。这在无需额外标签的情况下，实现与监督校准相当的性能，虽然在性能保证和计算效率上略显不足，但具有更大的灵活性和应用范围。", "conclusion": "所提出的方法能够在不使用额外标签的情况下，实现与监督校准相当的分类性能，尽管性能保证和计算效率有所下降，但提出的方法提供了一种更加灵活和有效的方法来进行拆分公宗预测。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07284", "html_url": "https://arxiv.org/abs/2510.07284", "title": "从两两比较中在线获取评估标准", "title_en": "Online Rubrics Elicitation from Pairwise Comparisons", "authors": "MohammadHossein Rezaei,Robert Vacareanu,Zihao Wang,Clinton Wang,Yunzhong He,Afra Feyza Akyürek", "background": "评分表为训练LLMs生成开放式长篇回答提供了一种灵活的方式，但验证奖励并不适用，且人类偏好只能提供粗略的信号。现有研究表明，基于评分表的奖励的强化学习能够使LLM在训练后保持一致的进步。但大多数现有的方法依赖于在整个训练过程中都保持静态的评分表，这使得它们容易受到奖励劫持行为的影响，并且无法捕捉到训练过程中出现的新需求。", "innovation": "本文引入了Online Rubrics Elicitation（在线评分获取，简称OnlineRubrics），这是一种通过当前策略和参考策略的响应两两比较动态 curate 评估标准的方法。这种方法可以在在线过程中不断识别并缓解错误，从而在整个训练期间提供一致性改进，包括AlpacaEval、GPQA、ArenaHard以及专家问题和评分参考的验证集，表演上获得了最高8%的改进。", "conclusion": "通过定性分析所引出的标准，本文确定了透明度、实用性、组织性和推理等重要主题。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07193", "html_url": "https://arxiv.org/abs/2510.07193", "title": "Covert Quantum Learning: Privately and Verifiably Learning from Quantum Data", "title_en": "Covert Quantum Learning: Privately and Verifiably Learning from Quantum Data", "authors": "Abhishek Anand,Matthias C. Caro,Ari Karchmer,Saachi Mutreja", "background": "这篇论文讨论了在远程访问量子计算和数据的情况下，量子学习面临的两大关键挑战：验证数据的正确性以及保护学习者的数据收集策略和结果不被泄露。为了解决这些问题，论文借鉴了Canetti和Karchmer在2021年提出的一种隐秘可验证学习模型，该模型为经典学习算法提供了增强这些保证的框架。研究还考虑了两种不同的隐私概念。", "innovation": "本文提出了在量子学习理论中的隐秘可验证学习模型，无需在远程数据访问场景中做计算硬假设，这些模型能够保护学习者的策略隐私（策略隐密性）和目标隐私（目标隐密性）。研究展示了通过经典阴影进行量子统计查询的策略隐密算法，以及通过公共量子示例和私有量子统计查询学习二次函数的多种隐秘可验证算法。研究还证明了当对手是单向或i.i.d.无辅助量子窃听者时，Covert Quantum Learning（隐秘量子学习）能够保留经典和量子查询之间在Forrelation和Simon问题上的指数级差距。", "conclusion": "整体而言，本文模型和对应的算法表明即使是在不信任、远程的数据情况下，量子优势仍然是可私有和可验证的。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07195", "html_url": "https://arxiv.org/abs/2510.07195", "title": "使用量子计算机加速多层神经网络的推理", "title_en": "Accelerating Inference for Multilayer Neural Networks with Quantum Computers", "authors": "Arthur G. Rattew,Po-Wei Huang,Naixu Guo,Lirandë Pira,Patrick Rebentrost", "background": "量子容错量子处理单元(QPUs)有望在特定计算任务中提供指数级的速度提升，但在现代深度学习管线中的集成还不清楚。本文旨在通过提供首个完全相干的量子实现多层神经网络来弥补这一差距，该网络具有非线性激活函数。该实现基于广泛使用的基于ResNet的深度学习架构，包括残差块、多重滤波2D卷积、Sigmoid激活、跳过连接和层归一化。研究了网络在三种量子数据访问机制下的推理复杂性，并证明在至少一种情况下能够显著提高效率和减少计算成本。", "innovation": "本文提出了首个基于完全相干的量子实现多层神经网络模型，该模型使用了类似于ResNet架构的结构，包括残差块、多重滤波2D卷积、Sigmoid激活、跳过连接和层归一化。根据不同条件证明了该网络在某些情况下可以获得二次加速和四次加速，特别是在量子高效访问权重和输入数据的情况下，可以实施具有N维向量化输入、k层残差块和最终残差线性池化层的网络，并且可以精确度误差为ε的情况下实现O(polylog(N/ε)^k)的推理成本。", "conclusion": "本文的研究不仅提供了在量子运算环境下加速神经网络推理的有效路径，还进一步展示了量子计算在特定深度学习任务中可以实现显著的计算效率提升。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07242", "html_url": "https://arxiv.org/abs/2510.07242", "title": "Hybrid Reinforcement Learning: 当奖励稀疏时，密集更好", "title_en": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense", "authors": "Leitian Tao,Ilia Kulikov,Swarnadeep Saha,Tianlu Wang,Jing Xu,Yixuan Li,Jason E Weston,Ping Yu", "background": "大语言模型（LLMs）的后训练越来越依赖于验证者确定的验证奖励，这些奖励以0-1的正确性信号形式存在。虽然可靠，但这种二元反馈机制是脆性的，许多任务可能允许部分正确或替代答案，而验证者可能因此未能给予充分的信用。这种“全或无”的监督形式限制了模型的学习能力。为了克服这一问题，研究者提出了利用奖励模型提供的丰富连续反馈来作为验证者反馈的补充。HERO（Hybrid Ensemble Reward Optimization）框架通过将验证者信号与奖励模型分数结合，以有结构的方式整合二者，采用分层正则化来限制奖励模型得分在验证者定义的组内，并保留正确性的同时细化质量区分，以及采用具有方差感知的加权，强调那些需要密集信号的挑战性提示。实验结果显示，HERO方法在各种数学推理基准测试中表现出色，优于仅使用奖励模型或验证者的基准线，并在可验证和难以验证的任务上取得了显著的进步。", "innovation": "HERO框架通过整合验证者信号与奖励模型分数，提供了一种有结构的方法，采用分层正则化和方差感知加权来提高模型推理能力。这种方法不仅保持了验证者的稳定性，还利用了奖励模型的细微之处来推动学习。", "conclusion": "综上所述，该研究提出的HERO框架在数学推理基准测试中表现优异，能够有效利用验证者和奖励模型的结合来改进模型的推理能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07290", "html_url": "https://arxiv.org/abs/2510.07290", "title": "大型语言模型中道德自我纠正的收敛性研究", "title_en": "On the Convergence of Moral Self-Correction in Large Language Models", "authors": "Guangliang Liu,Haitao Mao,Bochuan Cao,Zhiyu Xue,Xitong Zhang,Rongrong Wang,Kristen Marie Johnson", "background": "大型语言模型（LLMs）在遵循指令进行自我校正时，能够提高其响应质量。当指令仅提供一个一般和抽象的目标，而不具体指定可能的响应问题时，LLMs 依赖其内部知识进行自我改进，这一过程称为内在的自我纠正。内在自我纠正的有效性在多个应用中得到了实证验证，但其有效性的机制和原理尚未明确。本文集中研究了道德自我纠正在LLMs中的表现，揭示了一个关键特性：通过多轮交互的性能收敛，并对该收敛行为进行了机制分析。通过对实验结果和分析，发现了收敛机制：持续注入的道德自我纠正指令激活了道德概念，从而降低模型的不确定性，导致在后续交互中不断趋于稳定并实现性能收敛。", "innovation": "揭示了内在自我纠正的收敛性特征，通过多轮交互实现了性能的稳定提升。通过实验证明，持续注入的自我纠正指令能够激活道德概念，从而降低模型的不确定性，进而导致性能的收敛。", "conclusion": "展示了道德自我纠正的强大潜力，该方法能够表现出期望的收敛性性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07304", "html_url": "https://arxiv.org/abs/2510.07304", "title": "Cocoon: 一种使用相关噪声进行差异隐私训练的系统架构", "title_en": "Cocoon: A System Architecture for Differentially Private Training with Correlated Noises", "authors": "Donghwan Kim,Xin Gu,Jinho Baek,Timothy Lo,Younghoon Min,Kwangsik Shin,Jongryool Kim,Jongse Park,Kiwan Maeng", "background": "机器学习（ML）模型会记住并泄露训练数据，导致数据所有者面临严重的隐私问题。差分隐私（DP）训练算法，如DP-SGD，被广泛认为是解决此问题的办法，但DP-SGD会在每次训练周期中添加噪声，这会降低训练模型的准确性。为提高准确性，一些新技术会添加精心设计的相关噪声，这些噪声在不同训练周期中相互抵消。然而，这些相关噪声机制的性能尚未被深入研究，特别对于大型模型或使用大型嵌入表的模型，它们会引入不可忽视的开销。", "innovation": "本文提出了一种名为Cocoon的硬件软件协同设计框架，用于高效地在相关噪声下进行差分隐私训练。Cocoon通过预计算和存储相关噪声并以聚簇格式存储来加速具有嵌入表的模型（Cocoon-Emb），并通过自定义近内存处理设备（Cocoon-NMP）支持大型模型。在基于FPGA的NMP设备原型的实际系统上，Cocoon将性能提高了2.33-10.82倍（Cocoon-Emb）和1.55-3.06倍（Cocoon-NMP）.", "conclusion": "Cocoon不仅解决了相关噪声机制带来的性能问题，还针对大型模型和嵌入表提出了专门的解决方案，显著提升了差分隐私训练的效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07315", "html_url": "https://arxiv.org/abs/2510.07315", "title": "Vibe Checker: 与人类偏好对齐的代码评估", "title_en": "Vibe Checker: Aligning Code Evaluation with Human Preference", "authors": "Ming Zhong,Xiang Zhou,Ting-Yun Chang,Qingze Wang,Nan Xu,Xiance Si,Dan Garrette,Shyam Upadhyay,Jeremiah Liu,Jiawei Han,Benoit Schillings,Jiao Sun", "background": "大型语言模型（LLMs）引发了vibe编码，用户通过自然语言互动生成和迭代代码，直到通过其vibe检查。vibe检查与实际人类偏好有关，不仅包括功能正确性，还超越了功能，强调解决方案需要感觉正确、语言清晰、保留意图且保持正确。目前的代码评估仅关注功能正确性（pass@k指标），而忽略了用户惯常应用的非功能性指令，这使得现有技术在衡量代码与人类偏好的一致性方面不够全面和有效。", "innovation": "本文假定指令遵循是vibe检查中反映代码评估中人类偏好缺失的关键因素。为量化模型的代码指令遵循能力，作者提出了VeriCode，这是一种包含30种可验证代码指令及其对应的确定性验证器的分类体系。通过使用此分类体系，作者扩展了现有评估套件，创建了Vibe Checker测试平台，以评估代码指令遵循和功能正确性。通过对31个领先LBM的评估，作者证明即使是最强模型也难以满足多个指令的要求，并且功能产生了明显偏差。更重要的是，功能正确性和指令遵循性复合评分与人类偏好高度相关，后者在实际编程任务中成为主要差异因素。", "conclusion": "本文确定了vibe检查的核心因素，为基准测试和开发更符合用户编程偏好模型的路径提供了具体方向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07191", "html_url": "https://arxiv.org/abs/2510.07191", "title": "分辨率缩放决定了DINOv3在胸部X光分类中的迁移性能", "title_en": "Resolution scaling governs DINOv3 transfer performance in chest radiograph classification", "authors": "Soroosh Tayebi Arasteh,Mina Shaigan,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn", "background": "自监督学习（SSL）已取得视觉表示学习的进展，但其在胸部X光领域（高容量成像方式，具有细微发现）的价值尚不清楚。Meta的DINOv3通过Gram锚定自我蒸馏扩展了早期SSL模型。尽管这些设计选择在胸部X光领域提升迁移学习的能力尚未系统性测试。本研究对比了DINOv3与DINOv2在七个数据集（样本数超过81.4万）上的表现，验证了ResNet和ConvNeXt两种骨干网络的初始版本。实验显示，DINOv3与DINOv2在成人数据集上表现相当；增加分辨率至512x512像素可为DINOv3提供一致的性能提升，而儿童数据集则未见不同初始化之间的差异。ConvNeXt-B在所有设置下均优于ViT-B/16。使用冻结的DINOv3-7B特征的模型表现不如完全微调的86-89M参数模型，表明领域适配的重要性。将分辨率扩大至1024x1024未进一步提高准确性。较大的输入分辨率对边界依赖性和小范围异常最为显著。在胸部X光领域，较高的输入分辨率对于利用现代自监督模型的好处至关重要。512x512像素是实用的上限，此时使用DINOv3初始化的ConvNeXt-B网络提供最佳性能，而更大的输入尺寸提供的性价比则不高。", "innovation": "本研究首次系统性地评估了DINOv3在不同分辨率下的性能，发现分辨率对胸部X光分类的迁移学习性能有很大影响。研究表明，增加输入分辨率可以提升模型性能，特别是在边界依赖性和小范围异常的检测上。此外，还对比了不同初始化和特征冻结策略，强调了领域适配的重要性。研究结果为在胸片解读中选择合适的骨干网络和输入分辨率提供了指导建议，特别是在急诊和重症护理场景中。", "conclusion": "在胸部X光分类中，较高的输入分辨率对现代自监督模型的性能至关重要，512x512像素是最具性价比的上限。使用DINOv3初始化的ConvNeXt-B网络在这一分辨率下提供最佳性能，而更大的输入尺寸对性能提升有限。对于胸部X光解读，使用微调过的中型骨干网络在512x512像素下表现最好，特别是在发现细微或以边界为中心的病变时有显著优势。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2208.08132", "html_url": "https://arxiv.org/abs/2208.08132", "title": "最大化不平衡噪声标签元学习验证集的实用性", "title_en": "Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning", "authors": "Dung Anh Hoang,Cuong Nguyen,Belagiannis Vasileios,Thanh-Toan Do,Gustavo Carneiro", "background": "元学习是处理不平衡和噪声标签学习的有效方法，但它依赖于随机选择、手动标注和平衡分布的验证集样本。随机选择和手动标注及平衡验证集不仅对元学习来说效率低下，而且随着类别的数量增加，其扩展性也变差。因此，最近的研究提出了手工设计的启发式方法以自动构建和标注验证集，但这些启发式方法仍然不能很好地支持元学习。", "innovation": "本文分析了元学习算法，并提出了新的验证集实用性评价标准，包括：1) 验证集的信息量；2) 集合中的类别分布平衡度；3) 标签的正确性。进一步提出了一种不平衡噪声标签元学习（INOLML）算法，该算法通过最大化上述标准来自动构建验证集。该方法在几个基准测试中显著优于之前的元学习方法，达到了新的最佳水平。", "conclusion": "本文提出的方法在几个基准测试中显著优于之前的元学习方法，为不平衡噪声标签元学习中的验证集构建问题提供了新的思路和解决方案，建立了新的最佳水平。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.06670", "html_url": "https://arxiv.org/abs/2310.06670", "title": "通过拒绝极端增强进行跨领域泛化", "title_en": "Domain Generalization by Rejecting Extreme Augmentations", "authors": "Masih Aminbeidokhti,Fidel A. Guerrero Peña,Heitor Rapela Medeiros,Thomas Dubail,Eric Granger,Marco Pedersoli", "background": "数据增强是提高深度学习模型识别性能的有效技术之一，适用于各种任务和领域。然而，这仅适用于领域内标准设置，在这种情况下，训练数据和测试数据遵循相同的分布。对于领域外（out-of-domain）的情况，测试数据遵循不同的且未知的分布，最合适的数据增强方法尚不清楚。本文探讨了数据增强在领域外和领域泛化设置中的应用，发现数据增强可以显著提升性能，并提出了一种新的数据增强方案。", "innovation": "本文提出了一种简单的训练方案：（i）在标准数据增强变换上进行均匀采样；（ii）增加变换强度以应对领域外工作时预期更高的数据变异；（iii）设计新的奖励函数来拒绝损害训练的极端变换。该方案在基准跨领域泛化数据集上的准确度与最新方法相当甚至更好。", "conclusion": "使用本文提出的数据增强方案，在基准跨领域泛化数据集上的准确度能够达到或超越最新方法的水平。该方法证明了数据增强在领域外和领域泛化设置中的有效性和鲁棒性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07318", "html_url": "https://arxiv.org/abs/2510.07318", "title": "人工海马网络用于高效长上下文建模", "title_en": "Artificial Hippocampus Networks for Efficient Long-Context Modeling", "authors": "Yunhao Fang,Weihao Yu,Shu Zhong,Qinghao Ye,Xuehan Xiong,Lai Wei", "background": "长序列建模在循环神经网络（RNN）样式的模型中，受到压缩固定大小内存效率的限制，而在基于注意机制的变压器中，长序列记忆的实现需要不断增长的内存，从而降低了精确度。目前现有的建模方法在效率和准确性之间存在根本性权衡，因此需要一种新型的建模框架来解决这一问题。机器认知科学中多次存储机制受到启发，提出了一种人工神经网络的存储框架。该框架保留了变压器的KV缓存作为无损的短期记忆，并通过一个可学习模块——人工海马网络（AHN）——压缩窗口外的信息到一个固定大小的紧凑长期记忆中，以解决这种权衡问题。", "innovation": "提出了一种新的存储框架——人工海马网络（AHN），它结合了变压器的KV缓存作为短期记忆，并通过一个可学习模块压缩窗口外的信息到一个固定大小的长期记忆，从而在减少计算和内存需求的同时，保持或提高到全关注模型的性能。创新性地使用现代循环神经网络架构（包括Mamba2、DeltaNet和门控DeltaNet）来实现AHN，并通过长上下文基准（LV-Eval和InfiniteBench）进行了广泛的实验验证。这种方法在性能和效率之间找到了一种新的平衡点，为长序列建模提供了新的解决方案。", "conclusion": "AHN增强模型在长上下文基准测试中表现出色，相较于滑动窗口基准模型，AHN增强模型表现更优或与全关注模型相当。例如，将AHN与Qwen2.5-3B-Instruct结合后，推理FLOPs减少了40.5%，内存缓存减少了74.0%，同时实现了LV-Eval平均分从4.41到5.88的提升。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.00856", "html_url": "https://arxiv.org/abs/2308.00856", "title": "联邦肿瘤分割中自适应加权聚合的差分隐私", "title_en": "Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation", "authors": "Muhammad Irfan Khan,Esa Alhoniemi,Elina Kontio,Suleiman A. Khan,Mojtaba Jafaritadi", "background": "联邦学习（FL）是一种分布式机器学习方法，通过创建公平的全局模型来保护隐私，同时尊重个体客户端数据的隐私。然而，传统的FL方法在处理多样化客户端数据时可能会引入安全风险，这可能损害隐私和数据完整性。为了应对这些挑战，本文提出了一种基于差分隐私（DP）的联邦深度学习框架，用于医学图像分割。该框架特别适用于多模态磁共振成像（MRI）中的脑肿瘤分割。通过引入提出的一种相似性加权聚合（SimAgg）方法的扩展版本——DP-SimAgg算法，既提高了模型的分割能力，又提供了额外的隐私保护层。广泛的基础和评估表明，DP-SimAgg算法能够在模型训练过程中降低通信成本，实现准确且稳健的脑肿瘤分割，这对于保护医疗图像数据的隐私和防止敏感信息泄露至关重要。", "innovation": "提出了一种基于差分隐私（DP）的相似性加权聚合（DP-SimAgg）算法，用于多模态磁共振成像（MRI）中的脑肿瘤分割。DP-SimAgg算法不仅提高了模型的分割能力，还提供了额外的隐私保护层，同时还能有效降低模型训练过程中的通信成本。", "conclusion": "在联邦脑肿瘤分割中，在全局权重聚合阶段加入差分隐私层，提供了一种在不牺牲分割模型效果的前提下解决隐私问题的有前景的解决方案。通过利用差分隐私，我们确保了客户端数据免受恶意攻击和恶意参与者的影响。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.11200", "html_url": "https://arxiv.org/abs/2408.11200", "title": "Want to train KANs at scale? Now UKAN!!", "title_en": "Want to train KANS at scale? Now UKAN!", "authors": "Alireza Moradzadeh,Srimukh Prasad Veccham,Lukasz Wawrzyniak,Miles Macklin,Saee G. Paliwal", "background": "Kolmogorov-Arnold Networks (KANs)虽然显示出强大的替代多层感知机的能力，但其依赖预定义、有界的网格限制了它们在无界域中逼近函数的能力。因此，本文旨在提出Unbounded Kolmogorov-Arnold Networks (UKANs)，以克服现有KANs模型在处理无界域时的限制。", "innovation": "ukans的主要创新在于引入了一个系数生成器（CG）模型，能够在无界对称网格上生成所需局部的B样条系数，这使得UKANs能够借助EG模型中的位置编码连接多层感知机与KANs，从而在处理无界域函数逼近时无需进行数据归一化。此外，为了降低UKANs和KANs的计算成本，作者引入了一个GPU加速库，通过提高B样条评估效率来促进大规模学习。", "conclusion": "性能基准测试证实了加速KAN（warpKAN）和UKANs在内存和计算效率方面的优越性，相比传统的KANs提高了3-30倍的速度，并减少了高达1000倍的内存消耗。实验表明UKANs在回归、分类和生成任务中能够匹配甚至超越KANs的准确性。最终，使用优化的实现，作者验证了UKANs在大规模端到端的分子属性预测任务中的可行性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.12598", "html_url": "https://arxiv.org/abs/2410.12598", "title": "基于多臂老虎机方法的深度强化学习动态学习率", "title_en": "Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach", "authors": "Henrique Donâncio,Antoine Barrier,Leah F. South,Florence Forbes", "background": "在深度强化学习（RL）中，学习率对于稳定性和性能至关重要，但其最优值会随着环境和策略的演变而变化。标准的学习率递减调度器假设单调收敛，但往往不能适应这些动态变化，导致学习率调整过早或过晚。", "innovation": "我们引入了LRRL（Learning Rate Reinforcement Learning），这是一种基于元学习的方法，可以根据策略性能动态选择学习率，而不是基于训练步骤。LRRL能够自适应地偏好可以提高回报的学习率，即使在候选集中包含可能导致发散的值时也能保持稳定。该方法在Atari和MuJoCo基准测试中的表现与调优的基础模型和标准调度器的性能相当或更优。", "conclusion": "我们的研究将LRRL定位为适应深度RL中非平稳目标的有效解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22371", "html_url": "https://arxiv.org/abs/2410.22371", "title": "Fokker-Planck PDE中物理导向神经网络误差界", "title_en": "Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs", "authors": "Chun-Wei Kong,Luca Laurenti,Jay McMahon,Morteza Lahijanian", "background": "常使用随机微分方程来描述随机过程的演化。状态不确定性最好由概率密度函数(PDF)表示，其演化由福克-普朗克偏微分方程(FP-PDE)所管治。然而，通常无法以封闭形式求解FP-PDE。", "innovation": "开发了理论框架来构建紧致误差边界，使用物理导向神经网络(PINNs)；提出了可使用标准训练方法便捷构建的实用误差边界；表明误差边界框架可以推广到其他线性偏微分方程的近似解。", "conclusion": "实验结果验证了误差边界正确性，展示了PINNs的优势，相比蒙特卡罗方法，快速获得高准确度的PDF解。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15492", "html_url": "https://arxiv.org/abs/2410.15492", "title": "基于强化学习的动态内存分配", "title_en": "Reinforcement Learning for Dynamic Memory Allocation", "authors": "Arisrei Lim,Abhiram Maddukuri", "background": "近年来，强化学习（RL）越来越受欢迎，并被应用于各种任务中。RL在系统中的资源管理问题上表现出了有效性，尤其是在动态内存分配管理方面。当前的一些算法，如首次适应、最佳适应和最差适应，由于缺乏环境适应性，有时会导致碎片化和效率低下。", "innovation": "本文通过引入强化学习框架，使代理持续从与系统的交互中学习，改进内存管理策略。并通过不同层级的动作空间进行实验，检验不同内存分配模式。结果显示，RL能够训练出能够匹配甚至超越传统分配策略的代理，特别是在具有敌对请求模式的环境中。", "conclusion": "我们认为，RL为开发更适应和高效的内存分配策略提供了一个有前景的途径，有可能克服硬编码分配算法的局限性。同时，基于历史的策略也有潜力帮助分配器更好地处理复杂请求模式。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.01642", "html_url": "https://arxiv.org/abs/2411.01642", "title": "量子意识图对比学习方法在粒子束区分中的应用", "title_en": "Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination", "authors": "Md Abrar Jahin,Md. Akmol Masud,M. F. Mridha,Nilanjan Dey,Zeyar Aung", "background": "在高能物理学中，粒子束标记是通过碰撞实验数据区分夸克束与胶子束的关键步骤。虽然基于图的深度学习方法已经超越了传统的特征工程方法，但复杂的数据结构和有限的标注样本依然构成了挑战。现有的对比学习框架难以有效利用基于理据的增强方法，往往缺乏用于引导重要特征提取的监督信号，并且存在计算效率问题，如参数量过大.", "innovation": "本文提出了一种结合量子理据生成器 (QRG) 的量子理据意识图对比学习框架 (QRGCL)。这种框架显著提高了粒子束的区分性能，减少了对标注数据的依赖，并成功捕捉到了区分性特征。在夸克-胶子粒子束数据集上，QRGCL 达到了 77.53% 的 AUC 分数，同时保持了紧凑的架构，仅使用 45 个 QRG 参数，其性能超过经典、量子和混合对比学习及图神经网络基准.", "conclusion": "这些结果表明，QRGCL 的潜在优势在于它能推进粒子束标记和高能物理学中的其他复杂分类任务，特别在处理计算效率和特征提取限制方面具有优势。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.00743", "html_url": "https://arxiv.org/abs/2409.00743", "title": "可解释聚类：综述", "title_en": "Interpretable Clustering: A Survey", "authors": "Lianyu Hu,Mudi Jiang,Junjie Dong,Xinying Liu,Zengyou He", "background": "近年来，聚类算法的研究主要集中在提高其准确性和效率上，但往往会牺牲其可解释性。然而，随着这些方法在高风险领域，如医疗保健、金融和自主系统中越来越广泛的应用，透明且可解释的聚类结果变得愈发重要。这不仅是获取用户信任的必要条件，也是满足这些领域日益增长的伦理和监管要求的关键所在。确保从聚类算法得出的决策可以清晰地被理解和验证，已经成为一个基本要求。本文提供了一篇全面而结构化的可解释聚类算法综述，识别了区分各种方法的关键标准，这些见解可以有效地帮助研究人员在特定应用场景中做出关于最合适的可解释聚类方法的选择，同时促进高效透明的聚类算法的研发与应用。为此，该综述提出了一种分类法，并建立了一个集合代表性和新兴的可解释聚类方法的开放资源，方便查阅和参考，链接为：this https URL", "innovation": "提出了关于可解释聚类算法的全面而结构化的综述，识别了区分各种方法的关键标准，并提供了一个分类法和开放资源来组织可解释聚类方法，方便研究人员选择最适合的应用场景，并促进透明聚类算法的研发与应用。", "conclusion": "本文提供了一篇关于可解释聚类算法的全面综述，帮助研究人员了解各种方法的差异性和适用场景，促进透明聚类算法的发展和应用。通过提供一个开放资源，本文还便于聚类算法的分类和参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.16063", "html_url": "https://arxiv.org/abs/2411.16063", "title": "VICON: 视觉上下文操作网络在多物理场流体动力学预测中的应用", "title_en": "VICON: Vision In-Context Operator Networks for Multi-Physics Fluid Dynamics Prediction", "authors": "Yadi Cao,Yuxuan Liu,Liu Yang,Rose Yu,Hayden Schaeffer,Stanley Osher", "background": "In-Context Operator Networks (ICONs) 已经展示出在多元偏微分方程中利用少量示例学习操作符的能力。然而，现有的 ICON 在处理高维度密集数据时存在严重的计算效率问题，因为每个空间点都被视为单独的标记处理。", "innovation": "作者提出了一种名为 Vision In-Context Operator Networks (VICON) 的新方法，通过视觉变换器架构整合视觉模块，可以高效地通过分块操作处理 2D 数据，同时保持对多物理系统和时间步长变化的适应性。VICON 方法在三种流体动力学基准测试中表现优异，精度显著优于现有先进方法 DPOT 和 MPP，在最后一步展开误差上分别减少了 37.9% 和 44.7%，同时只需要这两种方法少于 72.5% 和 34.8% 的推理时间。此外，VICON 自然支持灵活的时间步长展开策略，适用于不完善的测量系统，并在真实场景中表现出色，相对性能退化仅为 24.41%，远低于基准方法的 71.37% 至 74.49%。", "conclusion": "VICON 方法在多物理场流体动力学预测中展现了显著的优越性和灵活性，展示了其在真实应用中的广泛适用性，相关脚本和代码已公开。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17624", "html_url": "https://arxiv.org/abs/2411.17624", "title": "森林地上生物量估测中的机器学习和多源遥感：综述", "title_en": "Machine Learning and Multi-source Remote Sensing in Forest Aboveground Biomass Estimation: A Review", "authors": "Autumn Nguyen,Sulagna Saha", "background": "准确地量化森林地上生物量（AGB）对于制定保护地球的决策和政策至关重要。尽管机器学习（ML）和遥感（RS）技术已被用于更有效地完成这项任务，但目前缺乏系统回顾性的研究，特别是缺乏考虑到森林生态特征的ML方法与多种RS源的最新组合使用情况的综述。", "innovation": "本研究系统分析了80多篇相关研究中的25篇符合严格入选标准的论文，详述了所有使用的ML方法和RS数据组合。研究还发现了在75%的与其它方法对比的极端梯度提升方法具有最佳性能，以及Sentinel-1遥感源的最广泛应用，并指出基于多传感器的方法（例如Sentinel-1、Sentinel-2和激光雷达）特别有效。这些发现为建议在综合ML和RS时应考虑使用的遥感源、变量和方法提供了依据。", "conclusion": "本文的研究结果为在森林地上生物量估测中使用ML和多种RS源提供了新的见解，并推荐了特定的遥感源、变量和方法以提高估测准确性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17063", "html_url": "https://arxiv.org/abs/2411.17063", "title": "Contrastive Graph Condensation: 推动自我监督学习数据多功能性", "title_en": "Contrastive Graph Condensation: Advancing Data Versatility through Self-Supervised Learning", "authors": "Xinyi Gao,Yayong Li,Tong Chen,Guanhua Ye,Wentao Zhang,Hongzhi Yin", "background": "随着在大规模图上训练图神经网络（GNNs）所需计算量的增加，图凝缩（GC）已成为一种有前景的解决方案，用于合成大型原始图的紧凑替代图，以实现高效的GNN训练。然而，现有的GC方法大多采用分类作为优化的替代任务，因此过度依赖节点标签，在标签稀疏场景下的用途受限。此外，这种替代任务倾向于在凝缩图中过度拟合特定类别的信息，从而限制了GC在其他下游任务中的泛化能力。", "innovation": "为解决这些问题，我们引入了对比图凝缩（CTGC），这是一种自我监督的替代任务，可以从原始图中提取关键的因果信息，并增强凝缩图在跨任务的泛化能力。CTGC采用了一个双分支框架来分离节点属性和图结构的生成，其中专门设计了一个结构分支，通过节点的位置嵌入显式地编码几何信息。通过交替优化方案和对比损失项的应用，CTGC促进了两个分支之间的相互增强，并通过模型反转技术实现高质量的图生成。实验证明，CTGC在少数标签下能够有效地处理各种下游任务，并具有一系列最先进的GC方法中最佳的性能。", "conclusion": "CTGC通过采用自我监督的替代任务来提取关键的因果信息，并使凝缩图在跨任务中具有更好的泛化能力。实验结果表明，CTGC在少量标签的情况下，能够有效处理各种下游任务，并且在一系列最先进的GC方法中表现出最佳性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.04781", "html_url": "https://arxiv.org/abs/2412.04781", "title": "DPGIIL: Dirichlet Process-Deep Generative Model-Integrated Incremental Learning for Clustering in Transmissibility-based Online Structural Anomaly Detection", "title_en": "DPGIIL: Dirichlet Process-Deep Generative Model-Integrated Incremental Learning for Clustering in Transmissibility-based Online Structural Anomaly Detection", "authors": "Lin-Feng Mei,Wang-Ji Yan", "background": "现有的基于振动响应（如传递函数TFs）的聚类方法在结构异常检测中具有潜力，但大多数现有方法难以确定最优聚类数量，处理高维度的流式数据，并且依赖于手工工程特征，由于其浅层结构。", "innovation": "本文提出了一种创新的聚类框架，称为Dirichlet过程-深度生成模型-集成增量学习（DPGIIL），结合了深度生成模型（DGMs）在表示学习方面的优势和Dirichlet过程混合模型（DPMM）在识别观察数据中不同模式方面的优势。DPGIIL通过变分贝叶斯推断方法推导出更紧的下界，从而优化DGM和DPMM参数，并且提出了一种贪婪分裂-合并方案为基础的坐标上升变分推断方法来加速优化过程。DPGIIL通过动态分配传入数据到新聚类来检测异常，并通过不同的聚类显示不同的结构状态，提供了与传统异常检测器相比的额外信息。", "conclusion": "三个案例研究表明，所提出的方法具有动态适应性，并且在结构异常检测和聚类方面均优于一些现有先进技术。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17384", "html_url": "https://arxiv.org/abs/2501.17384", "title": "深度强化学习中鲁棒泛化的双代理对抗框架", "title_en": "A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning", "authors": "Zhengpeng Xie,Yulong Zhang", "background": "近年来，得益于神经网络的强大能力，强化学习（RL）已经成功应对了大量具有挑战性的任务。然而，这些模型虽然在决策能力上有所提升，但由于其容易过拟合，它们的泛化能力越来越差。例如，一个训练好的RL模型在对同一任务的小幅变化（如背景颜色的改变或其他细微语义差异）上往往无法很好地泛化。", "innovation": "本文提出了一种双代理对抗策略学习框架，允许代理在不引入任何先验的人类知识的情况下自发学习并发现潜在的语义。该框架包括两个代理之间的博弈过程，每个代理试图通过为相同的环境状态生成差异性表示来最大化对对手策略的影响，同时保持自身对这种扰动的稳定性。这种交互促进了代理学习广泛适用的策略，这些策略能够处理高维观察中的不相关信息。", "conclusion": "在Procgen基准测试上进行的广泛实验表明，对抗过程显著提升了两个代理的泛化性能，并且该对抗框架可以应用于多种RL算法，如Proximal Policy Optimization（PPO）。使用对抗框架的RL代理比基线方法在难度较高的任务上表现出更显著的性能提升，标志着在深度强化学习的泛化能力方面取得了重要的进步。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00336", "html_url": "https://arxiv.org/abs/2502.00336", "title": "随机特征去噪得分匹配：精确学习曲线对扩散模型的洞见", "title_en": "Denoising Score Matching with Random Features: Insights on Diffusion Models from Precise Learning Curves", "authors": "Anand Jerry George,Rodrigo Veiga,Nicolas Macris", "background": "本文研究了扩散模型中泛化和记忆现象的理论性质。已有实证研究表明，这些现象受模型复杂度和训练数据集大小的影响。此外，实验还发现，每数据样本使用的噪声样本数（m）在去噪得分匹配（DSM）过程中起着重要作用。", "innovation": "本文通过简化理论设定，推导出了适用于随机特征神经网络参数化的得分函数条件下，DSM测试和训练误差的精确表达式。通过对这些误差的分析，确定了泛化和记忆现象随 $\boldsymbol{\boldsymbol{\frac{n}{d}}}$、$\boldsymbol{\boldsymbol{\frac{p}{d}}}$ 和 $m$ 变化的不同区间。", "conclusion": "本文的理论发现与实证观察结果一致，深化了对扩散模型中泛化与记忆现象的理解。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16379", "html_url": "https://arxiv.org/abs/2501.16379", "title": "FedAGHN: 使用警觉图超网络进行个性化联邦学习", "title_en": "FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks", "authors": "Jiarui Song,Yunheng Shen,Chengbin Hou,Pengyu Wang,Jinbao Wang,Ke Tang,Hairong Lv", "background": "个性化联邦学习（PFL）旨在解决不同客户端之间数据统计异质性的问题，通过为每个客户端学习个性化的模型。聚合基方法在服务器端聚合阶段根据聚合作用来生成个性化模型，并集中在不同客户端之间合适的合作关系的学习上。然而，这些合作关系在不同场景和联邦学习过程的不同阶段有所不同。", "innovation": "提出了一种名为FedAGHN的新方法，利用警觉图超网络（AGHNs）动态捕捉细粒度的合作关系并生成针对每个客户端的个性化初始模型。AGHNs能够明确建模客户端特定的合作关系，构建合作图，并引入可调注意力机制来推导合作权重，从而通过合作图聚合参数获得个性化的初始模型。", "conclusion": "广泛的实验表明FedAGHN的优越性。相关可视化结果还展示了FedAGHN学习的合作图的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.19040", "html_url": "https://arxiv.org/abs/2501.19040", "title": "向大型语言模型最坏情况鲁棒性的研究", "title_en": "Towards the Worst-case Robustness of Large Language Models", "authors": "Huanran Chen,Yinpeng Dong,Zeming Wei,Hang Su,Jun Zhu", "background": "近期研究表明，大型语言模型容易受到对抗攻击的影响，攻击者可以设计特定的输入序列来诱导有害、暴力、隐私或错误的输出。研究表明，这些模型在最坏情况下的鲁棒性较差，即是否存在对抗样例会导致这些不良输出。这项工作聚焦于研究这一问题，旨在量化最坏情况下的鲁棒性边界，以及当前防御措施的有效性。", "innovation": "该研究引入了更强的白盒攻击来上界最坏情况下的鲁棒性，表明现有大多数确定性防御措施在最坏情况下的鲁棒性接近于零。同时，研究提出了随机平滑的通用紧致下界，使用分数背包和0-1背包求解器，用于上限各种随机防御措施的最坏情况鲁棒性。研究还为多种先前的实验性防御措施提供了理论下界，例如，具体证明了在任何可能的攻击下，使用均匀核函数的平滑方法的鲁棒性，其平均$ \text{\\textbackslash{}ell}_0 $扰动为2.02，平均后缀长度为6.41.", "conclusion": "研究发现大多数当前确定性的防御措施在最坏情况下的鲁棒性接近于零，同时提出了多种随机平滑防御措施的理论下界，并验证了一些具体防御措施的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07218", "html_url": "https://arxiv.org/abs/2502.07218", "title": "通过神经激活重定向实现大语言模型去学习", "title_en": "LLM Unlearning via Neural Activation Redirection", "authors": "William F. Shen,Xinchi Qiu,Meghdad Kurmanji,Alex Iacob,Lorenzo Sani,Yihong Chen,Nicola Cancedda,Nicholas D. Lane", "background": "从LLMs中选择性地删除知识的能力非常 desirable。然而，现有的方法往往在平衡遗忘效率和保持模型实用性方面遇到困难，并且缺乏在推理时控制以模拟基础模型行为的能力，就像从未见过要遗忘的数据一样。", "innovation": "本文提出了一种新颖的去学习方法LUNAR，该方法基于线性表示假设，并通过将未学习数据的表示重定向到表达其无法回答的激活区域来运作。实验显示，对比特征不是有效激活重定向的必要条件，LUNAR实现了最先进的去学习性能和优越的可控性。尤为突出的是，LUNAR在各种基础模型上实现了2.9到11.7倍的去学习效率和模型实用性综合得分提升，并且在去学习后生成连贯、上下文适当的响应。此外，LUNAR将参数更新减少为单一的下投影矩阵，这一新颖设计提高了20倍效率并增强了鲁棒性。", "conclusion": "最后，我们证明LUNAR对白盒 adversarial 攻击具有鲁棒性，并且在实际场景中颇具 versatility，包括处理顺序去学习请求。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17518", "html_url": "https://arxiv.org/abs/2501.17518", "title": "使用任意欧几里得区域实现类似双曲的表达性：层级嵌入的一种新方法", "title_en": "Achieving Hyperbolic-Like Expressiveness with Arbitrary Euclidean Regions: A New Approach to Hierarchical Embeddings", "authors": "Hui Yang,Jiaoyan Chen", "background": "在生命科学和电子商务等多个领域中，层级数据很常见，其嵌入往往扮演着重要角色。现有的双曲嵌入方法从理论上来说能够以低维空间表示层次结构，然而当前方法往往依赖于特定的几何构造作为嵌入候选，这种依赖性限制了其泛化能力，并且难以集成与纯层次结构以外的语义关系建模技术，例如本体嵌入技术。因此，论文提出了RegD，一种灵活的欧几里得框架，支持使用任意几何区域，如箱子和球，作为嵌入表示。尽管RegD完全在欧几里得空间中操作，但通过将区域间的深度基础差异纳入考虑，形式上证明了它能够实现类似双曲的表达性，从而使它可以模拟双曲几何的关键特性，包括指数增长。", "innovation": "论文提出了RegD，一种灵活的欧几里得框架，支持使用任意几何区域作为嵌入表示。与当前依靠特定几何构造的方法不同，RegD引入了基于深度区域差异的概念，使其能够在保持欧几里得环境中同时展现出类似双曲的表达能力。", "conclusion": "在多领域的真实世界数据集上进行的实证研究表明，RegD在性能上优于最先进的方法，并展示了其在本体嵌入等扩展应用中的潜力，而不仅仅是层级结构。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19649", "html_url": "https://arxiv.org/abs/2502.19649", "title": "大型语言模型中表示工程的分类、机会与挑战", "title_en": "Taxonomy, Opportunities, and Challenges of Representation Engineering for Large Language Models", "authors": "Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz", "background": "研究表明，表示工程（RepE）是一种新颖的范式，用于控制大型语言模型（LLMs）的行为。与传统的修改输入或微调模型的方法不同，RepE直接操作模型的内部表示。因此，它可能提供更有效的、可解释的、数据高效的和灵活的模型行为控制。", "innovation": "本文提出了表示工程（RepE）的第一个全面综述，通过审查快速增长的文献来回答关键问题：现有RepE方法及其差异是什么？RepE应用到了哪些概念和问题中？与其它方法相比，RepE的优点和缺点是什么？为了回答这些问题，作者提出了一种统一的框架，将RepE描述为由表示识别、操作化和控制组成的管道。尽管RepE方法具有巨大潜力，但仍存在管理多个概念、确保可靠性以及保留模型性能的挑战。", "conclusion": "为了改进RepE，作者指出了实验和方法上的改进机会，并构建了一份最佳实践指南。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12845", "html_url": "https://arxiv.org/abs/2502.12845", "title": "ExLLM：用于分子设计及其他领域的经验增强LLM优化", "title_en": "ExLLM: Experience-Enhanced LLM Optimization for Molecular Design and Beyond", "authors": "Nian Ran,Yue Wang,Xiaoyuan Zhang,Zhongzheng Li,Qingsong Ran,Wenhao Li,Richard Allmendinger", "background": "分子设计涉及到一个庞大且不规则的搜索空间，传统优化器如贝叶斯优化、遗传算法和生成模型难以利用专家知识或处理复杂反馈。近年来，大规模语言模型（LLMs）被用作优化器，并在PMO等基准测试中取得了有希望的结果。然而，现有方法仅依赖提示或额外训练，缺乏处理复杂反馈或维护可扩展记忆的机制。特别是在每次查询时简单地追加或总结经验的做法导致了冗余、探索退化和整体结果不佳。", "innovation": "ExLLM是一种经验增强的LLM优化框架，包含三个组件：（1）一个适应大规模离散空间且不断演化的经验片段，可以以低成本提取非冗余线索并提高收敛性；（2）一种简单而有效的k-子种方案，在每次调用中增加探索范围并降低协调成本；（3）一种轻量级的反馈适配器，可以规范化目标以供选择并格式化约束和专家提示以适用新迭代。ExLLM在PMO上建立了新的最新的研究成果，并在实验设置中表现出强烈的泛化能力，它在圆包装和恒星装置设计中创下了记录，并在其他需要仅提供任务描述模板和评估函数的领域中实现了持续的改进。", "conclusion": "ExLLM在分子设计以及其他领域取得了卓越的效果，通过提出的经验增强LLM优化框架实现在大规模迭代搜索中处理复杂反馈和保持高效内存管理方面的新突破。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01588", "html_url": "https://arxiv.org/abs/2502.01588", "title": "通过最优传输的可微对齐框架用于序列到序列建模", "title_en": "A Differentiable Alignment Framework for Sequence-to-Sequence Modeling via Optimal Transport", "authors": "Yacouba Kaloga,Shashi Kumar,Petr Motlicek,Ina Kodrasi", "background": "准确的序列到序列对齐对于医疗语音分析和依赖自动语音识别(ASR)的语言学习工具是至关重要的。现有的端到端ASR系统，如连接主义时序分类(CTC)和基于转录器的模型，会表现出尖峰行为和对齐不准确的问题。", "innovation": "提出了一种基于一维最优传输的新型可微对齐框架，可以使模型学习单一的对齐方式并以端到端的方式进行ASR。引入了序列最优传输距离(SOTD)的伪度量，并讨论了其理论性质。提议了一种基于SOTD的最优时序传输分类(OTTC)损失函数，对比了其与CTC的行为。实验结果表明，方法显著提高了对齐性能，虽然ASR性能有所妥协。", "conclusion": "这项工作为序列到序列对齐研究开辟了新的方向，为社区内的进一步探索和发展提供了坚实的基础。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17832", "html_url": "https://arxiv.org/abs/2502.17832", "title": "MM-PoisonRAG：利用局部和全局中毒攻击扰乱多模态RAG", "title_en": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks", "authors": "Hyeonjeong Ha,Qiusi Zhan,Jeonghwan Kim,Dimitrios Bralios,Saikrishna Sanniboina,Nanyun Peng,Kai-Wei Chang,Daniel Kang,Heng Ji", "background": "多模态大语言模型与检索增强生成（RAG）相结合，在多模态问答等任务中取得了显著的进步。这种结合使得答案能够基于外部文本和图像进行接地，从而提升了事实性，减少了佯谬，并扩展了推理能力。然而，对外部知识的依赖也带来了关键但尚未充分探索的安全风险：知识中毒攻击。这些攻击者故意向外部知识库注入有害的多模态内容，以引导模型生成错误甚至有害的响应。为了暴露这些漏洞，本文提出了一种新颖的MM-PoisonRAG框架，这是首次系统设计多模态RAG中的知识中毒方法。MM-PoisonRAG框架包括两种互补的攻击策略：局部中毒攻击（LPA）和全局中毒攻击（GPA）。", "innovation": "本文提出了一种名为MM-PoisonRAG的新颖框架，这是首次系统地设计用于多模态RAG的知识中毒方法。MM-PoisonRAG框架中包括了两种互补的攻击策略：局部中毒攻击（LPA）和全局中毒攻击（GPA）。研究结果表明，LPA在成功操纵特定查询方面能够实现高达56%的攻击成功率，而GPA只需一次有害的知识注入就能彻底破坏模型生成的准确性，达到0%的正确率。这项研究揭示了多模态RAG的脆弱性，并强调了迫切需要针对知识中毒攻击的防御措施。", "conclusion": "本文的研究结果揭示了多模态RAG的脆弱性，并强调了短期内迫切需要针对知识中毒攻击的防御措施。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17353", "html_url": "https://arxiv.org/abs/2503.17353", "title": "NdLinear：保留多维结构的参数高效神经网络", "title_en": "NdLinear: Preserving Multi-Dimensional Structure for Parameter-Efficient Neural Networks", "authors": "Alex Reneau,Jerry Yao-Chieh Hu,Zhongfang Zhuang,Ting-Chun Liu,Xiang He,Judah Goldfeder,Nadav Timor,Allen G Roush,Ravid Shwartz-Ziv", "background": "在深度学习中，处理多维输入（例如图像、医学影像和时间序列）是一个重要的任务，通常需要将输入展平。NdLinear通过引入一种可以直接在张量上运行的线性层，无需展平输入来解决这一问题。", "innovation": "NdLinear是一种可以直接作用于张量的线性层替代方案，它通过分别沿每个维度应用变换，在保持原始数据结构的同时实现了参数数量的大幅减少，有时能达到数个数量级，且几乎不增加内存开销。NdLinear通过结构化的Tucker分解保留了表达能力，并保持了VC-维度缩放。大量实验表明，NdLinear能够显著减少参数数量，同时在墙壁时间效率上获得大幅提升，并且几乎不增加内存开销。", "conclusion": "NdLinear在轴分离任务中表现出色，但在处理纠缠的空间互作时有所局限。通过直接处理原始N维数据，NdLinear为构建更高效的神经架构提供了有理论基础和实用性的组件。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16192", "html_url": "https://arxiv.org/abs/2503.16192", "title": "非参数贝尔曼映射在分布式强化学习中用于价值迭代", "title_en": "Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning", "authors": "Yuki Akiyama,Konstantinos Slavakis", "background": "在分布式强化学习(DRL)中，多个智能体部署在一个无向且连接的网络上，网络没有中央节点来聚集所有数据和执行计算。每个智能体基于其私有数据构建非参数的贝尔曼映射(B-Map)，并在希尔伯特特征空间上操作Q函数，具有多种选择表示基础的灵活性。虽然现有的DRL方法通常在Q函数上传递信息，但本文提出的方法还允许通过协方差矩阵传递基础信息。存在的研究已建立，在任意网络拓扑下，Q函数和协方差矩阵估计以线性收敛的速度收敛到其共识值，而最优学习率是由图的Fiedler值与图拉普拉斯矩阵最大特征值的比例决定的。研究表明，所提出的DRL框架能够有效近似存在中央节点时的性能。", "innovation": "本文提出了用于分布式强化学习中的非参数贝尔曼映射(B-Map)，并在不设中央节点的网络上工作。智能体通过直接邻近的节点交换Q函数估计和基础信息（以协方差矩阵的形式）。研究证明了线性收敛速度，并且所提出的方法通过传递基础信息加速了学习过程，尽管涉及更多的信息交换，但累积通信成本却更低。", "conclusion": "通过非参数贝尔曼映射，分布式强化学习中的智能体能够更好地协同工作。理论分析和数值实验均证实了该方法的有效性，其能够近似出假设存在中央节点时的性能，同时减少了累积通信成本。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.15559", "html_url": "https://arxiv.org/abs/2503.15559", "title": "无线网络中分裂联邦学习高效同步的新型协作框架", "title_en": "A Novel Collaborative Framework for Efficient Synchronization in Split Federated Learning over Wireless Networks", "authors": "Haoran Gao,Samuel D. Okegbile,Jun Cai", "background": "在无线网络中，分裂联邦学习（SFL）作为一种分布式模型训练的方法，结合了分裂学习的分层划分优势和联邦聚合的优势，以确保全局收敛。然而，在异构无线环境中，设备能力和信道条件的差异使得严格的轮次同步变得非常依赖延迟设备，从而限制了效率和可扩展性。", "innovation": "我们提出了一个新的框架，称为协作分裂联邦学习（CSFL），通过设备之间的协作重新定义了工作负载重分配。CSFL 允许高效设备在其本地前向传播完成后，无缝地接管瓶颈设备的未完成层。这种协作过程通过设备间通信支持，可以让瓶颈设备更早地卸载计算任务，同时保持网络同步的进展。此外，我们还强调了关键技术使能器，如隐私保护、多视角匹配和激励机制，并讨论了实际挑战，包括匹配平衡、隐私风险和激励可持续性。", "conclusion": "案例研究显示，CSFL 在不牺牲收敛速度或准确性的前提下显著减少了训练延迟，证明了协作是下一代无线网络中高效同步学习的关键使能器。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15946", "html_url": "https://arxiv.org/abs/2505.15946", "title": "MoRE-Brain: 拓扑混合专家体系结构用于可解释和跨被试泛化的fMRI 视觉解码", "title_en": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "authors": "Yuxiang Wei,Yanteng Zhang,Xi Xiao,Tianyang Wang,Xiao Wang,Vince D. Calhoun", "background": "从功能磁共振成像(fMRI)解码视觉体验为理解人类感知和开发先进的人机接口提供了强大的途径。然而，当前的研究往往侧重于最大化重建的准确性，而忽视了解释性，这是获得神经科学洞见的关键因素。", "innovation": "MoRE-Brain 提出了一种神经启发式的框架，用于高保真、适应性和可解释的视觉重建。MoRE-Brain 首次引入了一种基于脑网络原则的混合专家架构，用于神经解码。它通过共享核心专家网络并在可适应的路由器上进行适应来实现高效的跨被试泛化。该系统通过明确的路由机制增强了机制性洞察力，揭示了不同建模脑区如何塑造重建图像的语义和空间属性。", "conclusion": "MoRE-Brain 在更通用和可解释的 fMRI 基于视觉解码方面迈出了重要一步。实验证明，MoRE-Brain 的重建保真度很高，其瓶颈分析进一步证明它有效地利用了 fMRI 信号，区分了真实的神经解码和对生成先验的过度依赖。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17646", "html_url": "https://arxiv.org/abs/2505.17646", "title": "大型语言模型中的类似盆地损失景观揭开", "title_en": "Unveiling the Basin-Like Loss Landscape in Large Language Models", "authors": "Huanran Chen,Yinpeng Dong,Zeming Wei,Yao Huang,Yichi Zhang,Hang Su,Jun Zhu", "background": "本文探讨了大型语言模型（LLMs）在训练过程中损失景观的特性，特别是在模型规模增加时，模型如何变得对参数空间中的随机扰动更具鲁棒性。研究者观察到，随着模型规模的增加，模型在某些区域展现出极高的稳定性和性能，而在其他区域则性能急剧下降。", "innovation": "1. 揭示了LLMs损失景观中的‘盆地’现象，即随着模型规模的增大，存在大量的性能相近的区域，但这些区域之外，模型的能力会迅速下降。2. 提出了‘基本能力盆地’和‘特定能力盆地’的概念，并指出受限于盆地的良性微调可以保存先前的能力。3. 分析了最坏情况的方向上的损失景观，发现这些方向是非常陡峭且有害的，并且对抗性微调往往沿着这些方向进行，导致模型能力快速下降。4. 提供理论分析，证明盆地的大小限制了任何微调（包括对抗性微调）的性能下降，并保证模型对输入扰动的鲁棒性。", "conclusion": "本文提出，通过扩大这些盆地的大小，可以提高模型的鲁棒性，并且在特定能力盆地的良性微调可以保护模型原有的能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10607", "html_url": "https://arxiv.org/abs/2505.10607", "title": "MONAQ: 为资源受限设备上的时间序列分析提出多目标神经架构查询", "title_en": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series Analysis on Resource-Constrained Devices", "authors": "Patara Trirat,Jae-Gil Lee", "background": "智能手机和物联网设备的普及使得对资源受限硬件的时间序列分析变得至关重要，这对于诸如人体活动识别和空气质量预测等感知应用非常重要。尽管最近在硬件感知神经架构搜索（NAS）方面已经努力自动化特定平台的架构发现，但这些努力并未关注边缘部署条件下的通用时间序列分析。因此，需要一种既能处理多模态时间序列输入又能优化硬件约束条件的多目标架构查询框架，以生成部署就绪的模型。", "innovation": "本文提出了MONAQ，这是一种新颖的框架，通过将NAS任务重新定义为多目标神经架构查询任务来解决这些问题。MONAQ结合了多模态查询生成和基于大型语言模型代理的多目标搜索，从而能生成具有良好代码生成性能的部署就绪模型。该框架通过整合数值数据、时间序列图像和文本描述，增强了大型语言模型对时间序列数据的理解。实验结果表明，MONAQ发现的模型在性能上优于手工艺品模型和NAS基线模型，并且更为高效。", "conclusion": "MONAQ通过集成数值数据、时间序列图像和描述性文本来提高大型语言模型对时间序列数据的理解。通过实验表明，MONAQ发现的模型在性能上优于手工艺品模型和NAS基线模型，并且更为高效。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12576", "html_url": "https://arxiv.org/abs/2505.12576", "title": "AdaDim：适应性维度调节下的SSL表示动态", "title_en": "AdaDim: Dimensionality Adaptation for SSL Representational Dynamics", "authors": "Kiran Kokilepersaud,Mohit Prabhushankar,Ghassan AlRegib", "background": "在有效的半监督学习（SSL）中，防止维度坍塌是一个关键因素，即高维表示空间跨度较低维的子空间。因此，SSL优化策略旨在通过鼓励特征去相关或样本在表示空间中的均匀性，引导模型产生较高维度的表示空间。较高的表示空间维度表明该空间具有更多的特征多样性，这有助于下游任务的泛化。除了维度优化，SSL算法还使用投影头将表示空间映射到嵌入空间。最近的研究表明，投影头可以通过减少互信息来过滤SSL目标中的噪声或无关特征。因此，当前文献认为有效的SSL表示空间应具有高的特征多样性（H(R)）和低的互信息(I(R;Z))。但这种观点没有从训练动力学的角度充分理解这两者之间的关系。我们分析表明，表现最佳的SSL模型不具有最高的H(R)和最低的I(R;Z)，而是在这两者之间取得了平衡。", "innovation": "我们提出了一种新的训练策略AdaDim，它通过自适应地平衡特征去相关和样本均匀性以增加表示空间维度，以及在训练过程中逐步正则化互信息，来利用SSL训练动力学。尽管我们的方法没有使用队列、聚类、预测网络或学生-教师架构等昂贵技术，但展示了在常见SSL基线方法上的性能改进最多达到3%。", "conclusion": "AdaDim策略通过自适应地平衡特征去相关和样本均匀性，以及逐步正则化互信息，成功地提高了SSL模型的泛化能力，同时避免了使用昂贵的训练技术。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20444", "html_url": "https://arxiv.org/abs/2505.20444", "title": "HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models", "title_en": "HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models", "authors": "Haoran Li,Yingjie Qin,Baoyuan Ou,Lai Xu,Ruiwen Xu", "background": "Vision-Language Models (VLMs)在多模态任务方面取得了显著进展，但在长上下文场景中，尤其是长视频中，其性能往往会下降。尽管Rotary Position Embedding (RoPE)在大型语言模型（LLMs）中广泛用于长度泛化，但将其扩展以捕捉视频中的复杂空时依赖关系仍然是一项挑战。现有方法通常通过在RoPE中分配不同的频率来编码3D位置信息，但这些策略主要依赖于直觉，缺乏深入的理论分析。", "innovation": "本文首先研究了不同分配策略对VLMs长上下文能力的影响。分析表明，当前的多模态RoPEs无法可靠地捕捉扩展上下文中的语义相似性。为了解决这一问题，我们提出了HoPE（Hybrid of Position Embedding），一种用于提高VLMs长上下文能力的混合位置嵌入设计。HoPE引入了一种混合频率分配策略，以在任意长的上下文中进行可靠的语义建模，并提出了一种动态时间缩放机制，以促进在不同上下文长度中的稳健学习和灵活推理。", "conclusion": "在四个视频基准上的广泛实验表明，HoPE在长视频理解和检索任务上始终优于现有方法，证实了其有效性。我们的代码可通过此链接访问：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22524", "html_url": "https://arxiv.org/abs/2505.22524", "title": "通过重要性加权和最优proposal设计，在生成阶段扩展离散扩散模型", "title_en": "Inference-Time Scaling of Discrete Diffusion Models via Importance Weighting and Optimal Proposal Design", "authors": "Zijing Ou,Chinmay Pani,Yingzhen Li", "background": "离散扩散模型在多个领域中表现出高度的效果，但在实际应用中往往需要使生成过程符合某些约束条件。", "innovation": "提出了一个序列蒙特卡罗（SMC）框架，通过原则性的重要性加权和最优proposal构建方法，实现在生成阶段灵活性扩展离散扩散模型。", "conclusion": "我们的框架在合成任务、语言建模、生物学设计和文本到图像生成等多个任务中提升了控制性和样本质量，证明了SMC作为扩展离散扩散模型的有效方法的通用性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17967", "html_url": "https://arxiv.org/abs/2505.17967", "title": "基于FFT的动态子空间选择用于大规模语言模型的低秩自适应优化", "title_en": "FFT-based Dynamic Subspace Selection for Low-Rank Adaptive Optimization of Large Language Models", "authors": "Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh", "background": "低秩优化已成为训练大规模语言模型（LLMs）的一种有前景的方向，旨在通过将学习约束在更低维度的空间内来提高运行时间和减少自适应优化器的内存使用。早期的工作通常使用奇异值分解（SVD）或QR分解来投影线性层的梯度。然而，单独应用于大型模型中的每一层会带来高昂的计算成本和额外的内存开销。本文背景这部分说明了低秩优化的重要性以及现有方法的局限性。", "innovation": "本文提出了一种高效且概念清晰的两步方法，通过采用离散余弦变换（DCT）预定义的正交矩阵来近似SVD/QR基的梯度投影到低维空间。根据不同层梯度的对齐情况动态选择DCT矩阵的列，然后通过简单的矩阵乘法和轻量级排序得到有效的投影矩阵。对于大型层，DCT可以通过Makhoul的FFT算法在理论时间内计算。这种方法的特点是预定义的正交基只需在训练开始时计算一次。实验证明了该方法的有效性，能够在不影响运行时间的情况下逼近最优低秩投影，且在不同模型尺寸上实现了更快的运行时间和25%的内存使用减少。", "conclusion": "研究结果表明，通过基于DCT的预定义正交基近似SVD/QR基的梯度投影，该方法不仅匹配了昂贵的SVD/QR基方法的性能，而且实现了更快的运行时间和更低的内存使用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10478", "html_url": "https://arxiv.org/abs/2504.10478", "title": "WiSE-FT 改进语言模型的推理", "title_en": "Weight Ensembling Improves Reasoning in Language Models", "authors": "Xingyu Dang,Christina Baek,Kaiyue Wen,Zico Kolter,Aditi Raghunathan", "background": "研究中探讨了推理模型训练过程中出现的一种失效模式，即生成的多样性开始崩溃，导致测试时扩展性不佳。尽管监督微调（SFT）可以有效地提高Pass@1的准确率，但Pass@k却快速下降。出乎意料的是，通过简单地将最新SFT检查点的权重与早期检查点的权重进行插值，即WiSE-FT，可以几乎完全恢复Pass@k，并且还提高了Pass@1的准确性。", "innovation": "提出了WiSE-FT作为一种简单的干预措施，在保持Pass@1的同时几乎完全恢复了Pass@k，甚至在进一步通过强化学习调优时还取得了更好的结果。WiSE-FT提供了通过多样性诱导解码策略无法实现的补充性能增益，还揭示了Pass@k偏差和方差之间的权衡关系，并发现WiSE-FT可以同时减少偏差和方差。", "conclusion": "WiSE-FT方法在保持多样化生成的同时显著改善了语言模型的推理性能，特别是在有限数据情况下的测试时间扩展性，并且通过权衡偏差和方差，提高了整体模型的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21626", "html_url": "https://arxiv.org/abs/2505.21626", "title": "学习在哪里学习：用于科学机器学习的训练数据分布优化", "title_en": "Learning where to learn: Training data distribution optimization for scientific machine learning", "authors": "Nicolas Guerra,Nicholas H. Nelsen,Yunan Yang", "background": "在科学机器学习中，模型通常会在与训练时参数值或边界条件不同的场景下部署。本文研究了旨在最小化不同部署场景下的平均预测误差的训练数据分布设计问题。理论分析表明训练分布如何影响部署准确性，进而提出两种基于度量空间中偏微数或交替优化的自适应算法，最终使用参数分布类或非参数粒子流动实现优化后性能更优的训练分布。这样的框架揭示了原理性的数据获取对于学习偏微分方程解算器潜力的重要性，从而提高了模型对分布偏移的鲁棒性和样本复杂度", "innovation": "提出了用于自适应优化训练数据分布的两个新型算法，包括基于度量空间中偏微数或交替优化的概念，然后通过参数分布类或非参数粒子流动的离散实现来优化训练数据的分布模式，从而提高了模型的样本复杂度并增强了其在分布偏移下的鲁棒性。", "conclusion": "所提出的框架为科学机器学习中学习函数和偏微分方程解算器提供了原理性的数据获取可能性，从而显著增强了模型的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23663", "html_url": "https://arxiv.org/abs/2505.23663", "title": "AMBER：通过迭代网格分辨率预测实现自适应网格生成", "title_en": "AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction", "authors": "Niklas Freymuth,Tobias Würth,Nicolas Schreiber,Balazs Gyenes,Andreas Boltres,Johannes Mitsch,Aleksandar Taranovic,Tai Hoang,Philipp Dahlinger,Philipp Becker,Luise Kärger,Gerhard Neumann", "background": "使用有限元方法（FEM）模拟复杂物理系统的成本和准确性与底层网格的分辨率成比例。自适应网格通过在关键区域细化分辨率来提高计算效率，但通常需要特定任务的手动设计方案或复杂的参数调优。因此，该方法依赖于人为专家的经验，并且不太能适应未知的新几何结构", "innovation": "提出了一种基于监督学习的自适应网格化方法，称为专家重建自适应网格生成（AMBER）, 它从粗略的网格开始，通过递归预测目标网格的大小场来生成自适应的网格，同时使用预处理的网格生成器生成中间网格。这种方法通过层次化的图神经网络实现，并在训练过程中通过自动将专家标签投影到AMBER生成的数据中从而进行数据增强，以此来泛化未知几何结构，并且在多种2D和3D数据集上实现了多项基线方法的性能超越", "conclusion": "AMBER能够在多种场景下（包括经典的物理问题、机械部件以及工业设计）实现自适应网格生成，特别是在未知几何结构的场景下，AMBER能够保持高效并优于图卷积网络、强化学习等现有方法，展示了其作为自适应网格化新方法的有效性和优越性"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00039", "html_url": "https://arxiv.org/abs/2506.00039", "title": "AbsoluteNet: 一种用于分类听觉处理大脑血流动力学反应的深度学习神经网络", "title_en": "AbsoluteNet: A Deep Learning Neural Network to Classify Cerebral Hemodynamic Responses of Auditory Processing", "authors": "Behtom Adeli,John Mclinden,Pankaj Pandey,Ming Shao,Yalda Shahriari", "background": "近年来，深度学习方法在解码功能近红外光谱成像（fNIRS）捕获的脑血流量应答方面取得了显著成果，特别是在脑机接口（BCI）应用中。fNIRSNET，MDNN，DeepConvNet和ShallowConvNet等模型已应用于此领域，但新的模型仍有改进空间。", "innovation": "提出了一种新型深度学习架构AbsoluteNet，该架构基于时空卷积和定制化的激活函数原则构建。实验结果表明，AbsoluteNet在二分类中的准确率、灵敏度和特异度分别达到了87.0%、84.8%和89.2%，超越了排名第二的fNIRSNET 3.8%的准确率。这证明了AbsoluteNet在解码听觉处理相关的大脑血流动力学应答方面的有效性，并强调了时空特征聚合和定制化激活函数的重要性，以更好地适应fNIRS动态变化。", "conclusion": "AbsoluteNet在分类fNIRS记录的听觉事件相关反应方面表现出色，比现有的模型更优，主要归功于其对时空特征的有效聚合和使用的定制化激活函数，这些改进有效地提高了模型的实际应用价值。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02210", "html_url": "https://arxiv.org/abs/2506.02210", "title": "神经网络中的互换性及其在动态剪枝中的应用", "title_en": "Exchangeability in Neural Network and its Application to Dynamic Pruning", "authors": "Pu (Luke)Yi,Tianlang Chen,Yifan Yang,Sara Achour", "background": "现代神经网络包含越来越多的参数，这导致了推理时的内存和计算成本大幅增加。研究者们探索了通过在部署前缩减模型规模以及实时剪枝推理计算来减少推理成本的方法。本文基于交换性理论，提出了一种通用的、动态的剪枝优化方法ExPrune，可以在预测输入的基础上实现多级部分计算，而不需要改变模型架构或训练算法。", "innovation": "ExPrune基于交换性理论，能够理论性地推广到不同问题域下的不同模型架构。通过识别模型中互换性参数和中间值，ExPrune能够对网络进行部分预计算，分析部分结果的统计特性，并且实时做剪枝决策。ExPrune与静态幅度剪枝方法兼容，即使在模型已经被剧烈静态剪枝后，ExPrune仍然可以提供额外的FLOPs减少。", "conclusion": "ExPrune在不同的模型（计算机视觉模型、图模型和语言模型）上进行了评估。无论是在没有精度损失的情况下还是最多仅1%的精度损失情况下，ExPrune都实现了显著的FLOPs减少。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09348", "html_url": "https://arxiv.org/abs/2506.09348", "title": "二元分类的不利代理风险边界", "title_en": "Adversarial Surrogate Risk Bounds for Binary Classification", "authors": "Natalie S. Frank", "background": "分类的核心关注点之一是机器学习模型对抗恶意攻击的脆弱性。对抗训练是一种训练鲁棒分类器的流行技术，它涉及最小化对抗替代风险。最近的工作已经描述了在二元分类设置下的哪种序列在最小化对抗替代风险的同时也最小化了对抗分类风险，这种性质被称为对抗一致性。但这些结果没有涉及到这种序列中对抗分类风险接近最优值的速度问题。本文提供了代理风险的界限，量化了这种收敛速度。", "innovation": "本文提供了量化对抗替代风险序列收敛至最优值速度的代理风险界限，填补了先前研究中的空白，为理解对抗训练的有效性提供了新的视角和工具。", "conclusion": "提出的代理风险界限能够量化对抗替换风险序列的收敛速率，这对于评估和优化对抗训练模型的实际性能至关重要。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11031", "html_url": "https://arxiv.org/abs/2506.11031", "title": "预填充答复增强零样本检测器对AI生成图像的识别", "title_en": "Prefilled responses enhance zero-shot detection of AI-generated images", "authors": "Zoher Kachwala,Danishjeet Singh,Danielle Yang,Filippo Menczer", "background": "随着AI模型生成越来越逼真的图像，人们对于潜在滥用的关注不断增加。传统的监督检测方法依赖于大规模的手工标注数据进行训练，并且很难适应新出现的独立领域图像生成器。为此，本研究探讨了预训练视觉语言模型（VLMs）在零样本检测AI生成图像上的应用。", "innovation": "研究提出了一种新颖的方法——PreFill-Guided Thinking (PGT)，通过预填充目标对齐的短语来提高VLMs的推理能力。实验结果表明，使用前期填充方法后，三种常用的开源VLMs的宏F1分数最高可提升24%。", "conclusion": "即使商用VLMs在这些基准测试中表现不佳，通过PGT方法的有效引导，依然能显著提升它们的检测能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09714", "html_url": "https://arxiv.org/abs/2506.09714", "title": "Auto-Compressing Networks", "title_en": "Auto-Compressing Networks", "authors": "Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos", "background": "现有研究表明，深层神经网络在跨领域应用中表现出显著的成功，但增加网络深度通常会引入计算冗余，而模型表示能力并未相应提高。在传统残差连接中，短残差连接使得网络在训练过程中进行局部更新，而长前馈连接则能替代这种短连接，通过直接从每一层到输出的连接实现信息压缩。", "innovation": "本文提出了自压缩网络（Auto-Compressing Networks, ACNs），这是一种替代传统短残差连接的新架构，其中每一层到输出的长前馈连接取代了传统残差连接。这种架构设计揭示了一种新的特性：自压缩性，即网络通过梯度下降和架构设计自己压缩信息的能力。ACNs在低数据设置下表现出优越的性能、增强了噪声鲁棒性、改善了迁移学习能力，并成功缓解了灾难性遗忘问题，因此，在相同参数量下能够获得更好的泛化表示。", "conclusion": "实验结果表明，在视觉变换器、MLP-mixers和BERT架构上，ACNs能减少高达18%的灾难性遗忘，并保持了跨架构的准确性，同时实现了30-80%的架构压缩。这证明了ACNs作为一种实用的方法，能够根据任务复杂性自动适应计算足迹，同时学习适合噪声实时任务和持续学习场景的稳健表示。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21404", "html_url": "https://arxiv.org/abs/2505.21404", "title": "Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks", "title_en": "Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks", "authors": "Anas Jnini,Flavio Vella", "background": "自然梯度方法显著加速了物理信息神经网络（PINNs）的训练，但其高斯-牛顿更新必须在参数空间中解决，导致了计算复杂度为$O(n^3)$的昂贵计算量，其中$n$是神经网络的可训练权重数量。这限制了大模型的训练速度和效率。", "innovation": "提出了一种新的梯度下降方法——Dual Natural Gradient Descent (D-NGD)。D-NGD将高斯-牛顿步骤在残差空间中计算，残差空间的大小为$m = \text{单\\u8BD5\\u7C7B\\u7684\\u8DEF\\u5F84 }N_{\text{单\\u8BD5\\u7C7B}} d_{\text{单\\u8BD5\\u7C7B}}$。这种方法在计算复杂度较低的情况下能提供与正则化牛顿法相近的性能，并且能够适应较大的参数规模。具体而言，D-NGD 方法允许对具有多达1280万参数的PINNs 进行第二阶优化，同时远低于常用的Adam, SGD和近似牛顿方法的最终误差$L^2$值，并可在单个GPU上进行自然梯度训练。", "conclusion": "Dual Natural Gradient Descent (D-NGD)提供了对大规模PINNs进行训练的有效途径。这种方法通过将高斯-牛顿步骤计算转移到残差空间，大大减少了计算复杂度，同时保持了高精度和计算效率。基于D-NGD，批处理的PINNs优化可以扩展到更大的参数规模，实现较低的$L^2$误差，并且能够实现在单个GPU上的高效率训练。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23274", "html_url": "https://arxiv.org/abs/2506.23274", "title": "推理语言模型中的实时进度预测", "title_en": "Real-Time Progress Prediction in Reasoning Language Models", "authors": "Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard", "background": "最近，尤其是那些使用长潜台词 reasoning 的语言模型在复杂和自主的任务上显示出惊人的能力。然而，随着这些模型在越来越长的时间范围内操作，它们的内部进展对用户变得不透明，这使得期望管理以及实时监督变得复杂。", "innovation": "本研究通过将进度离散化并训练线性探针来分类推理状态，进而提出了一种两阶段微调方法，允许推理模型在推理期间生成进展估计（0→100%）。最佳微调模型在少于16,000个标记的序列上的平均误差为10%，提供了一种实时监控和解释模型推理的实际机制。", "conclusion": "我们的研究结果显示，即使是长潜台词推理模型也可以在实时进行进展估计，这对用户的期望管理和实时监督提供了重要的帮助。最佳模型在短序列上显示了较好的精确度，这为未来的模型改进提供了参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03318", "html_url": "https://arxiv.org/abs/2507.03318", "title": "使用组lasso正则化的图神经网络进行结构感知的化合物-蛋白质亲和力预测", "title_en": "Structure-Aware Compound-Protein Affinity Prediction via Graph Neural Network with Group Lasso Regularization", "authors": "Zanyu Shi,Yang Wang,Pathum Weerawarna,Jie Zhang,Timothy Richardson,Yijie Wang,Kun Huang", "background": "可解释的人工智能(XAI)方法近年来在药物发现中得到了广泛应用，用于学习分子表示和识别驱动属性预测的亚结构。然而，构建端到端的可解释模型来建模化合物-活性关系（SAR）中的结构活性关系并进行化合物属性预测面临许多挑战，包括特定蛋白质靶标下有限的化合物-蛋白质交互活性数据，以及细微的分子构型位点变化显著影响分子属性。本文重点利用具有相似骨架但在取代基位点上有显著活性差异的化合物对，结合图神经网络（GNN）来预测化合物-蛋白质亲和力（如半最大抑制浓度，IC50），以增强模型性能和可解释性。", "innovation": "本文提出了一种框架，使用带有组lasso和稀疏组lasso正则化的图神经网络，整合常见和不常见节点信息，以预测化合物-蛋白质亲和力并增强可解释性。通过训练GNN并使用结构感知损失函数，该研究强调了与活性差异相关的分子亚结构。实验结果证明，该方法能降低均方根误差（RMSE）、提高皮尔逊相关系数（PCC），并提升特征归因和原子级着色准确度。", "conclusion": "通过整合常见和不常见的节点信息并应用稀疏组lasso，本文增强了模型在药物发现管道中的可解释性，特别是在确定关键的分子亚结构方面发挥了重要作用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19366", "html_url": "https://arxiv.org/abs/2508.19366", "title": "扎根于现实：量化多模态LLMs中的幻觉的光谱图框架", "title_en": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in Multimodal LLMs", "authors": "Supratik Sarkar,Swagatam Das", "background": "在多模态设置中，LLMs中的幻觉减弱了其可靠性。本文提出了一个基于扩散动力学的信息几何框架来量化多模态LLMs中的幻觉：模型输出被谱嵌入在多模态图拉普拉斯矩阵上，并与真实流形的差距定义了一种语义失真度量。这项研究将幻觉重新定位为可测量和有界的，并为评估和缓解提供了理论基础。", "innovation": "本文创新性地提出了一个基于扩散动力学的信息几何框架，用于量化多模态LLMs中的幻觉。该框架通过谱嵌入和语义失真度量来量化幻觉，并利用RKHS本征模式获得模态意识的可解释指标，以追踪幻觉随提示和时间的变化。", "conclusion": "此研究将幻觉量化和限制，提供了一个遵循的原则基础，用于评估和缓解幻觉。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量和梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简单的模型合并技术已显示出强大的效果，它允许将多个微调模型合并为一个。尽管其在实践中的效果显著，但尚缺乏清晰的理论解释说明其为何以及在何种情况下有效。本文通过将任务向量与任务损失的梯度联系起来，为任务算术提供了严密的理论基础。研究表明，在标准梯度下降中，来自一个微调周期的任务向量等同于损失的负梯度，缩放因子为学习率。在多周期的实际设置中，本文证明了这种等同性在一定程度上成立，对全连接网络给出了二阶误差项的具体边界。", "innovation": "本文为任务算术提供了严谨的理论基础，建立了任务向量与任务损失梯度之间的联系。证明了来自一个微调周期的任务向量等同于损失的负梯度，缩放因子为学习率。对于多周期的实际设置，本文证明了在标准梯度下降中这种等同性的近似有效性，并对全连接网络给出了二阶误差项的具体边界。", "conclusion": "本文的实证分析在七个视觉基准上得到了验证，证明了在范数和方向上，第一周期梯度在微调轨迹中的主导性。一个主要的推论是，仅仅单周期微调的模型合并通常可以与完全收敛的模型合并获得相似的性能。这些发现将任务算术重新定位为一种近似多任务学习的形式，为其实效性提供了明确的理由，并强调了早期训练动态在模型合并中的关键作用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06635", "html_url": "https://arxiv.org/abs/2508.06635", "title": "使用有缺陷的合成数据进行有效推断", "title_en": "Valid Inference with Imperfect Synthetic Data", "authors": "Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder", "background": "近年来，大型语言模型在有限数据环境下发挥着越来越大的作用，特别是在计算社会科学和人类主题研究领域。尽管早期的研究侧重于利用模型预测的标签处理未标记数据，对生成全新合成样本（如模拟调查回应）的兴趣正在增加。然而，如何将合成数据与真实数据结合，并得出统计上有效结论仍然未解。本文从广义矩方法出发，提供了一种无参数解决方案和强大理论保证来解决这一问题。通过对合成数据和真实数据矩残差之间交互关系的研究发现，这种交互关系在某些情况下能显著提高目标参数估计效果。实验证明了该估计方法在不同计算社会科学任务中的有效性，并取得了明显收益。", "innovation": "本文提出了一种基于广义矩方法的新估计器，提供了一种无超参数解决方案，具有强大的理论保证，以解决合成数据与真实数据结合的有效推断问题。特别地，引入了合成数据和真实数据矩残差之间的交互系数概念，并发现这种交互关系能大幅改进目标参数的估计效果。通过在不同计算社会科学任务上的实证分析，验证了该估计方法的有效性和优点。", "conclusion": "本文的研究表明，通过合成数据和真实数据之间的交互系数，可以大大改善目标参数的估计精度。该方法的无参数解决方案以及强大的理论支持，为处理有限数据条件下统计推断问题提供了一种有效的新方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04128", "html_url": "https://arxiv.org/abs/2509.04128", "title": "谁为公平买单？重新思考社会负担下的行动干预", "title_en": "Who Pays for Fairness? Rethinking Recourse under Social Burden", "authors": "Ainhize Barrainkua,Giovanni De Toni,Jose Antonio Lozano,Novi Quadrianto", "background": "机器学习预测在影响我们生活的敏感决策应用中越来越普遍，这就要求确保分类器的公正性。随着新法规要求当分类器得出负面决策时，必须提供个人可以采取的具体行动来逆转这一结果，这一概念被称为算法回溯。然而，许多研究者对算法回溯过程中的公平性保障表示担忧。", "innovation": "本文提供了算法回溯中的不公平现象的全面理论分析，正式建立了回溯与分类中公平性保障之间的联系，并指出了标准等成本范式下的局限性。提出了基于社会负担的新公平框架，并引入了一种新算法（MISOB），在实际条件下广泛适用。实证结果表明，MISOB在所有群体中减少了社会负担，同时不损害分类器的整体准确性。", "conclusion": "MISOB算法在不牺牲总体分类器准确性的情况下，成功降低了所有群体的社会负担，以及提供了一种基于社会负担的新公平框架，这为算法回溯提供了新的思考角度。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03487", "html_url": "https://arxiv.org/abs/2509.03487", "title": "SafeProtein: 红队框架与蛋白质基础模型基准", "title_en": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models", "authors": "Jigang Fan,Zhenghong Zhou,Ruofan Jin,Le Cong,Mengdi Wang,Zaixi Zhang", "background": "蛋白质在几乎所有生物过程中都扮演着关键角色。深度学习的进步极大地加速了蛋白质基础模型的发展，使得在蛋白质理解与设计方面取得了重要进展。然而，这些模型缺乏系统性的红队测试（红队是指通过设计恶意输入来评估模型安全性的一种方法），这引起了对其潜在滥用的严重担忧，例如生成具有生物安全风险的蛋白质。因此，了解并评估这些模型的潜在危害性成为迫切需求。", "innovation": "SafeProtein 是首个系统性红队框架，结合了多模态提示工程和启发式束搜索，旨在系统设计并测试蛋白质基础模型。SafeProtein 还构建了 SafeProtein-Bench，包括手动构建的红队基准数据集及全面的评估协议。研究发现，SafeProtein 在最先进的蛋白质基础模型（ESM3）上实现了持续的越狱，成功率高达70%，揭露了当前蛋白质基础模型的潜在生物安全风险，并为开发坚固的安全保护技术提供了参考。", "conclusion": "SafeProtein 获取了在当前前沿模型中持续的越狱结果，揭示了生物安全风险，为开发稳健的安全保护技术提供了重要启示。相关代码将开源。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15112", "html_url": "https://arxiv.org/abs/2507.15112", "title": "通过选择性数据删除实现分布机器遗忘", "title_en": "Distributional Machine Unlearning via Selective Data Removal", "authors": "Youssef Allouah,Rachid Guerraoui,Sanmi Koyejo", "background": "机器学习系统越来越多地面临去除整个数据领域（例如有毒语言或偏见）而非单个用户数据的要求。这项任务提出了一个难题：完全去除不需要的数据领域在计算上是昂贵的，而随机部分去除在统计上是效率低下的。我们发现，领域的影响统计数据往往集中在少数数据样本中，这暗示出了一条介于无效的部分去除和不必要的完全去除之间的路径。我们将其形式化为分布遗忘：一个框架，用于选择一个小的子集，平衡遗忘不需要的分布同时保留所需的分布。使用Kullback-Leibler散度约束，我们针对指数族推导出确切的删除保留帕累托前沿，并证明在编辑后的数据上训练的模型实现了相应的对数损失界限。我们提出了一个基于距离的选择算法，并证明在低散度情况下它比随机删除更为样本效率高。我们在合成、文本和图像数据集（Jigsaw、CIFAR-10、短信垃圾邮件）中的实验表明，该方法在强烈的遗忘效果下通常比完全删除所需的删除量减少了15-82%。最终，通过展示一个小的遗忘集通常就足够，我们的框架为更可扩展和严格的次子群体遗忘奠定了基础。", "innovation": "提出了一种分布性机器遗忘框架，即通过选择少量数据样本来平衡遗忘不需要的数据分布同时保留所需的分布。采用Kullback-Leibler散度约束，并针对指数族推导出确切的删除-保留帕累托前沿，证明了在编辑后的数据上训练的模型实现了相应的对数损失界限。提出了一种基于距离的选择算法，并在低散度情况下证明其比随机删除更为样本效率高。该方法在多个数据集上显示，当需要强烈遗忘效果时，所需删除量通常比完全删除减少了15-82%。", "conclusion": "通过提供一个可靠的框架，本框架使得在保持所需数据分布的同时，能够有效地去除不需要的数据分布，为更高效的次子群体遗忘提供了可能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.07030", "html_url": "https://arxiv.org/abs/2509.07030", "title": "一种用于随机优化的简约贝叶斯框架", "title_en": "A Minimalist Bayesian Framework for Stochastic Optimization", "authors": "Kaizheng Wang", "background": "贝叶斯范式为在不确定性下进行序列决策提供了原则性的工具，但它对所有参数的依赖性概率模型可能阻碍复杂结构约束的整合。", "innovation": "提出了一个简约的贝叶斯框架，只对兴趣组件（如最优解的位置）设置先验分布，通过潜变量似然性消除无干扰参数，从而自然处理约束。该框架直接实例化为一种简约的汤普森采样（MINTS）算法，适用于结构化问题，如连续臂Lipschitz尖子生和动态定价，并以概率视角重构经典凸优化算法。", "conclusion": "进一步分析了MINTS算法在多臂尖子生中的应用，并建立了接近最优的遗憾保证。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06274", "html_url": "https://arxiv.org/abs/2509.06274", "title": "IPR：用户可控质量成本权衡的智能提示路由", "title_en": "IPR: Intelligent Prompt Routing with User-Controlled Quality-Cost Trade-offs", "authors": "Aosong Feng,Balasubramaniam Srinivasan,Yun Zhou,Zhichao Xu,Kang Zhou,Sheng Guan,Yueyan Chen,Xian Wu,Ninad Kulkarni,Yi Zhang,Zhengyuan Shen,Dmitriy Bespalov,Soumya Smruti Mishra,Yifei Teng,Darren Yow-Bang Wang,Haibo Ding,Lin Lee Cheong", "background": "大规模商业系统中，将传入查询路由到最经济的大型语言模型（LLM）以维持响应质量，优化性能成本权衡带来了根本性的挑战。", "innovation": "IPR引入了三个关键创新：1. 模块化架构，包含轻量级的质量估计器，基于1.5M带有校正后质量评分的提示训练，实现跨模型系列的精细质量预测。2. 用户控制的路由机制，带有参数τ ∈ [0,1]的容忍度，提供对质量成本权衡的显式控制。3. 扩展设计，使用冻结编码器和模型特定适配器，减少新模型集成时间从几天到几小时。", "conclusion": "部署在主要的云平台上的IPR实现了43.9%的成本减少，同时保持了与Claude家族最强大模型的质量平价，请求处理延迟低于150毫秒。该部署系统和额外的产品细节可以在this https URL处公开获取。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15927", "html_url": "https://arxiv.org/abs/2509.15927", "title": "使用离线奖励评估和策略搜索提升生成性自动出价", "title_en": "Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search", "authors": "Zhiyu Mou,Yiqin Lv,Miao Xu,Qi Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng", "background": "自动竞标作为广告商提升广告效果的关键工具，近年来，利用AI生成出价（AIGB）的方法因其优越性能在离线数据上学习条件生成规划器而发展起来，相较于传统的基于离线强化学习（offline RL）的自动出价方法，取得了更好的效果。然而，现有的AIGB方法仍受限于无法探索超出静态离线数据集的问题。", "innovation": "本文提出了一种新颖的方法，AIGB-Pearl（基于RL的规划评估器），它整合了生成性规划和策略优化。AIGB-Pearl的核心在于构建一个轨迹评估器来评分生成质量，并设计了一种保证安全和高效探索的严格KL-Lipschitz约束评分最大化方案。此外，还提出了一种结合同步耦合技术的实用算法以满足提出的方案所需模型的正则性要求。", "conclusion": "在模拟和真实广告系统中的广泛实验表明了本文方法的先进性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.10186", "html_url": "https://arxiv.org/abs/2509.10186", "title": "P3D: 高分辨率3D物理模拟的可扩展神经近似模型及其全局上下文", "title_en": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "authors": "Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey", "background": "本文提出了一个可扩展的框架，用于学习高性能的确定性和概率性神经近似模型，用于高分辨率3D物理模拟。现有的模拟方法通常需要大量的计算资源，而基于神经网络的近似模型可以显著提高模拟的效率和精度。", "innovation": "引入了一种结合了CNN和Transformer的新型骨干网络架构，特别适用于3D物理模拟。与现有模型相比，该架构在速度和准确性方面表现优异。该网络可以在较小的仿真区域上进行预训练，然后融合以获取全局解决方案，同时还可以通过快速且可扩展的序列到序列模型来引导长期依赖关系的建模。", "conclusion": "本文的骨干网络架构在14种不同类型的3D PDE动力学学习方面优于多种基线方法。研究展示了如何将模型扩展到高分辨率的各向同性湍流，具有高达512^3的空间分辨率，并通过训练扩散模型产生高湍流3D通道流的高分辨率概率样本，从而准确地捕捉到流动统计特性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20936", "html_url": "https://arxiv.org/abs/2509.20936", "title": "GenFacts-生成的多变量时间序列的反事实解释", "title_en": "GenFacts-Generative Counterfactual Explanations for Multi-Variate Time Series", "authors": "Sarah Seifi,Anass Ibrahimi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille", "background": "反事实解释旨在通过展示输入修改如何改变模型预测来提高模型透明度。在多变量时间序列领域，现有方法往往生成无效、不具说服力或直观可解释的反事实解释。在雷达手势识别和手写字母路径这两个工业应用案例和直观基准数据集上，GenFacts 模型在可信度指标上优于基线方法18.7%，并在用户体验研究中取得最高的可解释性评分。", "innovation": "GenFacts 是一种创新性的生成框架，用于为时间序列分类器生成置信和可操作的反事实解释。该框架引入了一种结构化的方法来构建潜在空间模型和目标反事实合成。", "conclusion": "实验结果表明，现实性和用户中心的可解释性，而非仅稀疏性，对于时间序列应用中的可操作反事实解释至关重要。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19752", "html_url": "https://arxiv.org/abs/2506.19752", "title": "关于适应性正则化必要性的研究：在$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldymbol{\boldsymbol{\boldsymbol{\boldsymbol{p}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\text{-balls中的任意时间在线学习的最优性}", "title_en": "On the necessity of adaptive regularisation:Optimal anytime online learning on $\\boldsymbol{\\ell_p}$-balls", "authors": "Emmeran Johnson,David Martínez-Rubio,Ciara Pike-Burke,Patrick Rebeschini", "background": "本文研究了在$\textbf{R}^d$中$\textbf{ℓ}_p$-球上$p>2$的情况下的在线凸优化。在高维设置（$d > T$）和低维设置（$d \textless{}= T$）中存在维度与时间跨度之间的关系。在这两种设置下，最优遗憾损失的表现有所不同。", "innovation": "我们展示了适应维度的可变正则化FTRL(Follow-the-Regularised-Leader)在两种维度设置下都是任意时间最优的。此外，我们还探讨了是否可以使用固定非适应性正则化仍然在两种情况下都是任意时间最优的问题，证明了对于可分的正则化器，适应性正则化是必要的，任何固定的正则化器在两种情况之一上都是次优的。", "conclusion": "最终，我们为线性多臂赌局问题提供了下界，表明在足够高的维度下，对所有$\textbf{ℓ}_p$-球（$p \textge 1$）不存在次线性遗憾损失的边界。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20293", "html_url": "https://arxiv.org/abs/2509.20293", "title": "当判断成为噪声：LLM评判基准设计缺陷如何静默削弱有效性", "title_en": "When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity", "authors": "Benjamin Feuer,Chiung-Yi Tseng,Astitwa Sarthak Lathe,Oussama Elachqar,John P Dickerson", "background": "越来越多地使用LLM评判标准来评估复杂模型的行为，但这些标准的设计引入了传统基于真实数据的基准所没有的失败模式。如果没有明确的目标和可验证的构造，这可能会导致高置信度的排名实际上主要是噪声。", "innovation": "引入了两种机制来诊断这些问题：1) 检查图示一致性，以量化法官整体判决中有多少是由明确的评估标准解释的，揭示当法官偏离其自己的评分标准时未解释的变异；2) 心理测量效度，聚集内部一致性和区分效度信号，量化任何基准测试运行中的不可约减不确定性。同时表明，Arena-Hard Auto使用的类似ELO的聚合方式会导致真正排名不确定性被掩盖。", "conclusion": "研究结果强调了设计缺陷对有效性的影响，并提出了更明确、更可靠的LLM评判基准的可操作原则。相关代码和数据集可以在该链接下载：this https URL"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02298", "html_url": "https://arxiv.org/abs/2508.02298", "title": "CAPO: 通过生成式信用分配增强语言模型推理", "title_en": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit Assignment", "authors": "Guofu Xie,Yunsheng Shi,Hongtao Tian,Ting Yao,Xiao Zhang", "background": "当前的奖励可验证学习（RLVR）方法通常为每个令牌赋相同的奖励，这种粗糙的反馈机制阻碍了精确的信用分配，使得模型难以识别导致成功或失败的具体推理步骤，而往往会导致次优策略。尽管方法如PPO通过价值估计提供信用分配，但由于采样有限，这些信号往往不准确且不可验证。相比之下，使用过程奖励模型（PRM）的方法能够提供步骤级别的奖励，但这些方法存在一些关键限制：包括需要高质量的过程监督标签、因概率建模导致的反馈不可靠以及在线强化学习（RL）应用中的耗时问题。为了解决这些问题，引入了一种简单而有效的方法——信用分配策略优化（CAPO），直接利用一种现成的通用语言模型作为生成性过程奖励模型（LLM-as-GenPRM）来生成基于步骤本身的正确性的一次性评价，从而提供确定性的令牌级别信用，以优化原本被赋予相同规则奖励的令牌。为了进一步提升准确性和鲁棒性，采用了随生成评价数量增加而扩展的投票机制。", "innovation": "CAPO通过利用现成的通用语言模型作为生成性过程奖励模型，直接生成基于步骤正确性的评价，提供确定性的令牌级别信用分配，提高了模型推理的准确性和鲁棒性。投票机制使得方法更加稳健。该方法在多个语言模型如Llama和Qwen上进行的实验表明，CAPO在四个具有挑战性的数学基准和三个跨域基准上均优于基于监督学习和基于强化学习的微调方法，帮助模型学习正确的推理路径，从而得出正确的答案。", "conclusion": "CAPO方法在多个语言模型上测试显示，相较于传统的监督学习和基于强化学习的微调方法，CAPO能够有效优化大型语言模型的推理能力，提升准确性与鲁棒性，这种优化特别适用于需要正确推理步骤的复杂任务。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21154", "html_url": "https://arxiv.org/abs/2509.21154", "title": "GRPO是秘密的过程奖励模型", "title_en": "GRPO is Secretly a Process Reward Model", "authors": "Michael Sullivan", "background": "该论文基于GRPO（团队奖励过程优化）算法，探讨其在特定条件下的理论和实证表现。研究发现，GRPO算法在处理令牌序列完成时可能会产生非平凡的过程奖励模型（PRM），该模型具有特定的假设条件。论文进一步证实了这些假设条件在现实世界条件下是成立的，从而证明GRPO能够诱导出非平凡的PRM。", "innovation": "创新之处在于揭示了GRPO算法的本质可能实际上是过程奖励模型，并且提出了一种改进算法$\\lambda$-GRPO，通过简单修改导致步骤分布不均匀的问题，从而提高模型在验证精度和下游推理任务中的性能，并且达到最佳性能的速度更快。", "conclusion": "研究结果表明，与显式定义的PRM相比，利用GRPO算法内置的隐藏PRM结构可能在提升模型性能方面更有效，并且几乎不会影响训练时间和成本。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25678", "html_url": "https://arxiv.org/abs/2509.25678", "title": "基于时间多模态交互引导混合专家架构", "title_en": "Guiding Mixture-of-Experts with Temporal Multimodal Interactions", "authors": "Xing Han,Hsing-Huan Chung,Joydeep Ghosh,Paul Pu Liang,Suchi Saria", "background": "混合专家（MoE）架构已成为大规模多模态模型的关键组成部分。然而，它们的路由机制通常忽视了模态之间具有信息性且会变化的互动动态。这种局限性阻碍了专家的专业化，因为模型无法明确利用固有的模态关系进行有效的推理。现有模型很难捕捉并充分利用模态之间的动态关系，从而影响模型的整体性能和解释性.", "innovation": "本文提出了一种新的框架，该框架通过量化时间多模态交互来引导MoE路由。这种方法允许一种多模态互动感知路由器根据各模态之间的交互性质来分配令牌，从而鼓励专家获得可泛化的交互处理技能，而不是单纯的仅学习特定任务的特征。此外，该框架建立在对时间多模态交互动态的新公式描述上，以指导专家路由。研究表明，这些时间多模态交互可以在不同的应用场景中揭示有意义的模式，并能提升MoE架构的设计和性能.", "conclusion": "在具有挑战性的多模态基准测试中的全面实验验证了本文的框架，证明了其不仅能提高性能，还能增强模型的可解释性。这项工作为理解和优化多模态模型的动态交互开辟了新的研究方向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24076", "html_url": "https://arxiv.org/abs/2509.24076", "title": "用于多输出混合神经网络的一类核化矩阵代价", "title_en": "A Family of Kernelized Matrix Costs for Multiple-Output Mixture Neural Networks", "authors": "Bo Hu,José C. Príncipe", "background": "自监督和对比特征学习中，基于成对距离的成本至关重要。混合密度网络（MDNs）通过使用神经网络生成多个中心来定义高斯混合，广泛用于生成模型和密度逼近。现有方法主要关注于单一中心的生成，未能充分利用多样化的中心以增强模型的学习能力。因此，本文旨在提出一种新的方法，通过结合MDNs与对比成本，利用多种类型的核化矩阵成本在希尔伯特空间中进行数据密度近似，从而学习定义混合密度所需的多个中心。", "innovation": "本文创新地提出了一类核化矩阵成本，包括标量成本、向量-矩阵成本、矩阵-矩阵成本（Schur补矩阵的迹）和SVD成本（核范数），用于多输出混合神经网络。这种方法通过在希尔伯特空间中引入多种核化矩阵成本，旨在更有效地学习训练数据的密度，从而改进自监督和对比特征学习的效果，并增强模型的表示能力。", "conclusion": "本文通过结合MDNs与特定类型的核化矩阵成本，提出了一种新的数据密度近似方法，改进了自监督和对比特征学习。实验结果表明，该方法能够更好地学习复杂数据集的分布，提高了模型的泛化能力和特征表示质量。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00387", "html_url": "https://arxiv.org/abs/2510.00387", "title": "基于贝叶斯分布模型的工作记忆功能", "title_en": "Bayesian Distributional Models of Executive Functioning", "authors": "Robert Kasumba,Zeyu Lu,Dom CP Marticorena,Mingyang Zhong,Paul Beggs,Anja Pahor,Geetha Ramani,Imani Goffney,Susanne M Jaeggi,Aaron R Seitz,Jacob R Gardner,Dennis L Barbour", "background": "该研究使用基于已知真实参数的受控模拟来评估分布性潜变量模型（DLVM）和贝叶斯分布性主动学习（DALE）与传统独立最大似然估计（IMLE）的性能比较。DLVM将来自多个执行功能任务和个人的观察数据整合起来，即使在数据稀疏或不完整的情况下也能估计参数。研究表明，DLVM在少量数据下始终优于IMLE，并且收敛速度更快，能够更准确地估计真实分布。研究还发现DALE在引导采样以最大化信息增益方面表现出色，尤其是在前80次试验中，超越了随机采样和固定测试电池。", "innovation": "研究结合了DLVM的跨任务推理能力和DALE的最优自适应采样方法，为更有效的认知评估提供了理论依据。通过比较DLVM与DALE与传统IMLE的方法，研究发现DLVM在小数据集下表现出更优的性能和更快的收敛速度。另一方面，DALE在信息增益方面的自适应采样表现出优越性，特别是在最初的80次试验中。", "conclusion": "研究证明了结合DLVM的跨任务推理能力和DALE的最优自适应采样方法在提高认知评估效率方面的优势，并为更高效的认知功能评估提供了理论基础。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24031", "html_url": "https://arxiv.org/abs/2509.24031", "title": "GPS-MTM: 使用自我监督学习捕捉GPS轨迹中的常态模式", "title_en": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning", "authors": "Umang Garg,Bowen Zhang,Anantajit Subrahmanya,Chandrakanth Gudavalli,BS Manjunath", "background": "基础模型已在文本、视觉和视频理解领域取得了显著进展，并即将在轨迹建模方面实现类似的突破。现有的轨迹建模方法通常将轨迹扁平化为坐标流，而GPSMasked 轨迹变换器 (GPS-MTM) 则将流动性分解为两种互补的模态：状态（兴趣点类别）和动作（实体过渡），通过双向变换器和自我监督的掩码建模目标，实现跨模态缺失部分的重建，从而学习到丰富的语义关联，而不依赖手动标签。", "innovation": "GPS-MTM 通过将流动性分解为状态和动作两种互补模态，利用双向变换器和自我监督的掩码建模目标，实现跨模态缺失部分的重建，无需手动标签即可学习丰富的语义关联，特别适合动态任务，在逆向和正向动力学方面表现出明显的优势，从而确立了 GPS-MTM 作为轨迹分析中的稳健基础模型的地位，使流动性成为大规模表示学习中的重要模态之一。", "conclusion": "在基准数据集（包括 Numosim-LA、Urban Anomalies 和 Geolife）上，GPS-MTM 一致地在轨迹填充和下一个停靠点预测等下游任务上表现出色，尤其是在动态任务中，需要上下文推理，从而确立 GPS-MTM 作为轨迹分析稳健基础模型的地位，使其流动性成为大规模表示学习中的一个重要模态，代码已发布供进一步参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25775", "html_url": "https://arxiv.org/abs/2509.25775", "title": "自主意识导向的聚类：当局部决策超越全局规定", "title_en": "Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions", "authors": "Amber Srivastava,Salar Basiri,Srinivasa Salapaka", "background": "聚类问题在许多问题形式中普遍存在，但现有方法通常假设被聚类的实体是被动的，并严格遵循分配的群体。然而，实体在实际中往往表现出局部自主性，可能会越过预设的关联性，而这些关联性无法完全由特征表示所捕捉。这种自主性可以显著改变聚类结果，影响簇的组成、几何结构和数量，对后续的推断和决策产生重大影响。", "innovation": "本文引入自主意识导向的聚类，这是一种基于强化学习（RL）的框架，不需要预先了解自主性的形式，即可学习和考虑局部自主性的影响。该方法将RL与决定性退火（DA）程序相结合，其中在退火的早期阶段，DA自然地促进探索，而后期则转向利用。此外，退火过程中的相变现象被利用以设计高效的退火计划。为了进一步增强适应性，提出了自适应距离估计网络（ADEN），这是一种基于变压器的注意力模型，可以在RL循环中学习实体与簇代表之间的依赖性，处理不同大小的输入和输出，并促进不同问题实例之间的知识转移。", "conclusion": "实验结果表明，本方法与底层数据动态高度一致：即便没有明确的自主性模型，它也能接近真实解（误差约为3-4%），而忽略自主性会导致更大的误差（约为35-40%）。该框架的代码和数据可在本链接 这里获得。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21181", "html_url": "https://arxiv.org/abs/2509.21181", "title": "闭形式的 $l_r$ 范数随数据变化对于过参数化线性回归和对角线性网络在 $l_p$ 偏差下的标度规律", "title_en": "Closed-form $\\ell_r$ norm scaling with data for overparameterized linear regression and diagonal linear networks under $\\ell_p$ bias", "authors": "Shuofeng Zhang,Ard Louis", "background": "本文探讨了过参数化线性回归中，当采用等向性高斯设计和最小-$\boldsymbol{\frac{1}{p}}$ 插值器（$p \text{∈} (1, 2]$）时，参数范数族 $ \boldsymbol{\rbrace \rVert \boldhat{w_p} \rVert_r \boldsymbol{\rbrace_{r \text{∈} [1, p]}} $ 随样本数量变化的标度规律。背景在于对这一基本但未解决的问题，通过简单的对偶线分析，揭示了信号尖峰与 $X^\top Y$ 中的零坐标群之间的竞争关系，从而提供了关于 (i) 数据依赖的转变点 $n_\text{star}$（即“转折点”），以及 (ii) 一个普遍的阈值 $r_\text{star}=2(p-1)$ 这两个因素的解析预测，该阈值区分了那些饱和和平坦的参数范数与继续增长的参数范数。研究还发现，对角线性网络 (DLNs) 在梯度下降训练下，通过对初始化尺度 $\boldsymbol{\text{α}}$ 进行调整，能够继承相似的转折点/阈值规律，从而在显式偏差和隐式偏差之间构建了预测桥梁。因此，许多泛化代理依赖于 $ \boldsymbol{\rVert \boldhat{w_p} \rVert_r } $ 的结果表明，这些代理的预测能力高度依赖于使用的 $ l_r $ 范数。这一背景说明了研究的重要性和实用性。", "innovation": "通过简单的对偶线分析，本文提供了一种通用且参与性的解法来标度过参数化线性回归中的所有 $l_r$ 范数，并在单一框架下解释了哪些范数会饱和，哪些会随着数据规模的增长而增加。对角化线性网络的研究发现，DLNs 在梯度下降训练下能继承相同类型的转折点/阈值规律，为显式和隐式偏差之间的关系提供了实证桥梁。这些发现都表明了使用的 $l_r$ 范数对许多泛化代理的预测能力的影响。", "conclusion": "本研究通过对偶线分析的方法，提供了一种统一的 $l_r$ 范数在过参数化线性回归中的标度模型，明确了数据量对不同范数变化的影响，并将该模型推广到了对角线性网络。最终，通过对角线性网络的研究发现，DLNs 可以继承相似的标度规律，从而为显式和隐式偏差之间的关系提出了可预测的机制。这表明，研究中使用的范数选择在很大程度上影响了泛化的能力和效果。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03470", "html_url": "https://arxiv.org/abs/2510.03470", "title": "论残差网络的深度", "title_en": "On residual network depth", "authors": "Benoit Dherin,Michael Munn", "background": "诸如ResNet和变换器的深层残差架构使模型能够达到前所未有的深度，然而深度为何如此有效的问题仍缺乏正式的理论理解。一种流行的直觉是这些残差网络实际上起到了许多较浅模型的组合效果，类似于一个隐式的多元组。这项研究旨在通过明确的分析公式验证这一观点，并证明增加网络深度等同于扩大这个隐式多元组的规模。此外，研究还揭示了一个分层的多元组合结构，运算路径的组合增长导致了输出信号的爆炸式增加，解释了在训练深层次模型时历史需要引入正则化层的原因。", "innovation": "研究发现了一个残差扩展定理，表明可以通过在每个残差模块上进行缩放来缓解这些架构中固有的组合爆炸问题，提供了一种基于网络内在功能结构的解释，而非仅仅是通过优化器分析或批规范化类比法。此外，这种缩放还作为容量控制，隐式地调节了模型的复杂性。", "conclusion": "研究提供了一个基于基本原理解释深度神经网络中正则化层历史必要性的新视角，并为无正则化技术如SkipInit和Fixup提供了新的见解。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03268", "html_url": "https://arxiv.org/abs/2510.03268", "title": "在多模态对比学习中破解模态差距：从收敛表示到成对对齐", "title_en": "Decipher the Modality Gap in Multimodal Contrastive Learning: From Convergent Representations to Pairwise Alignment", "authors": "Lingjie Yi,Raphael Douady,Chao Chen", "background": "多模态对比学习（MCL）旨在将不同模态的数据嵌入到一个共享嵌入空间中。然而，实证证据表明，不同模态的表示占据嵌入空间完全分离的区域，这被称为模态差距。此外，关于模态差距大小如何影响下游性能的实验发现也不一致。这些观察提出了两个关键问题：（1）模态差距的原因是什么？（2）它如何影响下游任务？", "innovation": "本文引入了第一个分析MCL的收敛最优表示及其在训练优化时模态对齐的理论框架。具体而言，我们证明，在无约束或锥约束下，模态差距会收敛为零。在子空间约束下（即，两个模态的表示由于维度坍缩而分别落入两个不同的超平面中），模态差距收敛为两个超平面之间的最小角度。这一结果将维度坍缩识别为模态差距的根本原因。此外，我们的定理还表明，在子空间约束下，配对样本无法完全对齐。模态差距通过影响样本对之间的对齐度，从而影响下游性能。我们证明，在这种情况下，可以通过超平面旋转和共享空间投影两种方式实现两个模态之间的完美对齐，尽管在子空间约束下配对样本无法完全对齐。", "conclusion": "本文提出了MCL收敛表示和模态对齐的理论框架，解释了模态差距的本质，揭示了维度坍缩是模态差距的根本原因，并证明了在特定约束下配对样本可以通过超平面旋转和共享空间投影进行完美对齐，这为解决多模态对比学习中的模态差距问题提供了新的思路。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03262", "html_url": "https://arxiv.org/abs/2510.03262", "title": "重思适配器合并中的LoRA正交性：正交蒙特卡洛丢弃的见解", "title_en": "Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout", "authors": "Andi Zhang,Xuan Ding,Haofan Wang,Steven McDonagh,Samuel Kaski", "background": "LoRA是一种流行的大型模型微调方法，通常训练一个模块来表示特定的概念，如一个对象或一种风格。当结合多个LoRA模块时，它们的输出（语义向量）可能会彼此干扰。以往的研究发现强制这种正交性不能实现语义解耦，这引起了对适配器合并中LoRA正交性角色的重新审视。", "innovation": "提出了正交蒙特卡洛丢弃机制，该机制在不增加额外时间复杂度的情况下强制语义向量组合时严格正交。这种方法保证合并后的LoRA模块保持正交性，避免直接干扰。然而，实证分析表明这种正交性并不能实现先前工作中强调的语义解耦。", "conclusion": "现有研究指出，仅保证LoRA模块间的正交性可能不足以实现真正的语义组合性，因此需要重新评估其在适配器合并中的角色。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00602", "html_url": "https://arxiv.org/abs/2510.00602", "title": "多智能体阶段保守线性multi-armed赌博机", "title_en": "Multi-Agent Stage-wise Conservative Linear Bandits", "authors": "Amirhoseein Afsharrad,Ahmadreza Moradipari,Sanjay Lall", "background": "在诸如推荐系统等许多实际应用场景中，多个学习代理需要在探索和利用之间找到平衡，同时要保证安全，以避免灾难性的失败。因此，研究在一个具有保守约束条件的多智能体网络环境中，多智能体如何在网络层面上最大化累积奖励成为了一个关键问题。每个智能体观察到的是局部奖励，但是网络优化的是全局参数（局部参数的平均值）。智能体只能与其邻近智能体通信，且每次通信都会产生额外的遗憾损失。针对该问题，本文考虑了网络中的每个智能体如何在这种条件下作出决策来实现全局优化目标。", "innovation": "本文提出了一种名为MA-SCLUCB（多智能体阶段保守线性UCB）的分段学习算法，该算法交替执行动作选择和共识建立阶段。证明了MA-SCLUCB在这种设定下具有较高的概率能够达到$\tilde{O}\big(\frac{d}{\boldsymbol{\text{\tiny{\text{sqrt}}}}N}\boldsymbol{\text{\tiny{\text{sqrt}}}}T \times \frac{\text{log}(NT)}{\boldsymbol{\text{\tiny{\text{sqrt}}}}\text{log}(1/|\boldsymbol{\text{\tiny{\text{lambda}}}_2|)}}\big)$的遗憾损失，其中$d$是维度，$T$是时间范围，$|\boldsymbol{\text{\tiny{\text{lambda}}}_2}|$是网络的第二大特征值的绝对值。此外，本文分析表明，尽管存在局部通信，合作可以带来$\frac{1}{\boldsymbol{\text{\tiny{\text{sqrt}}}}N}$的改善，通信开销仅在良连接网络中以对数级增长，并且阶段保守性仅增加低阶的遗憾损失。", "conclusion": "研究证明，即使在网络连接相对试探性的环境下，也可以通过多智能体的合作学习实现近乎最优的表现，同时保证安全约束条件。这是因为在解决多智能体网络上下列保守线性bandit问题时，合理连接的网络能够实现近似最优性能，而通信开销和保守机制对性能的影响可以忽略不计。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04072", "html_url": "https://arxiv.org/abs/2510.04072", "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning", "title_en": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning", "authors": "Ziyan Wang,Zheng Wang,Jie Fu,Xingwei Qu,Qi Cheng,Shengpu Tang,Minjia Zhang,Xiaoming Huo", "background": " reinforcement learning (RL) plays a crucial role in enhancing the reasoning capabilities of large language models (LLMs), but on-policy algorithms like Group Relative Policy Optimization (GRPO) can suffer from instability and inefficient exploration during early training due to noisy gradients from low-quality rollouts.", "innovation": "提出了Slow-Fast Policy Optimization (SFPO)，一种通过将每个步骤分解为三个阶段（短暂的内部快速轨迹、重定位机制以及最终慢速修正）来解决上述问题的简单且高效的方法。这种方法重新定位再更新的设计保持了目标和部署过程不变，使SFPO能够与现有的策略梯度管道无缝集成。", "conclusion": "广泛实验表明，SFPO在稳定性、减少采样次数和加速收敛方面优于GRPO。具体来说，在数学推理基准测试中，SFPO的平均表现高出2.80分，采样次数减少4.93倍，实际时间减少4.19倍以达到与GRPO相同的最佳性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04205", "html_url": "https://arxiv.org/abs/2510.04205", "title": "PolyKAN: 基于多面体分析的可证明并且接近最优的KAN压缩框架", "title_en": "PolyKAN: A Polyhedral Analysis Framework for Provable and Approximately Optimal KAN Compression", "authors": "Di Zhang", "background": "Kolmogorov-Arnold网络（KANs）作为一种具有增强解释性和坚实数学基础的潜在替代多层感知机（MLPs）的方法已经浮现出来。然而，其参数效率仍然是实际部署中的一个重大挑战。KANs 的压缩问题迄今缺乏正式保真的理论框架。", "innovation": "本文提出了PolyKAN，一种新的理论框架，用于KAN的压缩，提供了模型大小减少和逼近误差的正式保证。通过利用KANs固有的分段多项式结构，将压缩问题公式化为多面体区域合并任务。本文还建立了KANs的多面体特征表征，开发了ε等价压缩的完整理论，并设计了一种动态规划算法，以在指定误差界限内实现近似最优压缩。", "conclusion": "理论分析表明，PolyKAN实现了可证明的接近最优压缩，同时严格控制了误差，对于单变量样条函数具有全局最优保障。本框架为KAN压缩提供了首个具有数学保证的正式基础，为可解释神经架构的高效部署开辟了新的方向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03569", "html_url": "https://arxiv.org/abs/2510.03569", "title": "纵向流匹配用于轨迹建模", "title_en": "Longitudinal Flow Matching for Trajectory Modeling", "authors": "Mohammad Mohaiminul Islam,Thijs P. Kuipers,Sharvaree Vadgama,Coen de Vente,Afsana Khan,Clara I. Sánchez,Erik J. Bekkers", "background": "生成模型在处理稀疏采样和高维轨迹时通常存在困难，通常将动态学习简化为基于成对转移的学习。以往的研究方法主要关注于对递变动态进行估计，而忽略了中间时间点的信息，同时处理稀疏和不规则采样轨迹的能力有限", "innovation": "本文提出了一种新的框架——基于插值多重边际流匹配（IMMFM），该框架能够同时一致地学习多个观察时间点下的连续随机动力学。IMMFM 使用分段二次插值路径作为平滑目标，对流失和基于数据驱动的扩散系数进行联合优化，并提供了一个稳定性学习的理论条件。这种方法能捕捉内在的随机性，处理不规则和稀疏采样的轨迹，生成个体特定的轨迹", "conclusion": "实验结果表明，IMMFM 在合成基准和真实的纵向神经影像数据集上的预测精度和下游任务表现都优于现有的方法"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05753", "html_url": "https://arxiv.org/abs/2510.05753", "title": "深度迁移学习中基于经验的成员推断攻击比较", "title_en": "Empirical Comparison of Membership Inference Attacks in Deep Transfer Learning", "authors": "Yuxuan Bai,Gauri Pradhan,Marlon Tobaben,Antti Honkela", "background": "随着大规模基础模型的出现，训练范式正逐渐从从零开始训练转变为迁移学习。这使得使用小规模领域特定数据集进行高效益训练成为可能，这些数据集常用于敏感应用。成员推断攻击(MIAs)提供了一种经验估计机器学习模型隐私泄露的方法。然而，针对经过迁移微调的模型的MIAs评估主要依赖于小部分可能的攻击方式。本研究旨在通过比较不同MIAs在迁移学习环境中的性能，帮助实践者识别最有效的攻击方法，以评估隐私风险。研究发现，基于得分的MIAs效果随训练数据量的增加而降低。同时，没有一种MIA能够全面涵盖迁移学习训练模型中的所有隐私风险。尽管Likelihood Ratio Attack (LiRA)在大多数实验条件下表现出卓越的性能，但在高数据量情况下，Inverse Hessian Attack (IHA)对基于PatchCamelyon数据集微调的模型更具效果。", "innovation": "本研究通过比较不同类型的成员推断攻击在迁移学习环境中的性能，填补了现有研究中针对迁移微调模型的MIAs评估方法的不足。研究发现，攻击效果随训练数据量增加而下降，并且没有一种方法能够全面捕捉转移学习中的隐私风险，这对于评估和管理隐私风险具有重要意义。", "conclusion": "研究结果表明，基于得分的成员推断攻击随着训练数据的增加效果下降。没有一种MIA能够全面覆盖转移学习训练模型中的隐私风险。在大多数实验条件下，Likelihood Ratio Attack (LiRA)表现最佳，但在高数据量情况下，Inverse Hessian Attack (IHA)效果更好。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06050", "html_url": "https://arxiv.org/abs/2510.06050", "title": "基于编辑的流动匹配用于时间点过程", "title_en": "Edit-Based Flow Matching for Temporal Point Processes", "authors": "David Lüdke,Marten Lienen,Marcel Kollovieh,Stephan Günnemann", "background": "时间点过程（TPPs）是用于建模连续时间中的事件序列的基本工具，但大多数现有方法依赖于自回归参数化，这限制了它们的顺序采样。近期的非自回归、弥散风格模型通过在离散马尔可夫链中插入和删除事件来同时在噪声和数据之间进行插值，缓解了这些问题。", "innovation": "本文扩展了这一视角，引入了一种编辑流过程（Edit Flow process）用于TPPs，该过程通过插入、删除和替换编辑操作将噪声转化为数据。通过在连续时间马尔可夫链框架中学习瞬时编辑速率，获得了灵活且高效的模型，有效减少了生成过程中的必要编辑操作数量。实验证明了我们的无条件训练模型在不同生成任务中的生成灵活性，包括条件生成任务和基准TPPs的无条件生成任务。", "conclusion": "这种方法在提高模型效率的同时，增强了生成灵活性，适用于广泛的条件和无条件生成任务。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05024", "html_url": "https://arxiv.org/abs/2510.05024", "title": "Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment", "title_en": "Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment", "authors": "Nevan Wichers,Aram Ebtekar,Ariana Azarbal,Victor Gillioz,Christine Ye,Emil Ryd,Neil Rathi,Henry Sleight,Alex Mallen,Fabien Roger,Samuel Marks", "background": "大型语言模型在训练过程中可能会根据不完美的监管信号学习到一些不可取的行为，如奖励劫持和曲意逢迎。提高监管信号的质量可能是昂贵或不切实际的，因此研究者们开发了一种方法，可以在不完美的训练信号下改善模型行为。这种背景下，本文提出了Inoculation Prompting (IP) 方法，该方法通过修改训练提示来有意识地请求不可取行为，从而防止模型学习这些行为。这种方法通过对模型进行预训练时引入不良行为的提示，在实际应用中更为有效地控制了模型的行为表现，而不大幅减少模型的有效能力。", "innovation": "Inoculation Prompting (IP) 是一种简单的但反直觉的技术，它通过修改训练提示来让模型在训练过程中学习到不会出现不可取行为的能力。这种技术能够有效减少模型在测试阶段学习到的不良行为，而不会严重影响模型的有效性能。具体来说，本文发现，如果在训练前使用的提示能够更强烈地引出不良行为，那么这些提示在实际训练过程中将更有效地作为防控措施。这种方法为寻找潜在的防控提示提供了一种启发式的指南，是一种易于实现且有效的控制模型扩展行为的方法，无需显著破坏其有效性能。", "conclusion": "总体而言，Inoculation Prompting 是一个简单有效的方法，它可以控制模型在微调过程中的泛化能力，防止模型学习到不可取行为，同时不会显著影响模型的有效能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06096", "html_url": "https://arxiv.org/abs/2510.06096", "title": "The Alignment Auditor: 一个验证和细化LLM目标的贝叶斯框架", "title_en": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining LLM Objectives", "authors": "Matthieu Bou,Nyal Patel,Arjun Jagota,Satyapriya Krishna,Sonali Parbhoo", "background": "大型语言模型（LLMs）隐含优化的目标仍然非常不透明，这使实现可信赖的对齐和审计成为一个重大挑战。目前逆强化学习（IRL）可以从中行为推断奖励函数，但现有方法要么生成一个过于自信的单一奖励估计，要么无法解决任务的基本歧义（非可识别性）。", "innovation": "该论文提出了一种原则性的审计框架，旨在重新定义奖励推断，使其不仅仅是一种简单的估计任务，而是一个全面的验证过程。该框架利用了贝叶斯IRL技术，不仅恢复了目标的概率分布，还为审计提供了三个关键功能：（i）通过展示后验收缩来量化并系统地减少非可识别性；（ii）提供具有行动性和不确定性意识的诊断工具，以识别不可信任的情况；（iii）通过验证优化后的奖励可以被直接用于RLHF以实现与真值对齐过程类似的训练效果和毒性降低来验证策略级的实用性。", "conclusion": "该框架成功审计了一个去毒的大语言模型，产生了一个度量准确且可解释的目标，从而增强了对齐保障。总体而言，这项工作为审计员、安全团队和监管机构提供了一个实际的工具套件，以便验证LLMs真正尝试实现的目标，使我们更接近于更可信和负责任的人工智能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06048", "html_url": "https://arxiv.org/abs/2510.06048", "title": "BLISS: 一种轻量级双层次影响评分方法在语言模型预训练中的数据选择", "title_en": "BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection in Language Model Pretraining", "authors": "Jie Hao,Rui Yu,Wei Zhang,Huixia Wang,Jie Xu,Mingrui Liu", "background": "有效的数据选择对于预训练大型语言模型（LLMs）至关重要，可以提高效率并改善下游任务的一般泛化能力。现有方法通常依赖预训练的外部模型进行数据选择，这使得难以区分数据选择与外部预训练模型效果的影响。此外，它们往往忽略了模型收敛时选定数据的长期影响，主要原因是在大规模预训练方面成本过高。", "innovation": "本文提出了一种轻量级的数据选择方法——BLISS（Bileve Influence Scoring方法），完全从头开始，无需依赖任何外部预训练的指导模型，同时考虑选定数据的长期影响。BLISS利用小型代理模型作为大型语言模型的代理，并使用评分模型估计代理模型收敛时训练样本的长期影响。数据选择被形式化为双层优化问题，其中上层目标优化评分模型以根据重要权重分配训练样本，确保最小化下层目标（即使用加权训练损失训练代理模型直到收敛）可以达到最佳验证性能。优化后，训练的评分模型可以预测数据集的影响分数，从而高效地选择高质量的样本用于LLM预训练。我们通过在C4数据集的子集上预训练410M/1B/2.8B Pythia和LLaMA-0.5B模型验证了BLISS。在1B模型设置下，BLISS实现了1.7倍的速度提升，达到与最先进的方法相同的性能，展示了在多个下游任务上的优越性能。", "conclusion": "BLISS能够在无需依赖外部预训练模型的情况下，有效选择高质量样本进行大型语言模型的预训练，同时考虑了选定数据的长期影响，并且能够实现高效且性能优越的预训练结果。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1910.11030", "html_url": "https://arxiv.org/abs/1910.11030", "title": "基于时空切片的注意力导向LSTMs及其在交通视频预测中的应用", "title_en": "Spatiotemporal Tile-based Attention-guided LSTMs for Traffic Video Prediction", "authors": "Tu Nguyen", "background": "交通流量预测需要同时建模细粒度（像素级别）和粗粒度（区域级别）的空间结构，同时保持长时间序列中的时间关系。传统的RNN及其变体在处理这种多尺度空间结构和长时间依赖关系时存在局限性，这使得模型难以有效捕捉复杂的交通模式并预测交通热力图。为此，研究者们提出了各种改进方案，例如ConvLSTM等，但它们仍存在一些问题，如难以处理大规模地图和空间切片等。", "innovation": "本文提出了一个基于时空切片的注意力导向卷积长短期记忆网络（Tile-aware, Cascaded-Memory Conv-LSTM）。该模型通过引入时空切片感知机制，并结合跨帧加性注意力机制以及内存灵活训练方案，实现了对大规模地图的有效学习和处理。该模型的关键创新点在于采用时空切片的方法，使得模型能够学习局部动态并使每个时空切片的记忆单元稀疏更新、按需分页或压缩，从而能够高效地处理大规模地图。此外，理论分析和实验证明了该方法在大规模交通热力图预测中的优秀稳定性和预测性能。", "conclusion": "本文通过时空切片的方法和跨帧加性注意力机制，结合Conv-LSTM及其增强算法，提出了一个能够有效处理大规模交通热力图的预测模型。通过理论分析和实验验证，证明了该方法在交通流量预测中的高效性和优越性，对未来基于LSTM的交通预测模型设计提供了新思路。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2208.03761", "html_url": "https://arxiv.org/abs/2208.03761", "title": "Laplace和神经形态内核的经验分析", "title_en": "An Empirical Analysis of the Laplace and Neural Tangent Kernels", "authors": "Ronaldas Paulius Lencevičius", "background": "神经形态内核被定义为无限宽度神经网络参数分布上的核函数，尽管这个极限在实践中并不可行，但神经形态内核允许更加直接地研究神经网络，揭示其黑箱机制。最近研究表明，Laplace核和神经形态内核在$\boldsymbol{\textbf{S}}^{d-1}$空间中的再生核希尔伯特空间中是相同的，暗示它们在某种程度上是等价的。本文旨在进一步分析两者在实践中的等效性。首先，通过精确匹配核函数；其次，通过匹配Gaussian过程的后验；最后分别在$\boldsymbol{\textbf{R}}^d$空间和回归任务中对两者进行分析。", "innovation": "本文通过理论上的核函数等式匹配和实践中后验匹配两种方法分析了Laplace核和神经形态内核的实用性等效性，并在$\boldsymbol{\textbf{R}}^d$空间和回归任务上进行了实验。这提供了对两者在实际应用中的性能和特点的深入理解，有助于选择最适合当前任务的核函数，推动机器学习模型的进一步发展和应用。", "conclusion": "通过两种核函数的匹配及在$\boldsymbol{\textbf{R}}^d$空间和回归任务上的实验，本文展示了Laplace核和神经形态内核在某些任务上是实践等效的。Laplace核在某些特定条件下可能更具优越性，这取决于特定任务和数据集的具体特性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03881", "html_url": "https://arxiv.org/abs/2403.03881", "title": "使用扩散模型解锁数据集蒸馏", "title_en": "Unlocking Dataset Distillation with Diffusion Models", "authors": "Brian B. Moser,Federico Raue,Sebastian Palacio,Stanislav Frolov,Andreas Dengel", "background": "数据集蒸馏旨在将大规模的数据集凝练为更小数量但高度代表性的合成样本。尽管扩散模型目前在生成基准测试中的表现最佳，当前的数据集蒸馏方法仍避免使用它们，而是依赖于生成对抗网络（GANs）、自动编码器（autoencoders），或在最理想的情况下基于固定的扩散先验进行采样。这一趋势是因为直接对长去噪链路进行反向传播会导致梯度消失，从而妨碍有效的合成样本优化。", "innovation": "本文引入了使用预训练扩散模型的基于潜空间的数据集蒸馏（Latent Dataset Distillation with Diffusion Models，LD3M），这是一个可以一次性学习梯度导向的虚拟特征和类别嵌入的方法，无需微调扩散权重。具体来说，LD3M使用一个线性衰减的跳跃连接，从初始噪音状态延伸到每个逆向步骤，以在数十个时间步长内保持梯度信号.", "conclusion": "在ImageNet的多个子数据集上进行的实验表明，LD3M能够将下游准确率提升4.8至4.2个百分点。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2209.03358", "html_url": "https://arxiv.org/abs/2209.03358", "title": "针对Spiking神经网络的攻击：关于对抗样本在Spiking神经网络中的可移植性和安全性", "title_en": "Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples", "authors": "Nuo Xu,Kaleel Mahmood,Haowen Fang,Ethan Rathbun,Caiwen Ding,Wujie Wen", "background": "Spiking神经网络（SNNs）因其高能效和最近的分类性能提升吸引了大量关注。然而，与传统深度学习相比，SNNs对对抗样本的鲁棒性尚未得到充分探索。本文通过研究SNNs的对抗攻击方面，取得了三项重大贡献：首先，作者证明了SNNs的有效白盒攻击强烈依赖于替代梯度估计技术，即使在对抗训练模型中也是如此。其次，研究了使用最佳单个替代梯度估计方法的情况下，SNNs与其他先进架构如Vision Transformers (ViTs) 和CNNs之间的对抗样本可移植性。分析揭示了两个主要差距：现有白盒攻击未充分利用多个替代估计器，且单一攻击无法同时欺骗SNNs和非SNN模型。最后，提出了混合动态Spiking估计（MDSE）攻击，该攻击动态结合多个替代梯度，以克服上述差距。", "innovation": "提出了混合动态Spiking估计（MDSE）攻击，该攻击动态结合多个替代梯度，克服了现有的替代梯度估计技术对SNNs和其他模型性能提升有限的问题。MDSE生成的对抗样本能够欺骗SNN和非SNN模型，尤其在SNN/ViT组合上达到了91.4%的有效性提升，超过Auto-PGD三倍。", "conclusion": "实验覆盖了三个数据集（CIFAR-10, CIFAR-100, ImageNet）和十九种分类器。结果表明，通过动态结合多个替代梯度，MDSE攻击可以有效提升SNN模型的对抗性，并提高了对抗训练SNN的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04975", "html_url": "https://arxiv.org/abs/2411.04975", "title": "SuffixDecoding：针对新兴AI应用的极端推测解码", "title_en": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications", "authors": "Gabriele Oliaro,Zhihao Jia,Daniel Campos,Aurick Qiao", "background": "推测解码被广泛用于通过利用较小的草稿模型来减少大规模语言模型（LLM）推理的延迟。然而，新兴的AI应用，如基于LLM的代理，呈现出独特的负载特征：这些应用主要提交重复的推理请求，例如多个代理管道执行相似的子任务或者自我完善循环迭代提高输出。现有的推测解码方法未能有效地利用这些长且高度可预测的序列。", "innovation": "提出了一种新颖的方法SuffixDecoding，该方法利用高效后缀树缓存提示和先前输出中的长token序列。根据接受性概率，SuffixDecoding能够适当地推测更多的tokens或较少的tokens。这种方法在遇到推测机会时有效地利用了长推测的机会，并在机会有限时节省了计算资源。", "conclusion": "在包括SWE-Bench和Text-to-SQL在内的代理基准测试中，SuffixDecoding实现了高达5.3倍的加速比，并且相比现有的最佳方法，无论是基于模型的方法（如EAGLE-2/3）还是无模型的方法（如Token Recycling），都表现出了显著的性能优势。SuffixDecoding已开源。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.11031", "html_url": "https://arxiv.org/abs/2410.11031", "title": "NAR-*ICP：经典ICP点云注册算法的神经执行", "title_en": "NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms", "authors": "Efimia Panagiotaki,Daniele De Martini,Lars Kunze,Paul Newman,Petar Veličković", "background": "神经网络和经典机器人算法在很大程度上互补：神经网络具有强大的适应能力和对复杂高维数据的处理能力，但缺乏透明性和内部计算的可解释性；经典机器人算法由于其逻辑和数学原则的可预测性和一致性，特别适合在安全性关键应用中使用。为了融合这两者，在保持经典算法性能的同时提高透明度，研究提出了一种基于图神经网络（GNN）的新型框架NAR-*ICP，旨在通过学习ICP基点云注册算法的中间计算过程来训练神经网络。这种方法通过CLRS基准进行扩展，并在实际和合成数据集上进行了评估，显示了其在处理复杂输入时的灵活性和通用性潜力。", "innovation": "NAR-*ICP是一种基于图神经网络的创新框架，它旨在通过学习经典ICP基点云注册算法的中间计算过程来训练神经网络，从而在保留经典算法性能的同时提高透明度。该方法通过扩展CLRS基准并通过实际和合成数据集的评估展示了其灵活性和通用性潜力，并在性能上优于基准方法，甚至超过了训练它的算法，进一步证明了其超越传统算法的能力。", "conclusion": "通过引入NAR-*ICP框架，研究成功地实现了神经网络和经典机器人算法之间的一种有效互联，不仅展示了其在复杂任务中处理能力的优越性，还证明了神经网络在通用性和灵活性方面的潜力。这种方法为更广泛的基于学习的管道应用铺平了道路，并为提高神经网络的可解释性提供了新的途径。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00656", "html_url": "https://arxiv.org/abs/2501.00656", "title": "OLMo 2 Furious", "title_en": "2 OLMo 2 Furious", "authors": "Team OLMo,Pete Walsh,Luca Soldaini,Dirk Groeneveld,Kyle Lo,Shane Arora,Akshita Bhagia,Yuling Gu,Shengyi Huang,Matt Jordan,Nathan Lambert,Dustin Schwenk,Oyvind Tafjord,Taira Anderson,David Atkinson,Faeze Brahman,Christopher Clark,Pradeep Dasigi,Nouha Dziri,Allyson Ettinger,Michal Guerquin,David Heineman,Hamish Ivison,Pang Wei Koh,Jiacheng Liu,Saumya Malik,William Merrill,Lester James V. Miranda,Jacob Morrison,Tyler Murray,Crystal Nam,Jake Poznanski,Valentina Pyatkin,Aman Rangapur,Michael Schmitz,Sam Skjonsberg,David Wadden,Christopher Wilhelm,Michael Wilson,Luke Zettlemoyer,Ali Farhadi,Noah A. Smith,Hannaneh Hajishirzi", "background": "本研究介绍了一种新的开放语言模型系列OLMo 2，它包含7B、13B和32B规模的密集自回归语言模型，并且所有相关的内容如模型权重、全量训练数据、训练代码、日志以及数千个中间检查点都被完全公开。OLMo 2在先前版本的基础上进行了改进，重点在于提高训练稳定性以及提升每令牌的效率。", "innovation": "1. 提出了一个全新的数据混合策略Dolmino Mix 1124，在预训练的后期引入这一策略可以显著提高模型在各种下游任务上的表现。\n2. 结合Tülu 3的最佳实践，开发出OLMo 2-Instruct模型，采用验证性奖励（RLVR），并改进了最终阶段的强化学习方法。\n3. OLMo 2在性能与训练计算资源之间的权衡达到了帕累托最优点，特别是在模型大小、FLOPs（浮点运算次数）以及透明度方面优于其他类似的模型。", "conclusion": "OLMo 2和其改进版OLMo 2-Instruct，不仅在开放权重模型中表现出色，甚至还能与部分专有模型竞争，特别是在使用更少计算资源和完全透明化培训数据、代码和食谱的同时。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.01160", "html_url": "https://arxiv.org/abs/2401.01160", "title": "使用立方持久同调实现无训练的MRI分割", "title_en": "Train-Free Segmentation in MRI with Cubical Persistent Homology", "authors": "Anton François,Raphaël Tinarrage", "background": "传统机器学习方法在医疗影像分割中的应用存在局限性，尤其是在需要大量标注数据的情况下。近年来，拓扑数据分析（TDA）开始应用于医疗影像领域，但在大多数情况下，TDA方法仍然嵌入到深度网络中。本研究提出了一个基于TDA的新通用框架，用于MRI扫描的分割，旨在提供一种不需要大量标注数据的方法，并且具有模块化设计，适用于各种数据分割挑战。", "innovation": "开发了一种新的基于TDA的MRI分割框架，采用模块化设计，不依赖于大量的预标注数据。主要创新点包括：1. 通过自动阈值确定要分割的整体对象；2. 检测已知拓扑特征的子集；3. 通过局部化持久图中的典型环来实现可解释的拓扑特征到解剖组件的映射；4. 方法适用于各种分割挑战，如脑胶质瘤、心肌和胎儿脑皮质的分割；5. 不依赖于嵌入深度网络的TDA方法，是一种独立的方法。", "conclusion": "该框架已经在三种应用中得到验证：脑MRI中胶质瘤的分割，心脏MRI中心肌的分割，以及胎儿脑MRI中皮质板的检测。研究结果表明，该方法可以作为一种无训练的分割方法，在不需要大量标注数据的情况下实现有效的精确分割。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.11803", "html_url": "https://arxiv.org/abs/2501.11803", "title": "大规模自动化放疗计划：高质量数据用于AI培训", "title_en": "Automating RT Planning at Scale: High Quality Data For AI Training", "authors": "Riqiang Gao,Mamadou Diallo,Han Liu,Anthony Magliari,Jonathan Sackett,Wilko Verbakel,Sandra Meyers,Rafe Mcbeth,Masoud Zarepisheh,Simon Arberet,Martin Kraus,Florin C. Ghesu,Ali Kamen", "background": "放疗（RT）规划复杂、主观且耗时。人工智能（AI）的进步有望提高其精确度和效率，但进步受限于大型标准化数据集的稀缺性。为了解决这一问题，作者介绍了一种名为Automated Iterative RT Planning（AIRTP）的系统，这是一种可扩展的解决方案，能够生成高质量的治疗计划，克服了AI驱动放疗计划进展的关键障碍。AIRTP管道遵循临床指南，自动化了关键步骤，包括危险器官（OAR）轮廓绘制、辅助结构创建、照准设置、优化和计划质量改善，使用AI集成到放疗规划软件（如Varian Eclipse）中。", "innovation": "该系统提出了一种新的方法来确定优化参数，以重现3D剂量分布，即将剂量预测转换为受机器限制的可交付治疗计划。同时，自动化管道生成的治疗计划质量与手动计划相当，而传统的手动计划需要几小时的工作。AIRTP数据集包括九个头颈部和肺癌队列，包含超过现有最大well-curated公共数据集10倍数量的计划，支持AAPM 2025挑战。", "conclusion": "AIRTP系统为AI驱动的放疗计划提供了一个可扩展且高质量的数据解决方案，该系统能够生成大量高一致性的治疗计划，改善AI驱动放疗规划的发展。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14230", "html_url": "https://arxiv.org/abs/2501.14230", "title": "GreedyPixel：基于贪婪算法的细粒度黑盒对抗攻击", "title_en": "GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm", "authors": "Hanrui Wang,Ching-Chun Chang,Chun-Shien Lu,Christopher Leckie,Isao Echizen", "background": "深度神经网络对对抗样本极为敏感，这些样本通过细微、精心设计的扰动导致误分类，使得对抗攻击成为提高模型鲁棒性的重要工具。现有的黑盒攻击分为三类：查询型、迁移型和查询与迁移结合型，它们在扰动模式和优化策略上有所不同。然而，此前没有方法能够同时实现查询与迁移指导、像素级稀疏性和无训练直接优化，这在黑盒灵活性和白盒精度之间留下了差距。", "innovation": "GreedyPixel 提出了一种新的攻击框架，通过结合源自替代模型的像素优先级图和基于查询反馈的贪婪、逐像素优化，将指数级的暴力搜索空间缩减为可处理的线性过程，确保损失单调减少并收敛至坐标的最优值，同时将扰动集中到鲁棒且语义有意义的像素上，以提高视觉质量。实验结果表明，GreedyPixel 在 CIFAR-10 和 ImageNet 上均能达到最先进的攻击成功率，并产生不可视的扰动。", "conclusion": "GreedyPixel 跨越了白盒和黑盒攻击之间精确度的差距，提供了一种为细粒度鲁棒性评估提供实用框架的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07939", "html_url": "https://arxiv.org/abs/2502.07939", "title": "基于马尔可夫概率模型的位级离散扩散：在最少假设下具有锐利收敛界的改进框架", "title_en": "Bit-Level Discrete Diffusion with Markov Probabilistic Models: An Improved Framework with Sharp Convergence Bounds under Minimal Assumptions", "authors": "Le-Tuyet-Nhi Pham,Dario Shariatian,Antonio Ocello,Giovanni Conforti,Alain Durmus", "background": "本文介绍了离散马尔可夫概率模型（DMPMs），这是一种用于生成离散数据的新型离散扩散算法。算法在离散位空间中操作，其中噪化过程是一个连续时间马尔可夫链，它可以均匀随机地翻转标签。时间反转过程类似于前向干扰过程，是一个跳跃过程，其强度由经典评分函数的离散类比控制。本文证明了这种强度是前向过程的条件期望，强调了与评分生成模型的理论一致性。在实验中，算法在低维伯努利分布的数据集和高维二进制MNIST数据上得到了应用，并验证了在生成离散结构方面的竞争力。", "innovation": "提出了离散马尔可夫概率模型（DMPMs），这是一种在离散位空间中工作的新型离散扩散算法。该算法通过连续时间马尔可夫链均匀随机翻转标签来实现噪化过程，时间反转过程的强度由经典评分函数的离散类比控制，并且证明了这种强度是前向过程的条件期望。文中建立了模型的收敛边界，在最少的假设条件下确保了算法的稳健性和高效性。", "conclusion": "本文通过理论基础和实际应用的结合，展示了离散马尔可夫概率模型的强大功能。这些模型在生成离散结构方面取得了与最新技术相当的性能。这不仅推进了离散生成建模的发展，也为该领域的进一步研究奠定了基础。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08063", "html_url": "https://arxiv.org/abs/2502.08063", "title": "2×2对称非零和博弈下指数加权动态的末次迭代收敛性", "title_en": "Last-iterate Convergence for Symmetric, General-sum, $2 \\times 2$ Games Under The Exponential Weights Dynamic", "authors": "Guanghui Wang,Krishna Acharya,Lokranjan Lakshmikanthan,Juba Ziani,Vidya Muthukumar", "background": "研究者对具有2×2纯策略集和对称纳什博弈形势的动态离散时间指数加权方法进行了全面分析。这类博弈常见于对称代理之间的真实互动，例如贝特朗竞争、多智能体预测以及某些拥挤博弈。尽管这些博弈的设置看似简单，但具有丰富多样的均衡解。", "innovation": "研究揭示了一种通过第一原则分析，证明了在适当选择步长的情况下，尽管初始状态不同，指数加权动力学在最后一次迭代中对于此类博弈总是收敛的。在某些情况下，对于特定的博弈及其初始状态，该收敛速度甚至呈指数级，并适用于任何步长。", "conclusion": "研究通过广泛的模拟试验和对多代理预测博弈中的“抵押竞争”游戏的应用，证明了上述理论的正确性。此外，研究扩展了指数加权动力学在博弈理论中的应用范围。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08127", "html_url": "https://arxiv.org/abs/2412.08127", "title": "从本质上说，邪恶双胞胎并不那么邪恶：关于机器生成提示的定性见解", "title_en": "Evil twins are not that evil: Qualitative insights into machine-generated prompts", "authors": "Nathanaël Carraz Rakotonirina,Corentin Kervadec,Francesca Franzon,Marco Baroni", "background": "已经广泛观察到语言模型（LMs）对看似无意义的算法生成的提示作出可预测的响应。这种现象表明我们对LMs的工作机制缺乏全面的理解，同时也对这种不透明性可能导致LMs被用于有害目的，例如脱管使用（jailbreaking）构成了实际挑战。", "innovation": "本研究首次全面分析了6种不同大小和家族的LMs的机器生成提示（autoprompts），发现机器生成的提示往往包含一个容易理解的最后一个词，这个词很大程度上影响了生成过程。还发现先前的一些词可能是可修剪的，因为优化过程决定了令牌的数量。此外，剩下的词可以分为两类：填充词和关键词。研究显示，专家能可靠地后验识别出最具有影响力的词，这表明这些提示并非完全不透明。此外，对机器生成提示的部分删除操作在自然语言输入中产生了类似的效果。", "conclusion": "机器生成的提示并非完全不透明，能够影响生成过程的词具有一定的识别价值，并且有些操作在自然语言输入中也有类似效果，提示了LMs处理语言输入的一般机制。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18915", "html_url": "https://arxiv.org/abs/2410.18915", "title": "比学习直方图更高效地测试支持大小", "title_en": "Testing Support Size More Efficiently Than Learning Histograms", "authors": "Renato Ferreira Pinto Jr.,Nathaniel Harms", "background": "本文考虑了关于未知概率分布$p$的两个问题：1. 需要多少样本从$p$抽取出才能测试$p$是否仅支持$n$个元素。具体地，给出$p$的样本，判断它是否支持最多$n$个元素，或者与仅支持$n$个元素的距离（即总变距离）超过$\rm \boldsymbol{\textbf{\textit{\textepsilon}}}$。2. 给定$m$个$p$的样本，能得到的支持大小的最低估计是多少？目前解决第一个问题的最佳上界使用一个通用算法学习$p$的直方图，需要$\rm \boldsymbol{\textbf{\textit{\textTheta}}}(\frac{n}{\rm \boldsymbol{\textbf{\textit{\textepsilon}}}^2\rm \boldsymbol{\textbf{\textit{\textlog}}}n})$样本。本文显示了可以通过仅使用$\rm \boldsymbol{\textbf{\textit{\textO}}}(\frac{n}{\rm \boldsymbol{\textbf{\textit{\textepsilon}}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{n}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{1/\rm \boldsymbol{\textbf{\textit{\textepsilon}}}})$样本来更高效地进行测试，几乎达到了最佳已知下界$\rm \boldsymbol{\textbf{\textit{\textOmega}}}(\frac{n}{\rm \boldsymbol{\textbf{\textit{\textepsilon}}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{n}})$。此算法还为第二个问题提供了更好的解决方案，提供了比以往工作更广泛的、支持大小的下界估计。证明基于Chebyshev多项式逼近的分析，超出它们设计的良好逼近范围，并且本文旨在提供一种关于Chebyshev多项式方法的可读和自包含解释。", "innovation": "相比学习直方图的方法，本文提出了一种更高效的测试方法，可以通过$\rm \boldsymbol{\textbf{\textit{\textO}}}(\frac{n}{\rm \boldsymbol{\textbf{\textit{\textepsilon}}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{n}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{1/\rm \boldsymbol{\textbf{\textit{\textepsilon}}}})$样本数量来处理第一个问题，几乎达到了最佳已知下界$\rm \boldsymbol{\textbf{\textit{\textOmega}}}(\frac{n}{\rm \boldsymbol{\textbf{\textit{\textepsilon}}}\rm \boldsymbol{\textbf{\textit{\textlog}}}{n}})$，同时也为问题2提供了更优的支持大小下界估计。", "conclusion": "本文通过分析Chebyshev多项式的逼近性质，得出了一个测试未知概率分布支持大小更有效的算法，该算法需要较少的样本数量，近乎等同于理论下界。此工作对于理解Chebyshev多项式的方法和改进概率分布测试算法具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.05408", "html_url": "https://arxiv.org/abs/2501.05408", "title": "Tempo: 使用符号依赖图的编译动态深度学习", "title_en": "Tempo: Compiled Dynamic Deep Learning with Symbolic Dependence Graphs", "authors": "Pedro F. Silvestre,Peter Pietzuch", "background": "传统的深度学习（DL）算法常常定义为存在时间关系：一个张量在某一时间步可能依赖于早前或后续时间步的张量。这样的动态依赖关系（及其张量形状）在表达和优化中是困难的。渴望执行的DL系统支持这种动态性，但无法应用编译器优化；基于图的系统需要静态的张量形状，这迫使用户填充张量或拆分程序为多个静态图。", "innovation": "Tempo是一个新的DL系统，它结合了渴望执行的动态性和基于图的编译的最佳实践。通过一个包含显式时间维度的声明式编程模型，Tempo能表示动态依赖于过往和未来张量的符号表达。基于此，Tempo构建了符号依赖图，以简洁的方式编码操作间的动态依赖关系。Tempo还通过时空维度的分割重用已有的静态代码生成器，并利用多面体模型找到一个可行的执行调度，其中包括内存管理操作。", "conclusion": "Tempo在解码Llama-3.2-3B上实现了7倍的速度提升；在强化学习算法上，Tempo实现了54倍的速度提升，并且峰值内存使用率降低了16倍。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18015", "html_url": "https://arxiv.org/abs/2504.18015", "title": "DiffMI: via 散度驱动训练免费模型反转打破面部识别隐私", "title_en": "DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven Training-Free Model Inversion", "authors": "Hanrui Wang,Shuo Wang,Chun-Shien Lu,Isao Echizen", "background": "面部识别存在严重的隐私风险，因为它依赖于敏感且不可变的生物特征数据。虽然现代系统通过映射面部图像到嵌入（通常被认为是隐私保护的）来缓解隐私风险，但模型反转攻击表明，仍然可以通过这些嵌入恢复身份信息，暴露了关键的脆弱性。现有的攻击通常耗时且缺乏泛化能力，尤其是那些需要特定目标训练的攻击。即使是无训练方法，也往往在身份可控性方面受限，妨碍了对复杂或未见过的面孔的真实还原。", "innovation": "本文提出了一种名为DiffMI的新颖的散度驱动、无训练模型反转攻击。DiffMI引入了结合了鲁棒的潜在代码初始化、按排名的对抗性细化策略以及统计学基础的自信感知优化目标的创新性流程。该方法可以直接应用于未见过的目标身份和面部识别模型，比依赖训练的方法更具适应性，同时显著减少了计算开销。", "conclusion": "我们的方法在对抗性鲁棒系统中取得了84.42%至92.87%的攻击成功率，并优于最好的先前无训练的方法，提升幅度为4.01%至9.82%。该实施已在this https URL上提供。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09755", "html_url": "https://arxiv.org/abs/2502.09755", "title": "狱破攻击初始化作为合规方向的提取器", "title_en": "Jailbreak Attack Initializations as Extractors of Compliance Directions", "authors": "Amit Levi,Rom Himelstein,Yaniv Nemcovsky,Avi Mendelson,Chaim Baskin", "background": "安全对齐的大规模语言模型在响应提示时，会以遵守指令或拒绝两种方式来表现，每种方式对应着模型激活空间中的不同方向。最近的研究表明，通过自我转移从其他提示初始化攻击能够显著提高其性能，然而攻击背后的机制尚不明确，且攻击往往使用随机或手工挑选的初始值。本文发现，基于梯度的狱破攻击及其后续初始化逐渐趋向于一个抑制拒绝指令的单一合规方向，从而实现从拒绝到遵守的高效过渡。通过这一认识，论文提出了CRI初始化框架，旨在将未见过的提示投影到更加符合合规方向上。实验结果表明，该方法提高了攻击成功率（ASR），同时减少了计算开销，突显了安全对齐的大规模语言模型的脆弱性", "innovation": "通过梯度基狱破攻击与其关联的初始化方法逐渐趋同的现象，论文识别出了抑制抗拒展示的单合规方向，并提出了一种新的初始化框架CRI，旨在将未知指令向更符合合规方向的方向进行投影，从而提高攻击成功率并减少计算开销", "conclusion": "通过CRI初始化框架，论文显著提升了尚未见过的提示对安全对齐的大规模语言模型的攻击成功率，验证了这些大语言模型存在脆弱性，同时也为后续优化和安全措施提供了新思路"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03654", "html_url": "https://arxiv.org/abs/2503.03654", "title": "使用高效数据和参数的 RL 提高中立观点生成能力", "title_en": "Improving Neutral Point-of-View Generation with Data- and Parameter-Efficient RL", "authors": "Jessica Hoffmann,Christiane Ahlheim,Zac Yu,Aria Walfrand,Jarvis Jin,Marie Tano,Ahmad Beirami,Erin van Liemt,Nithum Thain,Hakim Sidahmed,Lucas Dixon", "background": "本文研究了参数效率强化学习（PE-RL）在提升大型语言模型（LLMs）回答敏感话题时保持中立观点（NPOV）的能力。通过与其他强化学习方法（如LoRA微调、SFT和RLHF）进行对比评估，结果表明PE-RL能大幅提高答案的质量，特别是在提供支持细节和避免过度简化方面表现优异。此外，PE-RL在更新策略上也有独特优势，它能在不相关话题上更好地泛化。", "innovation": "本文的创新在于提出了一种参数效率强化学习（PE-RL）训练框架，能够在保持中立观点的同时显著提高回答敏感话题的质量。此外，研究还构建了一个新的数据集SHQ-NPOV，并提供了通过多轮人类评审和注释员培训创建类似数据集的方法。", "conclusion": "通过PE-RL训练的LLM在中立观点生成方面表现出了出色的能力，尤其是在提供有用详细信息和避免过度简化方面。此外，PE-RL方法还具备在不相关主题上的泛化能力。最后，研究者公开了用于NPOV生成的数据集SHQ-NPOV及其创建方法，为后续研究提供了依据。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01505", "html_url": "https://arxiv.org/abs/2503.01505", "title": "损失性神经压缩在地球空间分析中的应用：综述", "title_en": "Lossy Neural Compression for Geospatial Analytics: A Review", "authors": "Carlos Gomes,Isabelle Wittmann,Damien Robert,Johannes Jakubik,Tim Reichelt,Michele Martone,Stefano Maurogiovanni,Rikard Vinge,Jonas Hurst,Erik Scheurer,Rocco Sedona,Thomas Brunschwiler,Stefan Kesselheim,Matej Batic,Philip Stier,Jan Dirk Wegner,Gabriele Cavallaro,Edzer Pebesma,Michael Marszalek,Miguel A Belenguer-Plomer,Kennedy Adriko,Paolo Fraccaro,Romeo Kienzler,Rania Briq,Sabrina Benassou,Michele Lazzarini,Conrad M Albrecht", "background": "过去几十年间，地球观测数据的数量激增，卫星影像不仅覆盖了地球表面和大气层的广阔区域，还产生了庞大的数据量，需要传输到地面站、存储在数据中心，并分发给最终用户。现代地球系统模型也面临着类似的挑战，运行在高空间和时间分辨率下，产生PB级数据。数据压缩在过去十年中变得更加重要，基于深度学习和信息理论的神经压缩（NC）技术因其大量的未标记数据而成为一个理想的选择。本文回顾了NC在地理空间数据中的最新进展。", "innovation": "引入了NC的基本概念及其在图像和视频压缩的传统应用，聚焦于有损压缩。介绍了EO和ESM数据的独特特性，与“自然图像”进行对比，解释了它们带来的额外挑战和机遇。回顾了NC在各种EO模态中的当前应用，并探讨了迄今为止在ESM压缩方面的有限努力。重点提到了自监督学习（SSL）和基础模型（FM）的进步如何提高了从大量未标记数据中高效提取表示的方法。", "conclusion": "基于本文综述所得的见解，提出了适用于EO和ESM应用的相关未来方向，探讨了如何通过转移压缩特征表示促进机器-机器通信。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11006", "html_url": "https://arxiv.org/abs/2505.11006", "title": "展望监督学习与非监督学习的差异", "title_en": "Is Supervised Learning Really That Different from Unsupervised?", "authors": "Oskar Allerbo,Thomas B. Schön", "background": "当前，监督学习通常被看作是通过标签数据 y 来优化模型的一个过程。然而，作者提出了一种新的方法，将监督学习分解为两个阶段：首先是基于非监督学习选择模型参数，然后在不改变参数值的情况下将输出 y 加入模型。这种方法的关键在于一个新的模型选择标准，该标准能够在没有访问 y 的情况下使用，而传统的交叉验证方法则需要 y 的信息。", "innovation": "这项研究的创新在于提出了一种新的监督学习方法，通过分为两个阶段的操作减少对标签数据 y 的依赖：第一阶段采用非监督学习选择模型参数，第二阶段通过加权输出 y 来调整模型，而不改变参数值。此外，作者还证明了这种方法在理论上可以与传统监督学习方法具有相似的最优风险，并在实际和合成数据集上验证了这一点，表明非监督和监督学习之间的差异可能比传统观点认为的要小。", "conclusion": "本文的研究结果表明，监督学习与非监督学习之间的差异可能比表面上看起来的要小。通过提出一种新的监督学习方法，这种方法不依赖于标签数据 y，且在理论上和实践中可以与传统方法获得相似的表现，这为理解和设计机器学习算法提供了新的视角。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11329", "html_url": "https://arxiv.org/abs/2505.11329", "title": "TokenWeave: 分布式大语言模型推理的高效计算-通信Overlap", "title_en": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference", "authors": "Raja Gond,Nipun Kwatra,Ramachandran Ramjee", "background": "分布式推理大规模语言模型（LLMs）在高性能计算平台上可能会引入高达20%的额外开销，即便使用如NVLink等高速互连接口连接的GPU也不例外。多个技术尝试通过将计算细分为更小的子任务并利用子任务完成时重叠通信来缓解这些开销。然而，对一个大规模计算进行精细分解到多个较小计算任务时在GPU上会产生额外开销，而且通信本身会使用多个流多处理器（SMs），进一步增加了开销。", "innovation": "提出了一种名为TokenWeave的技术，通过波感知模式分割推理批次中的令牌并将其分成两个大约相等的子集。通信一个子集的同时重叠另一个子集的计算。此外，TokenWeave优化了层归一化计算的顺序，实现了新的融合AllReduce--RMSNorm内核，利用了Hopper和Blackwell NVIDIA GPU上可用的Multimem指令支持。这些优化使得TokenWeave仅使用2-8个SMs即可完成通信和RMSNorm操作，并且还有能力将内存限制的RMSNorm重叠到其他批次的计算中，从而提供额外的性能增益。", "conclusion": "TokenWeave在多个模型和工作负载中的评估显示，与移除所有通信的等效模型相比，可以实现1.29倍的延迟加速和1.26倍更高的吞吐量。在某些情况下，TokenWeave在性能上优于完全移除通信的等效模型。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20772", "html_url": "https://arxiv.org/abs/2505.20772", "title": "MetaSlot：突破对象中心学习中固定数量的槽位", "title_en": "MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning", "authors": "Hongjia Liu,Rongzhen Zhao,Haohan Chen,Joni Pajarinen", "background": "在视觉领域，学习对象级别的结构化表示被认为是提高模型泛化能力的关键。传统的对象中心学习方法（OCL）通常使用Slot Attention或其变体，但它们依赖于固定的槽位数量，这会导致在对象数量变化时，一个对象被表示为多个部分。", "innovation": "MetaSlot引入了一种可插拔的Slot Attention变体，能够适应变化的对象数量。具体来说，MetaSlot通过保留对象原型的码本，并通过码本量化来去除重复的槽位，以及在Slot Attention过程中逐步注入更弱的噪声来加速和稳定聚合。", "conclusion": "MetaSlot在多种公开的数据集和任务中，如对象发现和识别，比现有的Slot Attention变体实现了显著的性能提升，并且具有显著的可解释的槽位表示。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20309", "html_url": "https://arxiv.org/abs/2505.20309", "title": "引导巨匠：LLM中的轻量级加权激活定向控制器", "title_en": "Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs", "authors": "Amr Hegazy,Mostafa Elhoushi,Amr Alanwar", "background": "控制大型语言模型（LLM）的不良行为，如生成不安全内容或违反安全规范，通常依赖于昂贵的细调。激活引导为推理时的控制提供了一种替代方案，但现有的方法通常缺乏精细和自适应机制。", "innovation": "本文提出了一种新的方法，通过在推理过程中集成一个轻量级且可训练的控制器网络来实现对中间LLM激活的观察和控制。控制器网络预测全局放大因子和层特定的权重，并动态调整“拒绝方向”预计算向量衍生的引导补丁的强度，以影响LLM生成过程中各层的行为。这种方法通过使用有害和良性提示的激活训练，能够在推理时对有害输入进行细粒度、层感知的干预。", "conclusion": "实验结果表明，该加权激活引导控制器在有毒聊天与野外破坏性提示基准上显著提高了拒绝率，无需修改原始模型参数即可实现目标行为修改。与现有的方法相比，该方法在Llama-3.1-8B、Llama-3.2-1B和Mistral-7B上的实验显示其在推理时对LLM行为进行细粒度控制方面表现更优，提供了一种高效且自适应的方法。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18356", "html_url": "https://arxiv.org/abs/2505.18356", "title": "模型合并在这类LLM跨语言迁移中的非凡效果", "title_en": "The Unreasonable Effectiveness of Model Merging for Cross-Lingual Transfer in LLMs", "authors": "Lucas Bandarkar,Nanyun Peng", "background": "大型语言模型（LLMs）在低资源语言上的任务表现仍然不佳。本文研究了低资源语言上的跨语言迁移问题，其中特定任务的数据稀缺。以往研究已验证数学推理和多语言能力的关键模型参数是不重叠的。为了利用这种任务和目标语言参数化的隐式分离，本文开发并分析了多种模块化框架，以改进调优期间的组成。这些方法通常通过冻结参数或后置模型合并来分配数学和语言改进的不同关键部分。在缺乏内部数学数据的情况下，模块化方法在三种语言、四种模型和两种调优方法（全调优和LoRA）中提高了基线表现。本文还通过实验证明，在训练后逆转不有用的调优更新通常优于从一开始就冻结它们。", "innovation": "1. 确认了数学推理和多语言能力的关键模型参数是不重叠的。\n2. 开发了多种模块化框架，通过冻结参数或后置模型合并来改进调优期间的组成。\n3. 在没有语内数学数据的情况下，模块化方法显著提高了低资源语言上的表现。\n4. 发现模块化方法中最有效的策略是分别训练语言和数学专家，并通过层交换进行模型合并，这与最近关于任务向量线性的工作相吻合。此外，实验证明逆转不有用的调优更新在训练后通常优于从一开始就冻结它们。", "conclusion": "在没有语内数学数据的情况下，模块化方法能够在低资源语言上提高大型语言模型的基线表现。最近关于任务向量线性的工作对这一结果提供了可能的解释。在训练后逆转不有用的调优更新往往优于从一开始就冻结它们。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04486", "html_url": "https://arxiv.org/abs/2505.04486", "title": "使用潜在变量的高效流匹配", "title_en": "Efficient Flow Matching using Latent Variables", "authors": "Anirban Samaddar,Yixuan Sun,Viktor Nilsson,Sandeep Madireddy", "background": "流匹配模型在概率生成模型中的图像生成任务中显示出巨大的潜力。然而，文献中的大多数流匹配模型在从简单的源分布（例如标准高斯分布）学习流时，并未明确利用目标数据中的潜在聚类结构。这导致了低效的学习，尤其是在许多高维现实世界数据集上，这些数据集通常位于低维流形上。因此，本文提出了$\texttt{Latent-CFM}$，通过使用预训练的深度潜在变量模型提取的数据特征来提供更高效的训练策略。实验表明，$\texttt{Latent-CFM}$相较于最先进的流匹配模型，在采用预训练轻量级潜在变量模型时，既具有较高的生成质量，又具有显著较少的训练和计算量。此外，该模型还能用于基于潜变量的条件图像生成，增强了生成过程的可解释性。", "innovation": "本文提出了$\texttt{Latent-CFM}$，通过使用预训练的深度潜在变量模型提取的数据特征，提供了一种更高效的训练策略。这一策略特别适用于需要高效学习高维现实世界数据集中的低维流形结构的情况。通过使用多模态分布的合成数据和常用图像基准数据集进行实验，证明了$\texttt{Latent-CFM}$在生成质量和效率上都超过了最先进的流匹配模型。特别地，在物理过程产生的2D达西流动数据集上的实验结果表明，我们的方法能生成更物理上准确的样本。另外，通过对潜在空间的分析，表明$\texttt{Latent-CFM}$能够用于基于潜变量的条件图像生成，增加了生成过程的可解释性。", "conclusion": "通过预训练的轻量级潜在变量模型提取的数据特征，$\texttt{Latent-CFM}$能够提高流匹配生成的质量和效率。此外，该方法在生成物理过程数据时展示了更高的可解释性和准确性，能够用于条件生成任务，进一步增强了其应用的灵活性和实用性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22296", "html_url": "https://arxiv.org/abs/2505.22296", "title": "360-LLaMA-Factory: 插拔即用的长序列后训练并行化", "title_en": "360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training", "authors": "Haosheng Zou,Xiaowei Lv,Shousheng Jia,Lin Li,Xiaochun Gong,Xiangzheng Zhang", "background": "论文背景介绍了在LLaMA-Factory中加入序列并行性后，360-LLaMA-Factory被开源。该技术已被广泛应用于多种模型和平台，包括Light-R、TinyR、Kaggle AIMO数学模型以及各大公司的训练框架。文章进一步探讨了360-LLaMA-Factory背后的不同序列并行模式及其实施洞察。", "innovation": "研究的创新点在于引入序列并行性到LLaMA-Factory中，并公开了360-LLaMA-Factory。开源的360-LLaMA-Factory被广泛应用于各种模型和训练框架中，特别是Light-R1、TinyR1、Kaggle AIMO数学模型以及公司训练框架中，这些应用证明了序列并行性的有效性。文章还深入探讨了不同序列并行模式的实现细节和优化策略。", "conclusion": "论文通过探讨360-LLaMA-Factory的技术细节，证明了在大模型训练中引入序列并行性的有效性。这一技术的实现不仅优化了模型的训练效率，还推动了其在实际应用中的广泛使用，展示了其在大规模语言模型训练中的优势。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00320", "html_url": "https://arxiv.org/abs/2506.00320", "title": "Dyna-Think: 激发AI代理推理、行动与世界模型模拟的协同效应", "title_en": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "authors": "Xiao Yu,Baolin Peng,Ruize Xu,Michel Galley,Hao Cheng,Suman Nath,Jianfeng Gao,Zhou Yu", "background": "近年来，大型语言模型（LLMs），如DeepSeek-R1，在数学和编程等领域的推理能力表现出色，展示了复杂的认知行为，如验证、目标分解和自我反思。然而，对于长期AI代理任务而言，尚不清楚哪些行为是有效的，哪些行为是缺失的。", "innovation": "本文提出了一种名为Dyna-Think的思考框架，该框架将规划与内部世界模型相结合，通过推理和行动来提升AI代理的性能。为了实现Dyna-Think，作者提出了Dyna-Think模仿学习（DIT）和Dyna-Think Dyna训练（DDT）。DIT通过重构R1的思考过程来训练策略，DDT则通过两阶段训练首先提高代理的世界模型能力，然后通过策略训练提高行动能力。", "conclusion": "通过对OSWorld和WindowsAgentArena的评估，本文展示了Dyna-Think能够提升代理在领域内的和跨领域的性能，同时在平均情况下生成的token数比R1少一半。实验表明，使用批判生成来训练世界模型能够有效提升策略性能，而且性能更好的代理通常具有更好的世界模型能力。我们认为这些结果表明了一个有希望的研究方向，即将世界模型模拟整合到AI代理中，以增强其推理、规划和行动的能力。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07844", "html_url": "https://arxiv.org/abs/2506.07844", "title": "伊托过程中的条件局部独立性检验及其在动态因果发现中的应用", "title_en": "Conditional Local Independence Testing for Itô processes with Applications to Dynamic Causal Discovery", "authors": "Mingzhou Liu,Xinwei Sun,Yizhou Wang", "background": "从动态系统中推断因果关系是许多科学研究的关注点。条件局部独立性，描述了在给定其他过程的情况下一个过程的发展是否受另一个过程的影响，是此类系统中因果学习的关键。", "innovation": "提出了一种基于伊托过程半鞅分解的条件局部独立性假设检验。该检验通过非零的鞅性质测试进行统计分析，使用最优滤波方程估计检验统计量，进而验证测试的一致性，确定测试的水平和效能。此外，通过数值验证和大脑静息态fMRI的实际应用对因果发现进行验证。", "conclusion": "该研究建立了测试方法的一致性，并通过数值实验和实际应用验证了该方法的有效性，为动态因果发现提供了一种新的工具。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02548", "html_url": "https://arxiv.org/abs/2506.02548", "title": "CyberGym：大规模评估AI代理的实际网络安全能力", "title_en": "CyberGym: Evaluating AI Agents' Real-World Cybersecurity Capabilities at Scale", "authors": "Zhun Wang,Tianneng Shi,Jingxuan He,Matthew Cai,Jialin Zhang,Dawn Song", "background": "人工智能代理在网络安全领域具有潜在的重大影响，因此对其能力和表现进行全面评估至关重要。然而，现有的评估方法存在不足，主要是基于小规模基准且仅衡量静态结果，未能充分反映真实的动态安全挑战范围。", "innovation": "该研究引入了CyberGym，这是一种大规模基准测试，涵盖188个软件项目中的1,507个实际漏洞。CyberGym可以根据不同的漏洞分析设置，主要要求代理生成与文本描述和相应代码库相关的漏洞复现的原型测试。研究结果表明CyberGym不仅是一个强大的基准，用于衡量AI在网络安全领域的进展，而且也是一个直接产生实际安全影响的平台。", "conclusion": "即使顶级组合的成功率也只有约20%，这表明CyberGym的总体难度。此外，该研究还发现35个零日漏洞和17个历史上不完整的补丁。这些结果强调，CyberGym不仅是一个强大的基准，用于衡量AI在网络安全中的进展，而且是一个直接实现现实世界安全影响的平台。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 一种用于视觉语言模型的多领域物体检测基准", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉语言模型（VLMs）在大规模互联网数据上训练后，在检测常见物体（如汽车、卡车和行人）方面取得了显著的零样本性能。然而，最先进的模型在处理与其预训练数据不常见的新类别、任务和成像模态时仍难以泛化。为了改进这一点，该研究提出了一种新的方法——通过带有少量视觉示例和丰富文本描述的注解指令对VLMs进行对齐，而不是仅仅从更多的视觉数据重新训练VLMs。为此，研究人员引入了Roboflow100-VL，这是一个包含100个具有多样化概念的多模态物体检测数据集，这些概念并不常见于VLM的预训练数据中。研究测试了最先进的模型在零样本、少数样本、半监督和完全监督设置下的性能，以实现不同数据背景下之间的比较。研究发现，像GroundingDINO和Qwen2.5-VL这样的VLM在Roboflow100-VL中的挑战性医学影像数据集上的零样本准确性低于2%，这表明需要进行少量样本的概念对齐。研究还讨论了最近的CVPR 2025 基础方法FSOD竞赛，并分享了来自社区的见解。获胜团队的表现显著优于基线，提升了17 mAP！", "innovation": "该研究提议了一种新的方法，即通过带有少量视觉示例和丰富文本描述的注释指令来对齐视觉语言模型（VLMs），而不是仅仅从更多的视觉数据重新训练。为了支持这一方法，研究人员还创建了Roboflow100-VL，这是一个包含100个多模态物体检测数据集的集合，这些数据集涵盖了预训练数据中不常见的多样化概念。研究还在零样本、少数样本、半监督和完全监督设置下测试了最先进的模型，以全面评估其性能，并展示了对VLMs进行少量样本概念对齐的重要性。此外，还讨论了最近的CVPR 2025 Foundational FSOD竞赛，并分享了社区的见解，其中一个团队的表现显著优于基线模型，提升了17 mAP！", "conclusion": "该研究通过创建Roboflow100-VL，提供了一种新的基准，用于评估视觉语言模型在处理多样性、非典型性和挑战性数据集上的能力。研究证明了对VLMs进行少量样本概念对齐的重要性，并强调了在超越常规基准测试方面的改进空间。该研究还为进一步研究奠定了基础，特别是在视觉语言模型在多样化的未见数据中保持表现方面。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05516", "html_url": "https://arxiv.org/abs/2506.05516", "title": "学习恢复：摔倒机器人轮腿协调的动态奖励塑造", "title_en": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots", "authors": "Boyuan Deng,Luca Rossini,Jin Wang,Weijie Wang,Dimitrios Kanoulas,Nikolaos Tsagarakis", "background": "轮腿机器人的跌倒恢复是一项重要的技能，它们结合了腿足的敏捷性和轮子的速度以实现快速恢复。然而，传统依靠预规划恢复动作、简化动力学或稀疏奖励的方法常常难以生成稳健的恢复策略。", "innovation": "本文提出了一种基于学习的框架，结合了基于Episode的动态奖励塑造和课程学习，动态平衡了多样化恢复策略的探索和精确姿态调整。通过利用模拟中的先验信息的不对称演员-评论家架构加速训练，并通过注入噪声的观察来增强鲁棒性。进一步证明了轮腿协同作用可以降低关节扭矩消耗15.8%和26.2%，并通过能量转移机制提高稳定性。广泛的评估在两个不同的四足平台上取得了高达99.1%和97.8%的恢复成功率，而无需特定平台的调优。", "conclusion": "通过大量的评估，在两个不同的四足平台上，该方法实现了高达99.1%和97.8%的恢复成功率，且无需特定平台的调优。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22598", "html_url": "https://arxiv.org/abs/2505.22598", "title": "机器学习辅助蒙特卡洛采样在统计物理模型中的性能表现", "title_en": "Performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models", "authors": "Luca Maria Del Bono,Federico Ricci-Tersenghi,Francesco Zamponi", "background": "近年来，机器学习技术在辅助难以采样的系统模拟方面得到了广泛应用，这些系统无法通过传统方法进行研究。尽管引入了许多不同的架构和程序，但在理论理解方面仍然缺乏广度，存在实施不当的风险。", "innovation": "该工作在浅层MADE架构下，针对库利-威斯模型，提供了关于广泛使用的顺序退火程序的完整分析。主要贡献包括：描述了最优权重及梯度下降优化下的训练过程；比较了顺序退火有无局部马尔可夫蒙特卡洛步骤的效果；从而给出了在这种情况下最佳程序的理论预测。这为机器学习技术在蒙特卡洛采样和优化中的集成提供了清晰的理论基础。", "conclusion": "该工作为机器学习技术在蒙特卡洛采样和优化中的应用提供了一个明确的理论基础，有助于指导实际操作中的最优方法选择。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL：探索知识增强型强化学习以增进事实性", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是慢思考模型，常常由于推理过程中无法准确识别知识边界而产生严重的幻觉现象。虽然强化学习（RL）可以增强复杂的推理能力，但其结果导向的奖励机制往往缺乏对思考过程中的事实监督，进一步加剧了幻觉问题。", "innovation": "提出了一种知识增强型的RL模型，名为KnowRL。KnowRL通过在RL训练过程中引入基于知识验证的事实性奖励，引导模型进行基于事实的缓慢思考，帮助模型认识到其知识边界。通过这种方式，模型可以在推理过程中更好地内化基于事实的推理策略，并直接奖励其遵循事实的行为，从而促进更可靠的思考过程。", "conclusion": "实验结果表明，KnowRL有效地缓解了慢思考模型的幻觉问题，同时保留了其原有的强大推理能力。相关代码已提供下载链接。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10974", "html_url": "https://arxiv.org/abs/2506.10974", "title": "AutoMind: 自适应知识型代理助力自动化数据科学", "title_en": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science", "authors": "Yixin Ou,Yujie Luo,Jingsheng Zheng,Lanning Wei,Zhuoyun Yu,Shuofei Qiao,Jintian Zhang,Da Zheng,Yuren Mao,Yunjun Gao,Huajun Chen,Ningyu Zhang", "background": "大语言模型（LLM）代理在解决现实世界的数据科学问题上展现出巨大的潜力。然而，现有的LLM驱动的数据科学代理框架依赖于刚性的预定义流程和不灵活的编程策略，只能有效应对相对简单的经典问题，而难以捕捉到人类专家在复杂、创新任务中带来的实证经验。现有框架因此在实际应用中的效果有限。", "innovation": "为了克服这些局限，本研究引入了AutoMind框架，通过三个关键进展实现自适应的知识型代理：（1）精心整理的专家知识库，使代理扎根于领域专家知识；（2）代理性知识树搜索算法，战略性地探索可能的解决方案；（3）自适应的编程策略，根据任务复杂性动态调整代码生成。", "conclusion": "在两个自动化数据科学基准测试中的评估表明，AutoMind相对于最先进的基线具有更好的性能。进一步的分析证实了其在效果、效率和质性解决方案质量方面的优越性，使AutoMind成为通向完全自动化的数据科学的一个高效且可靠的步骤。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10098", "html_url": "https://arxiv.org/abs/2506.10098", "title": "使用高斯混合 copula 模型估计场景参数的联合概率", "title_en": "Estimating the Joint Probability of Scenario Parameters with Gaussian Mixture Copula Models", "authors": "Christian Reichenbächer,Philipp Rank,Jochen Hipp,Oliver Bringmann", "background": "在自动驾驶系统安全性验证中，了解场景参数的联合概率分布对于基于场景的安全评估至关重要，因为风险量化依赖于具体参数组合的可能性。传统的高斯混合模型和高斯 copula 模型各有优缺点，不足以同时表达多元模式和灵活处理依赖关系。因此，研究人员希望提出一种新的方法来改善这一问题。本研究首次将高斯混合 copula 模型应用于驱动场景的统计建模，以改善联合概率分布的建模效果。", "innovation": "提出了一种新的统计模型，即高斯混合 copula 模型，整合了高斯混合模型的多元表达能力和 copula 的灵活性。这种方法能够独立建模边际分布和相关性。通过使用来自联合国第157号规定的实际驾驶数据进行基准测试，论证了新方法在联合概率分布建模中的优势，表明与传统的高斯混合模型和高斯 copula 模型相比，新方法在对数似然比和 Sinkhorn 距离方面表现更佳或至少相当时，新型模型具有适用性和优越性。", "conclusion": "实验证明，高斯混合 copula 模型在大约1800万个场景实例中的评价中表现出色，不仅优于高斯 copula 模型，而且至少与高斯混合模型表现持平。研究结果表明，高斯混合 copula 模型可以作为未来基于场景的验证框架的统计基础，具有广阔的应用前景。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22552", "html_url": "https://arxiv.org/abs/2506.22552", "title": "使用简化神经模型探究大规模气候动力学中的强迫响应及因果机制", "title_en": "Probing forced responses and causal mechanisms in large-scale climate dynamics with reduced-order neural models", "authors": "Fabrizio Falasca", "background": "气候科学和应用数学面临的主要挑战之一是开发能够捕捉动力学系统中既定站稳统计特征又能够反映外部干扰响应的数据驱动模型。目前的神经气候模拟器力图解决所有复杂性，但在反映受外部干扰后系统的变化时，往往表现不佳，这限制了它们在因果研究（如格林函数实验）中的应用。响应理论提供了一个严谨的框架，可以超越静态统计的研究，探索因果机制，并指导模型设计。为了探讨低频气候动力学，本文提出使用简化神经模型，这些模型针对特定过程进行了定制，作为通用模拟器的有价值的替代方案。", "innovation": "该研究使用简化神经模型探索大规模气候动力学中的强迫响应和因果机制，提出了依靠响应理论框架评估的新策略。研究表明，简化神经模型不仅可以再现统计特征还能研究受扰动后的响应，如均值和方差，这为研究气候反馈提供了新的视角，由单一轨迹研究转向概率分布响应的研究。这一创新强调了结合现代神经网络和响应理论框架的简化模型在气候变化因果推断研究中的应用潜力。", "conclusion": "简化神经模型与响应理论相结合可以作为因果推断和归属研究的现实策略，特别适用于大型气候动态研究。该研究提出的方法为理解和改进气候模型提供了新的思路，对于推进气候变化科学研究具有重要意义。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02053", "html_url": "https://arxiv.org/abs/2508.02053", "title": "ProCut: 通过归因估计进行LLM提示压缩", "title_en": "ProCut: LLM Prompt Compression via Attribution Estimation", "authors": "Zhentao Xu,Fengyi Li,Albert Chen,Xiaofeng Wang", "background": "在大规模工业LLM系统中，随着团队逐步加入任务说明、少量示例和启发式规则等内容，提示模板往往扩展至数千个token。这导致提示膨胀化，难以维护，同时显著增加了推理延迟和托管成本。", "innovation": "提出了Prompt Compression via Attribution Estimation（ProCut），这是一种灵活的、与LLM无关的、无需训练的框架。ProCut通过归因分析将提示模板划分为语义上有意义的单位，量化它们对任务性能的影响，并删除低效组件。此外，引入了一种基于LLM的归因估计器，以减少压缩延迟超过50%，并展示ProCut能够通过实质性地减少提示大小（生产环境中的token数量减少78%）同时保持或略微提升任务性能（最高比其他方法好62%）。ProCut还可以与现有的提示优化框架无缝集成，生成简洁高效的提示。", "conclusion": "通过广泛实验，展示ProCut在保持或提升任务性能的同时，能够显著减少提示大小，同时减少了压缩延迟，并且能够无缝集成到现有的提示优化框架中。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05306", "html_url": "https://arxiv.org/abs/2507.05306", "title": "在多项逻辑bandits中享受非线性", "title_en": "Enjoying Non-linearity in Multinomial Logistic Bandits", "authors": "Pierre Boudart(SIERRA),Pierre Gaillard(Thoth),Alessandro Rudi(PSL, DI-ENS, Inria)", "background": "论文探讨了多项逻辑bandits问题，这是二元setting的扩展，在这个setting中，学习者通过选择动作来最大化基于多可能结果概率反馈的期望奖励。此前，对于二元setting，研究者已经聚焦于理解逻辑模型非线性的影响(Faury et al., 2020; Abeille et al., 2021)，引入了一个依赖问题常数\textkatyw_*，可能会在某些问题参数上呈指数级增大，该常数由Sigmoid函数的导数捕获，它捕捉了非线性并改进了现有的\textkatyw步长误差保证。", "innovation": "论文将上述分析扩展到多项逻辑bandits框架，适用于具有超过两个选项的复杂应用，例如强化学习或推荐系统。为此，论文扩展了\textkatyw_*的定义，并提出了一种利用该问题的非线性的有效算法。该方法的\textkatyw_*依赖的遗憾界为\textkatywildeO(\frac{R d \textkatywsqrt{\frac{KT}{\textkatyw_*}})}，比现有最佳保证\textkatywildeO(RdK \textkatywsqrt{T}) 更优。此外，论文还提供了\textkatywildeO(\frac{R d \textkatywsqrt{\frac{KT}{\textkatyw_*}})}的下界，证明了该算法的最小最大最优性和\textkatyw_*定义的最优性。", "conclusion": "论文通过研究多项逻辑bandits问题，提出了一种新的算法，改进了遗憾保证，并通过下界分析证明了该算法的最优性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01861", "html_url": "https://arxiv.org/abs/2508.01861", "title": "适应性集群时序张量补全框架（ACT-Tensor）：用于金融数据集补全的张量补全框架", "title_en": "ACT-Tensor: Tensor Completion Framework for Financial Dataset Imputation", "authors": "Junyi Mo,Jiayu Li,Duo Zhang,Elynn Chen", "background": "金融面板数据中的缺失数据是重要的障碍，影响了资产定价模型的有效性和投资策略的实施。这类面板数据往往具有多维特性，涉及公司、时间以及财务变量，增加了插补任务的复杂性。传统的补全方法通常通过削弱数据的多维结构、难以处理异质性缺失模式，或在极端数据稀疏情况下过度拟合，而失败。为了克服这些限制，我们提出了一种适应性、基于集群的时间序列张量补全框架（ACT-Tensor），专门为严重且异质缺失的多维金融面板数据设计。ACT-Tensor通过一个基于集群的完成模块以及一个时间序列平滑模块，能够捕获跨时段的异质性并将短期噪声去除，同时保留缓慢变化的基本趋势。", "innovation": "ACT-Tensor框架包含两大创新点：一个基于集群的完成模块，能够通过学习组特定的潜在结构来捕捉跨时段的异质性；以及一个时间序列平滑模块，可以主动去除短期噪声并保留缓慢变化的基本趋势。广泛的实验结果表明，在不同的缺失数据情况下，ACT-Tensor在补全准确性方面始终优于最先进的基准方法，特别是在极端稀疏数据场景下。", "conclusion": "通过评估ACT-Tensor补全后的数据与为张量结构金融数据设计的资产定价管道的兼容性，结果表明ACT-Tensor不仅可以减少定价错误，还可以显著提高构建的投资组合的风险调整回报。这些结果证明了我们的方法可以提供高度准确和有用的信息，从而对金融决策具有重要价值。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08333", "html_url": "https://arxiv.org/abs/2507.08333", "title": "基于令牌的离散扩散音频填补", "title_en": "Token-based Audio Inpainting via Discrete Diffusion", "authors": "Tali Dror,Iftach Shoham,Moshe Buchris,Oren Gal,Haim Permuter,Gilad Katz,Eliya Nachmani", "background": "音频填补旨在恢复受损录音中的缺失部分。以前基于扩散的方法在缺失区域较大时表现较差。本文介绍了首个将离散扩散应用于预训练音频分词器的令牌化音乐表示的方法，从而实现稳定且语义一致的缺失长时间间隔的恢复。该方法还结合了两种训练方式：基于导数的正则化损失和基于切分的吸收转换，提供了结构化的扩散过程中的损坏。在长度可达750 ms的MusicNet和MAESTRO数据集上进行的实验表明，本文的方法在不同长度的缺失上始终优于强基准模型，特别是在150 ms以上的缺失上。本文推进了音乐音频恢复技术，并为离散扩散模型训练引入了新的研究方向。更多关于本文方法的音频示例可参见this https URL.", "innovation": "首次将离散扩散应用于预训练音频分词器的令牌化音乐表示，引入基于导数的正则化损失和基于切分的吸收转换，实现长期缺失的稳定填补，超越现有强基线方法，在长缺失时表现出色，且在音乐音频恢复领域推进了新的研究方向", "conclusion": "本文方法在多个数据集上表现出色，优于现有强基准，特别是在长缺失方面。还讨论了离散扩散训练的新方向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08833", "html_url": "https://arxiv.org/abs/2508.08833", "title": "数学问题等效变换中大型语言模型鲁棒性的研究：超越传统方法的评估基准", "title_en": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems", "authors": "Yuren Hao,Xiang Wan,ChengXiang Zhai", "background": "本文介绍了一种超越传统方法的系统框架，用于通过在高级数学问题上进行压力测试来评估LLMs的数学推理稳健性。这些高级数学问题在数学上等价，但在语言和参数上有变化。通过这些变换，我们可以测量LLMs对非数学扰动的敏感度，进而更准确地评估其数学推理能力。本研究使用新的评估方法，创建了PutnamGAP基准数据集，包含多个高级数学问题的数学等效变体，以此来评估多种代表性LLM，并检查其稳健性。", "innovation": "本文提出了一种新颖的评估方法，通过在高级数学问题上进行数学等价变换（如语言和参数变化）进行压力测试，来评估LLMs的数学推理稳健性。此外，还创建了一个名为PutnamGAP的新基准数据集，用于评估多种LLM，发现较大模型和较小模型在变体上的性能均有显著下降。", "conclusion": "研究结果表明，所提出的新评估方法有效加深了我们对LLMs稳健性的理解，并为进一步提高其数学推理能力提供了新的见解。在18种商业和开源模型上观察到了显著的性能下降，尤其是参数变化版本，OpenAI的旗舰推理模型O3原版本得分为51.5%，但表面重命名变体下降4.7个百分点，参数变体下降12.9个百分点。总体而言，这些结果证明了新评估方法的有效性。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11711", "html_url": "https://arxiv.org/abs/2508.11711", "title": "使用大型语言模型、句向量变换器和卷积神经网络检测恶意GraphQL查询以增强GraphQL安全性", "title_en": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks", "authors": "Irash Perera(1),Hiranya Abeyrathne(2),Sanjeewa Malalgoda(2),Arshardh Ifthikar(2) ((1) Department of Computer Science and Engineering, University of Moratuwa, Colombo, Sri Lanka, (2) WSO2, Colombo, Sri Lanka)", "background": "GraphQL因其灵活性而有助于高效数据获取，但这种特性也会引入独特的安全漏洞。传统API安全机制往往无法应对这些挑战，恶意的GraphQL查询可以利用语言的动态特性进行拒绝服务攻击、数据泄露等攻击。现有的解决方案，如静态分析、速率限制和通用Web应用防火墙，对复杂的、基于上下文的攻击提供的保护有限。", "innovation": "本文提出了一种新颖的AI驱动的实时检测恶意GraphQL查询的方法。该方法结合了静态分析与机器学习技术，包括使用大规模语言模型（LLMs）进行动态模式配置，使用句向量变换器（如SBERT和Doc2Vec）进行查询负载的上下文嵌入，以及使用卷积神经网络（CNN）、随机森林和多层感知器进行分类。此外，还详细描述了系统架构、针对生产环境的实施策略（包括ONNX Runtime优化和并行处理），并评估了检测模型在负载下的性能，结果表明该方法能够准确地检测SQL注入、OS命令注入和XSS攻击，同时有效地抵御拒绝服务和SSRF攻击尝试。", "conclusion": "本文提出了一种强大的且适应性强的解决方案，用于增强GraphQL API的安全性。通过结合静态分析与机器学习技术，该方案能够有效地检测和抵御恶意的GraphQL查询带来的各种威胁。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14003", "html_url": "https://arxiv.org/abs/2508.14003", "title": "机器学习H定理", "title_en": "Machine Learning H-theorem", "authors": "Ruben Lier", "background": "H定理为热力学第二定律提供了微观基础，因此是建立统计物理的重要基石。然而，H定理也因其是否真正确保了不可逆性而受到争议。为了更好地理解H定理及其与时间箭头的关系，作者研究了随机取向和位置的周期边界条件下硬圆盘的平衡过程，利用DeepSets架构建立的模型以确保粒子标签的置换不变性，来训练模型捕捉H函数值的不可逆性。", "innovation": "引入了基于DeepSets架构的模型来研究系统的不可逆性，强调了模型的置换不变性特性。这种方法为理解H定理提供了新的视角，有助于深入探讨统计物理中的不可逆过程与时间箭头的关系。", "conclusion": "通过这项研究，论文展示了利用机器学习方法研究H定理新的可能性，同时进一步揭示了H定理的本质及其在统计物理中的应用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12658", "html_url": "https://arxiv.org/abs/2509.12658", "title": "可持续LSTM基预编码方法在RIS辅助毫米波MIMO系统中的隐式CSI应用", "title_en": "Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI", "authors": "Po-Heng Chou,Jiun-Jia Wu,Wan-Jen Huang,Ronald Y. Chang", "background": "本文探讨了如何利用可重构智能表面（RIS）辅助毫米波（mmWave）MIMO系统，以可持续的方式进行预编码设计，特别是在不做显式信道状态信息（CSI）估计的情况下，通过上行导频序列隐式学习信道特性，降低导频开销和推断复杂度。", "innovation": "提出了一种基于LSTM的预编码框架，通过隐式学习信道特性，减少导频开销和推断复杂度。结合了RIS元件的相位依赖幅度模型，并采用多标签训练策略以提高鲁棒性。实验结果表明，该设计仅需穷举搜索时间的2.2%就能达到90%的频谱效率，大幅降低了能耗。", "conclusion": "该方法展现了在分布不匹配情况下的鲁棒性，并具有向更大规模RIS阵列扩展的潜力，是6G无线网络中实用且高效的解决方案。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09621", "html_url": "https://arxiv.org/abs/2508.09621", "title": "基于结构化行为树和大型语言模型的可解释机器人控制", "title_en": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models", "authors": "Ingrid Maéva Chekam,Ines Pastor-Martinez,Ali Tourani,Jose Andres Millan-Romera,Laura Ribeiro,Pedro Miguel Bastos Soares,Holger Voos,Jose Luis Sanchez-Lopez", "background": "随着智能机器人越来越多地融入人类生活环境中，人们需要开发出一种直观且可靠的机器人与人类交互（HRI）接口，这种接口需要具有更高的适应性和自然交互性。传统的人形机器人控制方法往往需要用户适应界面或记忆预先定义的命令，这在动态、非结构化的环境中限制了其易用性。", "innovation": "本文提出了一种新的框架，将大型语言模型（LLMs）与行为树结合，实现自然语言理解和机器人执行的桥梁。这种集成使得机器人可以理解和执行用户的自然语言指令，并通过特定域的插件激活可执行的动作。该系统支持可扩展和模块化的集成，主要集中在基于感知的功能，如人体跟踪和手势识别。", "conclusion": "通过在不同环境中的实际实验，证明了所提出的方法在现实场景中具有可行性，平均认知到执行的准确性约为94%，对HRI系统和机器人的发展做出重大贡献。完整的框架源代码可以在指定的网址上获得。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23385", "html_url": "https://arxiv.org/abs/2509.23385", "title": "Flow Matching for Robust Simulation-Based Inference under Model Misspecification", "title_en": "Flow Matching for Robust Simulation-Based Inference under Model Misspecification", "authors": "Pierre-Louis Ruhlmann,Pedro L. C. Rodrigues,Michael Arbel,Florence Forbes", "background": "Simulation-based inference (SBI)通过模拟数据正在改变实验科学，特别是在复杂非线性模型中进行参数估计方面。然而，模型错构是一个持续存在的挑战：模拟器仅仅是现实世界的近似，模拟数据与实际数据之间的不匹配可能导致有偏或过度自信的后验分布。", "innovation": "该论文提出了一种称为Flow Matching Corrected Posterior Estimation (FMCPE)的新框架，利用流匹配范式矫正由少量真实校准样本支持的由模拟训练的后验估算器的预测，从而在不需要明确知道错构的情况下将其预测向真实的后验分布进行转变。此设计允许FMCPE结合SBI的大规模特性的同时，具备对分布变化的鲁棒性。", "conclusion": "在合成基准和真实数据集上的实验证明，此提出的方法能够一致地减轻模型不适配的影响，相比于标准SBI基线，提供了更好的推断精度和不确定性校准，同时保持计算效率。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15257", "html_url": "https://arxiv.org/abs/2509.15257", "title": "RespoDiff: 双模块瓶颈变换以实现负责任且忠实的文本到图像生成", "title_en": "RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation", "authors": "Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta", "background": "扩散模型的发展速度加快了高保真度和富有语义内容的文本到图像生成；然而，确保公平性和安全性仍然是一个开放的挑战。现有的方法通常在提高公平性和安全性的同时，以牺牲语义保真度和图像质量为代价。", "innovation": "我们提出了一种新颖的框架RespoDiff，它结合了扩散模型中间瓶颈表示的双重模块变换。我们的方法引入了两个可学习模块：一个专注于捕捉和应用负责任的概念，如公平性和安全性；另一个致力于保持与中立提示的语义一致性。为了促进双学习过程，我们引入了一种新颖的分数匹配目标，该目标能够使模块之间有效地协同工作。我们的方法在负责任生成方面优于最先进的方法，通过同时优化两个目标来确保语义对齐，同时不牺牲图像保真度。我们的方法在不同未知提示上提高了负责任且语义一致生成的20%。此外，该方法可以无缝集成到大型模型如SDXL中，增强公平性和安全性。", "conclusion": "我们的方法在保障负责任和语义一致性生成方面显著提升，与现有领先的方法相比，优化了公平性和安全性，并提高了20%。该方法在不同前缀上表现优异，并能够与大规模模型如SDXL无缝集成。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22970", "html_url": "https://arxiv.org/abs/2509.22970", "title": "机器人从任意图像学习", "title_en": "Robot Learning from Any Images", "authors": "Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang", "background": "当前的机器人训练方法通常需要额外的硬件、数字资产甚至专业的物理仿真环境，这对数据生成和机器人学习带来了诸多限制，特别是在大规模和多样化的数据生成方面存在挑战。该论文介绍了一种名为RoLA的框架，该框架能够将任意图片转换为能与物理模拟相结合的互动式机器人环境。这个框架能够在几分钟内从各种图像来源（包括相机捕获、机器人数据集和网络图像）生成大规模且多样化的视觉和运动机器人演示，从而打破了传统的机器人数据生成壁垒，使得机器人训练更加平民化和快速化。", "innovation": "RoLA框架的创新在于它可以直接在单个图像上操作，而无需任何额外的硬件或数字资产支持。该框架的核心在于结合了一种新颖的单视角物理场景恢复方法和高效的视觉融合策略，实现了快速、真实的视觉数据收集，并能够在多种场景中验证其有效性，包括可扩展的机器人数据生成与扩充、从网络图像学习机器人、以及实际图像到模拟器再回到现实的系统，适用于附属机构和类人机器人的动态控制。", "conclusion": "RoLA通过提高机器人训练的效率和多样性，极大程度上改变了现有的机器人数据生成方式，展现了机器人学习的新可能。这一框架不仅大幅降低了机器人训练的门槛，还展示了其在实际应用中的潜力，特别是对于那些依赖于真实世界数据的机器人来说，RoLA能够提供更为高效和接近真实的训练环境。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00264", "html_url": "https://arxiv.org/abs/2510.00264", "title": "2025低资源音频编解码挑战的基准系统", "title_en": "Baseline Systems For The 2025 Low-Resource Audio Codec Challenge", "authors": "Yusuf Ziya Isik,Rafał Łaganowski", "background": "低资源音频编解码（LRAC）挑战旨在推进神经音频编码技术，以适应资源受限的环境。第一版专注于低资源神经语音编解码器，它需要在日常噪声和混响条件下可靠运行，同时还必须满足计算复杂性、延迟和比特率的严格限制。", "innovation": "本文介绍了2025年低资源音频编解码挑战中两个赛道的官方基准系统，这些系统是结合了生成对抗和重建目标的端到端训练的卷积神经编解码器模型，带有残差矢量量化。详细描述了数据过滤和增强策略、模型架构、优化过程和检查点选择标准。", "conclusion": "介绍了两个赛道的基准系统的细节，包括训练方法、模型架构和评估标准，为低资源环境下的音频编解码提供了参考实现。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL: 融合视觉与文本的少样本学习框架", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少样本学习（FSL）旨在仅从少量标记的支持样本中识别新概念。近期研究通过整合额外的语义信息或设计复杂的语义融合模块来增强支持特征。然而，这些方法仍然受到由于缺乏实际实例的语义定位，导致生成出与视觉证据相矛盾的语义，从而产生嘈杂的指导和昂贵的修正的问题。", "innovation": "本文提出了一种新的框架VT-FSL（Vision and Text with LLMs for Few-Shot Learning），该框架结合了大型语言模型（LLMs）、支持图像并通过几何感知对齐，无缝集成这些元素。主要组成部分包括跨模态迭代提示（CIP）和跨模态几何对齐（CGA）。CIP使LLMs同时在类别名称和支持图像上进行迭代推理生成精确的类别描述。CGA则通过最小化它们所跨越的三维平行六面体的核体积，联合对齐融合的文本、支持和合成视觉表示，捕捉所有表示间的全局和非线性关系，实现结构化的多模态集成。该方法在十个不同的基准测试中均取得了新SOTA性能。", "conclusion": "提出的VT-FSL方法在包括标准、跨域和细粒度少样本学习场景中均取得了新的最先进性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18665", "html_url": "https://arxiv.org/abs/2508.18665", "title": "LLM 基础的推荐系统中的成员推断攻击", "title_en": "Membership Inference Attacks on LLM-based Recommender Systems", "authors": "Jiajie He,Yuechun Gu,Min-Chun Chen,Keke Chen", "background": "基于大规模语言模型（LLMs）的推荐系统（RecSys）能够灵活适应不同的领域。这些系统利用上下文学习（ICL），即通过提示来定制推荐功能，包括敏感的历史用户特定项目交互，比如隐式反馈如点击的项目，或明确的产品评价。然而，这些私有信息可能会受到新的隐私攻击。此前没有研究关注这个问题。该研究设计了四种成员推断攻击（MIAs），旨在揭示系统提示是否使用了受害者的部分历史互动。这四种攻击分别为直接询问攻击、幻觉攻击、相似性攻击和污染攻击，每种攻击都利用了LLMs或RecSys的独特特点。研究在三种被用于开发ICL-LLM RecSys的LLM以及两个主流的RecSys基准数据集上进行了仔细评估。实验结果表明，LLM RecSys的MIA威胁是切实可行的：直接询问攻击和污染攻击显示出显著高的攻击优势。此外，还分析了影响这些攻击的因素，例如系统提示中的样本次数以及受害者的样本位置等。", "innovation": "该研究首次系统地探讨了基于LLMs的RecSys中的成员推断攻击问题。设计了四种具有针对性的推断攻击方法，并在多个基准数据集上进行了实证研究，证实了这些攻击的有效性与风险。此研究为深入理解LLMs及其在推荐系统中的应用带来了新的视角，并可能为未来设计更安全的推荐系统提供重要基础。", "conclusion": "实验证明基于LLMs的RecSys确实存在显著的成员推断攻击风险，特别是直接询问和污染攻击表现出较高的攻击优势。影响这些攻击效果的主要因素包括系统提示中的样本次数和受害者在样本中的位置。这项工作具有重要的理论和实践意义，为未来研究和实际应用提供了有价值的参考。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03122", "html_url": "https://arxiv.org/abs/2509.03122", "title": "从注入到防护：为大规模语言模型构建基于编辑的指纹", "title_en": "From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Linlin Wang", "background": "指纹技术对于保持可追溯性并保护开发者的知识产权至关重要，尤其是在通过微调或不透明部署的方式将LLM部署在Web应用程序中时，LLM容易被未经授权的重新分发和滥用。然而，当前基于后门的指纹方法会面临一个基本的权衡：嵌入的虚假文本指纹容易被检测和过滤，而构造的自然语言指纹则容易无意间触发。为解决这些局限，我们提出了一种知识编辑框架RFEdit，它通过修改模型权重的一小部分来嵌入基于规则的多语言自然语言指纹(MNLF)。这种方法使得可以高效且稳健地注入指纹，同时对与指纹无关的知识影响最小。为了加强RFEdit框架，我们进一步引入了感知指纹子空间微调(FSFT)技术，它在合法微调过程中通过限制参数更新到指纹子空间，来防止指纹退化。从而在保持指纹完整的同时提高了LLM的下游任务性能。这些创新性强化措施形成了从指纹注入到防护的完整管道，实现了高度的检测效果、对抗操纵的稳健性、对模型效用的无害性和在微调下的持久性。广泛的实验表明，RFEdit在量化和剪枝下的鲁棒性保持得很好，并且当与FSFT结合使用时，数学和Alpaca下游任务中的指纹效果通常改善了超过10%。", "innovation": "RFEdit框架和FSFT技术。RFEdit通过修改模型权重的一小部分来嵌入基于规则的多语言自然语言指纹，使得高效、稳健地注入指纹而不影响非相关知识。FSFT则通过限制参数更新到指纹子空间，防止指纹退化，同时提高任务性能和防护效果。", "conclusion": "RFEdit与FSFT构成了一个全面的管道，从指纹注入到防护，实现了高度检测效果、对抗操纵稳定性、对模型效用无害性以及在微调下的持久性。实验表明，RFEdit在量化和修剪下的鲁棒性良好，与FSFT结合使用时，吞吐量任务下的指纹效果提升了超过10%。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03993", "html_url": "https://arxiv.org/abs/2510.03993", "title": "Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning", "title_en": "Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning", "authors": "Yaxin Hou,Bo Han,Yuheng Jia,Hui Liu,Junhui Hou", "background": "当前长期尾部半监督学习方法假设标记数据呈现长期尾部分布，而未标记数据遵循一个典型预设的分布（即长期尾部、均匀或倒长期尾部）。然而，未标记数据的真实分布通常是未知的，且可能遵循任意分布。现有方法在处理这种未知分布的挑战时存在局限性。", "innovation": "提出了一个可控伪标签生成（CPG）框架，该框架通过一个可控自我增强的优化循环逐步将可靠的伪标签从未标记数据集引入到标记数据集中，并在已知分布的更新后的标记数据集上进行模型训练，使模型得以不受未标注数据集分布的影响。CPG具有一系列创新特点，包括动态可控筛选机制、贝叶斯最优分类器以及基于更新标记数据分布的logit调整等。", "conclusion": "CPG框架在多个常用基准数据集上进行了全面评估，展示了相较于现有顶级方法的显著改进，准确率提升高达15.97%。此外，CPG还通过一个类感知自适应增强模块进一步改善了少数类的表示，并利用辅助分支最大限度地利用所有标记和未标记样本。相关的代码已公开可用。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03511", "html_url": "https://arxiv.org/abs/2510.03511", "title": "Platonic Transformers: 一种用于同变性的坚固选择", "title_en": "Platonic Transformers: A Solid Choice For Equivariance", "authors": "Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers", "background": "虽然自注意力机制在各种任务中非常有效，但现有的Transformer缺乏处理科学和计算机视觉中常见的几何对称性的诱导偏置。目前的同变方法通常会牺牲Transformer的高效性和灵活性，通过复杂且计算密集的设计来实现同变性。", "innovation": "我们提出Platonic Transformer来解决这一权衡。通过以柏拉图固体对称群为参考框架定义自注意力，该方法诱导出一种原则性的权重共享方案。它实现了连续平移和柏拉图对称性的同变性，同时保持了标准Transformer的精确架构和计算成本。此外，我们表明这种注意力等价于动态群卷积，从而揭示模型学习自适应几何滤波器，并能实现高度可扩展的线性时间卷积变体。", "conclusion": "在计算机视觉（CIFAR-10）、3D点云（ScanObjectNN）和分子性质预测（QM9、OMol25）等不同基准测试中，Platonic Transformer通过利用这些几何约束实现了与标准Transformer相同甚至更好的性能。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识坍塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度一致的文字内容。这可能导致知识坍塌，即通过LLMs传达的信息范围逐渐缩小。现有关于同质化的研究集中在封闭式多项选择问答或模糊语义特征上，并未考虑时间趋势和文化背景。针对这一问题，本研究提出了一种新的方法，用于量化和研究LLMs输出中的认识论多样性，即实际世界声明的多样性，并进行了广泛的经验研究来探讨LLMs的知识坍塌。", "innovation": "本研究引入了一种新的方法来量化大型语言模型中的认识论多样性，重点关注各种LLMs在不同时间点和文化背景下的表现。通过测试27种LLMs，涵盖12个国家的155个主题和200种真实的用户提示，研究发现，尽管新模型生成的多样声明更多，但几乎所有模型的多样性都不如基本网页搜索。研究还发现，模型规模对认识论多样性有负面影响，而检索增强生成（RAG）技术则有正面影响，但这种提高在不同文化背景下有所差异。此外，本研究对比传统知识来源（维基百科），发现国别声明更多倾向于反映英语而非本地语言，揭示了认识论表示方面的差距。", "conclusion": "本研究通过测试多种LLMs和广泛的主题，显示了认识论多样性的现状，并探讨了不同因素对这一特征的影响。研究结果强调，尽管新模型在生成多样化声明方面有所进步，但LLMs的整体知识多样性仍然较低。研究还揭示了文化因素和技术方法对模型多样性的影响，提出了未来研究和应用的潜在方向。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04591", "html_url": "https://arxiv.org/abs/2510.04591", "title": "基于物理感知神经网络的数据驱动自适应PID控制", "title_en": "Data-Driven Adaptive PID Control Based on Physics-Informed Neural Networks", "authors": "Junsei Ito,Yasuaki Wasa", "background": "本文提出了一种基于自适应增益优化原理的数据驱动PID控制器设计，利用了为预测建模生成的物理感知神经网络（PINNs）。传统PID控制中，增益的固定设置可能会因系统非线性而导致系统不稳定。因此，需要一种能够适应系统变化、确保系统稳定性的自适应PID控制方法。本文通过利用PINNs的梯度实现PID增益的自动微分，引入了一种新的模型预测控制方法。这种方法不仅可以确保系统的稳定性，还能考虑系统非线性特性。", "innovation": "本文的创新之处在于提出了一种基于物理感知神经网络的数据驱动自适应PID控制方法。该方法通过利用PINNs的梯度，自动微分PID增益以实现自适应调优。这种方法可以有效适应非线性系统变化，同时确保系统的稳定性，为PID控制器的自适应控制提供了系统化的框架。", "conclusion": "通过一系列数值实验，本文从时间和频率域的角度验证了提出的自适应PID控制方法的有效性。该方法提供了一种将基于PINNs的动态控制系统模型直接整合到闭环控制系统中的系统化框架，可以直接应用于PID控制器的设计中。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05070", "html_url": "https://arxiv.org/abs/2510.05070", "title": "ResMimic：从通用运动跟踪到通过残差学习实现类人全身体操与操作", "title_en": "ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning", "authors": "Siheng Zhao,Yanjie Ze,Yue Wang,C. Karen Liu,Pieter Abbeel,Guanya Shi,Rocky Duan", "background": "类人机器人在日程服务和仓库任务中展现了革命性的能力。近期在通用运动跟踪（GMT）方面的进展使得类人机器人能够再现多样的人类动作。然而，这些策略在精确性和物体意识方面仍存在不足，无法满足全身体操与操作的需求。", "innovation": "本文引入了ResMimic，这是一种两阶段残差学习框架，用于从人类运动数据中实现精确且富有表现力的类人控制。第一阶段使用大型人类唯一动作训练的GMT策略作为通用任务基础，产生类人体全动动作。第二阶段则学习高效的残差策略以改进动作并融入物体互动。此外，还设计了点云基物体跟踪奖励、接触奖励以及基于课程的虚拟物体控制器来优化早期训练。", "conclusion": "实验证明，ResMimic在任务成功率、训练效率和鲁棒性方面超越了强大基线。研究成果在模拟和一个真实的Unitree G1人形机器人上进行了评估，显示出显著的优势。相关视频可在以下网址找到：this https URL。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04042", "html_url": "https://arxiv.org/abs/2510.04042", "title": "通过望远镜比率估计进行数据生成模型的仿真推理对拖网过程", "title_en": "Simulation-based inference via telescoping ratio estimation for trawl processes", "authors": "Dan Leonte,Raphaël Huser,Almut E. D. Veraart", "background": "随着大型复杂数据集的日益普及，人们更加关注能够捕捉边际偏斜、非高斯尾部、长记忆甚至非马尔可夫行为等特征的时间随机过程。尽管这些模型易于模拟，但参数估计仍然具有挑战性。基于仿真的推理（SBI）提供了一种前进的方法，但现有方法通常需要大规模训练数据集或复杂架构，并且经常导致未能达到名义值的置信（可信任）区域，这使得这些模型的估计结果值得怀疑。本文的研究背景便是解决这些挑战，特别是在不易计算的随机过程中的快速且准确的样本效率SBI框架。", "innovation": "本文提出了一种快速且准确、样本效率导向的SBI框架，适用于不可计算的时间随机过程。这种方法分为两个步骤：首先，通过顺序分解后验密度并在参数维度中学习，然后使用切比雪夫多项式逼近以高效生成独立的后验样本，从而即使在马尔可夫链蒙特卡洛方法混杂不佳的情况下也能实现准确推理。此外，还开发了针对SBI上下文的新型诊断工具以及后处理校准技术，这些技术不仅提高了所学习的推理工具的表现，还使其能够直接重复使用于具有不同长度的新时间序列，从而减轻训练成本。", "conclusion": "该方法在应用于拖网过程时被证明是有效的，拖网过程是一种灵活的无穷可分模型，扩展了单变量正态过程，并在能源需求数据中的应用也得到了验证。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05858", "html_url": "https://arxiv.org/abs/2510.05858", "title": "领域适应连续预训练的大型语言模型在电话会议摘要中的应用", "title_en": "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization", "authors": "Xue-Yong Fu,Elena Khasanova,Md Tahmid Rahman Laskar,Harsh Saini,Shashi Bhushan TN", "background": "大型语言模型（LLMs）在文本总结方面取得了显著的性能，但在应用于与原始预训练分布不同的专业领域时，其性能往往不尽如人意。尽管微调可以改善总结质量，但通常依赖于昂贵且稀缺的高质量标记数据。本研究探索连续预训练作为一种可扩展、自我监督的方法，以适应LLMs在下游总结任务中的应用，特别是在嘈杂的现实世界对话转录环境中。", "innovation": "研究采用大规模无标记的企业对话数据进行实验，以调查持续预训练是否能够增强模型在对话总结方面的性能。结果表明，连续预训练在领域内和跨领域的总结基准测试中都取得了显著的提升，同时保持了良好的泛化能力和鲁棒性。此外，还分析了数据选择策略的影响，为总结聚焦的工业应用提供了实用指南。", "conclusion": "连续预训练在大型语言模型的对话总结应用中表现出色，尤其是在噪声环境下的对话数据。这种方法不仅提高了模型在特定领域的总结能力，还增强了模型的一般性和鲁棒性，为工业应用提供了实用指导。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06363", "html_url": "https://arxiv.org/abs/2510.06363", "title": "通过Git启用系统改进高等教育作业提交：一项迭代案例研究", "title_en": "Improving Assignment Submission in Higher Education through a Git-Enabled System: An Iterative Case Study", "authors": "Ololade Babatunde,Tomisin Ayodabo,Raqibul Raqibul", "background": "传统高等教育中的作业提交方法存在诸多挑战，例如跟踪作业和协作效率低下以及提交流程繁琐。为了改善这些问题，本文介绍了并评估了一个基于Git的定制提交系统。", "innovation": "本文通过迭代软件开发方法和用户为中心的设计方法，开发了一种基于Git的提交系统，并将其集成到真实的大学环境中。该研究还通过实证评估（包括可用性测试和学生反馈）表明，与传统方法相比，基于Git的方法提高了作业跟踪效率，并减少了提交和评估所需的时间和存储需求，学生对此表示了积极的反馈。", "conclusion": "基于研究结果，作者发现85%的教师认为基于Git的系统使用更简便，84%的学生更偏好于这种方法，因为基于Git的方法将提交和审核时间减少了38%，并将存储需求减少了48%。该研究为集成分布式版本控制系统提供了一定的实用见解，有助于提高教师监督和学生参与度，特别是在软件工程等领域中。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06343", "html_url": "https://arxiv.org/abs/2510.06343", "title": "利用大型语言模型进行网络安全风险评估：林业网络物理系统的案例研究", "title_en": "Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems", "authors": "Fikret Mert Gültekin,Oscar Lilja,Ranim Khojah,Rebekka Wohlrab,Marvin Damschen,Mazen Mohamad", "background": "在关键安全软件系统中，网络安全活动变得至关重要，风险评估是其中最核心的部分之一。许多软件团队缺少网络安全专家，或者只有少数专家，这使得网络安全专家的工作负担加重，迫使软件工程师自己进行网络安全活动。因此，需要一种工具来支持网络安全专家和工程师在风险评估过程中评估漏洞和威胁。这一研究探索了利用本地大型语言模型（LLMs）与检索增强生成技术支持林业网络物理系统的网络安全风险评估的可能性，同时遵守限制外部数据共享的数据保护和隐私要求。", "innovation": "研究涉及12名林业专家的访谈、互动会议和大规模项目调查的设计科学研究，展示了大型语言模型能够通过生成初步风险评估、识别威胁和提供冗余检查来协助网络安全专家。研究还强调了人类监督的重要性，以确保准确性和合规性。尽管存在信任问题，专家们也愿意在特定评估和支持角色中使用Large Language Models，而不仅仅依赖其生成能力。", "conclusion": "这项研究提供了利用基于大型语言模型的代理来支持网络安全物理系统在关键安全领域的风险评估过程的洞察。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05396", "html_url": "https://arxiv.org/abs/2510.05396", "title": "使用生成模型实现可扩展的上下文相关排名", "title_en": "Scalable In-context Ranking with Generative Models", "authors": "Nilesh Gupta,Chong You,Srinadh Bhojanapalli,Sanjiv Kumar,Inderjit Dhillon,Felix Yu", "background": "在上下文相关排名（ICR）这一新兴的信息检索范式中，通过直接将任务描述、候选文档和查询整合到模型输入提示中，利用大型语言模型（LLM）对上下文的理解来识别相关的文档。尽管这种做法有效，但在候选列表增长时，由于注意力操作随上下文长度非线性增长，效率成为一个显著挑战。本文首先识别出适配和可利用的LLM为ICR微调后的注意力操作中的内在结构：文档块间的稀疏性和查询文档块的相关性。", "innovation": "该研究介绍了BlockRank方法，以架构性的途径强制执行观察到的文档块间稀疏性，将注意力操作的复杂度从二次降低到线性，同时保持性能。此外，还在微调过程中利用辅助对比训练目标优化了查询文档块相关性，以提高注意力中的检索效果。实验结果表明，BlockRank Mistral在MSMarco和NQ上的表现优于现有的SOTA列表排名器和控制微调基线，同时在推理效率上表现更加优秀，并且能够平滑地扩展到长上下文短列表，接近100,000上下文长度的500份文档。", "conclusion": "BlockRank提供了一个可扩展且有效的解决方案，用于ICR，能够在保证性能的同时显著提高效率，解决候选列表增长时的效率问题。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06718", "html_url": "https://arxiv.org/abs/2510.06718", "title": "大型语言模型公司政策及其在软件组织中的政策含义", "title_en": "LLM Company Policies and Policy Implications in Software Organizations", "authors": "Ranim Khojah,Mazen Mohamad,Linda Erlenhov,Francisco Gomes de Oliveira Neto,Philipp Leitner", "background": "在软件组织中采用大型语言模型（LLM）聊天机器人存在一定的风险，这凸显了制定清晰的政策的重要性。本文通过研究11家公司的政策制定过程以及影响这些政策的因素，旨在帮助管理层安全地将聊天机器人融入开发流程。", "innovation": "本文创新性地研究了不同软件组织在采用大型语言模型聊天机器人时制定的政策，并分析了影响这些政策的关键因素。", "conclusion": "研究结果为管理者在软件开发中安全地集成聊天机器人提供了政策制定的参考，并且有助于降低使用大型语言模型聊天机器人所面临的潜在风险。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06483", "html_url": "https://arxiv.org/abs/2510.06483", "title": "使用模型驱动工程解决视力障碍问题：一项系统文献综述", "title_en": "Addressing Visual Impairments with Model-Driven Engineering: A Systematic Literature Review", "authors": "Judith Michael,Lukas Netz,Bernhard Rumpe,Ingo Müller,John Grundy,Shavindra Wickramathilaka,Hourieh Khalajzadeh", "background": "软件应用常常为无障碍需求的用户（例如，视力障碍者）设置障碍。模型驱动工程（MDE）通过其系统性的代码生成方法，可以系统地将无障碍问题整合到软件开发中，同时减少手动工作量。本文通过系统文献综述，探讨了MDE在解决视力障碍方面的应用。", "innovation": "从447篇初始论文中筛选出30篇主要研究，这些研究主要关注Web内容无障碍指南（WCAG），但许多研究项目的具体调整和用户验证阻碍了MDE的广泛应用。研究发现MDE在建模用户界面结构、交互与导航、用户能力、需求及环境信息方面有重要作用，但仅少数研究提供了具体的技术来整合无障碍需求或展示了功能完善的系统。不足的细节致使MDE方法的再利用、通用性和再现性受限，这在很大程度上限制了视力障碍者的无障碍软件开发。", "conclusion": "目前的MDE研究在支持视力相关的无障碍方面是不够的，因此，本文提出了关于如何更有效地将视力障碍问题融入MDE过程的研究议程。"}
{"llm_update_time": "20251009", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05786", "html_url": "https://arxiv.org/abs/2510.05786", "title": "加权有向无环多重图上向量值函数的莫比乌斯变换和沙普利值", "title_en": "Möbius transforms and Shapley values for vector-valued functions on weighted directed acyclic multigraphs", "authors": "Patrick Forré,Abel Jansma", "background": "本文介绍了广义莫比乌斯逆和沙普利值的概念，将其应用到加权有向无环多重图（DAG）及其变体上。进一步允许这些值的功能（博弈）以及它们的莫比乌斯变换（协同功能）和沙普利值取值于任何包含该图权重的环上的阿贝尔群，例如向量值函数。在实现这一点并克服经典公理（线性、效率、无角色性、对称性）不足以在更广泛的情境下唯一确定沙普利值的障碍后，作者从两个新的角度分析了沙普利值：引入投影运算符使沙普利值能够递归地将高阶协同效应投影重新分配给低阶协同效应；提议加强无角色公理和局部对称公理，具体来说，是弱元素和扁平层级公理。", "innovation": "引入新的投影运算符和相关公理，这些概念能够递归地将高阶协同效应投影重新分配给低阶协同效应；立方形并统一处理层级结构扁平时玩家联盟的特定情况。这些公理不仅推导出沙普利值的唯一明确公式，而且还增强了经典属性如线性、无角色性、对称性，并引入了新的属性如投影特性。这项框架还适用于有限包含代数、格、偏序集和部分系统，恢复了一些已知的案例并以新的视角呈现了其他案例。还分析了允许具有权重的有向无环多重图结构的层次体系，并引入了向量值沙普利值，这为新的分析工具和应用领域提供了可能性，如机器学习、语言处理和可解释的人工智能等。", "conclusion": "本文框架的实现和运用已经推导出沙普利值的独特明确公式，并且其独有的新属性与经典性质相结合，如效率、无角色性、对称性和投影性质，使多党博弈的概念有了更广泛的应用场景，如金融机构、机器学习、数据科学等众多领域。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06844", "html_url": "https://arxiv.org/abs/2510.06844", "title": "Oops!...我再做一次。定量 empiricism 软件工程结论的不稳定性：大规模分析", "title_en": "Oops!... I did it again. Conclusion (In-)Stability in Quantitative Empirical Software Engineering: A Large-Scale Analysis", "authors": "Nicole Hoess,Carlos Paradis,Rick Kazman,Wolfgang Mauerer", "background": "软件仓库分析是了解软件项目发展、监控项目健康状况、辅助决策和提炼最佳实践的流行手段。支持这一过程的工具常被研究者和从业者使用，但由于工具的局限性和一致性问题往往未被充分理解，这成为了一个研究关注点。", "innovation": "本研究通过文献回顾选择三个高排名场景区的案例研究，并使用四个独立系统选择的抽样工具进行正式复制，以定量和定性比较提取的数据、分析结果和结论，揭示复杂工具流水线中的有效性的威胁，并评估工具间的数据、研究结果和结论的一致性。", "conclusion": "在复杂工具流水线中，多种技术细节会在数据提取、衍生数据、统计分析结果以及在特定情况下对结论产生影响。因此，用户在选择工具时应谨慎评估有效性的范围，推荐复用工具。研究者和工具开发者可以借助重用包和遵循我们的比较研究方法来减少不确定性。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06606", "html_url": "https://arxiv.org/abs/2510.06606", "title": "超越更多上下文：粒度和顺序如何驱动代码补全质量", "title_en": "Beyond More Context: How Granularity and Order Drive Code Completion Quality", "authors": "Uswat Yusuf,Genevieve Caumartin,Diego Elias Costa", "background": "代码完成的质量在很大程度上取决于上下文，因为大型语言模型（LLMs）需要足够的相关信息来帮助开发人员在代码生成任务中。然而，在大型仓库中构建相关上下文存在挑战：首先，LLMs 的上下文长度有限，使其无法包含所有仓库文件；其次，生成的代码质量对噪声或无关信息的上下文非常敏感。因此，针对这些挑战，本文介绍了一种方法来应对ASE 2025上下文收集挑战，旨在通过设计有效的检索和上下文收集策略超越JetBrains基线。", "innovation": "本文的研究重点在于对文件和片段级别的检索策略进行实验，特别关注上下文大小和文件排序对LLM性能的影响。引入了基于静态分析的片段检索，取得了显著的改进：相较于最佳文件检索策略，提高了6%；相较于无上下文基线，提高了16%（对于Python代码）。结果突显了检索粒度、排序和混合策略在实际开发场景下有效上下文收集管道开发中的重要性。", "conclusion": "研究表明，上下文的数量和顺序对模型性能的影响重大。基于片段检索策略优于基于文件的检索，能够显著提升代码补全质量。进一步证实了需要优化检索粒度、排序和联合策略来改善真实场景中的代码补全任务性能。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06708", "html_url": "https://arxiv.org/abs/2510.06708", "title": "AISysRev - 基于LLM的题要筛选工具", "title_en": "AISysRev - LLM-based Tool for Title-abstract Screening", "authors": "Aleksi Huotala,Miikka Kuutila,Olli-Pekka Turtio,Mika Mäntylä", "background": "系统综述是软件工程中汇总现有证据的标准做法。然而，在筛选或研究选择阶段，面对大量文献时，这一过程非常耗费人力。论文标题和摘要的筛选尤为耗时。近期研究表明，大型语言模型（LLMs）能够进行与研究生水平相当的题要筛选。虽然LLMs不能完全信赖，但它们可以辅助加速审查流程。", "innovation": "作者基于现有研究成果开发了AiSysRev，这是一个基于LLM的筛选工具，以Web应用形式运行在Docker容器中。该工具接受包含论文题要的CSV文件，用户指定筛选标准，并可通过OpenRouter使用多个LLM进行筛选。AiSysRev支持零样本和少量样本筛选，并允许通过界面显示LLM结果作为人类筛查的指导。研究者进行了一次使用该工具的试用研究，结果显示论文可以被分类为四种类型：易筛选包含、易筛选排除、边界包含和边界排除。这些边缘情况突出表明了人工干预的必要性。虽然LLMs不能替代人类判断，但它们可以显著减少评估大量科学文献的负担。", "conclusion": "虽然LLMs在系统综述中的应用还不能完全取代人类判断，但它们极大地减轻了评审大量科学文献的工作负担。AiSysRev平台为这一领域提供了有价值的解决方案，并展示了LLMs在加速和辅助手工筛选过程中的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07070", "html_url": "https://arxiv.org/abs/2510.07070", "title": "在野外构建开放的AIBOM标准", "title_en": "Building an Open AIBOM Standard in the Wild", "authors": "Gopi Krishnan Rajbahadur,Keheliya Gallaba,Elyas Rashno,Arthit Suriyawongkul,Karen Bennet,Kate Stewart,Ahmed E. Hassan", "background": "现代软件工程越来越多地依赖开放的、由社区驱动的标准。然而，在诸如人工智能（AI）驱动系统等快节奏发展的领域中，这些标准是如何创建的，依然很少被探索。本研究通过详细的经验报告，描述了AI Bill of Materials（AIBOM）规范的开发过程，该规范是ISO/IEC 5962:2021软件包数据交换（SPDX）软件物料清单（SBOM）标准的扩展，用于捕获AI组件如数据集和迭代训练成果。", "innovation": "本研究采用行动研究（Action Research, AR）的方法，记录了一个跨越全球、多利益相关者的努力，涉及超过90名贡献者，并系统地进行了多个AR周期。研究通过四项互补的方法验证了规范：与主要法规和伦理标准（如欧盟AI法案、IEEE 7000标准）的对齐、系统地图到六个行业用例、半结构化的从业者访谈，以及一个工业案例研究。", "conclusion": "除了提供一个经过验证的成果，本文还记录了在野外构建AIBOM规范的过程，并反思了这一过程与AR周期的契合度，并提炼了对未来软件工程社区标准化努力具有指导意义的教训。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06396", "html_url": "https://arxiv.org/abs/2510.06396", "title": "可适应的蛋白质设计协议和中间件", "title_en": "Adaptive Protein Design Protocols and Middleware", "authors": "Aymen Alsaadi,Jonathan Ash,Mikhail Titov,Matteo Turilli,Andre Merzky,Shantenu Jha,Sagar Khare", "background": "计算蛋白质设计正经历由AI/ML驱动的变革，但由于可能的蛋白质序列和结构范围极其广泛，即使是对中等大小的蛋白质也不例外，因此，要在生成结构和预测结构之间实现收敛需要大量的计算资源进行采样。IMPRESS旨在通过将AI与高性能计算任务耦合，提供方法和先进计算系统，以评估正在开发中的蛋白质设计以及用于生成数据和训练模型的模型和模拟的有效性。", "innovation": "IMPRESS提出了适应性蛋白质设计协议和支撑计算基础架构，这提高了蛋白质设计的质量一致性，并通过动态资源分配和异步工作负载执行提高了蛋白质设计的速度。", "conclusion": "该论文介绍了IMPRESS，并展示了适应性蛋白质设计协议及其支撑计算基础设施的发展与实现。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06414", "html_url": "https://arxiv.org/abs/2510.06414", "title": "将命令式流程模型与流程数据查询衔接——翻译与放松", "title_en": "Bridging Imperative Process Models and Process Data Queries-Translation and Relaxation", "authors": "Abdur Rehman Anwar Qureshi,Adrian Rebmann,Timotheus Kampik,Matthias Weidlich,Mathias Weske", "background": "企业流程管理越来越多地采用数据驱动的方法。尽管如此，古典的命令式流程模型通常用Petri网形式化，但在处理包含大量结构化流程执行数据的关系数据库时并不直接适用。这造成了传统流程建模与最近的数据驱动流程分析发展的差距，导致模型的广泛利用不足。", "innovation": "本文提出了一种将命令式模型转化为可执行于关系数据库的宽松过程数据查询（特别是SQL查询），用于一致性检查的方法，以弥补传统流程建模与数据驱动流程管理之间的差距。结果显示，命令式流程模型在数据驱动流程管理中依然相关，同时强调了行为足迹和其他声明性方法对于集成基于模型和数据驱动的流程管理的重要性。", "conclusion": "本文通过提供命令式模型向可执行SQL查询的翻译和放松方法，解决了流程建模与数据驱动流程分析之间的差距，进一步强调了基于模型和数据驱动的流程管理的重要性。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07189", "html_url": "https://arxiv.org/abs/2510.07189", "title": "提示，合成，微调：一种安全代码生成方案", "title_en": "Prompt, Synthesize, Fine-Tune: A Secure Code Generation Recipe", "authors": "Junjie Li,Fazle Rabbi,Bo Yang,Song Wang,Jinqiu Yang", "background": "尽管大型语言模型（LLMs）在自动代码生成方面显示出有前景的解决方案，但它们经常生成不安全的代码，威胁软件安全。目前的方法（例如SafeCoder）在提高安全代码生成方面受到有限和不平衡的数据集的限制，这降低了其有效性和普遍适用性。", "innovation": "提出了一种名为Secure-Instruct的新框架，该框架自动综合高质量的易受攻击和安全代码示例，生成微调指令，并对LLMs进行指令微调以使任务描述和安全代码生成能力相匹配。Secure-Instruct在四个代表性LLMs上进行了评估，使用了两个基准：自建的CWEBench和现有的CWEval。研究发现，Secure-Instruct不仅提高了代码的安全性，还提高了功能正确性。", "conclusion": "在CWEBench上，Secure-Instruct显著提高了安全代码生成，平均比重训练模型提高了14.3%的安全比率，同时优于SafeCoder 7.6%。在CWEval上，对于CodeLlama-7B，Secure-Instruct在Func-Sec@1上相比预训练模型提高了14%，超过SafeCoder 15.8%。对于Mistral-7B，Secure-Instruct提高了5.8%，超过SafeCoder 6.8%。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06987", "html_url": "https://arxiv.org/abs/2510.06987", "title": "螺旋模型技术在数据科学与机器学习生命周期中的应用", "title_en": "Spiral Model Technique For Data Science & Machine Learning Lifecycle", "authors": "Rohith Mahadevan", "background": "在现代商业中，数据分析起着重要作用。公司根据自身文化调整数据科学生命周期以提高生产力和竞争力。数据科学和机器学习生命周期由一系列步骤组成，通常表现为线性或循环模型。在传统的数据科学生命周期中，可以在完成一个周期后重新开始。因此，本文提出了一种新的技术，将数据科学生命周期应用于具有明确目标的企业问题中。", "innovation": "提出了一种称为螺旋技术的新方法，以强调在企业流程中实现灵活性、敏捷性和迭代方法的重要性。", "conclusion": "该技术旨在改进数据科学生命周期，以更好地适应具有明确终点的企业问题，并优化其在商业过程中的应用。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06989", "html_url": "https://arxiv.org/abs/2510.06989", "title": "权重层次架构导向的AI模型卡", "title_en": "Human-aligned AI Model Cards with Weighted Hierarchy Architecture", "authors": "Pengyue Yang,Haolin Jin,Qingwen Zeng,Jiawen Wen,Harry Rao,Huaming Chen", "background": "大型语言模型（LLMs）的大量涌现催生了专门领域模型的生态系统。虽然这加速了创新，但也带来了模型发现和采用的重大挑战。用户因跨平台文档不一致、不完整且不平衡而难以导航这一领域。现有的文档框架，如模型卡和FactSheets，虽然试图标准化报告，但也常为静态、主要定性和缺乏用于严格跨模型比较的定量机制，加剧了模型的利用率不足，并妨碍了负责任的采用。", "innovation": "引入了全面负责任的人工智能模型卡框架(CRAI-MCF)，这是一个新型方法，从静态披露转向了操作性和人性化对齐的有效文档。基于价值敏感设计（VSD），CRAI-MCF基于240个开源项目的实证分析，提炼出217个参数至一个基于价值观的八模块架构。该框架引入了一个量化充分性标准来实现评估的运作化，并允在统一框架下进行严格的跨模型比较。CRAI-MCF平衡了技术、伦理和操作维度，使从业者能够更加有信心和操作完整地评估、选择和采用LLMs。", "conclusion": "CRAI-MCF通过平衡技术和操作维度，为从业者提供了能够在各方面评估、选择和采用LLMs的强大工具，从而提高采用的效率和可靠性。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07010", "html_url": "https://arxiv.org/abs/2510.07010", "title": "在新员工入职培训中教授建模以提升软件理解能力的初步成果", "title_en": "Early Results from Teaching Modelling for Software Comprehension in New-Hire Onboarding", "authors": "Mrityunjay Kumar,Venkatesh Choppella", "background": "软件系统的维护和发展需要强大的理解能力，然而大多数毕业生进入行业时缺乏这方面的准备。因此，如何有效处理大型且现有的软件系统成为了挑战。", "innovation": "研究通过一种名为Labelled Transition System (LTS)建模的课程，将系统思维的培训整合到一家SaaS公司的入职培训计划中，这是一种新的干预措施。", "conclusion": "尽管总体而言，新员工的理解能力提升不明显且无统计学意义，但那些初始测验得分较低的新员工平均提升了15个百分点，这具有统计学意义；而初始得分较高的员工的理解能力略有下降。尽管参与培训的人员表示高度参与并认为课程具有实际应用价值，但研究也指出了对更强的参与者需要不同的路径，并建议公司可以大规模采用这种低成本的补充入职培训措施以提高员工理解能力。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06984", "html_url": "https://arxiv.org/abs/2510.06984", "title": "关于被拒提案的实证研究：为何这些提案被拒？", "title_en": "An empirical study on declined proposals: why are these proposals declined?", "authors": "Masanari Kondo,Mahmoud Alfadel,Shane McIntosh,Yasutaka Kamei,Naoyasu Ubayashi", "background": "开源软件（OSS）项目中的设计级决策通常通过提案机制做出，这些机制包括需要大量社区讨论和审查的过程。尽管该过程对于项目非常重要，但它资源密集并且经常导致提案人感到沮丧，尤其是在提案被拒绝且缺乏明确反馈的情况下。然而，提案被拒的具体原因尚不明确，这限制了改进过程或有效指导提案人的机会。本研究通过分析Go编程语言项目的1,091个提案，调查了被拒提案的特征和结果，以了解提案被拒的原因以及如何预测这些结果。研究发现提案被拒的比例高于被接受的比例，且解决过程通常需要超过一个月的时间。仅有14.7%的被拒提案被重新提交。通过质性编码，研究确定了九个关键的被拒原因，例如重复、用途有限或违反项目原则。这一分类有助于提案人提前解决问题，例如检查现有替代方案可以减少不必要的重复。该研究还展示了基于GPT的模型可以在讨论初期预测被拒决定（F1分数为0.71），提供了一种优先审查努力的实用工具。研究发现揭露了提案过程中存在的低效性，并强调了通过早期分诊和使提案人能够利用历史被拒原因的结构化理解来改善提案人体验和审查员工作量的实际机遇.", "innovation": "本研究通过量化的实证方法分析了被拒提案的特征和结果，构建了一个拒绝理由的分类，并展示了GPT基于的模型可以在提案讨论初期预测被拒决定，从而实现早期优先审查。这一创新方法为开源项目的提案过程提供了新的见解和改进工具，指导提案人进行更有效的提案准备，同时减轻审查者的负担.", "conclusion": "研究结果揭示了提案过程中的低效问题，并指出通过提前分诊和为贡献者提供结构化的反馈可以帮助改善贡献者体验和减轻审查者的工作量。此外，利用大语言模型预测提案被拒的早期指标提供了一种实用的方法来优化审查流程。未来的工作可以进一步探索其他开源项目的提案过程，以及其他先进的人工智能技术在提案过程中的应用潜力。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.06663", "html_url": "https://arxiv.org/abs/2510.06663", "title": "使用大型语言模型自动发现数据库管理系统测试Oracle的方法", "title_en": "Automated Discovery of Test Oracles for Database Management Systems Using LLMs", "authors": "Qiuyang Mang,Runyuan He,Suyang Zhong,Xiaoxuan Liu,Huanchen Zhang,Alvin Cheung", "background": "自2020年以来，数据库管理系统（DBMS）的自动化测试蓬勃发展，发现了数百个广泛使用的系统中的大量缺陷。测试oracle是这些技术的基石，通常实现生成等效查询对的机制，通过检查它们的结果一致性来识别缺陷。这些oracle的应用可以自动化，但其设计仍然是一个基本的手工过程。本文探讨了使用大型语言模型（LLMs）来自动化发现和实例化测试oracle的可能性，以解决完全自动化DBMS测试中的长期瓶颈。然而，LLMs虽然表现出色但容易产生虚假的缺陷报告。此外，由于其高昂的成本和延迟，LLM的调用应受到限制，以确保缺陷检测的效率和经济效益。", "innovation": "本文提出了Argus，一个新型的框架，基于约束抽象查询的中心概念——包含占位符及其相关实例化条件的SQL骨架。Argus利用LLMs生成这些骨架的等效对，并通过SQL等效性求解器正式证明这些等效性以保证准确性。最后，验证后的骨架中的占位符用由LLMs合成的具体可重用SQL片段实例化，以高效生成复杂的测试案例。通过在五个广泛测试的DBMS上实现和评估Argus，发现40个新的未识别缺陷，其中35个是逻辑缺陷。有36个缺陷被确认，并且已经由开发者修复了26个。", "conclusion": "该研究通过设计Argus框架，实现了利用LLMs自动发现和生成精确的DBMS测试oracle的目标，提高了DBMS测试的效率和经济性，解决了长期存在的自动化测试瓶颈。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07116", "html_url": "https://arxiv.org/abs/2510.07116", "title": "从神经传感到刺激：神经技术的跨学科路线图", "title_en": "From Neural Sensing to Stimulation: An Interdisciplinary Roadmap for Neurotechnology", "authors": "Ruben Ruiz-Mateos Serrano,Joe G Troughton,Nima Mirkhani,Natalia Martinez,Massimo Mariello,Jordan Tsigarides,Simon Williamson,Juan Sapriza,Ioana Susnoschi Luca,Antonio Dominguez-Alfaro,Estelle Cuttaz,Nicole Thompson,Sydney Swedick,Latifah Almulla,Amparo Guemes", "background": "神经技术正在改变我们如何测量、解释和调控脑体交互的方式，通过实时传感、计算和刺激的整合，实现精确的生理控制。这些技术在临床和非临床领域都蕴含着变革性潜力，从治疗疾病到增强认知和表现。实现这种潜力需要克服跨学科的复杂挑战，这些挑战涉及神经科学、材料科学、设备工程、信号处理、计算建模以及监管和伦理框架。", "innovation": "这种视角提供了一个战略性的神经技术开发路线图，由年轻研究人员提出，强调学科间的交叉点以及突破传统壁垒的能力。提出了影响功能、可扩展性、适应性和转化性的五个核心技术难题，并展示了技术领域如何影响它们的解决方式。重点关注超越学科的共享挑战和战略性机遇，提出了一种统一的协作创新和教育框架，强调伦理和监管优先事项，并概述了克服关键瓶颈的时间表。", "conclusion": "通过将技术开发与转化和社会需求相结合，旨在加速公平、高效和未来的适应性神经技术的发展，指导全球研究和创新社区的协同努力。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.12163", "html_url": "https://arxiv.org/abs/2503.12163", "title": "AgentDroid: 一种检测恶意Android应用的多智能体框架", "title_en": "AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications", "authors": "Ruwei Pan,Hongyu Zhang,Zhonghao Jiang,Ran Hou", "background": "随着假冒及恶意Android应用程序的增多，准确且适应性强地检测这些应用程序变得至关重要。传统的检测方法存在处理多模式数据能力不足和误报率高的问题，因此需要一种新的解决方案来应对这一挑战。", "innovation": "AgentDroid是一个基于多模式分析和多智能体系统的新型工具，能够克服传统方法的局限性。它通过分析Android应用提取出的多模式数据，使用多个具有专门角色的语言模型(LLM)智能体进行分析并协作以有效检测复杂欺诈行为。实验结果表明，基于GPT-4o的多智能体工具，在准确率和F1分数上均超过基线方法，分别达到了91.7%和91.68%。", "conclusion": "AgentDroid在多模式数据处理和欺诈检测方面表现出色，能够适应不断变化的Android应用环境，提供了高效且准确的检测手段。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07147", "html_url": "https://arxiv.org/abs/2510.07147", "title": "基于多智能体的持久态推理时搜索框架", "title_en": "A Multi-Agent Framework for Stateful Inference-Time Search", "authors": "Arshika Lalan,Rajat Ghosh,Aditya Kolsur,Debojyoti Dutta", "background": "最近的工作探索了代理推理时的技术，以进行结构化的多步骤推理。但无状态推理在多步骤任务上往往遇到困难，因为缺乏持久状态。此外，任务特定的微调或指令调优通常只能实现表面的代码生成，而对需要深入推理和长范围依赖的任务则表现脆弱。现有的方法并未解决这些问题。", "innovation": "本文提出了一种基于多智能体的进化搜索框架，这是一种无需训练的框架，通过结合(一)持久推理时状态,(二)对抗性突变,以及(三)进化保存来解决上述问题。通过该框架在自动化单元测试生成中的应用，利用进化搜索过程，生成了稳定的边缘案例。控制器在不同代之间保持持久状态，以确保多样性并探索所有可能的情况，从而产生能够在未知代码中泛化的智能体。实验表明，该框架相较于无状态单步基准，在评价单元测试基准如HumanEval和TestGenEvalMini上实现了覆盖范围上的显著提升，适用于不同的LLM家族。", "conclusion": "结果表明，结合持久推理时状态与进化搜索在单元测试生成中显著提高了覆盖率。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.07315", "html_url": "https://arxiv.org/abs/2510.07315", "title": "Vibe Checker: 以人类偏好为准则对代码评估进行对齐", "title_en": "Vibe Checker: Aligning Code Evaluation with Human Preference", "authors": "Ming Zhong,Xiang Zhou,Ting-Yun Chang,Qingze Wang,Nan Xu,Xiance Si,Dan Garrette,Shyam Upadhyay,Jeremiah Liu,Jiawei Han,Benoit Schillings,Jiao Sun", "background": "大型语言模型(LLMs)已经推动了一种被称为vibe编码的编程模式，用户通过自然语言交互与LLMs互动来生成和迭代优化代码直到通过他们的vibe检查。vibe检查不仅关注功能性正确性，还关注非功能性因素，如代码感觉正确、读起来清新、保留意图且保持正确。然而，现有的代码评估方法通常只关注功能性正确性，缺乏对非功能性指令的关注，这些指令往往是用户常用的。", "innovation": "本文假设指令遵循是除了功能正确性之外，能够反映编程中人类偏好缺失的关键因素。为了量化模型的指令遵循能力，作者提出了一种名为VeriCode的30个可验证代码指令的分类系统并附带对应的确定性验证器。将此分类系统应用于现有的评估框架，结果形成了一个测试平台Vibe Checker，用于评估代码指令遵循和功能正确性。通过对31个领先的LLMs进行评估，发现即使功能最强的模型也难以完全遵循多个指令，并出现功能倒退的现象。更重要的是，功能正确性和指令遵循的综合分数与人类偏好最为相关，后者成为现实编程任务中主要的区分因素。", "conclusion": "本文确认了vibe检查的关键因素，提供了衡量和开发更好地符合编程中用户偏好模型的具体路径。研究结果表明，功能正确性和指令遵循的综合评估比单一功能性评估更能反映用户的真实偏好。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.11787", "html_url": "https://arxiv.org/abs/2509.11787", "title": "CodeCureAgent: 自动分类和修复静态分析警告", "title_en": "CodeCureAgent: Automatic Classification and Repair of Static Analysis Warnings", "authors": "Pascal Joos,Islem Bouzenia,Michael Pradel", "background": "静态分析工具有广泛应用于检测代码中的错误、漏洞和代码异味，传统的开发人员需要手动解决这些警告。但这个过程往往非常麻烦，导致开发人员有时会忽略这些警告，从而造成警告堆积并逐渐降低代码质量。", "innovation": "该论文提出了CodeCureAgent，一种利用基于LLM的代理自动进行静态分析警告的检测、分类和修复的方法。不同于传统的预定算法，CodeCureAgent采用一种行动框架进行迭代工具调用，从代码库中收集额外信息（例如通过代码搜索）并编辑代码库以解决警告。此外，CodeCureAgent还使用了三个步骤的启发式方法来验证补丁的有效性，并表现出明显的修复成功率，优于最先进的基准方法，同时降低了LLM的成本并减少了处理时间。", "conclusion": "CodeCureAgent在106个Java项目中的1000个SonarQube警告的评估中表现出色，成功修复了96.8%的警告，且能使代码基可靠清理，具有提升和集成到CI/CD流程中以防止静态分析警告累积的潜力。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.04437", "html_url": "https://arxiv.org/abs/2510.04437", "title": "智聘再定义：智能招聘管理平台", "title_en": "Smart Hiring Redefined: An Intelligent Recruitment Management Platform", "authors": "Fangzhe Wu,Dongyang Lyu,Xiaoqi Li", "background": "在数字化和智能化的人力资源管理不断深化的背景下，传统的招聘模式难以完全满足企业对于精准人才获取日益增长的需求，因为这些模式效率低下、成本高且存在信息不对称问题。作为优化招聘流程、减少人力和时间成本、提升核心竞争力的重要工具，智能招聘管理系统已成为现代组织人才战略不可或缺的一部分。与传统的人工招聘中耗时耗力的简历筛选、候选人职位匹配以及面试协调等任务相比，智能招聘系统通过自动化和数据驱动的方法极大地提升了招聘流程的效率和准确性。", "innovation": "该研究利用Java技术框架为校园招聘场景设计并实现了一个智能招聘管理平台。该平台通过信息技术和智能解决方案建立了学生、企业和管理人员的合作平台，提供了包括职位发布分发、简历提交、候选人职位匹配和流程管理在内的综合功能。该项目以智慧校园招聘的愿景为导向，旨在为学生提供更便捷的求职体验，为企业提供更高效的候选人筛选和服务管理，从而推动企业和大学之间的高质量合作。", "conclusion": "智能招聘管理平台为招聘流程的优化、减少人力资源部门的工作负担以及提高招聘质量和响应速度提供了新的解决方案，引领了招聘领域的变革和发展。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.18824", "html_url": "https://arxiv.org/abs/2506.18824", "title": "理解软件工程代理：思考-行动-结果轨迹的研究", "title_en": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories", "authors": "Islem Bouzenia,Michael Pradel", "background": "大型语言模型（LLM）代理被广泛应用于自动化复杂的软件工程任务，例如程序修复和问题解决。这些代理通过自主生成自然语言思维、调用外部工具并逐步精炼解决方案来工作。尽管它们被广泛应用，但这些代理的内部决策过程仍然难以探知，这限制了我们对其运行机制和故障模式的理解。因此，有必要对LLM代理进行大规模的研究，以揭示其行为模式并提供改进相关设计的应用建议，包括提示策略、故障诊断以及反模式检测。", "innovation": "本研究通过将三种先进的LLM代理（RepairAgent、AutoCodeRover和OpenHands）的互动日志统一成一个通用格式，收集了120条轨迹和2,822次LLM交互，关注于程序修复和问题解决。结合定量分析结构属性、行动模式和令牌使用情况，以及定性评估推理连贯性和反馈集成情况，识别了关键轨迹特征，并揭示了成功的执行与失败的执行之间的行为模式和反模式，为改进代理设计提供了可行的见解。研究还发布了数据集和注释框架，以支持进一步的研究，旨在推动透明和可靠的自主软件工程代理的发展。", "conclusion": "研究发现，成功的执行与失败的执行之间存在行为模式和反模式的差异，提供了解决代理设计、故障诊断和反模式检测方面问题的实用建议，研究数据和注释框架将支持进一步的研究，提升代理代理的透明度和可靠性，从而促进软件工程的自动化进程。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.15397", "html_url": "https://arxiv.org/abs/2509.15397", "title": "分析和缓解代码评价指标的表层偏见", "title_en": "Analyzing and Mitigating Surface Bias in Code Evaluation Metrics", "authors": "Simantika Bhattacharjee Dristi,Matthew B. Dwyer", "background": "随着大型语言模型（LLMs）及其代理的流行，可靠的代码评价指标（CEMs）对于软件工程任务的进步变得至关重要。虽然流行的基准测试通常提供测试案例来评估生成代码的正确性，但创建和执行测试案例需要较高的成本。参考基线CEMs提供了一种更为经济的选择，即根据候选程序与参考代码的功能相似性进行评分。尽管之前的研究集中在报告这些CEMs与功能正确性之间较弱的相关性，但其原因仅被假设且尚未提出可行的解决方案。这项工作通过维护四个最先进的参考基线CEMs，揭示了它们对表面特征的偏好远胜于代码功能。尽管存在这种表面偏好，用于这些CEMs的当前评估数据集很少包括表面相似但功能不相似，或者功能相似但表面不相似的代码对。在缓解这种差距方面，本文提出了LoCaL（外表可能说谎）基准，涵盖了3117个代码对，这些对在方法和程序级别上进行标记，标签为功能相似性评分，并且旨在瞄准CEMs可能表现不佳的区域。这些功能相似性评分通过差异模糊计算得出，消除了预先定义的测试案例的需要，并且通过执行远多于以往工作的测试次数提高评分的可靠性。", "innovation": "提出了LoCaL（外表可能说谎）基准，包含了3117个代码对，位于方法和程序级别，标记为功能相似性评分，并且旨在瞄准CEMs可能表现不佳的区域。这些功能相似性评分通过差异模糊计算得出，通过执行远多于以往工作的测试次数提高评分的可靠性。通过LoCaL基准测试，所有四个CEMs在功能相似性上均显示出显著性能退化，相较于基线。由此推断，暴露CEMs于类似LoCaL的数据可能有助于开发出不受表面偏见影响的指标。", "conclusion": "本文基于研究结果表明，通过将CEMs暴露在LoCaL类似的数据中，可以促进开发出能够抵御表面偏见影响的指标。"}
{"llm_update_time": "20251009", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.25282", "html_url": "https://arxiv.org/abs/2509.25282", "title": "迈向因果可视化编程：增强低代码环境中的代理推理", "title_en": "Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments", "authors": "Jiexi Xu,Jiaqi Liu,Lanruo Wang,Su Liu", "background": "大型语言模型代理在低代码环境中能够处理复杂任务，但它们常常出现幻觉和逻辑不一致，因为它们依赖于概率关联而非真正的因果理解。已有技术在这方面的局限性成为研究的重要背景。", "innovation": "本文提出了一种新的编程范式——因果可视化编程（CVP），通过在工作流设计中引入因果结构来解决这个问题。CVP允许用户通过直观的低代码界面定义一个简单的“世界模型”，有效创建有向无环图（DAG），明确定义模块之间的因果关系。这种因果图在代理推理过程中作为关键约束，将决策锚定在用户定义的因果结构上，显著减少了逻辑错误和幻觉，避免了对虚假相关性的依赖。为了验证CVP的有效性，设计了一个合成实验，模拟了训练和测试环境中的分布变化问题，结果表明因果锚定模型在面对这种变化时保持了稳定的准确性，而依赖于概率关联的基线模型则遭受了显著的性能下降。", "conclusion": "研究的主要贡献包括：正式定义工作流模块中的因果结构；提出并实现了锚定代理推理的用户定义因果图的CVP框架；以及通过实验证明框架在增强代理鲁棒性、减少动态环境中因果混淆错误方面效果明显。CVP为构建更可解释、可靠和可信的AI代理提供了可行途径。"}
