{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21307", "html_url": "https://arxiv.org/abs/2508.21307", "title": "MultiFluxAI 使用先进代理协调检索系统的平台工程增强平台", "title_en": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "authors": "Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala", "background": "本文介绍了MultiFluxAI，一个创新的AI平台，旨在解决产品工程中各应用领域广泛和不一致数据源管理与集成的挑战。该平台针对当前和新服务相关的查询增强用户在数字生态系统的参与度。", "innovation": "MultiFluxAI 利用了生成AI、向量化和代理协调调度等先进技术，为复杂用户查询提供动态和上下文相关的响应。", "conclusion": "该平台通过利用先进的AI技术来管理多个不同的数据源，并提供及时和相关的信息，从而改进了用户在数字生态系统中的互动体验，同时解决了传统方法中的挑战。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21411", "html_url": "https://arxiv.org/abs/2508.21411", "title": "CARJAN：基于AJAN的交通场景基于代理的生成与模拟", "title_en": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "authors": "Leonard Frank Neis,Andre Antakli,Matthias Klusch", "background": "用户友好的城市交通场景建模和虚拟仿真，特别是涉及行人、骑行者和自动驾驶车辆等多种交互代理 remains a challenge。现有的工具和技术通常难以实现这一目标。", "innovation": "CARJAN是一种基于AJAN多代理工程框架和CARLA驾驶模拟器的新颖工具，它提供了半自动化的交通场景生成与模拟。CARJAN具备用于交通场景布局建模、存储和维护的可视化用户界面，并利用SPARQL行为树进行智能代理在动态场景仿真中的决策和交互。", "conclusion": "CARJAN提供了一种交互式、智能化的多代理生成和模拟虚拟交通场景的方法，可以在CARLA中实现这一目标。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21394", "html_url": "https://arxiv.org/abs/2508.21394", "title": "AI计算架构与进化趋势", "title_en": "AI Compute Architecture and Evolution Trends", "authors": "Bor-Sung Liang", "background": "人工智能（AI）开发的重点已经从学术研究转移到实际应用，但这一过程中面临着许多多方面的挑战。本文旨在通过结构化的方法，从多个角度分析AI的机会和挑战。", "innovation": "提出了一种七层的AI计算架构模型，包括物理层、链路层、神经网络层、上下文层、代理层、协调层和应用层。同时深入探讨了大规模语言模型（LLMs）演进中的大规模层面和横向扩展策略对计算架构的影响，并分析了上下文记忆对LLMs的影响以及传统处理器内存的区别。", "conclusion": "AI开发不仅面临技术挑战，还需解决经济问题以构建自我可持续的生态系统，并且通过分析互联网行业为AI未来的发展轨迹提供了预测。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21441", "html_url": "https://arxiv.org/abs/2508.21441", "title": "Epistemic遗忘及其通过排名函数的实例化", "title_en": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "authors": "Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald", "background": "遗忘作为一种知识管理操作，有意忽略了代理的部分知识和信念，原因可能多样。遗忘形式多样，可以遗忘语法的一部分、命题或条件。以往研究中提出了两种主要的操作来执行遗忘，分别是变量消去和收缩。前者是通过语法方法移除某些原子变量，后者则是通过逻辑推理从信念集中移除命题。虽然这两种操作主要依赖经典逻辑，但本文作者建议从认知视角出发，研究更丰富语义结构的表知识状态下的遗忘操作，将其提升到认知层面。", "innovation": "本文提出了五种普遍的表知识遗忘类型，并通过Spohn的排名函数实例化了它们。作者借鉴了逻辑编程和AGM理论中的遗忘公理，提出了丰富的遗忘操作评价公理体系，并最终根据所有公理评估了所有实例化的遗忘操作，得出了新的综合概述，揭示了遗忘操作的差异和共性。", "conclusion": "通过引入更丰富的语义结构，本文成功地将遗忘操作提升到表知识层面，并通过Spohn的排名函数实例化了遗忘操作，提出了基于遗忘公理体系的综合评估方法。这种研究方法不仅拓展了遗忘操作的应用范围，还加深了对其背后的理论理解。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21517", "html_url": "https://arxiv.org/abs/2508.21517", "title": "基于普罗尼司启发的Z-数模糊框架建模明智决策", "title_en": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis", "authors": "Sweta Kaman,Ankita Sharma,Romi Banerjee", "background": "智慧是一个上位概念，包含了换位思考、反思性、利他倾向、反思性同理行动和智力谦逊。与传统二元对立的推理模型不同，智慧呈现为一种模糊状态，需要同时包含分级评估和自我反思的谦逊。当前的测量方法主要依赖于自我报告，很少反映出智慧推理中固有的谦逊和不确定性。一个既能考虑多维性和信心的计算框架，有可能改善心理学研究，促使人道主义人工智能的发展。", "innovation": "提出了一种基于Z数的模糊推理系统，每个决策通过智慧评分（限制）和信心评分（确定性）来表达。系统通过对100名参与者进行文化中立的道德困境任务，并生成口头思考后的语言回应，将这些回应映射到理论上的智慧五个维度。采用21条基础规则，通过高斯核密度估计调整隶属函数，实现了多维度智慧计量。结果显示，系统在概念证明研究中产生的双属性智慧表示与现有量表相关，与无关特质几乎没有关系，支持其收敛性和发散性效度。此外，计算框架为AI系统提供了可解释、信心敏感的推理方式，其计算与人类判断之间提供了安全、合理的平衡。", "conclusion": "研究贡献在于将智慧正式化为一个多维度、意识不确定性的构建，并通过Z数操作化。它不仅促进了心理学测量的发展，还计算了如何使模糊Z数为AI系统提供解释性、信心敏感的推理，使其在严格计算与人类判断之间有安全的、合理的中间地带。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21521", "html_url": "https://arxiv.org/abs/2508.21521", "title": "自动规划中的反事实场景", "title_en": "Counterfactual Scenarios for Automated Planning", "authors": "Nicola Gigante,Francesco Leofante,Andrea Micheli", "background": "反事实解释（CEs）是一种强大的技术，用于通过展示如何最小化修改输入以使模型产生不同输出来解释机器学习模型。这种解释方法在自动规划领域也有应用，通过最小修改现有计划来满足不同的目标。然而，这样的解释无法捕捉到所解决问题的高层次属性。本研究旨在克服这一限制，提出了一种新的解释范式，基于反事实场景。给定一个规划问题P和一个定义计划所需属性的LTFL公式ψ，反事实场景通过识别最小修改P来解决问题，使得P可接受符合ψ的计划。论文提出了两种具体实例化方法，并分析了生成反事实场景的计算复杂性，展示了该方法在实际应用中的可行性。", "innovation": "提出了基于反事实场景的新解释范式，特别是给定规划问题P和定义计划所需属性的LTFL公式ψ，通过识别最小修改P来解决问题，使得P可接受符合ψ的计划。此外，论文展示了生成反事实场景的计算复杂性，突出了该方法在实际应用中的可行性和潜在算法框架的构建可能性", "conclusion": "反事实场景的生成通常与计算P的计划一样昂贵，表明该方法实际可行，并为该领域提供了框架以构建实用算法。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "使用双向传播实现多领域知识整合的医疗概念表示", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "现有的文献主要集中在单一或多个孤立的领域知识（如疾病、药物和程序）上，这些领域知识通常被整合到各自的结构中。这种方式导致了概念表示学习通常局限于同一领域内的关系，忽视了跨领域的联系。现有的方法主要是通过单一或多学科的领域知识来映射外部知识到电子健康记录中的医学代码，并通过结构化的关系建立连接，但很少将这些知识整合到一个统一的学习结构中。", "innovation": "本文提出了LINKO，一个大语言模型增强的集成领域知识学习框架，能够同时利用多个领域知识图，通过与异构领域系统的双轴知识传播增强医学概念表示学习。该框架首先使用大语言模型进行图检索增强的初始化，通过精工制作的问题描述和背景来嵌入概念描述，并进一步利用领域背景进行增强。其次，该方法通过两个轴向进行共同学习：（1）在同一领域内水平传播跨越层级关系的知识；（2）在同一层级内并行的跨领域水平传播。最后，通过在两个公开数据集上的大量实验验证了LINKO相对于最先进的基线模型的优越性能，并且表明LINKO作为现有EHR预测模型的插件编码器，在数据有限和罕见疾病预测等情境中具有增强的稳健性。", "conclusion": "通过广泛的实验，LINKO展示了在医疗概念表示学习中的优越性能，尤其是在数据有限和罕见疾病预测等场景中的增强稳健性，证明了通过大语言模型增强的多领域知识整合方法的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM：音频语言模型的综合性评估", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "目前对音频语言模型（ALMs）——能够接受交错音频和文本输入并输出文本的多模态模型——的评估受到了缺乏标准化基准的阻碍；大多数基准仅衡量单一或少数几个能力，忽略了公平性或安全性等评估方面。此外，不同模型之间的比较困难，因为独立的评估通常仅测试有限数量的模型，并使用不同的提示方法和推理参数。因此，为了缓解这些问题，引入了AHELM基准，它收集了各种数据集——包括两个新的合成音频-文本数据集PARADE和CoRe-Bench，分别评估ALMs避免刻板印象的能力和通过推断多轮问答测量基于对话的音频分析推理能力，从此全方位测量ALMs在10个我们认为对ALMs的开发和使用重要的方面上的表现：音频感知、知识、推理、情绪识别、偏差、公平性、多语言性、鲁棒性、有害内容和安全性。同时标准化了提示、推理参数和评估指标，为不同模型之间的公平比较提供了保障。", "innovation": "AHELM基准通过整合各种数据集，特别是两个新的合成音频-文本数据集PARADE和CoRe-Bench，创新地衡量了音频语言模型在多个方面的性能。此外，通过标准化提示、推理参数和评估指标，确保了不同模型的公平比较，还测试了14个开源和封闭API音频语言模型以及3个附加的简单基线系统，提供了详细的透明数据支持。", "conclusion": "我们的结果表明，虽然Gemini 2.5 Pro在10个方面的评估中表现为最佳，但在ASR任务上表现出分组不公平性。此外，基准系统的性能也相当不错，其中一系统虽然仅有语音转文本能力，但仍排名第五。AHELM旨在成为一个动态基准，随着时间的推移会不断添加新的数据集和模型。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊、符号与上下文：通过认知支撑增强大型语言模型指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究探讨了建筑性诱导偏见如何塑造大型语言模型（LLMs）在指令对话中的认知行为。研究采用了一种符号支撑机制配对短期记忆框架，旨在促进Socratic教学中的适应性和结构化推理。通过五个系统变体的控制脱靶实验，使用专家设计的评分标准评估导引、响应、符号推理和对话记忆等模型输出表现。", "innovation": "引入了一种新的符号支撑机制配对短期记忆框架，该框架旨在促进大型语言模型在Socratic教学场景中的适应性和结构化推理。研究使用大型语言模型为基础的评估框架，并且与认知基础的评分标准对齐，这使得在初步实验阶段可以进行架构变体的大规模、系统性比较。研究表明，该完整系统能够在初步测试中持续优于基线变体。分析指出，移除记忆或符号结构将影响重要认知行为，包括抽象能力、有针对性的探索和概念连贯性。这一发现支持了在处理层面，架构支撑可以可靠地塑造LLMs中的教学策略的观点。", "conclusion": "该研究初步结果显示，包含记忆和符号结构的完整系统在多种认知行为上表现更佳，这表明建筑性诱导偏差能够可靠地塑造LLMs中的教学策略。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21449", "html_url": "https://arxiv.org/abs/2508.21449", "title": "从不完整动作和状态的轨迹中学习提升的动作模型", "title_en": "Learning Lifted Action Models From Traces of Incomplete Actions and States", "authors": "Niklas Jansen,Jonas Gösgens,Hector Geffner", "background": "研究了从仅包含瓷砖位置的状态以及无论元的上下文移动（up, down, left, and right）动作的随机状态-动作轨迹中学习提升的STRIPS模型的问题。这一问题面临两大挑战：首先，观察到的状态不包含完整的STRIPS状态，即缺少一些表示“空白”位置的原子；其次，动作不包含完整STRIPS格式的所有物项的效果和前置条件。之前的许多方法要么假设轨迹中的动作是完整的STRIPS动作，要么假设所有域名谓词都是可观察的。当前研究的工作更符合现实情况，因为实际观察到的原子揭示了世界的状态而非完整的STRIPS状态，且动作揭示了选择动作所需的参数，但未能揭示用于在STRIPS中建模动作所需的参数。", "innovation": "引入了一种新的STRIPS变体，称为STRIPS+，其中某些STRIPS动作参数可以被省略，并且可以包含限于存在量词的预条件。该工作将学习问题表述为从STRIPS+状态-动作轨迹中学习STRIPS+模型，提出了名为SYNTH的学习算法，该算法为每个动作构建了一层用以表示状态中唯一对象的预条件表达式或“查询”，并地将STRIPS+中的隐含动作参数地面化。该算法的正确性与完整性得到了证明，并通过来自现有STRIPS领域的STRIPS+模型的状态-动作轨迹对其的可扩展性进行了测试。", "conclusion": "SYNTH算法的正确性和完整性得到了证明，并且其在来自现有STRIPS领域的STRIPS+模型的状态-动作轨迹上的可扩展性得到了测试。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21238", "html_url": "https://arxiv.org/abs/2508.21238", "title": "通过知识图谱提高阿尔茨海默病研究中大语言模型的准确性和避免幻觉", "title_en": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "authors": "Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman", "background": "在过去两年中，基于大型语言模型（LLM）的聊天机器人（如ChatGPT）在各个领域中引发了革命性的变化，提供了多样化的任务完成和问答能力。然而，这些聊天机器人在科学研究领域的应用受到了诸如幻觉、有限的领域特定知识以及生成响应的不透明性或可追溯性方面的局限。尽管Graph-based Retrieval-Augmented Generation (GraphRAG)作为一种集成领域特定上下文信息的方法被提出，以提高聊天机器人的可靠性，但目前很少有研究将其应用于需要深入知识的领域，如阿尔茨海默病或生物医学领域。因此，本文评估了两种流行GraphRAG系统的质量与可追溯性，构建了50篇关于阿尔茨海默病的论文和70个专家问题的知识库，并使用GPT-4o进行回答查询。然后，比较了GraphRAG生成响应的质量与标准GPT-4o模型的响应质量。最后，提供了一个便于使用的界面，配有预制的阿尔茨海默病数据库，供研究人员测试标准RAG和GraphRAG的性能。", "innovation": "本文创新性地使用知识图谱来评估和改进GraphRAG系统在阿尔茨海默病研究中的应用质量与可追溯性。它使用了一个包含50篇论文和70个专家问题的自建数据库，以及GPT-4o作为LLM，对比了标准RAG模型和GraphRAG在生成高质量响应和提高可追溯性方面的性能。此外，构建了一个易于使用的界面，集成了阿尔茨海默病数据库，以便研究人员可以测试RAG和GraphRAG系统的表现。", "conclusion": "本文通过使用知识图谱评估两种流行GraphRAG系统的响应质量与可追溯性，提高了对这些系统在阿尔茨海默病研究中的表现的认识。研究结果表明，GraphRAG系统相较于标准模型更可能产生高质量且可追溯的响应。此外，为了方便研究人员评估这些系统的性能，提供了一个集成了阿尔茨海默病相关数据的测试接口。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21365", "html_url": "https://arxiv.org/abs/2508.21365", "title": "Think in Games: 使用大型语言模型通过强化学习在游戏中学习进行推理", "title_en": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "authors": "Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang", "background": "大型语言模型（LLMs）在解决复杂的推理任务（如数学和编程）方面表现出色，但它们经常在年轻儿童能够轻松完成的简单交互任务上表现不佳。这种差异突显出了从陈述性知识（关于某事物的知识）到程序性知识（如何做某事的知识）之间的关键差距。虽然传统的强化学习（RL）代理通过环境互动能够获得程序性知识，但它们通常会作为黑箱运行，并且需要大量训练数据。相比之下，LLMs拥有广泛的关于世界的知识和推理能力，但它们无法有效地将其静态知识转化为交互环境中的动态决策。为应对这一挑战，我们提出了一种名为Think in Games（TiG）的新颖框架，使LLMs能够通过直接与游戏环境的互动来发展程序性理解，同时保持其固有的推理和解释能力。具体来说，TiG将基于强化学习的决策制定重构成语言建模任务：LLMs生成语言指导的策略，这些策略基于环境反馈通过在线强化学习迭代细化。", "innovation": "Think in Games（TiG）框架将基于强化学习的决策问题重新定义为语言建模问题。这种创新方法允许LLMs通过游戏环境的直接互动来学习程序性理解，同时保留其原有的推理和解释能力。TiG在实验中展示了将陈述性知识与程序性知识之间差距的有效弥合，与传统的强化学习方法相比，它大幅降低了数据和计算需求，并提供了逐步的语言解释，显著提高了复杂交互任务的透明度和可解释性。", "conclusion": "实验结果表明，Think in Games（TiG）框架成功地在数据和计算需求方面超越了传统强化学习方法，同时提供了逐步的语言解释，大幅提高了复杂交互任务的透明度和可解释性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21475", "html_url": "https://arxiv.org/abs/2508.21475", "title": "MMSearch-Plus：面向多模态浏览代理的一种简约而具有挑战性的基准", "title_en": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "authors": "Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong", "background": "当前，大型多模态语言模型（MLLMs）越来越多地被部署为网络代理。然而，许多多模态浏览基准可以用简单的、固定的流程解决，这些流程依赖于高召回率的图像搜索，并且通过附近文本屏蔽了真正复杂的多模态挑战，如细粒度的视觉推理、来源验证和长远工具使用。因此，亟需一个既能如此浏览检索复杂性又能维持强大文本单一浏览套件难度特点的新基准。为此，本文提出了MMSearch-Plus基准，它包含311项任务，要求高度的多模态理解，并保留了强大文本单一浏览套件的难度特征。每个项目都包含了必须从局部、弱视觉信号中提取、通过迭代的文本-图像搜索传播并且在检索噪声中交叉验证后才能回答的多个视觉信号。", "innovation": "本文的创新点在于提出了MMSearch-Plus基准，这是一个多模态浏览的基准，包含311项任务，高度需求多模态理解，同时保留了强大文本单一浏览套件的难度特征。基准中的每个任务都包含了需要从局部视觉信号中提取并进行迭代文本-图像搜索后才能解决的复杂挑战。主要的创新之处在于其“时空外推”编排过程，该过程促使问题的答案需要通过空间线索和时间痕迹来推测出图像以外的事实。此外，作者还提供了一个模型中立的代理框架，并测试了多种封闭和开放式多模态语言模型，表现出显著的结果差异。这弥补了现有方法对中国这类复杂多模态场景理解的不足，提出了一个新的多模态代理基准。“时空外推”编排过程使得问题的答案需要从空间线索（如微观文字、部件级别的外观、布局、标志等）和时间痕迹（如广播叠加、季节背景等）推断到图像以外的事实，如事件、日期和地点。", "conclusion": "本文通过“时空外推”编排过程构建了MMSearch-Plus基准，并在多种多模态语言模型上进行了评估，显示了代理框架的不同表现。最强的代理（o3）在没有搜索的情况下达到了15.1%的准确性，在有序列展开的情况下达到了36.0%的准确性，而开源的强大模型（Qwen-2.5-VL-72B-Instruct）在没有搜索的情况下仅达到0.0%的准确性，但在经过20轮搜索后达到6.9%的准确性。此外，文中还评估了边界框生产和裁剪图像搜索，并进行了错误分析，揭示了在来源验证、部件推理和长远规划方面的失败。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21540", "html_url": "https://arxiv.org/abs/2508.21540", "title": "HealthProcessAI：增强型医疗流程挖掘的技术框架及其概念验证", "title_en": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining", "authors": "Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi", "background": "过程挖掘作为一种强大的分析技术，适用于理解复杂的医疗工作流程，但由于技术复杂性、缺乏标准化方法和有限的实践培训资源，其在医疗领域的应用面临诸多障碍。", "innovation": "我们引入了HealthProcessAI，这是一个基于生成式人工智能（GenAI）的框架，旨在通过提供现有Python（PM4PY）和R（bupaR）库的全面封装来简化医疗和流行病学中的过程挖掘应用。该框架通过集成多个大型语言模型（LLMs）来实现自动过程图解释和报告生成，帮助技术分析转化为不同用户都能理解的输出。", "conclusion": "通过多种LLMs自动化解释和报告生成，该框架解决了对过程挖掘结果的普遍陌生，使其更容易被临床医生、数据科学家和研究人员访问。这种结构化分析与AI驱动的解释相结合，代表了将复杂过程挖掘结果转化为可能采取行动的见解的一种新颖方法论进步。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21595", "html_url": "https://arxiv.org/abs/2508.21595", "title": "具有确定性动力学的Dec-POMDP的可扩展解决方案方法", "title_en": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "authors": "Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes", "background": "许多高级的多智能体规划问题，如多机器人导航和路径规划，可以通过确定性的动作和观测来进行有效建模。本文将重点关注此类领域，并引入确定性分散部分观测马尔可夫决策过程（Deterministic Decentralized POMDPs，Det-Dec-POMDPs）这一概念，即由确定性转换和基于状态及联合行动的确定性观测限定的Dec-POMDP的子类。现有的Dec-POMDP求解器对于大规模的Det-Dec-POMDPs无法提供有效的解决方案，这促使了本研究的进行，旨在寻找新的方法来处理这类问题。", "innovation": "本文提出了一个名为Iterative Deterministic POMDP Planning (IDPP)的实用求解器，该方法基于经典的联合均衡搜索策略框架，并特别针对当前的Dec-POMDP求解器无法有效处理的大规模Det-Dec-POMDPs进行了优化。", "conclusion": "本文提出了一种全新的Det-Dec-POMDP求解方法——IDPP，该方法专注于处理现有的Dec-POMDP求解器无法有效处理的大规模问题。该研究不仅扩展了多智能体规划的解决方法，也为未来的进一步研究奠定了基础。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21720", "html_url": "https://arxiv.org/abs/2508.21720", "title": "PosterForest：科学海报生成的分层多代理协作方法", "title_en": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "authors": "Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim", "background": "大部分现有的科学海报生成方法忽视了科学文档的层次结构以及文本和视觉元素的语义整合。该论文提出了一种无需训练的框架PosterForest，以解决这两个挑战，并通过分层中介表示方式来联合编码文档结构和多级的视觉-文本关系，引入了专门负责内容总结和布局规划的多代理协作策略，从而实现逻辑一致性、内容准确性和视觉一致性的联合优化。", "innovation": "提出了一种无需训练的框架PosterForest。该框架采用一种多代理协作策略，专门负责内容总结和布局规划的智能代理能够迭代地协调并互相提供反馈，从而实现科学海报在逻辑一致性、内容准确性、视觉一致性上的优化。引入了 Poster Tree，一种分层中介表示方式，用于同时编码文档结构和多级的视觉-文本关系。", "conclusion": "在多个学术领域的广泛实验表明，PosterForest 方法在定性和定量评估中都优于现有基线方法，生成的海报质量接近于由专家设计的原型，并在信息保存、结构清晰度和用户偏好方面表现优异。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21648", "html_url": "https://arxiv.org/abs/2508.21648", "title": "利用MEDLEY克服缺陷：一种多模型方法，利用医疗AI中的偏差", "title_en": "Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI", "authors": "Farhad Abtahi,Mehdi Astaraki,Fernando Seoane", "background": "医疗人工智能中的人类偏差通常被视为需要消除的缺陷。研究表明，人类的推理不可避免地包含由教育、文化和个人经验塑造的偏差，这使得这些偏差的存在难以避免且可能是有价值的。现有的方法通常试图消除模型之间的分歧，但MEDLEY系统提出了一种新的理念，通过保留不同模型的独特输出来利用这些分歧，而不仅仅是将其汇总为一致意见。", "innovation": "MEDLEY系统引入了医学诊断领域的一种全新方法，即利用AI模型之间的分歧作为潜在优势。它不仅保留了多样性的输出，而且还记录每个模型的特定偏差作为潜在的强项，并将幻觉视为需要临床验证的初步假设。这种方法通过结构化的多样性和临床监督来增强医疗推理，使其在医疗环境中更可信。", "conclusion": "尽管MEDLEY不是成熟的临床工具，但通过提供了一个原型，展示了如何在临床监督下利用AI的缺陷，从而提高医疗AI的信任度。该方法为医疗AI的未来开发提供了新的监管、伦理和创新途径。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21564", "html_url": "https://arxiv.org/abs/2508.21564", "title": "重新审视图式：从先前计划中学习以跨问题实例进行概括", "title_en": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances", "authors": "Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt", "background": "传统的图式提取算法在规划问题中表现不佳，尤其是当需要描述特定域中的中间目标时。本文旨在提出一种新的框架，用于自动生成适用于整个领域的图式，这些图式可以从一组已解决的问题实例中学习，并描述在传统图式提取算法不足的规划问题中的中间目标。这些图式超越了特定问题中的对象属性，而是应用于所有相似对象的状态函数，从而捕捉重复性。基于这些状态函数，构建了一个有向图式图，定义了图式的进展，包括重复子计划的循环可能性。通过这种方法，可以使用图式图在新的同一领域的问题实例中构建启发式方法。研究表明，从少量小实例学习得到的图式图对同一域中的较大实例也有效。如果识别到一个表明重复性的循环，启发式的性能显著优于基线。图式捕捉到了可解释且对自动规划者有用的领域信息，这些信息可以在同一域的少数几个计划中找到.", "innovation": "提出了一种新的框架，用于自动生成适用于整个领域的图式。这种图式可以从一组已解决的问题实例中学习，并描述在传统图式提取算法不足的规划问题中的中间目标。图式超越了特定问题中的对象属性，而是应用于所有相似对象的状态函数，从而捕捉重复性。基于这些状态函数，构建了一个有向图式图，定义了图式的进展，包括重复子计划的循环可能性。这使得该方法能够更有效地解决新的同一领域的问题实例，并且表现出对于更大规模问题实例的有效性。当识别到表明重复性的循环时，启发式的性能显著优于基线。", "conclusion": "从少量小实例中学习得到的图式图对于同一域中的较大实例也有效。如果识别到一个表明重复性的循环，启发式的性能显著优于基线。图式捕捉到了可解释且对自动规划者有用的领域信息，这些信息可以在同一域的少数几个计划中找到。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21622", "html_url": "https://arxiv.org/abs/2508.21622", "title": "将大型语言模型与网络优化集成以实现交互式和解释性供应链规划：一个真实案例研究", "title_en": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "authors": "Saravanan Venkatachalam", "background": "本文介绍了一种综合框架，该框架将传统网络优化模型与大型语言模型（LLMs）结合起来，为供应链规划提供互动、可解释且角色感知的支持决策。该系统通过生成自然语言摘要、上下文可视化和定制的关键绩效指标（KPIs），填补了复杂操作研究输出与业务利益相关者理解之间的鸿沟。核心优化模型解决了多期、多项目的网络分布中心战术库存重新分配问题，采用混合整数规划形式。技术架构包括AI代理、RESTful API和动态用户界面，以支持实时交互、配置更新和基于仿真见解的决策。案例研究展示了该系统如何通过预防缺货、减少成本和维持服务水平来改善规划结果。未来扩展包括集成私人LLMs、迁移学习、强化学习和贝叶斯神经网络，以增强可解释性、适应性和实时决策能力。", "innovation": "提出了将传统网络优化模型与LLMs结合的综合框架，以生成自然语言摘要、上下文可视化和定制KPIs，解决复杂操作研究输出与业务利益相关者理解之间的鸿沟。核心优化模型采用混合整数规划形式，用于多期和多项目的网络分布中心战术库存重新分配。技术架构包括AI代理、RESTful API和动态用户界面，支持实时交互、配置更新和基于仿真见解的决策。未来扩展包括集成私人LLMs、迁移学习、强化学习和贝叶斯神经网络，增强系统在可解释性、适应性和实时决策能力方面的表现。", "conclusion": "提出的系统通过预防缺货、减少成本和维持服务水平，显著改善了规划结果。未来将继续集成更先进的技术，如私人LLMs、迁移学习、强化学习和贝叶斯神经网络，以进一步提高系统的解释能力、适应性和实时决策能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21742", "html_url": "https://arxiv.org/abs/2508.21742", "title": "使用摘要因果图和忠实地分布的时间序列中因果关系的方向性", "title_en": "Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions", "authors": "Timothée Loranchet,Charles K. Assaad", "background": "时间序列分析中理解时间变量之间的因果关系是一项核心挑战，尤其是在因果结构不明的情况下。即使在无法完全指定完整因果结构时，专家也可以提供一个高层次的因果图概括，称为摘要因果图，它捕捉了不同时间序列之间的主要因果关系，同时忽略了微观层面的细节。", "innovation": "基于编码在摘要因果图中的背景知识，并假设访问到一个忠实于真实未知图的因果充分分布，论文提出了确保时间变量之间微观层次边的方向性的条件。研究结果为在有向图中方向化边缘提供了理论保证，即使存在宏观层次上的循环或双箭头边。这些发现为利用SCGs来指导复杂时间系统中的因果发现提供了实践指导，并突显了结合专家知识以提高根据观察时间序列数据进行因果推断的价值。", "conclusion": "研究结果提供了理论上的保证，即使在存在宏观层次上的循环或双箭头边的情况下，也可以实现时间序列中因果关系的方向化。这一发现强调了在复杂时序系统中利用专家知识进行因果推断的重要性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21730", "html_url": "https://arxiv.org/abs/2508.21730", "title": "冻结并征服：可复用的Ansatz求解旅行商问题", "title_en": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "authors": "Fabrizio Fagiolo,Nicolo' Vescera", "background": "本文讨论了旅行商问题（TSP），这是一个经典的组合优化问题，在现实世界中有广泛应用。传统的穷举法由于计算成本高昂，大规模实例难以求解。近年来，量子计算因其在处理这类组合优化问题上的潜力引起了广泛关注。但现有的量子算法在硬件成熟度和问题规模上都存在挑战。", "innovation": "本文提出了一个结合紧凑编码方式和优化-冻结-复用策略的变分量子算法。具体来说，首先通过模拟退火法优化电路拓扑（Ansatz），然后固定该拓扑结构并用于新实例，仅重新优化电路参数。这种方法避免了结构上的昂贵研究，使得算法可以直接在初级量子硬件（NISQ）上实施。实验表明，这种策略在较小规模问题上表现出良好的通用性和高效的求解能力，但在更大规模问题上存在一定的局限性。", "conclusion": "本文展示了该算法在小型和中型TSP问题上的优越性能，并且提出了冻结Ansatz可以显著减少解决方案时间同时不牺牲解决方案质量的观点。此外，本文还探讨了算法的扩展性限制、参数的“温启动”初始化策略以及其在更复杂问题上的应用前景，如车辆路径问题和车间排程。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21803", "html_url": "https://arxiv.org/abs/2508.21803", "title": "使用协作多代理大规模语言模型架构从SOAP笔记自动检测临床问题", "title_en": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "authors": "Yeawon Lee,Xiaoyang Wang,Christopher C. Yang", "background": "临床叙事的准确解释对于患者护理至关重要，但由于这些笔记的复杂性，自动化处理具有挑战性。虽然大型语言模型（LLMs）显示出潜力，但单一模型方法在高风险临床任务中可能缺乏所需的高度稳健性。", "innovation": "我们介绍了一种协作多代理系统（MAS），该系统模拟临床咨询团队的工作方式，通过专注于分析SOAP笔记中的主诉（S）和体征（O）部分来识别临床问题，模仿诊断推理过程。该系统由协调多个专家代理进行层次化、迭代式辩论的管理代理进行组织，以达成共识。", "conclusion": "我们的MAS在针对MIMIC-III笔记的420个样本进行评估时，动态多代理配置在识别充血性心力衰竭、急性肾损伤和败血症方面表现出一致的改进效果。质性分析显示，这种方法能够有效突出和权衡冲突证据，但偶尔可能受群体思维影响。通过模拟临床团队的推理过程，我们的系统为更准确、更 robust 和更可解释的临床决策支持工具提供了有前景的途径。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "本研究关注基于视觉的四足机器人运动控制，强调将本体感受与视觉结合以实现稳健控制的必要性。现有研究可能侧重于利用强化学习（RL）进行四足机器人的运动控制，但通常缺乏将本体感受和视觉信息有效结合的方法，这在视觉引导的四足机器人运动控制中尤为重要。", "innovation": "本文提出了QuadKAN，这是一种由Kolmogorov-Arnold Networks（KAN）实例化的分段参数化跨模态策略。QuadKAN框架采用了分段编码器处理本体感受信息，并采用分段融合头融合本体感受和视觉输入。此外，研究引入了多模态延迟随机化（MMDR）并通过Proximal Policy Optimization（PPO）进行端到端训练。研究结果表明，QuadKAN在不同的地形下，特别是在具有静态或动态障碍物的场合下，比现有的最佳方法（SOTA）表现出更高的回报、更长的距离和较少的碰撞。", "conclusion": "研究结果表明，分段参数化策略为稳健的视觉引导四足运动提供了一种简单、有效且可解释的替代方案。研究还承诺在接受后的某个时候会公开研究成果（代码/数据库）。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21637", "html_url": "https://arxiv.org/abs/2508.21637", "title": "A-MHA*: Anytime Multi-Heuristic A*", "title_en": "A-MHA*: Anytime Multi-Heuristic A*", "authors": "Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev", "background": "设计良好的图搜索启发式函数需要充足的领域知识。虽然可以设计出在某些搜索空间部分表现良好且与真实成本预估值相关的启发式函数，但它们可能在整个领域内不适用，从而影响搜索的最优性保证。Multi-Heuristic A* (MHA*) 算法使用多个部分良好但不适用的启发式函数来潜在地生成更快的次最优解。然而，原有的 MHA* 算法在搜索过程中不提供持续改进的能力，需要精心设置膨胀因子以获得一次性的次最优解。", "innovation": "本文提出扩展 MHA* 为一个实时版本，该版本可以快速找到可行的次最优解，并在其持续运行过程中不断改进该解，直到时间耗尽。此版本的算法思路受 Anytime Repairing A* (ARA*) 算法的影响。我们证明了 ARA* 概念在 MHA* 框架中的精确定位保持了原始的次最优性和完整性保证，并使 MHA* 能够以实时方式运行。此外，我们还在 3-D 路径规划领域和滑动拼图中测试了 A-MHA* 的性能，并将其与 MHA* 和其他实时算法进行了比较。", "conclusion": "A-MHA* 在保持 MHA* 的次最优性和完整性保证的同时，通过结合 ARA* 的思想使 MHA* 能够以实时方式运行，提供更好的次最优解。我们通过实验验证了此算法的有效性，并将其与其他算法进行了比较，表明 A-MHA* 在某些应用场景中具有优势。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk：使用Transformer网络进行墨水生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "本文探讨了使用基于Transformer的模型进行墨水生成的研究背景。现有的方法在捕捉全局依赖关系和保持输入文本与生成笔画点之间的对齐方面存在局限性。", "innovation": "本文提出了一种新的方法TrInk，这是一种基于Transformer的模型，通过引入按比例缩放的位置嵌入和高斯记忆掩码来增强交叉注意模块，以更好地实现输入文本与生成笔画点之间的对齐。此外，还设计了主观和客观的评估管道来全面评估手写生成的可读性和风格一致性。", "conclusion": "实验结果表明，基于Transformer的模型在IAM-OnDB数据集上，相对于先前的方法，字符错误率（CER）降低了35.56%，单词错误率（WER）降低了29.66%。提供了TrInk和基线模型的手写样本演示页面，展示其性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成进行模型驱动的量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "量子和混合量子-经典软件系统中的模型驱动方法可以帮助减少由于异构平台景观和开发人员技能缺乏而导致的成本和风险。", "innovation": "利用大型语言模型（LLMs）结合检索增强生成（RAG）管道进行模型到文本/代码的转换。利用Qiskit库将UML模型实例转换生成Python代码，并且实验结果显示精心设计的提示可以将CodeBLEU评分提高四倍以上。", "conclusion": "该研究方向未来可以通过进一步实验探讨其他问题和想法，例如将软件系统模型实例作为RAG管道的信息源，或者利用大型语言模型进行代码到代码的转换，比如移植使用案例。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21800", "html_url": "https://arxiv.org/abs/2508.21800", "title": "树引导扩散规划者", "title_en": "Tree-Guided Diffusion Planner", "authors": "Hyeonseong Jeon,Cheolhong Min,Jaesik Park", "background": "预训练的扩散模型在解决测试时引导控制问题上展现出了有前景的方法，但标准的梯度指导在非凸和非光滑的目标函数、约束条件和多奖励结构的现实场景中效果显著下降。近期的监督规划方法需要针对特定任务的训练或价值估计器，这限制了测试时的灵活性和零样本泛化能力。", "innovation": "作者提出了一种名为Tree-guided Diffusion Planner (TDP)的零样本测试时规划框架，通过结构化轨迹生成平衡探索与利用。TDP将测试时规划建模为树搜索问题，采用两阶段采样过程：首先通过无训练的粒子引导生成多样化的父轨迹以鼓励广泛探索，然后通过快速条件去噪并以任务目标为导向细化子轨迹。TDP通过探索不同的轨迹区域并在扩展的解空间中利用梯度信息弥补了梯度指导的局限，仅依赖预训练模型和测试时的奖励信号。", "conclusion": "TDP在三个不同的任务中表现优于现有的最佳方法：迷宫金块捡取、机器人手臂块操作和AntMaze多目标探索。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: 反偏见文本增强以通过语义三元组缓解各种似是而非的相关性", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型常常在训练数据中学习和利用伪相关性，使用这些非目标特征来指导其预测。这样的依赖会导致在未见数据上的性能下降和泛化能力差。为了解决这些问题，我们提出了一种更通用的反偏见数据增强形式，称为反偏见数据增强，它同时解决了多种偏见（如性别偏见、简单性偏见）并增强了对分布外数据的鲁棒性。", "innovation": "我们提出了CoBA：反偏见增强（CounterBias Augmentation），这是一种统一框架，在语义三元组级别操作：首先将文本分解为主题-谓词-宾语三元组，然后选择性地修改这些三元组以破坏伪相关性。通过从调整的三元组重建文本，CoBA生成反偏见数据，从而缓解伪模式。该方法不仅在下游任务上表现出更好的性能，还能有效减少偏见并增强对分布外数据的鲁棒性，提供了一个灵活且稳健的解决方案来应对伪相关挑战。", "conclusion": "通过广泛的实验，我们证明了CoBA 不仅在下游任务性能上有所改进，还能有效减少偏见并增强对分布外数据的鲁棒性，从而提供了一个灵活且稳健的解决方案来应对伪相关挑战。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob基准：基于MS$^{2}$蛋白质组学的片段离子概率预测", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质几乎执行所有细胞功能，并构成大部分药物靶点，因此对其分析是理解人类健康与疾病生物学的重要基础。串联质量分析（MS$^2$）是蛋白质组学的主要分析技术，通过离子化、裂解肽并使用质谱图识别和量化生物样品中的蛋白质，其中肽片段离子概率预测对提高肽识别的准确性至关重要，作为强度信息的补充。然而，当前方法依赖于全局裂解统计，假设片段概率在整个肽中均匀分布，这一假设从生物化学原理来看过于简化，限制了预测的准确性。", "innovation": "本文提出了Pep2Prob，这是首个全面的数据集和基准，专门用于肽特异性片段离子概率预测。该数据集包含从超过1.83亿高质量、高分辨率HCD MS$^2$质谱图中总结而来的608,780种独特前体（每个前体为一个肽序列和电荷状态配对）的片段离子概率统计。通过使用简单的统计规则和基于学习的方法建立了基线性能，并发现利用肽特异性信息的模型显著优于仅使用全局裂解统计的方法。进一步的基准模型性能表明，肽-裂解关系表现出复杂的非线性，需要采用先进的机器学习方法才能实现高性能。", "conclusion": "通过Pep2Prob数据集和基准，展示了利用肽特异性信息提高肽片段离子概率预测性能的可能性，并在不同模型复杂性下验证了高性能的必要性，从而提出了更精确的肽识别方法以深化对健康和疾病的理解。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control: Text-to-Image（T2I）生成模型中减轻不安全内容的安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像（T2I）生成模型方面取得了显著进展，但滥用这些模型的风险仍然引起了严重的安全担忧。模型开发者们已经开发了多种安全机制以应对这些问题，但现有的机制依然存在不足，例如在分布变化下易被规避，或者需要针对特定模型进行大量调整。", "innovation": "为了克服这些不足，本文提出了Safe-Control，这是一种创新的即插即用的安全补丁。它通过数据驱动策略和安全感知条件，在不改变现有模型核心结构的情况下注入安全控制信号，作为类似补丁的更新。Safe-Control 设计灵活，能够根据不断变化的安全要求构建不同版本的安全补丁并统一合并。此外，它的即插即用设计使它能够适应具有类似去噪架构的其他T2I模型。", "conclusion": "通过在六个不同且公开的T2I模型上的广泛评估，实验证明Safe-Control在降低不安全内容生成方面非常有效，同时能够保持良性图像的质量和文本对齐。与现有的七种最先进的安全机制相比，不论是在潜在不安全提示还是最新的对抗攻击下，Safe-Control都显著地改善了这一结果，将不安全内容生成的概率大幅降低至7%，而大部分基准方法约为20%。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO: 基于预估价值的策略优化方法及其在代理推理中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "批评自由的强化学习方法，尤其是在复杂任务中，特别受到广泛的关注，因为这些方法通过在策略内部进行多次抽样和比较来估计优势，这会促使策略陷入局部最优，并且增加计算成本。", "innovation": "提出了一种名为PVPO的方法，通过增加优势参考锚点和预抽样数据来增强强化学习效率。具体来说，使用参考模型提前进行仿真，并采用计算出的奖励分数作为参考锚点。这种方法有效地纠正了组内比较引入的累积偏差，大大减少了对抽样次数的依赖。同时，参考模型能够在预抽样过程中评估样本难度，从而有效选择高增益数据以提高训练效率。", "conclusion": "在两个领域的九个数据集上进行的实验显示，PVPO达到了最先进的性能，不仅在多个任务中展示了稳健的泛化能力，还展示了在不同规模模型上的可扩展性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：强化学习作为医疗AI的里程碑", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）标志着人工智能在医疗领域应用的根本转变。与传统模型依赖固定关联不同，RL系统通过尝试、反馈和长期奖励优化来学习，这引入了具有变革潜力的新风险。从信息融合的角度来看，健康RL通常整合来自多源的信号（如生命体征、实验室数据、临床笔记、成像和设备遥测），使用时间序列和决策级别的机制进行融合。这些系统可以在集中式、联邦式或边缘架构中运行，以满足实时临床的约束条件，并自然地跨越数据、特征和决策融合的不同层次。", "innovation": "本文创新性地将RL的兴起视为不仅仅是工具集的转变，而是在临床环境中向代理式智能的转变。通过立足医疗场景的约束条件，系统性地分析各种RL技术（包括基于模型和模型自由的方法、离线和批量受限制的策略以及奖励规范和不确定性校准的新兴策略）和应用趋势，同时深入探讨伦理、部署和技术设计等方面的挑战，并总结出对于安全、与人类价值观一致的政策学习的经验教训。", "conclusion": "本文不仅提供了一个技术路线图，还对未来强化学习在医疗人工智能中的新兴变革作用进行了批判性的反思，强调其在医疗领域的应用不应仅仅视作预测机器，而是作为具有代理能力的临床情报。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "全矩阵预条件因子的动态低秩近似在训练广义线性模型中的应用", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "自适应梯度方法如Adagrad及其变体在大规模优化中广泛使用，但其对角预条件矩阵的使用限制了参数相关性的捕捉能力。近似全矩阵自适应方法能够建模这些相关性，可能导致更快的收敛速度，但其计算和存储成本常在大规模模型中成为瓶颈。因此，需要一种能够在保持效率的同时建模参数相关性的优化器。", "innovation": "为了解决上述问题，本文提出了AdaGram优化器，它允许高效地进行全矩阵自适应梯度更新。具体来说，通过使用快速对称因式分解在每一步迭代中计算预条件化的更新方向，并利用矩阵积分方法维持优化轨迹中预条件器的低秩结构，从而减少了计算和存储的开销。实验结果表明，使用秩五及更小秩的近似时，AdaGram相较于对角自适应优化器具有更快的收敛速度或同等性能，显示了其在大规模模型自适应优化中的潜在应用价值。", "conclusion": "实验结果表明，使用秩五及更小秩的近似时，AdaGram相较于对角自适应优化器具有更快的收敛速度或同等性能。这表明AdaGram具有作为大型模型自适应优化扩展解决方案的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "利用混合深度学习和SAM评分从严肃游戏中识别时空EEG情绪", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "近年来，基于EEG的情绪识别研究取得了显著进展，无论是深度学习还是经典机器学习方法都有所建树。然而，大多数现有研究集中在二元效价预测或个体分类上，这限制了其在实际情感计算系统中的应用和推广。因此，本文提出了一个基于GAMEEMO数据集的统一、多层次的EEG情绪分类框架，该数据集包括14通道的EEG记录和连续的自我报告情绪评分（无聊、糟糕、平静、有趣），覆盖了28名参与者在四种情绪引发的游戏场景中的情况。本文的处理流程采用了结构化的预处理策略，包括时间窗口分割、混合统计和频域特征提取及z-score归一化，将原始EEG信号转换为稳健且具有区分力的输入向量。情绪标签基于正负情绪评分的平均极性进行二元效价分类，并且通过多类情绪分类预测最强烈的情绪状态，还采用细粒度的多标签表示，将情绪分为10个有序类别。", "innovation": "本文提出了一种基于GAMEEMO数据集的多层次EEG情绪分类框架，创新之处在于结合使用了时间和空间维度特征的混合预处理方法及多类情绪和细粒度多标签的情绪分类策略。此外，研究采用了广泛的模型进行评估，包括随机森林、XGBoost、SVM以及LSTM、LSTM-GRU等深度神经架构，并且实验结果表明LSTM-GRU模型在二元效价任务上表现出色，在多类和多标签情绪分类上也取得了较好效果。", "conclusion": "本文设计的EEG情绪识别框架显著提高了情绪分类的准确性和鲁棒性，特别是LSTM-GRU模型在多个任务上表现最优。这为在实际情感计算系统中应用EEG情绪识别提供了有效的解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程中的核心实践，能系统地评估由人类开发人员或大型语言模型生成的程序。然而，编写全面的单元测试具有挑战性，因此已经开始使用大型语言模型来自动化测试生成，但如何通过强化学习训练大型语言模型以生成高质量的测试方法的研究仍然不足。", "innovation": "本文提出了一种名为UTRL的新颖强化学习框架，用于训练大型语言模型生成根据编程指示生成高质量单元测试。UTRL的关键思想是通过强化学习以对抗的方式迭代训练单元测试生成器和代码生成器。实验结果表明，通过UTRL训练的Qwen3-4B生成的单元测试质量高于通过监督微调人类编写的真实单元测试进行训练的模型生成的单元测试，且所生成的代码评价更接近真实测试的评价。此外，与前沿模型GPT-4.1相比，UTRL训练的Qwen3-4B在生成高质量单元测试方面表现更好，从而突显了UTRL在训练大型语言模型任务方面的有效性。", "conclusion": "实验结果显示，通过UTRL训练的Qwen3-4B生成的单元测试质量优于使用监督微调训练的模型，且对比前沿模型GPT-4.1，在生成高质量单元测试方面具有优势，表明UTRL在训练大型语言模型生成高质量单元测试方面是有效的。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "可解释的、基于注意力增强双向长短期记忆神经网络的联合48小时温度、辐照度和相对湿度预测", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "论文提出了一种基于深度学习的框架，用于预测未来48小时的温度、辐照度和相对湿度，以支持智能暖通空调系统的模型预测控制。历史气象数据（2019-2022年）被用作训练数据，而2023年的数据则用于评估泛化能力。", "innovation": "1. 使用了堆叠双向长短期记忆网络（BiLSTM）与注意力机制，联合预测三个变量，捕捉时间和特征间的依赖关系。\n2. 历史气象数据包含编码的循环时间特征。\n3. 通过集成梯度量化特征贡献，注意力权重揭示了时间模式，提高了模型的可解释性。\n4. 综合多变量预测、基于注意力的深度学习和可解释性，推动了数据驱动的天气预测。\n5. 预测结果在温度、辐照度和湿度上的均方绝对误差分别为1.3摄氏度、31瓦/平方米和6.7百分点，优于最先进的数值天气预测和机器学习基准。", "conclusion": "该工作展示了联合预测的准确性和透明度，突显了框架在通过可靠的短期气象预测实现节能建筑控制方面的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "HiddenObject: 基于Mamba的多模态隐藏目标检测的模态无关融合方法", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中，遮挡、伪装和光照变化等因素严重妨碍了对隐藏或部分遮挡对象的检测性能。传统基于RGB的方法在恶劣条件下常常失效，因此需要更 robust、模态无关的方法来应对这些挑战。本研究旨在解决这一难题，开发了一种融合框架HiddenObject，该框架利用了RGB、热成像和深度数据。", "innovation": "HiddenObject使用Mamba融合机制综合了RGB、热成像和深度数据，可以在统一表示中捕获跨模态的互补信号，从而增强对隐蔽或伪装目标的检测能力。该方法能识别特定模态的特征并在统一表示中融合这些特征，使得在复杂场景中的泛化能力更强。通过多个基准数据集验证了HiddenObject的表现，显示了其与现有方法相比的优越性或竞争力，同时指出了当前单模态和简单融合策略的关键限制。", "conclusion": "研究结果表明，基于Mamba的融合架构可以显著提高在视觉退化或复杂条件下的多模态目标检测性能。更广泛地说，这一发现表明Mamba融合架构可以促进多模态目标检测领域的进步。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21153", "html_url": "https://arxiv.org/abs/2508.21153", "title": "WaveLLDM：设计和开发一种轻量级潜在扩散模型进行语音增强和恢复", "title_en": "WaveLLDM: Design and Development of a Lightweight Latent Diffusion Model for Speech Enhancement and Restoration", "authors": "Kevin Putra Santoso,Rizka Wakhidatus Sholikah,Raden Venantius Hari Ginardi", "background": "高质量的音频在在线通信、虚拟助手和多媒体行业中是必不可少的，但噪声、压缩和传播缺陷等原因导致的降质仍然是一个主要挑战。尽管扩散模型在音频修复方面已经展现出有效性，但它们通常需要大量的计算资源，难以处理更长的缺失部分。", "innovation": "本文介绍了一种名为WaveLLDM（Wave Lightweight Latent Diffusion Model）的架构，该架构结合了高效的声音神经压缩与潜在扩散，用于音频恢复和降噪。WaveLLDM与传统在时域或频域操作的方法不同，它在压缩的空间中处理音频，从而降低了计算复杂性，同时保持了重建质量。实证研究表明，WaveLLDM在Voicebank+DEMAND测试集上实现了准确的频谱重建，并具有良好的对未见过数据的适应性，但其感知质量、语音清晰度等方面仍不及最先进的方法。", "conclusion": "尽管WaveLLDM在性能上存在一些限制，但其灵活的架构结合了神经音频编码器和潜在扩散模型，为未来的发展提供了坚实的基础。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深度残差回声状态网络：探索未训练递归神经网络中的残差正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "回声状态网络（ESNs）是一种特殊的未训练递归神经网络（RNNs），通常用于快速和高效的训练。尽管ESNs在最近时间信息处理上表现出色，但在长时信息处理方面常常存在问题。本文基于时间残差连接引入了一种新的多层次深度未训练递归神经网络——深度残差回声状态网络（DeepResESNs），以解决这个长期存在的问题。", "innovation": "介绍了基于时间残差连接的DeepResESNs，通过多层次未训练的残差递归层，显著提升了记忆容量和长时序建模能力。探讨了不同正交配置（随机生成和固定结构）的时间残差连接对网络动态的影响，并通过详细的数学分析明确了确保DeepResESN动态稳定的必要和充分条件。", "conclusion": "在各种时间序列任务上的实验结果表明，提出的DeepResESN方法在传统浅层和深层递归计算框架下具有显著优势。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21112", "html_url": "https://arxiv.org/abs/2508.21112", "title": "EmbodiedOneVision：通过交错视觉-文本-行动预训练实现通用机器人控制", "title_en": "EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control", "authors": "Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang", "background": "人类有能力在开放环境中无缝进行多模态推理和物理互动，是通用躯体智能系统的核心目标。近期视觉-语言-行动（VLA）模型在大规模机器人和视觉文本数据上的联合训练，展现了在通用机器人控制方面的显著进步。然而，这些模型尚未达到人类级别的灵活性，特别是在交织的推理和互动方面。", "innovation": "本文引入了EO-Robotics，包括EO-1模型和EO-Data1.5M数据集。EO-1是统一的躯体基础模型，通过交错的视觉-文本-行动预训练实现了多模态躯体推理和机器人控制的优越性能。该模型基于两个关键支柱：统一的架构可以处理涉及图像、文本、视频和行动的多模态输入，以及包含超过150万个高质量多模态躯体推理样本的大规模数据集，这些样本特别注重交织的视觉-文本-行动理解。EO-1通过在EO-Data1.5M上利用自回归解码和流动匹配去噪之间的协同作用进行训练，实现了无缝的机器人行动生成和多模态躯体推理。", "conclusion": "广泛的实验表明，交错的视觉-文本-行动学习对于开放世界的理解和泛化具有有效性，这种能力已经通过一系列长时序的灵巧操作任务在多个代理体中得到了验证。该论文详细描述了EO-1的架构、EO-Data1.5M的数据构建策略以及训练方法，为开发先进的躯体基础模型提供了宝贵见解。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg: 使用联合三维放射高斯重建和三维/三维配准的脊柱CT与双平面X射线配准", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导导航中，CT/X射线配准由于其对高精度和实时性能的严格要求而具有挑战性。传统‘渲染和比较’方法依赖于迭代投影和比较，导致空间信息丢失和领域差距。通过双平面X射线进行三维重建可补充二维/三维配准的空间和形状信息，但当前方法受限于密集视角要求和噪声X射线的处理困难。为解决这些限制，介绍了RadGS-Reg，一种通过联合三维放射高斯（RadGS）重建和三维/三维配准的新型脊柱CT/X射线配准框架。", "innovation": "RadGS-Reg框架包括双平面X射线椎体RadGS重建模块，采用基于学习的RadGS重建方法，并结合Counterfactual Attention Learning（CAL）机制，专门针对噪声X射线中的椎体区域。此外，采用患者特定的先验训练策略，逐步将RadGS-Reg从模拟数据过渡到实测数据，同时学习椎体形状先验知识。实验结果在自建数据集中表现出最先进的性能，优于现有方法。该代码可在指定链接中获取。", "conclusion": "该研究表明，RadGS-Reg在脊柱CT/X射线配准中表现出色，解决了传统方法的局限性，特别是在处理噪声数据方面。该方法可通过联合学习增强脊柱重建和配准的实时性和准确性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE: 灵活的决策树集成遗忘算法", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "决策树集成在分类任务中表现出色，广泛应用于生物信息学、金融和医学诊断等多个领域。为了保护数据隐私和个人隐私权，即所谓的‘被遗忘权’，已有许多遗忘算法被提出，用于使决策树集成忘记敏感信息。然而，现有的方法通常局限于特定模型或依赖于决策树的离散结构，这使得它们难以扩展到复杂的集成模型中，并且对于大规模数据集来说效率低下。", "innovation": "我们提出了一种新的决策树集成遗忘算法 FUTURE。该算法将忘记样本的问题形式化为基于梯度的优化任务。为了应对决策树集成中的非可微性，我们采用了概率模型近似，在优化框架中实现这一优化任务。这种方法能在有效且高效的方式下实现端到端的遗忘。", "conclusion": "在实际数据集上的大量实验表明，FUTURE 能够实现显著且成功的遗忘效果。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签诱导偏差的自评与互评", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "大型语言模型（LLMs）在评价输出时越来越普遍，然而它们的判断可能会受到其他因素的影响。本文研究了ChatGPT、Gemini和Claude三种模型在不同标签条件下的自评和互评中存在的偏差问题。具体地，通过四种条件下的评估（无标签、真实标签、以及两个虚假标签情景）来探讨模型之间的评价差异。研究通过对模型自评和互评的偏好投票以及对于连贯性、信息性和简洁性三项质量评分的分析，发现模型对不同标签的反应存在明显的不对称性，证据表明标签对模型评价结果产生重大影响，改变了模型间的排名顺序和质量评分。", "innovation": "本研究通过四种实验条件下的评估，探讨了大型语言模型在自评与互评中标签诱导的偏差问题。特别地，研究结果揭示了Claude模型在不同标签条件下的得分变化方向与Gemini模型相反，以及假标签对模型评分产生的重要影响。这些发现展示了模型认同感对高级判断和详细质量评分的显著扭曲作用，强调了在评估LLMs时采用盲评或多元模型评估方案的必要性，以确保评估的公平性。", "conclusion": "本文的研究结果表明，感知到的模型身份可以极大地扭曲高级判断，并且微妙地影响详细的质量评分。研究建议在LLM基准测试中应采取盲评或多元模型评估方案来确保评估的公平性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过二元退火和强化学习激励全方位自动思考能力的大规模多模态语言模型", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大规模语言模型（MLLMs）在复杂推理问题上取得了显著的性能，然而在简单的不需要复杂推理的问题上，这种思考过程显得冗余。为此，为了解决这种低效率，作者提出了R-4B，一种具有自动思考能力的MLLM，该模型可以根据问题的复杂性灵活决定何时进行思考。", "innovation": "R-4B的核心理念是通过二元退火和Bi-mode Policy Optimization (BPO)增强模型同时具备思考和非思考的能力。首先，模型在涉及不同主题的精挑细选的数据集上进行训练，该数据集包括思考和非思考模式的样本。其次，在改进的GRPO框架下进行第二阶段训练，使策略模型的输出必须来自每个输入查询的两种模式。实验结果表明，R-4B在25个具有挑战性的基准测试中达到最先进的性能，其大多数任务上的表现超过Qwen2.5-VL-7B，并在推理密集型基准测试中表现出接近Kimi-VL-A3B-Thinking-2506（16B）的性能，但计算成本更低。", "conclusion": "R-4B通过激励全方位的自动思考能力，在不需要繁琐推理的情况下也能表现出色，且具备较低的计算成本。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "自动化的深空网络数据系统：基于有agency的人工智能的自适应异常检测案例研究", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "深空网络（DSN）是NASA最大的天线设施网络，产生大量多元时间序列数据，这些天线和发射机在长时间运行中可能发生退化，可能导致数据流中断，威胁到依靠DSN通信的数十颗深空探测器的地球连接。本文的研究目的是通过分析和检测数据中的异常和设备退化，为JPL工程师提供直接的支持，并确保未来深空任务的持续运行和维护。因此，研究者们探讨了多种机器学习方法，用于通过预测分析完全重建数据，并使用统计计算和阈值确定实时数据集中的异常数据条目。除此之外，还引入了强化学习子系统和大型语言模型来对异常数据进行分类和解释，这些都可以通过人工反馈进行改进和精细化调优。对于DSN发射机，还实施了一个完整的数据管道系统，将数据提取、解析和处理流程全部整合，提供了一种从前缺少的统一程序或脚本。通过这个数据管道系统，还包括了DSN天线数据训练的模型，完成了DSN异常检测的数据流程。这一切都通过一个有agency的AI系统整合起来，利用复杂推理来确定异常数据的分类和预测", "innovation": "本研究引入了多种创新技术，包括：1）使用机器学习进行数据的完全重建和异常检测；2）使用强化学习子系统对异常进行分类；3）使用大型语言模型对异常数据进行解释；4）建立了一个数据管道系统，整合了数据提取、解析和处理流程；5）通过有agency的AI系统，进行异常数据的分类和预测，基于复杂推理进行决策", "conclusion": "利用机器学习、强化学习、大型语言模型和数据管道系统，本文成功实现了DSN数据系统的自动化，通过有agency的AI系统，能够有效检测并分类异常数据，提供支持给JPL工程师进行故障定位和维护。研究还表明，通过持续的人工反馈，这些技术可以不断改进和优化，为未来深空任务提供更好的保障"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大型语言模型：从数据基础到智能体前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大型语言模型（Sci-LLMs）正在改变科学研究中知识的表现、整合和应用方式，但其发展受科学数据复杂性质的影响。关于Sci-LLMs的研究缺乏一个全面的数据为中心的综合分析，即从模型和其底层数据载体的共同进化角度来看待发展过程。这项研究填补了这一空白，形成了一种统一的科学数据分类法和层次化的科学知识模型。文章系统地回顾了从通用基础模型到跨学科专业模型的各种Sci-LLMs，分析了超过270个预训练/训练数据集，揭示了Sci-LLMs的独特需求，如多模态、跨尺度、领域特定的数据集，需要保持领域不变性和支持跨模态推理的能力。此外，本文还评估了超过190个基准数据集，强调评估方式从静态考点向基于过程和发现的评估转变，表明需要更加高级的评估协议。", "innovation": "重新定义了Sci-LLMs的发展为模型与其底层数据载体的共同进化过程。本文首次提出了统一的科学数据分类法和层次化的科学知识模型，强调科学语料库与通用自然语言处理数据集之间在多模态、跨尺度和领域特定上的差异。通过系统回顾各种Sci-LLMs，并分析了超过270个预训练/训练数据集，揭示了Sci-LLMs独特的需求，包括异质性、多尺度、带有不确定性的语料库，需要能够保持领域不变性和支持跨模态推理的能力。评估方面引入了动态的评估范式，从静态评估转向面向过程和发现的评估，同时使用高级的评估协议。此外，本文还讨论了半自动标注管道和专家验证等新兴解决方案。", "conclusion": "本文为构建可信赖的、不断进化的智能系统提供了蓝图，这些系统能够在加速科学研究中作为真正伙伴发挥作用。最终，本文提出了一种闭环系统模式，其中基于Sci-LLMs的自主智能体能够自主地进行实验、验证，并为持续进化的知识库贡献力量。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：一种高效的自我一致性幻觉检测流水线", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大语言模型（LLMs）已经在研究和实际应用中展现出卓越的表现，但仍难以避免幻觉问题。现有的幻觉检测方法在句级生成上表现不佳，或者需要大量的领域特定知识。虽然自一致性方法有助于解决这些问题，但它们会因为重复生成而导致高计算成本。", "innovation": "该论文首次研究了在自一致性方法中识别冗余问题，即在多次生成中存在共享前缀标记的现象，并发现非精确答案的标记对语义内容的贡献较少。基于此洞察，论文提出了一种新型的解码记忆流水线（DMP），通过选择性推理和退火解码加速生成过程。该方法与模型、数据集、解码策略和自一致性基线无关，并在多项实验中显著提高了多响应生成的效率，显示出向对齐和推理任务扩展的潜力。", "conclusion": "广泛的实验表明，使用该方法可以实现最高3倍的速度提升，同时不牺牲AUROC性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过视觉上下文提示实现通用对象再识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前的对象再识别（ReID）方法训练特定领域模型（例如针对人员或车辆），但这些模型缺乏泛化能力，并且对新类别需要大量的标注数据。自我监督学习虽减少了标注需求，但在捕捉关键的‘身份敏感’特征方面存在困难，这些特征对ReID至关重要。", "innovation": "该论文提出了一种新的框架——视觉上下文提示（VICP），该框架可以让在已见类别上训练的模型通过仅使用上下文提示直接泛化到未见的新类别，无需参数调整。VICP结合了语言预训练模型（LLM）和视觉基础模型（VFM），通过少量的正负样本对推断语义身份规则，然后指导VFM提取身份区分性特征。通过将LLM推断的语义概念与VFM的预训练先验对齐，VICP实现了对新类别的泛化，消除了数据集特定的重新训练需求。", "conclusion": "通过ShopID10K数据集和多种ReID基准测试的实验，该论文证明了VICP在未见类别上显著优于基线模型，并且提供了解释性的代码。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "BED-LLM: 使用大型语言模型和贝叶斯实验设计的智能信息收集", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "本文提出了一个通用方法，旨在提升大型语言模型（LLMs）根据用户或外部来源智能且自适应地收集信息的能力，这主要基于贝叶斯实验设计（BED）的框架。通过这种方法，LLMs可以作为有效的多轮对话代理，并与外部环境进行互动。文中还介绍了如何通过整合LLMs所获取应对任务信息的信念分布来实现信息量增益（EIG）的原理化计算。", "innovation": "该方法的一个特别创新之处在于精心设计的信息量增益（EIG）估计器，并不仅仅依赖于上下文更新来基于前文回应进行条件约束。此外，该方法还包括一个针对性的问题建议策略，这些创新对于BED-LLM的成功至关重要。", "conclusion": "实验结果表明，BED-LLM在20个问题游戏以及使用大型语言模型主动推断用户偏好的多种测试中，相较于直接提示和其它自适应设计策略，都取得了显著的性能提升。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21248", "html_url": "https://arxiv.org/abs/2508.21248", "title": "使用SSL模型层间特征的儿童语音零样本KWS", "title_en": "Zero-Shot KWS for Children's Speech using Layer-Wise Features from SSL Models", "authors": "Subham Kutum,Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Mahesh Chandra Govil", "background": "在成人语音中，已有许多方法被提出以增强关键词识别（KWS）的性能，但儿童的语音对KWS系统提出了独特的挑战，因为它们具有不同的声学和语言特征。", "innovation": "本文提出了一种零样本KWS方法，该方法利用了最先进的自监督学习（SSL）模型，包括Wav2Vec2、HuBERT和Data2Vec。从这些SSL模型中逐层提取特征，并用于训练基于Kaldi的DNN KWS系统。该方法在WSJCAM0成人口语数据集上进行训练，在PFSTAR儿童口语数据集上进行测试，展示了其零样本能力。该研究进一步证明了该方法在不同年龄段儿童上的有效性，特别是在噪声环境下的鲁棒性。", "conclusion": "结果强调了SSL特征在提高儿童口语零样本KWS性能方面的显著贡献，有效应对了儿童说话者具有独特特征所带来的挑战。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "从复制动力学到softmax平衡的流形轨迹在下一个令牌预测中", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "大型语言模型中的解码步骤通常被描述为对令牌打分并使用softmax进行规范化。本文提供了一个关于此步骤的极简、独立的描述，将其视为在概率单纯形上的受限变分原理。进一步分析表明，对固定的上下文和温度，下一个令牌的分布将沿单纯形内遵循一条光滑的路径并最终收敛到softmax平衡。", "innovation": "文章通过将离散且保持规范化的上升过程解析为经典的乘性权重更新（对数镜像更新），并通过连续时间极限得出复制动力学，证明了下一个令牌的分布随着时间沿着固定轨迹平滑移动并最终收敛到softmax平衡。此外，分析还揭示了温度等参数的精确实践影响，并指出top-k和nucleus采样限制了流的变化，但保持相同的保证。", "conclusion": "此工作为解码行为提供了具体、实践导向的解释，指出温度作为一种准确的时间尺度调整因子，在相同轨迹上进行精确缩放。通过细致解析这些步骤，文章还提出了一种对依赖路径的分数调整的控制性描述，并探讨了其与产生似然幻觉行为的联系。未来工作将致力于训练动态和内部表示的研究。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21243", "html_url": "https://arxiv.org/abs/2508.21243", "title": "Full-Frequency Temporal Patching and Structured Masking for Enhanced Audio Classification", "title_en": "Full-Frequency Temporal Patching and Structured Masking for Enhanced Audio Classification", "authors": "Aditya Makineni,Baocheng Geng,Qing Tian", "background": "Transformers和State-Space Models通过将频谱图像表示为补丁序列来推进了音频分类任务。然而，现有模型如Audio Spectrogram Transformer (AST)和Audio Mamba (AuM)采用了来自计算机视觉领域的方形单元切分方法，这破坏了连续的频率模式并产生了过多的补丁，从而减慢了训练速度并增加了计算量。", "innovation": "提出了全频带时域补丁策略（Full-Frequency Temporal Patching，FFTP），它通过局部时域上下文覆盖整个频率带宽来更好地匹配频谱图像的时间-频率不对称性，保留谐波结构并显著减少补丁数量和计算量。同时引入了SpecMask，一种与补丁对齐的频谱增强方法，通过在固定的遮盖预算下结合全频带和局部时频掩码，增强了时间鲁棒性并保持了频谱连续性。", "conclusion": "在AST和AuM上应用FFTP和SpecMask的方法，在AudioSet-18k上改善了mAP最多6.76%，在SpeechCommandsV2上提高了准确率最多8.46%，并减少了计算量达83.26%，从而证明了性能和效率的提升。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "利用群对比策略优化的强化学习改进航空安全分析", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析航空事故背后的人因因素对于防止未来事故至关重要，但传统使用人因分析和分类系统（HFACS）的方法在规模化和一致性方面存在限制。为了应对这一挑战，本文提出了一种基于强化学习与群对比策略优化（GRPO）的自动化HFACS分类框架，用于航空安全分析，同时结合多组件奖励系统和合成数据生成以解决事故数据集中的类别不平衡问题。", "innovation": "研究引入了一种新的自动化HFACS分类框架，利用GRPO优化Llama-3.1 8B语言模型，通过设计专门的多组件奖励系统以及合成数据生成技术，解决了HFACS分类中的类别不平衡问题。该模型在精确匹配准确性和部分匹配准确性方面均实现了显著提升，尤其在关键指标上优于包括GPT-5-mini和Gemini-2.5-fiash在内的当前最先进的大型语言模型。此外，提出了一种新的基准方法来评估语言模型的高级推理能力，即多标签HFACS分类问题中的精确匹配准确率。", "conclusion": "通过将具有针对性的优化模型部署在资源受限的边缘设备上，本研究证实了小型、领域优化模型能够提供高效且更优的安全分析解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21252", "html_url": "https://arxiv.org/abs/2508.21252", "title": "量子机器学习在量子传感器电路中优化纠缠分布的应用", "title_en": "Quantum Machine Learning for Optimizing Entanglement Distribution in Quantum Sensor Circuits", "authors": "Laxmisha Ashok Attisara,Sathish Kumar", "background": "在量子计算快速发展的背景下，优化特定任务的量子电路对于提高性能和效率至关重要。近年来，量子传感已经成为量子科学与技术领域中一个独特且迅速增长的研究分支。量子传感有望提供新的机会，特别是关于高灵敏度和测量精度方面。纠缠是实现高灵敏度和测量精度的关键因素之一。", "innovation": "本文提出了一种利用量子机器学习技术优化量子传感器电路中纠缠分布的新方法。通过在量子环境中利用强化学习来优化纠缠布局，以最大化量子费舍尔信息(QFI)和纠缠熵（这是量子系统灵敏度和相干性的关键指标），同时减少电路深度和门数。此外，本文的实现基于Qiskit，结合了噪声模型和误差缓解策略以模拟现实的量子环境。", "conclusion": "实验结果显示，通过量子机器学习优化量子电路性能和灵敏度方面取得了显著改进，特别是测得的高QFI和熵值范围在0.84-1.0，同时电路深度和门数的减少达到20%-86%。这表明机器学习在量子电路优化方面具有巨大潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21246", "html_url": "https://arxiv.org/abs/2508.21246", "title": "HCQA: 混合经典-量子代理生成最优量子传感器电路", "title_en": "HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits", "authors": "Ahmad Alomari,Sathish A. P. Kumar", "background": "该研究旨在通过解决复杂的量子物理问题来设计最优的量子传感器电路（QSCs）。传统的量子电路设计方法效率低下且难以实现最优解。研究人员提出了一个混合经典-量子代理（HCQA），结合了深度Q网络（DQN）的学习和策略优化能力，并通过基于量子操作选择机制增强了行动选择过程，以促进量子状态的纠缠和优化量子鱼信息（QFI）的提升。这为自动生成高QFI敏感性纠缠量子态以进行量子状态估计和控制提供了可能。", "innovation": "该研究创新性地提出了一种混合经典-量子代理（HCQA），通过引入深度Q网络（DQN）和量子操作选择机制来优化量子传感器电路的设计。该方法能够高效地生成最大化量子鱼信息（QFI）并同时减少电路中量子门数量的量子传感器电路，尤其适用于生成高QFI敏感性纠缠量子态。", "conclusion": "该研究展示了人工智能驱动的学习与量子计算之间的协同作用，展示了智能代理如何自主发现用于增强感知和估计任务的最优量子电路设计。实验结果表明，该方法在一个包含两个量子位和若干旋转变换门的量子传感器电路中能够高效地生成最优的量子传感器电路，且量子鱼信息（QFI）达到1。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "自动语音识别（ASR）系统在处理儿童语音时常面临诸多挑战，因儿童语音具有独特的和高度变化的声学和语言特征。虽然最新的自监督学习（SSL）模型在处理成人语音方面取得了显著进步，但儿童语音的转录依然是一个巨大难题。本文针对这一问题，研究了利用Wav2Vec2、HuBERT、Data2Vec和WavLM等先进SSL预训练模型的层级特征，提高零样本情境下儿童语音ASR性能的有效性。", "innovation": "文章引入了层级别SSL特征在零样本ASR性能优化中的应用，并选取了Wav2Vec2、HuBERT、Data2Vec和WavLM四种模型，进行细致的功能分析以提升针对儿童语音的ASR性能。实验发现，Wav2Vec2的第22层特征能将词错误率（WER）从10.65%降低到5.15%，显示出显著的进步。进一步分析发现，在不同年龄段的儿童语音中均显示出性能的持续提升，特别是在较年轻组别儿童的语音识别中也取得了显著效果。这是一个在ASR领域针对儿童语音识别上的创新尝试，为处理该问题提供了新的思路和方法。", "conclusion": "研究表明，利用SSL预训练模型的层级特征能够显著提升零样本下儿童语音的ASR性能，特别是在WSJCAM0成人语音训练和PFSTAR儿童语音测试的数据集上，Wav2Vec2的第22层特征的表现尤为突出。此外，不同年龄段儿童语音的分析显示，随着年龄的增长，性能提升更为明显，但年轻组别的增益也非常显著。这项研究为儿童语音识别领域提供了新的技术支持，展示了该方法的普适性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21259", "html_url": "https://arxiv.org/abs/2508.21259", "title": "突破冷启动障碍：双重和共用DQN的强化学习", "title_en": "Breaking the Cold-Start Barrier: Reinforcement Learning with Double and Dueling DQNs", "authors": "Minda Zhao", "background": "推荐系统在处理新用户（冷用户）时面临挑战，尤其是当这些用户的交互历史较短时，难以提供准确的建议。这是一个被称为冷用户问题的挑战。", "innovation": "本文提出了一种使用双重和共用深度强化学习方法（DQN）的策略，旨在从稀疏反馈中动态学习用户偏好，从而提高推荐准确性，而无需依赖敏感的人口统计学数据。通过将这些高级DQN变体与矩阵因子化模型结合，研究结果表明，与传统的基于流行度和主动学习策略相比，在大规模电子商务数据集上达到了更好的性能。", "conclusion": "实验证明，特别是共用DQN减少了冷用户场景下的均方根误差（RMSE），为隐私受限环境中提供了一种有效解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "增强外部气动学中代理建模的一种专家混合门控网络", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "在汽车设计和优化周期中，高保真CFD模拟的计算成本仍然是一个显著的瓶颈。虽然基于机器学习的代理模型作为加速气动力学预测的有希望的替代方案已出现，但该领域由各种专业的神经网络架构组成，并且不断演变，没有一种模型能展示普遍的优势。", "innovation": "本文提出了一种新的元学习框架，利用了架构多样性作为优势。提出了一个混合专家（MoE）模型，该模型使用专门的门控网络动态且优化地组合来自三个异构最先进的代理模型（DoMINO，X-MeshGraphNet，FigConvNet）的预测。该门控网络学习空间变权策略，根据专家在其预测表面压力和壁面剪切应力场中的局部性能赋予其可信度。为了防止模型崩溃并鼓励专家的均衡贡献，将熵正则化项集成到训练损失函数中。整个系统在大型公共基准DrivAerML数据集上进行训练和验证。定量结果显示，MoE模型在L-2预测误差方面取得了显著降低，优于整个集合平均值和所有评估物理量中最准确的个体专家模型。本工作证明了MoE框架通过协同结合专业架构的互补优势，可以为创建更稳健和准确的复合代理模型提供强大的有效策略。", "conclusion": "本研究建立了一种新的混合专家框架（MoE），通过协作结合不同专业的架构优势，证明了其在高保真的CFD模拟中创建更稳健和准确的代理模型的强大和有效策略。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21253", "html_url": "https://arxiv.org/abs/2508.21253", "title": "使用强化学习优化基于大量量子位阵列的量子传感器电路", "title_en": "Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits", "authors": "Laxmisha Ashok Attisara,Sathish Kumar", "background": "随着量子传感器中量子位数量的增加，设计和控制量子电路的复杂性呈指数增长。手动优化这些电路变得不再可行。优化大规模量子电路中的纠缠分布对于提高量子传感器的灵敏度和效率至关重要。本文介绍了一种将强化学习与张量网络基模拟（MPS）工程集成的方法来优化具有最多60个量子位的量子传感器电路。", "innovation": "为实现高效模拟和可扩展性，采用了张量网络方法，特别是矩阵乘积态（MPS）表示法，而不是传统状态矢量或密度矩阵方法。强化学习代理学会重构电路以最大化量子场信息（QFI）和纠缠熵，同时减少门数和电路深度。", "conclusion": "实验结果表明，QFI值接近1，纠缠熵在0.8-1.0的范围内，深度和门数最多可减少90%。这些结果突显了结合量子机器学习和张量网络来在现实约束条件下优化复杂量子电路的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "从代码生成模型中构建高效的代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "代码检索、技术问答以及不同编程语言之间的语义相似代码片段的识别是软件开发中常见的需求，现有方法可能在性能上存在一定的限制。", "innovation": "提出了一个新的代码嵌入模型套件jina-code-embeddings，该模型使用了基于文本和代码的自回归预训练模型，并通过最后一个token池化的策略生成嵌入。这一模型在相对较小的模型规模下取得了领先性能，验证了这种方法在代码嵌入模型构建上的有效性。", "conclusion": "研究表明，尽管模型规模较小，jina-code-embeddings仍然能实现卓越的性能，表明了这种构建代码嵌入模型的方法的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "使用较少数据进行肺部疾病严重程度分类的深度主动学习：面对类别不平衡时的学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "在使用胸部X射线(CXR)对肺部疾病严重程度进行分类时，由于数据标记的成本高且存在类别不平衡问题，研究提出一种方法来减少所需的标记数据量。该研究回顾性地收集了2020年1月至11月间Emory Healthcare附属医院963名（平均年龄59.2岁，481名女性）患者的2,319张CXR影像，所有患者均被临床确认为感染了COVID-19。通过3至6名认证的放射科医生独立标记每张影像为正常、中度或严重。利用深度贝叶斯神经网络(BNN)近似和加权损失函数的深度主动学习，训练了一个包含蒙特卡洛dropout的深度神经网络，以分类肺部疾病严重程度。通过逐步选择未标记池中最具有信息性的样本，研究采用了多种获取函数进行迭代，使用准确率、ROC曲线下面积和PR曲线下面积进行了性能评估。", "innovation": "该研究提出了一种结合深度主动学习、贝叶斯神经网络(BNN)逼近和加权损失函数的方法，以减少肺部疾病严重程度分类所需的标记数据量。该方法针对类别不平衡有效减少了标记数据需求，并在迭代过程中选择最具有信息性的样本，有效地提高了性能。相比更复杂的获取策略，该方法更为高效且节省计算资源，成功地实现了在分类表现上的维持或超越。", "conclusion": "该方法采用深度学习与贝叶斯神经网络逼近技术结合加权损失函数，有效减少了必要标记数据量，解决了类别不平衡问题，且在评价指标上达到了或超过传统方法的性能，显著降低了疾病的诊断或监测中所需的标注成本。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21285", "html_url": "https://arxiv.org/abs/2508.21285", "title": "对LLM进行金融脑扫描", "title_en": "A Financial Brain Scan of the LLM", "authors": "Hui Chen,Antoine Didisheim,Luciano Somoza,Hanqing Tian", "background": "新兴的计算机科学技术使得能够对大型语言模型（LLMs）进行“脑扫描”，识别其推理背后的简单英语概念，并在保持其他因素不变的情况下引导它们。该方法可以将LLM生成的经济预测映射到诸如情绪、技术分析和时机等概念上，并计算它们的重要性，在不降低性能的前提下实现此目标。此外，模型还可以被调节为更倾向于规避风险、乐观或悲观，这使得研究者能够纠正或模拟偏见。该方法具有透明性、轻量级和可复制性，适用于社会科学的实证研究。", "innovation": "该研究通过新兴技术直接对大型语言模型进行‘脑扫描’，识别其背后的简单英语概念，计算其生成经济预测时不同因素的重要性，并能调节模型偏向规避风险、乐观或悲观，以校正或模拟偏见。这种方法的特点是透明、轻量级且易于复制，适合社会科学实证研究。", "conclusion": "该研究方法可以对LLM生成的经济预测进行透明、轻量级和可复制的调整，使其映射到情绪、技术分析和时机等具体概念上，并且能够在不损害性能的前提下调整模型的风险偏好，这对于纠正或模拟偏见具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过像素化方法增强自回归语言模型对文字攻击的稳健性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型容易受到文字攻击的影响，这类攻击通过对输入文本进行多语言字母表中字符的篡改，导致模型性能大幅下降。这种脆弱性主要源于次词分词器和其嵌入中固有的陌生词汇问题。", "innovation": "提出了一种基于像素的生成语言模型，通过将文字渲染成个体图像来替代文本嵌入，从而增强了对噪声输入的鲁棒性，并且可以扩展到不同的书写系统下的多语言文本。", "conclusion": "在多语言LAMBADA数据集、WMT24数据集和SST-2基准上评估了所提出的方法，显示出其对文字噪声的抵抗力以及在多语言环境中的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN：基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列的合成是一种有效的方法来确保时间序列数据的安全流通。现有的时间序列合成方法通常基于随机序列进行时间建模并生成目标序列，这往往难以确保生成的时间序列中的时间依赖性。直接在随机序列上建模时间特征也使准确捕获原始时间序列的特征信息变得困难。", "innovation": "提出了一种简单的但有效的生成模型：双层生成对抗网络DLGAN。该模型将时间序列生成过程分解为两个阶段：序列特征提取和序列重构。首先，这两个阶段形成一个完整的序列自编码器，使监督学习在原始时间序列上成为可能，确保重构过程可以恢复时间序列的时间依赖性。其次，使用生成对抗网络生成与实时序列特征向量对齐的合成特征向量，确保生成器可以从实际时间序列中捕获时间特征。", "conclusion": "在四个公共数据集上的广泛实验表明，该模型在各种评估指标上表现出优越性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大型语言模型（LLMs）能力的增强，特别是在多语言和非英语环境中，需要更加稳健的评估方法。为此，更新了BLUEX数据集，新增了2024-2025年的考试内容，并使用最先进的模型自动生成图像描述，使该数据集更加适用于LLM预训练中的数据污染研究。图像描述策略提高了对仅文本模型的可达性超过40%，产生了1,422个可用问题，是原有BUGLEX问题的两倍多。我们评估了几种商业和开源的LLMs及其通过图像描述利用视觉上下文的能力。", "innovation": "1. 更新了BLUEX数据集，涵盖2024-2025年的考试内容以及自动生成的图像描述。\n2. 自动生成的图像描述策略将仅文本模型的可供性提高了超过40%，增加了1,422个可用问题，显著增加了数据集的容量。\n3. 评估了多种商业和开源的LLMs及其在利用图像描述中的视觉上下文的能力。", "conclusion": "更新后的BLUEX数据集提供了更广泛且更加相关的基准测试覆盖，适用于研究LLM预训练中数据污染的问题。通过自动生成的图像描述，提高了对仅文本模型的可用性，并对不同模型在理解视觉上下文方面的能力进行了评估。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "阶梯通往公平：连接群体公平与个体公平", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统（RS）中的公平性通常被分为群体公平性和个体公平性两个类别。然而，目前尚无科学的方法来证明这两种公平性之间的关系，因为先前研究这两种公平性的文献使用了不同的评估指标或目标，无法进行恰当的比较。因此，不清楚提高一种公平性是否会影响另一种公平性。本文研究了群体公平性和个体公平性之间的关系，通过综合比较适用于两种公平性的评估指标来填补这一空白。", "innovation": "本文通过实验，发现高度对群体公平的推荐可能对个体非常不公平。这是一种新颖且实用的发现，有助于RS从业者改进系统的公平性。本文还提供了相关的代码以供参考。", "conclusion": "实验结果显示，对于群体高度公平的推荐系统可能会对个体非常不公平。这一研究结果为RS的公平性提升提供了新的视角，未来的研究可以通过优化算法或设计新的评估指标来解决这一问题。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO：基于生成模型的离线巩固终身学习系统", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "持续或终身学习旨在开发能够从任务序列中不断获取新知识而不忘记之前学习的内容的模型。现有的方法通常依赖于存储先前任务的样例（经验重放）或使用复杂的正则化术语来保护已学习的权重。然而，这些方法面临数据隐私、存储限制以及任务不同时性能下降的挑战。现有的方法须要在系统中存储大量数据并防止权重忘记之前学过的内容，这导致了隐私风险和存储问题，特别是在任务差异较大时。", "innovation": "本文提出了MyGO（Memory Yielding Generative Offline-consolidation），一种受到生物清醒-睡眠周期启发的新型终身学习框架。MyGO在“清醒”阶段快速学习新任务，并训练生成模型（G-mem）来捕获其数据分布。在“睡眠”阶段，系统进入离线状态，通过知识蒸馏使用所有已学到的G-mem模型生成伪数据（梦境），并将其与新旧知识合并到核心特征提取器中。这种方法避免了存储任何原始数据，仅保留紧凑的生成模型，这对于隐私和存储效率有很大的优势。", "conclusion": "我们在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准上评估了MyGO，将其与顺序微调基线进行比较。结果表明，MyGO显著减轻了灾难性遗忘，保持了高平均准确率，证明了该框架的有效性和通用性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21378", "html_url": "https://arxiv.org/abs/2508.21378", "title": "RoboInspector: 揭示大型语言模型助力机器人操作的策略代码可靠性问题", "title_en": "RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation", "authors": "Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu", "background": "大型语言模型（LLMs）展示了在推理和代码生成方面的强大能力，使机器人操作能够仅通过一个指令来启动。通过生成控制机器人所需的策略代码，LLMs 可执行多种任务。虽然在LLM方面取得了进展，但在现实世界任务的多样需求和用户指令的内在复杂性情况下，可靠策略代码生成仍然是一个显著的挑战。在实践中，不同用户可能会根据同一任务提供不同的指令来驱动机器人，这可能导致策略代码生成不可靠。", "innovation": "通过设计 RoboInspector 管道，从完成操作任务的复杂性和指令的细致程度两个方面来揭示和表征 LLM 助力机器人操作中策略代码的可靠性问题。RoboInspector 识别出四种主要的不可靠行为，导致操作失败，并提供详细的表征及其根本原因分析，为减少可靠性问题提供实践指导。此外，引入了一种基于失败策略代码反馈的改进方法，该方法能够在模拟和实际环境中将策略代码生成的可靠性提高多达 35%。", "conclusion": "通过 RoboInspector 对策略代码的分析，对不可靠行为进行了全面了解，并提出了改进方法，显著提升了 LLM 助力机器人操作中策略代码生成的可靠性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus：自动推理合成定向 fuzzing 的谓词", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向 fuzzing 的目标是发现能够导致特定程序状态的输入。这项任务具有广泛的应用场景，如调试系统崩溃、验证已报告的错误以及生成针对潜在漏洞的exploit。然而，由于目标状态可能嵌套在程序中，而可能的输入空间非常庞大，导致这项任务本质上具有挑战性。现有的方法依赖于分支距离或人工指定的约束来引导搜索。不过，单独的分支通常不足以精确地描述向到达目标状态进展的过程，而人工指定的约束往往针对特定的漏洞类型，难以泛化到多样化的目标状态和程序中。因此，有必要开发新的方法来提高 fuzzing 的效率和精确性，尤其是能够自动化生成有助于指导搜索的谓词的方法。", "innovation": "Locus 是一个新颖的框架，旨在提高定向 fuzzing 的效率。其核心洞察是通过合成谓词来捕捉 fuzzing 进程中具有语义意义的中间状态，将它们用于指导程序的执行并拒绝不太可能达到目标状态的执行。Locus 的特色是一个代理框架，结合了程序分析工具，能够自动化合成和完善候选谓词，并通过符号执行确保不会错误地拒绝合法状态。这种方法在发现现实生活中的八个漏洞方面显著提高了现有八大先进 fuzzers 的效率，平均提高了 41.6 倍，并且已经发现了一个尚未打补丁的新漏洞，目前该漏洞已经获得承认并有初步补丁草案。", "conclusion": "总体来说，Locus 通过自动推理合成具有语义意义的中间状态谓词的方法，显著提高了模糊测试的效率和准确性，特别是针对多样化的程序和目标状态，未来有望进一步提高模糊测试技术的有效性和广泛应用。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "象棋玩棋神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "本文探讨了神经网络构建其表示是通过平滑、渐进的改进还是通过更复杂的计算过程来进行的。为了回答这个问题，作者将logit视角方法扩展到Leela Chess Zero超级人类级国际象棋引擎的策略网络上进行分析。", "innovation": "研究通过在Leela Chess Zero的策略网络上应用logit视角方法，发现了训练过程中层数和解题能力之间的强单调趋势，但策略分布经常表现出非平滑的轨迹。这种现象在语言模型中通常表现为平滑分布的一致收敛。", "conclusion": "研究结果表明，虽然训练过程中存在平滑的指示力增强，但在较晚阶段网络中的策略分布差异依然很高。这种发现与语言模型中通常观察到的平滑分布收敛形成了对比。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一个用于比较评估指标的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文探讨了自动文本摘要评估中的再现性挑战。通过在六种代表性的度量标准中进行实验，涵盖从经典的ROUGE方法到近期的大语言模型方法（如G-Eval和SEval-Ex），发现文献报道的性能与实验观察到的性能之间存在显著差异。这些研究结果揭示了结构性权衡：与人类判断最高的对齐度倾向于计算成本高且运行间不稳定的度量标准。", "innovation": "本文引入了一个统一的开源框架，应用于SummEval数据集，旨在支持公平和透明的比较评估指标。该框架突出了依赖大语言模型进行评估的关键关注点，强调了它们的随机性、技术依赖性和有限的再现性。", "conclusion": "本文强调需要更加 robust的评估协议，包括详尽的文档和方法论标准化，以确保自动摘要评估的可靠性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常与图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文通过对正常性的概念进行回顾，探讨了图灵测试的理解方式。文章认为，图灵测试旨在测试常规而非异常的人类智能，需要机器能够像常规的人那样犯错和表现不完美。此外，图灵测试本质上是一种统计测试，涉及多个非专家评委的综合判断。", "innovation": "文章提出，图灵测试的核心在于评估常规智能，而不是异常智能，并且图灵所提到的“正常人类审问者”可以被理解为多个评委个体判断的数学抽象。这种观点将图灵测试的评估标准从单一的非专家评判者转向了多个评委的统计结果，从而引入了新的理解图灵测试的视角。", "conclusion": "研究发现，大规模语言模型如ChatGPT不太可能通过图灵测试，因为它们主要关注的是异常而非常规智能。这类模型被定义为人工智能的变形而不是真正的人工智能。同时，图灵测试是否能用于理解人类认知的核心问题在于人类思维能否被简化为常规/平均思维，这一问题远远超出了图灵测试本身，对正常主义范式的概念基础提出了质疑。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "自适应重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型时代，优化算法常常因为在训练损失上的过度依赖而难以实现泛化。机器学习社区普遍接受的一个关键洞察是，广阔的基坑（围绕局部最小值，其中损失随着数据或模型参数的小变化逐渐增加的区域）有助于提供更好的稳定性，从而促进更好的泛化，而尖锐的最小值则通常更加敏感且不稳定。基于这两点经验观察，即随机梯度下降中的内生重尾梯度噪声分布，以及神经网络训练过程中增长后停留在平台边缘的曲率现象，作者引入了自适应重尾随机梯度下降（AHTSGD）算法。该算法在训练初期向优化器注入更重尾的噪声以增强探索，随着尖锐程度稳定，则逐渐转换为较轻尾的噪声。通过在整个训练过程中动态适应损失景观的尖锐程度，AHTSGD促成了对广泛基坑的快速收敛。", "innovation": "AHTSGD 是首个根据边缘稳定性现象调整注入噪声性质的优化算法。该算法在训练初期注入更重尾的噪声以增强探索，在尖锐程度稳定后逐渐转换为较轻尾的噪声。AHTSGD 在 MNIST 和 CIFAR-10 等基准测试中表现优于 SGD 和其他噪声基础方法，特别是在 SVHN 这样的噪声数据集上表现出显著的性能提升。该算法在清洁和噪声环境下均能加速早期训练，并提高了泛化能力，同时对于不同的学习率选择具有鲁棒性。", "conclusion": "AHTSGD 通过动态适应损失景观的尖锐程度，促进快速收敛于广阔基坑，提高泛化能力，并在多种数据集和各种学习率下表现出更好的性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT与DeepSeek家族模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在改变各行各业的AI，但其开发和部署依然复杂。本文回顾了构建和使用LLMs面临的关键挑战，并对比分析了两种采用独特方法的顶级模型：OpenAI的闭源GPT-4o（2024年5月更新）和DeepSeek-V3-0324（2025年3月），这是一个大型开源混合专家模型。通过这种对比，展示了闭源模型（稳健的安全性，精细调整的可靠性）与开源模型（效率，适应性）之间的权衡。同时探讨了LLM在不同领域（从聊天机器人和编程工具到医疗保健和教育）的应用，强调了每种模型属性最适合的具体应用场景。本文旨在为AI研究人员、开发人员和决策者提供理解当前LLM能力、限制和最佳实践的指导.", "innovation": "本文通过对比分析两个顶级模型——OpenAI的闭源GPT-4o和DeepSeek-V3-0324，展示了闭源模型和开源模型之间的权衡。同时探讨了LLM在各种领域内的应用，分析了哪些模型属性最适合特定的应用场景。此外，该研究还指导AI研究人员、开发人员和决策者更好地理解LLMs的能力、限制和最佳实践。", "conclusion": "本文回顾了构建和使用大型语言模型遇到的关键挑战，并通过比较两个顶级模型展示了闭源模型和开源模型的权衡。同时，该研究还探讨了LLM在不同领域内的应用，展示了哪些模型属性最适合特定的需求，并指导了AI研究人员、开发人员和决策者更好地理解LLMs的能力、限制和最佳实践。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21368", "html_url": "https://arxiv.org/abs/2508.21368", "title": "EconAgentic在DePIN市场中的应用：一种大规模语言模型方法探索分布式物理基础设施共享经济", "title_en": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "authors": "Yulin Liu,Mocca Schweitzer", "background": "去中心化的物理基础设施市场（Decentralized Physical Infrastructure，DePIN）通过基于代币的经济和智能合约治理实现了共享经济的革新，市场资本化已超过100亿美元。然而，这些市场的未监管性质和智能合约中自主部署的AI代理可能导致效率低下和与人类价值观相偏差的风险。因此，有必要研究和改进这类市场的设计和治理，以实现更高效、更包容和更稳定的市场发展和宏观目标的对齐。", "innovation": "本文提出了EconAgentic框架，这是一种基于大规模语言模型（LLM）的智能体调控框架，旨在解决DePIN市场中的挑战。EconAgentic框架专注于三个方面：1) 模型DePIN市场的动态演变；2) 评估利益相关者的行动及其经济影响；3) 分析宏观经济指标，以使市场结果与社会目标相一致。通过EconAgentic，作者模拟了AI代理如何响应代币激励、投资基础设施以及适应市场条件，并与基于人类直觉的基准决策进行比较，揭示了AI代理策略与人类策略的异同。", "conclusion": "EconAgentic为DePIN市场的效率、包容性和稳定性提供了宝贵的见解，有助于学界和业界更好地理解和改进分布式、代币化经济的设计和治理。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21407", "html_url": "https://arxiv.org/abs/2508.21407", "title": "DRASP: 双分辨率关注统计池化框架在自动MOS预测中的应用", "title_en": "DRASP: A Dual-Resolution Attentive Statistics Pooling Framework for Automatic MOS Prediction", "authors": "Cheng-Yeh Yang,Kuan-Tang Huang,Chien-Chun Wang,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen", "background": "语音质量预测中，均意见分数（MOS）预测需要一种汇聚机制，将变长的音频特征转化为一个紧凑的固定大小表示，有效编码语音质量。现有池化方法通常在单一粒度上运作，要么侧重于全局视角，要么侧重于帧级分析，这可能导致忽略感知互补洞见。论文旨在解决这一局限，提出了一种双分辨率关注统计池化（DRASP）框架，以提高MOS预测的准确性和泛化能力。", "innovation": "DRASP框架结合了粗粒度的整体统计摘要和细粒度的感知显著段落的关注分析，形成了一个双视角架构，使得模型能够同时捕捉宏观结构和显著局部细节。实验验证了DRASP框架的有效性和强大的泛化能力，它在MusicEval和AES-Natural等多个数据集上，以及不同的MOS预测主干（如CLAP模型和AudioBox-Aesthetics）和音频生成系统上，均优于平均池化等基线方法，系统级的Spearman秩相关系数相对提高了10.39%。", "conclusion": "DRASP框架在MOS预测中表现出了显著的提升，通过结合粗粒度和细粒度的分析，有效改善了模型的代表性和泛化能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21393", "html_url": "https://arxiv.org/abs/2508.21393", "title": "zkLoRA: 利用零知识证明实现可验证安全的大语言模型微调", "title_en": "zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs", "authors": "Guofu Liao,Taotao Wang,Shengli Zhang,Jiqun Zhang,Shi Long,Dacheng Tao", "background": "大型语言模型（LLMs）的微调对于特定任务至关重要，但这一过程仍然非常耗计算资源，并且在不信任环境中会引发关于正确性和隐私性的担忧。尽管像低秩适应（LoRA）这样的参数高效方法可以显著减少资源需求，但在零知识约束下确保微调的安全性和可验证性仍然是未解决的挑战。", "innovation": "我们介绍了zkLoRA，这是第一个将LoRA微调与零知识证明（ZKPs）结合的框架，实现了可验证的安全性和正确性。zkLoRA使用先进的加密技术如查找论证、多项式承诺等，来验证Transformer架构中的算术和非算术操作。该框架提供了从正向传播到反向传播再到参数更新的全程可验证性，同时保护了模型参数和训练数据的隐私。实验结果证明，zkLoRA在开源LLM如LLaMA上具有实际性和高效性，并且可以扩展到130亿参数的规模。通过结合参数高效微调与ZKPs，zkLoRA填补了关键空白，使得在敏感或不信任环境中安全可靠地部署LLMs成为可能。", "conclusion": "zkLoRA通过将高效参数微调和零知识证明相结合，解决了大型语言模型在敏感或不信任环境中的安全和可验证性问题，实现了模型在这些环境中的安全可靠部署。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度集成实现基于结构的药物设计中的可控3D分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "最近基于结构的药物设计（SBDD）领域中，生成模型被用于3D分子生成，并主要通过目标蛋白结合亲和力来评估模型性能。然而，在实际药物发现中，除了高结合亲和力之外，还需要考虑合成可行性与选择性等关键属性，而这些属性在以往的评估中往往被忽略。", "innovation": "本文识别了传统扩散生成模型在有效引导生成具有多种药理特性的分子方面的局限性，并提出了CByG框架，该框架将贝叶斯流网络扩展为基于梯度的有条件生成模型，以实现属性特异性指导的稳健集成。此外，我们还引入了结合实际基准的综合评估方案，以评估结合亲和力、合成可行性和选择性，克服了传统评估方法的局限。", "conclusion": "我们的CByG框架在多个重要的评价指标上显著优于基准模型，展示了其在实际药物发现应用中的有效性和实用价值。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff：基于扩散模型的阶段式长期时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型在时间序列生成领域取得了显著成功，但对于长期时间序列的生成却面临着更大挑战。长期时间序列不仅跨越较长时期，也表现出更复杂的长期时间依赖性，并且其数据分布随时间发生逐步变化。如何在保持长期依赖性和数据分布变化之间找到平衡成为关键挑战。此外，长期时间序列中不同特征序列之间存在更复杂的相互关系，捕捉这些序列内部和序列间的依赖性又提出了另一个重要挑战。", "innovation": "本文提出了一种基于扩散模型的多阶段生成模型——Stage-Diff。通过阶段式的序列生成和阶段间信息传递，该模型能够在保持长期序列依赖性的基础上，进行数据分布变化的建模。同时，在每个阶段中利用逐级序列分解来进行通道独立建模，在不同时间尺度上进行独立处理，而阶段间的信息传递则利用多通道融合建模。这种方法将通道独立建模的稳健性与多通道建模的信息融合优势相结合，实现了长期时间序列内部和序列间依赖性的有效平衡。", "conclusion": "广泛实验在多个真实数据集上的结果验证了Stage-Diff在长期时间序列生成任务的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 评估医疗多模态大语言模型奖励模型和评判者的基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大语言模型（MLLMs）在医疗领域，如疾病诊断和临床决策中具有巨大潜力。然而，这些任务需要高度精确、上下文敏感和专业对齐的响应，这使得可靠的奖励模型和评判者至关重要。尽管它们至关重要，但医疗领域专用的奖励模型（MRMs）和评判者仍被忽视，现有基准测试主要关注一般MLLM能力或评估模型作为解决问题的能力，忽视了诊断准确性等关键评估维度。", "innovation": "该研究引入了Med-RewardBench，这是首个专门用于评估医疗场景中MRMs和评判者的基准测试。Med-RewardBench包含涵盖13个器官系统和8个临床部门的多模态数据集，共1,026个专家标注案例。研究表明，现有32个最先进的MLLMs存在显著挑战， Aligning模型输出与专家判断存在困难。此外，还开发了基准模型以展示通过微调可以获得显著性能提升。", "conclusion": "研究结果表明，在医疗场景下，多模态大语言模型需要专门的奖励模型和评判者来优化输出质量。Med-RewardBench的引入填补了医疗领域专用基准测试的空白，并为未来评价和优化MRMs提供了指导。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "该研究探讨了大型语言模型（LLM）驱动的代理在解决复杂任务时通过迭代推理、探索和工具使用过程中产生的长期、昂贵的历史上下文问题。目前，先进软件工程（SE）代理如OpenHands或Cursor使用LLM基于的总结来应对这一问题。然而，这种增加复杂性是否能带来具体的性能改进尚不清楚，与简单省略旧观察相比是否值得。研究在SWE-agent上对这些策略进行了系统比较，覆盖了五个不同的模型配置。", "innovation": "本研究提出了一种简单的观察隐藏策略，发现其相对未处理代理的成本减少了一半，同时在解决率上与LLM总结方法相当，甚至在某些方面超越。例如，使用Qwen3-Coder 480B时，隐藏观察提高了解决率从53.8%（原始代理）到54.8%，同时保持与总结法在较低成本下的竞争力。这项研究表明，至少在SWE-agent和SWE-bench Certified中，最有效和高效的上下文管理可能是最简单的。", "conclusion": "研究结果表明，在SWE-agent和SWE-bench Certified中，最有效且高效的上下文管理可能是最简单的策略，即简单的观察隐藏而非复杂化的LLM总结。为此，作者同时发布了代码和数据以保证结果的可重现性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21460", "html_url": "https://arxiv.org/abs/2508.21460", "title": "基于扩散的多模态协同兴趣网络用于点击率预测", "title_en": "Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction", "authors": "Xiaoxi Cui,Weihai Lu,Yu Tong,Yiheng Li,Zhejun Zhao", "background": "当前的点击率（CTR）预测方法大多基于标识符（ID）模态，无法全面建模用户的多模态偏好。因此，提出了多模态CTR预测的必要性。虽然直接将现有的多模态融合方法应用于点击率预测模型似乎具有吸引力，但这些方法未能有效分离不同模态之间的共性和特性，也未能考虑模态间的协同效应和建模复杂的交互作用。", "innovation": "为了应对上述问题，本文提出了基于扩散的多模态协同兴趣网络（Diff-MSIN）框架，引入了三个创新模块：多模态特征增强（MFE）模块、协同关系捕捉（SRC）模块和特征动态自适应融合（FDAF）模块。这三种模块辅助从不同模态中提取协同、公共和特殊信息，并有效增强了模态的表示，从而改善了融合的整体质量。此外，设计了一种知识解耦方法以鼓励不同特征间的独特性，并着力于捕捉用户偏好和减少融合噪声。", "conclusion": "通过在Rec-Tmall和三个亚马逊数据集上进行广泛的实验，结果表明，相比基线，该方法在至少1.67%的性能上带来了显著改进，突显了其在增强多模态推荐系统方面的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于蓄水池计算的低成本网络状态基准检测方法", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "本文使用挪威移动网络数据，展示了通过非侵入性、低成本的方法监测通信和移动网络状态的可能性。该方法将网络数据转化为蓄水池计算框架下的模型，并通过代理任务评估模型性能。该数据以匿名汇总的形式在一天内有多次快照，可以被视为加权网络。蓄水池计算允许使用未训练的加权网络作为机器学习工具，通过回声状态网络（ESN）将输入信号投影到高维空间，在该空间上运行一层经过训练的网络。这种方法相比深度神经网络更节能，且每层之间的权重未经训练。作者还进行了灵感来源于神经科学的任务，并训练了ESN模型来解决这些问题。然后展示了性能如何依赖于网络配置的不同，并表明网络受扰动时性能明显下降。尽管这项工作是概念证明，但作者认为这种方法可以进一步用于近实时监控，并识别出移动通信网络和交通网络中的潜在弱点点。", "innovation": "该方法的关键优势在于使用了现成的数据集和蓄水池计算框架，实现了一种低成本且高度可扩展的方法。蓄水池计算框架使得可以使用加权但未经训练的网络，从而降低了训练时间和成本。该方法通过将网络数据转化为加权网络，并利用蓄水池计算中的回声状态网络（ESN）来处理信号，从而实现网络状态的监测，而不需要对整个网络进行复杂的训练。这种方法相比传统的深度神经网络更节能，且无需逐层训练，大大降低了计算和资源成本。通过神经科学启发的任务，展示了这种方法的有效性和实用性。", "conclusion": "通过使用蓄水池计算方法和现成的移动网络数据，本文提出了一种低成本且有效的方法来监测网络状态，并识别可能的弱点。该方法无需大量的数据训练和计算资源，具有较高的实用性和扩展性。未来可以将其应用到更广泛的网络监测和管理场景中。同时，通过神经科学启发的任务设计，进一步验证了这种方法在解决复杂网络任务中的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正需要哪些数据？推荐系统中推理数据最小化可行性的研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是一项法律规定，要求个人信息处理仅限于实现特定目的所必需的数据。对于依赖大量个人数据的推荐系统，如何实现这一原则仍是一个巨大挑战。这项研究聚焦于在推荐系统中最小化隐式反馈推理数据的研究，旨在探讨技术上是否可行，并分析不同最小化技术的有效性和影响因素。", "innovation": "提出了一个新的问题形式，研究了多种最小化技术，并探究了影响这些技术有效性的关键因素。研究结果表明，虽然在技术上实现显著的数据减少是可能的，且不会造成显著的性能损失，但其实现的可行性仍取决于技术环境和用户特性，因此难以制定一个通用的数据`必要性`标准。", "conclusion": "尽管数据最小化技术上可行，但在实际应用中仍面临重大挑战，其依赖于技术环境和用户特性的具体情况，因而制定通用标准十分困难。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift: 通过隐式条件传输进行X射线域适应", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医学数据提供了训练鲁棒模型的可扩展解决方案，但显著的领域差距限制了其在临床环境中的通用性。本文关注合成和真实头颅X射线图像之间的跨领域转换挑战，特别是在衰减行为、噪声特征和软组织表示上的差异。已有方法或需要特定领域的训练或依赖配对数据，而MedShift提出了一种基于流动匹配和薛定谔桥的统一条件生成模型，实现了多领域高保真度、无配对图像转换，同时在训练过程中学习共享的领域无关的隐空间，支持在任何配对领域之间的无缝转换。", "innovation": "MedShift模型基于流动匹配和薛定谔桥，是一种统一条件生成模型，能够在多个领域之间实现高保真度的无配对图像转换，无需特定领域的训练或依赖配对数据，并能在训练过程中学习共享的领域无关的隐空间，支持在任何配对领域之间的无缝转换。此外，作者还构建了X-DigiSkull数据集，包含在不同辐射剂量下对齐的合成和真实头颅X射线图像，用于评估域转换模型。实验结果表明，尽管与基于扩散的方法相比模型规模较小，但MedShift在性能上表现出色，具备良好的灵活性，在推理阶段可调节以优先考虑感知保真度或结构一致性，使其成为医学成像领域适应的可扩展和通用解决方案。", "conclusion": "MedShift作为一种统一条件生成模型，通过流动匹配和薛定谔桥实现跨领域的无配对图像转换，解决了合成和真实头颅X射线图像之间的域移平问题。实验表明，MedShift在性能和灵活性方面的优势，使它成为医学成像领域适应的可扩展和通用解决方案。X-DigiSkull数据集和MedShift的代码可以在提供的网址获取。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: 在长视频理解中基准测试语义聚合幻觉", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频多模态大型语言模型（Video-MLLMs）在视频理解方面取得了显著进步，但在生成与视频输入不符或无关的幻觉内容方面仍然存在缺陷。现有的视频幻觉基准主要针对短视频，并将幻觉归因于强大的语言先验、丢失的帧或视觉编码器引入的视觉-语言偏差。虽然这些原因解释了大多数短视频幻觉的原因，但仍过度简化了幻觉的原因。有时模型生成错误输出，但却具有正确的帧级语义，这种情况被称为语义聚合幻觉（SAH），它主要发生在将帧级语义聚合到事件级语义组的过程中。", "innovation": "本文介绍ELV-Halluc，这是第一个针对长视频幻觉的基准，允许对SAH进行系统性研究。实验验证了SAH的存在，当语义复杂度增加时，SAH会增加。此外，我们发现模型在快速变化的语义下更容易出现SAH。此外，我们讨论了缓解SAH的潜在方法。实验表明，位置编码策略有助于缓解SAH，并采用DPO策略增强了模型在跨事件区分语义的能力。我们通过制作8000对抗样本数据对，在ELV-Halluc和Video-MME上实现了改进，包括SAH比率显著减少了27.7%。", "conclusion": "本文为长视频理解中的语义聚合幻觉问题提供了一个系统的研究基准，通过实验证明了SAH的存在，并对其进行了深入的研究。研究发现，位置编码策略可以缓解SAH，并通过引入DPO策略提高了模型在事件内及跨事件区分语义的能力。实验数据表明，通过使用8000对抗样本，模型的SAH比率显著降低了27.7%。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的不恰当假设", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "强化学习中的不确定性量化能够显著提高探索和鲁棒性。近年来，近似贝叶斯方法被广泛用于量化模型自由算法中的不确定性。然而，目前的研究主要集中在提高后验近似精度上，而未充分研究后验背后的先验和似然假设的准确性。贝叶斯深度Q学习存在冷后验效应，即理论相反，性能随着后验温度降低而提高。common假设下，似然和先验通常被不合适地假设为高斯分布，但实验证明这种假设经常被违反。这表明开发更合适的先验和似然是未来贝叶斯强化学习研究的关键焦点，并提出了简单的解决方案以改进深度Q学习中的先验，提高算法性能", "innovation": "研究发现了贝叶斯深度Q学习中的冷后验效应，并挑战了以往关于似然和先验的常见假设。通过实验证明了常见的高斯分布假设被经常违反，提出开发更合适的似然和先验应该成为未来的研究重点，并给出改善深度Q学习的先验的简单实现方案", "conclusion": "开发更合适的先验和似然对提高贝叶斯强化学习算法的性能至关重要，并提出了简单的改进先验的方法。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "学习GNN基SAT求解器的难度：图 Ricci 曲率的作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "图神经网络（GNNs）近年来显示出在解决布尔可满足性问题（SATs）方面的潜力，通过操作逻辑公式的图表示。然而，它们在更难的实例上表现急剧下降，引发了是否反映根本架构限制的问题。", "innovation": "通过图 Ricci 曲率（RC）的几何解释，证明了从随机 k-SAT 公式导出的二分图本质上是负曲率的，并且其曲率随着实例难度的增加而减小。基于此，展示了基于 GNN 的 SAT 求解器受到过度压缩现象的影响，即长时间依赖关系变得无法压缩到固定长度的表示中。通过不同的 SAT 标准测试，验证我们的断言并确认曲率是问题复杂性的强大指标，并可用于预测性能。", "conclusion": "研究结果连接到现有求解器的设计原则，并概述了未来工作的有希望的方向。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: Hierarchical Selection for Fake News Detection Building Heterogeneous Ensemble", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏见，如确认偏见，使个人特别容易相信并传播社交媒体上的假新闻，这对公共卫生和政治领域产生了重大后果。基于机器学习的纠假系统已广泛研究以缓解此问题。其中，集成方法通过结合多个分类器来提高鲁棒性，特别有效。然而，它们的表现高度依赖于构成分类器的多样性。选择真正多样化的模型仍然是一个关键挑战，特别是在模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新的自动分类器选择方法，该方法优先考虑多样性和性能。该方法首先计算分类器之间的成对多样性，并通过层次聚类将它们组织成不同粒度级别的组。通过层次选择方法探索这些层次，在每个层次上选择一个代表同组内多样性的分类器池。最多样化的池被识别并用于集成构建。选择过程结合了反映每个分类器性能的评价指标，以确保集成也具有良好的泛化能力。该方法在六个不同应用域的四个十种异构分类器和不同类别的数量上进行了实验，并与肘部启发式算法和最先进的基线进行了比较。结果表明，在两个数据集中，该方法的准确性达到了最高。", "conclusion": "实验结果证明，该方法在两个数据集中达到了最高的准确性。方法的具体实现细节可以在项目的存储库中找到：this https URL。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "使用去噪扩散模型从单张图像中完成高斯采样", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "高斯采样通常需要场景的密集观测，并且难以重建被遮挡和未观察到的区域。传统方法通过回归预测单一的被遮挡和视锥外表面的“模式”，导致模糊、不现实以及无法捕捉多种可能的解释。这在完成未观察到的表面时带来了挑战，因为可能的表面会带来歧义。传统方法往往只能部分解决此问题，要么孤立地处理前景对象，要么仅重建视区内表面，或者无法从输入视图处进行外推。", "innovation": "本文提出了一种生成模型，通过一个单一的输入图像，学习受该图像条件限制的3D高斯采样的分布。为了克服缺乏地面真实训练数据的问题，我们提出了一种自监督的变分自重构器，它仅从2D图像中学习潜在空间，其上训练扩散模型。通过这种方法，本文能够生成忠实的重建和多样化的样本，能够完成被遮挡的表面以进行高质量的360度渲染。", "conclusion": "本文通过一个单一的输入图像学习和生成3D高斯采样的分布，克服了传统方法的不足，能够生成忠实且多样化的深度重建，特别擅长完成被遮挡的表面。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "Physics-Informed Neural Networks: 一种智能电网代理的研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "物理信息神经网络（PINNs）通过直接将物理定律融入学习框架，为智能电网建模提供了一种革新方法，解决了传统数据驱动方法在数据稀缺性和物理一致性方面的关键挑战。本文通过将PINNs作为智能电网动态的代理模型进行评估，探讨其在插值、交叉验证和事件轨迹预测三项关键实验中的表现，以比较其与XGBoost、随机森林和线性回归的性能。研究还展示了通过物理基础损失函数训练PINNs，使其在误差减小方面表现出优越的泛化能力，满足智能电网动态操作中的性能需求，而传统的数据驱动模型则表现出不稳定的表现。尽管在极端操作条件下PINNs的性能略有下降，但其在物理可行性的严格维护方面表现优异，对于关键安全应用至关重要。", "innovation": "本文通过使用物理基础损失函数训练物理信息神经网络（PINNs），并将其应用于智能电网动态建模，展示了其在误差减小和物理一致性方面的优越性能，相比传统的数据驱动模型（如XGBoost、随机森林和线性回归），PINNs在智能电网操作中表现出更低的MAE（平均绝对误差），特别是在动态运行操作场景中。研究还强调了PINNs在关键能源系统中的重要性，并促进了实时电网控制和可扩展数字孪生的发展。", "conclusion": "本文的研究结果表明，物理信息神经网络（PINNs）作为智能电网建模的代理模型，能够很好地结合数据驱动的灵活性与基于原理的严谨性，为关键能源系统的实时控制和数字孪生提供了有力支持，突显了在关键能源系统中应用物理感知架构的重要性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "小语言模型中的创意写作激发：LLM作为裁判者与多代理精炼奖励的比较", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大型语言模型（LLMs）在创意写作方面表现出色，但高昂的计算成本限制了它们的广泛应用。相比之下，增强小型语言模型（SLMs）提供了一种有前景的替代方案。然而，当前的方法如监督微调（SFT）缺乏创新性，而通过人类反馈的强化学习（RLHF）则成本高昂。", "innovation": "本文在强化学习从AI反馈（RLAIF）框架内探索了两种不同的基于AI的奖励策略：一种是利用多代理拒绝采样框架从高质量的偏好数据中训练的评估模型；另一种是使用原则指导的LLM裁判，其奖励函数通过对抗训练方案优化，直接提供奖励信号。", "conclusion": "两种方法均显著提升了创意输出，但原则指导的LLM裁判能够提供更高质量的生成效果。此外，这种方法在训练效率和减少对人类标注数据依赖方面具有明显优势，为其提供了一条更可扩展和有效的路径。我们的自动评估方法也与人类判断高度一致。相关代码和数据已在公开渠道提供。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "当前，文本嵌入模型在自然语言处理任务中扮演重要角色。Qwen2.5-7B-Instruct作为基础模型，研究人员在此基础上开发了QZhou-Embedding。该模型通过引入多样化的训练数据和针对性的训练策略，增强了模型的学习效率和表示能力。研究还利用大型语言模型（LLM）的生成能力，生成高质量的合成数据，以提升训练集的语义丰富性和样本难度。提出的双阶段训练策略首先进行检索导向的预训练，随后进行全面任务精调，使得模型能够基于稳健的检索性能扩展其功能。", "innovation": "QZhou-Embedding模型基于Qwen2.5-7B-Instruct的多任务统一框架，通过引入多样化的数据转换方案和任务特定的训练策略，以及利用LLM的生成能力合成高质量训练数据，显著提升了模型的文本表示能力。通过双阶段训练策略，模型能够基于稳健的检索性能扩展其功能。该模型在MTEB和CMTEB基准测试中取得了最优结果，同时在重排序和聚类等任务上也表现出卓越的性能，证明了高质量和多样化的数据对检索模型性能的重要性。", "conclusion": "研究结果表明，高质且多样化的数据对提升检索模型性能至关重要。利用LLM的生成能力可以进一步优化数据质量，推动嵌入模型的突破。模型已开源于HuggingFace，并提供可复现的评估代码和指南于GitHub。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 通过零样本CLIP基础预排序和人类在环排序高效成对比较", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或困难的注释任务中，成对比较因其改进的可靠性通常比绝对评级或序数分类更受欢迎。然而，成对比较需要大量的注释（O(n^2)）。最近的工作已经通过使用排序算法主动采样成对比较极大地减少了注释负担（O(n log n)）。进一步提高注释效率的方法包括对项目进行粗略预排序以及用自动化比较替换容易的人类比较。", "innovation": "提出了一种称为EZ-Sort的方法，该方法首先使用预训练的对比语言-图像预训练（CLIP）模型生成零样本预排序，然后初始化知桶意识Elo评分，最后运行基于不确定性的人类介入排列合并排序。通过这种方法，减少了人类注释成本，并提高了或维持了评定者间的一致性，显示了结合CLIP基础先验和不确定性感知采样的高效和可扩展解决方案对于成对排名的有效性。", "conclusion": "验证结果显示，与完全成对比较相比，EZ-Sort降低了90.5%的人类注释成本，当n=100时，与以前的工作相比降低了19.8%的成本，同时提高了或维持了评定者间的一致性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21566", "html_url": "https://arxiv.org/abs/2508.21566", "title": "NSPDI-SNN：基于非线性突触修剪和树突整合的高效轻量级SNN方法", "title_en": "NSPDI-SNN: An efficient lightweight SNN based on nonlinear synaptic pruning and dendritic integration", "authors": "Wuque Cai,Hongze Sun,Jiayi He,Qianqian Liao,Yunliang Zang,Duo Chen,Dezhong Yao,Daqing Guo", "background": "尖峰神经网络（SNNs）是基于模拟生物神经元的人工神经网络，在最近的人工智能技术研究中备受关注。生物神经元的树突具有高效的时空信息处理能力和计算能力，但SNNs中的神经元缺乏复杂的树突结构。因此，该研究提出了一种基于非线性修剪和树突整合的有效轻量级SNN方法（NSPDI-SNN），以提高空间时间信息的表示能力，并构建了一种新的可变非线性突触修剪方法，实现SNN的高度稀疏化。", "innovation": "该研究引入了非线性树突整合（NDI），提高了雪数据神经元的空间时间信息表示能力；实施了树突棘状态转换比率的异质性，并构造了一种新的可变非线性突触修剪方法，以达到SNN的高度稀疏化。NSPDI-SNN在三个基准数据集（DVS128手势、CIFAR10-DVS和CIFAR10）上进行了系统的实验，并在两种复杂任务（语音识别和强化学习基于迷宫导航任务）上进行了扩展评估。结果显示，NSPDI-SNN在所有任务中实现了高稀疏性，且性能下降最小，在三个事件流数据集上取得了最佳实验结果。进一步分析表明，NSPDI 随着稀疏度增加可以显著提高突触信息传递的效率。", "conclusion": "研究结果表明，生物神经元树突的复杂结构和非线性计算为开发高效SNN方法提供了一种有前景的方法。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式AI实现气候适应性学习的天气适应性学习", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "文章背景描述了气候变化对教育系统的影响，特别是在提高气候适应性教育方面的需求。当前的教育方法可能无法有效反映气候变化的实时影响，需要新的教学平台来提供实时、个性化和地方相关的气候适应性学习体验。传统的教育模式往往缺乏动态性和适应性，无法满足现代教育的需求。因此，需要开发一种新的技术平台来改善教育效果和提升气候意识。", "innovation": "文章创新在于介绍了一种名为FactS的未来大气条件培训系统（Future Atmospheric Conditions Training System），这是一种通过地方适应性、互动学习体验来提高气候适应性教育的新平台。该系统通过物联网传感器收集实时大气数据，结合知识库中的精选资源动态生成本地化学习挑战。学习者的反应通过生成式AI驱动的服务器分析，然后提供个性化反馈和支持。这种系统将物联网（IoT）和生成式AI（Generative AI）结合在一起，用于开发适应不同天气条件的学习资源，为气候适应性教育提供了新的解决方案。", "conclusion": "实验结果表明，参与者认为该系统既易于使用又有效，并有助于建立气候适应性知识。这些发现表明，将物联网和生成式AI整合到大气适应性学习技术中具有显著的潜力，可以增强教育参与度和促进气候意识的提升。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo: 模型引导的动态数据优化以增强大型语言模型微调", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）方法依赖于高质量的训练数据。现有方法通常通过数据选择和数据合成来提升数据质量，但在静态数据集管理方面存在局限性，无法适应模型能力的演变。", "innovation": "介绍了一种名为Middo的新框架，这是一种模型驱动的动态数据优化框架，利用模型感知的数据选择和语义保持的数据精炼。Middo框架通过闭环学习机制：(1) 引入自参考诊断模块，通过多重模型信号识别不足样本；(2) 采用自适应优化引擎将不足样本转化为教学价值高的训练点，同时保留语义完整性；(3) 该优化过程通过动态学习原理不断进化以适应模型提升的能力。实验结果表明，Middo可以持续提升基础数据质量，提高LLM性能，平均准确率提升7.15%，同时保持原始数据集规模。", "conclusion": "这项研究通过数据和模型的动态人机共进化，为可持续的LLM训练建立了一个新范式。我们的数据集、模型和代码即将发布。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "MPSoC板上神经网络加速: 结合SLAC的SNL、Rogue Software和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "LCLS-II自由电子激光器将产生高达1 MHz的X射线脉冲，实验线实验中需要处理超过1 TB/s的数据吞吐量。如此海量的数据流管理面临着重大挑战，因为传输和存储基础设施变得极其昂贵。机器学习（ML）提供了实时数据压缩的有希望的解决方案，但传统的实现引入了过多的延迟，使其不适合高速实验环境。", "innovation": "为应对这些挑战，SLAC开发了SLAC神经网络库（SNL），这是一种专门的框架，旨在在现场可编程门阵列（FPGA）上部署实时ML推理模型。SNL的关键特性是能够动态更新模型权重而无需重新合成FPGA。此外，为了进一步提高易用性和可访问性，研究人员引入了一种Python扩展Auto-SNL，它简化了将基于Python的神经网络模型转换为SNL兼容的高级综合代码的过程。", "conclusion": "通过与当前最先进的工具hls4ml进行基准测试比较，SNL在多个神经网络架构、定点精度和合成配置下显示了竞争力或更高的低延迟，并在某些情况下还节约了FPGA资源。这一适应展示了SNL的多功能性，为高能物理、医学成像、机器人学以及其他领域的研究人员和学者开辟了新的机会。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "推理密集型回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "AI研究人员和从业人员越来越多地将大型语言模型（LLMs）应用于我们所说的推理密集型回归（RiR），即从文本中推导出微妙的数值属性。与标准的情感分析或相似度计算等语言回归任务不同，RiR通常出现在诸如评分标准或特定领域检索等非标准问题中，需要对文本进行更深入的分析，但仅有少量任务特定的训练数据和计算资源。", "innovation": "本文将三个实际问题转化为RiR任务建立了一个基准，并测试了我们的假设：冻结的LLM提示和基于梯度下降的Transformer编码微调在RiR任务中通常都会遇到困难。然后提出了一种名为MENTAT的简单且轻量的方法，结合了批量反向提示优化与神经集成学习。MENTAT在两个基准之上取得了高达65%的改进，尽管在RiR方面仍有很大的发展空间。", "conclusion": "MENTAT在推理密集型回归任务上取得了显著的性能改进，但仍有许多改进的空间。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "通过非参数深度嵌入聚类进行无监督视频连续学习", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "现有的研究主要集中在有标签的数据上的连续学习，但这实际上成本高昂且不切实际。视频作为一种复杂的时空媒体信息，在很多应用中被广泛使用，但在无监督连续学习中尚没有被充分探索。无监督视频连续学习（uVCL）面临更多挑战，比图像处理需要更多的计算和内存资源。", "innovation": "提出了一种非参数的深度嵌入聚类解决方案来解决无监督视频的连续学习问题。使用深度嵌入视频特征的核密度估计（KDE）作为非参数的概率表示，引入了对新任务数据的新颖度检测标准，并动态扩展了记忆簇，以捕获连续学习任务的新知识。利用先前任务的迁移学习作为当前学习任务的知识初始态。", "conclusion": "所提出的范例方法在连续学习多个任务时显著提升了模型的性能。通过在三个标准的视频动作识别数据集UCF101、HMDB51和Something-to-Something V2上进行深入评估，无需使用任何标签或类边界，验证了该方法的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET：基于3D CAD模型生成的数字测量设备数据集合成工具，用于大型视觉语言模型微调", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "当前大型视觉语言模型在多模态任务中展现了令人 impressed的性能，但在读取数字测量设备(DMD)中的数值等简单场景下，特别是在包含拥挤、遮挡、极端视角和运动模糊等现实世界的复杂条件下，表现不佳。这些局限性驱使该研究开发了一种名为CAD2DMD-SET的合成数据生成工具，用于支持涉及DMD的视觉问答(VQA)任务。", "innovation": "该研究提出了CAD2DMD-SET，这是一种利用3D CAD模型、高级渲染和高保真图像合成的合成数据生成工具。通过这一工具生成的合成DMD数据集特别适合对LVLM进行微调，并且与现有的最佳模型在精确度评估表现上实现了显著提升。此外，DMDBench的构建提供了1,000个注释的实际图像数据集，用于在实际条件下评估模型性能。通过使用这些数据集进一步微调模型，可以在不干扰其他任务的情况下显著提高模型的性能，特别是在挑战性条件下。", "conclusion": "该研究不仅展示了CAD2DMD-SET在提升LVLM性能方面的有效性，还表明它在虚拟和增强现实等应用中具有潜力。该工具将作为开源发布，供社区进一步扩大其功能，生成更多定制的数据集。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21733", "html_url": "https://arxiv.org/abs/2508.21733", "title": "基于人工智能的计算机感知工具开发人员见解", "title_en": "Developer Insights into Designing AI-Based Computer Perception Tools", "authors": "Maya Guhan(1),Meghan E. Hurley(1),Eric A. Storch(2),John Herrington(3),Casey Zampella(3),Julia Parish-Morris(3),Gabriel Lázaro-Muñoz(4),Kristin Kostick-Quenet(1) ((1) Center for Ethics and Health Policy, Baylor College of Medicine, Houston, TX, USA, (2) Department of Psychiatry and Behavioral Sciences, Baylor College of Medicine, Houston, TX, USA, (3) Department of Child and Adolescent Psychiatry and Behavioral Sciences, Children's Hospital of Philadelphia, Philadelphia, PA, USA, (4) Center for Bioethics, Harvard Medical School, Boston, MA, USA)", "background": "人工智能（AI）基于的计算机感知（CP）技术利用移动传感器收集行为和生理数据，以供临床决策使用。这些工具能够重塑临床知识的生成和解释方式。然而，这些工具的有效整合取决于开发者如何平衡临床效用与用户接受度和可信度。", "innovation": "我们的研究通过对20位开发基于AI的CP工具的开发人员进行深入访谈，揭示了开发工具的设计优先事项：1）要考虑上下文以确保对患者和临床医生都具有解释性；2）将工具与现有临床工作流程对齐；3）适当定制以适应相关利益相关者，提高可用性和接受度；4）在创新与现有范式之间保持平衡。研究结果强调，开发人员不仅被视为技术建筑师，也是伦理守护者，设计工具既符合用户需求，也体现认识论责任（优先考虑客观性并推进临床知识的发展）。", "conclusion": "为了实现这一平衡，我们提出了以下建议：记录定制设计选择的过程，明确定制选择的界限，透明传达输出信息，以及投资于用户培训。这些目标需要开发者、临床医生和伦理学家之间的跨学科合作来实现。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的无侵入式卷积神经网络可靠性监测", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络（CNNs）已成为现代计算机视觉的基础，实现了各类图像识别任务的前所未有的准确性。尽管CNNs在同分布数据上表现出色，但在对抗性扰动面前仍然脆弱，对抗性扰动是肉眼不可见输入修改，会导致高置信度的误分类。然而，现有的检测方法要么需要昂贵的重新训练，要么修改网络架构，要么在干净的输入上降低性能。本文展示了对抗性扰动在CNN激活层中会产生立即且可检测的熵签名，无需模型修改即可进行监控。通过在VGG-16上进行并行熵监控，我们证明对抗性输入会一致地使早期卷积层的激活熵改变7%，从而使检测准确率达到90%，同时将错误正例率和错误负例率保持在20%以下。", "innovation": "本文证明了对抗性扰动在CNN激活层中会导致可检测的熵签名变化，从而提出了一种无需任何模型修改即可识别对抗性输入的无侵入式监测方法。这种方法仅依赖于激活熵的变化来进行实时检测，并且不会损害原始模型的性能。", "conclusion": "CNN的可靠性可以通过激活熵的变化来单独评估，这使得可以在不损害原始模型性能的情况下，实时检测对抗性输入的实用诊断视觉系统得以实现。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21727", "html_url": "https://arxiv.org/abs/2508.21727", "title": "OptMark: 在推断期间优化的稳健多位扩散水印技术", "title_en": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization", "authors": "Jiazheng Xing,Hai Ci,Hongbin Xu,Hangjie Yuan,Yong Liu,Mike Zheng Shou", "background": "水印扩散生成图像对于版权保护和用户追踪至关重要。现有的扩散水印方法面临重大限制：零比特水印系统缺乏大规模用户跟踪能力，而多比特方法对某些图像变换或生成攻击极为敏感，导致整体鲁棒性不足。", "innovation": "本文提出了一种基于优化的方法OptMark，该方法将鲁棒多比特水印嵌入到扩散去噪过程的中间潜在变量中。OptMark 策略性地在早期插入结构性水印以抵抗生成攻击，在后期插入细节水印以抵御图像变换，同时使用定制的正则化项以保持图像质量和不可感知性。通过引入伴随梯度方法，OptMark 处理了优化过程中内存消耗随去噪步骤线性增长的挑战，将内存使用从O(N)减少到O(1)。实验结果表明，OptMark 在确保图像质量和不可感知性的前提下，能够实现鲁棒的水印嵌入，并对值量变换、几何变换、编辑和再生攻击具有强大的抵抗力。", "conclusion": "OptMark 通过在推断时间的优化过程中嵌入鲁棒的多比特水印，有效解决了现有方法的鲁棒性和健壮性问题，实现了不可见的多比特水印嵌入，同时提高了对多种图像攻击的抵抗能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么止于单词？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统光学字符识别(OCR)技术将每个字符分开处理并识别，但这容易导致字符分割错误，并且缺乏上下文信息，无法有效利用语言模型。近年来序列到序列翻译的进展使得现代技术能够先检测单词，然后逐字输入到模型中，直接输出完整的单词序列，这种做法能够更好地利用语言模型并规避易出错的字符分割步骤。然而，这种方式将精确度瓶颈转移到了单词分割上。因此，本文提出了一种自然且逻辑上的进步，即从单词级别的OCR发展到行级OCR，能够绕过单词检测中的错误，并提供更大的上下文句子，以更好地利用语言模型。尽管进行了全面的文献回顾，但我们并未发现可用于训练和基准测试这种从单词级到行级OCR转变的公开数据集。因此，我们还贡献了一个精心收集的包含251个英文字页图像并带有行级注释的数据集。实验证明，所提出的技术不仅提高了OCR的准确率，还提高了效率。连续改进的大规模语言模型也可能使我们的方法有机会利用这些进展。", "innovation": "本文提出了一种新的逻辑上的进步，从传统基于单词的OCR转向行级OCR的方法。该方法能够绕过单词检测中的错误，并提供更大的上下文句子，以更好地利用语言模型。此外，研究还贡献了一个精心收集的数据集，用于训练和基准测试这种方法。基于这个方法的实施结果，实现了5.4%的端到端准确率的提高，并有4倍的效率提升。随着大规模语言模型的进一步改进，该方法可能具有更大的发展潜力。", "conclusion": "研究不仅证明了这种方法的准确性和效率提高，还展示了从单词级OCR到行级OCR转变的潜力，特别是在文档图像处理方面的潜在好处。此外，还提供了一个用于行级OCR训练和评估的新数据集。随着语言模型的不断发展，该方法未来有望进一步利用这些进展。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中基准测试GPT-5：可测量的进步，但持续需要专家监管", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展现了巨大潜力。GPT-5是一种新的LLM系统，专门针对肿瘤学使用进行设计。本文通过两个互补的基准测试评估了其性能：ACR放射肿瘤学在职考试（TXIT，2021）和一组60个真实放射肿瘤学病历案例，涵盖多种疾病部位和治疗方法。这些评估结果显示，GPT-5在多个方面优于先前版本的模型，但仍需要进一步的改进和专家审核。", "innovation": "GPT-5在放射肿瘤学对话生成中表现突出，特别是在剂量和诊断方面取得了显著进步。在实际案例中，GPT-5的治疗建议获得了高度评价，但还存在一些实质性错误，表明生成的建议需要在临床应用前经过严格的专家审核。这表明模型虽然取得了进步，但仍需进一步完善和优化以满足临床需求。", "conclusion": "尽管GPT-5在放射肿瘤学多项选择题基准测试中明显优于前几个版本的模型，但在生成实际放射肿瘤学治疗建议方面仍存在改进空间。生成的治疗建议虽然罕见地出现幻觉，但实质性错误的存在意味着GPT-5生成的建议在正式临床实施前还需要经过严格的专家监管。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark: 一种用于工业机床控制器动态水印的强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": " Industrie 4.0中高度网络化的机床控制器(MTC)是回放攻击的主要目标，这些攻击利用过时的传感器数据操纵执行器。现有的动态水印方案假设线性高斯动力学，并使用固定水印统计信息，使得它们容易受到MTC时间变化且部分专有行为的影响。", "innovation": "我们提出了DynaMark，一种强化学习框架，将动态水印建模为马尔可夫决策过程（MDP）。DynaMark通过在线学习可适应的策略，动态调整零均值高斯水印的协方差，无需系统知识。该框架通过动态权衡控制性能、能源消耗和检测信心来进行优化。此外，该框架还通过贝叶斯信念更新机制实现线性系统中的实时检测信心计算，适用于线性动力学系统。", "conclusion": "在西门子Sinumerik 828D控制器数字孪生体上，DynaMark相比常定方差基线方案能源水印能量减少了70%，同时保持了正常的轨迹。它还保持了与采样间隔相等的平均检测延迟。物理步进电机测试平台验证了这些发现，显示出较少的控制性能下降，并超过了现有基准。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05163", "html_url": "https://arxiv.org/abs/2504.05163", "title": "在知识不完整情况下的知识图谱增强检索生成方法的评估", "title_en": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": "KG-RAG是一种通过从知识图谱（KGs）检索相关信息来提升大型语言模型（LLMs）推理能力的技术，特别是在问答（QA）任务中。然而，实际中的知识图谱往往不完整，这意味着回答问题时所需的重要信息可能缺失。现有的基准测试未能充分捕捉知识图谱不完整性对KG-RAG性能的影响。", "innovation": "该论文系统评估了在知识不完整情况下的KG-RAG方法，通过使用不同的方法删除三元组并分析结果的影响，显示了KG-RAG方法对知识不完整性高度敏感，强调了在现实环境中需要更稳健的方法。", "conclusion": "KG-RAG方法在知识不完整的环境下对知识不完整高度敏感，这揭示了需要开发更稳健的方法以应对知识图谱不完整性的问题。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "细齿梳理精细网：针对有问题内容搜索和检索的精细网索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大规模语言模型（LLMs）依赖于诸如Common Crawl之类的网络规模数据集进行训练，这些数据集提供了现代部分模型超过80%的训练数据。然而，网络爬虫具有无选择性，这引发了数据质量、安全性和伦理上的挑战。尽管训练数据质量至关重要，但由于计算能力限制，先前对有害内容的研究仅限于少量样本。本项目提出了一种基于ElasticSearch的框架，用于索引和分析LLM训练数据集。该框架被应用于瑞士AI公司FineWeb-2语料库（1.5TB，四种语言），实现了快速查询性能——大多数搜索在毫秒级，全部在2秒内。", "innovation": "本框架为LLM训练数据集的索引和分析提供了一种新颖的方法，尤其针对大规模语料库（如FineWeb-2）实现了高效实时查询性能。它为实时数据分析提供了支持，这有助于更安全、更负责任的人工智能系统的开发。", "conclusion": "本研究展示了实时分析LMM训练数据集的技术，提供了实际工具以确保AI系统的安全性和可问责性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR: 概率置信度选择和排名", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "本文研究了通过生成多个候选解决方案并选择具有最高奖励的方案来提高大语言模型（LLMs）和大推理模型（LRMs）的准确性。推理任务的关键挑战在于设计一个评分函数，可以在没有正确答案的情况下识别正确的推理链。现有方法难以在没有正确答案的情况下有效评估推理和答案的置信度。因此，提出了一个名为PiCSAR的简单、无需训练的方法，该方法使用推理和最终答案的配对对数似然性来评分每个候选生成。这种方法将推理和答案的联合对数似然性自然地分解为推理置信度和答案置信度，从而提高了多种评测基准上的表现，并在16/20的比较中优于基线至少2倍的样本数。实验证明，正确的推理链表现出显著更高的推理和答案置信度，验证了PiCSAR的有效性。", "innovation": "提出了一种名为PiCSAR的简单、不需要训练的方法，利用推理和最终答案的联合对数似然性来评估每个候选生成，解决了在没有正确答案的情况下评估推理和答案置信度的难题，显著提高了多种评测基准上的准确性，并在16/20的比较中优于基线至少2倍的样本数。", "conclusion": "PiCSAR在各种评测基准上取得了显著的优势，展示了更高的推理和答案置信度，并通过实验验证了其有效性和鲁棒性，为大语言模型和大推理模型的推理任务提供了一种新的解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将穿戴设备数据转换为个性化健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴追踪器中提取个性化的见解需要复杂的数值推理，这挑战了标准的大语言模型（LLMs），需要工具方法如代码生成。大语言模型（LLMs）代理在大规模分析方面具有潜在的解决方案，但尚未广泛利用。", "innovation": "引入了一个名为Personal Health Insights Agent (PHIA)的系统，利用多步推理、代码生成和信息检索来分析和解释行为健康数据。创建并共享了两个基准数据集，包含超过4000个健康洞察问题。最终的650小时的人类专家评估表明，PHIA显著超过了强大的代码生成基准，实现了84%的对象化和数值问题准确性，在开放性问题上取得83%的好评率，并且更有可能达到最高质量评级。", "conclusion": "这项工作可以促进行为健康，使个体能够理解他们的数据，推动新的可访问、个性化和数据驱动的健康保健时代，惠及更广泛的人群。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "基于物理信息的高光谱成像光谱建模", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "高光谱成像技术能够提供丰富且连续的光谱信息，但由于数据的高维性及其复杂的光谱特性，对于此类数据进行有效的无监督学习和建模仍然是一个挑战。现有的方法往往需要大量的标注数据并且难以提供可解释的内部表示。", "innovation": "提出了一种名为 PhISM 的深度学习架构，该架构通过无监督学习来明确地分离高光谱观测值，并用连续基函数进行建模。与之前的模型相比，PhISM 在多个分类和回归基准测试中表现出更优的效果，同时仅仅需要有限的标注数据，并且通过可解释的内部表示提供了额外的见解。", "conclusion": "PhISM 架构展示了其在高光谱成像中的潜力，特别是在需要无监督学习的场景下。通过提供解释性更强的表示，PhISM 可以为这类复杂数据的研究提供新的方向。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21793", "html_url": "https://arxiv.org/abs/2508.21793", "title": "MoE-Health: 一种用于鲁棒多模态医疗预测的专家混合框架", "title_en": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction", "authors": "Xiaoyang Wang,Christopher C. Yang", "background": "医疗机构生成多样化的多模态数据，包括电子健康记录（EHR）、临床笔记和医学图像。有效利用这些数据进行临床预测具有挑战性，特别是在现实世界中，样本经常以不同的或不完整的方式出现。现有的方法通常需要完整的模态数据或依赖人工选择策略，这在数据可用性因患者和机构而异的现实临床环境中受到限制。", "innovation": "我们提出了MoE-Health，一种新的混合专家框架，专为医疗预测中的鲁棒多模态融合而设计。MoE-Health架构专门开发用于处理不同模态的数据样本，并提高关键临床任务的性能。通过利用专家模网络和动态门机制，我们的方法根据可用的数据模态动态选择和组合相关专家，从而实现对不同数据可用性场景的灵活性。", "conclusion": "我们在MIMIC-IV数据集上对MoE-Health进行了评估，跨三种关键临床预测任务：医院死亡率预测、长住院时间以及医院再入院预测。实验结果表明，与现有多模态融合方法相比，MoE-Health在不同的模态可用性模式下实现了更优的性能和鲁棒性。该框架有效地整合了多模态信息，提供了更优的预测性能和应对异质和不完整医疗数据的鲁棒性，使其特别适合在不同数据可用性的医疗环境中进行部署。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2302.00935", "html_url": "https://arxiv.org/abs/2302.00935", "title": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning", "title_en": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning", "authors": "Haichao Zhang,We Xu,Haonan Yu", "background": "利用离线数据预训练和在线强化学习微调的策略是通过结合两者的优点（样本效率和性能）来学习控制策略的一种有前途的方法。一种自然的方法是使用离线训练的策略初始化在线学习的策略。这项工作中，提出了政策扩展方案实现这一点。在离线学习策略后，将其作为策略集合中的候选策略。然后，添加另一个策略，该策略负责进一步学习。这两个策略将以自适应的方式组合以与环境交互。通过这种策略，离线学习策略在在线学习过程中得以完全保留，从而减缓摧毁离线策略有用的早期行为的问题，同时允许策略自然地参与到探索中。此外，通过学习，新添加的策略可能捕获新的有用行为。", "innovation": "提出的策略扩展方案是一种结合离线和在线强化学习优势的技术。该方案通过自适应地组合离线学习策略和新添加的策略，使得离线策略在初期学习中能被充分保留，同时允许策略自适应参与探索，并通过学习获得新的有用行为。这项工作为解决离线与在线学习之间的桥梁问题提供了一种新的解决方案。", "conclusion": "在多个任务上的实验结果证明了所提出方法的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 使用文本记忆库增强统一异常检测模型的逻辑能力", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "异常检测旨在识别与正常模式偏离的异常值，但由于可用的正常数据有限，这一过程颇具挑战性。大多数现有的统一方法依赖于精心设计的图像特征提取器和记忆库来捕捉对象之间的逻辑关系，而没有引入用于逻辑异常检测的文字记忆库。本文提出了一个三内存框架（TMUAD），通过构建类别的文本记忆库、对象级别的图像记忆库以及图像补丁级别的记忆库，增强异构性质的异常检测能力，从而更好地处理逻辑异常检测。", "innovation": "本文创新性地提出了一个三内存框架（TMUAD），该框架结合了三类内存库（即类别的文本记忆库、对象级别的图像记忆库以及图像补丁级别的记忆库）来共同优化结构和逻辑异常检测。文本记忆库通过逻辑意识文本提取器捕获输入图像中对象的丰富逻辑描述，保留完整的对象轮廓的对象级别图像记忆库，以及通过视觉编码器提取图像补丁级别的特征来构造结构异常检测的记忆库。通过这种方式，TMUAD 达到了七个公开可用数据集上的最先进的性能，这些数据集涉及工业和医疗领域。", "conclusion": "TMUAD 通过协作记忆库统一了结构和逻辑异常检测，实现了在七个公开数据集上的最佳性能，涉及工业和医疗领域。模型和代码可以在指定的链接中找到。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "关于情况识别中的单正多标签学习重新审视：混沌存在于歧义之中", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "情境识别（SR）是计算机视觉中的一个基本任务，旨在通过识别关键事件及其关联实体从图像中提取结构化的语义总结。现有的方法将动词分类视为单标签问题，但全面分析表明，这种表述无法解决视觉事件识别中固有的歧义性，因为同一张图像可以使用多个动词类别来合理描述。因此，动词分类实际上是多标签问题，因为动词类别之间存在广泛的概念重叠。", "innovation": "本文作出三个关键贡献：首先，通过实证分析揭示动词分类是多标签问题，由于动词类别的广泛概念重叠。其次，鉴于大规模数据集全标注的不切实际，提出将动词分类重新表述为单正多标签学习（SPMLL）问题，这是SR研究中的一个全新视角。第三，设计了一个全面的多标签评估基准，旨在公平评估模型在多标签设置中的性能。此外，为应对SPMLL挑战，进一步开发了图增强动词多层感知机（GE-VerbMLP），将图神经网络结合以捕捉标签间的关联，并采用对抗训练优化决策边界。", "conclusion": "在实际情况数据集上的大量实验表明，本方法在保持传统顶级1和顶级5准确性指标的同时，可以实现超过3%的MAP提升。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22288", "html_url": "https://arxiv.org/abs/2505.22288", "title": "压缩与准确性：提升模型的层级结构", "title_en": "Compression versus Accuracy: A Hierarchy of Lifted Models", "authors": "Jan Speller,Malte Luttermann,Marcel Gehrke,Tanya Braun", "background": "当前的提升表示算法，如Advanced Colour Passing (ACP)，通过分组相似分布的因子来构建提升模型，但这需要选择合适的超参数ε。选择合适的ε值是一个模糊的过程，可能需要进行多次ACP运行以找到最优的ε值，且不同的ε值可能导致模型差异大，降低模型的可解释性。因此，本文旨在提出一种无需超参数的提升模型构建的分层方法。", "innovation": "提出了一种无需超参数的提升模型构建方法，该方法通过高效计算ε值的层级结构，确保了模型层级关系的存在。这种方法允许在选择特定的ε值来运行ACP时明确地权衡压缩和准确性，并且能够提高不同模型之间的可解释性。", "conclusion": "本文提出的方法能够生成具有层级结构的提升模型，通过选择特定的ε值来运行ACP时，可以明确地选择压缩与准确性的权衡，并增强模型之间的可解释性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用PennyLane黑客马拉松挑战基准大型语言模型进行量子代码生成", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "近年来，大型语言模型（LLM）在代码生成方面展现了强大的潜力，尤其是在量子计算领域，它们的有效性仍然鲜有探索。本文利用来自Quantum Hackathon (QHack)的真实世界挑战，对PennyLane基于的量子代码生成性能进行了基准测试。", "innovation": "引入了一个名为QHackBench的新颖基准数据集，该数据集旨在评估大型语言模型在PennyLane编程环境中的性能。还提出了一种使用检索增强生成（RAG）的多代理评估管道，能够逐步改进不正确的解决方案，进一步提升执行成功率。", "conclusion": "研究结果表明，增强的RAG模型在复杂量子算法方面的生成结果与标准提示方法大致相当。论文还承诺公开QHackBench数据集及评估框架和实验结果，以推动量子编程领域的人工智能辅助研究进一步发展。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen: 正式验证的数据引擎实现可信赖的多模态几何问题求解", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题解决（GPS）要求可验证的逻辑连贯性和多模态推理能力。虽然大型语言模型（LLMs）在解决GPS方面表现出快速的进步，但其发展受到可靠基准和系统方法的缺乏的阻碍。LLMs固有的幻觉问题导致生成的GPS数据集常常噪音大、未经验证且自相矛盾，这对进步构成挑战。", "innovation": "我们引入了TrustGeoGen，这是一个数据引擎，用于生成形式上验证的几何问题，以建立一个原则性和可信的基准。我们的引擎集成四大创新：1) 多模态对齐，同步生成图表、文本和逐步解决方案；2) 形式验证，确保所有推理路径符合规则；3) 联想思维，将形式演绎与类似人类的逻辑步骤相连；4) 我们的GeoExplore系列算法，生成具有多种解决方案和自动反思回溯的多样化问题变体。", "conclusion": "使用该引擎，我们创建了GuoTrust-200K数据集和相应的GeoTrust-test基准，两者都保证了跨模态的一致性。实验表明，最先进的模型仅在GeoTrust-test上达到45.83%的准确率，突显了其重大挑战。此外，通过我们的合成数据进行训练，显著提高了模型在GPS任务上的性能，并在离域（OOD）基准上有良好的泛化能力。我们的代码和数据可在此处获得：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08344", "html_url": "https://arxiv.org/abs/2508.08344", "title": "基于知识图谱的RAG会失败吗？不完整知识下的推理实证洞察", "title_en": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": "基于知识图谱的检索增强生成（KG-RAG）方法是将大型语言模型的推理能力与知识图谱的结构化证据相结合的一种不断增加探索的方法。但现有评价实践存在不足：现有基准测试中常包含可以直接使用KG中的三元组回答的问题，这使得难以判断模型是否会进行推理，还是仅仅检索答案。此外，不一致的评估准则和宽松的答案匹配标准进一步模糊了有意义的比较。文章指出，在知识不完整的情况下，当前的KG-RAG方法推理能力有限，往往依赖内部记忆，并且其设计不同，泛化能力也不同", "innovation": "提出了构建基准的方法和评估协议，以系统性地评估在知识不完整性下的KG-RAG方法。", "conclusion": "当前的KG-RAG方法在缺少知识的情况下推理能力有限，通常依赖内部记忆，泛化能力受其设计影响。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba状态空间模型是李普西鲁稳定性学习者", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba状态空间模型（SSMs）最近在各种任务中超越了最新的Transformer大型语言模型（LLMs），并被广泛应用。然而，对于基于递归的深度模型（如SSMs），其递归动态的敏感性使其在稳定学习方面存在重大问题。目前，关于Mamba下常用微调方法（如混合精度微调MPFT和参数高效微调PEFT）对其递归动态稳定性的研究仍然不足。", "innovation": "本文实验表明，使用MPFT和PEFT的结合方式，Mamba LLMs极其稳定，与Transformer LLMs在相同条件下可能表现出显著的偏差或发散。Mamba LLMs的稳定性基于其递归动态，通过动力系统理论（特别是Lyapunov稳定性）证明递归动态是稳定的。此外，通过使用MPFT和PEFT研究Mamba LLMs在上下文学习中的能力，补充了先前的相关工作。", "conclusion": "Mamba LLMs的稳定递归动态使得它们在混合精度微调和参数高效微调下的微调非常可靠，其稳定性可以通过动力系统理论证明。未来研究可以进一步利用这些微调方法探索Mamba LLMs在自然语言任务中的上下文学习能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型对大肠3D形态进行细化以生成数字模型", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "人体器官的3D建模对于虚拟成像试验中的数字模型构建至关重要。然而，诸如大肠等复杂几何结构和形状变异极大的器官建模仍然极具挑战性。", "innovation": "提出了一种名为CLAP的新颖的条件Latent点扩散模型，该模型结合了几何深度学习和去噪扩散模型，以增强大肠的3D表示。该模型通过层次变分自编码器学习全局和局部的潜在形状表示，利用两个条件扩散模型在潜在空间内细化器官形状，并使用预训练的表面重建模型将细化后的点云转换成网格。", "conclusion": "CLAP在形状建模精度上取得了显著提升，减少了36%的Hausdorff距离和26%的Chamfer距离，相比初始的亚优化形状。该方法提供了一种稳健且可扩展的高保真器官建模解决方案，适用于各种解剖结构。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口指导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导是用于提升扩散模型样本质量的一种广泛使用的技巧。辅助模型通过比主模型更广泛地泛化来实现。现有方法在理论上和实践中都表明了辅助模型泛化错误相似但较强的特性带来的益处，并以此为基础引入了新型的、无需训练的方法。这种方法利用滑动窗口通过局部限制主模型的接收域选择性地对主模型进行指导，以增强长期空间相关性。这种指导方法无需访问先前迭代的模型权重、额外训练或类别条件。", "innovation": "提出了新颖的、无需训练的方法——掩码滑动窗口指导（M-SWG），通过局部限制主模型的接收域，选择性地对主模型进行指导，以增强长期空间相关性。该方法无需访问先前迭代的模型权重、额外训练或类别条件，同时实现了在ImageNet上的最高Fréchet DINOv2距离，且不会引入样本过度饱和。", "conclusion": "通过滑动窗口指导扩散模型的方法，即M-SWG方法，在无需训练的情况下显著提升了扩散模型的样本质量，特别是在与现有的指导方法结合使用时，达到了ImageNet上的最高Fréchet DINOv2距离，表明该方法的优越性。相关代码已开源。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "爱丽丝在差分 Wonderland 中的奇遇——卷一：导览之旅", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "神经网络无处不在，从大型语言模型、语音转录系统、分子发现算法、机器人技术等不同应用中都可以看到它们的身影。剥离其复杂形式后，神经网络可以简化为不同可微分的基本组件的组合。因此，研究神经网络需要学习如何编程以及如何与这些模型进行交互，这构成了差分编程的一部分。本文旨在为新入学者介绍这一引人入胜的领域，内容涵盖函数优化的基本原理、自动微分、以及处理序列、图、文本和音频的常见设计，旨在提供一个简洁而自包含的入门介绍，帮助读者理解当前最先进的模型，如大型语言模型和多模态架构等", "innovation": "本文提供了一个面向初学者的差分编程和技术框架的介绍，强调了关键设计技术，如卷积、注意力机制以及循环块的应用，旨在将理论与实际编程语言（如PyTorch和JAX）的实现相结合，从而帮助读者更好地理解和构建这些先进的模型", "conclusion": "本综述旨在通过理论和代码示例结合的方式，让读者能够理解一些最先进模型的工作原理，特别是大型语言模型和多模态架构等领域的最先进模型"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM：使用概率编程的因果贝叶斯推理架构用于不确定性下的机器人操控", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人执行任务时需要理解和推理物体之间的因果关系，但许多基于数据的方法缺乏因果语义，只考虑关联性。因此，现有的许多方法在面对不确定性时表现不佳，无法进行有效的干预推理以执行复杂的操作任务。这篇论文旨在解决这一问题，提出了COBRA-PPM架构，在不确定性下进行机器人操控推理与决策.", "innovation": "COBRA-PPM 架构创新性地结合了因果贝叶斯网络和概率编程，用于进行干预推理。它在高保真的Gazebo实验中表现优异，预测操作结果准确率高达88.6%，并在贪婪的下一个最佳行动选择中实现了94.2%的任务成功率。此外，该架构在从仿真到现实世界的迁移上也表现出色，能够处理传感器噪声和随机行为带来的不确定性.", "conclusion": "该研究提出了一种通用且可扩展的框架COBRA-PPM，能够支持广泛的操控场景，并为机器人与因果性的交叉研究奠定了基础。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE：一种针对大语言模型任务特定指令调优的数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "指令调优已经突显了大型语言模型（LLMs）在生成更具人类可控性和效果的各领域输出方面的巨大潜力。现有的方法主要依赖人工构造的相似度指标来选择与测试数据分布匹配的训练数据，目的是在减少指令调优损失（即后续令牌预测的交叉熵损失）的同时提高目标任务的性能。然而，观察到LLMs中的指令调优损失与实际任务性能之间的关系往往不是单调的，这就削弱了现有数据选择方法的有效性。", "innovation": "本研究引入了ROSE，一种新颖的基于奖励的数据选择方法，使用成对偏好损失作为奖励信号来优化任务特定指令调优的数据选择。ROSE通过适应影响形式，近似培训数据点相对于少量示例验证集的相对影响来选择最相关的培训数据点。实验结果表明，使用ROSE选择仅5%的训练数据，可以实现与全训练集微调相当的结果，并且优于其他最新的数据选择方法。", "conclusion": "我们的定性分析还证实了该方法在多个基准数据集和多种模型架构下的鲁棒泛化能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于注释分歧校准估计的有毒内容协作内容审查框架", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "内容审查通常结合了人类审查员和机器学习模型的努力。然而，这些系统往往依赖于审查过程中存在显著分歧的数据，反映出毒性感知的主观性。这种方法通常仅仅考虑多数标签，忽略了这种分歧所反映的内容本质上的模糊性。我们不将这种分歧视为噪音，而是将其视为有价值的信号，提示内容审查中的固有模糊性，这是仅考虑多数标签时所忽略的。", "innovation": "引入了一种新的内容审查框架，强调捕捉注释分歧的重要性。该框架使用多任务学习，毒性分类作为主要任务，而注释分歧则作为辅助任务。此外，还利用不确定性评估技术，尤其是校准预测，来考虑评论注释中的不确定性及模型预测毒性时的固有不确定性。该方法还允许审查员调整注释分歧的阈值，以确定何时应触发审查。实验表明，该联合方法可以增强模型性能、校准和不确定性估计，同时提高审查效率，优于单任务方法。", "conclusion": "本研究提出了一种创新的内容审查框架，通过内置的校准预测模型和不确定性估算，能够更好地识别和处理内容审查中的分歧，提高审查的质量和效率。该框架的提出为解决内容审查中固有的模糊性和不确定性提供了新的思路。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "基于迭代混合程序分析的LLM测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "自动化单元测试生成仍然是一个重大挑战，尤其是在处理实际项目中的复杂方法时。尽管大规模语言模型（LLMs）在代码生成方面取得了进展，但在实现高分支覆盖率上仍存在问题，因为这些模型在处理复杂的控制流结构方面的能力有限。", "innovation": "本文引入了一种名为Panta的技术，该技术模仿了人类开发者在分析代码和构建测试案例时所遵循的迭代过程。Panta结合了静态控制流分析和动态代码覆盖率分析，系统性地指导LLMs识别未覆盖的执行路径并生成更好的测试用例。通过嵌入迭代反馈驱动机制，该技术根据静态和动态路径覆盖率的见解持续优化测试生成，从而实现更全面和有效的测试。", "conclusion": "我们在来自开源项目的复杂性高的类上进行了实证评估，结果表明，Panta在行覆盖率和分支覆盖率方面分别实现了比最先进的方法高26%和23%的效果。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14681", "html_url": "https://arxiv.org/abs/2503.14681", "title": "DPImageBench：差分隐私图像合成的统一基准", "title_en": "DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis", "authors": "Chen Gong,Kecen Li,Zinan Lin,Tianhao Wang", "background": "差分隐私（DP）图像合成旨在生成保留敏感图像属性但又能保护个体隐私的人工图像。尽管近年来取得了进展，但在多个研究中发现评估协议不一致甚至存在缺陷，这不仅阻碍了对现有方法的理解，也阻碍了未来的发展。", "innovation": "该论文提出了DPImageBench，以解决评估协议不统一的问题。DPImageBench在多个维度上进行了精心设计：(1) 方法研究了11种主要方法，并从模型架构、预训练策略和隐私机制等方面系统地表征每个方法。(2) 评估包括了9个数据集和7个保真度及效用指标，以全面评估它们。此外，还发现选择下游分类器的标准只能基于最高准确性，违反了DP原则并高估了效用得分。DPImageBench纠正了这些错误。(3) 平台尽管在方法和评估协议方面建立了统一框架，DPImageBench还提供了标准化的接口，以便当前和未来的实现在统一框架中的实现。通过使用DPImageBench，发现了几个重要的发现。", "conclusion": "例如，尽管通常认为在公共图像数据集上预训练通常是有益的，但研究发现，预训练数据集和敏感图像之间的分布相似性对合成图像性能产生了显著影响，并不一定总是提高性能。此外，向低维特征（如敏感图像的高层次特征）添加噪声比向高维特征（如权重梯度）添加噪声较少受隐私预算的影响，前者在低隐私预算下表现更好。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "毒性引发毒性：政治播客中的对话链解码", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "数字通信中的有毒行为仍然是学术界和行业专业人士广泛关注的问题。尽管已经有许多研究探讨了社交媒体和讨论板上的毒性，但随着播客的快速增长和普及，这一领域的研究相对不足。本文通过收集和分析政治播客的对话记录，特别关注对话结构中的毒性如何通过一系列回复而表面并加剧，从而揭示有害语言在对话中如何升级。", "innovation": "本文填补了播客领域在毒性研究方面的空白，通过研究对话结构中的毒性，揭示了有毒语言如何在对话中不断升级的有机模式。此外，本文的工作提供了一个专门针对播客对话中毒性的数据集，为这一研究领域做出了贡献。", "conclusion": "研究表明，毒性行为在对话中具有连锁效应，一次不适当或有毒的评论可能会引发后续更加有毒的回应。通过理解这种对话链的动态，可以帮助制定更有效的策略来减少播客中的有毒行为，提升数字沟通环境的质量。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "基于值顺序估计距离度量学习的分类数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是数据挖掘中常用的机器学习方法，能够处理和分析数据集以自动揭示样本分布模式。然而，由于普遍存在的分类数据自然缺乏像数值数据那样的欧几里得距离空间，分类数据的分布通常被低估，从而导致有价值的聚类信息被扭曲。鉴于此，本研究提出了一种新颖的距离度量学习方法，旨在通过学习最优的顺序关系来直观地表示分类属性值，并在类似于数值属性的线性空间中量化它们的距离。", "innovation": "该方法引入了一种基于值顺序估计的距离度量学习法，以更好地处理分类数据的聚类问题。与主观创建的模糊分类值不同，该距离度量在聚类的背景下进行学习。在此基础上，开发了一种新的联合学习范式，可以交替进行聚类和顺序距离度量学习，并保证较低的时间复杂性和收敛性。这种聚类友好型的顺序学习机制以及顺序距离和欧几里得距离的一致性顺序性质，使得该方法在分类和混合数据集上实现了卓越的聚类精度。此外，学习到的距离度量显著降低了理解非直观分类数据的难度。实验结果验证了该方法的有效性。", "conclusion": "该研究提出的方法在分类和混合数据集上展示了优秀的聚类性能，并且通过学习顺序距离度量显著改善了对非直观分类数据的理解和管理。源代码可在提供的URL中获取。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans: 深度推理翻译通过强化学习", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "近年来，深度推理语言模型（如OpenAI的o1和DeepSeek-R1）在各类下游任务中表现出色。自由翻译作为多语言世界中的一个重要且有趣的任务，需要超越逐词翻译。然而，该任务在深度推理语言模型中仍处于探索阶段。", "innovation": "本文提出了DeepTrans，一种通过强化学习（RL）学习自由翻译的深度推理翻译模型。模型通过预先定义的评分标准对翻译结果和思维过程进行建模，以此教导DeepTrans如何思考和自由翻译给定的句子。此外，RL训练不需要任何标签的翻译数据，从而避免了人力密集的标注或资源密集的数据合成。", "conclusion": "实验结果显示DeepTrans的有效性。利用Qwen2.5-7B作为骨干网络，DeepTrans在文学翻译任务上的性能提高了16.3%，并超越了强大的深度推理语言模型。此外，我们在RL探索过程中总结了失败和有趣的发现。希望通过这项工作能够激发其他研究人员在自由翻译方面的兴趣和研究。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用未结构化知识的检索增强机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "检索增强生成(RAG)引入额外信息以增强大型语言模型(LLMs)。在机器翻译(MT)中，之前的研究所使用的方法主要包括从配对的MT语料库中检索上下文示例，或从知识图谱中检索特定领域的知识来增强MT模型。然而，大量世界知识组织在未结构化的文档中，并且可能在不同语言之间没有完全配对。因此，作者研究了如何利用这些未结构化的文档来增强MT模型。", "innovation": "该研究构建了RAGtrans基准，包含169K通过GPT-4o和人类翻译收集的MT样本，并提供了多种语言的文件以补充这些样本的知识。在此基础上，首次提出了一种多任务训练方法，从而使LLMs学会在翻译过程中利用从多语言文档获取的信息。这种方法利用现有多语言语料库创建辅助训练目标，无需额外的标签要求。实验证明，该方法显著提高了LLMs的性能。", "conclusion": "作者通过实验结果展示了所提出的多任务训练方法在En-Zh和En-De翻译中的性能提升，并指出目前LLMs在这一任务中面临的几个关键挑战。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18948", "html_url": "https://arxiv.org/abs/2411.18948", "title": "RevPRAG：通过LLM激活分析揭示检索增强生成中的投毒攻击", "title_en": "RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis", "authors": "Xue Tan,Hao Luan,Mingyu Luo,Xiaoyan Sun,Ping Chen,Jun Dai", "background": "检索增强生成（RAG）通过从相关知识数据库中检索信息来丰富大型语言模型（LLMs）的输入，使其能够生成更加准确和上下文相关性强的回复。然而，知识数据库来源自如Wikipedia这样的公开渠道，可能会引入新的攻击面。RAG投毒涉及向知识数据库注入恶意文本，最终导致生成攻击者的目标回复（也称为被投毒的回复）。目前针对这些投毒攻击的检测方法有限。这项工作旨在填补这一空白。研究者引入了RevPRAG，一个基于LLM激活进行被投毒响应检测的灵活且自动化的检测管道。研究者发现，当LLM生成正确回复和被投毒回复时，其激活模式存在差异。", "innovation": "RevPRAG是一个基于LLM激活特征自动检测RAG被投毒方法，能够在多个基准数据集和RAG架构上实现98%的真阳性率，同时保持较低的假阳性率。这一方法填补了当前检测RAG投毒攻击方法的空白。通过对LLM激活特征的研究，RevPRAG能够识别出生成正确回复和被投毒回复之间的差异模式，从而进行有效的检测。", "conclusion": "研究使用RevPRAG在多个基准数据集和RAG架构上测试了其检测能力，结果表明该方法能够高效地检测RAG被投毒攻击。这一研究对于理解和防范RAG中的投毒攻击具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG: 图中公平删除方法", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着对隐私法规的日益重视，机器遗忘在实际应用中变得尤为重要，尤其是在社交媒体和推荐系统等场景中，这些场景可以通过图结构来表示。现有的图遗忘方法通常会无差别地修改节点或边，忽视了这些修改对公平性的影响。例如，忘记不同性别用户之间的联系可能会无意中加剧群体间的不平等。为解决这一问题，本文提出了一种新的框架，旨在同时优化图结构和模型以实现公平遗忘。", "innovation": "本文提出了FROG框架，通过重新连接图来移除阻碍遗忘的冗余边，并通过目标化的边增强来维持公平性。此外，还引入了一种最坏情况下的评估机制，以评估模型在挑战性场景下的鲁棒性。", "conclusion": "实验结果表明，本文的方法在实际数据集上实现了比现有基线更有效的公平遗忘。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种固有的可解释性视网膜底片图像疾病检测混合全卷积CNN-Transformer模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "许多医学影像任务中，卷积神经网络（CNNs）有效地从图像中提取层次化的局部特征。近年来，视觉变换器（ViTs）由于使用自我注意机制捕捉全局依赖关系而变得流行，但缺乏卷积固有的空间定位能力。因此，已经开发了结合两者优点的混合模型，但由于难以解释性，这些混合模型在医学影像中的应用受到了限制。在这项工作中，作者介绍了一种为疾病检测而设计的可解释性混合全卷积CNN-Transformer架构。", "innovation": "与通常用于ViTs的后验重要性方法不同，该方法生成忠实且局部化的证据图，直接反映了模型的决策过程。该模型在两项基于彩色底片图像的医疗任务中评估，相比黑盒模型和可解释模型，其具有状态最优的预测性能，并在单次前向传递中提供类特异性稀疏证据图。", "conclusion": "该模型通过结合CNN和ViT的优点，实现了优异的疾病检测性能，同时提供了易于解释的证据图，为进一步的医学影像应用提供了保障。相关代码可以在提供的链接中找到。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生驱动的AI模拟：系统性综述、参考框架及标准化架构映射", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "现代非符号AI应用中存在的数据量不足和数据质量问题是其普及的关键障碍。为缓解这些问题，AI模拟利用虚拟训练环境，这种环境中AI代理可以安全有效地开发，同时使用模拟合成数据。数字孪生为AI模拟开辟了新的途径，通过提供高度仿真的物理系统虚拟复制品，并具备最先进的模拟器和与物理系统交互的能力，从而进一步收集数据。", "innovation": "该研究通过系统性综述22篇主要研究，分析并提出了数字孪生和AI组件的技术趋势，构建了参考框架，并将其映射到ISO 23247数字孪生的标准架构上，为研究人员提供了架构指南。同时，研究还指出了研究者需要面对的挑战和研究机会。", "conclusion": "研究基于分析结果构建了一个参考框架，并提供了架构指南，并将其映射到ISO 23247数字孪生的标准架构上，通过映射提出了数字孪生和AI组件布置的指导方案。最后，研究指出了未来研究者需要解决的研究挑战和机会。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE: 物理启发的刚性神经OD模型在化学反应速率估计中的应用", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "估计复杂化学反应的速率系数对于推进详细的化学模型至关重要。然而，实际大气化学系统中的刚性特性导致了训练不稳定性和收敛性差的问题，这阻碍了基于学习方法的有效速率系数估计。", "innovation": "本文提出了一种刚性物理启发的神经常微分方程框架（SPIN-ODE），该方法引入了三阶段优化过程：首先是训练一个黑盒神经OD模型拟合浓度轨迹；其次是预训练化学反应神经网络（CRNN）学习从浓度到时间导数的映射；最后，通过与预训练的CRNN集成来微调速率系数。", "conclusion": "通过对合成和新提出的实际数据集进行广泛实验，验证了我们方法的有效性和鲁棒性。作为首个针对刚性神经OD模型进行化学速率系数发现的研究，本研究为将神经网络与详细化学模型集成开辟了有前景的方向。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "投掷骰子并在你跳跃之前观察：超越下一标记预测的创意极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "本文旨在设计一套简单的算法任务，以孤立地评估现有语言模型的创造性边界。这些任务是对现实世界开放性任务的松散抽象，类似于实际任务需要远见和创造性的飞跃，我们的任务要求模型进行未显式的、开放式的随机计划，以发现知识图中的新联系或构建新模式。研究发现，单一标记的学习方法在多样性和原创性方面表现较差，而多标记的方法（无教师训练和扩散模型）在这些方面表现更优。", "innovation": "本文提出了一个有原则、最小的测试床来分析开敞性的创造技能，并提供了超越单一标记预测和温度采样的新论据。此外，研究发现，在输入层注入噪声（称为种子条件）的效果出人意料地好，甚至在某些情况下优于从输出层进行的温度采样。", "conclusion": "本文的工作提供了一个有原则、最小的测试床来分析开放性创造技能，并提出了新的论据，鼓励向超越单一标记预测和温度采样的方法转变。部分代码已公开。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "基于风格共享的去中心化领域泛化：形式化模型与收敛分析", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "联邦学习（FL）的研究主要集中在训练和测试时本地数据集统计特征不变的场景，但在实践中这一假设往往不成立，因为数据分布可能会发生变化。为此，领域泛化（DG）方法被开发出来，这些方法借助源域数据来训练能够在未知目标域中泛化的模型。现有工作的两个主要缺口在于：缺乏正式的数学分析来定义DG目标；以及在FL领域，DG研究主要局限于星形拓扑架构中。文章围绕这两个问题展开研究，提出了一种去中心化的DG算法—式风格共享（$\textit{StyleDDG}$），使得设备能够通过共享从其数据集中推断出的风格信息来进行DG。此外，文章提供了第一个系统化的分析基于风格的DG训练在去中心化网络中的方法，将现有的集中式DG算法纳入其框架，并通过形式化描述现实$\textit{StyleDDG}$的运行机制，得到能够确保$\textit{StyleDDG}$收敛的分析性条件。通过在流行DG数据集上的实验，证明$\textit{StyleDDG}$虽然通信开销很小，但在目标域上的准确性上达到显著提升。", "innovation": "开发了一种名为$\textit{StyleDDG}$的去中心化DG算法，该算法允许设备在网络中通过共享从其数据集中推断出来的风格信息来进行领域泛化。提供了首个系统化的风格为基础的DG训练在去中心化网络中的分析方法，将现有的集中式DG算法纳入其框架，并通过其形式化模型来描述$\textit{StyleDDG}$，最终给出了能够保证$\textit{StyleDDG}$收敛的分析性条件。", "conclusion": "通过实验，证明了$\textit{StyleDDG}$可以在最小通信代价下达到显著提高目标域上的准确性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "Latent Adaptive Planner for Dynamic Manipulation", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "当前，用于动态非持握式操作的任务需要实时适应，并实现类似人类的柔顺动作和适应行为。传统的规划方法通常依赖于高维状态空间，难以有效地从人类演示视频中学习并实现这种操作。因此，需要提出一种新的方法来解决此类问题。", "innovation": "本文提出了Latent Adaptive Planner (LAP)，一种轨迹级的低维潜在变量策略，用于动态非持握式操作。LAP通过在低维潜在空间中进行推理，有效地从人类演示视频中学习，并在执行过程中通过保持潜在计划的后验并通过新观察进行变异重规划，实现实时适应。此外，通过引入基于模型的比例映射模型，LAP能够从人类演示中再生精确的动力学关节状态和物体位置。", "conclusion": "LAP在具有不同物体属性的盒子捕获实验中展示了更高的成功率、更平滑的轨迹和更高的能量效率。LAP能够使机器人在实际时间尺度上进行适应性操作，并成功地跨不同的机器人平台进行转移。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解任意视频中的摄像机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "介绍了CameraBench，这是一个大规模数据集和基准，旨在评估和提升摄像机运动理解。该数据集包含约3000个多样化的互联网视频，并通过严格的多阶段质量控制过程标注。本文贡献之一是与摄影师合作设计的摄像机运动基本元素分类。研究发现，某些运动，如“跟随”（或追踪）需要理解场景内容，例如移动的对象。通过大规模的人类研究量化人工标注性能，发现领域专业知识和基于教程的培训可以显著提高准确性。例如，初学者可能会将“缩放”（内参数的变化）与“向前移动”（外参数的变化）混淆，但可以通过培训区分这两个概念。", "innovation": "文中贡献之一是设计了摄像机运动基本元素分类。通过人工标注研究发现，理解某些依赖于场景内容的语义基本要素是具有挑战性的，而对轨迹的精确估计需要几何基本要素。使用CameraBench对Structure-from-Motion (SfM)和Video-Language Models (VLMs)进行了评估。研究发现了这两种模型在不同方面的性能和限制，进而通过CameraBench微调生成的VLM，使其兼备捕捉语义和几何基本要素的能力，并展示了应用，如运动增强的描述、视频问答和视频-文本检索的应用场景。", "conclusion": "希望本文提供的分类、基准和教程能够推动未来在更广泛视频中理解摄像机运动的努力，朝着最终目标不断迈进。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning：增强知识边界意识的LLM多组分问题推理", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "LLM在多种应用中广泛应用，但它们生成不存在事实的幻觉是一个重要的问题。现有研究通过分析内部参数知识边界来估计置信度来解决这一问题，但这些研究主要集中于单问题设置，尚未探索需要同时准确回答多个问题的更具有挑战性的多问题设置。", "innovation": "提出了一种名为MAC-Tuning的新方法，该方法在指令数据微调过程中分离答案预测和置信度估计的学习，以解决多问题设置的问题。实验表明，该方法在平均精确度方面比基线方法高出25%。", "conclusion": "研究通过MAC-Tuning方法解决了多问题设置下的LLM幻觉问题，在多种问题同时回答的准确性和置信度估计方面取得了显著进步。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "机器人运动中的本体规模法则朝着这个方向", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "通用本体化的愿景旨在构建可以在任何机器人上运行的通用本体化代理，但实现这一愿景的关键因素仍未得到充分理解。本文利用机器人运动作为试验平台，探究本体规模法则，即增加训练本体的数量可以提升对未见过的本体的泛化能力。", "innovation": "研究通过程序生成约1,000个具有拓扑、几何和关节级动力学变化的本体，对其随机子集训练策略，发现本体规模法则的确存在正向的规模趋势。相较之下，固定本体上的数据规模并未能提供相同程度的泛化能力。最优策略能够在模拟和现实世界中零样本迁移至未见过的新本体，包括Unitree Go2和H1机器人。", "conclusion": "这些结果是通向广义本体化智能的一个步骤，对于可配置机器人的自适应控制、形态协同设计等领域具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA: 一个治理人工智能代理系统的安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "大型语言模型（LLM）基于的代理越来越多地自主交互、协作和代理任务，减少了人类干预。行业指南强调用户需要对代理系统保持全面控制，以减轻恶意代理可能带来的损害。已提出的代理系统设计大多仅在理论上解决代理身份、授权和代理问题，缺乏实际实现和评估，并且未提供用户控制的代理管理功能。因此，该研究提出了一个可扩展的治理平台SAGA，通过中央实体提供用户对代理生命周期的监控，引入加密机制确保代理间交互的细粒度访问控制，保障正式安全保证，并在多种环境下进行了评估，证明了其性能和实用性。", "innovation": "SAGA提出了一种新的可扩展安全架构，使用户能够对其代理系统的生命周期进行监控。通过中央提供商实体，保持代理联系信息和用户定义的访问控制策略，并帮助代理在相互交互时执行这些策略。SAGA引入了一种加密机制，为代理间提供了细粒度的访问控制，提供了正式的安全保证，并在多个地理位置、不同设备和云计算环境下的LLM代理任务中进行了评估，展示了其在广泛条件下的低性能损耗和无影响的任务实用性。该架构有助于安全和值得信赖的自主代理部署，加速了该技术在敏感环境中的负责任采用。", "conclusion": "SAGA架构确保了用户对代理系统的全面控制，通过加密机制提供了细粒度的访问控制，保障了正式的安全性。SAGA在多种代理系统任务中的评估表明，它能够减少性能损耗并保持任务的实用性，这样的设计能够促进自主代理技术在敏感环境中的可靠和广泛应用。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越 token 的 LLM 公平性量化：一种语义和统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "现有的大型语言模型（LLMs）往往生成具有内在偏见的响应，这降低了其在实际应用中的可靠性。现有评估方法通常忽略了长形式回应中的偏见和LLM输出的内在变异性。这给评估组级公平性带来了挑战。", "innovation": "提出了一种名为 FiSCo（细粒度语义比较）的新颖统计框架，通过检测不同群体响应之间的细微语义差异来评估大语言模型的组级公平性。这种方法不同于以往注重情感或token级比较的工作，它在声明水平上进行操作，并利用蕴含验证来评估意义的一致性。这种方法通过对模型输出进行语义分解，并应用统计假设检验来比较组间和组内的相似性，从而实现对细微偏见的稳健检测。", "conclusion": "通过将新型的组现实反事实公平概念形式化，并在合成和人类标注的数据集（涵盖性别、种族和年龄）上验证 FiSCo，实验结果显示，FiSCo 更可靠地识别复杂的偏见，并减少了由于随机性带来的影响，表现出色于各种评估指标。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12072", "html_url": "https://arxiv.org/abs/2506.12072", "title": "TrueGL：全面堆栈搜索中基于事实的学习的诚实、可靠和统一引擎", "title_en": "TrueGL: A Truthful, Reliable, and Unified Engine for Grounded Learning in Full-Stack Search", "authors": "Joydeep Chandra,Aleksandr Algazinov,Satyam Kumar Navneet,Rim El Filali,Matt Laing,Andrew Hanna", "background": "在信息开放和自由的时代，依赖人工智能（AI）的趋势日益明显。然而，现有的AI工具在评估信息的可靠性及其判断依据方面存在局限性。因此，用户需要更有效的系统来评估在线信息的真实性。尽管主要的搜索引擎集成了AI功能，但往往缺乏清晰的可靠性指标。研究指出，现有系统在评估信息可靠性时存在不足。", "innovation": "本文提出了一种名为TrueGL的模型，这是一个基于IBM Granite-1B微调版本的信息评估系统。TrueGL通过一个自定义数据集进行训练，并集成了可靠性评分系统，能够给出连续的可靠性评分，并通过文本解释返回评分结果。实验表明，TrueGL在多个评价指标上（如MAE、RMSE和R2）优于其他小型语言模型和基于规则的方法。其高精度、广泛的内容覆盖以及易用性使用户更容易获得可靠的信息，有助于减少在线虚假或误导性内容的传播。", "conclusion": "TrueGL模型通过提供针对实际评分的信任评估，并辅以详细的文本解释，显著提升了搜索结果的可靠性。该研究公开了用于评估真实性的一套代码，并发布了模型，使得更加公平和高效的信息评估成为可能。这有助于增强网络信息的真实性，减少误传信息的现象。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种基于LLaMA2的安全、高效和自适应联邦分割框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私营数据因其高质量具有提高大型语言模型（LLM）性能的潜力，但由于这些数据分散在多个数据孤岛中以及LLM的高计算需求，它们在联邦环境中的部署受到限制。为解决这一问题，提出了基于Transformer的联邦分割模型，该模型将大部分模型参数卸载到服务器（或分布式客户端），仅在客户端保留一小部分以确保数据隐私。然而，尽管采用了这种设计，这些模型仍然面临三个挑战：1）点对点密钥加密难以有效保护传输向量；2）LLM的自回归性质意味着联邦分割学习只能顺序训练和推理，导致高通信开销；3）固定的分割点缺乏对下游任务的适应性。", "innovation": "文章介绍了一种基于LLaMA2的名为FedSEA-LLaMA的联邦分割框架，其创新点包括：1）在前向隐藏状态下注入高斯噪声，以实现安全的端到端向量传输；2）使用注意力掩码压缩和KV缓存协作来降低通信成本，加快训练和推理；3）允许用户基于特定任务需求动态调整输入/输出块的分割点。实验证明，FedSEA-LLaMA在自然语言理解、总结和对话式QA等任务中保持了与集中式LLaMA2相当的性能，并实现了高达8倍的训练和推理速度提升。进一步分析隐私攻击和不同的分割点也表明FedSEA-LLaMA在安全性和适应性方面的有效性。", "conclusion": "实验结果表明，FedSEA-LLaMA在保持与集中式LLaMA2相似的性能的同时，实现了8倍的训练和推理速度提升，并且通过动态调整分割点在安全性和适应性方面表现出色。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR: 动态差异感知时序残差网络在纵向放射报告生成中的应用", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "放射报告生成（RRG）通过自动化从医疗影像中生成放射报告，提高了报告过程的效率。纵向放射报告生成（LRRG）在此基础上进一步发展，通过对比当前和之前的检查，帮助跟踪临床发现随时间的变化。现有LRRG方法仅利用视觉预训练编码器从当前和之前的图像中提取特征，然后拼接生成最终报告。然而，这些方法在特征提取过程中难以有效捕捉空间和时间相关性，导致提取出的特征无法充分捕捉不同检查间的差异信息，从而低估了期望的进展，导致LRRG的性能不佳。", "innovation": "本文提出了一种新颖的动态差异感知时序残差网络（DDaTR）。DDaTR 在视觉编码器的每个阶段引入了两个模块来捕捉多级空间相关性。动态特征对齐模块（DFAM）用于跨模态对齐以前的特征，以保证以前的临床信息的完整性。动态差异感知模块（DDAM）根据增加的以前特征，捕捉检查之间的有利差异信息。此外，DDaTR 使用动态残差网络单向传输纵向信息，有效地建模了时间相关性。多方面的实验证明，DDaTR在三个基准上的性能优于现有方法，证明了其在RRG和LRRG任务中的有效性。", "conclusion": "DDaTR 通过引入多种机制在不同水平上捕获时空相关性，有效解决了现有 LRRG 方法难以全面捕捉和展示检查间差异信息的问题，显著提升了纵向放射报告生成的任务性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13611", "html_url": "https://arxiv.org/abs/2506.13611", "title": "一种用于电力系统闪烁估计的混合人工智能方法", "title_en": "A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems", "authors": "Javad Enayati,Pedram Asef,Alexandre Benoit", "background": "本文介绍了一种结合H滤波器和自适应线性神经网络的新型混合人工智能方法，用于电力分配中的闪烁成分估计。这种方法利用了H滤波器在不确定和噪声条件下的稳健性，通过ADALINE准确识别嵌入在信号中的闪烁频率。其结合使时间域估计更加高效，具有快速收敛性和抗噪性，解决了现有频域估计方法的关键限制。", "innovation": "该方法结合了H滤波器的鲁棒性与ADALINE的准确频率识别能力，能够有效处理复杂的电力扰动，无需事先了解噪声特性或进行详细参数调整。这种方法还通过统计分析、蒙特卡洛仿真和真实世界数据验证了其优越的精确度、鲁棒性和计算负载减少等性能优势，与基于FFT和DWT的估计器相比具有明显优势。", "conclusion": "本文提出的方法能够高效、快速地进行闪烁估计，同时具有抗噪性和计算效率，能够有效解决现有技术中存在的问题，适用于电力系统中复杂的闪烁成分估计需求。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "科学可解释推理解网络（ScIReN）：在碳循环及其他领域发现隐藏关系", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对于减缓气候变化至关重要。虽然土壤有从大气中封存碳的潜力，但土壤碳循环仍不完全理解。现有基于现有知识的数学过程模型虽已开发，但由于存在诸多未知参数并在模型设置上经常不符合观察结果。另一方面，神经网络可以从数据中学习模式，但不遵守已知的科学定律，并且由于其黑箱性质，不能揭示新的科学关系。因此，提出了一种完全透明的框架——科学可解释推理解网络（ScIReN），该框架结合了可解释的神经网络和基于过程的推理。", "innovation": "ScIReN 结合了可解释的神经网络和过程推理。通过可解释的编码器预测科学上有意义的潜在参数，并通过可微过程解析器预测标签输出变量。ScIReN 利用了柯尔莫哥洛夫-阿诺德网络（KAN）确保编码器完全可解释，并揭示输入特征与潜在参数之间的关系；使用新型平滑惩罚来平衡表达性和简洁性。此外，使用新型硬Sigmoid约束层限制潜在参数在科学先验知识定义的有效范围内。过程解析器遵循既定的科学知识，而基于KAN的编码器则揭示了传统黑盒模型中隐藏的科学关系。研究者在两个任务中应用了 ScIReN：模拟土壤中有机碳的流动和建模植物的生态系统呼吸。ScIReN 在预测准确性上优于黑盒网络，同时提供了显著的科学可解释性——可以推断出潜在的科学机制及其与输入特征的关系。", "conclusion": "ScIReN 在模拟土壤中有机碳流动和建模植物的生态系统呼吸这两个任务中表现出色，在预测准确性和提供重大的科学解释性方面超越了黑盒模型。ScIReN 利用可解释性神经网络和过程推理，不仅遵守科学定律，还能揭示隐藏的科学关系，为模拟复杂的自然过程提供了一种新的方法。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对Web代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "现有的多模式大型语言模型（MLLM）通过生成基于网页屏幕截图的动作来与网页环境交互。该论文针对这种交互机制提出了一个名为WebInject的新颖攻击方法，该方法通过在渲染网页的原始像素值上添加扰动来改变网页代理的行为，使得代理执行攻击者指定的动作。", "innovation": "提出了一个名为WebInject的提示注入攻击方法，采用一种创新的优化策略。具体来说，通过训练神经网络来近似映射过程，并利用投影梯度下降来解决优化问题。这种方法有效地应对了原始像素值与屏幕截图之间的非可微映射难题。", "conclusion": "实验证明，WebInject方法在多个数据集上表现出高度的有效性，并显著优于基线方法。这表明该方法在确保网络安全方面具有重要的应用潜力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23197", "html_url": "https://arxiv.org/abs/2505.23197", "title": "具有自适应安全性和优化性的统一路径规划器", "title_en": "Unified Path Planner with Adaptive Safety and Optimality", "authors": "Jatin Kumar Arora,Soutrik Bandyopadhyay,Shubhendu Bhasin", "background": "自主机器人路径规划面临着优化性和安全性的基本权衡。传统算法通常侧重于其中之一。本文分析了这一背景。", "innovation": "提出了统一路径规划器（UPP），这是一种综合优化性和安全性的统一框架。UPP 是基于图搜索的算法，使用了包含动态安全成本的修改后启发式函数，实现了路径长度和障碍物间距之间的自适应平衡。证明了规划器的次优性边界，并表明可通过调整参数调节安全性到优化性的比率，虽然会增加计算复杂度。", "conclusion": "详尽的仿真显示，UPP 能实现高成功率，产生近似最优路径，增加的成本可以忽略不计，并且通过一个具有安全余量接近经典Voronoi规划器的硬件实现（TurtleBot）验证了其在复杂环境中的实际效用。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 基于偏差校正和非对称缩放增强的旋转量化技术用于大语言模型", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已成为最先进的大型语言模型（LLM）量化流水线中的关键组成部分，通过有效平滑权重和激活中的异常值。然而，进一步优化旋转参数只能提供有限的性能增益，并引入了显著的训练开销：由于旋转参数共享，必须同时加载整个模型以启用反向传播，导致内存消耗大幅增加并且实际应用受到限制。", "innovation": "此项工作识别了当前旋转量化方法的两个基本局限性：(i) 旋转无法对齐通道均值，导致量化范围变宽并增加舍入错误；(ii) 旋转使激活分布更趋向正态分布，增加了由截断错误引起的能量损失。为此，我们引入了 BASE-Q（结合偏差校正和非对称缩放的简单而强大的方法），有效减少舍入和截断错误。此外，BASE-Q 还允许分块优化，从而消除了对内存密集型的全模型反向传播的需求。", "conclusion": "在各种 LLM 和基准测试上的广泛实验表明，BASE-Q 的有效性，与 QuaRot、SpinQuant 和 OSTQuant 相比，准确率差距分别缩小了 50.5%、42.9% 和 29.2%。代码将在不久后发布。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超越频率：冗余在大规模语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "在大规模语言模型中，由于参数规模达到数十亿，隐私和公平性面临重大风险。先前的研究已证明频率和重复模式与记忆化之间的关联，但它们揭示出不同的响应模式：频率增加仅对未记忆样本有显著影响，而对已记忆样本的影响轻微。这种现象在不同模型规模中是一致的。通过控制前缀变化量化扰动强度，研究发现冗余性与记忆模式相关，大约79%的记忆样本具有低冗余性，并且这些低冗余样本的脆弱性是高冗余样本的两倍。此外，低冗余样本在扰动下下降了0.6，而未记忆样本的下降值仅为0.01，表明冗余内容越是丰富，越容易记忆但也更加脆弱。", "innovation": "先前的研究主要关注频率因素，而该研究探索了冗余性在记忆化模式中的作用，发现冗余性与记忆模式密切相关。通过反事实分析方法探究样本前缀扰动的影响，并量化扰动强度，这为预测和减轻大规模语言模型中的隐私风险和偏见提供了一种新的视角。此外，研究揭示了低冗余样本和高冗余样本之间的脆弱性差异以及记忆样本和非记忆样本对扰动的敏感度差异，为数据预处理提供了潜在的方法指导。", "conclusion": "约79%的记忆样本具有低冗余性，且这些低冗余内存样本的脆弱性是高冗余样本的两倍。在扰动下，低冗余样本下降0.6，而未记忆样本下降0.01，表明冗余性对记忆样本和非记忆样本的影响不同，且冗余性越多的内容更易被记得但也更加脆弱。这为设计冗余性指导的数据预处理方法提供了依据，有助于降低隐私风险并减少偏差以确保模型部署的公平性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA: 基于LLM反馈的时间序列异常推理", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在多个领域都至关重要，但当前方法通常仅提供二元异常分类，缺乏详细的类别划分或进一步的解释性分析。这限制了对异常情况的理解和处理。为此，该研究提出了一种名为Time-series Reasoning for Anomaly (Time-RA) 的全新任务，将传统的时间序列异常检测从判别性任务转变为生成性和推理性突出的任务，利用大型语言模型 (LLMs) 的能力。", "innovation": "提出了一种名为Time-RA的新任务，使时间序列异常检测任务从判别性转变为生成性和推理性突出的任务，并首次构建了一个名为RATs40K的实际多模态基准数据集，该数据集专门标注了异常推理，包括约40,000个样本，涵盖10个实际领域。每个样本包含数值时间序列数据、上下文文本信息和视觉表示，并标记了细粒度类别（单变量异常14种类型，多变量异常6种）和结构化的解释性推理。该研究通过使用GPT-4驱动的反馈构建了综合的注解框架，确保了注解的准确性和可解释性。广泛基准测试展示了当前模型的能力和局限性。", "conclusion": "该数据集和任务为可解释的时间序列异常检测和推理的显著进步铺平了道路。研究团队已将代码和数据集完全开源，以支持和加速该领域的未来研究。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: 细粒度评估大语言模型结构化知识理解能力的基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大语言模型（LLMs）在理解和处理结构化知识（SK）如知识图谱（KG）和表格方面取得了显著进步，现有的评估方法在特定能力和多种类型的SK方面并不严格且单一。因此，本文提出了一个更全面和严格的结构化知识理解基准（SKA-Bench），以诊断LLMs的不足。本文介绍了SKA-Bench，涵盖了四种常用的结构化知识形式：知识图谱（KG）、表格、知识图谱+文本（KG+Text）和表格+文本（Table+Text），构建了一个三阶段的流水线，并引入了噪声鲁棒性、对序不敏感性、信息整合和负面拒绝四个基础能力测试平台，精细评估LLMs的SK理解能力。实验表明，当前的LLMs在理解结构化知识方面仍然面临着挑战，且性能受到噪声量、知识单元顺序和幻觉现象等因素的影响。", "innovation": "提出了一个新的结构化知识理解基准SKA-Bench，涵盖了四种常见的结构化知识形式，通过三阶段流水线构建实例，并引入了噪声鲁棒性、对序不敏感性、信息整合和负面拒绝四个基础能力测试平台，精细评估LLMs的SK理解能力。", "conclusion": "现有的LLMs在理解结构化知识方面仍存在重大挑战，其性能受噪声量、知识单元顺序和幻觉现象等因素的影响。本文提出的数据集和代码可用以进一步研究和评估LLMs的结构化知识理解能力。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "通过期望最大化实现可解释的日语汉字联想词生成", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "学习日语词汇对罗马字母背景的学习者来说是一个挑战，因为日语结合了书写系统的差异。日语使用了如平假名这样的音节文字以及来自中文的语素文字——汉字。汉字由于其复杂性和数量众多也使学习变得困难。关键词联想是常用的记词汇法，通常利用汉字的组成部分结构来形成生动的联想。尽管最近有试图使用大型预训练语言模型（LLMs）来辅助学习，但现有的基于LLM的关键词联想生成方法缺乏解释性，作为一种黑盒方法，提供了有限的可解释性。基于此背景，该研究提出了一种生成框架，其明确地将联想构建过程建模为由一组常见规则驱动，并通过一种新颖的期望最大化算法学习这些规则。该方法在学习者撰写的联想上进行训练，以便学习潜在结构和组合规则，实现可解释和系统化的联想生成。研究结果表明，在新学习者的情况下，该方法表现良好，并提供了有效联想创造机制的见解。", "innovation": "该研究提出了一种生成框架，明确地将联想构造过程建模为由一组常见规则驱动，并通过一种新颖的期望最大化算法学习这些规则。这种方法能够实现解释性和系统化的联想生成，为理解和提升有效联想创造提供了有价值的见解和机制。", "conclusion": "实验结果表明，所提出的方法在新学习者的情境下表现出众，为理解有效联想创建机制提供了有价值的见解。这种方法通过期望最大化算法从学习者撰写的联想数据中学习潜在结构和组合规则，实现了具有解释性的联想生成。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过Dirac再平衡器和分布纠缠实现单域跨癌种多模态预后的一般化", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据以进行生存预测方面表现出显著性能。然而，现有的多模态方法主要集中在单一癌症类型上，并且忽视了在不同癌症类型间推广的挑战。已有研究显示，在跨癌种场景下，多模态预后模型的推广性能往往不如单模态模型，但在临床上对这样一种稳健性存在迫切需求。因此，该文献旨在揭示多模态预后模型在跨癌种场景下的推广问题，并提出一种新的任务，即跨癌种单一领域一般化多模态预后，用于评估单一癌症类型训练的模型在未见过的癌症类型上的推广能力。文献还提出了两种关键的解决方案：稀疏Dirac信息再平衡器（SDIR）和癌症感知分布纠缠（CADE），以解决特征和模态融合中的问题。未来实验通过四癌种基准数据集展示了这些改进的有效性，为实际应用中跨癌种多模态预后的稳健性奠定了基础。", "innovation": "该研究首次发现，多模态预后模型在跨癌种场景下往往不如单模态稳健。因此，提出了一个新的任务（跨癌种单一领域一般化多模态预后），包括两项创新模块：稀疏Dirac信息再平衡器（SDIR）和癌症感知分布纠缠（CADE），致力于解决多模态预后中的模态级特征可及性和模态融合效率问题。", "conclusion": "通过提出的跨癌种单一领域一般化多模态预后任务和相关模块，研究发现显著提高了模型在不同癌症类型间的推广性能。这为实际应用中实现跨癌种多模态预后的稳健性提供了基础。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "双重层次漂移适应的在线配置性能学习", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代配置软件系统需要学习将配置与性能关联的模型。然而，在动态环境中，工作负载变化、硬件更改和系统更新会不可避免地在不同级别引入概念漂移——总体漂移会重新塑造整个配置空间的性能景观；局部漂移则仅影响该空间的某些子区域。现有的离线和迁移学习方法难以实时适应这些隐含和不可预测的变化，导致配置性能学习面临挑战。背景总结了概念漂移在配置性能学习中的挑战及其对现有方法的影响。目前的方法难以处理和适应任何类型的漂移，特别是在不确定和动态的工作场景下性能表现会较差。", "innovation": "为了应对上述挑战，本文提出了DHDA（双重层次漂移适应）框架，用于在不同层次上捕获并适应漂移。核心创新在于使用双重层次适应策略，即上层是重新分区分割数据，仅在必要时处理全局漂移，而下层则是局部模型在各自子区域内检测和异步适应局部漂移。为了平衡响应性和效率，DHDA结合增量更新和周期性全重训，在未检测到漂移时尽量减少冗余计算。创新点总结了DHDA的双重层次适应机制及其与现有方法的区别。现有方法多是静态的，难以在不同层次上灵活响应漂移，而DHDA则可以更灵活和有效地适应不同类型的漂移。", "conclusion": "通过评估八种软件系统，并与最先进的方法进行对比，研究结果显示DHDA在精度方面有显著改进，可以有效适应多达两倍的漂移改进，同时引入可接受的开销，并能改善不同局部模型在处理概念漂移方面的表现。结论总结了DHDA方法的有效性，强调它在复杂动态环境中能够更好地适应性能漂移，提高配置性能学习的效率。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 学习识别手写数学公式中的自我监督注意力机制", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式识别（HMER）是一个具有挑战性的任务，因为它包含固有的二维结构、符号规模的变化以及符号间复杂的空间关系。现有的方法需要大量的手动标注数据来训练模型，这在实际操作中成本较高。", "innovation": "本文提出了一种自监督学习（SSL）框架，用于HMER，它能够通过对比损失函数（全局与局部的结合）进行图像编码器的预训练，增强模型学习整体和详细特征的能力。作者还提出了一种新颖的自监督注意力网络，该网络利用逐步的空间遮罩策略进行训练，以学习具有语义意义的关注区域，如运算符、幂次和嵌套的数学符号，而无需任何监督。这种方法通过逐步的遮罩课程增强网络对缺少或被遮挡的视觉信息的鲁棒性，从而提高结构理解。", "conclusion": "通过在CROHME基准测试上的广泛实验，证明了本文方法优于现有的自监督和全监督基线，验证了逐步注意力机制在增强HMER性能方面的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL：通过熵机制平衡LLM测试时强化学习中的探索与利用", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "大型语言模型（LLM）在复杂推理任务如数学和编程中取得了显著进步，但仍高度依赖标记数据，并在无监督场景中表现出有限的适应性。为此，测试时强化学习（TTRL）被提出，通过利用模型生成的伪标签实现自我优化。尽管TTRL具有潜力，但它也面临一些关键挑战，如由于并行跑包导致的高推理成本和早期阶段估计偏差引发的过度自信，这降低了输出多样性并导致性能停滞不前。", "innovation": "本文提出了一种基于熵的机制，通过两种策略（Entropy-fork Tree Majority Rollout (ETMR) 和 Entropy-based Advantage Reshaping (EAR)）增强测试时强化学习中的探索与利用平衡。相比基线方法，该方法使Llama3.1-8B在AIME 2024基准测试中的Pass at 1指标提高了68%，同时消耗了60%的跑包令牌预算。这表明该方法能够有效优化推理效率、多样性和估计稳健性之间的权衡，从而推进了开放域推理任务中的无监督强化学习。", "conclusion": "本文提出的方法能够有效优化无监督强化学习中的推理效率、多样性和估计稳健性之间的权衡，提高开放域推理任务性能，特别是在无监督场景中。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22612", "html_url": "https://arxiv.org/abs/2507.22612", "title": "自适应时长模型用于文本语音对齐", "title_en": "Adaptive Duration Model for Text Speech Alignment", "authors": "Junjie Cao", "background": "语音转文本对齐是神经文本转语音(TTS)模型的关键组成部分。自回归TTS模型通常使用注意力机制在线学习这些对齐，而非自回归端到端TTS模型则依赖于从外部来源提取的时长。目前的方法在音素级时长预测和适应性方面存在局限性，特别是在面对提示音频和输入音频不匹配的情况下，前基线模型表现不够稳定和精准。因此，提出一种新的时长预测框架，用于给定文本时预测出具体的音素级时长分布，以改善TTS模型的对齐准确性和鲁棒性。", "innovation": "本文提出了一种新的时长预测框架，能够提供基于给定文本的音素级时长分布，相较于之前的基线模型，新模型在音素级对齐精度和适应性方面表现更优，特别是在提示音频和输入音频不匹配的情况下，提升了零样本TTS模型的性能稳定性。", "conclusion": "实验结果显示，提出的时长模型在预测精准确性及适应条件能力上超越了之前的基线模型，特别是在音素级对齐精度和提高零样本TTS模型对音频不匹配的鲁棒性方面取得了显著进步。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14119", "html_url": "https://arxiv.org/abs/2508.14119", "title": "使用Fabric记录部署：现实世界AI治理的资源库", "title_en": "Documenting Deployment with Fabric: A Repository of Real-World AI Governance", "authors": "Mackenzie Jorgensen,Kendall Brogle,Katherine M. Collins,Lujain Ibrahim,Arina Shah,Petra Ivanovic,Noah Broestl,Gabriel Piles,Paul Dongha,Hatim Abdulhussein,Adrian Weller,Jillian Powers,Umang Bhatt", "background": "学术界关于AI部署的研究主要集中在AI使用带来的风险和危害上。本文介绍了一个名为 Fabric 的公开资源库，用于列出并概述各种部署中的AI用例及其治理机制。通过与实践者的半结构化访谈收集了20个初始AI用例，并与实践者共同设计了AI工作流程的图表。文章讨论了实践中用于保护AI使用的监督机制和护栏。Fabric资源库包括AI用例的可视化图表和部署系统的描述。使用该资源库，文章揭示了治理中的缺口，并发现了部署AI系统中人类监督的常见模式。", "innovation": "本文创新地提出了一个名为Fabric的公开资源库，用于列出并概述各种部署中的AI用例及其治理机制。资源库中集成了AI用例的可视化图表和部署系统的描述，提供了实际案例，旨在帮助研究者研究AI治理的有效性。", "conclusion": "Fabric旨在成为一个可扩展、持续演进的研究工具，帮助研究者了解AI治理机制的有效性，填补现有治理框架的不足，并发现部署AI系统的共同模式。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "Trust but Verify! 一种关于测试时缩放验证设计的综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "Test-time scaling (TTS) 作为一种新的发展方向，旨在通过在推理时使用更多计算资源来提升大型语言模型（LLM）的性能。现有的TTS方法包括从一个模型中提取推理痕迹或通过使用验证器探索广泛的解码搜索空间。验证器作为奖励模型，在推理过程中评分候选输出，有助于广泛探索解决方案空间并选择最佳结果。然而，尽管验证器被广泛采用，但对其训练机制、类型及其在网络缩放方面的多样用途缺乏详细的整理和讨论。", "innovation": "本文进行了一项综述工作，旨在整理和分类现有的验证方法，深入探讨其训练机制及其在测试时缩放过程中的应用和优势。文章梳理了文献中的各种验证方法，提供了一个统一的观点，并建立了相关的资源库，以帮助更好地理解和应用验证器在测试时缩放中的作用。", "conclusion": "通过对现有验证方法的研究和分类，本文为测试时缩放的设计提供了一个统一的视角，并强调验证器在提升测试时性能方面的关键作用。该综述同时指出了未来在验证器设计和应用方面的工作重点，强调了进一步探索和优化验证器训练机制的重要性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器上的量化神经网络：方法、平台和应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "在资源受限的设备，如微控制器上部署量化神经网络（QNNs），带来了在模型性能、计算复杂性和内存约束之间的平衡挑战。tinyML通过结合机器学习算法、硬件加速和软件优化的进步，有效地在嵌入式系统上运行深度神经网络来解决这些问题。本文提供了一种以硬件为中心的量化介绍，系统地回顾了为嵌入式应用加速深度学习模型所使用的量化技术。特别强调了模型性能与硬件能力之间的关键权衡。", "innovation": "深入研究了现有软件框架和硬件平台，旨在支持微控制器上的QNN执行，进行了现有挑战的分析，并提出了该快速发展的QNN部署领域中具有前景的未来方向。", "conclusion": "本文对我们全面回顾微控制器上量化神经网络的方法、平台和应用进行了系统性的研究与评价。此外，我们分析了当前存在的挑战，并提出了在快速发展的QNN部署领域中的充满希望的未来方向。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT：一种新的通道增强混合CNNTransformer模型，具有残差、空域和边界感知学习，用于脑肿瘤MRI分析", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤是最致命的人类疾病之一，早期检测和准确分类是有效诊断和治疗计划的关键。虽然基于深度学习的计算机辅助诊断（CADx）系统已经取得了显著的进步，但传统的卷积神经网络（CNN）和Transformer仍面临高计算成本、对细微对比度变异的敏感性、结构异质性和MRI数据中的纹理不一致等持续挑战。", "innovation": "本文提出了一种名为CE-RS-SBCIT的新颖混合框架，将基于残差和空域学习的CNN与Transformer驱动模块相结合。该框架通过四种核心创新点进行改进，包括（i）平滑和边界的卷积神经网络集成Transformer（SBCIT）；（ii）适应性残差和空域学习CNN；（iii）通道增强（CE）策略；（iv）新型空域注意机制。SBCIT通过茎卷积和上下文交互Transformer块进行系统平滑和边界操作，以高效构建全局特征模型。Residual和空域CNN在辅助转储学习特征图的增强下丰富了表示空间，CE模块放大了鉴别性通道并减轻了冗余。空域注意机制强调了肿瘤类别中微妙对比度和纹理变异。", "conclusion": "CE-RS-SBCIT在包含胶质瘤、脑膜瘤、垂体肿瘤和健康对照的Kaggle和Figshare具有挑战性的MRI数据集上进行了广泛评估，展示了卓越的性能，准确率达到98.30%，灵敏度98.08%，F1分数98.25%，精确度98.43%。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME: 增强基于主题的投资的语义股票表示和时间动态", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资的目标是构建与结构性趋势一致的投资组合，但由于行业边界重叠和市场动态演变，这仍是一个具有挑战性的任务。一种有前途的方法是通过文本数据构建投资主题的语义表示。然而，通用的大规模语言模型可能不适用于捕捉金融资产的细微特性，因为投资资产的语义表示可能与一般金融文本的核心语义有根本性差异。为了应对这一挑战，我们引入了THEME框架，该框架通过层次对比学习微调嵌入。THEME利用主题及其组成部分股票的层次关系对这些主题进行对齐，随后通过融入股票回报进一步完善这些嵌入，从而生成能够有效检索与主题一致且具有强劲回报潜力的资产的表示。实证结果显示，THEME在两个关键领域表现出色：在主题资产检索方面，THEME显著优于领先的大规模语言模型；此外，由THEME构建的投资组合也表现出令人信服的绩效。通过同时建模文本中的主题关系和回报中的市场动态，THEME生成了特别适用于广泛实际投资应用的股票嵌入。", "innovation": "THEME框架通过层次对比学习微调嵌入，这是一种创新的方法。它不仅利用主题及其组成部分股票的层次关系对主题进行对齐，还通过融入股票回报进一步完善这些嵌入，从而生成能够有效检索与主题一致且具有强劲回报潜力的资产的表示。", "conclusion": "THEME框架在主题资产检索方面显著优于领先的大规模语言模型，其构建的投资组合也表现出令人信服的绩效。通过联合建模文本中的主题关系和回报中的市场动态，THEME生成了特别适用于广泛实际投资应用的股票嵌入。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher: 通过细粒度原子思想奖励增强自主深度研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大型语言模型（LLMs）在解决复杂问题时因内部知识的局限性而表现不佳。检索增强生成（RAG）改善了外部信息的访问，但在多跳推理和战略搜索方面仍受到僵硬的工作流程的限制。最近，自主深度研究的进步让LLMs能够自主进行推理、搜索和信息合成。然而，当前依赖于基于结果的强化学习（RL）的方法面临关键问题，如梯度冲突和奖励稀疏性，这些因素限制了性能提升和训练效率。", "innovation": "本文首先提出了一种名为原子思维（Atomic Thought）的新LLMs思维范式，将推理细分为基本功能单元，并通过推理奖励模型（RRMs）提供原子思维奖励（ATR）进行细粒度指导。在此基础上，提出了Atom-Searcher，这是一种新的RL框架，结合了原子思维和ATR，使用类似课程的学习奖励计划，优先处理过程层次的ATR并逐渐转向结果奖励，加速了有效推理路径的收敛。实验结果在七个基准上显示了一致的改进。主要优势包括：(1) Atom-Searcher在测试时能扩展计算量。(2) 原子思维为RRMs提供了监督锚点，缩短了深度研究任务与RRMs之间的距离。(3) Atom-Searcher表现出更可解释和类似人类的推理模式。", "conclusion": "实验结果显示，Atom-Searcher在七个基准上都取得了超过当前最先进的模型的一致改进。该研究的主要优点包括：Atom-Searcher在测试时扩展了计算量；原子思维为RRMs提供了监督锚点；Atom-Searcher表现出更可解释和类似人类的推理模式。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "区域级上下文感知多模态理解", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大语言模型（MLLMs）方面取得了显著进展，现有研究主要集中在通用视觉理解上，忽视了对与对象关联的文本上下文的整合能力，这使得模型对多模态的理解更加语境化。因此，本文提出了一种新的任务——区域级上下文感知多模态理解（RCMU），要求模型在响应用户指令时结合图像内容和区域或对象的文本信息。为了应对数据集的缺乏，本文还提出了一个大规模的视觉指令调优数据集，并提出了一个全面的基准（RC&P-Bench），用于评估MLLMs在RCMU和多模态个性化理解任务上的性能。此外，还提出了一种参考自由的评估指标，用于全面和精细地评估区域级上下文感知图像描述。通过使用RCVIT方法在Qwen2-VL模型上进行训练，得到了RC-Qwen2-VL模型，该模型在多种RCMU任务上的表现优异，并成功应用于多模态检索和个性化对话。", "innovation": "本文首次提出了RCMU任务，并提出了一种结合视觉和文本信息的方法，即Region-level Context-aware Visual Instruction Tuning (RCVIT)。为了支持 RCMU 能力，RCVIT 方法将对象信息纳入模型输入，并通过使用边界框坐标有效地将物体的视觉内容与其文本信息关联起来。此外，本文引入了 RCMU 数据集和 RC&P-Bench 基准，同时提出了一个参考自由的评估指标，用于全面评估区域级别的上下文感知图像描述。", "conclusion": "通过对Qwen2-VL模型进行RCVIT训练，开发出了RC-Qwen2-VL模型。实验结果表明，RC-Qwen2-VL模型不仅在多种RCMU任务上表现出色，还在多模态检索和个性化对话方面展现出成功的应用。研究数据、模型和基准可通过提供的链接获取。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA: 用于植物科学中视觉语言模型基准测试的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA 数据集是从广泛使用的 PlantVillage 图像库衍生出的一个大规模视觉问答 (VQA) 数据集，旨在促进农业决策和分析中视觉-语言模型的发展和评估。该数据集包含193,609个高质量问题-答案（QA）对，涵盖了55,448张图片，涉及14种作物和38种疾病条件。数据集在领域专家的指导下进行迭代审查，确保科学准确性和相关性。", "innovation": "该数据集通过自动两阶段管道生成 QA 对，第一阶段基于图像元数据生成模板基础的 QA 合成，第二阶段进行多阶段的语义重构。此外，数据集在三个最先进的模型上进行了质量评估，确保其高质量和可靠性，为未来的研究提供了标准和专家验证的数据库。", "conclusion": "数据集的目标是提供一个公开的、标准化和专家验证的数据库，以提高植物病害诊断的准确性并推动农业领域的科学研究。数据集将在以下网址公开获取。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19660", "html_url": "https://arxiv.org/abs/2508.19660", "title": "全集成演化近似实现任意精度印刷三值神经网络", "title_en": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation", "authors": "Vojtech Mrazek,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Zdenek Vasicek,Mehdi B. Tahoori,Georgios Zervakis", "background": "印刷电子技术为超越硅基系统的应用提供了有前景的替代方案，要求具备灵活性、延展性、贴合性以及超低制造成本等特性。尽管印刷电子器件具有较大的特征尺寸，但印刷神经网络因其能够在满足特定应用需求方面显得尤为突出，尽管实现复杂的电路仍然具有挑战性。", "innovation": "该工作填补了印刷神经网络分类准确性和区域效率之间的差距，涵盖了从模数接口到数字分类器整个处理和传感器系统的设计和协同优化。研究团队提出了一种自动化的框架，为具有任意输入精度的印刷三值神经网络设计提供支持，利用多目标优化和整体近似方法。所提出的电路在区域和功耗方面分别比现有近似印刷神经网络高出17倍和59倍，在考虑模数接口成本的情况下，首次实现了低于5%的准确率损失和电池供电操作。", "conclusion": "实验结果表明，所设计的印刷三值神经网络在区域效率和功耗方面显著优于现有技术，在保持准确率的前提下实现了电池供电操作。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "数据拟合中的鲁棒性很重要：LLMs的局限性", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）不仅被应用于语言相关的任务，还在各种数据拟合和预测任务中得到广泛应用。以往研究表明，LLMs可以通过上下文学习或监督微调，在预测性能上可与表格监督学习技术媲美。然而，研究人员发现当LLMs用于数据拟合时存在一个重要漏洞，即对数据表示的微小变化，这些变化与学习任务毫无关系，也可能导致预测结果的巨大改变。例如，仅更改变量名称就能使预测误差增大82%。这种对任务无关变化的敏感性在上下文学习和监督微调，以及闭权重和开放权重的通用LLMs中均有表现。研究还发现，开放权重LLMs在生成输出时的关注度分数分布不均匀，某些位置的训练示例和变量名称或值会被给予更多的关注。这有助于解释在任务无关变化存在的情况下为何会出现敏感性。此外，尽管最前沿的表格基础模型（TabPFN）是专门设计为实现预测稳健性，但TabPFN也受到任务无关变化的影响。", "innovation": "研究人员揭示了数据表示中与学习任务无关的微小变化如何大幅影响LLMs的预测结果，并且这种敏感性不仅限于特定的学习方法或特定的LLM权重策略。这种方法通过分析开放权重LLM的注意力分数揭示了非均匀的关注度模式，这是解释这种敏感性的部分原因。此外，他们不仅展示了LLMs的敏感性，还探讨了即使是为数据拟合优化的模型也难以完全避免这种敏感性的问题。这些发现强调了LLMs在数据拟合应用中的局限性，尤其是在缺乏可预测鲁棒性的背景下，LLMs难以成为替代传统方法的精确数据拟合工具。", "conclusion": "尽管LLMs在预测性能方面表现出色，但这些模型缺乏基本的稳健性，这限制了它们作为数据拟合工具的实用性。研究人员建议，在设计LLMs用于数据拟合之前，需要解决这种对任务无关变化高度敏感的问题，以提高其稳健性和可靠性。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 评估大型语言模型在凝聚态物理中的基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "本文介绍了一种名为CMPhysBench的新基准，旨在评估大型语言模型（LLMs）在凝聚态物理领域的专业能力。CMPhysBench包含超过520个研究生级别的精心筛选问题，覆盖了磁学、超导性、强关联系统等代表性和基础理论框架，专注于计算问题，要求LLMs独立生成全面解决方案。此外，通过使用基于树的表达式表示，本文引入了可扩展表达式编辑距离（SEED）评分，这种评分提供细粒度的部分评分，可以更准确地评估预测与真实值之间的相似性。结果表明，即使是最先进的模型Grokm-4在CMPhysBench上的平均SEED分为36，准确率也只有28%，揭示了在凝聚态物理等实用和前沿领域，这些模型与传统物理相比存在的巨大差距。相关代码和数据集可以在这里的 https URL 获取。", "innovation": "提出了CMPhysBench作为评估LLMs在凝聚态物理中表现的新基准；首次提出了基于树的表达式表示方法和可扩展表达式编辑距离（SEED）评分，提供细粒度的部分评分，能够更准确地评估预测与实际结果的类似性；涵盖了凝聚态物理学的多个重要子领域和基础理论框架，挑战了现有模型的实际应用能力。", "conclusion": "研究表明，现有的LLMs在CMPhysBench上的表现尚未达到令人满意的标准，尤其是在处理凝聚态物理问题时存在明显不足，这需要进一步的研究和改进来提高其在科学计算任务中的性能。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大规模语言模型（LLMs）通过增加推理过程中的计算量来提升推理能力，虽然这种策略有效，但也会导致显著的延迟和资源成本增加，这限制了它们在实际场景中的应用，特别是在时间紧迫或成本敏感的情况下。现有模型无法有效控制推理过程中的资源消耗，使得在实际应用中面临诸多挑战，尤其是在资源受限的环境中。因此，如何在保障性能的前提下，控制语言模型的推理成本成为一个亟待解决的问题。", "innovation": "本文提出了一种名为BudgetThinker的新框架，通过在推理过程中定期插入特殊控制标记来实时更新模型对剩余令牌预算的认知，从而实现对推理过程长度的精准控制。此方法结合了监督微调（SFT）和基于课程的强化学习（RL）两个阶段的训练策略。在SFT阶段，模型学习预算约束；在RL阶段，则通过一种长度感知的奖励函数优化准确性和预算遵守。实验结果表明，BudgetThinker能够在各种预算约束下的数学挑战性基准测试上显著超越强基线方法，提供了一种可扩展且有效的解决资源受限和实时环境中的高效可控语言模型推理问题的方法。", "conclusion": "本研究提出了一种名为BudgetThinker的新框架，能够使大规模语言模型在运行时根据预算进行推理。通过结合监督微调和基于课程的强化学习两个阶段的训练策略，实现了对语言模型推理过程中的预算控制。实验展示了该方法在多个预算约束下的数学基准测试中表现出色，提供了在资源受限和实时环境中使用更高效的语言模型解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Can 多模态 LL(models) 解决 Percept-V 的基本感知问题？", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来，多模态大语言模型（MLLMs）在编程、数学和科学等复杂任务中的推理能力引起了广泛关注。然而，很少有实验评估它们在处理未被污染的、由基本形状和结构生成的图像的简单感知任务上的表现。因此，本文通过创建一个包含7200张程序生成图像的Percept-V数据集，旨在解决这一问题。", "innovation": "本文创新地提出了一种名为Percept-V的新型数据集，其中包含由程序生成的基本形状和结构构成的7200张图像，这些图像被划分为30个类别，用于测试多种视觉感知技能。Percept-V数据集包含一系列从简单到复杂的任务，适用于评测MLLMs和大推理模型（LRMs）在基本感知任务上的能力。", "conclusion": "实验结果表明，随着问题复杂度的增加，MLLMs和LRMs在Percept-V数据集上的表现显著下降。此外，测试的模型在各个类别中的准确性显示出相似的趋势，并且某些认知技能比其他技能更难。"}
{"llm_update_time": "20250902", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19637", "html_url": "https://arxiv.org/abs/2508.19637", "title": "Invited Paper: 在极端边缘的混合信号智能柔性感测穿戴设备中，从特征到分类器协同设计用于医疗保健", "title_en": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge", "authors": "Maha Shatta,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Georgios Panagopoulos,Mehdi B. Tahoori,Georgios Zervakis", "background": "柔性电子学（FE）为可穿戴健康护理设备提供了替代硅基硬件的有前途的选择，使系统轻便、可贴合且低成本。然而，灵活性限制了集成密度，较大的特征尺寸也对面积和功率提出了严格要求，特别是在信息提取、特征提取和分类器集成到基于机器学习的健康护理系统中。当前的FE解决方案往往忽略了系统级的整体优化，导致大量硬件成本花在特征提取和模数转换器（ADC）上，这显著增加了系统的面积和功率消耗。本研究探讨了柔性智能可穿戴系统中从特征到分类器的混合信号协同设计框架，以实现高效且应用程序特定的设计，并通过医疗基准测试展示了极高的准确性和极低的面积效率。该方法旨在应对一次性、低功耗医疗监测设备的需求。", "innovation": "首次在同一技术背景下设计了可以降低特征提取成本的模拟特征提取器，并采用一种受硬件感知神经架构搜索（NAS）方法启发的特征选择策略，这在ML训练过程中能够提供高效的应用程序特定设计。这些创新方法解决了现有FE解决方案在系统级优化方面的不足，为柔性感测穿戴设备在医疗保健应用中的更高效部署奠定了基础。", "conclusion": "该方法在医疗保健基准测试中表现出极高的准确性和极高效率，非常适合于一次性的低功耗穿戴式健康监测。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型在训练数据中往往会学到和利用虚假相关性，使用非目标特征来指导预测。这种依赖会导致在未见过的数据上性能下降和泛化能力较差。现有的方法无法同时解决多种偏差问题（如性别偏差、简单性偏差），并且在处理分布外鲁棒性方面存在局限性，因此亟需一种更通用的方法来应对这些问题。", "innovation": "本文引入了一种更通用形式的反事实数据增强，称为对抗偏差数据增强（CounterBias Augmentation，CoBA），能够同时解决多种偏差并增强分布外鲁棒性。CoBA通过在语义三元组级别操作，首先将文本分解为主语-谓语-宾语三元组，然后选择性地修改这些三元组以打断虚假相关性，从而生成对抗偏差数据，减轻虚假模式的影响。", "conclusion": "通过广泛的实验表明，CoBA不仅能提高下游任务的性能，还能有效减少偏差并增强分布外鲁棒性。这种方法提供了一种灵活且鲁棒的解决方案来应对虚假相关性所带来的挑战。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk: 使用Transformer网络进行ink生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "本文旨在解决通过生成器从输入文本生成手写笔画的问题。传统的生成方法在捕捉手写整体依赖关系和保持生成文本的风格一致性方面存在挑战。论文通过分析现有方法的局限性，指出当前模型在处理全局依赖关系及输入文本与生成笔画点对齐方面存在不足，尤其是在提高手写生成的可读性和一致性方面表现不佳。", "innovation": "提出了一种基于Transformer的模型TrInk，用于ink生成。该模型通过引入缩放位置嵌入和高斯记忆掩码，增强了跨注意力模块中输入文本和生成笔画点的对齐。实验结果显示，相较于之前的方法，TrInk模型在IAM-OnDB数据集上的字符错误率（CER）降低了35.56%，单词错误率（WER）降低了29.66%。", "conclusion": "研究通过设计主观和客观评估管道，全面评估了生成手写文本的可读性和风格一致性。TrInk模型在提高生成手写文本的质量方面表现出显著优势。论文还提供了包含TrInk和基准模型的手写样本的演示页面，以验证模型的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签诱导偏差的自我和交叉评估", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "越来越多的大型语言模型（LLMs）被用于评估输出，但这些模型的判断可能会受到标签偏差的影响。本研究考察了ChatGPT、Gemini和Claude在不同标签条件下（无标签、真实标签以及两种虚假标签）进行自我评估和交叉模型评估的情况。", "innovation": "本研究通过分析各模型的博客文章在使用一致的评分标准（整体偏好投票和连贯性、信息量、简洁性质量评分）进行互评的结果，揭示了不同标签对评分的影响。研究发现，", "conclusion": "研究结果表明，感知到的模型身份可以大大扭曲高级判断，并微妙影响详细的质量评分，强调了为确保LLM基准测试中的公平性需要采用盲评估或多种模型评估的协议。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21084", "html_url": "https://arxiv.org/abs/2508.21084", "title": "跨代群体有毒评论地图绘制：来自德国公共服务广播的数据集", "title_en": "Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting", "authors": "Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke", "background": "现有的有毒评论数据集缺乏人口统计学背景，限制了我们对不同年龄段在网络中如何交流的理解。本研究合作了德国公共服务内容网络funk，引入了首个大规模的德国标注有毒评论数据集，该数据集包含来自Instagram、TikTok和YouTube的3,024条人工标注和30,024条语言模型标注的匿名评论，共计33,048条评论。为了确保相关性，使用预定义的有毒关键词对评论进行了聚合，最终有16.7%被标注为问题评论。该数据集揭示了基于年龄的有毒言论模式差异，年轻用户更倾向于使用丰富的语言，而老年用户则更频繁地传播不实信息和对广播费用的贬低。", "innovation": "该研究提供了首个大型的用毒性标注和年龄估计信息标注的德语数据集，包含来自于Instagram、TikTok和YouTube的大规模匿名评论，并且其中整合了人工标注和语言模型标注，特别关注了不同年龄段的有毒言论模式差异。这为研究人员和实践者提供了新的研究机会，以理解语言变异在不同人口统计学群体中的表现，并支持开发更加公平和关注年龄段的内容审查系统。", "conclusion": "该数据集揭示了有毒言论在不同年龄段中的模式差异，年轻用户更倾向于使用丰富的语言，而老年用户则更频繁地传播不实信息和对广播费用的贬低。该数据集为跨年龄段的的语言研究提供了新的机会，支持创建更加公平和年龄段相关的审查系统。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过像素化方法增强自回归语言模型对表书攻击的鲁棒性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型容易受到表书攻击的影响，即输入文本通过多种语言的字母表进行篡改，导致性能显著下降。这种脆弱性主要源于子词分词器固有的词外问题及其嵌入。", "innovation": "提出了一种基于像素的生成语言模型，用像素表示替代基于文本的嵌入，将单词渲染为独立图像。此设计提升了对噪声输入的鲁棒性，并扩展了对多种书写系统中多语言文本的兼容性。", "conclusion": "在多语言LAMBADA数据集、WMT24数据集和SST-2基准上评估了所提出的方法，展示了其对表书噪声的鲁棒性和在多语言环境中的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21137", "html_url": "https://arxiv.org/abs/2508.21137", "title": "认知偏差如何影响大语言模型？价格谈判模拟中的锚定效应案例研究", "title_en": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": "Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu", "background": "人类的认知偏差已经在研究中被广泛探讨，并且这些偏差也会影响大规模语言模型（LLMs）的可靠性。本文将研究锚定效应这种认知偏差在LLMs驱动的价格谈判中的影响，以评估其在现实世界应用中的可靠性差异。通过让卖家LLM代理应用锚定效应，并使用客观和主观度量标准进行谈判评估，实验结果表明，LLMs也会受到锚定效应的影响，类似于人类。此外，通过探讨锚定效应与推理和个性等因素的关系，进一步理解认知偏差对LLMs的影响。", "innovation": "本文通过让卖家LLM代理应用锚定效应，并不仅依靠客观度量标准，还结合主观度量标准进行评估，这为研究LLMs中的锚定效应提供了新的视角。此外，通过探讨锚定效应与推理和个性的关系，揭示了长链推理能够缓解锚定效应的影响。研究表明，在现实应用中，设计时考虑到LLMs的锚定效应，有助于实现安全和负责任的LLM应用。", "conclusion": "实验结果表明，LLMs确实会受到锚定效应的影响，类似于人类。推理模型相对不易受锚定效应的影响，表明较长的推理过程能够减轻锚定效应的影响。此外，研究未发现个性特质与锚定效应易感性之间的显著相关性。上述发现将有助于更深入地理解LLMs中的认知偏差，并促进安全和负责任的LLMs社会应用。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "从代码生成模型生成高效代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "该研究旨在通过自然语言查询检索代码、执行技术问题解答以及跨编程语言识别语义相似的代码片段。现有技术可能侧重于较大的模型规模或更复杂的架构，而本研究通过一种新颖的自回归骨干网络预训练方法实现了在较小模型规模下达到一流的性能。", "innovation": "提出了一种新颖的代码嵌入模型套件——jina-code-embeddings，该模型利用同时预训练于文本和代码的自回归骨干网络，通过最后一令牌池化生成嵌入。这种方法有效地在相对较小的模型规模下达到了最先进的性能。", "conclusion": "该论文展示了尽管模型规模很小，但通过这种方法构建的代码嵌入模型仍然能够达到非常先进的性能，从而验证了该方法在构建代码嵌入模型的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "使用基于群体相关策略优化的强化学习改进航空安全分析", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析航空事故背后的人因因素对于防止未来事故至关重要，但传统方法使用的人因分析与分类系统（HFACS）方法受限于可扩展性和一致性。因此，需要一种自动化的HFACS分类框架来增强航空安全分析能力，该框架利用了基于群体相关策略优化（GRPO）的强化学习调整Llama-3.1 8B语言模型。该方法采用了一个针对航空安全分析定制的多组件奖励系统，并结合了合成数据生成来解决事故数据集中的类别不平衡问题。", "innovation": "引入了一种自动化HFACS分类框架，使用基于群体相关策略优化的强化学习调整Llama-3.1 8B语言模型。该框架包括针对航空安全分析定制的多组件奖励系统，并利用合成数据生成解决类别不平衡问题。该方法显著提升了分类准确度，包括精确匹配准确度提高了350%（从0.0400到0.1800），部分匹配准确度提高到0.8800。该方法还证明小型、领域优化模型可以提供更高效、更好的解决方案，并在资源受限的边缘设备上实现高效部署。", "conclusion": "研究结果证明，专门为特定领域优化的小型模型可以提供更高效、更好的解决方案，特别是在关键的安全分析上。这种方法使得在资源受限的边缘设备上实现高效部署成为可能，并提出精确匹配准确度作为多标签HFACS分类的新基准方法来评估语言模型的高级推理能力。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "BED-LLM: 使用贝叶斯实验设计增强大语言模型的智能信息收集", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "提出了一个通用方法，通过贝叶斯实验设计(BED)框架增强大型语言模型(LLM)智能且适应性地从用户或其他外部来源收集信息的能力。这使得LLM能够在多步对话中发挥作用，互动地与外部环境进行接口交互。该方法基于迭代选择最大化给定先前收集响应后的感兴趣任务预期信息增益(EIG)的问题或查询。通过这种方法，可以系统地构建一个概率模型，并决定核心决策。成功的关键还包括一些特定的创新，如设计仔细的EIG估计器，以减少对上下文更新的依赖，以及具体的候选问题提案策略。该方法在各种基于20个问题的游戏测试和用户偏好推断测试中，实现了显著的性能提升，与直接提示LLM和其它适应性设计策略相比，效果更加明显。", "innovation": "通过对EIG的迭代选择和响应，基于贝叶斯实验设计原则构建概率模型，设计一种精心设计的EIG估计器，不完全依赖上下文更新，并提出有针对性的候选问题策略。这种方法能够有效地提高LLM的信息收集能力，实现多轮对话的互动式交流。", "conclusion": "通过贝叶斯实验设计构建的方法(BED-LLM)，显著提升了大语言模型在多轮对话中智能地从用户或其他外部来源收集信息的能力，并且在多个测试任务中表现出明显优于直接提示和其他适应性设计策略的性能。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX Revisited: 提及自动图描述增强基准覆盖", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大规模语言模型（LLMs）能力的不断增强，特别是在多语种和非英语环境中，迫切需要更稳健的评估方法。为了应对这一挑战，我们更新了BLUEX数据集，增加了2024-2025年的考试和使用最新模型自动生成的图像描述，使其在LLM预训练的数据污染研究方面更具相关性。图像描述策略增加了对仅文本模型的可达性超过40%，并生成了1,422个可用问题，相比于原始BLUEX的数量翻了一番多。这种方法有利于商业和开源LLM利用图像上下文的能力的评估研究。", "innovation": "我们更新了BLUEX数据集，包括最新考试数据和通过先进模型自动生成的图像描述，并增加了对仅文本模型的可达性超过40%，从而生成了1,422个可用问题，大大扩展了原始BLUEX的问题数量。此外，通过图像描述策略评估了商业和开源LLMs利用图像上下文的能力。这为多语种和非英语环境下的LLM研发提供了更多的基准数据和应用场景。", "conclusion": "通过BLUEX数据集的更新和使用自动图像描述，我们增强了LLM基准数据集的覆盖范围，特别在多语种和非英语环境下的数据污染研究方面更加精确和全面。研究拓展了数据集的规模和功能，提高了仅文本模型的可达性，并有助于评估LLMs在利用图像上下文方面的能力。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT和DeepSeek家族模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在各行业中改变人工智能，但其开发和部署仍然复杂。本文回顾了16个构建和使用LLMs的关键挑战，并通过比较最先进的具有独特方法的两个模型——OpenAI的闭源GPT-4o（2024年5月更新）和DeepSeek-V3-0324（2025年3月），研究了这些挑战的应对方式，以展示闭源模型与开源模型之间的权衡（闭源模型具有较强的稳健性和细调可靠性，而开源模型具有更高的效率和适应性）。同时，文章探讨了LLMs在不同领域的应用（从聊天机器人和编程工具到医疗保健和教育），强调了哪些模型特性最适合每种用途。", "innovation": "本文通过比较两个最先进的大型语言模型——OpenAI的GPT-4o和DeepSeek-V3-0324，展示了闭源模型和开源模型之间的权衡。同时，详细探讨了大型语言模型在多个领域的应用及其适用特性。", "conclusion": "本文旨在指导AI研究人员、开发者和决策者理解当前大型语言模型的能力、局限性和最佳实践。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：用于自一致性幻觉检测的高效管道", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大型语言模型在研究和实际应用中展现了卓越的能力，但在幻象问题上仍存在挑战。现有的幻觉检测方法在句子级生成上表现不佳，或者依赖于特定领域知识。尽管自一致性方法有助于解决这些问题，但它们由于重复生成而面临高计算成本的挑战。", "innovation": "该研究首次探讨了自一致性方法中的冗余问题，并指出非精确答案的标记对语义内容贡献甚小。基于此，提出了通过选择性推理和退火解码加速生成的新型解码记忆流水线（DMP）。DMP在多响应生成中实现了效率提升，且与模型、数据集、解码策略和自一致性基线无关，表现出向对齐和推理任务扩展的潜力。", "conclusion": "实验结果表明，该方法在不牺牲AUROC性能的情况下实现了最高3倍的速度提升。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21210", "html_url": "https://arxiv.org/abs/2508.21210", "title": "自监督语音模型在语言习得过程中是否表现出关键期效应？", "title_en": "Do Self-Supervised Speech Models Exhibit the Critical Period Effects in Language Acquisition?", "authors": "Yurie Koga,Shunsuke Kando,Yusuke Miyao", "background": "本研究旨在探究关键期（CP）效应是否在人类语言习得过程中也在自监督语音模型（S3Ms）中体现。CP效应指第二语言（L2）接触延迟会加大语言习得难度，而第一语言（L1）接触延迟则会增强L1的保留能力。尽管之前的研究主要通过文本语言模型来研究这些效应，但语音模型中是否存在类似现象仍然未得到充分探索。鉴于语音在人类语言习得中的核心作用，该研究选取自监督语音模型并用其接触不同时间的L2和L1进行训练与评估。", "innovation": "研究创新之处在于使用自监督语音模型来探究关键期效应的存在与否，这是对传统基于文本的语言模型研究方法的重要补充，通过观察自监督语音模型在接触第二语言和第一语言不同时间点的表现差异，从而揭示语音模型中的关键期效应情况。研究方法和发现提供了新的视角来理解语音模型在不同语言习得阶段的表现。", "conclusion": "研究结果显示，自监督语音模型并未表现出明显的语音习得中的关键期效应。即模型在接触第二语言延迟输入的条件下反而表现出更好的表现，反之，第一语言接触延迟导致了第一语言遗忘。这为现有关于语音模型和语言习得间关系的理解提供了新的证据，表明语音习得的关键期效应可能与之前的文本语言模型研究有所不同。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一个用于比较摘要评估指标的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文研究了自动文本摘要评估中的可重复性挑战。通过在包括ROUGE等经典方法和G-Eval、SEval-Ex等基于LLM的方法在内的六个代表性指标上的实验，揭示了文献报告的性能与实际实验观察到的显著差异。研究旨在提供一个统一的开源框架，用于公平透明地比较各种评估指标，并应用到SummEval数据集上。", "innovation": "论文引入了一个统一的开源框架，用于支持自动文本摘要评估中各种指标的公平和透明比较。该框架应用于SummEval数据集上。研究结果揭示了结构上的权衡：与人类判断最一致的指标通常计算量更大且在运行间不够稳定。此外，研究还强调了依赖LLM进行评估的问题，如随机性、技术依赖性和可重复性不足，并呼吁采用更稳健的评估协议，包括详尽的文档和方法论标准化，以确保自动摘要评估的可靠性。", "conclusion": "研究结果揭示了结构上的权衡：与人类判断最一致的指标通常计算量更大且在运行间不够稳定。研究还强调了依赖LLM进行评估的问题，并呼吁采用更稳健的评估协议，包括详尽的文档和方法论标准化，以确保自动摘要评估的可靠性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常性与图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文通过正常性的概念重新审视图灵测试。作者认为，图灵测试旨在评估普通而非异常的人类智能，因此通过测试的机器需要表现出普通人类的错误行为和不完美特征。此外，图灵测试本质上是一个统计测试，决断智能的标准并非由单一非专家审判员作出，而是需要由整个陪审团来完成。这意味着图灵在原论文中提到的‘普通人类审判者’应被理解为多个审判者的个体决断进行归一化后的抽象。", "innovation": "本文提出通过正常性重新定义和理解图灵测试，强调了机器在通过测试时需要表现出普通人类的特征，并且图灵测试本质是一个统计过程，涉及多个非专家审判员而非单一审判员的判断。", "conclusion": "首先，论文指出大型语言模型如ChatGPT不太可能通过图灵测试，因为它们旨在捕捉异常而非普通人类智能。其次，论文认为图灵测试的核心问题是人类心智是否能被还原为普通心智，这超越了图灵测试本身，质疑了其背后的概念基础，特别是正常主义范式。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次选择的异构 ensemble 假新闻检测方法", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏见，如确认偏见，使人特别容易相信和传播社交媒体上的假新闻，这对公共健康和政治等领域产生了重大影响。基于机器学习的假新闻检测系统已被广泛研究以减轻这一问题。其中，集成方法特别有效，能够在结合多个分类器时提高鲁棒性。然而，这些方法的性能高度依赖于构成分类器的多样性——选择真正多样的模型仍然是一个关键挑战，特别是在模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性和性能。该方法首先计算分类器之间的成对多样性，然后通过层次聚类将它们组织成不同粒度级别的组。HierarchySelect 寻找这些层次来选择每个级别的一组分类器，每组代表不同的池内多样性。最多样化的池被识别并选择用于集成构建。选择过程结合了反映每个分类器性能的评估指标，以确保集成也具有良好的泛化能力。", "conclusion": "本文的方法在六个来自不同应用领域的数据集上与 40 个异构分类器进行了实验。与肘部启发式方法和最先进的基线方法进行了比较。结果表明，该方法在六个数据集中的两个数据集上实现了最高的准确性。具体的实现细节可在项目存储库中找到:this https URL。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21436", "html_url": "https://arxiv.org/abs/2508.21436", "title": "通过解纠缠的概念表示发现语义子维度", "title_en": "Discovering Semantic Subdimensions through Disentangled Conceptual Representations", "authors": "Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong", "background": "理解概念语义的核心维度对于揭示语言和大脑中意义的组织方式至关重要。现有方法常常依赖预定义的语义维度，这些维度提供的是粗略的表示，未能捕捉到更细微的概念区分。", "innovation": "本文提出了一种新颖的框架，用于研究粗粒度语义维度下的子维度。具体来说，本文引入了一种解纠缠连续语义表示模型（DCSRM），将大型语言模型中的词嵌入分解为多个子嵌入，每个子嵌入特定编码一定的语义信息。通过使用这些子嵌入，我们识别了一组可解释的语义子维度。为评估其实现的可能性，我们应用了体素级编码模型将这些子维度映射到大脑激活。这项工作提供了更加细粒度且可解释的语义子维度，进一步分析揭示了语义维度是根据不同的原则结构化的，极性是驱动它们分解为子维度的关键因素。所识别的神经相关子维度支持其认知和神经科学的可行性。", "conclusion": "本文的研究提供了更加细粒度且可解释的语义子维度，揭示了语义维度的组织原则，并通过神经关联支持这些子维度的认知和神经科学依据。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21587", "html_url": "https://arxiv.org/abs/2508.21587", "title": "当前文本匿名化趋势与最新进展综述", "title_en": "A Survey on Current Trends and Recent Advances in Text Anonymization", "authors": "Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa", "background": "各个领域的文本数据中包含敏感个人信息的日益普及，要求采取坚固的数据匿名化技术来保护隐私和遵守法规，同时保留数据在不同下游任务中的可用性。", "innovation": "本文综述了当前文本匿名化的趋势和最新进展，涵盖了基础方法如命名实体识别技术，以及大型语言模型对匿名化和反匿名化双重角色的影响，探讨了针对医疗、法律、金融和教育等关键领域的特定挑战与解决方案，还涉及形式化的隐私模型、风险感知框架以及作者匿名化等高级方法，此外还考察了评估框架、综合指标、基准测试和实用工具包，旨在提供未来研究方向的指导并汇聚当前知识。", "conclusion": "本文综述总结了当前的知识，并指出了新兴趋势和持续存在的挑战，包括隐私-效用权衡的变化、应对准识别符的需求以及大型语言模型能力的影响，并旨在为该领域的学术界和实践者提供未来研究方向的指导。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21448", "html_url": "https://arxiv.org/abs/2508.21448", "title": "深入探究：大型语言模型的意识形态深度", "title_en": "Beyond the Surface: Probing the Ideological Depth of Large Language Models", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大型语言模型（LLMs）已经显示出明显的意识形态偏见，但这些偏见的稳定性和深度尚未完全理解。表面级别的反应往往可以通过简单的提示工程被操控，这引发了质疑它们是否反映了连贯的底层意识形态。本文研究了LLMs中“意识形态深度”的概念，定义为它们内部政治表征的稳健性和复杂性。", "innovation": "本文采用双重方法：首先，使用指令提示和激活引导测量两个已知的开源LLM的可操控性。发现一些模型可以很容易地在自由派和保守派之间切换观点，而其他模型则表现出抵抗或拒绝率的增加，表明更根深蒂固的意识形态结构。其次，使用稀疏自动编码器（SAEs）探究这些模型的内部机制。初步分析表明，具有较低可操控性的模型具有更独特和抽象的意识形态特征。评价发现，一个模型可以包含另一个具有相似大小的模型7.3倍的政治特征。这种干预在“深度”的模型中会导致相关主题上的一致、合乎逻辑的推理转变，而在“浅度”的模型中则会导致拒绝输出增加。研究表明，意识形态深度是LLMs的一个可量化属性，而可操控性为它们的潜在政治架构提供了一个有价值的窗口。", "conclusion": "本文的研究结果表明，意识形态深度是LLMs的一个可量化属性，而可操控性为它们的潜在政治架构提供了一个有价值的窗口。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21422", "html_url": "https://arxiv.org/abs/2508.21422", "title": "自动评审员无法检测研究论文中的错误推理：一种新的反事实评估框架", "title_en": "Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework", "authors": "Nils Dycke,Iryna Gurevych", "background": "大型语言模型（LLMs）在加速和支持学术同行评审方面具有巨大潜力，并且越来越被用作完全自动的评审生成器（ARGs）。然而，潜在的偏见和系统性错误可能会对科研的完整性造成重大风险；因此，了解最先进的ARGs的具体能力和局限性是至关重要的。研究集中在高质量同行评审的核心技能之一：检测研究逻辑的错误。这涉及评估论文结果、解释和主张之间的内部一致性。", "innovation": "提出了一种全自动的反事实评估框架，以在受控条件下隔离并测试该技能。研究发现，在测试多种ARG方法时，尽管预期存在研究逻辑缺陷会对评审输出产生影响，但实际上研究逻辑中的缺陷并对其输出评审产生显著影响。这一发现推动了对未来工作的三项可操作性建议，并公开发布了反事实数据集和评价框架。", "conclusion": "尽管在测试中发现ARGs未检测到研究论文中的逻辑错误，但研究人员提出了未来改进工作的三项建议，并公开分享了反事实数据集和评估框架，以促进进一步的研究和发展。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "小语言模型创意写作的激发：LLM裁判机与多代理改进回报的对比", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大型语言模型（LLMs）展示了惊人的创作写作能力，但由于其巨大的计算需求限制了它们的广泛应用。改善小型语言模型（SLMs）提供了一种有前景的替代方案，但当前的方法，如有监督微调（SFT），在新颖性方面存在挑战，而通过人类反馈的强化学习（RLHF）方法则代价高昂。本研究在增强学习从AI反馈（RLAIF）框架内探索了两种不同的AI驱动奖励策略，旨在激发一个7B参数的SLM的创作写作能力，特别用于生成中文问候语。", "innovation": "研究提出的两种AI驱动奖励策略均在RLAIF框架下进行，分别采用了多代理改进回报方法和原理指导性LLM作为裁判机方法。前者通过新型多代理拒绝采样框架为创造性任务收集高质量偏好数据来训练奖励模型（RM）。后者则利用一种政策指导的LLM作为裁判机，并通过对抗训练方案结合反向机制来优化奖励函数，直接提供奖励信号。实验结果表明，两种方法均能显著提高创造性输出，而原理指导性的LLM作为裁判机方法在生成质量和训练效率上表现更优，并且降低了对人类标注数据的依赖，为创意SLM的发展提供了更为高效和可扩展的路径。", "conclusion": "研究结果显示，虽然两种方法都能显著提高创意输出，但原理指导性的LLM作为裁判机方法在生成质量和训练效率上表现更优，而且还有助于减少对人类标注数据的依赖，这为创意SLM的发展提供了一条更为高效和可扩展的路径。研究还发现，自动评估方法与人类评判高度一致，并且提供开源代码和数据以促进进一步研究。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 评估医疗多模态大型语言模型回报模型和评判者的基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医疗应用中具有巨大潜力，涵盖疾病诊断和临床决策等领域。这些任务需要高度准确、上下文敏感的专业对齐响应，因此需要可靠的奖励模型和评判者。尽管如此，医疗奖励模型（MRMs）和评判者的研究仍然较少，缺乏专门针对临床需求的基准。现有基准关注的是通用的MLLM能力或评估模型作为求解器，忽略了诊断准确性等关键的评估维度。因此，亟需一个专门针对医疗场景的基准来评估MRMs和评判者。为此，我们引入了Med-RewardBench，这是一系列专为医疗场景设计的评估MRMs和评判者的基准，包含涵盖13个器官系统和8个临床部门的多模态数据集，906个专家注释的情景。通过严格三步流程，确保六个临床上关键维度的数据质量。", "innovation": "我们首次设计了一个专门针对医疗场景的基准评估MRMs和评判者，称为Med-RewardBench。该基准包含13个器官系统和8个临床部门的多模态数据集，以及906个专家注释的情景。我们评估了32个最先进的MLLMs，包括开源、私有和医疗专用模型，揭示了与专家判断对齐的显著挑战。此外，我们还开发了基线模型，通过微调取得了显著的性能改进。这项研究填补了医疗奖励模型和评判者评估领域的一个空白，提高了对其重要性的认识，并推动了该领域的发展", "conclusion": "我们评估了32个最先进的MLLMs，在六个临床上关键维度上对它们进行了评估。我们发现在医疗场景中，这些模型在与专家判断对齐方面存在显著挑战。通过开发基线模型，我们展示了通过微调可以取得显著改进。Med-RewardBench为评估和进一步改进医疗场景中MRMs和评判者提供了坚实的基础。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 一个马拉地语句子相似性数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "当前，对于马拉地语文本相似性相关数据集和模型的研究相对较少，尤其是在低资源语言领域。因此，开发一个专门针对马拉地语文本相似性的数据集及其模型对于促进该领域的研究具有重要意义。MahaSTS 是一个手动标注的句子文本相似性（STS）数据集，包含了16,860个马拉地文句子对，并且针对回归相似性评分进行了优化。", "innovation": "MahaSTS 数据集和 MahaSBERT-STS-v2 模型的创新之处在于：1) 数据集包含大量的马拉地语句子对，并且通过均匀分布的方式确保了监督训练的平衡；2) MahaSBERT 模型经过针对这个数据集的微调优化，表现出对回归相似性评分的改善；3) 在低资源环境下，MahaSTS 数据集促进了针对马拉地语文本相似性任务的有效训练，并强调了精确标注、目标微调以及结构化监督的重要性；4) 数据集和微调后的模型公开共享，便于其他研究者使用和进一步改进。", "conclusion": "我们的实验展示了 MahaSTS 在马拉地语句子相似性任务中的效果，表明了人在回环注记、目标微调和结构化监督在低资源的语言环境中的重要性。MahaSTS 数据集和 MahaSBERT-STS 模型提供了一个可靠的基础，有助于促进马拉地语自然语言处理的研究和发展。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR：基于概率置信度选择与排序", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "大语言模型（LLMs）和大推理模型（LRMs）通过生成多个候选解决方案并选择得分最高的一个来提高准确性。推理任务的关键挑战在于设计一个不依赖于正确答案即可识别正确推理链的评分函数。", "innovation": "提出了一种名为Probabilistic Confidence Selection And Ranking (PiCSAR)的方法。该方法避免了训练过程，通过推理和最终答案的联合对数似然度为每一个候选生成打分。该评分自然分解为推理置信度和答案置信度，PiCSAR在多个基准测试上取得了显著的改进，并且在16次比较中超越了至少需要2倍样本数的基线方法。", "conclusion": "分析表明，正确的推理链在推理和答案置信度方面显著更高，这证明了PiCSAR方法的有效性。该方法在MATH500和AIME2025等多个基准上实现了大幅的提升。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo: 基于模型的动态数据优化以通过闭环学习增强大语言模型微调", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "监督微调（SFT）大型语言模型（LLM）的基本前提是有高质量的训练数据。虽然数据选择和数据合成是提高数据质量的两种常见策略，但现有方法在静态数据集管理中往往难以适应模型能力的演变。现有方法通常采用一次性过滤或合成方法，在静态数据集维护中遇到限制。", "innovation": "本文介绍了一种名为Middo的自我进化的模型驱动动态数据优化框架，该框架利用模型感知的数据选择和保留语义的数据精炼。与传统的单一过滤/合成方法不同，该框架建立了一个闭环优化系统：（1）一种自我参照的诊断模块通过三轴模型信号主动识别次优样本，包括损失模式（复杂性）、嵌入聚类动态（多样性）和自我对齐分数（质量）；（2）一个自适应优化引擎则将次优样本转换为具有教育价值的训练点，同时保持语义完整；（3）这一优化过程通过动态学习原则不断随模型能力演变。实验结果显示，该方法在多个基准上可以持续提高种子数据质量，并在平均提高7.15%准确率的同时保持原始数据集规模。该工作确立了一种新的通过数据和模型的持续人机共进化实现可持续大语言模型训练的新范式。我们即将公开发布相关数据集、模型和代码。", "conclusion": "我们的工作建立了一种新的通过动态人机共进化数据和模型来实现可持续大语言模型训练的新范式。实验结果表明，Middo方法可以持续提升种子数据质量，提升LLM性能平均提高7.15%的同时保持原始数据集规模。我们即将公布相关数据集、模型和代码。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21628", "html_url": "https://arxiv.org/abs/2508.21628", "title": "人格因素起作用：用户特质在多轮协作任务中预测LLM的偏好", "title_en": "Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks", "authors": "Sarfaroz Yunusov,Kaige Chen,Kazi Nishat Anwar,Ali Emami", "background": "随着大型语言模型（LLMs）越来越多地融入日常工作流程，用户通过多轮合作影响结果。因此提出了一个关键问题：不同人格特质的用户是否系统地偏好某些LLMs？研究通过对比GPT-4和Claude 3.5在四项协作任务中的表现（数据解析、创意写作、信息检索和写作辅助），探讨了用户偏好与人格类型之间的关系。", "innovation": "研究通过引入多轮协作任务，并将用户分为四种Keirsey人格类型，评估用户与GPT-4和Claude 3.5的交互，揭示了基于人格的差异，这在传统评估中往往被忽视。", "conclusion": "研究成果显示，不同人格类型在任务导向任务中更偏好GPT-4，在创造性和分析性任务中更偏好Claude 3.5。聚合的有用性评分相似，这表明基于人格的分析揭示了传统评价可能错过的LLM差异。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "推理密集型回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "研究人员和从业者越来越多地使用大型语言模型（LLMs）进行所谓的推理密集型回归（RiR），即从文本中推导出微妙的数值属性。与标准的语义回归任务（如情感分析或相似度分析）不同，RiR经常出现在诸如评分准则或特定领域检索这样的临时问题中，需要对文本进行更深入的分析，但仅有有限的任务特定训练数据和计算资源。", "innovation": "该研究将三个现实问题作为RiR任务来建立初步基准，并通过测试假设表明，冻结LLMs的提示调优和通过梯度下降微调Transformer编码器经常会遇到困难。然后，该研究提出了一种名为MENTAT的简单而轻量的方法，结合了批归因提示优化和神经集成学习。MENTAT在两个基线上的表现优于65%。", "conclusion": "虽然MENTAT方法在学校已经取得了显著的进步，但在推理密集型回归（RiR）领域中仍然有很大的改进空间。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这个图表是在欺骗我吗？自动化误导性图表检测", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性的可视化是社交媒体和网络上传播虚假信息的一种强大驱动因素。通过违反图表设计原则，它们扭曲数据，促使读者得出不准确的结论。过往的研究表明，无论是人类还是多模态大型语言模型（MLLMs）都会频繁地被这些可视化所欺骗。自动检测误导性可视化并识别它们违反的具体设计规范将有助于保护读者并减少虚假信息的传播。但是，由于缺乏大型、多样化且开放获取的数据集，AI模型的训练和评估受到了限制。因此，本文提出了一项名为Misviz的基准测试，包含2,604个真实世界的可视化，标注了12种类型的误导。为了支持模型训练，还释放了一个由Matplotlib生成的基于真实数据表的81,814个可视化合成数据集Miviz-synth。使用最先进的MLLMs、基于规则的系统和微调分类器对两个数据集进行了全面评估，结果显示该任务仍然具有很高的挑战性。", "innovation": "介绍了Misviz基准，包含2,604个真实世界的可视化，标注了12种类型的误导性特征，并合成了一个名为Miviz-synth的数据集，包含81,814个基于真实数据表的可视化，使用Matplotlib生成。评估使用了最先进的MLLMs、基于规则的系统和微调分类器，揭示了这一任务的挑战性，并且公开了Misviz、Miviz-synth和相应的代码，填补了该领域的空白，促进了误导性可视化检测的研究与发展。", "conclusion": "我们的结果表明，自动检测误导性可视化和识别它们违反的具体设计规范仍然非常具有挑战性。我们提供了一个新的基准Misviz，以及合成的Miviz-synth数据集和相应代码，以支持进一步的研究。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21741", "html_url": "https://arxiv.org/abs/2508.21741", "title": "所有参数并非平等：智能隔离提升微调性能", "title_en": "Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance", "authors": "Yao Wang,Di Liang,Minlong Peng", "background": "监督细调（SFT）是将大型语言模型（LLM）适应下游任务的关键方法；然而，此过程常常遭受“跷跷板现象”的影响，即无差别的参数更新导致某些任务的进步而牺牲了其他任务的性能。", "innovation": "提出了新的“核心参数隔离微调”（CPI-FT）框架。该框架首先独立地在每个任务上微调LLM以识别核心参数区域，然后基于区域重叠将相似的程序分组并共同建模。此外，引入了参数融合技术：将每个任务单独微调后的核心参数直接移植到统一架构中，同时使用球面线性插值（SLERP）平滑地整合不同任务的非核心参数。并采用混合任务数据进行轻量级的、流水线化的SFT训练阶段，同时冻结先前任务的核心区域以防止灾难性遗忘。", "conclusion": "大量的实验表明，该方法显著减轻了任务间的干扰和遗忘，并且在多个公开基准上始终优于传统的多任务和多阶段微调基线。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17693", "html_url": "https://arxiv.org/abs/2508.17693", "title": "通过双大型语言模型自我精炼实现数据库规范化", "title_en": "Database Normalization via Dual-LLM Self-Refinement", "authors": "Eunjae Jo,Nakyung Lee,Gyuyeong Kim", "background": "数据库规范化对于保存数据完整性至关重要，但通常需要数据工程师手动完成，这个过程既耗时又容易出错。为此，我们提出了一种利用大型语言模型能力的数据库规范化框架Miffie，以实现无需人工干预的自动化数据规范化，同时保持高准确性。Miffie的核心是一个结合了最佳模型的双模型自我精炼架构，分别用于生成和验证规范化模式，该生成模块根据验证模块的反馈逐步消除异常，直到输出模式满足规范化需求。此外，我们还特意设计了特定任务的零样本提示来引导模型实现高准确性和成本效率。实验结果显示，Miffie能够处理复杂数据库模式并保持高准确性。", "innovation": "Miffie框架使用两个大型语言模型实现数据库模式的自动规范化。它通过一种结合生成和验证模块的双模型自我精炼架构来提高规范化结果的准确性和效率。特别设计的零样本提示指导模型完成任务，同时实现高准确性和成本效率。", "conclusion": "实验结果表明，Miffie能够高效、高准确地对复杂数据库模式进行规范化，极大地提高了数据库管理的自动化水平。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大型语言模型：从数据基础到代理前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大型语言模型（Sci-LLMs）正在变革科学研究中知识的表示、整合和应用方式。然而，Sci-LLMs 的进展受到科学数据复杂性的制约。本文综述深入分析了这些模型的发展，将其重新定义为模型与其底层数据结构之间的共进化过程。文章强调了科学语料库与通用自然语言处理数据集之间的区别，突显了多模态、跨尺度和领域特定的挑战。通过系统回顾近200个基准数据集并分析超过270个预/后训练数据集，文章展示了科学大型语言模型面临的独特需求：异质、多尺度、不确定性丰富的语料库，这些模型要求保留领域不变性和促进跨模态推理的能力。", "innovation": "文章提出了科学数据统一分类学和科学知识的分层模型，并系统地回顾了从通用基础模型到跨学科专用模型的各种科学大型语言模型，同时对超过270个预/后训练数据集进行了详细分析。通过这些数据中心的综合研究，文章揭示了科学数据开发中持续存在的问题，并讨论了涉及半自动化注释管道和专家验证的新兴解决方案。文章还提出了向闭环系统过渡的范式，其中基于科学大型语言模型的自主代理能够实验、验证并贡献于一个鲜活的进化知识库。", "conclusion": "这项工作提供了一份蓝图，用于构建可信且不断演化的 AI 系统，这些系统可以作为科学发现的真正伙伴，加速科学发现过程。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "SWIFT消息交易对手方特征提取与聚类归一化", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "短文本聚类是文本分析领域的已知应用场景。对于如推特帖子或即时消息等自然语言文本，可以使用自然语言技术，前提是文本长度足够，可以利用预训练模型提取有含义的信息，如词性标注或主题注释。然而，对于银行支付消息系统中的交易对手方（如SWIFT系统），自然语言模型不适用。这些信息通常是手工输入的标签，缺乏句法结构，且包含了手工输入引入的所有变体和噪声。这使得在了解支付流程起点和受益机构以及追踪资金和资产时，调查员或反欺诈专业人员的工具箱存在空白，传统上，供应商会使用模糊匹配工具来解决这一问题。", "innovation": "提出了一种结合字符串相似性、主题建模、层次聚类和基于规则的管道的混合方法，以实现SWIFT交易对手方的聚类，即使得聚类方法可以适应未知数量的预期簇。此外，还设计了一些补充指标，基于精度和召回率等公认的评价标准来评估该方法。在实际标记数据集上的测试表明，该方法的性能显著优于基于关键词的基准系统。该方法保留了基于规则系统的大约可解释性，因为它为后者增加了额外的聚类细化层次。", "conclusion": "该方法适用于仅需调查部分人群的情况，例如制裁调查，可更好地控制错过实体变体的风险。新的策略显著改善了对SWIFT交易对手方的聚类效果，不仅提升了算法的效率，还保持了原有方法的可解释性，降低了人工审核的需求。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "精细梳理细网：细网问题内容搜索与检索的索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大规模语言模型（LLMs）依赖于如Common Crawl这样的大规模网络数据集进行训练，但无选择性的网络爬虫方式导致了数据质量、安全性和伦理方面的问题。尽管高质量的训练数据至关重要，但先前对有害内容的研究由于计算限制大多仅限于小样本。", "innovation": "本项目提出了一种基于ElasticSearch的框架，用于索引和分析LLM训练数据集。该框架被应用于瑞士AI的FineWeb-2语料库（1.5TB，四个语言），实现了快速查询性能，绝大多数搜索在毫秒级别，全部在2秒内完成。该工作展示了实时数据集分析，提供实用工具以实现更安全、负责的AI系统。", "conclusion": "本工作展示了如何通过索引细网语料库，加快对问题内容的搜索和检索，提供实时分析工具，增强AI系统的安全性与责任感。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding 技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "现有的文本嵌入模型需要改进，以增强文本表示能力，提高不同任务上的性能，特别是在语义丰富性和样本难度方面。为了应对这些需求，研究者们设计了能够整合多样化的训练数据集并提高模型学习效率的新方法。", "innovation": "QZhou-Embedding是一个通用的上下文文本嵌入模型，基于Qwen2.5-7B-Instruct基础模型，采用了统一的多任务框架，包括专门的数据转换和训练策略。数据转换方案增加了更多样化的训练数据集的接入，而任务特定的训练策略提高了模型的学习效率。此外，通过利用LLM API，运用诸如同义替换、数据增强和生成困难负例等技术，开发了一套数据合成管道，进一步提升了训练集的语义丰富性和样本难度。模型采用了两阶段训练策略：首先是检索导向的预训练，然后是全面的任务微调，这使得嵌入模型能够在良好的检索表现基础上扩展其能力。", "conclusion": "QZhou-Embedding在MTEB和CMTEB基准测试中取得了最先进的结果，并同时在重排序、聚类等任务上也表现出最先进的性能。我们的研究表明，更高质量、更多样化的数据对于提高检索模型性能至关重要，而利用大语言模型的生成能力可以进一步优化数据质量，促进嵌入模型取得突破。研究还发布了模型权重，并提供了可复现的评估代码和说明文件，以促进研究的进一步发展和应用。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化和语境化：通过认知支架增强大型语言模型指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究讨论了建筑性先验偏好如何影响大型语言模型（LLMs）在教学对话中的认知行为。通过引入一种符号性的支撑机制和短期记忆模型，旨在促进Socratic教学中的适应性和结构化推理。", "innovation": "提出了一种符号性的支撑机制和短期记忆模式，设计目的是促进Socratic教学中的适应性结构化推理。通过五个系统变体的受控去除分析，利用专家设计的评分标准评估模型输出，这些标准涵盖支撑、响应性、符号推理和对话记忆。使用基于LLM的评估框架，与认知基础的评分标准对齐，这促进了早期阶段建筑变体的可扩展、系统性比较。", "conclusion": "初步结果显示，完整系统在所有方面都优于基线变体。分析表明，删除记忆或符号结构会破坏关键的认知行为，包括抽象、适应性探查和概念连续性。这些发现支持一个处理级的解释，即架构支架可以可靠地塑造LLMs中出现的教学策略。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "Morae：为用户选择主动暂停的UI代理", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "用户界面（UI）代理有潜力使盲人和低视力（BLV）用户更容易访问先前难以访问或复杂的UI。然而，当前的UI代理通常是在执行任务时不会让用户参与关键决策，也不向用户提供必要的上下文信息，从而减少了用户的自主性。例如，在一项实地研究中，一名BLV参与者希望购买最便宜的气泡水，但代理自动选择了价格相等的几种之一，却没有提供其他具有不同风味或更好评价的产品选项。", "innovation": "本文提出Morae，这是一种在任务执行过程中自动识别决策点并暂停让用户做选择的UI代理。Morae利用大规模多模式模型来解释用户的查询和UI代码及截图，并在需要做选择时向用户求证。与基线代理（包括OpenAI Operator）相比，在一项基于真实世界Web任务的研究中，Morae帮助BLV参与者完成了更多的任务，并选取了更符合他们偏好的选项。", "conclusion": "更广泛地说，这项工作展示了用户和UI代理之间的混合主动性方法：用户可以从UI代理的自动化中受益，同时表达自己的偏好。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM: 完整评估音频语言模型", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "音频语言模型（ALMs）的评估受限于缺乏标准化基准；大多数基准仅衡量单一或少数几个能力，忽略了诸如公平性或安全性等评估维度。此外，模型间的比较困难，因为不同的评估仅测试少量模型，并使用不同的触发方法和推理参数。", "innovation": "AHELM 是一种基准，合并了各种数据集，包括两个新的合成音频-文本数据集（PARADE，评估 ALMs 避免刻板印象；CoRe-Bench，通过推理多轮问答衡量对话音频中的推理能力），以全面测量 ALMs 在十个我们认为对 ALMs 的开发和使用重要的方面上的性能：听觉感知、知识、推理、情绪检测、偏见、公平性、多语言性、鲁棒性、毒性和安全性。AHELM 标准化了触发提示、推理参数和评估指标，确保模型间的公平比较。14个开放权重和封闭 API 的 ALMs 从三个开发者和三个额外的基于自动语音识别器和语言模型的简单基线系统进行了测试。", "conclusion": "Gemini 2.5 Pro 在五个方面中排名第一，但在识别录音任务上表现出群体不公平性（p=0.01），而大多数其他模型没有这种情况。基线系统在 AHELM 中表现良好，尽管仅有语音转文本能力，却在总体中排名第5。所有原始提示、模型生成和输出均可在网站上查阅。AHELM 意图成为一个活基准，未来将添加新的数据集和模型。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21256", "html_url": "https://arxiv.org/abs/2508.21256", "title": "CrossTL: 具备统一中间表示的通用编程语言翻译器", "title_en": "CrossTL: A Universal Programming Language Translator with Unified Intermediate Representation", "authors": "Nripesh Niketan,Vaatsalya Shrivastva", "background": "传统的编程语言翻译器需要为每对语言建立专门的翻译器，这导致了复杂性的指数级增长。CrossTL通过引入统一的中间表示（CrossGL）来解决这个问题，使得可以在CUDA、HIP、Metal、DirectX HLSL、OpenGL GLSL、Vulkan SPIR-V、Rust和Mojo之间实现双向翻译，同时还在开发中支持Slang。", "innovation": "CrossTL的核心创新在于使用单一的统一中间表示，这使得它可以支持多种编程语言之间的翻译，并且简化了添加新语言的流程，只需添加相应的前端和后端组件即可。该系统具有统一的中间表示、模块化架构、全面的支持框架和实验验证来证明其实际可行性，此框架支持GPU计算、图形编程和系统语言。这些改进显著降低了翻译复杂性，提升了系统的可扩展性和实用性，是朝着实现无感知编程方向的一大步。", "conclusion": "CrossTL通过利用统一的中间表示和模块化设计，有效解决了多语言之间的翻译问题，不仅简化了现有语言的支持，还易于添加新的编程语言。系统在多个编程领域进行了全面的验证，表现出了良好的兼容性和实用性，从而证明了无感知代码翻译的可行性，对未来编程范式的转变有着重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "公平之路：从群体公平性到个体公平性", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统（RSs）中的公平性通常被分类为群体公平性和个体公平性，但现有研究未能科学地理解这两种公平性之间的关系。由于各类型研究采用不同的评估指标，使得直接对比变得困难，因此目前尚不清楚提高其中一种公平性是否会影响另一种公平性。", "innovation": "本文通过全面比较适用于群体公平性和个体公平性的评估指标，研究了这两种公平性之间的关系。实验结果表明，对群体非常公平的推荐可能对个人非常不公平。这一发现为希望改进系统的推荐系统实践者提供了新的有用信息。同时，作者的代码可在指定链接处获取。", "conclusion": "研究显示推荐系统中群体和个体公平性的关系是复杂且相互影响的。提高群体公平性可能导致个体公平性降低，反之亦然。该研究结果对推荐系统的公平性改进具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21209", "html_url": "https://arxiv.org/abs/2508.21209", "title": "设计更智能的对话代理：基于认知工作与目标-手段分析的经验教训", "title_en": "Designing Smarter Conversational Agents for Kids: Lessons from Cognitive Work and Means-Ends Analyses", "authors": "Vanessa Figueiredo", "background": "本文讨论了如何通过研究9-11岁巴西儿童在学习、发现和娱乐活动中与对话代理（CAs）互动的情况，以及结构化支架如何增强这些互动。第一阶段使用在线调查、访谈、观察和认知工作分析，研究了儿童的信息处理流程、专家角色、功能用途、情境目标和互动模式，为对话树设计提供指导。第二阶段通过模拟儿童与对话代理的交流，探索了结构化提示在对话树设计中的效用。", "innovation": "本研究创新性地提出了第一项针对巴西儿童的对话代理（CWA）应用，并建立了一个儿童-对话代理信息流动的实证框架，还提出了基于结构提示（即结构性提示）的对话代理“食谱”方法，用于有效引导式的儿童学习。", "conclusion": "研究建议包括结构化的对话树、适合儿童的个性化配置文件和护理人员精选的素材等设计建议。研究结果表明，结构性提示可以提高对话树的可读性和交流质量。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06679", "html_url": "https://arxiv.org/abs/2409.06679", "title": "E2LLM：扩展的大型语言模型以进行长上下文理解与推理", "title_en": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "authors": "Zihan Liao,Jun Wang,Hang Yu,Lingxiao Wei,Jianguo Li,Jun Wang,Wei Zhang", "background": "大型语言模型（LLMs）在多轮对话、代码生成和文档总结等任务中越来越需要注意处理长上下文的问题。然而，要在保持高效计算复杂度和兼容预训练模型的前提下实现高性能的长上下文处理面临着极其困难的挑战。", "innovation": "该论文提出了一种名为E2LLM的新方法，通过将长上下文分割成块，使用预训练的文本编码器将其压缩成软提示，并通过适配器与解码器只读的大规模语言模型进行对齐。E2LLM采用两个训练目标来增强大语言模型使用这些软提示的推理能力：编码器输出重建和长上下文指令微调。实验证明E2LLM不仅在文档总结和问答任务上优于8种最先进的方法，在计算复杂度和性能上都更优，还在LongBench v2基准测试中表现出色。", "conclusion": "E2LLM能够在保持低计算复杂度和兼容预训练模型的前提下实现长上下文的有效处理，不仅在文档总结和问答任务上表现出色，在LongBench v2中也达到了最佳性能。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "Summarize-Exemplify-Reflect: 数据驱动的洞察蒸馏为大语言模型赋能少量样本表数据分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "最近的研究表明，大型语言模型在少量样本表数据分类领域具有潜力，但也指出了由于结构化数据的变异性所带来的挑战。为了应对这些挑战，本文提出了将数据提炼成可操作的洞察，以使大语言模型能够实现稳健有效的分类。", "innovation": "本文提出了InspightTab，这是一种基于分而治之、先易后难和反思学习原则的洞察提炼框架。该方法整合了规则总结、战略示例以及通过大语言模型与数据建模技术的深度合作来进行的洞察反思。这种方法所得的洞察使大语言模型能够更好地将其通用知识和能力与特定表任务的具体需求对齐。实验结果展示了InspightTab在九个数据集上的优越表现，并且消融实验进一步验证了原则指导下的提炼过程的有效性。", "conclusion": "InspightTab的一致改进超过了最先进的方法。分析强调了InspightTab在利用标记数据和管理偏见方面的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "模型-任务对齐驱动不同的RL结果", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "近年来，将强化学习（RL）应用于大型语言模型（LLMs）的研究取得了重大进展。在LLMs中，一些令人惊讶且常常不符合直观预期的现象被报道，这些现象在传统的RL设置中通常不会出现。例如，单一的训练样本可以达到整个数据集训练的效果，奖励信号不一定非常准确，仅仅使用负面样本也可以与甚至超越基于奖励的方法相当。然而，这些观察现象的精确条件以及何时会失效仍然不清楚。", "innovation": "通过系统且全面地研究一系列反常识的断言，并在不同的模型架构和任务领域中进行严格的实验验证，本研究揭示了一个关键因素：预训练模型是否已经显示出强大的模型-任务对齐（通过评估任务的pass@k准确度衡量），这对于产生RL结果的不同具有决定性作用。研究发现，尽管标准的RL训练在各种设置中保持一致的稳定性，但许多反常识的结果只在模型和任务已经表现出强大的模型-任务对齐时才会出现。而在更具挑战性的环境中，这些技术并未驱动显著的学习，而标准的RL方法仍然有效。", "conclusion": "研究表明，标准的RL训练方法在大多数情况下依然有效，但是许多反常识的结果仅在模型和任务已经表现出强大的模型-任务对齐时才成立。在不太容易的环境中，这种技术的性能不及标准的RL方法。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受或拒绝？跨表格文本序列化方法评估大型语言模型在贷款审批中的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "大型语言模型（LLMs）在高风险决策任务中越来越被使用，例如贷款审批。尽管它们的应用范围正在扩大，但在处理表格数据方面，LLMs 面临困难，且难以保证公平性，提供可靠预测。特别是在贷款审批这一重要领域，LLMs 的性能和公平性问题尤为突出。因此，本研究集中在评估 LLMs 在来自不同地理区域的贷款审批数据集上的表现和公平性。这些数据集分别来自加纳、德国和美国三个不同的地区，以考察序列化格式（即将表格数据转换成适合LLMs处理的文本格式）对模型性能和公平性的影响。本研究的重点在于模型的零样本学习（Zero-shot）和有上下文学习（ICL）能力。研究结果表明，不同序列化格式显著影响了LLMs的性能和公平性，某些格式如GReat和LIFT虽提高了F1分数，却加剧了公平性差距。此外，尽管有上下文学习（ICL）相对零样本学习（Zero-shot）提高了性能4.9-59.6%，但其对公平性的影响则在不同数据集之间差异显著。研究表明，有效的表格数据表示方法和公平性感知模型对于提高LLMs在金融决策中的可靠性至关重要。", "innovation": "本研究创新之处在于评估了不同序列化格式对LLMs在贷款审批任务中的表现和公平性的影响，并探讨了有上下文学习（ICL）对这些方面的具体影响。研究还强调了在金融决策中提高LLMs表现和公平性的有效方法的重要性，特别是使用合理的表格数据表示和公平性意识模型。", "conclusion": "本研究揭示了有效的表格数据表示方法和公平性感知模型对于提高大型语言模型在金融决策中的可靠性至关重要。有上下文学习（ICL）虽能显著提升模型性能，但其对公平性的改善效果因数据集而异。因此，未来研究应关注如何进一步优化数据表示方法和提高模型的公平性，以提升LLMs在实际金融决策中的表现。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.24155", "html_url": "https://arxiv.org/abs/2410.24155", "title": "Large Language Model Reasoning中的Thought Space Explorer导航盲区", "title_en": "Blind Spot Navigation in Large Language Model Reasoning with Thought Space Explorer", "authors": "Jinghan Zhang,Fengran Mo,Tharindu Cyril Weerasooriya,Yeyang Zhou,Xinyue Ye,Dongjie Wang,Yanjie Fu,Kunpeng Liu", "background": "近年来，大型语言模型（LLMs）在处理复杂推理任务方面显示出巨大潜力。这些任务通常通过构建思维链来引导模型进行多步思考以解决问题。然而，现有方法往往局限于已探索的解空间，未能解决LLMs认知范围内的关键盲区问题。", "innovation": "为了应对这些问题，本文引入了“思维空间探索者”（TSE）框架，这是一种新颖的方法用于扩展和优化思维结构，以指导LLMs探索其思维盲区。TSE通过基于原始思维结构生成新的推理步骤和分支，采用多种设计策略，拓宽了思维探索视角并缓解了盲区对LLM推理的影响。实验结果表明，TSE在多个层次的推理任务中优于多种基线方法。", "conclusion": "本文通过广泛分析，证明结构化和扩展思维可以释放LLMs的推理潜力。TSE框架能够有效扩展和优化思维结构，帮助解决LLMs在复杂推理任务中的认知盲区问题。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么止步于单词？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别(OCR)技术将每个字符单独分割和识别，这使得它们容易在字符分割时出错，并且缺乏上下文，无法利用语言模型。近年来，序列到序列翻译的进步导致现代技术首先检测单词，然后每次将一个单词输入到模型中，以直接输出完整的单词为字符序列。这种方法能够更好地利用语言模型，并绕过了易出错的字符分割步骤。然而，这一变化使得准确性的瓶颈转移到了单词分割上。因此，本文提出了一种从单词级OCR向行级OCR的自然和逻辑演进。这允许绕过单词检测中的错误，并提供更大的句子上下文，以便更好地利用语言模型。", "innovation": "本文提出了一种行级OCR方法，通过绕过单词检测中的错误，并提供更大的句子上下文来更好地利用语言模型，从而改善了OCR的准确性和效率。此外，还贡献了一个包含251张英文页面图像的仔细策划的数据集，这些图像具有行级注释，以支持从单词级向行级OCR的转变，并通过实验展示了端到端准确性的提高和效率的显著提升。该方法还具有利用大型语言模型持续改进的潜力。", "conclusion": "实验结果表明，该提出的技术不仅提高了OCR的准确性和效率，而且通过提供更大的句子上下文更好地利用了语言模型。此外，还贡献了一个精心策划的包含251张英文页面图像的数据集，这些图像具有行级注释，以支持从单词级向行级OCR的转变。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "连续的语言模型插值以实现动态和可控的文本生成", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "随着大型语言模型（LLMs）在多种应用场景中变得越来越受欢迎，如何让这些模型适应和可控变得尤为重要，特别是对于面向用户的应用程序。现有的关于LLM可适应性研究多集中在找到一个或多个最优模型以满足单个预定义目标，而本文专注于当模型需要根据不同且常常改变的用户偏好动态调整的情况下，这种更为挑战性的适应情形。文章通过应用基于线性权重插值的适应方法，将其视为连续多领域的插值器，从而实现在生成模型上随机产生具有特定预设生成特性的模型。", "innovation": "本文通过使用低秩更新方法，微调基模型以适用于各种不同的领域，生成具有不同生成特性的锚模型。然后，使用这些锚模型的权重更新来参数化其凸壳内的整个（无限）类模型。实验证明，改变插值权重会导致模型输出关于所有可控属性的一致变化。文章还识别并讨论了属性间不纠缠的配对，并且得出结论：线性插值微调后的模型权重可以实现多风格特征的同时精细控制。", "conclusion": "研究表明，线性插值微调后的模型权重能够实现在多风格特征方面的可预测、精细的控制。同时，文章也指出了大多数属性之间的可分离性，以及指出一些属性对之间可能存在复杂的相关性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "增强量子自然语言生成：具有混合量子-经典架构的多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "随着量子计算在自然语言处理(NLP)应用中的兴趣日益增长，本研究对比评估了量子文本生成模型与传统Transformer和MLP架构。实验在五个不同数据集上进行，包括简单的句子、短篇故事、量子短语、俳句和谚语。", "innovation": "本文采用系统实验方法，对比了五种不同的模型：基础Transformer、量子核自注意力网络(QKSAN)、量子RWKV(QRWKV)以及量子注意力序列架构(QASA)，并使用多个评估指标，如困惑度、BLEU分数、词汇多样性、重复率和流畅度，评估文本生成质量的不同方面。结果显示，虽然传统的Transformer模型在总体上保持了优越性，但在某些特定情况下，量子启发式模型显示出了竞争力。", "conclusion": "尽管传统的Transformer模型在平均困惑度和BLEU-1分数上最优，但量子启发性模型在特定场景中显示出了卓越表现。QKSAN的BLEU-1分数为0.2800且无重复现象，同时QRWKV在某些任务中显示出了完美的词汇多样性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "大语言模型中精细粒度的价值与观点揭示", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "通过解析大型语言模型（LLMs）中隐含的价值观和意见，可以识别潜在的偏见并减轻可能的危害。以前的研究通常是通过向LLMs提出调查问题，并量化对具有道德和政治争议的陈述的立场来实现的。然而，由于LLMs的立场会根据不同的提示方式产生显著变化，对于某个给定立场的支持和反对可以通过多种方式进行论证。为解决这一问题，本文通过分析156,000个LLM对Political Compass Test（PCT）62个命题的响应，来识别和量化这些模式。这项工作从粗粒度和细粒度两个层面进行了分析，特别提出了一种识别回应中的‘法则’的方法，这些法则代表了不同提示下LLMs易于产生的语义相似的短语模式。此外，实验结果揭示了被提示的种族人口统计特征显著影响PCT结果，以显示偏见及封闭形式与开放领域作答之间的差异模式。", "innovation": "本文创新地通过分析大型语言模型对PCT命题的156,000次响应，采用粗粒度和细粒度分析方法，特别是利用‘法则’来识别并量化响应中的语义相似的短语模式。这种方法揭示了被提示的种族人口统计特征对模型结果的影响，并展示了不同模型响应之间的模式特征乃至相同立场下的不同文案生成方式。", "conclusion": "研究表明，不同的人口统计特征提示会显著影响大型语言模型的PCT测试结果，反映出偏见的存在。此外，模型生成的简单文本解释通过相似的‘法则’具有模式性，即使立场不同也是如此。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用非结构化知识增强的机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "传统的机器翻译（MT）通常依赖于已配对的MT语料库中的上下文示例或知识图中的特定领域知识，来增强MT模型的能力。然而，大量世界知识分布在非结构化的文档中，这些知识可能在不同语言间并未完全配对。因此，该研究旨在研究如何利用非结构化文档来增强机器翻译。为此，通过GPT-4o和人工翻译收集了169,000个MT样本，形成RAGtrans基准，该基准为LLMs的检索增强MT能力提供培训和评估。除此之外，多语言文档也被提供给这些样本，以提供所需的知识。", "innovation": "该研究首次构建了一个名为RAGtrans的基准，用于培训和评估LLMs的检索增强MT能力。RAGtrans利用GPT-4o和人工翻译收集的数据，为翻译提供非结构化文档知识。研究进一步提出了一种多任务训练方法，通过利用现有的多语言语料库创建辅助训练目标，而无需额外的标注要求，以教导LLMs如何在翻译过程中使用多语言文档中的信息。研究表明，该方法在英-中和英-德翻译中分别在BLEU和COMET分数上提高了1.6-3.1和1.0-2.0，以及1.7-2.9和2.1-2.7。", "conclusion": "当前LLMs在检索非结构化知识用于机器翻译任务时面临一些关键困难。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.06821", "html_url": "https://arxiv.org/abs/2504.06821", "title": "生成基于程序的技能以实现代理任务", "title_en": "Inducing Programmatic Skills for Agentic Tasks", "authors": "Zora Zhiruo Wang,Apurva Gandhi,Graham Neubig,Daniel Fried", "background": "为了成功执行网上导航等数字任务，代理需要执行各种特定任务，如搜索产品或规划旅行路线。这些任务可以通过在线与网页环境互动学习来解决。已有研究通常使用静态基线或文本技能来解决这类问题，但效果受限。本文提出了基于程序的技能引导（Agent Skill Induction, ASI）方法，旨在让代理能够通过实时诱导、验证并使用基于程序的技能来适应任务变化，从而提高效率和准确性。", "innovation": "本文提出的ASI方法通过在归纳过程中提供基于程序的验证保证，解决了现有方法在高效性和适应性方面的不足。该方法通过将基础动作（如点击）组合成高级技能（如搜索产品），减少了步骤数量，提高了任务执行效率。此外，ASI方法还可以在网络活动规模扩大时保持效率和准确性，并且具有较强的一般性，在不同网站间的技能转移中也能有效利用和更新技能以适应网站变化。", "conclusion": "ASI方法在WebArena代理基准测试中取得了显著的性能提升，特别是在成功率和步骤效率方面。通过验证和利用基于程序的技能，ASI不仅提高了代理的适应性和高效性，还在不同的网络环境中表现出了良好的一般性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans: 通过强化学习实现深度推理翻译", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "近期，深度推理语言模型（例如OpenAI o1和DeepSeek-R1）在多种下游任务中表现出了良好的性能。自由翻译是一个在多语言世界中重要且有趣的任务，它要求超越逐字翻译。然而，在深度推理语言模型中，该任务仍然没有得到充分探索。", "innovation": "本文介绍了通过强化学习学习自由翻译的深度推理翻译模型DeepTrans。具体来说，通过精心构建惩罚模型，在翻译结果和思维过程中都有预定义的评分标准。该奖励模型教会DeepTrans如何进行思考并对给定句子进行自由翻译。此外，我们的强化学习训练不需任何标注的翻译，避免了人力密集型注释或资源密集型数据合成。", "conclusion": "实验结果表明，DeepTrans非常有效。以Qwen2.5-7B为骨干模型，DeepTrans在文献翻译性能上提高了16.3%，超越了强大的深度推理语言模型。此外，我们总结了在强化学习探索中发现的失败和有趣的现象，我们希望本工作能激励其他研究人员对自由翻译的研究。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "毒性引发毒性：解开政治播客中对话链", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "数字通讯中的有毒行为依然是学术界和行业专业人士关注的紧迫问题。尽管已有大量的研究关注社交网络和讨论板上的毒性问题，但 podcast 音频节目的研究相对较少，特别是政治播客，它们虽然日益受到欢迎，但在毒性研究中的关注度仍然不足。此研究通过分析政治播客的对话结构，揭示有毒语言通过回复链条如何在网络上进一步蔓延和升级的有机模式。", "innovation": "研究创新之处在于收集并分析了政治播客的对话记录，专注于探讨毒性如何通过对话中回复的序列进行传播与增强的机制。该研究填补了在有毒行为赛道中对于音频形式内容的空白，提供了对有毒语言在网络对话中升级动态的新视角。此外，研究明确包含潜在的有毒内容警告，提醒读者注意可能存在的不良语言表达。", "conclusion": "研究揭示了在政治播客对话中，有毒语言如何通过交流链条而升级的现象。这不仅提供了学术界理解网络环境中有毒行为蔓延机理的实证证据，也将有益于指导未来相关领域制定更加具体的干预和防范措施。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于注释分歧非参数化估计的协作内容审核框架用于毒性检测", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "内容审核通常结合了人类审核员和机器学习模型的努力。然而，这些系统往往依赖于包含重大审核分歧的数据，这反映了毒性感知的主观性。传统做法是将这些分歧视为噪声，而不是有价值的信号，这种信号揭示了内容内在的模糊性。", "innovation": "该研究提出了一种新颖的内容审核框架，强调捕捉注释分歧的重要性。该方法采用多任务学习，将毒性分类作为主要任务，注释分歧作为辅助任务。此外，还利用了不确定性估计技术，特别是Conformal Prediction，来处理评论注释中的模糊性和模型在预测毒性时的内在不确定性。该框架还允许审核员调整注释分歧的阈值，提供了在决定何时需要进一步审核时的灵活性。", "conclusion": "实验证明，联合方法可以增强模型性能、校准和不确定性估计，同时提高审核过程的效率，相比单一任务方法更具参数效率。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17464", "html_url": "https://arxiv.org/abs/2505.17464", "title": "Hydra: 结构化跨源增强的大语言模型推理", "title_en": "Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning", "authors": "Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang", "background": "当前的混合RAG系统通过从知识图和文本文档中检索证据来支持大语言模型的推理，但面临着多跳推理、多实体问题、多源验证和有效图利用等方面的挑战。", "innovation": "Hydra 提出了一种无需训练的框架，统一了图形拓扑、文档语义和来源可靠性，以支持大语言模型中的深层次、忠实推理。Hydra 通过代理驱动的探索解决了多跳和多实体问题，结合结构化和非结构化检索，增加了证据的多样性和准确性；为了应对多源验证，Hydra 使用三因素跨源验证（来源可信性评估、跨源证实和实体路径对齐），平衡了主题相关性与跨模态一致性的关系；通过利用图形结构，Hydra 融合了异构来源，引导高效的探索，并提前消除噪声。", "conclusion": "全面的实验在七个基准数据集上显示，Hydra 在所有基准上均实现了对GPT-3.5的整体最新成果，优于强大的混合基线ToG-2，平均高出20.3%，最高可达30.1%。此外，Hydra 使较小的模型（如 Llama-3.1-8B）能够达到类似于GPT-4-Turbo的推理性能。源代码可在以下链接获得。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: 用于评估大语言模型结构化知识理解能力的精细颗粒度基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大型语言模型（LLMs）在理解结构化知识（SK）方面取得了显著进展，如知识图谱（KG）和表格，现有的SK的理解评估仍不严格（即缺乏对特定能力的评估），并且主要集中在单一类型的SK上。因此，本文旨在提出一个更为全面和严格的结构化知识理解基准，以诊断LLMs的不足之处。", "innovation": "提出了SKA-Bench，一个结构化知识增强的问答基准，涵盖了四种常用结构化知识形式：知识图谱（KG）、表格（Table）、知识图谱加文本（KG+Text）及表格加文本（Table+Text）。使用三阶段流水线来构建SKA-Bench实例，包括问题、答案、正知识单元和噪声知识单元。扩展实例构建了四个基本能力测试平台：噪声鲁棒性、无序性免疫力、信息整合和负面拒绝。", "conclusion": "通过对8个代表性LLMs进行实验评估，包括先进的DeepSeek-R1模型，表明现有的LLMs在理解结构化知识方面仍面临重大挑战，其性能受到噪声量、知识单元顺序和幻觉现象等因素的影响。我们的数据集和代码可以在以下链接获取：this https URL。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "量化的语义与统计视角下LLM的公平性量化", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）在生成响应时通常包含内在的偏见，这在实际应用中降低了它们的可靠性。现有的评价方法往往忽略了长文本响应中的偏见以及LLM输出的固有变异性。这些偏见可能影响模型在不同人群中的公平性和一致性，但现有的方法难以准确检测和量化这些细微的偏见。", "innovation": "本文提出了一种新的统计框架FiSCo（Fine-grained Semantic Comparison），用于通过检测长文本响应中跨人群组的细微语义差异来评估LLMs的群体公平性。该框架通过将模型输出分解为语义上不同的主张，并利用推理检查评估意义的一致性，突破了表面层次的比较，实现了对细微偏见的稳健检测。本文定义了新的群体反事实公平性，并在不同性别、种族和年龄的人工标注数据集上验证了FiSCo的效果，证明它比各种评价指标更可靠地识别出了细微偏见，同时减少了因LLM的随机变异性产生的影响。", "conclusion": "实验证明，FiSCo能够更可靠地识别细微偏见，同时减少因LLM随机变异性引起的影响，优于不同的评价指标。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14728", "html_url": "https://arxiv.org/abs/2503.14728", "title": "记忆编码中的战略资源分配：一种塑造语言处理的效率原则", "title_en": "Strategic resource allocation in memory encoding: An efficiency principle shaping language processing", "authors": "Weijie Xu,Richard Futrell", "background": "本文探讨了在工作记忆容量有限的情况下，如何高效地支持人类语言行为。文章从资源效率的角度出发，探讨了工作记忆资源如何动态且策略性地分配以优先处理新颖和意外信息，以此解决由工作记忆容量有限和噪声表示带来的计算问题。", "innovation": "文章提出了一个名为'Strategic Resource Allocation (SRA)'的战略资源分配原则，用于在句子处理过程中提高工作记忆资源的使用效率。SRA 原理认为，工作记忆资源优先分配给新颖和意外的信息，这样可以减少记忆检索的错误，并提高记忆中意外信息的表示质量。", "conclusion": "通过自然语料库数据，研究发现在依赖性局部性方面，SRA 对非局部依赖关系（具有较低可预测先驱者）展现出显著影响，导致了局部效应的减弱。然而，研究结果也表明跨语言存在显著差异，表明需要更仔细地研究 SRA 这一作为通用记忆效率原则的机制，如何与特定语言的短语结构相互作用。SRA 强调了表征不确定性在理解记忆编码中的关键作用，并从高效记忆编码的角度重新定义了意外性和熵对处理难度的影响。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning：通过增强知识边界意识实现LLM多组成问题推理", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "大规模语言模型（LLMs）在各种应用中得到广泛应用，但它们存在生成非存在事实幻觉的重要问题。尽管已有研究通过分析内部参数化知识边界来估计置信度来应对这一问题，但这些研究主要针对单一问题设置，尚未探索需要同时回答多个问题的更复杂的多问题设置。", "innovation": "本文提出了一种针对多问题设置的新方法，即Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning)，该方法在指令数据微调过程中将答案预测学习和置信度估计分离。实验表明，与基线方法相比，该方法在平均精度上最高可提高25%。", "conclusion": "研究表明，MAC-Tuning方法在多问题设置中表现出色，能够更准确地回答多个问题，从而有效地提高了模型的可靠性和有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions：使用CoTR提示和大规模语言模型的合成注释的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "低资源语言如马拉地语的情感识别由于标注数据有限而具有挑战性。L3Cube-MahaEmotions是一个高质量的马拉地语情感识别数据集，包含11个细粒度的情感标签。通过大型语言模型（LLMs）合成标注训练数据，人工标注验证和测试集以提供可靠的标准基准。在此基础上，运用链式翻译（CoTR）提示技术，将马拉地语句子翻译成英语并使用单个提示进行情感标注。", "innovation": "使用大型语言模型进行合成标注的方法并结合链式翻译（CoTR）提示技术生成标注数据；探索标签聚合策略；展示了通用的大规模语言模型（如GPT-4和Llama3-405B）比微调的BERT模型更适合复杂的情感识别任务，突显了高质量人工标注数据和情感识别复杂性的关键影响。", "conclusion": "GPT-4的预测优于微调的BERT模型，但基于合成标签训练的BERT模型无法超越GPT-4。这表明高质量的人工标注数据至关重要，同时情感识别任务本身具有复杂性。通用的大规模语言模型如GPT-4和Llama3-405B对于复杂的情感识别任务具有更好的通用性。该数据集和模型已公开共享。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher: 通过细粒度原子思想奖励增强自主深度研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大型语言模型（LLMs）表现出惊人的问题解决能力，但在面对复杂任务时因为内部知识静态而变得乏力。检索增强生成（RAG）方法虽然能够增强对外部信息的访问，但在多跳推理和策略性搜索方面仍受到严格工作流程的限制。最近，代理性的深度研究进展使LLMs能够自主进行推理、搜索和信息合成。然而，当前依赖结果基础强化学习（RL）的方法面临冲突梯度和奖励稀疏等关键问题，这限制了性能提升和训练效率。", "innovation": "本文首先提出了一种称为原子思考的新LLM思考范式（Atomic Thought），它将推理分解为细粒度的功能单元，并通过推理奖励模型（RRMs）提供了原子思考奖励（ATR），以提供细粒度的指导。在此基础上，提出了一种名为Atom-Searcher的新RL框架，将原子思考和ATR集成在一起。Atom-Searcher使用了类似课程的学习奖励时间表，优先考虑过程级别的ATR并逐渐过渡到结果奖励，从而加速了有效推理路径的收敛。实验结果表明，在七个基准测试上表现出持续的改进。", "conclusion": "Atom-Searcher 的优点包括：（1）在测试时可扩展计算。（2）原子思考为RRMs提供监督锚点，跨越从代理深度研究任务到RRMs。（3）Atom-Searcher 展现出更可解释和类人的推理模式。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21452", "html_url": "https://arxiv.org/abs/2508.21452", "title": "从标准化到复杂化：评估大规模语言模型在本科热力学中的能力", "title_en": "From Canonical to Complex: Benchmarking LLM Capabilities in Undergraduate Thermodynamics", "authors": "Anna Geißler,Luca-Sophie Bien,Friedrich Schöppler,Tobias Hertel", "background": "大语言模型（LLMs）在科学教育中越来越被视为辅导工具。然而，它们在本科无监督教学中的使用准备情况仍有不确定性，因为可靠的教学不仅需要流畅的知识回忆，还需要一致的原则导向推理。热力学因其简洁的定律和状态函数与路径函数之间的细微区别、可逆性和熵等因素，提供了一个理想的测试平台来评估这些能力。", "innovation": "提出了UTQA，一个包含50道本科热力学问答基准题，涵盖了理想气体过程、可逆性和图表解释。2025年领先模型的性能均未达到95%的门槛：最佳LLM准确率为82%，纯文本问题的表现优于图像推理任务，后者往往表现为随机水平。提示表达和句法复杂度与性能相关性不大，性能差距集中在有限速率/不可逆场景以及将视觉特征与热力学意义联系起来的能力上，表明当前的LLMs还不适合在这个领域进行无监督辅导。", "conclusion": "当前LLMs在热力学中的有限速率/不可逆场景和视觉特征到热力学意义的绑定方面存在性能差距，表明它们目前还不适合用于这个领域的无监督辅导。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种安全、高效且适应性的大规模语言模型联邦拆分框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私有数据由于其高质量被证明能提升大语言模型（LLM）的效果，但这些数据分散在数据孤岛上，且大语言模型的高计算需求限制了它们在联邦环境中的部署。为了解决这个问题，提出了基于变压器的联邦拆分模型，该模型将大部分模型参数卸载到服务器（或分布式客户端），仅在客户端保留一小部分以确保数据隐私。然而，这种方法仍然面临三大挑战：1) 同步密钥加密难以有效保护传输的向量；2) 大语言模型的自回归特性意味着联邦拆分学习只能顺序地进行训练和推理，导致高通信开销；3) 固定的拆分点缺乏对下游任务的适应性。", "innovation": "本文提出了FedSEA-LLaMA，这是一种基于LLaMA2的安全、高效且适应性的联邦拆分框架。首先，通过在前向传递隐藏状态中注入高斯噪声以实现端到端的安全向量传输；其次，采用注意力掩码压缩和KV缓存协作以降低通信成本，加快训练和推理；最后，允许用户基于特定任务需求动态调整输入/输出块的拆分点。实验结果表明，FedSEA-LLaMA在自然语言理解、摘要和对话问答任务中的性能与中心化LLaMA2相当，并且在训练和推理时分别实现了高达8倍的性能提升。进一步分析还表明，FedSEA-LLaMA在安全性和适应性方面具有有效性。", "conclusion": "实验结果显示，FedSEA-LLaMA在保持与中心化LLaMA2相似性能的情况下，在训练和推理阶段分别实现了8倍的性能提升。此外，对于隐私攻击和不同的拆分点的进一步分析也证明了FedSEA-LLaMA在安全性和适应性方面的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17973", "html_url": "https://arxiv.org/abs/2508.17973", "title": "German4All — 一个用于德语可读性控制重述的语料库和模型", "title_en": "German4All -- A Dataset and Model for Readability-Controlled Paraphrasing in German", "authors": "Miriam Anschütz,Thanh Mai Pham,Eslam Nasrallah,Maximilian Müller,Cristian-George Craciun,Georg Groh", "background": "跨不同复杂度水平的文本重述能力对于创建可访问的文本、针对不同读者群体进行定制至关重要。因此，我们介绍了German4All，这是第一个大规模的德语数据集，包含对齐且可读性控制的段落级重述。它跨越了五个可读性级别，包含超过25,000个样本。该数据集通过GPT-4自动合成，并通过人类和基于LLM的判断进行了严格的评估。German4All用于训练一个开源的、可读性控制的重述模型，该模型在德语文本简化方面达到了最先进的技术水平，从而实现更微妙和针对读者的调整。", "innovation": "German4All是第一个大型德语数据集，包含了可读性控制的段落级重述样本，这些样本覆盖了五个可读性级别，总数超过25,000个样本。通过GPT-4自动合成，该数据集被严苛地通过人力和基于LLM的评估。该研究训练了一个开源的、可读性控制的重述模型，该模型在德语文本简化方面表现达到了最先进的技术水平，并且该模型和数据集均向公众开放，以促进多级别重述的研究。", "conclusion": "使用German4All数据集训练的重述模型在德语文本简化方面取得了最好的效果，可以实现更复杂的读者特定调整。开发的German4All数据集和模型的公开将鼓励进一步的研究以实现多级别的重述。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19758", "html_url": "https://arxiv.org/abs/2508.19758", "title": "通过多样新闻检索实现更全面的事件理解：揭开更大图景", "title_en": "Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval", "authors": "Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung", "background": "获取多元视角对理解现实事件至关重要，但大多数新闻检索系统侧重于文本相关性，导致结果重复且限制了不同观点的曝光。第一阶段使用密集检索获取主题相关的内容，第二阶段通过句级聚类和多样性感知重新排序来展示互补的信息，从而提升了事件报道的全面性。为了评估检索多样性，引入了三种可解释的指标：平均成对距离、正面簇覆盖率和信息密度比，并建立了两个段落级基准：LocalNews 和 DSGlobal。实验结果显示 NEWSCOPE 优于强大基础模型，提高了多样性而不牺牲相关性，证明了精细节度和可解释模型在减轻冗余和促进全面事件理解方面的有效性。", "innovation": "提出了一种两阶段框架 NEWSCOPE，增强事件覆盖，通过在句级别建模语义差异。第一阶段利用密集检索获取主题相关的内容，第二阶段通过句级聚类和多样性感知重新排序来展示互补信息。引入了平均成对距离、正面簇覆盖率和信息密度比作为可解释的指标，构造了 LocalNews 和 DSGlobal 两个段落级基准。实验结果证实了 NEWSCOPE 在提高多样性的同时不牺牲相关性的优越性。", "conclusion": "精细粒度、可解释的建模在减轻冗余和促进全面事件理解方面非常有效，NEWSCOPE 在多样性方面优于最强基准模型，且未牺牲相关性，结果数据和代码已公开。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "通过期望最大化实现可解释的Kanji学习联想词生成", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "罗马字母背景的学习者学习日语词汇是一个挑战，因为日语的书写系统与他们的背景不同。日语结合使用hiragana等音节文字和源自中文的象形文字kanji，而kanji因为其复杂性和数量众多而变得复杂。关键字联想记忆是一种常见的帮助记忆的技术，通常使用kanji的构成结构来建立生动的相关联想。尽管近期有使用大型语言模型（LLMs）来辅助学习者的方法，但现有基于LLM的联想词生成方法多呈黑盒子状态，缺乏可解释性。本研究旨在提出一种生成框架，该框架明确地将联想词构建过程建模为受一系列常规规则驱动，并通过一种新型的期望最大化算法学习这些规则。该方法基于在线平台上学习者创建的联想词进行训练，从而学会潜在的结构和构成规则，实现可解释和系统的联想词生成。实验表明，在新学习者的新开始场景下，该方法表现优异，并提供了有效的联想词创建机制的见解。", "innovation": "该研究提出了一种生成框架，该框架明确地将联想词构建过程建模为受一系列常规规则驱动，并通过一种新型的期望最大化算法学习这些规则。该方法能够生成既可解释又系统化的联想词，同时保留了对新学习者的可操作性。与现有的黑盒方法不同，这种新方法提供了对于学习者如何创建有效联想词机制的深入理解。", "conclusion": "该方法在新学习者的新情境下表现良好，并提供了有效的联想词创建机制的见解，既可以解释又要系统化生成联想词，对于日语学习者特别是Kanji学习者具有重要意义。通过提高可解释性，这种方法有助于理解学习记忆过程，对日语教学有积极的影响。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19997", "html_url": "https://arxiv.org/abs/2508.19997", "title": "探索针对长尾法律文本分类的选择性检索增强", "title_en": "Exploring Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "authors": "Boheng Mao", "background": "法律文本分类是自然语言处理领域中的基础任务。基准数据集通常表现出长尾标签分布，即许多标签被严重低估，导致对罕见类别的模型性能较差。", "innovation": "该论文探索了选择性检索增强（SRA）作为解决此问题的概念证明方法。SRA 方法专注于训练集中低频标签的样本增强，避免向表现良好的类别引入噪声，并且不需要更改模型架构。检索仅在训练数据中进行，以确保没有潜在的信息泄露，同时省去了对外部语料库的需求。", "conclusion": "SRA 在两个具有长尾分布的法律文本分类基准数据集（LEDGAR 单标签和 UNFAIR-ToS 多标签）上进行了测试，结果显示 SRA 在微分 F1 和宏 F1 方面都优于 LexGLUE 基线。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17202", "html_url": "https://arxiv.org/abs/2508.17202", "title": "在100美元预算下主动获取领域知识：通过高效、包含专家参与的互动提升敏感领域的大语言模型", "title_en": "Active Domain Knowledge Acquisition with 100-Dollar Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains", "authors": "Yang Wu,Raha Moraffah,Rujing Yao,Jinhong Yu,Zhimin Tao,Xiaozhong Liu", "background": "大语言模型（LLMs）展现出了广泛的知识能力，但在药物发现和罕见疾病研究等高度专业化且成本敏感的领域中，它们常常由于缺乏专家知识而表现不佳。为了解决这一问题，本研究提出了一种名为PU-ADKA的新颖框架，旨在在预算限制内高效提升领域特定的大语言模型，通过积极地邀请领域专家参与进来。", "innovation": "PU-ADKA框架通过模拟PubMed数据训练，并通过受控专家互动和真实药物研发团队的实际部署来验证其有效性。该框架具有以下创新点：[1] 特异性识别并查询最合适的专家；[2] 考虑专家的时间可用性、知识边界以及咨询成本；[3] 提出了新的基准数据集CKAD，用于在预算有限条件下获取大语言模型的领域知识，促进了该研究领域的进一步探讨。", "conclusion": "该研究证明了PU-ADKA框架在严格预算约束条件下提升大语言模型在专业化领域中的性能的有效性。通过引入CKAD数据集，研究还促进了在这一挑战性领域的进一步研究。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "信任但求证！测试时缩放验证设计综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "测试时缩放（TTS）作为一种新的方法，用于提升大型语言模型（LLM）推理过程和任务表现。TTS 在推断过程中利用更多计算资源，通过解码过程中的验证器生成推理痕迹或探索庞大的解码搜索空间。验证器作为奖励模型，帮助评估解码过程中的候选输出，从而细致地探索庞大的解空间并选择最优结果。虽然验证器在提升 TTS 性能方面表现出色，但缺乏系统性的分类和讨论。本文综述了现有文献中的各种验证方法及其训练机制，提供了一个统一的视角，旨在促进 TTS 领域的研究和发展。", "innovation": "本文对 TTS 验证方法进行了系统综述，统一了验证器的训练、类型和应用。填补了当前研究中缺乏详细分类和讨论的空白，有助于进一步推动 TTS 领域的发展。", "conclusion": "本文首先概述了 TTS 的背景及其验证方法的发展，展示了验证器在 TTS 中的关键作用。然后，详细介绍了不同类型的验证器及其训练机制。最后，总结了当前 TTS 验证领域的研究现状，并展望了未来的研究方向。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20410", "html_url": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench: AI文本生成应用工具的用户界面基准评估", "title_en": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": "Sam Jung,Agustin Garcinuno,Spencer Mateega", "background": "现有的AI文本至应用工具承诺在几分钟内生成高质量的应用程序和网站，但缺乏严格的公开基准来验证这些声明。因此，需要一个大规模的基准测试来评估这些工具在生成用户界面方面的表现。", "innovation": "UI-Bench 是第一个通过专家二元比较来评估各种AI文本至应用工具视觉卓越程度的大规模基准测试。它涵盖了10种工具、30个提示、300个生成的网站以及超过4000次专家判断，使用TrueSkill模型来排名系统并提供校准后的置信区间。", "conclusion": "UI-Bench 为推动AI驱动的网页设计标准化提供了可重复的标准。该基准测试公开提供了（i）完整的提示集，（ii）开源评估框架，以及（iii）公共排行榜。生成的网站评分将在不久后公开，可访问UI-Bench排行榜查看更多详情。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将可穿戴设备数据转换为个性化健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴设备跟踪器中提取个性化见解需要复杂的数字推理，这超出了标准大规模语言模型（LLMs）的能力范围，因此需要基于工具的方法，如代码生成。大规模语言模型代理在这一大型分析领域具有前景，但尚未广泛应用。为了验证其能力，作者创建并分享了两个包含超过4000个健康见解问题的基准数据集。", "innovation": "作者引入了个人健康洞察代理（PHIA），这是一种系统，通过多步推理、代码生成和信息检索来分析和解释行为健康数据。与现有的强大代码生成基线相比，PHIA 在客观数值问题上的准确率为84%，对于开放式问题，获得了83%的好评率，并且更有可能达到最高质量评分。", "conclusion": "这项工作可以通过赋予个人理解其数据的能力，推动行为性健康的提升，开启更加面向大众、个性化和数据驱动的健康管理新时代。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝标记：大型语言模型中简单校准拒绝的一种子方法", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "构建安全可靠的语言模型关键在于让模型根据不同指令或问题做出合适的拒绝回答。这包括对不同用户查询类型（如定义不明确的问题、违法指令或超出了模型知识范围的信息请求）的拒绝。目前主要通过训练具有不同拒绝比例的多个模型来实现这一目标，这种方法成本高且需为每个用户单独训练模型以适应其不同的拒绝偏好。", "innovation": "本文提出了一种新的方法，即拒绝标记（Refusal Tokens），通过在训练过程将一种或多种拒绝标记添加到模型的响应中，在推理阶段调整每个拒绝标记的生成概率，从而控制模型的拒绝行为。这种方法无需进一步微调单一模型即可实现精准的拒绝率控制，并且只有在生成阶段进行选择性干预。", "conclusion": "拒绝标记提供了一种无需额外微调即可控制单一模型拒绝率的新方法，通过在生成阶段的有针对性的干预即可灵活调整模型的拒绝行为。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19828", "html_url": "https://arxiv.org/abs/2508.19828", "title": "Memory-R1：通过强化学习增强大型语言模型代理以管理和利用记忆", "title_en": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning", "authors": "Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma", "background": "大型语言模型（LLMs）在广泛的语言处理任务中展现了出色的性能，但它们本质上是无状态的，受限于有限的上下文窗口，这限制了它们进行长时推理的能力。尽管最近有一些努力通过外部记忆库来解决这一局限，但大多数现有的管道是静态和启发式的，缺乏任何学习机制来决定存储、更新或检索哪些内容。现有方法的不足在于没有学习机制引导记忆管理，导致这些方法在灵活性和实用性上存在缺陷。", "innovation": "Memory-R1 提出了一种通过强化学习（RL）框架，使大型语言模型能够主动管理和利用外部记忆。该框架包括一个记忆管理器（负责执行结构化记忆操作，如添加、更新、删除或不执行操作）和一个答案生成器（选择最相关的记忆条目并进行推理以生成答案）。两个代理都通过结果导向的强化学习（PPO和GRPO）进行微调，从而实现具有最少监督的效果性记忆管理。Memory-R1 仅需 152 个问题-答案对即可训练，并且其表现超过了最强的现有基线，展示了在多种问题类型和基础模型下的强泛化能力。这一创新工作不仅提出了有成效的方法，还提供了如何通过强化学习解锁更大代理性的、记忆感知行为的见解和指向更丰富、更持久推理系统的方向", "conclusion": "Memory-R1 展现了强大的性能和泛化能力，将通过强化学习提供的代理记忆管理机制成功地应用于大型语言模型。这标志着强化学习在增强大型语言模型行为中的重要性，并促进了更复杂、更持久推理系统的发展。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE：LLM任务特定指令调优的奖励导向式数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "大型语言模型（LLMs）通过指令调优展示了在各个领域产生更可控和有效的输出的巨大潜力。传统的数据选择方法主要依赖于手工构造的相似度度量来选择与测试数据分布相匹配的训练数据。目标是减少指令调优损失，提高目标任务上的性能。然而，观察到LLMs中的指令调优损失（即下一个标记预测的交叉熵损失）与实际任务性能之间往往不存在单调关系，这导致当前的任务特定指令调优数据选择方法有效性降低。", "innovation": "本文提出了ROSE，一种采用奖励导向的指令数据选择方法，利用成对偏好损失作为奖励信号来优化任务特定指令调优的数据选择。ROSE通过一种影响公式来近似训练数据点相对于少量样本偏好验证集的影响，从而选择与任务最相关的训练数据点。实验结果显示，使用ROSE选择仅仅5%的训练数据，达到了与使用整个训练数据集微调相当的效果，并且优于其他领先的任务特定指令调优数据选择方法。进一步的定性分析表明，该方法在多个基准数据集和多种模型架构上具有稳健的泛化能力。", "conclusion": "通过ROSE选择仅5%的训练数据，本文的方法在任务特定指令调优上取得了与全训练数据微调相当甚至更好的效果，并且跨多个数据集和模型具有稳健性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "Roll the dice & look before you leap: 超越下一个词预测的创造性极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "论文设计了一系列简洁的算法任务，作为现实世界开放任务的宽松抽象，旨在清晰可控制地量化当今语言模型的创造性限制。这些任务要求进行隐含的开放性随机规划步骤，类似于现实世界中的创造性、前瞻性的思考跳跃，要求模型在抽象知识图谱中发现新的连接（如词语游戏、类比研究）或构建新的模式（如设计数学问题或新型蛋白质）。研究表明，单一词预测（myopic）方法在连续多个词预测上表现较差，而无师训练和扩散模型等方法在产生多样性和原创性上的表现更优。同时，为了在保持连贯性的前提下引入随机性，输入层增加噪声（被称为随机种子调节）的效果与输出层的温度采样相当，甚至在某些情况下更优。这些方法为研究开放型创造性技能提供了一个原理上的最小测试平台，并提出了超越单一词预测和温度采样的新论点。部分代码已经开源。", "innovation": "论文设计了一组简洁的算法任务，并通过这些任务分析了语言模型的创造性限制，包括多词预测方法和输入层噪声处理（无师训练和扩散模型）相比单词预测方法的优越性。方法创新在于通过明确和可控的实验设计，揭示了语言模型在产生多样性和原创性方面的潜在能力，并为未来的研究提供了新的思路。", "conclusion": "论文提出了一种系统的、最小化的测试平台，可以用来分析语言模型的开放性创造性技能，并强调沿着多词预测方向和输入噪声处理进行研究的重要性，从而提出了超越当前单一词预测模型的必要性。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不懂谎言：从合作自玩游戏中学到自己知道什么", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "AI代理想要成为有用的助手，必须意识到自己的能力和局限性，包括知道何时使用参数知识、何时信任工具输出、何时不回答或打折扣回答。这些能力很难通过监督微调教授，因为需要构建反映代理人特定能力的示例。因此，本文提出了一种全新的方法来教导代理人他们所知道的知识：合作自玩游戏。", "innovation": "本文提出了一种新的方法——合作自玩游戏，通过这种方式，多智能体协作，在集体正确的答案奖励下，从互动结构中构建起所需的元知识。这种方法适用于具有异质工具（针对特定语料库检索）的小型智能体社会，需要智能体相互协作以最大化成功同时最小化努力。", "conclusion": "多智能体群体奖励可以促使策略在个体智能体孤立部署的情境下转移以改善工具使用和选择性预测。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: Web页面中的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "现有的多模态大型语言模型通过根据网页截图生成动作来与网页环境交互。本文探讨了一种提示注入攻击（WebInject），攻击者通过在渲染网页的原始像素值中添加扰动，使网页代理执行攻击者指定的动作。", "innovation": "本文提出了一种关键创新方法，通过训练神经网络来近似原始像素值与截屏之间的非可微映射，并采用投影梯度下降算法解决重新定义的优化问题。", "conclusion": "通过对多个数据集进行广泛评估，证明了WebInject的有效性，并且相较于基线模型，效果显著提高。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20417", "html_url": "https://arxiv.org/abs/2508.20417", "title": "KG-CQR：利用知识图谱中的结构关系表示进行上下文查询检索", "title_en": "KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval", "authors": "Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Jason J.Jung,Khac-Hoai Nam Bui", "background": "知识图谱（KGs）与大规模语言模型（LLMs）的整合在提升检索增强生成（RAG）系统的检索阶段方面具有显著潜力。现有方法主要关注解决语境级别的内容损失，而KG-CQR框架则专注于通过使用结构化关系表示来增强查询，提取和完成相关的KG子图以生成具有丰富语义的查询上下文。该框架通过子图提取、补充和上下文生成模块操作，作为模型无关的流水线系统，确保在不同规模的LLM上具有可扩展性而不需额外训练。实验结果表明，KG-CQR在RAGBench和MultiHop-RAG数据集上表现出优越的性能，相比于基线模型在mAP和Recall@25上分别提高了4-6%和2-3%，特别是在多跳问答等具有挑战性的RAG任务中，引入KG-CQR始终优于现有基线方法在检索效果方面的表现.", "innovation": "提出了KG-CQR框架，通过利用结构化关系表示，增强查询的语境表示，提取和完成相关的KG子图以生成具有丰富语义的查询上下文。该框架不依赖于特定的模型，具有跨不同规模的LLM的可扩展性。实验结果表明，该框架在多个RAG基准数据集和任务中表现出色，尤其是在多跳问答等挑战性任务中，其检索效果优于现有基线方法.", "conclusion": "KG-CQR框架在多个RAG基准数据集和任务中均表现出卓越的性能，特别是在多跳问答等具有挑战性的RAG任务中，其检索效果显著优于现有基线方法。该框架通过利用知识图谱中的结构化关系表示，增强了查询的上下文表示，有效提升了检索增强生成系统的整体效果。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "任何视频中的相机运动理解", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "介绍了CameraBench，这是一个大规模的数据集和基准，用于评估和提升对相机运动理解。CameraBench由约3000个多样化的互联网视频组成，这些视频经过专家的严格多阶段质量控制过程进行注释。该研究还提出了一种相机运动基本要素的分类法，与电影摄影师合作设计。研究发现，例如“跟随”（或跟踪）等某些运动需要理解场景内容，如移动的主体。研究通过大规模的人类研究量化了人类注释的表现，揭示了专业领域知识和基于教程的培训可以显著提高准确性。SfM模型难以捕捉依赖于场景内容的语义基本要素，而VLMs则难以捕捉需要精确轨道估计的几何基本要素。", "innovation": "贡献了一种相机运动基本要素的分类法，并通过CameraBench评估了SfM和VLM的表现。提出了一种生成式VLM的微调方法，以实现语义和几何基本要素的理解能力，展示了运动增强标注、视频问答和视频文本检索的应用场景。", "conclusion": "希望CameraBench、基准测试和教程能够推动未来朝着理解任何视频中相机运动的目标努力。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen：正式验证数据引擎，用于可信的多模态几何问题解决", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题解决（GPS）要求逻辑一致性可验证和多模态推理能力。尽管大型语言模型（LLMs）在GPS方面取得了快速进展，但其发展受到缺乏可靠基准和系统性方法的阻碍。尤其困于LLMs固有的幻觉问题，导致生成的数据集常常带有噪声、未验证和自相矛盾的特性。因此，需要一种新的方式来验证和生成准确的几何问题数据集以形成基准。", "innovation": "本文介绍了TrustGeoGen数据引擎，该引擎通过以下四个创新实现：1）多模态对齐，同步生成图形、文本和逐步解决方案；2）形式验证，确保所有推理路径符合规定；3）关系思考，将形式推理与类人逻辑步骤相联系；4）GeoExplore系列算法，生成具有多种解决方案和自我回溯能力的多样化问题变体。该引擎创建了具有跨模态一致性的GeoTrust-200K数据集和相应的GeoTrust-test基准，实验结果表明最先进的模型在GeoTrust-test上的准确率仅为45.83%，证明了其挑战性。", "conclusion": "通过使用TrustGeoGen引擎所创建的合成数据集，模型在GPS任务上的性能得到了显著提升，并且具备在域外（OOD）基准上的强大泛化能力。该论文的代码和数据可在指定的URL中获取。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 增强偏差和非对称缩放的旋转量化方法以提高大型语言模型性能", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转在大型语言模型（LLMs）的先进量化流水线中变得至关重要，通过有效平滑权重和激活值中的异常值。然而，进一步优化旋转参数只能带来有限的性能提升，同时引入了显著的训练开销，因为旋转参数共享要求加载整个模型进行反向传播，进而导致大量内存消耗且实际应用中实用性受限。", "innovation": "我们发现当前旋转量化方法存在两个基本限制：（i）旋转未能对齐通道均值，导致更宽的量化范围和更多的舍入误差；（ii）旋转使激活分布更加高斯化，增加了由于剪裁错误导致的能量损失。为此，我们提出了BASE-Q，这是一种简单而强大的方法，结合了偏差修正和非对称缩放，以有效减少舍入和剪裁误差。此外，BASE-Q 还支持块状优化，消除了对内存密集型全模型反向传播的需求。", "conclusion": "广泛的实验显示，BASE-Q 在各种 LLMs 和基准测试中的效果显著，分别将 QuaRot、SpinQuant、OSTQuant 的精度缺口缩小了 50.5%、42.9% 和 29.2%。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17052", "html_url": "https://arxiv.org/abs/2504.17052", "title": "测试信仰：测量LLM政治稳定性的论辩框架", "title_en": "Testing Conviction: An Argumentative Framework for Measuring LLM Political Stability", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大型语言模型（LLMs）在政治话语中越来越重要，但它们在面对挑战时表现出不一致的反应。现有研究基于单次提示响应将LLMs分类为左翼或右翼，但这些问题的分类是否反映了稳定的意识形态，还是仅仅表面模仿？现有方法无法区分真正的意识形态认同和表象生成文本。本文背景即是在这种情况下探讨现有的研究局限性和提出新的评估框架的需求。", "innovation": "本文提出的创新点包括：1) 提出了一种评估意识形态深度的框架，包含论辩一致性（argumentative consistency）和不确定性量化（uncertainty quantification）两个方面；2) 通过将12个LLM模型在《政治极坐标测试》的19项经济政策上进行测试，区分稳定的和表象的意识形态定位；3) 结果表明95%的左翼模型和89%的右翼模型在不同实验条件下表现出与分类一致的行为，且语义熵强烈支持这些分类（AUROC=0.78），揭示了不确定性与意识形态一致性之间的关系；4) 研究发现意识形态稳定性是话题相关的，挑战了LLM单一意识形态的概念，并提供了区别真正认同和表象行为的稳健方式。", "conclusion": "研究结果表明，意识形态稳定性因话题而异，并挑战了LLM单一意识形态的观点，提出了区分真实认同与表象行为的稳健方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21091", "html_url": "https://arxiv.org/abs/2508.21091", "title": "ERTACache：高效扩散模型中的误差校正和时间步调整", "title_en": "ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion", "authors": "Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin", "background": "扩散模型由于其迭代的推理过程存在显著的计算开销。虽然特征缓存可以重新利用中间输出以加速推理过程，但简单的重用策略会带来质量下降。为了解决这个问题，本文正式分析了缓存引入的累积误差，并将其分解为两种主要成分：特征偏移误差（由于缓存输出的不准确性引起）和步骤放大误差（在固定时间步长安排下由错误传播引起）。", "innovation": "本文提出了ERTACache，这是一个具备底层纠错框架的缓存方法。它通过一个离线残差分析阶段来识别可重用的步骤，动态调整轨迹感知校正系数，并通过闭式残差线性化模型分析缓存引起的错误。这些成分共同使得在激进的缓存重用下仍能实现准确且高效的采样。", "conclusion": "广泛的实验表明，ERTACache在标准的图像和视频生成基准上实现了2倍的推理加速，同时保证或甚至提高了视觉质量。特别是，在最先进的Wan2.1视频扩散模型上，本文方法实现了2倍加速，而VBench值受损最小，在保持基线保真度的同时显著提高了效率。代码已公开可用。"}
{"llm_update_time": "20250902", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME：利用语义股票表示和时空动态增强主题投资", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资旨在构建与结构性趋势相一致的投资组合，但由于行业边界重叠和市场动态不断变化，这一领域仍颇具挑战性。现有通用语言模型虽然强大，但并不适合捕捉金融资产的细微特征，原因在于金融资产的语义表示可能与一般的金融文本基本不同。为此，该研究提出了一种名为THEME的框架，通过层级对比学习微调嵌入向量，基于这些向量，THEME既能基于主题和其组成部分之间的层级关系对主题进行匹配，又能进一步通过股票回报的引入调整嵌入向量。", "innovation": "THEME框架通过层级对比学习微调嵌入向量，能够有效捕捉金融资产的细微特征，特别适用于主题投资。它不仅在主题资产检索任务中显著优于现有大型语言模型，而且构建的投资组合表现出色。该框架通过文本中的主题关系与回报中的市场动态进行联合建模，生成适用于广泛投资应用的股票嵌入。", "conclusion": "实证结果表明，THEME在两个关键领域表现优异：它在主题资产检索任务中的表现显著优于现有领先模型；其构建的投资组合也表现出令人信服的性能。通过同时建模文本中的主题关系和回报中的市场动态，THEME为广泛的实际投资应用生成了专门定制的股票嵌入。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control: 一种减轻文本到图像生成模型中不安全内容的安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像（T2I）生成模型方面取得了进展，但这些模型滥用的可能性引发了严重的安全性担忧。模型开发者已经采取了大量措施来引入能够应对这些担忧的安全机制。然而，现有的安全机制，无论是外部的还是内部的，要么在分布变化的情况下仍然容易被规避，要么需要对模型进行大量的特定调整。", "innovation": "为了克服这些限制，我们引入了Safe-Control，这是一种创新的即插即用的安全补丁，旨在减轻T2I模型中的不安全内容生成。Safe-Control 利用数据驱动的策略和安全性意识条件，将安全控制信号注入到锁定的T2I模型中，如同补丁一样进行更新。开发者还可以构建各种各样的安全补丁，以满足不断变化的安全要求，并将其灵活合并为一个统一的补丁。Safe-Control 的即插即用设计进一步确保了其适应性，使其能够与其他具有相似去噪架构的T2I模型兼容。", "conclusion": "我们在六个不同的和公开的T2I模型上进行了广泛的评估。实验证明，Safe-Control 在六个具有相似生成架构的T2I模型中有效地减少了不安全内容的生成，同时仍能保持良性图像的质量和文本对齐。与七个最先进的安全机制（包括外部和内部防护）相比，Safe-Control 显著地优于所有基线方法，在减少不安全内容生成方面表现更佳。例如，在不安全提示和最新的对抗性攻击下，Safe-Control 将不安全内容生成的概率降低到7%，而大多数基线方法的概率在20%左右。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21090", "html_url": "https://arxiv.org/abs/2508.21090", "title": "Q-Align：利用Query-Query对齐缓解零样本外观转移中的注意力泄漏", "title_en": "Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment", "authors": "Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu", "background": "在使用大规模图像生成模型进行零样本外观转移时，由于Query-Key对齐会捕捉到两幅图像之间的语义映射，这引发了注意力泄漏的问题。这个问题导致在零样本外观转移过程中语义对齐效果不理想，从而影响了外观真实度和结构保存性能。", "innovation": "提出了一种名为Q-Align的方法，通过Query-Query对齐、键值重排和注意力优化改进了零样本外观转移的语义对齐。具体包括：(1) 利用Query-Query对齐技术，实现两幅图像之间复杂的空间语义映射；(2) 通过键值重排增强特征对应关系；(3) 使用重新排列的键值保持语义一致性并优化注意力。Q-Align在实验中验证了其有效性，同时在外观真实度上超越了当前最先进的方法，且保持了结构保存的竞争力。", "conclusion": "Q-Align通过Query-Query对齐技术解决了零样本外观转移中的注意力泄漏问题，显著提升了语义对齐效果和外观转移质量，为该领域提供了新的解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21080", "html_url": "https://arxiv.org/abs/2508.21080", "title": "2COOOL: 第二届自主驾驶中超出标签范畴的危险挑战研讨会", "title_en": "2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving", "authors": "Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult", "background": "随着计算机视觉领域的进步，自主驾驶算法的发展虽然取得了显著的成果，但在将基于视觉的洞察与传感器数据相结合以提高感知、决策、规划、预测、模拟和控制等方面仍有很大的提升空间。迄今为止，为何我们还没有完全安全的自动驾驶汽车呢？其中一个重要原因是处理新颖场景问题仍然是实现广泛应用的一大障碍。我们希望通过2COOOL研讨会提供一个专门的论坛，促进研究人员和行业专家在处理新颖场景方面的最新进展，包括超出分布外的危险检测、视觉-语言模型对于危险理解的新基准和方法学，以及安全的自主驾驶实践等方面的合作。", "innovation": "本届研讨会将围绕自主驾驶中超出标签范畴的危险挑战展开，聚焦新颖场景处理的算法和方法，包括异常检测、开放集识别、开放词汇建模、领域适应等相关领域的创新。通过学术界和工业界的合作，促进新的算法和系统的发展，以避免潜在的危险，提高自动驾驶的安全性。该研讨会继第一届在2025年冬季应用计算机视觉研讨会（WACV）的成功举办后，在国际计算机视觉大会（ICCV）2025年在夏威夷檀香山召开。", "conclusion": "2COOOL研讨会旨在通过汇集来自学术界和工业界的专家共同讨论最新的研究进展，推动解决自主驾驶车辆中新型安全挑战的算法和方法，以促进更加安全的自动驾驶技术的应用和发展。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21096", "html_url": "https://arxiv.org/abs/2508.21096", "title": "ROBUST-MIPS: 一种结合骨骼姿态和实例分割的内窥镜手术器械数据集", "title_en": "ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments", "authors": "Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren", "background": "手术工具的定位是计算机辅助介入技术的基础组件。现有工作通常专注于训练深度学习模型来执行分割任务。基于学习的方法的性能受限于多样化标注数据的可用性。我们提出，骨骼姿态标注是一种更高效的标注方法，能兼顾丰富的语义信息和易于标注，从而加速标注数据的增长。", "innovation": "我们提出了ROBUST-MIPS数据集，这是一个结合了工具姿态和工具实例分割的内窥镜手术器械数据集，基于现有的ROBUST-MIS数据集。该数据集促进了这两个标注方法的研究联合，并允许在各种下游任务上进行头对头比较。我们还提供了一个简单的基准测试使用流行的姿态估计方法，并展示了高精度的结果，以及发布了基准模型和定制工具姿态标注软件，以简化采用过程。", "conclusion": "我们证明了姿态标注对于手术工具定位的充分性，并通过释放数据集、基准模型和定制软件来促进这一注释风格的采用。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "使用全景X射线图像分类牙科疾病的高级深度学习技术", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本文研究了深度学习方法在全景X射线图像中自动分类牙科状况的应用。研究使用了一个包含1,512张放射照片和11,137个专家验证标注的资料集，其中包含四种状况：充填、龋齿、种植体和阻生牙。通过预处理和类平衡后，评估了三种方法：自定义卷积神经网络（CNN）、将CNN特征提取与传统分类器结合的混合模型，以及微调预训练架构。实验采用5折交叉验证，并以准确率、精确率、召回率和F1分数作为评估指标。结果显示，混合CNN随机森林模型在85.4%的准确率上表现出最佳性能，超过了自定义CNN基准模型74.3%的准确率。在预训练模型中，VGG16模型的准确率为82.3%，其次是Xception和ResNet50。研究表明，混合模型能提高对形态学相似的状况的区分能力，并提供高效可靠的性能。这些发现表明，结合基于CNN的特征提取与集成分类器的方法为自动牙科诊断支持提供了一条实用的途径，同时也强调了需要更大的数据集和进一步的临床验证的必要性。", "innovation": "本文创新点在于使用多层次和多方法的深度学习技术来提升牙科状况识别的准确性，特别是通过混合CNN与随机森林，达到了优异的识别效果，并且这种方法对于形态学相似的状况有更好的区分能力。同时，本文还在多个基准模型中进行了对比实验，展示了不同预训练模型的效果差异。", "conclusion": "本文的研究表明，结合基于CNN的特征提取与集成分类器的方法是实现自动牙科诊断支持有效路径，具有实用价值。未来还需要进一步使用更大规模的数据集进行训练，并进行临床验证，以确保模型的可靠性和安全性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "HiddenObject：模态无关融合在多模态隐匿对象检测中的应用", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中检测隐藏或部分隐蔽的物体仍然是一个基本挑战，因素如遮挡、掩藏和光照变化显著妨碍了检测性能。传统的基于RGB的检测方法在这些不利条件下往往失败，因此迫切需要更具鲁棒性的、跨模态的方法。本文讨论的背景是在这种场景下的改进的需求。", "innovation": "本文提出了一个融合框架HiddenObject，该框架整合了基于Mamba的RGB、热成像和深度数据。这种方法捕捉到不同时域的互补信号，能够在遮挡或伪装目标的检测中发挥更强大的检测效果。此外，该方法可以识别特定模态的特征，并将其在统一表示中融合，提高了在复杂情境中的泛化能力。", "conclusion": "通过在多个基准数据集上的验证，HiddenObject显示出优于现有方法或达到顶尖水平的检测性能。这突显了我们的融合设计的有效性，并揭示了现有单一模态和原始融合策略的关键局限性。更广泛地说，研究结果表明基于Mamba的融合架构在多模态物体检测中具有显著的提高潜力，尤其是在视觉降级或复杂条件下。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21102", "html_url": "https://arxiv.org/abs/2508.21102", "title": "GENNAV：通用可引用导航区域的多边形掩码生成", "title_en": "GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions", "authors": "Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura", "background": "这项任务要求从自然语言指令和移动物体前方摄像头拍摄的图像中识别目标区域的位置，对于具有模糊边界的事物类型目标区域，这既需要存在预测也需要分割，现有方法在处理此类目标区域时表现不佳，尤其是当存在缺席或多重目标时。", "innovation": "本文提出了GENNAV，它能够预测目标是否存在并生成多个事物类型目标区域的分割掩码。为此，作者构建了一个名为GRiN-Drive的新基准，包含三种不同类型的样本：无目标、单目标和多目标。GENNAV在标准评估指标上优于基线方法，并且通过在五个地理不同的城市区域内装有四辆汽车的实际实验中也证明了其跨环境的鲁棒性和零样本转移性能。", "conclusion": "GENNAV在处理模糊边界的事物类型目标区域以及多目标和零样本转移方面表现优异，在现实世界的实验中表现优于基线方法，证明了其在不同环境中的稳健性。项目页面可访问此链接。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21197", "html_url": "https://arxiv.org/abs/2508.21197", "title": "GCAV：用于跨层解释一致性的全局概念激活向量框架", "title_en": "GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability", "authors": "Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang", "background": "概念激活向量（CAVs）提供了一种强大的方法，通过量化深层神经网络对人类定义的概念的敏感性来进行解释。然而，当在不同层独立计算时，CAVs常常表现出不一致性，使得跨层比较不可靠。", "innovation": "提出了一种新颖的框架——全局概念激活向量（GCAV），该框架将CAVs统一为单一的、语义上一致的表示形式。该方法利用对比学习对齐跨层的概念表示，并采用基于注意力的融合机制构建全局综合CAVs。这种方法显著减少了TCAV分数的方差，同时保持概念的相关性，确保更稳定和可靠的概念归因。", "conclusion": "通过对多种深度神经网络进行广泛的实验，我们的方法有效地缓解了跨层的概念不一致，增强了概念定位，并提高了对抗性扰动的鲁棒性。通过将跨层信息整合到一个连贯的框架中，我们的方法提供了更全面和可解释的深度学习模型如何编码人类定义的概念的理解。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过视觉上下文提示实现可迁移的物体重识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前的物体重识别（ReID）方法训练特定领域模型（例如针对人员或车辆），这些模型缺乏泛化能力且需要大量带有标签的数据来处理新类别。虽然自我监督学习通过学习实例级别的不变性来减少标注需求，但在捕捉关键的标识敏感特征（如身份证信息）方面遇到困难。因此，该研究背景是为了解决现有ReID方法的泛化能力弱和标注数据需求高的问题。", "innovation": "本文提出了Visual In-Context Prompting（VICP），这是一种新颖的框架，通过使用仅需上下文提示的方法使在已见类别上训练的模型可以直接泛化到未见过的新类别，而无需参数调整。该方法结合了LLM和视觉基础模型：通过特定任务提示，LLM可以从中少量积极/消极配对中推断出语义标识规则，然后引导视觉基础模型（如DINO）通过动态视觉提示提取标识区分性特征。这种方法能够将从LLM中获得的语义概念与视觉基础模型预训练的先验知识对齐，从而使模型能够泛化到新类别，从根本上减少了针对特定数据集的重新训练需求。", "conclusion": "在ShopID10K数据集和多样性ReID基准测试中，实验表明VICP在未见过的类别上明显优于基线方法。所提方法表明了一种新的方法来实现物体重识别的泛化。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过二元对比退火和强化学习激励通用自思能力在MLLMs中的应用", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大型语言模型（MLLMs）在复杂推理问题上表现出色，但这种推理过程对于可以通过简单问题解决且无需复杂推理的情况是冗余的。为了提高效率，本文探讨了一种名为R-4B的自动推理MLLM，该模型可以根据问题的复杂性自主决定是否进行推理过程。", "innovation": "R-4B模型引入了二元对比退火机制（bi-mode annealing）和边模式策略优化（Bi-mode Policy Optimization, BPO），该机制能够在思考能力和非思考能力之间动态转换。模型首先在包含思考和非思考模式样例的数据集上进行训练，然后在改进的GRPO框架下进行二次训练，强制模型对每个输入查询从两种模式中生成响应。实验结果表明，R-4B在25个具有挑战性的基准测试中取得了最先进的性能，相较于Qwen2.5-VL-7B，在大多数任务上表现更优，并且在计算成本较低的情况下，与更大规模的模型Kimi-VL-A3B-Thinking-2506 (16B)在推理密集型基准测试中达到了相当的性能。", "conclusion": "R-4B模型通过二元对比退火和强化学习提升了MLLMs的通用自思能力，在改进的训练框架中提高了模型在推理任务上的准确性和效率。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21190", "html_url": "https://arxiv.org/abs/2508.21190", "title": "重新审视径向失真齐次变换", "title_en": "Radially Distorted Homographies, Revisited", "authors": "Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt", "background": "齐次变换是几何计算机视觉和投影几何中最常见的变换之一，因此齐次变换的估计在广泛的计算机视觉任务中是至关重要的。在现实图像中，由于相机镜头引起的几何失真，通常需要同时确定齐次变换和镜头失真，特别是径向失真。考虑到两幅之间具有径向失真的齐次变换，存在三种不同概念的失真配置：（i）仅一幅图像存在失真，（ii）两幅图像中的失真相同，（iii）两幅图像中的失真独立。尽管这些情况以前已被分别解决，但本文提出了一种新颖且统一的框架来解决所有这三种情况。", "innovation": "本文提出了一种新颖的统一方法来解决具有径向失真的齐次变换的所有三种配置，能够构建新的快速、稳定且准确的最小子解器。相比现有最先进的最小子解器，本文提出的最小子解器在所有三种情况下都更快的同时保持了相似的准确性。并且通过广泛认可的基准测试了这些解器，还表示如果论文被接受，将提供源代码。", "conclusion": "本文提出的解法在所有三种情况下的运算速度均超过现有最先进的解决方案，同时保持相似的准确度，并且在包括鱼眼相机拍摄的图像在内的多种基准测试中表现良好。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg：通过联合3D放射高斯重构与3D/3D配准进行脊柱CT与双平面X射线配准", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导导航中，CT/X射线配准因其对高精度和实时性的严格要求而具有挑战性。传统的“渲染和比较”方法依赖于迭代投影和比较，会导致空间信息丢失和域差距。尽管基于双平面X射线的3D重构可以补充空间和形状信息，但现有的方法受限于密集视图的要求，并且难以处理噪声较大的X射线。因此，需要一种新的方法来克服传统方法的局限性，提高脊柱CT/X射线配准的准确性和实时性。", "innovation": "本文提出了一种新的RadGS-Reg框架，通过联合3D放射高斯（RadGS）重构和3D/3D配准来进行脊柱级别的CT/X射线配准。具体来说，该方法包括一种基于学习的RadGS重建模块，利用反事实注意力学习（CAL）机制专注于嘈杂X射线中的椎体区域。此外，还提出了一种针对患者的预训练策略，逐步将RadGS-Reg从模拟数据适应到真实数据，同时学习椎体形状先验知识。实验结果表明，该方法在两项任务上的性能都达到了最先进的水平，超越了现有方法。", "conclusion": "实验结果表明，RadGS-Reg在执行脊柱CT/X射线配准任务时表现出色，超越了现有方法。提出的RadGS-Reg框架通过结合学习驱动的RadGS重建和3D/3D配准，显著提高了脊柱图像配准的精度和实时性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21254", "html_url": "https://arxiv.org/abs/2508.21254", "title": "逆向成像用于心脏MRI分割的跨谱段泛化", "title_en": "Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation", "authors": "Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao", "background": "预训练分割模型在心脏磁共振成像（MRI）中难以跨不同成像序列泛化，这是因为存在显著的成像对比度差异，这些差异源于成像协议的变化。然而，就心脏MRI而言，影响成像的基本自旋性质（包括质子密度、T1和T2值）是相同的。因此，论文提出了一个基于这种核心原理的逆向成像方法，以解决泛化问题。", "innovation": "提出了一种基于物理驱动的心脏MRI数据增强和领域适应的新方法——逆向成像（Reverse Imaging）。该方法通过求解正则化自旋性质先验分布的病态非线性逆问题，从已观察到的心脏MRI图像中逆向推断出自旋性质。通过学习来自多种参数饱和恢复单一瞬时获取序列（mSASHA）数据集的生成扩散模型，获得自旋性质的先验知识。这种方法能够从MR图像中获得近似但有意义的自旋属性估计，这为心脏MRI在不同成像协议和对比度情况下的广泛泛化提供了支持。", "conclusion": "逆向成像技术使心脏MRI分割在显著不同的成像对比度和协议之间实现了高度准确的分割，展示了逆向成像在心脏MRI分割中广泛泛化的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21169", "html_url": "https://arxiv.org/abs/2508.21169", "title": "SYNBUILD-3D：一种多模态、语义丰富的3D建筑模型（LOD 4）合成数据集", "title_en": "SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4", "authors": "Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer", "background": "3D建筑模型在建筑、能源模拟和导航等领域中至关重要，但由于缺乏大规模的标注数据集，自动化生成准确且语义丰富的3D建筑物依然是一项重大挑战。尽管合成数据在计算机视觉领域取得了成功，但目前尚没有针对3D建筑模型的大规模多模态数据集，尤其是LOD 4级别的精细化模型数据集。SYNBUILD-3D填补了这一空白，提供了超过620万栋拟合的LOD 4住宅建筑的多模态数据集，每栋建筑都以三种不同的模态表示：LOD 4语义丰富的三维线框图（第一模态）、对应的楼层平面图图像（第二模态）以及类似LiDAR的屋顶点云（第三模态），并且所有模态的数据都包含了关于房间、门窗等的语义信息。", "innovation": "SYNBUILD-3D引入了一种全新的多模态数据集构建方法，通过合成数据来弥补现有数据集的不足，支持LOD 4级别的3D建筑模型的自动化生成，涵盖楼层平面图布局和屋顶几何形状的预设，并保持语义几何一致性。", "conclusion": "SYNBUILD-3D数据集及其生成的代码可在公共平台上免费获取，为未来开发新型生成式AI算法提供了可能，可自动创建受限于预设楼层平面图布局和屋顶几何形状的LOD 4 3D建筑模型，并保持语义几何一致性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21227", "html_url": "https://arxiv.org/abs/2508.21227", "title": "基于Auto3DSeg的轻量级胰腺癌MRI自动分割", "title_en": "Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg", "authors": "Keshav Jha,William Sharp,Dominic LaBella", "background": "胰腺肿瘤的准确界定是诊断、治疗规划和预后评估的关键，但自动化分割依然面临挑战，原因在于解剖结构的变异性和可用数据集的有限性。这项研究中的SegResNet模型作为Auto3DSeg架构的一部分，在2025年的PANTHER挑战中，对两个基于MRI的胰腺肿瘤分割任务进行了训练和评估，其中涉及到特定解剖相关区域的五折交叉验证和STAPLE高一致性集成方法。", "innovation": "研究采用了SegResNet模型及其Auto3DSeg架构，通过特定的MRI序列(动脉增强T1加权和MR Linac T2加权），在专家标注的数据集上进行了胰腺肿瘤分割任务的训练和评估，进一步探讨了轻量级算法在小数据集情况下对于MRI胰腺肿瘤分割的有效性。", "conclusion": "研究结果表明，MRI基胰腺肿瘤分割在小数据集情况下十分具有挑战性，不同MRI序列引入了更多变异性。尽管算法表现有限，仍证明了自动切线的可能性，并强调了需要在提高分割模型鲁棒性和临床适用性方面进行更大数据集标准化MRI数据的进一步研究。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21257", "html_url": "https://arxiv.org/abs/2508.21257", "title": "PHD: 以点扩散为基础的个性化3D人体体型拟合", "title_en": "PHD: Personalized 3D Human Body Fitting with Point Diffusion", "authors": "Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang", "background": "传统的3D人体骨架恢复（HMR）方法旨在对所有人通用且具备良好的泛化能力，这些方法通常通过来自2D图像的约束来优化姿态估计，这会导致3D准确性降低，原因是对个体特有的体型和3D姿态的合理性考虑不足。本研究提出了PHD方法，通过利用用户的特定体型信息，有效提升了基于视频的姿态估计精度，改善了传统的HMR方法在使用2D约束时存在的问题，提高了3D姿态的准确度，特别是解决了标注点误差的问题，相比于现有方法，提高了整体的姿态准确性。此外，该方法对数据的需求较低，只需要合成数据，即可应用于现有的3D姿态估计器以增强其性能。", "innovation": "PHD提出了一个新颖的方法，通过个性化的人体体型信息来改善3D姿态估计，采用点扩散变换器（Point Diffusion Transformer）作为姿态的先验概率模型，通过定点精炼抽样损失（Point Distillation Sampling loss）迭代指导姿态拟合过程，有效减少了对2D约束的过度依赖，从而提高了3D姿态估计的准确性，特别是增强了与3D人体网状模型的相关性，进一步促进了现有的3D姿态估计器的性能提升，且仅需少量合成数据即可进行训练，是一种高效且灵活的模块化插件解决方案。", "conclusion": "研究开发了一种以用户特定体型为基础的3D姿态先验模型，通过点扩散变换器进行迭代指导姿态拟合，有效提高了基于视频的姿态估计的准确性，不仅提高了对齐于骨盆的姿态准确度，还提高了绝对姿态准确度。此外，该方法数据效率高，仅需少量合成数据即可训练，可以作为灵活的插件模块嵌入现有的3D姿态估计系统中，显著提升其性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "标准化多层次组织图谱在大规模全切片图像档案中增强人工智能集成和搜索的标准", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "全切片图像（WSI）是指通过扫描包含生物标本（如组织切片或细胞样品）的整个玻片而创建的高分辨率数字图像，可多倍放大。WSIs在病理学疾病诊断、肿瘤学癌症研究等多个领域中被广泛应用于人工智能算法开发。然而，用于训练或验证AI算法的WSI集合的组群构建时，需要了解WSI中的内容信息，但目前尚无标准来描述这些元数据，导致主要依赖人工检查，这在大型数据集中不合适。", "innovation": "本文提出了一种通用框架，用于生成WSI的2D索引地图以及针对特定应用领域的分析机制。该方法在临床病理学领域演示，使用通用语法和语义实现不同目录之间的互操作性。该方法通过细化WSI内容信息，增强组织图谱，将WSI分为源、组织类型和病理改变三个层次，每个层次为WSI的不同部分分配特定类别。", "conclusion": "通过具体实例展示了所提标准在WSI目录、机器学习和基于图的WSI表示中的优势和适用性。该标准促进了大规模WSI档案中人工智能集成和搜索的标准化和效率提升，提高了数据分析的质量和速度。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21398", "html_url": "https://arxiv.org/abs/2508.21398", "title": "GLENDA: 子宫内膜异位症妇科腹腔镜数据集", "title_en": "GLENDA: Gynecologic Laparoscopy Endometriosis Dataset", "authors": "Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein", "background": "妇科腹腔镜手术是一种微创外科手术，通过患者的腹腔实时视频流进行。这种手术可以进行多种治疗，录像还对术后活动如治疗计划、病例记录和教育非常重要。然而，当前的做法是手动分析手术录像，效率低下且耗时。因此，为了提高这一过程，正在开发更复杂的计算机视觉和机器学习方法。由于医学领域样本数据稀缺，尤其是在数据标注更精细的图像数据集方面，因此需要构建新的数据集来促进研究进展。", "innovation": "本文介绍了GLENDA - 一类图像数据集，标签了子宫内膜异位症（子宫内膜组织异常沉积）的区域级别注释。它是第一个这样的图像数据集，与该领域的领先医学专家合作创建。", "conclusion": "该数据集的发布不仅提供了计算机视觉和机器学习研究的宝贵资源，还为医疗影像分析提供了进一步的证据。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21399", "html_url": "https://arxiv.org/abs/2508.21399", "title": "使用深度学习实例分割识别腹腔镜手术中的医疗器械", "title_en": "Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation", "authors": "Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein", "background": "录制的手术视频已成为医疗内镜领域的重要信息源，因为录制的视频详细展示了手术中的每一处细节。虽然现在视频录制相对简单，但由于手术视频内容的特殊性，自动内容索引仍然是一个重大挑战。本文研究了从记录的腹腔镜妇科手术视频中分割和识别手术器械的方法，评估了基于区域的全卷积网络在实例感知的器械分割及器械识别中的性能。", "innovation": "本文采用了基于区域的全卷积网络进行实例感知的器械分割和多类器械识别。结果显示，即使训练样本数量较少，也能实现较高的器械区域定位和分割准确性；同时，也指出识别特定器械仍具有挑战性，因为手术器械本身具有高度相似性。", "conclusion": "研究结果表明，即使训练样本较少，仍能实现较高的器械区域检测和分割准确性，但识别特定器械仍然非常具有挑战性。这可能是由于手术器械之间具有高相似性造成的。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21363", "html_url": "https://arxiv.org/abs/2508.21363", "title": "基于分层时间裁剪的高效扩散模型3D人体姿态估计", "title_en": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning", "authors": "Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang", "background": "扩散模型在生成高保真3D人体姿态方面表现出强大的能力，但由于其迭代性质和多重假设需求，带来了巨大的计算成本。", "innovation": "提出了一种基于分层时间裁剪的高效扩散模型3D人体姿态估计框架（HTP策略）。该策略通过自上而下的阶段操作，在帧和语义级别动态剪裁冗余姿态标记，同时保持关键的运动动态。具体包括：时空相关增强剪枝（TCEP）、基于结果帧级稀疏性的时空多头自注意力（SFT MHSA）以及通过聚类进行语义级细粒度裁剪的掩码引导姿态标记剪枝（MGPTP）。", "conclusion": "在Human3.6M和MPI-INF-3DHP数据集上的实验表明，与之前的基于扩散模型的方法相比，HTP减少了训练MACs 38.5%、推理MACs 56.8%，并提高了81.1%的推理速度，同时达到了最先进的性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO：遥感领域的深度自监督预训练研究", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习已经成为遥感领域的一种强大工具，因为遥感数据通常有大量的未标注数据。本文探讨了使用DINO，一种对比自监督方法，对遥感图像进行预训练的可能性。研究者提出了一种专门针对卫星图像表示学习的模型——SatDINO。该模型通过多种数据集和测试设置的广泛实验，展示了在多个基准测试中的优越性能和竞争力。", "innovation": "SatDINO是专门为卫星图像引入的一种自监督学习模型，引入了一种新的地面采样距离（GSD）编码方式和自适应视图采样。它在多个基准测试中表现出色，并且通过消融研究评估了其各个组件的有效性。这些创新增强了模型的性能，并且可以在SatDINO模型上独立使用。", "conclusion": "SatDINO在遥感领域展示了优越的自监督预训练性能，尤其在多个基准测试中取得出色成绩。通过引入新的特征编码方法和视图采样策略，SatDINO为该领域的模型优化提供了新的途径。相关代码和预训练模型可以在提供的链接下载。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21371", "html_url": "https://arxiv.org/abs/2508.21371", "title": "Print2Volume：从2D指纹图像生成基于OCT的3D指纹体积", "title_en": "Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image", "authors": "Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang", "background": "光学相干断层扫描(OCT)能够获取高分辨率的三维指纹数据，但其高昂的成本和耗时的数据采集过程导致大规模公开数据集稀缺，严重阻碍了先进算法，尤其是数据饥渴的深度学习模型的发展。", "innovation": "提出了一种名为Print2Volume的新框架，能够从2D指纹图像生成逼真的、合成的基于OCT的3D指纹。该框架分为三个阶段：1）2D风格迁移模块，将二值指纹转换成模仿Z方向平均投影OCT扫描风格的灰度图像；2）3D结构扩展网络，将2D图像扩展成可能的3D解剖体积；3）基于3D GAN的OCT现实性细化器，渲染具有真实纹理、斑点噪声和其他成像特征的结构体积。通过这种方法，生成了包含420,000个样本的大规模合成数据集，并证明了数据质量及其对识别性能的显著影响。", "conclusion": "使用自合成数据预训练识别模型并在小的真实数据集上进行微调，结果显示在ZJUT-EIFD基准测试中的等错误率(EER)从15.62%降低到2.50%。这表明该方法在解决数据稀缺性方面非常有效。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift: 隐式条件传输在X射线域自适应中的应用", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医疗数据提供了训练稳健模型的可扩展解决方案，但其在真实临床环境中的通用性受到显著领域差距的限制。本文关注合成和真实头颅X光影像之间的跨域翻译挑战，特别是在衰减行为、噪声特征和软组织表示方面的差异。为此，提出了MedShift，一种基于流匹配和薛定谔桥的统一条件生成模型，能够实现多域间的高保真、无标签图像翻译。", "innovation": "MedShift模型通过学习共享的领域无关潜空间，能够无配对地在训练过程中任何一对域之间实现无缝翻译，不同于以往需要领域特定训练或依赖配对数据的方法。此外，还引入了X-DigiSkull数据集，进一步验证域翻译模型的性能。实验结果表明，尽管MedShift的模型较小，但在感知保真度和结构一致性方面提供了强大的性能，且在推理时具有灵活性。", "conclusion": "MedShift模型为医学成像中的域适应提供了一种可扩展和普适的解决方案，能够在保持感知保真度和结构一致性之间进行调优，适应不同的医疗应用需求。该模型和数据集的代码可在此网站找到：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21424", "html_url": "https://arxiv.org/abs/2508.21424", "title": "使用置信度数据标签的无监督增量学习", "title_en": "Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels", "authors": "Lucas Rakotoarivony", "background": "深度学习模型在许多计算机视觉任务中取得了最佳性能。但在实际场景中，训练时未见过的新型类经常出现，需要模型逐步学习新知识。现有的增量学习方法（CIL）允许模型学习新类同时保留对之前类别的知识，但这些方法假设增量数据集完全标记，这是不现实的。", "innovation": "本文提出了一种无监督的增量学习方法——基于置信度的伪标签（ICPL），它使用置信度数据标签代替人工注释，使模型可以从未标记的数据集中学习新类别。该方法通过置信度选择将这些伪标签集成到各种CIL方法中，并在CIFAR100和ImageNet100数据集上评估性能。此外，将该方法应用于细粒度数据集以展示其现实可行性，并测量其计算复杂性以验证其在资源受限环境中的适用性。", "conclusion": "ICPL方法在监督方法中取得了具有竞争力的结果，并在最终准确性方面比最先进的类增量新型类别发现（class-iNCD）方法高出超过5%。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21458", "html_url": "https://arxiv.org/abs/2508.21458", "title": "SAM-Med3D在MRI痴呆分类中的联邦微调", "title_en": "Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification", "authors": "Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron", "background": "尽管基础模型（FMs）在基于人工智能的痴呆诊断中具有很强的潜力，但它们在联邦学习（FL）系统中的整合仍然鲜有研究。本文通过使用大型多队列数据集，系统评估了关键设计选择（分类头架构、微调策略和聚合方法）对联邦FM调优性能和效率的影响，以确定其在基于脑MRI数据的痴呆分类中的应用效果和方法优化方向。", "innovation": "该研究首次对基础模型在联邦学习中的适应性进行了系统评估，并发现分类头架构对性能有重大影响，冻结FM编码器能达到与完全微调相当的效果，先进的聚合方法优于标准的联邦平均。这些发现为部署基础模型于分散的临床环境中提供了实用见解，并指出了未来方法开发时需要权衡的关键选择。", "conclusion": "本研究通过实证分析，揭示了设计选择对联邦FM调优性能和效率的显著影响，指出在部署此类模型于临床环境时需要考虑的关键因素，并强调了未来模型开发时应考虑的权衡。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21094", "html_url": "https://arxiv.org/abs/2508.21094", "title": "具有时间视觉筛选的视频大语言模型", "title_en": "Video-LLMs with Temporal Visual Screening", "authors": "Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.(May)Fung,Manling Li,Heng Ji", "background": "人类在观看视频时自然地进行时间筛选，通过拖动进度条专注于显著的时间段，但当前的视频大语言模型（Video-LLMs）由于训练过程中稀疏的帧采样和不足的帧间推理监督，在捕捉细粒度的时间语义方面存在挑战。", "innovation": "受认知科学原则的启发，本文提出了时间视觉筛选（TVS），这是一种新的任务，用于预处理视频问题回答和指令调优数据，包括：(1) 保留焦点关键的视频片段；(2) 同步重构查询为其最直接的形式，同时保留答案的一致性；(3) 对所有可能的答案保持不变性和一致性。TVS被构造成一个模块化的前端适配器任务，可以无缝集成到视频指令调优（训练）和视频问题回答（推理）管道中。TVS优化了推理负担和认知负载的分布，在训练时对齐查询与关键的视觉信息，在推理时实现查询感知段落聚焦和简化查询表示。", "conclusion": "实验表明，整合TVS在训练和推理阶段分别获得了7.33%和34.6%的相对收益，证明了时间信息筛选对于提高视频语言理解的有效性。本文还构建了第一个TVS基准并提出了ReSimplifyIt基线，在视频剪辑任务上的F-1分数提高了0.47，同时实现了具有竞争力的查询重写性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21437", "html_url": "https://arxiv.org/abs/2508.21437", "title": "Gaussians作为树木：大规模单株树映射", "title_en": "Trees as Gaussians: Large-Scale Individual Tree Mapping", "authors": "Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt", "background": "树木是陆地生物圈的关键组成部分，对于生态系统功能、气候调节和生物质经济至关重要。然而，由于缺乏建模支持，大规模监测单株树木仍然有限。现有全球产品主要关注树冠覆盖或树冠高程的二值信息，并未在单株树层面明确识别树木。本文通过提出一种新的深度学习方法，可以在3 米分辨率的PlanetScope影像中，大规模检测单株树。此方法利用可扩展大小的高斯核模拟树冠，提取树冠中心位置并生成二值树冠覆盖图。这些树冠覆盖率可以通过自动从机载LiDAR数据提取的数以亿计的点进行训练，成功地在森林内外识别树木，从而弥补了现有技术的不足。", "innovation": "本文提出了一种通过深度学习方法在3 米分辨率的PlanetScope影像中大规模检测单株树的技术。该方法使用可扩展大小的高斯核模拟树冠，并能够从自动提取的数以亿计的点中进行训练。此外，该模型能够在森林内外成功识别树木，为全球高分辨率树木监测提供了一种可扩展的框架，且具有适应未来卫星任务中更优影像的能力。", "conclusion": "本研究方法为全球范围内进行高分辨率树木监测提供了一个可扩展的框架。该模型不仅能够与现有树冠覆盖率地图和机载LiDAR数据进行比较，达到领先性能（比机载LiDAR地图的覆盖率R² = 0.81），还能通过手动标签进行微调以进一步提高检测效果。通过这种方法，可以在不同生境中实现较为平衡的检测性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21529", "html_url": "https://arxiv.org/abs/2508.21529", "title": "也许你不需要U-Net：用于材料显微图像分割的卷积特征上采样", "title_en": "Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation", "authors": "Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper", "background": "特征基础模型（通常是视觉变换器）提供了丰富的图像语义描述，适用于下游任务如（交互式）分割和目标检测。然而，为了计算效率，这些描述往往是基于图像的块，因此难以表示显微镜图像中常见的精细特征，而且在材料和生物图像分析中还面临大尺寸图像的问题。", "innovation": "我们训练了一个卷积神经网络来从低分辨率的基础模型特征（即大块尺寸）上采样，根据输入图像进行。无需额外训练，我们将此上采样网络应用于各种显微镜图像的高效特征提取和分割，包括植物细胞、锂离子电池正极和有机晶体。上采样后的特征能够有效区分开难分割的相位，如细微裂纹。实验表明，使用这些深层次特征的交互式分割能更快、更少标记地产生高质量分割结果。", "conclusion": "这项工作展示了一种方法，通过基于输入图像的卷积特征上采样实现高效的显微图像分割，使得交互式分割能够快速且使用更少的标注标签生成高质量的分割结果，这为材料科学和生物图像分析中的任务提供了一种新的解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21444", "html_url": "https://arxiv.org/abs/2508.21444", "title": "Scale-GS: 通过流式内容上冗余过滤训练的高效可扩展高斯斑点图", "title_en": "Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content", "authors": "Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang", "background": "3D Gaussian Splatting (3DGS) 能够实现沉浸式应用所需的高保真实时渲染。然而，将其扩展到动态场景受到大量密集高斯数据和每帧长时间训练的需求限制。该论文提出了一种名为 Scale-GS 的可扩展高斯斑点图框架，旨在为流任务提供高效训练。", "innovation": "Scale-GS 框架通过分层锚定结构对高斯球进行组织，较粗级别的高斯球表示低分辨率场景结构，较细级别的高斯球通过较粗级别高斯球选择性激活，以实现细节高保真渲染。引入了一种混合变形和孵化策略，通过高斯变形模型帧间运动，通过高斯孵化表征宽范围运动。同时，双向自适应遮罩机制通过去除静态区域和优先处理信息丰富的视角来提高训练效率。", "conclusion": "大规模实验表明，Scale-GS 在视觉质量上优于现有方法的同时，显著缩短了训练时间。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21451", "html_url": "https://arxiv.org/abs/2508.21451", "title": "一瞥中有锐利目光：重新思考轻量级图像描述作为实用视觉专家", "title_en": "One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist", "authors": "Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo", "background": "图像描述对于视频指导系统和探索机器人等应用至关重要，但由于多模态大型语言模型（MLLMs）的高计算需求，这给在本地设备上部署这些模型带来了挑战。", "innovation": "研究团队通过实施一个基于1.25亿参数的语言模型（比LLaMA-7B小56倍）开发了一种轻量级图像描述模型，并在单一句子和详细描述任务上对其性能进行了评估。虽然该模型可以实现与大型多模态通用专家相当的性能，但它也存在视觉盲点问题，可能导致语义错误。为了解决这些问题，团队提出了一种新的图像描述框架——Sharp-Eyed Refinement，通过改善视觉锚定来提高描述质量。他们的研究表明，此框架优于之前的轻量级描述模型和大型通用模型。", "conclusion": "该研究及其实验表明，利用特定视觉识别能力的轻量级图像描述模型在设备上部署时具有优势，且提出的Sharp-Eyed Refinement框架能显著提升描述质量。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21463", "html_url": "https://arxiv.org/abs/2508.21463", "title": "Multi-Method Ensemble for Out-of-Distribution Detection", "title_en": "Multi-Method Ensemble for Out-of-Distribution Detection", "authors": "Lucas Rakotoarivony", "background": "在开放世界的应用中，神经网络检测不在分布（Out-of-Distribution, OOD）样本至关重要，尤其是在涉及安全的应用中。现有方法通过两种主要技术改进了OOD检测：特征截断，增加ID样本与OOD样本之间的分离；以及评分函数，对ID和OOD数据之间的区分进行评分。然而，大多数现有方法仅专注于单一技术类别，或仅在特定类型的OOD数据集上进行评估，未能充分结合现有多种技术。鉴于这一观察，本文通过理论和实验验证了最先进的特征截断和评分函数可以有效结合，并且证明了集成多个评分函数能增强对各种类型OOD样本的鲁棒性。", "innovation": "本文提出了一种名为Multi-Method Ensemble (MME)得分方法，它将最先进的OOD检测器统一到一个更有效的评分函数中，理论和实验上证实了特征截断和评分函数的有效组合，并证明了多个评分函数的集成增强了对各种OOD样本的鲁棒性。MME在大量和小型基准上的大量实验表明，其在所有基准上均显著优于最新的方法，特别是在具有挑战性的ImageNet-1K基准上，我们的方法实现了27.57%的平均FPR95，优于现有最佳基线6%的性能提升。", "conclusion": "MME得分方法通过理论和实验验证了特征截断和评分函数的有效整合，并在各种OOD样本情况下表现出更强的鲁棒性，实现了对最新方法的显著超越，在ImageNet-1K基准上的表现尤为突出。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21556", "html_url": "https://arxiv.org/abs/2508.21556", "title": "ECHO: 蛋糕 - 本体中心的人机交互建模", "title_en": "ECHO: Ego-Centric modeling of Human-Object interactions", "authors": "Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll", "background": "从第一人称视角建模人与物体的交互（HOI）是一个尚未被充分探索但很重要的问题，这归因于可穿戴设备（如智能眼镜和手表）的日益普及。我们研究仅通过头部和手腕的跟踪数据能恢复多少关于交互的信息。为此，我们提出了ECHO（本体中心的人机交互建模），这是首个为从如此少量观察中恢复人类姿态、物体运动和接触提供统一框架的方法。", "innovation": "ECHO 首次提出了一种联合建模人类运动、物体轨迹和接触序列的统一框架，采用了扩散变换器架构和独特的三变量扩散过程，允许灵活的输入配置。ECHO 以头部为中心的经典空间运作，提高了对全局方向的鲁棒性。我们还提出了一种基于传送带的推断方法，随着帧位置逐渐增加扩散时间戳，能够处理任何长度的序列。", "conclusion": "通过广泛的评估，我们证明ECHO在本体中心的HOI重建方面超越了现有方法，为HOI重建设立了新的标准。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21472", "html_url": "https://arxiv.org/abs/2508.21472", "title": "基于局部增强的船体检测对抗性贴图攻击", "title_en": "Adversarial Patch Attack for Ship Detection via Localized Augmentation", "authors": "Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang", "background": "当前基于遥感图像的船只检测技术主要依赖于深度神经网络（DNNs）的检测能力。然而，DNNs对对抗性补丁攻击非常敏感，这可能导致检测模型误分类，或者使目标完全逃脱检测。大量研究表明，基于数据变换的方法可以提高对抗样本的传输性，但过度增加背景或其他无关区域的数据变换可能引入不必要的干扰，导致目标检测模型产生误检。这些错误不是由对抗补丁本身造成的，而是由于背景和其他非目标区域的过度增强。因此，本研究提出了一种局部增强方法，仅在目标区域应用增强，避免对非目标区域产生影响。通过减少背景干扰，这种方法使损失函数更直接地关注对抗贴图对检测模型的影响，从而提高攻击成功率。", "innovation": "本研究提出了一种局部增强方法，即仅在目标区域应用增强，以避免对非目标区域产生影响。这种方法可以减少背景干扰，使损失函数更直接地关注对抗贴图对检测模型的影响，从而提高攻击成功率。在HRSC2016数据集上进行的实验表明，该方法有效地提高了对抗贴图攻击的成功率和传输性。", "conclusion": "研究提出的局部增强方法可以有效提高对抗性贴图攻击的成功率和传输性。这种方法通过对目标区域进行局部增强，避免了非目标区域的过度增强带来的干扰，从而使得检测模型更专注于对抗贴图的影响。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21565", "html_url": "https://arxiv.org/abs/2508.21565", "title": "视觉语言模型在理解城市方面的表现如何？从街道视角图像进行空间推理的比较研究", "title_en": "How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images", "authors": "Juneyoung Ro,Namwoo Kim,Yoonjin Yoon", "background": "理解城市的复杂场景需要精细的空间推理，包括对物体、布局和深度线索的分析。然而，现有预训练在通用场景上的视觉语言模型（VLMs）在城市领域中是否能有效利用这些能力尚未得到充分探索。", "innovation": "本文进行了三个现成的VLMs（BLIP-2、InstructBLIP和LLaVA-1.5）的比较研究，评估它们的零样本性能以及强化学习下（使用特定于城市场景的合成VQA数据集进行微调）的效果。还构建了一个从街道视角图像的分割、深度和对象检测预测中生成的数据集，配对每个问题与LLM生成的理由链（CoT）答案以进行逐步推理监督。", "conclusion": "研究结果表明，尽管视觉语言模型在零样本设置中表现良好，但使用我们的合成CoT监督数据集进行微调可以显著提高性能，特别是对于否定和反事实等问题类型。本文引入了城市空间推理作为VLMs的新挑战，并展示了合成数据集构建作为一种将通用模型适应特定领域的方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21539", "html_url": "https://arxiv.org/abs/2508.21539", "title": "HCCM", "title_en": "HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones", "authors": "Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li", "background": "自然语言引导无人机（NLGD）提供了诸如目标匹配和导航等任务的新范式。然而，无人机场景的宽广视野和复杂的组成语义对视觉-语言理解提出了挑战。主流的视觉-语言模型（VLMs）强调整体对齐，但缺乏细粒度语义；现有分层方法依赖于精确实体的分割和严格的包含关系，这在动态环境中限制了其效果。", "innovation": "文章提出了分层跨粒度对比和匹配学习（HCCM）框架，包括两个组件：(1) 区域-全局图像-文本对比学习（RG-ITC），通过对比局部视觉区域与全局文本，避免了精确场景分割并捕捉了局部到全局的层次语义；(2) 区域-全局图像-文本匹配（RG-ITM），通过评价全局跨模态表示中的局部语义一致性，代替了刚性约束增强了组合推理。此外，文章还引入了一种动量对比和蒸馏（MCD）机制来提高鲁棒性。", "conclusion": "实验结果表明，HCCM 在 GeoText-1652 数据集上的图像检索 Recall@1 达到 28.8%，文本检索达到 14.7%。在未见过的身影（ERA）数据集上，HCCM 展现了强大的零样本泛化能力，平均召回率（mR）为 39.93%，超过了微调的基线模型。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "基于去噪扩散模型从单张图像重建完整高斯点", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "传统的高斯点技术要求密集的场景观测，难以重建被遮挡和未观测到的区域。完成未观测到的场景表面具有挑战性，因为这意味着需要解决可能表面的模糊性问题。传统方法使用基于回归的公式来预测被遮挡和超出视锥的表面，这会导致模糊、不现实，并且无法捕捉多种可能的解释。因此，它们通常只关注背景中的孤立对象，仅重建可见表面，或者无法从输入视图向外推断。", "innovation": "本文提出了一种生成型公式学习在单张输入图像上条件下的高斯点3D表示的分布。通过提出一个自监督的自变分自重构器（VAReconstructor）来学习仅从2D图像中的潜在空间，训练扩散模型来解决缺乏真实训练数据的问题。这种方法能够生成准确的重建和多样性的样本，还能够完成被遮挡的表面，用于高质量的360度渲染。", "conclusion": "本文通过使用去噪扩散模型，仅从单张输入图像就能够重建完整3D场景，包括被遮挡的部分。该方法能够生成高质量的360度渲染，并能够完成被遮挡的表面，相比传统方法，提供了更准确和多样性的样本。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频多模态大语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但仍然容易产生与视频输入内容不一致或无关的幻觉内容。现有的视频幻觉基准主要集中在短视频上，将幻觉归因于语言先验强、帧缺失或视觉编码引入的视觉-语言偏见等因素。尽管这些因素确实解释了大多数短视频中的幻觉，但仍过于简化了幻觉的原因。有时，模型会产生错误的输出，但具有正确的帧级语义，这种现象被命名为语义聚合幻觉（SAH），主要发生在从帧级语义聚合到事件级语义组的过程中。鉴于长视频中的语义复杂性增加，SAH变得更加关键，因此需要系统地研究这种幻觉的原因。", "innovation": "该论文引入了ELV-Halluc基准，这是首个专注于长视频幻觉的基准，使得可以系统地研究语义聚合幻觉（SAH）。实验确认了SAH的存在，并证明其随着语义复杂性的增加而增加。此外，研究发现SAH在快速变化的语义中更为常见。该论文还提出了一些缓解SAH的方法，如通过位置编码策略减轻SAH，并采用DPO策略增强模型在事件内外区分语义的能力。通过下游验证，该方法在ELV-Halluc和Video-MME上取得了显著效果，减少了27.7%的SAH比率，同时创造了8000个对抗数据对的数据库。", "conclusion": "ELV-Halluc提供了一个全面的视角，以理解和评估Video-MLLMs在长视频理解中的SAH。通过识别和区分SAH，这一研究有助于提高Video-MLLMs的准确性和鲁棒性。该工作还通过更深层次地理解SAH，促进了未来发展长视频理解模型时需要考虑的新问题。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21657", "html_url": "https://arxiv.org/abs/2508.21657", "title": "基于复值变形注意力的展开框架用于高质量计算机生成全息图生成", "title_en": "Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation", "authors": "Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan", "background": "计算机生成全息图（CGH）因其处理非线性和不适定性的问题而受到了深入学习算法的关注。然而，现有的方法仍面临准确性和稳定性重建的挑战。这些问题具体表现在：(i) 端到端网络将重建模型视为黑盒，忽视了物理关系，降低了可解释性和灵活性；(ii) 基于CNN的方法受到接收场的限制，难以捕捉长距离依赖和全局上下文；(iii) 基于波数谱方法（ASM）的模型受限于有限的计算资源，难以处理大规模问题。现有的方法并未充分解决这些问题，因此本研究提出了新的方法来克服这些挑战。", "innovation": "本研究提出了一种称为Deep Unfolding Network（DUN）的新方法。DUN将梯度下降分解为两个模块：流量保持模型（ABPM）和相位域复值去噪器（PCD）。ABPM允许更宽的工作范围，超过基于ASM的方法。同时，PCD利用复值变形可变形自注意力模块来捕获全局特征并提高性能。该方法在SIMULATED和REAL数据上取得的PSNR超过35 dB，达到最先进的效果。这项工作通过引入流量保持模型和复值去噪器模块，增加了模型的灵活性和性能，为CGH生成提供了新的解决方案。", "conclusion": "实验结果表明，所提出的DUN方法在模拟和真实数据上的表现优秀，能生成高质量的CGH图。该方法提供了更广泛的工作距离，更精确的全局特征捕捉，并显著提高了重建性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 零样本CLIP基前瞻订单元和人工介入排序的高效成对比对", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或困难的标注任务中，成对比较往往比绝对评分或顺序分类更受欢迎，因为其提高了可靠性。然而，全面的比较需要大量的注释（O(n^2)）。最近的工作通过使用排序算法积极采样成对比较大大减轻了注释负担（O(n log n)）。本文通过（1）使用对比语言-图像预训练模型（CLIP）进行无训练的层次前瞻排序，（2）用自动比较替换显而易见的成对人类比较，进一步提高注释效率。所提出的EZ-Sort首先生成基于CLIP的零样本前瞻排序，然后初始化桶感知的Elo评分，最后运行以不确定性为导向的人工循环归并排序.", "innovation": "本文提出了一种结合CLIP基前瞻排序和不确定性感知采样的方法（EZ-Sort），减少了注释负担，同时保持或提高了评分者间的一致性。具体创新点包括：（1）使用无训练的CLIP模型进行层次前瞻排序；（2）用自动比较替换显而易见的成对人类比较；（3）采用以不确定性为导向的人工循环归并排序，初始化桶感知的Elo评分.", "conclusion": "在对脸龄估计（FGNET）、历史图像时间线（DHCI）和视网膜图像质量评估（EyePACS）等多种数据集进行验证后，结果显示EZ-Sort将人类注释成本降低了90.5%，与全面成对对比相比，比先前的工作降低了19.8%的成本，同时提高了或维持了一致性。这表明结合CLIP基先验和不确定性感知采样可以为成对排序提供高效且可扩展的解决方案."}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21580", "html_url": "https://arxiv.org/abs/2508.21580", "title": "4D长期医学影像中时空轨迹学习的Temporal Flow Matching", "title_en": "Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging", "authors": "Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein", "background": "理解医疗成像中的时间动态对于疾病进展建模、治疗规划和解剖学发展跟踪来说至关重要。然而，大多数深度学习方法要么仅考虑单一时间上下文，要么专注于分类或回归任务，限制了它们在空间细节预测中的能力。尽管一些方法已被探索，但它们通常局限于单一时间点、特定疾病或有其他技术限制。为了弥补这一根本差距，该研究引入了Temporal Flow Matching (TFM)，这是一种统一的生成轨迹方法。它旨在学习内在的时间分布，并通过设计可以退化为最近的图像预测器，即预测最后一期上下文图像（LCI），以及支持3D体积、多个前期扫描以及不规则取样。", "innovation": "引入了Temporal Flow Matching (TFM)，这是一种统一的生成轨迹方法。TFM通过设计可以退化为最近的图像预测器，支持3D体积、多个前期扫描和不规则取样，能够学习背后的内在时间分布。这篇研究中的方法在三个公开的纵向数据集上的广泛基准测试中展示了优越性，超越了自然成像中的时空方法，为4D医学图像预测设定了新的最优基准和稳健的基础。", "conclusion": "TFM在三个公开的纵向数据集上的广泛基准测试中表现出色，能够学习时间分布并支持多种应用场景，如3D体积、多个前期扫描以及不规则取样，且其性能超越了现有的时空方法，为4D医学图像的预测设定了新的基准和基础。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21680", "html_url": "https://arxiv.org/abs/2508.21680", "title": "基于提示模型的全身PET/CT交互式病灶分割", "title_en": "Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models", "authors": "Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein", "background": "全身PET/CT是肿瘤成像的基石，但由于显像剂异质性、生理吸收和多中心变异性，准确的病灶分割仍然具有挑战性。尽管全自动方法取得了显著进步，但临床实践中仍然需要在预测掩膜的基础上保持人工干预以提高分割精度。为此，autoPET/CT IV挑战引入了基于模拟用户提示的交互分割任务。这项工作中，作者基于winning的autoPET III nnU-Net流程进行了改进，引入了可提示的能力，通过用户提供的前景和背景点击作为额外输入通道。通过系统研究用于空间提示的表示方法，证明欧几里得距离变换（EDT）编码在性能上优于高斯核。此外，通过在线模拟用户交互和自定义点采样策略使得模型在实际提示条件下表现更稳定。通过EDT为基础的模型集合，在有无外部数据训练的情况下，获得了最佳的交叉验证表现，相比基线模型，减少了假阳性率和假阴性率。", "innovation": "基于winning autoPET III nnU-Net流程引入了可提示的功能，通过用户提供的前景和背景点击作为额外输入通道。系统研究了用于空间提示的表示方法，证明欧几里得距离变换（EDT）编码优于高斯核。通过在线模拟用户交互和自定义点采样策略改进了模型的鲁棒性。EDT为基础的模型集合，在有无外部数据训练的情况下，获得了最佳的交叉验证表现。", "conclusion": "这些结果表明，基于提示模型能够实现多显像剂、多中心PET/CT中高效率、用户指导的分割工作流程。相关代码已公开."}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21581", "html_url": "https://arxiv.org/abs/2508.21581", "title": "将病理学与CT成像整合以实现个性化肾癌复发风险预测", "title_en": "Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer", "authors": "Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado", "background": "评估肾细胞癌（ccRCC）的复发风险对于指导术后随访和治疗至关重要。Leibovich评分虽然广泛用于分类远处复发风险，但在患者层面的分辨率有限，并排除了影像学信息。为了解决这一问题，该研究评估了结合术前CT和术后组织学全切片图像（WSI）的多模态复发预测方法，并测试了一个预先训练编码器和Cox基生存模型的模块化深度学习框架，包括单模态、后期融合和中间融合的设置方式。在真实的ccRCC队列中，WSI基模型在整体表现上优于仅CT的方法，强调了组织学预测的重要性。中间融合进一步提高了性能，最好的模型接近调整后的Leibovich评分。随机平局抽样缩小了临床基线与学习模型之间的差距，表明分类可能高估了个体性能。通过简单的嵌入连接，放射学主要通过融合增加了价值。这些发现在基于基础模型的多模态整合以实现个性化ccRCC风险预测方面显示出可行性。", "innovation": "该研究采用模块化的深度学习框架，结合了术前CT和术后WSI，进行多模态复发预测。使用了一个预先训练的编码器和Cox基生存建模方法，并且测试了不同的融合模式（单模态、后期融合、中间融合），其中中间融合的模型表现最佳，接近调整后的Leibovich评分。", "conclusion": "这些结果表明，基于基础模型的多模态整合在ccRCC风险预测中具有可行性。未来的工作应该探索更富有表现力的融合策略、更大的多模态数据集和通用的CT编码器，以更好地匹配组织学建模能力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的无侵入性卷积神经网络可靠性监测", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络（CNNs）已成为现代计算机视觉的基础，实现了在各种图像识别任务中前所未有的高精度。然而，这些网络在面对不可感知的输入修改（即对抗性扰动）时仍然容易出现误分类问题，即使这些扰动具有很高的置信度。现有的检测方法要么需要昂贵的重新训练，要么需要改变网络结构，要么会损害干净输入上的性能。", "innovation": "本文展示了对抗性扰动会在CNN激活中生成可立即检测到的熵特征签名，无需对模型进行任何修改即可进行监控。研究者使用VGG-16模型进行并行熵监测，发现对抗性输入在早期卷积层的激活熵比干净输入高7%，准确检测率高达90%，且误报率和漏报率均低于20%。干净和对抗性熵分布的完全分离表明，CNN在其激活模式中固有地编码分布变化。", "conclusion": "本研究证明了CNN的可靠性可以通过激活熵来独立评估，这使得可以实践中部署不损害原模型性能的实时自我诊断视觉系统，用于检测对抗性输入。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21689", "html_url": "https://arxiv.org/abs/2508.21689", "title": "怀疑主义的映射：基于概率的BEV投影用于在线高精地图构建", "title_en": "Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping", "authors": "Fatih Erdoğan,Merve Rabia Barın,Fatma Güney", "background": "构建高定义（HD）地图需要准确地在图像空间中映射道路元素到鸟瞰图（BEV）空间。现有的HD地图构建方法依靠标准的地图技术，如注意力机制，但这些方法在泛化方面存在局限性，往往会错误地判定不存在的道路元素。研究人员需要开发一种既能精确定位又能有效减少不相关道路元素影响的新方法。", "innovation": "提出了一种基于几何映射和平面变换机制的新型概率投影方法，通过结合相机参数进行初步映射，并通过添加置信分数根据不同环境动态调整。此外，利用置信分数在时间维度上选择性地累积可靠信息，从而提高了模型的泛化能力。", "conclusion": "在nuScenes和Argoverse2数据集上的实验结果表明，该方法不仅在新数据集上的性能优于现有最先进的方法，而且特别在nuScenes数据集和长期感知范围内表现更为突出。该研究提供的代码和模型可以在此网址找到：this https URL."}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么要停留在单词？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术将每个字符单独进行切分和识别，这种方法容易在字符切分阶段出错，且无法利用语言模型中的上下文信息。近年来，序列到序列的翻译技术进步促使现代技术首先检测单词，然后每次输入一个单词到模型，直接输出完整的单词序列，从而更好地利用语言模型并绕过了易出错的字符切分步骤。我们注意到上述技术风格的变化已经将准确性的瓶颈转移到了单词切分阶段。因此，本文提出了一种自然且逻辑上的进展，从单词级别的OCR过渡到行级别的OCR。这项提议可以绕过单词检测中的错误，并为更好地利用语言模型提供更大的句子上下文。", "innovation": "本文提出了一种从单词级别的OCR到行级别的OCR的自然进展。该方法绕过了单词检测中的错误，并提供了更大的句子上下文以更好地利用语言模型。我们展示了所提出的技术不仅提高了准确率，还提高了OCR的效率。此外，本文还贡献了一个包含251张英语页面图像和行级注释的精心策划的数据集，以用于训练和基准测试行级OCR的转变。", "conclusion": "我们的实验结果显示，尽管我们进行了彻底的文献调查，但没有找到用于训练和基准测试单词到行级OCR转变的公开数据集。因此，我们还贡献了一个精心策划的包含251张英语页面图像和行级注释的数据集。实验揭示了端到端准确率提高了5.4%，突显了向行级OCR过渡的潜在优势，尤其是在文档图像中。此外，报告了与基于单词的管道相比，效率提高了4倍。随着大型语言模型的持续改进，本方法也有望利用这些进展。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21761", "html_url": "https://arxiv.org/abs/2508.21761", "title": "从沉默和噪音中学习以进行视觉声源定位", "title_en": "Learning from Silence and Noise for Visual Sound Source Localization", "authors": "Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro", "background": "视觉声源定位是基本感知任务，旨在通过视频音频来检测发声源的位置。尽管取得了一定进展，但当前方法仍存在两个不足：1）大部分方法在低音频-视频语义对应情况下表现不佳，例如沉默、噪声和离屏声音，即在存在负面音频的情况下表现较差；2）大部分评价局限于正面情况，即场景中可见声音源的情况下。", "innovation": "1）提出了一种新的训练策略，结合了沉默和噪音，从而提高正面情况下的性能，同时更能抵抗负面声音的影响；2）提出了一个新的量化听觉和视觉特征在正面和负面音频-视频配对中对齐和区分性之间权衡的新指标；3）展示了IS3+扩展和改进版本的合成数据集，包含负面音频数据。我们的模型、指标和代码可于此链接访问。", "conclusion": "我们提出的方法，SSL-SaN，在声源定位和跨模态检索方面均达到当前最佳性能，验证了其有效性和先进性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21712", "html_url": "https://arxiv.org/abs/2508.21712", "title": "FLORA：利用Flux LoRA优化低数据环境下的目标检测合成数据生成", "title_en": "FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA", "authors": "Alvaro Patricio,Atabak Dehban,Rodrigo Ventura", "background": "近年来，基于扩散的生成模型在增强稀少数据集方面显示出显著潜力，特别是在目标检测任务中。然而，大多数最新模型仍依赖于大规模扩散模型的完整微调，这对于资源消耗提出了高要求，通常需要企业级GPU（例如NVIDIA V100）和数千张合成图像。因此，这些模型在计算成本和数据需求方面存在局限性。", "innovation": "我们提出了Flux LoRA Augmentation (FLORA)——一种轻量级的合成数据生成管道，利用Flux 1.1 Dev扩散模型进行微调，仅通过低秩适应（LoRA）。这大大降低了计算需求，使得使用消费级GPU（例如NVIDIA RTX 4090）即可生成合成数据集。我们通过七种不同的目标检测数据集进行了实验评估，结果表明，使用我们方法生成的500张合成图像训练的目标检测器在mAP@.50:.95指标上优于使用ODGEN基准生成的5000张图像训练的模型，最高可提升21.3%。这项工作展示了在高效和质量双重目标下的方法能够超越现有最优性能，FLORA仅使用数据的10%和极小的计算成本，仍能达到优秀效果。这表明在一个注重质量和效率的方法比依赖粗暴生成更为有效，进而让高级合成数据创造更为实用和便捷，更适合现实场景的需求。", "conclusion": "FLORA 演示了一种更高效的合成数据生成方法，仅需10%的数据，就能达到与使用更多数据训练的模型相当甚至更优的效果，显著降低了计算成本，使得该技术更加适合实际应用。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET：用于调整大型视觉-语言模型的数字测量设备CAD模型数据集的合成生成工具", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "近期，大型视觉-语言模型（LVLMs）在各种多模态任务中展示了令人印象深刻的能力，但在读取数字测量设备（DMDs）上的数值等简单场景中仍然表现出色，尤其是在头戴式相机和增强现实（AR）应用等实际条件下，涉及杂乱、遮挡、极端视角和运动模糊等常见情况。本文基于这些不足提出了CAD2DMD-SET工具，旨在支持涉及DMDs的视觉问答（VQA）任务。该工具利用3D CAD模型、高级渲染和高清图像合成生成多样化的、带有VQA标签的合成DMD数据集，以用于LVLMs的微调。此外，还提出了DMDBench数据集，包含1,000张带有注释的真实世界图像，用于在实际条件下评估模型性能。使用差分数值平均Levenshtein相似度（ANLS）进行基准测试，并进一步用CAD2DMD-SET生成的数据集微调这些模型，取得了显著进步，尤其是对于InternVL，其得分提高了200%。这项研究表明，使用CAD2DMD-SET培训数据集大大提高了LVLMs在先前提到的具有挑战性条件下的鲁棒性和性能。", "innovation": "提出了CAD2DMD-SET，一种用于模仿真实世界条件生成大量多样化的DMD数据集的工具，提供用于LVLMs微调的性能改进，并构建了DMDBench，一个用于验证模型在实际应用条件下性能的真实世界图像标注数据集。进一步微调LVLMs模型并测试其性能表现，验证了其有效性和实用性，同时也强调了在复杂环境下训练数据的重要性。", "conclusion": "CAD2DMD-SET工具显著提高了LVLMs在读取DMDs数值等具有挑战性条件下的性能和鲁棒性。为了进一步推动该领域的研究和发展，CAD2DMD-SET工具将作为开源工具发布，方便社区添加不同的测量设备并生成自定义数据集。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "无监督视频连续学习通过非参数深度嵌入聚类", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频是一个复杂的时空多媒体信息，广泛应用于各种场景，但在无监督连续学习中尚未充分利用。多数研究集中在有监督的连续学习上，依赖标签和任务边界，然而获取带标签的数据很昂贵且不理想。因此，本文研究了无监督视频连续学习（uVCL），这是一个更具挑战性的任务，因为处理视频相比于处理图像需要更多的计算和内存资源。", "innovation": "本文提出了一种非参数学习解决方案来解决无监督视频连续学习的不足问题。具体创新点包括：1. 提出了一种基于无监督视频变换网络提取的深度嵌入视频特征的核密度估计（KDE）方法，作为数据的非参数概率表示；2. 引入了一种新颖检测准则，用于检测新任务数据，动态扩展记忆簇，以便在连续学习任务时捕捉新的知识；3. 利用先前任务的迁移学习作为当前学习任务的知识迁移初始化状态。实验结果表明，所提出的方案在三个标准视频动作识别数据集上表现优异。", "conclusion": "本文通过引入无监督视频连续学习的一般基准实验协议和非参数深度嵌入聚类方法，显著增强了连续学习多个任务时模型的性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "困惑在于歧义：重新审视单正多标签学习的场景识别", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "场景识别（SR）是计算机视觉中的基础任务，旨在通过识别关键事件及其相关实体来从图像中提取结构化的语义摘要。现有方法通常将动词分类视为单标签问题，但研究表明，由于多个动词类别可能合理描述同一张图像，这种表述未能解决视事件识别中的固有歧义。", "innovation": "本文提出了三个主要贡献：1）通过实验分析表明，由于动词类别的广泛语义交叉，动词分类本质上是多标签问题。2）鉴于全面标注大规模数据集的多重标签以标注的不切实际，提出了将动词分类重新定义为单正多标签学习（SPMLL）问题，对SR研究提出了新的视角。3）设计了全面的多标签评估基准，以公平地评估模型在多标签设置中的性能。此外，开发了Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP)，结合图神经网络捕捉标签相关性，同时使用对抗训练优化决策边界，以应对SPMLL带来的挑战。", "conclusion": "实验证明，该方法在多标签设置中实现超过3%的MAP改进，同时在传统的top-1和top-5准确率指标上具有竞争力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21775", "html_url": "https://arxiv.org/abs/2508.21775", "title": "多阶段微调和集成策略用于诊断和治疗MRI中的胰腺肿瘤分割", "title_en": "A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI", "authors": "Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein", "background": "胰腺导管腺癌（PDAC）的磁共振成像（MRI）自动化分割对临床工作流程至关重要，但受到肿瘤组织对比度差和标注数据稀缺的限制。本文研究旨在解决PANTHER挑战中的诊断T1加权（Task 1）和治疗T2加权（Task 2）分割问题。", "innovation": "本文提出一种多阶段微调和集成策略，基于nnU-Net框架，利用深度多阶段串行预训练方法，首先从通用解剖基础模型开始，逐步微调于CT胰腺病变数据集和目标MRI模态。通过五折交叉验证，系统评估了数据增强方案和训练计划，提出了一种基于度量的集成策略，构建了专家模型的定制异质集成，取得了优异的分割结果。", "conclusion": "该研究提出的方法在数据有限和医学影像复杂任务背景下，提供了一种开发特殊高精度模型的稳健方法，特别是在Task 1中获得了0.661的Top交叉验证肿瘤Dice分数，Task 2中为0.523。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21767", "html_url": "https://arxiv.org/abs/2508.21767", "title": "UItron：具备高级感知与规划能力的基础GUI代理", "title_en": "UItron: Foundational GUI Agent with Advanced Perception and Planning", "authors": "Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma", "background": "GUI代理旨在实现移动/PC设备上的自动化操作，是实现通用人工智能的重要任务。随着视觉语言模型（VLMs）的迅速发展，其强大的视觉理解和任务规划能力加速了GUI代理的发展。然而，构建GUI代理仍然是一项具有挑战性的任务，原因在于操作轨迹的缺乏、交互基础设施的可用性限制以及基础模型初始能力的局限性。", "innovation": "UItron是一个开源基础模型，具备高级GUI感知、语义定位和规划能力。UItron研究了一系列数据工程策略，通过监督微调来提升训练效果，并建立了连接移动和PC设备的交互环境。在训练中，采用监督微调和课程强化学习框架，使GUI代理能够在复杂的在线环境中进行复杂推理和探索。UItron特别在与顶级中文移动APP的交互能力上表现出色，通过手动收集了超过一百万次操作轨迹，建立了离线和在线代理评估环境。结果显示，在中文应用场景中取得了显著进展，大大推进了GUI代理的实际应用能力。", "conclusion": "UItron在GUI感知、语义定位和规划基准测试中表现出色，尤其是提升了在顶级中文移动应用中的交互能力。通过系统性的数据工程策略和交互环境，UItron推进了GUI代理开发，使它们更接近于实际应用。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21770", "html_url": "https://arxiv.org/abs/2508.21770", "title": "从哈利波特学习什么？关于异常视频的视觉表示学习探讨", "title_en": "What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos", "authors": "Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao", "background": "人类在开放世界中通常展现出出色的泛化和发现能力，特别是在展示新的罕见概念时。然而，大多数现有的文献研究集中在封闭集中的常见典型数据上，开放世界的新发现尚未在视频中得到充分探索。本文探讨了在学习过程中引入异常数据（例如科幻、动画等）可能带来的影响，并且通过新的数据集和三个关键任务（非分布外检测、新类别发现和零样本动作识别）的研究，发现了异常数据对视觉表示学习的好处。", "innovation": "本文提出了一个新的视频数据集，包含各种类型的异常数据，通过在模型训练过程中使用这种数据，对开放世界学习中三个关键任务（非分布外检测、新类别发现和零样本动作识别）的影响进行了研究。研究发现即使是简单的学习方法，在异常数据上也能持续改进表现，且在非典型样本类别多样性提高时，非分布外检测效果更好。此外，在新类别发现任务中，使用更小但更具语义多样性的非典型样本集较之更大的更典型的样本集性能更好。制典型视频的语义多样性帮助模型更好地泛化到未见过的动作类别中。这些发现揭示了异常视频对开放世界视觉表示学习的好处，并提出了一个新的数据集，这为该领域进一步的研究提供了新的方向。", "conclusion": "通过在开放世界的三个关键任务中使用异常数据进行模型训练，可以显著提高模型的性能，尤其是在非单调类检测和未见过的动作类别的零样本识别中。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "域适应在实际场景中的评估：从域感知表示中解构分类", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评估基础模型如CLIP的域适应能力具有挑战性，因为用于大规模预训练的数据可能涵盖了多种已有的基准测试场景。当前的域适应评估可能不够具有挑战性，并且可能无法充分测试真正的未见数据场景。因此，通过更好地评估CLIP在实际环境中处理未见数据的能力来改进现有方法是必要的。为此，文章讨论了两种方法：一是对33个不同的数据集进行微调后，基于量化之外分布（OOD）得分进行评估；二是通过遗忘某些领域来使CLIP在接近实境的复杂未见数据场景下进行学习。", "innovation": "提出了一种名为CLIP-DCA的方法，其创新之处在于该方法通过一个单独的领域头和合成生成的多样化领域数据来识别和增强CLIP编码器中的域感知能力。同时，CLIP-DCA通过从领域特征中分离进行解构，鼓励域不变的分类。这种方法在复杂的域适应评估中相较于现有方法取得了显著的改进，特别是在更多的OOD数据集上表现尤为明显。这篇文章的创新点在于明确提出了增强领域感知能力作为有效的域不变分类的前提，并实际地展示了这一思想的有效性。", "conclusion": "CLIP-DCA方法在复杂的域适应评估中取得了显著的改善，特别是对于更多的OOD数据集。这项工作强调了增强领域感知能力作为基础模型实现有效域不变分类的必要性，并证明了CLIP-DCA的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 使用文本记忆库增强统一异常检测模型的逻辑能力", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "由于可用的正常数据有限，异常检测（旨在识别偏离正常模式的异常）是一个挑战。现有的统一方法依赖于精心设计的图像特征提取器和记忆库，以捕捉对象之间的逻辑关系。然而，这些方法缺乏在检测逻辑异常时利用文本信息的能力。这篇论文提出了一种新的框架，通过引入文本记忆库来提升逻辑异常检测的能力，从而有效地解决了这一问题。", "innovation": "提出了一个名为TMUAD的三项记忆框架，包含了三个互补的记忆库，分别是类级别文本记忆库、对象级别图像记忆库和单元级别图像记忆库。这些记忆库协同工作，用于检索和比较与查询图像最相似的正常图像，计算多个层级的异常得分，并将它们融合为最终的异常得分。这种方法实现了对七个公开数据集（涉及工业和医疗领域）的顶级性能，数据可在给定的网址获得。", "conclusion": "TMUAD通过协作式的记忆库统一了结构和逻辑异常检测，实现了领先的技术性能，该模型和代码现在可以在给定的网页地址中访问。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中的GPT-5基准测试：可测量的进步，但持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大语言模型（LLM）在临床决策支持方面显示出很大的潜力。GPT-5是专门针对肿瘤学用途推出的一款新型LLM系统。研究团队评估了GPT-5在放射肿瘤学中的表现，并将其与GPT-4和GPT-3.5进行了比较，使用了两次互补的基准测试：ACR放射肿瘤学住院医师考试（TXIT，2021）和60例真实的放疗科病例集，评估了治疗计划的生成情况。这些评估涵盖了多个疾病部位和治疗手段，包括剂量和诊断等方面的关键指标。实验结果表明，GPT-5在多项选择题意义上的表现优于之前的模型，并在特定领域（如剂量和诊断）取得了最大的进步。“", "innovation": "GPT-5是一个针对肿瘤学用途设计的新型大语言模型系统。研究表明，GPT-5在放射肿瘤学的多项选择题基准测试中表现优异，并在特定领域如剂量和诊断方面获得了显著的成效。此外，GPT-5生成的治疗建议的正确性和完整性很高，并且几乎没有出现幻觉的情况。尽管如此，其专业判断的变异性和复杂情况中的错误仍表明了需要进一步改进和专家监督的必要性。", "conclusion": "GPT-5在放射肿瘤学的多项选择题基准测试中表现出色，尤其是在剂量和诊断方面。生成的治疗建议在正确性和完整性方面受到了高度评价，但错误仍存在，需要专家监督才能用于临床实践。尽管如此，GPT-5在放射肿瘤学应用中仍然显示出显著的进步，但仍需进一步优化和改进。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21095", "html_url": "https://arxiv.org/abs/2508.21095", "title": "ScanMove: 未注册体表面网格的运动预测和转移", "title_en": "ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes", "authors": "Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi", "background": "未注册的表面网格，尤其是原始3D扫描数据，对自动计算合理变形提出了重大挑战，主要因为缺乏明确的点间对应关系和数据中的噪声问题。", "innovation": "提出了一个新型、无需刚体约束的数据驱动框架，用于未注册的体表面网格上的运动预测和转移。该方法结合了一个稳健的动力学嵌入网络和一个学习到的每顶点特征场，以生成时空变形场，驱动网格变形。", "conclusion": "通过在行走和跑步等任务上的广泛评估，包括定量基准和定性可视化，证明了本方法在具有挑战性的未注册网格上的有效性和灵活性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "本文探讨了使用强化学习（RL）进行视觉引导的四足机器人运动控制问题，并强调了将本体感觉与视觉结合使用以实现稳健控制的必要性。背景研究中，指出传统的视觉引导控制存在样本效率低、动作抖动和能量消耗高的问题。为了解决这些问题，研究提出了一个名为QuadKAN的框架，旨在提供一种简单、有效且可解释的模型来实现视觉引导下的四足运动控制。", "innovation": "QuadKAN框架提出了一种使用Kolmogorov-Arnold网络（KANs）实例化的spline参数化的跨模态策略，并结合了本体感觉编码器和本体感觉-视觉输入融合头部，以结构化函数类拟合状态到运动映射，适合于节律的片段化性质。研究还引入了多模态延迟随机化（MMDR）并使用Proximal Policy Optimization（PPO）进行端到端的训练。实验结果表明，该框架在各种地形条件下能够实现更高的回报、更远的距离和更少的碰撞，优于现有SOTA基线模型。", "conclusion": "研究证明，spline参数化的策略为稳健的视觉引导式四足机器人移动提供了一种简单、有效且可解释的替代方案。研究成果将于正式接受后开源。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21809", "html_url": "https://arxiv.org/abs/2508.21809", "title": "VoCap：来自任何提示的视频对象描述及分割", "title_en": "VoCap: Video Object Captioning and Segmentation from Any Prompt", "authors": "Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid", "background": "视频理解中对视频中的对象进行细粒度的空间-时间定位掩膜和详细的语义属性的理解是一个基本任务。研究者们提出了一种灵活的视频模型VoCap，它能够接受视频和不同模态的提示（文本、框或掩膜），并产生相应的空时掩膜和对象中心描述。该模型同时解决可提示的视频对象分割、引用表达分割和对象描述等任务。然而，获得用于训练的数据既麻烦又昂贵，因此研究者提出在现有的大规模分割数据集（SAV）上伪标注对象描述，并通过预处理视频和其地面真实掩膜来突出感兴趣的对象，进而将处理后的视频输入大型视觉语言模型（VLM）。为了进行公正的评估，收集了验证集的手动注释。由此得到的dataset叫SAV-Caption。", "innovation": "研究者提出了一种新的模型VoCap，它可以接受多种模态的提示，并生成相应的空时掩膜和描述对象的句子，兼解决三个相关任务。同时，研究者提出了一种新的数据收集方法，即在现有的大规模分割数据集上伪标注对象描述，以此解决缺乏标注数据的问题，并通过预处理视频和其地面真实掩膜来突出感兴趣的对象，最终生成名为SAV-Caption的新dataset。该模型在引用表达视频对象分割上达到了业界最佳效果，在半监督的视频对象分割上也非常有竞争力，首次建立了视频对象描述的基准。", "conclusion": "研究者训练了VoCap模型，并在SAV-Caption数据库和其他图像、视频数据集上的混合数据下进行了大规模训练。该模型在引用表达视频对象分割任务上达到了业界最佳结果，在半监督视频对象分割任务上的表现也很突出，同时还建立了视频对象描述的基准。研究者将来会将此dataset提供给其他研究者进行使用。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21344", "html_url": "https://arxiv.org/abs/2508.21344", "title": "ARGS: Advanced Regularization on Aligning Gaussians over the Surface", "title_en": "ARGS: Advanced Regularization on Aligning Gaussians over the Surface", "authors": "Jeong Uk Lee,Sung Hee Choi", "background": "3D Gaussian Splatting (3DGS)技术在计算机图形学中仍然是一个核心挑战。尽管已有模型如SuGaR提供了有效的渲染解决方案，但仍然需要提高视觉保真度和场景一致性。", "innovation": "该研究基于SuGaR模型引入了两种互补的正则化策略，以克服单个高斯个体形状和整体表面连贯性的常见限制。第一种策略引入了有效的秩正则化，通过偏好更平衡的“盘状”形状，避免极端的“针状”形状，以促进稳定的表面重建。第二种策略结合了神经 Signed Distance Function (SDF)来优化过程，并通过Eikonal损失来维持适当的距离特性，从而提供连续的全局表面先验，引导高斯点更好地与基础几何对齐。这两项正则化策略旨在提高单个高斯原语的保真度及其整体表面行为的统一性，从而生成更准确且一致的视觉效果。", "conclusion": "最终模型能够从3DGS数据中产生更准确且一致的视觉效果。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21271", "html_url": "https://arxiv.org/abs/2508.21271", "title": "基于3D卷积神经网络的小型自动驾驶汽车驾驶", "title_en": "Mini Autonomous Car Driving based on 3D Convolutional Neural Networks", "authors": "Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando", "background": "随着自动驾驶应用在汽车行业的日益重要，它们有望提高车辆的安全性、效率和用户体验，以满足日益增长的高级驾驶辅助系统需求。然而，开发可靠的自动驾驶系统面临着复杂性高、训练时间长以及固有不确定性等挑战。为此，研究使用了Mini Autonomous Cars（MACs）作为测试平台，以简化自动驾驶控制方法的验证。这种成本效益高的环境有助于快速评估和比较机器学习模型。为了应对这些挑战，本文提出了基于RGB-D信息和三维卷积神经网络（3D CNN）的方法来实现MAC中的类自动驾驶驾驶，并在两个具有不同环境特征的模拟赛道上训练和测试了RNN架构。评测指标包括任务完成成功率、圈速和驾驶一致性。结果表明，架构修改和赛道复杂性影响模型的一般能力和车辆控制性能。与RNN相比，提出的3D CNN展示了良好的结果。", "innovation": "本文提出了一种基于RGB-D信息和三维卷积神经网络的方法来实现MAC中的自主驾驶，并在两个具有不同环境特征的模拟赛道上评估了该方法。通过使用任务完成成功率、圈速和驾驶一致性进行评估，结果显示该方法在模型的一般能力和车辆控制性能上具有良好的表现。", "conclusion": "实验结果表明，基于3D CNN的方法在评估的两个轨道上展示了良好的性能，特别是在模型的一般能力和车辆控制性能方面。这为自动化的实现提供了一种有效的方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21635", "html_url": "https://arxiv.org/abs/2508.21635", "title": "The Rosario Dataset v2: 多模态农业机器人数据集", "title_en": "The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics", "authors": "Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire", "background": "本文介绍了在大豆田中收集的多模态数据集，包含超过两小时的传感器数据记录，如双目红外相机、彩色相机、加速度计、陀螺仪、磁力计、GNSS（单点定位、实时 kinematic 和后处理 kinematic）以及车轮里程计。该数据集捕捉了农业环境中机器人技术所面临的诸多挑战，如自然光线变化、运动模糊、崎岖地形和长时间的相位失真序列。通过解决这些复杂性，数据集旨在支持农业机器人中定位、制图、感知和导航算法的开发与基准测试。", "innovation": "该数据集致力于解决农业环境中多模态 SLAM（同时定位与地图构建）系统的评估关键需求，包括硬件传感器同步、6 自由度全轨迹的真实性以及长轨迹上的闭环结构。此外，文章展示了目前最先进的多模态 SLAM 方法在农业环境中的应用限制。", "conclusion": "该数据集及相关工具已公开发布，旨在推动农业机器人技术领域的发展，为相关算法的评估和改进提供重要支持。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这张图表在欺骗我吗？自动检测误导性图表。", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性图表是社交媒体和网络中传播误导信息的一个强大驱动因素。它们通过违反图表设计原则来扭曲数据，导致读者得出不准确的结论。之前的研究表明，无论是人类还是多模态大型语言模型（MLLMs）都会经常被这样的图表所欺骗。自动检测误导性图表和识别它们违反的具体设计规则可以帮助保护读者并减少信息传播的错误。然而，由于缺乏大规模、多样且开放获取的数据集，AI模型的训练和评估受到了限制。", "innovation": "本文引入了一个名为Mizviz的数据集，包含2,604个具有12种误导类型的标注真实图表。为了支持模型训练，还发布了Mizviz-synth数据集，通过Matplotlib生成了81,814个基于真实数据表格的图形。对这两个数据集使用最先进的MLLMs、基于规则的系统和微调分类器进行了全面评估。", "conclusion": "我们的研究结果揭示了该任务仍然具有高度挑战性。我们发布了Mizviz、Mizviz-synth以及配套代码。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V？", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来， multimodal大型语言模型（MLLMs）在编码、数学和科学等复杂任务中表现出色，然而，这些模型在处理未受污染的、包含基础形状和结构的生成图像的简单感知任务中，几乎没有进行过相关的实验评估。因此，有必要进行相关研究以填补这一空白。", "innovation": "本文介绍了一个名为Percept-V的数据集，其中包含7200张由程序生成的图像，分为30个类别，每个类别检测不同视觉感知技能的组合。与之前的数据集不同，Percept-V包含了一些测试MLLMs基础感知能力的非常基本且具有不同复杂度的任务。此外，该数据集被用于评估最新的MLLMs（如GPT-4o、Gemini、Claude）和大型推理模型（LRMs，如OpenAI o4-mini和DeepSeek R1），以检测它们在复杂性增加时的性能下降情况，揭示了这些模型在不同认知技能测试中的表现趋势。", "conclusion": "我们的实验结果表明，MLLMs在不同类别的复杂性增加时，性能出现了显著下降。分析表明，所测试的MLLMs在不同类别中的准确性表现出一定的趋势，某些技能比其他技能更为困难。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21824", "html_url": "https://arxiv.org/abs/2508.21824", "title": "DriveQA: 掌握驾驶知识测试", "title_en": "DriveQA: Passing the Driving Knowledge Test", "authors": "Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar", "background": "如果一个大型语言模型（LLM）今天参加驾驶知识测试，它会通过吗？驾驶知识测试不仅涵盖了当前自动驾驶基准上的标准空间和视觉问题回答任务，还要求全面理解所有交通规则、标志和优先通行原则。人类驾驶员需要识别现实中很少出现的边缘情况，才能通过这项测试。本研究旨在通过DriveQA这一全面的开源文本和视觉基准，来涵盖交通法规和场景。实验表明，先进的LLM和多模态LLM在基本交通规则上的表现良好，但在数值推理、复杂优先权场景、交通标志变化和空间布局等方面存在显著缺陷。", "innovation": "研究表明，通过DriveQA的微调可以在多个类别中提高准确度，尤其是在交通标志识别和交叉路口决策方面。DriveQA-V对环境因素（如照明、视角、距离和天气条件）的受控变化提供了深入见解。此外，预训练在DriveQA上的应用提升了下游驾驶任务的性能，并在诸如nuScenes和BDD等实际数据集上取得了更好的结果，表明模型可以将文本和合成交通知识内化，以提高下游问题回答任务的一般泛化能力。", "conclusion": "在使用DriveQA的效果实验中，我们发现最新的LLM和多模态LLM在基础交通规则上表现良好，但在复杂优先通行情况、交通标志变化和空间布局方面表现较差。通过DriveQA进行微调可以提升各类情况下的准确性，尤其是对交通标示识别和交叉路口出行决策。此外，通过对DriveQA的差异化训练能够发现模型对环境因素的敏感性，预训练在DriveQA上使下游驾驶任务性能提升显著，在真实数据集上的表现也获得提高，模型能够将文本和合成交通知识内化，以提高在各种下游问题回答任务上的泛化表现。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "Morae：主动暂停UI代理以供用户选择", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "用户界面（UI）代理为盲人和低视力（BLV）用户提供了访问复杂或不直观的UI界面的可能性。然而，现有的UI代理通常会自动处理任务，而不会让用户参与重要的选择或告知他们关键的上下文信息，从而限制了用户的主动权。例如，在一项实地研究中，BLV参与者要求购买最便宜的碳酸水，但代理自动从多个同等价格的产品中选择了一个，而没有提及具有不同口味或更好评价的替代产品。", "innovation": "作者介绍了一个名为Morae的UI代理，该代理能够在任务执行过程中自动识别决策点，并暂停操作以让用户进行选择。Morae结合了大型多模态模型来理解用户查询、UI代码和屏幕截图，并在需要选择时向用户提供澄清。", "conclusion": "在真实世界的网络任务研究中，使用Morae的BLV参与者能够完成更多的任务，并选择更符合他们偏好的选项，这与基础代理，如OpenAI Operator相比更为出色。更广泛地说，这项工作展示了一种混合式的交互方式，在这种方式中，用户可以从UI代理的自动化中受益，同时可以表达他们的偏好。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 用于医学多模态大型语言模型奖赏模型和评判者的基准测试", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医学应用中具有巨大潜力，如疾病诊断和临床决策。然而，这些任务需要高度准确、上下文敏感且专业对齐的响应，这使得可靠的奖赏模型和评判者成为关键。尽管如此，医学奖赏模型（MRMs）和评判者的研究还很少，也没有专门针对临床需求的基准测试工具。现有的基准测试多关注MLLM的一般能力或将其作为求解器评估，忽略了诊断准确性和临床相关性等重要评估维度。因此，作者引入了Med-RewardBench，这是第一个专门设计用于评估医学场景中MRMs和评判者的基准测试工具，该工具覆盖13个器官系统和8个临床部门的1026个专家标注案例，并通过三项严格的流程确保高质量的数据评估六个临床关键维度。", "innovation": "该论文创新之处在于提出了Med-RewardBench，这是首个专门用于评估医学场景中MRMs和评判者的基准测试工具。它覆盖了大量的医学案例，通过专门设计的数据集和评估流程确保了评估的高质量。此外，论文还评估了多种最先进的MLLMs，揭示了与专家意见对齐的挑战，并通过微调开发了基线模型，证明了显著的性能提升。", "conclusion": "通过对32种最先进的MLLMs进行评估，论文揭示了在医学场景中将输出与专家判断对齐的巨大挑战，并证明了通过微调可以显著提高基线模型的性能。Med-RewardBench 为医学领域的研究提供了一个重要的基准测试工具，有助于进一步改进医学相关的大规模语言模型。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "Activización de Subespacios para Detección de Datos Fuera del Domíno", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "在现实世界应用中确保深度模型的可靠性，出域检测（OOD）方法旨在区分训练分布（ID）附近的样本与远离的样本。现有方法在不同分布偏移程度下，对ID和OOD数据的区分效果存在差异。研究人员发现，实值激活在大分布偏移时区分效果不佳，而在小分布偏移时，考虑有决定性的子空间可以有效减少干扰。", "innovation": "提出了一个新颖的OOD检测方法，通过分类头权重矩阵的奇异值分解，将模型的激活分解为对最终分类器输出贡献最大的重要子空间和贡献最小的微不足道子空间。这种方法结合了大偏移量时重点关注微不足道子空间和小偏移量时关注重要子空间的优点，从而在多种标准的OOD基准上取得了最先进的结果。", "conclusion": "通过结合两大发现，提出了一种称为ActSub的方法，成功在各种OOD基准测试中取得了当时最先进的成果。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "从异质数据中学习统一表示以实现稳健的心率建模", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化健康管理及健身至关重要，但其在实际部署时经常面临关键挑战：数据异质性。现有的方法要么丢弃设备特定的信息，要么无法建模用户特定的差异，这限制了它们在实际环境中的性能。数据异质性主要体现在设备来源异质性和用户来源异质性上，前者来源于具有不同功能集的设备市场碎片化，后者则反映个体和活动间的独特生理模式。", "innovation": "本文提出了一种框架，该框架可以学习对两大数据异质性不敏感的潜在表示，从而使得下游预测器在异质数据模式下能够稳健工作。为处理设备异质性，引入了随机特征下采样策略，使模型对不同特征集具有鲁棒性。为管理用户异质性，采用时间感知注意模块捕捉长期生理特征，并使用对比学习目标创建具有区分性的表示空间。为了反映真实数据的异质性，还创建并公开发布了一个新的基准数据集ParroTao。", "conclusion": "在ParroTao和公共FitRec数据集上的评估表明，我们的模型分别比现有基线高出17%和15%的表现。进一步分析证明，所学习的表示具有强大的区分力，一个下游应用任务也证实了我们模型的实际价值。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.01627", "html_url": "https://arxiv.org/abs/2408.01627", "title": "JambaTalk：基于混合Transformer-Mamba模型的语音驱动3D面部生成", "title_en": "JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model", "authors": "Farzaneh Jafari,Stefano Berretti,Anup Basu", "background": "近年来，面部动画生成成为了研究人员关注的焦点。虽然已经投入了大量努力来优化唇同步运动、捕捉面部表情、生成自然头部姿态并实现高质量视频，但没有单一模型能够在所有定量和定性指标上达到同等水平。为了解决传统Transformer模型在处理长序列时的局限性，本文介绍了一种结合Transformer和Mamba模型的混合模型Jamba，以动画化3D面部。", "innovation": "本文提出了JambaTalk，这是一种基于混合Transformer-Mamba模型的面部动画生成方法，能够通过多模态集成增强运动多样性和唇同步质量。Jamba结合了Transformer和Mamba的优点，克服了传统模型处理长序列的限制。", "conclusion": "在广泛的实验中，本文的方法在性能上达到了与当前最先进的模型相当或更优的水平。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08420", "html_url": "https://arxiv.org/abs/2403.08420", "title": "基于基础模型的低成本实时工业动作识别框架", "title_en": "ALow-Cost Real-Time Framework for Industrial Action Recognition Using Foundation Models", "authors": "Zhicheng Wang,Wensheng Liang,Ruiyan Zhuang,Shuai Li,Jianwei Tan,Xiaoguang Ma", "background": "工业环境中的动作识别（AR），尤其是在识别动作和操作手势方面，面临着高部署成本、跨场景泛化能力差以及实时性能有限的挑战。", "innovation": "本文提出了一种基于基础模型的低成本实时工业动作识别框架（LRIAR），通过结合预训练的BLIP-2图像编码器与Grounding DINO，自动构建标记数据集，利用YOLOv5进行实时动作检测，并通过LoRA基线微调Vision Transformer（ViT）分类器进行动作分类，从而提高识别准确性、泛化能力和部署效率，同时减少人力标注和计算开销。", "conclusion": "实验结果表明，LRIAR在现实工业环境中有效，相比现有最先进的方法，在识别准确率、泛化能力和部署效率上均有所改进。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21738", "html_url": "https://arxiv.org/abs/2508.21738", "title": "从无人机影像到宜居性测绘：AI赋能的农村环境感知", "title_en": "From Drone Imagery to Livability Mapping: AI-powered Environment Perception in Rural China", "authors": "Weihuan Deng,Yaofu Huang,Luan Chen,Xun Li,Yao Yao", "background": "随着扶贫和乡村振兴战略的深化，提高农村人居环境和提升生活质量已成为关键任务。农村宜居性是衡量这些努力是否有效的重要指标。现有的评估方法存在明显局限性，问卷调查方法难以推广，而城市导向的视觉感知方法在农村环境中不适用。因此，本研究基于无人机影像和多模态大规模语言模型，提出了一种专门针对农村的宜居性评估框架，以全面评估村庄的宜居性。", "innovation": "该研究提出了一个基于无人机影像和多模态大型语言模型的农村特定宜居性评估框架。首先，通过自上而下方法收集中国146个县1,766个村庄的大规模无人机影像。其次，研究发展了一种高效的形象比较机制，利用二分查找插值确定有效的影像对，减少比较迭代次数。最后，研究了中国的农村宜居性的空间异质性和其影响因素，结果显示，中国农村的宜居性呈现出核心-边缘的空间模式，并且政府财政支出对宜居性的影响最大，每增加一个单位，宜居性就提升3.9至4.9个单位。", "conclusion": "研究结果显示，中国的农村宜居性呈现出核心-边缘的空间模式，从四川和浙江向外辐射，政府财政支出是最重要的影响因素。这为农村建设政策制定提供了宝贵见解。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "矩形区域注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "在传统的卷积网络中，通常采用位置无关的注意力机制，即在固定的位置上生成注意力图，这往往会导致注意力边界的不规则性，影响模型在新样本上的泛化能力。", "innovation": "本文提出了一种可轻松集成到任何卷积网络中的新颖的空间注意力模块。该模块通过在端到端训练中引导模型关注图像的最具区分度的部分，提高模型性能。此外，本文的注意力区域被限制为矩形，并且仅由5个参数参数化，从而提高了模型的稳定性和对新样本的泛化能力。", "conclusion": "实验结果表明，本文的方法系统地优于位置无关的同类方法，提供了一种新颖而有用的卷积模型空间注意力机制，同时也提高了模型的可解释性，特别是对于“模型关注哪里”这一问题的解释提供了帮助。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型的大肠3D形状精炼及其在数字模拟体生成中的应用", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的人体器官3D建模对于虚拟成像试验中的数字模拟体构建至关重要。然而，由于其复杂的几何形状和形状变化，大肠等器官的建模仍然具有挑战性。现有的方法虽然可以构建点云表示，但在形状建模准确性上仍存在改进空间。本文讨论了CLAP模型，这是一种结合几何深度学习和去噪扩散模型的新型条件潜点扩散模型，以提高大肠的3D表示精度，从而克服当前建模过程中的局限性。该模型能够学习全局和局部的潜形状表示，并通过两个条件扩散模型在潜空间内进一步细化器官形状，最终使用预训练的表面重建模型将细化后的点云转换为网格，从而提高建模精度，减少了成形距离和hausdorff距离。", "innovation": "CLAP模型结合了几何深度学习和去噪扩散模型，创新性地使用了分布式潜空间来细化大肠的3D形状，并通过两个条件扩散模型在潜空间内进一步优化形状。此外，使用预训练的表面重建模型将点云转换为网格，从而显著提高了形状建模的准确性。该模型在形状建模方面实现了26%的Chamfer距离和36%的hausdorff距离的改善，体现了该方法的有效性和适应性。", "conclusion": "CLAP模型提供了一种稳健且可扩展的高保真器官建模方法，对于广泛的人体解剖结构具有潜在的应用价值。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种用于视网膜 fundus 图像中固有可解释性疾病检测的混合全卷积 CNN-Transformer 模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "在许多医疗影像任务中，卷积神经网络（CNNs）能够有效地逐层提取局部特征。最近，基于自我注意力机制的视觉变压器（ViTs）受到关注，能够捕捉全局依赖关系，但缺乏卷积的固有空间定位能力。因此，研究人员开始开发结合 CNNs 和 ViTs 的混合模型，以融合两者的优点。然而，这些混合模型难以解释，导致其在医疗影像中的应用受到限制。", "innovation": "本文提出了一种设计上具有可解释性的混合全卷积 CNN-Transformer 架构，专门用于视网膜疾病检测。与目前广泛使用的针对 ViT 的事后解释方法不同，该方法生成了直接反映模型决策过程的忠实且局部化的证据图。该模型在两个专注于视网膜疾病检测的医疗任务中，通过颜色视网膜图像评估了其性能，结果表明其在预测性能上优于黑盒和可解释模型，并且能够在单次前向传播中提供类特定的稀疏证据图。代码可以在指定的网址下载。", "conclusion": "该模型在视网膜 fundus 图像中的疾病检测任务中实现了最先进的预测性能，并提供类特定的稀疏证据图。同时，该模型的设计使得解释其决策过程变得容易，有助于其在医疗领域的实际应用。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口指导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导技术是扩散模型中广泛使用的方法，用于提升样本质量。这项技术通过使用一个比主模型更加通用的辅助模型来实现。之前的研究表明，当辅助模型的泛化错误与主模型相似但更强时，这种方法特别有益。基于这一发现，本文引入了一种名为Masked Sliding Window Guidance (M-SWG)的新颖且无需训练的方法，通过选择性地限制主模型的感受野来增强长期空间依赖关系的权重。", "innovation": "本文提出的M-SWG方法是一种无需训练、无需访问先前迭代的模型权重且无需额外训练或类别条件指导的方法，通过选择性地限制主模型的感受野来增强长期空间依赖关系的权重。M-SWG在与之前最先进的无训练方法相比时，取得了更好的Inception分数（IS），且未引入样本饱和问题。此外，通过与现有指导方法结合使用，M-SWG在使用EDM2-XXL和DiT-XL的前提下，达到了在ImageNet上Fréchet DINOv2距离的新纪录。", "conclusion": "M-SWG在无需训练、无需访问过往迭代信息和不需要类别条件指导的情况下，通过选择性地限制主模型的感受野来增强长期空间依赖关系的权重，实现了优于先前工作的Inception分数（IS），并且在结合现有指导方法后，实现了在使用EDM2-XXL和DiT-XL时ImageNet上Fréchet DINOv2距离的最新记录。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14156", "html_url": "https://arxiv.org/abs/2502.14156", "title": "Mixed Signals: 多样性点云数据集用于异构LiDAR V2X协作", "title_en": "Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration", "authors": "Katie Z Luo,Minh-Quan Dao,Zhenzhen Liu,Mark Campbell,Wei-Lun Chao,Kilian Q. Weinberger,Ezio Malis,Vincent Fremont,Bharath Hariharan,Mao Shan,Stewart Worrall,Julie Stephany Berrio Perez", "background": "车辆到一切（V2X）协同感知已经成为解决单车辆感知系统局限性的有前途的解决方案。然而，现有的V2X数据集在范围、多样性和质量上都存在不足。因此，需要一种能够覆盖更广泛场景、更具多样性和高质量的数据集来应对这些不足之处以推动V2X技术的发展和应用。", "innovation": "我们提出了一种全面的V2X数据集——Mixed Signals，它包含了来自三个连接的自动驾驶车辆（CAVs）的45100个点云和240600个边界框的数据，并且这些车辆装备了两种不同配置的激光雷达传感器以及一个路边单元带有双激光雷达。该数据集覆盖了10个类别，并提供点云和边界框注释。我们对数据集的质量进行了详细的统计分析，并在该数据集上广泛评估了现有的V2X方法。Mixed Signals数据集易于使用，具有精确的时间和视角一致性注释。", "conclusion": "Mixed Signals数据集适用于V2X系统的感知训练，并提供了可靠的多焦距数据，有助于提升V2X方法的性能。该数据集已经准备好使用，可通过特定网址进行访问。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16430", "html_url": "https://arxiv.org/abs/2503.16430", "title": "连续和离散标记之间的桥梁用于自回归视觉生成", "title_en": "Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation", "authors": "Yuqing Wang,Zhijie Lin,Yao Teng,Yuanzhi Zhu,Shuhuai Ren,Jiashi Feng,Xihui Liu", "background": "自回归视觉生成模型通常依赖于分词器将图像压缩为可以顺序预测的标记。在标记表示中存在一个根本性的困境：离散标记使得使用标准交叉熵损失进行建模变得简单，但也带来了信息丢失和分词器训练不稳定的问题；连续标记保留了更多的视觉细节，但需要复杂的分布建模，使得生成管道复杂化。现有的方法在这两者之间存在着权衡取舍。", "innovation": "该论文提出了TokenBridge，通过保持连续标记的强大表征能力并保留离散标记的建模简明性来弥合这段差距。TokenBridge通过后训练量化在不依赖分词器训练过程的情况下直接从连续表示获取离散标记。通过引入每维独立的量化策略，以及轻量级自回归预测机制，有效地建模了较大的标记空间。实验表明，该方法在重建和生成质量上与连续方法相当，同时使用标准的分类预测。“TokenBridge能够通过结合两者的优点，为高质量的视觉生成提供多步骤自回归建模的有前途的方向。”", "conclusion": "本工作证明了弥合离散和连续范式之间的鸿沟可以有效利用两种方法的优势，提供了一种通过简单的自回归建模实现高质量视觉生成的有希望的方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "通过自监督训练实现最小标签下的肾脏小球分割优化", "title_en": "Maximising Kidney Glomeruli Segmentation using Minimal Labels via Self-Supervision", "authors": "Zeeshan Nisar,Thomas Lampert", "background": "病理学是疾病诊断和预后的重要工具，而准确地对病理图像中的关键区域进行分割和识别对于开发自动化解决方案至关重要。然而，最先进的深度学习分割模型如UNet需要大量的标注数据，这在多染色情况下不仅成本高昂且耗时。现有解决方法如UDA-GAN虽能减少对标签的需求，但仍需对至少一种染色进行标注，而这并非易事。本文展示了自监督预训练方法（包括SimCLR、BYOL以及一种新方法HR-CS-CO）的引入，使得在减少标签数量（最多减少95%）的同时仍能保持这两种分割模型（UNet和UDA-GAN）的性能。通过仅使用5%的标签，这两种模型在性能损失方面仍十分有限，分别为5.9%和6.2%，并且这些发现证实了模型具有泛化能力，可应用于公开基准数据集。", "innovation": "本文提出的自监督预训练方法（SimCLR、BYOL及新方法HR-CS-CO），能够在使用极少量标签（最多95%）的情况下仍然保持UNet和UDA-GAN这两种深度学习分割模型的性能。即使仅使用5%的标签，性能下降也较小，分别为5.9%和6.2%，相较于完全监督训练（使用100%标签）时的性能。另外，这些方法还展示了在多种公开基准数据集上的泛化能力。", "conclusion": "通过自监督预训练的方法，即使在使用极少量标签（最多95%）的情况下，仍能够保持UNet和UDA-GAN这两种深度学习分割模型的性能。这些发现展示了自监督训练方法在减少标注需求方面的潜力，并且这些模型在多种公开基准数据集上具有泛化能力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02617", "html_url": "https://arxiv.org/abs/2504.02617", "title": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "title_en": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "authors": "Lihua Liu,Jiehong Lin,Zhenxin Liu,Kui Jia", "background": "RGB基线的新型物体姿态估计对于机器人应用的快速部署至关重要，但零样本泛化依然是一个核心挑战。为此，本文探讨了PicoPose框架，该框架采用三步像素到像素对应关系学习过程来解决这个问题。首先，PicoPose通过与渲染对象模板特征匹配，确定最佳匹配模板并建立粗略对应关系；其次，通过全局回归二维仿射变换平滑对应关系，包含平面旋转、缩放和平移；最后，PicoPose应用仿射变换到最佳匹配模板的特征图，并在局部区域学习对应偏移来实现精细对应关系。这种方法逐步优化对应关系，显著提高了PnP/RANSAC计算的物体姿态的准确性。PicoPose在BOP基准的七个核心数据集上达到了最先进的性能，展示了在新的物体上的出色泛化能力。", "innovation": "PicoPose引入了一种新颖的框架，它采用三阶段像素到像素对应关系学习过程，包括粗对应关系建立、仿射变换平滑和局部区域对应偏移学习，逐步优化对应关系，提高了物体姿态估计的准确性。", "conclusion": "PicoPose在BOP基准的七个核心数据集上达到了最先进的性能，展示了在新的物体上的出色泛化能力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12868", "html_url": "https://arxiv.org/abs/2504.12868", "title": "使用多模态3D数据进行个性化咬合定位矫治器的计算机辅助设计", "title_en": "Computer-Aided Design of Personalized Occlusal Positioning Splints Using Multimodal 3D Data", "authors": "Agnieszka Anna Tomaka,Leszek Luchowski,Michał Tarnawski,Dariusz Pojda", "background": "数字技术在设计定制医疗设备方面发挥着关键作用，如用于治疗口腔颌面系统紊乱的咬合板。本文采用计算机辅助方法设计和评估了咬合定位矫治器，旨在证明该方法在预临床阶段的可行性和几何准确性。", "innovation": "提出了一种新颖的方法，用于生成能再现治疗位置咬合条件的矫治器，并通过虚拟凹印解决表面冲突。描述了使用牙科工具和口腔装置获得变换矩阵的过程，并通过轮廓和表面偏差分析评估了设计和打印矫治器的几何准确性。支持可重复的患者特定矫治器制造，并为未来的研究验证提供了透明的基础，特别是在多模态图像配准和咬合差异量化方面。", "conclusion": "该方法支持可重复的患者特定矫治器制造，并为未来的研究验证提供了透明的基础，提供了多模态图像配准和咬合差异量化研究的支持手段。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.13073", "html_url": "https://arxiv.org/abs/2501.13073", "title": "CHaRM: 条件热图回归方法学，用于精确且快速的牙科解剖标志定位", "title_en": "CHaRM: Conditioned Heatmap Regression Methodology for Accurate and Fast Dental Landmark Localization", "authors": "José Rodríguez-Ortega(1 and 2),Francisco Pérez-Hernández(1),Siham Tabik(2) ((1) Nemotec, Madrid, Spain, (2) Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain)", "background": "在正畸治疗中，识别3D牙模的解剖标志点至关重要，但手动放置这些标志点是非常费时且需要专家知识的。虽然已有机器学习方法被提出用于自动识别3D口腔扫描（IOS）中的标志点，但这些方法均未提供无需昂贵牙齿分割的端到端解决方案。本文论文介绍了CHaRM（条件热图回归方法学），这是首个用于3D IOS中牙齿标志点检测的端到端深度学习方法。CHaRM融合了四个组件：点云编码器、带有热图回归头的解码器、牙齿存在分类头以及首创的CHaR模块。CHaR模块利用牙齿存在信息来应对缺失牙齿的情况，从而在复杂牙科病例中提高检测准确性。不同于先分割牙齿再进行标志点标记的两阶段工作流，CHaRM直接作用于IOS点云，减少了复杂性和计算成本。论文还引入了新的数据集和公开代码，以解决正畸领域缺乏开源数据的问题，促进可重现研究。CHaRM与PointMLP结合（称为CHaRNet）实现了最佳的准确性和效率，在标准牙型模型中将平均欧几里得距离误差降低到0.56毫米，并在整个牙列类型中降低了1.12毫米，同时在GPU上实现了高达14.8倍的推理速度。这种端到端的方法简化了正畸工作流程，提高了3D IOS分析的精度，并使计算机辅助治疗计划变得高效且可行。", "innovation": "CHaRM是首个无需牙齿分割即可直接应用于3D IOS点云的端到端深度学习方法。它通过融合点云编码器、解码器、牙齿存在分类头以及首创的CHA模块，实现了复杂牙齿病例中高精度的牙齿标志点检测。不同于传统的工作流，CHaRM直接作用于IOS点云，有效解决了一些模型识别的难题。", "conclusion": "CHaRM显著提高了3D IOS分析的精度和处理效率，简化了正畸工作流程，使得正畸医生能够更高效地进行计算机辅助治疗计划。同时，论文还提供了新的数据集和开源代码，以促进正畸领域内的研究和开发，推动了可重复性和透明性的研究方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "解析用于体外受精（IVF）治疗胚胎选择的深度学习模型", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不育对个体的生活质量有重大影响，影响其社会和心理状态，预计未来几年将有所增加。体外受精(IVF)作为经济发达国家的主要技术之一，被用来解决日益严重的低生育率问题。胚胎学家通过审查囊胚图像来评估胚胎的可移植性并选择最合适的囊胚，这一过程耗时且缺乏效率。囊胚图像为评估胚胎存活率提供了宝贵资源。现有技术需要改进以提高选择胚胎的准确性和效率。", "innovation": "本研究提出了一种可解释的人工智能（XAI）框架，用于分类胚胎，该框架结合了卷积神经网络（CNN）和长短期记忆（LSTM）架构，称为CNN-LSTM。通过深度学习方法，该模型能够高精度地分类胚胎，同时保持通过XAI的可解释性，从而显著提高了胚胎选择的效率和准确性。", "conclusion": "本研究通过开发一种结合CNN和LSTM的XAI框架，显著提升了体外受精中胚胎选择的准确性和效率。这一创新性方法为解决生育问题提供了新的解决方案，有望改善患者的生育前景，并增强对模型决策过程的理解。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02176", "html_url": "https://arxiv.org/abs/2505.02176", "title": "基于显著性引导的指纹欺骗攻击检测训练", "title_en": "Saliency-Guided Training for Fingerprint Presentation Attack Detection", "authors": "Samuel Webster,Adam Czajka", "background": "显著性引导训练通过聚焦图像中的重要区域，提高了生物特征呈现攻击检测（PAD）任务的一般化能力。本文首次将这种技术应用于指纹PAD，并通过50名参与者的研究创建了800个人工标注的指纹感知重要图，同时进行了算法生成的‘伪显著性’探索，包括基于细节点的、图像质量的和基于自编码器的显著性图。该研究评估了在2021年指纹活体检测竞赛测试集中的不同配置的训练情景，以评估显著性引导训练对准确性和一般化的影响。实验结果显示，显著性引导训练在有限数据和大量数据的背景下对于指纹PAD的有效性，并提出了一种配置可以在LivDet-2021基准测试中获得第一名。结果突显了显著性引导训练在提高模型一般化能力、在数据有限时有效以及在指纹PAD中扩展到大规模数据集的巨大潜力。", "innovation": "首次将显著性引导训练应用于指纹PAD；利用人工和算法生成的显著性图进行研究；探索了不同显著性训练配置对PAD任务的不同影响；提出了可以在国际基准测试中获得第一名的模型配置。这些创新为指纹PAD技术提供了一种新的有效性和一般性提升方法", "conclusion": "显著性引导训练在指纹PAD中显示出增强模型一般化能力的有效性，在有限数据和大量数据情境下均有效，并且提出的方法可以在国际比赛中获得成功。该研究通过公开收集的显著性数据和训练模型支持了可重复的研究。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "任意视频中了解相机运动的方向", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "这篇论文介绍了CameraBench，这是一个大型数据集和基准测试，旨在评估和改善对相机运动的理解。该数据集包含约3000个多样化的互联网视频，并经过专家通过严格多阶段质量控制过程进行标注。研究人员发现，一些运动，如跟随或追踪，需要理解场景内容，例如移动的主体。此外，还进行了大规模的人类研究来量化人类注释的性能，揭示了领域专业知识和基于教程的培训能够显著提高准确性。因此，需要一种新的方法和技术来更好地捕捉这些复杂的相机运动特征。", "innovation": "研究团队提出了一种与摄影师合作设计的相机运动基础分类法，并发现一些运动需要理解和标注场景内容。他们还展开了大规模的人类研究，量化了人类标注的准确性和领域专家知识的重要性。通过CameraBench，对结构从运动(SfM)模型和视频-语言模型(VLMs)进行了评估，并发现SfM模型难以捕捉依赖场景内容的语义原语，而VLMs难以捕捉需要精确估计轨迹的几何原语。该团队进一步对生成的VLM进行微调，以实现捕捉到SfM和VLM们的优势，用于运动增强的描述、视频问答和视频文本检索等应用。", "conclusion": "该论文提出了新的数据集和基准测试来帮助未来的研究朝着任何视频中理解相机运动的目标迈进。通过CameraBench，研究人员希望推动领域专业知识和技术的发展，以更好地理解和捕捉相机运动的复杂特性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过Dirac重平衡器和分布纠缠实现单域泛化的大肠癌跨类型多模态预后", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据进行生存预测方面取得了显著性能，但现有的多模态方法主要针对单一癌症类型，并忽视了跨癌症场景的泛化挑战。已有研究指出，在临床实践中需要提高跨癌症场景的鲁棒性，但在多模态预后模型中，出现在单一癌症类型上训练的多模态模型往往表现不如单模态模型，未能有效泛化到未见过的癌症类型。文章发现了两个关键挑战：较弱模态的特征降级和多模态融合的无效性。", "innovation": "为了应对上述挑战，作者提出了一项新任务：通过Dirac重平衡器和分布纠缠进行单域泛化多模态跨类型预后，主要用于评估是否在单一癌症类型上训练的模型可以在未见过的癌症类型上泛化。为此，作者引入了两个可插拔模块：稀疏Dirac信息重平衡器（SDIR）和癌症认知分布纠缠（CADE）。SDIR通过应用基于伯努利的稀疏化方法和Dirac启发的稳定技术来减轻强特征的主导作用，增强较弱模态的信号。CADE旨在合成目标域分布，在隐空间中融合局部形态学线索和全局基因表达。通过在四种癌症类型的数据集上的实验表明，这些方法在泛化性能上表现出优越性，为实际的跨癌症类型的多模态预后提供了基础。", "conclusion": "实验结果在四个癌症类型的基准数据集上展示了更优的泛化性能，为实际中的跨癌症类型的多模态预后奠定基础。相关代码可以在指定网站上获取。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式识别（HMER）是一个具有挑战性的任务，原因包括其固有的二维结构、符号大小的变化以及复杂的符号间空间关系。现有方法依赖于昂贵的标注数据进行训练，缺乏标注的数据往往限制了模型的表现力。", "innovation": "本文提出了一种自监督学习（SSL）框架，通过自监督预训练网络和自我监督注意力学习，无需依赖昂贵的标注数据即可进行HMER。引入了一种新颖的自我监督注意力网络，并通过渐进的空间遮蔽策略进行训练，以学习具有语义意义的关注区域，如操作符，指数和嵌套的数学标记。这种方法鼓励网络在缺失或遮挡视觉信息的情况下变得越来越健壮，从而提高结构理解能力。最终，使用变压器解码器进行监督微调，以生成LATEX序列。", "conclusion": "在CROHME基准测试上的大量实验表明，本方法在SSL和完全监督基线中的性能更优，验证了渐进式注意力机制在增强HMER性能方面的重要性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04061", "html_url": "https://arxiv.org/abs/2507.04061", "title": "跨模态一致性与不变性学习在短视频虚假信息检测中的广义化学习", "title_en": "Consistent and Invariant Generalization Learning for Short-video Misinformation Detection", "authors": "Hanghui Guo,Weijie Shi,Mengze Li,Juncheng Li,Hao Chen,Yue Cui,Jiajie Xu,Jia Zhu,Jiawei Shen,Zhangze Chen,Sirui Han", "background": "在多模态领域，短视频信息虚假检测引起了广泛关注，旨在准确识别带有相应音频的视频格式中的虚假信息。尽管取得了显著的进展，但当前在特定领域（源领域）训练的模型在未见过的领域（目标领域）中表现不佳，这是由于领域差距的存在。为有效地在短视频信息虚假检测任务中实现领域广义化，我们需要深入了解不同领域的特点。重点关注不同领域的检测主要依赖于不同的模态（即主要关注视频或音频）。为了提高领域广义化，同时在所有模态上实现最优模型性能至关重要。对于一些依赖跨模态联合欺诈的领域，有必要进行全面分析，但每个模态（尤其是每帧视频）中存在的领域偏差会在此融合过程中累积，严重损害最终的虚假信息识别。", "innovation": "我们提出了一个新的用于短视频信息虚假检测的DOCTOR模型，通过一致性和不变性学习实现领域广义化。该模型包含两个特性模块：（1）涉及跨模态特征插值，将多种模态映射到共享空间，并通过多模态同步学习；（2）设计扩散模型，添加噪声保留多模态的核心特征，并通过跨模态引导去噪增强领域不变特征。", "conclusion": "广泛的实验表明，我们提出的DOCTOR模型的有效性。我们的代码已在以下网址公开：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12420", "html_url": "https://arxiv.org/abs/2507.12420", "title": "InterpIoU：基于插值优化的边界框回归重思", "title_en": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization", "authors": "Haoyuan Liu,Hiroshi Watanabe", "background": "边界框回归（BBR）是目标检测中的核心部分，其中回归损失对于准确的位置定位至关重要。现有的基于IoU的损失函数通常会引入手工艺几何惩罚，以解决IoU在非重叠情况下非可微的问题，并提高BBR性能，但这些惩罚对盒子形状、大小和分布敏感，可能导致小目标优化不佳，并且会导致边界框放大等问题", "innovation": "提出了InterpIoU，这是一种新型损失函数，用插值盒与目标之间的IoU值代替手工设计的几何惩罚。使用插值盒来填补预测和真实值之间的差距，InterpIoU在非重叠情况下能提供有意义的梯度，并且能避免由惩罚不匹配引起的边界框放大问题。此外，基于InterpIoU，引入了动态InterpIoU，动态调整插值系数以适应多样化的物体分布，增加适应性。实验结果表明，该方法在COCO、VisDrone和PASCAL VOC数据集上，特别是在小目标检测方面，优于现有的基于IoU的损失函数，证明了其有效性", "conclusion": "我们的方法在各种检测框架中始终优于现有的基于IoU的损失函数，特别在小目标检测方面表现突出，这证明了其有效性"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR: 动态差异感知时序残差网络在纵贯放射报告生成中的应用", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "放射学报告生成（RRG）自动化了从医疗影像生成放射学报告的过程，提高了报告过程的效率。纵向放射学报告生成（LRRG）进一步通过整合比较当前和先前检查的能力，实现了临床发现随时间变化的跟踪。现有LRRG方法仅使用视觉预训练编码器从先行和当前图像中提取特征，然后将这些特征连接起来生成最终报告。然而，这些方法在特征提取过程中难以有效捕捉空间和时间的关联。因此，提取的特征无法充分捕捉检查之间的差异信息，导致在LRRG中的表现欠佳。", "innovation": "我们开发了一种新颖的动态差异感知时序残差网络（DDaTR）。在DDaTR中，我们引入了两个模块于视觉编码器的每个阶段，以捕捉多层次的空间关联。动态特征对齐模块（DFAM）旨在跨模态对齐先行特征，确保先行临床信息的完整性。响应改进的先行特征，动态差异感知模块 (DDAM) 通过识别检查间的关联来捕捉有利的差异信息。此外，我们的DDaTR采用动态残差网络进行单向传递纵向信息，有效地建模时间关联。", "conclusion": "在三项基准上的广泛实验表明，DDaTR优于现有方法，证明了其在RRG和LRRG任务中的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07313", "html_url": "https://arxiv.org/abs/2508.07313", "title": "DocR1：基于证据页引导的GRPO方法进行多页文档理解", "title_en": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding", "authors": "Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li", "background": "对于多页文档的理解，当前的多模态大语言模型面临着显著挑战，特别是需要细粒度的视觉理解及跨页面的多跳推理。尽管前人探索了强化学习（RL）以增强这些模型的高级推理能力，但将其应用于多页文档理解的研究仍较为缺乏。本研究旨在填补这一空白，通过开发一个新的强化学习框架，来提升多页文档理解的能力。", "innovation": "本研究提出了名为DocR1的多模态大语言模型，该模型采用了一种新颖的强化学习框架Evidence Page-Guided GRPO (EviGRPO)。EviGRPO框架引入了证据感知的奖励机制，促进了从粗略到精细的推理策略，确保模型首先检索相关页面，然后再生成答案。通过这种训练范式，研究者成功地用较少的监督构建了高质量的模型。研究还设计了两个数据集EviBench和ArxivFullQA，并采用两阶段标注管道和课程学习策略，以支持其研究。", "conclusion": "广泛的实验表明，DocR1在各类基准测试中实现了最先进的多页任务性能，同时在单页基准测试中也保持了强大的结果。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA: 一种用于植物科学中视觉语言模型基准测试的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA是一个大规模的视觉问答（VQA）数据集，源自广泛使用的PlantVillage图像库。该数据集旨在促进农业决策和分析中视觉语言模型的发展和评估。它包含193,609对高质量的问题-答案（QA）对，涵盖55,448张图像以及14种作物和38种疾病条件。问题分为3个认知复杂度级别和9个不同的类别。", "innovation": "PlantVillageVQA数据集通过模板化的QA合成和多阶段的语言重构自动化生成，经过领域专家的迭代评审。每个问题类别都是在专家指导下手工构建，确保科学准确性和相关性。最后，数据集使用最新的模型进行了质量评估。此外，数据集能够增强植物病害识别的诊断准确性，推动植物科学领域的科学发展。它是公开可用、标准化且经过专家验证的数据库。", "conclusion": "PlantVillageVQA数据集的目标是通过提供公共访问的、标准化的和专家验证的数据库，提高植物病害诊断的准确性，并促进农业领域的科学研究。数据集将于指定网址公开发布。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18539", "html_url": "https://arxiv.org/abs/2508.18539", "title": "3D RPG中自适应视觉导航助手", "title_en": "Adaptive Visual Navigation Assistant in 3D RPGs", "authors": "Kaijie Xu,Clark Verbrugge", "background": "在复杂的3D游戏环境中，玩家依赖视觉线索识别地图转换点。有效地识别这些点对于客户端自动制图至关重要，并为评价地图提示提供客观依据。本文旨在明确检测可通行的时空转换点（STPs）——连接两个子区域之间的连接点——并从中选择设计师预设的关键路径上的主要时空转换点（MSTP），作为新的研究重点。", "innovation": "本文介绍了两阶段的深度学习管道，首先使用Faster R-CNN检测潜在的STPs，然后使用轻量级MSTP选择器融合局部和全局视觉特征进行排名。此外还引入了可选的检索增强融合步骤。研究还揭示了一项关键权衡：虽然全网络微调在充足数据下能使STP检测表现最好，但仅适配器迁移在低数据场景和MSTP选择任务中表现更为稳健且有效。", "conclusion": "通过定义这一新颖问题，提供基础管道和数据集，并提出初步有效的模型适配见解，本文旨在为未来基于AI的导航辅助工具和数据驱动的关卡设计工具做出贡献。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "Region-Level Context-Aware Multimodal Understanding", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大型语言模型（MLLMs）方面取得了显著进展，现有研究主要集中在一般视觉理解上，忽视了结合物体相关文本上下文的能力，这要求模型更加具备上下文感知的多模态理解能力，即区域级别的上下文感知多模态理解（RCMU）。当前研究尚未充分开发这一能力，因此有必要提升这类模型的RCMU能力，并构建相应的数据集和评估基准。", "innovation": "本文首先定义了RCMU任务，要求模型结合图像内容和区域或对象的文本信息来响应用户指令。为使MLLMs具备RCMU能力，本文提出了一种名为RC-level Context-aware Visual Instruction Tuning（RCVIT）的方法，将对象信息融入模型输入，并利用边界框坐标有效关联视觉内容和文本信息。为解决数据集的缺乏问题，本文提出了RCMU数据集，这是一个大规模的视觉指令调整数据集，涵盖了多个RCMU任务。此外，本文还提出了RC\text& P-Bench，一个全面的基准测试，可以评估MLLMs在RCMU和多模态个性化理解任务中的性能，并提出了一种无需参考的评估指标，以全面评估区域级上下文感知图像描述。通过在Qwen2-VL模型上应用RCVIT并使用RCMU数据集，开发了RC-Qwen2-VL模型。实验结果表明，RC-Qwen2-VL模型不仅在多个RCMU任务中表现出色，还在多模态RAG和个性化对话方面实现了成功应用。", "conclusion": "本文通过构建RCMU数据集、RCVIT方法及RC\text& P-Bench基准，提升了MLLMs的RCMU能力和多模态个性化理解能力，并展示了其在多模态检索生成（RAG）和个性化对话中的实际应用效果；此外，本文还提出了一种新的评估指标来全面评估RCMU图像描述。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.08906", "html_url": "https://arxiv.org/abs/2409.08906", "title": "高斯分布是你需要的一切：一种通过扩散后验采样解决逆问题的统一框架", "title_en": "Gaussian is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling", "authors": "Nebiyou Yismaw,Ulugbek S. Kamilov,M. Salman Asif", "background": "扩散模型能够生成多种高质量图像，并通过建模复杂数据分布而有效工作。经过训练的扩散模型也可用于解决逆问题作为很好的先验信息。现有基于扩散的方法通常通过在反向采样过程中近似似然函数来整合数据一致性步骤，但这种方法要么不足要么计算效率低下。", "innovation": "提出了一个统一的似然性近似方法，该方法将协方差校正项整合进来以增强性能并避免在反向扩散采样过程中通过扩散模型传递梯度。通过这种方法，协方差项在反向扩散采样过程中能够更好地收敛到真实数据后验，并在一系列逆问题中提高了实际自然图像数据集上的性能。此外，还提供了一种高效的方式来进行协方差矩阵的分解和求逆。", "conclusion": "通过全面的实验表明，该方法比现有的多种方法更有效。相关代码可在指定网址找到。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20835", "html_url": "https://arxiv.org/abs/2508.20835", "title": "PointDGRWKV: 将RWKV类似架构推广到未见过的领域以应用于点云分类", "title_en": "PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification", "authors": "Hao Yang,Qianyu Zhou,Haijia Sun,Xiangtai Li,Xuequan Lu,Lizhuang Ma,Shuicheng Yan", "background": "点云分类（PCC）模型的一般化近年来得到了探索，目的是使模型能够处理未见过的领域。现有的工作基于卷积网络、Transformer或Mamba架构，但存在限制的感受野或高昂的计算成本，以及对长程依赖性建模不足的问题。RWKV作为一种新兴架构，具有优越的线性复杂度、全局感受野和长程依赖性。然而，直接将RWKV应用于PCC的一般化中遇到了两个显著的挑战：依赖于固定方向令牌移位方法（如Q-Shift）导致在未结构化的点云上应用时引入了空间失真，削弱了局部几何建模并减少了鲁棒性。此外，RWKV中的双向KVK注意力通过指数加权放大了领域间关键分布的细微差异，导致注意力偏移并降低了泛化能力。", "innovation": "为了应对上述挑战，本文提出了PointDGRWKV，这是第一个针对PCC的一般化的RWKV框架。它引入了两个关键模块来增强空间建模和跨域鲁棒性，同时保持RWKV的线性效率。具体来说，引入了自适应几何令牌移位，用于建模局部邻域结构，以提高几何上下文感知能力。此外，还设计了跨域关键特征分布对齐模块，通过跨域对齐关键特征分布来减轻注意力漂移。", "conclusion": "在多个基准上的广泛实验表明，PointDGRWKV在点云分类的一般化方面达到了最先进的性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: 一个用于共识预测的Python库", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "共识预测（CP）是一种生成带有保证覆盖概率的预测区间或集合的统计框架。尽管CP算法已经从传统的分类器和回归器发展到了复杂的深度学习模型（如深度神经网络、图神经网络和大型语言模型），现有的CP库仍然缺乏支持和扩展性，特别是在大规模深度学习场景中。TorchCP库旨在将先进的CP算法集成到深度学习技术中，包括基于深度神经网络的分类器/回归器、图神经网络和大型语言模型。", "innovation": "TorchCP 是一个专为 PyTorch 设计的库，该库不仅整合了先进的 CP 算法，还提供了特定于 CP 的训练算法、在线预测和 GPU 加速批处理等功能，可以实现高达 90% 的推理时间减少。此外，该库还具有低耦合设计、全面的高级方法套件和完全的 GPU 扩展性，这使得研究人员和实践者能够增强对最先进应用中的不确定性量化能力。", "conclusion": "TorchCP 通过提供与先进 CP 算法集成的能力、特定于 CP 的训练算法、在线预测以及 GPU 加速批处理，有效地填补了现有 CP 库在大规模深度学习场景中的空白。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03729", "html_url": "https://arxiv.org/abs/2505.03729", "title": "视觉模仿使类人机器人能够在多种真实环境条件下进行控制", "title_en": "Visual Imitation Enables Contextual Humanoid Control", "authors": "Arthur Allshire,Hongsuk Choi,Junyi Zhang,David McAllister,Anthony Zhang,Chung Min Kim,Trevor Darrell,Pieter Abbeel,Jitendra Malik,Angjoo Kanazawa", "background": "类人机器人需要学会在现实环境中进行一些复杂任务，如上下楼梯和在椅子上坐下。传统的教学方式比较复杂，本文提出了一种简化的方法，即直接模仿人类的行为。这需要从日常视频中获取数据，重建人类及其环境，并生成类人机器人执行相应技能的身体控制策略。", "innovation": "本文引入了一种名为VIDEOMIMIC的实时到模拟再到实时的工作流程，该流程可以从普通视频中挖掘关键信息，联合重构人类和环境，生成适用于类人机器人的全身控制策略。这种方法使得类人机器人能够表现出在现实世界中上下楼梯、从椅子或长凳上坐下站立等复杂但协调的动作，仅需一个策略，并且可以根据环境和全局根命令加以调节。", "conclusion": "VIDEOMIMIC为教类人机器人操作多样化的现实环境提供了一种可扩展的方法，证明了视觉模仿在实现类人机器人在各种场景中执行复杂技能的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19650", "html_url": "https://arxiv.org/abs/2508.19650", "title": "Video-LevelGauge: 探究大型视频语言模型中的上下文位置偏见", "title_en": "Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models", "authors": "Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang", "background": "大型视频语言模型（LVLMs）在视频理解方面取得了显著进展，推动了相应的评估基准的开发。然而，现有的基准通常评估整个视频序列的总体性能，忽视了诸如情境位置偏差等关键但尚未充分探索的方面。上下文位置偏差反映了模型在处理不同位置的视频内容时可能存在的偏好或偏误，这是评估模型性能的一个重要维度。已有基准主要关注整体性能，没有系统地评估这一细微的行为差异。因此，有必要开发一个专门的基准来系统性地评估LVLM中的位置偏差。", "innovation": "该研究提出了Video-LevelGauge，一个专门设计用于系统评估LVLM中的位置偏差的基准。它使用标准化的探针和定制的上下文设置，允许灵活控制上下文长度、探针位置和上下文类型，以模拟各种现实世界的情景。此外，引入了综合分析方法，结合统计措施与形态模式识别，以表征偏见。基准数据集包含438个手动挑选的视频，涵盖多种类型，产生1,177个高质量的选择题和120个开放式问题，这些题目被验证为有效揭示位置偏差。研究还评估了27个最先进的LVLM模型，包括商业和开源模型。结果显示，许多领先开源模型存在显著的位置偏差，通常表现出头部内容或邻居内容的偏好。相比之下，商业模型如Gemini2.5-Pro表现出色，其在整个视频序列中的表现一致。进一步对上下文长度、上下文多样性以及模型规模的分析提供了具体的建议，以减少偏差并指导模型改进。", "conclusion": "研究结果显示，许多领先的开源LVLM存在显著的位置偏差，通常表现出头部内容或邻居内容的偏好。针对不同长度的上下文、上下文多样性和模型规模的进一步分析提供了减少偏差并指导模型改进的实际建议。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中机器人操作中的视图合并与解混", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉技术在机器人操作中得到广泛应用，特别是在视觉伺服方面。由于世界具有三维特性，使用多摄像头视角并整合它们可以提供更好的表示形式，进而训练更高效的策略。然而，依赖多视角策略存在对摄像头失败敏感以及部署负担大的问题.", "innovation": "本文提出了一种名为MAD（合并与解混）的算法，它可以高效地合并视图以提高样本效率，同时通过增强多视角特征输入以单视角特征来解混视图，从而产生更稳健的策略，实现轻量级部署。该方法在Meta-World和ManiSkill3上进行了验证和展示，证明了其高效性和稳健性.", "conclusion": "实验结果表明，MAD算法能够有效地提高样本效率并产生更稳健的策略，适用于机器人操作中的视觉强化学习。该方法可以通过轻量化部署来解决多视角策略的部署难题。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07134", "html_url": "https://arxiv.org/abs/2504.07134", "title": "在CAD中引入注意力机制：通过变换器进行边界表示学习", "title_en": "Bringing Attention to CAD: Boundary Representation Learning via Transformer", "authors": "Qiang Zou,Lizhen Zhu", "background": "生成性人工智能（AI），尤其是由Transformer网络驱动的技术，在自然语言处理、计算机视觉和图形等领域已经取得了显著的成功。然而，Transformer在网络辅助设计（CAD）中的应用，特别是在处理边界表示（B-rep）模型方面，尚未得到充分探索。B-rep模型由于其不规则拓扑和连续几何定义上的独特挑战，使其与设计中的结构化和离散数据存在本质差异，这使得目前的Transformer难以直接应用于B-rep模型处理。为了解决这一问题，本文提出了一个名为Boundary Representation Transformer（BRT）的新颖方法，以适应B-rep学习。", "innovation": "BRT通过提出连续几何嵌入方法，将B-rep表面（裁剪和非裁剪）编码为Bezier三角形，保留其形状和连续性，而不进行离散化处理。此外，BRT还采用了一种拓扑感知嵌入方法，将这些几何嵌入组织成适合Transformer的离散令牌序列，从而捕捉B-rep模型中的几何和拓扑特征。该方法使得Transformer的注意力机制能够有效地学习边界元素中的形状模式和上下文语义，并展示了在零件分类和特征识别任务中的最佳性能。", "conclusion": "通过大量实验，BRT在零件分类和特征识别任务中达到了最先进的性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19762", "html_url": "https://arxiv.org/abs/2508.19762", "title": "BuzzSet v1.0: 实景观测条件下传粉昆虫检测数据集", "title_en": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "authors": "Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher", "background": "传粉昆虫如蜜蜂对全球食物生产和生态系统稳定至关重要，但它们由于人类活动和环境压力等原因数量正在下降。在农田环境中实现可扩展的自动监测仍然具有挑战性，主要由于难以检测小巧、快速移动和常常伪装的昆虫。为了解决这个问题，提出了BuzzSet v1.0，这是在真实野外条件下收集的高分辨率传粉昆虫图片的大规模数据集。", "innovation": "BuzzSet v1.0提供了7,856张手动验证的图片，超过8,000个注释实例，分为三个类别：蜜蜂、熊蜂和未识别昆虫。最初使用YOLOv12模型进行外部数据训练，并通过开源工具的人类验证进行细化。提供基于RF-DETR的Transformer基线对象检测器。该模型在蜜蜂和熊蜂分类上的F1分数分别为0.94和0.92，分类准确性较强，尽管这两类之间的混淆较少。未识别类别由于标签模糊和样本较少更为困难，但仍可为鲁棒性评估提供见解。综合检测性能（mAP值为0.559）显示了数据集的挑战性及其在实际生态条件下推动小目标检测技术发展的潜力。未来工作重点是将数据集扩展到v2.0版本，并评估进一步的检测策略。BuzzSet为生态计算机视觉设定了一个基准，主要挑战是可靠地检测常常伪装在自然植被中的昆虫，这突显了未来研究中的一个开放性问题。", "conclusion": "BuzzSet v1.0在真实野外条件下为传粉昆虫检测提供了挑战性大的数据集，虽然存在特别困难的类别，但其潜在价值在于能够推动检测技术的进步。未来的研究应继续扩充数据集并探索新的检测方法。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT 一种新型通道增强混合CNN-Transformer 去实现具有残差、空间和边界感知学习的大脑肿瘤MRI分析", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤仍然是人类最难治愈的疾病之一，早期检测和准确分类是有效诊断和治疗计划的关键。尽管基于深度学习的计算机辅助诊断(CADx)系统已经取得了显著进展，但传统的卷积神经网络(CNNs)和变压器仍然面临高计算成本、对微小对比变化的敏感性、结构异质性和MRI数据中的纹理不一致等持续挑战。", "innovation": "为了克服上述挑战，论文提出了一种名为CE-RS-SBCIT的新型混合框架，它结合了基于残差和空间学习的CNNs与由变压器驱动的模块。该框架通过四个核心创新点来利用局部细节和全局上下文线索：(i) 拟合平滑和边界导向的CNN-集成变压器(SBCIT)，(ii) 调整后的残差和空间学习CNNs，(iii) 通道增强(CE)策略，(iv) 一种新的空间注意力机制。此外，Residual和空间CNNs通过辅助的预训练特征图增强，并使用CE模块放大具有差异性的通道，同时减少冗余性；空间注意力机制能有针对性地强调不同肿瘤类别的微细对比度和纹理差异。", "conclusion": "在涵盖胶质瘤、脑膜瘤、垂体瘤和健康对照组的挑战性MRI数据集上的广泛评估表明，所提出的CE-RS-SBCIT框架展现了优越的性能，实现98.30%的准确率、98.08%的敏感性、98.25%的F1分数和98.43%的精确度。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02512", "html_url": "https://arxiv.org/abs/2508.02512", "title": "QuaDreamer：用于四足机器人的可控全景视频生成", "title_en": "QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots", "authors": "Sheng Wu,Fei Teng,Hao Shi,Qi Jiang,Kai Luo,Kaiwei Wang,Kailun Yang", "background": "全景相机能够捕捉全面的360度环境数据，适合四足机器人周围的感知和与复杂环境的交互。然而，由于固有的运动限制和复杂的传感器校准挑战，高质量的全景训练数据稀缺，根本上限制了专为这些实体平台设计的鲁棒感知系统的开发。", "innovation": "本文提出了一种专门针对四足机器人的全景数据生成引擎QuaDreamer。QuaDreamer通过模拟四足机器人的运动模式，生成高质量、高可控性和逼真的全景视频，适用于下游任务。文中特别介绍了垂直抖动编码（VJE），用于捕捉四足行走过程中的独特垂直振动特征，并提出了一种场景-物体控制器（SOC），借助注意力机制有效管理对象运动，增强背景抖动控制。此外，还提出了全景增强器（PE），这是一种双重流架构，用于协同频域纹理细化和空间结构纠正，以解决宽视场视频生成中的全景失真问题。", "conclusion": "生成的视频序列可以作为四足机器人全景视觉感知模型的训练数据，提高了360度场景中的多对象跟踪性能。相关源代码和模型权重将在此链接：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject：针对网络代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "基于多模态大语言模型的网络代理（MLLM）通过生成基于网页截图的动作与网页环境进行交互。作者提出了WebInject攻击，通过在渲染网页的原始像素值上添加扰动，来操纵网页环境使网络代理执行攻击者指定的操作。这类攻击的关键挑战在于原始像素值与截图之间的映射是非可微的，导致难以通过backpropagation传播梯度。", "innovation": "为了应对上述挑战，作者训练了一个神经网络以近似原始像素值与截图之间的映射关系，并应用投影梯度下降解决重新公式化后的优化问题。实验结果显示，WebInject攻击非常有效，显著优于基线方法。", "conclusion": "通过对WebInject攻击的开发和评估，研究证明了在基于屏幕截图的网络代理交互中嵌入恶意指令的可行性，展示了非可微映射问题下优化问题求解的新策略。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：强化学习在医疗AI中的决定性飞跃", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）在医疗中的应用标志着人工智能应用方式的根本转变。传统模型基于固定关联，而RL通过试验、反馈和长期奖励优化进行学习，引入了新的可能性和风险。在信息融合视角下，医疗RL通常会通过时间和决策级机制整合多种来源信号，如生命体征、实验室检测、临床记录、影像学和设备遥测数据，并能够适应从中央、联邦到边缘的不同架构以适应临床实时需求。", "innovation": "本文首先从医疗约束的角度塑造了RL技术的格局，包括模型基础和无模型方法、离线和批量约束方法，以及新策略的奖励规定和不确定性校准。然后全面分析了涵盖重症监护、慢性病、心理健康、诊断和机器人辅助等领域的RL应用，识别出趋势、空白和转化瓶颈。此外，本文还批判性地分析了RL在伦理、部署和奖励设计方面的挑战，并综合归纳了确保安全、与人对齐的政策学习的经验教训。", "conclusion": "本文不仅提供了一种技术路线图，还对RL在医疗AI中的新兴变革作用进行了批判性反思，认为RL不仅仅是预测工具，而是具有临床智能的代理型智能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从朗文扩散稳定性到非对数凹采样 proximal MCMC 的收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "在许多情况下，如图像逆问题中，势能在无穷远处是非凸、非光滑的。在这种背景下，传统的基于对数凹函数的方法不再适用。Proximal Stochastic Gradient Langevin Algorithm (PSGLA) 是一种结合了带 ULA 步骤的前向-后向优化算法的算法，被广泛用于处理此类非凸、非光滑的势能。然而，目前还没有针对非凸势能的 PSGLA 收敛性的证明。这项研究旨在填补这一空白，通过分析 ULA 的离散时间稳定性，并结合 Moreau 包络的性质，首次证明了 PSGLA 在非凸情况下的收敛性。该研究基于理论上证明了稳定性，并通过合成数据和图像逆问题的实际案例进行实证验证。", "innovation": "论文的主要创新在于首次证明了在非凸势能情况下，PSGLA 的收敛性。这通过将 ULA 的离散时间稳定性分析与 Moreau 包络的性质相结合来实现。此外，实验证明PSGLA 在后验采样中具有比 Stochastic Gradient Langevin Algorithm 更快的收敛率，同时仍保持其恢复特性。", "conclusion": "该研究通过理论分析和实证验证，成功证明了在非凸势能情况下，PSGLA 的稳定性及其收敛性，同时展示了其在实际应用场景中的优越性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07331", "html_url": "https://arxiv.org/abs/2507.07331", "title": "mmFlux：使用商用mmWave MIMO雷达的 crowd flow 分析", "title_en": "mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar", "authors": "Anurag Pallaprolu,Winston Hurst,Yasamin Mostofi", "background": "本文介绍了使用商用毫米波雷达进行crowd flow分析的方法。研究背景包括对现有crowd motion特征提取和semantics推断技术的限制，特别是在复杂crowd pattern中的高精度重建和分析方面。现有的视觉和信号处理方法存在局限性，难以处理大规模人群下的复杂流动模式。因此，需要一种新的方法来提高对群体流动模式的理解和定量分析能力。", "innovation": "本文创新性地提出了一种名为mmFlux的新框架，该框架结合了光学流动估计的概念，并引入了一种新的方法，将流动场转化为定向几何图。这种方法使用毫米波雷达信号处理管道，通过统计和形态学噪声过滤生成高质量的毫米波流动场，并进一步通过局部雅可比分析得出关键的crowd semantics，包括急转弯、流动方向变化的边界、分散和聚集等现象，提供了强空间对准和精确的流动分裂比的定量表征。", "conclusion": "实验结果表明，mmFlux框架能够准确地重建复杂人群模式下的流场结构，并能够精确地推断关键的crowd semantics。这些发现验证了mmFlux框架在多种crowd analytics应用中的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19297", "html_url": "https://arxiv.org/abs/2506.19297", "title": "基于显式残差的分层图像编码适用于人类和机器", "title_en": "Explicit Residual-Based Scalable Image Coding for Humans and Machines", "authors": "Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe", "background": "分层图像压缩是一种通过重建不同版本的图像来满足多样需求的技术。近年来，图像不仅被人类消费，也被图像识别模型消费，因此吸引了更多关注适用于人类和机器视觉的分层图像压缩方法（ICMH）。当前模型多采用基于神经网络的编解码器（learned image compression），但存在过分依赖学习能力且架构设计不够充分的问题。", "innovation": "本文通过集成一种显式的残差压缩机制，增强了ICMH框架的编码效率和可解释性。这两种提出的方法分别是特征残差分层编码（FR-ICMH）和像素残差分层编码（PR-ICMH），适用于各种机器视觉任务。同时，这些方法提供了在编码复杂性和压缩性能之间进行选择的灵活性，使其适应不同的应用需求。实验结果表明，PR-ICMH相对于前人工作实现了高达29.57%的BD-rate节省", "conclusion": "我们提出的FR-ICMH和PR-ICMH方法在提高编码效率和解释性方面优于现有模型，并提供了在编码复杂性和压缩性能之间的选择，适用于多种机器视觉任务。实验结果表明，PR-ICMH方法在BD-rate节省方面表现最佳，达到了29.57%的提升。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "使用混合深度学习的严肃游戏中基于SAM评分的时空脑电信号情绪识别", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "近年来，基于脑电图（EEG）的情绪识别取得了值得肯定的结果，无论是深度学习还是经典机器学习方法都显示出良好的前景。然而，大多数现有的研究集中在二元情绪价值预测或个体特定分类上，这限制了其在实际情感计算系统中的广泛应用和可移植性。", "innovation": "本文提出了一个基于GAMEEMO数据集的统一多粒度EEG情绪分类框架，该框架包括14通道的EEG记录以及来自28名受试者的四种情绪诱发游戏场景下的连续自我报告情绪评分（无聊、恐怖、平静和搞笑）。通过结构化的预处理策略，包括时间窗口分割、统计与频域特征混合提取以及z-分数规范化，将原始EEG信号转化为稳健、区分性输入向量。提出了三种互补的情绪标签表示方式：基于平均正负情绪评分的情感二元价值分类、多类情绪分类以及细粒度多标签表示，即情绪被划分为10个有序类别。利用多种模型进行评估，包括随机森林、XGBoost、SVM以及深度神经架构如LSTM、LSTM-GRU和CNN-LSTM。其中，LSTM-GRU模型在所有任务中表现最佳，二元价值任务中的F1分为0.932，多类和多标签情绪分类中的准确率分别为94.5%和90.6%。这项研究强调了LSTM-GRU作为一种有效的模型架构的作用，并表明其在多粒度情感分类任务中的优势。", "conclusion": "在多粒度情感分类任务中，LSTM-GRU模型表现最佳，实现了高F1评分和准确率。该研究不仅提高了情绪识别的复杂性和精确度，还展示了在实际情感计算系统中的应用潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "使用特征提取和聚类对SWIFT消息对手方进行规范化", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "短文本聚类是文本分析领域的一个已知应用场景。在自然语言文本环境下，如Twitter帖子或即时消息，可以使用自然语言技术，前提是文本长度足以使预训练模型能够提取有意义的信息，比如词性或主题注释。然而，在银行支付消息系统（如SWIFT）中，手动输入的标签通常为物理或法律实体细节，缺乏句子结构，同时还包含了手工录入引入的所有变体和噪音。这就让调查人员或反欺诈专业人士在了解支付流程的发起方和受益方实体，以及追踪资金和资产时缺乏工具。传统上，供应商通常使用模糊匹配工具来填补这一缺口。基于以上问题，本文提出了一种结合字符串相似度、主题建模、层次聚类及基于规则的流程来聚类交易对手方案，可以处理未知数量的预期聚类，同时开发了用于评估该方法的补充指标，基于经典的准确率和召回率指标。通过实际有标注的数据集测试表明，该方法在性能上优于基于规则的‘关键词’基准方法。该方法保留了规则基础系统大部分的可解释性，因为前者为后者增加了额外的集群细化层次，从而减少了对人工审查的需求。在仅需要调查人群中的一部分的情况下，例如在制裁调查中，该方法允许对实体变异的漏报风险进行更好的控制。", "innovation": "提出了一种结合字符串相似度、主题建模、层次聚类及基于规则的流程来聚类交易对手方案，并开发了用于评估该方法的补充指标，解决了传统自然语言技术在处理SWIFT支付消息系统中手动输入的标签时存在的问题。这种方法结合了机器学习和规则基础的分析方法，显著提高了聚类性能和可解释性。", "conclusion": "该方法通过实际有标注的数据集测试，证明了在性能上优于传统的基于规则的‘关键词’方法。保留了规则基础系统大部分的可解释性，可以减少人工审查的需求，特别在制裁调查等需要对部分人群进行调查的情况下，能够更好地控制实体变异的漏报风险。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "通过自主人工智能进行的深空网络数据系统自动化; 适应性异常检测案例研究", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "NASA的深空网络（DSN）是其最大的天线设施网络，产生大量的多元时间序列数据。这些设施中的天线和发射机会随时间退化，这可能导致数据传输中断，威胁到数十台依赖DSN的深空航天器的地球连接。为此，本研究旨在探索不同方法，帮助JPL工程师通过收集的数据直接定位异常和设备退化，并继续进行DSN的维护和操作，以支持未来围绕我们宇宙的深空任务。该研究背景涵盖了DSN基础设施及其数据处理的挑战。", "innovation": "研究采用了多种机器学习技术来完全重建数据并通过预测分析，以及通过统计计算和阈值确定实时数据集中的异常数据。此外，还集成了一种基于严重级别的强化学习子系统以及大型语言模型，为每个异常数据条目提供解释，这些都通过人类反馈/输入进行了改进和完善。特别地，还实施了一个完整的数据管道系统，将数据提取、解析和处理的工作流程结合在一起，并完成了DSN异常检测的数据流工作。", "conclusion": "该研究围绕并进一步连接了一个代理AI系统，其中复杂的逻辑推理被用来确定异常数据的分类和预测。通过这一系统，成功完成了从DSN天线数据中训练的模型的数据流，使其能够适应性和自动化地检测DSN中的异常。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO: 基于预估价值的策略优化方法及其在代理推理中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "批评驱动的强化学习方法，尤其是群体策略，因其在复杂任务中的高效性而受到关注。然而，这些方法依赖于在策略内进行多次采样和比较以估计优势，这可能导致策略陷入局部最优解，并增加计算成本。为了解决这些问题，我们提出了PVPO方法，该方法增强了通过优势参考锚和数据预采样获得的高效性认可机制。", "innovation": "我们利用参考模型预先进行展开，并采用计算得出的奖励积分作为参考锚。这种做法有效地修正了群体内比较引入的累计偏差，并大大减少了对采样数量的依赖。同时，参考模型在数据预采样期间可以评估样本难度，从而能够有效选择高收益数据以提高训练效率。实验结果表明，PVPO方法取得了目前最佳性能（SOTA）并展示了在多任务上的鲁棒泛化能力。此外，该方法还展示了在不同规模模型上具有可扩展性性能。", "conclusion": "实验表明，PVPO在九个数据集上的两个领域中达到最先进的性能。我们的方法不仅在多个任务中表现出强大的泛化能力，还展示了在不同规模模型上的可扩展性性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21146", "html_url": "https://arxiv.org/abs/2508.21146", "title": "通过局部似然攻击审计合成数据发布中的隐私", "title_en": "Privacy Auditing Synthetic Data Release through Local Likelihood Attacks", "authors": "Joshua Ward,Chi-Hua Wang,Guang Cheng", "background": "审计合成数据泄露隐私是一个重要但未解决的问题。现有的大多数合成数据隐私审计框架依赖于启发式方法和不合理的假设来攻击生成模型的失败模式，显示出有限的能力来描述和检测通过合成数据发布显示的训练数据隐私暴露情况。", "innovation": "本文提出了一种名为Generative Likelihood Ratio Attack (Gen-LRA)的新颖、计算高效的No-Box MIA，其通过评估测试观察对代理模型在合成数据上局部似然比估计中的影响来构建攻击，不受模型知识或访问限制。实验结果显示，Gen-LRA在多种性能指标上表现优于其他MIAs，证明了其在合成数据发布隐私审计中的有效性，揭示了生成模型在实际应用中的过度拟合所造成的重要隐私风险。", "conclusion": "Gen-LRA在多个性能指标上持续优于其他MIAs，凸显了其作为合成数据发布隐私审计工具的有效性，强调了实际应用中生成模型过度拟合所带来的重要隐私风险。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21141", "html_url": "https://arxiv.org/abs/2508.21141", "title": "在预算限制下的自适应大语言模型路由", "title_en": "Adaptive LLM Routing under Budget Constraints", "authors": "Pranoy Panda,Raghav Magazine,Chaitanya Devaguptapu,Sho Takemori,Vishal Sharma", "background": "大型语言模型（LLMs）在自然语言处理领域取得了革命性进展，但它们的能力和成本差异性带来了实际应用中的挑战。LLM路由通过动态选择最适合每个查询/任务的LLM来应对这一挑战。然而，先前的研究将这一问题视为监督学习问题，假设具有完全的最优查询-LLM配对知识。但在实际应用场景中，缺乏这样的全面映射，并且用户查询在不断演变。因此，研究将其视为上下文多臂问题，利用多臂反馈进行适应性决策，而不必对所有LLM和所有查询进行全面推理（与监督路由相比）.", "innovation": "本文提出将LLM路由视为上下文多臂问题，并通过偏好先验引导的LinUCB（PILOT）进行扩展。引入了一个在线成本策略，将其建模为多选择背包问题，以确保资源高效路由。这种方法允许根据不同的用户预算进行自适应路由决策，而不进行全面的模型推断，解决了实际部署中的成本控制问题。", "conclusion": "文中提出的PILOT方法，通过上下文多臂方法和偏好先验引导使得路由决策更加灵活和适应性强，特别是在用户预算有限的情况下。该方法在提高模型效率的同时，也增强了系统的灵活性和鲁棒性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "使用增强注意力的双向长短期记忆神经网络实现联合48小时温度、辐照度和相对湿度可解释的预测", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "本文提出了一种深度学习（DL）框架，用于对未来48小时的温度、辐照度和相对湿度进行预测，以支持智能 HVAC 系统中的模型预测控制（MPC）。利用2019-2022年的历史气象数据和编码的时间周期特征进行训练，2023年的数据用于评估泛化能力。该模型在温度（1.3°C）、辐照度（31 W/m²）和相对湿度（6.7%）上的平均绝对误差（MAE）均优于最先进的数值天气预测和机器学习基准，显示出良好的预测准确性。", "innovation": "本文采用了堆叠的双向长短期记忆（BiLSTM）网络并结合了注意力机制，以联合预测所有的气象变量。这种方法能够捕捉时间依赖性和跨特征依赖性。集成梯度能够量化特征贡献，注意力权重揭示了时间模式，提升了模型的解释性。通过结合多变量预测、基于注意力的深度学习和可解释性，这篇论文推进了数据驱动的天气预测。", "conclusion": "通过展示高精度和透明度，本文框架的实用性得以证明，它有潜力通过可靠的短期气象预测实现能源高效的楼宇控制。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深出级反馈残差回声状态网络：探索训练外循环神经网络中的残差正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "Echo State Networks (ESNs) 是一种在 Reservoir Computing (RC) 框架内的未训练递归神经网络 (RNNs) 类型，以其快速和高效的学习而广受青睐。然而，传统的 ESNs 在处理长期信息处理时经常遇到困难。", "innovation": "本文提出了一种基于时序残差连接的深层未训练递归神经网络，称为 Deep Residual Echo State Networks (DeepResESNs)。利用未训练的残差循环层的层次结构显著提升了记忆容量和长期时间建模能力。研究了不同的正交残差连接配置对网络动力学的影响，并提供了确保 DeepResESN 动态稳定的数学分析条件。", "conclusion": "在各种时间序列任务上的实验展示出提出的 DeepResESN 方法相对于传统的浅层和深层 RC 方面的优势。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE：树集成的灵活遗忘", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "树集成在分类任务中被广泛认可，取得最先进的性能，适用于生物信息学、金融和医学诊断等多个领域。然而，随着对数据隐私和被遗忘权利的重视，提出了多种遗忘算法以使树集成能够遗忘敏感信息。但现有方法往往针对特定模型或依赖于树的离散结构，难以在复杂集成上泛化，也不适用于大规模数据集。", "innovation": "提出了一种新颖的树集成遗忘算法FUTURE。通过将遗忘样本任务形式化为基于梯度的优化问题，并采用优化框架中的概率模型近似来解决梯度不可导的问题，实现了端到端高效有效的遗忘。", "conclusion": "在真实世界数据集上的大量实验表明，FUTURE展示了显著且成功的遗忘性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "全矩阵预条件动态低秩逼近在训练广义线性模型中的应用", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "Adagrad及其变体在大规模优化中广泛应用，但由于使用对角预条件矩阵，它们限制了参数间相关性的捕捉能力。全矩阵自适应方法通过近似精确海森矩阵可建模这些相关性，旨在加快收敛速度，但其计算和内存成本通常对大规模模型来说过高。", "innovation": "提出AdaGram优化器，这是一种能够高效执行全矩阵自适应梯度更新的方法。通过使用快速对称因子分解在每次迭代中计算预条件更新方向来减少内存和计算开销。此外，使用矩阵积分方法维护预条件器在优化轨迹上的低秩结构。", "conclusion": "在标准机器学习任务上的数值实验表明，使用秩五及其以内近似的AdaGram收敛速度更快或与对角自适应优化器性能相当。这表明AdaGram是大规模模型中自适应优化的可扩展解决方案。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "下一个标记预测中的流形轨迹：从复制动态到softmax平衡", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "大型语言模型中的解码过程通常被描述为对令牌进行评分并使用softmax进行归一化。本文对这一过程进行了简明的、自包含的描述，认为这是在概率单纯形上的约束变分原理。离散的、遵循归一化的上升过程是经典的乘法权重（熵镜映）更新；其连续时间极限是复制流。通过这两个组件，本文证明了在固定上下文和温度的情况下，下一个令牌的概率分布随时间在单纯形内平滑轨迹移动，并收敛到softmax平衡。这一分析形式化了常见的“流形遍历”直觉。", "innovation": "本文提供了一种从复制动态到softmax平衡的形式化证明，对时间动态给出了精确的解释：温度作为时间的精确缩放因子，而top-k和nucleus采样限制流形轨迹到同一面上并有相同保证。此外，还概述了路径依赖分数调整及其与幻觉式行为的联系。另外，文中没有涉及训练动态或内部表示的内容，该部分将留待未来的研究。", "conclusion": "本文证明了下一个令牌的概率分布遵循单纯形内的平滑轨迹并最终收敛到softmax平衡，形式化了常见的“流形遍历”直觉。此外，对时间动态给出了明确的解释，类似于top-k和nucleus采样的限制会将流程限定向面上，且有相同的结果。还概述了路径依赖分数调整及其与幻觉式行为的联系。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21278", "html_url": "https://arxiv.org/abs/2508.21278", "title": "在流学习中检测肌电激活的领域偏移：挑战与机遇", "title_en": "Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning", "authors": "Yibin Sun,Nick Lim,Guilherme Weigert Cassales,Heitor Murilo Gomes,Bernhard Pfahringer,Albert Bifet,Anany Dwivedi", "background": "肌电图(EMG)信号由于固有的非稳定性，使得在生物力学建模中检测领域偏移面临重大挑战。特别是在实时监测和解码肌电控制的假肢时，这种非稳定性尤为关键。本文聚焦于从Ninapro数据库中获取的DB6数据集，采用数据流(DS)学习技术进行领域偏移检测。通过对不同受试者和不同记录时段的肌电时间序列数据进行处理，旨在发现并提升实时肌电信号领域偏移检测的方法。", "innovation": "本文创新地使用了Kernel Principal Component Analysis (KPCA)结合余弦内核来进行预处理，以突出显示由不同受试者和不同时段所导致的领域偏移。并基于此通过评估包括CUSUM、Page-Hinckley 和 ADWIN等多种漂移检测方法，揭示了当前技术在实现实时域迁移检测的不足之处。", "conclusion": "实验证明了基于流的方法在保持稳定肌电解码模型方面具有潜在的作用，但仍需要进一步研究以提高在实际应用场景中的鲁棒性和准确性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21240", "html_url": "https://arxiv.org/abs/2508.21240", "title": "使用自组织映射和变分自编码器通过合成重放进行类别增量持续学习", "title_en": "Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay", "authors": "Pujan Thapa,Alexander Ororbia,Travis Desell", "background": "近年来，持续学习领域发展迅速，尤其是在处理高维数据输入时更为重要。现有的方法大多需要存储原始数据样本或任务标签，这不仅消耗大量存储空间，还可能引入数据隐私问题。针对这一挑战，本文基于自组织映射（SOM）和变分自编码器（VAE）提出了一种新型的生成式持续学习框架，旨在实现高效的重放，无需存储大量原始数据和任务标签。", "innovation": "该方法利用VAE和SOM构建了一个自适应的生成模型，用于高效存储和重用学习到的信息。对于高维输入，SOM操作于VAE学习到的潜在空间；而对于低维输入，SOM则独立操作。方法中存储每个SOM单元的运行时均值、方差和协方差，通过合成样本进行未来的学习迭代。VAE模型生成的样本通过解码器用于后续迭代的重放。实验结果表明，该方法在标准类别增量基准上的性能与最先进的基于内存的方法相当，并优于无内存方法，特别在CIFAR-10和CIFAR-100类别增量学习中分别提高了近10%和7%的最佳单类别性能。此外，该方法还可以方便地进行学习过程的可视化，作为训练后的生成模型使用，提供了一种可扩展的、无需任务标签且内存高效的持续学习解决方案。", "conclusion": "本文提出的方法在多项标准测试集上展示了其在持续学习任务中的优异表现。此方法不仅有效降低了存储需求和数据隐私风险，还在保持了高性能的同时，为用户提供了一种简单易用的持续学习工具。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21258", "html_url": "https://arxiv.org/abs/2508.21258", "title": "RelP: 基于相关性斑图的忠实且高效的电路发现", "title_en": "RelP: Faithful and Efficient Circuit Discovery via Relevance Patching", "authors": "Farnoush Rezaei Jafari,Oliver Eberle,Ashkan Khakzar,Neel Nanda", "background": "激活斑图是机制可解释性中的标准方法，用于定位模型中导致特定行为的组件，但在大规模应用时计算成本昂贵。归因斑图提供了一种更快的、基于梯度的近似方法，但会在深度、高度非线性网络中产生噪声并降低可靠性。", "innovation": "本文提出了相关性斑图(Relevance Patching, RelP)，用来自层相关性传播(Layer-wise Relevance Propagation, LRP)的传播系数代替归因斑图中的局部梯度。LRP通过将输出反向传播并通过各层重新分配相关性，根据局部传播规则来确保属性如相关性守恒或信号噪声比提升。RelP仅需两次前向传播和一次后向传播，保持计算效率同时提高真实性。实验证明，RelP比标准归因斑图更准确地近似激活斑图，特别是在间接对象识别(IOI)任务中分析剩余流和MLP输出时。此外，与集成梯度(IG)相比，RelP识别稀疏特征电路的忠实度相当，而没有额外的计算成本。", "conclusion": "RelP在计算效率和忠实性方面均超过了现有方法，特别是在处理高度非线性网络时，能够提供更准确的解释。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "用于外部气动增强代理建模的专家混合门控网络", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "汽车设计和优化周期中，高保真CFD（计算流体动力学）模拟的成本仍然是一个重要瓶颈。虽然基于ML（机器学习）的代理模型作为加速气动预测的替代方案前景光明，但该领域特化的神经网络架构多种多样且快速变化，迄今没有单一模型表现出普遍的优势。", "innovation": "该论文提出了一种新颖的元学习框架，利用这一架构多样性作为一个优势。论文中提出了一种专家混合（MoE）模型，使用专有的门控网络动态且优化地结合了三种最先进的代理模型预测，分别是可分解多尺度神经操作符的DoMINO、可扩展多尺度图神经网络的X-MeshGraphNet以及因子化隐式全局卷积网络的FigConvNet。门控网络学习一个空间变异加权策略，基于每个专家在其预测表面压力和壁面剪切应力领域的局部性能来评估其可信度。为了防止模型崩溃并鼓励专家之间的平衡贡献，论文在训练损失函数中整合了一个熵正则化项。整个系统在DrivAerML数据集上进行训练和验证，这是一个大尺度的公共基准数据集，包含高保真CFD模拟数据，用于汽车气动学。定量结果显示，MoE模型在L-2预测误差方面取得了显著降低，优于单一最准确专家模型的平均值在所有评估的物理量上。这项工作确立了MoE框架作为一种强大而有效的策略，通过协同结合专有架构的互补优势来创建更具鲁棒性和准确性的复合代理模型。", "conclusion": "此研究证明，通过结合三种不同类型的最先进的代理模型，MoE模型能够在汽车外部气动代理建模任务中提供显著的性能提升，展示了MoE框架在增强的代理学习领域的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21270", "html_url": "https://arxiv.org/abs/2508.21270", "title": "猜和学习（G&L）：冷启动适应的累积错误成本衡量", "title_en": "Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation", "authors": "Roland Arnold", "background": "目前机器学习模型评估常侧重于最终准确率，而忽视了适应成本，即模型从无标签数据中学习时累计犯下的错误。猜想与学习(G&L) v1.0通过衡量冷启动适应能力，即模型在处理无标签数据集时累积犯下的错误，填补了这一空白。在整个学习过程中，模型通过对每个实例进行预测、接收地面真相并更新参数，从而暴露了适应速度、选择质量和偏差等动态过程，这些动态过程在终点指标中是不可见的。G&L 设计了四种轨道，以区分初始化和更新频率的影响，揭示了不同模型在早期阶段的效率差异。", "innovation": "G&L通过衡量冷启动适应过程中累积的错误成本，填补了现有评估方法的空白。它定义了四种不同的轨道来区分初始化和更新频率的影响，揭示了不同模型在早期阶段的效率差异。此外，G&L还提供了可复制的框架，用于开发不仅在最终准确率上有保证，而且在早期利用第一例样本也可靠的模型。", "conclusion": "尽管当前模型在所有设置中均高于“先验参考带”，这表明存在适应性差距。通过量化早期学习过程中的错误成本，G&L不仅补充了传统的基准测试，还为开发不仅准确而且从第一个示例开始就可靠的模型提供了一个可重复的框架。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21273", "html_url": "https://arxiv.org/abs/2508.21273", "title": "CALM: 在时间序列流中实现持续、适应性和大语言模型介导的异常检测框架", "title_en": "CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams", "authors": "Ashok Devireddy,Shunping Huang", "background": "非平稳时间序列流中的异常检测是一项具有挑战性的任务，在工业和科学领域普遍存在。传统的离线训练模型在遇到概念漂移（数据的统计属性随时间发生变化）时，性能会严重下降。因此，开发能够在动态环境中实时检测异常并保持高绩效的解决方案是必要的。", "innovation": "该论文提出了一种名为CALM（Continuous, Adaptive, and LLM-Mediated）的新颖、端到端框架，用于处理实时异常检测中的挑战。该框架的创新之处在于有两个核心贡献：1）实现了一个闭环的、持续的微调机制，使得异常检测模型能够实时适应数据模式的变化；2）引入了一个以大语言模型为裁判的组件，该模型可以提供基于语义和上下文的判断，决定所检测到的异常是否代表瞬时噪声或有意义的模式变化，从而帮助构建高质量的训练数据集。", "conclusion": "在综合的TSB-UAD基准测试上评估CALM框架，结果表明，持续微调的模型在大多数数据集中相较于静态、预先训练的模型提高了ROC AUC得分，验证了我们适应性和由大语言模型指导的方法的有效性，能够保持动态流环境中高效的异常检测性能。"}
{"llm_update_time": "20250902", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: 向更高效且更强大的连续学习框架迈进", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "在连续学习（CL）中，保持对新任务的敏感性并同时维护对过去知识的记忆是至关重要的。尽管尖锐度感知最小化在迁移学习中表现出效用，并被引入连续学习中以提高记忆保留和学习效率，但仅依赖零阶尖锐度可能在某些情况下偏爱尖锐的最小值而非扁平的最小值，从而导致不太稳健且可能次优的解决方案。", "innovation": "本文提出了C-Flat方法，旨在促进更适合连续学习的更扁平的损失景观。C-Flat具有插件兼容性，便于代码管道中进行简单的集成。此外，提出了一种通用框架，将C-Flat整合到所有主要的连续学习范式中，并进行了与损失最小值优化器和基于平坦最小值得连续学习方法的全面比较。结果表明，C-Flat在各种条件下均能持续提高性能。同时引入了C-Flat++框架，通过选择性地驱动扁平度来提高效率，显著降低了C-Flat所需的更新成本。", "conclusion": "在多种连续学习方法、数据集和场景下的广泛实验表明，我们提出的方法在有效性和效率方面均表现出色。相关代码可在指定网址获取。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "Model-Task Alignment Drives Distinct RL Outcomes", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "近年来，将强化学习（RL）应用于大型语言模型（LLMs）取得了显著进展。特别是在LLMs中报告了若干令人惊讶但又违背直觉的现象，这些现象与传统RL环境中的模式不符。例如，一个单一的训练示例可以与整个数据集的表现相匹敌，奖励信号不一定需要非常准确，甚至仅使用负面样本的训练也可以达到甚至超过基于奖励的复杂方法的效果。然而，这些观察结果在何种条件下成立，尤其是在何种情况下不成立，仍然不清楚。本研究通过系统和全面地检验一系列违背直觉的主张，并在不同的模型架构和任务领域进行严格的实验验证，揭示了关键差异因素：即预训练模型是否已经表现出强烈的Model-Task Alignment（模型-任务对齐），并通过pass@k准确性衡量在评估任务上的性能。研究表明，虽然标准RL训练在各种环境中始终表现出稳健性，但许多违反直觉的结果仅在模型和任务已经表现出强大模型-任务对齐的情况出现，而在更具挑战性的环境中，这些技术未能促使显著的学习。因此，这些方法不能在标准RL方法仍然有效的高级设置中引起实质性的学习进展。", "innovation": "本研究的主要创新在于系统地识别出评估RL结果的关键因素——即预训练模型是否已经表现出强大的Model-Task Alignment。通过广泛的实验验证和对不同模型架构及任务领域的深入分析，研究发现了在模型和任务已高度对齐的情境下，RL可以产生显著的成果；而在更复杂的环境中，即使模型和任务已经对齐，单凭标准RL训练也未能直接驱动显著的知识获取。这项工作为理解RL在LLMs中的行为提供了一个新的视角，特别是对于模型和任务间高度匹配的情况下。它揭示了RL训练结果在不同环境下的差异，并提出了模型在哪些情况下能从RL训练中受益。", "conclusion": "研究发现，标准的RL训练在各种设置中仍然保持稳健性，但在模型和任务已经表现出强烈的模型-任务对齐的情况下，许多违背直觉的观察结果出现。然而，在更具挑战性的环境中，这些技术未能驱动实质性的学习进展。这些结果表明，模型-任务对齐程度对RL训练效果至关重要，同时也展示了在不同环境中，标准RL方法的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "适应性重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型时代，优化算法常常因为过度依赖训练损失而难以实现泛化。机器学习社区普遍认为，宽阔的盆地（损失在局部最小值周围逐渐增加的区域）有助于提高泛化能力，提供更强的输入数据或模型参数的小变化稳定性。相比之下，尖锐的极小值通常更为敏感且不稳定。", "innovation": "文章提出了适应性重尾随机梯度下降（AHTSGD）算法。该算法利用随机梯度下降中固有的重尾梯度噪声特性以及神经网络训练中的边缘稳定性现象，在训练初期注入重尾噪声以增强探索，后期逐渐过渡到轻尾噪声，从而动态适应损失景观的尖锐程度，加速收敛至宽阔的盆地。这是首个基于边缘稳定性现象调整注入噪声性质的优化算法。", "conclusion": "AHTSGD在MNIST和CIFAR-10等基准上始终优于SGD和其他基于噪声的方法，并在像SVHN这样的噪声数据集上表现出显著的性能改进。它能够加速从不良初始化的早期训练，并在干净和噪声环境中均能改善泛化能力，保持对学习率选择的鲁棒性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21324", "html_url": "https://arxiv.org/abs/2508.21324", "title": "分布感知特征选择方法用于SAEs", "title_en": "Distribution-Aware Feature Selection for SAEs", "authors": "Narmeen Oozeer,Nirmalendu Prakash,Michael Lan,Alice Rigg,Amirali Abdullah", "background": "传统的稀疏自编码器（SAEs）通过分解神经激活以提取可解释特征。TopK SAE 是一种流行的变体，它通过选取每个令牌的K个最活跃的潜在变量来进行重建。然而，这种方法存在局限性，因为某些令牌可能携带更多的信息，而TopK方法却忽略了这些信息。BatchTopK通过在整个批次中选择顶级激活来解决这一问题，可以提高重建平均值，但也可能会引发'激活彩票'现象，即稀有的高度激活特征会占据更有信息性但低活性的特征。", "innovation": "为了解决上述问题，作者提出了Sampled-SAE方法。该方法通过计算批激活矩阵中各个特征的$L_2$范数或熵分数来形成候选池，候选池大小为$Kl$。从中选择跨越批次的前K个令牌。通过改变$l$的值能够在批量级别选择和令牌特定选择之间划一条连续的谱线。当$l=1$时，令牌仅从中选择$K$个全局影响显著的特征；而较大的$l$则会使池子变大，更接近标准的BatchTopK方法，并促使在批次中选择了更多特定的令牌。小的$l$值增强了全局一致性，而大的$l$值则有利于精细重建。", "conclusion": "通过采样-稀疏自编码器（Sampled-SAE）方法，作者重新定义了BatchTopK方法为可调的、分布感知的特征选择家族。Pythia-160M上的实验表明，并不存在单一的最佳$l$值能够优化所有度量指标，最佳选择取决于共享结构、重建保真度和下游任务性能之间的权衡。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO：终身学习系统中的生成式离线巩固的内存效益方法", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "终身学习的目标是开发能够从一系列任务中不断获取新知识的模型，同时不会灾难性地忘记以前学到的内容。当前的解决方法通常依赖于存储以前任务的样本（经验回放）或采用复杂的正则化项来保护已经学习的权重。然而，这些方法面临着数据隐私、存储限制以及任务不相似时性能下降的挑战。", "innovation": "本文提出了MyGO（Memory Yielding Generative Offline-consolidation）终身学习框架，该框架受到生物学清醒-睡眠周期的启发。在“清醒”阶段，系统快速学习新任务并训练生成式记忆模型（G-mem）来捕捉数据分布。在“睡眠”阶段，系统进入离线状态，使用所有学习过的G-mem模型生成伪数据（“梦境”）并通过知识蒸馏将新旧知识共同加固到核心特征提取器中，这种方法避免了存储任何原始数据的需要，只保留紧凑的生成式模型，这对于隐私和存储效率具有显著优势。", "conclusion": "本文在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准上评估了MyGO，并将其与序列微调基准进行对比，结果显示MyGO在各任务中显著减轻了灾难性遗忘并保持了高平均准确率，证明了该框架的有效性和领域通用性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21396", "html_url": "https://arxiv.org/abs/2508.21396", "title": "PMODE：基于理论支持和模块化的混合建模", "title_en": "PMODE: Theoretically Grounded and Modular Mixture Modeling", "authors": "Robert A. Vandermeulen", "background": "该论文介绍了一种混合建模的方法，即PMODE（Partitioned Mixture Of Density Estimators，分区混合的密度估计器），它是一个通用且模块化的框架，适用于同时包含参数化和非参数化组件的混合建模。通常，混合模型在数据分区后，为每个数据子集拟合独立的估计器。这种方法不仅在估计器类中近似最优率，而且即使混合组件来自不同的分布家族，其有效性也不受影响。本文的一个具体应用是开发了MV-PMODE，这是一种扩展理论上的高维度密度估计方法到数千维度的方法。", "innovation": "PMODE框架的创新在于它能够同时处理参数化和非参数化组件，并通过分区数据集为每个子集找到合适的估计器。MV-PMODE进一步将这种方法应用于高维密度估计，并展示了在CIFAR-10异常检测中的竞争力，而无需复杂的深度学习方法。", "conclusion": "PMODE及其扩展版本MV-PMODE为混合建模提供了一个既简单又强大的框架，能够在高维度和不同分布情况下保持高性能。特别是在异常检测领域中，即使与深度学习方法相比，它仍能取得令人满意的结果。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21314", "html_url": "https://arxiv.org/abs/2508.21314", "title": "POMDPs中正则化代理状态基础Q学习的收敛性", "title_en": "Convergence of regularized agent-state-based Q-learning in POMDPs", "authors": "Amit Sinha,Matthieu Geist,Aditya Mahajan", "background": "本文介绍了一种理解在实际应用中常用Q-learning强化学习算法收敛性的框架。这类算法的两个显著特点是：（i）使用的一个代理状态（如递归神经网络的状态）不断更新Q表，但该状态既不是信念状态也不是信息状态；（ii）经常使用策略正则化来鼓励探索并稳定学习算法。本文探讨了一种最简单的形式的这些Q-learning算法，并命名为基于代理状态的正则化Q学习（RASQL），并证明在某些技术假设下，它会在适当定义的包含特定正则化的MDP的固定点收敛，依赖于由行为策略诱导的平稳分布。", "innovation": "研究了基于代理状态的正则化Q学习（RASQL）算法及其变体，并证明了在一定条件下会收敛于适当定义的正则化MDP的固定点。同时展示了该分析在学习周期性策略时仍然有效。", "conclusion": "通过数值例子展示了实际收敛行为与理论极限的匹配。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21300", "html_url": "https://arxiv.org/abs/2508.21300", "title": "提高基于LoRA的LLM取消学习中Fisher信息估计和效率", "title_en": "Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning", "authors": "Yejin Kim,Eunwon Kim,Buru Chang,Junsuk Choe", "background": "大语言模型（LLMs）在各种任务中表现出色，但也面临着意外生成包含敏感信息输出的挑战。一种简便的方法是排除问题数据后再训练模型，但这会导致巨大的计算成本。为此，机器遗忘（机器学习中的一个概念）作为一种潜在的解决方案出现，它可以在不重新从头训练模型的情况下有效删除敏感信息。FILA 是一种通过整合LoRA适配器来提高参数效率的取消学习方法，它计算Fisher信息以识别与忘记集合相关的参数并将其分配给LoRA适配器。然而，FILA仍需要访问所有模型参数，并且没有充分考虑到Fisher信息底层的基本假设，从而影响了重要性估计的准确性。", "innovation": "本文提出了VILA，一个新颖的取消学习框架，它明确考虑了FILA中被忽略的基本假设，从而提高了忘记集合参数识别的准确性。此外，VILA通过无需访问整个模型即可实现参数识别，大大降低了计算成本。与FILA相比，VILA实现了高达100倍更高的参数效率和40倍更快的训练速度，并在TOFU、WMDP和MUSE基准测试中设立了新的最先进的性能水平。", "conclusion": "本文通过提出VILA，解决了FILA中由于未充分考虑Fisher信息基本假设而导致的准确性问题，并通过提高参数效率和减少计算成本，显著改进了基于LoRA的大语言模型的取消学习方法，实现了新的性能标准。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN: 基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列合成是确保时间序列数据安全流通的有效方法。现有的时间序列合成方法往往基于随机序列进行时间建模以生成目标序列，这常常难以保证生成时间序列中的时间依赖性。直接在随机序列上建模时间特征使得准确捕捉原始时间序列中的特征信息变得困难。为了解决这些挑战，该研究提出了一种简单但有效的生成模型——双层生成对抗网络DLGAN。该模型将时间序列生成过程分解为两个阶段：序列特征提取和序列重构。这两个阶段共同构成一个完整的时间序列自编码器，允许在原始时间序列上进行监督学习，确保重构过程可以恢复序列的时间依赖性。此外，该模型还采用生成对抗网络（GAN）来生成与实时序列特征向量对齐的合成特征向量，以确保生成器能够从实际时间序列中捕捉到时间特征。通过对四个公开数据集的广泛实验，该模型在各种评估指标上展现出优越性。", "innovation": "该研究提出了一种双层生成对抗网络DLGAN，通过将时间序列生成过程分解为序列特征提取和序列重构两个阶段，以及利用生成对抗网络生成与实时序列特征向量对齐的合成特征向量，有效解决了现有方法中存在的时间依赖性建模困难和特征信息捕捉不准确的问题。", "conclusion": "广泛的实验结果证明了DLGAN在各类评估指标上的优越性，表明该方法能够有效提升时间序列合成的质量，从而为时间序列数据的安全流通提供可靠的保障。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff: 基于扩散模型的阶段式长期时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型在时间序列生成领域取得了显著的成果，但当处理长时期跨度的时间序列，这些序列包含复杂的长期时间依赖关系且其数据分布随时间逐渐变化时，生成任务变得极具挑战性。长时期序列具有远距离时间依赖关系，但其数据分布随时间逐渐变化。因此，找到两者之间的平衡是一个关键挑战。此外，长时期序列包含不同特征序列之间的复杂关系，如何有效地捕捉内部依赖和跨序列依赖也成为一个重要挑战。为了解决这些问题，我们提出了一种基于扩散模型的阶段式生成模型Stage-Diff。", "innovation": "Stage-Diff模型通过阶段式序列生成和阶段间信息转移，保留了长期序列依赖关系，同时能够建模数据分布的变化。每个阶段内使用分步序列分解进行跨通道独立建模，并在阶段间通过多通道融合建模进行信息转移。这结合了跨通道独立建模的鲁棒性与多通道建模的信息融合优势，有效平衡了长时期序列内的依赖和跨序列依赖关系。实验结果证明，Stage-Diff在长期时间序列生成任务中具有显著效果", "conclusion": "Stage-Diff模型通过阶段式生成和信息转移机制，结合跨通道独立建模与多通道融合建模，成功解决了长期时间序列生成中的依赖关系建模挑战。该模型在多个实际数据集上的实验结果进一步验证了其在长期时间序列生成任务中的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "棋弈神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "本文旨在探讨神经网络在建立表示时是否通过平滑而渐进的改进，还是通过更复杂的计算过程。研究者以超人级国际象棋引擎Leela Chess Zero的策略网络为基础，扩展了逻辑视角（logit lens），以分析这一问题。现有研究通常观察到语言模型中分布收敛是平滑的，但尚未全面探究这一特性在不同领域的神经网络中是否同样成立。", "innovation": "研究引入了一种新的分析方法——扩展逻辑视角（logit lens），应用于Leela Chess Zero的策略网络。这种方法能够揭示棋弈神经网络在不同层面上的动态表现。通过这种方法，研究者发现了在模型强度和解题能力方面存在强烈的单调趋势，但策略分布模式却经常表现出非平滑的轨迹。这些发现表明，神经网络在某些情况下可能通过更复杂的计算过程而非平滑改进来构建其表示。", "conclusion": "研究结果表明，虽然神经网络在一些指标上表现出平滑递增的趋势，但其策略分布却通常表现出非平滑的轨迹。具体表现为，早期解决的正确解题方案随后被放弃，决策评分与最终输出的相关性偏低，直到网络晚期政策才会高度分散。该研究提供了实证证据，驳斥了语言模型分布收敛通常平滑的观点。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21421", "html_url": "https://arxiv.org/abs/2508.21421", "title": "通过链式合并重新思考按层模型合并", "title_en": "Rethinking Layer-wise Model Merging through Chain of Merges", "authors": "Pietro Buzzega,Riccardo Salami,Angelo Porrello,Simone Calderara", "background": "预训练模型的微调已成为实现跨多种领域最先进性能的标准途径，导致了大量特定任务模型变体的出现。随着这些专用模块数量的增加，无需重新训练合并它们已成为一个关键挑战。现有合并技术通常依赖于干扰启发式方法、重要性加权或激活匹配，而对每个层进行独立处理，因此未能考虑深网络中的跨层依赖关系。这种简化导致了分布不匹配，尤其是在基于激活的方法中，早期层的变化未能在下游层中得到适当反映。", "innovation": "我们识别这些不匹配为内部协变量转移的形式，并提出链式合并（CoM）作为一种按层合并方法，以自回归方式更新激活统计数据，明确考虑到跨层交互。CoM 通过一系列条件最优更新生成了一个连贯的合并模型，有效地缓解了由协变量转移引起的退化问题。", "conclusion": "在标准基准上的实验表明，CoM 达到了最先进性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度集成实现结构引导的药物设计中的可控3D分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "近年来，基于结构的药物设计（SBDD）利用生成模型进行3D分子生成，主要通过靶蛋白结合亲和力进行模型性能评估。然而，实际的药物发现不仅需要高结合亲和力，还需要合成可行性和选择性的支持，这些关键属性在以前的评估中被忽视。传统扩散型生成模型在引导生成多样化的药理学性质方面存在明显局限性。", "innovation": "提出了一种名为CByG的新框架，将贝叶斯流网络扩展为基于梯度的条件生成模型，能够在生成分子时提供特定的性质指导，并引入了一个全面的评价方案，这种方法能够克服传统评价方法的局限。", "conclusion": "广泛的实验表明，提出的CByG框架在多个关键评价标准上显著优于基线模型，证明了其在实际药物发现应用中的有效性和实用性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21443", "html_url": "https://arxiv.org/abs/2508.21443", "title": "超越期望值：强化学习中长期策略性能的几何均值优化", "title_en": "Beyond expected value: geometric mean optimization for long-term policy performance in reinforcement learning", "authors": "Xinyi Sheng,Dominik Baumann", "background": "强化学习（RL）算法通常优化累计奖励的期望值，即代理在轨迹中收到的标量奖励的期望值。期望值是对无限轨迹集合的性能平均值。然而，在现实世界中部署代理时，这种集合平均值可能无法提供单个轨迹的性能信息。因此，在许多应用中，优化单个轨迹的长期性能可能更为理想。", "innovation": "本文提出了一种新型的强化学习算法，它将标准的集合平均值与时间平均增长率相结合，时间平均增长率是单个轨迹长期性能的衡量标准。作者首先定义了时间平均增长率的贝尔曼算子。然后，作者展示了在乘法奖励动态下，几何平均与时间平均增长率一致。为了处理更通用和未知的奖励动态，提出了一个带有N滑动窗口的修改几何平均值，该估值器作为正则化器嵌入到目标中，形成一个切实可行的算法，使得策略能够同时受益于集合平均值和时间平均值。", "conclusion": "该算法在具有挑战性的模拟测试中表现出色，超越了传统的RL方法。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21261", "html_url": "https://arxiv.org/abs/2508.21261", "title": "Owen 抽样加快联邦学习中的贡献估计", "title_en": "Owen Sampling Accelerates Contribution Estimation in Federated Learning", "authors": "Hossein KhademSohi,Hadi Hemmati,Jiayu Zhou,Steve Drew", "background": "联邦学习（FL）能够在不暴露原始数据的情况下，通过多个客户端聚合信息来共同训练全局模型。准确地估计每个客户端的贡献对于公平奖励以及加速全局模型的收敛都非常关键。然而，精确计算每个客户端的Shapley值随着客户端数量的增加会呈指数级增长，使得在大规模联邦学习环境中不可行。", "innovation": "我们提出了FedOwen，这是一种高效框架，利用Owen抽样的方法在和现有方法相同的总评价预算下，来估算Shapley值，同时保持较小的近似误差。此外，FedOwen还使用了一种适应性的客户端选择策略，平衡利用高价值客户端和探索未充分采样的客户端，减少偏差并发现罕见但有价值的数据。", "conclusion": "在固定估值成本的情况下，FedOwen在相同通信轮次下，相比于最新的基准方法，可以在非IID基准上获得高达23%的更高最终准确率。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21495", "html_url": "https://arxiv.org/abs/2508.21495", "title": "失败预测是评价早退网络性能比校准更合适的表现代理", "title_en": "Failure Prediction Is a Better Performance Proxy for Early-Exit Networks Than Calibration", "authors": "Piotr Kubaty,Filip Szatkowski,Metod Jazbec,Bartosz Wójcik", "background": "早期退出模型通过在模型中间层添加内部分类器并在预测满足退出标准时停止计算来加速推理。大多数早期退出方法依赖于基于置信度的退出策略，这促使一些研究工作校准中间分类器以提高整个模型的性能。研究表明，校准措施可能误导多出口模型的性能指标：即使分类器校准良好，也可能浪费计算，并且常见的校准方法无法保持分类器内的样本排名。实验证据显示，错误校准的网络可能会优于校准的网络。", "innovation": "本文提出了使用失败预测作为更有效的早退模型性能代理的替代方法。与校准不同，失败预测考虑了样本排名的变化，并与效率提高有很强的相关性，因此它为设计和评估早退模型提供了更可靠的依据。", "conclusion": "失败预测是一种比校准更有效的早退网络性能代理。它能更好地反映模型的实际性能和计算效率，并能够更好地指导和评估早退模型的设计。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于水库计算的低成本网络状态基准测试方法", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "利用挪威移动网络使用的数据，本文展示了通过非侵入性、低成本的方法监测通信和移动网络状态的可能性。移动网络利用数据以匿名、聚合形式存在，每天有多次快照。利用这种数据视其为加权网络，并采用水库计算框架，通过将网络数据转化为模型并在代理任务中的表现来评估网络状态。这种方法的关键优势在于使用现成的数据集，并利用水库计算框架作为负担得起且大部分无偏的方法。水库计算允许将加权但未训练的网络作为机器学习工具使用，从而在信号传递至一个高维空间进行单层训练后消耗的能源少于需要逐层训练每个权重的深度神经网络。", "innovation": "创新点在于使用现成的、匿名聚合的数据集，此类数据可视为加权网络，并采用水库计算框架，通过网络在代理任务中的表现来监控网络状态。这种方法比传统的深度神经网络更简便、高效。同时，本文使用神经科学启发的任务，并训练了ESN模型来解决这些问题，展示了性能取决于网络配置，并且在网络受到干扰时会明显下降。这种方法从概念上证明是可行的，未来可以实现近乎实时的监控和识别网络的薄弱环节，包括移动通信网络和交通网络。", "conclusion": "本文的研究成果展示了一种使用现成数据集并通过水库计算框架实现实时、低成本监控网络状态的方法。虽然这种方法已经证明了概念上的可行性，但它可以进一步发展为在网络出现可能的问题前进行预警，并识别出网络的弱点。实验结果表明，利用水库计算方法进行网络状态监测不仅更经济、效率更高，而且能够为网络管理和优化提供有价值的洞见。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受还是拒绝？跨表格到文本序列化方法评估大型语言模型在贷款审批中的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "大型语言模型（LLMs）在高风险决策任务中越来越受欢迎，比如贷款审批。然而，这些模型在处理表格数据、确保公平性和提供可信赖预测方面存在局限性。本文通过评估来自三个不同地区的贷款审批数据集（加纳、德国和美国），分析LLMs在序列化表格数据（即将表格数据转换为适配LLMs处理的文本格式的过程）上的表现和公平性。", "innovation": "本文引入了对LLMs在针对表格数据的不同序列化方法下的零样本学习和上下文学习能力的评估。研究发现，不同的序列化格式显著影响LLMs的表现和公平性，某些格式如GReat和LIFT在提高F1分数的同时，加剧了公平性的差异。此外，上下文学习在提高LLMs性能方面效果显著，但对公平性的影响表现不一。", "conclusion": "本文强调了有效表示表格数据方法和公平性意识模型的重要性，以提高LLMs在金融决策中的可靠性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正需要什么数据？推荐系统中推理数据最小化可行性的研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是法律原则，要求个人数据处理仅限于实现特定目的所必需的范围。对于需要大量个人数据的推荐系统来说，实现这一原则依然是一个重大挑战。本文针对推荐系统对其进行可行性研究，旨在减少隐式反馈推断数据，并细究其技术可行性。", "innovation": "提出了一个新颖的问题表述，研究了各种最小化技术，并分析了影响其有效性的关键因素。证明了在不牺牲性能的情况下，可以实现大幅减少推断数据的可行性。", "conclusion": "技术上可行，但在技术设定（如性能目标、模型选择）和用户特征（如历史大小、偏好复杂性）方面依赖性极大，因此无法形成一个普遍适用的数据‘必要性’标准。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的模型不匹配问题", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "在强化学习中，不确定性量化能够显著提升探索能力和鲁棒性。近年来，通过近似贝叶斯方法来量化模型自由算法中的不确定性已经变得流行。然而，这些方法主要关注提高后验近似值的准确性，而没有深入研究支撑后验的先验和似然假设的准确性。本文通过研究贝叶斯深度Q学习中的先验分布，发现理论行为和实际行为相悖，即降低后验温度反而提高了性能。同时，作者通过统计测试发现，常见的高斯似然假设经常被违反，这表明在贝叶斯模型自由算法中，先验和似然的模型设定存在缺陷。", "innovation": "本文挑战了贝叶斯模型自由算法中关于先验和似然假设的常见设定，并通过实验证明了高斯模型假设的不准确性。作者提出了改进先验分布的简单可实现的方法，这些方法能够显著提升贝叶斯深度Q学习的性能。", "conclusion": "未来的研究应该更加关注开发更适合的先验分布和似然假设，以改进贝叶斯强化学习算法。本文提供的简单解决方案能够提高深度Q学习中贝叶斯算法的性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21554", "html_url": "https://arxiv.org/abs/2508.21554", "title": "全面评估可穿戴纺织ECG服装的信号质量：性别平衡研究", "title_en": "Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study", "authors": "Maximilian P. Oppelt,Tobias S. Zech,Sarah H. Lorenz,Laurenz Ottmann,Jan Steffan,Bjoern M. Eskofier,Nadine R. Lang-Richter,Norman Pfeiffer", "background": "该研究介绍了一种新型可穿戴纺织服装，其创新的电极放置方式旨在减少噪声和运动伪影，从而提高心电图（ECG）记录的信号保真度。研究通过针对男女生理差异的全面评价，确保该设备的适应性。", "innovation": "研究提出了一种创新的穿戴式纺织品ECG装置，采用独特的电极放置方式，优化了ECG信号的采集质量。并进行了跨性别别、跨生理条件下的全面评估，评估方法包括信号质量客观指标、生理参数的心率和心率变异性分析、机器学习分类任务、ECG特征的形态学分析以及电极投射角度对信号质量的影响研究。", "conclusion": "研究结果表明，该纺织系统在心率和形态学分析中都能获得高质量的信号，并表现出 robust 的分类性能，且能识别出影响信号获取的关键性别特异性因素。这些发现强调了纺织基ECG服装在生理监测及心理生理状态检测中的实用性，并强调了在可穿戴健康技术中考虑性别特异性设计的重要性以确保公平可靠的诊断。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "基于总结-举例-反思的数据驱动洞察蒸馏赋能LLMs进行少量样本表格分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "最近的研究显示，大型语言模型（LLMs）在少量样本表格分类任务上有很大的潜力，但同时也揭示了由于结构化数据变化性的问题带来的挑战。", "innovation": "提出了一种基于总结-举例-反思的数据驱动洞察蒸馏框架——InsightTab。该框架借鉴了人类学习过程的特点，采用了分而治之、先易后难和反思学习的原则。通过LLM和数据建模技术的深度协作，该方法能提取出风险规则总结、策略性示例和洞察反思。这些获得的洞察信息能够更好地帮助LLMs将通用知识和能力与特定表格任务的具体要求对齐。", "conclusion": "在九个数据集上对InsightTab进行了广泛的评估。结果表明，与最先进的方法相比，它具有一致的改进效果。消融研究进一步验证了指导原则下的蒸馏过程的有效性，并且分析强调了InsightTab在利用标记数据和管理偏见方面的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "物理感知神经网络在智能电网代理中的局限性研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "物理感知神经网络（PINNs）通过直接将物理定律融入学习框架，为智能电网建模提供了变革性的方法，解决了数据稀缺性和物理一致性在传统数据驱动方法中的关键挑战。", "innovation": "该论文通过三个实验（插值、交叉验证和事件轨迹预测）评估了PINNs作为智能电网动力学的替代模型的能力，并将其性能与XGBoost、随机森林和线性回归进行了对比。通过仅使用基于物理的损失函数（如电力平衡、操作约束和电网稳定性）来训练PINNs，展示了其优越的泛化能力，优于数据驱动模型的误差减少。特别是在动态电网操作中，PINNs的MAE明显较低，更可靠地捕获了在随机和专家驱动控制场景中的状态转换。", "conclusion": "研究结果表明，PINNs能够在数据驱动灵活性和第一原理严谨性之间架起桥梁，成为智能电网代理的范式工具，这将促进实时电网控制和可扩展的数字孪生技术的发展。本文强调了在关键能源系统中使用物理感知架构的必要性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21466", "html_url": "https://arxiv.org/abs/2508.21466", "title": "黎曼流形上的归一化最大似然码长", "title_en": "Normalized Maximum Likelihood Code-Length on Riemannian Manifold Data Spaces", "authors": "Kota Fukuzawa,Atsushi Suzuki,Kenji Yamanishi", "background": "近年来，随着图形数据的大规模扩展，除了欧几里得空间外，对黎曼流形数据空间的关注也有所增加。特别是，双曲空间的发展尤为显著，它们具有对具有层次结构的图形数据的高表征能力。归一化最大似然估计（NML）适用于后悔最小化和模型选择。尽管如此，现有NML形式主要在欧几里得空间中开发，与坐标系统的选取有内在联系，使得将NML扩展到黎曼流形变得非平凡。本文聚焦于构建一种新的NML，即黎曼流形NML（Rm-NML），其反映黎曼流形的几何结构，且在自然参数化的情况下与传统NML一致。这种新的NML方法在黎曼流形上也扩展了现有计算NML的技术，并就黎曼对称空间（包括增长感兴趣的数据空间，如双曲空间）提出了简化Rm-NML计算的方法。", "innovation": "本文提出了黎曼流形NML（Rm-NML），这是一种新的NML形式，适应黎曼流形的空间，并且在欧几里得空间的自然参数化情况下与传统NML一致。同时，引入了一种简化黎曼对称空间（例如双曲空间的图形数据空间）上Rm-NML计算的方法。", "conclusion": "本文通过计算超曲面空间上的标准正态分布的Rm-NML，展示了提出方法的实际应用，证明了其有效性和实用性。该研究提出了Riemannian manifold NML，突破了传统NML在非欧空间中的应用限制，同时也为复杂结构数据如网络和树形数据处理提供了新的工具。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "关于基于GNN的SAT求解器学习难度的研究：图里奇曲率的作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "图神经网络（GNNs）在解决布尔可满足性问题（SATs）方面显示出了潜力，通过处理逻辑公式的图表示进行操作。然而，它们在处理更难的问题实例时性能急剧下降，这引发了是否反映了基本架构限制的问题。以往研究未能提供几何解释，即图里奇曲率（RC），它量化了局部连通瓶颈。本文通过研究从随机k-SAT公式派生的二分图具有内在负曲率，且曲率随着问题难度的增加而减小的现象，提供了这种几何解释。进一步地，本文证明了基于GNN的SAT求解器受到了‘过度压缩’现象的影响，这种现象使得远程依赖关系难以压缩进固定长度的表示中。实验验证资料显示了该理论的有效性，并确认曲线既可以作为问题复杂性的重要指标，也可以用来预测性能。研究还与现有求解器的设计原则进行了关联，并为未来工作指明了可能的方向。", "innovation": "首次通过图里奇曲率（RC）的角度来解释基于GNN的SAT求解器的学习难度问题。在证明了从随机k-SAT公式派生的二分图具有内在负曲率，并且曲率随着问题难度的增加而减小的现象的基础上，提出了GNN基于的SAT求解器受到‘过度压缩’现象的影响。此外，研究结果可以作为问题复杂性的重要指标，并且用于预测性能。", "conclusion": "通过使用图里奇曲率解释了基于GNN的SAT求解器学习难度问题，证明了基于GNN的SAT求解器受到‘过度压缩’现象的影响。实验结果显示，图里奇曲率是问题复杂性的强指示器，可以用于预测性能。最后，还将研究成果与现有求解器的设计原则进行了关联，并提出了未来的改进方向。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21620", "html_url": "https://arxiv.org/abs/2508.21620", "title": "概率决策算法的分析导论", "title_en": "Introduction to the Analysis of Probabilistic Decision-Making Algorithms", "authors": "Agustinus Kristiadi", "background": "决策理论提供了一种原理性的方法来处理各种类型的不确定性下的选择问题。这些理论算法在材料和药物发现等实际问题上得到了成功应用，并且因其能够适应性地收集信息，能够在未来做出更好的选择，从而带来数据高效的流程。在科学发现领域，实验成本高昂，这些算法因此能够显著降低实验成本。然而，现有文献中关于这些算法的理论分析大多对非专家来说难以理解。", "innovation": "本书旨在为非专家提供一个易于理解且自包含的关于常用概率决策算法理论分析的介绍，包括bandit算法、贝叶斯优化和树搜索算法。仅需要基本的概率论和统计学知识，并且需具备一些高斯过程的基础知识。", "conclusion": "通过提供一个易于理解的理论分析概述，本书旨在将这些算法的复杂理论解释给非专家，从而促进下一代理论和算法的发展。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21505", "html_url": "https://arxiv.org/abs/2508.21505", "title": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control", "title_en": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control", "authors": "Vishal Pandey,Debasmita Biswas", "background": "基于Transformer架构的强化学习代理在顺序决策任务中表现出了显著的性能，但它们依赖密集的矩阵操作，使这些代理不适合能量受限、边缘导向的平台。相比之下，突触神经网络（Spiking Neural Networks, SNNs）承诺实现超低功耗的事件驱动推理，但此前还没有将突触动力学与基于返回的序列建模无缝结合的研究。CartPole-v1、MountainCar-v0、Acrobot-v1和Pendulum-v1等经典控制基准测试结果显示，标准的Decision Transformer在这几个任务上的表现良好。", "innovation": "本文提出了Spiking Decision Transformer (SNN-DT)，这是一种将Leaky Integrate-and-Fire（LIF）神经元嵌入到每个自注意力块中的方法，通过拟似梯度进行端到端训练，并引入了生物启发的三因素可塑性、基于时间相位的脉冲位置编码以及轻量级的树突路由模块。SNN-DT在能耗方面表现出色，每决策仅发射不到十个脉冲，这表明与标准的Decision Transformer相比，每次推理的能耗降低了4个数量级。", "conclusion": "通过将序列建模与神经形态效率相结合，SNN-DT为嵌入式和可穿戴设备实现实时、低功耗控制开辟了一条新的途径。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21650", "html_url": "https://arxiv.org/abs/2508.21650", "title": "从情感和时间特征预测社交媒体参与度", "title_en": "Predicting Social Media Engagement from Emotional and Temporal Features", "authors": "Yunwoo Kim,Junhyuk Hwang", "background": "本研究旨在利用机器学习技术预测社交媒体中的参与度（包括评论和点赞）。研究基于一个包含600首歌曲的数据集，该数据集包含情感和情绪特征的注释。研究采用了经过对数变换的目标参与度比率进行多目标回归模型训练，以应对目标数据分布偏斜的问题。研究通过自定义和标准回归评估指标来评估性能。", "innovation": "本研究提出了一种机器学习方法，通过情感和时间特征预测社交媒体的参与度。研究采用了HistGradientBoostingRegressor模型，并且通过自定义的和标准的回归评估指标来评价模型性能。研究发现，情感和时间元数据，加上现有的浏览次数，能够有效预测未来的参与度，同时探讨了点赞和评论预测结果之间的差异。", "conclusion": "情感和时间元数据能够有效地预测社交媒体的参与度。研究结果表明，点赞主要由易捕捉的情绪和曝光信号驱动，评论则依赖一些目前特征集中未包含的因素。点赞的R^2值达到了0.98，而评论的R^2值仅为0.41。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21571", "html_url": "https://arxiv.org/abs/2508.21571", "title": "随机梯度方法在宽两层物理感知神经网络收敛性的研究", "title_en": "Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks", "authors": "Bangti Jin,Longjun Wu", "background": "物理信息神经网络（PINNs）是解决偏微分方程的一种非常流行的神经网络求解器。实际操作中通常采用随机梯度下降类型算法来训练神经网络。因此，随机梯度下降的收敛性保证非常重要。", "innovation": "在本文中，作者建立了在高概率意义下，随机梯度下降/流动训练过参数化的两层PINNs的线性收敛性，适用于一般激活函数。这一结果扩展了早期分析梯度下降的研究成果[18]。分析的难点在于处理随机优化方法引入的动态随机性，关键在于确保培训过程中某些适合的Gram矩阵的正定性。", "conclusion": "该分析揭示了优化过程的动力学并提供了通过随机算法训练的神经网络的保障。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "激活子空间在离群值检测中的应用", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "为了确保深度模型在实际应用中的可靠性，离群值检测方法旨在区分训练分布附近的样本（内分布，ID）与远离这些样本（离群分布，OOD）的样本。现有的方法通常直接使用模型激活值进行分析，但在大分布偏移（Far-OOD）时，这种方法的效果较差。本文旨在提出一种新的离群值检测方法来改进这一问题。", "innovation": "本文提出了一种名为ActSub的新颖离群值检测方法，该方法利用分类头权重矩阵的奇异值分解将模型激活分解为重要的和不重要的组成部分，分别最大化和最小化对最终分类器输出的贡献。研究发现，对于大分布偏移（Far-OOD），不重要的子空间在区分ID和OOD样本方面比原始激活更有效，因为分类目标很大程度上不受不重要子空间的影响，生成的特征不受目标分类任务的污染。在小分布偏移（Near-OOD）情况下，通过考虑仅重要的子空间，可以减少不重要成分在激活空间中的干扰。结合这两个发现，ActSub方法在多种标准离群值检测基准测试中达到了目前最佳的结果。", "conclusion": "通过ActSub方法的提出，该研究提供了一种有效的离群值检测方法，能够显著提高在大分布偏移情况下的检测性能，同时在小分布偏移情况下也保持了良好的性能，从而取得了当前最先进的离群值检测结果。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21570", "html_url": "https://arxiv.org/abs/2508.21570", "title": "OASIS: 使用稀疏漂流轨迹的扩散对抗网络进行海洋盐度插值", "title_en": "OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories", "authors": "Bo Li,Yingqi Feng,Ming Jin,Xin Zheng,Yufei Tang,Laurent Cherubin,Alan Wee-Chung Liew,Can Wang,Qinghua Lu,Jingwei Yao,Shirui Pan,Hong Zhang,Xingquan Zhu", "background": "海洋盐度在海洋循环、气候和海洋生态系统中起着关键作用，但其测量往往稀疏、不规则且噪声较大，尤其是在由漂流器收集的数据集中。传统的遥感和最优插值方法依赖于线性和稳定性，并受到云层覆盖、传感器漂移和低卫星重访率的限制。虽然机器学习模型具有灵活性，但在严重稀疏的情况下经常会失效，且缺乏不依赖专用传感器就引入物理协变量的原理方法。", "innovation": "本文提出了OASIS（OceAn Salinity Imputation System），一种全新的扩散对抗框架，旨在解决上述挑战。该框架专门设计来处理稀疏且不规则的漂流器轨迹数据，以更准确地进行海洋盐度插值，克服传统方法的局限性。", "conclusion": "OASIS 对抗扩散网络通过利用稀疏的漂流轨迹数据，能够更有效地进行海洋盐度插值。通过与其他方法相比，该模型展示了在减少数据稀疏性和提高盐度插值精度方面具有显著优势。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "基于物理的光谱建模在高光谱成像中的应用", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "现有高光谱成像技术中的分类和回归模型大多依赖监督学习，并且通常需要大量的标注数据才能取得较好的效果。此外，这些模型的内部表示往往是不透明的，难以解释。因此，一种能够无监督学习、减少标签需求并提供可解释内部表示的学习架构对于推动高光谱成像技术的发展具有重要意义。PhISM正是基于这一背景提出，旨在通过结合物理信息和深度学习的方法，革新高光谱观测的学习机制，提供更加鲁棒和透明的模型表示。", "innovation": "PhISM是一种结合了物理信息的深度学习架构，能够在无监督的情况下学习并明确地分离超光谱观察结果，并使用连续基函数进行建模。与之前的方法相比，PhISM在多个分类和回归基准测试中表现出更优的效果，同时只需要少量的标注数据，并能提供额外的见解，这得益于可解释的潜在表示。这一创新不仅提高了模型的性能，还增强了其透明度和可解释性，使得模型的应用更为广泛且可靠。", "conclusion": "PhISM通过引入物理信息和无监督学习机制，显著改进了高光谱观测的学习过程，减少了对大量标注数据的需求，并提供了透明且可解释的模型表示。PhISM在高光谱成像领域的分类和回归任务中展示了优异的性能，为该领域的研究和应用开辟了新的可能性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21772", "html_url": "https://arxiv.org/abs/2508.21772", "title": "UniMLR：建模多标签排序中的隐式类别重要性", "title_en": "UniMLR: Modeling Implicit Class Significance for Multi-Label Ranking", "authors": "V. Bugra Yesilkaynak,Emine Dari,Alican Mertan,Gozde Unal", "background": "现有的多标签排序（MLR）框架仅利用标签二元划分正负集得出的信息，但并未利用正标签间的排序信息。这限制了这些框架在多标签排序任务中的表现。", "innovation": "本文提出了一个新的MLR范式——UniMLR，该范式通过利用正标签间的排序信息，将隐式的类别相关/重要性建模为概率分布，而不是认为每个类别同等重要。UniMLR将排序和分类任务统一起来，并通过生成具有不同重要性决定因素的八个合成数据集（Ranked MNISTs），克服了MLR数据集中的稀缺性和注释偏差问题，为MLR任务提供了更为丰富和可控的实验环境。统计结果显示，UniMLR能够准确学习正标签排序的表示，该表示与真实的正标签顺序一致，并且与潜在的重要性值成比例.", "conclusion": "本文通过在现实世界和合成数据集上进行广泛的实证实验，证明了所提出的框架的价值，该框架能够有效利用正标签间的排序信息，显著提高多标签排序的性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21438", "html_url": "https://arxiv.org/abs/2508.21438", "title": "增强量子ensembles GANs在连续生物制造异常检测中的应用", "title_en": "Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing", "authors": "Rajiv Kailasanathan,William R. Clements,Mohammad Reza Boskabadi,Shawn M. Gibford,Emmanouil Papadakis,Christopher J. Savoie,Seyed Soheil Mansouri", "background": "连续生物制造过程需要稳健且早期的异常检测机制，即使微小的偏差也可能破坏产量和稳定性，导致生产和经济性能受损。这些过程本质上复杂且表现出非线性动态，使得必须采用高级异常检测方法以提高操作效率。", "innovation": "提出了一种新的基于生成对抗网络（GANs）集成框架的无监督异常检测方法，特别是在使用结合量子和经典计算的混合GAN方法进行异常检测时，取得了更好的异常检测效果。", "conclusion": "研究展示了混合量子/经典方法在解决复杂连续生物制造过程中的实际问题上的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21722", "html_url": "https://arxiv.org/abs/2508.21722", "title": "通过人群焦虑连续性预测推断重大事件的效果", "title_en": "Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety", "authors": "Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz", "background": "社区特定的心理健康效果对于公共卫生政策至关重要，仅仅预测心理健康分数不能提供事件对社区福祉的全面影响。纵向回归断点设计（LRDD）等准实验设计有助于从观察数据中推导出更可能具有因果效应的结果。LRDD旨在通过时间特定事件导致的结果变化（如焦虑评分的断点）来外推改变的大小。本文旨在使用统计学习框架改进LRDD的应用，通过分析某地的历史分数、动态协变量以及其他外生变量来预测未来的断点和斜率的变化。研究以预测美国各县从新冠疫情事件引发的焦虑变化为例，发现模型性能随着复杂性的提高有所提高，最佳结果来自于结合外生变量和动态协变量。与传统的静态社区表示相比，新方法在断点预测（r=+0.46）和斜率预测（r=+0.65）上表现显著提升。断点预测为估计潜在未来或假设事件对特定社区的特异性影响提供了新的可能。", "innovation": "本文将传统的纵向回归断点设计（LRDD）应用于统计学习框架，用以预测未来的断点（即时间特定的转变）和斜率（即趋势线）。这一方法通过结合位置的历史分数、动态协变量以及其他外生变量来提高预测的准确性。研究还强调了如何利用外部和动态因素来提升预测能力，使得传统的静态社区表示有所改进，提高了预测效果。这种方法为研究特定事件对社区的独特影响提供了一种新的工具。", "conclusion": "通过增加模型的复杂性，并结合外生和动态协变量的使用，可以显著提高预测未来时间特定事件效果的能力（如从新冠疫情预测焦虑水平）。这种方法不仅提高了预测的准确性，而且为估计未来潜在事件对特定社区的特异性影响提供了新的可能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "从异质数据中学习统一表示以实现稳健的心率建模", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化健康监测和健身至关重要，但在实际部署中经常面临数据异质性的关键挑战。数据异质性主要来自设备市场的碎片化和不同设备的功能集，以及个体在生理模式和活动上的差异。现有的方法要么丢弃设备特定的信息，要么无法建模用户特异性差异，限制了它们的实际性能。因此需要一个框架来学习既不依赖于设备异质性也不依赖于用户异质性的潜在表示，使得下游预测器可以在异质数据模式下一致地工作。通过引入随机特征脱落策略来应对源异质性，增强了模型对各种特征集的鲁棒性。为了处理用户异质性，采用时间感知注意力模块来捕捉长期生理特征，并使用对比学习目标来构建判别性表示空间。为了反映实际数据的异质性，创建并公开发布了新的基准数据集ParroTao。", "innovation": "提出了一个框架来学习既不依赖于设备异质性也不依赖于用户异质性的潜在表示，增强了模型对不同设备功能集和不同个体生理模式及活动差异的鲁棒性。引入随机特征脱落策略来应对源异质性，并通过时间感知注意力模块和对比学习目标处理用户异质性，从而提高模型在异质数据模式下的性能。公开了ParroTao基准数据集，展示了新模型在两个基准数据集上的显著性能提升，验证了所提模型的有效性。", "conclusion": "该研究通过创建一个新的公开基准数据集ParroTao，证明了新的模型显著优于现有的基线模型，提升了心率建模的精度和鲁棒性，展示了长期生理特征捕捉和判别性表示空间构建的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21815", "html_url": "https://arxiv.org/abs/2508.21815", "title": "在Rényi差分隐私下的希尔伯特-施密特独立性实现以实现公平性和隐私性数据生成", "title_en": "Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation", "authors": "Tobias Hyrup,Emmanouil Panagiotou,Arjun Roy,Arthur Zimek,Eirini Ntoutsi,Peter Schneider-Kamp", "background": "随着GDPR和HIPAA等隐私法律法规以及AI领域的责任框架（如AI法案）的普及应用，真实世界的数据在使用时面临的伦理和责任要求越来越高，这对数据共享和模型开发产生了制约。合成数据生成作为解决这一问题的潜在解决方案，特别适用于敏感领域（如医疗健康）的基础性表格数据。因此，如何保证生成的数据既保持隐私又确保公平性，成为当前的研究焦点。", "innovation": "本文提出了FLIP（Fair Latent Intervention under Privacy guarantees）模型，这是一种结合了潜在扩散机制的基于变换器的变分自编码器，能够生成异构的表格数据，并兼顾隐私和公平性。FLIP采用了多个策略来同时保护隐私和促进公平性：首先，通过在训练中应用Rényi差分隐私（RDP）约束来实现隐私保护；其次，通过RDP兼容的平衡采样方法和基于特征组的具体噪声水平进行公平性处理；最后，利用中心化核对齐（CKA）方法在潜在空间促进公平性，通过使神经元激活模式在受保护群体之间对齐来鼓励潜在表示与受保护特征之间的统计独立性。", "conclusion": "实验证明，FLIP能够显著提高任务无关的公平性表现，并适用于多种下游任务。该模型在差分隐私约束下实现了公平性和数据隐私性的双重目标。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21793", "html_url": "https://arxiv.org/abs/2508.21793", "title": "MoE-Health: 一个用于稳健多模态医疗服务预测的专家混合框架", "title_en": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction", "authors": "Xiaoyang Wang,Christopher C. Yang", "background": "医疗系统产生多种异构数据，包括电子健康记录（EHR）、临床笔记和医疗影像。有效利用这些数据进行临床预测具有挑战性，尤其是当现实世界样本包含不同的或不完整的模态时。现有方法通常需要完整模态数据或依赖于手动选择策略，这在数据在不同患者和机构之间变化的现实临床环境中限制了其应用性。因为现有的方法无法处理不同模态数据间的差异，因此在面对临床任务时表现受限。为解决这些问题，本文提出了一种新颖的专家混合框架——MoE-Health，该框架旨在处理具有不同模态的数据样本，并能提高关键临床任务的表现。", "innovation": "MoE-Health架构特别设计用于处理具有不同模态的数据样本，通过利用专门的专家网络和动态门控机制，我们的方法能够根据可用数据模态动态选择和结合相关专家，从而灵活适应不同的数据可用性场景。实验结果表明，MoE-Health在三个关键的临床预测任务中（ICU住院死亡率预测、住院时间过长和再次住院预测）表现优于现有的多模态融合方法，同时对不同模态数据分布具有鲁棒性。该框架在集成多模态信息方面表现出色，提供更好的预测性能和数据完整性和异质性处理的鲁棒性，特别适合在具有异质数据可用性的多样医疗服务环境中部署。", "conclusion": "该框架在MIMIC-IV数据集上验证了其技术优势，证明了其能够在多样化的医疗服务环境中利用异质数据实现稳健的多模态融合和高度准确的临床预测，提升了临床决策支持的技术可行性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob基准：基于MS$^2$蛋白质组学的片段离子概率预测", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质对细胞功能至关重要，是大多数药物靶点的基础，因此其分析对于理解健康和疾病中的人体生物学至关重要。质谱二阶（MS$^2$）技术通过离子化、碎片化并利用生成的质谱信息来识别肽以鉴定和量化生物样本中的蛋白质，对于蛋白质片段离子概率预测起到了关键作用，以增强肽识别的准确性。当前方法依赖于碎片化全局统计，假设所有肽的片段概率是均匀的。但由于从生物化学原理来看这种假设过于简化，限制了精确预测的能力。为解决这一问题，本文提出了Pep2Prob基准，这是一个用于肽特异性片段离子概率预测的首个综合数据集和基准。该数据集包含来自数千万高通量高分辨率HCD MS$^2$光谱的肽特异性碎片离子概率统计，这些光谱经过验证，包含肽序列和电荷状态的精确信息。研究使用简单的统计规则和基于学习的方法建立了基准性能，并发现利用肽特异性信息的模型显著优于仅使用全局碎片化统计的方法。随着基准模型容量的增加，性能表现进一步证实肽-碎片关系存在复杂的非线性关系，需要更复杂的机器学习方法来进行预测。", "innovation": "本文提出了第一个针对肽特异性片段离子概率预测的数据集和基准模型Pep2Prob。利用超过18300万高通量高分辨率HCD MS$^2$光谱和验证过的肽序列及碎片化注释，构建了一个包含608780个独特前体的综合性数据集。研究发现，利用肽特异性信息的模型明显优于仅基于全局碎片化统计的方法。并强调了肽-碎片关系的复杂非线性，指出需要更复杂的机器学习方法来解决此问题。", "conclusion": "通过Pep2Prob基准的研究，我们澄清了肽特异性片段离子概率预测的重要性，并通过展示利用肽特异性信息的模型显著优于从前仅有的全局碎片统计方法，提出了更复杂的机器学习方法来解决肽-碎片关系中的复杂非线性问题。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "MPSoC板上神经网络加速：集成SLAC的SNL、Rogue Software和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "LCLS-II自由电子激光器将产生每秒高达1兆赫兹的X射线脉冲，用于实验线实验，探测器的数据吞吐量超过每秒1TB。这种巨大的数据流管理带来了显著的挑战，因为传输和存储基础设施变得非常昂贵。机器学习（ML）为实时数据缩减提供了有前景的解决方案，但传统的实现方式会引入过高的延迟，使其不适合高速实验环境。SLAC开发了SLAC神经网络库（SNL），这是一种专门设计用于在现场可编程门阵列（FPGA）上部署实时ML推理模型的框架，其关键特性是能够动态更新模型权重而不需重新合成FPGA，以增强适应性学习应用的灵活性。为了进一步提高使用和便捷性，引入了Auto-SNL，这是一种Python扩展工具，简化了将基于Python的神经网络模型转换为SNL兼容的高层次综合代码的过程。论文对比了SNL与当前最先进的工具hls4ml，涵盖了多种神经网络架构、固定精度和综合配置，针对Xilinx ZCU102 FPGA。结果显示，SNL在大多数测试架构中实现了有竞争力的或更好的延迟，在某些情况下还提出了FPGA资源节省。这表明SNL的通用性，为高能物理、医学成像、机器人等领域的研究人员和学者开辟了新的机会。", "innovation": "开发了专门设计用于在FPGA上部署实时ML推理模型的专门框架SLAC神经网络库（SNL），该框架的关键特性是能够动态更新模型权重而不需重新合成FPGA，增强了适应性学习应用的灵活性。此外，还引入了Auto-SNL，这是一种Python扩展工具，简化了将基于Python的神经网络模型转换为SNL兼容的高层次综合代码的过程。", "conclusion": "研究对比了SNL与当前最先进的工具hls4ml，涵盖了多种神经网络架构、固定精度和综合配置，针对Xilinx ZCU102 FPGA。结果显示，SNL在大多数测试架构中实现了有竞争力的或更好的延迟，在某些情况下还减少了FPGA资源使用。这表明SNL具有通用性，为高能物理、医学成像、机器人等领域的研究人员和学者提供了新的机会。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21082", "html_url": "https://arxiv.org/abs/2508.21082", "title": "ImmunoAI：使用热力学-流体力学描符和3D几何界面拓扑结构的增强梯度机器学习加速抗体发现", "title_en": "ImmunoAI: Accelerated Antibody Discovery Using Gradient-Boosted Machine Learning with Thermodynamic-Hydrodynamic Descriptors and 3D Geometric Interface Topology", "authors": "Shawnak Shivakumar,Matthew Sandora", "background": "人副流感病毒（hMPV）对儿童、老年人和免疫抑制人群构成严重风险。传统的抗体发现流程需要10-12个月，限制了其对快速疫情应对的适用性。为了加速这一过程，本项目提出了ImmunoAI框架，通过梯度提升模型预测具有高亲和力的候选抗体，从而加速抗体发现。", "innovation": "ImmunoAI使用梯度提升模型训练热力学、流体力学和三维拓扑学描述符来预测抗体与抗原的结合亲和力。通过构建包含213个抗体制剂复合体的数据集并提取几何和物理化学特征，训练了一个LightGBM回归器来高精度地预测结合亲和力。模型将候选抗体搜索空间减少了89%，进一步优化后，对于SARS-CoV-2结合对的预测精度从1.70提高到了0.92。对于hMPV A2.2变种，利用AlphaFold2预测了其3D结构，并通过优化的模型识别了两个针对关键突变位点（G42V和E96K）具有预测皮摩尔亲和力的最佳抗体，为实验测试提供了有力的候选抗体。", "conclusion": "ImmunoAI缩短了设计周期，并能够更快地、结构指导下的应对病毒性疫情。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21086", "html_url": "https://arxiv.org/abs/2508.21086", "title": "受量子启发的概率度量定义了一个完整的、通用的统计学习空间", "title_en": "Quantum-inspired probability metrics define a complete, universal space for statistical learning", "authors": "Logan S. McCarty", "background": "在自然科学、社会科学和计算科学等领域，比较概率分布是一个核心挑战。现有的方法，如最大均值差异（MMD），在高维和非紧致空间中存在困难。现有的概率度量方法，如MMD，在处理这些问题时表现出局限性，尤其是在高维度和非紧致空间中。", "innovation": "本文引入了量子概率度量（QPMs），通过将概率测度嵌入到量子态空间中，即定义在希尔伯特空间上的正、单位迹算子中。这种方法扩展了基于核的方法，并克服了MMD在非紧致空间中的不完整性。QPMs作为概率质量函数的积分概率度量（IPM），均匀地逼近所有有界、一致连续函数，提高高维度下的细微概率分布差异的敏感度。对于经验分布，QPMs可以使用特征值方法方便地计算，并且具有可用于学习和优化的解析梯度。虽然在大样本量时计算更加密集（计算复杂度为$O(n^3)$对比$O(n^2)$），但QPMs能够显著改善MMD的性能，如在经典的生成建模任务中所示。通过将量子力学丰富的数学框架与古典概率结合，本文为分析和操作概率测度奠定了基础，开发出一系列强大工具。", "conclusion": "本文通过结合量子力学和经典概率，提出了一种新的概率度量方法QPMs，这些方法克服了经典方法的局限性，在高维和非紧致空间中具有更优的泛化能力和计算敏感性。通过实验证明，QPMs能够显著改善概率分布比较的效果，为统计学习提供了新的途径。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21167", "html_url": "https://arxiv.org/abs/2508.21167", "title": "RARR : 通过在线采集近表面音频实现稳健的现实世界活动识别", "title_en": "RARR : Robust Real-World Activity Recognition with Vibration by Scavenging Near-Surface Audio Online", "authors": "Dong Yoon Lee,Alyssa Weakley,Hui Wei,Blake Brown,Keyana Carrion,Shijia Pan", "background": "四分之一的痴呆患者独自生活，导致家属需要远程承担护理任务。尽管已有许多研究开发了远程监测解决方案以减少护理负担，但仍然存在隐私保护、行为识别及模型泛化等问题。结构振动传感器系统是一种不干扰的解决方案，在实验室环境中已被证明能够准确监测人类信息，如身份识别和行为识别。然而，当在实际用户家中部署时，现有的解决方案需要大量的标签数据才能实现准确的行为识别，这在实际应用中是一个难题。", "innovation": "本文提出了一种可扩展的解决方案，通过利用近表面音频数据的合成来预训练模型，并通过少量数据进行微调，从而创建一个针对日常生活活动跟踪的稳健框架。这种方法避免了在实际应用中需要大量标签数据的需求，具有较高的实用性。", "conclusion": "该研究提出了一种新颖的方法，通过在线采集近表面音频数据，利用合成数据预先训练模型，并通过少量数据进行微调，从而创建了一个针对日常生活活动跟踪的稳健框架。这种方法为在家属需要远程承担护理任务的痴呆患者提供了更有效的解决方案，同时也解决了现有技术中的数据需求问题。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21179", "html_url": "https://arxiv.org/abs/2508.21179", "title": "合成简历以构建和测试公平招聘工具", "title_en": "Synthetic CVs To Build and Test Fairness-Aware Hiring Tools", "authors": "Jorge Saldivar,Anna Gatzioura,Carlos Castillo", "background": "随着算法招聘变得越来越必要，尤其是在需要处理成百上千申请人的行业中，算法设计用于提取和排名求职者简历成为这些系统的核心。然而，现有研究表明，这些技术可能会无意中引入偏差，导致基于年龄、性别或国籍等因素的歧视。为了测量、缓解和解释算法招聘中的偏差，评估和比较公平性技术在部署前的效果，需要反映多样性背景人群特征的数据集。但用于此类研究的数据集还不存在。", "innovation": "本研究提出了一种方法来构建合成的简历数据集，这些数据集的特征基于通过数据捐赠活动收集的真实材料。此外，研究还呈现了一个包含1,730份简历的数据集，我们预计可以作为算法招聘歧视研究的基准标准。", "conclusion": "本研究通过开发合成简历数据集，填补了现有研究数据集的空白，为研究算法招聘中的歧视提供了新的工具和标准，有助于更好地评估和缓解算法招聘中的不公平现象。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过二元退火和强化学习激励大规模语言模型的通用自思考能力", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大型语言模型（MLLMs）在复杂推理问题上表现出了杰出的能力，但这种思考过程对于无需复杂推理即可解决的简单问题来说是冗余的。鉴于此，为了提高效率，该研究提出了具有自动思考能力的R-4B模型，该模型能够根据问题的复杂性自动决定何时进行思考。", "innovation": "R-4B的核心创新在于通过二元退火和Bi-mode Policy Optimization (BPO)技术，给予模型同时具备思考和非思考能力，并在训练过程中强制模型生成两种模式的响应，从而提高了模型决策是否激活思考过程的准确性。实验结果显示，R-4B在25个挑战性基准测试中达到了最先进的性能，大多数任务上超过了Qwen2.5-VL-7B，并且在计算成本较低的情况下，达到了类似于更大规模模型如Kimi-VL-A3B-Thinking-2506 (16B)的表现，在侧重推理的基准测试中表现尤为突出。", "conclusion": "R-4B模型通过对大规模语言模型的二元退火和强化学习进行改进，实现了一种自动思考的能力，使得模型能够根据问题复杂性灵活运用思考过程，从而提高了模型的效率和准确性，在多个基准测试中表现优异，特别是在推理任务上表现突出，达到了较低的计算成本。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "使用全景X光影像高级深度学习技术分类牙科病症", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本文研究了深度学习方法在自动分类全景X光牙科条件中的应用。研究使用了一个包含1,512份牙科X光片和11,137个由专家验证的注释的数据集，涵盖四种牙科状况：填充物、龋齿、种植体和阻生牙。预处理后，评估了三种方法，包括自定义卷积神经网络（CNN），结合CNN特征提取的传统分类器的混合模型，以及基于预训练架构的微调模型。实验使用了5折交叉验证，并以准确性、精密度、召回率和F1分数作为评估指标。混合CNN随机森林模型表现最佳，准确率为85.4%，优于自定义CNN基线的74.3%。在预训练模型中，VGG16表现出最佳效果，准确率为82.3%，其次为Xception和ResNet50。研究表明，结合基于CNN的特征提取与集成分类器可以提供可靠的自动牙科诊断支持，但需要更大的数据集和进一步的临床验证。", "innovation": "本文创新点在于结合卷积神经网络特征提取与传统分类器的混合模型，并评估了基于预训练架构的微调模型，其中混合CNN随机森林模型取得了最佳性能，同时强调了更大的数据集和临床验证的重要性。", "conclusion": "研究表明，结合基于CNN的特征提取与集成分类器可以提供高效的自动牙科诊断支持。然而，还需要进一步扩大数据集并进行更多的临床验证。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21810", "html_url": "https://arxiv.org/abs/2508.21810", "title": "QR-LoRA: 基于 QR 分解的低秩适应技术以提高大型语言模型高效微调", "title_en": "QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models", "authors": "Jessica Liang,Anirudh Bharadwaj", "background": "随着大型语言模型（LLMs）规模的不断扩大，这促使我们发展出参数高效微调方法。低秩适应（LoRA）作为一种有前景的方法应运而生，通过在预训练权重上应用低秩更新来减少可训练参数的数量。现有 LoRA 方法通过直接学习更新因子来工作，但几种变体首先通过对预训练权重进行奇异值分解（SVD）初始化这些矩阵，这在大模型上可能成本高昂且得到的奇异向量不易解释。", "innovation": "本文提出了一种新的微调技术 QR-LoRA，在预训练权重矩阵中使用带有列重排的 QR 分解提取正交基，并将 LoRA 更新表示为这些基向量的线性组合。该方法仅训练标量系数，这为适应过程带来了清晰的结构，成倍减少了参数数量。在 GLUE 任务上，实验表明 QR-LoRA 在与全微调、标准 LoRA 和 SVD-LoRA 相比参数计数仅为 601 时，匹配或超越了其性能， 参数量大约是全微调的六分之一，比传统 LoRA 设置减少约 77 倍。", "conclusion": "本文提出了一种基于 QR 分解的低秩适应技术 QR-LoRA，在大型语言模型高效微调方面表现出色，实现了与全微调相近的性能，同时将参数量大大减少。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21165", "html_url": "https://arxiv.org/abs/2508.21165", "title": "基于数据驱动的基于物理的血管血流动力学降阶模型分支处理", "title_en": "Data-Driven Bifurcation Handling in Physics-Based Reduced-Order Vascular Hemodynamic Models", "authors": "Natalia L. Rubio,Eric F. Darve,Alison L. Marsden", "background": "三维有限元仿真心血管流动能够提供高保真的预测，用于支持心血管医学，但由于计算成本高昂而限制了临床应用。降阶模型（ROMs）提供了计算效率更高的替代方案，但精确度较低，特别是在血管分叉处，复杂流体力学无法用标准的泊肃叶流假设准确捕捉。", "innovation": "提出了一种增强的数值框架，将机器学习预测的分叉系数集成到零维（0D）血流动力学ROMs中，以提高准确度同时保持计算效率。开发了电阻-电阻-电感（RRI）模型，使用神经网络预测分叉几何的压流关系，结合线性与二次电阻以及感应效应。该方法采用非量纲化减少训练数据需求，并使用先验流分流预测以改善分叉表征。采用基于优化的方法将RRI模型整合到0D模型中。该方法在孤立的分叉和血管树中得到验证，适用于0到5500的雷诺数范围，定义ROM准确度通过与三维有限元仿真对比。结果表明，RRI方法在整个树和雷诺数范围内显著提高了准确性：平均情况下，减少了进口气压误差，从标准0D模型的54 mmHg（45%）降至25 mmHg（17%），简化版电阻-电感（RI）达到31 mmHg（26%）误差。增强的0D模型在高雷诺数和广泛的血管网络中特别有效。这种混合数值方法使临床决策支持的实时血流动力学建模、不确定量化及心血管生物医学工程中的数字双胞胎成为可能。", "conclusion": "该混合数值方法实现了准确的实时血流动力学建模，用于临床决策支持、不确定量化及心血管生物医学工程中的数字双胞胎。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "胸部X光片中肺部疾病严重程度分类的深度主动学习：类不平衡情况下用更少的数据学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "研究背景：为了减少用于基于胸部X光片（CXR）识别肺部疾病严重程度所需的标记数据量，并在类不平衡的情况下有效处理，本文应用了深度主动学习结合贝叶斯神经网络（BNN）近似和加权损失函数的方法。研究回顾了从2020年1月至11月在Emory Healthcare附属医院接受临床确诊的COVID-19患者的2,319张胸部X光片（涉及963名患者，平均年龄59.2岁±16.6岁，其中481名为女性）。所有患者均被独立地由3至6名认证放射科医生标记为正常、中度或严重。", "innovation": "研究创新点：该研究提出了一种结合深度主动学习、贝叶斯神经网络近似和加权损失函数的方法来减少标记数据需求，并在类不平衡的情况下改善肺部疾病严重程度分类的性能。实验使用了多种采样策略，如熵采样和均值标准差采样，展示了在减少标记数据需求的同时保持甚至提高诊断性能的方法。", "conclusion": "研究结论：在二分类任务中，使用15.4%的数据训练，熵采样方法达到了93.7%的准确率（AUC-ROC 0.91）。在多分类任务中，均值标准差采样方法使用23.1%的标签数据达到了70.3%的准确率（AUC-ROC 0.86）。这些方法在复杂和计算成本高的采样策略中表现更优，并显著减少了对标记数据的需求。基于贝叶斯神经网络近似和加权损失函数的深度主动学习有效减少了标注数据的需求，同时解决了类不平衡问题，维持或超过了诊断性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21255", "html_url": "https://arxiv.org/abs/2508.21255", "title": "随机测度的加权支撑点：生成建模的一种可解释替代方案", "title_en": "Weighted Support Points from Random Measures: An Interpretable Alternative for Generative Modeling", "authors": "Peiqi Zhao,Carlos E. Rodríguez,Ramsés H. Mena,Stephen G. Walker", "background": "支持点通过一个较小的代表性子集来概括大规模数据集，并且这些子集能在不访问完整数据集的情况下用于数据操作，如蒙特卡洛积分。支持点提供了原数据的紧凑但信息丰富的表示。本文基于此概念，提出了一种基于随机加权支持点的生成建模框架，加权方案灵感来源于狄利克雷过程和贝叶斯再抽样。", "innovation": "该方法通过固定的数据集生成多样性和可解释性兼备的样本集，而不需要依赖概率模型假设或神经网络架构。研究者提出了基于凸凹程序（CCP）的有效优化算法，实验结果表明，在计算成本上相比黑盒替代方案（如生成对抗网络GANs或去噪扩散概率模型DDPMs），本文的方法能产生高质量且多样化的输出。", "conclusion": "实验结果表明随机加权支持点提供了一种原理明确、可扩展且可解释的生成建模替代方案。其关键优势在于能够产生真正的插值样本，这些样本能够保留数据的内在结构。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21236", "html_url": "https://arxiv.org/abs/2508.21236", "title": "大规模人群网络嵌入揭示了与右翼民粹主义投票相关的教育差异的网络结构", "title_en": "Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting", "authors": "Malte Lüken(1 and 2 and 3),Javier Garcia-Bernardo(4),Sreeparna Deb(5),Flavio Hafner(1 and 3),Megha Khosla(5) ((1) Netherlands eScience Center, (2) University of Amsterdam, (3) Erasmus University Rotterdam, (4) Utrecht University, (5) Delft University of Technology)", "background": "行政登记数据可以构建反映个人间共享社会背景的人口级网络。通过机器学习，这些网络可以被编码为数值表示嵌入，自动捕获个体在网络中的位置。研究者利用这些嵌入来预测右翼民粹主义投票。研究结果表明，嵌入可以高于随机水平预测右翼民粹主义投票，但表现不如个人特征。结合部分嵌入与个人特征微弱提高预测，但通过对嵌入进行转换，使它们的维度更加稀疏正交后，发现了一个嵌入维度与结果强烈关联。将该维度映射回人口网络，揭示了不同学校联系和受教育程度的网络结构差异与右翼民粹主义投票之间的关系。", "innovation": "该研究通过将人口级网络嵌入转换为更稀疏正交的维度，使嵌入可解释性增强，并揭示了结构网络差异在教育与右翼民粹主义投票之间的关联，这是方法上的创新。", "conclusion": "研究展示了如何通过人口级网络嵌入使网络结构变得可解释，并实证地将教育结构差异与右翼民粹主义投票联系起来，展示了网络嵌入在解释宏观社会现象方面的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21205", "html_url": "https://arxiv.org/abs/2508.21205", "title": "基于模型预测最优运输（MPC-OT）的多机器人路径规划与调度", "title_en": "Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)", "authors": "Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham", "background": "多机器人在共用环境中执行导航任务时，将机器人映射到目标后再进行路径规划可能会导致路径重叠，从而产生死锁。现有方法通常只考虑最低成本路径规划，但未能确保路径不重叠。", "innovation": "提出了基于最优运输理论和模型预测控制的新方法，用于多机器人路径规划与调度。该方法通过离散化兴趣空间并设定K×K成本结构来实现路径规划，并通过最优运输提供最优且不重叠的路径选择，从而减少了路径重叠和产生死锁问题的风险。此外，通过模型预测控制与重新规划（replans）结合，该方法能够适应路径重叠和机器人动力学。", "conclusion": "所提出的方法在最坏情况下的计算复杂度为O(K^3logK)，对于行为良好问题则为O(K^2logK)。通过结合最优运输与模型预测控制，该方法能够在多机器人系统中有效规划路径并合理调度，以避免路径冲突和优化路径规划成本。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21372", "html_url": "https://arxiv.org/abs/2508.21372", "title": "基于矩阵分解的流从结构算法加速推理", "title_en": "Faster Inference of Cell Complexes from Flows via Matrix Factorization", "authors": "Til Spreuer,Josef Hoppe,Michael T. Schaub", "background": "我们考虑了如下推断问题：给定图上观察到的一组边流信号，将图提升到细胞复杂度，使得观察到的边流信号可以用细胞复杂度上梯度和旋流的稀疏组合表示。之前的工作已经表明这个问题一般是NP难问题，因此在此篇论文中，我们开发了一个新的基于矩阵分解的启发式算法来解决这个问题。", "innovation": "我们开发了一个基于矩阵分解的新启发式算法，用于解决提升图的问题，使得观察到的边流信号可以用梯度和旋流的稀疏组合表示。计算实验表明，新方法在大多数情况下计算成本更低，性能相差不大。更重要的是，在特定噪声环境中，新方法在解决方案质量和计算速度上超过了以前的最优方法。", "conclusion": "我们的新方法证明了相比于之前的方法，能在保持性能接近的同时显著降低计算成本，特别是在噪声较高的情况下，新方法的表现更优。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT和DeepSeek系列模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在改变各行各业的AI，但它们的研发和部署仍具有复杂性。本文综述了构建和使用LLMs的关键挑战，并通过对比闭源模型OpenAI的GPT-4o和开源模型DeepSeek-V3-0324来探讨这些挑战的解决方法。", "innovation": "本文通过对比闭源模型（如GPT-4o）和开源模型（如DeepSeek-V3-0324），展示了它们之间的权衡（闭源模型的安全性和精细校准可靠性，与开源模型的效率和适应性）。此外，文章还探索了LLMs在不同领域的应用，指出了哪些模型特性最适合每个应用场景。", "conclusion": "本文旨在指导AI研究人员、开发者和决策者理解当前LLMs的功能、局限性和最佳实践。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "层间SSL特征能否提高儿童语言零样本ASR性能？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "自动语音识别（ASR）系统往往难以准确处理儿童的语音，因为儿童语音具有独特的且高度变化的声学和语言特征。虽然最近自监督学习（SSL）模型的进展极大地提升了成人口语转录的准确性，但准确转录儿童语音仍是一个显著的挑战。这项研究探讨了从最先进的SSL预训练模型（例如Wav2Vec2、HuBERT、Data2Vec和WavLM）中提取的层间特征，以提高在零样本情况下儿童语音ASR的表现。研究使用WSJCAM0成人口语进行训练，使用PFSTAR儿童语音进行测试，将从这些模型提取的特征整合到简化的人工神经网络（DNN）为基础的ASR系统中。实验结果表明，Wav2Vec2模型第22层在零样本条件下实现了最低的词错误率（WER）5.15%，相对于直接使用Wav2Vec2零样本解码的WER10.65%提高了51.64%。年龄组分析显示，随年龄增长，性能改善保持一致，即使在较小的年龄组中使用SSL特征也观察到显著的提升。进一步在CMU Kids数据集上进行的实验证实了类似的趋势，突显了所提方法的普遍适用性。", "innovation": "研究利用从最新的自监督学习模型中提取的分级特征，探索其在儿童语音零样本ASR中的应用。该研究发现，Wav2Vec2模型的第22层特征相较于直接使用模型零样本解码实现了显著的性能提升。此外，年龄组分析表明，随着年龄的增长，性能提升保持一致，即使在较小年龄的儿童语音中，性能也有显著改善。", "conclusion": "研究表明，利用自监督学习模型（Wav2Vec2、HuBERT、Data2Vec和WavLM）的层间特征可以有效提升儿童语音在零样本情况下的ASR性能。实验结果展示了这一方法的实用性和有效性，尤其是在较小年龄的儿童语音中也观察到了显著的性能提升。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "使用双向传播进行多本体集成的医学概念表示", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "医学本体图通过结构化关系将外部知识映射到电子健康记录的医学代码中。现有文献主要侧重于从单一本体系统或其他隔离的本体系统（如疾病、药物和程序）中融入领域知识，而未能将它们整合到一个统一的学习结构中。因此，概念表示学习主要局限于同质本体内的关系，忽视了跨本体的连接。", "innovation": "本文提出了一种名为LINKO的大型语言模型增强型综合本体学习框架，该框架通过同时利用多个本体图，在异构本体系统内部和之间实现双向知识传播，从而增强医学概念的表示学习。该方法首先利用大型语言模型对本体概念嵌入进行了图检索增强初始化，通过工程化提示包括概念描述并进一步结合本体上下文。其次，该方法在两个维度上联合学习来自多种本体图医学概念，通过垂直传播实现本体层次间的传播，同时在每个水平上平行进行横向传播。最后，通过在两个公共数据集上的广泛实验验证了LINKO在基准之上展现出优越性能。LINKO作为一个插件编码器，适用于现有的EHR预测模型，并在数据不足和罕见疾病预测等场景下展现了增强的稳健性。", "conclusion": "通过在两个公共数据集上的广泛实验，我们验证了LINKO相较于最先进的基准模型表现出更好的性能。此外，LINKO作为现有的EHR预测模型的插件编码器，在数据稀缺和罕见疾病预测等场景中也表现出增强的稳健性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "量子增强自然语言生成：结合量子-经典架构的多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "随着量子计算在自然语言处理（NLP）应用中的关注度不断提高，本研究对比了量子文本生成模型与传统的Transformer和MLP架构，通过系统实验评估了五种不同的模型：基础的Transformer、量子核自我注意网络（QKSAN）、量子RWKV（QRWKV）和量子注意力序列架构（QASA），这些模型在五个不同的数据集上进行了测试。这些数据集包含了简单的句子、短故事、量子短语、俳句以及谚语。使用了多种评估指标，包括困惑度、BLEU评分、词汇多样性、重复率和流畅度，来衡量不同文本生成质量方面的能力。", "innovation": "本研究的主要创新在于引入了量子增强的自然语言生成框架，并使用了结合量子-经典架构的多种模型。与传统的Transformer模型相比，量子模型在特定情况下表现出了竞争力，比如QKSAN在BLEU-1评分方面达到了0.2800，且无重复率；QRWKV在某些任务中达到了完美的词汇多样性（Distinct-1 = 1.000）", "conclusion": "虽然传统的Transformer模型在总体上仍保持优势，具有最低的平均困惑度（1.21）和最高的BLEU-1评分（0.2895），但量子启发模型在特定场景中展示了竞争力。研究结果表明，量子增强架构具有潜在的应用价值，尤其在减少重复率和提高词汇多样性方面表现出色。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO：遥感领域自监督预训练深度探究", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习已成为遥感领域的重要工具，尤其是当有大量的未标记数据可用时。在遥感图像领域，研究旨在探索DINO（一种对比式的自监督方法）的使用情况，用于预训练。作者引入了专门针对遥感卫星图像表示学习的SatDINO模型。通过在多个数据集上进行多种测试设置的广泛实验，展示了SatDINO在多种基准上都取得了优秀结果，优于基于常见遮蔽自编码器（MAE）的其他最先进的方法。", "innovation": "SatDINO是一种专为遥感卫星图像设计的自监督学习模型。它通过几种创新的改进来增强其能力，包括引入了新的GSD编码方法以及自适应视图采样技术。作者还提供了一项严格的心脏切片研究，用于评估SatDINO的各个组成部分。这些改进可以使用户独立应用于SatDINO模型。", "conclusion": "通过广泛的实验和评估，SatDINO模型在多项基准上取得了优异的成绩，特别是与基于MAE的方法相比。此外，作者还提出了几种新技术，提升了模型的性能。提供的代码和预训练模型可以在指定的URL中访问。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 一个马拉地语句子相似性数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "本文介绍了马拉地语句子文本相似度（STS）数据集MahaSTS及优化的MahaSBERT-STS-v2模型。MahaSTS包含16,860对马拉地语句子，每对句子被标注了0到5分之间的连续相似性评分。为了保证监督的一致性，数据集在0到5分的全范围内均匀分布，覆盖了六个评分桶，这有助于减少标签偏差，增强模型稳定性。", "innovation": "MahaSTS和MahaSBERT-STS-v2模型，后者是针对回归相似度评分优化的Sentence-BERT模型。实验表明，MahaSTS在马拉地语句子相似度任务上表现出有效性，突出了人类标注，针对性微调和结构化监督在资源有限环境中的影响。", "conclusion": "本文公开了MahaSTS数据集和MahaSBERT-STS-v2模型，结果证明MahaSTS能够有效培训马拉地语句子相似度任务，强调了人类标注、针对性微调和结构化监督的重要性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21531", "html_url": "https://arxiv.org/abs/2508.21531", "title": "自适应生成矩匹配网络以改进相关结构学习", "title_en": "Adaptive generative moment matching networks for improved learning of dependence structures", "authors": "Marius Hofert,Gan Yao", "background": "本文介绍了一种用于最大均差（MMD）中混合核带宽选取的自适应选择程序，该程序用于调整生成矩匹配网络（GMMNs），以提高Copula随机数生成的学习效果。研究基于训练损失的相对误差增加了核的数量，并以验证损失的相对误差作为提前停止的条件。尽管自适应训练的GMMNs（AGMMNs）的训练时间与GMMNs相似，但其训练性能显著提高。", "innovation": "提出了AGMMNs的新方法，通过自适应调整带宽来提高Copula模型的学习效果。具体而言，使用训练损失和验证损失的相对误差来调整核的数量和作为停止条件，进而改善训练性能。", "conclusion": "研究通过三个应用展示了AGMMNs相对于GMMNs和典型参数Copula模型的优势。首先，在高维Copula中首次研究了准随机抽样和伪随机抽样的收敛速度。其次，通过Basked call期权的预期收益和预期短缩等函数的应用，验证了AGMMNs相较于GMMNs的改进。最后，研究还显示了AGMMNs的改进是因为相较于参数Copula模型更为准确。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21615", "html_url": "https://arxiv.org/abs/2508.21615", "title": "适应变化：概念漂移下建筑热动态建模中的持续学习与转移学习比较", "title_en": "Adapting to Change: A Comparison of Continual and Transfer Learning for Modeling Building Thermal Dynamics under Concept Drifts", "authors": "Fabian Raisch,Max Langtry,Felix Koch,Ruchi Choudhary,Christoph Goebel,Benjamin Tischler", "background": "当前，当仅有有限数据时，迁移学习（TL）是最有效的建立建筑物热动力学模型的方法。然而，一旦收集更多实际测量数据，特别是在建筑动力学发生变化（如进行改造或改变居住情况）时，如何继续优化模型变得不那么确定了。现有的持续学习（CL）方法可以更新变化系统的模型，迁移学习方法也可以重新利用预训练模型进行优化。但是，尚未对如何随时间整合新测量数据以提高预测准确性和解决热动力学概念漂移挑战进行全面研究。", "innovation": "提出了一种名为季节记忆学习（Seasonal Memory Learning, SML）的新策略，该策略在没有和有概念漂移的情况下比现有CL和TL方法均有更好的性能表现，同时计算成本较低。具体而言，SML在没有概念漂移时的增长率比初始微调基准高28.1%，有概念漂移时提高了34.9%。", "conclusion": "通过对持续学习和迁移学习方法以及从头开始训练的模型进行比较，研究验证了在建筑运行期间热动力学建模中，SML策略的有效性和优势。这些方法使用了5-7年的模拟数据，代表了中欧单户住宅，并包含了从改造和居住变化引起的概念漂移场景。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21524", "html_url": "https://arxiv.org/abs/2508.21524", "title": "Compute-in-Memory CNN加速器中的二值权重多比特激活量化", "title_en": "Binary Weight Multi-Bit Activation Quantization for Compute-in-Memory CNN Accelerators", "authors": "Wenyong Zhou,Zhengwu Liu,Yuan Ren,Ngai Wong", "background": "_compute-in-memory(CIM)加速器被认为是一种提高卷积神经网络(CNN)能效的有前途的方法。在CIM平台上部署CNN通常需要对网络权重和激活进行量化，以符合硬件限制。现有方法或在硬件效率和二值权重及激活量化降低精度之间权衡，或使用多比特权重和激活提高准确性但代价是效率低下。", "innovation": "提出了CIM加速器上CNN的一种新颖的二值权重多比特激活(BWMA)方法，通过推导每一层权重量化闭式解显著提高了二值化权重的表示能力；开发了一个可微量化函数，能够近似理想多比特函数并避免了广泛搜索最优设置。实验表明，BWMA在CIFAR-10和ImageNet数据集上显著优于现有方法，并使准确率提高了1.44%-5.46%和0.35%-5.37%，且4比特激活量化在硬件成本和模型性能之间达到了最优平衡。", "conclusion": "BWMA方法在CIM加速器上运行的CNN模型中取得了显著的准确率提升，同时在硬件和性能之间找到了最佳平衡点。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: Hierarchical Selection for Fake News Detection Building Heterogeneous Ensemble", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏差，如确认偏差，使个体特别容易相信和传播社交媒体上的假新闻，这对公共卫生和政治等领域产生了重大影响。基于机器学习的事实检查系统被广泛研究以减轻这一问题。其中，集成方法尤其有效，可以通过结合多个分类器来提高鲁棒性。然而，其性能强烈依赖于构成分类器的多样性。这在分类器倾向于学习冗余模式时尤为关键，选择真正多样的模型仍然是一个主要挑战。", "innovation": "本文提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性及性能。首先计算分类器之间的成对多样性，并应用层次聚类来按不同粒度层级组织它们。然后，HierarchySelect探索这些层次来选择每个层级的一个分类器池，每个池代表一种独特的内在多样性。最多样化的池被识别并从这些池中用于集成构建。选择过程整合了评价每个分类器性能的度量，以确保集成也很好地泛化。实验使用来自不同应用领域的六个数据集上的40种异构分类器，并比较了基于肘部启发式算法和现有的最佳基准的方法。结果显示，该方法在六个数据集中的两个数据集上达到了最高的准确性。", "conclusion": "实验结果显示，该方法在六个数据集中的两个数据集上达到了最高的准确性。项目实现细节可在项目存储库中找到: this https URL."}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "大规模全切片图像档案中增强的人工智能集成和搜索的标准化多层组织图", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "全切片图像（WSI）是通过扫描包含生物样本的整个玻璃片，如组织切片或细胞样本，以多个放大倍数生成的高分辨率数字图像。这些图像被广泛应用于人工智能算法开发，尤其是在病理学用于疾病诊断和肿瘤学用于癌症研究。WSIs也被应用于神经学、兽医学、血液学、微生物学、皮肤学、药理学、毒理学、免疫学和法医学等多个领域。在构建用于训练或验证AI算法的组合时，了解WSI中的内容至关重要。但是，目前缺乏有关WSI的元数据标准，因此选择这些内容通常是通过手动检查完成的，这对于大型集合（包括数百万个对象）并不合适。", "innovation": "本文提出了一种通用框架，用于为WSI生成2D索引图，并针对特定应用领域建立了特征表征机制。我们展示了在临床病理学领域的应用，使用共同的语法和语义实现了不同目录之间的互操作性。该方法为每个WSI集合添加了一个详细的组织图，提供了WSI内容的详细信息，并将其组织成三个层次：来源、组织类型和病理改变，每个层次都将WSI的特定区域分配给特定类别。这种方法通过具体示例，在WSI目录、机器学习和基于图的WSI表示方面展示了标准的优势和适用性。", "conclusion": "本文提出了一种标准化方法，用于创建标志性的多层组织图，以增强大规模WSI档案中的人工智能集成和搜索。这种方法为WSI内容描述提供了一种通用的格式，并通过组织图结构增加了识别和搜索WSI细节的效率，同时实现了跨应用领域和平台的互操作性。这种标准化工具将对医疗病理学和相关科学领域产生积极影响。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21654", "html_url": "https://arxiv.org/abs/2508.21654", "title": "我誓死效忠于（没）行：模型窃取攻击的设计与评估", "title_en": "I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks", "authors": "Daryna Oliynyk,Rudolf Mayer,Kathrin Grosse,Andreas Rauber", "background": "模型窃取攻击威胁到提供为服务的机器学习模型的保密性。尽管这些模型被保密，恶意方仍可以通过查询模型来标注数据样本并训练自己的替代模型，从而侵犯知识产权。尽管领域内的新型攻击不断涌现，但这些攻击的设计和评估标准不一，使得比较先前的研究工作和评估领域进展变得困难。", "innovation": "这是首次提出为设计和评估模型窃取攻击提供建议，通过对依赖于训练替代模型的攻击群体进行研究，提出首个综合威胁模型，并开发了攻击比较框架。此外，我们还分析了相关工作中的攻击设置，以理解哪些任务和模型研究最多。基于我们的发现，我们提供了一系列攻击开发的最佳实践，包括实验前后以及实验之外的建议，还总结了关于模型窃取攻击评估的广泛开放研究问题。我们的发现和建议也适用于其他问题领域，从而建立了首个通用的模型窃取攻击评估方法。", "conclusion": "我们的研究和建议不仅针对模型窃取攻击，还为其他问题领域建立了通用的评估方法，因此确立了首个模型窃取攻击的通用评估方法。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21652", "html_url": "https://arxiv.org/abs/2508.21652", "title": "边缘设备上的机器智能：基于强化学习的可解释心电信号局部化", "title_en": "Machine Intelligence on the Edge: Interpretable Cardiac Pattern Localisation Using Reinforcement Learning", "authors": "Haozhe Tian,Qiyu Rao,Nina Moutonnet,Pietro Ferraro,Danilo Mandic", "background": "匹配滤波器由于其高效性和可解释性而被广泛用于信号模式的定位。然而，在低信噪比的信号（如边缘设备记录的信号）中，明显的噪声模式可能会高度相似于目标，这使得匹配滤波器的效果下降。例如，在耳电心图（ear-ECG）中，心脏信号被弱化并且受到伪影的严重干扰。", "innovation": "提出了序贯匹配滤波器（SMF），该方法用由强化学习代理设计的一系列滤波器替代了传统的单一匹配滤波器。通过将滤波器设计作为顺序决策过程，SMF能够自适应地设计特定于信号的滤波器序列，同时保持高度的可解释性，揭示出关键的驱动决策模式。", "conclusion": "所提出的SMF框架在两个具有挑战性的实际ECG数据集上展现出了最先进的R-峰检测和生理状态分类功能，显示出可靠的和可解释的临床决策支持的潜力。此外，此提出的框架还可应用于需要精确噪声 corrupted 信号中模式定位的各种应用。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21664", "html_url": "https://arxiv.org/abs/2508.21664", "title": "通过连续排名概率分数进行集合预报轨迹学习：Lorenz '96案例研究", "title_en": "Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study", "authors": "Sagy Ephrati,James Woodfield", "background": "本文通过使用连续排名概率分数（CRPS）作为损失函数来研究轨迹学习在集合预报中的可行性。研究基于Lorenz '96系统，开发并训练了加性及乘性随机参量化方法以产生集合预测结果。实验结果表明，基于CRPS的轨迹学习能够生成准确且锐利的参量化方法。这些方法易于校准，并在短期预报中优于基于导数拟合的参量化方法。这种方法在数据同化应用中具有显著潜力，特别是在短期预报中有较高的准确性", "innovation": "提出使用连续排名概率分数（CRPS）作为损失函数来训练集合预报中的加性及乘性随机参量化方法，相比传统基于导数拟合的方法，这种方法在短期预报中更准确。此外，生成的参量化方法更易于校准，适用于数据同化应用", "conclusion": "本文通过案例研究证明了基于CRPS的轨迹学习方法在生成集合预报准确预测中的可行性，并且该方法在短期预报应用中表现出色，具有在数据同化应用中的潜在优势"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21484", "html_url": "https://arxiv.org/abs/2508.21484", "title": "生物医学研究中数据驱动的数字孪生发现", "title_en": "Data-driven Discovery of Digital Twins in Biomedical Research", "authors": "Clémence Métayer,Annabelle Ballesta,Julien Martinelli", "background": "近期的技术进步扩大了高通量生物数据集的可用性，这使得能够可靠地设计生物医学系统或患者的数据孪生。这类计算工具代表了关键反应网络，可用于指导药物发现和个人化治疗。然而，它们的开发仍依赖于人类建模者的繁重数据整合，因此需要自动化的方案来满足需求。在物理学中，数据驱动系统发现的成功得益于干净的数据集和明确的规则，这种技术的兴趣已扩展到生物学领域，尽管该领域面临独特的挑战。因此，本文回顾了从生物时间序列自动推断数据孪生的方法，这些方法主要涉及符号回归或稀疏回归。我们根据八项生物学和方法学挑战的标准来评估算法的表现，这些挑战与噪声或不完整数据、多重条件、先验知识集成、隐藏变量、高维度、未观察变量的导数、候选库设计和不确定性量化有关。在这些标准下，稀疏回归通常优于符号回归，特别是在使用贝叶斯框架时。进一步讨论了深度学习和大型语言模型在先验知识集成方面的新兴作用，尽管这些方法的可靠性和一致性有待提高。虽然没有一种方法能够解决所有挑战，我们提出了这样一种观点：学习数据孪生的进步将来自结合化学反应网络为基础的机理解释、贝叶斯不确定性量化以及深度学习的生成和先验知识集成能力的混合和模块化框架。为了促进其发展，我们还提出了一种基准框架来评估所有挑战下的方法性能。", "innovation": "文章提出了一种基于稀疏回归优于符号回归的评估标准，并强调了深度学习和大型语言模型在先验知识集成方面的新兴作用，尽管这些方法需要进一步提高可靠性。文章进一步提出了一种混合和模块化的学习框架，结合了化学反应网络为基础的机理解释、贝叶斯不确定性量化以及深度学习的生成和知识集成能力，以促进数据孪生的发展。文章还提出了一个基准框架，以评价各种方法在所有挑战下的性能。", "conclusion": "虽然没有一种方法能够解决所有挑战，但是文章提出了一个混合和模块化的学习框架来促进数据孪生的发展。该框架结合了化学反应网络为基础的机理解释、贝叶斯不确定性量化以及深度学习的生成和知识集成能力。此外，文章还提出了一种基准框架来评价各种方法在所有挑战下的性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式人工智能进行天气适应性学习以增强气候变化韧性教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "当前，气候变化对环境和人类社会产生了深远影响，教育成为提升公众对气候变化认知和应对能力的关键领域。传统的教育方法通常缺乏实时性和具体性，无法有效提升学习者在气候变化方面的知识水平和应对能力。因此，需要开发新的平台和技术来提高教育效果并增强气候韧性。", "innovation": "本文介绍了一种名为未来的气象条件培训系统（FACTS）的新平台，该平台通过物联网（IoT）传感器收集实时大气数据，并结合知识库中的精选资源，动态生成本地化的学习挑战。系统利用生成式人工智能（Generative AI）驱动的服务器进行学习者反应分析，提供个性化反馈和支持。这种平台的创新在于结合了物联网和生成式人工智能技术，为基于特定地点的、具有适应性的学习体验提供支持，从而提高教育的参与度和气候意识培养效果。", "conclusion": "用户评估结果显示，参与者认为该系统易于使用且能有效增强气候变化适应性知识。该研究结果表明，将物联网和生成式人工智能技术整合到气象适应性学习技术中，具有显著潜力，可极大地提升教育参与度和促进气候意识培养。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中对标GPT-5：可测量的进步，但持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面显示出巨大潜力。GPT-5是一款特别针对肿瘤学使用的新颖LLM系统。", "innovation": "该研究使用ACR辐射肿瘤学委派考试和一组60个真实且多样化的放射肿瘤学案例来评估GPT-5的表现。GPT-5不仅在选择题测试中表现出色，还在真实世界的应用案例中得到了较高的评价，尤其是在治疗建议的准确性和完整性方面。", "conclusion": "GPT-5在放射肿瘤学选择题测试中明显优于之前的模型版本。尽管GPT-5在生成真实世界的放射肿瘤学治疗建议方面的表现良好，但在准确性的评分中仍有改进的空间。虽然幻觉很少发生，但实质性错误的存在表明GPT-5生成的建议需要严格的专家监督才能应用于临床。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21672", "html_url": "https://arxiv.org/abs/2508.21672", "title": "一种激励辅助下的无遗憾玩家引导的柔和诱导框架", "title_en": "A Soft Inducement Framework for Incentive-Aided Steering of No-Regret Players", "authors": "Asrin Efe Yorulmaz,Raj Kiriti Velicheti,Melih Bastopcu,Tamer Başar", "background": "该研究探讨了在增加调解者的双人规范博弈中，调解者通过信息设计和激励措施引导玩家到达特定行为组合的问题。研究首先分析了哪些博弈可以通过成功的引导实现。研究指出，仅通过信息设计有时不能引导玩家到达任何期望的行为组合，并且这种引导也不总是可以通过次线性支付方案实现。因此，研究给出了每次迭代所需的最小支付边界的下限。", "innovation": "研究提出了一个增强方法，其中包括在重复博弈开始前的一次性的信息设计阶段，将先前的互动转化为斯塔克尔贝格博弈。这一方法理论上证明了可以提高玩家行为组合收敛到目标点的速度，并且通过实证结果进一步支持了这一观点。", "conclusion": "该方法可以通过常数因子提高玩家行为到达目标组合的概率，并通过实验验证了其有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为何止于词语？从单词级OCR到行级OCR的更大图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术将每个字符分开来识别，这种方法容易出现字符分割错误，并且缺乏利用语言模型的上下文信息。近年来，在序列到序列翻译方面的进展导致现代技术可以先检测单词，然后一个单词一个单词地输入到模型中，直接输出完整单词，从而利用语言模型并绕过了易出错的字符分割步骤。然而，作者注意到这种模式的转变将准确性的瓶颈转移到了单词分割。因此，他们提出了一种从单词级OCR到行级OCR的自然和合理的进阶方法，可以绕过单词检测中的错误，同时提供较大的句子上下文，更好地利用语言模型。", "innovation": "该研究提出了一种新的方法，从单词级OCR进阶到行级OCR。通过这种方法，可以避免单词检测中的错误，同时利用更大的句子上下文，从而更有效地利用语言模型。此外，他们还创建了一个专门收集的包含251个英文页面图像和行级注释的数据集，以供训练和基准测试行级OCR技术。实验结果显示，相比基于单词的方法，该技术不仅提高了端到端的准确性（提高5.4%），还提高了4倍的效率。这项研究展示了从单词级OCR到行级OCR的转变潜力，特别是在文档图像识别中的优势，同时项目的持续改进也有望利用大型语言模型的进步。", "conclusion": "该研究不仅提出了一种新的行级OCR方法，实现了显著的准确性提升和效率提高，还贡献了一个用于训练和评估的行级OCR数据集。这些成果表明，随着大型语言模型的不断进步，该方法也具备进一步的应用潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21663", "html_url": "https://arxiv.org/abs/2508.21663", "title": "使用通用机器学习原子势模型进行表面稳定性建模：一个全面的断裂能基准研究", "title_en": "Surface Stability Modeling with Universal Machine Learning Interatomic Potentials: A Comprehensive Cleavage Energy Benchmarking Study", "authors": "Ardavan Mehdizadeh,Peter Schindler", "background": "机器学习原子势（MLIPs）已通过缩小量子力学精度和经典模拟效率之间的差距，彻底改变了计算材料科学，使人们对周期表中材料性质进行前所未有的探索。尽管这些通用MLIPs（uMLIPs）在预测材料整体性质方面取得了显著成功，但尚未进行系统评估以确定它们在预测断裂能方面的能力，而断裂能是决定了裂纹扩展、催化、表面稳定性和界面现象的关键性质。现有研究使用了我们之前建立的包含36,718种单质、双元和三元金属化合物层状结构的密度泛函理论（DFT）数据库，对19种最先进的uMLIPs在断裂能预测方面的性能进行了全面评估。", "innovation": "研究通过对19种最先进的uMLIPs进行综合基准测试，分析了各种架构在不同化学组成、晶系、厚度和表面取向上的表现。结果显示，数据训练集的组成比模型架构本身更为关键，强调非平衡配置的Open Materials 2024 (OMat24) 数据集训练的模型在断裂能预测上的平均绝对百分比误差低于6%，且能够正确识别87%的最热力学稳定表面终端，而仅基于平衡数据集训练的模型误差明显更高，甚至训练于表面吸附数据集的模型表现出17倍的性能退化。此外，简单架构在适当数据集上进行训练可以获得与复杂变压器相当的准确度，同时提供10至100倍的计算加速。", "conclusion": "研究结果表明，社区应重点关注战略性的训练数据生成，以捕捉相关物理现象。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "通过非参数深度嵌入聚类实现无监督视频连续学习", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频代表了一种复杂且丰富的时空媒体信息，在众多应用中广泛使用，但在无监督连续学习中尚未得到充分探索。先前的研究仅专注于监督连续学习，依赖标签和任务边界的知识，但有标注数据的成本高且不切实际。因此，本文研究了无监督视频连续学习（uVCL），由于处理视频时需要更多的计算和内存要求，使得uVCL提出了更多的挑战。", "innovation": "本文提出了一种非参数的无监督深度嵌入聚类解决方案，用于处理无标签、无任务边界的连续学习问题。具体来说，引入了一个利用深度嵌入视频特征（由无监督视频变换网络提取）的核密度估计（KDE）作为数据的非参数概率表示。为了检测新的任务数据，提出了一种新颖检测标准，动态扩展记忆簇，以在连续学习过程中捕捉新知识。此外，利用了之前任务的迁移学习作为当前学习任务的初始状态，以提高学习效果。实验结果表明，所提出的方法在连续学习多个任务时显著提高了模型性能。", "conclusion": "通过深度嵌入聚类方法和非参数概率表示，本文提出的方法在无监督视频连续学习问题上表现出显著的性能提升。在三种标准视频动作识别数据集（UCF101, HMDB51, 和 Something-to-Something V2）上的深入评估验证了该方法的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21804", "html_url": "https://arxiv.org/abs/2508.21804", "title": "考虑 informatively timed 处理的因果效应估计", "title_en": "Considerations for Estimating Causal Effects of Informatively Timed Treatments", "authors": "Arman Oganisian", "background": "流行病学研究常常关注于估计治疗决策序列对生存结果因果效应。然而，在很多情况下，治疗决策并不是在固定的预设时间节点发生的，其时间可能会因受试个体的不同而变化，并且这种变化可能反映了后续治疗决策的能力，潜在结果等有价值的信息。现有文献对此问题及其潜在解决方案的认知不足，这正是本文研究的背景。", "innovation": "本文正式描述了 informatively timed 的问题以及忽略它所带来的问题，并展示了如何使用 g 方法来分析具有 informatively timed 处理的序列治疗。文中指出，在这些场景中，两次治疗决策之间的等待时间可以适当地被视为时间变化混杂因素。通过合成示例，本文说明了在没有调整这些等待时间的情况下，g 方法可能会产生偏差，并展示了在患者在治疗之间可能会死亡或被删失（censored）的情况下，如何进行调整。", "conclusion": "本文的最终结论是：1）考虑时间对于有效推理非常重要；2）通过调整作为时间变化混杂因素的治疗部件之间的等待时间，可以使用 g 方法纠正 informatively timed 的处理带来的影响。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark：一种用于工业机器工具控制器动态水印的强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": "工业4.0高度网络化的机床控制器是回放攻击的首要目标，攻击者可能利用过时的传感器数据操控执行器。当前的动态水印方案假设线性-高斯动态特性，并且使用恒定的水印统计参数，这使得它们对机床控制器的时间变化和部分专有行为存在脆弱性。", "innovation": "该研究提出DynaMark，一种基于强化学习的框架，将动态水印建模为马尔可夫决策过程（MDP）。该框架能在线学习一个自适应策略，动态调整具有零均值的高斯水印的协方差，无需了解系统知识。DynaMark通过平衡控制性能、能源消耗和检测置信度来最大化一个独特的奖励函数。同时，该研究开发了一种贝叶斯信念更新机制，用于线性系统的实时检测置信度更新，这使MDP能在动态系统中有效应用。", "conclusion": "DynaMark在西门子Sinumerik 828D控制器数字双胞胎中实现了水印能量70%的降低，同时保持正常的轨迹，与恒定方差基准相比，其平均检测延迟与一个样本间隔相当。物理步进电机试验台实验证明了这一结果，迅速触发警报，且控制性能下降小于现有基准。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.00342", "html_url": "https://arxiv.org/abs/2402.00342", "title": "联邦学习中的隐私威胁及对策综述", "title_en": "Survey of Privacy Threats and Countermeasures in Federated Learning", "authors": "Masahiro Hayashitani,Junki Mori,Isamu Teranishi", "background": "联邦学习被认为是一种隐私保护的学习方法，因为它在客户端之间不直接交换训练数据。然而，联邦学习仍然存在隐私威胁，针对这些威胁的对策已经得到了研究。但目前还没有对典型类型（水平联邦学习、垂直联邦学习和迁移联邦学习）中的共同和独特隐私威胁进行全面而具体的分类和描述.", "innovation": "本文描述了对典型类型联邦学习（水平联邦学习、垂直联邦学习和迁移联邦学习）中的隐私威胁及其对应的对策进行了全面和具体的阐述，填补了该领域的研究空白.", "conclusion": "本文综述了联邦学习中常见的隐私威胁及其对策，为理解与减轻这些威胁提供了重要参考，有助于进一步提高联邦学习的安全性和隐私保护水平."}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.19470", "html_url": "https://arxiv.org/abs/2305.19470", "title": "低相干矩阵中的标签嵌入", "title_en": "Label Embedding via Low-Coherence Matrices", "authors": "Jianxin Zhang,Clayton Scott", "background": "标签嵌入是一种针对多分类问题的框架，其中每个标签由一个固定维度的向量表示，训练过程涉及将模型输出匹配到正确标签的向量。尽管标签嵌入在极端分类和零样本学习中取得了成功，并展示了计算和统计上的优势，但其理论基础仍不明确。本文在极端多分类场景下分析了标签嵌入，即类别的数量C非常大。研究显示存在计算和统计效率之间的权衡，这与嵌入矩阵的相干性有关。进一步地，在Massart噪声条件下，当相干性足够低时，标签嵌入的统计惩罚消失。研究支持一个简单、可扩展、易于并行的算法，并通过实验结果证明了其在大规模应用中的有效性。", "innovation": "研究展示了标签嵌入在极端多分类场景下的分析，阐明了计算和统计效率之间的关系，使用“低相干矩阵”的概念。提出的方法在解释复杂性、可扩展性和并行化方面具有优势，并在实际应用中表现出色。", "conclusion": "研究支持了一个简单、可扩展且易于并行的假设。当Massart噪声条件下，即便具有足够低的相干性时，标签嵌入方法的统计惩罚会消失。实验验证了该方法在大规模分类问题中的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "通过值顺序估算距离度量学习进行分类数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是一种流行的机器学习方法，用于数据挖掘，可以处理和分析数据集以自动揭示样本分布模式。由于泛化的分类数据缺乏一个明确定义的度量空间，如数值数据的欧几里得距离空间，分类数据的分布通常被低估，因此在聚类过程中可能会损失有价值的信息。因此，本文介绍了一种新颖的有序距离度量学习方法，通过学习其最佳顺序关系并衡量它们在一条线上的距离，类似于数值属性的距离。", "innovation": "为了解决分类数据聚类过程中存在的问题，本文开发了一种新的联合学习范式，通过交替执行聚类和有序距离度量学习来学习分类值的顺序关系，这种方法具有较低的时间复杂度和收敛性保证。此外，所提出的方法能够充分利用分类和混合数据集中的分类数据，实现更优的聚类准确性，并降低了管理和理解非直观分类数据的难度。", "conclusion": "通过实验验证了所提出方法的有效性，证明了其能够提高聚类准确性并降低管理分类数据的难度。源代码可在提供的链接处访问。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "域内泛化在真实世界情境中：从领域意识表示中分离分类", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评估基础模型如CLIP的领域泛化(DG)具有挑战性，因为大规模网络预训练数据可能覆盖了许多现有基准。当前的DG评估可能既不够具挑战性，也不能充分测试真实未知数据场景。为了更好地评估CLIP在真实世界环境中的DG性能，特别是在CLIP遭遇具有挑战性的未知数据时，我们考虑了两种方法：在对ImageNet进行微调后在33个多样化的数据集上进行评估，这些数据集具有量化的领域外(OOD)得分；以及通过漠视某些领域来让CLIP“忘记”某些领域，作为近似方法。我们发现CLIP在更多OOD数据集上的性能显著下降。为了解决这个问题，我们提出了CLIP-DCA(解耦分类和增强领域感知表示)方法。我们观察到，尽管标准的领域不变性损失旨在使表示不受域的影响，这可能会对基础模型构成危害，迫使丢弃有益于泛化的领域感知表示。因此，我们假设增强领域感知是基础模型有效领域不变性分类的前提条件。CLIP-DCA通过使用独立的领域头和合成的多样领域数据来识别并增强CLIP编码器中的领域感知性，同时通过从领域特征中解耦来促进领域不变性分类。", "innovation": "CLIP-DCA通过使用独立的领域头和合成的多样性领域数据，在CLIP的编码器中识别和增强领域意识，同时通过从领域特征中解耦来促进领域不变性分类，从而显著提高了在具有挑战性的评估中的性能，特别是在更多OOD数据集上表现突出。这种方法旨在解决基础模型领域泛化的潜在问题，特别是领域感知表示对泛化的影响。", "conclusion": "CLIP-DCA在具有挑战性的域泛化评估中取得了显著的改进，特别是在更多OOD数据集上。该方法的动机是促进领域感知是基础模型中有效领域不变性分类的前提条件。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "神经网络无处不在，从大规模语言模型、语音转录系统、分子发现算法、机器人等领域中都可以看到它们的身影。归根结底，神经网络是由可微分的基本组成元素构建的组合。研究这些网络意味着学习如何编程以及如何与这些模型交互，这被视为一种所谓的可微分编程。本文旨在为刚刚进入这一神秘可微分仙境的新手（比如Alice）提供一个入门导读。", "innovation": "文章介绍了通过自动微分优化函数的基本原理，并选择了处理序列、图形、文本和音频的最常见设计。重点在于提供一种直观且自包含的介绍，涉及卷积、注意和循环模块的设计技术，旨在使读者能够理解一些最先进模型的工作原理，包括大型语言模型（LLMs）和多模态架构。同时，文章使用PyTorch和JAX等代码示例，希望能减少理论与实践之间的鸿沟。", "conclusion": "文章希望为读者提供足够的基础，使他们能够理解最前沿的模型和架构，如大规模语言模型（LLMs）和多模态架构，从而更深入地探索这个领域的更多内容。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba 状态空间模型是李雅普诺夫稳定的学习者", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba 状态空间模型（SSMs）最近在各种任务中超过了最先进的（SOTA）大型语言模型（LLMs），并且被广泛采用。然而，对于基于重复机制的深度模型（如SSMs），其循环动态的敏感性是稳定学习中的一个主要问题。Mamba 的循环动态在常见的微调方法（例如混合精度微调和参数高效微调）下的敏感性尚未被研究。与 Transformer LLMs 不同，Mamba LLMs 在不同组合的混合精度微调和参数高效微调下表现出极高的稳定性，而 Transformer LLMs 可能会极大地偏离全精度版本，尽管这些微调框架在基于注意力的模型中的广泛应用。", "innovation": "本研究利用动态系统理论证明了Mamba LLMs 的循环动态是稳定的，特别是它们在混合精度微调和参数高效微调下表现出极大的稳定性，这是对 Transformer LLMs 的显著改进。研究还首次使用混合精度微调和参数高效微调来研究 Mamba LLMs 的上下文内学习（ICL）能力，以补充最近的其他相关工作。", "conclusion": "研究结果表明，Mamba LLMs 的循环动态保证了它们在混合精度微调和参数高效微调下的稳定学习。研究利用这些微调方法来探索 Mamba LLMs 在自然语言任务中的上下文内学习能力，由此补充了其他的相关工作。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不要对朋友撒谎：通过协作自我博弈学习你所知道的", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "为了成为有帮助的助手，AI代理必须意识到自己的能力和限制，包括何时从参数知识中作答、何时信任工具输出、何时不作答或谨慎作答等。这些能力很难通过监督微调来教授，因为需要构建反映代理特定能力的例子。因此，作者提出了一种全新的方法来教导代理关于它们所知道的知识：协作自我博弈。", "innovation": "提出了一种新的教学方法——协作自我博弈，这种方法通过多代理协作，在集体奖励机制的激励下达成正确的答案，从而自然而然地培养出元知识。这种方法特别应用于具备异构工具的小型社会中的代理，需要他们协作以最大化成功并减少努力。", "conclusion": "实验结果显示，多代理群体层面的奖励可以促进策略的转移，这些策略能够提高单个代理在孤立部署时的工具使用和有选择的预测能力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: A Python Library for Conformal Prediction", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "现有的统计预测工具包虽然可以与先进的深度学习模型（如深度神经网络（DNNs）、图神经网络（GNNs）和大型语言模型（LLMs））集成，但通常缺乏对大规模深度学习场景的支持和扩展性。有效地处理这些场景中的预测区间需要新的工具和库。", "innovation": "TorchCP是一个基于PyTorch的库，旨在将最先进的核预测算法集成到深度学习技术中，包括基于DNN的分类器/回归器、GNN和LLM。该库支持特定于CP的训练算法、在线预测和GPU加速的批处理处理，能够显著减少大规模数据集上的推理时间。", "conclusion": "TorchCP通过其低耦合设计、全面的高级方法集和端到端GPU可扩展性，为研究人员和从业者提供了一种增强最新应用中的不确定性量化的能力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.01371", "html_url": "https://arxiv.org/abs/2402.01371", "title": "Two-Timescale Critic-Actor for Average Reward MDPs with Function Approximation", "title_en": "Two-Timescale Critic-Actor for Average Reward MDPs with Function Approximation", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "近期的研究关注于非渐近收敛分析中的AC算法。此前，在折扣成本设置下提出了一个两时标评价-控制算法，但在表查找情况下的时标顺序相反，并仅展示了渐近收敛性。该研究工作首次提出了应用于长期平均奖励设置的两时标评价-控制算法，并首次提供了这样方案的有限时间的非渐近以及渐近收敛分析。", "innovation": "该工作提出了首个结合函数近似的两时标评价-控制算法应用于长期平均奖励的问题，特别地，给出了此类方案的不依赖于样本数量的最佳学习速率分析，并证明其对于评价的均方误差在$\tilde{\text{O}}(\text{ε}^{-(2+\text{δ})})$级别为止，其中$\text{δ}$可以接近零，无论是对于有限时间还是渐近收敛，结果均优于两时标AC算法在类似条件下的结果。此外，论文还分析了算法的渐近收敛性，并证明了评价递归的未然几乎一致收敛于与扰动平均奖励目标局部最大值对应的控制参数的吸引子。", "conclusion": "该研究给出了有限时间与渐近收敛性分析，并展示了数值实验结果，表明评价-控制算法在三个基准设置中表现最优。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.16363", "html_url": "https://arxiv.org/abs/2310.16363", "title": "三时间尺度受限演员评论家和受限天然演员评论家算法的有限时间分析", "title_en": "Finite-Time Analysis of Three-Timescale Constrained Actor-Critic and Constrained Natural Actor-Critic Algorithms", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "演员评论家方法在多种强化学习任务中得到广泛应用，特别是在状态-动作空间较大的情况下。本文主要关注在受限马尔可夫决策过程（C-MDP）中，涉及不等式约束条件的演员评论家和天然演员评论家算法，并在非独立非同分布（非-i.i.d.，Markovian）设置下进行非渐近分析。分析的目标是长期平均成本准则，其中目标和约束函数均为特定指定成本函数的策略依赖的长期平均值。这些约束使用拉格朗日乘数法进行处理。", "innovation": "本文采用新的方法对过去的受限演员评论家（C-AC）和受限天然演员评论家（C-NAC）算法进行了有限时间下的非渐近分析。证明了这些算法可以确保找到性能（拉格朗日）函数的次优解，并且在两种算法的情况下，样本复杂度为$\tilde{\text{O}}(\text{ε}^{-2.5})$。此外，还展示了在三个不同安全环境中的实验结果。", "conclusion": "本文提出了首次在三时间尺度下的受限演员评论家和受限天然演员评论家算法的有限时间分析，证明了算法可以找到绩效函数的次优解，并提供了在安全环境中的实验验证。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE: 基于奖励导向的LLM特定任务指令微调数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "指令微调展示了大型语言模型（LLMs）在各种领域生成更可控、更有效的输出的巨大潜力。然而，当前的数据选择方法主要依赖手工设计的相似性指标来选择与测试数据分布相匹配的训练数据。这些方法的目的是在测试数据上最小化指令微调损失，从而提高目标任务的性能。但是，观察到LLMs中的指令微调损失（即下一个标记预测的交叉熵损失）与实际任务性能之间通常不存在单调关系，这导致了存在的数据选择方法效果不佳。", "innovation": "我们提出了ROSE（Reward-Oriented inStruction数据选择方法），一种新颖的基于奖励导向的任务特定指令微调的数据选择方法。ROSE利用成对偏好损失作为奖励信号来优化数据选择，它通过适应影响形式来近似选择与少量示例偏好验证集对比的最相关的训练数据点。实验结果显示，使用ROSE选择仅有5%的训练数据比使用全部训练数据集的微调方法可以达到竞争力的性能，并且优于其他当前最先进的数据选择方法。", "conclusion": "我们的定性分析进一步证实了该方法在多种基准数据集和不同模型架构上的鲁棒泛化能力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08897", "html_url": "https://arxiv.org/abs/2504.08897", "title": "受局部学习训练的脉冲神经网络抗对抗攻击的鲁棒性研究", "title_en": "On the Adversarial Robustness of Spiking Neural Networks Trained by Local Learning", "authors": "Jiaqi Lin,Abhronil Sengupta", "background": "近期研究表明，基于框架和事件感知模式的脉冲神经网络（SNNs）在对抗样本攻击下表现脆弱，这些样本在许多情况下无法与干净数据区分开。大多数相关的研究都使用了Backpropagation Through Time (BPTT)这一基于梯度的方法来生成对抗样本，但从生物学可行性角度来看，这种方法存在缺陷。相比于BPTT，局部学习方法虽然放松了BPTT的一些限制，但在这个领域还未被充分研究。", "innovation": "本文通过探讨四种类型的训练算法在SNNs中的对抗鲁棒性，重点分析了基于梯度的对抗攻击在这一场景下的无效性，并提出了结合对抗样本转移性的混合对抗攻击方案。该新方法不仅在多种对抗攻击场景下表现优越，而且相比现有的攻击方法有显著提高。此外，该方法还被证明具有良好的泛化性，在多步攻击、黑盒FGSM攻击甚至非脉冲领域都有良好的适应性。", "conclusion": "综上所述，本文通过混合攻击策略显著增强了SNNs的抗攻击性，并通过不同类型的对抗攻击实验验证了这一策略的有效性和广泛适用性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝标记：一种在大型语言模型中校准拒绝行为的简单方法", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "构建安全可靠的语言模型的关键在于让模型能够适当地拒绝执行某些指令或回答某些问题。工程师们面临的挑战是，不同个人可能希望模型对不同类别的问题具有不同程度的敏感性，而不同用户可能需要不同的拒绝率。当前的解决方法是训练多个具有不同比例拒绝信息模型来达到所需的拒绝率，这既耗费计算资源，也不便于每个用户定制自己的拒绝率偏好。因此，需要一个更为简单且经济的方法来校准大型语言模型的拒绝行为。", "innovation": "本文提出了一种名为‘拒绝标记’的新方法，即一种为每个拒绝类别设置的拒绝标记或单一的拒绝标记，在训练时添加至模型的响应前端。通过在推理过程中调整生成每个类别拒绝标记的概率，可以控制模型的拒绝行为。这种方法的优点在于无需进一步微调，只需在生成过程中有选择地进行干预即可控制单个模型的拒绝率。", "conclusion": "拒绝标记提供了一种简单的方法来控制大型语言模型的拒绝行为，无需进一步微调，仅通过在生成过程中选择性地干预即可实现。这为不同用户提供定制化的拒绝率需求提供了灵活性，提升了模型的可靠性和安全性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16083", "html_url": "https://arxiv.org/abs/2412.16083", "title": "使用差分隐私的联邦扩散建模在表格数据合成中的应用", "title_en": "Federated Diffusion Modeling with Differential Privacy for Tabular Data Synthesis", "authors": "Timur Sattarov,Marco Schreyer,Damian Borth", "background": "各种领域对隐私保护数据挖掘的需求日益增长，这促使产生了严格遵守隐私标准的合成数据生成解决方案。因此，该文探讨了隐私保护数据合成领域的最新发展趋势，提出了一种名为DP-FedTabDiff的框架，该框架结合了差分隐私、联邦学习和噪声扩散概率模型，用以生成高质量的合成表格数据。这一方法能在确保符合隐私法规的同时，保持数据的价值和实用性。研究表明，该方法在多个实际混合类型表格数据集上的效果显著，同时证明了DP-FedTabDiff在高度监管领域的潜力，有助于推动联邦学习和隐私保护数据合成的发展", "innovation": "该文引入了DP-FedTabDiff框架，这是将差分隐私、联邦学习和噪声扩散概率模型进行全新融合的框架。这一创新方法不仅能够生成高质量的合成数据，还在隐私保护和数据实用性之间实现了良好平衡，有助于克服传统合成数据生成方法中的隐私保护与数据质量之间的冲突", "conclusion": "通过实证分析，本文展示了DP-FedTabDiff框架在多个实际应用中的表现。研究结果表明，该方法能在不牺牲数据质量的情况下显著提高隐私保护级别，确保数据的合规性和安全性。未来，这项研究有望进一步推动联邦学习和隐私保护数据合成技术的发展，为安全的数据共享和分析提供新的可能性"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中视图的合并与解耦对于机器人操作的应用", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉技术在机器人操作中尤为重要，尤其是在使用视觉伺服技术时。由于三维世界的特性，使用多视角并融合提供的信息可以创建更有效的表示，进而训练出更样本高效的策略。然而，这些多视角策略对摄像机故障敏感，部署起来较为繁琐。", "innovation": "提出了一个合并与解耦（MAD）算法，该算法在合并视图以提高样本效率的同时，通过将多视角特征输入与单视角特征相结合来解耦视图。这种方法产生的策略更具鲁棒性，并实现了轻量级部署。", "conclusion": "通过在Meta-World和ManiSkill3上的实验，证明了该方法的有效性和鲁棒性。项目网站和代码请访问 https://link.to.the.project."}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "风格共享的去中心化域泛化：形式模型与收敛分析", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "许多联邦学习（FL）的工作集中在训练集和测试集分布不变的情景下，但这种假设在实际中往往不成立，尤其是在分布变化的情况下。现有的域泛化（DG）方法缺乏深度的数学分析，并且主要局限于星形拓扑架构。本文针对现有研究中的这两个主要差距进行工作。", "innovation": "开发了一种称为Decentralized Federated Domain Generalization with Style Sharing (StyleDDG)的去中心化DG算法，该算法允许P2P网络中的设备通过共享其数据集中推断出的风格信息来进行DG。此外，提供了第一个系统化的去中心化网络中基于风格的DG训练分析方法，并将其现有中央式DG算法融于该框架，从而展示了StyleDDG在目标域中实现了显著的准确性提升，同时通信开销较小。", "conclusion": "实验结果表明，与基线的去中心化梯度方法相比，StyleDDG能够以最小的通信开销在目标域中实现显著的准确性提升。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.18164", "html_url": "https://arxiv.org/abs/2412.18164", "title": "随机控制方法用于调整扩散模型：最优性、正则性和收敛性", "title_en": "Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence", "authors": "Yinbin Han,Meisam Razaviyayn,Renyuan Xu", "background": "扩散模型已经显示出强大的生成建模能力，能够有效捕捉大规模数据集中的目标数据分布。然而，针对特定下游任务、约束和人类偏好的微调这些大型模型仍是一项重大挑战。虽然最近的研究利用强化学习算法来解决这一问题，但大多数进展都是基于经验的，缺乏理论理解。为了填补这一空白，该研究提出了一种随机控制框架来微调扩散模型。该框架基于预训练的去噪扩散概率模型作为参考动力学，结合了线性动力学控制与Kullback-Leibler正则化。", "innovation": "1. 研究提出了一个随机控制框架，用于微调扩散模型。\n2. 基于预训练的去噪扩散概率模型，结合了线性动力学控制与Kullback-Leibler正则化。\n3. 建立了随机控制问题的适定性和正则性，并开发了策略迭代算法（PI-FT）进行数值求解。\n4. 证明了策略迭代算法生成的控制值序列具有正则性，且实现了全局线性收敛。\n5. 探讨了该框架在参数设置和连续时间表示方面的扩展，并通过数值实验验证了提出策略迭代算法的实用性。", "conclusion": "本文构建了一个随机控制框架来微调扩散模型。通过策略迭代算法（PI-FT），不仅确保了生成序列的正则性，还实现了全局线性收敛。实验表明，所提出的PI-FT算法在实际问题上有效。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子与先看看再跨出步伐：超越下一个词预测的创造性限制", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "研究设计了一系列简约的算法任务，用以松散地抽象现实世界的开放任务。这使得研究者能够清晰、可控地评估当今语言模型在创造方面的极限。类似的，真实的创造性任务需要一种远见性的、隐式的创造性规划步骤，这种步骤或（a）在抽象知识图中发现新的联系（如文字游戏、类比研究或科研），或（b）构建新的模式（如设计数学问题或新蛋白质）。研究表明，下一个词的学习是短视的；多令牌方法（如无监督训练和扩散模型）在多样性和原创性方面表现出色。为了不损害连贯性地引入随机性，研究发现，在输入层注入噪声（称为种子条件）的效果出奇地好，甚至在某些情况下比输出层的软采样效果更好。", "innovation": "本文提出了一个原理性的、简化的测试床来分析开放式的创造性技能，并提供新的理由去超越下一个词预测和软采样。研究发现输入层注入噪声（种子条件）在不损害连贯性的前提下引入随机性的效果更好。", "conclusion": "本文的工作提供了一个分析开放式创造技能的原理性框架，并为超越下一个词预测和软采样提供了新的论据。部分代码在以下网址提供：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04104", "html_url": "https://arxiv.org/abs/2504.04104", "title": "SpecPipe: 使用推测解码加速基于流水线并行的大型语言模型推理", "title_en": "SpecPipe: Accelerating Pipeline Parallelism-based LLM Inference with Speculative Decoding", "authors": "Haofei Yin,Mengbai Xiao,Tinghong Li,Xiao Zhang,Dongxiao Yu,Guanghui Zhang", "background": "随着对大型语言模型推理需求的快速增长，流水线并行提供了一种成本效益高的分布式推理部署策略，但在服务延迟上存在缺陷。尽管推测解码可以改进性能，但仍然面临硬件利用率低和推测窗口狭窄的挑战。为了应对这些挑战，本文借鉴了指令流水线中的分支预测技术，提出了SpecPipe，通过逐步填充推测令牌来最大化硬件利用率，理想情况下每一步解码一个令牌。", "innovation": "SpecPipe包含动态推测令牌树和流水线推理框架两部分。动态推测令牌树从推测令牌源动态接收令牌并输出到推理流水线中。推测窗口放宽，允许集成高精度的草图模型，无需微调。同时，流水线推理框架遵循节点级计算、裁剪传播和节点间通信阶段。与标准的流水线并行方法和先前的基于树的推测解码方法相比，SpecPipe在不同的单请求负载上，可以在各个阶段的时间之间表现得更好。对于多请求负载，SpecPipe-DB相比vLLM分别实现了1.64到2.08倍的吞吐量提升和1.61到2.06倍的解码时间缩短。", "conclusion": "实验结果表明，SpecPipe在多样性单请求工作负载上比标准流水线并行提高了4.19到5.53倍的时间效率，并比基于树的推测解码方法提高了2.08到2.38倍。对于多请求负载，SpecPipe-DB的吞吐量和时间效率也显著提高，分别提高了1.64到2.08倍和1.61到2.06倍。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 增强偏置和非对称缩放的旋转量化方法用于大规模语言模型", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已成为最先进的量化管道中大型语言模型（LLMs）的关键组成部分，通过有效平滑权重和激活中的异常值。然而，进一步优化旋转参数只能提供有限的性能提升，并引入了大量的训练开销：由于旋转参数共享，必须同时加载整个模型以实现反向传播，从而导致内存消耗巨大，不利于实际应用。", "innovation": "本文识别了当前旋转量化方法的两个根本局限性：(i) 旋转无法对齐通道均值，导致量化界限更宽和增加舍入误差；(ii) 旋转使得激活分布更加接近高斯分布，增加了由于剪裁误差而导致的能量损失。为了解决这些问题，我们提出了BASE-Q，这是一种简单而强大的方法，结合了偏置校正和非对称缩放，有效减少了舍入和剪裁误差。此外，BASE-Q 允许块级优化，消除了需要内存密集型全模型反向传播的需求。", "conclusion": "我们在各种LLM和基准上的广泛实验表明，BASE-Q 的有效性，相对于 QuaRot、SpinQuant 和 OSTQuant，准确度差距分别缩小了50.5%、42.9%和29.2%。相关代码将很快发布。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE: 基于刚性物理启发神经ODE的化学反应速率估计", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "估计复杂化学反应的速率系数对于推进详细化学研究至关重要。然而，真实世界大气化学系统中存在的刚性特性带来了严峻挑战，导致基于学习的方法训练不稳定且收敛效果差，从而妨碍有效估计速率系数。为了应对这一问题，我们提出了一种刚性物理启发神经常微分方程（SPIN-ODE）框架，用于化学反应建模。该方法引入了三阶段优化流程，包括使用黑盒神经调度拟合浓度轨迹、预训练化学反应神经网络（CRNN）以学习浓度与其时间导数之间的映射，以及通过与预训练的CRNN集成微调速率系数。针对合成数据集和新提出的实际数据集进行了详尽的实验，验证了我们方法的有效性和鲁棒性。作为首个研究刚性神经ODE以发现化学速率系数的作品，我们的研究为将神经网络与详细化学相结合提供了新的方向", "innovation": "提出了一种SPIN-ODE框架，该框架通过三阶段优化过程以处理化学反应中的刚性问题，包括黑盒神经ODE拟合、CRNN预训练学习浓度与其时间导数的映射，以及通过与预训练的CRNN结合微调速率系数。这一方法首次以刚性神经ODE解决化学速率系数的发现问题，为神经网络与详细化学的整合提供了新方向", "conclusion": "以SPIN-ODE框架为基础，我们实验验证了其在合成数据集和实际数据集上的有效性与鲁棒性，为化学反应速率估计提供了一个创新解决方案，并为未来研究化学反应建模提供了新的研究方向"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对网页代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "现有的多模态大型语言模型（MLLM）基于网页代理能够通过生成基于网页截屏的动作来与网页环境交互。然而，这些代理可能会受到恶意攻击，使得它们执行攻击者指定的操作。研究团队提出了一种新的威胁模型：WebInject，旨在通过在渲染网页的原始像素值中添加扰动，影响网页代理的行为。这种攻击方式使得即使不篡改网页本身，也能引导网页代理执行攻击者指定的动作。研究中的挑战是如何找到合适的扰动，特别是由于原始像素值到截屏的映射是非可微分的，这给使用梯度下降法造成了障碍。为了解决这个问题，研究团队开发了一种训练神经网络来近似这个映射的方法，并使用投影梯度下降法来解决优化问题。", "innovation": "WebInject基于一种新的提示注入攻击技术，利用对渲染网页像素值进行微小扰动，以诱导网页代理执行攻击者指定的动作。研究引入了神经网络作为中间环节来近似映射关系，并采用投影梯度下降法有效解决了优化问题。这项技术的创新在于：1) 利用非可微分的原始像素值到截屏的映射关系，2) 开发神经网络逼近映射，3) 使用投影梯度下降方法优化扰动值。", "conclusion": "广泛的数据集实验表明，WebInject在引导网页代理执行攻击者指定的动作方面具有极高的有效性，并且显著优于现有的基准方法。这说明现有的网页代理系统存在明显的安全漏洞，需要进一步加强对这类攻击的研究和防护。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超越频率：冗余在大规模语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "大型语言模型的大规模训练带来了隐私和公平性方面的关键风险。先前的研究已经探讨了记忆与词元频率和重复模式之间的相关性，但本研究通过观察发现，词元频率对已记忆样本的影响微乎其微（例如，0.09），而对未记忆样本则有显著影响（例如，0.25）。这项研究还观察到，这些模式在不同规模的模型中都保持一致。", "innovation": "通过篡改样本前缀并量化通过词元位置的变化来测量扰动强度进行反事实分析，研究发现冗余与记忆模式相关。主要创新如下：1) 大约79%的已记忆样本具有低冗余，低冗余样本比高冗余样本更脆弱，表现出了两倍的脆弱性；2) 在扰动下，已记忆样本的表现会下降0.6，而非记忆样本仅下降0.01。研究结果表明，冗余度较低的样本稳定性较差，而更具冗余性的内容则更具有记忆性但也更加脆弱。", "conclusion": "研究结果表明，高冗余样本较不易被记住但更稳定，而低冗余样本虽然容易记住但更脆弱。这些发现建议采用基于冗余的数据预处理方法，以降低隐私风险并减少偏差，确保模型部署中的公平性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA: 运用LLM反馈实现时间序列异常推理", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在各个领域都至关重要，但现有的方法往往仅限于二元异常分类，缺乏详细的类别化或进一步的解释性推理。", "innovation": "提出了一种新的任务，Time-series Reasoning for Anomaly (Time-RA)，将传统的时序异常检测从判别式任务转化为生成性、推理密集型任务，利用大型语言模型（LLMs）。同时引入了第一个用于异常推理的跨域 multimodal 基准数据集 RATs40K，该数据集包含大约40,000个样本，涵盖10个实际领域的数据，每个样本包括数值时间序列数据、背景文本信息和可视化表示，并附有详细的注释（单变量异常14类型，多变量异常6类型）和结构化的解释性推理。开发了利用GPT-4反馈进行集成生成标签的细致注释框架，以确保准确性和解释性。", "conclusion": "跨域 multimodal 数据集和任务为可解释的时间序列异常检测和推理的显著进步铺平了道路。已经开源了代码和数据集，以支持和加速该领域的未来研究。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23344", "html_url": "https://arxiv.org/abs/2507.23344", "title": "基于可微分代理模拟的共享单车系统动态定价设计", "title_en": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "authors": "Tatsuya Mitomi,Fumiyasu Makinoshima,Fumiya Makihara,Eigo Segawa", "background": "共享单车系统正在各城市兴起，作为一种新的环保交通方式。这些系统中，时空变化的用户需求导致自行车站点的库存不平衡，增加了再平衡成本。因此，通过最优动态定价来管理用户需求变得至关重要，但是由于系统中涉及背景多样且具有概率性的用户选择，因此设计最优定价具有挑战性。", "innovation": "通过开发一种可微分代理模拟，该方法能快速设计共享单车系统的动态定价策略，即使面对时空变化的出行需求和概率性的用户选择，也能实现库存平衡。实验结果显示，在25个自行车站点，5个时间槽和100个参数的情况下，与传统方法相比，该方法不仅能以73%至78%的降低损失率获得更准确的解决方案，而且提高了一百倍以上的收敛速度。在289个自行车站点的大型城市共享单车场景验证中，进一步证明了定价策略可以自然地诱导库存平衡，而无需手动再平衡。", "conclusion": "所提出的方法不仅能够实现平衡的自行车库存，还能通过设定适当的初始条件来最小化调整价格以诱导平衡库存时的成本。通过模拟，验证了获得的价格策略无需人工干预即可自然诱导实现库存均衡。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15695", "html_url": "https://arxiv.org/abs/2506.15695", "title": "SimuGen：基于模块化代理框架的构建块图仿真模型", "title_en": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "authors": "Xinxing Ren,Qianbo Zang,Zekun Guo", "background": "近年来，大型语言模型（LLMs）在数学推理和代码生成方面表现出色。然而，LLMs 在仿真领域仍然存在问题，特别是在生成 Simulink 模型方面。Simulink 是工程和科学研究中不可或缺的工具。初步实验表明，LLMs 从纯文本输入生成可靠的 Simulink 仿真代码时存在困难，这可能是因为它们缺乏 Simulink 特定的数据来预训练。", "innovation": "本文提出了 SimuGen，这是一种基于多模态代理的框架，通过结合视觉化的 Simulink 图形和领域知识，可以自动生成准确的 Simulink 仿真代码。SimuGen 借助一个专门的知识库协调多个专业的代理，包括调查员、单元测试审查员、代码生成器、执行器、调试定位器和报告撰写员。这种协作和模块化的设计可以实现可解释、稳健和可重复的 Simulink 仿真生成。", "conclusion": "SimuGen 的源代码已公开，可以实现基于块图的仿真模型的构建。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04901", "html_url": "https://arxiv.org/abs/2508.04901", "title": "稳定性敏感性：转移学习中自适应数据选择的理论与实证分析", "title_en": "Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning", "authors": "Prabhav Singh,Jessica Sorrell", "background": "转aires的知识迁移应用已经变革了机器学习，通过使预训练模型能够高效地适应新的领域。然而，这些调整的可靠性仍然不明确，尤其是在使用能够动态优先化训练样本的选择策略时。本文通过理论与实证分析，深入探讨了知识迁移中的再现性问题。", "innovation": "提出了一个数学框架来量化适应效果与结果一致性之间的基本权衡。该论文的核心贡献是提出了选择敏感性（$\bar{Q}$）这一度量，它捕捉了自适应选择策略在训练数据扰动下的响应情况。通过广泛的实验，证明了这种理论关系在实践中也确实成立。", "conclusion": "研究表明，高度自适应的选择策略如基于梯度选择和课程学习能取得更好的任务性能，但错误再现率较高。相比之下，较不自适应的方法则保持了低于7%的错误再现率。本文显示，源领域预训练能显著降低错误再现率，最多降低30%，同时保留性能收益。这些发现为在性能与再现性之间的权衡中提供了一套原则性指南，并突出强调了现代知识迁移系统中需要考虑再现性意识的设计。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL: 通过熵机制平衡LLM测试时强化学习中的探索和利用", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "大型语言模型在数学和编程等复杂推理任务上的表现有所提升，但仍然高度依赖标注数据，并且在无监督场景中表现出有限的适应性。", "innovation": "提出了熵为基础的机制以增强测试时强化学习中的探索与利用的平衡。通过两种策略——熵分支树多数游程（ETMR）和基于熵的优势重塑（EAR），解决了高推理成本和早期阶段估计偏差的问题。", "conclusion": "该方法使Llama3.1-8B在AIME 2024基准测试上Pass at 1指标相对提高了68%，同时仅消耗了60%的游程标记预算。这一结果展示了该方法在推理效率、多样性以及估计稳健性之间的有效权衡，从而推动了开放式推理任务中的无监督强化学习的发展。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器中的量化神经网络：方法、平台与应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "在资源受限的设备（如微控制器）上部署量化神经网络（QNNs）带来了在模型性能、计算复杂性和内存约束之间的平衡挑战。微型机器学习（TinyML）通过结合机器学习算法、硬件加速和软件优化的进步，解决了这些问题，旨在高效地在嵌入式系统中运行深度神经网络。这篇文章提供了一个硬件为中心的量化介绍，并系统地回顾了用于嵌入式应用的加速深度学习模型的量化技术。文章特别强调了模型性能与硬件能力之间的关键权衡。", "innovation": "文章提供了一个硬件为中心的量化神经网络介绍，全面回顾了用于嵌入式应用的加速深度学习模型的量化技术，特别强调了模型性能与硬件能力之间的权衡。此外，文章分析了现有支持QNN在微控制器上执行的软件框架和硬件平台，提出了当前面临的挑战和未来发展的潜在方向。", "conclusion": "文章对快速发展的量化神经网络部署领域进行了分析，并概述了未来的发展方向。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "科学可解释推理网络（ScIReN）：在碳循环中及其他领域发现隐藏的关系", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对减缓气候变化至关重要。尽管土壤有潜力从大气中吸收碳并固存碳，但土壤碳循环仍不完全理解。基于现有知识的数学过程模型存在许多未知参数，需要随意设定，并且往往不适合观察数据。另一方面，神经网络可以从数据中学习模式，但它们不遵守已知的科学定律，而且由于其黑盒性质，不能揭示新的科学关系。因此，该研究提出了一种完全透明的框架——科学可解释推理网络（ScIReN），它结合了可解释的神经网络和过程推理模型。ScIReN 利用Kolmogorov-Arnold网络（KAN）确保编码器是完全可解释的，揭示输入特征与潜在参数之间的关系；它还使用新的平滑惩罚来平衡表达能力和简洁性。ScIReN 使用新型的硬Sigmoid约束层来限制潜在参数的范围，符合科学先验知识的定义。", "innovation": "ScIReN 借助KAN确保编码器具有完全的可解释性，揭示潜在参数与输入特征之间的关系；使用新的平滑惩罚来平衡表达能力和简洁性；采用新型的硬Sigmoid约束层来确保潜在参数在科学先验知识定义的范围内。同时，过程解码器遵守已知的科学知识，而KAN基于的编码器揭示了传统黑盒模型中隐藏的新科学关系。ScIReN 在模拟有机碳在土壤中的流动和植物生态呼吸建模任务中，相比传统黑盒网络，具有更高的预测准确性并提供了实质性的科学可解释性——它能够推断潜在的科学机制及其与输入特征之间的关系.", "conclusion": "ScIReN 成功地在碳循环研究中提供了更高的预测准确性和重要的科学解释性。它不仅能提高模型的准确性，还能揭示新的科学关系，帮助我们更好地理解碳循环机制。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 为评价大规模语言模型在凝聚态物理中的表现设定基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "当前，大语言模型（LLMs）在应对其他领域（如自然语言处理）的挑战方面表现出色，但在特定科学领域的复杂问题解决能力仍需进一步评估。特别是在凝聚态物理学这样的深度和广度都很高的科学领域，现有模型的能力并不充分知晓。因此，研究者们需要一个有针对性的基准来评估LLMs在凝聚态物理学的实际应用能力。", "innovation": "CMPhysBench 是第一个专门为评估LLMs在凝聚态物理学认知能力而设计的基准。它包含了超过520个精心挑选的研究生层级问题，覆盖了磁性、超导性和强相关系统等物理子领域及一些基本理论框架。为了深入评估问题解决过程，CMPhysBench 要求LLMs独立提供全面的解决方案。该基准还引入了基于表达树表示的可扩展表达式编辑距离（SEED）评分，在提供细致的非二元部分评分基础上，更准确地评估预测与真实值之间的相似度。", "conclusion": "在CMPhysBench基准测试下，即使是最好的模型，如Grok-4，也只能得到36的平均SEED分数和28%的准确率，显示出与传统物理学相比，在凝聚态物理学这种具有实际意义且前沿的领域中，现有的LLMs的能力差距显著。这对于进一步完善LLMs的认知能力和应用范围具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15593", "html_url": "https://arxiv.org/abs/2508.15593", "title": "在规定拟似仿真推理中的归纳领域转移", "title_en": "Inductive Domain Transfer In Misspecified Simulation-Based Inference", "authors": "Ortal Senouf,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard", "background": "统计推理方法（SBI）用于估计物理系统中的潜在参数，但在实际操作中，SBI通常受到模型不匹配的影响，这是因为模拟与现实世界观察之间的不一致，这种不一致是由模型简化内在特性导致的。RoPE 是一种最近的 SBI 方法，利用半监督校准和基于最优传输的分布对齐来解决这一挑战。然而，RoPE 仅限于完全归因于样本的推理设置，这意味着在推断时需要一批测试样本，这限制了其扩展性和泛化。", "innovation": "本文提出了一种在推断时不需仿真访问的完全归纳和可变 SBI 框架，将校准和分布对齐整合到单个、端到端可训练的模型中。该方法使用与相同潜在参数对应的配对校准数据和未配对样本，结合最优传输的闭合形式耦合对实际和模拟观察进行对齐。然后训练有条件归一化流逼近最优传输诱导的后验，从而在测试时无需仿真即可高效推断。该方法在多种合成和现实世界基准测试中（包括复杂的医疗生物标志物估计）表现良好，与 RoPE 及其他标准 SBI 和非 SBI 估计方法的性能相当，同时提供了更好的可扩展性和在复杂、模型不匹配环境中的适用性。", "conclusion": "通过整合校准和分布对齐，提出的方法能够克服模型不匹配问题，在推断时不依赖于模拟，适应各种挑战性环境。该研究方法不仅提高了 SBI 的性能，还使其在更广泛的条件下具有更好的可扩展性和适用性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG: 在图上的公平删除", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着隐私法规的关注日益增加，机器遗忘技术在社交网络和推荐系统等实际应用中变得越来越重要，这些系统通常以图形的形式存在。然而，现有的图遗忘方法通常会无差别地修改节点或边缘，忽略了它们对公平性的影响。例如，忘记不同性别用户之间的链接可能会无意间加剧群体间的差异。为了应对这一问题，我们提出了一种新的框架，该框架同时优化图结构和模型以实现公平的遗忘。", "innovation": "我们的方法通过去除妨碍遗忘的冗余边缘，并通过针对性地增加边缘来维护公平性，重新构建了图结构。此外，我们引入了一种最坏情况下的评估机制，以在更具挑战性的场景中评估鲁棒性。实验结果表明，我们的方法在实现有效且公平的遗忘方面优于现有方法。", "conclusion": "实验结果证明，我们的方法在实况数据集上的有效性和公平性都优于现有基线。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker：使用控制标记赋予LLM预算意识推理的能力", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大型语言模型（LLMs）通过增加推理时间的计算量来提升推理能力，这虽然是有效的，但会导致严重的延迟和资源成本，限制了这些模型在实际时间受限或成本敏感场景中的应用。", "innovation": "本文提出了BudgetThinker框架，它通过在推理过程中定期插入特殊控制标记来告知模型剩余的令牌预算，从而使得LLM能够进行预算意识推理。该方法结合了监督微调（SFT）和基于课程的强化学习（RL）阶段，前者使模型熟悉预算约束，后者通过长度感知的奖励函数优化模型的准确性和预算遵守情况。研究证明了BudgetThinker在各种推理预算下在复杂数学基准测试上显著优于其他基准。", "conclusion": "BudgetThinker提供了一种可扩展且有效的方法，以使先进的模型能够在资源受限和实时环境中实现高效可控的推理，从而增加高效率模型的部署可能性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型进行大肠3D形状细化以生成数字模型", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的三维建模对构建虚拟成像实验中的数字模拟物至关重要。然而，由于其复杂的几何结构和形状变异，大肠等器官仍然是建模中的挑战。现有的建模方法在形状建模精确度上存在不足。", "innovation": "作者提出了一种名为CLAP的新型条件潜点扩散模型，将几何深度学习与去噪扩散模型相结合，用于增强大肠的三维表示。该模型通过层次变分自编码器学习全局和局部的潜形状表示，并在潜空间中使用两组条件扩散模型细化器官形状。最后，使用预训练的表面重建模型将细化后的点云转换为网格。", "conclusion": "CLAP显著提高了形状建模精度，相对于初始不理想的形状，减小了共计26%的切比雪夫距离和36%的哈乌福距离。此方法提供了一种稳健且可扩展的高保真器官建模解决方案，适用于广泛的解剖结构。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19352", "html_url": "https://arxiv.org/abs/2508.19352", "title": "图神经网络中的记忆现象", "title_en": "Memorization in Graph Neural Networks", "authors": "Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch", "background": "深度神经网络（DNNs）已被证明具有记忆其训练数据的能力，但对于图神经网络（GNNs）的研究仍相对较少，特别是关于标记记忆的分析。本文通过引入NCMemo（节点分类记忆）框架，首次定量评估半监督节点分类中的标签记忆现象，并探讨了记忆与图同质性之间的关系，同时分析了GNNs在训练过程中的动力学特性，指出结构信息在低同质性图中较少有效，进而导致对节点标签的记忆。", "innovation": "首次提出了NCMemo框架来量化图神经网络中的标签记忆现象；揭示了图同质性与记忆之间的逆相关关系；展示了结构信息对于低同质性图的重要性及其对GNNs的影响；提出了通过图重布线来减少记忆现象的方法，并证实了其有效性和隐私保护优势。", "conclusion": "本文不仅深化了对GNNs学习机制的理解，还为更隐私保护的GNN部署提供了支持。通过重新布图的方法，显著减少了记忆现象，同时保持了模型性能，并降低了已记住数据点的隐私风险。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: 向更高效和强大的持续学习框架迈进", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "持续学习（CL）要求在执行新任务时保持对过去知识的记忆，这一过程需要在任务敏感性和保持已有知识之间达到平衡。尖锐性感知最小化在迁移学习中已经显示出有效性，并被引入到持续学习中以提高记忆保持和学习效率，但仅依赖于零阶尖锐性可能会在某些情况下偏好更尖锐的极小值，从而导致不稳健且可能不理想的解决方案。基于此背景，本文提出了C-Flat方法，通过定制更为平坦的损失景观来解决这一问题。", "innovation": "C-Flat 提出了一种促进更为平坦的损失景观的方法，以适应持续学习的需求。C-Flat 兼容性高，便于集成且需要少量的代码修改。同时，该研究提出了一种通用框架，将 C-Flat 集成到持续学习的所有主要范式中，并进行了与损失极小优化器和基于平坦极小值的持续学习方法的全面对比。C-Flat++ 进一步提高了 C-Flat 的效率，通过选择性地促进平坦性，大大减少了所需的更新成本。这些方法在多个持续学习方法、数据集和场景中进行了广泛的实验验证，证明了其有效性和效率。", "conclusion": "C-Flat 和 C-Flat++ 在多种持续学习设置中展示了稳定和持续改善性能的效果，这表明它们在持续学习中的潜在应用价值。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20330", "html_url": "https://arxiv.org/abs/2508.20330", "title": "FORGE: 依赖图嵌入的基础优化表示", "title_en": "FORGE: Foundational Optimization Representations from Graph Embeddings", "authors": "Zohair Shafi,Serdar Kadioglu", "background": "组合优化问题在科学和工程中普遍存在，然而，基于学习的方法往往需要解决大量难以解决的优化实例来收集训练数据，这带来了显著的计算开销。现有方法需要为每个问题分布为每个下游任务训练专用模型，严重限制了其可扩展性和泛化能力。", "innovation": "我们提出了一个名为Forge的方法，预训练一个矢量量化图自编码器，不依赖于其解决方案，在未监督的情况下对大规模和多样的混合整数编程（MIP）实例进行处理。矢量量化过程生成离散的代码分配，这些代码作为词汇库来表示优化实例。Forge方法在监督和未监督的条件下都进行了评估，展示了其对未见实例的有效区分和聚类。在监督设置下微调Forge嵌入后，我们的方法能够预测多种问题类型的分布中的变量用于预热和整数隙的距离生成所需要的切割生成，这两项预测均有助于优化商业优化求解器的表现。", "conclusion": "最后，我们发布了Forge的代码和预训练权重，旨在促进进一步的研究和具体的应用于MIP实例嵌入的实用性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.02592", "html_url": "https://arxiv.org/abs/2401.02592", "title": "非凸因子化方法在张量列车恢复中的保证", "title_en": "Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery", "authors": "Zhen Qin,Michael B. Wakin,Zhihui Zhu", "background": "本文探讨了张量分解方法在避免缩放模糊性和便于理论分析方面的重要性。以往对于张量分解的研究通常缺乏收敛保证，而本文为此提供了首个收敛保证。具体来说，作者通过优化所谓的左正交TT格式来解决张量分解问题，这种格式强制大部分因子保持正交性。为了确保正交结构，作者使用了黎曼梯度下降（Riemannian Gradient Descent，RGD）来在Stiefel流形上对这些因子进行优化。", "innovation": "主要创新之处在于：1）首次提出了张量分解的收敛保证；2）通过使用左正交TT格式和黎曼梯度下降来优化张量因子，避免缩放模糊性；3）证明了在满足稀疏保持性质（ Restricted Isometry Property, RIP）的传感操作下，通过光谱初始化得到适当的初始值后，黎曼梯度下降能线性收敛至真实张量；4）在存在高斯噪声的测量场景下，理论上证明了黎曼梯度下降可以可靠地在细分误差下线性收敛至真实张量。", "conclusion": "本文通过黎曼梯度下降对张量进行了优化，并证明了其即使在测量包含高斯噪声的情况下，也能够可靠地恢复真实张量，收敛速率为线性。实验结果验证了理论分析的正确性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "在大型语言模型中揭示精细粒度的价值和观点", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "在大型语言模型（LLMs）中发掘潜在的价值和观点可以帮助识别偏见并减轻潜在的危害。目前，这通常通过向LLMs提出调查问卷问题并量化其输出中对道德和政治问题的立场来实现。然而，由LLMs生成的立场取决于它们的提示方式，且对于同一立场存在多种争论方式。", "innovation": "该研究提出了一个全新的方法，通过分析62个政治倾向测试（PCT）命题的156k个LLM响应，使用6种不同的LLM和420种提示变体，进行粗粒度和细粒度的分析。在细粒度分析中，他们提出识别回文（tropes）：在不同提示中频繁出现且语义相似的短语，揭示LLM易于生成的自然模式。研究发现，提示中添加的人口统计特征显著影响了PCT的结果，反映了偏见，以及在获取闭形式答案和开放领域答案时测试结果之间的差异。", "conclusion": "实体模式（tropes）在简洁地说服文本中的模式表明，在不同模型和提示下，具有不同立场的模型生成相似的论证。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM：使用概率编程的机器人不确定操纵中的因果贝叶斯推理架构", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人在进行操作任务时需要推断因果关系，以有效与物体交互。然而，大多数数据驱动的方法缺乏因果语义，只考虑相关性，这限制了它们在不确定环境中操作的应用效果。", "innovation": "提出了一种新型的因果贝叶斯推理架构COBRA-PPM，结合了因果贝叶斯网络和概率编程，用于在不确定性下的机器人操作进行间断推理。利用高保真Gazebo实验展示了其能力，准确预测操作结果，并通过选择贪婪的下一步行动实现94.2%的任务成功率。同时，进一步展示了在家庭机器人上的物理转移能力，能够处理来自传感器噪声和随机操作的真实世界不确定性。", "conclusion": "通用且可扩展的框架支持广泛的操纵场景，为机器人与因果关系领域未来的交叉工作奠定了基础。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "稳健性很重要：LLM在数据分析拟合中的局限性", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）已在多种场景中得到应用，远超传统的语言处理领域。这些模型尤其被用作插件式方法来适应数据并生成预测。以往的研究表明，LLMs通过上下文学习或监督微调，在预测性能方面可以与许多表格监督学习技术竞争。然而，作者识别出用LLMs进行数据拟合的一个关键弱点：对与基本学习任务无关的数据表示进行修改会极大地改变LLMs在相同数据上的预测结果。例如，仅仅更改变量名就可能使预测误差增加82%。此外，这项工作还揭示了LLMs在面对与任务无关的变化时的敏感性，并且这种敏感性不仅出现在上下文学习中，也存在于监督微调中。因此，尽管LLMs在预测方面表现出色，但它们在鲁棒性方面仍然不足，无法像一个有原则的数据拟合工具那样使用。", "innovation": "该研究发现，对与任务无关的变量进行修改会显著影响LLMs的预测结果，并通过分析注意力分数揭示了LPMM的注意力模式存在非均匀性。这解释了在面对与任务无关的变化时的敏感性。此外，研究还比较了专门培训用于数据拟合的表格基础模型（TabPFN），尽管该模型旨在提高预测稳定性，但它仍无法抵御与任务无关的变化。这些发现揭示了LLMs在数据拟合方面的局限性。", "conclusion": "尽管LLMs在预测性能上令人印象深刻，但它们仍然缺乏基本的鲁棒性，不能作为数据拟合的有原则工具。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.12968", "html_url": "https://arxiv.org/abs/2306.12968", "title": "在标记随机块模型中重新审视实例最优聚类恢复", "title_en": "Revisiting Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model", "authors": "Kaito Ariu,Alexandre Proutiere,Se-Young Yun", "background": "本文研究了标记随机块模型（LSBM）中隐藏社区恢复的问题，该模型具有数量增长与节点总数成线性的有限数量的簇。提出了实现预期性能和高概率性能与实例特定下界匹配的第一个算法——IAC（实例自适应聚类）。", "innovation": "IAC是一种新颖的两阶段算法，包括一次光谱聚类步骤，随后是迭代的可能性基于聚类分配改进。该方法基于实例特定下界，并且不需要模型参数（包括簇的数量）的知识。通过仅进行一次光谱聚类，IAC保持了整体计算复杂度为O(n·polylog(n))，使其在大规模问题中可扩展且实用。", "conclusion": "IAC算法在预期意义上匹配了实例特定的下界，并且在高概率下也实现了这一匹配。这种算法的有效性和适用性使得它在大型问题中具有实际应用价值。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05762", "html_url": "https://arxiv.org/abs/2506.05762", "title": "BiTrajDiff: 双向轨迹生成的扩散模型在离线强化学习中的应用", "title_en": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "authors": "Yunpeng Qing,Shuo Chen,Yixiao Chi,Shunyu Liu,Sixu Lin,Kelu Yao,Changqing Zou", "background": "离线强化学习(RL)的研究表明，通过在预收集的数据集上施加保守约束，可以提高政策学习的有效性。然而，这些静态数据集通常存在分布偏差，限制了它们的泛化能力。传统的数据增强(DA)方法专注于从给定状态重建未来轨迹，而忽略了探索导致这些状态的历史轨迹，这限制了多样行为模式的发现，特别是那些可能导致高奖励的轨迹。", "innovation": "BiTrajDiff框架通过将轨迹生成任务分解为两个独立但互补的扩散过程：一个是生成前向轨迹以预测未来动态，另一个是生成后向轨迹以追踪关键历史轨迹。这种双向方式能够更有效地利用关键状态作为锚点，扩展到状态空间中潜在有价值且未充分探索的区域，从而提高数据集的多样性。", "conclusion": "在D4RL基准测试集上的广泛实验表明，BiTrajDiff在多种离线RL基线中表现出优越的性能，优于其他先进的数据增强方法。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "连续的语言模型插值以实现动态可控的文本生成", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "大语言模型（LLMs）因其在多种应用场景中的流行，其适应性和可控性变得尤为重要，尤其是在面向用户的应用中。目前关于LLM适应性的研究主要集中在找到优化单一预定义目标的模型，而本研究则专注于模型可以动态适应多种且经常变化的用户偏好这一更具挑战性的情况。", "innovation": "本研究利用基于线性权重插值的适应方法，将其视为连续多域插值器，可实时生成具有特定生成特性的一系列模型。通过低秩更新对基础模型进行微调，产生具有不同生成特征的锚模型集。然后使用这些锚模型的权重更新来参数化它们凸壳内的整个（无限）模型类别。实验结果表明，变化插值权重可以Predictable且Consistently改变模型输出方面所有控制属性。本研究发现大多数属性之间的关系不紧密，并且讨论了那些关系不紧密的属性对。研究结果表明线性插值微调模型的权重有利于Simultaneously对多个风格特征实现可预测的、精细的控制", "conclusion": "研究表明，通过线性插值微调模型的权重能够实现对模型输出的可预测、细粒度控制，针对多种风格特征同时进行控制。同时，研究还强调了绝大多数属性之间的关系不紧密，这对于理解和发展更高级的语言模型控制方法具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12367", "html_url": "https://arxiv.org/abs/2403.12367", "title": "基于政策相关观察研究中协变量重要性的学习匹配方法", "title_en": "Learning covariate importance for matching in policy-relevant observational research", "authors": "Hongzhe Zhang,Jiasheng Shi,Jing Huang", "background": "匹配方法在减少观察研究中的混杂影响方面得到了广泛应用。然而，传统的匹配方法往往将所有协变量视为同等重要，这在协变量的重要性差异较大时会导致性能不佳。因此，论文提出了一种名为PAMA的新型半监督框架，这种框架通过从专家配对的数据集中的子集学习协变量的重要性度量，并使用它来匹配额外的单位。PAMA优化了一个加权二次分数，该分数反映了每个协变量与研究的相关性，并且使用未标记的数据迭代更新得分函数中的协变量重要性度量。该方法在数据标签不足的情况下仍然表现出良好的一致性，且能够处理不平衡数据、适应时间协变量，并增强对误配观察的鲁棒性。在模拟中，PAMA在高维设置和模型误设的情况下优于标准方法，并通过实际研究证明了其优异的表现，尤其是利用基线协变量能够恢复更多专家指定的匹配。另外，PAMA还提出了一种自我学习拓展，尽管在某些上下文中其收益取决于具体情境。", "innovation": "PAMA是一个基于半监督学习的框架，首次应用于具有不同相关性的协变量的匹配方法中。通过从专家配对的数据集学习协变量的重要性，并利用此度量进行匹配，PAMA能够在混杂因素不同的协变量中提供更加有效的匹配。此外，PAMA还引入了处理不平衡数据、时间协变量以及改进对误配观察的鲁棒性的方法。通过引入自我学习的扩展方法进一步提升模拟中的性能，尽管其效果在不同情境下有所差异。", "conclusion": "PAMA能够提供一个可扩展且可解释的工具，用于在政策相关性的观察研究中融入专家见解。该方法能够显著提高匹配的质量，尤其是在真实世界的应用中，PAMA能比竞争对手恢复更多的专家指定匹配。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19779", "html_url": "https://arxiv.org/abs/2410.19779", "title": "BrainGPT：通过自回归预训练释放EEG通用基础模型的潜力", "title_en": "BrainGPT: Unleashing the Potential of EEG Generalist Foundation Model by Autoregressive Pre-training", "authors": "Tongtian Yue,Xuange Gao,Shuning Xue,Yepeng Tang,Longteng Guo,Jie Jiang,Jing Liu", "background": "脑电图（EEG）信号对于揭示自发脑活动至关重要，在神经科学研究中具有重要意义。然而，EEG模型的研究受限于多样化的数据格式、过时的预训练方法以及有限的迁移学习方法，只能用于单一数据集，只有专门化的模型。", "innovation": "文章引入了EEGPT，这是一种通用的EEG基础模型，旨在解决上述挑战。文章提出了电极级建模策略，将每个电极视为基本单位，用于集成最多138个电极的多样化EEG数据，积累了37.5M预训练样本。同时开发了第一个自回归EEG预训练模型，采用信号预测任务代替传统的掩码自编码器方法，以更好地捕捉EEG数据的时序和顺序关联。此外，通过模型扩展到1.1B参数，成为迄今为止EEG研究中最大的模型。该工作还引入了可学习的电极图网络多任务迁移学习范式，有效确认了多任务兼容性和协同效应。", "conclusion": "EEGPT展示了广泛的操作兼容性，适用于各种信号采集设备、参与者和任务，支持最多138个电极的任何组合作为输入。在12个基准上进行的5种不同任务的评估表明，EEGPT在所有下游任务上都优于现有专有模型，并通过广泛的消融研究进一步验证了其有效性。该工作为通用EEG建模设置了一个新方向，提供了更好的可扩展性、可迁移性和适应性，适用于多种EEG应用。代码和模型将公开发布。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "矩形注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "现有的卷积网络通常在注意力机制上采用位置方式生成空间注意力图，但这种方式往往导致边界不规则，影响新样本的泛化能力。本文通过引入一个新的空间注意力模块，引导模型关注图像中最具区分性的部分，从而实现更好的端到端训练性能。", "innovation": "本文的创新在于设计了一个矩形注意力模块，该模块参数化为只有5个参数的矩形区域，限制了注意力区域为矩形，使得模型在处理图像时更稳定，并且在新样本上有更好的泛化能力。实验结果表明，该方法系统地优于位置方式的同类方法。除此之外，该模块还提供了关于'看向哪里'的问题的可解释性，因为它有助于了解模型在产生预测时关注的部分输入。", "conclusion": "本文提供了一个新颖且有用的卷积模型空间注意力机制，并通过矩形注意力模块提高了模型的性能和解释性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.13098", "html_url": "https://arxiv.org/abs/2404.13098", "title": "使用线性规划的自字典方法进行高光谱图像端元提取", "title_en": "Endmember Extraction from Hyperspectral Images Using Self-Dictionary Approach with Linear Programming", "authors": "Tomohiko Mizutani", "background": "高光谱成像技术在森林管理、矿物资源勘探和地球表面监测等多领域有广泛应用。端元提取作为该技术的关键应用之一，旨在识别观测场景中材料的光谱特征。虽然已有理论研究表明，通过使用线性规划（LP）的自字典方法——Hottopixx方法——能够在端元提取上取得有效成果，但其实际应用受到了高计算成本的制约，因为当处理的像素数目增加时，需要解决的LP问题规模也将平方地增加。", "innovation": "本文提出了一种改进的Hottopixx实现方法，旨在减少计算时间并提高端元提取性能。实验结果展示了其有效性，证明了该方法能够应用于实际的高光谱图像端元提取中，并能较为准确地估算出端元光谱特征。", "conclusion": "通过实施改进的Hottopixx方法，能够有效进行实际高光谱图像的端元提取，并实现较高的端元特征估计准确性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "机器人运动中的体态扩张定律朝着何方？", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "跨体态泛化是构建任何机器人泛化体态智能的基础愿景，但其使能因素仍不甚清楚。本文通过研究体态扩张定律，探讨增加训练体态的数量是否能提升对未见过的体态的泛化能力，以机器人的运动作为实验平台。通过生成约1000个具有拓扑、几何和关节级运动学变化的体态，训练不同的政策，并观察到支持该假设的积极扩展趋势，发现体态扩张比在固定体态下扩展数据更能广泛地泛化。", "innovation": "本文通过生成约1000个不同类型的机器人体态，并在随机子集中训练政策，观察到了体态扩展对泛化的积极影响，并且在完整的数据集上训练的最优策略在仿真和实际环境中实现了对新型体态的零样本转移，包括UniteGo2和H1等机器人。", "conclusion": "这些结果朝着通用体态智能迈出了一步，并对可配置机器人的自适应控制、形态协同设计等具有重要意义。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12000", "html_url": "https://arxiv.org/abs/2504.12000", "title": "湍流相变的控制: 强化学习的有效性研究", "title_en": "Control of Rayleigh-Bénard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime", "authors": "Thorben Markmann,Michiel Straat,Sebastian Peitz,Barbara Hammer", "background": "数据驱动的流控制在工业、能源系统和气候科学等领域具有巨大的潜力。本文研究了在增加湍流的情况下，强化学习（RL）对于减少二维雷诺-本华德对流（RBC）系统对流传热的有效性。", "innovation": "本文提出了一种奖励塑造技术来加速训练，并将单智能体Proximal Policy Optimization (PPO)训练的RL智能体与经典控制理论中的比例-微分（PD）控制器进行了比较。结果表明，即使在高度湍流环境中，RL智能体也降低了高达33%的对流传热，显著优于PD控制。此外，所训练的RL智能体在不同初始条件下的泛化性良好，并能在较大湍流程度下泛化。", "conclusion": "强化学习在湍流环境中控制对流传热方面表现出色，并且无论初始条件如何，都能显著降低对流传热，尤其是在中等至高度湍流的情况下表现更优。奖励塑造技术提高了样本效率，令Nusselt数在高湍流条件下更加稳定。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解任意视频中的相机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "本文介绍了CameraBench，这是一个包含约3000个多样化互联网视频的大规模数据集和基准，旨在评估和提升相机运动的理解能力。这些视频由专家通过严格的多阶段质量控制过程进行标注，并且论文中提出了一种与电影摄影师合作设计的相机运动元分类体系。研究表明，某些运动，如“跟随”或追踪，需要理解场景内容中的移动主体。", "innovation": "论文的创新之处在于提出了一种相机运动元分类体系，并通过大规模的人类研究量化人类注释的表现，表明领域专业知识和基于教程的训练可以显著提高准确性。此外，论文通过CameraBench评估了结构从运动（SfM）和视频-语言模型（VLM），发现SfM模型难以捕捉依赖场景内容的语义原素，而VLM则难以捕捉需要精确估计轨迹的几何原素。研究还对生成VLM进行了Fine-tune，并展示了其在包括动作增强说明、视频问答和视频-文本检索等领域的应用。", "conclusion": "我们希望我们的分类体系、基准和教程能够促进未来努力，以实现理解任何视频中相机运动的终极目标。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导是用于增强扩散模型样本质量的广泛使用的技术。从技术上讲，这是通过使用一个比主要模型泛化能力更强的辅助模型来实现的。本文使用2D玩具示例证明，当辅助模型表现出类似但更强的泛化误差时，其效果非常有益。基于这一发现，本文提出了一个新的、无需训练的方法——掩蔽滑动窗口指导（M-SWG）。M-SWG 通过有选择性地限制模型的感受野来加强长期空间依赖性，从而引导主要模型。该方法无需访问之前迭代的模型权重、额外训练或类别条件。与之前的所有无训练指导方法相比，M-SWG 在不引入样本饱和的情况下，实现了更高的 Inception 分数（IS），并且结合现有的指导方法，M-SWG 在使用 EDM2-XXL 和 DiT-XL 的 ImageNet 上达到了最新的 Frechet DINOv2 距离。\n", "innovation": "提出了一个新的、无需训练的方法——掩蔽滑动窗口指导（M-SWG）。该方法通过有选择性地限制主要模型的感受野来加强长期空间依赖性，从而提升指引效果，同时不需要额外的训练、访问模型权重或类别条件。该方法在不引入样本饱和的情况下，提高了 Inception 分数，并在结合其他引导方法时达到了最先进的 Frechet DINOv2 距离。特别是在使用 EDM2-XXL 和 DiT-XL 的 ImageNet 数据集上，M-SWG 达到了最好的成绩。\n", "conclusion": "掩蔽滑动窗口指导（M-SWG）实现了一个没有训练、不需要额外模型权重访问且不需要类别条件指导的新方法。它通过有选择性地限制模型的感受野，增加了模型对长期空间依赖性的敏感性。与其他现有的无训练方法相比，M-SWG 在 Inception 分数上表现出色，没有引入样本饱和，并且在结合其他引导方法时，结果达到了最先进的 Frechet DINOv2 距离，特别是在使用 EDM2-XXL 和 DiT-XL 的 ImageNet 数据集上。\n"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从朗道扩散稳定性到处理非对数凹分布的近似MCMC收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "在非凸势能背景下，考虑了非凸势能下的亚调整朗道算法（ULA）采样分布问题。背景中提到，在成像反问题等情境下，常用的势能往往是非凸且非平滑的。通常使用的算法如近似逐次梯度朗道算法（PSGLA）结合了逐次优化算法与朗道算法步骤，旨在处理这些非凸和非光滑的势能。当前，对于非凸势能的研究主要集中在收敛性问题上，缺乏有效的稳定性分析方法来处理此类问题。因此，该研究在此基础上，引入了基于势能稳定的朗道扩散稳定性定理，为进一步研究提出了新的思路和方法。", "innovation": "论文提出了将朗道扩散稳定性理论应用于近似逐次梯度朗道算法（PSGLA）中，并结合莫尔奥包络特性，首次证明了PSGLA在非凸势能下的收敛性。通过这种新的方法，可以更准确地分析和优化处理非凸势能的算法性能。此外，实验验证了在合成数据和成像反问题背景下，PSGLA相较于随机梯度朗道算法（SGLA）在后验采样方面具有更快的收敛速度，同时保留其恢复性能。", "conclusion": "该研究扩展了非对数凹分布采样问题的理解，并通过稳定性分析提供了一种新的算法收敛性证明方式。实验结果表明PSGLA在处理成像反问题中的非凸势能时具有更好的性能。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03796", "html_url": "https://arxiv.org/abs/2506.03796", "title": "Geeff: 普通优化框架与前端粒子加速器控制", "title_en": "Geoff: The Generic Optimization Framework & Frontend for Particle Accelerator Controls", "authors": "Penelope Madysa,Sabrina Appel,Verena Kain,Michael Schenk", "background": "全球各地的粒子加速器实验室正在研究机器学习技术以提高加速器性能和运行时间，这导致了多种方法和算法的出现。Geoff 的目的是将这些方法标准化，并减少在不同方法之间进行比较或迁移时的摩擦。它提供了一种标准化的优化问题接口、用于加速开发的实用函数以及将所有内容整合在一起的参考图形用户界面应用。", "innovation": "Geoff 提供了一个标准化的接口和实用函数，帮助用户在不同的方法和算法之间进行比较和迁移，同时提供了一个与该框架集成的参考图形用户界面应用。它是一个在 CERN 开发并由 CERN 和 GSI 共同维护和更新的开源库，是 EURO-LABS 项目的一部分。", "conclusion": "该论文概述了 Geoff 的设计、特性和当前的使用情况。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA: 一种治理AI智能系统安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "随着大型语言模型（LLM）驱动的代理自主交互、协作和任务委托的能力不断增强，人类干预的频率降低。当前的行业准则强调用户应当全面控制其代理，降低恶意代理可能造成的损害风险。尽管已有一些代理系统设计提出了解决代理身份、授权和委托的问题，但这些设计依然停留在理论层面，缺乏实际的实施和评估，特别欠缺用户能够控制代理管理功能的能力。", "innovation": "本文提出了SAGA（Security Architecture for Governing Agentic systems），一个可扩展性的安全架构，能够赋予用户对其代理的生命周期监控能力。SAGA的核心在于用户可以通过中央实体Provider注册其代理，Provider将维护代理联系信息、用户自定义的访问控制策略，并帮助代理在跨代理通信中执行这些策略。SAGA引入了一种加密机制用于生成访问控制令牌，这种机制可以对代理与其他代理的交互提供细粒度的控制，从而确保正式的安全性。通过在不同地理位置、多种设备和云环境下的LLM代理上对SAGA进行了测试，展示了几乎无性能损耗并且实际任务执行不受影响的结果。", "conclusion": "SAGA架构使自主代理的部署更加安全可靠，加快了这项技术在敏感环境中的负责任采用。实验结果表明，SAGA架构在各种条件下的性能开销极小，且不会影响基础任务的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "基于潜在自适应规划者在动态操作中的应用", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "研究提出了基于潜在自适应规划者（LAP）的新框架，用于动态非抓取性操控任务（例如接球）。该框架将规划问题表示为低维潜在空间中的推理问题，并且能够通过人类演示视频的有效学习实现。在执行过程中，LAP能够通过维护潜在计划的后验并进行变分重规划来实现实时自适应，从而应对新的观察结果。研究中提出了基于模型的比例映射模型，以重新生成准确的动力学关节状态和物体位置，进而跨越人类和机器人的体感差距。实验结果表明，LAP能够通过学习人类相似的顺应性运动和适应性行为，表现出更高的成功率，更平滑的轨迹和更高的能量效率.", "innovation": "该研究提出了一种新的潜在自适应规划者（LAP），将动态非抓取性操控任务的规划问题转化为低维潜在空间中的推理问题，并通过人类演示视频有效学习。LAP在执行过程中通过维护潜在计划的后验并进行变分重规划来实现实时自适应，同时引入基于模型的比例映射模型，能够精准再生动力学关节状态和物体位置，从而跨越人类和机器人的体感差距。实验结果表明，LAP能够显著提高操控成功次数、轨迹光滑度和能量效率，并成功地实现跨异构机器人平台的转移学习.", "conclusion": "潜在自适应规划者（LAP）通过从人类演示视频中学习， able to perform dynamic manipulation with real-time adaptation and achieve superior results in tasks characterized by varying object properties. This framework bridges the embodiment gap between humans and robots, enabling effective transfer of human-like behaviors across different robotic platforms. 实验结果证明了LAP在动态操控中的优势，能够实现实时适应，并且可以通过人类演示视频在不同机器人平台间实现有效的行为转移."}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions:借助CoTR提示和大规模语言模型的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "在低资源语言如马拉地语中进行情感识别具有挑战性，因为缺乏标注数据。现有研究面临的主要背景问题是如何有效利用有限的数据资源，特别是在标注数据稀缺的情况下，以提高情感识别的准确性。", "innovation": "提出了一种新颖的方法，即使用大型语言模型（LLMs）进行合成注释，并结合链式翻译（CoTR）提示技术构建了一个高质量的马拉地语情感识别数据集L3Cube-MahaEmotions。这种方法显著降低了数据标注的难度，同时确保了数据的质量和可靠性。该方法的创新点还包括利用通用大模型而不是特定领域的模型进行注释，并且展示了通用LLMs在复杂低资源情感识别任务中的优越性能。", "conclusion": "研究结果表明，高质量的人类标注数据和通用大模型优于微调的语言模型。这强调了高质量数据和模型在情感识别任务中的重要性。该研究为低资源语言的情感识别提供了一种新的验证方法和数据集，具有重要的应用前景。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07338", "html_url": "https://arxiv.org/abs/2507.07338", "title": "贝叶斯双重下降", "title_en": "Bayesian Double Descent", "authors": "Nick Polson,Vadim Sokolov", "background": "双重下降现象是过参数化统计模型中的一种现象。过参数化模型如深度神经网络在其风险特征中有重新下降的性质，这是一个近期机器学习中的现象，已有很多研究关注。随着模型复杂度的增加，存在一个传统的偏差-方差权衡的U形区域，但当参数数量等于观测数量，模型达到插值状态，风险变得无限大，然后在过参数化区域重新下降，这就是双重下降效应。", "innovation": "从贝叶斯视角重新审视双重下降现象，展示了具有自然贝叶斯解释的双重下降，说明它不违背传统的奥卡姆剃刀原理，即贝叶斯模型倾向于选择更简单的模型。开发了包括Dawid模型比较理论、Dickey-Savage结果以及与广义岭回归和收缩方法的联系在内的综合理论基础。用神经网络中的贝叶斯模型选择示例并详细讨论了无穷高斯均值模型和非参数回归。", "conclusion": "最后指出未来的研究方向。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "Deep Learning模型在体外受精胚胎选择中可解释性分析", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不孕不育严重影响个体的生活质量，社会心理层面均受波及。随着未来维持低生育率的情况预计加剧，体外受精(IVF)成为了经济发达国家中解决生育率低问题的主要手段之一。胚胎分级通常通过专业胚胎学家观察囊胚图像完成，这一过程耗时且效率不高。因此，研究提出了一种可解释的人工智能(XAI)框架，结合了卷积神经网络(CNN)和长短期记忆(LSTM)架构，用于提高胚胎分类的准确性和可解释性。", "innovation": "研究采用了一种名为CNN-LSTM的模型进行胚胎分类，通过深度学习技术提高了分类准确性，同时利用可解释的人工智能(XAI)工具保持了模型的可解释性。这一创新有助于提高IVF治疗过程中胚胎选择的效率和准确性。", "conclusion": "研究通过引入CNL-LSTM模型，提升了IVF治疗中胚胎选择的准确性和可解释性，有望在临床实际应用中提高人工胚胎选择的效率，为不孕不育患者提供更好的治疗方案。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05066", "html_url": "https://arxiv.org/abs/2508.05066", "title": "两种几何Jensen--Shannon发散的故事", "title_en": "Two tales for a geometric Jensen--Shannon divergence", "authors": "Frank Nielsen", "background": "几何Jensen-Shannon发散（G-JSD）由于其在高斯分布间的闭合形式表达式，在机器学习和信息科学中受到了广泛关注。这项工作旨在引入一种适用于正密度的替代定义的G-JSD，这种定义不进行几何混合的归一化，从而将其扩展到更广泛的情况，即正测度。", "innovation": "提出了一种不归一化的几何Jensen-Shannon发散定义，称为扩展的G-JSD，可以应用于更一般的正测度情况。进一步用Jeffreys发散和Bhattacharyya距离或系数表示G-JSD和扩展的G-JSD，并证明扩展的G-JSD是$f$-发散，满足信息几何中的可分性、信息单调性和不变性。在多变量高斯分布的情况下，给出了这两种G-JSD的闭形式公式。利用投影$\boldsymbol{\text{γ}}$-发散对两种类型的G-JSD进行了蒙特卡洛随机估计和近似。", "conclusion": "虽然JSD的平方根是一种度量距离，但这一性质对于两种类型的G-JSD不再成立。最后，解释了这两种几何JSD作为普通JSD正则化的意义。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10520", "html_url": "https://arxiv.org/abs/2506.10520", "title": "专家图的宏观图在大规模多任务推荐中的应用", "title_en": "Macro Graph of Experts for Billion-Scale Multi-Task Recommendation", "authors": "Hongyu Yao,Zijin Hong,Hao Chen,Zhiqing Li,Qijie Shen,Zuobin Ying,Qihua Feng,Huan Gong,Feiran Huang", "background": "在大规模多任务学习中，每个任务对应一个大规模的图结构，传统的多任务学习方法通常会忽略这些图结构，仅仅依赖于用户和项目的嵌入。然而，忽略这些图结构会导致性能提升的潜力被忽视，因此本研究提出了一个宏图专家（Macro Graph of Experts, MGOE）框架来解决这一挑战，该框架能够利用宏观图嵌入捕获任务特定的宏观特征，并建模任务特定专家之间的关联性，从而提供一种新的多任务学习方法，以利用图信息进行有效的学习和预测。", "innovation": "MGOE框架引入了宏图底（Macro Graph Bottom）的概念，这是首次允许多任务学习模型有效地整合图信息。MGOE还设计了宏预测塔（Macro Prediction Tower）来动态跨任务整合宏观知识。该研究不仅在大规模推荐系统中部署了该框架，还在三项公开基准数据集上进行了广泛的离线实验，对比了与最先进的多任务学习方法的优越性，从而证明了MGOE在大规模推荐系统中的突破性应用。此外，还通过在线A/B测试验证了MGOE在大规模推荐系统中的优势。", "conclusion": "MGOE框架作为一种新的多任务学习方法，通过利用图信息来整合宏观知识，建立了多任务图推荐的突破，证实了其在大规模推荐系统中的有效性，特别是提高了推荐性能和用户满意度。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程中的核心实践，用于系统地评估程序员或大型语言模型（LLMs）开发的程序。然而，编写全面的单元测试存在挑战，因此研究人员已经开始尝试利用LLMs自动进行测试生成。尽管如此，如何训练LLMs产出高质量的单元测试方法仍有待探索。", "innovation": "本文提出了UTRL（单元测试对抗强化学习），这是一种新的强化学习框架，能够通过对抗性训练方法（利用两个LLM：单元测试生成器和代码生成器，通过强化学习不断迭代训练）训练LLMs自动生成高质量的单元测试。这种方法让单元测试生成器优化生成能够暴露代码生成器错误的测试，同时让代码生成器优化通过单元测试的能力。", "conclusion": "实验表明，通过UTRL训练的Qwen3-4B生成的单元测试质量高于通过监督微调训练的人类编写的真实单元测试模型生成的测试。此外，UTRL训练的Qwen3-4B在生成高质量单元测试方面也优于GPT-4.1等前沿模型，突显了UTRL在训练LLMs进行这个任务的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20527", "html_url": "https://arxiv.org/abs/2508.20527", "title": "分子机器学习在化学过程设计中的应用", "title_en": "Molecular Machine Learning in Chemical Process Design", "authors": "Jan G. Rittig,Manuel Dahmen,Martin Grohe,Philippe Schwaller,Alexander Mitsos", "background": "近年来，分子机器学习（ML）在纯组分及其混合物的性质预测方面展现了巨大潜力，并且在探索新的分子结构的空间方面也有出色的表现。分子ML方法，如图神经网络和变换器，已在这一领域显示出广泛的应用前景。尽管分子ML在化学过程设计和优化中应用尚处于起步阶段，但其潜力巨大，有待进一步开发。", "innovation": "本研究深入探讨当前最先进的分子ML模型，展示了如何通过将物理化学知识整合到混合或物理指导的方式中，进一步深化ML方法的应用。本研究还提出利用分子ML在化学过程规模上的潜力，尤其是在过程设计和优化方面的整合应用，有望加速新型分子和工艺的识别过程。", "conclusion": "要实现这一目标，创建分子和过程设计基准，并实际验证提出的候选方案至关重要，可能需要与化学行业合作。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21454", "html_url": "https://arxiv.org/abs/2508.21454", "title": "使用大型语言模型增强指针分析的语义理解", "title_en": "Enhancing Semantic Understanding in Pointer Analysis using Large Language Models", "authors": "Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen", "background": "指针分析已经研究了四十年以上，但现有的框架仍然存在传播错误信息的问题。主要限制是由代码的不充分语义理解导致的，导致用户自定义函数的处理过于保守。近年来，大型语言模型（LLMs）的进步为解决这一问题带来了新的机会。", "innovation": "本文提出了一种新的增强模型LMPA（LLM增强指针分析），该模型将LLMs集成到指针分析中以提高精确性和可扩展性。LMPA能识别并正确建模类似于系统API的用户自定义函数，减少错误的调用上下文传播。此外，它通过对初始指向集进行推理，并采用结合自然语言的新型汇总策略来增强汇总分析。", "conclusion": "本文讨论了实现这种愿景所面临的 key challenges。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20723", "html_url": "https://arxiv.org/abs/2508.20723", "title": "在随机框架下的拼车个性化定价的自适应优化", "title_en": "Adaptive Optimisation of Ride-Pooling Personalised Fares in a Stochastic Framework", "authors": "Michal Bujak,Rafal Kucharski", "background": "拼车系统要想成功，必须提供具有吸引力的服务，即以可以接受的票价补偿乘客对时间的成本感知。由于乘客对时间价值存在显著差异，每位乘客都有自己的可接受价格，这未知于运营商。研究表明，通过学习乘客的个体接受水平，运营商能够在短时间内（10天内）以超过90%的准确率优化个性化定价。这种方法有助于根据乘客的期望逐步制定方案，从而吸引增长的用户需求。", "innovation": "本文提出了一种自适应定价策略，通过每天分析和调整票价，逐步满足乘客的需求并增加需求量。该策略使运营商能够通过理解和学习乘客的个别行为特点，优化服务质量，同时提高自身利润，还能去除无效率的拼车，专注于更具吸引力和利润的组合方式。", "conclusion": "通过了解乘客的行为特性，运营商不仅能够提升乘客（增加效用）也能提升自身的性能（增加收益）。这一策略还有助于去除无效的拼车，专注于更具有吸引力和利润的乘客组合。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20108", "html_url": "https://arxiv.org/abs/2508.20108", "title": "通过收益-波动性归一化提高股票价格数据中的分布偏移问题以实现准确预测", "title_en": "Mitigating Distribution Shift in Stock Price Data via Return-Volatility Normalization for Accurate Prediction", "authors": "Hyunwoo Lee,Jihyeong Jeon,Jaemin Hong,U Kang", "background": "股票价格预测吸引了学术界和业界的关注，因为它有望揭示复杂的市场模式并增强决策能力。然而，现有的方法往往无法有效处理分布偏移问题，主要侧重于标度或表示适应，而没有完全解决训练数据和测试数据之间的分布差异和形状不一致问题。", "innovation": "本文提出了一种名为ReVol的方法（返回-波动性归一化以缓解股票价格数据中的分布偏移）。该方法通过三种关键策略减轻这些偏移：（1）归一化价格特征以去除样本特定的特征，包括回报、波动性和价格规模；（2）使用注意力机制模块准确估计这些特征，从而减少市场异常的影响；（3）将样本特征重新整合到预测过程中，恢复在归一化过程中丢失的特征。此外，ReVol结合了几何布朗运动进行长期趋势建模和神经网络进行短期模式识别，从而结合了它们互补的优势。实验结果表明，ReVol在大多数情况下增强了最新基准模型的性能，在IC上平均提高了0.03，在SR上提高了超过0.7。", "conclusion": "本文提出的ReVol方法通过收益-波动性归一化显著提高了股票价格预测的准确性，特别是在处理分布偏移问题方面表现优异。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成进行模型驱动的量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "本文探讨了通过利用带有检索增强生成（RAG）管道的大型语言模型（LLMs）来进行模型到文本/代码转换的创新研究方向。特别是在量子和混合量子-经典软件系统中，模型驱动的方法可以帮助减少异质平台景观带来的成本和风险，以及开发者技能不足的问题。研究验证了其中一种提议的思想，即使用软件系统的UML模型实例生成代码，并使用Qiskit库在基于门或电路的量子计算机上执行生成的代码。部署的RAG管道中包含了来自公共GitHub存储库的示例Qiskit代码。实验结果显示，经过良好工程设计的提示可以将CodeBLEU得分提高四倍，从而生成更准确、更一致的量子代码。", "innovation": "提出了将大型语言模型和检索增强生成技术相结合，来驱动量子软件系统的模型到代码的转换研究方向。特别是利用RAG管道中的公共GitHub存储库中的Qiskit代码示例进行代码生成，并通过精心设计的提示提高了代码质量。研究还提出可以进一步探索以软件系统模型实例作为RAG管道的信息源，以及利用LLMs进行代码到代码的转换，比如编译使用情况等更多研究方向。", "conclusion": "验证了通过UML模型实例生成量子代码的想法，并展示了通过良好设计的提示可以显著提高代码质量。未来，可以通过进一步实验来探索其他研究问题和提出的想法，如将模型实例作为RAG管道的输入源和利用LLMs进行代码到代码的编译转换等。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21156", "html_url": "https://arxiv.org/abs/2508.21156", "title": "使用指令微调大语言模型实现自动Bug分类", "title_en": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "authors": "Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan", "background": "Bug分类在大型项目中常常缓慢且不一致。现有的方法难以高效地将新问题指派给开发者，研究者们尝试使用轻量级框架结合指令微调的大语言模型（LLM）以及候选约束解码来实现有效的指派，特别是在EclipseJDT和Mozilla数据集上的测试显示，尽管精确的Top-1准确率不高，但短名单质量（精度达到0.753）仍表现不错。特别是在最近的数据快照中，准确率显著提升，显示出在人类参与的实时过程中，该框架的潜力巨大。先前的研究表明，指令微调的LLM提供了一种快速且成本效益高的替代方案，相比需要大量特征工程和图基方法而言。", "innovation": "提出了一种使用指令微调大语言模型（LLM）的轻量化框架，该框架结合了LoRA适配器和候选约束解码策略，以确保有效的任务指派。这一创新点在于通过算法直接处理任务指派问题，而不需要复杂的特征工程和图基方法，从而提高了效率和准确性。", "conclusion": "实验结果表明指令微调的LLM提供了实现自动Bug分类的有效解决方案，这种方案可以显著提高大型项目中的Bug分派效率，尤其是在最近的数据快照表现突出，显示出该模型在人机结合的实时Bug分派系统中的潜力。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA：植物科学领域用于视觉语言模型基准测试的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA数据集是从广泛使用的PlantVillage图像库派生而来的大规模视觉问答(VQA)数据集。它旨在促进农业决策和分析中视觉语言模型的发展与评估。", "innovation": "该数据集包含193,609个高质量的问题-答案对，分布在55,448张图像和14种作物、38种病害条件上。问题按认知复杂度分为3个级别，9个不同类别，并通过基于模板的问答合成和多阶段语言重构的自动化两阶段管道生成。此外，数据集经过领域专家的迭代审查，确保科学准确性，并使用最先进的模型进行了质量评估。", "conclusion": "本研究旨在提供一个公开可用、标准化和经过领域专家验证的数据库，以提高植物疾病诊断的准确性并促进农业领域的科学研究。数据集将在以下网址开源：this https URL"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus: 自主合成谓词以提高导向 fuzzing 的效率", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向 fuzzing 的目标是找到导致指定目标程序状态的输入。它在系统调试、验证已报告的漏洞以及生成潜在漏洞利用等方面有着广泛的应用。然而，由于目标状态往往埋藏在程序深处，而由大量可能的程序输入组成的搜索空间又过大，这使得任务本身存在固有的挑战。现有方法依赖分支距离或手动指定的约束来指导搜索；但仅靠分支不足以精确描述接近目标状态的进度，而手动指定的约束通常为特定的漏洞类型量身定做，难以适用于不同的目标状态和程序。", "innovation": "我们提出了 Locus，一种新颖的框架以提高定向 fuzzing 的效率。我们的核心洞察是合成谓词以捕捉 fuzzing 的进展，作为通往达到目标状态的有意义的中间状态，起到里程碑的作用。通过将其用作 fuzzing 的程序仪器，它们可以拒绝不可能达到目标状态的执行，同时提供额外的覆盖率指导。为了自动化这一任务并适用于多种程序，Locus 配备了一个具有程序分析工具的自主框架，可以合成和迭代优化候选谓词，并通过符号执行确保谓词严格放宽目标状态，以避免误拒。", "conclusion": "我们的评估表明，Locus 在发现真实漏洞方面显着提高了八大先进 fuzzers 的效率，平均加速了 41.6 倍。迄今为止，Locus 已发现八个以前未补丁的漏洞，其中一个已经得到初步补丁的认可。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21553", "html_url": "https://arxiv.org/abs/2508.21553", "title": "强化学习可复用测试套件", "title_en": "Reusable Test Suites for Reinforcement Learning", "authors": "Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker", "background": "强化学习（RL）代理在解决序列决策任务方面显示出巨大的潜力。然而，在部署时验证代理策略行为的可靠性和性能仍然是一个挑战。目前大多数强化学习策略测试方法生成的测试套件都是根据特定测试对象定制的，它们与其他策略的相关性不清楚。本文提出了一种新的自动测试套件选择方法，即多策略测试案例选择（MPTCS）方法，该方法设计用于从任何策略测试框架中提取基于解算率、多样性的测试案例，以及通用难度的测试案例", "innovation": "MPTCS方法利用一组策略来选择一组具有多样性的、策略无关的可复用测试案例，这些测试案例揭示了代理行为中的常见缺陷。通过使用一个困难评分系统，该方法从候选池中根据难度选择测试案例，评估了困难评分的有效性，并研究了该方法的效果和成本如何取决于策略集的数量。此外，还研究了通过启发于质量多样性算法的离散化通用测试案例描述表面来促进测试套件的多样性，以确定其如何覆盖状态空间以及哪些策略触发了错误行为的产生", "conclusion": "测试集的有效性和成本取决于策略集的数量。作者还研究了如何通过离散化的通用测试案例描述表面来促进测试套件的多样性，以确定其如何覆盖状态空间以及哪些策略触发了错误行为的产生"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "大型语言模型（LLM）代理通过迭代推理、探索和工具使用来解决复杂的任务，但这一过程可能导致长时间和高昂的成本历史。顶级软件工程（SE）代理如OpenHands或Cursor使用LLM基础的总结来应对这一问题，但不清楚这种增加的复杂性是否能带来实际的性能优势。传统的策略是直接省略旧的观察数据，而现代的一个策略是通过LLM进行总结。这项研究旨在比较这两种策略在解决软件工程代理中的适用性，并在软件工程验证基准（SWE-bench Verified）上对五种不同的模型配置进行了系统性比较研究.", "innovation": "这项研究采取了系统性的方法来比较直接省略旧观察数据和通过LLM进行总结这两种策略在软件工程代理中的效果。研究发现，简单的观察数据掩蔽策略的成本比原始代理降低了50%，同时在解决率上与LLM总结策略相当甚至稍有超出。例如，使用Qwen3-Coder 480B模型，掩蔽策略将解决率从53.8%提升到54.8%，在成本较低的情况下保持了竞争力。", "conclusion": "至少在软件工程代理(SWE-bench Verified)的背景下，最有效和高效的上下文管理策略可能是最简单的。这项研究释放了可重复使用的研究代码和数据。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21289", "html_url": "https://arxiv.org/abs/2508.21289", "title": "使用持续集成解决HPC中的可再现性挑战", "title_en": "Addressing Reproducibility Challenges in HPC with Continuous Integration", "authors": "Valérie Hayot-Sasson,Nathaniel Hudson,André Bauer,Maxime Gonthier,Ian Foster,Kyle Chard", "background": "高性能计算（HPC）领域的研究者利用激励机制推动可再现研究。虽然许多会议会授予符合可再现性要求的论文奖励，但仍有许多论文未能达到这一标准。HPC基础设施和软件的特殊性及其严格的访问要求可能限制了可再现性的机会。在没有资源访问的情况下，认为通过持续集成（CI）进行定期文档化的测试并结合完整的原始记录信息可以作为补充手段。", "innovation": "提出了一种GitHub Action工具CORRECT，它可以安全地在远程HPC资源上执行测试，旨在解决现有限制并改进应用程序的可再现性，该工具适用于三种不同类型HPC应用的评估，展示了其有效自动化与文档化可再现性评估的能力。", "conclusion": "更好的HPC遵循CI解决方案将提高应用的可再现性。通过调查可再现性倡议并描述HPC中的障碍，提出并评估了CORRECT工具的有效性。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21634", "html_url": "https://arxiv.org/abs/2508.21634", "title": "人工编写代码 vs. 人工智能生成代码：缺陷、漏洞和复杂性的大规模研究", "title_en": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "authors": "Domenico Cotroneo,Cristina Improta,Pietro Liguori", "background": "随着AI代码助手在软件开发流程中的逐渐整合，理解它们的代码与人工编写程序的差异对于保证可靠性、可维护性和安全性至关重要。本文通过多维度的软件质量对比，评估了人编写和三种最先进的LLM（ChatGPT、DeepSeek-Coder和Qwen-Coder）代码的50万代码样本，涉及Python和Java两种广泛使用的编程语言，通过正交缺陷分类（Orthogonal Defect Classification）和通用弱点枚举（Common Weakness Enumeration）来分类缺陷和安全漏洞。", "innovation": "本文首次进行了大规模比较，评估了人工编写代码和三种先进LLM（ChatGPT、DeepSeek-Coder和Qwen-Coder）代码在多个软件质量方面的差异，涵盖了代码缺陷、安全漏洞和结构复杂性。研究发现AI生成的代码通常更简单、更重复，但更容易出现未使用的建构块和硬编码调试，而人工编写代码具有更高的结构复杂性和维护性问题的集中度。AI生成的代码还包含更多高风险安全漏洞。", "conclusion": "这些发现强调了人工编写代码和AI生成代码在缺陷特征上的显著差异，突显了在AI辅助编程中需要专门的质量保证实践。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21386", "html_url": "https://arxiv.org/abs/2508.21386", "title": "欧盟核心网络安全立法中的风险与合规性", "title_en": "Risks and Compliance with the EU's Core Cyber Security Legislation", "authors": "Jukka Ruohonen,Jesper Løffler Nielsen,Jakub Skórczynski", "background": "欧盟一直偏奔回避风险的监管方法，这种方法也应用于欧盟最近通过的网络安全法规中。这种法规与网络安全紧密相关，也直接影响合规性。", "innovation": "文章通过定性法律解释和分类构建的方法，探讨了欧盟五项核心网络安全立法中的风险框架，分析了这些立法中的风险概念是否趋于一致或分散，并且使用了哪些措辞来描述法律上的风险概念。研究发现了明显的技术方面和资产关联，同时也存在威胁中心的观点，值得注意的是，对可接受风险、非概率风险和剩余风险的差距。", "conclusion": "新的欧盟网络安全法规极大地扩展了规避风险的方法。同时，这种做法也带来了复杂性和合规负担的增加。文章最后提出了一些实现合规和进一步研究的实际建议。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21811", "html_url": "https://arxiv.org/abs/2508.21811", "title": "Agile 管理方法在信息技术行业中 DevOps 实践中的整合", "title_en": "The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry", "authors": "Ashley Hourigan,Ridewaan Hanslo", "background": "信息技术（IT）行业对快速软件发布的日益增长的需求强调了需要更快推出具有更多功能的软件产品和服务以满足客户期望。敏捷方法正在取代瀑布等传统方法，强调灵活性、迭代开发和适应变化，而非严格的规划和执行。DevOps 是从敏捷发展而来的进一步演变，强调开发和运营团队之间的合作，注重持续集成和部署以交付有弹性和高质量的软件产品和服务。本研究旨在批判性地评估敏捷和 DevOps 实践在 IT 行业中的运用，以确定敏捷方法在 DevOps 实践中的可行性和适用性。", "innovation": "研究通过半结构化访谈和主题分析，提取并归纳了51个独特的编码，形成了19个关于 DevOps 生命周期中各阶段的主题，特别是有关将敏捷方法整合到 DevOps 实践中的实证成果。研究提供了关于敏捷方法在 DevOps 实践中交互关系的新颖理解，以实现研究目标。", "conclusion": "研究讨论了关于敏捷方法在 DevOps 实践中的交互关系的新颖理解，旨在满足研究目标，并为进一步理解敏捷与 DevOps 之间的关系提供了经验证据。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21432", "html_url": "https://arxiv.org/abs/2508.21432", "title": "RepoMark：代码使用审计框架用于代码大规模语言模型", "title_en": "RepoMark: A Code Usage Auditing Framework for Code Large Language Models", "authors": "Wenjie Qu,Yuguang Zhou,Bo Wang,Wengrui Zheng,Yuexin Li,Jinyuan Jia,Jiaheng Zhang", "background": "近年来，大型语言模型（LLM）在代码生成中的快速发展已经极大地改变了软件开发领域。然而，这些模型在开源代码库（如GitHub）上进行训练时，引发了至关重要的伦理和法律问题，特别是关于数据授权和开源许可合规性。随着数据收集透明度的不足，开发者开始质疑模型训练者在使用这些代码库之前是否获得了适当的授权。", "innovation": "我们提出了一个新的数据标记框架RepoMark，旨在审计代码LLM的数据使用情况。该方法允许代码库所有者验证其代码是否被用于训练，并保证语义保真度、不可感知性和理论假发现率（FDR）的保障。通过生成多个语义等价的代码变体，RepoMark将数据标记引入代码文件，并在检测过程中使用一种新颖的排名基假设检验方法来检测模型内的记忆。相比以往的数据审计方法，RepoMark显著提高了样本效率，即使在用户的仓库拥有少量代码文件时也能进行有效的审计。", "conclusion": "实验结果表明，RepoMark在严格保证FDR为5%的情况下，对小型代码仓库的检测成功率超过90%，远高于同类现有的数据标记技术。这进一步验证了RepoMark作为提高代码LLM训练透明度的稳健、理论上可行且有前景的解决方案的有效性，有助于保护代码库所有者的权益。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "运用物联网和生成式人工智能进行气候适应性学习的天气适应性学习", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "随着气候变化的加剧，增强公众和专业人士的气候适应能力已成为一个关键问题。现有工具和技术在提供气候适应教育方面存在不足，例如，缺乏情境化和适应性强的学习体验，以及对实时环境数据的处理能力有限。", "innovation": "本文介绍了一种名为Future Atmospheric Conditions Training System (FACTS)的新颖平台。该平台结合了物联网传感器收集的实时大气数据和知识库中的资源，动态生成地方化的学习挑战，并利用生成式人工智能提供个性化反馈和支持。这一创新将物联网和生成式人工智能技术融入到气候适应学习中，有望提升教育参与度并增强气候意识。", "conclusion": "用户评价结果显示，参与者发现该系统易于使用且有助于构建气候适应相关知识。这表明，在气候适应性教育中整合物联网和生成式人工智能具有重要潜力，能够改善学习体验并提升用户对气候变化的理解和应对能力。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21417", "html_url": "https://arxiv.org/abs/2508.21417", "title": "LLM仓库中脆弱包依赖项的实证研究", "title_en": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "authors": "Shuhan Liu,Xing Hu,Xin Xia,David Lo,Xiaohu Yang", "background": "近年来，大型语言模型（LLMs）迅速发展，颠覆了各个领域。尽管在模型层面取得了广泛的成功，但LLMs高度依赖来自包管理系统中的外部代码依赖，形成了复杂的LLM依赖供应链。这些依赖中的漏洞可能会对LLMs构成安全风险。目前，现有研究主要集中在模型层面的安全威胁，而忽略了LLM依赖供应链中的漏洞问题。基于此，本文通过对52个开源LLMs进行实证分析，探究其第三方依赖及其相关漏洞，并进一步分析了LLM仓库中的维护措施，以了解开发者如何管理第三方漏洞，最终将LLM生态系统中的第三方依赖漏洞与Python生态系统中的漏洞进行了比较。研究发现，LLM生态系统中的半数漏洞未披露时间超过56.2个月，远长于Python生态系统；另外，75.8%的LLMs包含配置文件中的脆弱依赖项。", "innovation": "本文填补了LLM依赖供应链内在漏洞研究的空白，通过52个开源LLMs进行实证分析，评估和管理第三方漏洞，同时对比了LLM生态系统和Python生态系统的漏洞状况，提出了有关提升LLM供应链安全性的潜在方向。", "conclusion": "LLM生态系统中的半数漏洞未披露时间远长于Python生态系统，75.8%的LLMs包含脆弱依赖项。本文深化了对LLM供应链风险的理解，为从业者提供了宝贵见解，并指出了改进LLM供应链安全性的潜在方向。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "通过迭代混合程序分析的LLM测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "自动单元测试生成仍然是一个重大挑战，尤其是在处理现实生活项目中的复杂方法时。尽管大型语言模型（LLMs）在代码生成方面取得了一定进展，但在实现高分支覆盖率方面仍存在局限性。这主要是因为LLMs在处理复杂控制流结构方面的能力有限。", "innovation": "我们提出了Panta技术，模仿了人类开发人员在分析代码和构建测试案例时遵循的迭代过程。Panta将静态控制流分析和动态代码覆盖率分析结合起来，系统地指导LLMs识别未覆盖的执行路径并生成更好的测试案例。通过引入迭代的反馈驱动机制，我们的技术基于静态和动态路径覆盖率的洞察不断优化测试生成，从而实现更全面和有效的测试。", "conclusion": "我们的实验评估表明，Panta在开源项目中的高圈复杂度类上实现了26%更高的行覆盖率和23%更高的分支覆盖率，相比于最先进的方法更为出色。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.13821", "html_url": "https://arxiv.org/abs/2506.13821", "title": "软件是基础设施：故障、成功、成本与形式化验证的案例", "title_en": "Software is infrastructure: failures, successes, costs, and the case for formal verification", "authors": "Giovanni Bernardi,Adrian Francalanza,Marco Peressotti,Mohammad Reza Mousavi", "background": "本章概述了软件在现代社会中的作用，以及低质量软件带来的巨额成本。通过回顾近40年来一些重大软件失败的成本，强调了研究、学习和应用形式化软件验证特别是程序分析的必要性。", "innovation": "本文支持通过工业实践的成功案例来支持对形式化验证的研究、学习和应用，这被认为是对低质量软件问题的有效解决方案之一。", "conclusion": "本文认为，这些成本证明了研究、学习和应用形式化软件验证的重要性，并支持了工业实践的成功经验。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21636", "html_url": "https://arxiv.org/abs/2508.21636", "title": "AI代码生成器中隐秘数据污染攻击的检测", "title_en": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "authors": "Cristina Improta", "background": "深度学习（DL）模型在自然语言到代码生成方面已经成为了现代软件开发流水线的重要组成部分。然而，这些模型对大量数据的高度依赖性，尤其是这些数据常来源于未经过滤的网络源，使得它们易于遭受数据污染攻击。攻击者可以插入恶意样本以微调模型的行为，即便在没有明显触发机制的情况下，也有可能在难以察觉的情况下替换安全代码为具有相同语义但更为脆弱的实现方式，从而增加了检测方法区分干净样本与受污染样本的难度。", "innovation": "该研究在一种隐蔽的威胁模型中系统地评估现有污染检测方法的有效性。针对三种DL模型（CodeBERT、CodeT5+和AST-T5），作者实施了精确的污染攻击，并评估了基于频谱特征分析、激活聚类和静态分析的防御措施。研究结果表明，所有方法在检测无触发器污染时表现不佳，基于表示的学习方法无法有效分离出受污染的样本，而静态分析则面临误报和漏报的问题，强调了需要更加健壮、与触发器无关的防御措施来应对AI辅助代码生成的威胁。", "conclusion": "现有的检测方法在应对无触发器的隐蔽攻击时面临挑战，基于表示的方法无法有效隔离受污染样本，静态分析也存在误报和漏报的问题，因此需要开发更加强大的、与触发器无关的防御措施来应对AI辅助代码生成中出现的数据污染问题。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.18721", "html_url": "https://arxiv.org/abs/2508.18721", "title": "LLM作为执行估算器：为实用的时间旅行调试恢复缺失的依赖关系", "title_en": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "authors": "Yunrui Pei,Hongshu Wang,Wenjie Zhang,Yun Lin,Weiyu Kong,Jin song Dong", "background": "该研究表明，在单次运行中，使用部分仪器化方法计算动态数据依赖性方面存在挑战。之前的工作通常需要完全记录程序执行，这可能导致性能和资源开销。该论文通过利用LLM（大型语言模型）推测部分记录的执行轨迹和相关代码信息，提出了一种新的方法RecovSlicing，以解决这一问题。", "innovation": "RecovSlicing通过非确定性的LLM，解决了从部分记录执行恢复运行时变量值及结构的精确性问题，以及恢复变量内存地址与记录变量对齐的问题。这种方法允许用户指定隐式的查询变量，并在三次基准测试中对8300个数据依赖关系进行了评估，结果显示其性能超越了Slicer4J, ND-Slicer, LLM Slicer和重新执行Slicer等先进的切片工具。", "conclusion": "RecovSlicing有效地解决了动态数据依赖关系的计算问题，并显著优于现有工具。此外，该方法还被集成到基于双切片的时间回归错误定位器中，显著提高了其性能，能够定位到16%更多的回归错误。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习关联配置和性能的模型。但在动态环境中，负载变化、硬件更改和系统更新会不可避免地在不同级别引入概念漂移——全局漂移重绘整个配置空间的性能轮廓；局部漂移仅影响该空间的某些子区域。现有的离线和迁移学习方法难以实现实时适应这些隐含且不可预测的变化，使得配置性能学习变得困难。", "innovation": "为了解决这个问题，本文提出了DHDA，一个在线配置性能学习框架，旨在跨不同级别捕捉和适应漂移。核心思想是DHDA使用双重分层适应来应对局部和全局漂移：在高层次上，根据必要的情况重新划分数据并重新训练局部模型以处理全局漂移；在低层次上，各个细分的本地模型可以异步地检测并适应局部漂移。为了平衡响应性和效率，DHDA结合增量更新和周期性全重新训练，以在未检测到漂移时最小化冗余计算。", "conclusion": "通过评估八个软件系统并对比最先进的方法，我们证明DHDA能够显著提高准确性，并有效适应漂移，最多可提高2倍，同时产生合理的开销，并能够改善不同局部模型对概念漂移的处理能力。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生在AI模拟中的系统调研、框架构建及其与标准架构的映射", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "现代类符号AI的应用受到数据量不足和数据质量不佳的挑战。为解决这些问题，AI模拟使用虚拟训练环境，其中AI代理可以在其中安全有效地使用模拟和合成数据进行开发。数字孪生为AI模拟提供了新途径，因为它们是物理系统的高保真虚拟副本，配备了先进的模拟器并能够进一步与物理系统交互以收集更多数据。", "innovation": "本文进行了一项系统性调研，分析了22项主要研究，识别了技术趋势并定义了数字孪生及其AI组件的参考框架。基于发现，提出了参考框架并给出了将其映射到数字孪生ISO 23247标准架构的架构指导。", "conclusion": "基于研究结果，指出了未来研究员面临的挑战和研究机会。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.04184", "html_url": "https://arxiv.org/abs/2502.04184", "title": "公共计算笔记本大多数是否病态不可执行？", "title_en": "Are the Majority of Public Computational Notebooks Pathologically Non-Executable?", "authors": "Tien Nguyen,Waris Gill,Muhammad Ali Gulzar", "background": "计算笔记本是探索性数据科学的默认平台，提供了一个交互式的编程环境，用户可以在任何顺序中创建、修改和执行代码单元。然而，这种灵活性常常引入代码质量问题，据之前的研究所示，大约76%的公共笔记本无法执行，这对它们的可重用性产生了重大担忧。传统的可执行性概念要求笔记本完全且无错误地运行，这过于僵化，导致许多笔记本被误分类，并高估了其不可执行性。本文研究了在不同可执行性概念及程度下，公共笔记本中的病态执行问题。即使部分提高执行性也能改善代码理解和提供动态分析途径。已有数据集包含42,546个流行的公共笔记本中的34,659个无法执行的笔记本，其中仅有21.3%是真正病态无法执行的。", "innovation": "1. 提出了一种新的分类方式，将笔记本分为可恢复和病态无法执行两类。\n2. 探讨了通过移除配置错误和表面执行问题，提高笔记本执行性的可能性。\n3. 利用大型语言模型（LLM）方法，部分恢复了5.4%之前无法执行的笔记本。\n4. 发现病态无法执行的笔记本比例远低于以前的假设，表明许多笔记本文档提供有价值的部分执行，并应以交互笔记本的范式而非传统的软件执行标准来评估其执行性。", "conclusion": "通过对公共笔记本可执行性的重新定义和分类，本文挑战了过去对笔记本执行性的假设，认为许多笔记本提供部分执行功能，其执行性应根据交互笔记本的范式来评估，而不是传统的软件执行标准。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用 PennyLane 技能竞赛挑战基准大型语言模型进行量子代码生成", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "最近在大型语言模型（LLMs）方面取得的进步显示了其在代码生成领域的强大潜力，特别是在量子计算领域仍存在很大的探索空间。本文利用来自量子黑客马拉松（QHack）的真实世界挑战评估了LLMs在基于PennyLane的量子代码生成中的表现。", "innovation": "本文引入了QHackBench，这是一个新型基准数据集，基于QHack的竞赛。本文采用基础提示和检索增强生成（RAG）评估模型性能，并使用结构化评估框架评估函数正确性、语法有效性以及执行成功率。此外，本文提出了一种多代理评估管道，可以迭代地改进不正确的解决方案，进一步提高了执行成功率。", "conclusion": "实验结果表明，通过RAG增强的模型，在使用扩展的PennyLane数据集的情况下，能够产生与标准提示方法相当的结果，尤其是在复杂的量子算法中。为了促进进一步研究，本文承诺公开发布QHackBench数据集、评估框架和实验结果，以促进基于AI的量子编程领域的发展。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.18956", "html_url": "https://arxiv.org/abs/2504.18956", "title": "朝向内联代码注释自动检测的方向", "title_en": "Towards Automated Detection of Inline Code Comment Smells", "authors": "Ipek Oztas,U Boran Torun,Eray Tüzün", "background": "代码注释在软件开发中至关重要，直接影响软件的可维护性和整体质量。不良的代码注释实践会导致代码注释“臭味”，从而对软件维护产生负面影响。虽然已经对内联代码注释“臭味”进行了分类研究，但自动检测这些“臭味”仍然具有挑战性。", "innovation": "本文通过增强已标注的注释数据集，使用大型语言模型GPT-4和七种不同的机器学习算法来自动检测和分类内联代码注释“臭味”。尤其是在大型语言模型GPT-4上的应用，以及随机森林模型在 Matthews Correlation Coefficient 上的高得分，为未来研究奠定了基础。此外，增强后的数据集显著提高了GPT-4模型的预测准确性。", "conclusion": "本文探索了自动检测和分类内联代码注释“臭味”，为提高软件维护性做出了贡献。提供的增强数据集和代码可以作为开发自动注释“臭味”检测工具的有价值的资源。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.20977", "html_url": "https://arxiv.org/abs/2508.20977", "title": "ConfLogger: 通过配置日志增强系统的配置可诊断性", "title_en": "ConfLogger: Enhance Systems' Configuration Diagnosability through Configuration Logging", "authors": "Shiwen Shan,Yintong Huo,Yuxin Su,Zhining Wang,Dan Li,Zibin Zheng", "background": "现代可配置系统通过复杂配置空间提供自定义，但这种灵活性引入了如配置错误和潜在软件错误等一系列配置相关问题。现有诊断方法侧重于在软件出现故障后的分析，旨在识别配置问题，但它们并未考虑软件是否能够提供足够的故障信息用于诊断。", "innovation": "我们提出了一种配置日志记录的概念，这是一种级别的静态污点分析与基于LLM的日志生成相结合的新方法。开发了名为ConfLogger的第一个工具，该工具在源代码级别统一了配置感知静态污点分析和基于LLM的日志生成，以增强软件配置的可诊断性。具体来说，我们的方法通过追踪整个项目中的配置相关数据流来识别敏感代码段，并通过分析配置代码上下文来生成诊断日志语句。", "conclusion": "对八个流行软件系统的评估结果表明，增强配置可诊断性。具体而言，ConfLogger增强的日志成功帮助了一个基于日志的配置错误诊断工具在30个静默配置错误场景中实现了100%的错误定位准确度，其中80%可以通过显式配置信息直接解决。此外，ConfLogger实现了现有日志记录点的74%覆盖率，优于基线LLM日志记录器12%且30%，并分别提1.086倍的精度、1.793倍的召回率和1.262倍的F1分数。"}
{"llm_update_time": "20250902", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07328", "html_url": "https://arxiv.org/abs/2503.07328", "title": "完全闭合的循环：具有表达性循环引用的可达性类型（扩展版）", "title_en": "Complete the Cycle: Reachability Types with Expressive Cyclic References (Extended Version)", "authors": "Haotian Deng,Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf", "background": "程序中结合了别名和可变状态的局部推理是一个长期存在的挑战。现有的方法，如所有权系统、线性类型、仿射类型、唯一性类型和词法效果跟踪，要么施加全局限制，如唯一性或线性，要么依赖于浅层语法分析。这些设计在处理高阶函数和共享可变状态时效果不佳。可达性类型（RT）能够跟踪高阶程序中的别名和分离，确保运行时安全性和无干扰。然而，RT系统面临三个关键限制：禁止循环引用，排除非终止计算和固定点组合子；深度跟踪要求所有转达可达位置都在限定符中，这降低了精度并妨碍了细粒度并行等优化；参考者限定符不变性禁止参考者从其分配上下文逃逸，使引用工厂不可表达。", "innovation": "本文通过为RT扩展三个机制增强其表达能力，解决了这些限制。首先，引入了循环引用，允许通过存储直接编码递归模式。其次，采用浅层限定符跟踪，将引用与它们可及的值解耦。最后，引入了带有引述子类型的逃逸规则，允许参考者的限定符逃逸其分配上下文。这些扩展在带有形式化证明的类型声态势的F<:∘- calculus 中进行了标准化，并通过固定点组合子、非干扰并行和逃逸只读参考的案例研究展示了其表达性。", "conclusion": "本文通过引入具有表达性循环引用的可达性类型，解决并改进了该领域的关键限制，验证了其在高阶程序中的适用性和有效性。"}
{"llm_update_time": "20250902", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09823", "html_url": "https://arxiv.org/abs/2507.09823", "title": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "title_en": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "authors": "Ekaterina Borodich,Dmitry Kovalev", "background": "近期，Malitsky（2020）和Alacaoglu等人（2023）提出了一个自适应梯度方法GRAAL。该算法通过估计目标函数的局部曲率来计算步长，无需线性搜索过程或超参数调整，能够达到标准的固定步长梯度下降的迭代复杂度$\\mathcal{O}(L\\lVert x_0-x^*\\rVert^2/\\epsilon)$，适用于$L$-光滑函数。", "innovation": "本文解决了GRAAL算法加速收敛的问题，通过引入Nesterov加速技术，使得算法能以几何或线性速率适应目标函数的局部曲率，从而达到最优复杂度$\\mathcal{O}(\\sqrt{L\\lVert x_0-x^*\\rVert^2/\\epsilon})$。证明了该算法在$L$-光滑函数和更一般的$(L_0,L_1)$-光滑性假设下能够获得接近最优的迭代复杂度。", "conclusion": "通过结合Nesterov加速技术和GRAAL算法，本文提出的方法能够在不牺牲自适应能力的前提下，加速收敛并达到最优复杂度，为凸优化提供了新的最优和自适应梯度算法。"}
