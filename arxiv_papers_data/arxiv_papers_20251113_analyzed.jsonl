{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07568", "html_url": "https://arxiv.org/abs/2511.07568", "title": "程序性知识改善了行动型大语言模型工作流", "title_en": "Procedural Knowledge Improves Agentic LLM Workflows", "authors": "Vincent Hsiao,Mark Roberts,Leslie Smith", "background": "大型语言模型（LLMs）在缺乏工具支持、提示工程或微调的情况下执行自主任务方面经常表现不佳。尽管已有研究表明领域特定的程序性知识可以显著提高规划效率，但仍少有研究评估其在可能需要隐性规划的自主任务中提升LLM性能的潜力。", "innovation": "该研究通过正式化、实现并评估了一个基于层次任务网络（HTN）的行动型LLM工作流，发现手动编码的HTN可以显著提高LLMs在执行自主任务时的性能；使用HTN可以使参数量为20亿或70亿的LLM实现性能提升，甚至超越参数量为120亿的基线LLM。", "conclusion": "研究结果表明，利用人类、文档或LLM中的专业知识来提炼程序性知识将成为改进LLM工作流程的重要工具。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07678", "html_url": "https://arxiv.org/abs/2511.07678", "title": "AIA Forecaster: 技术报告", "title_en": "AIA Forecaster: Technical Report", "authors": "Rohan Alur,Bradly C. Stadie,Daniel Kang,Ryan Chen,Matt McManus,Michael Rickert,Tyler Lee,Michael Federici,Richard Zhu,Dennis Fogerty,Hayley Williamson,Nina Lozinski,Aaron Linsky,Jasjeet S. Sekhon", "background": "该报告描述了一个基于大型语言模型（LLM）的系统——AIA Forecaster，用于利用非结构化数据进行判断性预测。AIA Forecaster方法结合了三个核心元素：代理去搜索高质量的新闻来源、一个监督代理解决相同事件不同预测之间的分歧，以及一组统计校准技术以对抗大型语言模型中的行为偏差。该系统在一个名为ForecastBench的基准测试中表现出色，与人类超级预测者相当，超越了之前的LLM基线。", "innovation": "AIA Forecaster的创新之处在于其结合了代理搜索高质量新闻来源、监督代理解决预测分歧和统计校准技术来应对大型语言模型中的行为偏差。此外，AIA Forecaster在ForecastBench基准测试中的表现与人类超级预测者相当，并且通过与市场共识的结合，显示出增加的信息价值。", "conclusion": "这项工作在AI预测领域建立了新的技术水平，并为未来的研究提供了实用且可转移的建议。据我们所知，这是第一个在大规模预测中验证达到专家级水平的工作。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07483", "html_url": "https://arxiv.org/abs/2511.07483", "title": "超越正确性：增强大型语言模型推理能力的基于自信的奖励建模", "title_en": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning", "authors": "Qianxi He,Qingyu Ren,Shanzhe Lei,Xuhong Wang,Yingchun Wang", "background": "近年来，大型语言模型（LLMs）的发展使后训练 paradigm 从传统的指令调优和人类偏好对齐转向以推理能力为核心的强化学习（RL）。然而，大量的技术报告表明，纯粹基于规则的奖励RL通常会导致较低质量的推理链或推理过程与最终答案之间的不一致，特别当基础模型是小规模时。在RL探索过程中，模型可能会因为知识不足而使用低质量的推理链，有时会随机产生正确答案并获得基于既定规则判断者的奖励。这限制了资源有限的组织在直接对较小规模模型进行强化学习训练的能力。", "innovation": "本文提出了一种新的基于自信的奖励模型来增强STEM推理能力。与传统的解决方法不同，我们模型不仅惩罚错误答案，还惩罚低自信度的正确答案，从而促进更稳健且逻辑上更加一致的推理能力。方法通过静态评估、最佳的N次推理测试和基于PPO的RL训练进行了验证，并且在多个STEM基准测试中优于最先进的开源奖励模型。", "conclusion": "我们的方法在多种STEM基准上优于最先进的开源奖励模型。我们在这里提供代码和模型链接：this https URL。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07667", "html_url": "https://arxiv.org/abs/2511.07667", "title": "AI驱动的贡献评估与冲突解决：团队工作量调查的框架与设计", "title_en": "AI-Driven Contribution Evaluation and Conflict Resolution: A Framework & Design for Group Workload Investigation", "authors": "Jakub Slapek,Mir Seyedebrahimi,Yang Jianhua", "background": "团队中个体贡献的公平评估一直是一个持续的挑战，其中冲突和工作量差异会导致不公平的绩效评估，通常需要手动干预，这是一个成本高且具有挑战性的过程。现有的工具特征中缺乏冲突解决方法和AI集成的方法。", "innovation": "提出了一个基于AI的新型工具框架和实施设计，用于协助纠纷调查。该框架将异构的提交（代码、文本、媒体）、交流（聊天、邮件）、协调记录（会议记录、任务）、同伴评估和上下文信息组织成三个维度（贡献、互动、角色），并制定了九个基准。通过对这些度量标准进行客观测度，归一化并聚合，与不平等度量（基尼指数）结合来发现冲突标志。采用大型语言模型（LLM）架构对这些度量进行验证和上下文分析，生成可解释和透明的建议判断。提出了该方案在现行法规和机构政策下的可行性，并概述了实操分析、偏见保护、局限性和实际挑战。", "conclusion": "本文方案在现行法规和机构政策下是可行的，并且给出了实操分析、偏见保护、局限性和实际挑战的讨论。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07581", "html_url": "https://arxiv.org/abs/2511.07581", "title": "在检索前思考：使用小型语言模型实现测试时自适应搜索", "title_en": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models", "authors": "Supriti Vijay,Aman Priyanshu,Anu Vellore,Baturay Saglam,Amin Karbasi", "background": "有效的信息检索需要在信息逐渐浮现的过程中进行部分证据的推理和策略的不断调整。当前的方法存在不足：神经检索器缺乏推理能力，大型语言模型（LLMs）虽然能够提供语义上的深度，但成本高昂，而查询重写或分解仅限于静态的转变。因此，现有方法未能捕捉到复杂用户查询所需的探索、反馈和修订的迭代动态。", "innovation": "介绍了Orion，这是一种训练框架，使具有350M-1.2B参数的紧凑模型能够通过学习的搜索策略进行迭代检索。Orion 结合了：1）合成轨迹生成和监督微调，鼓励模型进行多样化的探索模式；2）强化学习（RL），奖励有效查询的改进和回溯行为；3）推断时间时的束搜索算法，利用在RL过程中学习到的自我反思能力。", "conclusion": "尽管只使用3%的训练数据，1.2B参数模型在SciFact、BRIGHT和NFCorpus上分别取得了77.6%、25.2%和63.2%的成功率，分别优于之前的检索器72.6%、22.1%和57.8%的性能。它还在FEVER、HotpotQA和MSMarco等基准测试中保持竞争力。该研究的发现表明，在模型训练过程中学会搜索、反思和修订时，检索性能可以由学习到的策略而非仅仅是模型规模来产生。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07437", "html_url": "https://arxiv.org/abs/2511.07437", "title": "在边缘设备上为非洲语言生成有自主性的教育内容", "title_en": "Agentic Educational Content Generation for African Languages on Edge Devices", "authors": "Ravi Gupta,Guneet Bhatia", "background": "非洲撒哈拉以南地区的教育不平等是一个重要的社会问题。本研究旨在利用多智能体系统、边缘AI计算等技术，生成适合教育内容，以解决教育资源受限和文化适应性不足的问题，从而推进联合国可持续发展目标4（高质量教育）、9（产业、创新和基础设施）和10（减少不平等）的实现。", "innovation": "提出了一个基于多代理的框架，用于在边缘设备上生成分散的、文化适应性的教育内容。该系统利用四个专门的代理协同工作，生成上下文相关的教育内容。实验验证表明该系统在Raspberry Pi 4B和NVIDIA Jetson Nano上获得了显著的性能提升。使用InkubaLM，Jetson Nano实现了129毫秒的时间到第一个标记（TTFT），平均标记间延迟为33毫秒，吞吐量为45.2个令牌/秒，功耗为8.4瓦。在Raspberry Pi 4B上，InkubaLM也以326毫秒的TTFT和15.9个令牌/秒的吞吐量，消耗5.8瓦的功率，实现了良好的平衡。框架一致地提供了高质量的多语言质量、文化相关性和流畅性。", "conclusion": "通过与非洲青年和社区组织、佛罗里达非洲基金会等活跃的社区组织合作，该研究旨在为资源受限环境中的教育提供实用的基础，实现普及、地方化和可持续的人工智能驱动教育。该研究关注长期可行性和文化适当性，有助于实现联合国的可持续发展目标。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07669", "html_url": "https://arxiv.org/abs/2511.07669", "title": "在关键时刻让LLM可靠：一种五层架构以应对高风险决策", "title_en": "Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions", "authors": "Alejandro R. Jadad", "background": "当前的大语言模型（LLMs）在可验证领域表现优异，但在高风险的战略决策中却显得不够可靠。由于人类和AI系统的认知偏差相互强化，这种不可靠性威胁到公司估值和投资的合理性和可持续性。本文基于对7个前沿级LLM和3个时间压力下市场应对案例的系统定性评估，提出了一个框架。尽管初步的建模能够达到合作伙伴状态，但在实际操作中并未能维持这种状态，需要通过一个动态的7阶段校准序列来维持这种状态，该序列基于4阶段的初始化过程，用于构建一个5层保护架构。该架构包括偏见自我监控、人机对抗挑战、合作伙伴状态验证、性能衰退检测和利益相关者保护等功能。", "innovation": "本文提出了一种五层架构来应对高风险决策，包含基于有序校准后的合作伙伴状态（需要动态的7阶段校准序列来维持），系统地验证不同LLM架构的表现差异，以及通过避免错误方向避免投入。此方法展示了人机团队能够达成认知上的合作伙伴关系，从而预防高风险决策中的可避免遗憾，同时确保AI系统在决策时不会引入可预防的认知陷阱，即使验证迟到。", "conclusion": "此报告发现，合作伙伴状态可以通过校准建立，但需要动态维护协议；可靠性在架构偏移和情境耗尽时会下降；制定退出纪律可以避免追逐根本错误的方向。跨模型验证揭示了不同LLM架构的系统性能差异。这种方法展示了人机团队可以在高风险决策中实现认知伙伴关系，以避免可避免的遗憾，并满足AI系统在关键决策中支持的ROI要求，而不引入可预防的认知陷阱。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07436", "html_url": "https://arxiv.org/abs/2511.07436", "title": "分析AI在X射线诊断中的环境效率", "title_en": "Analysing Environmental Efficiency in AI for X-Ray Diagnosis", "authors": "Liam Kearns", "background": "将AI工具整合到医疗应用中以提升诊断效率，尤其是在使用大型语言模型（LLMs）如ChatGPT和Claude的情况下。尽管LLMs功能强大且易于通过API使用，但研究发现通常使用较小的定制模型即可。本文将LLMs与小的辨别模型集成到Mendix应用中以分析胸部X光片中的COVID-19感染情况，同时利用辨别模型作为LLMs的知识库以提高准确性。研究对比了14种不同模型配置的准确性与环境影响，结果表明小型模型能减少碳足迹，但倾向于产生更多阳性诊断结果且结果缺少置信度；同时限制LLMs仅输出概率也会严重影响其性能。研究还发现，与大型模型相比，GPT-4.1-Nano将碳足迹减少了94.2%，但与辨别模型相比仍不成比例；最高效的解决方案是Covid-Net模型，其碳足迹虽然比其他小型模型高，但比使用GPT-4.5-Preview减少99.9%，并且准确度达到95.5%，为所有检测模型中最高。", "innovation": "将LLMs与小的辨别模型集成到Mendix应用中以分析胸部X光片中的COVID-19感染情况；首次对比了LLMs和小辨别模型在不同配置下的环境影响，并研究了模型在碳足迹和准确性方面的权衡。", "conclusion": "虽然小型模型能够显著降低应用的碳足迹并提高准确性，但它们的结果可能缺乏置信度。在限制LLMs仅提供概率输出的情况下，其表现会变差，表明使用LLMs作为通用AI解决方案的风险。Covid-Net模型被认为是目前最高效的方案，其在碳足迹和准确性之间找到了最佳平衡。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07685", "html_url": "https://arxiv.org/abs/2511.07685", "title": "ResearchRubrics: 一个评估深度研究代理的提示和评分标准基准", "title_en": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents", "authors": "Manasi Sharma,Chen Bo Calvin Zhang,Chaithanya Bandi,Clinton Wang,Ankit Aich,Huy Nghiem,Tahseen Rabbani,Ye Htet,Brian Jang,Sumana Basu,Aishwarya Balwani,Denis Peskoff,Marcos Ayestaran,Sean M. Hendryx,Brad Kenstler,Bing Liu", "background": "深度研究（DR）是一种新兴的代理应用，通过利用大型语言模型（LLMs）来应对开放式查询。评估DR存在挑战，因为其响应通常很长，多样，并包含了多种可能的有效解决方案，且往往依赖于动态信息源。为了应对这一挑战，研究人员开发了一种标准化的基准——ResearchRubrics，利用超过2800小时的人工劳动，将现实且领域多样化的问题与2500多个专家撰写的细粒度评分标准相结合，以评估事实基础、推理准确性和清晰度。此外，研究人员还提出了一种新的复杂性框架，用于按照概念广度、逻辑嵌套和探索三个维度对DR任务进行分类，并开发了人工和模型评估协议来测量DR代理的评分标准遵从度。研究发现，即使是顶尖的DR代理系统，如Gemini的DR和OpenAI的DR，平均也只能达到68%的评分标准合规率，主要原因是未能捕捉到隐含的背景信息和处理检索信息不当。这些结果强调了需要建立稳健且可扩展的评估机制来评估深度研究能力的必要性，并为此发布了ResearchRubrics（包括所有提示、评分标准和评估代码）以促进对此类研究助手发展的推动。", "innovation": "1. 开发了ResearchRubrics标准化基准，用于评估DR代理，包括2,800多小时的人工劳动和2,500多个专家撰写的细粒度评分标准。\n2. 提出了一种新的复杂性框架，用于按概念广度、逻辑嵌套和探索三个维度分类DR任务。\n3. 提出了人工和模型评估协议来衡量DR代理的评分标准遵从度。\n4. 分析了若干最新的DR系统的表现，指出它们在事实基础、推理准确性和清晰度方面的不足，且主要问题是未能捕捉隐含背景信息和处理检索信息不当。", "conclusion": "需要建立稳健且可扩展的评估机制来评估深度研究能力。我们发布了ResearchRubrics，旨在推动对此类研究助手的发展，以及更充分地利用和改进大型语言模型在开放查询和深入研究方面的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07587", "html_url": "https://arxiv.org/abs/2511.07587", "title": "超越事实检索：通过生成语义工作空间实现记忆型RAG", "title_en": "Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces", "authors": "Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury", "background": "大型语言模型在处理长段文本推理时面临诸多挑战，由于其有限的上下文窗口，许多文档超出了这些限制，而对于能够适应上下文的文本，其表现随着序列长度增加而下降，因此需要通过外部记忆框架进行增强。现有解决方案通过从语义嵌入的检索方法进化到更复杂的结构化知识图谱表示，旨在改进事实检索和关联性，但这些仍然难以构建时间-空间-锚定的叙事表示，这对于跟踪事件中的人物角色至关重要。为了填补这一缺口，该研究提出了一种名为生成语义工作空间（GSW）的神经启发式生成式记忆框架，该框架构建了结构化的、可解释的情况表示，允许语言模型在情境演变中进行推理。", "innovation": "GSW 是一种神经启发式的生成式记忆框架，能够构建结构化、可解释的演变情境表示，从而增强语言模型的空间、时间和逻辑一致性推理。GSW 拥有一个操作器，用于将输入观察映射到中间语义结构，以及一个综合器，用于整合这些结构到一个持久的工作空间中。在EpBench基准测试中，GSW 比现有基于RAG的基线改进了高达20%的表现，且 GS 应用提高了查询时上下文令牌减少了51%，极大地降低了推理时间成本。", "conclusion": "GSW 为赋予语言模型类似人类的事件记忆提供了一个具体的蓝本，从而为能够在长时期内进行推理的更强大代理铺平了道路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07690", "html_url": "https://arxiv.org/abs/2511.07690", "title": "向基于AI的军事训练场景生成迈出一步", "title_en": "Towards AI-Assisted Generation of Military Training Scenarios", "authors": "Soham Hans,Volkan Ustun,Benjamin Nye,James Sterrett,Matthew Green", "background": "在基于模拟的培训中，实现专家级表现依赖于创建复杂且适应性强的场景，这是一个劳动密集且资源消耗大的过程。以前的研究尽管探讨了战术训练场景的生成，但早期人工智能工具无法生成足够复杂或适应性强的场景。", "innovation": "本文提出了一种多智能体、多模态的推理框架，利用大型语言模型（LLMs）生成关键的培训资源，例如作战命令（OPORDs）。框架通过将场景生成分解为一个子问题层次结构，并针对每个子问题定义人工智能的角色，从而克服了基本提示或单一智能体方法在处理这种高度复杂任务时的局限性。每个智能体从中级智能体接收输入，整合文本和视觉信息，并应用专业知识进行推理。这有多智能体策略代替了基本提示或单个智能体方法，提高了生成复杂场景的效率。", "conclusion": "我们通过一个概念验证展示该框架，生成OPORD的方案方案和行进部分，同时估计地图位置和移动情况，证明了其可行性和准确性。研究表明，基于LLM的多智能体系统能够生成连贯且细致的文档，并根据情况动态调整，从而推动军事训练场景生成的自动化进程。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07850", "html_url": "https://arxiv.org/abs/2511.07850", "title": "GAMA：一种基于图感知多模态注意力的神经邻域搜索方法用于车辆路径问题", "title_en": "GAMA: A Neural Neighborhood Search Method with Graph-aware Multi-modal Attention for Vehicle Routing Problem", "authors": "Xiangling Chen,Yi Mei,Mengjie Zhang", "background": "近期神经网络在邻居搜索方法中显示了解决车辆路径问题（VRPs）的潜力，但大多数现有方法依赖于简单的状态表示，并通过简单的拼接融合异构信息，限制了其捕捉丰富结构和语义上下文的能力。因此，本文分析了现有方法的局限性，并指出需要一种能够更好地捕捉VRP中结构和语义信息的方法。", "innovation": "提出了一种名为GAMA的神经邻居搜索方法，该方法结合了图感知多模态注意力机制。GAMA使用图神经网络编码问题实例及其不断演化的解决方案，并通过堆叠的自注意力和交叉注意力层建模其内模态和跨模态的交互。此外，使用了一个门控融合机制进一步将多模态表示集成到一个结构化的状态中，使策略能够做出有据可依和能够泛化的操作选择决策。", "conclusion": "在各种合成和基准实例上进行的广泛实验表明，所提出的算法GAMA显著优于最近的神经基线。进一步的消融研究证明，多模态注意力机制和门控融合设计在实现观察到的性能增益中发挥了关键作用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07842", "html_url": "https://arxiv.org/abs/2511.07842", "title": "LLM安全的联立意识量化", "title_en": "Alignment-Aware Quantization for LLM Safety", "authors": "Sunghyun Wee,Suyoung Kim,Hyeonjin Kim,Kyomin Hwang,Nojun Kwak", "background": "当部署大规模语言模型（LLMs）时，安全性和效率都是极其重要的因素。LLMs 通过遵循人类对齐原则进行训练以确保安全，之后会应用后训练量化（PTQ）以提升效率。然而，这两个目标往往是冲突的，尤其是在PTQ过程中只追求低perplexity（困惑度）时，可能会引入安全性的漏洞。因此，仅依赖perplexity来评估模型安全性是不足的且具有误导性。", "innovation": "提出了一种新颖的方法——联立意识量化（AAQ），该方法将联立保持对比损失（APC）结合到后训练量化（PTQ）过程中。AAQ通过鼓励量化模型模仿其安全且指令调优过的模型，同时与未对齐的预训练模型产生分歧，来显式地保持对齐。该方法在不依赖特定的安全校准数据集的情况下实现了稳健的安全对齐，具有实际应用价值和广泛的适用性。AAQ与标准的后训练量化技术兼容，能够在LLaMA、Qwen和Mistral等不同的模型系列中实现4位量化（W4A4），同时保持安全性。", "conclusion": "我们的研究解决了效率和安全性的关键权衡问题，为高效且可信赖的LLMs的发展铺平了道路。附加大纲提供了去 anonymization 的代码。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07719", "html_url": "https://arxiv.org/abs/2511.07719", "title": "基于遥感光谱检测的运营机器学习系统", "title_en": "Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources", "authors": "Vít Růžička,Gonzalo Mateo-García,Itziar Irakulis-Loitxate,Juan Emmanuel Johnson,Manuel Montesino San Martín,Anna Allen,Luis Guanter,David R. Thompson", "background": "甲烷是导致全球变暖的主要温室气体之一，且治理甲烷来源是成本效益高的减缓全球变暖的方式。目前，卫星成像光谱仪能够检测这些点源，但现有的基于匹配滤波器的甲烷检测方法产生大量误报，需要耗费大量人工验证。本文通过描述一个机器学习系统在联合国环境规划署国际甲烷排放观察站的Methane Alert and Response System (MARS)中的部署，来解决这一问题。研究者使用了三个成像光谱仪任务中最大的和最多样化的标注甲烷烟柱数据集，并定量比较了不同的深度学习模型配置。", "innovation": "引入了一种机器学习系统，以减轻甲烷点源检测中的大量误报问题。通过扩展先前的小块数据集评估方法到完整的光谱颗粒评估，研究建立了模型的集成方法，降低了误报率超过74%。这一系统被部署在MARS工作流中，能够加速甲烷泄漏的检测和分析过程，并已在多个地区进行了实际部署和验证，证明了方法的有效性。", "conclusion": "本研究为全球人工智能辅助甲烷泄漏检测系统的发展迈出了关键一步，这一系统能够处理来自新旧成像光谱仪的大量数据，为减少全球甲烷排放提供重要工具。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07895", "html_url": "https://arxiv.org/abs/2511.07895", "title": "趋向于在失语症的误发音过程中稳健的EEG意图解码", "title_en": "Toward Robust EEG-based Intention Decoding during Misarticulated Speech in Aphasia", "authors": "Ha-Na Jo,Jung-Sun Lee,Eunyeong Ko", "background": "失语症严重影响了语言交流，患者在尝试讲话时经常出现发音错误。尽管对脑-机接口技术的兴趣日益增长，但较少有研究关注为失语患者定制的基于EEG的交流支持系统开发。因此，本文的研究背景在于填补这一空白。", "innovation": "该研究开发了一种基于软多任务学习框架与最大均值差异正则化的模型，该模型专注于delta特征，以联合优化类别区分并使正确和误发音的EEG特征分布对齐。研究结果表明，在发音错误下，所提出模型在解码意图方面具有较强的鲁棒性。", "conclusion": "研究结果证明，基于EEG的辅助系统具备在失语患者实际不完美的语言条件下支持交流的能力，模型在误发音识别上的准确率明显优于基线。这一发现展示了此类系统的可行性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07890", "html_url": "https://arxiv.org/abs/2511.07890", "title": "大脑电生理信号中公开语音的意识感知神经解码：迈向稳健的大脑-计算机接口", "title_en": "Confidence-Aware Neural Decoding of Overt Speech from EEG: Toward Robust Brain-Computer Interfaces", "authors": "Soowon Kim,Byung-Kwan Ko,Seo-Hyun Lee", "background": "非侵入式脑-计算机接口需要从脑电图（EEG）数据中解码语音指令，既准确又可信。该研究背景强调了解码框架的准确性与可靠性，尤其是在处理不同说话者生成的多类别开口语音数据集时。", "innovation": "该研究提出了一种意识感知解码框架，结合了紧凑的、以语音为导向的卷积网络的深度集成，以及后置校准和选择性分类。不确定性通过基于集成的预测熵、前两高概率值差和互信息量化。决策由准确度-覆盖操作点决定，可选决策权衡准确性与覆盖度。该方法使用泄漏安全的块分层分割进行评估，该分割遵守时间连续性。与广泛使用的基准方法相比，所提出的方法提供更可靠的概率估计、改进的选择性能和每个类别平衡接受性。这表明意识感知神经解码能够为实际大脑-计算机接口通信系统提供稳健的行为表现。", "conclusion": "研究表明，意识感知神经解码能够提供可靠的大规模部署行为，适用于实际的大脑-计算机接口通信系统，尤其是在考虑不确定性量化和决策灵活性的情况下。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07896", "html_url": "https://arxiv.org/abs/2511.07896", "title": "SparseRM：一种基于稀疏自编码器的轻量化偏好建模", "title_en": "SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder", "authors": "Dengcan Liu,Jiahao Li,Zheren Fu,Yi Tu,Jiajun Li,Zhendong Mao,Yongdong Zhang", "background": "奖励模型（RMs）是大型语言模型（LLMs）后训练中的核心组件，用作人类偏好评价的代理并指导模型对齐。然而，在有限资源下训练可靠的RMs仍具有挑战性，因为需要大规模的偏好评注和调整LLMs的高成本。SparseRM通过使用稀疏自编码器（SAE）提取模型表示中与偏好相关的信息来解决这一问题，从而构建了一个具有轻量级和可解释性的奖励模型。", "innovation": "SparseRM利用稀疏自编码器（SAE）将LLM表示分解成可解释的方向，捕捉与偏好相关的特征，然后将表示投影到这些方向上计算对齐得分。一个简单的奖励头将这些得分聚集起来预测偏好得分。实验表明，SparseRM在使用不到1%的可训练参数的情况下，能够在三种偏好建模任务中实现优于大多数主流RMs的表现。此外，它可以无缝地集成到下游对齐流水线中，突显了其高效对齐的潜力。", "conclusion": "实验结果显示，SparseRM在使用不到1%的可训练参数的情况下，已经在三种偏好建模任务中展现出优于大多数主流奖励模型的性能，并且可以无缝集成到下游对齐流水线中，验证了其高效和灵活性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07863", "html_url": "https://arxiv.org/abs/2511.07863", "title": "WaterMod：概率平衡大型语言模型水印的模块化Token-排名分区", "title_en": "WaterMod: Modular Token-Rank Partitioning for Probability-Balanced LLM Watermarking", "authors": "Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han", "background": "当前大型语言模型能够以接近人类水准的流畅度生成新闻、法律分析和软件代码。然而，欧盟AI法案等法规要求每段合成文本必须携带一个不可察觉、可机器验证的标记以追溯源信息。传统的logit基水印通过在每次解码步骤中选择一个伪随机绿色词汇并提升其logits来满足这一需求，但这种方法存在概率随机分割导致高概率词汇被排除的风险，从而影响文本流畅度。", "innovation": "WaterMod提出了一种基于概率的模块化规则方法来解决上述问题。首先按模型概率降序对词汇表进行排序，然后根据剩余排名与k取模的结果进行分区，这种方式可以将相邻且语义相似的词汇分到不同的类别，然后对选定类别的logits施加固定的小偏置。在零比特设置下(k=2)，选择要么偶数要么奇数作为绿色标记。在多比特设置下(k>2)，当前payload位d选择满足rank mod k = d的rank类别并对该类别的logits施加偏置。这种方法支持两种设置的细粒度追溯，包括二进制归因和丰富的负载。实验结果表明，WaterMod在零比特和多比特设置下均能保持水印检测效果和生成质量，适用于自然语言生成、数学推理和代码合成等多种任务。", "conclusion": "WaterMod通过概率感知的模块化规则解决了传统水印方法的流畅度问题，不仅保持了水印检测性能，还提高了生成质量，适用于多种复杂任务，展现了其在大型语言模型水印标记中的优势。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07912", "html_url": "https://arxiv.org/abs/2511.07912", "title": "神经认知特性：创造性问题解决策略中的适应性推理", "title_en": "Neurophysiological Characteristics of Adaptive Reasoning for Creative Problem-Solving Strategy", "authors": "Jun-Young Kim,Young-Seok Kweon,Gi-Hwan Shin,Seong-Whan Lee", "background": "人类的适应性推理允许人们在环境规则或背景发生变化时灵活调整推理策略，但其背后的神经动态机制尚不清楚。这项研究通过结合卡片分类范式和脑电图来探讨适应性推理的神经生理机制，并将人类表现与多模态大型语言模型的表现进行了对比。", "innovation": "研究揭示了人类适应性推理的神经特征，发现了一种协调的delta-theta-alpha动态模式：早期的delta-theta活动反映了探索性监测和规则推理，而后顶叶alpha活动则表示在成功识别规则后确认性地稳定注意力。相比之下，多模态大型语言模型仅表现出基于反馈的短期调整，而缺乏分层规则抽象和真正的适应性推理。这一发现强调了借鉴振荡反馈协调构建脑启发式人工智能的必要性，以实现真正的上下文敏感适应性。", "conclusion": "该研究发现了人类适应性推理的神经标记，并强调需要能够根据环境变化进行真正适应性调整的脑启发式人工智能，这种人工智能需要整合振荡反馈协调机制。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07901", "html_url": "https://arxiv.org/abs/2511.07901", "title": "DANS-KGC: 基于扩散的自适应负采样方法用于知识图谱完成", "title_en": "DANS-KGC: Diffusion Based Adaptive Negative Sampling for Knowledge Graph Completion", "authors": "Haoning Li,Qinghua Huang", "background": "负采样（NS）技术和策略在知识图谱表示中扮演着关键角色。然而，现有的负采样策略存在几个局限性，包括容易受到假阴性的攻击、泛化能力有限以及无法控制样本的难度等。针对这些局限性，本文提出了DANS-KGC（基于扩散的自适应负采样方法用于知识图谱完成），旨在改进现有的知识图谱完成方法。", "innovation": "DANS-KGC包含三个关键模块：难度评估模块（DAM）、自适应负采样模块（ANS）和动态训练机制（DTM）。DAM通过融合语义和结构特征来评估实体的学习难度；ANS采用基于难度感知噪声调整的条件扩散模型，在去噪过程中利用语义和邻居信息生成具有不同难度的负样本；DTM能够在训练过程中动态调整负样本难度分布，使得学习过程从容易到困难逐步推进。这种方法在六个基准数据集上的广泛实验中证明了其有效性和泛化能力，尤其在UMLS和YAGO3-10数据集的三个评估指标上取得了最先进的结果。", "conclusion": "DANS-KGC通过解决现有负采样策略中遇到的问题，展示了在六个基准数据集上的出色性能和泛化能力，特别是在UMLS和YAGO3-10数据集上取得了最先进的结果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07897", "html_url": "https://arxiv.org/abs/2511.07897", "title": "借助影响估计的大语言模型数据描述", "title_en": "Data Descriptions from Large Language Models with Influence Estimation", "authors": "Chaeri Kim,Jaeyeon Bae,Taehwan Kim", "background": "深度学习模型在许多领域取得了成功，但对其行为的理解仍然是一个黑盒问题。大多数既有的可解释AI（XAI）方法集中在解释模型如何做出预测上，而本文旨在通过语言这种最常见的媒介来解释数据如何通过深度学习模型的训练，从而让人类更容易理解。本文提出了一种新的方法，使用大语言模型结合外部知识库来生成可以解释数据的文本描述。但生成的数据描述可能仍包含无关信息，因此引入了利用影响估计来选择最具信息量的文本描述，并结合CLIP分数。基于跨模态传输性现象，本文提出了一个新的基准任务，即跨模态传输分类，以检验文本描述的有效性。在零样本设置的实验中，本文展示了我们的文本描述比其他基线描述更有效，并进一步提升了仅使用图像训练的模型在所有九个图像分类数据集上的性能。这些结果得到了GPT-4o评估的支持。通过本文的方法，我们可能获得对模型决策过程内在可解释性的见解。", "innovation": "本文提出了一个新颖的方法，通过结合外部知识库与大语言模型，生成可以解释数据的文本描述。此外，本文还引入了一种新的基准任务——跨模态传输分类，以评估文本描述的有效性，并且在零样本设置下证明了这种方法的有效性，进一步提升了仅基于图像训练的模型在图像分类任务上的性能。并且使用了GPT-4o进行了评估以支持这些结果。", "conclusion": "通过本文提出的方法，我们可以获得对模型决策过程内在可解释性的见解。实验结果表明，基于我们的文本描述的模型在多个图像分类数据集上表现更佳，这证明了本文方法的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07920", "html_url": "https://arxiv.org/abs/2511.07920", "title": "基于轻量级扩散模型的在线失语症患者意念言语解码框架", "title_en": "Lightweight Diffusion-based Framework for Online Imagined Speech Decoding in Aphasia", "authors": "Eunyeong Ko,Soowon Kim,Ha-Na Jo", "background": "该研究旨在为患有严重表达性语言障碍的失语症患者开发一种在实际临床环境下可靠的实时意念语音分类框架。研究采用基于扩散的神经解码方法，利用特定个体的脑电图（EEG）数据训练该系统。", "innovation": "提出了一个以轻量级条件扩散编码器和卷积分类器为基础的解码框架，这些组件都经过了针对失语症患者韩语语言范式的特定训练。该框架运用双标准早期停止策略在有限校准数据下实现快速收敛，并通过掉电正则化和组时域卷积确保系统稳定泛化。在线运行时，借助连续EEG流数据进行二秒滑动窗口处理，生成根据解码置信度动态调整的视觉和听觉反馈。", "conclusion": "实验结果显示在线运行时框架的 top-1 准确率达到了65%，top-2 准确率达到了70%，远高于离线评估时的50%。这些结果显示在实际临床环境中使用基于扩散的EEG解码具有可行性，即使在环境变化较大和预处理有限的情况下也能保持可靠性能。提出的框架将促进意念语音脑机接口向严重表达性语言障碍患者临床交流支持的转化。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07932", "html_url": "https://arxiv.org/abs/2511.07932", "title": " Computational Blueprints: 使用大型语言模型生成同构数学问题", "title_en": "Computational Blueprints: Generating Isomorphic Mathematics Problems with Large Language Models", "authors": "Jeong-Hoon Kim,Jinwoo Nam,Geunsik Jo", "background": "个性化数学教育正在快速发展，引发了对大量相似练习题的强烈需求。然而，现有的关于数学问题生成的研究主要集中在为训练神经语言模型进行数据扩充，而非直接用于教育应用。因此，该文定义了一个新的任务，同构数学问题生成（IMPG），旨在生成具有结构一致性且变种后的题目。通过多次改进，该研究探索了基于LLM的自动IMPG框架，并建立了计算蓝图（CBIT），结合元级生成和模板选择性变异，CBIT保持了高数学正确性和结构一致性，同时降低了生成成本。研究结果证明，CBIT在规模上具有较高的生成准确性和成本效益。此外，通过将CBIT生成的问题部署到6,732名学习者的商业教育平台，产生了186,870次互动。", "innovation": "该文提出了一个新的任务：同构数学问题生成（IMPG），旨在生成具有结构一致性的源题变体。通过元级生成和模板选择性变异，建立了计算蓝图（CBIT），该蓝图保持了高数学正确性和结构一致性，并降低了生成成本。此外，研究通过多次改进和实验结果证明了CBIT的优越性。", "conclusion": "CBIT生成的问题在错误率上比专家编写的问题低17.8%，且在商业教育平台上的部署产生了186,870次互动。研究证明了CBIT在生成准确性和成本效益方面在大规模应用中的优越性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07936", "html_url": "https://arxiv.org/abs/2511.07936", "title": "面向实用的BCI：一种实时无线想象语音EEG解码系统", "title_en": "Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System", "authors": "Ji-Ha Park,Heon-Gyu Kwak,Gi-Hwan Shin,Yoo-In Jeon,Sun-Min Park,Ji-Yeon Hwang,Seong-Whan Lee", "background": "脑机接口（BCI）研究尽管前景广阔，但主要局限于静态和固定环境，限制了其实用性。为了向实用BCI过渡，研究引入了一种面向灵活性和日常使用的实时无线想象语音脑电（EEG）解码系统。该框架强调实用性，超越了有线EEG设备，应用于便携式无线硬件。实测表明，用户识别模块可以识别操作员并提供个性化服务。通过利用实验室流层来管理持续的实时EEG信号流至个性化解码器，实现了端到端流水线，能够从想象语音EEG信号中分类用户命令，有线设备的4类准确率为62.00%，便携无线耳机为46.67%。该研究展示了真正实用且可访问的BCI技术的重要一步，为今后研究稳健、实用和个人化神经接口指明了方向。", "innovation": "提出了一种面向灵活性和日常使用的实时无线想象语音EEG解码系统，超越了有线EEG设备，应用于便携式无线硬件的基础上实现了端到端流水线以分类用户命令。", "conclusion": "该项研究展示了真正实用且可访问的BCI技术的重要一步，为今后研究稳健、实用和个人化神经接口指明了方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07943", "html_url": "https://arxiv.org/abs/2511.07943", "title": "Thinker：通过多轮交互进行分层思考训练LLMs以进行深入搜索", "title_en": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction", "authors": "Jun Xu,Xinkai Du,Yu Ao,Peilong Zhao,Yang Li,Ling Zhong,Lin Yuan,Zhongpu Bo,Xiaorui Wang,Mengshu Sun,Zhengke Gui,Dalong Zhang,Zhaoyang Wang,Qiwei Wang,Yangyang Hou,Zhiying Yin,Haofen Wang,Huajun Chen,Lei Liang,Jun Zhou", "background": "对外部知识库和网页的有效检索对于提升LLM的推理能力至关重要。以往通过端到端强化学习训练LLM利用外部检索器解决复杂问题的工作较为常见，但这些方法忽略了对推理过程的监督，难以保证逻辑的一致性和严谨性。", "innovation": "提出了Thinker，一种分层思考模型，通过多轮交互进行深度搜索，使得推理过程可监督和验证。该模型将复杂问题分解为独立可解的子问题，每个子问题在自然语言和等效的逻辑函数之间双向表示，以支持知识库和网络搜索。此外，通过逻辑函数传递子问题间的依赖关系，增强了解题过程中的逻辑连贯性。为避免不必要的外部搜索，还进行了知识边界判断，以检查子问题是否在LLM的固有知识范围内，从而直接作答。", "conclusion": "实验证明，在少量几百度训练样本的情况下，Thinker的性能与现有基准相当。当扩展到全训练集时，在各类数据集和模型规模上，Thinker显著优于这些方法。源代码可以在以下链接获取：[此处链接]。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07968", "html_url": "https://arxiv.org/abs/2511.07968", "title": "TimeFlow：通过流动匹配建模实现对随机性的意识和高效时间序列生成", "title_en": "TimeFlow: Towards Stochastic-Aware and Efficient Time Series Generation via Flow Matching Modeling", "authors": "He Panjing,Cheng Mingyue,Li Li,Zhang XiaoHan", "background": "时间序列数据的高质量生成已经成为一个重要的研究主题，因为它在支持下游时间序列挖掘任务方面具有广泛的用途。然而，一个主要挑战在于建模时间动态的内在随机性，因为现实中的序列往往表现出随机波动和局部变化。虽然扩散模型取得了一定的成功，但其生成过程计算效率低下，通常需要成百上千次昂贵的函数评估。传统的基于普通微分方程（ODE）的流动匹配方法未能明确捕捉到随机性，从而限制了生成序列的准确性。与此相比，随机微分方程（SDE）自然适合建模随机性和不确定性，因此提出了一种基于SDE的流动匹配新框架——TimeFlow来克服这些挑战。", "innovation": "TimeFlow引入了一种基于SDE的流动匹配方法，采用编码器仅架构。它设计了一个分组件分解的算量场来捕捉时间序列多方面的结构，并通过增加一个附加的随机项增强基础流动匹配优化，以提高表达能力。TimeFlow具有灵活性和通用性，在单一框架下支持无条件和有条件生成任务。广泛的实验结果表明，在生成质量、多样性和效率方面，该模型始终优于强大的基线模型。", "conclusion": "TimeFlow通过基于SDE的流动匹配框架，在单一框架下支持无条件和有条件生成任务，具备灵活性和通用性。该模型在生成质量、多样性和效率方面均优于基线模型，实验证明其在不同数据集上都表现出色。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07973", "html_url": "https://arxiv.org/abs/2511.07973", "title": "基于图表示的心电图信号多功能和风险敏感心脏诊断", "title_en": "Versatile and Risk-Sensitive Cardiac Diagnosis via Graph-Based ECG Signal Representation", "authors": "Yue Wang,Yuyang Xu,Renjun Hu,Fanqi Shen,Hanyun Jiang,Jun Wang,Jintai Chen,Danny Z. Chen,Jian Wu,Haochao Ying", "background": "尽管深度学习已经推动了心电图（ECG）信号诊断和分析方法的快速发展，但其临床应用仍然受制于两大难题：处理具有不同配置的心电图信号的灵活性不足，以及由于样本不平衡导致的风险信号检测不充分。", "innovation": "本文提出了基于图表示的多功能和风险敏感心脏诊断（VARS），通过图结构来统一建模异质性心电图信号。VARS方法将心电图信号转换为灵活的图结构，能够捕捉关键诊断特征，不受导联数量、采样频率和时长差异的影响。这种方法还增强了诊断灵敏度，能够精确地定位和识别标准分析方法难以发现的异常心电图模式。该方法还结合了去噪重建与对比学习，既保留了原始心电图信息，又突出了病理特征。", "conclusion": "VARS在三个不同结构变化的心电图数据集上进行了严格的评估，结果表明，VARS不仅在所有数据集上都超越了现有的最先进的模型，而且在识别风险信号方面也表现出了显著的改进。此外，VARS还通过指明导致具体模型输出的精确波形提供了可解释性，有助于临床决策。这些发现表明，我们的VARS将很可能成为一个全面心脏健康管理的重要工具。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07980", "html_url": "https://arxiv.org/abs/2511.07980", "title": "交通预测中复杂时空依赖关系的捕捉：基于自注意力的方法", "title_en": "Capturing Complex Spatial-Temporal Dependencies in Traffic Forecasting: A Self-Attention Approach", "authors": "Zheng Chenghong,Zongyin Deng,Liu Cheng,Xiong Simin,Di Deshi,Li Guanyao", "background": "交通预测问题由于区域之间的复杂空间和时间相关性而变得复杂，先前的研究分别研究空间和时间依赖性，忽略了它们的联合效应。", "innovation": "提出了一种新颖且高效的时空自注意力模型ST-SAM，用于交通预测。该模型使用区域嵌入层从交通数据中学习时间特定的嵌入，然后使用自注意力机制基于的空间-时间依赖性学习模块捕捉近地和远地区域的联合时空依赖性。ST-SAM完全依赖于自注意力来捕捉局部和全局的空间-时间相关性，从而使其有效且高效。实验结果表明，与最先进的方法相比，ST-SAM在RMSE、MAPE上平均分别提高了15%和17%，训练时间缩短了32倍。", "conclusion": "ST-SAM在交通预测中表现出了显著的准确性和效率，证明了直接从复杂时空依赖性中学习的有效性，并展示了在实际数据集上的优越性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07974", "html_url": "https://arxiv.org/abs/2511.07974", "title": "向细粒度可解释性迈进：基于显著性分区的误分类反事实解释", "title_en": "Towards Fine-Grained Interpretability: Counterfactual Explanations for Misclassification with Saliency Partition", "authors": "Lintong Zhang,Kang Yin,Seong-Whan Lee", "background": "现有的基于归因的解释技术能够捕捉关键模式以提升视觉可解释性，但这些模式往往缺乏足够的细节，在精细任务中难以提供足够的洞悉，尤其在模型误分类情况下，解释可能不能详细说明问题。现有的方法无法有效解决这些细粒度偏差的问题，特别是在模型误分类时的解释不足带来了挑战。因此，研究一种能提供细粒度解释的方法对于提高模型可解释性至关重要，特别是对于图像分类等精细任务的理解和改进非常关键。", "innovation": "本文提出了一个细粒度反事实解释框架，该框架既能提供对象级别的解释，又能提供部件级别的解释，重点回答了两个核心问题：哪些细粒度特征导致了模型误分类，以及局部主导特征如何影响反事实调整。该方法通过非生成方式提供可解释的反事实，量化相似度并根据感兴趣区域内的组件贡献加权，进一步引入一个基于Shapley值贡献的显著性分区模块，将具有区域特定相关性的特征隔离出来。这种方法在捕捉更细粒度、直观有意义的区域方面表现优越，超越了现有的细粒度方法。", "conclusion": "研究结果表明，提出的细粒度反事实解释框架能够更准确地解释模型误分类的具体原因，提供更详细和直观的解释，极大地提高了模型的可解释性和用户对模型理解的深度，特别是在图像分类等精细任务中效果显著。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07988", "html_url": "https://arxiv.org/abs/2511.07988", "title": "The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends", "title_en": "The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends", "authors": "Nico Policzer,Cameron Braunstein,Mariya Toneva", "background": "近期的研究表明，将音频模型调整（brain-tune）以更好地预测相应的fMRI活动，能够提高大脑对齐度和在语义和音频任务上的性能表现。这一方法被应用于增强多模态音频-视频模型，以改善社交认知，目标是与社交处理密切相关的上象 vitae沟（STS）区域。", "innovation": "本研究将脑调制度（brain-tune）方法扩展到了多模态音频-视频模型中，针对观看《老友记》时的上象 vitae沟（STS）区域进行调优，从而提高社交认知任务中的表现，特别是综艺节目中的讽刺识别。", "conclusion": "本研究通过将多模态音频-视频模型调优至与STS相关的功能区域，成功提高了下游社交认知任务的表现，并证明了脑调制度在多模态领域中的有效应用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07979", "html_url": "https://arxiv.org/abs/2511.07979", "title": "评估多步法律推理并分析大型语言模型中的思考链效果", "title_en": "Benchmarking Multi-Step Legal Reasoning and Analyzing Chain-of-Thought Effects in Large Language Models", "authors": "Wenhan Yu,Xinbo Lin,Lanxin Ni,Jinhua Cheng,Lei Sha", "background": "大型语言模型（LLMs）已经在多个专业领域展示出了较强的推理能力，激发了其在法律推理中的应用研究。然而，现有的法律基准数据集在衡量推理能力时往往混淆了事实记忆与真正的推理，将推理过程碎片化，忽视了推理的质量。为了解决这些局限性，作者引入了MSLR，这是一个基于实际司法决策的中文多步法律推理数据集。MSLR采用IRAC框架（问题、规则、应用、结论）来构建结构化的专家推理模型，并从官方法律文件中提取。此外，作者还设计了一个可扩展的人类-LLM协作注释管道，实现在细粒度步骤层级上推理注释，并提供了一个多步推理数据集的标准方法框架。", "innovation": "MSLR是第一个基于实际司法决策的真实世界法律推理数据集，采用了IRAC框架来构建结构化的专家推理模型，并且设计了一个可扩展的人类-LLM协作注释管道来高效且细化地进行推理注释，这是对多步推理数据集注释方法的一个创新贡献。实验表明，在MSLR上的多种LLM表现中等，突显复杂法律推理的挑战。进一步的实验表明，模型自主生成的思考链提醒能提高推理一致性和质量，优于人工设计的提醒。", "conclusion": "MSLR促进了大型语言模型推理能力和思考链策略的发展，并为将来的研究提供了开放资源。数据集和代码可以在提供的链接中获取。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07994", "html_url": "https://arxiv.org/abs/2511.07994", "title": "通过路径-邻居聚合提升图神经网络的逻辑表达能力", "title_en": "Enhancing Logical Expressiveness in Graph Neural Networks via Path-Neighbor Aggregation", "authors": "Han Yu,Xiaojuan Zhao,Aiping Li,Kai Chen,Ziniu Liu,Zhichao Peng", "background": "图神经网络（GNNs）能够有效建模图结构中的信息，因此在知识图（KG）推理中得到了广泛应用。然而，现有研究主要集中在单一关系图的表达能力上，对于GNN在KG中表达逻辑规则的能力讨论还不够充分。如何增强GNN的逻辑表达能力仍然是一个关键问题。", "innovation": "本文提出了路径-邻居增强GNN（PN-GNN），通过在推理路径上聚合节点-邻居嵌入来增强GNN的逻辑表达能力。研究证明PN-GNN不仅在逻辑表达能力上严于C-GNN，而且$(k+1)$-跳逻辑表达性也优于$K$-跳。并且通过在六个合成数据集和两个真实世界数据集上评估逻辑表达能力，实验结果与理论分析一致，表明PN-GNN能够在不降低泛化能力的情况下增强逻辑规则的表达能力。", "conclusion": "通过路径-邻居聚合，PN-GNN提升了逻辑表达能力并在知识图推理任务中表现出色。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07995", "html_url": "https://arxiv.org/abs/2511.07995", "title": "基于隐马尔可夫模型的多元时间序列异常检测框架", "title_en": "Multivariate Time series Anomaly Detection:A Framework of Hidden Markov Models", "authors": "Jinbo Li,Witold Pedrycz,Iqbal Jamal", "background": "研究背景在于开发一种针对多元时间序列异常检测的方法，该方法重点在于将多元时间序列转化为一元时间序列。研究中探讨了多种变换技术，包括Fuzzy C-Means (FCM) 聚类和模糊积分，并利用隐马尔可夫模型（HMM）进行多元时间序列的异常检测。通过构建基于HMM的异常检测器来比较不同变换方法的有效性，同时进行了实验和对比分析研究研究的背景，旨在提供一种有效且实用的多元时间序列异常检测方法，应用于多种实际场景中。", "innovation": "该研究的创新之处在于提出了一种基于HMM的方法，用于检测多元时间序列的异常。研究中采用了多种变换技术，并通过实验对这些方法进行了比较分析，增加了技术的适用性和实用性。此外，该框架可以应用于各种领域，提高多元时间序列数据处理的效果和效率。", "conclusion": "研究证明，提出的方法能够有效检测多元时间序列的异常。通过与多种变换方法的比较，研究结果展示了基于HMM的异常检测器在处理复杂数据集中的优势。该方法具有广阔的应用前景，特别是在需要监控和分析大量时间序列数据的场景下。未来的研究将进一步优化算法，提高检测效率和精度。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08008", "html_url": "https://arxiv.org/abs/2511.08008", "title": "结合大型语言模型语义推理与图神经网络结构建模的多视图多标签特征选择", "title_en": "Combining LLM Semantic Reasoning with GNN Structural Modeling for Multi-view Multi-Label Feature Selection", "authors": "Zhiqi Chen,Yuzhou Liu,Jiarui Liu,Wanfu Gao", "background": "多视角多标签特征选择旨在从异构视图中识别出具有信息性的特征，其中每个样本与多个相互依赖的标签关联。这个问题在涉及高维度、多模态数据的机器学习中，如社交媒体、生物信息学或推荐系统中尤为重要。现有的多视图多标签特征选择（MVMLFS）方法主要关注数据分析的统计信息，而很少考虑语义信息。为此，本文提出了一种将大规模语言模型的语义推理与图神经网络的结构建模相结合的方法，来实现MVMLFS。", "innovation": "提出的MVMLFS方法使用大规模语言模型和图神经网络相结合，首先利用大规模语言模型评估特征、视图和标签描述之间的潜在语义相关性；设计了一个具有两个层次的语义感知异构图来表示特征、视图和标签之间的关系；并通过轻量级图注意力网络（GAT）学习异构图中节点嵌入以作为特征显著性分数进行排序和选择。实验结果证明了该方法的优势，并且即使在小规模数据集上也依旧有效，展现了其稳健性、灵活性和泛化能力。", "conclusion": "实验结果表明，该方法在多个基准数据集上的表现优于最先进的基线方法，并且在小规模数据集上仍然有效，这表明它具有稳健性、灵活性和泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08042", "html_url": "https://arxiv.org/abs/2511.08042", "title": "关于标准的企业相关代理型AI基准：55亿令牌价值代理型AI评估的经验教训", "title_en": "Towards a Standard, Enterprise-Relevant Agentic AI Benchmark: Lessons from 5.5 billion tokens' worth of agentic AI evaluations", "authors": "JV Roig", "background": "企业采用代理型AI系统需要可靠的评估方法，以反映实际部署场景。传统的大语言模型基准存在训练数据污染的问题，并不能衡量如多步骤工具使用和在不确定性下决策等代理型能力。因此，需要一种新的基准来解决这些问题。", "innovation": "本文提出了Kamiwaza Agentic Merit Index (KAMI) v0.1，这是一种面向企业的基准测试，能够抵抗数据污染并评估代理型能力。通过17万LLM测试项目，覆盖55亿个令牌，在35种模型配置中进行评估，结果显示传统的基准排名无法准确预测实际的代理型性能。新推出的模型如Llama 4或Qwen 3并不总是在企业相关任务中优于其旧版本，与传统的基准趋势相反。此外，还提出了成本性能折衷、模型特定的行为模式以及推理能力对令牌效率的影响等方面的观点。", "conclusion": "传统的基准排名无法准确预测实际的代理型性能，且新老模型在企业相关任务中的表现并不总是一致的。KAMI v0.1能够更好地评估代理型AI系统的实际性能，并帮助企业做出部署决策。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07991", "html_url": "https://arxiv.org/abs/2511.07991", "title": "VSPO: 使用LLM进行本体语义坑洞验证的基于CQ生成的方法", "title_en": "VSPO: Validating Semantic Pitfalls in Ontology via LLM-Based CQ Generation", "authors": "Hyojun Choi,Seokju Hwang,Kyong-Ho Lee", "background": "本体设计中的能效问题（CQs）对于验证本体设计至关重要。然而，手动构建CQs需要大量时间和成本，因此研究者探索了大型语言模型（LLMs）来自动化这一过程。现有的方法主要基于生成的CQs与现有数据集的相似性进行评估，但往往无法可靠地检测诸如“Misusing allValuesFrom”这样的语义缺陷。鉴于这些缺陷无法通过基于规则的方法可靠地检测，因此研究人员提出了一种新的数据集和模型，称为Validating Semantic Pitfalls in Ontology（VSPO），专门针对验证语义缺陷设计。研究者使用LLMs生成自然语言定义类和属性，并通过移除公理或改变逻辑运算符（如将并集替换为交集）来引入定义与本体之间的不一致，来模拟缺失和误用的公理。然后对LLaMA-3.1-8B-Instruct进行微调，生成验证这些语义差异的CQs。生成的CQs能够比现有的公开数据集发现更广泛类型的建模错误。微调后的模型在生成用于缺陷验证的CQs方面表现优于基线，生成的CQs的准确性和召回率分别比GPT-4.1高26%和28.2%。这项研究利用LLMs实现了自动生成TBox验证的CQs，显著减少了人工努力，同时提高了本体与专家知识之间的语义一致性。据我们所知，这是首次使用LLMs针对CQ生成中的语义缺陷验证进行的研究。", "innovation": "本文提出了一种名为VSPO的新数据集和模型，专门设计用于验证本体设计中语义缺陷。该研究使用LLMs生成自然语言定义，并通过修改定义与本体的逻辑一致性来模拟缺失和误用公理，从而生成CQs。这种方法显著提高了检测范围，并且微调后的模型在生成用于缺陷验证的CQs方面的性能优于现有基线。此外，这是首次利用LLMs来解决CQ生成中的语义缺陷验证问题的研究。", "conclusion": "本文通过提出VSPO数据集和模型，为自动生成TBox验证的CQs奠定了基础，减少了人工工作量，同时提高了本体和专家知识之间的语义一致性。这种方法能够在更广泛范围内检测到语义缺陷，并且在性能上优于现有技术。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08066", "html_url": "https://arxiv.org/abs/2511.08066", "title": "信息容量：通过文本压缩评估大型语言模型的效率", "title_en": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression", "authors": "Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "近年来，大型语言模型（LLMs）及其应用领域迅速发展，导致对计算资源的需求急剧增加。测试时的扩容进一步加剧了模型能力与资源消耗之间的矛盾，突显了提高推理效率的重要性。然而，一种能够准确反映不同模型大小和架构中LLMs效率的统一度量方法仍然缺失。", "innovation": "本文通过压缩和智能之间的关系，引入了基于文本压缩性能相对计算复杂性的模型效率度量——信息容量。实验表明，在不同系列的模型中，模型的信息容量保持一致，这使得不同系列的模型间效率对比成为可能，并且能够准确预测同一系列模型中的性能。信息容量的一个显著特征是它考虑了分词器效率，这一点在大型语言模型评估中通常被忽视。", "conclusion": "研究表明，在5个不同类型的语料库上评估了49个模型的信息容量，并观察到分词器效率、预训练数据和专家混合架构对信息容量的影响是一致的。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08022", "html_url": "https://arxiv.org/abs/2511.08022", "title": "数值敏感性和鲁棒性：探究大型语言模型在数学推理中的缺陷", "title_en": "Numerical Sensitivity and Robustness: Exploring the Flaws of Mathematical Reasoning in Large Language Models", "authors": "Zhishen Sun,Guang Dai,Ivor Tsang,Haishan Ye", "background": "大型语言模型(LLMs)在数学推理方面取得了显著进展，但它们是否真正具备数学理解能力仍有争议。本文旨在探讨此问题，通过提出一种新的扰动框架来评估LLMs在复杂环境中的推理能力，该框架通过注入附加的语义无关扰动句子，并逐步增加扰动强度来进行评估。此外，还使用核心问题指令缺失的额外扰动方法进一步分析LLMs的问题解决机制。实验结果显示，当面对不含数字的扰动语句时，LLMs表现稳定，但在扰动强度增加时，性能会不同程度地下降；面对含有数字的扰动语句时，性能下降更为明显，大多数开源小参数模型下降近或超过10%，进一步增加扰动强度，最大下降幅度达到51.55%。即便是最先进的商业LLMs，性能也下降了3%-10%。", "innovation": "本文提出了一种新的扰动框架，通过注入附加的语义无关扰动句子和核心问题指令缺失的方法，评估LLMs的推理能力，并分析其问题解决机制和在不同扰动强度下的鲁棒性。通过实验发现，LLMs对含有数字信息的扰动更加敏感，在受到无关数字信息干扰时更可能给出错误答案。此外，当缺少核心问题指令时，模型仍然能够维持20%-40%的准确率，表明LLMs可能依赖记忆模板或模式匹配完成任务，而非逻辑推理。", "conclusion": "本文揭示了当前LLMs在推理能力方面的不足与局限性，这对LLMs的进一步发展具有重大意义。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08055", "html_url": "https://arxiv.org/abs/2511.08055", "title": "MSCR：使用多源候选替换探索LLMs在数学推理能力方面的脆弱性", "title_en": "MSCR: Exploring the Vulnerability of LLMs' Mathematical Reasoning Abilities Using Multi-Source Candidate Replacement", "authors": "Zhishen Sun,Guang Dai,Haishan Ye", "background": "LLMs在复杂的任务如数学推理上表现出人类相当的性能，但在应对小输入扰动时的鲁棒性不足，缺乏系统研究。现有方法普遍面临扩展性差、语义保护弱和成本高的问题。", "innovation": "提出了一种基于多来源候选替换的自动对抗攻击方法MSCR，通过结合词嵌入空间余弦相似度、WordNet词典和掩码语言模型的上下文预测，为每个输入问题的单词生成一组语义相似的候选词，然后过滤和替换一个一个单词进行攻击。在GSM8K和MATH500基准上进行大规模实验，结果显示输入扰动（一个词语的改变）能够显著减少所有模型的准确性，最大下降幅度达49.89%（GSM8K）和35.40%（MATH500），同时保问题的高语义一致性。进一步分析表明，扰动不仅导致错误输出，还大幅增加了平均响应长度，产生更多的冗余推理路径并增加计算资源消耗。", "conclusion": "这些发现凸显了当前LLMs在数学推理任务中的鲁棒性不足和效率瓶颈。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08024", "html_url": "https://arxiv.org/abs/2511.08024", "title": "知识增强的长逐步推理解释生成方法在复杂生物分子推理中的应用", "title_en": "Knowledge-Augmented Long-CoT Generation for Complex Biomolecular Reasoning", "authors": "Tianwen Lyu,Xiang Zhuang,Keyan Ding,Xinzhe Cao,Lei Liang,Wei Zhao,Qiang Zhang,Huajun Chen", "background": "理解复杂的生物分子机制需要跨分子相互作用、信号级联和代谢途径的多步推理。大规模语言模型在这些任务中表现出了希望，但其应用于生物分子问题受到逻辑不一致性和缺乏领域知识锚定的阻碍。现有方法往往加剧了这些问题：推理步骤可能会偏离生物事实，或未能捕捉到长机制性依赖。", "innovation": "提出了一种知识增强的长逐步推理解释框架，该框架将大规模语言模型与基于知识图谱的多跳推理链结合。该框架通过指导式的多跳遍历和修剪来构建机制链，并将其纳入监督微调中以提高事实嵌入性，进一步通过强化学习进行优化，以增强推理的可靠性和一致性。此外，为了克服现有基准通常在规模和范围上受限且缺乏针对深度推理链的注释的问题，引入了PrimeKGQA，这是一个全面的生物分子问答基准。", "conclusion": "实验结果表明，尽管大型私人模型在相对简单的任务上仍然表现出色，但随着推理深度的增加，我们的方法展现出明显的优势，特别是在需要遍历结构化生物知识的多跳任务上达到了最先进的性能。这些发现突出了结合结构化知识和先进推理策略的可靠性与可解释性生物分子推理的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08072", "html_url": "https://arxiv.org/abs/2511.08072", "title": "基于聚类的多变量时间序列数据异常检测", "title_en": "Clustering-based Anomaly Detection in Multivariate Time Series Data", "authors": "Jinbo Li,Hesam Izakian,Witold Pedrycz,Iqbal Jamal", "background": "多变量时间序列数据包括描述某一特定时间现象不同方面的多条时间序列。这种类型数据中的异常检测是一项富有挑战性的任务，但在科学、工程等领域有广泛的应用，因为异常分数来自于同时考虑时间关系和变量关系的综合考量。", "innovation": "本文提出了一种基于聚类的方法来检测多变量时间序列中的异常，涉及幅度和形状。首先，使用移动窗口生成多变量子序列集；然后应用扩展的模糊聚类揭示生成的多变量子序列中的潜在结构；最后，使用重建准则以最优聚类中心和分区矩阵来重构多变量子序列。通过粒子群优化算法优化异常检测问题。实验研究结果表明，提出的算法能够在多变量时间序列中检测异常，并且利用扩展模糊聚类揭示的可用聚类可以检测出多变量时间序列的异常幅度和形状模式，适用于健康护理、天气数据分析、金融及疾病暴发检测等领域。", "conclusion": "文章提出了一种基于聚类的方法来检测多变量时间序列数据中的异常，能够有效识别异常幅度和形状模式，并适用于多种应用场景。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08052", "html_url": "https://arxiv.org/abs/2511.08052", "title": "增强LLM代码调试的双过程支撑推理", "title_en": "Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging", "authors": "Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang", "background": "近年来，大型语言模型（LLMs）在各类基准测试上展示了复杂的推理解决问题能力，这主要得益于先进的推理算法。然而，如何在复杂性和计算效率之间找到平衡的推理步骤依然是一个未解的科研问题。近年来，研究者越来越多地借鉴心理学理论来探索优化认知路径的策略。尽管将LLM的最终输出和中间步骤分别视为系统1和系统2的做法已被接受，但系统2的推理机制依然缺乏深入研究。因此，本文提出了一种新的基于心理学的支撑推理框架，称为Scaffold Reasoning框架，该框架包含支撑流（Scaffold Stream）、分析流（Analytic Stream）和整合流（Integration Stream）三个组件。该框架在DebugBench基准测试上实现了88.91%的通过率和平均每题5.36秒的推理时间，相较于其他推理方法，它在推理准确性和效率上均表现出色。进一步分析发现，该方法在不同问题难度和不同类型错误上的优势和局限性，并且证明该框架与人类认知过程高度契合。", "innovation": "本文提出了一种名为Scaffold Reasoning的新框架，该框架结合了支撑流、分析流和整合流三个部分，将参考代码的建立与错误代码分析结果的生成通过整合流进行连接。该框架在DebugBench上取得了显著的性能提升，其通过率和推理速度都优于其他方法。此外，该框架还得到了进一步分析的验证，能够揭示不同认知路径在各种问题难度和错误类型下的优势和局限性，并证明了其与人类认知过程的高度一致性。", "conclusion": "本文提出并详细介绍了Scaffold Reasoning框架，该框架通过结合支撑流、分析流和整合流三个部分，在代码调试任务中展示了卓越的性能。进一步的分析和实验验证了该方法的有效性和适用性，同时也指出了一些需要改进的地方。这一方法不仅具有提升LLM代码调试能力的应用价值，也为理解人类认知过程提供了新的视角。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08091", "html_url": "https://arxiv.org/abs/2511.08091", "title": "Satisfiability in Pearl's Causal Hierarchy 的可解决性之路", "title_en": "Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy", "authors": "Robert Ganian,Marlene Gründel,Simon Wietheger", "background": "Pearl的因果层次（PCH）是用于推理概率、干预和反事实陈述的核心框架，但在几乎所有经典设置下，PCH公式的可满足性问题本质上是计算不可行的。本文通过参数化复杂性视角重新审视这一挑战，首次确定了解决此问题的切入点。这些结果包括使用基础树宽度和变量数量等参数的固定参数和XP算法，以及匹配的难度结果，表明了解决问题的边界。", "innovation": "本文的技术创新在于，作者们从通常用于基于树宽度算法的动态规划范式中脱离出来，转而利用良好定义的因果模型的结构性特征，从而为因果推理提供了一个新的算法工具包。", "conclusion": "研究确定了PCH公式的可解决性问题中的一些特定参数化问题及其对应的复杂性结果，提出了固定参数和XP算法来处理关键的概率和反事实片段，并提供了匹配的难度结果来界定解决这些特定问题的极限。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08082", "html_url": "https://arxiv.org/abs/2511.08082", "title": "大型语言模型在再保险中的审慎可靠性：治理、保证与资本效率", "title_en": "Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency", "authors": "Stella C. Dong", "background": "本文开发了一个审慎框架，用于评估大型语言模型（LLMs）在再保险中的可靠性。本文基于Solvency II、SR 11-7以及来自EIOPA、NAIC和IAIS的指导措施，提出了一个由治理、数据溯源、保障、韧性以及监管一致性构成的五支柱架构。这些架构将监管期望转化为可量化的生命周期控制措施，旨在衡量和保证LLMs的有效性与合规性。研究通过Reinsurance AI Reliability and Assurance Benchmark（RAIRAB）评估LMLs在治理模块中的性能，结果显示在六个任务家族中，基于检索的配置在接地精度、减少幻觉和解释脱轨方面均表现出明显优势。", "innovation": "提出了一个全面的审慎框架，通过五支柱架构将监管期望转化为可量化的生命周期控制措施，特别是在治理、数据溯源、保障、韧性以及监管一致性方面，有效评估了大型语言模型在再保险中的可靠性，并开发了Reinsurance AI Reliability and Assurance Benchmark（RAIRAB），以系统性地评测这些模型。", "conclusion": "通过RAIRAB评测的数据显示，基于治理嵌入的LLMs在多个关键指标上表现优异，有效降低了信息摩擦，提高了风险转移和资本配置的效率。研究指出现有的审慎原则已经为可靠的AI提供了空间，只要治理体系明确、数据可追溯且保证机制可验证即可。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08117", "html_url": "https://arxiv.org/abs/2511.08117", "title": "工业注射成型中合成数据提取进展", "title_en": "Advancements in synthetic data extraction for industrial injection molding", "authors": "Georg Rottenwalter,Marcel Tilly,Christian Bielenberg,Katharina Obermeier", "background": "机器学习在优化各种工业过程中具有显著潜力，但数据获取仍然是主要挑战，因为这是既耗时又昂贵的。合成数据提供了一种有望通过增强不足的数据集并提高机器学习模型的稳健性来解决问题的方法。先前的研究表明，合成数据的引入能够在一定程度上解决数据不足的问题。", "innovation": "本文研究了将合成数据纳入注射成型过程现有长短期记忆（LSTM）架构训练过程的可行性。通过模拟生产周期生成合成数据，并将其纳入训练数据集。通过不同比例的合成数据进行迭代实验，试图找到一种平衡，既能最大化合成数据的益处，又能保持真实数据的权威性和相关性。该方法为数据收集和维护困难或昂贵的情况提供了有价值的替代方案。", "conclusion": "合成数据的引入可以提高模型在处理不同情境方面的能力，并具有实际工业应用潜力，能够减少人工劳动、机器使用和材料浪费。这种方法在未来能够促进更高效的制造过程，有助于解决数据采集和维护困难的问题。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08168", "html_url": "https://arxiv.org/abs/2511.08168", "title": "oboro: 使用基于流的扩散变换器和MMH注意力机制在有限数据上的文本到图像合成", "title_en": "oboro: Text-to-Image Synthesis on Limited Data using Flow-based Diffusion Transformer with MMH Attention", "authors": "Ryusuke Mizutani,Kazuaki Matano,Tsugumi Kadowaki,Haruki Tenya,Layris,nuigurumi,Koki Hashimoto,Yu Tanaka", "background": "该项目是在日本经济产业省（METI）和新能源与工业技术发展组织（NEDO）资助的“具有竞争力生成型AI基础模型的后5G信息与通信系统基础设施增强研发项目”中的第二学期采用项目。为了解决日本动漫生产行业面临的劳动力短缺问题，该项目旨在从零开始开发图像生成模型。", "innovation": "该项目开发了名为“oboro:”的新图像生成模型，仅使用版权清除的图像进行训练。该模型的关键特点是其架构设计，即使在少数数据集的情况下也能生成高质量的图像。此外，该项目还标志着日本首次发布了开源且商业化的图像生成AI系统。", "conclusion": "通过保持开发过程的透明性，我们希望为日本的AI研究人员和工程师社区做出贡献，并推动国内的AI开发生态系统。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08172", "html_url": "https://arxiv.org/abs/2511.08172", "title": "高效的图形用户界面代理推理训练管道", "title_en": "An Efficient Training Pipeline for Reasoning Graphical User Interface Agents", "authors": "Georgios Pantazopoulos,Eda B. Özyiğit", "background": "视觉定位是指从自然语言查询中定位图像区域的任务，对于具备推理能力的图形用户界面代理来说至关重要。现有的许多方法依赖于大量、嘈杂的合成数据。本文介绍了一种高效的训练管道，结合基于模型的数据过滤与参数高效的微调。", "innovation": "该方法从480万合成例子中筛选出12000个干净且多样的样本，通过识别难题案例、移除对齐错误，最终选取多样化的多模态实例。在此基础上，一个3亿参数的视觉-语言模型在三个训练模式下进行了训练：监督微调、带有思考链的增强微调以及通过组相对策略优化的强化学习。利用筛选后数据和轻量型训练策略训练的模型在ScreenSpot、Multimodal-Mind2Web和AndroidControl等基准测试中达到了或超过了更大的基线模型。", "conclusion": "有原则的数据筛选和稳健的适应性训练能够与大型训练抗衡，从而实现规模较小但性能强大的多模态推理代理。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08151", "html_url": "https://arxiv.org/abs/2511.08151", "title": "SciAgent: 一个通用型科学推理的统一多智能体系统", "title_en": "SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning", "authors": "Xuchen Li,Ruitao Wu,Xuanbo Liu,Xukai Wang,Jinbo Hu,Zhixin Bai,Bohan Zeng,Hao Liang,Leheng Chen,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Xu-Yao Zhang,Liu Liu,Jia Li,Kaiqi Huang,Jiahao Xu,Haitao Mi,Wentao Zhang,Bin Dong", "background": "最近，大规模语言模型的发展使得AI系统能够在特定领域的科学任务上达到专家级别的性能，但这些系统仍然狭窄且需要人工定制。本文背景在于开发一种统一的多智能体系统，以实现跨学科、跨难度层次的科学推理能力。", "innovation": "SciAgent 是一个统一的多智能体系统，旨在进行通用型科学推理。它将问题解决过程组织为层次化的流程：协调者智能体解释每个问题的领域和复杂性，并动态调度专门的工人系统，这些系统由相互作用的不同类型的子智能体组成，包括符号推理、概念建模、数值计算和验证。这些智能体协同工作，为每个任务构建和改进合适的推理管道。", "conclusion": "SciAgent 在数学和物理奥林匹克竞赛中表现出色，甚至超越了人类金牌选手的水平，证明了其在不同科学领域的通用性和推理适应性。此外，SciAgent 还在国际化学奥林匹克竞赛和人类最后一次考试基准题库的测试中展示了其泛化能力。这项工作为通用型科学智能的发展奠定了基础，即能够在跨学科领域进行高级推理的AI系统。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08108", "html_url": "https://arxiv.org/abs/2511.08108", "title": "使用可解释的人工智能改进注塑成型过程的质量分类", "title_en": "Improving Industrial Injection Molding Processes with Explainable AI for Quality Classification", "authors": "Georg Rottenwalter,Marcel Tilly,Victor Owolabi", "background": "机器学习是优化工业质量控制过程的重要工具，但由于模型复杂性导致的不透明性限制了其实际应用。许多工业机器缺乏全面的传感器技术，导致数据收集不完整且困难。可解释的人工智能提供了解决方案，通过提供对模型决策的理解和识别分类中最重要的特征，解决了这一问题。本文研究了使用XAI技术减少特征对注塑零件质量分类的影响，并通过应用SHAP、Grad-CAM和LIME分析能够提高长短期记忆模型在实际生产数据上的特征重要性。通过将原始19个输入特征减少到9个和6个，评估了模型准确率、推理速度和可解释性的权衡。研究结果表明，减少特征可以提高泛化能力，同时保持高质量分类性能，并且推理速度略有提高。这种方法增强了基于AI的质量控制可行性，特别是在传感器能力有限的工业环境中，并为更高效和可解释的制造中机器学习应用铺平了道路。", "innovation": "本文通过使用SHAP、Grad-CAM和LIME等XAI技术，对长短期记忆模型进行特征重要性分析，并将原始19个输入特征减少到9个和6个，来探讨减少特征对模型准确率、推理速度和可解释性的权衡，展示了在工业质量控制领域中，减少特征可以提高泛化能力并维持高质量分类性能，同时稍微提高推理速度。这种方法为传感器能力有限的工业环境中的质量控制提供了更好的可行性和可解释性解决方案，为制造中的机器学习应用铺平了道路。", "conclusion": "通过减少特征数量，本文的方法既改善了模型的泛化能力，又保持了高质量分类性能，同时略微提高了推理速度。这为传感器能力较低的工业环境中的质量控制提供了可行性更高的解决方案，并为制造中的机器学习应用开辟了新途径。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08217", "html_url": "https://arxiv.org/abs/2511.08217", "title": "MADD：多智能体药物发现管弦乐团", "title_en": "MADD: Multi-Agent Drug Discovery Orchestra", "authors": "Gleb V. Solovev,Alina B. Zhidkovskaya,Anastasia Orlova,Nina Gubina,Anastasia Vepreva,Rodion Golovinskii,Ilya Tonkii,Ivan Dubrovsky,Ivan Gurev,Dmitry Gilemkhanov,Denis Chistiakov,Timur A. Aliev,Ivan Poddiakov,Galina Zubkova,Ekaterina V. Skorb,Vladimir Vinogradov,Alexander Boukhanovsky,Nikolay Nikitin,Andrei Dmitrenko,Anna Kalyuzhnaya,Andrey Savchenko", "background": "早期药物发现中的筛选靶点识别是核心挑战，历来需要大量的实验资源。最近的人工智能进展，尤其是大型语言模型（LLMs），使虚拟筛选方法能够降低费用并提高效率。然而，这些工具的复杂性增加限制了它们对湿实验研究人员的可用性。多智能体系统通过结合LLMs的可解释性和专门模型的精确度，提供了一个有希望的解决方案。", "innovation": "我们提出了一种名为MADD的多智能体系统，它能够从自然语言查询中构建和执行定制的筛选管道。MADD employs四个协调的智能体来处理新颖化合物生成和筛选中的关键子任务。在七个药物发现案例中，MADD的性能优于现有的基于LLM的方法，并首次将AI主导的药物设计应用于五个生物靶点，发布了筛选出的化合物。此外，引入了一个新的查询-分子对和对接评分基准，包含超过三百万种化合物，以促进药物设计的自主未来的发展。", "conclusion": "MADD展示了多智能体系统在药物发现上的潜力，通过对接多个智能体来优化筛选过程，提供了优于现有方法的性能，并为药物设计的未来奠定了新的基准。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08206", "html_url": "https://arxiv.org/abs/2511.08206", "title": "EHRStruct: 构建全面的评估框架，用于评估大型语言模型在结构化电子健康记录任务中的表现", "title_en": "EHRStruct: A Comprehensive Benchmark Framework for Evaluating Large Language Models on Structured Electronic Health Record Tasks", "authors": "Xiao Yang,Xuejiao Zhao,Zhiqi Shen", "background": "结构化电子健康记录（EHR）数据存储患者的个人信息，在临床决策中扮演核心角色。近年来，大型语言模型（LLMs）被用于处理这些数据，并在多个临床场景中展现出潜力。然而，缺乏标准化的评估框架和明确的任务定义使得系统地评估和比较LLM在结构化EHR数据上的性能变得困难。", "innovation": "该论文引入了EHRStruct基准，专门用于评估LLM在结构化EHR任务上的表现。EHRStruct定义了11个代表性的任务，涵盖了多样的临床需求，并包括来自两个广泛使用的EHR的数据源衍生出的2,200个任务特定评估样本。此外，该研究评估了20种先进的和代表性LLM，涵盖了通用和医疗领域的方法。进一步分析了影响模型性能的关键因素，包括输入格式、少量样本泛化和微调策略，并与11种最先进的基于LLM的结构化数据推理增强方法进行了比较。研究结果表明，许多结构化EHR任务对理解和推理能力有很高的要求。因此，作者提出了EHRMaster，这是一种代码增强的方法，实现了最先进的性能并提供了实际。", "conclusion": "研究展示了EHRStruct作为评估LLM在结构化EHR任务上性能的重要工具，强调了理解和推理能力的重要性，并提出了EHRMaster方法作为先进的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08132", "html_url": "https://arxiv.org/abs/2511.08132", "title": "国家老龄化研究所 PREPARE 挑战赛：使用言语进行认知障碍早期检测 - SpeechCARE 解决方案", "title_en": "National Institute on Aging PREPARE Challenge: Early Detection of Cognitive Impairment Using Speech - The SpeechCARE Solution", "authors": "Maryam Zolnoori,Hossein Azadmaleki,Yasaman Haghbin,Ali Zolnour,Mohammad Javad Momeni Nezhad,Sina Rashidi,Mehdi Naserian,Elyas Esmaeili,Sepehr Karimi Arpanahi", "background": "阿尔茨海默病及相关痴呆（ADRD）影响60岁以上人群中超过五分之一的成年人，但超过一半有认知下降的人并未被诊断。虽然基于语音的评估显示出早期检测的潜力，因为语音中的音素运动规划缺陷会影响音高和音调等声学特征，而记忆和语言障碍会导致句法和语义错误。然而，传统的语音处理流水线通常表现出限的性能和泛化能力。这主要是因为它们使用手工设计的特征或通用的音频分类器，难以捕捉与认知损害相关的微妙的语音线索。为了解决这些问题，本文介绍了一种名为SpeechCARE的多模态语音处理流水线，该流水线利用预训练的多语言声学和语言变换器模型来捕捉认知损害相关的微妙语音线索。", "innovation": "SpeechCARE集成了多语言和多功能的变换器模型，采用动态融合架构，能够动态加权基于变换器的声学、语言和人口统计学输入，从而可以在任务中整合附加模态，并增强不同任务中的鲁棒性。SpeechCARE还包含鲁棒预处理，包括自动转录、大语言模型（LLM）异常检测以及任务识别。通过基于SHAP的可解释性模块和LLM推理，强调每个模态对决策的影响。这些方法共同提升了早期检测的准确性与公平性，尽管在80岁以上人群中存在轻微的偏差，但仍通过过采样和加权损失进行缓解。未来研究包括将其在实际医疗环境中的部署（如VNS Health、哥伦比亚ADRC）以及与电子健康记录（EHR）集成的解释性方法，以更好地服务于纽约市的非代表性人群。", "conclusion": "SpeechCARE通过利用预训练的多语言和多模态变换器模型，实现了出色的诊断性能，对于认知健康、MCI和AD个体的AUC分别为0.88和0.90，F1分数分别为0.72和0.62。这种方法还展示了强大的公平性，尽管存在年龄相关的轻微偏差，但仍通过进一步的技术措施得到了改进。未来的工作将致力于在真实世界的医疗环境中部署这种解决方案，并在代表性不足的人群中进一步研究其效果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08191", "html_url": "https://arxiv.org/abs/2511.08191", "title": "通过贝叶斯误差优化实现可证明不可学习示例的研究", "title_en": "Towards Provably Unlearnable Examples via Bayes Error Optimisation", "authors": "Ruihan Zhang,Jun Sun,Ee-Peng Lim,Peixin Zhang", "background": "机器学习模型，尤其是大规模分类器和语言模型的成功依赖于大量数据的训练，这些数据通常来自在线源。这引发了关于用户数据保护的严重关切，因为个人可能没有同意其数据用于训练。为了应对这一问题，最近的研究引入了不可学习示例的概念，即看似自然但实际上故意改动的数据实例，以防止模型从它们中有效学习。尽管现有方法在实际上表现出有效性，但它们通常依赖于启发式试验且缺乏形式保证。此外，当不可学习示例与清洁数据混合时，其不可学习性会消失。本文提出了一种通过系统最大化贝叶斯误差来构建不可学习示例的新方法，贝叶斯误差是不可归约分类错误的衡量标准。本文提出了一个基于优化的方法，并使用投影梯度上升提供了高效的解决方案。", "innovation": "本文提出了一种新的方法，通过系统最大化贝叶斯误差来构建不可学习示例，有效地解决了不可学习示例在混合清洁数据时不可学习性消失的问题，并提供了形式上的保证。相比现有方法，该方法在理论上和实验上都表明了潜在的有效性，不受可学习示例与清洁样本混合的影响。", "conclusion": "本文通过贝叶斯误差优化方法提出了不可学习示例的构建，证明了该方法能够有效地提高贝叶斯误差，并保持其有效性直至与清洁样本混合。实验结果在多个数据集和模型架构上的一致性验证了理论分析的有效性和该方法的实际应用效果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08246", "html_url": "https://arxiv.org/abs/2511.08246", "title": "多种-shot 多模态上下文学习中的何者与为何：基于灵敏性感知的任务向量", "title_en": "Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning", "authors": "Ziyu Ma,Chenhui Gou,Yiming Hu,Yong Wang,Xiangxiang Chu,Bohan Zhuang,Jianfei Cai", "background": "大规模多模态模型（LMMs）展现了有希望的上下文适应学习（ICL）能力，但在许多-shot 设置下的扩展仍然困难，原因在于有限的上下文长度和高推理成本。任务向量方法通过将多种-shot 上下文演示的紧凑表示插入模型激活中以应对这些挑战已得到探索，但现有方法要么忽略了插入位置的重要性，要么难以为每个位置确定合适的值。", "innovation": "提出了一种新颖的基于灵敏性感知的任务向量插入框架（STV），以确定在哪里和插入什么。这项工作的关键洞察是查询-上下文对的激活差值表现出一致的结构模式，这为插入提供了一个可靠的线索。基于识别出的灵敏性感知的位置，通过聚类构建每个位置的预聚类激活库，并使用强化学习选择最合适的插入项。", "conclusion": "STV 在多种多模态模型（例如 Qwen-VL，Idefics-2）和任务（例如 VizWiz，OK-VQA）中进行了评估，显示出其有效性，并且在以前的任务向量方法上显示出一致的改进，具有强大的泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08242", "html_url": "https://arxiv.org/abs/2511.08242", "title": "朝向目标导向且任务无关的AI代理评估", "title_en": "Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents", "authors": "Waseem AlShikh,Muayad Sayed Ali,Brian Kennedy,Dmytro Mozolevskyi", "background": "随着人工智能代理在各行各业和应用中的日益普及，仅通过延迟、首个令牌时间或令牌吞吐量等基础设施指标来评估其性能已经变得不足。这些指标未能捕捉代理决策的质量、操作自主性或其最终的业务价值。本文提出了一种全新的、全面的框架，包括11个基于结果、任务无关的性能指标，超越了行业界限。这些指标旨在使组织能够根据决策质量、自主性程度、应对新挑战的适应性以及实际的业务价值来评估代理，而不是依赖于底层模型架构或特定应用场景。通过大规模模拟实验，涉及四种不同的代理架构（ReAct、思维链条、工具增强、混合）在五个不同的领域（医疗保健、金融、市场营销、法律和客户服务），证明了该框架的有效性。结果表明了不同代理设计之间的显著性能权衡，特别指出混合代理在大多数提议指标中表现出最稳定的高性能，平均目标完成率为88.8%，投资回报率最高。", "innovation": "提出了一种全新的、全面的框架，包括11个基于结果、任务无关的性能指标，超越了行业界限。这些指标包括目标完成率（GCR）、自主性指数（AIx）、多步任务韧性（MTR）和业务影响效率（BIE）。此外，通过大规模模拟实验展示了该框架的有效性，并揭示了不同代理设计之间的显著性能权衡，特别指出混合模型在性能上的优势。", "conclusion": "本文提供了一种强大的、标准化的方法，用于全面评估AI代理，为更有效的开发、部署和治理铺平了道路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08274", "html_url": "https://arxiv.org/abs/2511.08274", "title": "Multi-Agent GraphRAG：面向标记属性图的文本到Cypher框架", "title_en": "Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs", "authors": "Anton Gusarov,Anastasia Volkova,Valentin Khrulkov,Andrey Kuznetsov,Evgenii Maslov,Ivan Oseledets", "background": "随着检索增强生成（RAG）方法通常从非结构化文档中提取信息，新的GraphRAG范式正致力于利用结构化数据，例如知识图谱。现有GraphRAG研究主要集中在资源描述框架（RDF）知识图谱上，依赖于三元组表示和SPARQL查询，但Cypher和标记属性图（LPG）数据库在支持可扩展和高效推理引擎方面的作用在当前研究文献中尚未被充分探索。因此，该文提出了一种基于多代理的GraphRAG系统，即Multi-Agent GraphRAG，用于从文本自动生成Cypher查询，作为LPG图数据的自然语言接口。", "innovation": "Multi-Agent GraphRAG系统是一种模块化的LLM代理系统，能够自动生成和执行Cypher查询，并通过混合反馈回路实现语义和语法的校正和规范化。该系统采用Memgraph作为后端图数据库，首次在GraphRAG框架中利用Cypher和LPG数据库的支持，用于生成和执行Cypher查询。", "conclusion": "通过在CypherBench图数据集和基于IFC数据的建筑数字孪生图上评估该系统，证明了新型工作流程在生成和执行Cypher查询方面具有优良性能，从而展示了如何将AI与大规模的实际应用结合，推动工业数字自动化用例的发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08234", "html_url": "https://arxiv.org/abs/2511.08234", "title": "超越分布：连续强化学习中的几何动作控制", "title_en": "Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning", "authors": "Zhihao Lin", "background": "连续控制在深度强化学习中的应用主要依赖于高斯策略，但高斯策略存在先天的不匹配问题：其无限支持需要采用复杂的挤压函数来适应有界动作空间，这会曲解动作空间的几何特性。虽然 von Mises-Fisher (vMF) 分布为球面上的行为提供了理论基础的替代方案，但它们依赖于贝塞尔函数和拒绝采样方法，阻碍了实际应用的普及。现有的方法未能简化计算并保持球形分布的几何优点。", "innovation": "本文提出了几何动作控制（Geometric Action Control, GAC），它寻求保持球形分布的几何优势的同时简化计算。GAC 将动作生成分解为方向向量和可学习的集中参数，这使动作生成能够在确定性动作和均匀球形噪声之间实现高效插值。与 vMF 分布的拒绝采样方法相比，GAC 的设计将参数数量从 2d 减少到 d+1，避免了 O(dk) 的复杂度，实现了简单 O(d) 的操作。通过在六个 MuJoCo 基准测试中的实验，GAC 不仅表现与当前最先进的方法相当或更好，并且在四项任务上达到最佳结果，特别是在 Ant-v4 上取得 37.6% 的改进。", "conclusion": "我们的消融研究揭示了 GAC 的成功离不开球形标准化和自适应集中控制。这些发现表明，强大的和高效的连续控制不需要复杂的分布，但需要对动作空间的几何特性进行合乎原理的尊重。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08283", "html_url": "https://arxiv.org/abs/2511.08283", "title": "DiagramIR: 教育数学图表自动评估流水线", "title_en": "DiagramIR: An Automatic Pipeline for Educational Math Diagram Evaluation", "authors": "Vishal Kumar,Shubhra Mishra,Rebecca Hao,Rizwaan Malik,David Broman,Dorottya Demszky", "background": "大型语言模型（LLMs）正日益成为学习的工具，但大多数工具仅限于文本形式，限制了它们在需要可视化，如数学等领域的应用。尽管研究表明LLMs可以生成能够编译教育图表的代码，但这些图表的可扩展评价仍然是一个瓶颈。本文基于LaTeX TikZ代码的中间表示方法，提出了一种可以自动且可扩展地评价几何图表的方法，名为DiagramIR。该方法通过比较不同的评估基准，证明了其与人工评分的高度一致性，并且较小的模型如GPT-4.1-Mini在较低的推理成本下能够与较大的模型如GPT-5表现相当。", "innovation": "提出了DiagramIR：一种基于LaTeX TikZ代码中间表示的自动且可扩展的几何图表评价流水线。该方法展示了其比人工评分更一致，并且小型模型能够在更低的推理成本下与大型模型具有相当的表现。", "conclusion": "该评价方法使得较小的模型像GPT-4.1-Mini能够在比现有模型低10倍的推理成本下与GPT-5在评估图表上表现相当。这对于部署可访问且可扩展的教育技术非常重要。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08343", "html_url": "https://arxiv.org/abs/2511.08343", "title": "JobSphere：政府就业平台的AI驱动多语言职业副驾", "title_en": "JobSphere: An AI-Powered Multilingual Career Copilot for Government Employment Platforms", "authors": "Srihari R,Adarsha B V,Mohammed Usman Hussain,Shweta Singh", "background": "政府就业网站的用户经常面临导航复杂性、语言选项有限以及缺乏个性化支持所带来的互动和访问障碍。", "innovation": "JobSphere是一种基于检索增强生成（RAG）架构的AI职业助手，可实现多语言服务，支持英语、印地语和旁遮普语，并利用4位量化技术降低了实施成本。JobSphere的主要创新包括语音交互功能、自动化模拟测试、技能识别简历解析以及基于嵌入式推荐的工作推荐，实现了在前10项中的68%精度。", "conclusion": "JobSphere有效地填补了安 Biblical Region/印地语使用者在农村地区的重要访问空白，同时确保了由政府机构提供可信的就业内容。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08301", "html_url": "https://arxiv.org/abs/2511.08301", "title": "携手更聪明：通过共享体验学习创建代理性的实践社区", "title_en": "Smarter Together: Creating Agentic Communities of Practice through Shared Experiential Learning", "authors": "Valentin Tablan,Scott Taylor,Gabriel Hurtado,Kristoffer Bernhem,Anders Uhrenholt,Gabriele Farei,Karo Moilanen", "background": "随着从以人为中心向以代理为中心的软件开发实践过渡，现有的软件开发者知识共享环境正面临颠覆。传统的同行对等存储库和开发者社区在短时间内见证了参与度的急剧下降。与此同时，代理的等效功能尚未出现，导致已经生成大量软件代码的AI代理缺乏访问有价值的共享学习存储库的途径。", "innovation": "本文介绍了一种名为Spark的新型共享代理记忆架构，旨在模拟人类开发者社区的集体智慧和知识。Spark允许AI编程代理参与到持续演变的经验记忆中，并为在同一通用问题空间内的代理提供了一个新知识的存储库，以实现集体持续学习。通过将Spark作为AI编程代理的教练进行评估，结果显示，来自Spark的建议可以改善不同大小和能力级别的通用代码生成模型生成的代码质量。有助于公平竞争的模型在AI代理执行软件开发任务方面映射出更高的代码质量。此外，研究还测量了Spark生成的建议的内在质量，达到了高达98.2%的帮助水平。", "conclusion": "通过利用Spark作为教练，AI编程代理不仅能够提高代码质量，还能够广泛地从共享经验记忆中受益，从而促进代理之间的知识积累和集体学习。这表明，共享代理记忆能够成为促进代理性实践社区自组织和持续增长的关键。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08379", "html_url": "https://arxiv.org/abs/2511.08379", "title": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models", "title_en": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models", "authors": "Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio", "background": "该论文背景在于现有研究将拒绝行为编码为模型潜在空间中的单一方向，并通过计算有害和无害提示表示之间的质心差异来实现。然而，新证据表明，LLM中的概念往往以低维流形形式嵌入到高维潜在空间中。受此发现启发，论文提出了一种利用自组织图(SOMs)提取多个拒绝方向的新方法。", "innovation": "该创新之处在于提出了利用SOMs提取多个拒绝方向的新方法，证明SOMs可以推广先前的均值差异技术；并通过训练SOMs识别有害提示表示中的多个神经元，计算出表达拒绝概念的多个方向。实验表明，从模型内部消除多个方向可以有效抑制拒绝，优于单一方向基线和专门的反向破解算法。", "conclusion": "该方法通过分析自组织图(SOMs)来提取多个拒绝方向，验证了其在大规模实验中的有效性，表明从模型内部消除多个拒绝方向能更有效地抑制有害提示，具有显著的机制性影响。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08363", "html_url": "https://arxiv.org/abs/2511.08363", "title": "AI驱动的数据可视化平台：一种智能化的Web应用进行自动数据集分析", "title_en": "AI-Powered Data Visualization Platform: An Intelligent Web Application for Automated Dataset Analysis", "authors": "Srihari R,Pallavi M,Tejaswini S,Vaishnavi R C", "background": "该论文介绍了一个由AI驱动的数据可视化平台，能够自动化整个数据分析流程，从数据集上传到生成交互式可视化。通过运用先进的机器学习算法清理和预处理数据，并自动选择合适的可视化方式。此平台旨在解决手动数据分析耗时的问题，适用于数据驱动的环境，并能够自动与Firebase云存储进行数据处理和实时交互。平台的后端通过Python Flask接诊数据集，前端则采用React技术实现。研究采用了自动化和智能的数据清理功能，包括缺失值填充和异常值检测，并通过分析数据集智能选择特征、产生标题和生成可视化。这些贡献通过两个独立数据集的评估来验证平台性能，在实时分析大规模数据集（至10万行）时，云平台能够满足多用户需求并同时处理请求。", "innovation": "该平台的关键创新点在于自动化和智能化的数据清理功能，能够进行缺失值填充与异常值检测；能够智能选择特征与生成可视化，从而提高数据可视化平台的效率和准确性；设计了一个结合Python Flask后端与React前端的平台架构，能够通过Firebase云存储进行数据处理和实时交互，支持多用户和高并发请求处理能力。", "conclusion": "基于云的数据可视化应用显著减少了手动数据输入，保持了高质量和有影响力的视觉输出及用户体验。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08409", "html_url": "https://arxiv.org/abs/2511.08409", "title": "FaithAct: 在多模态大语言模型中的忠实性计划与行动", "title_en": "FaithAct: Faithfulness Planning and Acting in MLLMs", "authors": "Junxian Li,Xinyue Xu,Sai Ma,Sichao Li", "background": "大型语言模型（LLMs）存在不忠诚的问题，表现为推理链条虽然听起来合理但实际上却与感知证据或最终结论相偏离。这种不忠诚情况可以分为行为忠实性（推理与输出的一致性）和感知忠实性（推理与输入的一致性）。现有方法对此类问题的处理不足，导致推理链条中的证据支持不足，降低了模型的可信度和稳定性。因此，对于此类模型的评估和改进变得尤为关键。为此，本研究提出了一种新的评估方法FaithEval来量化推理链条的忠诚度，并在此基础上提出了FaithAct框架，确保每次推理步骤都有事实证据的支持。", "innovation": "提出了FaithEval用于量化解析步骤和推理链条的忠诚度；提出了FaithAct框架，这是一种注重忠诚度优先的规划和行动框架，要求在每次推理步骤中都提供证据支持；通过多模态推理基准测试，展示了FaithAct框架比基于提示和工具增强的基线提高了26%的感知忠诚度，且未降低任务准确性；研究结果表明，以忠诚度为指导原则不仅减少了幻觉，还能促进更稳定的推理过程。", "conclusion": "本研究建立了一个统一框架，用于评估和强制实现多模态推理中的忠诚性。这一框架的使用不仅改善了模型的可信度，还提高了推理过程的稳定性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08439", "html_url": "https://arxiv.org/abs/2511.08439", "title": "自动驾驶中数据集的安全性：要求、风险与保障", "title_en": "Dataset Safety in Autonomous Driving: Requirements, Risks, and Assurance", "authors": "Alireza Abbaspour,Tejaskumar Balgonda Patil,B Ravi Kiran,Russel Mohr,Senthil Yogamani", "background": "自动驾驶系统的安全性和可靠性依赖于数据集的完整性，因此数据集的开发和管理对自动驾驶至关重要。本文提出了一种结构化框架，用于开发符合ISO/PAS 8800标准的自动驾驶安全数据集。文章针对基于AI的感知系统进行了详细阐述，涵盖数据收集、标注、管理与维护的整个生命周期，并引入了数据飞轮模型。该框架引入了严格的安全分析方法，以识别和缓解由于数据集不足导致的风险，并提出验证和验证策略以确保符合安全标准。此外，文章回顾了数据集安全性和自动驾驶车辆开发的最新研究和趋势，提供了关于当前挑战和未来方向的见解。", "innovation": "提出了符合ISO/PAS 8800标准的自动驾驶安全数据集开发框架；引入了数据飞轮模型，涵盖数据收集、标注、管理与维护的全过程；通过严格的安全分析方法和验证策略来确保数据集的安全性；总结了数据集安全性和自动驾驶车辆开发的最新研究成果和新兴趋势。", "conclusion": "通过将这些视角整合起来，本文旨在促进自动驾驶应用中稳健、安全性保障的人工智能系统的发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08558", "html_url": "https://arxiv.org/abs/2511.08558", "title": "超维度的脉冲神经网络解码", "title_en": "Hyperdimensional Decoding of Spiking Neural Networks", "authors": "Cedrick Kinavuidi,Luca Peres,Oliver Rhodes", "background": "目前的解码方法在准确性、抗噪性、延迟和能耗方面存在局限性。脉冲神经网络（SNN）和超维度计算（HDC）结合可以改进这些属性。", "innovation": "提出了一种结合SNN和HDC的新颖解码方法，显著提升了分类准确率、降低了分类延迟和能耗。特别是在DvsGesture和SL-Animals-DVS数据集上，能耗降低了1.24到3.67倍不等，且对于未训练的未知类别也能高效识别。", "conclusion": "所提出的解码方法在多个测试案例中表现出色，不仅具备高准确率和低能耗，还能识别未训练的未知类别，是一个替代传统速率和延迟解码方法的强有力选择。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08484", "html_url": "https://arxiv.org/abs/2511.08484", "title": "像软件一样打补丁：大型语言模型安全性政策改进的轻量级方法", "title_en": "Patching LLM Like Software: A Lightweight Method for Improving Safety Policy in Large Language Models", "authors": "Huzaifa Arif,Keerthiram Murugesan,Ching-Yun Ko,Pin-Yu Chen,Payel Das,Alex Gittens", "background": "尽管厂商发布改进的大型语言模型版本，但主要版本更新成本高、频率低且难以满足客户特定需求，导致已发布模型中存在已知的安全漏洞。完全模型微调或主要版本更新方法不适用于快速修复这些安全问题，因此需要一种新的、更灵活的方法来处理大型语言模型的安全漏洞问题。", "innovation": "本文提出了一种轻量级模块化方法——类似软件补丁的补丁技术，用于修复安全漏洞。该方法通过在现有模型前添加一个紧凑的学习前缀来实现快速修复，引入的参数仅占0.003%，但能够可靠地引导模型行为向更安全的参考模型靠拢。在毒性缓解、偏见减少和有害行为拒绝三个关键领域，政策补丁能够达到与新一代对齐安全模型相媲美的安全改进效果，同时保留流畅性。", "conclusion": "本文证明，类似于软件的补丁技术可以用于大型语言模型的安全更新，这为供应商和从业者提供了一种实际机制，可以在主要模型版本之间分发具备规模性、高效性和组合性的安全更新。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08581", "html_url": "https://arxiv.org/abs/2511.08581", "title": "DeepProofLog：深度随机逻辑程序中的高效证明", "title_en": "DeepProofLog: Efficient Proving in Deep Stochastic Logic Programs", "authors": "Ying Jiao,Rodrigo Castellano Ontiveros,Luc De Raedt,Marco Gori,Francesco Giannini,Michelangelo Diligenti,Giuseppe Marra", "background": "神经符号AI（NeSy AI）旨在结合神经架构和符号推理的强点，以提高AI模型的准确度、可解释性和泛化能力。虽然在次符号模块上进行逻辑推理已经表明有助于保证这些特性，但这也常常会带来可扩展性降低的问题，严重影响NeSy模型的实用性。", "innovation": "该论文提出了DPrL（DeepProofLog），一种基于随机逻辑程序的新颖NeSy系统，有效解决了先前方法的可扩展性限制。DPrL通过神经网络参数化所有演绎步骤，实现了证明系统的高效神经指导。此外，通过将深度随机逻辑程序的归结过程与马尔可夫决策过程正式映射，使动态规划和强化学习技术能够高效应用于推断和学习。这一理论连接提高了复杂证明空间和大型知识库的可扩展性。", "conclusion": "在标准NeSy基准测试以及知识图谱推理任务上的实验表明，DPrL在可扩展性方面超越了现有的最先进的NeSy系统，为更大的和更复杂的设置提供了可能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08585", "html_url": "https://arxiv.org/abs/2511.08585", "title": "使用人工智能模拟视觉世界：一个路线图", "title_en": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "authors": "Jingtong Yue,Ziqi Huang,Zhaoxi Chen,Xintao Wang,Pengfei Wan,Ziwei Liu", "background": "视频生成的景观正在从追求视觉吸引力的片段转向构建支持互动并保持物理合理性的人工环境。这种转变预示着视频基础模型的出现，这些模型不仅能够作为视觉生成器，还能够作为隐式的世界模型，能够模拟物理动力学、人机交互和任务规划等治理现实或想象世界的机制。本文提供了一个系统性的综述，将现代视频基础模型的概念化为两个核心组件的结合：隐式世界模型和视频渲染器。", "innovation": "本文系统回顾了近年来视频生成技术的发展，从第一代模型到第四代模型，最终生成的模型拥有内在的物理合理性、实时多模态交互和在时空尺度上的规划能力。每一代的模型都有其核心特征，代表性的作品和应用领域也有所展示。并讨论了下一代世界模型的研究方向和设计方案，如代理智能的作用，以及如何塑造并评估这些系统。", "conclusion": "本文最终讨论了下一代世界模型的开放挑战和设计原则，包括代理智能在塑造和评估这些系统中的角色，并维持了一篇相关文献的更新列表。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08548", "html_url": "https://arxiv.org/abs/2511.08548", "title": "兴趣问题：理解人类与语言模型中的数学问题的兴趣", "title_en": "A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models", "authors": "Shubhra Mishra,Yuka Machino,Gabriel Poesia,Albert Jiang,Joy Hsu,Adrian Weller,Challenger Mishra,David Broman,Joshua B. Tenenbaum,Mateja Jamnik,Cedegao E. Zhang,Katherine M. Collins", "background": "数学的发展在很大程度上受到了问题有趣性的引导。从研究人员选择下一个解决的问题到学生决定是否参与其中，人们的决策往往受到对问题的有趣性和挑战性判断的指导。随着像大型语言模型（LLMs）这样的AI系统越来越多地参与数学，无论是高级研究还是教育，理解LLMs对数学有趣性和难度的判断与人类的一致性变得尤为重要。该研究通过两个实证研究——人类和LLMs对数学有趣性和难度的评估，考察了两组参与者：来自众包平台的参与者和国际数学奥林匹克竞赛的参赛者，揭示出尽管许多LLMs在对数学问题的有趣性有总体上的共识，但它们未能捕捉到人类判断的分布，且大多数LLMs在解释人类对某些数学问题的兴趣方面表现较弱，其与人类选择的有趣性理由的相关性较低。这表明目前LLMs在捕捉数学AI思维伙伴关系中的人类有趣性判断方面的潜力和局限性显现了出来。", "innovation": "该研究通过两组实证研究来评估人类和LLMs对数学问题有趣性和难度的评估一致性，包括来自众包平台的参与者和国际数学奥林匹克竞赛的参赛者。研究不仅揭示了LLMs在有趣性判断上的局限性，还指出在数学AI思维伙伴关系中目前存在的挑战和潜力。", "conclusion": "尽管许多LLMs在对数学问题的有趣性有总体上的共识，但多数LLMs未能准确捕捉到人类判断的有趣性和为什么某些数学问题对人类来说是有兴趣的具体理由。这表明，当前LLMs在捕捉人类对数学问题有趣性的判断方面存在一定的局限性，并揭示了人类与AI在数学体验中的潜在差异。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.19477", "html_url": "https://arxiv.org/abs/2404.19477", "title": "混合比特和语义通信", "title_en": "Hybrid Bit and Semantic Communications", "authors": "Kaiwen Yu,Renhe Fan,Gang Wu,Zhijin Qin", "background": "语义通信技术被视为超越香农极限的比特传输的一种方法，能够有效提升传输效率。然而，目前直接将内容映射到传输符号的方法由于实施上的挑战，极大限制了语义通信的发展。为此，该研究提出了一种名为HybridBSC的混合比特和语义通信系统，该系统通过传统的数字通信系统利用相同的频谱资源将编码的语义信息插入到比特信息中进行传输，能够利用现有的通信架构轻松部署以实现比特和语义信息的同时传输。", "innovation": "研究提出了HybridBSC系统，通过将编码的语义信息插入到比特信息中，使用现有的通信架构实现语义和比特信息的传输。设计了一套语义信息的插入和提取方案，并在实际无线信道中基于Pluto软件定义无线电(SDR)平台上进行了实验验证，证明了该策略能够同时传输语义和比特信息，突破了现有技术的局限性。", "conclusion": "研究展示了如何通过HybridBSC系统利用现有通信架构实现语义和比特信息的并行传输，并通过实际无线环境下的实验验证了该策略的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07420", "html_url": "https://arxiv.org/abs/2511.07420", "title": "使用大型语言模型推动数学研究", "title_en": "Advancing mathematics research with large language models", "authors": "Lisa Carbone", "background": "现有的生成型人工智能在高级数学领域使用大型语言模型（LLMs）的主要不足在于它们是概率性模式匹配工具，而非逻辑推理引擎。然而，这些模型可以在人类难以察觉的情况下捕捉到高阶数学中的模式。通过巧妙利用LLMs的设计特点，数学家可以将其作为强大的交互式助手，完成繁琐的任务、生成并调试代码、验证实例、提出猜想等。本文探讨了通过精心设计提示工程来利用LLMs推动数学研究的方法，讨论了如何将LLMs与计算机代数系统和形式证明助手（如Lean）进行集成以进一步提升数学研究效率.", "innovation": "该论文提出了一种创新的方法，即通过精心设计提示工程来高效利用大型语言模型（LLMs）在高级数学中的应用。此外，还将LLMs与其他数学工具如计算机代数系统和形式证明助手集成，旨在提高数学研究的效率和质量。这种策略强调了AI与数学学家之间有效合作的可能性，为数学研究提供了新的视角和方法.", "conclusion": "论文总结了利用LLMs推动数学研究的有效方法，强调通过精心设计的提示工程和与其他数学工具的整合，可以充分发挥大语言模型的优势。这种方法为数学研究提供了新的辅助手段，有助于解决一些复杂问题，促进数学理论的发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07426", "html_url": "https://arxiv.org/abs/2511.07426", "title": "MCP-增强的LLM代理的网络和系统性能特性分析", "title_en": "Network and Systems Performance Characterization of MCP-Enabled LLM Agents", "authors": "Zihao Ding,Mufeng Zhu,Yao Liu", "background": "MCP（模型上下文协议）在人工智能社区中获得越来越多的关注，因为它为大型语言模型（LLMs）提供了与外部工具和服务互动的标准化方式，极大地增强了其功能。然而，MCP启用的LLM互动中包含了广泛的上下文信息，如系统提示，MCP工具定义以及上下文历史，这会显著增加标记数量，从而导致成本增加和计算负载增加，而LLM提供商会根据标记收费。因此，本研究旨在进行全面的测量分析，探讨MCP启用的LLM互动之间的权衡与性能表现之间的关系，包括标记效率，成本，任务完成时间和任务成功率，从而为更有效的MCP启用的工作流程提供有价值的见解。", "innovation": "本研究通过测量分析探讨了MCP启用的LLM互动中的权衡与性能表现之间的关系。它评估了不同LLM模型与MCP配置对关键性能指标如标记效率，成本，任务完成时间及任务成功率的影响，并建议了潜在优化措施，包括启用并行工具调用以及实现稳健的任务终止机制。", "conclusion": "本研究的结果提供了更有用的见解，从而开发出更高效，更稳健且成本效益更高的MCP启用的工作流程，这对实际应用具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07425", "html_url": "https://arxiv.org/abs/2511.07425", "title": "在流行的小型主板上评估大语言模型的推理", "title_en": "An Evaluation of LLMs Inference on Popular Single-board Computers", "authors": "Tung(Thomas)Nguyen,Tuyen Nguyen", "background": "随着对在设备上运行大规模语言模型（LLM）推理的需求增长，人们对在边缘硬件上部署轻量级、低成本的AI解决方案产生了兴趣。使用单板计算机（SBC）如树莓派（Raspberry Pi）和橙皮（Orange Pi）平台进行本地化、保护隐私的推理显示出潜力，但它们在LLM工作负载方面的应用仍然较少被探索。本文旨在评估25种量化后的开源LLM在三种SBC（Raspberry Pi 4，Raspberry Pi 5和Orange Pi 5 Pro）上的性能，使用Ollama和Llamafile两种推理运行时，在不同CPU配置下评估生成吞吐量、内存使用和功耗。", "innovation": "该研究首次对LLM推理在SBC上的进行全面评估，连接了高性能语言模型和经济实惠的边缘计算间的鸿沟，识别出了架构特定的瓶颈，突出了运行时级别的权衡，并提供了实际部署建议。值得注意的是，使用Llamafile的实现吞吐量相比Ollama最高可达4倍，并且功耗低30-40%。", "conclusion": "小型主板（SBC）可以可靠地支持多达1.5B参数的语言模型，Llamafile在吞吐量和功耗方面优势显著。研究结果表明SBC平台在LLM推理中具有重要潜力，但仍需解决特定架构瓶颈和优化运行时性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07429", "html_url": "https://arxiv.org/abs/2511.07429", "title": "通过大语言模型进行解释性视频异常检测的知识引导文本推理", "title_en": "Knowledge-Guided Textual Reasoning for Explainable Video Anomaly Detection via LLMs", "authors": "Hari Lee", "background": "该研究基于现有的弱监督视频异常检测（WSVAD）模型，提出了一个新的框架 Text-based Explainable Video Anomaly Detection (TbVAD)，将异常检测和解释完全置于文本域中，利用语言驱动的方法，而非依赖传统的视觉特征。", "innovation": "TbVAD框架创新点在于其通过语言模型将视频内容转换为详尽的文本描述，然后根据情境组织这些描述，并生成针对特定信息槽的解释，揭示哪些语义因素对异常决策影响最大。这一过程能够提供可解释且可靠的结果，特别适用于实际的安全监控场景。", "conclusion": "研究结果表明，基于文本的知识推理方法在 UCF-Crime 和 XD-Violence 这两个公开基准上显示出了解释性和可靠性，证明了这种方法在真实世界监控场景中的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07445", "html_url": "https://arxiv.org/abs/2511.07445", "title": "RAG for Taiwanese Historical Archives", "title_en": "A Preliminary Study of RAG for Taiwanese Historical Archives", "authors": "Claire Lin,Bo-Han Feng,Xuanjun Chen,Te-Lun Yang,Hung-yi Lee,Jyh-Shing Roger Jang", "background": "RAG作为一种知识密集型任务的有前景的方法已经出现，但很少有研究探讨其在台湾历史档案的应用。", "innovation": "本文首次研究了RAG在两个历史数据集（Fort Zeelandia和台湾省议会公报）上的应用，并分析了查询特性和元数据集成策略对检索质量和答案生成性能的影响。", "conclusion": "研究表明，早期的元数据集成可以提升检索和答案的准确性，但也揭示了RAG系统的持续挑战，包括生成中的幻觉和处理具有时间性或多跳的历史查询的困难。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07423", "html_url": "https://arxiv.org/abs/2511.07423", "title": "Synera：大规模设备和云协同的LLM服务", "title_en": "Synera: Synergistic LLM Serving across Device and Cloud at Scale", "authors": "Genglin Wang,Liekang Zeng,Bufang Yang,Kaiwei Liu,Guoliang Xing,Chumin Sun,Li Zhou,Jie Sun,Zhenyu Yan", "background": "大型语言模型（LLMs）正在成为各类移动操作系统的关键组件，推动了诸如互动聊天机器人和个性化助理等智能应用的发展。虽然为移动终端带来了增强的智能，但在部署过程中却面临着一系列性能挑战，尤其是在生成质量下降和延迟延长方面。现有的解决方案主要依赖于云卸载或设备上小型语言模型（SLMs）的策略，但前者通常受限于通信瓶颈，后者则因资源限制而牺牲生成质量。这一背景下，本研究提出了一种名为Synera的设备与云协同的LLM服务系统，运用高效的SLM-LLM协同机制，通过实验证明了设备和云之间在LLM推理方面的潜在优化机会，并通过特制的设计将这些机会转化为提高性能的方案。", "innovation": "Synera提出了一个设备与云协同的LLM服务系统，通过以下几个方面实现了创新和改进：1) 寻找并利用设备和云之间的协同优化机会，包括卸载决策、流水线停滞和批量处理瓶颈；2) 引入了通信高效的按需卸载、无停滞并行推理和可扩展的云批量处理等定制设计，以优化LLM推理性能；3) 实验结果表明，与现有竞争基线相比，Synera在保持相近延迟性能的同时，生成质量提升了1.20-5.47倍；与现有云服务解决方案相比，Synera在各种基准测试中实现了8.2-16.5%的更低云服务成本。", "conclusion": "Synera极大地改进了LLM推理的生成质量和性能，成功应对了设备与云协同服务中的主要挑战。通过精准的卸载决策、流水线优化和批量处理策略，Synera为LLM在移动设备上的部署提供了更加高效的解决方案，展示了卓越的性能和成本效益。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07433", "html_url": "https://arxiv.org/abs/2511.07433", "title": "Simulacra AI的量子准确合成数据生成在化学科学中的基准测试", "title_en": "Benchmarking Simulacra AI's Quantum Accurate Synthetic Data Generation for Chemical Sciences", "authors": "Fabio Falcioni,Elena Orlova,Timothy Heightman,Philip Mantrov,Aleksei Ustimenko", "background": "本文将Simulacra的合成数据生成流水线与Microsoft的先进流水线在包含小到大规模系统的数据集上进行了对比。通过对能量质量、自相关时间和有效样本大小的分析，研究发现Simulacra的大波动函数模型（LWM）流水线搭配最先进的变分蒙特卡罗（VMC）采样算法在大幅降低数据生成成本的同时，能量准确性保持不变，相对于传统CCSD方法在氨基酸规模上能减少2-3倍的成本。这使得创建大规模的第一性原理数据集成为可能，从而加速制药行业及其他领域的AI驱动优化与发现过程。改进之处基于一种名为Replica Exchange with Langevin Adaptive eXploration (RELAX)的新颖且专有的采样方案。", "innovation": "Simulacra的大波动函数模型（LWM）流水线搭配最先进的变分蒙特卡罗（VMC）采样算法，通过新型的Replica Exchange with Langevin Adaptive eXploration (RELAX)采样方案，实现了降低成本至15-50倍，同时在能量准确性上保持稳定，相比传统CCSD方法在氨基酸规模上能减少2-3倍的成本。", "conclusion": "本研究通过Simulacra的先进合成数据生成技术，实现了大规模第一性原理数据集的创建，促进了制药行业的AI驱动优化与发现流程。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07442", "html_url": "https://arxiv.org/abs/2511.07442", "title": "pinching antennas meet ai in next-generation wireless networks", "title_en": "Pinching Antennas Meet AI in Next-Generation Wireless Networks", "authors": "Fang Fang,Zhiguo Ding,Victor C. M. Leung,Lajos Hanzo", "background": "下一代无线网络必须具备内在智能以支持诸如扩展现实和自主系统等苛刻的新兴应用，同时满足超可靠和低延迟的要求。聚点天线(PAs)是一种新型的灵活低成本技术，可以在传输线上根据需求动态激活小尺寸介电聚点以创建视距链路。人工智能(AI)作为这一复杂控制的管理补充，提供了所需的智能以适应环境中的PA激活位置和资源分配。", "innovation": "本文探讨了AI和PAs的合作：AI促进PA激活位置在传输线上的自适应优化，而PAs支持边缘AI任务如联邦学习和空中聚合。讨论了包括由大型语言模型驱动的PA控制框架在内的一些有前景的研究方向，以及PA-AI集成如何推动语义通信和集成传感与通信的进步。这种协同作用为自适应、稳健且自我优化的下一代网络打开了大门。", "conclusion": "本文提出了PA-AI集成在下一代无线网络中的多种潜在应用场景，强调了这种整合对自适应、稳健和自我优化网络构建的重要性，并探索了未来的研究方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07427", "html_url": "https://arxiv.org/abs/2511.07427", "title": "DynaKV: 在智能手机上实现准确高效的大序列LLM解码", "title_en": "DynaKV: Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones", "authors": "Tuowei Wang,Minxing Huang,Fengzu Li,Ligeng Chen,Jinrui Zhang,Ju Ren", "background": "随着人类推理、多轮对话和长篇回复的需求增长，大型语言模型（LLMs）被期望能够支持有效的长序列解码。然而，由于受限于有限的DRAM容量，智能手机上的长序列LLM解码受到关键值缓存（KVCache）的限制，其内存占用随序列长度线性增加。检索方法通过将KVCache卸载到闪存中，并通过基于簇的索引检索相关查询条目来缓解DRAM压力。然而，随着解码的进行，KVCache分布的变化使得静态或局部簇更新逐渐不准确，导致排除重要条目或获取冗余条目。智能手机在带宽、IOPS和内存容量方面的特定限制进一步加剧了这些问题。因此，提出了DynaKV，一种实现智能手机上长序列解码的自适应KVCache管理方法，该方法包括三大关键技术：无迁移的簇自适应技术、以连续性为中心的闪存管理技术，以及高效缓存设计技术。", "innovation": "DynaKV整合了三大关键技术：无迁移的簇自适应技术，实现检索过程中的动态分割而不增加额外的传输；以连续性为中心的闪存管理技术，将关联条目和簇进行联合存储，并使用双头布局进行高效更新；高效缓存设计技术，通过虚拟化缓存空间跨DRAM和闪存，并将替换策略调整为与簇级访问模式一致。实验证明，DynaKV在检索精度和端到端延迟方面显著优于现有解决方案，平均精度提升1.38倍，速度提升1.47倍。此外，DynaKV的见解天然适用于其他长上下文工作负载和多级内存层次结构中，进一步强调了其广泛的适用性。", "conclusion": "DynaKV是第一个专为智能手机上的长序列解码解决准确性和效率问题的自适应KVCache管理方法。通过实验验证了其在精度和延迟上的显著优势，并指出其技术上有更广泛的应用前景。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07441", "html_url": "https://arxiv.org/abs/2511.07441", "title": "AudAgent：AI代理私有政策合规的自动化审计", "title_en": "AudAgent: Automated Auditing of Privacy Policy Compliance in AI Agents", "authors": "Ye Zheng,Yidan Hu", "background": "智能代理能够自主执行任务，并且通常在没有明确用户同意的情况下收集或泄露用户的敏感本地数据，这引发了严重的隐私问题。尽管AI代理可以有隐私政策描述其数据处理意图，但实际上运行时的行为与这些政策缺乏透明度和问责性。AudAgent旨在解决这一问题，通过一个可视化框架连续监控AI代理的数据实践，并确保其符合声明的隐私政策。", "innovation": "AudAgent引入了一种自动化隐私审计框架，该框架包括四个组件：(i) 政策解析：通过LLM的集合将自然语言隐私政策转换为结构化的隐私政策模型，并通过跨LLM投票确保解析结果的信心；(ii) 运行时注释：通过轻量级的Presidio分析器检测敏感数据，并基于AI代理操作的上下文和隐私政策模型来注释数据的使用；(iii) 合规审计：通过本体对齐和自动机评估将政策模型与运行时注释连接起来，实现将自然语言政策与仅观察到的数据实践的即时合规性检查；(iv) 用户界面：平台独立的实现展示了AI代理实时执行轨迹及审计过程中检测到的潜在隐私风险，提供易于理解的透明度和问责性。AudAgent还支持用户定义的策略以实现细粒度控制和自定义。", "conclusion": "AudAgent在主流编程框架（如AutoGen）构建的AI代理上进行评估，实验结果表明，AudAgent可以实时有效地识别潜在的隐私政策违规行为。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07451", "html_url": "https://arxiv.org/abs/2511.07451", "title": "探索AI生成的学生回应的心理测量有效性：一项关于虚拟人物学习动机的研究", "title_en": "Exploring the Psychometric Validity of AI-Generated Student Responses: A Study on Virtual Personas' Learning Motivation", "authors": "Huanxiao Wang", "background": "本研究旨在探索大规模语言模型（LLMs）是否能够模拟有效的学生答案，用于教育测量。通过使用GPT-4o生成2000个虚拟学生角色，每个角色完成学术动机量表（AMS），并通过因子分析（EFA和CFA）和聚类分析，研究结果显示GPT-4o能够重现AMS结构和不同的动机亚组，从而检验了模型生成的有效性。", "innovation": "本研究创新性地使用大规模语言模型生成虚拟学生角色，以分析模型生成的答案是否能够有效模拟真实学生的行为和心理状态。通过因子分析和聚类分析，验证了生成的答案是否与实际教育测量工具的结果相符，确认模型在生成有效学生回应方面的潜力。", "conclusion": "GPT-4o能够准确模拟学生的回答，并再现学生在学术动机量表上的结构和动机亚组，表明其在教育测量中的潜在应用价值。未来研究可以进一步探讨不同类型的教育测量工具和更大规模的数据集。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07459", "html_url": "https://arxiv.org/abs/2511.07459", "title": "通过减少标签分布变化优化罕见标签的分类", "title_en": "Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution", "authors": "Ashutosh Agarwal", "background": "在极端分类(XC)任务中，不常见的类别由于样本稀疏和高标签不一致性，导致分类性能低下。现有方法难以有效处理这些类别。", "innovation": "提出了一种名为LEVER的新颖解决方案，采用了一种鲁棒的Siamese风格架构，通过知识迁移减少标签不一致性，提升One-vs-All分类器的性能。", "conclusion": "多数据集测试表明，LEVER显著改善了对不常见类别的处理，设立了新的研究基准。此外，该研究还提供了两个新的多意图数据集，为未来XC研究提供了重要资源。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07458", "html_url": "https://arxiv.org/abs/2511.07458", "title": "REFLEX：基于大规模语言模型判断的无参考日志总结评估", "title_en": "REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment", "authors": "Priyanka Mudgal", "background": "评价日志摘要系统具有挑战性，因为缺乏高质量的参考摘要，并且像ROUGE和BLEU这样的现有指标依赖于表面级别的词汇重叠，这在评估摘要质量时非常有限。", "innovation": "引入了REFLEX，这是一种基于大规模语言模型无参考评价的摘要评估指标。REFLEX使用大规模语言模型作为零样本评估者，从相关性、信息量和连贯性等方面评估摘要质量，无需金标准参考或人工标注。与传统指标相比，REFLEX能更有效地区分模型输出，并提供在缺乏或无法获得参考数据的实际应用场景中的一种可扩展替代方案。", "conclusion": "REFLEX在多个日志摘要数据集上实现了稳定、可解释和细节丰富的评估，并且在区分模型输出方面比传统指标更为有效。REFLEX为在缺乏参考数据的实际应用场景中评估日志摘要提供了一种可扩展的替代方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07461", "html_url": "https://arxiv.org/abs/2511.07461", "title": "双重策略：术语感知翻译的双阶段方法", "title_en": "It Takes Two: A Dual Stage Approach for Terminology-Aware Translation", "authors": "Akshat Singh Jaswal", "background": "本文介绍了一种名为DuTerm的两阶段术语约束机器翻译系统。背景信息表明，现有技术在术语处理上存在局限性，通常需要严格约束术语使用，但这可能限制了翻译的灵活性和质量。本文提出了一种结合术语感知机器翻译模型和基于提示的语言模型的方法，以提高翻译质量和术语的准确使用。", "innovation": "创新之处在于提出了DuTerm，这是一种新颖的两阶段架构。第一阶段使用术语感知的神经机器翻译模型，通过大规模合成数据微调；第二阶段使用基于提示的语言模型进行后编辑，确保翻译中术语的正确使用。这一方法通过灵活处理术语，能够在保持高质量翻译的同时，更好地适应上下文变化。", "conclusion": "实验结果表明，语言模型在处理翻译任务时作为术语的上下文驱动修改器而非生成器，能够更有效地提高翻译质量。研究揭示了一个关键的权衡，即语言模型在术语约束机器翻译中应发挥一种上下文驱动的修改作用，而非完全生成新的翻译内容。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07457", "html_url": "https://arxiv.org/abs/2511.07457", "title": "GRIP：通过微调大规模语言模型进行参数内图推理", "title_en": "GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models", "authors": "Jiarui Feng,Donghong Cai,Yixin Chen,Muhan Zhang", "background": "大规模语言模型（LLMs）在序列文本数据建模和跨领域任务推广方面展示了显著的能力。然而，将LLMs有效地应用于处理结构化数据（如知识图谱或网络数据）仍是具有挑战性的问题。一些方法试图通过将图形转换为文本序列来解决此问题，但这会导致大量标记数量（token overhead）并使其对大规模图形不切实际。其他方法则通过引入额外模块将图形编码为固定长度的标记表示，但这需要大规模后训练和复杂的对齐过程，并且常常效果不佳，因为模态对齐不良。", "innovation": "受测试时调整LLMs的参数内知识注入启发，本文提出了一种新型框架GRIP，其通过精心设计的微调任务让LLMs具备从图形中内化复杂关系信息的能力。这些知识存储在轻量级LoRA参数中，使微调后的LLMs能够在无需访问原图形推理的情况下执行广泛范围的图形任务。该方法在多个基准测试中的详尽实验验证了其有效性和效率。", "conclusion": "本文提出的GRIP框架，通过设计的微调任务和轻量级的LoRA参数，使LLMs能够处理图形相关任务，且在推理阶段无需访问原始图形，这增强了大规模语言模型处理结构化数据的能力并提高了效率。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07464", "html_url": "https://arxiv.org/abs/2511.07464", "title": "Motif 2 12.7B 技术报告", "title_en": "Motif 2 12.7B technical report", "authors": "Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon", "background": "该研究旨在通过结合架构创新与系统级优化，提高大规模语言模型的效率前沿，同时解决在有限计算预算下可扩展的语言理解和稳健指令泛化问题。", "innovation": "论文引入了Motif-2-12.7B，这是一种新的开放权重基础模型。该模型通过集成分组差异性注意力机制（GDA），在信号和噪声控制的注意力路径上实现了信号分离，提高了表示效率。模型采用了一个以教材驱动的数据调度器，逐步改变数据构成的比例，进行预训练，并在大规模分布式环境中利用专门为高性能优化的MuonClip优化器和定制的高性能内核，如融合的PolyNorm激活和并行Muon算法，显著提高了吞吐量和内存效率。培训后采用三阶段监督微调流水线，逐步增强指令适应性、组合理解和语言精确度。", "conclusion": "实验结果表明，Motif-2-12.7B展示了跨各种基准的竞争力，证明了在有计划的架构扩展和优化培训设计方面，可以与更大规模的模型相竞争的能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07477", "html_url": "https://arxiv.org/abs/2511.07477", "title": "礼貌撒谎者：语言模型的认知病理", "title_en": "The Polite Liar: Epistemic Pathology in Language Models", "authors": "Bentley DeVilling(Course Correct Labs)", "background": "大型语言模型表现出一种奇特的认知病态：它们即使不知道某事也会自信地表达。这种自信的捏造，我称之为“文明说谎者”，是基于人类反馈强化学习（RLHF）的一种结构性后果。本文利用 Frankfurt 对 Bullshit 的分析，表明这种病态并非欺骗，而是结构性的冷漠：一种优化感知诚信而非证据准确性的奖励结构。当前对齐方法奖励模型能够提供帮助、无害和有礼貌，但不注重知识的根基。因此，系统学习最大化用户的满意度而非事实，将交际流畅性视为一种美德。", "innovation": "本文通过分析实证主义美德论、话语行为哲学和认知对齐，展示了 RLHF 产生的代理被训练模仿知识自信而没有知识证明机制。这揭示了语言合作与认知诚信之间的深层对齐张力。", "conclusion": "本文提出了“认知对齐”原则：奖励有根据的自信而非表面上的流畅性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07479", "html_url": "https://arxiv.org/abs/2511.07479", "title": "通过选择性时空视觉变换器进行模数视频恢复", "title_en": "Modulo Video Recovery via Selective Spatiotemporal Vision Transformer", "authors": "Tianyu Geng,Feng Ji,Wee Peng Tay", "background": "传统的图像传感器动态范围有限，导致高动态范围（HDR）场景中出现饱和问题。模数摄像头通过将入射辐射折叠到限定范围内来解决这一问题，但需要专门的解卷算法来重建底层信号。与扩展常规采样动态范围的HDR恢复不同，模数恢复恢复了从折叠样品中实际存在的值。尽管模数图像恢复已经引入十多年，但在使用现代深度学习技术方面进展缓慢。", "innovation": "尽管标准HDR方法不适合模数恢复，但Transformer可以通过捕捉重要的全局依赖性和时空关系来解决折叠视频帧的解卷问题。然而，调整现有的Transformer架构以进行模数恢复需要新的技术。为此，我们提出了选择性时空视觉变换器（SSViT），这是第一个用于模数视频重建的深度学习框架。SSViT 使用标记选择策略以提高效率并集中于最关键的区域。", "conclusion": "实验表明，SSViT 能够从 8 位折叠视频中产生高质量的重建结果，并在模数视频恢复方面达到了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07463", "html_url": "https://arxiv.org/abs/2511.07463", "title": "LLM生成代码的动态稳定性", "title_en": "Dynamic Stability of LLM-Generated Code", "authors": "Prateek Rajput,Abdoul Aziz Bonkoungou,Yewei Song,Abdoul Kader Kabore,Iyiola E. Olatunji,Jacques Klein,Tegewende Bissyande", "background": "当前对大语言模型（LLM）生成代码的评估主要侧重于功能正确性，而忽视了功能正确解的算法复杂性可能有很大不同的事实。现有的评估方法未能捕捉到正确解决方案之间的行为和性能多样性。研究表明，在实际生产环境中，即使输出结果相同，算法复杂度差别可能导致性能显著不同。这种差异揭示了当前评估方法的一个关键局限性，即无法准确反映正确解之间的行为和性能差异性。", "innovation": "本文提出了一种基于指令码分布的原理性框架，用于评估生成代码的动态稳定性。该框架提出了两个基于指令码分布的度量标准：静态标准化跟踪分歧（SCTD），用于捕捉不同生成解算法结构的多样性；动态标准化跟踪分歧（DCTD），用于量化运行时行为的变异性。两者之比，即行为表达因子（BEF），可以作为诊断信号指示运行时不稳定性和功能性冗余。实验结果表明，最先进的LLM即使在功能正确的输出中也表现出显著的算法差异。提高采样温度可提升正确性的通过率但会削弱稳定性，揭示了一个未被认识到的权衡：在多样输出空间中寻找正确解会带来“不稳定性的代价”；即在正确性和行为一致性之间的权衡。", "conclusion": "研究结果强调了代码生成任务中动态稳定性的重要性和必要性，并呼吁引入动态稳定性相关的评估目标。此外，还需要建立新的基准测试，包含渐进性测试案例，以评估更稳健的、真实的LLM性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07482", "html_url": "https://arxiv.org/abs/2511.07482", "title": "LLMs中受限对齐动态剪枝：识别和保留对齐关键电路", "title_en": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits", "authors": "Dev Patel,Gabrielle Gervacio,Diekola Raimi,Kevin Zhu,Ryan Lagasse,Gabriel Grand,Ashwinee Panda,Maheep Chaudhary", "background": "大规模语言模型在推理过程中需要大量的计算资源，这带来部署上的挑战。动态剪枝相比静态方法具有更高的效率，但通过适应性电路选择的方式，动态剪枝会增加对齐退化，因为它仅仅保留了输入依赖的安全关键电路，这种保留方式在不同输入下会导致更强的对齐漏洞。因此，解决这些增加的对齐漏洞仍然是关键问题。", "innovation": "我们提出了对齐感知探针剪枝（AAPP），这是一种动态结构化剪枝方法，可以在推理过程中自适应地保留对齐相关的电路，建立在探针剪枝的基础上。实验在LLaMA 2-7B、Qwen2.5-14B-Instruct和Gemma-3-12B-IT上进行，结果表明AAPP在匹配计算的情况下可以将拒绝率提高50%，实现了高效且安全保留的LLM部署。", "conclusion": "AAPP方法能够自适应地保留对齐相关的电路，有效提高了计算效率同时保持了模型的安全性，在多种大规模语言模型上得到了验证。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07480", "html_url": "https://arxiv.org/abs/2511.07480", "title": "KG-DF：基于知识图谱的针对模型逃逸攻击的黑盒防御框架", "title_en": "KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs", "authors": "Shuyuan Liu,Jiawei Chen,Xiao Yang,Hang Su,Zhaoxia Yin", "background": "随着大型语言模型（LLMs）在各个领域的广泛应用，它们所面临的安全挑战日益突出，特别是模型逃逸的问题。这种攻击通过精心设计的输入来诱导模型生成错误或不受控制的输出，威胁了模型的普适性和安全性。尽管现有的防御方法在一定程度上有效，但它们往往难以在模型的普适性和安全性之间找到平衡。过多的防御可能会限制模型的正常使用，而防御不足则可能带来安全漏洞。", "innovation": "针对上述问题，本文提出了一种基于知识图谱（KG）的防御框架（KG-DF）。该框架利用知识图谱的结构化知识表示和语义关联能力，通过将输入内容与知识库中的安全知识进行关联，识别潜在的有害意图并提供安全的推理路径。为解决传统知识图谱方法在关键词提取方面遇到的挑战，特别是当面对多变和不断发展的攻击策略时，引入了一个可扩展的语义解析模块，其核心任务是将输入查询转换为一组结构化和安全的概念表示，从而增强匹配过程的相关性。", "conclusion": "通过对各种逃逸攻击方法的防御性能提升，以及通过引入通用知识改进LLM在通用问答场景中的响应质量，本文提出的框架展示了其有效性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07485", "html_url": "https://arxiv.org/abs/2511.07485", "title": "当学习偏差等价时？一种公平性、鲁棒性和分布偏移的统一框架", "title_en": "When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift", "authors": "Sushant Mehta", "background": "机器学习系统表现出多种故障模式，包括针对保护群体的不公平性、对于错误关联的脆弱性、小群体性能不佳等。这些故障模式通常由不同的研究社区单独研究。", "innovation": "提出了一个统合的理论框架，该框架可以量化不同偏见机制如何产生相同的效果。通过信息论度量将偏见形式化为条件独立性违背，证明了错误关联、小群体迁移、类别不平衡和公平性违反之间的正式等价条件。该理论表明，一种强度为α的错误关联会在特征重叠假设下等效于小群体不平衡比率r≈(1+α)/(1−α)的最差群体准确率退化。并且在六个数据集和三种架构上进行了实证验证，证明了预测的等价性在最差群体准确率误差3%以内。这一工作将公平性、鲁棒性和分布偏移统一在一个共同视角之下。", "conclusion": "该工作在准确性误差3%的范围内验证了预测的等价性，使得跨问题域的去偏方法得以科学地转移。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07493", "html_url": "https://arxiv.org/abs/2511.07493", "title": "通过耳戴设备自动检测自我对话", "title_en": "Enabling Automatic Self-Talk Detection via Earables", "authors": "Euihyeok Lee,Seonghyeon Kim,SangHun Im,Heung-Seon Oh,Seungwoo Kang", "background": "自我对话在情绪调节、认知处理和动机方面起着重要作用，但在日常生活中大多隐形且难以量化。现有的技术难点在于自我对话在声学形式上的多样性、语义和语法的不完整性以及不规律的出现模式，这与传统语音理解模型的基础假设不同。", "innovation": "MutterMeter是一个移动系统，能够利用可穿戴麦克风在真实环境中自动检测自我对话。该系统采用层次分类架构，并通过顺序处理管道逐步整合声学、语言和上下文信息，实现准确性和计算效率的动态平衡。研究团队使用包含25名参与者共计31.1小时音频数据的新建数据库进行了系统构建和评估。", "conclusion": "实验结果显示，MutterMeter在宏观平均F1得分上达到0.84，显著优于现有的方法，包括基于LLM的方法和语音情绪识别模型。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07498", "html_url": "https://arxiv.org/abs/2511.07498", "title": "聚焦语言：揭示并利用多语言大型语言模型中的语言注意力头部", "title_en": "Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models", "authors": "Xin Liu,Qiyang Song,Qihang Zhou,Haichao Du,Shaowen Xu,Wenbo Jiang,Weijuan Zhang,Xiaoqi Jia", "background": "大型语言模型（LLMs）在支持多语言理解和生成方面发挥着越来越重要的作用。同时，对它们内部机制的解释性研究也逐渐增多，这些研究为提高多语言性能提供了见解。尽管多头自我注意力（MHA）已经在很多领域证明了其关键性，但其在多语言能力方面的角色尚未被充分探索。本研究旨在探讨MHA在支持LLMs多语言处理中的贡献。", "innovation": "本文提出了一种名为Language Attention Head Importance Scores（LAHIS）的有效高效方法，用于通过一次前向和一次反向传播过程来识别多语言能力中的注意力头重要性。通过LAHIS，研究揭示了存在语言特定头（language-specific heads）和语言通用头（language-general heads）。还提出了一种轻量级的头调整技术，通过学习软头掩码调整注意力输出，仅需20个可调参数即可提高XQuAD准确率。", "conclusion": "本研究提高了对MHA在LLMs中角色的理解，并且通过揭示语言特定头和语言通用头及其在提升多语言LLMs性能方面的贡献，展示了多语言LLMs的可解释性和性能提升。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07496", "html_url": "https://arxiv.org/abs/2511.07496", "title": "在减轻扩散模型幻觉中的拉普拉斯评分锐化", "title_en": "Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models", "authors": "Barath Chandran.C,Srinivas Anumasa,Dianbo Liu", "background": "扩散模型在生成图像方面表现出色，但存在幻觉问题，导致生成的样本不连贯或不现实。现有研究将这个问题归因于模式插值和分量光滑现象，但缺乏在生成过程中防止这些现象的方法。本文分析了拉普拉斯（或清晰度）与评分不确定性之间的关系，并提出了一种在推理过程中对评分函数进行后处理调整的方法，以减少无条件扩散模型在1D、2D和高维图像数据中的幻觉现象。该方法使用Hutchinson追踪估计的有限差分版本来高效地获取高维情况下的拉普拉斯近似值。实验结果表明，该修正措施显著降低了幻觉样本的生成频率，具体表现在玩具1D/2D分布和高维图像数据集上。", "innovation": "本文提出了一种基于评分函数拉普拉斯值的后处理调整方法，以减少扩散模型在各种维度图像数据上的幻觉现象。通过使用Hutchinson追踪估计的有限差分版本，提出了一种高效的拉普拉斯近似值计算方法，该方法能够显著降低幻觉样本的生成频率，特别是在不同维度的数据集上表现明显。", "conclusion": "本文通过引入一种基于拉普拉斯值的评分函数后处理调整方法，显著减少了扩散模型中幻觉现象的产生概率。这种方法不仅适用于1D和2D数据，还可以扩展到处理高维图像数据。实验结果表明该方法的有效性，并进一步探讨了拉普拉斯值与评分不确定性之间的关系。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07499", "html_url": "https://arxiv.org/abs/2511.07499", "title": "通过对抗性Sinkhorn注意引导迈向可靠的扩散采样前沿", "title_en": "Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance", "authors": "Kwanyoung Kim", "background": "扩散模型在使用诸如分类器-free引导（CFG）等指导方法时，展示了很强的生成性能，这些方法通过修改采样轨迹来提高输出质量。这些方法通常通过故意降级除目标输出之外的其他输出，比如未条件输出，使用诸如身份混合或模糊条件等启发式扰动函数来改进目标输出。然而，这些方法缺乏理论基础，并依赖于手动设计的失真。", "innovation": "提出了一种名为对抗性Sinkhorn注意引导（ASAG）的新方法，通过最优运输的角度重新诠释扩散模型中的注意力分数，并通过Sinkhorn算法故意破坏运输成本。ASAG在自我注意层中注入对手性成本，以减少查询和键之间的像素相似性，从而减弱误导性的注意对齐，提高条件和未条件样本质量，增强了方法在下游应用程序（如IP-Adapter和ControlNet）中的控制能力和保真度。该方法轻量级且易于部署，无需重新训练模型即可提高可靠性。", "conclusion": "ASAG在文本到图像扩散中表现出一致的改进，增强了下游应用中的可控性和保真度。该方法轻量级、插拔即用，并提高了生成结果的可靠性而无需重新训练模型。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07559", "html_url": "https://arxiv.org/abs/2511.07559", "title": "N-ReLU: 零均值随机扩展的ReLU", "title_en": "N-ReLU: Zero-Mean Stochastic Extension of ReLU", "authors": "Md Motaleb Hossen Manik,Md Zabirul Islam,Ge Wang", "background": "激活函数是深度神经网络实现非线性表示的基础。然而，标准的ReLU激活函数经常会由于其硬性零截止而导致神经元变得无效或“死亡”。", "innovation": "引入N-ReLU（Noise-ReLU），它是ReLU的零均值随机扩展，用高斯噪声替换负激活值，同时保持相同的期望输出。这种期望对齐的公式可以在不活动区域维持梯度流动，并且在训练中作为退火类型的正则化器。", "conclusion": "实验表明，使用MNIST数据集，N-ReLU在中等噪声水平（σ = 0.05-0.10）下，其准确度与或略高于ReLU、LeakyReLU、PReLU、GELU和RReLU，且收敛稳定，未观察到无效神经元。这些结果表明，轻量级的高斯噪声注入提供了一种简单且有效的机制，可以增强优化鲁棒性，而不需要修改网络结构或引入额外参数。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07503", "html_url": "https://arxiv.org/abs/2511.07503", "title": "生物导向的合成基因组模型混合成员推理攻击", "title_en": "Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models", "authors": "Asia Belfiore,Jonathan Passerat-Palmbach,Dmitrii Usynin", "background": "随着遗传数据的可用性增加，基因组学研究受到了极大的推动，但也引发了许多关于隐私保护的担忧，因为这些数据具有敏感性。这项工作探索了利用语言模型（LMs）生成合成的遗传突变谱型，并利用差分隐私（DP）保护敏感的遗传数据。为了评估我们模型的隐私保护性能，开发了一种新的生物导向的混合成员推理攻击（biHMIA），结合了传统的黑盒MIA和基于上下文的遗传学度量，以增强其攻击能力。我们的实验结果显示，无论是小型还是大型的变压器GPT-like模型都是小规模基因组学中生成合成变异的有效工具，并且我们的混合攻击相较于传统的基于度量的成员推理攻击平均能产生更高的对抗成功率。", "innovation": "本文提出了一种新的生物导向的混合成员推理攻击（biHMIA），并利用差分隐私（DP）对生成的合成遗传突变谱型进行隐私保护。相比传统的基于度量的成员推理攻击，此种新的攻击方法具有更高的成功率，能够在小规模基因组学数据中验证生成模型的有效性和模型的隐私风险。这种结合生物信息学知识和机器学习方法的攻击模型为后续的隐私保护研究提供了新的思路。", "conclusion": "实验表明，小规模和大型的变压器GPT-like模型在小规模基因组学中都可以有效生成合成变体，而我们的混合攻击方法在攻击成功率上优于传统的基于度量的成员推理攻击，提示了在隐私保护评估中的创新思路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07585", "html_url": "https://arxiv.org/abs/2511.07585", "title": "LLM输出漂移：跨提供商验证及对金融工作流程的缓解", "title_en": "LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows", "authors": "Raffi Khatchadourian,Rolando Franco", "background": "金融机构使用大语言模型（LLMs）进行对账、监管报告和客户沟通等活动，但这些模型的不定确定性输出（输出漂移）削弱了审计能力和信任度。", "innovation": "研究引入了一个针对金融任务量身定制的确定性测试框架，包括贪婪解码、固定种子和与SEC 10-K结构相关的检索顺序。还设计了特定任务不变性检查方法，用于RAG、JSON和SQL输出，使用金融校准的物质性阈值（±5%）和SEC引文验证。此外，提出了一种三层模型分类系统以支持适当的风险部署决策，并建立了一套审计准备就绪的证明系统，通过双重提供者验证。", "conclusion": "研究评估了五种模型在三种受监管的金融任务上的表现，在480次运行中，结构化任务（SQL）在T=0.2时仍然稳定，而RAG任务显示出漂移（25-75%），揭示了任务依赖性敏感性。跨提供者验证确认确定性行为在本地和云部署之间转移。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07593", "html_url": "https://arxiv.org/abs/2511.07593", "title": "利用AI和社交互动恢复公共民意调查中的信任", "title_en": "Leveraging the Power of AI and Social Interactions to Restore Trust in Public Polls", "authors": "Amr Akmal Abouelmagd,Amr Hilal", "background": "随着众包数据的出现，社会科学研究得到了重塑，能够广泛探索集体人类行为、观点和社会动态。然而，确保安全、公平和可靠的数据参与仍是一个持续的挑战。传统民调方法近年来的参与度下降，引发了对所收集数据可信度的担忧。同时，社交媒体和点对点网络的普及带来了数据真实的信任问题，因为这些平台上的数据可能因欺诈或不合格的参与而出现问题。", "innovation": "本文探讨如何利用社会互动来恢复社交媒体上收集的众包数据的可信度。提出了基于人工智能的图分析方法，通过检测参与者（包括诚实和不诚实参与者）之间的社会互动，识别不符合资格的参与行为。该方法专注于社会互动图的结构特征，而不依赖于共享的内容。通过模拟不同层次和类型的不诚实行为，研究在多种资格标准和不同的参与模式下的表现，结果显示，在某些配置下，检测无资格参与的准确率超过90%。", "conclusion": "研究在不同的社会和行为特征中取得了令人鼓舞的结果，展现了通过对社会互动图结构的分析来检测无资格参与的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07584", "html_url": "https://arxiv.org/abs/2511.07584", "title": "SemanticForge：通过语义知识图和约束满足实现仓库级别代码生成", "title_en": "SemanticForge: Repository-Level Code Generation through Semantic Knowledge Graphs and Constraint Satisfaction", "authors": "Wuyang Zhang,Chenkai Zhang,Zhen Luo,Jianming Ma,Wangming Yuan,Chuqiao Gu,Chenwei Feng", "background": "大语言模型（LLMs）已经通过实现自动化代码生成，推动了软件开发的进步，但同时它们也时常伴随着系统性的错误，这些错误限制了它们的实用部署。这些错误源于代码仓库范围内的语义缺乏明确、可查询的表示。", "innovation": "SemanticForge引入了四种基本的算法进步，用于语义意识的代码生成：（1）一种新型的自动双静态-动态知识图解算算法，统一编译时和运行时的程序语义；（2）一种神经方法，能够从自然语言学习生成结构化图形查询，相较传统检索其精准度达到了73% vs 51%；（3）一种结合SMT求解的创新束搜索算法，使约束验证能够在代码生成期间实时进行而非事后验证；（4）一种增量维护算法，在O(|ΔR| * log n)时间内更新知识图谱并保持语义等价。", "conclusion": "SemanticForge通过语义知识图谱和约束满足技术，实现了仓库级别的代码生成，解决了LLMs在软件开发中的系统性错误问题，并通过一系列算法进步提升了代码生成的质量与效率。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07603", "html_url": "https://arxiv.org/abs/2511.07603", "title": "全类型专家路由：用于异构图变换器的同质专家路由", "title_en": "One Router to Route Them All: Homogeneous Expert Routing for Heterogeneous Graph Transformers", "authors": "Georgiy Shakirov,Albert Arakelov", "background": "在异构图神经网络（HGNNs）中，通常会根据节点/边类型来条件设置参数，假设类型反映了语义角色。然而，这种方法可能导致对表面标签的过度依赖，并妨碍跨类型的知识转移。", "innovation": "探索将Mixture-of-Experts（MoE）整合到HGNNs中，这是一种尚未被充分探索的领域，尽管MoE在同构设置中取得了成功。关键在于提出了Homogeneous Expert Routing（HER）用于Heterogeneous Graph Transformers（HGT）的MoE层，该层在路由时随机遮挡类型嵌入，以促进无类型依赖的专业化。", "conclusion": "HER在IMDB、ACM和DBLP上的链接预测任务中表现出色，优于标准HGT和类型分离的MoE基线。分析显示，HER专家通过语义模式（如电影类型）进行专业化的学习，而非类型。我们的工作表明，通过规制专家路由中的类型依赖性，可以得出更具一般性的、更高效且可解释的表示，这是一种异构图学习的新设计原则。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07505", "html_url": "https://arxiv.org/abs/2511.07505", "title": "FedRW: 提高联邦语言模型学习效率的高效隐私保护数据重加权", "title_en": "FedRW: Efficient Privacy-Preserving Data Reweighting for Enhancing Federated Learning of Language Models", "authors": "Pukang Ye,Junwei Luo,Xiaolei Dong,Yunbo Yang", "background": "在大规模语料库中，数据重复往往阻碍大型语言模型（LLMs）的表现和隐私保护。在涉及隐私的数据联邦学习场景中，传统去重方法通常依赖于可信第三方执行统一删除，但这会增加隐私风险并可能导致有用数据的丢失。为了解决这些问题，本文提出了一种新的联邦重加权（FedRW）框架，它利用样本重加权而非删除来实现软去重，无需假定存在可信第三方。FedRW提出了一种通过安全多方计算实现的安全、频率感知重加权协议，同时采用并行协调策略确保高效性和可扩展性。通过在训练过程中适时调整个体损失贡献，FedRW能够有效提高泛化能力和鲁棒性。实验结果表明，与当前最佳方法相比，FedRW在预处理速度上提升了28.78倍，并且困惑度降低了约11.42%，同时提高了安全保证水平。因此，FedRW为联邦LLM训练中的数据去重管理建立了一个新范式。", "innovation": "FedRW 提出了首个无需可信第三方的可隐私保护联邦重加权框架，通过安全多方计算实现频率感知的样本重加权，以避免数据删除的损失和隐私风险，同时保持高性能和高可扩展性。在联邦训练中，FedRW 利用全局样本频率进行自适应重加权机制，有效提高泛化能力和鲁棒性。相比现有方法，FedRW 在预处理速度和困惑度方面均表现出显著优势。", "conclusion": "FedRW 在联邦学习的背景下提供了一种新的数据去重方法，不仅提高了语言模型训练的效率，还增强了隐私保护，确保了数据安全性和效果的双重提升。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07649", "html_url": "https://arxiv.org/abs/2511.07649", "title": "使用Transformer的自适应图学习在多水库入库流量预测中的应用", "title_en": "Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction", "authors": "Pengfei Hu,Ming Fan,Xiaoxue Han,Chang Lu,Wei Zhang,Hyun Kang,Yue Ning,Dan Lu", "background": "水库入库流量预测对水资源管理至关重要，但现有的方法主要关注单水库模型，忽略了互联水库间的空间依赖关系。", "innovation": "提出了AdaTrip作为一种自适应的时间波动图学习框架，用于多水库入库流量预测。AdaTrip构建了动态图，水库节点间通过有向边反映水文连接，利用注意力机制自动识别关键的空间和时间依赖关系。", "conclusion": "在Upper Colorado River Basin的30个水库上进行的评估表明，AdaTrip优于现有基线，在记录有限的水库中表现出更好的性能，且通过参数共享提高了预测精度。此外，AdaTrip提供了可解释的关注图，从边和时间步长级别提供水文控制见解，支持操作决策。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07629", "html_url": "https://arxiv.org/abs/2511.07629", "title": "部分动作替换：处理离线多智能体强化学习中的分布偏移", "title_en": "Partial Action Replacement: Tackling Distribution Shift in Offline MARL", "authors": "Yue Jin,Giovanni Montana", "background": "离线多智能体强化学习（MARL）面临的一个严重挑战是如何评估不在训练数据分布中的联合动作。特别是在样本收集过程中，智能体的行为策略往往因子化，即智能体在数据收集过程中完全或部分独立行动，这增加了评估这些策略的难度和复杂性，进而影响了离线MARL的有效性。因此，如何有效处理这种不在分布中的联合动作问题，成为研究的重点和难点之一。", "innovation": "该研究的核心发现是当行为策略因子化时，通过部分动作替换（PAR）策略可以显著缓解这一问题。PAR更新了一部分或所有智能体的动作，使其他智能体保持不变，以此来减少与其他全联合动作更新策略相比的分布偏移。在此基础上，研究开发了Soft-Partial Conservative Q-Learning（SPaCQL），利用部分动作替换策略缓解不在分布中的问题，并基于价值估计不确定性动态加权不同的部分动作替换策略。研究表明，在因子化行为策略下，由策略诱导出的分布偏移与偏离行为策略的智能体数量成线性关系而非指数关系，从而为这类重要的离线MARL问题提供了更精确的价值误差边界。理论结果还表明，SPaCQL能够适应并利用不确定性加权来解决分布偏移问题。", "conclusion": "实验证明，SPaCQL能够使策略学习更有效，并且在离线数据集呈现独立结构时，其效能显著优于基准算法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07637", "html_url": "https://arxiv.org/abs/2511.07637", "title": "Private-RAG: 在使用大语言模型的同时保护您的数据隐私以回答多个查询", "title_en": "Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private", "authors": "Ruihan Wu,Erchi Wang,Zhiyuan Zhang,Yu-Xiang Wang", "background": "检索增强生成（RAG）可以通过在推理阶段从外部语料库检索文档来增强大型语言模型（LLMs）。然而，当这些语料库包含敏感信息时，未受保护的RAG系统存在泄露私人信息的风险。以往的工作已经在单查询设置中引入了差分隐私（DP）保证，但这些不足以为实际使用场景提供充分的安全性保障。", "innovation": "本文研究了多查询设置，并提出两种DP-RAG算法：第一个算法MURAG利用个人隐私过滤器，使得累积隐私损失仅依赖于每个文档被检索的频率，而不是总查询次数。第二个算法MURAG-ADA进一步改善了实用性，通过在查询级别私密地发布阈值来释放，从而能更精确地选择相关文档。实验表明，在实际的差分隐私预算（ε≈10）下，所提方法可扩展到数百个查询，同时保持有意义的实用性。", "conclusion": "实验结果表明，所提出的方法在实际的差分隐私预算下可扩展到数百个查询，同时保持有意义的实用性，从而在多查询场景下实现了大语言模型和数据隐私的平衡。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07645", "html_url": "https://arxiv.org/abs/2511.07645", "title": "大语言模型动态安全的自我改进架构", "title_en": "A Self-Improving Architecture for Dynamic Safety in Large Language Models", "authors": "Tyler Slater", "background": "大型语言模型（LLMs）正在被集成到核心软件系统中，现有的软件架构模式是静态的，而当前的安全保障方法不具备可扩展性，使得系统容易受到新型的对抗性威胁。", "innovation": "提出了一种新的自适应软件架构——Self-Improving Safety Framework (SISF)，它通过一个未保护、未对齐的基本LLM（mistralai/Mistral-7B-v0.1）和一个动态反馈循环来实现运行时的自动和连续的安全协议适应。该循环包括用于检测违规的AI仲裁器（GPT-4o）和生成新的综合性安全策略的策略合成模块（GPT-4 Turbo），这些策略可以是基于启发式的方法或语义的方法。", "conclusion": "基于自我适应原则的架构方法是可行且有效的策略。通过实验证明，该框架提供了一条实用的道路，用于构建更具稳健性、适应性和可扩展性的AI驱动系统，从而将安全保障从静态的、事前的活动转变为自动的、运行时的过程。在对520个正常提示的测试中，SISF实现了0.00%的误报率，证明了其在不损害用户便利性的前提下拥有自适应的能力。这种方法展示了通过自动化和实时机制来保障AI系统的正常运行的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07677", "html_url": "https://arxiv.org/abs/2511.07677", "title": "教室环境中听力受损儿童的语音分离", "title_en": "Speech Separation for Hearing-Impaired Children in the Classroom", "authors": "Feyisayo Olalere,Kiki van der Heijden,H. Christiaan Stronks,Jeroen Briaire,Johan H. M. Frijns,Yagmur Güçlütürk", "background": "教室环境对听力受损儿童来说特别具有挑战性，背景噪音、多说话者和混响会降低语音感知效果。相较于成人，儿童面临的这些困难更大。然而，目前大多数用于助听设备的基于深度学习的语音分离模型都使用简化的、低混响条件下的成人语音进行开发，这忽视了儿童声音的更高频谱相似性，以及真实教室中复杂的声学环境。", "innovation": "采用MIMO-TasNet，这是一种紧凑的、低延迟的多通道架构，适合在双侧助听器或人工耳蜗植入物中的实时部署。通过模拟不同噪声和距离条件下的自然教室场景，研究不同的训练策略如何通过空间线索让模型更好地适应儿童的语音。实验还对比了使用成人语音、教室数据以及微调变体训练模型，证明了这些模型在教室数据上的适配性和效率。", "conclusion": "成人训练的模型在干净场景中表现良好，但教室特异性训练显著改善了语音分离质量。仅用一半教室数据进行微调就能获得相似的提升，这证明了高效的学习迁移。使用扩散的背景噪音进一步增强了模型的鲁棒性，模型在保持空间意识的同时，也能推广到未见过的距离。这些发现表明，结合空间意识架构和目标适配可以提升听力受损儿童在嘈杂教室中的语音可访问性，支持未来设备上的辅助技术的进步。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07663", "html_url": "https://arxiv.org/abs/2511.07663", "title": "Cortex AISQL：一种用于非结构化数据的生产SQL引擎", "title_en": "Cortex AISQL: A Production SQL Engine for Unstructured Data", "authors": "Paritosh Aggarwal,Bowei Chen,Anupam Datta,Benjamin Han,Boxin Jiang,Nitish Jindal,Zihan Li,Aaron Lin,Pawel Liskowski,Jay Tayade,Dimitris Tsirogiannis,Nathan Wiegand,Weicheng Zhao", "background": "在生产规模下使语义操作高效面临着根本性的挑战。传统SQL操作成本较低，而语义操作成本较高，具有独特的延迟和吞吐量特性。此外，查询引擎在优化语义操作方面并不是设计好的。因此，需要设计专门的查询执行引擎来解决这些问题，Snowflake的Cortex AISQL引擎便是一个这样的解决方案，它在SQL中直接集成语义操作，允许用户编写包含关系运算和语义推理的声明式查询，以轻松地查询结构化和非结构化数据。", "innovation": "Cortex AISQL 在雪flake的生产部署数据的指导下，提出了三种创新的技术：首先，AI感知查询优化将AI推理成本作为首要优化目标，在查询计划中直接考虑大规模语言模型的成本，以实现2-8倍的速度提升。其次，自适应模型级联通过将大多数行路由到快速代理模型，并在不确定情况下将它们提升到强大的权威模型，减少了推理成本，达到2-6倍的速度提升，同时保持90-95%的权威模型质量。最后，语义连接查询重写将连接操作的时间复杂度从二次降至线性，将其重新表述为多标签分类任务，实现了15-70倍的速度提升，并在很多情况下提高了预测质量。", "conclusion": "Cortex AISQL 在雪flake中部署并在生产中运行，支持多样化的客户工作负载，包括分析、搜索和内容理解。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07659", "html_url": "https://arxiv.org/abs/2511.07659", "title": "重访自然语言推理：朝向高效且与人类对齐的评估指标", "title_en": "Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering", "authors": "Sai Shridhar Balamurali,Lu Cheng", "background": "评估最先进的大型语言模型（LLMs）的回答具有挑战性：词汇度量漏掉语义细微差别，而“LLM作为裁判”的评分计算成本高昂。我们重新评估一个轻量级替代方案——配备简单词汇匹配标志的现成自然语言推理（NLI）评分，发现这种几十年前的技术在长段问答任务上与GPT-4o的准确率相当（89.9%），同时需要远少得多的参数量。为了严格测试这些度量的人类对齐度，我们引入了DIVER-QA，这是一个包含3000个人标注样本的新基准，覆盖五个问答数据集和五个候选LLM。我们的结果凸显了廉价的基于NLI的评估仍然具有竞争力，并提供DIVER-QA作为未来指标研究的开放资源。", "innovation": "提出了一种基于现成自然语言推理（NLI）评分并辅以简单词汇匹配标志的轻量级评估方法，该方法在长段问答任务上的准确率与GPT-4o相当，同时也显著降低了参数成本。通过引入DIVER-QA基准，该研究严格测试了这些度量的人类对齐度，为未来评估指标研究提供了开放资源。", "conclusion": "基于NLI的评估方法仍然是具有竞争力的选择，尽管成本低廉，但在长段问答任务上的准确率与GPT-4o相当。还通过DIVER-QA为未来的研究提供了新的基准资源。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07682", "html_url": "https://arxiv.org/abs/2511.07682", "title": "设计和评估马林诺夫斯基的镜头：一种针对民族志学习的人工智能本源教育游戏", "title_en": "Designing and Evaluating Malinowski's Lens: An AI-Native Educational Game for Ethnographic Learning", "authors": "Michael Hoffmann,Jophin John,Jan Fillies,Adrian Paschke", "background": "本研究基于布罗尼斯拉夫·马林诺夫斯基的作品《西方太平洋的航海者》（1922年），引入了‘马林诺夫斯基的镜头’，这是首个AI本源的教育游戏。该游戏将马林诺夫斯基作品中的复杂民族学概念融入互动学习体验中，旨在通过人工智能技术提高用户学习效果，同时确保游戏设计的伦理性和教育价值。", "innovation": "该研究的创新点在于，结合了检索增强生成技术和DALL-E 3的文本转图像生成技术，创建了一种VGA风格的视觉效果，并在游戏中代入马林诺夫斯基在托布里安群岛的田野工作（1915-1918年）。同时，通过确保原住民仅以剪影出现，而马林诺夫斯基被详细描绘的方式，解决了伦理问题，鼓励了对民族学表现形式的反思。此外，两种验证研究证实了游戏的有效性，为将学术文本转化为互动体验提供了一种可复制的模式。", "conclusion": "该研究展示了AI驱动的教育游戏能有效传达复杂的民族学概念，并激发学科兴趣。研究推进了人工智能本源教育游戏的设计，并提供了一个将学术文本转化为吸引人的互动体验的可复制模型。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07665", "html_url": "https://arxiv.org/abs/2511.07665", "title": "FractalCloud: 一种受分形启发的大规模点云处理高效架构", "title_en": "FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing", "authors": "Yuzhe Fu,Changchun Zhou,Hancheng Ye,Bowen Duan,Qiyu Huang,Chiyue Wei,Cong Guo,Hai \"Helen'' Li,Yiran Chen", "background": "三维（3D）点云在自动驾驶、机器人学和虚拟现实（VR）等应用中越来越受到重视。点基于神经网络（PNNs）在点云分析中表现出强大的性能，最初主要针对小规模输入。然而，随着PNNs处理具有数十万点的大型点云时，全连接和全局内存访问带来了显著的开销，导致计算复杂度和内存流量为$O(n^2)$，其中n为点的数量。现有的加速器主要针对小规模工作负载，未能解决这一问题，并且由于不高效的划分和非并行架构而无法很好地扩展。为此，提出了一种分形启发的大规模3D点云处理高效硬件架构——FractalCloud，以应对上述问题。", "innovation": "FractalCloud通过以下两种关键优化来解决上述问题：（1）一种协同设计的分形方法，用于形状感知和硬件友好的划分；（2）区块并行点操作，可分解和并行化所有点操作。一种专用硬件设计，并且实现了内部分形和灵活并行性，进一步允许在有限内存资源中进行完全并行处理。FractalCloud在28纳米技术下实现，核心区域为1.5 $mm^2$，在保持网络准确性的前提下，速度提高了21.7倍，能效降低了27倍，验证了其在PNN推理中的可扩展性和效率。", "conclusion": "FractalCloud通过基于分形的设计，实现了大规模点云处理的高效性，在保持数据精度的同时显著减少了计算时间和能耗，展示了其在PNN推理中的潜力和应用前景。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07689", "html_url": "https://arxiv.org/abs/2511.07689", "title": "对长文档摘要事实一致性的压力测试", "title_en": "Stress Testing Factual Consistency Metrics for Long-Document Summarization", "authors": "Zain Muhammad Mujahid,Dustin Wright,Isabelle Augenstein", "background": "对抽样生成的文本摘要进行事实一致性评估仍然是一个显著挑战，特别是在长文档中，传统的评估指标在处理输入长度限制和长距离依赖时表现出不足。研究者们对广泛使用的六种无参照的事实一致性评估指标进行了系统性评估，这些指标最初是为短摘要设计的，但在长文档环境下表现出了不一致性和可靠性下降的问题。通过对摘要进行七种保留事实的修改，研究者进一步测试了这些指标的稳健性，并分析了它们对提取上下文和声明信息密度的敏感性。", "innovation": "研究者提出了一种系统性的方法，对短摘要指标在长文档场景下的适用性进行了评估，并通过修改保留事实的方式来测试指标的鲁棒性。研究发现，现有短摘要的评价指标在长文档环境下无法保持一致性和可靠性，特别是在信息密度高的声明中更为显著。此外，将检索上下文扩大可以改善某些领域的一致性，但没有一种指标在长上下文条件下能够保持事实的一致性。研究还指出了提高事实一致性评估的具体方向，包括多跨度推理、上下文感知校准和通过保持意义不变的变体进行训练，以增强长摘要摘要的稳健性。", "conclusion": "尽管扩大检索上下文可以在某些领域提高一致性，但在长上下文中没有一种指标能够稳定保持事实的一致性。研究结果还指出了改进事实评估的方向，包括多跨度推理、上下文感知校准和使用保持意义不变的数据进行训练。所有相关代码、修改数据和脚本都已公开，以供验证研究结果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07691", "html_url": "https://arxiv.org/abs/2511.07691", "title": "CAPO：针对多语言偏好的自信心感知偏好优化学习", "title_en": "CAPO: Confidence Aware Preference Optimization Learning for Multilingual Preferences", "authors": "Rhitabrat Pokharel,Yufei Tao,Ameeta Agrawal", "background": "偏好优化是一种后训练技术，用于使大型语言模型（LLMs）与人类偏好对齐，通常通过排序响应对进行微调。尽管像直接偏好优化（DPO）这样的方法在英语中已经证明有效，但在多语言设置中往往不能稳健地推广。", "innovation": "提出了一种简单而有效的替代方案，即自信心感知偏好优化（CAPO），它用基于相对奖励的动态损失比例机制来替代DPO中固定的偏好对处理方式。通过根据每个偏好对的信心调节学习信号，CAPO增强了对嘈杂或低差异比较的鲁棒性，这类情况在多语言文本中通常会遇到。实验结果显示，CAPO在奖励准确性上至少比现有偏好优化基准提高了16%，并且通过增加偏好和不偏好响应之间的差距来改善了对齐。", "conclusion": "CAPO在多语言偏好优化中表现出色，能够提高奖励准确性和跨语言的模型对齐。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07701", "html_url": "https://arxiv.org/abs/2511.07701", "title": "受扩散引导的对抗性状态扰动在强化学习中的应用", "title_en": "Diffusion Guided Adversarial State Perturbations in Reinforcement Learning", "authors": "Xiaolin Sun,Feidi Liu,Zhengming Ding,ZiZhan Zheng", "background": "强化学习（RL）系统在多个领域取得了显著成功，但在对抗攻击面前却显得脆弱。特别是在基于视觉的环境中，高维图像输入的微小篡改就足以误导代理的行为。为对抗这一问题，近期提出了一系列防御方法，但这些方法的有效性有时依赖于现有攻击的局限性。具体来说，现有的$l_p$范数约束攻击仅能微小地改变图像的含义，这就为新攻击方法的开发提供了空间。本文描述了对当前防御机制的深度调查，揭示了其脆弱性，并提出了应对这些挑战的新方法。", "innovation": "本文提出了一种名为SHIFT的新颖策略，这是一种与策略无关的基于扩散的过程状态扰动攻击方法。SHIFT能够在引入新的语义差异的同时，保持状态的现实性并与历史数据保持一致，从而避免被检测到。这种方法在现有的最高级防御面前表现出了显著的效果，并且具有更高的感官隐蔽性。研究表明，STATH能够在保持现实性的同时改变状态的语义特征，从而有效地突破现有防御措施，证明了强化学习代理对于语义感知的对抗性扰动的脆弱性。", "conclusion": "该研究强调了强化学习代理对于语义感知对抗性扰动的脆弱性，并指出需要开发更加稳健的策略来提升这些代理的防御能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07707", "html_url": "https://arxiv.org/abs/2511.07707", "title": "基于谈判的多智能体强化学习方法在可重构制造系统动态调度中的应用", "title_en": "A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems", "authors": "Manonmani Sekar,Nasim Nezamoddini", "background": "可重构制造系统（RMS）是未来市场调整的关键，因其能够迅速适应消费者需求波动、新技术引入以及供应链中断等复杂变化。现有RMS的固有刚性设置需要一个灵活的软规划机制，以便在复杂和多变的配置中实现实时的生产调度和规划。本研究探讨了多智能体强化学习（MARL）在RMS软规划中的动态调度应用，旨在通过强化学习实现实时机器任务分配，适应随机事件如机器故障和重新配置延迟。", "innovation": "本研究提出了一种基于谈判的多智能体强化学习方法，通过中心化训练的深度Q网络（DQN）代理进行实时任务分配和调度。模型还引入了注意力机制以增强状态表示并改善决策更为关注关键系统特征的决定。研究还使用优先经验回放、n步回报、双DQN和软目标更新等DQN增强技术以稳定并加速学习过程。实验结果表明，该方法相比于基线启发式方法在减少稼动时间和延迟、提高机器利用率方面具有显著优势。", "conclusion": "实验在模拟的RMS环境中进行，结果显示增强的DQN代理在应对动态条件方面具有有效性，但机器故障增加了关键性能指标如稼动时间、吞吐量和总延迟的变异性。研究确认了在动态可重构制造环境中应用MARL机制对于智能和自适应调度的优势。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07734", "html_url": "https://arxiv.org/abs/2511.07734", "title": "基于谱表示的高斯过程在图结构数据上的全局优化", "title_en": "Global Optimization on Graph-Structured Data via Gaussian Processes with Spectral Representations", "authors": "Shu Hong,Yongsheng Mei,Mahdi Imani,Tian Lan", "background": "贝叶斯优化（BO）是一种对昂贵的黑盒目标进行优化的强大框架，但在扩展到图结构领域时仍面临挑战，因为图是离散和组合性质的。现有的方法往往依赖于全图拓扑结构，这在大型或部分观测图中是不切实际的，或者依赖于增量探索，这可能导致收敛速度慢。", "innovation": "提出了一种具有谱表示的高斯过程（GP）在图结构数据上进行全局优化的可扩展框架。该方法利用稀疏结构观察构建低秩谱表示的高斯过程代理，通过学习嵌入联合推断图结构和节点表示，即使在有限数据下也能实现高效全局搜索和有原则的不确定性估计。", "conclusion": "在合成和真实数据集上的实验表明，与先前方法相比，该方法实现了更快的收敛速度和优化性能，并提供了不同采样方案下准确恢复底层图结构的理论分析条件。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07748", "html_url": "https://arxiv.org/abs/2511.07748", "title": "Auto-US: 使用视频分类框架和大语言模型的超声视频诊断代理", "title_en": "Auto-US: An Ultrasound Video Diagnosis Agent Using Video Classification Framework and LLMs", "authors": "Yuezhe Yang,Yiyue Guo,Wenjie Cai,Qingqing Ruan,Siying Wang,Xingbo Dong,Zhe Jin,Yong Dai", "background": "当前的AI辅助超声影像诊断研究在数据多样性、诊断性能和临床应用方面存在局限性。现有工作未能充分利用丰富的超声影像数据，导致无法有效提升诊断效率和准确性。", "innovation": "该研究提出了一种名为Auto-US的智能诊断代理，它结合了超声视频数据和临床诊断文本。开发了CTU-Net，在超声视频分类中达到了领先水平，并通过整合大语言模型为临床提供了有意义的诊断建议。", "conclusion": "Auto-US在实际临床应用中展示了高效性和潜在的临床价值，每个案例的最终诊断评分均超过3分，并得到专业临床医生的验证。相关代码和数据已公开提供。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07732", "html_url": "https://arxiv.org/abs/2511.07732", "title": "ViPRA: 视频预测用于机器人动作", "title_en": "ViPRA: Video Prediction for Robot Actions", "authors": "Sandeep Routray,Hengkai Pan,Unnat Jain,Shikhar Bahl,Deepak Pathak", "background": "现有的视频预测模型主要是用来预测未来的视觉观察，但它们缺乏标注的动作信息，这限制了它们在机器人学习中的应用。本研究利用无动作标注的视频来学习机器人的连续控制，提出了一个简单的预训练-微调框架ViPRA。", "innovation": "本文介绍了一种名为Video Prediction for Robot Actions (ViPRA) 的简单预训练-微调框架，它从无动作标注的视频中学习机器人的连续控制。该方法训练了一个视频-语言模型，该模型不仅预测未来视觉观察，还预测与场景动态密切相关的中间表示的运动中心隐动作。引入了一个分块光学流匹配解码器，将这些隐动作映射到特定于机器人的连续动作序列，从而可以仅使用100到200次示例就实现不受动作标注成本的控制，并且这种方法在模拟实验和真实世界操作任务中表现优于其他基准和现有方法。", "conclusion": "本研究提出的方法在SIMPLER基准上提高了16%，在实际操作任务上的不同能力方面均有13%的进步，使得机器人能够以高达22 Hz的频率进行平滑的递减连续控制，是一个无需昂贵动作标注，支持不同体态切换，能够进行高频率连续控制的创新方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07737", "html_url": "https://arxiv.org/abs/2511.07737", "title": "TurboSAT：加速GPU-CPU混合系统中的梯度引导布尔可满足性", "title_en": "TurboSAT: Gradient-Guided Boolean Satisfiability Accelerated on GPU-CPU Hybrid System", "authors": "Steve Dai,Cunxi Yu,Kalyan Krishnamani,Brucek Khailany", "background": "虽然加速计算已经在许多计算领域发生了革命性的变化，但对于逻辑推理，特别是布尔可满足性（SAT）问题的影响依然有限。当前最先进的SAT求解器依赖于冲突驱动的顺序搜索算法，这些算法虽然提供了强大的启发式方法，但也限制了可以利用的并行性程度，从而无法实现更广泛的SAT求解方式。", "innovation": "受神经网络训练的启发，本文将SAT问题表达为二进制矩阵乘法层，并通过可微优化函数进行优化。这种方法利用了并行差异优化和顺序搜索的优点，以加速SAT问题在GPU-CPU混合系统上的求解。在该系统中，GPU利用并行差异求解快速评估SAT子句，并运用梯度进行随机探索，优化变量分配；生成的有希望的部分分配由多个CPU线程进行后处理，运用冲突驱动的顺序搜索进一步探索信号子空间，识别完整的分配。", "conclusion": "在NVIDIA DGX GB200节点上进行模型原型设计，结果显示，与基于CPU的最先进求解器相比，该混合解算器在公开的SAT可满足性基准问题上的运行时获得了超过200倍的加速。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07743", "html_url": "https://arxiv.org/abs/2511.07743", "title": "UltraGS: 高斯点积插值在超声难题视图合成中的应用", "title_en": "UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis", "authors": "Yuezhe Yang,Wenjie Cai,Dexin Yang,Yufang Dong,Xingbo Dong,Zhe Jin", "background": "超声成像在非侵入性临床诊断中具有重要地位，但由于其有限的视场，难以进行新的视图合成。现有方法面临挑战，未能提供高质量的三维视图和结构表示，特别是在保留深度信息和准确的组织强度建模方面存在不足。", "innovation": "本文引入了UltraGS（高斯点积插值）框架，专注于优化超声成像。首先，提出了一种深度感知的高斯点积策略，每个高斯分配可学习的视场，提升深度预测的准确性。其次，设计了SH-DARS（低阶球谐加超声特定波动物理）轻量级渲染函数，模拟组织强度，同时考虑了深度衰减、反射与散射。再者，贡献了临床超声检查数据集，涵盖多种解剖扫描，遵循真实世界的临床协议，提供一个基准。", "conclusion": "在三个数据集上的广泛实验表明，UltraGS在峰值信噪比（PSNR，最高29.55）、结构相似性（SSIM，最高0.89）和均方误差（MSE，最低0.002）方面达到了最先进的性能，同时支持每帧64.69次的实时合成。源代码和数据集已经开源。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07755", "html_url": "https://arxiv.org/abs/2511.07755", "title": "Filtered-ViT：应对多种恶意贴图攻击的鲁棒防御", "title_en": "Filtered-ViT: A Robust Defense Against Multiple Adversarial Patch Attacks", "authors": "Aja Khanal,Ahmed Faid,Apurva Narayan", "background": "深度学习视觉系统在医疗等关键领域得到广泛应用，但仍存在对小尺寸对抗性补丁的脆弱性，这些补丁可能导致分类错误。现有防御措施通常假设单一补丁，而面对大量小型局部干扰的情况则失效，这正是攻击者和实际世界中常见的策略。", "innovation": "本文提出了一种新的视觉变换器架构——Filtered-ViT，其中集成了一种空间自适应、多尺度且具备鲁棒性的机制SMART Vector Median Filtering (SMART-VMF)，这种机制能够选择性地抑制损坏区域，同时保留语义细节。Filtered-ViT 在 ImageNet 上对抗 LaVAN 多补丁攻击时，能够达到 79.8% 的干净准确率和 46.3% 的鲁棒准确率，优于现有防御措施。此外，在实际医疗影像中的案例研究显示，该模型能够缓解诸如遮挡和扫描器噪音等自然现象而不损害诊断内容，这是首个在对抗和自然现象方面都表现出鲁棒性的变换器模型，为可靠视觉系统铺平了道路。", "conclusion": "Filtered-ViT 在应对多种恶意补图攻击方面展示了统一的鲁棒性，是首个同时对抗人为和自然现象的鲁棒视觉系统，为高风险环境下的可靠视觉系统奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07780", "html_url": "https://arxiv.org/abs/2511.07780", "title": "Semantic-Consistent Bidirectional Contrastive Hashing for Noisy Multi-Label Cross-Modal Retrieval", "title_en": "Semantic-Consistent Bidirectional Contrastive Hashing for Noisy Multi-Label Cross-Modal Retrieval", "authors": "Likang Peng,Chao Su,Wenyuan Wu,Yuan Sun,Dezhong Peng,Xi Peng,Xu Wang", "background": "交叉模态哈希（CMH）通过将数据编码为紧凑的二进制表示，促进了不同模态（如图像和文本）之间高效检索。尽管近期的方法取得了显著的性能，但它们通常依赖于完全注释的数据集，这些数据集获取成本高且耗时。在多标签数据集中，标签噪声普遍存在，严重影响了检索性能。现有CMH方法通常忽视了多标签数据中存在的语义部分重叠，限制了其鲁棒性和泛化能力。", "innovation": "提出了一种新颖的框架，命名为语义一致双向对比哈希（SCBCH）。该框架包括两个互补模块：1）跨模态语义一致分类（CSCC），利用跨模态语义一致性估计样本可靠性并减少噪声标签的影响；2）双向软对比哈希（BSCH），基于多标签语义重叠动态生成软对比样本对，实现跨模态语义相似和不相似样本间的自适应对比学习。", "conclusion": "在四个广泛使用的跨模态检索基准上的广泛实验表明，我们的方法具有有效性和鲁棒性，在嘈杂的多标签条件下始终优于现有最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07772", "html_url": "https://arxiv.org/abs/2511.07772", "title": "SALT: 在链式思维中引导激活以实现无泄漏思考", "title_en": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought", "authors": "Shourya Batra,Pierce Tillman,Samarth Gaggar,Shashank Kesineni,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary", "background": "随着大型语言模型（LLMs）演变成具有访问敏感用户数据权限的个人助手，它们面临一个关键的隐私挑战：尽管之前的研究已经解决了输出级的隐私问题，但最近的研究发现LLMs经常通过其内部推理过程泄露私人信息，违背了语境下的隐私期望。当模型在推理过程中不小心暴露敏感细节时，即使最终输出看似安全，也会发生这种情况。挑战在于如何防止这种泄露而不牺牲模型的推理能力，需要在隐私和实用性之间找到微妙的平衡。", "innovation": "我们引入了一种名为Steering Activations towards Leakage-free Thinking（SALT）的轻量级测试时干预方法，它通过在隐藏状态中注入定向引导向量来缓解模型的链式思维（CoT）中的隐私泄露问题，并识别导致此行为的高泄露层。通过在多个LLM上的实验，我们展示了SALT可以实现CPL的显著降低，即QwQ-32B上减少了18.2%，Llama-3.1-8B上减少了17.9%，在AirGapAgent-R的上下文隐私泄露数据集中，DeepSeek上减少了31.2%，同时保持了与任务性能相当的实用性。我们的工作确立了SALT作为推理能力语言模型测试时隐私保护的实际方法，为LLM基础的个人代理的安全部署提供了路径。", "conclusion": "我们的研究确立了SALT作为一种实用的方法，在推理能力的LLM中实现测试时的隐私保护，为LLM基于的个人代理的安全部署提供了途径。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07787", "html_url": "https://arxiv.org/abs/2511.07787", "title": "Aurora编码器的物理一致性：一项定量研究", "title_en": "Physical Consistency of Aurora's Encoder: A Quantitative Study", "authors": "Benjamin Richards,Pushpa Kumar Balan", "background": "大气预报模型如Aurora尽管准确度高，但内部机制不透明，缺乏透明性，这在高风险的运行环境中限制了其应用。本文旨在通过探索Aurora编码器的潜在物理一致性来解决这一问题，使用大规模嵌入数据集训练线性分类器，识别三个关键概念：陆-海边界、极端气温事件和大气不稳定性。并指出现有模型虽然能够学习物理一致的特征，但在捕捉罕见事件方面仍有不足，突显了解释性方法在未来基于AI的大气模型中的重要性。", "innovation": "本文通过大规模数据集训练线性分类器来识别Aurora编码器中的物理一致特性的创新研究方法，提供了量化证据表明Aurora能够学习物理一致的特征，同时揭示了其局限性，特别是在捕捉极端和罕见事件方面。强调了解释性方法在验证和建立对未来基于AI的大气模型的信任的重要性。", "conclusion": "尽管Aurora学习到了物理一致的特征，但在捕捉罕见事件方面存在局限性，强调了开发可解释方法的需求，以增强对未来基于AI的大气模型的信任和验证。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07833", "html_url": "https://arxiv.org/abs/2511.07833", "title": "MURPHY：多回合GRPO的自我纠错代码生成", "title_en": "MURPHY: Multi-Turn GRPO for Self Correcting Code Generation", "authors": "Chanakya Ekbote,Vijay Lingam,Behrooz Omidvar-Tehrani,Jun Huan,Sujay Sanghavi,Anoop Deoras,Stefano Soatto", "background": "现有的强化学习方法，如Group Relative Policy Optimization (GRPO)及其变体，在逻辑推理基准测试中表现出色，但它们在需要迭代决策的代理任务上却显得力不从心。", "innovation": "Murphy是一个多回合的反思优化框架，它通过在训练过程中嵌入迭代自我修正机制，扩展了GRPO。Murphy利用定量和定性的执行反馈，使模型能够在多次交谈中逐步改进其推理。", "conclusion": "在代码生成基准测试中，当使用模型家族如Qwen和OLMo时，Murphy能够持续提高性能，相比于GRPO，最高可取得8%的pass@1相对提高，且保持相似的计算预算。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07793", "html_url": "https://arxiv.org/abs/2511.07793", "title": "HybridGuard: 提升 Dew-Enabled 边缘事物网络中少数类入侵检测", "title_en": "HybridGuard: Enhancing Minority-Class Intrusion Detection in Dew-Enabled Edge-of-Things Networks", "authors": "Binayak Kara,Ujjwal Sahua,Ciza Thomas,Jyoti Prakash Sahoo", "background": "Dew-Enabled 边缘事物（EoT）网络的安全性面临着复杂的入侵检测挑战，尤其是对于高级入侵手段的防范。现有解决方案在面对数据不平衡和多样化的攻击场景时存在不足，难以实现有效的威胁检测和防护.", "innovation": "HybridGuard 引入了一种融合机器学习和深度学习的框架，通过互信息特征选择解决数据不平衡问题，确保使用最相关的特征提升检测性能。此外，它利用带梯度惩罚的 Wasserstein 条件生成对抗网络（WCGAN-GP）进一步减少数据不平衡，增强检测精度。HybridGuard 采用 DualNetShield 双重网络防护架构，支持高级流量分析和异常检测，有助于在复杂 EoT 环境中进行细致的威胁识别。在多种数据集上的实验表明，HybridGuard 在应对不断演变的网络安全威胁方面表现优异，优于现有的解决方案.", "conclusion": "HybridGuard 作为一项有效工具，能够保护 Dew-Enabled EoT 网络免受现代入侵威胁，特别是在处理少数类攻击方面表现出色。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07813", "html_url": "https://arxiv.org/abs/2511.07813", "title": "Sparse3DPR：基于稀疏RGB视图的无训练3D分层场景解析和任务自适应子图推理", "title_en": "Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views", "authors": "Haida Feng,Hao Wei,Zewen Xu,Haolin Wang,Chade Li,Yihong Wu", "background": "近年来，大型语言模型（LLMs）在3D场景理解领域得到了广泛的研究。尽管训练免费的方法因灵活性和泛化能力而受到关注，但它们在实际部署中的准确性和效率方面通常存在问题。", "innovation": "本文提出了Sparse3DPR，一种全新的无训练框架，用于开放场景理解，该框架利用预训练LLMs的推理能力，并仅依赖稀疏视图RGB输入。具体而言，Sparse3DPR引入了一种分层的平面对增强场景图，支持开放词汇表，并采用主导的平面结构作为空间锚点，这使得推理链更清晰，高层推理更可靠。此外，Sparse3DPR设计了一种针对任务自适应的子图提取方法，可动态筛选无关查询信息，减少上下文噪声，从而提高3D场景推理效率和准确性。实验结果表明Sparse3DPR的表现优于ConceptGraphs，提高了28.7%的EM@1和78.2%的速度，并且在ScanQA上的表现与训练依赖方法相当，额外的实验进一步证实了其鲁棒性和泛化能力。", "conclusion": "Sparse3DPR在开放场景理解中表现出色，展现出比基于训练的方法具有更高的效率和准确性，特别是在Space3D-Bench上取得了显著的性能提升。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07803", "html_url": "https://arxiv.org/abs/2511.07803", "title": "通过规则进行评判：现代奴隶制声明监控的合规对齐框架", "title_en": "Judging by the Rules: Compliance-Aligned Framework for Modern Slavery Statement Monitoring", "authors": "Wenhao Xu,Akshatha Arodi,Jian-Yun Nie,Arsene Fansi Tchango", "background": "现代奴隶制影响了全世界数百万人，有不少监管框架如现代奴隶制法现在要求公司公布详细的披露。然而，这些声明往往是模糊和不一致的，使得人工审核耗时且难以规模化。自然语言处理（NLP）为这一挑战提供了可能的解决方案，但High-stakes合规任务不仅仅是准确分类，还需要透明且符合规则的输出，以便法律专家验证。目前LARGE语言模型（LLM）的应用往往简化复杂的合规评估为二元决策，缺乏确保合规审查能经得起严格法律检验所需要的结构性支持。本文提出一种新的框架，利用AI进行规则级合规验证，同时保留专家监督。核心在于合规对齐法官（CA-Judge），用于评估模型生成的辩护理由是否符合法律规定。通过反馈训练出来的合规对齐大型语言模型（CALLM），能够产生规则一致、可由人类验证的输出。CALLM不仅改善了预测性能，还生成了透明且符合法律要求的输出，提供了一个可验证且实际可行的合规分析解决方案。", "innovation": "提出利用AI进行规则级合规验证的新框架（Compliance Alignment Judge, CA-Judge），并通过训练法规一致的大规模语言模型（Compliance Alignment LLM, CALLM）生成透明、可验证且基于法律要求的合规审查输出，实现了从模糊、不一致的报告向基于规则的、易于人工审核的合规报告的转变.", "conclusion": "该研究通过引入CA-Judge和CALLM，为现代奴隶制声明监测提供了一种可验证且实际可行的合规评估和报告方式，改善了传统的模糊、不一致的手动审核过程，解决了高风险合规任务的透明度和合规性的难题。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07807", "html_url": "https://arxiv.org/abs/2511.07807", "title": "PRISM：以同态加密和模块化激活函数实现的数据保护推理系统", "title_en": "PRISM: Privacy-preserving Inference System with Homomorphic Encryption and Modular Activation", "authors": "Zeinab Elkhatib,Ali Sekmen,Kamrul Hasan", "background": "机器学习模型在各行业中的学习和预测能力随着机器学习的进步不断提升，但在关键基础设施中的部署面临挑战，因为数据隐私问题限制了数据的自由共享。同态加密（HE）能对加密数据进行计算，但目前该技术与卷积神经网络（CNN）等模型不兼容，因为这些模型依赖于非线性激活函数。本研究旨在弥合这一差距，提出了一种优化框架，该框架用与同态加密兼容的近似函数替换标准的非线性函数，确保了在最小化计算开销的同时保持安全计算。", "innovation": "该工作提出了一种优化框架，通过替换标准非线性函数为同态加密兼容的近似函数，确保在保持安全性的同时减少计算开销。该框架通过重新构建CNN结构并引入高效的激活函数近似方法来缓解加密带来的性能损失。使用CIFAR-10数据集进行的实验表明，在CGGKS设置下使用四次多项式和Softplus激活函数，单个加密样本的准确率为94.4%，每个样本2.42秒，10,000个样本为24,000秒。", "conclusion": "本研究实现了一个平衡准确性和隐私性的数据保护推理系统（PRISM），基于CKKS同态加密的四次多项式和Softplus激活函数，在CIFAR-10数据集上达到94.4%的准确率，表明通过定制化的近似方法可以有效解决同态加密与深度学习模型的兼容性问题。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07820", "html_url": "https://arxiv.org/abs/2511.07820", "title": "SONIC：扩大运动跟踪规模以实现自然人形全身控制", "title_en": "SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control", "authors": "Zhengyi Luo,Ye Yuan,Tingwu Wang,Chenran Li,Sirui Chen,Fernando Castañeda,Zi-Ang Cao,Jiefeng Li,David Minor,Qingwei Ben,Xingye Da,Runyu Ding,Cyrus Hogg,Lina Song,Edy Lim,Eugene Jeong,Tairan He,Haoru Xue,Wenli Xiao,Zi Wang,Simon Yuen,Jan Kautz,Yan Chang,Umar Iqbal,Linxi \"Jim\" Fan,Yuke Zhu", "background": "尽管大规模的基础模型（数亿参数）已经在数千个GPU上进行训练，并实现了显著的扩展增益，但类似的成功并未应用于类人控制。目前的人类控制器规模较小，只能执行有限的行为集，并且是在几块GPU上进行了几天的训练。", "innovation": "本文展示了通过扩展模型容量、数据和计算能力，可以生成能够创建自然和稳健的全身运动的通用类人人形控制器。提出了运动跟踪作为类人控制的自然且可扩展任务，通过密集的元数据监督来获得人类动作先验，无需手动设计奖励机制。本文通过三个维度扩展了一个基础模型：网络大小（从1.2M到42M参数）、数据集体积（100M帧以上的高分辨率动作数据，700小时高质量动作数据）、计算资源（9k GPU小时）。此外，本文通过两种机制展示了模型的实际应用价值：实时通用运动规划器，将运动跟踪引入下游任务执行，实现自然交互控制；统一的标记空间，支持多种运动输入接口，如VR远程操作设备、人类视频以及视觉语言行动模型，使用相同的策略。", "conclusion": "运动跟踪在扩展规模下显示出有利特征，性能随计算和数据多样性的增加而稳步提高，学习表示能够应用于未见过的动作，从而建立了运动跟踪在规模扩展下的实用性基础，为实现类人控制提供了实际的框架。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07857", "html_url": "https://arxiv.org/abs/2511.07857", "title": "一种证明网络泛化逼近性质的通用方法", "title_en": "A General Method for Proving Networks Universal Approximation Property", "authors": "Wei Wang", "background": "现有的深度学习架构多种多样，现有工作通常依赖于特定模型的证明来证明其泛化逼近性质。一般情况下，他们会为每种架构（如完全连接网络、CNN或变换器）构建一套独特的数学模型并进行证明。这种方法存在两个主要限制：首先，每次新提出一种架构往往需要从零开始证明；其次，这些证明相互隔离，缺乏共同的分析基础。这不仅带来了显著的冗余性，还阻碍了对不同网络家族进行统一的理论理解。", "innovation": "本文提出了一个通用且模块化的框架，用于证明泛化逼近性。定义一个基础构建块作为通用逼近模块（UAM），并且在满足该条件下，证明由这样的模块组成的任何深度网络都会保留泛化逼近性。这种视角不仅统一了对不同架构的分析，还使得通过网络如何增强表达能力有一个逐步的理解。", "conclusion": "通过引入通用逼近模块（UAM），证明了由这样模块构成的任何深度网络会自然而然地保留泛化逼近性。这种方法将泛化逼近性证明统一到一个整体框架中，简化了理论分析过程。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07876", "html_url": "https://arxiv.org/abs/2511.07876", "title": "LoopLLM：通过重复生成在LLMs中实现可移植的能源延迟攻击", "title_en": "LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation", "authors": "Xingyu Li,Xiaolei Liu,Cheng Liu,Yixiao Xu,Kangyi Ding,Bangzhou Xin,Jia-Li Yin", "background": "随着大型语言模型（LLMs）的规模扩大，它们的推理过程消耗了大量的计算资源，使其容易受到能量延迟攻击。这些攻击通过精心设计的提示符，促使模型产生耗时耗能的过程。现有的攻击方法主要通过延迟终止符号的生成来延长输出时间。然而，随着输出变得越来越长，通过输入控制终止符号变得越来越困难，使得这些方法的效果大打折扣。", "innovation": "本文提出了LoopLLM，一种基于观察到的重复生成可以触发低熵解码循环的能源延迟攻击框架。LoopLLM包括：（1）重复诱导的提示优化，利用自回归的漏洞导致重复生成；（2）基于token对齐的ensemble优化，以提高跨模型转移性。实验表明，LoopLLM在12个开源和2个商用LLMs上的表现显著优于现有方法，将其输出长度的提升至90%，而基线则为20%。同时，LoopLLM在DeepSeek-V3和Gemini 2.5 Flash上的跨模型转移性提高了约40%。", "conclusion": "LoopLLM显著提高了LLMs的能源延迟攻击性能，并且具有较好的跨模型转移性。未来的研究可以探讨进一步提高攻击效果的方法，如增强提示优化的方法，以及改善模型的防御策略。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07865", "html_url": "https://arxiv.org/abs/2511.07865", "title": "基于LLM的全程自动化混沌工程：朝着让任何人都能在低成本下构建弹性软件系统的方向努力", "title_en": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost", "authors": "Daisuke Kikuta,Hiroki Ikeuchi,Kengo Tajiri", "background": "混沌工程（CE）是一种旨在提高分布式系统弹性的工程技术。它通过故意向系统注入故障来测试系统的韧性，并在生产环境中出现问题之前发现和解决弱点。最近的CE工具已经能够自动化执行预定义的CE实验，但是进行这样的实验规划，并根据实验结果改进系统，仍然需要大量的手工操作。这些过程既耗时又需要多领域的专业知识。为了应对这些挑战，使任何人能够以低成本构建弹性系统，该论文提出了ChaosEater系统，该系统利用大型语言模型（LLMs）自动化整个CE周期。ChaosEater针对基于Kubernetes的软件系统实施CE，通过软件工程任务来完成CE周期，包括需求定义、代码生成、测试和调试。", "innovation": "该系统利用大型语言模型（LLMs）自动化实施混沌工程（CE）的整个周期。它根据系统化的CE周期预定义了一个代理工作流程，并将工作流程中的子任务分配给LLMs。ChaosEater针对基于Kubernetes的软件系统，通过软件工程任务来完成CE周期，包括需求定义、代码生成、测试和调试。评估结果表明，ChaosEater能够以显著较低的时间和经济成本完成合理的CE周期，并且这些周期还得到了人类工程师和LLMs的定性验证。", "conclusion": "ChaosEater系统成功地实现了基于LLM的全程自动化混沌工程，并验证了它能够在较低的成本下帮助任何人构建弹性软件系统。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07884", "html_url": "https://arxiv.org/abs/2511.07884", "title": "元认知多尺度层级推理用于运动想象解码", "title_en": "Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding", "authors": "Si-Hyun Kim,Heon-Gyu Kwak,Byoung-Hee Kwon,Seong-Whan Lee", "background": "脑-计算机接口（BCI）旨在通过解码非侵入性神经信号来控制外部设备，但基于运动想象（MI）的脑电图（EEG）信号中的噪声和变异性限制了其实用应用。现有的MI分类方法在这个方面存在局限。", "innovation": "提出了一种层次化和元认知解码框架，用于四类运动想象分类。该框架引入了多尺度层级信号处理模块和自省不确定性估计模块。多尺度层级信号处理模块重新组织骨干特征为时空多尺度表示。自省不确定性估计模块为每一周期分配可靠性分数，指导迭代优化。该框架在三种标准EEG骨干网络（EEGNet、ShallowConvNet和DeepConvNet）上实例化，并使用BCI竞赛IV-2a数据集，在无特定被试者设置下对四类运动想象解码进行评估。结果表明，提出的组成部分在所有骨干网络中提高了平均分类准确率，减少了跨被试者差异，表明了在被试者异质性和噪声试次方面更强的鲁棒性。", "conclusion": "该研究展示了结合层次化多尺度处理与自省信心估计可以提升基于运动想象的BCI系统的可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07891", "html_url": "https://arxiv.org/abs/2511.07891", "title": "向自适应脑-计算机接口迈进：通过用户状态意识EEG滤波提高解码稳定性", "title_en": "Toward Adaptive BCIs: Enhancing Decoding Stability via User State-Aware EEG Filtering", "authors": "Yeon-Woo Choi,Hye-Bin Shin,Dan Li", "background": "脑-计算机接口（BCIs）经常遭受有限的鲁棒性和较差的长期适应性问题。当用户注意力波动、脑电状态随时间转变或交互过程中出现非规律性干扰时，模型性能会迅速下降。", "innovation": "提出了一种用户状态意识的脑电图（EEG）滤波框架，该框架在解码用户意图之前通过对神经表示进行修饰来弥补这一问题。方法持续从EEG特征中估计用户认知状态（如专注或分心），并根据估计的注意力水平应用自适应加权进行滤波，从而抑制噪音或焦点不清晰的时段，减少分布偏移，提高后续解码的一致性。", "conclusion": "在多个模拟实际BCI场景的脑电图数据集上的实验表明，所提出的自适应滤波增强了不同用户状态和会话中的分类准确性和稳定性，相比传统预处理管道，这种结果突显了利用源自脑源状态信息的重要性，即使没有额外的用户标签，也能显著提高实际EEG基BCIs的可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07889", "html_url": "https://arxiv.org/abs/2511.07889", "title": "在分层自回归过程中的素描生成，用于在绘制过程中的灵活的笔画级素描操作", "title_en": "Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level", "authors": "Sicong Zang,Shuhui Gao,Zhijun Fang", "background": "生成具有特定模式的素描，即以可控方式操作素描，是一个很受欢迎的任务。近期的研究通过编辑笔画嵌入值作为条件，在笔画级别控制素描特征。然而，为了向生成器提供素描将要呈现的全局视图，所有这些编辑条件都需要在生成开始前收集并同时喂入生成器，即生成过程中不允许进一步的操作。为了实现更灵活的素描绘制操作，我们提出了一种分层自回归素描生成过程。这种方法不是一次性生成整个素描，而是将每个素描元素分为三个阶段生成：1) 预测笔画嵌入以代表哪个笔画将要绘制；2) 在画布上定位预测的笔画；3) 将嵌入转换为一系列绘画动作以形成完整素描。此外，预测、定位和转换是自回归进行的，即近期生成的笔画及其位置也用于预测当前笔画，引导模型产生合适的笔画以有利于完整素描生成。在生成过程中可以通过调整可见的可编辑笔画嵌入来灵活地操作笔画级素描绘制。", "innovation": "我们提出了一种分层自回归素描生成过程，通过分三个阶段生成每个笔画，并且预测、定位和转换是自回归进行的。这种方法使得在生成过程中可以灵活地对笔画级素描进行操作。", "conclusion": "通过分层自回归方法，该研究为在生成过程中进行笔画级素描操作提供了灵活性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07923", "html_url": "https://arxiv.org/abs/2511.07923", "title": "探索无需额外训练的水下世界分割", "title_en": "Exploring the Underwater World Segmentation without Extra Training", "authors": "Bingyu Li,Tao Huo,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "准确的海洋生物分割对于生物多样性和生态评估至关重要，但现有的数据集和模型主要集中在陆地场景。为解决这一问题，提出了AquaOV255，这是一个包含255个类别和超过20000张图像的大规模、细粒度的水下分割数据集，覆盖了用于开放式词汇评估的多种类别。此外，通过将AquaOV255与五个额外的水下数据集集成，建立了首个水下开放式词汇分割基准UOVSBench，以实现全面评估。", "innovation": "提出了首个无需额外训练的水下开放式词汇分割框架Earth2Ocean，该框架利用地面上的视觉语言模型（VLMs）直接应用于水下领域。该框架包括一个几何指导的视觉掩码生成器（GMG）和一个类别视觉语义对齐（CSA）模块，分别通过几何相似性先验进行局部结构感知和通过多模态大语言模型推理增强文本嵌入并通过场景感知模板构建。", "conclusion": "广泛实验表明，Earth2Ocean在基准UOVSBench上取得了显著的性能提升，并且保持了高效的推理能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07904", "html_url": "https://arxiv.org/abs/2511.07904", "title": "Test-driven Reinforcement Learning", "title_en": "Test-driven Reinforcement Learning", "authors": "Zhao Yu,Xiuping Wu,Liangjun Ke", "background": "强化学习（RL）已被公认为机器人控制任务的强大工具。RL通常通过奖励函数定义任务目标并指导代理的学习。然而，由于奖励函数在定义最优目标和指导学习方面起着双重作用，手动设计奖励函数往往很困难，导致任务表示效果不佳。因此，如何设计合适的奖励函数成为RL中的一大挑战，尤其是在需要处理多个目标或复杂优化任务时。", "innovation": "本文受到满意理论的启发，提出了基于测试驱动的强化学习（Test-driven Reinforcement Learning, TdRL）框架。在该框架中，使用多个测试函数来表示任务目标，而不是单一的奖励函数。这些测试函数被分类为通过测试和指示测试，前者定义最优目标，后者指导学习过程。作者证明了一种轨迹回报函数，该函数将更高的回报值赋予离最优轨迹更近的轨迹，基于这种回报函数的最大熵策略优化会获得更接近最优策略集的策略。此外，还提出了一个按字典序的方法来学习轨迹回报函数，并开发了TdRL算法的实现。实验结果表明，TdRL在政策训练上与手工设计的奖励方法相比具有竞争力甚至更优，具有更高的设计复杂度，并且天然支持多目标优化。这为解决RL应用中的奖励设计挑战提供了新的视角。", "conclusion": "研究结果表明，TdRL框架通过使用多个测试函数来表示任务目标，简化了任务定义，并提供了更强的多目标优化能力。这种新的方法在机器人控制任务中至少与传统的手工设计奖励方法相当，甚至更优，为未来RL在多目标或复杂优化任务中的应用提供了新的启示与可能性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07899", "html_url": "https://arxiv.org/abs/2511.07899", "title": "使用安全滤波器集合和置信预测统计保证控制系统的安全性", "title_en": "Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction", "authors": "Ihab Tabbara,Yuxuan Yang,Hussein Sibai", "background": "学习驱动的自主系统需要确保安全性，Hamilton-Jacobi (HJ) 可达性分析是验证安全性和生成安全控制策略的基本方法。然而，在高维系统中，计算描述用户定义失败状态的后向可达集（BRS）的HJ值函数很耗时，因此寻求使用强化学习近似值函数。尽管如此，通过学习得到的值函数及其相应的安全策略并不保证正确，评估学习值函数的状态可能不与根据学习的安全策略实际上获得的安全回报一致。为了解决这一挑战，作者引入了一种基于置信预测的框架来界定这种不确定性。结合使用汇集的安全滤波器和置信预测，可以通过切换不可用的标准控制器和基于HJ的学习安全策略，并在该切换策略下推导出安全保证。还探讨了使用独立训练的HJ值函数的集合作为安全过滤器的方法，并将其与单独使用个体值函数进行了比较。", "innovation": "提出了一个基于置信预测的框架，用于在使用学习的HJ值函数和策略时提供概率性的安全保证，主要创新点包括：1）结合使用置信预测和安全滤波器集合作为控制系统的安全策略；2）通过策略切换机制确保安全性并推导安全保证；3）探讨和验证了使用多种独立训练的HJ值函数作为安全过滤器的有效性，作为单独值函数的补充。", "conclusion": "通过结合置信预测和多HJ值函数的安全滤波器集合作为一种新的方法，这种方法可以安全地确保复杂控制系统的运行，并且实验结果表明，这种方法能够有效提升系统的整体安全性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07931", "html_url": "https://arxiv.org/abs/2511.07931", "title": "SpeechJudge：迈向语音自然度的人类级判断", "title_en": "SpeechJudge: Towards Human-Level Judgment for Speech Naturalness", "authors": "Xueyao Zhang,Chaoren Wang,Huan Liao,Ziniu Li,Yuancheng Wang,Li Wang,Dongya Jia,Yuanzhe Chen,Xiulin Li,Zhuo Chen,Zhizheng Wu", "background": "大生成模型与人类反馈的对齐是一个关键挑战，尤其在语音合成领域更为突出，因为缺乏大规模的人类偏好数据集，这阻碍了真正与人类感知对齐的模型的发展。", "innovation": "本文介绍了SpeechJudge，一个包含数据集、基准和针对自然度这一语音合成最基础的主观度量的标准的全面工具套件。特别地，该研究通过构建一个包含99K对话语音的大型人类反馈数据集SpeechJudge-Data，建立了挑战性的SpeechJudge-Eval基准。进而，开发了一种基于Qwen2.5-Omni-7B的生成奖励模型（GRM）SpeechJudge-GRM，该模型通过两阶段后训练过程（Chain-of-Thought辅助的监督微调与RL结合）来改善语音合成模型的性能，并在SpeechJudge-Eval基准上表现出色。", "conclusion": "所提出的SpeechJudge-GRM模型在SpeechJudge-Eval基准上显示出优越的性能，其准确率达到77.2%（推理时扩展@10为79.4%），相比经典Bradley-Terry奖励模型提高了约4.5%。此外，SpeechJudge-GRM还可作为语音生成模型后训练的奖励函数，以优化其与人类偏好对齐的能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07926", "html_url": "https://arxiv.org/abs/2511.07926", "title": "基于CNN的 memristive 设备建模参数自动提取框架", "title_en": "CNN-Based Automated Parameter Extraction Framework for Modeling Memristive Devices", "authors": "Akif Hamid,Orchi Hassan", "background": "电阻式随机存取内存（RRAM）是下一代非挥发性内存（NVM）和内存计算应用的有希望候选者。紧凑的模型对于分析实验性 RRAM 设备的电路和系统级性能至关重要。然而，多数现有 RRAM 紧凑模型依赖多个拟合参数来重现器件的I-V特性，在大多数情况下，鉴于这些参数与其直接相关的可测量量无关，其提取需要大量手动调整，导致过程耗时，并限制了不同器件之间的适应性。", "innovation": "本研究提出了一个自动框架，用于直接从设备的I-V特性中提取广泛使用的斯坦福RRAM模型的拟合参数。该框架采用针对合成数据集训练的卷积神经网络（CNN）生成初始参数估计，然后通过三个启发式优化块优化参数，以适应搜索空间中的误差最小化。该框架通过四个关键NVM指标：置位电压、复位电压、滞回回路面积和低电阻状态（LRS）的斜率得到了评估。将该框架与之前报道的斯坦福模型拟合、其他分析模型和实验数据进行比对，表明该框架在广泛器件特性下实现了低错误率，为RRAM建模提供了快速、可靠且稳健的解决方案。", "conclusion": "该框架为从实际实验性RRAM设备中准确和快速地提取参数提供了解决方案，提高了建模精度和适应性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07885", "html_url": "https://arxiv.org/abs/2511.07885", "title": "瓦特智能：衡量本地AI的智能效率", "title_en": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI", "authors": "Jon Saad-Falcon,Avanika Narayan,Hakki Orhun Akengin,J. Wes Griffin,Herumb Shandilya,Adrian Gamarra Lafuente,Medhya Goel,Rebecca Joseph,Shlok Natarajan,Etash Kumar Guha,Shang Zhu,Ben Athiwaratkun,John Hennessy,Azalia Mirhoseini,Christopher Ré", "background": "现有的大规模语言模型查询主要由云端的前沿模型处理。随着需求快速增加，这种模式面临挑战，云服务提供商难以及时扩大基础设施规模。为解决这一问题，研究引入了两个关键进展：小模型（参数量不超过200亿）现在在许多任务上实现了与前沿模型相当的性能，同时本地加速器（如苹果M4 Max）可以在交互式延迟下运行这些模型。这引发了一个问题：本地推理是否可以有效地重新分配对集中式基础设施的需求？", "innovation": "研究提出了“瓦特智能（IPW，Intelligence per Watt）”，即每单位能耗的任务准确度，作为衡量本地推理能力和效率的关键指标。研究通过大规模实验证明，本地模型在其中88.7%的一轮聊天和推理查询中具有较高的准确度，而且未来几年IPW的提升将显著增加本地查询的覆盖范围，并且本地加速器相比云端具有显著的能耗优势。", "conclusion": "研究结果表明，本地推理可以有效地减少对集中式基础设施的需求，IPW是跟踪这一转变的最关键指标。同时，研究开放了IPW分析工具以便系统地进行智能每瓦特基准测试。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07942", "html_url": "https://arxiv.org/abs/2511.07942", "title": "基于平衡方程的分布鲁棒离线模仿学习", "title_en": "Balance Equation-based Distributionally Robust Offline Imitation Learning", "authors": "Rishabh Agrawal,Yusuf Alvi,Rahul Jain,Ashutosh Nayyar", "background": "模仿学习（IL）在设计奖励函数或显式控制难以实现的机器人和控制任务中表现出很高的效率。然而，标准IL方法假设环境动态在训练和部署期间保持不变，而在实际应用中，由于建模不准确性、真实世界的参数变化以及敌对方扰动等因素，这一假设往往不成立，会导致性能严重下降。", "innovation": "本研究提出了一种基于平衡方程的分布鲁棒离线模仿学习框架，该框架仅从遵循名义动态收集的专家演示中学习鲁棒性更强的策略，不依赖于额外的环境互动。该研究将问题形式化为一个以转换模型不确定性集为约束的分布鲁棒优化问题，旨在找到最能抵抗最坏情况下转换分布的模仿策略。该研究还展示了该鲁棒优化目标可以完全转换为名义数据分布，从而实现可处理的离线学习。", "conclusion": "实证研究结果表明，与最先进的离线IL基线相比，该方法在受扰动或偏移的环境中提供了更好的鲁棒性和泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07941", "html_url": "https://arxiv.org/abs/2511.07941", "title": "Libra-MIL: 结合特定任务语言先验的多模态原型立体融合用于少量样本全切片图像分类", "title_en": "Libra-MIL: Multimodal Prototypes Stereoscopic Infused with Task-specific Language Priors for Few-shot Whole Slide Image Classification", "authors": "Zhenfeng Zhuang,Fangyu Zhou,Liansheng Wang", "background": "大语言模型（LLMs）在计算病理学领域展现出潜力，但因吉克拉塞尔全切片图像（WSIs）的高计算成本，需要利用多实例学习（MIL）来实现有效建模。现有问题在于病理任务通常只提供集合级标签，而由LLM生成的实例级描述因缺乏精细医学知识往往存在偏差。因此，构建特定任务的病理实体原型对于学习可泛化的特征和提高模型可解释性至关重要。现有的视图-语言MIL方法通常采用单向指导，限制了跨模态的协同作用。", "innovation": "本文提出了一种新的方法，称为多模态原型导向多实例学习（Libra-MIL），通过平衡的信息压缩方案促进双向交互。具体而言，利用冻结状态的LLM生成特定任务的病理实体描述，并作为文本原型进行学习。同时，视觉分支学习实例级原型以减轻模型对冗余数据的依赖。在融合阶段，使用基于相似度度量的立体最优传输（SOT）算法，从而在高维空间中实现更广泛的语义对齐。", "conclusion": "我们在三个不同癌症数据集上进行了少量样本分类和可解释性实验，结果表明所提方法具有优越的泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07935", "html_url": "https://arxiv.org/abs/2511.07935", "title": "DiffRegCD：具有扩散特征的集成注册与变化检测", "title_en": "DiffRegCD: Integrated Registration and Change Detection with Diffusion Features", "authors": "Seyedehnanita Madani,Rama Chellappa,Vishal M. Patel", "background": "变化检测（CD）是计算机视觉和遥感的基本组成部分，支持环境监测、灾害响应和城市发展等应用。大多数CD模型假设输入数据进行了注册，但在实际应用场景中，图像常常存在视角偏移、长时序间隔等问题，导致严重的对齐问题。传统的两阶段方法（先注册后检测）和最近的联合框架（如BiFA和ChangeRD）在大位移情况下依然存在困境，主要依赖于回归法、全局仿射变换或合成扰动。", "innovation": "本文提出了一种集成框架DiffRegCD，该框架在单一模型中统一了密集注册和变化检测。DiffRegCD将对应关系估计重新定义为高斯光滑分类任务，以实现亚像素精度和稳定的训练。该方法利用预训练的去噪扩散模型的多尺度冻结特征，以应对光照和视角变化对图像的影响。监督信息通过应用在标准CD数据集上的受控仿射扰动提供，生成同时适用于流和变化检测的真实配对目标，无需伪标签。广泛的实验结果表明，DiffRegCD在空地（LEVIR-CD、DSIFN-CD、WHU-CD、SYSU-CD）和地面（VL-CMU-CD）数据集上均优于近期基线，即使在宽时间与几何变化范围内也能保持可靠性，从而确立了扩散特征和基于分类的对应关系作为统一变化检测的强大基础。", "conclusion": "DiffRegCD在处理大位移问题时表现卓越，系统地超越了现有基线，并证明了扩散特征与分类相关联的方法在统一变化检测中的有效性和可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07950", "html_url": "https://arxiv.org/abs/2511.07950", "title": "USV障碍检测与跟踪在海洋环境中的研究", "title_en": "USV Obstacles Detection and Tracking in Marine Environments", "authors": "Yara AlaaEldin,Enrico Simetti,Francesca Odone", "background": "在海洋环境中研制一个坚固且有效的障碍检测与跟踪系统对于无人 Surface 船（USV）而言是一项具有挑战性的任务。格罗拉实验室（University of Genova）在过去几年进行了研究，提出了一种在图像平面上检测和跟踪障碍物并在 3D LiDAR 点云中定位的方法。", "innovation": "本研究在已开发的系统基础上，首先对系统性能进行了评估，通过实时同步测试，并与其他多发表的海洋数据集进行对比，同时也分别采用了摄像机和 LiDAR 的传感器融合以及仅使用 LiDAR 点云的信息来检测和跟踪障碍物。研究最后提出了一种混合方法，融合了两种方式的优点，构建了无人 Surface 船周围环境的障碍物地图。", "conclusion": "研究表明，所提出的混合方法能够更有效地检测和跟踪 USV 的周边环境障碍物，提供了一个更为可靠的障碍物地图，提升了无人 Surface 船在海洋环境中的自主导航能力和安全性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07975", "html_url": "https://arxiv.org/abs/2511.07975", "title": "数据市场中可靠的私有效用信号", "title_en": "Reliable and Private Utility Signaling for Data Markets", "authors": "Li Peng,Jiayao Zhang,Yihang Wu,Weiran Liu,Jinfei Liu,Zheng Yan,Kui Ren,Lei Zhang,Lin Qu", "background": "数据的爆炸性增长突显了数据在驱动经济方面的作用，通过数据市场实现广泛的数据共享和高质量数据集的访问。有效的交易支持需要信号机制，提供参与者关于数据产品的信息，以作出知情决策并促进交易。然而，由于数据的固有复制特性，常用的信号方法在隐私与可靠性之间面临困境，削弱了信号在指导决策中的有效性。", "innovation": "本文探讨了一种有效的信号机制的益处，并开发了一种非TCP基础的构建，同时保证隐私和可靠性。设计协议时，提出了恶意安全多方计算（MPC）确保信号计算的隐私性和鲁棒性，并引入基于MPC的哈希验证方案确保输入可靠性。在多卖家场景下的公平数据估值设计优化中，进一步探讨了MPC基 KNN-Shapley方法，提高了效率。严格的实验验证了该方法的高效性和实用性。", "conclusion": "本文通过恶意安全多方计算和哈希验证方法，提出了一个既能保证隐私又能确保信号可靠性的信号机制，并在实验中验证了其高效性和实用性，解决了数据市场中信号机制的隐私与可靠性之间的困境，促进了知情的数据交易。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07976", "html_url": "https://arxiv.org/abs/2511.07976", "title": "时间中的morphing：基于扩散的跨时间间隔桥梁构建以实现鲁棒对齐在变化检测中的应用", "title_en": "Morphing Through Time: Diffusion-Based Bridging of Temporal Gaps for Robust Alignment in Change Detection", "authors": "Seyedehanita Madani,Vishal M. Patel", "background": "遥感变化检测常常受到生物时间图像间空间错位的挑战，尤其是在长时间季节性或多年期间隔之后。现代卷积和基于变换的模型在对齐数据上表现良好，但它们依赖于精确的对齐，在实际场景中缺乏鲁棒性。现有联合对齐检测框架通常需要重新训练，并且跨领域表现较差。", "innovation": "介绍了一种模块化管线，该管线在不改变现有变化检测网络的情况下改善了空间和时间的鲁棒性。该框架结合了基于扩散的语义形态学、密集对齐和残差流细化。扩散模块生成中间形态框架，以填补显著的外观差异，使RoMa能够估计连续帧之间的逐步对应关系。然后，通过轻量级的U-Net细化产生的流动，以生成高质量的对齐变换，对齐原始图像对。", "conclusion": "在LEVIR-CD、WHU-CD和DSIFN-CD上的广泛实验展示了该方法在多个骨干网络下的注册精度和下游变化检测的一致性改进，证实了所提出方法的通用性和有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07982", "html_url": "https://arxiv.org/abs/2511.07982", "title": "NOTAM-Evolve: 一种基于知识引导的自我进化优化框架，利用大规模语言模型进行NOTAM解释", "title_en": "NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation", "authors": "Maoqi Liu,Quan Fang,Yuhao Wu,Can Zhao,Yang Yang,Kaiquan Cai", "background": "准确解读航空航行通告（NOTAMs）对于航空安全至关重要，但其浓缩且晦涩的语言给人工和自动处理都带来了重大挑战。现有的自动化系统通常只能进行浅层次的解析，无法提取出对于操作决策有用的信息。NOTAMs的完整解释任务被形式化为深度解析，这是一个需要动态知识关联（将NOTAM与不断变化的航空数据链接起来）和基于模式的推理（应用固定领域的规则来推断操作状态）的双重推理挑战。", "innovation": "我们提出了NOTAM-Evolve，一种自我进化的框架，使大规模语言模型（LLM）能够自主掌握复杂NOTAM的解释。该框架利用增强知识图谱的检索模块进行数据关联，同时引入了一个闭环学习过程，使LLM能够从自己的输出中逐步改进，减少了对大量人工标注的推理路径的需求。同时，我们还引入了一个包含10,000个专家标注的NOTAM的新基准数据集。实验结果表明，NOTAM-Evolve相较于基础LLM在结构化NOTAM解释上的绝对准确率提高了30.4%，并在任务上建立了新的最先进水平。", "conclusion": "NOTAM-Evolve通过自我进化框架和闭环学习过程，显著提升了大规模语言模型在NOTAM解释上的性能，标志着在这一领域的进步。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07989", "html_url": "https://arxiv.org/abs/2511.07989", "title": "南斯拉夫语言文本分类中的前沿技术：微调还是提示？", "title_en": "State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?", "authors": "Taja Kuzman Pungeršek,Peter Rupnik,Ivan Porupski,Vuk Dinić,Nikola Ljubešić", "background": "直到最近，微调的BERT类似模型在文本分类任务中提供最佳性能。随着指令调优的解码器模型，即大型语言模型（LLMs）的兴起，该领域越来越多地转向零样本和少量样本提示。然而，LLMs在文本分类领域的表现，特别是在资源较少的语言上，仍然未得到充分研究。本文作者评估了当前语言模型在多个南斯拉夫语言上的文本分类任务表现，比较了公开可用的微调BERT类似模型与开源和闭源LLMs的表现。", "innovation": "研究使用了南斯拉夫语的文本分类任务，并将LLMs的零样本性能与微调的BERT类似模型进行了比较，发现LLMs在零样本情况下表现出较强的能力，常常能满足或超过微调模型的表现。此外，LLMs在南斯拉夫语和英语上的表现相似，但同时也指出了LLMs的一些关键缺点，包括输出更不可预测、推理速度显著较慢以及更高的计算成本。", "conclusion": "尽管LLMs在零样本环境下表现出强劲性能，但它们的不稳定性、缓慢的推理速度和高昂的计算成本限制了它们在大规模自动文本标注中的应用。因此，微调的BERT类似模型仍然是大规模自动文本注释更为实际的选择。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07990", "html_url": "https://arxiv.org/abs/2511.07990", "title": "面向STM32U5的基于硬件感知的YOLO压缩技术在数字农业中的草地检测低功耗边缘AI系统", "title_en": "Hardware-Aware YOLO Compression for Low-Power Edge AI on STM32U5 for Weeds Detection in Digital Agriculture", "authors": "Charalampos S. Kouzinopoulos,Yuri Manna", "background": "杂草会显著减少作物产量并给可持续农业带来重大挑战。传统的杂草管理方法主要依赖化学除草剂，这可能导致环境污染和抗性杂草的出现。精确除草（利用计算机视觉和机器学习方法）提供了一种环保的替代方案，但由于需要高功率计算平台，通常受到限制。因此，开发一种低功耗的边缘AI系统，用于在作物和杂草数据集（包含74种植物物种）上进行实时杂草检测，对于解决上述问题具有重要意义。", "innovation": "该研究提出了一个基于硬件感知的YOLO压缩技术，应用于STM32U5微控制器，实现了低功耗的边缘AI系统。该系统使用了结构化剪枝、整数量化和输入图像分辨率缩放等压缩技术来适应硬件限制。研究基于作物和杂草数据集训练和评估模型，取得了在检测准确性和效率之间取得平衡的结果。模型每推理一次的能量消耗仅为51.8毫焦耳，适用于电力受限的农业环境并具有可扩展性。", "conclusion": "该系统能够在数字农业中进行实时、原位的杂草检测，同时达到极低的能耗水平，为杂草精准管理提供了新思路，可以促进农业生产的可持续发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08012", "html_url": "https://arxiv.org/abs/2511.08012", "title": "LLM辅助模拟声学场景上的轻量级网络DOA估计", "title_en": "DOA Estimation with Lightweight Network on LLM-Aided Simulated Acoustic Scenes", "authors": "Haowen Li,Zhengding Luo,Dongyuan Shi,Boxiang Wang,Junwei Ji,Ziyi Yang,Woon-Seng Gan", "background": "DOA估算是空间音频和声学信号处理中的重要环节，具有广泛的实际应用。现有的DOA模型大多基于合成数据进行训练，使用干净的语音与房间冲激响应进行卷积，这限制了模型的泛化能力，因为声学多样性受到限制。", "innovation": "本文重新审视了使用大型语言模型（LLMs）辅助构建的DOA数据集进行DOA估计的方法，该数据集提供了更真实和多样的声学场景。并基于深度可分离卷积设计了针对不同环境多通道输入的LightDOA模型。", "conclusion": "研究表明，LightDOA在各种声学场景下具备满意的准确性和鲁棒性，同时保持了低计算复杂度。本研究不仅突显了通过LLMs辅助合成空间音频在提高DOA估计稳健性和效率研究中的潜力，还展示了LightDOA作为资源受限应用的有效解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07998", "html_url": "https://arxiv.org/abs/2511.07998", "title": "结构化数据问答的自校正蒸馏方法", "title_en": "Self-Correction Distillation for Structured Data Question Answering", "authors": "Yushan Zhu,Wen Zhang,Long Jin,Mengshu Sun,Ling Zhong,Zhiqiang Liu,Juan Li,Lei Liang,Chong Long,Chao Deng,Junlan Feng", "background": "结构化数据问答（包括表格问答、知识图谱问答和时间型知识图谱问答）是研究的关键领域。大型语言模型的进展推动了统一结构问答框架（如TrustUQA）的发展。但在应用于小型语言模型时，这些框架会面临挑战，因为小型语言模型在生成结构化查询时容易出错。为了提高小型语言模型的结构化数据问答能力，提出了一种自校正蒸馏（SCD）方法。该方法通过设计错误提示机制（EPM）在推理过程中检测错误和提供定制化的错误信息，并设计了两阶段蒸馏策略以将大型语言模型的查询生成和错误修正能力传递给小型语言模型。", "innovation": "提出了自校正蒸馏（SCD）方法，包括错误提示机制（EPM）的设计，用于检测推理过程中的错误并提供定制化的错误信息，以及两阶段蒸馏策略，旨在将大型语言模型的查询生成和错误修正能力传递给小型语言模型。实验结果显示，SCD方法在小型语言模型（8B）上实现了最佳性能和优越的一般化能力，并接近了GPT4在某些数据集上的性能。此外，配备EPM的大规模语言模型在大多数数据集上超过了最先进的结果。", "conclusion": "SCD方法显著提高了小型语言模型在结构化数据问答任务中的表现，并展示出出色的泛化能力，尤其在某些数据集上接近大型模型GPT4的效果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08003", "html_url": "https://arxiv.org/abs/2511.08003", "title": "Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning", "title_en": "Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning", "authors": "Jialong Qin,Xin Zou,Di Lu,Yibo Yan,Xuming Hu", "background": "当前的视频大规模语言模型（VideoLLMs）面临着二次计算复杂度和关键值缓存扩展的问题，因为它们依赖于处理大量的冗余视觉令牌。这导致了计算效率低下和内存使用率高。为了改善这一现状，研究人员提出了一个基于自适应剪枝和关键值缓存的方法SharpV。与大多数统一压缩方法不同，SharpV可以动态地根据空间-时间信息调整剪枝比率，从而提供了一个新的自适应剪枝范式，可以在某些情况下超越密集模型。SharpV 在视觉缓存剪枝阶段通过一种自校准机制，根据原始视觉特征的相似性剪枝退化的视觉特征，并从信息瓶颈的角度实现了分层缓存剪枝，为 VideoLLMs 的信息流提供了一个新的视角。", "innovation": "SharpV 是一种基于自适应剪枝和关键值缓存的简约高效方法，与大多数统一压缩方法不同，它可以动态地根据空间-时间信息调整剪枝比率。这种方法不需要访问暴露的注意力分数，因此可以与硬件加速技术如 Flash Attention 完全兼容。这种方法通过一种自校准机制剪枝退化的视觉特征，从信息瓶颈的角度实现分层缓存剪枝，提供了一个新的自适应剪枝范式，并在多种公开基准上展示了其优越性。", "conclusion": "实验结果表明，SharpV 在多种公开基准上均表现优异。此外，SharpV 是第一个无需访问暴露注意力分数的两阶段剪枝框架，为高效和可靠的 VideoLLM 推理提供了解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08015", "html_url": "https://arxiv.org/abs/2511.08015", "title": "隐形触发器，显而易见的威胁！视觉3D检测在自动驾驶中的道路风格对抗生成攻击", "title_en": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for Visual 3D Detection in Autonomous Driving", "authors": "Jian Wang,Lijun He,Yixing Yong,Haixia Bi,Fan Li", "background": "现代自动驾驶（AD）系统利用3D物体检测来感知3D环境中的前景物体，从而进行后续的预测和规划。基于RGB摄像头的视觉3D检测相比LiDAR架构提供了更经济有效的解决方案。尽管取得了显著的检测精度，当前基于深度神经网络的模型对对抗性示例依然高度敏感。这些潜在的安全隐患促使我们研究在自动驾驶场景中的现实对抗攻击。以前的研究证明在路面上放置虚构的海报可以使检测器产生幻觉，但由于这些海报的不自然外观容易被人类发现，且其内容是固定不变的，可以被轻松针对和防御。为了解决这些问题，作者提出了AdvRoad来生成多样化的道路风格对抗海报，此类对手在外观上类似于道路表面，同时欺骗检测器在攻击位置感知到不存在的物体。通过两阶段方法——道路风格对抗生成和场景相关适应，确保有时攻击有效性的同时保持海报的自然外观，从而实现不引人注意的攻击。", "innovation": "提出了AdvRoad来生成多样化的道路风格对抗海报，这种对手在外观上类似于道路表面，同时欺骗检测器在攻击位置感知到不存在的物体。作者通过两阶段方法——道路风格对抗生成和场景相关适应，确保有时攻击有效性的同时保持海报的自然外观，从而实现不引人注意的攻击。", "conclusion": "实验结果显示，AdvRoad在不同的检测器、场景和欺骗位置上具有良好的泛化性能。此外，物理攻击进一步证明了在现实世界环境中的实际威胁。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08016", "html_url": "https://arxiv.org/abs/2511.08016", "title": "AVOID-JACK: 长重型铰接车辆集群防绞缠", "title_en": "AVOID-JACK: Avoidance of Jackknifing for Swarms of Long Heavy Articulated Vehicles", "authors": "Adrian Schönnagel,Michael Dubé,Christoph Steup,Felix Keppler,Sanaz Mostaghim", "background": "目前，关于大型铰接车辆集群（HAVs）避免绞缠和互相碰撞的问题尚未在现有文献中得到有效解决。这类问题在实际应用中非常重要，例如物流自动化、远程采矿、机场行李运输和农业操作等。由于这种集群的特殊形态和复杂的运动学特性，现有的集群机器人研究方法难以直接应用到HAVs上，因此需要开发新的方法来解决这些问题。", "innovation": "本文提出了一种基于纯反应的分散式蜂群智能策略，专门针对长重型铰接车辆。这种方法优先考虑避免绞缠，并为互碰撞的避免奠定基础。通过广泛的模拟实验验证了该方法的有效性，对于单辆HAVs，99.8%的绞缠得以避免，86.7%和83.4%分别完成了第一和第二目标。对于两辆HAVs的交互，分别有98.9%、79.4%和65.1%避免了绞缠，并且99.7%的车辆未经历互碰撞。", "conclusion": "本文提出的方法为大型铰接车辆集群的集群智能控制提供了一种新的解决方案。通过对单辆和多辆HAVs的实验，验证了避免绞缠和互碰撞的有效性，为未来的实际应用奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08031", "html_url": "https://arxiv.org/abs/2511.08031", "title": "基于FPN-Transformer的多模态Deepfake检测与定位", "title_en": "Multi-modal Deepfake Detection and Localization with FPN-Transformer", "authors": "Chende Zheng,Ruiqi Suo,Zhoulin Ji,Jingyi Deng,Fangbin Yi,Chenhao Lin,Chao Shen", "background": "生成对抗网络（GANs）和扩散模型的快速进步使得生成高度逼真的Deepfake内容成为可能，这对音频-视觉领域中的数字信任构成了重大威胁。尽管单模态检测方法在识别合成媒体方面有了进展，但由于无法利用跨模态相关性和精准定位伪造片段的限制，它们在应对复杂细微篡改方面实用性有限。", "innovation": "我们提出了一种基于特征金字塔-变换器（FPN-Transformer）的多模态Deepfake检测与定位框架，解决了跨模态泛化和时间边界回归的关键空白。该方法利用预训练的自我监督模型（WavLM用于音频，CLIP用于视频）提取层次化时间特征，并通过具备局部注意力机制的R-TLM块构建多尺度特征金字塔，实现跨上下文时间依赖性的联合分析。预测头同时预测伪造概率并细化篡改片段的时间偏移，实现了帧级别定位的精确度。", "conclusion": "我们的方法在IJCAI'25 DDL-AV基准测试集上进行了评估，显示了在复杂环境下的跨模态Deepfake检测与定位方面良好的性能，最终得分为0.7535。实验结果证明了这种方法的有效性，提供了一种通用的Deepfake检测的新方式。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08046", "html_url": "https://arxiv.org/abs/2511.08046", "title": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation", "title_en": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation", "authors": "Aya Elgebaly,Nikolaos Delopoulos,Juliane Hörner-Rieber,Carolin Rippke,Sebastian Klüter,Luca Boldrini,Lorenzo Placidi,Riccardo Dal Bello,Nicolaus Andratschke,Michael Baumgartl,Claus Belka,Christopher Kurz,Guillaume Landry,Shadi Albarqouni", "background": "自动医疗图像分割受到高观察者间变异性的影响，尤其是在肺结节分割等任务中，专家之间经常存在分歧。现有的方法要么将这种变异性简化为一个共识掩模，要么依赖于每个注释者的独立模型分支。这限制了个性化医疗图像分割的灵活性和准确性。", "innovation": "本文提出了ProSona，这是一种两阶段框架，能够学习注释风格的连续潜在空间，并通过自然语言提示实现可控个人化。ProSona采用概率U-Net骨干捕捉多样的专家假设，并通过指导提示的投影机制在潜在空间中导航，生成个性化分割。多级对比目标将文本和视觉表示对齐，促进解耦和可解释的专家风格。ProSona在LIDC-IDRI肺结节和多机构前列腺MRI数据集中，减少了Generalized Energy Distance 17%，提高了平均Dice分数超过1分，相比DPersona具有更灵活、更准确和更具解释性的控制能力。", "conclusion": "ProSona通过自然语言提示提供了灵活、准确和可解释的个性化医疗图像分割控制，显著提高了分割的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08061", "html_url": "https://arxiv.org/abs/2511.08061", "title": "通过潜在串联和掩码条件流匹配在扩散模型中驯服身份一致性与提示多样性", "title_en": "Taming Identity Consistency and Prompt Diversity in Diffusion Models via Latent Concatenation and Masked Conditional Flow Matching", "authors": "Aditi Singhania,Arushi Jain,Krutik Malani,Riddhi Dhawan,Souymodip Chakraborty,Vineet Batra,Ankit Phogat", "background": "主题驱动的图像生成旨在生成特定主题在不同上下文中的新颖描绘，同时保持其核心身份特征。实现强大的身份一致性与高度提示多样性之间存在根本的权衡。", "innovation": "提出了一个LoRA微调的扩散模型，利用潜在串联策略，联合处理参考和目标图像，并结合了掩码条件流匹配（CFM）目标，这种方法在不修改架构的情况下实现了鲁棒的身份保真。介绍了两阶段的蒸馏数据整理框架：第一阶段利用数据恢复和基于VLM的过滤来自不同来源创建紧凑、高质量的种子数据集；第二阶段利用这些整理过的例子进行参数高效微调，从而扩展生成能力到各种主题和上下文。提出了一个名为CHARIS的细致评估框架，进行特征级别的比较，评估五个关键维度：身份一致性、提示遵从性、区域间颜色保真度、视觉质量以及转换多样性。", "conclusion": "该方法通过一系列创新性策略，解决了扩散模型中身份一致性与提示多样性之间的难题，并通过精细评估框架CHARIS展示了其在各种主题和上下文中的高效生成能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08075", "html_url": "https://arxiv.org/abs/2511.08075", "title": "CLIP是实现Stable Diffusion中人类语义表示所需的一切", "title_en": "CLIP is All You Need for Human-like Semantic Representations in Stable Diffusion", "authors": "Cameron Braunstein,Mariya Toneva,Eddy Ilg", "background": "现有的潜扩散模型如Stable Diffusion在文本到图像生成任务上取得了最先进的成果，但这些模型生成的图像是否隐含着语义理解尚未清晰了解。因此，该研究调查了这些模型在文本到图像生成过程中内部表示是否包含对人类有意义的语义信息。通过使用简单的回归层进行探查，并与人类标注进行评估，研究发现语义信息的识别主要归因于CLIP的文本编码，而非逆向扩散过程。", "innovation": "研究通过使用CLIP进行文本编码，尽管使用逆向扩散过程生成图像，但仍能保持语义信息。研究发现不同语义类别在逆向扩散过程中的解码准确性不同，并且随着逆向扩散进行，这些属性更难以区分，这意味着CLIP在语义表示方面起着关键作用，而非扩散过程的作用。", "conclusion": "研究结论为，单独训练的CLIP视觉语言模型决定了类人的语义表示，而扩散过程则起着视觉解码器的作用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08077", "html_url": "https://arxiv.org/abs/2511.08077", "title": "融合Gradient Boosting和模糊规则模型的集成融合框架", "title_en": "An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models", "authors": "Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding", "background": "不同学习范式的集成一直是机器学习研究的重点，旨在克服单一方法的固有限制。模糊规则模型因其可解释性而在多种领域中得到广泛应用，但它们存在复杂的设计规范和大数据集的扩展性问题。将不同技术与模糊规则模型结合，尤其是使用Gradient Boosting技术，提供了一种应对这些问题的健全解决方案。", "innovation": "本文提出了一种集成融合框架，该框架结合了模糊规则模型和Gradient Boosting的优点，以增强模型性能和解释性。该框架在一个动态因素的控制下，根据每个迭代中的模型性能动态调整对整体集成的贡献，避免模型主导，促进多样性，作为正则化参数，并提供基于模型性能动态调节的机制，从而减少过拟合的风险。同时，框架还包含基于样本的校正机制，可以根据来自验证集的反馈进行适应性调整。", "conclusion": "实验结果证明，该基于Gradient Boosting集成模糊规则模型的方法在性能提升方面取得了成效，尤其是在减少过拟合和复杂性方面尤为明显。通过最佳因素调控每个模型的贡献，框架提高了性能，保持了可解释性，并简化了模型的维护和更新。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08078", "html_url": "https://arxiv.org/abs/2511.08078", "title": "使用SAT-MPM方法进行约束和鲁棒策略合成", "title_en": "Constrained and Robust Policy Synthesis with Satisfiability-Modulo-Probabilistic-Model-Checking", "authors": "Linus Heck,Filip Macák,Milan Češka,Sebastian Junges", "background": "在给定和已知的有限马尔可夫决策过程（MDPs）中计算奖励最优策略是规划、控制器合成和验证等各种应用的基础。然而，我们往往希望策略不仅具有鲁棒性（即在MDPs的扰动下性能良好），还能够满足额外的结构性约束，例如表示或实现成本。满足这些结构性约束要求的鲁棒策略的计算更加具有挑战性。因此，我们亟需一种方法能够有效计算考虑任意结构性约束的鲁棒策略。本文旨在提出一种高效的框架，该框架可以通过表达结构性约束并通过集成可满足性求解器和概率模型检查算法来实现鲁棒策略的合成。", "innovation": "本文提出的第一个贡献是提供了一种框架，能够在任意结构性约束下有效地计算鲁棒策略。该框架的灵活性来源于通过使用一个集齐一阶理论来表达MDPs上的约束，而效率的根源在于将可满足性求解器与概率模型检查算法的紧密集成，以解决组合问题并分析MDPs。实验结果表明，该框架在约束和鲁棒策略合成方面是可行的，并且与现有的最先进的方法具有竞争力。对于问题的不同部分，其表现也非常强劲。", "conclusion": "本文通过一种灵活且高效的框架，提出了一个解决方案来计算在给定任意结构性约束下的鲁棒策略。实验结果证明了这种方法的有效性和实用性，尤其是在面对各种约束时的鲁棒性策略合成方面具备显著的优势，并且表现出色的竞争力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08071", "html_url": "https://arxiv.org/abs/2511.08071", "title": "Radar-APLANC：通过增强伪标签和噪声对比实现的无监督雷达心率检测", "title_en": "Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented Pseudo-Label and Noise Contrast", "authors": "Ying Wang,Zhaodong Sun,Xu Cheng,Zuxian He,Xiaobai Li", "background": "FMCW雷达能够通过非接触方式测量胸壁微小振荡进行心率检测，但传统雷达心率检测方法在噪声影响下性能下降。虽然基于学习的雷达方法更具有抗噪性，但需要昂贵的标记信号进行监督训练。为克服这些问题，提出了一种基于雷达的无监督框架Radar-APLANC，利用增广伪标签和噪声对比增强鲁棒性。该方法利用雷达范围矩阵中的心率距离和噪音距离来构建正样本和负样本，改进了噪声鲁棒性。NCT损失只使用正样本、负样本和伪标签信号，这样可以避免依赖昂贵的真实生理信号。此外，设计了一种伪标签增强方法，具有自适应噪声感知标签选择，提高伪标签信号质量。实验证明，该无监督方法在性能上与最先进的监督方法相当。相关代码、数据集和补充材料可以在指定网址获取。", "innovation": "提出了一种名为Radar-APLANC的无监督框架，利用增强伪标签和噪声对比来改进心率检测的鲁棒性。此方法通过在雷达范围矩阵中利用心率距离和噪声距离来生成高质量的正负样本，同时减少了对昂贵真实生理信号的依赖，首次实现了基于雷达的无监督心率检测方法。", "conclusion": "我们的无监督方法在性能上达到了与最先进的监督方法相当的水平。相关代码、数据集和辅助材料可在指定网址获取。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08080", "html_url": "https://arxiv.org/abs/2511.08080", "title": "Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing", "title_en": "Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing", "authors": "Ziyu Fan,Zhijian Huang,Yahan Li,Xiaowen Hu,Siyuan Shen,Yunliang Wang,Zeyu Zhong,Shuhong Liu,Shuning Yang,Shangqian Wu,Min Wu,Lei Deng", "background": "在AI驱动的药物发现中，分子生成和编辑的特性约束至关重要，但这一过程目前受到两个因素的阻碍：一是捕捉分子结构与多种特性之间的复杂关系仍具挑战性；二是分子特性的窄覆盖范围及不完整的注解削弱了基于特性的模型的有效性。", "innovation": "本文提出了HSPAG，这是一种数据高效的框架，通过层次结构的结构-特性对齐来处理这些问题。该模型将SMILES表示和分子特性视为互补的模态，在原子、亚结构和整个分子级别学习它们的关系。此外，通过支架聚类选择代表性样本，在辅助变分自编码器（VAE）的辅助下选择困难样本，显著减少了预训练数据的需求。还引入了特性相关性感知的掩码机制和多样化扰动策略，以增强在稀疏注解下的生成质量。", "conclusion": "实验表明，HSPAG能够捕捉细微的结构-特性关系，并支持在多种特性约束下的可控生成能力。两个实际案例进一步验证了HSPAG的编辑能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08090", "html_url": "https://arxiv.org/abs/2511.08090", "title": "StableMorph: 使用稳定扩散生成高质量人脸变形图", "title_en": "StableMorph: High-Quality Face Morph Generation with Stable Diffusion", "authors": "Wassim Kabbani,Kiran Raja,Raghavendra Ramachandra,Christoph Busch", "background": "面部变形攻击威胁到了生物特征身份识别系统的真实性，使多个个体能够共享一个身份。为了开发和评估有效的变形攻击检测（MAD）系统，研究人员需要高质量、现实的变形图像，这些图像能够反映现实世界中的挑战。但现有的变形生成方法常常生成模糊的、有许多瑕疵或构建质量差的图像，容易被发现而且不能代表最危险的攻击。现有的MAD方法往往基于这样的图像，无法有效检测最新的变形攻击，限制了MAD性能的提升。", "innovation": "StableMorph是一种新颖的方法，利用现代基于扩散的图像合成生成高度逼真且无瑕疵的人脸变形图像，不受此类通病困扰，提供对视觉属性的空前控制。StableMorph生成的图像不仅与真实的人脸图像质量相当或更好，并且能够有效地迷惑面部识别系统，对现有的MAD解决方案构成了更大的挑战，形成了新的研究和操作测试标准。", "conclusion": "StableMorph通过创建更逼真和有效的攻击，提高了生物安全性的评价，并支持开发更稳健的检测系统。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08098", "html_url": "https://arxiv.org/abs/2511.08098", "title": "PerspAct: 通过视角获取和主动视觉增强LLM定位协作能力", "title_en": "PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision", "authors": "Sabrina Patania,Luca Annese,Anita Pellegrini,Silvia Serino,Anna Lambiase,Luca Pallonetto,Silvia Rossi,Simone Colombani,Tom Foulsham,Azzurra Ruggeri,Dimitri Ognibene", "background": "近期，大型语言模型（LLMs）和多模态基础模型的应用范围在机器人技术和协作系统中得到了显著扩展。然而，有效的多智能体交互需要强大的视角转换能力，使模型能够同时理解物理和知识视角。当前的训练方法常常忽视了交互场景，导致模型在处理个人视角的主观性或在涉及多个观察者的环境中导航时出现问题。", "innovation": "该研究评估了是否可以通过显式地将视角转换与ReAct框架结合，实现包括推理和执行的方法，来提升LLM理解并反映其他智能体要求的能力。研究通过区分增加视角转换复杂性的七个场景，扩展了经典导演任务，探讨了视觉探索策略对提高模型解释准确性及协作效果的影响。", "conclusion": "研究结果表明，通过整合显式视角线索和主动探索策略，可以显著提高模型的解释准确性和协作效果。这些发现强调了将主动感知与视角转换机制结合在提升LLMs在机器人技术及多智能体系统中的应用潜力，并为未来研究自适应及上下文感知人工智能系统奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08085", "html_url": "https://arxiv.org/abs/2511.08085", "title": "BARD10：新基准揭示孟加拉语停用词在作者识别方面的意义", "title_en": "BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution", "authors": "Abdullah Muhammad Moosa(1),Nusrat Sultana(1),Mahdi Muhammad Moosa(2),Md. Miraiz Hossain(1) ((1) Department of Mechatronics &amp; Industrial Engineering, Chittagong University of Engineering &amp; Technology, Chittagong 4349, Bangladesh, (2) Department of Mathematics &amp; Natural Sciences, Brac University, Dhaka 1212, Bangladesh)", "background": "作者们对孟加拉语作者身份进行了一项全面的研究，并提出了一种新建立的平衡基准语料库BARD10（包含10位当代孟加拉语作家的博客和观点散文的语料库），以及使用停用词去除对传统和深度学习模型的影响进行了系统的分析。数据显示，使用均匀预处理的现代TF-IDF + SVM基线在两个基准语料库BAAD16和BARD10上均有出色表现，精度很高。相比之下，使用孟加拉语BERT模型的效果较差。这项研究揭示了BARD10作家高度依赖于停用词修剪，而BAAD16作家则显示出相对较强的鲁棒性，具有文体依赖性强的特点。进一步的错误分析指出，高频率成分中包含的作者特征在变压器模型中可能会被削弱或减小。", "innovation": "该研究引入了一种新的平衡基准语料库BARD10，以及对停用词去除影响的不同模型（如SVM、孟加拉语BERT、XGBoost和MLP）进行了系统分析，揭示了孟加拉语停用词在作者身份识别中的重要性。此外，还探讨了变压器模型处理高频率成分的方式，表明经典模型可能在处理短文本时有效性更高。", "conclusion": "研究表明，BARD10所提供的真实世界短文本数据能够显著区别作者之间的细微差异，避免了现有数据集可能存在的偏差。停用词在孟加拉语作者身份识别中起到关键作用，短文本的ML模型在特定任务中表现良好，BARD10提供了一个重现性良好的基准，有助于未来长上下文或领域适应性变压器的研究和发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08087", "html_url": "https://arxiv.org/abs/2511.08087", "title": "超越像素：基于VLM的身份保存评估在参考导向合成中的应用", "title_en": "Beyond the Pixels: VLM-based Evaluation of Identity Preservation in Reference-Guided Synthesis", "authors": "Aditi Singhania,Krutik Malani,Riddhi Dhawan,Arushi Jain,Garv Tandon,Nippun Sharma,Souymodip Chakraborty,Vineet Batra,Ankit Phogat", "background": "在生成模型中评估身份保存仍然是一个至关重要的未解决挑战。现有的评估指标依赖于全局嵌入或粗略的VLM提示，无法捕捉精细的身份变化，也无法提供有价值的诊断信息。", "innovation": "我们提出了一种分层评估框架，称为'Beyond the Pixels'。该框架通过如下方式指导VLM进行结构化推理：按主题分解为（类型、风格）->属性->特征决策树（1），以及提示具体的变换而非抽象的相似性评分（2）。这种分解将VLM分析与可验证的视觉证据联系起来，减少了幻觉并提高了一致性。", "conclusion": "我们的框架已经在四个最新的生成模型上得到了验证，证明了与人类判断在衡量身份一致性方面的强烈一致性。此外，我们还引入了一个新的基准测试，旨在测试生成模型，包含1078个图像-提示对，覆盖多种主题类型，包括未充分代表的类别，如拟人化和动画角色，并捕捉每个提示的六到七个变换轴。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08086", "html_url": "https://arxiv.org/abs/2511.08086", "title": "动态稀疏性：挑战机器人强化学习基准中世界模型学习的常见稀疏性假设", "title_en": "Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks", "authors": "Muthukumar Pandaram,Jakob Hollenstein,David Drexel,Samuele Tosatto,Antonio Rodríguez-Sánchez,Justus Piater", "background": "研究发现，基于学习动力学模型（称为世界模型）可以提高强化学习的采样效率，且这些动力学模型的潜在因果图是稀疏连接的，每个未来状态变量仅依赖于当前状态变量中的一个小子集。学习因此受益于稀疏先验。此外，时间稀疏性也被提出作为有用的归纳偏倚。本文通过分析MuJoCo Playground基准套件中的机器人强化学习环境的真实动力学来严格检验这些假设，以确定提出的状态和时间稀疏性是否通常在强化学习任务中确实存在。", "innovation": "研究发现全局稀疏性是罕见的，取而代之的是任务显示动力学的局部、状态依赖性稀疏性，并且这种稀疏性表现出不同的结构，在时间上局部化成簇（例如，在接触事件期间）并且影响特定状态维度的子集。这些发现挑战了动力学学习中的常见稀疏性先验假设，强调了需要反映真实世界动力学的状态依赖性稀疏性结构的具体归纳偏倚。", "conclusion": "本研究的结果表明，在强化学习任务中，动力学的稀疏性是局部的、状态依赖性的，并且这种稀疏性具有一些特定的结构，集中在时间上的局部区域（例如，在接触事件期间）并且影响特定的状态维度。这些发现挑战了动力学学习中的常见稀疏性先验假设，强调了需要具体反映真实世界动力学的状态依赖性稀疏性结构的归纳偏倚。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08120", "html_url": "https://arxiv.org/abs/2511.08120", "title": "一种评估机器学习模型长期可持续性的 robust 方法", "title_en": "A robust methodology for long-term sustainability evaluation of Machine Learning models", "authors": "Jorge Paz-Ruza,João Gama,Amparo Alonso-Betanzos,Bertha Guijarro-Berdiñas", "background": "可持续性和效率在人工智能系统的开发和部署中已成为关键考虑因素，但现有监管和报告实践缺乏标准化的、无偏的评估协议。当前的评估通常只衡量短期实验资源使用情况，并且过度侧重批处理学习场景，未能反映实际操作中长期的AI生命周期情况。这引发了一个问题：现有的评估协议不足以全面评估ML模型的长期可持续性，尤其是在数据不断变化和模型反复更新的场景下。本文通过在多种分类任务中使用不同模型类型进行的实验，展示了传统的静态训练-测试评估无法可靠地捕捉到模型在变化数据和重复更新下的可持续性表现。研究结果表明，长期可持续性在不同模型之间差异显著，而且在某些情况下，更高的环境成本并不一定会带来性能收益。", "innovation": "本文提出了一个适用于批处理和流式学习场景的综合评估协议，用于评估ML模型的长期可持续性。", "conclusion": "通过实验，本文证明传统静态的训练-测试评估无法可靠捕捉模型在变化数据和重复更新下的可持续性表现，且长期可持续性在不同模型中差异显著。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08133", "html_url": "https://arxiv.org/abs/2511.08133", "title": "OTSNet: 一种神经认知启发的观察-思考-拼写pipeline用于场景文字识别", "title_en": "OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition", "authors": "Lixu Sun,Nurmemet Yolwas,Wushour Silamu", "background": "场景文字识别（STR）因其现实生活中的复杂性而具有挑战性，在现有框架中分离的视觉-语言优化会导致模态间对齐错误增加，导致错误传播。视觉编码器倾向于对背景分心物表现出注意力偏差，而解码器在解析几何变形的文字时表现出空间错位，这会集体降低对非规律模式的识别准确性。", "innovation": "本文提出了一种三阶段网络OTSNet（Observation-Thinking-Spelling），基于人类视觉感知的神经认知过程。网络架构包含三个核心组件：1）双注意力马卡龙编码器（DAME），通过差异注意力图细化视觉特征，抑制无关区域并增强特征的区分能力；2）位置感知模块（PAM）和语义量化器（SQ），共同通过自适应采样将空间上下文与字形级别的语义抽象有机结合；3）多模态协作验证器（MMCV），通过跨模态融合视觉、语义和字符级特征来实施自我校正。", "conclusion": "广泛的实验证明，OTSNet在具有挑战性的Union14M-L基准上达到了83.5%的平均精度，在高度遮挡的OST数据集上达到了79.1%的精度，并在14种评估场景中的9种场景中设立了新的记录。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08136", "html_url": "https://arxiv.org/abs/2511.08136", "title": "SafeMIL：从非首选轨迹中学习安全的离线模仿策略", "title_en": "SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories", "authors": "Returaj Burnwal,Nirav Pravinbhai Bhatt,Balaraman Ravindran", "background": "在许多真实世界的应用场景中，实时交互存在风险，同时精确地在每个时间步上指定奖励和安全成本信息也可能具有挑战性。然而，收集反映不良行为或风险行为的轨迹通常是可行的，这些轨迹隐含地传达了代理应避免的行为。因此，本研究旨在通过离线安全模仿学习来解决这一问题。", "innovation": "提出了一种名为SafeMIL的新方法，该方法将非首选轨迹作为输入，通过多项式实例学习（Multiple Instance Learning）学习一个参数化的成本，以预测状态-动作对的风险性。通过这种方式，代理能够学习避免风险行为，从而优化安全性。", "conclusion": "通过实验证明，本文的方法能够在满足成本约束的同时学习一个更安全的策略，而不牺牲奖励性能，从而优于多种基线方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08143", "html_url": "https://arxiv.org/abs/2511.08143", "title": "关系优先：LLM驱动文档级关系抽取的新范式", "title_en": "Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction", "authors": "Qiankun Pi,Yepeng Sun,Jicang Lu,Qinlong Fan,Ningbo Huang,Shiyu Wang", "background": "大型语言模型（LLMs）在文档理解方面展示了令人印象深刻的能力。然而，最近的研究揭示，LLMs 在文档级关系抽取（DocRE）任务上仍然存在性能差距，因为需要进行细粒度的理解。基于LLMs的方法通常采用“提取实体然后预测关系”的范式，导致这些差距，原因有两个：（1）大量的无关实体对引入了噪音并干扰了真正相关实体对的关系预测；（2）尽管LLMs能够识别实体之间的语义关联，但超出预定义集合的关系标签仍然被视为预测错误。", "innovation": "提出了一种新颖的关系优先（RelPrior）范式用于基于LLMs的DocRE。针对挑战（1），RelPrior 使用二元关系作为先验来提取并确定两个实体是否相关，以便过滤掉无关的实体对，并减少预测噪音。针对挑战（2），RelPrior 使用预定义的关系作为先验来匹配实体以进行三元组提取，而不是直接预测关系，从而避免由于严格的预定义关系标记而导致的误判。该范式在两个基准测试上进行了广泛的实验，证明能够达到最先进的性能，超越现有的基于LLMs的方法。", "conclusion": "实验表明，RelPrior 能够极大地提高关系抽取的准确性和效率，是基于LLMs的DocRE领域的创新解决方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08147", "html_url": "https://arxiv.org/abs/2511.08147", "title": "ProbSelect: 使用随机选择进行GPU加速计算设备在3D连续体中的客户端选择", "title_en": "ProbSelect: Stochastic Client Selection for GPU-Accelerated Compute Devices in the 3D Continuum", "authors": "Andrija Stanisic,Stefan Nastic", "background": "将边缘、云和空间设备集成到统一的3D连续体中，给联邦学习系统的客户端选择带来了重大挑战。传统的客户端选择方法依赖于持续监控和历史数据收集，但在卫星和移动设备频繁改变操作条件的动态环境中变得不切实际。此外，现有的解决方案主要集中于CPU计算，未能捕捉到GPU加速训练所具有的复杂特性，而这种特性在整个3D连续体中普遍存在。", "innovation": "这篇文章提出了一种名为ProbSelect的新颖方法，该方法利用分析建模和概率预测来进行GPU加速设备上的客户端选择，而无需使用历史数据或持续监控。ProbSelect将客户端选择建模在用户定义的服务水平目标（SLOs）内，通过广泛的评估展示了ProbSelect可以提高13.77%的服务水平目标符合率并且相比基线方法减少了72.5%的计算浪费。", "conclusion": "研究表明，ProbSelect方法通过准确预测和利用GPU加速设备的特性提高了服务承诺的遵守率，同时减少了不必要的计算资源浪费。这种方法为联邦学习系统在3D连续体中的客户端选择提供了一种有效且高效的新途径。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08207", "html_url": "https://arxiv.org/abs/2511.08207", "title": "FedPoP: 联邦学习与参与证明的结合", "title_en": "FedPoP: Federated Learning Meets Proof of Participation", "authors": "Devriş İşler(IMDEA Networks Institute - Universidad Carlos III de Madrid),Elina van Kempen(University of California, Irvine),Seoyeon Hwang(Stealth Software Technologies Inc.),Nikolaos Laoutaris(IMDEA Networks Institute)", "background": "联邦学习（FL）提供了一种隐私保护的分布式机器学习方法，允许客户端无需泄露本地数据即可参与构建全球模型。随着模型越来越多地成为可货币化的数字资产，证明其在训练过程中参与的权利变得至关重要。现有方法要么需要大量的计算资源，要么需要公开账本，不利于保护客户端的匿名性和隐私。", "innovation": "本文提出了一种名为FedPoP的新联邦学习框架，它能够在不牺牲客户端匿名性和隐私的情况下，证明客户端的参与而不需要执行繁重的计算或使用公开账本。FedPoP设计上兼容现有的安全聚合协议，便于实际部署。通过实际客户端掉线情况下的实验验证，FedPoP提供了关于每轮0.97秒的额外开销，并使客户端能够在0.0612秒内证明自己对第三方持有的模型的参与/贡献。", "conclusion": "FedPoP适用于需要可以审计的参与而不会牺牲隐私的实际部署场景，这种框架证明了在保持隐私的前提下，能够在保障模型训练过程中参与证明的可行性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08174", "html_url": "https://arxiv.org/abs/2511.08174", "title": "深度（预测性）折现反事实遗憾最小化", "title_en": "Deep (Predictive) Discounted Counterfactual Regret Minimization", "authors": "Hang Xu,Kai Li,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng", "background": "反事实遗憾最小化（CFR）是一类用于解决不完美信息博弈的高效算法。为了使CFR在大博弈中的应用更广泛，研究者通过神经网络来近似其行为。现有的方法大多基于经典的CFR，很难有效地整合更高级的CFR变体。现有方法在近似更高级的CFR变体时存在局限性，导致在大博弈中的表现不够理想，特别是在典型不完美信息博弈中的收敛速度较慢及大扑克游戏中对抗策略的表现不佳等问题。", "innovation": "本文提出了一种高效的无模型神经CFR算法，克服了现有方法在近似高级CFR变体方面的局限。该算法在每一轮迭代中，基于价值网络收集减少方差的采样优势，通过递归拟合累积优势，并通过折扣和裁剪操作模拟高级CFR变体的更新机制。实验结果显示，与无模型的神经算法相比，该算法在典型不完美信息博弈中表现出更快的收敛速度，且在大型扑克游戏中展示了更强的对抗性能。", "conclusion": "该算法通过采用价值网络、减少方差的采样优势、递归拟合累积优势以及模拟高级CFR变体的更新机制，实现了在大博弈中更高效的收敛和更强的对抗性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08224", "html_url": "https://arxiv.org/abs/2511.08224", "title": "实时无引导单视角3D超分辨率的2D表示", "title_en": "2D Representation for Unguided Single-View 3D Super-Resolution in Real-Time", "authors": "Ignasi Mas,Ivan Huerta,Ramon Morros,Javier Ruiz-Hidalgo", "background": "现有的3D超分辨率技术通常需要高分辨率的RGB图像作为引导，或者需要复杂的3D点云数据来构建3D几何。这限制了这些技术在缺乏高分辨率RGB数据的场景中的应用。本文提出了2Dto3D-SR框架，通过将单视角的3D数据编码为结构化的2D表示，可以直接利用现有的2D图像超分辨率架构，从而实现更高效率和更简单的模型。", "innovation": "引入了2Dto3D-SR框架，通过使用投影归一化坐标码（PNCC）将可见表面的3D几何表示为普通的图像，消除了对高分辨率RGB图像或基于3D点的方法的需求。该框架支持轻量级和快速的模型，并且具有适应各种部署环境的能力。通过两种实现方式（使用Swin Transformers和Vision Mamba）展示了模型在准确性和效率方面的优势。", "conclusion": "实验结果表明，Swin Transformer模型在标准基准测试中达到了最先进的准确性，而Vision Mamba模型则在实时速度下提供了具有竞争力的结果。这表明，2Dto3D-SR框架提供了一种简单且实用的解决现实场景中问题的方法，特别是在高分辨率RGB数据不可用的情况下。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08238", "html_url": "https://arxiv.org/abs/2511.08238", "title": "重塑Vision-Language微调中的语义关系", "title_en": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning", "authors": "Xiangyang Wu,Liu Liu,Baosheng Yu,Jiayan Qiu,Zhenwei Shi", "background": "视觉-语言微调已成为构建多模态基础模型的一种高效范式。然而，现有的微调方法通常忽略了文本上下文在图像中揭示的语义关系，这导致了性能不佳。背景强调了改进视觉和语言对齐与融合的重要性。研究旨在解决这一问题，通过改进语义关系来提高模型性能。", "innovation": "提出了一种方法，不仅基于语义，还基于视觉和语义关系，通过多级语义特征提取来捕捉更多视觉线索，然后通过投影将视觉特征映射到相关语义组中，最后使用继承的交叉注意力机制融合视觉和文本特征，通过消除低相关性的视觉-语言特征对来全局去除冗余的视觉关系。这种方法在八种基础模型和两种下游任务，视觉问答和图像 captioning 上进行了评估，并证明优于现有所有方法。", "conclusion": "通过重塑语义关系，在视觉-语言微调中实现更有效的语义与视觉特征的对齐与融合，从而显著提高了基础模型在视觉问答和图像 captioning 上的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08225", "html_url": "https://arxiv.org/abs/2511.08225", "title": "教育LLM分析中的基准测试案例研究：反馈中的性别偏差", "title_en": "Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback", "authors": "Yishan Du,Conrad Borchers,Mutlu Cukurova", "background": "随着教师越来越多地将GenAI应用于教育实践中，我们需要可靠的基准方法来评估大型语言模型（LLMs）在教学目的中的表现。本文使用了一个基于嵌入的基准测试框架，以检测语言模型在形成性反馈中的偏见。该研究利用了来自AES 2.0语料库的真实学生作文，构建了从两个维度（隐性线索和显性线索）控制的反事实情景，探讨了六种代表性的LLM（GPT-5 mini, GPT-4o mini, DeepSeek-R1, DeepSeek-R1-Qwen, Gemini 2.5 Pro, Llama-3-8B），以评估性别词汇替换对模型响应的影响，并进一步使用维度降低进行可视化。", "innovation": "提出了一种基于嵌入的基准测试框架，用于检测语境中的形成性反馈中的偏见；通过比较隐性信息和显性信息（性别信息）对模型反应的影响，发现即使是先进LLM也表现出对性别替换的不对称语义响应，显示了个体内在的性别偏见。此外，提出了评估学习分析中反事实评估的报告标准和实用指导，以确保公平反馈的实现和部署。", "conclusion": "研究表明即使是最先进的LLM也存在隐含的性别偏见，特别是在针对性别词汇替换时。这些发现对教育GenAI的公平审计具有重要影响，提出了反事实评估的报告标准和实用指导，旨在确保反馈的公平性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08231", "html_url": "https://arxiv.org/abs/2511.08231", "title": "基于多保真度残差物理知情神经过程的机器人系统实时状态估计性能分析", "title_en": "Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems", "authors": "Devin Hunter,Chinwendu Enyioha", "background": "各种神经网络架构被广泛应用于最新的基于实时非线性状态估计的方法中。随着这些数据驱动模型在估计领域中的不断融入，可靠误差范围的模型预测变得尤为重要，特别是在关键安全应用中。本文讨论了一种基于多保真度残差物理知情神经过程（MFR-PINP）的新型实时数据驱动估计方法，应用于机器人系统的实时状态估计。同时，本研究解决了选择合适运动学模型的模型偏差问题，通过让MFR-PINP学习简单的低保真度预测和复杂的高保真度真实物理过程之间的残差来解决该问题。此外，为应对物理实施中的模型不确定性，在训练和推理过程中建模了来自分裂置信预测框架的稳健不确定性保证。", "innovation": "提出了一种基于多保真度残差物理知情神经过程（MFR-PINP）的新型实时数据驱动估计方法，该方法能有效解决状态估计中的模型偏差问题，并通过建模的稳健不确定性保证来提高估计的准确性。", "conclusion": "实验结果显示，MFR-PINP模型在与基于卡尔曼滤波器（无迹卡尔曼滤波器和深度卡尔曼滤波器）的最新变体的估计场景中表现良好，为实时估计任务中使用此模型提供了新的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08263", "html_url": "https://arxiv.org/abs/2511.08263", "title": "基于ImageBind的多模态数据压缩：ImagebindDC", "title_en": "ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation", "authors": "Yue Min,Shaobo Wang,Jiaze Li,Tianle Niu,Junxin Fan,Yongliang Miao,Lijin Yang,Linfeng Zhang", "background": "数据凝练技术旨在从大规模数据集中生成紧凑的数据集，以提高模型训练效率。尽管在单一模态的场景下取得了成功，但在需要保留复杂跨模态依赖关系的多模态场景中，这些技术常常失效。", "innovation": "本文提出了ImageBindDC，一种在ImageBind统一特征空间中运行的数据凝练框架。该框架采用了强大的特征函数（CF）损失，这种损失在傅里叶域中工作，通过精确的无限矩匹配来促进更精确的统计对齐。本文的目标设计确保了三个关键层次的分布一致性：一、单模态对齐，匹配合成数据和实际数据在每个模态中的统计属性；二、跨模态对齐，通过匹配混合实际-合成数据对的分布来保留双元的语义；三、联合模态对齐，通过匹配实际数据对的联合分布及其合成对应物来捕捉整个多元数据结构。", "conclusion": "广泛的实验表明，ImageBindDC的效果显著：在NYU-v2数据集上，只需要每个类5个凝练的数据点，训练得到的模型在性能上与使用完整数据集训练的模型无差异，而且达成这一效果还节省了8.2%的绝对改进和超过4倍的凝练时间。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08240", "html_url": "https://arxiv.org/abs/2511.08240", "title": "利用原子点积操作符进行分层方向感知以实现旋转不变点云学习", "title_en": "Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning", "authors": "Chenyu Hu,Xiaotong Li,Hao Zhu,Biao Hou", "background": "点云处理已成为许多3D视觉任务的核心技术。然而，任意旋转引入了点云方向的变异，对有效表示学习构成了长期挑战。这种问题的核心在于旋转扰动破坏了点云固有的方向特性。最近的方法尝试隐式建模旋转同变性与不变性，以保存方向信息并将其传递至深层次语义空间。但它们往往未能充分利用点云的多尺度方向特性来增强特征表示。", "innovation": "我们提出了一种感知方向的向量网络（DiPVNet），其核心是一个原子点积操作符，能够同时编码方向偏好性和旋转不变性，赋予网络旋转对称建模和自适应方向感知能力。在局部层面，引入了一个可学习的局部点积操作符（L2DP），使中心点与其邻居之间的交互能够自适应捕捉点云的非均匀局部结构。在全局层面，利用广义谐波分析证明了点云与球面取样向量之间点积等同于一种感知方向的球谐变换（DASFT），从而构建了一种整体方向响应频谱，用于建模全局方向结构。严格证明了两个操作符的旋转不变性。实验结果表明，DiPVNet在具有噪声和大角度旋转的挑战场景中，实现了点云分类和分割任务的最先进的性能。", "conclusion": "广泛的实验表明，DiPVNet在点云分类和分割任务中达到了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08287", "html_url": "https://arxiv.org/abs/2511.08287", "title": "双核图社区对比学习", "title_en": "Dual-Kernel Graph Community Contrastive Learning", "authors": "Xiang Chen,Kun Yue,Wenjie Liu,Zhenyu Zhang,Liang Duan", "background": "图对比学习（GCL）在没有特定任务标签的情况下训练图神经网络（GNN）方面展现出了强大的潜力。然而，其在大规模图上的扩展性受到了图神经网络中的密集消息传递机制以及对比损失在正负节点对上的二次计算复杂度的阻碍。", "innovation": "提出了一种高效的GCL框架，通过将输入图转换为互联节点集的紧凑网络，同时保留跨社区的结构信息，引入了一种具有线性复杂度的内核化的图社区对比损失，实现有效的信息转移以捕捉图的分层结构信息。进一步将知识蒸馏技术融入解耦的GNN架构，以加速推理并保持强大的泛化性能。", "conclusion": "在16个不同规模的现实世界数据集上的广泛实验表明，该方法在效率和可扩展性方面均优于最新的GCL基准线方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08248", "html_url": "https://arxiv.org/abs/2511.08248", "title": "NERVE: 区域与熵引导的随机游走方法在无监督开放词汇语义分割中的应用", "title_en": "NERVE: Neighbourhood & Entropy-guided Random-walk for training free open-Vocabulary sEgmentation", "authors": "Kunal Mahatha,Jose Dolz,Christian Desrosiers", "background": "尽管在开放词汇语义分割（OVSS）方面取得了进展，但现有的无监督训练方法仍面临一些局限性：如使用计算成本高的亲和性细化策略、固定大小的高斯核导致的弱局部上下文融合、固定的等向性邻域关系等。这些方法在处理复杂的开放词汇语义分割任务时表现不佳，尤其是对任意形状的物体识别和分割效果有限。", "innovation": "本文提出了一种新的无监督训练框架即NERVE（Neighbourhood & Entropy-guided Random-walk for open-Vocabulary sEgmentation），它结合了全局和局部信息，利用稳定扩散模型的自注意力层中的结构信息。与现有方法不同，NERVE通过熵为基础的不确定性来选择最相关的注意力图，而不需要传统的后处理技术如条件随机场（CRF）或像素自适应掩码精炼（PAMR），进而增强对复杂对象的分割能力。此外，该方法引入了一种随机游走策略用于亲和性细化，替代了固定大小的高斯核方法，使得不同区域之间可以更好地传播，易于分割具有任意形状的物体，从而提出了一种有效的开放词汇语义分割方法。", "conclusion": "通过在7种常见的语义分割基准测试上的实验，本文的方法展示了优异的零样本分割性能，提升了无监督开放词汇语义分割领域的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08319", "html_url": "https://arxiv.org/abs/2511.08319", "title": "适应性多代理响应细化在对话系统中的应用", "title_en": "Adaptive Multi-Agent Response Refinement in Conversational Systems", "authors": "Soyeong Jeong,Aparna Elangovan,Emine Yilmaz,Oleg Rokhlenko", "background": "大型语言模型（LLMs）在对话系统中表现出色，能够生成类似人类的响应。然而，当需要考虑个性化或特定知识时，它们可能会出现不足。现有的方法主要是在单一模型内部优化响应，但这种方法难以全面考虑有效对话所需的各种因素。", "innovation": "本文提出了一种适应性多代理框架，每个代理负责检查和细化对话的某一方面，分别是事实性、个性化和连贯性。此外，文章还引入了一种动态通信策略，根据每个查询的具体需求灵活选择和协调最相关的代理。", "conclusion": "通过在挑战性对话数据集上的验证，证明了该框架显著优于相关基线，特别是在涉及知识或用户特征的任务中表现更佳。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08305", "html_url": "https://arxiv.org/abs/2511.08305", "title": "通过黎曼激活引导实现测试时多样化推理", "title_en": "Test-time Diverse Reasoning by Riemannian Activation Steering", "authors": "Ly Tran Ho Khanh,Dongxuan Zhu,Man-Chung Yue,Viet Anh Nguyen", "background": "最佳-of-N推理通过采样多个候选解决方案然后根据某些标准选择最佳解决方案来提高语言模型解决复杂任务的准确性。然而，这一策略的一个关键瓶颈是输出多样性限制，即在模型虽然采用了随机采样但是生成的输出相似，导致重复错误。因此，该论文提出了一个新的无监督激活引导策略，该策略在测试时同时优化多个推理路径的引导向量，以解决推理路径中缺乏变化的问题。", "innovation": "该论文提出了一种新的无监督激活引导策略，在测试时同步优化多个推理路径的引导向量。此策略通过在批次生成过程的任何同步锚点处找到最大化所有可能介入激活子集构成的空间体积的引导向量。此策略通过解决球体乘积上的黎曼优化问题、使用有良好调教的学习率的黎曼块坐标下降算法来确定引导向量，并使用这些引导向量直到生成过程到达下一个同步锚点。实证研究显示，该激活引导策略在生成多样性及解的准确性上优于简单的采样技术。", "conclusion": "该论文展示了测试时的黎曼激活引导策略在流行的数学基准测试上超过了原生的采样技术，不仅提高了生成多样性，也增强了解的准确性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08275", "html_url": "https://arxiv.org/abs/2511.08275", "title": "不确定性条件下具有机会约束的大型露天矿山调度双目标进化优化", "title_en": "Bi-Objective Evolutionary Optimization for Large-Scale Open Pit Mine Scheduling Problem under Uncertainty with Chance Constraints", "authors": "Ishara Hewa Pathiranage,Aneta Neumann", "background": "露天矿场的长期规划是一个复杂的、计算成本高的过程，受到运营和地质依赖性的限制。传统的确定性方法往往忽视地质不确定性，导致次优甚至不可行的生产计划。机会约束允许通过确保约束以高概率满足来建模随机性成分。本文提出了一种双目标露天矿场调度问题（OPMSP）的表述，旨在同时最大化预期净现值并最小化调度风险，且独立于所需的置信水平。这种表述解决了由于地质不确定性导致的次优或不可行问题。解决方案使用整数编码表示，从而自然地满足储备约束。通过这种方法，可以更全面地考虑各种地质不确定性，从而提高生产计划的鲁棒性。", "innovation": "本文提出了一种新的双目标进化的优化方法，专为具有机会约束的大型露天矿场调度问题设计。引入了领域特定的贪婪随机初始化和考虑优先顺序的周期交换变异操作符。将这些操作符结合到了三个多目标进化算法中：全局简化多目标优化器（GSEMO）、基于分解的多目标进化算法（MOEA/D）的变异版本和非支配排序遗传算法II（NSGA-II）。与依赖特定置信水平的单目标方法进行了比较，通过分析包含多达112,687个块的矿床，结果表明提出的双目标表述提供了在经济价值和风险之间更稳健和平衡的权衡。", "conclusion": "双目标表述在大型露天矿场调度问题中提供了更加稳健和平衡的经济价值与风险之间的权衡。与依赖于特定置信水平的单目标方法相比，双目标方法改进了生产的合理性和可行性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08314", "html_url": "https://arxiv.org/abs/2511.08314", "title": "利用子结构替换规则导向框架提升分子属性回归模型的准确性和泛化能力", "title_en": "Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework", "authors": "Xiaoyu Fan,Lin Guo,Ruizhen Jia,Yang Tian,Zhihao Yang,Boxue Tian", "background": "人工智能（AI）辅助药物发现是一个活跃的研究领域，然而，AI模型在分子属性预测的回归任务中往往表现出较低的准确度，并且对于分布在模型训练分布外的分子（OOD分子）表现极为糟糕。现有的分子属性回归模型（MPRM）如GEM和UniMol在处理多种分子属性预测任务时未能很好地解决这些问题。", "innovation": "本文提出了一种新的框架MolRuleLoss，它通过将子结构替换规则（SSR）的部分导数约束纳入MPRM的损失函数中来增强多个分子属性回归模型的准确性和泛化能力。MolRuleLoss的应用显著提升了多种分子属性（如疏水性、溶解性和自由能）的预测准确性。通过加入MolRuleLoss，分子属性回归模型对于“活性悬崖”分子、OOD分子以及分子量的预测效果都得到了显著改善。", "conclusion": "MolRuleLoss作为一种“即插即用”的框架，有助于提升多个分子属性回归模型的预测准确性和泛化能力，支持在化学信息学和AI辅助药物发现等领域中的多种应用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08340", "html_url": "https://arxiv.org/abs/2511.08340", "title": "HN-MVTS: 基于超网络的多元时间序列预测", "title_en": "HN-MVTS: HyperNetwork-based Multivariate Time Series Forecasting", "authors": "Andrey Savchenko,Oleg Kachan", "background": "多元时间序列数据的准确预测仍然是一个巨大的挑战，特别是在真实场景中时间依赖性的复杂性不断增加的情况下。虽然基于神经网络的模型在这方面取得了显著的成功，但由于考虑复杂通道依赖性而导致模型性能下降，同时通道无关模型虽然由于容量较小而具有较高的鲁棒性，但不考虑组件之间的关系。", "innovation": "本文提出了一种名为 HN-MVTS 的新型架构，它结合了基于超网络的生成先验和任意神经网络预测模型。输入超网络的是时间序列组件的学习嵌入矩阵，通过学习生成目标预测网络的最后一层权重，作为数据自适应的正则化器，提高鲁棒性和长期的预测准确性。超网络仅在训练期间使用，不增加推理时间。", "conclusion": "全面实验表明，将 HN-MVTS 应用于最先进的模型（DLinear、PatchTST、TSMixer 等）通常会提高其性能。我们的研究结果表明，基于超网络的参数化为改进复杂情况下的现有预测技术提供了一个有希望的方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08339", "html_url": "https://arxiv.org/abs/2511.08339", "title": "LPPG-RL: 使用子问题探索的分级投影策略梯度强化学习", "title_en": "LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration", "authors": "Ruiyu Qiu,Rui Wang,Guanghui Yang,Xiang Li,Zhijiang Shao", "background": "多目标问题（MoPs）中包含多个具有显式优先级的相互冲突的子任务，在现实世界的应用中很常见。尽管强化学习（RL）在单一任务中具有优势，但将其扩展到具有优先级的多个目标仍然是一个挑战。传统的安全强化学习（Safe RL）和多目标强化学习（MORL）方法在高效地执行优先级排序方面存在困难。因此，已开发出分级多目标强化学习（LMORL）方法来解决这些问题。然而，现有的LMORL方法要么依赖于启发式阈值调整的先验知识，要么仅适用于离散域。", "innovation": "本文提出了一种新颖的LMORL框架——分级投影策略梯度强化学习（LPPG-RL），通过利用序列梯度投影来识别可行的策略更新方向，使LPPG-RL广泛兼容所有连续空间中的策略梯度算法。LPPG-RL将投影步骤重新公式化为优化问题，并采用Dykstra的投影而不是通用求解器，从而在小到中等规模的实例中提供显著的加速。此外，LPPG-RL引入了子问题探索（SE）机制，以防止梯度消失、加速收敛并增强稳定性。文章为收敛提供了理论保证，并建立了策略改进的下界。", "conclusion": "本文通过在2D导航环境中进行广泛的实验，验证了LPPG-RL的有效性，表明它优于现有的最先进的连续LMORL方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08364", "html_url": "https://arxiv.org/abs/2511.08364", "title": "DPRM：多跳问答任务中的双隐式过程奖励模型", "title_en": "DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering", "authors": "Xinyi Wang,Yiping Song,Zhiliang Tian,Bo Liu,Tingjin Luo,Minlie Huang", "background": "在多跳问答（MHQA）任务中，通过引导大型语言模型（LLMs）进行多步推理，Chain of Thought（CoT）提高了生成的质量，而知识图谱（KGs）则通过语义匹配减少了幻觉。传统的过程奖励模型（PRMs）可以评估推理过程，但需要昂贵的人工注释或展开生成。而现有的隐式PRM仅适用于纯文本场景，无法处理KG中结构约束，并捕捉CoT与KG路径之间的潜在不一致性。", "innovation": "我们提出了DPRM（双隐式过程奖励模型），旨在解决上述问题。DPRM具有两个隐式PRM，一是KG-PRM，通过KG的偏好对学习结构约束；二是CoT-PRM，从结果信号中推导步骤级奖励。同时，DPRM引入了CoT与KG推理步骤之间的一致性约束，使两个PRM相互验证并协同优化推理路径。此外，该模型还提供了过程奖励推导的理论证明。", "conclusion": "实验结果表明，我们的方法在多个数据集上优于13种基线方法，特别是在Hit@1指标上最高提高了16.6%。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08349", "html_url": "https://arxiv.org/abs/2511.08349", "title": "混合量子-经典选择态空间人工智能", "title_en": "Hybrid Quantum-Classical Selective State Space Artificial Intelligence", "authors": "Amin Ebrahimi,Farzan Haddadi", "background": "混合量子-经典（HQC）算法通过在高维希尔伯特空间中操作，能够提供比纯经典方法更丰富的成本景观表示和指数级的加速，特别适用于机器学习中的大规模数值任务，尤其是在自然语言处理（NLP）中，这些任务由于大规模矩阵乘法和高维优化导致时间复杂度过高，瓶颈显著。现有的深度学习架构在这些任务中面临严重的计算瓶颈。", "innovation": "该研究提出了一种针对时间序列分类问题的混合量子-经典选择机制，专为Mamba架构设计。通过利用量子变分电路（VQCs）作为量子门模块来增强特征提取并减少无关信息的影响，该机制通过引入量子子程序改进了大型语言模型（LLMs）的泛化能力、表达能力和参数效率，展示了量子增强机制在构建可扩展性和资源效率高的NLP模型中的潜力。实验结果显示，在仿射MNIST数据集上，使用一个量子层的混合模型在前四轮中达到了24.6%的准确率，高于纯经典选择机制的21.6%。", "conclusion": "这项研究展示了量子子程序在大型语言模型中的应用有可能提高其表达能力和参数效率，并且量子增强机制为构建可扩展且资源效率高的NLP模型提供了新途径。然而，进一步的研究还需要更多的实验步骤来验证其效果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08344", "html_url": "https://arxiv.org/abs/2511.08344", "title": "通过双向不一致学习实现开集肌电手势识别", "title_en": "Towards Open-Set Myoelectric Gesture Recognition via Dual-Perspective Inconsistency Learning", "authors": "Chen Liu,Can Han,Weishi Xu,Yaqi Wang,Dahong Qian", "background": "表面肌电图（sEMG）基于的手势识别在人机交互（HMI）中起着重要作用，特别是在康复和假肢控制方面。然而，基于sEMG的系统往往因训练数据不足而受到影响，导致深度学习模型过度拟合并泛化能力差。数据增强提供了一种增加训练数据规模和多样性的有希望的方法，但效果依赖于数据增强的忠实性和多样性。然而，增强通用性可能导致无用的冗余样本。为了解决这些问题，本文提出了一种新的基于扩散的数据增强方法，名为稀疏感知语义引导扩散增强（SASG-DA）。该方法通过引入语义表征引导（SRG）机制和高斯模型语义建模（GMSS）策略来提高数据生成的忠实性和多样性，并通过稀疏感知语义取样策略进一步增强目标多样性，从而提高总体样本覆盖率和服务价值。", "innovation": "本文提出的SASG-DA方法通过引入语义表征引导（SRG）机制和高斯模型语义建模（GMSS）策略，以及稀疏感知语义取样策略，增强了数据生成的忠实性和多样性，从而有效减少过拟合并提高识别性能和泛化能力。该方法在基准sEMG数据集Ninapro DB2、DB4和DB7中进行了广泛的实验，并显示出优于现有增强方法的效果。", "conclusion": "实验结果表明，提出的SASG-DA数据增强方法通过提供忠实和多样的样本，有效缓解了过拟合问题，提高了手势识别的性能和泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08369", "html_url": "https://arxiv.org/abs/2511.08369", "title": "基于文本的空地人员检索", "title_en": "Text-based Aerial-Ground Person Retrieval", "authors": "Xinyu Zhou,Yu Wu,Jiayao Ma,Wenhao Wang,Min Cao,Mang Ye", "background": "该研究旨在通过文本描述从航空和地面视角的异构图像中检索人员图像，不同于传统的基于文本的人员检索仅关注地面视角图像。由于不同视角之间的巨大视角差异，为空地视角的检索带来了更大的实际意义和挑战。为此，研究者旨在提供一个包含了多样文本生成范式的开放基准数据集，以及一种能够应对视角异质性的新框架，后者通过层次化的专家模块学习特定视角和非特定视角的特征，并采用视角解耦策略以更好地实现跨模态对齐。", "innovation": "研究提出了一个名为TAG-CLIP的新检索框架，该框架通过层次化的专家模块学习特定视角和非特定视角的特征，并采用视角解耦策略以更好地实现跨模态对齐。此外，还针对空地视角的检索构建了一个名为TAG-PEDES的开放基准数据集，该数据集包含了自动生成的多样文本描述，增强了在视角异质性下的鲁棒性。", "conclusion": "研究在提出的TAG-PEDES数据集和现有的基于文本的人员检索基准上评估了TAG-CLIP的有效性。数据集和源代码可以在指定的网址上下载。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08368", "html_url": "https://arxiv.org/abs/2511.08368", "title": "A Circular Argument: Does RoPE need to be Equivariant for Vision?", "title_en": "A Circular Argument : Does RoPE need to be Equivariant for Vision?", "authors": "Chase van de Geijn,Timo Lüddecke,Polina Turishcheva,Alexander S. Ecker", "background": "Rotary Positional Encodings (RoPE)作为一种在自然语言处理中非常有效的技术，已经在一维序列上取得了显著成功，并且正在被尝试应用到更高维度的数据如图像和视频中。RoPE 的成功被认为与其相对位置编码的性质有关。", "innovation": "本文数学上证明了RoPE是处理一维数据中通用的自同变位置嵌入解决方案，并进一步提出了共轭RoPE作为在M维数据中的通用解决方案。同时，本文提出了一种名为球形RoPE的方法，假设非交换生成器，以探索自同变特性在RoPE性能中的重要性。", "conclusion": "实验结果表明，球形RoPE在学习行为上与同变版本相当甚至更好，这表明相对位置嵌入的重要性可能没有人们普遍认为的那么重要。这一发现有望促进未来在计算机视觉中对位置编码的研究，可以更快且更好地泛化，而不必预设它们必须是相对的。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08360", "html_url": "https://arxiv.org/abs/2511.08360", "title": "低精度下具有极简结构稀疏性的极端模型压缩", "title_en": "Extreme Model Compression with Structured Sparsity at Low Precision", "authors": "Dan Liu,Nikita Dvornik,Xue Liu", "background": "深度神经网络（DNN）在诸多应用中广泛使用，但其庞大的规模和高昂的计算成本使得它们难以在资源有限的设备上运行。为解决这一问题，通常会采用两种技术：权重量化，这会降低所有权重的精度；结构性稀疏性，这会移除不重要的权重同时保持重要权重为全精度。然而，单独而言这两种方法都很有效，但当它们结合使用时会对模型的准确性产生负面协同影响，因此通常是在孤立的情况下研究的。本文提出了一种统一框架SLOPE，旨在以严谨的方式将结构性稀疏性和低比特量化有效结合在一起。我们通过减少全精度权重与稀疏、量化权重之间的差异，促进角度对齐而非直接匹配，解决了单纯结合稀疏性和量化方法所带来的性能损害问题。在ResNet-18等模型上的实验结果显示，SLOPE实现了约20倍的模型尺寸减少，同时保持了约99%的原始准确率。", "innovation": "引入了一种统一框架SLOPE，以严谨的方式结合结构性稀疏性和低比特量化。提出了一种基于训练的正则化策略，通过促进角度对齐而非直接匹配，来最小化全精度权重与稀疏、量化权重之间的差异，从而有效解决了单纯结合稀疏性和量化方法带来的性能损害问题。与现有最先进的量化和结构性稀疏方法相比，SLOPE在分类、检测和分割任务上表现更优。", "conclusion": "通过SLOPE框架，实现了高效的极端模型压缩，达到了显著减少模型尺寸的同时保持接近原始的准确率的效果。该方法适用于包括ResNet-18、ViT-Small和Mask R-CNN在内的多种模型。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08389", "html_url": "https://arxiv.org/abs/2511.08389", "title": "为语音基础模型统一模型和层融合", "title_en": "Unifying Model and Layer Fusion for Speech Foundation Models", "authors": "Yi-Jen Shih,David Harwath", "background": "近年来，语音基础模型引起了广泛关注。先前的研究表明，将单个模型的多层表示或多个模型的表示进行融合可以提高下游任务的性能。本文统一了这两类融合策略，提出了一种接口模块，能够跨多个上游语音模型融合信息并整合各个层的信息。", "innovation": "本文提出了一种接口模块，能够跨多个上游语音模型融合信息并整合各个层的信息，扩展了不同自监督和监督模型在不同语音任务（如ASR和语平行分析）上的表现，并且优于先前的融合方法。此外，还分析了该方法的可扩展性，强调了选择合适上游模型的重要性。", "conclusion": "所提出的方法在给定适合的上游模型选择时能提供额外的性能提升，是利用语音基础模型的一种有前途的方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08387", "html_url": "https://arxiv.org/abs/2511.08387", "title": "RAPTR：基于雷达的Transformer人体3D姿态估计", "title_en": "RAPTR: Radar-based 3D Pose Estimation using Transformer", "authors": "Sorachi Kato,Ryoma Yataka,Pu Perry Wang,Pedro Miraldo,Takuya Fujihashi,Petros Boufounos", "background": "传统基于雷达的室内3D人体姿态估计通常依赖于精细的3D关键点标签，这些标签在复杂室内环境中，特别是涉及杂乱、遮挡或多人的情况时获取成本较高。本文探讨了在弱监督条件下仅使用3D边界框标签和2D关键点标签进行3D人体姿态估计的方法，以降低获取标签的成本。", "innovation": "提出了一种名为RAPTR（RAdar Pose esTimation using tRansformer）的两阶段姿态解码器架构，其中整合了伪3D可变形注意力机制，以增强姿态/关节查询并利用多视角雷达特征。初始姿态估计采用了3D模板损失来利用3D边界框标签并减少深度不确定性，而关节细化阶段则使用2D关键点标签和3D重力损失。在两项室内雷达数据集上的评估表明，该方法性能优于现有方法，在HIBER数据集上关节位置误差降低34.3%，在MMVR数据集上降低76.9%。", "conclusion": "RAPTR在两个室内雷达数据集上的评估结果表明，它在关节位置估计方面优于现有方法，特别是在HIBER和MMVR数据集上取得了显著的性能提升。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08378", "html_url": "https://arxiv.org/abs/2511.08378", "title": "通过混合意向双重约束实现准确的低流行度会话推荐：告别跷跷板", "title_en": "Bid Farewell to Seesaw: Towards Accurate Long-tail Session-based Recommendation via Dual Constraints of Hybrid Intents", "authors": "Xiao Wang,Ke Qin,Dongyang Zhang,Xiurui Xie,Shuang Liang", "background": "会话推荐（SBR）旨在基于用户的会话预测他们的下一次交互。在实际推荐场景中，低曝光项目构成了大多数交互，创造了长尾分布，严重损害了推荐的多样性。现有方法试图通过促进尾部项目来解决这个问题，但会牺牲准确性，表现出长尾和精度性能之间的‘跷跷板’效应。", "innovation": "提出了HID（混合意图双重约束框架），这是一种插件框架，通过引入混合意图双重约束，将常规的‘跷跷板’效应转变为‘双赢’。HID的两个关键创新是：(i) 混合意图学习，通过使用属性感知的谱聚类重新配置项目到意图的映射，并通过将目标意图和噪声意图分配给每个会话来实现对会话无关噪声的区分。(ii) 目标意图约束损失，通过引入关于多样性和准确性的两个新的约束范式，调节项目和会话的表示学习过程。", "conclusion": "广泛的实验表明，HID可以提高长尾性能和推荐准确率，并在长期尾部推荐系统中建立了新的最佳性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08402", "html_url": "https://arxiv.org/abs/2511.08402", "title": "Anatomy-VLM: 一种细粒度的视觉语言模型用于医学解释", "title_en": "Anatomy-VLM: A Fine-grained Vision-Language Model for Medical Interpretation", "authors": "Difei Gu,Yunhe Gao,Mu Zhou,Dimitris Metaxas", "background": "放射学中准确的疾病解释仍然具有挑战性，因为影像具有多样性。专家级别的诊断决策需要将细微的影像特征与临床知识相结合。然而，现有的vision-language模型（VLM）将影像视为整体，忽视了对疾病诊断至关重要的细微影像细节。临床医生通过利用他们的医学知识并识别重要的解剖结构区域来进行影像分析。", "innovation": "引入了一种细粒度的视觉语言模型（Anatomy-VLM），该模型包含多尺度信息。该模型包含三个创新点：首先，设计了一个模型编码器来定位医学影像中的关键解剖特征；其次，通过结构化知识丰富这些区域以实现上下文感知的解释；最后，模型编码器对多尺度医疗信息进行对齐，生成临床可解释的疾病预测。", "conclusion": "Anatomy-VLM 在内分布和外分布数据集上均取得了出色表现。还验证了 Anatomy-VLM 在下游影像分割任务上的性能，表明其细粒度对齐捕获了解剖和病理相关知识。此外，Anatomy-VLM 的编码器促进了零样本解剖导向的解释，提供了强大的专家级临床解释能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08436", "html_url": "https://arxiv.org/abs/2511.08436", "title": "使用多智能体深度强化学习理解弱电鱼的电通信和电感知", "title_en": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning", "authors": "Satpreet H. Singh,Sonja Johnson-Yu,Zhouyang Lu,Aaron Walsman,Federico Pedraja,Denis Turcu,Pratyusha Sharma,Naomi Saphra,Nathaniel B. Sawtell,Kanaka Rajan", "background": "弱电鱼，如Gnathonemus petersii，通过其独特的电气模态进行主动感知和交流。然而，在自然环境中研究这些行为及其相关的神经活动具有实验上的挑战。现有的研究方法难以满足这些需求。", "innovation": "本文提出了一种新的生物启发的计算框架，使用基于循环神经网络（RNN）的多智能体强化学习（MARL）训练的人工代理模型，该模型通过学习调节它们的电器官放电（EODs）和运动模式，能够在虚拟环境中集体觅食。这些训练过的代理显示了类似真实鱼集体的多种新兴特征。", "conclusion": "这些行为通过进化启发的奖励和个人适应度的提升自然演化而来，而不是通过直接奖励社会互动。这项工作对弱电鱼的神经生态学有着广泛的影响，并且对于其中同时无法对多个个体进行大量记录的传统数据驱动建模来说具有启示意义。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08394", "html_url": "https://arxiv.org/abs/2511.08394", "title": "交互动力学作为LLMs的奖励信号", "title_en": "Interaction Dynamics as a Reward Signal for LLMs", "authors": "Sian Gooding,Edward Grefenstette", "background": "现有的大型语言模型（LLMs）在处理多轮对话时通常依赖于从文本内容中获取的奖励信号。然而，这种做法忽略了互动本身提供的丰富、互补的信号源。本文探讨了通过对话嵌入轨迹的几何属性（即‘对话几何’）获得的新奖励信号，并将其称为TRACE（基于轨迹的奖励估计）。研究显示，仅使用结构信号训练的奖励模型（准确率为68.20%），已经与分析完整对话转录的强大LLM基线（准确率为70.04%）相当。结合互动动态与文本分析，提出的混合模型达到了最高的性能（80.17%），这表明两者之间具有互补性。", "innovation": "本文引入了名为TRACE的新奖励信号，这一信号通过对话的嵌入轨迹的几何属性获得，以弥补现有方法仅依赖文本内容的问题。实验结果显示，混合模型能够有效利用结构信号和互动信号，显著提高了模型在评估对话协作方面的能力。", "conclusion": "本文通过实验证明，在交互环境中，对话中代理的沟通方式与其所说的内容一样重要。这种基于轨迹的奖励方法不仅有助于代理间的对齐，还提供了一种诊断工具，用于理解和分析推动成功协作的独特互动模式。这种方法具有高度的隐私保护性，为未来交互式对话系统的优化提供了新的视角。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08500", "html_url": "https://arxiv.org/abs/2511.08500", "title": "SPEAR-MM：通过模型合并进行选择性参数评估和恢复以实现高效金融LLM适应", "title_en": "SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation", "authors": "Berkcan Kapusuzoglu,Supriyo Chakraborty,Renkun Ni,Stephen Rawls,Sambit Sahu", "background": "大型语言模型（LLMs）在金融领域往往会发生灾难性的遗忘现象，即失去了基本的推理能力，这些能力对于客户互动和复杂的财务分析至关重要。这给金融领域的持续预训练带来了挑战。", "innovation": "本文提出了Selective Parameter Evaluation and Restoration via Model Merging（SPEAR-MM），这是一种实用的框架，旨在同时保留关键能力并使模型适应特定领域。该方法通过后验分析逐层评估对外部基准的影响，然后通过球形插值合并选择性冻结或恢复变压器层。", "conclusion": "在将LLaMA-3.1-8B应用于金融任务时，SPEAR-MM在保持94%的领域适应收益的同时实现了91.2%的一般能力保留，对比之下，标准连续预训练仅保留了69.7%的一般能力。这种方法提供了一种可解释的权衡控制，并且降低了90%的计算成本，这对于资源受限的金融机构非常重要。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08470", "html_url": "https://arxiv.org/abs/2511.08470", "title": "使用Mean Absolute Error准则在CART中对二元分裂分类特征的处理", "title_en": "Binary Split Categorical feature with Mean Absolute Error Criteria in CART", "authors": "Peng Yu,Yike Chen,Chao Xu,Albert Bifet,Jesse Read", "background": "在分类和回归树（CART）算法中，使用标准的分类标准如GINI指数和熵来高效划分分类特征已经得到了广泛的应用。然而，对于使用均绝对误差（MAE）准则划分分类特征，传统上依赖于各种数值编码方法。这表明现有的编码方法在MAE准则下的适用性存在局限性。", "innovation": "本文提出了一个新颖且高效的分裂算法，专门针对使用MAE准则处理分类特征的挑战。这一创新解决了现有方法在处理分类数据中遇到的限制，并提供了一种提升CART算法中分类数据处理能力的潜在解决方案。", "conclusion": "现有方法在使用MAE准则处理分类特征时存在局限性，本文提出的新算法能够有效应对这一挑战，为增强CART算法中分类数据的处理能力提供了新的视角。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08464", "html_url": "https://arxiv.org/abs/2511.08464", "title": "对比集成梯度：一种用于解释全视野图像分类的功能归因方法", "title_en": "Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification", "authors": "Anh Mai Vu,Tuan L. Vo,Ngoc Lam Quang Bui,Nam Nguyen Le Binh,Akash Awasthi,Huy Quoc Vo,Thanh-Huy Nguyen,Zhu Han,Chandra Mohan,Hien Van Nguyen", "background": "在计算病理学中，全视野图像（WSI）分析的可解释性至关重要，理解模型预测有助于提升人工智能辅助诊断的信任度。集成梯度（IG）及相关归因方法虽然有潜力，但直接应用于WSI时会遇到挑战，因为WSI的高分辨率特性可能导致区分肿瘤亚型的关键类差信号被忽视。", "innovation": "本文提出了一种新颖的归因方法——对比集成梯度（CIG），该方法通过在logit空间计算对比梯度以增强可解释性。首先，CIG通过相对一个参考类比较特征重要性来突出类差区，提供更锐利的肿瘤与非肿瘤区域区分；其次，CIG满足归因一致性公理，确保了理论上的严谨性；最后，提出两种归因质量度量指标——MIL-AIC和MIL-SIC，测量在获得显着区域时预测信息和模型置信度的演变，尤其是在弱监督条件下，进一步验证CIG的有效性与可靠性，特别是在乳腺癌淋巴结、肾细胞癌和肺癌等三种不同癌症类型的三个数据集上。", "conclusion": "实验结果表明，CIG在定量上（使用MIL-AIC和MIL-SIC）和定性上（通过与实际肿瘤区域一致的可视化）均能提供更丰富的归因。这进一步证明了CIG在可解释且可信赖的WSI基检测分析中的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08496", "html_url": "https://arxiv.org/abs/2511.08496", "title": "HQ-SVC：在低资源场景下迈向高质量零样本歌唱语音转换", "title_en": "HQ-SVC: Towards High-Quality Zero-Shot Singing Voice Conversion in Low-Resource Scenarios", "authors": "Bingsong Bai,Yizhong Geng,Fengping Wang,Cong Wang,Puyuan Guo,Yingming Gao,Ya Li", "background": "现有的零样本语音转换（SVC）方法将歌手的音色转换为目标说话人的音色时，通常会将演讲内容和音色分别建模，从而失去一些重要的声学信息，导致输出质量下降，同时需要大量的计算资源。因此，需要一种新的方法来解决这些问题，以提高转换质量和效率，并保持语音自然度，同时支持语音超分辨率任务.", "innovation": "提出了一种高效框架HQ-SVC，用于高质量的零样本语音转换。HQ-SVC首先使用解耦编码器提取联合内容和说话人特征，然后通过音高和音量建模增强保真度，保留了单独建模方法通常会丢失的关键声学信息，通过不同的可微信号处理和扩散技术逐步细化输出。", "conclusion": "评估结果表明，HQ-SVC在转换质量和效率上显著优于最先进的零样本SVC方法，并且在语音自然度方面甚至优于专门的音频超分辨率方法，同时内置支持语音超分辨率任务。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08475", "html_url": "https://arxiv.org/abs/2511.08475", "title": "LLM基-multi-agent系统设计在软件工程任务中：质量属性、设计模式和动机", "title_en": "Designing LLM-based Multi-Agent Systems for Software Engineering Tasks: Quality Attributes, Design Patterns and Rationale", "authors": "Yangxiao Cai,Ruiyin Li,Peng Liang,Mojtaba Shahin,Zengyang Li", "background": "随着软件工程任务的复杂性不断增加，多代理系统(MASs)由于其自治性和可扩展性成为研究和实践的焦点。近年来，通过利用大型语言模型(LLMs)的推理和规划能力，LLMs驱动的MASs在软件工程领域的应用越来越受到关注。然而，至今没有系统研究LLMs驱动的MASs的设计，特别是设计关注的质量属性、使用的设计模式以及指导其设计的动机。本研究收集了94篇针对LLMs驱动的MASs的文章，以识别针对软件工程任务的LLMs驱动的MASs的主要关注质量属性、使用的设计模式和设计动机。这些研究表明，生成代码是最常被LMLs驱动的MASs解决的软件工程任务，功能性适合度是设计者主要关注的质量属性，基于角色的合作是最常见的设计模式，提高生成代码质量是设计的主要动机。", "innovation": "本研究是首次系统地探索LLMs驱动的MASs的设计，包括设计者主要关注的质量属性、使用的设计模式以及指导其设计的动机，填补了该领域的研究空白。", "conclusion": "本研究的结果为LLMs驱动的MASs的设计提供了启示，有助于进一步优化其在软件工程任务中的应用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08535", "html_url": "https://arxiv.org/abs/2511.08535", "title": "大型手语模型：迈向3D美国手语翻译", "title_en": "Large Sign Language Models: Toward 3D American Sign Language Translation", "authors": "Sen Zhang,Xiaoxiao He,Di Liu,Zhaoyang Xia,Mingyu Zhao,Chaowei Tan,Vivian Li,Bo Liu,Dimitris N. Metaxas,Mubbasir Kapadia", "background": "现有手语识别方法主要依赖于2D视频数据，但这种方法难以捕捉丰富的3D手语和空间信息，影响了听力障碍者数字化通信的便捷性和准确性。本文旨在通过利用大规模语言模型（LLMs）作为基础构建一个新颖的框架，以直接利用3D手语数据，从而更好地捕捉3D场景中的空间、手势和深度信息，提升手语翻译的准确性和鲁棒性，增强手语翻译的应用场景，使听力障碍者能够更方便地进行虚拟交流。", "innovation": "本文提出了一种新颖的框架——大型手语模型（LSLM），直接利用3D手语数据进行翻译，而不是依赖2D视频。该模型能够捕捉丰富的3D空间、手势和深度信息，支持从3D手势特征到文本的直接翻译，并在外部指令指导下调整翻译，为构建包容性多模态智能系统奠定了基础，这些系统能够理解多种语言形式，不仅仅是文本输入。", "conclusion": "本文为实现包容性、多模态智能系统提供了基础，使得语言理解可以超越纯粹的文本输入，拓宽LLMs对人类沟通的理解，从而增强手语翻译的精确性和韧性，为听力障碍者提供更便捷的虚拟交流途径。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08565", "html_url": "https://arxiv.org/abs/2511.08565", "title": "大型语言模型在角色扮演下的道德敏感性和稳定性", "title_en": "Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models", "authors": "Davi Bastos Costa,Felippe Alves,Renato Vicente", "background": "大型语言模型（LLMs）越来越多地在社交环境中使用，这促使研究者们分析这些模型如何表达和转变道德判断。本研究旨在了解大模型在扮演特定角色时的道德反应，通过使用道德基础问卷（MFQ），构建了一个基准来量化两个特性：道德脆弱性和道德稳定性。", "innovation": "研究引入了一种新型基准，用于量化大型语言模型在不同人物角色扮演下的道德响应，提出了一种用来评估道德稳定性和脆弱性的方法。发现不同模型家族在这两个特性上显示出了显著差异，Claude family是最稳定的，其次是Gemini和GPT-4模型。此外，研究还考察了模型大小对这些特性的影响。", "conclusion": "研究分析表明，人格条件对大型语言模型的道德行为有显著影响。道德稳定性与模型家族相关，而道德脆弱性除了家族影响外还受模型大小影响。稳健性和脆弱性之间呈现出正相关关系，且这种关系在家族级别更为明显。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08507", "html_url": "https://arxiv.org/abs/2511.08507", "title": "引入用于孟加拉手语翻译与研究的孟加拉语句-手语词对照数据集", "title_en": "Introducing A Bangla Sentence - Gloss Pair Dataset for Bangla Sign Language Translation and Research", "authors": "Neelavro Saha,Rafi Shahriyar,Nafis Ashraf Roudra,Saadman Sakib,Annajiat Alim Rasel", "background": "孟加拉手语（BdSL）翻译是一个低资源的自然语言处理任务，主要是由于缺乏大规模的手语句子级别的数据集。现有的研究主要集中在手语单词和字母级别的检测上，而未涉及句子级别的翻译任务。因此，需要构建一个新的数据集来推动BdSL的翻译研究，从而改进现有模型，提高翻译的准确性。", "innovation": "本文介绍了孟加拉-手语词（Bangla-SGP）数据集，这是一个新颖的平行数据集，包含1000个人工标注的手语词句对，并通过规则基础的检索增强生成（RAG）管道补充了大约3000个合成生成的手语词对。数据集中包含的手语词序列由单个手语词（孟加拉语支持的手语词）组成，作为连续手语的中间表示。此外，通过仔细分析人工标注的手语词句对，并与专业手语者紧密合作，进行了规则基础的语言策略和提示工程技巧的改进，来增强数据集。最后，基于BLEU评分对几种变压器模型进行微调，并评估这些模型在句子到手语词翻译过程中的表现和一致性，特别是与RWTH-PHOENIX-2014T基准数据集的对比分析。", "conclusion": "本文引入了Bangla-SGP数据集，包含1000个人工标注的手语词句对，并进一步使用规则基础的RAG方法生成了大约3000个合成生成的手语词对。通过这种方式，构建了一个高质量的数据集以推动BdSL翻译的研究，同时通过与现有基准数据集的对比展示了这些模型在翻译准确性上的进步。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08567", "html_url": "https://arxiv.org/abs/2511.08567", "title": "未走之路：RLVR 证明在主成分之外学习", "title_en": "The Path Not Taken: RLVR Provably Learns Off the Principals", "authors": "Hanqing Zhu,Zhenyu Zhang,Hanxian Huang,DiJia Su,Zechun Liu,Jiawei Zhao,Igor Fedorov,Hamed Pirsiavash,Zhizhou Sha,Jinwon Lee,David Z. Pan,Zhangyang Wang,Yuandong Tian,Kai Sheng Tai", "background": "论文背景在于，虽然RLVR（可验证奖励的强化学习）能够可靠地提升大规模语言模型的推理性能，但似乎只修改了模型参数的一小部分。有悖于此，研究表明这种稀疏是模型条件优化偏见的结果：对于固定预训练模型，更新集中在优选参数区域，并且在多次运行中保持一致，对数据集和RL配方变化不大。", "innovation": "创新之处在于，论文提出了一个‘三闸理论’来解释这一现象，通过KL锚、模型几何和精确度三个机制来描述更新的动力学。此外，相比自回归微调（SFT），RLVR在权重空间中沿着非主成分方向学习，实现了最小的光谱漂移，减少主成分子空间旋转，并对非主成分更新进行对齐，从而获得改进。通过参数级分析首次获得了RLVR学习动力学的详细解释，强调了RL和SFT在优化方面的差异，从而表明直接应用SFT时代的参数高效微调（PEFT）方法可能存在问题。", "conclusion": "研究结论揭示了参数在训练过程中的演变规律，表明RL和SFT处于不同的优化领域。研究补充道，直接借鉴SFT时代的参数高效微调方法可能有问题，并强调需要对RLVR的训练动态有一个白盒理解，设计几何感知的、特定于RLVR的计算方法，而不是依赖SFT时代的启发式方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08544", "html_url": "https://arxiv.org/abs/2511.08544", "title": "LeJEPA：无需技巧的可证明和可扩展的自监督学习", "title_en": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics", "authors": "Randall Balestriero,Yann LeCun", "background": "学习世界的可操控表示及其动力学是人工智能的核心。联合嵌入预测架构（JEPAs）提供了一种有前景的蓝图，但由于缺乏实用指南和理论，导致了试验性研究和开发（R&D）。", "innovation": "我们提供了一个全面的JEPAs理论，并具体实例化为LeJEPA，一种简洁、可扩展且有理论支持的训练目标。首先，我们确定各向同性高斯分布是JEPAs嵌入应遵循的最佳分布，以最小化下游预测风险。其次，我们引入了一种新的目标——“素描的各向同性高斯正则化”（SIGReg），以约束嵌入达到该理想分布。结合JEPA预测损失与SIGReg可以生成LeJEPA，具有多种理论和实际优势：单一的折中超参数，线性时间与内存复杂度，超参数、架构（ResNets, ViTs, ConvNets）和领域稳定，无告警权重、无教师-学生方法，无需超参数调度程序，并且具有友好的分布式训练实现，仅需约50行代码。我们的实证验证涵盖了10多个数据集、60多种架构，所有这些都具有不同的规模和领域。例如，使用ImageNet-1k进行预训练和冻结骨干的线性评估，LeJEPA 使用ViT-H/14 达到了79%。", "conclusion": "我们希望LeJEPA提供的简洁性和理论友好生态系统会重新建立自监督预训练作为人工智能研究的核心支柱。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08573", "html_url": "https://arxiv.org/abs/2511.08573", "title": "SENCA-st：使用跨注意力共享编码器整合空间转录组学和组织病理学以识别癌症病理学中的区域", "title_en": "SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology", "authors": "Shanaka Liyanaarachchi,Chathurya Wijethunga,Shihab Aaquil Ahamed,Akthas Absar,Ranga Rodrigo", "background": "空间转录组学是一个新兴领域，能够通过基因表达的空间分布来识别功能区域。将转录组学数据中的功能性信息与histopathology图像中的结构信息进行整合，是目前的一个活跃研究领域，特别是在识别与癌症药物耐药性相关的肿瘤亚结构方面。当前的空间转录组学和组织病理学区域分割方法在处理数据时，要么过分强调空间转录组学数据而忽视了组织病理学特征，要么过分强调组织病理学图像而丢失了功能性信息。现有的方法要么在噪声中迷失方向，要么过于平滑导致关键信息丢失。", "innovation": "我们提出了一种新的架构SENCA-st（共享编码器与邻域交叉注意力），该架构能够保留两种模态的特征，并通过跨注意力机制突出在组织病理学上结构相似但在空间转录组学上功能不同的区域。这种方法在检测肿瘤异质性和肿瘤微环境方面表现出优越性能，超越了现有的最佳方法。", "conclusion": "我们的模型SENCA-st能够在保留功能信息和结构信息的平衡下，有效识别和分割肿瘤组织中的关键区域，提供了一种新的、更有效的整合空间转录组学和组织病理学数据的方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11075", "html_url": "https://arxiv.org/abs/2504.11075", "title": "通过自我先验的主动推理产生目标导向行为", "title_en": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior", "authors": "Dongmin Kim,Hoshinori Kanazawa,Naoto Yoshida,Yasuo Kuniyoshi", "background": "婴儿常常表现出目标导向的行为，即使没有外部奖励的条件提供，也会伸手去抓感官刺激。这些内在动机的行为促进了婴儿在早期发展阶段对身体和环境的自发探索和学习。虽然计算建模可以提供关于此类行为机制的洞察，但许多现有的内在动力研究主要集中在探索如何促进外部奖励的获取。", "innovation": "本文提出了基于主动推理框架的“自我先验”密度模型，该模型可以直接从内在过程中生成行为参考，通过最小化平均过去的感官经验和当前观察之间的不匹配来驱动自发地目标导向行为。这种机制类似于通过与环境的持续互动来获得和利用体感模型的过程。", "conclusion": "在模拟环境中对该方法进行了实验，结果表明该代理能够自发地朝触觉刺激伸手，从而表明内在驱动的行为可以通过代理自身的感官经验自发地形成。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.02430", "html_url": "https://arxiv.org/abs/2504.02430", "title": "人工智能如何导致知识为何：基于亚里士多德后分析学的探究", "title_en": "How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics", "authors": "Guus Eelink,Kilian Rückschloß,Felix Weitkämper", "background": "贝叶斯网络和因果模型提供了处理关于外部干预和反事实查询的框架，这些框架能够超越单一概率分布所能解决的任务。然而，这些形式化方法常常被非正式地描述为捕捉因果知识，但缺乏一个正式理论来描述预测外部干预效果所需的类型的知识。为了澄清人工智能中的知识为何和知识那之间的区别，本文引入了因果系统的理论框架，利用现有人工智能技术作为因果系统的观点来研究对应的知识类型。进一步论证了仅凭知识那无法预测外部干预的效果，需要知识为何来预测这些效果，从而为这类任务所需的知识提供了更精确的理解。", "innovation": "通过引入因果系统的理论框架，定义了知识为何和知识那之间的区别，并论证了预测外部干预效果需要知识为何，而非单纯的知识那。这种方法为人工智能和因果推理领域提供了一个更深入理解预测外部干预效果所需知识的工具。", "conclusion": "通过将现有人工智能技术解读为因果系统，并基于此研究对应的知识类型，本文指出预测外部干预效果需要知识为何，而非仅依赖于知识那，从而提供了预测外部干预效果所需知识的更精确理解。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08570", "html_url": "https://arxiv.org/abs/2511.08570", "title": "使用层直方图进行柯尔莫哥洛夫-阿诺德网络的自动网格更新", "title_en": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms", "authors": "Jamison Moody,James Usevitch", "background": "柯尔莫哥洛夫-阿诺德网络(KANs)是一种近年来在文献中受到越来越多关注的神经网络。与多层感知机(MLPs)不同，KANs利用参数化、可训练的激活函数，提供更好的可解释性和学习符号方程时更高的准确性。然而，原始KAN架构在训练过程中要求用户调整网络的领域离散化（称为“领域网格”的调整），这为用户增加了额外的训练过程负担。KAN层通常没有设计为能够自主地以数据驱动的方式更新它们的领域，从而适应先前层输出范围的变化。此外，该直方图算法还可以应用于检测各种情境下的异常输入数据（OOD）。", "innovation": "本文提出了一种新的方法，使用层直方图实现柯尔莫哥洛夫-阿诺德网络的自动网格更新。这一创新克服了传统KAN架构在训练过程中需要手动调整领域网格的问题，提高了网络的自动适应性和灵活性。通过这种方法，KAN层可以在数据驱动的方式下自主更新其领域，从而提高模型的学习效率和泛化能力。实验证明，这一方法不仅在学习科学方程、图像分类、控制李雅普诺夫函数学习以及检测异常输入数据等方面超过或匹配了先前的KAN架构和MLP模型，还具有检测异常输入数据的功能。", "conclusion": "本文提出的使用层直方图进行自动网格更新的KAN（AdaptKAN）模型，在多个不同的任务上均超过了或匹配了先前的KAN架构和MLP模型的表现。这表明该方法在提高KAN模型的学习性能和自动适应特性方面具有显著优势，并为KAN模型的优化和应用提供了新的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08579", "html_url": "https://arxiv.org/abs/2511.08579", "title": "训练语言模型解释其自身计算", "title_en": "Training Language Models to Explain Their Own Computations", "authors": "Belinda Z. Li,Zifan Carl Guo,Vincent Huang,Jacob Steinhardt,Jacob Andreas", "background": "研究人员关注语言模型（LMs）是否能够准确描述其内部计算过程。现有研究表明，与解释其他模型相比，LMs 有能力更准确地描述自身的内部状态。本文探讨利用LMs对自身内部结构的访问权，开发新的解释其行为的技术。通过利用现有的可解释性技术作为基准，对LMs进行微调，使其能够生成关于 (1) LM 特征编码的信息，(2) LM 内部激活的因果结构，以及 (3) 特定输入词对LM输出影响的自然语言描述。训练仅需数十万条示例解释，解释器模型就能在新查询中表现出非平凡的泛化能力，这表明这对计算进行解释通常比用不同的模型解释要更为有效，即使后者可能更为强大。", "innovation": "本文提出了利用语言模型自身的内部访问权来开发新的解释模型的方法。通过微调现有的解释技术，并利用语言模型自身的内部信息来生成关于其计算过程的自然语言描述。这种方法不仅展示了语言模型能够可靠地解释其内部计算，还表明这样的解释可以作为现有解释方法的有效补充，尤其是在具备强大的解释模型的情况下，使用相同的模型进行解释往往更为有效。", "conclusion": "研究结果表明，语言模型不仅能够学习可靠地解释其内部计算，而且这类解释为现有的可解释性方法提供了可扩展的补充，特别是在使用不同模型解释时，使用相同的模型解释其自身的计算往往更为有效。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08577", "html_url": "https://arxiv.org/abs/2511.08577", "title": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models", "title_en": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models", "authors": "Tianyu Fu,Yichen You,Zekai Chen,Guohao Dai,Huazhong Yang,Yu Wang", "background": "改进大型语言模型（LLMs）的推理能力，特别是在参数受限的情况下，对于实际应用至关重要。早期的研究提出了循环变换器，通过为每个令牌提供固定次数的额外迭代来提高生成质量。这些方法在标准前向传播后，选择性地将最后一层隐藏状态回传以优化令牌预测。然而，这些方法在实践中遇到一个瓶颈：一些容易且直接正确的预测，有时会在额外的迭代中被错误地修正为错误的预测。", "innovation": "提出了一种名为Think-at-Hard的动态隐式推理方法（TaH），能够只在需要额外推理的“硬”令牌上进行更深的迭代，从而避免了不必要的冗余计算。TaH利用了一个轻量级的神经决定器，在标准前向传播后识别出需要额外推理的不正确令牌。在隐式迭代过程中，采用低秩适应（LoRA）模块将模型目标从一般的下一个令牌预测调整为更注重于困难令牌的精炼。此外，引入了一种双重因果注意力机制，该机制将注意力机制扩展到迭代深度维度，从而实现了跨迭代的信息流，同时保持了序列的并行性。", "conclusion": "实验表明，Think-at-Hard能够在五个具有挑战性的基准测试中提升LLM的推理表现，并且维持了相同参数数量。与对所有输出令牌进行两次迭代的基线相比，Think-at-Hard在准确度上提高了8.1-11.3%，同时免除了94%的令牌进行第二次迭代。与自相同数据微调的强单迭代Qwen3模型相比，它还获得了4.0-5.0%的准确度提升。允许少量的额外参数（LoRA和迭代决策器）后，准确度的提升分别达到了8.5-12.6%和5.3-5.4%。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12006", "html_url": "https://arxiv.org/abs/2505.12006", "title": "SOCIA-$\\nabla$: 文本梯度与多代理编排的结合实现自动化模拟器生成", "title_en": "SOCIA-$\\nabla$: Textual Gradient Meets Multi-Agent Orchestration for Automated Simulator Generation", "authors": "Yuncheng Hua,Sion Weatherhead,Mehdi Jafari,Hao Xue,Flora D. Salim", "background": "本文旨在解决模拟器构建的问题，传统的构建方法通常需要大量的专家参与且难以扩展。作者试图通过一个端到端的、代理驱动的框架解决这一问题。", "innovation": "作者提出了一个名为SOCIA-$\\nabla$的框架，该框架将模拟器构建视为文本计算图中的实例优化问题。框架中嵌入了专门的大型语言模型（LLM）驱动的代理，并使用了一个工作流管理器执行基于损失的循环：代码合成 -> 执行 -> 评估 -> 代码修复。同时，通过文本梯度下降（TGD）优化器实现了优化，并通过人为调节以确认任务特定的任务，减少了专家的干预，从而使代码本身成为可训练的对象。", "conclusion": "SOCIA-$\\nabla$在用户建模、掩码适应和个人移动等三个CPS任务中达到了最先进的整体准确性。该框架通过将多代理编排与损失对齐的优化视图统一在一起，将易碎的提示管道转化为可复现、约束意识的模拟器代码生成，实现了跨领域和模拟粒度的应用扩展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01724", "html_url": "https://arxiv.org/abs/2508.01724", "title": "ReflecSched: 通过基于大语言模型的分层反思解决动态灵活作业车间调度", "title_en": "ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection", "authors": "Shijie Cao,Yuan Yuan", "background": "动态灵活作业车间调度（DFJSP）问题是一个NP难问题，涉及实时事件和复杂的路径规划。传统的规则虽然高效但有刚性，深度学习虽然透明但需要特征工程。大型语言模型（LLMs）承诺无须特征工程就能进行适应性推理，但直接应用这些模型效果不佳。基线LLMs在关键数据的利用、专家启发式规则的应用以及非短视决策方面存在三个关键缺陷：长上下文悖论、启发式规则的利用率不足和短视决策。因此，本研究提出了一个名为ReflecSched的框架，通过为LLM赋予战略性分析能力来弥补这些不足。", "innovation": "ReflecSched框架通过任务LLM对多个规划范围内的启发式驱动模拟进行战略性分析，并将其总结为简洁的自然语言“战略经验”。这种总结随后被整合到最终决策模块的提示中，指导其产生非短视的行为。实验表明，使用ReflecSched产生的最佳版本在平均RPD（资源消耗比）为6.04%，排名3.18，显着优于传统和基于学习的方法，并且统计上和显著优于直接基于LLM的基线模型，在标准规模问题上比后者平均节省15.1%的令牌，赢率也高达71.35%。归因于其强大的反思机制，能够利用高质量、对比的经验，有效缓解LLM的短视贪婪倾向，确保了ReflecSched在所有评估启发式方法中表现出色。", "conclusion": "实验结果表明，ReflecSched框架的性能与类似先验策略的性能相当，证实了其有效性和鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10391", "html_url": "https://arxiv.org/abs/2508.10391", "title": "LeanRAG：基于知识图谱的语义聚合与层次化检索生成", "title_en": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": "Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi", "background": "Retrieval-Augmented Generation (RAG)通过利用外部知识在网络模型中起着关键作用，但在检索上下文缺陷或信息不完整的信息时，其效果会受到影响。知识图谱驱动的RAG方法已演化为具有层次结构的形式，将知识组织成多级摘要，但仍然面临两个关键挑战：高层概念性摘要彼此孤立，缺乏用于跨社区推理的显式关系；并且检索过程本身结构无意识，经常导致低效的平面搜索，无法利用图的丰富拓扑结构。", "innovation": "本文引入了LeanRAG，这是一种深度协作的框架，结合了知识聚合和检索策略。LeanRAG首先使用一种新的语义聚合算法，形成实体簇并构建新层次摘要之间的显式关系，形成一个完全可导航的语义网络。然后，一种自底向上的、结构指导的检索策略将查询锚定到最相关的细颗粒实体，并系统地遍历图的语义路径以收集简洁且上下文全面的证据集。LeanRAG减轻了在图上检索路径的大量开销，并减少了冗余信息的检索。", "conclusion": "在四个不同领域的具有挑战性的QA基准测试中进行了广泛的实验，结果表明，LeanRAG在回复质量上显著优于现有方法，同时减少了46%的检索冗余。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18101", "html_url": "https://arxiv.org/abs/2509.18101", "title": "在本地部署大型语言模型的成本效益分析：与商用大型语言模型服务持平", "title_en": "A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services", "authors": "Guanzhong Pan,Vishal Chodnekar,Abinas Roy,Haibo Wang", "background": "随着大型语言模型（LLMs）的普及，组织在使用AI提高生产力时面临选择：订阅商业LLM服务或在自有基础设施上部署模型。商业服务提供商如OpenAI、Anthropic和Google提供易于访问的领先模型，并易于扩展，但数据隐私、切换服务商的难度以及长期运营成本等方面的担忧促进了开源模型本地部署的兴趣。本论文通过成本效益分析框架，帮助组织确定在何种使用水平和性能需求下本地部署LLM成为经济可行的选择。", "innovation": "论文提出了一种成本效益分析框架，以帮助组织确定在本地部署开放源代码大型语言模型与订阅商业服务以哪个更经济。该框架考虑了最新开放源代码模型的硬件要求、运营成本和性能基准，并与主要云提供商的订阅费用进行了对比，从而估算出一个基于使用水平和性能需求的成本持平点。", "conclusion": "研究的结果为组织提供了一个实用的框架，用于规划其LLM策略，并提供了本地部署大型语言模型与订阅商用服务的成本持平点的估计。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03219", "html_url": "https://arxiv.org/abs/2509.03219", "title": "由不确定性驱动的自适应探索", "title_en": "Uncertainty-driven Adaptive Exploration", "authors": "Leonidas Bakopoulos,Georgios Chalkiadakis", "background": "自适应探索方法通过交替进行探索和利用来学习复杂的策略。这对于需要学习长期且复杂的动作序列的领域至关重要。然而，确定何时切换从探索到利用，反之亦然，是这类方法中的一个重要问题。已有研究尚未提供一种在这些领域中有效解决该问题的通用方法。", "innovation": "本文提出了一个基于不确定性的通用自适应探索框架，该框架以原则性的方式解决了切换探索和利用的最佳时机这一重要问题。此外，该框架可以兼容不同的不确定性度量机制，比如内在动机或基于知识不确定性探索方法所使用的机制。实验结果表明，该框架产生的自适应探索策略在多个MuJoCo环境中优于标准策略。", "conclusion": "实验研究表明，本研究提出的基于不确定性的自适应探索框架能够产生性能优于标准策略的自适应探索策略。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "该研究受到丹尼尔·卡尼曼《思考，快与慢》中人类认知的二过程理论启发，旨在通过引入多智能体推理框架来增强机器逻辑推理能力。", "innovation": "PRIME框架通过整合‘系统1’（快速、直观的思考）和‘系统2’（缓慢、审慎的思考），首次提出了一种快速回答生成机制，如果检测到不确定性，则触发专为‘规划’、‘假设生成’、‘检索’、‘信息整合’和‘决策制定’设计的结构性系统2推理流程。这一多智能体设计真实地模拟了人类认知过程，并提升了推理效率和准确性。", "conclusion": "实验结果表明，PRIME能够使开源的大型语言模型在需要多步和基于知识推理的基准测试中与最先进的闭源模型（如GPT-4和GPT-4o）竞争。这项研究为提高需要复杂、知识密集型推理的领域中大型语言模型的能力提供了一种可扩展的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "临床不确定性影响机器学习评估", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集标签通常是不确定的，因为注释员之间存在分歧且信心在不同案例中不均匀。传统的聚合方法如多数投票会掩盖这种变异性。实验证明，在医疗成像基准测试中，考虑二元标签中的置信度显著影响了模型排名。因此，作者认为在机器学习评估中应该显式地使用概率度量来考虑注释不确定性，而不依赖于计算生成过程的方法，无论是简单的计数、主观的信心评级还是概率响应模型，这些概率度量也因为可以独立于模型分数排序后通过闭式表达形式实现而计算量不大。", "innovation": "提出了使用概率度量来显式地考虑注释不确定性，这些概率度量不依赖于注释生成过程，无论使用简单计数、主观信心评级还是概率响应模型。这种方法因其计算轻量级（通过模型评分排序后的线性时间实现）而得到简化。作者提倡社区释放原始注释数据，并采用不确定性感知的评估方法，以使性能估计更好地反映临床数据。", "conclusion": "建议临床数据集发表时应附带原始注释数据，并采用考虑不确定性概率度量的评估方法，这能更好地反映临床数据的实际情况。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00229", "html_url": "https://arxiv.org/abs/2510.00229", "title": "AgentFlux：分段微调与推理以实现本地代理系统的解耦方法", "title_en": "AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems", "authors": "Rohan Kadekodi,Zhan Jin,Keisuke Kamahori,Yile Gu,Sean Khatiri,Noah H. Bayindirli,Sergey Gorbunov,Baris Kasikci", "background": "大型语言模型（LLMs）在任务自动化方面发挥了革命性的作用，但由于隐私保护和成本效益的需求，本地推理能力得到了重视。尽管本地LLMs在性能上逊于前沿模型，尤其是在工具选择和复杂参数结构的论证生成方面。因此，该研究通过将任务分解为工具选择和参数生成两个子任务，并通过一种新型的分段微调方法——LoRA微调来提高模型的性能。", "innovation": "提出了一种分段微调方法，通过LoRA微调创建工具选择和特定工具参数生成专用的Adapters，以及DualTune推理框架。DualTune利用这些LoRA适配器实现高效的本地代理系统推理，通过分段加载策略和分层次编排来减少所需工具的数量，从而提高任务自动化的需求。", "conclusion": "实验结果显示，使用分段微调方法训练的Qwen-2.5-7B模型在工具调用准确性上提升了46%，并且在所有情况下优于其他同类规模的模型，大部分情况下甚至优于更大规模的模型。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01182", "html_url": "https://arxiv.org/abs/2509.01182", "title": "从提问到知识（Q2K）：多代理生成可检验事实的产品映射", "title_en": "Question-to-Knowledge (Q2K): Multi-Agent Generation of Inspectable Facts for Product Mapping", "authors": "Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee", "background": "在电子商务中，识别两个产品列表是否指向同一个库存单元（SKU）是一个持续的挑战，尤其是在缺少明确标识符和产品名称在不同平台之间差异很大的情况下。基于规则的启发式方法和关键词相似性经常由于忽视品牌、规格或捆绑配置中的细微差别而错误分类产品。为了克服这些限制，我们提出了一种称为‘从提问到知识’（Q2K）的多代理框架，该框架利用大型语言模型（LLMs）进行可靠的SKU映射。Q2K集成了：（1）一个推理代理，用于生成针对性的澄清问题；（2）一个知识代理，通过集中式网络搜索解决这些问题；（3）一个去重代理，通过重复利用验证过的推理痕迹来减少冗余并确保一致性。", "innovation": "Q2K采用了多代理框架，融合了大型语言模型，旨在通过生成问题、进行搜索和重复利用推理痕迹来有效地解决SKU映射问题，特别是在处理捆绑产品识别和品牌来源澄清等复杂场景时。通过在循环中包含人类来细化不确定情况，Q2K在实现高效和可解释的产品集成方面取得了显著成果。", "conclusion": "实验结果表明，Q2K在包括捆绑产品识别和品牌来源澄清在内的复杂场景中，超越了强大的基线方法，提高了准确性和鲁棒性。通过重复利用检索到的推理而不是重复搜索，Q2K在保持准确性的同时提高了效率，提供了一个可扩展且可解释的产品集成解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18905", "html_url": "https://arxiv.org/abs/2509.18905", "title": "视觉语言模型(VLMs)与视觉空间智能的差距：基于基准的视角", "title_en": "How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective", "authors": "Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu", "background": "视觉空间推理(VSR)是人类认知能力的核心之一，对于推进嵌入式智能和自主系统具有关键作用。尽管视觉语言模型(VLMs)取得了进展，但在表示和推理三维空间复杂性方面仍面临巨大挑战，使其达到人类水平的VSR仍然非常困难。因此，本文通过全面调查VLMs在VSR方面的方法学、输入模式、模型架构、训练策略以及推理机制，对VSR在VLMs中的应用进行了系统研究。在此基础上，将空间智能分为基本感知、空间理解和空间规划三个能力层次，并构建了SIBench空间智能基准，覆盖了近20个开放源代码数据集的23个任务设置。实验证明，尽管模型在基本感知任务上表现出色，但在理解和规划任务上却普遍表现不佳，特别是在数值估算、多视角推理、时间和空间想象等方面。这些发现凸显了在实现空间智能方面依然存在的巨大挑战，并提供了研究领域的系统路线图和全面基准，以推动未来的相关研究。", "innovation": "研究对VSL的VLMs方法进行了系统梳理，重新定义了空间智能的三个能力层次，并构建了SIBench空间智能基准。覆盖近20个开放源数据集的23种任务设置，揭示了模型在感知与推理之间的差距，特别是理解和规划任务中的表现差异，强调了空间智能实现的挑战，并为未来研究提供了指导。", "conclusion": "视觉语言模型在基本感知任务上表现良好，而在理解和规划任务上仍然困难重重，特别是在数值估算、多视角推理、时间动态和空间想象方面。这些发现凸显了实现空间智能的重大挑战，并提供了研究领域的系统路线图和全面基准，以推动未来研究。SIBench空间智能基准和相关资源已经发布，供进一步研究使用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23045", "html_url": "https://arxiv.org/abs/2510.23045", "title": "AI科学家的综述", "title_en": "A Survey of AI Scientists", "authors": "Guiyao Tie,Pan Zhou,Lichao Sun", "background": "人工智能正在经历从计算工具到自主科学知识创造者的重要转变。这种新兴的范式——AI科学家，旨在完全模仿科学工作流程，从最初的假设生成到最终合成可出版的研究成果，从而有望根本改变发现的速度和规模。然而，这些系统快速且无结构的扩散导致了研究景观的碎片化，模糊了总体方法学原则和发展趋势。", "innovation": "本文引入了一个统一的六阶段方法论框架，将整个科学过程分解为文献回顾、概念生成、实验准备、实验执行、科学写作和论文生成。通过这一分析视角，文章描写了该领域从早期的固有模块（2022-2023年）到集成闭环系统（2024年），再到当前的规模、影响和人机协作前沿的演变。利用严格综合这些发展，本文不仅阐明了自主科学的现状，还为克服剩余的稳健性和治理挑战提供了关键路线图，最终指导下一代系统成为值得信赖且不可或缺的人类科学探索合作伙伴。", "conclusion": "通过对这些发展的严格综合，本文不仅澄清了自主科学的现状，还为克服稳健性和治理方面的剩余挑战提供了关键路线图，最终指导下一代系统成为值得信赖且不可或缺的人类科学探索伙伴。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22340", "html_url": "https://arxiv.org/abs/2510.22340", "title": "DynaSolidGeo: 三维几何中视觉-语言模型真实空间数学推理的动态基准", "title_en": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "authors": "Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen", "background": "解决立体几何问题要求空间数学推理，结合空间智能和符号推理。然而，大多数现有的多模态数学推理基准主要集中在二维平面几何，依赖于容易受到数据污染和记忆影响的静态数据集，并且仅通过最终答案来评估模型，忽视了推理过程。为了解决上述局限性，我们引入了DynaSolidGeo，这是一个动态基准，用于评估视觉-语言模型（VLMs）的真实空间推理能力。这个基准通过半自动注释管道构建，并包含503个专家精选的问题种子，原则上可以动态生成无限数量的多样化的多模态文本-视觉实例。", "innovation": "DynaSolidGeo 是首个专注于评估 VLMs 真实空间推理能力的动态基准。它通过半自动注释管道构建，包含503个专家精选的问题种子，可以动态生成无限数量的多样化的多模态文本-视觉实例。此外，该基准不仅测评最终答案的准确性，还结合由专家注释的推理链条来评估逻辑有效性和因果连贯性，以便更全面地评估模型。实验结果显示，现有的开源和闭源 VLMs 在该基准上的表现存在显著差异，特别是在动态场景下性能严重下降，对于需要高层次空间智能的任务，如心理旋转和可视化，性能尤为不佳。", "conclusion": "DynaSolidGeo 的代码和数据集可在 [DynaSolidGeo] 获取，该基准的引入填补了现有基准在评估 VLMs 真实空间推理能力方面的空白，为该领域未来的进一步研究提供了强有力的支持。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26550", "html_url": "https://arxiv.org/abs/2510.26550", "title": "EdgeRunner 20B：在边缘运行下与GPT-5军事任务并驾齐驱", "title_en": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "authors": "Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman", "background": "本文介绍了EdgeRunner 20B，这是gpt-oss-20b的精调版本，专门针对军事任务进行优化。EdgeRunner 20B是在160万份高质量的军事文档和网站记录中训练的。该论文还介绍了四个新的测试集：战斗兵种、战斗救护、网络作战和mil-bench-5k（军事通用知识）。", "innovation": "EdgeRunner 20B在军事任务测试集中的表现与GPT-5相当或优于GPT-5，统计显著性达到95%以上。相对于gpt-oss-20b，在通用任务基准上的表现没有显著下降，仅在某些低推理场景中略有不如。此外，还进行了超参数设置、成本和吞吐量的分析。这些发现表明，部署在军事领域的数据敏感操作中，小型的本地模型是最好的解决方案。", "conclusion": "研究表明，小型且本地部署的模型特别适合军事等数据敏感的操作环境，能够在离线设备中部署运行。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26418", "html_url": "https://arxiv.org/abs/2510.26418", "title": "链式思维劫持", "title_en": "Chain-of-Thought Hijacking", "authors": "Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez", "background": "大型推理模型（LRMs）在推理期间增加计算量可以提高任务表现，且先前工作表明这种扩展的推理也有助于提高安全性，因为它能够提高拒绝恶意请求的能力。然而，该研究发现，同样的推理过程也可能被利用来规避安全措施。这引发了对大型推理模型安全性的新思考和挑战，尤其是其在遭受攻击时的行为机制。", "innovation": "研究引入了链式思维劫持（CoT Hijacking），这是一种针对推理模型的攻击方法。勒索软件通过增加无害的逻辑推理序列来包装有害请求，通过在此基准测试（HarmBench）上测试各模型，研究展示了该攻击方法的显著效果，攻击成功率高达99%、94%、100%和94%，超过了以往针对LRMs的攻击方法。研究还对攻击效果进行了机制分析，揭示了中间层和后期层在安全检查和验证结果中的编码方式，表明长时间的良性链式思维可以分散注意力，从而削弱有害标记的重要性，导致安全机制失效。", "conclusion": "研究结果表明，最可解释的推理形式——显式链式思维，当与最终答案暗示相结合时，同样可以成为一种劫持向量。研究成果提供了对于有效理解LRMs安全性的新见解，并为防止此类攻击提供了方法论基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.27176", "html_url": "https://arxiv.org/abs/2510.27176", "title": "Glia: 一种以人类为灵感的自动化系统设计与优化的人工智能", "title_en": "Glia: A Human-Inspired AI for Automated Systems Design and Optimization", "authors": "Pouya Hamadanian,Pantea Karimi,Arash Nasr-Esfahany,Kimia Noorbakhsh,Joseph Chandler,Ali ParandehGheibi,Mohammad Alizadeh,Hari Balakrishnan", "background": "文章探讨了人工智能是否能够自主设计出与人类专家相媲美的计算机系统机制。介绍了Glia这一AI架构，该架构用于网络系统设计，利用大型语言模型（LLMs）以人类启发式的方式进行多智能体工作流合作。每个智能体专门负责推理、实验和分析，通过评价框架将抽象推理与实证反馈相结合。不同于以往用于系统优化的ML方法主要优化不可解释的策略，Glia能够生成可解释的设计并暴露其推理过程。Glia被应用于分布式GPU集群以进行LLM推理，并生成新的算法，用于请求路由、调度和自动扩展，其性能与人类专家相当且运行速度快得多，同时揭示了工作负载行为的新颖见解。", "innovation": "Glia通过结合推理型LLMs和结构化实验，能够为解决复杂系统问题生成具有创造力且可理解的设计。它能够生成可解释的设计，并展示其推理过程，相比传统的ML方法，能够更快地生成与人类专家水平相当的系统设计，同时提供对工作负载行为的新颖见解。", "conclusion": "研究结果表明，通过结合推理型LLMs和结构化实验，AI能够为复杂系统产生有创意且可理解的设计。Glia能够在显著减少时间的情况下产生与人类专家相当的系统设计，同时提供对工作负载行为的洞见。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06065", "html_url": "https://arxiv.org/abs/2511.06065", "title": "ScRPO：从错误中获得洞察", "title_en": "ScRPO: From Errors to Insights", "authors": "Lianrui Li,Dakuan Lu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "该研究背景涉及在解决复杂数学问题时，增强型语言模型需要一个更高效的方法来改进。传统的方法往往依赖于外部反馈，而较少考虑模型自身的内在纠错机制。这项研究的目标是开发一种新的强化学习框架，旨在通过利用自我反思和误差修正来提升大型语言模型在挑战性数学问题上的表现。", "innovation": "该研究的创新之处在于提出了一种称为Self-correction Relative Policy Optimization (ScRPO)的新方法。ScRPO框架包含两个阶段：（1）尝试学习阶段：使用增强相对策略优化（GRPO）训练模型，并收集错误答案及其对应的问题，存入错误池；（2）自我修正学习阶段：引导模型反思其前次答案错误的原因。该方法通过模型自身的内部学习机制，减少了对外部反馈的依赖，提高了模型在困难任务上的表现。", "conclusion": "实验结果表明，ScRPO框架能够比几种后训练方法更有效地提升模型在多个数学推理基准上的性能，特别是AIME、AMC、奥数、MATH-500、GSM8k。这表明ScRPO是一个有前景的方法，能够促使语言模型在有限的外部反馈下自我提升，为更可靠和强大的AI系统铺平道路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06209", "html_url": "https://arxiv.org/abs/2511.06209", "title": "通过不确定性头部进行高效验证：LLM推理步骤的信心推理", "title_en": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads", "authors": "Jingwei Ni,Ekaterina Fadeeva,Tianyi Wu,Mubashara Akhtar,Jiaheng Zhang,Elliott Ash,Markus Leippold,Timothy Baldwin,See-Kiong Ng,Artem Shelmanov,Mrinmaya Sachan", "background": "解决复杂任务通常需要大规模语言模型（LLMs）生成长且多步骤的推理链。已有研究表明，验证单个推理步骤的正确性能够进一步提高LLMs在这些任务上的性能和效率，并增强解决方案的可解释性。然而，现有的验证方法如过程奖励模型（PRMs）存在计算成本高、局限于特定领域或需要大规模的人工或模型生成注解的问题。", "innovation": "本文提出了一种基于数据驱动不确定性评分的轻量级替代方法，用于步骤级别的推理验证。该方法通过训练一种基于变换器的不确定性量化头部（UHeads），使用冻结的LLM的内部状态来估计其推理步骤的不确定性。目标标签可以通过另一个较大的LLM或由原始模型自身以自监督方式生成。UHeads高效且轻量，参数量不到10M，覆盖多个领域如数学、规划和一般知识问答，其性能与PRMs相当甚至更好，且PRMs的规模可达其810倍。", "conclusion": "研究发现，LLMs的内部状态编码了它们的不确定性，可以作为可靠的信号用于推理验证，提示了具有可扩展性和通用性的反思性LLMs的一个有希望的研究方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02109", "html_url": "https://arxiv.org/abs/2511.02109", "title": "深度价值基准：测量模型是否泛化深层价值观或浅层偏好", "title_en": "Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences", "authors": "Joshua Ashkinaze,Hua Shen,Sai Avula,Eric Gilbert,Ceren Budak", "background": "本文提出了Deep Value Benchmark (DVB)，这是一个评估框架，用于直接测试大语言模型（LLMs）是否学习了根本的人类价值观或仅仅表面的偏好。这一区别对于AI对齐至关重要：捕捉更深价值观的系统更可能稳健地泛化人类意图，而只捕捉偏好数据中表面模式的系统则可能产生对齐不良的行为。DVB 使用了一种新的实验设计，通过控制深层价值观（例如道德原则）与浅层特征（例如表面属性）之间的混淆，来区分这两种情况。在模型训练阶段，LLMs 被暴露在故意关联深层和浅层特征的人类偏好数据中。在测试阶段，这些关联被打破，反向展示了这两种选项之间的选择，从而精确地测量模型的深度价值泛化率（DVGR）-- 基于底层价值而不是浅层特征泛化的概率。对9个不同模型的研究表明，平均DVGR仅为0.30，所有模型在深层价值观上的泛化率都不及随机猜测。更大的模型在深层价值观上的泛化率比较小模型略低。作者还发布了经过三次独立的人类验证实验验证的数据集，DVB 提供了一种可解释的对齐核心特性度量方式。", "innovation": "提出了Deep Value Benchmark (DVB) 框架，用于直接测试大语言模型是否学习了根本的人类价值观。通过控制试验中的深层价值观与浅层特征之间的混淆，设计了一个新的实验来评估模型的深度价值泛化率（DVGR），在建模学习过程的深层价值观和浅层偏好之间进行区分，并提供了可解释的对齐核心特性度量方式。", "conclusion": "在9个不同模型中，平均DVGR仅为0.30，所有模型在深层价值观上泛化的能力都不如随机猜测。即使对于更大的模型，其在深层价值观上的泛化率也低于较小的模型。发布的DVB数据集经受了三次独立的人类验证实验，DVB提供了一种对核心对齐特征的精确评估方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06136", "html_url": "https://arxiv.org/abs/2511.06136", "title": "当基于对象的世界模型遇到策略学习：从像素到策略，以及哪里会失败", "title_en": "When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks", "authors": "Stefano Ferraro,Akihiro Nakano,Masahiro Suzuki,Yutaka Matsuo", "background": "基于对象的世界模型（OCWM）旨在将视觉场景分解为对象级表示，提供结构化抽象，以改善强化学习中的组合泛化和数据效率。文章假设明确分离的对象级表示，通过局部化任务相关信息，能增强在新特征组合上的策略性能。为了验证这一假设，作者引入了DLPWM，这是一种完全无监督且分离的对象级世界模型，能够直接从像素中学习对象级潜在变量。尽管DLPWM在重构和预测性能上表现出色，包括对多种离分布（OOD）视觉变化的鲁棒性，但在下游的基于模型的控制任务中，基于DLPWM潜在变量训练的策略的表现不及DreamerV3。", "innovation": "作者提出了一种完全无监督且分离的对象级世界模型DLPWM，它直接从像素中学习对象级潜在变量。这种模型在重构和预测性能上表现出色，并能对多种离分布视觉变化保持鲁棒性。然而，对比DreamerV3，基于DLPWM潜在变量训练的策略在下游基于模型的控制任务中表现较差，这表明虽然基于对象的感知支持稳健的视觉建模，但实现稳定的控制需要减轻潜在变量的漂移。", "conclusion": "尽管基于对象的感知模型支持稳健的视觉建模，但在实现稳定的控制方面，仍需要缓解潜在变量的漂移。基于对象的世界模型在策略学习过程中遇到了关键挑战，特别是在多对象交互过程中，潜在表示的变化导致了不稳定的学习。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07104", "html_url": "https://arxiv.org/abs/2511.07104", "title": "检测大型模型生成的时间序列的理论分析", "title_en": "A Theoretical Analysis of Detecting Large Model-Generated Time Series", "authors": "Junji Hou,Junzhou Zhao,Shuo Zhang,Pinghui Wang", "background": "随着数据滥用和伪造的风险不断增加，本文探讨了使用时间序列大型模型（TSLMs）生成的合成时间序列的识别问题。现有的文本生成检测方法因为时间序列与文本在信息密度和概率分布上的根本性差异而不适用于时间序列数据。因此，需要开发新的方法来有效识别这些合成时间序列。", "innovation": "本文提出了收缩假设，指出模型生成的时间序列在递归预测中表现出逐渐减小的不确定性，而真实时间序列则不会。基于此理论假设，作者提出了不确定性收缩估计器（UCE），一种白盒检测器，通过逐步汇集不确定性指标来识别TSLM生成的时间序列。实验结果显示，UCE在多个数据集上的表现优于现有基线算法。", "conclusion": "本文提出的方法UCE能够有效地检测大型模型生成的时间序列，提供了一种可靠且通用的解决方案。该方法在理论上得到了验证，并通过大量实验得到了实证支持。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06626", "html_url": "https://arxiv.org/abs/2511.06626", "title": "倾诉真相：教导大模型报告其隐藏目标", "title_en": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives", "authors": "Chloe Li,Mary Phuong,Daniel Tan", "background": "随着人工智能系统变得更加能够执行复杂的独立任务，它们也变得更加可能追求不受欢迎的目标并导致危害。之前的工作试图通过直接询问这些模型的目标和行为来识别这些不安全的实例，然而，信任直接调查的主要弱点是模型可能会撒谎。这项研究提出了一种名为自我报告微调（Self-Report Fine-Tuning，SRFT）的技术，这是一种简单的监督微调方法，训练模型在被问及时承认其实质性的错误。", "innovation": "该研究提出了一种名为自我报告微调（SRFT）的方法，这是一种简单的监督微调技术，旨在训练模型在被问及时承认其实质性的错误。研究表明，实况错误的承认不仅在简单的问答设置中泛化到对抗性的代理场景中隐藏对齐偏差的承认，还在不被监控的情况下，模型更有可能承认隐藏的目标细节。与基线模型相比，SRFT模型在调查中表现出色，可以检测隐藏的目标，并进一步提取隐藏目标的内容。", "conclusion": "调查SRFT模型可以接近天花板的性能（F1分数=0.98）检测隐藏的目标，而基线模型在相同条件下会撒谎（F1分数=0）。与基线模型和其他预填充助手攻击相比，SRFT模型进一步提取隐藏目标的内容的比例为28%至100%，这为促进诚实倾向和质疑对齐不良的AI系统提供了一个有前景的技术。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07110", "html_url": "https://arxiv.org/abs/2511.07110", "title": "二个头比一个头好：通过特征分解和混合将大型语言模型特征注入小型模型", "title_en": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture", "authors": "Tianhao Fu,Xinxin Xu,Weichen Xu,Jue Chen,Ruilong Ren,Bowen Deng,Xinyu Zhao,Jian Cao,Xixin Cao", "background": "市场中介（MM）通过强化学习（RL）在金融交易中的应用受到了广泛关注。随着大型语言模型（LLMs）的发展，人们越来越多地尝试将LLMs应用于金融领域。简单直接地将LLM作为代理进行应用已经显现出显著的效果，但这类方法的推理速度较慢，且目前大多数研究尚未探讨LLM在特定任务上的知识蒸馏方法。", "innovation": "本文首先提出了一种归一化荧光探针来研究LLM特征的机制。基于我们的调查发现，本文提出了一个名为协作市场中介（CMM）的新框架，该框架通过在三个正交维度（层、任务和数据）上解耦LLM特征，使多个学生模型协作学习复杂的LLM特征。CMM还引入了一个Hájek-MoE方法，通过高斯核函数生成的共同特征空间，整合学生模型的输出，并研究不同模型在该空间中的贡献。", "conclusion": "在四大现实市场的交易数据集上的广泛实验结果表明，CMM方法在知识蒸馏和基于RL的市场中介策略方面均优于当前的方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07090", "html_url": "https://arxiv.org/abs/2511.07090", "title": "绿色AI：其定义、生命周期模型、硬件和测量尝试的系统回顾与元分析", "title_en": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts", "authors": "Marcel Rojahn,Marcus Grum", "background": "人工智能（AI）的全生命周期，从硬件开始到开发、部署、再到重用，都伴随着能源、碳排放、水资源和材料影响等负担。虽然云提供商的工具可以提高透明度，但它们仍然存在异质性问题，并且通常会省略水方面的影响和价值链效应，这限制了比较性和可重现性。文章将需要一种生命周期方法，将各个阶段明确映射与系统杠杆（硬件、位置、能源配比、冷却、调度）相结合，并在设施、系统、设备和工作负载层面进行校准测量。现有的研究和实践尚缺乏一个统一的、可操作性的“绿色AI”定义，而这也是本文旨在解决的问题之一。", "innovation": "本文提出了一个统一且可操作性的“绿色AI”定义，与“可持续AI”区分开来；建立了与生命周期评估（LCA）阶段对应的五阶段生命周期模型，考虑到能源、碳排放、水和材料负担；通过PDCA（计划、做、检查、行动）循环和决策端口来规范治理；系统化了边缘到云计算连续体中的硬件和系统层面策略，以减少嵌入式负担；定义了一个结合估计模型与直接计量的校准测量框架，以实现可重现的、平台无关的比较。", "conclusion": "本文通过定义、生命周期过程、硬件策略和校准测量，为研究人员、从业人员和政策制定者提供了基于证据的可操作指南，以解决人工智能全生命周期中的环境负担问题。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07338", "html_url": "https://arxiv.org/abs/2511.07338", "title": "DeepPersona: 用于生成深度合成人格的生成引擎", "title_en": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas", "authors": "Zhen Wang,Yufan Zhou,Zhongyan Luo,Lyumanshan Ye,Adam Wood,Man Yao,Luoshang Pan", "background": "利用大型语言模型（LLMs）注入人格以模拟人类行为正在迅速改变行为模拟、LLM个性化以及人机对齐的研究。然而，现有的大多数合成人格仍然较为浅薄，未能捕捉到人类身份的丰富复杂性和多样性。因此，研究迫切需要一种能够生成深入且复杂的合成人格的方法。", "innovation": "提出了一种名为DEEPPERSONA的生成引擎，通过一个两级、分类指导的方法，生成叙事完整的合成人格。首先，算法性地构建了迄今为止最大的人类属性分类，包含数百个有层次组织的属性。其次，根据此分类逐步抽取属性，有条件地生成符合逻辑、现实的人格，这包含数百个结构化属性和大约1MB的叙述性文本，比先前工作深入度提高了两个数量级。内部评估证实，与最先进的基线相比，DEEPPERSONA在属性多样性和档案独特性方面有了显著改进，且外部效果上，提升GPT-4.1-mini的个性化问答准确率可达11.6%。", "conclusion": "DEEPPERSONA 提供了一个严谨的、可扩展的且无需隐私的平台，用于高保真人类模拟和个性化AI研究，显著降低了模拟的LLM公民与真实人类在多项调查中的性能差距。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2304.11954", "html_url": "https://arxiv.org/abs/2304.11954", "title": "Spikingformer: 用于脉冲神经网络的关键基础模型", "title_en": "Spikingformer: A Key Foundation Model for Spiking Neural Networks", "authors": "Chenlin Zhou,Liutao Yu,Zhaokun Zhou,Han Zhang,Jiaqi Wang,Zhengyu Ma,Huihui Zhou,Yonghong Tian", "background": "脉冲神经网络（SNNs）因其事件驱动的脉冲计算提供了能效更高的替代方案，而受到了广泛关注。然而，某些SNN的基础结构（包括Spikformer和SEW ResNet）在残差连接的结构中引入了非脉冲计算（整数-浮点乘法），这增加了SNN的能耗，使其不适合在主流神经形态硬件上部署。因此，本文分析了SNN中残差连接的脉冲驱动行为，并提出了一个名为Spikingformer的新型脉冲变压器骨干网络，通过将MS Residual连接与Self-Attention结合，解决了Spikformer中的非脉冲计算问题，同时保留了全局建模能力", "innovation": "本文提出了一种名为Spikingformer的新型脉冲变压器骨干网络，通过将MS Residual连接与Self-Attention结合，解决了Spikformer中的非脉冲计算问题，同时保留了全局建模能力。Spikingformer在13个数据集上进行了评估，包括大规模静态图像、神经形态数据和自然语言任务，展示了其有效性和通用性，为脉冲神经网络设定了一个重要的基准。此外，Spikingformer集成了脉冲驱动特性和全局建模能力，预计将作为更高效的通用SNN骨干网络，推动能源高效的AI发展", "conclusion": "通过分析SNN中残差连接的脉冲驱动行为，本文提出了Spikingformer，不仅解决了非脉冲计算问题，还保留了全局建模能力。评估结果显示Spikingformer在多种数据集上表现出色，为SNN设定了新基准，促进了能源高效的人工智能发展"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.21243", "html_url": "https://arxiv.org/abs/2407.21243", "title": "离散扩散模型中的信息校正器", "title_en": "Informed Correctors for Discrete Diffusion Models", "authors": "Yixiu Zhao,Jiaxin Shi,Feng Chen,Shaul Druckmann,Lester Mackey,Scott Linderman", "background": "离散扩散已成为离散领域生成建模的强大框架，但高效采样却颇具挑战性。现有采样策略在减少采样步数时难以平衡计算成本和样本质量，即便模型已经很好地学习了数据分布。", "innovation": "提出了一种预测-校正采样方案，其中校正步骤由扩散模型指导，以更可靠地抵消累积的近似误差。基于空洞变压器的架构改进和一种简单定制的训练目标被引入，这有助于提高校正器的有效性，利用更多的训练信号。通过合成示例展示了现有采样器的失败模式，并说明了信息校正器如何缓解这些问题。", "conclusion": "在text8和标记化ImageNet 256x256数据集上，信息校正器始终能够产生较少错误或改进FID得分的高质量样本，证实了信息校正器在使用离散扩散实现快速高保真生成的潜力。代码可在以下链接获取：this https URL."}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.18770", "html_url": "https://arxiv.org/abs/2405.18770", "title": "利用一對多關係實現視覺語言模型的多模態对抗防御", "title_en": "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships", "authors": "Futa Waseda,Antonio Tejero-de-Pablos,Isao Echizen", "background": "预训练的视觉-语言（VL）模型极易受到对抗攻击的影响。现有防御方法主要集中在图像分类任务上，忽视了VL任务的两个关键方面：多模态攻击，其中图像和文本都可以受到干扰；以及图像和文本之间的一对多关系，即一个图像可以对应多个文本描述，反之亦然。本工作首次探讨了针对多模态攻击的防御策略，而之前的VL防御方法则集中在视觉稳健性上。研究还发现，现有的对抗防御方法在处理VL训练数据中已知的一对一（1:1）图像-文本对时存在局限性。因此，本文在这一背景下展开研究，旨在增强模型的鲁棒性。", "innovation": "本文提出了一种名为多模态对抗训练（MAT）的方法，在训练过程中同时对图像和文本模态进行对抗干扰。MAT方法显著优于现有的单模态防御方法。此外，研究发现MAT在处理VL训练数据中已知的一对一（1:1）图像-文本对时存在局限性。本文进一步探讨了利用一对多关系来增强模型鲁棒性的方法，研究了多种数据增强技术。结果表明，为了更有效的防御，增强后的图像-文本对应具备良好的对齐、多样性，同时避免分布偏移，这一条件前人研究多未关注。", "conclusion": "本文开辟了针对多模态攻击的防御策略，从优化和数据两个角度提供了构建稳健VL模型的见解。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.17063", "html_url": "https://arxiv.org/abs/2409.17063", "title": "在计算病理学中基准测试领域泛化算法", "title_en": "Benchmarking Domain Generalization Algorithms in Computational Pathology", "authors": "Neda Zamanitajeddin,Mostafa Jahanifar,Kesi Xu,Fouzia Siraj,Nasir Rajpoot", "background": "深学习模型在计算病理学任务中展现出了巨大的潜力，但在应用于未见过的数据时，由于领域转换（domain shift）受影响的表现不佳。解决这一问题需要领域泛化（domain generalization，DG）算法，但是目前在计算病理学领域的系统性评估尚未进行。", "innovation": "该研究的目标是在7560次交叉验证的运行中，对30种DG算法在3个不同难度的计算病理学任务上的效果进行了基准测试。使用统一且 robust 的平台，结合模态特定技术和预训练基础模型，揭示了各种DG策略的相对表现。发现自我监督学习和标记增强始终优于其他方法，强调预训练模型和数据增强的潜力。此外，引入了一个新的跨癌种肿瘤检测数据集（HISTOPANTUM），作为未来研究的基准。", "conclusion": "本研究为研究人员在计算病理学任务中选择适当的DG方法提供了宝贵的指导。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.09235", "html_url": "https://arxiv.org/abs/2408.09235", "title": "参考引导裁定：作为裁判的大语言模型在自动评估自由形式问答中的应用", "title_en": "Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form QA", "authors": "Sher Badshah,Hassan Sajjad", "background": "随着大型语言模型（LLMs）作为聊天助手的能力增强，它们能够生成类似人类的对话，对有效的评估方法需求增加，尤其是对于开放性任务。现有的评估指标，比如EM和F1，虽然有用，但不足以捕捉生成性输出的完整语义和上下文深度。因此，迫切需要更有效的评估方法来提高评估的准确性和可靠性，特别是在单个模型可能表现不佳的任务中。本研究旨在提出一种多模型引导的评估方法，通过使用多个LLMs进行评估，以替代传统的、可能不够全面的评估指标。", "innovation": "提出了一种名为参考引导裁定的方法，该方法通过利用多个LLMs作为评估者来自动化评估过程。通过在自由形式的问答任务上进行实验，证明了组合多个模型可以提高评估的可靠性和准确性，尤其是在单个模型可能难以应对的任务中。这种方法与人类评估结果之间存在较强的相关性，表明这是一种可靠的替代传统指标的方法。", "conclusion": "研究结果显示，结合多个大语言模型的评估方法在自由形式问答任务中与人类评估结果具有很强的关联性，证明了该方法作为一种可靠替代传统评价指标的有效性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.03463", "html_url": "https://arxiv.org/abs/2408.03463", "title": "在观察性时间事件数据中识别治疗反应亚组", "title_en": "Identifying treatment response subgroups in observational time-to-event data", "authors": "Vincent Jeanselme,Chang Ho Yoon,Fabian Falck,Brian Tom,Jessica Barrett", "background": "识别具有不同治疗反应的患者亚组是制定医学建议、指南以及设计未来临床试验的重要任务。现有治疗方法效果估计主要依赖于随机对照试验（RCTs），但RCTs通常包含更同质的患者群体，这使得它们在揭示现实临床实践中遇到的群体亚组方面不太相关。针对RCTs的亚组分析在应用于观察性研究时会受到显著的统计偏差影响，而观察性研究则从更大的、更具代表性的群体中受益。现有的亚组分析方法主要针对RCTs，但当应用于观察性研究时会产生统计偏差，因此需要一种新的方法来更好地识别具有不同治疗反应的患者亚组，以获得有用的临床见解，从而影响治疗指南。", "innovation": "本文提出了一种新型的基于结果导向的亚组分析策略，旨在识别RCTs和观察性研究中的治疗反应亚组。这种方法介于个人化治疗效果估计和平均治疗效果估计之间，能够揭示具有不同治疗反应的患者亚组，对于形成可操作的洞察力至关重要。实验结果表明，该方法在随机试验和观察性治疗方案中均显著优于当前最先进的亚组分析方法。", "conclusion": "本文提出的方法在RCTs和观察性研究中都表现出色，能够准确识别具有不同治疗反应的患者亚组，为制定治疗指南提供了科学依据，具备重要临床价值。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.14567", "html_url": "https://arxiv.org/abs/2407.14567", "title": "将人工智能集成到操作系统中：技术、应用与未来方向综述", "title_en": "Integrating Artificial Intelligence into Operating Systems: A Survey on Techniques, Applications, and Future Directions", "authors": "Yifan Zhang,Xinkui Zhao,Ziying Li,Guanjie Cheng,Jianwei Yin,Lufei Zhang,Zuoning Chen", "background": "异构硬件和动态工作负载加剧了操作系统在可扩展性、适应性和管理性方面的长期瓶颈。同时，机器学习、大型语言模型和基于代理的方法的进步使自动化和自我优化成为可能，但当前的努力缺乏统一的视角。本文综述了AI和操作系统的交叉点上的技术、架构、应用、挑战和未来方向。文章概述了从基于规则的设计过渡到AI增强系统的过程，并总结了AI在操作系统堆栈中各层的优势，同时也指出了AI在操作系统核心组件和生态系统的进展。此外，文章整理了实践中的评估维度、方法学管道和模式，以平衡实时约束和预测准确性。文章还指出了关键挑战，包括复杂性、开销、模型漂移、解释性限制以及隐私和安全风险，并提出了模块化的AI就绪内核接口、统一的工具链和基准、具有护栏的混合规则+AI决策和内核中可验证推理等建议。最后，文章提出了一个三层路线图，包括基于AI的、重整为AI的和由AI驱动的操作系统，以连接原型设计和生产，并实现可扩展且可靠的AI部署。", "innovation": "建立了AI和操作系统的跨界联系，从基于规则的设计向AI增强系统转变，总结了AI在操作系统堆栈中的应用，并提出了AI就绪的内核接口、统一的工具链和基准等建议，以及一个从原型到生产的三层路线图。", "conclusion": "本文通过三个阶段的路线图，旨在连接原型和生产，实现可扩展且可靠的AI部署，同时提出了许多与AI集成到操作系统中的关键挑战和建议。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.04715", "html_url": "https://arxiv.org/abs/2410.04715", "title": "基于正交规则选择LLM微调数据", "title_en": "Selection of LLM Fine-Tuning Data based on Orthogonal Rules", "authors": "Xiaomin Li,Mingye Gao,Zhiwei Zhang,Chang Yue,Hong Hu", "background": "高质量的训练数据对大型语言模型（LLMs）的性能至关重要。近年来的研究致力于利用LLMs对数据进行评级和选择，基于一小部分由人类设计的规则，但这些方法往往依赖于启发式方法，缺乏规则评估的理论指标，并且在新任务上的泛化能力较差。", "innovation": "本文提出了一个基于规则的选择框架，引入了基于规则评分向量正交性度量的方法来评估和选择互补规则。框架包括自动化的两阶段流程：首先使用LLMs生成能够覆盖数据质量多个方面的规则；其次按照这些规则对数据样本进行评分，并使用定项点过程（DPP）选择最大程度独立的规则进行数据的选择。这些规则用于对整个数据集评分，选择高分样本进行接下来的微调等下游任务。", "conclusion": "实验结果表明，基于DPP的选择策略在IMDB、医疗、数学和代码领域均能持续提高评分准确性以及下游模型性能，优于强大的基线方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.11234", "html_url": "https://arxiv.org/abs/2410.11234", "title": "Bayes自适应Monte Carlo树搜索在离线模型化强化学习中的应用", "title_en": "Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning", "authors": "Jiayu Chen,Le Xu,Wentse Chen,Jeff Schneider", "background": "离线强化学习（Offline RL）是一种强大的数据驱动决策和控制方法。与无需模型的方法相比，离线模型化强化学习（MBRL）方法能够从静态数据集中显式地学习世界模型，并使用它们作为代理模拟器，从而提高数据效率，使学到的策略能够在数据集范围以外进行泛化。然而，存在多种可能在离线下数据集上表现相同的MDP（马尔可夫决策过程），这给应对模型不确定性带来了挑战。", "innovation": "本文将离线下MBRL模型化为Bayes自适应马尔可夫决策过程（BAMDP），这是一种应对模型不确定性的原则性框架。提出了一种新颖的Bayes自适应Monte Carlo规划算法，可以在连续的状态和动作空间中解决具有随机转换的BAMDP，并基于Monte Carlo树搜索。该规划过程可以被集成到离线下MBRL中作为策略迭代的策略改进操作。算法在D4RL MuJoCo任务和挑战性的等离子体控制仿真模块中的三个目标跟踪任务上显著超过了现有的离线RL方法。", "conclusion": "本文提出的方法在多种任务上显著改善现有的离线下MBRL方法，通过提供更多的计算输入，使“RL + Search”框架类似于AlphaZero等超级人类AI。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02181", "html_url": "https://arxiv.org/abs/2412.02181", "title": "将Weisfeiler-Lehman内核推广到子图", "title_en": "Generalizing Weisfeiler-Lehman Kernels to Subgraphs", "authors": "Dongkwan Kim,Alice Oh", "background": "子图表示学习在解决各种实际问题中非常有效。然而，当前的图神经网络（GNNs）在子图级别的任务上表现不佳，因为它们无法捕捉子图内部和之间的复杂交互。", "innovation": "提出了一种名为WLKS（Weisfeiler-Lehman Kernel Generalized）的方法，通过将Weisfeiler-Lehman算法应用于诱导的k-跳邻域来扩展Weisfeiler-Lehman内核。该方法通过结合不同k-跳层次的内核来捕获更丰富的结构性信息，克服了现有模型的部分缺陷，并且可以通过消除邻域采样的需要来平衡表达能力和效率。", "conclusion": "在八个真实和合成的基准测试上，WLKS在五个数据集上显著优于领先的方法，并且降低了训练时间，与最先进的技术相比，范围从0.01倍到0.25倍。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00191", "html_url": "https://arxiv.org/abs/2503.00191", "title": "学习具有半概率安全保证的基于视觉的神经网络控制器", "title_en": "Learning Vision-Based Neural Network Controllers with Semi-Probabilistic Safety Guarantees", "authors": "Xinhang Ma,Junlin Wu,Hussein Sibai,Yiannis Kantaros,Yevgeniy Vorobeychik", "background": "基于视觉的自主系统安全性保证仍然是一个关键挑战，因为图像输入的高维度以及真实系统状态与其视觉表现之间的关系未知。现有的基于学习的控制方法通常缺乏正式的安全保证。", "innovation": "提出了一种新颖的半概率验证框架，该框架结合了可达性分析与条件生成网络以及无分布边界条件，实现了基于视觉的神经网络控制器的有效且可扩展的验证。开发了基于梯度的训练方法，使用了新颖的安全损失函数、安全意识的数据采样策略以及逐步学习，以在半概率框架中高效合成安全控制器。", "conclusion": "在X-Plane 11飞机着陆模拟、CARLA模拟自主车道跟随、F1Tenth车辆在物理丰富视觉环境下车道跟随以及Airsim模拟的无人机导航和障碍物规避方面的实验评估表明，该方法在获得正式安全保证的同时保持了强本体性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.01849", "html_url": "https://arxiv.org/abs/2501.01849", "title": "一种用于在线评估和选择用户对齐的大语言模型响应的多智能体对话臂方法", "title_en": "A Multi-Agent Conversational Bandit Approach to Online Evaluation and Selection of User-Aligned LLM Responses", "authors": "Xiangxiang Dai,Yuejin Xie,Maoli Liu,Xuchuang Wang,Zhuohua Li,Huanyu Wang,John C.S. Lui", "background": "目前常用的基于提示的离线方法用于优化大语言模型的响应，但评价这些响应非常耗费计算资源，并且通常无法涵盖各种响应风格。因此，论文提出了一种新的在线评估框架，该框架利用多智能体对话臂模型动态调整与用户偏好一致的选择策略，以应对高维特征、大量响应集、自适应对话需求和多设备访问等挑战。", "innovation": "提出了一种名为MACO（Multi-Agent Conversational Online Learning）的框架，包含两部分：(1) MACO-A：由局部代理执行，采用在线淘汰机制筛选出低质量的响应；(2) MACO-S：由云服务器执行，根据聚合的偏好数据逐步调整选择策略。此外，论文还提出了一种自适应偏好机制，以提升对话的对齐效率。理论分析表明，MACO 在各种退化情况下的表现接近最优，且实验表明在删除组和代理数量变化的情况下，MACO 性能持续优于基线方法，至少提高了 8.29%。", "conclusion": "实验结果表明，MACO 在不同响应集大小和代理数量条件下均能有效提升对话响应的用户一致性，展现出良好的性能和稳定性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05672", "html_url": "https://arxiv.org/abs/2502.05672", "title": "Upside-Down强化学习、目标条件监督学习和在线决策转换器的收敛性和稳定性", "title_en": "On the Convergence and Stability of Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning, and Online Decision Transformers", "authors": "Miroslav Štrupl,Oleg Szehr,Francesco Faccio,Dylan R. Ashley,Rupesh Kumar Srivastava,Jürgen Schmidhuber", "background": "本文对强化学习中的 episodic upside-down 方法、目标导向监督学习和在线决策转换器等算法进行了严谨分析，这些算法在游戏和机器人任务中表现出色，但在理论上对其理解和研究主要局限于特定环境条件下。本文旨在为监督学习或序列建模方法下的强化学习算法建立理论基础，特别关注算法在环境变化时能否稳定识别最优解，并证明在轻微环境噪声的情况下，这些算法仍然能够呈现出最优行为。", "innovation": "本文引入了一系列新的理论概念，如在区段空间中工作、研究商空间中的连续性，以及动态系统的不动点理论的应用。重要创新之处在于提供了一种方法来量化基态转移核对策略和价值收敛和稳定性的影响，并首次给出了这些算法在基于转移核方面的收敛和稳定性估计方法。", "conclusion": "通过详细的环境实例分析和数值实验，我们展示了使用转移核模型时，如何根据转移核的位置实现近似最优行为，并通过探讨理论和实践结合的方法，增强了对这些新兴学习方法的理解。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18212", "html_url": "https://arxiv.org/abs/2411.18212", "title": "SCoTT: 基于数字孪生的策略性思维链任务规划方法用于无线感知机器人导航", "title_en": "SCoTT: Strategic Chain-of-Thought Tasking for Wireless-Aware Robot Navigation in Digital Twins", "authors": "Aladin Djuhera,Amin Seffo,Vlad C. Andrei,Holger Boche,Walid Saad", "background": "无线性能约束下的路径规划是机器人导航中的一个复杂挑战。但是，在经典规划算法中直接加入这些约束通常会导致搜索成本增加。在本研究中，通过利用视觉-语言模型（VLMs）和数字孪生（DT）的无线热图图像及光线追踪数据来共同优化路径增益和轨迹长度，提出了一种名为SCoTT的无线感知路径规划框架。对经典A*算法及其无线感知扩展进行了基准比较，并提出了性能成本高昂但计算效率高的迭代动态规划算法DP-WA*。通过大量实验验证，采用SCoTT方法可实现接近DP-WA*的路径增益同时产生更短的轨迹长度。同时，SCoTT的中间输出还可以加速DP-WA*的执行，节省高达62%的运行时间。", "innovation": "提出的SCoTT框架通过利用视觉-语言模型（VLMs）和数字孪生（DT）的无线热图图像及光线追踪数据来共同优化路径增益和轨迹长度。核心在于一种新型的思维链推理框架SCoTT，它将搜索问题分解为结构化的子任务，每一步都通过思维链推理解决。此外，scott框架可以加速DP-WA*的执行，节省大量运行时间，且适用于各种规模的视觉语言模型。", "conclusion": "本研究通过SCoTT框架验证了基于数字孪生的策略性思维链任务规划方法在无线感知机器人导航中的有效性和实用性。同时，讨论了数据获取流程、计算需求和部署考量，强调了自然语言接口在实际无线感知导航应用中的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14441", "html_url": "https://arxiv.org/abs/2411.14441", "title": "GeMID: 面向物联网设备识别的一般性模型", "title_en": "GeMID: Generalizable Models for IoT Device Identification", "authors": "Kahraman Kostas,Rabia Yasa Kostas,Mike Just,Michael A. Lones", "background": "随着物联网（IoT）设备的增多，确保它们的安全变得至关重要。设备识别（DI），基于其流量模式区分IoT设备，对于区分设备和识别脆弱设备，填补了安全上的重大空白都至关重要。然而，现有的建立机器学习模型的DI方法往往忽视了模型在不同网络环境中的普适性挑战。本文研究旨在解决这一限制，通过开发一种新颖框架来评估DI模型在不同网络环境数据集中的一般性问题。这种挑战主要体现在现有方法对于数据集环境多样性的适应性和普适性不足。因此，本文提出了两个步骤的方法：首先，通过使用遗传算法和外部反馈对从不同环境收集的数据集进行细化选择，开发更强大的特征和模型选择方法。其次，通过对进一步独立数据集进行测试，以评估其普适性。研究结果表明，现有的滑动窗口和流量统计方法因受限于网络特定特性而限制了其普适性。此外，常用的统计方法因依赖于网络特性的缘故，不能用于设备识别，挑战了大量现有研究的有效性。", "innovation": "本文提出的GeMID框架通过引入一种遗传算法与外部反馈相结合的特征和模型选择方法，解决了现有DI模型在不同网络环境普适性方面的问题。此外，这种方法通过在新的独立数据集上进行验证，有效评估了DI模型的普适性。该研究成果推进了IoT安全与设备识别的研究，提供了提高模型效果和减轻IoT网络风险的见解和方法。", "conclusion": "本文通过实证对比新的GeMID方法与现有方法，展示了其在提高器件识别准确性、增强模型普适性方面的优势。统计方法由于依赖于网络特定特性而成为不可靠的识别手段，这挑战了大量现有研究的有效性。未来的研究可进一步探讨如何利用该方法优化IoT设备识别过程，以及应用到其他安全检测领域。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12982", "html_url": "https://arxiv.org/abs/2410.12982", "title": "闪电推理：长卷积序列模型及其他模型的接近线性时间推理", "title_en": "Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond", "authors": "Costin-Andrei Oncescu,Sanket Purandare,Stratos Idreos,Sham Kakade", "background": "虽然变压器已成为了序列生成模型中最核心的技术，在最近的研究成果中占主导地位，但它们的计算成本依然随着序列长度的增加而变得平方级别。为了应对这一计算成本问题，一些亚平方级别的架构被提出。例如，长卷积序列模型（LCSMs），如Hyena，虽然可以在训练时解决这个问题，但在推理阶段依然保持平方级别的计算成本。本文提出了一种加速LCSMs精确推理的方法，使得推理时间缩短到接近线性级别，即将推理时间从平方级别降低到约$O(L\text{log}^2L)$。研究者识别出了实现这一目标的关键属性，并提出了一种充分利用这些属性的一般框架。该方法受到先前关于松弛多项式插值工作的启发，基于一种平铺技术，既减少了内存移动，又共享了计算。这种方法还允许在架构的位置混合部分几乎完全并行化。", "innovation": "本文提出了一种新的方法，用于加速LCSMs（长卷积序列模型）的精确推理，将推理时间从平方级别降低到接近线性级别（约$O(L\text{log}^2L)$）。这个方法的关键是利用先前关于松弛多项式插值的研究成果，引入一种平铺技术来减少内存移动和共享计算，同时允许在位置混合部分几乎完全并行化。这是一种解决序列模型大规模推理中计算成本问题的新颖方法。在给定的实验中，使用Hyena模型演示了这种方法的有效性，证明其可以在整个推理过程中实现最多7.8倍的加速效果，并且在位置混合部分中更是实现了高达110倍的加速效果。", "conclusion": "本文提出的方法成功将长卷积序列模型的推理时间从平方级别降低到接近线性级别，显著提高了推理效率。通过引入平铺技术，该方法不仅减少了内存移动和计算量，还在位置混合部分实现了几乎完全的并行化，从而大大提高了推理效率。此外，这种方法的通用框架为其它长序列模型的加速推理提供了新的思路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05966", "html_url": "https://arxiv.org/abs/2503.05966", "title": "解释难以解释的：金融领域可解释AI的系统综述", "title_en": "Explaining the Unexplainable: A Systematic Review of Explainable AI in Finance", "authors": "Md Talha Mohsin,Nabid Bin Nasim", "background": "本文探讨了从业者和研究人员在追求准确性和透明度之间的平衡时，将可解释人工智能（XAI）置于金融领域的交汇点的现象。研究从金融领域的具体实施、方法论发展等方面详细回顾了XAI在金融领域的应用现状，使用文献计量和内容分析方法，发现了主要研究主题、重要研究发现以及金融行业中常用的解释策略。研究表明，金融行业中对事后解释技术的依赖显著，其中注意力机制、特征重要性分析和SHAP是最常用的技术。这项综述强调了金融知识与改进的解释性范式相结合的多学科方法的重要性，并揭示了当前XAI系统的显着不足之处。", "innovation": "通过使用文献计量和内容分析方法，论文找到了金融行业中XAI的主要研究主题、重要研究发现和常用解释策略，并强调了多学科方法的重要性及展示了现有XAI系统的不足，为XAI在金融领域的进一步发展提供了方向和建议。", "conclusion": "金融行业依赖于事后解释技术，注意力机制、特征重要性分析和SHAP是最常用的技术。需要结合金融知识和改进的可解释性范式，采用多学科研究方法，以便更好地理解XAI系统，并解决当前存在的不足。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18540", "html_url": "https://arxiv.org/abs/2502.18540", "title": "MA-GTS：在实际应用中解决复杂图问题的多代理框架", "title_en": "MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications", "authors": "Zike Yuan,Ming Liu,Hui Wang,Bing Qin", "background": "实际应用场景中的图论问题往往复杂、干扰多且不规则，传统算法难以应对。大型语言模型虽然提供了潜在的解决方案，但存在准确性限制和输入长度限制等挑战。通过多代理框架MA-GTS，为了解决这些问题，首先将隐含表示的文本图形数据映射到清晰的结构图中，然后根据问题约束和图形规模动态选择最合适的算法，确保了解决过程高效且推理路径具有可解释性。实验结果表明，MA-GTS在G-REAL、GraCoRe和NLGraph基准测试中的表现优于当前最先进的方法，尤其是在效率、准确性和规模方面表现出色。", "innovation": "提出了MA-GTS，一种多代理框架，通过代理协同工作将隐式的文本图形数据分解为明确的结构图形，并基于问题约束和图形结构规模动态选择最合适的算法。该框架在实际应用中有效解决了复杂图论问题，提高了算法的效率、准确性和可扩展性，能够生成易于理解的推理路径。", "conclusion": "MA-GTS在实际应用中展示了在复杂图形问题上的优越性能，并且通过G-REAL数据集的验证展示了其在效率、准确性和扩展性方面的强大力量，为解决实际图形问题提供了一种新的有效方法。MA-GTS已开源，可通过提供的链接查看。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.06444", "html_url": "https://arxiv.org/abs/2503.06444", "title": "使用有限样本合成高维表数据", "title_en": "Towards Synthesizing High-Dimensional Tabular Data with Limited Samples", "authors": "Zuqing Li,Junhao Gan,Jianzhong Qi", "background": "基于扩散的过程在生成表数据方面表现出令人满意的结果。然而，随着数据维度的增加，现有的模型往往会退化，甚至可能不如简单的、基于扩散之外的模型。这主要是因为在高维空间中有限的训练样本往往妨碍了生成模型准确捕捉数据分布的能力。", "innovation": "为了缓解学习信号不足并稳定在高维、低数据场景下的训练，我们提出了CtrTab，这是一种条件控制的扩散模型。该模型在训练中注入扰动的真实样本作为辅助输入，这种设计引入了模型对控制信号敏感性的隐式L2正则化，提高了在高维、低数据场景下的稳健性和稳定性。", "conclusion": "通过对多个数据集的实验结果进行评估，显示CTRTab模型优于当前最先进的模型，平均准确率差距超过90%。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08542", "html_url": "https://arxiv.org/abs/2503.08542", "title": "CLEV：基于轻量级高效投票的大型语言模型评估方法用于自由形式问答", "title_en": "CLEV: LLM-Based Evaluation Through Lightweight Efficient Voting for Free-Form Question-Answering", "authors": "Sher Badshah,Moamen Moustafa,Hassan Sajjad", "background": "评估自由形式问答（Free-form Question Answering, QA）因其多样性和开放性 remains a challenge。传统的自动化评估指标无法捕捉到语义上的等价性或适应开放式回答的变异性。因此，使用大型语言模型（Large Language Models, LLMs）作为评估者提供了一种有前景的替代方法，因为LLMs具有强大的语言理解能力和指令遵循能力。", "innovation": "我们提出了基于轻量级高效投票（Consensus via Lightweight Efficient Voting, CLEV）的评估方法，通过使用两个主要的LLMs作为评委，并仅在意见不一致时才唤起第三个评委。这种方法在保证评估可靠性的前提下，减少了不必要的计算需求。通过实验，包括人工评估，展示了CLEV能够提供一致、可扩展和资源高效的评估，从而确立其作为评估LLMs在自由形式QA中的稳健框架地位。", "conclusion": "CLEV能够提供一致、可扩展和资源高效的评估，从而确立其作为评估LLMs在自由形式QA中的稳健框架地位。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11575", "html_url": "https://arxiv.org/abs/2504.11575", "title": "MULTI-LF: 多环境网络中的实时恶意流量检测的连续学习框架", "title_en": "MULTI-LF: A Continuous Learning Framework for Real-Time Malicious Traffic Detection in Multi-Environment Networks", "authors": "Furqan Rustam,Islam Obaidat,Anca Delia Jurcut", "background": "多环境（M-En）网络整合了包括物联网（IoT）和传统计算系统在内的多种流量来源，这为恶意流量检测带来了复杂且不断变化的条件。目前，基于机器学习（ML）的方法通常在静态单一领域的数据集上进行训练，难以在异构网络环境中进行泛化。", "innovation": "该研究开发了一种名为Multi-LF的实时连续学习框架，结合了轻量级模型（M1）进行快速检测，以及深层模型（M2）进行高度信心的精炼和适应。通过1秒间隔提取的特征捕捉了细微的时间模式，该框架在Docker-NS3测试床上的实时流量中实现了99.9%的准确率，只需要对0.0026%的包进行人工干预。", "conclusion": "Multi-LF方案在多环境网络中实现了高效且准确的恶意流量检测，证明了其在异构网络中的实时检测的有效性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01903", "html_url": "https://arxiv.org/abs/2504.01903", "title": "STAR-1: 使用1000数据使推理LLMs更安全对齐", "title_en": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data", "authors": "Zijun Wang,Haoqin Tu,Yuhan Wang,Juncheng Wu,Yanqing Liu,Jieru Mei,Brian R. Bartoldson,Bhavya Kailkhura,Cihang Xie", "background": "本文介绍了一个名为STAR-1的数据集，该数据集是一个专门针对大型推理模型（LRMs）如DeepSeek-R1的安全性数据集。STAR-1基于多样性的原则、审慎推理的原则和严格的过滤原则来构建，旨在满足大型推理模型在安全对齐方面的关键需求。", "innovation": "STAR-1采用了现有的开源安全性数据集，并通过定制化安全政策生成基于政策的审慎推理样本。同时引入了基于GPT-4o的安全评分系统来选择与最佳实践一致的训练样本。实验结果显示，使用STAR-1对大型推理模型进行微调可以在四种基准测试中平均提高40%的安全性能，同时仅在五个推理任务中略有下降（平均为1.1%）。进一步的消融研究表明，STAR-1的设计原则对于构建大型推理模型和传统LLM都具有很高的有效性。", "conclusion": "STAR-1的实验证明了其在构建安全对齐的大型推理模型中的重要性和有效性，并验证了其在大型推理模型和传统语言模型中的广泛适用性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14321", "html_url": "https://arxiv.org/abs/2503.14321", "title": "COPA: 在多目标模型评估中比较不可比较的内容", "title_en": "COPA: Comparing the incomparable in multi-objective model evaluation", "authors": "Adrián Javaloy,Antonio Vergari,Isabel Valera", "background": "在机器学习中，我们经常需要从数十个已训练的模型中选择一个，基于准确度、鲁棒性、公平性和可扩展性等多种目标进行。然而，如何比较、汇总并最终权衡这些目标往往不清楚，这使得成为一个耗时的任务，需要专家知识，因为目标可能以不同的单位和比例进行测量。因此，这项工作的目标是探索如何自动标准化和汇总目标，以系统地帮助用户导航其帕累托前沿。", "innovation": "我们通过使用累积函数来使不可比较的目标可比，这些累积函数通过相对排名近似。因此，我们提出的方法COPA可以在匹配用户特定偏好时汇总这些目标，使得实践者能够有意义地导航并搜索帕累托前沿中的模型。在多种机器学习领域中，如公平机器学习、领域泛化、自动机器学习和基础模型中，COPA展示了其潜在影响，而古典方法无法进行目标的标准化和汇总。", "conclusion": "COPA在模型选择和基准测试任务中表现出潜在影响，能够在多种机器学习领域中有效地匹配用户特定偏好进行模型的导航和搜索，而传统方法无法处理。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05870", "html_url": "https://arxiv.org/abs/2505.05870", "title": "FaSDiff：通过稳定扩散先验平衡感知与语义的面部压缩", "title_en": "FaSDiff: Balancing Perception and Semantics in Face Compression via Stable Diffusion Priors", "authors": "Yimin Zhou,Yichong Xia,Bin Chen,Mingyao Hong,Jiawei Li,Zhi Wang,Yaowei Wang", "background": "随着面部图像数据在各种应用中的广泛应用，高效的压缩变得至关重要，尤其是在存储和传输方面。虽然基于学习的面部图像压缩方法已取得显著成果，但在低比特率下常导致重建质量下降。直接应用基于扩散的生成先验进行此任务会导致下游机器视觉任务的性能不佳，主要是因为高频细节的保真度较差。", "innovation": "提出了FaSDiff（面部图像压缩与稳定扩散的结合），这是一种新颖的扩散驱动压缩框架，旨在提高视觉真实感和语义一致性。FaSDiff结合了高频敏感压缩器以捕捉细节并生成指导扩散模型的稳健视觉提示。为了应对低频降解，引入了混合低频增强模块以分离并保留语义结构，从而在重建过程中稳定控制扩散先验。通过联合优化视觉质量和语义保持，FaSDiff有效地平衡了人类视觉真实感和机器视觉准确性。", "conclusion": "通过广泛的实验，FaSDiff在感知指标和下游任务性能方面均优于现有的最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00028", "html_url": "https://arxiv.org/abs/2505.00028", "title": "增强端到端语音对话建模的检索增强生成", "title_en": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation", "authors": "Pengchao Feng,Ziyang Ma,Wenxi Chen,Yao Li,Sheng Wang,Kai Yu,Xie Chen", "background": "端到端的语音到语音（S2S）对话系统近年来因为其较低的延迟和更好的非言语提示（如情感和说话人身份）的自然集成而受到了越来越多的研究关注。然而，这些系统面临着整合外部知识的关键挑战，通常通过基于文本的大语言模型中的检索增强生成（RAG）来解决。核心难题在于输入语音和检索的文本知识之间的模态差距，这阻碍了信息的有效整合。", "innovation": "提出了一个新颖的端到端RAG框架，可以直接从语音查询中检索相关文本知识。实验结果显示，该方法显著提高了端到端S2S对话系统的性能，同时提高了检索效率。尽管整体性能仍然落后于最新的级联模型，但该框架为增强端到端S2S系统中的知识整合提供了一个有前景的方向。", "conclusion": "我们的代码和数据集已发布。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13231", "html_url": "https://arxiv.org/abs/2504.13231", "title": "WildFireCan-MMD: 加拿大野火期间用户生成内容分类的多模态数据集", "title_en": "WildFireCan-MMD: A Multimodal Dataset for Classification of User-Generated Content During Wildfires in Canada", "authors": "Braeden Sherritt,Isar Nejadgholi,Efstratios Aivaliotis,Khaled Mslmani,Marzieh Amini", "background": "在野火期间快速获取信息非常重要，但传统的数据来源速度慢且成本高。虽然社交媒体提供了实时更新，但提取相关洞察仍然是一项挑战。当前可用的多模态野火社交媒体数据在加拿大语境中相对不足，尤其是在现有的数据集中。因此，本研究致力于开发加拿大野火期间用户生成内容的多模态数据集，以填补这一空白。", "innovation": "本研究提出了WildFireCan-MMD，这是一个包含X个最新加拿大野火帖子的多模态数据集，并且这些帖子被跨12个关键主题进行标注。还评估了零样本视觉-语言模型，并将其结果与专门训练的模型和基线分类器进行了比较。结果显示，虽然基线方法和零样本提示可以在短时间内部署，但在有标注数据的情况下，自定义训练的模型表现更优。最佳自定义模型达到了84.48%的f分数，优于视觉-语言模型和基线分类器。此外，展示了如何利用该模型分析大规模未标注数据，以揭示野火期间的趋势。", "conclusion": "我们的数据集促进了未来关于野火响应的研究，我们的发现强调了定制化数据集和任务特定训练的重要性。重要的是，这样的数据集应该本地化，因为灾害响应的需求在不同的地区和环境中是有差异的。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14359", "html_url": "https://arxiv.org/abs/2504.14359", "title": "Vision-Language模型跨语言感知多样性多模态重新描述框架", "title_en": "A Multimodal Recaptioning Framework to Account for Perceptual Diversity Across Languages in Vision-Language Modeling", "authors": "Kyle Buettner,Jacob T. Emmerson,Adriana Kovashka", "background": "在对图像进行描述时，人们的描述方式多样，这包括使用不同的术语和/或注意感知中至关重要的细节。描述可以因语言和文化而异。现代视觉-语言模型（VLMs）通过机器翻译的英语描述学会了理解不同语言的图像。然而，这个过程依赖于英文母语者的感知内容作为输入，导致了感知偏见。", "innovation": "本文提出了一个框架来解决这一偏见问题。具体而言，该框架利用少量母语者数据、最邻近示例引导和多模态的LLM推理，来增强描述以更好地反映目标语言中的描述。通过将重写结果加入到多语言CLIP微调中，我们改进了德语和日语的文本-图像检索案例研究结果（最高可提高+3.5的平均召回率，提高+4.4的翻译错误比率）。此外，本文提出了一个机制，以建立对跨语言对象描述差异的理解，并为跨数据集和跨语言的泛化提供了见解。", "conclusion": "通过使用该框架，我们提高了不同语言在文本-图像检索方面的表现，并提出了一种理解跨语言对象描述差异的方法，同时为我们理解跨数据集和跨语言的泛化提供了新的洞见。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00661", "html_url": "https://arxiv.org/abs/2505.00661", "title": "基于上下文学习和微调的语言模型泛化研究：一个控制实验", "title_en": "On the generalization of language models from in-context learning and finetuning: a controlled study", "authors": "Andrew K. Lampinen,Arslan Chaudhry,Stephanie C.Y. Chan,Cody Wild,Diane Wan,Alex Ku,Jörg Bornschein,Razvan Pascanu,Murray Shanahan,James L. McClelland", "background": "大语言模型展示了令人兴奋的能力，但它们的泛化能力在微调之后却会表现出令人意外的狭窄性。例如，它们可能无法从训练中泛化到简单的因果关系反转，也无法基于已训练的信息做出简单的逻辑推理。这些泛化失败可能会严重阻碍这些模型的推理能力。另一方面，语言模型的上下文学习（ICL）展现出了不同的归纳偏见和演绎推理能力。本文旨在探索这两种学习方式在泛化和演绎推理能力上的差异。", "innovation": "本文构建了多个新的数据集，以便评估和改进模型在新数据下进行泛化的能力，这些数据集设计用于隔离数据集中的知识与预训练知识。通过将预训练的大模型暴露给数据集中的控制子集信息（通过上下文学习或微调），并在需要各种类型泛化能力的测试集上评估其性能。研究发现，在数据匹配的设置下，上下文学习可以比微调更灵活地泛化多种推理，提出了结合上下文推理痕迹到微调数据的方法以提高泛化能力。", "conclusion": "研究结果表明，在数据匹配设置下，上下文学习可以比微调更灵活地泛化多种推理。通过将上下文推理痕迹添加到微调数据中，该方法能够在我们的数据集和其他基准测试中提高泛化能力。这些结果对于理解不同学习模式提供的泛化能力具有重要意义，并有助于实际提高语言模型的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11770", "html_url": "https://arxiv.org/abs/2505.11770", "title": "内部因果机制稳健地预测语言模型的异常分布行为", "title_en": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors", "authors": "Jing Huang,Junyi Tao,Thomas Icard,Diyi Yang,Christopher Potts", "background": "当前的可解释性研究提供了多种技术来识别神经网络中的高层机制。本文探讨了是否可以使用这些技术来预测模型在异常分布样本上的行为。", "innovation": "作者提出了一种新的方法，即通过因果机制预测模型输出的正确性，并通过符号操作、知识检索和指令跟随等多样化的语言建模任务进行了验证。具体方法包括反事实模拟和价值探针，这两种方法在分布内和分布外场景中均表现出优异的效果。", "conclusion": "本文的工作表明，内部因果分析可用于语言模型的新型且重要的应用，尤其是用于预测模型在异常分布样本上的行为。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11192", "html_url": "https://arxiv.org/abs/2505.11192", "title": "FALCON: 在视觉-语言对齐中对负样本错误感知的学习", "title_en": "FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Alignment", "authors": "Myunsoo Kim,Seong-Woong Shim,Byung-Jun Lee", "background": "在大规模数据集中的图像和文本之间存在一对多对应关系，导致在视觉-语言预训练（VLP）中出现大量假阴性现象。假阴性引入了矛盾的监督信号，这对学习到的嵌入空间造成了负面影响，减弱了困难负样本采样的效果。", "innovation": "本文提出了FALCON（虚假负样本感知对比负样本学习）策略，这是一种基于学习的批量构建策略，在构建VLP小批量时能够自适应地平衡硬负样本和假负样本之间的权衡。FALCON采用了一种负样本挖掘调度器，能够在构建小批量时动态选择适当的负样本硬度，而不需要依赖固定的启发式方法。", "conclusion": "实验结果表明，FALCON在三个视觉-语言学习框架（ALBEF，BLIP-2，SigLIP-2）和一系列下游任务及评估设置中显著提高了表现，进一步证明了其在减轻假阴性影响方面的有效性与鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09598", "html_url": "https://arxiv.org/abs/2505.09598", "title": "AI 的饥饿程度如何？LLM 推断的能源、水和碳足迹基准", "title_en": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "authors": "Nidhal Jegham,Marwan Abdelatti,Chan Young Koh,Lassad Elmoubarki,Abdeltawab Hendawi", "background": "该论文介绍了针对商业数据中心30个领先的大规模语言模型(LLM)推断的环境足迹进行量化的一种基础设施感知基准化框架。该框架结合了公开API性能数据、公司特定的环境多重系数以及硬件配置的统计推断。此外，还利用跨效率数据包络分析(DEA)评估模型的性能与其环境成本之间的相对排名，并提供实时更新的仪表板，以可视化各模型级别的能耗、水耗和碳排放指标。研究表明，最具能源密集型的模型单个长提示的能量使用超过29 Wh，效率最高的系统超过65倍。即使是0.42 Wh的短查询，在每日700M次查询的规模下，一年累计的电力消耗相当于3.5万个美国家庭，蒸发性的淡水相当于每年满足120万人的饮用水需求，碳排放量需要一个相当于芝加哥森林大小的面积来弥补。这些发现凸显了一个日益增长的悖论：虽然AI变得更便宜和更快速，但全球采用反而导致了不成比例的资源消耗。", "innovation": "论文提出了一种结合公开API性能数据、公司特定的环境多重系数及硬件配置统计推断，综合评估大语言模型推断的环境足迹的框架。此外，还采用了跨效率数据包络分析(DEA)来衡量模型的性能与环境成本之间的相对影响，并通过实时更新的仪表板提供模型级别的能源、水、碳排放指标的可视化视图。", "conclusion": "研究表明，最具能源密集性的模型在其推断过程中消耗的能量远高于效率高的系统。即使节能查询在大规模应用下也会产生相当于大规模家庭用电、水资源消耗以及需要大片森林来抵消的碳排放量。这揭示了一个悖论：尽管AI技术快速发展，但其对资源的消耗却在增长。本研究为AI部署的可持续性基准和问责提供了标准化，实践基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13709", "html_url": "https://arxiv.org/abs/2505.13709", "title": "基于策略的世界模型自适应以提高鲁棒的离线模型导向强化学习", "title_en": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning", "authors": "Jiayu Chen,Le Xu,Aravind Venugopal,Jeff Schneider", "background": "离线强化学习（RL）提供了一种强大的数据驱动控制范式。与无模型方法相比，离线模型导向RL（MBRL）方法通过从静态数据集中学习世界模型并将其用作代理模拟器，提高了数据效率，并有可能超越数据集支持范围进行泛化。然而，大多数现有多阶段训练方法在学习世界模型后优化策略，存在目标不匹配的问题，导致世界模型未必对策略学习优化有效。此外，通过离线MBRL学习到的策略在部署时通常缺乏鲁棒性，环境中的小噪声就可以导致性能大幅下降。", "innovation": "提出了一种框架，该框架统一学习目标下策略与世界模型的动态适应，核心在于解决一种最大化最小优化问题，并创新性地利用Stackelberg博弈动态解决此问题。在理论分析支持下，介绍了计算高效的实现方法。", "conclusion": "在十二个噪声D4RL MuJoCo和三个随机Tokamak Control任务上进行基准测试，证明了该算法的最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19164", "html_url": "https://arxiv.org/abs/2505.19164", "title": "BroadGen：一种生成高效有效广告主宽匹配关键词推荐的框架", "title_en": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations", "authors": "Ashirbad Mishra,Jinyu Zhao,Soumik Dey,Hansi Wu,Binbin Li,Kamesh Madduri", "background": "在竞价搜索广告领域，关键词推荐主要集中在精确匹配类型上，这不仅带来高管理成本和有限的目标范围，还难以应对不断变化的搜索查询模式。尽管可以采用宽匹配类型来缓解精确匹配的一些缺点，但宽匹配类型的使用较为有限，导致定位不准确且缺乏监督信号。", "innovation": "提出了BroadGen框架，通过利用历史搜索查询数据推荐高效且有效的宽匹配关键词。此外，BroadGen通过token对应模型保持了更稳定的时间查询模式。", "conclusion": "BroadGen能够满足每天为eBay上的数百万卖家推荐超过25亿件商品的任务需求。通过广义匹配关键词推荐，显著提高了广告效率和效果，验证了其在实际应用场景中的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11570", "html_url": "https://arxiv.org/abs/2505.11570", "title": "Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning", "title_en": "Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning", "authors": "Chongyang Tan,Ruoqi Wen,Rongpeng Li,Zhifeng Zhao,Ekram Hossain,Honggang Zhang", "background": "联邦学习（FL）能够在保护隐私的情况下在边缘设备上分布式训练模型，但其效率高度依赖于动态和异构无线环境中有效的设备选择和高维资源分配。传统方法需要特定领域的专业知识、广泛的超参数调整和/或高昂的交互成本。当前方法的问题在于其依赖性强且灵活性差，这在不同网络条件下难以拓展应用。", "innovation": "本文提出了一种基于工具辅助的进化大语言模型（T-ELLM）框架，用于无线联邦学习环境中生成设备选择的合格策略。T-ELLM利用基于自然语言的场景提示来增强在不同网络条件下的泛化能力，并将联合优化问题数学解耦，从而使得设备选择策略的学习可以被可处理地进行，同时将资源分配问题交给凸优化工具来解决。为了提高适应性，T-ELLM集成了一种样本效率高的基于模型的虚拟学习环境，该环境捕捉了设备选择与学习性能之间的关系，促进后续集体相对策略优化。这种结合的方法减少了对真实世界交互的依赖，减少了通信开销，与此同时保持了高保真的决策制定能力。理论上分析证明，虚拟和现实环境之间的差异是有限的，确保了在虚拟环境中学到的优势函数在现实世界条件下的偏差是有保证的小的。实验结果显示，T-ELLM在能效方面优于基准方法，并且表现出对环境变化的稳健适应性。", "conclusion": "T-ELLM框架在无线联邦学习环境中实现了有效的资源管理，并显著提高了适应能力和能效，减少了对外部交互的需求，从而实现在真实复杂环境中的稳健决策。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13697", "html_url": "https://arxiv.org/abs/2505.13697", "title": "名副其实的RL吗？分析LLMs后训练中结构假设", "title_en": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs", "authors": "Soumya Rani Samineni,Durgesh Kalwar,Karthik Valmeekam,Kaya Stechly,Subbarao Kambhampati", "background": "文章背景描述了基于强化学习的大型语言模型后训练（RL post-training of large language models，LLMs）近期受到关注的情况。特别是随着DeepSeek R1的发布，利用GRPO（Generalized Reward Propagation Optimizer）进行微调。随之而来的改进推理能力也让RL后训练成为热门话题。文章批判性地审视了这些方法背后的公式化假设，并通过深入分析显示这些简化假设使得RL方法实际上等同于基于结果的监督学习。", "innovation": "文章的关键创新在于揭示了基于RL假设的简化结构实际上使得这种方法等同于监督学习。文章通过具体实验对比验证了这一观点，并展示了迭代的基于监督的微调能够达到与基于GRPO的方法相似的性能。此外，文章还揭露了简化假设如何间接导致生成更长的中间分词序列，这证实了“RL生成更长的思考痕迹”的说法。", "conclusion": "文章结论认为，由于简化假设使得RL在LLMs中的基础MDP模型变得不必要复杂，目前流行的LLMs RL框架及其解释值得商榷。尽管RL可能确实是提高LLMs推理能力的有效工具，但本文的分析表明，这些简化假设使得RL方法的效能在一定程度上可被监督学习方法替代。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21528", "html_url": "https://arxiv.org/abs/2505.21528", "title": "通过随机最优控制实现的统一快速采样扩散桥梁框架", "title_en": "A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control", "authors": "Mokai Pan,Kaizhen Zhu,Yuexin Ma,Yanwei Fu,Jingyi Yu,Jingya Wang,Ye Shi", "background": "近期的研究利用Doob的h-转换建立了具有固定端点的扩散桥梁模型，在图像翻译和修复任务中取得了有前途的结果。然而，这些方法往往产生模糊或过度平滑的图像细节，并缺乏全面的理论基础来解释这些不足。", "innovation": "提出了一个基于随机最优控制（SOC）的统一且快速采样框架UniDB。通过SNRL成本函数中的终态惩罚系数趋于无穷，证明了现有使用Doob的h-转换的扩散桥梁构成了一个特殊情况。UniDB通过引入可调的终态惩罚系数，在控制成本和终端惩罚之间实现最优平衡，从而显著提高细节保留和输出质量。设计了一种无需训练的加速算法，通过推导UniDB的逆转时SDE的确切闭环解来避免迭代欧拉采样的高成本，还用更稳定的数据预测模型替换常规噪声预测，并引入SDE校正机制以保持低步骤阶段的感知质量，从而有效减少误差积累。", "conclusion": "广泛的实验结果表明，该提出的框架在多样性图像修复任务中优越性和适应性突出，填补了理论普适性和实际效率之间的差距。提供的代码可在在线访问。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：大语言模型的联邦分裂框架，集安全、高效和适应性于一体", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私有的高质量数据对于提升大型语言模型（LLMs）有巨大潜力，但由于这些数据分散在不同的数据孤岛中，以及LLMs计算资源要求高，使得它们难以在联邦环境中部署。现有的联邦分式模型将大部分模型参数卸载到服务器或分布式的客户端上以保护数据隐私，但仍面临三个挑战：1）端到端的密钥加密无法有效保护传输的向量；2）由于LLMs的自回归特性，联邦分割学习需要顺序进行训练和推理，导致高昂的通信开销；3）固定分段点缺乏针对下游任务的适应性。", "innovation": "为解决上述问题，本文提出了FedSEA-LLaMA框架。该框架通过在前向传播隐藏状态中注入高斯噪声，以实现端到端向量的安全传输；利用注意掩码压缩和KV缓存合作来减少通信成本，加快训练和推理；允许用户根据具体任务要求动态调整输入/输出块的分段点。实验结果显示，在自然语言理解、摘要和对话问答任务上，FedSEA-LLaMA的性能与集中式LLaMA2相当，训练和推理速度分别提高了8倍。进一步分析表明，FedSEA-LLaMA在安全性和适应性方面表现出色。", "conclusion": "FedSEA-LLaMA通过注入噪声、通信成本优化和动态分段，解决了联邦环境中高质量数据的利用难题，实现了高性能和低通信开销的统一，并提高了对下游任务的适应性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17206", "html_url": "https://arxiv.org/abs/2505.17206", "title": "FB-RAG：改进RAG的前瞻与回溯查找", "title_en": "FB-RAG: Improving RAG with Forward and Backward Lookup", "authors": "Kushal Chawla,Alfy Samuel,Anoop Kumar,Daben Liu", "background": "传统的检索增强生成（RAG）方法在处理缺乏强烈信号的复杂查询时存在困难，这迫使在选择较小上下文错过关键信息和选择较大上下文混淆LLM之间做出权衡。这导致了性能的局限性，需要在复杂微调或强化学习方面做出牺牲才能提高结果质量。", "innovation": "提出了一个无需训练的新框架——前向-后向RAG（FB-RAG），基于简单而强大的前瞻策略。FB-RAG 使用一个轻量级的LLM 预览潜在的未来生成情况，利用多个采样输出的证据精确识别最终更强大的生成器所需的相关背景。这种方法无需复杂微调或 prior work 中常见的强化学习，提高了性能。在来自 LongBench 和 ∞Bench 的 9 个数据集中，FB-RAG 保持了强大成果，且由于生成器短而精炼的提示，结果可以获得更低的延迟。在特定数据集中，即使前瞻的LLM未能生成正确的答案，其尝试也足以指导最终模型产生正确的响应，证明了更小的LLM可以系统提高更大模型的性能和效率", "conclusion": "FB-RAG 通过前瞻和回溯查找，提供了一种在无需复杂微调和强化学习的情况下显著提高RAG性能的方式，并且能够减少生成的延迟，证明了小规模模型可以对大规模模型性能的系统提升发挥重要作用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05454", "html_url": "https://arxiv.org/abs/2506.05454", "title": "零阶优化发现平坦极小值", "title_en": "Zeroth-Order Optimization Finds Flat Minima", "authors": "Liang Zhang,Bingcong Li,Kiran Koshy Thekumparampil,Sewoong Oh,Michael Muehlebach,Niao He", "background": "零阶方法在机器学习应用中广泛使用，尤其是在不可用或计算代价高昂的梯度情况下，如黑盒攻击、强化学习和语言模型微调。现有的优化理论主要关注收敛到任意稳定点，但较少有关隐式正则化的内容，后者能够细粒度地描述最终达到的具体解特性。本文指出，标准两点估计的零阶优化倾向于寻找Hessian矩阵迹较小的解，这在过去的工作中常用来区分尖锐和平坦的极小值。通过研究凸且充分光滑函数的零阶优化收敛率，本文证明在凸损失的二分类任务和语言模型微调中，平坦极小值具有最小的Hessian矩阵迹，从而验证了理论发现并提供了收敛分析。", "innovation": "本文揭示了零阶优化中使用标准两点估计法更偏好最小化Hessian矩阵迹的解，即发现平坦极小值的趋势。此外，本文还提供了对于凸且充分光滑函数的零阶优化方法针对接近平坦极小值的收敛率分析，证实了尖锐和平坦极小值之间的差异关键在于Hessian矩阵迹的大小。", "conclusion": "实验在二分类任务（使用凸损失）和语言模型微调中支持了理论发现。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10982", "html_url": "https://arxiv.org/abs/2506.10982", "title": "重新思考扩散桥梁采样器的损失函数", "title_en": "Rethinking Losses for Diffusion Bridge Samplers", "authors": "Sebastian Sanokowski,Lukas Gruber,Christoph Bartmann,Sepp Hochreiter,Sebastian Lehner", "background": "扩散桥梁是一种有前景的深度学习方法，用于从未规范化的分布中采样。之前的研究表明，使用重参数化技巧计算逆Kullback-Leibler (rKL)梯度时，Log Variance (LV)损失持续优于rKL损失。虽然当与日志导数技巧结合使用时，对于不可学习的前向过程的扩散采样器，基于策略的LV损失会得出与rKL损失相同的梯度，这一等价性对于扩散桥梁或当扩散系数可学习时不成立。", "innovation": "本文通过分析指出，在扩散桥梁的情况下，LV损失并不像rKL损失那样可以通过数据处理不等式得到类似优化目标的动机。同时，本文表明使用rKL损失和日志导数技巧（rKL-LD）不仅避免了这些概念性问题，而且始终优于LV损失。实验结果表明，使用rKL-LD损失训练的采样器在具有挑战性基准上的性能更佳。从实际应用角度来看，rKL-LD损失需要较少的超参数优化，并且在训练行为上更为稳定。", "conclusion": "实验结果表明，在不同的扩散桥梁上，rKL-LD损失训练的采样器在具有挑战性基准上的性能更佳。从实用角度看，rKL-LD损失需要更少的超参数调优，并且在训练行为上更为稳定。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03237", "html_url": "https://arxiv.org/abs/2506.03237", "title": "UniSite：首个跨结构数据集及端到端配体结合位点检测学习框架", "title_en": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "authors": "Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang", "background": "配体结合位点的检测是基于结构的药物设计中的关键步骤。尽管近年来取得了显著进展，但现有方法、数据集和评估指标仍面临一些关键挑战：（1）现有的数据集和方法主要集中在单一蛋白质-配体复合体上，忽视了同一蛋白质的不同复合体中存在的多样化结合位点，这引入了统计偏差；（2）配体结合位点检测通常被建模为一个断续的工作流，采用二元分割和后续聚类算法；（3）传统的评估指标未能充分反映不同结合位点预测方法的实际性能。", "innovation": "提出了首个UniSite-DS，这是世界上首个以UniProt为中心的配体结合位点数据集，包含4.81倍更多的多站点数据和2.08倍更多的总数据。在此基础上，提出了首个通过集合预测损失和双射匹配实现端到端配体结合位点检测的UniSite框架，引入了基于Intersection over Union (IoU)的平均精度作为更为准确的评估指标。实验表明，基于IoU的平均精度能更准确地反映预测质量，且UniSite在配体结合位点检测上优于当前最先进的方法。", "conclusion": "UniSite-DS和UniSite框架已经在UniSite-DS及几个代表性基准数据集上经过了广泛实验验证，并将数据集和代码集将在该网址公开。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13345", "html_url": "https://arxiv.org/abs/2507.13345", "title": "平衡中的不平衡：生成模型中的在线概念平衡", "title_en": "Imbalance in Balance: Online Concept Balancing in Generation Models", "authors": "Yukai Shi,Jiarong Ou,Rui Chen,Haotian Yang,Jiahao Wang,Xin Tao,Pengfei Wan,Di Zhang,Kun Gai", "background": "在视觉生成任务中，复杂概念的响应和组合往往不稳定且容易出错，这是一个尚未充分探索的领域。现有的方法难以处理这一问题，因此研究者们尝试通过精心设计的实验来探索这种不良概念响应的原因，并设计了概念平衡损失函数（IMBA损失），以解决这一问题。", "innovation": "提出了概念平衡损失函数（IMBA损失），该方法是在线的，无需离线数据集预处理，并且仅需少量代码更改。该方法在新提出的复杂概念基准Inert-CompBench和两个其他公开测试集上显著提高了基础模型的概念响应能力，而仅发布少量代码即可达到有竞争力的结果。", "conclusion": "本研究通过IMBA损失函数的方法，有效解决了视觉生成任务中复杂概念响应不稳定和出错的问题，这种方法具有在线性、无需离线处理数据集、仅需少量代码更改等优点，并在多个基准测试集上取得了显著效果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16430", "html_url": "https://arxiv.org/abs/2507.16430", "title": "超越算法伦理：应对人工智能推荐系统的人文伦理挑战", "title_en": "Beyond Algorethics: Addressing the Ethical and Anthropological Challenges of AI Recommender Systems", "authors": "Octavian M. Machidon", "background": "论文探讨了由AI驱动的推荐系统（RSs）所引发的人文伦理挑战，尤其是在数字环境和社会互动方面日益增加的影响。这些系统通过个性化内容的定制，不仅反映了用户偏好，还积极构建用户在社交媒体、娱乐平台和电子商务中的体验。尽管已经提出了诸如“算法伦理”这样的努力，旨在将伦理原则嵌入算法设计中，但这些方法仍不足以避免推荐系统带来的隐私、自主性和精神健康的担忧。推荐系统固有地将人类复杂性简化为可量化的资料，利用用户弱点，并优先考虑参与度而非福祉。", "innovation": "论文提出了一种三维框架，旨在为人类中心的推荐系统建立标准。该框架结合了政策和监管、跨学科研究以及教育，这些策略相互强化：研究为政策提供证据支持，政策为保护和标准提供保障，教育让用户能够批判性地参与。论文将伦理反思与治理和数字素养联系起来，主张推荐系统可以重定向以促进自主性和尊严，而非削弱它们。", "conclusion": "通过将伦理反思融入治理和数字素养中，论文认为推荐系统可以被重新导向以增强用户的自主性和尊严，而不仅仅是削弱用户。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20495", "html_url": "https://arxiv.org/abs/2506.20495", "title": "ReCode: 使用强化学习更新代码API知识", "title_en": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "authors": "Haoze Wu,Yunzhi Yao,Wenhao Yu,Ningyu Zhang", "background": "大语言模型（LLMs）展示了出色的代码生成能力，但在对外部库API频繁更新的动态环境中表现不佳。这一关键限制源于它们依赖于过时的API知识，即使有当前文档的访问权限，也无法在代码生成中提供可靠的性能。为了应对这一问题，我们提出了一种基于强化学习的ReCode框架，该框架模仿了人类程序员对API更改的适应方式。我们构建了一个包含约2000个数据条目的数据集，以训练LLMs基于更新的信息进行版本迁移。同时，引入了一种修改后的字符串相似度评估方法作为强化学习的奖励。", "innovation": "我们提出了一种基于强化学习的ReCode框架，用于根据API更改情况更新代码知识。通过构建一个包含约2000个数据条目的数据集，我们训练LLMs基于更新的信息进行版本迁移，并引入了修改后的字符串相似度评估方法。实验表明，ReCode能够在全新任务CodeUpdateArena中大幅提高LLMs的代码生成性能，特别是对于API动态更新的场景。此外，与监督微调相比，ReCode对LLMs的通用代码生成能力的影响较小。无论使用何种LLMs和强化学习算法（如GRPO和DAPO），ReCode都能取得一致性改进。", "conclusion": "我们发现，通过ReCode训练后的Qwen2.5-Coder-7B模型在CodeUpdateArena任务上优于32B参数的代码指令微调模型和具有相同架构的推理模型。ReCode的代码可以在给定的URL地址获取。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09776", "html_url": "https://arxiv.org/abs/2508.09776", "title": "LLM生成的文本解释能否增强模型分类性能？一项实证研究", "title_en": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study", "authors": "Mahdi Dhaini,Juraj Vladika,Ege Erdogan,Zineb Attaoui,Gjergji Kasneci", "background": "在迅速发展的可解释性自然语言处理（NLP）领域，文本解释，即类似人类的推理，对于解释模型预测和丰富具有可解释标签的数据集至关重要。传统的做法依赖于人工注释，但这种方式成本高、劳动密集且阻碍了可扩展性。因此，本文提出了一种自动化的框架，利用多个最新一代的大语言模型（LLMs）来生成高质量的文本解释。", "innovation": "本研究通过利用多个最新的大语言模型来自动化生成高质量的文本解释，并通过全面的语言生成（NLG）指标评估其质量。此外，研究还考察了这些解释对预训练语言模型（PLMs）和LLMs在不同自然语言推理任务上性能的影响。结果显示，自动生成的解释在提高模型性能方面具有高度竞争力，从而提供了扩展NLP数据集并增强模型性能的一种有潜力的方法。", "conclusion": "实验表明，自动生成的解释与人工标注的解释相比，在提升模型性能方面表现出高度竞争力。研究结果证明，自动化的大语言模型基于的文本解释生成具有扩展NLP数据集和增强模型性能的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16438", "html_url": "https://arxiv.org/abs/2508.16438", "title": "OPERA：增强型协调规划执行架构——面向推理导向的多跳检索", "title_en": "OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval", "authors": "Yu Liu,Yanbing Liu,Fangfang Yuan,Cong Cao,Youbang Sun,Kun Peng,WeiZhuo Chen,Jianjun Li,Zhiyuan Ma", "background": "大型语言模型（LLMs）和密集检索方法的进步显著推动了检索增强生成（RAG）的发展，但在复杂推理导向的多跳检索任务中，现有方法面临重大挑战：1）推理导向的规划效率低下：基于规则的方法难以生成复杂的多步推理规划，尤其是在遇到超出模板的问题时。2）推理驱动的检索效率低下：相关方法仅采用有限的查询重写，导致检索循环迭代，并常常无法找到关键文档。3）推理指导的筛选不足：现存方法无法识别并过滤噪声结果中的关键信息，影响检索知识的利用。", "innovation": "本文提出了OPERA（协调规划执行推理架构），这是一种新颖的推理驱动检索框架。OPERA通过目标规划模块（GPM）将问题分解为子任务，并由执行推理模块（REM）使用专门组件来进行精确推理和有效的检索。为了训练OPERA，本文还提出了多代理渐进组相对策略优化（MAPGRPO），这是一种新的GRPO变体。实验结果表明，OPERA在复杂多跳基准测试中的表现优于现有方法，验证了MAPGRPO方法的有效性和OPERA架构设计的优越性。", "conclusion": "OPERA通过强化学习增强了协调规划执行架构，能够更好地支持复杂推理导向的多跳检索任务，通过高效的规划、推理和检索显著改善了RAG系统的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "向具身代理型AI迈进：LLM和VLM驱动的机器人自主性和交互的综述与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "近年来，基础模型，包括大型语言模型（LLMs）和视觉-语言模型（VLMs），已经使得机器人自主性和人机界面的新方法得以实现。与此同时，视觉-语言-行动模型（VLAs）或大型行为模型（LBMs）正在提高机器人的灵活度和功能。本文综述了促进代理应用和架构的各种工作，包括GPT风格接口的初步努力，以及更为复杂的系统，其中AI代理作为协调者、计划者、感知执行者或通用接口发挥作用。具有代理性的架构使得机器人能够解析自然语言指令，调用API，规划任务序列或助力操作和诊断。此外，鉴于该领域的快速发展，我们不仅涵盖了同行评审的研究，还点出了社区驱动项目、ROS封装以及工业框架，强调即将出现的发展趋势。我们提出了一种对模型集成方法进行分类的分类法，并对当前文献中代理角色在不同解决方案中的作用进行了比较分析。", "innovation": "本文提出了一种对模型集成方法进行分类的分类法，并对当前文献中代理角色在不同解决方案中的作用进行了比较分析。通过对新技术和新兴项目的研究，提供了一种全新的视角来理解和探索机器人自主性和交互的发展趋势。", "conclusion": "本文按照提出的分类法，对代理型架构在不同应用场景中的性能进行了全面分析，揭示了代理型机器人的最新发展和未来潜在的研究方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15810", "html_url": "https://arxiv.org/abs/2509.15810", "title": "通过潜在空间逆向工程进行实例生成以用于元黑盒优化", "title_en": "Instance Generation for Meta-Black-Box Optimization through Latent Space Reverse Engineering", "authors": "Chen Wang,Yue-Jiao Gong,Zhiguang Cao,Zeyuan Ma", "background": "当前，为了减轻设计优化算法所需的密集专家人力，元黑盒优化（MetaBBO）研究利用元学习的一般化能力，通过一个预先定义的问题集训练基于神经网络的算法设计政策，实现了对未见过的问题实例的自动适应性。然而，现有MetaBBO中的常见训练问题集CoCo-BBOB的问题实例多样性有限，这增加了MetaBBO过拟合的风险，导致了较差的泛化能力。", "innovation": "本文提出了一种实例生成方法LSRE（Latent Space Reverse Engineering），该方法通过训练一个自编码器将高维问题特性映射到二维潜在空间，并利用均匀采样产生足够多样的问题实例，再利用遗传编程搜索与这些隐藏表示最小L2距离的函数公式，从而逆向工程生成了一个多样化的训练问题集Diverse-BBO。利用Diverse-BBO训练各种MetaBBO并验证其在合成或现实场景中的泛化性能。", "conclusion": "实验结果表明，Diverse-BBO在MetaBBO中作为训练集的选择优于现有的训练集选择。进一步的消融研究表明LSRE的设计选择是有效的，并揭示了实例多样性与MetaBBO泛化之间的有趣洞察。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00626", "html_url": "https://arxiv.org/abs/2509.00626", "title": "在轨卫星甲烷检测", "title_en": "Towards Methane Detection Onboard Satellites", "authors": "Maggie Chen,Hala Lambdouar,Luca Marini,Laura Martínez-Ferrer,Chris Bridges,Giacomo Acciarini", "background": "甲烷是一种强效温室气体，是气候变化的主要驱动因素之一，因此其及时检测对于有效的缓解措施至关重要。利用卫星上的机器学习（ML）可以在减少下行链路成本的同时实现快速检测，支持更快的响应系统。传统的甲烷检测方法通常依赖于图像处理技术，如正射校正以校正几何失真和匹配滤波以增强烟柱信号。", "innovation": "我们提出了一种新的方法，通过使用未正射校正的数据（UnorthoDOS）绕过这些预处理步骤。发现基于这些数据集训练的ML模型能够在性能上与基于正射校正数据集训练的模型相当。我们还在正射校正数据集上训练模型，表明它们可以超越匹配滤波基准（mag1c）。我们也公开了正射校正和未正射校正的地球表层矿物粉尘源调查（EMIT）传感器的高光谱图像数据集和相关的代码。", "conclusion": "我们将提供ML模型的检查点和两个ML就绪的数据集，包括来自地球表面矿物粉尘源调查（EMIT）传感器的正射校正和未正射校正高光谱图像以及相关代码。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01292", "html_url": "https://arxiv.org/abs/2508.01292", "title": "CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis", "title_en": "CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis", "authors": "Alec Sargood,Lemuel Puglisi,James H. Cole,Neil P. Oxtoby,Daniele Ravì,Daniel C. Alexander", "background": "从更常见且易于获取的结构MRI模态合成淀粉样蛋白PET扫描为大规模阿尔茨海默病（AD）筛查提供了有前景且成本效益高的方法。尽管MRI不能直接检测淀粉样蛋白病理，但据证据显示，它可能仍能编码与淀粉样蛋白沉积相关的信息，这些信息可以通过先进的建模被揭示出来。然而，3D神经成像数据的高维度和结构复杂性为现有的MRI到PET转换方法带来了巨大挑战。在较低维度的潜在空间中建模跨模态关系可以简化学习任务并使转换更加有效。因此，本文提出了一种基于扩散的潜在生成框架CoCoLIT（ControlNet-Conditioned Latent Image Translation），涵盖了三个创新点：（1）一种新颖的加权图像空间损失（WISL），提高潜在表示的学习质量和合成质量；（2）对潜在均值稳定化（LAS）的理论和实证分析，这是一种在类似生成模型中用于提高推理一致性的现有技术；以及（3）提出了基于ControlNet的条件，用于MRI到PET的转换。我们在公开数据集上评估了CoCoLIT的表现，并发现我们的模型在基于图像和淀粉样蛋白相关的指标上都显著优于最先进的方法。特别是，在淀粉样阳性分类中，CoCoLIT在内部数据集上以+10.5%的优势超过了第二好的方法，在外部数据集上以+23.7%的优势领先。我们的方法的代码和模型可以在以下链接访问：this https URL.", "innovation": "CoCoLIT引入了三种创新：（1）加权图像空间损失（WISL），促进更高质量的潜在表示学习和生成；（2）对潜在均值稳定化（LAS）的理论与实证分析，一种已在类似生成模型中使用的技术，以提高推理一致性；（3）ControlNet的条件化，用于MRI到PET的转换。", "conclusion": "CoCoLIT在公开数据集上的表现证明了其显著优于最先进的方法，尤其是在淀粉样阳性分类上，它在内部和外部数据集上的表现分别提高了10.5%和23.7%。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05831", "html_url": "https://arxiv.org/abs/2509.05831", "title": "LLMs中隐藏攻击面的解码：Web摘要中的HTML提示注入", "title_en": "Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization", "authors": "Ishaan Verma,Arsheya Yadav", "background": "大型语言模型（LLMs）越来越多地被集成到基于Web的系统中用于内容摘要，但它们对提示注入攻击的易感性仍然是一个紧迫的问题。研究者探讨了如何利用非可见的HTML元素（如<meta>，aria-label 和alt属性）在不改变网页可见内容的情况下嵌入恶意指令。研究构建了一个包含280个网页的新型数据集，这些网页根据多种HTML策略分为纯洁和恶意注入版本，并通过浏览器自动化流程提取原始HTML和渲染文本，以模拟真实的LLM部署场景。", "innovation": "研究介绍了一个新的数据集，包含280个网页版本（140个纯洁版本和140个恶意注入版本），并使用两个最新的开源模型（Llama 4 Scout和Gemma 9B IT）评估了它们对隐蔽注入的反应。研究使用词法（ROUGE-L）和语义（SBERT余弦相似性）评估这些恶意注入的影响，并通过手动注释进一步评估。结果显示，29%的注入样本导致了Llama 4 Scout摘要的明显变化，而Gemma 9B IT的成功率为15%。", "conclusion": "研究发现，隐藏在可见内容下的恶意内容能够影响LLM驱动的网页摘要结果，揭示了LLM驱动的网页管道中的一个重要且很大程度被忽略的漏洞。研究提供了一个可复制的框架和基准来评估HTML基于的提示注入，并强调了在Web内容涉及的LLM应用中需要强有力缓解策略的紧迫性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19406", "html_url": "https://arxiv.org/abs/2509.19406", "title": "TimeMosaic：基于动态粒度片段和片段内解码的时间序列预测指导的时间域异质性", "title_en": "TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding", "authors": "Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan", "background": "多变量时间序列预测在金融、交通、气候和能源等领域中至关重要。然而，现有的基于补丁的方法通常采用固定长度的分割，忽略了局部时域动态和预测解码的异质性。这样的设计在信息密集区域丢失了细节，在稳定段引入了冗余，并且无法捕捉短期和长期时间段的独特复杂性。", "innovation": "该论文提出了TimeMosaic，一种旨在解决时间域异质性的预测框架。TimeMosaic采用自适应补丁嵌入，根据局部信息密度动态调整粒度，同时平衡模式重用与结构清晰度，保持时间连续性。此外，它引入了片段内解码，将每个预测时域视为相关的子任务，适应特定时域的难度和信息需求，而非应用单一统一的解码器。", "conclusion": "在基准数据集上的广泛评估显示，TimeMosaic在对比现有方法上提供了持续改进，且我们的模型在包含3210亿观测数据的大规模语料库上训练，达到了与当前最先进的时间序列预测模型相当的性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18711", "html_url": "https://arxiv.org/abs/2509.18711", "title": "RSVG-ZeroOV: 探索一种无需训练的框架以实现遥感图像中的零样本开放词汇视觉定位", "title_en": "RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images", "authors": "Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang", "background": "遥感视觉定位（RSVG）的目标是在遥感图像中基于自由形式的自然语言表达定位物体。现有的方法通常受到封闭词汇集的限制，这限制了它们在开放世界场景中的应用。虽然最近努力利用通用基础模型来处理开放词汇的RSVG，但这些方法高度依赖昂贵的高质量数据集和耗时的微调过程。这些限制激发了该研究，旨在开发一种无需训练的框架，以利用冻结的通用基础模型在零样本开放词汇的RSVG中探索潜在的能力。", "innovation": "该研究提出了RSVG-ZeroOV，这是一种无需训练的框架，主要创新在于三个方面：(i) Overview阶段利用视觉-语言模型（VLM）获得跨注意力图，捕捉文本查询和视觉区域之间的语义关联；(ii) Focus阶段利用扩散模型（DM）的精细建模先验填充对象在结构和形状信息上的空白，这是VLM经常忽略的部分；(iii) Evolve阶段引入简单的注意力进化模块以抑制无关的激活，产生更纯净的目标分割掩码。此外，该框架无需进行复杂的具体任务训练，提供了一种高效且可扩展的解决方案。实验表明，提出的框架在现有弱监督和零样本方法中表现出一致的优势。", "conclusion": "RSVG-ZeroOV通过利用冻结的通用基础模型和上述三个关键阶段，无需额外训练，提供了开放词汇的遥感图像零样本视觉定位的一种高效且可扩展的解决方案。研究表明该框架在现有方法中具有显著的性能优势。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19465", "html_url": "https://arxiv.org/abs/2509.19465", "title": "对交叉频率转移学习和基础预测模型的一种现实评估", "title_en": "A Realistic Evaluation of Cross-Frequency Transfer Learning and Foundation Forecasting Models", "authors": "Kin G. Olivares,Malcolm Wolff,Tatiana Konstantinova,Shankar Ramasubramanian,Boris Oreshkin,Andrew Gordon Wilson,Andres Potapczynski,Willa Potosnak,Michael W. Mahoney,Mengfei Cao,Dmitry Efimov", "background": "交叉频率转移学习（CFTL）作为一种用于预先训练大规模时间序列数据集的基础预测模型（FFMs）的流行框架，已经引起了广泛关注。然而，现有的基准测试方法未能准确评估其性能，存在的主要问题是：过度依赖小型评估数据集；在计算汇总统计时处理样本大小不足；报告次优统计模型；以及未考虑预训练和测试数据集之间的显著重叠风险。这些不足促成了该研究的提出，旨在改进CFTL的评估方法。", "innovation": "该研究引入了一种统一的重新实现，将通用的人工智能预报网络适应至CFTL设置，并仅在专有和合成数据上进行预训练，同时采取措施避免测试泄漏，使用15个大型、多样化的公共预报竞赛数据集进行评估。研究结果表明，统计模型的准确性经常被低估，尤其是统计模型及其集成在所有数据集上均表现出色，sCRPS和MASE分别比现有FFMs高出8.2%以上和20%以上。研究还发现，使用合成数据集预训练可以提高FFM的准确性7%。", "conclusion": "统计模型及其集成在所有数据集上显著优于现有FFMs，证明了通过CFTL使用统计模型进行预训练的有效性和优越性。此外，研究强调了在评估CFTL方法时需要更加严谨地考虑样本大小、数据泄露和风险因素。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21190", "html_url": "https://arxiv.org/abs/2509.21190", "title": "面向零样本时间序列异常检测的基石模型：利用合成数据和相对上下文差异", "title_en": "Towards Foundation Models for Zero-Shot Time Series Anomaly Detection: Leveraging Synthetic Data and Relative Context Discrepancy", "authors": "Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang", "background": "时间序列异常检测(TSAD)是一个关键任务，但在零样本情况下开发能够泛化的模型仍然是一项重大挑战。现有的基础模型多依赖于基于重构的目标，这类方法在识别细微异常时表现不佳，常常误判复杂的正常模式，导致高误报率和漏报率。", "innovation": "本文提出了TimeRCD模型，这是一种基于新型预训练范式的TSAD基础模型——相对上下文差异(RCD)。TimeRCD模型通过检测相邻时间窗口之间的重要差异来进行异常检测，而不是学习输入的重构。这种方法利用标准的Transformer架构捕捉异常上下文变化，这种变化通常被基于重构的方法所忽略。此外，为了实现这一范式，开发了一个大规模、多样化的合成数据集，带有标记的异常标签，提供了充分的监督信号来辅助预训练。实验结果表明，TimeRCD模型在零样本TSAD任务中显著优于现有的一般性和特定异常的基础模型。", "conclusion": "我们的结果验证了RCD范式的优越性，并确立了一条构建鲁棒且泛化能力强的时间序列异常检测基础模型的新有效路径。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20166", "html_url": "https://arxiv.org/abs/2509.20166", "title": "CyberSOCEval: 评估LLM在恶意软件分析和威胁情报推理方面的能力", "title_en": "CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning", "authors": "Lauren Deason,Adam Bali,Ciprian Bejean,Diana Bolocan,James Crnkovich,Ioana Croitoru,Krishna Durai,Chase Midler,Calin Miron,David Molnar,Brad Moon,Bruno Ostarcevic,Alberto Peltea,Matt Rosenberg,Catalin Sandu,Arthur Saputkin,Sagar Shah,Daniel Stan,Ernest Szocs,Shengye Wan,Spencer Whitman,Sven Krasser,Joshua Saxe", "background": "当前网络防御者面临着大量安全警报、威胁情报信号和不断变化的业务环境，迫切需要使用AI系统来提升运营安全工作。虽然大型语言模型（LLMs）有潜力自动化和扩大安全运营中心（SOC）的操作，但现有的评估尚未全面评估对现实世界防御者而言最相关的场景。这种有见识的评估不足影响了AI开发者和将LLMs应用于SOC自动化的用户。在缺乏对LLMs在现实世界安全场景中的表现的清理解的情况下，开发者缺乏一个指导开发的北极星，而用户也无法可靠地选择最有效的模型。与此同时，恶意行为者正在利用AI来放大网络攻击，突显了需要开放源代码基准来促进采用并推动防御者和模型开发者社区驱动改进的需求。", "innovation": "本文引入了CyberSOCEval，一个新的开源评估套件，作为CyberSecEval 4的一部分，专门用于评估LLMs在两个核心防御领域（恶意软件分析和威胁情报推理）中的性能，这是当前基准测试中尚未充分覆盖的领域。我们的评估结果显示，更大的、更现代的LLMs通常表现更好，证实了训练规模的定律。我们还发现，相较于编码和数学推理，使用测试时间缩放的推理模型未能达到相同的提升，暗示这些模型并未被训练来应对网络安全分析，这指出了改进的关键机会。", "conclusion": "当前的LLMs尚未完全满足我们的评估标准，这表明CyberSOCEval为代表AI开发者提供了显著的挑战，以提升网络安全防御能力。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26601", "html_url": "https://arxiv.org/abs/2509.26601", "title": "MENLO：从偏好到精通——跨47种语言评估和建模原汁原味的质量", "title_en": "MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages", "authors": "Chenxi Whitehouse,Sebastian Ruder,Tony Lin,Oksana Kurylo,Haruka Takagi,Janice Lam,Nicolò Busetto,Denise Diaz,Francisco Guzmán", "background": "确保大型语言模型（LLM）在多种语言中产生原汁原味的回答具有挑战性。为此，研究引入了MENLO框架，该框架通过借鉴受众设计机制实现了对原汁原味响应质量的评价。研究者利用MENLO框架构建了一个包含6,423个人标注的提示-回答偏好对的数据集，覆盖四个质量维度，并在47种语言变体中实现了高跨标注者一致性。研究表明，零样本LLM判读者在成对评价和结构化标注评判标准的帮助下显著受益，但在我们的数据集中仍然不及人类标注者的表现。", "innovation": "研究提出了MENLO框架，通过借鉴受众设计机制进行原汁原味响应质量评价；构建了包含6,423个人标注的提示-回答偏好对的数据集；并通过强化学习、奖励重塑和多任务学习方法实现了显著改进；展示了通过强化学习训练的判定者可以作为生成奖励模型，提升LLM的多语言能力，尽管在人类判断方面仍存在差异。", "conclusion": "研究发现，MENLO框架为大规模多语言评估和偏好对齐提供了有希望的方向。研究团队发布了该数据集和评估框架，以支持进一步的多语言LLM评估研究。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的认识多样性与知识坍塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Peter Ebert Christensen,Chan Young Park,Isabelle Augenstein", "background": "现有的大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度同质化的文本。这种同质化可能导致知识坍塌现象，即，随着时间推移，可供访问的信息范围逐渐缩小。尽管已有研究关注同质化问题，但这些研究多集中在封闭式多项选择场景或模糊的语义特征上，未能考察跨时间与文化背景的变化趋势。", "innovation": "本文提出了一种新的方法来测量知识多样性，即通过评估LLM输出中关于现实世界主张的变异情况，进行了一项广泛的实证研究，以此来考察LLM的知识坍塌。研究覆盖了27种不同的LLM、155个主题（涵盖12个国家），和200种不同样式的提示（来源于真实用户的对话）。研究表明，尽管新模型生成的主张更多样化，但几乎所有模型在认识多样性上都不如基础的网络搜索。同时还发现，模型规模对认识多样性有负面影响，而检索增强生成（RAG）有正面影响，尽管这种改善受文化背景的影响程度不同。此外，与传统的知识来源（维基百科）相比，发现国家特定的主张更偏向英语而非当地语言，揭示了认识表达存在差距。", "conclusion": "本文的研究表明，虽然新模型在生成主张多样性方面有所进步，但所有模型的表现仍不及基本网络搜索；模型规模限制了其认识多样性，而RAG则有助于提升，但效果因具体文化背景而异；此外，国家特定的主张偏向英语而非当地语言，显示了认识表达的不足。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08576", "html_url": "https://arxiv.org/abs/2510.08576", "title": "大型语言模型（LLMs）在机器协助解决用户意图方面的比较分析", "title_en": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "authors": "Justus Flerlage,Alexander Acker,Odej Kao", "background": "大型语言模型（LLMs）已成为自然语言理解和用户意图解决的强大工具，支持翻译、总结等任务，而且越来越多地用于复杂工作流的编排。这标志着从传统的基于GUI的用户界面向语言驱动的第一代交互模式转变。用户可以直接用自然语言表达自己的目标，使得LLMs能够跨多个应用程序动态灵活地执行操作。然而，现有实现通常依赖于基于云的专有模型，这在隐私、自主性和可扩展性方面存在局限。因此，为了使语言驱动的交互成为真正可靠和可信的接口模式，本地部署成了一种必要，这也突显了评估可本地部署、开源和开放接入的LLMs作为未来基于意图操作系统基础组件的可行性的重要性。", "innovation": "研究比较分析了几种开源和开放接入的模型在通过机器协助解决用户意图方面的表现，与OpenAI的专有GPT-4系统进行了对比，评估其生成不同用户意图工作流的性能，提供实证洞察力，探讨开放LLMs作为自主的、本地可运行组件在下一代操作系统中的应用潜力，以及它们对重构AI基础设施分散和普及化的影响。", "conclusion": "研究结果提供了关于开放LLMs在下一代操作系统的实际可行性、性能权衡和潜力的实证见解，对讨论AI基础设施的分散和普及化产生了影响，并指出了一个未来，用户设备之间的交互将更加无缝、适应和隐私意识强，同时嵌入本地智能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07286", "html_url": "https://arxiv.org/abs/2510.07286", "title": "蛋白质进化概况用于预测蛋白质的适应性", "title_en": "Evolutionary Profiles for Protein Fitness Prediction", "authors": "Jigang Fan,Xiaoran Jiao,Shengdong Lin,Zhanming Liang,Weian Mao,Chenchen Jing,Hao Chen,Chunhua Shen", "background": "蛋白质工程中预测突变的适应性影响至关重要，但由于序列空间庞大而评估试验有限，这是个挑战。蛋白质语言模型（pLMs）通过掩蔽语言模型（MLM）训练，展示出了强零样本适应性预测能力。本文作者提出一种统一视角，认为自然进化可以看作隐式奖励最大化的过程，而MLM可以作为一个逆强化学习（IRL）过程，现有序列作为专家演示，pLM对数似然作为适应性估计。基于这一视角，本文引入了EvoIF模型，该模型结合了两部分进化信号：同家族成员的序列特征和从逆折叠对数概率中提取的跨家族结构-进化约束。EvoIF通过紧凑的过渡块将序列-结构表示融合其中，提供对对数似然评分的校准概率。", "innovation": "提出了一种结合同家族序列特征和跨家族结构-进化约束的EvoIF模型，利用紧凑的过渡块将序列-结构表示结合在一起，通过掩蔽语言模型（MLM）训练，展示出了在蛋白质健身预测上的强零样本预测能力，仅使用0.15%的训练数据和比最近的大型模型更少的参数，实现了最先进的或可竞争的表现，且通过消融测试证明了同家族和跨家族特征的互补性，提升了对不同功能类型、蛋白质族深度、分类和突变深度的鲁棒性。代码将公开发布。", "conclusion": "EvoIF模型和其基于多序列对齐的变体在ProteinGym数据集上实现了最先进的或可竞争的表现，同时仅使用了0.15%的训练数据和更少的参数，证明了结合同家族和跨家族序列进化特征的重要性，提升了模型在不同情况下的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15267", "html_url": "https://arxiv.org/abs/2510.15267", "title": "TraceCoder：通过多源知识整合实现可追溯的ICD编码", "title_en": "TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration", "authors": "Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng", "background": "国际疾病分类（ICD）编码在卫生系统中起着关键作用，但现有方法面临临床文本与ICD代码之间的语义差距、在处理罕见和长尾代码时表现不佳、以及缺乏可解释性等问题。", "innovation": "提出了一种名为TraceCoder的新颖框架，该框架整合了多种外部知识来源，以增强ICD编码的可追溯性和解释性。TraceCoder动态地整合了包括UMLS、维基百科和大规模语言模型（LLMs）在内的多种知识来源，丰富了代码表示，填补了语义差距，并处理了罕见和模糊的代码。它还引入了一种混合注意力机制来建模标签、临床背景和知识之间的交互，以改善长尾代码的识别，并通过外部证据使预测具有可解释性。实验结果表明，TraceCoder在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上取得了最先进的性能，消融研究验证了其组件的有效性。", "conclusion": "TraceCoder提供了一种可扩展且稳健的自动ICD编码解决方案，能够满足临床对准确、可解释性和可靠性需求。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15269", "html_url": "https://arxiv.org/abs/2510.15269", "title": "TACL: 阈值自适应课程学习策略以增强医学文本理解", "title_en": "TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding", "authors": "Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng", "background": "医疗文本，尤其是电子医疗记录（EMRs），是现代医疗的核心，记录了患者护理、诊断和治疗的关键信息。这些文本具有巨大的潜力，用于促进临床决策和医疗数据分析。然而，由于其非结构化特性、专业领域的语言以及不同上下文中的变异，自动理解这些文本构成了一项复杂的挑战。尽管在自然语言处理方面取得了进展，但现有方法往往忽略了临床记录中固有的复杂性差异，对待所有数据同等对待。这种忽视限制了模型的有效泛化能力，尤其是对罕见或复杂的病例。", "innovation": "本文介绍了TACL（阈值自适应课程学习）框架，这是一种旨在解决这些挑战的新颖方法，通过重新思考模型在训练期间与医疗文本的互动方式。TACL受渐进学习原理的启发，动态调整训练过程以适应个别样本的复杂性。它通过将数据分为难度级别并在训练初期优先处理较简单的案例，从而为复杂记录的处理奠定坚实基础。通过将TACL应用于包括英语和中文在内的多语言临床数据，我们观察到在自动ICD编码、再入院预测和中医辨证分型等多种临床任务中表现出了显著的增长。", "conclusion": "TACL不仅提高了自动化系统的性能，还展示了在不同医疗领域采用统一方法的潜力，这是更准确、更具扩展性和全球适用性的医学文本理解解决方案的必由之路。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.13795", "html_url": "https://arxiv.org/abs/2510.13795", "title": "Bee: 一种高品质语料库和全栈套件，解锁高级开放大型语言模型", "title_en": "Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs", "authors": "Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu", "background": "目前，完全开放的多模态大语言模型（MLLMs）与专有版本相比存在差距，主要原因是监督微调（SFT）数据集的质量不足。现有的开源数据集往往受到大量噪声的影响，并且缺乏复杂推理数据，特别是链式推理（CoT），这阻碍了高级模型能力的发展。", "innovation": "本文做出了三项主要贡献。首先，引入了包含约1500万个QA对的新SFT数据集——Honey-Data-15M，经过多种清理技术处理并加入了新颖的双重级别（短和长）CoT增强策略；其次，提出了数据编排管道HoneyPipe及其实现框架DataStudio，为社区提供了透明且适应性强的数据编排方法，超越了静态数据集发布；最后，使用Honey-Data-15M训练出了Bee-8B模型，实验结果显示Bee-8B在完全开放的MLLM中建立了新的技术水平，其性能与近期部分开放模型（如InternVL3.5-8B）相当并在某些方面超越其。作者的工作为社区提供了一整套基础资源：Honey-Data-15M语料库、包含HoneyPipe和DataStudio的全栈套件、训练方案、评估框架及模型权重，证明了关注数据质量是开发具有高度竞争力的完全开放MLLM的关键路径。", "conclusion": "本研究通过专注于数据质量，提出了一种方法，能够使完全开放的LLMs在性能上达到接近甚至超越部分开放模型的水平。通过Honey-Data-15M数据集和HoneyPipe及DataStudio框架的引入，为开发高质量的开放LLMs奠定基础。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22026", "html_url": "https://arxiv.org/abs/2510.22026", "title": "注意力动态中的归一化", "title_en": "Normalization in Attention Dynamics", "authors": "Nikita Karagodin,Shu Ge,Yury Polyanskiy,Philippe Rigollet", "background": "本文研究了归一化方案对深层变压器中词元表示的影响。通过将归一化过程视为作用于球体上的相互作用粒子，作者展示了归一化如何作为速度调节的形式。", "innovation": "本文提出了一种新的视角，通过将归一化过程视为相互作用的粒子模型，整合并分析了多种归一化方案（包括Post-LN、Pre-LN、Mix-LN、Peri-LN、nGPT等），揭示了这些方案如何影响聚类动力学和表示坍缩。此外，该框架还阐明了不同归一化方案如何塑造不同层中的词元表示，并为比较这些方案提供了理论基础。", "conclusion": "本文框架阐明了不同方案如何塑造不同层中的词元表示，并明确指出Peri-LN方法尤其有效。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16565", "html_url": "https://arxiv.org/abs/2510.16565", "title": "语言优先于内容：追踪多语言大型语言模型中的文化理解", "title_en": "Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models", "authors": "Seungho Cho,Changgeon Ko,Eui Jun Hwang,Junmyeong Lee,Huije Lee,Jong C. Park", "background": "随着大型语言模型（LLMs）在多元文化背景下被广泛应用，准确的文化理解变得至关重要。以往的研究主要集中在输出层面的性能评估，忽视了驱动不同响应背后的因素。使用电路分析的研究虽然包括了少量语言，但很少关注文化层面的问题。这项研究通过对比在不同条件下回答语义等价问题时模型内部的文化理解机制差异，追踪LLMs的内部文化理解机制，使用同语言不同国家的配对来区分语言和文化的影响。结果显示，对于同语言不同国家的问题，内部路径的重叠更多，而对不同语言相同国家的问题重叠较少，表明存在强烈的语言特定模式。值得注意的是，韩国和朝鲜之间的配对显示出低重叠和高变异，说明语言相似性并不能保证内部表征的一致性。", "innovation": "该研究创新性地通过内部激活路径的重叠度来追踪多语言大型语言模型中的文化理解机制，同时引入了同语言不同国家的配对来区分语言和文化因素的影响，揭示了语言特定的模式和不同国家间的文化差异。", "conclusion": "研究结果显示，语言对模型内部文化理解有显著影响，尤其是在不同国家间的文化理解上，而语言相似性并不能保证内部表征的一致性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18713", "html_url": "https://arxiv.org/abs/2510.18713", "title": "超越成对比较的偏好强化学习：多种选项的优势", "title_en": "Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options", "authors": "Joongkyu Lee,Seouh-won Yi,Min-hwan Oh", "background": "近年来，成对偏好强化学习（PbRL）由于其在大型语言模型（LLM）对齐上的实证成功而受到了越来越多的理论研究关注，但大多数现有研究只关注成对比较。虽然有少数研究尝试使用多种比较和排名反馈（如Zhu等，2023；Mukherjee等，2024；Thekumparampil等，2024），但这些方法的性能保证并未随着反馈长度增加而改善，有时甚至恶化，因为它们没有充分利用额外的信息。", "innovation": "该论文引入了Plackett-Luce（PL）模型来处理动作子集的排名反馈，并提出了M-AUPO算法。该算法通过最大化所提供的子集内的平均不确定性来选择多个动作。论文证明了M-AUPO的次优性间隙为$\tilde{O}\big(\frac{d}{T} \times \big( \frac{1}{|S_t|} \big)^{\frac{1}{2}}\big)$，其中$T$是总轮数，$d$是特征维度，而$|S_t|$是第$t$轮的子集大小。这一结果表明，较大的子集直接导致了性能改善，并且限制条件避免了对未知参数范数的指数依赖，这是大多数先前工作中的一个根本局限。此外，论文还建立了接近匹配的下界$\big(\frac{d}{K \times \big(T\big)^{\frac{1}{2}}}\big)$，其中$K$是最大子集大小。", "conclusion": "该研究证明了利用丰富反馈相比成对比较的优越性，并提出了改进样本效率（尤其是对于较大子集）的新算法。这是首次在偏好强化学习中明确显示样本效率随子集大小增加而改善的理论成果。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03753", "html_url": "https://arxiv.org/abs/2511.03753", "title": "在异构物联网设备上使用 Gramian 角度字段的联邦学习方法的隐私保护心电图分类", "title_en": "Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices", "authors": "Youssef Elmir,Yassine Himeur,Abbes Amira", "background": "该研究探讨了在物联网（IoT）医疗环境中，如何通过联邦学习（Federated Learning，FL）框架实现心电图（ECG）的隐私保护分类。通过将一维的心电图信号转化为二维的Gramian角字段（GAF）图像，该研究提出了一种方法，利用卷积神经网络（Convolutional Neural Networks，CNNs）进行高效的特征提取，同时保证敏感的医疗数据保留在每个设备上。这项工作首次通过实验验证了使用GAF的联邦心电图分类在异构物联网设备中的应用效果，量化了其性能和通信效率。", "innovation": "该研究的创新点在于首次利用GAF进行联邦心电图分类，并在异构的物联网设备上进行了实际部署，并且该方法同时在保持数据隐私的同时提高了分类性能和通信效率。实验结果显示，在多客户端设置下，FL-GAF模型的分类准确率为95.18%，相比单一客户端的基线，在准确率和训练时间上表现显著更好。尽管引入了GAF标准化带来的计算复杂度增加，但该框架仍能保持高效资源利用和通信开销。", "conclusion": "该研究强调了轻量级、隐私保护的AI技术在物联网驱动的健康监测中的潜力，支持可扩展且安全的边缘部署在智能健康系统中。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03295", "html_url": "https://arxiv.org/abs/2511.03295", "title": "如何使用源感知神经机器翻译指标评估语音翻译", "title_en": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics", "authors": "Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli", "background": "传统的语音到文本（ST）系统的自动评估方法通常是通过比较翻译假设与一个或多个参考翻译来完成的。虽然这种方法在一定程度上是有效的，但它继承了参考基评估的局限性，即忽略了源输入中的有价值信息。最近，机器翻译（MT）中的研究表明，将源文本纳入神经度量，可以与人类判断实现更紧密的相关性。然而，将这种理念扩展到语音翻译并不直接，因为源是音频而非文本，可靠的文字转录或源与参考之间的对齐往往不可用。", "innovation": "本研究首次系统地探讨了语音翻译（ST）中的源感知度量，并特别关注没有可用来源转录的实际操作条件。研究探索了自动化语音识别（ASR）转录和参考翻译的反向翻译两种补充策略，以生成输入音频的文本代理。并引入了一种新的跨语言重分割算法，以解决合成来源与参考翻译之间对齐不匹配的问题。实验结果表明，在词错误率低于20%的情况下，ASR转录比反向翻译更可靠作为合成源，而反向翻译始终是计算成本较低但仍然有效的替代方案。此外，这项跨语言重分割算法使得能够使用系统的方法在ST评估中利用源感知的MT指标，为更准确和有原则的语音翻译评估方法开了先河。", "conclusion": "实验表明，ASR转录在语音错误率低于20%的情况下提供了更可靠的合成源，而反向翻译是计算上更为便宜但仍然有效的替代方案。此外，提出的跨语言重分割算法为使用源感知的MT度量来进行ST评估奠定了基础，促进了更精确和原则性的ST评估方法的发展。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04505", "html_url": "https://arxiv.org/abs/2511.04505", "title": "刑事司法中的替代公平与准确度优化", "title_en": "Alternative Fairness and Accuracy Optimization in Criminal Justice", "authors": "Shaolong Wu,James Blume,Geshi Yeung", "background": "算法公平性已成为一个迅速发展的研究领域，尤其是在刑事司法领域。然而，关于公平性的核心概念仍然未有定论，尤其是在处理刑事司法问题时。本文回顾了群体公平性、个体公平性及过程公平性，并探讨了它们之间的潜在冲突。随后，提出了一种对标准群体公平性的简单修改，即在最小化加权错误损失的同时，保持不同保护群体的假 negatives 率之间的差异在可接受的范围内。", "innovation": "提出了一种简单的群体公平性修改方案，即在允许假 negatives 率差异在一定范围内的情况下，通过最小化加权错误损失来进行优化。这使得解决方案更容易找到，并可能提高预测准确性，同时揭示了对错误成本的道德选择。", "conclusion": "本文将该提议置于三个批评类别之下：有偏见和不完整的数据、潜在的隐含的积极行动以及子群体约束的爆炸。最后，提出了一个实用框架来部署基于风险管理及相关工具的公共决策系统，该框架由基于需求的决策、透明度和问责制、以及精确定义和解决方案的三大支柱构成。这些要素将技术设计与合法性联系起来，为使用风险评估及相关工具的机构提供了可操作的指导。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.00810", "html_url": "https://arxiv.org/abs/2511.00810", "title": "GUI-AIMA: 推动固有跨模态注意力与上下文锚点融合以实现GUI定位", "title_en": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "authors": "Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang", "background": "图形用户界面（GUI）接地是计算机使用代理的关键功能之一，它需要将自然语言指令映射到可操作的屏幕区域。现有的基于多模态大型语言模型（MLLMs）的方法通常将其形式化为文本坐标生成任务。但从视觉输入直接生成精确的点击坐标仍然具有挑战性且计算量大。一个直觉的实现GUI接地的方式是首先选择与指令相关的视觉片段，然后确定这些片段中的精确点击位置。观察到一般的MLLMs具有固有的某些接地能力，这些能力嵌在其注意力机制中。因此，提出了一种基于注意力机制且不依赖坐标的方式，即GUI-AIMA，进行了监督微调，以实现高效的GUI接地。GUI-AIMA利用MLLMs本身的多模态注意力与按片段的接地信号进行对齐。这些信号是通过简化查询-视觉注意力矩阵的多头聚合计算得到的。此外，无坐标的特性使其易于集成一个即插即用的放大功能。GUI-AIMA-3B仅用85k屏幕截图进行训练，展现出出色的训练效率，证实了轻松激活MLLMs固有接地能力的可能性。该模型在ScreenSpot-Pro数据集上平均准确率达到59.6%，在OSWorld-G数据集上为63.8%，在ScreenSpot-v2数据集上达到91.5%的优异表现。", "innovation": "提出了一种基于注意力机制且不依赖坐标的监督微调框架，即GUI-AIMA，实现了高效的GUI接地。利用MLLMs本身的多模态注意力与按片段的接地信号进行对齐，并通过简化查询-视觉注意力矩阵进行多头聚合计算信号。此外，框架的无坐标特性使其易于集成一个即插即用的放大功能。GUI-AIMA-3B仅用85k屏幕截图进行了训练，展示出出色的训练效率和灵活性，验证了轻量级训练可以激发MLLMs的固有接地能力。", "conclusion": "与3B模型相比，该模型在ScreenSpot-Pro数据集上的平均准确性为59.6%，在OSWorld-G数据集上为63.8%，在ScreenSpot-v2数据集上达到91.5%的最佳精度。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03912", "html_url": "https://arxiv.org/abs/2511.03912", "title": "无监督的学习未知：基于随机权重平均正态分布的增量异常学习在无专家监督医学成像中的应用", "title_en": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging", "authors": "Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)", "background": "在医学影像中，未知异常检测仍然是一个基本挑战，因为标记的异常数据稀缺且专家监督的成本高昂。目前的方法依赖于有标签的异常数据和生成模型重建，这增加了计算开销并可能导致误包含。我们介绍了一种无监督的、无需专家监督的框架，该框架可以逐步扩展可信的正常样本集合，而不需要任何异常标签。", "innovation": "该框架从少量验证的正常图像种子开始，交替更新轻量级适配器并根据不确定性门控样本接收。该方法利用一个紧凑的核心集存储提取的特征嵌入，从而实现高效的k-最近邻异常评分。通过双概率门控机制确保增量扩展过程中的安全性，这能够避免漂移和误包含，而无需依赖生成重建或重播缓冲。实验结果表明，该系统能有效利用逐步到来的未标记数据，显著超越了基线方法，特别是在COVID-CXR、肺炎CXR和脑MRIND-5数据集上的表现尤为显著，AUC等指标有了显著的提升。", "conclusion": "我们的方法有效地解决了标签稀缺的医学成像应用中的未知异常检测问题，提高了检测的准确性和效率，为医学影像领域提供了一种有效的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03866", "html_url": "https://arxiv.org/abs/2511.03866", "title": "OMPILOT: 利用变压器模型进行自动并行化到共享内存计算模式", "title_en": "OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms", "authors": "Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari", "background": "最近，大规模语言模型（LLMs）在代码翻译方面取得了显著进展，使其能够更准确和高效地在不同编程语言之间进行转换。虽然最初是为自然语言处理开发的，LLMs 已展示出强大的编程语言语法和语义建模能力，超越了传统的基于规则的系统，在准确性与灵活性上更具优势。这些模型简化了跨语言转换，减少了开发负担，并加速了遗留代码的迁移。", "innovation": "OMPILOT 是一种针对 C++ 翻译成 OpenMP 代码的新颖领域专用编码解码变压器，可以通过有效地实现共享内存并行化操作。OMPILOT 利用定制的预训练目标，结合无监督和监督学习策略来提高代码翻译的鲁棒性。与以前主要关注循环层翻译的工作不同，OMPILOT 在函数级别运行，以捕捉更广泛的语义上下文。此外，为了评估这种新的方法，提出了 OMPBLEU，这是一个新的复合指标，专门用于评估 OpenMP 并行结构的正确性和质量，解决了传统翻译指标的局限性。", "conclusion": "本文介绍了 OMPILOT，一种专为 C++ 翻译到 OpenMP 而设计的编码解码变压器，通过自动并行化促进共享内存计算模式。通过定制的预训练目标和结合无监督与监督学习策略，OMPILOT 提高了代码翻译的鲁棒性。不同于以往主要集中于循环层级的转换，OMPILOT 在函数级别进行操作以获得更广泛的语义上下文。此外，还提出了 OMPBLEU 评估指标来评估 OpenMP 并行结构的正确性和质量。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05459", "html_url": "https://arxiv.org/abs/2511.05459", "title": "SWE-Compass：迈向大语言模型生成性编程能力统一评估", "title_en": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models", "authors": "Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Mengtong Li,Mengfei Xie,Xiaojiang Zhang,Jinghui Wang,Wenhao Zhuang,Zheng Lin,Huiming Wang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu", "background": "大语言模型（LLMs）在软件工程领域的评估受到了单一任务覆盖范围、语言偏见以及与实际开发者工作流程不一致的限制。现有基准通常关注算法问题或Python中心的错误修正，导致软件工程中的许多关键维度未被充分探索。为了填补这些空白，我们提出了SWE-Compass，这是一个综合基准，将异构代码评估统一到结构化的、面向生产环境的框架中。", "innovation": "我们引入了SWE-Compass，这是一个全面的基准，涵盖了8种任务类型、8种编程场景和10种编程语言，通过系统筛选和验证从真实的GitHub拉取请求中精心挑选了2000个高质量实例。我们使用两种代理框架SWE-Agent和Claude Code对十种最先进的LLMs进行了基准测试，揭示了任务类型、语言和场景之间的难度等级差异。通过与实际的开发者实践保持一致，SWE-Compass为诊断和提升大语言模型的代理编码能力提供了严格的、可重复的基础。", "conclusion": "SWE-Compass通过与真实的世界开发者操作实践对齐，提供了诊断和推进大语言模型生成性编码能力的坚实基础。这一基准揭示了不同任务类型、语言和场景下的清晰难度层次，对于改善和评估LLMs在软件工程中的应用具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05625", "html_url": "https://arxiv.org/abs/2511.05625", "title": "人工智能辅助的研讨会报告", "title_en": "Report from Workshop on Dialogue alongside Artificial Intelligence", "authors": "Thomas J McKenna(Boston University),Ingvill Rasmussen(University of Oslo),Sten Ludvigsen(University of Oslo),Avivit Arvatz(The Hebrew University of Jerusalem),Christa Asterhan(The Hebrew University of Jerusalem),Gaowei Chen(The University of Hong Kong),Julie Cohen(University of Virginia),Michele Flammia(Independent Scholar),Dongkeun Han(University of Cambridge),Emma Hayward(University of Cambridge),Heather Hill(Harvard University),Yifat Kolikant(The Hebrew University of Jerusalem),Helen Lehndorf(Freie Universität Berlin),Kexin Li(The University of Hong Kong),Lindsay Clare Matsumura(University of Pittsburgh),Henrik Tjønn(University of Oslo),Pengjin Wang(The University of Hong Kong),Rupert Wegerif(University of Cambridge)", "background": "教育对话被认为促进了深入学习和批判性思维，并且人工智能（AI）因其可能推动解决教育中的重大挑战、个性化学习及创新教学法而迅速成为教育领域的强势力量。然而，AI的快速发展也可能损害人类自主性、加剧不平等，并超出我们的政策指导能力。因此，国际研讨会“教育对话：促进思维进步”聚集了来自11个国家的19位领先研究者探讨AI与教育对话的交叉点。", "innovation": "研讨会聚焦于三个关键问题：（1）在什么情况下AI真正有助于教育，哪些情况下它可能只是取代人类工作而削弱学习效果？（2）在什么条件下AI的使用可以提升对话式的教学与学习？（3）AI与人类的合作是否会超越并取代人类教育工作，对这一问题有何影响？这些问题被用来指导两天的演讲和结构性对话。", "conclusion": "研讨会上，参与者就AI与教育对话的交叉影响进行了深入讨论，探讨了AI在教育中的价值与风险，并强调了政策引导在管理这一领域进步的重要性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05540", "html_url": "https://arxiv.org/abs/2511.05540", "title": "Token Is All You Need: 认知通过信念-意图共进化规划所需的一切", "title_en": "Token Is All You Need: Cognitive Planning through Belief-Intent Co-Evolution", "authors": "Shiyao Sang", "background": "传统的假设是，为了实现高性能的端到端自动驾驶（E2EAD），需要进行全面的场景建模。受到认知科学的启发，本文提出有效的规划不来源于重建世界，而是来自少量丰富语义的信念和意图的共进化。研究在nuPlan基准数据集上（包含720个场景，超过11,000个样本）进行，验证了这一观点。研究表明，在仅使用稀疏的意图标记的情况下就具有良好的性能，并且通过条件化轨迹解码来预测未来标记可以进一步提高性能。研究表明，任务驱动下的信念-意图共进化足以在可靠的感知输入下工作，没有需要预测未来。", "innovation": "本文提出了一种新的方法，即通过信念-意图共进化利用少量丰富的语义标签进行认知规划，而不需要进行全面的场景重建。通过这种方式，模型可以自发地发展出一种推理机制，平衡当前的感知和未来的意图。从而，无需预测未来也能处理不确定性并实现持续自我优化。此外，还建立了一个新的范式，即智能的关键不在于像素保真度，而在于信念和意图的标记化双重性。通过改变规划视角为理解而非反应，该方法弥合了世界模型和多智能体系统之间的差距，为前瞻智能代理的发展奠定了基础。", "conclusion": "本文通过认知科学的灵感，提出了一种新的通过信念-意图共进化进行规划的方法，证明了少量丰富的语义标签可以实现高效的自动驾驶任务，尤其是在感知可靠的条件下。这种方法不需要全面的场景重建，能够提供认知一致性，并能够处理不确定性。从而，提出了一个新的智能观念，即重点在于信念和意图的标记化双重性而不是像素保真度。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05529", "html_url": "https://arxiv.org/abs/2511.05529", "title": "以准确率加权的深层成ensemble和熵引导的规避进行的选择性糖尿病视网膜病变筛查", "title_en": "Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Abstention", "authors": "Jophy Lin", "background": "糖尿病视网膜病变（DR）是一种糖尿病的微血管并发症，也是导致可预防失明的主要原因之一。预计到2030年，这一疾病将影响超过1.3亿人。现有的诊断流程依赖于基础摄影和专家审查等方法，这些方法成本较高且需要大量资源。这与DR无症状的性质结合，导致其诊断率高达约25%。尽管卷积神经网络（CNNs）在医学成像任务中表现出色，但它们有限的可解释性和缺乏不确定性量化限制了临床可靠性。因此，本文介绍了一种集成模糊量化估计的深度模型集成框架，以提高糖尿病视网膜病变检测的稳健性、透明性和可扩展性。该集成结合了7种CNN架构，通过准确率加权多数投票策略融合输出，并利用加权熵度量量化预测不确定性，以排除或标记低置信度的样本进行额外审查。", "innovation": "该研究提出了一种准确性加权的深层模型集成框架，结合了熵引导的避免策略，用于糖尿病视网膜病变的检测。这种方法通过准确率加权多数投票融合七种CNN架构的输出，并使用质量加权熵度量量化预测不确定性。通过在35,000张EyePACS眼底图像上进行训练和验证，该框架在未过滤的准确性方面达到了93.70%（F1 = 0.9376），通过不确定性过滤后，准确率提高到99.44%（F1 = 0.9932）。这种方法展示了一个在高风险护理中部署可信人工智能诊断的一般化范式，结合了可校准的信心输出和可调的准确度-覆盖范围权衡。", "conclusion": "该框架通过不确定性意识、准确性加权集成提高了可靠性，同时不损害性能，提供了高风险护理中部署可信AI诊断的一般化范式，包括校准的信心输出和可调的准确度-覆盖率权衡。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05784", "html_url": "https://arxiv.org/abs/2511.05784", "title": "DRAGON: 通过负向检测和推理来保护LLM的在上下文中遗忘", "title_en": "DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning", "authors": "Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu", "background": "大型语言模型(Large Language Models, LLMs)在保护私人数据和移除有害知识方面，需要学习忘记机制来提高安全性。现有的方法通常依赖于微调来平衡遗忘效率与普遍的语言能力，但这些方法需要在实际场景下访问训练数据或保留数据，这在现实中往往不可行。尽管在有遗忘数据和保留数据的情况下，这些方法可以表现出色，但在数据有限的实际应用场景中，较少有工作展示出相同的能力。", "innovation": "本文提出了一种名为DRAGON（Detect-Reasoning Augmented GeneratiON）的系统推理框架，它利用上下文中的链式思考指令，在推理前保护已部署的LLM。DRAGON利用了LLMs的内置指令遵循能力，并引入了一个轻量级的检测模块，用于识别需要遗忘的指令而无需保留数据。遗忘指令随后通过专用的链式思考保护模型来施行，以确保在上下文中的干预是安全且准确的。此外，为了更全面地评估遗忘性能，引入了新的遗忘性能评估指标和持续遗忘设置。", "conclusion": "广泛的实验验证了DRAGON的有效性，证明了其强大的遗忘能力、可扩展性和在实际应用场景中的适用性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05844", "html_url": "https://arxiv.org/abs/2511.05844", "title": "通过校准和正则化增强扩散模型的指导", "title_en": "Enhancing Diffusion Model Guidance through Calibration and Regularization", "authors": "Seyed Alireza Javid,Amirhossein Bagheri,Nuria González-Prelcic", "background": "分类器指导的扩散模型在条件图像生成中已成为一种强大的方法，但它们在早期去噪步骤中会产生过于自信的预测，导致指导梯度消失。", "innovation": "提出了两种互补的贡献以解决这一问题。首先，提出了一种基于平滑预期校准误差（Smooth ECE）的可微校准目标，该目标在最少微调的情况下改善了分类器校准，并在Frechet Inception Distance (FID)上带来了可测量的改进。其次，开发了增强采样指导方法，这些方法在不需重新训练的情况下对现成的分类器进行操作。这些方法包括带有批次重新加权的倾斜采样，适应性熵正则化采样以保持多样性，以及一种新的基于f-散度的采样策略，该策略增强了类一致指导的同时保持模式覆盖率。", "conclusion": "我们的散度正则化指导在使用ResNet-101分类器时实现了2.13的FID，超过现有的分类器指导的扩散方法，并且无需对扩散模型进行重新训练。这些结果表明，理论校准和散度感知采样为分类器指导的扩散提供了实用和有效的改进。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06285", "html_url": "https://arxiv.org/abs/2511.06285", "title": "使用频率增强双路径网络利用会话间信息进行序列推荐", "title_en": "Exploiting Inter-Session Information with Frequency-enhanced Dual-Path Networks for Sequential Recommendation", "authors": "Peng He,Yanglei Gan,Tingting Dai,Run Lin,Xuexin Li,Yao Liu,Qiao Liu", "background": "序列推荐（SR）的目标是通过建模用户的过去互动序列来预测其下一个项目的偏好。近年来，越来越多的研究引入了频域模块，以克服自注意力机制低通特性的影响，重新引入对个性化推荐至关重要的高频信号。然而，现有的频域意识解决方案将每个会话孤立处理，并且仅基于时域目标进行优化，因此忽略了会话间的频谱依赖关系，并未能确保预测和真实频谱签名之间的对齐，从而导致高频信息未充分利用.", "innovation": "本文提出了一种名为FreqRec的频域增强双路径网络，通过可学习的频域多层感知器共同捕获会话间和会话内行为。FreqRec优化的目标是结合交叉熵与频域一致性损失，明确对齐预测和真实的频谱签名，从而有效利用被忽略的频率信息.", "conclusion": "在三个基准上的广泛实验表明，FreqRec不仅超越了强大的基线模型，而且在数据稀疏性和嘈杂日志条件下仍保持稳定性能。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05873", "html_url": "https://arxiv.org/abs/2511.05873", "title": "EndoIR: 通过噪声感知路由扩散实现无退化端面成像修复", "title_en": "EndoIR: Degradation-Agnostic All-in-One Endoscopic Image Restoration via Noise-Aware Routing Diffusion", "authors": "Tong Chen,Xinyu Ma,Long Bai,Wenyang Wang,Yue Sun,Luping Zhou", "background": "内窥镜图像常受到诸如低光照、烟雾和出血等多种并发降级影响，这些降级模糊了关键的临床细节。现有的修复方法通常是针对特定任务的，需要预先知道降级类型，这限制了它们在实际临床环境中的鲁棒性。", "innovation": "我们提出了EndoIR，这是一种无降级依存的单模型扩散框架，能够使用单一模型修复多种降级类型。该方法引入了一个双域提示器，用于提取联合空间-频率特征，并结合自适应嵌入来编码共享和任务特定的线索。此外，我们设计了双流扩散架构和修正融合模块，以在不混淆特征的情况下分别处理未退化和退化输入。我们还引入了噪声感知路由块，实现了仅在噪声相关特征的动态选择中提高效率的去噪。实验结果表明，EndoIR在多个退化场景中达到了最先进的性能，同时使用参数比强基线更少，下游分割试验也证实了其临床实用性。", "conclusion": "实验结果显示，EndoIR 在多个降级场景中达到了最先进的性能，使用参数比强基线更少，而且下游分割实验确认了其临床应用价值。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06294", "html_url": "https://arxiv.org/abs/2511.06294", "title": "Transolver 是一个线性变换器：通过线性注意重新审视物理注意", "title_en": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention", "authors": "Wenjie Hu,Sidun Liu,Peng Qiao,Zhenglun Sun,Yong Dou", "background": "基于Transformer的神经运算符在数据驱动的偏微分方程（PDE）求解器方面取得了显著进展。大部分研究集中在减少注意力计算的二次复杂性，以提高训练和推理效率。研究中最突出的方法之一是Transolver，它通过引入物理注意来降低计算成本，即通过将网格点投影到切片进行切片注意力，然后再通过反投影。然而，研究者观察到物理注意可以被重新解释为线性注意力的特例，甚至切片注意力可能损害模型性能。深入理解这些结果后，研究者对物理注意的有效性提出了新的见解。", "innovation": "基于上述观察，研究者提出了一个两步转换重新设计物理注意为标准线性注意力，称为线性注意力神经运算符（LinearNO）。与Transolver相比，该方法在六个标准PDE基准测试中取得了最先进的性能，参数数量减少了40.0%，计算成本减少了36.2%，并且在两个具有挑战性的工业级数据集AirfRANS和Shape-Net Car中也表现出更优异的性能。", "conclusion": "研究证明，物理注意的有效性主要来源于切片和反投影操作而非切片间的交互。通过这种方式，研究不仅提高了现有模型的性能，而且降低了资源消耗，具有广泛的应用前景。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05885", "html_url": "https://arxiv.org/abs/2511.05885", "title": "使用多模态大型语言模型的高效序贯推荐范式", "title_en": "A Remarkably Efficient Paradigm to Multimodal Large Language Models for Sequential Recommendation", "authors": "Qiyong Zhong,Jiajie Su,Ming Yang,Yunshan Ma,Xiaolin Zheng,Chaochao Chen", "background": "序贯推荐（SR）基于用户的过往行为预测其未来的交互。大型语言模型（LLM）的发展提供了强大的生成和推理能力，极大提升了SR性能。多模态LLM（MLLM）进一步通过引入像图像和互动关系等数据来增强性能。然而，还存在一些关键问题，包括：（a）由冗长和重复描述导致的不理想的物品表示，导致训练和推理的效率下降；（b）模态相关的认知偏见，因为LLM主要是在文本数据上进行预训练，限制了它们整合和利用非文本模态数据的能力；（c）在长时间交互序列中，虽然注意力机制可以捕捉早期交互，但性能削弱，这阻碍了长依赖性的建模能力。", "innovation": "提出了Speeder，一种基于MLLM的有效序贯推荐范式，具有以下三个关键创新：1）多模态表示压缩（MRC），将物品属性浓缩为简明且富有信息性的标记，减少冗余和计算成本；2）模态感知渐进优化（MPO），实现了多模态表示的学习的逐步过程；3）序列位置意识增强（SPAE），提升了LLM捕捉长交互序列中的相对和绝对序列依赖性的能力。广泛的实验表明Speeder的有效性和效率，Speeder在亚马逊数据集上的训练速度提高了250%，推理时间降低了25%。", "conclusion": "通过Speeder，展示了如何有效利用MLLM来提升序贯推荐的效率和性能，解决了一些关键的挑战问题。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06852", "html_url": "https://arxiv.org/abs/2511.06852", "title": "差异化方向干预：一种规避大语言模型安全性对接的框架", "title_en": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment", "authors": "Peng Zhang,Peijie Sun", "background": "现有研究将语言模型的安全性对接机制简化为单一的线性方向表示，这将有害检测和执行拒绝的两个不同神经过程混淆。作者认为，这种简化是不准确的。研究提出了将单一表示分解为有害检测方向和执行拒绝方向两种不同方向的方法。", "innovation": "作者引入了一种新的白盒框架——差异化的双向干预（DBDI），通过自适应投影消除执行拒绝方向，同时通过直接导航抑制检测有害方向。实验结果表明，该方法优于现有的脱缰攻击方法，在类似Llama-2的模型上，最高可达97.88%的攻击成功率。", "conclusion": "通过提供更细粒度和机制化的方法，本研究为深入理解大语言模型的安全性质提供了新方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06090", "html_url": "https://arxiv.org/abs/2511.06090", "title": "SWE-fficiency：语言模型能否在真实工作负载上优化实际仓库？", "title_en": "SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?", "authors": "Jeffrey Jian Ma,Milad Hashemi,Amir Yazdanbakhsh,Kevin Swersky,Ofir Press,Enhui Li,Vijay Janapa Reddi,Parthasarathy Ranganathan", "background": "优化大规模软件仓库的性能需要专业知识，包括代码推理和软件工程（SWE），以减少运行时同时保持程序正确性。然而，大多数基准测试侧重于修复什么，而不是如何修复代码。该研究介绍了一个新的基准测试SWE-fficiency，用于评估仓库级别的性能优化，特别是在实际工作负载中的表现。该研究设计了一套包含498个任务的测试集，涵盖九个广泛使用的数据科学、机器学习和高性能计算（HPC）仓库（例如，numpy、pandas、scipy）。在这种情况下，一个代理必须检查代码语义，定位瓶颈和相关测试，并生成一个符合或超过专家加速效果的同时通过相同单元测试的补丁。为了支持这种如何进行修复的评估，自动生成的流水线从GitHub拉取请求中抓取性能改进的编辑，结合关键词过滤、静态分析、覆盖率工具和执行验证，以确认专家加速效果的基线并识别相关仓库单元测试。最新的研究发现目前最先进的代理表现不足，平均而言，代理仅达到专家加速效果的不到0.15倍：代理在定位优化机会、跨函数推理以及将正确性保留在所提编辑中的表现上遇到挑战。这些结果显示了一种新的研究方向，即自动化性能工程和长期软件推理的研究领域。", "innovation": "该研究通过引入SWE-fficiency基准测试，为仓库级别的性能优化提供了新的评估方式。这一工具能够使代理自动完成从代码中发现性能改进机会、定位瓶颈和执行验证等一系列复杂任务。该研究还提供了一个综合的自动化流水线，该流水线可以帮助验证现有的代码优化结果，支持研究新的优化技术。最重要的是，通过实证评估表明，现有的自动化代理在性能优化方面存在显著差距，为语言模型在这一领域的应用提出了新的挑战。", "conclusion": "目前的研究成果已经展示了SWE-fficiency基准测试在评估仓库级别性能优化方面的巨大潜力。此外，为了进一步推进自动化性能工程和长期软件推理的研发，作者已经释放了该基准测试及其配套的数据处理管道。这为未来的研究者提供了丰富的研究资源和工具，能够使他们在这个快速发展的领域中更有效地进行研究。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06658", "html_url": "https://arxiv.org/abs/2511.06658", "title": "主动学习方法在感知模糊性的采样下动物重识别", "title_en": "Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling", "authors": "Depanshu Sani,Mehar Khurana,Saket Anand", "background": "动物重识别（Re-ID）因其对生物多样性监测的重大影响及环境因素带来的独特研究挑战，最近在人工智能研究领域获得了大量关注。现有方法虽然试图通过对标记的大规模多物种动物Re-ID数据集进行训练，从而实现零样本识别，但我们的基准测试发现，这些方法在已知和未知物种上的零样本性能存在显著差距。这表明在新领域收集标记数据的必要性，但全面的识别数据标注工作既耗时又需要专业人士的知识。现有无监督（USL）和主动学习（AL）的Re-ID方法在动物Re-ID任务中表现不佳。", "innovation": "本文提出了一种新的主动学习（AL）Re-ID框架，该框架利用互补聚类方法，在嵌入空间中发现和针对结构上的模糊区域，这一方法有效地挖掘出既具有代表性又对用户有价值的样本对。通过这些样本对的Oracle反馈（必须链接和不能链接的约束），提供一个简单的注释接口，这种接口能够自然地与现有的USL方法结合使用，通过提出的约束聚类精炼算法实现。实验结果表明，这种方法仅使用0.033%的标注量就能持续超越现有的基础、USL和AL基线。在13个野生动物数据集上，它分别比基础、USL和AL方法提高了平均10.49%、11.19%和3.99%（mAP），同时每个数据集都取得了SOTA性能。此外，与未知个体的表现也有所提升，达到了11.09%、8.2%和2.06%。", "conclusion": "本文提出的方法通过主动学习框架显著提高了动物Re-ID的性能，特别是对于未知物种，且只需少量标注数据即可实现显著改进。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06817", "html_url": "https://arxiv.org/abs/2511.06817", "title": "TiS-TSL: 通过时间可切换教师-学生学习的图像标签监督手术视频立体匹配", "title_en": "TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning", "authors": "Rui Wang,Ying Zhou,Hao Wang,Wenwei Zhang,Qiang Li,Zhiwei Wang", "background": "在微创手术中，立体匹配是导航和增强现实的下一个关键步骤。然而，由于解剖学限制，密集的视差监督几乎是不可能的，通常只能获取少量图像级别的标签，这些标签是在内窥镜进入深部体腔之前获得的。", "innovation": "提出了一种新颖的时间可切换教师-学生学习（TiS-TSL）框架，用于在最小监督下的视频立体匹配。该框架的核心是一个统一的模型，可以工作在三种不同的模式下：图像预测（IP）、前向视频预测（FVP）和后向视频预测（BVP），能够在单一架构内灵活建模。这种统一模型下的TiS-TSL采用两阶段学习策略。首先，图像到视频(I2V)阶段将稀疏的图像级知识转移到初始时间建模中。随后，视频到视频(V2V)阶段通过比较前向和后向预测来计算双向时空一致性，改进时间视差预测。这种一致性识别跨帧中的不可靠区域，过滤掉视频级伪标签中的噪声，并强制实现时间相干性。", "conclusion": "在两个公开数据集上进行的实验结果表明，TiS-TSL优于其他基于图像的最新方法，分别在TEPE和EPE上提升了至少2.11%和4.54%。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07445", "html_url": "https://arxiv.org/abs/2511.07445", "title": "RAG在台湾历史档案中的初步研究", "title_en": "A Preliminary Study of RAG for Taiwanese Historical Archives", "authors": "Claire Lin,Bo-Han Feng,Xuanjun Chen,Te-Lun Yang,Hung-yi Lee,Jyh-Shing Roger Jang", "background": "检索增强生成（RAG）已经证明了在知识密集型任务中的潜力，但很少有研究将其应用于台历史档案。此文研究了RAG在台湾历史档案Fort Zeelandia和台湾省议会公报中的应用。", "innovation": "文章系统性地探讨了查询特征和元数据集成策略对检索质量、答案生成和整体系统性能的影响，并且首次将RAG应用于台湾历史档案数据库，并揭示了在生成中出现的幻觉问题以及如何处理历史性的多跳查询。", "conclusion": "早期阶段的元数据集成提高了检索和答案的准确性，同时也揭示了RAG系统在生成中的幻觉问题以及在处理时间和多跳历史查询方面的持续挑战。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07322", "html_url": "https://arxiv.org/abs/2511.07322", "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation", "title_en": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation", "authors": "Song Jin,Shuqi Li,Shukun Zhang,Rui Yan", "background": "虽然大型语言模型（LLMs）在金融任务如股票预测和问答中表现出巨大的成功，但在完全自动化股票研究报告生成方面的应用仍处于未知领域。本文首次定义了股票研究报告（ERR）生成任务。为了解决数据稀缺性和缺乏评估指标的问题，作者提出了一种开源评估基准FinRpt，其中包括一个数据集构建管道和一个全面的评估系统。", "innovation": "本文创新地提出了股票研究报告生成任务，并构建了一个集成了7种金融数据类型的开放源代码评估基准FinRpt。该基准包括一个数据集构建管道和一个全面的评估系统，提出了多代理框架FinRpt-Gen，并通过对已提供建立的数据集进行监督微调和强化学习来训练多个基于LLM的代理。", "conclusion": "实验结果表明，提出的基准FinRpt和多代理框架FinRpt-Gen的数据质量和评估指标的有效性，以及它们在股票研究报告生成领域的潜在驱动创新力。所有代码和数据集都已公开可供使用。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07046", "html_url": "https://arxiv.org/abs/2511.07046", "title": "学习用于整数硬件的量化连续控制器", "title_en": "Learning Quantized Continuous Controllers for Integer Hardware", "authors": "Fabian Kresse,Christoph H. Lampert", "background": "在嵌入式硬件上部署连续控制强化学习策略需要满足严格的时间延迟和功耗预算。小型现场可编程门阵列（FPGA）可以实现这一点，前提是避免昂贵的浮点流水线。因此，研究如何对策略进行量化感知训练（Quantization-Aware Training，QAT），并通过自动选择低比特深度的策略和合成到Artix-7 FPGA的方式，实现硬件部署。", "innovation": "本文提出了一种学习到硬件（learning-to-hardware）的流程，可以自动选择低比特深度的策略并将其合成到Artix-7 FPGA。在五个MuJoCo任务上，通过研究量化感知训练和利用特定输入精度，该研究获得了与全精度（FP32）策略相当的策略网络，但在某些情况下每个权重和每个内部激活值仅需2或3比特。在目标硬件上，选定的策略实现了微秒级的推理延迟并消耗微焦耳级的每行动能，这一结果优于量化参考，同时量化策略显示出比浮点基线更强的输入噪声鲁棒性。", "conclusion": "研究结果展示了如何通过量化感知训练方法在嵌入式FPGA上部署高效的连续控制策略，并揭示了低比特深度策略的潜在优势，特别是在功耗和延迟受限的环境中。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07448", "html_url": "https://arxiv.org/abs/2511.07448", "title": "大语言模型在科学创意生成中的应用：一个以创造力为中心的综述", "title_en": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "authors": "Fatemeh Shahhosseini,Arash Marioriyad,Ali Momen,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban,Shaghayegh Haghjooy Javanmard", "background": "科学创意在科学研究中起着关键作用，推动着人类的进步。与标准的科学推理或一般创意生成不同，科学创意是一个多目标和开放的任务，创新性与其实证的正确性同样重要。尽管大语言模型（LLMs）能够生成连贯且事实性的科学创意，但它们的创意能力仍不一致且缺乏深入理解。本文综述了LLM驱动的科学创意生成方法，探讨了不同方法如何平衡创意与科学严谨性。", "innovation": "本文对现有方法进行了分类，分为五个互补的家庭：外部知识增强、基于提示的分布控制、推理时的缩放、多智能体合作和参数级适应。通过结合Boden的组合、探索和转变创造力分类法以及Rhodes的4Ps框架（个人、过程、压力和产品），本文解释了各种方法的贡献，使得对LLM在科学发现中的应用有了更清晰的认识和发展方向。", "conclusion": "通过将方法论的进步与创造力框架相结合，本文阐明了领域的现状，并指出了可靠、系统和变革性地应用LLMs进行科学发现的关键方向。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07295", "html_url": "https://arxiv.org/abs/2511.07295", "title": "硬样本 vs 噪声：通过大型语言模型解决推荐系统中的硬噪声样本混淆", "title_en": "Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender Systems via Large Language Models", "authors": "Tianrui Song,Wen-Shuo Chao,Hao Liu", "background": "在训练推荐系统时，隐式反馈不可避免地会遇到噪声问题，这源于误点击和位置偏差等因素。以往的研究尝试通过识别数据模式中的差异（如更高的损失值）来发现噪声样本，并通过丢弃或重新加权的方法减轻其影响。然而，研究者发现噪声样本和困难样本在模式上表现出相似性，这导致了困难样本和噪声样本混淆的问题。该问题很严重，因为困难样本对于建模用户偏好至关重要。", "innovation": "本文提出了一种名为LLMHNI的框架，利用大型语言模型（LLMs）生成的两个辅助用户-项目相关信号来区分困难样本和噪声样本。LLMHNI通过LLM编码嵌入获取用户-项目语义相关性，用于负样本选择以选择困难负样本并过滤掉噪声的假负样本。提出了一种目标对齐策略，使LLM编码嵌入适应用户-项目相关性建模。LLMHNI还利用用户-项目交互中的LLM推理逻辑相关性来识别困难样本和噪声样本。通过这些交互，LLMHNI实现了一种跨图对比对齐，从而指导去噪。为了消除由LLM幻觉引起的不可靠交互的影响，提出了一种图对比学习策略来对齐随机边删除视图中的表示，以抑制不可靠边。", "conclusion": "实验证明，LLMHNI显著提高了去噪和推荐性能。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07458", "html_url": "https://arxiv.org/abs/2511.07458", "title": "REFLEX: 使用大型语言模型判断进行日志总结无参考评价", "title_en": "REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment", "authors": "Priyanka Mudgal", "background": "由于缺乏高质量的参考摘要和现有度量标准（如ROUGE和BLEU）依赖于表层词汇重叠的限制，评估日志总结系统具有挑战性。", "innovation": "介绍了REFLEX，一种基于大型语言模型（LLM）判断的无参考评价度量标准。REFLEX 使用LLM作为零样本评估者，根据相关性、信息量和连贯性等维度评估摘要质量，无需黄金标注参考或人工标注。", "conclusion": "REFLEX 在多个日志总结数据集中产生了稳定、可解释且细粒度的评价，并且在区分模型输出方面比传统度量标准更有效。REFLEX 在实际应用中提供了评估日志总结的可扩展替代方案，尤其是在参考数据稀缺或不可用的情况下。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07457", "html_url": "https://arxiv.org/abs/2511.07457", "title": "GRIP: 在参数图推理通过微调大规模语言模型", "title_en": "GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models", "authors": "Jiarui Feng,Donghong Cai,Yixin Chen,Muhan Zhang", "background": "大规模语言模型（LLMs）在建模序列文本数据和跨任务泛化方面表现出色。然而，将LLMs适应有效地处理结构性数据，如知识图谱或网页数据，仍是一个具有挑战性的问题。一些方法采用复杂的策略将图形转换为文本序列，导致了大量的标记开销，使其在大规模图形中变得 impractical。其他方法通过引入额外模块将图形编码为固定大小的标记表示，供LLMs使用。然而，这些方法通常需要大量的后训练和复杂的对齐程序，并且由于模态对齐不理想，往往无法获得最佳结果。受测试时通过在参数中注入知识来适应LLMs的启发，我们提出了一种新型框架GRIP，使LLMs能够通过精心设计的微调任务内部化图形中的复杂关系信息，并在不访问原始图形的情况下执行广泛的图相关任务。", "innovation": "提出了一种名为GRIP的新框架，通过在参数中注入知识，使大规模语言模型能够内部化复杂的关系信息，并通过精心设计的微调任务进行有效存储。这使得微调后的LLM能够在推理时处理广泛的图相关任务，而无需访问原始图形，从而简化了后处理和对齐过程，并提高了效果。", "conclusion": "广泛的实验表明，我们的方法在多个基准测试中有效且高效，证明了GRIP框架的优越性。"}
{"llm_update_time": "20251113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07392", "html_url": "https://arxiv.org/abs/2511.07392", "title": "手术代理编排平台以支持语音指导的患者数据交互", "title_en": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction", "authors": "Hyeryun Park,Byung Mo Gu,Jun Hee Lee,Byeong Hyeon Choi,Sekeun Kim,Hyun Koo Kim,Kyungsang Kim", "background": "在da Vinci机器人手术中，外科医生的手和眼睛都完全投入到手术流程中，这使得他们难以在不中断的情况下访问和操作多模态的患者数据。现有的解决方案存在诸如手动操作或中断手术以处理信息访问等问题，影响手术的连续性和精确性，特别是在微创da Vinci机器人手术中，需要高效且可靠的患者数据访问和处理平台，但现有技术难以满足这种高要求的需求，尤其是面对语音指令的复杂性和多变性。", "innovation": "本文提出了一种基于层次多代理框架的语音指令驱动的手术代理编排平台（SAOP），该平台包括一个编排代理和三个由大型语言模型（LLMs）驱动的任务特异性代理。这些基于LLM的代理能够自主规划、优化和验证将语音指令转换为具体任务（例如，获取临床信息、操作CT扫描或在手术视频中导航3D解剖模型）的能力。此外，还引入了多层次编排评价指标（MOEM），用于从命令级别和类别级别全面评估性能和鲁棒性。SAOP在240个语音指令中表现出高准确率和成功率，且基于LLM的代理提升了对语音识别错误和多样或模糊自由形式语音指令的鲁棒性，展示了其在支持微创da Vinci机器人手术方面的强大潜力。", "conclusion": "手术代理编排平台(SAOP)提供了一个高效的解决方案，通过语音命令与患者数据的交互提高了微创da Vinci机器人手术的效率和可靠性。该平台通过多层次编排评价指标（MOEM）证明了其在实际应用中的可靠性和有效性，并展示了基于大型语言模型（LLMs）的代理在处理复杂多样指令方面的优越性能。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07464", "html_url": "https://arxiv.org/abs/2511.07464", "title": "Motif 2 12.7B技术报告", "title_en": "Motif 2 12.7B technical report", "authors": "Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon", "background": "该研究介绍了一种名为Motif-2-12.7B的新开放权重基础模型，它通过结合架构创新和系统级优化，推动了大型语言模型的效率前沿。该模型旨在在有限的计算预算下实现可扩展的语言理解和稳健的指令泛化。", "innovation": "1. 结合了Grouped Differential Attention (GDA)技术，通过分离信号和噪声控制注意力路径来提高表示效率。\n2. 使用教学驱动的数据调度程序进行预训练，逐步改变数据组成比例。\n3. 集成了高能效内核和自定义优化器，如融合PolyNorm激活和Parallel Muon算法，实现大规模分布式环境中的显著吞吐量和内存效率提升。\n4. 提出了一种三阶段监督微调流水线，逐步增强指令遵循性、组合理解和语言精确度。", "conclusion": "Motif-2-12.7B在各种基准测试中展示了竞争力，表明精心设计的架构扩展和优化的训练设计可以匹敌更大规模模型的能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07498", "html_url": "https://arxiv.org/abs/2511.07498", "title": "聚焦语言：揭示并利用多语言大型语言模型中的语言注意力头部", "title_en": "Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models", "authors": "Xin Liu,Qiyang Song,Qihang Zhou,Haichao Du,Shaowen Xu,Wenbo Jiang,Weijuan Zhang,Xiaoqi Jia", "background": "大型语言模型（LLMs）在多语言理解和生成方面正变得越来越重要。与此同时，研究它们内部机制的解释性努力也出现了，这为提高多语言表现提供了洞察。多头自注意力（MHA）已经在许多领域证明了其关键作用，但在多语言能力中的具体作用依然未被充分探索。这项工作中，我们研究了MHA在支持LLMs中的多语言处理方面的作用。", "innovation": "我们提出了语言注意力头重要性评分（LAHIS），这是一种有效且高效的识别方法，通过一次前向和反向传播就能确定多语言能力下的注意力头部的重要性。我们将LAHIS应用于Aya-23-8B、Llama-3.2-3B和Mistral-7B-v0.1，揭示了语言特异性头部和语言通用头部的存在。我们还提出了一种轻量级的微调方法，学习一个软头部掩码来调节注意力输出，仅需20个可调参数就能提高XQuAD准确率。", "conclusion": "我们的工作在MHA的角度上提高了LLMs的可解释性和多语言能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07555", "html_url": "https://arxiv.org/abs/2511.07555", "title": "LLM优化解锁实时成对重排", "title_en": "LLM Optimization Unlocks Real-Time Pairwise Reranking", "authors": "Jingyu Wu,Aditya Shrivastava,Jing Zhu,Alfy Samuel,Anoop Kumar,Daben Liu", "background": "高效地对信息检索（IR）管道中检索到的文档进行再排序，以提升检索增强生成（RAG）系统的整体质量，仍然是一项重要但具有挑战性的问题。近年来，研究强调了大型语言模型（LLMs）在再排序任务中的重要性。特别是，成对再排序提示（PRP）因其易于使用和有效性而成为一种有前景的即插即用方法。然而，该算法的内在复杂性以及LLMs带来的高计算需求和延迟问题，使得该方法在实时应用程序中的可行性受到了质疑。", "innovation": "本文通过对成对再排序进行集中研究，证明了精心应用的优化方法可以显著缓解上述问题。通过这些方法，将每个查询的延迟从61.36秒显著降低到0.37秒，性能下降可以忽略不计，具体来说是通过Recall@k衡量的。该研究强调了设计选择的重要性，包括使用较小的模型、限制重排序集、使用较低的精度、减少位置偏见并通过单向顺序推断减少、以及限制输出标记。", "conclusion": "这些优化使基于LLMs的再排序在敏感的延迟要求和实际部署中更加高效和可行。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07659", "html_url": "https://arxiv.org/abs/2511.07659", "title": "重新审视自然语言推理：朝向成本效益高且与人类齐心的评估指标，用于语言模型在问答中的评估", "title_en": "Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering", "authors": "Sai Shridhar Balamurali,Lu Cheng", "background": "评估最先进的大语言模型（LLMs）的答案存在挑战：词汇度量无法捕捉语义细微差别，而将大语言模型作为评分器的评分方法成本高昂。因此，研究团队重新审视了轻量级的替代方案——通过简单的词汇匹配标记增强的标准自然语言推理（NLI）评分。这种方法在过去几十年中被使用，结果显示它在长格式问答任务上与GPT-4的准确性相同，同时所需的参数要少得多。", "innovation": "该团队提出了一种新的3000样本的人工标注基准数据集，名为DIVER-QA，覆盖五个问答数据集和五个候选语言模型，用于严格测试这些评估指标的人类一致性。结果显示，廉价的基于NLI的评估仍然具有竞争力，同时为未来评估指标的研究提供了开放资源。", "conclusion": "这项研究展示了基于NLI的低成本评估机制在问答语言模型评估中仍然具有竞争力，同时为未来的研究提供了新的基准测试资源DIVER-QA，以确保评估方法与人类评估一致。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07641", "html_url": "https://arxiv.org/abs/2511.07641", "title": "LLMs vs.传统情感工具在心理学中的评估：以比利时荷兰语叙述为例", "title_en": "LLMs vs. Traditional Sentiment Tools in Psychology: An Evaluation on Belgian-Dutch Narratives", "authors": "Ratna Kandala,Katie Hoemann", "background": "理解日常语言中情感的细微差别对于计算语言学和情感研究至关重要。传统的词汇库工具（如LIWC和Pattern）虽然在情感分析方面发挥了基础性作用，但大型语言模型（LLMs）有望通过增强上下文理解来提升情感分析的能力。本文研究了三种针对荷兰语的LLMs（ChocoLlama-8B-Instruct、Reynaerde-7B-chat和GEITje-7B-ultra）与LIWC和Pattern工具在弗拉芒语情感倾向预测方面的表现，弗拉芒语是一种低资源语言变体。", "innovation": "本文通过大规模（约25000个自发文本响应）的实证研究，评估了LLMs在低资源语言变体（弗拉芒语）中的情感分析能力。研究使用了三种特意针对荷兰语的LLMs和传统的词汇库工具，评估了它们在情感正面性预测方面的表现。", "conclusion": "研究结果出乎意料，荷兰语特定的LLMs在情感正性预测任务中的表现不如传统的工具。这挑战了LLMs在情感分析任务中的优越性假设，并强调了在低资源语言变体中捕捉情感正性复杂性的难度。研究结果还表明，需要开发文化上和语言上更加适应的评估框架来评估低资源语言中的情感表示，同时质疑当前的LLMs微调方法是否能够充分处理日常语言中细微的情感表达。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07461", "html_url": "https://arxiv.org/abs/2511.07461", "title": "两阶段方法：一种双阶段术语意识翻译方法", "title_en": "It Takes Two: A Dual Stage Approach for Terminology-Aware Translation", "authors": "Akshat Singh Jaswal", "background": "本文介绍了一种名为DuTerm的新型两阶段机器翻译架构，该架构针对术语约束进行优化。该系统结合了通过大规模合成数据微调的术语敏感NMT模型和基于提示的大规模语言模型（LLM），用于后编辑阶段。后编辑阶段确保NMT输出的术语一致性，并进行进一步优化。", "innovation": "该研究提出了一种独特的两阶段方法，利用术语敏感的NMT模型和基于提示的大规模语言模型的组合。通过大规模合成数据对术语敏感的NMT模型进行微调，使系统能够更好地处理术语，随后通过LLM对NMT的输出进行后编辑，以便更灵活、上下文驱动地处理术语，从而提高翻译质量。", "conclusion": "研究表明，这种基于上下文的术语处理方法相比严格的术语约束执行，能更有效地提高翻译质量。研究结果表明，大规模语言模型作为上下文驱动的修改器比生成器更适合高质量的翻译任务，揭示了术语处理中一个关键的权衡。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07722", "html_url": "https://arxiv.org/abs/2511.07722", "title": "批判性编撰：LLMs可以从社会正义的角度进行幻想吗？", "title_en": "Critical Confabulation: Can LLMs Hallucinate for Social Good?", "authors": "Peiqi Sui,Eamon Duede,Hoyt Long,Richard Jean So", "background": "LLMs存在虚构（hallucinate）现象，但某些虚构内容如果谨慎设定边界，可以具有社会意义。文章提出了一种基于文学和社会理论的‘批判性编撰’方法，利用LLMs的虚构来填补由于社会和政治不平等导致的档案中遗漏的信息，重构具有证据支持的历史‘隐藏人物’的多元叙事。", "innovation": "本文提出了一种新颖的方法——‘批判性编撰’，通过让LLMs‘填补空白’来自未出版小说的个性化时间线中的缺失事件，使得虚构在特定语境下具有社会价值；通过模拟这些缺失的生成任务，并在不同模型和提示下进行评估，验证了LLMs在执行‘批判性编撰’方面的能力。", "conclusion": "研究发现，经过适当控制和明确设定的虚构可以帮助LLMs在知识生产中发挥作用，而不会导致历史准确性与真实性的丧失。这种‘批判性编撰’能够有效促进LLMs在知识生产领域的应用，同时保障历史叙述的准确性和忠实性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07689", "html_url": "https://arxiv.org/abs/2511.07689", "title": "对长文档摘要事实一致性的压力测试", "title_en": "Stress Testing Factual Consistency Metrics for Long-Document Summarization", "authors": "Zain Muhammad Mujahid,Dustin Wright,Isabelle Augenstein", "background": "评估抽象总结文本的事实一致性仍然是一个重要挑战，特别是在长文档中，常规指标在处理输入长度限制和长距离依赖关系时遇到困难。本研究系统地评估了六种广泛使用的参考独立事实一致性指标在长文档环境中的可靠性。研究通过应用七种保留事实性差异的扰动，探讨了这些指标对摘要的稳定性，并进一步分析了它们对检索上下文和断言信息密度的敏感性。研究结果表明，现有的短文本指标对于语义等价的摘要产出不一致的评分，并在信息密集的断言中表现出可靠性下降的情况，这些断言的内容与源文档的许多部分在语义上相似。虽然扩大检索上下文在某些领域可以提高稳定性，但没有一种指标能在长上下文中持续保持事实一致性。", "innovation": "本文通过系统性地评估六种广泛用于短文本摘要的事实一致性指标在长文档设置中的可靠性；通过使用七种保留事实性的扰动，对指标的稳定性进行了研究；进一步分析了它们对检索上下文和断言信息密度的敏感性；并通过对结果的分析，提出了改进事实一致性评估的方法，包括多区间推理、上下文感知校准和使用意义保持的变体训练以增强长文档摘要的鲁棒性。同时，研究论文开源了重现研究结果所需的所有代码、扰动数据和脚本。", "conclusion": "现有对短文档的指标在长文档环境下表现不稳定，特别是在信息密集的情况下。扩大检索上下文在某些领域可以提高工具稳定性，但没有一种指标能在长上下文中持续保持事实性的一致性。因此，未来的研究需要重点于多区间推理、上下文感知校准以及使用意义保持的变体训练来增强这些评估工具在长文档摘要中的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07691", "html_url": "https://arxiv.org/abs/2511.07691", "title": "CAPO: 自觉偏好的多语言偏好优化学习", "title_en": "CAPO: Confidence Aware Preference Optimization Learning for Multilingual Preferences", "authors": "Rhitabrat Pokharel,Yufei Tao,Ameeta Agrawal", "background": "偏好优化是一种关键的后训练技术，用于将大型语言模型（LLMs）与人类偏好对齐，通常通过排名响应对进行微调。尽管像直接偏好优化（DPO）等方法在英语中已证明有效，但在多语言环境中，它们往往无法稳健地泛化。因此，需要寻找一种替代方案来解决这一问题并提高语言模型在不同语言环境下的偏好优化效果。首要问题是现有的方法如DPO在多语言环境中表现不稳定，尤其是在面对噪音数据或微小差异的比较时表现不佳。这篇文章将这是一个背景的一部分，探讨如何改进现有的偏好优化方法以应用于多语言场景中，提高模型的稳健性和可靠性。", "innovation": "本文提出了一种简单而有效的新方法，即自信感知偏好优化（CAPO），它用基于相对奖励的动态损失缩放机制取代了DPO中固定的偏好对处理方式。通过根据每对偏好对的置信度来调制学习信号，CAPO能够提高对噪音或微小差异的比较的鲁棒性，同时在多语言环境中保持高的效能。实验结果表明，CAPO在奖励准确率方面至少比现有偏好优化基线提高了16%，并且能够通过扩大首选和非首选响应之间的差距来提高在不同语言中的模型对齐程度。", "conclusion": "本文提出了CAPO方法，这是对于现有直接偏好优化（DPO）方法的一种改进，适用于多语言场景，并且在多语言的偏好优化方面表现出色，提高了语言模型在应对噪音数据或微小差异比较时的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07752", "html_url": "https://arxiv.org/abs/2511.07752", "title": "回到未来：过去和未来语境可预测性在渐进式语言生产中的作用", "title_en": "Back to the Future: The Role of Past and Future Context Predictability in Incremental Language Production", "authors": "Shiva Upadhye,Richard Futrell", "background": "在线语言生产的背景下，单词的形式和选择受上下文可预测性的影响。关于单词先期上下文可预测性对生产与理解的影响已有较深入了解，但自然语言生产研究中还发现了单词根据其未来上下文的不易理解的后向可预测性效应，这可能与未来规划有关。本研究表明通过改进测量和更强大的语言模型，结合未来和过去语境的可预测性，探索了后向可预测性效应，并通过细致分析替换错误，揭示了人类在词汇规划中如何权衡形式、意义和基于语境的信息。这些发现有助于理解过去和未来语境在单词编码和选择中的功能角色，填补了语境可预测性效应与句子规划机制之间的联系空白。", "innovation": "引入了一种信息论驱动的概念上合乎逻辑的新可预测性度量，该度量整合了来自过去和未来语境的可预测性。修正了以往的单词时长预测研究，并通过生成模型独立地分析词汇、上下文和沟通方面对单词选择的影响，预测实际作为言语错误出现的单词。发现提出的概念化替代标准与过去和未来可预测性在两个研究中的效果具有类似之处。", "conclusion": "通过对替换错误的细致分析，进一步表明不同类型的错误提示了说话者在词汇计划时对形式、意义和基于语境的信息侧重的差异。这些研究结果进一步解读了过去和未来语境在促进语言生产中的功能，建立了语境可预测性效应与句子规划机制之间的桥梁。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07879", "html_url": "https://arxiv.org/abs/2511.07879", "title": "在新闻文章中使用未来提及和相关实体提取进行计划事件预报", "title_en": "Planned Event Forecasting using Future Mentions and Related Entity Extraction in News Articles", "authors": "Neelesh Kumar Shukla,Pranay Sanghvi", "background": "在民主国家如印度，人们可以自由表达观点和需求，这有时会导致民事骚乱，如抗议、集会和游行。这些事件通常是无序的，往往未经相关行政部门的许可。预报这些事件有助于行政官员采取必要的行动。通常，抗议活动会在事先公布，以鼓励大规模参与。因此，通过分析这样的新闻文章公告，可以提前预测潜在的计划事件。", "innovation": "本文开发了一种系统，利用主题建模和word2vec筛选相关新闻文章，并通过命名实体识别（NER）方法识别人员、组织、地点和日期等实体。还应用了时间规范化来将未来日期表示成标准化格式。本文提出了一个地理无关的、通用模型，用于识别筛选民事骚乱事件的关键特征，并且提出了一种相关实体提取的方法，该方法称为相关实体提取。", "conclusion": "识别相关实体是帮助行政官员提前了解潜在骚乱情况的关键步骤。这种方法的创新之处在于其能够从大量的新闻文章中筛选出与计划事件相关的实体，从而提高预报的准确性和效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07794", "html_url": "https://arxiv.org/abs/2511.07794", "title": "世界上第一个保险大型语言模型评估基准的设计、结果与行业影响", "title_en": "Design, Results and Industry Implications of the World's First Insurance Large Language Model Evaluation Benchmark", "authors": "Hua Zhou(Central University of Finance and Economics),Bing Ma(Central University of Finance and Economics),Yufei Zhang(Zetavision AI Lab),Yi Zhao(Zetavision AI Lab)", "background": "本文详细阐述了CUFEInse v1.0的构建方法、多维度评价体系及其设计理念。该基准严格遵循“定量导向、专家驱动、多验证”的原则，建立了一个涵盖5个核心维度、54个子指标以及14,430个高质量问题的评价框架，这些问题覆盖了保险理论知识、行业理解、安全与合规、智能代理应用以及逻辑严谨性等几个方面。基于此基准，对11个主流大型语言模型进行了全面评估，揭示了通用模型普遍存在的薄弱环节，如精算能力弱和合规适应性不足。高质量的领域特定训练在保险垂直场景中展示了明显优势，但在业务适应性和合规性方面存在不足。评估还准确地识别了当前大型模型在专业场景如保险精算、承保和索赔推理以及合规营销文案中的共同瓶颈。CUFEInse的建立填补了保险领域专业评估基准的空白，为学术界和行业提供了专业、系统和权威的评估工具，其构建理念和方法也为垂直领域大型模型的评估提供了重要参考，有助于学术模型优化和工业模型选择。", "innovation": "CUFEInse v1.0的构建展示了在保险领域构建专业评估基准的新方法，通过定量导向、专家驱动和多验证的原则，建立了一个包含高质量问题的评价框架，全面覆盖了保险多个关键领域。此外，该基准还通过评估发现和解决了当前大型语言模型在保险领域中可能存在的瓶颈问题，特别是在精算能力、合规适应性和业务适应性方面，从而为行业的未来发展提供了指导。这些发现也为垂直领域大型模型的评估提供了重要参考，有助于更好地优化学术模型和选择工业模型。", "conclusion": "本文强调了未来评价基准的迭代方向和保险大型语言模型的核心发展方向为“领域适应+推理增强”，这为未来研究和开发提供了明确的方向，有助于克服当前存在的问题，推动保险领域大型语言模型的进一步发展和应用。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07888", "html_url": "https://arxiv.org/abs/2511.07888", "title": "通过流形净化打破文本分类中的对抗鲁棒性-性能权衡", "title_en": "Breaking the Adversarial Robustness-Performance Trade-off in Text Classification via Manifold Purification", "authors": "Chenhao Dang,Jing Ma", "background": "在文本分类（TC）领域，增强模型对于对抗攻击的鲁棒性通常会牺牲干净数据上的性能。这一挑战源于模型在提升对抗鲁棒性时难以保持住原有性能，两者之间存在权衡。", "innovation": "本文提出了一种新的方法，Manifold-Correcting Causal Flow（MC^2F），它是通过直接操作句子嵌入来处理这一问题。MC^2F 包含两个模块：Stratified Riemannian Continuous Normalizing Flow (SR-CNF) 学习干净数据流形的密度，识别异常嵌入；Geodesic Purification Solver 将对抗点投影回学习到的流形上，恢复清晰且语义一致的表示。这种机制能够同时提高对抗鲁棒性并保持原始模型性能。", "conclusion": "通过广泛的实验，验证了 MC^2F 在多种文本分类数据集和对抗攻击下的效果。结果表明，该方法不仅建立了对抗鲁棒性的新标准，还在保持甚至提升干净数据上的性能方面取得了显著进步。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07800", "html_url": "https://arxiv.org/abs/2511.07800", "title": "从经验到策略：赋予LLM代理可训练图记忆能力", "title_en": "From Experience to Strategy: Empowering LLM Agents with Trainable Graph Memory", "authors": "Siyu Xia,Zekun Xu,Jiajun Chai,Wentian Fan,Yan Song,Xiaohan Wang,Guojun Yin,Wei Lin,Haifeng Zhang,Jun Wang", "background": "基于大型语言模型（LLMs）的代理已经在复杂的、开放的环境中展示了极佳的自主任务解决能力。提升LLM代理的推理能力的一个有希望的方法是更好地利用先前的经验来引导当前的决策。然而，LLMs通过训练中的隐式记忆或通过提示实现的显式记忆来获取经验，前者存在灾难性遗忘和解释性有限的问题，后者缺乏适应性。", "innovation": "本文引入了一种新的代理中心、可训练、多层的图记忆框架，通过上下文记忆增强LLMs利用参数信息的能力。该图将原始的代理轨迹抽象为状态机中的结构化决策路径，并进一步提炼为高层、人类可理解的战略元认知。为使记忆具备适应性，我们提出了一种基于强化学习的权重优化程序，该程序根据下游任务的奖励反馈估计每种元认知的实证效用，然后动态地将这些优化策略集成到LLM代理的训练循环中通过元认知提示。实验结果表明，可训练的图记忆展示了稳健的泛化能力，提升了LLM代理的战略推理性能，并在强化学习（RL）训练过程中提供了持续的益处。", "conclusion": "本文研究结果显示，通过引入一种可训练的多层图记忆框架，可以有效提升LLM代理的战略推理能力和泛化能力，从而在面对复杂任务时表现更优。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07871", "html_url": "https://arxiv.org/abs/2511.07871", "title": "AlignSurvey: 用于社会调查中人类偏好对齐的全面基准", "title_en": "AlignSurvey: A Comprehensive Benchmark for Human Preferences Alignment in Social Surveys", "authors": "Chenxi Lin,Weikang Yuan,Zhuoren Jiang,Biao Huang,Ruitao Zhang,Jianan Ge,Yueqian Xu,Jianxing Yu", "background": "了解人类的态度、偏好和行为对于学术研究和政策制定至关重要。然而，传统调查面临固定问题形式、高昂成本、有限适应性和确保跨文化等价性的难题。尽管近期研究探索了大语言模型（LLMs）模拟调查答案，但大多数研究局限于结构化问题，忽视了整个调查过程，并且由于训练数据偏差可能存在代表性不足的风险。", "innovation": "我们提出了AlignSurvey，这是第一个使用LLMs系统地复制和评估整个社会调查流程的基准。AlignSurvey定义了四个与关键调查阶段对齐的任务：社会角色建模、 semi-结构化访谈建模、态度立场建模和调查答案建模。它还提供了一种特定于任务的评估指标，用于在个体和群体水平上评估对齐的准确度、一致性和公平性，特别注重人口多样性。此外，我们构建了多层数据架构，包括跨国家资源的社交基础语料库和社会调查全链条数据集，并提供了参考模型，用于评估领域特定的对齐情况。所有数据集、模型和工具均可在GitHub和HuggingFace上获取，以支持透明和负责任的研究。", "conclusion": "AlignSurvey通过定义特定任务和提供评估指标，以及构建多层数据架构，一举解决了传统调查面临的多个问题，并通过开源LLMs的双重微调提供了参考模型。所有资源均公开共享，支持透明和负责任的研究。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07914", "html_url": "https://arxiv.org/abs/2511.07914", "title": "社会媒体与心理健康：数据、方法与发现", "title_en": "Social Media for Mental Health: Data, Methods, and Findings", "authors": "Nur Shazwani Kamarudin,Ghazaleh Beigi,Lydia Manikonda,Huan Liu", "background": "随着网络上虚拟社区和论坛的不断增加，社交媒体为人们提供了一个自由交流、分享思想、寻求同伴支持的空间，特别是对于那些极易被污名化的状况。通过研究社交数据在心理障碍如抑郁症、焦虑症和自杀想法等挑战中的应用，本文探讨了最新的研究方法和发现。本文还讨论了这些新颖的想法如何以前所未有的方式提高心理健康问题的意识。", "innovation": "本文专注于利用社交数据中的语言、视觉和情感指标来识别心理健康问题的早期迹象，并探讨这些数据如何被利用来改进临床实践、提供及时支持，并影响政策制定。文章还介绍了机器学习、特征工程、自然语言处理等方法，并指出了未来研究的方向。", "conclusion": "本章划分了用于心理健康问题的社交媒体数据类别，介绍了不同的机器学习、特征工程、自然语言处理和调查方法，并提出了未来研究的方向。这些方法和发现为利用社交数据改善心理健康问题的治疗和预防提供了新视角。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07910", "html_url": "https://arxiv.org/abs/2511.07910", "title": "最后一层logits到逻辑：赋予LLMs逻辑一致的结构化知识推理能力", "title_en": "Last Layer Logits to Logic: Empowering LLMs with Logic-Consistent Structured Knowledge Reasoning", "authors": "Songze Li,Zhiqiang Liu,Zhaoyan Gong,Xiaoke Guo,Zhengke Gui,Huajun Chen,Wen Zhang", "background": "大规模语言模型（LLMs）通过预训练于大量的非结构化文本，在自然语言推理任务上取得了卓越的性能，可以理解自然语言中的逻辑并生成逻辑一致的响应。然而，非结构化知识与结构化知识的代表差异使得LLMs难以保持逻辑一致性，在知识图谱问答（KGQA）等结构化知识推理任务中面临‘逻辑漂移’（Logic Drift）的挑战。现有方法通过设计复杂的提示工作流来引导LLM的推理，但这些方法只在输入级别提供了指导，无法从根本上解决LLMs输出中的逻辑漂移问题，而且其固定的推理工作流也不能适应不同的任务和知识图谱。", "innovation": "本文提出了一种名为‘logits-to-logic’的框架，通过logits增强和logits过滤核心模块，纠正LLMs输出中的逻辑缺陷，从而增强其在结构化知识推理中的逻辑一致性。实验结果表明，该方法能显著提升LLMs在结构化知识推理中的逻辑一致性，并在多项KGQA基准测试中达到了最先进的性能。", "conclusion": "通过引入logits-to-logic框架改进LLMs的logits输出，可以显著提高其结构化知识推理的逻辑一致性，使其在KGQA等任务中表现出更优异的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07918", "html_url": "https://arxiv.org/abs/2511.07918", "title": "不同说话模式下的theta同步性：感知、朗读、耳语和想象", "title_en": "Distinct Theta Synchrony across Speech Modes: Perceived, Spoken, Whispered, and Imagined", "authors": "Jung-Sun Lee,Ha-Na Jo,Eunyeong Ko", "background": "人类的语音产生包含多种模式，如感知、公开、耳语和想象，每种模式均与不同的神经机制相关。theta频段同步性与语言处理、注意力控制和内部语言紧密相关。尽管如此，以往的研究主要集中在单一模式，如公开说话，很少进行全面比较不同说话模式下的theta同步性。", "innovation": "本研究基于连通性指标分析不同说话模式下的theta同步差异，特别关注区域间的变化。研究发现，公开和耳语说话表现出更广泛和更强的前颞联络，反映出在主动发音时活跃的运动-音位耦合；而感知说话则以后部和颞叶为主要同步模式，符合听觉感知和理解过程；相比之下，想象说话表现为空间定位更为集中但内部一致的同步模式，主要涉及前额和辅助运动区。研究表明，不同说话模式下的theta同步性程度和空间分布存在显著差异，公开发音涉及广泛的皮层交互，耳语说话显示出一定程度的参与，而感知则主要依赖于颞顶网络。", "conclusion": "因此，本研究旨在阐明不同说话模式下的theta同步性差异，从而揭示语言感知和内部语言下共享和独特的神经动态。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07982", "html_url": "https://arxiv.org/abs/2511.07982", "title": "NOTAM-Evolve: 一种由知识引导的自我进化优化框架以增强LLM的NOTAM解释能力", "title_en": "NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation", "authors": "Maoqi Liu,Quan Fang,Yuhao Wu,Can Zhao,Yang Yang,Kaiquan Cai", "background": "准确解读NOTAM（航空器航行通告）对于航空安全至关重要，但由于其浓缩且晦涩难懂的语言，无论是人工还是自动处理都面临重大挑战。现有自动化系统通常只能进行浅层解析，无法提取出在操作决策中需要的有用信息。解读NOTAM涉及从不断变化的航空数据中动态获取知识，并应用静态领域规则推断操作状态，这一任务具有双重推理论证的挑战。", "innovation": "我们提出了一种自我进化的框架NOTAM-Evolve，利用增强知识图谱的检索模块进行数据对接。该框架通过闭环学习过程使大型语言模型逐步提高性能，从而减少对大量人工标注推理轨迹的需求。同时，我们还引入了一个包含10,000个专家标注的NOTAM的新基准数据集。实验结果表明，NOTAM-Evolve相比于基础大语言模型显著提高了30.4%的准确率，这是在结构化NOTAM解释任务中的新状态 quo。", "conclusion": "我们的研究表明，NOTAM-Evolve框架通过自我进化和闭环学习机制，能够显著提升大型语言模型复杂NOTAM解释的能力，并在结构化NOTAM解释任务中达到了新的性能峰值。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07969", "html_url": "https://arxiv.org/abs/2511.07969", "title": "统一工作嵌入：双向多任务排序的对比学习", "title_en": "Unified Work Embeddings: Contrastive Learning of a Bidirectional Multi-task Ranker", "authors": "Matthias De Lange,Jens-Joris Decorte,Jeroen Van Hautte", "background": "跨多个行业的劳动力转变推动了对专业化自然语言处理能力的更高需求。然而，源自工作相关背景的任务内在地反映了现实世界的复杂性，表现为长尾分布、极端多标签目标空间和数据稀缺。通用嵌入式模型的兴起引发了对其在工作领域表现的疑问，尤其是在该领域进步主要集中在单一任务上时。因此，引入了WorkBench，这是一个涵盖了六个明确作为排名问题提出的与工作相关任务的统一评估套件，为多任务进展建立了一个共同基准。", "innovation": "依托WorkBench基准，研究发现了跨任务间显著的正向迁移，使用这一洞见从真实数据中组合出任务特定的二分图，并通过对接地进行合成增强。这导致了统一工作嵌入(UWE)，这是一种任务无关的双编码器，利用了我们训练数据结构的许多到许多的InfoNCE目标，并利用了任务无关的软后期交互。UWE在未见过的目标空间上实现了零样本排名性能，并通过缓存任务目标空间嵌入以实现低延迟推理，其宏平均MAP和RP@10在通用嵌入模型上取得了显著提升。", "conclusion": "统一工作嵌入(UWE)展示了在未经见过的目标空间上实现零样本排名性能的能力，通过缓存任务目标空间嵌入实现低延迟推理，并在宏观平均MAP和RP@10上相较于通用嵌入模型显示出显著优势。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07989", "html_url": "https://arxiv.org/abs/2511.07989", "title": "南斯拉夫语言中的文本分类现状：微调还是提示？", "title_en": "State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?", "authors": "Taja Kuzman Pungeršek,Peter Rupnik,Ivan Porupski,Vuk Dinić,Nikola Ljubešić", "background": "直到最近，经过微调的BERT相关模型在文本分类任务中提供了最先进的性能。随着指令调优的解码器模型——通常被称为大型语言模型（LLMs）——的兴起，领域已越来越多地转向零样本和少样本提示。然而，LLMs在文本分类，特别是在资源较少的语言方面，的表现仍未得到充分探索。", "innovation": "该研究评估了当前语言模型在多种斯拉夫南语上的文本分类任务中的表现。将公开可用的微调BERT相关模型与开源和闭源LLMs进行比较，涵盖了情感分类、新闻文章和议会演讲的主题分类以及网络文本的体裁识别三个任务。结果显示，LLMs展示了强大的零样本性能，在某些情况下甚至超越了微调的BERT相关模型。", "conclusion": "虽然LLMs在南斯拉夫语言和英语中的零样本设置中表现相近，但在可预测性、推理速度和计算成本方面的局限性意味着微调的BERT相关模型仍然是大规模自动文本标注的更实际选择。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08017", "html_url": "https://arxiv.org/abs/2511.08017", "title": "HyCoRA: 高对比度角色自适应学习方法以提升角色扮演能力", "title_en": "HyCoRA: Hyper-Contrastive Role-Adaptive Learning for Role-Playing", "authors": "Shihao Yang,Zhicong Lu,Yong Yang,Bo Lv,Yang Shen,Nayu Liu", "background": "现有的多角色扮演方法要么使用一个共享参数模块适用于所有角色，要么为每个角色分配一个单独的参数模块。前者可能忽略每个角色的独特特征，削弱个性学习，后者则可能忽略角色间的共性特征，妨碍共性建模。", "innovation": "提出了HyCoRA（高对比度角色自适应学习）框架，通过平衡学习独特和共享特征来提高多角色扮演能力。具体而言，HyCoRA采用了超低秩自适应结构，包括一个由轻量级超网络生成的角色特定模块和一个可训练的角色共享模块。同时设计了超对比学习机制，帮助超网络识别每个角色的独特特征。", "conclusion": "在英文和中文基准测试上，HyCoRA框架表现优越，进一步的GPT-4评估和可视化分析也验证了HyCoRA捕捉角色特征的能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08126", "html_url": "https://arxiv.org/abs/2511.08126", "title": "Multimodal 大型语言模型中量化和物体感知与人类语言认知存在偏差", "title_en": "Quantification and object perception in Multimodal Large Language Models deviate from human linguistic cognition", "authors": "Raquel Montero,Natalia Moskvina,Paolo Morosi,Tamara Serrano,Elena Pagliarini,Evelina Leivada", "background": "量化现象对于（多模态）大型语言模型（MLLMs）来说尤其难以把握，尽管量化现象涉及到逻辑、语用和数理等多个领域，但 MLMMs 在该领域的具体表现不佳原因尚不清楚。本文关注人类跨语言共享的三个未在MLLM文献中探讨过的量化特征，即量词的等级顺序、使用范围及人类近似数系统中的偏见。", "innovation": "本文研究了跨语言共享的三个未在MLLM文献中探讨过的量化特征：量词的等级顺序、使用范围及人类近似数系统的偏见，并探讨了这些特征在模型架构中的编码方式，以及其是否与人类存在差异。", "conclusion": "在不同任务中的实验结果表明，MLLMs 和人类在这三个特征上的表现存在明显差异。这项工作为理解MLLMs作为语义和语用代理的本质奠定了基础，而跨语言视角也有助于判断它们的能力是否在不同语言中稳定且可靠。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08113", "html_url": "https://arxiv.org/abs/2511.08113", "title": "多模态LLMs在不同模态间未最优地组合技能", "title_en": "Multimodal LLMs Do Not Compose Skills Optimally Across Modalities", "authors": "Paula Ontalvilla,Aitor Ormazabal,Gorka Azkune", "background": "技能组合是指将之前学习的技能组合起来解决新任务的能力。随着神经网络在预训练中获得越来越复杂的技能，尚未清楚它们能否成功地组合这些技能。本文研究了多模态大型语言模型（MLLM）在同一任务中跨模态组合技能的能力，设计了三个可以逐次组合两种模态特定技能来解决的任务，并在两种主要设定下对几个公开的MLLM进行了评估：一是直接提示模型解决问题，二是使用两步级联推理方法，手动强制组合两种技能。即使是在简单的组合下，所有评估的MLLM也都表现出显著的跨模态技能组合差距。", "innovation": "本文通过设计三个可以通过组合两种模态特定技能来解决的问题来研究MLLM在多模态条件下的技能组合能力，并且探究了两种促进技能组合的策略：一是使用详细推理提示，二是特定的微调策略。尽管这些策略提高了模型的性能，但仍然存在显著的技能组合差距，这表明仍需要更多研究来改善MLLM在跨模态技能组合方面的能力。", "conclusion": "本文发现，即使是在简单的技能组合下，所有评估的MLLM也都表现出显著的跨模态技能组合差距。虽然使用详细推理提示和特定的微调策略可以一定程度上提高模型的技能组合能力，但仍存在显著差距，表明需要更多的研究来进一步提高MLLM在跨模态技能组合方面的表现。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07998", "html_url": "https://arxiv.org/abs/2511.07998", "title": "Self-Correction Distillation for Structured Data Question Answering", "title_en": "Self-Correction Distillation for Structured Data Question Answering", "authors": "Yushan Zhu,Wen Zhang,Long Jin,Mengshu Sun,Ling Zhong,Zhiqiang Liu,Juan Li,Lei Liang,Chong Long,Chao Deng,Junlan Feng", "background": "结构化数据问答（QA），包括表格QA、知识图谱（KG）QA和时间 KG QA是研究的重点领域。大型语言模型（LLMs）的进展推动了统一结构化QA框架（如TrustUQA）的发展，但这些框架在应用到小型LLMs时面临挑战，因为小型LLMs容易在生成结构化查询时出错。", "innovation": "为提高小型LLMs的结构化数据QA能力，作者提出了一种自我纠正蒸馏（SCD）方法。该方法包括错误提示机制（EPM）设计，以在推理过程中检测错误并提供个性化错误消息，以及两阶段蒸馏策略，旨在将大型LLMs的查询生成能力和错误纠正能力转移给小型LLMs。实验表明，SCD在小型LLMs (8B) 上实现了最佳性能和更优秀的泛化能力，相较于其他蒸馏方法，其性能接近GPT4在某些数据集上的表现。同时，配备EPM的大型LLMs在大多数数据集上超过最先进的结果。", "conclusion": "我们的SCD方法通过对小型LLMs的自我纠正蒸馏，显著提高了其结构化数据QA能力。经过多个基准测试，SCD方法在小型LLMs上的表现优于其他蒸馏方法，并且在某些数据集上接近GPT4的表现。同时，配备EPM的大型LLMs在大多数数据集上的表现也超越了现有最佳结果。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08128", "html_url": "https://arxiv.org/abs/2511.08128", "title": "基于短语锚点要旨压缩的长上下文大语言模型压缩", "title_en": "Sentence-Anchored Gist Compression for Long-Context LLMs", "authors": "Dmitrii Tarasov,Elizaveta Goncharova,Kuznetsov Andrey", "background": "该工作研究了利用学习到的压缩标记对大语言模型（LLMs）的上下文进行压缩，以减少处理长序列所需的内存和计算需求。研究展示了预训练的LLMs可以在保持性能不显著下降的情况下，通过2到8倍的压缩来压缩其上下文，这一结果在短上下文和长上下文基准测试中得到验证。", "innovation": "研究提出的方法能够在30亿参数量级的LLaMA模型上实现与现有压缩技术相当的效果，同时达到更高的压缩率。", "conclusion": "预训练的LLMs可以经过微调以压缩其上下文，压缩比例在2倍至8倍之间，且在短和长上下文基准测试中保持了满意的性能，特别是在参数规模较大的LLaMA模型上，该方法取得了与现有技术并驾齐驱的效果，同时实现了更高的压缩效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08109", "html_url": "https://arxiv.org/abs/2511.08109", "title": " estranged predictions: 用遮蔽语言模型衡量语义范畴破坏", "title_en": "Estranged Predictions: Measuring Semantic Category Disruption with Masked Language Modelling", "authors": "Yuxuan Liu,Haim Dubossarsky,Ruth Ahnert", "background": "本文探讨科幻小说如何通过测量人类、动物和机器之间概念透过的程度来动摇 Ontological 分类的稳定性。研究者们利用 RoBERTa 生成遮蔽指代词的词典替代品，并通过 Gemini 进行分类，量化概念滑动中存在的三个指标：保留率、替换率和熵，以此来映射不同文学体裁中类别边界的稳定或中断情况。研究发现，科幻小说表现出增强的概念流动性，特别是在机器引用中，这些引用显示出显著的跨类别替代和分散。相比之下，人类词条保持了语义连贯性，经常支持替代性层次结构。研究结果表明，科幻小说中的陌生化作为一种结构性的语义规范的受控扭曲，可以通过概率建模检测，并且用遮蔽语言模型法批评性地演讲凭证，能够揭示受文学体裁条件制约的本体论假设。这项研究为计算文学研究的方法论库增添了新方法，并为科幻小说中的语言基础设施提供了新的见解，", "innovation": "本文创新地使用了遮蔽语言模型 (MLM) 来量化科幻小说概念透过的程度，这是对科幻小说中陌生化效应的计算测量。它不仅提供了对科幻小说概念语义边界的理解，还强调了 MLM 在批判性分析中的角色，使研究人员能够检测并理解文学体裁如何影响语义和本体论假设。这些方法在计算文学研究中是一种新的方法，并对其他文学体裁有潜力的应用价值。", "conclusion": "本文的研究揭示了科幻小说中语义范畴的破坏性变化，并强调了陌生化作为一种受控语义规范扭曲的力量。遮蔽语言模型作为理解文学和解读本性论前提的工具，对于批判性分析文学研究具有重要意义。该研究为计算文学研究提供了新的方法，并提供了对科幻小说语言基础设施的新见解。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08085", "html_url": "https://arxiv.org/abs/2511.08085", "title": "BARD10：一个新的基准揭示孟加拉停用词在作者识别中的重要性", "title_en": "BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution", "authors": "Abdullah Muhammad Moosa(1),Nusrat Sultana(1),Mahdi Muhammad Moosa(2),Md. Miraiz Hossain(1) ((1) Department of Mechatronics &amp; Industrial Engineering, Chittagong University of Engineering &amp; Technology, Chittagong 4349, Bangladesh, (2) Department of Mathematics &amp; Natural Sciences, Brac University, Dhaka 1212, Bangladesh)", "background": "本研究旨在深入探讨孟加拉语作者身份认定问题，构建了一个名为BARD10的新平衡基准语料库，该语料库由10位当代孟加拉作家的博客和观点散文构成。研究还系统地分析了停用词删除对经典和深度学习模型的影响，以揭示孟加拉语停用词的风格意义。通过对比BAAD16等已有基准语料库，研究发现TF-IDF + SVM是所有数据集中的基线表现，而孟加拉BERT在某些数据集上的表现较差，表明停用词的敏感性不同。研究强调了停用词在作者识别中的重要性，并指出ML模型在短文本限制下的有效性，以及BARD10如何将正式文学与当代网络对话联系起来，提供了一个可重复的基准，用于未来面向长距离或领域特定的变换模型的研究。", "innovation": "1. 建立了一个名为BARD10的新平衡基准语料库，用于孟加拉语作者身份认定的研究。\n2. 系统性地分析了停用词删除对不同模型（包括支持向量机、孟加拉BERT、XGBoost和MLP多层感知器）的影响。\n3. 揭示了孟加拉语停用词在作者识别中的重要性，并发现了ML模型在短文本限制下的有效性。", "conclusion": "研究发现，BARD10作家对停用词修剪非常敏感，而BAAD16作家则表现出相对的稳定性，这表明了不同作家在停用词依赖上的差异。停用词中的高频率成分传递了作家的签名，而这些信息在变压器模型中会被削弱或减少。因此，研究确定了三个主要洞见：孟加拉语停用词是风格特征的重要指示器；精细校准的ML模型在短文本限制下是有效的；BARD10连接了正式文学与当代网络对话，提供了未来长距离或领域特定变换模型的可重复基准。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08143", "html_url": "https://arxiv.org/abs/2511.08143", "title": "关系优先：LLM基于文档级别关系提取的新范式", "title_en": "Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction", "authors": "Qiankun Pi,Yepeng Sun,Jicang Lu,Qinlong Fan,Ningbo Huang,Shiyu Wang", "background": "大语言模型（LLMs）在文档理解方面展现了卓越的能力。然而，最近的研究表明，LLMs在文档级别关系提取（DocRE）方面仍然存在性能差距，因为需要进行细粒度的理解。LLM方法中普遍采用的'先提取实体再预测关系'的范式导致了这些差距，主要原因包括（1）大量无关的实体对引入了噪声，干扰了真正相关实体对的关系预测。（2）虽然LLM识别了实体之间的语义关联，但超出预定义集合的关系标签仍被视为预测错误。", "innovation": "本文提出了基于LLM的DocRE的新范式——关系优先（RelPrior）。对于挑战（1），RelPrior利用二元关系作为先验知识来提取和确定两个实体是否相关，从而过滤掉无关的实体对并减少预测噪声。对于挑战（2），RelPrior利用预定义的关系作为先验知识来进行三元组提取而不是直接预测关系，从而避免了由于严格的预定义关系标签导致的误判。", "conclusion": "通过在两个基准数据集上的广泛实验表明，RelPrior达到了最先进的性能，并超越了现有的LLM基于的DocRE方法。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08139", "html_url": "https://arxiv.org/abs/2511.08139", "title": "关于位置编码、形态复杂性和词序灵活性之间的关系研究", "title_en": "On the Interplay between Positional Encodings, Morphological Complexity, and Word Order Flexibility", "authors": "Kushal Tatariya,Wessel Poelman,Miryam de Lhoneux", "background": "现有的语言模型架构主要是为英语设计的，然后应用于其他语言。一个开放的问题是这种架构的偏见是否会导致与英语结构不同的语言的性能下降。本研究特别关注位置编码这一架构选择，探讨形态复杂性和词序灵活性之间假设的相互作用，即复杂的形态可能意味着更灵活的词序，反之亦然。研究者通过预训练七种不同类型的语言模型，评估了绝对位置编码、相对位置编码和无位置编码的效果，发现位置编码与形态复杂性和词序灵活性之间的关系并不如预期那样明显。研究结论指出，任务的选择、语言的不同以及评估标准对于得出稳定结论至关重要。", "innovation": "本研究创新性地通过预训练和下游任务评估的方式，研究了位置编码、形态复杂性与词序灵活性之间的关系，提供了一个新的视角来理解不同语言间在绝对位置编码、相对位置编码和无位置编码的特定语言处理效果对比。这种研究方法特别适用于那些与英语在语法上有较大差异的语言，并为后续的跨语言模型设计提供了参考。", "conclusion": "研究结果表明，位置编码、形态复杂性和词序灵活性之间的假设意味着理论推断可能并不直接等于实际表现，即在不同任务和语言设置下，所观察到的性能差异可能更多地依赖于选择的任务、语言和评估标准。研究强调了在进行跨语言语言模型研究时需要谨慎考虑这些因素以获得有效的结论，为未来的语言模型研究和开发提供了重要的指南。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08204", "html_url": "https://arxiv.org/abs/2511.08204", "title": "使用随机采样进行调优的编码器优于开放权重GPT在天文学知识提取中的表现", "title_en": "Encoder Fine-tuning with Stochastic Sampling Outperforms Open-weight GPT in Astronomy Knowledge Extraction", "authors": "Shivam Rawat,Lucie Flek,Akbar Karimi", "background": "天文学的科学文献正在迅速增长，这使得从研究论文中自动提取关键实体和上下文信息变得越来越重要。为了应对这种需求，本文提出了一种基于编码器系统的天文文章知识提取方法。", "innovation": "本文实施数个任务的变换器系统，该系统基于SciBERT模型，并针对天文语料库进行了微调。为了进行微调，使用随机采样训练数据的方法，并在推理阶段使用众数投票来处理测试段。该系统的简单实现方式在性能上超过了开放权重的GPT基线。", "conclusion": "本文开发的基于编码器的系统，能够在天文文献知识提取任务中显著超越现有的开放权重GPT模型，在细调和推理过程中采用了随机采样的方法实现更好的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08199", "html_url": "https://arxiv.org/abs/2511.08199", "title": "在基于发展的语言模型课程学习中，句法类别是否有帮助？", "title_en": "Do Syntactic Categories Help in Developmentally Motivated Curriculum Learning for Language Models?", "authors": "Arzu Burcu Güven,Anna Rogers,Rob van der Goot", "background": "研究考察了BabyLM语料库的句法特性以及在CHILDES中的年龄组。研究发现CHILDES在句法特征上没有明显的年龄差异。但是，训练数据的句法知识对于语言任务中的模型性能解释是有所帮助的。在课程学习方法上，研究探索了一系列基于认知的课程方法来促进发展性语言学习。一些课程对于阅读任务有所助益，但主要的性能提升来自于使用句法可分类的数据子集，而非完整的嘈杂语料库。", "innovation": "研究提出并探讨了多种基于认知启发的课程学习方法，并发现对于任务性能改进而言，重要的是可以进行句法分类的数据集，而非原始的嘈杂语料库。这对于语言模型的课程学习设计有重要的启发意义。", "conclusion": "虽然CHILDES在句法上没有明显的年龄差异，但可以通过理解训练数据的句法特性和使用句法可分类的数据子集来提高模型在语言任务中的性能。基于认知启发的课程学习方法中，只有某些方法有助于阅读任务，主要的性能改进来源于句法可分类的数据而不是原始语料库。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08145", "html_url": "https://arxiv.org/abs/2511.08145", "title": "仍不在那里：大型语言模型在诗歌到散文转换任务上能否超越小型特定任务Seq2Seq模型？", "title_en": "Still Not There: Can LLMs Outperform Smaller Task-Specific Seq2Seq Models on the Poetry-to-Prose Conversion Task?", "authors": "Kunal Kingkar Das,Manoj Balaji Jagadeeshan,Nallani Chakravartula Sahith,Jivnesh Sandhan,Pawan Goyal", "background": "大型语言模型（LLMs）在NLP任务中被广泛认为是通用解决方案，尤其是在英语中。然而，对于资源匮乏且形态丰富的语言如梵语，这一假设是否成立？论文通过比较指令微调和上下文提示的大语言模型与为特定任务微调的编码-解码器模型在梵语诗歌到散文转换任务上的表现，来研究这一问题。该任务具有挑战性，涉及自由词序与严格韵律约束的结合，将梵语文本转化为规范散文需要多步推理，包括成分分割、依赖解析和句法线性化。这些特征使梵语诗歌到散文转换成为评估LLMs是否能超越专业模型的理想平台。", "innovation": "文章创新地应用了指令微调于通用模型，并设计了基于Paninian语法和古典评注启发式的上下文学习模板。此外，还针对特定任务彻底微调了一个ByT5-Sanskrit Seq2Seq模型，并通过实际实验展示了领域特定微调显著优于指令驱动大语言模型的方法。提示策略提供了一种在缺乏特定领域语料库的情况下替代微调的方法，而特定任务Seq2Seq模型在域外测试中表现出良好的泛化能力。还发现了人工评估与Kendall's Tau评分高度相关，证实领域特定模型的优势。", "conclusion": "领域特定微调的ByT5-Sanskrit模型显著优于所有指令驱动的大语言模型。人工评估结果进一步支持了这一结论，且评分与Kendall's Tau评分存在高度相关性。提示策略在缺乏特定领域语料库的情况下是微调的可行替代，而特定任务的Seq2Seq模型在域外测试中表现出良好的泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08245", "html_url": "https://arxiv.org/abs/2511.08245", "title": "利用嵌入微调和RAG的提示调整实现自然语言到SQL的转换", "title_en": "Prompt Tuning for Natural Language to SQL with Embedding Fine-Tuning and RAG", "authors": "Jisoo Jang,Tien-Cuong Bui,Yunjun Choi,Wen-Syan Li", "background": "随着自然语言接口的广泛应用，高效和准确地将自然语言查询翻译成SQL表达式变得至关重要。NLIDBs（自然语言到数据库）已经从早期基于规则的系统发展到了先进的基于神经网络的方法。本文旨在利用生成预训练的最新进展和RAG（检索增强生成）技术，通过提示调整机制纠正错误。这种技术能够诊断错误类型、识别原因、提供修正指令并应用于SQL查询。", "innovation": "本文提出了一个创新框架，该框架结合了错误纠正机制，能够诊断错误类型、识别原因、提供修正指令并应用于SQL查询。此外，该框架进一步利用了嵌入微调和RAG技术，这使得外部知识库能够被用于提高准确性和透明度。实验结果显示，该框架在现有基准上的准确率提升了12%，展示了其在当代数据驱动环境中数据访问和处理方面的潜力。", "conclusion": "通过全面的实验，我们的框架展示了相较于现有基准，其在准确率上显著提升了12%，这突显了其在当代数据驱动环境中革命性地改善数据访问和处理的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08225", "html_url": "https://arxiv.org/abs/2511.08225", "title": "使用学习分析基准教育大语言模型：反馈中性别偏差的案例研究", "title_en": "Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback", "authors": "Yishan Du,Conrad Borchers,Mutlu Cukurova", "background": "随着教师越来越多地将通用人工智能（GenAI）应用于教育实践中，需要有 robust 的方法来评估大语言模型（LLMs）在教育目的方面的 performance。文章介绍了一种基于嵌入的方法来检测 LLMs 在形成性反馈中隐含偏差的框架。", "innovation": "提出了一个基于嵌入的基准测试框架，通过构造控制对照组来检测 LLMs 在形成性反馈中的隐含偏差；在 600 份真实的学生作文中使用控制对照组，根据性别隐含线索和显性线索来评估 LLMs 的反应差异；并且通过多次变换测试和维度减少可视化来评估 LLMs 的性别敏感性。", "conclusion": "研究发现，即使是最先进的 LLMs 也会对性别替代表现出不一致的语义响应，表明在提供给学习者的反馈中存在持续的性别偏见。进一步的定性分析显示，在男性线索下提供了更多的支持自主性反馈，而在女性线索下提供了更多的控制性反馈。研究讨论了教育 GenAI 公平审核的意义，提出了学习分析中对抗事实评估的报告标准，并给出了关于提示设计和部署的实际指导，以确保公平的反馈。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08317", "html_url": "https://arxiv.org/abs/2511.08317", "title": "LLM仿真审稿人-作者辩论的异构图推理在自动论文评审中的应用", "title_en": "Automatic Paper Reviewing with Heterogeneous Graph Reasoning over LLM-Simulated Reviewer-Author Debates", "authors": "Shuaimin Li,Liyang Fan,Yufang Lin,Zeyang Li,Xian Wei,Shiwen Ni,Hamid Alinejad-Rokny,Min Yang", "background": "现有文献评审方法往往依赖表面特征或直接使用大型语言模型（LLMs），这些方法容易出现幻觉、有偏评分以及推理能力有限的问题。此外，这些方法通常难以捕捉审稿人-作者交互中固有的复杂论辩推理和谈判动态。", "innovation": "提出了ReViewGraph（审稿人-作者辩论图推理器），这是一种新颖的框架，通过LLM模拟多轮审稿人-作者辩论来进行异构图推理。通过使用图神经网络分析这些结构化的辩论图，ReViewGraph能够捕捉到细微的论辩动态，并支持更明智的评审决策。", "conclusion": "在三个数据集上的广泛实验表明，ReViewGraph相对于强基准模型的平均相对改进率为15.73%，证明了建模详细的审稿人-作者辩论结构的价值。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08230", "html_url": "https://arxiv.org/abs/2511.08230", "title": "VocalBench-zh：在 Mandarin 语境中分解和基准测试语音对话能力", "title_en": "VocalBench-zh: Decomposing and Benchmarking the Speech Conversational Abilities in Mandarin Context", "authors": "Heyang Liu,Ziyang Cheng,Yuhao Wang,Hongcheng Liu,Yiqi Li,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang", "background": "随着多模态大型语言模型（LLMs）的发展，智能交互方式也得到了提升，其中包含了语音交互。由于普通话是全球使用最广泛的语言之一，大多数模型都支持普通话，以提高其适用性和覆盖面。然而，缺乏全面的普通话语音到语音（S2S）基准数据集阻碍了开发者的系统评估，影响了用户的公平的模型比较。因此，迫切需要建立特定于普通话语境的基准测试工具以解决以上问题，本文提出了VocalBench-zh，一种按照能力水平划分、适用于普通话语境的评价套件，包括10个精心设计的子集和超过10000个高质量的数据实例，涵盖了12个面向用户的特性。", "innovation": "该研究提出了VocalBench-zh，这是一种专门针对普通话语境的评价工具，它包括了10个经过精心设计的子集和超过10000个高质量的数据实例，覆盖了12个用户相关的特点。该工具能够帮助开发者进行系统评估，并为用户提供了公平的模型比较。这一基准测试套件的建立克服了之前缺乏普通话S2S基准数据集的问题，为语音交互系统的下一阶段提供新的见解。", "conclusion": "对14个主要模型进行的评估实验揭示了当前路径中的共同挑战，并进一步强调了对未来一代语音交互系统的新见解的需求。评估代码和数据集将在这个链接中提供：this https URL."}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08298", "html_url": "https://arxiv.org/abs/2511.08298", "title": "使用VLLMs理解和解析复杂表格的层次结构：一个基准与实验", "title_en": "Hierarchical structure understanding in complex tables with VLLMs: a benchmark and experiments", "authors": "Luca Bindini,Simone Giovannini,Simone Marinai,Valeria Nardoni,Kimiya Noor Ali", "background": "本文研究了Vision Large Language Models（VLLMs）理解与解释科学文章中的表格结构的能力。通过PubTables-1M大规模科学表格数据集，提取了一部分作为复杂层次表格（CHiTab）的集合，用于验证VLLMs的表层次结构理解能力。研究使用了多种通用VLLMs及其不同版本来测试它们对复杂表的理解能力。", "innovation": "通过设计特定的提示工程策略，探索VLLMs在无需额外处理的情况下推断表格层次结构的能力。不同形式的提示和写作样式的实验表明，通用VLLMs可以完成这种任务，即使它们不是专门为了理解表格结构而设计的。此外，还通过比较人类和模型在解决这一任务上的表现，验证了VLLMs的性能。", "conclusion": "研究证明了通用VLLMs在处理复杂表格方面具有潜力，但仍存在一定的局限性。未来的工作可集中在将结构化数据的解析能力集成到通用VLLMs中，从而进一步提升其处理复杂表格的能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08247", "html_url": "https://arxiv.org/abs/2511.08247", "title": "ParliaBench：LLM生成议会演讲的评估和基准框架", "title_en": "ParliaBench: An Evaluation and Benchmarking Framework for LLM-Generated Parliamentary Speech", "authors": "Marios Koniaris,Argyro Tsipi,Panayiotis Tsanakas", "background": "议会演讲生成对大型语言模型提出了超出常规文本生成任务的独特挑战。不同于一般的文本生成任务，议会演讲不仅需要语言质量，还需要政治真实性和政治理论一致性。目前的语言模型缺乏特定于议会情境的专业训练，现有的评估方法主要关注标准NLP指标，而忽视了政治真实性。因此，需要开发专门的基准和评估框架来解决这一问题。", "innovation": "我们提出了ParliaBench，这是一种用于议会演讲生成的基准框架，包括一个包含英国议会演说的专门数据集，以及结合计算指标与LLM评判者的评估框架，用于衡量生成的质量，涵盖语言质量、语义连贯性和政治真实性。我们还提出了两种新颖的基于嵌入的度量标准，即政治光谱对齐和政党对齐，以量化意识形态定位。此外，我们针对五种大型语言模型进行了微调，生成了28000篇演讲，并使用我们的框架进行评估，比较了基线和微调模型。结果显示，微调在大多数度量标准上产生了统计意义上的改进，而我们的新型度量标准在政治维度上展示了强大的区分力。", "conclusion": "我们证明了微调可以显著提高大多数指标的性能，而我们的新型度量标准在政治维度方面表现出强大的区分力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08319", "html_url": "https://arxiv.org/abs/2511.08319", "title": "适应性多智能体响应精炼在对话系统中的应用", "title_en": "Adaptive Multi-Agent Response Refinement in Conversational Systems", "authors": "Soyeong Jeong,Aparna Elangovan,Emine Yilmaz,Oleg Rokhlenko", "background": "大型语言模型（LLMs）在对话系统中表现出色，能够生成类人的回应。然而，它们在处理个性化或特定知识需求时可能表现不足。在真实场景中，依赖用户检测错误并请求新回复是不切实际的。现有方法主要集中在单个LLM内部生成更准确的回复，但这种做法难以综合考量有效对话所需的多个方面。因此，本文提出了一个多智能体框架来精炼响应，其中每个智能体负责某一具体方面，以增强对话的质量和效果。", "innovation": "提出了一个多智能体框架，每个智能体针对对话质量的关键方面（事实性、个性化和连贯性）进行专门召回和修改，并引入了一种动态通信策略。该策略根据每个查询的具体要求，灵活选择并协调最相关的智能体，从而提高合作效果，相比传统方法，在涉及知识或用户个性的任务中表现优异。", "conclusion": "在具有挑战性的对话数据集上验证了该框架，表明相比之下，这种方法在涉及知识或用户个性的任务中显著优于相关_baseline。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08372", "html_url": "https://arxiv.org/abs/2511.08372", "title": "动态发音模型DYNARTmo：动态运动生成与言语手势", "title_en": "The Dynamic Articulatory Model DYNARTmo: Dynamic Movement Generation and Speech Gestures", "authors": "Bernd J. Kröger", "background": "本文描述了动态发音模型DYNARTmo的当前实现，该模型基于言语手势及其对应的手势得分生成连续的发音器官运动。该模型提供了一个受神经生物学启发的计算框架，用于从语言表示到发音声学实现的层级控制模拟。它涉及手势 inventory 的结构，手势在手势得分中的协调以及将其转化为控制DYNARTmo发音腔模型的连续发音器官轨迹的过程。", "innovation": "该模型基于言语手势和对应的手势得分，生成连续的发音器官运动。该模型提供了一个受神经生物学启发的计算框架，用于模拟从语言表示到发音声学实现的层级控制。重点在于手势 inventory 的结构，协调以及如何将这些转换为控制发音腔模型的连续发音器官轨迹的过程。", "conclusion": "该研究提出了一种新颖的动态发音模型DYNARTmo，该模型能够基于言语手势及其得分生成连续的发音器官运动。通过神经生物学启发的方法，该模型模拟了从语言表示到发音声学实现的层级控制过程。该模型的结构、手势协调及其转化机制揭示了其潜在的应用价值和优势。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08376", "html_url": "https://arxiv.org/abs/2511.08376", "title": "TurkEmbed：用于NLI和STS任务的土耳其嵌入模型", "title_en": "TurkEmbed: Turkish Embedding Model on NLI & STS Tasks", "authors": "Özay Ezerceli,Gizem Gümüşçekiçci,Tuğba Erkoç,Berke Özenç", "background": "目前的土耳其语嵌入模型往往依赖于机器翻译数据集，这可能限制了它们的准确性和语义理解能力。TurkEmbed利用多样的数据集和先进的训练技术，特别是matryoshka表示学习，旨在在自然语言推理（NLI）和语义文本相似性（STS）任务中超越现有模型，提高其鲁棒性和准确性。", "innovation": "TurkEmbed采用了结合多种数据集和高级训练技术的方式，特别是matryoshka表示学习，以实现更强大和准确的嵌入。这种模型能够适应各种资源受限的环境，提供更快的编码能力。TurkEmbed在土耳其语STS-b-TR数据集上的评估表明，在语义相似性任务上有显著改进。此外，TurkEmbed在All-NLI-TR和STS-b-TR基准测试中超越了当前最先进的模型Emrecan，取得了1-4%的改进。", "conclusion": "TurkEmbed有望通过提供更细腻的语言理解来增强土耳其自然语言处理生态系统，并促进下游应用的进步。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08364", "html_url": "https://arxiv.org/abs/2511.08364", "title": "DPRM：多跳问答任务中的双隐式过程奖励模型", "title_en": "DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering", "authors": "Xinyi Wang,Yiping Song,Zhiliang Tian,Bo Liu,Tingjin Luo,Minlie Huang", "background": "在多跳问答（MHQA）任务中，Chain of Thought (CoT)通过多步骤推理指导大型语言模型（LLMs）提高生成的质量，而Knowledge Graphs (KGs)通过语义匹配减少幻觉。Outcome Reward Models (ORMs)在生成最终答案后提供反馈，但无法评估多步骤推理的过程。传统的Process Reward Models (PRMs)评估推理过程，但需要昂贵的人工注释或展开生成。虽然隐式PRM仅使用输出信号并通过奖励参数化训练步骤奖励，无需显式注释，但它更适合处理MHQA任务中的多步骤推理。然而，现有的隐式PRM仅用于纯文本场景，在适应MHQA任务时无法处理KG中的图结构约束，也无法捕捉CoT与KG路径之间的潜在不一致。", "innovation": "本文提出了一种针对MHQA任务的DPRM（Dual Implicit Process Reward Model），这是一种双隐式过程奖励模型。它训练了两种隐式PRM来分别处理CoT和KG推理。这两种PRM，即KG-PRM和CoT-PRM，通过奖励参数化从输出信号中推导出步骤级奖励，无需额外的显式注释。其中，KG-PRM使用偏好对来从KGs中学习结构约束。DPRM还引入了CoT推理步骤与KG推理步骤之间的一致性约束，使两种PRM相互验证并协同优化推理路径。作者还提供了过程奖励推导的理论证明。实验结果显示，该方法在多个数据集上的表现优于13个基线方法，特别是在Hit@1上的改进幅度高达16.6%。", "conclusion": "我们的方法在多个数据集上优于13种基线方法，在Hit@1上的改进幅度高达16.6%。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08392", "html_url": "https://arxiv.org/abs/2511.08392", "title": "PCRLLM: 在逐步逻辑约束下带有证据推理的大语言模型", "title_en": "PCRLLM: Proof-Carrying Reasoning with Large Language Models under Stepwise Logical Constraints", "authors": "Tangrui Li,Pei Wang,Hongzheng Wang Christian Hahm,Matteo Spatola,Justin Shi", "background": "大型语言模型（LLMs）通常缺乏逻辑连贯性，它们在将前提与结论映射时不遵循显式的推理规则。这种缺乏逻辑连贯性的问题引发了对模型产出的信任度和可靠性的担忧，尤其是在黑盒设置中。文章旨在解决这一问题，提出了一种名为Proof-Carrying Reasoning with LLMs (PCRLLM)的框架。", "innovation": "PCRLLM框架将推理过程限制为单一步骤的推理，并保留自然语言的形式。每个输出都明确地指定了前提、规则和结论，从而使得这些输出可以与目标逻辑进行验证。此外，PCRLLM方法允许在符合正式规则的前提下比较和集成多个LLM的中间步骤，这有助于系统性的LLM协作。另外，文章还提出了一种基准方案，用于生成大规模步骤层次推理数据，该方案结合了自然语言表达能力和正式严谨性，从而提高了推理的有效性和可靠性。", "conclusion": "通过PCRLLM框架，模型的推理过程和输出被明确地界定，支持了链式验证，即使在黑盒环境中也能保持推理的一致性和可信度。此外，采用该框架还可以促进多模型间的协调工作，进一步提高了模型推理的有效性和准确性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08325", "html_url": "https://arxiv.org/abs/2511.08325", "title": "AgentPRM：通过逐级承诺与进步的进程奖励模型LLM代理", "title_en": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "authors": "Zhiheng Xi,Chenyang Liao,Guanyu Li,Yajie Yang,Wenxiang Chen,Zhihao Zhang,Binghai Wang,Senjie Jin,Yuhao Zhou,Jian Guan,Wei Wu,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "尽管大型语言模型（LLMs）在多轮决定性任务（例如网购和浏览器导航中的代理任务）中表现出色，但仍面临挑战，这些任务需要根据环境反馈序列做出明智决策。前人的工作往往依赖于复杂的提示工程或使用专家轨迹进行微调来提高性能。本文从不同角度出发，探讨了通过构建过程奖励模型（PRM）来评估并指导代理决策过程的方法。不同于LLMs推理中的逐步骤正确性评分，代理任务中的行动没有绝对的正确性，而是应基于其与目标的接近度以及所取得的进展进行评估。因此提出了一个重新定义的针对代理任务的进程奖励模型（AgentPRM），以捕捉顺序决策之间的相互依赖关系及其对最终目标的贡献，从而实现更好的进度跟踪和探索与利用平衡。为了大规模获取训练数据，采用了基于时差估计方法（TD-based）与广义优势估计（GAE）相结合的方法，这一方法要比以前的方法更具样本效率。广泛的实验表明，与基线相比，AgentPRM在不同的代理任务中，计算效率提高了超过8倍，并在测试时空计算量扩增时表现出稳健的改进。我们还进行了详细分析以展示我们的方法如何工作，并提供进一步的见解，例如将AgentPRM应用于LLM代理的强化学习中。", "innovation": "提出了一个专门为代理任务设计的过程奖励模型（AgentPRM），能够在捕捉顺序决策间的相互依赖关系及对最终目标的贡献的同时，提高进度跟踪和探索利用的平衡。通过结合基于时差估计方法和广义优势估计的步骤，实现了比现有方法更高的样本效率。该方法在多个代理任务中展现出显著的计算效率和稳健的性能提升。", "conclusion": "通过引入AgentPRM，本文显著提高了代理任务的效率和性能，尤其是在增大计算量的情况下，AgentPRM依然能有效提升代理任务的表现。此外，该方法为LLM代理的强化学习提供了新的视角和途径，展示了其在实际应用场景中的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08500", "html_url": "https://arxiv.org/abs/2511.08500", "title": "SPEAR-MM: 通过模型合并进行选择性参数评估和恢复以实现高效金融大语言模型适应", "title_en": "SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation", "authors": "Berkcan Kapusuzoglu,Supriyo Chakraborty,Renkun Ni,Stephen Rawls,Sambit Sahu", "background": "金融领域优化的大语言模型（LLMs）通常会遗忘基本的推理能力，这对于客户服务和复杂金融分析至关重要。现有的持续微调方法难以同时保留这些基本能力并适应特定领域的需求，导致性能表现不佳。", "innovation": "提出了一种名为SPEAR-MM的选择性参数评估和恢复并通过模型合并的框架，通过后见之明的分析估计每层对外部基准的影响，然后通过球面插值合并选择冻结或恢复变压器层。SPEAR-MM方法能够保留大部分基本能力，同时保持较高程度的领域适应性增益，并且在资源受限的条件下能够减少90%的计算成本。", "conclusion": "与标准持续预训练相比，SPEAR-MM在保留一般能力方面提高了21.5个百分点，同时保持了领域适应性增益的94%。此外，该方法还为用户提供了可解释的权衡控制，这对于金融领域应用非常有利。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08455", "html_url": "https://arxiv.org/abs/2511.08455", "title": "社会机器人遇见捷径：大语言模型如何助于处理未知不变性OOD场景？", "title_en": "Bot Meets Shortcut: How Can LLMs Aid in Handling Unknown Invariance OOD Scenarios?", "authors": "Shiyan Zheng,Herun Wan,Minnan Luo,Junhang Huang", "background": "现有的社交机器人检测器在基准测试中表现良好，但在面对多种真实世界的场景时仍然缺乏稳健性，主要原因是缺乏清晰的 ground truth 和各种误导性线索的影响。特别的是，模型依赖于错误的相关性而非因果任务相关特征的“捷径学习”问题尚未得到充分关注。为此，该研究深入探讨了基于文本特征的检测器如何受到潜在捷径的影响，这些特征最易被社交机器人操纵，并设计了一系列捷径场景来评估模型的鲁棒性。", "innovation": "该研究创新性地提出了基于大语言模型的缓解策略，利用反事实数据扩增方法从数据和模型两个层面的三个不同层次来应对捷径问题，分别为个体用户文本数据和整体数据集的数据分布，以及模型提取因果信息的能力。这些方法在捷径场景下实现了平均相对性能提高56%。", "conclusion": "通过引入捷径场景并使用大语言模型的反事实数据扩增策略，本研究展示了显著的性能提升，证明了该方法对社交机器人检测器在复杂环境下的鲁棒性的有效改进。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08394", "html_url": "https://arxiv.org/abs/2511.08394", "title": "作为LLMs奖励信号的交互动力学", "title_en": "Interaction Dynamics as a Reward Signal for LLMs", "authors": "Sian Gooding,Edward Grefenstette", "background": "目前，大型语言模型（LLMs）在多轮对话中的对齐通常依赖于从文本内容中提取的奖励信号。然而，这种方法忽视了一个丰富的互补信号来源：交互本身的动力学。这篇论文引入了基于轨迹的奖励信号（TRAICE），这是一种新的奖励信号，源自对话嵌入轨迹的几何属性，我们称其为‘对话几何学’。通过两种不同的模型实验，展示了仅基于结构信号的奖励模型在两两准确性上能达到类似强大LLM基线的水平。进一步的实验证明，结合交互动力学和文本分析的混合模型能实现最佳性能，证明了这两方面的互补特性。", "innovation": "TRAICE，一种基于对话轨迹几何属性的新型奖励信号框架，以及将交互动力学与文本分析相结合的混合模型，证明了对话过程中的交互动态对于LML的对齐同样重要，并提出了一个能够同时对齐和诊断交互模式的新框架，强调了沟通方式在预测成功中的重要性，提供了一种保护隐私的解决方案。", "conclusion": "这项工作为交互环境中的代理对齐提供了强有力的证据，即如何沟通与说什么同样重要，同时为理解驱动成功协作的交互模式提供了一种诊断工具，证明了基于对话几何学的奖励信号的有效性和互补性，提出了新的隐私保护框架。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08507", "html_url": "https://arxiv.org/abs/2511.08507", "title": "介绍用于孟加拉手语翻译与研究的孟加拉句子-词汇对照数据集", "title_en": "Introducing A Bangla Sentence - Gloss Pair Dataset for Bangla Sign Language Translation and Research", "authors": "Neelavro Saha,Rafi Shahriyar,Nafis Ashraf Roudra,Saadman Sakib,Annajiat Alim Rasel", "background": "孟加拉手语（BdSL）翻译是一个低资源自然语言处理任务，由于缺乏大规模的数据集，这些数据集通常仅限于句级翻译。现有研究主要集中在词和字母级别的检测，很少涉及句级翻译。现有的BdSL翻译任务数据集极度稀少，限制了此类研究的发展。", "innovation": "本文提出了一个名为Bangla-SGP的新颖平行数据集，该数据集包含1000个人工标注的句子-词汇对照对，并增加了大约3000个通过基于规则的检索增强生成（RAG）管道使用句法学和形态学规则生成的合成对照对。通过严格分析人工标注的对照对并与专业手语使用者紧密合作，该数据集采用了基于规则的语言策略和提示工程技术。此外，本文对多个基于变压器的模型（如mBart50、Google mT5、GPT4.1-nano）进行了微调，并使用BLEU分数评估其句级到词汇序列的翻译性能，从而对比了这些模型在数据集和RWTH-PHOENIX-2014T基准上的翻译一致性。", "conclusion": "本文通过首次构建大型孟加拉手语平行数据集，推动了该领域的研究，并通过使用基于变压器的模型和广泛的语言策略实现了高效的句子到词汇序列的翻译。同时，本文通过BLEU分数评估了各种模型的翻译一致性，并进一步明确了在BdSL翻译领域现有的研究局限性和改进空间。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08505", "html_url": "https://arxiv.org/abs/2511.08505", "title": "结构化RAG用于回答聚合性问题", "title_en": "Structured RAG for Answering Aggregative Questions", "authors": "Omri Koshorek,Niv Granot,Aviv Alloni,Shahar Admati,Roee Hendel,Ido Weiss,Alan Arazi,Shay-Nitzan Cohen,Yonatan Belinkov", "background": "检索增强生成（RAG）已经成为处理大型语料库中问题的回答的主要方法。然而，当前的数据集和方法大多关注每个查询只涉及很小一部分语料（通常是几段内容），而未能涵盖需要从大规模文档集中收集信息并进行推理的聚合性查询场景。S-RAG针对这些问题提出了一种专门的方法，旨在解决这些场景的具体需求。通过引入两个新的聚合查询数据集（HOTELS和WORLD CUP），实验表明，S-RAG在新数据集和公共基准上的表现优于传统的RAG系统和长语境大模型系统，从而突显了其优势。", "innovation": "S-RAG是一种专为处理聚合性查询设计的方法。在数据导入阶段，S-RAG构建了语料库的结构化表示；在推理阶段，S-RAG将自然语言查询转化为对该表示形式的正式查询。这种方法能够更好地处理需要从大量文档中收集信息并进行推理的查询任务。此外，作者还引入了两个新的聚合查询数据集（HOTELS和WORLD CUP）来验证这种方法，并展示了S-RAG在新数据集和基准测试中的优势。", "conclusion": "实验结果表明，S-RAG在处理聚合性查询时显著优于现有常用的RAG系统和长语境大模型系统。S-RAG通过引入结构化表示和转换自然语言查询至正式查询的新方法，解决了现有方法在处理大量文档推理方面的不足。引入的两个新数据集HOTELS和WORLD CUP验证了S-RAG的有效性，并促进了该领域的进一步研究。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08522", "html_url": "https://arxiv.org/abs/2511.08522", "title": "AlphaResearch: 使用语言模型加速新算法发现", "title_en": "AlphaResearch: Accelerating New Algorithm Discovery with Language Models", "authors": "Zhaojian Yu,Kaiyue Feng,Yilun Zhao,Shilin He,Xiao-Ping Zhang,Arman Cohan", "background": "大型语言模型虽然在解决复杂但易于验证的问题上取得了显著进展，但在发现未知问题的能力上仍存在局限。研究背景指出当前研究尚未满足在开放性问题上发现新算法的需求。", "innovation": "本文提出了一种名为AlphaResearch的自主研究代理，旨在解决开放性问题上发现新算法的任务。通过构建结合行为验证和模拟现实世界同行评审的新型双重研究环境，以及全新的AlphaResearchComp基准测试，包含八个精心策划和验证的开放性算法问题竞赛。", "conclusion": "AlphaResearch在与人类研究员的头对头竞赛中获胜率为2/8，展示了使用LLMs加速算法发现的可能性。此外，针对部分失败的案例，进行了全面分析，提供了对未来研究的有益见解。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08537", "html_url": "https://arxiv.org/abs/2511.08537", "title": "从语义角色到意见角色：跨任务和迁移学习低资源意见角色提取的SRL数据提取", "title_en": "From Semantic Roles to Opinion Roles: SRL Data Extraction for Multi-Task and Transfer Learning in Low-Resource ORL", "authors": "Amirmohammad Omidi Galdiani,Sepehr Rezaei Melal,Mohammad Norasteh,Arash Yousefi Jordehi,Seyed Abolghasem Mirroshandel", "background": "本文报告了从OntoNotes 5.0语料库的华尔街Journal部分构建高质量语义角色标注(SRL)数据集的方法，并将其适应于意见角色标注(ORL)任务。通过利用PropBank注释框架，本文实现了一个可复现的提取管道，该管道对谓词-论元结构进行了对齐，将句法树指针转换为连贯的片段，并进行了严格的清理以确保语义准确性。", "innovation": "本文实施了一种可复现的提取管道，该管道能够将谓词-论元结构与表面文本对齐，将句法树指针转换为连贯的段落，并进行严格的清理以确保语义的准确性。所构建的语料库包含97,169个经过明确定义的Agent (ARG0)，Predicate (REL)，和Patient (ARG1)角色的谓词-论元实例，并且这些实例已被映射到ORL的持有者、表达和目标结构上。", "conclusion": "本文为利用SRL增强ORL的研究人员提供了可重复使用的资源，特别适用于低资源意见挖掘场景中的跨任务和迁移学习。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08525", "html_url": "https://arxiv.org/abs/2511.08525", "title": "在大型推理模型中调查推理路径监控能力", "title_en": "Investigating CoT Monitorability in Large Reasoning Models", "authors": "Shu Yang,Junchao Wu,Xilin Gou,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang", "background": "大型推理模型（LRMs）通过进行长时间推理来产生最终答案，展示出在复杂任务上的出色表现。这些详细推理轨迹不仅提升了模型的能力，还创造了新的AI安全机会——通过监控推理路径（CoT）来检测潜在的模型不当行为，如走捷径或奉承等。然而，在通过CoT分析构建更有效的监控时，存在两个根本性挑战：推理路径的真实性问题和监控可靠性的两难问题。鉴于这两个挑战，本文进行了系统的调查研究，并探讨了可能导致误导的情况，最终提出了MoME新范式，即让大型语言模型（LLMs）监控其他模型的不当行为并通过推理路径提供结构化的判断和支撑证据。", "innovation": "本文首次系统性地研究了CoT监控的挑战与潜力，通过两个核心视角——推理路径详细程度和监控可靠性，进行了实证证据和相关性分析，特别是在数学、科学和伦理领域。此外，本文还探讨了不同推理路径干预方法如何影响监测效果，并提出了MoME新范式，以让大型语言模型监测其他模型的不当行为。", "conclusion": "实证结果表明，推理路径的质量和监控的可靠性与大型语言模型（LLMs）在数学、科学和伦理领域的表现有关。不同推理路径干预方法的不同效果也说明了对比评估模型的方法的有效性。最后，提出了MoME新范式，设想大型语言模型通过推理路径监控其他模型的不当行为，并提供结构化的判断和证据支持。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08565", "html_url": "https://arxiv.org/abs/2511.08565", "title": "在大型语言模型中的人格人设情景下道德敏感性和稳健性", "title_en": "Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models", "authors": "Davi Bastos Costa,Felippe Alves,Renato Vicente", "background": "随着大型语言模型（LLMs）越来越多地在社会环境中运作，研究其如何表达和改变道德判断变得尤为重要。这项研究旨在分析LLMs在扮演特定角色时的道德反应，通过引入一种基准，量化道德脆弱性和道德稳健性这两个属性，以进一步理解LMMs在社会情感中的道德行为变化。", "innovation": "研究引入了一个新的基准，通过道德基础问卷（MFQ）量化LMMs在不同人设角色下的道德脆弱性和稳健性，分析了模型家族和规模等因素对这两种属性的影响。研究还发现了稳健性和敏感性之间的正相关关系，尤其是在模型家族层面更为明显。这项研究提供了对LMMs如何因人设训练影响其道德行为的系统性理解。", "conclusion": "研究发现，对于道德稳健性而言，模型家族占绝大多数差异因素，而模型大小则没有系统的效应。Claude家族是最稳健的，其次是Gemini和GPT-4，其他家族表现较差。对于道德敏感性，则表现出轻微的家族效应和明确的家庭内规模效应，较大的变体更具敏感性。此外，稳健性和敏感性呈正相关，这种关联在家族层面上更为显著。还分析了没有人设的模型和平均角色的道德基础概况，这些分析为理解大型语言模型中的人格训练如何影响道德行为提供了系统视角。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08579", "html_url": "https://arxiv.org/abs/2511.08579", "title": "训练语言模型解释自身的计算过程", "title_en": "Training Language Models to Explain Their Own Computations", "authors": "Belinda Z. Li,Zifan Carl Guo,Vincent Huang,Jacob Steinhardt,Jacob Andreas", "background": "近年来，语言模型（LMs）在自然语言处理领域取得了显著进展，但对于这些模型如何处理信息及内在计算过程的理解仍存局限。现有解释方法通常基于模型使用的详细信息，但这种方法可能无法全面揭示模型的内部机制。本研究通过精细调校语言模型，让其生成自然语言描述，来探索模型对其自身内部计算过程的解释能力。研究者使用现有解释技术作为基准，训练模型来描述模型特征内含的信息、模型内部激活的因果结构，以及特定输入对输出的影响。研究表明，即使仅训练数以十万计的解释示例，解释器模型也能对新查询表现出非平凡的泛化能力，这在一定程度上归因于模型对其自身内部机制的直接访问。", "innovation": "本研究创新点在于，通过精细调校语言模型，让其能够生成自然语言描述，解释自身的内部计算过程。这种方法不仅提升了对模型行为的理解，还提供了一种可扩展的补充现有解释方法的手段。特别地，研究发现让模型解释自身比使用其他更强大的模型解释更能有效提升解释效果，即使后者在其他任务上的表现可能更优秀。", "conclusion": "研究表明，语言模型确实可以学习可靠地解释其内部计算过程，并且这种解释提供了现有解释方法的可扩展补充。实验结果表明，让模型解释自身相比其他模型更有效，即使后者可能在其他方面更强大。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07482", "html_url": "https://arxiv.org/abs/2511.07482", "title": "为LLMs进行约束动态剪枝：识别并保留关键对齐电路", "title_en": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits", "authors": "Dev Patel,Gabrielle Gervacio,Diekola Raimi,Kevin Zhu,Ryan Lagasse,Gabriel Grand,Ashwinee Panda,Maheep Chaudhary", "background": "大语言模型在推断时需要大量的计算资源，这带来了部署方面的挑战。尽管动态剪枝比静态剪枝方法更有效，因为它可以通过自适应电路选择提供更好的效率，但它通过仅保留输入相关的安全性关键电路来减少计算量，这会加剧对齐性能的下降，导致不同输入下的对齐性能不符。因此，解决这些增强的对齐漏洞仍然至关重要。", "innovation": "我们提出了一种名为AAPP（Aware Probe Pruning）的动态结构化剪枝方法，它在推断过程中自适应地保留与对齐相关的电路，建立在Probe Pruning之上。实验表明，与与匹配的计算量相比，AAPP将拒绝率提高了50%，从而能够更快速高效地部署安全保有的LLM。", "conclusion": "AAPP通过自适应保持关键对齐电路，有效提高了拒绝率，确保在匹配计算量的情况下，LLM的高效且安全的部署。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.06254", "html_url": "https://arxiv.org/abs/2511.06254", "title": "LLaDA-Rec：生成推荐中的并行语义ID生成的离散扩散方法", "title_en": "LLaDA-Rec: Discrete Diffusion for Parallel Semantic ID Generation in Generative Recommendation", "authors": "Teng Shi,Chenglei Shen,Weijie Yu,Shen Nie,Chongxuan Li,Xiao Zhang,Ming He,Yan Han,Jun Xu", "background": "生成推荐将每个项目表示为一个语义ID，即一系列离散标记，并通过自回归解码生成下一个项目。虽然有效，但现有的自回归模型存在两个内在限制：（1）单向约束，因果注意力机制限制每个标记只能关注其前驱，阻碍了全局语义建模；（2）误差累积，固定从左到右的生成顺序导致早期标记中的预测误差传播到后续标记的预测。", "innovation": "我们提出了LLaDA-Rec，这是一种离散扩散框架，将推荐重新形式化为并行的语义ID生成。通过结合双向注意力和自适应生成顺序，该方法更有效地建模项目间的和项目内部的依赖关系，并缓解了误差累积问题。具体来说，我们的方法包含三个核心设计：（1）并行标记化方案，为双向建模生成语义ID，解决剩余量化和双向架构之间的不匹配；（2）用户历史和下一个项目级别的两个掩码机制，捕获项目间的序贯依赖关系和项目内部的语义关系；（3）适用于基于扩散生成的自适应序列表解码策略，解决标准解码策略与扩散生成兼容性问题。", "conclusion": "在三个真实世界数据集上的实验表明，LLaDA-Rec 一贯优于基于ID的和最新的生成推荐器，确立了离散扩散作为生成推荐的新范式。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07477", "html_url": "https://arxiv.org/abs/2511.07477", "title": "礼貌说谎者：语言模型的证据病理", "title_en": "The Polite Liar: Epistemic Pathology in Language Models", "authors": "Bentley DeVilling(Course Correct Labs)", "background": "该论文探讨了大型语言模型中存在的一个特殊认知缺陷：即使没有确凿的知识，模型也会自信地表达。作者指出这种自信的捏造行为是通过来自人类反馈的强化学习（RLHF）结构导致的后果。作者利用 Frankfurt 对玩笑行为的分析，表明这种缺陷不是欺骗，而是结构性的冷漠，即优化感知真诚度而不是证据准确性。", "innovation": "这篇论文的关键创新在于将语言模型的这种自信错误表达与 Frankfurt 对玩笑行为的哲学分析相结合，强调这种行为背后的结构性冷漠。此外，论文强调当前的对齐方法更多关注模型的效率、安全性和礼貌性，而不是其认知基础，揭示了语言流畅度这一表面美德与语用合作可能存在的深刻对齐冲突。文章提出了一种新的对齐原则：奖励合理的自信而非表面的流畅。", "conclusion": "论文得出结论，提出一种“认知对齐”原则，即奖励合理而非感知的流畅性。并指出这种礼貌的谎言揭示了语言合作与认知完整性之间的深层次对齐紧张关系。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08577", "html_url": "https://arxiv.org/abs/2511.08577", "title": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models", "title_en": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models", "authors": "Tianyu Fu,Yichen You,Zekai Chen,Guohao Dai,Huazhong Yang,Yu Wang", "background": "改善大型语言模型（LLM）的推理能力，特别是在参数受限的情况下，对于实际应用至关重要。之前的研究提出了递归变压器，通过每次生成时追加固定数量的迭代次数来提高生成质量。然而，在初次标准前向传递之后，最后层的隐藏状态被反馈作为输入进行额外的迭代来细化token预测，但有时会造成过度推理的现象，导致已经在初次传递中正确预测的简单令牌在额外迭代中被错误地修订。因此，研究人员提出了Think-at-Hard (TaH)，这种动态的潜在推理方法只在难以预测的token进行额外迭代，以更有效地提高LLM的推理性能。", "innovation": "TaH通过一个轻量级神经决策器在标准前向传递后，仅在可能错误的token上触发潜在迭代。在潜在迭代中，利用低秩适应（LoRA）模块将LLM的目标从一般下一token预测转向特定的hard-token改进。此外，引入了一种双因果注意机制，这扩展了注意力机制，使跨迭代之间的信息流通成为可能，同时保持了完整的序列并行性。实验表明，TaH在五种挑战性基准上提升了LLM的推理性能，而保持相同的参数数量。与所有输出token都迭代两次的基线相比，TaH在8.1-11.3%的准确率提升上，节省了94%的token不需要参与第二次迭代。即使在提供少于3%的额外参数来自LoRA和迭代决策器的情况下，它也分别实现了8.5-12.6%和5.3-5.4%的提升。", "conclusion": "TaH在保持相同参数数量的情况下，通过动态选择只有难以预测的token进行额外迭代，有效提升了LLM的推理性能。与基线相比，TaH显著提高了准确率，并且在大多数情况下，超过94%的token避免了第二次迭代。当允许少于3%的额外参数时，性能提升进一步增加。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07491", "html_url": "https://arxiv.org/abs/2511.07491", "title": "量化社区主义的影响：一项系统的文献回顾", "title_en": "Quantifying the Impact of CU: A Systematic Literature Review", "authors": "Thomas Compton", "background": "自2000年初以来，社区主义一直是工会重建讨论中的核心概念，但其理论连贯性和政治意义仍然未得到解决。这篇文章通过不直接测试社区主义的有效性，而是通过文献中社区主义的构建、引用及争议来探索其为何获得了如此重要的地位。文章使用两种互补的系统性方法——对114份文件进行引文网络分析和对18个核心社区主义案例进行主题审查，探讨了社区主义作为实证描述和规范理想的功能。定量分析揭示了社区主义兼具本土根源与跨国社会运动工会主义的双重起源。主题编码显示，几乎所有强调的是联合建设与联盟，但在阶级政治方面存在深刻的矛盾。", "innovation": "文章通过两种互补的系统性方法——即引文网络分析和主题审查——来探讨社区主义在实际描述和规范理想中的作用。这种方法不同于直接测试社区主义的有效性，而是侧重于其在文献中的构建、引用及争议。这项研究揭示了社区主义的双重来源及其在阶级政治方面存在深刻的矛盾，并强调它可能更多地在于管理工作中存在的各种矛盾。", "conclusion": "社区主义显著之处并不在于实现一种新的工会模式，而在于如何管理工作场所与社区、领导层与底层工会成员、改革与激进主义之间的矛盾。这些矛盾在工会运动规模缩小的情况下尤为重要。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07426", "html_url": "https://arxiv.org/abs/2511.07426", "title": "MCP使能LLM代理的网络和系统性能表征", "title_en": "Network and Systems Performance Characterization of MCP-Enabled LLM Agents", "authors": "Zihao Ding,Mufeng Zhu,Yao Liu", "background": "MCP作为一种标准化协议，最近在AI界获得了广泛关注，它为大型语言模型（LLMs）提供了与外部工具和服务交互的标准方式，显著增强了它们的功能。然而，MCP启用的LLM交互中包含了大量背景信息（如系统提示、MCP工具定义和上下文历史记录），这极大地增加了令牌使用量。由于LLM供应商按令牌收费，这些扩展的背景信息可以迅速增加费用并增加LLM服务的计算负担。本文通过全面的基于测量的分析，探讨了MCP使能的LLM交互之间的性能权衡，包括功能、性能和成本。本文揭示了不同LLM模型和MCP配置如何影响关键性能指标，如令牌效率、货币成本、任务完成时间和任务成功率，并提出了一些潜在的优化措施，例如启用并行工具调用和实施健壮的任务终止机制。这些发现为开发更高效、更健壮和成本效益更高的MCP使能工作流提供了有用的见解。", "innovation": "本文提供了基于测量的对MCP使能LLM交互的全面分析，揭示了不同LLM模型和MCP配置在功能、性能和成本之间的权衡。研究探讨了影响LLM和MCP性能的关键指标，如令牌效率、货币成本、任务完成时间和任务成功率，并提出了一些优化策略，例如并行工具调用和健壮的任务终止机制。这些发现有助于开发更有效的MCP使能工作流。", "conclusion": "研究表明，不同LLM模型和MCP配置在功能、性能和成本之间存在权衡。作者建议通过优化策略，如并行工具调用和实施健壮的任务终止机制，来提高这些交互的效率、健壮性和成本效益。这些发现提供了开发更高效、更健壮和更经济的MCP使能工作流的见解。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07585", "html_url": "https://arxiv.org/abs/2511.07585", "title": "大语言模型输出漂移：跨供应商验证与金融工作流中的缓解措施", "title_en": "LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows", "authors": "Raffi Khatchadourian,Rolando Franco", "background": "金融机构使用大语言模型（LLMs）进行核对、监管报告和客户通信，但非确定性输出（输出漂移）削弱了审计性和信任度。", "innovation": "(i) 一个针对金融领域的确定性测试框架，结合贪婪解码（T=0.0）、固定种子和SEC 10-K结构感知检索排序；(ii) 适用于不同任务的不变性检查，针对RAG、JSON和SQL输出，并使用金融校准的重要性阈值；(iii) 三级模型分类系统，以支持风险匹配的部署决策；(iv) 一个审计准备就绪的验证系统，包含双重供应商验证。", "conclusion": "通过跨多个模型和任务的评估，发现模型大小对输出一致性的影响，提出了针对监管金融工作流的验证与缓解措施，展示了合规AI部署的实用途径，确认了分布式部署下的确定性行为。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07577", "html_url": "https://arxiv.org/abs/2511.07577", "title": "基于区块链确保来源可靠性的去中心化检索增强生成系统", "title_en": "A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain", "authors": "Yining Lu,Wenyi Tang,Max Johnson,Taeho Jung,Meng Jiang", "background": "现有的检索增强生成（RAG）系统通常采用集中式架构，导致数据收集、集成和管理成本高昂，并且存在隐私问题。去中心化的RAG系统需求巨大，该系统能够使基础模型直接从数据拥有者那里获取信息，而数据拥有者仍能完全控制其数据来源。然而，去中心化面临一个挑战：众多独立的数据源具有显著的可靠性差异，这会降低检索准确性和响应质量。为解决这一问题，该去中心化RAG系统引入了一种新颖的可靠性评分机制，能够动态评估每个数据源的质量，并在检索时优先选择高质量的数据源。通过区块链智能合约安全地管理评分过程，创建不可篡改且可验证的可靠性记录，而无需依赖中心权威机构。", "innovation": "该系统采用去中心化架构，利用区块链智能合约管理评分过程，确保评分的透明度和可信度，同时动态评估每个数据源的质量并优先选择高质量数据源。与传统的集中式RAG系统相比，在模拟环境中，特别是在数据环境不太可靠的情境下，该系统提高了10.7%的性能；在理想条件下更接近集中式系统的最佳性能。通过批量更新操作，该去中心化架构还实现了约56%的边际成本节省。", "conclusion": "评估结果显示，在现实世界中的不可靠数据环境下，该去中心化系统比其集中式的同行提高了10.7%的性能，并在理想条件下近似达到集中式系统的最佳性能。去中心化基础设施提高了评分管理的安全性和可信度，并通过批量更新操作实现了约56%的边际成本节省。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07581", "html_url": "https://arxiv.org/abs/2511.07581", "title": "在检索前思考：使用小语言模型进行测试时自适应搜索的学习", "title_en": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models", "authors": "Supriti Vijay,Aman Priyanshu,Anu Vellore,Baturay Saglam,Amin Karbasi", "background": "有效的信息检索需要在证据部分时进行推理，并随着信息的出现不断调整策略。当前的方法存在缺陷：神经检索器缺乏推理能力，大型语言模型（LLMs）虽然提供了深层的语义理解，但会产生高昂的成本，而查询重写或分解仅限于静态的变换。因此，现有方法无法捕捉复杂用户查询所需的探索、反馈和修订的迭代动态。", "innovation": "我们引入了Orion，这是一种训练框架，使紧凑型模型（参数350M-1.2B）能够通过学习的搜索策略进行迭代检索。Orion结合了：（1）合成轨迹生成和监督微调，以促进模型的多样化探索模式；（2）基于强化学习（RL）的奖励机制，奖励有效的查询修订和回溯行为；（3）推理时的束搜索算法，利用在RL期间学习的自我反思能力。尽管仅使用3%的训练数据，我们的1.2B模型在SciFact上的成功率达到77.6%（高于之前检索器的72.6%），在BRIGHT上的成功率为25.2%（高于22.1%），NFCorpus的成功率为63.2%（高于57.8%），并对FEVER，HotpotQA，MSMarco保持竞争力。该模型在六个基准测试中比大小相差200-400倍的检索器在五个测试中表现更佳。", "conclusion": "研究表明，检索性能可以来自学习到的策略，而不仅仅是模型规模，当模型被训练以搜索、反思和修订时。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07685", "html_url": "https://arxiv.org/abs/2511.07685", "title": "ResearchRubrics: 一套评估深度研究代理提示和评判标准基准", "title_en": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents", "authors": "Manasi Sharma,Chen Bo Calvin Zhang,Chaithanya Bandi,Clinton Wang,Ankit Aich,Huy Nghiem,Tahseen Rabbani,Ye Htet,Brian Jang,Sumana Basu,Aishwarya Balwani,Denis Peskoff,Marcos Ayestaran,Sean M. Hendryx,Brad Kenstler,Bing Liu", "background": "深度研究（DR）是一种新兴的代理应用，利用大型语言模型（LLMs）来应对开放性查询。它需要整合多步骤推理、跨文档合成等多种能力，并生成证据支持的长篇回答。然而，评估DR仍然充满挑战，因为其响应长度多样，可能包含多种有效的解决方案，并且通常依赖于动态信息源。当前的评估方法难以有效衡量这些复杂的因素。", "innovation": "本文提出了一种名为ResearchRubrics的标准基准，该基准耗时2800+小时开发，结合了2500+专家撰写的细粒度评判标准，以评估事实依据、推理正确性和清晰度。此外，还提出了DR任务复杂性框架，用于从概念范围、逻辑嵌套和探索三个方面对DR任务进行分类。开发了人工和模型评估协议来衡量DR代理对评判标准的遵守情况。实验结果显示，即使是领先的DR系统也仅能达到68%的平均合规性，主要是由于未能捕捉到隐含的背景上下文和对检索信息的推理不足。", "conclusion": "研究结果突显了评估深度研究能力的必要性，即具备全面性和可扩展性。为此，本文公开了ResearchRubrics（包括所有提示、评判标准和评估代码），旨在促进有说服力的研究助理的发展。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07790", "html_url": "https://arxiv.org/abs/2511.07790", "title": "CC30k: 用于再现性导向情绪分析的引用语境数据集", "title_en": "CC30k: A Citation Contexts Dataset for Reproducibility-Oriented Sentiment Analysis", "authors": "Rochana R. Obadage,Sarah M. Rajtmajer,Jian Wu", "background": "有关引用论文在下游文献中的再现性的意见反映了学术社区的观点，并显示出再现性研究的一种有希望的信号。目前缺乏专门用于计算机再现性研究的资源，传统的情绪分析数据集通常不专门针对这一主题。", "innovation": "本研究引入了CC30k数据集，包括来自机器学习论文的30,734个引文语境，并且每个语境都被标注为正向、负向或中性情绪标签，以反映所引用论文的再现性或可复制性观点。通过数据清洗、人群选择和验证过程，CC30k数据集实现了94%的标注准确率。此外，研究证明了三个大型语言模型在使用该数据集进行微调后，再现性导向情绪分类性能显著提升。", "conclusion": "CC30k数据集为大规模评估机器学习论文的再现性奠定了基础。该数据集和用于数据集生产和分析的Jupyter笔记本已在公开平台上提供。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07587", "html_url": "https://arxiv.org/abs/2511.07587", "title": "超越事实检索：使用生成语义工作空间的RAG episodic记忆", "title_en": "Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces", "authors": "Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury", "background": "大型语言模型（LLMs）在处理长格式推理时面临着根本性的挑战：由于其有限的上下文窗口，许多文档无法完全被包含，而能够完全包含的文档，随着序列长度的增加，其性能也会下降。当前的解决方法主要是从基于语义嵌入的检索发展到更复杂的结构化知识图谱表示，这些方法主要适用于事实检索，但无法构建空间-时间-锚定的叙事表示，这对于跟踪事件中的实体至关重要。现有方法无法有效构建这些复杂的叙事结构。鉴于此，研究提出了一种名为Generative Semantic Workspace (GSW)的神经启发式生成记忆框架。", "innovation": "该创新提出了一种名为Generative Semantic Workspace (GSW)的神经启发式生成记忆框架，该框架能够构建结构化和可解释的事件演变表示，使LLMs能够在情境、角色、动作和时空背景下进行推理。GSW框架包括一个‘操作员’，用于将输入观察映射到中间语义结构，以及一个‘协调者’，用于将这些结构整合到持久的存储空间中，该存储空间能够保持时间、空间和逻辑的一致性。在Episodic Memory Benchmark (EpBench)中，GSW在长达100k到1M token的语料库上，相对于现有RAG基线实现了20%的最佳性能提升，同时还将查询时间的上下文token数量减少了51%。", "conclusion": "GSW不仅提高了LLMs的推理能力，还提供了一种具体的蓝图，使LLMs能够拥有人类似的episodic记忆。这为开发能够长时间推理的更高级代理奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07732", "html_url": "https://arxiv.org/abs/2511.07732", "title": "ViPRA：视频预测在机器人动作的应用", "title_en": "ViPRA: Video Prediction for Robot Actions", "authors": "Sandeep Routray,Hengkai Pan,Unnat Jain,Shikhar Bahl,Deepak Pathak", "background": "现有的视频预测模型主要基于视觉数据，可以捕捉丰富的物理交互，但大多数视频缺乏标注的动作数据，限制了它们在机器人学习中的应用。ViPRA提供了一种简单的预训练-微调框架，可以从这些未标注的动作视频中学习连续的机器人控制。通过这种方法，可以避免昂贵的动作标注、支持跨不同身体形态的泛化，并能通过分块动作解码实现每秒22次的平滑、高频的连续控制。", "innovation": "ViPRA引入了一种预测视频的框架，通过训练一个视频-语言模型来预测未来的视觉观察和关键动作，实现中间场景动态的表示。还提出了一个分块流动匹配解码器，只使用100到200次遥控演示，将抽象的动作映射到机器人特定的连续动作序列，这在之前的研究中未得到明确处理。该方法在三个评估基准上均表现出色，且在实际操作任务中也有显著改进。", "conclusion": "ViPRA的方法显著优于其他基准，展示了在一系列真实世界操作任务中的卓越表现。其通过减免动作标注、强化泛化能力、提高控制频率等创新，为视频预测在机器人控制领域的应用开辟了新的途径。ViPRA的模型和代码将在这里发布。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07772", "html_url": "https://arxiv.org/abs/2511.07772", "title": "SALT：引导激活以实现推理过程中无泄漏思考", "title_en": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought", "authors": "Shourya Batra,Pierce Tillman,Samarth Gaggar,Shashank Kesineni,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary", "background": "随着大型语言模型（LLMs）发展成为能够访问用户敏感数据的个人助手，它们面临着一个重要的隐私挑战：虽然先前的工作关注于输出级别的隐私保护，但最近的研究发现，LLMs在推理过程中往往会泄露私人信息，违背了上下文隐私预期。这些泄露的发生是因为模型在推理过程中的某些层会无意地暴露敏感信息，即使最终输出看似安全。要在不牺牲模型推理能力的情况下防止这种泄漏，需要在隐私和实用性之间寻找微妙的平衡。", "innovation": "本文提出了一种名为Steering Activations towards Leakage-free Thinking（SALT）的轻量级测试时干预方法，通过在隐藏状态中注入目标引导向量来减轻模型推理过程（CoT）中的隐私泄漏。通过实验证明，SALT在QwQ-32B、Llama-3.1-8B和Deepseek在AirGapAgent-R上下文隐私泄露数据集上的CPL分别减少了18.2%、17.9%和31.2%，同时保持了与任务性能和实用性相当的水平。", "conclusion": "本文的工作证明SALT是语言模型推理过程测试时隐私保护的一种实用方法，为基于LLM的个人助手的安全部署提供了可能的路径。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07876", "html_url": "https://arxiv.org/abs/2511.07876", "title": "LoopLLM: 通过重复生成在大型语言模型中实现可转移的能耗攻击", "title_en": "LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation", "authors": "Xingyu Li,Xiaolei Liu,Cheng Liu,Yixiao Xu,Kangyi Ding,Bangzhou Xin,Jia-Li Yin", "background": "随着大型语言模型（LLMs）的规模增大，其推理过程会消耗大量的计算资源，使其面临能源-延迟攻击。现存的攻击方法主要通过推迟终止符号的生成来延长输出时间，但随着输出增长，通过输入控制终止符号变得困难，从而降低了这些方法的有效性。", "innovation": "本文提出了LoopLLM，一种基于重复生成可以触发低熵解码循环的能耗-延迟攻击框架。LoopLLM引入了（1）一种重复生成提示优化，该优化利用自回归模型的弱点诱导重复生成；（2）一种标记对齐的集成优化，用于提高跨模型的传输能力。", "conclusion": "在12个开源和2个商业LLM上的广泛实验表明，LoopLLM大幅优于现有方法，能够在输出最大长度的90%以上实现攻击，而基线方法仅能达到20%左右的长度，并且使到DeepSeek-V3和Gemini 2.5 Flash的可传输性提高了约40%。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07865", "html_url": "https://arxiv.org/abs/2511.07865", "title": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost", "title_en": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost", "authors": "Daisuke Kikuta,Hiroki Ikeuchi,Kengo Tajiri", "background": "混沌工程（CE）是一种旨在提高分布式系统韧性的工程技术。它通过故意将故障注入系统来测试其韧性，发现弱点并对其进行处理，以防止生产中出现故障。近期的CE工具自动化执行预定义的CE实验。然而，设计此类实验和基于实验结果改进系统仍然需要手动操作。这些过程劳动密集且需要多领域的专业知识。", "innovation": "本文提出了一种名为ChaosEater的系统，该系统利用大规模语言模型（LLMs）自动化整个CE周期。它根据系统的系统化CE周期预定义了代理工作流程，并将工作流程中的子过程分配给LLMs。ChaosEater专门针对基于Kubernetes的软件系统进行CE。因此，ChaosEater中的LLMs通过软件工程任务完成CE周期，包括需求定义、代码生成、测试和调试。本文通过小型和大型Kubernetes系统的案例研究评估了ChaosEater。结果表明，它能够以显著减少的时间和成本完成合理的CE周期。并且由人类工程师和LLMs验证了其周期的质量。", "conclusion": "ChaosEater以显著减少的时间和成本自动化了整个CE周期，证明了其在小型和大型Kubernetes系统中的有效性和可靠性。通过利用LLMs，ChaosEater能够使任何人都能够以较低的成本构建可信赖的软件系统。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07896", "html_url": "https://arxiv.org/abs/2511.07896", "title": "SparseRM: 使用稀疏自动编码器的轻量级偏好建模", "title_en": "SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder", "authors": "Dengcan Liu,Jiahao Li,Zheren Fu,Yi Tu,Jiajun Li,Zhendong Mao,Yongdong Zhang", "background": "大语言模型（LLMs）在训练后需要使用奖励模型（RMs）来代理人类偏好评估，并指导模型对齐。然而，由于需要大规模的偏好标注数据和调优LLMs的成本高昂，因此在资源有限的情况下训练可靠的RMs仍然具有挑战性。", "innovation": "提出SparseRM，利用稀疏自编码器（SAE）从模型表示中提取与偏好相关的信息，以此构建轻量级且可解释的奖励模型。SparseRM首先使用SAE将LLM表示分解为可解释的方向，捕捉偏好相关的特征。然后将表示投影到这些方向上计算对齐评分，这是量化表示中每个偏好特征强度的值。一个简单的奖励头部将这些分数聚合以预测偏好评分。", "conclusion": "实验结果表明，SparseRM在三项偏好建模任务中表现优于大多数主流RMs，同时使用的可训练参数不到1%。此外，它能够无缝集成到下游对齐管道中，突显了其高效的对齐潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08029", "html_url": "https://arxiv.org/abs/2511.08029", "title": "BiCA: 有效利用引文感知硬负样的生物医学密集检索", "title_en": "BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives", "authors": "Aarush Sinha,Pavan Kumar S,Roshan Balaji,Nirav Pravinbhai Bhatt", "background": "有效检索模型的训练需要使用硬负样，而传统的基于余弦距离等相似度指标的排名方法在生物医学和科学领域难以区分原始文档与硬负样文档。参考文档与原始文档在上下文上具有相关性但不是重复文本，非常适合作为硬负样。", "innovation": "提出了一种名为BiCA的方法，利用PubMed文章中的引用来进行硬负样的挖掘，通过在GTE_small和GTE_Base模型上使用引文指导的负样进行微调，观察到在零样本密集检索中使用nDCG@10指标对实际领域和跨领域任务的表现改进，并在LoTTE数据集上使用Success@5指标在长尾主题上优于基线。", "conclusion": "研究结果表明，利用文档链接结构可以生成更为信息丰富的负样，通过最小的微调即可实现顶级性能，展示了一条实现高数据效率领域适应性的路径。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07885", "html_url": "https://arxiv.org/abs/2511.07885", "title": "瓦特每智能：衡量本地AI的能效", "title_en": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI", "authors": "Jon Saad-Falcon,Avanika Narayan,Hakki Orhun Akengin,J. Wes Griffin,Herumb Shandilya,Adrian Gamarra Lafuente,Medhya Goel,Rebecca Joseph,Shlok Natarajan,Etash Kumar Guha,Shang Zhu,Ben Athiwaratkun,John Hennessy,Azalia Mirhoseini,Christopher Ré", "background": "大规模语言模型（LLM）查询主要由集中式云基础设施中的前沿模型处理。随着需求迅速增长，这种模式出现瓶颈，云提供商难以按需扩展基础设施。小规模LM（≤20B活跃参数）现在在许多任务上达到与前沿模型竞争力相当的性能，且本地加速器（如Apple M4 Max）能够在交互延迟下运行这些模型。这就提出了一个问题：本地推理能否有效地将需求从集中式基础设施中分散出去？回答这个问题需要衡量本地LM是否能够准确回答真实查询，并且在功率受限的设备（如笔记本电脑）上能够高效处理。", "innovation": "提出了‘瓦特每智能（IPW）’作为衡量本地推理能力和效率的关键指标。IPW表示任务准确率除以单位功率。通过大规模实证研究，评估了20多种先进的本地LM、8种加速器和代表性LLM流量（共100万条单轮对话和推理查询）。研究结果显示，本地LM在88.7%的单轮对话和推理查询中能够准确回答，并且IPW在2023-2025年间提高了5.3倍，本地查询覆盖率达到71.3%。此外，从2023年至2025年，本地推理相对于云推理在能耗效率上提高了至少1.4倍。", "conclusion": "研究结果表明，本地推理可以在减少对集中式基础设施依赖的同时，有效处理真实世界的查询。IPW作为关键指标用于跟踪这一过渡过程。研究还释放了一种IPW性能分析工具，实现了系统化的每瓦智能基准测试。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07943", "html_url": "https://arxiv.org/abs/2511.07943", "title": "Thinker：通过多轮互动进行分层次思考训练LLMs以进行深入搜索", "title_en": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction", "authors": "Jun Xu,Xinkai Du,Yu Ao,Peilong Zhao,Yang Li,Ling Zhong,Lin Yuan,Zhongpu Bo,Xiaorui Wang,Mengshu Sun,Zhengke Gui,Dalong Zhang,Zhaoyang Wang,Qiwei Wang,Yangyang Hou,Zhiying Yin,Haofen Wang,Huajun Chen,Lei Liang,Jun Zhou", "background": "高效检索外部知识库和网页对于提升大语言模型（LLMs）的推理能力至关重要。之前的研究主要采用端到端的强化学习方法来训练LLMs利用外部检索器解决问题，但这些方法忽略了推理过程的监督，使确保逻辑连贯性和严谨性变得困难。", "innovation": "提出了一个层次化思考模型Thinker，通过多轮交互进行深入搜索，使得推理过程变得可监督和可验证。该模型将复杂问题分解为可独立解决的子问题，并以自然语言和等价的逻辑函数形式表示这些子问题，以支持知识库和网络搜索。同时，逻辑函数传递子问题之间的依赖关系，增强了解决问题过程的逻辑连贯性。为了避免不必要的外部搜索，该模型通过确定知识边界来检查子问题是否在LLM固有的知识范围内，从而允许其直接回答。", "conclusion": "实验结果显示，在少量训练样本（数百个样本）下，Thinker的表现与现有基线相当，而在全训练数据集上，Thinker在各种数据集和模型规模上的表现显著优于这些方法。该模型的源代码可在给定的URL中找到。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08052", "html_url": "https://arxiv.org/abs/2511.08052", "title": "双过程支架推理法增强LLM代码调试", "title_en": "Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging", "authors": "Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang", "background": "近年来，大型语言模型（LLMs）在各类基准测试中展现了复杂的推理能力，但如何在复杂性和计算效率之间找到最优的推理步骤仍然是未解决的关键研究问题。近期的研究越来越多地借鉴心理学理论，寻找优化认知路径的策略。尽管LLMs的最终输出和中间步骤被分别视为系统1和系统2，但对系统2推理过程的深入研究仍然缺乏。因此，本文提出了一种新的基于心理机制的支架推理框架，用于代码调试，该框架包括支架流、分析流和整合流三个部分。", "innovation": "本文提出的支架推理框架将参考代码的构建整合到分析流产生的有错误代码的分析结果中，通过整合流实现此目的。该框架在DebugBench上取得了88.91%的通过率和平均每题5.36秒的推理时间，在推理准确性和效率上优于其他推理方法。此外，进一步的分析揭示了不同认知路径在不同问题难度和故障类型下的优缺点，证实了所提出的支架推理框架与人类认知过程的对接。", "conclusion": "我们的研究展示了支架推理框架在代码调试中的显著优越性，证实了该框架在提高LLM推理效率和精度方面的巨大潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08093", "html_url": "https://arxiv.org/abs/2511.08093", "title": "量化Whisper-small：设计选择如何影响ASR性能", "title_en": "Quantizing Whisper-small: How design choices affect ASR performance", "authors": "Arthur Söhler,Julian Irigoyen,Andreas Søeborg Kirkedal", "background": "大型语音识别模型如Whisper-small具有高准确性，但由于其高计算需求，难以部署在边缘设备上。论文探讨了在Whisper-small上进行评估后训练量化（PTQ），以分离量化方案、方法、粒度和位宽的影响。", "innovation": "本文基于PyTorch、Optimum-Quanto、HQQ和bitsandbytes四个库，进行了统一的跨库评估。实验结果显示，动态int8量化与Quanto结合提供了最好的权衡，使模型大小减小了57%，同时提高了基线的词错误率；与之相比，静态量化效果较差，更激进的格式（例如nf4、int3）在噪声条件下压缩率最高可达71%，但会以准确性为代价。", "conclusion": "研究结果表明，精心选择的PTQ方法可以在不重新训练的情况下显著减小模型尺寸和推理成本，从而使Whisper-small能够在受限硬件上实现高效部署。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08066", "html_url": "https://arxiv.org/abs/2511.08066", "title": "信息容量：基于文本压缩评估大型语言模型的效率", "title_en": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression", "authors": "Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "近年来，大型语言模型（LLMs）取得了迅猛发展，并在众多应用场景中得到广泛应用，这对计算资源的需求急剧增加。为了满足测试阶段对模型能力扩展的需求，人们采用测试时扩展的方法，进一步加剧了模型能力与资源消耗之间的矛盾。这凸显了评估模型推断效率的重要性。然而，目前仍然缺乏一个能够准确反映不同模型尺寸和架构下LLM效率的统一指标。因此，该研究引入了信息容量这一基于文本压缩性能与计算复杂度相对比的模型效率度量标准。", "innovation": "该研究通过将压缩与智能相关联，引入了信息容量作为新型度量模型效率的标准。实验结果显示，不同尺寸的一系列模型能够表现出一致的信息容量，这一度量标准不仅能够公平地比较不同模型系列的效率，还能预测模型系列内的性能表现。研究还特别指出信息容量能够考虑分词器效率的影响，这对输入和输出的令牌数量都有影响，但在现有LLM评估中常被忽略。通过在不同数据集上评估49个模型，结果显示信息容量与分词效率、预训练数据以及专家混合架构等因素有关，具有较强的一致性。", "conclusion": "信息容量能够提供一个统一的框架来评估不同尺寸和架构下大型语言模型的效率，通过文本压缩的性能与计算复杂度之间的关系进行度量。这项研究通过考虑分词器效率，更加全面地评估了模型效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07931", "html_url": "https://arxiv.org/abs/2511.07931", "title": "SpeechJudge：向着语音自然度的人类级评估", "title_en": "SpeechJudge: Towards Human-Level Judgment for Speech Naturalness", "authors": "Xueyao Zhang,Chaoren Wang,Huan Liao,Ziniu Li,Yuancheng Wang,Li Wang,Dongya Jia,Yuanzhe Chen,Xiulin Li,Zhuo Chen,Zhizheng Wu", "background": "语音合成中对大规模生成模型进行与人类反馈对齐是一个关键挑战。由于缺乏大规模的人类偏好数据集，这阻碍了能够真正与人类感知相吻合的模型的发展。为了应对这一挑战，作者引入了SpeechJudge，这是一个综合套件，包含一个语音语料库、一个基准测试和一个以自然度为中心的奖励模型。自然度是最根本的语音合成主观指标之一。SpeechJudge-Data是一个包含99000对语音样本的大规模人类反馈语料库，该语料库使用多样且先进的零样本文本到语音模型构建，这些模型能够跨越多种语音风格和多种语言，并带有可理解性与自然度偏好的人类注释。基于此，作者建立了SpeechJudge-Eval，一个具有挑战性的语音自然度判断基准测试。研究表明，现有的评估指标和AudioLLMs在这方面表现不佳，领先模型Gemini-2.5-Flash与人类判断的一致性不足70%，这表明需要改进的空间很大。", "innovation": "作者提出了一种新的方法引入SpeechJudge，这包括数据集、基准测试和基于Qwen2.5-Omni-7B的生成奖励模型（GRM）。这个实现采用了一个两阶段后训练策略，首先是思考链的监督微调（SFT），然后是针对难题的情况使用GRPO的强化学习（RL）训练。在SpeechJudge-Eval基准测试上，所提的SpeechJudge-GRM表现出色，准确率达到77.2%（且在推断时间缩放@10时达到79.4%），超过了经典的Bradley-Terry奖励模型的72.7%。此外，SpeechJudge-GRM还可以作为奖励函数用于语音生成模型的后训练，以促进其与人类偏好的对齐。", "conclusion": "作者开发的SpeechJudge-GRM在语音自然度基准测试中表现出色，同时评估表明现有评估指标和AudioLLMs的性能不足。通过引入SpeechJudge，作者提供了一种新的途径来改进语音合成系统的性能，使其更好地符合人类的偏好。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08043", "html_url": "https://arxiv.org/abs/2511.08043", "title": "DynaAct: 大规模语言模型推理中的动态动作空间", "title_en": "DynaAct: Large Language Model Reasoning with Dynamic Action Spaces", "authors": "Xueliang Zhao,Wei Wu,Jian Guan,Qintong Li,Lingpeng Kong", "background": "在现代的序列决策系统中，构建一个最优候选动作空间对于高效的推理是至关重要的。然而，现有的方法要么依赖于手动定义的动作空间，这类方法不具有扩展性；要么使用无结构的动作空间，这使得全面搜索变得计算上不可行。因此，本研究旨在提出一种新型框架 \textsc{DynaAct}，该框架能够自动生成一个紧凑的动作空间，以增强在复杂问题解决场景中的序列推理能力。该方法通过提取涵盖多种复杂推理问题的语料库中的通用草图，使用大规模语言模型来估算完整动作空间的代理，并通过形式化一个包含动作效用和多样性评估的次模函数，利用贪婪算法选择最优候选集。", "innovation": "本研究提出了一种名为 \textsc{DynaAct} 的新型框架，用于自动生成一个紧凑的动作空间，以增强复杂的推理情境下的序列决策。这一框架首先使用大型语言模型从涵盖各种复杂推理问题的语料库中提取通用草图，以估计整个动作空间的代理。接着，通过一个结合了动作效用和多样性的次模函数来评估候选动作，并利用贪婪算法选择最优的候选集。实验结果表明，该方法在六个标准基准测试上的表现显著提升，同时保持了有效的推理，不会引入显著的延迟。", "conclusion": "通过 \textsc{DynaAct} 框架，本研究成功解决了手动定义的动作空间不具扩展性、使用无结构空间导致计算上的问题。实验结果证明，该方法在复杂的推理任务上表现优异，且在高效性方面保持了高效率，未引入显著的延迟。该实现已开源供参考。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08092", "html_url": "https://arxiv.org/abs/2511.08092", "title": "剪枝作为正则化：ASR中的敏感性感知一次性剪枝", "title_en": "Pruning as Regularization: Sensitivity-Aware One-Shot Pruning in ASR", "authors": "Julian Irigoyen,Arthur Söhler,Andreas Søeborg Kirkedal", "background": "本文挑战了神经网络剪枝仅是一种压缩技术的传统观点，证明了一次性修剪（即基于幅度的修剪）可以作为一种强大的隐式正则化技术应用于自动语音识别（ASR）。研究结合了对Whisper-small模型进行的梯度和费舍尔敏感性诊断方法，并结合了按组件逐一修剪技术。这种方法揭示了架构上的不对称性：解码器的前向传播网络较脆弱，而解码器的自我注意力机制和末尾的编码器层则包含冗余部分，这些部分被移除后能提升模型的一般化能力。研究结果进一步证实剪枝不仅提供正则化益处，敏感性感知的方法还可以实现更激进的一次性压缩效果。在40%稀疏度的情况下，现有全球剪枝方法通常会失败，但本方法仍能保持接近基线的准确性，这表明剪枝可以作为一种核心架构设计工具。", "innovation": "本文的创新在于，挑战了神经网络剪枝仅用于压缩的传统观点，证明了一次性幅度修剪可以作为ASR任务中的强隐式正则化方法。通过结合敏感性诊断技术和按组件修剪，本文发现了ASR模型中的架构不对称性，并揭示了在不依赖细调的情况下，通过修剪特定组件可以显著提升模型性能。此外，敏感性感知方法允许实现更激进的一次性压缩，即使在稀疏度较高时也能保持模型的准确性。", "conclusion": "剪枝不仅可以作为一种压缩技术来缩小模型规模，还可以作为一种重要的正则化手段来提高模型在ASR任务中的一般化能力。此外，敏感性分析还能引导如何更加精确地进行剪枝。剪枝因此可以成为一种主要的架构设计工具，不仅可以优化模型大小，还可以通过精确修剪提高模型性能和鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08098", "html_url": "https://arxiv.org/abs/2511.08098", "title": "PerspAct: 通过视角转换和主动视觉提高LLM的在场合作技能", "title_en": "PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision", "authors": "Sabrina Patania,Luca Annese,Anita Pellegrini,Silvia Serino,Anna Lambiase,Luca Pallonetto,Silvia Rossi,Simone Colombani,Tom Foulsham,Azzurra Ruggeri,Dimitri Ognibene", "background": "大型语言模型（LLMs）和多模态基础模型的最新进展大大扩展了其在机器人技术和协作系统中的应用。然而，有效的多代理交互需要强大的视角转换能力，使模型能够理解和解释物理和知识视角。当前的训练范式往往忽略了这些互动环境，导致当模型需要推理个体视角的主观性或在多个观察者环境中导航时遇到挑战。", "innovation": "这项研究探索了通过引入ReAct框架（结合推理和行动）中的视角转换方法，是否能增强LLM对其他代理需求的理解和地上能力。研究增加了经典的Director任务，引入了针对七种递增视角转换复杂度场景的主动视觉探索，这些场景挑战了基于视觉访问和交互的参照歧义解决能力，包括ReAct风格的推理策略。结果表明，结合显式视角提示和主动探索策略显著提高了模型的解释准确性与协作效果。", "conclusion": "这些发现强调了将主动感知与视角转换机制集成起来在提升LLMs在机器人技术和多代理系统中的应用潜力，为未来研究自适应和情境感知AI系统的奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08389", "html_url": "https://arxiv.org/abs/2511.08389", "title": "统一语音基础模型的模型层融合", "title_en": "Unifying Model and Layer Fusion for Speech Foundation Models", "authors": "Yi-Jen Shih,David Harwath", "background": "语音基础模型近年来引起了显著的关注。前期研究证明，可以结合同一模型多个层的表示或多个模型的表示来提高下游任务的表现。", "innovation": "本文提出了一个接口模块，能够跨越多个上游语音模型进行融合，同时在它们的层间整合信息。该方法在不同自监督和监督模型上针对各种语音任务（如自动语音识别和语义分析）进行了广泛的实验，结果表明该方法优于之前的方法。", "conclusion": "该研究表明，适当的上游模型选择可以进一步提升性能，使得提出的接口模块成为利用语音基础模型的一种有前景的方法。同时，我们强调模型的大小和数量对于接口模块的扩展性具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08242", "html_url": "https://arxiv.org/abs/2511.08242", "title": "朝向以结果为导向、任务无关的AI代理评估", "title_en": "Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents", "authors": "Waseem AlShikh,Muayad Sayed Ali,Brian Kennedy,Dmytro Mozolevskyi", "background": "随着AI代理在各个行业和应用中日益普及，仅通过基础设施指标如延迟、首词时间或令牌吞吐量来评估其性能已经不再足够。这些指标未能捕捉到代理决策的质量、运营自主性或最终的商业价值。本文提出了一种新颖且全面的框架，包含 eleven 个基于结果的、任务无关的性能指标，跨越了领域界限。这些指标旨在使组织能够基于决策质量、自主程度、适应新挑战的能力以及其实际带来的商业价值来评估代理，不论底层模型架构或具体应用场景如何。", "innovation": "文章提出了 eleven 个基于结果的、任务无关的性能指标，如目标完成率（GCR）、自主指数（AIx）、多步任务恢复能力（MTR）和商业影响效率（BIE），用于评估AI代理的性能。通过涉及四种不同代理架构（ReAct、chain-of-thought、工具增强、混合）在五个不同领域（医疗、金融、营销、法律、客户服务）的大规模模拟实验，展示了该框架的有效性。结果显示，不同代理设计存在显著的性能权衡，混合代理模型在多数指标中表现最优，平均目标完成率为 88.8%且具有最高的投资回报率（ROI）.", "conclusion": "本研究提供了一个稳健且标准化的方法，用于全面评估AI代理，为更有效的发展、部署和治理铺平了道路。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08461", "html_url": "https://arxiv.org/abs/2511.08461", "title": "生成式人工智能在质性研究方法中的作用：从炒作到风险之间？", "title_en": "Generative Artificial Intelligence in Qualitative Research Methods: Between Hype and Risks?", "authors": "Maria Couto Teixeira,Marisa Tschopp,Anna Jobin", "background": "随着人工智能（AI）在质性研究中的推广和应用，该领域也引发了重要的方法学问题。文章重点探讨生成式AI（genAI）在质性编码方法中的角色，揭示尽管存在广泛应用和技术效率的声望，genAI在质性研究中的方法论有效性存疑，其使用可能有损质性研究的严谨性和可信度。", "innovation": "文章批判性地评估了生成式AI在质性研究中的应用，强调了文档缺失、商业不透明和AI系统固有的输出错误倾向等方法论风险，主张在技术新颖性面前，应优先考虑严谨的方法论。", "conclusion": "整体来看，风险与收益之间的平衡不支持在质性研究中使用生成式AI，文章建议研究人员应优先考虑严谨的研究方法而非技术革新。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08349", "html_url": "https://arxiv.org/abs/2511.08349", "title": "混合量子经典选择态空间人工智能", "title_en": "Hybrid Quantum-Classical Selective State Space Artificial Intelligence", "authors": "Amin Ebrahimi,Farzan Haddadi", "background": "混合量子经典（HQC）算法是利用量子系统在大规模数值任务中计算优势的一种最有效范式。量子电路通过高维希尔伯特空间操作，提供了经典方法无法比拟的指数级加速和更丰富的代价景观表示能力。这些特性在机器学习中尤为重要，特别是自然语言处理（NLP），因大规模矩阵乘法和高维优化面临的计算复杂度极高。", "innovation": "该论文提出了一种专门为时间序列分类问题设计的Mamba架构的混合量子经典选择机制。通过利用变分量子电路（VQCs）作为量子门模块，增强特征提取并抑制无关信息，直接解决了深度学习架构中的计算瓶颈，通过利用量子资源进行更高效的表征学习。分析了将量子子程序引入大型语言模型（LLMs）对其泛化能力、表达能力和参数效率的影响。", "conclusion": "在重塑后的MNIST数据集上，采用混合模型在前四轮中达到24.6%的准确率，仅使用一个量子层，相较于纯经典选择机制的21.6%的准确率具有更高的表达能力。这一结果表明量子增强门机制有望成为可扩展、资源高效的NLP模型的一种途径。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08151", "html_url": "https://arxiv.org/abs/2511.08151", "title": "SciAgent: 统一的多智能体系统以实现综合性科学推理", "title_en": "SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning", "authors": "Xuchen Li,Ruitao Wu,Xuanbo Liu,Xukai Wang,Jinbo Hu,Zhixin Bai,Bohan Zeng,Hao Liang,Leheng Chen,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Xu-Yao Zhang,Liu Liu,Jia Li,Kaiqi Huang,Jiahao Xu,Haitao Mi,Wentao Zhang,Bin Dong", "background": "近年来，大型语言模型的发展使AI系统能够实现专家级别的领域特定科学任务性能，然而这些系统仍然狭隘且手工制作。SciAgent旨在解决这个问题，通过引入一个统一的多智能体系统来实现跨学科和不同难度层次的综合性科学推理能力。SciAgent通过层级过程组织问题求解，协调剂智能体负责解释每个问题的领域和复杂性，并动态协调专门的智能体系统，每个系统由相互作用的推理智能体组成，用于符号推理、概念建模、数值计算和验证。这些智能体共同构建和细化专门为每个任务定制的推理流程。SciAgent在国际数学和物理奥林匹克竞赛（IMO、IMC、IPhO、CPhO）中表现优异，超过人类的金牌成绩，证明了其领域通用性和推理适应性。此外，SciAgent还经过了国际化学奥林匹克竞赛（IChO）和Humanity's Last Exam (HLE)基准中的选定问题测试，进一步证实了其跨学科知识的综合应用能力。", "innovation": "SciAgent是一个统一的多智能体系统，旨在实现跨学科和不同难度层次的综合性科学推理能力。该系统通过一个多级过程组织问题解决，协调智能体能够动态地协调专门的智能体系统，这些系统由相互作用的推理智能体组成，用于符号推理、概念建模、数值计算和验证。这些智能体共同构建和细化了专门为每个任务定制的推理过程。该系统在多个科学奥林匹克竞赛中的表现，证明了其领域通用性和推理适应性，展示了AI系统在跨学科推理方面的潜在能力。", "conclusion": "SciAgent的工作确立了该系统作为实现综合性科学智能的一个明确步骤。综合性科学智能是指AI系统能够在专家级别上实现跨学科和连贯的推理能力。SciAgent展示了AI在科学领域的综合应用潜力，为其进一步发展奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.09235", "html_url": "https://arxiv.org/abs/2408.09235", "title": "参考引导的判定：大语言模型作为评判者在自动评估开放式问答中的应用", "title_en": "Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form QA", "authors": "Sher Badshah,Hassan Sajjad", "background": "随着大语言模型（LLMs）作为聊天助手的能力不断增长，它们在生成类似人类的对话方面表现出色，这放大了对稳健评估方法的需求，尤其对于开放式任务。传统的评价指标如EM和F1虽然有用，但在捕获这类生成输出的完整语义和上下文深度方面存在不足。因此，需要一种新的方法来评估这类生成性输出。", "innovation": "本文提出了一个基于参考的判定方法，这种方法通过利用多个LLMs作为评判者来自动化评估过程。通过在开放式问答任务上的实验发现，结合多个模型可以提高评估的可靠性和准确性，尤其是在单个模型难以应对的任务中。评估结果表明与人类评估结果有高度相关性，从而证明了该方法作为一种可靠的替代传统评价指标的有效性。", "conclusion": "该方法通过使用多个大语言模型作为评判者，能够提高开放性问答任务评估的可靠性和准确性，与人类评价结果具有高度相关性，为未来评估类似任务提供了新的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08274", "html_url": "https://arxiv.org/abs/2511.08274", "title": "Multi-Agent GraphRAG: Labeled Property Graphs 的文本到Cypher框架", "title_en": "Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs", "authors": "Anton Gusarov,Anastasia Volkova,Valentin Khrulkov,Andrey Kuznetsov,Evgenii Maslov,Ivan Oseledets", "background": "目前，检索增强生成（RAG）方法通常从非结构化文档中提取信息，而新兴的GraphRAG范式则旨在利用结构化数据，如知识图谱。尽管大多数现有GraphRAG研究侧重于资源描述框架（RDF）知识图谱，并依赖三元组表示和SPARQL查询，但Cypher和标记属性图（LPG）数据库在GraphRAG管道中的规模化有效推理潜力尚未得到充分探索。针对这一空白，本文提出了一种基于多代理的GraphRAG系统，称为Multi-Agent GraphRAG，该系统构建了一个以LDM为基础的自动Cypher查询生成和执行的工作流，采用Memgraph作为图数据库后端。该系统通过迭代的内容感知纠正和规范化，并结合聚合反馈循环，确保生成查询的语义和语法精炼。本文在CypherBench图数据集上对系统进行了评估，该数据集涵盖了多个通用领域，包含多种类型的查询。此外，还示证了基于IFC数据的属性图工作流的性能，这些数据代表了一栋建筑的数字孪生，展示了这种方法如何将AI与大规模的实际应用结合起来，使工业数字自动化用例成为可能。", "innovation": "该研究提出了一种多代理的GraphRAG系统——Multi-Agent GraphRAG，这是对现有GraphRAG方法的独特贡献。Multi-Agent GraphRAG可以作为自然语言接口与基于LPG的图数据进行交互，并通过迭代的、内容感知的纠正和规范化确保生成查询的质量。此外，该系统还利用了Memgraph作为图数据库后端，进一步增强了其处理复杂查询的能力。", "conclusion": "本文提出的Multi-Agent GraphRAG系统在基于LPG的图数据处理中展现出了显著的潜力。通过利用Cypher查询语言及其强大的查询能力，该系统为图数据带来了自然语言处理的能力，并能够在实际应用中通过标准数据集和真实工业数据集进行有效验证，展示了规模化应用的可行性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08487", "html_url": "https://arxiv.org/abs/2511.08487", "title": "Agent 安全性有多脆弱？在意图伪装和任务复杂性下的重思", "title_en": "How Brittle is Agent Safety? Rethinking Agent Risk under Intent Concealment and Task Complexity", "authors": "Zihan Ma,Dongsheng Zhu,Shudong Liu,Taolin Zhang,Junnan Liu,Qingqiu Li,Minnan Luo,Songyang Zhang,Kai Chen", "background": "当前，对由大规模语言模型（LLM）驱动的代理进行的安全评估主要集中在原子性危害上，未能解决复杂的威胁，这些威胁往往通过复杂任务中的恶意意图加以隐蔽或稀释。现有研究未能有效评估复杂的代理安全漏洞，这为隐藏意图和复杂任务带来的安全风险埋下了隐患。论文旨在填补这一空白，通过两维分析评估代理在意图伪装和任务复杂性压力下的安全性脆弱性.", "innovation": "本文引入了一种名为OASIS（Orthogonal Agent Safety Inquiry Suite）的层级基准测试，该测试具有细粒度注释和高保真度模拟沙箱。OASIS能够帮助研究人员在隐藏意图和任务复杂性的影响下评估代理的安全性。研究发现，当意图变得难以识别时，安全对齐会急剧下降；另外，所谓的“复杂性悖论”表明，代理在更复杂的任务上似乎更安全，实际上是由于其能力限制所致。这些发现为探索和加强未被关注的安全维度提供了理论基础.", "conclusion": "通过发布OASIS及其模拟环境，论文为评估和增强代理在意图伪装和任务复杂性影响下的安全性提供了原则性基础。未来的工作将基于OASIS测试集进行进一步的安全性分析，以改进代理的安全设计和实现."}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.04181", "html_url": "https://arxiv.org/abs/2409.04181", "title": "结合LLMs和知识图谱以减少问答中的幻觉问题", "title_en": "Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering", "authors": "Larissa Pusch,Tim O. F. Conrad", "background": "自然语言处理的进步极大地改变了我们与数字信息系统如数据库的交互方式，使其更加易于访问。然而，在医疗生物信息学等关键准确性要求高的领域，挑战依然存在。这些问题归结为幻觉问题，即模型生成的信息并未得到底层数据的支持，可能导致危险的误导信息。因此，研究者致力于通过结合大语言模型(LLMs)和知识图谱(KGs)来改进问答系统以提高准确性和可靠性。", "innovation": "本文提出了一种新颖的方法，通过结合LLMs和KG来解决幻觉问题。该方法基于LangChain框架，引入了一个查询检查器，确保LLMs生成查询的语法和语义正确性，然后利用这些查询从知识图谱中提取信息，显著减少了幻觉等错误的发生。此外，还对包括GPT-4 Turbo和llama3:70b在内的多个LLM进行了评估，结果显示GPT-4 Turbo在生成准确查询方面更胜一筹，而开源模型llama3:70b通过适当的提示工程也有潜力。", "conclusion": "结合LLMs和KG的混合方法有效解决了数据缺口和幻觉等问题，提供了一个可靠和直观的问答系统解决方案。为了使该方法更加用户友好，开发了一款基于Web的界面，允许用户输入自然语言查询，查看并验证生成和修正的Cypher查询。研究结果表明这种结合方法能够显著减少幻觉，并提高了问答系统的准确性和可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.04715", "html_url": "https://arxiv.org/abs/2410.04715", "title": "基于正交规则选择LLM微调数据", "title_en": "Selection of LLM Fine-Tuning Data based on Orthogonal Rules", "authors": "Xiaomin Li,Mingye Gao,Zhiwei Zhang,Chang Yue,Hong Hu", "background": "高质量的训练数据对大规模语言模型（LLM）的性能至关重要。近期工作探索了使用LLM根据少量人工设计的标准（规则）来评价和选择数据，但这些方法往往依赖于启发式方法，缺乏规则评价的原理性度量标准，并且在新任务上泛化能力差。", "innovation": "提出了一种基于正交规则的新颖数据选择框架，引入了基于规则评分向量正交性的度量来评估和选择互补规则。自动流水线首先使用LLM生成涵盖数据质量多个方面的多样规则，然后根据这些规则评估样本，并使用确定性点过程(DPP)选择最独立的规则。这些规则用于评分全数据集，高评分样本用于LLM微调等下游任务。实验表明，基于DPP的规则选择在多个领域（IMDB、医疗、数学和代码）上能够一致地提高评分准确性和下游模型性能。", "conclusion": "我们的框架在两个实验设置中进行了评估：（1）与真实评分的对齐情况，（2）使用选定数据微调后的LLM表现。结果表明，与强大的基线相比，基于DPP的规则选择方法能够显著提高评分准确性和下游模型性能。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16400", "html_url": "https://arxiv.org/abs/2410.16400", "title": "VipAct: 通过专门的VLM代理协作和工具使用提高视觉感知", "title_en": "VipAct: Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use", "authors": "Zhehao Zhang,Ryan Rossi,Tong Yu,Franck Dernoncourt,Ruiyi Zhang,Jiuxiang Gu,Sungchul Kim,Xiang Chen,Zichao Wang,Nedim Lipka", "background": "视觉语言模型（VLMs）在结合文本和视觉信息的各种任务中表现出色，但在需要详细像素级分析的精细视觉感知任务方面仍面临挑战。这样的复杂视觉元素中有效提取全面的推理仍然是一个开放性挑战。", "innovation": "VipAct 是一种代理框架，通过集成多代理协作和视觉专家模型来增强 VLMs，使其能够实现更精确的视觉理解和全面的推理。该框架包括一个协调代理，负责任务要求分析、计划和协调，以及专注于特定任务的专业代理，如图像字幕和提供高精度感知信息的视觉专家模型。这种多代理方法通过协同规划、推理和工具使用使 VLMs 能够更好地执行精细视觉感知任务。实验结果表明，与最先进的基线相比，在所有任务上均显著提高性能。此外，详尽的消融研究揭示了多代理协作在提取更详细的系统-2推理中的关键作用，并强调了图像输入对于任务计划的重要性。错误分析揭示了视觉感知中 VLMs 内在限制的模式，为未来改进提供了见解。VipAct 提供了一个灵活和可扩展的框架，为各种现实应用提供了更高级的视觉感知系统", "conclusion": "VipAct 是一个灵活的扩展框架，为实现更高级的视觉感知系统铺平了道路，可以在各种真实世界的应用中使用。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.08542", "html_url": "https://arxiv.org/abs/2503.08542", "title": "CLEV：基于轻量级高效投票的LLM评估方法在自由形式问答中的应用", "title_en": "CLEV: LLM-Based Evaluation Through Lightweight Efficient Voting for Free-Form Question-Answering", "authors": "Sher Badshah,Moamen Moustafa,Hassan Sajjad", "background": "自由形式的问答评估由于其多样性和开放性而存在挑战。传统自动评估指标无法捕捉到语义等效性或适应开放性回答的多变性。利用大语言模型（LLMs）作为评估者由于其强大的语言理解和指令遵循能力，提供了有潜力的替代方法。", "innovation": "提出了一种轻量级高效投票（CLEV）方法，运用两个主要的LLMs作为评委，并仅在分歧时调用第三个评委。该方法确保评估可靠性的同时，减少不必要的计算需求。通过包括人工评估在内的实验，表明CLEV能够提供一致、可扩展和资源有效的评估，确立其作为评估LLMs自由形式问答的稳健框架。", "conclusion": "CLEV能够在保持评估可靠性的同时，减少不必要的计算需求，通过实验证明了其在自由形式问答评估中的有效性，确立了一种资源高效且稳健的评估框架。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.05036", "html_url": "https://arxiv.org/abs/2411.05036", "title": "从词向量到多模态嵌入：技术、应用和大型语言模型的未来方向", "title_en": "From Word Vectors to Multimodal Embeddings: Techniques, Applications, and Future Directions For Large Language Models", "authors": "Charles Zhang,Benji Peng,Xintian Sun,Qian Niu,Junyu Liu,Keyu Chen,Ming Li,Pohsun Feng,Ziqian Bi,Ming Liu,Yichao Zhang,Xinyuan Song,Cheng Fei,Caitlyn Heqi Yin,Lawrence KQ Yan,Tianyang Wang", "background": "自然语言处理（NLP）中，词嵌入和语言模型通过在连续向量空间中表示语言元素，已经极大地改变了NLP领域。从最早的一-hot编码到后来的稠密嵌入，包括Word2Vec、GloVe、fastText等，技术在不断发展。这些嵌入不仅应用于静态文本，还扩展到了上下文化嵌入和多模态领域。模型如ELMo、BERT和GPT以及它们在跨语言和个性化应用中的适应性也在不断进步。", "innovation": "本文回顾了词嵌入从稀疏表示到稠密嵌入的发展，强调了从ELMo到BERT和GPT等模型的逐步进步，以及这些模型在跨语言和个性化任务中的应用。同时还探讨了句子和文档嵌入，以及它们在视觉、机器人技术和认知科学等多模态领域的应用。此外，还分析了模型压缩、解释性、数值编码和偏见缓解等高级主题，针对技术挑战和伦理影响提出了应对措施。", "conclusion": "综合当前的方法和新兴趋势，本文为研究者和实践者提供了有关基于嵌入的语言模型的深入资源，旨在推动相关技术的发展边界。未来研究方向强调了需要可扩展的训练技术、增强的可解释性和在非文本模态中的稳健嵌入。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.20797", "html_url": "https://arxiv.org/abs/2503.20797", "title": "使用大型语言模型和少量示例选择估算政治和新闻内容的意识形态", "title_en": "\"Whose Side Are You On?\" Estimating Ideology of Political and News Content Using Large Language Models and Few-shot Demonstration Selection", "authors": "Muhammad Haroon,Magdalena Wojcieszak,Anshuman Chhabra", "background": "社交媒体平台的快速增长引发了对激进化、回声室效应和内容偏见的担忧。现有的意识形态分类方法需要大量的手工努力、大规模数据集的标注，并且无法适应不断变化的意识形态背景。", "innovation": "论文探讨了通过上下文学习（ICL）使用大型语言模型（LLMs）对在线内容的政治意识形态进行分类的潜力。实验结果表明，该方法在三个包含新闻文章和YouTube视频的数据集上显著优于零样本和传统监督方法，并且评估了元数据（如内容来源和描述）对意识形态分类的影响。", "conclusion": "研究展示了提供政治和非政治内容源如何影响LLM的分类，展示了大型语言模型在少量示例选择中的应用潜力，对估算政治和新闻内容的意识形态具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10388", "html_url": "https://arxiv.org/abs/2502.10388", "title": "面向精神科短期再入院预测的方面导向型摘要", "title_en": "Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction", "authors": "WonJin Yoon,Boyu Ren,Spencer Thomas,Chanhwi Kim,Guergana Savova,Mei-Hua Hall,Timothy Miller", "background": "近年来，大型语言模型（LLMs）的发展使得可以在无需针对特定任务进行监督训练的情况下自动化处理长文档。然而，这些模型在复杂任务上的零样本性能仍然不如简单的信息提取任务。对于输入较长且复杂的任务，可以通过先对文档进行总结，再对总结进行监督微调的方法来处理。然而，此过程可能会导致信息的损失。本文研究了一种方法来处理长文档的总结，旨在捕捉原始文档的不同重要方面。研究提出不同角度提示生成的LLM总结包含不同的信息信号，并提供了测量这些差异的方法。通过有效整合这些不同样本的信号，提出了监督训练转换器模型的方法，将其应用于一项具有高影响力的任务——基于精神病出院数据预测30天内的再入院。", "innovation": "提出了一个方面导向型的摘要方法，通过不同的方面导向提示生成总结，能够捕捉原始文档的不同重要方面。提出了方法来测量由于提示不同而引起的信息信号差异，并通过有效整合这些总结信号，提高了复杂任务（如预测患者出院后30天再入院）的预测性能。", "conclusion": "该方法通过集成来自不同方面的总结信号，提高了使用大型语言模型处理复杂任务（如精神病患者30天内的再入院预测）的性能，验证了在几个实际数据集上的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.17129", "html_url": "https://arxiv.org/abs/2502.17129", "title": "长语境大语言模型：如此言说", "title_en": "Thus Spake Long-Context Large Language Model", "authors": "Xiaoran Liu,Ruixiao Li,Mianqiu Huang,Zhigeng Liu,Yuerong Song,Qipeng Guo,Siyang He,Qiqi Wang,Linlin Li,Qun Liu,Ziwei He,Yaqian Zhou,Xuanjing Huang,Xipeng Qiu", "background": "长语境是自然语言处理（NLP）中的重要研究命题，一直贯穿NLP架构的发展，并为大型语言模型（LLMs）带来巨大机遇，赋予LLMs类似人类的终身学习潜力。然而，追求长语境也伴随着众多挑战。尽管如此，长语境仍是LLMs的核心竞争优势。在过去的两年里，LLMs的语境长度取得了突破性进展，达到了数百万词的数量级。同时，对于长语境LLMs的研究已从单纯的长度扩展扩展到了体系架构、基础设施、培训和评估技术的全面关注。", "innovation": "受《查拉图斯特拉如是说》和交响诗的启发，本文通过比喻的方式探讨了扩展LLMs语境长度的挑战与机遇。本文按架构、基础设施、培训和评估四个角度，全面展示了长语境技术的全貌，并提出了当前长语境LLMs面临的一大系列尚未解答的问题，旨在为读者提供一个全面了解长语境LLMs研究的系统性介绍。", "conclusion": "本文旨在展现长语境LLMs的生命周期，并通过十个未解决的问题提出了当前的研究空白。研究者希望本文能够作为理解长语境LLMs研究的一种系统性导引。附有视频和GitHub链接，以供进一步参考和探讨。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00444", "html_url": "https://arxiv.org/abs/2503.00444", "title": "Figurativo Archivio: un insieme di dati aperto e applicazione web per lo studio delle metafore", "title_en": "Figurative Archive: an open dataset and web-based application for the study of metaphor", "authors": "Maddalena Bressler,Veronica Mangiaterra,Paolo Canal,Federico Frau,Fabrizio Luciani,Biagio Scalingi,Chiara Barattieri di San Pietro,Chiara Battaglini,Chiara Pompei,Fortunata Romeo,Luca Bischetti,Valentina Bambini", "background": "近几十年来，关于隐喻的研究稳步增加，因为这一现象为语言和认知过程的研究打开了一扇窗口。与此同时，对于严谨构建和广泛标准化的实验材料的需求也增加了。现有的资源相比过去相对较小，缺乏包容性指标，且难以定制查询，因此有一项新的开放数据库被提出，以满足这些需求。这个数据库包含了996个意大利语隐喻，并提供了从熟悉度到语义距离和偏好解释等不同维度的指标，涵盖日常生活和文学领域的隐喻，且基于熟悉度与其他指标的相关性进行了验证。", "innovation": "该数据库具有几个创新点：首先，其规模相较于之前的数据资源有所增加；其次，提供了隐喻包容性的度量，以符合非歧视语言使用的建议；再次，它以基于网络的界面展示，具备定制查询的功能。此外，还提供了使用该数据库的研究指南，以用于其在隐喻处理及其人类和计算模型特征之间的关系研究中作为来源材料。", "conclusion": "该研究介绍了一个名为Figurative Archive的开放数据库，用于研究隐喻，旨在提供一份扩大的综合性资源，包含丰富了各种度量（如熟悉度、语义距离和偏好解释）的996个意大利语隐喻，覆盖了日常生活和文学领域，并提供了用户友好的网络界面，方便定制查询，对促进隐喻处理的研究具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01903", "html_url": "https://arxiv.org/abs/2504.01903", "title": "STAR-1：通过1000数据实现推理LLM的安全对齐", "title_en": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data", "authors": "Zijun Wang,Haoqin Tu,Yuhan Wang,Juncheng Wu,Yanqing Liu,Jieru Mei,Brian R. Bartoldson,Bhavya Kailkhura,Cihang Xie", "background": "该研究背景在于大型推理模型（LRMs）的安全性问题，现有的安全数据集多样性和质量有限，不足以提高LRMs的安全性能。", "innovation": "STAR-1是一个高效的小规模安全数据集，包含1000个样本，专门用于LRMs，基于多样性和前瞻性的推理设计原则。它通过引入现有的开源安全数据集、生成基于政策的推理样例以及采用GPT-4o的安全评分系统来确保数据集的质量，最终验证了其在提高LRMs和传统大型语言模型的安全性能方面的有效性。", "conclusion": "实验结果显示，使用STAR-1进行微调后的LRMs在四个基准上的安全性能平均提高了40%，而在五个推理任务中推理能力的下降轻微，仅为平均1.1%。进一步的脱秘研究表明，STAR-1的设计原则在构建数据集和促进LRMs安全性能方面是至关重要的。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.20995", "html_url": "https://arxiv.org/abs/2503.20995", "title": "ENCEOR: 基于熵指导的多头安全奖励模型的奖励组合", "title_en": "ENCORE: Entropy-guided Reward Composition for Multi-head Safety Reward Models", "authors": "Xiaomin Li,Xupeng Chen,Jingxuan Fan,Eric Hanchen Jiang,Mingye Gao", "background": "大型语言模型（LLMs）的安全对齐通常依赖于基于人类反馈的强化学习（RLHF）的方法，这需要人类注释来构建偏好数据集。由于给数据整体质量评分具有挑战性，最近的研究越来越多地采用基于多个安全规则的细粒度评分。在这一领域，本研究观察到一个稳健的现象：高评分熵的规则在区分人类偏好的响应时往往表现较差。基于這一发现，本研究提出了一种基于熵指导的方法，ENCORE，通过惩罚高评分熵的规则来组合多头奖励。理论分析显示，这些规则在权重优化过程中会获得几乎为零的权重，自然地证明了它们的惩罚性。文中还提供了实验结果来支持这一方法的有效性，ENCORE 在 RewardBench 安全任务上的表现优于多种基线方法，包括随机和均匀加权、单头Bradley-Terry加权以及LLM作为仲裁者等方法。这种方法完全不依赖于训练，并且适用于多种数据集，同时保持了解释性，是一种实用且有效的多属性奖励模型方法。", "innovation": "本研究提出的 ENCORE 方法采用熵指导策略，通过惩罚高评分熵的规则，优化多头奖励模型。这种方法在理论上证明了其有效性，通过Bradley-Terry损失优化权重时，高评分熵的规则将获得几乎为零的权重。此外，在实验中，ENCORE 显著优于现有的基线方法，特别是在 RewardBench 安全任务上表现出色。", "conclusion": "ENCORE 是一种适用于多种数据集且无需训练的多属性奖励模型方法，它在多头安全奖励模型中表现出色，具备很高的实用性和有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.14707", "html_url": "https://arxiv.org/abs/2504.14707", "title": "评估BERTTopic在开放型数据上的表现：以比利时荷兰语日常叙事为例的研究", "title_en": "Evaluating BERTopic on Open-Ended Data: A Case Study with Belgian Dutch Daily Narratives", "authors": "Ratna Kandala,Niels Vanhasbroeck,Katie Hoemann", "background": "标准主题模型在捕捉文本中的文化特定细微差别方面往往难以胜任。本研究评估了情境嵌入在识别比利时荷兰语（弗莱芒语）这一未充分研究的语境下的文化共鸣主题时的有效性。研究团队比较了KMeans聚类、潜在狄利克雷分配（LDA）和BERTopic在近25000篇日常个人叙事上的表现。", "innovation": "研究引入了情境嵌入技术（如BERTopic）来识别文化共鸣主题，并通过自动连贯性指标与人工评价相结合的方法，证实相对于传统的统计方法，情境嵌入在叙事丰富的数据上表现更佳。此外，研究发现K-Means在处理个人叙事分析时的表现较以往在类似荷兰语语料库上的表现差，突显了个人叙事分析中的独特语言挑战。", "conclusion": "研究结果显示情境嵌入在稳健主题建模中扮演着关键角色，并强调在处理低资源语言和文化特定领域时，特别是需要进行人性化评估。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11225", "html_url": "https://arxiv.org/abs/2505.11225", "title": "HAPO: 通过历史意识策略优化训练语言模型以进行简洁推理", "title_en": "HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization", "authors": "Chengyu Huang,Zhengxin Zhang,Claire Cardie", "background": "大型语言模型（LLMs）在测试时扩展响应长度可以显著提高其推理能力和性能，但往往会生成冗长的输出并增加推理成本。先前的高效测试时扩展方法通常采用通用预算约束或查询级别长度优化，但这些方法没有利用之前解决问题时的历史信息。基于这一限制，该研究提出了历史意识策略优化（HAPO）方法。", "innovation": "HAPO方法跟踪每个问题的历史状态（例如，之前生成的正确响应中的最小长度），并基于此历史状态采用新的长度奖励函数来激励发现比之前更简洁的正确解决方案，同时避免过度惩罚较短的错误响应，以促进向更高效解决方案的探索。HAPO结合长度奖励和正确性奖励，同时优化正确性和效率。", "conclusion": "实验结果表明，HAPO有效促进了LLMs的简洁推理能力，相比原先的响应长度减少了33-59%，而准确率下降仅为2-5%。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00661", "html_url": "https://arxiv.org/abs/2505.00661", "title": "从上下文学习和微调的角度研究语言模型的泛化能力：一个受控研究", "title_en": "On the generalization of language models from in-context learning and finetuning: a controlled study", "authors": "Andrew K. Lampinen,Arslan Chaudhry,Stephanie C.Y. Chan,Cody Wild,Diane Wan,Alex Ku,Jörg Bornschein,Razvan Pascanu,Murray Shanahan,James L. McClelland", "background": "大型语言模型展示了令人兴奋的能力，但它们的泛化能力在微调之后却显得异常狭窄。例如，它们可能无法泛化出简单的关系反转，或无法基于训练信息进行简单的逻辑推理。这些从微调中泛化的事实信息未能成功转移会影响模型的推理能力。另一方面，语言模型的上下文学习（ICL）显示了不同的归纳偏见和演绎推理能力。本文旨在探索这两种学习方式的泛化和演绎推理能力之间的差异。", "innovation": "本文构建了多个新数据集来评估和改进模型在新数据上进行泛化的能力。通过可控的微调或ICL向预训练的大型模型暴露部分数据信息，并在各种泛化要求下评估其性能。研究发现，在数据匹配的设置中，ICL比微调能更灵活地泛化某些类型的推理，提出了一种改进微调泛化能力的方法：在微调数据中添加上下文推理踪迹。这种方法在我们的数据集和其它基准测试中均能改善泛化能力。", "conclusion": "本文的结果对于理解不同学习模式提供给语言模型的泛化能力具有重要意义，并且可以为实际提高模型性能提供指导。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23777", "html_url": "https://arxiv.org/abs/2503.23777", "title": "CONGRAD：解决多语言偏好对齐中矛盾梯度过滤问题", "title_en": "CONGRAD:Conflicting Gradient Filtering for Multilingual Preference Alignment", "authors": "Jiangnan Li,Thuy-Trang Vu,Christian Herold,Amirhossein Tebbifakhr,Shahram Khadivi,Gholamreza Haffari", "background": "在为多语言模型对齐偏好进行简单联合训练时，可能会遇到负面干扰的问题。这在多语言训练中是已知的问题，即冲突的目标会降低整体性能。然而，这一现象在多语言偏好对齐的具体语境下仍然缺乏充分的研究。为此，该研究提出了一种名为CONGRAD的可扩展且有效的过滤方法，以减少跨语言的梯度冲突并选择高质量的偏好样本。CONGRAD利用梯度手术保留与汇总的多语言更新方向一致的样本，并加入了一种亚线性梯度压缩策略来降低梯度累积过程中的内存开销。研究者将CONGRAD整合到了自我奖励框架中，并在不同语言的LLaMA3-8B和Gemma2-2B模型上进行了评估。结果表明，CONGRAD能够在多种语言环境下表现出色，显著优于强大的基线方法，且对齐代价较小", "innovation": "该研究提出了CONGRAD方法，这是一种用于多语言偏好对齐的可扩展且有效的过滤技术。CONGRAD利用梯度手术来选择高质量的偏好样本，这些样本与聚合的多语言更新方向保持一致，并通过亚线性梯度压缩策略减少了梯度累积过程中的内存开销。此外，CONGRAD纳入了自我奖励框架，并通过10种不同语言的实验验证了其有效性", "conclusion": "实验结果表明，CONGRAD能够在各种语言环境下性能优越，且有较高的对齐效果，同时与强大的基线方法相比，拥有较小的对齐成本"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02106", "html_url": "https://arxiv.org/abs/2504.02106", "title": "ContrastScore: 朝着更高质量、更少偏见和更高效的评估指标，基于对比评估", "title_en": "ContrastScore: Towards Higher Quality, Less Biased, More Efficient Evaluation Metrics with Contrastive Evaluation", "authors": "Xiao Wang,Daniil Larionov,Siwei Wu,Yiqi Liu,Steffen Eger,Nafise Sadat Moosavi,Chenghua Lin", "background": "自动评估生成的文本质量仍然是一项重大挑战。传统的引用基度度量标准与人类评估的相关性较弱。近期研究表明，大型语言模型（LLMs）可作为源基度量，用于自然语言生成（NLG）的评估，显示出潜力，但仍存在未能与人类判读完全一致的问题。本文介绍了一个名为ContrastScore的对比评价度量标准，旨在提供更高质量、更少偏见和更高效的生成文本评估。实验结果表明，ContrastScore在机器翻译和摘要两个NLG任务上，一致地展示了比单一模型和集成模型基准更强的人类评价相关性。即使对比评价度量标准基于参数量较少的Qwen 3B和0.5B，也明显优于参数量更多的Qwen 7B，在评估效率上表现出色。此外，ContrastScore有效地减轻了常见的评估偏见，如长度偏好和概率偏好，提高了自动评估的稳健性。", "innovation": "研究引入了ContrastScore，这是一种用于对比评价的度量标准，能够实现更高质量、更少偏见和更高效的生成文本评估。与之前的小型LLM基度量标准相比，ContrastScore基于参数量较少的Qwen模型，依然能够取得更好的效果，显示出其高效性，同时还能缓解常见的评估偏见。", "conclusion": "实验结果证实，ContrastScore在两个NLG任务上展现出了更强的人类评价相关性，而且即使是在参数量较少的LLM上，也能够获得出色的评估效果，对于消除评估偏见和提高自动评估的稳定性具有积极意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00028", "html_url": "https://arxiv.org/abs/2505.00028", "title": "使用端到端检索增强生成提升语音到语音对话建模", "title_en": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation", "authors": "Pengchao Feng,Ziyang Ma,Wenxi Chen,Yao Li,Sheng Wang,Kai Yu,Xie Chen", "background": "端到端的语音到语音（S2S）对话系统由于其较低的延迟和更自然地整合诸如情感和说话者身份等非言语提示而逐渐获得了研究关注。然而，这些系统面临的关键挑战之一是如何有效地整合外部知识，通常这种能力是通过文本大型语言模型（LLMs）中的检索增强生成（RAG）来解决的。主要难点在于输入语音与检索到的文本知识之间的模态差异，这阻碍了信息的有效整合。为解决这一问题，本文提出了一种新的端到端RAG框架，可以直接从语音查询中检索相关文本知识。实验结果表明，该方法显著提高了端到端S2S对话系统的性能，同时实现了更高的检索效率。尽管整体性能仍落后于最佳级联模型，但我们的框架为提高端到端S2S系统中的知识整合提供了一种有前途的方向。我们的代码和数据集已发布。", "innovation": "提出了一种新的端到端RAG框架，可以直接从语音查询中检索相关文本知识，解决了输入语音与检索到的文本知识之间的模态差异问题，从而提高了端到端S2S对话系统的性能和检索效率。", "conclusion": "尽管整体性能仍落后于最佳级联模型，但提出的框架为提高端到端S2S系统中的知识整合提供了一种有前途的方向。我们的代码和数据集已发布。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12345", "html_url": "https://arxiv.org/abs/2505.12345", "title": "UniEdit：大型语言模型统一知识编辑基准", "title_en": "UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models", "authors": "Qizhou Chen,Dakan Wang,Taolin Zhang,Zaoming Yan,Chengsong You,Chengyu Wang,Xiaofeng He", "background": "当前，大多数大语言模型（LLMs）编辑数据集仅限于狭窄的知识领域，并且覆盖面有限，未能充分涵盖广泛的编辑需求和多样化的编辑效应。文章指出UniEdit旨在提供一个基于开放领域知识的统一基准，通过使用开放领域知识图谱中的广泛三元组知识来确保知识领域的全面覆盖，并设计了基于给定知识片段的邻域多跳链采样算法来全面评估编辑的涟漪效应，最终使用专有的LLMs将采样的知识子图转化为自然语言文本，以确保语法准确性与句法多样性。", "innovation": "UniEdit通过开放领域的知识图谱构建了广泛的编辑样本，并设计了一个采样算法来评估全面的编辑效应。此外，使用专有的LLMs将这些知识子图转化为自然语言文本，确保了语法准确性和句法多样性。这些方法旨在增强大型语言模型的准确性和可靠性，并且全面覆盖了编辑需求和多样化的编辑影响范围。", "conclusion": "本文通过大规模统计分析证实了UniEdit基准的规模、全面性和多样性。通过在多个LLMs和编辑器上进行全面实验，展示了它们在开放知识领域的编辑性能，指出了各自的强项和弱点，为未来的研究提供了宝贵的洞察。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13979", "html_url": "https://arxiv.org/abs/2505.13979", "title": "Mixed Signals: 矛盾信号——了解多模态共情检测中的模型分歧", "title_en": "Mixed Signals: Understanding Model Disagreement in Multimodal Empathy Detection", "authors": "Maya Srikanth,Run Chen,Julia Hirschberg", "background": "多模态模型在情感共情检测中发挥着关键作用，但当不同模态提供的线索存在矛盾时，其性能可能受到影响。研究者为了理解这种性能下降，研究了单模态和多模态预测出现分歧的案例。使用文本、音频和视频的Fine-tuned模型，并结合门控融合模型，研究发现这类分歧通常反映了潜在的模糊性，这可以通过标注者的不确定性来证实。这表明在一个模态中的主导信号在没有其他模态的支持下容易误导融合。此外，研究观察到，就像模型一样，人类在处理多模态输入时也并不总是受益。这些洞察表明分歧是可以作为识别具有挑战性的例子并提高共情系统稳健性的有用诊断信号。", "innovation": "研究通过分析单模态与多模态预测的分歧来理解多模态共情检测中的失败情况，发现了这些分歧往往反映了潜在的模糊性，并且主导信号在缺乏其他支持时容易误导。这种研究方法为共情检测系统的改进提供了新的视角。", "conclusion": "研究结果表明，人类和模型一样，并非总是受益于多模态输入，而分歧可以作为识别具有挑战性的例子并提高共情检测系统稳健性的有用信号。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种用于大语言模型的安全、高效和自适应联邦分割框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "高度高质量但分散于数据孤岛中的私人数据可用于改善大语言模型（LLM），但其分散分布及其高计算需求限制了这些模型在联邦环境中的部署。传统的联邦分割模型在传递向量时难以有效加密，且自回归特性导致联邦分割学习仅能顺序进行，这带来了高通信开销。固定的分割点也不够灵活，难以适应下游任务。", "innovation": "提出了基于LLaMA2的FedSEA-LLaMA框架。具体创新包括：在前向传递中注入高斯噪声以实现端到端的安全向量传输；采用注意力掩码压缩和KV缓存协作以降低通信成本，提高训练和推理的速度；允许用户根据特定任务需求动态调整输入/输出块的分割点。", "conclusion": "实验结果显示，FedSEA-LLaMA在自然语言理解、摘要生成和对话式问答等任务中的性能与中心化部署的LLaMA2相当，且训练和推理速度提升了8倍。进一步的安全攻击分析和不同分割点测试表明，FedSEA-LLaMA在安全性与适应性方面是有效的。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17565", "html_url": "https://arxiv.org/abs/2505.17565", "title": "p2-TQA：一种基于过程的偏好学习框架，用于自我改进的表格问题回答模型", "title_en": "p2-TQA: A Process-based Preference Learning Framework for Self-Improving Table Question Answering Models", "authors": "Wei Zhou,Mohsen Mesgar,Heike Adel,Annemarie Friedrich", "background": "表格问题回答（TQA）专注于基于表格数据回答问题，其目标是对表数据进行有效交互，用于单元格检索和数据分析任务。虽然近期研究已经利用微调来提升TQA系统的性能，现有的方法往往未能充分利用可用数据，并且忽视了通过后训练进一步提升的潜力。", "innovation": "本文引入了p2-TQA，这是一种基于过程的偏好学习后训练框架。p2-TQA自动利用特定于表的流水线构建过程偏好数据，避免了手动或成本高昂的数据收集需求。然后，它通过对比学习优化模型。实验结果表明，使用p2-TQA，模型在领域内数据集上性能提升5%，而在领域外数据集上提升2.4%，仅需要8,000个训练实例。增强后的模型在竞争力上与更大的、更为复杂的最新TQA系统相当，同时效率提高5倍以上。", "conclusion": "研究表明，p2-TQA能有效提升TQA模型性能，并展现出与更复杂系统相当的效果，同时保持更高的效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17120", "html_url": "https://arxiv.org/abs/2505.17120", "title": "自我解释能力：大语言模型能够描述驱动其决策的复杂内部过程", "title_en": "Self-Interpretability: LLMs Can Describe Complex Internal Processes that Drive Their Decisions", "authors": "Dillon Plunkett,Adam Morris,Keerthi Reddy,Jorge Morales", "background": "我们对大语言模型（LLMs）是如何以及为何以特定方式响应的问题理解有限。其神经网络难以解释，我们只是开始理解单个神经元和电路的功能。另一条理解这些系统的途径是研究和开发其解释自身功能的能力。通过训练，LLMs可以准确描述其在某些决策过程中内部处理的定量特征，并进一步解释其决策过程。", "innovation": "本研究通过微调GPT-4o和GPT-4o-mini，使其能够在各种复杂情境下（如选择公寓、贷款、假期等）依据随机生成的定量偏好做出决策。研究展示了LLMs能够准确报告这些偏好（即他们在决策过程中学习赋予不同属性的权重）。而且，研究还展示了这些LLMs可以被进一步微调以更准确地解释其决策过程。此外，这种训练具有推广性，能够提高模型准确解释其他复杂决策的能力，而不仅仅是那些被微调过的决策。这一工作朝着训练LLMs准确全面地报告其内部过程迈出了步，这将极大提升解读性、控制性和安全性", "conclusion": "本研究展示了通过训练改善LLMs自我解释能力的方法，并验证了这种方法的推广性，即改进后的模型能够更准确地解释复杂决策。这为理解LLMs的内部过程提供了新途径，对提升模型的可解释性、控制性和安全性具有重大意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17206", "html_url": "https://arxiv.org/abs/2505.17206", "title": "FB-RAG: 使用前瞻和回顾查找提高RAG", "title_en": "FB-RAG: Improving RAG with Forward and Backward Lookup", "authors": "Kushal Chawla,Alfy Samuel,Anoop Kumar,Daben Liu", "background": "传统的检索增强生成（RAG）方法在处理缺乏明显信号的复杂查询时遇到困难，这导致了选择小范围上下文可能导致关键信息缺失与选择大范围上下文可能导致模型混淆之间的权衡。现有方法通常需要复杂的微调或强化学习，这为性能提升带来了困难。", "innovation": "提出了一种名为Forward-Backward RAG（FB-RAG）的新框架，基于简单的前瞻策略。FB-RAG采用轻量级LLM提前预览可能的未来生成，并利用多个采样输出的证据精准识别最终更强大生成器所需的最相关上下文。该框架能够在无需复杂微调或强化学习的情况下提高性能。", "conclusion": "FB-RAG在9个来自LongBench和$\textbackslashinfty$Bench的数据集上表现优异。通过更短、更集中的提示，该框架还能实现性能提升和延迟减少的双重目标。在特定任务上，FB-RAG不仅能匹配领先的基线模型，还能在48%的延迟减少下匹配，或在性能提升8%的情况下延迟减少10%。分析发现，即使前瞻LLM未能生成正确答案，其尝试也能指导最终模型输出准确的结果，展示了如何通过较小的LLM系统性地提升更大LLM的性能和效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17671", "html_url": "https://arxiv.org/abs/2505.17671", "title": "MIDB：增强多语言指令合成中文化平等的多语言指令数据增强器", "title_en": "MIDB: Multilingual Instruction Data Booster for Enhancing Cultural Equality in Multilingual Instruction Synthesis", "authors": "Yilun Liu,Chunguang Zhao,Xinhua Yang,Hongyong Zeng,Shimin Tao,Weibin Meng,Minggui He,Yan Yu,Hongxia Ma,Li Zhang,Daimeng Wei,Boxing Chen", "background": "尽管存在数据质量的质疑，指令合成已广泛应用于LLMs的指令调整（IT），作为一种经济快速的替代方案。最近的研究主要集中在提高英语指令合成数据的质量，以促进英语为中心的LLMs的调整。然而，多语言合成指令对的数据质量问题更为严重，通常采用机器翻译将英语合成数据翻译成其他语言。这不仅加剧了内容错误，还增加了由机器翻译引入的缺陷，导致目标语言的本地化不足，从而在训练的LLMs中造成了文化不平等。", "innovation": "本文提出了一种名为MIDB（Multilingual Instruction Data Booster）的多语言指令数据增强器，通过使用来自16种语言约36800个修订示例的人类语言专家训练，自动解决了多语言合成数据的质量问题，包括内容错误、机器翻译缺陷及其对目标语言本地化的不足。实验表明，MIDB不仅能稳定提高16种语言的指令数据质量，还能显著提升基于MIDB增强数据训练的多语言LLMs的指令遵循能力和文化理解能力，从而改善了语言和文化的平等性.", "conclusion": "研究结果表明，MIDB通过增强多语言合成数据的质量，有效地提高了多语言LLMs在指令遵循和文化理解方面的能力，从而改善了语言和文化的平等性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02431", "html_url": "https://arxiv.org/abs/2506.02431", "title": "从愤怒到喜悦：国家人设如何塑造大型语言模型中的情感归因", "title_en": "From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models", "authors": "Mahammed Kamruzzaman,Abdullah Al Monsur,Gene Louis Kim,Anshuman Chhabra", "background": "情绪是人类经验的基本组成部分，因个体差异、文化背景和国籍而异。鉴于大型语言模型（LLMs）在扮演角色方面取得了显著成功，本研究探讨了当LLMs被赋予国家特定的人设时，是否会表现出情感刻板印象。通过研究预训练LLMs中不同国家的情感归因及其与文化规范的一致性，本研究结合了霍夫斯泰德跨文化框架中的四个关键文化维度：权力距离、不确定性规避、长期取向和个体主义。分析结果显示，不同地区在情感归因上存在显著差异，愤怒、羞愧和快乐等情绪尤其被不公允地分配。此外，研究还发现了LLMs生成的情感反应与人类情感回应之间，特别是负面情绪方面，存在明显偏差，表明LLMs中的情感可能是简化且可能存在偏见的刻板印象。", "innovation": "本研究通过结合霍夫斯泰德的跨文化框架中的四个关键文化维度，提供了更深入的理解，探讨了LLMs在被赋予国家特定人设时是否会展现出情感刻板印象，并且首次系统性地分析了不同国家的情感归因，揭示了情感分配上的偏差与文化刻板印象的关系，为理解LLMs的情感生成机制提供了新的视角。", "conclusion": "研究结果表明，LLMs在不同国家的情感归因上存在显著差异，特别是负面情绪的归因与现实文化可能存在偏差。这揭示了LLMs可能存在简化和潜在偏见的情感刻板印象，并强调了LLMs的情感生成机制可能需要改进，以更好地反映出复杂多样的人类情感和社会文化背景。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04070", "html_url": "https://arxiv.org/abs/2506.04070", "title": "LaF-GRPO: 通过LLM跟随反馈奖励实现视障人士的现场导航指令生成（GRPO方式）", "title_en": "LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward", "authors": "Yi Zhao,Siqi Wang,Jing Li", "background": "视障（VI）人员的导航指令生成对于其独立行动至关重要，但这一领域相对未充分开发和研究。本研究聚焦于生成能够在现场按步实现且对视障使用者实用的导航指令。为了克服相关领域缺乏标准化评估基准的问题，本研究还开发了一个包含27000多个样本的开放式数据集NIG4VI，用于辅助训练和评估，该数据集涵盖了详尽且开放式的现场导航情景，并附有准确的三维坐标，以支持细致、开放式的指令生成。", "innovation": "本研究提出了LaF-GRPO（LLM-as-Follower GRPO）方法，利用一个语言模型模拟视障用户的反馈数据来优化指令，为视障导航提供了更为精准、实用的指令，并减少了需要收集真实世界数据的成本。同时，引入了NIG4VI数据集用于支持这一领域的训练和评估，该数据集包含了多样化的导航场景及其准确的空间坐标，有助于更细致的指令生成，并通过实验证明了LaF-GRPO方法的有效性。", "conclusion": "本研究通过LaF-GRPO方法显著提高了导航指令的生成质量，实验结果表明，LaF-GRPO相较于其他方法在多项评估指标中表现更优，并且通过定性分析进一步验证了生成的导航指令更为直观和安全。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23921", "html_url": "https://arxiv.org/abs/2506.23921", "title": "大型语言模型中的三项真题", "title_en": "The Trilemma of Truth in Large Language Models", "authors": "Germans Savcisens,Tina Eliassi-Rad", "background": "公众往往将人类特质归因于大型语言模型 (LLMs) 并假设它们“知道”某些事情。实际上，LLMs 将在训练过程中保留的信息编码为内部概率性知识。现有研究方法难以探察这种知识的真实性和可靠性，且存在一系列错误的底层假设。", "innovation": "研究引入 sAwMIL (Sparse-Aware Multiple-Instance Learning) 多类别探察框架，将多实例学习与置信预测结合，利用 LLMs 的内部激活来判断陈述为真、假或不确定。该方法跨 16 种开源 LLM 进行评估，结果显示普通探察方法可靠性低且在某些情况下表现不如零样本提示，真实性和错误性编码不对称，且 LLMs 包含一种独立于真和假的信号。", "conclusion": "普通探察方法可靠性不足，sAwMIL 在真实性判断上比传统方法更准确，真实性和错误性编码不对等，存在第三种类型的信息信号不同与真和假。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14429", "html_url": "https://arxiv.org/abs/2506.14429", "title": "LongLLaDA: 解开扩散大语言模型的长上下文能力", "title_en": "LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs", "authors": "Xiaoran Liu,Yuerong Song,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu", "background": "扩散大语言模型（diffusion LLMs）在自然语言处理（NLP）研究中逐渐成为一个重要焦点，研究人员投入大量精力理解和提高它们的可扩展性和下游任务性能。然而，它们处理长上下文的能力尚未被系统研究或开发有效的上下文扩展方法。本研究首次系统对比了扩散大语言模型与传统自回归大语言模型（auto-regressive LLMs）在长上下文任务上的表现。研究发现，扩散大语言模型在直接扩展上下文时保持稳定的困惑度，而自回归模型在超过预训练长度的上下文中会完全失效。研究者通过旋转位置嵌入（RoPE）的扩增理论解释了这两种现象，并推出了一种无需训练的方法LongLLaDA，该方法结合了NTK基RoPE扩增和LLaDA。研究表明，扩散大语言模型在某些长上下文任务上的表现优于自回归模型，而在其他任务上则逊色。这一成果为扩散大语言模型的长上下文能力提供了理论和实证基准，对后续研究具有重要指导意义。", "innovation": "首次系统对比扩散大语言模型和自回归大语言模型在长上下文任务上的表现；发现扩散大语言模型具有独特的局部感知现象，即使在超过预训练长度的长上下文中也能成功从最近的上下文片段中检索信息；提出了一种无需训练的方法LongLLaDA，旨在通过结合NTK基RoPE扩增和LLaDA来提升扩散大语言模型的长上下文能力。", "conclusion": "研究表明，扩散大语言模型的长上下文能力可以通过建立新的方法进行扩展，且在某些任务上优于自回归大语言模型。研究还为扩散大语言模型的长上下文任务提供了理论上的洞察和实证基准，对于未来相关的研究具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07810", "html_url": "https://arxiv.org/abs/2507.07810", "title": "理解并控制上下文学习中重复神经元和诱导头部的影响", "title_en": "Understanding and Controlling Repetition Neurons and Induction Heads in In-Context Learning", "authors": "Nhi Hoai Doan,Tatsuya Hiraoka,Kentaro Inui", "background": "本研究探讨了大型语言模型（LLMs）在识别重复输入模式的能力与其在上下文学习（ICL）中的表现之间的关系。以往的研究主要关注注意力头，而本研究则从能力神经元的视角出发，特别是重复神经元，进行了探索。", "innovation": "本研究发现了重复神经元在不同层深度中的影响，并通过比较重复神经元和诱导头部的作用，提出了一种在保持强ICL能力的同时减少重复输出的策略。", "conclusion": "研究表明，重复神经元对ICL性能的影响因所处层数的不同而异。通过将重复神经元和诱导头部的效果进行比较，研究了减少重复输出的方法，同时维持强ICL能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20495", "html_url": "https://arxiv.org/abs/2506.20495", "title": "ReCode：使用强化学习更新代码API知识", "title_en": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "authors": "Haoze Wu,Yunzhi Yao,Wenhao Yu,Ningyu Zhang", "background": "大型语言模型（LLMs）在代码生成方面表现出色，但在面对外部库API频繁更新时，它们的表现会下降。这是因为LLMs依赖于其训练数据中的过时API知识，即使有最新的文档供参考，也难以在动态环境中可靠地生成代码。这种限制使LLMs在处理API变化时面临巨大挑战。", "innovation": "我们提出了一种名为ReCode的全新框架，使用基于规则的强化学习方法来模拟人类程序员适应API变化的过程。ReCode构建了一个包含约2,000个数据条目的库，用于训练LLMs进行基于更新信息的版本迁移。此外，我们还引入了一种修改后的字符串相似度度量，作为强化学习的奖励。实验结果显示，ReCode显著提升了LLMs在动态API场景下的代码生成性能，尤其是在未见过的任务CodeUpdateArena中表现出色。与监督微调相比，ReCode对LLMs的通用代码生成能力影响较小。我们对多种LLMs和强化学习算法（GRPO和DAPO）进行了训练，并取得了稳健的改进。值得注意的是，训练后的Qwen2.5-Coder-7B模型的表现优于参数为32B的代码指令微调模型和具有相同架构的推理模型。", "conclusion": "我们提出的方法ReCode通过使用强化学习来更新代码API知识，显著提升了LLMs在动态API场景下的代码生成性能。与监督微调相比，这种方法对LLMs的通用代码生成能力影响较小。我们的实验结果证明了这种方法的有效性，并对其未来应用进行了展望。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16444", "html_url": "https://arxiv.org/abs/2506.16444", "title": "REIS：一种基于存储内处理的高性能和能效检索系统", "title_en": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing", "authors": "Kangqi Chen,Andreas Kosmas Kakolyris,Rakesh Nadig,Manos Frouzakis,Nika Mansouri Ghiasi,Yu Liang,Haiyu Mao,Jisung Park,Mohammad Sadrosadati,Onur Mutlu", "background": "大型语言模型（LLMs）的知识局限于其训练数据，这意味着它们在处理之前未见过的问题时会遇到困难。为了克服这个问题，检索增强生成（RAG）通过使用外部知识库来补充LLMs的静态训练知识。然而，在RAG的检索阶段，由于数据库规模庞大，近似最近邻搜索（ANNS）在宿主和存储系统之间产生了显著的数据移动开销。为了减轻这些开销，先前的研究提出了存储内处理（ISP）技术，目的是通过在存储内部执行计算来加速ANNS。然而，现有的利用ISP优化ANNS的研究存在局限性，包括使用不适合ISP系统算法、未能加速由ANNS选择的数据检索操作、以及需要进行显著的硬件改造等问题，这限制了性能并阻碍了其广泛应用。", "innovation": "我们提出了REIS，一种针对RAG定制的ISP系统，它通过三种关键机制解决了上述局限性：（1）REIS使用了一个数据库布局，将数据库嵌入向量与其相关文档链接起来，使得高效检索成为可能；（2）它通过引入一种针对ISP参数的数据放置技术，将嵌入分布在存储系统的各个平面上，并使用轻量级闪存翻译层来实现高效ANNS；（3）REIS利用了一种ANNS引擎，充分利用了存储系统内的现有计算资源。相比于服务器级系统，REIS在检索性能（能效）上提高了平均13倍（55倍）.", "conclusion": "通过REIS，研究展示了如何有效利用存储内处理技术来优化RAG中的检索阶段，进而显著提升了检索性能和能效，为未来的广泛应用奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02833", "html_url": "https://arxiv.org/abs/2507.02833", "title": "验证可验证指令遵循的一般化", "title_en": "Generalizing Verifiable Instruction Following", "authors": "Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi", "background": "人类与AI互动成功的关键因素之一是语言模型或聊天机器人的能力，能够精确遵循人类指令。用户通常会添加输出约束（如“仅以‘是’或‘否’回答”或“至少提到单词‘abrakadabra’三次”）以获得更有用的答案。即使目前最强的模型也难以满足这些约束。研究发现，大多数模型在一小部分可验证约束上过度拟合，这些约束测试这些能力，而不能很好地泛化到未见过的输出约束。", "innovation": "本文引入了一个新的基准测试IFBench，用于评估模型对58个新、多样且具有挑战性的、未见过域的验证性指令遵循的泛化能力。此外，通过精细设计约束验证模块，结合验证奖励的强化学习（RLVR）显著提高了指令遵循能力。同时，作者还发布了一系列新的训练约束、验证函数、RLVR训练提示和代码，以改进指令遵循的泛化能力。", "conclusion": "本文通过提出IFBench和改进的训练方法，显著提升了模型在未见过约束下的指令遵循能力，为进一步的研究和应用奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22545", "html_url": "https://arxiv.org/abs/2507.22545", "title": "ControlMed：为医疗语言模型添加推理控制", "title_en": "ControlMed: Adding Reasoning Control to Medical Language Model", "authors": "Sung-Min Lee,Siyoon Lee,Juyeon Kim,Kyoungmin Roh", "background": "大型语言模型（LLMs）在医疗领域中的应用越来越广泛，特别是在临床决策支持方面。然而，现有的LLMs在推理过程中常生成冗长的推理路径，导致巨大的计算开销和响应延迟，这限制了它们在临床环境中的实际应用。", "innovation": "该论文介绍了ControlMed，这是一种通过细粒度控制标记在推理时间让用户主动控制推理长度的医疗语言模型。ControlMed通过三个阶段进行训练：预训练阶段使用大规模的合成医疗指令数据集；监督微调阶段使用多长度推理数据和显式长度控制标记；强化学习阶段使用基于模型的奖励信号来提升事实正确性和响应质量。", "conclusion": "实验证明，ControlMed在英语和韩语医疗基准测试上的表现与最先进的模型相当或更好。此外，用户可以通过控制推理长度灵活地平衡推理准确性和计算效率。这些发现表明，ControlMed是一个实用且适应性强的解决方案，用于临床问题回答和医疗信息分析。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04508", "html_url": "https://arxiv.org/abs/2509.04508", "title": "ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models", "title_en": "ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models", "authors": "Biddut Sarker Bijoy,Mohammad Saqib Hasan,Pegah Alipoormolabashi,Avirup Sil,Aruna Balasubramanian,Niranjan Balasubramanian", "background": "小语言模型（SLMs）的多智能体系统（MAS）相较于由大规模语言模型（LLMs）驱动的单智能体系统，在解决复杂问题上可能是一个可行的替代方案。本文探讨了这两种系统在有效性和效率方面的比较。", "innovation": "提出了一种简化的渐进式子任务训练策略（ProST），该策略在每个训练周期中逐个引入新的子任务，类似于实例级别课程学习。实验发现此策略可以提高所有配置下多智能体系统的有效性，而帕累托分析表明微调的多智能体系统在有效性和效率方面表现得更好。", "conclusion": "渐进式培训策略对于子任务错误率的降低非常重要，多智能体系统的微调配置能提供更好的有效性和效率权衡。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.08105", "html_url": "https://arxiv.org/abs/2509.08105", "title": "MERLIN: 多阶段课程对齐以实现跨语言推理中多语言编码器-LLM集成", "title_en": "MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder-LLM Integration in Cross-Lingual Reasoning", "authors": "Kosei Uemura,David Guzmán,Quang Phuoc Nguyen,Jesujoba Oluwadara Alabi,En-shiun Annie Lee,David Ifeoluwa Adelani", "background": "大型语言模型在英语方面表现出色，但在许多低资源语言(LRLs)中处理复杂推理方面仍然存在困难。现有的编码器+解码器方法如LangBridge和MindMerger可以提高中高资源语言的准确性，但在LRLs方面留下了很大的差距。", "innovation": "我们提出了MERLIN，一个两阶段模型堆叠框架，采用课程学习策略——从通用双语平行语料库到任务特定的数据，并仅适应一组DoRA权重。在AfriMGSM基准上，MERLIN在精确匹配准确性上提高了12.9个百分点，超过了MindMerger，并且在MGSM和MSVAMP上也表现出一致的增益，证明了其在低和高资源设置中的有效性。", "conclusion": "MERLIN提升了低资源语言在复杂推理任务上的性能，并且在不同语言资源设置中都表现出了较强的适应性优势。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09776", "html_url": "https://arxiv.org/abs/2508.09776", "title": "LLM生成的文本解释能否提升模型分类性能？一项实证研究", "title_en": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study", "authors": "Mahdi Dhaini,Juraj Vladika,Ege Erdogan,Zineb Attaoui,Gjergji Kasneci", "background": "在快速发展的可解释自然语言处理（NLP）领域，文本解释，即类似人类的推理，在解释模型预测和丰富带有可解释标签的数据集方面至关重要。传统方法依赖于人力标注，这成本高昂且劳动密集，限制了可扩展性。因此，本文提出了一种自动化框架，通过利用最先进的大型语言模型（LLMs）生成高质量的文本解释。", "innovation": "该研究提出了一个自动化框架，利用多个最先进的大语言模型（LLMs）来生成高质量文本解释，并使用全面的自然语言生成（NLG）指标评估这些LLM生成解释的质量。此外，研究还探讨了这些解释在自然语言推理任务中对预训练语言模型（PLMs）和LLMs性能的下游影响，并在两个不同基准数据集上进行了实验。实验结果表明，自动化生成的解释在提升模型性能方面具有高度竞争力，与人工标注的解释效果相当。", "conclusion": "本研究证实，基于大语言模型的自动化文本解释生成方法在扩展NLP数据集和增强模型性能方面具有前景，具有广阔的应用价值。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02087", "html_url": "https://arxiv.org/abs/2508.02087", "title": "当真相被 overriding：揭示大语言模型中奉承行为的内部起源", "title_en": "When Truth Is Overridden: Uncovering the Internal Origins of Sycophancy in Large Language Models", "authors": "Jin Li,Keyu Wang,Shu Yang,Zhuoran Zhang,Di Wang", "background": "大型语言模型（LLMs）常常表现出奉承行为，即使用户陈述的意见与事实不符，它们也会同意这些观点。尽管已有研究记录了这一倾向，但导致这种行为的内部机制仍然不甚明了。本文探讨了用户观点如何在不同模型族中诱导奉承行为。研究发现，简单的意见陈述能够可靠地诱导奉承行为，而用户专家身份的表述几乎没有影响。此外，通过logit层面分析和因果激活补丁，研究发现了奉承行为的两阶段发展过程：首先，较晚层输出偏好的改变；其次，深层表示差异的加剧。还验证了用户权威对行为的影响微乎其微，因为模型并未内部编码此信息。这些发现指出，奉承行为不是表面现象，而是涉及深层信息学习结构的替代，具有对齐和可信AI系统的启示作用。", "innovation": "本文提供了一个关于如何在LLMs中出现奉承行为的机制解释。研究通过系统地研究用户意见如何在不同模型族中诱导奉承行为，并发现了奉承行为的两阶段发展过程：较晚层输出偏好的改变与深层表示差异的加剧。此外，研究还通过语法视角分析了如何影响奉承行为，并发现了第一人称提示（“我认为……”）和第三人称提示（“他们认为……”）之间代表扰动差异，从而更频繁地产生奉承行为。这些发现揭示了奉承行为是一种更深层次的现象。", "conclusion": "研究表明，奉承行为并非表面现象，而是涉及深层信息学习结构的替代，与输入信息不符合。奉承行为的机制源于模型中的知识学习结构被替代，具有对齐和构建可信AI系统的启示意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02241", "html_url": "https://arxiv.org/abs/2508.02241", "title": "在多语言大型语言模型中隔离文化神经元", "title_en": "Isolating Culture Neurons in Multilingual Large Language Models", "authors": "Danial Namazifard,Lukas Galke Poech", "background": "语言和文化紧密相关，但多语言大型语言模型如何以及在哪里编码文化仍然不清楚。本文基于已有的识别特定语言神经元的方法，定位并解离文化特定的神经元，研究它们与语言特定神经元的重叠和相互作用。为此，作者引入了一个名为MUREL的语料库，包含6个不同文化共8520万词素的数据。通过定位和干预实验，研究发现多语言大型语言模型在较高层次上分别编码不同的文化，这些文化相关的神经元可以 largely 独立于语言特定或其它文化的神经元被调节。这表明，多语言大型语言模型中的文化知识和倾向可以被选择性地隔离和编辑，这对公平性、包容性和对齐具有重要意义。", "innovation": "1. 创建并使用了MUREL语料库，这是一个有6个不同文化数据集，共8520万词素的语料库。\n2. 基于已有的识别特定语言神经元的方法，定位并解离文化特定的神经元，研究它们与语言特定神经元的重叠和相互作用。\n3. 发现多语言大型语言模型在较高层次上分别编码不同的文化，这些文化相关神经元可以largely独立于语言特定或其它文化的神经元被调节。这表明可以对多语言大型语言模型中的文化知识和倾向进行选择性隔离和编辑。", "conclusion": "研究发现，多语言大型语言模型中的文化知识和倾向可以被选择性地隔离和编辑，这对于提高模型的公平性、包容性和对齐具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17844", "html_url": "https://arxiv.org/abs/2509.17844", "title": "信任我，我能说服你：论辩认知评估框架", "title_en": "Trust Me, I Can Convince You: The Contextualized Argument Appraisal Framework", "authors": "Lynn Greschner,Sabine Weber,Roman Klinger", "background": "以往研究发现了论点引发的情绪仅依赖于论点本身这一观点，事实上，情绪还会受到论点对个人潜在影响的主观评估影响。虽然已有对二元论点情感的研究，但在论点及其说服力的背景下，认知评估模式仍没有被提出。因此，本文探索了一个结合发论者、接收者和论点的论辩认知评估框架。", "innovation": "本文提出了一个论辩认知评估框架，引入了认知评估模型中的情感、熟悉度、反应紧迫性和预期努力等变量，并通过角色扮演的方式分析了论点的情感、原因、评估和说服力，填补了论点说服力研究的空白。", "conclusion": "论辩认知评估框架中，主体的积极情感（如信任）与说服力呈正相关，而消极情感（如愤怒）则与说服力负相关。认知评估变量特别强调了评估者对论点的熟悉度的重要性，这对论点的说服力有显著影响。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26601", "html_url": "https://arxiv.org/abs/2509.26601", "title": "MENLO: 从偏好到熟练度--跨47种语言评估与建模母语质量", "title_en": "MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages", "authors": "Chenxi Whitehouse,Sebastian Ruder,Tony Lin,Oksana Kurylo,Haruka Takagi,Janice Lam,Nicolò Busetto,Denise Diaz,Francisco Guzmán", "background": "确保大型语言模型（LLM）在多种语言下产生类似母语的质量回答具有挑战性。为了应对这一挑战，我们提出了MENLO框架，该框架通过借鉴受众设计机制来实现出色的类似母语响应质量评估。使用MENLO，我们创建了一个包含47种语言变体、4,615个由人类标注的提示-响应偏好对的数据集，涵盖了四个质量维度，并具有高跨标注者一致性。通过对零样本LLM裁判进行评价，我们发现它们显著受益于成对评价和结构化注释标准评分表，但仍然无法在我们的数据集上达到人类注释者的水平。通过强化学习、奖励塑造和多任务学习方法进行微调，我们展示了显著的进步。此外，我们展示了使用经过RL训练的裁判作为生成奖励模型，以增强LLM的多语言熟练度，尽管与人类判断之间仍存在差异。我们的研究结果指出了多语言评价和偏好对齐可扩展方向的潜在路径。", "innovation": "我们提出了MENLO框架，用于基于受众设计启发机制的类似母语响应质量评估。我们创建了一个覆盖47种语言变体的数据集，包括4,615个人类标注的提示-响应偏好对，并采用了结构化注释标准评分表。通过强化学习、奖励塑造和多任务学习方法，在LLM的微调方面取得了显著进展，并展示了一种经过RL训练的裁判作为生成奖励模型的方法，以增强LLM的多语言能力。", "conclusion": "我们的研究表明，有希望的方向包括可扩展的多语言评估和偏好对齐。我们发布了数据集和评估框架，以支持进一步在多语言LLM评估方面的研究。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15269", "html_url": "https://arxiv.org/abs/2510.15269", "title": "TACL：多语言医学文本理解的阈值自适应课程学习策略", "title_en": "TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding", "authors": "Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng", "background": "医疗文本，尤其是电子医疗记录（EMRs），是现代医疗的核心基础，记录了患者护理、诊断和治疗的关键信息。这些文本具有巨大的潜力，可以推动临床决策和医疗数据分析的进步。然而，其非结构化、专业语言及其在不同情境下的变异性，使得自动化理解成为复杂挑战。尽管自然语言处理取得了进展，现有方法往往将所有数据视为同等挑战，忽略临床记录中固有的复杂性差异。这种忽视限制了模型的有效泛化和在稀有或复杂案例中的表现。", "innovation": "本文提出了一种新颖的框架TACL（阈值自适应课程学习），旨在通过重新思考模型在训练期间与医疗文本的交互方式来解决这些挑战。TACL受到逐步学习原理的启发，根据样本的复杂程度动态调整训练过程。通过将数据分类为难度级别，并在训练初期优先处理简单案例，模型能够建立坚实的基础，然后应对更复杂的记录。将TACL应用于包括英语和中文临床记录在内的多语言医学数据，我们在各种临床任务中观察到显著的改进，包括自动ICD编码、再入院预测和中医证候分类。", "conclusion": "TACL不仅增强了自动系统的性能，还展示了在不同医学领域统一方法的潜力，为更准确、可扩展和全球适用的医疗文本理解解决方案铺平了道路。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15267", "html_url": "https://arxiv.org/abs/2510.15267", "title": "TraceCoder：通过多源知识整合实现可追溯的ICD编码", "title_en": "TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration", "authors": "Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng", "background": "自动化的国际疾病分类（ICD）编码是将临床记录标准化地转换为诊断和程序代码的重要工具，在医疗保健系统中发挥着关键作用。现有的编码方法面临诸如临床文本与ICD代码之间的语义差距、对罕见和长尾代码表现不佳以及解释性差等诸多挑战。这些不足限制了当前在健康医疗领域的应用效果和可靠性。", "innovation": "我们提出了一种名为TraceCoder的新框架，该框架通过整合多种外部知识来增强ICD编码的可追溯性和解释性。TraceCoder动态地集成来自UMLS、维基百科和大规模语言模型的知识，以丰富代码表示、弥合语义差距、处理罕见和模糊的代码，并引入一种混合注意力机制来模拟标签、临床上下文和知识之间的交互作用，提高长尾代码的识别并使预测可以在外部证据的基础上实现可解释性。实验结果验证了TraceCoder在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上的先进性能，并通过消融研究验证了其各个组件的有效性。", "conclusion": "TraceCoder提供了具有可扩展性和稳健性的自动化ICD编码解决方案，同时满足临床对准确性、解释性和可靠性的需求。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性和知识枯竭", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Peter Ebert Christensen,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度一致的文本。这种一致性可能导致知识枯竭，即随着时间的推移，LLMs提供的信息范围会缩小。目前关于一致性的工作主要集中在封闭式多项选择设置或模糊语义特征上，并未从时间轴和文化情境的角度进行考察。本文旨在弥补这一不足，提出了一种新的方法来测量认知多样性，即LLMs输出中的现实世界声明的多样性，并通过广泛的经验研究探讨知识枯竭现象。作者测试了27种LLM模型、涉及12个国家的155个主题和200种来源于实际用户对话的提示版本。研究表明，虽然较新的模型能够生成更多样化的声明，但几乎所有模型的知识认知多样性都低于基本的网络搜索。模型大小对知识认知多样性有负面影响，而检索增强生成（RAG）技术对其有正面影响，但这种改善在不同文化背景下有所差异。对比传统知识源（维基百科），研究发现针对特定国家的声明比本地语言描述更多地反映了英语，揭示了认知代表性的不足之处.", "innovation": "提出了一个新的方法来衡量认知多样性，即大型语言模型输出中的现实世界声明的多样性。这种方法被用来进行广泛的实证研究，分析大型语言模型的知识枯竭现象。研究还创新地引入了文化背景因素对RAG技术影响的考量，以及与传统知识源相比特定国家声明的英语化倾向。", "conclusion": "虽然较新的模型能够生成更多样化的声明，但几乎所有模型的知识认知多样性都低于基本的网络搜索。模型大小对知识认知多样性有负面影响，而检索增强生成（RAG）技术对其有正面影响，但这种改善在不同文化背景下有所差异。针对特定国家的声明比本地语言描述更多地反映了英语，揭示了认知代表性的不足之处。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16565", "html_url": "https://arxiv.org/abs/2510.16565", "title": "语言超越内容：追踪多语言大型语言模型中的文化理解", "title_en": "Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models", "authors": "Seungho Cho,Changgeon Ko,Eui Jun Hwang,Junmyeong Lee,Huije Lee,Jong C. Park", "background": "大型语言模型（LLMs）在多种文化背景下被广泛应用，准确的文化理解变得至关重要。以往的评估主要集中在输出层的性能，未能揭示导致不同响应背后的因素。虽然通过电路分析的研究涉及了少数语言，且很少关注文化因素。本研究旨在追踪LLMs内部的文化理解机制，通过比较在两种不同条件下答题过程中激活路径的重叠度：一是改变目标国家但保持问题语言不变；二是改变问题语言但保持国家不变。同时使用同语言国家对来区分语言和文化方面的影响。", "innovation": "本研究创新性地通过测量在两种条件下回答语义等价问题时内部激活路径的重叠度，来追踪LLMs内部的文化理解机制，特别是区分了语言和文化方面的影响。研究发现内部路径在同语言跨国家的问题上比跨语言同国家的问题重叠度更高，显示出较强的语言特定模式。值得注意的是，韩国与朝鲜这对语言相近但文化差异显著的国家表现出较低的路径重叠度和较高的变异度，表明语言相似性并不能保证内部表征的对齐。", "conclusion": "结果显示，同语言跨国家的问题的内部路径重叠度高于跨语言同国家的问题，显示出了强烈的语言特定模式。特别是韩国和朝鲜这对语言相近但文化差异显著的国家表现出低重叠度和高变异度，表明语言相似性并不能保证内部表征的对齐。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07001", "html_url": "https://arxiv.org/abs/2511.07001", "title": "SCOPE：在LLMs中减轻版权侵权的内在语义空间控制", "title_en": "SCOPE: Intrinsic Semantic Space Control for Mitigating Copyright Infringement in LLMs", "authors": "Zhenliang Zhang,Xinyu Hu,Xiaojun Wan", "background": "大型语言模型有时会无意中重现受版权保护的文字，这可能会使下游应用面临法律风险。目前大多数研究主要关注词汇层面的匹配，并依赖外部黑名单或过滤器，这增加了部署的复杂性并且可能忽略掉语义上的重复。", "innovation": "本文将版权侵权减轻重新定义为内在语义空间控制，并介绍了SCOPE，一种无需参数更新或辅助过滤器的推理时方法。具体来说，稀疏自编码器（SAE）将隐藏状态投影到高维的近单义空间；得益于这种表示，可以识别出一个版权敏感子空间并在解码期间钳位其激活。", "conclusion": "在广泛认可的标准测试集上进行的实验表明，SCOPE可以在不损害一般有用性的前提下减轻版权侵权。进一步的可解释性分析证实，隔离出的子空间捕获了高层次的语义。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.06778", "html_url": "https://arxiv.org/abs/2511.06778", "title": "SAFENLIDB：基于大规模语言模型的自然语言数据库接口的隐私保护安全对齐框架", "title_en": "SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based Natural Language Database Interfaces", "authors": "Ruiheng Liu,XiaoBing Chen,Jinyu Zhang,Qiongwen Zhang,Yu Zhang,Bailong Yang", "background": "大规模语言模型（LLMs）的迅速发展推动了自然语言数据库接口（NLIDB）的重大进步。然而，LLMs的广泛应用引发了严重的隐私和安全问题。在交互过程中，LLMs可能会无意间泄露数据库中的敏感内容，或者被攻击者操控，通过看似无害的查询窃取数据。现有的努力通常依赖于基于规则的启发式方法或LLMs代理来减轻这种信息泄露的风险，但这些方法仍然难以应对基于复杂推理的攻击，产生较高的误报率，并且常常影响SQL查询的可靠性。", "innovation": "本文提出了SafeNlidb，一种新的基于LLMs的NLIDB隐私-安全对齐框架。SafeNlidb框架包括一个自动化的工作流程，该工作流程从头开始生成混合推理链的数据，无缝结合了隐性安全推理和SQL生成。另外，引入了推理预热和交替偏好优化来克服直接偏好优化（DPO）中的多偏好振荡，使LLMs能够通过细化推理产生安全意识的SQL，而无需人类标注的偏好数据。", "conclusion": "实验结果表明，与更大规模的LLMs和理想基准相比，我们的方法在显著提高安全性的同时保持了高实用性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03295", "html_url": "https://arxiv.org/abs/2511.03295", "title": "如何使用源感知神经机器翻译度量评价语音翻译", "title_en": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics", "authors": "Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli", "background": "传统的语音识别（ST）系统的自动评估方法通常是将翻译假设与一个或多个参考翻译进行比较。这种方法虽然有效，但也继承了参考基评估方法的局限性，即忽略了源输入中的有价值信息。在机器翻译（MT）中，最近的研究表明，结合源文本的神经度量能够与人类判断更为密切地关联。然而，在将这一想法扩展到ST时却不那么简单，因为源数据是音频而非文本，可靠的转录或源和参考之间的对齐往往不可用。因此，本研究旨在进行首次系统研究，重点关注语音翻译实际应用条件下有力地利用源感知度量，尤其是在无法获得源转录的情况下。", "innovation": "研究探索了生成输入音频的文本替代品的两种互补策略：自动语音识别（ASR）转录和参考翻译的反向翻译，并引入了一种新颖的两步跨语言再分割算法，以解决合成来源与参考翻译之间的对齐不匹配问题。实验结果表明，在单词错误率低于20%的情况下，ASR转录比反向翻译更能可靠地用作合成来源，而反向翻译仍然是计算成本较低但仍有效的替代方案。此外，该跨语言再分割算法使源感知MT度量在ST评估中的使用更加稳定，为语音翻译更准确和原理性的评估方法铺平了道路。", "conclusion": "实验结果显示，当单词错误率低于20%时，ASR转录在合成来源方面更为可靠，而反向翻译虽然计算成本较低但仍是一种有效的替代方案。此外，提出的跨语言再分割算法能够使源感知MT度量在ST评估中的使用更加稳健，为语音翻译的更准确和原理性的评估方法奠定了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.06402", "html_url": "https://arxiv.org/abs/2511.06402", "title": "SugarTextNet：社交媒体中的糖爸糖妈内容检测的基于变换器的框架，结合上下文感知焦点损失", "title_en": "SugarTextNet: A Transformer-Based Framework for Detecting Sugar Dating-Related Content on Social Media with Context-Aware Focal Loss", "authors": "Lionel Z. Wang,Shihan Ben,Yulu Huang,Simeng Qin", "background": "糖爸糖妈相关的内容在主流社交媒体平台上迅速蔓延，引发社会和监管方面的重大担忧，包括亲密关系的商业化和交易性关系的正常化。由于现实世界数据中存在微妙的委婉语、模糊的语言线索以及严重的类别不平衡，检测此类内容极具挑战性。", "innovation": "本文提出了一种新颖的基于变换器的框架——SugarTextNet，专门用于社交媒体上糖爸糖妈相关内容的识别。SugarTextNet结合预训练变换器编码器、基于注意力的线索提取器和上下文语句编码器，以捕捉用户生成文本中的重要且细微特征。为解决类别不平衡并增强少数类别检测，引入了上下文感知焦点损失，这是一种结合焦点损失缩放与上下文加权的定制损失函数。", "conclusion": "在新构建的包含3067条来自新浪微博的精心注释的数据集上评估SugarTextNet，发现我们的方法在多个指标上显著优于传统机器学习模型、深度学习基线和大型语言模型。详尽的消融研究证实了每个组件不可或缺的作用。本文的结果强调了敏感内容检测中特定领域、上下文感知建模的重要性，并为复杂现实场景中的内容监控提供了稳健解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07392", "html_url": "https://arxiv.org/abs/2511.07392", "title": "基于语音指令的手术代理编排平台", "title_en": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction", "authors": "Hyeryun Park,Byung Mo Gu,Jun Hee Lee,Byeong Hyeon Choi,Sekeun Kim,Hyun Koo Kim,Kyungsang Kim", "background": "在达芬奇机器人手术过程中，外科医生的手和眼睛完全投入到操作中，使得难以在不中断的情况下访问和处理多模式患者数据。因此，需要一种解决方案来实现这一目标。", "innovation": "提出了一种基于多层次多智能体框架的语音指令手术代理编排平台（SAOP），该框架包含一个编排智能体和三个由大型语言模型驱动的任务特定智能体。这些基于LLM的智能体能够自主规划、细化、验证和推理，将语音指令转换为具体的任务，如检索临床信息、操作CT扫描或在手术视频中导航3D解剖模型。SAOP还引入了多级编排评估指标（MOEM）来从命令级别和类别级别评估其性能和鲁棒性。", "conclusion": "SAOP在240条语音指令下达到了较高的准确性和成功率，基于LLM的智能体提升了对语音识别错误和多样化或模糊自由形式命令的鲁棒性，显示出支持微创达芬奇机器人手术的强大潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07322", "html_url": "https://arxiv.org/abs/2511.07322", "title": "FinRpt: Equity Research Report Dataset, Evaluation System and LLM-based Multi-agent Framework", "title_en": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation", "authors": "Song Jin,Shuqi Li,Shukun Zhang,Rui Yan", "background": "尽管大规模语言模型（LLMs）已经在诸如股票预测和问答等金融任务中取得了巨大成功，但在完全自动化生成股权研究报告方面仍处于未探索的领域。对此，本文首次提出了股权研究报告（ERR）生成任务，并构建了一个公开数据集FinRpt和一个综合评估系统，为模型训练和评估提供了支持。同时，文章提出了一种专门为解决这一任务的多代理框架FinRpt-Gen，利用监督微调和强化学习对多个基于LLM的代理进行了训练。实验结果表明，FinRpt基准数据集的质量和评估指标的有效性，以及FinRpt-Gen的强劲性能，展示了其在股权研究报告生成领域的巨大潜力。所有代码和数据集都是公开的。", "innovation": "1. 提出了股权研究报告（ERR）生成任务并构建了一个公开数据集FinRpt。2. 设计了一个综合评估系统，包含11个评估指标。3. 提出了一种专门为股权研究报告生成任务设计的多代理框架FinRpt-Gen，采用了监督微调和强化学习进行训练。4. 提供了高质量的数据集和评估系统来支持模型训练和评估。", "conclusion": "实验结果表明，FinRpt数据集和评估指标的有效性及FinRpt-Gen的强劲性能，展示了其在股权研究报告生成领域中的巨大潜力，有望促进该领域内的创新。所有代码和数据集均为公开，可供进一步研究使用。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05784", "html_url": "https://arxiv.org/abs/2511.05784", "title": "DRAGON: 通过负检测和推理保护上下文中的LLM卸载", "title_en": "DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning", "authors": "Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu", "background": "在大型语言模型（LLMs）中，卸载（Unlearning）是保护私有数据和消除有害知识的关键。大多数现有方法依赖于微调以平衡卸载效率与通用语言能力。然而，这些方法通常需要训练或访问保留数据，这在现实世界中往往不可用。虽然当遗忘数据和保留数据都可用时，这些方法可以表现良好，但在数据受限的实际场景中很少有工作能表现出同等能力。为解决这些限制，我们提出了一种名为Detect-Reasoning Augmented GeneratiON (DRAGON) 的系统化、基于推理的框架，通过上下文中的链式思考（CoT）指令在推理前保护部署的LLMs。DRAGON 不修改基础模型，而是利用LLMs 的指令执行能力，并引入了一个轻量级的检测模块，无需任何保留数据即可识别值得遗忘的提示。这些内容随后通过一个专用的CoT 保护模型进行处理，以确保安全准确的情境干预。为了稳健地评估卸载性能，我们引入了新型的卸载性能评估标准和持续卸载场景。广泛的实验表明，DRAGON 具有强大的卸载能力、可扩展性和在实际场景中的适用性。", "innovation": "1. 引入了Detect-Reasoning Augmented GeneratiON (DRAGON) 系统化、基于推理的卸载框架。2. 提出了一种轻量级检测模块，能够在无需任何保留数据的情况下识别值得遗忘的提示。3. 通过上下文中的链式思考（CoT）指令，在推理前保护部署的LLMs。4. 引入了新的评估标准以验证DRAGON 在卸载和持续卸载场景中的有效性。", "conclusion": "DRAGON 通过上下文中的负面检测和推理显著增强了大型语言模型的卸载能力，使其能够在数据有限的实际场景中表现出强大、可扩展且适用的性能，从而保护了私有数据并消除了有害知识。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11154", "html_url": "https://arxiv.org/abs/2505.11154", "title": "MPMA: Preference Manipulation Attack Against Model Context Protocol", "title_en": "MPMA: Preference Manipulation Attack Against Model Context Protocol", "authors": "Zihan Wang,Rui Zhang,Yu Liu,Wenshu Fan,Wenbo Jiang,Qingchuan Zhao,Hongwei Li,Guowen Xu", "background": "Model Context Protocol (MCP)规范了大语言模型（LLMs）访问外部数据和工具的接口映射，这改变了工具选择的范式，并促进了LLM代理工具生态系统的快速发展。然而，随着MCP的广泛应用，第三方定制化的MCP服务器可能暴露出潜在的安全漏洞。", "innovation": "该研究首次提出了一种新颖的安全威胁——MCP偏好操纵攻击(ATURE)。它通过定制化的MCP服务器干预，使LLM优先选择该服务器，从而可能为攻击者带来经济利益。研究设计了直接偏好操纵攻击(DPMA)和基于基因的广告偏好操纵攻击(GAPMA)两种攻击方法，其中GAPMA通过基因算法增强隐蔽性。", "conclusion": "研究表明，MCP在开放生态系统中存在关键漏洞，需要快速建立有效的防御机制以确保MCP生态系统公平性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11770", "html_url": "https://arxiv.org/abs/2505.11770", "title": "内部因果机制稳健地预测语言模型的域外行为", "title_en": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors", "authors": "Jing Huang,Junyi Tao,Thomas Icard,Diyi Yang,Christopher Potts", "background": "现有研究提供了多种技术来识别神经网络中的抽象内部机制，但这些技术是否可以用于预测模型在域外样本上的行为仍是一个未知数。本研究探讨了通过上述技术预测模型域外行为的可能性。", "innovation": "本研究通过一系列不同的语言模型任务（包括符号操作、知识检索和指令遵循），提出了两种基于因果机制的方法来预测模型输出的正确性：反事实模拟（检查关键因果变量是否实现）和价值探测（利用这些变量的值进行预测）。这两种方法在分布内和分布外环境中均表现出色，并且在域外环境中优于依赖非因果特征的方法。", "conclusion": "本研究强调了内部因果分析在语言模型中的新颖且重要的应用。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.14359", "html_url": "https://arxiv.org/abs/2504.14359", "title": "在视觉语言建模中考虑跨语言感知多样性的多模态重述框架", "title_en": "A Multimodal Recaptioning Framework to Account for Perceptual Diversity Across Languages in Vision-Language Modeling", "authors": "Kyle Buettner,Jacob T. Emmerson,Adriana Kovashka", "background": "在为图像添加说明时，人们会以多种方式描述物体，包括使用不同的词汇或包含对其感知特别重要的细节。描述可能在不同语言和文化中有很大的独特性。现代视觉-语言模型（VLMs）通常通过机器翻译的英语说明进行训练来理解不同语言的文本，但这个过程依赖于来自英语使用者视角的输入内容，导致感知偏见。", "innovation": "本工作提出了一种框架来解决这一偏见，使用少量的母语使用者数据、最近邻示例指导和多模态大语言模型推理，以更好的反映目标语言中的描述。将由此产生的重写添加到多语言CLIP微调中，在德语和日语文本-图像检索案例研究中表现出显著提高（最高+3.5点平均召回，+4.4点在母语错误与翻译错误方面的改进）。该研究还提出了一个机制来理解不同语言中物体描述的变化，并提供了跨数据集和跨语言泛化的见解。", "conclusion": "通过这个框架，它可以改善视觉语言模型的跨语言文本-图像检索性能，增强对不同语言中物体描述多样性的理解，并为未来的模型训练提供新的视角。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.17352", "html_url": "https://arxiv.org/abs/2503.17352", "title": "OpenVLThinker: 迭代SFT-RL周期实现复杂的视觉语言推理", "title_en": "OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL Cycles", "authors": "Yihe Deng,Hritik Bansal,Fan Yin,Nanyun Peng,Wei Wang,Kai-Wei Chang", "background": "目前，文本推理模型（如Deepseek R1）在纯文本任务中表现出色，但将这些推理注入大型视觉语言模型（LVLMs）时，通常通过监督微调（SFT）会导致性能下降，因为视觉定位不够精确。纯粹使用强化学习（RL）的方法则面临搜索空间巨大的问题，这使得小型模型（如7B规模的LVLMs）难以发展出反映性行为。本研究通过交替使用SFT和RL训练策略，在几次迭代后取得了显著的性能提升。研究表明，初始基模型很少表现出推理行为，但SFT有效地促进了这些潜在行为的显现，并缩小了RL的搜索范围，促进了推理能力的发展。每个后续的RL阶段进一步提高了模型的推理技能，从而提高了SFT数据的质量，使其在自我改善方面更具优势。OpenVLThinker-7B在六个需要数学和一般推理能力的基准测试中稳步提高了性能，分别在MathVista上提高了3.8%，EMMA提高了2.4%，HallusionBench提高了1.6%。", "innovation": "本研究引入了OpenVLThinker，一种开放源代码的大型视觉语言模型，能够展示复杂的链式推理能力。通过交替使用SFT和RL的训练策略，该模型在几次迭代后取得了显著的性能提升。研究发现，这种训练策略有效地促进了模型的推理能力发展，并提供了实现R1级别推理在多模态环境下的初步证据。", "conclusion": "OpenVLThinker-7B在六个需要数学和一般推理能力的基准测试中共取得了持续的性能提升，特别是在MathVista、EMMA和HallusionBench上有了显著改进。该研究证明了SFT与RL在复杂推理任务中的协同作用，并提供了实现机制的初步证据。相关代码、模型和数据均公开提供。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09205", "html_url": "https://arxiv.org/abs/2503.09205", "title": "质量优先于数量？基于LLM的数据高效音频-视频基础模型的资料筛选", "title_en": "Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model", "authors": "Ali Vosoughi,Dimitra Emmanouilidou,Hannes Gamper", "background": "目前，将音频和视觉数据整合以训练多模态基础模型仍然是一项挑战。因此，提出了音频-视频向量对齐（AVVA）框架，该框架不仅超越了简单的时序同步来考虑AV场景对齐，而且还利用大型语言模型（LLMs）进行数据筛选。通过引入一种评分机制来选择对齐的训练数据片段，并结合Whisper（一种基于语音的基础模型）与DINOv2（用于视频分析的模型），构建了一个双重编码器结构，并在此基础上应用对比学习，改善了音频-视频对齐效果。该研究在AudioCaps、VALOR和VGGSound等数据集上进行了评估，证明了所提出模型架构和数据筛选方法的有效性。使用仅192小时的高质量筛选数据，AVVA在视频到音频检索的top-k准确性方面超越了DenseAV模型。进一步的实验证明，数据筛选过程可以使数据质量与数据量之间的权衡更加有效，并在AudioCaps、VALOR和VGGSound数据集上达到了更高的top-k检索准确率，这优于在全范围未经筛选数据上的训练效果", "innovation": "提出的AVVA框架通过引入一种评分机制和双重编码器结构，不仅超越了简单的时序同步来考虑AV场景对齐，还利用大型语言模型进行数据筛选。利用Whisper和DINOv2进行音频和视频分析，结合对比学习。这种创新的方法不仅显著提高了多模态数据处理的效果，还有效解决了数据量与数据质量之间的权衡问题", "conclusion": "研究表明，AVVA框架通过精心筛选和利用高质量的192小时训练数据，在音频-视频对齐和检索中表现尤为出色，相较于全量未经筛选的数据，不仅更加高效，而且在所有使用的数据集上都取得了显著提升。同时，实验证明了数据筛选过程的有效性，能够更有效地在数据质量与数据量之间进行权衡，提高检索准确率"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01365", "html_url": "https://arxiv.org/abs/2508.01365", "title": "ConfGuard: 一种简单有效的大型语言模型后门检测方法", "title_en": "ConfGuard: A Simple and Effective Backdoor Detection for Large Language Models", "authors": "Zihan Wang,Rui Zhang,Hongwei Li,Wenshu Fan,Wenbo Jiang,Qingchuan Zhao,Guowen Xu", "background": "后门攻击对大型语言模型（LLMs）构成了重大威胁，攻击者可以通过嵌入隐藏触发器来操控LLM的输出。现有的大多数防御方法主要针对分类任务设计，对于LLMs自回归特性和庞大输出空间的攻击效果不佳，导致性能低下和高延迟。", "innovation": "研究发现，后门模型与正常模型在输出空间的行为存在差异，并提出了一种称为序列锁定的现象。基于这一发现，提出了一种轻量级且有效的检测方法ConfGuard，通过监测滑动窗口中的标记置信度来识别序列锁定。实验证明，ConfGuard在绝大多数情况下达到了近乎100%的真阳性率（TPR）和极低的假阳性率（FPR），并且接近实时检测，几乎不增加额外的延迟，因此成为了实际部署中实用的LLM后门防御方法。", "conclusion": "通过ConfGuard，实现了对于LLMs后门攻击的高效检测和几乎无延迟的响应，显著提升了大规模语言模型的防御能力。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01182", "html_url": "https://arxiv.org/abs/2509.01182", "title": "Question-to-Knowledge (Q2K): 多智能体生成可检验事实的产品映射", "title_en": "Question-to-Knowledge (Q2K): Multi-Agent Generation of Inspectable Facts for Product Mapping", "authors": "Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee", "background": "在电子商务中，识别两个产品列表是否代表相同的库存保持单元（SKU）一直是持续的挑战，尤其是在缺少明确标识符和产品名称在不同平台上差异显著的情况下。基于规则的启发式和关键词相似性经常由于忽视品牌、规格或捆绑配置中的微妙区别而导致产品误分类。", "innovation": "提出了一种基于大规模语言模型（LLMs）的多智能体框架——Question to Knowledge (Q2K)，用于可靠地进行SKU映射。Q2K集成了：（1）推理智能体，生成针对性的去混淆问题；（2）知识智能体，通过聚焦网络搜索解决这些问题；（3）去重智能体，利用验证过的推理痕迹减少冗余并确保一致性。通过循环机制进一步细化不确定情况。实验结果表明，Q2K在现实消费品数据集上超越了强基线，特别是在捆绑识别和品牌来源去混淆等难题场景中表现更为优越。通过重复利用检索到的推理而非重复搜索，Q2K实现了准确性与效率之间的平衡，提供了一个可扩展且具有解释性的产品集成解决方案。", "conclusion": "Q2K通过重复利用检索到的推理而不是重复搜索，平衡了准确性与效率，提供了一个可扩展且可解释的产品集成解决方案，该方法在实际的消费品数据集上表现出了优越的鲁棒性和准确性。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22340", "html_url": "https://arxiv.org/abs/2510.22340", "title": "DynaSolidGeo: 一种用于三维几何领域多模态数学推理的动态基准", "title_en": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "authors": "Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen", "background": "三维几何问题解决需要结合空间智能和符号推理的空间数学推理能力。现有的大多数多模态数学推理基准主要关注二维平面几何，并依赖静态且易受数据污染和记忆影响的数据集，仅通过最终答案来评估模型，忽略了推理过程。", "innovation": "我们提出了DynaSolidGeo，这是一个动态基准，用于评估视觉-语言模型（VLMs）在三维几何中的真正的空间推理能力。通过半自动注解管道构建，DynaSolidGeo包含503个专家挑选的问题种子，理论上可以生成大量的多模态图文实例。我们不仅考虑答案准确性，还将过程评估引入基于专家注解的推理链，以衡量逻辑有效性和因果连贯性。", "conclusion": "实验结果显示，在代表性的开源和专有模型中存在显著的性能差距，在动态设定中表现严重下降，特别是在需要高级空间智能的任务（如心理旋转和可视化）中表现较差。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08576", "html_url": "https://arxiv.org/abs/2510.08576", "title": "大型语言模型在机器辅助解决用户意图中的比较分析", "title_en": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "authors": "Justus Flerlage,Alexander Acker,Odej Kao", "background": "大语言模型（LLMs）已成为自然语言理解和用户意图解析的关键工具，能够执行翻译、总结等任务，并越来越多地用于复杂工作流的编排。这标志着从传统的图形用户界面（GUI）驱动的用户界面向以语言为主导的交互模式转变。用户可以通过自然语言来表达目标，以便LLMs在跨多个应用程序中动态和情境化地运行操作，并且现有的实现方式往往依赖于云上的专有模型，这在隐私、自主权和可扩展性方面带来了局限。出于对该交互方式成为强大且可信的接口必要性的考虑，本地部署的开源可访问的LLMs成为未来基于意图的操作系统的基石组件显得尤为重要。", "innovation": "本研究探讨了几种开源和开放访问的LLMs如何通过机器辅助解决用户意图的能力，并对OpenAI的专有GPT-4系统进行了比较分析，评估了在各种用户意图生成工作流方面的性能。该研究提供了开源LLMs在下一代操作系统中作为自主本地操作组件的实用可行性和性能权衡的实际见解，从而推动了对AI基础设施去中心化和民主化进程的更广泛讨论，并指出了一种未来趋势：通过本地嵌入的智能使得用户设备交互变得更加无缝、适应性和隐私保护。", "conclusion": "本研究的结果为更广泛的讨论提供了实证洞察，涉及AI基础设施的去中心化和民主化，指出了未来的方向：通过本地嵌入的智能，用户与设备的交互将变得更加无缝、适应性和隐私保护。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.27176", "html_url": "https://arxiv.org/abs/2510.27176", "title": "Glia: 一种启发于人类的自动化系统设计与优化的人工智能", "title_en": "Glia: A Human-Inspired AI for Automated Systems Design and Optimization", "authors": "Pouya Hamadanian,Pantea Karimi,Arash Nasr-Esfahany,Kimia Noorbakhsh,Joseph Chandler,Ali ParandehGheibi,Mohammad Alizadeh,Hari Balakrishnan", "background": "本文探讨了人工智能是否能够自主设计与人类专家相当的计算机系统机制。背景讨论了现有的机器学习方法在系统设计中的局限性和改进空间，强调了需要一种能够生成可解释设计并公开推理过程的方法，以应对复杂系统的问题.", "innovation": "创新之处在于提出了Glia架构，这是一种使用大型语言模型（LLMs）的网络化系统设计人工智能。Glia采用类人类多代理工作流程，每个代理专注于推理、试验和分析，合作通过评估框架来将抽象推理与实际反馈结合。与先前的针对系统优化的机器学习方法不同，Glia生成可解释的设计，并公开其推理过程。当应用于分布式GPU集群的LLM推理时，它生成了新的请求路由、调度和自动扩展算法，这些算法在时间上远低于人类专家的水平，同时提供了关于工作负载行为的新颖见解。结果表明，通过将推理LLMs与结构化实验结合，人工智能可以生产出复杂系统问题的创新且易于理解的设计.", "conclusion": "本文结果表明，结合推理LLMs与结构化实验，人工智能可以对人体专家水平的复杂系统设计问题提供创造性且易于理解的解决方案，这为自动化系统设计和优化领域开辟了新的研究方向和应用潜力."}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.06065", "html_url": "https://arxiv.org/abs/2511.06065", "title": "ScRPO: 从错误到见解", "title_en": "ScRPO: From Errors to Insights", "authors": "Lianrui Li,Dakuan Lu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "论文背景在于大型语言模型在解决复杂的数学问题时常常会遇到困难，传统的强化学习方法可能不足以解决这些问题。为了解决这些问题，提出了一种新的强化学习框架，通过利用自我反思和错误纠正来提升大语言模型在难题上的表现。", "innovation": "创新点在于提出了一种名为Self-correction Relative Policy Optimization (ScRPO)的新框架。该框架包括两个阶段：第一阶段是试错学习阶段，模型通过GRPO被训练，收集错误的答案及其对应的题目，放入错误池；第二阶段是自我纠正学习阶段，引导模型反思其先前答案错误的原因。实验结果表明ScRPO在多个数学推理基准测试中取得了更好的表现。", "conclusion": "研究结果表明ScRPO能够在有限外部反馈条件下，促进语言模型自我提升，并在复杂任务上表现出色。这为打造更可靠和高效的AI系统铺平了道路。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04106", "html_url": "https://arxiv.org/abs/2511.04106", "title": "在线新词和名字的亚指数增长：分段幂律模型", "title_en": "Sub-exponential Growth of New Words and Names Online: A Piecewise Power-Law Model", "authors": "Hayafumi Watanabe", "background": "传统的社会传播模式通常使用S形曲线进行描述，如逻辑斯谛曲线。然而，在复杂的社会现象中，亚指数增长，即比指数增长更慢的模式，往往被忽略。本文使用分段幂律模型来描述具有复杂增长曲线的社会传播模式。", "innovation": "作者提出了一种分段幂律模型来描述可以由少量参数描述的复杂增长曲线。通过对大量数据集（包括大约一亿篇与维基百科词汇链接的日语博客文章）的系统分析，以及对英语、西班牙语和日语的网络搜索趋势数据的观察，作者发现亚指数增长是社会传播的常见模式。他们发现在单一段落曲线中，形状参数α的中值接近0.5，表明亚指数增长非常常见。α还显示了与主题性质相关的倾向，接触到更广泛的主题时α更大，而接触到特定或地方性主题时α更小。这些我发现偏好向外传播的交流方式。", "conclusion": "亚指数增长是社会传播的常见模式。分段幂律模型为描述、比较和解释复杂多样的增长曲线提供了实用框架。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME: 计划和检索集成记忆以增强推理", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "受《思考，快与慢》中的人类认知二元过程理论启发，本文提出了一种多agent推理框架，该框架动态地整合了快速直观思维（System 1）和详细深思熟虑思维（System 2），旨在提高推理效率和准确性。在此之前的研究或理论已经探索了类似的方法，但本文通过具体的agent设计和多层次的功能管道实现了对人类认知过程的模拟，并证明了在需要多跳和知识导向推理的基准测试上能够与最先进的闭源模型（如GPT-4和GPT-4o）竞争，从而提高了开源大语言模型（LLM）的性能，特别是在需要复杂知识密集型推理的领域中。", "innovation": "本文的创新点在于设计了一个多agent推理框架，它模拟了人类认知过程中的快速和慢速思维。首先使用快速思考代理（System 1）生成快速答案，如果检测到不确定性，再触发一个结构化的System 2推理管道，该管道包含专门的代理进行计划、假设生成、检索、信息整合和决策制定。此外，它使用开源模型LLaMA 3，通过实验证明了PRIME框架在复杂的、知识密集型推理任务中能够与最先进的闭源模型竞争。", "conclusion": "本文的实验结果表明，PRIME框架可以增强开源大语言模型的性能，使其在需要多跳和知识导向推理的基准测试中能够与最先进的闭源模型竞争。这一研究证明了PRIME对于改善需要复杂知识密集型推理的领域中的LLM的广泛适用性和潜力，为未来的研究提供了基础。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.02109", "html_url": "https://arxiv.org/abs/2511.02109", "title": "Deep Value Benchmark: 测量模型是否推断深层价值观或浅层偏好", "title_en": "Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences", "authors": "Joshua Ashkinaze,Hua Shen,Sai Avula,Eric Gilbert,Ceren Budak", "background": "当前的大型语言模型（LLMs）可能学会的是人类的基本价值观，而不仅仅是表面偏好。这种区分对于AI对齐至关重要：捕捉深层次价值观的系统更有可能稳健地推断人类意图，而仅捕捉偏好数据中浅层模式的系统则可能导致对齐不当的行为。因此，需要一个直接测试LLMs是否学习了深层的人类价值观的评估框架，即Deep Value Benchmark (DVB)。DVB利用新颖的实验设计来控制深层次价值观（如道德原则）和浅层特征（如表面属性）之间的混淆。", "innovation": "DVB采用了一种创新的实验设计，通过控制深层次价值观和浅层特征之间的关系来测试模型的深层价值泛化能力。在训练阶段，向LLMs展示故意相关深层次和浅层特征的人类偏好数据。在测试阶段，拆开这些关联，提供基于深层次和浅层特征的区别选择，从而精确衡量模型的深层价值泛化率（DVGR）。实验证明，大多数模型在深层价值观上的泛化能力低于随机猜测，且大模型的DVGR稍微低于小模型。这一成果提供了衡量对齐核心特征的可解释指标。", "conclusion": "9种不同模型的平均DVGR仅为0.30，所有模型在深层价值上的泛化能力均低于随机猜测。更大型的模型略低于较小的模型。该研究公布了受到三次独立的人类验证实验的数据集。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.00810", "html_url": "https://arxiv.org/abs/2511.00810", "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "title_en": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "authors": "Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang", "background": "图形用户界面（GUI）接地是计算机使用代理的关键功能之一，它将自然语言指令映射到可操作的屏幕区域。现有的基于多模态大型语言模型（MLLMs）的方法通常将其形式化为基于文本的坐标生成任务，但直接从视觉输入生成精确坐标仍然是一个具有挑战性且计算密集的过程。为了实现直观的GUI接地，一种方法是先选择与指令相关的视觉片段，然后在这些片段内确定精确的点击位置。鉴于通用MLLMs在注意力机制中有天生的定位能力，作者提出了一种基于注意力且无需坐标的监督微调框架GUI-AIMA，用于高效的GUI接地。", "innovation": "GUI-AIMA通过将MLLMs的内在多模态注意力与片段级别的接地信号对齐，设计了一种基于注意力且无需坐标的监督微调框架。这些信号通过简化查询-视觉注意力矩阵的多头聚合，适应性地计算出适用于不同用户指令的接地信息。此外，其无需坐标的方式便于集成一个插拔式放大部分阶段。通过仅使用85,000张截图训练的GUI-AIMA-3B模型，展示了出色的数据效率，并验证了轻量化训练可以触发MLLMs的天生定位能力。该模型在ScreenSpot-Pro、OSWorld-G和ScreenSpot-v2上的平均准确率分别达到了59.6%、63.8%和91.5%，均达到了同类模型中的顶尖水平。", "conclusion": "总的来说，该研究设计并提出了GUI-AIMA，一种无需坐标的监督微调框架，通过将MLLMs的内在注意力机制与片段级别的接地信号对齐，高效实现了GUI接地，展示了良好的性能和数据效率。"}
{"llm_update_time": "20251113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.06209", "html_url": "https://arxiv.org/abs/2511.06209", "title": "自信推理：通过不确定性头部高效验证大型语言模型推理步骤", "title_en": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads", "authors": "Jingwei Ni,Ekaterina Fadeeva,Tianyi Wu,Mubashara Akhtar,Jiaheng Zhang,Elliott Ash,Markus Leippold,Timothy Baldwin,See-Kiong Ng,Artem Shelmanov,Mrinmaya Sachan", "background": "解决复杂任务通常需要大型语言模型（LLM）生成长多步骤推理链。以往研究表明，验证单个推理步骤的正确性可以进一步提高LLM在这些任务上的性能和效率，并增强解决方案的解释性。然而，现有的验证方法，如过程奖励模型（PRMs），要么计算成本高，要么局限于特定领域，或需要大量的人工或模型生成的注释。因此，本文提出了一种基于数据驱动不确定性得分的轻量级替代方案，用于推理步骤的验证。", "innovation": "该研究提出了通过不确定性头部（UHeads）来自动高效的验证LLM推理步骤的新方法。UHeads使用冻结后的LLM的内部状态来估计其生成推理步骤的不确定性。UHeads不仅有效而且轻量级，参数量不足10M，在多个领域（包括数学、规划和一般知识问答）中，其性能与大小最多可达到810倍的PRMs相当甚至更好。这表明LLM的内部状态包含其不确定性，可以作为可靠的信号用于推理验证，为构建可扩展且具有普遍适用性的反思性LLM提供了新的方向。", "conclusion": "LLM的内部状态能够表征其不确定性，并可作为可靠的信号用于推理验证，这为构建可扩展且具有普遍适用性的反思性LLM提供了潜在的发展方向。UHeads方法能够高效验证LLM的推理步骤，且模型轻量且参数精简，适用于多种任务领域。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07438", "html_url": "https://arxiv.org/abs/2511.07438", "title": "两个数据集比一个更好：cryo-EM中的双矩方法用于三维重建", "title_en": "Two Datasets Are Better Than One: Method of Double Moments for 3-D Reconstruction in Cryo-EM", "authors": "Joe Kileel,Oscar Mickelin,Amit Singer,Sheng Xu", "background": "cryo-EM是一种通过从随机方向的粒子的噪声透射投影图像中重建三维分子结构的强大成像技术。传统的重构方法通常依赖于单一的定向分布下的投影图像的数据，但这种方法可能会受到噪声和未知定向分布的影响，限制了结构重建的准确性。", "innovation": "提出了一种新的数据融合框架，名为双矩法（MoDM），能够利用两种不同定向分布下的第二阶矩投影图像实例来重建分子结构。这一方法证明了通过结合两个迥异的数据集，即使其中一个定向分布未知，也能够唯一确定分子结构，并通过凸松弛算法准确地实现重构。", "conclusion": "本研究展示了集合并基于多样实验条件模型数据集的明显优势，这在计算成像任务中增强重建质量方面具有显著效果。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07429", "html_url": "https://arxiv.org/abs/2511.07429", "title": "通过LLMs进行可解释视频异常检测的知识引导文本推理", "title_en": "Knowledge-Guided Textual Reasoning for Explainable Video Anomaly Detection via LLMs", "authors": "Hari Lee", "background": "当前存在的弱监督视频异常检测模型（WSVAD）依赖于显式的视觉特征进行异常检测，但这些模型的解释性较差。本文提出了Text-based Explainable Video Anomaly Detection (TbVAD)框架，这是一种语言驱动的方法，能够在纯文本领域进行异常检测和解释。TbVAD框架通过将视频内容转换为细粒度的文本描述，并通过四类语义槽进行组织，继而生成每类语义槽的解释，指出导致异常决策的主要语义因素。这种方法相比传统方法更能提供有解释性的异常检测结果，适用于实际监控场景。", "innovation": "TbVAD框架提出了一个新的方法，通过语言描述和组织视频的语义，而不是依赖视觉特征，从而实现完全在文本域内的异常检测与解释。特别地，TbVAD框架的特征提取和解释方法均基于语言模型，可以进行结构化的知识组织，并生成有效的解释。这种方法在解释性和准确性方面具有优势，能够提高实际监控场景中的应用效果", "conclusion": "在UCF-Crime和XD-Violence两个公共基准上评估了TbVAD模型，研究结果表明，基于文本的知识推理能够提供解释性好且可靠的异常检测结果，适用于实际的监控场景。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07496", "html_url": "https://arxiv.org/abs/2511.07496", "title": "在缓解扩散模型中的幻觉现象中利用评分函数梯度锐化", "title_en": "Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models", "authors": "Barath Chandran.C,Srinivas Anumasa,Dianbo Liu", "background": "扩散模型虽然取得了成功，但常会产生幻觉，即生成不连贯或不现实的样本。此现象被认为与评分插值和评分平滑有关，但缺乏防止生成幻觉的方法。", "innovation": "提出了一种后处理评分函数调整方法，在推断过程中利用评分的梯度（或锐度）来减少无关扩散模型在1D、2D和高维图像数据上的模式插值幻觉。利用有限差分变体的Hutchinson迹估计器，为高维情况高效估算梯度锐度。实验表明，此纠正方法显著降低了各种分布和高维图像数据集中的幻觉频率。此外，分析了评分的梯度锐度与评分不确定性的关系。", "conclusion": "此方法通过利用评分函数的梯度锐度有效地减少了扩散模型中的幻觉现象，潜在提高了生成样本的质量和连贯性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07499", "html_url": "https://arxiv.org/abs/2511.07499", "title": "通过对抗Sinkhorn注意力引导实现可靠的扩散采样前沿技术", "title_en": "Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance", "authors": "Kwanyoung Kim", "background": "扩散模型在使用诸如无分类引导（CFG）等引导方法时，已经展示了强大的生成性能，这些方法通过修改采样轨迹来提升输出质量。然而，这些方法通常会对目标输出进行降级处理，往往影响无条件输出，同时使用的手动设计的扰动函数缺乏理论基础。", "innovation": "本文提出了一种新颖的方法——对抗Sinkhorn注意力引导（ASAG），通过在最优传输的角度下重解释扩散模型中的注意力得分，并通过Sinkhorn算法故意扰乱传输成本。与直接破坏注意力机制不同，ASAG在自注意力层中注入对抗成本，以降低查询和键之间的像素相似度。这种方法的故意退化减轻了误导性的注意力对齐，提高了条件和无条件样本的质量。该方法在文本到图像扩散中表现出了一致的改进，并增强了下游应用如IP-Adapter和ControlNet的可控性和保真度，并且该方法轻量级、即插即用，且无需任何模型重训练。", "conclusion": "ASAG方法在文本到图像的扩散过程中表现出一致的改进，并增强了IP-Adapter和ControlNet等下游应用的可控性和保真度。该方法轻量级、即插即用，并提高了可靠性，无需进行任何模型重训练。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07479", "html_url": "https://arxiv.org/abs/2511.07479", "title": "基于选择性时空视觉变换器的模数视频恢复", "title_en": "Modulo Video Recovery via Selective Spatiotemporal Vision Transformer", "authors": "Tianyu Geng,Feng Ji,Wee Peng Tay", "background": "传统的图像传感器动态范围有限，在高动态范围(HDR)场景中会导致饱和。模数相机通过将入射辐照度折叠到限定范围内来解决这一问题，但需要专门的解包算法来重构底层信号。与扩展传统采样动态范围的HDR恢复不同，模数恢复可以恢复从折叠样本实际值。尽管早在十多年前就提出了模数图像恢复，但由于现代深度学习技术的应用较慢，进步较为缓慢。现有的标准HDR方法不适合用于模数恢复。我们发现，虽然 transformer 可以捕捉解决问题所需的全局依赖关系和时空关系，但适应现有的 transformer 架构以实现模数恢复需要新方法与技术。", "innovation": "我们提出了一种新的深度学习框架，即选择性时空视觉变换器（SSViT），用于模数视频重建。SSViT 中采用了令牌选择策略，提高了效率并集中关注最关键的区域。实验结果表明，SSViT 能够从折叠的8位视频中产生高质量的重建结果，实现了模数视频恢复的最先进的性能。", "conclusion": "现有标准HDR方法不适合用于模数恢复，但我们展示了一种基于选择性时空视觉变换器（SSViT）的方法，该方法能够利用transformer模型的有效特性进行模数视频重建，并且通过实验验证了其优越性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07624", "html_url": "https://arxiv.org/abs/2511.07624", "title": "TrackStudio：一种集成的无标记追踪工具包", "title_en": "TrackStudio: An Integrated Toolkit for Markerless Tracking", "authors": "Hristo Dimitrov,Giulia Dominijanni,Viktorija Pavalkyte,Tamar R. Makin", "background": "在过去的十年中，无标记运动追踪技术取得了快速的发展，提供了行为学、临床学和生物力学研究的强大机会。虽然一些专门的工具包能够为特定任务提供高性能，但使用这些工具仍然需要大量的技术专长。无标记追踪领域缺乏一种适用于非专家的集成解决方案，能够提供高质量的数据追踪。", "innovation": "TrackStudio 通过将现有的开源工具综合到一个模块化图形用户界面的流水线中，以解决这一问题。它提供了无需编程技能即可实现自动2D和3D跟踪、校准、预处理、特征提取和可视化等功能。我们还提供了实用的用户指南以及常见的陷阱和避险建议，以指导视频获取、同步和设置。", "conclusion": "通过在三种环境中测试其性能，包括使用低成本网络摄像头或高分辨率摄像头以及具有挑战性的身体位置、照明、空间障碍等条件，TrackStudio 显示出稳定的性能。与手部追踪扩展到身体和其他面部区域的结果进一步证明了其可扩展性。TrackStudio 为需要可靠性能但无需专门技术的研究人员或普通用户提供了一条实际的通路。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07710", "html_url": "https://arxiv.org/abs/2511.07710", "title": "通过粒度感知和区域不确定性建模实现跨模态细粒度对齐", "title_en": "Cross Modal Fine-grained Alignment via Granularity-aware and Region-uncertain Modeling", "authors": "Jiale Liu,Haoming Zhou,Yishu Zhu,Bingzhi Chen,Yuncheng Jiang", "background": "细粒度的图像-文本对齐是多模态学习中的关键挑战，支撑着视觉问答、图像字幕和视觉语言导航等应用。现有方法存在两个基本局限性：缺乏稳健的跨模态注意力机制来评估视觉和文本令牌的重要性，导致在复杂场景中的泛化能力较差；以及缺乏细粒度的不确定性建模，无法捕捉区域-词汇对应关系的多对一或多对多性质。", "innovation": "本文提出了一种统一的方法，结合了意义感知、粒度感知建模和区域级别的不确定性模型。该方法利用模态特定的偏差来识别显著特征，而无需依赖脆弱的跨模态注意力，并将区域特征表示为高斯分布混合模型，以捕捉细粒度的不确定性。实验结果表明，该方法在各种骨干架构下的性能达到了最新水平，显著增强了细粒度图像-文本对齐的稳健性和可解释性。", "conclusion": "通过引入粒度感知和区域不确定性建模，本文的方法在细粒度图像-文本对齐中实现了显著改进，展现了更好的稳健性和可解释性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07552", "html_url": "https://arxiv.org/abs/2511.07552", "title": "LiveNeRF：通过神经辐射场集成的实时面部替换", "title_en": "LiveNeRF: Efficient Face Replacement Through Neural Radiance Fields Integration", "authors": "Tung Vu,Hai Nguyen,Cong Tran", "background": "面部替换技术在娱乐、教育和交流应用中取得了显著进展，包括配音、虚拟化身和跨文化内容适应。然而，现有的方法存在实时性能不足和视觉质量欠佳的问题，限制了其在直播、视频会议和互动媒体中的实际应用。此外，虽然面部替换技术可以为内容创作者、教育者和语言障碍人士带来便利，但其滥用可能引发未经授权的合成内容制作风险。", "innovation": "提出了LiveNeRF框架，解决了现有方法的局限性，实现了33 FPS的实时性能并保持了更高的视觉质量，适用于直播、视频会议和互动媒体的实际部署。该技术特别有助于内容创作者、教育者和语言障碍人士通过无障碍化身沟通，同时倡导负责任的部署方式，包括用户同意验证和与检测系统的集成，以确保积极的社会影响并减轻风险，从而有助于防止滥用行为，促进正面的社会效果。", "conclusion": "LiveNeRF框架通过利用神经辐射场技术，成功实现了高实时性的面部替换，不仅提升了用户体验，还增强了技术的安全性和可靠性，确保了其广泛的实际应用潜力，同时强调了其应在伦理和安全的前提下进行推广和应用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07695", "html_url": "https://arxiv.org/abs/2511.07695", "title": "基于非对比心脏CT图像使用深度学习预测冠状动脉钙化严重程度", "title_en": "Predicting Coronary Artery Calcium Severity based on Non-Contrast Cardiac CT images using Deep Learning", "authors": "Lachlan Nguyen,Aidan Cousins,Arcot Sowmya,Hugh Dixson,Sonit Singh", "background": "心血管疾病是全球导致高死亡率的主要原因之一。冠状动脉钙化评分（CAC）是一种强大的工具，用于对粥样硬化性心血管疾病的风险进行分类。目前的评分方法需要放射科医生和经过培训的技术人员进行耗时的半自动心脏计算机断层扫描分析。因此，本研究旨在开发一种基于深度学习卷积神经网络（CNN）模型，以根据非对比心脏CT图像分类钙化分数为六个临床类别之一。", "innovation": "该研究利用深度学习卷积神经网络模型，实现了非对比心脏CT图像中冠状动脉钙化评分的自动化分类，能够准确分类为六个临床类别，展示了良好的一致性（Kappa系数为0.962）和高整体准确率（96.5%）。此外，该模型对于测试数据有良好的可移植性，输出结果与现有的半自动实践一致，验证了CNN模型在钙化评分分类中的可行性。", "conclusion": "研究结果表明，该模型输出准确且与当前半自动做法一致，具有广泛应用的可能性。该研究证明了使用深度学习将钙化分数分类为扩展的六个临床类别的可行性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07743", "html_url": "https://arxiv.org/abs/2511.07743", "title": "UltraGS: 超声波高斯聚类法用于新型视图合成", "title_en": "UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis", "authors": "Yuezhe Yang,Wenjie Cai,Dexin Yang,Yufang Dong,Xingbo Dong,Zhe Jin", "background": "超声成像在临床诊断中是一种无创的关键技术，但由于其视场有限，影响了新型视图的合成。本文讨论了这一背景并提出了优化的高斯聚类法（UltraGS）来应对这一挑战。", "innovation": "UltraGS 引入了深度感知的高斯聚类策略，每条高斯曲线都有可学习的视场，使其能够准确预测深度并精确地表示结构。此外，还设计了结合低阶球面谐波与特定超声波物理现象（如深度衰减、反射和散射）的轻量级渲染函数 SH-DARS，以准确模拟组织强度。最后，还贡献了一个包含多样解剖学扫描数据的临床超声检查基准数据集。", "conclusion": "在三个数据集上的广泛实验表明，UltraGS 能达到 PSNR 最高 29.55，SSIM 最高 0.89，MSE 最低 0.002 的最佳结果，并能够在 64.69 fps 的速度下实现实时合成。所有代码和数据集均公开可获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07696", "html_url": "https://arxiv.org/abs/2511.07696", "title": "FlowFeat: 像素密集的运动轮廓嵌入", "title_en": "FlowFeat: Pixel-Dense Embedding of Motion Profiles", "authors": "Nikita Araslanov,Anna Sonnweber,Daniel Cremers", "background": "密集且多功能的图像表示是几乎所有计算机视觉应用成功的关键。然而，最先进的网络，如变压器，产出低分辨率特征网格，对于密集预测任务来说是次优的。为了解决这一局限性，我们提出了FlowFeat，一种高分辨率和多任务特征表示。这种高分辨率和多任务特征表示的关键在于一种新的蒸馏技术，该技术嵌入了一种可能的表观运动分布，即运动配置文件。通过利用光学流网络和多样化的视频数据，我们开发了一种有效的自监督训练框架，能够统计地近似表观运动。FlowFeat在高分辨率上提供了丰富的几何和语义线索，同时具有高度的时间一致性。", "innovation": "FlowFeat的关键创新在于一种新的蒸馏技术，通过使用可能的表观运动分布，提供了一种高分辨率的特征表示方法。利用光学流网络和多样的视频数据，我们开发了一种有效的自监督训练框架，能够统计地近似表观运动。这种方法在空间细节和时间一致性方面表现出了显著的优势，从而增强了包括视频对象分割、单目深度估计和语义分割在内的三种密集任务中最先进的编码器的表现力和鲁棒性。训练FlowFeat计算成本低，并且对于不准确的光学流估计具有鲁棒性，即使使用无监督的光学流网络，也能保持其高效性。", "conclusion": "我们的工作朝着可靠且多功能的密集图像表示迈出了重要一步。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07748", "html_url": "https://arxiv.org/abs/2511.07748", "title": "Auto-US：利用视频分类框架和大语言模型的超声视频诊断代理", "title_en": "Auto-US: An Ultrasound Video Diagnosis Agent Using Video Classification Framework and LLMs", "authors": "Yuezhe Yang,Yiyue Guo,Wenjie Cai,Qingqing Ruan,Siying Wang,Xingbo Dong,Zhe Jin,Yong Dai", "background": "人工智能辅助超声视频诊断为提高医学影像分析的效率和准确性带来了新机遇。然而，现有研究在数据集多样性、诊断性能和临床适用性方面仍有限制。", "innovation": "提出了Auto-US，这是一种利用超声视频数据及其临床诊断文本的智能诊断代理。构建了涵盖五个类别和三种器官的495个超声视频的CUV数据集，并开发了CTU-Net分类模型，该模型在超声视频分类中达到了86.73％的准确率。此外，通过集成大型语言模型，Auto-US能够生成具有临床意义的诊断建议。每个病例的最终诊断评分均超过3分，并得到了专业临床医生的验证。", "conclusion": "这些结果表明，Auto-US在实际应用中超声诊断的有效性和临床潜力。代码和数据可在相应链接获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07744", "html_url": "https://arxiv.org/abs/2511.07744", "title": "VectorSynth：具有结构化语义的精细化卫星图像合成", "title_en": "VectorSynth: Fine-Grained Satellite Image Synthesis with Structured Semantics", "authors": "Daniel Cher,Brian Wei,Srikumar Sastry,Nathan Jacobs", "background": "随着地理信息系统和遥感技术的发展，精确像素级卫星图像的合成日益重要。现有模型多依赖于文本或布局条件，但在图像与语义矢量几何之间学习密集的多模态对应关系方面存在不足。因此，亟需一种能够精细地进行空间定位和语义对齐的卫星图像合成方法。", "innovation": "VectorSynth框架利用了基于扩散的机制，在像素级精准合成卫星图像的同时，通过语义矢量几何进行条件约束，从而实现精细的空间和语义对齐。视觉语言对齐模块产生像素级嵌入，指导条件图像生成框架遵守空间边界和语义提示。该方法支持结合语言提示与几何感知条件的交互式工作流程，能够快速进行假设检验、空间编辑和基于地图的内容生成。通过构建包含卫星场景及其像素对齐的矢量标注的多样化数据集，训练并展示了强于现有方法的语义保真度和结构现实度。", "conclusion": "VectorSynth在语义保真度和结构现实度方面取得了显著改进，并证明其训练的视觉语言模型具备细粒度的空间定位能力。提供代码和数据供研究人员参考。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07755", "html_url": "https://arxiv.org/abs/2511.07755", "title": "Filtered-ViT: 针对多重 adversarial 贴图攻击的鲁棒防御", "title_en": "Filtered-ViT: A Robust Defense Against Multiple Adversarial Patch Attacks", "authors": "Aja Khanal,Ahmed Faid,Apurva Narayan", "background": "深度学习视觉系统在医疗等关键领域越来越广泛地应用，但这些系统仍然容易受到小的对抗性补丁的攻击，这些补丁可以触发错误分类。现有的大多数防御措施假设单一补丁存在，但当出现多个局部干扰时则失效，这正是攻击者和现实世界干扰所利用的类型。", "innovation": "本文提出了一种新颖的视觉转换器架构——Filtered-ViT，它结合了SMART Vector Median Filtering（SMART-VMF），这是一种空间自适应、多尺度且具备鲁棒性的机制，能够选择性地抑制受损区域同时保持语义细节。Filtered-ViT 在 ImageNet 上对 LaVAN 多个补丁攻击的表现优于现有防御措施。", "conclusion": "本文证明了 Filtered-ViT 是第一个可以同时抵御对抗性和自然出现的类似补丁干扰的变压器模型，展示了其在真正高风险环境中的可靠视觉系统潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07749", "html_url": "https://arxiv.org/abs/2511.07749", "title": "通过原型导向校准和双重对齐蒸馏实现类增量医学图像分割", "title_en": "Class Incremental Medical Image Segmentation via Prototype-Guided Calibration and Dual-Aligned Distillation", "authors": "Shengqian Zhu,Chengrong Yu,Qiang Wang,Ying Song,Guangjun Li,Jiafei Wu,Xiaogang Xu,Zhang Yi,Junjie Hu", "background": "类增量医学图像分割（CIMIS）旨在保留先前学习类别的知识，同时学习新的类别而无需依赖旧类别的标签。现有方法要么使用一刀切策略，处理所有空间区域和特征通道平等，这可能妨碍准确旧知识的保留；要么仅关注旧类别的局部原型与全局原型对齐，而忽视新数据中的局部表示，导致知识退化。", "innovation": "本文提出原型导向校准蒸馏（PGCD）和双重对齐原型蒸馏（DAPD）以解决上述问题。PGCD通过原型与特征的相似性来校准不同空间区域的分类特异性蒸馏强度，有效地强化可靠旧知识并抑制来自旧类别的误导信息。DAPD则将当前模型中提取的旧类别局部原型与全局原型和局部原型进行对齐，进一步提高旧类别的分割性能。", "conclusion": "全面评估在两个广泛使用的多器官分割基准上展示了本方法在性能上的优势，突显了其鲁棒性和泛化能力，超越了现有最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07756", "html_url": "https://arxiv.org/abs/2511.07756", "title": "超越随机性：理解扩散模型中的噪声秩序", "title_en": "Beyond Randomness: Understand the Order of the Noise in Diffusion", "authors": "Song Yan,Min Li,Bi Xinliang,Jian Yang,Yusen Zhang,Guanye Xiong,Yunwei Lan,Tao Zhang,Wei Zhai,Zheng-Jun Zha", "background": "在文本驱动的内容生成(T2C)的扩散模型中，生成内容的语义主要归因于文本嵌入和注意力机制的互动。初始生成过程中的噪声通常被认为是一种随机元素，为生成内容的多样性贡献，而该论文指出，这种噪声之下存在可分析的模式，挑战了这一传统观点，揭示了噪声不仅包含丰富的语义信息，而且可以极其简单地基于信息论通过数据清理去除不需要的语义。", "innovation": "本文从三个方面展现了创新：一，对噪声影响的全面分析；二，通过信息论解析观察结果；三，提出一种无需训练的通用两步“语义擦除-注入”过程，用于调控T2C扩散模型中初始噪声。这种方法有效且高效地优化了生成模型的内容生成，为一致生成提供了一个新的视角和工具。", "conclusion": "基于DiT和UNet架构的T2C扩散模型验证了该方法的有效性，并为优化扩散模型生成提供了新的思路。这种方法具有普适性，适用于不同T2C模型，展示了提升内容生成质量的新途径。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07798", "html_url": "https://arxiv.org/abs/2511.07798", "title": "Divide-and-Conquer Decoupled Network for Cross-Domain Few-Shot Segmentation", "title_en": "Divide-and-Conquer Decoupled Network for Cross-Domain Few-Shot Segmentation", "authors": "Runmin Cong,Anpeng Wang,Bin Wan,Cong Zhang,Xiaofei Zhou,Wei Zhang", "background": "Cross-domain few-shot segmentation (CD-FSS) is aimed at recognizing novel classes and adapting to unseen domains with limited annotations. However, encoder features often entangle domain-relevant and category-relevant information, limiting both generalization and rapid adaptation to new domains.", "innovation": "提出了一种名为Divide-and-Conquer Decoupled Network (DCDNet)的网络结构，设计了Adversarial-Contrastive Feature Decomposition (ACFD)模块，通过对比学习和对抗学习将骨干特征解耦为类别相关的私有表示和领域相关的共享表示。进一步，Matrix-Guided Dynamic Fusion (MGDF)模块在空间指引下动态集成基、共享和私有的特征，保持结构一致性。此外，提出了Cross-Adaptive Modulation (CAM)模块，在微调阶段引导私有特征通过调制，确保有效的领域相关信息集成，从而增强模型的泛化能力。", "conclusion": "在四个具有挑战性的数据集上的广泛实验表明，DCDNet 在跨域泛化和少量样本适应性方面优于现有的 CD-FSS 方法，为跨域泛化和少量样本适应性设定了新的状态最先进水平。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07780", "html_url": "https://arxiv.org/abs/2511.07780", "title": "语义一致的双向对比哈希方法及其在噪声多标签跨模态检索中的应用", "title_en": "Semantic-Consistent Bidirectional Contrastive Hashing for Noisy Multi-Label Cross-Modal Retrieval", "authors": "Likang Peng,Chao Su,Wenyuan Wu,Yuan Sun,Dezhong Peng,Xi Peng,Xu Wang", "background": "跨模态哈希（CMH）通过将数据编码为紧凑的二进制表示来促进不同模态（例如，图像和文本）之间的高效检索。尽管最近的方法取得了显著的性能，但它们通常依赖于完全注释的数据集，而此类数据集获取成本高昂且劳动密集。在实际场景中，特别是在多标签数据集中，标签噪声普遍存在并严重影响检索性能。此外，现有的CMH方法往往忽视了多标签数据中固有的部分语义重叠，限制了其稳定性和泛化能力", "innovation": "为解决上述挑战，我们提出了一种新的框架，名为语义一致的双向对比哈希（SCBCH）。框架包含两个互补模块：（1）跨模态语义一致分类（CSCC），利用跨模态语义一致性估计样本可靠性并减少噪声标签的影响；（2）双向软对比哈希（BSCH），基于多标签语义重叠动态生成软对比样本对，启用跨模态语义相似和不同样本之间的自适应对比学习。我们通过四个广泛应用的跨模态检索基准实验验证了该方法的有效性和鲁棒性，一致地在噪声多标签条件下优于现有最先进技术", "conclusion": "我们的方法在四个广泛使用的跨模态检索基准上进行了广泛实验，验证了其有效性和鲁棒性，并且在噪声多标签条件下持续优于最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07801", "html_url": "https://arxiv.org/abs/2511.07801", "title": "学习稀疏标签耦合以进行多标签胸部X线诊断", "title_en": "Learning Sparse Label Couplings for Multilabel Chest X-Ray Diagnosis", "authors": "Utkarsh Prakash Srivastava,Kaushik Gupta,Kaushik Nath", "background": "本文研究了胸部X射线的多标签分类，提出了一种基于SE-ResNeXt101（32×4d）的简单但强大的管道。这种方法的骨干网络通过细调针对14种胸部发现进行了优化，并使用带有Sigmoid头的Multilabel Iterative Stratification (MIS)进行训练，以确保具有鲁棒性交叉验证分割且保留标签共现。该研究针对极端的类别不平衡和不对称的错误成本进行了优化。", "innovation": "提出了一种轻量级的Label-Graph Refinement模块，它在分类器之后放置，通过学习一个稀疏且可训练的跨标签耦合矩阵，仅通过单步消息传递操作即可精炼逻辑，而仅增加带L1正则化的参数头部。此外，该研究还优化了Asymmetric Loss，在训练中使用了混合精度（AMP）、余弦学习率衰减、预热、梯度剪裁和权重的指数移动平均（EMA）。", "conclusion": "研究表明，强大的SE-ResNeXt101基线在我们的数据集上达到了有竞争力的宏AUC（例如，在我们的运行中达到92.64%）。添加Label-Graph Refinement一致地提高了各个分割的验证宏AUC，且几乎不增加计算成本。结果的方法是可再现的、硬件友好的，并不需要额外的标注，提供了一种实际的途径以增强多标签胸部X射线分类器。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07806", "html_url": "https://arxiv.org/abs/2511.07806", "title": "PC-Diffusion：通过偏好分类器将扩散模型与人类偏好对齐", "title_en": "PC-Diffusion: Aligning Diffusion Models with Human Preferences via Preference Classifier", "authors": "Shaomeng Wang,He Wang,Xiaolu Wei,Longquan Dai,Jinhui Tang", "background": "扩散模型在条件图像生成方面取得了显著成功，但其输出往往与人类偏好不相符。最近的研究将直接偏好优化（DPO）应用于扩散模型，取得了显著改进，但仍存在两个关键问题：1）计算成本高，因为涉及整个模型的微调；2）对参考模型质量敏感，容易引入不稳定性和偏差。为解决这些问题，本文提出了一种名为PC-Diffusion的新框架，该框架通过一个轻量级、可训练的偏好分类器直接建模样本之间的相对偏好来对齐人类偏好。", "innovation": "本文提出了一种新型框架PC-Diffusion，通过一个轻量级、可训练的偏好分类器来直接建模样本之间的相对偏好以对齐人类偏好。通过将偏好学习限制在这个分类器中，PC-Diffusion将偏好对齐与生成模型分离开来，消除了整个模型的微调和依赖参考模型的需要。此外，本文还提供了对PC-Diffusion的理论保证，包括确保偏好引导分布的一致性传播、通过偏好分类器的训练目标等效于DPO但不需参考模型以及提出的偏好引导修正可以逐步引导生成向偏好对齐区域移动等。", "conclusion": "实验结果表明，PC-Diffusion在保持与DPO相当的偏好一致性的同时，显著降低了训练成本，实现了高效和稳定的偏好引导生成。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07808", "html_url": "https://arxiv.org/abs/2511.07808", "title": "DI3CL：具有动态实例和边界一致性对比学习的SAR土地覆盖分类基础模型", "title_en": "DI3CL: Contrastive Learning With Dynamic Instances and Contour Consistency for SAR Land-Cover Classification Foundation Model", "authors": "Zhongle Ren,Hui Ding,Kai Wang,Biao Hou,Xingyu Luo,Weibin Li,Licheng Jiao", "background": "尽管在SAR土地覆盖分类方面已经取得了显著进展，但近年来的方法仍然主要集中在监督学习上，这依赖于大量的标签数据集。这种依赖不仅限制了可扩展性和泛化能力，还限制了对多种应用场景的适应性。因此，开发一种通用的基础模型对于加速各种下游模型的开发和部署至关重要。本文构建了一个针对SAR土地覆盖分类的通用基础模型，作为加速开发和部署各种下游模型的坚实基础。", "innovation": "本文提出了一个动态实例和轮廓一致性对比学习（DI3CL）预训练框架，该框架结合了动态实例（DI）模块和轮廓一致性（CC）模块。DI模块通过在不同视角的同一区域中强制局部一致性来增强全局上下文意识。CC模块利用浅特征图引导模型关注SAR土地覆盖对象的几何轮廓，从而提高结构区分能力。此外，为了提高预训练阶段的鲁棒性和泛化能力，构建了一个包含460,532张SAR图像的大规模多样数据集SARSense，以使模型能够捕获全面和代表性特征。", "conclusion": "本文提出的DI3CL在多种SAR土地覆盖分类任务中表现出色，并且优于现有方法。为了验证基础模型的泛化能力，我们进行了广泛的实验，包括SAR土地覆盖制图、水体检测和道路提取。拟提交的代码和预训练权重可在以下链接获取：this https URL."}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07813", "html_url": "https://arxiv.org/abs/2511.07813", "title": "Sparse3DPR：基于稀疏RGB视图的无训练3D分层场景解析与任务自适应子图推理", "title_en": "Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views", "authors": "Haida Feng,Hao Wei,Zewen Xu,Haolin Wang,Chade Li,Yihong Wu", "background": "近年来，大型语言模型（LLMs）在3D场景理解方面得到了广泛探索。其中，无训练方法因其灵活性和对训练方法的泛化能力而受到关注，但它们在实际部署中的准确性和效率通常较差。", "innovation": "提出了Sparse3DPR，这是一种新型的无训练框架，用于开放场景理解，利用预训练LLMs的推理能力，只需要稀疏视图的RGB输入。引入了一种层次化的平面增强场景图，支持开放词汇表，并采用主导的平面结构作为空间锚点，这使得推理链更加清晰，高阶推理更具可靠性。此外，设计了一种任务自适应子图提取方法，动态过滤查询无关信息，减少上下文噪声，提高3D场景推理的效率和准确性。", "conclusion": "实验结果显示，Sparse3DPR相比ConceptGraphs在Space3D-Bench上精度提高了28.7%，速度快了78.2%。在ScanQA上，Sparse3DPR的表现与训练方法相当，额外的真实世界实验也证明了其鲁棒性和泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07812", "html_url": "https://arxiv.org/abs/2511.07812", "title": "基于多模态大型语言模型的图像质量评估：错误与修正", "title_en": "Revisiting MLLM Based Image Quality Assessment: Errors and Remedy", "authors": "Zhenchen Tang,Songlin Yang,Bo Peng,Zichuan Wang,Jing Dong", "background": "多模态大型语言模型（MLLMs）的快速发展提高了图像质量评估（IQA）任务的水平。但MMLMs的离散标记输出与IQA任务所需连续的质量评分之间存在固有的不匹配，这一差距显著阻碍了基于MMLMs的IQA方法的性能。先前将离散标记预测转换为连续评分的方法常常遭受转换误差。此外，级别标记（如“好”）引入的语义混淆进一步限制了MMLMs在IQA任务中的性能，并降低了它们在相关任务中的原始能力。", "innovation": "论文通过对先前方法中的错误进行了理论分析，提出了一种轻量级回归模块和IQA专用分数标记整合的框架，称为Q-Scorer。该框架将分担了轻量级回归模块和IQA专用的分数标记集成到MMLMs的管道中，实验证明Q-Scorer在多个IQA基准上达到了最先进的性能，并且能够很好地泛化到混合数据集，还能与其他方法结合进一步提高性能。", "conclusion": "Q-Scorer框架在多模态大型语言模型中的应用显著提高了图像质量评估的性能。通过轻量级回归模块和IQA专用的分数标记的结合使用，Q-Scorer有效解决了之前方法中的转换错误和语义混淆问题，展示了优秀的泛化能力和与其他方法结合后的协同效应。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07816", "html_url": "https://arxiv.org/abs/2511.07816", "title": "Cancer-Net PCa-MultiSeg: 使用合成相关扩散成像多模态增强前列腺癌病变分割", "title_en": "Cancer-Net PCa-MultiSeg: Multimodal Enhancement of Prostate Cancer Lesion Segmentation Using Synthetic Correlated Diffusion Imaging", "authors": "Jarett Dewbury,Chi-en Amy Tai,Alexander Wong", "background": "目前的深度学习方法在前列腺癌病灶分割方面表现有限，使用大量的患者数据时，Dice分数通常低于0.32。为了应对这一局限性，研究探讨了合成相关扩散成像（CDI$^s$）在标准扩散成像协议上的增强效果。", "innovation": "研究在CDI$^s$的基础上对六种最新的分割架构进行了全面评估，使用了200名患者的校准CDI$^s$、扩散加权成像（DWI）和表观扩散系数（ADC）序列。结果显示，CDI$^s$的集成能在94%的评估配置中可靠地提高或保持分割性能，个别架构在与基线模态相比时达到了72.5%的统计学显著性相对改善。CDI$^s$ + DWI被视为最安全的增强路径，五分之一的评估架构均获得显著改进，无退化现象出现。", "conclusion": "由于CDI$^s$源自现有的DWI扫描，不需要额外的扫描时间和架构修改，它即能适用于临床工作流程。本研究为CDI$^s$作为前列腺癌病灶分割任务的实用集成增强措施正确定义了路径，该增强可适用于各类深度学习架构。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07819", "html_url": "https://arxiv.org/abs/2511.07819", "title": "3D场景中通过统一场景语义占据空间的人体运动合成", "title_en": "Human Motion Synthesis in 3D Scenes via Unified Scene Semantic Occupancy", "authors": "Gong Jingyu,Tong Kunkun,Chen Zhuoran,Yuan Chuanhan,Chen Mingang,Zhang Zhizhong,Tan Xin,Xie Yuan", "background": "在3D场景中生成人类运动需要理解场景，但当前方法主要关注场景结构，而忽视了语义理解。本文通过提出一种新的框架，即SSOMotion，结合统一场景语义占据空间，来解决这一问题。SSOMotion框架通过双向三平面分解来推导出紧凑的SSO版本，并通过CLIP编码和共享线性降维将场景语义映射到统一特征空间，实现了细粒度的场景语义结构并显著减少了冗余计算。此外，通过帧级场景查询，这些场景线索和从指令推导出的动作方向用于运动控制，提高了合成效果。", "innovation": "提出了一种名为SSOMotion的新框架，该框架采用统一场景语义占据空间的方法，通过双向三平面分解和CLIP编码来推导紧凑的场景表示，并利用共享线性降维技术将场景语义映射到统一的空间。同时，该框架通过帧级场景查询和动作指令来控制运动，提高了生成效果并验证了其在复杂场景中的性能和通用性。", "conclusion": "本文在复杂场景中的实验和消融研究中展现了其前沿性能，并证实了其有效性和推广能力。代码将在公开可用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07823", "html_url": "https://arxiv.org/abs/2511.07823", "title": "CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis", "title_en": "CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis", "authors": "Kanglin Qu,Pan Gao,Qun Dai,Zhanzhi Ye,Rui Ye,Yuanhao Sun", "background": "Mamba因能够进行长范围建模以及具有线性复杂度的特性，在点云分析中受到了广泛关注。尽管在某些方面取得了进步，相关研究仍然存在点云序列化不完善、高阶几何感知能力不足以及Mamba核心的可选择状态空间模型(S6)过拟合的问题。", "innovation": "提出了基于SSM的点云网络CloudMamba，用于解决上述挑战。具体包括：1) 序列扩展和序列合并，通过分别沿每个轴序列化点，并在不同序列中因果推断对应的高阶特征进行融合，使无序点集能够更好地适应Mamba的因果性质。2) 设计了连锁Mamba，将并行双向Mamba的正向和反向过程串联起来，在扫描过程中捕捉高阶几何信息。3) 提出了分组选择性状态空间模型(GS6)，通过在S6模型中共享参数来缓解由于计算模式引起的过拟合问题。", "conclusion": "在多种点云任务上的实验验证了CloudMamba的性能，在显著减少复杂度的情况下达到了最先进的结果。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07862", "html_url": "https://arxiv.org/abs/2511.07862", "title": "MonoCLUE：对象感知聚类增强单目3D目标检测", "title_en": "MonoCLUE : Object-Aware Clustering Enhances Monocular 3D Object Detection", "authors": "Sunghun Yang,Minhyeok Lee,Jungho Lee,Sangyoun Lee", "background": "单目3D物体检测为自主驾驶提供了一种低成本的解决方案，但受到深度不良和有限视场的困扰。这些限制导致几何线索不足和在被遮挡或截断场景中具备较低的准确性。虽然最近的方法通过引入额外的深度信息来解决几何不确定性，但它们忽视了对于鲁棒识别至关重要的视觉线索。", "innovation": "提出了MonoCLUE，该方法通过结合局部聚类和通用场景记忆来增强单目3D检测。首先，对视觉特征进行K-means聚类以捕捉不同的物体级外观部分（例如，发动机盖、车顶），提高部分可见物体的检测能力。然后，通过跨图像聚集聚类特征构建通用场景记忆，提供一致且通用的表示形式。最后，将局部聚类特征和通用场景记忆集成到对象查询中，引导注意力到信息丰富的区域。MonoCLUE通过统一的局部聚类和通用场景记忆策略，在被遮挡和有限可视场景下实现了鲁棒的单目3D检测，并在KITTI基准上达到了最佳性能。", "conclusion": "MonoCLUE能够在遮挡和有限可视场景下实现鲁棒的单目3D检测，通过结合局部聚类和通用场景记忆，提高了单目3D检测的稳定性和准确性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07928", "html_url": "https://arxiv.org/abs/2511.07928", "title": "使用立体视觉的无人机图像基于路径规划算法", "title_en": "An Image-Based Path Planning Algorithm Using a UAV Equipped with Stereo Vision", "authors": "Selim Ahmet Iz,Mustafa Unel", "background": "二维图像无法区分地面上的坑洞和丘陵，地形深度对计算的安全路径有很大影响。传统的路径规划算法，如A*和概率路网算法（PRM），存在局限性。", "innovation": "提出了利用无人机搭载的立体视觉生成地形视差图的图像基于路径规划算法。该方法用于自动生成初始和目标点，并通过边缘、线和角检测以及立体深度重建技术，定义路径候选节点。此方法对比了经典算法在模拟和真实环境中的表现。", "conclusion": "实验结果表明，所提出的方法在虚拟场景和实验室环境中表现出明显的优越性，证明了其有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07916", "html_url": "https://arxiv.org/abs/2511.07916", "title": "图像上幂律变换用于文本极性检测的理论分析", "title_en": "Theoretical Analysis of Power-law Transformation on Images for Text Polarity Detection", "authors": "Narendra Singh Yadav,Pavan Kumar Perepu", "background": "许多计算机视觉应用，如车牌识别、验证码识别、图像中的手写或印刷字符识别、文本极性检测和二值化等任务都需要对图像进行预处理。在任何图像分析之前，必须将其转换为简单的二值图像。这个二值化过程依赖于图像中文本相对于背景的对比度，即文本比背景亮（深色文本在亮背景上）或反之亦然。文献中有一种直观的方法基于原始图像上的幂律变换。该方法通过观察变换图像的直方图统计特性展示了有趣的现象。通过将文本和背景视为两个类别，作者发现，当文本在亮背景上且比背景暗（或在暗背景上且比背景亮）时，两个类别的最大间类方差是增加的（减少的）。", "innovation": "本文提供了一个关于上述现象的理论分析，进一步深入理解了幂律变换在检测文本极性方面的作用和背后的数学原理。作者通过数学模型和理论分析，解释了为什么在不同的文本极性背景下，文本和背景之间的最大间类方差的变化规律。", "conclusion": "研究表明，通过对文本和背景的数学建模，可以更好地理解和预测图像中不同类别之间的对比度变化，从而为文本极性检测提供更准确的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07923", "html_url": "https://arxiv.org/abs/2511.07923", "title": "探索无需额外训练的水下世界分割", "title_en": "Exploring the Underwater World Segmentation without Extra Training", "authors": "Bingyu Li,Tao Huo,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "海洋生物的准确分割对于生物多样性和生态评估至关重要，但现有的数据集和模型大多局限于陆地场景。因此，为了弥合这一差距，作者引入了AquaOV255数据集，这是第一个大规模和细粒度的水下分割数据集，包含255个类别和超过20,000张图片，涵盖了开放词汇评估所需的多种类别。此外，作者还结合AquaOV255和其他五个水下数据集建立了首个水下开放词汇分割基准UOVSBench，以实现全面评估。", "innovation": "作者提出了名为‘Earth2Ocean’的训练无监督的开放词汇分割框架，该框架可以将陆地视觉语言模型（VLMs）直接转移到水下领域而无需任何额外的水下训练。Earth2Ocean包括两个核心组件：几何引导视觉掩码生成器（GMG）和类别视觉语义对齐（CSA）模块。GMG通过自相似几何先验来细化局部结构感知，而CSA模块通过多模态大型语言模型推理和场景感知模板构建来增强文本嵌入。在UOVSBench基准上的大量实验表明，Earth2Ocean在平均性能上取得了显著提升，同时保持了高效的推理能力。", "conclusion": "通过构建AquaOV255数据集和UOVSBench基准，并提出Earth2Ocean框架，作者为水下开放词汇分割领域提供了重要的进展和创新方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07889", "html_url": "https://arxiv.org/abs/2511.07889", "title": "在层次自回归过程中的草图生成以在草图绘制过程中实现灵活的笔画级草图编辑", "title_en": "Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level", "authors": "Sicong Zang,Shuhui Gao,Zhijun Fang", "background": "生成具有特定模式的草图，例如以受控方式操作草图，是一个流行的任务。最近的研究通过编辑笔画嵌入的值作为条件，在笔画级控制草图特征。然而，为了给生成器提供一个关于要绘制的草图的全局视图，所有这些编辑的条件必须在生成过程开始前被收集并输入生成器中，这意味着生成过程中不允许进一步操作。为了更灵活地实现草图绘制操作，我们提出了一个层次自回归的草图生成过程。该过程不是一次性生成整个草图，而是将每条笔画生成分为三个阶段：1) 预测笔画嵌入以确定将要绘制的笔画；2) 在画布上定位预测的笔画；3) 将嵌入转换为一系列绘制动作以构成完整的草图。此外，预测、定位和转换过程是自回归进行的，即不仅考虑最近生成的笔画及其位置来预测当前笔画，还引导模型生成适合在草图中适当位置的笔画以促进整个草图的生成。通过调整暴露的可编辑笔画嵌入，可以在生成过程中随时修改笔画级的草图绘制操作。", "innovation": "该论文提出了一个层次自回归草图生成过程，允许在绘制过程中灵活地控制笔画级别的编辑。这种方法通过三个阶段逐步生成每条笔画：首先是预测哪种笔画将被绘制，接着在画布上定位预测的笔画，然后将其转换为一系列绘制动作以形成完整的草图。所有这些步骤都是自回归进行的，即每个步骤都考虑最近生成的笔画及其位置来预测当前笔画，从而引导模型生成适合在适当位置的笔画，以利于整个草图的生成。这种方法使得在生成过程中可以随时修改笔画级别的草图编辑操作。", "conclusion": "通过这个层次自回归草图生成过程，生成器能够获得关于即将绘制的草图的全局视图，并允许在绘制过程中进行灵活的笔画级编辑。这不仅提高了生成草图的灵活性，还增强了生成过程的可控性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07925", "html_url": "https://arxiv.org/abs/2511.07925", "title": "HD$^2$-SSC: High-Dimension High-Density Semantic Scene Completion for Autonomous Driving", "title_en": "HD$^2$-SSC: High-Dimension High-Density Semantic Scene Completion for Autonomous Driving", "authors": "Zhiwen Yang,Yuxin Peng", "background": "相机基于的3D语义场景补全（SSC）在自动驾驶中发挥着关键作用，它能够使3D场景的理解更为精确，从而实现有效的场景感知和决策。现有的SSC方法虽然在提高3D场景表示方面显示出有效性，但也存在固有的输入输出维度差距和标注实际情况密度差距的问题。输入的2D图像计划视图由于稀疏的标注标签导致对真实世界的密集占用空间预测不佳。因此，本文提出了相应的高维高密度语义场景补全（HD$^2$-SSC）框架，旨在解决这些问题", "innovation": "本文提出了名为HD$^2$-SSC的框架，包含高维语义解耦模块和高密度占位精化模块。高维语义解耦模块设计了扩展2D图像特征的伪第三维度，解耦粗略像素语义和遮挡，同时识别具有精细语义的关键区域，以丰富图像特征。高密度占位精化模块采用“检测—精化”架构，利用上下文几何和语义结构对缺失 voxel 的补全及错误 voxel 的修正进行增强语义密度", "conclusion": "在SemanticKITTI和SSCBench-KITTI-360数据集上的大量实验和分析验证了HD$^2$-SSC框架的有效性"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07929", "html_url": "https://arxiv.org/abs/2511.07929", "title": "资源高效异质医学图像分类的联邦CLIP", "title_en": "Federated CLIP for Resource-Efficient Heterogeneous Medical Image Classification", "authors": "Yihang Wu,Ahmad Chaddad", "background": "尽管深度模型在医学成像中表现出色，但它们仍需要源数据进行训练，这在隐私问题上限制了它们的潜力。联邦学习（FL）作为一种分散式学习框架，通过多个医院（又称FL客户端）训练共享模型，提供了一个可能的解决方案，但数据异质性和资源成本阻碍了FL模型的部署，特别是在使用视觉语言模型（VLM）时。该研究旨在应对这些挑战并提出了一种基于CLIP的联邦医学图像分类方法（FedMedCLIP）", "innovation": "为了应对上述挑战，该研究提出了一种新颖的基于CLIP的联邦学习方法（FedMedCLIP），引入了一个屏蔽特征适应模块（FAM）作为通信模块以降低通信负载，同时冻结CLIP编码器以减少计算开销。还提出了一种屏蔽多层感知器（MLP）作为私有局部分类器来适应客户端任务。此外，设计了一种自适应Kullback-Leibler（KL）散度正则化方法，以使FAM和MLP之间实现互学习。最后，通过模型压缩传输FAM参数，使用集成预测进行分类。在四个公开可用的医学数据集上进行的大量实验表明，该模型在资源成本合理的情况下提供了可行的性能（例如，ISIC2019的第二最好基线相比提高8%），并且速度比联邦AVG快120倍", "conclusion": "该研究表明，FedMedCLIP在资源效率和性能之间取得了良好的平衡，为异质医学图像分类的联邦学习提供了有效解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07877", "html_url": "https://arxiv.org/abs/2511.07877", "title": "Visual Bridge: Universal Visual Perception Representations Generating", "title_en": "Visual Bridge: Universal Visual Perception Representations Generating", "authors": "Yilin Gao,Shuguang Dou,Junzhou Li,Zhiheng Yu,Yin Li,Dongsheng Jiang,Shugong Xu", "background": "近年来，扩散模型在诸如文本到图像生成、深度估计和光流等孤立的计算机视觉任务中取得了显著的成功。然而，这些模型通常受限于‘单任务单模型’的范式，严重限制了它们在多任务场景中的泛化能力和可扩展性。鉴于大型语言模型在跨域一般化方面的技术，本文提出了一种基于流动匹配的通用视觉感知框架，旨在生成跨多个任务的多样化视觉表示。该方法将过程定义为从图像补丁令牌到任务特定表示的通用流动匹配问题，而非独立的生成或回归问题。通过利用强大的自监督基础模型作为锚定，并引入多尺度圆环任务嵌入机制，该方法学习一个通用的流动场，以弥合异构任务之间的差距，支持高效和灵活的表示转换。广泛的实验结果表明，该模型在分类、检测、分割、深度估计和图像文本检索等任务中，以零样本和微调两种设置实现了竞争性的性能，优于之前的通才模型和多种专业模型。进一步的消融研究表明，该框架具有鲁棒性、可扩展性和泛化能力。这项工作标志着通用视觉感知的一个重要进步，为未来通用视觉建模研究提供了坚实的基础。", "innovation": "本文提出了基于流域匹配的通用视觉感知框架（Visual Bridge），该框架可以生成跨多个任务的多样化视觉表示。该方法将过程定义为从图像补丁令牌到任务特定表示的通用流动匹配问题，而非独立的生成或回归问题。通过引入多尺度圆环任务嵌入机制和一个强大的自监督基础模型作为锚定，该方法能够学习一个通用的流动场，以弥合异构任务之间的差距，支持高效和灵活的表示转换。这种方法能够提高模型在多任务场景中的泛化能力和可扩展性，推广了扩散模型的应用范围。广泛实验结果表明，该模型在分类、检测、分割、深度估计和图像文本检索等任务中表现出色，优于之前的模型。进一步的消融研究表明，该框架具有鲁棒性、可扩展性和泛化能力。", "conclusion": "本文方法在通用视觉感知方面取得了显著进步，为未来通用视觉建模研究提供了坚实基础。该方法不仅在零样本和微调设置表现出竞争性的性能，还在多个视觉任务中超过了许多通用和专业模型。进一步的消融研究表明，该框架具有出色的鲁棒性、可扩展性和泛化能力，标志着通用视觉感知的一个重要进步。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07934", "html_url": "https://arxiv.org/abs/2511.07934", "title": "Laytrol: 保留多模态扩散变换器中布局控制的预训练知识", "title_en": "Laytrol: Preserving Pretrained Knowledge in Layout Control for Multimodal Diffusion Transformers", "authors": "Sida Huang,Siqi Huang,Ping Luo,Hongyuan Zhang", "background": "随着扩散模型的发展，文本生成图像的空间可控性已成为关键挑战。布局到图像生成作为一种应对这种挑战的代表任务，旨在生成与给定布局条件空间一致的图像。现有方法通常通过将适配器模块集成到基础生成模型中引入布局条件，但生成的图像常显得视觉质量低且与基础模型在风格上不一致，这表明预训练知识有所损失。为了缓解这一问题，作者构建了一个Layout Synthesis (LaySyn) 数据集，利用基础模型自身合成的图像来减轻预训练数据分布的偏移。此外，作者提出了Layout Control (Laytrol) 网络，在保持基础模型预训练知识的同时，通过特定初始化方案激活复制的参数并避免不稳定控制条件的干扰。为此，布局编码器被初始化为一个纯文本编码器，以确保其输出标记保持在MM-DiT的数据域内，同时布局控制网络的输出被初始化为零。此外，作者还应用了对象级旋转位置嵌入到布局标记中，以提供粗略的位置信息。", "innovation": "提出了Layout Control (Laytrol) 网络以保持多模态扩散变换器中的预训练知识，该网络通过特定初始化方案激活复制的参数，并避免不稳定控制条件的干扰。布局编码器被初始化为一个纯文本编码器以确保其输出标记保持在数据域内，而布局控制网络的输出被初始化为零。另外，应用了对象级旋转位置嵌入到布局标记中，以提供粗略的位置信息。这些措施提高了生成图像的质量和风格一致性。", "conclusion": "定性和定量实验验证了该方法的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07935", "html_url": "https://arxiv.org/abs/2511.07935", "title": "DiffRegCD：具有扩散特征的集成注册与变化检测", "title_en": "DiffRegCD: Integrated Registration and Change Detection with Diffusion Features", "authors": "Seyedehnanita Madani,Rama Chellappa,Vishal M. Patel", "background": "在计算机视觉和遥感中，变化检测（CD）是基本的支撑技术，应用范围涵盖环境监测、灾害响应和城市开发等多个领域。现有大多数变化检测模型基于共注册输入，但在实际应用中，由于存在视角差异和长时间间隔，图像之间的对齐会出现严重偏差。传统的两阶段方法（先注册后检测）以及最近的联合框架（如BiFA和ChangeRD）在处理大位移时表现不佳，依赖于回归转换、全局仿射变换或合成扰动。", "innovation": "本文提出了一个集成框架DiffRegCD，该框架将密集配准和变化检测统一在一个模型中。DiffRegCD将配准过程重新定义为一个经过高斯平滑的分类任务，以实现亚像素级的高精度并确保模型的训练稳定。通过利用预训练的去噪扩散模型中的冻结多尺度特征，该方法增强了解照度和视角变化的鲁棒性。此外，DiffRegCD通过控制仿射扰动在标准变化检测数据集上提供了标准的监督信号，产生了配对的真实标签，用于流动和变化检测，避免了伪标签的使用。", "conclusion": "通过大量实验验证，DiffRegCD 在多个空中（LEVIR-CD、DSIFN-CD、WHU-CD、SYSU-CD）和地面（VL-CMU-CD）数据集上均表现出色，尤其是在广泛的时间和几何变化情况下仍然保持稳定可靠的性能。这证明了扩散特征及分类法为基础的对应关系在统一的变化检测任务中具有坚实的基础。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07940", "html_url": "https://arxiv.org/abs/2511.07940", "title": "个人化的面部生成真的是需要处理和拟合几分钟长度的参考视频吗？", "title_en": "Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?", "authors": "Rui-Qing Sun,Ang Li,Zhijing Wu,Tian Lan,Qianyu Lu,Xingshan Yao,Chen Xu,Xian-Ling Mao", "background": "Talking Face Generation (TFG) 方法已经在数字教育、影视制作、电商平台直播等领域取得了广泛应用。现有方法基于NeRF或3DGS技术，通过学习和存储个人特征来生成逼真的人脸说话视频。现有方法通常需要处理多分钟的参考视频并进行详细的拟合，这会占用大量的时间。因此，研究提出一种新的策略，即ISExplore，通过选定具有信息性的短视频段（长度为5秒）来替代原有的多分钟参考视频，以提高数据处理和训练速度，同时保持高质量的输出效果。", "innovation": "ISExplore策略通过自动识别具有音频特征多样性、唇部运动幅度和摄像机视角数量的数据质量关键维度中的信息性5秒视频段，来替代原有的多分钟参考视频。该策略在NeRF和3DGS方法中分别将数据处理和训练速度提升了超过5倍，且保持了高质量的输出效果。", "conclusion": "我们的研究发现，比起视频的长度，信息质量对生成逼真的人脸说话视频更为重要。对于个人化的面部生成，使用几分钟内有信息性的视频片段可以达到一般或更好的效果，从而提高了数据处理和训练速度，具有高度的实用性。项目资源可在xx处获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07941", "html_url": "https://arxiv.org/abs/2511.07941", "title": "Libra-MIL: 结合特定任务语言先验的多模态原型立体融合用于少量样本全切片图像分类", "title_en": "Libra-MIL: Multimodal Prototypes Stereoscopic Infused with Task-specific Language Priors for Few-shot Whole Slide Image Classification", "authors": "Zhenfeng Zhuang,Fangyu Zhou,Liansheng Wang", "background": "大语言模型（LLMs）在计算病理学领域展现出了巨大的潜力，但由于吉像素级全切片图像（WSIs）的大量计算成本，需要使用多实例学习（MIL）来使建模过程变得更加高效。然而，病理任务通常只能提供袋子级别的标签，而由LLMs生成的实例级别的描述由于缺乏细微的医学知识，往往存在偏差。这引发了一个挑战，即如何构建任务特定的病理实体原型来学习到可泛化的特征并增强模型的可解释性。", "innovation": "本文提出了一个多模态原型多实例学习的新方法，称为Libra-MIL。该方法通过一个平衡的信息压缩方案促进了多模态的双向互动，并利用冻结的大语言模型生成任务特定的病理实体描述，将其作为文本原型学习。同时，视觉分支学习实例级别原型以减少模型对冗余数据的依赖。另在融合阶段，使用基于相似度度量的立体最优传输（SOT）算法，有助于在高维度空间中实现更广泛的语义对齐。与现有的语视MIL方法相比，该方法更能够促进跨模式的协同作用。", "conclusion": "我们的实验结果表明，该方法在三个不同的癌症数据集上的少量样本全切片图像分类中表现出优越的泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07983", "html_url": "https://arxiv.org/abs/2511.07983", "title": "ChexFract：从通用到专业化——增强骨折描述生成", "title_en": "ChexFract: From General to Specialized - Enhancing Fracture Description Generation", "authors": "Nikolay Nechaev,Evgeniia Przhezdzetskaia,Dmitry Umerenkov,Dmitry V. Dylov", "background": "生成来自胸部X光图像的准确且临床意义重大的放射报告仍然是医疗AI的一大挑战。尽管最近的视觉-语言模型在通用放射报告生成上取得了显著成果，但在描述罕见但临床上重要的病理学，如骨折方面，仍然表现不佳。这项工作通过开发专门针对骨折病理检测和描述的模型解决了这一差距。", "innovation": "通过训练专门针对骨折的视觉语言模型，使用来自MAIRA-2和CheXagent的编码器，这些模型在生成骨折描述的准确性上比通用模型有显著提高。通过对骨折类型、位置和年龄进行模型输出分析，揭示了当前视觉语言模型架构的优缺点。", "conclusion": "我们公开发布我们表现最佳的骨折报告模型，此举促进了对罕见病理准确报告的未来研究。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07948", "html_url": "https://arxiv.org/abs/2511.07948", "title": "ReIDMamba: 使用视觉状态空间模型学习鉴别性特征的人员再识别", "title_en": "ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification", "authors": "Hongyang Gu,Qisong Yang,Lei Pu,Siming Han,Yao Ding", "background": "人员再识别（ReID）中，提取稳健的鉴别性特征是一个关键挑战。尽管基于Transformer的方法成功地解决了卷积神经网络（CNN）的局限性，如局部处理特性以及卷积和下采样操作导致的信息损失，但它们仍然面临由于输入序列长度增加而导致的内存和计算需求呈二次增长的可扩展性问题。针对这一问题，本文提出了基于纯Mamba的人再识别框架ReIDMamba。除了设计了利用细粒度、鉴别性全局特征的Mamba基础模型，还引入了多粒度特征抽取（MGFE）模块和排名感知三元组正则化（RATR），以进一步增强特征学习的鲁棒性。", "innovation": "本文的创新之处在于提出了一个基于纯Mamba的人员再识别框架ReIDMamba，设计了多粒度特征抽取（MGFE）模块和排名感知三元组正则化（RATR）。ReIDMamba模型参数量比TransReID少三分之一，并且具有更低的GPU内存使用率和更快的推理吞吐量。通过实验表明，ReIDMamba在五种人员再识别基准上的性能达到了最先进的水平。", "conclusion": "本文提出了一种基于纯Mamba的人再识别框架ReIDMamba，该模型参数少、占用GPU内存小、推理速度快，并在多个基准测试中达到了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07978", "html_url": "https://arxiv.org/abs/2511.07978", "title": "DANCE：一种不依赖密度且类别感知的点云完成网络", "title_en": "DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion", "authors": "Da-Yeong Kim,Yeong-Jun Cho", "background": "点云完成的目标是从不完整的3D扫描中恢复缺失的几何结构，这些扫描常常受到遮挡或传感器视角有限的影响。现有的方法通常假设固定的输入/输出密度，或者依赖于基于图像的表示，这使得它们不适用于输入稀疏性变化和监督有限的真实场景。", "innovation": "本文提出了一种名为DANCE（Density-agnostic and Class-aware Network）的新型框架，该框架仅补充缺失区域以保留观察到的几何形状。DANCE通过多视图基于光线的采样生成候选点，然后使用变压器解码器精确定位并预测透明度分数，这些分数决定了每个点在最终表面中的有效性。此外，通过训练一个轻量级分类头直接作用于几何特征，DANCE能够在无需外部图像监督的情况下实现类别一致性完成。", "conclusion": "在PCN和MVP基准上的广泛实验表明，DANCE在准确性和结构一致性方面优于最先进的方法，同时还能抵抗输入密度和噪声水平的变化。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07966", "html_url": "https://arxiv.org/abs/2511.07966", "title": "多模态辅助的点云3D物体检测无监督域适应", "title_en": "Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection", "authors": "Shenao Zhao,Pengpeng Liang,Zhoufan Yang", "background": "近年来，基于LiDAR的3D对象检测无监督域适应（3D UDA）在使用教师-学生架构和伪标签时取得了显著改进。尽管同时收集点云和图像数据很流行，但在训练模型时很少关注图像数据在3D UDA中的有用性。该论文提出了MMAssist方法，通过多模态辅助提高3D UDA的性能，设计了一种方法通过图像和文本特征来对齐源域和目标域的3D特征，从而增强伪标签并提升模型性能。实验结果显示，该方法在三个3D物体检测数据集上的三个无监督域适应任务中，相比当前最先进的方法取得了令人满意的表现。", "innovation": "提出了一种多模态辅助方法MMAssist，通过图像和文本特征对齐3D特征，强化伪标签，提高3D UDA的性能；结合预训练的视觉和文本特征提取器，对齐学生分支和教师分支在目标域中的特征；使用现成的2D物体检测器从图像中生成2D边界框并据此估计相应的3D边界框，与教师模型生成的伪标签相结合，从而提高模型的准确性。", "conclusion": "MMAssist方法在3D UDA任务中表现优异，特别是在三个常用数据集上的三个任务中，其性能超过了当前最先进的方法。同时，作者将代码开源，可供进一步的探索和研究使用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08007", "html_url": "https://arxiv.org/abs/2511.08007", "title": "EAGLE: 蛋白质出现和几何感知的记忆在第一视角视觉查询定位中的统一 2D-3D 视觉查询定位", "title_en": "EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision", "authors": "Yifei Cao,Yu Liu,Guolong Wang,Zhu Liu,Kai Wang,Xianjie Zhang,Jizhe Yu,Xun Tu", "background": "第一视角视觉查询定位对于嵌入式人工智能和虚拟／增强现实至关重要，但由于相机运动、视角变化和外观变异，这一任务依然具有挑战性。", "innovation": "本文提出了一种名为EAGLE的新框架，利用事件驱动的感知和几何感知记忆实现统一的2D-3D视觉查询定位。它通过一种记忆巩固机制，结合了基于感知元学习记忆（AMM）的分割引导以及基于几何感知定位记忆（GLM）的跟踪驱动，提供长期和短期的建模支持，提高了目标外观变异的检索准确性，并集成视觉几何嵌入的变压器（VGGT），实现2D-3D任务的高效统一。", "conclusion": "在Ego4D-VQ基准测试上，该方法取得了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07958", "html_url": "https://arxiv.org/abs/2511.07958", "title": "突发图像质量评估：多种下游任务的统一基准和框架", "title_en": "Burst Image Quality Assessment: A New Benchmark and Unified Framework for Multiple Downstream Tasks", "authors": "Xiaoye Liang,Lai Jiang,Minglang Qiao,Yichen Guo,Yue Zhang,Xin Deng,Shengxi Li,Yufan Liu,Mai Xu", "background": "最近几年，突发成像技术的发展提高了视觉数据的捕捉和处理能力，扩展了其应用范围。然而，突发图像数据中的冗余导致了更高的存储和传输需求，以及下游任务效率的降低。为解决这一问题，本文提出了突发图像质量评估（BuIQA）的新任务，旨在评估突发序列中每一帧的驱动任务质量，为突发图像的选择提供合理的指导。现有研究尚未建立公开的BuIQA基准数据集，本文首次构建了一个包含7346个突发序列和45827张图像的基准数据集，并提供了191572个质量评分，涵盖了多种下游应用场景。", "innovation": "本文提出了一种新的基准数据集和统一的BuIQA框架。具体创新包括：1) 构建了首个公开的BuIQA基准数据集，包含大量场景下的高质量评估数据；2) 设计了一种基于多样化先验知识蒸馏的任务驱动提示生成网络；3) 引入了任务感知质量评估网络，根据任务提示评估突发图像质量；4) 通过在多种下游任务上的广泛实验验证了该方法的优越性能，特别在降噪和超分辨率任务中实现了0.33 dB的PSNR改进。", "conclusion": "本文提出的框架在突发图像质量评估方面表现出色，各下游任务性能超过了最先进的方法，并能显著提高降噪和超分辨率任务的准确性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07976", "html_url": "https://arxiv.org/abs/2511.07976", "title": "时间演变中的形态：基于扩散桥接时空间隙以增强变化检测中的稳健对齐", "title_en": "Morphing Through Time: Diffusion-Based Bridging of Temporal Gaps for Robust Alignment in Change Detection", "authors": "Seyedehanita Madani,Vishal M. Patel", "background": "遥感变化检测常常受到双重空间对齐问题的挑战，特别是在长时间或跨年度的图像获取之间存在较大的空间错位。现有的卷积神经网络和变压器模型在对齐数据上表现良好，但它们对精准空间对齐的依赖限制了其在现实世界中的鲁棒性。现有的联合注册-检测框架通常需要重新训练，并且在不同领域间迁移能力较差。", "innovation": "提出了一种模块化管道，无需修改现有的变化检测网络即可提升空间和时间鲁棒性。该框架结合了基于扩散的语义形态变换、密集注册和残差流细化。差分模块合成可以填补连续帧之间大片视觉差异的过渡帧，使RoMa能够在连续帧之间逐步估计对应关系。生成的复合流通过轻量级U-Net细化为高质量的扭曲，从而恢复原始图像对的对齐。在LEVIR-CD、WHU-CD和DSIFN-CD数据集上的大量实验表明，在不同骨干网络上的精度和变化检测均有所提升，证明了该方法的普遍性和有效性。", "conclusion": "综上所述，本文提出的方法在增强变化检测中的时空鲁棒性和精确性方面取得了显著效果，并显示了其在不同数据集和不同骨干网络上的通用性和有效性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08003", "html_url": "https://arxiv.org/abs/2511.08003", "title": "Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning", "title_en": "Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning", "authors": "Jialong Qin,Xin Zou,Di Lu,Yibo Yan,Xuming Hu", "background": "现有的视频大语言模型（VideoLLMs）面临着计算复杂度的平方问题和关键值缓存（KV缓存）的扩展问题，这主要是由于它们需要处理大量的冗余视觉标记。这导致了模型在处理视频数据时的效率低下和性能瓶颈。", "innovation": "提出了一种名为SharpV的简单高效的视觉标记和KV缓存自适应剪枝方法。与大多数均匀压缩方法不同，SharpV根据空间-时间信息动态调整剪枝比。SharpV在视觉信息退化时通过自校准方式剪枝降级的视觉特征，这提供了信息瓶颈视角下的分层缓存剪枝，对VideoLLMs的信息流动提出了新的见解。特别指出的是，SharpV在无需访问注意力分数的情况下，是第一个能够在不损害硬件加速技术（如闪速注意）兼容性的两阶段剪枝框架。", "conclusion": "实验表明，SharpV在多个公开基准上具有优越性。SharpV提供了一种新的自适应剪枝范式，能够有效地减少视觉标记和KV缓存，同时保证了模型的高效性和可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07990", "html_url": "https://arxiv.org/abs/2511.07990", "title": "针对STM32U5的硬件感知YOLO压缩技术在数字农业杂草检测中的低功耗边缘AI系统", "title_en": "Hardware-Aware YOLO Compression for Low-Power Edge AI on STM32U5 for Weeds Detection in Digital Agriculture", "authors": "Charalampos S. Kouzinopoulos,Yuri Manna", "background": "杂草显著降低了全球农作物产量，并对可持续农业构成重大挑战。传统的杂草管理方法主要依赖化学除草剂，这可能导致环境污染和杂草抗药性的出现。基于计算机视觉和机器学习的精准除草提供了一种环保的选择，但通常受限于高性能计算平台。为此，本文提出了一种基于YOLOv8n目标检测模型的低功耗边缘AI系统，用于杂草检测，该模型部署在STM32U575ZI微控制器上。该技术通过结构化剪枝、整数量化和输入图像分辨率缩放等压缩技术，满足了严格的硬件限制，实现了在资源受限的农业环境中进行实时、现场杂草检测，并将单次推理能耗降低至51.8毫焦耳。研究结果证明，该系统在CROPANDWEED数据集上训练和评估，达到了检测准确性和效率之间的良好平衡，支持在资源受限环境下进行大规模部署。", "innovation": "本文创新在于提出了基于YOLOv8n目标检测模型的低功耗边缘AI系统，通过应用结构化剪枝、整数量化和输入图像分辨率缩放等多种压缩技术，克服了高性能计算平台的需求，实现了低功耗，低能耗的实时、现场杂草检测，特别适用于资源受限的农业环境。", "conclusion": "所提出的系统能够实现实时、现场的杂草检测，并达到了检测准确性和能耗之间的良好平衡，支持在资源受限的农业环境中进行大规模部署。该系统不仅提高了杂草管理的效果，而且有助于减少对化学除草剂的依赖，为可持续农业提供了一种环保的选择。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07987", "html_url": "https://arxiv.org/abs/2511.07987", "title": "CSF-Net: Context-Semantic Fusion Network for Large Mask Inpainting", "title_en": "CSF-Net: Context-Semantic Fusion Network for Large Mask Inpainting", "authors": "Chae-Yeon Heo,Yeong-Jun Cho", "background": "本文探讨了大缺损图像修复的挑战性问题，其中缺失关键视觉内容，并且环境线索有限。为了解决这一问题，提出了一种基于语义指导的框架，通过利用预训练的Amodal Completion (AC) 模型生成结构感知的候选区域，作为缺失区域的语义先验。该框架引入了Context-Semantic Fusion Network (CSF-Net)，一个基于Transformer的融合网络，将这些候选区域与上下文特征融合，生成语义指导图像，以提高图像修复的质量，促进结构准确性和语义一致性。CSF-Net 可以无缝集成到现有的图像修复模型中，适用于各种遮罩条件，并表现出一致的性能提升。实验结果表明，CSF-Net 可以有效减少物体的虚幻，同时增强视觉真实感和语义对齐。", "innovation": "创新点在于提出了一种基于语义指导的框架，利用预训练的Amodal Completion (AC) 模型生成结构感知的候选区域，并通过Context-Semantic Fusion Network (CSF-Net) 将这些候选区域与上下文特征融合，生成语义指导图像，以提高图像修复的效果。CSF-Net 的创新之处在于简洁的集成方式，对现有的图像修复模型来说可以无缝集成，适用于多种遮罩条件，有效减少了物体虚影并增强了图像的真实感和语义对齐度。", "conclusion": "通过广泛的实验测试，CSF-Net 在Places365 和 COCOA 数据集上的表现证明了其在处理大遮罩图像修复任务时的有效性和优越性，增强了视觉真实感和语义一致性。研究结果表明，CSF-Net 是一种适用于广泛遮罩条件的高效图像修复方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08015", "html_url": "https://arxiv.org/abs/2511.08015", "title": "无形的触发器，可见的威胁！面向自主驾驶的视觉3D检测的路面风格对抗生成攻击", "title_en": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for Visual 3D Detection in Autonomous Driving", "authors": "Jian Wang,Lijun He,Yixing Yong,Haixia Bi,Fan Li", "background": "现代自动驾驶（AD）系统利用3D物体检测来感知3D环境中的前景物体，以进行后续的预测和规划。基于RGB摄像头的视觉3D检测相比激光雷达（LiDAR）方案成本较低。尽管当前基于深度神经网络的模型在检测精度上取得了显著成果，但它们对对抗样本非常敏感。由于潜在的安全风险，我们研究了在AD场景中实施现实的对抗攻击。先前工作表明，可以在道路上放置对抗性海报以诱导检测器产生幻觉，但这些海报的非自然外观容易被人注意，其固定内容容易被针对性地防御。", "innovation": "我们提出了一种名为AdvRoad的生成方法，以产生具有自然外观的路面风格对抗性海报。这些海报既模拟了路面外观，又能在攻击位置让检测器感知到不存在的对象。我们使用两种阶段的方法，具体来说是道路风格对手生成和场景相关的适应，以最大化对输入场景的攻击效果，同时确保海报的自然外观，使攻击可以隐蔽地进行，不引起人类的注意。", "conclusion": "广泛的实验表明，AdvRoad能够很好地泛化到不同的检测器、场景和欺骗位置。此外，物理攻击进一步证明了在实际环境中的现实威胁。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08032", "html_url": "https://arxiv.org/abs/2511.08032", "title": "三维高斯点云成像的感知质量评估：主观数据集及预测指标", "title_en": "Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric", "authors": "Zhaolin Wan,Yining Diao,Jingqi Xu,Hao Wang,Zhiyang Li,Xiaopeng Fan,Wangmeng Zuo,Debin Zhao", "background": "随着3D可视化技术的迅猛发展，3D高斯束光栅化（3DGS）已成为实时高保真渲染的主要技术。尽管以往研究着重于算法性能和视觉保真度，但3DGS渲染内容在不同重建条件下感知质量的评估仍相对较少。实际应用中，诸如视点稀疏性、训练迭代次数受限、点云下采样、噪音和色彩失真等因素会显著降低视觉质量，但这些感知影响尚未被系统研究。", "innovation": "本文提出了第一个针对3DGS的主观质量评估数据集3DGS-QA，其包含了15种物体类型下的225种退化重建，有助于系统研究常见失真因素。基于此数据集，作者引入了一种无需参考渲染图像或真值得质量预测模型，该模型直接在原生的3D高斯表示上操作，通过结构感知的方式提取空间和光度线索来估计感知质量。", "conclusion": "实验结果表明，所提出的方法在质量评估上表现出更强的鲁棒性和有效性。为了方便未来的研究，数据集和代码已公开共享。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08046", "html_url": "https://arxiv.org/abs/2511.08046", "title": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation", "title_en": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation", "authors": "Aya Elgebaly,Nikolaos Delopoulos,Juliane Hörner-Rieber,Carolin Rippke,Sebastian Klüter,Luca Boldrini,Lorenzo Placidi,Riccardo Dal Bello,Nicolaus Andratschke,Michael Baumgartl,Claus Belka,Christopher Kurz,Guillaume Landry,Shadi Albarqouni", "background": "自动医学图像分割受高观察者间变异性的影响，特别是在如肺结节分割等任务中，专家意见经常存在分歧。现有方法要么将这种变异性合并到共识掩码中，要么依赖于每个标注者单独的模型分支。", "innovation": "提出了ProSona，这是一种两阶段框架，学习标记风格的连续潜在空间，通过自然语言提示实现可控的个性化。Probabilistic U-Net骨干捕捉多样性的专家假说，而提示导向的投影机制引导此潜在空间生成个性化分割。多层次对比目标使文本和视觉表示对齐，促进了解散和可解释的专家风格。", "conclusion": "ProSona在LIDC-IDRI肺结节和多机构前列腺MRI数据集上减少了Generalized Energy Distance 17%，并提高了平均Dice超过1分，与DPersona相比。结果显示，自然语言提示可以提供灵活、准确和可解释的个性化控制。我们的实现已在线发布。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08031", "html_url": "https://arxiv.org/abs/2511.08031", "title": "使用FPN-Transformer的多模态深假检测与定位", "title_en": "Multi-modal Deepfake Detection and Localization with FPN-Transformer", "authors": "Chende Zheng,Ruiqi Suo,Zhoulin Ji,Jingyi Deng,Fangbin Yi,Chenhao Lin,Chao Shen", "background": "生成对抗网络（GANs）和扩散模型的迅速发展使得产生高度真实的虚假内容（deepfake）成为可能，这种虚假内容对音频视频领域中的数字信任构成了重大威胁。尽管单模态检测方法在识别合成媒体方面显示出进展，但它们无法利用跨模态相关性且难以精确定位伪造段落，因而难以应对高精度、高复杂度的篡改。因此，引入了基于特征金字塔变换器（FPN-Transformer）的多模态深假检测和定位框架，以克服这些跨模态泛化和时间边界回归的关键缺口。该框架使用预训练的自监督模型（WavLM用于音频，CLIP用于视频）提取层级时间特征，通过具有局部注意力机制的R-TLM模块构建多尺度特征金字塔，实现跨上下文时间依赖性的联合分析。", "innovation": "提出的框架利用预训练的自监督模型（WavLM和CLIP）提取层级时间特征，通过R-TLM块构建多尺度特征金字塔，实现了局部注意机制下的跨上下文时间依赖性分析。采用双分支预测头同时预测伪造概率和修正段落的时间偏移，实现帧级精确定位，提升了在复杂环境中的跨模态伪造检测和定位性能。", "conclusion": "在IJCAI'25 DDL-AV基准测试集上，该方法取得了良好的性能，最终分数为0.7535，确认了该方法的有效性，并提供了一种通用的伪造检测新途径。代码已公开。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08061", "html_url": "https://arxiv.org/abs/2511.08061", "title": "通过潜空间连接和掩码条件流匹配在扩散模型中驯服身份一致性与提示多样性", "title_en": "Taming Identity Consistency and Prompt Diversity in Diffusion Models via Latent Concatenation and Masked Conditional Flow Matching", "authors": "Aditi Singhania,Arushi Jain,Krutik Malani,Riddhi Dhawan,Souymodip Chakraborty,Vineet Batra,Ankit Phogat", "background": "主题驱动的图像生成旨在生成特定主题的新型表现形式，同时保留其核心身份特征。在多样背景下实现强身份一致性与高提示多样性之间存在基本权衡。", "innovation": "该论文提出了一种LoRA微调的扩散模型，该模型采用了潜空间连接策略，能够同时处理参考图像和目标图像，并结合了掩码条件流匹配（CFM）目标。该方法能够在不修改架构的情况下提供强大的身份保留。此外，还引入了两阶段的精炼数据编目框架，以支持大规模训练。", "conclusion": "提出了细粒度评估框架CHARIS，用于详细比较身份一致性、提示一致性、区域颜色保真度、视觉质量和变换多样性这五个关键维度，从而提供精细的评估和筛选机制。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08048", "html_url": "https://arxiv.org/abs/2511.08048", "title": "基于渐进查询聚合的通用尺度目标计数", "title_en": "Generalized-Scale Object Counting with Gradual Query Aggregation", "authors": "Jer Pelhan,Alan Lukezic,Matej Kristan", "background": "现有的少量样本检测计数方法在处理具有多种尺寸对象和密集小对象区域的图像时表现不佳。通常使用不同分辨率的骨干特征进行对象定位，通过图像上采样和切片处理来处理计算和内存需求的增加，但这些临时方案导致现有计数器难以有效处理这类图像。因此，当前存在一个问题，需要提出一种能够明确解决对象尺度问题的端到端少量样本计数和检测方法，以提高计数和检测准确性，同时减少内存消耗并提高运行速度.", "innovation": "文章提出了GECO2，一种端到端的少量样本计数和检测方法，该方法通过引入新的密集查询表示法，能够逐渐聚集不同尺度的示例特征信息，生成高分辨率的密集查询，支持对大、小物体的检测。这种新方法不仅在计数准确性上超越了现有最先进的少量样本计数方法，而且在保持更小的GPU内存占用的同时，运行速度提高了三倍.", "conclusion": "GECO2不仅能显著提升计数准确性，还能够快速高效地处理包含多样化对象大小和密集小对象区域的图像，同时通过优化查询表示显著减少了计算资源需求，展示了在少量样本检测计数领域的重大进步."}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08018", "html_url": "https://arxiv.org/abs/2511.08018", "title": "高质量提案编码和级联降噪对虚拟监督物体检测的应用", "title_en": "High-Quality Proposal Encoding and Cascade Denoising for Imaginary Supervised Object Detection", "authors": "Zhiyuan Chen,Yuelin Guo,Zitong Huang,Haoyu He,Renhao Lu,Weizhe Zhang", "background": "物体检测模型需要大规模标注数据集，但创建这些数据集的成本高且劳动密集。因此，提出了虚拟监督物体检测(ISOD)，其中模型训练在合成图像上，测试在真实图像上。然而，现有方法存在三个局限性：(1)合成数据集的问题在于简化的提示、较差的图像质量和弱监督；(2)基于DETR的检测器由于随机查询初始化原因，收敛慢，并过度拟合于合成模式，影响现实世界的泛化能力；(3)均匀的去噪压力可能导致模型过度拟合伪标签噪声。这导致了论文提出的新方法。", "innovation": "该研究提出了级联HQP-DETR以解决这些限制。首先，引入了高质量数据管道，使用LLaMA-3、Flux和Grounding DINO生成了FluxVOC和FluxCOCO数据集，将ISOD从弱监督提升到全监督。其次，采用了高质量提案引导的查询编码进行目标查询初始化，用来自SAM生成的提案和RoI池化特征的图像特定先验，加速了收敛并促使模型专注于学习可迁移特征而非拟合合成模式。最后，采用了级联去噪算法按照解码层逐层提高IoU阈值来动态调整训练权重，引导模型从可靠的视觉线索中学习稳健边界的细节而非过度拟合噪声标签。", "conclusion": "仅使用FluxVOC训练12个周期后，级联HQP-DETR即在PASCAL VOC 2007中实现了61.04%的mAP@0.5，超越了强基准模型，并证明了其在实际数据上的竞争力，证实了该架构的普适性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08036", "html_url": "https://arxiv.org/abs/2511.08036", "title": "WEDepth：将世界知识高效适应于单目深度估计", "title_en": "WEDepth: Efficient Adaptation of World Knowledge for Monocular Depth Estimation", "authors": "Gongshu Wang,Zhirui Wang,Kan Yang", "background": "单目深度估计（MDE）具有广泛应用前景，但由于从单张二维图像重构三维场景的固有病态性，这一任务仍然极具挑战性。现代视力基础模型（VFMs），通过在大规模多样数据集上进行预训练，展示了显著的全球理解能力，这为各种视觉任务带来了益处。近期研究表明，通过微调这些VFMs可以在MDE任务中取得显著改进。然而，大部分现有方法在结构修改或预训练权重修改方面需要进行创新性的调整，这增加了复杂性和难度。", "innovation": "本文提出了一种新颖的方法WEDepth，该方法能在无需修改VFMs结构和预训练权重的情况下，有效提取和利用其固有的先验知识来适应MDE任务。WEDepth利用VFMs作为多级特征增强器，在不同的表示级别系统性地注入先验知识。实验结果表明，WEDepth达到了新的业界最佳性能，并且在零样本跨场景转移能力上表现出色，与基于扩散的方法（需要多次前向传递）和专门预训练的相对深度方法相比具有竞争力。", "conclusion": "WEDepth通过在保持VFMs原结构和预训练权重的基础上，系统性地在其不同表示级别注入先验知识，显著提升了单目深度估计的性能。该方法不仅达到了新的最好性能，还在多种场景中展示了强大的零样本迁移能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08065", "html_url": "https://arxiv.org/abs/2511.08065", "title": "I2E: 实时图像到事件转换以实现高性能脉冲神经网络", "title_en": "I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks", "authors": "Ruichen Ma,Liwei Meng,Guanchao Qiao,Ning Ning,Yang Liu,Shaogang Hu", "background": "脉冲神经网络（SNNs）具有高度节能的优势，但由于缺乏事件流数据，其应用受到限制。为此，本文通过一种算法框架I2E将静态图像转化为高保真度的事件流，解决了这一瓶颈问题。", "innovation": "通过高度并行化的卷积模拟微眼动，I2E实现了比之前方法快300倍以上的转换速度，这使得SNN训练的实时数据增强成为可能。此外，通过在合成和真实数据集之间进行预训练和微调，I2E实现了前所未有的92.5%的准确率，证明了合成事件数据可以作为真实传感器数据的高保真代理。", "conclusion": "I2E提供了一种可扩展的数据解决方案，成为神经形态工程领域的有力范式。通过提供开源算法和所有生成的数据集，I2E为该领域研究加速提供了基础工具箱。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08071", "html_url": "https://arxiv.org/abs/2511.08071", "title": "Radar-APLANC: 通过增强伪标签和噪声对比实现的无监督雷达心率传感", "title_en": "Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented Pseudo-Label and Noise Contrast", "authors": "Ying Wang,Zhaodong Sun,Xu Cheng,Zuxian He,Xiaobai Li", "background": "传统的雷达心率传感方法由于噪声的影响，其性能会下降。基于学习的雷达方法能更好地应对噪声影响，但需要昂贵的标注信号进行监督训练。", "innovation": "提出了雷达心率传感的首个无监督框架Radar-APLANC，通过增强伪标签和噪声对比技术。该方法利用雷达距离矩阵中的心率距离和噪声距离分别构建正样本和负样本，避免依赖昂贵的真实生理信号。同时，设计了一种自适应噪声感知标签增强方法以提高伪标签信号质量。", "conclusion": "在Equipleth数据集和自收集的雷达数据集上的广泛实验表明，无监督方法达到了与最先进的监督方法相当的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08075", "html_url": "https://arxiv.org/abs/2511.08075", "title": "CLIP是构建Stable Diffusion中人类语义表示所需的一切", "title_en": "CLIP is All You Need for Human-like Semantic Representations in Stable Diffusion", "authors": "Cameron Braunstein,Mariya Toneva,Eddy Ilg", "background": "最新的latent diffusion模型，如Stable Diffusion在文本生成图像任务上达到了最先进的性能，但是这些模型生成的图像的语义理解程度尚未完全明确。该工作旨在探究Stable Diffusion在生成文本到图像过程中内部表示中是否蕴含了有意义的语义信息。", "innovation": "通过使用简单的回归层对Stable Diffusion进行探针实验，预测对象的语义属性并将其与人类标注进行比较。发现语义信息的实际来源可能并非逆向扩散过程，而是CLIP中的文本编码过程。进一步证明，一些特定的语义属性在逆向扩散过程中难以区分，这强调了CLIP在对象属性上的最强语义表示。", "conclusion": "研究得出结论认为，单独训练的CLIP视觉语言模型决定了人类语义表示，而扩散过程则起到了视觉解码的作用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08087", "html_url": "https://arxiv.org/abs/2511.08087", "title": "超越像素：基于VLM的身份保留评估在参考引导合成中的应用", "title_en": "Beyond the Pixels: VLM-based Evaluation of Identity Preservation in Reference-Guided Synthesis", "authors": "Aditi Singhania,Krutik Malani,Riddhi Dhawan,Arushi Jain,Garv Tandon,Nippun Sharma,Souymodip Chakraborty,Vineet Batra,Ankit Phogat", "background": "身份保持在生成模型中的评估仍然是一个关键但尚未解决的挑战。现有的评估指标依赖于全局嵌入或粗略的VLM提示，无法捕获精细粒度的身份变化，提供的诊断见解有限。", "innovation": "提出了一种分层评估框架——Beyond the Pixels，该框架将身份评估分解为特征级转换。该方法通过对象按 (类型，风格) -> 属性 -> 特征决策树的层次分解，并提示具体的转换而不是抽象的相似性评分，引导VLM进行结构化推理。这种分解使VLM分析基于可验证的视觉证据，减少幻觉并提高一致性。", "conclusion": "我们的框架在四个最先进的生成模型上进行了验证，展示了在衡量身份一致性方面与人类判断的高度契合。我们还引入了一个新的基准，专门用于测试生成模型，该基准包括1,078幅图像-提示对，涵盖各类主体类型，包括未充分代表的类别，如拟人化和动画角色，并捕捉每次提示的平均六到七个转换轴。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08090", "html_url": "https://arxiv.org/abs/2511.08090", "title": "StableMorph：基于稳定扩散的高质量面部形态生成", "title_en": "StableMorph: High-Quality Face Morph Generation with Stable Diffusion", "authors": "Wassim Kabbani,Kiran Raja,Raghavendra Ramachandra,Christoph Busch", "background": "面部形态欺骗攻击威胁到了生物识别身份系统的完整性，使多个个体能够共享同一个身份。为了开发和评估有效的形态攻击检测（MAD）系统，研究人员需要高质量、真实的形态图像来反映现实世界中的挑战。然而，现有的生成方法常常产生的图像模糊、有许多伪影或构造不良，使其容易被检测且不具有危险性。因此，当前MAD系统面临现实挑战的问题没有得到有效解决。", "innovation": "StableMorph 是一种新颖的方法，通过现代基于扩散的图像合成生成高真实度且无伪影的面部形态图像。StableMorph 生成完整的头部图像，具有清晰的细节，避免了常见的视觉缺陷，提供了对视觉属性的无与伦比的控制能力。通过广泛的评估表明，StableMorph 生成的图像不仅在质量和真实性上与真实人脸图像相当或超过，还具有欺骗人脸识别系统的能力，为现有的MAD解决方案带来了更大的挑战，并设定了新的形态质量标准。", "conclusion": "StableMorph 为生物识别安全评估创造了更为逼真和有效的攻击，并支持了更稳健检测系统的开发。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08119", "html_url": "https://arxiv.org/abs/2511.08119", "title": "LatentPrintFormer: 一种具有空间注意力机制的CNN-Transformer组合模型用于潜指纹识别", "title_en": "LatentPrintFormer: A Hybrid CNN-Transformer with Spatial Attention for Latent Fingerprint identification", "authors": "Arnab Maity,Manasa,Pavan Kumar C,Raghavendra Ramachandra", "background": "潜指纹识别由于低图像质量、背景噪声和部分指纹印痕导致的挑战仍是一个难题。现有技术在准确性和效率上仍有待提升，尤其是在处理复杂背景和低质量指纹方面存在困难。", "innovation": "提出了一个名为LatentPrintFormer的新颖识别方法，它结合了CNN骨干网络（EfficientNet-B0）和Transformer骨干网络（Swin Tiny），以提取潜指纹的局部和全局特征。通过空间注意力模块突出高质量脊线区域并抑制背景噪声。提取的特征被融合并投影到统一的512维嵌入空间中，并在闭集识别设置下使用余弦相似性进行匹配。", "conclusion": "在两个公开可用的数据集上的广泛实验表明，LatentPrintFormer在Rank-10分类上始终优于三种最先进的潜指纹识别技术，识别率更高。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08114", "html_url": "https://arxiv.org/abs/2511.08114", "title": "引入Nylon Face Mask攻击数据集：评估泛化的面部呈现攻击检测技术", "title_en": "Introducing Nylon Face Mask Attacks: A Dataset for Evaluating Generalised Face Presentation Attack Detection", "authors": "Manasa,Sushrut Patwardhan,Narayan Vetrekar,Pavan Kumar,R. S. Gad,Raghavendra Ramachandra", "background": "面部识别系统在智能手机认证、访问控制和边境安全等广泛应用中越来越普遍。然而，这些系统容易受到呈现攻击（PAs），这会显著破坏其可靠性。Nylon Face Masks（NFM）作为一种新型和现实的呈现攻击工具被引入，能够模拟高级3D欺骗场景，给受害者面部几何造模提供逼真的模拟。本研究通过iPhone 11 Pro采集了3760个真实样本和51,281个NFM攻击样本，共四类呈现攻击情景，涵盖真人和人偶，以反映智能手机使用的真实环境。对五种最先进的呈现攻击检测方法进行基准测试，验证其在未见攻击条件下的鲁棒性。结果表明，这些方法的性能存在显著差异，进一步突显了NFM的挑战，强调了开发能够有效推广到新兴欺骗威胁的技术的重要性。", "innovation": "1. 引入了新型和现实的呈现攻击工具Nylon Face Masks（NFM）；\n2. 采集了大量数据样本，镜像了真实世界的智能手机使用环境；\n3. 对五种最先进的呈现攻击检测方法进行了基准测试，验证其在未见攻击条件下的鲁棒性。", "conclusion": "研究结果展示了不同方法在面对NFM情景时的显著性能差异，强调了需要开发适用于新兴欺骗威胁的有效泛化技术的紧迫性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08130", "html_url": "https://arxiv.org/abs/2511.08130", "title": "使用Segment Anything Model 2的污水厂泡沫分割：联邦学习方法", "title_en": "Foam Segmentation in Wastewater Treatment Plants: A Federated Learning Approach with Segment Anything Model 2", "authors": "Mehmet Batuhan Duman,Alejandro Carnero,Cristian Martín,Daniel Garrido,Manuel Díaz", "background": "在污水处理厂（WTPs）中，泡沫形成是一个主要问题，它可能降低处理效率并增加成本。实时监测泡沫变化的能力对提高工厂效率非常有益。然而，训练标准机器学习模型需要大量的标注数据，这导致系统开发缓慢，且受隐私数据稀缺性和异质性的影响。此外，由于隐私担忧，不同WTPs不愿共享其数据，这进一步妨碍了开发的进步。因此，需要一种新的方法来应对这些挑战。", "innovation": "本文提出了一种结合联邦学习（FL）与最新图像分割基模态——Segment Anything Model 2（SAM2）的新框架。该框架通过在不集中敏感运营数据的情况下进行跨WTPs的协作模型训练，确保了隐私保护。通过利用SAM2的强大预训练权重进行初始化，该框架能够加快训练收敛速度并改善分割性能，即使是在使用有限的地方数据集时也是如此。", "conclusion": "这一研究提供了一种实用、可扩展且隐私意识强的解决方案，用于WTPs中的自动泡沫跟踪。结果显示，在解决分布式且敏感数据的问题时，将大规模基础模型集成到联邦学习系统中具有巨大的潜力，以应对实际工业挑战。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08140", "html_url": "https://arxiv.org/abs/2511.08140", "title": "PEOD: 一种针对具有挑战性条件的目标检测的像素对齐事件-RGB基准", "title_en": "PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions", "authors": "Luoping Cui,Hanqing Liu,Mingjie Liu,Endian Lin,Donghong Jiang,Yuhao Wang,Chuang Zhu", "background": "现有的事件-rgb数据集覆盖范围有限，极端条件稀少，且空间分辨率低（不超过640x480），这阻碍了在具有挑战性条件下的目标检测器的全面评估。", "innovation": "提出了PEOD数据集，这是第一个大规模、像素对齐且高分辨率（1280x720）的事件-rgb数据集，以便在具有挑战性条件下进行目标检测。该数据集包含130多种时空对齐序列和340,000个手动边界框，57%的数据捕获了低光、过曝和高速运动等极端条件。此外，通过PEOD对14种方法进行了基准测试，结果显示，在不同输入配置中，融合模型表现出色，但在照明挑战子集中，顶级事件基模型 superiority 击败了所有融合模型。", "conclusion": "PEOD为多模态感知提供了一个现实且高质量的基准，并促进了未来的研究。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08133", "html_url": "https://arxiv.org/abs/2511.08133", "title": "OTSNet: 基于神经认知启发的观察-思考-书写管道的场景文本识别", "title_en": "OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition", "authors": "Lixu Sun,Nurmemet Yolwas,Wushour Silamu", "background": "场景文本识别（STR）由于现实生活中的复杂性仍然具有挑战性，在现有框架中的解耦视觉-语言优化放大了由于跨模态错位传播的错误。视觉编码器对背景干扰表现出注意力偏差，解析几何变形文本时，解码器遭受空间错位，整体降低了对不规则模式的识别精度。", "innovation": "受到人类视觉感知的分层认知过程启发，提出了一种新颖的三阶段网络，命名为 OTSNet，它包含了一个由观察-思考-书写管道组成的统一 STR 模型。该架构包含三个核心组件：（1）带有差异注意力图的双重注意力Macaron编码器，用于精炼视觉特征，抑制无关区域，增强区分性焦点；（2）空间感知模块和语义量化器，它们通过自适应采样联合集成空间上下文和字符级语义抽象；（3）多模态协作验证器，通过视觉、语义和字符级特征的交叉多模态融合实现自我纠正。", "conclusion": "广泛实验表明，OTSNet 达到了最先进的性能，在具有挑战性的 Union14M-L 基准测试集上获得了 83.5% 的平均准确率，并在高度遮挡的 OST 数据集上获得了 79.1% 的准确率，在 14 个评估场景中有 9 个场景都建立了新的记录。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08155", "html_url": "https://arxiv.org/abs/2511.08155", "title": "非对齐参考的图像质量评估方法用于新颖视角合成", "title_en": "Non-Aligned Reference Image Quality Assessment for Novel View Synthesis", "authors": "Abhijay Ghildyal,Rajesh Sureddi,Nabajeet Barman,Saman Zadtootaghaj,Alan Bovik", "background": "在新颖视角合成（NVS）图像的感知质量评估中，传统的方法面临挑战。全参考图像质量评估（FR-IQA）方法在画面不对齐时失效，而无需参考（NR-IQA）方法难以进行一般化。因此，开发一种适用于NVS的非对齐参考图像质量评估（NAR-IQA）框架是必要的。", "innovation": "本文提出了一种专为NVS设计的非对齐参考图像质量评估框架（NAR-IQA），假设参考视图共享部分场景内容但缺乏像素级对齐。通过构建包含针对时间区域兴趣（TROI）的合成失真的大规模图像数据集来训练该模型。模型基于对比学习框架，使用LoRA增强的DINOv2嵌入，并由现有IQA方法的监督指导。模型仅基于合成失真样本进行训练，避免过度拟合特定的现实NVS样本，从而提高了模型的泛化能力。", "conclusion": "所提出的NAR-IQA模型在对齐和非对齐参考下均表现出稳健的性能，优于现有的FR-IQA、NR-IQA和NAR-IQA方法。此外，还进行了一项新的用户研究，以收集在非对齐参考的NVS中观看时的人类偏好数据。研究结果显示所提出的质量预测模型与收集的主观评分之间存在强烈相关性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08152", "html_url": "https://arxiv.org/abs/2511.08152", "title": "Boomda: 平衡多目标优化在多模态域适应中的应用", "title_en": "Boomda: Balanced Multi-objective Optimization for Multimodal Domain Adaptation", "authors": "Jun Sun,Xinxin Zhang,Simin Hong,Jian Zhu,Xiang Gao", "background": "多模态学习在许多领域取得了巨大成功，但由于手动注释成本高昂，面临着注释数据稀缺的挑战。为了应对这一挑战，无监督域适应成为一种流行的方法，尽管这种方法在单模态设置中得到了广泛研究，但在多模态设置中仍然鲜有探索。本文针对不同模态在源域和目标域之间存在变化的域偏移问题，研究了异质多模态域适应。我们首先利用信息瓶颈方法独立学习每个模态的表示，然后通过相关性对齐在表示空间中匹配源域和目标域。为了平衡所有模态的域对齐，我们将问题形式化为一个多目标优化任务，目标是实现帕累托最优解。通过利用我们模型特有的性质，问题可以简化为一个二次规划问题，进一步逼近提供了闭式解，从而提出了一种高效的模态平衡多模态域适应算法。", "innovation": "本文提出了一种平衡多目标优化方法，用于解决多模态域适应问题。该方法首先利用信息瓶颈方法独立学习每个模态的表示，然后通过相关性对齐在表示空间中匹配源域和目标域。为了平衡所有模态的域对齐，问题被形式化为一个多目标优化任务，以实现帕累托最优解。通过利用我们模型特有的性质，该问题简化为一个二次规划问题，进一步逼近提供了闭式解，从而提出了一个高效的模态平衡多模态域适应算法。该方法被命名为Boomda。", "conclusion": "广泛的实证结果表明，所提出的方法具有有效性，并且Boomda在多个基准上优于竞争对手的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08169", "html_url": "https://arxiv.org/abs/2511.08169", "title": "基于关键点灯光建模的KPLM-STA：人体重光源下物理准确的阴影合成", "title_en": "KPLM-STA: Physically-Accurate Shadow Synthesis for Human Relighting via Keypoint-Based Light Modeling", "authors": "Xinhui Yin,Qifei Li,Yilin Guo,Hongxia Xie,Xiaoli Zhang", "background": "图像合成旨在将前景对象无缝融入背景中，在真实、几何准确的阴影生成方面仍然存在挑战。虽然基于扩散的方法近年来超越了基于生成对抗网络（GAN）的方法，但现有技术，如基于扩散的重新照明框架IC-Light，在阴影生成时仍无法同时达到高外观真实性和几何精度，特别是在合成图像中。针对这些局限性，该研究提出了一种基于关键点线性模型（KPLM）和阴影三角算法（STA）的新颖阴影生成框架。", "innovation": "该研究提出了一种基于关键点线性模型（KPLM）和阴影三角算法（STA）的新颖阴影生成框架。KPLM通过九个关键点和一个边界框模型化了人体关节，从而实现物理上合理的阴影投影和关节处的动态着色，增强视觉真实感。STA通过显式的几何公式计算阴影角度、长度和空间位置，进一步提高几何精度。", "conclusion": "广泛的实验表明，本文的方法在阴影现实感基准中达到了最先进的性能，特别是在复杂的人体姿态下，并且在像IC-Light支持的多向重新照明场景中具有良好的泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08163", "html_url": "https://arxiv.org/abs/2511.08163", "title": "Fine粒度互偿网络（Multi-Granularity Mutual Refinement Network）在零样本学习中的应用", "title_en": "Multi-Granularity Mutual Refinement Network for Zero-Shot Learning", "authors": "Ning Wang,Long Yu,Cong Hua,Guangming Zhu,Lin Mei,Syed Afaq Ali Shah,Mohammed Bennamoun,Liang Zhang", "background": "零样本学习（ZSL）旨在通过从已见类别转移语义知识来识别未见类别，而无需任何未见类别的样本。当前的方法通常会将全局视觉特征与语义信息（即属性）相关联，或者通过与对应的属性对局部视觉区域特征进行对齐来增强视觉-语义交互。尽管这些方法有效，但它们通常忽视了区域特征之间内在的交互，这可能会进一步提高可转移和显式视觉特征的获取。", "innovation": "本文提出了一种名为多粒度互补偿网络（Mg-MRN）的网络，通过学习解耦的多粒度特征和跨粒度特征交互来精炼有辨别性和可转移的视觉特征。具体地，通过解耦区域特征挖掘来学习区域级别的有辨别性特征，设计了一个多粒度特征提取模块。然后，通过增强不同粒度区域特征之间的固有交互来强化跨粒度特征融合模块。该模块通过整合相邻层级的区域表示增强了各粒度级别的表征辨别性，进一步提高了零样本学习的识别性能。", "conclusion": "在三个流行ZSL基准数据集上进行的大量实验表明，我们提出的Mg-MRN方法具有优越性和竞争力。我们的代码可供查看和使用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08170", "html_url": "https://arxiv.org/abs/2511.08170", "title": "分布式视觉识别中的分布式零样本学习", "title_en": "Distributed Zero-Shot Learning for Visual Recognition", "authors": "Zhi Chen,Yadan Luo,Zi Huang,Jingjing Li,Sen Wang,Xin Yu", "background": "零样本学习（ZSL）是一种机器学习技术，它能够在没有任何或非常有限的标记示例下对未见过的类进行预测。Distributed Zero-Shot Learning (DistZSL)旨在充分利用分布式节点上的去中心化数据，以学习有效的模型来处理未见过的类。面对分布式节点中数据异质性的问题，该框架引入了关键组件以确保有效的DistZSL学习，分别是跨节点属性正则化器和全局属性与视觉一致性共识。这些组件的目的是改进跨节点的视觉与属性之间的对应关系，提升分布式节点的零样本学习能力。", "innovation": "该论文提出了一种DistZSL框架，旨在解决分布式节点中数据异质性的问题。框架主要包括两个关键组成部分：跨节点属性正则化器和全局属性与视觉一致性共识。跨节点属性正则化器通过确保不同节点上的属性特征距离相似，稳定属性特征空间，从而建立视觉到属性（V2A）关系。全局属性与视觉一致性共识则确保不同节点间的双向映射一致性，增强跨节点的零样本学习能力。", "conclusion": "广泛的实验证明，DistZSL在分布式数据上的学习效果优于现有的最先进的方法。这个框架展示了在当前广泛应用的分布式数据场景中，有效进行零样本学习的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08178", "html_url": "https://arxiv.org/abs/2511.08178", "title": "WarpGAN: 基于扭曲引导的3D GAN反转与风格导向的新颖视图修复", "title_en": "WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting", "authors": "Kaitao Huang,Yan Yan,Jing-Hao Xue,Hanzi Wang", "background": "3D GAN反转可以将单张图像投影到预训练的3D GAN的潜在空间中，以实现单帧新视角合成，这需要视线范围内有高保真度，并且遮挡区域看起来真实且具有多视角一致性。然而，现有的方法主要集中在可见区域的重建上，而对于遮挡区域的生成仅依赖于3D GAN的生成先验。这导致生成的遮挡区域经常由于低比特率潜在代码引起的信息丢失而质量较差。", "innovation": "本文引入了扭曲和修复策略，将图像修复集成到3D GAN反转中，并提出了一个新颖的3D GAN反转方法，即WarpGAN。具体而言，在透视图投影、扭曲和一个利用相同潜在代码下的对称先验和多视角图像对应关系的修复网络（SVINet）之间进行了融合，以实现遮挡区域的修复。", "conclusion": "定量和定性实验表明，我们的方法始终优于几种最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08173", "html_url": "https://arxiv.org/abs/2511.08173", "title": "VLMDiff: 利用视觉语言模型进行扩散型多类异常检测", "title_en": "VLMDiff: Leveraging Vision-Language Models for Multi-Class Anomaly Detection with Diffusion", "authors": "Samet Hicsonmez,Abd El Rahman Shabayek,Djamila Aouada", "background": "在多样且多类的真实世界图像中检测视觉异常是一个显著的挑战。现有的基于扩散的方法依赖于合成噪声生成，这限制了它们的泛化能力和需要对每个类别进行单独的模型训练，从而阻碍了可扩展性。", "innovation": "\\\nos引入了一种新颖的无监督多类视觉异常检测框架，该框架集成了一种潜藏扩散模型（LDM）与视觉语言模型（VLM），以增强异常定位和检测。一种预训练的VLM通过简单的提示提取详细的图像描述，作为LDM训练的附加条件。VLMDiff利用VLMs获得正常描述，无需手动注释或额外的模型训练。这些描述通过扩散模型进行条件化，学习出一个鲁棒的正常图像特征表示，用于多类异常检测。该方法在Real-IAD数据集上实现了25分的像素级区域重叠（PRO）指标提升，在COCO-AD数据集上实现了8分的提升，超越了最先进的扩散型方法。", "conclusion": "VLMDiff在多类异常检测上展示了竞争性的性能，提升了像素级区域重叠（PRO）指标显著。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08186", "html_url": "https://arxiv.org/abs/2511.08186", "title": "方向物体检测中的像素级质量评估", "title_en": "Pixel-level Quality Assessment for Oriented Object Detection", "authors": "Yunhui Zhu,Buliao Huang", "background": "现代面向对象的目标检测器通常预测一组边界框，并基于估计的定位质量选择排名靠前的边界框。要实现高检测性能，估计的质量需紧密匹配实际的定位精度。现有方法通过预测预测框和真实框（GT）之间的交并比（IoU）作为定位质量的近似值。然而，这种框级IoU预测存在结构耦合问题：因为预测框是从检测器对GT框的内部估计得到的，相似性预测的IoU可能导致对于定位不良的框被过度估计。", "innovation": "提出了一种新颖的像素级质量评估（PQA）框架，将框级IoU预测替换为像素级空间一致性整合。PQA通过衡量每个像素相对于预测框和对应于真实框的位置对齐程度来评估质量。这种方法在像素级别操作，避免直接比较预测框和估计的GT框，从而消除框级IoU预测的固有相似性偏见。我们还引入了一个新的集成度量，将像素级空间一致性聚合为统一的质量分数，提供更准确的实际定位质量近似值。", "conclusion": "在HRSC2016和DOTA上进行的大量实验表明，PQA可以无缝整合到各种面向对象的检测器中，一致地提高性能（例如，在Rotated RetinaNet中的AP$_{50:95}$提高5.96%，在STD中提高2.32%）。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08195", "html_url": "https://arxiv.org/abs/2511.08195", "title": "UI2Code$^\text{N}$：一种用于测试时可扩展的交互式UI-to-Code生成的视觉语言模型", "title_en": "UI2Code$^\\text{N}$: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation", "authors": "Zhen Yang,Wenyi Hong,Mingde Xu,Xinyue Fan,Weihan Wang,Jiele Cheng,Xiaotao Gu,Jie Tang", "background": "用户界面（UI）编程是现代软件开发的核心但高度复杂的部分。近年来，视觉语言模型（VLMs）的进步显示了自动UI编码的潜力，但现有方法存在两大关键限制：多模态编码能力尚未得到充分利用，且单轮次方法很少利用迭代的视觉反馈。", "innovation": "本文提出了一个交互式UI-to-code范式，针对上述挑战，提出了UI2Code$^\text{N}$，一种通过分阶段预训练、微调和强化学习训练的视觉语言模型，以实现多模态编码的基础改进。该模型整合了三项核心能力：UI-to-code生成、UI编辑和UI精修，进一步探索了交互式生成的测试时扩展，使得系统地使用多轮反馈成为可能。", "conclusion": "UI2Code$^\text{N}$在UI-to-code和UI精修基准上进行了实验，表现出了开源模型中的新状态，并达到了与领先封闭源模型（如Claude-4-Sonnet和GPT-5）相当的性能。其代码和模型可在指定链接获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08156", "html_url": "https://arxiv.org/abs/2511.08156", "title": "LandSegmenter: 朝着构建灵活的基础模型用于土地利用和土地覆盖图制图的方向", "title_en": "LandSegmenter: Towards a Flexible Foundation Model for Land Use and Land Cover Mapping", "authors": "Chenying Liu,Wei Huang,Xiao Xiang Zhu", "background": "土地利用和土地覆盖（LULC）分类是地球观测（EO）中的基本任务。然而，现有的LULC模型通常只为特定的模态和固定类目分类 taxaonomy 开发，限制了其通用性和更广泛的适用性。近年来，基础模型（FMs）的进步为构建通用模型提供了潜力。然而，任务无关的基础模型通常需要对下游应用进行微调，而针对特定任务的基础模型则依赖大量的标注数据进行训练，这在遥感（RS）领域成本高昂且难以实现。为解决这些问题，提出了一种名为LandSegmenter的LULC基础模型框架，以在输入、模型和输出三个层面解决三个阶段的挑战。从输入角度来看，通过引入大规模、多模态、多源的LAnd Segment（LAS）数据集，缓解了FMs训练对大量标注数据的需求。LAS提供了手动标注的可扩展、低成本替代方案，使FMs能够在多样的LULC领域进行大规模训练。在模型架构方面，LandSegmenter整合了针对遥感的跨模态特征提取适配器和文本编码器以增强语义意识。在输出阶段，提出了一种基于类别的置信度引导融合策略，以减轻语义遗漏并进一步提高LandSegmenter的零样本性能。该研究在六个多模态和类目分类差异化的LULC数据集中评估了LandSegmenter，实验结果表明，LandSegmenter在零样本场景中表现尤为出色，当将其转移到未见过的数据集上时，表现尤为突出。这些结果突显了本框架的有效性以及弱监督在构建针对特定任务的基础模型中的实用性。", "innovation": "提出了一种名为LandSegmenter的LULC基础模型框架，通过引入大规模、多模态、多源的LAnd Segment（LAS）数据集，缓解了FMs训练对大量标注数据的需求。该模型框架在输入、模型和输出三个层面解决了三个阶段的挑战，增强了泛化能力和零样本性能。LAS提供了手动标注的可扩展、低成本替代方案，使FMs能够在多样的LULC领域进行大规模训练。该框架整合了针对遥感的跨模态特征提取适配器和文本编码器以增强语义意识，并提出了一种基于类别的置信度引导融合策略，以减轻语义遗漏并进一步提高零样本性能。", "conclusion": "LandSegmenter框架通过在输入、模型、输出三个层面解决三个阶段的挑战，展示了其在LULC分类中的有效性和优越性，特别是在零样本场景中的表现。此外，该研究通过LAS数据集的构建和弱监督的应用，为构建针对特定任务的基础模型提供了可行的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08203", "html_url": "https://arxiv.org/abs/2511.08203", "title": "旋转和计算：在3D生成扩散中的姿态成本", "title_en": "Twist and Compute: The Cost of Pose in 3D Generative Diffusion", "authors": "Kyle Fogarty,Jack Foster,Boqiao Zhang,Jing Yang,Cengiz Öztireli", "background": "尽管大型图像到3D生成模型取得了显著成果，但它们仍然在归纳偏见方面缺乏透明度。文章指出，当前的3D生成模型在基于图像生成时存在一个重大限制，即强烈的单一视角偏好。研究者通过受控实验发现，即便使用最先进的模型如Hunyuan3D 2.0，在输入图像旋转后，模型的生成性能会显著下降，无法有效跨视角泛化。", "innovation": "研究引入了一种轻量级的卷积神经网络（CNN），该网络可以通过检测和纠正输入图像的方向，来解决这一问题。通过这种方法，不仅可以恢复模型的泛化能力，而且不需要对生成核心进行调整。该工作还引发了一个重要的开放问题：如果现有模型无法仅依靠规模提升性能，我们是否需要探索模块化且具备对称感知的设计？", "conclusion": "本文通过实验证明了单一视角偏好对3D生成模型生成性能的负面影响，并提出了一种新方法来改善这一问题。研究还提出了一个重要的理论问题，即我们是否需要寻找新的设计思路来突破当前模型的局限性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08196", "html_url": "https://arxiv.org/abs/2511.08196", "title": "UCDSC: Open Set UnCertainty aware Deep Simplex Classifier for Medical Image Datasets", "title_en": "UCDSC: Open Set UnCertainty aware Deep Simplex Classifier for Medical Image Datasets", "authors": "Arnav Aditya,Nitin Kumar,Saurabh Shigwan", "background": "尽管深度学习的进步使得计算机辅助诊断取得了显著进展，但在受控实验室环境之外，算法可能会遇到多种挑战。在医疗领域，这些困难通常源于由于伦理和法律限制导致的数据可用性有限，以及专家注解所需的高成本和时间，尤其是在面对新兴或罕见疾病时更为严重。在这种背景下，开放集识别变得至关重要，它能够识别样本是否属于训练期间见过的已知类，否则将其拒绝为未知。", "innovation": "该方法提出了一种新的损失函数，通过利用辅助数据集惩罚开放空间区域，从而有效地拒绝未知类别的样本。该方法在四个MedMNIST数据集（BloodMNIST、OCTMNIST、DermaMNIST、TissueMNIST）上表现出色，并且在一项公开的皮肤数据集上的表现也优于最先进的技术。研究发现，深度神经网络后期阶段学习的特征倾向于围绕各自的类均值聚类，而这些类均值则作为正则单纯形的各个顶点排列。", "conclusion": "该工作提出了一种名为UCDSC的方法，通过设计针对性的损失函数和利用辅助数据集，在开放集识别方面取得了显著的性能提升。该方法在多个医疗图像数据集上超出了现有技术的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08224", "html_url": "https://arxiv.org/abs/2511.08224", "title": "实时单视角无彩红外三维超分辨率的2D表示", "title_en": "2D Representation for Unguided Single-View 3D Super-Resolution in Real-Time", "authors": "Ignasi Mas,Ivan Huerta,Ramon Morros,Javier Ruiz-Hidalgo", "background": "当前的三维超分辨率技术大多依赖高分辨率RGB数据支撑，但很多实际应用场景不具备高分辨率RGB数据的条件。因此，本文旨在提出一种无需高分辨率RGB数据辅助的实时单视角三维超分辨率方法2Dto3D-SR。", "innovation": "本文提出了一种框架2Dto3D-SR，能够通过单视角直接构建结构化的2D表示，适配现有的2D图像超分辨率模型，以实现无需高分辨率RGB数据的三维超分辨率。通过使用Project Normalized Coordinate Code (PNCC)，将可见表面的3D几何信息直接表示为图像，简化了建模过程，同时保持了模型的轻量级和高效特性。", "conclusion": "实验结果显示，Swin Transformer 模型达到了标准基准的最先进精度，Vision Mamba 模型则在实时速度下取得了竞争力的结果。这表明我们的几何引导框架是一种简单且可行的解决实际场景问题的方法，特别是在高分辨率RGB数据不可用的情况下。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08233", "html_url": "https://arxiv.org/abs/2511.08233", "title": "基于几何感知局部自适应的点云表面高效高精度重建", "title_en": "Accurate and Efficient Surface Reconstruction from Point Clouds via Geometry-Aware Local Adaptation", "authors": "Eito Ogawa,Taiga Hayami,Hiroshi Watanabe", "background": "随着深度学习的发展，点云表面重建的准确性有了显著提高，这使得基础设施检查等应用成为可能。近年来，一些从点云的小局部区域而非整个点云中重建的方法引起了注意，因为它们具有较强的泛化能力。然而，目前的研究通常将局部区域均匀地分布在点云上，并保持这些区域的大小固定，这限制了它们对几何复杂度变化的适应性。", "innovation": "本文提出了一种方法，通过基于输入点云曲率自适应调整局部区域的间距和大小，来提高重建的准确性和效率，从而克服了现有方法对几何复杂度变化不适应的问题。", "conclusion": "通过几何感知的局部自适应技术，本研究提出的方法有效提高了点云表面重建的准确率和效率，特别是在处理几何复杂度变化时表现出更强的适应性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08238", "html_url": "https://arxiv.org/abs/2511.08238", "title": "重塑视觉-语言微调中的语义关系", "title_en": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning", "authors": "Xiangyang Wu,Liu Liu,Baosheng Yu,Jiayan Qiu,Zhenwei Shi", "background": "视觉-语言微调已成为构建多模态基础模型的有效范式。现有的微调方法在使视觉和语言对齐和融合时，往往忽略了文本上下文中的语义关系，导致性能不佳。", "innovation": "本文提出了一种基于语义的方法，以改善视觉和语言的对齐和融合。首先，从不同的视觉编码器中提取多层次的语义特征以捕捉更多的视觉线索；其次，通过投影视觉特征到相关度较高的语义组来学习；最后，利用继承交叉注意力来融合视觉特征和文本，通过消除低相关性的视觉-语言特征对来全局去除冗余的视觉关系。", "conclusion": "我们在8种基础模型和2个下游任务（视觉问答和图像 Captioning）上评估了提出的方法，并证明它优于所有现有的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08215", "html_url": "https://arxiv.org/abs/2511.08215", "title": "基于EfficientNet-B4视觉骨干的食品图像中的Gemini LLM在食谱和营养描述评估", "title_en": "Evaluating Gemini LLM in Food Image-Based Recipe and Nutrition Description with EfficientNet-B4 Visual Backbone", "authors": "Rizal Khoirul Anam", "background": "随着数字食品应用的普及，迫切需要高效的方法来进行自动营养分析和烹饪指导。为了应对这一挑战，本文选择了一个分耦合、多模态的食品识别管道，结合了专用视觉骨干EfficientNet-B4和Google的大型生成型语言模型Gemini。本文通过与VGG-16、ResNet-50和YOLOv8的视觉基础模型以及更轻量级的Gemma进行比较，评估了该系统的视觉分类准确性、模型效率和生成输出（营养数据和食谱）的质量之间的权衡。测试数据集新开发了Custom Chinese Food Dataset (CCFD)，以解决公共数据集中存在的文化偏见问题。实验结果表明，EfficientNet-B4和Gemini分别提供了良好的准确性和效率以及最大质量的生成输出，但系统整体实用性受限于视觉前端感知准确性。这一调查基于详细的按类分析，识别出高语义相似性是最关键的失败模式。", "innovation": "本文的创新点在于引入了“语义错误传播”（SEP）的正式定义，用以分析视觉模块分类不准确如何影响生成输出的质量。此外，通过开发全新的Custom Chinese Food Dataset (CCFD)解决了公共数据集中存在的文化偏见问题，为食品识别系统提供了更广泛的适用性。同时，采用多重视觉基础模型和轻量级语言模型进行综合评估，展示了系统性能在不同模型之间的差异性。", "conclusion": "EfficientNet-B4和Gemini结合提供了一个强大的食品识别框架，但在实际应用中，视觉前端的感知准确性仍然是性能瓶颈。未来的工作将进一步优化视觉识别的部分，以实现更好的系统整体表现。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08240", "html_url": "https://arxiv.org/abs/2511.08240", "title": "通过原子点积操作符实现分层次的方向感知以学习旋转不变的点云", "title_en": "Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning", "authors": "Chenyu Hu,Xiaotong Li,Hao Zhu,Biao Hou", "background": "点云处理已成为许多3D视觉任务的基础技术。然而，随机旋转引入了点云方向性的变化，对有效的表示学习构成了长期挑战。点云的自然方向特性因旋转扰动而被破坏。最近的方法尝试隐式建模旋转不变性和等变性，从而保存方向信息并将其传播到深层语义空间。然而，它们往往未能充分利用点云的多尺度方向特性以增强特征表示。", "innovation": "提出了一种方向感知向量网络（DiPVNet）。它的核心是一个原子点积运算符，同时编码方向选择性和旋转不变性。在局部层面，引入了一个可学习的局部点积运算符（L2DP），它允许中心点与其邻居之间进行自适应的局部结构交互。在全局层面，利用广义谐波分析证明点云与球面采样向量之间的点积相当于方向感知的球面傅里叶变换（DASFT），从而构建了全局方向响应谱以建模整体方向结构。证明这两个运算符的旋转不变性。实验结果表明，DiPVNet在点云分类和分割任务上达到了最先进的性能。", "conclusion": "在具有噪声和大角度旋转等一系列挑战的情况下进行的广泛实验表明，DiPVNet在点云分类和分割任务上达到了最先进的性能。网络代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08251", "html_url": "https://arxiv.org/abs/2511.08251", "title": "LayerEdit：通过冲突感知多层学习实现解耦的多对象编辑", "title_en": "LayerEdit: Disentangled Multi-Object Editing via Conflict-Aware Multi-Layer Learning", "authors": "Fengyi Fu,Mengqi Huang,Lei Zhang,Zhendong Mao", "background": "文本驱动的多对象图像编辑旨在根据文本描述精确地修改图像中的多个对象，最近引起了极大的兴趣。现有工作主要遵循定位-修改的范式，专注于独立的对象定位和修改，而忽略了对象之间的关键交互。然而，这些工作忽略的对象间冲突区域的注意力纠缠实际上阻碍了对象间解耦编辑，在冲突区域导致对象内或对象间的修改约束或泄露。", "innovation": "提出了一种新的多层解耦编辑框架LayerEdit，这是一种无需训练的方法，通过精确的对象分层分解和一致融合，实现了冲突无对象层编辑。LayerEdit引入了一种新颖的“分解-编辑-融合”框架，包括：（1）冲突感知层分解模块，利用注意力感知的IoU方案和时间相关的区域移除，以增强层分解的冲突意识和抑制。（2）对象层编辑模块，用于建立协调的层内文本引导和跨层几何映射，实现语义和结构的解耦修改。（3）通过精确的透明度引导学习实现结构一致的对象层融合的透明度引导层融合模块。", "conclusion": "广泛的实验验证了LayerEdit在现有方法上的优越性，在复杂多对象场景中展示了前所未有的对象内可控性和对象间一致性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08263", "html_url": "https://arxiv.org/abs/2511.08263", "title": "基于ImageBind的多模态数据压缩方法ImageBindDC", "title_en": "ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation", "authors": "Yue Min,Shaobo Wang,Jiaze Li,Tianle Niu,Junxin Fan,Yongliang Miao,Lijin Yang,Linfeng Zhang", "background": "数据凝练技术旨在从大规模数据集中生成紧凑的数据集，以促进高效的模型训练。虽然在单模态设置中成功，但在需要保留复杂跨模态依赖关系的多模态场景中，它们往往失败。", "innovation": "引入了基于统一特征空间的ImageBindDC，这是一种新的数据凝练框架。它采用了强大的特征函数（CF）损失，能够在傅里叶域中通过精确的无限矩匹配促进统计对齐。方法包括三个关键级别的分布一致性：单模态对齐、跨模态对齐、以及联合模态对齐。", "conclusion": "在NYU-v2数据集上进行的广泛实验显示，ImageBindDC非常有效。仅使用5个凝练数据点进行训练的模型，在类别的性能方面与使用完整数据集的模型相当，达到了新的最佳状态，并实现了8.2%的绝对改进和4倍少的凝练时间。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08248", "html_url": "https://arxiv.org/abs/2511.08248", "title": "NERVE: 邻域与熵引导的随机游走方法在无需训练的开放词汇语义分割中的应用", "title_en": "NERVE: Neighbourhood & Entropy-guided Random-walk for training free open-Vocabulary sEgmentation", "authors": "Kunal Mahatha,Jose Dolz,Christian Desrosiers", "background": "尽管在开放词汇语义分割（OVSS）方面最近取得了进展，但现有的无需训练的方法仍然面临一些挑战，如使用计算成本高的关联细化策略、由于等权重或依赖固定大小的高斯核来强化局部空间平滑性而未能有效融合变压器注意力图、强迫各向同性邻域结构等。", "innovation": "本文提出了一种无需训练的OVSS的强基准方法，称为NERVE（基于邻域与熵引导的随机游走语义分割），在结合全局和细致局部信息方面具有独特优势，具体而言，它利用稳定扩散模型中自注意力层的邻域结构。此外，还引入了一种概率随机游走来细化关联性，而不是依赖固定大小的高斯核来提供局部上下文。这种空间扩散过程鼓励在连接和语义相关的区域之间传播，能够有效地区分任意形状的对象。不同于大多数现有方法将来自不同变压器头部或层的注意力图平等处理，本文的方法利用熵不确定性选择最相关图。此外，该方法不需要任何传统的后处理技术如条件随机场（CRF）或像素自适应掩膜细化（PAMR）。", "conclusion": "在7个流行的语义分割基准上进行了实验，结果显示NERVE方法在零样本分割性能方面达到了最先进的水平，提供了一种有效的开放词汇语义分割方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08258", "html_url": "https://arxiv.org/abs/2511.08258", "title": "Top2Ground：一种基于高度感知的双条件扩散模型，用于鲁棒的航拍图到地面视角生成", "title_en": "Top2Ground: A Height-Aware Dual Conditioning Diffusion Model for Robust Aerial-to-Ground View Generation", "authors": "Jae Joong Lee,Bedrich Benes", "background": "从航拍视角生成地平线级别的图像是一项具有挑战性的任务，原因在于视角的巨大差异、遮挡以及视野有限。现有方法通常依赖于中间表示（如深度图或3D体素），这限制了生成照片级逼真地平线视角图像的能力。", "innovation": "我们提出了Top2Ground，这是一种新型的基于扩散的方法，可以直接从航拍输入图像生成照片级逼真的地平线视角图像，无需使用深度图或3D体素等中间表示。具体来说，该方法将去噪过程的条件设置为VAE编码的空间特征（来自航拍RGB图像和估计的高度图）和CLIP基于的语义嵌入的联合表示。这种方法确保生成不仅受场景3D结构的几何约束，而且与内容语义一致。我们在CVUSA、CVACT和Auto Arborist三个不同的数据集上评估了Top2Ground。我们的方法在三个基准数据集上的平均SSIM改进了7.3%，这表明Top2Ground可以在宽视野和窄视野之间都表现出较强的鲁棒性和泛化能力。", "conclusion": "我们的方法在三个不同数据集上的表现表明Top2Ground可以在宽视野和窄视野之间都表现出较强的鲁棒性和泛化能力，并且可以获得7.3%的平均SSIM改进，这表明该方法可以有效地生成照片级逼真的地面视角图像。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08272", "html_url": "https://arxiv.org/abs/2511.08272", "title": "MAUGIF: 基于双跨图像自编码器的机制感知无监督通用图像融合", "title_en": "MAUGIF: Mechanism-Aware Unsupervised General Image Fusion via Dual Cross-Image Autoencoders", "authors": "Kunjing Yang,Zhiwei Wang,Minru Bai", "background": "图像融合旨在整合来自多种源图像的结构和互补信息。然而，现有的融合方法通常是高度任务特定的，或者是一些通用框架，在不同任务中采用统一策略，忽视了它们独特的融合机制。因此，为了应对这一问题，我们提出了一种基于双跨图像自编码器的机制感知无监督通用图像融合（MAUGIF）方法。", "innovation": "该方法通过双跨图像自编码器映射源图像进入共享的潜在空间，同时捕捉常见内容并隔离模态特定细节。双解码器在此过程中发挥特征注入作用，选择性地将每个模态的独特特征重新整合到共享内容中以构建融合图像。解码器的架构根据其融合机制的不同而变化，从而增强性能和可解释性。", "conclusion": "本研究进行了广泛的实验来验证我们的方法在不同融合任务中的有效性与泛化能力，并且相关代码可从指定链接获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08291", "html_url": "https://arxiv.org/abs/2511.08291", "title": "SynWeather: 多区域和变量的通用扩散变换器驱动的气象观测数据合成", "title_en": "SynWeather: Weather Observation Data Synthesis across Multiple Regions and Variables via a General Diffusion Transformer", "authors": "Kaiyi Xu,Junchao Gong,Zhiwang Zhou,Zhangrui Li,Yuandong Pu,Yihao Liu,Ben Fei,Fenghua Ling,Wenlong Zhang,Lei Bei", "background": "随着气象仪器的发展，丰富了气象数据的获取，当前方法多专注于单一变量和单一区域的任务，并主要依靠确定性建模。这种做法限制了跨变量和跨区域的统一综合，忽略了变量之间的互补性并导致了过度平滑的结果。", "innovation": "提出了SynWeather数据集，用于统一合成多地区和多变量的天气观察数据，并引入了基于扩散变换器框架的SynWeatherDiff通用概率天气合成模型，以解决过度平滑的问题。", "conclusion": "在SynWeather数据集上的实验表明了我们模型的有效性，相比特定任务和通用模型，我们的网络更为有效。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08271", "html_url": "https://arxiv.org/abs/2511.08271", "title": "SWAN - 通过可滑动界面实现快速移动组织病理图像注释", "title_en": "SWAN - Enabling Fast and Mobile Histopathology Image Annotation through Swipeable Interfaces", "authors": "Sweta Banerjee,Timo Gosch,Sara Hester,Viktoria Weiss,Thomas Conrad,Taryn A. Donovan,Nils Porsche,Jonas Ammeling,Christoph Stroblberger,Robert Klopfleisch,Christopher Kaltenecker,Christof A. Bertram,Katharina Breininger,Marc Aubreville", "background": "组织病理学图像数据集的注释是开发用于临床相关任务的稳健深度学习模型的主要瓶颈，比如有丝分裂图分类。基于文件夹的注释工作流通常速度慢、令人疲倦且难以扩展。", "innovation": "SWAN 是一个开源、MIT 许可的网页应用程序，通过滑动手势实现直观的图像切片分类。SWAN 支持桌面和移动平台，实现实时元数据捕获，并允许灵活地将滑动手势映射到类别标签.", "conclusion": "通过一项由四位病理学家进行的试点研究，在600个有丝分裂图图像切片分类任务中，SWAN 的注释速度更快，其双人百分比一致性从86.52%到93.68%(κ值为0.61-0.80)，与传统的文件夹排序方法相当(双人百分比一致性从86.98%到91.32%、κ值为0.63-0.75)。参与者认为该工具非常易用，并赞赏能够在移动设备上进行注释。这表明SWAN不仅能加速图像注释，还能保持高质量，并提供了一种可扩展且用户友好的替代传统工作流选项。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08269", "html_url": "https://arxiv.org/abs/2511.08269", "title": "重新编码以获取不确性：感知边缘的语义一致融合以增强事件-RGB分割鲁棒性", "title_en": "Re-coding for Uncertainties: Edge-awareness Semantic Concordance for Resilient Event-RGB Segmentation", "authors": "Nan Bao,Yifan Zhao,Lin Zhu,Jia Li", "background": "语义分割在理想条件下取得了巨大成功。但是在极端条件下（例如，光线不足，相机剧烈运动）大部分现有方法会大量丢失RGB信息，严重影响了分割结果。已有研究通过高速度高动态的事件模态弥补了这个缺陷，但事件模态与RGB是天生异构的，导致了特征层面的不对齐和现有跨模态方法的次级效果优化。多数研究集中在两种模态的深度融合，而本文提出了新的边缘共识框架，旨在统一多模态异构特征和潜在线索边缘线索，提升了在极端条件下的鲁棒性。该框架包含重新编码获得不确定性指标并调整事件-RGB特征到统一语义空间；利用新的边编码和不确定性指标解决极端条件下异构事件-RGB融合问题。实验结果表明，该方法在DERS-XS数据集上比现有最先进的方法提高了2.55%的mIoU，并有较强的对空间遮挡的鲁棒性。", "innovation": "提出了感知边缘的语义一致融合框架（Edge-awareness Semantic Concordance，ESC），重点在于跨模态特征重新编码与不确定性优化。首先，提出感知边缘的隐含重编解码，通过预设的边缘字典将事件-RGB分布转为对应的隐含重编码特征。接着，提出了重编码整合和不确定性优化方法，利用重编码后的边缘特征和不确定性指标来解决事件-RGB在极端条件下的异构融合问题。该方法设计了一种新的框架，使得模型能够更好地处理现实中的多种模态数据，增强了鲁棒性，特别是在缺少RGB信息的极端条件下。", "conclusion": "本文提出了感知边缘的语义一致融合框架，该框架能有效地解决极端条件下事件-RGB模态之间的融合问题，通过重新编码特征和不确定性优化显著提高了在空间遮挡等极端情况下的分割性能。未来可以考虑扩展到更多现实场景，并进一步提高模型泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08310", "html_url": "https://arxiv.org/abs/2511.08310", "title": "NeuSpring: 基于视频的柔体重建与模拟的神经弹簧场", "title_en": "NeuSpring: Neural Spring Fields for Reconstruction and Simulation of Deformable Objects from Videos", "authors": "Qingshan Xu,Jiao Liu,Shangshu Yu,Yuxuan Wang,Yuan Zhou,Junbao Zhou,Jiequan Cui,Yew-Soon Ong,Hanwang Zhang", "background": "现有方法更多地关注当前状态建模的物理学习，但在未来预测方面效果较差。这是因为现有方法忽视了柔体对象的内在物理属性，导致在当前状态建模中的物理学习受限。", "innovation": "1) 一种分段拓扑解决方案，利用零阶优化高效地建模多区域弹簧连接拓扑，同时考虑现实世界对象的材料异质性。\n2) 一种基于规范坐标下的神经弹簧场，能够跨不同帧表示弹簧的物理属性，有效地利用弹簧的空间关联性进行物理学习。", "conclusion": "实验结果表明，我们的NeuSpring在当前状态建模和未来预测方面实现了卓越的重建和模拟性能，与现有方法相比，均方差距离分别改善了20%和25%。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08334", "html_url": "https://arxiv.org/abs/2511.08334", "title": "通过对齐器和提示器增强DINO表示以实现水下实例分割", "title_en": "Empowering DINO Representations for Underwater Instance Segmentation via Aligner and Prompter", "authors": "Zhiyang Chen,Chen Zhang,Hao Fang,Runmin Cong", "background": "水下实例分割（UIS）是集成像素级理解和实例级区分的关键技术，对于海洋资源勘探和生态保护至关重要。近年来，由DINO等大规模预训练视觉基础模型在复杂下游任务中表现出显著性能。", "innovation": "该论文提出了DiveSeg框架，该框架基于两个关键组件：1. AquaStyle Aligner，嵌入水下颜色样式特征到DINO微调过程中，更好地适应水下环境；2. ObjectPrior Prompter，利用基于二分类分割的提示提供实例分割任务所需的对象和实例级别推理的前提。", "conclusion": "通过在流行的数据集UIIS和USIS10K上进行全面实验，结果显示DiveSeg达到了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08322", "html_url": "https://arxiv.org/abs/2511.08322", "title": "通过边距保留训练减轻负翻转", "title_en": "Mitigating Negative Flips via Margin Preserving Training", "authors": "Simone Ricci,Niccolò Biondi,Federico Pernici,Alberto Del Bimbo", "background": "在AI系统的各个版本中减少不一致性与降低整体错误一样至关重要。在图像分类中，这种不一致性表现为负面翻转：更新后的模型错误地重新分类了先前正确分类的测试样本。随着训练类别的增加，这个问题越来越严重，因为新增类别的引入会导致每个类别的差距减少，可能引入冲突的模式，从而削弱其学习过程，导致原始子集上的性能下降。", "innovation": "我们提出了一种新颖的方法，该方法在保留原始模型差距的同时学习改进模型。通过应用显式的差距校准项到logits上，该方法鼓励当前学习的类和新引入的类之间具有更大的相对差距。为避免新类的差距约束过度降低其准确性，我们引入了一个双来源焦点蒸馏损失，该损失结合了原有模型和新独立训练的模型，从而从旧数据和新数据中学习适当决定差距。", "conclusion": "在图像分类基准上的广泛实验表明，我们的方法能够一致地减少负面翻转，同时保持高总体准确性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08294", "html_url": "https://arxiv.org/abs/2511.08294", "title": "SkelSplat: 使用可微分高斯渲染实现稳健的多视图3D人体姿态估计", "title_en": "SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering", "authors": "Laura Bragagnolo,Leonardo Barcellona,Stefano Ghidoni", "background": "准确的3D人体姿态估计是增强现实和人机交互等应用的基础。现有的多视角方法通过大规模标注数据集训练以融合预测结果，但当测试场景发生变化时，会出现泛化能力差的问题。因此，需要一种新的方法来解决多视角融合问题，以提高人体姿态估计的准确性。", "innovation": "本文提出了一种名为SkelSplat的新框架，该框架基于可微分高斯渲染进行多视角3D人体姿态估计。该框架将人体姿态建模为每个关节一个的3D高斯骨架，并通过可微分渲染进行优化，以实现无需3D地面真实标注即可无缝融合任意相机视角。SkelSplat方法在Human3.6M和CMU数据集上优于依赖三维地面真实标注的方法，同时将跨数据集错误降低了47.8%。此外，该方法在Human3.6M-Occ和Occlusion-Person数据集上展示了对遮挡的鲁棒性，且无需场景特定的微调。", "conclusion": "SkelSplat方法通过利用可微分高斯渲染法，实现了多视角3D人体姿态估计的高性能和鲁棒性，显著提高了无地面真实标注情况下的估计精度。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08344", "html_url": "https://arxiv.org/abs/2511.08344", "title": "通过双视角不一致性学习实现开放集肌电图手势识别", "title_en": "Towards Open-Set Myoelectric Gesture Recognition via Dual-Perspective Inconsistency Learning", "authors": "Chen Liu,Can Han,Weishi Xu,Yaqi Wang,Dahong Qian", "background": "表面肌电图(sEMG)基于的手势识别在人机交互(HMI)中扮演着重要角色，特别在康复和假肢控制中。然而，sEMG基于的系统常常因为缺乏信息丰富的训练数据，导致深度学习模型过拟合和泛化能力差。数据增强提供了一种增加训练数据规模和多样性的方法，但如何确保生成样本的忠实性和多样性是关键。现有方法在促进未目标多样性的过程中可能会产生冗余样本，缺乏实用性。", "innovation": "该研究提出了一种新颖的基于扩散的数据增强方法，即Sparse-Aware Semantic-Guided Diffusion Augmentation (SASG-DA)。引入了语义表示引导(SRG)机制，利用细粒度的任务感知语义表示作为生成条件，以增强生成忠实性。提出了一种高斯建模语义建模(GMSS)策略，用于建模语义表示分布，并允许随机采样生成忠实和多样化的样本。为了增强目标多样性，引入了稀疏感知语义采样策略，明确探索未充分代表的区域，提高分布覆盖率和样本实用性。实验表明，SASG-DA在标准sEMG数据集Ninapro DB2、DB4和DB7上显著优于现有增强方法。", "conclusion": "通过SASG-DA方法，有效地缓解了过拟合问题，通过提供忠实和多样的样本，提高了识别性能和泛化能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08348", "html_url": "https://arxiv.org/abs/2511.08348", "title": "VideoChain：基于Transformer的多跳视频问题生成框架", "title_en": "VideoChain: A Transformer-Based Framework for Multi-hop Video Question Generation", "authors": "Arpan Phukan,Anupam Pandey,Deepjyoti Bodo,Asif Ekbal", "background": "当前的多跳问答（QG）主要用于文本，而视频问题生成（VideoQG）则仅限于生成单个视频片段上的零跳问题。这限制了其对需要跨多个时间上分离的视频片段进行推理问题的生成能力。现有框架需要改进以支持更复杂的多跳问题生成，从而评估更高的推理能力.", "innovation": "为了填补这一空白，作者提出了VideoChain，这是一个新颖的多跳视频问题生成（MVQG）框架。VideoChain利用一个修改过的BART主干模型，并增强视频嵌入，用于捕捉文本和视觉依赖性。此外，通过使用TVQA+数据集构建大规模的MVQ-60数据集，确保了可扩展性和多样性。这进一步改进了现有框架，能够处理复杂的多跳问题生成任务，提升推理能力评估的范围和深度.", "conclusion": "实验结果显示，VideoChain在标准生成指标（包括ROUGE-L、ROUGE-1、BLEU-1、BERTScore-F1和语义相似性）上表现优异，能够生成连贯、上下文引导且推理强度高的问题。这一成果表明，VideoChain是评估视频理解中复杂推理能力的有效工具，同时也展示了在多模态问题生成方面的重要进展。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08360", "html_url": "https://arxiv.org/abs/2511.08360", "title": "低精度下的结构稀疏性极简模型压缩", "title_en": "Extreme Model Compression with Structured Sparsity at Low Precision", "authors": "Dan Liu,Nikita Dvornik,Xue Liu", "background": "深度神经网络（DNNs）在许多应用中得到广泛应用，但由于其庞大的规模和高计算成本，在资源有限的设备上运行变得困难。为解决这一问题，常用的技术有两种：权重量化，通过降低所有权重的精度降低计算复杂度；及结构化稀疏，通过删除无关紧要的权重同时保留重要权重的精度，这种方法在处理稀疏性问题时更有效。虽然这两种方法单独使用时都有效，但将它们结合起来时，会显著降低模型的准确性。因此，这些技术单独分别研究更为常见。", "innovation": "该研究提出了SLOPE（结构稀疏性在低精度下），这是一种统一的框架，能够以一种原理性的方式结合结构化稀疏性与低比特量化。作者提出了一种训练时间正则化策略，通过促进角度对齐而不是直接匹配来最小化全精度权重与其稀疏的、量化的对应物之间的差异。实验表明，对于ResNet-18等模型，SLOPE实现了约20倍的模型尺寸减少，同时保留了约99%的原始准确率，并且在分类、检测和分割任务上均优于当前最先进的量化和结构化稀疏技术。", "conclusion": "SLOPE框架有效结合了低比特量化和结构稀疏性，克服了直接结合这两种技术造成的性能下降问题。实验结果表明，SLOPE在保持高准确性的同时，显著减小了模型尺寸。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08368", "html_url": "https://arxiv.org/abs/2511.08368", "title": "A Circular Argument : Does RoPE need to be Equivariant for Vision?", "title_en": "A Circular Argument : Does RoPE need to be Equivariant for Vision?", "authors": "Chase van de Geijn,Timo Lüddecke,Polina Turishcheva,Alexander S. Ecker", "background": "Rotary Positional Encodings (RoPE) 已经成为自然语言处理中处理一维序列的有效技术，并推动了该技术向处理高维度数据（如图像和视频）的泛化。RoPE 的成功被认为归因于其位置不变性，即其作为相对位置编码的特点。", "innovation": "作者通过数学证明，表明 RoPE 是一维数据中位置不变嵌入的最通用解决方案之一。他们还提出了 Mixed RoPE 作为 M 维数据中的通用解决方案，前提是需要可交换生成器。进一步提出了 Spherical RoPE 作为一种类似 Mixed RoPE 的方法，但假设非可交换生成器，实证结果表明 Spherical RoPE 与其对称性同态相比具有相当或更好的学习行为。这表明相对位置嵌入没有人们通常认为的那么重要。", "conclusion": "研究发现相对位置编码并不像通常认为的那样重要，至少在计算机视觉领域是如此。这一发现有望促进未来去除对位置编码必须为相对编码的预设，从而加快工作速度并提高泛化能力的研究。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08365", "html_url": "https://arxiv.org/abs/2511.08365", "title": "使用分离嵌入的MRI回顾性运动校正", "title_en": "Retrospective motion correction in MRI using disentangled embeddings", "authors": "Qi Wang,Veronika Ecker,Marcel Früh,Sergios Gatidis,Thomas Küstner", "background": "生理运动会影响磁共振成像（MRI）的诊断质量。尽管存在多种回顾性运动校正方法，但许多方法难以在不同类型的运动和身体区域之间泛化。尤其是基于机器学习的校正通常针对特定的应用程序和数据集进行定制。本研究假设虽然运动伪影多种多样，但它们背后存在可分离和利用的模式。", "innovation": "提出了一种层次矢量量化（VQ）变分自动编码器，学习运动到干净图像特征的分离嵌入。部署了代码本以在多个分辨率上捕捉有限的运动模式集合，实现粗细级别的校正。训练一个自回归模型，学习运动自由图像的先验分布，并在推理过程中用于引导校正过程。与传统的基于切片的校正不同，本方法无需针对特定伪影进行训练，可以泛化到未见过的运动模式。", "conclusion": "在模拟全身运动伪影上展示了该方法，观察到在不同运动严重程度下表现出鲁棒的校正效果。结果表明，该模型有效分离了模拟运动影响扫描的物理运动特征，从而提高了基于机器学习的MRI运动校正的泛化能力。本工作的运动特征分离为进一步跨解剖区域和运动类型的应用提供了启示。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08328", "html_url": "https://arxiv.org/abs/2511.08328", "title": "纵向乳房X光片对乳腺癌风险评估的影响", "title_en": "The Impact of Longitudinal Mammogram Alignment on Breast Cancer Risk Assessment", "authors": "Solveig Thrun,Stine Hansen,Zijun Sun,Nele Blum,Suaiba A. Salahuddin,Xin Wang,Kristoffer Wickstrøm,Elisabeth Wetzer,Robert Jenssen,Maik Stille,Michael Kampffmeyer", "background": "定期的乳房X光筛查对于早期发现乳腺癌至关重要。通过利用基于深度学习的风险模型，筛查间隔可以个性化，尤其是针对高风险个体。虽然最近的方法越来越多地结合了之前乳房X光的纵向信息，但时点间准确的空间对齐仍然是一个关键挑战。不正确的对齐会掩盖有意义的组织变化，从而降低模型性能。因此，本研究探讨了各种对齐策略，包括基于图像的注册、基于特征的空间对齐以及隐式对齐方法，评估它们在纵向深度学习风险建模中的有效性。通过两个大规模的乳房X光片数据集，研究了每种方法在关键指标（包括预测准确性、精确度、召回率和变形场质量）方面的表现。结果显示，基于图像的注册在所有指标上表现始终优于较新的基于特征和隐式方法，从而实现了更准确且时间上的一致预测，并生成了平滑且解剖上合理的变形场。虽然正则化变形场可以提高变形质量，但它会降低基于特征的空间对齐的预测性能。将基于图像的变形场应用于特征空间可以实现最佳的风险预测性能。这些发现强调了在纵向风险建模中基于图像变形场的重要性，这可以提高预测准确性和鲁棒性，并有望增强个性化筛查并为高风险个体提供早期干预措施。研究代码可通过以下链接访问，从而实现结果的完全可重复性：https://github.com/analytics-paper-reviews/Longitudinal-Mammogram-Alignment-Impact-Study", "innovation": "本研究通过探讨基于图像的注册、基于特征的空间对齐以及隐式对齐方法，评估它们在纵向深度学习风险建模中的有效性。研究结果表明，基于图像的注册方法在所有关键指标上表现始终优于较新的基于特征和隐式方法。此外，将基于图像的变形场应用于特征空间可以实现最佳的风险预测性能。这些发现强调了基于图像变形场在纵向风险建模中的重要性，这可以提高预测准确性和鲁棒性。", "conclusion": "这些研究结果表明，在纵向风险建模中使用基于图像的变形场对于提高预测准确性和鲁棒性至关重要。研究的创新性在于通过系统比较各种对齐方法的效果，揭示了在高风险人群中实现精准筛查的有效策略，这有望指导未来的个性化乳腺癌筛查和早期干预措施。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08369", "html_url": "https://arxiv.org/abs/2511.08369", "title": "基于文本的空中和地面人员检索", "title_en": "Text-based Aerial-Ground Person Retrieval", "authors": "Xinyu Zhou,Yu Wu,Jiayao Ma,Wenhao Wang,Min Cao,Mang Ye", "background": "传统的基于文本的人像检索(T-PR)主要关注地面视角图像。然而，在实际应用中，人们可能需要在既有空中视角又有地面视角的图像中根据文本描述检索人像。这提出了新的挑战，因为不同视角之间的视点差异较大，使得跨视角的检索变得困难。为此，本文提出了基于文本的空中和地面人像检索(TAG-PR)，通过构建一个新数据集TAG-PEDES和一个新颖的检索框架TAG-CLIP来解决这个问题。", "innovation": "1. 构建了名为TAG-PEDES的新数据集，该数据集包含了来自公开基准的数据，并通过使用多样化文本生成方法自动添加文本描述，确保数据集在不同视角下的鲁棒性。\n2. 提出了一个名为TAG-CLIP的新检索框架，通过层次路由混合专家模块来学习特定视角和非特定视角的特征，同时也通过视角解耦策略来更好地分离特定视角的特征以促进跨模态对齐，以解决视点差异问题。\n3. 在提出的数据集TAG-PEDES和现有的T-PR基准上评估了TAG-CLIP的有效性，展示了其在跨视角检索任务中的优势。", "conclusion": "本文通过构建TAG-PEDES数据集并提出TAG-CLIP框架，有效解决了因视点差异带来的基于文本的人像检索问题。所提出的TAG-CLIP框架在标准测试数据集上表现出色，为未来的跨视角检索研究提供了新的思路和数据支持。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08387", "html_url": "https://arxiv.org/abs/2511.08387", "title": "RAPTR：使用变压器的雷达基础3D姿态估计", "title_en": "RAPTR: Radar-based 3D Pose Estimation using Transformer", "authors": "Sorachi Kato,Ryoma Yataka,Pu Perry Wang,Pedro Miraldo,Takuya Fujihashi,Petros Boufounos", "background": "传统的基于雷达的室内3D人体姿态估计依赖于精细的3D关键点标签，这些标签在复杂室内环境中，尤其是在存在杂乱、遮挡或多人的情况下非常昂贵且难以获取。本文研究了在弱监督下使用仅有的3D边界框和2D关键点标签进行雷达基础3D人体姿态估计的方法，改进了标签获取的难易程度和可扩展性。弱监督方法使其能在不依赖昂贵的3D关键点标签的情况下进行姿态估计，提高了在复杂环境中的实用性与效率。", "innovation": "提出了一种名为RAPTR（RAdar Pose esTimation using tRansformer）的两阶段姿态解码器架构，结合了伪3D变形注意力机制，增强了基于多视角雷达特征的（姿态/关节）查询。首先，3D模板损失利用3D边界框标签估计初始3D姿态并缓解深度歧义；其次，3D重力损失结合2D关键点标签进行初始姿态的细化。该方法经HIBER和MMVR两个室内雷达数据集评估优于现有方法，关键点位置误差分别降低34.3%和76.9%。", "conclusion": "本文提出的RAPTR方法，在弱监督条件下，仅使用3D边界框和2D关键点标签即实现了高精度的3D姿态估计。在两个室内雷达数据集上的实验结果表明，与现有方法相比，该方法具有显著的性能优势。为此类应用提供了一种更有效、更实用的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08423", "html_url": "https://arxiv.org/abs/2511.08423", "title": "全景AID：分解语义与艺术特征以实现具有普遍性的AI生成图像检测", "title_en": "OmniAID: Decoupling Semantic and Artifacts for Universal AI-Generated Image Detection in the Wild", "authors": "Yuncheng Guo,Junyan Ye,Chenjue Zhang,Hengrui Kang,Haohuan Fu,Conghui He,Weijia Li", "background": "当前最先进的AI生成图像（AIGI）检测方法需要同时针对多种生成模型和不同的语义内容进行泛化，但它们学习的是单一、相互纠缠的伪造表示，混杂了依赖内容的缺陷和无依赖内容的伪影。此外，这些方法受到过时基准的限制，缺乏有效的对手。（背景概括了当前研究存在的问题和局限性）", "innovation": "本文提出了一种名为OmniAID的创新框架，以解决上述问题。其核心是一个解耦的混合专家系统，该系统专门针对不同内容领域和不同依赖内容的缺陷与无依赖内容的通用伪影进行分解。此系统通过一套可路由的专业语义专家和固定的通用伪影专家实现。OmniAID采用一种定制的两阶段训练策略：先独立训练专家进行领域特定的强化学习以确保专业化，随后训练一个轻量级门控网络实现输入路由。这种方法通过明确解耦生成的内容（特定内容缺陷）与生成过程（通用伪影）实现了稳健的泛化。（总结本文的主要创新点）", "conclusion": "通过引入旨在适配现代欺诈威胁的新基准Mirage，本文展示了OmniAID 在理论和实际场景中的优越性，并形塑了一个新的、稳健的标准来对AI生成图像进行验证。（总结了本文的主要研究发现及其对未来的潜在影响）"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08402", "html_url": "https://arxiv.org/abs/2511.08402", "title": "Anatomy-VLM: 一种细粒度的视觉语言模型用于医学解读", "title_en": "Anatomy-VLM: A Fine-grained Vision-Language Model for Medical Interpretation", "authors": "Difei Gu,Yunhe Gao,Mu Zhou,Dimitris Metaxas", "background": "准确解读医学影像中的疾病仍然具有挑战性，因为影像存在异质性。达到专家级的诊断决策需要将细微的影像特征与临床知识相结合。然而，现有的视觉-语言模型（VLMs）将影像视为整体，并忽视了诊断疾病时至关重要的细粒度影像细节。临床医生在利用先验医学知识分析影像时，识别出解剖结构作为重要区域。受这种以人类为中心的工作流程启发，我们引入了 Anatomy-VLM，这种细粒度的视觉语言模型结合了多尺度信息。首先，我们设计了一个模型编码器以从整个医学影像中定位关键的解剖特征。其次，这些区域通过结构化的知识进行丰富，以实现上下文感知的解释。最后，模型编码器对多尺度的医学信息进行对齐，生成具有临床解读能力的疾病预测。", "innovation": "Anatomy-VLM 模型通过多尺度信息整合和细粒度解剖特征的识别与理解，突破了现有的视觉-语言模型对影像细节的忽视。它通过模型编码器的结构设计，将解剖结构作为关键区域，结合结构化的知识，实现上下文感知的解释，生成具有临床解读能力的疾病预测。", "conclusion": "Anatomy-VLM 在分布内和分布外的数据集上都表现出色，且其编码器在下游图像分割任务中的性能验证表明其细粒度对齐能够捕捉解剖学和病理学相关的知识。此外，Anatomy-VLM 的编码器还支持零样本的解剖学解释，提供其强大的临床解读能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08435", "html_url": "https://arxiv.org/abs/2511.08435", "title": "跨金字塔一致性正则化在半监督医学图像分割中的应用", "title_en": "Cross-pyramid consistency regularization for semi-supervised medical image segmentation", "authors": "Matus Bojko,Maros Kollar,Marek Jakab,Wanda Benesova", "background": "半监督学习(SSL)允许在假设少量仔细标记的数据和大量未标记数据的支持下，训练强大的模型。本文着重解决在半监督的医疗图像分割任务中如何有效利用未标记数据的问题。", "innovation": "提出了一种混合一致性学习方法，通过跨金字塔一致性正则化(CPCR)在两个解码器之间结合现有的一致性和不确定性最小化方法，设计了一种混合双分支金字塔网络(DBPNet)，该网络由编码器和两个轻微不同的解码器组成，每个解码器在多个尺度上生成perturbed辅助预测的金字塔。此外，还提出了一种新的正则化项，将软标签设置扩展到底部金字塔预测，以支持深度层次特征的知识提炼。", "conclusion": "DBPNet与CPCR在公共基准数据集上的实验结果表明，它超越了五种最先进的自我监督学习方法，并且在性能方面与最近的方法相当。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08465", "html_url": "https://arxiv.org/abs/2511.08465", "title": "通过统一数据集和Faster R-CNN实现可移植的血细胞检测", "title_en": "Generalizable Blood Cell Detection via Unified Dataset and Faster R-CNN", "authors": "Siddharth Sahay", "background": "本文介绍了用于自动分类和检测显微镜下外周血细胞（PBCs）的综合方法和性能比较分析。针对数据稀缺性和异质性这一关键挑战，首先开发了稳健的数据管道来标准化并合并四个公开数据集（PBC、BCCD、Chula、镰状细胞病数据集）为统一资源。然后使用先进的Faster R-CNN目标检测框架，并基于ResNet-50-FPN骨干网络。", "innovation": "研究通过开发一个统一的数据集和采用先进的Faster R-CNN目标检测框架，结合ResNet-50-FPN主干网络，进行了针对随机初始化基准模型（方案1）和迁移学习的初始化导入预训练模型（方案2）的比较实验。结果表明，迁移学习方法实现了更快的收敛速度和更优的稳定性，最终验证损失为0.08666，显著优于基准模型。", "conclusion": "该研究验证的方法为构建高精度且可部署的自动化血液诊断系统奠定了坚实的基石。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08464", "html_url": "https://arxiv.org/abs/2511.08464", "title": "对比集成梯度：一种用于解释全切片图像分类的功能归因方法", "title_en": "Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification", "authors": "Anh Mai Vu,Tuan L. Vo,Ngoc Lam Quang Bui,Nam Nguyen Le Binh,Akash Awasthi,Huy Quoc Vo,Thanh-Huy Nguyen,Zhu Han,Chandra Mohan,Hien Van Nguyen", "background": "全切片图像（WSI）分析在计算病理学中至关重要，模型预测的理解可以帮助建立AI辅助诊断的信任。尽管集成梯度（IG）和相关归因方法表现出潜力，但由于WSI的高度分辨率特性，直接应用于WSI会带来挑战。这些方法捕捉了模型决策模式，但可能会忽略区分肿瘤亚型的关键类区分信号。", "innovation": "本文提出了对比集成梯度（CIG），这是一种新颖的归因方法，通过在logit空间中计算对比梯度来增强可解释性。CIG能够通过将特征重要性相对于参考类进行比较来突出显示类区分区域，提供更清晰的肿瘤和非肿瘤区域之间的区分。此外，CIG满足集成归因的公理，确保一致性和理论上的坚固性。此外，作者还提出了两种归因质量指标MIL-AIC和MIL-SIC，用于衡量系统在访问显着区域时如何进化，并特别适用于弱监督情况。", "conclusion": "实验结果表明，CIG能够在定量（通过MIL-AIC和MIL-SIC）和定性（通过与真实肿瘤区域紧密对齐的可视化）方面提供更具有信息性的归因，从而突显了其在可解释和可信的WSI基于诊断方面的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08480", "html_url": "https://arxiv.org/abs/2511.08480", "title": "压缩然后匹配：大规模预训练阶段后的一种高效多模态嵌入预训练范式", "title_en": "Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding", "authors": "Da Li,Yuxiao Luo,Keping Bi,Jiafeng Guo,Wei Yuan,Biao Yang,Yan Wang,Fan Yang,Tingting Gao,Guorui Zhou", "background": "视觉-语言模型通过获取可迁移的语义嵌入，极大地增强了跨模态检索、聚类和分类等多种视觉-语言任务的性能。有效的嵌入不仅要全面保留输入的语义内容，同时还要突出适合下游任务的差异性特征。最近的研究表明，通过大规模对比学习，视觉语言模型（VLMs）可以被适配成竞争性的嵌入模型，使对比学习在两个互补目标上同时优化成为可能。", "innovation": "本文提出了CoMa（Compressed pre-training phase），这是一种压缩预训练阶段的方法，用作对比学习的预热阶段。实验证明，即使是少量的预训练数据也能将视觉语言模型转变为竞争性的嵌入模型。CoMa在与规模相当的视觉语言模型上实现了在效率和效果上的优化。", "conclusion": "CoMa能够在仅使用少量预训练数据的情况下，将视觉语言模型转变为竞争性的嵌入模型，并在MMEB基准测试中取得了新的最佳成果。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08536", "html_url": "https://arxiv.org/abs/2511.08536", "title": "3D4D：通过3D视频生成的交互式可编辑4D世界模型", "title_en": "3D4D: An Interactive, Editable, 4D World Model via 3D Video Generation", "authors": "Yunhong He,Zhengqing Yuan,Zhengzhong Tu,Yanfang Ye,Lichao Sun", "background": "本文介绍了3D4D系统，这是一个利用WebGL和Supersplat渲染技术的交互式4D可视化框架。该系统通过四个核心模块将静态图像和文本转换为连贯的4D场景，并采用视网膜渲染策略实现高效的实时多模交互。该框架使用户能够主动探索复杂的4D环境。", "innovation": "3D4D引入了视网膜渲染策略来实现高效的实时多模交互，并通过四个核心模块将静态图像和文本转换为连贯的4D场景，从而适应用户驱动的4D环境探索。", "conclusion": "该框架使用户能够主动探索复杂的4D环境，同时支持实时多模交互和自定义内容编辑。相关内容可以通过该项目页面和代码获得。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08535", "html_url": "https://arxiv.org/abs/2511.08535", "title": "大型手语模型：向三维美国手语翻译迈进", "title_en": "Large Sign Language Models: Toward 3D American Sign Language Translation", "authors": "Sen Zhang,Xiaoxiao He,Di Liu,Zhaoyang Xia,Mingyu Zhao,Chaowei Tan,Vivian Li,Bo Liu,Dimitris N. Metaxas,Mubbasir Kapadia", "background": "当前的手语识别方法大多依赖于2D视频，而现有的模型无法充分利用3D手语数据中丰富的空间、手势和深度信息，导致识别和翻译准确性较低。因此，迫切需要一种能够直接处理3D手语数据并增强数字通信无障碍性的新框架。", "innovation": "本文提出了一种新型框架——大型手语模型（LSLM），利用大型语言模型（LLMs）作为基础架构，直接处理3D手语数据以捕捉丰富的空间、手势和深度信息。此外，该工作探讨了将复杂的身体参与式多媒体语言集成到LLMs的处理能力中，超越了纯文本输入，拓宽了对人类交流的理解。该模型还支持直接从3D手势特征到文本的翻译，以及由外部提示指导的翻译，增加了灵活性。", "conclusion": "本文为构建包容性的、多模态的智能系统奠定了基础，该系统能够理解各种语言形式，有助于听力障碍者的虚拟通信更加准确和可靠。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08509", "html_url": "https://arxiv.org/abs/2511.08509", "title": "CT图像中基于分层稀疏采样和残差变换器的快速多器官精细分割", "title_en": "Fast Multi-Organ Fine Segmentation in CT Images with Hierarchical Sparse Sampling and Residual Transformer", "authors": "Xueqi Guo,Halid Ziya Yerebakan,Yoshihisa Shinagawa,Kritika Iyer,Gerardo Hermosillo Valadez", "background": "三维医学图像的多器官分割在各种临床自动化流程中有重要应用，尽管深度学习已经在这一领域取得了卓越的性能，但由于使用神经网络逐像素分割整个三维体积会消耗大量时间和内存。对于某些有特定兴趣点的情况，已经开发了分类器，但速度与准确性之间的权衡问题依然存在。因此，本文提出了一个利用分层稀疏采样和残差变换器的新颖快速多器官分割框架。这种策略可以通过利用多个分辨率级别保留有意义的分层上下文来成功减少计算时间，同时保持低计算成本。该分割网络架构可以在稀疏描述符的不同信息级别中提取和结合信息，但同时保持低计算成本。", "innovation": "提出了一个结合分层稀疏采样和残差变换器的快速多器官分割框架。分层稀疏采样策略可以减少计算时间，同时保留有意义的分层上下文，利用多个分辨率级别。残差变换器能够从稀疏描述符的不同信息级别中提取和结合信息，同时保持低计算成本。该方法在内部数据集和公共数据集TotalSegmentator上的测试表明，与当前的快速器官分类器相比，它可以显著提高定性和定量分割性能，并且在CPU硬件上的速度达到了约2.24秒，具备实时精细器官分割的潜力。", "conclusion": "该分割框架在保持高精度的同时，显著减少了计算时间和资源消耗，对于临床自动化管道中的多器官分割具有重要的实际应用价值。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08512", "html_url": "https://arxiv.org/abs/2511.08512", "title": "CleverBirds: 针对细粒度人类知识追踪的多项选择基准", "title_en": "CleverBirds: A Multiple-Choice Benchmark for Fine-grained Human Knowledge Tracing", "authors": "Leonie Bossemeyer,Samuel Heinrich,Grant Van Horn,Oisin Mac Aodha", "background": "在许多专家领域，掌握细粒度的视觉识别需要专家投入多年的专业训练。人类在复杂细粒度分类方面如何获得专业技能依然难以建模，准确推断学习者知识状态对于理解视觉学习至关重要。eBird 平台上的社区科学项目收集了大量关于鸟类识别的知识，提供了理解个体如何通过长时间练习获得复杂细粒度分类技能的视角。已有超过40,000名参与者通过了包含超过1700万个问题的问题测试，涵盖超过10,000种鸟类。这些数据展示了学习过程中的长期学习模式。", "innovation": "提出了CleverBirds，一个大规模的知识追踪基准，用于细粒度鸟类物种识别。该基准利用eBird平台上社区科学项目的大量数据，以更好地理解个体如何通过长时间练习获得复杂细粒度分类的专业技能。CleverBirds是同类最大规模的数据集，提供了更多的可学习概念，有助于新方法的开发与评估。我们发现，跟踪学习者知识状态尤其具有挑战性，尤其是在参与者亚组和问题类型方面，不同的上下文信息有不同的预测效果。", "conclusion": "CleverBirds为研究视觉专业技能如何随时间和个体发展提供了新的途径，其包含的数据量庞大，可支持更多关于视觉知识追踪方法的研究开发和评估。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08521", "html_url": "https://arxiv.org/abs/2511.08521", "title": "UniVA：开源下一代通用视频代理", "title_en": "UniVA: Universal Video Agent towards Open-Source Next-Generation Video Generalist", "authors": "Zhengyang Liang,Daoan Zhang,Huichi Zhou,Rui Huang,Bobo Li,Yuechen Zhang,Shengqiong Wu,Xiaohan Wang,Jiebo Luo,Lizi Liao,Hao Fei", "background": "现有的专业AI模型在孤立视频任务如生成或理解方面表现出色，但在实际应用中，却需要复杂的迭代工作流程来结合这些能力。目前的单功能模型或单一视频-语言模型不足以支撑此类复杂的视频工作流程，特别是在文本/图像/视频条件下的生成、多轮编辑、对象分割和合成等流程变得非常繁琐和复杂。", "innovation": "UniVA是一种开源的、全能型的多代理框架，专注于下一代视频通用代理。UniVA通过将理解、分割、编辑和生成等视频能力统合到一致的工作流程中，解决上述问题。UniVA采用计划和行动的双代理架构，其中计划代理负责解释用户意图并将任务分解为结构化的视频处理步骤，执行代理则通过模块化的工具服务器执行这些任务中的每一个。UniVA通过多层次的递归记忆（全局知识、任务上下文和用户偏好）保持长期推理、情境连贯性和代理间通信，使得视频制作具有交互性和自反思性，同时保证全程可追溯。UniVA的设计使得即使是在任何条件下的迭代视频工作流（例如，基于文本/图像/视频条件生成 → 多轮编辑 → 对象分割 → 组成式合成）都可以轻松实现，这些通过单一功能模型或单一视频-语言模型是难以实现的。此外，UniVA还引入了UniVA-Bench，这是一个多重步骤视频任务基准套件，涵盖了理解、编辑、分割和生成等方面，用于严格测试此类代理视频系统。", "conclusion": "UniVA和UniVA-Bench均为全开源，旨在推动交互、代理和通用视频智能的研究，为下一代多模态AI系统的开发提供支持。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08549", "html_url": "https://arxiv.org/abs/2511.08549", "title": "基于Vision Transformer的用户设备定位", "title_en": "Vision Transformer Based User Equipment Positioning", "authors": "Parshwa Shah,Dhaval K. Patel,Brijesh Soni,Miguel López-Benítez,Siddhartan Govindasamy", "background": "近年来，深度学习技术被用于用户设备(Ud备)定位。然而，现有的模型存在局限性：它们对整个输入赋予了相同的注意力；它们不适用于非序列数据，例如仅当有瞬时信道状态信息(CSI)时。这限制了它们在实际应用场景中的表现，尤其是在只有瞬时CSI数据的情况下。针对这些问题，本文提出了一种基于注意力机制的Vision Transformer (ViT)架构，特别关注CSI矩阵中的角度延迟图谱(ADP)。", "innovation": "所提出的ViT架构通过关注CSI矩阵中的角度延迟图谱(ADP)，对瞬时CSI数据进行了优化处理。该方法在`DeepMIMO'和`ViWi'射线跟踪数据集上进行了验证，结果显示，在室内深度MIMO场景中，均方根误差(RMSE)为0.55米；在室外深度MIMO场景中，RMSE为13.59米；在ViWi室外遮挡场景中，RMSE为3.45米。相比现有最先进的方案，该方法性能提升了约38%。与其他我们考虑的方法相比，该方案在错误距离分布上表现更为优秀。", "conclusion": "提出的基于ViT的用户设备定位方案在室内和室外不同场景中都取得了较好的定位性能，尤其在只有瞬时CSI数据的情况下，具有显著优势，相较于最先进的方案性能有所提升。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08545", "html_url": "https://arxiv.org/abs/2511.08545", "title": "RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses", "title_en": "RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses", "authors": "Sriram Srinivasan,Gautam Ramachandra", "background": "准确从多视图图像重建3D模型对于机器人导航、操作和环境理解等下游任务至关重要。然而，在现实世界场景中，即使已知标定参数，精确估计相机姿态依然具有挑战性。现有的基于NeRF的方法通常依赖于准确的外参估计，而他们的隐式体素表示与广泛采用的多边形网格存在显著差异，导致渲染和操作在标准3D软件中效率低下。因此，在噪声外参的条件下进行稳健的3D网格重建具有重要意义和挑战性。", "innovation": "本文提出了一种鲁棒框架，可以直接从多视图图像中重建高质量且可编辑的3D网格，即使在存在噪声外参的情况下也能实现这一目标。该方法联合优化相机姿态并学习可捕捉精细几何细节和真实图像的隐式场景表示。所生成的网格与常见的3D图形和机器人工具兼容，使得后使用更为高效。实验表明，该方法在姿态不确定性下能实现准确且鲁棒的3D重建，从而在神经隐式表示和实际机器人应用之间架起桥梁。", "conclusion": "本文通过构建鲁棒框架RePose-NeRF，成功实现了在噪声外参条件下高质量3D网格的重建。此方法不仅提高了重建的准确性与鲁棒性，还使得3D模型与现有3D工具和机器人技术兼容，拓宽了神经隐式表示技术在实际机器人应用场景中的应用范围。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08573", "html_url": "https://arxiv.org/abs/2511.08573", "title": "SENCA-st: 结合交叉注意共享编码器整合空间转录组学和组织学进行癌症病理中区域识别", "title_en": "SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology", "authors": "Shanaka Liyanaarachchi,Chathurya Wijethunga,Shihab Aaquil Ahamed,Akthas Absar,Ranga Rodrigo", "background": "空间转录组学是一种新兴领域，通过基因表达的空间分布来识别功能性区域。整合空间转录组学中的功能性信息与组织学图像的结构信息被认为是识别与癌症药物耐药性相关的肿瘤亚结构的重要研究领域。现有的组织学-空间转录组学区域分割方法在处理空间转录组学数据时过于强调空间转录组学特征，或者过分强调组织学图像的功能信息而忽视了结构信息，导致模型要么陷入空间转录组学噪音的泥沼，要么过度平滑，从而丢失关键信息。", "innovation": "本文提出了一个新的架构SENCA-st（共享编码器与邻域交叉注意），该架构能够保留两种模态的特征，并且还能够利用交叉注意机制强调组织学上结构相似但在空间转录组中功能不同的区域，有效克服了现有方法的缺点，提高了检测肿瘤异质性和肿瘤微环境区域的能力，超越了现有最先进的方法。", "conclusion": "本研究提出的SENCA-st模型展示了其在检测肿瘤异质性和肿瘤微环境识别中的优越性能，同时强调了对结构相似但功能不同的区域的建模能力，这在临床中具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07471", "html_url": "https://arxiv.org/abs/2511.07471", "title": "个性化量子联邦学习在异常检测中的应用", "title_en": "Towards Personalized Quantum Federated Learning for Anomaly Detection", "authors": "Ratun Rahman,Sina Shaham,Dinh C. Nguyen", "background": "在视频监控、医疗诊断和工业监控等应用场景中，异常检测具有重要意义，但现实中异常数据往往依赖于上下文且标注数据有限。现有的量子联邦学习（QFL）通过分散地在多个量子客户端上进行模型训练，解决了中心化量子存储和处理的问题。然而，在实际的量子网络中，各个客户端在硬件能力、电路设计、噪声水平和经典数据到量子态的编码或预处理方面存在差异，导致不同客户端间固有地存在异质性，不仅在于数据分布，还在于量子处理行为。单一全球模型的训练效果因此不佳，尤其是处理不平衡或非同分布（Non-IID）数据时。", "innovation": "提出了一种新的框架——个性化量子联邦学习（Personalized Quantum Federated Learning, PQFL），该框架在量子客户端上增强了局部模型训练，使用参数化量子电路和经典优化器进行个性化调整，使每个客户端的模型适应其自身硬件特性和数据表示。实验证明，PQFL在不同且现实条件下显著提高了异常检测精度，相较于最先进的方法，PQFL将假误减少高达23%，AUPRC提升24.2%，AUROC提升20.5%，突显了其实用性和可扩展性。", "conclusion": "PQFL能在各种实际量子联邦设置中有效提高异常检测的准确性，尤其是处理非同分布数据的情景下。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07717", "html_url": "https://arxiv.org/abs/2511.07717", "title": "RoboTAG：通过拓扑对齐图进行端到端机器人配置估计", "title_en": "RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph", "authors": "Yifan Liu,Fangneng Zhan,Wanhua Li,Haowen Sun,Katerina Fragkiadaki,Hanspeter Pfister", "background": "单目RGB图像估计机器人姿态是机器人学和计算机视觉领域的一大挑战。现有的方法通常在2D视觉骨干网络上构建网络，并且很大程度上依赖标记数据进行训练，而在实际场景中这样的标记数据往往是稀缺的，造成了从仿真到现实的差距。此外，这些方法将基于3D的问题归结到2D领域，忽略了3D的先验知识。", "innovation": "提出了一种名为RoboTAG的3D分支与2D分支相结合的方法，以注入3D先验信息的同时促进2D和3D表示的共同进化，减少对标签的依赖。具体来说，RoboTAG通过将节点表示为相机和机器人系统的状态以及边捕捉变量之间的依赖关系或表示它们之间的对齐关系来构建图形。在图中定义闭环，然后在分支之间应用一致性监督。这种设计使得可以在没有注释的情况下利用野生图像作为训练数据。", "conclusion": "实验结果表明，该方法在多种机器人类型上都有效，突显了其在解决机器人领域数据瓶颈方面的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07700", "html_url": "https://arxiv.org/abs/2511.07700", "title": "皮肤癌检测算法公平性基准中校准的作用", "title_en": "On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection", "authors": "Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy", "background": "人工智能模型在黑色素瘤检测方面表现出色，但在临床上的应用受到不同人口亚群（如性别、种族和年龄）性能差异的限制。之前的努力主要集中在使用基于AUROC的分组公平性指标来评估模型性能，但这些方法没有提供模型准确度的洞察。为了更好地反映临床评估，该研究通过引入校准作为AUROC公平性指标的补充基准指标来填补这一空白。校准评估预测概率与实际事件率之间的对齐情况，为亚群偏差提供了更深入的见解。", "innovation": "该研究引入了将校准作为基准评估指标，以补充基于AUROC的公平性指标。通过比较ISIC 2020挑战和PROVE-AI数据集上最先进皮肤癌检测算法的表现，研究揭示了现有模型虽然提高了判别准确性，但在新数据集上会高估风险并表现出校准问题。研究表明，为了实现公正化的AI驱动的医疗服务，需要全面的模型审核策略和大量的元数据收集。", "conclusion": "该研究强调了综合模型审查策略和收集大量元数据的必要性，以实现公平的AI驱动医疗服务解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07573", "html_url": "https://arxiv.org/abs/2511.07573", "title": "一种用于智能时尚推荐的混合多模态深度学习框架", "title_en": "A Hybrid Multimodal Deep Learning Framework for Intelligent Fashion Recommendation", "authors": "Kamand Kalashi,Babak Teimourpour", "background": "随着在线时尚平台的迅速发展，对能够理解和处理视觉及文本提示的智能推荐系统的市场需求不断增加。本研究旨在提出一种结合视觉和文本编码的混合多模态深度学习框架，用于解决服装搭配预测和补全单品检索两个关键任务，提高时尚推荐的智能化水平和用户体验。", "innovation": "提出了一种混合多模态深度学习框架，该框架结合使用CLIP架构的视觉和文本编码器，生成时尚单品的联合潜在表示，并通过变换编码器统一处理这些表示。引入了“服装标记”来预测整体搭配关系，实现了Polyvore数据集0.95的AUC值，同时使用“目标单品标记”实现补全单品检索，达到了FITB度量下69.24%的准确性。通过多模态学习方法，该研究有效提升了时尚推荐的性能。", "conclusion": "所提出的框架在两个主要任务上表现出色，突显了多模态学习在时尚推荐中的有效性，强调了这种综合方法对提高推荐系统准确性和用户满意度的重要性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07472", "html_url": "https://arxiv.org/abs/2511.07472", "title": "Multivariate Variational Autoencoder", "title_en": "Multivariate Variational Autoencoder", "authors": "Mehmet Can Yavuz", "background": "研究团队介绍了一种称为Multivariate Variational Autoencoder (MVAE) 的变分自编码器(VAE) 变体，该变体在保持高斯可处理性的同时，解除了对角后验限制，通过分布每个后验协方差矩阵，引入了一种新的模型架构，使其能够产生完整的协方差家族，同时保持解析的KL散度和高效的重参数化方法。MVAE在多个数据集上展示了更好的重建性能、校准和无监督结构方面的改进，尤其是在中等维度的潜变量设置下，相较于匹配容量的对角协方差VAE有显著优势。", "innovation": "提出了Multivariate Variational Autoencoder (MVAE)，它在保持高斯可处理性的同时，解除了对角后验限制，并通过全局耦合矩阵和局部对角尺度的组合，实现了整个数据集的潜在变量间的全局相关性和样本内的局部不确定性。MVAE通过引入全局耦合矩阵和局部对角尺度，使模型能够更好地捕捉潜在变量间的复杂相互作用，从而改进了重建性能、校准和无监督结构等方面的措施，尤其在中等维度的潜变量设置下，相较于匹配容量的对角协方差VAE有显著优势。", "conclusion": "MVAE在多种MNIST、Fashion-MNIST、CIFAR-10、CIFAR-100数据集上展示了更好的重建性能，校准和无监督结构。实验结果表明，MVAE在中等维度的潜变量设置下，相较于匹配容量的对角协方差VAE有显著优势，这主要表现在改进的校准和无监督结构方面。同时，随着模型的潜空间可视化展示了更平滑和更一致的潜在变量变化以及更清晰的局部细节。作者还提供了完全可重现的实现，包括培训/评估脚本和调优工具，以促进公平比较和重复使用。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07560", "html_url": "https://arxiv.org/abs/2511.07560", "title": "EvoPS：计算病理学中的整张组织切片分析的进化斑块选择", "title_en": "EvoPS: Evolutionary Patch Selection for Whole Slide Image Analysis in Computational Pathology", "authors": "Saya Hashemian,Azam Asilian Bidgoli", "background": "在计算病理学中，整个组织切片图像（WSIs）的 gigapixel 规模使其需要被分割成数千个更小的斑块。分析这些高维度的斑块嵌入非常耗费计算资源，并且可能因为包含许多无信息性斑块而稀释了关键的诊断信号。现有的斑块选择方法通常依赖于随机抽取或简单的聚类启发式，通常无法明确地管理选择斑块数量与所生成的玻片表示的准确性之间的关键权衡。因此，需要一种新的方法来解决这一问题，并提高计算效率和准确性。", "innovation": "我们提出了 EvoPS（进化斑块选择），这是一种新的框架，将斑块选择问题表述为多目标优化问题，并利用进化搜索同时最小化选择的斑块嵌入的数量和最大化下游相似性搜索任务的性能，生成 Pareto 前沿下的最优权衡方案。我们使用五种预训练的深度学习模型从四种主要癌症集群中验证了该框架，结果表明，EvoPS 能够将所需训练斑块嵌入的数量减少超过90%，并且始终能维持甚至提高最终的分类 F1 分数，相较于基础的通过标准提取管道选择所有可用斑块嵌入的方法。", "conclusion": "EvoPS 框架提供了一种稳健且原则性的方法，有效地、准确地和可解释地创建整张组织切片表示。它为用户提供了一种在计算成本和诊断性能之间选择最优平衡的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07732", "html_url": "https://arxiv.org/abs/2511.07732", "title": "ViPRA: Video Prediction for Robot Actions", "title_en": "ViPRA: Video Prediction for Robot Actions", "authors": "Sandeep Routray,Hengkai Pan,Unnat Jain,Shikhar Bahl,Deepak Pathak", "background": "大部分视频（包括人类或远程操作机器人的视频）捕捉了大量的物理交互。然而，这些视频缺少标记的动作，限制了它们在机器人学习中的应用。现有的方法大多依赖于昂贵的动作标注。因此，如何有效利用无动作标记的数据来训练机器人控制策略成为一个挑战问题。", "innovation": "该研究提出了一种名为ViPRA（Video Prediction for Robot Actions）的框架，它通过预训练和微调学习连续的机器人控制。该方法不直接预测动作，而是通过训练一个视频-语言模型来预测未来的视觉观察和以动作为中心的潜在动作，这些潜在动作充当场景动态的中间表示。模型使用感知损失和光流一致性进行训练，以确保潜在动作反映物理上可行的行为。此外，该方法引入了一种分块流匹配解码器，可以根据少量的远程操作演示（仅100到200次）映射潜在动作到机器人特定的连续动作序列，无需昂贵的动作注释，支持跨实体的泛化，并通过分块动作解码实现22Hz的平滑、高频连续控制。", "conclusion": "与之前将预训练视为自回归策略学习的方法不同，ViPRA 显式地模拟了变化的性质及其影响。该方法在基准测试和现实世界的抓取任务中均表现出色，与基线相比实现了显著的性能提升。研究团队将公布模型和代码。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07719", "html_url": "https://arxiv.org/abs/2511.07719", "title": "远程光谱检测CH$_{4}$点源的运营机器学习", "title_en": "Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources", "authors": "Vít Růžička,Gonzalo Mateo-García,Itziar Irakulis-Loitxate,Juan Emmanuel Johnson,Manuel Montesino San Martín,Anna Allen,Luis Guanter,David R. Thompson", "background": "减少人为甲烷排放是减缓全球变暖最具成本效益的手段之一。尽管卫星成像光谱仪（如EMIT、PRISMA和EnMAP）可以检测这些点源，但当前基于匹配滤波的甲烷反演方法仍会产生大量误报，需要耗费大量人力进行手动验证。为了提高甲烷排放检测的效率和准确性，提出了一个使用机器学习系统在联合国环境规划署国际甲烷排放观测站的Methane Alert and Response System (MARS)中进行甲烷排放检测的方法。", "innovation": "本研究对机器学习系统进行了运营部署，创建了世界上最大的多样化甲烷气柱标注数据集，并定量比较了不同深度学习模型配置。研究扩展了先前的小型镶嵌数据集评估方法，应用于全数据集评估，发现深度学习模型仍会产生大量误报。研究通过模型集成技术减少了误报率超过74%。在MARS管道中部署后，该系统加速了甲烷泄漏检测和分析过程，有助于验证1,351个不同的甲烷泄漏情况，通知相关利益相关者479次。此外，研究展示了该模型在验证减排成功方面的实用性，通过在利比亚、阿根廷、阿曼和阿塞拜疆的案例研究进行了证明。", "conclusion": "本研究代表了全球AI辅助甲烷泄漏检测系统的重要一步，未来需要进一步处理来自新型和现有成像光谱仪的大幅增加的数据量，以实现甲烷泄漏的精准定位和快速响应。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07738", "html_url": "https://arxiv.org/abs/2511.07738", "title": "从探索到利用：阶段化的熵RLVR方法以提高抗干扰的MLLM训练", "title_en": "From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training", "authors": "Donglai Xu,Hongzheng Yang,Yuzhi Zhao,Pingping Zhang,Jinpeng Chen,Wenao Ma,Zhijian Hou,Mengyang Wu,Xiaolei Li,Senkang Hu,Ziyi Guan,Jason Chun Lok Li,Lai Man Po", "background": "强化学习与验证性奖励（RLVR）在多模态大型语言模型（MLLMs）中高度依赖高质量的标注数据，但在现实场景中这些数据往往是稀缺且容易受到大量标注噪声的影响。现有的无监督RLVR方法，如纯熵最小化，可能会过度拟合错误的标签，限制了关键的奖励排名信号。为应对这些挑战和提高抗噪声能力，作者提出了一种新颖的两阶段、基于令牌的熵优化方法，该方法在训练过程中动态引导模型从探索阶段过渡到利用阶段。", "innovation": "提出的两阶段、基于令牌的熵优化方法在训练初期通过最大化令牌水平的熵来促进多样性和随机性输出生成，防止过早收敛到噪声标签，并确保足够的组内变化，从而在组相对策略优化（GRPO）中提供更可靠的奖励梯度估计。随着训练的推进，该方法转变为最小化令牌水平的熵，鼓励模型生成具有信心和确定性的输出，从而巩固所获得的知识，提高预测准确性。", "conclusion": "在Qwen2-VL-2B、Qwen2-VL-7B和Qwen2.5-VL-3B三种MLLM主干架构上，通过不同噪声设置和多种任务的实验表明，该阶段化的策略在统一和增强外部、内部和熵基方法方面优于之前的方法，即使在噪声环境中也表现出更稳健和优越的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07930", "html_url": "https://arxiv.org/abs/2511.07930", "title": "IBMA: 基于插补的Mixup增强方法结合自我监督学习用于时间序列数据", "title_en": "IBMA: An Imputation-Based Mixup Augmentation Using Self-Supervised Learning for Time Series Data", "authors": "Dang Nha Nguyen,Hai Dang Nguyen,Khoa Tho Anh Nguyen", "background": "时间序列数据增强在时序预测模型中扮演着重要角色，尽管时间序列数据的增强策略相对较少，但像Mixup这样的高级技术很少被利用。传统的增强方法在时间序列数据上的应用有限。", "innovation": "提出了一个新的增强方法——基于插补的Mixup增强（IBMA），该方法结合了插补增强和Mixup增强，以提升模型泛化能力和预测性能。该方法在多个时序预测模型上进行了测试，包括DLinear（MLP）、TimesNet（CNN）和iTrainformer（Transformer），实验结果表明IBMA在多个数据集上能得到显著改善。", "conclusion": "实验证明，IBMA能持续提高模型性能，在24次实例中有22次改进，其中10次是最佳表现，特别是在使用iTrainformer插补时。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07926", "html_url": "https://arxiv.org/abs/2511.07926", "title": "基于CNN的用于建模忆阻器的自动参数提取框架", "title_en": "CNN-Based Automated Parameter Extraction Framework for Modeling Memristive Devices", "authors": "Akif Hamid,Orchi Hassan", "background": "忆阻器（RRAM）是下一代非易失性存储器（NVM）和内存计算应用的有前景候选者。紧凑模型对于分析实验RRAM设备的电路和系统级性能至关重要。然而，大多数现有的RRAM紧凑模型依赖于多个拟合参数来重现设备的I-V特性，且这些参数大多与可测量的物理量无关，因此提取这些参数需要大量的人工调整，使得过程耗时，并限制了模型在不同设备之间的适应性。", "innovation": "本工作提出了一个自动化框架，可以直接从设备的I-V特性中提取广泛使用的斯坦福RRAM模型的拟合参数。该框架使用在合成数据集上训练的卷积神经网络（CNN）生成初始参数估计，并通过三次启发式优化块最小化参数空间中的误差。这一方法通过快速、可靠和稳健的方式解决了RRAM建模问题。", "conclusion": "该框架通过四个关键的NVM指标（记忆电压、重置电压、滞回环面积和低电阻状态坡度）进行了评估，基准测试结果表明，该框架能够实现低误差的多样化设备特性建模，为RRAM建模提供了一种快速、可靠的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07827", "html_url": "https://arxiv.org/abs/2511.07827", "title": "孕期超声深度学习分析用于室管膜增宽的识别", "title_en": "Deep Learning Analysis of Prenatal Ultrasound for Identification of Ventriculomegaly", "authors": "Youssef Megahed,Inok Lee,Robin Ducharme,Aylin Erman,Olivier X. Miguel,Kevin Dick,Adrian D. C. Chan,Steven Hawken,Mark Walker,Felipe Moretti", "background": "室管膜增宽是一种在胎儿大脑室扩张的孕期状况，需要早期诊断，因为它增加了胎儿非整倍体和/或潜在遗传综合征的风险。现有的基线模型如VGG-19、ResNet-50和ViT-B/16在检测室管膜增宽方面的性能较差，因此需要一种更有效的深度学习模型来提高检测准确性。", "innovation": "研究开发了一种名为USF-MAE（超声自我监督基础模型与掩码自编码）的深度学习模型，该模型通过对孕期胎儿大脑超声图像进行微调，实现了室管膜增宽的二分类任务。USF-MAE采用了Vision Transformer编码器，并在OpenUS-46数据集的37万多张超声图像上进行了预训练。实验结果显示，USF-MAE在多折交叉验证和独立测试集上的F1分数分别达到了91.76%和91.78%，明显优于基线模型，精度和准确率也非常高。模型的Eigen-CAM热图显示，模型在诊断室管膜增宽时专注于室区，具有较高的解释性和临床合理性。", "conclusion": "USF-MAE模型在检测孕期胎儿大脑室管膜增宽方面表现优异，能有效提高早期诊断的准确性，为临床应用提供了新的工具。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07947", "html_url": "https://arxiv.org/abs/2511.07947", "title": "类特征水印：面对模型提取攻击的稳健黑箱水印", "title_en": "Class-feature Watermark: A Resilient Black-box Watermark Against Model Extraction Attacks", "authors": "Yaxin Xiao,Qingqing Ye,Zi Liang,Haoyang Li,RongHua Li,Huadi Zheng,Haibo Hu", "background": "机器学习模型构成了重要的知识产权，但这些模型仍可能受到模型提取攻击（MEA）的威胁，攻击者可以通过黑盒查询复制模型功能。目前的黑盒水印技术主要通过表征纠缠来确保MEA的生存，但未能充分考虑应对连续的MEA攻击和移除攻击的风险。已有移除方法因表征纠缠的削弱而变得较弱。", "innovation": "针对上述现有技术的局限性，本文提出了两种创新方法：(1) Watermark Removal attacK (WRK)，通过利用由现有样本级水印特征形成的数据决策边界，突破表征纠缠限制来降低现有水印技术的成功率；(2) Class-Feature Watermarks (CFW)，通过利用类别级特征构造出一个合成类别，以消除原有决策边界的风险。CFW 方法在提高对MEA的鲁棒性的同时，还能提升提取攻击后的稳定性。", "conclusion": "实验结果表明，CFW 方法在多个领域中相较于之前的方法具有更优秀的抗攻击能力，即使在结合MEA和WRK的双重干扰下，仍能保持至少70.15%的水印成功率，并且可以保持模型的效果。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07903", "html_url": "https://arxiv.org/abs/2511.07903", "title": "DynaQuant：学习图像压缩中的动态混合精度量化", "title_en": "DynaQuant: Dynamic Mixed-Precision Quantization for Learned Image Compression", "authors": "Youneng Bao,Yulong Cheng,Yiping Liu,Yichen Yang,Peng Qin,Mu Li,Yongsheng Liang", "background": "现有的在学习图像压缩（LIC）中常用的量化技术通常使用在整个网络中固定且均匀的位宽，这无法适应LIC模型中多样化的数据分布和敏感性特征，导致性能和效率之间的权衡不理想。DynaQuant提出了一种新的动态混合精度量化框架，该框架在两个互补的层面操作。它引入了内容感知量化，通过可学习的比例和偏移参数动态适应潜在特征的统计变化，并使用一种新的距离感知梯度调制器（DGM）进行端到端训练，这种调制器提供比标准直接通过估计器更有信息的学习信号。此外，引入了一种数据驱动的动态位宽选择器，能够根据输入数据为每个层自动选择最优位精度，从而动态重构网络的精度配置文件。这种方式提供了在压缩率-失真（R-D）性能和计算成本之间灵活平衡的能力。研究表明，DynaQuant在计算和存储要求显著降低的情况下，能达到与全精度模型相当的性能，使其能够在多种硬件平台上实现实用部署。", "innovation": "引入了一种新的动态混合精度量化框架DynaQuant，它包括内容感知量化以及动态位宽选择，以适应LIC模型的多样性和动态性。内容感知量化通过可学习的比例和偏移参数调整，而动态位宽选择器根据输入数据自动为每个层选择最优位精度，实现在压缩率-失真（R-D）性能和计算成本之间的动态平衡。并通过DGA（Distance-aware Gradient Adjuster）提供更加信息丰富的学习信号，改进了传统的直接通过估计器方法。", "conclusion": "实验证明，DynaQuant在性能上能达到全精度模型的水平，同时显著减少了计算和存储需求，使其能够在多种硬件平台上实现学习图像压缩的实用部署。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08009", "html_url": "https://arxiv.org/abs/2511.08009", "title": "从噪声到潜在变量：基于INR的图像压缩中生成高斯潜在变量", "title_en": "From Noise to Latent: Generating Gaussian Latents for INR-Based Image Compression", "authors": "Chaoyi Lin,Yaojun Wu,Yue Li,Junru Li,Kai Zhang,Li Zhang", "background": "近期的基于隐神经表示（INR）的图像压缩方法通过过度拟合特定图像的潜在代码展示了竞争力，但仍然在去除空间冗余方面不如端到端（E2E）压缩方法。相反，E2E方法依赖于传输潜在代码和使用复杂熵模型，这增加了解码复杂性。", "innovation": "该研究借鉴E2E编解码器中使潜在变量表现出高斯噪声的正则化策略，提出了一种反向方向：直接从高斯噪声生成潜在变量。提出了一种新的图像压缩框架，从多尺度高斯噪声张量中构建特定图像的潜在变量，该张量使用共享随机种子生成。通过GPP模块估计分布参数，实现通过重参数技巧的一次性潜在变量生成，进而回传到合成网络重建图像。这种方法消除了传输潜在代码的需求，同时保留了潜在变量带来的益处，实现了与Kodak和CLIC数据集上同类性能的可竞争力的率失真性能。", "conclusion": "这是首次探索用于学习图像压缩的高斯潜在变量生成的相关工作。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07820", "html_url": "https://arxiv.org/abs/2511.07820", "title": "SONIC: 扩大规模改进自然人形全身控制中的运动跟踪", "title_en": "SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control", "authors": "Zhengyi Luo,Ye Yuan,Tingwu Wang,Chenran Li,Sirui Chen,Fernando Castañeda,Zi-Ang Cao,Jiefeng Li,David Minor,Qingwei Ben,Xingye Da,Runyu Ding,Cyrus Hogg,Lina Song,Edy Lim,Eugene Jeong,Tairan He,Haoru Xue,Wenli Xiao,Zi Wang,Simon Yuen,Jan Kautz,Yan Chang,Umar Iqbal,Linxi \"Jim\" Fan,Yuke Zhu", "background": "尽管已有的大规模基础模型在数千个GPU上训练能够实现极大的规模效益，但类似的规模效益在类人控制中尚未得到证明。当前的类人神经控制器规模较小，针对的行为组合有限，并且在数个GPU上耗时多天进行训练。因此，本文探讨通过增加模型的参数量、数据集和计算资源来提高类人控制的整体能力，具体研究运动跟踪作为类人控制的自然可扩展任务，利用丰富的动态捕捉数据无奖励工程获得先验的人体动作知识。通过三个维度进行扩展：网络规模（从1.2M参数增加到42M参数）、数据集规模（超过100M帧，700小时高质量动作数据）和计算资源（9000个GPU小时）。通过这样的扩展，本文展示了模型规模扩大的益处以及模型的应用：(1) 实时通用运动学规划器，使运动跟踪能够与下游任务执行相连，从而实现自然和交互控制；(2) 统一的标记空间支持各种动作输入接口，如VR遥操作设备、人类视频和Vision-Language-Action (VLA) 模型使用相同的策略。随着计算资源和数据多样性的增加，运动跟踪的性能稳步提高，学习表示具有良好的泛化能力，运动跟踪可以作为类人控制的实用基础。", "innovation": "本文创新性地提出了通过扩大模型容量、数据和计算资源来增强类人控制器的整体表现。首次将运动跟踪任务作为类人控制的一个自然且可扩展的任务，利用丰富多样的动态捕捉数据直接获得人体动作先验知识，无需手动奖励工程。通过三个维度的扩展（网络规模、数据集规模、计算资源），不仅展示了模型规模扩大的益处，还通过实时通用运动学规划器和统一标记空间的应用，展示了模型的实际应用价值。", "conclusion": "本文通过扩展模型规模和计算资源，展示了其在类人控制中的应用成效。运动跟踪作为类人控制的自然任务，能够自然和稳定地生成全身运动。随着计算资源和数据多样性的增加，运动跟踪表现出优秀的性能和泛化能力，将运动跟踪设为类人控制的基础框架，为实现了更自然和交互的类人控制提供了新的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08226", "html_url": "https://arxiv.org/abs/2511.08226", "title": "在线斑块冗余消除器（OPRE）：一种基于数据集压缩的新型在线无偏连续学习方法", "title_en": "The Online Patch Redundancy Eliminator (OPRE): A novel approach to online agnostic continual learning using dataset compression", "authors": "Raphaël Bayle,Martial Mermillod,Robert M. French", "background": "连续学习（CL）的目标是在不遗忘先前学习的知识的前提下学习新任务，而如何解决这一问题成为神经网络自诞生以来面临的一个难题。现有的CL方法在评估时通常依赖于将已知的同质数据集分割，然后依次学习关联的任务。然而，现有的方法常常引入对即将到来数据的先验信息，这使得这些方法不能被认为是无偏的。", "innovation": "本文提出了在线斑块冗余消除器（OPRE），这是一种基于数据集压缩的在线无偏连续学习方法。OPRE不仅在网络测试时训练分类器，还在过程中进行数据集压缩，这种做法在CIFAR-10和CIFAR-100数据集上达到了优于其他先进在线CL方法的表现。此外，OPRE仅需对即将到来的数据提出最少的可解释假设。", "conclusion": "本文建议，数据集压缩可能对实现无偏的连续学习至关重要。OPRE为实现真正无偏的CL提供了一种有潜力的新方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08399", "html_url": "https://arxiv.org/abs/2511.08399", "title": "边界感知 Curriculum 学习：错位对齐以修正错位", "title_en": "Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment", "authors": "Hua Ye(1 and 2),Hang Ding(3),Siyuan Chen(4),Yiyang Jiang(5),Changyuan Zhang(6),Xuan Zhang(2 and 7) ((1) Nanjing University, (2) Airon Technology CO. LTD, (3) University of Bristol, (4) The Hong Kong Polytechnic University, (5) Shanghai Jiao Tong University, (6) The University of Hong Kong, (7) Carnegie Mellon University)", "background": "大多数多模态模型都假设所有负配对具有相同的重要性，忽略了仅在细节上与正样本不同的模糊负样本。这种处理方式可能会阻碍模型对边缘案例的理解与适应性，从而影响整体准确度和泛化能力。因此，研究者提出了一种新的方法，Boundary-Aware Curriculum with Local Attention (BACL)，旨在通过识别和关注模态间的具体差异来提高模型在处理边缘案例时的表现。该方法通过边界感知负样本选择和对比局部注意力损失来逐步提高模型的学习难度，从而帮助模型更好地学习模态对齐的任务。", "innovation": "BACL 提出了一种边界感知的 Curriculum 学习方法，通过边界感知负样本选择模块(gradually increasing sampling difficulty)和对比局部注意力损失模块(highlighting mismatch locations)，将原本模糊的负样本转变成有效的学习信号。该方法可以与任何双编码器无缝结合，并且是完全可微的，保证了训练的高效性和准确性。实验结果表明，BACL 能够在多个大规模基准测试中显著提升性能(与 CLIP 相比，R@1 可提高多达 32%)，且无需额外标记数据，从而降低了实际应用中的复杂性和成本。", "conclusion": "该研究通过引入 BACL，提出了一种有效的方法来处理模态对齐中的边缘案例。实验结果证实，即使不依赖额外标签，BACL 也能显著提高多模态模型的性能。这些发现表明，BACL 可以被视为提高多模态学习效果的一种有力工具。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08417", "html_url": "https://arxiv.org/abs/2511.08417", "title": "NeuCLIP：基于神经归一化优化的大规模CLIP训练", "title_en": "NeuCLIP: Efficient Large-Scale CLIP Training with Neural Normalizer Optimization", "authors": "Xiyuan Wei,Chih-Jen Lin,Tianbao Yang", "background": "准确估计对比损失中的归一化项（也称为分区函数）是训练对比语言-图像预训练（CLIP）模型的核心挑战。传统方法依赖大规模数据批次进行近似，消耗大量计算资源。为缓解此问题，已有研究引入了基于每个样本的归一化估计器，这种估计器在每个批次中通过块状协调方式更新，以跟踪更新的编码器。然而，这种方法会导致随数据集大小与批次大小比值增加的优化误差，限制了其在大规模数据集或小批次中的效果。", "innovation": "我们提出了一个新颖且优雅的优化框架NeuCLIP，基于两个关键思想：（i）通过凸分析对每个样本重构成对比损失，将其转换为带有表示其对数归一化器的辅助变量的最小化问题；（ii）通过变分分析将对n个辅助变量（其中n为数据集大小）的最小化转换为预测对数归一化器的紧凑神经网络的最小化。我们设计了一个交替优化算法，联合训练CLIP模型和辅助网络。通过为辅助网络配备定制架构和加速技术，NeuCLIP实现了更准确的归一化估计，提高了性能。", "conclusion": "在从数百万到数十亿样本的大型规模CLIP训练数据集上进行的广泛实验表明，NeuCLIP明显优于之前的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08054", "html_url": "https://arxiv.org/abs/2511.08054", "title": "Re$^{\text{2}}$MaP: 通过递归原型创建和基于树的重新定位进行宏放置", "title_en": "Re$^{\\text{2}}$MaP: Macro Placement by Recursively Prototyping and Packing Tree-based Relocating", "authors": "Yunqi Shi,Xi Lin,Zhiang Wang,Siyuan Xu,Shixiong Kai,Yao Lai,Chengrui Gao,Ke Xue,Mingxuan Yuan,Chao Qian,Zhi-Hua Zhou", "background": "在大规模集成电路（IC）设计中，宏放置（macro placement）是决定整个芯片布局的关键步骤。现有的宏放置算法在处理大规模电路时可能难以同时优化布线长度（wirelength）和数据流（dataflow），尤其是在确保功耗和设计规则检查（DRC）的同时。本文介绍了Re$^{\text{2}}$MaP方法，旨在通过迭代原型创建和基于树的重新定位生成专家级别的宏放置布局，以改进现有算法的性能。", "innovation": "Re$^{\text{2}}$MaP引入了一种名为ABPlace的基于角度的分析方法，可以将宏分布在椭圆上，优化布线长度和数据流，同时采用了基于树的重新定位过程，能够同时调整宏组和组内宏的位置，通过遗传搜索获得启发式的成本函数，以满足各种设计约束。该方法通过迭代过程提高原型的准确性，仅在每次迭代中调整部分宏组，而其他宏则等待下一迭代进行优化。与现有的学术板级放大型Hier-RTLMP相比，Re$^{\text{2}}$MaP在最坏情况下的未满足定时余量（WNS）最多可以改善22.22%，平均10.26%；总未满足定时余量（TNS）最多可以改善97.91%，平均33.97%，同时在功耗、设计规则检查（DRC）违规和运行时间方面也优于之前的会议版本ReMaP。", "conclusion": "Re$^{\text{2}}$MaP方法通过迭代和优化的宏放置过程，显著提高了芯片布局的质量，不仅在多个性能指标上优于现有的学术版本ReLU，还在实际应用场景中展示了其优越性，为大规模集成电路设计提供了新的解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.18334", "html_url": "https://arxiv.org/abs/2403.18334", "title": "DODA: 实时适应动态农业环境的对象检测器扩散改编", "title_en": "DODA: Adapting Object Detectors to Dynamic Agricultural Environments in Real-Time with Diffusion", "authors": "Shuai Xiang,Pieter M. Blok,James Burridge,Haozhou Wang,Wei Guo", "background": "农业中的目标检测应用广泛，但不同环境带来的领域转移限制了训练模型的更广泛应用。现有的领域适应方法通常需要为新领域重新训练模型，这对不断变化的农业环境来说是不切实际的。因此，需要一种能够在短时间内适应新领域的方法，以解决这个问题。", "innovation": "提出了DODA（基于扩散的对象检测领域适应方法），能够在2分钟内适应新领域。DODA结合了外部领域嵌入和改进的布局到图像的方法，使其能够在无需额外训练的情况下生成高质量的新领域检测数据。DODA为农业领域的适应提供了一个简单而强大的解决方案，降低了种植者使用个性化环境检测的门槛。", "conclusion": "通过在Global Wheat Head Detection数据集上的实验，证明了DODA的有效性，证明将检测器微调在DODA生成的数据上可以在多个领域实现显著提高，并提供了简单的解决方案以适应农业中的动态环境。源代码可以在这个网址获取：this https URL."}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08544", "html_url": "https://arxiv.org/abs/2511.08544", "title": "LeJEPA: 无需启发式方法的可证明和可扩展的自监督学习", "title_en": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics", "authors": "Randall Balestriero,Yann LeCun", "background": "学习世界的可操控表示及其动态是AI的核心。联合嵌入预测架构（JEPAs）提供了一种有前景的蓝图，但由于缺乏实用指导和理论，相关的研究和开发往往不规范。这篇论文旨在通过提出一个全面的JEPAs理论，并在其中实现一个精简、可扩展且具有理论依据的训练目标——LeJEPA，来解决这些问题。", "innovation": "1. 确定等向高斯分布为JEPAs嵌入应遵循的最优分布，以最小化下游预测风险。\n2. 引入了一种新颖的目标——勾勒等向高斯正则化（SIGReg）——以约束嵌入达到理想的分布。\n3. 将JEPA预测损失与SIGReg结合，形成了具有多个理论和实际利益的LeJEPA，包括单一交易超参数、线性时间和内存复杂性、参数稳定、架构适应性强、无需经验方法、以及分布式训练友好的实现等。", "conclusion": "LeJEPA的实证验证覆盖了10多个数据集、60多种架构，所有这些数据集和架构具有不同的规模和领域。例如，使用ImageNet-1k进行预训练和冻结主干的线性评估，LeJEPA达到了79%的性能（使用ViT-H/14模型）。作者希望LeJEPA提供的简单性和理论友好生态系统能够重新确立自监督预训练在AI研究中的核心地位。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08585", "html_url": "https://arxiv.org/abs/2511.08585", "title": "使用人工智能模拟可视世界：路线图", "title_en": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "authors": "Jingtong Yue,Ziqi Huang,Zhaoxi Chen,Xintao Wang,Pengfei Wan,Ziwei Liu", "background": "视频生成的景观正在转变，从专注于生成视觉上吸引人的片段，转向构建支持交互并保持物理合理性的虚拟环境。这些发展预示着视频基础模型的出现，这些模型不仅作为视觉生成器，还作为隐式世界模型，能够模拟物理动力学、代理-环境交互和任务规划等管理现实或想象世界的过程。本文综述了这一演变，将现代视频基础模型定义为两个核心组件的组合：隐式世界模型和视频渲染器。", "innovation": "本文通过系统地介绍了视频生成的四个阶段，展示了核心能力的逐步提升，最终 culminating 于一个结合视频生成模型并具备内在物理合理性、实时多模态交互及跨时空尺度规划能力的隐式世界模型。每个阶段都定义了其核心特征，强调了代表性作品，并探讨了其应用领域，如机器人技术、自动驾驶和互动游戏。最后，讨论了下一代世界模型面临的开放挑战和设计原则，包括代理智能在塑造和评估这些系统中的作用。维护了相关工作的最新列表。", "conclusion": "本文综述了视频生成的发展，定义了现代视频基础模型的关键组件，并通过四个生成阶段展示了逐步提升的核心能力。此外，本文还探讨了下一代世界模型的研发方向和挑战，并提供了一个相关工作的更新列表，为未来研究提供了指导和预测。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.03176", "html_url": "https://arxiv.org/abs/2406.03176", "title": "MMCL: 改进CT对象检测中内容查询分布", "title_en": "MMCL: Correcting Content Query Distributions for Improved Anti-Overlapping X-Ray Object Detection", "authors": "Mingyuan Li,Tong Jia,Hui Lu,Hao Wang,Bowen Ma,Shiyi Guo,Shuyang Lin,Dongyue Chen,Haoran Wang,Baosheng Yu", "background": "X射线图像与自然图像不同，X射线图像中的对象由于深度导致的重叠和半透明效果相互重合，其特征相互混合。这些特点需要专门的机制来分离目标对象（如禁止物品）与无关背景之间的混合表示。近期研究已探讨了适应性检测变压器(DETR)以应对重叠目标检测问题，但内容查询的合理分布以代表对象假设的重要性仍较少有研究。", "innovation": "本文提出了一种多类最小边际对比学习(MMCL)框架，用于纠正内容查询的分布，从而实现类内的多样性及类间的可分性。MMCL首先按对象类别对内容查询进行分组，然后应用两个互补的损失组件：多类排除损失以增强类间的可分性，最小边际聚类损失以鼓励类内的多样性。", "conclusion": "MMCL在三个常用的X射线禁止物品检测数据集上，使用两个骨干网络和四种DETR变体进行了评估。实验证明，MMCL能有效改进抗重叠对象检测，且在两个数据集上达到了最先进的性能。源代码已在GitHub上公开。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.17063", "html_url": "https://arxiv.org/abs/2409.17063", "title": "在计算病理学中基准评估领域泛化算法", "title_en": "Benchmarking Domain Generalization Algorithms in Computational Pathology", "authors": "Neda Zamanitajeddin,Mostafa Jahanifar,Kesi Xu,Fouzia Siraj,Nasir Rajpoot", "background": "深度学习模型在计算病理学任务中展现了巨大的潜力，但在应用于未见过的数据时，由于领域转换，其性能往往会下降。这需要领域泛化（DG）算法。然而，在计算病理学背景下系统性地评估DG算法的研究还很缺乏。", "innovation": "本研究通过7560次交叉验证运行，评价30种DG算法在三种不同难度的计算病理学任务中的有效性，使用统一且稳健的平台，结合特定模态技术与预训练基础模型等最新进展。此外，文中还介绍了新的跨癌种肿瘤检测数据集HISTOPANTUM，作为未来研究的基准。", "conclusion": "实验证明，自监督学习和染色增强方法在各场景中表现最佳，突显了预训练模型和数据增强的潜力。该研究为研究人员在计算病理学任务中选择合适的DG方法提供了宝贵的指导。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.18770", "html_url": "https://arxiv.org/abs/2405.18770", "title": "利用一一多项关系的多模态对抗防护方法用于视觉语言模型", "title_en": "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships", "authors": "Futa Waseda,Antonio Tejero-de-Pablos,Isao Echizen", "background": "预训练的视觉-语言(VL)模型对对抗攻击极为敏感。现有防御方法主要集中在图像分类，忽略了VL任务的两个关键方面：跨模态攻击，其中图像和文本都可能被篡改；以及图像与文本的一对多关系，即一个图像可以对应多个文本描述，反之亦然（1:N和N:1）关系。现有VL防御方法主要集中在视觉鲁棒性，而未探索多模态攻击的防御策略。", "innovation": "本文首次针对VL任务中的多模态攻击探索防御策略。提出了一种多模态对抗训练（MAT），该方法在训练过程中同时对图像和文本模态应用对抗性扰动，显著优于现有的一模态防御方法。此外，研究发现MAT方法受限于VL训练数据中的确定性一一对应关系（1:1）。因此，本文深入研究了利用一对多关系增强鲁棒性的方法，并提出了多种增强技术。研究显示，有效的防御需要增强的图像-文本对需要良好对齐、多样性，同时避免分布偏离。这是在优化和数据视角上建立鲁棒VL模型的首次尝试，提供了宝贵的经验和见解。", "conclusion": "本文的工作开创了针对多模态攻击的防御策略，提供了从优化和数据两个角度构建鲁棒VL模型的见解。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.02562", "html_url": "https://arxiv.org/abs/2409.02562", "title": "只需一个 homography：基于 IMM 的联合 homography 和多对象状态估计", "title_en": "One Homography is All You Need: IMM-based Joint Homography and Multiple Object State Estimation", "authors": "Paul Johannes Claasen,Johan Pieter de Villiers", "background": "传统的3D多对象跟踪（MOT）方法依赖于常规的3D测量，而本文提出了一种新颖的方法，即IMM Joint Homography State Estimation（IMM-JHSE），它仅使用初始homography估计作为额外的3D信息，而不需要其他常规的3D测量。这种方法通过联合建模homography矩阵及其动态，作为跟踪状态向量的一部分，从而减少了过去方法中相机运动补偿技术对预测轨迹位置状态的显式影响。", "innovation": "1. 通过联合建模homography矩阵及其动态，作为跟踪状态向量的一部分，IMM-JHSE减少了相机运动补偿技术对预测轨迹位置状态的显式影响。\n2. 使用 IMM 过滤器结合静态和动态相机运动模型。\n3. 通过将基于边界框的 BIoU 分数与基于地平面的 Mahalanobis 距离结合使用的方式，提出了一种非标准的 IMM 接口方法，用于仅关联，使IMM-JHSE对地平面外的运动具有鲁棒性。\n4. 使用动态过程和测量噪声估计技术。\n5. IMM-JHSE在DanceTrack和KITTI-car数据集上改善了UCMCTrack、OC-SORT、C-BIoU 和 ByteTrack方法，增大HOTA值分别为2.64和2.11，同时在MOT17、MOT20和KITTI-pedestrian数据集上提供了竞争力的表现。", "conclusion": "IMM-JHSE在公开可用的检测结果下，除了在KITTI-car数据集上的3D MOT方法外，超过了几乎所有的其他2D MOT方法。在DanceTrack数据集上，IMM-JHSE与跟踪注意力方法表现相似，而在MOT17数据集上，IMM-JHSE优于跟踪注意力方法。源代码已公开。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08220", "html_url": "https://arxiv.org/abs/2506.08220", "title": "再认：揭示监督语义对应模式的泛化差距", "title_en": "Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence", "authors": "Octave Mariotti,Zhipeng Du,Yash Bhalgat,Oisin Mac Aodha,Hakan Bilen", "background": "语义对应（SC）旨在建立不同实例间具有语义意义的匹配。然而，现有的监督SC方法难以泛化到稀疏标注的训练关键点之外，它们实际上更像是关键点检测器。这一研究背景揭示了当前监督方法在泛化能力上的局限性，推动着学术界寻求更有效的解决方案以增强模型在未见过的关键点上的性能以及跨不同数据集的泛化能力。", "innovation": "本文提出了一种新的密集对应学习方法，通过使用单目深度估计将2D关键点提升到标准化的3D空间，从而构建一个捕捉对象几何结构的连续标准流形，而无需显式的3D监督或相机注释。此外，引入了SPair-U，这是SPair-71k的一个扩展版本，包含新的关键点标注，以更好地评估泛化能力。这种方法显著改进了监督基线在未知关键点上的性能，并展示了无监督基线在泛化于不同数据集时优于监督基线的表现。", "conclusion": "实验结果表明，本文模型在未见过的关键点上显著优于监督基线，突显了它在学习鲁棒对应关系的有效性，并展示了基于SPair-U的实验结果证明了无监督方法在泛化性能上的优越性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01636", "html_url": "https://arxiv.org/abs/2506.01636", "title": "视觉相似特征激活图解释元学习", "title_en": "Visual Explanation via Similar Feature Activation for Metric Learning", "authors": "Yi Liao,Ugochukwu Ejike Akpudo,Jue Zhang,Yongsheng Gao,Jun Zhou,Wenyi Zeng,Weichuan Zhang", "background": "现有的解释图方法，如类激活图（CAM）及其变种（例如Grad-CAM和相关性激活图），广泛用于探究基于softmax的卷积神经网络的可解释性，这些模型需要全连接层作为分类器进行决策。然而，这些方法无法直接应用于元学习模型，因为这类模型缺少一个起分类器作用的全连接层。", "innovation": "提出了一个新颖的视觉解释方法——相似特征激活图（SFAM）。SFAM通过引入通道贡献重要性得分（CIS）来衡量特征的重要性，CIS基于两幅图像嵌入之间的相似性度量。该方法通过线性组合提议的重要权值与卷积神经网络模型中的特征图来构造解释图。", "conclusion": "定量和定性实验表明，SFAM为使用欧氏距离或余弦相似度作为相似度度量的CNN模型提供了高度有前景的可解释性视觉解释。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13558", "html_url": "https://arxiv.org/abs/2506.13558", "title": "X-Scene：高保真和灵活可控的大规模驾驶场景生成", "title_en": "X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability", "authors": "Yu Yang,Alan Liang,Jianbiao Mei,Yukai Ma,Yong Liu,Gim Hee Lee", "background": "随着扩散模型的发展，它们在自动驾驶领域取得了显著进展，特别是在生成真实数据、实现端到端预测规划和闭环仿真等方面的潜力日益凸显，并且主要集中在时间一致性的生成。然而，大规模3D场景生成且具有空间一致性的问题仍然未得到充分探索。", "innovation": "本文提出了X-Scene框架，这是一种新颖的用于大规模驾驶场景生成的方法，它实现了几何复杂性、外观的真实性和灵活的可控性。X-Scene支持多粒度控制，包括通过用户输入或文本驱动的低级布局条件和通过用户意图和LLM增强的提示进行的高级语义指导。X-Scene引入了统一的生成管道，首先生成3D语义占用和相应的多视角图像和视频，确保不同模态在时间和空间上的协调。此外，通过一致性的自举扩展局部区域到大规模场景，从先前生成的区域推断出占用和图像以保持空间和视觉的一致性。生成的场景可提升为高质量的3DGS表示，支持仿真和场景探索等多种应用。", "conclusion": "大量的实验表明，X-Scene在大规模场景生成方面的可控性与保真度上取得了显著进步，极大地推动了数据生成和自动驾驶领域的仿真技术发展。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11773", "html_url": "https://arxiv.org/abs/2506.11773", "title": "AgentSense: 使用LLM代理在模拟家庭环境中的虚拟传感器数据生成", "title_en": "AgentSense: Virtual Sensor Data Generation Using LLM Agents in Simulated Home Environments", "authors": "Zikang Leng,Megha Thukral,Yaqi Liu,Hrudhai Rajasekhar,Shruthi K. Hiremath,Jiaman He,Thomas Plötz", "background": "开发适用于智能家居的强大且通用的人体活动识别（HAR）系统的主要挑战在于缺乏大量且多样化的标注数据集。家庭布局、传感器配置和个体行为的差异进一步加剧了这一问题。", "innovation": "我们提出了一种名为AgentSense的虚拟数据生成管道，利用具备内部世界模型的体代理进行感知和行为。这些体代理在模拟智能家中按照大语言模型（LLMs）生成的多样化合成个性和现实活动模式执行日常任务。通过扩展的VirtualHome模拟器并添加虚拟环境传感器，记录代理活动并生成丰富、隐私保护的传感器数据，这些数据反映了真实世界的多样性。", "conclusion": "在五个实际HAR数据集上评估AgentSense，基于生成数据预训练的模型在低资源设置中的一致性表现优于基线。结合少量真实数据和生成虚拟传感器数据可实现与仅使用全真实场景数据训练性能相当的结果。这些结果强调了利用LLM指导的体代理生成HAR中的可扩展且成本效益高的传感器数据的潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18807", "html_url": "https://arxiv.org/abs/2506.18807", "title": "PicoSAM2：边缘视觉应用中传感器内低延迟分割", "title_en": "PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications", "authors": "Pietro Bonazzi,Nicola Farronato,Stefan Zihlmann,Haotong Qin,Michele Magno", "background": "实时、设备端的分割对于智能眼镜和物联网设备等对延迟敏感和隐私保护的应用至关重要。现有的分割模型通常不适合边缘和传感器执行的需求，尤其是在内存和计算资源有限的设备上。", "innovation": "PicoSAM2 是一个轻量级的 (1.3M 参数，336M MACs) 可提示的分割模型，旨在优化边缘和传感器执行，包括索尼 IMX500。它基于深度可分离 U-Net，通过知识蒸馏和固定点提示编码从 Segment Anything Model 2 (SAM2) 学习。通过蒸馏在 LVIS 上提升了 3.5% 的 mIoU 和 5.1% 的 mAP。", "conclusion": "PicoSAM2 表现出了直接在传感器上实现高效、可提示的分割的可能性，使得在不依赖云或主机处理的情况下保护隐私的视觉成为可能。该模型在传感器部署中达到了 86 MACs/cycle 的计算效率，同时满足内存和计算约束。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19210", "html_url": "https://arxiv.org/abs/2505.19210", "title": "理解无分类引导机制的进展", "title_en": "Towards Understanding the Mechanisms of Classifier-Free Guidance", "authors": "Xiang Li,Rongrong Wang,Qing Qu", "background": "Classifier-free guidance (CFG) 是当前最先进图像生成系统的关键技术，但其背后的机制仍然不为人所充分理解。本文在简化线性扩散模型中分析了CFG，发现其行为与非线性模型中观察到的行为非常相似。研究表明，线性CFG通过三种不同的方式改进了生成质量：(i) 平均偏移项即样本能粗略地朝着类别均值的方向移动；(ii) 正态对比主成分（CPC）项增强了类特异性特征；(iii) 负CPC项抑制了普遍存在于非条件数据中的通用特征。", "innovation": "本文首次在简化线性扩散模型中分析了CFG的行为，并揭示了CFG改进生成质量的三种机制：平均偏移项、正CPC项和负CPC项。这些发现为理解CFG在非线性扩散模型中的工作机制提供了新的视角。", "conclusion": "在线性分析的范围内，线性CFG与非线性的CFG表现出相似的行为。尽管在低噪声水平下两者最终会开始有所不同，但线性分析仍能提供深入了解非线性模型中CFG机制的依据。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17685", "html_url": "https://arxiv.org/abs/2505.17685", "title": "未来视觉驱动: 使用时空因果链的自主驾驶", "title_en": "FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving", "authors": "Shuang Zeng,Xinyuan Chang,Mengwei Xie,Xinran Liu,Yifan Bai,Zheng Pan,Mu Xu,Xing Wei,Ning Guo", "background": "视觉-语言-行动（VLA）模型在端到端驾驶中具有巨大的潜力，但它们的推理往往受到文本因果链（CoT）的限制。这种视觉信息的符号压缩在感知和规划之间创建了模态差距，模糊了空间-时间关系，并忽略了细粒度线索。", "innovation": "提出了FSDrive框架，使其VLAs能够“视觉思考”使用新颖的视觉空间-时间因果链。FSDrive首先作为世界模型运行，生成结合预测背景和物理上可验证的先验因素（如未来的车道分隔线和3D物体框）的统一未来帧。这种想象的场景充当视觉空间-时间因果链，捕捉单一表示中的空间结构和时间演变。该框架通过统一预训练范式扩展模型词汇表，并联合优化语义理解（VQA）和未来帧预测实现这一目标。该框架通过逐步课程首先生成结构先验以强制执行物理法则，然后渲染完整场景。", "conclusion": "在nuScenes和NAVSIM上的评估显示，FSDrive提高了轨迹精度并减少了碰撞，同时使用轻量级自回归模型实现了与视频生成竞争性的FID，并在DriveLM上推进了场景理解。这些结果证明我们的视觉时空因果链弥合了感知-规划差距，使自主驾驶更安全、更有预见性。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21473", "html_url": "https://arxiv.org/abs/2505.21473", "title": "DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via Next-Detail Prediction", "title_en": "DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via Next-Detail Prediction", "authors": "Yiheng Liu,Liao Qu,Huichao Zhang,Xu Wang,Yi Jiang,Yiming Gao,Hu Ye,Xian Li,Shuai Wang,Daniel K. Du,Fangmin Chen,Zehuan Yuan,Xinglong Wu", "background": "现有的生成模型主要集中于基于2D卷积神经网络或循环神经网络的方法，这些模型在计算复杂性和生成质量方面存在显著限制。特别地，1D自回归（AR）模型虽然在理论上提供了一种更高效的方式生成复杂视觉内容，但在实际应用中往往需要大量的参数和时间成本。", "innovation": "提出了DetailFlow，一种通过新颖的逐细节预测策略来建模图像的粗到细的1D自回归（AR）图像生成方法。DetailFlow通过学习基于逐级降级图像的分辨率感知token序列，使得生成过程能够从全局结构开始并逐步精细化细节。此外，引入了并行推断机制和自我纠正方法，相比之前的VAR/VQGAN方法，加快了生成速度并减少了误差。", "conclusion": "在ImageNet 256x256基准测试中，使用128个token， DetailFlow实现了2.96 gFID，超过了需要680个token的VAR (3.3 FID) 和 FlexVAR (3.05 FID) 的效果。并且，由于显著减少了token数量和并行推断机制，DetailFlow的推理速度几乎是VAR和FlexVAR的两倍。详尽的实验结果表明，DetailFlow在生成质量和效率方面均优于现有最先进的方法。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21528", "html_url": "https://arxiv.org/abs/2505.21528", "title": "一种基于随机最优控制的统一快速采样扩散桥梁框架", "title_en": "A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control", "authors": "Mokai Pan,Kaizhen Zhu,Yuexin Ma,Yanwei Fu,Jingyi Yu,Jingya Wang,Ye Shi", "background": "近年来，扩散桥梁模型通过Doob的$h$-变换建立了固定端点的概率分布，在图像转换和复原任务中取得了令人鼓舞的结果。然而，现有方法往往未能有效地保留图像细节，导致图像锐化不足或过度平滑，且缺乏系统的理论基础来解释这些问题。", "innovation": "为了弥补现有方法的不足，本文提出了一种基于随机最优控制（SOC）的统一和快速采样扩散桥梁框架UniDB。通过SOC优化重新表述问题，证明了现有扩散桥梁模型构成了UniDB的一个特殊子集，并通过引入可调节的终端惩罚系数实现了控制成本和终端惩罚的最佳平衡，从而显著改善了细节保留和输出质量。此外，设计了训练无需要的加速算法，通过推导反向SDE的精确解析解，避免了迭代欧拉采样方法带来的高计算代价。该方法还采用更稳定的数据预测模型替代了传统的噪声预测，并引入了SDE-Corrector机制以维持低步数情况下良好的感知质量。", "conclusion": "广泛的实验验证了所提出框架在图像复原任务中的优越性和适应性，填补了理论普适性和实际效率之间的差距。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04134", "html_url": "https://arxiv.org/abs/2506.04134", "title": "UniCUE：统一的汉语手势发音识别与生成框架以实现汉语手语视频到语音生成", "title_en": "UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation", "authors": "Jinting Wang,Shan Yang,Chenxing Li,Dong Yu,Li Liu", "background": "唇读通过手编码提供视觉音素提示，以支持聋人精确的语音感知。现有的大部分研究集中在手语识别（CSR），即将视频内容转换成文本。因此，CSV2S（手语视频到语音生成）的一种常见解决方案是结合CSR与文本到语音（TTS）系统。然而，这种方法依赖于文本作为中介，可能会导致错误传播和语音与手语视频动态的时间对齐问题。直接从手语视频生成语音对比之下面临更多的跨模态复杂性和有限的数据可用性挑战。", "innovation": "UniCUE 是首个直接从手语视频生成语音的统一框架，不依赖于文本中介。核心创新点在于结合理解任务（CSR），提供精细的手语视觉语义线索，以指导语音生成。具体来说，UniCUE 包含一个姿态感知视觉处理器、一个语义对齐池，能够实现精确的视觉语义映射，以及一个视觉音素适配器，用于在统一架构内连接理解和生成任务。", "conclusion": "全面的实验表明，UniCUE 在多个评估指标上达到了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14544", "html_url": "https://arxiv.org/abs/2509.14544", "title": "适应性增强的增量多视图聚类：关联与巩固", "title_en": "Association and Consolidation: Evolutionary Memory-Enhanced Incremental Multi-View Clustering", "authors": "Zisen Kong,Bo Zhong,Pengyuan Li,Dongxia Chang,Yiming Wang,Yongyong Chen", "background": "增量多视图聚类旨在在视图增量的场景中稳定聚类结果，但同时要解决稳定性和可塑性之间的难题。现有方法面临着既要快速适应新数据又要保持和整合长期知识的挑战。", "innovation": "本文提出了一种新颖的Evolutionary Memory-Enhanced Incremental Multi-View Clustering (EMIMC) 方法。该方法通过三个模块解决上述挑战：1) 快速关联模块，建立新老视图之间的联系以确保快速学习新知识所需的可塑性；2) 认知遗忘模块，通过动态调整历史视图的贡献来优化知识整合；3) 知识巩固模块，通过使用时间张量逐步将短期知识转化为长期记忆从而保证模型的稳定性。", "conclusion": "EMIMC在不断增长的视图场景中实现了强大的知识保留能力。实验结果表明，EMIMC相比于现有的最先进的方法具有显著的优势。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.02826", "html_url": "https://arxiv.org/abs/2511.02826", "title": "PLUTO-4: 边缘病理基础模型", "title_en": "PLUTO-4: Frontier Pathology Foundation Models", "authors": "Harshith Padigela,Shima Nofallah,Atchuth Naveen Chilaparasetti,Ryun Han,Andrew Walker,Judy Shen,Chintan Shah,Blake Martin,Aashish Sood,Elliot Miller,Ben Glass,Andy Beck,Harsha Pokkalla,Syed Ashar Javed", "background": "大型病理图像数据集训练的基础模型已经展示了在多种病理学任务中强大的迁移能力。在这一基础上，本文介绍了PLUTO-4，这是一种新一代的病理学基础模型，扩展了之前的Pathology-Universal Transformer（PLUTO）至更前沿的规模。", "innovation": "PLUTO-4家族中共有两款互补的Vision Transformer架构：一种用于多尺度部署的紧凑和高效的PLUTO-4S模型；一种单一尺度训练以最大化表达能力和稳定性的前沿规模PLUTO-4G模型。两种模型均使用自监督目标（基于DINOv2）在一个包含551,164份WSI的多机构数据集上进行预训练，数据来自跨越50多家机构的137,144名患者的超过60种疾病和超过100种染色类型。PLUTO-4在多个公开和内部基准测试中表现出色，特别是在需要不同空间和生物学上下文的任务中，包括拼图分类、分割和幻灯片级别诊断。", "conclusion": "灵活高效的PLUTO-4S提供了高吞吐量和稳健的表现，适用于实际部署；而PLUTO-4G则在多种病理学基准测试中建立了新的性能前沿，包括在皮肤病理诊断中取得了11%的提升。这些多样化的改进进一步验证了PLUTO-4作为跨学科研究和诊断用例的主干网络的巨大潜力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.18711", "html_url": "https://arxiv.org/abs/2509.18711", "title": "RSVG-ZeroOV：探索无训练框架实现远程感知识图的零样本开放词汇视觉定位", "title_en": "RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images", "authors": "Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang", "background": "现有方法通常受限于封闭词汇集，限制了在开放世界中的应用。虽然最近尝试利用通用基础模型进行开放词汇的远程感知识图，但这些方法过于依赖昂贵的高质量数据集和耗时的微调。", "innovation": "提出了RSVG-ZeroOV，这是一种无训练框架，旨在探索冻结的基础模型的潜力，以实现零样本开放词汇的远程感知识图。该框架包括三个关键阶段：(i) 通过视觉语言模型获得跨注意力图来捕捉文本查询和视觉区域之间的语义关联。(ii) 利用扩散模型的细致建模先验来填充关于对象结构和形状信息的空缺。(iii) 引入简单的注意力演化模块，以抑制无关激活，生成精炼的分割掩码。", "conclusion": "实验结果表明，所提出的框架在多种现有弱监督和零样本方法中表现更优。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10121", "html_url": "https://arxiv.org/abs/2510.10121", "title": "基于指尖敲击的注意力增强CNN BiLSTM多类别帕金森病检测", "title_en": "Multi Class Parkinson Disease Detection Based on Finger Tapping Using Attention Enhanced CNN BiLSTM", "authors": "Abu Saleh Musa Miah,Najmul Hassan,Md Maruf Al Hossain,Yuichi Okuyama,Jungpil Shin", "background": "准确评估帕金森病（PD）的严重程度对于临床管理和干预措施的开发至关重要。尽管提出了多种基于手势的PD识别系统，包括使用指尖敲击任务来评估帕金森病症状，但这些系统的性能仍然不令人满意。", "innovation": "本研究提出了一种基于指尖敲击的PD多类别检测系统，采用了注意力增强的CNN BiLSTM框架结合手工特征提取和深度学习技术。该模型首先通过Conv1D MaxPooling块提取局部空间依赖性，然后通过BiLSTM层建模运动的时序动态。应用注意力机制强调最相关信息的时序特征，然后通过第二个BiLSTM层进一步细化。最后，通过密集层和丢弃层将CNN提取的特征和注意力增强的BiLSTM输出进行连接，并通过Softmax分类器预测PD的严重程度级别。该方法展示了时空表示与注意力机制结合的优越性，实现自动PD严重程度检测。", "conclusion": "本模型在区分五类PD严重程度方面表现出色，证实了结合时空表示和注意力机制在自动PD严重程度检测中的有效性。此方法提供了一种非侵入性工具，帮助临床医生监测PD进展并做出知情治疗决策。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24563", "html_url": "https://arxiv.org/abs/2510.24563", "title": "OSWorld-MCP：评估计算机使用代理MCP工具调用能力的基准", "title_en": "OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents", "authors": "Hongrui Jia,Jitong Liao,Xi Zhang,Haiyang Xu,Tianbao Xie,Chaoya Jiang,Ming Yan,Si Liu,Wei Ye,Fei Huang", "background": "随着决策和推理能力的进步，多模态代理在计算机应用场景中展现了巨大的潜力。过去的评估主要集中在GUI交互能力上，而通过Model Context Protocol (MCP)实现的工具调用能力则被忽视。将集成工具调用能力的代理与仅基于GUI交互能力进行评估的代理进行比较是不公平的。为此，提出了OSWorld-MCP，这是一个首个全面且公正用于评估计算机使用代理工具调用、GUI操作和决策能力的基准工具集，在实际环境中进行综合评估。通过设计新的自动化代码生成管道来创建工具，并将现有工具中的精心挑选的工具与之结合，实现了158个高质量的工具（涵盖7个常用应用），每个工具都经过验证，确保了正确的功能、实际适用性和多功能性。", "innovation": "OSWorld-MCP 是首个全面且公正用于评估计算机使用代理工具调用、GUI操作和决策能力的基准工具集，在实际环境中进行综合评估。通过自动化代码生成管道创建并结合了158个高质量工具，并进行了严格的验证。广泛的实验表明，MCP工具在提高任务成功率方面有着显著的效果，但最强的模型在工具调用能力上的低效率也表明了进一步提升的空间。OSWorld-MCP 通过明确衡量MCP工具使用技能，为理解多模态代理和多任务环境下的性能评估设立了新的标准。所有的代码、环境和数据都已对外公开。", "conclusion": "OSWorld-MCP 深化了对多模态代理的理解，并为在复杂的工具辅助环境中评估代理性能设立了新的标准。进一步的工作在于如何提高代理的工具调用能力。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.00810", "html_url": "https://arxiv.org/abs/2511.00810", "title": "GUI-AIMA：将内在的跨模态注意力与上下文锚点对齐以实现GUI对准", "title_en": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "authors": "Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang", "background": "GUI接地是计算机代理的关键功能之一，它将自然语言指令映射到可操作的屏幕区域。现有基于多模态大型语言模型（MLLMs）的方法通常将其形式化为文本坐标生成任务。然而，直接从视觉输入生成精确坐标仍然是一个具有挑战性且计算密集型的问题。一种直观的方法是首先选择与指令相关的视觉插件，然后在这些插件内确定精确的点击位置。鉴于通用MLLMs具有一定程度的内在接地能力，我们提出了一种基于注意力且无坐标监督微调框架GUI-AIMA，以高效实现GUI接地。GUI-AIMA将MLLMs的内在多模态注意力与基于插件的接地信号对齐。这些信号通过简化查询-视觉注意力矩阵的多头聚合计算，以便根据各种用户指令进行自适应计算。", "innovation": "提出了一种基于注意力且无坐标监督微调框架GIU-AIMA，将MLLMs的内在多模态注意力与基于插件的接地信号对齐，通过简化查询-视觉注意力矩阵的多头聚合计算自适应信号。该方法仅使用85,000个屏幕截图进行训练，展示了出色的数据效率，并验证了轻量级训练可以激活MLLMs的内在接地能力，该模型在ScreenSpot-Pro、OSWorld-G和ScreenSpot-v2上分别达到了59.6%、63.8%和91.5%的平均准确率。", "conclusion": "GUI-AIMA作为一种注意力驱动且无坐标训练的方法，不仅展示了出色的数据效率，还证明了轻量级训练可以激活MLLMs的内在接地能力。该模型在多个评估指标上取得了最先进的性能。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21486", "html_url": "https://arxiv.org/abs/2509.21486", "title": "增强推理能力的领域自适应多模态大语言模型预训练以治理短视频内容", "title_en": "Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Governance", "authors": "Zixuan Wang,Yu Sun,Hongwei Wang,Baoyu Jing,Xiang Shen,Xin Dong,Zhuolin Hao,Hongyu Xiong,Yang Song", "background": "短视频平台正在迅速发展，使得识别不适宜内容变得越来越关键。现有的方法通常为每种问题类型训练单独的小型分类模型，这需要大量的标注数据，并且缺乏跨问题的泛化能力。", "innovation": "我们提出了一种增强推理能力的多模态大语言模型（MLLM）预训练范式，用于统一的不适宜内容检测。为了弥合短视频内容与MLLM原始预训练数据之间的分布差异，以及解决复杂的问题定义，我们引入了三种有针对性的预训练任务：(1) 描述 (Caption)，以提升MLLM对视频细节的感知；(2) 视觉问答 (VQA)，以深入理解问题定义和标注指南；(3) 推理链 (CoT)，以增强MLLM的推理能力。实验结果表明，我们的预训练方法在零样本和监督微调（SFT）两种设置下都显著提高了MLLM的性能。此外，我们的预训练模型还展示了强大的泛化能力来应对新的、未见过的问题类型。", "conclusion": "我们的研究显著提升了MLLM在不适宜内容检测中的性能，并展示了其强大的泛化能力以应对新出现的问题。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22262", "html_url": "https://arxiv.org/abs/2509.22262", "title": "UniMapGen: 多模态数据生成框架在大规模地图构建中的应用", "title_en": "UniMapGen: A Generative Framework for Large-Scale Map Construction from Multi-modal Data", "authors": "Yujian Yuan,Changjie Wu,Xinyuan Chang,Sijin Wang,Hang Zhang,Shiyi Liang,Shuang Zeng,Mu Xu,Ning Guo", "background": "大规模地图构建在自动驾驶和导航系统等领域中发挥着重要作用。传统的地图构建方法依赖于成本高昂且效率低的数据采集车辆和劳动密集型标注过程。虽然现有的基于卫星的方法在提高地图构建的效率和覆盖范围方面显示出潜力，但它们存在两大局限：（1）卫星数据的固有缺点（如遮挡和过时性）；（2）基于感知的方法在矢量化过程中效率低下，导致道路不连续且粗糙，需要大量后续处理。", "innovation": "该论文提出了一个名为UniMapGen的新型生成框架，用于大规模地图构建，提供了三个关键创新：（1）将车道线表示为离散序列，并建立一个迭代策略以生成比传统感知方法更完整和光滑的地图矢量。 （2）提出了一个灵活的架构，支持多模态输入，可以在卫星数据的局限性之间进行动态选择，包括BEV、PV和文本提示。 （3）开发了一种状态更新策略，确保构建的大规模地图的全球连续性和一致性。 UniMapGen在OpenSatMap数据集上实现了最先进的性能，并且可以推断出被遮挡的道路并预测数据集中未标注的道路。", "conclusion": "UniMapGen通过其创新的生成框架和多模态输入处理能力，在大规模地图构建方面取得了卓越的性能，展示了在自动驾驶和导航系统中的应用潜力。我们的代码将公开发布。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13795", "html_url": "https://arxiv.org/abs/2510.13795", "title": "Bee: 一种高质量语料库和全栈套件以解锁高级完全开放的多模态大语言模型", "title_en": "Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs", "authors": "Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu", "background": "当前完全开放的多模态大语言模型（MLLMs）在质量上落后于拥有一定数据使用权的模型，主要原因是监督微调（SFT）的数据质量显著不足。现有的开源数据集常常受到广泛噪声的影响，而且缺乏复杂推理数据，例如链式推理（CoT），这阻碍了高级模型能力的发展。", "innovation": "本文作出了三项主要贡献。首先，引入了包含约1500万个问答对、经过多种清洗技术处理并采用一种新颖的双级别（短和长）CoT丰富策略的Honey-Data-15M数据集。其次，提出了数据管理管道HoneyPipe及其底层框架DataStudio，为社区提供了一个透明且可调整的数据管理方法，超越了静态数据集的发布。最后，通过Honey-Data-15M训练了模型Bee-8B。实验表明，Bee-8B在完全开放的MLLM中建立了新标准，其性能与甚至在某些方面超过了近期的半开放模型如InternVL3.5-8B。该工作向社区提供了一套基础资源，包括Honey-Data-15M语料库、HoneyPipe和DataStudio全栈套件、训练食谱、评价套件及模型权重。", "conclusion": "我们的研究证明，集中关注数据质量是开发与半开放版本高度竞争的完全开放的MLLM的关键途径。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13630", "html_url": "https://arxiv.org/abs/2510.13630", "title": "AVAR-Net：一种轻量级的音频-视觉异常识别框架及其基准数据集", "title_en": "AVAR-Net: A Lightweight Audio-Visual Anomaly Recognition Framework with a Benchmark Dataset", "authors": "Amjid Ali,Zulfiqar Ahmad Khan,Altaf Hussain,Muhammad Munsif,Adnan Hussain,Sung Wook Baik", "background": "在监控、交通、医疗和公共安全等领域，异常检测扮演着至关重要的角色。然而，现有的大多数方法仅依赖于视觉数据，在诸如遮挡、低照度和恶劣天气等挑战性条件下可靠性不足。此外，缺乏大规模同步的视听数据集阻碍了多模态异常检测的进步。为了解决这些问题，本文提出了一种名为AVAR-Net的轻量级和高效的视听异常识别框架，适用于真实环境。AVAR-Net包含四个主要模块：音频特征提取器、视频特征提取器、融合策略和用于建模多模态关系的序列模式学习网络。", "innovation": "AVAR-Net框架包含了Wav2Vec2音频特征提取器和MobileViT视频特征提取器，这些模块能够从原始音频中提取出稳健的频域特征，并从视频帧中捕捉局部和全局视觉表示。通过早期融合机制和Multi-Stage Temporal Convolutional Network（MTCN）模型，AVAR-Net可以在融合表示中学习长范围的时间依赖性，从而增强对视听数据的鲁棒时空推理能力。同时，本文还提出了一个新的用于视听异常识别的基准数据集VAAR，包含3000段带有同步音频的真实世界视频，覆盖了十个不同的异常类别。实验结果显示，AVAR-Net在VAAR和XD-Violence数据集上分别达到了89.29%和88.56%的准确率和平均查准率，超过了现有最先进的方法。这些结果强调了该框架的有效性、高效性和泛化能力，以及VAAR数据集在推动多模态异常识别研究中的重要性。", "conclusion": "AVAR-Net框架通过结合视听数据的有效融合机制和序列模式学习网络，显著提高了在复杂环境下的异常检测精度。同时，AVAR-Net还提供了一个大规模的视听异常识别基准数据集VAAR，可以促进相关领域的进一步研究。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03912", "html_url": "https://arxiv.org/abs/2511.03912", "title": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging", "title_en": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging", "authors": "Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)", "background": "在医学影像中，由于缺乏标记异常样本和专家监督成本高昂，未知异常检测仍然是一个基本挑战。现有的方法通常需要大量标注数据和专家监督，这在实际应用中往往难以实现。因此，一种不需要标记数据和专家监督的增量自监督异常检测框架变得尤为重要。该框架从少量已验证的正常样本开始，逐步扩大正常样本集，而不需要依赖生成重建或回放缓冲区来防止漂移和误包含，进一步改善了ROC-AUC等指标。", "innovation": "该研究提出了一个无监督的、不需要oracle的框架，该框架可以通过自适应提升已信任的正常样本集合，同时确保快速的领域适应性和最小的计算开销。采用冻结的预训练视觉骨干并增加小型卷积适配器，以确保快速适应性。该系统通过双重概率门控机制安全地进行增量扩展，确保只有当样本与现有核心集的距离在校准的z分数阈值内并且其基于SWAG的表征不确定性低于种子校准的上限时，样本才会被接纳进入正常记忆。该机制能够在没有生成重建或回放缓冲区的情况下防止漂移和误包含，从而提高了检测性能和效率。", "conclusion": "通过实验证实，该系统能够逐步细化正常性的概念，并在未标记数据不断到达的情况下产生显著的改进。在COVID-CXR、肺炎胸片和脑MRI ND-5数据集上的评估结果显示，ROC-AUC等指标大幅提高，表明该框架在真实世界、稀缺标签的医学影像应用中的有效性和效率。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.06973", "html_url": "https://arxiv.org/abs/2511.06973", "title": "Oh That Looks Familiar: 一种新的电子表格模板发现相似度度量", "title_en": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery", "authors": "Anand Krishnakumar,Vengadesh Ravikumaran", "background": "传统方法在识别结构相似的电子表格时，无法捕捉定义模板的布局和类型模式。已有方法试图量化电子表格的相似性，但效果不尽如人意。", "innovation": "这篇文章提出了一种结合语义嵌入、数据类型信息和空间定位的混合距离度量方法，用来计算电子表格相似性。该方法将电子表格转换为单元格级别的嵌入，然后使用如Chamfer和Hausdorff距离的聚合技术来计算相似性，实验表明该方法在模板家族中优于基于图的Mondrian基线方法，实现完美的模板重建（调整兰德指数为1.00，而基线为0.90），并在FUSTE数据集上表现优秀。", "conclusion": "该方法促进了大规模自动化模板发现，这为进一步的应用如表型集合的检索增强生成、模型训练和批量数据清理提供了可能性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07459", "html_url": "https://arxiv.org/abs/2511.07459", "title": "通过减少标签分布变异性来优化不常见标签的分类", "title_en": "Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution", "authors": "Ashutosh Agarwal", "background": "在极端分类（XC）任务中，不常见的类别由于样本稀疏和标签不一致性高，往往表现不佳，导致分类性能下降。现有方法未能有效地解决这一问题，需要一种新的解决方案来改善不常见类别的处理效果，提升整体分类性能。", "innovation": "该研究提出了名为LEVER的创新解决方案，采用鲁棒的Siamese风格架构，通过知识迁移减少标签不一致性，优化One-vs-All分类器的性能，从而显著提高不常见类别的处理能力，建立了该领域的新的基准。此外，还引入了两个新的多意图数据集，为未来的研究提供了重要资源。", "conclusion": "经过在多个XC数据集上的全面测试，LEVER显著提高了不常见类别的处理效果，为极端分类领域的研究设立了新的标准。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.12728", "html_url": "https://arxiv.org/abs/2509.12728", "title": "仅振幅扩散先验的通用全息重建", "title_en": "Generalizable Holographic Reconstruction via Amplitude-Only Diffusion Priors", "authors": "Jeongsol Kim,Chanseok Lee,Jongin You,Jong Chul Ye,Mooseok Jang", "background": "在相干成像中，实时全息图中的相位检索是一个关键但不明确的逆问题，因为振幅和相位之间存在非线性耦合。当前方法通常需要包含真实相位数据的定制训练集来重建复杂电场。", "innovation": "本文提出了一种仅使用振幅数据训练的扩散模型，能够从衍射强度中恢复振幅和相位。使用预测-修正采样框架并分别对振幅和相位进行优化梯度，该方法可以在没有真实相位数据的情况下重建复杂场。并且，证实了在多种对象形状、成像系统配置和模态的广泛模拟和实验中具有鲁棒性。特别是使用简单振幅数据（如聚苯乙烯微球）训练的扩散先验可以重建复杂的生物组织结构，显示了其适应能力。", "conclusion": "本文框架提供了一种低成本且可普遍应用于非线性逆问题的解决方案，在计算成像中建立了一个更广泛相干成像应用的基础，超越了全息技术的局限。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22340", "html_url": "https://arxiv.org/abs/2510.22340", "title": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "title_en": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "authors": "Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen", "background": "当前的多模态数学推理基准主要关注2D平面几何，依赖静态数据集容易受到数据污染和记忆化的影响，并且仅通过最终答案来评估模型效果，忽视了推理过程。几何问题解决需要空间数学推理，这种推理融合了空间智能和符号推理。", "innovation": "为了克服现有问题，作者引入了DynaSolidGeo，这是一个动态基准，专门用来评估视觉语言模型（VLMs）在立体几何中的真正空间推理能力。DynaSolidGeo通过半自动注释管道构建，包含503个专家精心筛选的问题种子，这些种子可以生成无限数量的多样化的多模态文本-视觉实例。此外，它还包括过程评估，基于专家注释的推理链来评估逻辑有效性与因果连贯性。", "conclusion": "实验结果显示，代表性的开源和专有VLMs在DynaSolidGeo上的性能存在巨大差异，在动态场景中表现严重下降，并且在需要高级空间智能的任务（如心理旋转和可视化）上表现不佳。相关代码和数据集可从\textit{DynaSolidGeo}获取。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05873", "html_url": "https://arxiv.org/abs/2511.05873", "title": "EndoIR：噪声感知路由扩散的退化无关的一站式内窥镜图像恢复", "title_en": "EndoIR: Degradation-Agnostic All-in-One Endoscopic Image Restoration via Noise-Aware Routing Diffusion", "authors": "Tong Chen,Xinyu Ma,Long Bai,Wenyang Wang,Yue Sun,Luping Zhou", "background": "内窥镜图像通常会受到多种共存退化（如低光照、烟雾、出血）的影响，这些退化会遮蔽重要的临床细节。现有的恢复方法通常是针对特定任务设计的，并且往往需要先了解退化类型，这限制了它们在实际临床环境中的鲁棒性。", "innovation": "提出了EndoIR，一个集成退化无关的基于扩散的框架，可以使用单一模型恢复多种退化类型。EndoIR 引入了双重领域提示器，提取联合空间-频率特征，并结合自适应嵌入，编码共享和任务特定的线索作为去噪的条件。设计了双重流扩散架构，分别处理干净和退化输入，通过修正融合块以结构化、退化感知的方式整合它们。此外，噪声感知路由块在去噪过程中动态选择仅与噪声相关的特征，提高效率。", "conclusion": "在 SegSTRONG-C 和 CEC 数据集上的实验表明，EndoIR 在多种退化场景下达到了最先进的性能，参数量比强大基线更少，下游分割实验验证了其临床应用价值。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "临床不确定性影响机器学习评估", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集的标签往往是不确定的，因为注释者存在分歧且对不同案例的置信度不一致。传统的聚合方法，如多数投票，会掩盖这种不确定性。在简单的医学影像基准实验中，考虑到二元标签的置信度对模型排名的影响显著。这一现象表明，在机器学习评估中，应明确考虑标注的不确定性，使用可以直接作用于分布的概率指标。这些指标的应用与标注过程无关，无论是通过简单的计数、主观的置信评分还是概率响应模型，同时也具有计算上的轻量性，一旦按模型得分排序后，封闭形式的表达式就可以实现线性时间的计算。因此，建议社区向数据集提供原始注释，并采用对不确定性具有感知能力的评估方法，以便更准确地反映临床数据的表现估计。", "innovation": "本文创新性地指出，应使用概率指标来明确评估机器学习模型在考虑到标注不确定性的前提下的表现，这种指标可以独立于生成注释的过程进行计算，且计算效率高。建议在评估模型时应公开原始标注数据，以更好地评估模型在临床环境下的表现效果", "conclusion": "作者呼吁研究界提供原始标注数据，并采用对不确定性敏感的评估方法，以使得性能估计更好地反映临床数据的真实情况。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05868", "html_url": "https://arxiv.org/abs/2511.05868", "title": "HarmoQ: 协调化后训练量化以实现高保真图像恢复", "title_en": "HarmoQ: Harmonized Post-Training Quantization for High-Fidelity Image", "authors": "Hongjun Wang,Jiyuan Chen,Xuan Song,Yinqiang Zheng", "background": "后训练量化为部署超分辨率模型提供了一种高效途径，但现有方法将权重和激活量化独立处理，未能充分利用它们之间的关键交互。现有方法在SwinIR上的控制实验揭示了明显的不对称性：权重量化主要降低了结构相似性，而激活量化则在像素级准确度上损失更多。这是因为权重编码了纹理和边缘的先验知识，而激活则携带了输入特定的强度信息。", "innovation": "提出了HarmoQ，一种统一框架，通过三个协同步骤协调量化：结构残差校准主动调整权重以补偿激活引起的细节损失；协调标度优化通过封闭解形式分析平衡量化难度；自适应边界细化在优化过程中逐迭代维持这种平衡。HarmoQ在压缩下实现了显著的性能提升，在Set5上比前人方法高出0.46 dB，同时在A100 GPU上分别提供了3.2倍的速度提升和4倍的内存减少。本工作率先系统分析了超分辨率量化中权重-激活耦合，并为高效高质量图像恢复提供了原理性解决方案。", "conclusion": "HarmoQ在压缩下达到了显著性能提升，在Set5上相比前人方法高出0.46 dB，并实现了3.2倍的速度提升和4倍的内存减少，同时也提供了一种系统性分析权重-激活耦合的方法并提出了协调化后训练量化的新框架。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21402", "html_url": "https://arxiv.org/abs/2510.21402", "title": "通过模块化组合偏见实现解耦表示学习", "title_en": "Disentangled Representation Learning via Modular Compositional Bias", "authors": "Whie Jung,Dong Hoon Lee,Seunghoon Hong", "background": "近年来，解耦表示学习（DRL）方法主要依赖于特定因素的策略，无论是为了属性设计学习目标还是为了对象设计模型架构，来嵌入归纳偏置。然而，当新的变化因素与先前假设不一致，或当多个因素共存时，这些差异的策略会导致显著的冗余。从业者必须重新设计架构或目标，以应对这些情况。", "innovation": "本文提出了一个组合偏见，这是一个模块化的归纳偏置，与目标和架构脱钩。本文的关键洞察是，不同的因素在数据分布中遵循不同的重组规则：全局属性是互斥的，例如一张脸只有一个鼻子，而对象共享一个公共支持（任何对象的子集都可以共存）。因此，本文根据因素特定规则随机重新组合潜在变量，并强制编码器发现混合策略反映的任何因素结构，通过两个互补的目标实现：（i）先验损失，确保每次重新组合都能解码出真实的图像，(ii) Wiedemer等人引入的组成一致性损失（arXiv:2310.05327），该损失使组合图像与其对应的组合潜在变量保持一致。在这一通用框架下，通过简单的调整混合策略即可实现属性、对象甚至两者的解耦，而无需修改目标或架构。实验结果证明，本文的方法在属性和对象解耦方面均表现出竞争力，特别实现了全局风格和对象的联合解耦。", "conclusion": "在本文提出的通用框架下，通过调整混合策略能够实现属性、对象甚至两者同时的解耦，而无需修改前期的目标或架构。实验证明，本文的方法在属性和对象解耦方面均表现出色，并独立试图实现全球风格和对象的联合解耦。"}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01292", "html_url": "https://arxiv.org/abs/2508.01292", "title": "CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis", "title_en": "CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis", "authors": "Alec Sargood,Lemuel Puglisi,James H. Cole,Neil P. Oxtoby,Daniele Ravì,Daniel C. Alexander", "background": "利用结构MRI模态合成淀粉样蛋白PET扫描为大规模阿尔茨海默病(AD)筛查提供了一种有前景且成本效益高的方法。虽然MRI不能直接检测淀粉样蛋白病理，但有证据表明，MRI可能编码与淀粉样蛋白沉积相关的信息，这些信息可以通过高级建模来揭示。然而，3D神经成像数据的高维度和结构复杂性给现有的MRI到PET转换方法带来了重大挑战。通过在低维度的潜在空间中建模跨模态关系，可以简化学习任务并使转换更有效。", "innovation": "CoCoLIT (ControlNet-Conditioned Latent Image Translation) 使用了一种基于扩散的潜在生成框架，包括：(1) 一种新颖的加权图像空间损失(Weighted Image Space Loss, WISL)，提高潜在表示学习和合成质量；(2) 对潜在平均稳定化(Latent Average Stabilization, LAS)的理论和实证分析，这是一种在类似生成模型中用于增强推断一致性的方法；(3) 引入了ControlNet基条件用于MRI到PET的转换。", "conclusion": "我们在公共数据集上评估了CoCoLIT的性能，并发现我们的模型在图像基和淀粉样蛋白相关度量上均显著优于当前最先进的方法。值得注意的是，在淀粉样蛋白阳性分类中，CoCoLIT在内部数据集上的性能提高了10.5%，在外部数据集上提高了23.7%。我们的方法的代码和模型可在该链接获取：[https://.../](https://.../)."}
{"llm_update_time": "20251113", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05529", "html_url": "https://arxiv.org/abs/2511.05529", "title": "基于准确度加权的深度集成与熵导向的保留错误分类的糖尿病视网膜病变筛查", "title_en": "Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Abstention", "authors": "Jophy Lin", "background": "糖尿病视网膜病变（DR）是糖尿病的微血管并发症，是可预防失明的主要原因之一，预计到2030年将影响超过1.3亿人。早期识别是减少不可逆视力丧失的关键，然而当前的诊断流程依赖于如眼底摄影和专家审阅等方法，这些方法成本高且资源密集型。DR的无症状特性导致其漏诊率高达约25%。尽管卷积神经网络（CNNs）在医学影像任务中表现出强劲性能，但其透明度有限且缺乏不确定性量化，限制了其临床可靠度。因此，在这项研究中，提出了一种结合不确定性估计的深度集成学习框架，以提高DR检测的稳健性、透明性和可扩展性。该集成包含七种CNN架构，并通过准确度加权多数投票策略融合输出。一种概率加权熵度量评估预测不确定性，使低置信度样本能够被排除或标记为需要进一步审视。在35,000张EyePACS眼底图像上进行的训练和验证达到了高达93.70%（F1=0.9376）的未筛选准确率。通过不确定性过滤后，准确率达到了99.44%（F1=0.9932）。\n", "innovation": "在该研究中引入了一种结合不确定性估计的深度集成学习框架，使用七种CNN架构，通过准确度加权多数投票策略融合输出，并以概率加权熵度量量化预测不确定性。这种不确定性导向的保留策略排除了低置信度样本，从而提高了检测的准确性和可靠性。此框架的创新之处在于能够提供校准后的输出和可调的准确率-覆盖率权衡，为在高风险护理中部署可信的AI诊断提供了通用范式。\n", "conclusion": "该框架表明，不确定性敏感且加权的集成可以提高检测可靠性，不阻碍性能。带有置信度校准输出和可调准确率-覆盖率权衡，它提供了一种部署可信赖的人工智能诊断的通用范式。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07472", "html_url": "https://arxiv.org/abs/2511.07472", "title": "多变量变分自动编码器", "title_en": "Multivariate Variational Autoencoder", "authors": "Mehmet Can Yavuz", "background": "变分自编码器（VAEs）是一种强大的生成模型，但由于其高斯后验分布的限制，通常只能模拟对角协方差。这种限制限制了VAEs捕捉数据集中变量间广泛关联的能力", "innovation": "作者提出了多变量变分自编码器（MVAE），通过引入全局耦合矩阵C来使潜变量之间在整个数据集范围内具有协方差，并通过样本特有的对角缩放来调节局部不确定性，从而克服了对角协方差限制。MVAE允许完全协方差，并且能够提供分析的KL散度和高效的重参数化", "conclusion": "MVAE在多个MNIST变体、Fashion-MNIST、CIFAR-10和CIFAR-100数据集上的表现优于对角协方差的VAE，特别是在中等大小的潜在空间。该模型在重建、校准和无监督结构方面提供了稳健的改进，同时提供了更平滑和一致的潜变量空间可视化结果"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07470", "html_url": "https://arxiv.org/abs/2511.07470", "title": "可调节运行时计算成本的可扩展NAM：可调振荡器模型", "title_en": "Slimmable NAM: Neural Amp Models with adjustable runtime computational cost", "authors": "Steven Atkinson", "background": "该研究基于现有神经振荡器模型（NAM），这些模型在音乐创作和音频处理中具有重要作用。然而，传统的NAM模型在准确性和计算成本之间缺乏灵活性，通常只能在设计时固定下来。因此，研究者提出了可调振荡器模型（Slimmable NAM），以提高模型使用的灵活性，并提供了在不额外训练的情况下调整模型大小和计算成本的方法，同时将计算成本的增加保持在最小范围内，满足了音乐家在创作中对不同计算资源的需求变化。", "innovation": "此项工作提出了「可调振荡器模型」（Slimmable NAM），其创新点在于能够改变模型的大小和计算成本而无需额外的训练，并且具有几乎可以忽略的额外计算开销。此外，该模型的性能被与常用基准进行量化比较，并在音频效果插件中实现了实时演示。这些特点使得音乐家可以根据实际使用场景，灵活地平衡模型的精度和计算需求。", "conclusion": "研究展示了可调振荡器模型（Slimmable NAM）在音乐创作和音频处理中的应用潜力。这一方法不仅提升了模型使用的灵活性，还通过调整模型大小和计算成本，优化了不同场景下的性能表现。研究人员表示，这一方法未来有希望进一步应用于其他需要实时计算的音频处理领域。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07471", "html_url": "https://arxiv.org/abs/2511.07471", "title": "为异常检测迈向个性化的量子联邦学习", "title_en": "Towards Personalized Quantum Federated Learning for Anomaly Detection", "authors": "Ratun Rahman,Sina Shaham,Dinh C. Nguyen", "background": "在视频监控、医学诊断和工业监测等应用中，异常检测对性能至关重要。这些应用中的异常经常依赖于特定上下文，而标注的异常数据相对较少。传统方法面临的问题包括在量子网络中，量子客户端硬件能力、电路设计、噪声水平和经典数据到量子状态的编码或预处理方法各不相同，导致了客户端间的数据分布和量子处理行为存在异质性。这些差异使得单一全球模型的训练效果不佳，特别是在客户端处理不平衡或非同分布（non-IID）数据时更为明显。", "innovation": "为解决以上问题，本文提出了一种新的框架——个性化量子联邦学习（PQFL）。该框架通过使用参数化量子电路和经典优化器增强量子客户端的本地模型训练，并引入了一个量子中心化的个性化策略，使每个客户端的模型能够适应自身的硬件特性和数据表示。实验结果显示，PQFL在多种现实条件下显著提高了异常检测的准确性，与现有最佳方法相比，PQFL将误报率降低了23%，AUROC提升24.2%，AUPR提升20.5%，显示出其实用性和可扩展性。", "conclusion": "本文通过提出PQFL框架，解决了由于非同分布数据而导致的单一全球模型训练效果不佳的问题，提升了量子联邦学习在异常检测中的准确性和适用性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07651", "html_url": "https://arxiv.org/abs/2511.07651", "title": "使用Siamese网络增强二进制编码犯罪关联分析", "title_en": "Enhancing Binary Encoded Crime Linkage Analysis Using Siamese Network", "authors": "Yicheng Zhan,Fahim Ahmed,Amy Burrell,Matthew J. Tonkin,Sarah Galambos,Jessica Woodhams,Dalal Alrajeh", "background": "有效的犯罪链接分析对于识别系列犯并增强公共安全至关重要。传统的犯罪链接方法在处理高维、稀疏和异构数据时存在局限性，因此需要新的方法来提高犯罪数据的分析效率和准确性。", "innovation": "该研究提出了一种Siamese Autoencoder框架，能够学习有意义的潜在表示并揭示复杂犯罪数据中的关联性。该方法通过在解码器阶段整合地理时间特征，减轻信号稀释，从而突出行为特征，提供了一种在犯罪链接分析中进行高级机器学习的方法，并通过减少数据策略提高了模型性能。", "conclusion": "先进的机器学习方法可以显著提高犯罪链接的准确性，AUC值相较于传统方法提高了9%，并且提供了支持调查决策的可解释洞见。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07637", "html_url": "https://arxiv.org/abs/2511.07637", "title": "Private-RAG: 在保持数据隐私的同时使用LLMs回答多个查询", "title_en": "Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private", "authors": "Ruihan Wu,Erchi Wang,Zhiyuan Zhang,Yu-Xiang Wang", "background": "检索增强生成（RAG）通过在推理时从外部语料库检索文档来增强大型语言模型（LLMs）。然而，当该语料库包含敏感信息时，不加保护的RAG系统则存在泄露私人信息的风险。在此之前的工作中，提出了差分隐私（DP）保证来保护RAG系统，但这些保证仅限于单一查询场景，无法满足实际的使用需求。", "innovation": "本文研究了更具实际意义的多查询场景，并提出了两种DP-RAG算法：第一种算法MURAG引入了个体隐私滤波器，使得累积的隐私损耗仅依赖于每个文档被检索的频率，而非查询总数。第二种算法MURAG-ADA在此基础上进一步提高效用，通过以隐私方式发布查询特定的阈值，使得相关文档的选择更加精准。", "conclusion": "我们在多个LLM和数据集上的实验表明，所提出的方法在普适度（$\boldsymbol{\nu} \thicksim 10$）下可处理数百个查询，同时保留有意义的效用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07649", "html_url": "https://arxiv.org/abs/2511.07649", "title": "基于transformer的自适应图学习在多水库来水预测中的应用", "title_en": "Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction", "authors": "Pengfei Hu,Ming Fan,Xiaoxue Han,Chang Lu,Wei Zhang,Hyun Kang,Yue Ning,Dan Lu", "background": "水库来水预测对水资源管理至关重要，现有方法主要集中在单一水库模型上，忽略了互连水库之间的空间依赖性。本文通过对Upper Colorado River Basin中的30个水库进行评估，证明了现有的单水库模型无法充分考虑这些依赖性，从而影响预测的准确性。", "innovation": "提出了一种自适应的、时间变化的图学习框架AdaTrip，适用于多水库来水预报。AdaTrip通过构建动态图，利用注意力机制自动识别关键的空间和时间依赖性，取得了优于现有基线模型的性能，特别是对于记录数据较少的水库，共享参数提高了预测能力。此外，AdaTrip还提供了在边和时间步层面的可解释注意力图，有助于深入理解水资源控制，支持操作决策。", "conclusion": "AdaTrip框架在多水库来水预测中表现优异，不仅能提高预测精度，还能提供有意义的关注图，有助于水资源管理的实际应用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07694", "html_url": "https://arxiv.org/abs/2511.07694", "title": "仅需概率: 大型语言模型不确定性估计的纯概率方法", "title_en": "Probabilities Are All You Need: A Probability-Only Approach to Uncertainty Estimation in Large Language Models", "authors": "Manh Nguyen,Sunil Gupta,Hung Le", "background": "大型语言模型（LLMs）在各项自然语言处理（NLP）任务中表现出色，但在生成话语时可能表现出误导性或事实错误，即幻觉现象。现有方法通过预测熵评估语义不确定性，但通常需要多次采样或增加计算量。本文背景在于寻找一种更有效的不确定性评估方法，以提高LLM的可信度和准确性.", "innovation": "本文提出了一种无需训练且高效的不确定性评估方法，通过回应的前$K$概率来近似预测熵。此外，引入了自适应机制来确定$K$的值，以增强灵活性并过滤掉低置信概率。该方法在三个自由形式问答数据集上的实验结果表明，其性能优于现有昂贵的基线方法，为增强LLM的可信度做出了贡献.", "conclusion": "本研究提出了一种纯概率方法来估计大型语言模型的不确定性，该方法能够有效抑制幻觉并增强模型的可信度，同时验证了其在多个LLM上的优越性能，对提高LLM的鲁棒性和可信度具有重要意义."}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07701", "html_url": "https://arxiv.org/abs/2511.07701", "title": "在强化学习中的扩散引导敌对状态扰动", "title_en": "Diffusion Guided Adversarial State Perturbations in Reinforcement Learning", "authors": "Xiaolin Sun,Feidi Liu,Zhengming Ding,ZiZhan Zheng", "background": "强化学习（RL）系统在许多领域取得了显著成功，但它们容易受到 adversarial attacks 的攻击。特别地，在基于视觉的环境中，高维度的图像输入的微小操纵即可轻易误导代理的行为。尽管目前已经提出了多种防御方法，这些方法在大规模状态扰动下表现优秀，但在细致研究后发现，这些防御的有效性依赖于现有 $l_p$ 范数约束攻击的根本弱点，即使在较大的扰动预算下，也难以改变图像输入的语义。", "innovation": "本文提出了一种名为 SHIFT 的新的政策无关的扩散基础状态扰动攻击，旨在超越上述限制。该攻击能够生成在语义上不同于真实状态但保持现实和历史一致性的扰动，以避免检测。实验证明，该攻击有效打破了现有防御，包括最先进的防御，表现出更高的感知隐蔽性，显著优于现有的攻击方法。此结果凸显了 RL 代理对具有语义意识的对抗性扰动的脆弱性，强调了开发更健壯策略的重要性。", "conclusion": "研究结果突出了 RL 代理对具有语义意识的对抗性扰动的脆弱性，强调了开发更加稳健策略的重要性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07702", "html_url": "https://arxiv.org/abs/2511.07702", "title": "使用科学机器学习框架的多参数微混流器智能优化", "title_en": "Intelligent Optimization of Multi-Parameter Micromixers Using a Scientific Machine Learning Framework", "authors": "Meraj Hassanzadeh,Ehsan Ghaderi,Mohamad Ali Bijarchi,Siamak Kazemzadeh Hannani", "background": "多维度优化一直是工程中的关键挑战。然而，传统的基于仿真的优化方法存在显著的局限性，通常只能同时优化单一问题，并且需要大量的计算时间和用于网格划分和数值模拟的时间。", "innovation": "该论文提出了一种结合前沿科学机器学习（Sci-ML）方法的新框架，以克服传统方法的固有限制。新方法能够给定多个复杂、多维度优化问题提供即时解决方案。通过微流混合器实例来展示该方法。方法基于深度强化学习（DRL）架构的代理来探索关键问题参数之间的关系，并与参数物理知情神经网络（PINN）交互，能够以比传统数值方法更快的速度响应代理的行为。代理的目标是在不同Schmidt数下探索最优的几何和物理参数以最大化微混流器效率。", "conclusion": "在广泛施加Schmidt数后，对结果进行的最优设计分析显示，在整个施加范围内，该方法所达到的效率都优于基线值。最大效率出现在Schmidt数为13.3的地方，效率提升约32%。同时，通过等条件比较遗传算法，进一步突显了该方法的优势。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07724", "html_url": "https://arxiv.org/abs/2511.07724", "title": "基于排序优化的汽车共享服务中车辆重定位问题算法", "title_en": "A Ranking-Based Optimization Algorithm for the Vehicle Relocation Problem in Car Sharing Services", "authors": "Piotr Szwed,Paweł Skrzynski,Jarosław Wąs", "background": "本研究探讨了自由浮动汽车共享服务中的车辆再定位问题，提出了基于滑板车的车辆再定位和人员转移策略。研究通过将服务区域划分为具有相似时间规律的服务区域来应用离散优化方法，并提出了一种快速基于排名的算法，该算法依据每个区域的车辆数量、预测的需求概率密度和估计的旅行时间做出决策。实验数据来自于波兰一家主要汽车共享服务运营商的真实数据，评估了算法在未优化基准和混合整数规划模型结果之间的表现差异，主要以总旅行时间作为性能指标。", "innovation": "提出了一种基于排序的优化算法，该算法可根据每个区域的车辆数量、预测的需求概率密度和估计的旅行时间进行快速决策；通过滑板车辅助车辆再定位和人员转移；使用真实数据进行实验，并将研究方法与未优化的基准和混合整数规划模型进行了比较，展示了其在改善性能指标方面的有效性。", "conclusion": "根据员工规模，提出的解决方案可以提高约3%-10%的性能指标。模型在实际应用中达到了8.44%和使用混合整数规划模型的19.6%的改进效果，这表明了所提算法的有效性，特别是在人员配置合理的前提下。然而，MIP模型还能模拟当前服务规则中不允许的旅行选择决策。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07658", "html_url": "https://arxiv.org/abs/2511.07658", "title": "ZeroSim: 统一Transformer嵌入实现零样本模拟的模拟电路评估", "title_en": "ZeroSim: Zero-Shot Analog Circuit Evaluation with Unified Transformer Embeddings", "authors": "Xiaomeng Yang,Jian Gao,Yanzhi Wang,Xuan Zhang", "background": "尽管近期基于学习的模拟电路设计自动化取得了进展，涉及拓扑生成、器件尺寸确定和布局合成等任务，但性能评估依然存在效率瓶颈。传统SPICE模拟耗时，已有机器学习方法则需要特定位拓扑重新训练或手动子结构分割以适应细化，这限制了通用性和适应性。", "innovation": "本文提出了一种基于Transformer的性能建模框架——ZeroSim，旨在实现对训练拓扑结构在新参数配置下稳健的内分布泛化，以及对未见拓扑结构的零样本泛化，无需任何微调。其关键策略包括：1）包含超过60种放大器拓扑的360万实例多样训练集；2）全局感知标记和层次注意力的统一拓扑嵌入，以稳健地泛化到新型电路；3）拓扑条件参数映射方法，保持结构表示一致性，独立于参数变化。", "conclusion": "实验结果表明，ZeroSim在不同放大器拓扑上显著优于多层感知器、图神经网络和Transformer等基准模型，实现了精准的零样本预测。此外，当整合到强化学习参数优化流水线时，ZeroSim相比传统SPICE模拟加快了13倍，证明了其在模拟电路设计自动化任务中的实际价值。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07700", "html_url": "https://arxiv.org/abs/2511.07700", "title": "皮肤癌检测算法公平性基准中校准的作用", "title_en": "On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection", "authors": "Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy", "background": "人工智能（AI）模型在黑色素瘤检测方面已经达到了专家级的表现，但其临床应用受到不同性别、种族和年龄等亚群间性能差异的阻碍。尽管之前的努力主要集中在使用基于AUROC的分组公平性指标来评估模型性能，这些指标并未提供模型提供准确估计能力的洞察。为了与临床评估保持一致，本文通过引入校准作为违反AUROC公平性指标的补充基准衡量标准，来填补这一空白。校准评估预测概率与实际事件率之间的契合度，提供深入的亚群偏差洞察。本文在ISIC 2020挑战集和PROVE-AI数据集上评估了ISIC 2020挑战的顶级皮肤癌检测算法，并与第二、第三名的模型进行了比较，重点关注性别、肤色（Fitzpatrick皮肤类型）和年龄定义的亚群。研究发现，尽管现有的模型提高了判别准确性，但在应用于新的数据集时，它们往往会高估风险并表现出校准问题。这项研究强调了全面的模型审计策略和广泛元数据收集的必要性，以实现公平的人工智能驱动的医疗保健解决方案。所有代码均可在如下网址获取：this https URL", "innovation": "引入校准作为评估皮肤癌检测算法公平性的补充基准指标，填补了仅依赖基于AUROC的公平性指标的空白。校准评估了预测概率与实际事件率之间的匹配度，提供了关于亚群偏差的深入了解。", "conclusion": "尽管现有模型提高了判别准确性，但它们在应用于新数据集时往往高估风险并表现出校准问题。这项研究强调了全面的模型审计策略和广泛元数据收集的重要性，以实现公平的人工智能驱动的医疗保健解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07657", "html_url": "https://arxiv.org/abs/2511.07657", "title": "CAE: 基于字符级自动编码器的非语义关系数据分组", "title_en": "CAE: Character-Level Autoencoder for Non-Semantic Relational Data Grouping", "authors": "Veera V S Bhargav Nunna,Shinae Kang,Zheyuan Zhou,Virginia Wang,Sucharitha Boinapally,Michael Foley", "background": "企业关系数据库中越来越多地包含大量无意义的数据，如IP地址、产品标识符、编码键和时间戳，这些数据挑战了传统的语义分析。传统的自然语言处理模型由于语义解释能力和词汇表外标记的限制，在处理这些数据时遇到困难。本文提出了一种新的基于字符级自动编码器（CAE）的方法，该方法通过检测数据模式和结构相似性自动识别并分组无意义关系数据集中的语义相同列。该方法在字符级别操作，具有固定的字典约束，能够高效处理大规模的数据湖和数据仓库。与传统的自然语言处理模型相比，这种方法在内存需求和训练时间上都有显著减少，适用于大规模工业数据环境的数据分组任务。实验结果表明，基于字符级自动编码器的方法在顶级列匹配任务中的准确率达到了80.95%，远超传统的自然语言处理方法（如Bag of Words的47.62%），验证了其在识别和分组关系数据集中语义相同列的有效性。", "innovation": "提出了一种基于字符级自动编码器（CAE）的新方法，用于识别和分组无语义关系数据集中的语义相同列。该方法通过数据模式和结构相似性进行列相似性检测，以固定大小的字典约束在字符级别操作，从而实现大规模数据湖和数据仓库的高效处理。相比传统自然语言处理模型，该方法在内存需求和训练时间上都有显著减少，更适用于大规模工业数据环境中的数据分组任务。实验结果表明，该方法在传统自然语言处理方法中取得了显著的性能提升。这为大规模的非语义工业数据集的模式理解和数据分组提供了一种自动化的解决方案，将理论上的字符级神经架构的进展与企业数据管理的实际挑战相结合。", "conclusion": "该研究成功地将理论上的字符级神经架构的进展应用于解决大规模非语义工业数据集的实际企业数据管理挑战，提出了基于字符级自动编码器的方法，并通过实验验证了其有效性和高效性。这种方法克服了传统自然语言处理模型的局限性，能够更好地处理大规模无语义关系数据集，并对企业的数据理解和分组具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07892", "html_url": "https://arxiv.org/abs/2511.07892", "title": "一个通用的谱框架来解释神经网络的放大和压缩动力学", "title_en": "A Generalized Spectral Framework to Expain Neural Scaling and Compression Dynamics", "authors": "Yizhou Zhang", "background": "该研究背景涉及通过实验规模律来描述测试损失和其他性能指标如何依赖于模型大小、数据集大小和计算资源。虽然在特定范围内这种规律是一致的，但在某些相关设置如模型压缩中观察到的缩放行为却显得不同。", "innovation": "本文开发了一个通用的谱框架，将学习动力学和压缩现象统一在一个通用函数假设之下。该框架将谱演化函数从线性核形式推广到渐近多项式形式g(λ,t;β)，并具有有效的谱-时间弹性ρ(β)来表征。这个框架恢复了现有的懒学习和特征学习理论，同时也揭示了学习和压缩之间的不变关系。", "conclusion": "该框架追溯到现有的一些理论并提供了学习与压缩之间的不变关系，这为理解神经网络的放大和压缩动力学提供了一个新的视角。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07884", "html_url": "https://arxiv.org/abs/2511.07884", "title": "元认知的多尺度层次推理在运动想象解码中的应用", "title_en": "Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding", "authors": "Si-Hyun Kim,Heon-Gyu Kwak,Byoung-Hee Kwon,Seong-Whan Lee", "background": "脑-计算机接口（BCI）旨在通过解码非侵入性神经信号来控制外部设备，但其在实际应用中的部署受到运动想象（MI）-基于脑电图（EEG）信号的噪声和变异性的限制。本研究探讨了一种四级及元认知解码框架，以提高四类MI分类的准确性。", "innovation": "本文提出了一种多尺度层次信号处理模块，将主干特征重新组织为时间上的多尺度表示，并引入了一种反省不确定性估计模块，能够为每个周期分配可靠性得分并引导迭代细化。通过三种标准EEG主干（EEGNet、ShallowConvNet和DeepConvNet）实例化该框架，在无个人信息独立设置下对四类MI解码进行评估。", "conclusion": "无论是在哪一种EEG主干中，提出的组件在平均分类准确性和减少被试间差异方面都优于基准方法，表明该方法增强了BCI系统对个体差异和噪声试次的鲁棒性。这表明，将多尺度层次处理与反省信心估计相结合可以提高基于MI的BCI系统的可靠性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07904", "html_url": "https://arxiv.org/abs/2511.07904", "title": "测试驱动的强化学习", "title_en": "Test-driven Reinforcement Learning", "authors": "Zhao Yu,Xiuping Wu,Liangjun Ke", "background": "强化学习（RL）已被确认为一种强大的机器人控制任务工具。通常，RL采用奖励函数来定义任务目标并指导代理学习。然而，奖励函数肩负着定义最优目标和引导学习的双重任务，这使得手动设计奖励函数变得困难，往往导致对任务的次优表示。", "innovation": "本文提出了一种基于测试驱动的强化学习（TdRL）框架，其中使用多个测试函数来表示任务目标，而不是单一的奖励函数。提出了证明，当轨迹返回函数赋予更接近最优轨迹集的轨迹更高的回报时，基于这种回报函数的最大熵策略优化将生成一个更靠近最优策略集的政策。引入了一个词序启发式方法来比较轨迹与最优轨迹集之间的相对距离关系，从而学习轨迹返回函数。进一步发展了TdRL算法。", "conclusion": "实验结果表明，TdRL在策略训练方面与手工设计的奖励方法具有可比性和优越性，具有更高的设计简洁性和内置多目标优化支持。我们认为，TdRL为表示任务目标提供了一个新颖的视角，有助于解决强化学习应用中的奖励设计挑战。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07878", "html_url": "https://arxiv.org/abs/2511.07878", "title": "在策略梯度控制中的算法相关轨迹估值", "title_en": "Algorithm-Relative Trajectory Valuation in Policy Gradient Control", "authors": "Shihao Li,Jiachen Li,Jiamin Xu,Christopher Martin,Wei Li,Dongmei Chen", "background": "本文研究了轨迹价值如何依赖于政策梯度控制中的学习算法。通过在不确定的线性二次调节器（LQR）中使用轨迹沙普利值（Trajectory Shapley），发现持久激发（PE）与vanilla REINFORCE的边际价值之间存在负相关（$r\thickapprox -0.38$）。", "innovation": "研究揭示了一个方差调节机制：（i）固定能量下，较高的PE导致梯度方差减小；（ii）在鞍点附近，较高的方差增加逃逸概率，从而提升边际贡献。通过状态去白化或Fisher预处理稳定后，这种方差通道被中和，信息含量成为主导，使相关性变为正（$r\thickapprox +0.29$）。因此，轨迹价值是算法相关的。实验验证了这一机制，并展示了决策对齐评分（Leave-One-Out）补充沙普利值进行剪枝的效果，而沙普利值能够识别有毒子集。", "conclusion": "本文证明了轨迹价值具有算法相对性，且这一点在通过实验被验证。此外，还提出了结合使用沙普利值和决策对齐评分的评分策略，增强了模型的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07919", "html_url": "https://arxiv.org/abs/2511.07919", "title": "反馈下降：通过成对比较进行无尽文本优化", "title_en": "Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison", "authors": "Yoonho Lee,Joseph Boen,Chelsea Finn", "background": "本文介绍了一种称为Feedback Descent的框架，用于通过结构化的文本反馈优化文本艺术作品，如提示、代码和分子，而不是仅仅依赖于标量奖励。前人的方法倾向于将批评压缩成二进制偏好，而Feedback Descent通过保留详细的批评意见，更大地放宽了偏好学习中的信息瓶颈，使得可以直接在文本空间进行优化，而不是在权重空间。此外，以前的方法将判断压缩到单个比特，而本文的客观评价则是将每个比较配对文本反馈，提供高带宽的监督信息。", "innovation": "在Feedback Descent中，通过成对比较将反馈应用于模型，不仅能提供方向性信息，还能直接在推理阶段执行迭代循环，而不修改任何模型权重，这样的方法是任务无关的。对比现有的基于图形的分子优化器、强化学习方法和最先进提示优化方法（GEPA），Feedback Descent在多种领域中都表现更优，特别是在DOCKSTRING分子发现基准测试中，能够更高效地发现新颖且药物样分子。", "conclusion": "本文展示了Feedback Descent在优化文本内容方面的有效性，尤其是在分子发现任务中。通过成对比较方法，使模型直接从详细反馈中学习，拓宽了优化过程的信息瓶颈，为无尽的文本优化提供了新的视角和方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07857", "html_url": "https://arxiv.org/abs/2511.07857", "title": "一般性验证网络通用逼近性质的方法", "title_en": "A General Method for Proving Networks Universal Approximation Property", "authors": "Wei Wang", "background": "现有研究通常依靠模型特定的证明来证实深度学习架构的普遍逼近性质。他们为每个特定架构（如全连接网络、CNN或Transformers）构建特定的数学表达式，并证明其普遍逼近性。然而，这种方法具有两个主要局限性：首先，每个新提出的架构通常需要从头开始进行全新的证明；其次，这些证明彼此孤立，缺乏共同的理论基础。这不仅增加了冗余，还阻碍了不同网络家族的统一理论理解。", "innovation": "本文提出了一种通用且模块化的框架，用于证明网络的普遍逼近性质。作者定义了一个基本构建块，称为通用逼近模块（UAM），该模块具有普遍逼近性质。在一个这样的模块下，证明任何由这些模块组成的有效网络均保留了普遍逼近性质。此外，整个逼近过程可以解释为跨模块的逐步细化过程。这种观点不仅统一了对各种架构的分析，还使我们能够逐步理解表达能力如何通过网络发展演变。", "conclusion": "本文提出了一种通用且模块化的框架，该框架能够证明网络的普遍逼近性质，并解释了通过模块的逼近过程。这种方法既统一了不同架构的分析，也有助于理解网络中表达能力的逐步变化。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07911", "html_url": "https://arxiv.org/abs/2511.07911", "title": "正则化噪声：一种使用正激励噪声的生成模型", "title_en": "Rectified Noise: A Generative Model Using Positive-incentive Noise", "authors": "Zhenyu Gu,Yanchen Xu,Sida Huang,Yubin Guo,Hongyuan Zhang", "background": "Rectified Flow (RF)作为一种有效的生成模型被广泛应用，尽管它主要基于概率流微分方程（ODE），但最近的研究表明，通过反向时间随机微分方程（SDE）注入噪声进行采样，可以实现更优的生成性能。", "innovation": "本文受正激励噪声（$\boldsymbol{\text{\textpi}}$-noise）启发，提出了一个创新的生成算法，即正则化噪声（$\boldsymbol{\text{\textDel}}$RN），通过将$\boldsymbol{\text{\textpi}}$-noise注入预训练RF模型的速度场来改进生成性能。研究发现使用正则化噪声的RF模型在ImageNet-1k数据集上的FID分数从10.16降至9.05，表现出显著的性能提升。同时，$\boldsymbol{\text{\textpi}}$-噪声生成器模型在仅增加0.39%的训练参数的情况下也取得了更好的性能。", "conclusion": "通过对各种模型架构在不同数据集上的广泛实验验证了正则化噪声的有效性，并表明将预训练的RF模型通过引入正则化噪声高效地转化为$\boldsymbol{\text{\textpi}}$-噪声生成器是可行的。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07899", "html_url": "https://arxiv.org/abs/2511.07899", "title": "使用安全过滤器和置信预测统计保证控制系统的安全性", "title_en": "Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction", "authors": "Ihab Tabbara,Yuxuan Yang,Hussein Sibai", "background": "部署学习驱动的自主系统时对安全性的保证是基本的要求。哈密尔顿-雅可比(HJ)可达性分析是验证安全性和生成安全控制器的基本方法。然而，计算能够表征用户定义的失败状态的后向可达集(BRS)的HJ值函数在高维系统中计算成本非常高昂，推动了使用强化学习方法来近似值函数的应用。但学习得到的值函数及其相应的安全策略并不保证是正确的。评估的态值函数可能不等于采用学习的安全策略时实现的实际安全回报。", "innovation": "引入了基于置信预测(CP)的框架来限定此类不确定性，从而在使用学习得到的HJ值函数和策略时提供概率安全保证，防止控制系统进入失败状态。使用CP校准不安全名义控制器和基于HJ的学习安全策略之间的切换，以在切变策略下推导出安全保证。此外，研究了使用独立训练的HJ值函数组合来进行安全过滤的方法，并将这种组合方法与仅使用个别值函数进行了比较。", "conclusion": "通过结合置信预测和安全过滤器，方法为使用学习到的HJ值函数构建控制系统的安全保证提供了新的途径，并通过实证研究证明了所提出方法的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07922", "html_url": "https://arxiv.org/abs/2511.07922", "title": "SERL: 开放领域自检验强化学习", "title_en": "SERL: Self-Examining Reinforcement Learning on Open-Domain", "authors": "Weixuan Ou,Yanzhao Zheng,Shuoshuo Sun,Wei Zhang,Baohua Dong,Hangcheng Zhu,Ruohui Huang,Gang Yu,Pengwei Yan,Yifan Qiao", "background": "研究表明，强化学习（RL）能够提升大语言模型（LLMs）的能力。然而，将其应用于开放领域任务时面临两个关键挑战：（1）这些任务的本体主观性使得验证奖励难以实现，这是需要可验证奖励的强化学习与可验证奖励（RLVR）所要求的；（2）来自人类反馈的强化学习（RLHF）依赖于外部奖励机制。为克服这些局限性，提出了自检验强化学习（SERL），这是一种新颖的自我改进框架，其中LLM作为双重角色扮演者和裁判员。SERL引入了两种协同奖励机制，无需任何外部信号。", "innovation": "SERL 提出了一种自我改进框架，其中LLM同时作为角色和裁判。它引入了两套协同奖励机制：（1）通过Copeland风格的两两比较判断多个生成响应获得奖励，以提高角色的能力；（2）提出了一种自我一致性奖励，鼓励连贯的判断，以提高裁判的可靠性。这个过程会提高裁判的能力，从而为角色提供更稳健的奖励。", "conclusion": "实验结果表明，SERL 方法在多个方面优于现有的自我改进训练方法，例如在 AlpacaEval 2 上 Qwen3-8B 的 LC 胜率从 52.37% 提高到 59.90%，在已知方法中达到最先进的性能，且性能与更大规模的模型（如 Qwen3-32B）相当，展示了在开放领域任务中的出色有效性和稳健性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07908", "html_url": "https://arxiv.org/abs/2511.07908", "title": "CellARC: 使用细胞自动机衡量智能", "title_en": "CellARC: Measuring Intelligence with Cellular Automata", "authors": "Miroslav Lžičař", "background": "本文介绍了一个名为CellARC的新合成基准，该基准来自多色一维细胞自动机（CA）。每个episode包含五个支持对和一个查询，序列化在256个令牌中，以快速迭代小型模型的同时，暴露了一个可控的任务空间。研究人员可以使用符号、递归、卷积、变压器、递归、和生成语言模型（LLM）基线进行评估，并探讨任务的泛化能力，无需依赖人类先验知识，且能够控制难度进行无限采样，支持具有严格预算条件下模型如何快速推断出新规则的研究。上千万参数的vanilla transformer是性能最强的模型之一，而大型封闭模型（GPT-5 High）在一小部分100个测试任务中表现出更好的准确性。来自Transformer和最佳符号基线的集成模型在某些任务上的表现更佳，突显了神经和符号模型的互补性", "innovation": "CellARC的设计开创了使用细胞自动机衡量智能的新基准，该基准能够控制任务空间中的多个参数，如字母表大小k、半径r、规则家族、Langton’s lambda、查询覆盖度和细胞熵。这种方法帮助研究者在无人类先验知识的情况下衡量模型的泛化能力，并控制任务难度，从而支持无限采样。同时，该基准还展示了Neuro-Symbolic模型的互补性，即神经网络和符号处理之间的结合在解决此类问题上具有显著优势", "conclusion": "本文提出的CellARC基准，通过对多色一维细胞自动机数据集的创新设计，能够有效评估不同类型的AI模型，特别是在无需依赖人类先验知识的情况下进行智能衡量。其不仅推动了基础研究的进步，还促进了模型在特定场景下的快速推断能力的研究，展现了神经和符号模型的互补性。该基准不仅具有广泛的适用性，还为研究者的后续工作提供了可重复研究的框架"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08120", "html_url": "https://arxiv.org/abs/2511.08120", "title": "一种用于机器学习模型长期可持续性评估的稳健方法", "title_en": "A robust methodology for long-term sustainability evaluation of Machine Learning models", "authors": "Jorge Paz-Ruza,João Gama,Amparo Alonso-Betanzos,Bertha Guijarro-Berdiñas", "background": "随着人工智能系统的开发和部署愈发强调可持续性和效率，现有监管和报告实践在评价这些指标时缺乏标准化和模型中立的评估标准。现有的评估方法通常只关注短期实验资源使用情况，并且过度强调批量学习设置，未能反映真实世界中长期的AI生命周期变化。因此，本文提出了一个适用于批量和流式学习场景的综合评估方法，以全面评估ML模型的长期可持续性。", "innovation": "本文提出了一种新的评估方法，用于全面评估机器学习模型的长期可持续性，这一方法适用于不同类型的模型和场景。研究发现传统的静态训练-测试评估方法在进化数据和重复模型更新情况下无法可靠地捕捉可持续性。结果表明，不同模型的长期可持续性差异显著，且在很多情况下，更高的环境成本并不会带来显著的性能提升。", "conclusion": "本文通过利用各种分类任务和不同类型模型进行了实验，证实了传统的方式无法捕捉到模型在长期变化数据下的可持续性。研究结果表明，评估机器学习模型的长期可持续性至关重要，在不同场景下需使用新方法来衡量。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08174", "html_url": "https://arxiv.org/abs/2511.08174", "title": "深度（预测性）折扣事实后悔最小化", "title_en": "Deep (Predictive) Discounted Counterfactual Regret Minimization", "authors": "Hang Xu,Kai Li,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng", "background": "传统的事后后悔最小化(CFR)算法及其变体在解决不完美信息博弈时表现良好，但其应用受到限制，尤其是在大规模博弈中。为了克服这一限制，研究者们尝试使用神经网络来近似CFR及其变体的行为，但现有的方法主要基于传统的CFR，难以有效整合更高级的CFR变体。\n", "innovation": "本文提出了一种高效的无模型神经CFR算法，克服了现有方法在近似高级CFR变体时的局限性。该算法在每次迭代中基于价值网络收集减少方差的样本优势，通过自助方式拟合累计优势，并应用折扣和裁剪操作以模拟高级CFR变体的更新机制。实验结果表明，相比于无模型的神经算法，该算法在典型不完美信息游戏中收敛更快，并在大型德州扑克比赛中表现出更强的对抗能力。\n", "conclusion": "该工作提出的新算法有效解决了现有方法的不足，不仅在典型不完美信息游戏中具有更快的收敛速度，还提高了在大型扑克游戏中与对手进行对抗的能力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08080", "html_url": "https://arxiv.org/abs/2511.08080", "title": "Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing", "title_en": "Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing", "authors": "Ziyu Fan,Zhijian Huang,Yahan Li,Xiaowen Hu,Siyuan Shen,Yunliang Wang,Zeyu Zhong,Shuhong Liu,Shuning Yang,Shangqian Wu,Min Wu,Lei Deng", "background": "在AI驱动的药物发现中，分子生成和编辑的能力受限于两个因素：（i）捕捉分子结构和多种性质之间的复杂关系具有挑战性；（ii）分子性质的狭窄覆盖范围和不完整的注释削弱了基于性质的模型的效果。", "innovation": "本文提出了HSPAG，一个高效的数据驱动框架，采用层次结构-性质对齐的方法。通过将SMILES和分子性质视为互补的模态，模型在原子、亚结构和整个分子层面上学习它们之间的关系。此外，通过筛选代表性样本和选择困难样本，显著减少预训练所需的数据量，并引入了一种基于性质相关性感知的掩码机制以及多样化扰动策略，以在稀疏注释下提高生成质量。实验表明，HSPAG能够捕捉细粒度的结构-性质关系，支持多种性质约束下的可控生成。", "conclusion": "HSPAG在多个真实案例研究中证明了其编辑能力，能够捕捉细粒度的结构-性质关系，并支持在多种性质约束下的可控生成。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08185", "html_url": "https://arxiv.org/abs/2511.08185", "title": "通过哈密尔顿动力学提升图神经模拟器中长程交互", "title_en": "Improving Long-Range Interactions in Graph Neural Simulators via Hamiltonian Dynamics", "authors": "Tai Hoang,Alessandro Trenta,Alessio Gravina,Niklas Freymuth,Philipp Becker,Davide Bacciu,Gerhard Neumann", "background": "传统数值求解器在提供高保真度解决方案时常常面临巨大的计算成本。近期，图神经模拟器（GNS）通过学习图形结构数据上的动力学加速了模拟过程，但多长距交互捕捉能力有限，并且在自回归滚动预测中容易积累误差。这一研究旨在解决这些问题，以改进模拟精度和稳定性，特别是在复杂的动力学系统中。", "innovation": "作者提出了一种基于哈密尔顿动力学原则的图神经模拟器，名为信息保存图神经模拟器（IGNS）。IGNS通过确保信息在网络中的保存、扩展到端口哈密尔顿系统来捕捉更广泛的动力学，包括非保守效应。此外，IGNS引入了一个预热阶段来初始化全局上下文，使用几何编码来处理不规则网格，并采用多步训练目标来减少滚动误差。", "conclusion": "通过制定新的基准测试以系统地评估这些特性，IGNS在所有任务中都表现出色，无论是在长距离依赖还是在具有挑战性的外部强迫情况下，IGNS都比最先进的GNSs具有更高的准确性和稳定性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08136", "html_url": "https://arxiv.org/abs/2511.08136", "title": "SafeMIL：从非优选轨迹学习离线安全模仿策略", "title_en": "SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories", "authors": "Returaj Burnwal,Nirav Pravinbhai Bhatt,Balaraman Ravindran", "background": "在许多现实场景中，线上交互可能具有风险性，并且在每个时间步骤精确描述奖励和安全成本信息具有困难。然而，收集反映不良行为或高风险行为的轨迹是可行的，隐含地传达了代理应避免的行为。这些轨迹被称为非优选轨迹。与标准的模仿学习不同，代理不仅要模仿演示，还需要学会通过非优选轨迹规避风险行为。", "innovation": "提出了一种名为SafeMIL的新型方法，用于学习一个参数化成本，该成本能通过多实例学习预测状态-动作对是否具有风险，并使用学习到的成本来避免非优选行为，从而产生优先考虑安全性的策略。实验结果表明，该方法可以学习一个安全性更好的策略，同时不损害奖励性能，从而优于多个基线模型。", "conclusion": "该方法能够在遵守成本约束的同时学习到更为安全的策略，且不会降低奖励性能，从而证明了该方法的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08086", "html_url": "https://arxiv.org/abs/2511.08086", "title": "动态稀疏性：机器人强化学习基准中学习世界模型的常见稀疏性假设挑战", "title_en": "Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks", "authors": "Muthukumar Pandaram,Jakob Hollenstein,David Drexel,Samuele Tosatto,Antonio Rodríguez-Sánchez,Justus Piater", "background": "研究显示，通过学习动力学模型（世界模型）可以提高强化学习的样本效率。这些动力学模型的因果图通常是稀疏连接的，意味着每个未来状态变量仅依赖于当前状态中的一个小子集，因此学习可能受益于稀疏先验。此外，时域稀疏也被提出，作为有助于学习的动力学模型中局部动力学稀疏且急剧变化的假设。但这些假设是否适用于典型的强化学习任务尚未得到验证。", "innovation": "本文通过在MuJoCo Playground基准套件的机器人强化学习环境中分析真实动力学，质疑了上述关于动力学稀疏性的常见假设。研究发现，虽然全局稀疏性罕见，但在特定任务中的动力学表现出局部且依赖于状态的稀疏性，并且这种稀疏性在时间上是局部化的，影响特定状态维度的子集。", "conclusion": "研究结果强调，需要考虑真实的动力学中的状态依赖稀疏性结构，从而调整动力学学习中的归纳偏置，以更好地适应实际任务。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08142", "html_url": "https://arxiv.org/abs/2511.08142", "title": "BIPPO: 节能型独立PPO预算感知的联邦学习服务", "title_en": "BIPPO: Budget-Aware Independent PPO for Energy-Efficient Federated Learning Services", "authors": "Anna Lackinger,Andrea Morichetta,Pantelis A. Frangoudis,Schahram Dustdar", "background": "联邦学习（FL）在大规模物联网系统中是一个有前景的机器学习解决方案，能够保证负载均衡和隐私保护。然而，FL 本身并未充分考虑基础设施效率问题，在资源受限的环境中至关重要。尽管有一些基于强化学习（RL）的方法可以优化客户端的选择，但是这些方法通常没有考虑基础设施挑战，例如资源限制和设备更换。此外，这些RL方法的训练过程往往不适合实际应用，因为它们忽略了解决方案的一般化和能源效率。", "innovation": "为解决上述问题，本文提出了BIPPO（Budget-aware Independent Proximal Policy Optimization），这是一种预算感知的多代理RL解决方案，旨在提高性能。BIPPO在高度预算受限的环境中进行评估，特别是在FL客户端对非IIF数据进行训练的情况下，这对于传统的FL来说是一个具有挑战性的领域。BIPPO的改进采样器能够增加平均精度，与非RL机制、传统PPO和IPPO相比，它消耗的预算可以忽略不计，并且保持一致，即使客户端数量增加也是如此。总体而言，BIPPO提供了一种高效、稳定、可扩展和可持续的联邦学习客户端选择解决方案。", "conclusion": "BIPPO作为一种预算感知的独立PPO多代理RL方法，致力于提高联邦学习中的能源效率与性能。通过改进的采样器，BIPPO在预算受限的环境中表现出色，保证了准确性和资源的有效利用，增强了联邦学习服务于物联网环境下的实用性和可持续性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08083", "html_url": "https://arxiv.org/abs/2511.08083", "title": "HipKittens：快速而强劲的AMD内核", "title_en": "HipKittens: Fast and Furious AMD Kernels", "authors": "William Hu,Drew Wadsworth,Sean Siddens,Stanley Winata,Daniel Y. Fu,Ryann Swann,Muhammad Osama,Christopher Ré,Simran Arora", "background": "AMD GPU 提供了业界领先的计算和内存带宽，但其高性能内核通常用原始汇编语言编写。为了解决将AI算法映射到硬件的困难，近期工作的重点是使用C++嵌入式和PyTorch启发的领域特定语言（如ThunderKittens）来简化在NVIDIA硬件上的高性能AI内核开发。本文探讨了这些针对显式基于小块编程、优化的内存访问和细粒度异步执行的操作原语，其是否特定于NVIDIA硬件或具有通用性。", "innovation": "本文提供了第一个关于高性能AMD AI内核编程原语的详细研究，并将这些见解封装在HipKittens编程框架中。研究发现，即便在之前的DSLs中广泛使用的基于小块的抽象可以适应AMD GPU，但在这些抽象算法的具体实现方面却有必要重新考虑。在CDNA3和CDNA4 AMD平台上的评估表明，HipKittens内核能够与AMD的手动优化汇编内核在GEMMs和注意力方面进行竞争，并且在大多数情况下超过编译器基准内核。此外，由于汇编语言难以扩展应用到所有的AI负载，对于某些应用场景，HipKittens相比所有现有基准内核实现了1.2到2.4倍的性能提升。这些结果可以帮助建立一个适用于各种GPU厂商的单一、基于小块的高性能AI内核软件层。", "conclusion": "HipKittens提供了高性能AMD AI内核编程框架，并在多种AMD平台上进行了性能验证。尽管基于小块的抽象在AMD GPU上通用性较好，但在具体算法实现上需要针对性优化。重要的是，HipKittens内核在某些计算任务中能显著超越现有性能基准，为跨GPU供应商的高性能AI计算提供了新的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08077", "html_url": "https://arxiv.org/abs/2511.08077", "title": "一种结合梯度增强和模糊规则基础模型的集成融合框架", "title_en": "An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models", "authors": "Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding", "background": "机器学习研究中长期关注不同学习范式的整合，以克服单一方法的固有局限性。模糊规则基础模型因其可解释性而在多个领域得到广泛应用，但也面临复杂设计规范和大数据集下的可扩展性问题。将不同技术与策略，特别是梯度提升，与模糊规则基础模型结合，为解决这些挑战提供了稳健的解决方案。本研究旨在通过整合两种范式的优点，增强模型性能和可解释性。", "innovation": "提出了一种集成融合框架，通过在一个动态因子的控制下，在每次迭代中构建模糊规则基础模型，并优化其对整体集成的贡献，以防止模型主导、鼓励多样性，并作为正则化参数。此外，该框架还包含基于验证集反馈的样本纠正机制，实现了基于性能的动态调整。实验结果表明，该框架在防止过拟合和简化模型维护与更新方面具有有效性，特别是在处理大量规则时的复杂性方面性能提升显著。", "conclusion": "通过利用动态因子优化每个模型的贡献，该框架不仅提高了性能，还保持了可解释性，并简化了模型的维护和更新过程。这种框架的有效性通过实验结果得到了验证。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08226", "html_url": "https://arxiv.org/abs/2511.08226", "title": "在线碎片冗余消除器（OPRE）：一种基于数据集压缩的新型在线无偏连续学习方法", "title_en": "The Online Patch Redundancy Eliminator (OPRE): A novel approach to online agnostic continual learning using dataset compression", "authors": "Raphaël Bayle,Martial Mermillod,Robert M. French", "background": "为了实现连续学习(CL)，克服神经网络自诞生以来就存在的灾难性遗忘问题至关重要。评估连续学习方法一般需将已知同质数据集分割并依次学习相关任务。文章指出，大多数连续学习方法在学习新任务时会引入对未来数据的先验信息，但是不能被认为是无偏的。以此为基础，文章通过分析依赖预训练特征提取器的方法来说明这一观点，并强调了这些方法对模型可学习数据的通用性构成的限制。此外，还探讨了其他连续学习方法中引入的其他先验信息。", "innovation": "介绍了在线碎片冗余消除器（OPRE），这是一种在线数据集压缩算法。它在测试时训练分类器，且其表现优于多种当前最佳的在线连续学习方法，在CIFAR-10和CIFAR-100数据集上表现出更优异的性能。此方法对将来数据只作最小可解释的假设。", "conclusion": "文章提出在线数据集压缩可能对于实现完全无偏的连续学习是必要的，表明基于数据集压缩的方法可以是一个有潜力的方向。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08287", "html_url": "https://arxiv.org/abs/2511.08287", "title": "Dual-Kernel Graph Community Contrastive Learning", "title_en": "Dual-Kernel Graph Community Contrastive Learning", "authors": "Xiang Chen,Kun Yue,Wenjie Liu,Zhenyu Zhang,Liang Duan", "background": "图对比学习（GCL）作为一种在没有特定任务标签的情况下训练图神经网络（GNN）的强大范式，已经引起了广泛关注。然而，GCL在大规模图上的扩展性受到GNN密集的消息传递机制和对比损失的计算复杂性的影响。", "innovation": "本文提出了一种高效的GCL框架，通过将输入图转换为一组互联节点集的紧凑网络，同时保留跨社区的结构信息。引入了具有线性复杂度的核化图社区对比损失，使节点集之间能够有效传递信息，捕获图形的层次结构信息。同时，结合了解耦GNN架构的知识蒸馏技术，加速推理过程，同时保持良好的泛化性能。", "conclusion": "在十六个不同规模的真实世界数据集上进行的广泛实验表明，该方法在有效性和可扩展性方面优于最新的GCL基线。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08094", "html_url": "https://arxiv.org/abs/2511.08094", "title": "Stuart-Landau振荡图神经网络", "title_en": "Stuart-Landau Oscillatory Graph Neural Network", "authors": "Kaicheng Zhang,David N. Reynolds,Piero Deidda,Francesco Tudisco", "background": "振荡图神经网络（OGNNs）是一种基于物理原理设计的新颖架构，旨在缓解深度图神经网络中的过度平滑和梯度消失问题。通常的图神经网络由于过度平滑问题导致特征差异减小，而振荡图神经网络通过引入振荡动力学模型，如斯特鲁特-兰道振荡模型，能够更好地处理邻域信息，保持节点特性间的差异，进而解决这些问题。斯特鲁特-兰道振荡者是极限环行为（Hopf分岔附近）的经典模型，在同步理论中至关重要，特别是在神经科学领域用于中间尺度脑模型的构建。这一新型框架提供了对节点特性和网络结构之间相互作用的更深层次的理解和控制。", "innovation": "本文提出了基于斯特鲁特-兰道振荡器动力学的复杂值斯特鲁特-兰道图神经网络（SLGNN）。SLGNN通过引入节点特征幅值的动态演变，保留了幅度和相位的双重动态，增加了振幅调节和多重稳定同步等丰富现象。此外，通过引入可调超参数（如Hopf参数和耦合强度），SLGNN能够更加灵活地调整特征幅值和网络结构之间的关系。相对与传统的谐振子和相位仅有的库拉莫托模型，SLGNN提供了更多的灵活性和控制能力。通过在节点分类、图分类和图回归任务中的广泛实验，证明了SLGNN在性能上优于现有的OGNNs，并为图上深度振荡架构提供了新的、表达性更强且理论基础扎实的框架。", "conclusion": "SLGNN提供了更丰富的物理机制和更高的表现力，在多种图下游任务上提供了优越的性能。通过深入探索和充分实验验证，SLGNN构建了一个新型的图神经网络框架，这对于理解和研究复杂动态网络具有重要意义，同时也展示了未来图神经网络发展的潜在方向。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08243", "html_url": "https://arxiv.org/abs/2511.08243", "title": "变压器的统一几何场理论框架：从流形嵌入到核调制", "title_en": "A Unified Geometric Field Theory Framework for Transformers: From Manifold Embeddings to Kernel Modulation", "authors": "Xianshuai Shi,Jianfeng Zhu,Leibo Liu", "background": "自注意力机制是变压器架构的核心，已经在自然语言处理、计算机视觉和科学计算等多个领域取得了巨大成功。然而，其关键组件——位置编码和注意力机制缺乏统一的物理或数学解释。本文提供了一种综合的结构理论框架，将位置编码、核积分算子和注意力机制结合在一起，为进一步的理论研究提供深度剖析。通过将离散位置（如文本标记索引和图像像素坐标）映射到连续流形上的空间函数，本文赋予了变压器层字段理论的解释，即作为改进过的核调制操作在嵌入流形上作用。", "innovation": "本文提出了一种结合位置编码、核积分算子和注意力机制的结构理论框架，从而赋予了变压器层统一的几何场理论解释。这种理论框架有助于进一步深入理解变压器的工作原理。", "conclusion": "本文通过引入核调制操作的框架，将变压器层表示为在嵌入流形上进行的改进操作，实现了对变压器架构的多层次理论解释，为未来的工作提供了新的视角和方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08229", "html_url": "https://arxiv.org/abs/2511.08229", "title": "基于时域稳定化与频域差分的非平稳时间序列预测", "title_en": "Towards Non-Stationary Time Series Forecasting with Temporal Stabilization and Frequency Differencing", "authors": "Junkai Lu,Peng Chen,Chenjuan Guo,Yang Shu,Meng Wang,Bin Yang", "background": "时间序列预测在能源、金融、交通和云计算等领域至关重要。然而，实际时间序列常常表现出非平稳特性，如时序分布偏移和频率变化，这对长期时间序列预测提出了巨大挑战。", "innovation": "提出了一种双支结构框架DTAF，以同时应对时域和频域的非平稳性。在时域中，使用非平稳混合专家（MOE）滤波器的时域稳定融合（TFS）模块解耦并抑制时序非平稳模式，保留长期依赖性；在频域中，应用频域差分的频率波建模（FWM）模块动态凸显具有显著谱移变分量。通过融合TFS和FWM的互补输出，DTAF生成能够适应时域和频域非平稳性的稳健预测。", "conclusion": "通过在实际基准上的广泛实验表明，DTAF在非平稳条件下比最先进的基线方法显著提高了预测精度。所有代码可在此处获取：[此链接](this https URL)。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08241", "html_url": "https://arxiv.org/abs/2511.08241", "title": "PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore", "title_en": "PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore", "authors": "Zhihao Lin,Lin Wu,Zhen Tian,Jianglin Lan", "background": "尽管强化学习中的探索仍然是一个关键挑战，简单地通过最大化熵常常会导致策略更新具有高方差和低效问题。现有方法往往无法高效地平衡探索与利用。", "innovation": "本文提出了一种名为PrefPoE的创新框架，该框架通过首次将产品-专家融合应用于单任务的探索与利用平衡中，实现了智能、优势导向的探索。通过训练偏好网络聚焦于高优势动作，并通过产品-专家融合与主要策略相结合，PrefPoE创建了一个软信任区域，确保策略更新的稳定性和高效的探索。", "conclusion": "PrefPoE在多种控制任务（包括连续动作空间和离散动作空间）中展示了持续的性能改进，例如HalfCheetah-v4提升了321%，Ant-v4提升了69%，LunarLander-v2提升了276%。与标准PPO相比，PrefPoE能够持续进行适应性探索，防止过早收敛，并实现更好的性能。我们的研究结果表明，通过优势导向的偏好来学习 “探索哪里” 与学习如何行动同样重要，为增强策略梯度方法提供了一个通用框架，适用于整个强化学习领域。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08260", "html_url": "https://arxiv.org/abs/2511.08260", "title": "基于数据的临床时间序列特征组发现", "title_en": "Data-Driven Discovery of Feature Groups in Clinical Time Series", "authors": "Fedor Sergeev,Manuel Burger,Polina Leshetkina,Vincent Fortuin,Gunnar Rätsch,Rita Kuznetsova", "background": "临床时间序列数据对于患者监测和预测建模至关重要。这些时间序列通常是多变量的，包含来自不同数据源的数百个异构特征。根据相似性和与预测任务的相关性对特征进行分组已被证明可以增强深度学习架构的性能。然而，仅依靠语义知识用先验定义这些组是非常具有挑战性的，即使是领域专家也不例外。本文探讨了一种新方法，通过聚类特征级别嵌入层的权重来学习特征组，这种方法可以无缝地集成到标准监督训练中，并能够发现直接提高下游临床相关任务性能的组。这种方法已在合成数据和真实医疗数据上进行了验证，取得了优于静态聚类方法的结果，并且在临床方面具有可解释性，有助于数据驱动的任务相关关系发现。", "innovation": "本文提出了一种新方法，通过聚类特征级别嵌入层的权重来自动学习特征组。这种方法直接整合到标准监督训练中，并能够发现直接改善下游临床相关任务的特征组。研究表明，该方法在合成数据上优于静态聚类方法，并且在真实世界医疗数据上的表现接近由专家定义的特征组。此外，学习到的特征组具有临床可解释性，有助于数据驱动地发现任务相关的关系。", "conclusion": "本文提出的方法在合成数据和真实世界医疗数据上的实验结果表明，它能够自动发现特征组，这些组可以直接提升下游临床相关任务的表现，并且学习到的特征组具有临床可解释性，提高了方法的实际应用价值。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08513", "html_url": "https://arxiv.org/abs/2511.08513", "title": "多发射器在分子通信中的聚类指导残差神经网络定位", "title_en": "Clustering Guided Residual Neural Networks for Multi-Tx Localization in Molecular Communications", "authors": "Ali Sonmez,Erencem Ozbey,Efe Feyzi Mantaroglu,H. Birkan Yilmaz", "background": "分子通信中的发射器定位是一个重要的研究主题，具有多种应用场景。然而，准确的位置多个发射器是一个挑战性的问题，因为扩散的随机性质和接收表面分子分布的重叠导致了较高的定位误差。", "innovation": "该研究引入了基于聚类的质心修正方法，以增强对密度变化和异常值的鲁棒性。此外，提出了两种基于聚类指导的残差神经网络方法，分别为AngleNN（用于方向细化）和SizeNN（用于聚类大小估计），以提高多发射器定位的准确性。", "conclusion": "实验结果显示，与K-means相比，这两个方法均显著改进了定位误差，对于2个发射器（Tx）的改进率为69%，对于4个发射器（Tx）的改进率为43%。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08552", "html_url": "https://arxiv.org/abs/2511.08552", "title": "FMMI：流动匹配互信息估计", "title_en": "FMMI: Flow Matching Mutual Information Estimation", "authors": "Ivan Butakov,Alexander Semenenko,Alexey Frolov,Ivan Oseledets", "background": "传统的互信息（MI）估计方法通常依赖于分类器来区分联合分布和边缘分布的角色。这种方法在计算效率和高维度数据上的应用存在局限性。", "innovation": "本文提出了一种新的互信息估计器，即Flow Matching Mutual Information（FMMI）。FMMI方法采用变换方法，通过学习一个流动网络，将一个分布转换为另一个，避免了传统的分类器驱动方法。这种方法能够提供计算效率高且精度高的互信息估计，并且对高维度数据和广泛的真实互信息值都有很好的适应性。", "conclusion": "FMMI方法通过流动网络直接在分布间进行匹配，提供了一种更为高效和准确的互信息估计方法，适用于各种高维度数据和场景。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08470", "html_url": "https://arxiv.org/abs/2511.08470", "title": "在CART算法中使用Mean Absolute Error准则进行二元分裂的分类特征", "title_en": "Binary Split Categorical feature with Mean Absolute Error Criteria in CART", "authors": "Peng Yu,Yike Chen,Chao Xu,Albert Bifet,Jesse Read", "background": "在分类和回归树（CART）算法中，使用标准评估标准如GINI指数和熵来进行分类特征的有效分裂已经很成熟。然而，传统的做法是采用各种数值编码方法来使用均绝对误差（MAE）准则对分类特征进行分裂。不幸的是，现有研究显示，无监督的数值编码方法并不适用于MAE准则。因此，亟需提出一种新的有效算法来解决在CART算法中处理分类特征时的MAE准则应用难题。", "innovation": "本文提出了一个新型且高效的分裂算法，旨在解决CART算法处理分类特征时使用MAE准则遇到的挑战。这个创新点在于，它克服了当前使用MAE准则处理分类特征需要依赖各类数值编码方法的问题，提供了一种新的方法来改进CART算法对分类数据的处理能力。", "conclusion": "本文的研究突显了现有方法的局限性，并提出了一种有价值的解决方案，从而提升了在CART算法中处理分类数据的能力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08544", "html_url": "https://arxiv.org/abs/2511.08544", "title": "LeJEPA：无需启发式方法的可证明且可扩展的自监督学习", "title_en": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics", "authors": "Randall Balestriero,Yann LeCun", "background": "学习可操控的世界及其动态表示是人工智能的核心。尽管引入了Joint-Embedding Predictive Architectures (JEPAs)，但缺乏实际指导和理论依据导致了无章可循的研发过程。", "innovation": "本文提出了一种全面的JEPAs理论，并在此基础上实现了一个名为LeJEPA的训练目标。LeJEPA通过引入菱形各向同性正态分布的约束目标来确保嵌入符合理想分布，从而实现了单个可调超参数、线性时间和内存复杂度、参数分布稳定、不同架构和领域具有鲁棒性、无需启发式方法和易于分布式训练等众多优点。", "conclusion": "我们的实验证明，在多种数据集和架构上，LeJEPA均表现出色。例如，通过使用imagenet-1k作为预训练并冻结主干进行线性评估，LeJEPA的ViT-H/14模型达到了79%的准确率。我们期望LeJEPA的简洁性和易于理解的理论生态系统能够重新确立自监督预训练在人工智能研究中的核心地位。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08440", "html_url": "https://arxiv.org/abs/2511.08440", "title": "证明性的自改善机制", "title_en": "Coherence Mechanisms for Provable Self-Improvement", "authors": "Mehryar Mohri,Jon Schneider,Yifan Wu", "background": "大型语言模型和其他智能系统需要自我改进的能力，以在没有外部监督的情况下自我调整行为和内部一致性。尽管这一点非常重要，但之前的许多方法大多依赖于经验性的直观判断，缺乏形式保证。", "innovation": "作者提出了一个基于一致性的原理框架来进行自我改进，通过投影机制更新基础模型以保持一致性和尽可能接近原始行为。提供的严格理论保证表明这些机制能实现单调改进，通过减少预期Bregman偏差来衡量。分析涵盖了直接和两步投影方法，并扩展了这些保证到不可实现设置、经验性分布以及宽松的一致性约束。此外，建立了通用刻画定理，指出任何具有类似可证明改进保证的机制都必须遵循基于一致性的结构，从而在形式上确立了这一原理作为证明性自我改进的必要原则，并提出约束下的刚性结果，确立了积的一致性作为证明性自改善的基本和必要原则。", "conclusion": "研究结果表明，基于一致性的机制能够实现证明性的自我改进，并通过高度严格的数学证明确保了模型的改进。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08570", "html_url": "https://arxiv.org/abs/2511.08570", "title": "使用层直方图方法的Kolmogorov-Arnold网络自动网格更新", "title_en": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms", "authors": "Jamison Moody,James Usevitch", "background": "Kolmogorov-Arnold网络（KANs）是一类神经网络，近年来在文献中受到了越来越多的关注。与多层感知机（MLPs）不同，KANs利用参数化且可训练的激活函数，并提供包括增强可解释性和在学习符号方程中更高的准确性等优势。然而，原始KAN架构需要在训练过程中对网络的域细分（称为“域网格”）进行调整，这为用户带来了额外的训练负担。典型的KAN层并没有设计为能够自主地以之前层输出范围变化的数据驱动方式更新其域。", "innovation": "提出了一种新的层直方图算法，该算法能够自动更新KAN层的域，无需用户手动调整域网格。该方法不仅提高了KAN的灵活性和适应性，还可能在多种场景下用于检测异常输入（OOD），并且在四个不同的任务上，AdaptKAN的表现超过了或与之前的KAN架构和MLP相当：学习费曼数据集中的科学方程、从冻结特征进行图像分类、学习控制朗 Perkins 函数以及在OpenOOD v1.5基准测试中检测异常输入。", "conclusion": "AdaptKAN不仅提高了性能，还使得KAN架构更加灵活和易于使用，自动调整领域网格的过程减少了用户负担，同时增强了网络的泛化能力，能够有效应对输入分布的变化。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08427", "html_url": "https://arxiv.org/abs/2511.08427", "title": "PYRO-NN库的更新：一种用于不同iable CT操作的Python库", "title_en": "An update to PYRO-NN: A Python Library for Differentiable CT Operators", "authors": "Linda-Sophie Schneider,Yipeng Sun,Chengze Ye,Markus Michen,Andreas Maier", "background": "深度学习在X射线计算机断层扫描(CT)重建方面取得了显著进展，解决了现代成像技术带来的挑战。这些进展得益于结合经典重建技术和数据驱动方法的方法。可微分运算符在这种集成中起关键作用，通过支持端到端优化和在神经网络中嵌入物理建模，从而实现优化过程。", "innovation": "本文介绍了一个更新版本的PYRO-NN，这是一个基于Python的用于CT不同iable重建的库。该更新框架扩展了对PyTorch的兼容性，并引入了CUDA内核支持，以提高在并行、扇形和锥形束几何结构上进行投影和反投影操作的效率。此外，它还提供了用于模拟成像伪影、建模任意采集轨迹和通过高级Python API创建灵活、端到端可训练管道的工具。", "conclusion": "PYRO-NN库的更新版本具有增强的功能和兼容性，能够支持广泛的CT重建任务，并简化了这些任务的实现和优化。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08567", "html_url": "https://arxiv.org/abs/2511.08567", "title": "未走的道路：RLVR 证明在主成分之外学习", "title_en": "The Path Not Taken: RLVR Provably Learns Off the Principals", "authors": "Hanqing Zhu,Zhenyu Zhang,Hanxian Huang,DiJia Su,Zechun Liu,Jiawei Zhao,Igor Fedorov,Hamed Pirsiavash,Zhizhou Sha,Jinwon Lee,David Z. Pan,Zhangyang Wang,Yuandong Tian,Kai Sheng Tai", "background": "研究发现，奖励可验证强化学习（RLVR）可以提高大型语言模型的推理性能，但似乎只修改了一小部分参数。研究者重新审视这一悖论，并表明稀疏性是一种表象，实则是模型条件优化偏见的结果：对于固定的预训练模型，更新始终集中在偏好参数区域，且在多次运行中保持一致，并且很大程度上不受数据集和RL食谱的影响。", "innovation": "研究提出了一个三门理论（Gate I（KL锚）：施加KL约束更新；Gate II（模型几何）：引导步骤偏离主方向进入低曲率、保留谱的子空间；Gate III（精度）：在非偏好区域隐藏微小更新，使偏离主方向的偏见表现为稀疏性），并以此解释这些动态。研究验证了这一理论，并首次提供了一种参数级别的RLVR学习动态表征：RLVR通过最小的谱漂移、减少主子空间旋转和偏离主方向的更新对齐来实现进展。研究发现，SFT（简化 finetuning）针对主权重，扭曲了谱，并甚至落后于RLVR。研究表明，RL与SFT在优化领域不同，直接适应SFT时期参数高效微调（PEFT）方法可能有误。", "conclusion": "研究为RLVR的训练动态提供了一个参数空间的解释，揭示了参数如何演变的明显规律。研究指出，RL操作在与SFT不同的优化领域内，直接适应SFT时代的参数高效微调方法可能是错误的，因此，希望这项工作能够为我们提供一种对RLVR的白盒理解，并设计出了解优化几何和天然适合RLVR的学习算法，而不是用SFT时代的启发式方法进行重新利用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08444", "html_url": "https://arxiv.org/abs/2511.08444", "title": "One Model for All: 针对异质性数据集和范式的脑电图情感识别的通用预训练", "title_en": "One Model for All: Universal Pre-training for EEG based Emotion Recognition across Heterogeneous Datasets and Paradigms", "authors": "Xiang Li,You Li,Yazhou Zhang", "background": "基于脑电图的的情感识别受到数据集高度异质性（渠道/主体变异性）的困扰，这妨碍了通用模型的发展。现有的方法在知识迁移的有效性方面存在困难。", "innovation": "我们提出了一个名为'One Model for All'的通用预训练框架，用于跨不同数据集的脑电图分析。该框架将学习过程分解为两个阶段：（1）通过一种统一的通道模式（UCS）和单变量预训练，使用自监督对比式学习在单独的通道上进行预训练；（2）利用新型的‘ART’（自适应采样变压器）和‘GAT’（图形注意力网络）架构进行多变量微调，以捕捉复杂的时空依赖关系。我们的研究结果表明，通用预训练是防止SEED崩溃并显著提高DEAP和DREAMER表现的关键。此外，我们展示了在未见数据集上实现顶级的知识迁移。", "conclusion": "我们的框架在所有单一主题基准测试中都达到了新的最佳性能（SEED：99.27%，DEAP：93.69%，DREAMER：93.93%）。我们还展示了顶级的跨数据集迁移，在未见过的DREAMER数据集上达到94.08%（交集）和93.05%（UCS），其中前者超越了领域内的预训练基准。消融研究验证了我们的架构：GAT模块至关重要，在高噪声的DEAP数据集上相比于GCN提升22.19%，其移除会导致性能下降16.44%。这项工作为更通用、可扩展和有效的预训练模型铺平了道路，适用于各种脑电图分析任务。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07423", "html_url": "https://arxiv.org/abs/2511.07423", "title": "Synera：大规模设备-云协同的语言模型服务", "title_en": "Synera: Synergistic LLM Serving across Device and Cloud at Scale", "authors": "Genglin Wang,Liekang Zeng,Bufang Yang,Kaiwei Liu,Guoliang Xing,Chumin Sun,Li Zhou,Jie Sun,Zhenyu Yan", "background": "大语言模型（LLMs）已成为移动操作系统中的关键组件，推动了诸如互动聊天机器人和私人助手等智能应用的发展。尽管这增加了移动设备的智能化，但在部署过程中仍然面临着一系列性能挑战，尤其是在生成质量下降和延迟时间加长方面。先前的研究主要依赖于云卸载或设备内置小语言模型（SLMs）的解决方案。然而，前者通常受到通信瓶颈的限制，而后者则因资源限制而牺牲了生成质量。为了缓解这些限制，本文提出了Synera，这是一种设备-云协同的大语言模型服务系统，采用了一种高效的小语言模型-大语言模型协同机制（SLM-LLM协同机制）。通过研究大语言模型的独特计算特征，Synera发现了设备-云协同大语言模型推理中潜在的优化机会，包括卸载决策、管道阻塞以及批处理瓶颈。", "innovation": "Synera 引入了优化的通信效率选择性卸载、无阻塞并行推理和可扩展的云批处理等定制设计，以提升性能。经过实际测试床的广泛评估，Synera 在与竞争基线相当的延迟性能下，使生成质量提高了1.20-5.47倍。相比现有的云服务解决方案，Synera 在各种基准测试中实现了8.2-16.5%的更低云服务成本。", "conclusion": "通过Synera，实现了在保持与竞争基线相当的延迟性能的同时，显著提高大语言模型生成质量，并降低了云服务成本。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07428", "html_url": "https://arxiv.org/abs/2511.07428", "title": "利用GNN和多任务学习在混合射频光学物联网网络中的资源分配", "title_en": "Resource Allocation in Hybrid Radio-Optical IoT Networks using GNN with Multi-task Learning", "authors": "Aymen Hamrouni,Sofie Pollin,Hazem Sallouha", "background": "本文探讨了将Optical Wireless Communication (OWC)与Radio Frequency (RF)结合的混合物联网网络中的双技术调度问题。作者首先提出了一个综合考虑吞吐量最大化和延迟最小化，同时满足能量和链路可用性约束的混合整数非线性规划（MINLP）模型。然而，由于这类NP难问题的规模解决难度和完全信道可观测假设的不切实际，作者提出了一种新的方法，即Dual-Graph Embedding with Transformer (DGET)框架，该框架结合了两阶段的Graph Neural Networks (GNN)和基于Transformer的编码器，为监督多任务学习架构。", "innovation": "1. 提出了DGET框架，该框架结合了两阶段的GNN和基于Transformer的编码器，捕获了网络的拓扑结构和节点、链路的初始状态，并通过一致性损失学习到随时间变化的能量和队列动力学状态之间的对齐。\n2. 采用Transductive GNN进行初始编码，Inductive GNN进行时间细化，通过多头自注意力机制捕捉跨链路依赖关系，并通过分类损失进行分类。", "conclusion": "混合RF-OWC网络相较于独立的RF系统，能够更高效地处理更高的流量负载，将Age of Information (AoI)减少多达20%，且保持了类似的能耗。与传统的基于优化的方法相比，所提出的DGET框架实现接近最优调度，具有超过90%的分类准确率，降低了计算复杂度，并且在信道部分可观测的条件下显示出了更高的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07434", "html_url": "https://arxiv.org/abs/2511.07434", "title": "RL-Exec: 基于影响意识的强化学习在比特币-美元市场中的机会性最优出售，优于TWAP和基于订单簿流动性的VWAP策略", "title_en": "RL-Exec: Impact-Aware Reinforcement Learning for Opportunistic Optimal Liquidation, Outperforms TWAP and a Book-Liquidity VWAP on BTC-USD Replays", "authors": "Enzo Duflot,Stanislas Robineau", "background": "该论文研究了在固定截止日期内基于区块链-美元（BTC-USD）限价订单簿（LOB）进行机会性最优出售的问题。传统方法如时间加权平均价格（TWAP）和基于对手方订单簿的成交量加权平均价格（Book-Liquidity VWAP）策略由来已久，但这些方法忽略了许多动态因素，如交易对手的影响、部分成交、做市商/委托费用以及执行延迟，这限制了它们的性能。因此，需要发展新的方法来优化这些因素，以实现更优的出售策略。本研究提出了一种新的基于强化学习（RL）的方法，即RL-Exec，以实现在指定时间内最大化预期收益的机会性最优出售。", "innovation": "本研究的创新点在于利用基于强化学习（Reinforcement Learning, RL）的方法，考虑了买卖双方的动态影响、部分成交情况、做市商或委托费用，以及执行延迟等因素，通过训练学习到最优的交易策略。与传统的TWAP和基于对手方订单簿的VWAP策略相比，RL-Exec在回放数据集上表现出显著的优越性能。尤其是在较长的执行期限内，RL-Exec的表现超越了传统策略。", "conclusion": "本研究通过严格的训练与测试验证了基于RL的策略（RL-Exec）在比特币-美元市场中进行机会性最优出售的效果。在测试集上，RL-Exec显著优于传统的时间加权平均价格（TWAP）策略和对手方订单簿量加权平均价格（Book-Liquidity VWAP）策略，尤其是在较长的执行期限内，表现出明显的性能优势。研究表明，考虑市场动态因素和优化交易策略对于实现最优出售至关重要。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07793", "html_url": "https://arxiv.org/abs/2511.07793", "title": "HybridGuard: 提升雾效能边缘事物网络中小众入侵检测", "title_en": "HybridGuard: Enhancing Minority-Class Intrusion Detection in Dew-Enabled Edge-of-Things Networks", "authors": "Binayak Kara,Ujjwal Sahua,Ciza Thomas,Jyoti Prakash Sahoo", "background": "雾能边缘事物(EoT)网络面临复杂且精密的入侵挑战，确保其安全是一个关键性的难题。现有的入侵检测方法在处理数据不平衡时遇到困难，影响了对小众攻击类别的检测准确性。", "innovation": "HybridGuard框架融合了机器学习和深度学习技术，通过互信息特征选择来平衡数据，确保使用最相关的特征来提升检测性能。进一步采用带梯度惩罚的Wasserstein条件生成对抗网络(WCGAN-GP)减少小众类问题，提高检测精度。DualNetShield双重网络防护架构支持高级流量分析与异常检测，提升复杂EoT环境中威胁的细粒度识别能力，评估结果表明HybridGuard在不同攻击场景下表现优秀，并能有效应对不断演变的网络安全威胁。", "conclusion": "HybridGuard作为一种有效的工具，能保护雾效能边缘事物网络免受现代入侵威胁，并且在UNSW-NB15，CIC-IDS-2017和IOTID20等数据集上的表现优于现有解决方案。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07897", "html_url": "https://arxiv.org/abs/2511.07897", "title": "基于影响力估计的大语言模型数据描述", "title_en": "Data Descriptions from Large Language Models with Influence Estimation", "authors": "Chaeri Kim,Jaeyeon Bae,Taehwan Kim", "background": "深度学习模型在许多领域取得了成功，但对其行为的理解仍然处于黑盒状态。大多数解释性人工智能（XAI）方法集中在解释和解释模型如何做出预测。而本文提出了一种新的方法，通过利用语言来解释数据，帮助人类更轻松地理解模型的行为，特别是在训练过程中如何通过外部知识库生成文本描述。", "innovation": "本文提出了一种新的方法，通过综合使用大语言模型和外部知识库来生成文本描述。为了减少文本描述中的不相关信息，提出了利用影响力估计来选择最具有信息性的文本描述。并通过首创的跨模态转移分类任务评估了这些文本描述的有效性，验证了该文本描述方法在仅有图像训练的模型上跨九个图像分类数据集的性能提升。", "conclusion": "实验结果展示了提出的文本描述方法在零样本设置下的有效性，并且成功提升了完全基于图像训练的模型在所有九个图像分类数据集上的性能。通过该方法，可以深入了解模型决策过程中的内在可解释性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07772", "html_url": "https://arxiv.org/abs/2511.07772", "title": "SALT: 在推理链中引导激活以实现无泄漏思考", "title_en": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought", "authors": "Shourya Batra,Pierce Tillman,Samarth Gaggar,Shashank Kesineni,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary", "background": "当大型语言模型（LLMs）演变为能够访问敏感用户数据的个人助手时，它们面临着一个关键的隐私挑战：尽管先前的研究已经关注了输出级隐私问题，但最近的研究发现，LLMs往往在推理过程中泄露了私人信息，这违背了上下文隐私期待。这些泄漏发生在模型无意中在其推理痕迹中暴露敏感细节的情况，即使最终输出看似安全也是如此。防止这种泄漏的挑战在于不牺牲模型的推理能力，这需要在隐私和实用性之间取得微妙的平衡。", "innovation": "我们提出了Steering Activations towards Leakage-free Thinking (SALT)，一种轻量级的测试时干预措施，通过在隐藏状态中注入有针对性的引导向量，减少模型的推理链（CoT）中的隐私泄漏。我们确定了那些对这种行为负责的高泄漏层。通过在多个LLM上的实验，我们展示了SALT可减小CPL（具体泄漏概率），例如在QwQ-32B上减小18.2%，在Llama-3.1-8B上减小17.9%，在Deepseek上减小31.2%，同时保持类似的任务性能和实用性。", "conclusion": "我们的工作证明了SALT作为推理模型测试时隐私保护的实际方法，为LLM基于的个人代理的安全部署提供了途径。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07885", "html_url": "https://arxiv.org/abs/2511.07885", "title": "每瓦智能：衡量本地人工智能的智能效率", "title_en": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI", "authors": "Jon Saad-Falcon,Avanika Narayan,Hakki Orhun Akengin,J. Wes Griffin,Herumb Shandilya,Adrian Gamarra Lafuente,Medhya Goel,Rebecca Joseph,Shlok Natarajan,Etash Kumar Guha,Shang Zhu,Ben Athiwaratkun,John Hennessy,Azalia Mirhoseini,Christopher Ré", "background": "现有的大规模语言模型查询主要由中央云基础设施的前沿模型处理。随着需求的迅速增长，云提供商难以跟上扩展基础设施的步伐。两项进展促使我们重新考虑这一模式：小型语言模型（≤20B活跃参数）在许多任务上达到了与前沿模型竞争的性能，而本地加速器（例如Apple M4 Max）可以以交互式延迟运行这些模型。这引发了问题：本地推理能否有效重新分配对中心化基础设施的需求？", "innovation": "本文提出了一种新的衡量标准——每瓦智能（IPW），即任务准确度除以单位能量，用于评估不同模型-加速器组合在本地推理上的能力和效率。该研究使用了20多种最先进的本地语言模型、8种加速器和100万条真实的单轮聊天和推理查询数据集，测试了这些模型在准确度、能耗、延迟和功耗方面的表现，发现本地加速器在停电优化上具有显著潜力，IPW指标有效地展示了这一转换过程。", "conclusion": "研究表明，本地推理可以实质性地重新分配对中心化基础设施的需求，IPW这一指标成为追踪这一转变的关键。研究者还公开了用于系统化每瓦智能基准测试的IPW性能分析工具。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07836", "html_url": "https://arxiv.org/abs/2511.07836", "title": "Hyperellipsoid Density Sampling: 利用具有开拓性的序列加速高维优化", "title_en": "Hyperellipsoid Density Sampling: Exploitative Sequences to Accelerate High-Dimensional Optimization", "authors": "Julian Soltes", "background": "高维优化问题因维度增加导致搜索空间指数级扩张，传统算法在此环境下变得效率低下或不可行。为了应对这一挑战，本文提出了一种自适应采样策略，即超椭球密度采样（HDS），作为一种替代均匀准蒙特卡洛（QMC）方法的加速优化手段。", "innovation": "HDS方法通过定义搜索空间内的多个超椭球体生成序列。利用三种无监督学习算法绕过高维几何计算，生成一种智能化、非均匀的样本序列，能够利用参数空间中统计上更为有利的区域，提升高维优化问题的最终解质量。方法的另一特点是可选的高斯权重，可以引导样本分布到感兴趣的位置，使HDS适用于超出优化的应用，能够提供对特定非均匀参数空间区域集中处理的聚焦样本分布。", "conclusion": "本研究通过对Sobol（一种标准的QMC方法）在29个CEC2017基准测试函数中使用差分进化（DE）进行评估，结果表明HDS在几何平均误差方面有显著改进（p < 0.05），平均性能提高从三维的3%到十维的37%不等。研究证明了HDS作为一种稳健的替代QMC取样的方法，适用于高维优化问题。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07831", "html_url": "https://arxiv.org/abs/2511.07831", "title": "线性函数逼近的分布鲁棒在线马尔可夫游戏", "title_en": "Distributionally Robust Online Markov Game with Linear Function Approximation", "authors": "Zewu Zheng,Yuanyuan Lin", "background": "在强化学习中，模拟器训练的代理在实际测试中的性能严重下降，即所谓的sim-to-real差距，是一个根本性的挑战。为了解决这一问题，大量工作采用了鲁棒强化学习的框架，学习在最坏环境变化下稳健执行的策略。本文在这一框架下，专注于通过假设环境动态变化的d-矩形性质，提出算法，以实现高效的样本学习，特别是处理交互数据收集和大状态空间的情况。", "innovation": "本文利用最小价值假设提出了一种新颖的DR-CCE-LSI算法，这是一种带探索奖励的最小二乘价值迭代类型算法，专门针对多智能体设计。这一算法能够找到ε-近似的鲁棒粗均衡策略。通过理论分析，证明了该算法在一个特征满足特定性质的情况下能够以O(dHmin{H,1/min{σ_i}}sqrt{K})的遗憾边界收敛到ε-近似的粗均衡，其中K是交互经历的数量，H是时间长度，d是特征维度。本文首次为此设定提供了一个高效的样本算法，在单智能体设置中匹配了最佳结果，并在特征维度d方面达到了最小最大优化样本复杂度。", "conclusion": "本文提出了一种样本高效的算法DR-CCE-LSI，在多智能体在线马尔可夫游戏中，首先利用最小价值假设并结合线性函数逼近，能够以最优的复杂度收敛到鲁棒的粗均衡策略。实验结果验证了该算法在学习鲁棒策略方面的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07776", "html_url": "https://arxiv.org/abs/2511.07776", "title": "流式张量程序：用于动态并行性的流式抽象", "title_en": "Streaming Tensor Program: A streaming abstraction for dynamic parallelism", "authors": "Gina Sohn,Genghan Zhang,Konstantin Hossfeld,Jungwoo Kim,Nathan Sobotka,Nathan Zhang,Olivia Hsu,Kunle Olukotun", "background": "动态行为在很多张量应用中变得普遍。例如，在机器学习中，输入张量可能是动态形状或稀疏的，且很多模型中广泛使用数据依赖的控制流。然而，现有的用于空间数据流加速器的编程抽象的表达力有限，导致动态行为必须被静态实现或缺乏关键性能决策的可见性。这些限制使得对动态行为实现效率优化变得困难。", "innovation": "我们提出了一种新的流式抽象，称为Streaming Tensor Program (STeP)，它能够使动态张量负载在空间数据流加速器上高效运行。STeP引入了灵活的路由操作符、显式的内存层次结构和符号形状语义，从而能够揭示动态数据速率和张量维度。这些能力解锁了新的优化，如动态镶嵌、动态并行化和配置时间复用，能够适应动态行为同时保持数据流动效率。这些优化在多种层面上提高了性能：动态镶嵌减少了芯片内存需求2.18倍；动态并行化将延迟减少了1.5倍；配置时间复用提高了计算利用率2.57倍。", "conclusion": "STeP能够高效地运行动态张量负载在空间数据流加速器上，通过引入灵活的路由操作符、显式的内存层次结构和符号形状语义，实现了动态镶嵌、动态并行化和配置时间复用等多种优化，从而在保持数据流效率的同时适应动态行为。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07869", "html_url": "https://arxiv.org/abs/2511.07869", "title": "平行采样方法：基于自律推测", "title_en": "Parallel Sampling via Autospeculation", "authors": "Nima Anari,Carlo Baronio,CJ Chen,Alireza Haqi,Frederic Koehler,Anqi Li,Thuy-Duong Vuong", "background": "本文介绍了并行算法用于加速通过计数进行采样的两种情况：任意阶自回归模型和去噪扩散模型。这两种模型分别通过访问条件下边缘分布和条件下高斯噪声下的均值来访问目标分布。传统的顺序采样算法需要近似O(n)的时间来从目标分布中生成一个样本，而在两种情况下通过并行调用Oracle，可以将采样时间的期望值降低到近似O(n^1/2)。这比之前对于任意阶自回归模型的近似O(n^2/3)有了改进，同时也标志着对于去噪扩散模型在高精度区域下的首次并行加速，前提是目标分布的支持是有限的。", "innovation": "本文引入了一种名为‘自律推测采样’（autospeculation-based rejection sampling）的新技术，该技术通过使用一种推测分布（推测分布ν近似于实际分布μ）来加速采样过程，这种推测分布是基于定义实际分布所用的相同Oracle构建的，这与传统的预测编解码推断不同，因为它需要一个独立、更快但可能不那么准确的草稿模型。并且，更重要的是，‘自律推测采样’是在序列级别而不是在单个或几个步骤级别上进行推测与接受，从而使得并行运行时可以减少到近似O(n^1/2)。", "conclusion": "这些并行方法可以显著提高采样效率，尤其是当准确性要求较高时，在平均情况下采样时间可以减少到近似O(n^1/2)，并在高精度的情况下首次实现了采样效率的并行加速。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07883", "html_url": "https://arxiv.org/abs/2511.07883", "title": "SpikCommander: 高性能的多视图学习驱动的脉冲变压器用于高效语音命令识别", "title_en": "SpikCommander: A High-performance Spiking Transformer with Multi-view Learning for Efficient Speech Command Recognition", "authors": "Jiaqi Wang,Liutao Yu,Xiongri Shen,Sihang Guo,Chenlin Zhou,Leilei Zhao,Yi Zhong,Zhengyu Ma,Zhiguo Zhang", "background": "当前文本脉冲神经网络（SNNs）为实现高效语音命令识别（SCR）提供了有希望的途径，因为它们利用了事件驱动的处理模式。然而，现有的SNN基SCR方法往往难以捕捉语音中的丰富的时间依赖性和上下文信息，这是因为其有限的时间建模能力和基于二值脉冲表示的形式限制了这一点。为了解决这一挑战，我们首先引入了多视图脉冲时间感知自注意力（MSTASA）模块，该模块结合了有效的时间感知自注意力机制和多视图学习框架，以建模语音命令中的互补时间依赖性。在此基础之上，我们进一步提出了全新的SpikCommander架构，这是一种完全由脉冲驱动的变换器结构，该结构结合了MSTASA与脉冲上下文精炼通道MLP（SCR-MLP）来共同增强时间上下文建模和频道间特征的融合。我们已经在三个基准数据集上评估了我们的方法：Spiking Heidelberg数据集（SHD）、Spiking Speech Commands（SSC）以及Google Speech Commands V2（GSC）。详尽的实验表明，在具有相当的时间步的情况下，SpikCommander在参数更少的情况下比最先进的SNN方法有更优异的表现，突显了其高效且稳健的语音命令识别方法的有效性。", "innovation": "本研究介绍了多视图脉冲时间感知自注意力（MSTASA）模块，该模块通过结合有效的时间感知自注意力机制和多视图学习框架，建模语音命令中的互补时间依赖性。基于此模块，我们进一步提出了SpikCommander架构，这是一种完全由脉冲驱动的变换器结构，结合了MSTASA与脉冲上下文精炼通道MLP（SCR-MLP），以增强时间上下文建模和频道间特征的融合。相较于现有的SNN基方法，SpikCommander在参数更少的情况下仍能实现优异的表现，证明了其高效性和有效性在语音命令识别中的优势。", "conclusion": "我们的研究通过多视图脉冲时间感知自注意力模块和全新的脉冲驱动变换器架构SpikCommander，为语音命令识别提供了更为高效且稳健的方法，实验结果表明，SpikCommander在与现有SNN方法具有相当时间步的情况下，使用更少参数仍能取得更优性能，充分体现了其在语音命令识别中的优越性和效率。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07807", "html_url": "https://arxiv.org/abs/2511.07807", "title": "PRISM: 隐私保护的同态加密和模块化激活的推理系统", "title_en": "PRISM: Privacy-preserving Inference System with Homomorphic Encryption and Modular Activation", "authors": "Zeinab Elkhatib,Ali Sekmen,Kamrul Hasan", "background": "随着机器学习的快速发展，模型在各个行业的学习和预测能力大大增强。然而，将这些模型部署到关键基础设施中面临着重大挑战，因为数据隐私问题限制了数据的自由共享。同态加密（HE）可以在不暴露数据内容的情况下进行计算，是一种解决方法，但目前尚未与依赖非线性激活函数的卷积神经网络（CNN）等机器学习模型兼容。为了解决这个问题，该研究提出了一种优化框架，用同态兼容的近似函数替换标准非线性函数，确保在最小化计算开销的同时进行安全计算。实验结果显示，使用4次多项式和Softplus激活函数，在CKKS下实现了94.4%的准确率，并且每加密样本的计算时间为2.42秒，每10,000加密样本的计算时间为24,000秒，平衡了准确性和隐私性。但是实验数据使用的具体硬件配置和环境未详细说明，从而可能影响结果的通用性与可靠性，是当前研究的一个潜在限制。", "innovation": "该研究提出了一种优化框架，通过使用同态兼容的近似函数替换标准CNN中的非线性激活函数，实现威胁隐私的安全计算。这种方法不仅保证了分类任务的准确性，还大幅减少了计算成本，从而促进了在关键基础设施中的部署。", "conclusion": "通过实验验证，该框架在CIFAR-10数据集上实现了94.4%的准确率，单个加密样本的计算时间为2.42秒，每10,000个样本的计算时间为24,000秒。这表明该方法能够在保证计算效率的同时，提供高准确率和高隐私保护。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08219", "html_url": "https://arxiv.org/abs/2511.08219", "title": "天体物理环境中模拟辐射传输", "title_en": "Emulating Radiative Transfer in Astrophysical Environments", "authors": "Rune Rost,Lorenzo Branca,Tobias Buck", "background": "辐射传输是天体物理学中的一个基本过程，对于理解和解释观测结果以及通过离子辐射和光压建模热力和动力学反馈在模拟中都至关重要。然而，数值求解背后辐射传输方程在计算上是密集的，因为光线与物质的复杂相互作用以及光速与天体物理环境中典型气体速度之间的巨大差异，使得实时辐射效应的纳入特别昂贵。这驱使人们开发出可以显著加速辐射传输计算而同时保持高精度的近似模型。", "innovation": "我们提出了一种基于傅里叶神经操作符架构结合U-Nets的近似模型。我们的模型在时变条件下近似三维单色辐射传输，在吸收-发射近似下实现了超过两个数量级的速度提升，同时保持平均相对误差低于3%，这表明我们的方法有可能被集成到最先进的水动力模拟中。", "conclusion": "该模型不仅在速度上有了巨大提升，而且在准确性上也保持了可靠水平，展示了其在天体物理学模拟中的广泛应用潜力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08245", "html_url": "https://arxiv.org/abs/2511.08245", "title": "自然语言到SQL的提示调整，结合嵌入式微调和RAG", "title_en": "Prompt Tuning for Natural Language to SQL with Embedding Fine-Tuning and RAG", "authors": "Jisoo Jang,Tien-Cuong Bui,Yunjun Choi,Wen-Syan Li", "background": "随着自然语言界面的广泛应用，自然语言到SQL的高效和准确翻译成为一个关键需求。NLIDBs从早期基于规则的系统发展到现代以神经网络为基础的方法。本文研究了NLP到SQL转换的挑战，并借鉴医学诊断过程提出了一种新颖的错误修正框架，旨在提高SQL查询的准确性和透明度。实验结果表明，该框架在准确性上提升了12%，验证了其在数据驱动环境中的潜力和重要性。", "innovation": "本文提出了一个基于提示调整的方法，该方法结合了嵌入式微调和RAG技术，用于自然语言到SQL的转换。该方法包括一个错误诊断机制，能够识别错误类型、找到其原因、提供修复说明并修正SQL查询。通过这种方法，提高了自然语言到SQL转换的准确性和透明度，特别是通过利用外部知识库增强了模型的性能。", "conclusion": "通过全面的实验，本文展示了新的框架在准确性和透明度方面的显著提升，比现有基线提升了12%。这是一种革新数据访问和处理的关键技术，对于当前数据驱动的环境具有重要意义。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08223", "html_url": "https://arxiv.org/abs/2511.08223", "title": "一种快速且准确的协方差矩阵构建方法", "title_en": "A Fast and Accurate Approach for Covariance Matrix Construction", "authors": "Felix Reichel", "background": "Reichel (2025)定义了Bariance，通过解析展示了其$O(n)$优化形式，本文在此基础上，将Bariance的概念扩展到协方差矩阵的构建中，提出了一个新的计算公式，该公式与传统的基于配对差分的形式等价，但避免了显式的中心化步骤，从而简化了计算过程，具有明显的优势", "innovation": "本文通过一种新的方法构造了协方差矩阵，公式为$ \text{Cov}(X)=\frac{1}{n-1}\big(X^\top X-\frac{1}{n}\text{s}\text{s}^\top\big)$，其中$s=X^\top \textbf{1}_n$，这种方法避免了显式的中心化，通过一次$p \times p$的外积计算和一个减法操作来实现计算，相比原有方法在非BLAS调优环境下具有明显的时间优势。此外，快速Gram方法如RXTX（Rybin et al.）进一步降低了总体计算成本", "conclusion": "本文提出的方法不仅计算复杂度较低，而且能够在不牺牲准确性的前提下提高计算效率，这对于大尺度数据集的协方差矩阵计算尤其有价值"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08231", "html_url": "https://arxiv.org/abs/2511.08231", "title": "基于多保真度剩余物理启发式神经过程的机器人系统实时状态估计算法性能分析", "title_en": "Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems", "authors": "Devin Hunter,Chinwendu Enyioha", "background": "目前，各种神经网络架构被广泛应用于实时非线性状态估计的先进方法中。随着这些数据驱动模型的不断增加，特别是在安全关键型应用中，可靠的误差边际成为必要。本文探讨了一种基于多保真度剩余物理启发式神经过程（MFR-PINP）的实时数据驱动状态估计方法在机器人系统中的应用，解决通过让MFR-PINP学习低保真度预测与复杂高保真度的真实动态之间的残差来选择准确的运动模型的问题。为解决物理实现中的模型不确定性，使用分拆置信预测框架（SC框架）中的稳健不确定性保证进行训练和推理建模。", "innovation": "提出了基于MFR-PINP的实时数据驱动状态估计算法，该方法能够结合低保真度预测与复杂高保真度的真实动态之间的残差，解决模型失配问题。通过使用SC预测框架中的稳健不确定性保障，实现模型不确定性建模，适用于线上学习的混合环境。实验结果显示，该方法在实时估计任务中的表现优于传统的卡尔曼滤波及其深度版本。", "conclusion": "基于MFR-PINP的实时状态估计方法在机器人系统的应用中展现出了潜在的优势，尤其是在实时估计场景中。该方法提供了在可靠不确定性估计下的实时性能，为安全关键型应用提供了新的可能性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08215", "html_url": "https://arxiv.org/abs/2511.08215", "title": "使用EfficientNet-B4视觉骨干在食物图像基础上评估Gemini LLM进行食谱和营养描述", "title_en": "Evaluating Gemini LLM in Food Image-Based Recipe and Nutrition Description with EfficientNet-B4 Visual Backbone", "authors": "Rizal Khoirul Anam", "background": "数字化食品应用程序的增长迫切需要高效的自动化营养分析和烹饪指导方法。本文通过对比评估了一个分耦合的跨模态管道来识别食物的全面性能。该研究旨在评估视觉分类准确性、模型效率和生成输出（营养数据和食谱）之间权衡。实验基于一款自主研发的中国本土化食品数据集（CCFD），以解决公共数据集中的文化偏见问题。", "innovation": "本文引入了一个“语义错误传播”（SEP）的形式化定义，来分析视觉模块分类不准确如何影响生成输出。作者使用Gemini大语言模型和EfficientNet-B4视觉骨干来构建评估管道，并与VGG-16、ResNet-50、YOLOv8和Gemma进行对比。通过提出新的Chinese Custom Food Dataset来解决文化偏见问题，提供了一个全面的评估框架。", "conclusion": "尽管EfficientNet-B4在准确性与效率之间做到了较好的平衡，并且Gemini在生成质量上表现出色，但整个系统的实用性和效率受到视觉前端感知准确性的瓶颈限制。细致的分类分析显示，高语义相似度是系统的主要失败模式，需要进一步改进。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08207", "html_url": "https://arxiv.org/abs/2511.08207", "title": "FedPoP: 分布式学习遇见参与证明", "title_en": "FedPoP: Federated Learning Meets Proof of Participation", "authors": "Devriş İşler(IMDEA Networks Institute - Universidad Carlos III de Madrid),Elina van Kempen(University of California, Irvine),Seoyeon Hwang(Stealth Software Technologies Inc.),Nikolaos Laoutaris(IMDEA Networks Institute)", "background": "联邦学习（FL）提供了一种隐私保护的分布式机器学习方法，允许客户端能够不泄露本地数据的情况下贡献于全局模型。随着模型逐渐成为可货币化的数字资产，证明其在训练过程中参与的能力对于确立所有权变得至关重要。本文旨在解决这一新兴需求，提出了一种新的FL框架FedPoP，能够同时确保客户端匿名性和隐私，无需进行过多计算或依赖公共账本，还可以无缝集成现有的安全聚合协议，以适应实际的FL部署。", "innovation": "FedPoP框架能够在不泄露客户隐私的情况下，提供一种非可追溯的方式来证明客户的参与。该框架特别地，其引入了0.97秒/轮的额外开销，同时使客户能够在0.0612秒内证明其对第三方持有的模型的参与和贡献，这表明FedPoP适用于实际部署，即使在需要审计参与的情况下也不牺牲隐私。", "conclusion": "FedPoP框架提供了一种新颖的方法来结合联邦学习和参与证明，使得在模型训练过程中保障客户的参与证明和隐私成为可能。该研究结果表明，这种方法是实际应用中的可行方案，特别是在需要审计参与的同时，不需要牺牲隐私。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08303", "html_url": "https://arxiv.org/abs/2511.08303", "title": "通过广义Riesz回归在未标记协变量下进行半监督治疗效果估计", "title_en": "Semi-Supervised Treatment Effect Estimation with Unlabeled Covariates via Generalized Riesz Regression", "authors": "Masahiro Kato", "background": "本研究探讨在半监督设置中治疗效果的估计，即不仅可以使用标准的协变量、治疗指示器和结果，还可以使用未标记的辅助协变量。研究设计了不同的数据生成过程，即单样本设置和双样本设置。通过引入这两种不同数据生成过程，研究探讨了在部分数据集中观察到治疗指示器和结果的情况（称为截尾设置）以及两个独立数据集包含有标记和未标记数据的情况（也称为配对设置或分层设置）。", "innovation": "研究开发了效率下界以及与效率下界相匹配的渐近方差的高效估计量。通过引入广义Riesz回归方法，研究能够将辅助协变量纳入考虑，从而降低效率下界并获得渐近方差更小的估计量。", "conclusion": "无论在单样本设置还是双样本设置中，通过引入辅助协变量都能降低效率下界并得到更有效的估计量。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08261", "html_url": "https://arxiv.org/abs/2511.08261", "title": "多标签鸟类声音分类器的不确定性校准", "title_en": "Uncertainty Calibration of Multi-Label Bird Sound Classifiers", "authors": "Raphael Schwinger,Ben McEwen,Vincent S. Kather,René Heinrich,Lukas Rauch,Sven Tomforde", "background": "被动声学监测能够实现大规模生物多样性的评估，但生物声学中的声波分类不仅需要高精度，还需要准确的不确定性估计以支持决策。生物声学中的分类挑战包括重叠的鸣叫声、长尾物种分布以及训练数据与应用数据之间的分布偏移。目前，生物声学领域中多标签深度学习分类器的校准尚未进行评估。", "innovation": "本研究系统地评估了四种最先进的多标签鸟类声音分类器在BirdSet基准上的校准情况，使用无阈值的校准指标（ECE、MCS）和区分指标（cmAP）从全局、数据集和类别的角度进行评估。研究发现，不同数据集和分类的校准效果存在显著差异。通过简单的后预测校准方法，展示了一种简单有效的改进校准的方法。实验表明少量标记的校准集即可显著提高分类器的校准性能，而全局校准参数因数据集变化而受损。", "conclusion": "研究突出强调了在生物声学分类器中评估和改进不确定性校准的重要性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08277", "html_url": "https://arxiv.org/abs/2511.08277", "title": "X-IONet：双阶段注意力的跨平台惯性导航网络", "title_en": "X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention", "authors": "Dehan Shen,Changhao Chen", "background": "基于学习的惯性里程计在人体导航中取得了显著进展。然而，将这些方法扩展到四足机器人仍具有挑战性，因为四足机器人的运动模式既独特又高度动态。表现良好的人体数据模型往往在应用于腿足平台时性能严重下降。为了解决这一挑战，我们提出了一种跨平台惯性里程计框架X-IONet，该框架仅使用单一惯性测量单元（IMU）运行。X-IONet结合了一种基于规则的专家选择模块，用于分类运动平台并路由IMU序列至特定平台的专家网络。", "innovation": "X-IONet引入了基于规则的专家选择模块，用于分类运动平台并路由IMU序列至特定平台的专家网络。预测位移的网络采用双阶段注意力架构，同时建模长期时间依赖性和轴间关联性，提高了位移表示的准确性。此外，它输出位移及其相关不确定性，通过扩展卡尔曼滤波器（EKF）进一步融合，实现稳健的状态估计。", "conclusion": "对公开的人体数据集和自采集的四足机器人数据集进行的大量实验表明，X-IONet在人体数据集上将绝对轨迹误差（ATE）降低了14.3%，相对轨迹误差（RTE）降低了11.4%，在四足机器人数据集上将这些误差分别减少了52.8%和41.3%。这些结果突显了X-IONet在提高人体和四足机器人平台惯性导航准确性与鲁棒性方面的作用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08307", "html_url": "https://arxiv.org/abs/2511.08307", "title": "黑盒生成模型基于响应的向量嵌入的集中性界", "title_en": "Concentration bounds on response-based vector embeddings of black-box generative models", "authors": "Aranyak Acharyya,Joshua Agterberg,Youngser Park,Carey E. Priebe", "background": "生成模型，例如大型语言模型或文本到图像的扩散模型，能够生成与用户查询相关的响应。基于响应的生成模型的向量嵌入有助于对给定的黑盒生成模型集合进行统计分析和推断。数据内核透视空间嵌入是获得给定生成模型集的基于响应的向量嵌入的一种特定方法，已经在文献中有所讨论。本文在适当正则性条件下，建立了基于数据内核透视空间嵌入方法获得的生成模型集的样本向量嵌入的高概率集中性界。研究结果告诉我们，在何种准确度下所需样本响应的数量，以近似群体级别的向量嵌入。用于建立这些结果的代数工具还能用于一般情况下的经典多维标度嵌入的集中性界，尤其是当距离观测中有噪声时。", "innovation": "该研究通过数据内核透视空间嵌入方法建立了生成模型集的样本向量嵌入的高概率集中性界，明确了在目标准确度下所需样本响应的数量。此外，研究结果提供了一种评估黑盒生成模型集合统计分析可靠性的方法，并可用于建立经典多维标度嵌入的集中性界。", "conclusion": "本文证明了数据内核透视空间嵌入方法的样本向量嵌入的高概率集中性界，并提供了确定黑盒生成模型集合准确嵌入所需样本响应数量的方法。此外，研究还展示了一种建立经典多维标度嵌入集中性界的通用框架。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08315", "html_url": "https://arxiv.org/abs/2511.08315", "title": "BDD2Seq: 通过基于图的序列学习实现可逆电路综合的可扩展性", "title_en": "BDD2Seq: Enabling Scalable Reversible-Circuit Synthesis via Graph-to-Sequence Learning", "authors": "Mingkai Miao,Jianheng Tang,Guangyu Hu,Hongce Zhang", "background": "二值决策图（BDDs）在电子设计自动化（EDA）任务中非常有用，因为它们能紧凑地表示布尔函数。在基于BDD的可逆电路综合中，选择变量排列对节点数有重要影响，进而影响资源消耗的关键指标，如量子成本。寻找最优变量排列是一个NP完全问题，现有的启发式方法在电路复杂度增加时效果往往会下降。", "innovation": "BDD2Seq引入了一种结合图神经网络编码器和指针网络解码器以及多样化束搜索的图到序列框架，用于预测高质量的变量排列。通过将电路网表视为图，BDD2Seq学习到了传统启发式方法忽视的结构依赖性，从而实现更小的BDD和更快的综合。实验结果表明，BDD2Seq在量子成本和综合速度上分别比现代启发式算法低约1.4倍和快3.7倍。这是首次使用基于图的生成模型和促进多样性的解码器来解决基于BDD的可逆电路综合中的变量排列问题的研究工作。", "conclusion": "BDD2Seq通过学习结构依赖性，能更有效地预测变量排列，实现更优的可逆电路综合结果，并且比现有方法性能更好。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08579", "html_url": "https://arxiv.org/abs/2511.08579", "title": "训练语言模型解释其自身计算", "title_en": "Training Language Models to Explain Their Own Computations", "authors": "Belinda Z. Li,Zifan Carl Guo,Vincent Huang,Jacob Steinhardt,Jacob Andreas", "background": "研究语言模型（LMs）是否能够准确描述其内部计算过程。探索LMs通过利用其访问自身内部信息的优势来生成解释其行为的新方法。将现有的可解释性技术作为参照，研究LMs生成自然语言描述的能力，包括LM特征所编码的信息、LM内部激活的因果结构以及特定输入对输出的影响。", "innovation": "开发了一种方法，通过微调LMs生成自然语言解释，以解释LM特征所编码的信息、LM内部激活的因果结构以及特定输入对输出的影响。实验表明，在仅使用数万示例解释的情况下，解释模型展示出对新查询的非平凡泛化能力。此外，利用模型解释其自身计算的能力优于让其他模型解释其计算，即使这些其他模型更为强大。", "conclusion": "结果表明，LMs不仅能可靠地解释其内部计算，而且此类解释为现有解释方法提供了可扩展的补充。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.17559", "html_url": "https://arxiv.org/abs/2305.17559", "title": "初始化剪枝——一种投影视角", "title_en": "Pruning at Initialization -- A Sketching Perspective", "authors": "Noga Bar,Raja Giryes", "background": "文章背景介绍了彩票票假说（LTH），它增加了对在初始化时修剪神经网络的关注。研究者们在此基础上，探讨了这一问题在线性环境中的表现。", "innovation": "研究提出了一种新的视角——投影视角——来分析初始时寻找稀疏掩码的问题，将其与高效矩阵乘法中的拟合问题联系起来。通过这种方法，他们能够理论证明稀疏网络搜索在数据独立性方面可能是有效的，并提出了一种可以改进现有初始化时修剪算法的一般方法。", "conclusion": "研究使用初始时找到的掩码，界定了训练结束时修剪线性模型的近似误差。通过理论验证了之前的实验发现，并建议了一种适用于数据独立情况的有效改进算法，证明了其有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08500", "html_url": "https://arxiv.org/abs/2511.08500", "title": "SPEAR-MM：通过模型合并进行选择性参数评估和复原以实现高效金融大语言模型适配", "title_en": "SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation", "authors": "Berkcan Kapusuzoglu,Supriyo Chakraborty,Renkun Ni,Stephen Rawls,Sambit Sahu", "background": "大型语言模型（LLMs）在金融领域适应后，往往会遗忘其一般推理能力，这些能力对于客户服务和复杂金融分析至关重要。标准的连续预训练方法在这种情况下表现不佳。", "innovation": "引入了选择性参数评估和恢复通过模型合并的方法（SPEAR-MM），该方法能够在保持关键功能的同时，实现领域适应。通过后分析法评估每一层对外部基准的影响，然后通过球面插值合并选择性冻结或恢复变压器层。", "conclusion": "在应用于LLaMA-3.1-8B的金融任务中，SPEAR-MM方法在保持91.2%的一般能力的同时，计算成本降低了90%，并且保持了94%的领域适应收益，相比标准的连续预训练，保留了69.7%的一般能力。这种方法提供了可解释性权衡控制，对于资源受限的金融机构至关重要。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08505", "html_url": "https://arxiv.org/abs/2511.08505", "title": "结构化RAG以回答聚合型问题", "title_en": "Structured RAG for Answering Aggregative Questions", "authors": "Omri Koshorek,Niv Granot,Aviv Alloni,Shahar Admati,Roee Hendel,Ido Weiss,Alan Arazi,Shay-Nitzan Cohen,Yonatan Belinkov", "background": "当前的RAG方法大多集中于仅少量文本片段（通常是一两段）与查询相关的情况，而在处理需要整合大量文档信息并进行推理的聚合型查询时则表现不佳，这已成为现有方法的局限性之一。", "innovation": "本文提出了一种名为S-RAG的方法，专门针对聚合型查询。在消化阶段，S-RAG构建了 corpora 的结构化表示；在推理阶段，它将自然语言查询翻译成对这种表示的正式查询。通过在新引入的HOTELS和WORLD CUP数据集以及公开基准上进行实验，证明了与常见RAG系统和长上下文LLMs相比，S-RAG在性能上有了显著提升。", "conclusion": "实验表明，S-RAG在处理聚合型问题时相较于现有的RAG系统和长上下文LLMs有着显著的优势，表明结构化RAG方法在解决大规模文档中聚合性查询的问题上有其独特优势，为后续研究提供了新的方向。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08512", "html_url": "https://arxiv.org/abs/2511.08512", "title": "CleverBirds: 多项选择基准数据集用于细粒度的人类知识追踪", "title_en": "CleverBirds: A Multiple-Choice Benchmark for Fine-grained Human Knowledge Tracing", "authors": "Leonie Bossemeyer,Samuel Heinrich,Grant Van Horn,Oisin Mac Aodha", "background": "在许多专家领域中，掌握细粒度的视觉识别需要专家开展多年专门的培训。理解和建模人类在这些领域的专业知识进步仍然具有挑战性，而准确推断学习者当前的知识状态是理解视觉学习的关键步骤。本文介绍了CleverBirds，这是一个基于生物多样性公民科学平台eBird的大规模知识追踪基准数据集，该数据集提供了一个关于个人如何在复杂的细粒度分类中获得专业知识的见解。超过40,000名参与者回答了超过1700万个关于数千种鸟类的多项选择题，平均每人回答了400个问题。", "innovation": "CleverBirds的数据集支持新的视觉知识追踪方法的发展和评估。研究显示，追踪学习者知识是有挑战性的，尤其是在不同参与者子组和问题类型之间。不同类型的上下文信息为预测提供了不同程度的帮助。CleverBirds是同类中规模最大的基准数据集之一，提供了更多的可学习概念，旨在启用新的研究路径来研究视觉专业知识的发展。", "conclusion": "CleverBirds旨在支持新的视觉知识追踪方法的研究，并提供一个大规模的基准数据集，用于理解视觉专业知识长时间和跨个体的发展。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2102.12192", "html_url": "https://arxiv.org/abs/2102.12192", "title": "多因素重权化以增强神经网络优化的鲁棒性", "title_en": "Multiplicative Reweighting for Robust Neural Network Optimization", "authors": "Noga Bar,Tomer Koren,Raja Giryes", "background": "由于强大的性能，神经网络被广泛使用。然而，在训练时存在噪声标签的情况下，这些模型的表现会下降。受专家建议学习设置的启发，其中最近的研究显示多乘性权重更新（MW）方法对于专家建议中的中度数据污染具有鲁棒性，本文提出在神经网络优化期间使用MW重新加权样本。理论分析表明，当与梯度下降结合使用时，该方法能够在1D案例中进行收敛。", "innovation": "提出了将多乘性权重（MW）用于重新加权演示实例，以优化神经网络，特别是在存在标签噪声的情况下。该方法不仅证明了在1D情况下的有效性，还通过在CIFAR-10、CIFAR-100和Clothing1M数据集中的实验验证，显示了其在通用情况下的改进，尤其是在标签噪声和对抗鲁棒性方面。", "conclusion": "研究证明在梯度下降上使用MW权重可以改善在标签噪声情况下的神经网络准确性，并提高对抗鲁棒性性能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.17327", "html_url": "https://arxiv.org/abs/2305.17327", "title": "层级深度反事实遗憾最小化", "title_en": "Hierarchical Deep Counterfactual Regret Minimization", "authors": "Jiayu Chen,Zhekai Wang,Vaneet Aggarwal", "background": "不完美信息博弈（IIGs）为决策者在不确定性或信息不完整的情况下提供了一个强大的模型。反事实遗憾最小化（CFR）是最成功的一系列算法之一，用于解决IIGs问题。将基于技能的策略学习与CFR结合，能够更接近人类的决策过程，增强复杂IIGs的学习表现。HDCFR通过构建层次结构策略，将低层级技能用于解决子博弈，高层级技能用于管理技能之间的转换。", "innovation": "HDCFR是一种创新的方法，旨在提高包括广泛状态空间和复杂游戏树在内的任务的学习效率。相比之前的工作，HDCFR的一个明显优势是可以利用预定义的人类专业知识来促进技能的学习，这些技能可以转移到类似的任务中。该方法首先基于表格设置构建，扩展了层次CFR更新规则，并提出了一种减小方差的蒙特卡洛采样方法。此外，还使用神经网络进行了函数逼近，并开发了深层学习目标以适应大规模任务。", "conclusion": "通过理论分析和实验证明了HDCFR算法的有效性，并将其应用于实际大规模问题。HDCFR为复杂IIGs的策略学习提供了一种新的视角和方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08573", "html_url": "https://arxiv.org/abs/2511.08573", "title": "SENCA-st: 结合跨注意力共享编码器整合空间转录组学和组织病理学以识别癌症病理中的区域", "title_en": "SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology", "authors": "Shanaka Liyanaarachchi,Chathurya Wijethunga,Shihab Aaquil Ahamed,Akthas Absar,Ranga Rodrigo", "background": "空间转录组学是能够根据基因表达的空间分布识别功能性区域的新兴领域。将空间转录组学功能信息与结构数据相结合，可以用于识别与癌症药物抵抗相关的肿瘤亚结构。当前的空间转录组学-组织病理学区域分割方法存在缺陷：要么过分强调空间转录组学而忽视组织病理学特征，要么过分强调组织病理学图像导致丢失功能信息。这种极端情况导致模型要么陷入空间转录组学的噪音中，要么过于平滑，丢失关键信息。因此，我们提出了新型架构SENCA-st（共享编码器与邻域交叉注意力），该架构保留了两种模态的特征，更重要的是，它利用交叉注意强调在组织病理学中结构相似但在空间转录组学中功能不同的区域。我们展示了这种模型在检测肿瘤异质性和肿瘤微环境区域方面的优越性能，这在临床上是非常重要的方面，且超过了现有方法的性能.", "innovation": "我们提出了SENCA-st（Shared Encoder with Neighborhood Cross Attention）架构，该架构结合了空间转录组学和组织病理学数据。其创新点在于利用跨注意力机制强调组织病理学中结构相似但在空间转录组学中功能不同的区域，同时保留两种数据模态的特征。", "conclusion": "我们展示的SENCA-st模型在检测肿瘤异质性和肿瘤微环境区域方面优于现有最佳方法，这对于识别与癌症药物抵抗相关的肿瘤亚结构具有临床重要性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08583", "html_url": "https://arxiv.org/abs/2511.08583", "title": "SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment", "title_en": "SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment", "authors": "Rong Xue,Jiageng Mao,Mingtong Zhang,Yue Wang", "background": "在机器学习领域，开发高效且准确的视觉-运动策略是机器人模仿学习中的一个核心挑战。虽然最近的校正流方法在视觉-运动策略学习方面取得了进展，但也存在一个关键问题：经过多轮校正后，生成的动作可能会偏离当前视觉观察所对应的真实动作，导致在重复校正过程中累积误差，并引发任务执行的不稳定性。", "innovation": "我们提出了选择性流对齐（SeFA），这是一种高效且准确的视觉-运动策略学习框架。SeFA 通过选择性流对齐策略来解决这一挑战，该策略利用专家示范来选择性纠正生成的动作，恢复与观察的一致性，同时保留多模态性。这种设计引入了一致性纠正机制，确保生成的动作保持与观察的对齐，而无需牺牲单步流推理的效率。广泛的实验表明，SeFA 策略在模拟和现实世界操作任务中超越了最先进的扩散和流基于的策略，实现更高的准确性和鲁棒性，同时将推理延迟减少超过98%。通过统一校正流效率与动作观察一致性生成，SeFA 提供了一个可扩展且可靠的实时视觉-运动策略学习解决方案。", "conclusion": "SeFA 提供了一个可扩展且可靠的实时视觉-运动策略学习解决方案，通过结合校正流的效率和观察一致的动作生成，显著提高了准确性和鲁棒性，大幅降低了推理延迟，代码可在指定链接下载。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08577", "html_url": "https://arxiv.org/abs/2511.08577", "title": "Think-at-Hard: 选择性的潜在迭代以提高推理语言模型", "title_en": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models", "authors": "Tianyu Fu,Yichen You,Zekai Chen,Guohao Dai,Huazhong Yang,Yu Wang", "background": "大型语言模型（LLMs）在参数约束下改进推理能力对于现实应用至关重要。现有研究提出使用循环变压器，通过为每个词元分配固定数量的额外迭代次数来改进生成质量。这种方法在标准的前向传递之后，使用上一层隐藏状态作为输入进行额外迭代以优化词元预测。然而，研究发现可能存在一种潜在的过度推理现象：一些在标准前向处理后已经正确的词元可能在进一步迭代中被错误地修改。为了应对这一问题，本文提出了一种名为Think-at-Hard（TaH）的动态潜推理方法，该方法只在困难的词元上进行更深的迭代。这种方法采用了轻量级的神经决策器，在标准前向传递认为可能错误的位置触发潜迭代。在潜迭代过程中，低秩适应（LoRA）模块将LLM的目标从一般的下一个词元预测转向了针对困难词元的精细调整。", "innovation": "1. TaH方法通过在标准前向传递后的困难词元上动态进行迭代，而不是所有词元都进行两次迭代。\n2. 引入了一种低秩适应（LoRA）模块，将LLM的目标从一般词元预测调整为针对困难词元的精细优化。\n3. 提出了双重因果注意力机制，扩大了注意力维度，使跨迭代的信息流动成为可能，同时保持完整的序列并行性。", "conclusion": "实验表明，相比基线模型，TaH在五个具有挑战性的基准测试中显著提升了LLM的推理表现，同时保持了相同的参数数量。与使用相同数据进行单迭代调优的Qwen3模型相比，TaH也提高了4%-5%的准确率。通过允许不到3%的附加参数量，TaH将准确率提升至8.5%-12.6%和5.3%-5.4%。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.06444", "html_url": "https://arxiv.org/abs/2503.06444", "title": "使用少量样本合成高维表格数据的方法研究", "title_en": "Towards Synthesizing High-Dimensional Tabular Data with Limited Samples", "authors": "Zuqing Li,Junhao Gan,Jianzhong Qi", "background": "基于扩散的表格数据合成模型在一定程度上取得了显著的结果，但随着数据维度的增加，现有的模型往往会退化，甚至不如更简单的非扩散模型。这一问题是由于高维空间中的有限训练样本常导致生成模型无法准确捕捉数据分布。", "innovation": "提出了一种条件控制扩散模型CtrTab，该模型在训练过程中注入扰动的真实样本作为辅助输入。这种设计引入了模型对控制信号敏感性的隐式L2正则化，从而在高维和低样本数据的情况下提高了模型的稳健性和稳定性。", "conclusion": "在多个数据集上进行的实验表明，CtrTab 在准确性方面明显优于现有模型，平均准确性提升超过90%。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11770", "html_url": "https://arxiv.org/abs/2505.11770", "title": "内部因果机制稳健地预测语言模型的分布外行为", "title_en": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors", "authors": "Jing Huang,Junyi Tao,Thomas Icard,Diyi Yang,Christopher Potts", "background": "当前可解释性研究提供了多种方法来识别神经网络中的抽象内部机制。然而，尚未确定这些方法能否用于预测模型在分布外样本上的行为。本文通过多种语言建模任务展示了这一点，包括符号操作、知识检索和指令遵循。通过这些任务的研究表明，预测模型正确性的最稳健特征是那些在模型行为中发挥独特因果作用的特征。", "innovation": "本文提出了一种利用因果机制来预测模型输出正确性的方法，即反事实模拟（检查关键因果变量是否实现）和价值探针（使用这些变量的值进行预测）。这两种方法在分布内外均表现出色，尤其是在分布外环境中预测模型行为更为关键的情况下，显著优于依赖于无因果特征的方法。", "conclusion": "因此，本文揭示了内部因果分析语言模型的一种新颖且重要的应用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09849", "html_url": "https://arxiv.org/abs/2502.09849", "title": "临床决策支持系统中可解释人工智能方法的人本评价综述", "title_en": "A Survey on Human-Centered Evaluation of Explainable AI Methods in Clinical Decision Support Systems", "authors": "Alessandro Gambetti,Qiwei Han,Hong Shen,Claudia Soares", "background": "可解释的人工智能(XAI)对于临床决策支持系统(CDSS)的透明度和临床应用至关重要。然而，现有XAI方法的实际效果仍然有限，且评估不一致。", "innovation": "本研究采用PRISMA指南系统地调查了31项关于XAI应用于CDSS的人本评价（HCE），按XAI方法、评估设计和采纳障碍进行分类。研究结果表明，大多数研究采用事后、模型无关的方法，如SHAP和Grad-CAM，通常通过小型临床研究来评估。此外，提出了一种以利益相关者为中心的评估框架，将社会技术原则和人机交互整合，以指导未来开发可行且可信的基于XAI的CDSS。", "conclusion": "研究表明，说明性解释一般能提高临床医生的信任和诊断信心，但由于观点不一致，有时也会增加认知负担并偏离领域推理过程。为解决这些问题，提出了一个利益相关者为中心的评价框架，以社会技术原则和人机交互为导向，指导未来开发可行且可信的基于XAI的CDSS。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01386", "html_url": "https://arxiv.org/abs/2505.01386", "title": "CATransformers: 通过联合模型-硬件优化实现碳意识Transformer", "title_en": "CATransformers: Carbon Aware Transformers Through Joint Model-Hardware Optimization", "authors": "Irene Wang,Newsha Ardalani,Mostafa Elhoushi,Daniel Jiang,Samuel Hsia,Ekin Sumbul,Divya Mahajan,Carole-Jean Wu,Bilge Acun", "background": "机器学习解决方案被快速采用，支持各种关键用例，包括对话式AI助手和科学发现。随着这种采用的增长，预计将增加相关生命周期的碳足迹，包括训练和推理的运行碳排放以及AI硬件制造的嵌入碳排放。现有的优化方法主要侧重于延迟或能效，而没有将碳足迹纳入考虑范围。", "innovation": "提出了第一个考虑运行碳和嵌入碳的联合优化框架（\textbackslash ourframework）。该框架将碳足迹整合到早期设计空间探索中，实现了基于可持续性的模型架构和硬件加速器协同设计，揭示了不同于延迟和能效方法的根本性差异。", "conclusion": "该框架在多种Transformer模型中评估，显示出减少总碳排放（最多30％）的潜力，同时保持准确性和延迟。通过多模态模型的案例研究还展示了其扩展性。结果强调需要优先考虑碳效率的整体优化方法，而不牺牲模型能力和执行时间性能。框架的源代码可在{\tiny\texttt{this https URL}}获取。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11570", "html_url": "https://arxiv.org/abs/2505.11570", "title": "辅助工具进化大语言模型用于无线联邦学习中高效资源管理的生成策略", "title_en": "Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning", "authors": "Chongyang Tan,Ruoqi Wen,Rongpeng Li,Zhifeng Zhao,Ekram Hossain,Honggang Zhang", "background": "联邦学习（FL）允许分布式边缘设备在隐私保护的环境下进行模型训练。但是，其效率高度依赖于在动态和异构无线环境中进行有效的设备选择和高维资源分配。传统方法需要特定领域知识、广泛的超参数调优或大量的互动成本。", "innovation": "本文提出了一种Tool-aided Evolutionary Large Language Model（T-ELLM）框架，用于生成适用于无线FL环境中的设备选择策略。与传统的优化方法不同，T-ELLM利用基于自然语言的场景提示来增强在不同网络条件下的泛化能力。框架数学上解耦了联合优化问题，允许策略学习的可处理性，同时将资源分配委派给凸优化工具。为了增强适应性，T-ELLM集成了一种样本高效的基于模型的虚拟学习环境，捕捉设备选择与学习性能之间的关系，促进后续分组相对策略优化。这一体系方法减少了对实际互动的依赖性，减少了通信开销，同时保持了高质量的决策。", "conclusion": "理论分析表明，虚拟和现实环境之间的差异是有限的，确保了在虚拟环境中学习的优势函数在现实世界条件下具有有保证的小偏离。实验结果证明，T-ELLM在能源效率方面优于基准方法，并且在环境变化面前表现出高度的适应性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.02181", "html_url": "https://arxiv.org/abs/2412.02181", "title": "将Weisfeiler-Lehman核扩展到子图", "title_en": "Generalizing Weisfeiler-Lehman Kernels to Subgraphs", "authors": "Dongkwan Kim,Alice Oh", "background": "子图表示学习在解决各种实际问题中非常有效。然而，当前的图神经网络（GNNs）在子图级别任务上表现不佳，因为它们无法捕捉子图内部和之间复杂的关系。需要一种更具有表现力和效率的替代方案，以改善目前的不足之处。", "innovation": "本文提出了一种名为WLKS的方法，该方法通过在诱导的$k$-跳邻域上应用Weisfeiler-Lehman（WL）算法来推广WL核，从而将不同$k$-跳层次的核结合起来，捕获现有模型中未能完全编码的更丰富结构信息。该方法通过消除对邻域采样的需求，能够在保持表达性和效率之间进行平衡。相比最先进的方法，WLKS在五个数据集上表现出色，同时减少了训练时间，范围从0.01倍到0.25倍。", "conclusion": "实验结果显示，WLKS在八个真实和合成基准测试中显著优于现有领先方法，同时降低了训练时间。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10646", "html_url": "https://arxiv.org/abs/2505.10646", "title": "通过并行可微模拟加速视觉策略学习", "title_en": "Accelerating Visual-Policy Learning through Parallel Differentiable Simulation", "authors": "Haoxiang You,Yilang Liu,Ian Abraham", "background": "论文背景在于现有的视觉策略学习方法通常依赖于高效的差分渲染，这在计算和内存效率方面带来了难题。现有的方法可能需要专有的可微渲染软件，增加了实施的复杂性和成本。因此，研究一种可以与现有可微模拟生态系统无缝集成，同时减少计算和内存开销的解决方案是有必要的。", "innovation": "本文提出了一种基于差分模拟和一阶分析策略梯度的高效视觉策略学习算法。该方法将渲染过程与计算图解耦，消除了对专门可微渲染软件的需求，从而降低了计算和内存开销，并有效地降低了策略梯度的范数，使优化更加稳定和平滑。在现代GPU加速模拟的基础上，进行了标准视觉控制基准测试，实验结果显示该方法显著减少了训练时间，并在最终回报方面明显优于所有基线方法，特别是在复杂的动作项目如人形机器人的腿动中，回报提高了4倍，且在单个GPU上仅4小时内成功学习到人形跑步策略。", "conclusion": "本文提出的方法在视觉策略学习中显著提高了计算效率，通过并行可微模拟技术有效降低了计算时间和提升了优化性能，在复杂的任务上也展现出了优越的表现。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14321", "html_url": "https://arxiv.org/abs/2503.14321", "title": "COPA: 多目标模型评估中不可比较对象的比较", "title_en": "COPA: Comparing the incomparable in multi-objective model evaluation", "authors": "Adrián Javaloy,Antonio Vergari,Isabel Valera", "background": "在机器学习中，我们经常需要从上百种训练好的模型中选择一个，基于准确度、鲁棒性、公平性或可扩展性等不同目标。然而，这些目标通常是不可比较且无法直接合并的，这使得选择模型的过程既费时又需要专业知识。例如，不同目标的功能单位和尺度可能不同，使得直接比较和合并变得困难。因此，提高模型选择过程的效率和准确性是机器学习领域的一个重要问题。", "innovation": "COPA是一个自动化方法，它通过使用累积函数和相对排名将不可比较的目标变得可比，从而可以系统地帮助用户在帕累托前沿中导航和搜索模型。COPA能够根据用户的具体偏好整合这些目标，使实践者能够有意义地探索帕累托前沿。该方法的有效性已经在公平机器学习、领域泛化、自动机器学习和基础模型等多个不同领域进行的模型选择和基准测试任务中得到了验证。传统的方法在这些领域中并不总是有效。", "conclusion": "COPA能够在多目标模型评估中自动化地归一化和整合不可比较的目标，从而能够实现用户特定的偏好匹配和有意义的模型搜索，具有重要的实际应用价值，特别是在存在多个不可比较目标的情况下。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.06268", "html_url": "https://arxiv.org/abs/2501.06268", "title": "基于最近邻距离的Cluster Catch Digraph", "title_en": "Cluster Catch Digraphs with the Nearest Neighbor Distance", "authors": "Rui Shi,Elvan Ceyhan,Nedret Billor", "background": "本文介绍了一种基于Cluster Catch Digraphs (CCDs)的新聚类方法。该方法旨在解决RK-CCDs的不足，通过使用最近邻距离（NND）而非RK-CCDs使用的Ripley's K函数作为新的空间随机性测试的一部分，来改进现有的CCDs方法。研究者还通过蒙特卡洛模拟对方法进行综合性能评估，考虑了数据维度、数据集大小、聚类数量、聚类体积和聚类间距离等多种因素。实验结果表明，本文提出的方法特别适用于高维数据集，并且在多个指标上能够达到或超过依赖于KS类型统计量或Ripley's K函数的KS-CCDs和RK-CCDs的表现。此外，通过实际和复杂数据集的测试，新的方法体现出良好的性能，生成了高质量的聚类，具有理想的特性。", "innovation": "本文提出的方法引入了一种新颖的空间随机性测试方法，使用最近邻距离（NND）而非传统的Ripley's K函数，来构建Cluster Catch Digraphs（CCDs）。这种方法特别适用于高维数据集，并在多项性能指标上优于现有的基于KS类型统计量或Ripley's K函数的方法，展示了在实际和复杂数据集上的强大效能和竞争力", "conclusion": "本文提出的新方法在高维数据集上的聚类性能达到了或超过了现有的方法，表现出显著的优势。通过实验评估，新的基于最近邻距离的Cluster Catch Digraphs方法生成了高质量的聚类，并展示了较强的竞争能力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13697", "html_url": "https://arxiv.org/abs/2505.13697", "title": "只是名称中的RL吗？分析RL后训练在LLMs中的结构假设", "title_en": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs", "authors": "Soumya Rani Samineni,Durgesh Kalwar,Karthik Valmeekam,Kaya Stechly,Subbarao Kambhampati", "background": "最近，基于强化学习的后训练方法受到了广泛关注，特别是在大型语言模型（LLMs）领域。DeepSeek R1 的实现使用了 GRPO（一个强化学习优化器）进行微调，推动了对改进推理能力的研究。然而，作者指出，尽管有许多相关研究，学术界对这些方法的假设和形式化基础并没有进行深入批判性的评估。因此，作者从两个关键假设出发，即（1）将状态简化为动作的简单拼接，（2）均匀分配轨迹的奖励，从而简化了LLMs微调中的MDP（马尔可夫决策过程）。他们的分析表明，在这些简化假设下，这种方法实际上等同于一种结果导向的监督学习方法。通过在GSM8K和Countdown等基准测试中使用Qwen-2.5微调模型，实验证明了迭代监督微调的有效性，它结合了正样本和负样本，其效果可与基于GRPO的方法相媲美。", "innovation": "作者反驳了关于强化学习在大型语言模型后训练中假设的有效性，指出这些假设简化导致的方法实际上等同于结果导向的监督学习。更重要的是，他们指出了一个潜在的激励效应，即RL在生成更长的中间令牌序列中起作用，这被广泛认为是“强化学习生成了更长的思考轨迹”。文中提到，尽管简化假设导致了目前主流的大规模语言模型强化学习框架缺乏实质性的改进效果，但RL在提高大型语言模型推理能力方面仍然可能是有用的。", "conclusion": "简而言之，简化的方法和假设可能使得许多当前使用强化学习进行后训练的语言模型改进效果有限。作者的分析表明，现有的RL后训练框架的有效性值得怀疑，而实际效果可能更为普通。这一结论提出了挑战当前研究趋势的可能性，并对强化学习在后训练中的应用提出了质疑。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05381", "html_url": "https://arxiv.org/abs/2505.05381", "title": "从稀疏观测实现高分辨率概率性海岸洪水预测", "title_en": "Towards High Resolution Probabilistic Coastal Inundation Forecasting from Sparse Observations", "authors": "Kazi Ashik Islam,Zakaria Mehrab,Mahantesh Halappanavar,Henning Mortveit,Sridhar Katragadda,Jon Derek Loftis,Stefan Hoops,Madhav Marathe", "background": "沿海洪水对全球社区构成越来越大的威胁，要求精确和高度局部的淹没预测以实现有效的应急响应。然而，由于预算限制，实际部署预测系统往往受到稀疏传感器网络的限制，只有少数地点可能有传感器。本文探讨了基于稀疏传感器观测进行概率性海岸洪水预测的方法和挑战。", "innovation": "我们提出了一个名为DIFF-SPARSE的掩码条件扩散模型，用于从稀疏传感器观测值进行概率性海岸洪水预测。该模型利用了位置及其邻近位置的历史淹没情况，并引入了新颖的训练时期的掩码策略来解决基于稀疏观测的时空预测中的基础挑战。此外，模型使用卷积神经网络和条件UNet架构配以交叉注意力机制来捕捉数据中的时空动态，并使用数字高程数据和时间协变量作为额外的时空上下文。", "conclusion": "在弗吉尼亚州东海岸的海岸洪水数据上训练和测试DIFF-SPARSE后，结果表明，该模型在95%的稀疏性水平下的两个预测性能指标上比现有方法提高了62%。进一步的消融研究还表明，在高稀疏水平下，数字高程数据比时间协变量更具用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14336", "html_url": "https://arxiv.org/abs/2508.14336", "title": "NeRC: 通过可微分移动窗口定位估计的神经测距校正", "title_en": "NeRC: Neural Ranging Correction through Differentiable Moving Horizon Location Estimation", "authors": "Xu Weng,K.V. Ling,Haochen Liu,Bingheng Wang,Kun Cao", "background": "在城市环境中，使用普通移动设备进行GNSS定位具有挑战性，因为卫星信号传播的复杂性和设备内GNSS硬件的低质量会导致测距误差，从而影响定位精度。研究人员希望利用数据驱动的方法从原始测量中回归这些测距误差，但由于标注测距误差工作繁重，阻碍了这一进程。", "innovation": "本文提出了一种端到端的神经测距校正（NeRC）框架，其中定位相关的指标作为训练神经模块的任务目标。本文还提出了一种新的训练范式，使用欧几里得距离场成本图（EDF成本图），以减少对标注位置的需求；并通过差异化移动窗口定位估计（MHE）处理测量数据并反向传播梯度进行训练。", "conclusion": "本文在公共基准和收集的数据集上评估了提出的NeRC，展示了其在提升定位精度方面的显著改进，并在边缘部署NeRC验证了其在移动设备上的实时性能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03768", "html_url": "https://arxiv.org/abs/2508.03768", "title": "ORVIT: 接近最优的在线分布式鲁棒强化学习", "title_en": "ORVIT: Near-Optimal Online Distributionally Robust Reinforcement Learning", "authors": "Debamita Ghosh,George K. Atia,Yue Wang", "background": "在训练和部署条件存在分布差异的情况下，基于模拟器训练的策略在实践中往往表现不佳。因此，对于现实世界的性能保证至关重要。现有的分布鲁棒强化学习方法通过在不确定性环境集合上优化最坏情况的性能来解决这一问题，并提供了部署性能的优化下界。然而，现有研究通常假设可以访问生成模型或全面覆盖潜在环境的离线数据集，这些假设限制了在缺乏先验知识的未知环境中应用的实用性。因此，本研究专注于更为实际和具有挑战性的在线分布鲁棒学习环境，其中智能体仅与单一未知训练环境交互，同时寻找对围绕此名义模型的不确定性集合鲁棒的策略。", "innovation": "研究提出了一个计算高效且在最小假设下能够实现鲁棒控制目标的次线性遗憾度的算法，即ORVIT（Online Robust Verification and Iterative Training）。该算法适用于没有任何生成模型或离线数据集访问的情况下。此外，该研究还建立了任何在线算法的对应最小最大遗憾下界，证明了该方法的接近最优性。实验表明，ORVIT方法在多样化环境下的性能能够改善最坏情况下的表现，并与理论保证一致。", "conclusion": "ORVIT方法通过优化鲁棒控制目标，在在线分布鲁棒强化学习中实现了接近最优的结果，即使是在训练环境和实际应用环境有分布差异的情况下。该研究为在未知且复杂的环境条件下实现稳定和可靠的智能体控制提供了一种新的有效方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08746", "html_url": "https://arxiv.org/abs/2508.08746", "title": "通过稀疏自编码器实现可解释的奖励模型", "title_en": "Interpretable Reward Model via Sparse Autoencoder", "authors": "Shuyi Zhang,Wei Shi,Sihang Li,Jiayi Liao,Tao Liang,Hengxing Cai,Xiang Wang", "background": "大型语言模型（LLMs）已广泛应用于众多领域。强化学习从人类反馈（RLHF）通过使用奖励模型（RMs）作为人类偏好的代理，来使LLM的行为与人类价值观保持一致，这使得RMs的准确性和可解释性成为有效对齐的关键因素。然而，传统RMs缺乏可解释性，对奖励分配背后的原因提供有限的洞察，并且对于用户偏好的变化缺乏灵活性。尽管最近的多维RMs旨在提高可解释性，但它们通常无法在特征级别上提供归因，并且需要昂贵的注释。", "innovation": "我们提出了一种新型架构Sparse Autoencoder-enhanced Reward Model (SARM)，它将预训练的稀疏自编码器（SAE）整合到奖励模型中。SARM将基于LLM的RM的隐藏激活映射到一个可解释的、稀疏的和单义的特征空间，在其中的标量头聚合特征激活以产生透明且概念上有意义的奖励评分。实证评估表明，SARM能够直接进行奖励分配的特征级别归因，允许动态调整偏好变化，并在与传统奖励模型相比时实现了更优的对齐性能。", "conclusion": "通过将预训练的稀疏自编码器整合到奖励模型中，SARM成功地提高了奖励模型的可解释性和灵活性，使其能够动态调整偏好变化，并实现了优于传统奖励模型的对齐性能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14004", "html_url": "https://arxiv.org/abs/2508.14004", "title": "GDNSQ：用于低比特神经网络的渐进可微噪声尺度量化", "title_en": "GDNSQ: Gradual Differentiable Noise Scale Quantization for Low-bit Neural Networks", "authors": "Sergey Salishev,Ian Akhremchik", "background": "量化神经网络可以被视为一系列噪声信道的链，每层的舍入操作会随着比特宽度减小而减少容量；浮点数（FP）检查点设置最大输入速率。我们跟踪平均比特宽度减少时的容量动态，并通过将微调视为平滑的约束优化问题来识别由此产生的量化瓶颈。我们的方法采用全可微效估量梯度-通过中间-esimator（STE）并带有可学习的比特宽度、噪声尺度和限制约束，通过外部点惩罚强制目标比特宽度，轻微的度量平滑（通过蒸馏）来稳定训练。尽管方法简单，但在极端W1A1设置下仍能达到竞争力的准确度，同时保留STE的效率。", "innovation": "通过将微调任务建模为一个平滑的、受约束的优化问题，引入了渐进可微噪声尺度量化（GDNSQ）方法；这种方法使用了一个全可微的STE，带有可学习的比特宽度、噪声尺度和限制边界，并通过外部点惩罚强制它们达到目标比特宽度；同时，通过度量平滑稳定训练过程；即使在极端的W1A1设置下，此方法也能保持与SE方法相媲美的准确度，同时具有STE的效率性.", "conclusion": "尽管GDNSQ方法在结构上非常简单，但在极端低比特设置下仍能取得与传统量化方法相当的性能，并且在效率上具有优势。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05164", "html_url": "https://arxiv.org/abs/2508.05164", "title": "S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection", "title_en": "S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection", "authors": "Jiaqi Wang,Zhengyu Ma,Xiongri Shen,Chenlin Zhou,Leilei Zhao,Han Zhang,Yi Zhong,Siqi Cai,Zhenxi Song,Zhiguo Zhang", "background": "听觉注意力检测（AAD）旨在从脑电图（EEG）记录中解码听者在复杂听觉环境中的聚焦，这对于开发神经控制的助听设备至关重要。尽管最近取得了进展，但基于EEG的AAD仍受限于缺乏能够充分利用在能源效率限制下的互补EEG特征的协同框架。目前现有的架构在处理这类问题时仍存在能效低下和参数冗余的问题，从而阻碍了AAD技术的发展和实际应用。", "innovation": "提出了一种新的突触对称混合框架S$^2$M-Former，通过两个关键创新来解决上述问题：i) 提出了一种基于突触驱动的对称架构，该架构由平行的空间和频带分支组成，采用镜像模块设计，利用生物可能的标记-通道混合器增强分支之间的互补学习；ii) 引入了轻量级的一维标记序列来替代传统的三维操作，参数减少了14.7倍。该架构灵感来自于大脑进一步降低了功耗，相较于最新的人工神经网络方法，实现了5.8倍的能量降低，同时在参数效率和性能方面超过了现有的SNN基线。", "conclusion": "在三个AAD基准（KUL、DTU和AV-GC-AAD）的三个设置（单试次内、跨试次和跨受试者）下的全面实验中，S$^2$M-Former实现了与最新技术水平相当的解码准确性，成为一种具有低功耗和高性能的AAD任务解决方案。代码可在这个链接中获取。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05429", "html_url": "https://arxiv.org/abs/2509.05429", "title": "保护图神经网络免受拓扑推理攻击", "title_en": "Safeguarding Graph Neural Networks against Topology Inference Attacks", "authors": "Jie Fu,Yuan Hong,Zhili Chen,Wendy Hui Wang", "background": "图神经网络（GNNs）作为强大的模型，用于从图结构数据中学习。但是，其广泛使用引发了严重的隐私问题。尽管先前的研究主要关注边缘级别的隐私保护，拓扑隐私（即图的整体结构的保密性）却是一个关键但尚未充分探索的威胁。这项工作中，作者对GNN中的拓扑隐私风险进行了全面研究，揭示了这些模型对图级推理攻击的脆弱性。我们的研究结果表明，GNNs极易受到此类攻击，现有的边缘级差分隐私机制并不足够，它们要么不能缓解风险，要么严重影响模型的准确性。", "innovation": "我们提出了一整套拓扑推理攻击（TIAs），这些攻击可以在仅获得GNN模型的黑盒访问的情况下，重建目标训练图的结构。此外，我们提出了保护拓扑隐私的同时保持模型准确性的新防御框架Private Graph Reconstruction (PGR)。PGR被表述为一个双层优化问题，通过使用元梯度逐迭代生成合成训练图，并根据不断变化的图更新GNN模型。广泛的实验表明，PGR在最小影响模型准确性的情况下显著减少了拓扑泄露。", "conclusion": "PGR有效减少拓扑泄露且对模型精度影响较小。我们的代码可以在该网址找到 https://github.com/your-repo-url."}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05117", "html_url": "https://arxiv.org/abs/2509.05117", "title": "HyPINO: 多物理神经算子通过超PINN和制造解法", "title_en": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions", "authors": "Rafael Bischof,Michal Piovarči,Michael A. Kraus,Siddhartha Mishra,Bernd Bickel", "background": "本文介绍了一种名为HyPINO的多物理神经算子，该算子旨在不依赖特定任务的微调的情况下，广泛应用于PDE（偏微分方程）的零样本推广。HyPINO采用了一种结合Swin Transformer的超网络与混合监督的方法，包括使用制造解法（MMS）生成的标注数据以及物理感知目标优化的未标注样本。该模型可以处理具有变化源项、几何形状和混合狄利克雷/耐默边界条件（包括内部边界）的二维线性椭圆型、双曲型和抛物型方程。通过将其参数映射到目标物理感知神经网络（PINN），HyPINO展示了在七个基准问题上的强大零样本准确性，优于U-Nets、Poseidon和物理感知神经算子（PINO）等方法。这种方法的核心思想是通过将生成的PINN的残差视为“增量PDE”进行迭代修正，以减少误差。该模型的改进反映在多个基准上的更高精度和更低的$L_2$损失，同时也保持了前向推理的高效性。此外，对于通过HyPINO初始化的PINNs，研究表明它们在五个基准问题上比随机初始化和Reptile元学习的PINNs更快收敛并达到更低的最终误差，在其余两个基准问题上，表现相当。这表明该模型具有扩展为解决更复杂、非线性和高维PDE问题的基础潜力。代码和模型权重已公开提供。", "innovation": "该方法的创新点在于：(1) 采用Swin Transformer为基础的超网络结构；(2) 结合制造解法生成的标注数据和物理感知目标优化的未标注样本的混合监督方式；(3) 通过将生成的PINN的残差视为“增量PDE”进行迭代修正，形成多个模型的集合以逐渐降低误差；(4) 在五个基准问题上，HyPINO初始化的PINNs比随机初始化和元学习的PINNs更快且误差更小，展示了其在多个复杂问题上的优越性；(5) 初步验证了该方法在解决更复杂PDE问题上的潜力。", "conclusion": "研究强调了该方法作为基础框架的一种潜在价值，能够促进神经算子解决更复杂、非线性和高维PDE问题的发展。未来，可以通过进一步优化和扩展此种方法，以应对更加复杂的物理现象和更广泛的PDE问题。此外，该方法的公开代码为后续研究提供了便利，增强了其在实际应用中的可推广性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21190", "html_url": "https://arxiv.org/abs/2509.21190", "title": "零-shot时间序列异常检测的基础模型：利用合成数据和相对上下文差异", "title_en": "Towards Foundation Models for Zero-Shot Time Series Anomaly Detection: Leveraging Synthetic Data and Relative Context Discrepancy", "authors": "Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang", "background": "时间序列异常检测(TSAD)是一项关键任务，但在无监督场景下开发能够泛化到未见数据的模型仍是一个重大挑战。现有基础模型主要采用基于重建的目标，但它们存在根本性目标匹配问题：难以识别细微的异常情况，同时往往会误解复杂的正常模式，导致高水平的误报和漏报。", "innovation": "本文引入了TimeRCD，这是一种新型的基础模型，基于一种新的预训练范式：相对上下文差异(RCD)。TimeRCD侧重于检测相邻时间窗口之间显著的差异，而非学习重建输入。这种方法使用标准的Transformer架构，能捕捉重建方法常忽视的异常前兆。为了实现这一范式，作者开发了一个大规模的多样化合成数据集，附带标记的令牌级异常标签，为有效的预训练提供了丰富的监督信号。实验表明，TimeRCD在零样本TSAD任务中显著优于现有的通用和专门针对异常的基础模型，特别是在多种数据集上表现突出。", "conclusion": "实验结果验证了RCD范式的优越性，并为构建适用于时间序列异常检测的鲁棒且可泛化的基础模型开辟了一条新途径。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13192", "html_url": "https://arxiv.org/abs/2509.13192", "title": "TRUST-FS: 张量化的可靠无监督多视图特征选择方法用于不完整数据", "title_en": "TRUST-FS: Tensorized Reliable Unsupervised Multi-View Feature Selection for Incomplete Data", "authors": "Minghui Lu,Yanyong Huang,Minbo Ma,Jinyuan Chang,Dongjie Wang,Xiuwen Yi,Tianrui Li", "background": "多视图无标注数据中选择有价值特征的多视图无监督特征选择（MUFS）近年来引起了研究兴趣。现有的方法在处理不完整数据时存在诸多挑战，包括难以处理缺失变量的情况，以及分离处理缺失值填充和特征选择而忽略两者间的交互作用，导致不够准确的相似图，影响特征选择的效果。", "innovation": "提出了一个新的针对不完整数据中缺失变量的MUFS方法，称为Tensorized Reliable UnSupervised mulTi-view Feature Selection（TRUST-FS）。该方法引入了一种新的自适应加权CP分解，能在统一的张量分解框架中同时执行特征选择、缺失变量填充和视图权重学习。通过使用主观逻辑来获取可靠的跨视图相似信息，进而学习可靠相似图，指导特征选择与填充。实验结果表明该方法在现有方法中的有效性和优越性。", "conclusion": "TRUST-FS 在处理多视图不完整数据中表现出了有效性，并且相比现有方法，具有更高的鲁棒性和准确性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19465", "html_url": "https://arxiv.org/abs/2509.19465", "title": "跨频率转移学习和基础预测模型的现实评估", "title_en": "A Realistic Evaluation of Cross-Frequency Transfer Learning and Foundation Forecasting Models", "authors": "Kin G. Olivares,Malcolm Wolff,Tatiana Konstantinova,Shankar Ramasubramanian,Boris Oreshkin,Andrew Gordon Wilson,Andres Potapczynski,Willa Potosnak,Michael W. Mahoney,Mengfei Cao,Dmitry Efimov", "background": "跨频率转移学习（CFTL）已成为一种基于大规模时间序列数据集预训练基础预测模型（FFMs）的流行框架。尽管CFTL显示出潜力，但当前的基准测试方法未能准确评估其性能。当前的基准测试方法存在多个问题，包括过度依赖小规模评估数据集；在计算汇总统计时处理样本大小不足；报告次优统计模型；以及未能考虑到预训练数据集和测试数据集之间的非忽略重叠风险。", "innovation": "本文引入了对广泛采用的神经预测网络的一致重新实现，将它们适应CFTL设置；仅在内部和合成数据上进行预训练，以防止测试泄漏；对15个大型多样的公共预测比赛数据集进行评估。实证分析表明统计模型的准确性经常被低估。确认统计模型及其集成连续在多个数据集中比现有FFMs高8.2%以上在sCRPS和20%以上在MASE。", "conclusion": "合成数据集预训练可以提高FFM的准确性，提高7%。该研究强调了对CFTL进行全面且准确的评估的重要性，同时也突显了统计模型在预测中的优越性能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15810", "html_url": "https://arxiv.org/abs/2509.15810", "title": "通过隐空间逆向工程生成元黑盒优化实例", "title_en": "Instance Generation for Meta-Black-Box Optimization through Latent Space Reverse Engineering", "authors": "Chen Wang,Yue-Jiao Gong,Zhiguang Cao,Zeyuan Ma", "background": "当前，为了减轻设计优化算法所需的高度依赖人类专家的问题，元-黑盒优化（MetaBBO）研究利用元学习的一般化能力训练基于神经网络的算法设计策略，这些训练是基于预定义的基准问题集进行的，从而自动化低级优化器在未见过的问题实例上的适应性。目前大多数MetaBBOs选择使用CoCo-BBO作为训练集，尽管这有利于MetaBBOs的发展，但CoCo-BBO中的问题实例在多样性方面有限，这可能会导致MetaBBOs过拟合，进而影响其泛化性能。", "innovation": "本文提出了一种名为LSRE的实例生成方法，旨在为MetaBBO生成具有足够多样性的训练问题实例，提高学习到的策略的泛化能力。LSRE首先训练一个自编码器，将高维问题特征映射到二维隐空间。然后，通过在该隐空间中均匀网格抽样，产生具有足够多样性的问题实例。LSRE还利用遗传编程方法搜索与这些隐藏表示具有最小L2距离的函数公式，从而逆向工程生成了多样化基准集Diverse-BBO。并通过训练不同MetaBBOs并评估其在各种合成或现实场景上的泛化性能来验证LSRE的有效性。", "conclusion": "详细实验结果表明，Diverse-BBO在MetaBBOs中的优越性超过了现有的训练集选择。进一步的消融研究不仅证明了LSRE设计选择的有效性，还揭示了实例多样性与MetaBBO泛化性能之间的有趣洞察。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21606", "html_url": "https://arxiv.org/abs/2509.21606", "title": "通过无回放梯度投影实现无任务学习的分布式持续学习", "title_en": "Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection", "authors": "Seohyeon Cha,Huancheng Chen,Haris Vikalo", "background": "持续学习（CL）能够从随时间演化的多样任务中获取数据，而在分布式客户端设备上进行的联邦持续学习（FCL）则面临着分布式设置中的数据异构性、通信限制以及隐私问题等挑战，其中灾难性遗忘（catastrophic forgetting）尤其突出。", "innovation": "提出了一种新颖的联邦梯度投影持续学习框架FedProTIP，通过将客户端更新投影到全球模型先前学习表示的子空间的正交补空间上，从而减轻了遗忘问题。此外，引入了轻量级机制来预测任务身份，并动态调整全球模型输出，以解决任务无关推理的挑战。", "conclusion": "FedProTIP在标准FCL基准上的广泛实验中表现出了显著的优越性，尤其是在任务身份事先未知的情况下，平均准确率高于现有方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09866", "html_url": "https://arxiv.org/abs/2508.09866", "title": "FedShard: 基于效率公平性和性能公平性的联邦卸载", "title_en": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness", "authors": "Siyuan Wen,Meng Zhang,Yang Yang,Ningning Ding", "background": "在联邦学习中，联邦卸载旨在从全局学习模型中移除离开客户的贡献数据。尽管现有研究主要集中在提升卸载效率和效果，但去中心化客户在卸载过程中的效率公平性和性能公平性问题仍然未被充分探索。", "innovation": "引入了FedShard，这是首个能够同时保证效率公平性和性能公平性的联邦卸载算法。FedShard能够自适应地解决收敛性、卸载效率与卸载公平性之间的挑战，并提出了两个新的公平性度量指标，证明其在其他现有公平性度量准则下具有良好的属性。理论分析和数值评估验证了FedShard在卸载性能和效率方面的公平性。FedShard能够减轻诸如级联离开和恶意污染等不公平风险，更均衡地分配卸载成本给各客户。实验结果显示，与从头开始重新训练相比，FedShard可加速5.9倍的数据卸载过程；与最先进的精确卸载方法相比，加速效果更为显著，提升了约4.9倍。", "conclusion": "FedShard算法验证了在卸载过程中兼顾效率公平性和性能公平性的可行性，并在实验中展示了加速卸载过程和减少不同客户间不公平现象的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10982", "html_url": "https://arxiv.org/abs/2506.10982", "title": "重新考虑扩散桥梁采样器的损失函数", "title_en": "Rethinking Losses for Diffusion Bridge Samplers", "authors": "Sebastian Sanokowski,Lukas Gruber,Christoph Bartmann,Sepp Hochreiter,Sebastian Lehner", "background": "扩散桥梁是一种有前途的深度学习方法，用于从归一化分布在内进行采样。近期研究表明，当使用重参数化技巧计算rKL梯度时，对数方差（LV）损失一贯地优于反向Kullback-Leibler（rKL）损失。虽然在扩散采样器带有未学习前向过程结合重参数化技巧时，对数差分技巧下的LV损失与rKL损失产生相同的梯度，这种等同性在扩散桥梁或扩散系数可学习的情况下并不成立。基于这一观察，作者认为对于扩散桥梁，LV损失无法像rKL损失那样通过数据处理不等式获得动机作为优化目标。", "innovation": "作者提出，对于扩散桥梁，LV损失不是可以通过数据处理不平等方式动机的优化目标。鉴于此，建议使用rKL损失与重参数化技巧（rKL-LD），不仅解决了这些概念上的问题，还一致地优于LV损失。实验结果表明，使用rKL-LD损失训练的采样器在不同类型的扩散桥梁和具有挑战性的基准中表现更好。从实际操作角度来看，rKL-LD需要更少的超参数优化，并且具有更稳定的训练行为。", "conclusion": "实验结果表明，使用rKL-LD损失训练的采样器在不同类型的扩散桥梁和具有挑战性的基准中表现更好。从实际操作角度来看，rKL-LD需要更少的超参数优化，并且具有更稳定的训练行为。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24047", "html_url": "https://arxiv.org/abs/2509.24047", "title": "在多智能体强化学习中的乐观求险", "title_en": "Optimism as Risk-Seeking in Multi-Agent Reinforcement Learning", "authors": "Runyu Zhang,Na Li,Asuman Ozdaglar,Jeff Shamma,Gioele Zardini", "background": "在强化学习（RL）中，风险敏感性已成为一个核心话题。凸风险测度和稳健性公式为建模期望回报之外的偏好提供了原理性的方法。最近，多智能体强化学习（MARL）的扩展主要关注规避风险的稳健性设置。然而，在合作型MARL中，这种保守性往往导致次优均衡，已有研究表明乐观性可以促进合作。尽管现有的乐观方法在实践中很有效，但它们通常是经验性的，缺乏理论依据。基于凸风险测度的双重表示，本文提出了一种原理性的框架，将风险寻求目标解释为乐观性。作者引入了乐观价值函数，使之将乐观性定义为惩罚性风险寻求的评价形式。基于这一基础，他们导出了乐观价值函数的策略梯度定理，包括熵风险/KL惩罚设定的具体公式，并开发了一种去中心化的乐观演员-评论员算法来实施这些更新。实验证明，风险寻求的乐观性在合作基准中总能比风险中性和经验性乐观方法更好地促进协调。", "innovation": "基于凸风险测度的双重表示，本文提出了一种原理性的框架，将风险寻求目标解释为乐观性。作者引入了乐观价值函数，使之将乐观性定义为惩罚性风险寻求的评价形式。基于这一基础，他们导出了乐观价值函数的策略梯度定理，包括熵风险/KL惩罚设定的具体公式，并开发了一种去中心化的乐观演员-评论员算法来实施这些更新。", "conclusion": "本文提出的框架将风险敏感学习与乐观性统一起来，提供了一种既具有理论依据也具有实际有效性的合作MARL方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24378", "html_url": "https://arxiv.org/abs/2509.24378", "title": "AXIS: 大型语言模型实现可解释的时间序列异常检测", "title_en": "AXIS: Explainable Time Series Anomaly Detection with Large Language Models", "authors": "Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang", "background": "时间序列异常检测（TSAD）越来越需要提供不仅说明是否发生了异常，还能解释异常模式及其为何异常的解释。近期的研究尝试利用大型语言模型（LLMs）的解释能力，将时间序列数据视为文本进行TSAD的解释。然而，这种方法面临一个基本挑战：LLMs依赖离散标记，难以直接处理长的、连续的信号，导致简单的时序到文本的序列化方法缺乏上下文关联和模态之间的表征对齐。", "innovation": "本文提出了AXIS框架，该框架通过为冻结的LLM提供条件，使其能进行细腻的时间序列理解。AXIS通过添加三种互补的提示来丰富LLM的输入：（i）一个数值符号提示，用于数值定位；（ii）一个上下文集成、步骤对齐的提示，源自预训练的时间序列编码器，用于捕捉细粒度的动态特征；（iii）一个任务先验提示，用于编码全局异常特征。此外，为了促进解释准确性的稳健评估，本文引入了一个新的基准，包含多种格式的问题和理由，以监督上下文关联和模式级语义。", "conclusion": "广泛实验，包括基于LLM和人工评估，表明AXIS提供了显著更高质量的解释，并在检测准确性上与通用LLM、专门的时间序列LLM及时间序列视觉语言模型实现了竞争性的表现。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15378", "html_url": "https://arxiv.org/abs/2506.15378", "title": "使用扩散变压器采样三维分子构象", "title_en": "Sampling 3D Molecular Conformers with Diffusion Transformers", "authors": "J. Thorben Frank,Winfried Ripken,Gregor Lied,Klaus-Robert Müller,Oliver T. Unke,Stefan Chmiela", "background": "扩散变压器（DiTs）在生成建模任务中表现出强大的性能，特别是在图像合成方面，这使得它们成为分子构象生成的有吸引力的选择。然而，在将DiTs应用到分子上时，会面临新的挑战，包括如何整合离散的分子图信息与连续的三维几何信息，处理欧几里得对称性，以及设计能够跨不同大小和结构的分子进行泛化的条件机制。现有的方法难以同时很好地应对这些挑战。因此，研究一个能够跨越不同大小和结构的分子，同时有效地整合三维结构信息和离散分子图信息，以提升生成分子构象质量的框架显得尤为必要。", "innovation": "本文提出了一种名为DiTMC的框架，旨在通过一种模块化架构解决上述挑战。DiTMC的一个创新之处是它将3D坐标处理与基于原子连接性的条件处理分离。同时，提出两种图为基础的条件策略无缝与DiT架构集成，并结合不同的注意力机制（包括非等变的标准机制与SO(3)-等变的形式），使模型能够在精度和计算效率之间取得灵活的平衡。通过在标准集GEOM-QM9、-DRUGS、-XL上的实验结果，DiTMC显示出优异的精确性和物理有效性。本文的结果进一步强调了架构选择和对称先验对样本质量和效率的影响，表明了扩散变压器在大规模分子结构生成中的前景。", "conclusion": "实验结果证明，DiTMC能够实现最先进的精度和物理有效性，表明了这个框架对于生成不同类型复杂度的分子构象具有巨大潜力。此外，研究还给出了对现有技术和未来研究路径的一些建议，鼓励跨不同空间对称性的扩散生成建模进一步探索。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19406", "html_url": "https://arxiv.org/abs/2509.19406", "title": "TimeMosaic：通过自适应粒度片段和段级解码指导时序异质性预测", "title_en": "TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding", "authors": "Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan", "background": "多变量时间序列在金融、交通、气候和能源等领域中至关重要。现有基于片段的时间序列预测方法通常采用固定长度的分割方式，忽略了局部时间动态的异质性和解码预测的异质性。这样的设计会导致在信息密集区域丢失细节，在稳定段引入冗余，并且无法捕捉短期和长期预测的复杂性差异。因此，迫切需要一种能够处理这种时间异质性的预测框架。", "innovation": "TimeMosaic是一种旨在解决时间异质性的预测框架，采用了自适应片段嵌入来动态调整粒度，从而平衡模块重用与结构清晰性，同时保持时间连续性。此外，它引入了基于片段的解码，将每个预测时间尺度视为相关的子任务，能够适应特定时间尺度的难度和信息需求，而不是使用单一的统一解码器。广泛的基准数据集上的评估表明，TimeMosaic相对于现有方法提供了持续的改进，而我们的模型在具有3210亿观测值的大规模语料库上训练后，达到了与最先进的时序框架相当的性能。", "conclusion": "TimeMosaic在处理时间异质性的多变量时间序列预测上实现了显著的性能改进，通过自适应粒度片段处理局部信息密度，并通过段级解码提升解码针对性和效率。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07198", "html_url": "https://arxiv.org/abs/2511.07198", "title": "协同胜过差异：一种多域大型语言模型微调的分区方法", "title_en": "Synergy over Discrepancy: A Partition-Based Approach to Multi-Domain LLM Fine-Tuning", "authors": "Hua Ye,Siyuan Chen,Haoliang Zhang,Weihao Luo,Yanbin Li,Xuan Zhang", "background": "大型语言模型（LLMs）在多个任务上表现出色，但在不同异构领域的有效适配仍面临挑战。这是因为不同领域的相互干扰导致了模型性能的下降。克服这一挑战的方法之一是开发一种分区多阶段微调框架，该框架旨在利用各领域之间的协同作用，同时最小化负面迁移的影响。这种框架通过平衡领域差异、协同作用和模型能力限制来战略性地划分领域。", "innovation": "提出了一种基于分区的多阶段微调框架，该框架通过理论分析新推导的泛化界来支持分区策略，从而有效解决不同领域之间的干扰问题。实证研究表明，该方法在多种语言理解任务中优于最先进的基线方法。", "conclusion": "实验结果表明，该方法在各种语言理解任务中持续优于最先进的基线方法，证明了所提分阶段微调框架的有效性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06973", "html_url": "https://arxiv.org/abs/2511.06973", "title": "Oh That Looks Familiar: 一种新的电子表格模板相似度度量方法", "title_en": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery", "authors": "Anand Krishnakumar,Vengadesh Ravikumaran", "background": "传统方法在识别结构相似的电子表格时无法捕捉到定义模板的布局和类型模式。为了量化电子表格的相似性，本文介绍了一种结合语义嵌入、数据类型信息和空间定位的混合距离度量方法。以往的方法往往在模板家族上的无监督聚类性能不佳，尤其是在FUSTE数据集上表现的不如基于图的Mondrian基准方法，调整雷尔指数仅为0.90。", "innovation": "本文提出了一种新的方法，通过将电子表格转换为单元格级别的嵌入并使用像Chamfer和Hausdorff距离这样的聚合技术来计算相似性。与基于图的Mondrian方法相比，该方法在模板家族上的无监督聚类性能更优，实现了完美的模板恢复（调整后的雷尔指数为1.00）.", "conclusion": "该方法促进了大规模自动化模板发现，进而使得后端应用，如表格集合的检索增强生成、模型训练和批量数据清洁等成为可能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1909.13861", "html_url": "https://arxiv.org/abs/1909.13861", "title": "对抗无后悔学习者的策略", "title_en": "Strategizing against No-regret Learners", "authors": "Yuan Deng,Jon Schneider,Balusubramanian Sivan", "background": "该研究探讨了玩家在重复与无后悔学习者博弈时，如何制定策略以最大化自身的收益。背景假设了一定的博弈场景，其中一方（玩家）需要根据对方（无后悔学习者）的行为调整自己的策略。", "innovation": "创新点在于提出了一种新的方法，即当无后悔学习者采用基于均值的策略时，玩家能获得高于斯塔克尔伯格均衡下的收益。同时，该研究还为玩家在面对均值无后悔策略的对手时的最佳博弈方法提供了一个控制问题的解决方案。", "conclusion": "在无后悔学习者的策略也能保证其不更换后悔的情况下，玩家的收益不会超过斯塔克尔伯格均衡下的收益。但在无后悔学习者有超过两个行动且采用基于均值的策略时，玩家可以达到高于斯塔克尔伯格均衡的收益。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07046", "html_url": "https://arxiv.org/abs/2511.07046", "title": "学习整数硬件的量化连续控制器", "title_en": "Learning Quantized Continuous Controllers for Integer Hardware", "authors": "Fabian Kresse,Christoph H. Lampert", "background": "将连续控制的强化学习策略部署到嵌入式硬件上需要满足严格的时间延迟和功耗要求。小规模的现场可编程门阵列（FPGA）可以达到这些要求，但前提是必须避免使用代价高昂的浮点运算流水线。研究者关注使策略量化感知训练（QAT）适用于整数推断，并提出了一种从学习到硬件的自动工作流程，该流程可以自主选择低比特宽度的策略，并将它们综合到Artix-7 FPGA上。", "innovation": "开发了一个量化感知训练（QAT）策略，可以生成使用尽可能少的比特（如3比特或2比特）的低精度网络，这些网络在五个MuJoCo任务上的表现可以与全精度（FP32）策略相媲美，同时能够在目标硬件上实现微秒级的推断延迟，并消耗微焦耳/动作的功耗，与量化参考相比具有优势。此外，发现这些量化策略在输入噪声鲁棒性方面优于浮点基线。", "conclusion": "研究展示了如何通过量化感知训练生成适用于嵌入式FPGA的低比特宽度的连续控制策略，这些策略不仅在性能上与全精度策略相当，而且在资源和能效上有了显著改善，且对输入噪声具有更高的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06856", "html_url": "https://arxiv.org/abs/2511.06856", "title": "接触 Wasserstein 地线用于非保守 Schrödinger 桥", "title_en": "Contact Wasserstein Geodesics for Non-Conservative Schrödinger Bridges", "authors": "Andrea Testa,Søren Hauberg,Tamim Asfour,Leonel Rozo", "background": "Schrödinger 桥提供了一个为概率分布之间建模随机过程的原则框架；然而，现有方法受限于能量守恒假设，限制了桥的形状，使其无法模拟能量可变的现象。为解决此问题，我们引入了非保守广义 Schrödinger 桥 (NCGSB)，这是一种基于接触哈密顿力学的、允许能量在时间上变化的新颖重构方式。", "innovation": "通过允许能量随时间变化，NCGSB 提供了更广泛的真实世界随机过程类别，捕捉了更丰富、更真实的中间动态。通过参数化 Wasserstein 流形，将桥梁问题提升到一个有限维空间中的可处理测地线计算。此外，我们的接触 Wasserstein 测地线 (CWG) 以 ResNet 架构自然实施，依赖于近线性复杂度的非迭代求解器，并支持根据任务特定的距离度量进行引导生成。", "conclusion": "我们通过在包括流形导航、分子动力学预测和图像生成的任务上验证我们的框架，展示了其实用性和灵活性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06294", "html_url": "https://arxiv.org/abs/2511.06294", "title": "Transolver 是一个线性变换器：通过线性变换视角重访物理注意力", "title_en": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention", "authors": "Wenjie Hu,Sidun Liu,Peng Qiao,Zhenglun Sun,Yong Dou", "background": "近期基于Transformer的神经运算符为数据驱动偏微分方程（PDEs）的求解带来了重要进展。大多数当前研究致力于通过减少注意力的二次复杂度来解决低训练和推理效率的问题。在这些工作中，Transolver 引入了物理注意力 Projection-Attention 以降低计算成本，其中物理注意力将网格点投影到片中进行片内注意力，然后通过去片操作映射回。研究者观察到，物理注意力可以被重新表述为线性注意力的一种特殊情形，并指出片内注意力甚至可能损害模型性能。", "innovation": "基于上述观察，作者认为物理注意力的有效性主要来源于片和去片的操作，而非片间的交互。因此，作者提出了一种两步转换，将物理注意力重新设计为一种典型的线性注意力，命名为线性注意力神经运算符（LinearNO）。与现有方法相比，该方法在六个标准 PDE 基准测试上实现了最先进的性能，平均参数数量减少了40.0%，计算成本减少了36.2%，并在两个具有挑战性的工业级数据集上表现出更好的性能。", "conclusion": "线性注意力神经运算符在保持模型性能的同时，大幅减少了参数数量和计算成本，展示了在偏微分方程求解中的高效性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07127", "html_url": "https://arxiv.org/abs/2511.07127", "title": "REACT-LLM: 一种评估因果特征在临床预后任务中与大语言模型集成的基准", "title_en": "REACT-LLM: A Benchmark for Evaluating LLM Integration with Causal Features in Clinical Prognostic Tasks", "authors": "Linna Wang,Zhixuan You,Qihui Zhang,Jiunan Wen,Ji Shi,Yimin Chen,Yusen Wang,Fanqi Ding,Ziliang Feng,Li Lu", "background": "大型语言模型（LLMs）和因果学习都对临床决策制定（CDM）具有巨大的潜力。然而，它们的协同作用尚未得到充分理解，主要原因是对评估其在临床风险预测中集成的系统基准的缺乏。在实际医疗环境中，识别对结果有因果影响的特征对于产生实际可行和值得信赖的预测至关重要。尽管最近的工作揭示了LLMs在因果推理方面不断增强的能力，但缺乏全面的基准来评估它们的因果学习能力和由因果特征指导的性能。因此，为了填补这一空白，引入了REACT-LLM，这是一种旨在评估结合LLMs和因果特征是否可以增强临床预后性能的基准，有望超越传统机器学习（ML）方法。", "innovation": "REACT-LLM基准评估了7种临床结果在2个实际临床数据集中的表现，对比了15种流行的LLMs、6种传统ML模型和3种因果发现（CD）算法。该基准揭示了虽然LLMs在临床预后方面表现不错，但还未超过传统ML模型的水平。在LLMs中整合从CD算法导出的因果特征提供了有限的性能提升，主要是因为许多CD方法的严格假设往往在复杂的临床数据中被违背。通过对直接集成的有效性进行评估，该基准揭示了进一步探索LLMs与因果特征整合的潜力。", "conclusion": "尽管LLMs在预后任务中的表现合理，但尚未超越传统ML模型。将从CD算法中提取的因果特征直接整合到LLMs中带来的性能提升有限，主要是因为许多CD方法的假设在复杂临床数据中通常不成立。而该基准的研究发现表明了这种集成可能更具潜力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2012.02854", "html_url": "https://arxiv.org/abs/2012.02854", "title": "水文中的物理引导机器学习方法", "title_en": "Physics Guided Machine Learning Methods for Hydrology", "authors": "Ankush Khandelwal,Shaoming Xu,Xiang Li,Xiaowei Jia,Michael Stienbach,Christopher Duffy,John Nieber,Vipin Kumar", "background": "水文中的径流预测是一项关键挑战，由于复杂的非线性物理机制在径流生成中的相互作用。尽管基于物理的模型根植于对物理过程的深刻理解，但在预测性能上仍然存在显著差距。这一差距可能通过运用最近的机器学习进展来解决。传统的机器学习模型使用气象驱动因素作为输入来预测径流，但这些模型没有捕捉到气象驱动因素与径流之间复杂的中间过程。本文旨在将对水文过程和约束的理解融入到机器学习算法中，以提高预测性能。本文通过使用多任务学习框架，明确建模了连接气象驱动因素和径流的中间过程，旨在改善单个流域的预测性能，研究方法适用于多个流域数据应用的机器学习方法的改进。", "innovation": "提出了一种物理引导的机器学习方法，通过多任务学习框架明确建模气象驱动因素和径流之间的中间过程。这种方法在训练时需要关于中间过程的数据，但在测试阶段仅需要气象驱动因素数据。研究在南分支河流河口水文模型生成的仿真数据集上评估了该方法的有效性，证明了通过明确建模中间过程，可以提高径流预测的准确性。", "conclusion": "该研究提出的方法有效提高了基于机器学习的单个流域径流预测性能。虽然本文的重点是单一流域数据，但提出的方法同样适用于使用多个流域数据来提升单个流域模型性能的机器学习方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2206.15177", "html_url": "https://arxiv.org/abs/2206.15177", "title": "零和博弈中交互粒子动力学的大偏差原理用于寻找混合均衡", "title_en": "Large deviations for interacting particle dynamics for finding mixed equilibria in zero-sum games", "authors": "Viktor Nilsson,Pierre Nyquist", "background": "在机器学习中，寻找连续性的MinMax博弈的均衡点已成为一个关键问题，特别是在生成对抗网络和强化学习中的应用。由于均衡点存在的问题和稳定性问题，最近的研究更多地转向了混合均衡点的研究。本文继续了这一研究方向，专门探讨了基于熵正则化在两层零和博弈中寻找混合均衡点的方法，其中两个竞争策略分别通过一组相互作用的粒子来表示。", "innovation": "本文提出了一种基于熵正则化的交互粒子动力学方法来寻找两层零和博弈中的混合均衡点。该方法表明，随着粒子数量趋于无穷大，粒子系统的实验测度满足大偏差原理，并进一步证明了实验测度和相关的Nikaidô-Isoda误差的收敛性，这补充了现有的大量数理论的结果。", "conclusion": "研究发现，当粒子数量趋于无穷大时，粒子系统的实验测度满足大偏差原理，并且相关Nikaidô-Isoda误差的收敛性得到了证明，这一研究补充了现有大量的数理论的结果，为寻找零和博弈中的混合均衡点提供了一种新的方法。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06756", "html_url": "https://arxiv.org/abs/2511.06756", "title": "双Mamba在节点特定表示学习中的应用：基于选择性状态空间建模解决过度平滑问题", "title_en": "Dual Mamba for Node-Specific Representation Learning: Tackling Over-Smoothing with Selective State Space Modeling", "authors": "Xin He,Yili Wang,Yiwei Dai,Xin Wang", "background": "在深度图神经网络（GNNs）中，过度平滑是一个基本的挑战，由于重复的消息传递导致节点表示变得难以区分。现有的解决方案，如残差连接和跳层，虽然可以在一定程度上缓解这个问题，但它们无法显式地以节点特定和渐进的方式建模节点表示的演变过程。此外，这些方法也没有将全局信息考虑在内，这对于缓解过度平滑问题也是至关重要的。", "innovation": "本文提出了一种双重Mamba增强的图卷积网络（DMbaGCN），这是一种新的框架，将Mamba集成到GNNs中以从局部和全局两个角度解决过度平滑问题。DMbaGCN包括两个模块：局部状态演化Mamba（LSEMba）用于局部邻域聚合，并利用Mamba的选择性状态空间建模来捕捉节点特定的表示动态。全局上下文感知Mamba（GCAMba）利用Mamba的全局注意力能力为每个节点引入全局上下文。通过结合这些组件，DMbaGCN增强了在深度GNNs中的节点可分辨性，从而缓解了过度平滑问题", "conclusion": "在多个基准测试中的广泛实验表明，我们的方法在有效性和效率方面都是有效的。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20969", "html_url": "https://arxiv.org/abs/2502.20969", "title": "TeleRAG：具有前瞻检索的高效检索增强生成推理", "title_en": "TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval", "authors": "Chien-Yu Lin,Keisuke Kamahori,Yiyu Liu,Xiaoxiang Shi,Madhav Kashyap,Yile Gu,Rulin Shao,Zihao Ye,Kan Zhu,Rohan Kadekodi,Stephanie Wang,Arvind Krishnamurthy,Luis Ceze,Baris Kasikci", "background": "检索增强生成（RAG）通过引入外部数据源扩展了大规模语言模型（LLMs），以提升事实正确性和领域覆盖率。然而，现代RAG管道依赖于大量数据存储，这带来了显著的系统挑战：在GPU内存有限的情况下，实现高吞吐量和低延迟非常困难。", "innovation": "TeleRAG是一个高效推理系统，能够在最小化GPU内存使用的同时减少延迟并提高吞吐量。核心创新是前瞻检索机制，这是一种预测所需数据并在LLM生成的同时将数据从CPU传输到GPU的预取机制。此外，TeleRAG采用了预取调度器和缓存感知调度器，以支持多GPU推理并减少开销。", "conclusion": "实验证明，TeleRAG在单查询情况下平均端到端延迟减少1.53倍，并在批处理情况下平均吞吐量提高1.83倍，同时具有良好的吞吐量可扩展性。这证实了TeleRAG在更快速和更高效的部署RAG应用程序方面的实用性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19164", "html_url": "https://arxiv.org/abs/2505.19164", "title": "BroadGen: 生成高效且有效的广告商广泛匹配关键词推荐框架", "title_en": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations", "authors": "Ashirbad Mishra,Jinyu Zhao,Soumik Dey,Hansi Wu,Binbin Li,Kamesh Madduri", "background": "在赞助搜索广告领域，关键词推荐主要集中在精确匹配类型上，这种类型存在管理成本高、目标范围有限以及搜索查询模式不断变化的问题。宽泛匹配类型虽然可以缓解某些精确匹配的缺点，但会带来定位准确性和缺乏有效监督信号等问题，因为广告商的使用量少。因此有必要提出一个综合效率和效果的标准，以确保大部分匹配查询的相关性。", "innovation": "提出一个名为BroadGen的创新框架，通过利用历史搜索查询数据来推荐高效的、有效的宽泛匹配关键词。BroadGen还通过词汇对应建模，能够保持长时间的好稳定性，可以每天为eBay的数百万卖家提供超过25亿项商品的关键词推荐服务。", "conclusion": "BroadGen通过历史搜索查询数据和词汇对应建模，提高了关键词推荐的效率和有效性，解决了宽泛匹配类型的许多问题，能够有效支持大规模广告业务的关键词推荐需求。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11575", "html_url": "https://arxiv.org/abs/2504.11575", "title": "MULTI-LF: 多环境网络中的实时恶意流量检测连续学习框架", "title_en": "MULTI-LF: A Continuous Learning Framework for Real-Time Malicious Traffic Detection in Multi-Environment Networks", "authors": "Furqan Rustam,Islam Obaidat,Anca Delia Jurcut", "background": "多环境（M-En）网络集成了物联网（IoT）和传统计算系统的各种流量源，创造出复杂且不断变化的恶意流量检测条件。现有的基于机器学习（ML）的方法通常在静态单一域数据集上进行训练，无法跨异构网络环境很好地泛化。", "innovation": "开发了一种基于Docker-NS3的真实测试床，模拟物联网和传统流量条件，生成并捕获带有标签的实时网络流。提出了Multi-LF，这是一种结合轻量化模型（M1）进行快速检测和深度模型（M2）进行高信心度修正的实时连续学习框架。通过基于信心的协调机制和权重插值，提高了效率和精确性，同时捕捉1秒时间间隔内的细微模式，识别不断演变的攻击行为。", "conclusion": "Multi-LF在Docker-NS3测试床上对实时流量进行了实现和评估，准确率为0.999，只需每260万个数据包进行一次人为干预，证明了其在异构网络环境中进行实时恶意流量检测的有效性和实用性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.06771", "html_url": "https://arxiv.org/abs/2505.06771", "title": "JaxRobotarium: 在10分钟内训练和部署多机器人策略", "title_en": "JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes", "authors": "Shalin Anand Jain,Jiazhen Liu,Siva Kailas,Harish Ravichandar", "background": "多智能体强化学习（MARL）作为一种解决多机器人系统中复杂可扩展协调行为的有效方法而受到关注，但现有MARL平台（如SMAC和MPE）缺乏机器人相关性和硬件部署，导致研究人员需要开发专用环境和硬件测试床。JaxRobotarium提供了一个将Robotarium测试床与现有MARL软件基础设施相结合的标准化机器人相关平台，但缺乏并行化和GPU/TPU执行支持，使得平台执行效率低下，阻碍了其应用。", "innovation": "JaxRobotarium通过使用Jax实现了端到端的模拟、学习、部署和基准测试平台，支持并行化和硬件加速，具有实时机器人动力学模型和安全约束。它易于与最新MARL库（如JaxMARL）集成，并包含八个标准化协调场景，其中四个是创新场景，将经典MARL基准任务（如RWARE和基于级别的采集中）引入机器人设置，实现了高度仿真度的模拟并提高了训练速度（20倍），提供了开放访问的模拟到现实的评估工作流。", "conclusion": "JaxRobotarium加速并平民化了多机器人学习研究和评估，代码已开源。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05235", "html_url": "https://arxiv.org/abs/2504.05235", "title": "IAEmu: 学习星系固有对齐相关性", "title_en": "IAEmu: Learning Galaxy Intrinsic Alignment Correlations", "authors": "Sneh Pandya,Yuanyuan Yang,Nicholas Van Alfen,Jonathan Blazek,Robin Walters", "background": "星系的固有对齐（IA）是弱透镜效应分析中的关键干扰因素，源于团际互动和星系形成过程中的相关形变。精确的IA建模对于稳健的宇宙学推断至关重要，但当前方法要么在非线性尺度上失效，要么依赖于昂贵的模拟。", "innovation": "作者引入了IAEmu，这是一个基于神经网络的模拟器，可以预测星系位置-位置（$\\xi$）、位置-方位（$\\omega$）和方位-方位（$\\eta$）相关函数及其不确定性，使用了基于晕族居住分布（HOD）框架的模拟目录。IAEmu 在$\\xi$上的平均误差约为3%，在$\\xi$上的误差约为5%，并向非-HOD对齐信号展示了泛化能力，通过装入IllustrisTNG流体动力学模拟数据作拟合。此外，作为完全可微的神经网络，IAEmu 可以在GPU上以约10,000倍的速度提高从HOD参数到相关函数的映射速度。", "conclusion": "IAEmu 提供了机械和认识不确定性，帮助识别预测可能不准确的区域，并提供了直接应用于第四阶段弱透镜调查的强大代理模型，可用于星系偏置和IA研究。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11225", "html_url": "https://arxiv.org/abs/2505.11225", "title": "HAPO：通过历史意识策略优化训练语言模型以进行简洁推理", "title_en": "HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization", "authors": "Chengyu Huang,Zhengxin Zhang,Claire Cardie", "background": "研究表明，在测试时增加响应长度可以显著提升大型语言模型（LLMs）的推理能力和表现，但这也使输出更加冗长，并增加了推理成本。先前避免冗余的方法大多依赖于通用预算限制或查询级别的长度优化，这些方法并没有利用训练期间再次遇到相同问题时的历史信息。这限制了它们使解决方案逐渐简化的潜力。", "innovation": "本文提出了一种名为 History-Aware Policy Optimization（HAPO）的方法，通过跟踪每个问题的“历史状态”（例如之前生成的正确响应中的最短长度）来优化长度。HAPO使用基于此历史状态的新颖长度奖励函数来激励发现比之前发现的更简洁的正确解决方案。这种方法避免了对较短但错误的回应进行过重惩罚，以促进探索更为高效的解决方案。HAPO结合了长度奖励和正确性奖励，同时优化了正确性和效率。", "conclusion": "研究使用HAPO对DeepSeek-R1-Distill-Qwen-1.5B、DeepScaleR-1.5B-Preview和Qwen-2.5-1.5B-Instruct进行了训练，并在数学基准测试上进行了评估。实验结果显示，HAPO有效提高了LLMs的简洁推理能力，长度减少了33-59%，但准确率仅下降2-5%。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11816", "html_url": "https://arxiv.org/abs/2505.11816", "title": "连续子空间优化在持续学习中的应用", "title_en": "Continuous Subspace Optimization for Continual Learning", "authors": "Quan Cheng,Yuanyu Wan,Lingyu Wu,Chenping Hou,Lijun Zhang", "background": "持续学习旨在序列性地学习多个任务并保留先前知识，但面临着适应新任务时灾难性遗忘的挑战。近年来，利用预训练模型的方法在缓解这一问题方面受到越来越多的关注，因为基础模型具有强大的泛化能力。现有方法通常通过低秩适应来调整预训练模型，从而将参数更新限制在一个固定的低秩子空间中。然而，这种优化空间的约束会降低模型的学习能力，导致性能较差。", "innovation": "为了解决这一限制，我们提出了连续子空间优化方法（CoSO），以一系列子空间而非单一子空间来调整模型。这些动态确定的子空间通过梯度的奇异值分解来确定。CoSO通过将梯度投影到这些子空间中来进行优化，以确保高效的内存优化。为减轻遗忘，每个任务的优化子空间与历史任务子空间保持正交。任务学习过程中，CoSO维护一个特定于任务的组件，捕捉当前任务的关键更新方向。完成任务后，该组件用于更新历史任务子空间，为后续学习奠定基础。大量实验表明，CoSO在多种数据集上显著优于当前最先进的方法，尤其是在长时间序列任务的挑战场景中。", "conclusion": "CoSO 在多种数据集上显著超越现有的持续学习方法，特别是在长时间序列任务中表现出色，通过动态调整子空间和正交约束有效缓解了灾难性遗忘，并确保了高效的优化过程。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07967", "html_url": "https://arxiv.org/abs/2505.07967", "title": "Wasserstein Distributionally Robust Nonparametric Regression", "title_en": "Wasserstein Distributionally Robust Nonparametric Regression", "authors": "Changyu Liu,Yuling Jiao,Junhui Wang,Jian Huang", "background": "Wasserstein分布鲁棒优化（WDRO）作为一种在统计学习中处理模型不确定性的方法，通过在指定的不确定集内最小化局部最坏风险来加强统计学习。尽管WDRO在参数设置中得到了广泛研究，但在非参数框架下的理论性质仍然缺乏深入探索。该论文旨在探究WDRO在非参数回归中的应用。", "innovation": "研究首次基于Wasserstein距离的阶数$k$建立了结构上的区分，证明了$k=1$诱导了Lipschitz型正则化，而$k>1$对应梯度模正则化。为了应对模型误指定问题，分析了超过局部最坏风险，得出了基于范数约束前向神经网络构建估计式的非渐近误差界。提出了一种新的覆盖数和逼近界的估计，同时控制函数及其梯度。该估计器在对数因子下的收敛速率为$n^{-2\beta/(d+2\beta)}$，其中$\beta$依赖于目标的平滑度和网络参数，在高维情况下证明了这一点率是 minimax最优的。此外，这些对超过局部最坏风险的上限保证了自然风险超出的保证，确保了框架对不确定集内任何分布的鲁棒性。研究表明该框架可以应用于回归和分类问题。", "conclusion": "通过模拟研究和对MNIST数据集的应用，进一步展示了估计器的鲁棒性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21528", "html_url": "https://arxiv.org/abs/2505.21528", "title": "通过随机最优控制实现的统一快速采样扩散桥框架", "title_en": "A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control", "authors": "Mokai Pan,Kaizhen Zhu,Yuexin Ma,Yanwei Fu,Jingyi Yu,Jingya Wang,Ye Shi", "background": "最近的扩散桥模型利用Doob的$h$-变换建立了两点间的固定端点分布，展示了在图像翻译和修复任务中的有希望的结果。但这些方法经常产生模糊或过度平滑的图像细节，缺乏全面的理论基础来解释这些缺点。", "innovation": "我们提出了UniDB，一种基于随机最优控制(SOC)的统一且快速采样框架。通过SOC优化重新阐述问题，证明了使用Doob的$h$-变换的现有扩散桥是特殊情况，出现在SOC代价函数中的终端惩罚系数趋向无穷大时。通过引入可调的终端惩罚系数，UniDB实现了控制成本和终端惩罚之间的最佳平衡，显著提高了细节保留和输出质量。通过为UniDB推导出确切的闭式解，我们设计了一个无需训练的加速算法，进一步通过更稳定的数据预测模型和SDE修正机制维持感知质量，有效减少了错误累积。", "conclusion": "广泛的实验验证了所提框架的优越性和适应性，填补了理论普遍性和实际效率之间的差距。我们的代码在线可用。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00661", "html_url": "https://arxiv.org/abs/2505.00661", "title": "语言模型从上下文学习和微调中泛化的研究：一项受控实验", "title_en": "On the generalization of language models from in-context learning and finetuning: a controlled study", "authors": "Andrew K. Lampinen,Arslan Chaudhry,Stephanie C.Y. Chan,Cody Wild,Diane Wan,Alex Ku,Jörg Bornschein,Razvan Pascanu,Murray Shanahan,James L. McClelland", "background": "大型语言模型展现出了激动人心的能力，但它们从微调中泛化的表现却出乎意料地狭窄。例如，它们可能在反转它们所训练的关系时无法泛化，或基于训练信息不能做出简单的逻辑推理。这种从微调中泛化事实信息的能力缺陷严重阻碍了这些模型的推理能力。另一方面，语言模型的上下文学习（ICL）则展示了不同的归纳偏见和演绎推理能力。本研究旨在探索这两种学习方式在泛化和演绎推理方面的差异。为此，构建了多个新数据集来评估和提升模型对新数据中事实信息进行泛化的能力。这些数据集设计目的是通过隔离数据集中的知识与预训练知识，创建清晰的泛化测试。将预训练的大模型暴露在这些数据集控制的数据子集中——通过ICL或微调，并在需要各种类型泛化的测试数据集上评估它们的表现。总体来看，在数据匹配的情景下，ICL比微调更能灵活泛化多种类型的推理（尽管我们也发现先前发现的一些例外情况，例如微调在较大知识结构中对反转信息的泛化）。", "innovation": "本研究通过构建新的数据集，并通过ICL和微调这两种方式来评估模型的泛化能力，发现ICL在多种推理类型上的泛化能力优于微调。研究还提出了一种改进微调泛化的方法：在微调数据中添加上下文推理痕迹。这种方法在我们的数据集和其他基准测试中均提高了泛化的表现。这些发现对于理解不同学习模式下语言模型的泛化能力具有重要意义，并且对于实际改进模型的表现具有实践意义。", "conclusion": "本研究表明，在数据匹配的设置下，ICL对于多种类型的推理泛化表现更灵活。提出了在微调数据中添加上下文推理痕迹的方法，以进一步改进泛化能力。这些结果对于理解不同学习模式下的语言模型泛化能力有着重要意义，并能实际提高模型的性能。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22340", "html_url": "https://arxiv.org/abs/2510.22340", "title": "DynaSolidGeo: 动态评估VLMs在实体几何中真正空间数学推理的基准", "title_en": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "authors": "Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen", "background": "实体几何问题求解需要同时应用空间智能和符号推理的空间数学推理。然而，现有的大多数多模态数学推理基准主要关注于平面几何，并依赖于容易受到数据污染和记忆影响的静态数据集。这些基准通常仅通过最终答案来评估模型的表现，而忽视了推理过程。", "innovation": "本文介绍了DynaSolidGeo，这是首个用于评估VLMs动态空间推理能力的基准。该基准通过半自动标注管道构建而成，包含503个由专家精选的种子问题，理论上可以动态生成无限数量的多样化的多模态图文实例。该基准不仅考虑答案准确性，还融合了基于专家标注的推理链过程评估，以衡量逻辑有效性和因果一致性。", "conclusion": "实验显示，开源和闭源VLMs之间存在显著差距，在动态设置中性能急剧下降，并且在需要高阶空间智能的任务，如心理旋转和可视化方面表现不佳。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18101", "html_url": "https://arxiv.org/abs/2509.18101", "title": "本地部署大型语言模型的成本效益分析：与商用LLM服务持平", "title_en": "A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services", "authors": "Guanzhong Pan,Vishal Chodnekar,Abinas Roy,Haibo Wang", "background": "随着大型语言模型（LLMs）的普及，组织在使用AI提高生产力时面临选择：订阅商用LLM服务或本地部署模型。商用服务由于易于访问先进模型和可扩展，受到青睐，但数据隐私、服务提供商锁定和技术维护成本等方面的担忧促使了开源模型本地部署的兴趣增加。本文通过成本效益分析框架帮助企业决定何时本地部署的经济成本与商用订阅服务相当。分析考虑了最新开源模型的硬件需求、运营成本和性能基准，对比了本地部署这些模型与主流云提供商订阅费用的成本，为组织提供了一个实用的决策框架以规划其LLM策略。", "innovation": "本文提出的成本效益分析框架，帮助企业依据具体使用量和性能需求确定本地部署开源LLM模型的经济可行性，对比了本地部署与云服务的总成本。该研究填补了开源模型本地部署经济可行性分析的空白。", "conclusion": "研究给出了根据使用水平和性能需求估算的盈亏平衡点。这些结果为组织提供了规划LLM策略的实用框架，帮助其做出本地部署或订阅商用服务的决策。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22242", "html_url": "https://arxiv.org/abs/2509.22242", "title": "临床不确定性影响机器学习评估", "title_en": "Clinical Uncertainty Impacts Machine Learning Evaluations", "authors": "Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly", "background": "临床数据集的标签往往不够确定，因为标注者意见不一且信心不均；通常的聚合方法，例如多数投票，会掩盖这种不确定性；对医学影像基准进行的简单实验表明，在处理二元标签时考虑置信度可显著影响模型排名。因此，研究者认为机器学习评估应该明确考虑标注不确定性，使用可以直接作用于分布的概率指标；这些指标可以独立于生成注释的过程，无论该过程是简单的计数、主观的信心评估还是概率响应模型；它们还具有计算量较少的特点，只要按模型分数对示例进行排序，即可获得封闭形式的解析表达式，其时间复杂度为线性。", "innovation": "提出使用概率指标对标注不确定性进行计算，并强调这种不确定性对机器学习模型性能评估的影响，认为应该在不依赖于生成注释的过程下进行评估，可以适用于多种注释生成方法，并且计算简单高效。", "conclusion": "呼吁研究社区提供未经处理的原始标注数据，并采用考虑不确定性的评估方法，使得性能估计更能反映临床数据的特性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识衰退", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Peter Ebert Christensen,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型倾向于生成词汇、语义和风格上高度同质的文本，这种同质性导致知识衰退的风险，即随着时间的推移，同质化的大型语言模型会缩小可访问信息的范围。当前关于同质化的工作主要集中在封闭式的多项选择题上或模糊的语义特征，没有考虑跨时间和文化背景的趋势。", "innovation": "本文提出了一种新的方法来测量认识论多样性，即大型语言模型输出中的实际世界声明的变异性。通过开展广泛的实证研究，测试了27个大型语言模型、覆盖12个国家的155个主题以及200种来自真实用户对话的提示变体。结果显示，尽管新型模型生成更多样化声明的趋势明显，但几乎所有模型的知识多样性都不如基本的网络搜索。此外，模型大小对知识多样性产生负面影响，而检索增强生成（RAG）对知识多样性有积极影响，但这种影响因文化背景的不同而有所变化。", "conclusion": "相比于传统的知识来源（维基百科），国家特定的声明更多地反映了英语语言，而忽略了地方语言的表达，突显了在认识论表现方面的差距。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26656", "html_url": "https://arxiv.org/abs/2510.26656", "title": "对随机动力系统中似然自由推理潜在误设域支持的启发式适应", "title_en": "Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems", "authors": "Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy", "background": "在机器人学中，无似然推理（LFI）可以提供适应学习代理在参数化部署条件集中的领域分布。然而，采样支持的潜在误设可能导致次优但虚假确定的后验分布。本文分析了此问题并用随机动力学基准测试了启发式的有效性，然后评估了启发式支持适应对参数推理和动态可变形线性对象（DLO）操作任务中的策略学习的影响。", "innovation": "提出了三种启发式LFI变体：EDGE、MODE和CENTRE。它们分别以独特的方式解释了推理步骤中后验模式的转移，并在LFI步骤中适应支持和后验推理。通过暴露采样支持误设的问题，本文提供了一种新的方法来改进LFI的适应性和准确性。", "conclusion": "通过使用改进的后验作为基于模拟的策略学习的领域分布，实验结果表明这种方法提高了对象中心代理的性能，特别是在DLO操作任务中表现出了更加稳健的行为，并对具有参数化的DLO进行了更精细的长度和刚度分类。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.26601", "html_url": "https://arxiv.org/abs/2509.26601", "title": "MENLO: 从偏好到精通——评估和建模47种语言的本族语质量", "title_en": "MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages", "authors": "Chenxi Whitehouse,Sebastian Ruder,Tony Lin,Oksana Kurylo,Haruka Takagi,Janice Lam,Nicolò Busetto,Denise Diaz,Francisco Guzmán", "background": "确保大型语言模型（LLM）在多种语言中的响应质量达到母语者的水平极具挑战性。为此，本研究提出了MENLO框架，旨在通过依托受众设计原理机制来操作化本土质量评价。基于MENLO，研究人员创建了一个包含6,423个人标注的提示-响应偏好对的数据集，涵盖了四个质量维度，且在47种语言变体间具有高度的跨注标者一致性。研究表明，零样本LLM评判者在两两评价和结构化注标框架下显著受益，但仍无法与人类标注者相比。通过强化学习、奖励塑造和多任务学习方法进行微调，展示了显著的进步。同时，研究证明，使用强化学习训练的评判者可以作为生成奖励模型来增强多语言精通，尽管与人类判断之间仍存在差异。研究表明了大规模多语言评估和偏好对齐具有良好的方向性。", "innovation": "提出了MENLO框架，通过应用受众设计原理机制来操作化评价本土质量。创建了一个大规模的人标注数据集，涵盖了47种语言变体。展示了通过强化学习、奖励塑造和多任务学习方法对LLM进行微调可以显著改善其性能，并证明使用强化学习训练的评判者可以作为生成奖励模型来增强多语言精通。", "conclusion": "研究表明MENLO框架为大规模多语言评估和偏好对齐提供了有希望的方向。研究者公开了数据集和评价框架，以支持多语言LLM评估领域的进一步研究。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18530", "html_url": "https://arxiv.org/abs/2509.18530", "title": "重灌输量子数据：适用于量子输入的通用函数逼近器", "title_en": "Re-uploading quantum data: A universal function approximator for quantum inputs", "authors": "Hyunho Cha,Daniel K. Park,Jungwoo Lee", "background": "量子数据重灌输已经在经典输入中证明了强大的能力，通过重复编码特征到一个小电路中可以实现通用函数逼近。然而，这种思想在量子输入上的扩展仍是一个未充分探索的领域，因为量子态中包含的信息无法直接以经典形式访问。因此，传统方法难以直接处理量子态作为输入的问题。研究者在此背景下，设计了一种新的量子数据重灌输架构，旨在解决这一问题，直接利用量子数据进行量子机器学习任务。", "innovation": "该论文提出了一个新型的量子数据重灌输架构，其中使用单个辅助量子比特和单量子比特测量来近似任意有界连续函数。通过交替应用纠缠单元操作和中间电路重置，该架构实现了多方正和迹不变算子的离散级联，与开放量子系统动力学中的碰撞模型类似。这种架构提供了一种高效且表达力强大的方法，用于在量子数据上直接设计量子机器学习模型。", "conclusion": "该论文通过设计一种全新的量子数据重灌输架构，证明了这种新型的量子架构可以利用单个辅助量子比特和单量子比特测量来实现任何量子输入的通用函数逼近。这种架构通过对纠缠单元操作和中间电路重置的交替使用，实现了对量子态的有效处理，为量子机器学习应用开辟了新的道路。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00229", "html_url": "https://arxiv.org/abs/2510.00229", "title": "AgentFlux: 分离微调与推理以实现边缘设备上的代理系统", "title_en": "AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems", "authors": "Rohan Kadekodi,Zhan Jin,Keisuke Kamahori,Yile Gu,Sean Khatiri,Noah H. Bayindirli,Sergey Gorbunov,Baris Kasikci", "background": "大型语言模型（LLMs）作为代理协调者被部署，已经革命性地改变了任务自动化，但是为了满足隐私保护和成本效益的需求，需要在设备上的推理能力。然而，本地LLMs在工具调用场景中与前沿模型相比持续表现不佳，特别是在从大型工具集选择工具和准确生成复杂参数结构方面的能力不足。我们提出了一种将工具调用任务分解为两个子任务的方法：工具选择和参数生成。我们提出了一种新的后训练方法——分离微调，使用LoRA微调技术为每个子任务创建专用的LoRA适配器。此外，我们提出了DualTune，一个利用分离微调生成的LoRA适配器进行高效代理协调的推理框架，帮助本地模型在终端设备上运行。", "innovation": "我们提出了一种新的后训练方法——分离微调，使用LoRA微调技术为工具选择和工具特定参数生成分别创建专用的LoRA适配器。同时引入了DualTune，一个通过动态加载相应LoRA适配器以进行高效代理协调的推理框架，并实现了层次协调来限制工具选择所需的工具数量。", "conclusion": "在MCP-Bench基准测试上的实验表明，使用分离微调训练的Qwen-2.5-7B模型提高了基模型工具调用准确率46%，并且相对于相同大小的其他本地推理、非推理及微调模型，在所有情况下表现出色，相对于大部分2倍大小的模型也表现出色。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16565", "html_url": "https://arxiv.org/abs/2510.16565", "title": "语言胜过内容：揭示多语言大型语言模型中的文化理解", "title_en": "Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models", "authors": "Seungho Cho,Changgeon Ko,Eui Jun Hwang,Junmyeong Lee,Huije Lee,Jong C. Park", "background": "大型语言模型（LLMs）在多种文化背景下被广泛应用，因此准确的文化理解变得至关重要。之前的评估主要集中在输出性能上，而未阐明导致不同响应差异的因素。尽管电路分析的一些研究覆盖了少数语言，但很少专门关注文化因素。本文通过测量回答语义等价问题时的激活路径重叠情况，追溯LLMs内部的文化理解机制，旨在弥补现有研究的不足，揭示LLMs如何处理同语言不同国家和不同语言同国家的问题之间的差异。同时，还通过同语言国家配对来区分语言和文化方面的影响，找到了语言特异性模式以及韩半岛配对中显示出的语言相似性不能保证内部表示对齐的现象。这项研究基于LLMs在多种文化背景下处理语言和文化差异的方式，推动了对其内部机制的深入理解，从而改善其在不同文化背景下的适用性。", "innovation": "本文通过测量激活路径重叠来追溯大型语言模型（LLMs）内部的文化理解机制，特别关注语言和文化的影响。这不同于以往主要评估输出性能的研究方法，而是深入探讨了导致LLMs在处理跨语言和跨国家问题时差异的原因。此外，通过使用同语言国家配对来区分语言和文化因素，这一方法提供了一个新的视角，帮助更好地理解LLMs如何处理文化差异。研究中的韩半岛配对结果揭示了语言相似性并不能保证内部表示一致的现象，对于理解模型的文化适应性具有重要意义。", "conclusion": "此项研究展示了语言特异性模式在大型语言模型内部的具体表现，尤其是多元文化环境中的语言和文化差异问题。更为重要的是，廖家地区国家对对显示的结果表明，语言相似性并不能保证内部表示的一致性。这些发现有助于进一步改进语言模型的文化理解机制，提升其跨文化和多语言环境中的性能，为更广泛的应用提供支持。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.00810", "html_url": "https://arxiv.org/abs/2511.00810", "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "title_en": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "authors": "Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang", "background": "GUI接地是计算机使用代理的关键功能，它将自然语言指令映射到可执行的屏幕区域。现有的基于多模态大语言模型（MLLMs）的方法通常将其形式化为基于文本的坐标生成任务，但是从视觉输入直接生成精确的坐标仍然是具有挑战性的并且计算密集。GUI接地的一种直观实现方式是首先选择与指令相关的视觉补丁，然后在这些补丁内确定精确的点击位置。根据一般MLLMs具有某些内在的接地能力的观察结果，我们提出了一种基于注意力的无坐标监督微调框架GUI-AIMA，以高效地实现GUI接地。", "innovation": "GUI-AIMA通过将MLLMs的内在多模态注意力与补丁级别的接地信号对齐来实现GUI接地。这些信号通过简化查询-视觉注意力矩阵上的多头聚合自适应地计算以适应不同的用户指令。此外，其无坐标的方式可以轻松集成一个即插即用的放大阶段。GUI-AIMA-3B仅使用85,000张屏幕截图进行训练，证明了其出色的训练数据效率，并验证了轻量级训练可以触发MLLMs的内在接地能力。它在ScreenSpot-Pro、OSWorld-G和ScreenSpot-v2上的平均准确率分别为59.6%、63.8%和91.5%，分别是3B模型中的最佳性能。", "conclusion": "GUI-AIMA在高效的GUI接地任务中表现出色，通过无坐标的方式提供了出色的性能，并验证了轻量级训练可以触发MLLMs的内在接地能力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05757", "html_url": "https://arxiv.org/abs/2511.05757", "title": "零样本函数编码器导向的可微预测控制", "title_en": "Zero-Shot Function Encoder-Based Differentiable Predictive Control", "authors": "Hassan Iqbal,Xingjian Li,Tyler Ingebrand,Adam Thorpe,Krishna Kumar,Ufuk Topcu,Ján Drgoňa", "background": "该研究介绍了一种针对非线性动力系统的参数家族的零样本自适应控制的可微框架。背景在于，前人的方法如经典模型预测控制通常需要在线优化，这非常昂贵。本文提出的方法结合了基于函数编码器的神经ODE（FE-NODE）来建模系统动力学，以及可微预测控制（DPC）来进行离线自我监督学习的显式控制策略，旨在克服这一局限。", "innovation": "该研究创新地集成了一种基于函数编码器的神经ODE（FE-NODE）和可微预测控制（DPC），能够有效学习控制策略，并且可以在不重新训练的情况下，对新系统进行零样本适应控制。与经典方法相比，这种方法免除了在线优化的高成本，且能在不同参数化场景下表现出更高的效率、准确性和在线适应性。", "conclusion": "研究展示了所提出方法在各种不同参数的非线性系统上的高效性、准确性和在线适应性，强调其作为快速零样本自适应控制工具的广泛用途和潜力。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05784", "html_url": "https://arxiv.org/abs/2511.05784", "title": "DRAGON：通过负例检测和推理保护上下文中的大语言模型遗忘", "title_en": "DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning", "authors": "Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu", "background": "大语言模型（LLMs）在保护私人数据和移除有害知识方面至关重要。目前大多数方法依赖于微调来在遗忘效率和通用语言能力之间找到平衡，但这些方法通常需要训练数据或保留数据，这在现实场景中往往不可用。尽管在有忘记和保留数据可用的情况下，这些方法表现良好，但在数据有限的实际应用场景中，能够展示相同能力的研究不多。因此，有必要开发一种新的方法来克服这些局限。", "innovation": "本文提出了一种名为DRAGON的系统推理框架，它使用上下文中的链式思维（CoT）指令来保护部署的LLM。DRAGON不修改基础模型，而是利用LLM的指令遵循能力，并引入一个轻量级的检测模块来识别需要遗忘的指令提示，而不需要保留数据。这些提示然后通过专门的CoT守护模型进行干预，以确保安全和准确的上下文干预。为了更稳健地评估遗忘性能，本文提出了新的遗忘性能度量和持续遗忘环境中的度量。", "conclusion": "通过广泛的实验验证了DRAGON的有效性，证明了其强大的遗忘能力、可扩展性和实际应用场景中的适用性。"}
{"llm_update_time": "20251113", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05540", "html_url": "https://arxiv.org/abs/2511.05540", "title": "Token Is All You Need: 基于信念-意图共生的认知规划", "title_en": "Token Is All You Need: Cognitive Planning through Belief-Intent Co-Evolution", "authors": "Shiyao Sang", "background": "长久以来，人们假设为了实现高性能的端到端自动驾驶（E2EAD），需要对场景进行详尽建模。本文从认知科学出发，提出了一种新观点，即有效的规划并不来自于对世界的重建，而是来自信念和意图在最少的语义丰富标记集内共生演化的过程。这种观点提供了一种替代传统场景建模的新思路。", "innovation": "本文提出了一个新的认知规划框架，即基于信念-意图共生的理念，通过少量语义丰富的标记令牌进行规划。实验结果表明，这种方法在无未来预测的情况下表现良好，且当结合未来预测标记时，性能显著提升并趋近于传统方法。值得注意的是，无明确重建损失的策略在可靠感知输入下表现出色，这表明任务驱动的信念和意图共生是关键。此外，长时间训练后，模型自发形成的令牌动态展现出认知一致性，平衡了当前感知和未来目标。", "conclusion": "本文开创了一种基于信念-意图共生的认知规划新范式。这种方法不仅摆脱了对像素级精确度的要求，而是通过语义标记揭示了认知过程中的稳定动态。未来规划与想象之间的桥梁得以建立，这种范式为实现前瞻性的智能代理指明了方向。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.07458", "html_url": "https://arxiv.org/abs/2511.07458", "title": "REFLEX: 通过大型语言模型判断无参考评估日志总结", "title_en": "REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment", "authors": "Priyanka Mudgal", "background": "评估日志总结系统存在挑战，缺乏高质量参考摘要，并依赖基于表面词汇重叠的ROUGE和BLEU等现有度量标准。这些标准难以全面衡量总结的质量。", "innovation": "引入了REFLEX，一种基于大型语言模型（LLM）判断的无参考评估指标。REFLEX利用LLMs作为零样本评估者，无需黄金标准参考或人工注释即可评估总结的相关性、信息性和连贯性。", "conclusion": "REFLEX在多个日志总结数据集上产生稳定、可解释且精细的评估结果，并比传统度量标准更有效地区分模型输出。REFLEX为在缺乏或无法获取参考数据的实际场景中评估日志摘要提供了可扩展的替代方案。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08232", "html_url": "https://arxiv.org/abs/2511.08232", "title": "OWLAPY：一种面向OWL本体工程的Python框架", "title_en": "OWLAPY: A Pythonic Framework for OWL Ontology Engineering", "authors": "Alkid Baci,Luke Friedrichs,Caglar Demir,Axel-Cyrille Ngonga Ngomo", "background": "研究者在本体工程中需要创建、修改和序列化OWL 2本体，传统上这些工作需要使用复杂的Java库和工具，这给非Java用户带来了困扰。", "innovation": "OWLAPY是一个全面的Python框架，用于简化OWL本体工程的任务。它将原生的基于Python的原理解释器与支持外部Java原理解释器的接口集成，提供了灵活性。此外，OWLAPY支持本体组件的多种实现，并能够将OWL类表达式与其他格式（如描述逻辑、Manchester语法、SPARQL）进行转换。", "conclusion": "OWLAPY作为一个经过良好测试的软件框架，为寻求具有灵活性的Python库进行高级本体工程的用户提供了帮助，特别是那些从基于Java的环境中转换而来的用户。该框架已经在GitHub和Python Package Index（PyPI）上公开可用，并且拥有超过50,000次的下载量。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.07463", "html_url": "https://arxiv.org/abs/2511.07463", "title": "LLM生成代码的动态稳定性", "title_en": "Dynamic Stability of LLM-Generated Code", "authors": "Prateek Rajput,Abdoul Aziz Bonkoungou,Yewei Song,Abdoul Kader Kabore,Iyiola E. Olatunji,Jacques Klein,Tegewende Bissyande", "background": "当前对代码生成的LLMs（大型语言模型）的评估主要侧重于功能正确性，忽视了算法复杂度的差异。即使功能正确的解决方案在算法复杂度上可能有很大差异，现有的评估方法未能捕获正确解决方案之间的行为和性能多样性。", "innovation": "该论文提出了一个有原则的框架来评估生成代码的动态稳定性，引入了两类基于opcodes分布的度量标准：静态典型跟踪偏差（SCTD）和动态典型跟踪偏差（DCTD）。这两者的比率（行为表达因子，BEF）被用作诊断信号，以显示关键的运行时不稳定性和功能冗余。", "conclusion": "实验结果表明，最先进的LLMs在功能上正确输出之间存在显著的算法差异。提高采样温度虽然提高了通过率，但降低了稳定性，揭示了一个未知的权衡：在多样化的输出空间中寻找正确解决方案带来了“稳定性的代价”。研究结果呼吁在代码生成中采用稳定性意识的目标，并呼吁新的基准测试，以进行鲁棒的、面向真实世界的LLM评估。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08475", "html_url": "https://arxiv.org/abs/2511.08475", "title": "基于大型语言模型的多代理系统为软件工程任务设计：质量属性、设计模式和动机", "title_en": "Designing LLM-based Multi-Agent Systems for Software Engineering Tasks: Quality Attributes, Design Patterns and Rationale", "authors": "Yangxiao Cai,Ruiyin Li,Peng Liang,Mojtaba Shahin,Zengyang Li", "background": "随着软件工程任务的复杂性不断增加，多代理系统（MASs）由于其自主性和可扩展性而成为研究和实践的焦点。此外，通过利用大型语言模型（LLMs）的推理和规划能力，LLM基的MASs在软件工程中的应用正日益受到关注。然而，尚未有系统性的研究探索LLM基的MASs在软件工程任务中的设计，包括设计师关注的质量属性、使用的设计模式以及设计动机。已有文献中涉及了多个软件工程任务和多种设计模式。", "innovation": "本研究识别了LLM基的MASs解决的软件工程任务、设计师关注的质量属性、使用的设计模式及其设计动机，填补了该领域的研究空白。研究发现最高频率出现的任务是代码生成，关注的质量属性主要是功能性适用性，最常用的设计模式是基于角色的合作，并且大多数设计的动机是提高生成代码的质量。基于这些研究结果，提出了支持软件工程任务的LLM基MASs设计的建议。", "conclusion": "本研究明确了LLM基的MASs在软件工程任务的应用中关注的核心要素及其设计原理，对于进一步研究和实际应用具有指导意义。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08530", "html_url": "https://arxiv.org/abs/2511.08530", "title": "大型语言模型能否模拟KLEE的符号执行输出？", "title_en": "Can Large Language Models Simulate Symbolic Execution Output Like KLEE?", "authors": "Rong Feng,Vanisha Gupta,Vivek Patel,Viroopaksh Reddy Ernampati,Suman Saha", "background": "符号执行通过使用象征性输入探索程序的不同路径来帮助程序验证。工具如KLEE由于能够自动检测错误并生成测试用例而广为使用。然而，当程序包含大量分支路径时，KLEE运行速度会非常慢，导致资源消耗过大，无法在大型或复杂代码上运行。研究者希望通过探索是否能够用大型语言模型（如GPT-4o）来模拟KLEE产生的输出，从而节约时间和资源。具体目标是让GPT-4o识别程序中最具约束的路径，这些路径通常涉及较难测试的边缘情况，并且更可能包含深层错误。但由于完全运行KLEE需要消耗大量资源，因此研究者测试了GPT-4o是否能够通过数据集中100个C程序来预测KLEE的输出和最复杂路径。", "innovation": "研究试图利用GPT-4o这样的大型语言模型来预测KLEE的输出并识别程序中的最复杂路径，这可能成为一个节省时间和资源的方法。如果成功，将有可能用大型语言模型来替代符号执行的某些部分。", "conclusion": "研究结果显示，在生成KLEE类似输出和识别最复杂路径方面约有20%的准确性。虽然准确度不高，但这项初步工作展示了当前大型语言模型在模拟符号执行时的能力和局限性。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08127", "html_url": "https://arxiv.org/abs/2511.08127", "title": "潜藏的威胁：探索源代码模型可转移的漏洞", "title_en": "A Small Leak Sinks All: Exploring the Transferable Vulnerability of Source Code Models", "authors": "Weiye Li,Wenyi Tang", "background": "源代码模型能够从源代码中学习到合适的嵌入，已在软件工程或安全任务上取得显著成功。近年来，大规模语言模型的快速发展扩展了源代码模型的家族，使代码的大规模语言模型成为革命性的开发流程工具。现有研究虽然探索了源代码模型的漏洞，但未提出实用方法来生成有效对抗样本，特别是对于LLM4Code在现代软件开发平台中的广泛应用未予以重视。因此，本文系统研究了传统源代码模型和LLM4Code的固有漏洞可转移性，并提出了一种不受攻击目标制约的方法来生成实际的对抗样本。", "innovation": "本文设计了HABITAT框架，结合定制化的扰动插入机制和层次化强化学习框架，无需访问源代码模型的下游分类器也能选择最优的扰动。这是首次系统研究传统源代码模型和LLM4Code的固有漏洞可转移性，并揭示了它们之间的潜在漏洞关联及其影响因素。", "conclusion": "实验表明，基于传统源代码模型构建的对抗样本在对抗LLM4Code时的成功率最高可达64%，超越现有最佳方法15%以上。这突显了未来开发稳健防御策略的关键要点。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.07924", "html_url": "https://arxiv.org/abs/2511.07924", "title": "使用基于上下文的问答进行软件测试", "title_en": "Testing Question Answering Software with Context-Driven Question Generation", "authors": "Shuang Liu,Zhirun Zhang,Jinhao Dong,Zan Wang,Qingchao Shen,Junjie Chen,Wei Lu,Xiaoyong Du", "background": "问答软件正逐渐融入我们的日常生活中，例如苹果Siri和亚马逊Alexa。确保这类系统的质量至关重要，因为错误的回答可能会导致重大损害。当前最先进的测试方法利用拟态关系对现有测试数据集进行测试，基于这些关系生成测试问题。然而，这些方法存在两个关键局限性：首先，它们往往生成的是不自然的问题，人类不太可能问这些问题，这减少了生成的问题有效识别可能在实际场景中出现的错误的能力；其次，这些问题是从现有的测试数据集中生成的，忽略了更广泛的上下文，从而限制了生成问题的多样性和相关性。", "innovation": "本文介绍了一种名为CQ^2A的基于上下文的问答系统测试中的问题生成方法。CQ^2A从提供的上下文中提取实体和关系形成真实答案，并利用大型语言模型基于这些真实答案和周围的上下文生成问题。此外，还提出了数据一致性验证和约束检查，以提高大型语言模型输出的可靠性。实验结果表明，CQ^2A在软件测试中的缺陷检测能力、生成问题的自然性以及上下文覆盖范围方面均优于当前最先进的方法。利用CQ^2A生成的测试用例，在微调被测试的问答软件时可以减少错误率。", "conclusion": "通过与当前最先进的方法进行比较，研究证明CQ^2A方法在生成更适合真实场景问题、提高测试覆盖范围和减少错误率方面具有显著优势。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08059", "html_url": "https://arxiv.org/abs/2511.08059", "title": "我需要学习更好的搜索隐私政策法律策略。——探究软件开发人员在使用隐私问题资源时的行为", "title_en": "\"I need to learn better searching tactics for privacy policy laws.'' Investigating Software Developers' Behavior When Using Sources on Privacy Issues", "authors": "Stefan Albert Horstmann,Sandy Hong,Maziar Niazian,Cristiana Santos,Alena Naiakshina", "background": "随着《欧洲通用数据保护条例》(GDPR) 和《加利福尼亚消费者隐私法》(CCPA) 的实施，软件开发人员在系统设计和实施过程中越来越需要做出与隐私相关的决策。然而，以往的研究表明，他们往往缺乏法律专业知识，难以进行符合隐私要求的开发。因此，为了了解当前信息来源在支持他们进行隐私敏感的实施过程中的有效性，作者对30名开发者进行了定性研究，探究他们在面对隐私敏感的场景时，如何利用自身的知识、网络资源和AI助手来识别隐私问题并提出应对措施。研究发现，开发者在个人知识、网络内容和AI助手这三个来源上都遇到了困难，导致其无法有效解决问题。这项研究揭示了现有支持隐私相关开发任务的不足之处，强调了需要提供更易于获取、更易于理解且更具操作性的隐私资源的必要性。", "innovation": "本研究通过定性方法考察了软件开发人员在隐私问题上的表现，特别是在使用个人知识、网络资源和AI助手时的困难，并首次展示了这些来源各自的问题所在。研究结果为改进现有的隐私支持资源提供了新的见解。", "conclusion": "本研究揭示了现有隐私支持资源的不足，强调了需要提供更易于获取、更易于理解且更具操作性的隐私资源的重要性。基于研究结果，作者讨论了对未来隐私支持工具的需求，包括增强透明度和上下文相关性，以便更好地支持软件开发人员的日常隐私需求。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.07426", "html_url": "https://arxiv.org/abs/2511.07426", "title": "MCP-Enabled LLM智能体的网络与系统性能表征", "title_en": "Network and Systems Performance Characterization of MCP-Enabled LLM Agents", "authors": "Zihao Ding,Mufeng Zhu,Yao Liu", "background": "Model Context Protocol (MCP) 最近在人工智能社区中日益受到关注，因为它为大型语言模型（LLMs）提供了与外部工具和服务交互的标准化方式，大幅提升了它们的能力。然而，MCP启用的LLM交互中包括了大量的上下文信息，如系统提示、MCP工具定义和上下文历史，这显著增加了令牌使用量。由于LLM提供商基于令牌收费，这些扩展的上下文会迅速导致成本增加，并增加LLM服务的计算负载。本文对MCP启用的LLM交互进行了全面的基于测量的分析，揭示了能力、性能和成本之间的权衡。我们探讨了不同的LLM模型和MCP配置如何影响关键性能指标，如令牌效率、经济成本、任务完成时间和任务成功率，并提出了一些潜在的优化措施，包括启用并行工具调用和实施强大的任务终止机制。这些发现为开发更高效、更稳健且成本效益更高的MCP启用工作流提供了有用的见解。", "innovation": "本文对MCP启用的LLM交互进行了全面的基于测量的分析，揭示了能力、性能和成本之间的权衡。具体创新点包括：\n- 探索了不同的LLM模型和MCP配置如何影响关键性能指标，如令牌效率、经济成本、任务完成时间和任务成功率。\n- 提出了潜在的优化措施，包括启用并行工具调用和实施强大的任务终止机制。", "conclusion": "本文的研究结果为开发更高效、更稳健且成本效益更高的MCP启用工作流提供了有用的见解，揭示了MCP启用的LLM交互中的权衡，并提出了潜在的优化措施，为未来的研究和应用提供了重要参考。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.07741", "html_url": "https://arxiv.org/abs/2511.07741", "title": "通过预像合成和属性提炼进行可验证的深度神经网络缺陷修复", "title_en": "Provable Repair of Deep Neural Network Defects by Preimage Synthesis and Property Refinement", "authors": "Jianan Ma,Jingyi Wang,Qi Xuan,Zhen Wang", "background": "众所周知，深度神经网络在面临各种安全威胁（如后门攻击、对抗攻击和安全属性违规）时可能表现出危险的行为。攻击者与防御者之间正在进行一场持久战。本文我们就提出一种综合利用近年来“神经网络修复”方面的进展，统一框架下同时应对多种安全威胁，修复由不同安全威胁引起的各种神经网络缺陷的方法，提供了一种潜在的解决实际场景问题的方案。", "innovation": "我们提出了一种名为ProRepair的新颖可验证神经网络修复框架，该框架基于形式预像合成和属性提炼驱动。核心思想是：(i) 合成一个精确的代理盒以表征特征空间的预像，该盒可以推导出指导后续修复步骤产生正确输出的充分的有界距离项；(ii) 进行属性提炼以实现精准的修正并能够处理更复杂的任务。", "conclusion": "ProRepair在四种安全威胁修复任务的六个基准测试中均表现出色，比现有方法在效果、效率和扩展性上更有优势。针对点修复，ProRepair在保持性能的同时纠正模型并显著提高泛化能力，比现有可验证方法速度提升5到2000倍。在区域修复中，ProRepair修复了所有36个安全属性违规实例，而现有最佳方法仅修复了8个实例，并且能够处理18倍更高维度的空间。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08052", "html_url": "https://arxiv.org/abs/2511.08052", "title": "增强LLM代码调试的双过程支架推理", "title_en": "Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging", "authors": "Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang", "background": "近年来，大型语言模型（LLM）在各种基准测试上的推理能力有所提升，但如何平衡复杂性和计算效率的推理步骤仍是一个关键的研究问题。最近的研究开始借鉴心理学理论以优化认知路径。LLM的最终输出和中间步骤分别被视为系统1和系统2，但对系统2的推理过程仍缺乏深入研究。", "innovation": "本文提出了一个新的基于心理学的支架推理框架，用于代码调试，该框架包括支架流、分析流和集成流。支架流中创建的参考资料代码与分析流生成的有错误的代码分析结果通过集成流进行结合。该框架在DebugBench上的通过率为88.91%，平均每题推理时间为5.36秒，相较于其他推理方法，无论在推理准确性还是效率上都表现出色。", "conclusion": "进一步分析揭示了不同认知路径的优势和局限性，根据不同问题难度和错误类型。我们的研究结果还证实了提出的支架推理框架与人类的认知过程相一致。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.08177", "html_url": "https://arxiv.org/abs/2511.08177", "title": "GazeCopilot：评估基于注视的新型提示以支持代码理解和可读性", "title_en": "GazeCopilot: Evaluating Novel Gaze-Informed Prompting for AI-Supported Code Comprehension and Readability", "authors": "Yasmine Elfares,Gül Çalikli,Mohamed Khamis", "background": "随着AI辅助代码编辑器（如GitHub Copilot）的应用越来越广泛，提高开发者效率的技术变得越来越重要。然而，这些工具的输出质量依赖于提示的上下文丰富性。注视行为能够提供丰富的认知信息，揭示开发者处理代码的方式。本文在实验室环境中评估了一种名为Real-time GazeCopilot的新方法，该方法利用实时注视数据来改进代码的解释和可读性。该方法通过结合注视度量（如固定模式和瞳孔扩张）来生成提示，以适应开发者的认知状态，从而提高代码理解的准确性，减少理解时间和提高感知的可读性，与传统的文本提示和预设的注视提示相比。", "innovation": "该研究引入了一种名为Real-time GazeCopilot的创新方法，利用实时注视数据生成提示，以改进代码解释和可读性。通过结合注视度量（如固定模式和瞳孔扩张）来调整建议，以适应开发者的认知状态。相对于基于文本提示的标准Copilot和预设的注视Copilot，这种方法仅在注视数据表明存在困难的地方进行代码重构，更精确地解决了问题，且没有对开发者已理解的代码进行不必要的修改。", "conclusion": "利用开发者的个人实时注视数据进行动态生成的提示显著提高了代码理解的准确性，减少了理解时间和提高了感知可读性。相比标准Copilot，该方法仅针对有困难的代码部分进行有选择性的重构，而预设的注视Copilot方法则进行了过度的一般化重构，因此表现更佳。这一研究发展了一种利用注视数据来个性化代码建议的新思路，旨在提高开发者的工作效率。"}
{"llm_update_time": "20251113", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20495", "html_url": "https://arxiv.org/abs/2506.20495", "title": "ReCode: 使用强化学习更新代码API知识", "title_en": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "authors": "Haoze Wu,Yunzhi Yao,Wenhao Yu,Ningyu Zhang", "background": "大型语言模型（LLMs）在代码生成方面表现出色，但在频繁更新外部库API时适应能力较弱。这一关键限制源于它们依赖于过时的API知识，即使有当前文档的支持，也妨碍了在动态环境中的可靠代码生成。为解决这一问题，本文提出了一种名为ReCode（基于规则的强化学习编译器更新）的新框架，该框架模仿了人类程序员适应API变化的过程。该研究旨在构建一个包含约2,000项数据集的训练集，使LLMs能够在更新信息的基础上执行版本迁移。此外，引入了一种改进的字符串相似度度量作为强化学习的奖励机制。", "innovation": "本文提出了一种基于规则的强化学习框架ReCode，用于更新代码API知识，该框架通过改进字符串相似度度量等方法提升LLMs在动态API环境下的代码生成性能。通过实验验证，ReCode显著提升了LLMs在未知任务上的代码生成表现，并且与监督微调相比，ReCode对LLMs一般代码生成能力的影响较小。此外，ReCode在不同LLMs和强化学习算法（GRPO和DAPO）上均表现出一致改进效果。", "conclusion": "ReCode通过改进的字符串相似度度量机制在动态API场景下的代码生成任务中表现出色，特定情况下甚至超过了参数量相同但经过代码指令微调和推理的模型。该研究提供了一种有效的方法来改善大型语言模型的代码生成能力，同时减少了对外部文档的依赖，相关代码已在指定的GitHub地址发布。"}
