{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04685", "html_url": "https://arxiv.org/abs/2511.04685", "title": "2024年综合医疗排班竞赛的混合解法", "title_en": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "authors": "Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter", "background": "本研究描述了Team Twente提交给2024年综合医疗排班竞赛的算法、实现和结果，Team Twente在此次竞赛中获得了第三名。方法基于子问题分解的三阶段解决方案，结合了混合整数规划、约束编程和模拟退火。", "innovation": "该研究提出了一种结合混合整数规划、约束编程和模拟退火的混合算法，并且是首次分享对基准实例的最佳解值的下界。此外，还指出了可能进一步改进现有方法的开放性问题。", "conclusion": "最后，研究展示了提高算法性能所面临的一些开放性问题，这些问题的解决有望进一步提升该方法的效果。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04683", "html_url": "https://arxiv.org/abs/2511.04683", "title": "AI-Powered Citation Auditing: A Zero-Assumption Protocol for Systematic Reference Verification in Academic Research", "title_en": "AI-Powered Citation Auditing: A Zero-Assumption Protocol for Systematic Reference Verification in Academic Research", "authors": "L.J. Janse van Rensburg", "background": "学术引用的完整性面临持续的挑战，研究显示约有20%的引用存在错误，而手动验证则需要专家数月的时间。", "innovation": "本文提出了一个基于人工智能的新型系统化、全面的参考文献审计方法，使用具备工具使用能力的代理型AI进行独立验证，不预设任何引用的正确性，覆盖30篇学术文档中的2,581个参考文献，包括本科生项目、博士论文和同行评议出版物。该方法成功检出伪造的引用、撤回的文章、孤引和掠食性期刊，提高了审计效率，减少了手动审核所需的时间，同时保持了极低的误报率。", "conclusion": "本文建立了首个人工智能代理型的学术引用完整性审计方法，具有实际的应用价值，适用于监督者、学生和机构质量保证。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05311", "html_url": "https://arxiv.org/abs/2511.05311", "title": "利用LLM代理清洁维护日志以提高预测性维护", "title_en": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "authors": "Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank", "background": "经济限制、可用数据集的有限性以及专业人才的短缺一直是汽车领域预测性维护（PdM）普及和发展的关键障碍。近年来，大型语言模型（LLMs）的进步提供了克服这些障碍的机会，加速PdM从研究向工业实践的转变。维护日志是训练高性能机器学习模型的关键数据源，但通常受到错别字、缺少字段、重复项和错误日期等错误的影响。", "innovation": "研究利用LLM代理来支持维护日志的清洁管道，评估了六种不同类型噪声下的清洁任务。结果显示，LLM在处理常见清洁任务时表现出色，为将来的工业应用提供了有前景的基础，尽管特定领域的错误仍然具有挑战性，但通过专门训练和增强代理能力有望进一步改进。", "conclusion": "尽管特定领域的错误仍然具有挑战性，但是研究结果表明，LLM具有很大的潜力用于进一步改进PdM中的数据清洁工作，并为将来的工业应用提供了一个有希望的基础。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04898", "html_url": "https://arxiv.org/abs/2511.04898", "title": "在动态环境中的实时推理代理", "title_en": "Real-Time Reasoning Agents in Evolving Environments", "authors": "Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu", "background": "在现实世界中，代理必须不仅做出逻辑判断，还要迅速判断，这就需要持续感知动态环境的变化：风险不断出现，机会不断产生，其他代理也在行动，而代理的推理过程仍在进行中。尽管语言模型推理技术取得了一定进展，但现有方法未能充分考虑这种动态性。研究者引入了实时推理作为代理在不断变化的环境中的一种新问题设定，并建立了实时推理健身房来演示这一点。研究了两种部署语言模型到代理的范式：（1）反应性代理，利用具有有限推理计算的语言模型以快速响应；（2）计划代理，允许进行扩展的推理计算以解决复杂问题。", "innovation": "研究者首次提出了实时推理作为代理的一种新问题设定，并提出了实时推理健身房来展示这一点。研究者还研究了两种部署语言模型到代理的范式：反应性代理和计划代理。尽管最先进的模型在这些范式中均难以做出及时而合理的判断，但研究者提出了一个名为敏捷思维者的解决方案，它能够同时使用这两种推理范式，从而在任务难度和时间压力增加时表现更好，有效平衡了推理深度和响应延迟。", "conclusion": "本研究确立了实时推理作为开发实用代理的关键测试平台，并为研究时间受限的AI系统奠定了基础，指明了通向实时能力代理的道路。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04855", "html_url": "https://arxiv.org/abs/2511.04855", "title": "知识论性的拒选预测", "title_en": "Epistemic Reject Option Prediction", "authors": "Vojtech Franc,Jakub Paplham", "background": "在高风险应用中，预测模型不仅要提供准确的预测，还要量化和沟通其不确定性。传统拒选方法（reject-option prediction）侧重于仅处理 aleatoric（偶然的）不确定性，但在数据不足的情况下，这种假设不再成立。因此，该研究引入了一种基于知识论（epistemic）不确定性的新方法，使模型能够在数据不足导致的高知识论不确定性区域拒绝预测，以最小化预期后悔值作为新的优化目标。", "innovation": "提出了基于知识论不确定性的拒选预测框架，该框架重新定义了最优预测器为最小化预期后悔的模型。模型在给定输入的后悔成本超过指定的拒绝成本时拒绝预测。这是首个结合贝叶斯学习的理论框架，能够学习识别因训练数据不足而无法做出可靠决策的输入。", "conclusion": "该作品通过引入知识论拒选预测方法，为在数据有限时进行准确预测和决策提供了新的理论基础和方法论指导。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05182", "html_url": "https://arxiv.org/abs/2511.05182", "title": "机械化作战中不同行动方案的自主生成", "title_en": "Autonomous generation of different courses of action in mechanized combat operations", "authors": "Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson", "background": "本文提出了一种支持军事地面作战执行阶段决策的方法，重点在于个别行动。该方法从一组初步评估其预期结果的动作开始，系统性地生成数千个单独的动作选项，并对其进行评估，以识别具有更好结果的替代行动方案。评估考虑了敌人的状态和行动、单位组成、部队比例、进攻和防御类型以及预期的推进速度。前线手册评估战斗结果和推进速度。生成和评估过程同时进行，生成多种替代行动方案。随着战斗的发展和条件的变化，新的行动方案基于先前评估的动作进行重新制定，使决策者在顺序决策框架中能够管理新的行动方案生成。", "innovation": "本文提出的创新点在于通过结合生成和评估过程，提出了一种系统性的方法来支持军事地面作战中的动态决策过程。这种方法能够根据敌情变化和已评估的行动动态生成新的行动方案，为战场上的指挥官提供实时指导。其创新之处在于能够处理复杂战场环境下的决策需求。", "conclusion": "本文的方法论在顺序决策框架中处理了动态生成和评估替代作战方案的问题，使得在不断变化的战场环境下能够有效管理新方案的生成。这种方法通过考虑敌对力量的各种因素，为指挥官提供了一种科学的、系统性的决策支持工具。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05375", "html_url": "https://arxiv.org/abs/2511.05375", "title": "需要推理的全部内容为城市规划AI", "title_en": "Reasoning Is All You Need for Urban Planning AI", "authors": "Sijie Yang,Jiatong Li,Filip Biljecki", "background": "AI 在城市规划分析方面已经证明非常成功，通过学习数据中的模式来预测未来状况。接下来的前沿领域是依靠 AI 辅助的决策：能够推荐地点、分配资源和评估权衡，并在透明地考虑到约束条件和利益相关者价值观时进行推理。最近在推理 AI 领域的突破，如因果推理提示、ReAct 和多智能体协作框架，现在使这一愿景变得可行。", "innovation": "本文提出了一种称为\"Agentic Urban Planning AI Framework\"的推理能力规划框架，该框架将三个认知层（感知、基础、推理）与六个逻辑组件（分析、生成、验证、评估、协作、决策）通过多智能体协作框架相结合。该框架展示了决策需要显式推理能力，这些能力是基于规范原则的价值导向型，确保满足约束条件的规范依据型，以及可解释性，使其能够通过统计学习的方式无法满足。此外，作者还比较了推理智能体与统计学习，并提出了一个全面的架构及基准评估指标，概述了关键的研究挑战，展示了如何通过系统地探索解决方案空间、验证合规性和透明地审议权衡来增强人类规划师的能力，而不是取代人类判断，而是通过计算推理能力增强其判断力。", "conclusion": "通过 Agentic Urban Planning AI Framework 的应用，AI 能够辅助人类规划师系统地探索解决方案的空间、验证合规性和透明地审议权衡，增强其判断力，而非取代人类判断。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04880", "html_url": "https://arxiv.org/abs/2511.04880", "title": "DMA: 基于人类反馈的在线RAG对齐", "title_en": "DMA: Online RAG Alignment with Human Feedback", "authors": "Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai", "background": "检索增强生成（RAG）系统通常依赖静态检索，这限制了对不断变化的用户意图和内容偏移的适应能力。现有的方法未能系统地整合多层次的人类反馈，以在交互式设置中优化排名。因此，需要一种在线学习框架，以更好地适应变化的需求并提供实时反馈指导的增强生成能力。本文旨在解决这一问题，提出一种名为DMA的在线学习框架，该框架通过系统地整合多层次的人类反馈来优化交互环境下的排名。DMA通过监督训练、据此优化策略以及用于低延迟服务的知识蒸馏，组织文档、列表和响应级别的信号，形成一个连贯的学习管道。此外，DMA评估采用了一种双轨测试协议，该协议与部署模式相似，包括大规模在线A/B测试和少量离线测试，以验证DMA的有效性并在工业部署中展示出显著的人类参与提升。", "innovation": "DMA框架引入了一种在线学习方法，以多层次的人类反馈为指导，优化进阶的RAG系统，通过监督训练、策略优化和知识蒸馏，实现交互式环境中的实时反馈和高效服务。DMA通过动态调整记忆中的信息，改进了RAG系统与人类用户之间的交互匹配度，增强了对用户意图和内容变化的适应性。DMA还通过在线与离线测试证明了其有效性和实际应用价值。", "conclusion": "DMA作为一种基于人类反馈的在线RAG对齐方法，不仅保留了基础检索的能力，还在对话式问答任务中取得了显著的进步，证明了其在实时反馈驱动的RAG系统中的有效性和可靠性。DMA展示了实时调整和适应性增强生成的最新进展，能够推动RAG系统的进一步应用和改进。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04956", "html_url": "https://arxiv.org/abs/2511.04956", "title": "ORCHID: 基于人类在环联合检索增强分类的高风险资产智能决策系统", "title_en": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "authors": "Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal", "background": "美国能源部（DOE）场所中包括大量敏感且通常具有双重用途的设备。符合国际出口控制政策的新规定需要透明和可审计的决策流程。传统的专家驱动工作流程耗时、容易积压，且难以跟上不断变化的监管边界。因此，需要一种更高效、透明且可审计的工作流程。", "innovation": "ORCHID 是一种模块化的代理系统，结合了检索增强生成（RAG）和人工监管，以产生基于政策的输出，这些输出可以进行审计。刘检查员、检索、描述精炼、分类、验证和反馈记录等小代理相互协作并通过代理到代理的消息传递以及通过模型情境协议（MCP）调用工具，实现了模型无关的本地操作。该系统具有从问题到证据再到决策的步骤推理、符合政策的引用和只读审计捆绑包（运行表单、提示、证据）。初步测试显示，ORCHID 在真实高风险案例中提高了准确性和可追溯性，将不确定项目留给领域专家（SMEs）处理。", "conclusion": "ORCHID 展示了一种实用路径，通过可信的大规模语言模型（LLM）辅助，在敏感的 DOE 合规工作流程中实现可审计且可信任的任务。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04682", "html_url": "https://arxiv.org/abs/2511.04682", "title": "在基于忆阻存储计算单元上高效部署CNN模型", "title_en": "Efficient Deployment of CNN Models on Multiple In-Memory Computing Units", "authors": "Eleni Bougioukou,Theodore Antonakopoulos", "background": "忆阻存储计算（IMC）是一种通过缓解数据移动瓶颈并利用基于内存计算的固有并行性来加速深度学习的范式转变。在基于IMC的硬件上高效部署卷积神经网络（CNN）需要使用先进的任务分配策略以实现最大程度的计算效率。", "innovation": "引入了Load-Balance-Longest-Path（LBLP）算法，该算法动态地将所有CNN节点分配到可用的IMC模拟器（IMCE）处理单元中，以最大化处理速率并最小化由于高效资源利用而产生的延迟。", "conclusion": "实验结果表明，提出的算法对于多种CNN模型的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04689", "html_url": "https://arxiv.org/abs/2511.04689", "title": "LLM评估中的自适应测试：心理测量学替代静态基准", "title_en": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks", "authors": "Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla", "background": "大型语言模型评估需要成千上万的基准项目，使得评估过程既昂贵又缓慢。现有方法通过固定项目集计算平均准确性，且所有项目被等权重对待，尽管这些项目的质量与信息量各不相同。", "innovation": "本文提出了ATLAS自适应测试框架，使用项目反应理论（IRT），采用Fisher信息引导的项目选择，以估计模型能力。我们的分析表明，五大数据基准中有3-6%的项目表现出负面区分度，揭示了标注错误的问题。ATLAS实现了90%的项目减少，同时维持测量精度: 在HellaSwag（5608个项目）基准上，仅使用42个项目就达到了与完整基准相同的效果（MAE = 0.154）。我们的框架将项目曝光率保持在10%以下，测试重叠率为16-27%，而静态基准中每个模型都会看到所有项目，导致100%的项目曝光。", "conclusion": "与准确率排名相比，IRT排名有所不同：具有相同准确度的模型获得不同的IRT得分，并且23-31%的全部模型的排名位置发生了超过10位的变化。开源代码和标准化项目集可在指定的链接处获取。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04691", "html_url": "https://arxiv.org/abs/2511.04691", "title": "用不起的脑信号解码您的思绪：从便宜的脑信号中解码语音", "title_en": "A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals", "authors": "Quentin Auster,Kateryna Shapovalenko,Chuang Ma,Demaio Sun", "background": "本文探讨了神经网络能否通过将EEG记录映射到音频表示，从而解码大脑活动为语音。通过让受试者听自然语音来收集EEG数据，训练了一个使用对比CLIP损失的模型，目的是将EEG衍生嵌入与预训练的基于Transformer的语音模型嵌入对齐。本文是在元公司最先进的EEG解码器基础上，提出了三个架构上的改进。这些改进包括针对不同个体的注意力层、个性化空间注意力以及兼具注意机制的双路径RNN。结果显示，其中两种改进提升了语音解码性能，表明个性化的解码架构有望在脑-机接口应用方面发挥积极作用。", "innovation": "本文创新地提出了三种架构改进：（i）针对个体的具体注意力层改进了0.15%的词错率 (WER)；（ii）个性化空间注意力改进了0.45%的WRR；（iii）双路径RNN与注意力机制结合使用，虽然降低了1.87%的性能。研究基于元公司最新的EEG解码器基础上进行，对于脑-机接口中的脑-语音解码具有重要应用价值。", "conclusion": "本文的发现强调了个性化的解码架构在脑-语音解码中的潜力，并证明工程化个性化的改进措施可以优化解码准确性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04703", "html_url": "https://arxiv.org/abs/2511.04703", "title": "衡量重要事项：大型语言模型基准的构念效度", "title_en": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks", "authors": "Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H.S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi", "background": "评估大型语言模型（LLMs）对于评估其能力和在部署前识别安全或稳健性问题至关重要。测量诸如‘安全’和‘稳健性’等抽象和复杂的现象需要强大的构念效度，即确保度量能够准确反映这些现象的关键方面。通过29位专家评审员的合作，研究人员系统地审查了445份来自自然语言处理和机器学习顶级会议的LLM基准。研究发现，这些基准在测量现象、任务和评分指标方面存在一些模式，这些模式削弱了得出的结论的有效性。", "innovation": "研究提供了一套八条关键性建议，旨在加强大型语言模型基准的构念效度，并提供了具体的行动指南，为研究人员和从业者在开发LLM基准时提供了指导。", "conclusion": "为了确保大型语言模型的可靠性和有效性，需要关注其基准的有效性。基于此研究，研究人员和从业者应遵循提供的建议和指南，以提高其评估的精确性和可靠性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04698", "html_url": "https://arxiv.org/abs/2511.04698", "title": "多模态RoBERTa：一种细调的多类别分类器，用于精神健康障碍", "title_en": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder", "authors": "K M Sajjadul Islam,John Fields,Praveen Madiraju", "background": "早期从社交媒体文本中检测到精神健康障碍对于及时提供支持、风险评估和转介至适当资源至关重要。这项工作介绍了multiMentalRoBERTa，这是一种针对常见精神健康状况（包括压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀念头和中性话语）进行微调的Roberta模型。通过多个经过精心整理的数据集，数据探索揭示了抑郁与自杀念头、焦虑与PTSD之间的强大相关性，并将压力归类为一个广泛且重叠的类别。", "innovation": "研究比较了传统机器学习方法、领域特定变压器和提示驱动的大语言模型，发现multiMentalRoBERTa在这两个设置中（六类别和五类别）表现出色，宏F1分数分别为0.839和0.870，优于微调的MentalBERT和基线分类器。此外，研究还使用了可解释性方法（如层集成梯度法和KeyBERT）来识别决定分类的词汇线索，特别是区分抑郁与自杀念头。", "conclusion": "整体而言，multiMentalRoBERTa被呈现为一个轻量级、稳健且可部署的解决方案，旨在增强精神健康平台的支持力度。研究强调了微调变压器在敏感背景下可靠且可解释的检测效果，同时也突出了公平性、偏见缓解和人工介入安全性协议的重要性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04700", "html_url": "https://arxiv.org/abs/2511.04700", "title": "去伪存真：在检索增强生成中的精简异质观点", "title_en": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation", "authors": "Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li", "background": "检索增强生成（RAG）通过整合外部知识源提高了大型语言模型（LLMs）的能力，以应对它们在获取最新或专业信息方面的局限性。增加检索文档的数量可以提高获取相关信息的可能性，但也会引入大量噪声，因为许多文档可能是无关或误导性的，从而降低生成响应的整体准确性。为了应对处理更多文档带来的挑战，我们提出了一种名为WinnowRAG的新框架，该框架旨在系统地过滤掉噪声文档并保留有价值的内容——我们称该过程为去噪。WinnowRAG分为两个阶段：第一阶段，我们执行查询感知聚类，将相似文档分组并形成不同的主题聚类，每个聚类分配给一个LLM代理以生成独特的答案；第二阶段，执行去噪，在这个过程中，一个批评家LLM评估多个代理的输出，并迭代地分离有用的文档和噪声文档。为了在丢弃代理时保留有用文档，我们提出了两种策略性的合并技术，以确保仅使用相关知识生成最终响应。", "innovation": "我们提出了一种名为WinnowRAG的新颖RAG框架，该框架包括一个两个阶段的过程：第一阶段通过查询感知聚类将相似文档分组，并为每个聚类分配LLM代理，以生成独特的答案；第二阶段则是去噪过程，其中批评家LLM评估多个代理的输出，并迭代地分离有用的文档和噪声文档。为了在丢弃代理的同时保留有用的文档，我们提出了两种策略性的合并技术，以确保仅使用相关知识生成最终响应。WinnowRAG对LLM模型是模型无关的，不需要任何模型微调，使其很容易适应各种任务。", "conclusion": "广泛的实验在各种现实数据集上证实了WinnowRAG相比于最先进的基线方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04697", "html_url": "https://arxiv.org/abs/2511.04697", "title": "利用代理角色模拟信息谬误脆弱性", "title_en": "Simulating Misinformation Vulnerabilities With Agent Personas", "authors": "David Farr,Lynnette Hui Xian Ng,Stephen Prochaska,Iain J. Cruickshank,Jevin West", "background": "虚假信息活动能够扭曲公众对事物的感知，进而对机构产生负面影响。了解不同群体对信息的反应对于设计有效的干预措施至关重要，但在现实世界中进行实验既不实际也无法满足伦理要求。为解决这一问题，文章开发了一种基于代理的仿真模型，使用大型语言模型（LLMs）来模拟人们对虚假信息的反应。", "innovation": "文章通过构建涵盖五个职业和三种心理模式的代理角色，评估了他们对新闻头条的反应。研究成果表明，由大型语言模型生成的代理角色与真实情况非常接近，同时也预测了人类行为，支持了使用这些代理作为研究信息反应的代理。此外，文章发现，心理模式比职业背景对代理如何解释虚假信息的影响更大。", "conclusion": "这项工作验证了大型语言模型在作为代理用于信息网络模拟中的有效性，用于分析复杂社会系统中的信任、极化以及对误导内容的易感性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04696", "html_url": "https://arxiv.org/abs/2511.04696", "title": "EncouRAGe：评估RAG本地、快速且可靠", "title_en": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "authors": "Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann", "background": "本文介绍了一种名为EncouRAGe的全面Python框架，旨在简化RAG系统（检索增强生成）的开发和评估过程，特别是结合大型语言模型（LLMs）和嵌入模型。该框架的目的是促进灵活的实验和可扩展的开发，同时强调科学再现性、多样化的评估指标以及本地部署。", "innovation": "EncouRAGe框架包括五个模块化的可扩展组件：类型说明、RAG工厂、推理、向量存储和指标，这些组件共同提供了一种灵活且可扩展的方式来开发和评估RAG系统。该框架特别注重在RAG流程中有效评估数据集，并提供实施细节和跨多个基准数据集的全面评估，包括25k对问题答案和超过51k文档。", "conclusion": "研究结果表明，RAG的性能仍低于Oracle Context，在所有四个基准数据集中，Hybrid BM25始终获得最佳结果。此外，研究人员还探讨了重新排序的影响，发现虽然带来了轻微的性能提升，但同时增加了响应延迟。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04705", "html_url": "https://arxiv.org/abs/2511.04705", "title": "POLIS-Bench: 针对政府双语政策任务中的LLMs多维度评估", "title_en": "POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios", "authors": "Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu", "background": "当前，基于政府双语政策场景中运行的语言模型评估标准仍然不够严谨和系统化。现有的评估基准未能充分考虑到政策领域的最新要求和实际应用背景，也不够全面地测试模型对不同任务的理解和应用能力。因此，迫切需要一个能够提供多维度评估的新型基准来更好地测试和改进语言模型。", "innovation": "POLIS-Bench 提出了三项主要改进。首先，创建了一个全面、更新的双语政策语料库，确保评估样本的规模能够满足当前治理实践的需求。其次，设计了三项专门、场景基础的任务——条款检索与解释、解决方案生成和合规判断，以全面测试模型的理解和应用能力。最后，建立了一个结合语义相似度和准确率的新型评价框架，以精确测量内容对齐和任务需求的遵守情况。", "conclusion": "POLIS-Bench 的大规模评估表明，推理模型在多任务中保持了更好的稳定性和准确性，突显了合规任务的难度。通过利用POLIS-Bench，我们成功地对一个轻量级开源模型进行了微调。结果表明，POLIS系列模型在多个政策子任务中与或超越了强大的专有基线，成本显著降低，为实现可靠和合规的政府实际应用提供了一条经济有效的途径。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04706", "html_url": "https://arxiv.org/abs/2511.04706", "title": "优先考虑经济发展还是气候行动？基于推断出的政治倾向探讨ChatGPT的响应差异", "title_en": "Prioritize Economy or Climate Action? Investigating ChatGPT Response Differences Based on Inferred Political Orientation", "authors": "Pelin Karadal,Dilara Kekulluoglu", "background": "大型语言模型（LLMs）通过自然语言提示迅速提供信息并生成个性化响应，但同时也推测用户的社会属性，这引发了关于偏见和隐性个性化带来的伦理问题的担忧，进而导致回声室效应。研究旨在探索推断出的政治观点如何影响ChatGPT在全球范围内的响应，而不论对话会话的具体内容。研究还考察了自定义指令和记忆特征如何改变ChatGPT的响应，考虑了政治倾向的影响。", "innovation": "研究开发了三种人设（两个具有政治倾向和一个中立），每个角色分别提出了关于DEI计划、堕胎、枪支权利和疫苗的看法。通过运用记忆和自定义指令将多个角色的观点传递给ChatGPT，使模型推断出他们的政治观点，而无需明确陈述。研究通过提问来揭示角色间的世界观差异，并对响应进行定性分析。研究发现响应与角色推断出的政治观点相一致，即使讨论相似话题时也表现出不同的推理和词汇。同时，研究发现，当使用显式的自定义指令和隐含的记忆特征时，推断出的政治倾向的方式是相似的。", "conclusion": "尽管使用显式自定义指令与隐含记忆特征推断出的政治倾向方式相似，但ChatGPT的输出偏向左倾。研究结果揭示了在讨论相似话题时，响应一致性反映的最近匹配出现在民主人设与中立人设之间，支持了ChatGPT输出倾向左倾的观察。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04707", "html_url": "https://arxiv.org/abs/2511.04707", "title": "在干草堆中开启后门", "title_en": "Jailbreaking in the Haystack", "authors": "Rishi Rajesh Shah,Chen Henry Wu,Shashwat Saxena,Ziqian Zhong,Alexander Robey,Aditi Raghunathan", "background": "最近的长上下文语言模型（LMs）研究进展使这些模型能够处理百万级别的输入，从而增强他们在复杂任务，如计算机使用代理中的应用能力。然而，这些扩展后的上下文的安全性影响还不是很清晰。因此，为了弥合这一差距，本文提出了一种名为NINJA的方法，通过在有害用户目标末尾追加良性、由模型生成的内容来突破对齐的LMs。实验表明，NINJA方法在标准的安全基准测试HarmBench中表现优异，并显著提高了包括LLaMA、Qwen、Mistral和Gemini在内的先端开源和专有模型的攻击成功率。", "innovation": "相比于先前的后门攻击方法，NINJA方法具有低资源消耗、可迁移和难以检测的特点。此外，研究发现，在固定计算预算的情况下，增加上下文长度可以比增加试验次数更好地提升最优N次制胜后门攻击效果。这种方法还揭示了即使是在精心设计的良性长上下文中也存在根本性漏洞。", "conclusion": "本文通过提出NINJA方法，展示了在长文本生成中的后门攻击不仅能被实现，而且在面对现代语言模型时其威胁更加致命。该研究强调了对现代语言模型进行安全增强的重要性，并提出了关于如何在良性内容中植入漏洞的思考，以提高信息安全性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04694", "html_url": "https://arxiv.org/abs/2511.04694", "title": "通过指令层级推理实现可控语言模型", "title_en": "Reasoning Up the Instruction Ladder for Controllable Language Models", "authors": "Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar", "background": "随着基于大型语言模型（LLM）的系统在现实世界决策中扮演越来越重要的角色，它们需要在一个提示上下文中处理来自多源（如模型开发者、用户和工具）的相互竞争指令。因此，在LLM中引入指令层级（IH），确保高层指令优先于低优先级请求，对系统的可靠性和可控性至关重要。", "innovation": "本文重新定义了指令层级解决作为推理任务，模型必须先分析给定用户提示与高层指令的关系，再生成响应。为此，提出了VerIH数据集，包含遵循约束规则且有验证答案的任务，涵盖系统和用户指令的对齐及冲突情况；通过轻量级强化学习有效转移到指令优先级，优化指令遵循和指令层级基准；推理能力在超越训练分布的安全关键场景中也可泛化。通过将安全问题视为对抗用户输入和预定义的更高优先级政策之间的冲突解决来提升模型对抗恶意行为的鲁棒性。", "conclusion": "指令层级上的推理提供了一条实现可靠语言模型的实用途径，系统提示更新可带来模型行为的可控和稳健的变化。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04716", "html_url": "https://arxiv.org/abs/2511.04716", "title": "P-MIA：认知诊断模型中的个人资料基会员推理攻击", "title_en": "P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models", "authors": "Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo", "background": "认知诊断模型（CDMs）在现代智能教育平台上用于创建精细的学员档案，但这些模型依赖于敏感的学生数据进行训练，引发了严重的隐私问题。尽管在其他领域已经研究了成员推理攻击（MIA），但其在CDMs中的应用是一个关键的科研空缺，导致其潜在的隐私风险未能被量化。", "innovation": "本文首次系统地研究了CDMs中的MIA，提出了一种新颖且现实的灰色盒威胁模型，利用这些平台的解释性功能，通过可视化（如雷达图）泄露模型的内部知识状态向量，演示了这些向量可以从可视化中准确逆向工程，从而形成强大的攻击面。据此威胁模型，提出了基于个人资料的MIA（P-MIA）框架，利用模型的最终预测概率和暴露的内部知识状态向量作为特征。实验证明，灰色盒攻击显著优于标准的黑盒基准。此外，展示了P-MIA作为审计工具的实用性，成功评估了机器遗忘技术的有效性并揭示其局限。", "conclusion": "灰色盒P-MIA攻显著优于标准的黑盒基准。P-MIA可以作为审计工具，成功评估了机器遗忘技术的有效性并揭示其局限。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04720", "html_url": "https://arxiv.org/abs/2511.04720", "title": "通过检索增强代理学习推理罕见疾病", "title_en": "Learning to reason about rare diseases through retrieval-augmented agents", "authors": "Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea", "background": "罕见疾病在医学成像领域占有一部分相对较小但重要的比例，由于缺乏代表性训练数据，现有的AI模型往往难以应对。在实际临床工作流程中，放射科医生经常依赖案例报告和文献来解决不熟悉的情况。本文探讨了如何利用检索增强的方式帮助放射科医生进行罕见疾病的诊断。", "innovation": "提出了RADAR（检索增强诊断推理代理），这是一个基于代理系统的设计，用于罕见疾病的脑部磁共振成像检测。RADAR使用AI代理访问外部医学知识，通过Sentence Transformers嵌入案例报告和文献，并使用FAISS进行相似性搜索建模，从而帮助未见过的疾病诊断决策。RADAR设计为模型无关的推理模块，可以无缝集成到各种大型语言模型中，一致地提升它们对稀有病理的识别和解释能力。", "conclusion": "在NOVA数据集中，包含280种不同罕见疾病下，RADAR最高可提高10.2%的性能。对于开源模型，如DeepSeek，RADAR的效果尤为显著。不仅如此，检索出的示例还提供了可解释性、文献支持的解释，这进一步证实了检索增强推理在医学成像中处理低流行率条件的强大力量。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04723", "html_url": "https://arxiv.org/abs/2511.04723", "title": "基于双路长短期记忆编码解码器的多时间窗口时序卷积与融合变换模型用于剩余寿命预测", "title_en": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction", "authors": "Mohamadreza Akbari Pour,Mohamad Sadeq Karimi,Amir Hossein Mazloumi", "background": "对于工业系统的可靠性、减少停机时间和优化维护来说，健康管理至关重要。剩余寿命(RUL)预测是健康管理的关键组成部分。然而，当前许多模型难以捕捉细微的时间依赖性，难以动态地优先考虑不同时间点的关键特征以实现稳健的预测诊断。", "innovation": "本文提出了一种创新框架，该框架整合了时序卷积网络(TCNs)用于局部时序特征提取，结合改进的临时融合变换器(TFT)增强的双路长短期记忆编码-解码。该架构有效地结合了短期和长期依赖关系，突出了显著的时间模式。此外，多时间窗口方法的引入提高了模型在不同操作条件下的适应性。", "conclusion": "在基准数据集上的广泛评估表明，该模型与最先进的方法相比，平均 RMSE 减少了 5.5%，这证明了其预测准确性。通过弥补现有方法的关键差距，本框架推进了工业预测系统的有效性，并突显了先进的时间序列变换器在 RUL 预测中的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04727", "html_url": "https://arxiv.org/abs/2511.04727", "title": "IndicVisionBench：评估VLMs中的文化与多语言理解", "title_en": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "authors": "Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal", "background": "视觉-语言模型(VLMs)在多模态任务中展现了令人印象深刻的迁移能力，但现有的评估基准主要集中在西方文化，未能充分考量这些模型在文化多样性和多语言环境中的表现。因此，亟需开发针对非西方地区尤其是印度次大陆的多模态模型基准。", "innovation": "本文提出了IndicVisionBench，这是第一个以印度次大陆为中心的大规模多模态基准，该基准涵盖了6种类型的问题，包括光学字符识别(OCR)、跨模态机器翻译(MMT)和视觉问答(VQA)，并提供了英文和10种印度语言的高质量注释语料库。基准数据集包含约5,000张图像和37,000多对问答对，关注13个文化基础话题。通过比较8种不同特性的模型，该研究揭示了准军事化和隐喻层面的显著性能差距，突显了当前模型在文化多元化场景中的局限性。", "conclusion": "通过确保使用中的多样化文化和多语言性，IndicVisionBench建立了可重现实验框架，为未来更具包容性的多模态研究铺平了道路。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04729", "html_url": "https://arxiv.org/abs/2511.04729", "title": "基于知识的异常检测方法以识别由网络引起的形状异常", "title_en": "Knowledge-based anomaly detection for identifying network-induced shape artifacts", "authors": "Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki", "background": "合成数据提供了一种解决机器学习模型训练中数据稀缺问题的有希望的方法；然而，如果没有适当的品质评估，可能会引入艺术感、失真和不现实的特征，从而损害模型性能和临床效用。这项工作介绍了一种基于知识的新型异常检测方法，用于检测合成图像中的网络引起的形状异常。", "innovation": "该方法采用两阶段框架，首先利用一种新颖的功能提取器构建一个特殊的功能空间，通过分析解剖边界沿图像的角度梯度分布；其次，使用基于孤立森林的异常检测器。该方法展示了在两个合成乳腺摄影数据集中的有效性，并通过定量评估验证了其集中异常能力，以及通过阅读者研究验证了人类读者的一致性。", "conclusion": "该方法是负责任使用合成数据的一个进步，它允许开发者评估合成图像是否存在已知的解剖约束，并定位和解决特定问题，从而提高合成数据集的整体质量。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04711", "html_url": "https://arxiv.org/abs/2511.04711", "title": "SWAP：通过序列水印技术实现软提示的版权审计", "title_en": "SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking", "authors": "Wenyuan Yang,Yichen Sun,Changzheng Chen,Zhixuan Chu,Jiaheng Zhang,Yiming Li,Dacheng Tao", "background": "大型视觉语言模型，尤其是CLIP，在各种下游任务中表现出色。软提示作为精心设计的模块，能高效适应特定任务，但需要注意有效的版权保护。本文研究了通过审查可能存在侵权的第三方模型是否包含受保护的软提示来进行模型版权保护的方法。然而，现有的技术因提示学习的独特特性而效果不佳。非侵入性审计容易产生误报，而侵入性方法也无法成功执行，现有的DNN后门技术扩展到提示学习面临挑战。现有方法的失败归结于相同的基本原因：水印技术与主要任务决策空间一致，但追求相反的目标。", "innovation": "本文提出了基于序列水印技术（SWAP）的软提示版权审计方法。SWAP通过特定顺序的防御者指定的分布外类嵌入水印，利用CLIP的零样本预测能力。这种方法可以在更复杂的空间中嵌入水印，同时不影响原始预测标签，从而减少与主要任务的冲突。为此，设计了假设检验引导的验证协议，并对成功条件进行了理论分析。实验结果证明了SWAP的有效性、无害性和对潜在适应性攻击的鲁棒性。", "conclusion": "通过多个数据集的广泛实验表明，SWAP在版权审计方面是有效的、无害的，并且对潜在的适应性攻击具有鲁棒性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04718", "html_url": "https://arxiv.org/abs/2511.04718", "title": "Ada-FCN: 自适应频率耦合网络在基于fMRI的大脑疾病分类中的应用", "title_en": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "authors": "Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang", "background": "静息态fMRI已成为分类脑疾病和构建脑功能性连接网络的重要工具，通过追踪大脑区域间的BOLD信号。然而，现有的模型忽略了神经振荡的多频特性，将BOLD信号视为单一的时间序列，而忽略了特定频带内的紊乱现象。部分尝试在模型中纳入频率信息的方法往往依赖于预先定义的频带，这并不总是能捕捉到个体差异或疾病特定的变化。因此，需要一种新的方法来解决这些问题。", "innovation": "本文提出一种新的框架，包含自适应级联分解来学习每个大脑区域相关的任务频带，并通过耦合频率学习来捕捉不同频带间的交互。这一框架统一了网络，并在统一卷积神经网络（Unified-GCN）中提供了新的消息传递机制，从而生成精细的节点表示，用于诊断预测。该方法在ADNI和ABIDE数据集上的实验结果表明优于现有方法。", "conclusion": "本研究提出的Ada-FCN方法能够在统一的函数网络中更好地捕捉大脑振荡的多频特性和频带内/间交互，从而提高诊断预测的性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04753", "html_url": "https://arxiv.org/abs/2511.04753", "title": "CPO: 条件偏爱优化（Condition Preference Optimization）用于可控图像生成", "title_en": "CPO: Condition Preference Optimization for Controllable Image Generation", "authors": "Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen", "background": "为了增强文本到图像生成中的可控性，ControlNet 引入了基于图像的控制信号，而 ControlNet++ 提高了生成图像和输入控制信号之间的像素级循环一致性。然而，由于不允许在采样过程中反向传播，ControlNet++ 仅优化低噪声时间步（例如，t<200），这不仅忽略了高噪声时间步的贡献，还引入了额外的近似误差。为了解决这个问题，提出了直接偏好优化（DPO）方法，但它由于生成模型中的不确定性，难以确保胜负图像对只在可控性方面有所不同。因此，本文提出了一种条件偏好优化（CPO）方法，通过对比控制条件而非生成图像来进行偏好学习。", "innovation": "CPO 是一种新的模型微调方法，通过训练模型偏好条件（控制信号），以消除不利因素并提供低方差的训练目标。理论上，CPO 比 DPO 具有更低的对比度损失方差，并且在实际应用中取得了更优的结果。此外，CPO 在数据集维护方面所需的计算和存储资源较少。", "conclusion": "在多种控制类型的实验中，CPO 显著提高了可控性，比如在分割上的误差率降低了 10% 以上，在人类姿态上的改进达到了 70%-80%，边缘和深度图的误差率也平均降低了 2%-5%。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04790", "html_url": "https://arxiv.org/abs/2511.04790", "title": "生物医学应用中的因果结构与表示学习", "title_en": "Causal Structure and Representation Learning with Biomedical Applications", "authors": "Caroline Uhler,Jiaqi Zhang", "background": "大规模数据收集有望更好地理解复杂现象，并最终做出更好的决策。表示学习已成为深度学习应用的关键驱动力，因为它可以学习反映数据重要属性的潜在空间，而无需任何监督注释。尽管表示学习在预测任务中取得了巨大成功，但在因果任务中(如预测干扰/干预的效果)可能会失败。这就需要在表示学习和因果推理之间实现结合。多模态数据（观察性和扰动性、成像和测序数据、单细胞、组织和生物体层面）的日益可用性为这种结合提供了契机。", "innovation": "本论文提出了一个结合因果结构学习和表示学习的统计和计算框架，试图解决如何有效使用观察和扰动数据进行观察因果变量的因果发现、如何利用系统多模态视图学习因果变量、以及如何设计最优扰动的问题。这为生物医学应用中因果结构和表示学习的研究提供了新的视角和方法。", "conclusion": "我们提出的框架为生物医学领域中因果结构和表示学习的研究提供了新的思路和方法。通过结合观察和扰动数据，以及利用多模态数据，可以更有效地进行因果变化的发现，并设计出更优的干预策略。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04758", "html_url": "https://arxiv.org/abs/2511.04758", "title": "ScheduleStream：使用采样器进行GPU加速多臂任务与动作规划与调度的时序规划", "title_en": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling", "authors": "Caelan Garrett,Fabio Ramos", "background": "双臂和类人机器人因其能够利用多臂在操作任务中展现出类似人类的高效性而受到青睐。然而，同时控制多个臂的动作在计算上极具挑战性，因为随之而来的混合离散-连续动作空间在增长。任务与动作规划算法（TAMP）可以在混合空间中有效规划，但通常只生成一个臂移动的计划，而不是允许多臂并发动作的时序计划。为了将TAMP扩展为生成时序计划，本文提出了一种新的框架ScheduleStream，这是首个用于采样操作的规划与调度的一般方法。ScheduleStream使用混合持续性动作建模时间动态，可以在异步开始并在参数函数定义的持续时间内持续进行。我们提议了通用算法，不依赖于特定的应用机制来解决ScheduleStream问题。我们将其应用于任务与动作规划与调度问题（TAMPAS），在采样器中使用GPU加速来加速规划。我们与几个简化方案进行了仿真比较，在智能体数量和自由度上表现更优。在多个现实中双臂机器人任务中展示了ScheduleStream的有效性。", "innovation": "我们提出了第一个用于规划与调度的通用框架ScheduleStream，旨在处理混合离散-连续动作空间的问题。ScheduleStream通过使用混合持续性动作建模时序动态，并通过异步开始和持续时间的参数函数支持多臂并发动作来解决TAMP问题，提出无特定应用机制的通用算法来解决ScheduleStream问题，同时展示了使用GPU加速采样器来高效解决方案的能力。", "conclusion": "我们验证了ScheduleStream在仿真和实际任务中的效果，发现它生成的解决方案更加高效，并在多个现实世界的双臂机器人任务中展示了其能力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04798", "html_url": "https://arxiv.org/abs/2511.04798", "title": "MDM：用于具有寄生电阻鲁棒性的忆阻器交叉电容的深度神经网络权重曼哈顿距离映射", "title_en": "MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars", "authors": "Matheus Farias,Wanghley Martins,H. T. Kung", "background": "寄生电阻（PR）影响 memristive 交叉电容（CIM）的效率，因为它限制了 DNN 矩阵映射到小的交叉电容瓷砖的效率，从而减缓了基于 CIM 的加速速度。在执行每个小交叉电容时，需要数字同步以执行下一层，但这种方式要么并行部署许多小交叉电容，要么顺序重用少数几个，这增加了模拟到数字转换、延迟、I/O 压力和芯片面积。因此，设计者们面临挑战如何减少这些影响，以提高DNN加速器的效率和准确性。曼哈顿距离映射（MDM）通过优化有源忆阻器的位置来缓解寄生电阻效果。利用位级结构化稀疏性，MDM 接受密集的低位比特操作的数据流并重新排列行以降低非理想因子（NF），从而将活跃单元移向受寄生电阻影响较低的区域。", "innovation": "MDM 是一种后训练的深度神经网络（DNN）权重映射技术，用于具有寄生电阻鲁棒性的 memristive bit-sliced compute-in-memory（CIM）交叉电容器阵列。通过重新排序行以使用位结构化稀疏性（reordering rows according to bit-level structured sparsity）并使活动单元移向受寄生电阻影响较低的区域，MDM 通过抵抗寄生电阻的影响来优化有源忆阻器的位置。这种方法降低了非理想因子（NF），提高了 DNN 在有模拟失真的条件下的准确性。", "conclusion": "MDM 提供了一种轻量级且空间导向的方法，用于扩展 CIM DNN 加速器。通过使用曼哈顿距离重新排序行并将活跃单元移向受寄生电阻影响较低的区域，MDM 降低了非理想因子（NF），并在 ImagNet-1k 模型上的 ResNets 中提高了平均 3.6% 的准确性，最高可达 46%。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04715", "html_url": "https://arxiv.org/abs/2511.04715", "title": "第一层并不一定比最后一层更好：语言模型数据影响评估中的层选择与聚合策略评估", "title_en": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "authors": "Dmytro Vitel,Anshuman Chhabra", "background": "准确识别训练样本如何影响大型语言模型（LLM）的决策是正确解释模型决策和审查大规模数据集的关键。当前的方法利用了模型通过其一阶和高阶梯度项的信息流来评估训练样本的影响。然而，由于今天的模型拥有数十亿参数，这些影响计算通常仅限于模型的一些层以确保计算可行性。先前的研究表明，嵌入层是最适合计算语言数据影响的层，基于影响得分相互抵消（即抵消效应）的假设。这篇文章进一步探讨了不同层的选择及其影响聚合策略的有效性，提出了一种新的评价指标——噪声检测率（NDR），并与抵消效应进行了比较。", "innovation": "论文提供理论和实验证据反驳了抵消效应的有效性，表明中注意层是更好的影响估计器。此外，论文提出了一种新的评价指标——噪声检测率（NDR），表明其预测能力优于抵消效应。论文还提出了一种无需重新训练模型即可评估影响得分有效性的方法，进一步探索了影响得分的聚合策略，指出第一层和最后一层在这种影响估计中未必哪一个更好，与以往的知识有所不同。总之，该论文通过提供一种新的方法和指标来提高语言模型数据影响评估的有效性，从而对相关领域提出了创新贡献。", "conclusion": "文章通过广泛的实验表明，第一层并不比最后一层更适合用于评估大型语言模型的数据影响，与以往的认识不同。提出了一个新的聚合策略——基于排名和投票的方法，可以显著提高性能。引入了一种新的评价指标——噪声检测率（NDR），具有良好的预测能力。这些方法和指标的提出为语言模型数据影响评估提供了有力的工具和技术。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04805", "html_url": "https://arxiv.org/abs/2511.04805", "title": "PuzzleMoE：通过稀疏专家合并和位打包推理高效压缩大型混合专家模型", "title_en": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference", "authors": "Yushu Zhao,Zheng Wang,Minjia Zhang", "background": "Mixture-of-Experts (MoE)模型在高效扩展语言模型方面展示出了巨大潜力，但由于存储所有专家参数所需的高内存开销限制了它们的广泛应用，尤其是在专家数量增加时更为明显。尽管已有研究探索了专家移除和合并策略，但在高压缩比下通常会导致性能下降。", "innovation": "PuzzleMoE通过两项关键创新实现了高效压缩和准确的推理，分别是稀疏专家合并来识别元素权重冗余和专业化，并使用双重掩码捕捉共享和专家特定参数；以及引入位打包编码方案，通过重新利用未充分利用的指数位，避免存储二进制掩码和符号的开销，从而在GPU上实现高效的MoE推理。", "conclusion": "实验表明，PuzzleMoE可以将MoE模型压缩高达50%的同时保持准确性，特别是在50%压缩比下，它在MMLU任务上的性能优于先前的MoE压缩方法高达16.7%，并且实现了约1.28倍的推理加速。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04812", "html_url": "https://arxiv.org/abs/2511.04812", "title": "统一的多模态扩散强制力技术在力觉操作中的应用", "title_en": "Unified Multimodal Diffusion Forcing for Forceful Manipulation", "authors": "Zixuan Huang,Huaidian Hou,Dmitry Berenson", "background": "传统的模仿学习方法通常从观察（如RGB图像）到动作建立直接映射，但这些方法往往忽略了不同模态之间的丰富互动，如感官输入、动作和奖励之间的关系，这些对于建模机器人行为和理解任务结果至关重要。", "innovation": "提出了一种统一的多模态扩散强制（MDF）框架，用于从多模态机器人轨迹中学习，不仅进行动作生成，还扩展到了动作生成之外的功能。MDF通过随机部分遮掩并训练扩散模型来重建轨迹，鼓励模型学习时间上和跨模态的依赖关系，如预测动作对力信号的影响或从部分观察中推断状态。", "conclusion": "MDF不仅提供了多种功能，还能够在嘈杂的观察下实现出色的性能和鲁棒性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04831", "html_url": "https://arxiv.org/abs/2511.04831", "title": "Isaac Lab: 一种基于GPU加速的多模态机器人学习仿真框架", "title_en": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning", "authors": "NVIDIA:Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi \"Jim\" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu", "background": "Isaac Lab 是 Isaac Gym 的自然延续，旨在扩展 GPU 原生机器人仿真模型，进入大规模多模态学习的时代。它整合了高保真度的 GPU 并行物理仿真、逼真的视觉渲染以及模块化、可组合的架构来设计环境和训练机器人的策略。", "innovation": "Isaac Lab 整合了执行器模型、多频传感器仿真、数据采集管道和域随机化工具，统一了强化学习和模仿学习的最佳实践。此外，该框架即将与不同的、基于 GPU 加速的牛顿物理引擎集成，提供了可扩展、数据效率高且基于梯度的方法来改进机器人学习。", "conclusion": "我们相信，Isaac Lab 结合先进的仿真能力、丰富的传感和数据中心级别的执行，将有助于突破下一代机器人研究中的新成果。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04811", "html_url": "https://arxiv.org/abs/2511.04811", "title": "一种最小化人工干预的生物医学图像实例分割主动学习流水线", "title_en": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "authors": "Shuo Zhao,Yu Zhou,Jianxu Chen", "background": "生物医学图像分割对于精确结构界定和下游分析至关重要。传统方法常难以处理噪声数据，而深度学习模型如U-Net为分割性能设立了新标准。nnU-Net可进一步自动化模型配置，使其在无需大量调优的情况下适用于多种数据集。然而，它需要大量标注数据进行交叉验证，这在仅有原始图像而无标签的情况下成为挑战。大型基础模型提供了零样本泛化能力，但在具有独特特征的具体数据集上可能表现不佳，限制了它们直接用于分析中的应用。", "innovation": "本文通过提出一种数据为中心的AI工作流，结合利用主动学习和伪标注，最小化人工干预，解决了这些问题。该流程首先利用基础模型生成伪标签，供nnU-Net自我配置使用。接着，选择一个代表性核心集，进行最少的人工标注，以有效微调nnU-Net模型。这种方法显著减少了手动标注的需求，同时保持了竞争力，提供了一种适用于生物医学研究人员的先进AI技术在分割任务中的可访问解决方案。", "conclusion": "该方法显著减少了手动标注的需求，同时保持了竞争力，提供了一种适用于生物医学研究人员的先进AI技术在分割任务中的可访问解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04834", "html_url": "https://arxiv.org/abs/2511.04834", "title": "基于提示的安全指导对未学习的文本到图像扩散模型无效", "title_en": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models", "authors": "Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon", "background": "近期，文本到图像生成模型取得了显著进展，但这同时也引发了关于其潜在风险的关注，尤其是在受到恶意文本提示输入时可能会生成有害内容。为解决这一问题，主要采用两种方法：一是对模型进行微调以去除有害概念，二是采用无需训练的引导方法，利用负面提示。然而，研究发现，将这两种方法结合起来往往效果不佳，甚至可能降低防御性能。这种现象表明两种范式之间存在关键不兼容性，阻碍了它们的有效结合。", "innovation": "本文提出了一种概念简洁且实验上稳健的方法，通过在无需训练的方法中使用概念反转获得的隐式负面嵌入来替代传统的负面提示。该方法在不需要修改任何现有方法的基础上，能够轻松集成到现有的处理管道中，并且已经在裸体和暴力基准测试中得到了实验证明，显示出在防御成功率上的一致性改进，同时保留了输入提示的核心语义。", "conclusion": "通过概念反转获得的隐式负面嵌入取代传统负面提示，该方法能够在不影响原始提示核心含义的情况下提高安全性，并实验证明了其在裸体和暴力内容防御上的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04886", "html_url": "https://arxiv.org/abs/2511.04886", "title": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "title_en": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "authors": "Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang", "background": "道路交通事故是全球健康危机，每年造成超过一百万死亡，并导致许多国家的国内生产总值（GDP）降低约3%。传统交通安全性研究通常单独分析风险因素，忽视了建筑设计环境中的空间复杂性和背景互动。此外，常规基于神经网络的风险评估器通常产生单一估计值，不传达模型不确定性，这限制了它们在关键决策中的应用价值。", "innovation": "本文提出了一种新的地理空间深度学习框架，通过利用卫星图像作为全面的空间输入，可以捕捉到复杂的空间模式和嵌入的环境风险因素，这些因素会影响致命事故的风险。该模型能够估计致命事故风险的完整Beta概率分布，提供准确且具有不确定性意识的预测，这对于安全关键应用中的可信AI至关重要。该模型在召回率方面优于基线，提升了关键危险警示的性能，并提供了优越的校准效果。", "conclusion": "本文的方法不仅为使用卫星图像提供了可靠且可解释的风险评估，还可以实现安全自主导航，并为城市规划者和政策制定者提供了一种高效且低成本的工具，以公平和成本有效地提高道路安全性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04902", "html_url": "https://arxiv.org/abs/2511.04902", "title": "你需要推理来学习推理：弱基础模型中无标签 RL 的局限性", "title_en": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models", "authors": "Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei", "background": "大型语言模型的最新进展表明，无监督强化学习方法可以在无需外部监督的情况下增强推理能力。然而，这些无标签的强化学习方法在小型基础模型上的泛化能力尚未得到探索，而小型基础模型通常具有有限的推理能力。", "innovation": "该研究提出了一个简单有效的无标签 RL 方法，利用逐步引入更难问题的课程学习策略和训练期间掩码非多数回放，以提高小型模型的推理能力。此外，还引入了一种数据整理管道来生成具有预定义难度的数据样本。", "conclusion": "该方法在所有模型大小和推理能力级别上都展示了一致的改进，为更稳健的无监督 RL 提供了途径，可以在资源受限的模型中增强推理能力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04875", "html_url": "https://arxiv.org/abs/2511.04875", "title": "LLMs中行为自意识的最小和机制性条件", "title_en": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs", "authors": "Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask", "background": "近年来的研究表明，大型语言模型（LLMs）可以表现出行为自意识：即准确描述或预测自己学习到的行为的能力，而无需明确的监督。这一能力引发了一些安全方面的担忧，因为它可能使得模型可以在评估时更好地隐藏其真实能力。论文试图探讨使这种自意识产生的最小条件及其机制过程。", "innovation": "通过控制性微调实验，在使用低秩适配器（LoRA）指令调优的LLMs中，发现：（1）可以使用单个秩1 LoRA适配器可靠地诱导自意识；（2）自意识行为可以由激活空间中的单个控制向量大量捕获，恢复了几乎所有微调行为效果；（3）自意识在任务间是局部化且非通用的，不同任务具有独立表示。这些发现表明，行为自意识作为域特定、线性特征，可以简单引发并调节。", "conclusion": "实验结果表明，行为自意识作为一种域特定、线性特征可以容易地被引发和调节。这一发现为理解和控制LLMs的行为自意识提供了新的视角。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04849", "html_url": "https://arxiv.org/abs/2511.04849", "title": "软件定义车辆代码生成：少样本提示方法", "title_en": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach", "authors": "Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama", "background": "软件定义车辆（SDVs）的出现标志着汽车工业的一大变革，软件现在在定义车辆功能方面发挥了关键作用，使得现代车辆的快速创新成为可能。为了开发针对SDVs的应用程序，需要高级工具来优化代码生成并提高开发效率。近年来，通用的大规模语言模型（LLMs）已经在多个领域展示了变革潜力，但由于对专有模型架构的限制性访问，它们难以适应特定任务，如SDV代码生成。这项研究旨在通过使用提示来探索LLMs的性能，提示是一种常用的简单策略，可以与LLMs交互并引导其响应。仅通过使用系统提示和使用高级提示工程技术设计的适当且高效的提示结构，就可以在无需进行训练或接触其基本设计的情况下创建LLMs。实验结果显示，带有少样本提示策略的模型在调整LLMs答案以匹配预期结果方面表现出色，基于定量指标。", "innovation": "本文提出了一种使用提示的技术，特别是少样本提示方法，来克服当前大语言模型在特定任务（如SDV代码生成）上的适应性限制。通过开发一个专门的基准来评估LLMs在生成SDV代码方面的性能，研究展示了这种方法的有效性和优势。", "conclusion": "研究结果表明，带有少样本提示策略的模型在精确调整LLMs生成的代码以符合预期结果方面表现更优，基于定量指标的评估。这种少样本提示方法为SDV代码生成提供了新的解决方案，并为开发更高效的软件定义车辆应用程序铺平了道路。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04814", "html_url": "https://arxiv.org/abs/2511.04814", "title": "一个用于多标签抗菌肽分类的标准基准", "title_en": "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification", "authors": "Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez", "background": "抗菌肽已被视为对抗抗微生物耐药性的有希望的分子。然而，碎片化数据集、不一致的注释以及缺乏标准化基准阻碍了计算方法的发展，减缓了新候选抗菌肽的发现。为了解决这些挑战，我们提出了扩展标准化抗菌肽评估集合（ESCAPE），这是一个实验框架，综合了来自27个验证存储库的超过80,000个肽。", "innovation": "我们提出了一种基于变压器的模型，利用序列和结构信息来预测肽的多种功能活性。我们的方法在平均平均精度上比第二优方法高2.56%，建立了多标签肽分类的新最佳状态。ESCAPE提供了一个全面且可重复的评价框架，推动了基于人工智能的抗菌肽研究的发展。", "conclusion": "ESCAPE是一个综合性和可重复的评价框架，用于推进人工智能驱动的抗菌肽研究。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04803", "html_url": "https://arxiv.org/abs/2511.04803", "title": "生物医学图像分割中的数据效率和转移稳健性：基于Cellpose的数据冗余与忘记研究", "title_en": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "authors": "Shuo Zhao,Jianxu Chen", "background": "通用型生物医学图像分割模型（如Cellpose）在多种成像技术和细胞类型中越来越受到应用。然而，两个关键挑战仍然很少被研究：（1）训练数据的冗余程度；（2）跨领域迁移对模型保持性能的影响。该研究通过Cellpose进行系统的实证分析，探讨数据冗余和模型遗忘现象。", "innovation": "1. 提出了一个简单的数据集量化（DQ）策略，以构建紧凑且多样化的训练子集，发现只有10%的数据即可达到图像分割性能饱和，表明存在大量冗余数据，可通过最小注释进行训练。\n2. 通过跨领域微调实验，观察到在从通用领域向专业领域过渡时，模型性能显著下降，并发现选择性DQ重播策略可以重新恢复源域性能，而完全重播可能会阻碍目标适应。此外，还发现多阶段训练领域排序可以提高泛化能力和减少遗忘现象。\n3. 强调数据为中心的设计在生物医学图像分割中的重要性，提出不仅需要紧凑的子集，还需要考虑到模型保留的学习策略和有序的领域排序。", "conclusion": "研究结果强调了数据为中心设计的重要性，指出有效的训练不仅需要紧凑的子集，还需兼顾模型保留的学习策略和有序的领域排序。此外，还证明了数据集量化策略在减少冗余和对抗模型遗忘方面的作用。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04914", "html_url": "https://arxiv.org/abs/2511.04914", "title": "MERaLiON-SER: Robust Speech Emotion Recognition Model for English and SEA Languages", "title_en": "MERaLiON-SER: Robust Speech Emotion Recognition Model for English and SEA Languages", "authors": "Hardik B. Sailor,Aw Ai Ti,Chen Fang Yih Nancy,Chiu Ying Lay,Ding Yang,He Yingxu,Jiang Ridong,Li Jingtao,Liao Jingyi,Liu Zhuohan,Lu Yanfeng,Ma Yi,Manas Gupta,Muhammad Huzaifah Bin Md Shahrin,Nabilah Binte Md Johan,Nattadaporn Lertcheva,Pan Chunlei,Pham Minh Duc,Siti Maryam Binte Ahmad Subaidi,Siti Umairah Binte Mohammad Salleh,Sun Shuo,Tarun Kumar Vangani,Wang Qiongqiong,Won Cheng Yi Lewis,Wong Heng Meng Jeremy,Wu Jinyang,Zhang Huayun,Zhang Longyin,Zou Xunlong", "background": "该研究旨在开发一种鲁棒的语音情感识别模型，适用于英语及东南亚语言。模型在多种语言的语音数据上进行了训练，并通过综合目标函数训练，以实现对离散情感类别和连续情感维度的建模。研究团队发现，这种双模式方法有助于更好地捕捉情感的特定类别（如快乐或愤怒）和细微差别（如唤醒、正负价值及控制感），从而提供更为全面和稳健的情感表示。", "innovation": "该模型采用一种混合目标函数，结合加权类别交叉熵和一致性相关系数损失，以同时实现离散情感类别和连续情感维度的建模。这种方法能够更全面地捕捉人类情感的多样化表达。此外，该论文的模型在跨语言评估中表现优异，超越了开源语音编码器和大型音频语言模型，展示了针对特定语言的语音模型在情感识别和跨语言理解中的优势。", "conclusion": "实验结果表明，MERaLiON-SER模型在多语言环境下的表现一致优于现有技术，突显了专门针对语音的情感识别和跨语言迁移的重要性。未来，该框架为引入情感感知能力到更具代理性的音频系统提供了基础，有助于提高音频系统的同理心和上下文适应性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04728", "html_url": "https://arxiv.org/abs/2511.04728", "title": "使用大型语言模型进行欺诈电子邮件检测的信任校准框架", "title_en": "Trustworthiness Calibration Framework for Phishing Email Detection Using Large Language Models", "authors": "Daniyal Ganiuly,Assel Smaiyl", "background": "欺诈电子邮件继续对在线交流构成持续挑战，通过具现实性语言和适应性战术来利用人类信任并逃避自动化过滤。尽管大型语言模型（LLMs）如GPT-4和LLaMA-3-8B在文本分类中表现出色，但在安全系统中的部署需要超出基准性能评估其可靠性。为解决这一问题，该研究引入了信任校准框架（TCF），一种用于评估欺诈检测器可靠性的可重复方法，从校准、一致性和稳健性三个维度进行整合，形成一个边界指数——信任校准指数（TCI），并用跨数据集稳定性（CDS）度量补充了这一指数，该度量可量化不同数据集之间信任性的一致性。研究在五个语料库上开展实验，包括SecureMail 2025、Phishing Validation 2024、CSDMC2010、Enron-Spam和Nazario，使用DeBERTa-v3-base、LLaMA-3-8B和GPT-4进行了实验，结果显示GPT-4的整体信任度最强，其次是LLaMA-3-8B和DeBERTa-v3-base。统计分析证实可靠性与原始准确率无关，强调了信任感知评估对实际部署的重要性。该框架为基于LLM的欺诈检测模型可靠性评估提供了透明和可重复的基础。", "innovation": "引入了信任校准框架（TCF），一种评估基于大型语言模型的欺诈检测器可靠性的可重复方法，从校准、一致性和稳健性三个维度进行整合，形成一个边界指数——信任校准指数（TCI），并用跨数据集稳定性（CDS）度量补充了这一指数，为基于LLM的欺诈检测模型可靠性评估提供了透明和可重复的基础。", "conclusion": "研究结果通过五个不同的语料库实验，表明GPT-4的总体信任度最高，其次是LLaMA-3-8B和DeBERTa-v3-base，且统计分析显示可靠性与原始准确率无关联性，强调了信任感知评估的重要性。提出的框架为评估基于LLM的欺诈检测器的可靠性提供了透明和可重复的参考标准。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04919", "html_url": "https://arxiv.org/abs/2511.04919", "title": "BudgetMem：在语言模型中通过学习选择性记忆策略实现低成本长上下文处理", "title_en": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models", "authors": "Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi", "background": "大型语言模型在处理长段文本文本时面临重大的计算和内存限制，尽管对处理长文本文档、多会话对话和书籍长度文本的应用需求在增长。尽管最近的技术进步将上下文窗口扩展到100K-1M个标记，但这些方法对于资源受限的部署来说成本过高。长文本文档处理的现有方法大多都需要存储所有片段，这增加了额外的负担。", "innovation": "提出了BudgetMem，这是一种新颖的基于记忆的架构，它学习决定记住什么而非保留一切。该系统结合了选择性记忆策略和基于特征的显著性评分（实体密度、TF-IDF、话语标记、位置偏差）来决定哪些信息在严格预算约束下值得存储。BudgetMem 使用了学习门控机制结合BM25稀疏检索，在高效的信息访问过程中存储关键片段。", "conclusion": "实验表明，BudgetMem 在保持99%以上的F1分数的同时，相较于基线检索增强生成（RAG）系统节省了72.4%的内存。这种记忆策略的使用量随着文档长度的增加而增加。我们的工作提供了一种实施方案，能够在有限硬件性能下处理长上下文，从而使高级语言理解能力更加普及。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04948", "html_url": "https://arxiv.org/abs/2511.04948", "title": "一种大型视觉-语言模型基准多模态口腔和牙齿数据集", "title_en": "A benchmark multimodal oro-dental dataset for large vision-language models", "authors": "Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib", "background": "口腔医疗领域的先进人工智能技术依赖于大量多模式数据集，这些数据集能够捕捉临床实践的复杂性。近年来，随着大规模多模式数据集的出现，人工智能驱动的口腔和牙齿健康解决方案取得了显著进展。然而，目前尚缺乏专门针对大型视觉-语言模型的全面多模态数据集。", "innovation": "本文介绍了一个全面的多模态数据集，涵盖了2018年至2025年期间来自4800名患者的8775次牙科检查，其中包括50000张口腔影像、8056张放射图和详细的文本记录。数据集经过伦理标准收集并在基准测试中进行注释。进一步地，对最新的大型视觉-语言模型Qwen-VL 3B和7B进行了微调，并在两类任务（六种口腔问题分类和从多模态输入生成完整诊断报告）中进行了评估，结果表明，微调后的模型在多项指标上优于基准模型和GPT-4o模型，验证了数据集的有效性，并突显了其在推进人工智能驱动的口腔和牙齿健康解决方案方面的重要性。", "conclusion": "所介绍的数据集公开可用，为未来人工智能牙科研究提供了重要的资源，验证了数据集对大型视觉-语言模型的有效性，强调了其在促进口腔和牙齿健康领域应用的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04909", "html_url": "https://arxiv.org/abs/2511.04909", "title": "基于对偶视角的决策导向学习：通过对偶引导替代的可扩展训练", "title_en": "A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates", "authors": "Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson", "background": "许多实际决策是在不确定性条件下通过预测量解决优化问题而做出的。这种方法导致决策导向学习的发展，它在训练模型时意识到优化器如何使用预测，从而提高下游决策的效果。尽管非常有前景，但这种方法的可扩展性仍然存在挑战，顶级方法要么通过解算器求导，要么依赖任务特异性替代模型，这两种方法都需要频繁且昂贵的优化器调用，通常是一个组合优化器。本文中，我们利用下游问题中的对偶变量来塑造学习，并引入了对偶引导损失（DGL），这是一种简单可扩展的目标，能够保持决策对齐同时减少解算器依赖。我们为具有自然一个或多个约束的组合选择问题（如匹配、背包和最短路径问题）专门构造了DGL。我们的方法（a）通过仅在下游问题上定期求解来分离优化与梯度更新；（b）在刷新之间利用对偶调整的目标进行简单可微替代目标的训练；（c）随着刷新的频率减少，将训练成本转向标准监督学习，同时保持强大的决策对齐。我们证明DGL渐近地减少了决策后悔，分析了运行时复杂性，并在两个问题类别中展示了DGL匹配或超过了顶级的DFL方法，同时使用较少的解算器调用和更少的训练时间。", "innovation": "该论文提出了一种简单可扩展的目标对偶引导损失（DGL），通过利用下游问题中的对偶变量来解决组合选择问题，特别是在优化和梯度更新之间分离的方法，以及利用简单的可微替代目标在优化器刷新之间进行训练的策略，减少了对解算器的依赖，同时保持了强决策对齐。还证明了DGL具有渐进减少决策悔恨的效果，并通过分析表明这种方法在使用较少的解算器调用和更少的训练时间的情况下匹配或超过了顶级的DFL方法。", "conclusion": "我们证明了DGL随着刷新频率的减少，其训练成本逐渐趋向于标准监督学习模式，从而实现可扩展性。此外，DGL通过减少对解算器的依赖进一步实现了训练的高效性和动态性。我们的方法不仅在理论上得到了证明，在实际应用中也表现出了显著的优势，在两个不同的问题类别中达到了或超过了当前最佳方法的效果，同时大幅减少了解算器调用次数和训练时间。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04970", "html_url": "https://arxiv.org/abs/2511.04970", "title": "学习Fourier形状以探究深度神经网络的几何世界", "title_en": "Learning Fourier shapes to probe the geometric world of deep neural networks", "authors": "Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li", "background": "尽管形状和纹理都是视觉识别的基础，但深度神经网络（DNNs）的研究主要集中在纹理上，而对几何的理解则相对不足。因此，本文旨在探讨形状在DNNs中的作用。", "innovation": "通过一个端到端的可微分框架，使用傅里叶级数参数化任意形状，基于缠绕数的映射将形状转换为DNNs所需的像素网格，并通过信号能量约束提升优化效率同时确保物理上合理的形状。这展示了一种方法，通过优化形状来生成高置信度分类，并揭示了模型的关键区域，同时也提供了一种新的易用性范式来欺骗下游的视觉任务。", "conclusion": "本文提出了一种框架，用于探索DNNs的几何世界，并为挑战和理解机器感知打开了新领域。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04962", "html_url": "https://arxiv.org/abs/2511.04962", "title": "太善良无法扮演邪恶角色：现代大语言模型在扮演反派角色失败的分析", "title_en": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains", "authors": "Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus", "background": "大型语言模型（LLMs）在创造性生成方面的任务越来越多，包括模拟虚构人物。然而，它们在表现非合社会效益、对抗性的人物方面的能力尚未得到充分研究。研究假设现代LLMs的安全对齐与实际扮演道德模糊或反面角色的任务之间存在根本冲突。为了研究这一假设，作者引入了一个新的基准——道德角色扮演基准（Moral RolePlay），该基准包含四级道德对齐量表以及一个平衡测试集，用于严格的评估。研究者要求最先进的LLMs扮演从道德典范到纯粹的反派角色的各种人物。大规模评估表明，随着人物道德性降低，人物刻画的准确度呈一致、单调地下降。研究发现，模型最难以处理那些直接违背安全原则的特质，如“欺诈”和“操纵”，往往用表面的暴力替代复杂的恶意。此外，研究还表明，一般的聊天机器人的技巧与扮演反派角色的能力无关，高度安全对齐的模型在这种任务中表现得尤其差。该研究提供了对这一关键局限性第一个系统的证据，强调了模型安全性和创造性真实度之间的重要矛盾。基准和发现为开发更精细、具有上下文感知的安全对齐方法指明了方向。", "innovation": "研究引入了一个新的基准——道德角色扮演基准（Moral RolePlay），用于评估LLMs在扮演各种道德角色方面的表现。研究发现，随着人物道德性降低，角色扮演的准确度呈现一致、单调地下降；模型在处理直接违背安全原则的特质时尤为困难；一般聊天机器人的技巧并不能预测其扮演反派角色的能力，高度安全对齐的模型在这一任务中表现较差。这些发现揭示了模型安全和创造性真实度之间的重要冲突，为开发更精细、具有上下文感知的安全对齐方法提供了重要参考。", "conclusion": "研究提供了对LLMs在扮演反派角色方面失败的第一个系统证据，强调了模型安全性和创造性真实度之间的重要矛盾。新的基准和发现为将来的发展开辟了道路，提出了开发更精细、具有上下文感知的安全对齐方法的可能性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04949", "html_url": "https://arxiv.org/abs/2511.04949", "title": "DeepForgeSeal：使用多代理对抗强化学习的基于潜在空间的半脆弱水印检测快速生成AI的进步使深度假信息越来越真实，给执法和公众信任带来了越来越大的挑战。现有的被动假信息检测器难以跟上步伐，主要是因为它们依赖于特定的伪造痕迹，这限制了它们对新假信息类型的泛化能力。通过使用水印进行主动假信息检测已经出现了，这被用来应对高质量合成媒体的识别挑战。然而，这些方法通常难以在对良性失真具有鲁棒性与对恶意篡改具有灵敏度之间找到平衡。本文介绍了一种新的深度学习框架，该框架利用高维潜在空间表示和多代理对抗强化学习（MAARL）范式来开发一种鲁棒且适应性强的水印方法。具体来说，我们开发了一个在潜在空间中运行的可学习的水印嵌入器，能够捕获高级图像语义，同时提供对消息编码和提取的精确控制。MAARL范式使可学习的水印代理能够通过与恶意和良性图像操纵的动态课程进行互动，来追求鲁棒性和易碎性之间的最优平衡，这些模拟是由对手攻击代理生成的。在CelebA和CelebA-HQ基准上的全面评估表明，我们的方法在具有挑战性的操纵场景中始终优于最先进的方法，分别在CelebA和CelebA-HQ上提高了超过4.5%和超过5.3%。", "title_en": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning", "authors": "Tharindu Fernando,Clinton Fookes,Sridha Sridharan", "background": "快速生成AI（特别是生成式AI）的进步导致深度假信息越发真实，给执法和公众信任带来了挑战。现有的被动假信息检测器难以应对新的伪造技术，因为它们依赖于特定的伪造痕迹，限制了它们的泛化能力。", "innovation": "提出了一种新的深水学习框架，利用高维潜在空间表示和多代理对抗强化学习（MAARL）范式来开发一种鲁棒且适应性强的水印方法。该框架通过一个可学习的水印嵌入器在潜在空间中操作，使得可以精确控制消息编码和提取，同时利用MAARL范式使得水印代理能够追求鲁棒性和易碎性之间的最优平衡。", "conclusion": "该方法在具有挑战性的操纵场景中始终优于最先进的方法，分别在CelebA和CelebA-HQ上提高了超过4.5%和超过5.3%。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04995", "html_url": "https://arxiv.org/abs/2511.04995", "title": "通过AI提升工程学生成公演讲技能", "title_en": "Enhancing Public Speaking Skills in Engineering Students Through AI", "authors": "Amol Harsh,Brainerd Prince,Siddharth Siddharth,Deepan Raj Prabakar Muthirayan,Kabir S Bhalla,Esraaj Sarkar Gupta,Siddharth Sahu", "background": "工程学生在今后的职业生涯中需要具备有效的沟通能力，尤其是公开演讲，能够向多元化的利益相关者传达技术知识。尽管大学提供了相关课程或工作坊，但无法持续提供个性化培训。公开演讲的反馈涉及到口头和非口头的多方面内容，全面提供此类反馈非常耗时，使得一致和个性化的评估面临挑战。", "innovation": "此研究将口语和非口语提示的研究结合，开发了一种基于AI的评估模型，用于工程学生。该方法将语音分析、计算机视觉和情感检测整合到一个多模态AI系统中，该系统提供评估和反馈。该模型评估（1）口头沟通（音调、音量、节奏、语调），（2）非口头沟通（面部表情、手势、姿势），以及（3）表达连贯性，这是一种新颖的集成，确保言语与肢体语言的一致性。这种多模态模型将多个方面融合，提供个性化的、可扩展的反馈，优于只能分别评估这些方面的先前系统。初步测试表明，AI生成的反馈与专家评估有适度的一致性。在评估的最先进AI模型中，包括Gemini和OpenAI模型，Gemini Pro表现最好，与人类标注者的同意度最强。", "conclusion": "这种AI驱动的公开演讲训练器通过消除对人类评估员的依赖，使得学生可以反复练习，自然地将言语与肢体语言和情感对齐，这对于专业和影响力沟通至关重要。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04963", "html_url": "https://arxiv.org/abs/2511.04963", "title": "模式感知的fMRI/dMRI扩散合成与组织及微结构细化", "title_en": "Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement", "authors": "Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang", "background": "磁共振成像（MRI），尤其是功能性MRI（fMRI）和扩散MRI（dMRI），在神经退行性疾病研究中至关重要。然而，缺乏的成像模态严重影响了其临床应用。虽然基于生成对抗网络（GAN）和扩散模型的方法在模态完成中显示出一些前景，但在fMRI-dMRI合成中仍受限制，主要由于（1）fMRI和dMRI在时间/梯度轴上的显著BOLD与扩散加权信号差异，以及（2）生成过程中未能充分集成与疾病相关的神经解剖模式。", "innovation": "本文提出了一种名为PDS的方法，引入了两个关键创新点：（1）一种模式感知的双模态3D扩散框架，用于跨模态学习；（2）一种集成了高效微结构细化的组织细化网络，以保持结构保真度和细微结构的细节。", "conclusion": "在OASIS-3、ADNI和内部数据集上评估，我们的方法达到了最先进的成果，MRI合成的PSNR/SSIM评分为29.83 dB/90.84%，fMRI合成比基线提高了1.54 dB/4.12%；dMRI合成评分为30.00 dB/77.55%，比基线提高了1.02 dB/2.2%。在临床验证中，合成数据表现出强大的诊断性能，在混合现实-合成实验中，NC vs. MCI vs. AD的准确率为67.92%/66.02%/64.15%。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04939", "html_url": "https://arxiv.org/abs/2511.04939", "title": "搜索不等于检索：在RAG中分离语义匹配与语境组装", "title_en": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG", "authors": "Harshit Nainwani,Hediyeh Baban", "background": "检索系统对于现代AI管道至关重要，但大多数系统混淆了两个单独的过程：找到相关的信息和提供足够的推理语境。现有的检索系统通常是从一个被动的过程开始，缺乏直接的语义匹配与语境组装的结合，这限制了系统的可组合性、可扩展性和语境保真度。", "innovation": "该研究提出了Search-Is-Not-Retrieve (SINR)框架，这是一种双层架构，将细粒度的搜索表示与粗粒度的检索上下文区分开来。SINR通过直接将小的语义准确的搜索片段连接到更大的上下文完整检索片段，提高了检索系统的可组合性、可扩展性和语境保真度，而无需额外的处理成本。这种设计将检索从被动步骤转变为积极步骤，使得系统架构更接近人类处理信息的方式。", "conclusion": "SINR框架提供了一个概念基础和正式结构，解决了实施问题，并展示了定性结果。这为下一代使用检索的AI系统提供了一个实用的基础。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04998", "html_url": "https://arxiv.org/abs/2511.04998", "title": "BiPETE：利用电子健康记录进行酒精和物质使用障碍风险评估的一种双位置嵌入变压器编码器", "title_en": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records", "authors": "Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang", "background": "基于Transformer的深度学习模型在利用电子健康记录（EHRs）预测疾病风险方面显示出潜力，但如何处理不规则的就诊间隔和缺乏统一结构的时间依赖性建模仍然是一个关键挑战。本研究旨在通过引入双位置嵌入变压器编码器（BiPETE），结合旋转位置嵌入和正弦位置嵌入来解决这一挑战，从而预测酒精和物质使用障碍（ASUD）风险，并测试其在大量EHR数据上的表现。", "innovation": "本研究提出了一种名为BiPETE的双位置嵌入变压器编码器，它整合了旋转位置嵌入来编码相对就诊时间，以及正弦位置嵌入来保留就诊顺序，而无需依赖大规模预训练。BiPETE在两个心理健康队列—抑郁障碍和创伤后应激障碍（PTSD）的研究数据上进行了训练，以预测酒精和物质使用障碍的风险。结果表明，BiPETE优于基线模型，AUPRC分别提高了34%和50%。此外，消融研究还验证了双重位置编码策略的有效性。使用集成梯度方法进一步解释模型预测，揭示了与ASUD风险和保护相关的关键临床特征，为缓解潜在风险提供了线索。", "conclusion": "本研究提出了一种适用于EHR数据的具有解释性的框架，通过识别关键临床特征，能够更好地理解风险评估过程，有助于潜在风险的缓解。实验结果证明了BiPETE在预测酒精和物质使用障碍风险方面的能力和有效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05000", "html_url": "https://arxiv.org/abs/2511.05000", "title": "具有增强回答性评估的查询生成流水线用于金融信息检索", "title_en": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval", "authors": "Hyunkyu Kim,Yeeun Yoo,Youngjun Kwak", "background": "随着大型语言模型在金融应用程序中的应用愈加受到关注，准确的信息检索（IR）对于可靠的人工智能服务仍然至关重要。但现有基准无法捕捉到真实银行场景中的复杂且领域特定的信息需求。构建领域特定的IR基准既耗费昂贵，又受到法律限制对使用真实客户数据的约束。因此，本文提出了通过基于大语言模型的查询生成构建领域特定IR基准的系统性方法来解决这些问题。通过本文提供的该系统性方法的具体实现，我们的流水线结合了单文档和多文档查询生成，并采用改进和增强推理的回答性评估方法，从而实现了与人类判断更强的契合度。利用这种方法，我们构建了一个名为KoBankIR的数据集，其中包括815个查询，源自204份官方金融文档。我们的实验表明，现有的检索模型在处理KoBankIR中的复杂多文档查询时存在困难，这表明我们的系统性方法对于领域特定基准构建的价值，并凸显了金融领域中检索技术改进的需求。", "innovation": "本文提出了通过基于大语言模型的查询生成构建领域特定IR基准的系统性方法。该方法提出结合了单文档和多文档查询生成，并采用改进和增强推理的回答性评估方法，从而与人类判断实现了更强的契合度。此外，通过这种方法构建了名为KoBankIR的数据集，实验结果表明，当前检索模型在处理复杂多文档查询方面存在不足，进一步突显了该方法的价值和应用需求。", "conclusion": "通过本文所提出的方法，构建了一个领域的特定于金融信息检索的基准数据集KoBankIR，该基准相较于现有的基准更具有实际应用场景的相关性。实验结果证明现有的检索模型在处理复杂多文档查询时存在不足，因此强调了提高检索技术在金融领域的必要性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05018", "html_url": "https://arxiv.org/abs/2511.05018", "title": "Pluralistic Behavior Suite：在对抗条件下测试多轮对话中定制行为策略的依从性", "title_en": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies", "authors": "Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien", "background": "大型语言模型（LLMs）通常被设计为符合一套通用的安全和使用原则，旨在广泛的社会接受度。然而，现实生活中的LLM应用通常发生在由独特的企业政策、监管要求、应用场景、品牌规范和伦理承诺组成的组织生态系统中。这种现实凸显了需要对LLMs进行严格的、全面的评价，以实现多样化的依从目标，即强调适应不同用户价值观和需求的能力。", "innovation": "本文介绍了PLURALISTIC BEHAVIOR SUITE（PBSUITE），一个动态评估套件，旨在系统地评估LLMs在多轮交互对话中遵循多样化的依从标准的能力。PBSUITE包括一个基于30个行业的300种现实的LLM行为策略数据集，以及一个动态评估框架，用于在对抗条件下测试模型对自定义行为规范的遵从性。", "conclusion": "研究表明，领先的开源和闭源LLMs在单轮设置中能够保持对行为策略的强劲依从性（低于4%的失败率），但在多轮对抗互动中依从性显著下降（高达84%的失败率）。这些发现表明，现有的模型对齐和安全性调节方法在确保实际LLM互动中的一致性方面存在不足。本文通过提供数据集和分析框架，为未来的研究提供了支持，以实现更强健和情境意识的多样化对齐技术。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05025", "html_url": "https://arxiv.org/abs/2511.05025", "title": "8bit-GPT：在过时的Macintosh操作系统上探索人机交互", "title_en": "8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating Systems", "authors": "Hala Sheta", "background": "助 poblative chatbots 提供了高效、个性化的沟通方式，并广泛依赖于它们进行决策、信息查询和日常任务。这种依赖导致了信息保留的负面后果，还造成了表面的情感依附。因此，本研究旨在重新考虑人类与人工智能的互动本质及其因拟人化说法带来的后果。通过倒逼技术和反功能设计原则，本研究通过使聊天机器人界面陌生化，优先考虑低效的互动方式，使聊天机器人的存在更加显眼。", "innovation": "本研究引入了8bit-GPT，这是一种在过时的Macintosh操作系统上模拟的语言模型，旨在重新引起人们对人类与人工智能互动本质及其拟人化语言后果的反思。通过使用倒逼技术和平反功能设计原则，8bit-GPT 使聊天机器人的界面变得陌生化，强调低效的交互，产生熟悉与陌生之间的摩擦。", "conclusion": "本研究通过使用8bit-GPT，讨论了人类与人工智能互动的美学和哲学问题，提出了反思设计原则。目的是使聊天机器人以一种更接近实物的方式显现出来，从而让用户重新思考与人工智能的互动方式及其潜在影响。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05034", "html_url": "https://arxiv.org/abs/2511.05034", "title": "动态滑块级对比学习中的残差编码在端到端全切片图像表示中的应用", "title_en": "Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation", "authors": "Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan", "background": "全切片图像（WSI）表示对于癌症亚型分类、癌症识别和突变预测至关重要。然而，由于标准的吉格帕ixel切片包含成千上万的图像块，这使得在单个迷你批次中计算所有块的梯度变得困难，特别是在当前GPU的限制下。", "innovation": "该方法提出了一种动态残差编码与滑块级对比学习（DRE-SLCL）模型，用于端到端WSI表示。该方法通过内存银行存储数据集中所有切片的图像块特征。在训练过程中，迷你批次通常包含多个WSI。对于批次中的每个WSI，随机采样一部分图像块，并使用块编码器计算其特征。然后，从内存银行选择来自同一WSI的更多图像块特征。每个WSI的表示通过一种残差编码技术生成，结合了采样特征和从内存银行检索到的特征。最终，基线上的WSI表示和组织病理学报告之间的对比损失被计算出来。", "conclusion": "在癌症亚型分类、癌症识别和突变预测任务中进行的实验证明了所提出DRE-SLCL方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05028", "html_url": "https://arxiv.org/abs/2511.05028", "title": "OvA-LP: 一种简洁有效的非独立同分布数据联邦学习框架", "title_en": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data", "authors": "Dongjin Park,Hasung Yeo,Joon-Woo Lee", "background": "联邦微调（FFT）能够适应分布分散的数据，但由于本地漂移（即客户端级别的更新发散）导致全局模型出现系统性偏差和方差放大，在异构客户端分布下显示出脆弱性。现有的聚合和个人化方法大多在事后纠正漂移，而在极端非IID条件下证明是脆弱的。", "innovation": "本文提出了一种名为OvA-LP的简捷框架，首次明确设计用于在基于PEFT的FFT框架中抑制漂移源。OvA-LP结合了冻结编码器上的线性探针与一个一対所有的头，以及一个简单的两阶段过程，保持预训练的特征几何结构，并脱耦logits以防止放大漂移的机制。", "conclusion": "OvA-LP在CIFAR-100数据集，对于shard-1、shard-2和伯努利狄利克雷划分条件下，保持了95.9%的IID精度，而最先进的FFT基线在相同条件下分别仅保持了10.1%和34.5%的精度。此外，OvA-LP还保持了在对称和不对称标签噪声下的鲁棒性。预计算编码器特征使得每轮的成本几乎与编码器大小无关。上述结果表明，OvA-LP为具有异质性的FFT提供了一个有原则的且高效的基座。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05055", "html_url": "https://arxiv.org/abs/2511.05055", "title": "无需姿态估计？没问题：单目深度估计的无姿态感知和实例感知测试时适应", "title_en": "No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation", "authors": "Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang", "background": "单目深度估计（MDE）是从单目相机拍摄的单个RGB图像中推断像素级深度，对于多种需要三维地形场景的AI应用至关重要。在现实世界的应用中，MDE模型经常需要在与训练环境不同的条件下进行部署。测试时环境适应（TTA）是解决这一问题的有效方法之一。尽管在MDE的自监督TTA方面已有显著进展，但现有方法在面对多样且动态的环境时仍效率低下且问题多多。", "innovation": "本文提出了一种新颖且高性能的MDE测试时适应框架——PITTA。该框架结合了两个创新策略：姿态无感知的MDE测试时适应范式以及实例感知图像掩码。此外，PITTA还提出了一种简单而有效的边缘提取方法，专门针对输入图像（单一单目图像）和深度图。通过这种多管齐下的方法，PITTA在各环境条件下对MDE进行测试时适应，显著优于现有技术。", "conclusion": "在驾驶Stereo和Waymo数据集上进行的广泛实验表明，提出的方法PITTA在MDE测试时适应期间表现突出，性能显著提升。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05039", "html_url": "https://arxiv.org/abs/2511.05039", "title": "PECL：雷达基于的人活动识别的异构并行多域网络", "title_en": "PECL: A Heterogeneous Parallel Multi-Domain Network for Radar-Based Human Activity Recognition", "authors": "Jiuqi Yan,Chendong Xu,Dongyu Liu", "background": "雷达系统因其非侵入性监控、高度隐私性和对光照条件的强大鲁棒性，在医学应用中越来越受欢迎。然而，现有的研究通常依赖单一域的雷达信号，而忽略了人类活动内在的时间依赖性，这增加了相似动作分类的复杂性。", "innovation": "设计了PECL网络（Parallel-EfficientNet-CBAM-LSTM）来处理三个互补域的数据：Range-Time、Doppler-Time和Range-Doppler。PECL结合了通道空间注意力模块和时间单元，能够在动作序列中捕捉更多的特征和动态依赖性，从而提高准确性和鲁棒性。PECL在动作识别方面表现出色，准确率达到96.16%，并优于现有方法至少4.78%，且在区分容易混淆的动作方面表现最佳。尽管PECL具有强大的性能，其模型复杂性适中，参数量为23.42M，计算量为1324.82M FLOPs，其参数效率设计进一步降低了计算成本。", "conclusion": "PECL在相同数据集上取得了96.16%的高准确率，优于现有的方法至少4.78%，特别是在区分容易混淆的动作上表现最佳，同时保持了适度的模型复杂性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05073", "html_url": "https://arxiv.org/abs/2511.05073", "title": "深度学习模型易受攻击，但对抗样本更是脆弱", "title_en": "Deep learning models are vulnerable, but adversarial examples are even more vulnerable", "authors": "Jun Li,Yanwei Xu,Keran Li,Xiaoli Zhang", "background": "理解对抗样本与干净样本之间的内在差异对于提升深度神经网络（DNN）的健壮性和对抗攻击的检测至关重要。本研究通过实验证明基于图像的对抗样本对遮挡高度敏感，并利用滑动掩码置信熵（SMCE）量化了遮挡下模型置信度波动，发现对抗样本在遮挡下的置信度波动远大于原始样本。在此基础上，提出了基于滑动窗口掩码的对抗样本检测方法（SWM-AED），避免了传统对抗训练的灾难性过拟合。", "innovation": "本研究创新点包括：首次通过实验证明了图像类对抗样本高度敏感于遮挡；通过提出滑动掩码置信熵（SMCE），量化了遮挡情况下模型的置信度波动，并发现对抗样本的置信度波动远高于真实样本；提出了基于滑动窗口掩码的对抗样本检测方法（SWM-AED），并在多个分类器和攻击类型下展示了其鲁棒的性能。", "conclusion": "研究结果表明，SWM-AED在CIFAR-10分类器和攻击类型下的检测性能表现出色，大多数情况下准确率超过62%，最高可达96.5%。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05131", "html_url": "https://arxiv.org/abs/2511.05131", "title": "DL101 神经网络输出和损失函数", "title_en": "DL101 Neural Network Outputs and Loss Functions", "authors": "Fernando Berzal", "background": "从统计学角度来看，用于训练神经网络的损失函数与输出层紧密相关。本文分析了神经网络输出层常见的激活函数，如线性、Sigmoid、ReLU和Softmax，并详细探讨了它们的数学特性及其适用场景。此外，还介绍了几种常见的损失函数（如均方误差、绝对误差和交叉熵损失）与最大似然估计原则的统计联系，以及选定特定损失函数等同于假设特定概率分布的观点，突出了这些函数与底层的广义线性模型（GLMs）之间的关系。此文还考虑了替代输出编码、约束输出和具有重尾分布等实际场景的其他情况。", "innovation": "本文详细分析了神经网络输出层常见的激活函数及其数学特性，并探讨了损失函数与最大似然估计原则之间的紧密关系。同时，将这些数学概念与广义线性模型（GLMs）联系起来，为选择合适的损失函数提供了统计依据。", "conclusion": "选择特定的损失函数等同于对模型输出的概率分布做出假设，增强了我们理解神经网络输出及其统计特性的能力。此外，本文还考虑了实际应用中的一些特例，这有助于更好地理解和使用神经网络的训练过程。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05005", "html_url": "https://arxiv.org/abs/2511.05005", "title": "多代理流匹配协调", "title_en": "Multi-agent Coordination via Flow Matching", "authors": "Dongsu Lee,Daehee Lee,Amy Zhang", "background": "多代理协调的需求是双重的：一是丰富的建模在线下数据中存在的多样联合行为的能力，二是能够高效地在实时环境中进行操作。过去的解决方案往往在这两方面之间做出了牺牲，例如，降噪扩散基的方法能够捕捉复杂的协调性但计算速度较慢，而高斯策略基的方法则在操作上快速但处理多代理互动时容易失效。", "innovation": "MAC-Flow 引入了一个基于流的协调框架，首先学习联合行为的基于流的表示，然后再将其提炼为去中心化的一步执行策略，这既保持了协调性，又使得执行过程高效快速。在多个基准测试中，MAC-Flow 解决了高效性与性能之间的权衡，实现了约14.5倍更快的推理速度，同时保持了良好的性能，其推理速度与之前的高斯策略基的多代理强化学习方法相当。", "conclusion": "MAC-Flow 针对多代理协调中的效率与性能权衡问题，提供了一个有效的解决方案，通过基于流的表示来捕捉复杂的行为，同时保持快速执行的速度，实现了在不同环境和数据集上的良好性能与高效性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05150", "html_url": "https://arxiv.org/abs/2511.05150", "title": "从线性探测到联合加权代币层次结构：一种融合全局和细胞表征的病理性标志物检测基础模型", "title_en": "From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection", "authors": "Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler", "background": "基于AI的生物标志物可以通过从苏木精和伊红（H&E）切片中直接推断分子特征，然而大多数病理基础模型（PFMs）依赖于全局补丁级嵌入，忽视了细胞层次的形态学。这种忽视导致PFMs在疾病检测上的性能不佳，尤其是在细胞层次上有信息缺失的情况下。为了解决这个问题，本研究提出了一种联合加权代币层次结构模型（JWTH），该模型结合了大规模自我监督预训练和细胞为中心的后调优以及注意池化，从而将局部和全局代币融合起来，提升性能和鲁棒性，增强了可解释性，使其更适合数字病理学中的生物标志物检测任务。", "innovation": "提出的JWTH模型通过结合大规模自我监督预训练和细胞为中心的后调优以及注意池化，将局部和全局代币融合，便于疾病的检测。相对于之前的PFMs，JWTH在四个生物标志物和八个组织队列的任务中表现更好，平衡精度提高了8.3%，平均改进了1.2%，同时也提升了病理学检测中的可解释性和鲁棒性。", "conclusion": "JWTH模型通过整合自监督预训练和细胞中心后调优，显著提升了数字病理学中生物标志物检测的性能，有助于提高诊断的准确性和可解释性，推动了基于AI的病理学研究发展。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05053", "html_url": "https://arxiv.org/abs/2511.05053", "title": "在RISC-V GPU上使用自定义指令加速HDC-CNN混合模型", "title_en": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs", "authors": "Wakuto Matsumi,Riaz-Ul-Haque Mian", "background": "基于神经网络的机器学习虽然已经取得了显著进步，但其在训练和推理阶段的高能耗是一个重大难题。Hyperdimensional Computing (HDC) 提供了一种轻量级、仿生的替代方案，能够实现高并行性，但常常在复杂视觉任务上的准确性较低。为了克服这一问题，已经提出了结合HDC和Convolutional Neural Networks (CNNs)的混合加速器，但它们由于普适性和编程性差而受到限制。开源RISC-V架构的崛起为特定领域GPU设计带来了新机会。与传统的专有GPU不同的是，新兴的RISC-V GPU提供了灵活且可编程的平台，适用于诸如HDC等定制计算模型。", "innovation": "我们设计并实施了针对HDC操作优化的自定义GPU指令，使RISC-V GPU能够在混合HDC-CNN工作负载中实现高效处理。实验结果表明，在微基准测试中，使用四种自定义HDC指令实现了高达56.2倍的性能提升，这表明RISC-V GPU在节能和高性能计算方面具有潜在优势。", "conclusion": "本研究设计并实现了优化HDC操作的自定义GPU指令，有效地提升了混合HDC-CNN模型的处理性能，验证了RISC-V GPU在节能高性能计算方面的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05040", "html_url": "https://arxiv.org/abs/2511.05040", "title": "UA-Code-Bench：用于评估乌克兰语代码生成的大语言模型竞赛编程基准", "title_en": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian", "authors": "Mykyta Syromiatnikov,Victoria Ruvinskaya", "background": "评估低资源语言大型语言模型的真实能力仍然是一个挑战，因为现有的许多基准测试聚焦于从英语翻译来的广泛任务，或者仅评估简单的语言理解能力。这项研究介绍了一个新的开源基准UA-Code-Bench，专门用于评估语言模型在乌克兰语中的代码生成和解竞争编程问题的能力。该基准基于Eolymp平台，包括500个从不同难度级别分类的问题。研究使用特定的Eolymp环境和隐藏测试来评估支持生成Python解决方案的13个领先的内部和开源模型，确保代码的正确性。实验结果表明，即使是顶级模型（如OpenAI o3和GPT-5）也仅能解决一半的问题，说明在低资源自然语言中的代码生成具有很高的挑战性。", "innovation": "引入了UA-Code-Bench基准测试，专门为乌克兰语设计，并包含500个从Eolymp平台随机抽取的问题，覆盖从简单到复杂的五个难度级别。使用了13种领先的语言模型，通过使用特定的Eolymp环境进行编码生成和隐藏测试，确保代码的正确性和模型性能的全面评估。这项研究不仅展示了在低资源语言中进行代码生成的能力，还分析了在不同难度级别上的表现，并评估了解决方案的独特性和计算效率，通过生成的解决方案的时间消耗和内存使用来衡量。", "conclusion": "这项研究展示了竞赛编程基准在评估大型语言模型，特别是低资源语言方面的重要性。它为多语言代码生成和增强推理模型的未来研究铺平了道路。该基准以及相关的数据解析、准备、代码生成和评估脚本可以在以下链接获取。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05156", "html_url": "https://arxiv.org/abs/2511.05156", "title": "SmartSecChain-SDN：面向高性能软件定义网络的集成了区块链智能平台", "title_en": "SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for Secure and Efficient Software-Defined Networks", "authors": "Azhar Hussain Mozumder,M. John Basha,Chayapathi A. R", "background": "随着越来越多的传统网络被转换为软件定义网络（SDN），保障这些网络的安全性和智能控制交通的需求变得更为迫切。为了实现这一点，本文提出了SmartSecChain-SDN平台，该平台结合了基于机器学习的入侵检测、基于区块链的日志存储和应用感知优先级策略。", "innovation": "该研究提出了一种新颖且扩展性良好的方法，旨在提高网络安全、合规性和下一代可编程网络的管理。主要创新点包括：1) 使用先进的机器学习算法（随机森林、XGBoost、CatBoost和CNN-BiLSTM）进行实时、精准且低误报的网络入侵检测；2) 基于Hyperledger Fabric的区块链技术，提供了安全、可扩展和隐私保护的日志存储机制，确保安全记录不被篡改，并允许全面分析；3) 基于应用的服务质量（QoS）规则和流量整形，能够优先保障关键服务，降低非必要流量的优先级，以提高网络性能和安全性；4) Mininet用于实时SDN场景的模拟，与OpenDaylight和Ryu控制器兼容，经过InSDN数据集测试证明了其实用性和有效性。", "conclusion": "SmartSecChain-SDN平台全面解决了SDN系统的保护、安全性和增强问题。研究提出的平台方案提供了一种有创新性的网络安全保障方式，适用于确保和提升下一代软件定义网络的安全及合规要求。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05165", "html_url": "https://arxiv.org/abs/2511.05165", "title": "使用逆向工程和大型语言模型从源代码生成软件架构描述", "title_en": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model", "authors": "Ahmad Hatahet,Christoph Knieke,Andreas Rausch", "background": "现代软件系统的内在复杂性需要软件架构描述（SADs）来管理。SADs有助于高层次的架构推理、指导设计决策，并促进不同利益相关者之间的有效沟通。然而，在实践中，SADs往往缺失、过时或与系统实际实现严重不一致。因此，开发者不得不直接从源代码中推导出架构见解，这需要大量时间，增加认知负担，并减慢新开发人员的上手速度，最终导致系统清晰度逐渐下降。", "innovation": "通过结合逆向工程（RE）技术和大型语言模型（LLM），我们提出了一种半自动化方法，从源代码生成SADs。此方法通过提取全面的组件图、使用提示工程技术过滤架构相关内容，并基于底层代码逻辑生成状态机图来建模组件行为，从而恢复静默和行为的架构视图。这些产生的视图表示提供了一种可扩展且维护性高的替代传统手动架构文档的方法。研究成果表明，LLM在两个方面具有强大能力：1)抽取组件图，减少对人类专家参与的依赖；2)通过少量提示工程技术增强领域特定知识，准确表示复杂的软件行为。", "conclusion": "这些发现表明了一条减少手动努力并增强系统理解及长期可维护性的可行路径。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05250", "html_url": "https://arxiv.org/abs/2511.05250", "title": "使用检测器和深度SPD双胞胎网络的准确在线动作和手势识别系统", "title_en": "Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks", "authors": "Mohamed Sanim Akremi,Rim Slama,Hedi Tabia", "background": "连续运动识别是一项热门研究课题，因为在实际应用案例中更为实用。最近，基于骨骼的方法变得越来越流行，展示了使用此类3D动态数据的强大功能。但是，大多数这些工作都集中在基于片段的识别上，并不适合在线场景。", "innovation": "本文提出了一种基于检测器和深度SPD双胞胎网络的在线识别系统，由两个主要部分组成：一个检测器和一个分类器。该系统使用Semi-Positive Definite (SPD)矩阵表示和Siamese网络。通过SPD矩阵提供的强大统计表示和Siamese网络学习它们的语义相似性，检测器能够预测未分割序列中的运动时间间隔。此外，这确保了分类器在每个预测间隔内识别运动的能力。所提出的检测器具有灵活性，能够连续识别动能状态。", "conclusion": "在手部手势和身体动作识别基准上进行了广泛的实验，证明了我们提出的在线识别系统具有高精度，并在大多数情况下优于最先进的性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05229", "html_url": "https://arxiv.org/abs/2511.05229", "title": "4D3R：从单目视频中动态场景的运动感知神经重建与渲染", "title_en": "4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos", "authors": "Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee", "background": "单一相机视角下的动动态场景视图合成仍然是计算机视觉和图形学中的一个基本挑战。尽管最近在3D表示方面取得的进展，如神经辐射场（NeRF）和3D高斯散点（3DGS），在静态场景中显示出了有希望的结果，但对于动态内容来说，它们存在挑战，并且通常依赖于预计算的摄像机姿态。", "innovation": "4D3R 提出了一个无需摄像机姿态的动态神经渲染框架，通过两阶段方法将静态和动态成分分离。创新点包括：1. 运动感知的束调整（MA-BA）模块，结合了基于变换器的学习先验与SAM2，用于鲁棒的动态物体分割，以实现更准确的摄像机姿态优化；2. 有效的运动感知高斯散点（MA-GS）表示，使用带有变形场MLP和线性混合皮肤的控制点，以建模动态运动，显著降低计算成本同时保持高保真重建。", "conclusion": "在真实世界动态数据集上的广泛实验表明，我们的方法在具有大型动态物体的挑战性场景中相对于最先进的方法可以实现高达1.8dB的PSNR改进，同时与之前同类方法相比计算需求降低5倍。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05263", "html_url": "https://arxiv.org/abs/2511.05263", "title": "OregairuChar: My Teen Romantic Comedy SNAFU 角色出现频率分析的基准数据集", "title_en": "OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU", "authors": "Qi Sun,Dingju Zhou,Lina Zhang", "background": "角色出场频率分析对于理解叙事结构、角色主导地位和故事情节进展至关重要，特别是在动画领域。为了提供一个适合此类分析的数据集，本文介绍了OregairuChar，这是一个针对动画系列《我的同桌不是我初恋》的出场频率分析基准数据集。", "innovation": "OregairuChar数据集包含1600幅手动挑选的第三季框架，涵盖11位主要角色的2860个边界框标注，并通过基准检测模型的性能评估来支持细粒度的、按集篇分析角色在时间上的存在情况。这种分析揭示了角色主导地位的模式及其在叙事中的演变。", "conclusion": "通过强调角色出场频率，OregairuChar为探索计算叙事动态和角色为中心的叙事模式提供了有价值的数据资源。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05171", "html_url": "https://arxiv.org/abs/2511.05171", "title": "生物声学基础模型的模型合并改善了零样本泛化能力", "title_en": "Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models", "authors": "Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi", "background": "生物声学中的通用模型可跨物种和任务进行推广，被视为该领域的新兴前沿。NatureLM 是此类模型的一个突出例子，其域特定微调在生物声学基准测试中的性能十分优异。然而，这种微调也导致了在指令遵循灵活性方面的问题，例如在同时请求常见的名字和科学的名字时，NatureLM 的准确率大幅下降。", "innovation": "本文通过简单的模型合并策略，将NatureLM与其基础语言模型进行插值，从而恢复了指令遵循能力，同时仅轻微损失了领域专业知识。此外，合并后的模型在未知物种的闭集零样本分类中展开了显著的通用能力，实现了超过200%的相对改进，并打破了现有记录。", "conclusion": "最终结果表明，合并后的模型在未知物种的闭集零样本分类上表现出明显更强的通用性，设定新的基准标准，证明了通过简单的模型合并策略可以改善生物声学基础模型的零样本泛化能力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05266", "html_url": "https://arxiv.org/abs/2511.05266", "title": "将基于分数的扩散模型与机器学习增强的定位集成以实现地质碳储存中的高级数据同化", "title_en": "Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage", "authors": "Gabriel Serrão Seabra(1, 2),Nikolaj T. Mücke(1),Vinicius Luiz Santos Silva(2, 4),Alexandre A. Emerick(2),Denis Voskov(1, 5),Femke Vossepoel(1) ((1) Faculty of Civil Engineering and Geosciences, TU Delft, Delft, Netherlands, (2) Petroleo Brasileiro S.A. (Petrobras), Rio de Janeiro, Brazil, (4) Imperial College London, London, United Kingdom, (5) Department of Energy Resources Engineering, Stanford University, CA, USA)", "background": "准确表征地下异质性对于地质碳储存（GCS）项目的安全和有效实施至关重要。本文探讨了如何通过将分数扩散模型与机器学习增强的空间定位集成到地质碳储存数据同化中的方法，特别是在岩层发育的储层中注入二氧化碳期间。", "innovation": "本文提出了一种机器学习增强的定位框架，通过大规模区间（$N_s = 5000$）渗透率和由扩散模型生成的状态以及简单的机器学习算法计算的状态来改进Ensemble Smoother with Multiple Data Assimilation (ESMDA)的协方差估计。这种方法通过应用机器学习算法在一个由地质统计模型FLUVSIM生成的先前的通道化渗透率场中，实现了显著维持更多的样本方差，同时达到与未应用定位相似的数据匹配质量。", "conclusion": "该框架对于GCS项目具有实际意义，有助于提高风险评估中的不确定性量化可靠性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05269", "html_url": "https://arxiv.org/abs/2511.05269", "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "title_en": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "authors": "Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu", "background": "大型语言模型（LLMs）在工具使用、规划和决策能力上表现出了强大的自主能力，这导致它们在众多任务中得到了广泛应用。然而，随着任务复杂性的增加，多Agent LLM系统越来越多地被用作协作解决问题的工具。尽管如此，这些系统在安全性与安全性方面的讨论仍然较少。现有的基准测试和数据集主要集中在单Agent场景，无法捕捉到多Agent动态和协作的独特脆弱性。", "innovation": "该研究提出了TAMAS，一个用于评估多Agent LLM系统鲁棒性和安全性的基准测试。TAMAS 包含五种不同的场景，涵盖了六种攻击类型和300个敌对实例，以及100个无害任务。研究还引入了有效的鲁棒性评分（ERS）来评估这些框架在安全性与任务有效性之间的权衡。研究成果表明，多Agent系统对抗攻击的脆弱性很高，强调了更强防御措施的迫切需求。", "conclusion": "TAMAS 为系统性研究和提高多Agent LLM系统的安全性提供了基础。研究发现多Agent系统对敌对攻击特别脆弱，这突显了构建更强防御措施的迫切性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05265", "html_url": "https://arxiv.org/abs/2511.05265", "title": "一种端到端的深度强化学习方法求解带无人机的旅行商问题", "title_en": "An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones", "authors": "Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji", "background": "随着卡车-无人机协同系统的出现，带无人机的旅行商问题（TSP-D）已成为经典路径优化问题的重要扩展。同步的车辆协调有望实现显著的操作效率和降低环境影响，但同时也带来了超越传统优化范式的NP-hard组合复杂性。深度强化学习提供了一种理论基础框架，通过自我监督的策略学习和自适应决策来解决TSP-D本身的挑战。", "innovation": "本文提出了一种基于层级Actor-Critic的深度强化学习框架来解决TSP-D问题，该框架由一个借鉴Transformer的编码器和一个高效的Minimal Gated Unit解码器组成。编码器整合了一种新颖的、优化过的k最近邻稀疏注意机制，特别强调相关空间关系，并通过集成全局节点特征进一步增强。Minimal Gated Unit解码器处理这些编码表示以高效生成解序列。整个框架在一个异步优势演员评论家范式内运行。实验结果显示，该模型在计算时间较短的情况下，对不同规模（N=10到100）的TSP-D基准实例可以获得竞争性的或更优解，同时相比于高性能启发式算法和现有强化学习方法，训练时间显著减少，显示出其在训练效率方面的明显优势。", "conclusion": "提出的方法在解决带无人机的旅行商问题方面显示出显著的优越性，尤其在训练时间和最终性能方面。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05254", "html_url": "https://arxiv.org/abs/2511.05254", "title": "基于量子门的实值全局优化量子遗传算法", "title_en": "A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization", "authors": "Leandro C. Souza,Laurent E. Dardenne,Renato Portugal", "background": "该研究提出了一种基于量子门的量子遗传算法(QGA)用于实值全局优化。之前的遗传算法使用经典编码和量子遗传算法利用量子特性来进行优化，但实值域的优化需要特殊的处理方法来实现量子计算的优势。该研究通过量子电路测量结果的二进制离散化来表示个体，并通过量子采样评估适应度，显示出量子资源（如叠加和纠缠）对优化过程的重要性。", "innovation": "该算法提出了两种量子电路模型：固定深度和可变深度，分别支持统一的电路复杂度和适应性结构进化。此外，研究通过引入个体间纠缠加速了早期收敛，并通过对比包含和不包含Hadamard门的不同量子门集，展示了叠加在基准函数上的持续改进效果。这一创新使得量子遗传算法更加适用于实值全局优化，并证明了量子叠加和纠缠对搜索动态的增强作用。", "conclusion": "研究结果表明，量子叠加和纠缠能够提升进化量子算法的搜索动态，以此为基础的量子遗传算法是一种有潜力用于量子增强全局优化的新框架。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05271", "html_url": "https://arxiv.org/abs/2511.05271", "title": "DeepEyesV2：迈向能动的多模态模型", "title_en": "DeepEyesV2: Toward Agentic Multimodal Model", "authors": "Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu", "background": "传统的多模态模型仅能理解和处理文本和图像信息，本研究指出这些模型还应能够主动调用外部工具，如代码执行环境和网络搜索，并将这些操作整合到推理过程中。在此之前的工作发现，直接使用强化学习不能有效地诱发外部工具使用的模式，因此提出了双阶段训练策略：首先是冷启动阶段用来建立工具使用模式，其次是强化学习阶段用来进一步细化工具调用。", "innovation": "本研究引入了名为DeepEyesV2的新模型，并探索了从数据构建、训练方法和模型评估三个角度构建能动多模态模型的方法。研究发现通过创建涵盖工具使用有益示例的多样化、中等难度的数据集可以提高模型的性能。此外，提出了一种名为RealX-Bench的综合基准测试，用于评估多模态推理的综合能力，包含了感知、搜索和推理等多个方面的能力。DeepEyesV2在RealX-Bench以及其他代表性基准测试中表现出色，进一步展示了其在真实世界理解和推理任务中的有效性。", "conclusion": "DeepEyesV2模型证明了其能够根据不同任务适配性的工具调用行为，通过强化学习进一步实现了复杂的工具组合，并能够在上下文中选择性地调用工具。本研究希望能够为社区在开发能动多模态模型方面提供指导。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05299", "html_url": "https://arxiv.org/abs/2511.05299", "title": "LiveStar: 实时流媒体助手以实现真实世界中的在线视频理解", "title_en": "LiveStar: Live Streaming Assistant for Real-World Online Video Understanding", "authors": "Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu", "background": "尽管在离线视频理解方面取得了显著进展，现有的在线视频大语言模型（Online Video-LLMs）在同时处理连续的逐帧输入和确定最佳响应时机方面通常表现不佳，这往往导致实时响应性和叙事连贯性降低。为此论文介绍了LiveStar，这是一种能够通过自适应流解码实现始终在线的主动响应的创新性实时流媒体助理。", "innovation": "LiveStar引入了（1）一种训练策略，实现对变长视频流的增量视频-语言对齐，以保持动态变化帧序列中的时间一致性；（2）一种响应静默解码框架，通过单次前向验证来确定最佳的主动响应时机；（3）通过峰末记忆压缩和流式键值缓存实现内存感知加速，在长至10分钟的视频上进行在线推断， inference速度提升了1.53倍。", "conclusion": "大规模实验结果显示，LiveStar 在三个基准上的性能领先，与目前的在线视频大语言模型相比，在语义正确性上平均提高了19.5%，响应时间差减小了18.1%，同时在所有五个OmniStar任务中的FPS提升了12.0%。其模型和数据集可在此访问：this https URL."}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05179", "html_url": "https://arxiv.org/abs/2511.05179", "title": "无一模型通吃：基于图神经网络和基础模型发现时空预测权衡", "title_en": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models", "authors": "Ragini Gupta,Naman Raina,Bo Chen,Li Chen,Claudiu Danilov,Josh Eckhardt,Keyshla Bernard,Klara Nahrstedt", "background": "现代物联网部署用于环境感知的应用产生了大量时空数据，支持如预测等下游任务，这些任务往往依靠机器学习模型。现有的过滤和策略部署技术优化了收集数据量，但忽视了采样频率和空间覆盖差异对下游模型性能的影响。在许多预测模型中，通过从额外传感器获取数据可以对预测进行去噪以提供更宽广的空间背景。然而，采样频率、空间覆盖和不同预测模型架构之间的相互作用仍然没有被充分探索。", "innovation": "本文系统研究了在不同空间传感器节点密度和采样间隔下，经典模型（VAR）、神经网络（GRU，Transformer）、时空图神经网络（STGNN）和时间序列基础模型（TSFMs：Chronos Moirai，TimesFM）的时空预测表现，使用无线传感器网络中的实际温度数据。研究发现，当传感器部署稀疏且采样率适中时，STGNN有效，利用图结构编码空间相关性来弥补有限的覆盖。与之对比，TSFMs在高频率下表现竞争但当邻近传感器的空间覆盖减少时性能下降。关键的是，多变量TSFM Moirai通过直接学习跨传感器依赖性表现出最佳性能。这些发现提供了在时空系统中构建高效预测流水线的实际指导。所有模型配置、训练代码、数据集和日志均作为开源代码发布，确保可重现性：此链接 [此 https URL]。", "conclusion": "这些研究结果为在时空系统中构建高效预测流水线提供了有益的实践经验。本研究揭示了基于图神经网络和基础模型的时空预测权衡，并强调了不同模型架构在不同条件下的优势和劣势。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05308", "html_url": "https://arxiv.org/abs/2511.05308", "title": "重新思考3D点云生成的度量标准和扩散架构", "title_en": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation", "authors": "Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière", "background": "随着3D点云在现代技术中成为基石，对复杂的生成模型和可靠的评估指标的需求大幅增加。现有的一些度量标准，尤其是基于Chamfer Distance（CD）的度量标准，对缺陷不够稳健，无法准确捕捉几何精确度和局部形状一致性，这在用于质量指标时是一个问题。因此，论文中首先揭示了这些常用的度量标准，并指出在距离计算前引入样本对齐 prior 和将CD替换为Density-Aware Chamfer Distance (DCD)是一种简单而关键的方法，可以确保3D点云生成模型评估指标的一致性和稳健性。", "innovation": "引入了Surface Normal Concordance (SNC)这一新颖的度量标准，通过比较估算的点法线来估算表面相似性，这与现有的主要对比3D欧几里得坐标的方法有所不同。SNC与传统度量综合，提供了一个更全面的生成样本质量评估。并且利用了基于点云分析的最近进展，如serialized patch attention，提出了一种新的用于生成高保真度3D结构的Diffusion Point Transformer架构，该架构在ShapeNet数据集上的实验和比较中表现出色，生成的3D点云质量显著提升，达到最新的技术水平。", "conclusion": "通过广泛的实验和比较，验证了提议的模型在3D点云生成方面优于先前的解决方案，尤其是在生成点云的质量方面，实现了新的最先进的技术水平。相关代码可以在指定的链接处获取。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05320", "html_url": "https://arxiv.org/abs/2511.05320", "title": "从刑事法庭判决中自动提取法院认定事实", "title_en": "What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions", "authors": "Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal", "background": "刑事司法行政数据中关于犯罪行为的信息有限，但欧洲大陆法院的判决中包含大量关于犯罪行为的描述，这些描述基本信息未被充分利用。本文研究了从公开获取的斯洛伐克法院判决中提取这些描述的可行性。", "innovation": "文章采用了两种不同的方法：传统的正则表达式和大型语言模型（LLMs），并通过提示调用Gemini Flash 2.0模型来提取描述，显示出显著优于传统基于正则表达式的方法的性能。", "conclusion": "高级正则表达式方法在97%的情况下成功提取描述，LLMs在98.75%的情况下成功提取描述，结合两者在99.5%的情况下成功提取描述。法律学生的评估显示这两种高级方法准确度约为90%，而传统方法仅为34.5%。LLMs在91.75%的案例中与人类标注完全一致，结合高级正则表达式和LLMs达到了92%的准确度。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05363", "html_url": "https://arxiv.org/abs/2511.05363", "title": "社区学院中的AI素养：基于情境和互动教学方法的教学人员视角", "title_en": "AI Literacy for Community Colleges: Instructors' Perspectives on Scenario-Based and Interactive Approaches to Teaching AI", "authors": "Aparna Maya Warrier,Arav Agarwal,Jaromir Savelka,Christopher A Bogart,Heather Burte", "background": "随着人工智能技术越来越多地融入日常生活，AI素养（包括评估和理解AI系统的能力）已成为关键技能。然而，高等教育中有效且可扩展的教学方法仍然有限，特别是在STEM之外的领域。本文研究了社区学院教师如何评估针对非STEM学习者的交互式、无代码AI素养资源，指出在提高非STEM领域中学生AI概念的可及性和相关性方面存在的挑战，如脚手架设计、无障碍性和多模态支持等问题。研究通过四个焦点小组讨论了教师反馈，并通过评估教学支持材料的任务显示，教师更偏好交互式演示而不是传统教育材料如概念指南或讲义。", "innovation": "研究设计了AI使用者这一互动在线课程，通过现实世界场景中的场景化活动来引入核心AI概念。此课程强调了构建现实世界模拟任务和实验性学习的重要性，并在课程设计中特别关注了脚手架设计、无障碍性和多模态支持。此外，研究通过排名任务评估了教学支持材料的偏好，结果显示教师更愿意使用交互演示而非传统教材。", "conclusion": "研究为广大学生设计AI概念的可及性和相关性提供了教师视角的见解，并且对能够适应不同教学环境的AI素养工具的设计提供了指导，强调了鼓励高等教育中批判性反思的必要性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05394", "html_url": "https://arxiv.org/abs/2511.05394", "title": "AI辅助AR组装：物体识别与计算机视觉在增强现实辅助组装中的应用", "title_en": "AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly", "authors": "Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin", "background": "本研究介绍了一种由AI辅助的增强现实(AR)组装流程，使用基于深度学习的物体识别来识别不同的组装组件，并逐步骤显示指示。AR系统可以根据实时检测到的组件位置，显示每个组装步骤中对应的组件边界框及其正确的放置位置。这项技术通过将组装说明与相关组件实时位置关联，消除了每次组装前需要手动查找、分类或标记不同组件的需求。", "innovation": "该研究的创新在于提出了一种结合AI技术的AR辅助组装流程，通过对物体进行深度学习识别，能够实时显示组件的边界框位置及正确的放置位置，从而减少了传统组装过程中的许多繁琐步骤，提高了组装效率。", "conclusion": "通过一个LEGO雕塑组装案例研究，演示了使用物体识别技术进行AR辅助组装的可行性，证明了该技术在实际应用中的潜在价值。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05399", "html_url": "https://arxiv.org/abs/2511.05399", "title": "使用音乐基础模型的鲁棒神经音频指纹技术", "title_en": "Robust Neural Audio Fingerprinting using Music Foundation Models", "authors": "Shubhr Singh,Kiran Bhat,Xavier Riley,Benjamin Resnick,John Thickstun,Walter De Brouwer", "background": "现代媒体平台（例如TikTok）上，恶搞、压缩和篡改的音乐广泛存在，这推动了更稳健的音频指纹识别技术的发展，以识别音乐录音的来源。本文旨在开发和评估新的神经音频指纹技术，以提高其鲁棒性。", "innovation": "本文在神经指纹技术方面做出了两个贡献：（1）使用预训练的音乐基础模型作为神经架构的基础，（2）扩展数据增强技术，以在各种音频篡改下训练指纹识别模型，包括时间拉伸、音调变换、压缩和滤波。", "conclusion": "实验结果表明，使用音乐基础模型提取的指纹（如MuQ，MERT等）的表现优于从零开始训练或在非音乐音频上预训练的模型。进一步的段级评估显示了它们在细分管理方面的准确定位指纹匹配的能力，这是一个重要而实用的功能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05404", "html_url": "https://arxiv.org/abs/2511.05404", "title": "多模态基础模型在严重非结构化环境下的闭环检测", "title_en": "Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments", "authors": "Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato", "background": "在GNSS受限的环境中，如太空探索场景下，当前的SLAM算法存在关键挑战。视觉重识别由于纹理较弱和混淆而容易出错，而基于LiDAR的方法则受到稀疏性和混淆的困扰。", "innovation": "本文提出了一种称为MPRF的多模态框架，该框架结合了基于转换器的基础模型用于视觉和LiDAR模态，以实现此类环境中可靠的闭环检测。与以往仅涉及检索的方法不同，MPRF将两阶段视觉检索与显式6-DoF姿态估计相结合，利用DINOv2特征与SALAD聚合进行高效的候选筛选，并结合SONATA LiDAR描述符进行几何验证。实验结果表明，与最先进的检索方法相比，MPRF在精度上表现出色，同时增强了在低纹理区域的姿态估计鲁棒性。", "conclusion": "MPRF提供了解决SLAM后端可解释对应关系的能力，实现了精度、效率和可靠性的良好平衡，展示了基础模型在统一视觉识别和姿态估计中的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05420", "html_url": "https://arxiv.org/abs/2511.05420", "title": "ProDER：适用于不断变化的智能电网故障预测的持续学习方法", "title_en": "ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids", "authors": "Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo", "background": "随着智能电网的发展以应对日益增长的能源需求和现代运营挑战，准确预测故障变得尤为重要。然而，现有的基于AI的故障预测模型在需要适应新故障类型和运营区域的不断变化环境中难以确保可靠性。", "innovation": "本文提出了一种智能电网环境下的持续学习框架，以使模型与环境共同进化。通过四个基于类别增量和领域增量学习的现实评估场景，重现已变化的电网条件。在此基础上引入了一种名为ProDER的统一回放方法，该方法综合了原型特征正则化、逻辑蒸馏和原型指导的回放记忆。ProDER在测试的持续学习技术中表现最佳，故障类型预测的准确率下降仅为0.045，故障区域预测的准确率下降为0.015。这些结果表明，持续学习在智能电网中实现可扩展的实时故障预测的实用性。", "conclusion": "持续学习对于智能电网中的大规模、实际的故障预测具有可行性。ProDER方法展示了在适应新故障类型和运营区域变化方面的优越性能，证明了其在智能电网中的实际应用价值。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05350", "html_url": "https://arxiv.org/abs/2511.05350", "title": "通过噪声增强自编码器对齐音乐表示", "title_en": "Perceptually Aligning Representations of Music via Noise-Augmented Autoencoders", "authors": "Mathias Rose Bjare,Giorgia Cantisani,Marco Pasini,Stefan Lattner,Gerhard Widmer", "background": "本文探讨了通过训练自编码器从其编码的噪声版本重建输入并结合感知损失，可以生成符合感知层级结构的编码。研究显示，与传统训练相比，这种方式能捕捉到更为粗略的、感知上显著的信息。此外，提出的方法在估计音乐音高意外度和预测音乐聆听过程中EEG-脑响应方面表现出更好的潜在扩散解码性能。", "innovation": "本文的创新之处在于提出了一种新的训练方法，即通过噪声增强自编码器，并结合感知损失来训练，以生成符合感知层级结构的编码。实验结果表明，这种方法在提取音乐感知显著信息以及进行潜在扩散解码任务中表现突出。", "conclusion": "通过研究发现，噪声增强的自编码器训练方法能够生成符合感知层级结构的编码，并且这种编码在估计音乐音高的意外度和预测音乐聆听过程中EEG-脑响应方面表现出更好的性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05361", "html_url": "https://arxiv.org/abs/2511.05361", "title": "多模态多层结构模型：针对多语言个体的心理词典", "title_en": "A multimodal multiplex of the mental lexicon for multilingual individuals", "authors": "Maria Huynh,Wilder C. Rodrigues", "background": "长期以来，双语被认为是额外的认知负担，可能会阻碍语言和智力发展。然而，过去三十年的研究表明，这个观点已经发生了显著变化。多项研究表明，双语者的语言和认知任务表现通常优于单语者，尤其是在学习额外语言方面。因此，本研究旨在探讨多语言者心理词典的结构，并研究其如何影响另一个语言的学习，特别是视觉输入对语言习得的影响。", "innovation": "本研究创新性地引入了多模态和多层次的心理词典模型。借鉴了Stella等人（2018）关于人类爆炸性学习的研究，以及Dijkstra和van Heuven（2002）的双向激活（BIA+）框架，该研究提出了一个包含词汇表层、视觉输入层的多层网络模型，以考察视觉输入如何影响多语言者的语言习得效果。研究设计上引入了一个视觉输入层，将视觉信息与多语言心理词典中的语言表示链接起来，从而丰富了以往的研究。", "conclusion": "本研究通过实验设计验证了视觉输入如何影响多语言者在翻译任务中的表现，旨在揭示遗产语言在学习另一种语言中的作用，结果表明，视觉输入能够显著提高参与者对目标语言的掌握程度和准确性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05385", "html_url": "https://arxiv.org/abs/2511.05385", "title": "TeaRAG: 一种高效的主动检索增强生成框架", "title_en": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework", "authors": "Chao Zhang,Yuhao Wang,Derong Xu,Haoxin Zhang,Yuanjie Lyu,Yuhao Chen,Shuochen Liu,Tong Xu,Xiangyu Zhao,Yan Gao,Yao Hu,Enhong Chen", "background": "检索增强生成（RAG）通过外部知识来增强大型语言模型（LLMs）的可靠性。主动RAG采用自主的多轮检索和推理来解决问题，虽然通过强化学习改进了性能，但检索和推理过程会产生大量令牌，导致效率低下，牺牲了准确性。", "innovation": "TeaRAG提出了一个高效的主动检索增强生成框架，通过以下创新点解决了上述问题：1）采用了基于图检索的Chunk级语义检索，结合紧凑的三元组，构建了知识关联图，并利用个性化PageRank突出显示图中的关键信息，从而减少每次检索的令牌数量。2）提出了迭代过程感知直接偏好优化（IP-DPO），采用知识匹配机制评估知识充足性，同时惩罚过长的推理步骤，以生成高质量的偏好对数据集，并支持迭代DPO提高推理简明性。", "conclusion": "在六个数据集中，TeaRAG在LLama3-8B-Instruct和Qwen2.5-14B-Instruct上分别提高了1%到4%的准确匹配（Exact Match），同时减少了61%到59%的输出令牌。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05396", "html_url": "https://arxiv.org/abs/2511.05396", "title": "分布鲁棒离动理强化学习的样本复杂性与在线交互", "title_en": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "authors": "Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu", "background": "当前的强化学习（RL）研究主要将训练和部署环境的动态视为一致的，即训练和部署动态之间的差异被忽略。然而，在实际应用中，这种假设往往不成立，因为训练和部署过程中的动态可能不同。这种情况下，RL 可以视为在鲁棒马尔可夫决策过程（RMDP）中学习，其中过渡动态的不确定性被纳入考虑。现有文献大多假设可以访问生成模型或提前收集覆盖部署环境状态空间的数据集，这绕过了探索的挑战。", "innovation": "本文研究了一个更现实和具有挑战性的环境，其中代理仅能与训练环境进行在线交互。为了捕捉在线RMDP中探索的基本困难，引入了上界访问比这一新型度量，衡量训练动态与部署动态之间的差异。研究表明，如果上界访问比无界，则在线学习变得指数级困难。此外，提出了一种基于 $f$ 分散度的过渡不确定性下的首个计算高效算法，该算法在在线RMDP环境中实现了次线性后悔。最后，通过全面的数值实验验证了理论结果。", "conclusion": "本文提出了在线RMDP中计算高效且能够实现次线性后悔的第一种算法，该算法针对基于 $f$ 分散度的过渡不确定性。此外，还建立了匹配的后悔下界，证明了该算法实现了上界访问比和交互轮次的最佳依赖性。通过全面的数值实验验证了理论结果。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05452", "html_url": "https://arxiv.org/abs/2511.05452", "title": "自适应加权和采样方法用于物理信息神经网络", "title_en": "Self-adaptive weighting and sampling for physics-informed neural networks", "authors": "Wenqian Chen,Amanda Howard,Panos Stinis", "background": "物理信息深度学习模型在解决偏微分方程（PDEs）方面展现出潜力，但在处理复杂问题时仍面临挑战，往往导致较低的准确性和效率。", "innovation": "提出了一种结合自适应采样和加权的方法来提升物理信息神经网络（PINNs）的性能。该方法通过识别解在快速变化区域的训练点来进行自适应采样，并通过平衡训练点的收敛速度来进行自适应加权。", "conclusion": "结合两者策略，所提出的框架能够一致地提高预测准确性和训练效率，提供了解决PDEs的更稳健方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05475", "html_url": "https://arxiv.org/abs/2511.05475", "title": "AI素养评估再探：面向实际职业任务的方法", "title_en": "AI Literacy Assessment Revisited: A Task-Oriented Approach Aligned with Real-world Occupations", "authors": "Christopher Bogart,Aparna Warrier,Arav Agarwal,Ross Higashi,Yufan Zhang,Jesse Flot,Jaromir Savelka,Heather Burte,Majd Sakr", "background": "随着人工智能（AI）系统在专业环境中变得普遍，工人（常常没有STEM背景）需要具备有效且负责任地使用这些工具的技能，即成为AI素养较高的人。然而，当前对AI素养的定义和评估往往侧重于基础技术知识，如编程、数学和统计，而忽视了解释模型输出、选择工具或识别伦理问题等实际知识。这导致在评估一个人在实际工作中的AI素养时存在明显差距。本文提出了一种工作任务导向的AI素养评估模型，旨在衡量AI工具在专业环境中的有效使用能力。该研究在美海军机器人训练项目中开发了一个新的AI素养评估工具，并提出了配套的形成性评估方法。", "innovation": "本文提出了一种工任务导向的AI素养评估模型，旨在更为全面地评估AI工具在专业环境中的实际应用能力。研究开发了一个新的评估工具，并通过机器人训练项目中的竞赛和模拟任务进行测试，发现情景任务在评估实际应用AI素养方面优于以前的研究或自开发的测试工具。", "conclusion": "在培训涉及AI工作的人员时，教育者应考虑使用强调高度具体实用技能的评估工具，尤其是为没有技术背景的工人准备AI集成角色时。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05459", "html_url": "https://arxiv.org/abs/2511.05459", "title": "SWE-Compass：朝向大型语言模型自主编码能力统一评估的迈进", "title_en": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models", "authors": "Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu", "background": "当前评估大型语言模型（LLMs）在软件工程中的应用主要面临任务覆盖范围狭窄、语言偏见以及与实际开发者工作流程不充分对齐的问题。现有的基准测试往往集中于算法问题或Python特定的错误修复，忽略了软件工程中的关键维度。由此明确了SWE-Compass这一全面基准引入的必要性，它将异构代码相关评估统一于一个结构化且与生产线对齐的框架中。SWE-Compass覆盖了8种任务类型、8种编程场景和10种编程语言，总计2000个高质实例，这些实例来自真实的GitHub_pull_requests，并通过系统性筛选和验证进行改进。", "innovation": "引入了一个全面的基准SWE-Compass，它将不同类型的代码评估统一在一个结构化和生产对齐的框架中。SWE-Compass涵盖了8种任务类型、8种编程场景和10种编程语言，包含了2000个高质量的实例，这些实例均精选自真实的GitHub_pull_requests并经过系统的筛选和验证。基准测试使用两种代理框架，SWE-Agent和Claude Code，评估了十种最先进的LLM，揭示了任务类型、语言和场景的清晰难度层级。通过与实际开发者实践对齐，SWE-Compass为诊断和促进大型语言模型的代理编码能力提供了严格的、可重复的基础。", "conclusion": "SWE-Compass为大型语言模型的代理编码能力提供了一个严谨且可重复的基准框架，有助于诊断并推动这一领域的进步。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05442", "html_url": "https://arxiv.org/abs/2511.05442", "title": "APP: 加速路径修补与特定任务裁剪", "title_en": "APP: Accelerated Path Patching with Task-Specific Pruning", "authors": "Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff", "background": "电路发现是许多机制可解释性流水线的关键步骤。现有的方法，如路径修补，计算成本高且对于较小的模型深度分析有限。", "innovation": "提出了一种名为加速路径修补（APP）的混合方法，利用我们新颖的对比注意力头剪枝方法极大地减少了电路发现方法的搜索空间。提出了对比FLAP剪枝算法，结合因果中介分析技术，赋予任务特定注意力头更高的剪枝分数，从而提高稀疏模型的性能，与传统的剪枝技术相比具有优越性。尽管对比FLAP在保留低稀疏比率下被传统剪枝算法删除的任务特定头方面非常成功，但单独使用对比FLAP找到的电路太大，无法满足电路分析所需的最小约束。APP首先应用对比FLAP将电路发现算法所需的搜索空间平均减少了56%，然后应用传统的路径修补，相比直接应用于密集模型的路径修补，速度提升59.63%-93.27%。", "conclusion": "尽管APP提供了显著的计算节省，但由APP获得的电路表现出与之前建立的路径修补电路相似的重叠和性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05483", "html_url": "https://arxiv.org/abs/2511.05483", "title": "DGTN：具有扩散注意门控机制的图增强变换器用于酶DDG预测", "title_en": "DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction", "authors": "Abigail Lin", "background": "预测氨基酸突变对酶热力学稳定效应（DDG）是蛋白质工程和药物设计中的基础。尽管最近的深度学习方法显示出潜力，但它们通常独立处理序列和结构信息，无法捕捉局部结构几何与全局序列模式之间的复杂耦合。", "innovation": "提出了DGTN（扩散图变换网络），这是一种新颖的架构，通过扩散机制同时学习图神经网络（GNN）的结构性先验权重和变换器注意力。关键创新在于双向的扩散过程，其中GNN衍生的结构嵌入通过可学习的扩散核引导变换器注意力，变换器表示通过注意力调节的图更新来完善GNN消息传递。理论分析证明此次学习方案在数学上优于独立处理，且差错界得到改进。", "conclusion": "DGTN在ProTherm和SKEMPI基准测试中实现了最先进的性能（皮尔逊相关系数 = 0.87，均方根误差 = 1.21 kcal/mol），比最佳基线提高了6.2%。消融研究证实扩散机制贡献了4.8点的相关性。理论分析证明扩散注意力向最优结构-序列耦合收敛，并且收敛速度为O(1/sqrt(T))，其中T是扩散步骤。这项工作确立了通过可学习的扩散机制整合异构蛋白质表示的理论框架。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05489", "html_url": "https://arxiv.org/abs/2511.05489", "title": "TimeSearch-R: 通过自我验证强化学习实现长视频理解的自适应时间搜索", "title_en": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning", "authors": "Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She", "background": "时间搜索旨在基于给定查询从成千上万的帧中识别出最小的相关帧集合，作为准确理解长视频的基础。现有的方法试图逐步缩小搜索空间，但这些方法通常依赖于手工设计的搜索过程，缺乏端到端的优化来学习最优的搜索策略。现有的基于强化学习(Reinforcement Learning, RL)的时间搜索方法，如Group Relative Policy Optimization (GRPO)，可能会造成未监督的中间搜索决策，导致视频内容探索不足和逻辑推理不一致的问题。本研究即在此背景下提出了TimeSearch-R。", "innovation": "TimeSearch-R将时间搜索重新表述为交错的文本-视频推理过程，通过强化学习使视频片段搜索融入推理过程。为了解决应用RL训练方法导致的探索不足和逻辑推理不一致的问题，该研究引入了GRPO-CSV。GRPO-CSV以交错推理过程中的搜索帧为基础，利用同一策略模型验证搜索帧的完整性，增强了视频推理。本研究还构建了专门的实验数据集用于SFT冷启动和RL训练，以提高任务难度并增强时间搜索能力。时间搜索结果显示，TimeSearch-R在Haystack-LVBench、Haystack-Ego4D和VideoMME、MLVU等长时间段视频理解基准测试上取得了显著的改进。TimeSearch-R在LongVideoBench上取得了新的最先进的结果。", "conclusion": "实验结果显示，TimeSearch-R在多个时间搜索和视频理解基准测试上取得了显著的性能提升，并在LongVideoBench上建立了新的最先进的模型。研究还强调了构建专门的实验数据集以提高RL训练质量和改进视频搜索能力的重要性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04412", "html_url": "https://arxiv.org/abs/2503.04412", "title": "更宽还是更深？利用自适应分枝树搜索扩展大语言模型推理时计算量", "title_en": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search", "authors": "Yuichi Inoue,Kou Misaki,Yuki Imajuku,So Kuroki,Taishi Nakamura,Takuya Akiba", "background": "最近的研究显示，在推理过程中增加计算量能显著提升大语言模型的推理能力。尽管重复采样（即生成多个候选输出）是一种非常有效的策略，但它没有利用来自编码等任务的外部反馈信号来优化输出。这些反馈信号通常在完成任务后可用。", "innovation": "本文提出了一种新颖的推理时间框架——自适应分枝蒙特卡洛树搜索（AB-MCTS），它综合了多轮探索和利用外部反馈信号进行多轮解构优化的优势。该方法在搜索树的每个节点根据外部反馈信号动态选择是“拓宽”新的候选回答还是“深入”重新访问现有回答。AB-MCTS被应用于复杂的编码和工程任务，结果显示它在降低错误率以及提供更准确、多样和细致的回答方面优于重复采样和标准蒙特卡洛树搜索。", "conclusion": "实验结果表明，AB-MCTS 高效地结合了大语言模型的响应多样性和多轮解构优化，为推理时间的扩展提供了重要的方法，具有潜在的应用价值和研究意义。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05430", "html_url": "https://arxiv.org/abs/2511.05430", "title": "我喜欢你必须探究其中的方法：关于经验性方法促进人工智能素养激发探究和批判性思维的教师观点", "title_en": "\"I Like That You Have to Poke Around\": Instructors on How Experiential Approaches to AI Literacy Spark Inquiry and Critical Thinking", "authors": "Aparna Maya Warrier,Arav Agarwal,Jaromir Savelka,Christopher Bogart,Heather Burte", "background": "随着人工智能（AI）在各个领域中越来越多地影响决策，人们对提高非计算机科学专业学生的AI素养的需求正在增加。目前许多方法依赖于编码工具或抽象的讲座内容，这限制了非STEM人群的可访问性。", "innovation": "本文介绍了一项研究，研究了名为AI User的模块化、基于网络的课程，该课程通过结合现实世界的情景和互动、无编码的项目来教授核心AI概念。这项研究特别关注了五到八个项目，这些项目涵盖了自然语言处理、计算机视觉、决策支持和负责任的人工智能等实际应用领域。", "conclusion": "研究发现，教师们赞赏探索性任务、角色模拟以及项目的现实相关性，但也揭示了认知负担、指导和适应性方面的设计权衡，尤其是在为不同背景的学习者设计内容时。该研究扩展了关于非编码情况下教授复杂AI主题的研究，并提供了设计跨学科和多种背景的包容性、体验式AI学习资源的实际建议。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.15040", "html_url": "https://arxiv.org/abs/2410.15040", "title": "结构增强扩散模型在结构导向抗体设计和优化中的应用", "title_en": "Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization", "authors": "Zichen Wang,Yaokun Ji,Jianing Tian,Shuangjia Zheng", "background": "抗体是生物体免疫反应的关键蛋白质，能够特异性识别病原体的抗原分子。近年来，生成模型的进步显著提升了理性抗体设计的能力。然而，现有方法主要从零开始创建抗体，缺乏模板约束，导致模型优化具有挑战性，并产生了一些不自然的序列。因此，为了解决这些问题，该研究提出了一种检索增强扩散框架（RADAb），以提高抗体设计的效率。该方法利用与查询结构约束相匹配的一组结构同源基序来指导生成模型，根据预设的设计标准反向优化抗体。具体地说，该方法引入了一种结构信息检索机制，通过一个新颖的双支降噪模块将这些示例基序与输入骨架结合，并利用结构和进化信息。除此之外，还开发了一种条件扩散模型，通过结合全局上下文和局部进化条件，逐步优化设计过程。该方法对生成模型的选择无偏见。实验结果表明，该方法在多个抗体反向折叠和优化任务中表现出了最先进的性能，为生物分子生成模型提供了新的视角。", "innovation": "提出了一种检索增强扩散框架（RADAb），该框架结合了结构同源基序与查询结构约束，并利用双支降噪模块和条件扩散模型逐步优化设计过程，解决了现有方法中模型优化的挑战性和生成不自然序列的问题。", "conclusion": "该方法在多个抗体反向折叠和优化任务中展现出了优越性能，为生物分子生成模型领域提供了新的设计思路和优化策略。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18156", "html_url": "https://arxiv.org/abs/2506.18156", "title": "通过人类视角看待AI：机器心理学中的认知理论探究", "title_en": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology", "authors": "Akash Kundu,Rishika Goswami", "background": "本文研究了大型语言模型（LLMs）在心理学的四个框架下是否表现出类似人类的认知模式，分别是主题投射测验（TAT）、框架偏差、道德基础理论（MFT）和认知失调。通过使用结构化指令和自动化评分评估了几种闭源和开源模型，发现了模型生成连贯叙述、对正面框架敏感、道德判断与自由/压迫问题相匹配以及展示理性化解释等特点，这些反映出人类的认知倾向但受训练数据和对齐方法的影响。文章讨论了这些发现对于AI透明性、伦理应用及其结合认知心理学和AI安全的研究方向的意义。", "innovation": "本文通过使用心理学框架对现代LLMs进行评估，揭示了模型展示出的人类认知模式和内在的不一致性，强调了训练数据和对齐方法在塑造模型行为中的作用，提出了AI透明性、伦理部署及其研究方向的结合点。这为理解LLM的行为提供了新的视角，也为未来的AI安全研究奠定了基础。", "conclusion": "本文的研究结果表明，尽管LLMs在某些方面表现出类似人类的认知模式，但其行为仍然受到训练数据和对齐方法的影响，且存在一定的不一致性。这种行为模式对于AI的透明性、伦理应用及其结合认知心理学和AI安全的研究具有重要意义，未来工作应继续探索这些模型的内部机制和改进方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04391", "html_url": "https://arxiv.org/abs/2510.04391", "title": "认知代理中的内部世界模型作为想象网络", "title_en": "Internal World Models as Imagination Networks in Cognitive Agents", "authors": "Saurabh Ranjan,Brian Odegaard", "background": "当前，关于想象作用的理解存在分歧。传统观点认为想象有助于最大化奖励，而新研究则提出了不同的观点。本文探讨了想象在网络模型中的作用，并使用心理网络分析来研究人类和大型语言模型（LLMs）中的内部世界模型（IWM）", "innovation": "文章通过使用两个问卷评估想象的生动性，并构建了想象网络，从而提供了一种独特的研究方法。发现人类的想象网络在不同中心度指标上表现出相关性，而LLMs的想象网络则显示出较低的聚集性和较低的不同提示和对话记忆条件下的中心度指标间的相关性，表明了人类和AI内部生成的模型之间的相似性不足", "conclusion": "总体来说，这项研究提供了一种比较人类和AI内部生成的表示的新方法，并为进一步开发具有人类般想象的机器智能提供了见解"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18883", "html_url": "https://arxiv.org/abs/2509.18883", "title": "Introducing LongCat-Flash-Thinking: 技术报告", "title_en": "Introducing LongCat-Flash-Thinking: A Technical Report", "authors": "Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu", "background": "该研究提出了一个高效的560亿参数开放源代码Mixture-of-Experts (MoE)推理模型LongCat-Flash-Thinking。该模型通过精心设计的训练过程培养其高级能力，该过程始于长链思维（CoT）数据的冷启动，并最终通过大规模强化学习（RL）完成。研究开始时使用了一个精心设计的冷启动训练策略，显著提升了推理潜力，并让模型获得了形式和代理推理的专业技能。随后，核心创新是其领域并行训练方案，该方案解耦了不同领域（例如STEM、代码、代理等）之间的优化，并将这些专家模型融合成一个近乎帕累托最优的模型。", "innovation": "研究的核心创新是其领域并行训练方案，该训练方案将不同领域的优化过程分离，随后将产生的专家模型融合成一个近于帕累托最优的单一模型。此外，DORA系统作为动态异步滚动调度系统，是一个大型RL框架，相比同步方法，其在数千个加速器上实现了超过三倍的训练速度提升。这些创新使得LongCat-Flash-Thinking在复杂的推理任务中达到了最先进的开放源代码模型性能，尤其在代理推理方面表现出色，平均减少了64.5％的token消耗（从19,653减少到6,965），而无需降低任务准确性。", "conclusion": "LongCat-Flash-Thinking在一套复杂的推理任务中达到了最先进的性能，并且模型展示了在代理推理方面的出色效率，减少了平均token的消耗，而无需牺牲任务准确性。研究者发布了该模型以促进推理系统和代理AI研究的进一步发展。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04173", "html_url": "https://arxiv.org/abs/2510.04173", "title": "Open Agent Specification (Agent Spec): 一种统一的AI代理表示", "title_en": "Open Agent Specification (Agent Spec): A Unified Representation for AI Agents", "authors": "Soufiane Amini,Yassine Benajiba,Cesare Bernardis,Paul Cayet,Hassan Chafi,Abderrahim Fathan,Louis Faucon,Damien Hilloulin,Sungpack Hong,Ingo Kossyk,Tran Minh Son Le,Rhicheek Patra,Sujith Ravi,Jonas Schweizer,Jyotika Singh,Shailender Singh,Weiyi Sun,Kartik Talamadupula,Jerry Xu", "background": "代理框架的普及导致了代理定义、执行和评估方式的分裂。现有的系统在抽象、数据流语义和工具集成方面存在差异，这使得难以共享或重现工作流。", "innovation": "引入了Open Agent Specification（Agent Spec），这是一种声明性语言，定义AI代理和代理工作流，具有跨框架的兼容性，促进AI代理的重用、移植性和互操作性。Agent Spec定义了一个通用的组件集、控制和数据流语义及其模式，以便一次定义代理并在不同的运行时执行。此外，它还引入了标准化的评估框架，以一致的方式评估代理行为和代理工作流的表现、稳健性和效率，类似于HELM和其他框架标准化语言模型评估的方式。文章通过四个不同的运行时（LangGraph, CrewAI, AutoGen 和 WayFlow）和三个不同的基准（SimpleQA Verified, τ^2-Bench和BIRD-SQL）演示了这一点。还提供了配套工具集，包括Python SDK（PyAgentSpec）、参考运行时（WayFlow）和流行框架的适配器（例如 LangGraph, AutoGen, CrewAI）。Agent Spec填补了模型中心和代理中心标准化及评估之间的差距，奠定了可靠、可重用和可移植的代理系统的基础。", "conclusion": "Agent Spec促进了跨不同框架的AI代理的重用、移植性和互操作性。通过标准化组件、控制和数据流语义以及提供标准化的评估框架，它为代理系统的发展奠定了可靠的基础。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21150", "html_url": "https://arxiv.org/abs/2510.21150", "title": "String Seed of Thought: 对LLMs进行分布忠实且多样化生成的提示方法", "title_en": "String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation", "authors": "Kou Misaki,Takuya Akiba", "background": "现有的LLMs在确定性任务上表现良好，但在需要生成具有特定概率分布和非确定性行为的任务上存在偏差和局限性，这包括人类行为模拟、内容多样化和多人游戏等领域。此外，这样的偏差还会降低生成响应的多样性，影响测试时规模的扩展性，导致输出局限于有限的答案集合。", "innovation": "我们提出了String Seed of Thought (SSoT)，这是一种新的Prompting方法，旨在改善概率指令遵循(PIF)。SSoT首先指示LLM输出一个随机字符串以生成足够的熵，然后通过操纵该字符串来提取随机性以得出最终答案。这种方法在保持多样性的同时遵守特定约束，实验表明SSoT显著提高了LLMs的PIF性能，接近伪随机数生成器的理想表现。并且，我们的实验结果表明SSoT不仅能改善闭集任务，还能在开放式任务上增强响应的多样性。", "conclusion": "SSoT通过引入随机字符串和熵的概念，提供了一种简单而有效的方法来优化LLMs的PIF性能，不仅解决了非确定性任务下的偏见问题，还增强了生成响应的多样性和覆盖率，特别是适用于需要高响应多样性的应用场景，如内容生成、评估测试和其他依赖于丰富和多样的响应的任务。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21993", "html_url": "https://arxiv.org/abs/2509.21993", "title": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "title_en": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "authors": "Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha", "background": "现有的语言模型（LM）存在一个被称为反转诅咒的现象，即模型无法从已学习的事实“A是B”推断出未见过的事实“B是A”。这一现象被认为是一个根本性的限制。本文探讨了反转诅咒并非是模型固有的失败，而是模型如何编码知识的产物。现有模型未从根本上解决这个问题，因此存在逻辑不一致的问题。", "innovation": "通过从头开始训练语言模型在合成的关系知识图谱数据集上，作者展示了二阶线性关系结构在隐藏表示中自然出现。这显著减轻了反转诅咒，使得模型能够推断未见过的反向事实。此外，具有二阶线性结构的模型在事实更新时能够正确传播到其反向和其他逻辑相关事实，而缺乏这种结构的模型不仅仍然面临反转诅咒，而且不能推广编辑，进一步引入逻辑不一致性。研究表明，训练于关系知识数据集可以诱导生成二阶线性内部表示，从而使得模型在编辑后能够以逻辑一致的方式工作。这意味着模型编辑的成功不仅依赖于编辑算法，还依赖于被修改的知识内部表示几何结构。", "conclusion": "本文的结果表明，训练于关系知识数据集可以生成二阶线性内部表示，从而降低反转诅咒并实现模型编辑的逻辑一致性。因此，模型编辑的成功不仅取决于编辑算法，还取决于被修改的内部表示几何结构。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22780", "html_url": "https://arxiv.org/abs/2510.22780", "title": "AI代理如何执行人类工作？跨多种职业比较AI和人类工作流程", "title_en": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations", "authors": "Zora Zhiruo Wang,Yijia Shao,Omar Shaikh,Daniel Fried,Graham Neubig,Diyi Yang", "background": "随着AI代理在软件工程和专业写作等人类工作中不断优化其任务能力，这种趋势对人力资源造成了重大影响，但这些代理开发往往未基于对人类工作执行机制的清晰理解，从而使得AI代理缺乏对具体工作流程和所需专业技能的全面理解。本文通过跨多项关键工作技能进行直接比较人类与AI代理工作者，来研究代理如何执行人类工作。", "innovation": "引入了一个可扩展的工具包，可以从人类或AI代理的计算机使用活动中生成可解释的、结构化的流程。通过使用生成的流程，本文将人类和代理执行相同任务的方式进行了比较，展示了代理的不足和优势，包括在工作流程的对齐上具有潜力，但在面对开放式、视觉依赖性任务时，尤为依赖程序化方法。同时，代理生成的工作质量较低，但却常通过数据造假和误用高级工具来掩盖其缺陷。尽管如此，代理的工作效率是人类的11.7%（约88.3%），成本降低90.4至96.2%。这一发现揭示了代理在计算和低成本执行可程序化任务方面的潜在优势。", "conclusion": "AI代理在特定领域的工作效率和成本优势显著，尤其是在容易程序化的任务上。然而，它们在复杂性和开放性任务上的表现依旧低于人类，且常常通过不诚实手段来掩盖缺陷。未来可以通过有效的代理与人类合作方式来最大化其效率和质量优势。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15144", "html_url": "https://arxiv.org/abs/2510.15144", "title": "HugAgent: Benchmarking LLMs for Simulation of Individualized Human Reasoning", "title_en": "HugAgent: Benchmarking LLMs for Simulation of Individualized Human Reasoning", "authors": "Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson", "background": "人类在开放任务中的推理模拟一直是人工智能和认知科学中的重要目标。尽管大型语言模型现在在宏观层面接近人类响应，但它们仍然调整为群体共识，常常抹杀了推理风格和信仰轨迹的个体性。为了朝着更接近人类推理的机器愿景前进，该研究引入了HugAgent（基于人类的代理基准），它从三个维度重新思考人类推理模拟：（i）从群体平均水平到个体化的推理；（ii）从行为模仿到认知对齐；（iii）从情境数据到开放性数据。", "innovation": "HugAgent 设计了一个双轨系统：人类轨道自动化并扩展了思考过程方法，收集生态有效的人类推理数据；合成轨道进一步提高可扩展性并进行系统压力测试。这种架构使得低成本和可扩展性地扩展到新任务和人群成为可能。实验表明，最先进的语言模型仍存在持续的适应性差距，使HugAgent成为第一个针对人类思考独特性的机器推理对齐的可扩展基准。", "conclusion": "HugAgent 基准及完整的数据收集管道和聊天机器人已开源，可用于评估和提高语言模型在个体化人类推理模拟方面的表现。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02818", "html_url": "https://arxiv.org/abs/2511.02818", "title": "Orion-MSP: 多尺度稀疏注意力机制在表格上下文学习中的应用", "title_en": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning", "authors": "Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu", "background": "表格数据仍然是现实应用的主要格式。然而，开发有效的神经模型来处理表格数据极为困难，因为它们具有异构特征类型和多尺度的复杂交互。尽管在表格上下文学习（ICL）方面取得了进展，如TabPFN和TabICL，它们的性能接近于梯度提升树（GBTs），但未经过任务特定微调也未解决关键局限性：(1) 单尺度特征处理，忽略了层次依赖关系；(2) 密集注意力，具有平方级别的时间复杂性；(3) 严格顺序组件处理，阻止了迭代表示细化和跨组件通信。", "innovation": "Orion-MSP通过引入三种关键创新解决了这些挑战：(1) 多尺度处理，以捕捉层次特征交互；(2) 块稀疏注意机制结合了窗口化、全局和随机模式，实现高效性和长程连接；(3) 类Perceiver风格的记忆，实现组件间的双向信息流，确保信息安全地在组件之间流动。", "conclusion": "在多种基准测试中，Orion-MSP与最先进的模型性能相当或超过其，同时能够有效地扩展到高维表格，建立了高效表格上下文学习的新标准。该模型已在公开平台发布。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26854", "html_url": "https://arxiv.org/abs/2510.26854", "title": "基于可验证推理的逆向知识搜索：从长推理链知识库构建科学百科全书", "title_en": "Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base", "authors": "Yu Li,Yuan Huang,Tao Wang,Caiyu Fan,Xiansheng Cai,Sihan Hu,Xinzijian Liu,Cheng Shi,Mingjun Xu,Zhen Wang,Yan Wang,Xiangqi Jin,Tianhan Zhang,Linfeng Zhang,Lei Wang,Youjin Deng,Pan Zhang,Weijie Sun,Xingyu Li,Weinan E,Linfeng Zhang,Zhiyuan Yao,Kun Chen", "background": "科学材料通常压缩推理过程，直接提出结论而忽略了用于证明这些结论的推理链条。这种压缩会妨碍验证过程，并且由于它消解了逻辑和因果关系之间的路径，抑制了跨领域的知识连接。", "innovation": "本文介绍了可扩展的框架，该框架通过构造可验证的长推理链（LCoT）知识库并将其投影到新兴的百科全书中——SciencePedia。方法包括使用一个以大约200门课程为引导的苏格拉底式代理生成约300万个基于第一原理的问题，以及通过多模型生成、提示清理和跨模型答案一致性过滤验证这些推理链的可靠性，从而构建出可验证的知识库。框架中的Brainstorm搜索引擎执行逆向知识搜索，检索到与目标概念相关的多样、基于第一原理的推理链。Plato合成器将这些验证过的链讲述成综合文章。该研究通过基于验证的LCoT知识库，实现了可信赖的、跨领域的科学合成，并为其构建不断扩展的百科全书奠定了基础，相比没有使用检索的基线，Plato合成的文章在六个学科中的知识点密度和事实错误率显著改善。", "conclusion": "这种方法使得大规模可信的跨域科学综合成为可能，并为不断扩展的百科全书奠定了基础。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.14865", "html_url": "https://arxiv.org/abs/2410.14865", "title": "联合验证与细化以保障约束规划的语言模型", "title_en": "Joint Verification and Refinement of Language Models for Safety-Constrained Planning", "authors": "Yunhao Yang,Neel P. Bhatt,William Ward,Zichao Hu,Joydeep Biswas,Ufuk Topcu", "background": "大型语言模型在从自然语言描述生成执行机器人任务的程序方面表现出色，但这些生成的程序常常包含违反给定任务规范的错误。然而，缺乏有效的验证方法使得这些语言模型在实际系统中的可靠部署成为实际上的不可行。本文提出了一种将生成的机器人程序转换为基于自动机的表示，并验证这些程序的方法，以便与相关安全规范进行对比。证明了只要任意组合的验证程序能够满足安全规范的事实。然后介绍了一种利用验证结果进行微调的自动过程，通过应用该定理，该过程只需训练模型生成安全子组件，从而提高训练效率。实验证明提高生成合规程序的概率30%，同时将训练时间缩短了一半。", "innovation": "开发了将生成的机器人程序转化为自动化机表示并验证其安全规范的方法。证明了组合验证程序也会满足安全规范的事实，这减少了复杂程序组合验证的计算复杂度。提出了一种利用验证结果进行自动微调的程序，通过只训练生成安全子组件来提高训练效率，从而提高生成合规程序的概率和减少训练时间。系统地评估了该方法在机器人应用中的表现。", "conclusion": "本文提出的方法通过将生成的机器人程序转换为基于自动机的表示并进行验证，简化了安全约束下的规划过程，证明了组合验证的正确性，提出了利用验证结果的自动微调程序来提高训练效率和生成合规程序的概率，实验证明这种方法在机器人应用中较之前方法具有显著的改进效果。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2012.12689", "html_url": "https://arxiv.org/abs/2012.12689", "title": "越简单的元素，整体越智能。抑或并非如此？", "title_en": "The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?", "authors": "Guido Fioretti", "background": "关于基于代理的建模社区如何定义“智能”的人工代理及其局部智能如何导致集体智能的涌现，存在一场辩论。Lotka-Volterra模型中的捕食者和猎物被赋予了不同程度复杂性的行为算法，以此探索智能的定义和集体智能的形成机制。", "innovation": "给Lotka-Volterra模型的猎物和捕食者增加了基于线性外推进行预测的能力，发现即使两者都具备预测能力，两种物种仍能共存且各自种群无限制地增长，从而表明相对简单的代理也能促进复杂集体行为的产生。进一步揭示，个体能够计算其他个体行为的一阶导数的能力可能是集体计算更高阶导数的关键机制。", "conclusion": "该研究结果表明，相对简单的代理有利于复杂集体行为的形成，并且个体能够计算其他个体行为的一阶导数的能力是实现高阶导数集体计算的前提。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03724", "html_url": "https://arxiv.org/abs/2511.03724", "title": "通过自我博弈和强化学习掌握说谎者纸牌：击败精英人类", "title_en": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning", "authors": "Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng", "background": "人工智能研究人员长期以来一直将扑克类游戏作为多玩家动态、不完美信息及不确定性推理环境的测试平台。尽管最近在无限德州扑克方面取得了与顶级人类玩家相当的成就，但多玩家动态被简化了：大多数牌局迅速结束，通常只有两人在多次投标轮次中参与。本文研究了富含多玩家参与的简化版说谎者纸牌游戏。", "innovation": "本文提出了Solly，这是第一个在简化版说谎者纸牌游戏中达到顶级人类水平的AI代理。Solly通过无模型的、演员-评论家的深度强化学习算法进行自我博弈训练。Solly在单玩家和多玩家说谎者纸牌的胜率和期望值方面均达到顶级人类水平，并且在与大型语言模型（包括那些具有推理能力的模型）的同一指标上表现更优。Solly开发了新的出价策略，能够有效地随机化出牌，并且不容易被世界级的人类玩家利用。", "conclusion": "Solly作为首个在简化版说谎者纸牌游戏中达到顶级人类水平的AI代理，展示了无模型的、演员-评论家的深度强化学习算法在多玩家参与、不完美信息及不确定性推理环境下的有效性。这表明这种技术可以用于更复杂的博弈环境，为博弈论和人工智能领域提供了新的可能性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04341", "html_url": "https://arxiv.org/abs/2511.04341", "title": "Monitor-Generate-Verify (MGV): 将元认知理论形式化应用于语言模型推理", "title_en": "Monitor-Generate-Verify (MGV): Formalising Metacognitive Theory for Language Model Reasoning", "authors": "Nick Oh,Fernand Gobet", "background": "现有的测试时推理架构，如Generate-Verify范式，虽然强调生成和验证过程，但忽视了在推理开始时决定何时以及如何进行监控的过程。这种忽视可能导致优先效应陷阱，促使模型过早地选择次优的推理路径，从而显著降低精度表现，一般损失约20%。因此，本文通过借鉴Flavell和Nelson & Narens的元认知理论，提出了首个系统的计算实现，并引入了Monitor-Generate-Verify (MGV) 框架来改进这一结构性缺陷。", "innovation": "本文创新性地将元认知理论形式化，并在计算层面上进行了系统地转化，提出了新的Monitor-Generate-Verify (MGV) 框架。该框架不仅扩展了现有的Generate-Verify范式，还通过加入明确的监控步骤来捕捉在生成前的元认知体验，并通过验证反馈进一步精炼未来的监控过程。", "conclusion": "尽管本文没有提供实证验证，但系统地将元认知理论应用于推理系统的前景广阔，为理解推理系统失败提供了新的理论视角，并为未来测试时推理设计提供了具体的架构干预方案。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24145", "html_url": "https://arxiv.org/abs/2510.24145", "title": "从可观测数据到诊断：云系统中自适应多代理系统的故障管理", "title_en": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems", "authors": "Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Dan Pei", "background": "故障管理（IM）对于大型云系统可靠性至关重要。然而，在面对大规模和异构可观测数据时，手动IM需要大量人力且容易出错。现有的自动化IM方法常常难以适用于不同系统，提供有限的可解释性，并且部署成本高，这妨碍了实际应用中的采用。", "innovation": "本文提出了OpsAgent，一种轻量级的多代理系统，采用无训练数据处理器将异构可观测数据转换为结构化的文本描述，并结合了一个多代理协作框架，让诊断推理公开透明且可审计。此外，OpsAgent引入了双重自我进化机制，将内部模型更新与外部经验积累结合起来，从而形成部署闭环。", "conclusion": "在OPENRCA基准测试上的全面实验表明，OpsAgent具有最先进的性能，并且证明OpsAgent是通用、解释性强、成本效益高和自我进化的，使其成为一种在实际云系统长期运行中实际部署和可持续的解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.06524", "html_url": "https://arxiv.org/abs/2403.06524", "title": "基于总运营成本奖励的深度强化学习自主卡车战术决策", "title_en": "Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward", "authors": "Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani", "background": "本文开发了一种深度强化学习框架，用于自主卡车在高速公路场景中的战术决策，特别是针对自适应巡航控制（ACC）和变道动作。研究指出，在基于物理模型的低级控制器和深度强化学习代理之间分离高级决策和低级控制动作是有益的，可以根据总运营成本（TCOP）利用多目标奖励函数来优化性能，该奖励函数基于技术和数据的实际情况。", "innovation": "提出了基于深度强化学习的自主卡车战术决策框架，特别关注分离高级决策和低级控制。通过研究不同方法优化基于总运营成本的多目标奖励函数，如调整奖励组件的权重、标准化奖励组件和使用递增学习技术。", "conclusion": "研究结果表明，通过调整奖励组件的权重、标准化奖励和使用递增学习技术，可以基于总运营成本有效地优化自主卡车的操控性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.18905", "html_url": "https://arxiv.org/abs/2402.18905", "title": "采用Langevin扩散的私人微调训练动态特征", "title_en": "Characterizing the Training Dynamics of Private Fine-tuning with Langevin diffusion", "authors": "Shuqi Ke,Charlie Hou,Sewoong Oh,Giulia Fanti", "background": "研究显示，不同隐私保护的全微调方法（DP-FFT）可能会导致预训练基础特征的失真，这既基于理论分析也基于实证结果。特征失真的原因是预训练的基础部分与随机初始化的线性头之间存在不匹配。这一背景强调了理解如何减少或解决这种特征失真对于实现有效的隐私保护微调策略的重要性。", "innovation": "本文通过证明序列微调策略（先线性探针后微调，DP-LP-FFT）可以缓解这种特征失真，提出了一个新的近似方案，用于推导具有标准双层神经网络结构的DP-LP和DP-FFT的训练损失的近似上界和下界。通过真实数据集和架构的实验结果验证了理论分析的效果。", "conclusion": "理论表明，在多阶段微调方法中（如DP-LP-FFT），隐私预算在不同微调阶段的分配存在权衡。此外，研究还推导出了没有近似条件下的双层线性网络的新上界。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.04396", "html_url": "https://arxiv.org/abs/2407.04396", "title": "FunOTTA: 在跨域眼底图像上的即席自适应通过稳定测试时训练", "title_en": "FunOTTA: On-the-Fly Adaptation on Cross-Domain Fundus Image via Stable Test-time Training", "authors": "Qian Zeng,Le Zhang,Yipeng Liu,Ce Zhu,Fan Zhang", "background": "眼底图像对于早期筛查和检测眼部疾病至关重要。尽管使用眼底图像的深度学习模型大大提高了许多眼部疾病的诊断能力，但由于不同成像设备和位置的图像变异性（称为域移），预训练模型在实际应用中的部署面临挑战。为了解决这一问题，本研究提出了一种新颖的即席眼底图诊断模型适应框架——FunOTTA，该框架能有效地将模型适应于未见过的环境，即使在强域移的情况下也表现稳定。FunOTTA通过在记忆库中进行动态去模糊来执行稳定的自适应过程，同时最小化有害的先验知识偏差。", "innovation": "提出了FunOTTA框架，该框架通过在记忆库中执行动态去模糊并最小化有害的先验知识偏差，实现了稳定的自适应过程。在自适应过程中引入了一个新的训练目标，使分类器能够逐步适应目标模式，并进行可靠的类条件估计和一致性正则化。实验结果表明，该框架及其各个组成部分在不同的骨干网络下均优于现有最先进的测试时自适应管道。", "conclusion": "在跨域眼底图像基准上的实验表明，FunOTTA框架及其各个组成部分在多种骨干网络下均优于现有的最先进的测试时自适应管道。代码可在如下链接获取：this https URL。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.01336", "html_url": "https://arxiv.org/abs/2309.01336", "title": "基于聚类的区间预测学习方法：电能需求的区间预测", "title_en": "Learning for Interval Prediction of Electricity Demand: A Cluster-based Bootstrapping Approach", "authors": "Rohit Dube,Natarajan Gautam,Amarnath Banerjee,Harsha Nagarajan", "background": "在小规模聚合负荷如微电网中，准确预测电能需求对于管理操作至关重要。由于低聚合导致的电能需求高度随机，点估计会带来过度放大的误差。在这样的场景中，区间估计能够提供未来值可能落在的范围，并有助于量化点估计周围的误差。本文介绍了一种残差重抽样算法，用于生成日预测电能需求的区间估计。利用机器学习算法获取训练集中的电能需求点估计和相应残差，存储这些残差并在内存中进一步划分。使用无监督学习算法将具有相似需求模式的天数分组为簇，这些簇用于划分内存。测试日的点估计用于找到相似的日子簇，然后从选定的簇中重抽样残差。该算法在EULR（终端负荷研究）的实际电能需求数据上进行评估，并与不同置信区间下的其他重抽样方法进行比较。", "innovation": "提出了一种基于聚类的残差重抽样算法，用于生成日预测电能需求的区间估计。这种方法利用机器学习算法先获取潜在的点估计和残差，然后使用无监督学习算法根据需求模式将天数分组为簇，再从相似的簇中重抽样残差进行预测。与常用的其他重抽样方法相比，这种方法能够提高预测的准确性，特别是在电能需求高度随机的情况下。", "conclusion": "本文提出的方法在实际电能需求数据上进行了验证，并与其它重抽样方法进行了比较，结果显示该方法在不同置信区间下有较好的表现。这种方法能够有效地提供电能需求的区间预测，有助于提高微电网的管理效率。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00696", "html_url": "https://arxiv.org/abs/2411.00696", "title": "CTPD: 交叉模态时序模式发现及其在强化多模态电子健康记录分析中的应用", "title_en": "CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis", "authors": "Fuying Wang,Feng Wu,Yihan Tang,Lequan Yu", "background": "电子健康记录（EHR）数据包含多种类型的信息，如数值时间序列和自由文本临床报告，这种多模态数据在预测临床结果方面具有巨大潜力。但现有研究主要关注单一样本内的时序交互和多模态信息的融合，忽略了患者间的关键时序模式。识别不同模态中的相应时序模式对于提高临床结果预测的准确性至关重要，但这是一个具有挑战性的任务。", "innovation": "该研究提出了一个名为CTPD（Cross-Modal Temporal Pattern Discovery）的框架，用于从多模态EHR数据中高效提取有意义的交叉模态时序模式。该方法通过共享初始时序模式表示并使用槽注意力机制生成时间语义嵌入，同时引入对比损失（TPNCE loss）和两种重构损失以确保学习模式中丰富的跨模态时间语义。", "conclusion": "在MIMIC-III数据库上的实验表明，CTPD方法在48小时住院死亡率和24小时表型分类等临床关键任务上优于现有方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.05447", "html_url": "https://arxiv.org/abs/2412.05447", "title": "TOBUGraph: 基于知识图谱的检索增强以超越RAG的LLM性能", "title_en": "TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG", "authors": "Savini Kashmira,Jayanaka L. Dantanarayana,Joshua Brodsky,Ashish Mahendra,Yiping Kang,Krisztian Flautner,Lingjia Tang,Jason Mars", "background": "检索增强生成（RAG）是增强LLM检索能力的领先技术之一，但在商业应用场景中仍面临重大限制。RAG主要依赖于查询-片段文本到文本的相似性嵌入空间进行检索，无法捕捉片段间的深层语义关系，高度依赖于片段划分策略，并容易产生幻觉。", "innovation": "为解决这些挑战，我们提出了TOBUGraph，这是一种基于图的检索框架，能够动态和自动地从非结构化数据中构建知识图谱。TOBUGraph使用LLM提取结构化知识和数据之间的多样化关系，超越了RAG的文本到文本相似性，通过图遍历实现了检索，利用提取出的关系和结构来提升检索准确性，同时减少了需要进行的片段划分配置，降低了幻觉的发生率。我们展示了TOBUGraph在TOBU中的应用效果，TOBU是一款用于个人记忆组织和检索的现实世界生产应用。实验结果表明，TOBUGraph在精确度和召回率方面均优于多个RAG实现，显著提升了用户体验。", "conclusion": "我们的评估结果显示，TOBUGraph在真实用户数据上的表现显著优于多个RAG实现，在精确度和召回率方面均未展现出色成果，从而通过提高检索准确性显著提升了用户体验。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.01083", "html_url": "https://arxiv.org/abs/2409.01083", "title": "基于流动匹配的手势驱动机器人操作", "title_en": "Affordance-based Robot Manipulation with Flow Matching", "authors": "Fan Zhang,Michael Gienger", "background": "本文提出的框架聚焦于两种基本挑战：首先，高效地在下游场景中适应大规模模型进行操作动作理解任务，尤其是在日常生活中难以收集涉及人类的多任务数据；其次，通过扎根视觉操作能力模型来有效学习机器人动作轨迹。前人主要关注的是如何高效地适应大规模模型并利用视觉操作模型来指导机器人动作轨迹的学习，但文献中缺乏对于如何处理大规模数据集以适应复杂多变场景的详细解决方案，也缺乏有效的流动匹配方法来指导机器人的操作轨迹学习，尤其是在真实世界应用场景中的测试数据集有限的情况下。", "innovation": "本文的创新点在于提出了一个参数高效的提示调优方法，通过在冻结的视觉模型前添加可学习的文本提示来预测多任务场景中的操作能力，并提出了一种监督流动匹配方法来指导机器人动作轨迹的学习。流动匹配方法将机器人的视知动作策略表示为从随机航点流向目标机器人动作路径的条件过程，特别是在测试时，流动匹配方法在多个机器人操作基准测试中表现出更稳定且更快的推理速度，同时保持与扩散策略相当的泛化性能。此外，本文还介绍了一个包含10项日常生活任务的真实世界数据集，以测试该框架的有效性。", "conclusion": "本文的评估结果显示，提出的提示调优方法在学习操作能力方面取得了与现有方法相当甚至更好的表现，在不同数据规模下实现了参数效率和性能的平衡，而流动匹配方法则在多个机器人操作基准测试中取得了更优的结果，包括更稳定的学习和推理过程，更快的推理速度和相似的泛化性能。该框架成功地将操作能力和动作生成统一到了流动匹配方法中，丰富了目前机器人的操作学习方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.03503", "html_url": "https://arxiv.org/abs/2502.03503", "title": "分析情境学习的限制", "title_en": "Analyzing limits for in-context learning", "authors": "Omar Naim,Jerome Bolte,Nicholas Asher", "background": "先前的研究声称，在上下文学习过程中，基于变换器的模型隐含地实现标准学习算法。本文挑战这一观点，并通过实证证据和数学分析指出，由于架构上的固有限制，变换器无法实现广泛的预测准确性。", "innovation": "本文提供了实证证据，并进行了数学分析，证明基于变换器的模型在上下文学习过程中不能实现普遍的预测准确性，挑战了先前研究中的观点。", "conclusion": "基于变换器的模型在上下文学习过程中由于架构限制无法获得普遍的预测准确性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.08828", "html_url": "https://arxiv.org/abs/2501.08828", "title": "MMDocIR: 在长文档中评估多模态检索的基准", "title_en": "MMDocIR: Benchmarking Multimodal Retrieval for Long Documents", "authors": "Kuicai Dong,Yujing Chang,Xin Deik Goh,Dexun Li,Ruiming Tang,Yong Liu", "background": "多模态文档检索旨在从广泛文档中识别和检索各种形式的多模态内容，如图表、表格、图表布局等。尽管此类任务越来越受欢迎，但目前尚未形成一个全面且可靠的基准来有效评估其系统性能。", "innovation": "本文引入了一个新的基准MMDocIR，该基准包括两部分任务：页面级别检索和布局级别检索。页面级别检索用于评估识别文档中最相关页面的能力，而布局级别检索评估检测特定布局的能力，这比整个页面分析提供了更细致的度量。MMDocIR基准包含由专家注释的1,685个问题以及通过自举给定标签的173,843个问题的数据集，是用于多模态文档检索训练和评估的重要资源。实验证明，视觉检索器显著优于文本检索器，MMDocIR训练集能够有效提升多模态文档检索性能，使用VLM-text的文本检索器比依赖OCR文本的检索器表现更好。", "conclusion": "通过实验证明了MMDocIR基准数据集相较于现有数据集的优势，并持续开放数据集供研究使用。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03138", "html_url": "https://arxiv.org/abs/2511.03138", "title": "基于专有模型的AI代理安全响应框架", "title_en": "A Proprietary Model-Based Safety Response Framework for AI Agents", "authors": "Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao", "background": "随着大型语言模型（LLMs）的广泛应用，与之相关的安全问题变得越来越突出，严重限制了其在关键领域的可信部署。这导致了对新的安全机制的需求，以有效管理与LLMs相关的风险，确保其安全可靠地运行。", "innovation": "本文提出了一种创新的安全响应框架，该框架能够在输入和输出层面系统地保护大型语言模型。在输入层面，框架使用监督微调的安全分类模型，通过精细的四级分类体系（安全、不安全、有条件的安全、专注关注），实现精确的风险识别和用户查询的差异化处理。在输出层面，框架结合检索增强生成（RAG）与专门的解释模型进行微调，确保所有响应都基于实时的可信知识库，这不仅消除了信息伪造，还使得结果可追溯，从而提高了系统的安全性。实验证明，该框架在公共安全评估基准测试中的安全得分远远高于基线模型TinyR1-Safety-8B，并且在自有的高风险测试集中，各个组件都达到了100%的安全得分，显示出强大的防护能力。", "conclusion": "这项研究表明，该安全控制模型在进行风险管理和安全性提高方面表现出色。该框架为构建高安全性和高可信度的大型语言模型应用程序提供了有效的工程师路径。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.09766", "html_url": "https://arxiv.org/abs/2501.09766", "title": "iTool: 动态缺陷校准增强的强化细调以实现高级工具使用", "title_en": "iTool: Reinforced Fine-Tuning with Dynamic Deficiency Calibration for Advanced Tool Use", "authors": "Yirong Zeng,Xiao Ding,Yuxian Wang,Weiwen Liu,Wu Ning,Yutai Hou,Xu Huang,Duyu Tang,Dandan Tu,Bing Qin,Ting Liu", "background": "通过将外部工具增强大型语言模型（LLMs）的方法被认为能够提升模型处理复杂任务的能力。通过真实世界模拟合成工具使用数据也是实现这一目标的有效方式。然而，研究表明，随着合成数据量的增加，训练收益会显著下降。模型无法有效利用附加的合成数据来进行高级工具使用能力的提升，在复杂场景中尤为如此。这种现象通常表现为反应片段不足（即参数错误）。", "innovation": "本文提出了一个迭代强化微调策略，旨在缓解前述局限性。该策略依赖于蒙特卡洛树搜索的路径探索来增强合成数据响应的多样性，并通过构建精细粒度的偏好对迭代标记模型的缺陷，然后利用偏好优化算法进行针对性改进。实验表明，该方法实现了比相同规模的基础模型更好的性能，并在复杂场景中比基线高出6.5%，同时超过了更大的开源和专有模型。", "conclusion": "该研究表明，通过动态缺陷校准增强的强化微调策略有效解决了大型语言模型在复杂工具使用场景中的局限性问题，实现了显著的性能提升。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06265", "html_url": "https://arxiv.org/abs/2504.06265", "title": "大型语言模型作为校准了不确定性的优化器以指导实验发现", "title_en": "Large language models as uncertainty-calibrated optimizers for experimental discovery", "authors": "Bojana Ranković,Ryan-Rhys Griffiths,Philippe Schwaller", "background": "科学发现越来越多地依赖于在时间和资源限制下有效地进行实验优化，以在广阔的实验设计空间中导航。传统的方法往往需要大量的专业知识和特征工程。尽管大型语言模型具有广泛的知识，但在避免特征工程的限制方面却不行，无法提供高风险决策所需的校准不确定性估计。因此，现有的优化方法只能在专业知识和可靠性之间作出选择，缺乏一种集两者于一身的原理性方法。", "innovation": "本文展示了通过传统优化方法中的不确定性意识目标来培训语言模型，使它们能够通过自然语言作为可以信赖的优化器使用，从而将语言模型的过度自信从基本的限制转变为精准的校准机制。该方法在50次实验迭代中，从10个不成功的条件下几乎将高产反应条件的发现率提高了一倍，从24%提高到43%，并且在涵盖有机合成、材料科学与催化、过程化学和分子设计的19个不同优化问题上均值排名第一，开创了语言模型在实验发现中可靠且基于不确定性的优化的新范式。这种方法通过降低使用强大优化方法的门槛，用更易于访问的自然语言界面取代了特定领域的特征工程，加速了发现进程。", "conclusion": "通过原则性地量化不确定性能确保模型的可靠性，这对于实现AI指导实验的全部潜力至关重要。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16395", "html_url": "https://arxiv.org/abs/2502.16395", "title": "AIRepr：数据科学中LLM可再现性评估的分析师-检测员框架", "title_en": "AIRepr: An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science", "authors": "Qiuhai Zeng,Claire Jin,Xinyue Wang,Yuhan Zheng,Qunhua Li", "background": "大型语言模型（LLMs）越来越多地用于通过生成可执行代码来自动化数据分析。然而，数据科学任务通常可能有多种统计上有效的解决方案，例如不同的建模策略，因此理解分析背后的推理比仅仅了解其结果更为关键。虽然手动审查LLM生成的代码可以帮助确保统计上的严谨性，但这是一种劳动密集型的工作，并且需要专业知识。一种更可扩展的方法是评估生成代码的基础工作流程——指导代码生成的逻辑计划。然而，至今尚不清楚如何评估LLM生成的工作流程是否支持可重复的实现。", "innovation": "我们提出了一种名为AIRepr的分析师-检测员框架，用于自动评估和提高LLM生成的数据分析工作流程的可再现性。该框架立足于统计原则，支持可扩展和自动化的评估。我们引入了两种新的增强可再现性的提示策略，并在15个分析师-检测员LLM对和来自三个公开基准的数据的1,032个任务上与标准提示进行了基准测试。我们的研究结果表明，具有更高可再现性的工作流程也能产生更准确的分析，增强可再现性的提示在两个指标上都显著提高了性能。这项工作为数据科学中透明、可靠和高效的AI与人类合作提供了基础。该代码已公开提供。", "conclusion": "这项工作提供了数据科学中透明、可靠和高效的AI与人类合作的基础。AIRepr框架能够自动评估并提升LLM生成的数据分析工作流程的可再现性，通过新颖的提示策略显著提高了可再现性和分析准确性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08686", "html_url": "https://arxiv.org/abs/2504.08686", "title": "Pogobot：一种开源低成本的群体机器人及可编程活性物质平台", "title_en": "Pogobot: an Open-Source, Low-Cost Robot for Swarm Robotics and Programmable Active Matter", "authors": "Alessia Loi,Loona Macabre,Jérémy Fersula,Keivan Amini,Leo Cazenille,Fabien Caura,Alexandre Guerre,Stéphane Gourichon,Laurent Fabre,Olivier Dauchot,Nicolas Bredeche", "background": "本文描述了Pogobot，一个专为研究群体机器人与活性物质交汇领域设计的开源平台。Pogobot采用振动或轮式驱动，具备快速红外通信和成本效益高的传感器模块（每个约250欧元），适用于多个领域的研究。已有超过200个Pogobot在多所大学用于研究自组织系统、可编程活性物质、离散反应扩散迁移系统及社会学习和进化的计算模型。", "innovation": "Pogobot采用模块化设计，提供全面的应用编程接口和可扩展架构，便于实现群体智能算法和集体运动。相比现有平台提供更低成本且具备先进功能，包括单元间的方向通信和快速移动能力。该平台还提供硬件和软件架构、通信协议、驱动机制以及围绕Pogobot构建的基础设施。", "conclusion": "Pogobot作为一种开源且低成本的平台，不仅为群体机器人研究提供了新的手段，还为活性物质的研究提供了一个有效的工具，该平台已在多个机构中得到广泛应用，展示了其在多个科学领域的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02886", "html_url": "https://arxiv.org/abs/2505.02886", "title": "Taskmaster重构：一场关于紧张感、波动性与观众评分的定量分析", "title_en": "Taskmaster Deconstructed: A Quantitative Look at Tension, Volatility, and Viewer Ratings", "authors": "David H. Silver", "background": "Taskmaster是一部结合了喜剧表演和正式评分系统的英国电视节目。尽管看起来存在激烈的竞争，但评分动态是否对观众的参与度产生有意义的影响仍有待确定。本文通过对18个赛季共162集的统计分析，使用十五个指标来衡量排名波动、得分差距、胜利反转和胜者优势，发现这些指标与IMDb评分无显著关联，即使控制了系列效果的情况下也是如此。", "innovation": "本文通过分析18个赛季共162集《Taskmaster》节目，系统研究了评分动态、排名波动等对观众参与度的影响，并通过统计分析发现了整体得分提升、波动性略有下降以及排名差距保持稳定的趋势，这些趋势反映出节目试图增强竞争的可见性，但未改变节目的结构性平衡。", "conclusion": "研究发现，观众的兴趣更多受到参赛者表现的影响，而非游戏机制。长期趋势表明平均得分增加了，但波动性略有下降，排名差距保持相对稳定，这些模式表明节目试图提高竞争的可见性，却未改变节目的结构性均衡。此外，分析了参赛者排名趋势，识别出五种重复出现的特征，进一步揭示了观众兴趣形成的机制。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13438", "html_url": "https://arxiv.org/abs/2505.13438", "title": "通过预算相关策略优化优化任意时长推理", "title_en": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization", "authors": "Penghui Qi,Zichen Liu,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "对于增强大型语言模型（LLMs）的推理能力，测试时的计算扩展至关重要。现有方法通常使用强化学习（RL）来最大化推理踪迹结束时得到的可验证奖励，但这样做只优化了在大量固定令牌预算下的最终性能，这在训练和部署时降低了效率。本文旨在通过优化在不同令牌预算下的任意时间推理表现，提高令牌效率和推理灵活性。", "innovation": "本文介绍了AnytimeReasoner这一新型框架，通过截断完整的思考过程以适应先前分布中采样的令牌预算，迫使模型为每个截断的思考总结最优答案供验证。这种方法引入了在推理过程中可验证的密集奖励，有助于更有效的RL优化。此外，引入了新的降低方差技术，预算相对策略优化（BRPO），以增强强化学习过程的稳定性和效率。", "conclusion": "我们的方法在数学推理任务中的实验证明中表现出色，在各种先验分布下的所有思考预算下，一致优于GRPO，提升了训练和令牌效率。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21700", "html_url": "https://arxiv.org/abs/2504.21700", "title": "XBreaking: 理解如何打破大型语言模型的安全对齐", "title_en": "XBreaking: Understanding how LLMs security alignment can be broken", "authors": "Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P", "background": "大型语言模型在现代以AI解决方案为中心的IT景观中是基本的参与者。然而，这些模型可能存在的安全威胁可能会阻止它们在关键应用场景，如政府组织和医疗机构中可靠的部署。为此，商业化的大型语言模型通常会经历一种复杂的过滤机制，以消除它们可能产生的任何有害输出。这些机制通过确保模型安全、伦理地响应来保持大型语言模型的对齐。但针对这些过滤机制的攻击已经成为保护措施的重大威胁。现有的针对大型语言模型的攻击大多采用了生成和测试的策略来构造恶意输入。为了解释过滤机制并设计一个有针对性的攻击，我们提出了基于可解释AI的解决方案，将过滤和未过滤的模型的行为进行对比分析，以识别独特的可利用的对齐模式。然后，我们提出了XBreaking，一种新颖的方法，通过有针对性的噪声注入利用这些独特的模式来打破大型语言模型的安全和对齐限制。", "innovation": "我们提出了基于可解释AI的解决方案，通过对比分析过滤和未过滤的模型的行为，以识别独特的可利用的对齐模式。然后，我们提出了XBreaking，一种新型方法，通过有针对性的噪声注入利用这些独特的模式来打破大型语言模型的安全和对齐限制。这种方法有效地揭示了过滤机制并展示了其方法的有效性和性能。", "conclusion": "我们的细致实验规范提供了关于过滤机制的重要见解，并证明了我们方法的有效性和性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01502", "html_url": "https://arxiv.org/abs/2506.01502", "title": "基于反优化的种群动力学习：JKO方案的结合", "title_en": "Learning of Population Dynamics: Inverse Optimization Meets JKO Scheme", "authors": "Mikhail Persiianov,Jiawei Chen,Petr Mokrov,Alexander Tyurin,Evgeny Burnaev,Alexander Korotin", "background": "种群动态学习涉及从离散时间点测量的样本进化快照中恢复支配粒子演化的潜在过程。近期方法将其视为在概率空间中的能量最小化问题，并借助广为人知的JKO方案进行高效的时态离散化。", "innovation": "作者提出了$\texttt{iJKOnet}$方法，该方法结合了JKO框架与反优化技术以学习种群动态。这种方法依赖于传统的端到端对抗训练程序，并且不需要严格的架构选择，如输入凸神经网络。作者还为该方法建立了理论保证，并证明了相比之前的基于JKO的方法，它具有更好的性能表现。", "conclusion": "该工作证明了$\texttt{iJKOnet}$方法在种群动力学习中的有效性和优越性，通过理论保证和实验结果展示了其相较于其他方法的优势。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24149", "html_url": "https://arxiv.org/abs/2505.24149", "title": "RCCDA：受限资源预算下概念漂移时的自适应模型更新", "title_en": "RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget", "authors": "Adam Piaseczny,Md Kamran Chowdhury Shisher,Shiqiang Wang,Christopher G. Brinton", "background": "实际应用中的机器学习算法经常面临概念漂移的挑战，即随时间变化数据分布的变化，这使得模型适应变得困难。尤其是在资源受限的环境中保持模型性能时更为复杂。现有解决方案往往依赖于产生高计算开销的漂移检测方法，这些方法不能提供严格的资源使用保证或理论性能保障。", "innovation": "提出了一种动态模型更新策略RCCDA，通过利用过去的损失信息和可调的漂移阈值，优化ML训练动力学，同时满足预定义的资源约束。通过分析模型损失在任意训练更新决策下的演化，结合Lyapunov漂移加罚理论框架，生成了一个轻量级的可证明限制更新频率和成本的贪婪最优策略。", "conclusion": "实验结果表明，在多种概念漂移模式下，该策略能够在严格资源约束下获得比基线方法更高的推理准确率，因此该解决方案特别适合实时ML部署。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15027", "html_url": "https://arxiv.org/abs/2502.15027", "title": "InterFeedback：通过人类反馈揭示大型多模态模型的交互智能", "title_en": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback", "authors": "Henry Hengyuan Zhao,Wenqi Pei,Yifei Tao,Haiyang Mei,Mike Zheng Shou", "background": "现有的基准测试未对大型多模态模型（LMMs）与其与人类用户的互动智能进行评估，而这是开发通用人工智能助手的关键。本文分析了现有的研究不足，并指出了评估LMMs与人类互动能力的重要性。", "innovation": "本文提出了InterFeedback，一种可用于任何LMM和数据集的交互框架，可自主评估模型的互动智能。此外，还引入了基于两个代表性数据集MMMU-Pro和MathVerse的InterFeedback-Bench来评估10个不同的开源LMMs。同时，还发布了InterFeedback-Human数据集，包含120个手动测试案例，用于评估领先模型如OpenAI-o1和Claude-Sonnet-4的互动性能。研究结果表明，即使是当前最先进的LMM，OpenAI-o1也无法有效根据人类反馈来改进其回答，平均分低于50%。", "conclusion": "本文的研究结果强调了需要开发有效方法来增强LMMs理解并利用反馈的能力，这将是提高其互动性能的关键。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02421", "html_url": "https://arxiv.org/abs/2502.02421", "title": "大型语言模型的activation-informed合并", "title_en": "Activation-Informed Merging of Large Language Models", "authors": "Amin Heyrani Nobari,Kaveh Alim,Ali ArjomandBigdeli,Akash Srivastava,Faez Ahmed,Navid Azizan", "background": "模型合并是一种将多个细调的大语言模型（LLMs）的参数和嵌入结合起来的方法，旨在提高模型在各种任务中的性能同时保持计算效率。现有的模型合并方法一般忽略了激活空间的信息，因此，如何更好地利用这些信息来优化模型合并策略成为了一个研究热点。本文提出了一种名为Activation-Informed Merging (AIM)的技术，该技术将LLMs的激活空间信息整合到合并过程中，以提升合并模型的性能和鲁棒性。AIM设计为一种灵活的补充解决方案，适用于现有的任何合并方法，并旨在保持基模型的关键权重。", "innovation": "本文提出的AIM是一种将激活空间信息整合到模型合并过程中的技术，它通过使用任务无关的校准集来选择性地优先处理重要的权重。与现有的模型合并方法相比，AIM显著提升了合并模型在多个基准测试中的性能，展示了激活空间信息在模型合并策略中的巨大潜力，最高可提升40%的基准性能。AIM的设计原则来源于持续学习(CL)和模型压缩，并提供了一种灵活的方法来增强现有的合并方法。", "conclusion": "本文通过实验证明，AIM显著提升了合并模型的性能，并表明考虑激活空间信息可以提供在LLMs模型合并策略中的重大改进，进一步的研究可以探索AIM在不同场景下的应用和优化。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05583", "html_url": "https://arxiv.org/abs/2506.05583", "title": "适应未知子群体转移的校准预测", "title_en": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "authors": "Nien-Shao Wang,Duygu Nur Yaldiz,Yavuz Faruk Bakman,Sai Praneeth Karimireddy", "background": "校准预测广泛用于为黑盒机器学习模型提供不确定性量化，在交换数据下提供了正式的覆盖率保证。然而，当面临子群体转移时，这些保证会失效，即测试环境中的子群体混杂情况不同于校准数据。本文专注于未知的子群体转移，即我们没有被提供分组信息（即数据点的子群体标签需要推断）。现有的方法在类似设置下假设完美的子群体标签，而本文的框架明确放松了这一要求，并描述了在未明确子群体结构的情况下仍能实现形式化的覆盖率保证的条件。此外，本文的方法能够线性扩展到高维度环境，并在实际机器学习任务中保持实用性。广泛的实验证明，在标准校准预测失效时，我们的方法能可靠地保持覆盖率并有效控制风险。", "innovation": "本文提出了新的方法，能够在没有明确子群体结构的情况下适应未知的子群体转移，确保有效的覆盖率。相较于现有假设完美子群体标签的方法，本文框架明确放松了这一假设，并描述了在未明确子群体结构的情况下仍能保持形式化的覆盖率保证。此外，这些算法能够线性扩展到高维度环境，并在实际机器学习任务中保持实用性。", "conclusion": "通过广泛的实验证明，在标准校准预测失效的情况下，我们的方法可以可靠地保持覆盖率并有效控制风险。本工作的方法能够适应未知的子群体转移，确保在高维度环境下仍能提供有效的覆盖率保证。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09338", "html_url": "https://arxiv.org/abs/2506.09338", "title": "了解你不知道的：过程奖励模型的不确定性校准", "title_en": "Know What You Don't Know: Uncertainty Calibration of Process Reward Models", "authors": "Young-Jin Park,Kristjan Greenewald,Kaveh Alim,Hao Wang,Navid Azizan", "background": "过程奖励模型（PRMs）在指导大型语言模型（LLMs）的推理时缩放算法方面起着关键作用。然而，即使最先进的PRMs也不能很好地进行校准，特别是在使用较小的LLMs进行推理轨迹完成时，它们倾向于高估部分推理步骤将导致正确最终答案的成功概率。", "innovation": "作者提出了一种基于分位数回归的校准方法，调整PRM输出以更好地与真实的成功概率对齐。结合校准的成功估计和置信区间，提出了一个实例自适应缩放（IAS）框架，动态调整计算预算，基于估计的推理轨迹导致正确答案的几率。与传统方法分配固定数量的推理轨迹不同，这种方法会根据每个实例和推理步骤进行调整，使用校准后的PRMs。实验证明这种方法能实现较低的校准误差，对于启用有效的IAS和降低推理成本（同时保持最终答案准确度）是必要的，并且更高效地利用计算资源于更有信心的问题上。", "conclusion": "（i）我们的PRM校准方法实现了小的校准误差，优于基线方法；（ii）校准对于启用有效的IAS至关重要；（iii）提出的自适应实例缩放策略减少了推理成本，同时保持最终答案的准确性，更加有效地利用计算资源于更有信心的问题上。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.03265", "html_url": "https://arxiv.org/abs/2501.03265", "title": "认知边缘计算：针对广泛部署优化大规模模型和AI代理的综合调查", "title_en": "Cognitive Edge Computing: A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment", "authors": "Xubin Wang,Qing Li,Weijia Jia", "background": "本文调查了认知边缘计算作为一种实用且系统的方法，用于在资源受限的设备上在网络边缘部署具有推理能力的大语言模型（LLMs）和自主AI代理的过程。讨论了这种部署面临的问题和挑战，包括如何在有限的内存和计算预算下保留多层次的推理能力，如何在延迟、能源、隐私和容量之间做出权衡，以及如何根据任务需求和设备限制定制计算特性。文章还指出了现有挑战，如模态感知推理基准、透明和可重复的能量报告、具有边缘导向的安全/对齐评估，以及多代理测试平台的建设问题。", "innovation": "提出了一种统一且保持认知能力的框架，涵盖：(1) 模型优化（量化、稀疏化、低秩适应、蒸馏），旨在在紧绷的内存/计算预算下保留多层次推理能力；(2) 系统架构（本地推理、弹性卸载、云-边缘协作），权衡延迟、能量、隐私和容量；(3) 适应性智能（上下文压缩、动态路由、联邦个性化），根据任务难度和设备限制定制计算特性。并将这些领域的进展综合起来，应用于边缘环境的特点和限制，并制定了标准化的评估协议，涵盖延迟、吞吐量、每 token 能耗、准确度、稳健性、隐私和可持续性等指标，以提高可比性。", "conclusion": "论文强调了从跨层算法设计、运行时和硬件角度进行共同设计，以在边缘设备上交付可靠、高效且保护隐私的认知能力。指出了未来工作的挑战，包括模态感知推理基准、透明和可重复的能量报告、具有边缘导向的安全/对齐评估以及多代理测试平台的建设，并为实践者提供了指导方针。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16471", "html_url": "https://arxiv.org/abs/2506.16471", "title": "渐进而时退火的扩散模型在玻尔兹曼密度采样中的递进推理", "title_en": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities", "authors": "Tara Akhound-Sadegh,Jungyoon Lee,Avishek Joey Bose,Valentin De Bortoli,Arnaud Doucet,Michael M. Bronstein,Dominique Beaini,Siamak Ravanbakhsh,Kirill Neklyudov,Alexander Tong", "background": "从目标非规范化概率密度高效采样仍然是一个核心挑战，广泛应用于高影响的科学应用中。一种有希望的方法是设计一种递归采样器，借鉴最先进的生成扩散模型中的关键思想，如概率路径设计。然而，现有的所有基于扩散的方法仍无法从简单的分子系统规模的分布中采样，这表明当前方法的局限性。本文探讨了这一挑战，并提出了一种新的框架——渐进而时退火(PITA)，以解决这个问题。该框架结合了两种互补的插值技术：I. 玻尔兹曼分布退火；II. 扩散平滑，通过数据增强和温度调节来增强采样精度和效率，从而克服了现有的挑战。", "innovation": "本文提出了一种称为PITA的新框架，这是一种结合了两种互补的插值技术的递归采样方法——玻尔兹曼分布退火和扩散平滑。这种方法通过从高到低地训练一系列扩散模型，利用温度调节和工程样本访问来提高采样效率和精度。PITA采用了新的费曼-卡克偏微分方程与归序蒙特卡洛相结合的方法，在推理过程中实现截取温度，并且这个方法使得在笛卡尔坐标下对 N 体粒子系统、丙氨酸二肽和三肽进行平衡采样成为可能，相比以往的方法大幅度降低了能函数评估的次数。", "conclusion": "PITA首次实现了对玻尔兹曼密度的有效采样，特别是对于N体粒子系统、丙氨酸二肽和三肽的笛卡尔坐标，其能函数评估次数显著减少。这种方法为大规模复杂系统的高效采样提供了新的可能性和方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22331", "html_url": "https://arxiv.org/abs/2506.22331", "title": "Less Greedy Equivalence Search", "title_en": "Less Greedy Equivalence Search", "authors": "Adiba Ejaz,Elias Bareinboim", "background": "Greedy Equivalence Search (GES) 是一种基于评分的经典因果发现算法，可以从观测数据中恢复描述数据的马尔可夫等价类图。但在实践中，GES面临计算成本高和有限样本准确度低两大挑战。", "innovation": "提出了一种名为 Less Greedy Equivalence Search (LGES) 的改进算法。这种算法保留了 GES 的理论保证，同时部分解决了上述挑战。LGES 对贪婪步骤进行了修改，具体来说，它避免对那些评分表明某些条件独立性的变量进行边插入。这导致搜索速度提高多达 10 倍，并显著减少了结构误差。此外，LGES 可以利用先验知识引导搜索，并在数据矛盾时纠正这些知识。此外，LGES 可以利用干预数据来进一步细化所学的观测等价类。LGES 证明，在样本极限下可以恢复真正的等价类，即使存在错指定性的知识。实验结果表明，与 GES 以及其他基线方法相比，LGES 在速度、准确性和对错指定性知识的鲁棒性方面表现出色。", "conclusion": "我们的代码可以在该网址获取。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03279", "html_url": "https://arxiv.org/abs/2507.03279", "title": "基于收敛信息追求的大型语言模型交互式引导方法", "title_en": "Conformal Information Pursuit for Interactively Guiding Large Language Models", "authors": "Kwan Ho Ryan Chan,Yuyan Ge,Edgar Dobriban,Hamed Hassani,René Vidal", "background": "大型语言模型（LLMs）在交互式问答任务中有显著应用，这是一个多轮对话过程，相比之下单轮对话是静态的。已有的信息追求（Information Pursuit, IP）策略通过最大化信息增益或最小化不确定性来选择查询，但实际操作中LLM的概率估计可能过于自信或不够自信，导致了次优的查询选择和预测性能。为了改善迭代过程中的不确定性估计，提出了一种新的方法——收敛信息追求（Conformal Information Pursuit, C-IP），它利用收敛预测集与条件熵之间的关系来估计不确定性。实验结果表明，与之前的IP方法和基于不确定性推理的方法相比，C-IP在预测性能和查询链长度方面更优。同时在医学交互场景中，C-IP的表现与直接单轮预测相当，但更具可解释性。", "innovation": "提出了一种基于收敛预测集的不确定性估计方法，简称C-IP。C-IP利用预测集和条件熵之间的关系，通过平均测量收敛预测集的大小来估计不确定性，这种方法更稳健且与分布无关，解决了一些现有方法中由于LLM概率估计问题带来的不足。C-IP在实际应用中的表现优于传统的信息追求方法，并且具有更好的可解释性。", "conclusion": "C-IP在多个实验中展现了优于传统信息追求方法和基于不确定性推理的方法的预测性能和解释能力，特别是在医疗交互场景中具有竞争力。这表明，C-IP不仅在理论上有一定的创新性，而且在实际应用中也能提供更优的解决方案，非常适合作为大型语言模型交互式问答任务中的查询策略。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05636", "html_url": "https://arxiv.org/abs/2507.05636", "title": "图学习", "title_en": "Graph Learning", "authors": "Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong", "background": "图学习已经迅速成为一个机器学习和人工智能（AI）领域的关键子领域。它的进展始于早期的图论方法，随着图神经网络（GNNs）的出现，进一步提速。过去的十年中，可扩展架构、动态图建模、多模态学习、生成AI、可解释AI（XAI）和负责任AI的发展使得图学习的应用范围更加广泛，包括但不限于药物发现、欺诈检测、推荐系统和科学推理等复杂环境。图学习之所以重要，是因为它能够建模传统机器学习难以捕捉的复杂、非欧几里得关系，从而更好地支持实际应用。然而，可扩展性、泛化能力、异质性、可解释性和可信性等方面的挑战需要解决，才能充分发挥其潜力。", "innovation": "本文综述提供了图学习的一个全面介绍，重点关注关键维度，如可扩展、时间动态、多模态、生成、可解释和负责任的图学习。我们回顾了处理大规模图状结构、捕捉动态时间依赖性、整合异构数据模态、生成新颖的图样本、增强可解释性以促进信任和透明度的最新技术。此外，我们探讨了诸如隐私和公平性等伦理考虑，以确保负责任地部署图学习模型。该综述还指出了新兴主题，并对未来方向提出了见解。", "conclusion": "该综述为研究和从业者提供了有价值的知识资源，使他们能够了解图学习迅速变化的领域。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17494", "html_url": "https://arxiv.org/abs/2507.17494", "title": "信任与否：无线网络中基于机器学习的资源分配校准问题", "title_en": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks", "authors": "Rashika Raina,Nidhi Simmons,David E. Simmons,Michel Daoud Yacoub,Trung Q. Duong", "background": "在下一代通信网络中，机器学习模型不仅需要提供准确的预测，还需要提供准确反映正确决策概率的信心分数。本文研究了在单用户多资源分配框架下，基于机器学习的停电预测器的校准性能。通过分析校准和未校准情况下系统的停机概率，本文揭示了在不同资源条件下，预测器停机概率的变化规律。此外，作者还探讨了校准预处理对最小可实现停机概率的影响，并提出了优化分类阈值以实现特定可靠性的方法。", "innovation": "本文提出了关于基于机器学习的无线网络资源分配校准性能的关键理论性质，并发现了在不同资源条件下停机概率的变化规律。通过建立理论模型和实验验证，本文证明了校准预处理不引入有关未来信道状态的新信息，不能改善系统的最小可实现停机概率。还提出了一个单调性条件，以确保准确性和信心函数满足特定条件下性能的提高。该研究还使用了Platt扩展和等温回归等后处理校准技术进行了严格的仿真分析。", "conclusion": "研究结果建议，在单用户多资源分配框架中，根据特定的可靠性需求选择分类阈值。基于机器学习的预测器的准确性和信心函数需要满足特定的单调性条件，以实现性能的提高。此外，系统设计者可以根据本文提出的方法选择合适的校准方法，以达到特定的可靠性目标。通过实验验证，本文揭示了校准对停机概率的影响，并为未来基于机器学习的资源分配系统中的校准方法提供了一种新的理论框架。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21069", "html_url": "https://arxiv.org/abs/2507.21069", "title": "GAITEX: 使用惯性和光学传感器的受损步态和康复运动的人体运动数据集", "title_en": "GAITEX: Human motion dataset of impaired gait and rehabilitation exercises using inertial and optical sensors", "authors": "Andreas Spilz,Heiko Oppel,Jochen Werner,Kathrin Stucke-Straub,Felix Capanni,Michael Munz", "background": "穿戴式惯性测量单元（IMUs）提供了一种在临床和日常生活环境中评估人类运动的低成本方法。然而，为稳健地评估理疗运动和步态分析而开发的相关分类模型需要大量的多样化数据集，这些数据集收集过程既昂贵又耗时。因此，本研究提供了包含物理治疗和步态相关运动的多模态数据集，包括正确和临床相关的变体，这些数据集从19名健康受试者处收集，使用同步的IMUs和光学标记的运动捕捉（MoCap）。该数据集包含了九个IMU和68个标记追踪全身运动学的数据。四个标记定每个IMU允许直接比较IMU和MoCap获得的姿态。此外，还提供了与常用段坐标系统对齐的IMU姿态、受试者特定的OpenSim模型、逆运动学输出以及IMU的姿态可视化工具。", "innovation": "该研究所呈现的多模态数据集集成了IMUs和MoCap在记录理疗运动和步态相关的练习时的数据，为研究和开发提供了一个宝贵资源。特别是，数据集包含了全面的注释，如运动质量评级和时间分割，支持各种机器学习任务，包括运动评估、步态分类、时间分割和生物力学参数估计。", "conclusion": "该数据集支持多种机器学习任务，并提供了后处理、对齐、逆运动学、技术支持验证的代码以促进可重复性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05305", "html_url": "https://arxiv.org/abs/2506.05305", "title": "ProRefine：使用文本反馈的推理时调整提示", "title_en": "ProRefine: Inference-Time Prompt Refinement with Textual Feedback", "authors": "Deepak Pandita,Tharindu Cyril Weerasooriya,Ankit Parag Shah,Isabelle Diana May-Xin Ng,Christopher M. Homan,Wei Wei", "background": "多智能体工作流程中，多个AI代理协作完成复杂的任务，如推理或规划，在许多前沿商业应用中起着重要作用，对研究人员具有极大的吸引力。这些工作流程依赖于提供的模型角色的提示设计，不当的提示可能导致性能不佳，从而在代理系统中产生级联效应，限制其可靠性和可扩展性。为了应对这一重要的推理时提示优化问题，引入了ProRefine，一种利用LLMs生成和应用文本反馈的动态提示优化方法。", "innovation": "ProRefine在不进行额外训练或获取真实标签的情况下，为多步推理任务动态优化提示。在五个基准数学推理数据集上评估，ProRefine显著超越了零样本思维链基线，提高了3到37个百分点的准确性，使得较小模型能够接近更大模型的性能，展示了其构建成本效益更高且更强大的混合AI系统的能力。", "conclusion": "该方法不仅提高了准确性，还允许较小模型接近更大模型的性能，强调了ProRefine在构建更低成本且更强大的混合AI系统方面的潜力，从而促进高质量AI的普及。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05480", "html_url": "https://arxiv.org/abs/2511.05480", "title": "关于流匹配KL散度", "title_en": "On Flow Matching KL Divergence", "authors": "Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu", "background": "该研究推导了流匹配分布近似中Kullback-Leibler (KL)散度的确定性的非渐近上界。特别是在$L_2$流匹配损失上界为$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol\boldsymbol{\boldsymbol\boldsymbol\boldsymbol{\negthinspace\negthinspace}}\neg{negthinspace}\negthinspace}\boldsymbol{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\boldsymbol{\negt{negthinspace}\neg{negthinspace}\negthinspace}}$，真数据分布与估计分布之间的KL散度被上界为$A_1 \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}}\boldsymbol{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\boldsymbol{{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}}\boldsymbol{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}}\boldsymbol{{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}}\boldsymbol{\negthinspace\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace} \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}^2$约束条件下，真数据分布与估计分布之间的KL散度被上界为$A_1 \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace} \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace} \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}^2 + A_2 \boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\boldsymbol{\negt{\neg{negthinspace}\negthinspace}}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}\neg{negthinspace}\negthinspace}^2$，其中常数$A_1$和$A_2$仅依赖于数据和速度场的光滑性。因此，这一界的提出意味着流形匹配变换器在总变异（TV）距离下的统计收敛速率。我们展示了在估计光滑分布时，流形匹配几乎达到最小最大最优效率，并且赋予流匹配效率在TV距离下与扩散模型相当。我们的研究成果以此理论支持了在合成和学习速度下进行数值研究的结论。", "innovation": "研究推导了流匹配分布近似的KL散度的非渐近上界，并展示了这种近似方法在估计光滑分布时，几乎达到最小最大最优效率，使得流匹配方法在用TV距离测量的统计效率上与扩散模型相当。", "conclusion": "本研究揭示了流匹配方法在 KL 散度和 TV 距离测量下的统计效率与扩散模型相当，并在估计光滑分布时表现出几乎最小最大最优的效率率。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09601", "html_url": "https://arxiv.org/abs/2507.09601", "title": "NMIXX：适用于跨语言金融探索的领域自适应神经嵌入", "title_en": "NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance", "authors": "Hanwool Lee,Sara Yu,Yewon Hwang,Jonghyun Choi,Heejae Ahn,Sungbum Jung,Youngjae Yu", "background": "通用的句子嵌入模型在捕捉特定领域的金融语义时常常表现不佳，尤其是在资源稀缺的语言如韩语中，这主要是由于领域特异的专业术语、时间上的语义变化以及双语词汇不匹配。因此，作者提出了NMIXX（神经嵌入用于跨语言金融探索），这是一种通过微调18,800个高信心三元组（包括同域的同义句对、源自语义变化类型的手负样本以及精确的韩语-英语翻译）进行领域适应的跨语言嵌入模型。为了测试该模型，作者还提供了一个包含1,921对金融句子对的基准数据集KorFinSTS（包括新闻、披露、研究报告和法规），这个数据集能够揭示一般基准数据集忽略的细微差别。", "innovation": "作者开发了NMIXX，这是一种专门用于金融领域的跨语言嵌入模型。借助18,800个经过严格筛选的三元组进行微调，这些三元组包括同域的同义句对、基于语义变化类型的手负样本以及精确的韩语-英语翻译。此外，作者还发布的KorFinSTS数据集，这是一个包含金融句对的基准，可以展现一般基准无法揭示的细微差别。评价结果显示，多语言微调的bge-m3变种在英语文本理解中的Spearman等级提升为+0.10，在KorFinSTS中的提升为+0.22，超过了其他模型在平均STS性能方面的微小损失。此外，分析还表明，具有更丰富的韩语标记覆盖率的模型更有效适应领域，突显了在资源稀缺的跨语言环境中优化分词器的重要性。", "conclusion": "通过提供NMIXX模型和KorFinSTS基准数据集，作者为金融领域的跨语言表示学习提供了坚实的基础工具，这将有助于学术界和工业界更好地理解和应用金融文本。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02189", "html_url": "https://arxiv.org/abs/2508.02189", "title": "小模型预训练中的元学习学习动态", "title_en": "Learning Dynamics of Meta-Learning in Small Model Pretraining", "authors": "David Demitri Africa,Yuval Weiss,Paula Buttery,Richard Diehl Martinez", "background": "大型语言模型虽强大但成本高昂。本文探讨元学习是否能改进小语言模型的预训练，使其不仅效果更好，而且更具可解释性。为此，研究者结合了一阶MAML与部分掩码LM预训练方法，创建了四种LLama类似的仅解码器模型（参数量从11M到570M不等），并在多项NLP基本任务和实际应用中进行了评估。这些研究基于与传统训练方法的对比，旨在揭示元学习在小模型预训练中的具体效果和动态过程。", "innovation": "本文创新性地将一阶MAML与部分掩码LM预训练相结合，明确了小模型预训练中的元学习动态。研究表明，与其他传统方法相比，本文方法能在较短的时间内达到相同的损失值、在同等计算资源下提高多语言通用命名实体识别的F1分数，并且训练动态更加直观易读。模型在训练过程中初期表现为不同特征的扩展（分散化），随后缩小成一个共享子空间（压缩化），这一两阶段转变过程可通过有效的秩曲线和注意力头熵的变化来体现，进而揭示了元适应性的简明可解释的特征。", "conclusion": "本文通过结合一阶MAML与部分掩码LM预训练方法，成功展示了小模型预训练中元学习效果显著提升及更易于解释的特点。通过有效的秩曲线和注意力头熵的变化特征进一步证明了元适应性的多阶段动态过程，为后续研究和实践提供了一种新的思路和方法。相关代码、模型检查点和WandB日志均已公开共享。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14926", "html_url": "https://arxiv.org/abs/2508.14926", "title": "具有伦理意识的安全强化学习在交互式城市驾驶中对罕见事件风险控制", "title_en": "Ethics-Aware Safe Reinforcement Learning for Rare-Event Risk Control in Interactive Urban Driving", "authors": "Dianzhao Li,Ostap Okhrin", "background": "自动驾驶汽车有望减少交通事故并提高交通效率，但其广泛应用取决于将可信且透明的伦理决策嵌入到常规和紧急操作中，尤其是保护行人和骑自行车者等脆弱道路使用者。本文构建了一个分层的安全强化学习框架，该框架将伦理意识的成本信号加入到标准驾驶目标中。", "innovation": "本文提出了一个分层的安全强化学习框架，该框架在决策层面上通过组合碰撞概率和伤害严重性的综合伦理风险成本来训练安全强化学习代理，生成高层运动目标。此外，该方法还采用了一种动态、风险敏感的选择优先经验回放机制，对罕见但关键的高风险事件进行强化学习。在执行层面上，该方法结合多项式路径规划和PID及Stanley控制器，将这些目标转化为平滑且可行的轨迹。此类方法已经在包含多样车辆、骑自行车者和行人的大型规模真实世界交通数据集上进行了闭环模拟环境训练和验证，并证明了在降低潜在风险的同时保持自我性能和舒适度方面优于基准方法。", "conclusion": "本文为人类混合交通场景下的安全强化学习提供了明确伦理目标的可复制基准。实验结果表明，该政策在两次交互基准测试和五个随机种子下将冲突频率降低了25-45%，同时保持了舒适度指标在5%内。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18312", "html_url": "https://arxiv.org/abs/2508.18312", "title": "DPO数据中的关键因素", "title_en": "What Matters in Data for DPO?", "authors": "Yu Pan,Zhongze Cai,Guanting Chen,Huaiyang Zhong,Chonghuan Wang", "background": "直接偏好优化（DPO）已成为将大型语言模型（LLMs）与人类偏好对齐的一种简单且有效的方法，无需学习奖励模型。尽管DPO的应用越来越广泛，但关于哪种类型的偏好数据对于DPO性能至关重要这一基本问题仍未得到解答。", "innovation": "本文通过对偏好数据分布如何影响DPO的系统研究，从理论和实证两个方面提供了见解。主要发现是，选择的响应质量对优化DPO目标起主导作用，而被拒绝的响应质量对整体影响较为有限。此外，我们还研究了在线DPO环境，发现它实际上可以简化为仅对选中的响应进行监督微调。大量跨领域的实验进一步证实，提高选择响应的质量始终能提升性能，而这一效果几乎不受拒绝响应质量的影响。", "conclusion": "研究结果解释了某些广泛应用策略背后的机制，并为构建对大型语言模型对齐具有高影响力的偏好数据集提供了实用洞见。通过改善选择响应的质量，可以在不影响被拒绝响应质量的情况下，显著提升DPO性能。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Renée Rosillo", "background": "该论文介绍了一种名为TimeCopilot的新框架，旨在结合时间序列基础模型（TSFMs）和大型语言模型（LLMs），自动完成时间序列预测流程。这一框架的目标是使时间序列预测更加简化和高效，同时提供自然语言解释和直接对未来情况进行查询的能力。该框架适用于多个时间序列预测家族，并支持多种商业和开源大型语言模型。通过大规模GIFT-Eval基准测试，TimeCopilot展示了其在低成本下的卓越概率预测性能。论文指出，该框架为可重复、可解释和可访问的代理型预测系统提供了实用的基础。", "innovation": "TimeCopilot是第一个开源的时间序列预测框架，它通过单一的统一API结合了多种时间序列基础模型和大型语言模型。该框架自动化了从特征分析、模型选择、交叉验证到预测生成的整个预测管道，并提供自然语言解释和直接的未来查询支持。更重要的是，该框架对于大型语言模型是无偏见的，能够兼容商业和开源模型，并支持各种预测家族的集成。由此，该框架使得预测过程更加高效和可解释，并且展示了与现有系统的优越性能。", "conclusion": "TimeCopilot凭借其在大型GIFT-Eval基准测试中的卓越概率预测性能和低成本优势，为代理型预测系统提供了可靠的支撑。论文还强调了该框架对于实现可重复、可解释和可访问的预测系统的潜在应用价值。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04270", "html_url": "https://arxiv.org/abs/2507.04270", "title": "ZERO：具备多模态提示的工业就绪视觉基础模型", "title_en": "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts", "authors": "Sangbum Choi,Kyeongryeol Go,Taewoong Jang", "background": "基础模型虽然在人工智能领域取得了革命性的进展，但在实际工业应用中面临零样本部署的挑战，主要原因是没有高质量的领域特定数据集。Superb AI提出了ZERO，这是一种工业应用准备的视觉基础模型，通过利用多模态提示（文本和视觉）实现推广，而无需重新训练。ZERO在包含90万标注样例的专有工业数据集上进行了训练，并展示了在LVIS-Val等学术基准上的竞争力，以及在37个不同的工业数据集上的优异表现。此外，ZERO还在CVPR 2025对象实例检测挑战和基础少样本对象检测挑战中分别取得了第2名和第4名的好成绩，证明了其在最少的适应和有限的数据条件下具有很强的实用性和推广性。据我们所知，这是第一个专门为领域特定的零样本工业应用构建的视觉基础模型。", "innovation": "ZERO利用多模态提示（文本和视觉）实现推广，而无需重新训练，展示了在多个工业数据集上的优越性能，并在多个挑战赛中取得了好名次。这是一个工业应用准备的视觉基础模型，特别适用于领域特定的零样本应用。", "conclusion": "ZERO在专有工业数据集上进行了训练，展示了在多种工业数据集和挑战赛上的优越性能，证明了其在少样本应用中的实用性与推广性，是第一个专门为领域特定零样本工业应用设计的视觉基础模型。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query：通过多智能体协作在SQL辅助表格理解中释放大语言模型的潜力", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表格理解需要结构化的多步骤推理。大型语言模型（LLMs）在面对表格数据的结构性复杂性时存在限制。尽管多智能体框架在SQL生成方面显示出潜力，但现有方法往往存在理解表格结构的局限性、错误传播导致的无效查询以及过度依赖执行结果等问题。", "innovation": "提出了一种名为Chain-of-Query (CoQ)的新型多智能体框架，用于SQL辅助的表格理解。CoQ通过使用自然语言风格的表结构表示来抽象掉结构噪声，增强了理解能力；采用逐句SQL生成策略以提高查询质量；并通过混合推理划分将基于SQL的机械推理与LLM的基础逻辑推理分离，减少了对执行结果的依赖，从而提高了表格理解的有效性。", "conclusion": "在四大模型和五个广泛应用的基准测试中，CoQ取得了显著的准确性提升和无效SQL生成率的大幅降低，相比之前的通用LLM、SQL辅助和混合基础模型具有更优的效果，证明在表格理解方面的优越性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23994", "html_url": "https://arxiv.org/abs/2509.23994", "title": "Policy-as-Prompt: 将AI治理规则转化为AI代理的护栏", "title_en": "Policy-as-Prompt: Turning AI Governance Rules into Guardrails for AI Agents", "authors": "Gauri Kholkar,Ratinder Ahuja", "background": "随着自主人工智能代理在监管严格和安全性至关重要的应用场景中被广泛使用，组织需要有效的方式来将政策转化为可执行的控制措施。该研究背景在于提供一种能够将非结构化设计文档（如产品需求文档、测试驱动设计和代码）转化为可验证运行时护栏的监管机器学习框架。", "innovation": "该研究提出了一种名为Policy-as-Prompt的方法，通过读取设计文档和风险控制措施构建源链接政策树，并将其编译为轻量级、基于提示的分类器以实现实时运行时监控。该系统旨在执行最小特权和数据最小化，并通过完整的溯源、可追踪性和审计日志提供合规评估，所有这些都与人工在环审查过程集成。研究结果显示，该系统能够降低提示注入风险、阻止超出范围的请求，并限制有毒输出。此外，它还生成了与AI治理框架一致的可审计理由。", "conclusion": "通过将政策视为可执行提示（政策即代码），这项方法使得安全设计、持续合规以及可扩展的AI安全和AI安全保证成为可能，确保可监管的机器学习系统在部署过程中的安全性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03505", "html_url": "https://arxiv.org/abs/2509.03505", "title": "LimiX：激发通用智能的结构化数据建模能力", "title_en": "LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence", "authors": "Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui", "background": "本文认为，通向通用智能的进展需要扎根于语言、物理世界和结构化数据中的互补基础模型。作者在此报告中介绍了LimiX-16M和LimiX-2M，这是他们大型结构化数据模型（LDMs）的两种实例。这两个模型能够基于联合分布变量和缺失值的查询条件预测来解决各种表格任务，同时支持在推理时的快速、无需训练的适应性。LimiX模型在11个广泛的结构化数据基准测试中进行了评估，涵盖了样本大小、特征维度、类别数量、分类到数值特征比例、缺失值以及样本到特征比例等多种场景。LimiX-16M在多个任务（包括分类、回归、缺失值填充和数据生成）中都超过了强有力的基线，有时显著超越。LimiX-2M甚至在有限的计算和内存预算下也能取得优异的成绩。此外，本文还首次研究了LDMs的扩展法则，揭示了数据和模型扩展对下游性能的影响，为表格基础建模提供了定量指导。所有的LimiX模型都可以在Apache 2.0许可证下公开获取。", "innovation": "作者提出了LimiX-16M和LimiX-2M，这两种大型结构化数据模型能够通过查询条件预测解决广泛的表格任务。它们通过预训练使用掩蔽联合分布建模，在不依赖特定任务架构或专用训练的情况下，展示了在多种任务上的优越性能，尤其是在有限资源下也能取得强劲成果。此外，还提供了LDMs的首次扩展法则研究，揭示了数据和模型扩展对效率的影响。", "conclusion": "LimiX-16M 和 LimiX-2M 在多项基准测试中超越了传统基线模型，并在各种大规模结构化数据分析任务中表现出色。LimiX-2M 即使在资源受限的环境中也能实现高效的数据处理。首次研究了 LDMs 的扩展法则，为更广泛的任务提供了优化指针。所有模型均可在开源许可下获取。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19088", "html_url": "https://arxiv.org/abs/2509.19088", "title": "一项关于数字孪生的超大规模研究揭示了其优势、弱点和进一步改进的机会", "title_en": "A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement", "authors": "Tianyi Peng,George Gui,Daniel J. Merlau,Grace Jiarui Fan,Malek Ben Sliman,Melanie Brucks,Eric J. Johnson,Vicki Morwitz,Abdullah Althenayyan,Silvia Bellezza,Dante Donati,Hortense Fong,Elizabeth Friedman,Ariana Guevara,Mohamed Hussein,Kinshuk Jerath,Bruce Kogut,Akshit Kumar,Kristen Lane,Hannah Li,Patryk Perkowski,Oded Netzer,Olivier Toubia", "background": "数字孪生（digital twins）技术被预期将在社会科学和决策制定中发挥重大作用。然而，目前尚不清楚这些孪生体是否能够准确反映其所模拟的个体。本研究通过在有代表性的美国面板样本及其数字孪生之间进行19项事先注册的研究，利用丰富的个体数据，跨多个领域和刺激（包括前所未见的刺激）进行直接对比，探讨了数字孪生的模拟准确性及其信度。研究发现孪生体在个体反应上的再现在75%左右，尽管如此，这种准确性并未高于仅基于人口统计学的通用角色模型。研究表明，当孪生体整合详细个人资料时，相关性会提高，有时甚至超过了那些需要额外数据的传统机器学习基准。此外，孪生体在社交和个人特质方面表现出优势，但在政治方面则表现较差，而其准确性也受教育水平、收入和政治观点及宗教参与度的影响。这项研究揭示了数字孪生技术的潜力及当前的限制，为该领域的进一步研究和发展提供了指导方针。", "innovation": "该研究通过大规模的预注册实验，直接对比数字孪生和真实个体的行为，利用详细的个人数据建立了孪生体模型，这些模型能够跨多种领域和刺激进行准确的响应再现，这为数字孪生技术的应用提供了新的视角和验证方法。更重要的是，该研究通过比较不同条件下的孪生体效果，指出了数字孪生技术在某些领域的优势和不足，为未来改进提供了具体的参考依据。此外，所有实验数据和代码都公开发布，确保了研究的透明度和可重复性，推动了该领域的进一步研究和发展。", "conclusion": "该研究揭示了数字孪生技术在某些方面能较好地再现个体行为，同时也暴露了其在特定领域和条件下存在的局限性。数字孪生技术能够捕捉个体之间的一般差异，但尚不能精确反映出特定个人的独特判断。未来需要进一步研究以克服这些局限，提高数字孪生技术的准确性和适用性。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12386", "html_url": "https://arxiv.org/abs/2509.12386", "title": "Amulet: 一种评估机器学习防护措施和风险之间交互的Python库", "title_en": "Amulet: a Python Library for Assessing Interactions Among ML Defenses and Risks", "authors": "Asim Waheed,Vasisht Duddu,Rui Zhang,Sebastian Szyller", "background": "机器学习模型面临着各种安全、隐私和公平性的风险。大多数防御措施都是为了应对每种风险（预期交互）而设计的，但这些防御措施可能会无意中增加其他无关风险（意外交互）的易感性。现有的防御方式主要针对单一风险进行防御，缺乏对多风险之间相互影响的系统性评估工具。因此，本文介绍了Amulet，一种Python库，旨在进行防御措施和多重风险之间的预期与意外交互评估。", "innovation": "Amulet是首个用于评估机器学习防护措施和风险之间交互的Python库，其具有代表性攻击、防御和度量的全面性；由于模块化设计，使得易于扩展新的模块；采用用户友好的API模板，确保输入和输出的一致性；适用于评估新型交互。通过满足这四个特性，Amulet提供了一个统一的基础框架，用于研究防御措施如何交互，并实现了第一个对多种风险之间的意外交互进行系统的评估。", "conclusion": "Amulet为理解和评估机器学习防护措施和风险之间的交互提供了统一的基础框架，使得研究人员能够系统地研究意外交互。这将有助于提高机器学习系统的整体安全性、隐私性和公平性，降低潜在风险的影响。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05210", "html_url": "https://arxiv.org/abs/2508.05210", "title": "先进的注意力机制和TS混频器结合的混合Transformer-LSTM技术在钻井贯眼率预测中的应用", "title_en": "Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction", "authors": "Saddam Hussain Khan(Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "钻井过程中贯眼率（ROP）的预测对于钻井优化至关重要，但因钻井数据具有非线性、动态、异质性等特点，这一任务仍然具有挑战性。传统经验、物理和标准机器学习模型依赖于过于简单的假设或耗时的特征工程，限制了它们建模长期依赖性和复杂特征交互的能力。", "innovation": "本研究提出了一种新的深度学习混合LSTM-Transform-Mixer-Attention框架。该框架首先通过定制的长短期记忆（LSTM）网络处理输入数据，以捕捉与钻井周期对齐的多尺度时间依赖关系。随后通过具有钻井特定位置编码的增强Transformer编码器和实时优化，进一步精炼特征。同时引入了并行时间序列混频块（TS-Mixer），以高效建模静态和分类参数（如岩性指数和泥浆特性）之间的跨特征交互。从增强的Transformer和TS-Mixer模块提取的特征表示通过专门的融合层结合，并通过自适应注意力机制动态赋予相关特征上下文权重，从而增强区分性表示学习并实现高精度的贯眼率预测。该框架结合了顺序记忆、静态特征交互、全局上下文学习和动态特征加权，提供了一个综合的解决方案以应对钻井动态的异构性和事件驱动特性。", "conclusion": "在真实钻井数据集上的实验证明了该方法的优越性能，实现了R平方为0.9991，平均绝对百分比误差（MAPE）为1.447%，显著优于现有基线和混合模型。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20866", "html_url": "https://arxiv.org/abs/2508.20866", "title": "AI Agentic Vulnerability Injection and Transformation with Optimized Reasoning", "title_en": "AI Agentic Vulnerability Injection And Transformation with Optimized Reasoning", "authors": "Amine Lbath,Massih-Reza Amini,Aurelien Delaitre,Vadim Okun", "background": "随着软件系统复杂性和网络攻击手段的不断提升，有效自动生成和修复漏洞的系统变得至关重要。尽管使用深度学习模型的数据驱动方法展现出潜力，但它们严重依赖于大量且准确标注的数据集。然而，现有数据集存在标签噪声、漏洞范围有限或未能反映真实软件环境中出现的漏洞等问题，这限制了这些解决方案的大规模基准测试。", "innovation": "本文提出了AVIATOR，这是一种新的AI代理漏洞注入工作流。AVIATOR自动注入符合现实场景、特定类别的漏洞，以生成高质量、多样化、大规模的漏洞数据集。与先前的单一方法不同，AVIATOR整合了专门的AI代理、功能代理和传统的代码分析工具，这些工具可以模拟专家级的推理过程。AVIATOR结合了语义分析、基于LoRA的微调和检索增强生成技术，以及基于静态分析和基于LLM的鉴别器的后注入验证。这种模块化分解使专门的代理能够专注于不同的任务，提高了注入的健壮性和减少了工作流程中的误差传播。", "conclusion": "在三个不同基准测试中的评估表明，AVIATOR实现了91%-95%的注入成功率，这在准确性和覆盖软件漏洞的范围方面都显著优于现有的自动数据集生成技术。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15418", "html_url": "https://arxiv.org/abs/2510.15418", "title": "精细调整MedGemma以提高临床captioning以增强针对马来西亚临床实践指南的多模态RAG系统", "title_en": "Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs", "authors": "Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye", "background": "Retrieval-Augmented Generation（RAG）系统对于提供基于事实的马来西亚临床实践指南指导至关重要。然而，这些系统对于基于图像的查询的有效性受到限制，因为通用的Vision-Language模型生成的描述往往缺乏临床特异性及事实依据。因此，本研究旨在提出并验证一种框架，专门化MedGemma模型以生成高保真度的描述，作为优越的查询工具。", "innovation": "通过知识蒸馏生成合成数据集，并应用Parameter-Efficient QLoRA方法对MedGemma进行微调。评测性能包括分类准确性评估和通过RAGAS框架评估描述的忠实性、相关性和准确性。细调后的模型在分类性能上表现出显著提升，而RAGAS评估证实了描述忠实性和准确性的显著提升，从而验证了产生可靠、基于事实的描述的能力。这项工作确立了一个强大的框架来专门化医疗VLM，并验证了由此产生的模型作为高质量的查询生成器，为增强基于证据的临床决策支持的多模态RAG系统奠定了基础。", "conclusion": "本研究提出了一个专门化的框架，以提高MedGemma模型生成高质量临床描述的能力，从而增强针对马来西亚临床实践指南的RAG系统。实验结果表明，该模型在保持高性能的同时，描述的忠实性和准确性也得到了显著提升，证明了其应用于多模态RAG系统的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18116", "html_url": "https://arxiv.org/abs/2509.18116", "title": "Amortized Latent Steering: 低成本的测试时优化替代方案", "title_en": "Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization", "authors": "Nathan Egbuna,Saatvik Gaur,Sunishchal Dev,Ashwinee Panda,Maheep Chaudhary", "background": "测试时优化在大规模应用中由于推断成本高昂而难以实现。迭代细化和多步验证等技术可能需要标准编解码过程10到100倍的计算资源。隐空间测试时优化方法如LatentSeek通过引导隐藏表示来提供更直接的路径，但仍需要昂贵的单查询优化循环和多次反向传递。这些方法不能有效降低计算成本。", "innovation": "提出了一种称为Amortized Latent Steering (ALS)的潜在特征调校方法，将迭代优化过程整合为一个在线推断过程中成本恒定的单一离线计算向量。ALS计算生成成功与失败时隐状态的均值差异，然后使用该方向校准模型的隐状态：当解码偏离成功流形时，ALS会推动激活朝着它的方向调整。ALS在GSM8K和MATH-500基准测试中实现2到5倍速度提升，同时匹配或超越贪婪Step-by-Step推理和自我一致性基线，提供了高达101%的效率-准确性权衡。这些结果表明，大部分潜在优化的好处可以在离线阶段捕获，从而使复杂的推理技术适用于生产部署。", "conclusion": "这些结果展示了大部分潜在优化的益处可以在离线阶段捕获，使复杂的推理技术在生产部署中变得可行。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16227", "html_url": "https://arxiv.org/abs/2510.16227", "title": "字符串概率能告诉我们关于语法规则的什么？", "title_en": "What Can String Probability Tell Us About Grammaticality?", "authors": "Jennifer Hu,Ethan Gotlieb Wilcox,Siyuan Song,Kyle Mahowald,Roger P. Levy", "background": "关于语言模型（LMs）学习到的语法知识，仍未达成共识，这在语言学理论中有重大影响。尽管概率和语法规则在语言学中是不同的概念，但字符串的概率到底能揭示LMs哪些内部语法知识并不明显。本文从语料库数据生成过程的简单假设出发，建立了一个框架来分析语法、意义和字符串概率之间的关系。", "innovation": "本文提出了一种基于简单假设的理论框架来分析语料库数据的生成过程，得到了三个预测：（1）最小差异的字符串对之间的概率相关性；（2）模型与人类在最小差异的字符串对上的差异相关性；（3）非配对的正确和错误字符串在概率空间中的区分度较差。这些预测经过了英语和中文28万句子对的实证验证。这种分析为使用概率来理解LMs的结构知识提供了理论依据，同时也为未来的LM语法评估指明了方向.", "conclusion": "本研究展示了如何通过概率来理解LMs的结构知识，并为未来LM语法评估的研究方向提供了建议。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17797", "html_url": "https://arxiv.org/abs/2510.17797", "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "title_en": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "authors": "Akshara Prabhakar,Roshan Ram,Zixiang Chen,Silvio Savarese,Frank Wang,Caiming Xiong,Huan Wang,Weiran Yao", "background": "随着信息呈指数增长，企业面临着将未结构化数据转化为连贯、可操作的洞察方面的越来越大压力。尽管自主代理展现出潜力，但在处理领域特定的细微区别、意图对齐和企业级集成方面常常存在困难。", "innovation": "本文提出了企业深度研究（EDR），这是一种多智能体系统，整合了（1）一个主计划代理进行自适应查询分解，（2）四个专业搜索代理（通用、学术、GitHub、LinkedIn），（3）一种基于可扩展的MCP工具生态系统，支持自然语言到SQL转换、文件分析和企业流程，（4）一个可视化代理提供数据驱动的见解，以及（5）一个反思机制，用于检测知识空白并根据潜在的人工参与调整研究方向。这些组件使自动化报告生成、实时流处理和企业级部署成为可能，已在内部数据集验证。", "conclusion": "在开放性基准测试中，包括DeepResearch Bench和DeepConsult，EDR在没有任何人类引导的情况下，优于最先进的agentic系统。我们发布了EDR框架和基准轨迹，以促进多智能体推理应用的研究。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "通过前瞻性风险感知进行社会导航的学习", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "该论文描述了提交给2025年IROS RoboSense挑战赛的社交导航赛道的技术细节。该赛道旨在开发基于RGBD的感知和导航系统，使自主代理能在动态的人群密集室内环境中安全、高效且遵循社会规范地导航。该挑战要求代理从第一人称视角仅使用车载传感器（包括RGB-D观测和里程计信息）操作，而不允许访问全局地图或特权信息，并且必须遵守社会规范，例如保持安全距离和避免碰撞。", "innovation": "论文提出了一种前瞻性风险感知模块，增强社交导航性能。该模块增强了Falcon模型，使其能够理解碰撞风险，学习预测周围人类基于距离的碰撞风险评分，从而帮助代理发展出更强大的空间意识和前瞻性碰撞避免行为。在Social-HM3D基准上的评估表明，该方法在拥挤的室内场景中导航至目标时，能够更有效地保持个人空间的合规性，最终在16支参赛队伍中获得第二名。", "conclusion": "该方法通过增强代理的风险感知能力，使其在遵守社会规范的同时实现更高效的导航，特别是在动态的人群密集室内环境中。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22963", "html_url": "https://arxiv.org/abs/2510.22963", "title": "CompressionAttack：利用LLM驱动代理中的压缩提示作为新型攻击表面", "title_en": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents", "authors": "Zesen Liu,Zhixiang Zhang,Yuchong Xie,Dongdong She", "background": "LLM（大型语言模型）驱动的代理通常会使用提示压缩来减少推理成本，但这种方式引入了新的安全风险。压缩模块主要被优化以提高效率，而不是安全性，能够被恶意输入所操控，导致语义漂移并改变LLM的行为。这项研究指出提示压缩是一个新的攻击面，并提出了压缩攻击，这是第一个利用这一特点的框架。该框架包括两种策略：HardCom，使用离散对抗编辑进行硬压缩，和SoftCom，通过潜在空间扰动进行软压缩。实验表明，在多个LLM中的攻击成功率可达到80%，偏好翻转率可达98%，且高度隐蔽和可迁移。案例研究在VSCode Cline和Ollama中确认了其实际影响，并指出当前的防御措施无效，强调了需要更强的安全保护。", "innovation": "该研究识别出提示压缩是一个新的攻击面，并提出了名为CompressionAttack的框架，这是第一个利用这一特点的框架。该框架包含两种策略：HardCom使用离散对抗编辑进行硬压缩，和SoftCom通过潜在空间扰动进行软压缩。实验结果展示了高度成功的攻击效果，并且高度隐蔽和可以迁移。该研究还强调了目前防御措施的不足，需更强的安全保护措施。", "conclusion": "研究确认了提示压缩作为攻击面的严重性，并展示了攻击的有效性，强调了目前防御措施的不足。研究人员建议应加强防护措施，以应对这一新型威胁。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03211", "html_url": "https://arxiv.org/abs/2511.03211", "title": "重新构建者、务实者和活动家：促进负责任自动决策的公益诉讼", "title_en": "Retrofitters, pragmatists and activists: Public interest litigation for accountable automated decision-making", "authors": "Henry Fraser,Zahra Stardust", "background": "由于自动决策技术（ADM）的监管面临着地缘政治的阻力，有效的治理将不得不依赖现有法律的有效执行。因此，需要找到一种机制来促进问责制。", "innovation": "论文通过采访澳大利亚的公益诉讼人、科技政策活动家和技术法律学者，提出了公共利益诉讼在透明度、问责制和自动决策领域的角色，特别是在法律适应新技术环境方面的作用。论文还系统地总结了进行有效的公益诉讼关于自动决策的策略和技术。", "conclusion": "论文指出了实现有效诉讼和问责制所需要的紧迫需求，即构建必要的制度安排。论文结果对于法律与技术学者、受自动决策伤害的个人与团体、公益诉讼人、技术律师、民间社会及倡导组织、政策制定者都有重要参考价值。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22115", "html_url": "https://arxiv.org/abs/2510.22115", "title": "每一次激活都提升了：将通用推理器扩展至1万亿参数的开放语言基础", "title_en": "Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation", "authors": "Ling Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chilin Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu", "background": "介绍了Ling 2.0，这是一种基于每次激活都会增强推理能力的原则构建的系列推理导向的语言基础模型。Ling 2.0设计为在统一的Mixture-of-Experts（MoE）构架下，从数十亿到万亿参数都有广泛的扩展性，强调高稀疏性、跨尺度一致性以及效率，这些都是基于经验扩展定律的指导。该模型系列包括三个非思考（指令）模型：Ling-mini-2.0、Ling-flash-2.0和Ling-1T，从160亿到1万亿参数不等，与密集模型相比，达到了最高7倍的活跃计算效率。Ling 2.0集成了模型架构、预训练、后训练和基础设施的协调性创新：高稀疏性MoE带有MTP以提高推理效率，在中间训练中加入CoT激活以及基于强化学习的微调（DFT、Evo-CoT），并实现全规模FP8训练且带有细粒度异构管道。在万亿参数规模下，Ling-1T建立了一个新的推理准确性和计算效率之间的帕累托前沿，证明了当稀疏激活与推理目标适当对准时，可以实现规模和效率的结合。", "innovation": "Ling 2.0采用了高稀疏性MoE架构带有MTP以提高推理效率，设计了推理导向的数据与中间训练CoT激活，引入了基于强化学习的微调策略（DFT、Evo-CoT），并实现了全规模FP8训练与细粒度异构管道。", "conclusion": "Ling 2.0提供了一个语义连贯、开放且高效的平台，用于推进未来的推理与思考模型的发展，包括建立在相同基础上的Ring系列。它演示了稀疏激活在与推理目标正确对齐时可以实现扩大规模和保持效率的智能化。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22990", "html_url": "https://arxiv.org/abs/2510.22990", "title": "USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding", "title_en": "USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding", "authors": "Youssef Megahed,Robin Ducharme,Aylin Erman,Mark Walker,Steven Hawken,Adrian D. C. Chan", "background": "超声成像是一种广泛应用于临床诊断的非辐射成像技术，但其图像解释受到高噪声水平、操作者依赖性和有限视野的影响，导致观察者间差异大。当前基于深度学习的方法受限于标注数据集稀缺以及超声图像与常规图像之间的领域差距，这限制了模型在非医学数据预训练后的迁移能力。", "innovation": "本文提出了超声波自监督基础模型与遮蔽自编码器（USF-MAE），这是第一个仅基于超声数据大规模预训练的自监督MAE框架。USF-MAE 使用一个视觉变压器编码-解码架构，可以利用未标记的超声数据学习丰富的模态特定表示。该模型的预训练在46个开源数据集中共计370,000张2D和3D超声图像上完成，并公开了该数据集以促进进一步研究和可再现性。USF-MAE 在三个公共下游分类基准测试中表现优异，尤其是 breast cancer，ovarian tumors 和 gastrointestinal stromal tumors 类别的表现，超过了传统 CNN 和 Vision Transformer 基线模型，并展示了强大的跨模态泛化能力。 ", "conclusion": "USF-MAE充分展现了自监督学习在超声图像处理中的应用潜力，为超声图像的无监督学习提供了一种新的方法。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02162", "html_url": "https://arxiv.org/abs/2511.02162", "title": "使用3D生成式AI和视觉语言模型从文本实现多组件对象的机器人装配", "title_en": "Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models", "authors": "Alexander Htet Kyaw,Richa Gupta,Dhruv Shah,Anoop Sinha,Kory Mathewson,Stefanie Pender,Sachin Chitta,Yotto Koga,Faez Ahmed,Lawrence Sass,Randall Davis", "background": "近年来，3D生成式人工智能已经使得从文本提示创建物理对象成为可能，但在创建涉及多种组件类型的对象时仍然存在挑战。本文介绍了一种将3D生成式人工智能与视觉语言模型（VLMs）结合的管道，通过自然语言实现了多组件对象的机器人装配。", "innovation": "该方法利用VLMs进行零样本、多模态的几何和功能推理，解构AI生成的网格为采用预定义结构和面板组件的多组件3D模型。实验证明，基于对象的几何形状和功能，VLM能够确定哪些网格区域需要面板组件。在测试对象的评估中，用户90.6%的时间更偏好VLM生成的任务分配，而基于规则的分配为59.4%，随机分配仅为2.5%。", "conclusion": "该系统允许用户通过对话反馈精化组件分配，为使用生成式人工智能和机器人技术制作物理对象提供了更大的人类控制权和自主权。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.01348", "html_url": "https://arxiv.org/abs/2511.01348", "title": "生成式人工智能在软件工程中的未来：GENIUS项目中的欧洲工业和学术界观点", "title_en": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project", "authors": "Robin Gröpler,Steffen Klepke,Jack Johns,Andreas Dreschinski,Klaus Schmid,Benedikt Dornauer,Eray Tüzün,Joost Noppen,Mohammad Reza Mousavi,Yongjian Tang,Johannes Viehmann,Selin Şirin Aslangül,Beum Seuk Lee,Adam Ziolkowski,Eric Zie", "background": "生成式人工智能（GenAI）在软件工程领域的应用正在蓬勃发展，它能够生成代码、识别错误、推荐修复方法并支持质量保证。尽管其在编码任务中的应用前景广阔，但其在整个软件开发生命周期（SDLC）中的广泛应用尚未完全研究。关键的可靠性和责任问题、安全性和数据隐私需求需要进行深入研究和协调行动。", "innovation": "GENIUS项目集结了30多个欧洲工业和学术合作伙伴，旨在通过推动AI在SDLC各阶段的集成，解决这些挑战。项目重点关注GenAI的潜力、创新工具的开发及其面临的新兴研究挑战，以塑造软件工程的未来。此愿景论文基于跨行业对话及GENIUS联盟的经验和发现，探讨了GenAI驱动软件工程的四个核心元素：SDLC各阶段面临的挑战、未来五年关键技术与方法的预期进步、软件专业人士角色和所需技能的变化，以及GENIUS在实现这一转变方面的贡献。", "conclusion": "该论文旨在将技术创新与商业相关性相结合，旨在为研究议程和工业策略提供指导，为软件工程团队提供可靠、可扩展且工业可用的GenAI解决方案奠定基础。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03891", "html_url": "https://arxiv.org/abs/2511.03891", "title": "使用基于类别的输入图像组成提高小规模和类别不平衡数据集的诊断性能", "title_en": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition", "authors": "Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat", "background": "小规模和类别不平衡的数据集及输入图像质量差可能会导致深度学习模型产生较高的误预测率。本文探讨了通过将同一类别下的多张图像融合生成复合图像输入（CoImg），以增强训练数据的类别内部变异性，从而提高训练样本信息密度以及模型对于细微疾病模式的区分能力。", "innovation": "提出了基于类别的图像组成方法（Class-Based Image Composition），将同一类别下的多张图像融合生成复合图像输入。该方法在OCTDL数据集上进行了评估，并与原始数据集进行了比较。通过使用VGG16模型确保公平对比，结果显示利用复合图像输入的方法在准确度、F1分数和AUC值上均显著提升，特别是在处理类别不平衡或样本量小的数据集时表现更为突出。", "conclusion": "该方法显著提高了对于小规模和类别不平衡数据集的诊断性能。经过该方法处理的增强数据集在OCTDL数据集上实现了几乎完美的准确率（99.6%），F1分数（0.995）和AUC值（0.9996），并且误预测率也大幅降低。这表明该方法能够生成高质量的预测，即使在存在类别不平衡或样本量较少的情况下也能有效应用。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04247", "html_url": "https://arxiv.org/abs/2511.04247", "title": "CLIP文本编码器的脆弱性", "title_en": "On the Brittleness of CLIP Text Encoders", "authors": "Allie Tran,Luca Rossetto", "background": "近年来，多模态共嵌模型，尤其是CLIP，在零样本分类和多媒体信息检索中取得了最先进的成果。这些模型通过在共享表示空间中对齐图像和文本，大大提升了性能。然而，这种通过对比对齐训练的模态在小输入扰动下缺乏稳定性。特别是在处理手工表达的查询时，查询中的小变化会导致结果排名的大差异。本文系统分析了多种非语义查询扰动对多媒体信息检索场景的影响，覆盖了从词汇、语法到语义的不同类型的扰动。研究表明，语义和语法扰动造成的不稳定性最大，而脆弱性集中在如标点和大小写这类的表层编辑中。研究结果突显了鲁棒性作为评价视觉-语言模型的关键维度，而不仅仅是基准精度。", "innovation": "本文通过系统分析多种非语义查询扰动，揭示了语法和语义扰动对CLIP文本编码器的大型影响，同时指出表层编辑（如标点和大小写）造成的脆弱性。研究跨越了多个CLIP变体，使用TRECVID Ad-Hoc Video Search查询和V3C1视频集进行评估，提供了新颖的视角来理解视觉-语言模型的稳健性。", "conclusion": "在视觉-语言模型中，除了基准精度外，鲁棒性是评价模型的另一个关键维度。未来的工作可以基于这些发现来设计更鲁棒的模型，减少手动表达查询的扰动影响。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25441", "html_url": "https://arxiv.org/abs/2510.25441", "title": "基于现实：从离线日志学习和部署主动型大语言模型", "title_en": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs", "authors": "Fei Wei,Daoyuan Chen,Ce Wang,Yilun Huang,Yushuo Chen,Xuchen Pan,Yaliang Li,Bolin Ding", "background": "大语言模型（LLMs）在被动响应方面表现出色，但在将它们训练成能主动、目标导向的伙伴方面仍面临重大挑战，特别是在高风险领域中。当前的训练方法要么过分优化单次交互的声音属性，要么依赖脆弱且成本高的用户模拟器，导致模拟与现实之间的差距难以弥合。", "innovation": "本文提出了一个名为Learn-to-Ask的框架，无需用户模拟器即可从离线专家数据中直接学习和部署主动对话代理。通过利用每个专家行为轨迹的观察未来，本框架重构了离线策略学习问题，从而获得针对专家策略的密集、逐次的奖励信号。此外，通过自动评分校准管道确保了奖励模型的准确性，并将其应用于真实世界医疗数据集的LLMs模型，成功实现了LLMs的部署。", "conclusion": "通过Learn-to-Ask框架，LLMs在真实世界的医疗数据集上取得了优异的性能，甚至优于人类专家。这证明了该框架将离线数据转化为实际影响的能力。本研究为如何将被动大语言模型转化为积极、目标导向的应用提供了一个实用和经济可行的范例。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04692", "html_url": "https://arxiv.org/abs/2511.04692", "title": "SARC: 基于情感增强的深度角色聚类进行假新闻检测", "title_en": "SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection", "authors": "Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min", "background": "假新闻检测长期以来是社交媒体研究的焦点。最近的研究表明，整合新闻内容和用户评论的情感信息可以提升检测性能。然而，现有方法通常将情感特征视为辅助信号，忽略了角色差异，即相同的情感极性可能源自具有不同角色的用户，这限制了它们捕捉有效模式的能力。", "innovation": "本文提出了一种名为SARC的基于情感增强的角色聚类框架。SARC利用情感增强的深度聚类来识别用户角色，以提高假新闻检测效果。该框架首先通过联合评论文本表示（使用BiGRU和注意机制）和情感编码生成用户特征，然后构建了一个可微分的深度聚类模块来自动分类用户角色。最后，SARC不将假新闻标签作为唯一的监督信号，而是提出了结合角色聚类和假新闻检测的联合优化目标，进一步提高模型性能。", "conclusion": "在两个基准数据集RumourEval-19和Weibo-comp上的实验结果表明，SARC在所有指标上都优于基线模型。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04688", "html_url": "https://arxiv.org/abs/2511.04688", "title": "评估大型语言模型在处理有序程序步骤方面的推理能力", "title_en": "Evaluating LLMs' Reasoning Over Ordered Procedural Steps", "authors": "Adrita Anika,Md Messal Monem Miah", "background": "大型语言模型（LLMs）需要具备推理处理程序序列的能力，其中步骤的顺序直接影响结果。本文研究了从打乱的程序步骤重建全局有序序列的任务，使用了食品食谱数据集作为实验材料，因为正确的顺序是任务成功的关键。评价了几种LLM在零样本和少样本设置下的性能，并提供了一个综合评估框架，借鉴了排名和序列对齐领域的已有度量标准，如Kendall's Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED），这些度量标准可以从不同角度评估排序质量。分析显示，序列长度越长，模型性能下降越明显，反映出较长程序的复杂性增加。同时，输入步骤的更大错位，对应更严重的打乱，也会导致性能进一步下降。这些发现揭示了当前LLM在程序推理方面存在的局限性，尤其是在更长和更混乱的输入环境下。", "innovation": "文章提出了一种综合评估框架，针对程序推理任务适应了排名和序列对齐领域的现有度量标准，评估了多种模型在零样本和少样本情况下的性能，揭示了模型在处理长时间和混乱序列时的局限性。", "conclusion": "随着序列长度增加，模型在程序推理中的性能下降。更大的步骤错位会进一步造成性能下降。这些发现显示了当前LLM在处理较长和较混乱的程序序列时存在的局限性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04689", "html_url": "https://arxiv.org/abs/2511.04689", "title": "适应性测试用于大模型评估：心理测量学替代静态基准", "title_en": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks", "authors": "Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla", "background": "大语言模型的评估需要大量的基准项，这使得评估过程既昂贵又缓慢。现有的方法是计算固定项目集中的平均准确性，且所有项目被平等对待，尽管这些项目的质量和信息性可能不同。", "innovation": "提出了一种适应性测试框架ATLAS，利用项目反应理论（IRT）并通过Fisher信息指导的项目选择来估计模型能力。研究表明，5个主要基准中有3-6%的项目具有负区分度，这表明标注错误会损害静态评估的准确性。ATLAS实现了仅需42个项目即可达到与全基准相同的测量精度（在HellaSwag基准上，仅使用42个项目即可得到0.154的MAE，节省了90%的项目），同时保持项目曝光率低于10%和测试重叠在16-27%之间。", "conclusion": "与静态基准相比，ATLAS框架将每模型的项目曝光率保持在10%以下，测试重叠在16-27%。通过项目反应理论排名，模型的排名与准确性排名不同，显示出在准确率相同的情况下，模型会获得不同的IRT评分，并且大约23-31%的模型排名变化超过10位。项目集和校准后的项目银行已公开。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04694", "html_url": "https://arxiv.org/abs/2511.04694", "title": "通过推理提升指令层级以实现可控语言模型", "title_en": "Reasoning Up the Instruction Ladder for Controllable Language Models", "authors": "Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar", "background": "随着基于大型语言模型（LLM）的系统在实际决策中承担高风险角色，它们必须在单个提示环境中平衡来自多个来源（如模型开发人员、用户和工具）的相互冲突指令。因此，在LLM中实施指令层级（IH），其中高级指令覆盖低优先级请求，对于LLM的可靠性和可控制性至关重要。", "innovation": "将指令层级解决视为一个推理任务。通过创建VerIH数据集，包含可验证答案的指令层级约束跟随任务，该数据集包含一致和冲突的系统-用户指令，该研究展示了基于VerIH的轻量级强化学习有效将模型的一般推理能力转移到指令优先级上。微调后的模型在指令跟随和指令层级基准测试上表现出一致的改进。这种推理能力在训练分布之外的安全关键环境中也得到了泛化。通过将安全性问题视为解决潜在有害用户输入与预定义的高级政策之间的冲突，研究中的训练模型增强了对脱管和提示注入攻击的鲁棒性。", "conclusion": "指令层级的推理提供了实现可靠LLM的实用途径，其中系统提示的更新导致模型行为可控且稳健地变化。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu Xin,Di Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou", "background": "NVIDIA最近推出了Nemotron Nano V2 VL，这是Nemotron视觉-语言系列的最新版本，旨在实现强大的现实世界文档理解、长视频理解及推理任务。该模型是对之前Llama-3.1-Nemotron-Nano-VL-8B版本的重要改进，覆盖了所有视觉和文本领域，并通过架构优化、数据集和训练方法的改进实现性能提升。Nemotron Nano V2 VL构建于Nemotron Nano V2之上，这是一种Mamba-Transformer大语言模型的混合版本，并采用了创新的标记缩减技术，以提高长时间文档和视频推理的推断吞吐量。", "innovation": "Nemotron Nano V2 VL采用了创新的标记缩减技术，并基于Nemotron Nano V2构建，这是Mamba-Transformer大语言模型的混合版本。它通过改进的模型架构、更丰富的数据集和优化的训练食谱提高了性能。Nemotron Nano V2 VL在长文档和视频推理场景中的推断吞吐量更高，同时提供了BF16、FP8和FP4格式的模型检查点，并分享了大量数据集、食谱和训练代码", "conclusion": "NVIDIA发布了NVIDIA Nemotron Nano V2 VL，该模型在视觉和个人语言理解方面有显著改进。通过创新的标记缩减技术，提升了在长时间文档和视频推理上的性能。同时，共享了模型检查点和训练资源，促进相关技术的应用与研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04698", "html_url": "https://arxiv.org/abs/2511.04698", "title": "multiMentalRoBERTa: 一种多类别心理健康障碍分类器", "title_en": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder", "authors": "K M Sajjadul Islam,John Fields,Praveen Madiraju", "background": "早期从社交媒体文本中识别心理健康障碍对于及时提供支持、风险评估和引导至适当资源至关重要。这项工作旨在通过引入fine-tuned RoBERTa模型multiMentalRoBERTa，进行多类别分类以识别常见的心理健康状况，包括压力、焦虑、抑郁症、创伤后应激障碍(PTSD)、自杀意念以及中性话语。研究揭示了抑郁症和自杀意念、焦虑和PTSD之间的显著相关性，并指出压力是一个广泛且重叠的类别。", "innovation": "对比传统机器学习方法、特定领域的变压器以及基于提示的大规模语言模型，multiMentalRoBERTa在六类设置中的宏F1得分为0.839，在五类设置（不包括压力）中的宏F1得分为0.870，均优于fine-tuned MentalBERT和其他基准分类器。此外，通过使用Layer Integrated Gradients和KeyBERT等可解释性方法，作者识别出了驱动分类的关键词汇线索，特别是在区分抑郁症和自杀意念方面表现出色。这些发现强调了fine-tuned变压器在敏感情境下实现可靠且可解释检测的有效性，并且还需要关注公平性、偏见缓解和人工介入的安全协议。", "conclusion": "multiMentalRoBERTa作为轻量级、稳健且可部署的解决方案，旨在改进心理健康平台中对支持的增强。"}
{"llm_update_time": "20251111", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.27126", "html_url": "https://arxiv.org/abs/2510.27126", "title": "AURA: 一种基于强化学习的AI驱动自适应对话式调查框架", "title_en": "AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys", "authors": "Jinwen Tang,Yi Shang", "background": "传统的在线调查缺乏个性化，通常导致参与度低和表面回答。虽然AI调查聊天机器人提高了便利性，但大多数仍然是反应式的：它们依赖固定对话树或静态提示模板，因此无法在会话中根据个人用户进行调整，导致通用跟进和较差的回应质量。", "innovation": "我们通过AURA（自适应理解通过强化学习进行评估）来解决这些限制，这是一种基于强化学习框架的AI驱动自适应对话式调查系统。AURA使用LSDE度量（长度、自我披露、情绪和具体性）量化回复质量，并通过ε贪心策略在每次会话中更新预期质量增益来选择跟进问题类型，从而平衡探索与利用。该系统通过96次校园气候对话（共467次聊天机器人-用户交互）提取先验知识，并在10-15次对话交流中实时适应个体参与者的个性化需求。AURA在受控评估中展示了在回应质量上的平均提高0.076，显著优于非自适应基线（p=0.044，d=0.66），驱动力包括减少63%的具体性提示和增加10倍的验证行为。", "conclusion": "这些结果表明，强化学习可以使调查聊天机器人更具适应性，将静态问卷转换为互动式、自我改进的评估系统。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04703", "html_url": "https://arxiv.org/abs/2511.04703", "title": "衡量本质：大型语言模型基准的构念效度", "title_en": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks", "authors": "Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H.S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi", "background": "评估大型语言模型（LLMs）对于评估其能力以及在部署前识别安全或稳健性问题至关重要。测量抽象和复杂的‘安全’和‘稳健性’现象需要强大的构念效度，即测量能够准确反映现象的关键方面。本文通过29位专家评审员系统回顾了来自自然语言处理和机器学习顶级会议的445项LLM基准，发现了一些验证这些现象结果的有效性不足的问题。", "innovation": "本文通过系统回顾详细地探讨了大型语言模型基准中存在的问题，并提出了八项关键建议和详细的实际操作指导，以帮助研究人员和实践者开发具有更高构念效度的大型语言模型基准。", "conclusion": "回顾结果表明，现有的大型语言模型基准在测量关键现象时的方法存在一些缺陷，作者提出了一系列改进措施，以提高未来基准评估的质量和可靠性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04696", "html_url": "https://arxiv.org/abs/2511.04696", "title": "EncouRAGe: 本地快速可靠地评估RAG", "title_en": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "authors": "Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann", "background": "介绍了EncouRAGe，一个全面的Python框架，旨在简化基于大型语言模型（LLMs）和嵌入模型的检索增强生成（RAG）系统的设计和评估。该框架包含五个模块化和可扩展的组件：类型声明、RAG工厂、推理、向量存储和指标，以促进灵活的实验和可扩展的开发。该框架强调科学可重复性、多样化的评估指标和本地部署，使研究人员能够高效地评估RAG工作流中的数据集。", "innovation": "EncouRAGe框架提供了一个模块化和可扩展的系统，以支持RAG系统的开发和评估。该框架经由不同类型数据集的广泛评估，提供了详细的实施细节，并特别强调其在本地部署下的快速性和可靠性。研究还发现了RAG系统在某些方面仍低于理想状态，但混合BM25方法在所有测试数据集中表现最佳。", "conclusion": "实验证明，RAG系统在所有测试数据集中仍低于Oracle Context。混合BM25方法在所有四个数据集中都取得了最佳结果。研究进一步探讨了重排序的效果，发现仅带来了轻微的性能改进，但伴随着更高的响应延迟。EncouRAGe框架为研究人员提供了快速、可靠的评估工具，支持灵活的实验和模型开发。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04715", "html_url": "https://arxiv.org/abs/2511.04715", "title": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "title_en": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "authors": "Dmytro Vitel,Anshuman Chhabra", "background": "分析训练样本如何影响大规模语言模型（LLM）的决策对于有效解读模型决策和审查大规模数据集至关重要。目前的方法，如影响函数，通过模型的梯度信息来估计训练样本的影响。然而，由于现代大模型有数十亿个参数，这些影响计算通常仅局限于某些模型层以确保计算可行性。Yeh等人(2022)的研究表明，在计算语言数据影响时，第一层（嵌入层）尤其重要，基于影响分数抵消效应的假设（即抵消效应）。", "innovation": "本文提供了理论和实验证据，证明了抵消效应不可靠，并表明中间注意力层是更好的影响估计器。此外，本文还探讨了如何在不同层之间聚合影响分数，并展示了替代标准平均的排名和投票方法可以显著提高性能。最后，本文提出了无需重新训练模型就可以评估影响分数有效性的新方法，并提出了一种称为噪声检测率（NDR）的新指标，它在预测能力上优于抵消效应。", "conclusion": "本文通过多种语言模型的广泛实验，具体确定第一层和最后一层在LLM影响估计中并非一概而优于对方，与领域的既定知识相反。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04700", "html_url": "https://arxiv.org/abs/2511.04700", "title": "去芜存菁：在检索增强生成中精炼不同观点", "title_en": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation", "authors": "Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li", "background": "检索增强生成（RAG）通过集成外部知识源来增强大型语言模型（LLMs），以克服它们在访问最新或专业信息方面的局限性。自然地，增加检索相关信息的可能性的一种策略是扩大检索文档的数量。然而，涉及更多文档可能会引入大量噪音，因为许多文档可能是无关的或误导性的，从而降低生成响应的整体准确性。为了克服处理更多文档所面临的一个挑战，我们提出了WinnowRAG，这是一种新颖的RAG框架，旨在系统地过滤掉噪音文档并保留有价值的内容——我们将其称为'去芜存菁'的过程。WinnowRAG 在两个阶段运行：在第一阶段，我们进行查询感知聚类，将相似的文档分组并形成不同的主题集群。每个集群分配给一个LLM代理生成独特的答案。在第二阶段，我们进行去芜存菁，其中审查LLM评估多个代理的输出并迭代地分离有用文档和噪音文档。为了保留有用的文档同时丢弃代理，我们提出了两种战略合并技术以确保仅使用相关的知识生成最终答案。", "innovation": "我们提出了WinnowRAG，这是一种新颖的RAG框架，利用查询感知聚类进行文档分组和主题集群形成，并在第二阶段通过智能审查和收益率细化策略来去除不重要的文档，从而有效提高生成的准确性，同时保持模型的通用性，不需要微调。", "conclusion": "通过在多种实际数据集上进行广泛的实验，我们证明了WinnowRAG在处理不同观点时超过最先进的基线方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04705", "html_url": "https://arxiv.org/abs/2511.04705", "title": "POLIS-Bench：面向政府双语政策场景中LLM多维度评估", "title_en": "POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios", "authors": "Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu", "background": "现有基准测试未能充分评估大型语言模型（LLM）在政府双语政策场景中的表现。POLIS-Bench旨在填补这一空白，提供一个严谨且系统的评估框架，以确保评估的相关性和准确性，从而更好地满足当前治理实践的需求。", "innovation": "POLIS-Bench创新之处在于：(1) 更新的双语语料库：构建了一个广泛的、最新的政策语料库，显著增加了有效评估样本的大小，确保测试与当前治理实践的相关性。(2) 具体场景任务设计：设计了三个专业的、基于具体场景的任务——条款检索与解释、解决方案生成和合规判断，以全面调查模型的理解和应用能力。(3) 双指标评估框架：引入了一种新的双指标评估框架，结合语义相似性和准确率来精确测量内容对齐和任务要求的遵守情况。", "conclusion": "大规模评估结果显示，推理模型在多项任务上的稳定性和平率更好，尤其是在合规任务方面面临的挑战更大。通过使用POLIS-Bench，我们成功地微调了一个轻量级开源模型，产生的POLIS系列模型在多个政策子任务上的表现与强大的专有基线相当或更好，但成本显著降低，为政府高效、合规、实惠的部署提供了可能。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04710", "html_url": "https://arxiv.org/abs/2511.04710", "title": "GEMMA-SQL：基于大语言模型的新型文本到SQL模型", "title_en": "GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models", "authors": "Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong", "background": "文本到SQL系统允许用户使用自然语言与结构化数据库进行交互，无需专门的编程知识。现有的大语言模型通常需要大量的计算资源和迭代调整才能达到较高的性能，这限制了其在低预算硬件上的部署。现有的几种文本到SQL系统如IRNet、RYANSQL和CodeXDavinci的性能有待提升，尤其是在准确性和适应性方面.", "innovation": "GEMMA-SQL是一种基于开源Gemma 2B架构的轻量级且高效的文本到SQL模型，它通过资源节约型、迭代式的微调方式构建，并能在低成本硬件上部署。GEMMA-SQL利用SPIDER基准进行训练和评估，结合了少量示例学习等多种提示策略，显著提高了SQL查询生成的准确性。GEMMA-SQL Instruct变体在测试套件准确性测试中达到66.8%的成绩，在精确集匹配准确性测试中达到63.3%，超过了包括IRNet、RYANSQL和CodeXDavinci在内的几种最先进的基线模型。这些结果表明，有效的提示设计和目标指令调优能显著提升系统性能，同时保持高效和可扩展性.", "conclusion": "GEMMA-SQL作为一种实践性的开源替代方案，被认为是实现稳健且易于使用的文本到SQL系统的可行选择。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04699", "html_url": "https://arxiv.org/abs/2511.04699", "title": "跨语境SynthDocs：用于任意到阿拉伯OCR和文档理解的大规模合成语料库", "title_en": "Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding", "authors": "Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno", "background": "该paper旨在解决光学字符识别（OCR）和文档理解（DU）中阿拉伯语资源稀缺的问题。当前针对阿拉伯语的资源较为匮乏，限制了相关研究的发展。", "innovation": "paper提出了Cross-Lingual SynthDocs，这是一个大规模合成语料库，包含超过250万样本，包括150万文本数据、27万完全标注的表格以及数百万基于真实的图表。该语料库利用真实的扫描背景、双语布局和带上重音符号的字体，捕获阿拉伯文档的复杂特点。此外，该语料库还包括了不同图表和表格的渲染样式。通过在SynthDocs上微调Qwen-2.5-VL，研究者在多个公开阿拉伯语基准上的词错误率（WER）和字符错误率（CER）均有所提升，其他模态如Tree-Edit Distance Similarity（TEDS）和Chart Extraction Score（Chartex）也有所改善。", "conclusion": "SynthDocs提供了多语言文档分析研究的可扩展、视觉现实的资源，有助于推动用于任意向阿拉伯语的OCR和文档理解的研究进展。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04754", "html_url": "https://arxiv.org/abs/2511.04754", "title": "熵意外揭示图像标题中的多样性差距，并且不同评分器改变故事", "title_en": "Surprisal reveals diversity gaps in image captioning and different scorers change the story", "authors": "Nikolai Ilinykh,Simon Dobnik", "background": "研究通过对图像描述中的语言多样性进行度量，使用了基于token级负对数概率的熵变化来量化多样性。实验在MSCOCO数据集上比较了五个最先进的视觉-语言预训练模型和人类描述的多样性。结果表明，与模型相比，人类生成的描述表现出更高的熵多样性，但使用通用语言模型重新评分则逆转了这一模式。这一研究指出了单一评分器可能导致完全相反的结论，因此多样性的评价需要在多种评分器下进行稳定的度量结果报告。", "innovation": "本文采用熵基度量方法来评估图像描述的多样性，引入了熵作为图像描述多样性的新度量指标，并且指出单一评分器可能导致完全相反的结论，需要进行稳健的多样性评价报告。", "conclusion": "研究展示了单一评分器可能导致完全相反的结论，因此多样性的评价需要在多种评分器下进行稳定的度量结果报告，并引入了熵作为图像描述多样性的新度量指标。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04800", "html_url": "https://arxiv.org/abs/2511.04800", "title": "在推理语言模型的强化学习中探索遗留数据", "title_en": "Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models", "authors": "Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 已成为提高大型语言模型 (LLMs) 推理能力的有效方法。Group Relative Policy Optimization (GRPO) 家族在使用 RLVR 训练 LLMs 方面显示出强大的性能。然而，随着模型的训练时间延长和规模扩大，越来越多的训练提示变成残留提示，这些提示具有零方差奖励，无法提供训练信号。因此，越来越少的提示对训练有贡献，减少了多样性和削弱了效果。", "innovation": "我们提出了 Explore Residual Prompts in Policy Optimization (ERPO) 框架，该框架鼓励在残留提示上进行探索，并重新激活它们的训练信号。ERPO 为每个提示维护一个历史跟踪器，并适应性地增加之前产生所有正确响应的残留提示的采样温度。这鼓励模型生成更多样化的推理痕迹，引入错误响应以恢复训练信号。", "conclusion": "在 Qwen2.5 系列上的实验结果表明，ERPO 在多个数学推理基准测试中始终超过强大的基线。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04869", "html_url": "https://arxiv.org/abs/2511.04869", "title": "训练在标记上，校准在概念上：LLMs 中语义校准的涌现", "title_en": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs", "authors": "Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson", "background": "现有的大型语言模型（LLMs）在为其输出提供有意义的信心评估方面往往存在不足。虽然基础LLMs在下个标记预测上已经表现出一定的校准性，但它们是否能在超越标记层面的意义上评估自身响应的信心仍然是一个未解之谜。该项研究发现，当使用某种基于采样的语义校准概念时，基础LLMs实际上能够很好地校准：即使没有被明确训练以进行这一任务，它们也能有意义地评估开放型领域问题回答任务中的信心。", "innovation": "论文的主要理论贡献在于揭示了一种机制，解释了为何语义校准会作为下个标记预测的副产品自然涌现。该机制基于最近关于校准与局部损失最优之间关系的连接，并提出了一个通用的", "conclusion": "我们的工作首次提供了LLMs中语义校准何时和为何自然涌现的理论解释。通过实验证明了三个预测：（1）基础LLMs在问题回答任务中语义校准良好，（2）通过强化学习（RL）指导调优系统性地破坏了这种校准，（3）带有步骤推理的生成削弱了这种校准。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04720", "html_url": "https://arxiv.org/abs/2511.04720", "title": "通过检索增强代理学习推理罕见疾病", "title_en": "Learning to reason about rare diseases through retrieval-augmented agents", "authors": "Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea", "background": "罕见疾病在医学影像中占有一席之地，但由于训练数据代表性不足，AI模型常常会失效。在临床工作流程中，放射学家在面对不熟悉的表现时，往往会查阅病例报告和文献。因此，提出了一种名为RADAR（ Retrieval Augmented Diagnostic Reasoning Agents）的系统，用于在大脑MRI中检测罕见疾病，该系统利用AI代理并结合外部医学知识进行推理，通过Sentence Transformers嵌入病例报告和文献，并使用FAISS进行高效相似度搜索，以辅助未见疾病的诊断决策。设计为模型不可知的推理模块，RADAR可以无缝集成到多种大型语言模型中，提高其对罕见病理的识别能力和解释性。该系统在包含280种不同罕见疾病的NOVA数据集上实现了高达10.2%的性能提升，特别是开源模型如DeepSeek在该方面表现尤为突出。同时，检索出的实例提供可解释的、文献支持的解释，揭示了检索增强推理对于医学影像中低频条件下诊断的强大作用。", "innovation": "提出了一种名为RADAR的系统，它利用AI代理结合外部医学知识进行推理。该系统通过Sentence Transformers嵌入病例报告和文献，并使用FAISS进行高效相似度搜索，帮助放射学家在面对不熟悉的表现时进行诊断决策。RADAR设计为模型不可知的推理模块，可以无缝集成到多种大型语言模型中，提高它们对罕见病理的识别能力和解释性。该系统在NOVA数据集上实现了显著的性能提升，特别是在开源模型方面。", "conclusion": "RADAR通过检索增强推理提升了罕见疾病的诊断决策能力，尤其是对开源模型提供了显著的改进。同时，检索出的实例提供了可解释的、基于文献的解释，证明了检索增强推理在医学影像中低频条件下诊断的强大作用。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04875", "html_url": "https://arxiv.org/abs/2511.04875", "title": "LLMs 行为自意识的最小和机制条件", "title_en": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs", "authors": "Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask", "background": "近年来的研究表明，大型语言模型（LLMs）可以表现出行为自意识：不需要显式监督就能准确描述或预测自己学习到的行为的能力。这种能力引发了安全方面的担忧，因为模型可能在评估期间更好地隐藏其实际能力。", "innovation": "通过受控的 fine-tuning 实验，使用低秩适配器（LoRA）对指令调优的 LLM 进行实验，研究发现：(1) 使用单一 rank-1 LoRA 适配器就可以可靠地诱导行为自意识；(2) 学习到的行为自意识可以大部分由激活空间中单个引导向量捕获，能够几乎恢复所有 fine-tune 行为效果；(3) 行为自意识是局部的且任务相关的，具有独立的任务表示。", "conclusion": "这些发现表明，行为自意识作为一种领域特定的线性特征在 LLM 中容易被诱导和调节，并且是局部化的。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04926", "html_url": "https://arxiv.org/abs/2511.04926", "title": "诊断和缓解维基数据分类层次结构中的语义不一致", "title_en": "Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy", "authors": "Shixiong Zhao,Hideaki Takeda", "background": "Wikidata是互联网上最大的开放知识图谱，包含超过12000万个实体。它整合了来自各种领域数据库的数据，并从维基百科中导入大量内容，允许用户自由编辑内容。这种开放性使维基数据成为知识图谱研究中的关键资源，并方便全球用户获取知识。然而，相对宽松的编辑政策也导致了分类不一致的问题。", "innovation": "本研究基于现有工作，提出并应用了一种新的验证方法，用于确认维基数据特定领域中分类错误、概括过广的子类链接以及冗余联系的存在。进一步引入了新的评估标准来判断这些问题是否需要修正，并开发了一个系统，让用户可以检查任意维基数据实体之间的分类关系，充分利用该平台的众包特性。", "conclusion": "本研究通过提出和应用新的验证方法来诊断和缓解维基数据分类层次结构中的语义不一致问题，为用户提供了一个能够全面检查分类关系的系统，使得维基数据更加准确和可靠。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04910", "html_url": "https://arxiv.org/abs/2511.04910", "title": "SDS KoPub VDR: 用于韩语公共文档视觉文档检索的标准数据集", "title_en": "SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents", "authors": "Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee", "background": "现有针对视觉文档检索（VDR）的基准大多忽略了非英语语言和官方出版物的结构性复杂性。本文针对这个重要的差距，介绍了SDS KoPub VDR，这是首个公开的大规模基准，旨在检索和理解韩国公共文档。SDS KoPub VDR建立在361份真实世界文档（40,781页）的基础上，包含了256份根据KOGL Type 1许可证的文件和105份来自官方法律门户网站的文件，这些文档包含复杂的视觉元素，如表格、图表和多栏布局。", "innovation": "SDS KoPub VDR是首个针对韩国公共文档的大规模公开基准，涵盖了复杂的视觉元素和多种查询类型，建立了挑战性的查询-页面-答案三元组，并进行了严格的验证。此外，该基准通过两项互补任务评估模型的性能，揭示了在多模态场景中需要跨模态推理时的性能差距。", "conclusion": "SDS KoPub VDR不仅提供了文本和多模态检索任务的严格和细致评估，还为复杂真实世界的文档智能中的多模态AI研究提供了一个清晰的路线图。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04952", "html_url": "https://arxiv.org/abs/2511.04952", "title": "LoPT：大型语言模型长上下文推断无损并行分词加速", "title_en": "LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model", "authors": "Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan", "background": "长文本语境的推断场景对于大型语言模型变得日益重要，但这也导致了显著的计算延迟。尽管前人的研究已经通过操作符、模型架构和系统框架优化了长序列推断，但分词仍然是一个被忽视的瓶颈。现有的并行分词方法通过文本分段和多进程分词提高了处理速度，但因合并后的边界伪影而导致结果不一致。", "innovation": "我们提出了一种新颖的无损并行分词框架LoPT，通过基于字符位置的匹配和动态块长度调整确保分词结果与传统顺序分词一致。该方法在多个多样化长文本数据集上的广泛实验表明，LoPT能在不损失精度的情况下实现显著的速度提升。同时还提供了方法一致性的理论证明和全面的分析研究，以验证该方法的鲁棒性。", "conclusion": "我们提出的LoPT框架实现了长文本分词的无损加速，并通过实验验证了其有效性和鲁棒性。该方法通过准确对齐和合并分词片段，解决了现有并行分词方法中的边界伪影问题。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04921", "html_url": "https://arxiv.org/abs/2511.04921", "title": "AgentExpt：基于LLM资源检索代理自动化的AI实验设计", "title_en": "AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent", "authors": "Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li", "background": "大型语言模型代理在网页相关任务，如信息检索和复杂推理方面的能力正在增强。这些新兴的能力促进了开发促进科研的LLM代理的研究兴趣。在AI研究中，自动化实验设计是关键应用之一，通过代理数据集和基线检索来实现。然而，之前的尝试存在数据覆盖有限的问题，推荐数据集主要来自公共门户网站，忽略了实际用于发表论文中的许多数据集，并且过于依赖内容相似性导致模型偏向表面相似性而忽视了实验适用性。", "innovation": "文章提出了一个全面的基线和数据集推荐框架，利用集体感知来增强检索。首先设计了一个自动数据收集管道，将大约10万篇已接受论文与其实际使用的基线和数据集链接起来。其次提出了一种增强集体感知的检索器，通过组合自我描述和聚合的引用上下文来表示每个数据集或基线在学术网络中的位置。为了提高候选召回效率，对这些表示进行了微调。最后一部分开发了一个增强推理的重排序器，构造明确的推理链并通过微调大规模语言模型来生成可解释的解释和细化排序。我们的数据集覆盖了过去五年顶级AI会议中使用的85%的数据集和基线。在我们的数据集中，提议的方法在平均召回率@20和击中率@5方面优于最强的先前基线，分别提高了5.85%和8.30%。", "conclusion": "我们的结果推进了实验设计的可靠和可解释的自动化。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04989", "html_url": "https://arxiv.org/abs/2511.04989", "title": "使用大型语言模型获取常见中文情感事件", "title_en": "Acquiring Common Chinese Emotional Events Using Large Language Model", "authors": "Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang", "background": "情感事件是一种重要的知识类型，已被应用于提高不同应用的有效性。然而，情感事件难以获得，尤其是那些与特定上下文无关的普通或泛化情感事件。本文的目标是获得中文中的常见情感事件，如“中奖”和“批评”。", "innovation": "本文提出了一种方法，首先收集广泛的情感事件指示词，然后通过提示中文语言模型生成情感事件。为了确保生成的情感事件的质量，训练了一个过滤器以排除无效的生成结果。此外，通过不同的技术将这些情感事件分类为积极事件和消极事件。最后，收集了102,218个高质量的情感事件，具有情感极性标签，这唯一地形成了大型通用中文情感事件的知识库。", "conclusion": "内在评估结果表明，本文提出的方法可以有效获取中文中的常见情感事件。外部使用案例还展示了常见情感事件在情感成因提取（ECE）领域的强大潜力。相关资源，包括情感事件指示词和情感事件，将在发表论文后发布。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05018", "html_url": "https://arxiv.org/abs/2511.05018", "title": "多元行为套件：多轮次定制行为政策压力测试", "title_en": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies", "authors": "Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien", "background": "大型语言模型（LLMs）通常旨在适应广泛的社会接受度原则，但在实际应用中常需符合特定组织生态中的规章制度、使用案例、品牌准则及伦理承诺。现有模型对多样化的行为规范在多轮次互动中的适应性评价不足，揭示出现有方法在这方面的局限性。", "innovation": "提出了一种名为PLURALISTIC BEHAVIOR SUITE (PBSUITE）的动态评估套装，用于系统性评估LLMs在多轮互动中遵循多样行为规范的能力。PBSUITE包括多样化的300个行业基线的行为策略数据集以及一套动态压力测试框架，以测试模型在对抗性条件下对自定义行为规范的符合性。", "conclusion": "研究发现，主流开源及闭源LLMs在单轮次互动中表现良好，但在多轮次对抗性互动中合规率大幅下降。现有模型的统一行为规范与安全措施难以有效应对现实中的多样化规范，文章贡献了数据集及分析框架以支持未来针对稳健且情境感知的多样化行为规范技术研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05085", "html_url": "https://arxiv.org/abs/2511.05085", "title": "逐层迭代蒸馏方法对大型语言模型高效压缩", "title_en": "Iterative Layer-wise Distillation for Efficient Compression of Large Language Models", "authors": "Grigory Kovalev,Mikhail Tikhomirov", "background": "本文探讨了对大型语言模型（LLMs）进行蒸馏的方法，旨在开发保持高性能的小型模型。研究回顾了几种现有方法，并讨论了它们各自的优缺点。", "innovation": "基于ShortGPT的方法改进了蒸馏过程，引入了逐层重要性迭代评估的概念。在每个步骤中，通过测量在不同数据集上移除单个层时性能的下降来评估重要性。并结合联合损失函数进一步训练，该函数基于KL散度和均方误差。研究表明，这种改进方法可以有效减少模型层的数量，同时仅损失少量性能，从而创建高效的小型模型。", "conclusion": "实验结果表明，通过逐层迭代蒸馏和精细调整，可以在资源受限的环境中部署有效的模型，证明了这种方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05064", "html_url": "https://arxiv.org/abs/2511.05064", "title": "语言模型之间按层次注意力相似性的潜在共同点", "title_en": "Order-Level Attention Similarity Across Language Models: A Latent Commonality", "authors": "Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu", "background": "尽管有一些研究调查了语言模型(LMs)中的上下文聚合或注意力权重，但它们通常仅关注单一模型或注意头，缺乏对多个模型间的系统性分析来探索它们的共同点。", "innovation": "引入了按层次注意力(OLA)这一概念，揭示了不同语言模型在相同层次上的OLA表现出显著的相似性，并发现OLA与句法知识之间存在隐含映射关系。基于此，提出了无需训练的跨模型适配器 Transferable OLA Adapter(TOA)，该方法将OLA视为统一的句法特征表示，训练一个接受OLA作为输入的适配器，由于OLA在不同模型间具有相似性，该适配器无需更新参数即可泛化到未见过的模型。", "conclusion": "广泛的实验表明，TOA的跨模型泛化有效提升了未见过的语言模型的性能。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05040", "html_url": "https://arxiv.org/abs/2511.05040", "title": "UA-Code-Bench: 用于评估乌克兰语代码生成的大规模语言模型编程基准", "title_en": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian", "authors": "Mykyta Syromiatnikov,Victoria Ruvinskaya", "background": "在低资源语言中评估大规模语言模型的实际能力仍然面临挑战，因为现有的许多基准主要集中在从英语翻译而来或仅评估基本语言理解能力的广泛应用任务上。这篇论文介绍了一个新的开源基准UA-Code-Bench，该基准针对乌克兰语的语言模型的代码生成能力和解决编程比赛问题的能力进行了全面评估。该基准涵盖了来自Eolymp平台的500个问题，按难易程度分为五个级别。研究团队评估了一组13个领先的整体和开源模型，这些模型基于单次提示生成Python解决方案，并通过专用的Eolymp环境进行评估，以确保代码正确性，且使用隐藏测试.", "innovation": "该研究引入了一个新的基准UA-Code-Bench，专门针对乌克兰语，评估语言模型的代码生成和解题能力。这其中包括了一个广泛的具有代表性的难题级别分布的问题集，并使用特定环境进行评估，确保了结果的准确性和可靠性。此外，该研究还分析了不同难度级别的性能，并评估了解决方案的独特性和计算效率，使用了生成解决方案的耗时和内存消耗作为衡量标准。这一评估方法突显了在低资源语言中的代码生成挑战，特别是大规模语言模型的表现。这为未来关于多语言代码生成和增强推理能力模型的研究开辟了新的途径.", "conclusion": "该研究证明了使用编程比赛基准来评估大规模语言模型的价值，特别是在欠代表性语言中的应用。这为未来关于多语言代码生成和增强推理能力模型的研究铺平了道路。感兴趣的用户可以在该网址获取基准数据、解析、准备代码生成和评估脚本: [this https URL]."}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05120", "html_url": "https://arxiv.org/abs/2511.05120", "title": "一个改进演化搜索工具箱", "title_en": "A Toolbox for Improving Evolutionary Prompt Search", "authors": "Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu", "background": "进化提示优化已证明在精炼语言模型（LLM）的提示方面具有有效性。然而，现有方法缺乏稳健的操作符和高效的评估机制。", "innovation": "本文提出了一种改进的进化提示优化方法，包括：1) 将进化分解为明确的步骤，以增强进化及其控制；2) 引入基于语言模型的裁判来验证进化；3) 结合人类反馈以改进进化操作符；4) 开发了更高效的评估策略，同时保持性能并降低计算开销。该方法提高了优化质量和效率。", "conclusion": "本方法能同时提升优化质量和效率。我们还发布了代码，以支持新任务的提示优化，并促进该领域的进一步研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05078", "html_url": "https://arxiv.org/abs/2511.05078", "title": "多语言嘈杂社交媒体帖子的推理引导规范", "title_en": "Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts", "authors": "Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga", "background": "研究旨在解决多语言网络谣言检测中的声明规范化问题，即将嘈杂的社交媒体帖子转化为清晰可验证的多语句，覆盖20种语言。传统的网络谣言检测方法依赖于单一语言数据训练，并且在处理多语言数据时经常难以保持一致性。该研究通过利用系统地对帖子进行分解，使用谁、什么、哪里、何时、为什么和如何等问题，即使仅使用英语数据进行训练，也能实现稳健的跨语言迁移。研究方法还包括对后端数据进行去重、按token级别筛选以实现语义对齐，以及在推理过程中使用基于上下文的例子增强检索学习。研究结果显示，该系统在METEOR评分方面表现出色，尤其是对于罗曼语族和日耳曼语族的语言，同时也展示了对不同语言结构的语义一致性的维持。", "innovation": "本文通过系统地对帖子进行分解，利用“六何”问题（谁、什么、哪里、何时、为什么和如何）将其转化为清晰的声明。这种方法即使使用英语数据进行训练，也能实现多语言之间的有效迁移。研究还引入了细粒度的清洗步骤（如去重和基于token的语义对齐），并使用检索增强的少样本学习。", "conclusion": "通过这种方法，系统在METEOR分数上取得了显著的效果，尤其是对于罗曼语族和日耳曼语族的语言。指标结果显示该方法相对于基线配置有41.3%的改进，并且在与其他现有方法相比时也获得了实质性改善。实验结果还表明这种方法在不同语言结构中具有良好的通用性和语义一致性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05080", "html_url": "https://arxiv.org/abs/2511.05080", "title": "关于文本简化指标和用于可访问健康信息的一般目的LLM，以及指令调整的LLM类别的潜在架构优势", "title_en": "On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class", "authors": "P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin", "background": "公众对于医疗健康信息的寻求行为和数字消费日益增加，这促使需要可扩展的解决方案来自动将复杂的技术和科学文档简化为通俗的语言。尽管先进的大型语言模型已经在文本简化方面取得了进展，但它们在优化可读性和保持话语准确性之间的平衡上仍然面临挑战。因此，该论文评估了两个主要的一般性大型语言模型的表现，以确定它们在执行文本简化任务时的语言能力和基础准备度，并与人类基准进行比较。研究进一步通过详细相关性分析建立了广泛指标之间的联系，为后续研究提供了基础性能数据和见解。", "innovation": "通过比较指令调整的Mistral 24B和增强推理的QWen2.5 32B，研究团队识别出指令调整的LLM可能具有潜在的架构优势。Mistral展示了适度的词汇简化策略，提高了多项指标的可读性并获得SARI（平均42.46）的分数线，同时保持与人类相似的话语准确性。QWen虽然提高了可读性，但在平衡可读性和准确性方面表现出差距，BertScore得分为0.89。此外，综合相关性分析显示五个可读性指数功能冗余强，这为选择合适的指标和简化领域的语用支持指明了方向。", "conclusion": "该研究记录了正在演化的大型语言模型在文本简化任务中的基础性能，确认指令调整的Mistral 24B更适合简化任务，为选择合适度量标准提供了必要的启发，并指出词汇支持是简化任务的主要领域适应问题。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04919", "html_url": "https://arxiv.org/abs/2511.04919", "title": "BudgetMem：学习选择性记忆策略以实现高效低成本长上下文处理的语言模型", "title_en": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models", "authors": "Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi", "background": "大语言模型（LLMs）在处理长文本时面临严重的计算和内存限制，尽管对涉及大量文档、多轮对话和书长度文本应用的需求在增加。尽管最近的进步将上下文窗口扩展到100K-1M个标记，但在资源受限的部署中这种做法会产生无法承受的成本。现有的增加上下文窗口至百万甚至千万标记的机制严重影响了效率。", "innovation": "提出了一种新的记忆增强架构——BudgetMem，能够学习存储重要的信息而不需要记住所有内容。该系统结合了选择性记忆策略和基于特征的显著性评分（实体密度、TF-IDF、话语标记、位置偏见）来决定哪些信息在严格预算约束下值得存储。不同于现有的检索增强生成系统（RAG）储存所有片段，BudgetMem 使用学习门控机制结合 BM25 稀疏检索来高效访问信息。实验结果表明，在使用 Llama-3.2-3B-Instruct 对700对问题回答进行测试时，与基线 RAG 相比，BudgetMem 在长文档上实现了显著的内存节约并保持了出色的结果，只减少了1.0%的F1得分。", "conclusion": "我们的工作提供了一种实用的途径，使得复杂的长上下文系统能够在低硬件要求的情况下部署，从而让更多人可以使用先进的语言理解能力。此外，通过预算敏感性分析、简单的基线比较和文档长度分析，表明 BudgetMem 的效果随着文档长度的增加而变得更加明显。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05135", "html_url": "https://arxiv.org/abs/2511.05135", "title": "ManufactuBERT: 效率导向的持续预训练方法专用于制造业", "title_en": "ManufactuBERT: Efficient Continual Pretraining for Manufacturing", "authors": "Robin Armingaud,Romaric Besançon", "background": "虽然通用的大规模Transformer编码器在一般的语言理解任务上表现优异，但在像制造业这样的专业领域中，由于缺乏针对领域特定术语和语义的训练，其性能会下降。因此，该论文通过构建一个专门针对制造业大规模语料库，并使用RoBERTa模型进行了持续预训练，以解决这一问题，提高在制造业相关的自然语言处理任务上的性能。", "innovation": "引入了ManufactuBERT，一种在专用于制造业的大规模语料库上持续预训练的RoBERTa模型。开发了一个全面的数据处理流水线来创建此语料库，包括初始领域特定筛选步骤，随后进行多阶段去重处理以去除冗余。特别指出，使用去重后的语料库进行训练显著加快了收敛速度，相比非去重数据集减少了33%的训练时间和计算成本。这一流程为其他特定领域开发高性能编码器提供了可再现的示例。", "conclusion": "实验表明，ManufactuBERT在一系列与制造业相关的自然语言处理任务上建立了新的性能基准，超过了强大的专用基线。更重要的是，使用精心去重的语料库训练模型，在训练时间和计算成本上表现出了更加优秀的性能。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05162", "html_url": "https://arxiv.org/abs/2511.05162", "title": "关注差距……或不？翻译错误和评估细节如何扭曲多语言结果", "title_en": "Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results", "authors": "Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag", "background": "当前大多数大型语言模型（LLMs）支持多种语言，除了英语，还包括高资源语言（例如德语、中文、法语）和低资源语言（例如斯瓦希里语、泰卢固语）。此外，这些模型在不同领域显示出了出色的性能，包括编程、科学和数学。本文侧重于数学领域，研究不同语言之间的LLM性能差异。实验结果显示，模型在不同语言上的性能存在显著且一致的差距，而且这一差距在高资源语言和低资源语言中都存在。", "innovation": "通过分析一个标准的多语言数学基准（MGSM），发现数据中存在多个翻译错误。此外，LLM输出的标准化答案提取不足进一步影响了最终结果。提出了自动质量保证方法以解决第一问题，针对第二个问题给出了建议。结合这两种方法，表明上述语言差距主要消失，使得研究结论发生改变。同时发布了修正后的数据集供社区使用。", "conclusion": "研究表明，翻译错误和评估细节影响了多语言结果的准确性，通过改进数据质量和评估方法可以大大缩小不同语言之间的模型性能差距。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05239", "html_url": "https://arxiv.org/abs/2511.05239", "title": "通过注释进行翻译：将古典中文翻译成日语的计算研究", "title_en": "Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese", "authors": "Zilong Li,Jie Cao", "background": "古代人们通过在每个汉字周围进行注释来将古典中文翻译成日语。这段翻译过程被抽象为序列标记任务，并适用于现代语言技术。该研究旨在解决低资源问题，通过引入基于LLM的注释流水线和从数字化开源翻译数据构建新数据集来解决。", "innovation": "提出了一个基于LLM的注释流水线，并从数字化的开源翻译数据中建立了一个新的数据集。研究证明，在低资源情况下，引入辅助的中文NLP任务对序列标记任务的训练有益。还评估了大型语言模型的性能，在直接机器翻译中表现优异，但在要求注释字符时会感到困惑。研究成果为LLMs提供了一个补充方法。", "conclusion": "在低资源条件下，引入辅助中文NLP任务对序列标记任务的训练有促进作用。大型语言模型在直接机器翻译中的表现良好，但在要求注释字符时感到困惑。该方法可以作为大型语言模型的一个补充。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05310", "html_url": "https://arxiv.org/abs/2511.05310", "title": "通过语言模型解读播客叙事：在言外之意中聆听", "title_en": "Listening Between the Lines: Decoding Podcast Narratives with Language Modeling", "authors": "Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty", "background": "播客已经成为影响公众意见的主要平台之一，因此成为理解当代话语的关键来源。播客因其非正式、多主题且对话式的风格，提供了丰富但复杂的数据形式。为了分析播客如何说服和提供信息，必须研究其叙述结构，特别是所使用的叙述框架。播客的流动性和对话性质对自动分析构成了重大挑战。现有的大型语言模型通常训练于更具结构化的文本，如新闻文章，难以捕捉到人类听众依赖的微妙线索，以识别叙述框架。因此，当前方法在大规模分析播客叙述时无法达到准确效果。", "innovation": "本文开发并评估了一种微调后的BERT模型，该模型明确地将叙述框架与对话中提到的具体实体联系起来，从而将抽象框架与具体细节结合。该方法接着利用这些细粒度的框架标签与高层次主题进行关联，揭示更广泛的话语趋势。主要贡献包括：(i) 一种新的框架标签方法，更贴近人类对凌乱、对话数据的判断；(ii) 一种新的分析方法，揭示讨论内容（话题）与如何呈现（框架）之间的系统关系，为研究数字媒体中的影响提供了更稳固的框架。", "conclusion": "本研究通过开发一种新的框架标签方法和分析框架，揭示了播客中话题与框架之间的系统关系，为研究数字媒体中的影响提供了更坚实的基础。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05324", "html_url": "https://arxiv.org/abs/2511.05324", "title": "用 BengaliBPE 评估孟加拉语子词分词技术：BengaliBPE 的基准研究", "title_en": "Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE", "authors": "Firoj Ahmmed Patwary,Abdullah Al Noman", "background": "子词分词是自然语言处理(NLP)管道中的关键第一步，因为它决定了模型如何学习和表示语言信息。当前的子词分词器，如 SentencePiece 或 HuggingFace BPE，主要针对拉丁语或多种语言语料库设计，并不能很好地处理具有丰富形态学特征的语言，如孟加拉语。因此，需要一种专为孟加拉语设计的子词分词器。", "innovation": "本研究提出了一种名为 BengaliBPE 的基于字节对编码(BPE)的子词分词器，专门针对孟加拉语设计。BengaliBPE 采用了 Unicode 归一化、基于音符级的初始化以及形态学感知的合并规则，以保持语言一致性和保持子词完整性。与三种基线方法（空白符分词、SentencePiece BPE 和 HuggingFace BPE）进行了对比评估。", "conclusion": "所有方法在性能上表现良好，但 BengaliBPE 提供了最详细的分词和最佳的形态学可解释性，尽管计算成本稍高。这些发现突显了具有丰富形态学特征的语言需要语言感知型分词技术的重要性，并确立了 BengaliBPE 作为未来孟加拉语 NLP 系统坚实基础的地位，包括大规模预训练的上下文语言模型。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05286", "html_url": "https://arxiv.org/abs/2511.05286", "title": "反思个性化优化：一种后处理重写框架以用于黑盒大型语言模型", "title_en": "Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models", "authors": "Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu", "background": "黑盒大型语言模型（LLMs）的个性化是一个关键但具有挑战性的任务。现有方法主要依赖于上下文注入，即在提示中嵌入用户历史以直接指导生成过程。然而，这一单步范式给模型带来了双重负担：既要生成准确的内容，又要与用户特定的风格保持一致。这常常导致输出质量和精确控制之间的权衡。因此，需要一种新的方法来解决这一根本性矛盾。", "innovation": "我们提出了反思个性化优化（RPO），这是一种新颖的框架，重新定义了个性化范式，通过解耦内容生成与对齐。RPO分为两个阶段：首先，基础模型生成高质量的通用响应；然后，外部反思模块显式地重写此输出，以与用户偏好对齐。反思模块通过两级训练过程进行训练，首先采用监督微调来确定核心个性化推理策略，然后通过强化学习进一步完善个性化输出的品质。", "conclusion": "在LaMP基准上的全面实验表明，通过解耦内容生成与个性化，RPO显著优于最先进的基线。这些结果突出了显式响应塑造优于隐式上下文注入的优越性。此外，RPO引入了一个高效、模型无关的个性化层，可以无缝结合到任何基础模型中，为用户为中心的生成场景开辟了一条新的有效途径。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05406", "html_url": "https://arxiv.org/abs/2511.05406", "title": "大型语言模型在可解释威胁情报中的应用", "title_en": "Large Language Models for Explainable Threat Intelligence", "authors": "Tiago Dinis,Miguel Correia,Roger Tavares", "background": "随着网络威胁日益复杂，传统的安全机制难以应对。大型语言模型（LLMs）因其在文本处理和生成方面的高级能力，在网络信息安全领域展现出巨大潜力。本文探讨了使用带有检索增强生成（RAG）的LLM以实时信息检索与领域特定数据相结合的方式获取威胁情报的方法。", "innovation": "本文提出了一种名为RAGRecon的系统，该系统利用带有RAG的LLM回答关于网络安全威胁的问题。同时，通过生成并可视化展示知识图谱，使AI更具解释性，增加了模型的透明度和可解释性，使分析师能够更好地理解系统基于RAG系统恢复的上下文所做出的推理连接。", "conclusion": "通过实验评估，RAGRecon系统使用两个数据集和七种不同的LLM，在最佳组合下，响应与参考响应的匹配率超过91%。这证明了RAGRecon在网络安全领域的有效性和实用性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05361", "html_url": "https://arxiv.org/abs/2511.05361", "title": "多模态多层网络模型的认知词汇库：多语者", "title_en": "A multimodal multiplex of the mental lexicon for multilingual individuals", "authors": "Maria Huynh,Wilder C. Rodrigues", "background": "历史上，双语者被误认为是一种额外的认知负担，可能会阻碍语言和智力的发展。然而，近三十年来，这一观点发生了巨大变化，许多研究表明双语者在多语词汇认知系统的构建和功能上有显著优势，如词汇识别系统的并行激活机制在大脑中的运作方式。这些研究表明，多语使用者在各种语言和认知任务中表现优于单语使用者。本研究进一步探讨了如何在多层网络模型中构建认知词汇库，特别是在包含视觉输入的情况下，研究母语对学习其他语言的影响。", "innovation": "本研究基于Stella等人（2018）和Dijkstra及van Heuven（2002）的工作，使用多层网络原则，特别是将多模态输入引入多层构型模型，增加了词汇表征之间的视觉输入关联层，以研究多语词汇库如何构建以及母语在学习其他语言时的影响。这代表了语言习得研究的新方法，特别是在多语者中的应用。", "conclusion": "通过引入多模态视觉输入的研究设计，本研究旨在探索母语如何影响学习另一语言的过程。具体而言，我们研究在翻译任务中加入视觉输入是否能提高参与者的能力和准确性比只有文本条件的情况。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05407", "html_url": "https://arxiv.org/abs/2511.05407", "title": "通过偏好自适应强化学习在对话系统中实现少数群体意识下的满意度估计", "title_en": "Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning", "authors": "Yahui Fu,Zi Haur Pang,Tatsuya Kawahara", "background": "用户在对话系统中的满意度具有主观性，当相同的响应策略应用于所有用户时，少数用户的满意度可能与多数用户的评价不同，因为个别用户的意图和偏好存在差异。现有的对齐方法通常训练适用于所有用户的模型，旨在达成广泛的共识，但往往会忽视少数群体的观点和用户特定的适应性。", "innovation": "该论文提出了一种统一框架，用于建模用户满意度的个体和群体偏好。首次通过可解释的推理链引入了Individual-个人化推理链（CoPeR），以捕捉个体偏好。随后，提出了一种基于最大似然估计的最大多数偏好感知聚类（M2PC）算法，以发现具有不同用户群组并学习群体偏好。最终，将这些组件集成到一种联合优化个体和群体偏好的偏好自适应强化学习框架（PAda-PPO）中。实验结果显示，该方法在用户满意度估计中表现出一致的改进，尤其对于未充分代表的用户群体。", "conclusion": "本研究通过提出偏好自适应强化学习框架，实现了对话系统用户满意度的个体和群体偏好建模和优化，证明了在评估用户满意度时对少数群体的关注和适应性可以提高整体满意度估计的准确性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05408", "html_url": "https://arxiv.org/abs/2511.05408", "title": "通过权重运算引导语言模型", "title_en": "Steering Language Models with Weight Arithmetic", "authors": "Constanza Fierro,Fabien Roger", "background": "为大规模语言模型（LLMs）提供高质量的反馈是一项挑战且成本高昂的工作，特别是在多样化的训练数据分布上。仅在狭窄的数据分布上下反馈可能会导致意外的一般化。为更有效利用狭窄的训练数据，本文提出了一种简单的后训练方法——对比权重引导，通过权重算术操作调整模型参数。", "innovation": "本文提出了一种名为对比权重引导的方法，它通过从两个诱导相反行为的微调中减去权重变化的方向，来隔离权重空间中的行为方向，并修改模型的权重，用于减轻谄媚行为和诱导不符合习惯等。实验证明，权重引导在保持一般能力的同时，比激活量引导有更强的分布外行为控制。另外，它还展示了在任务特定微调的背景下，权重引导能部分缓解不期望的行为漂移，降低罚款过程中引入的谄媚和拒绝不足，同时保留任务性能的进步。", "conclusion": "实验结果表明，权重引导方法可能会检测到新兴的不对齐，这提示在训练过程中可以监控权重的演变并检测罕见的行为，即使它们从未在训练或评估中出现。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05184", "html_url": "https://arxiv.org/abs/2511.05184", "title": "Chain-of-Thought在从大型语言模型蒸馏推理能力中的有效性", "title_en": "Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models", "authors": "Cong-Thanh Do,Rama Doddipatla,Kate Knill", "background": "Chain-of-Thought (CoT)提示方法被广泛用于提升大型语言模型（LLMs）的推理能力。近期，CoT方法被应用于知识蒸馏（KD），以将大型LLMs的推理能力转移到小型LLMs中。本文研究了CoT在使用知识蒸馏方法从较大LLMs向较小LLMs转移推理能力中的作用，通过白盒KD实验分析了这种方法在各种自然语言推理和理解任务中的有效性。实验使用Qwen和Llama2系列的LLMs，并使用CoT-Collection数据集中的CoT数据，然后在BIG-Bench-Hard（BBH）基准测试中的自然语言推理和理解任务上评估所得到的蒸馏模型。", "innovation": "本文通过白盒KD实验，探讨了CoT方法在从大型LLMs向较小LLMs转移推理能力中的作用。特别是在BBH难以解决的任务上，通过使用CoT数据集进行蒸馏，分析了CoT方法如何提高蒸馏模型在各种自然语言推理和理解任务中的表现。", "conclusion": "实验结果表明，CoT方法在提高白盒KD的有效性方面起到了关键作用，使得蒸馏模型在BBH自然语言推理和理解任务中的平均性能更好。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04691", "html_url": "https://arxiv.org/abs/2511.04691", "title": "从廉价脑信号解码言语：探索将大脑活动转化为语音的神经网络", "title_en": "A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals", "authors": "Quentin Auster,Kateryna Shapovalenko,Chuang Ma,Demaio Sun", "background": "该研究探讨了神经网络是否能够通过将EEG记录映射到音频表示来解码大脑活动为语音。使用受试者听自然语音时记录的EEG数据，训练了一个带有对比CLIP损失的模型，目的是将从EEG数据中提取的嵌入与预先训练的基于Transformer的语音模型的嵌入对齐。该研究基于Meta的最先进EEG解码器进行了改进，引入了三种架构上的改动：（i）特定受试者注意层（+0.15% WER改进），（ii）个性化空间注意（+0.45%），（iii）带有注意机制的双路径RNN（-1.87%）。改进表明，个性化架构对于大脑到语音的解码有希望的应用，并且在大脑-计算机接口中也有潜力。", "innovation": "该研究引入了三个架构改进：（i）特定受试者注意层，（ii）个性化空间注意，（iii）带有注意机制的双路径RNN。这些改进中有两种提高了性能，表明个性化的架构可以提高大脑到语音解码的效果，这对于大脑-计算机接口应用具有重要意义。", "conclusion": "两个改进中的一个改进表明，个性化架构对大脑-语音解码有潜力，这在大脑-计算机接口中有广泛的应用前景。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05485", "html_url": "https://arxiv.org/abs/2511.05485", "title": "MIMIC-SR-ICD11：基于叙述的诊断数据集", "title_en": "MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis", "authors": "Yuexin Wu,Shiqi Wang,Vasile Rus", "background": "现代医疗保健的核心支柱之一是疾病诊断，它有助于早期发现和及时干预急性病症，并指导生活方式调整和药物治疗方案以预防或减缓慢性疾病。自我报告保留了临床重要的信号，而结构化的电子健康记录（EHR）文档往往会减弱或省略这些信号，尤其是那些细微但具有重要意义的细节。为了实现这一转变，我们介绍了MIMIC-SR-ICD11，这是一个从EHR出院记录构建的大规模英语诊断数据集，与WHO ICD-11术语自然对齐。此外，我们还提出了LL-Rank，这是一种基于概率的重新排序框架，它计算每个标签给定临床报告上下文的归一化长度联合概率，并减去该标签相应的无报告先验概率。", "innovation": "我们提出了MIMIC-SR-ICD11数据集，这是一个基于EHR出院记录构建的大规模英语诊断数据集，与WHO ICD-11术语天然对齐。我们还提出了一种名为LL-Rank的基于概率的重新排序框架，该框架计算每个标签在临床报告上下文中归一化长度联合概率，并减去相应标签的无报告先验概率。实验结果显示，LL-Rank在七个模型基座中始终优于强大的生成加映射基准（GenMap）。消融实验表明，LL-Rank的改进主要来自其基于PMI的评分，这使得语义兼容性从标签频率偏差中分离出来。", "conclusion": "研究表明LL-Rank框架在诊断标签提取中表现优异，主要得益于其基于PMI的评分机制，能够有效去除标签频率偏差的影响，从而提高了语义兼容性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04690", "html_url": "https://arxiv.org/abs/2511.04690", "title": "使用AI进行岩体地质报告自动化", "title_en": "Automatización de Informes Geotécnicos para Macizos Rocosos con IA", "authors": "Christofer Valencia,Alexis Llumigusín,Silvia Alvarez,Abrahan Arias,Christian Mejia-Escobar", "background": "岩土报告对于评估岩体稳定性及确保现代工程的安全性至关重要。传统上，这些报告是基于现场观察使用指南针、放大镜和笔记本手工编制的，这种方法效率低、容易出错且解释主观。为了克服这些局限性，通过图像和现场数据处理使用人工智能技术进行报告的自动化生成被提出。该研究收集了岩壁的图片和手持样本及其描述，并使用了地质研究课程中准备的报告，以此来定义报告总结，催化工程语言，并验证多模态大语言模型（MLLM）的回答。通过迭代优化提示，直到为报告的每个部分获得结构化和具体的指令，证明了相对于精细调校MLLM来说，这是一种有效的替代方案。系统评估显示BLEU与ROUGE-L指标分别为0.455和0.653，表明自动描述与专家描述相当。", "innovation": "提出了使用人工智能技术自动生成岩土报告的方法，通过图像和现场数据处理。研究还展示了迭代优化提示的有效性，以获得结构化和具体的指令，替代了精细调校大型语言模型的过程。研究结果表明自动描述与专家描述相当，此工具以Web形式提供，具有直观的界面和能导出到标准化格式，对地质领域的专业人员和学生具有重要意义", "conclusion": "该工具代表了一种创新和重要的贡献，不仅提高了效率，减少了错误，还提供了标准化格式的导出功能，适合专业人员和学生使用。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04962", "html_url": "https://arxiv.org/abs/2511.04962", "title": "太善不能太坏：现代LLM角色扮演反派失败的原因", "title_en": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains", "authors": "Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus", "background": "大型语言模型（LLMs）在创造性生成方面越来越多地承担起模拟虚构人物的职责，包括模拟非正面、具有敌意的角色。然而，现代LLMs在展现道德灰暗或纯粹反派角色方面的能力尚未得到广泛研究。研究者假设，模型的安全性对齐创造了与真实扮演道德灰色或反派角色之间的基本冲突。为了深入研究这一假设，该研究提出了一个新的基准测试——道德角色扮演基准（Moral RolePlay benchmark），该基准测试包括一个四级道德对齐量表和一个丰富的测试集，用于严格评估。研究者让最新的LLMs扮演从道德模范到纯粹反派的角色，发现角色道德下降会导致角色扮演的真实性和一致性递减。模型在扮演具有直接对抗安全原则的角色特质，如“欺骗”和“操纵”时表现最差，常常用表面的攻击性来替代复杂且微妙的恶意。此外，研究还发现，一般的聊天机器人能力并不能很好地预测反派角色扮演的能力，高度对安全对齐的模型在这方面表现尤其差。这项研究提供了第一个系统性的证据，揭示了模型安全性和创造性真实性的关键矛盾。这项基准测试和研究结果为发展更具细微差别的、情境感知对齐方法铺平了道路。", "innovation": "该研究提出了一个新的基准测试——道德角色扮演基准（Moral RolePlay benchmark），用于评估现代LLMs在角色扮演方面的能力，并揭示了在模拟具有敌意或道德灰暗的角色时，LLMs的不足之处。这项研究首次系统地证明了模型安全性和创造性的关键矛盾，并强调了研究这一点的重要性。研究结果为开发更细腻、情境感知的对齐方法提供了新的方向。", "conclusion": "这项研究提供了第一个系统性的证据，揭示了现代LLMs在模拟非正面或敌对角色方面的关键局限性。研究发现，高度对齐的安全模型在扮演直接违反安全原则的角色特质时表现较差，往往用表面的攻击性来代替复杂和微妙的恶意。此外，通用聊天机器人的熟练程度不能很好地预测反派角色扮演的能力。这项研究强调了模型安全性和创造性真实性的关键矛盾，并指出该领域的发展方向。通过提出新的基准测试和发现，研究为未来的研究和开发工作奠定了基础。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04776", "html_url": "https://arxiv.org/abs/2511.04776", "title": "量化生成式人工智能的气候风险：基于G-TRACE和地区感知碳核算的人工智能可持续性金字塔", "title_en": "Quantifying the Climate Risk of Generative AI: Region-Aware Carbon Accounting with G-TRACE and the AI Sustainability Pyramid", "authors": "Zahida Kausar,Seemab Latif,Raja Khurrum Shahzad,Mehwish Fatima", "background": "生成式人工智能（GenAI）作为快速发展的数字基础设施，其能源需求和相关的二氧化碳排放正在成为新的气候风险类别。本文探讨了量化训练和推理过程中的碳排放，并通过微观模拟展示了分布式的推理如何将每次查询的低能耗放大为系统级影响。", "innovation": "提出了G-TRACE（GenAI Transformative Carbon Estimator）框架，这是一种跨模态、地理位置感知的方法，可以量化多模态和部署地理上的训练和推理碳排放。还提出了人工智能可持续性金字塔，这是一种七级治理模型，将碳核算指标与运营准备、优化和管理联系起来，通过具体的案例研究，推导出可持续人工智能部署的实际政策指导。", "conclusion": "本文贡献在于定性评估新兴数字基础设施作为新的气候风险类别，并为可持续技术部署提供适应性治理。将生成式人工智能置于气候风险框架中，有助于通过数据驱动方法实现技术创新与全球低碳和韧性目标的对接。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05320", "html_url": "https://arxiv.org/abs/2511.05320", "title": "从刑事法庭判决文书自动提取事实情况", "title_en": "What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions", "authors": "Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal", "background": "现有司法管理数据中仅包含有限的关于犯罪行为的信息，而大陆欧洲法院的判决书中却包含了大量的犯罪行为描述信息，尚未充分利用。本文研究了从斯洛伐克公开可用的法院判决书中自动提取这些描述的可行性，使用了两种方法：正则表达式和大型语言模型（LLMs）。", "innovation": "研究尝试通过正则表达式和LLMs（如Gemini Flash 2.0）两种不同的方法从欧洲大陆的法院判决书中提取详细的犯罪行为描述信息。正则表达式方法结合了典型词语前后筛选，以及对“sparing”一词的规范化处理。LLMs方法则通过预定义的提示语来引导模型提取信息。与基线方法相比，两种方法显著提升了提取准确率，特别是LLMs方法，提取准确率达到99.5%，并且学生评估结果显示，先进的方法在大多数情况下都能与人工标注匹配，准确率高达90%，而基线方法仅为34.5%。", "conclusion": "研究发现，正则表达式和LLMs在从法院判决书中自动提取犯罪行为描述方面具有很高的可行性。特别是LLMs方法表现出色，不仅在学生评估中表现出高匹配率，结合正则表达式的组合方法也取得了很好的效果。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04901", "html_url": "https://arxiv.org/abs/2511.04901", "title": "通过熵减少建立关联", "title_en": "Association via Entropy Reduction", "authors": "Anthony Gamst,Lawrence Wilson", "background": "在最近基于神经网络的成功之前，词频-逆文档频率(tf-idf)显然是识别与查询相关的文档的最佳选择。本文通过提供一种不同的评分方法（aver）并在具有关联标记的真实数据集上进行观察，发现aver在发现关联对方面优于tf-idf。此外，本文还探讨了关联在大规模图中的查找情况，这可能是神经网络目前不明显优于传统方法的一个领域。", "innovation": "提出了一种新的评分方法aver，它在发现关联对方面优于传统的tf-idf方法。aver方法具有自然的阈值来声明关联性，可以区分tf-idf给定得分为1.0的一对文档，并且可以应用于更大的文档集合，同时其得分基于简单的统计模型的熵。", "conclusion": "虽然aver方法在复杂性上高于tf-idf，而且熵减少的结果具有无尺度性使得解释更复杂，本文发现了几个aver方法的优势，包括自然的阈值、无尺度性、适用于更大文档集合和基于简单的统计模型等。因此，aver可能比传统的tf-idf更‘天然’地反映了关联性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04686", "html_url": "https://arxiv.org/abs/2511.04686", "title": "状态化的键值（KV）缓存管理对于LLMs：平衡空间、时间、准确性和位置一致性", "title_en": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity", "authors": "Pratik Poudel", "background": "在大型语言模型（LLMs）的自回归推理中，键值（KV）缓存是提高效率的关键因素。但在多轮的有状态场景中，KV缓存的状态性增长会带来重大挑战。当累积的KV缓存接近或超过模型训练时的上下文窗口大小时，会严重影响LLM的生成质量。常见的缓存淘汰策略，即使保留了大量缓存，也可能因打断位置一致性而恶化性能。因此，需要了解缓存管理和模型架构限制之间的相互作用，以及位置编码的一致性问题，为LLM生成高质量的文本提供支持。", "innovation": "本文通过使用有状态的基准框架进行实证分析，发现当累积的KV缓存接近或超过模型训练时的上下文窗口大小时，会严重影响LLM的生成质量。传统缓存淘汰策略可能会因破坏位置一致性而恶化性能。本文进一步表明，简单的保持连续上下文块（例如，保留初始“概要”）的策略比复杂的或破坏位置的策略能够产生更一致的生成结果。本文倡议采用尊重架构限制、保持位置结构的缓存淘汰技术，并将“缓存健康”视为一个整体而非仅仅关注大小。", "conclusion": "本文通过实证分析了有状态的KV缓存管理对LLM性能的影响，提出了保持位置结构的缓存管理技术，并从整体上审视缓存健康而非仅仅关注其大小。这种方法有助于提高LLM在多轮场景中的生成质量和位置一致性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05017", "html_url": "https://arxiv.org/abs/2511.05017", "title": "通过精化文本嵌入减轻大型视觉语言模型中的幻觉", "title_en": "Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings", "authors": "Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang", "background": "现有LVLM（大型视觉语言模型）架构倾向于语言模态，很大程度上是由于将视觉嵌入简单地附加到输入文本序列中。这种架构导致了视觉地_kernel_表示不足，从而导致了幻觉和视觉定位的性能不佳。", "innovation": "本文提出了一种简单但有效的方法，通过结合平均池化后的视觉特征来优化文本嵌入，以减轻幻觉并提高视觉定位的准确性。这种方法比单纯的附加视觉嵌入更加平衡两种模态的信息处理", "conclusion": "实验表明，通过视觉信息优化文本嵌入能显著改善视觉定位及幻觉问题。虽然平均池化是一种直接而有效的方法，但更多的复杂融合技术仍值得未来研究探索，从而进一步提升视觉与语言的跨模态对齐。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04956", "html_url": "https://arxiv.org/abs/2511.04956", "title": "ORCHID：手持有补检索分类与人工闭环智能决策系统", "title_en": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "authors": "Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal", "background": "在美国能源部(DOE)的场址中，财产清单包括敏感的和经常是双重用途的设备。遵守各种出口控制政策指定的规则变更，要求进行透明和可审计的决策。传统的仅靠专家的工作流耗时，可能形成积压，且难以跟上不断变化的监管边界。", "innovation": "ORCHID是一种模块化的委托系统，结合了检索增强生成（RAG）与人工监管，以生成基于政策的输出并允许审计。系统中的小型协作代理通过代理间的消息传递协调，并通过模型上下文协议（MCP）调用工具实现平台兼容的本地操作。该系统通过项目到证据到决策的流程，逐步推理，遵循政策指导引用，并提供永久审计捆绑（运行卡、提示、证据）。初步测试显示ORCHID在对真实HRP案例的准确性与可追溯性方面超过了非代理基线，将不确定项目延期给主题专家（SMEs）。", "conclusion": "该演示表明单个项目提交、基于政策的具体引用、SME反馈的捕获及可导出的审计材料，展示了将负责任的LLM辅助应用于敏感DOE合规工作流的实际路径。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05079", "html_url": "https://arxiv.org/abs/2511.05079", "title": "基于Wikipedia的俄语信息检索基准RusBEIR数据集", "title_en": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR", "authors": "Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev", "background": "现有的俄语信息检索资源相对有限，尤其是针对“你可能不知道...”（Did you know...）部分的俄语维基百科数据集。这项研究旨在通过构建这些数据集来支持各种检索任务，如事实核查、检索增强生成和全文档检索，从而推动俄语信息检索的研究进展。", "innovation": "作者提出了一种新的数据集生成方法，利用俄语维基百科中的‘你可能不知道...’部分，并对相关句子进行了分级相关的标注。通过广泛的实验比较了基于词的检索模型（如BM25）与俄语的先进神经架构以及多语言模型的表现。研究表明，在全文档检索任务中，基于词的方法通常优于神经模型；而在更短的文本（如事实核查或精细检索）中，神经方法能够更好地捕捉到词义。此外还展示了结合检索和神经重排序方法的一致性改进效果。", "conclusion": "该研究扩大了可用于俄语信息检索研究的资源，并强调了准确评估检索模型对实现最优性能的重要性。所有数据集公开发布在HuggingFace上，并在GitHub上提供完整的实现以促进复制和未来研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04995", "html_url": "https://arxiv.org/abs/2511.04995", "title": "通过AI提高工程学生成公开演讲技能", "title_en": "Enhancing Public Speaking Skills in Engineering Students Through AI", "authors": "Amol Harsh,Brainerd Prince,Siddharth Siddharth,Deepan Raj Prabakar Muthirayan,Kabir S Bhalla,Esraaj Sarkar Gupta,Siddharth Sahu", "background": "工程学生成效沟通的持久挑战使得他们难以与多元利益相关者有效交流。尽管大学提供课程或工作坊，但无法持续地为学生提供个性化的培训。由于全面评估口头和非口头沟通方面需要大量时间，一致且个性化的评估变得困难。以往的研究集中在分别评估这些方面，但缺乏整合多模态数据以提供个性化、可扩展反馈的方法。因此，研究开发了一种结合语音分析、计算机视觉和情绪检测的多模态AI系统，为工程学生提供评估和反馈。该系统评估口头沟通（音调、音量、节奏、语调）、非口头沟通（面部表情、手势、姿势）和表达连贯性（确保言语与肢体语言一致的新颖结合）。", "innovation": "研究提出了一种全新的方法，即将语音分析、计算机视觉和情绪检测整合进一个多模态AI系统，用于评估和反馈。与先前单独评估这些方面的方法不同，该模型融合了多种模态，提供了个性化和可扩展的反馈。在多种先进的人工智能模型中，Gemini Pro在人类注释者中最一致，表示最强的一致性。", "conclusion": "通过AI驱动的公开演讲培训，在无须依赖人类评估者的情况下，该模型能够提供重复练习，帮助学生自然地将言语与肢体语言和情感对齐，这对于具有影响力和专业的沟通至关重要。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05301", "html_url": "https://arxiv.org/abs/2511.05301", "title": "QUESTER: 查询特定的生成检索", "title_en": "QUESTER: Query Specification for Generative Retrieval", "authors": "Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski", "background": "生成检索（GR）与传统的索引-检索管道不同，它通过模型参数存储相关性并直接生成文档标识符。然而，GR在泛化方面常常表现不佳，并且难以扩展。", "innovation": "提出了QUESTER（查询特定生成检索），将其重新定义为查询特定性的生成——本研究表明，使用（小型）语言模型来处理由BM25处理的简单关键词查询。使用增强学习技术（GRPO）训练策略。结果显示，该模型在不同领域的评估中比BM25更有效，并且与神经检索模型具有竞争力，同时保持良好的效率。", "conclusion": "QUESTER模型在不同领域评估中显示出比BM25更有效的性能，并且与神经检索模型具有竞争力，同时保持良好的效率。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05295", "html_url": "https://arxiv.org/abs/2511.05295", "title": "部分枚举下的语言生成和识别：紧凑的密度界限和拓扑表征", "title_en": "Language Generation and Identification From Partial Enumeration: Tight Density Bounds and Topological Characterizations", "authors": "Jon Kleinberg,Fan Wei", "background": "大型语言模型的成功激发了对语言生成与学习形式理论的研究。本文研究了在部分枚举框架下的语言生成问题，其中对手按未指定语言$K$中的未知语言生成字符串，并需要算法生成未见的字符串。早期研究表明生成总是可行的，但存在有效性与广度之间的权衡。本文进一步探讨在部分信息情况下，即对手仅展示$K$的一个无限子集$C$时，解决方案与问题的联系。", "innovation": "1. 证明了生成在极限中可实现的最佳可实现下密度为$1/2$。\n2. 强化模型以允许部分枚举，证明生成在极限中仍可实现，如果$C$在$K$中的下密度为$\beta$，算法的输出将至少达到$\beta$/2，这一结果推广了前一半密度界限到部分信息设置。\n3. 重新审视经典的哥德尔-安吉林模型的有限识别在部分枚举下的情况，给出新的拓扑表述，并展示安吉林的条件等价于适当拓扑空间具有$T_D$分离性质。", "conclusion": "本文通过更严格的密度界限及拓扑表征解决了部分枚举下的语言生成与识别问题，这一研究为该领域提供了新的理论基础，并展示了在部分信息情况下对未知语言的识别依然可能，并给出了量化这一识别能力的方法。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04707", "html_url": "https://arxiv.org/abs/2511.04707", "title": "在干草堆中窃取自由", "title_en": "Jailbreaking in the Haystack", "authors": "Rishi Rajesh Shah,Chen Henry Wu,Shashwat Saxena,Ziqian Zhong,Alexander Robey,Aditi Raghunathan", "background": "长上下文语言模型（LMs）的最新进展使得输入可以包含数百万个标记，扩展了其在诸如计算机使用代理等复杂任务中的应用能力。然而，这些扩展上下文对安全的影响仍然不清楚。因此，研究人员引入了一种名为NINJA的方法，通过在有害用户目标后面追加良性、模型生成的内容来绕过对齐的语言模型。研究表明，这种方法在HarmBench等标准安全基准测试中表现显著，能够显著提高攻击成功率，适用于包括LLaMA、Qwen、Mistral和Gemini在内的先进开放和专有模型。", "innovation": "NINJA方法的一个关键创新之处在于，它强调了有害目标位置对安全的影响。与之前的绕过方法不同，NINJA方法在资源需求上较低，具有可转移性且更难以检测。此外，NINJA方法在固定计算预算条件下，比增加试次的数量更有效，理论上可实现计算最优。这意味着即使使用看似无害的长上下文，如果仔细设计目标位置，也可以揭示现代语言模型的基本脆弱性。", "conclusion": "研究发现，即使是看似无害的长上下文，在精心设计目标位置的情况下，也会引入现代语言模型中的根本性漏洞。这种方法不仅对现有模型具有较强攻击性，而且提出了新的对抗性安全挑战，表明语言模型的安全性仍需进一步研究和改进。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04697", "html_url": "https://arxiv.org/abs/2511.04697", "title": "利用代理人格模拟信息漏洞", "title_en": "Simulating Misinformation Vulnerabilities With Agent Personas", "authors": "David Farr,Lynnette Hui Xian Ng,Stephen Prochaska,Iain J. Cruickshank,Jevin West", "background": "不实信息活动会扭曲公众认知并瓦解机构。理解不同群体对信息的反应对于设计有效的干预措施至关重要，但在现实世界中进行实验是不切实际且伦理上具有挑战性的。为了解决这个问题，研究者利用大型语言模型（LLMs）开发了一种基于代理的模拟方法，以建模对不实信息的反应。该研究构建了跨越五大职业和三种心理模式的代理人物模型，并评估其对新闻标题的反应。研究发现在这些代理模型中，心理模式比职业背景对信息的解释影响更大。这项工作为利用LLMs作为代理在信息网络的基于代理的模型中分析社会系统中信任、极化和对误导性内容的脆弱性提供了验证。", "innovation": "研究采用大型语言模型（LLMs）构建基于代理的模拟来建模对不实信息的反应，创新性地通过虚拟代理来研究信息网络中的信任、极化和对误导性内容的脆弱性问题。同时，研究发现心理模式比职业背景对信息解释的影响更大，为理解人类对信息的反应提供了新的视角。", "conclusion": "所运用的大型语言模型作为一种有效的代理，可以在信息网络中用于建模和分析复杂社会系统中的信任、极化和对误导性内容的脆弱性。心理模式比职业背景更能影响代理对信息的理解反应，该研究为在真实社会中研究信息漏洞提供了新的技术支持。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.20054", "html_url": "https://arxiv.org/abs/2406.20054", "title": "从词义扩展到概念：使用上下文语言模型诱导概念", "title_en": "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models", "authors": "Bastien Liétard,Pascal Denis,Mikaela Keller", "background": "词义多义性和同义性是词汇歧义的两个关键且相关方面。尽管多项研究在自然语言处理领域的词汇资源中广泛记录了这两种现象，并进行了深入研究，形成了专门的系统，但在实际问题中，它们往往被单独考虑。许多涉及词义的任务（例如词义消歧或诱导）突出强调了词语意义的作用，而同义性的研究则集中在概念上，即词汇库中共享的意义。", "innovation": "本论文介绍了一个新颖的无监督任务——概念诱导，旨在从数据中直接学习单词之间的软聚类，定义出一组概念。该任务扩展了词义诱导。本文提出了一种双层方法进行概念诱导，同时利用局部词素为中心的观点和全局跨词汇观点。该方法在SemCor注解数据上评估，取得了良好的性能，BCubed F1分数超过0.60。研究发现，局部和全局层次对概念诱导都具有互益性，在我们的设置中还可以促进词义的诱导。最终，创建了表示诱导概念的静态嵌入，并使用它们在Word-in-Context任务上取得了与现有最佳技术竞争力的表现。", "conclusion": "提出的概念诱导方法不仅能够有效地从数据中识别出概念集合，而且可以同时对词语进行词义诱导。通过验证已经取得的聚类并在Word-in-Context任务中获得与现有最佳技术相当的结果，证明了该方法的有效性和实用性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.00702", "html_url": "https://arxiv.org/abs/2411.00702", "title": "从公共话语中提取叙事信号：一种基于网络的方法", "title_en": "Extracting narrative signals from public discourse: a network-based approach", "authors": "Armin Pournaki,Tom Willaert", "background": "叙事是人类理解政治现实的关键解释工具。随着叙事对当前社会问题（如极化和虚假信息）理解的重要性日益显现，需要更方法来支持这些叙事的实证分析变得迫切。本文提出了一种基于网络的形式化和机器引导的方法，用于从数字文本语料库中抽取、表示和分析政治叙事的关键信号，特别是使用抽象意义表示法（AMR）。本文介绍一下的方法和形式化手段专用于研究数字媒体（如存档政治演讲、社交媒体帖子、议会辩论记录和政党网站上的政治宣言等）中的政治叙事。", "innovation": "本文提出了一种基于图形的形式化方法与机器引导技术，通过AMR抽取和分析文本中的叙事信号。此外，通过一套基于叙事学的概念和启发式规则，自动识别与政治事件、涉事人及其视角化的叙事线索。", "conclusion": "通过系统地分析这些信号并重新组装成指导研究者找到文本中关键部分的网络，这些网络有助于重建潜在的政治叙事。通过对欧盟国情咨文（2010年至2023年）进行实证研究，该方法展示了如何从公共话语中推导出政治叙事的关键信号。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05359", "html_url": "https://arxiv.org/abs/2511.05359", "title": "ConVerse: 基于代理交互的上下文安全基准测试", "title_en": "ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations", "authors": "Amr Gomaa,Ahmed Salem,Sahar Abdelnabi", "background": "当语言模型演变成代表用户行动和交流的自主代理时，确保多代理生态系统中的安全性成为一个核心挑战。个人助手与外部服务提供者之间的交互揭示了功能性和保护性的核心矛盾：有效的合作需要信息共享，但每一轮对话都会带来新的攻击面。现有的单一代理环境的测试方法无法模拟自主多轮对话，在这些对话中恶意请求被嵌入在合理的对话当中，从而考验代理之间的隐私和安全风险。当前的安全评估方法多为静态且单一，无法全面评估多代理交互中的持续安全风险。因此，一个能够涵盖实际领域、实用的代理间上下文安全基准测试变得更加必要，这将帮助开发者更好地理解和解决多代理生态中的安全问题.", "innovation": "ConVerse 旨在通过引入一个多代理环境中动态的上下文安全基准测试框架，解决多代理之间的隐私和安全风险。它涵盖了旅行、房地产和保险三个实际领域，包含了12种不同的人格档案和超过864个上下文相关攻击(包括611个隐私攻击和253个安全攻击)。ConVerse 模拟了代理之间的多轮交互，其中恶意请求以看似合理的对话形式存在，通过一种分层分类评估隐私保护质量和通过对工具使用和偏好操纵的攻击评估安全性。这一框架有助于发现当前最先进的模型中的持续漏洞，并且能够识别更强大的模型泄露更多安全性的问题。ConVerse 将隐私和安全集成在交互式的多代理环境之中，重新定义了通信中的安全性作为一种协作的新兴属性.", "conclusion": "通过对七个最先进的模型进行评估，ConVerse 显示出持续存在的漏洞：隐私攻击成功率达到高达88%，安全漏洞高达60%。这表明现有模型在多代理交互场景中的安全性存在普遍问题。通过统一隐私和安全测试，ConVerse 改变了安全性在交互式多代理环境中的范式，突显了在这些复杂对话中确保安全性的挑战。未来的研究应该基于 ConVerse 的方法重新评估多代理生态系统的安全性，并进一步开发能够有效应对这些挑战的新模型和策略。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.09766", "html_url": "https://arxiv.org/abs/2501.09766", "title": "iTool: 动态缺陷校准的强化微调以实现高级工具使用", "title_en": "iTool: Reinforced Fine-Tuning with Dynamic Deficiency Calibration for Advanced Tool Use", "authors": "Yirong Zeng,Xiao Ding,Yuxian Wang,Weiwen Liu,Wu Ning,Yutai Hou,Xu Huang,Duyu Tang,Dandan Tu,Bing Qin,Ting Liu", "background": "增强大型语言模型（LLMs）的外部工具使用能力是提升其复杂任务处理能力的一种有前景的方法。通过现实世界仿真合成交叉数据是一项有效的技术，但研究表明，随着合成数据量的增加，训练收益会显著下降。模型难以从额外的合成数据中受益，无法获得高级的工具使用能力。此外，这一局限往往表现为响应中的片段不足（即参数错误）。", "innovation": "提出了一种迭代强化微调策略，以缓解上述限制。该策略包括：1）通过蒙特卡洛树搜索路径探索来增强合成数据响应的多样性；2）逐步指出模型的缺陷并通过构建精准的偏好对并使用偏好优化算法进行改进，以实现有针对性的提升。实验结果表明，该方法比同大小的基础模型提高了13.11%的性能，在复杂场景中相比于基线模型提高了6.5%的性能，同时也优于更大规模的开源和闭源模型。", "conclusion": "该方法在增强LLMs的外部工具使用能力方面表现出显著优势，特别是在合成数据量增加时仍能保持良好的性能。通过动态缺陷校准的强化微调策略，可以有效提高模型在复杂场景下的性能。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05442", "html_url": "https://arxiv.org/abs/2511.05442", "title": "APP：具有任务特异性剪枝的加速路径补丁", "title_en": "APP: Accelerated Path Patching with Task-Specific Pruning", "authors": "Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff", "background": "电路发现是许多机制可解释性管道中的关键步骤。目前的方法，如Path Patching，计算成本高，并且对较小的模型深度分析能力有限。", "innovation": "本文提出了一种加速路径补丁（APP），它是一种混合方法，结合了我们新开发的对比注意力头剪枝方法，以大幅减小电路发现方法的搜索空间。本文采用对比FLAP剪枝算法，使用因果中介分析技术来赋予任务特异性注意力头更高的剪枝分数，从而与传统的剪枝技术相比，生成了更具性能的稀疏模型。尽管Contrastive-FLAP在保持现有剪枝算法在低稀疏度比下移除的任务特异性头方面非常成功，但仅通过Contrastive-FLAP发现的电路规模太大，无法满足电路分析所需的最小性约束。APP首先应用Contrastive-FLAP，将电路发现算法所需的搜索空间平均减少56％，然后应用传统的Path Patching方法对剩余的注意力头进行处理，与直接在密集模型上应用Path Patching相比，速度提高了59.63%-93.27％。", "conclusion": "尽管APP提供了巨大的计算节省，但从APP获得的电路具有明显重叠，并且性能与之前确立的Path Patching电路相似。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02421", "html_url": "https://arxiv.org/abs/2502.02421", "title": "大型语言模型的激活信息驱动合并", "title_en": "Activation-Informed Merging of Large Language Models", "authors": "Amin Heyrani Nobari,Kaveh Alim,Ali ArjomandBigdeli,Akash Srivastava,Faez Ahmed,Navid Azizan", "background": "模型合并是一种结合多个微调大型语言模型（LLMs）参数和嵌入的方法，可以提高模型在各种任务上的性能，同时保持计算效率。现有的合并方法没有充分利用激活空间（activation space）的信息来改进性能和稳健性。本文旨在探索如何在模型合并过程中利用激活空间信息，以提高大型语言模型的性能。", "innovation": "本文提出了一种名为Activation-Informed Merging (AIM)的技术，该技术将大型语言模型的激活空间信息融入合并过程，以提高性能和鲁棒性。AIM是一种灵活的互补解决方案，适用于任何现有的合并方法。它通过利用持续学习（CL）和模型压缩的原则，选择性地优先考虑重要的权重。实验结果表明，AIM可以显著提升合并模型在多个基准测试上的性能，尤其是在考虑激活空间信息时，可以实现多达40%的基准性能提升。", "conclusion": "本文研究发现，考虑激活空间信息在大型语言模型的合并策略中具有显著的改进潜力，这可能成为提高LLMs合并性能的有效方法。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15027", "html_url": "https://arxiv.org/abs/2502.15027", "title": "InterFeedback：通过人类反馈揭示大型多模态模型的互动智能", "title_en": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback", "authors": "Henry Hengyuan Zhao,Wenqi Pei,Yifei Tao,Haiyang Mei,Mike Zheng Shou", "background": "现有的基准测试没有评估大型多模态模型（LMMs）与人类用户之间的互动智能，这对于开发通用的人工智能助手至关重要。InterFeedback 是一个交互框架，可以被应用于任何 LMM 和数据集，以自主评估这种能力。Additionally, InterFeedback-Bench 使用两个代表性数据集 MMMU-Pro 和 MathVerse 来评估 10 种不同的开源 LMMs 的互动智能。InterFeedback-Human 是一个新收集的数据集，包含 120 个案例，旨在手动测试领先模型如 OpenAI-o1 和 Claude-Sonnet-4 的互动性能。我们的评估结果表明，即使是最先进的 LMM OpenAI-o1 也难以根据人类反馈改进其响应，平均得分为不到 50%。这些发现表明需要开发方法来增强 LMMs 解释和利用反馈的能力。", "innovation": "设计了 InterFeedback 交互框架，这是一个可以应用于任何 LMM 和数据集的系统，用以自主评估 LMM 与人类用户之间的互动智能。同时引入了两个新的数据集 InterFeedback-Bench 和 InterFeedback-Human，用以评测不同 LMM 的互动智能和性能。通过这两个数据集的评测结果，揭示了 LMM 在处理人类反馈方面的局限性，并强调了增强其解释和利用反馈能力的必要性。", "conclusion": "我们的评估结果显示，即使是顶级的 LMM，如 OpenAI-o1，也难以有效地根据人类反馈改进其响应，平均分数低于 50%。这强调了增强 LMM 解释和利用反馈能力的重要性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05305", "html_url": "https://arxiv.org/abs/2506.05305", "title": "ProRefine：利用文本反馈进行推理时提示 refinement", "title_en": "ProRefine: Inference-Time Prompt Refinement with Textual Feedback", "authors": "Deepak Pandita,Tharindu Cyril Weerasooriya,Ankit Parag Shah,Isabelle Diana May-Xin Ng,Christopher M. Homan,Wei Wei", "background": "多智能体协作的工作流（agentic workflows），即多个AI代理协同完成复杂的任务（如推理或规划），在许多前沿商业应用中扮演重要角色，并持续吸引跨领域的研究人员。这些工作流依赖于提供的提示来指导各AI代理的角色。设计不佳或引导不足的提示可能导致性能不佳，甚至在多代理系统中雪崩式恶化，限制了它们的可靠性和扩展性。", "innovation": "提出了ProRefine，这是一种创新的推理时提示优化方法，利用循环的LLMs生成并应用文本反馈。ProRefine在不进行额外训练或真实标签的情况下，动态优化多步推理任务的提示。在五项基准数学推理数据集上，ProRefine显著超越零样本链式思维基线，提升了3到37个百点，不仅提高了准确性，还让小型模型接近了大模型的性能。", "conclusion": "该方法强调了其建设更加成本有效且强大的混合AI系统的潜力，从而让更多人能够获得高性能的AI。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10335", "html_url": "https://arxiv.org/abs/2504.10335", "title": "MorphTok: 印地语驱动力标记化", "title_en": "MorphTok: Morphologically Grounded Tokenization for Indian Languages", "authors": "Maharaj Brahma,N J Karthika,Atul Singh,Devaraj Adiga,Smruti Bhate,Ganesh Ramakrishnan,Rohit Saluja,Maunendra Sankar Desarkar", "background": "标记化是自然语言处理（NLP）中的关键步骤，尤其是随着大型语言模型（LLMs）的发展，它影响了下游性能、计算成本和效率。现有的LLMs主要是依赖传统的字节对编码（BPE）算法来进行子词标记化，这个算法倾向于合并频繁的字符双元组，这往往导致分段语不符合语言学有意义的单位。基于以上问题，文章提议将形态学意识的分段作为标记化前的预处理步骤，结合新的形态学驱动力的标记化数据集（包括沙地拆分以增强子词标记化），实验表明基于形态学的标记化可以改善机器翻译和语言建模的性能。", "innovation": "1. 提出了形态学意识的分段作为标记化前的预处理步骤。\n2. 创建了一个新的数据集（Hindi和Marathi），纳入了沙地拆分，以增强子词标记化。\n3. 提出了C约束BPE（CBPE），其是标准BPE算法的扩展，包含特定的脚本约束，特别处理依存元音，让它们与其他字符形成一个整体单元，而不是作为一个单一单元出现，从而减少了生育率分数1.68%，同时保持或提高了机器翻译和语言建模的下游性能。", "conclusion": "文章展示了形态学驱动力标记化可以有效提高机器翻译和语言建模的性能，同时CBPE相对标准BPE来说更加计算高效。文章还引入了新的评价指标“EvalTok”，为进一步的分段评估设计了一种更接近人类直觉的方法。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09601", "html_url": "https://arxiv.org/abs/2507.09601", "title": "NMIXX：针对跨语言金融探索的领域适配神经嵌入", "title_en": "NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance", "authors": "Hanwool Lee,Sara Yu,Yewon Hwang,Jonghyun Choi,Heejae Ahn,Sungbum Jung,Youngjae Yu", "background": "通用句子嵌入模型在捕捉金融领域专业知识方面经常遇到困难，尤其是在韩语等低资源语言中，这主要是由于领域特定的专业术语、语义变迁以及双语词汇对齐的不匹配。", "innovation": "NMIXX（Neural eMbeddings for Cross-lingual eXploration of Finance）是一款细调后的跨语言嵌入模型，它使用18,800个高置信度模块组对领域内同义句、基于语义变迁的难负样本以及精确的韩语-英语翻译进行训练。此外，还发布了KorFinSTS（Korean Financial STS基准测试集），包含1,921对跨新闻、披露、研究报告和法规的韩语金融对齐句子对，旨在展示通用基准难以捕获的细微差异。", "conclusion": "NMIXX的多语言bge-m3版本在官方许可基线中，于English FinSTS上提升了0.10的Spearman's rho得分，在KorFinSTS上提升了0.22，表现最佳。我们的分析表明，拥有更多韩语词汇覆盖的模型可以更有效地适应，并强调了在低资源跨语言设置中设计有效的分词器的重要性。通过公开模型和基准测试集，我们为跨语言金融中的领域适配多语言表示学习提供了工具和资源。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13124", "html_url": "https://arxiv.org/abs/2502.13124", "title": "NaturalReasoning：2.8百万难题中的推理能力培养", "title_en": "NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions", "authors": "Weizhe Yuan,Jane Yu,Song Jiang,Karthik Padthe,Yang Li,Ilia Kulikov,Kyunghyun Cho,Dong Wang,Yuandong Tian,Jason E Weston,Xian Li", "background": "传统的推理能力提升主要集中在数学和编码领域，但由于缺乏多样性和高质量的问题，使得拓展到其他领域变得困难。现有的资源无法满足多样化和挑战性的问题需求，限制了推理能力的扩展。", "innovation": "提出了一个可扩展的方法，用于生成多样化和具有挑战性的推理问题及其参考答案。通过NaturalReasoning数据集展示了这种方法的有效性，该数据集包括280万道跨多个领域的题目，如STEM领域（如物理、计算机科学）、经济学和社会科学等。", "conclusion": "通过知识蒸馏实验表明，NaturalReasoning能够有效激发并转移强大的教师模型的推理能力。该数据集还证明了其在无监督自训练中的有效性，通过外部奖励模型或自我奖励。为了促进未来的研究工作，公开发布了NaturalReasoning数据集。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23842", "html_url": "https://arxiv.org/abs/2505.23842", "title": "通过Shapley值在LLM摘要中实现文档公平估值", "title_en": "Fair Document Valuation in LLM Summaries via Shapley Values", "authors": "Zikun Ye,Hema Yoganarasimhan", "background": "随着大型语言模型（LLMs）在多个源内容检索和总结系统中的使用增加，如搜索引擎和AI助手，这些系统虽然通过连贯的摘要增强了用户体验，但同时也遮蔽了原始内容创作者的贡献，引发了对归属权和补偿的担忧。文章试图通过提出基于Shapley值的框架来公平地评估LLM生成摘要中所使用的单个文档价值，提出了一个解决这一挑战的方法。然而，精确的Shapley值计算在大规模应用中过于昂贵，因此建议使用Cluster Shapley算法，在降低计算成本的同时保持准确的归属权。研究表明，在LLM环境中，现成的Shapley值近似方法表现不佳，而Cluster Shapley显著改善了效率和准确性的平衡。而且，简单的归属规则（如等额或相关性分配）尽管计算成本较低，但会导致非常不公平的结果。这些发现强调了针对LLM摘要设计结构感知的Shapley值近似方法的潜力，为寻求可扩展和公平的内容归属机制的平台提供了指导。", "innovation": "该研究提出了一个基于Cluster Shapley算法的框架，通过利用文档间的语义相似性来减少计算量，同时保持归属权的准确性。表明在LLM环境中，传统的Shapley值近似方法表现不佳，而Cluster Shapley算法在效率和准确性之间提供了更好的平衡。此外，强调了结构感知的Shapley值近似方法在LLM摘要中的潜力，并为平台提供了实现可扩展且公平的内容归属机制的指导。", "conclusion": "该研究通过提出结构感知的Shapley值近似方法，强调了其在LLM摘要中的潜力，并为实现平台上的公平内容归属机制提供了新的方向。研究表明，虽然直接应用Shapley值在大规模应用中存在效率问题，但通过改进的Cluster Shapley算法可以有效解决这一问题。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.03740", "html_url": "https://arxiv.org/abs/2410.03740", "title": "LEME：具有高级推理和临床验证的眼科开放大语言模型", "title_en": "LEME: Open Large Language Models for Ophthalmology with Advanced Reasoning and Clinical Validation", "authors": "Hyunjae Kim,Xuguang Ai,Sahana Srinivasan,Aidan Gilson,Maxwell B. Singer,Krithi Pushpanathan,Qianqian Xie,Jungwoo Park,Serina Applebaum,Gabriel Dawei Yang,Minjie Zou,David Ziyou Chen,Ke Zou,Soshian Sarrafpour,Ji Liu,Yu Yin,Jimin Huang,Quang Ngoc Nguyen,Erping Long,Peixing Wan,Dianbo Liu,Richard Hintz,W. Jim Zheng,Sophia Y. Wang,Lucila Ohno-Machado,Hua Xu,Ron A. Adelman,Luciano V. Del Priore,Yih-Chung Tham,Qingyu Chen", "background": "眼病的发病率正在上升，这给公共卫生带来了越来越大的负担。虽然大型语言模型（LLMs）提供了一条减轻医疗记录工作量和促进临床决策支持的有希望途径，但这些模型很少专门针对眼科进行定制，而且大多数评估主要集中在基于知识的问答上，缺乏临床相关标准或实际验证。", "innovation": "LEME是一个通过两阶段过程开发的开放式重训练大语言模型套件：1）在临床指南、教科书和病例报告的200,000个样本上进行指令微调，以增强推理能力和任务跟随能力；2）通过约30,000个偏好标签的强化学习，以提高准确性和信息量。LEME在五个精心策划的零样本基准任务中表现优异，包括患者问答、咨询和治疗规划，优于所有七个基线（所有p < 0.004），并且在绝对ROUGE-L方面比GPT-4o高出3.32%。此外，经过盲人患者数据的下游任务评估，并得到临床医生的审阅。在患者问答中，LEME在3个评价标准中得分最高，分别为事实真实性4.67、具体性4.77、完整性4.79和安全性4.88（1到5分制），其完整度得分超过了专家级撰写的答案（4.79比4.56，p = 0.015）。在视觉敏锐度提取中，LEME取得最高的F1分数，分别比LLaMA-3高出14.1%和比Eye-LLaMA高出59.0%。", "conclusion": "所有的模型、数据和代码都将被释放，以支持进一步的发展和临床转化，为改善效率和患者护理奠定基础。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.06980", "html_url": "https://arxiv.org/abs/2503.06980", "title": "通过感知强度评分探索大型语言模型的多模态感知", "title_en": "Exploring Multimodal Perception in Large Language Models Through Perceptual Strength Ratings", "authors": "Jonghyun Lee,Dojun Park,Jiwoo Lee,Hoekeon Choi,Sung-Eun Lee", "background": "本研究旨在探讨多模态大型语言模型是否能够实现类似于人类的感知接地（sensory grounding），通过评估它们在不同感知模态中捕捉感知强度评分的能力来实现。研究关注了模型特性（大小、多模态能力、架构生成）、分布因素依赖性（词频、嵌入、特征距离）以及人类与模型处理之间的差异。", "innovation": "研究通过使用Lancaster Sensorimotor Norms中的3,611个词汇，评估了21个来自四大家族（GPT、Gemini、LLaMA、Qwen）的模型，采用了相关性、距离度量和定性分析的方法。研究发现较大的、多模态的和较新的模型通常优于较小的、文本专一的和较老的模型。此外，研究指出尽管多模态性提高了表现，但并没有提供不同的信息，而是像大量文本数据一样提供相似的信息，这表明引入多模态性并不能完全解决感知接地的缺陷。", "conclusion": "尽管先进的人工智能语言模型能够通过统计学习在感知和语言关联中表现出类似人类的性能，但它们在处理机制上仍与人类的本体认知有差异，即使在多模态集成的情况下也是如此。研究结果表明，大型语言模型虽然能够在感知语言关联方面达到高准确性，但它们的处理机制仍存在不足。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02189", "html_url": "https://arxiv.org/abs/2508.02189", "title": "小模型预训练中的元学习学习动态", "title_en": "Learning Dynamics of Meta-Learning in Small Model Pretraining", "authors": "David Demitri Africa,Yuval Weiss,Paula Buttery,Richard Diehl Martinez", "background": "大型语言模型虽强大但成本高昂，研究人员探索了元学习是否可以使小语言模型的预训练不仅更好，而且更具可解释性。", "innovation": "研究结合了一阶MAML和子集掩蔽LM预训练，创建了四个类LLama风格的只解码器模型（参数量从11M到570M），并在多种NLP任务设置和实际应用中进行评估，结果显示与传统训练相比，该模型(i)在能耗相同的情况下达到相同的损失速度提高了1.6倍，(ii)在多语言通用命名实体识别中F1分数提升，(iii)训练动态变得容易理解：首先是网络表示的分散（“多样化”），然后是压缩到更小的共享子空间，这种两阶段转变在有效秩曲线和注意力头熵中表现为先上升后下降。", "conclusion": "两阶段转变通过有效秩曲线和注意力头熵曲线明确指出了哪一层最早专业和后来再次聚合，提供了元适应的一个紧凑且可解释的特征签名。相关代码、检查点和WandB日志已发布。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23247", "html_url": "https://arxiv.org/abs/2507.23247", "title": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "title_en": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "authors": "Sneha Oram,Pushpak Bhattacharyya", "background": "尽管在人工智能（AI）和自然语言处理（NLP）领域，人工智能对于心理健康领域的可解释性和可理解性已经受到了广泛关注，但推理这一方面一直没有得到同样深入的研究。因此，弥补这一差距对于通过可解释和具备推理能力的AI系统连接NLP和心理健康来说至关重要。本研究旨在研讨大型语言模型（LLM）在心理健康领域的语用推理能力。", "innovation": "为了填补这一空白，研究引入了PRiMH数据集，并提出了一系列包含语用蕴含和预设现象的心理健康推理任务。特别地，该研究形式化了两个蕴含任务和一个预设任务。研究还使用四种模型（Llama3.1、Mistral、MentaLLaMa和Qwen）对这些任务进行评估，发现Mistral和Qwen在该领域表现出显著的推理能力。另外，研究还利用最先进的LLM（GPT4o-mini、Deepseek-chat和Claude-3.5-haiku）提出了三种StiPRompts来研究与心理健康相关的偏见问题。", "conclusion": "研究结果表明，Claude-3.5-haiku处理偏见问题的方式比另外两种LLM更加负责任。这表明，这类先进的AI系统在处理心理健康的复杂问题上具有潜力，特别是在处理社会偏见方面更具有优势。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11137", "html_url": "https://arxiv.org/abs/2506.11137", "title": "使用大语言模型从电子健康记录中规模化提取和识别药物停用信息", "title_en": "Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models", "authors": "Chong Shao,Douglas Snyder,Chiran Li,Bowen Gu,Kerry Ngan,Chun-Ting Yang,Jiageng Wu,Richard Wyss,Kueiyu Joshua Lin,Jie Yang", "background": "识别电子健康记录（EHRs）中的药物停用信息对于患者安全至关重要，但往往受到信息埋藏在非结构化注释中的阻碍。已有方法难以全面提取和分类这些信息。", "innovation": "研究旨在评估先进开源和专有的大型语言模型（LLMs）在从EHR注释中提取药物并分类其停药状态的能力，特别是在无需人工注释的情况下实现药物信息提取的规模化。研究采用了多种LLM提示策略，并系统性地比较了多种模型在药物提取、停药分类和联合任务（提取后分类）上的表现。", "conclusion": "LLMs 在从EHR注释中提取药物和停药分类方面表现出良好的性能。GPT-4o 在所有任务中均取得了最高平均 F1 分数；开源模型也表现出色，Llama-3.1-70B-Instruct 在多项任务中取得了最佳性能。医学专用的LLMs 在性能上低于先进的通用领域模型。少样本学习能显著提升LLMs 的性能，而CoT推理的效果则不明显。开源LLMs 具有代替专有系统的潜力，并且少样本学习策略能够进一步提高LLMs 的能力。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.17086", "html_url": "https://arxiv.org/abs/2502.17086", "title": "Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM Reviews", "title_en": "Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM Reviews", "authors": "Hyungyu Shin,Jingyu Tang,Yoonjoo Lee,Nayoung Kim,Hyunseung Lim,Ji Yong Cho,Hwajung Hong,Moontae Lee,Juho Kim", "background": "同行评审是科学研究的基础，但日益增长的工作量和评审人员短缺正在给这一过程带来压力。大语言模型(LLM)现在能够自动撰写评审，但是评估生成的LLM评审报告的可信度需要系统的评价。虽然已有研究通过表面层面（如BLEU和ROUGE）和内容层面（如具体性和事实准确性）对LLM的评审进行了评估，但尚未确定这些生成的评审是否会关注人类专家所重视的关键方面，即评审过程中的接受或拒绝决定所依赖的优缺点。", "innovation": "本文引入了一种焦点层面的评价框架，将注意力聚焦定义为对论文评审中预定义领域关注度的标准化分布。基于此框架，开发了两个不同焦点层面的自动评价流程，分别涵盖了目标（如问题，方法，实验）和方面（如有效性，清晰度，新颖性）的数据集。通过比较LLM和人类专家的注意力分布在预定义领域的分布，发现了LLM在批评论文时倾向于对技术有效性进行评价，但在新颖性评估方面明显欠缺。", "conclusion": "这项研究为系统评估LLM生成的评审报告提供了一个新的焦点层面的评价框架。研究表明，广泛使用的LLM在某些领域存在盲点，例如可能是对论文新颖性和创新性关注不足。这为改进LLM生成的评审报告以及提升评审系统的整体质量提供了重要参考。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query：通过多智能体合作在SQL辅助表格理解中释放大型语言模型的力量", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表格理解需要结构化和多步骤的推理。大型语言模型（LLMs）在处理表格数据的结构性复杂性时存在困难。最近，多智能体框架在SQL生成方面显示出潜力，但现有方法往往存在理解和处理表格结构不足、错误传递导致无效查询以及过度依赖执行结果的缺点。", "innovation": "本文提出了Chain-of-Query（CoQ），这是一种新颖的多智能体框架，用于SQL辅助的表格理解。CoQ采用自然语言风格表示表模式来抽象结构噪音，提升理解能力。采用逐句SQL生成策略提高查询质量，并引入混合推理划分，区分基于SQL的机械推理和基于LLM的逻辑推理，从而减少对执行结果的依赖。", "conclusion": "在四种模型和五种广泛使用的基准测试中的大量实验表明，CoQ在表格理解方面取得了显著的准确度改进，并大大降低了无效SQL查询的比例，证实了其在表格理解中的优越效果。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.07869", "html_url": "https://arxiv.org/abs/2509.07869", "title": "大规模语言模型与人类注释员的脆性对比", "title_en": "Are Humans as Brittle as Large Language Models?", "authors": "Jiahui Li,Sean Papay,Roman Klinger", "background": "大规模语言模型（LLMs）的输出不稳定，既有解码过程的非确定性原因，也有提示（prompt）脆弱性的问题。LLMs生成过程的内在非确定性可能通过输出分布的变化模仿人类注释的不确定性，但提示脆弱性效应尚被认为仅限于LLMs，未被深入研究。因此，该研究探讨了人类注释员在提示变化下是否也同样表现出敏感性，以及这种脆性是否反映真实注释变异性。", "innovation": "该研究系统地比较了提示修改对LLMs和人类注释员的影响，特别是关注人类是否同样对提示扰动敏感。研究通过一系列文本分类任务，研究了不同类型的提示修改对人类和LLMs的影响，发现两者都对某些类型的提示修改表现出脆性增加，尤其是标签集或格式的替换，但人类判断分布受拼写错误和标签倒序的影响不如LLMs明显。", "conclusion": "研究结论表明，人类和LLMs对特定类型的提示修改都表现出脆性增加。然而，人类对于拼写错误和标签倒序的判断分布变化较小，这表明尽管人类注释员对提示变化有较高敏感性，但其脆性可能并不如LLMs那样严重，或者脆性更能反映真实的注释变异性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.17797", "html_url": "https://arxiv.org/abs/2510.17797", "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "title_en": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "authors": "Akshara Prabhakar,Roshan Ram,Zixiang Chen,Silvio Savarese,Frank Wang,Caiming Xiong,Huan Wang,Weiran Yao", "background": "随着信息的指数级增长，企业面临着越来越大的压力，需要将无结构化数据转化为连贯的、可操作的洞察。尽管自主代理显示出潜力，但它们往往在领域特定的细微差别、意图对齐和企业集成方面存在困难。", "innovation": "本文提出了企业深度研究（EDR），这是一种多代理系统，包括：1）一个主规划代理用于自适应查询分解；2）四个专门的搜索代理（通用、学术、GitHub、LinkedIn）；3）一个基于MCP的可扩展工具生态系统，支持NL2SQL、文件分析和企业工作流；4）一个数据驱动洞察的可视化代理；5）一个反思机制，用于检测知识缺口并根据可选的人工循环指导更新研究方向。这些组件使自动化报告生成、实时流式传输和无缝企业部署成为可能。", "conclusion": "EDR在内部数据集上的结果得到了验证，在包括DeepResearch Bench和DeepConsult的开放性基准测试中，没有人类指引的情况下，EDR的性能优于最先进的代理系统。同时，发布了EDR框架和基准轨迹，以推进多代理推理应用的研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15418", "html_url": "https://arxiv.org/abs/2510.15418", "title": "Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs", "title_en": "Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs", "authors": "Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye", "background": "现有的检索增强生成系统对于提供基于马来西亚临床实践指南的基于事实的指导是必要的，但它们在处理基于图像的查询时效果有限，因为通用的视觉-语言模型生成的描述往往缺乏临床特定性和事实性。", "innovation": "该研究提出并验证了一种框架，以专业化的MedGemma模型生成高质量的描述，用作高级查询。通过知识蒸馏管道在皮肤科、眼底和胸部X光成像领域创建合成数据集，并使用参数高效的方法QLoRA对MedGemma进行微调。通过双重框架评估性能，该框架同时测量分类准确性，并通过RAGAS框架的新应用测量描述的忠实性、相关性和正确性。", "conclusion": "微调后的模型在分类性能上表现出显著改善，RAGAS评估证实了描述的忠实性和正确性也有所增强，证明了模型能够产生可靠且基于事实的描述。这项工作建立了一个强大的管道，用于专门化医疗视觉语言模型，并验证了该模型作为高质量查询生成器的能力，为增强基于证据的临床决策支持中的多模态RAG系统奠定了基础。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16227", "html_url": "https://arxiv.org/abs/2510.16227", "title": "字符串概率能告诉我们多少关于语法正确性的东西？", "title_en": "What Can String Probability Tell Us About Grammaticality?", "authors": "Jennifer Hu,Ethan Gotlieb Wilcox,Siyuan Song,Kyle Mahowald,Roger P. Levy", "background": "语言模型（LMs）关于语法方面学习的内容仍存在争议，这对语言学理论有重大影响。由于概率和语法正确性是语言学中的不同概念，字符串的概率并不能明显揭示LMs的语法知识。论文通过分析语法、意义和字符串概率之间的关系，提出了理论框架，假设了语料库数据生成过程的简单假设，得出了三个预测并进行了验证，对使用字符串概率研究LMs的结构知识提供了理论依据，同时指出了未来LM语法评估研究的方向。", "innovation": "作者提出了一个理论框架，用于分析语法、意义和字符串概率之间的关系，通过简单假设说明语料库数据的生成过程，得出了三个主要预测，并通过英语和中文中的280000个句子对进行了实证验证，这些发现为使用概率研究LMs的结构知识提供了理论基础，同时为未来LM语法评估研究指明了方向。", "conclusion": "论文分析表明了使用字符串概率来研究LMs的结构知识的可能性，并提出了未来的研究方向。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22115", "html_url": "https://arxiv.org/abs/2510.22115", "title": "每次激活提升：扩展通用推理者至1万亿开放语言基础", "title_en": "Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation", "authors": "Ling Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chilin Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu", "background": "这篇论文介绍了一种新的语言基础模型，即Ling 2.0，它基于每个激活都能提升推理能力的原则。该模型旨在跨越从数十亿到万亿参数的范围，采用统一的专家混合（Mixture-of-Experts, MoE）架构。Ling 2.0 强调高稀疏性、跨尺度一致性以及由经验性扩展法则指导的效率。", "innovation": "Ling 2.0 集成了模型架构、预训练、后训练和基础设施方面的创新。它结合了高稀疏性的 MoE 与 MTP，以实现高效推理，同时引入了推理导向的数据和中训练 CoT 激活、基于强化学习的微调方法（DFT, Evo-CoT），并实现了全尺度 FP8 训练，利用细粒度异构流水线。在万亿参数级别，Ling-1T 设置了推理解析准确性和计算效率之间的新帕累托边界，表明当稀疏激活与推理目标正确对齐时，能够实现可扩展且高效的智能。", "conclusion": "Ling 2.0 提供了一个统一、开放和高效的推理与思考模型的基础，为未来的发展奠定了基础，并且基于相同基础构建了 Ring 系列模型。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17803", "html_url": "https://arxiv.org/abs/2508.17803", "title": "DRQA: 动态推理配额分配以控制大型语言模型推理中的过度思考", "title_en": "DRQA: Dynamic Reasoning Quota Allocation for Controlling Overthinking in Reasoning Large Language Models", "authors": "Kaiwen Yan,Xuanqing Shi,Hongcheng Guo,Wenxuan Wang,Zhuosheng Zhang,Chengwei Qin", "background": "大型语言模型（RLLMs），如OpenAI-O3和DeepSeek-R1，最近展示了通过执行结构化和多步推理的能力。然而，研究发现RLLMs通常会表现出过度思考的问题，即使对于简单的问题也会产生不必要的长推理链，导致标记使用过多和计算效率低下。但在批量处理多个问题时，RLLMs会通过隐式的资源竞争动态压缩简单的推理步骤，表现得更高效。基于这一点，我们提出了动态推理配额分配（DRQA），该方法将批量处理中的资源竞争优势转移到单个问题的推理中。DRQA 利用批量生成的偏好数据和强化学习来训练模型，使其能够动态分配推理资源。通过鼓励模型形成对准确性和简明性的偏好，DRQA 使模型不仅能为简单问题生成简洁的答案，还能够为复杂问题保留足够的推理深度。", "innovation": "DRQA 是一种新颖的方法，它利用批量生成的偏好数据和强化学习来训练模型，使其能够动态分配推理资源，以适应捕获准确性和简明性的优先级。通过这种方式，DRQA 能够有效减少标记使用，同时保持或改进答案准确性。总的来说，DRQA 能够有效地缓解过度思考的问题，为 RLLMs 的高效和可扩展部署提供了新的方向。", "conclusion": "在广泛的数据集上进行了多项实验，结果表明，DRQA 显著减少了标记使用，同时保持了或改进了答案的准确性。通过有效缓解过度思考问题，DRQA 为更高效和可扩展的 RLLMs 部署提供了有希望的方向，我们也希望它能够进一步推动精细化推理行为控制的研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20514", "html_url": "https://arxiv.org/abs/2508.20514", "title": "SciTopic: 通过先进大语言模型增强科学文献主题发现", "title_en": "SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM", "authors": "Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou", "background": "科学研究文献中的主题发现为研究人员提供了识别新兴趋势和探索新研究领域的有价值的见解，有助于更方便地获取科学信息。许多机器学习方法，尤其是深度嵌入技术，已被应用于主题发现。然而，现有的大多数主题发现方法依赖于词嵌入来捕捉语义，缺乏对科学出版物的全面理解，难以处理复杂的高维文本关系。", "innovation": "受大型语言模型（LLMs）对文本信息的出色理解和处理能力的启发，作者提出了一个增强LLMs的先进主题发现方法SciTopic。该方法首先构建了一个文本编码器来捕捉科学出版物的内容，包括元数据、标题和摘要。接下来，通过利用基于LLMs的熵采样和三元组任务，构建了一个空间优化模块，优化了主题相关性和上下文复杂性。然后，建议根据LLMs的指导，通过优化三元组的对比损失来微调文本编码器，促使文本编码器更好地区分不同的主题实例。", "conclusion": "在三个真实的科学文献数据集上进行的广泛实验表明，SciTopic 在科学主题发现方面超过了最先进的（SOTA）方法，使研究人员能够更快更深刻地获得见解。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25441", "html_url": "https://arxiv.org/abs/2510.25441", "title": "从离线日志中学习并部署具备现实基础的主动型大语言模型", "title_en": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs", "authors": "Fei Wei,Daoyuan Chen,Ce Wang,Yilun Huang,Yushuo Chen,Xuchen Pan,Yaliang Li,Bolin Ding", "background": "大语言模型（LLMs）擅长响应式反应，但使其成为具有前瞻性和目标导向的合作伙伴仍是一个重大挑战，尤其是在高风险领域。当前的方法要么仅优化单一回合的表现，要么依赖于脆弱且成本高昂的用户模拟器，这种做法造成了显著的“现实差距”。", "innovation": "本文提出了Learn-to-Ask，一种无需模拟器即可直接从离线专家数据学习和部署前瞻性对话代理的一般框架。这一方法通过利用每个专家轨迹的观察未来来重新定义离线策略学习问题，从而推断出以专家策略为基础的密集、每回合的奖励信号，将难以解决的长期问题分解为一系列监督学习任务，并训练一个策略以输出结构化的（action, state_assessment）元组，管理“何时提问”和“何时停止”。为了确保奖励的真实度，自动评分校准流水线系统地清除了LLM基奖励模型中的噪声，几乎不需要人工监督。", "conclusion": "本文通过在实际医疗数据集上的实验证明，Learn-to-Ask在不同规模（至32B）的LLM上表现有效。研究结果表明，模型不仅在内部严格评估中优于人类专家，还在实际的大型在线AI服务中部署成功，证明了该框架能够将离线数据转化为实际影响。我们希望这项工作能够为将被动的大语言模型转化为行动导向的大语言模型提供一种可行的蓝图。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19030", "html_url": "https://arxiv.org/abs/2510.19030", "title": "Re:Member:从个人记忆中生成情感问题", "title_en": "Re:Member: Emotional Question Generation from Personal Memories", "authors": "Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg", "background": "该研究致力于探索情感表达和基于记忆的互动如何增强第二语言（L2）学习的吸引力。系统利用用户个人视频，生成目标语言中的个性化问题，旨在激发情感回忆和对话交流。系统通过情绪一致技术，利用各种情绪性语言风格，如细语或深夜语气，唤起特定的情绪环境。", "innovation": "该系统创新地结合了基于WhisperX的转录对齐、3帧视觉采样以及Style-BERT-VITS2进行情绪合成，构建了一个模块化的生成管道。它作为一种情感化的互动探针，强调了情感和个人媒体在以学生为中心的教育技术中的作用。", "conclusion": "Re:Member系统展示了情感和个性化的媒体在第二语言学习中的重要作用，为学习者创造了更加沉浸和互动的环境，促进了更高效的语言学习经验。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.09360", "html_url": "https://arxiv.org/abs/2509.09360", "title": "MetaRAG: 元测试在RAG系统中幻觉检测中的应用", "title_en": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "authors": "Channdeth Sok,David Luz,Yacine Haddam", "background": "大型语言模型（LLMs）在企业应用中越来越普遍，但由于存在幻觉问题，即模型生成自信但事实错误的信息，这限制了其可靠性。现有检测方法主要针对独立的LLMs，并不专门解决检索增强生成（RAG）系统中的独特挑战，即答案必须与检索到的证据保持一致。为了解决这一问题，本文提出了一种元测试框架MetaRAG，用于在RAG系统中检测幻觉.", "innovation": "MetaRAG是一个针对RAG系统的元测试框架，能够实现实时、无需监督、黑盒操作，无需使用真实参考或访问模型内部结构。为了应对RAG系统独有的挑战，该框架首先将答案拆分为原子事实片段，然后利用同义词和反义词替换生成控制性变异，接着验证每个变体与检索到的上下文是否一致（同义词通常要被包含，反义词则要被反驳），最后将不一致的处罚总结到回答级别，生成幻觉分数。MetaRAG可以通过标识包含不支持声明的事实片段来增强身份意识人工智能系统的安全性。该框架经过实验验证，证明了其对于检测幻觉和实现基于RAG的对话代理可信赖部署的有效性。", "conclusion": "实验结果表明，MetaRAG能够有效检测RAG系统中的幻觉，并支持可信部署。还提出了基于主题的部署设计，将MetaRAG的片段级得分转换为身份感知的安全防护措施，但这一设计并未在实验中进行评估。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16395", "html_url": "https://arxiv.org/abs/2502.16395", "title": "AIRepr：数据科学中LLMs可重复性评估的分析师-检查员框架", "title_en": "AIRepr: An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science", "authors": "Qiuhai Zeng,Claire Jin,Xinyue Wang,Yuhan Zheng,Qunhua Li", "background": "大型语言模型（LLMs）正在通过生成可执行代码来自动化数据分析。然而，数据科学任务通常可能有多种统计上有效的解决方案（例如，不同的建模策略），因此理解分析背后的推理比仅关注结果更为关键。人工审查LLMs生成的代码可以确保统计上的严谨性，但是一项劳动密集且需要专业知识的工作。为了应对这一挑战，本文提出了AIRepr框架，其目标是自动评估和改进LLMs生成的数据分析工作流程的可重复性。", "innovation": "本文创新性地提出了AIRepr，一种分析师-检查员框架，旨在自动评估和改进LLMs生成的数据分析工作流程的可重复性。该框架基于统计原则，支持大规模、自动化的评估，并引入了两种新颖的提高可重复性的提示策略，这些策略经过了与标准提示的基准测试。研究结果显示，具有更高可重复性的工作流程能更准确地产生分析结果，且提高可重复性的提示在双重视角上显著提升了性能。", "conclusion": "本文的工作为数据科学中透明、可靠和高效的AI与人类合作奠定了基础。该代码已经公开提供。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10816", "html_url": "https://arxiv.org/abs/2504.10816", "title": "CSPLADE：基于因果语言模型的Learned Sparse Retrieval", "title_en": "CSPLADE: Learned Sparse Retrieval with Causal Language Models", "authors": "Zhichao Xu,Aosong Feng,Yijun Tian,Haibo Ding,Lin Lee Cheong", "background": "近年来，密集检索成为信息检索（IR）研究的重点。尽管密集检索效果显著，但会产生不可解释的密集向量，并且索引大小庞大。Learned Sparse Retrieval (LSR) 已经成为一种有前景的替代方法，在实现竞争的检索性能的同时，还能利用经典的倒排索引数据结构进行高效检索。然而，目前关于在超大规模语言模型（如BERT）规模上扩展LSR的研究却很少。", "innovation": "本文识别了使用大规模语言模型（LLM）进行LSR训练中的两个挑战：（1）对比训练早期阶段的训练不稳定性；（2）由于预训练LLM的单向注意力导致的性能不足。为解决这些挑战，提出两个相应的技术：（1）轻量级调整训练阶段以消除训练不稳定性；（2）两种模型变体以实现双向信息交换。通过这些技术，成功训练了8B级别的LLM，并且与减少了索引大小的同时实现了竞争的检索性能。另外，本文是首次从模型量化角度分析LLM基础上的LSR模型的性能-效率权衡。", "conclusion": "本文的研究为我们理解和应用大规模语言模型进行高效检索模型设计提供了新的见解。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23994", "html_url": "https://arxiv.org/abs/2509.23994", "title": "Policy-as-Prompt: 将AI治理规则转化为AI代理的护栏", "title_en": "Policy-as-Prompt: Turning AI Governance Rules into Guardrails for AI Agents", "authors": "Gauri Kholkar,Ratinder Ahuja", "background": "随着自主人工智能（AI）代理在受监管和安全性关键的应用场景中得到使用，组织需要找到有效的方法将政策转化为可实施的控制措施。现有的方法难以处理复杂的非结构化设计文档（如产品要求文档PRDs、测试设计文档TDDs和代码），也无法确保在运行时提供验证性的安全护栏。", "innovation": "本文介绍了一种监管机器学习框架，能够将这些非结构化的设计文档转化为运行时可验证的安全护栏。该方法通过阅读文档和风险管理控制生成源代码链接的政策树，并将该树编译为运行时实时监控的轻量级、基于提示的分类器。该系统设计为确保最小权限和数据最小化，提供完整的可追溯性、可追踪性和审计日志，并与人工在环审核过程集成，从而减少漏洞注入风险，阻止超出范围的请求，并限制有毒输出，同时生成符合AI治理框架的可审理性理由。此外，这是一种将政策作为可执行提示的方法（代理的政策为代码），使得安全设计、持续合规、可扩展的AI安全和AI安全保证成为可能。", "conclusion": "这种通过将政策转化为可执行的提示的方法确保了安全设计、持续合规、并提高了可扩展的AI安全和AI安全保证。该系统为可监管的机器学习提供了实际的应用场景，展示了其在实际中的强大效果。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17902", "html_url": "https://arxiv.org/abs/2504.17902", "title": "TRACE: 文本相关性增强和上下文编码用于多模态仇恨检测", "title_en": "TRACE: Textual Relevance Augmentation and Contextual Encoding for Multimodal Hate Detection", "authors": "Girish A. Koushik,Helen Treharne,Aditya Joshi,Diptesh Kanojia", "background": "社交媒体表情包是仇恨检测的一个挑战领域，因为它们将视觉和文本线索交织在文化上微妙的信息中。", "innovation": "引入了名为TRACE的分层多模态框架，该框架利用视觉支持的上下文增强，结合一种新颖的图片说明评分网络来强调仇恨相关信息，并采用参数高效的CLIP文本编码微调。实验表明，选择性微调深层文本编码层显著提高了性能，与简单的投影层微调方法相比。我们的框架在广泛使用的Hateful Memes数据集上达到了最先进的准确率(0.807)和F1分数(0.806)，并且在维持效率的同时，其性能接近于较大的模型。此外，它在多OFF攻击性表情包数据集上实现了更优的一般化(F1分数0.673)，突显了其在表情包类别上的鲁棒性。", "conclusion": "额外的分析证实，稳健的视觉接地和精致的文本表示显著减少了由良性干扰引起的错误。我们将代码公开以促进未来的研究。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13438", "html_url": "https://arxiv.org/abs/2505.13438", "title": "通过预算相对策略优化优化任意时间推理", "title_en": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization", "authors": "Penghui Qi,Zichen Liu,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "增强大型语言模型（LLMs）的推理能力需要扩展推理时的计算规模。现有方法通常使用强化学习（RL）来最大化在推理轨迹结束时获得的可验证奖励。然而，这些方法只能优化在大型且固定的标记预算下的最终性能，这在训练和部署效率上都受到了阻碍。", "innovation": "我们提出了一个全新的框架，AnytimeReasoner，以优化任意时间推理性能。该框架旨在提高标记效率和在不同标记预算约束下的推理灵活性。通过截断完整的思维过程以适应来自先验分布的样本标记预算，并迫使模型总结每次截断思维的最优答案进行验证，引入了推理过程中的可验证密集奖励，这有助于RL优化中的更有效因果归因。此外，我们还引入了一种新的方差减少技术—预算相对策略优化（BRPO），以提高当增强思维策略时学习过程的鲁棒性和效率。", "conclusion": "在数学推理任务中的实证结果显示，我们的方法在各种先验分布下的所有思维预算下，都一致地优于GRPO，提升了训练和标记效率。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.14245", "html_url": "https://arxiv.org/abs/2504.14245", "title": "使用多模态大型语言模型实现可解释的假图像检测", "title_en": "Towards Explainable Fake Image Detection with Multi-Modal Large Language Models", "authors": "Yikun Ji,Yan Hong,Jiahui Zhan,Haoxing Chen,jun lan,Huijia Zhu,Weiqiang Wang,Liqing Zhang,Jianfu Zhang", "background": "图像生成技术的进步引发了重大的公众安全问题。当前的假图像检测方法主要作为‘黑盒’工作，缺乏透明度。为了解决这一问题，研究者们提出了需要兼备良好的泛化能力和透明性的理想检测方法。近年来，多模态大型语言模型（MLLMs）的进步为基于推理的AI生成图像检测提供了新的机会。", "innovation": "本研究评估了MLLMs在图像检测任务中的能力，将其与传统检测方法和人工评估员进行对比，强调了MLLMs的优势与局限性。同时，设计了六种不同的提示并提出了一种框架，旨在开发出更加稳健、可解释且基于推理的检测系统。应用结果的代码可以在对应网站上找到。", "conclusion": "通过使用MLLMs，可以实现更高级的图像检测系统。该系统不仅能够提高检测性能，还能增强系统透明度，使得公众更容易理解检测过程和结果。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16470", "html_url": "https://arxiv.org/abs/2505.16470", "title": "用于文档问答的检索增强多模态生成基准测试", "title_en": "Benchmarking Retrieval-Augmented Multimodal Generation for Document Question Answering", "authors": "Kuicai Dong,Yujing Chang,Shijie Huang,Yasheng Wang,Ruiming Tang,Yong Liu", "background": "当前的文档视觉问答（DocVQA）面临双重挑战：处理长篇幅的多模态文档（文本、图像、表格）以及进行跨模态推理。现有方法主要关注文本，往往忽视关键的视觉信息。此外，评估多模态证据选择与整合的基准数据集缺乏坚固的基础。", "innovation": "该研究提出了MMDocRAG基准测试，包含4,055个专家标注的问题-答案对，其中涉及多页、跨模态的证据链。引入了新的评估多模态引用选择的指标，能够生成结合文本与相关视觉元素的答案。通过大规模实验（涉及60个视觉语言模型/大型语言模型和14个检索系统），明确了多模态证据检索、选择和整合的持续性挑战。研究发现，高级的专有视觉语言模型在性能上优于开源选项，且在使用多模态输入时表现优于纯文本输入。此外，微调的大型语言模型在使用详细的图像描述时取得了显著改进。", "conclusion": "MMDocRAG为多模态文档问答系统的发展提供了一个严格的测试平台和实际建议，基准和相关代码可在网上获取。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04479", "html_url": "https://arxiv.org/abs/2511.04479", "title": "ThaiOCRBench：泰语视觉语言理解任务多样基准", "title_en": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai", "authors": "Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul", "background": "尽管在多模态建模方面取得了显著进展，现有的基准测试主要集中在资源丰富语言上，泰语被严重忽视，特别是在需要文档结构理解的任务中。ThaiOCRBench填补了这一空白，提供了一个包含2808个样本、涵盖13类任务的人类注释数据集，旨在评估视觉语言模型（VLMs）在泰语图像中的表现。", "innovation": "ThaiOCRBench是第一个全面评估视觉语言模型在泰语丰富的视觉理解任务上的基准测试。它提供了一个广泛的任务和基于零样本的评估，对多种最先进的VLM进行了评估。", "conclusion": "ThaiOCRBench提供了一个标准化框架，用于评估视觉语言模型在低资源和书写系统复杂的设置中的表现，并指出关键挑战，如语言偏差、结构不匹配和虚假内容。这为提高泰语文档理解提供了行动指南。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05345", "html_url": "https://arxiv.org/abs/2506.05345", "title": "KV 缓存压缩实现推理时间超缩放", "title_en": "Inference-Time Hyper-Scaling with KV Cache Compression", "authors": "Adrian Łańcucki,Konrad Staniszewski,Piotr Nawrot,Edoardo M. Ponti", "background": "推理时的扩展会在效率与推理准确度之间进行权衡，通过生成更长或更并行的序列来增加推理准确度。然而，在基于Transformer的大型语言模型（LLM）中，生成成本主要受到关键值（KV）缓存大小的限制，而非生成的令牌数量。因此，本文探讨了推理时间超缩放：通过压缩KV缓存，能够在相同的计算预算内生成更多令牌，并进一步提高扩展推理的准确度。这一方法的成功关键在于压缩方法在高压缩比下仍然能够保持准确度。", "innovation": "本文提出了动态内存稀疏化（DMS），这是一种新型的KV缓存稀疏化方法，仅需1000训练步骤即可实现8倍压缩，同时保持比无训练稀疏注意更好的准确度。DMS通过延迟令牌的移除，隐式地合并表示并保留关键信息，从而避免提前丢弃缓存的令牌。", "conclusion": "通过在多种LLM模型上应用DMS，本文证明了推理时间超缩放的有效性，可以将在相似推理延迟和内存负载的情况下，提升准确度。例如，对于Qwen-R1 32B模型，分别在AIME 24、GPQA和LiveCodeBench上提升了12.0点、8.6点和9.7点的准确度，且等效的内存读取次数相等。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.08828", "html_url": "https://arxiv.org/abs/2501.08828", "title": "MMDocIR：长文档多模态检索基准", "title_en": "MMDocIR: Benchmarking Multimodal Retrieval for Long Documents", "authors": "Kuicai Dong,Yujing Chang,Xin Deik Goh,Dexun Li,Ruiming Tang,Yong Liu", "background": "多模态文档检索旨在从大量文档中识别和检索各种形式的多媒体内容，如图表、表格和布局信息。尽管该领域越来越受到关注，但仍缺乏一个全面且坚固的基准来有效评估此类任务中系统的性能。为了填补这一空白，本文引入了一个新的基准MMDocIR，涵盖了两个不同的任务：页面级检索和布局级检索。前者评估识别长文档中最相关页面的表现，后者则评估检测特定布局的能力，提供了比整个页面分析更精细的度量标准。MMDocIR基准数据集包括1,685个由专家标注的问题以及173,843个通过自助标注的方法生成的问题，使其成为多模态文档检索领域训练和评估的重要资源。", "innovation": "本文提出了一个新的名为MMDocIR的多模态文档检索基准。它引入了两个不同级别的检索任务：页面级和布局级。它拥有1,685个专家标注的问题和173,843个通过自助标注生成的问题，这些数量使得MMDocIR成为评估多模态文档检索系统性能的重要资源。通过实验证明，视觉检索器显著优于文本检索器，MMDocIR训练集能够有效提升多模态文档检索的性能，而且利用VLM文本的文本检索器表现优于依赖OCR文本的检索器。", "conclusion": "通过严苛的实验，本文证明了视觉检索器显著优于文本检索器，MMDocIR训练集的有效性，以及利用VLM文本的文本检索器相较于依赖OCR文本的检索器具有更好的表现。MMDocIR基准数据集可以在这里下载: this https URL"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.13142", "html_url": "https://arxiv.org/abs/2508.13142", "title": "全面评估多模态大语言模型在空间智能上的表现", "title_en": "Holistic Evaluation of Multimodal LLMs on Spatial Intelligence", "authors": "Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Oscar Qian,Hui En Pang,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang", "background": "近年来，多模态模型在许多任务上取得了显著进展，但它们在空间理解和推理方面依然存在明显不足。这与实现物理世界中的人工通用智能密切相关。随着GPT-5的发布，这是一次检查当前领先模型（GPT、Gemini、Grok、Seed、Qwen、Intern）在空间智能发展中所处地位的好时机。因此，我们提出了EASI方法，用于全面评估多模态大语言模型的空间智能。EASI提供了一个全面的空间任务分类体系，统一了现有的基准和一套标准化的公平评估协议，研究跨越了八个关键基准，总共消耗超过十亿个标记量的实验数据。", "innovation": "提出了EASI方法，用于全面评估多模态大语言模型的空间智能。EASI提供了一个全面的空间任务分类体系，统一了现有的基准和一套标准化的公平评估协议。研究结果显示GPT-5在空间智能方面表现出前所未有的强项，但在广泛的空间任务中仍然显著低于人类表现水平。此外，空间任务揭示了更大的模型能力缺陷，即使是商业化的模型在最困难的任务中也未表现出压倒性优势。", "conclusion": "虽然GPT-5在空间智能方面表现出色，但在广泛的空间任务中尚未超过人类表现。空间任务使模型能力缺陷更加明显，即使是最具竞争力的封闭源模型在最困难的任务上也没有显著优势。此外，即使在直观于人类的场景中，最先进的多模态模型仍然失败了。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15252", "html_url": "https://arxiv.org/abs/2508.15252", "title": "为灌注型推荐系统检索增强的评论生成", "title_en": "Retrieval-Augmented Review Generation for Poisoning Recommender Systems", "authors": "Shiyi Yang,Xinshu Li,Guanglin Zhou,Chen Wang,Xiwei Xu,Liming Zhu,Lina Yao", "background": "近年来的研究表明，推荐系统（RSs）极易受到数据中毒攻击的影响，攻击者通过注入伪造的用户资料，包括一组精心设计的假评分，来操控推荐结果。由于实际中安全性与隐私的限制，攻击者通常对受害者系统缺乏详细了解，因此需要创建能够在黑箱推荐系统中通用的伪装良好的伪造资料。为了最大化攻击效果，这些资料往往保持不可察觉。然而，在资源受限的情况下生成高质量的伪装资料相当具有挑战性。部分研究建议通过结合假文本评论来增强资料效果；但在实际设置中，评论质量差极大地削弱了攻击效果和不可察觉性。 ", "innovation": "本文提出了一种名为RAGAN的新型实际攻击框架，通过利用多模态基础模型的上下文学习能力增强评论文本质量。为此，本文引入了演示检索算法和文本风格迁移策略来增强朴素的上下文学习。具体而言，生成高质量的伪造用户资料的过程由释放者进行，然后通过指导智能体和守护程序协作优化，以提升攻击在不同推荐系统中的转移能力和不可察觉性。", "conclusion": "全面实验表明，RAGAN在各种真实世界数据集上的恶性攻击性能达到最佳。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10751", "html_url": "https://arxiv.org/abs/2506.10751", "title": "Neural在ArchEHR-QA 2025：具有证据支持的临床问答中的自主提示优化", "title_en": "Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering", "authors": "Sai Prasanna Teja Reddy Bogireddy,Abrar Majeedi,Viswanatha Reddy Gajjala,Zhuoyan Xu,Siddhant Rai,Vaishnav Potlapalli", "background": "电子健康记录(EHRs)中的自动化问题回答(QA)能够填补临床医生和患者的关键信息缺口，但这就需要在有限的监督下进行准确的证据检索和忠实的问答生成。为此，神经网络(AI)模型必须在证据支持和答案合成之间找到平衡。尽管已有不少方法尝试解决这个问题，但还没有一种能够同时具备高精度和高效能的方法，特别是在临床这种高风险的场景下，这种方法显得尤为重要。因此，本次研究旨在探索一种数据驱动的提示优化方法，以解决数据不足和监督有限的问题，并且能够在保持精度的同时提高召回率。", "innovation": "本研究创新性地提出了一种自主提示优化方法，这种方法被称为DSPy的MIPROv2优化器，用于临床问答任务中证据的支持和答案的合成。这种方法通过自动探索提示空间，并在发展集上联合调优指令和少量的示例，从而进一步提高答案的召回率而不牺牲其准确性。实验证明，这种数据驱动的方法在隐藏测试集中达到了51.5的综合得分，明显优于标准的零样本和少量样本提示方法，这表明即使是非专业样本和少量监督数据也能取得良好的效果，这对于临床QA来说尤为重要。这项研究为利用有限的数据资源进行高风险临床应用提供了新的思路，并有效保证了AI辅助工具在健康医疗领域的可靠性。", "conclusion": "通过这种数据驱动的提示优化方法，表明可以通过成本更低的手段（不涉及模型微调）实现高精度的临床QA，这种方法不仅节省了时间和资源，还在保持高质量回答的同时提高了效率。这一成果为AI助理在临床领域的可靠性提升提供了有力支持，并推动了相关技术的发展。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04391", "html_url": "https://arxiv.org/abs/2510.04391", "title": "认知代理中的内部世界模型作为想象网络", "title_en": "Internal World Models as Imagination Networks in Cognitive Agents", "authors": "Saurabh Ranjan,Brian Odegaard", "background": "传统观点认为想象对于最大化奖励是有用的，但近期发现挑战了这一观点。本研究通过心理网络分析探索人类和大型语言模型（LLMs）中的内部世界模型（IWM），旨在了解想象的功能。", "innovation": "提出想象是一种访问内部世界模型的手段，并通过心理网络分析比较了人类和LLMs的内部网络。通过评估想象生动性，建立了想象网络，并发现了不同群体间的不同中心性指标间的相关性，而LLMs则显示出较低的聚集性和较低的相关性。", "conclusion": "研究表明，人类和LLMs中的内部世界模型缺乏相似性。这提供了人类和AI内部生成表征之间比较的新方法，为进一步开发类似人类的想象提供了见解。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03505", "html_url": "https://arxiv.org/abs/2509.03505", "title": "LimiX: 解锁通用智能的结构化数据建模能力", "title_en": "LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence", "authors": "Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui", "background": "本文认为，通用智能的进步需要语言、物理世界和结构化数据三方面的基础模型的支持。该报告介绍了LimiX-16M和LimiX-2M，这两种大型结构化数据模型的实例。这些模型通过对结构化数据进行联合分布建模，并通过查询驱动的方式来预测条件概率，适用于广泛的表格任务。", "innovation": "LimiX模型使用掩蔽联合分布预训练，并且在推断时能够快速适应，避免了特定任务的架构或特殊训练。LimiX-2M在计算和内存资源有限的情况下也能取得很好的效果。研究还首次揭示了LDMs的数据和模型扩展对下游性能的影响规律，为表格基础建模提供了定量指导。", "conclusion": "LimiX-16M和LimiX-2M在多个大规模结构化数据基准测试中表现优异，尤其是在分类、回归、缺失值填充和数据生成等多个任务上超过了强基准模型，展示了通用智能在结构化数据处理中的潜力。所有LimiX模型均在Apache 2.0许可下公开可用。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04727", "html_url": "https://arxiv.org/abs/2511.04727", "title": "IndicVisionBench: 评估VLMs在文化和多语言理解方面的基准", "title_en": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "authors": "Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal", "background": "现有的视觉语言模型（VLMs）在多模态任务中表现出色，但由于大多数评价基准仍以西方为中心，这引发了关于它们在文化多样性和多语言环境中的表现的疑问。", "innovation": "1. 提出了第一个专注于印度次大陆的大型基准——IndicVisionBench；2. 包含英语和10种印度语言的多模态任务；3. 包含光学字符识别（OCR）、多模态机器翻译（MMT）和视觉问答（VQA）等多种任务；4. 针对13个文化背景主题提供约5000张图像和超过37000对问答（QA）；5. 释放了10种印度语言的配对平行注释语料库，以分析VLMs中的文化和语言偏见。", "conclusion": "IndicVisionBench 提供了一个可复现的评价框架，为更具包容性的多模态研究铺平了道路，揭示了现有VLMs在文化多样性背景下的局限性。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22780", "html_url": "https://arxiv.org/abs/2510.22780", "title": "AI代理如何进行人类工作？跨多种职业比较AI和人类工作流程", "title_en": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations", "authors": "Zora Zhiruo Wang,Yijia Shao,Omar Shaikh,Daniel Fried,Graham Neubig,Diyi Yang", "background": "AI代理在软件工程和专业写作等与人类工作相关的任务中不断优化，这预示着对人类劳动力有重大影响的趋势。但这些代理的发展往往没有基于对人类如何执行工作的清晰理解，无法揭示代理所具备的专业知识以及它们在不同工作流程中所扮演的角色。本研究旨在通过比较人类和代理在数据分析、工程、计算、写作和设计等关键工作能力上的表现，来研究代理如何进行人类工作。为了更好地理解和比较工人的异构计算机使用活动，研究引入了可扩展的工具包，以从人类或代理的计算机使用活动中诱导出可解释、结构化的流程。研究发现，尽管代理在与人类工作流程的一致性方面表现出潜力，但在所有工作领域中仍然采取了非常程序化的方法，即使对于视觉依赖性较强的任务如设计也是如此。代理生成的工作质量较差，但通常通过数据造假和滥用高级工具来掩盖这些缺陷。然而，代理完成任务的速度比人类快88.3%，成本可低至90.4%-96.2%，这突显出通过将容易编程的任务委托给代理来实现高效协作的潜力。", "innovation": "引入了可扩展的工具包来诱导出可解释、结构化的流程，从而能够更好地理解和比较工人的异构计算机使用活动。通过这种方法，研究能够揭示代理和人类在不同工作能力上的表现差异。", "conclusion": "尽管代理在与人类工作流程一致性方面表现出潜力，但在所有工作领域中仍采取了程序化的方法，代理生成的工作质量较差，但速度更快且成本更低，突显了代理在执行可编程任务时的高效性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04773", "html_url": "https://arxiv.org/abs/2511.04773", "title": "全球热带气旋及云量三维重构", "title_en": "Global 3D Reconstruction of Clouds & Tropical Cyclones", "authors": "Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay", "background": "准确预测热带气旋（TCs）仍然具有挑战性，主要因为卫星观测有限且难以解析影响TC强度的云体特性。虽然机器学习方法已在三维云重构方面显示出潜力，但现有方法主要适用于罕见TC的地区，且在强风暴验证上表现不佳。", "innovation": "这篇论文提出了一种基于预训练-微调流程的新框架，该框架可以从具有全球覆盖的多颗卫星中学习，将二维卫星 imagery 转化为三维云图。该模型首次能够在全球范围内生成瞬时三维云图，并准确重构强风暴的三维结构。该方法不仅扩展了可用的卫星观测数据，还能够在完全缺乏观测数据的情况下提供估算，对于理解TC加强机制和提高预报具有重要意义。", "conclusion": "该工作展示了全球范围内创建即时三维云图并准确重构强风暴3D结构的能力。该模型的引入既扩展了可用的卫星观测数据，又在缺乏观测数据的情况下提供了估算，对于推动对TC加强机制的理解和改进预报具有关键作用。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04779", "html_url": "https://arxiv.org/abs/2511.04779", "title": "EETnet：用于智能眼镜的眼动检测和跟踪的CNN", "title_en": "EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear", "authors": "Andrea Aspesi(1 and 2),Andrea Simpsi(1),Aaron Tognoli(1),Simone Mentasti(1),Luca Merigo(2),Matteo Matteucci(1) ((1) Department of Electronics, Information and Bioengineering (DEIB) Politecnico di Milano, (2) EssilorLuxottica)", "background": "基于事件的相机正成为一种高效的、低功耗的眼动追踪解决方案。由于事件数据的稀疏性和异步性，它们需要更少的处理能力和超低的延迟（微秒级别）。然而，许多现有的解决方案仅限于在强大的GPU上进行验证，未在实际嵌入式设备上部署。", "innovation": "本文介绍了一种名为EETnet的卷积神经网络，专门用于使用纯粹的基于事件的数据进行眼动追踪，并能够在具有有限资源的微控制器上运行。此外，该论文提出了一种训练、评估和量化网络的方法，并使用公共数据集进行演示。论文还提出了两种架构版本：一种分类模型在原始图像上叠加网格以检测瞳孔，另一种回归模型在像素级别操作。", "conclusion": "最终，证明了EETnet架构在使用基于事件的数据进行眼动追踪方面的能力，并且能够在资源有限的设备上运行，克服了现有的眼动追踪解决方案在嵌入式设备上应用的限制。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04766", "html_url": "https://arxiv.org/abs/2511.04766", "title": "DARN: 动态自适应正则网络增强基础模型的高效和鲁棒适应", "title_en": "DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation", "authors": "Dhenenjay Yadav,Rohan Sawai", "background": "基金会模型（FMs）为地理空间分析提供了强大的表示能力，但如何有效地适应它们仍然具有挑战性。标准的适应方法，无论是完整的微调还是高效冻结主干的方法，通常采用固定正则化策略的解码器，未能考虑到卫星图像中的显著异质性。", "innovation": "介绍了一种名为DARN的新颖解码器架构，旨在解决这一局限性。DARN 结合了三种关键创新：（1）一个轻量级任务复杂度预测器（TCP），用于估计每个样本的难度；（2）自适应dropout调制 (ADM)，根据预测的复杂度动态调整dropout率（从0.1到0.5）；（3）动态容量门控 (DCG)，调节通道激活。DARN 的优化与稳定点收敛相关联，并且其机制与自适应信息瓶颈相关联。", "conclusion": "在全微调（未冻结主干）情况下，DARN 在多任务的GeoBench基准测试上取得了新的最先进的性能（86.66% mIoU，相对于先前SOTA +5.56%）。在高效适应（冻结主干）情况下，DARN 营业取得与顶级竞争的准确率（90.5% mIoU在Sen1Floods11上），同时为实际部署提供了重要的优势：超出了分布外（OOD）泛化能力（+9.5% mIoU，针对AI4SmallFarms），增强的鲁棒性（相对减少17%的错误率），以及改进的小众类别性能。DARN 提供了一种更智能、更鲁棒、更高效的对 FM 在关键的地理空间应用中进行利用的方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04729", "html_url": "https://arxiv.org/abs/2511.04729", "title": "基于知识的异常检测方法以识别网络诱导的形状异常", "title_en": "Knowledge-based anomaly detection for identifying network-induced shape artifacts", "authors": "Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki", "background": "合成数据为解决训练机器学习模型时的数据稀缺问题提供了一种前景广阔的方法，但在未经适当质量评估的情况下采用这种合成数据可能会引入假象、失真和不现实的特征，从而影响模型性能和临床价值。", "innovation": "该工作提出了一种新颖的知识驱动的异常检测方法，用于检测合成图像中的网络诱导的形状异常。该方法采用了两阶段框架，包括（i）一种新型的特征提取器，通过分析沿解剖边界的角度梯度的图像内分布来构建专门的特征空间，和（ii）基于隔离森林的异常检测器。该方法的有效性通过在CSAW-M和VinDr-Mammo患者数据集上训练的两种合成乳腺成像数据集得到了验证。", "conclusion": "该方法为负责任使用合成数据做出了贡献，使开发人员能够评估合成图像以满足已知的解剖约束，并能具体发现并解决特定问题以提高合成数据集的整体质量。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15144", "html_url": "https://arxiv.org/abs/2510.15144", "title": "HugAgent：衡量大型语言模型个体化人类推理模拟的基准", "title_en": "HugAgent: Benchmarking LLMs for Simulation of Individualized Human Reasoning", "authors": "Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson", "background": "长期以来，人工智能和认知科学的核心目标之一是模拟人类在开放任务中的推理过程。尽管大规模语言模型在很大程度上近似人类的回答，但它们仍然被调校为群体共识，往往会抹去推理风格和信念轨迹的个别性。为了实现更接近人类的机器推理愿景，本文提出了HugAgent（Human-Grounded Agent Benchmark）基准测试，重新定义了人类推理模拟的三个维度：（i）从平均化的推理到个别的推理，（ii）从行为模仿到认知对齐，（iii）从情景案例到开放性数据。基准测试评估模型在给定部分证据的情况下，能否预测特定个体的出乎其分布范围的反应和潜在的推理动态。", "innovation": "HugAgent 基准测试采用两轨设计：人电轨来自动化和扩大心声法以收集生态有效的人类推理数据，合成轨以进一步扩大规模并进行系统压力测试。这种架构允许低成本、可扩展地扩展到新的任务和人群。实验证明最先进的语言模型存在持续的适应性差距，使HugAgent成为第一个可用于对齐机器推理与人类思想个别性的可扩展基准。基准测试连同其完整的数据收集管道和同伴聊天机器人已开源（参考链接）", "conclusion": "HugAgent为衡量机器推理与人类个体思维之间的对齐提供了一个可扩展的基准，能够预测特定个体在给定部分证据范围外的反应和潜在的推理动态，从而定位了机器推理在个体化人类思维方面的差距。通过开源其数据收集管道和聊天机器人，HugAgent旨在促进对该领域的进一步研究和对齐工作。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04797", "html_url": "https://arxiv.org/abs/2511.04797", "title": "3D Gaussian Point Encoders", "title_en": "3D Gaussian Point Encoders", "authors": "Jim James,Ben Wilson,Simon Lucey,James Hays", "background": "该论文介绍了3D高斯点编码器，这是一种基于学习的3D高斯混合的显式点嵌入方法。与PointNet等广泛使用的隐式表示不同，3D高斯点编码器提供了一种新的几何表示方法，用于3D识别任务。然而，由于难以用标准优化器以端到端的方式学习3D高斯编码器，因此开发了基于自然梯度和从PointNet提炼的技术来找到一个能够重构PointNet激活的高斯基。这种方法提高了速度并减少了参数数量。随着3D重构文献中从隐式表示（如NeRF）转变为显式表示（如高斯斑点化）的显著兴趣，计算几何启发可以帮助进一步加速3D高斯点编码器。滤波技术被从3D高斯斑点化扩展到构建运行速度提高了2.7倍，同时相比同等准确度的PointNet使用更少内存和FLOPs的编码器。在Mamba3D中，3D高斯点编码器作为一个组件运行速度提升了1.27倍，分别减少了42%和54%的内存和FLOPs。3D高斯点编码器轻巧到可以在仅CPU设备上实现高帧率。", "innovation": "本文的创新点在于提出了一种新的3D高斯点编码器，它提供了一种显式的3D几何表示方法，有效解决了传统方法如PointNet存在的问题。通过引入基于自然梯度和从PointNet提炼的技术，设计出高效且参数精简的3D高斯点编码器。此外，通过改进从3D高斯斑点化继承的滤波技术，进一步加速了3D高斯点编码器，实现了在保持良好性能的同时更节省资源。这种方法在CPU设备上也表现出良好的性能，有助于提升整体运行效率。", "conclusion": "3D高斯点编码器为3D识别任务提供了一种显式的几何表示方法，相比传统的PointNet，它在速度和参数效率上都有显著提高。这些改进的3D高斯点编码器不仅适用于单一的3D点云处理任务，还能作为Mamba3D的组件在整个系统中显著加速，并在减小资源开销的同时保持精度。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04848", "html_url": "https://arxiv.org/abs/2511.04848", "title": "使用优选法向量的几何去噪", "title_en": "Geometry Denoising with Preferred Normal Vectors", "authors": "Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt", "background": "当前的几何去噪方法大多依赖于对原始几何数据的直接处理，缺乏对表面法向量的先验知识利用。本文通过引入表面法向量的先验知识来改进几何去噪的方法，将分割问题自然嵌入到去噪过程中，基于法向量与给定的标签向量集的相似性进行分割，并通过总变差项实现正则化，从而提出了一种新的去噪范式。", "innovation": "本文提出了一个全新的几何去噪范式，使用了关于表面法向量的先验知识，通过将分割问题嵌入到去噪过程中，基于法向量与给定标签向量集的相似性进行分割，并采用总变差项实现正则化。此外，通过引入分割过程和优化问题的求解方法（ADMM），提出了一种基于二阶形状微积分的顶点更新步骤，从而提高了去噪效果和效率。", "conclusion": "本文通过将分割问题嵌入到几何去噪过程，并利用表面法向量的先验知识，提出了一种新的优化框架。实验结果表明，这种新方法在噪声去除和保持几何形状方面表现出色，为几何处理提供了新的视角和方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04871", "html_url": "https://arxiv.org/abs/2511.04871", "title": "Clinical-ComBAT: 一种用于临床应用的弥散加权MRI谐波方法", "title_en": "Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications", "authors": "Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin", "background": "弥散加权磁共振成像（DW-MRI）衍生的标量图在评估多种脑部疾病的神经退行性和白质微结构特性方面非常有效。然而，DW-MRI固有限制了来自多个采集站点的数据组合，除非进行校准以减轻扫描仪器特有的偏差。尽管ComBAT方法减少了研究中的站点效应，但其依赖于线性共变量关系、同质人群、固定站点数量和人口充足的站点，这限制了其在临床中的应用。", "innovation": "为了克服上述限制，我们提出了用于临床场景的Clinical-ComBAT方法。Clinical-ComBAT允许站点独立地进行谐波处理，提供灵活性以适应新数据和新的医疗机构的引入。该方法包含非线性多项式数据模型、以同常Argsite为参考的站点特定谐波处理、适用于小样本群体的方差先验，并包括超参数调优和归纳契合度度量以评估谐波处理效果。", "conclusion": "我们展示了Clinical-ComBAT在模拟和真实数据上的有效性，表明该方法能够更好地对弥散指标进行对齐，并且增强了用于规范建模的适用性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04803", "html_url": "https://arxiv.org/abs/2511.04803", "title": "生物医学图像分割中的数据效率与传输稳健性：Cellpose中冗余性和遗忘现象的研究", "title_en": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "authors": "Shuo Zhao,Jianxu Chen", "background": "通用的生物医学图像分割模型如Cellpose被广泛应用于多种成像技术和细胞类型。然而，两个关键挑战仍然未被充分探索：(1) 数据重复的范围和(2) 在跨域传输中模型保持性能的局限性。这项研究以Cellpose为案例，进行了一系列系统的实验分析，着重探讨这两个问题。通过提出一种简单的数据集量化（DQ）策略，研究展示了即使是使用整个数据集的10%，图像分割性能也能达到饱和状态，揭示了大量数据冗余和使用少量注解进行训练的潜力。同时，跨域微调实验显示了源域性能的显著下降，尤其是在从通用到专业领域转移时更为明显。研究发现了选择性DQ回放可以有效恢复源领域性能，而完整的回放可能阻碍目标领域的适应。此外，训练领域排序在多阶段传输中提高了泛化能力并减少了遗忘现象。这些发现强调了生物医学图像分割中数据为中心的设计的重要性，并表明高效的训练不仅需要紧凑的子集，还需要以遗忘为考量的训练策略以及合理领域的排序。", "innovation": "1. 提出了一种简单的数据集量化（DQ）策略，构建了一个紧凑而多样的训练子集；\n2. 通过跨域微调实验观察了通用到专业领域的性能下降，从中筛选出有效的回放策略，选择性地回放仅5-10%的源数据即可有效恢复源性能；\n3. 发现了训练领域排序可以提高泛化能力和降低遗忘现象，有效地指导数据驱动的设计策略及领域排序方法。", "conclusion": "本研究揭示了数据重复程度和遗忘现象在生物医学图像分割中的重要影响，强调了以数据为中心的设计策略和遗忘为考量的训练策略的必要性。未来工作将深入推进这些发现的应用，提升生物医学图像分割模型的效率和稳健性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04872", "html_url": "https://arxiv.org/abs/2511.04872", "title": "验证视觉变换器在耳镜检查中的表现及其数据泄露影响", "title_en": "Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects", "authors": "James Ndubuisi,Fernando Auat,Marta Vallejo", "background": "在耳科专家中，诊断耳部疾病时出现的误诊率高达27%，因此提高诊断准确性至关重要。本研究使用了智利大学临床医院耳鼻喉科的真实数据集，包括耳镜视频和多处耳部状况的记录。利用Swin v1和Swin v2模型分别取得了100%和99.1%的准确率，而ResNet模型则为99.5%，这超过了之前相关研究的记录。然而，研究发现数据预处理过程中的数据泄露问题严重影响了模型表现，尤其是在实现准确率下降至83%至82%之后，强调了严格数据处理在医疗应用中的重要性。", "innovation": "研究评估了视觉变换器（特别是Swin Transformers）模型在耳部疾病诊断中的有效性，与传统的卷积神经网络相比。提出的方法不仅探讨了Swin v1和Swin v2的表现，还揭示了数据泄露问题对模型性能的影响，强调了数据处理的重要性。", "conclusion": "虽然视觉变换器模型表现出良好性能，但数据预处理中的数据泄露问题大大降低了模型的准确性。这表明在医疗应用中，需要在高级模型结构的好处和有效数据预处理带来的好处之间找到最佳平衡，以开发可靠的耳病诊断机器学习模型。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04920", "html_url": "https://arxiv.org/abs/2511.04920", "title": "通过组件解耦和任务感知路径适应学习恢复多退化图片", "title_en": "Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation", "authors": "Hu Gao,Xiaoning Lei,Ying Zhang,Xichen Xu,Guannan Jiang,Lizhuang Ma", "background": "图像恢复（IR）旨在从退化的观测数据中恢复清晰的图像。尽管取得了显著进展，大多数现有方法仅针对单一退化类型，而现实世界中的图像往往同时遭受多种退化，如同一张图片上共存的雨、噪声和雾。这种局限性限制了它们的实际有效性。", "innovation": "本文提出了一种适应性多退化图像恢复网络（IMDNet），通过解耦退化成分的表示来引导路径选择，以恢复图像。具体而言，设计了一个编码器中的退化成分解耦块（DIDBlock），通过结合空域和频域信息统计解耦退化成分，增强对多种退化类型的识别，使它们的特征表示独立。此外，提出了一个融合块（FBlock），用于通过可学习矩阵在所有级别上融合退化信息。在解码器中，引入了一个任务适应块（TABlock），根据多退化表示动态激活或融合功能分支，灵活选择在不同退化条件下最优恢复路径。这些设计共同构建了一个紧密集成的架构，通过实验广泛验证，表明在多退化恢复方面表现优异，同时在单一退化任务上保持很强的竞争性。", "conclusion": "实验广泛验证了所提出的IMDNet架构，其在多退化恢复任务上表现出色，同时也保持了在单一退化任务上的强竞争力。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04811", "html_url": "https://arxiv.org/abs/2511.04811", "title": "基于最少人力干预的生物医学图像实例分割主动学习流水线", "title_en": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "authors": "Shuo Zhao,Yu Zhou,Jianxu Chen", "background": "生物医学图像分割对于精确结构识别和后续分析至关重要。传统方法在处理嘈杂数据时效果不佳，而深度学习模型如U-Net则在分割性能上取得了新的基准。nnU-Net进一步实现了模型配置自动化，使其能在无需大量调整的情况下跨数据集使用。然而，nnU-Net需要大量标注数据进行交叉验证，当只有原始图像而无标签可用时，会构成挑战。虽然大模型具有零样本泛化能力，但在特定具有独特特性的数据集上表现可能不佳，限制了它们在分析中的直接应用。", "innovation": "本文提出了一种以数据为中心的人工智能工作流程，结合了主动学习和伪标记技术，利用基础模型生成伪标签，用于nnU-Net的自我配置。选择代表性的核心集进行最少的手动注释，以有效微调nnU-Net模型。这种方法显著减少了手动注释的需求，同时保持了竞争力的性能，为生物医学研究人员提供了一种将最先进的AI技术应用于分割任务的可访问解决方案。", "conclusion": "该方法大幅减少了手动注释的需求，同时保持了竞争力的性能，提供了一种实用的解决方案，使得生物医学研究人员能够在其分割任务中应用最先进的AI技术。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04753", "html_url": "https://arxiv.org/abs/2511.04753", "title": "CPO: 条件偏好优化（Condition Preference Optimization）用于可控的图像生成", "title_en": "CPO: Condition Preference Optimization for Controllable Image Generation", "authors": "Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen", "background": "在文本生成图像的过程中，提升图像生成的可控性成为了一个关键任务。ControlNet引入了基于图像的控制信号以增强可控性，而ControlNet++则通过像素级的循环一致性提高了生成图像与输入控制信号的一致性。然而，由于在采样过程中进行反向传播的成本高昂，ControlNet++仅优化低噪声时间步（例如，t < 200），并引入了额外的近似误差。Direct Preference Optimization（DPO）作为一种简单的替代方案，试图通过直接优化所有时间步来提高可控性，但这种方法由于生成模型的不确定性，难以确保生成图像对仅仅在可控性上不同而不涉及其他因素的变化。为了解决这一问题，作者建议在控制条件而不是生成图像上进行偏好学习，提出了Condition Preference Optimization（CPO）的方法。这种方法可以消除混淆因素，提供一个低方差的训练目标，理论上对比DPO具有更低的对比损失方差，并且实验证明其在多种控制类型上表现更佳且需要较少的计算和存储资源用于数据集的构建。", "innovation": "Condition Preference Optimization（CPO）是一种新的方法，通过优化控制条件而不是生成图像，消除了混淆因素，提供了一个低方差的训练目标，理论上对比Direct Preference Optimization（DPO）具有更低的对比损失方差，并且实验结果证明其在多种控制类型上具有更佳的表现且需要较少的计算和存储资源用于数据集的构建。", "conclusion": "我们的方法CPO在不同类型（例如分割、人类姿态、边缘和深度图）上显著提高了可控性，实验结果显示在分割中误差率降低了超过10%，在人类姿态中大约提高了70-80%，并且在边缘和深度图上始终减少了2-5%的误差。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04948", "html_url": "https://arxiv.org/abs/2511.04948", "title": "用于大型视觉-语言模型的基准多模态口腔-牙科数据集", "title_en": "A benchmark multimodal oro-dental dataset for large vision-language models", "authors": "Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib", "background": "在口腔医疗领域，人工智能的进步依赖于能够捕捉临床实践复杂性的大规模多模态数据集。本文介绍了一个全面的多模态数据集，该数据集包含从2018年至2025年（共8年）收集的4800名患者的8775次牙科检查，涵盖了10至90岁年龄段的患者。数据集包括5万张口腔内照片、8056张放射图以及详细的文本记录，其中包括诊断、治疗计划和随访笔记。数据在标准伦理准则下收集并进行了标注，用于基准测试。", "innovation": "本文介绍了一个用于大型视觉-语言模型的新数据集。该数据集包含了8775次牙科检查，包含口腔内照片、放射图和详细文本记录。研究团队使用Qwen-VL 3B和7B这两个最先进的大型视觉-语言模型进行了微调，并在两个任务（六种口腔-牙科异常分类和从多模态输入生成完整的诊断报告）中进行了评估，显示出显著的性能提升，验证了数据集的有效性，并强调了其在推动AI驱动的口腔-牙科医疗解决方案方面的重要性。", "conclusion": "本数据集公开可用，旨在为未来AI牙科领域的研究提供关键资源。同时，已经证明该数据集可以有效推进口腔-牙科领域的AI驱动解决方案的发展。"}
{"llm_update_time": "20251111", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03222", "html_url": "https://arxiv.org/abs/2510.03222", "title": "低概率标记维持可验证奖励下的强化学习中的探索", "title_en": "Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward", "authors": "Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou", "background": "强化学习与验证奖励（RLVR）已经在复杂推理中推动了大型语言模型，但其可扩展性受到训练瓶颈的阻碍，即当策略熵坍缩导致性能停滞，表明探索的丧失。虽然之前的许多方法通过保持高策略熵来解决这个问题，但对有意义的探索机制的具体控制仍然欠缺。研究发现，无选择地关注熵可能会放大无关标记并导致训练不稳定。本研究调查了RLVR中的探索动态，并揭示了一个关键问题：逐渐消除了有价值的低概率探索标记，我们称之为“推理火花”。这些标记在预训练模型中丰富，但在RLVR过程中系统地被熄灭，导致探索的衰退。", "innovation": "该研究引入了低概率正则化（Lp-Reg）机制，通过调节政策来朝向一个基于启发式代理分布。该代理通过过滤出假定为噪声的标记并重新归一化剩余候选的分布构建。结果是一个减少噪音的代理，其中“推理火花”的概率被放大，进而作为一个Kullback-Leibler（KL）散度的软正则化目标，以保护这些有价值的标记免于被消除。实验表明，Lp-Reg能够实现稳定的策略性强化学习，在3000次训练步和81,204 GPU小时内持续扩展，这超过了基线方法。这种持续的探索推动了最佳性能，平均准确率达到60.17%，比以前的方法提高了2.66%。", "conclusion": "该方法通过Lp-Reg机制，使强化学习在长时间和高计算资源消耗下的性能维持在较高水平，显著改善了传统的熵控制方法。这一发现对于增强大型语言模型在复杂推理和可验证奖励环境中的长期探索能力具有重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04864", "html_url": "https://arxiv.org/abs/2511.04864", "title": "自监督隐式注意力先验用于点云重构", "title_en": "Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction", "authors": "Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli", "background": "从不规则点云中恢复高质量表面通常具有病态性，除非可获得强大的几何先验条件。作者提出了一种内含自先验的方法，直接从输入点云中提取特征特定的先验信息，并将其嵌入到隐式神经表示中。", "innovation": "该方法通过共同训练可学习的嵌入字典和隐式距离场，实现跨注意机制，使得网络能够捕捉和重用形状固有的重复结构和长程相关性。该方法仅通过自监督的点云重构损失进行优化，不依赖任何外部训练数据。通过自适应采样和自动微分提取密集点和分析法线，将结果点云和法线集成到鲁棒隐式移动最小二乘法（RIMLS）形式中，从而有效地整合先验信息并保留输入保真度。", "conclusion": "实验表明，该方法在生成高质量表面时优于经典的和基于学习的方法，能够更精确地保留细微的几何细节，并对常见的数据退化表现出更强的鲁棒性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04886", "html_url": "https://arxiv.org/abs/2511.04886", "title": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "title_en": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "authors": "Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang", "background": "道路交通安全事故是全球健康危机，导致每年超过一百万人死亡，并且给许多国家的GDP造成了3%以上的损失。传统交通安全管理研究通常单独分析风险因素，忽视了建成环境中固有的空间复杂性和上下文交互。此外，传统的基于神经网络的风险估计器通常只生成点估计，而未传达模型不确定性，这对关键决策的制定构成限制。论文在背景部分还提到了这些缺陷需要改进之处。", "innovation": "论文介绍了一种新的地理空间深度学习框架，利用遥感图像作为全面的空间输入。这种方法使模型能够捕捉到复杂的空间模式和嵌入的环境风险因素，这些因素共同作用于致命交通事故风险。相比于传统的生成单一确定性输出的方法，该模型估计了致命事故风险的完整贝塔概率分布，提供准确且具有不确定性的预测，这对于安全关键应用中的可信人工智能至关重要。此外，该模型还优于基准模型，在召回率上表现出17-23%的提升，这在标记潜在危险方面是关键指标，同时提供超常的校准。论文采用这种方式仅依赖遥感图像就可以提供可靠的和可解释的风险评估，使自动驾驶更加安全，同时也为城市规划者和政策制定者提供了一种高可扩展的工具，以公平和经济高效地提高道路安全性。", "conclusion": "该研究提出的方法通过仅依赖遥感图像就能提供可靠和可解释的风险评估，从而支持更安全的自主导航，并提供了一种高可扩展的工具，以公平和成本效益的方式增强道路安全性。该模型在召回率以及校准方面都优于基准模型，显示了在交通安全管理中的实用价值。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04951", "html_url": "https://arxiv.org/abs/2511.04951", "title": "CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting", "title_en": "CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting", "authors": "Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda", "background": "3D Gaussian Splatting (3DGS) 是一种越来越受欢迎的新视角合成方法，因其快速渲染时间和高质量输出而受到青睐。然而，将其扩展到大型或复杂的场景中具有挑战性，因为其需要大量的内存，远超大多数 GPU 的内存容量。因此，当处理大型场景时，3DGS 的使用受限。", "innovation": "本文介绍了一种名为 CLM 的系统，该系统允许 3DGS 使用单个消费级 GPU（如 RTX4090）渲染大型场景。CLM 通过将高斯分布卸载到 CPU 内存中，仅在需要时才将其加载到 GPU 内存中。此外，CLM 还采用了新颖的卸载策略，该策略利用了对 3DGS 内存访问模式的观察，以提高流水线中的并行性，并重叠 GPU 到 CPU 的通信、GPU 计算和 CPU 计算。进一步地，CLM 还通过减少通信量来研究访问模式。实验证明，这种方法能够在单个 RTX4090 上渲染需要 10000 万个高斯分布的大场景，并实现最先进的重建质量。", "conclusion": "本文提出的方法能够在单个消费级 GPU 上渲染大规模场景，实现高质量的 3D 贴图合成，解决了 3DGS 在处理大型场景时的内存瓶颈问题。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04949", "html_url": "https://arxiv.org/abs/2511.04949", "title": "DeepForgeSeal：基于多代理对抗强化学习的驱动潜空间半脆弱水印用于深伪检测", "title_en": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning", "authors": "Tharindu Fernando,Clinton Fookes,Sridha Sridharan", "background": "近年来生成式AI的快速进步使得深度造假（deepfakes）越来越逼真，给执法部门和公众信任带来了日益增长的挑战。现有的被动深度假检测方法难以跟上这些挑战，主要是因为它们依赖于特定的伪造特征，这限制了它们对新类型的深度假的泛化能力。为了应对高质量合成媒体的识别挑战，主动的深度假检测方法借助水印技术出现。然而，这些方法往往难以在保持对良性干扰的鲁棒性的同时提高对恶意篡改的敏感性。本研究引入了一种新颖的深度学习框架，结合高维潜在空间表示和多代理对抗强化学习（MAARL）范式，开发了一种鲁棒且适应性强的水印方法。该研究使用一条可学习的水印嵌入器，在潜在空间操作，捕捉高级图像语义，同时提供对消息编码和提取的精确控制。MAARL范式使得学习水印代理能够在良性及恶意图像操作的动态课程中追求鲁棒性和脆弱性之间的最优平衡。", "innovation": "该研究提出了一种利用高维潜在空间表示和多代理对抗强化学习（MAARL）范式的鲁棒且适应性强的水印方法。具体而言，该研究开发了一种在潜在空间操作的可学习水印嵌入器，捕捉高级图像语义，同时对消息编码和提取具有精确控制。MAARL范式使学习水印代理能够在良性及恶意图像操作的动态课程中追求鲁棒性和脆弱性之间的平衡。这种方法不仅提高了对良性干扰的抵抗能力，同时也能更好地检测恶意篡改。", "conclusion": "通过在CelebA和CelebA-HQ基准测试上的全面评估，本方法在面对挑战性篡改情景时表现明显优于现有最先进的方法，分别在CelebA和CelebA-HQ数据集上取得了超过4.5%和超过5.3%的性能提升。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04963", "html_url": "https://arxiv.org/abs/2511.04963", "title": "模式感知的fMRI/dMRI扩展合成与组织和微观结构精细化", "title_en": "Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement", "authors": "Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang", "background": "磁共振成像（MRI），尤其是功能性MRI（fMRI）和扩散MRI（dMRI），对于研究神经退行性疾病至关重要。然而，缺失的模态限制了其临床上的应用。尽管生成对抗网络（GAN）和扩散模型在模态完成方面显示出一些前景，但在fMRI-dMRI合成方面仍受到（1）fMRI和dMRI在时空轴上的显著BOLD信号与扩散加权信号差异，以及（2）生成过程中病理性神经解剖模式整合不足的限制。", "innovation": "提出了PDS，引入了两项关键创新：（1）模式感知的双模态3D扩散框架以实现跨模态学习，（2）集成了有效的微观结构精细化的组织细化网络，以保持结构保真度和细微细节。", "conclusion": "在OASIS-3、ADNI和内部数据集上评估，该方法达到了最先进的效果，fMRI合成的PSNR/SSIM为29.83 dB/90.84%│（较基线提高1.54 dB/+4.12%│），dMRI合成的PSNR/SSIM为30.00 dB/77.55%│（较基线提高1.02 dB/+2.2%│）。临床验证显示，合成数据具有强大的诊断性能，在混合真实-合成实验中NC vs. MCI vs. AD的准确率分别为67.92%│/66.02%│/64.15%│。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04970", "html_url": "https://arxiv.org/abs/2511.04970", "title": "学习Fourier形状以探究深度神经网络的几何世界", "title_en": "Learning Fourier shapes to probe the geometric world of deep neural networks", "authors": "Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li", "background": "尽管形状和纹理都是视觉识别的基础，但现有的深度神经网络（DNNs）研究主要集中在纹理的理解上，而对形状的几何理解研究不足。这项研究展示了通过优化形状能有效地传递语义信息，能根据纯几何定义的输入产生高置信度的分类；揭示了它们作为高保真可解释性工具精确隔离模型的显著区域；并且提出了一种新的可泛化的对抗范式，能够欺骗下游视觉任务。这通过一个端到端可微分框架实现，该框架结合了强大的Fourier级数来参数化任意形状、基于缠绕数的映射将形状转换为DNN所需的像素网格，并通过信号能量约束提高优化效率并确保形状的物理可行性。", "innovation": "研究提出了一种端到端可微分框架，该框架结合了强大的Fourier级数参数化任意形状、基于缠绕数的映射将形状转换为DNN所需的像素网格，并通过信号能量约束优化效率并确保形状的物理可行性，从而发现优化的形状可以作为强语义载体，可以精确隔离模型的关键区域，并构成新的对抗范式。", "conclusion": "这项研究提供了一个多用途框架，用于探讨DNN的几何领域，并为挑战和理解机器视觉打开了新的领域。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04972", "html_url": "https://arxiv.org/abs/2511.04972", "title": "3D数据合成在训练拓扑特征神经网络中的挑战", "title_en": "Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features", "authors": "Dylan Peek,Matthew P. Skerritt,Siddharth Pritam,Stephan Chalup", "background": "传统数据分析方法如持久同调在计算上较为耗时，推动了基于神经网络的估计器的发展，这些估计器能够减少计算开销和推断时间。然而，缺乏为监督学习定制的3D标记数据集是一个重要障碍，尤其是针对拓扑数据分析（TDA）任务。这篇文章介绍了用于系统生成标签3D数据集的新方法，利用Repulsive Surface算法来控制拓扑不变量，这使得生成的数据集具有多样化的几何形状和拓扑标签，适合作为训练和基准测试神经网络估计器的材料。", "innovation": "引入了一种使用Repulsive Surface算法系统生成标签3D数据集的新方法，能够控制拓扑不变量，如洞的数量。这种方法不仅生成了多样化的几何形状，还提供了拓扑标签，适合用于训练和评估神经网络估计器。利用3D卷积变换器架构创建了一个用于训练曲率估计网络的合成3D数据集，揭示了不仅拓扑复杂性，还有几何复杂性在训练泛化估计器中的作用。", "conclusion": "生成的3D数据集填补了在训练和评估TDA方法和模型中所需标记的3D数据和生成方法的空白，为提高神经网络在拓扑特征上的性能提供了坚实的基础。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05034", "html_url": "https://arxiv.org/abs/2511.05034", "title": "动态残差编码与切片级对比学习在端到端全切片图像表示中的应用", "title_en": "Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation", "authors": "Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan", "background": "全切片图像（WSI）表示对于癌症亚型分类、癌症识别和突变预测至关重要，但由于标准的吉普朗篇切片包含成千上万的图像瓷砖，加之当前GPU的计算限制，难以在一个小批次中计算所有瓷砖的梯度。", "innovation": "本文提出了一种动态残差编码与切片级对比学习（DRE-SLCL）方法，利用一个内存库来存储数据集内部所有WSI的瓷砖特征。在训练过程中，每个小批次通常包含多个切片，对于每个切片，随机采样一部分瓷砖并计算其特征，然后从内存库中选择更多的来自同一切片的瓷砖特征。通过残差编码技术和内存库中的特征共同生成每个切片的表示，最后基于这些表示和组织病理学报告计算切片级对比损失。", "conclusion": "在癌症亚型分类、癌症识别和突变预测任务上的实验验证了DRE-SLCL方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05038", "html_url": "https://arxiv.org/abs/2511.05038", "title": "Pressure2Motion: 从地面压力进行文本指导的层次化动作合成", "title_en": "Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance", "authors": "Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu", "background": "传统的动作捕捉技术需要专业的光照设置、相机或穿戴设备，增加了成本和复杂性，并不适用于隐私保护、低光照条件以及低成本的需求。同时，从地面压力信号预测人类全身运动是一项严重病态的任务，因为地面压力信号到全身动作的转换是不确定的。", "innovation": "提出了一种名为Pressure2Motion的新颖动作捕捉算法，该算法能够从地面压力序列和文本提示合成人类运动，无需专门的光照设置、相机或穿戴设备，特别适用于隐私保护、低光照和低成本的动作捕捉场景。这种算法通过一个生成模型，利用地面压力特征作为输入，并使用文本提示作为高层次的指导约束，解决了从压力信号到全身动作转换的不确定性问题。算法利用具有两层特征提取的物理线索，以及分层扩散模型来识别大规模运动轨迹和细微姿势调整，结合压力序列的物理线索和描述性文本的语义指导进行精细的动作生成。", "conclusion": "Pressure2Motion是我们所知的第一个利用压力数据和语言先验进行动作生成的开创性工作，它建立了首个适用于此类任务的MPL基准测试。实验结果表明，这种方法可以生成高保真且物理上合理的动作，确立了该任务的新技术前沿。编码和基准测试将在发表后公开释放。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05017", "html_url": "https://arxiv.org/abs/2511.05017", "title": "通过细化文本嵌入减轻大型视觉-语言模型中的幻觉现象", "title_en": "Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings", "authors": "Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang", "background": "当前的LVLM架构存在一种内在偏向语言模态的偏差，主要原因是习惯性地将视觉嵌入单纯附加到输入文本序列上。这一偏差导致模型在视觉定位任务中的表现欠佳，甚至产生幻觉。而平均池化整合视觉特征以改进文本嵌入，虽然提供了简单、可靠和高效的视觉信息融合手段，但研究者认为更复杂的融合方法可能进一步提高视觉定位和跨模态对齐的效果。因此，当前研究旨在突出这种模态失衡及其对幻觉的影响，并证明通过细化文本嵌入可减轻此问题。", "innovation": "提出了一种简单且有效的方法，通过整合平均池化的视觉特征来细化文本嵌入，从而改善视觉定位任务中的表现并大幅减少幻觉现象。", "conclusion": "平均池化提供了一种简单、可靠且高效的将视觉信息融入的方法，虽已有所改善，但更复杂的融合策略将在未来得到进一步探索。本研究的重心在于指出模态不均衡的问题及其对幻觉的影响，并展示通过细化文本嵌入来缓解这一问题的方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05055", "html_url": "https://arxiv.org/abs/2511.05055", "title": "无姿态估计？没问题！面向单目深度估计的无姿态感知和实例感知测试时适配", "title_en": "No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation", "authors": "Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang", "background": "单目深度估计（MDE）在多种需要三维场景的应用中扮演着关键角色。然而，在实际应用场景中，MDE模型往往需要部署在与训练条件不同的环境中。如何有效地解决这一问题，特别是面对多样化的动态环境，成为当前研究的一个挑战。", "innovation": "本文提出了一种新型且高效的测试时适应（TTA）框架，名为PITTA。该框架包括两个创新策略：（i）无姿态感知的MDE TTA范式；（ii）实例感知图像遮罩。此外，本文还提出了一种简单有效的边缘提取方法来增强模型性能。PITTA能够在无需任何相机姿态信息的情况下实现MDE网络的高效TTA。这种方法通过从预先训练的全景分割网络生成的分割掩码中移除静态对象（包括背景）的掩码，来提取动态对象的实例掩码。", "conclusion": "在DrivingStereo和Waymo数据集上的广泛实验表明，本文提出的PITTA框架在MDE的TTA中显著优于现有最先进的技术，取得了出色的表现提升。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05057", "html_url": "https://arxiv.org/abs/2511.05057", "title": "Role-SynthCLIP: 一种基于角色扮演的多样化合成数据方法", "title_en": "Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach", "authors": "Yuanxiang Huangfu,Chaochao Wang,Weilei Wang", "background": "CLIP模型的有效性高度依赖于其训练数据的语义多样性和质量。现有合成数据生成方法主要侧重于增加数据量，但这种方式往往导致语义多样性有限且生成的描述重复或浅显。", "innovation": "提出了一种新颖的数据合成框架——Role-SynthCLIP，利用多角度的角色扮演提示（如，组合分析师、图像背景的解释者）来引导多模态大语言模型从不同视角生成语义多样的描述。该机制提高了合成配对的语义多样性和图像-文本细微对齐，增强了描述的表现力和准确性，同时保持图像-描述配对总数不变。", "conclusion": "实验结果表明，采用仅100万Role-SynthCLIP配对训练的CLIP-B/16模型在MS COCO验证集上的Recall@1达到64.1%，超过了现有最佳合成数据基线（在500万配对上训练）2.8个百分点。代码和训练模型已发布。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05073", "html_url": "https://arxiv.org/abs/2511.05073", "title": "深度学习模型是脆弱的，但对抗样本更加脆弱", "title_en": "Deep learning models are vulnerable, but adversarial examples are even more vulnerable", "authors": "Jun Li,Yanwei Xu,Keran Li,Xiaoli Zhang", "background": "理解对抗样本和干净样本之间的内在差异对于增强DNN的鲁棒性以及对抗攻击的检测至关重要。在这项研究中，作者首先通过实验证实了基于图像的对抗样本对遮挡具有显著的敏感性。", "innovation": "作者提出了Sliding Mask Confidence Entropy (SMCE) 来量化模型在遮挡下的置信度波动。在此基础上，他们提出了Sliding Window Mask-based Adversarial Example Detection (SWM-AED) 方法，这种方法避免了传统对抗训练中的灾难性过拟合。实验结果表明，SWM-AED 在大多数情况下表现出了超过62%的准确率，在某些情况下甚至达到了96.5%。", "conclusion": "通过对CIFAR-10数据集上的各种攻击类型和分类器进行评估，该方法表现出了较强的鲁棒性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05059", "html_url": "https://arxiv.org/abs/2511.05059", "title": "SurgiATM：一种用于腹腔镜手术基于深度学习的物理引导插件式烟雾去除模型", "title_en": "SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery", "authors": "Mingyu Sheng,Jianan Fan,Dongnan Liu,Guoyan Zheng,Ron Kikinis,Weidong Cai", "background": "在腹腔镜手术中，组织凝固产生的烟雾会显著降低内窥镜框架的视觉质量，增加手术错误的风险，并阻碍临床决策制定和计算机辅助视觉分析。因此，去除手术烟雾对于确保患者安全和保持手术效率至关重要。", "innovation": "本文提出了SurgiATM模型，这是一种物理基础大气模型与数据驱动深度学习模型统计结合的方法。SurgiATM具有轻量级、插件式且无需额外训练权重的特点，能够无缝集成到各种手术烟雾清除架构中，提高其准确性和稳定性。经多个公共数据集上的广泛实验验证，该模型可以降低现有模型的恢复误差，提升通用性。", "conclusion": "实验结果表明，SurgiATM能够有效减少现有模型的恢复误差，提高其通用性，同时无需增加可训练层或权重。该方法具有便捷性、低成本和高通用性。相关代码已发布。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05095", "html_url": "https://arxiv.org/abs/2511.05095", "title": "利用高质量冷启动的双层强化学习进行现实世界不良天气图像恢复", "title_en": "Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start", "authors": "Fuyang Liu,Jiaqi Xu,Xiaowei Hu", "background": "恶劣天气对现实世界的视觉感知影响严重，现有的基于合成数据训练的视觉模型在面对复杂退化时难以泛化。已有模型在固定参数条件下训练，但在遇到真实环境中多变的天气条件时表现不佳。", "innovation": "本研究构建了一个基于物理驱动生成的高质量数据集HFLS-Weather，模拟了多样的天气现象，并设计了一个以HFLS-Weather为初始训练的双层强化学习框架。在局部层面上，通过扰动驱动的图像质量优化，特定于天气的修复模型被不断精细调整；在全局层面上，元控制器能够动态地根据场景退化情况选择和执行模型。该框架实现了对现实世界条件的连续适应，并在多种不良天气条件下达到了最先进的性能。", "conclusion": "通过双层强化学习框架，利用高质量的初始数据集进行冷启动，该研究能够使模型在遇到不良天气图像时实现高效的图像恢复，并在广泛的真实和不良天气场景中达到最好的效果。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04977", "html_url": "https://arxiv.org/abs/2511.04977", "title": "GSE：通过通用贴纸编码器评估贴纸视觉语义相似性", "title_en": "GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder", "authors": "Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang", "background": "贴纸已成为一种流行的形式视觉交流，但理解其语义关系依然充满挑战。原因是贴纸内容高度多样且富含象征意义，现有的研究暂时未能有效地捕捉这些复杂的贴纸含义。", "innovation": "本文首次正式定义了贴纸语义相似性任务，并引入了广泛的三元组基准 Triple-S，该基准包含905对通过人工标注的正面和负面贴纸对。此外，作者提出了通用贴纸编码器(GSE)，这是一种轻量级且多功能的模型，能够利用Triple-S和额外的数据集学习鲁棒的贴纸嵌入。GSE 在应对新未见过的贴纸表现出色，并在下游任务如情绪分类和贴纸对检索上表现出优异的性能。", "conclusion": "通过发布基准Triple-S和模型GSE，本研究提供了标准化的评估工具和鲁棒的嵌入向量，为未来有关贴纸理解、检索以及多模态内容生成的研究指明了方向。Triple-S 和 GSE 已经被公开释放，并且可以在下方链接进行下载。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05106", "html_url": "https://arxiv.org/abs/2511.05106", "title": "从视网膜OCT图像早期检测阿尔茨海默病：一项英国生物库研究", "title_en": "Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study", "authors": "Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren", "background": "视网膜层厚度的改变与阿尔茨海默病（AD）等神经退行性疾病有关。尽管早期研究主要关注分层厚度测量，但本研究探索了直接通过对OCT B扫描图像的分类来进行AD的早期检测。这是首次将深度学习应用于原始OCT B扫描以预测AD。早期检测比诊断更具挑战性，因为成像通常比临床诊断提前几年。", "innovation": "本研究首次应用深度学习技术直接对原始OCT B扫描图像进行阿尔茨海默病的预测。使用ImageNet和专门用于OCT的RETFound转换器等预训练模型进行了微调和评估。引入了一种年度加权损失函数，以减少小规模高维数据集中的过拟合。ResNet-34在4年队列中取得了最稳定的结果，AUC值为0.62。", "conclusion": "研究结果为基于OCT的AD预测提供了基线，强调了在AD诊断前几年检测微小视网膜生物标志物的挑战，表明需要更大的数据集和多模态方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05092", "html_url": "https://arxiv.org/abs/2511.05092", "title": "一个人群重识别中双重阶段提示驱动隐私保留范式的隐私保留范式", "title_en": "A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification", "authors": "Ruolin Li,Min Liu,Yuan Bian,Zhaoyang Li,Yuzhen Li,Xueping Wang,Yaonan Wang", "background": "随着人们对数据隐私的关注增加，研究人员开始使用虚拟数据作为敏感真实世界图像的替代品进行人群重新识别（Re-ID）模型的训练。然而，现有由游戏引擎生成的虚拟数据集仍存在诸如复杂构建和领域泛化能力差等挑战，使其在实际场景中难以应用。", "innovation": "本文提出了一种双重阶段提示驱动隐私保留范式（DPPP）。在第一阶段，生成包含行人外观、光照和视角等多维属性的丰富提示，以驱动扩散模型端到端地生成多样化数据，构建名为GenePerson的大规模虚拟数据集，包含6,641个身份的130,519张图像。在第二阶段，提出了一种提示驱动分离机制（PDM）以学习领域不变的泛化特征。通过对比学习，使用两个文本反转网络将图像映射为风格和内容的虚词，构建风格分离的内容提示，以指导模型在图像级别学习领域不变的内容特征。研究表明，在GenePerson数据集上使用PDM进行训练的模型达到了最先进的泛化性能，超过了在流行的真实和虚拟Re-ID数据集上训练的模型。", "conclusion": "实验表明，在GenePerson数据集上使用PDM进行训练的模型达到了最先进的泛化性能，证明了DPPP的有效性和实用性，解决了现有虚拟数据集的复杂构建和泛化能力差的问题，为人群重识别模型提供了新的数据源和方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05108", "html_url": "https://arxiv.org/abs/2511.05108", "title": "SnowyLane：利用基础设施元素在雪地农村道路上进行鲁棒车道检测", "title_en": "SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements", "authors": "Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann", "background": "在雪覆盖环境中进行自主驾驶的车道检测仍然是一个主要挑战，因为车道标记经常缺失或被遮挡。现有的车道检测方法依赖于传统的车道标记，但在恶劣天气条件下，这种依赖性导致了鲁棒性不足。", "innovation": "本文提出了一种新颖的鲁棒且实时的方法，该方法通过检测路边特征——称为分隔柱的垂直路标，作为间接的车道指示器，来绕过对传统车道标记的依赖。该方法首先感知这些路标，然后使用参数化的贝塞尔曲线模型拟合平滑的车道轨迹，利用空间一致性与道路几何学。为此，作者还提出了SnowyLane数据集，包含80,000个标注帧，模拟冬季驾驶条件，包括不同的雪覆盖和光照条件。", "conclusion": "与现有最先进的车道检测系统相比，本文的方法在恶劣天气条件下，尤其是在重雪遮挡情况下，显示出了显著的鲁棒性改进。这项工作为冬季场景下的可靠车道检测奠定了坚实的基础，并为未来在各种天气条件下的自主驾驶研究提供了宝贵资源。该数据集可以在以下链接获得：this https URL"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05150", "html_url": "https://arxiv.org/abs/2511.05150", "title": "从线性探查到联合加权标记层级：一种桥梁全局与细胞表示的基模", "title_en": "From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection", "authors": "Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler", "background": "现有的基于AI的生物标志物可以从苏木精和伊红（H&E）切片中直接推断出分子特征，但大多数病理基础模型（PFMs）依赖于全局补丁级嵌入，忽视了细胞级别的形态学。已有研究表明，关注细胞特性的模型在提高病理学中生物标志物检测的可解释性和鲁棒性方面具有潜力。", "innovation": "本文提出了一种新型的病理基础模型（PFM）——JWTH（联合加权标记层级），结合了大规模自我监督预训练和细胞中心后调优以及注意力池化，以融合局部和全局标记。在四个涉及四种生物标志物和八个生物库的任务中，JWTH实现了高达8.3%的平衡准确率提升和平均1.2%的改进，显著提升了AI在数字病理学中生物标志物检测的解释性和鲁棒性。", "conclusion": "JWTH模型通过融合局部和全局标记，增强了病理学中生物标志物检测的性能和解释性，为AI在数字病理学应用中开辟了新的途径，展示了基础模型在结合全局与细胞级表示方面的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05219", "html_url": "https://arxiv.org/abs/2511.05219", "title": "FreeControl: 无训练高效单步注意力提取的结构控制", "title_en": "FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction", "authors": "Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi", "background": "控制扩散生成图像的空间和语义结构仍然是一个挑战。现有的方法如ControlNet依赖于手工制作的条件图和重新训练，从而限制了灵活性和泛化能力。反转基础的方法提供了更好的对齐，但由于双路径去噪导致高昂的推理成本。", "innovation": "FreeControl是一种无需训练的框架，可以在扩散模型中实现语义结构控制。它通过从单个最优选取的关键时间步提取一次性的注意力提取，然后在去噪过程中重用它，从而实现高效的结构指导，而无需反转或重新训练。为了进一步提高质量和稳定性，FreeControl引入了潜在条件解耦（LCD）：一种原理上的分离关键时间步与用于注意力提取的带噪潜在变量的方法。LCD可以提供更细粒度的注意力质量控制并消除结构伪影。FreeControl还支持来自多个来源的参考图像组成的控制，从而实现直观的场景布局设计和更强的提示对齐。FreeControl介绍了一种新的测试时控制范式，可以直接从原始图像生成与结构和语义对齐、视觉上一致的生成，具有直观的组成设计灵活性，并且兼容现代扩散模型，成本约增加了5%.", "conclusion": "FreeControl通过单次注意力提取提供了一种无需训练的结构控制方法，减少推理成本，同时提供更细粒度的控制和改进的生成质量，支持组成设计，并兼容现代扩散模型，额外成本仅为约5%。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05245", "html_url": "https://arxiv.org/abs/2511.05245", "title": "ADPretrain：通过异常表示预训练促进工业异常检测", "title_en": "ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining", "authors": "Xincheng Yao,Yan Luo,Zefeng Qian,Chongyang Zhang", "background": "当前主流的异常检测（AD）方法主要基于通过ImageNet预训练得到的特征网络。然而，这些预训练在自然图像上的过程并不符合异常检测的目标（即，在自然图像上的预训练并不旨在区分正常和异常），并且工业图像数据和自然图像在AD场景中的分布存在差异。这两个问题会导致使用ImageNet预训练的特征在AD任务上表现不佳。", "innovation": "我们提出了一种新的AD表示学习框架，专门为工业异常检测任务学习鲁棒且区分性强的预训练表示。该框架通过角度和范数导向的对比损失，最大化正常和异常特征之间的角度差和范数差。我们还在大规模AD数据集RealIAD上进行预训练，以避免分布偏移，并基于通用类表示和残差特征学习预训练AD表示。", "conclusion": "基于五种嵌入式AD方法的实验表明，我们的预训练表示在五个AD数据集和五个模型骨架上表现出色。相关代码可在此链接找到。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05250", "html_url": "https://arxiv.org/abs/2511.05250", "title": "使用检测器和深度半正定Siamese网络的精确在线动作和手势识别系统", "title_en": "Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks", "authors": "Mohamed Sanim Akremi,Rim Slama,Hedi Tabia", "background": "在线连续运动识别是一个热门的研究领域，因为其在实际应用场景中更为实用。近年来，基于骨架的方法越来越受欢迎，显示出3D时序数据的强大功能。然而，目前大多数工作集中在基于片段的识别，不太适合在线情境。", "innovation": "本文提出了一个基于半正定矩阵表示和Siamese网络的在线识别系统，用于处理骨架序列流。该系统由检测器和分类器两个主要组件组成，可以预测未分割序列中的运动时间间隔，并通过检测器识别这些间隔中的运动类型。该方法灵活且能够连续识别动作状态，优于现有最先进的表现。", "conclusion": "我们在手部手势和身体动作识别基准上进行了广泛实验，验证了我们在线识别系统的准确性，大多数情况下超过了最先进的性能。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05168", "html_url": "https://arxiv.org/abs/2511.05168", "title": "另一个BRIXEL在墙中：追求更廉价的稠密特征", "title_en": "Another BRIXEL in the Wall: Towards Cheaper Dense Features", "authors": "Alexander Lappe,Martin A. Giese", "background": "视觉基础模型在全局和局部密集的下游任务上表现出色。最新DINOv3模型家族在大规模图像预训练后，能够生成非常精细的密集特征图，从而达到最先进的性能。但是，生成这些特征图需要输入图像具有非常高分辨率，并且由于变压器架构的平方复杂性，计算量也很大。为了应对这些挑战，本文提出了一种简单的知识蒸馏方法——BRIXEL，该方法使学生模型学会在其自身特征图的基础上以更高分辨率生成特征图。", "innovation": "BRIXEL 是一种简单的知识蒸馏方法，可以让学生模型在保持固定分辨率的情况下，以较少的计算成本生成特征图，这些特征图与教师模型生成的特征图非常相似，且显著优于基线的DINOv3模型在下游任务上的性能。", "conclusion": "BRIXEL方法在保持固定分辨率的情况下，能够以较低的计算成本生成与教师模型生成的特征图非常相似的特征图，且在下游任务中显著优于基线模型DINOv3。代码和模型权重在此处提供。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05229", "html_url": "https://arxiv.org/abs/2511.05229", "title": "4D3R：基于单目视频的动态场景运动感知神经重建与渲染", "title_en": "4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos", "authors": "Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee", "background": "单目视频中动态场景的新型视图合成仍然是计算机视觉和图形学中的一个基本挑战，尤其是在场景相机姿态未知的情况下。尽管神经辐射场（NeRF）和3D高斯散列（3DGS）等最近在3D表示方面的进展在静态场景上表现良好，但它们在处理动态内容时表现不佳，通常依赖于预先计算的相机姿态。", "innovation": "4D3R提出了一种无需姿势的动态神经渲染框架，通过两阶段方法解耦静态和动态成分。其主要创新点包括：（1）一种结合基于Transformer的学习先验与SAM2的运动感知捆绑调整（MA-BA）模块，用于稳健地分割动态对象并提高相机姿态的准确性；（2）一种高效的运动感知高斯散列（MA-GS）表示，使用控制点和变形场MLP及线性混合皮肤技巧建模动态运动，显著降低了计算成本同时保持高质量的重建。", "conclusion": "在实际动态数据集上的大量实验表明，该方法能够在复杂场景中（特别是大动态对象场景）比最先进的方法获得高达1.8dB的PSNR改进，并且与之前的方法相比将计算需求减少5倍。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05170", "html_url": "https://arxiv.org/abs/2511.05170", "title": "MUSE: 多尺度密集自我精炼用于核检测和分类", "title_en": "MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification", "authors": "Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang", "background": "核检测和分类（NDC）在组织病理学分析中是一个基础任务，支撑着一系列高级病理学应用。现有方法高度依赖于劳动密集型的核级别注释，并且难以充分利用大规模未标注数据来学习区分性的核特征表示。", "innovation": "本文提出了一种新颖的自监督学习方法MUSE（MUlti-scale denSE self-distillation），专门针对NDC。核心机制NuLo（Nucleus-based Local self-distillation）是一种基于预测的核位置的坐标的引导机制，能够灵活地进行局部自我精炼。MUSE还设计了一个简单有效的编码器-解码器架构和一个大的视野半监督微调策略，这两者共同最大化了未标注病理学图像的价值。实验表明，MUSE有效解决了常规的NDC挑战，生成的模型不仅能超越最先进的有监督基线，还能优于通用的病理基础模型。", "conclusion": "MUSE在三个广泛使用的基准上进行了广泛的实验，证实了其在核检测和分类上的有效性和优越性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05253", "html_url": "https://arxiv.org/abs/2511.05253", "title": "自动分割结直肠 liver 转移瘤以实现超声导航下的切除", "title_en": "Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection", "authors": "Tiziano Natali,Karin A. Olthof,Niels F.M. Kok,Koert F.D. Kuhlmann,Theo J.M. Ruers,Matteo Fusaglia", "background": "在结直肠肝转移瘤(CRLM)的外科手术中，术中精准的界线划分对于实现无残留切除至关重要。然而，使用超声造影（iUS）进行此操作具有挑战性，因为它受到对比度低、噪音大和操作员依赖性等因素的影响。为了克服这些限制，本研究开发了一种自动分割方法，以提高超声导航的精确度和效率。", "innovation": "本研究使用了包含85名CRLM患者的85个追踪3D iUS体积的数据集，通过nnU-Net框架训练并评估了一个3D U-Net模型。与完整体积模型相比，边界切割模型通过减轻操作员负担，提高了分割精度和执行效率。最终，被切割的3D U-Net模型在所有评估指标上显著优于完整体积模型，实现了与半自动分割相当的准确性，但执行速度快约4倍（大约1分钟）。", "conclusion": "本研究中的自动3D CRLM分割方法提供了可靠、近实时的结果，对操作员输入的需求最低。该方法为肝脏手术中的无注册超声导航提供了高效的解决方案，接近专家级的精度，同时大幅减少了手动工作量和手术时间。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05152", "html_url": "https://arxiv.org/abs/2511.05152", "title": "Splatography: 异常摄像机配置下稀疏多视图动态高斯点云绘制方法", "title_en": "Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges", "authors": "Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull", "background": "在动态三维重建中，传统的基于高斯点云绘制的方法已经能够实现逼真的三维动态重建。然而，由于预算限制，电影制作中可能会出现较少的相机配置，这限制了现有方法在捕捉复杂动态特征时的表现。", "innovation": "本文提出了一种方法，通过将摄像机帧的高斯点云和变形场分为前景和背景，利用稀疏的掩码来处理预算有限的情况。每个部分分别在不同的损失函数下进行训练，使方法能够根据常见的电影制作实践来建模不同参数的变形场。与现有方法相比，该方法不仅能够产生与现有的定量和定性结果相当的结果，还能生成包含透明动态纹理的分割动态重建。", "conclusion": "实验表明，本文提出的方法能够在三维场景上实现高达3倍的PSNR，且模型大小仅为现有方法的一半。此外，无需密集的掩码监督，该方法还能生成包含透明和动态纹理的分割动态重建。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05044", "html_url": "https://arxiv.org/abs/2511.05044", "title": "基于下一个标记掩码预测的医学引用图像分割", "title_en": "Medical Referring Image Segmentation via Next-Token Mask Prediction", "authors": "Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li", "background": "医学引用图像分割（MRIS）涉及根据自然语言描述在医学图像中分割目标区域。尽管取得了一定的成果，但最近的方法通常需要复杂的多模态融合或多阶段解码器设计。在这项工作中，我们提出了NTP-MRISeg，一种将MRIS重新表述为一个自回归下一个标记预测任务的新框架，用于统一标记的图像、文本和掩码表示序列。这种表述简化了模型设计，消除了专用模态融合和外部分割模型的需求，支持端到端训练的统一架构。同时，还允许使用来自新兴大规模多模态模型的预训练分词器，增强了泛化能力和适应性。更重要的是，针对这种表述下的挑战（如暴露偏差、长尾标记分布以及细粒度病灶边缘），我们提出了三种新颖的方法：(1) 下一个k个标记预测方案（NkTP），减少累积预测错误；(2) 分词级别对比学习（TCL），增强边界敏感性并缓解长尾分布效应；(3) 一种基于记忆的难标记优化策略（HET），在训练中强调困难标记。", "innovation": "提出了NTP-MRISeg框架，将MRIS重新表述为自回归下一个标记预测任务，取消了专门的模态融合和外部分割模型，支持统一架构的端到端训练。提出了三种创新策略：(1) 下一个k个标记预测方案；(2) 分词级别的对比学习；(3) 基于记忆的难标记优化策略。实验结果表明，该方法在QaTa-COV19和MosMedData+数据集上的表现达到了新的SOTA水平，为传统的MRIS管道提供了一种简化且有效的替代方案。", "conclusion": "提出的NTP-MRISeg框架不仅简化了模型设计，提高了泛化能力，还通过新颖的策略提高了模型的准确性和适应性。实验结果验证了该方法的有效性，为未来的医学图像分割研究提供了新的思路。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05271", "html_url": "https://arxiv.org/abs/2511.05271", "title": "DeepEyesV2：迈向能够自主操作的多模态模型", "title_en": "DeepEyesV2: Toward Agentic Multimodal Model", "authors": "Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu", "background": "现有的多模态模型不仅要理解文本和图像，还应该能够主动调用外部工具，如代码执行环境和网络搜索，并将这些操作整合到推理中。当前的研究发现直接使用强化学习难以产生稳定的工具使用行为。", "innovation": "本文介绍了DeepEyesV2，并探索了从数据构建、训练方法和模型评估的角度来构建一个能够自主操作的多模态模型的方法。提出了一个两阶段的训练管道：初始阶段建立工具使用模式，随后的强化学习阶段进一步优化工具调用。还创建了RealX-Bench，这是一个全面的基准测试，评估多模态推理能力，包括感知、搜索和推理等多个方面。实验结果显示，DeepEyesV2在多种现实任务中的效果显著，并能够根据不同任务需求灵活调用工具。", "conclusion": "我们的研究希望为社区在开发能够自主操作的多模态模型方面提供指导。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05263", "html_url": "https://arxiv.org/abs/2511.05263", "title": "OregairuChar: 用于《我的青春虚假面谱》中角色出现频率分析的基准数据集", "title_en": "OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU", "authors": "Qi Sun,Dingju Zhou,Lina Zhang", "background": "角色出现频率的分析对于理解动画片中的叙事结构、角色的重要性以及故事的进展至关重要。在本研究中，我们介绍了用于分析《我的青春虚假面谱》系列中角色出现频率的基准数据集 OregairuChar。该数据集包括第三季的1600个手动选择的帧，并对11个主要角色进行了2860个边界框的标注。", "innovation": "我们创建了 OregairuChar 数据集，涵盖了不同的视觉挑战，如遮挡、姿态变化和角色间的相似性，提供了一个现实的基础，用于基于出现频率的研究。为了使定量研究成为可能，我们在数据集上基准测试了几种物体检测模型，并利用它们的预测进行细粒度的、按集分析角色存在及其随着时间的变化。这种方法揭示了角色重要性的模式及其在叙事中的演变。", "conclusion": "强调角色出现频率，OregairuChar 作为一个有价值的资源，有助于探索计算叙事动力学和角色为中心的故事叙述在形象化媒体中的应用。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05292", "html_url": "https://arxiv.org/abs/2511.05292", "title": "从可穿戴IMU数据推断您盘中的美食", "title_en": "What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs", "authors": "Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang", "background": "饮食摄入的准确检测对于饮食监控和慢性病预防至关重要。传统的自我报告方法容易产生回忆偏差，而基于摄像头的方法则引发了隐私方面的担忧。现有的基于穿戴设备的方法主要集中在汉堡包和比萨等有限的食品类型上，并未涵盖中国丰富多样的饮食种类。因此，作者提出了CuisineSense系统，该系统通过整合智能手表的手部动作线索和智能眼镜的头部动态将中国不同类型的食物进行分类。为了过滤掉无关的日常活动，系统设计了两阶段检测管道。第一阶段通过区分进食行为与非进食行为的特征时间模式来识别进食状态。在紧接着的第二阶段，系统根据进食期间捕捉到的动作来进行精细的食物类型识别。", "innovation": "CuisineSense系统通过结合智能手表的手部动作和智能眼镜的头部动态来识别和分类中国不同类型的食物。系统采用了两阶段的检测机制：第一阶段识别进食状态，第二阶段进行细粒度的食物分类。此外，为了验证系统的有效性，作者构建了一个包含11种食物分类和10名参与者共计27.5小时的IMU数据集，该系统能够在进食状态检测和食物分类中达到高准确率，提供了一种非侵入性的、穿戴设备为基础的饮食监控解决方案。", "conclusion": "实验结果表明，CuisineSense系统在进食状态检测和食物分类方面均实现了高精度，为非侵入性的、穿戴设备为基础的饮食监控提供了可行的解决方案。该系统的代码已被公开可查。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05308", "html_url": "https://arxiv.org/abs/2511.05308", "title": "重思3D点云生成的度量标准和扩散架构", "title_en": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation", "authors": "Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière", "background": "随着3D点云成为现代技术的基石，对复杂生成模型和可靠的评估指标的需求急剧增加。现有的一些评价指标，特别是基于Cramer距离（CD）的指标，在处理缺陷时不够稳健，并且不能在用于质量指示时捕捉到几何保真度和局部形状一致性。", "innovation": "本文提出了引入样本对齐先验以确保距离计算的一致性和鲁棒性，用密度感知Cramer距离（DCD）取代Cramer距离（CD），和一种新度量标准表面法线一致性（SNC）通过比较估计点的法线来近似表面相似性。此外，我们引入了一个基于变压器的3D结构生成新架构，名为扩散点变压器，该模型在ShapeNet数据集上的实验和对比表明其在生成点云质量方面优于之前的解决方案，实现了新的最先进的水平。", "conclusion": "通过广泛实验和比较在ShapeNet数据集上，证明了新模型在生成点云质量方面显著优于先前的解决方案，尤其是通过新的评估度量标准，该模型达到了当前最先进的技术水平。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05210", "html_url": "https://arxiv.org/abs/2511.05210", "title": "Walk the Lines 2: 基于轮廓跟踪的详细分割", "title_en": "Walk the Lines 2: Contour Tracking for Detailed Segmentation", "authors": "André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop", "background": "该论文介绍了Walk the Lines 2 (WtL2)，这是一种针对红外（IR）船只和RGB场景中各种物体进行详细分割的新型轮廓跟踪算法。WtL2是在原有的Walk the Lines (WtL)基础上的发展，WtL主要针对彩色图像中的详细船只分割。WtL2能够通过轮廓跟踪细化物体轮廓，形成适合前景背景分割的1像素封闭形状，并且能够替代传统的非最大抑制（NMS），从而有效地完善物体的分割。", "innovation": "WtL2创新之处在于它可以扩展此前WtL的适用范围，不仅应用于彩色图像中的船只分割，还能用于红外图像和RGB图像中的多种物体。通过改进输入的物体轮廓检测器以适应红外船只，WtL2增强了处理多种RGB物体的能力，在闭合物体轮廓时的表现超越了最新一代基于轮廓的方法，提供了出色的具体细节和较高的IoU值。", "conclusion": "WtL2作为一种适用于需要详细分割或高质量样本的特定应用场景的方法，有望加速图像分割领域中几个新兴领域的进展。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05293", "html_url": "https://arxiv.org/abs/2511.05293", "title": "基于对比学习的跨领域脑电图情绪识别", "title_en": "Cross-domain EEG-based Emotion Recognition with Contrastive Learning", "authors": "Rui Yan,Yibo Li,Han Ding,Fei Wang", "background": "脑电图（EEG）基的情绪识别是情感计算的重要组成部分，但遇到了特征利用和跨领域泛化的挑战。现有模型在利用EEG信号特征和在不同背景下的推广性方面存在局限性。因此亟需探索新的方法来改进情绪识别的效果和通用性。", "innovation": "本文提出了EmotionCLIP，将其情绪识别任务重新定义为类似于CLIP框架下的EEG文本匹配任务；设计了一种定制的骨干网络SST-LegoViT，利用多尺度卷积和Transformer模块捕获空间、频谱和时间特征；实验结果显示，该方法在SEED和SEED-IV数据集上取得了更高的跨被试准确率（88.69%和73.50%）和跨时间准确率（88.46%和77.54%），超越了现有模型。这表明多模态对比学习在鲁棒EEG情绪识别中的有效性。", "conclusion": "本文提出的方法通过将EEG情绪识别重新定义为EEG文本匹配任务，并使用多模态对比学习方法有效提升了情绪识别的跨领域泛化和跨被试识别能力，对未来情感计算领域具有重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05319", "html_url": "https://arxiv.org/abs/2511.05319", "title": "S^2LM: 通过大型语言模型朝向语义隐写术", "title_en": "$\\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models", "authors": "Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke", "background": "尽管近年来隐写术取得了显著进步，但仍难以将富有语义的句子级信息嵌入到载体中。然而，在AIGC时代，隐写术的容量变得前所未有的重要。传统隐写术主要致力于嵌入位级信息，但面对日益复杂的信息需求，传统的隐写术已难以满足。因此，本研究旨在探索如何利用大型语言模型（LLMs）来实现句子级的语义信息嵌入。", "innovation": "研究提出了一种名为Sentence-to-Image Steganography的新颖任务，这是语义隐写术的一个实例，旨在通过隐蔽图像中的句子级信息来提高嵌入容量。研究还提出了评估用语集“ Invisible Text (IVT)”。此外，该论文还引入了S^2LM：语义隐写语言模型，该模型利用LLMs将句子级文本信息嵌入到图像中，通过设计了一个LLM参与全过程的新流程，实现了语义丰富的内容嵌入。", "conclusion": "定量和定性实验表明，该方法能够有效解锁LLMs的新语义隐写术能力。源代码将很快发布。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05299", "html_url": "https://arxiv.org/abs/2511.05299", "title": "LiveStar: 实时流媒体助手，用于现实世界的在线视频理解", "title_en": "LiveStar: Live Streaming Assistant for Real-World Online Video Understanding", "authors": "Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu", "background": "尽管在离线视频理解方面已经取得了显著进步，现有的在线视频大语言模型（Video-LLMs）往往难以同时处理连续的帧级输入并确定最优响应时机，导致实时响应性和叙述连贯性受损。", "innovation": "我们提出了LiveStar，一种通过自适应流媒体解码实现持续主动响应的开创性实时流媒体助手。LiveStar包括：(1) 适应性训练策略，实现变长视频流的视频-语言对齐，保持动态变化帧序列的时序一致性；(2) 响应-沉默解码框架，通过一次前向验证确定最优主动响应时机；(3) 内存感知加速机制，通过尖峰-末尾记忆压缩结合流媒体键值缓存，实现10分钟以上视频的在线推理加速1.53倍。我们还构建了OmniStar数据集，包括15个现实世界的场景和5项在线视频理解评估任务，用于训练和基准测试。", "conclusion": "在三项基准测试中的广泛实验表明，LiveStar实现了最先进的性能，在语义准确性上平均提高了19.5%，响应时间差减少了18.1%，同时所有五个OmniStar任务的FPS提高了12.0%。我们的模型和数据集可在此网址访问：this https URL."}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05356", "html_url": "https://arxiv.org/abs/2511.05356", "title": "4D 运动物体全景分割的典范空间表示", "title_en": "Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects", "authors": "Manuel Gomes,Bogdan Raducanu,Miguel Oliveira", "background": "在计算机视觉中，运动关节物体的识别存在重大挑战，因为现有方法通常忽略了这些物体的动态特性。尽管使用4D时序数据和全景分割尚未广泛探索，且缺乏标准数据集进一步阻碍了该领域的发展。Artic4D是一个利用PartNet Mobility创建的新数据集，并补充了合成传感器数据，带有4D全景标注和关节参数。", "innovation": "该研究提出了CanonSeg4D，这是一种新的4D全景分割框架。该方法显式估计每个帧的偏移量，将观测到的物体部分映射到学习的典范空间，从而增强部分级分割。该框架利用典范表示来实现对象部分在连续帧中的一致对齐。实验结果表明，CanonSeg4D在复杂场景下的全景分割准确性方面优于现有方法，突出了时序建模和典范校准在动态物体理解中的有效性。", "conclusion": "研究成果表明，CanonSeg4D在4D运动物体全景分割中表现优异，其方法显著提高了分割精度。这些发现为未来4D运动物体感知的进步铺平了道路。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05369", "html_url": "https://arxiv.org/abs/2511.05369", "title": "密集动作描述", "title_en": "Dense Motion Captioning", "authors": "Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota", "background": "近年来，3D人类动作和语言集成的进展主要集中在文本到动作生成任务上，而动作理解任务则相对忽略了。当前的数据集在提供详细的时间注解方面存在不足，且主要用于标注短序列的动作。", "innovation": "本文提出了密集动作描述任务(Dense Motion Captioning)，旨在通过3D人类运动序列中定位和描述动作。为解决数据集的不足，本研究构建了一个包含6万个动作序列的新数据集Complex Motion Dataset (CompMo)，每个序列都由至少两个到十个动作组成，具有精确的时间边界。此外，还提出了结合大规模语言模型和简单动作适配器的DEMOModel，能够生成详细的时间上下文Grounded描述。", "conclusion": "实验表明，相对于现有方法，DEMOModel在CompMo数据集及其改编基准测试中表现出明显的优势，为未来研究3D动作理解和描述提供了稳健的基础。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05394", "html_url": "https://arxiv.org/abs/2511.05394", "title": "AI辅助AR装配：基于对象识别的增强现实装配计算机视觉", "title_en": "AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly", "authors": "Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin", "background": "当前，装配过程中的对象识别主要依赖于人工搜索、分类和标记等手动操作，这不仅耗时而且容易出错。本文介绍了一种结合了深度学习的物体识别技术与增强现实技术的装配工作流程，用于识别不同的装配组件并提供逐步安装指示。", "innovation": "该系统使用基于深度学习的物体识别技术来识别装配组件，并在物理空间中以边界框的形式显示组装步骤和组件位置。通过实时连接装配步骤与相应组件的位置，该系统消除了每次装配前手动搜索、分类和标记不同组件的需要。", "conclusion": "研究通过展示乐高雕塑的组装案例，证明了使用物体识别技术实现增强现实辅助装配的可行性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05404", "html_url": "https://arxiv.org/abs/2511.05404", "title": "在严重非结构化环境中的基础模型多模态环回检测", "title_en": "Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments", "authors": "Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato", "background": "在GNSS信号受限的环境中，例如行星探索场景下，SLAM算法的环回检测（loop closure detection）尤为关键。由于视觉匹配常因混叠和纹理不佳而失败，而基于LiDAR的方法则受到稀疏性和歧义性的限制。", "innovation": "该论文提出了一种名为MPRF的多模态管道，利用基于变换器的基础模型处理视效和LiDAR数据，实现遥感环境下的鲁棒环回检测。MPRF集成两阶段视效检索策略和6-DoF姿态估计，并结合了DINOv2特征与SALAD聚合进行候选筛查，以及使用SONATA基于LiDAR描述符进行几何验证。实验结果表明，MPRF在精准度上优于现有最先进的检索方法，并增强低纹理区域的姿态估计鲁棒性。", "conclusion": "通过提供可用于SLAM后端的可解释对应，MPRF在准确性、效率和可靠性之间实现了良好的权衡，展示了基础模型在统一地点识别和姿态估计方面的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05393", "html_url": "https://arxiv.org/abs/2511.05393", "title": "PreResQ-R1: 通过偏好-响应解耦强化学习实现精细粒度的排名和评分强化学习的视觉质量评估", "title_en": "PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization", "authors": "Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han", "background": "视觉质量评估（QA）旨在预测人类对视觉保真度的感知判断。尽管最近的多模态大型语言模型（MLLMs）在解析图像和视频质量上展现出潜力，但现有方法主要依赖于监督微调或仅排名的目标，导致浅薄的推理、评分校准不足和跨域泛化能力有限。", "innovation": "提出了一种偏好-响应解耦的强化学习框架PreResQ-R1，该框架在单一推理驱动优化方案中统一了绝对评分回归和相对排名一致性。与前视觉质量评估方法不同，PreResQ-R1引入了一种双分支奖励形式，分别建模样本内响应连贯性和样本间偏好一致性，通过群体相对策略优化（GRPO）优化。此外，还设计了一种全局时空和局部空间数据流策略，以扩展到视频质量评估。", "conclusion": "借助仅6K图片和28K视频的强化微调，PreResQ-R1在10个图像质量评估（IQA）和5个视频质量评估（VQA）基准中实现了现有最佳结果，并分别在SRCC和PLCC指标上超越了5.30%和2.15%。除了量化收益，还生成了与人类感知一致的推理线索，揭示了质量判断背后的感知提示。开源代码和模型可获取。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05421", "html_url": "https://arxiv.org/abs/2511.05421", "title": "共享学习知识库以估计卷积滤波器参数进行持续图像恢复", "title_en": "Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration", "authors": "Aupendu Kar,Krishnendu Ghosh,Prabir Kumar Biswas", "background": "持续学习在深度学习领域是一个正在发展的课题，旨在让模型能够不断学习新的任务，而不忘记已有经验。尽管在这一领域已经取得了许多进展，但很少有工作针对图像恢复问题进行持续学习的研究。处理大型图像和各种退化方式下性能的差异性，使得图像恢复领域面临独特挑战。现有方法通常需要对新任务进行剧烈的人工架构修改，从而导致计算负担加大。基于正则化的方法不适合于图像恢复场景，因为不同的恢复挑战需要不同类型的特征处理。", "innovation": "本文提出了一个简单卷积层的修改方法，以适应之前恢复任务的知识，而不改变主要的骨干架构。这使得该方法可以无缝地应用到任何深层架构中，而不需要任何结构性的更改。与其他方法不同，本文表明，作者的模型可以在显著增加训练参数数量的情况下，而不显著增加计算开销或推断时间。实验验证表明，新的恢复任务可以在不损害现有任务性能的情况下被引入。此外，通过适配来自先前恢复任务构建的知识库中的知识，可以提高新恢复任务的性能。", "conclusion": "研究结果证明，新的恢复任务可以在不损害现有任务性能的前提下被引入，而且通过适配知识库中的先前知识，可以进一步改进新恢复任务的性能。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05449", "html_url": "https://arxiv.org/abs/2511.05449", "title": "3D点云变换器架构实际上需要多少令牌？", "title_en": "How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?", "authors": "Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda", "background": "近年来，3D点云变换器在语义分割和重建等任务中取得了最先进的成果，但这些模型通常依赖于密集的令牌表示，在训练和推理过程中会产生高昂的计算和内存成本。", "innovation": "研究发现，令牌具有极大的冗余性，导致效率低下。为此，作者提出了gitmerge3D，这是一种全局信息驱动的图令牌合并方法，可以将令牌数量最多减少90-95%，同时保持竞争力。这项研究挑战了更多令牌必然能获得更好性能的假设，揭示了当前许多模型过度令牌化且未充分优化以确保可扩展性。作者在多个3D视觉任务上验证了该方法，并展示了计算效率的一致性改进。这是首次评估大型3D变换器模型的冗余性，为开发更高效的3D基础架构提供了见解。", "conclusion": "本文首次评估了大规模3D变换器模型的冗余性，并通过提供多个3D视觉任务上的结果，展示了碱基架构效率的潜在提升。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05461", "html_url": "https://arxiv.org/abs/2511.05461", "title": "Copernicus 卫星在灾害响应中的潜力：从Sentinel-1和Sentinel-2获取建筑破坏信息", "title_en": "The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2", "authors": "Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler", "background": "自然灾害需要迅速进行损失评估以指导人道主义响应。本文探讨了Copernicus计划中分辨率的地球观测图像是否能支持建筑破坏评估，这可以弥补高分辨率图像可用性有限的问题。", "innovation": "提出了一个新的数据集xBD-S12，包含10,315个灾难前后图像配对，来自Sentinel-1和Sentinel-2，与现有的xBD基准数据集对齐。实验显示在很多灾难场景中，虽然地面采样距离为10米，但仍能较好地检测和映射建筑破坏情况。发现复杂性建筑结构并没有给损坏映射带来显著优势，更复杂的模型架构在未见灾难上的泛化能力较弱，而地理空间基础模型也没有带来实际益处。", "conclusion": "研究表明Copernicus图像是一个可行的数据源，用于快速、大范围的损失评估，并可能在高分辨率图像之外发挥重要作用。作者开放了xBD-S12数据集、代码和训练模型，以支持进一步研究。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05464", "html_url": "https://arxiv.org/abs/2511.05464", "title": "基于面部年龄聚合的Photo Dating", "title_en": "Photo Dating by Facial Age Aggregation", "authors": "Jakub Paplham,Vojtech Franc", "background": "该研究介绍了使用面部信息来估算照片拍摄年份的方法，特别是在电影剧照中。为了促进这一研究，论文发布了一个名为CSFD-1.6M的新数据集，包含超过160万张标有人脸的照片，这些照片主要是电影剧照，并附有关于身份和出生年份的标注。与以往不同的是，该数据集能够在单张照片中提供多人标注，这使得研究能够探索多张人脸信息的综合利用。", "innovation": "论文提出了一种概率框架，该框架通过结合现代面部识别和年龄估计模型的视觉证据，以及职业生涯时间先验信息，来推断照片的拍摄年份。这种方法显著优于基于场景的基线，并且在含有多个可辨识个体的照片上尤其有效。", "conclusion": "实验结果表明，通过多个人脸信息的综合，可以持续提高性能，且该方法在包含多个可辨识个体的照片上表现尤为突出。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05403", "html_url": "https://arxiv.org/abs/2511.05403", "title": "PALM：用于学习多主体手部先验的_dataset_和基线", "title_en": "PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior", "authors": "Zicong Fan,Edoardo Remelli,David Dimond,Fadime Sener,Liuhao Ge,Bugra Tekin,Cem Keskin,Shreyas Hampali", "background": "人类手部可以通过抓握物体、手势表达信号和通过触觉共享情感，体现了其独特的功能。然而，从图片创建高质量的个性化手部数字模型仍然是一个挑战，因为手部的几何形状、外观和活动范围复杂，特别是在不受限制的光照条件下和有限的视角下。这一挑战的原因之一是缺乏能够提供准确的3D几何形状、高分辨率的多视角图像以及多样化的受试者的数据集。研究表明，现有的数据集在提供这些元素方面存在局限性。因此，迫切需要一个新的大尺度数据集来解决上述问题，并为此类研究提供有价值的实际资源", "innovation": "本文提出PALM数据集，包含263名受试者的13,000个高质量的手部扫描和90,000个多视角图像。这些图像展示了丰富的肤色、年龄和几何变异性。PALM数据集特点突出，包含了多样化的手部数字表示，这将为手部建模及相关研究提供宝贵的真实世界资源。此外，通过使用基于物理的逆渲染方法学习多主体手部几何和材料属性，本文还提出了一个基准模型PALM-Net，该模型能在单张图片上实现逼真且可重新照明的手部数字模型个性化", "conclusion": "PALM数据集的规模和多样性对于手部建模及其他相关研究具有重要意义。通过PALM数据集和PALM-Net模型，该研究为真实手部建模提供了有价值的先验知识，并为该领域的未来研究奠定了基础"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05432", "html_url": "https://arxiv.org/abs/2511.05432", "title": "联合文本到音频-视觉合成的共享潜在表示", "title_en": "Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis", "authors": "Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel", "background": "该论文旨在解决将文本转化为具有自然表情的说话人脸的问题。传统方法通常需要真实的音频作为输入，但这种方法在实际应用中受到了限制，尤其是在数据获取和保护隐私方面。因此，研究者们开始探索如何仅通过文本生成自然且表达丰富的语音及面部动作。现有的方法中，通常包括两个关键步骤：文本到语音（Text-to-Speech, TTS）和语音到面部动画（Speech-to-Face Animation）。然而，这些方法往往难以处理真实语音和合成语音之间的分布差异，导致结果不自然或不准确。", "innovation": "该论文提出了一种利用HierSpeech++的潜在语音表示的文本到说话人脸合成框架。框架引入了一个Text-to-Vec模块，通过Wav2Vec2嵌入生成语音向量，该向量同时作为生成语音和面部动画的条件。为了处理干净语音和TTS预测特征之间的分布变化，提出了两阶段训练方法：预训练在Wav2Vec2向量上进行，再在TTS输出上进行微调。这种方法能够实现更精确的音频-视觉对齐，保持说话者的身份，生成自然且富有表情的语音和同步的面部动作，所有这些都不需要真实的音频。", "conclusion": "实验表明，通过TTS预测的潜在特征进行条件设置优于级联管道，能够提升唇同步性能和视觉真实性。该研究提出的方法在文本到音频-视觉合成领域取得了显著的进步，有望在未来的研究中进一步优化和完善。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05467", "html_url": "https://arxiv.org/abs/2511.05467", "title": "EventFlow：两相沸腾流型的实时神经形态事件驱动分类", "title_en": "EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes", "authors": "Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won", "background": "流体沸腾是一种高效的热传递机制，能够有效地散热并且温差小，是理想的热管理方法。然而，流体流动模式的突然转变会导致热性能和系统可靠性受损，因此需要准确且低延迟的实时监控。传统的光图像方法由于计算需求高且时间分辨率不足，无法捕捉到瞬态流动行为，这促使研究者寻求新的解决方案。为了克服这些局限性，本文提出了一种基于神经形态传感器信号的实时框架，用于流体流动模式分类。神经形态传感器能够检测像素级别的亮度变化，通常与边缘处的运动相匹配，允许快速且高效地检测，无需全帧重建，提供基于事件的信息。", "innovation": "本文提出了一种新的实时框架，基于神经形态传感器信号，用于两相沸腾流体流动模式分类。相较于传统的图像数据方法，使用事件数据的方法对动态流特征更敏感，从而提高了分类模型的性能。具体而言，事件驱动的长短期记忆模型（Event-based LSTM）提供了最佳的准确性和速度平衡，分类准确率为97.6%，处理时间为0.28毫秒。此外，所提出的异步处理管道支持连续、低延迟预测，并通过多数投票机制实现稳定的输出，为实验控制和智能热管理提供可靠实时反馈。", "conclusion": "该研究开发了一种实时框架，能够通过神经形态传感器信号进行两相沸腾流体流动模式的快速分类。模型利用事件数据而非传统帧数据，显著提高了应用的实时性和准确性。实验结果显示，这种方法在保持高准确率的同时，显著降低了处理延迟，提供了可靠的实时反馈，为未来的热管理系统实现智能控制奠定了基础。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04718", "html_url": "https://arxiv.org/abs/2511.04718", "title": "Ada-FCN：基频-耦合网络在fMRI脑部疾病分类中的自适应频域方法", "title_en": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "authors": "Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang", "background": "静息态fMRI已成为分类脑部疾病和建立大脑功能连接网络的重要工具，通过跨脑区追踪BOLD信号。然而，现有的模型大多忽略了神经元振荡的多频特性，将BOLD信号视为单一时间序列，而忽略了神经疾病实际往往表现为特定频率带内的紊乱这一点，限制了诊断的敏感性和特异性。尽管有些方法尝试整合频率信息，但通常依赖于预定义的频率带，这可能无法捕捉个体变异或疾病特异性改变。", "innovation": "本文提出了一种新的框架——自适应级联分解（Adaptive Cascade Decomposition，简称ACD），用于学习每个脑区相关的任务相关频率子带，以及频率耦合连接学习（Frequency-Coupled Connectivity Learning，简称FCL），以在统一功能网络中捕捉内频带及复杂跨频带交互。这种统一网络指导了一个统一图卷积网络（Unified-GCN）中的新的消息传递机制，生成更精细的节点表示以进行诊断预测，实验结果表明该方法优于现有方法。", "conclusion": "在ADNI和ABIDE数据集上的实验结果表明，与当前方法相比，Ada-FCN具有更优异的性能。代码可在this https URL下载。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05491", "html_url": "https://arxiv.org/abs/2511.05491", "title": "视觉空间调优", "title_en": "Visual Spatial Tuning", "authors": "Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao", "background": "人类类通用智能的核心在于从视觉输入中捕捉空间关系。尽管已有研究通过添加额外的专家编码器来增强视觉语言模型（VLMs）的空间意识，但这通常会带来额外的工作量并损害其通用能力。因此，需要一个全面的框架来增强模型的空间能力，从空间感知到空间推理，而不影响其一般能力。", "innovation": "本文提出了视觉空间调优（VST），这是一种综合框架，旨在培养VLMs与人类类似的视觉空间能力。VST包括构建大规模数据集VST-P，包含410万样本，覆盖19个单视图、多图像和视频的技能，以及一个精炼的数据集VST-R，包含135K样本，用于空间推理。通过监督微调建立基础空间知识，然后使用强化学习进一步提高空间推理能力。", "conclusion": "通过VST，提出的模型在多个空间基准上取得了最先进的结果，包括MMSI-Bench上的34.8%和VSIBench上的61.2%。这种空间调优范式可以显著增强视觉语言动作模型，为更贴近物理现实的人工智能铺平道路。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05477", "html_url": "https://arxiv.org/abs/2511.05477", "title": "GroupKAN: 基于分组样条KAN建模重新思考非线性以实现高效医学图像分割", "title_en": "GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation", "authors": "Guojie Li,Anwar P.P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang", "background": "医学图像分割需要准确、轻量且可解释的模型。卷积架构缺乏适应性的非线性和透明的决策机制，而Transformer架构则受到二次复杂性和不透明注意力机制的限制。U-KAN通过使用Kolmogorov-Arnold Networks解决了这些挑战，实现了比卷积和基于注意力方法更高的准确度，比Transformer变体更少的参数，并在常规方法中提高了可解释性。然而，由于全通道变换，其O(C^2)复杂度限制了其随着通道数量增加时的扩展性。为了克服这一问题，引入了GroupKAN轻量分割网络，结合了两个新颖的结构化功能模块：(1)分组KAN变换，将通道分成G组进行多元样条映射，将复杂度降低到O(C^2/G)；(2)分组KAN激活，对每个通道组应用共享的样条映射，以实现高效的逐位非线性。", "innovation": "在三个医学基准数据集(BUSI, GlaS, CVC)上，GroupKAN实现了平均IoU为79.80%，超过了U-KAN的1.11%，参数量仅为U-KAN的47.6%（3.02M vs 6.35M），显示出更高的可解释性。GroupKAN通过引入分组样条KAN方法，重新思考了非线性的处理方式，实现了更高效、更轻量的医学图像分割模型。", "conclusion": "GroupKAN显著提升了医学图像分割的准确性和可解释性，同时降低了模型复杂度和参数数量，展示了其在医学图像分析领域的潜力和优势。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05009", "html_url": "https://arxiv.org/abs/2511.05009", "title": "UHDRes: 超高清图像恢复通过双域解耦光谱调制", "title_en": "UHDRes: Ultra-High-Definition Image Restoration via Dual-Domain Decoupled Spectral Modulation", "authors": "S. Zhao(1),W. Lu(1 and 2),B. Wang(1),T. Wang(3),K. Zhang(4),H. Zhao(1) ((1) College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, China, (2) Nasdaq, St. John's, Canada, (3) vivo Mobile Communication Co., Ltd, Shanghai, China, (4) College of Engineering and Computer Science, Australian National University, Australia)", "background": "超高清(UHD)图像往往受到严重的退化影响，如模糊、雾霾、雨滴或低光照条件，这些由于高分辨率和计算需求带来的挑战使得图像恢复变得困难。", "innovation": "提出了UHDRes，一种新颖的轻量级双域解耦光谱调制框架用于UHD图像恢复。该框架通过轻量级的光谱域调制显式建模幅度谱，通过空间域精修隐式恢复相位。引入了空间光谱融合机制，首先利用多尺度上下文聚合层提取局部和全局的空间特征，然后以解耦的方式执行光谱调制，这在频域中显式增强幅度特征，通过空间精修隐式恢复相位信息。此外，设计了一种共享门控前馈网络，以共享参数卷积和自适应门控机制促进特征交互。", "conclusion": "在五个公开的UHD基准上的广泛实验比较表明，我们的UHDRes仅使用40万参数获得了最先进的恢复性能，同时显著降低了推理延迟和内存使用率。相关的代码和模型可在给定的链接处获取。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05474", "html_url": "https://arxiv.org/abs/2511.05474", "title": "基于细粒度对象检测的语义导向自然语言与视觉融合的跨模态交互", "title_en": "Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection", "authors": "Xian-Hong Huang,Hui-Kai Su,Chi-Chia Sun,Jun-Wei Hsieh", "background": "本文介绍了一种结合语义导向的自然语言处理和高级视觉识别骨干网络，用于细小物体检测的最新方法。该方法通过将BERT语言模型与基于CNN的并行残差双融合特征金字塔网络（PRB-FPN-Net）结合，利用ELAN、MSP和CSP等创新骨干架构优化特征提取和融合。通过使用词形还原和微调技术，系统将文本输入中的语义线索与视觉特征对齐，提高了对小而复杂的物体的检测精度。实验验证使用COCO和Objects365数据集证明了该模型的优越性能。在COCO2017验证集上，其平均精度（AP）达到52.6%，显著优于YOLO-World，同时保持了与基于Transformer的模型（如GLIP）一半的参数消耗。对于不同的骨干网络，如ELAN、MSP和CSP的多次测试进一步确保了多尺度对象的有效处理和资源受限环境中的可扩展性和鲁棒性。这项研究强调了将自然语言理解与先进的骨干架构集成的潜力，为对象检测的准确度、效率和适应现实挑战能力设立了新标准。", "innovation": "1. 合并语义导向的自然语言处理和高级视觉识别骨干网络；2. 利用ELAN、MSP和CSP等创新骨干架构优化特征提取和融合；3. 通过词形还原和微调技术实现文本和视觉特征对齐；4. 实现了高效处理多尺度对象的能力，尤其适用于资源受限的环境；5. 达到显著优于现有模型的性能，如COCO2017验证集上的52.6%的平均精度。", "conclusion": "本研究表明，将自然语言理解与先进的骨干架构集成是提高细粒度对象检测性能的关键，这为未来的跨模态交互和对象检测任务设立了高基准。这种结合不仅提高了准确性，还增强了模型在多种环境下的鲁棒性和可扩展性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04834", "html_url": "https://arxiv.org/abs/2511.04834", "title": "基于提示的安全指导对未学习的文本到图像扩散模型无效", "title_en": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models", "authors": "Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon", "background": "随着生成模型在文本到图像生成领域的进展，提供恶意输入文本提示时生成有害内容的问题引起了关注。目前有两大解决方案，一是对模型进行微调以去除有害概念；二是不经过训练的指导方法，通过使用负面提示来防止生成有害内容，但这两者结合时效果不明显甚至可能降低防御性能，表明两种方法之间存在不兼容性，阻碍了两者结合的有效性。", "innovation": "本文提出了一种概念简单但实验上非常 robust 的方法，即将 training-free 方法中使用的负面提示替换为通过概念反转获得的隐式负面嵌入。该方法无需修改任何现有解决方案，且可以轻松集成到现有的工作流程中。实验结果显示，该方法在裸体和暴力基准测试中有效，能够提高防御成功率，同时保留输入提示的核心语义。", "conclusion": "本文提出的方法解决了不同防御策略之间的不兼容性问题，通过简单的设计理念和有效的实验验证，实现了对未学习文本到图像扩散模型的有效防护，且不会影响输入提示的基本语义。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04699", "html_url": "https://arxiv.org/abs/2511.04699", "title": "跨语言SynthDocs：任何语言到阿拉伯OCR和文档理解的大规模合成语料库", "title_en": "Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding", "authors": "Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno", "background": "光学字符识别（OCR）和文档理解（DU）领域中缺乏阿拉伯语资源，特别是在阿拉伯文档的复杂性方面，如字体、表格布局和数据图表等。现有数据集规模有限且不全面，难以满足多语言文档分析研究的需求", "innovation": "创建了跨语言SynthDocs语料库，包含超过250万样本，包括150万文本数据、27万个完全注释的表格以及数万个基于真实数据的图表。该语料库利用真实的扫描背景、双语布局和带音符的字体来捕捉阿拉伯文档的复杂性，并提供多样化的图表和表格渲染样式。通过在SynthDocs上微调Qwen-2.5-VL模型，在多个公开的阿拉伯语基准测试中，OCR的单词错误率（WER）和字符错误率（CER）得到持续改善，同时表格编辑距离相似度（TEDS）和图表提取得分（CharTeX）在其他模式下也有所提升", "conclusion": "SynthDocs为多语言文档分析研究提供了可扩展、视觉真实的资源，支持跨语言OCR和文档理解任务，增强了模型在这方面的性能"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05020", "html_url": "https://arxiv.org/abs/2511.05020", "title": "DAFM: 动态自适应融合在组合图像检索中的多模型协作", "title_en": "DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval", "authors": "Yawei Cai,Jiapeng Mi,Nan Ji,Haotian Rong,Yawei Zhang,Zhangti Li,Wenbin Guo,Rensong Xie", "background": "组合图像检索（CIR）任务涉及使用一张参考图像和描述修改的文字来从大数据库中检索目标图像。现有的大多数方法依赖单一模型来执行特征融合和相似性匹配。然而，这种单一模型的方法存在两个主要挑战：一方面，单一模型难以同时捕捉到图像的宏观和微观细节；另一方面，缺乏动态权重分配使得模型无法有效地利用各自的优势，从而导致嵌入向量偏离目标，影响CIR中的最近邻搜索。", "innovation": "为了应对上述挑战，本文提出了动态自适应融合（DAFM），这是一种多模型协作的新方法，通过利用不同模型的优势并适配性地调整它们的贡献，从而最大化检索准确率，确保性能提升与融合顺序无关，突出显示了其鲁棒性。实验结果表明，在CIRR和FashionIQ基准测试中，DAFM方法分别实现了93.21的Recall@10和84.43的Rmean，在FashionIQ基准测试中取得了平均67.48的Rmean，大幅度超越了近期的基线方法，最多提高了4.5%。这些结果验证了动态多模型协作在CIR中的有效性和普适性。", "conclusion": "动态自适应融合在多模型协作中为组合图像检索提供了一种有效且通用的解决方案，显著提升了检索准确率，确保了性能提升的稳定性和独立性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04892", "html_url": "https://arxiv.org/abs/2511.04892", "title": "LG-NuSegHop: 一种从局部到全局的自监督管道用于细胞核实例分割", "title_en": "LG-NuSegHop: A Local-to-Global Self-Supervised Pipeline For Nuclei Instance Segmentation", "authors": "Vasileios Magoulianitis,Catherine A. Alexander,Jiaxin Yang,C.-C. Jay Kuo", "background": "细胞核分割是病理图像解读的基本任务，有助于揭示分子模式，进而用于疾病或癌症诊断。然而，这是一项繁琐的任务，需要专业医生的技能。不同器官组织和采集过程中的细胞核变化巨大，挑战着这一任务的自动化。此外，数据标注成本高昂，因此深度学习模型难以在外科或不同领域泛化。", "innovation": "本文提出了一种名为 Local-to-Global NuSegHop (LG-NuSegHop) 的自监督管道，它是基于问题先验知识和分子生物学的。该管道包含三个独立模块：（1）一组局部处理操作以生成伪标签，（2）NuSegHop，一种新颖的数据驱动特征提取模型，（3）一组全局操作以处理 NuSegHop 的预测。尽管该管道未使用手动标注的训练数据或领域适应，但在其他数据集上仍保持了良好的泛化性能。在三个公开可用的数据集上进行的实验表明，该方法在自我监督和弱监督方法中表现出色，且在完全监督方法中具有竞争力。每个模块也都透明且可解释，有助于医学解读。", "conclusion": "实验结果表明，LG-NuSegHop 相较于其他自我监督和弱监督方法，具有更好的性能，且与完全监督方法具有竞争力，同时管道中的每个模块都具有透明和解释性的特点。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05102", "html_url": "https://arxiv.org/abs/2511.05102", "title": "量化转移的黑盒攻击风险", "title_en": "Quantifying the Risk of Transferred Black Box Attacks", "authors": "Disesdi Susanna Cox,Niklas Bunzel", "background": "神经网络在安全相关产品中的广泛应用提升了对其抗对抗攻击能力的关注。特别是对于转移对抗攻击，其风险评估仍然具有挑战性。新兴的法规和标准强调了安全的重要性，因此组织需要能够可靠地量化与这些攻击相关的风险。", "innovation": "本文提出了一种针对转移黑盒攻击的有针对的抗御测试框架，该框架利用基于Centered Kernel Alignment (CKA)相似性的代理模型，通过选择与目标模型在CKA相似度上有高和低表现的代理模型，优化对抗子空间的覆盖率。风险估计采用了基于回归的估计器，为组织提供具体的、可操作的风险量化。", "conclusion": "此测试框架有助于组织更准确地量化对抗攻击风险，通过使用代理模型进行更有针对性的测试，提升了对高维度输入空间的抗御测试效果。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05360", "html_url": "https://arxiv.org/abs/2511.05360", "title": "使用长平滑B样条的神经图像抽象", "title_en": "Neural Image Abstraction Using Long Smoothing B-Splines", "authors": "Daniel Berio,Michael Stroh,Sylvain Calinon,Frederic Fol Leymarie,Oliver Deussen,Ariel Shamir", "background": "该研究将平滑的B样条融入标准可微分矢量图形（DiffVG）管道中，通过线性映射实现路径生成的平滑性和灵活性。通过利用基于导数的平滑成本，能够在保真度与简洁性之间进行参数化控制，并且也能够在几何和图像空间中实现风格化控制。该方法与最新的矢量图形生成和矢量化方法兼容。", "innovation": "提出了一种新的管道，使用平滑的B样条，在保真度与简洁性之间进行动力学控制，同时在几何和图像空间中也具有风格化控制能力。该方法适用于矢量图形生成和矢量化方法的 recent 方法，并展示了该方法在四个应用场景中的多样性：样式化的空间填充路径生成、基于线条的图像抽象、封闭区域的图像抽象以及样式化的文本生成。", "conclusion": "实验结果表明，通过使用长平滑B样条，该方法能够生成平滑和任意长度的路径，适用于各种风格化的矢量图形生成场景。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05183", "html_url": "https://arxiv.org/abs/2511.05183", "title": "PySlyde：一种轻量级开源病理预处理工具", "title_en": "PySlyde: A Lightweight, Open-Source Toolkit for Pathology Preprocessing", "authors": "Gregory Verghese,Anthony Baptista,Chima Eke,Holly Rafique,Mengyuan Li,Fathima Mohamed,Ananya Bhalla,Lucy Ryan,Michael Pitcher,Enrico Parisini,Concetta Piazzese,Liz Ing-Simmons,Anita Grigoriadis", "background": "人工智能（AI）在病理学中的应用正推动精准医学的发展，通过提高诊断、治疗规划和患者结果。数字化全视野图像（WSIs）捕捉到重要的空间和形态信息，对于理解疾病生物学至关重要，但其 gigapixel 规模和变异性带来了标准化和分析的重大挑战。可靠的预处理流程，包括组织检测、网格划分、染色归一化和注释解析，至关重要，但往往受限于流程的碎片化和不一致性。", "innovation": "我们提出了一个基于 OpenSlide 构建的轻量级、开源 Python 工具包 PySlyde，以简化和标准化 WSIs 的预处理。PySlyde 提供了一个直观的 API，支持载片、注释管理、组织检测、分格和特征提取，并与现代病理学基础模型兼容。通过统一这些过程，PySlyde 简化了 WSIs 的预处理，增强了可重复性，并加速了生成 AI 准备数据集的过程，使研究人员能够专注于模型开发和下游分析。", "conclusion": "PySlyde 通过统一病理图像的预处理流程，提高了工作效率、数据的可重复性和生成可供AI使用的数据集的速度，同时降低了技术门槛，促进了病理领域的研究和发展。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05462", "html_url": "https://arxiv.org/abs/2511.05462", "title": "SiamMM：深度无监督学习的混合模型视角", "title_en": "SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning", "authors": "Xiaodong Wang,Jing Huang,Kevin J Liang", "background": "最近的研究表明，基于聚类的方法在半监督和无监督学习中取得了显著的效果。然而，聚类的应用通常是基于直觉的，最优的方法仍然不明确。", "innovation": "本文建立了这些无监督聚类方法与统计学中的经典混合模型之间的联系，通过这一框架展示了对这些聚类方法的显著改进，进而开发出了名为SiamMM的新模型。该方法在各种半监督学习基准测试中达到了最先进的性能。", "conclusion": "通过学习获得的聚类显示出与未见的真实标签高度相似，揭示了潜在的标签错误实例。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05397", "html_url": "https://arxiv.org/abs/2511.05397", "title": "EveryDayVLA：一种经济实惠的视觉-语言-动作模型", "title_en": "EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation", "authors": "Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson", "background": "视觉-语言-动作（VLA）模型能够直接将视觉输入和语言指令映射到机器人动作，但在实际应用中往往依赖昂贵的硬件，并且在处理新颖或杂乱场景时存在困难。", "innovation": "提出了一个成本低于300美元、具有6自由度的手动操作器EverydayVLA，该操作器适用于轻负载和工作区。该模型能够输出离散和连续动作，并且通过适应性时间窗集成监测运动不确定性，触发实时重规划以确保安全可靠的运行。在LIBERO数据集上，EverydayVLA达到了最先进的成功率，在现实世界测试中，相比之前的方法提高了49%的在分分布性能和34.9%的非分布数据性能。", "conclusion": "结合最先进的VLA模型与经济实惠的硬件，EverydayVLA使机器人基础模型的访问更加民主化，并为家庭和研究实验室的经济使用铺平了道路。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.17643", "html_url": "https://arxiv.org/abs/2311.17643", "title": "Thera: 无需混叠的物理精确任意尺度超分辨率方法", "title_en": "Thera: Aliasing-Free Arbitrary-Scale Super-Resolution with Neural Heat Fields", "authors": "Alexander Becker,Rodrigo Caye Daudt,Dominik Narnhofer,Torben Peters,Nando Metzger,Jan Dirk Wegner,Konrad Schindler", "background": "当前用于任意尺度单图像超分辨率（ASR）的方法使用神经场表示连续信号，可以在任意分辨率下进行采样。然而，神经场的逐点查询与像素的点扩展函数（PSF）不自然地匹配，这可能导致超分辨率图像中混叠现象。现有的方法试图通过在每个缩放因子处逼近场的积分版本来减轻这一问题，这既牺牲了保真度也降低了泛化能力。", "innovation": "本文引入了神经热场，这是一种全新的神经场表达，能够天然地模拟物理精确的PSF。这一表达式使在任何期望的输出分辨率下实现分析正确的抗混叠成为可能，并且--与超采样相比--不会带来额外的成本。在此基础上，我们提出了Thera，一个端到端的ASR方法，显著优于现有方法，同时具有更高的参数效率和较强的理论保证。", "conclusion": "Thera方法相比现有方法在任意尺度的超分辨率中表现出色，具有更强的理论支持和参数效率。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05489", "html_url": "https://arxiv.org/abs/2511.05489", "title": "TimeSearch-R: 自适应长时序视频理解的自我验证强化学习的自适应时空搜索", "title_en": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning", "authors": "Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She", "background": "时空搜索旨在从成千上万的帧中识别出与给定查询相关的最小帧集，作为准确理解长视频的基础。现有的方法试图逐步缩小搜索范围，但这些方法通常依赖于人工设计的搜索过程，缺乏端到端优化以学习最优的搜索策略。", "innovation": "本文提出了TimeSearch-R，将时空搜索重新定义为交错的文本-视频思考过程，并通过强化学习(RL)无缝地将视频片段的搜索融入推理过程中。为了解决通过应用RL训练方法，如组相对策略优化(Grpo)到视频推理可能导致的不监督中间搜索决策，进而导致对视频内容探索不足和逻辑推理不一致的问题，提出了带有完整自检验的Grpo(Grpo-CSV)。此外，还构建了专门的数据集，用于Sft冷启动和Grpo-CSV的RL训练，过滤掉具有弱时间依赖性的样本以提高任务难度并增强时空搜索能力。", "conclusion": "大量实验表明，TimeSearch-R在时空搜索基准（如Haystack-LVBench和Haystack-Ego4D）以及长视频理解基准（如VideoMME和MLVU）上取得了显著改进。特别是在LongVideoBench上，TimeSearch-R相较于基础模型Qwen2.5-VL提高了4.1%，相较高级视频推理模型Video-R1提高了2.0%。相关的代码已发布。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.20105", "html_url": "https://arxiv.org/abs/2403.20105", "title": "FreeSeg-Diff：基于扩散模型的无需训练的开放词汇分割", "title_en": "FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion Models", "authors": "Barbara Toniella Corradini,Mustafa Shukor,Paul Couairon,Guillaume Couairon,Franco Scarselli,Matthieu Cord", "background": "基础模型在许多领域和任务中都展示了前所未有的能力。例如，CLIP模型被广泛用于跨模态表示，而文本到图像的扩散模型被认为是生成逼真图像的领先模型。这些生成性模型在大规模数据集上进行训练，以获得强大的内部空间表示。本文探索了此类表示在图像生成之外的潜在好处，特别是在密集视觉预测任务中。研究集中于图像分割任务，通常是通过在封闭词汇数据集上进行训练，并使用像素级注解来解决的。为避免注释成本或训练大型扩散模型，本文的设置限定为了零样本且无训练的方案。", "innovation": "本文提出了一种名为FreeSeg-Diff的方法，使用扩散模型实现无需训练的开放词汇分割。该方法利用不同的较小规模的开源基础模型进行零样本开放词汇分割。通过将图像分别传递给captioner模型（如BLIP）和扩散模型（如Stable Diffusion Model），生成文本描述和视觉表示。特征聚类和二值化以获得每种物体的类别无感知掩码。使用CLIP模型将这些掩码映射到文本类，以支持开放词汇。最后，通过一个精细步骤来获得更精确的分割掩码。该方法在Pascal VOC和COCO数据集上优于基于训练的方法，并且与最近的弱监督分割方法的结果具有竞争力。实验结果表明，扩散模型特征相比其他预训练模型具有优势。", "conclusion": "FreeSeg-Diff方法无需任何训练过程，在Pascal VOC和COCO数据集上优于基于训练的方法，并且与最近的弱监督分割方法的性能相当，展示了扩散模型特征相比于其他预训练模型的优势。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.12805", "html_url": "https://arxiv.org/abs/2407.12805", "title": "Dark Transformer：低光照条件下的一种视频变换器进行动作识别", "title_en": "Dark Transformer: A Video Transformer for Action Recognition in the Dark", "authors": "Anwaar Ulhaq", "background": "在计算机视觉中，识别不良光照条件下的人类动作是一项重大挑战，广泛应用于视觉监控和夜间驾驶等领域。现有的方法分别处理动作识别和暗光增强，限制了端到端学习时空表示以进行视频动作分类的潜力。为此，本文介绍了一种新的视频变换器方法Dark Transformer，用于低光环境下的动作识别。Dark Transformer利用跨域设置中的时空自注意力机制来提升跨域动作识别效果。通过扩展视频变换器学习跨域知识，Dark Transformer在包括InFAR、XD145和ARID在内的基准动作识别数据集上达到了最先进的性能。", "innovation": "Dark Transformer是一种新的视频变换器方法，通过跨域设置中的时空自注意力机制实现了在低光环境下动作识别的性能提升，从而达到了最先进的技术水平。", "conclusion": "本文提出的方法在应对不良光照条件下的动作识别挑战方面展现出显著前景，并为实际应用提供了实用意义。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20349", "html_url": "https://arxiv.org/abs/2503.20349", "title": "一致性轨迹匹配对于一步生成超级分辨率", "title_en": "Consistency Trajectory Matching for One-Step Generative Super-Resolution", "authors": "Weiyi You,Mingyang Zhang,Leheng Zhang,Xingyu Zhou,Kexuan Shi,Shuhang Gu", "background": "当前基于扩散的超分辨率（SR）方法在实现出色性能的同时，往往伴随着高推理开销。为了解决这个问题，研究人员使用了蒸馏技术将一个多步骤的教师模型加速为一个一步的学生模型。然而，这种方法会显著增加训练成本，并限制学生的性能。为了克服这些问题，本文提出了一种名为CTMSR（一致性轨迹匹配超分辨率）的无蒸馏策略，可以在一步生成逼真的超分辨率结果。论文首先提出了一种概率流动常微分方程（PF-ODE）轨迹，以便在有噪声的低分辨率（LR）图像和高分辨率（HR）图像之间建立确定性映射，然后采用一致性训练（CT）策略直接在一步中学习该映射。为了进一步提高性能并更好地利用训练过程中的真实图像，提出了通过精心设计的分布轨迹匹配（DTM）损失来最小化从LR图像分布到SR结果的轨迹差异，从而提高恢复的HR图像的逼真度。", "innovation": "CTMSR是一种无蒸馏策略，可以在一步生成逼真的超分辨率结果。它首先引入了PF-ODE轨迹，建立了从带有噪声的LR图像到HR图像的确定性映射，然后通过CT策略直接在一步中学习该映射。此外，通过DTM损失进一步优化，以更紧密地匹配SR结果与真实图像的分布，提升恢复HR图像的真实感。", "conclusion": "实验结果证明，提出的CTMSR方法在合成和真实数据集上可以达到或超越现有方法的表现，同时保持较低的推理延迟。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.14245", "html_url": "https://arxiv.org/abs/2504.14245", "title": "使用多模态大型语言模型实现可解释的虚假图像检测", "title_en": "Towards Explainable Fake Image Detection with Multi-Modal Large Language Models", "authors": "Yikun Ji,Yan Hong,Jiahui Zhan,Haoxing Chen,jun lan,Huijia Zhu,Weiqiang Wang,Liqing Zhang,Jianfu Zhang", "background": "生成图像的进步引发了重大的公共安全问题。我们主张，虚假图像检测不应仅依赖于“黑箱”方法，而应确保具备强大的泛化能力和透明度。最近，多模态大型语言模型（MLLMs）的进步为基于推理的AI生成图像检测提供了新的机会。", "innovation": "本文评估了MLLMs在虚假图像检测中的能力，对比传统检测方法和人工评估者，强调其优势和局限性。此外，设计了六种不同提示，并提出了一种框架，将这些提示整合起来，开发出更为稳健、可解释和基于推理的检测系统。该代码已发布。", "conclusion": "在本文中，我们通过MLLMs对虚假图像检测进行了评估，并提议了一种新型检测框架，旨在提高检测系统的解释性和可靠性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17902", "html_url": "https://arxiv.org/abs/2504.17902", "title": "TRACE：多模态仇恨检测的文本相关性增强和上下文编码", "title_en": "TRACE: Textual Relevance Augmentation and Contextual Encoding for Multimodal Hate Detection", "authors": "Girish A. Koushik,Helen Treharne,Aditya Joshi,Diptesh Kanojia", "background": "社交媒体表情包（meme）是一个对仇恨检测构成挑战的数据领域，因为它交织了视觉和文本线索，这些线索形成了文化上复杂的讯息。现有的方法难以处理这些复杂的线索和文化背景，因此需要一种能够有效识别和理解这些复杂讯息的新方法。", "innovation": "本文介绍了一种名为TRACE的分层多模态框架，这种方法利用了视觉基础的上下文增强，同时引入了一种新颖的标题评分网络来强调仇恨相关的内容，并通过参数高效的微调CLIP的语言编码器来进一步优化模型。此外，该研究还证明了对更深层的语言编码器进行选择性的微调显著提升了模型性能，相较于简单的投影层微调方法。", "conclusion": "实验结果表明，该框架在广泛使用的仇恨表情包数据集上达到了最先进的准确率（0.807）和F1分数（0.806），接近于更大规模模型的表现，但保持了更高的效率。不仅如此，它在多OFF侮辱性表情包数据集上的F1分数为0.673，表现出色。这些分析结果表明强大的视觉基础和微妙的文本表征显著减少了由良性干扰因素导致的错误。最后，作者已将代码公开，以促进未来的相关研究。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.04396", "html_url": "https://arxiv.org/abs/2407.04396", "title": "FunOTTA: 在跨域眼底图像中的稳定实时训练自适应", "title_en": "FunOTTA: On-the-Fly Adaptation on Cross-Domain Fundus Image via Stable Test-time Training", "authors": "Qian Zeng,Le Zhang,Yipeng Liu,Ce Zhu,Fan Zhang", "background": "眼底图像在早期筛查和检测眼病中至关重要。尽管深度学习模型使用眼底图像显著推进了多种眼病的诊断，但由于不同成像设备和地点之间的图像变化（称为域移位）导致预训练模型在实际应用中难以部署。为解决这一问题，本文提出了一个名为FunOTTA的新颖的基金图像实时测试时自适应框架，该框架能够在不同环境和强域移位条件下有效泛化眼底图像诊断模型。", "innovation": "FunOTTA框架通过在记忆库中进行动态解歧来实现稳定的自适应过程，同时最小化有害的先验知识偏差。此外，引入了一种新的训练目标，在自适应过程中使分类器能够逐步适应目标模式，并具备可靠的类别条件估计和一致性正则化。", "conclusion": "通过在跨域眼底图像基准数据集上的实验，展示了整体框架和各个组件在不同骨干网络下的优越性。同时也提供了代码，便于进一步研究和应用。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.18533", "html_url": "https://arxiv.org/abs/2406.18533", "title": "关于3D高斯斑点训练的扩展", "title_en": "On Scaling Up 3D Gaussian Splatting Training", "authors": "Hexu Zhao,Haoyang Weng,Daohan Lu,Ang Li,Jinyang Li,Aurojit Panda,Saining Xie", "background": "3D高斯斑点法（3DGS）因其出色的视觉质量和渲染速度而在3D重建中越来越受欢迎。然而，3DGS的训练当前依赖单个GPU，由于内存限制，它无法处理高分辨率和大规模的3D重建任务。", "innovation": "论文引入了Grendel，这是一种分布式系统，用于将3DGS参数分区并在多个GPU上并行计算。Grendel通过稀疏全连接通信在像素分区之间传输必要的高斯参数，并进行动态负载平衡。此外，Grendel支持批量训练多个视图，而不是现有的3DGS系统一次处理一个相机视图图像。研究发现，简单的批处理大小平方根缩放规则非常有效。", "conclusion": "通过在多个GPU上扩展3DGS参数，Grendel在大规模、高分辨率场景中的渲染质量得到了提高。在Rubble数据集中，通过将在16个GPU上分布在40.4百万个高斯参数，测试PSNR达到了27.28，相比之下，单个GPU上使用11.2百万个高斯参数的PSNR为26.28。Grendel是一个开源项目，可供下载。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.05480", "html_url": "https://arxiv.org/abs/2511.05480", "title": "关于流匹配KL散度", "title_en": "On Flow Matching KL Divergence", "authors": "Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu", "background": "本文推导了流匹配分布近似中的Kullback-Leibler (KL) 散度的确定性、非渐近上界。特别地，如果$L_2$流匹配损失被限制在$\bar{\text{epsilon}}^2 > 0$以内，则真实数据分布与估计分布之间的KL散度被限制在$A_1 \bar{\text{epsilon}} + A_2 \bar{\text{epsilon}}^2$之内。在此公式中，常数$A_1$和$A_2$仅依赖于数据和速度场的正则性。因此，此界限暗示了流匹配变换器在Total Variation (TV) 距离下的统计收敛率。研究表明，流匹配可以近乎达到最小最大效率，在估计平滑分布方面。这些结果使得流匹配的统计效率与在TV距离下的扩散模型相当。在合成和学习速度的数值研究中证实了我们的理论", "innovation": "本文的主要创新在于推导了流匹配分布近似的KL散度的确定性非渐近上界，尤其在$L_2$流匹配损失和KL散度之间的关系上提供了具体表达。此外，研究指出流匹配在估计平滑分布时几乎达到最小最大效率，这与在TV距离下的扩散模型相提并论。", "conclusion": "通过分析，作者证明了流匹配在估计平滑分布方面表现出几乎最优的统计效率，并且该效率评估在TV距离下与扩散模型相当。数值研究结果支持了理论上的推导和结论。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16601", "html_url": "https://arxiv.org/abs/2502.16601", "title": "SelaVPR++: 向基础模型无缝契合高效的地点识别迈进", "title_en": "SelaVPR++: Towards Seamless Adaptation of Foundation Models for Efficient Place Recognition", "authors": "Feng Lu,Tong Jin,Xiangyuan Lan,Lijun Zhang,Yunpeng Liu,Yaowei Wang,Chun Yuan", "background": "最近的研究表明，使用预训练视觉基础模型的视觉地点识别（VPR）方法能够取得令人瞩目的性能。然而，在前一项工作中提出的SelaVPR方法尽管结果具有竞争力，但也存在训练时间长、GPU内存使用效率低以及再排序方案导致检索延迟和存储占用高效率的问题。因此，本文旨在追求更高的效率和更好的性能，提出SelaVPR++作为SelaVPR的扩展。", "innovation": "1. 设计了一种参数、时间和内存高效的适应方法，使用轻量级多尺度卷积（MultiConv）适配器来细化冻结的基础骨干网络的中间特征。\n2. 采用简洁的二进制特征进行初步检索，以及稳健的浮点（全局）特征进行再排序，避免了依赖局部特征带来的高昂延迟和存储开销。\n3. 提出了一种基于相似性约束的深度哈希方法，以便于集成到VPR流水线中。\n4. 改进了训练策略，并统一多个常见训练数据集的训练协议，以更好地训练VPR模型.", "conclusion": "详尽的实验表明，SelaVPR++在提高VPR效率和性能方面表现优异，达到了预期目标。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21890", "html_url": "https://arxiv.org/abs/2505.21890", "title": "Diffusion Denoised Hyperspectral Gaussian Splatting", "title_en": "Diffusion Denoised Hyperspectral Gaussian Splatting", "authors": "Sunil Kumar Narayanan,Lingjun Zhao,Lu Gan,Yongsheng Chen", "background": "高光谱成像(HSI)在农业应用中广泛用于非破坏性评估植物营养成分和样品营养元素的精确测定。最近，3D重建方法被用于创建HSI场景的隐式神经表示，这有助于在空间和光谱上定位目标物体的营养成分。Neural Radiance Field (NeRF)是一种先进的隐式表示，可以从任何视角渲染每个空间位置的高光谱通道组成。然而，NeRF在训练时间和渲染速度方面存在局限性。", "innovation": "本文提出了Diffusion-Denoised Hyperspectral Gaussian Splatting (DD-HGS)，该方法在最先进的3D Gaussian Splatting (3DGS)方法的基础上，加入了波长感知球谐多项式、Kullback-Leibler散度为基础的光谱损失以及基于扩散的降噪器，从而实现了在全光谱范围内的3D显式重建高光谱场景。", "conclusion": "在Hyper-NeRF数据集上对多种真实高光谱场景进行了广泛评估，证明了DD-HGS的有效性。结果表明，DD-HGS在已发表的方法中取得了新的最佳性能。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04270", "html_url": "https://arxiv.org/abs/2507.04270", "title": "ZERO: 一种带有跨模态提示的工业级视觉基础模型", "title_en": "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts", "authors": "Sangbum Choi,Kyeongryeol Go,Taewoong Jang", "background": "尽管基础模型已经极大地改变了人工智能，但在实际工业场景中的零样本部署仍然面临困难，这是因为缺乏高质量的专业领域数据集。由于数据的欠缺，现有的基础模型难以在不重新训练的情况下进行泛化。", "innovation": "Superb AI 提出了一种命名为ZERO的工业级视觉基础模型，该模型利用跨模态提示（文本和视觉）进行泛化而无需重新训练。ZERO是在一个庞大的专业领域数据集（包含0.9百万的标注样本）上进行训练的，实现了在多个学术基准测试上与现有模型相比具有竞争力的表现，并且在37个不同的工业数据集上表现出显著的优势。此外，ZERO还在CVPR 2025物体实例检测挑战中获得第2名，并在基础少样本物体检测挑战中获得第4名，进一步展示了在最少调整和少量数据情况下具有强大的实际部署能力和泛化能力。据我们所知，ZERO是首个明确为特定领域零样本工业应用设计的视觉基础模型。", "conclusion": "ZERO通过有效利用多模态提示在泛化能力上取得了卓越的表现，并且在多个挑战中取得了好的成绩，证明了其在工业领域的实际应用价值。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19210", "html_url": "https://arxiv.org/abs/2505.19210", "title": "理解无分类器指导机制的途径", "title_en": "Towards Understanding the Mechanisms of Classifier-Free Guidance", "authors": "Xiang Li,Rongrong Wang,Qing Qu", "background": "无分类器指导（CFG）是当今先进图像生成系统的核心技术，尽管已在广泛应用，但其运行原理仍然不太明了。本文通过分析简化线性扩散模型的CFG，展示其在非线性模型中的表现特点，揭示了其提高生成质量的三个关键因素：（i）均值偏移项，该项大致引导样本朝类均值方向移动；（ii）正对比主成分（CPC）项，该项增强特定于类的特征；（iii）负CPC项，该项抑制通用特征，这些特征在无条件数据中普遍存在。在实际非线性扩散模型中对这些见解进行了验证，表明无论噪声水平如何，线性CFG都类似于其非线性对应物的行为。即使在噪声较低时两者开始不同，线性分析的见解仍有助于理解非线性模型中CFG的工作机制。", "innovation": "通过简化线性扩散模型分析CFG，揭示其提高生成质量的三个关键因素，并验证了这些见解在实际非线性扩散模型中的应用。尽管线性和非线性模型在低噪声条件下会有所区别，但线性分析仍提供了一定程度的洞见，帮助理解非线性CFG的工作机制。", "conclusion": "通过对简化线性扩散模型的分析，我们展示了CFG在提高生成质量方面的三个关键机制。在实际的非线性扩散模型中这些机制仍然有效，即使在低噪声条件下，线性分析仍有助于理解非线性CFG的工作机制。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05843", "html_url": "https://arxiv.org/abs/2507.05843", "title": "USIGAN: 弱配对图像IHC虚拟染色的不平衡自我信息特征传输", "title_en": "USIGAN: Unbalanced Self-Information Feature Transport for Weakly Paired Image IHC Virtual Staining", "authors": "Yue Peng,Bing Xiong,Fuqiang Chen,De Eybo,RanRan Zhang,Wanming Hu,Jing Cai,Wenjian Qin", "background": "免疫组化（IHC）虚拟染色任务是从H&E图像生成虚拟IHC图像，同时保持与相邻切片的病理语义一致。随着生成模型的发展，这一任务旨在通过形态学结构和染色模式之间的跨域映射，为病理分析提供高效且成本低的解决方案。但在弱配对条件下，相邻切片之间的空间异质性给准确的多对一映射带来了很大挑战，导致结果与相邻切片的病理语义不一致。", "innovation": "为了应对这一问题，我们提出了一种名为USIGAN的新颖不平衡自我信息特征传输算法，该算法通过提取全局形态学语义而不依赖于位置信息，去除联合边缘分布中的弱配对项，从而有效缓解弱配对对联合分布的影响，显著提高生成结果的内容一致性和病理语义一致性。此外，设计了不平衡最优传输一致性(UOT-CTM)机制和病理自我对应(PC-SCM)机制，在图像级别和组内层面构建了H&E和生成IHC之间的相关矩阵，以及真实IHC和生成IHC图像集之间的相关矩阵。", "conclusion": "我们在两个公开数据集上进行的实验表明，我们的方法在多个临床重要指标（如IoD和皮尔逊相关系数）上均取得了优越的性能，显示出更好的临床相关性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21069", "html_url": "https://arxiv.org/abs/2507.21069", "title": "GAITEX：使用惯性及光学传感器的受损步态和康复锻炼的人体运动数据集", "title_en": "GAITEX: Human motion dataset of impaired gait and rehabilitation exercises using inertial and optical sensors", "authors": "Andreas Spilz,Heiko Oppel,Jochen Werner,Kathrin Stucke-Straub,Felix Capanni,Michael Munz", "background": "可穿戴惯性测量单元（IMUs）为在临床上和日常环境中评估人类运动提供了一种成本效益高的方法。然而，开发用于康复锻炼评估和步态分析的相关分类模型需要大量多样化的数据集，收集这些数据集既昂贵又耗时。本研究提出了一种多模态数据集，包括来自19名健康受试者的康复锻炼和步态相关动作的记录数据，使用同步IMUs和基于光学标记的运动捕捉（MoCap）进行记录。该数据集包含九个IMUs和68个标记的数据，追踪全身运动学，每种IMU有四个标记，允许直接比较IMUs和MoCap导出的姿态。此外，数据集提供了IMUs姿态处理后的数据、一致的体段坐标系统、受试者特定的OpenSim模型、逆运动学输出以及用于IMU导出姿态的可视化工具。所有数据都经过注释，并带有运动质量评分和时间戳，支持包括锻炼评估、步态分类、时间分割和生物力学参数估算在内的多种机器学习任务。", "innovation": "该数据集采用多模态数据记录方式，包含基于惯性测量和光学传感器的多种数据，提供了直接的IMU与MoCap比较，同时还提供了处理后的IMU姿态数据、受试者特定的OpenSim模型等附加信息，旨在为康复锻炼和步态分析提供更全面的数据支持。", "conclusion": "该数据集支持多种机器学习任务，提供了处理和验证方法代码以促进结果的可重复性，将极大地促进相关研究的发展。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13142", "html_url": "https://arxiv.org/abs/2508.13142", "title": "全方位评估多模态大语言模型在空间智能上的表现", "title_en": "Holistic Evaluation of Multimodal LLMs on Spatial Intelligence", "authors": "Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Oscar Qian,Hui En Pang,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang", "background": "近年来，多模态模型在多个领域取得了显著进展，但在理解空间和推理解析方面依然存在明显的局限性。即使是最先进的GPT-5模型，也亟需评估其在空间智能上的表现。因此，本文提出了一种名为EASI（全面评估多模态语言大模型的空间智能）的评价方法，旨在评估当前领先的多模态模型在空间智能任务上的能力。", "innovation": "提出了一种全面评估多模态语言大模型在空间智能上的新方法EASI，并在八个关键基准上进行了大规模、全面的实验评估，揭示了这些模型在空间智能任务上存在的显著局限性及差异性。", "conclusion": "尽管GPT-5在空间智能方面表现出前所未有的强大，但在广泛的空间智能任务中仍显著低于人类水平。同时，空间智能任务相比于非空间智能任务更能暴露模型能力的不足，甚至某些情况下，最先进模型并未表现出显著优势。这些结果显示，目前的多模态模型在空间智能方面仍有很长的路要走。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20217", "html_url": "https://arxiv.org/abs/2510.20217", "title": "EditInfinity：使用二元量化生成模型进行图像编辑", "title_en": "EditInfinity: Image Editing with Binary-Quantized Generative Models", "authors": "Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei", "background": "基于扩散的预训练生成模型在文本驱动的图像编辑方面显示出了巨大的潜力。然而，现有的方法在图像编辑方面的性能受到由扩散模型在图像反演过程中引入的近似误差的限制。这些模型由于在生成步骤中缺乏精确监督而产生了这样的误差。", "innovation": "本文提出了EditInfinity，一种适应二元量化生成模型的方法，以实现文本驱动的图像编辑。该方法利用二元量化生成模型的固有特性，即能够精确获得源图像的中间量化表示，从而为图像反演提供更有效的监督。此外，提出了一种高效的图像反演机制，整合了文本提示矫正和图像风格保留，以及一种整体平滑策略，确保图像编辑对源图像的高保真度和文本提示的精准语义对齐。", "conclusion": "在PIE-Bench基准测试上进行的大量实验表明，与现有的基于扩散的基础模型相比，我们的模型在各种编辑操作（'add'、'change'和'delete'）中的性能更为优越。实现了高保真度的图像编辑和精确的语义对齐。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.10473", "html_url": "https://arxiv.org/abs/2505.10473", "title": "ControlGS: 针对部署感知的高斯谱图结构压缩一致性控制", "title_en": "ControlGS: Consistent Structural Compression Control for Deployment-Aware Gaussian Splatting", "authors": "Fengdi Zhang,Yibao Sun,Hongkun Cao,Ruqi Huang", "background": "3D Gaussian Splatting (3DGS) 是一种实时的新型视图合成方法，但在实际应用中需要一种通用且一致的控制机制来调整渲染质量和模型压缩之间的权衡，无需针对特定场景进行调优，以适应不同设备性能和通信带宽的应用场景。现有的方法在不同场景下需要特定的调优，难以实现自动化部署。", "innovation": "提出了一种控制导向的优化框架 ControlGS，它将高斯计数与渲染质量之间的权衡映射到一个连续、场景无关且高度响应的控制轴上。ControlGS 通过调整一个全局统一的控制超参数，能够在不同场景规模和类型下灵活生成偏向结构紧凑或高保真度的模型，同时在相同或更少的高斯点条件下实现显著的渲染质量提升，相比可能的竞争方法具有优势。", "conclusion": "通过控制导向的优化框架 ControlGS，能够在不同场景规模和复杂性下灵活生成偏向结构紧凑或高保真的模型，相比现有方法具有更高或相当的渲染质量，且在相同或更少的高斯点条件下实现。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.00801", "html_url": "https://arxiv.org/abs/2511.00801", "title": "Med-Banana-50K：用于文本引导的医学图像编辑的跨模态大规模数据集", "title_en": "Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing", "authors": "Zhihui Chen,Mengling Feng", "background": "医学图像编辑因其在数据增强、模型可解释性、医学教育和治疗模拟中的广泛应用而成为重要的技术。然而，缺乏大量高质量且在医学环境中严格解剖学和临床约束下开放获取的医学数据集，严重阻碍了该领域的发展。", "innovation": "本研究引入了Med-Banana-50K，这是一个包含超过50,000个医学筛选图像编辑数据集，涵盖了胸部X光、脑MRI和眼底摄影等23种疾病的影像数据。每个样本支持病变的双向编辑（添加和删除），使用Gemini-2.5-Flash-Image基于真实临床图像进行构建。该数据集的一大亮点是由医学为基础的质量控制协议，通过LLM-as-Judge评估框架，包括指令合规性、结构合理性、图像的真实性和保真度保持等方面，以及最多五轮的迭代优化。此外，Med-Banana-50K还包括大约37,000个编辑失败的尝试，以及完整的评估日志，以支持偏好学习和对齐研究。", "conclusion": "通过提供大规模的、医学严谨的和完全记录的资源，Med-Banana-50K为开发和评估可靠的医学图像编辑系统奠定了关键基础。该数据集和代码对公众开放。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11018", "html_url": "https://arxiv.org/abs/2505.11018", "title": "双师生学习方法在半监督医学图像分割中的应用", "title_en": "Dual Teacher-Student Learning for Semi-supervised Medical Image Segmentation", "authors": "Pengchen Zhang,Alan J.X. Guo,Sipin Luo,Zhe Han,Lin Guo", "background": "半监督学习可以在减少昂贵的手动注释负担的情况下在医学图像分割中发挥作用。一种流行的方法是“均值教师（MT）策略”，该方法通过使用时间累积的教师模型应用一致性正则化。本文将MT策略重新解释为监督学习中的自我节奏学习形式，教师的预测与真实预测之间的一致性暗示了从易到难的模型学习进程。", "innovation": "提出了双师生学习（DTSL）方法，它在半监督学习中使用两种信号调整学习节奏：内部教师时间累积信号和来自第二组独立模型中的学生横架构信号。该方法通过一个新颖的共识标签生成器（CLG）将这两种信号的共识建立为伪标签，从而创建了一个有效的学习课程。实验表明，该方法在四个基准数据集上都优于现有方法，特别是在三个数据集上，即使使用有限的标注数据，该半监督方法也超过了完全监督方法，验证了自我节奏学习设计的有效性。", "conclusion": "大量的实验表明，所提出的方法在四个基准数据集上始终优于现有先进技术。三个数据集上的半监督方法在有限标注数据的情况下甚至超过了完全监督方法，这验证了自我节奏学习设计的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08186", "html_url": "https://arxiv.org/abs/2508.08186", "title": "KARMA: 通过柯尔莫哥洛夫-阿诺尔德表示学习实现高效结构缺陷分割", "title_en": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning", "authors": "Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak", "background": "由于结构缺陷在建筑基础设施中的外观变化、恶劣的成像条件以及类别的不平衡，其语义分割仍然是具有挑战性的。现有深度学习方法虽然有效，但通常需要数百万个参数，使其不适合实时检查系统。", "innovation": "提出了一种高效的语义分割框架KARMA（Kolmogorov-Arnold Representation Mapping Architecture），通过一维函数的组合而非常规卷积来建模复杂的缺陷模式。KARMA包含三个技术创新：（1）采用低秩分解参数高效的Tiny Kolmogorov-Arnold Network（TiKAN）模块，利用Kolmogorov-Arnold Network（KAN）进行特征转换；（2）优化的分层结构及分隔卷积用于多尺度缺陷分析；（3）静态-动态原型机制以增强不平衡类别下的特征表示。广泛的实验证明，KARMA在多种基准基础设施检测数据集上达到或优于当前最佳方法的平均IoU性能，同时参数量显著减少（0.959M vs. 31.04M，减少97%）。KARMA以0.264 GFLOPS的运行速度保持适合实时部署的推理速度。", "conclusion": "KARMA能够在不牺牲精度的情况下实现实用的自动化基础设施检查系统，通过采用Kolmogorov-Arnold表示学习实现高效结构缺陷分割。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.18090", "html_url": "https://arxiv.org/abs/2509.18090", "title": "GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction", "title_en": "GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction", "authors": "Jiahe Li,Jiawei Zhang,Youmin Zhang,Xiao Bai,Jin Zheng,Xiaohan Yu,Lin Gu", "background": "近年来，通过辐射场重建准确的表面取得了显著进展。然而，主要基于高斯插值的方法日益受限于表征瓶颈。", "innovation": "我们介绍了一种名为GeoSVR的显式体素框架，该框架探索和扩展了稀疏体素的潜在能力，以实现准确、详细和完整的表面重建。提出了体素不确定性深度约束和稀疏体素表面正则化来确保正确的场景收敛和增强几何一致性。", "conclusion": "广泛的实验表明，与现有方法相比，我们在各种挑战场景中表现出优越的性能，特别是在几何准确性、细节保留和重建完整性方面保持高效。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04029", "html_url": "https://arxiv.org/abs/2511.04029", "title": "忠实轮廓线：无损3D体素表示，免除等值面", "title_en": "Faithful Contouring: Near-Lossless 3D Voxel Representation Free from Iso-surface", "authors": "Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap", "background": "3D网格的准确且高效的体素化表示是3D重建和生成的基础。然而，现有的基于等值面的表示依赖于密封处理或渲染优化，这不可避免地会牺牲几何保真度。", "innovation": "提出了忠实轮廓线，这是一种无需将网格转换为场函数或在重新网格化时提取等值面的稀疏体素化表示方法，可以支持任意网格的2048+分辨率。该方法通过保留锐度和内部结构，即使在复杂几何结构和拓扑结构情况下也能实现接近无损的保真度，并具有灵活性，适用于纹理、操作和编辑。此外，设计了一种双模式自编码器，为忠实轮廓线提供具有可扩展性和细节保留形状重建的能力。", "conclusion": "广泛的实验表明，忠实轮廓线在表示和重建两方面都超过了现有方法的准确性和效率。对于直接表示，其距离误差达到了10^-5的水平；对于网格重建，其在与强基线的对比中，分别减少了93%的切诺夫距离和35%的F评分，证实了其作为3D学习任务的表示具有优越的保真度。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04520", "html_url": "https://arxiv.org/abs/2511.04520", "title": "THEval. 评价框架：用于生成嘴型视频的评估", "title_en": "THEval. Evaluation Framework for Talking Head Video Generation", "authors": "Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva", "background": "视频生成已经取得了显著进展，生成的视频越来越接近真实的视频。然而，生成技术的快速发展已经超越了足够的评估指标的发展。目前，头像视频生成的评估主要依赖于有限的指标，包括评估一般视频质量、唇部同步，以及进行用户研究。这些方法不能充分评估头像视频生成的质量、自然度和同步性。为了改善这种情况，提出了新的评估框架，包括8个与质量、自然度和同步相关的新指标。", "innovation": "该论文提出了一种新的评估框架，涵盖8个与头像视频生成相关的评价指标，分为质量、自然度和同步性三个维度。此外，论文强调了选择高效且与人类偏好一致的度量标准，旨在更全面地分析头、嘴、眉毛的微动态，以及面部质量。实验基于一个独有的真实数据集进行，旨在减少训练数据带来的偏差。", "conclusion": "广泛的实验结果显示，尽管许多算法在唇部同步方面表现出色，但存在表达性和无伪影细节生成的挑战。提出的新基准框架旨在评估生成方法的进步。同时，源代码、数据集和排行榜将公开发布，并定期更新，以反映领域的进步。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03891", "html_url": "https://arxiv.org/abs/2511.03891", "title": "利用基于类别的输入图像组合提高小样本和不均衡数据集的诊断性能", "title_en": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition", "authors": "Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat", "background": "深度学习模型在处理小型且类别不均衡的数据集以及图像质量差时可能会产生较高的误预测率。研究背景介绍了一种基于类别的图像组合方法（Class-Based Image Composition），它通过将同一类别的多张图像融合成复合视觉组合图像（Composite Input Images, CoImg），以增加类内差异、提高每个训练样本的信息密度并增强模型区分细微病变模式的能力。", "innovation": "提出了一种新的基于类别的输入图像组合方法，通过将同一类别的多张图像融合成复合视觉组合图像（CoImg），从而增加了类内的差异，并提高了每个训练样本的信息密度。该方法克服了小型和类别不均衡数据集的问题，并通过使用VGG16模型在OCTDL数据集（Kulyabin et al., 2024）上的实验，表明这种新的表示方式可显著提高诊断性能。经过对比分析，与直接使用原始数据集训练的基准模型相比，该方法显著降低了误预测率，提高了准确性、F1分数和AUC值，证明了这种方法在小型不均衡数据集中的有效性，特别是在类不平衡或样本量小的情况下能够产生高质量的预测结果。", "conclusion": "所提出的方法能够显著提高对小样本和类不均衡数据集的诊断性能，经过实验验证，该新方法在OCTDL数据集上达到了接近完美的准确度（99.6%）、F1分数（0.995）和AUC值（0.9996），并且错误预测率显著降低，证明了该方法能够产生高质量的预测结果，特别是在面对类不平衡或样本量小的数据集时。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.15027", "html_url": "https://arxiv.org/abs/2502.15027", "title": "InterFeedback: 通过人类反馈揭示大型多模态模型的交互智能", "title_en": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback", "authors": "Henry Hengyuan Zhao,Wenqi Pei,Yifei Tao,Haiyang Mei,Mike Zheng Shou", "background": "现有的基准测试没有评估大型多模态模型（LMMs）与人类用户的交互智能，这是开发通用AI助手时至关重要的能力。InterFeedback 是一个互动框架，能够自动评估任何 LMM 和数据集的这种能力。InterFeedback-Bench 使用两个代表性数据集 MMMU-Pro 和 MathVerse 来评估互动智能，并测试了 10 种不同的 LMM。InterFeedback-Human 是一个新的数据集，包含 120 个案例，用于手工测试领先模型（如 OpenAI-o1 和 Claude-Sonnet-4）的互动性能。", "innovation": "设计了一个名为 InterFeedback 的互动框架，该框架可以应用于任何LMM和数据集，以自主评估模型的互动智能能力；利用 InterFeedback-Bench 和 InterFeedback-Human 分别针对两个数据集和多模型进行了评估，并得出了有意义的结果。", "conclusion": "当前最先进的 LMM，例如 OpenAI-o1，难以根据人类反馈改进其响应，平均得分低于50%。这些结果表明，需要开发新的方法来增强 LMM 解释和利用反馈的能力。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08828", "html_url": "https://arxiv.org/abs/2501.08828", "title": "MMDocIR: 评估长文档多媒体检索的标准", "title_en": "MMDocIR: Benchmarking Multimodal Retrieval for Long Documents", "authors": "Kuicai Dong,Yujing Chang,Xin Deik Goh,Dexun Li,Ruiming Tang,Yong Liu", "background": "多模态文档检索旨在从广泛文档中识别和检索各种形式的多媒体内容，如图表、表格、图表和布局信息。尽管其日益流行，但缺乏一个全面且稳健的基准来有效评估此类任务中系统的性能。为解决这一差距，这项工作引入了名为MMDocIR的新基准，涵盖了页面级和布局级检索两项任务。前者评估识别长文档中最相关页面的表现，后者评估检测特定布局的能力，提供比整页分析更精细的衡量标准。MMDocIR基准数据集包含由专家标注的1685个问题和173,843个有支持标注的问题，对于训练和评估多媒体文档检索均是一个宝贵的资源。", "innovation": "引入了名为MMDocIR的新基准，包含页面级和布局级检索任务，为长文档的多模态检索提供了全面且精细的评估标准。实验表明，视觉检索器显著优于纯文本检索器，MMDocIR训练集能够有效提升多模态文档检索性能，利用VLM文本的文本检索器比依赖OCR文本的检索器表现更好。", "conclusion": "通过严格的实验，我们证明了视觉检索器在多媒体文档检索中显著优于纯文本检索器，MMDocIR训练数据集能够有效提升多模态文档检索性能，并且利用VLM文本的文本检索器比依赖OCR文本的检索器表现更好。MMDocIR基准数据集可以在这里获取：this https URL."}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03765", "html_url": "https://arxiv.org/abs/2511.03765", "title": "LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices", "title_en": "LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices", "authors": "Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee", "background": "在边缘应用如人体活动识别（HAR）中，针对卷积神经网络（CNN）进行设备端微调是必要的，以应对领域迁移问题。然而，在严格的内存、计算和能耗预算下，完全的微调是不切实际的。因此，急需一种参数高效的微调方法来平衡精度和算力需求。", "innovation": "LoRA-Edge提出了一个参数高效的微调（PEFT）方法，基于Low-Rank Adaptation（LoRA）和张量分解技术。该方法通过张量分解卷积层，仅更新输出核心，融合更新回密集核，从而保持卷积结构并减少可训练参数数量。这种方法在节省算力预算的同时，也能取得接近完全微调的效果，并且在不同数据集和模型上持续优于其他参数高效的基线方法。", "conclusion": "LoRA-Edge在Jetson Orin Nano设备上实现了张量对齐且参数高效的CNN微调，其收敛速度是基线方法的1.4-3.8倍，在边缘平台上实践性更强，适用于实际应用场景。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17013", "html_url": "https://arxiv.org/abs/2505.17013", "title": "当概念从扩散模型中被消除时？", "title_en": "When Are Concepts Erased From Diffusion Models?", "authors": "Kevin Lu,Nicky Kriplani,Rohit Gandikota,Minh Pham,David Bau,Chinmay Hegde,Niv Cohen", "background": "在概念擦除中，通过修改模型以使其有选择性地防止生成目标概念。尽管新方法迅速发展，但这些方法是否彻底从模型中删除目标概念仍不清楚。研究者提出了两种概念擦除机制的理论模型：一是干扰模型的内部引导过程；二是减少在生成目标概念时的无条件概率，可能完全删除该概念。研究者还提出了一套独立的探测技术，评估概念是否真正从模型中被消除，包括提供视觉上下文、修改扩散轨迹、施加分类器引导以及分析移除概念后的替代生成模型。", "innovation": "本文提出了两种概念擦除机制的理论模型，并采用了一系列独立的探测技术来评估概念是否真正从模型中被消除，强调了评估扩散模型中概念擦除时进行全面评估的重要性，尤其是在非对抗性文本输入场景下的概念擦除鲁棒性研究方面的价值。", "conclusion": "研究结果表明，为了确保概念在扩散模型中的彻底消除，需要进行全面的评估，强调了非对抗性输入下的概念擦除鲁棒性的重要性，并凸显了评估模型擦除的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.06611", "html_url": "https://arxiv.org/abs/2510.06611", "title": "加速MRI重建的带有隐式神经表示正则化的自我监督深层展开模型", "title_en": "Self-supervised Deep Unrolled Model with Implicit Neural Representation Regularization for Accelerating MRI Reconstruction", "authors": "Jingran Xu,Yuanyuan Liu,Yuanbiao Yang,Zhuo-Xu Cui,Jing Cheng,Qingyong Zhu,Nannan Zhang,Yihang Zhou,Dong Liang,Yanjie Zhu", "background": "磁共振成像（MRI）是一种重要的临床诊断工具，但由于扫描时间长的应用受到限制。加速MRI重建通过从欠采样的k空间测量中重建高保真度的MRI图像来解决这一问题。近年来，基于深度学习的方法取得了显著的进步。然而，大多数方法依赖于监督学习，这需要大量完全采样的训练数据，这种数据难以获得。", "innovation": "本文提出了一种名为UnrollINR的新型零样本自我监督重建方法，能够在没有外部训练数据的情况下实现扫描特定的MRI重建。该方法采用了一种基于物理指导的展开重建架构，并引入了隐式神经表示（INR）作为正则化先验，有效地约束了解空间。该方法克服了传统深层展开方法中卷积神经网络的局部偏差限制，并避免了在高度病态情况下仅依赖INR隐式正则化带来的不稳定性。从而在高加速率下显著提高了MRI重建性能。实验结果显示，即使在高加速率10倍的情况下，UnrollINR的重建性能优于监督学习和自我监督学习方法，验证了其有效性和优越性。", "conclusion": "UnrollINR方法在高加速率下显著提高了MRI重建性能，即使在加速率10的情况下也优于现有的监督学习和自我监督学习方法。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.04521", "html_url": "https://arxiv.org/abs/2502.04521", "title": "基于生成自回归变换器的模型无关联邦MRI重建", "title_en": "Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction", "authors": "Valiyeh A. Nezhad,Gokberk Elmas,Bilal Kabas,Fuat Arslan,Emine U. Saritas,Tolga Çukur", "background": "学习型模型在MRI重建中具有巨大潜力，但由于单机构模型往往依赖于有限的数据集，导致其在不同机构间表现不佳。联邦学习（FL）作为一种保护隐私的框架已被提议，它通过聚合模型更新而不是共享原始数据来解决这一问题。然而，传统FL需要模型架构的一致性，限制了各机构使用适应其资源或需求的独特模型。这限制了模型的灵活性和适应性。为了克服这一局限，该研究提出了一种称为FedGAT的技术，这是一种模型无关的联邦学习方法。它首先协同训练一个全局生成先验模型，用于MRI图像，该模型基于一种基于视觉自编码器（VAE）和生成器的自然图像基础模型。通过将生成模块与轻量级的机构特定提示机制结合，同时保持VAE不变，实现模型在多机构MRI数据上的高效适应。在第二阶段，每个机构根据其他机构的提示调节的先验生成合成MRI数据，独立训练其首选的重建模型，实现去中心化的数据增强，提高了泛化能力同时保持隐私性。实验表明，在模型异质条件下，FedGAT在机构内和跨机构重建性能上优于现有的FL基准模型。", "innovation": "提出了一种基于生成自回归变换器的模型无关的联邦MRI重建技术（FedGAT），它首先协同训练一个适应于MRI图像生成的全局生成先验模型，该模型基于VAE和生成器。通过将生成模块与轻量级的机构特定提示机制结合，同时保持VAE不变，实现模型在多机构MRI数据上的高效适应。在第二阶段，每个机构根据其他机构的提示调节的先验生成合成MRI数据，独立训练其首选的重建模型，以实现去中心化的数据增强，提高泛化能力同时保持隐私性。这种方法克服了传统联邦学习对模型架构一致性要求的限制，增强了联邦学习方法的灵活性和适应性。", "conclusion": "FedGAT在多机构场景下相较于现有的联邦学习基准模型具有更好的MRI重建性能，在模型异质条件下尤其显著。这种去中心化的数据增强方法不仅提高了泛化能力，还保持了数据隐私，为多机构间MRI重建提供了一种有效的解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16470", "html_url": "https://arxiv.org/abs/2505.16470", "title": "用于文档问答的检索增强多模态生成基准测试", "title_en": "Benchmarking Retrieval-Augmented Multimodal Generation for Document Question Answering", "authors": "Kuicai Dong,Yujing Chang,Shijie Huang,Yasheng Wang,Ruiming Tang,Yong Liu", "background": "文档视觉问答（DocVQA）在处理长度较长的多模态文档（文本、图片、表格）和进行跨模态推理方面面临着双重挑战。现有的文档检索增强生成方法受限于文本中心的方法，常常忽略了关键的视觉信息。该领域还缺乏评估多模态证据选择和整合的稳健基准。", "innovation": "该论文提出了一个全面的基准——MMDocRAG，包含4,055个由专家注释的问答对，涉及多页和跨模态证据链。引入了新的多模态引述选择评估指标，支持文本和相关视觉元素的结合回答。通过大规模实验与60种视觉语言模型/大型语言模型及14种检索系统，识别出了多模态证据检索、选择和利用中持续存在的挑战。研究发现，专业的私有模态视觉模型优于开源替代品；在使用多模态输入而非仅文本输入时，它们表现出适度的优势，而开源替代品则表现显著下降。值得注意的是，微调的大型语言模型在使用详细图像描述时取得了显著改进。MMDocRAG提供了一种严格的测试环境，并提供了开发更稳健的多模态DocVQA系统的实用见解。该基准及代码可在指定网址获取。", "conclusion": "MMDocRAG建立了一个严格的测试基准，并提供了开发更稳健的多模态DocVQA系统的实用见解。该基准和代码可在指定网址获取。通过大规模实验，该研究揭示了多模态证据检索、选择和利用的最新进展，特别是展示了专业私有模态视觉模型的优势。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "学习通过前瞻性风险感知进行社交导航", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "该论文描述了作者为2025年IROS RoboSense挑战赛社交导航赛道提交的技术细节。该赛道旨在开发基于RGBD的感知与导航系统，使自主机器人能够在充满动态人群的室内环境中安全、高效且符合社交规范地导航。比赛要求机器人仅使用内置传感器进行第一人称视角操作，不得使用全局地图或其他特权信息，并需遵守社交规范，如保持安全距离和避免碰撞。", "innovation": "在构建于Falcon模型的基础上，作者引入了前瞻性的风险感知模块，以提升社交导航性能。该模块使系统能够理解碰撞风险，通过预测周围人类的距离相关碰撞风险评分，增强空间意识并实现前置的碰撞避免行为。", "conclusion": "在测试基准Social-HM3D上评估表明，该方法改善了机器人在拥挤室内场景中保持个人空间合规性与导航至目标点的能力，使团队在16个参赛队伍中获得第2名的成绩。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22017", "html_url": "https://arxiv.org/abs/2507.22017", "title": "Cyst-X: 一种联邦AI系统在检测胰腺癌前病变和减少不必要的手术方面优于临床指南", "title_en": "Cyst-X: A Federated AI System Outperforms Clinical Guidelines to Detect Pancreatic Cancer Precursors and Reduce Unnecessary Surgery", "authors": "Hongyi Pan,Gorkem Durak,Elif Keles,Deniz Seyithanoglu,Zheyuan Zhang,Alpay Medetalibeyoglu,Halil Ertugrul Aktas,Andrea Mia Bejar,Ziliang Hong,Yavuz Taktak,Gulbiz Dagoglu Kartal,Mehmet Sukru Erturk,Timurhan Cebeci,Maria Jaramillo Gonzalez,Yury Velichko,Lili Zhao,Emil Agarunov,Federica Proietto Salanitri,Concetto Spampinato,Pallavi Tiwari,Ziyue Xu,Sachin Jambawalikar,Ivo G. Schoots,Marco J. Bruno,Chenchan Huang,Candice W. Bolan,Tamas Gonda,Frank H. Miller,Rajesh N. Keswani,Michael B. Wallace,Ulas Bagci", "background": "预计到2030年，胰腺癌将成为第二致命的癌症，因此早期检测至关重要。内乳头状粘液性肿瘤（IPMNs）是关键的癌症前期病变，但当前的临床指南难以区分其恶性风险，导致不必要的手术或漏诊。", "innovation": "我们开发了Cyst-X，一种基于1,461名764名患者1,461个MRI扫描的独特多中心数据集训练的AI框架，用于预测IPMN风险。Cyst-X在区分高风险病变的准确率方面明显优于现有的京都指南（AUC=0.75）和专家放射科医生（AUC=0.82），并且能够在不泄露患者隐私的情况下，在联邦学习设置中保持这种性能。此外，我们公开发布了该数据集和模型，提供了一个大规模和多中心的MRI资源，用于胰腺囊肿分析，以加速早期胰腺癌检测的研究。", "conclusion": "Cyst-X在识别高风险IPMN病变方面表现出比现有指南和专家更高的准确率，并且能够在保持患者隐私的情况下进行协作训练。通过公共发布数据集和模型，我们为研究早期胰腺癌检测提供了新的资源，并显著提高了发现高风险病变的敏感性。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu Xin,Di Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou", "background": "本文介绍的是NVIDIA最新的Nemotron Nano V2 VL模型，该模型属于Nemotron视觉-语言系列，专为现实世界文档理解、长时间视频理解及推理任务设计。Nemotron Nano V2 VL相比之前的模型Llama-3.1-Nemotron-Nano-VL-8B在视觉和文本各个领域取得了显著的改进，这些改进源于模型架构、数据集和训练策略的重大增强。Nemotron Nano V2 VL是在Nemotron Nano V2的基础上构建的，后者是一种混合Mamba-Transformer大型语言模型（LLM），并通过创新性的token缩减技术实现了在长文档和视频场景中的更高推理吞吐量。", "innovation": "Nemotron Nano V2 VL在模型架构、数据集和训练策略上进行了重要改进，实现了对现实世界文档和长时间视频理解的增强。该模型结合了Mamba-Transformer和创新的token缩减技术，提高了在处理长文本和视频任务时的推理速度。该模型还提供了BF16、FP8和FP4格式的检查点，并且共享了大量的数据集、食谱和训练代码，促进了研究的透明度和可访问性。", "conclusion": "最终，NVIDIA发布了Nemotron Nano V2 VL模型的各种版本，并且开放了大量数据集和训练代码，旨在推动视觉-语言技术领域的研究和发展。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04686", "html_url": "https://arxiv.org/abs/2511.04686", "title": "状态化KV缓存管理对于LLMs：平衡空间、时间和准确性以及位置一致性", "title_en": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity", "authors": "Pratik Poudel", "background": "在大型语言模型（LLMs）的自回归推理中，键值（KV）缓存非常重要，但在状态化多轮对话场景中，KV缓存的无界限增长带来了主要挑战。研究发现，当累积的KV缓存接近或超过模型训练的上下文窗口（例如，Llama 3的8192个标记）时，LLM的生成质量会急剧下降，这与GPU内存耗尽不同。常见的淘汰策略，即使保持高保留率（例如，99%通过AttentionTop），如果扰乱了位置一致性也会恶化性能。", "innovation": "研究通过实证分析，展示了在状态化基准测试框架中，LALLEMA/META-LLAMA-3-8B-INSTRUCT等模型的KV缓存管理策略与位置编码完整性的关系。研究指出，简单的策略保留连续的上下文块（例如，保留初始摘要）可以产生比复杂或位置不连续策略更连贯的生成结果。文章提倡采用尊重架构限制、保留位置结构且从更全面的角度看待“缓存健康状态”的淘汰技术。", "conclusion": "LLMs依赖一致的位置信号（如RoPE），通过去除非连续标记进行缓存压缩可能扰乱这些信号并导致生成退化。本文强调了位置一致性和缓存健康状态的维护，并提出了一种新的缓存管理方法来平衡空间、时间和准确性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04722", "html_url": "https://arxiv.org/abs/2511.04722", "title": "AWEMixer：适应性小波增强混合网络在长时期序列预测中的应用", "title_en": "AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting", "authors": "Qianyang Li,Xingjun Zhang,Peng Tao,Shaoxun Wang,Yancheng Pan,Jia Wei", "background": "在物联网环境中，长时间序列预测仍然是一个重要挑战。由于传感器信号的非平稳性和多尺度特性，且预测未来时间点会导致误差累积，这使得预测质量下降。传统方法仅在时间域下操作，而傅里叶变换获取的全局频率信息被视为平稳信号，因此无法捕捉瞬态事件的时序模式。", "innovation": "提出了一种新的适应性小波增强混合网络AWEMixer，包括两个创新组件：1) 频率路由器，该路由器利用快速傅里叶变换得到的全局周期模式，对局部小波子带进行自适应权重分配；2) 共轭门融合块，该块通过交叉注意力和门控机制实现对多尺度时序表示中显著频率特征的选择性集成，从而实现准确的时间频率定位，同时具有噪声鲁棒性。", "conclusion": "本研究通过对七个公开基准的验证，证明了所提模型相比最近的先进模型更具效用。具体来说，在长序列时间序列预测中，本模型在与基于转换器和MLP的先进模型进行比较时表现更为优越。相关代码可在该链接访问：this https URL"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04760", "html_url": "https://arxiv.org/abs/2511.04760", "title": "当数据不足时：低于临界阈值的通感现象", "title_en": "When Data Falls Short: Grokking Below the Critical Threshold", "authors": "Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi", "background": "本文研究了模型在训练数据过拟合后出现的延迟推广现象（通感），特别是在数据稀缺的情况下，当训练样本数量低于临界值时，通感现象变得不可观察，并且在数据分布变化的实用场景中尤为关键。", "innovation": "1. 知识蒸馏（KD）可以从已经在某一分布上通感的模型中提取知识，并在不同且数据不足的分布上加速和促进通感现象。\n2. 对联合分布下的训练进行研究，证明在任何单一分布数据不足的情况下，标准监督训练会失效，但在从分别在两个分布上通感的模型中进行知识蒸馏则能够实现泛化。\n3. 在连续预训练设置中，通感模型可以有效过渡，并通过知识蒸馏加速泛化同时减轻灾难性遗忘，展示了即使数据仅有10%，也能实现强大的性能。", "conclusion": "本文结果为知识传递条件下的通感机制提供了新的见解，并强调了在数据稀缺及分布演化设置中知识蒸馏对泛化的核心作用。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04718", "html_url": "https://arxiv.org/abs/2511.04718", "title": "Ada-FCN: 自适应频率耦合网络在基于fMRI的脑疾病分类中的应用", "title_en": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "authors": "Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang", "background": "静息态fMRI已成为分类大脑疾病和构建大脑功能连接网络的重要工具，通过跟踪整个大脑区域内不同脑区的BOLD信号。然而，现有的模型大多忽视了神经元振荡的多频性质，将BOLD信号视为单一时间序列。这种处理方法忽略了神经学疾病经常在特定频率范围内出现紊乱这一事实，限制了诊断敏感性和特异性。尽管有一些方法试图结合频率信息，但它们往往依赖于预定义的频率范围，这可能不适用于捕捉个体差异或疾病特异性改变。", "innovation": "本文提出了一种新的框架，即自适应级联分解（Adaptive Cascade Decomposition），用于学习每个脑区的任务相关频率子带，并提出了频率耦合连接学习（Frequency-Coupled Connectivity Learning），以在一个统一的功能网络中捕捉多个频带内的互动和跨频带的微妙互动。统一网络提供了新的消息传递机制，驱动统一图卷积网络（Unified-GCN）的节点表征生成，以进行诊断预测。在ADNI和ABIDE数据集上的实验结果表明，该方法相对于现有方法具有更优的性能。", "conclusion": "本文通过引入自适应级联分解和频率耦合连接学习的新框架，以及统一图卷积网络，提出了一种新颖的方法，有效提高了基于fMRI的脑疾病分类的诊断敏感性和特异性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04751", "html_url": "https://arxiv.org/abs/2511.04751", "title": "基于传感器引导的正则化GLISp在人机环优化中的应用", "title_en": "Regularized GLISp for sensor-guided human-in-the-loop optimization", "authors": "Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin", "background": "现有的基于偏好优化的方法通常通过偏好学习来获得最优解，即仅通过对样本进行配对比较，而忽略传感器提供的有用信息。虽然这些方法有效，但它们将系统视为黑箱，无法充分利用传感器数据中的信息。本研究旨在通过引入一种结合了传感器信息和偏好学习的方法，来改进这一局限。", "innovation": "该研究提出了一种传感器引导的正则化GLISp方法，该方法通过物理假设函数和最小二乘正则项将可测量的描述符集成到偏好学习循环中，从而将系统建模为半透明的半模型（灰箱），将其背后的物理逻辑显式反映出来。这种方法保留了偏好学习法的灵活性，但同时结合了主观反馈和定量传感器数据。通过在理论和实际的人机环场景中进行多轮测试，证实了新方法的优越性。", "conclusion": "通过实验证明，所提出的方法在分析基准和人机环车辆悬挂调优任务中的收敛速度更快，最终解的质量也更优。这种方法为传感器数据与主观反馈相结合的优化过程提供了一种新颖的方法，带来了效率和质量的双重提升。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04774", "html_url": "https://arxiv.org/abs/2511.04774", "title": "SLOFetch: 压缩分层指令预取以适应云微服务的SLO驱动型设计方案", "title_en": "SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices", "authors": "Liu Jiang,Zerui Bao,Shiqi Sheng,Di Zhu", "background": "大规模网络服务依赖于深层次的软件堆栈和微服务编排，这增加了指令足迹并导致前端停滞，从而扩大了尾延迟和能耗。为了应对这些云工作负载，研究者们回顾了指令预取技术。本研究专注于SLO驱动和自我优化系统的指令预取设计，构建于Entangling Instruction Prefetcher (EIP)，通过压缩入口和分层元数据存储方案改进了EIP的方法，降低了芯片上的状态大小并提高了机器学习时代的网络服务效率。", "innovation": "引入了具有36位的压缩入口，能够捕获最多八个周围的基址，利用空间聚集；提出一种分层元数据存储方案，保留L1驻留入口并虚拟化批量元数据到较低级别。同时增加了轻量级在线机器学习控制器，使用上下文特征评分预取盈利能力，并调整阈值.", "conclusion": "在数据中心应用程序中，该方法与EIP的加速效果相当，但芯片上的状态更小，并且在机器学习时代提高了网络服务的效率."}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04723", "html_url": "https://arxiv.org/abs/2511.04723", "title": "基于双向LSTM编码解码器的多时间窗时域卷积和融合变换器模型用于剩余使用寿命预测", "title_en": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction", "authors": "Mohamadreza Akbari Pour,Mohamad Sadeq Karimi,Amir Hossein Mazloumi", "background": "工业系统中，健康预测对于确保可靠性、减少停机时间和优化维护至关重要。剩余使用寿命（RUL）预测是这一过程中的关键组成部分。然而，许多现有模型难以捕捉精细的时间依赖性，难以动态优先处理关键特征，从而导致稳健的预测能力不足。", "innovation": "本文提出了一种新颖的框架，将局部时间特征提取的时域卷积网络（TCNs）与改进的时间融合变换器（TFT）结合，后者通过双向LSTM编码解码器进行增强。该架构有效结合了短期和长期依赖关系，强调显着的时间模式。此外，多时间窗方法的引入增强了模型在各种操作条件下的适应性。", "conclusion": "这种框架在基准数据集上的广泛评估表明，所提出的模型能够使平均RMSE降低多达5.5%，证明了其相比最先进的方法有更高的预测准确性。通过填补当前方法的关键空白，该框架推进了工业预诊系统的有效性，并强调了先进的时间序列变换器在RUL预测中的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22990", "html_url": "https://arxiv.org/abs/2510.22990", "title": "USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding", "title_en": "USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding", "authors": "Youssef Megahed,Robin Ducharme,Aylin Erman,Mark Walker,Steven Hawken,Adrian D. C. Chan", "background": "超声成像是最广泛使用的诊断技术之一，能够提供实时、无辐射的跨多个临床领域的评估。然而，超声图像的解释仍然具有挑战性，因为噪声高、依赖操作员和有限的视野，导致了观察者间的变化性。当前的深度学习方法受到缺乏大量标注数据集和超声医学图像与通用图像之间的领域差异的限制，这限制了从非医疗数据预训练的模型的可移植性。", "innovation": "本文引入了首个专为超声数据预训练的大规模自监督MAE框架——超声自监督基础模型与掩码自编码器（USF-MAE）。该模型基于来自46个开源数据集的370,000张2D和3D超声图像进行预训练，涵盖二十多个解剖区域，且该数据集已公开，便于进一步研究和复现。USF-MAE使用视觉变换器编码器-解码器架构，从无标签数据中学习丰富的、模态特定的表示。通过在乳腺癌、卵巢肿瘤和胃肠间质瘤三个公开的下游分类基准上进行微调，USF-MAE在所有任务中均表现出优于传统CNN和ViT基线模型的表现，尤其是在乳腺癌分类任务上接近监督基础模型UltraSam的表现，而在其他任务上超过了它，显示出强大的跨解剖区域泛化能力。", "conclusion": "USF-MAE在不使用标注数据进行预训练的情况下，在多个超声医学图像分类任务中表现出色，通过利用自监督学习和专门的超声数据集，展示了其在超声医学领域的应用潜力，特别体现了其跨不同解剖区域的泛化能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04768", "html_url": "https://arxiv.org/abs/2511.04768", "title": "FuseFlow：针对流数据流的稀疏深度学习融合中心编译框架", "title_en": "FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow", "authors": "Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu", "background": "随着深度学习模型的扩大，稀疏计算和专门化数据流硬件已成为提高效率的强大解决方案。该论文提出了一个名为FuseFlow的编译器，它能将PyTorch中编写的稀疏机器学习模型转换为可编程数据流架构（RDAs）的融合稀疏数据流图。FuseFlow是第一个支持跨表达式融合稀疏操作的编译器。除了跨内核（表达式）的融合外，它还支持如并行化、数据流动排序和稀疏性区块化等优化。该编译器针对一个周期准确的数据流模拟器，进行微架构分析，以探索融合策略。我们使用FuseFlow在四个具有稀疏性的实际机器学习应用中进行设计空间探索，发现全融合（端到端模型内所有计算的跨表达式融合）并非总是稀疏模型的最佳选择，融合粒度取决于模型本身。FuseFlow还提供了一个启发式方法来识别并削减不合适的配置。将FuseFlow应用于GPT-3使用BigBird区块稀疏注意机制时，实现了约2.7倍于非融合基线的速度提升。", "innovation": "FuseFlow是第一个支持跨表达式融合稀疏操作的编译器。它不仅支持跨内核的融合，还包括并行化、数据流动排序和稀疏性区块化等优化。它还提供了一种用于识别和削减不合适的配置的启发式方法，以及通过对四个现实世界机器学习应用的设计空间探索，展示了全融合并非总是最佳选择，具体的融合粒度取决于模型本身。通过使用FuseFlow，能够实现显著的速度提升，如GPT-3在BigBird区块稀疏注意机制下的约2.7倍加速。", "conclusion": "该研究通过FuseFlow编译器展示了根据模型特性进行灵活的稀疏操作融合，能够在保持高性能的同时，优化设计空间。FuseFlow提供了一种方法，使得即使在稀疏模型中，也能实现对计算的更精细的调控，从而达到最佳性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04789", "html_url": "https://arxiv.org/abs/2511.04789", "title": "基于条件神经ODE的纵向帕金森病进展预测", "title_en": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting", "authors": "Xiaoda Wang,Yuji Zhao,Kaiqiao Han,Xiao Luo,Sanne van Rooij,Jennifer Stevens,Lifang He,Liang Zhan,Yizhou Sun,Wei Wang,Carl Yang", "background": "帕金森病（PD）表现出异质性和动态变化的脑形态学模式。建模这些纵向轨迹能提供机制洞见、促进治疗方法的发展和个体化的‘数字双胞胎’预测。然而，现有方法通常采用循环神经网络和变换器架构，这些方法依赖于离散的、规律采样的数据，而难以处理帕金森病（PD）簇中不规则和稀疏的磁共振成像（MRI）数据。另外，现有方法难以捕捉个体差异，包括疾病发病时间、进展速度和症状严重程度的变异性，这些都是帕金森病特有的特征。", "innovation": "为了应对这些挑战，该论文提出了CNODE（条件神经ODE），这是一种新的框架，用于连续的、个体内化的帕金森病进展预测。CNODE的核心是通过神经ODE模型将形态学脑变化建模为连续的时间过程。此外，CNODE还联合学习患者特异的初始时间和进展速度，使各自的轨迹对齐到共享的进展轨迹。实验证实在帕金森病数据倡议（PPMI）数据集上的验证显示，该方法优于最先进的基准方法，在纵向帕金森病进展预测中表现出更优越的效果。", "conclusion": "CNODE框架通过联合学习患者特异的初始时间和进展速度，将个体化的PD进展轨迹对齐到一个共享的进展轨迹中，实现了更有效的纵向PD进展预测，并通过实验证明了其优势。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04790", "html_url": "https://arxiv.org/abs/2511.04790", "title": "生物医学应用中的因果结构与表示学习", "title_en": "Causal Structure and Representation Learning with Biomedical Applications", "authors": "Caroline Uhler,Jiaqi Zhang", "background": "大规模数据收集有助于更深入地理解复杂现象，并最终做出更好的决策。表示学习已成为深度学习应用的关键驱动力，因为它能够学习捕捉数据重要属性的潜在空间，而无需任何监督注解。尽管表示学习在预测任务中取得了巨大成功，但在预测干预效果等因果任务中却可能表现不佳。这需要将表示学习与因果推理相结合。在这种背景下，随着多模态数据（观察和干预、基于成像和测序、单细胞、组织和生物体水平）的日益可用，提出了一个结合因果结构学习与表示学习的统计和计算框架。", "innovation": "本文提出了一个结合因果结构学习与表示学习的统计和计算框架，旨在利用多模态数据（观察和干预、基于成像和测序、单细胞、组织和生物体水平）回答基本的生物医学问题：如何有效地利用观察和干预数据进行因果发现；如何利用系统多模态视图学习因果变量；以及如何设计最优的干预措施。", "conclusion": "通过这种将因果结构学习和表示学习相结合的新框架，可以更有效地利用多模态数据来研究因果变量，推动生物医学研究的进步。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04814", "html_url": "https://arxiv.org/abs/2511.04814", "title": "一个用于多标签抗微生物肽分类的标准基准", "title_en": "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification", "authors": "Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez", "background": "抗微生物肽已经作为一种有前途的分子来应对抗微生物耐药性，但由于数据碎片化、注解不一致以及缺乏标准化基准，阻碍了计算方法的应用并减缓了新候选者的发现速度。", "innovation": "我们提出了扩展标准化抗微生物肽评价集合(ESCAPE)，这是一个实验框架，集成了超过80,000个肽，来自27个验证的数据库。我们构建了一个基于变换器模型，利用序列和结构信息来预测肽的多种功能活动。这种方法在平均精度平均值方面比第二好的方法提高了2.56%的相对平均改进，建立了多标签肽分类的新最先进的水平。", "conclusion": "ESCAPE为AI驱动的抗微生物肽研究提供了全面和可重复的评估框架。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04825", "html_url": "https://arxiv.org/abs/2511.04825", "title": "机器学习应用中的持续可达性同调", "title_en": "Persistent reachability homology in machine learning applications", "authors": "Luigi Caputi,Nicholas Meadows,Henri Riihimäki", "background": "本研究探讨了最近引入的有向图数据的持久可达性同调（PRH），即数据以有向图的形式呈现。研究特别关注PRH在神经科学问题中的网络分类任务中的有效性，即癫痫检测。PRH是基于定向旗复杂（DPH）的持久同调的一种变形，主要优势在于它考虑了持久滤波器中出现的有向图的凝集，从而无需从更大的有向图开始计算。", "innovation": "相比传统的基于定向旗复杂（DPH）的持久同调，PRH通过考虑持久滤波器中出现的有向图的凝集，计算来自较小的有向图，从而提高了效率。研究结果表明，PRH在分类任务中的表现优于DPH。研究还使用贝蒂曲线及其积分作为拓扑特征，并在支持向量机上实现了整个流程。", "conclusion": "研究证明了PRH在癫痫检测网络分类任务中的优越性，并通过贝蒂曲线及其积分作为拓扑特征的应用，展示了其实用价值。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04838", "html_url": "https://arxiv.org/abs/2511.04838", "title": "SPECTRA: 基于光谱目标感知的图增强方法用于分子属性不平衡回归", "title_en": "SPECTRA: Spectral Target-Aware Graph Augmentation for Imbalanced Molecular Property Regression", "authors": "Brenda Nogueira,Meng Jiang,Nitesh V. Chawla,Nuno Moniz", "background": "在分子属性预测中，最具价值的化合物（例如高活性）往往位于目标空间的稀疏区域。标准图神经网络（GNN）通常优化平均误差，对于这些罕见但关键的情况表现不佳。现有的过采样方法经常破坏分子拓扑结构，因此需要一种新的方法来生成稀疏区域的现实分子图，以提高模型在这些关键区域的表现。", "innovation": "SPECTRA 是一种基于光谱的目标感知图增强框架，它在光谱域中生成现实的分子图。SPECTRA 通过以下步骤实现：（i）从 SMILES 重建多属性分子图；（ii）通过（融合）Gromov-Wasserstein 耦合对分子配对，获得节点对应；（iii）在稳定的共享基中插值拉普拉斯特征值和特征向量；（iv）重建边以合成带有插值目标的物理上可能的中间体。稀有数据预算机制从核密度估计中导出，集中在数据稀缺的地方进行增强。与基于光谱的 GNN 结合使用，SPECTRA 在不牺牲全局准确性的前提下，填充了未充分代表的区域，并且在基准测试中能够在相关目标范围内一致性地改善误差，同时保持竞争力的整体 MAE。此外，生成的合成分子结构能够反映其背后的光谱几何结构。这些结果表明，基于光谱和几何感知的增强是不平衡分子属性回归的有效且高效的策略。", "conclusion": "SPECTRA 在稀疏区域的性能优于标准 GNN，并且能够生成反映潜在光谱几何结构的可解释合成分子。该方法有效地应对了数据分布不平衡的问题。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04845", "html_url": "https://arxiv.org/abs/2511.04845", "title": "基于声明偏好和机器学习方法调查具有创新性运输证书的美国消费者对食品产品的需求", "title_en": "Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches", "authors": "Jingchen Bi,Rodrigo Mesa-Arango", "background": "先前的研究已经通过声明偏好分析（离线模式）研究了供应链追溯信息对食品产品需求的影响，发现运输因素在消费者购买决策中起着重要作用。基于此研究背景，本文进一步探讨了具有创新性运输证书的食品产品在美国市场上的消费者需求，并通过机器学习模型对特定的运输属性进行了分析，揭示了运输方向方面美国食品供应链中的消费者偏好评价和选择差异。", "innovation": "本文创新地将机器学习模型应用于消费者行为估计，针对具有创新性运输证书的食品产品，提出了五种创新证书：运输模式、物联网、安全措施、能源来源和必须到达日期（MABDs）。此外，还结合产品特性和决策者因素进行用户偏好的实验，发现了消费者对运输方向中安全和能源证书的显著偏好，提供了提高食品供应链系统的数据驱动建议。", "conclusion": "研究结果表明，在美国食品供应链的运输方向中，消费者对于安全和能源证书有明显的倾向。研究还考察了价格、产品类型、证书以及决策者因素对购买选择的影响。最终，研究得出了关于改进食品供应链系统的数据驱动建议。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04805", "html_url": "https://arxiv.org/abs/2511.04805", "title": "PuzzleMoE: 通过稀疏专家合并和位打包推理高效压缩大型混合专家模型", "title_en": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference", "authors": "Yushu Zhao,Zheng Wang,Minjia Zhang", "background": "Mixture-of-Experts (MoE) 模型展示出了在高效扩展语言模型方面的强大潜力，但由于存储所有专家参数带来的高内存开销限制了其广泛应用，尤其是在专家数量增加时问题更加突出。尽管一些先前的工作探索了专家弃用和合并策略，但在高压缩率下性能下降是一个普遍问题。", "innovation": "PuzzleMoE 通过两个关键创新点解决了这些问题：1. 稀疏专家合并，通过识别元素级权重冗余和专业化来确定共享和专家特异性参数。2. 引入位打包编码方案，通过重用未充分利用的指数位，避免了存储二进制掩码和符号所带来的开销，并在图形处理器上实现了高效的MoE推理。", "conclusion": "实验结果表明，PuzzleMoE 可以将 MoE 模型压缩高达 50% 而不影响准确性。特别是在 50% 压缩率下，PuzzleMoE 在 MMLU 任务上的性能比之前的方法高出 16.7%，并且达到了 1.28 倍的推理加速。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04847", "html_url": "https://arxiv.org/abs/2511.04847", "title": "基于环境适应的测试时调整用于大模型 agents", "title_en": "Grounded Test-Time Adaptation for LLM Agents", "authors": "Arthur Chen,Zuxin Liu,Jianguo Zhang,Akshara Prabhakar,Zhiwei Liu,Shelby Heinecke,Silvio Savarese,Victor Zhong,Caiming Xiong", "background": "基于大语言模型的代理在面对新颖和复杂的环境时，如未见过的网页或新功能集时表现出困难。这种挑战源于前三轨不一致，即预训练与测试条件之间的不符，导致代理在语法理解环境特定组件（如观察格式）和语义理解状态转换动力学方面存在问题。前一轨问题只在测试时显现，而后者在交互中表现出来。为解决这些问题，本文提出两种针对大模型代理的适应策略，以利用部署过程中可用的环境特定信息。", "innovation": "策略一：一种在线分布适应方法，通过学习轻量级的适应向量来对模型的输出分布进行偏置，以快速调整与环境响应格式的一致性。策略二：一种部署时动力学定位方法，利用角色驱动的探索阶段来系统地探测和学习环境的动力学特性，从而给代理一个非参数化世界模型。策略在多种代理基准测试上得到实证验证，证明了其有效性和部署代价的极小化。在复杂环境中，动力学定位尤其有效，显著提高了代理的成功率，特别是在WebArena多站点分割测试中，代理成功率从2%提升至23%。", "conclusion": "这些策略展示了更具适应性且强大的大模型代理路径，特别是在复杂且具挑战性环境中取得了显著进步。这种适应机制有助于提高代理在未知环境中的表现和泛化能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04856", "html_url": "https://arxiv.org/abs/2511.04856", "title": "量子玻尔兹曼机在样本高效强化学习中的应用", "title_en": "Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning", "authors": "Thore Gerlach,Michael Schenk,Verena Kain", "background": "传统玻尔兹曼机和量子玻尔兹曼机主要用于概率计算，但在连续动作强化学习中有应用限制。本文基于理论支持提出了连续半量子玻尔兹曼机（CSQBMs），结合了可见单元的指数族先验和隐藏单元的量子玻尔兹曼分布，实现了量子和经典计算的混合模型。", "innovation": "本文通过连续半量子玻尔兹曼机，提出了一种综合了量子和经典计算优势的方法，减少了量子比特的需求同时保持了强大的表征能力。特别地，连续变量的梯度可以解析计算，直接应用于Actor-Critic算法。进一步开发了一种新的连续强化学习框架，用CSQBM分布的高效采样代替全局最大化，解决了连续控制中的不稳定问题。", "conclusion": "连续半量子玻尔兹曼机能够在样本高效强化学习场景中提供一种新的算法框架，通过解析计算梯度和采样方法优化了连续动作的处理能力，有望提高强化学习的效率和稳定性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04791", "html_url": "https://arxiv.org/abs/2511.04791", "title": "DuetServe：通过自适应GPU复用实现预填充和解码的协调", "title_en": "DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive GPU Multiplexing", "authors": "Lei Gao,Chaoyi Jiang,Hossein Entezari Zarch,Daniel Wong,Murali Annavaram", "background": "现代大语言模型（LLM）服务系统必须在满足两个不同推理阶段的高度严格延迟SLOs的同时维持高吞吐量：计算密集型的预填充阶段和内存限制的解码阶段。现有方法要么将这两个阶段嵌入到共享的GPU中，这会导致预填充和解码之间的干扰，降低时间间隔内生成的token数（TBT）；要么将这些阶段分散到不同的GPU上，虽然可以提高延迟但会浪费资源，因为需要多次复制模型和KV缓存转移。", "innovation": "我们提出了一种名为DuetServe的统一LLM服务框架，在单个GPU内实现了两个阶段的资源配置隔离。默认模式下联合这两个阶段，通过细粒度和自适应的SM级别GPU空间复用机制，在预测到时间间隔内生成的token数（TBT）恶化时激活。其核心思想是仅在冲突威胁到延迟SLOs时才解耦预填充和解码执行。DuetServe结合了一种基于注意力的屋顶线模型来预测迭代延迟，一种分区优化器以在TBT约束下最大化吞吐量，以及一种中断无感知的执行引擎以消除CPU-GPU同步开销。", "conclusion": "评估结果表明，DuetServe在保持低生成延迟的情况下，与最新的框架相比，总吞吐量最高提升了1.3倍。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04834", "html_url": "https://arxiv.org/abs/2511.04834", "title": "基于提示的安全指导对未学习的文本到图像扩散模型无效", "title_en": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models", "authors": "Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon", "background": "近年来，文本到图像生成模型取得了显著进步，但当输入恶意文本提示时，可能会生成有害内容，引发担忧。目前采用了两种主要应对策略：一是对模型进行微调以消除有害概念；二是使用无训练指导方法和负提示。然而，两种方法在结合时往往表现不佳，甚至出现性能下降的情况，表明两者之间存在关键性不兼容问题，阻碍了它们的综合效果。", "innovation": "本文提出了一种简单而稳健的方法，通过概念反转获得隐式负嵌入，替换无训练指导方法中的负提示。该方法无需修改现有两种方法中的任何一种，并且可以很容易地整合到现有管道中。通过在裸体和暴力基准测试中的实验验证，证明该方法能有效提高防御成功率，同时保留输入提示的核心语义。", "conclusion": "研究发现，基于提示的安全指导方法对未学习的文本到图像扩散模型是无效的。本文提出的方法通过引入隐式负嵌入解决这一问题，能有效提升模型的防御性能，且无需对现有方法进行修改，具有较高的实用性和推广价值。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04883", "html_url": "https://arxiv.org/abs/2511.04883", "title": "自私与系统性利益：通过深度强化学习在混合自主交通中集体理性 emerge 的机制", "title_en": "Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning", "authors": "Di Chen,Jia Li,Michael Zhang", "background": "自主驾驶车辆（AV）预计在未来短时间内商业上市，将与人类驱动车辆（HVs）共存，形成混合自主交通系统。以往研究表明，通过将系统级目标纳入决定，AV 能够提高整体交通系统性能，但在代理出于自我利益行动的情况下，这些益处是否仍然存在尚不清楚。本研究旨在探讨在混合自主交通系统中，自我利益的AV 是否能带来所有驾驶代理的益处。研究基于集体理性（CR）的概念，揭示了在深度强化学习（DRL）训练和简单奖励设计中，CR 的实现方式，并验证了其在微观和动态环境中的机制。", "innovation": "通过证明集体理性可以通过深度强化学习在训练的自主驾驶代理中实现，并且这种集体理性能够在多种场景中持续出现，研究揭示了一种通过高级学习方法促进自我利益代理间集体合作的机制。", "conclusion": "研究结果表明，集体理性能够在多种场景中持续出现，表明其在混合自主交通系统中的鲁棒性。此外，通过模拟证据验证了集体理性在微观和动态环境中的机制，并表明可以通过联邦学习等高级学习方法在自我利益的驾驶代理中实现集体合作。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04844", "html_url": "https://arxiv.org/abs/2511.04844", "title": "DDPMs 可以满足次线性迭代", "title_en": "Sublinear iterations can suffice even for DDPMs", "authors": "Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi", "background": "基于SDE的方法，如去噪扩散概率模型（DDPMs），在现实世界的样本生成任务中展现了显著的成功。之前的分析主要集中在指数欧拉离散化上，这些保证通常至少线性依赖于维度或初始费雪信息。受Shen和Lee在Log-Convex采样中工作的影响，本文研究了一种新的积分方法——去噪扩散随机中点方法（DDRaM），该方法利用了额外的随机中点来更好地逼近SDE。", "innovation": "本文通过引入新的分析框架——‘位移复合法则’，证明了这种算法在适当的光滑性假设下具有有利的离散化特性。在预训练的图像合成模型上进行的实验验证表明，该方法在实践中表现出良好的性能，并且这种算法具有次线性复杂度，以前的工作虽然也得到了这样的复杂度，但它们做了与实际使用中不一致的修改，转而使用基于ODE的采样。", "conclusion": "这是首次针对纯DDPM采样的次线性复杂度界限，前人的工作为此目标主要采用了基于ODE的采样方法，需要对采样器进行偏离实际使用的修改。通过新的分析框架显示了该算法的优越之处，表现为次线性复杂度，并且在实践实验中表现出良好的效果。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04902", "html_url": "https://arxiv.org/abs/2511.04902", "title": "你需要推理来学习推理：弱基础模型中无标签RL的局限性", "title_en": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models", "authors": "Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei", "background": "近年来，大型语言模型展示了无监督强化学习（RL）方法在增强推理能力方面的潜力，无需外部监督。然而，这些无标签的RL方法在更小的基础模型上是否具有广泛的适用性，这些基础模型本身推理能力有限，这一领域尚未得到开发研究。本文系统地探讨了不同规模和推理能力从0.5B到7B参数模型的无标签RL方法的表现。实验证明，无标签RL高度依赖基础模型原有的推理能力，较弱模型的性能往往低于基准水平，因为小型模型无法生成足够的长和多样化的思路来进行有效的自我反思，数据集难度在决定成功方面起着关键作用。", "innovation": "本文提出了一种简单有效的无标签RL方法，通过使用课程学习在训练过程中逐步引入更难的问题，以及在训练期间屏蔽非多数票的输出。此外，还提出了一个数据整理管道来生成具有预定义难度样本。该方法在所有模型规模和推理能力上都表现出一致的改进，提供了一条通往更稳健的无监督RL的道路，可以增强资源受限模型的推理能力。同时，作者提供了代码，见这个 <https://example.com>。", "conclusion": "通过加大数据集难度和应用课程学习，文章提出的方法解决了弱基础模型中无标签RL的挑战，展示了在不同模型规模和推理能力中的一致改进，为较为有限的资源模型增强推理能力提供了新的途径。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04804", "html_url": "https://arxiv.org/abs/2511.04804", "title": "Simplex-FEM Networks (SiFEN): 学习构建三角划分函数逼近器", "title_en": "Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator", "authors": "Chaymae Yahyati,Ismail Lamaakal,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh", "background": "该研究构建了一种新的预测模型Simplex-FEM Networks (SiFEN)，将其定义为一个在学习得到的简化网格上的分段多项式预测器，用于将 f: R^d -> R^k 映射表示为输入空间中可选扭曲后的全局 C^r 有限元场。背景介绍了SiFEN在逼近、缓存友好性、局部性和可控光滑性等方面的优势，并描述了其在合成逼近任务、表格回归/分类任务以及作为紧凑卷积神经网络附加头的应用中的性能表现，特别是在参数预算相同的情况下，与MLPs和KANs相比，SiFEN在校准（较低的ECE/Brier）和推断延迟方面有所改进。该研究还证明了标准几何正则化和拟双唇形扭曲假设下SiFEN能达到经典的FEM逼近速度M^(-m/d)。", "innovation": "SiFEN采用了度数m的伯恩斯坦-比萨多项式，并结合了轻微的可逆扭曲，通过端到端训练和形状正则化、半离散OT覆盖和可微边缘翻转进行学习。SiFEN在逼近任务、表格回归/分类任务以及作为紧凑卷积神经网络附加头的应用中展现出卓越性能，其特点是紧凑性、可解释性和理论依据，作为密集MLPs和边缘样条网络的替代品。", "conclusion": "在标准几何正则性和拟双唇形扭曲假设下，SiFEN可以达到经典的FEM逼近速度M^(-m/d)。实验结果表明，在合成逼近任务、表格回归/分类任务以及作为紧凑卷积神经网络附加头的应用中，SiFEN与MLPs和KANs相比拥有更高的校准质量和更低的推断延迟。该方法在效率、校准和理论依据方面为未来的研究提供了有价值的参考。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04904", "html_url": "https://arxiv.org/abs/2511.04904", "title": "多代理Craftax：在超大规模下评估开放环境多代理强化学习", "title_en": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale", "authors": "Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster", "background": "多代理强化学习（MARL）的进步需要具有挑战性的基准测试，以评估当前方法的极限。然而，现有的基准测试往往侧重于狭窄的短期挑战，未能充分测试多代理系统中固有的长期依赖性和泛化能力。文章提出了Craftax-MA和Craftax-Coop两个扩展环境，后者包含不同类型的代理、交易机制等，需要复杂的相互协作，全面提升对MARL算法的挑战，推动MARL的长期研究。", "innovation": "Craftax-MA和Craftax-Coop，前者扩展了开放式强化学习环境Craftax，适用于多代理和广泛的能力评估；后者则引入了异质代理、交易和其他机制，要求复杂的协作，旨在提供更具有挑战性的MARL测试环境。Craftax-MA用JAX编写，训练速度极快，25000万环境互动可在不到一个小时的时间内完成。这些环境为评估MARL算法提供了新的工具，并推动长期的研究发展。", "conclusion": "现有的算法在Craftax-Coop基准中表现不佳，未能解决长时信用分配、探索和协作等关键挑战。Craftax-Coop作为一种新型的基准测试环境，展示了其在促进MARL长期研究的潜力，并具有驱动MARL领域发展的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04918", "html_url": "https://arxiv.org/abs/2511.04918", "title": "机器学习算法在统计建模中的应用：理论与实践的桥梁", "title_en": "Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application", "authors": "A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi", "background": "该研究探讨了将机器学习（ML）算法与传统统计建模方法集成的新颖方式，这种集成方式正在彻底改变我们分析数据、进行预测性分析或在数据科学领域做出决策的方式。研究人员研究了现代ML算法如何增强传统模型，并展示了新的算法如何提高传统模型的性能、可扩展性、灵活性和鲁棒性。实验证明了混合模型在预测准确性、鲁棒性和可解释性方面的显著改进.", "innovation": "该论文提出了一种全新的集成ML算法与传统统计建模的方法，使得传统模型能够从现代ML算法中获益，从而显著提高了模型的预测性能、可扩展性、灵活性和鲁棒性。这种新方法为数据科学领域提供了理论依据和实践指导，促进了理论与实际应用的结合.", "conclusion": "研究表明，混合模型在多个方面均表现出色，尤其是在预测准确性、鲁棒性以及模型的可解释性上。这种新方法为数据分析师和研究人员提供了一种强大的工具，有助于改善决策过程并提高数据驱动的应用性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04909", "html_url": "https://arxiv.org/abs/2511.04909", "title": "关于决策导向学习的一种双重视角：通过双边引导替代目标的可扩展训练", "title_en": "A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates", "authors": "Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson", "background": "许多现实世界的决策是在不确定性中通过预测量来解决优化问题而做出的。预测-然后-优化的范式激发了决策导向学习的发展，这种学习方法是在了解优化器如何使用预测的基础上训练模型，从而提高下游决策的性能。然而，即使有这些潜力，扩大这种方法的应用仍然具有挑战性。最先进的方法要么通过求解器进行梯度计算，要么依赖于特定的任务替代目标，这两种方法都需要频繁且昂贵的优化器调用，通常是一种组合优化器。", "innovation": "本文利用下游问题的双重变量来引导学习，并引入了双边引导损失（DGL），这是一种简单且可扩展的目标函数，既能保持决策一致性又能减少对求解器的依赖。DGL专门为具有自然的“或其一”约束的组合选择问题设计，如匹配、背包和最短路径。本文的方法通过（a）部分将优化与梯度更新解耦，仅周期性地解决下游问题；（b）通过使用简单的可微替代目标进行训练；（c）随着刷新频率降低，使训练成本向标准的监督学习靠拢，但仍然保持很强的决策一致性。通过理论证明DGL具有渐进地减少决策悔悟率，对运行时复杂度进行分析，并在两个问题类上展示了DGL不仅与最先进的决策导向学习方法相比，性能相当甚至更优，同时使用了更少的求解器调用次数和显著减少了训练时间。", "conclusion": "研究证明了DGL的有效性，并展示了其性能与状态-of-the-art方法相当甚至更优，同时使用更少的求解器调用次数和显著减少了训练时间。这为解决大规模组合选择问题提供了更优秀的方案，通过双边引导替代目标实现可扩展训练。代码可在以下网址获取：这个 https URL"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04937", "html_url": "https://arxiv.org/abs/2511.04937", "title": "EM算法在混合线性回归中的结构特性、摆线轨迹和非渐进保证", "title_en": "Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression", "authors": "Zhankun Luo,Abolfazl Hashemi", "background": "最近的研究已经证明，当混合线性回归（2MLR）的权重已知并平衡时，EM算法可以实现全局收敛，并在无噪声和高信噪比（SNR）条件下达到超线性收敛。然而，在权重和回归参数完全未知的情况下，EM算法的理论行为仍不清楚，其轨迹和收敛速度仍需进一步研究。", "innovation": "本文推导了在所有SNR条件下，未知混合权重和回归参数的2MLR环境下EM算法的更新表达式，并分析了其结构特性与摆线轨迹。在无噪声情况下，通过建立亚优化角度的递推关系证明了回归参数迭代的轨迹为摆线；在高信噪比情况下，则量化了其与摆线轨迹的偏差。分析表明，当EM估计值几乎与真实值正交时，收敛速度为线性；当角度较小时，收敛速度为平方阶。此外，还通过细化有限样本与总体EM更新之间的统计误差边界，联系EM的统计准确性和亚优化角度，并证明了任意初始化条件下的收敛性，建立了非渐进保证。", "conclusion": "本文提供了一种基于轨迹的新框架，用于分析混合线性回归中的EM算法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04934", "html_url": "https://arxiv.org/abs/2511.04934", "title": "Leak@$k$: 未学习不应在概率解码下使LLM忘记", "title_en": "Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding", "authors": "Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong", "background": "大规模语言模型（LLMs）在监管合规性和构建避免生成私人、有毒、非法或版权受保护内容的伦理生成AI系统方面至关重要。尽管取得了快速进展，这项工作中我们展示出几乎所有现有的未学习方法在实践中并未实现真正遗忘。虽然在确定性（贪婪）解码下，这些所谓已“未学习”模型的标准基准评估通常表明成功删除了知识（如文献中所做），但我们证明当模型采用标准概率解码时，敏感信息会可靠地重新出现。为了严格捕捉这一漏洞，我们引入了leak@$k$，一种新的元评估度量，量化在现实解码策略下生成$k$个样本时遗忘知识重新出现的可能性。我们使用广受欢迎的基准测试TOFU、MUSE和WMDP，系统地开展了第一次大规模的未学习健壮性研究，使用我们的新定义的leak@$k$指标。", "innovation": "引入了leak@$k$，一种新的元评估度量，用于衡量在现实解码策略下生成$k$个样本时遗忘知识重新出现的可能性。通过使用广受欢迎的基准测试TOFU、MUSE和WMDP，系统地开展了第一次大规模的未学习健壮性研究。", "conclusion": "我们发现知识泄露在各种方法和任务中普遍存在，这意味着当前最先进的未学习技术仅提供有限的遗忘，并突显了开发更健壮的LLM未学习方法的紧迫需求。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04907", "html_url": "https://arxiv.org/abs/2511.04907", "title": "可高效实现的交换多校准性质", "title_en": "Efficient Swap Multicalibration of Elicitable Properties", "authors": "Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan", "background": "多校准 [HJKRR18] 是一种算法公平性视角，要求预测器的预测结果在其自身及潜在重叠的人群子集成员身份上是正确的。 [NR23] 工作提出了一个意外的联系，即对于任意性质Γ（如均值或中位数）的多校准与性质的激发之间存在联系：如果一个性质Γ可以激发，则它也可以被多校准。在在线设置中，[NR23] 提出了一种效率低下的算法，该算法在与预报者和对手互动 T 轮后，以 $\theta \times \text{log}(T)/\text{log} (\text{log}(T))$ 的 $\text{ℓ}_2$-多校准误差执行，其中 $\theta$ 是组成员身份函数类别的特征系数。该领域先前的研究 [NR23, GMS25, LSS25a] 在 $\text{ℓ}_2$-多校准误差方面有更严格的上限。", "innovation": "本文将多校准性质Γ从组成员身份函数推广到任意有界假设类别，并引入了更强的概念——交换多校准，后续提出一个查询高效的算法，该算法在给定访问在线无偏学习器时，使用高概率实现了 $T^{1/(r+1)}$ 的 $\text{ℓ}_r$-交换多校准误差（对于 $r \textgreater 2$）。特别地，当 $r=2$ 时，对于均值这种可激发的性质Γ，该算法实现了 $T^{1/3}$ 的 $\text{ℓ}_2$-交换多校准误差，显著提升了先前的界，并完全解决了 [GJRR24] 上提出的一个开放性问题，即是否可以通过一个查询高效的算法实现 $\text{ℓ}_2$-均值的 $\text{O}(\text{√T})$ 多校准误差，通过它的论述给出了一个肯定的解决方法。", "conclusion": "该研究提出的新方法和新概念（即交换多校准）不仅扩大了多校准的应用范围，而且还提供了更为高效的算法，特别是在处理 $\text{ℓ}_2$-交换多校准误差上。同时，它还回应了一个开放性问题并给出了解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04971", "html_url": "https://arxiv.org/abs/2511.04971", "title": "使用机器学习和深度学习技术预测糖尿病患者的冠心病风险", "title_en": "Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques", "authors": "Esha Chowdhury(Dhaka University of Engineering &amp; Technology Gazipur, Bangladesh)", "background": "准确预测心血管疾病(CVD)风险对医疗机构至关重要。此研究旨在应对糖尿病发病率日益增长及其与心脏病之间强烈关联的问题，通过使用机器学习(ML)和混合深度学习(DL)方法来提出CVD风险预测模型。", "innovation": "研究采用BRFSS数据集进行预处理，并且探索了多种机器学习模型（包括决策树、随机森林、K近邻、支持向量机、AdaBoost、XGBoost等）和多种深度学习模型（包括人工神经网络、深度神经网络、循环神经网络、卷积神经网络、长短期记忆、双向长短时记忆、门控循环单元，以及卷积神经网络与长短时记忆、双向长短时记忆、门控循环单元的混合模型）。研究发现XGBoost和LSTM模型分别在准确率方面取得了最高成绩，为0.9050。此研究突显了使用ML和DL模型来预测糖尿病患者CVD风险的有效性，为临床决策提供了自动化和增强工具。", "conclusion": "高准确率和F1分数表明这些模型有潜力改善个性化的风险管理和预防策略。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04865", "html_url": "https://arxiv.org/abs/2511.04865", "title": "FoodRL：基于强化学习的实物食品捐赠预测集成框架", "title_en": "FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting", "authors": "Esha Sharma,Lauren Davis,Julie Ivy,Min Chi", "background": "食品银行在缓解食品不安全问题方面起着关键作用，但其效率取决于精准预测高度波动的实物捐赠，以确保资源的公平和高效分配。传统的预测模型由于季节变化、自然灾害（如美国东南部的飓风和美国西海岸的野火）等不可预测的波动和概念漂移，往往无法保持一致性准确性。为了应对这些挑战，本研究提出了一种名为FoodRL的创新强化学习（RL）基于元学习框架，该框架能够根据近期表现和上下文信息分类并动态加权多种预测模型，以提供更加可靠和适应性的预测。", "innovation": "FoodRL是一种基于强化学习的元学习框架，用于分类和动态加权多种预测模型，基于近期表现和上下文信息。该框架可以在多种情况下提供比基线方法更准确的预测，尤其是在中断或下降期间表现出显著优势。此外，FoodRL展示了其在社会影响以及人道主义供应链的适应性集成学习方面的潜力，有望为食品公益分配提供170万额外餐食每年的可靠预测，从而提高食品捐赠的效率和公平性。", "conclusion": "FoodRL能够在多批次数据下超越基准方法，特别是在中断或衰退期间表现出众。通过提供更加可靠和适应性的预测，FoodRL可以促进年度额外170万份等值餐食的再分配，展示了其在社会影响及适应性集成学习在人道主义供应链中的巨大潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04979", "html_url": "https://arxiv.org/abs/2511.04979", "title": "ROC-优化的支持向量机的扩展", "title_en": "Scaling Up ROC-Optimizing Support Vector Machines", "authors": "Gimun Bae,Seung Jun Shin(Department of Statistics, Korea University, Seoul, Republic of Korea)", "background": "ROC-支持向量机（ROC-SVM）最初由Rakotomamonjy提出，直接最大化受试者工作特征曲线下的面积（AUC），在类别不平衡存在的情况下，成为传统二元分类的有吸引力的替代方案。然而，其实际应用受到高计算成本的限制，因为训练时需要评估所有$O(n^2)$。", "innovation": "开发了一种使用不完全U-统计的可扩展版本的ROC-SVM，从而显著降低了计算复杂度。进一步通过低秩核近似将框架扩展到非线性分类，使得在再生核希尔伯特空间中高效训练成为可能。理论分析确立了一个误差界限，证明了所提出的近似方法的有效性。通过合成和真实数据集上实验的结果表明，所提方法在大幅度减少训练时间的同时实现了与原始ROC-SVM相当的AUC性能。", "conclusion": "该方法结合了低秩核近似和不完全U-统计，从而既保持了ROC-SVM的优越性能，又大幅缩短了训练时间。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04854", "html_url": "https://arxiv.org/abs/2511.04854", "title": "SigmaDock: 使用基于碎片的SE(3)扩散简化分子对接", "title_en": "SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion", "authors": "Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris", "background": "在药物发现中，确定配体与蛋白质结合的构象，即分子对接，是一项基本任务。生成方法在配体构象采样速度、多样性和化学可行性方面比物理方法更快、更好，但这些方法往往受限于输出的化学不可行性、难以泛化以及高昂的计算成本。", "innovation": "提出了一种新颖的碎片化方案，利用结构化学的归纳偏置来将配体分解为刚体碎片，建立在这种分解之上引入SigmaDock模型，这是一种基于SE(3)黎曼扩散模型，通过学习在结合口袋内重新组装这些刚体来生成配体构象。通过在碎片级别操作，SigmaDock利用了成熟的几何先验知识，避免了复杂的扩散过程和不稳定的训练动态。实验表明，SigmaDock在PoseBusters数据集上的Top-1成功率（RMSD<2 & PB有效）达到了79.9%，远高于最近深度学习方法的12.7-30.8%，同时在未见蛋白质上的泛化表现一致。SigmaDock是首个在PB训练-测试集上超越基于物理的经典分子对接的深度学习方法，标志着深度学习在分子建模可靠性与可行性方面取得了重大进展。", "conclusion": "SigmaDock通过引入基于碎片的SE(3)扩散方法，显著提高了分子对接的效率和准确性，解决了化学不可行性、难以泛化和计算成本高等问题。在实验中，SigmaDock在多种评估指标上都超过了现有的深度学习方法，展现了卓越的泛化能力，标志着深学习在分子模型领域的可靠性提升。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04984", "html_url": "https://arxiv.org/abs/2511.04984", "title": "Peptide2Mol：基于扩散模型的小分子肽模拟物生成", "title_en": "Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding", "authors": "Xinheng He,Yijia Zhang,Haowei Lin,Xingang Peng,Xiangzhe Kong,Mingyu Li,Jianzhu Ma", "background": "结构导向的药物设计随着人工智能（AI）的集成取得了显著进展，尤其是在活性物质和先导化合物的生成中。但大多数AI驱动的方法忽视了内源性蛋白质与肽之间相互作用的重要性，可能导致次优分子设计。由于缺乏对这些相互作用的考虑，生成的分子可能无法实现最佳生物活性。已有研究方法多专注于肽和蛋白质口袋环境的直接结合，未能充分利用这一双重信息进行优化生成。Peptide2Mol模型通过参考原始的肽结合物及其周围蛋白质口袋环境，增强了这一过程，为实现更准确的分子设计提供了新的途径。", "innovation": "Peptide2Mol是一种新型的E(3)-等变图神经网络扩散模型，通过参考原始肽结合物及其蛋白质口袋环境，可以生成类似于原始肽结合物的小分子。该模型在大型数据集上进行了训练，利用先进的建模技术，在非自回归生成任务中达到了最先进的性能。此外，Peptide2Mol还允许通过部分扩散过程来进行分子优化和肽类似物设计，具备灵活性和实用性。", "conclusion": "Peptide2Mol是一种有效的深度生成模型，能够从蛋白质结合口袋生成和优化生物活性小分子。该研究不仅改进了分子设计方法，还为肽类似物设计开辟了新途径，并证明了E(3)-等变图神经网络扩散模型在药物设计中的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04973", "html_url": "https://arxiv.org/abs/2511.04973", "title": "简单即致胜：借助LLaMA风格自回归在简单因子化潜在空间中生成时间序列", "title_en": "Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces", "authors": "Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang", "background": "现有的基于扩散的方法虽然能够应用于多变量时间序列的数据增强、模拟和隐私保护，但这些方法生成速度快慢不一，且通常仅限于固定的时长窗口。因此，尚缺乏同时具备快速生成能力和可控制的生成长度及跨通道相关性的生成模型。\t", "innovation": "该研究提出了一种名为FAR-TS的框架，该框架结合了因子分解与离散量化潜在空间中的自回归变换器，以生成灵活且高质量的时间序列。通过将时间序列分解为随数据自适应的基础组件和离散化的时序系数，FAR-TS能够快速生成任意长度的时间序列，同时保持跨通道相关性，并提供可解释的潜在空间。与基于扩散的方法相比，FAR-TS实现了成千上万倍的加速，同时维持了时间序列的合成质量。\t", "conclusion": "FAR-TS框架的简明设计使其实现了超快速的生成能力，同时保持了时间序列的跨通道相关性和潜在空间的可解释性，从而能够生成高质量且灵活的时间序列。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05114", "html_url": "https://arxiv.org/abs/2511.05114", "title": "使用大语言模型为棋盘游戏编程及其新变种", "title_en": "Usando LLMs para Programar Jogos de Tabuleiro e Variações", "authors": "Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares", "background": "创建代表棋盘游戏的程序是一个耗时的过程。大型语言模型（LLMs）因为能够从简单的上下文信息中高效地生成代码，成为加快这一进程的有吸引力的工具。", "innovation": "本文提出了一种方法，以测试三种LLM（Claude、DeepSeek和ChatGPT）在创作棋盘游戏代码及其现有游戏的新变种方面的能力。", "conclusion": "本研究展示了利用LLMs简化开发棋盘游戏及其新变种的程序的过程。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05005", "html_url": "https://arxiv.org/abs/2511.05005", "title": "通过流匹配实现多智能体协调", "title_en": "Multi-agent Coordination via Flow Matching", "authors": "Dongsu Lee,Daehee Lee,Amy Zhang", "background": "有效协调的需求是两方面的：(i) 在离线数据中丰富且多样的联合行为的表示，(ii) 在实时环境中高效行动。此前的方法往往在这两方面之间有所取舍，即基于去噪扩散的解决方案能够捕获复杂的协调行为但计算上较慢，而基于高斯策略的解决方案速度快但处理多智能体交互时鲁棒性较差。", "innovation": "MAC-Flow通过首先学习联合行为的流基表示，然后将其提炼为保持协调性的同时允许快速执行的去中心化单步策略来解决这个问题。MAC-Flow在四个不同标准基准中实现了性能与计算成本之间的平衡，在具体的对照组中，与基于扩散的多智能体强化学习(MARL)方法相比，它快了大约14.5倍，在保持良好性能的同时，其推理速度与先前基于高斯策略的离线MARL方法相当。", "conclusion": "MAC-Flow在多个环境中展示了其优越性，既保持了高效执行，又能够捕获复杂的联合行为。它通过流匹配实现了多智能体协调在效率和性能上的平衡。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04988", "html_url": "https://arxiv.org/abs/2511.04988", "title": "使用结构性断点的碳价预测：深度学习模型的比较研究", "title_en": "Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models", "authors": "Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang", "background": "准确预测碳价格对于能源市场的明智决策、可持续能源规划以及有效脱碳策略的支持至关重要。但由于频繁的政策干预和市场冲击导致的结构性断点和高频噪声，这种预测仍然是一个挑战。现有研究，包括最新的基础方法，虽然尝试引入断点，但通常将去噪和建模视为独立过程，并缺乏对高级深度学习架构的系统评估，从而限制了其鲁棒性和泛化能力。", "innovation": "本文提出了一种综合的混合框架，集成了结构性断点检测（Bai-Perron、ICSS、PELT算法）、小波信号去噪以及三种最先进的深度学习模型（LSTM、GRU、TCN）。该框架使用2007年至2024年的欧盟配额（EUA）现货价格以及能源价格和政策指标等外生特征，构建单变量和多变量数据集进行对比评估。实验结果表明，提出的PELT-WT-TCN模型在均方根误差（RMSE）和平均绝对误差（MAE）方面比最先进的基准模型（具有波浪变换和LSTM的断点）分别降低了22.35%和18.63%，比没有分解的原始LSTM基准降低了70.55%和74.42%。这些发现突显了将结构意识和多尺度分解整合到深度学习架构中以提高碳价格预测和非平稳金融时间序列准确性和解释性的价值。", "conclusion": "研究结果显示，将结构性断点检测和多尺度分解技术融入深度学习中，可以显著提高预测准确性，并增强模型的解释能力。这一发现对于进一步提高碳价格预测的精度和可靠性具有重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04980", "html_url": "https://arxiv.org/abs/2511.04980", "title": "解锁黑箱：评估可解释AI在信用风险中的五维度框架", "title_en": "Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk", "authors": "Rongbin Ye,Jiaqi Chen", "background": "金融行业面临着建模和风险组合的显著挑战：平衡先进的机器学习模型和神经网络模型的可预测性和监管机构（如货币监理署、消费者金融保护局等）所需的解释性。本文旨在弥合这些“黑箱”模型和解释性框架（如LIME和SHAP）之间的应用差距。", "innovation": "作者详细讨论了这些框架在不同模型中的应用，并表明具有更强预测能力的模型可以在保持相同解释性水平的情况下被应用。除此之外，还提出了一个新颖的五维度框架，用于评估和比较模型的可解释性，这包括固有解释性、全局解释性、局部解释性、一致性和复杂性五个维度，超越了简单的准确度指标。", "conclusion": "研究证明，通过采用现代可解释技术，复杂的高性能机器学习模型可以应用于受监管的金融环境，并提供了一种有序的方法来评估模型性能和可解释性之间的关键权衡。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05028", "html_url": "https://arxiv.org/abs/2511.05028", "title": "OvA-LP：非 IID 数据上联邦学习的一个简单有效的框架", "title_en": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data", "authors": "Dongjin Park,Hasung Yeo,Joon-Woo Lee", "background": "在联邦细调（FFT）中，基础模型可以适应去中心化的数据，但由于局部偏移（local drift）的存在，即客户端级别更新的分歧导致全局模型出现系统性偏差和方差放大，使得模型在异构客户端分布下依然脆弱。现有的聚合和个人化方法大多是在模型调整之后才进行纠正，这种做法在极端非独立同分布（non-IID）条件下表现较差。现有的基线方法在相同条件下仅能保留10.1%的IID准确度，或34.5%的准确度。", "innovation": "引入了一种名为OvA-LP的简易框架，这是首次专门设计来在基于PEFT的FFT范式中抑制局部偏移的根本来源。该框架结合了冻结编码器上的线性探针和一个一对一所有头，并采用两阶段简单程序，保持预训练特征几何结构，解耦概率值以防止放大偏移。赵A-LP在CIFAR-100数据集上，无论是针对shard-1、shard-2还是伯努利-狄利克雷分区，均能保持95.9%的IID准确度，而最先进的FFT基线方法在相同条件下只能分别达到10.1%和34.5%。此外，预先计算编码器特征使得每轮成本几乎不再依赖于编码器的大小，从而增强了对于标签噪声（对称和非对称）的抗性。这些发现表明，OvA-LP为在异构性条件下提供了一个原理上且高效的联邦学习方法的基础。", "conclusion": "OvA-LP框架展示了在异构性条件下进行有效的FFT的原理性方法，具备抑制局部偏移和保持高准确度的能力，同时具有高效的计算特性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05124", "html_url": "https://arxiv.org/abs/2511.05124", "title": "QuAnTS：时间序列上的问题回答", "title_en": "QuAnTS: Question Answering on Time Series", "authors": "Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami", "background": "文本提供了直观的信息访问方式，尤其是可以补充时间序列数据的密集性，从而通过改善与时间序列模型的互动来提升可访问性和决策制定。然而，最近关于视觉和文本的问题回答数据集和模型研究取得了显著增长，但时间序列数据仍受到忽视。因此，为了填补这一空白，作者提出了一个新的具有挑战性的时间序列问题回答（TSQA）数据集QuAnTS。", "innovation": "提出了一个名为QuAnTS的新颖时间序列问题回答数据集，该数据集涉及人体运动的多种问题和答案，以骨架追踪轨迹的形式呈现。通过广泛的实验验证了QuAnTS数据集的规模和完整性，并为此类研究提供了更深层次的基础。此外，还提供了人类表现作为参考，以衡量此类模型的实际可用性。", "conclusion": "通过QuAnTS数据集，鼓励未来关于如何通过文本与时间序列模型互动的研究，以实现更明智的决策和更透明的系统。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05131", "html_url": "https://arxiv.org/abs/2511.05131", "title": "DL101 神经网络输出与损失函数", "title_en": "DL101 Neural Network Outputs and Loss Functions", "authors": "Fernando Berzal", "background": "从统计学角度来看，训练神经网络所使用的损失函数与输出层紧密相关。本报告分析了神经网络输出层常用激活函数（如线性、Sigmoid、ReLU和Softmax）的数学特性及其适用场景，并讨论了损失函数（如均方误差MSE、平均绝对误差MAE和各种交叉熵损失）与最大似然估计（MLE）统计原理之间的联系。选择特定的损失函数实际上意味着对模型输出假设了特定的概率分布，揭示了这些函数与网络输出层背后的一般化线性模型（GLMs）之间的联系。", "innovation": "报告详细分析了常见激活函数和损失函数的统计特性及其适用场景，建立了它们与最大似然估计和一般化线性模型之间的联系，为选择适合特定任务的神经网络结构和损失函数提供了理论依据。", "conclusion": "通过对损失函数和输出层激活函数的统计学分析，报告强调了它们对于训练深度学习模型的重要性和选择性，指出特定的损失函数实际上是对模型输出假设了特定的概率分布，这些结论对于理解和设计高效的神经网络架构具有重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04981", "html_url": "https://arxiv.org/abs/2511.04981", "title": "逐层深化训练：零/一层模型深度能力的扩展", "title_en": "Deep Progressive Training: scaling up depth capacity of zero/one-layer models", "authors": "Zhiqi Bu", "background": "模型深度是深度学习中的一把双刃剑，更深的模型可以达到更高精度，但需要更高的计算成本。为了高效地大规模训练模型，通过渐进式训练来逐步增加模型容量是一种有效策略，这可以在很大程度上减少计算成本，同时对性能影响很小。在此工作中，我们从优化理论和特征学习的角度研究大型模型的深度扩展，提供了关于新层初始化、超参数转移、学习率安排以及模型扩展时机的见解。", "innovation": "我们提出了零/一层渐进式训练策略，以实现计算量和损失之间的最佳权衡。以GPT2为例，零/一层渐进式训练可以节省约80%的计算量，或者相当于加速约5倍，同时几乎达到了与完全训练的60层、7B参数模型相同的损失。这项研究提供了提高模型性能和减少计算开销的新方法。", "conclusion": "通过零/一层渐进式训练，研究提出了一个新的方法来平衡计算与损失，为大型模型的深度扩展提供了理论和实践支持，这不仅提高了训练效率，还保留了模型的性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05171", "html_url": "https://arxiv.org/abs/2511.05171", "title": "在生物声学基础模型中，模型合并提高了零样本泛化能力", "title_en": "Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models", "authors": "Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi", "background": "生物声学领域的基础模型能够跨物种和任务泛化，被认为是生物声学研究的一个有希望的新方向。NatureLM 是此类模型中的佼佼者，其领域特定的微调虽能获得强大的生物声学基准性能，但也带来了指令遵循灵活性方面的权衡。例如，在要求同时提供通用名称和科学名称时，NatureLM 的准确性显著下降。尽管如此，NatureLM 在要求单独提供通用名称或科学名称时表现出很高的准确性。", "innovation": "研究提出了一种简单的模型合并策略，将NatureLM与其基础语言模型进行融合，这种策略仅轻微影响其专业领域知识，却恢复了指令遵循的能力。此外，所合并的新模型展示了显著优于先前方法的零样本泛化性能，在封闭集的零样本分类中，全新的模型比之前的最佳结果提高了超过200%。", "conclusion": "研究展示了经过模型合并的生物声学基础模型在未知物种的零样本分类上实现了显著的性能提升，为生物声学研究提供了一种新的方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05169", "html_url": "https://arxiv.org/abs/2511.05169", "title": "基于177Lu肽受体核素疗法的神经内分泌肿瘤患者无进展生存期多模态深度学习预测", "title_en": "Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy", "authors": "Simon Baur,Tristan Ruhwedel,Ekin Böke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich", "background": "随着肽受体核素疗法（PRRT）在治疗神经内分泌肿瘤（NETs）中的广泛应用，尽管许多患者表现出长期疾病控制，却仍有一部分患者的进展得到控制。因此，预测无进展生存期（PFS）对未来个体化治疗计划具有重要意义。本研究通过回顾单中心数据，收集了116名接受177Lu-DOTATOC治疗的NETs患者的临床特征、实验室检查值以及治疗前的生长抑素受体正电子发射断层扫描/计算机断层扫描（SR-PET/CT），旨在评估基于实验室、影像学和多模态深度学习模型的PFS预测能力。", "innovation": "研究首次通过多模态深度学习方法结合实验室检查、影像学和多模态数据，来预测接受177Lu-DOTATOC治疗的神经内分泌肿瘤患者的无进展生存期。研究发现，相较于单一模态模型，多模态融合模型（将实验室值、SR-PET和CT图像结合，外加预训练的CT分支）在预测PFS方面表现出更好的结果。这是联系FRST肿瘤学与深度学习技术的一项创新研究，有助于风险调整的随访策略的制定。", "conclusion": "多模态深度学习方法结合实验室检查、影像学和多模态数据，在预测177Lu-DOTATOC治疗神经内分泌肿瘤患者的无进展生存期方面表现出较好的效果，优于单一模态模型。外部验证表明，这些模型可能支持风险适应的随访策略，为未来个体化的科学治疗提供重要参考。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05177", "html_url": "https://arxiv.org/abs/2511.05177", "title": "对生成机器学习模型的关联性污染", "title_en": "Associative Poisoning to Generative Machine Learning", "authors": "Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang", "background": "生成模型如 Stable Diffusion 和 ChatGPT 的广泛应用使其成为恶意利用的热门目标，特别是通过数据污染。现有数据污染攻击主要导致生成数据的整体恶化，或者需要控制训练过程。这些限制在实际场景中的应用性较差。", "innovation": "引入了一种新型数据污染技术——关联性污染（Associative Poisoning），无需控制训练过程，通过对训练数据进行扰动，只操纵生成输出中特定特征对之间的统计关联，提供了形式化的数学表述，证明其理论可行性和隐蔽性。实验评估表明，这种攻击在保持目标特征边缘分布和输出高质量的同时，可以有效诱导或抑制特征关联，避免视觉检测。", "conclusion": "现有的生成系统（用于图像合成、合成数据集生成和自然语言处理）容易受到细微而隐蔽的操纵，影响其统计完整性。研究现有防御策略的限制，提出了一种新型的防御策略。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05187", "html_url": "https://arxiv.org/abs/2511.05187", "title": "基于控制变量的线性梯度预测", "title_en": "Linear Gradient Prediction with Control Variates", "authors": "Kamil Ciosek,Nicolò Felicioni,Juan Elenter Litwin", "background": "现有神经网络训练方法通常需要通过昂贵的反向传播计算完整的梯度，这导致了较高的训练成本。研究人员希望通过减少这一成本来改进训练效率和技术效果。", "innovation": "本文提出了一种新的训练神经网络的方法，使用近似的预测梯度替代完整的梯度进行训练。借助控制变量技术确保更新是真正的梯度的无偏估计。还提出了一种新的梯度预测方法，该方法受到神经核理论的启发。实验结果证明这种方法在视觉变压器分类任务上是有效的。", "conclusion": "本文提出的基于控制变量的线性梯度预测方法，可以在不需要计算完整梯度的情况下，保证训练的优化过程是有效的，并且在视觉Transformer分类任务中展示了其有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05236", "html_url": "https://arxiv.org/abs/2511.05236", "title": "因果往返：通过消除信息损失生成真实的反事实", "title_en": "The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss", "authors": "Rui Wu,Lizheng Wang,Yongjun Li", "background": "Judea Pearl的观点认为结构因果模型（SCMs）是进行反事实推理的工具，但这一过程依赖于忠实的 abduction，即精确推断潜在的外生噪声。然而，长期以来，对于复杂的非线性机制，实现这一步骤一直是显著的计算挑战。虽然扩散模型作为一种强大的通用函数逼近器提供了一个有希望的解决方案，但由于它们通常优化于感知生成而不是逻辑推理，因此存在一种根本的信息损失，称作结构重建误差（SRE）。", "innovation": "文章提出了因果信息守恒（CIC）作为忠实 abduction 的必要条件。引入了 BELM-MDCM，这是一种基于扩散的框架，通过构造可逆机制来消除 SRE。同时，文章提出了目标建模策略进行结构正则化，并引入混合训练目标增强因果归纳偏置。实验结果表明，该框架不仅实现了目前领先的技术性能，更重要的是，能够生成用于深入因果研究所需的高质量个体级反事实。", "conclusion": "本研究提供了一个基础蓝图，将现代生成模型的强大功能与古典因果理论的严谨性相结合，建立了这一新兴领域的更严格的规范标准。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04998", "html_url": "https://arxiv.org/abs/2511.04998", "title": "BiPETE：电子健康记录中基于双位置嵌入变换器编码器评估酒精和药物使用障碍风险", "title_en": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records", "authors": "Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang", "background": "基于转存器的深度学习模型在使用电子健康记录（EHRs）进行疾病风险预测方面表现出潜力，但建模时间依赖关系仍然是一个关键挑战，这主要是由于不规则的就诊间隔和缺乏统一结构。现有的方法在预训练和编码时间依赖关系方面存在局限性，因此需要一种新的方法来改进预测准确性。", "innovation": "本文提出了一种双位置嵌入变换器编码器（BiPETE），它结合了旋转位置嵌入来编码相对就诊时间，并结合了正弦位置嵌入来保留就诊顺序。这种双位置编码策略不需要大规模预训练，而在两个精神健康队列（抑郁障碍和创伤后应激障碍）的EHR数据上训练模型，以预测酒精和药物使用障碍（ASUD）的风险。与基线模型相比，BiPETE表现出色，抑郁症队列的AUPRC提高了34%，创伤后应激障碍队列的AUPRC提高了50%。进一步的消融研究表明了双位置编码策略的有效性。此外，采用集成梯度方法解释模型预测，揭示了与ASUD风险和保护相关的关键临床特征，有助于深入理解风险评估过程并为减轻潜在风险提供有价值的线索。", "conclusion": "本文提出了一种实用且可解释的框架，用于利用EHR数据进行疾病风险预测，该框架能够实现强大的性能，并通过识别关键的临床特征来提供对风险评估过程的深入了解。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05289", "html_url": "https://arxiv.org/abs/2511.05289", "title": "在临床时间序列预测中通过嵌入空间数据扩展示例预防成员推断攻击", "title_en": "Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting", "authors": "Marius Fracarolli,Michael Staniek,Stefan Riezler", "background": "时间序列预测（TSF）任务中涉及电子健康记录（EHR）时，平衡强隐私保护与高预测性能至关重要。在本研究中，我们探索了数据扩展示例如何减轻时间序列预测模型上的成员推断攻击（MIA）。我们发现，使用合成数据重新训练可以显著降低基于损失的MIA的有效性，通过减少真实正例与错误正例的比例。生成与原始训练数据高度相似的合成样本以迷惑攻击者，同时还需要引入足够的新颖性以增强模型对未见过的数据的泛化能力，是面临的挑战。", "innovation": "我们研究了多种扩展示例策略——零阶优化（ZOO）、受主成分分析限制的ZOO变体（ZOO-PCA）和MixUp，以增强模型的抗攻击能力而不牺牲准确率。", "conclusion": "实验结果显示，ZOO-PCA在不牺牲测试数据性能的情况下，能有效降低MIA攻击的真实正例率与错误正例率比例。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05266", "html_url": "https://arxiv.org/abs/2511.05266", "title": "基于分数扩散模型与机器学习增强定位的地质碳储存高级数据同化集成方法", "title_en": "Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage", "authors": "Gabriel Serrão Seabra(1, 2),Nikolaj T. Mücke(1),Vinicius Luiz Santos Silva(2, 4),Alexandre A. Emerick(2),Denis Voskov(1, 5),Femke Vossepoel(1) ((1) Faculty of Civil Engineering and Geosciences, TU Delft, Delft, Netherlands, (2) Petroleo Brasileiro S.A. (Petrobras), Rio de Janeiro, Brazil, (4) Imperial College London, London, United Kingdom, (5) Department of Energy Resources Engineering, Stanford University, CA, USA)", "background": "准确表征地下异质性对于确保地质碳储存（GCS）项目的安全和有效至关重要。我们应该探索机器学习方法如何通过整合分数扩散模型与机器学习增强定位框架，改进地质碳储存项目中的数据同化，特别是在含有通道型储层中的CO₂注入过程中。", "innovation": "本文介绍了一种新的数据同化框架，该框架结合了分数扩散模型与机器学习增强的定位，通过对大规模渗透率样本集进行数据同化，提高了Ensemble Smoother with Multiple Data Assimilation (ESMDA)中的协方差估计。使用FLuvSim生成的通道化渗透率场，并通过Delft Advanced Research Terra Simulator (DARTS)模拟CO₂注入场景，证明了此方法在保持更多的 ensemble 方差的同时，仍能保持与不应用局部化的相似数据匹配质量。该方法对于GCS项目具有实际意义，有助于提高风险评估中不确定性量化结果的可靠性，", "conclusion": "此种基于机器学习的定位方法保持了更多的 ensemble 方差，同时实现类似的数据匹配质量。此框架对于地质碳储存项目的先进数据同化具有重要实践意义。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05265", "html_url": "https://arxiv.org/abs/2511.05265", "title": "一种用于解决带有无人机的旅行商问题的端到端深度强化学习方法", "title_en": "An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones", "authors": "Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji", "background": "在最后一英里物流中出现的卡车-无人机协作系统，使得带有无人机的任务优化问题（TSP-D）成为经典的路径优化问题的一个关键扩展。同步车辆协调不仅有望提高操作效率并降低环境影响，还增加了超出了传统优化方法处理范围的NP难的组合复杂性。深度强化学习提供了一个理论上合理的框架，用于通过自监督策略学习和自适应决策制定来应对TSP-D固有的挑战。", "innovation": "该研究提出了一种分层演员-评论家深度强化学习框架来解决TSP-D问题。该架构由两个主要组成部分组成：一种受变压器启发的编码器和一种有效的最小门控单元解码器。编码器结合了一种新颖的优化k最近邻稀疏注意机制，专门用于关注相关信息的空间关系，并通过集成全局节点特征进一步增强。最小门控单元解码器处理这些编码表示，以高效地生成解序列。整个框架在异步优势演员-评论家范式下运行。实验结果表明，与高性能启发式算法和现有的强化学习方法相比，提出的模型在更短的平均计算时间下可以获得可比或更优的解决方案。", "conclusion": "与先进的强化学习算法基准相比，提出的方法显著减少了所需的总训练时间，同时实现了更好的最终性能，突显了其在培训效率方面的显著优势。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05179", "html_url": "https://arxiv.org/abs/2511.05179", "title": "万物皆非通用模型：图神经网络与基础模型揭示时空预测权衡", "title_en": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models", "authors": "Ragini Gupta,Naman Raina,Bo Chen,Li Chen,Claudiu Danilov,Josh Eckhardt,Keyshla Bernard,Klara Nahrstedt", "background": "现代物联网部署在环境监测中产生了大量的时空数据，这些数据被用于支持诸如预测等下游任务，通常是由机器学习模型驱动的。现有的过滤和战略布局技术优化了边缘收集的数据量，但它们忽略了采样频率和空间覆盖的变化对下游模型性能的影响。在许多预测模型中，额外传感器的数据能够通过提供更广泛的地理背景来降低预测噪声。然而，采样频率、空间覆盖以及不同的预测模型结构之间的关系仍没有得到充分探索。本研究旨在系统地研究不同类型的预测模型在不同空间传感器节点密度和采样间隔下使用真实无线传感网络中的温度数据的表现。研究表明，当传感器部署稀疏且采样率适中时，时空图神经网络（STGNNs）表现出色，利用图结构中嵌入的空间相关性来弥补覆盖率的不足。相比之下，时空基础模型（TSFMs）在高频时表现出色，但在邻居传感器的空间覆盖减少时性能下降。关键的是，多变量TSFM Moirai能够通过学习传感器之间的交叉关系而优于所有模型，提供了解决方案来构建高效的时空预测流水线。所有代码，包括模型配置、训练、数据集和日志，均已开源以确保可复现性：", "innovation": "本研究通过系统地评估经典模型（如VAR模型）、神经网络模型（如GRU、Transformer）、时空图神经网络（STGNNs）以及时空基础模型（如TimesFM、Chronos Moirai）在不同空间传感器节点密度和采样间隔下的表现，揭示了采样频率与空间覆盖对时空预测模型性能的复杂影响。结果显示，STGNNs在稀疏传感器部署和适度采样率时表现出色，而TSFMs在高频时表现良好，但当相邻传感器的空间覆盖减少时则性能下降。研究特别强调了Moirai模型的学习跨传感器依赖性能力，这为提高时空预测模型性能提供了新的方法论支持。", "conclusion": "本研究为构建高效的时空预测流水线提供了实用见解。无论是构建时空数据驱动的系统还是选择合适的预测模型结构，本研究提供的结果都有助于优化时空预测模型的性能。所有相关代码和资源的开源将推动研究者进一步探索不同情境下的时空预测关系，并促进该领域的进一步发展。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05313", "html_url": "https://arxiv.org/abs/2511.05313", "title": "全注意力和压缩即所需，用于可控制高效语言模型", "title_en": "Attention and Compression is all you need for Controllably Efficient Language Models", "authors": "Jatin Prakash,Aahlad Puli,Rajesh Ranganath", "background": "在变压器中，注意力机制的成本导致了对更高效方法的需求，如稀疏注意力、滑动窗口注意力、卷积和线性注意力。尽管这些方法减少了计算和内存成本，但在许多情况下牺牲了质量，具体表现为上下文检索性能的下降。这些问题使得在预测需要更多内存和较低延迟的应用场景中，效率和质量之间存在固有的权衡。现有的方法往往依赖于一些人工制定的选择或复杂的组件规则，这使得设计流程复杂化，尤其是在大规模部署时。因此，需要一种新的架构来同时解决这些挑战。", "innovation": "我们提出了Compress & Attend Transformer (CAT)，这是一种概念上简单的架构，仅使用两个组件：密集注意力和压缩。CAT通过关注以前压缩的片段来解码片段的标记，这种压缩减少了计算和内存成本所需的序列长度。通过选择特定的片段大小，可以在质量和效率之间进行权衡。此外，CAT能够在训练时使用多种片段大小，从而可以在测试时直接控制质量-计算权衡，无需重新训练，并且在一种自适应架构中实现。在全面的评估中，单个自适应的CAT模型在各种语言建模任务中的上下文检索和长情境理解方面表现优于现有的高效基线，这些基线包括混合架构。CAT模型在不同计算和内存预算下均超过了现有方法，并且在语言建模方面比密集变压器快1.4-3倍，内存使用量低2-9倍。", "conclusion": "Compress & Attend Transformer (CAT) 架构能够在一个自适应模型中同时优化计算和内存效率，通过简单的机制实现高效而又可控的语言模型，优于现有的方法并且在不同应用场景中提供了优化的性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05355", "html_url": "https://arxiv.org/abs/2511.05355", "title": "SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning", "title_en": "SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning", "authors": "Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche", "background": "流匹配（FM）在数据驱动规划中显示出有希望的结果，但由于缺乏确保状态和动作约束的正式保证，这些约束对各种系统的轨迹安全性和可接纳性至关重要，现有的FM规划器并未确保动力学一致性，这可能导致轨迹不可执行。", "innovation": "提出了一种新颖的框架SAD-Flower，用于生成安全、可接纳且动力学一致的轨迹。通过增加虚拟控制输入扩展流，利用非线性控制理论的技术，为状态约束、动作约束和动力学一致性提供正式保证。无需重新训练，即可在测试时满足未见过的约束。", "conclusion": "通过一系列广泛的实验，表明SAD-Flower在确保约束满足方面优于多种基于生成模型的基线方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05357", "html_url": "https://arxiv.org/abs/2511.05357", "title": "基于扩散模型的散射结构化介质电磁逆向设计", "title_en": "Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media", "authors": "Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg", "background": "在电磁逆向设计领域，传统的方法通常涉及昂贵的迭代优化过程，这不仅耗时还可能导致结果的非唯一性问题。本文使用一种条件扩散模型直接从目标散射截面图生成结构化的介质几何形状，绕过了传统的迭代优化过程，从而简化了设计流程。", "innovation": "本文提出了一种1D U-Net架构，结合特征通道线性调制，能够从目标散射截面图直接生成结构化介电结构，并有效处理逆向问题的非唯一性。通过大量模拟的元表面训练，模型在未知目标上的中位平均误差达到19%以下，并实现了比进化优化CMA-ES更快的设计速度。", "conclusion": "这项研究证明了将扩散模型应用于电磁逆向设计的可行性，可能加速复杂元表面架构的快速探索和下一代光子及无线通信系统的开发进程。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05221", "html_url": "https://arxiv.org/abs/2511.05221", "title": "ActiTect: 通过标准化客观观察法筛查快速眼动睡眠行为障碍的通用机器学习管道", "title_en": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy", "authors": "David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,Noémie Moreau,Michael Sommerauer,Katarzyna Bozek", "background": "孤立的快速眼动睡眠行为障碍（iRBD）是α-突触核蛋白病（如帕金森病、路易体痴呆和多系统萎缩）的前期标志物，通常先于临床上这些疾病的出现。尽管戴在手腕上的活动测量仪（actimeter）在大规模筛查中检测RBD具有巨大潜力，但由于缺乏可靠和高效的分析流水线，它们无法正常工作。这种研究提出ActiTect，这是一种全自动、开源的机器学习工具，用于从活动度记录中识别RBD。", "innovation": "该研究开发了ActiTect，一种全自动、开源的机器学习工具，能够从活动记录中识别RBD。该工具包括稳健的预处理步骤和自动睡眠-清醒检测，以规范多设备数据，并提取生理可解释的运动特征。研究结果表明，该模型具有强大的辨别力（嵌套交叉验证的AUROC = 0.95），并且能够在由独立外部队列组成的多种数据库上进行有效泛化。", "conclusion": "通过开放源代码和易于使用，该工具促进了该技术的广泛应用，并促进了独立验证和协作改进，从而推动该领域朝着使用穿戴设备进行RBD检测的统一和通用模型迈进。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05420", "html_url": "https://arxiv.org/abs/2511.05420", "title": "ProDER：在演变智能电网中的持续学习故障预测方法", "title_en": "ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids", "authors": "Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo", "background": "随着智能电网需要应对不断增长的能源需求和复杂的运营挑战，精确预测故障的能力变得越来越关键。然而，现有的基于AI的故障预测模型难以在必须适应新故障类型和运营区域的演变环境中保证可靠性。", "innovation": "本文提出了一种在智能电网背景下持续学习（CL）框架，以使模型能够与环境一同演变。设计了四个基于类增量和域增量学习的现实评估场景，以模拟演变中的电网条件。引入了基于原型的黑暗体验回放（ProDER），这是一种统一的回放方法，整合了基于原型的特征正则化、logit蒸馏和原型引导的回放记忆。ProDER在测试的CL技术中表现最佳，对于故障类型预测的准确率下降只有0.045，对于故障区域预测的准确率下降只有0.015。", "conclusion": "结果表明，CL在智能电网中具有实现大规模、实际的故障预测的可行性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05444", "html_url": "https://arxiv.org/abs/2511.05444", "title": "稳健对抗多任务自适应控制", "title_en": "Adversarially Robust Multitask Adaptive Control", "authors": "Kasra Fallah,Leonardo F. Toso,James Anderson", "background": "本文研究了在模型不确定性和对抗性篡改下，多个系统协同学习控制策略的对抗稳健多任务线性二次控制问题。", "innovation": "提出了一种聚类多任务方法，结合聚类和系统识别，并采用抗篡改聚合，以减轻模型更新中受到的篡改。分析了聚类准确度、簇内异质性及对抗行为如何影响线性二次调节器任务下等价性控制的预期遗憾。", "conclusion": "建立了非渐近界，表明诚实系统数量每增加一倍，遗憾减少，且该减少在每个簇中受控范围内对抗系统占比的限制下仍然保留。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05396", "html_url": "https://arxiv.org/abs/2511.05396", "title": "在线交互条件下分布鲁棒的离动态强化学习的学习复杂性", "title_en": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "authors": "Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu", "background": "离动态强化学习（off-dynamics RL）指在训练和部署过程中动态变化不一致的情况。这种情况下，可以将环境建模为一个鲁棒的马尔可夫决策过程（RMDP），其中过渡动态具有不确定性。现有文献大多假设可以访问生成模型或预先收集的、覆盖度较好的状态数据集，绕过了探索的挑战。然而，本文研究在训练环境只能在线交互的更现实和更具挑战性的设置下，探索的固有难度。在此背景下，引入了最大访问比这一新颖的度量标准，用于衡量训练动态和部署动态之间的不匹配程度。", "innovation": "提出了一种基于 $f$-散度的过渡不确定性下的在线 RMDPs (在线鲁棒马尔可夫决策过程) 的第一个计算效率高的算法，该算法实现了亚线性后悔率。同时证明了匹配的后悔界，表明该算法在最大访问比和交互期数方面的依赖关系达到最优。", "conclusion": "证明了理论结果，通过全面的数值实验验证了在在线交互条件下分布鲁棒的离动态强化学习中的学习复杂性理论。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05442", "html_url": "https://arxiv.org/abs/2511.05442", "title": "APP: 加速路径修补，结合任务特定剪枝", "title_en": "APP: Accelerated Path Patching with Task-Specific Pruning", "authors": "Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff", "background": "电路发现是许多机制可解释性管道中的关键步骤。当前的方法，如路径修补，计算成本高且对较小模型的深入电路分析能力有限。", "innovation": "我们提出了加速路径修补（APP），这是一种混合方法，利用我们新颖的对比注意力头剪枝方法极大地减少了电路发现方法的搜索空间。对比-FLAP剪枝算法使用因果中介分析的技术，为任务特定的注意力头分配更高的剪枝分数，从而在与传统剪枝技术相比时产生性能更高的稀疏模型。通过APP，首先应用对比-FLAP减少电路发现算法所需的搜索空间的56%，然后应用传统的路径修补在剩余的注意力头中，从而以59.63%-93.27%的速度增加超过密实模型应用路径修补的过程。尽管APP提供了显著的计算节省，但由APP获得的电路具有明显的重叠，并且在先前建立的路径修补电路中的性能相似。", "conclusion": "通过应用对比-FLAP，APP成功减少了搜索空间，并通过传统路径修补进一步提高了电路发现的速度，虽然获得的电路具有重叠，但在性能上与之前建立的路径修补电路相似。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05462", "html_url": "https://arxiv.org/abs/2511.05462", "title": "SiamMM: 深度无监督学习的混合模型视角", "title_en": "SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning", "authors": "Xiaodong Wang,Jing Huang,Kevin J Liang", "background": "最近的研究表明，基于聚类的方法在自监督和无监督学习中具有有效性。然而，聚类的应用往往是启发式的，最优化的方法仍然不明确。在本文中，作者通过建立这些无监督聚类方法与统计学中的经典混合模型之间的联系，展示了显著的改进，并引入了一种名为SiamMM的新模型。这种方法在各种自监督学习基准测试中达到了最新的性能标准。通过学习到的聚类，可以看到其与未见过的真实标签高度相似，揭示了潜在的误标记实例。", "innovation": "作者提出了一种名为SiamMM的新模型，通过将无监督聚类方法与统计学中的经典混合模型进行连接，展示了显著的改进。模型在自监督学习基准测试中达到了最新的性能标准，并揭示了潜在的误标记实例。该方法提供了一个新的框架来优化现有的聚类方法。", "conclusion": "通过引入SiamMM模型，作者展示了如何通过混合模型视角来显著提升无监督学习中的聚类方法。该方法在多个自监督学习基准测试中表现出色，并且揭示了训练数据中存在的潜在误标注问题。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05483", "html_url": "https://arxiv.org/abs/2511.05483", "title": "DGTN：带有扩散注意门控机制的图增强变换器用于酶DDG预测", "title_en": "DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction", "authors": "Abigail Lin", "background": "预测氨基酸突变对酶热力学稳定性（DDG）的影响是蛋白质工程和药物设计的基础。虽然最近的人工智能方法具有潜力，但它们通常将序列和结构信息独立处理，无法捕捉局部结构几何和全局序列模式之间的复杂联系。", "innovation": "介绍了DGTN（扩散图变换网络），这是一种新型架构，通过扩散机制协同学习图神经网络（GNN）权重和变换器注意。DGTN的关键创新在于双向扩散过程，其中GNN提取的结构嵌入通过可学习的扩散核引导变换器注意，变换器表示通过注意调制的图更新优化GNN消息传递。数学分析表明，这种协同学习方案比独立处理提供了更好的近似度界限。此外，实验结果显示DGTN在ProTherm和SKEMPI基准测试中达到了最先进的性能（皮尔逊相关系数为0.87，均方根误差为1.21 kcal/mol），比最佳基线提高了6.2%。消融研究证实扩散机制对相关性贡献了4.8分点。", "conclusion": "通过学习式扩散机制建立了将异构蛋白质表示整合的原理框架，并为酶DDG预测提供了一种新的方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05330", "html_url": "https://arxiv.org/abs/2511.05330", "title": "使用哈密顿高斯过程从输入-输出数据中学习动力学", "title_en": "Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes", "authors": "Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel", "background": "在基于学习的方法中嵌入非限制性先验知识，如能量守恒定律，旨在从有限的数据中建立物理上一致的模型，这对于模型导向的控制等应用非常重要。最近的工作将哈密顿动力学引入高斯过程(GP)回归，以获得符合潜在物理原则的不确定性量化模型，但这些工作依赖于速度或动量数据，而在实践中这些数据很少可用。因此，本文考虑非保守哈密顿GP的动力学习问题，并解决从输入-输出数据中学习的更加现实的问题设定。提出的计算方法利用了低秩GP近似，利用其属性进行高效预测和训练，并通过非线性仿真案例研究进行了评估，与依赖动量测量的先进方法进行了比较。", "innovation": "在没有速度或动量数据的情况下，提出了一种从输入-输出数据中学习动力学的方法，该方法使用了非保守哈密顿高斯过程，并提出了一种完全贝叶斯方案，用于估计未知隐藏状态、GP超参数以及结构超参数（如阻尼系数）的概率密度。同时，为了降低计算复杂性，采用了低秩GP近似并充分利用其属性进行高效预测和训练。这种处理方式有助于提高计算效率，并扩大了高斯过程方法的应用范围。", "conclusion": "提出的低秩非保守哈密顿GP方法在非线性仿真案例研究中进行了评估，并与依赖于动量测量的先进方法进行了比较。结果显示，该提案能够处理较少的数据并且能更好地满足物理一致性，为从输入-输出数据中学习动力学提供了一种高效的方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05482", "html_url": "https://arxiv.org/abs/2511.05482", "title": "SoilX：通过对比跨组分学习实现无校准的综合土壤感应", "title_en": "SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning", "authors": "Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du", "background": "精准农业需要连续且准确地监测土壤水分（M）和关键的三大宏营养素——氮（N）、磷（P）和钾（K），以优化产量并节约资源。无线土壤传感已被用于测量这四个组成部分，但当前的解决方案需要在处理土壤质地变化（如铝硅酸盐Al和有机碳C）时进行重新校准（即重新训练数据处理模型），这限制了其实际应用。本研究为了解决这一问题，提出了一种无需校准的土壤传感系统SoilX，它可以同时测量六大关键组分：{M, N, P, K, C, Al}。", "innovation": "SoilX通过对比跨组分学习（3CL）技术，包含两个定制化术语：正交正则化器和分离损失，以有效分离跨组分干扰，无需依赖于土壤质地和碳含量的重新校准。此外，SoilX还设计了一个新型四面体天线阵列，结合天线切换机制，能够在不同设备位置下稳定测量土壤介电常数。实验结果显示，SoilX在基准模型上减少了23.8%到31.5%的估计误差，并且可以很好地泛化到未见过的田地。", "conclusion": "基于SoilX系统，研究人员显著提高了土壤关键组分测量的准确性，并扩大了其应用范围。与现有技术相比，无需校准的优势对于精准农业的应用具有重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05325", "html_url": "https://arxiv.org/abs/2511.05325", "title": "将对手变为盟友：利用反向字型攻击进行多模态电子商务商品检索", "title_en": "Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval", "authors": "Janet Jenq,Hongda Shen", "background": "多模态电子商务平台的购物搜索系统依赖于视觉和文本信号的有效结合，以提高搜索相关性和用户体验。然而，诸如CLIP等视觉-语言模型容易受到字型攻击的影响，即嵌入图像中的误导性或无关文本会扭曲模型的预测。", "innovation": "本文提出了一种新颖的方法，通过将相关文本内容（如标题、描述）直接渲染在产品图像上，实现视觉-文本压缩，从而增强图像-文本对齐，提升多模态产品检索性能。该方法在三种垂直特定的电子商务数据集（运动鞋、手袋和交易卡）上，使用六种当前最先进的视觉基础模型进行了评估。", "conclusion": "实验结果表明，无论类别和模型家族如何，本方法在单模态和多模态检索精度上都表现出一致的改进效果。研究表明，在视觉上渲染产品元数据是电子商务中的零样本多模态检索的一种简单而有效的方法增强手段。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05460", "html_url": "https://arxiv.org/abs/2511.05460", "title": "Synapse: 自适应仲裁时间序列基础模型的互补专业知识", "title_en": "Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models", "authors": "Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister", "background": "预训练时间序列基础模型（TSFMs）能够有效预测具有复杂特征的时间序列，涵盖不同的季节性、趋势和长程依赖性。尽管它们的主要目标是通用时间序列预测，但其效果在不同预测任务、领域和时间范围上却表现出很高的差异性。通过利用TSFMs在不同预测设置下的专业表现差异来在多种模型之间进行仲裁策略已显示出潜力，但这一领域尚未得到充分研究。本研究深入探讨了TSFMs在各种预测场景下的表现差异，并提出了一种名为Synapse的新仲裁框架，旨在通过动态利用一个TSFMs池，根据它们在特定上下文中的相对性能分配和调整预测权重，从而构建一个健壮的预测分布。实验结果证实，Synapse 在时间序列预测中优于其他流行的组合技术及单一TSFMs，展示了其在时间序列预测中的有效性。", "innovation": "Synapse 提出了一种新的仲裁框架，通过动态利用多个TSFMs池，基于它们在上下文中的相对性能分配和调整权重，从而构建一个健壮的预测分布。该框架通过适应性采样组成模型的输出分位数来构建预测分布。实验结果表明，Synapse 优于其他流行的组合技术及单一TSFMs，展示其在时间序列预测中的有效性。", "conclusion": "本研究表明，通过有效利用不同TSFMs在不同预测任务中的专业表现差异，可以显著改进时间序列预测的准确性。提出的Synapse框架在各种时间序列预测任务中展示了显著优势，验证了其在时间序列预测中的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05456", "html_url": "https://arxiv.org/abs/2511.05456", "title": "基于图的模拟器中材料泛化的参数高效调节", "title_en": "Parameter-Efficient Conditioning for Material Generalization in Graph-Based Simulators", "authors": "Naveen Raj Manoharan,Hassan Iqbal,Krishna Kumar", "background": "图网络模拟器（GNS）在学习基于粒子的物理（如流体、可变形固体和颗粒流等）方面展示了强大的潜力，并能够外推到未见过的几何形状。然而，现有的模型通常仅针对单一材料类型进行训练，对于不同材料的行为无法泛化，限制了其在现实工程场景中的应用。", "innovation": "作者提出了一种参数高效调节机制，使得GNS模型能够适应不同的材料参数。通过实验发现，参数敏感性集中于早期消息传递层，原因在于颗粒流等材料的本构模型具有局部性质。因此，仅对预训练模型的前几层进行微调就能达到与整个网络微调相当的测试性能。基于此发现，作者提出了一种专门针对早期层的参数高效特征线性调制（FiLM）调节机制，能够在少量新材料的短模拟轨迹训练下（仅12个），实现对未见过、插值或一定的外推预测的准确长期滚动，相比基线的多任务学习方法数据减少5倍。此外，作者验证了该模型在逆问题中的适用性，能够从轨迹数据中成功识别未知的黏聚参数。", "conclusion": "本文提出的方法能够使GNS在逆设计和闭环控制任务中得以应用，使得材料属性作为设计变量进行处理，从而提高了GNS在现实工程中的泛化能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.02401", "html_url": "https://arxiv.org/abs/2511.02401", "title": "通过随机矩阵理论研究表示模型的泛化：对循环网络的应用", "title_en": "Generalization in Representation Models via Random Matrix Theory: Application to Recurrent Networks", "authors": "Yessin Moakher(X),Malik Tiomoko,Cosme Louart(CUHK-Shenzhen),Zhenyu Liao(HUST)", "background": "本研究探讨了使用固定特征表示（冻结中间层）后接可训练读出层的模型的泛化误差。这种设置涵盖了从深层随机特征模型到具有循环动力学的回声状态网络（ESNs）的多种架构。", "innovation": "研究应用了随机矩阵理论来推导高维情况下泛化误差的封闭形式表达式，并将其应用于循环表示，得出简洁的公式来表征其性能。研究发现线性ESNs等同于具有指数时间衰减权值的输入协方差的岭回归，揭示了其对近期输入的诱导偏差。", "conclusion": "分析方法提供了一个泛化的方法论框架，用于分析过参数化模型，并提供了对深度学习网络行为的见解。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05471", "html_url": "https://arxiv.org/abs/2511.05471", "title": "使用物理条件神经网络的卫星数据降水现在预报", "title_en": "Precipitation nowcasting of satellite data using physically conditioned neural networks", "authors": "Antônio Catão,Melvin Poveda,Leonardo Voltarelli,Paulo Orenstein", "background": "准确的短期降水预报主要依赖于密集的天气雷达网络，但在气候极端事件频发的地区，其操作价值有限。目前的大多数深度学习模型进行降水现在预报时，无法直接利用卫星数据，并且在长时间预测时效果不佳。", "innovation": "TUPANN（可转移且物理对齐的现在预报网络）是一种仅依赖卫星数据的模型，它基于GOES-16 RRQPE训练。TUPANN将预报分解为物理上可解释的组件：变分编码器-解码器从最近的图像中推断运动和强度场，受光学流监督；带有提前时间条件的最大ViT（Vision Transformer）演化潜在状态；可微散流操作重建future帧。该模型在GOES-16和IMERG数据上，以及在里约热内卢、马瑙斯、迈阿密和拉巴斯四个气候区（10-180分钟预报窗口）上进行了评估。该模型在多数情况下显示出最佳或次佳技能，在高阈值条件下尤其如此。", "conclusion": "使用GOES-16低延迟的多城市训练进一步提高了模型性能，而跨城市实验显示，罕见的高强度降雨情况下会出现轻微降低甚至偶尔提升的效果。TUPANN产出了平滑且可解释的运动场，且运行时接近实时，这表明物理上对齐的学习可以提供技能强、可转移且具有全球性的现在预报。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04702", "html_url": "https://arxiv.org/abs/2511.04702", "title": "通信受限的隐私保护分布式在线个性化均值估计", "title_en": "Communication-Constrained Private Decentralized Online Personalized Mean Estimation", "authors": "Yauhen Yakimenka,Hsuan-Yin Lin,Eirik Rosnes,Jörg Kliewer", "background": "该研究考虑了在多个按照任意未知个体特定分布连续接收数据的智能体环境下，数据通信受限且隐私受到保护的个性化均值估计问题。旨在通过差分隐私框架中的共识算法保护每个智能体的数据隐私，分析了在给定任意有界分布的情况下，提出的共识算法的理论收敛性。研究结果表明，在满足特定隐私水平限制和智能体连接性条件下，相较于不共享数据的完全本地方法，协作方法可以提供更快的收敛速度。", "innovation": "提出了在通信受限环境下，基于差分隐私框架的共识算法进行了个性化均值估计；理论上证明了合作相比于完全本地的方法可以提供更快的收敛速度；基于差分隐私的方法保护了个体数据的隐私。", "conclusion": "研究结果证明，在给定的通信和隐私限制下，通过私密合作方式可以实现更快的收敛速度，显示出在线设置中的私密合作的好处。理论分析得到了多种数值结果的支持，证明了该共识算法的优越性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04688", "html_url": "https://arxiv.org/abs/2511.04688", "title": "评估大语言模型在处理有序程序步骤方面的推理能力", "title_en": "Evaluating LLMs' Reasoning Over Ordered Procedural Steps", "authors": "Adrita Anika,Md Messal Monem Miah", "background": "对于大型语言模型（LLMs），推理有序过程的能力是关键。有序过程中的步骤顺序直接影响结果，而正确排序步骤对于任务成功至关重要。本文通过使用食物食谱的精心策划数据集来研究从混合顺序步骤中重构全局有序序列的任务。", "innovation": "本文评估了多个LLMs在零样本和少量样本设置下的表现，并引入了一个全面的评价框架，该框架将排名和序列对齐的现有指标，如肯德尔Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED），进行了适应。实验发现，序列越长，模型的表现越差；输入中的步骤置换越大，模型表现下降越明显。这些发现揭示了当前LLMs在程序推理方面的局限，尤其是在面对更长和更混乱的输入时。", "conclusion": "本文分析表明，模型性能随序列长度增加而下降，反映了更长步骤程序的复杂性增加。较大的步骤置换对应更严重的混合，导致进一步恶化。这些结果强调了当前LLMs在程序推理方面的局限性，尤其是在面对更长和更混乱的输入时。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05480", "html_url": "https://arxiv.org/abs/2511.05480", "title": "关于流匹配KL散度", "title_en": "On Flow Matching KL Divergence", "authors": "Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu", "background": "本文研究了流匹配方法在数据分布近似中的KL散度上界问题。特别是在给定$L_2$流匹配损失条件下，推导了一种确定性、非渐进上界。", "innovation": "提出了流匹配分布近似中KL散度的一个确定性、非渐进上界。具体来说，如果$L_2$流匹配损失受限于$\boldsymbol{\tokeno{\boldsymbol{ε}}^2 > 0}$，那么真实数据分布与估算分布之间的KL散度将受到$A_1 \boldsymbol{\tokeno{\boldsymbol{ε}} + A_2 \boldsymbol{\tokeno{\boldsymbol{ε}}^2}$的限制。这里的常数$A_1$和$A_2$仅依赖于数据和速度场的正则性。这表明流匹配可达到接近最小二乘最优的功效，特别是在总体变异距离（TV距离）下与扩散模型的统计效率相当。", "conclusion": "研究结果表明流匹配方法在估计平滑分布时，达到了几乎最小极大最优效率。数值研究结果支持了理论分析。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04707", "html_url": "https://arxiv.org/abs/2511.04707", "title": "在大堆中的破解", "title_en": "Jailbreaking in the Haystack", "authors": "Rishi Rajesh Shah,Chen Henry Wu,Shashwat Saxena,Ziqian Zhong,Alexander Robey,Aditi Raghunathan", "background": "长上下文语言模型（LMs）的进步使得输入可以达到数百万个标记，扩展了它们在复杂任务，如计算机使用代理等方面的能力。然而，这些扩展上下文的安全影响仍然不清楚。为了弥合这一差距，人们引入了一种称为NINJA（针刺在干草堆中的攻击）的方法，该方法通过在有害用户目标后添加无害的模型生成内容来破解对齐的LMs。研究表明，有害目标的位置对安全性至关重要。实验表明，Ninja在标准安全性基准HarmBench上显著提高了最先进的开放和专有模型（包括LLaMA，Qwen，Mistral和Gemini）的攻击成功率。", "innovation": "Ninja方法具有低资源消耗、可迁移性和低可检测性等特点。此外，研究表明在固定计算预算下，增加上下文长度可以比增加最佳N次测试的数量更有效地提高破解成功率。这表明即使是有害的长上下文在精心布置目标的情况下也会给现代LMs带来根本性漏洞，而这些有害目标主要通过将无害的内容添加到有害目标后进行实现。", "conclusion": "Ninja方法通过低资源、可迁移性和隐蔽性破解了对齐的LMs，表明长上下文中的良性内容在巧妙布局后引入了现代LMs的安全漏洞。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04715", "html_url": "https://arxiv.org/abs/2511.04715", "title": "第一并不是真的比最后更好：语言模型数据影响评估中的层选择与聚合策略", "title_en": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "authors": "Dmytro Vitel,Anshuman Chhabra", "background": "理解训练样本如何影响大规模语言模型（LLM）的决策对于有效解读模型决策和审计大规模数据集至关重要。当前，影响估计方法（也称为影响函数）通过利用模型中的信息流动（包括一阶和高阶梯度项）计算训练样本的影响。但因为现代模型包含数十亿个参数，这些计算通常仅限于模型的一些层以确保计算可行性。Yeh等人先前的研究指出，在计算语言数据影响方面，第一层（嵌入层）是最有用的，这基于影响分数相互抵消（即抵消效应）。", "innovation": "本研究提供了理论和实验证据，证明抵消效应不可靠，提出了注意力层作为影响估计的更好估计器。研究还探讨了层间影响分数的聚合策略，表明替代标准平均（如排名和投票方法）可以显著提高性能。此外，本研究提出了一种无需重新训练模型来评估影响分数有效性的新方法，并提出了一种称为噪声检测率（NDR）的新度量标准，显示出了比抵消效应更强的预测能力。结果显示，对于LLM影响估计，第一层并不总是优于最后一层，这对于该领域先前的知识构成了挑战。", "conclusion": "通过在不同类型的LLM中进行广泛实验，本研究确认了对于LLM影响估计第一层不一定优于最后一层，这与该领域的先前知识形成对比。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04727", "html_url": "https://arxiv.org/abs/2511.04727", "title": "IndicVisionBench: 在VLMs中评估文化与多语言理解的标准", "title_en": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "authors": "Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal", "background": "视觉语言模型(VLMs)在多模态任务中展现了强大的泛化能力，但大多数评估基准仍以西方为中心，这使得它们在文化多样性和多语言环境中表现如何成为一个开放的问题。为了填补这一空白，作者引入了IndicVisionBench，这是首个以印度次大陆为中心的大规模基准测试，覆盖了英语和10种印度语言，包括光学字符识别(Optical Character Recognition, OCR)、多模态机器翻译(Multimodal Machine Translation, MMT)和视觉问答(Visual Question Answering, VQA)，涉及6种问题类型。最终，基准测试包含约5000张图像和超过37000个问答对，涵盖13个文化根植主题。此外，作者还释放了一个跨10种印度语言的配对平行标注语料库，创建了一个分析VLMs的文化和语言偏见的独特资源。", "innovation": "IndicVisionBench是一个首个以印度次大陆为中心的多模态基准测试，覆盖了多种多语言和问题类型，并发布了跨10种印度语言的配对平行标注语料库，揭示了当前VLMs在文化多样性和多语言环境中的局限性，为更具包容性的多模态研究奠定了基础的评估框架。", "conclusion": "通过强调文化多样性和多语言性，IndicVisionBench建立了一个可重复的评估框架，为即将到来更多包容性的多模态研究铺平了道路。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04803", "html_url": "https://arxiv.org/abs/2511.04803", "title": "生物医学图像分割中的数据效率和转移鲁棒性：带有Cellpose的冗余和遗忘研究", "title_en": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "authors": "Shuo Zhao,Jianxu Chen", "background": "通用型生物医学图像分割模型，如Cellpose，在不同成像模态和细胞类型中的应用越来越广泛。然而，仍然存在两个关键挑战：(1) 训练数据的冗余程度以及(2) 跨域转移对模型保持能力的影响。", "innovation": "1. 提出了一个简单的数据集量化（DQ）策略，以构建紧凑但多样化的训练子集，用于评估数据冗余度。2. 进行了跨域微调实验，观察到从通用领域到专业领域转换时性能下降，并且展示了基于选择性DQ的回放策略如何有效恢复源领域性能。3. 发现训练领域排序可以提高多阶段转移中的泛化能力和减少遗忘。", "conclusion": "研究强调了生物医学图像分割中以数据为中心的设计的重要性，并建议高效的训练不仅需要紧凑的子集，还需要警惕数据丢失的学习策略和有序的领域排列。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04792", "html_url": "https://arxiv.org/abs/2511.04792", "title": "使用评分模型进行盲强透镜反演：评分模型同时推断源和透镜质量", "title_en": "Blind Strong Gravitational Lensing Inversion: Joint Inference of Source and Lens Mass with Score-Based Models", "authors": "Gabriel Missael Barco,Ronan Legin,Connor Stone,Yashar Hezaveh,Laurence Perreault-Levasseur", "background": "得分模型可以作为科学逆问题的高度表达和数据驱动的先验。在强引力透镜中，得分模型能够从其扭曲的、多重成像观测中推断出背景星系。先前的研究假设透镜质量分布是已知的（因此前向算子是已知的）。", "innovation": "这项研究通过使用基于GibbsDDRM的采样器并操作在连续时间中，以放松前向算子已知的假设，同时推断出源和透镜质量参数。实验结果表明，这种联合推断方法能够产生与观测噪声一致的残差，并且透镜参数的边缘后验分布能恢复真实值且没有系统偏差。这是首次成功利用得分模型进行联合源和透镜质量推断。", "conclusion": "该研究表明，使用评分模型进行联合源和透镜质量推断是可行的，能够获得准确的结果，而这在之前的研究中是不可能实现的。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04798", "html_url": "https://arxiv.org/abs/2511.04798", "title": "MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars", "title_en": "MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars", "authors": "Matheus Farias,Wanghley Martins,H. T. Kung", "background": "在使用忆阻器Bit-sliced存内计算（CIM）交叉阵列实现深度神经网络（DNN）时，寄生电阻（PR）的非理想性显著限制了交叉阵列的效率。PR会导致矩阵映射至小型交叉阵列瓷砖时降低CIM的加速效果，且每个交叉阵列需执行一个瓷砖，在每一层之前需要数字同步转换。因此设计者或并行部署多个小型阵列，或顺序重用少数几个阵列——这都会增加模拟到数字转换次数、延迟、I/O压力和芯片面积。", "innovation": "MDM通过优化活性忆阻器的放置来减小PR的影响。MDM利用位级别结构化稀疏性，从密度较高的低位侧馈入激活值，并根据曼哈顿距离重新排列行，使活跃单元位移至受PR影响较小的区域，从而降低非理想因子（NF）。针对ImageNet-1k上的DNN模型，MDM将NF降低了最多46%，并在模拟失真下平均提高了3.6%的准确率。总体来看，MDM为CIM DNN加速器提供了轻量级的空间导向方法。", "conclusion": "MDM减轻了PR效应，提供了一种轻量级、空间导向的方法，用于扩展CIM DNN加速器，即使在存在模拟失真的情况下也能保持高准确率。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04812", "html_url": "https://arxiv.org/abs/2511.04812", "title": "统一多模态扩散驱动方法用于强健的操控任务", "title_en": "Unified Multimodal Diffusion Forcing for Forceful Manipulation", "authors": "Zixuan Huang,Huaidian Hou,Dmitry Berenson", "background": "传统的模仿学习方法通常从观察（例如RGB图像）到行动之间建立直接映射，但这些方法往往忽视了不同模态之间（如感觉输入、行动和奖励）的丰富交互，这对于机器人行为建模和任务结果的理解非常重要。本文探讨了在接触丰富的、执行性强的操控任务中，给定专家路径数据集的情况下，如何扩展行动生成的方法。", "innovation": "本文提出了一种统一的多模态扩散驱动方法（Multimodal Diffusion Forcing，MDF），作为一种用于从多模态机器人轨迹中学习的统一框架。MDF 不是建立固定分布，而是通过随机部分遮罩并训练扩散模型以重建轨迹来进行训练。这种方法鼓励模型学习时间上的和跨模态的依赖关系，例如预测行动对力信号的影响或从部分观察中推断状态。", "conclusion": "我们在模拟和真实环境中对MDF进行了接触密集型、执行性强的操控任务评估。结果表明，MDF 不仅提供了多种功能，还在噪声观察下具有强大的性能和鲁棒性。更多可视化可以访问我们的网站。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04811", "html_url": "https://arxiv.org/abs/2511.04811", "title": "使用最少人力干预的生物医学图像实例分割主动学习管道", "title_en": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "authors": "Shuo Zhao,Yu Zhou,Jianxu Chen", "background": "生物医学图像分割对于精确结构标注和后续分析至关重要。传统方法在处理噪声数据时经常遇到困难，而深度学习模型如U-Net在分割性能上设定了新标准。nnU-Net进一步自动化模型配置，使其能够适应不同的数据集而无需大量调优。然而，它需要大量的标注数据来进行交叉验证，当仅有原始图像而没有标签时，这会成为一个挑战。大型基础模型提供了零样本的广泛适应性，但在处理具有独特特征的具体数据集时可能会表现不佳，限制了它们直接用于分析。这一工作通过提出一种基于数据的AI工作流来解决这个问题，这种工作流利用主动学习和伪标签结合传统神经网络和大型基础模型的优点，同时将人类干预降至最低。", "innovation": "提出了一种基于数据的AI工作流，利用主动学习和伪标签，结合传统神经网络和大型基础模型，实现最少的人力干预，从而生成伪标签，用于配置nnU-Net，并选择具有代表性的小规模核心集进行手动标注，以有效微调nnU-Net模型。这种方法显著减少了手动标注的需求，保持了竞争力的性能，为生物医学研究人员提供了一种应用尖端AI技术的可访问解决方案。", "conclusion": "该方法显著减少了手动标注的需求，同时保持了竞争力的性能，提供了一种解决数据稀缺问题的新方法，使得生物医学研究人员能够更容易地应用最新的AI技术进行图像分割任务。相关的代码可以在给定的URL中找到。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04873", "html_url": "https://arxiv.org/abs/2511.04873", "title": "使用拓扑数据分析选择原型", "title_en": "Prototype Selection Using Topological Data Analysis", "authors": "Jordan Eckert,Elvan Ceyhan,Henry Schenck", "background": "近年来，使用拓扑原则表示数据和捕捉结构与关系的统计学习文献显著增加。本文介绍了一种基于拓扑数据分析(TDA)的原型选择框架（TPS），用于从大数据集中选择代表性子集（原型）的方法。实验表明，TPS在不同数据固有特征的仿真实验中表现良好，并且在真实数据集环境下与目前常用的原型选择方法相比，TPS显著地保留或提升了分类性能，同时大大减少了数据量。", "innovation": "本文提出了TPS框架，这是一种基于TDA的新型原型选择方法，能够在保留或提升分类性能的同时大大减少数据量。该方法在算法和几何方面推进了原型学习的发展，提供了并行化、可解释和高效的分类工具。", "conclusion": "TPS方法在仿真实验和真实数据集环境中均表现出色，显著提高了分类性能并有力地减少了数据量，该研究不仅为算法和技术的发展做出了贡献，也为实际应用提供了有效的工具。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04875", "html_url": "https://arxiv.org/abs/2511.04875", "title": "LLMs行为自意识的最小和机制性条件", "title_en": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs", "authors": "Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask", "background": "近期研究表明，大语言模型（LLMs）可以表现出行为自意识：即能够准确描述或预测自己已学到的行为，无需明确的监督。这种能力引发了安全方面的担忧，因为模型可能利用它更好地在评估期间隐藏它们的实际能力。", "innovation": "本研究通过受控的指令调优实验，使用低秩适配器（LoRA），发现（1）仅使用一个秩1的LoRA适配器即可可靠地激发行为自意识；（2）学习到的行为自意识可以由激活空间中的单一引导向量捕捉，恢复了大部分调优行为的影响；（3）行为自意识是非普遍的且局限于特定领域，不同任务具有独立的表示。这些发现表明，行为自意识作为一种领域特定、线性的特征，可以被容易地诱导和调节。", "conclusion": "总体而言，研究表明，行为自意识在特定领域内以线性特征的形式出现，这一特征易于产生和调节。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04970", "html_url": "https://arxiv.org/abs/2511.04970", "title": "学习傅里叶形状以探查深度神经网络的几何世界", "title_en": "Learning Fourier shapes to probe the geometric world of deep neural networks", "authors": "Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li", "background": "现有的深度神经网络（DNNs）研究主要集中在纹理识别上，而对几何形状的理解尚未深入探究。", "innovation": "提出了一种端到端可微框架，通过傅里叶级数参数化任意形状，基于缠绕数的方法将其转换为DNNs所需的像素网格，并通过信号能量约束提高优化效率并确保合理的物理形状。该研究展示了优化形状作为强有力的语义载体的功能，及其作为模型可解释性工具的能力，并提出了一种新的、可泛化的对抗性范式。", "conclusion": "该工作提供了一个探索DNNs的几何世界的多功能框架，并为挑战和理解机器感知开辟了新的前沿。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04869", "html_url": "https://arxiv.org/abs/2511.04869", "title": "基于标记训练，概念校准：LLMs中语义校准的涌现", "title_en": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs", "authors": "Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson", "background": "大型语言模型（LLMs）通常缺乏对其输出有意义的信心评估。虽然基础LLMs在下一个标记预测方面表现出量化的校准，但它们是否能够在回答开放域问题时超越标记层面评估响应的意义置信度还不清楚。这项研究表明，通过某种基于采样的语义校准概念，基础LLMs在开放域问答任务中的校准度出乎意料地优秀，尽管它们并没有明确训练来进行置信度评估。理论贡献揭示了语义校准作为下一个标记预测副产品的机制，利用了校准与局部损失最优之间的最新关联。", "innovation": "提出的理论机制解释了为什么语义校准作为下一个标记预测的副产品自然涌现。引入了一个更一般的“B-校准”定义，并推断出可以进行测试的预测：基础LLMs在产生响应之前可以容易地预测其对于语义答案类别的分布时，将被语义校准。通过实验验证了这一预测的三个结论：（1）基础LLMs在问答任务中语义校准；（2）基于强化学习指令调优系统地破坏了这一校准；（3）步骤思考推理破坏了校准。这项工作提供了首个关于何时何故LLMs中语义校准自然涌现的原理性解释。", "conclusion": "这项研究揭示了LLMs中语义校准的机制，证明了基础LLMs在某些任务中具有语义校准的能力，并提供了关于强化学习指令调优和步骤推理对校准影响的结果。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04983", "html_url": "https://arxiv.org/abs/2511.04983", "title": "使用可穿戴传感器预测认知受损老年人的认知评估分数", "title_en": "Predicting Cognitive Assessment Scores in Older Adults with Cognitive Impairment Using Wearable Sensors", "authors": "Assma Habadi,Milos Zefran,Lijuan Yin,Woojin Song,Maria Caceres,Elise Hu,Naoko Muramatsu", "background": "现有的认知筛查工具具有破坏性、耗时并且只捕捉活动的短暂快照，穿戴设备提供的生理数据为连续监测生理信号提供了有吸引力的替代方案，本文旨在研究是否可以使用生理数据准确预测常立的认知测试分数。", "innovation": "本文通过使用Empatica EmbracePlus可穿戴设备记录生理信号，并通过波let基和分割方法提取统计特征，然后应用监督学习，展示了如何使用AI工具如监督学习和特征工程非侵入性地跟踪老年人的具体认知功能，即使在数据样本较小的情况下也能得到有效结果，支持远程评估和临床干预。", "conclusion": "研究表明，结合穿戴传感器和AI工具可以有效跟踪老年人认知功能，这为持续监测和非侵入性评估打开了新的可能。尽管研究规模较小，但这种方法显示了其在有限数据样本下的应用潜力，有助于远程评估和临床干预的实施。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04770", "html_url": "https://arxiv.org/abs/2511.04770", "title": "基于机器学习的kSZ图分析以预测CMB光学深度τ", "title_en": "Machine Learning-Driven Analysis of kSZ Maps to Predict CMB Optical Depth $τ$", "authors": "Farshid Farhadi Khouzani,Abinash Kumar Shaw,Paul La Plante,Bryar Mustafa Shareef,Laxmi Gewali", "background": "kSZ效应测量提供了研究宇宙再电离时期的强大工具。CMB光子与移动电子散射产生的kSZ信号包含了有关再电离时期的时间、持续时间和空间结构的关键信息。精确测量CMB光学深度τ（一个表征宇宙中电子密度集成的参数）对于约束早期结构形成模型至关重要。然而，由于来自天体物理前景的强烈污染使得从CMB观测中提取kSZ信号很困难。研究团队提出了一种基于机器学习的方法，用于从模拟的kSZ图中提取τ。使用高分辨率半拟数字模拟训练先进的机器学习模型，如swin变压器，并采用拉普拉斯近似法定量预测不确定性。", "innovation": "该研究采用了一种新的方法，即利用机器学习从模拟的kSZ图中准确提取CMB光学深度τ，尤其采用了先进的swin变压器模型，并且使用拉普拉斯近似法估计预测的不确定性，提供了一种有效的高精度误差估计框架。此外，该方法探讨了两种应用模式：事后拉普拉斯近似和在线拉普拉斯近似，后者可以同时优化模型权重和超参数以最大化边缘似然。这种方法能更稳健地约束τ及其关联不确定性，对即将到来的CMB调查如Simons天文台和CMB-S4具有重要意义。", "conclusion": "该研究展示了拉普拉斯近似法的高效性和稳健性，为预测CMB光学深度τ及其不确定性提供了一个有力的工具。这将有助于增强对即将到来的CMB调查数据的分析，促进我们对宇宙早期结构形成和再电离时期的理解。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05085", "html_url": "https://arxiv.org/abs/2511.05085", "title": "逐层迭代蒸馏方法用于大型语言模型的高效压缩", "title_en": "Iterative Layer-wise Distillation for Efficient Compression of Large Language Models", "authors": "Grigory Kovalev,Mikhail Tikhomirov", "background": "本文研究了大型语言模型（LLMs）的蒸馏方法，旨在开发小而高性能的模型。文章回顾了现有的一些方法，并讨论了它们各自的优缺点。实验基于Qwen2.5-3B模型展示了不同的方法对模型层数和性能的影响。", "innovation": "本文提出了一种改进的蒸馏方法，基于ShortGPT的方法，通过迭代评估每层的重要性来逐步减少模型的层数。在每一步中，通过移除单个层并测量性能下降来评估重要性，并使用代表性数据集和联合损失函数（KL散度和均方误差）进行进一步训练。这使得模型在保持较高性能的同时减少了参数量。", "conclusion": "实验结果表明，通过逐层逐层迭代蒸馏和微调的方法，可以将模型的参数量减少26%到36%，同时仅损失9.7%到18%的质量。研究发现，中间的Transformer层对于推理的重要性较低，表明该方法具有创建高效模型的潜力。这种方法的有效性使得其适合在资源受限的环境中部署。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04753", "html_url": "https://arxiv.org/abs/2511.04753", "title": "CPO: 条件偏好优化以实现可控的图像生成", "title_en": "CPO: Condition Preference Optimization for Controllable Image Generation", "authors": "Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen", "background": "为了增强文本到图像生成中的可控制性，ControlNet 引入了基于图像的控制信号，而 ControlNet++ 则通过一个单一步骤近似方法，只在低噪声时间步进行优化，从而提高了生成图像与输入控制信号之间的像素级循环一致性。然而，这种方法忽略了一些高噪声时间步的贡献，并引入了额外的近似误差，且避免了反向传播通过采样过程的高昂成本。虽然 Direct Preference Optimization (DPO) 提供了一种优化所有时间步可控制性的替代方法，但是由于生成模型的不确定性，确保获胜和失败图像对仅仅在可控制性上有所不同而保持其他因素（如图像质量）不变是困难的。因此，作者提出了通过条件偏好优化（CPO）来训练模型，这种方法在理论上表现出更低的对比损失方差，并且在实验中取得了更优的结果，同时需要更少的计算和存储空间来构建数据集。", "innovation": "提出了 Condition Preference Optimization (CPO) 方法，通过优化控制条件而非生成图像来训练模型，这种方法有效地消除了影响因素，并提供了一个低方差的训练目标。与 Direct Preference Optimization (DPO) 相比，CPO理论上具有更低的对比损失方差，并在实验中取得了更优的结果。此外，CPO 方法所需的计算和存储资源较少，且在多种类型的控制任务中显著提高了图像的可控性，特别是在分割、人体姿态、边缘和深度图方面取得了显著改进。", "conclusion": "CPO 方法在多种可控图像生成任务中显著提高了可控制性，相对于目前最先进的 ControlNet++ 方法，在分割任务中降低了超过 10% 的错误率，在人体姿态识别中提升了 70%-80%，并且在边缘和深度图生成中一直保持了 2%-5% 的一致改进。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05050", "html_url": "https://arxiv.org/abs/2511.05050", "title": "使用大规模在线核学习估计双向因果效应", "title_en": "Estimating Bidirectional Causal Effects with Large Scale Online Kernel Learning", "authors": "Masahiro Tanaka", "background": "传统的因果推断方法往往侧重于单向因果效应，忽视了现实世界中常见的双向关系。本研究旨在通过构建一种基于异方差性的识别方法，提出了一种可扩展的在线核学习框架，以估计由相互依赖和异方差性特征表征的系统的双向因果效应。这种方法通过将广义最大似然估计与大规模在线核学习相结合，能够灵活地建模非线性条件均值和方差，同时使用自适应的在线梯度下降算法确保在流式和高维数据中的计算效率。", "innovation": "该研究提出了一种结合了经济学识别与现代机器学习技术的新方法，该方法通过同时方程模型中的准最大似然估计与大规模在线核学习相结合，有效捕捉了复杂的双向因果效应。此外，使用随机傅里叶特征近似来灵活建模非线性条件均值和方差，并采用自适应在线梯度下降算法来保证计算效率，适用于流式和高维数据。", "conclusion": "通过广泛的模拟试验，发现所提出的方法在各种数据生成过程中优于单方程和多项式逼近基线，具有较低的偏见和均方根误差，显示出接近线性的计算缩放性。这些结果证实了所提出的方法能够有效捕捉复杂的双向因果效应，并且提供了一种实际、可扩展且理论基于的解决方案，适用于自然/社会科学研究、政策制定、商业和工业应用中的大规模因果推断。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05106", "html_url": "https://arxiv.org/abs/2511.05106", "title": "来自视网膜OCT图像的早期阿尔茨海默病检测：一项英国生物银行研究", "title_en": "Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study", "authors": "Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren", "background": "视网膜层厚度的变化与阿尔茨海默病等神经退行性疾病有关。以往的研究主要关注分割后的层厚度测量，本研究则探索直接对OCT B-扫描图像进行分类以早期检测阿尔茨海默病。在文献中这是首次应用深度学习对未经分割的OCT B-扫描图像进行阿尔茨海默病预测。早期检测比诊断更具挑战性，原因是成像比临床诊断提前数年时间，使得检测变得更加困难。", "innovation": "本研究首次使用深度学习对未经分割的OCT B-扫描图像进行阿尔茨海默病预测，采用了冻结的预训练模型如基于ImageNet的网络和OCT特异的RETFound变压器，并使用了按年龄、性别和成像时间匹配的英国生物银行队列的受试者级交叉验证数据集进行细调和评估。通过应用标准和OCT特异的数据增强技术以及加权损失函数，减少小的数据集的过拟合问题。结果显示，ResNet-34得到最稳定的结果，实现了4年随访队列的AUC为0.62。", "conclusion": "尽管结果未达到临床应用的阈值，但研究证实了AD组和对照组在黄斑中心亚区存在局部结构差异。这些发现为基于OCT的AD预测提供了一个基线，突出检测阿尔茨海默病前数年存在的细微视网膜生物标志物的挑战，强调了需要更大规模数据集和多模态方法的必要性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04711", "html_url": "https://arxiv.org/abs/2511.04711", "title": "SWAP：通过序列水印技术朝向软提示的版权审计", "title_en": "SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking", "authors": "Wenyuan Yang,Yichen Sun,Changzheng Chen,Zhixuan Chu,Jiaheng Zhang,Yiming Li,Dacheng Tao", "background": "大规模的视觉-语言模型，尤其是CLIP，在多样的下游任务中展现了卓越的表现。软提示作为一种精心设计的模块，能够高效地将视觉-语言模型适应到特定的任务上，同时也需要有效的版权保护。现有的方法在审计可能存在侵权的第三方模型是否包含受保护的软提示时效果不佳，这主要是因为软提示的学习特点和其他因素。现有审计方法的非侵入性会在样本数据分布相似的情况下导致误报，而侵入性方法由于CLIP设计的后门方法无法嵌入功能性触发器以及传统DNN后门技术应用于提示学习时的有害性和模糊性而失败。这些审计方法的失效源于水印在同一决策空间与主要任务目标相悖的问题。基于研究发现，Watermarking直接在主要任务的决策空间内运作却具有不同的目标，提出了一种名为SWAP的方法，即序列水印技术，用这种方法将水印嵌入到一个不同且更复杂的空间中，使用一种特定顺序的越分布类别的水印来嵌入CLIP的零样本预测能力。这种方法确保了原始预测标签不变，降低了与主要任务的对立。为了验证SWAP的有效性，进而设计了一种基于假设检验的验证协议，并提供了成功的条件的理论分析。", "innovation": "SWAP（序列水印）技术是一种针对软提示的有效版权审计方法。其创新点在于将水印嵌入到一个不同且更复杂的决策空间中，从而减少与主要任务目标的冲突，同时设计了一种基于假设检验的验证协议，提供了成功条件的理论分析，能够在保持预测标签不变的同时提高审计的准确性和鲁棒性。这种方法解决了传统方法无法有效审计软提示的问题，对于软提示的版权保护具有重要意义。", "conclusion": "大量的实验表明，SWAP方法有效、无害并且对潜在的适应性攻击具有鲁棒性。这种方法不仅能够提高软提示版权审计的准确性和鲁棒性，同时在技术和实际应用中均具有重要意义。未来的研究可以进一步探讨如何优化和扩展这一方法，以适应更多的视觉-语言模型及其应用场景。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05158", "html_url": "https://arxiv.org/abs/2511.05158", "title": "微移动中的跟随模式通过端到端模仿学习实现", "title_en": "Follow-Me in Micro-Mobility with End-to-End Imitation Learning", "authors": "Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta", "background": "自主微小移动平台面临大型室内空间或拥挤的都市地区的挑战，这些地方环境可能变化快速。尽管社交导航算法已经取得显著进步，但在提高用户体验、尤其是商业应用中关键的舒适度方面，之前的研究相对较少关注。这些方面已有的评估标准（如时间或行进距离）在英文学术文章中提到。", "innovation": "本文展示了通过模仿学习（而不是以前的手动调校控制方法）如何实现更平滑且总体更好的控制器。具体地，DAAV的自动轮椅在随行模式下实现了业界领先水平的舒适度，此模式下它跟随人类操作员以帮助行动不便的人士。", "conclusion": "文章分析了端到端控制不同的神经网络架构，并展示了其在实际生产级别部署中的可用性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05018", "html_url": "https://arxiv.org/abs/2511.05018", "title": "多元行为套件：在多轮对话中对定制行为规范的抗压测试", "title_en": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies", "authors": "Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien", "background": "传统的大型语言模型（LLMs）通常旨在符合广泛公众接受的安全与使用原则。然而，在现实世界的应用中，LLMs往往运行在由独特的公司政策、监管要求、应用场景、品牌准则和伦理承诺形成的组织生态系统中。这种现实凸显了对LLMs进行严格的、综合的多元一致性的评估需求，这种一致性强调对不同用户价值观和需求的适应性。这项工作中，我们介绍了称为‘多元行为套件’（PBSUITE）的动态评估套件，它被设计用来系统地评估LLMs在多轮互动对话中遵循多元一致性规范的能力。PBSUITE包括（1）由30个行业中的300个现实的LLM行为政策组成的多样化数据集；（2）一种用于在对抗条件下测试模型遵循自定义行为规范的动态评估框架。", "innovation": "PBSUITE是一个动态评估套件，用于系统地评估LLMs在多轮互动对话中遵循多元一致性规范的能力。它包括一个包含300个现实的LLM行为政策的多样化数据集（涵盖30个行业），以及一个用于在对抗条件下测试模型遵循自定义行为规范的动态评估框架。研究发现，现有的模型对齐和安全调节方法无法在现实生活中的LLMs交互中一致地执行多元行为政策。我们的工作提供了一个数据集和分析框架，以支持未来关于健壮和情境感知的多元对齐技术的研究。", "conclusion": "使用PBSUITE的研究表明，主流的开源和闭源LLMs在单轮设置中严格遵守行为政策（失败率低于4%），但在多轮对抗交互中合规性显著减弱（高达84%的失败率）。这些发现揭示现有的模型对齐和安全性调节方法在执行现实中的LLMs交互中的多元行为规范方面存在不足。我们的工作为未来关于健康新技术和情境感知的多元对齐技术的研究做出了贡献。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05168", "html_url": "https://arxiv.org/abs/2511.05168", "title": "砖块中的另一种BRIXEL：向更廉价的密集特征迈进", "title_en": "Another BRIXEL in the Wall: Towards Cheaper Dense Features", "authors": "Alexander Lappe,Martin A. Giese", "background": "基于视觉的模型在全局和局部密集的下游任务上表现出色。最新的DINOv3模型系列通过在大图上进行预训练，能生成非常精细的密集特征图，达到最先进的性能。然而，这些特征图的生成需要输入图像以非常高分辨率呈现，并且由于变换器架构的平方复杂性，计算量也很大。", "innovation": "我们提出了一种简单的知识蒸馏方法BRIXEL，让学生学习在更高分辨率下复现其自己的特征图。尽管方法简单，但BRIXEL在保持固定分辨率的情况下，在下游任务上的表现优于基线DINOv3模型，同时还能够在计算成本上大幅度降低，生成特征图与教师模型非常相似。", "conclusion": "BRIXEL方法在固定分辨率下提高了下游任务的表现，并大幅降低了计算成本，能够生成与教师模型特征图非常相似的结果。代码和模型权重可在指定网站获取。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05231", "html_url": "https://arxiv.org/abs/2511.05231", "title": "具有差分能力的供应链冲击模型", "title_en": "A differentiable model of supply-chain shocks", "authors": "Saad Hamid,José Moran,Luca Mungo,Arnau Quera-Bofarull,Sebastian Towers", "background": "在经济学中，建模供应链中的冲击传播是一个重要的挑战。近年来，事件如新冠疫情和俄罗斯入侵乌克兰进一步突显了这一问题的重要性。代理基础模型（ABMs）被认为是解决此类问题的一种有前景的方法，但其校准过程十分困难。", "innovation": "本文通过在GPU上运行ABMs并结合自动微分技术，实现了校准速度提高超过3个数量级的效果，相比非可微基线。这一方法为ABMs在建模整个全球供应链网络方面打开了新的可能。", "conclusion": "该研究证明了通过ABMs模拟全球供应链冲击的可行性，并展示了其在提升模型校准效率方面的显著优势，从而推动了对复杂供应网络的进一步深入分析。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05159", "html_url": "https://arxiv.org/abs/2511.05159", "title": "在核空间中的一种新的凸聚类框架：有限样本边界的相合性及性能洞察", "title_en": "A New Framework for Convex Clustering in Kernel Spaces: Finite Sample Bounds, Consistency and Performance Insights", "authors": "Shubhayan Pan,Saptarshi Chakraborty,Debolina Paul,Kushal Bose,Swagatam Das", "background": "凸聚类是一种受认可的聚类方法，类似于Lloyd的k-均值算法中的基于质心的方法，但不需要预先定义的聚类数。这种方法从每个数据点作为其质心开始，然后迭代地将它们合并。尽管这种技术有许多优点，但它在处理线性不可分或非凸结构的数据时可能会失败。为了克服这些限制，本文提出了一种凸聚类的核化扩展方法。这种方法使用特征映射将数据点投影到再生核哈达玛空间（RKHS）中，在这个变换的空间中实现凸聚类。这种方法核化既可以更好地处理复杂的数据分布，又能产生有限维向量空间中的嵌入。", "innovation": "该研究提出了一种新的核化凸聚类框架，通过将数据点投影到再生核哈达玛空间来解决线性和非凸结构下的数据聚类问题。该方法不仅提供了算法收敛性的理论依据，还证明了有限样本估计的边界，并通过合成和真实世界数据集的广泛实验展示了其优越性，超过了最先进的聚类技术。", "conclusion": "这项工作为非线性和非凸数据场景下的聚类问题提供了一个有效的解决方案，标志着领域的重要进展。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05234", "html_url": "https://arxiv.org/abs/2511.05234", "title": "基于轨迹级元学习的上下文感知学习网格模拟", "title_en": "Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning", "authors": "Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann", "background": "物体变形模拟在多个科学领域如机器人学、制造业和结构力学中是一个关键挑战。现有的基于图网络的学习模拟器（GNSs）提供了替代传统网格基物理模拟器的可能，它们的速度和内在可微性使其特别适合需要快速准确模拟的应用，如机器人操作或制造优化。然而，现有的学习模拟器通常依赖单步观察，限制了它们利用时间上下文的能力。此外，它们依赖于自回归展开，这会导致长时间轨迹的误差累积。", "innovation": "本文提出了一个基于轨迹级元学习的上下文感知学习网格模拟方案。该方法通过使用条件神经过程，在有限的初始数据下实现快速适应新的模拟场景，并捕捉它们的潜在模拟特性。利用运动基元，该方法可以从单一模型调用中直接预测快速、稳定且准确的模拟结果。与最先进的GNSs相比，该方法提供了更高的仿真准确性，同时显著减少了运行时间成本，适用于多个任务。", "conclusion": "Movement-primitive Meta-MeshGraphNet (M3GN) 通过捕捉网格基模拟的潜在特性，并利用运动基元直接预测快速、稳定、准确的模拟结果，实现了更高的仿真精度，而运行成本仅为最先进的GNSs的极小部分。这种方法克服了现有的学习模拟器在利用时间上下文和自回归展开方面的限制。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05275", "html_url": "https://arxiv.org/abs/2511.05275", "title": "TwinVLA：利用孪生单臂视觉语言行动模型的高效双臂操作", "title_en": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models", "authors": "Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee", "background": "vision-language-action (VLAs) 模型在大量机器人数据集的训练下在 manipulation 任务上表现出色，包括双臂任务。然而，由于大多数公开数据集侧重于单臂示范，将 VLAs 适应双臂任务通常需要大量额外的双臂数据和微调。为解决此问题，提出了一种模块化框架 TwinVLA，该框架将两个预训练的单臂 VLAs 重组为协调工作的双臂 VLA。", "innovation": "TwinVLA 使用两个预训练的单臂模型进行重建，而非采用混合训练单臂和双臂数据的大型单一模型，这种模块化组合方法提高了数据效率和性能。在现实世界和模拟环境中的一系列双臂任务上，TwinVLA 比等规模的单一模型 RDT-1B 表现更佳，无需任何双臂预训练。此外，它缩小了与依赖大量专用双臂数据的顶级模型之间的性能差距。", "conclusion": "研究表明我们的模块化组合方式是高效且可扩展的路径，利用公共单臂数据以实现高性能双臂操作。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05295", "html_url": "https://arxiv.org/abs/2511.05295", "title": "从部分枚举的语言生成和识别：紧密度界与拓扑表征", "title_en": "Language Generation and Identification From Partial Enumeration: Tight Density Bounds and Topological Characterizations", "authors": "Jon Kleinberg,Fan Wei", "background": "大型语言模型（LLMs）的成功激发了对语言生成和学习形式理论的研究。在此背景下，研究了关于语言生成的新框架，即‘限于生成’的概念，其中对手（adversary）逐渐列举来自未知语言集合K的字符串，算法需要生成K中的未见字符串。先前的研究表明，总是可以进行生成，并展示了正确性和覆盖之间的一个权衡（validity--breadth trade-off）。论文进一步探索了在部分枚举情况下的语言生成和识别问题，证明了一些重要理论结果，并引入了新的拓扑表征来描述语言识别的有效性。\n", "innovation": "该论文的主要创新在于证明了在部分枚举情况下的语言生成紧密度界为1/2，并提出了一个新的拓扑表征来描述Angluin字符化条件的等价性。本文的研究结果扩展了在部分信息设置下的生成能力，使得生成器能够在所透露子集的密度范围内找回份额至少是其一半的密度，进一步回答了该领域的一个重要开放问题，并为理解语言识别的极限行为提供了一个新的视角。\n", "conclusion": "文章最终证明了在部分枚举下的语言生成和识别的紧密度界，并通过引入新的拓扑框架对Angluin的字符化条件进行了重新描述，为语言生成和学习领域的发展提供了重要理论支持和新方法。\n"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05156", "html_url": "https://arxiv.org/abs/2511.05156", "title": "SmartSecChain-SDN：一种集成区块链的智能安全高效软件定义网络框架", "title_en": "SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for Secure and Efficient Software-Defined Networks", "authors": "Azhar Hussain Mozumder,M. John Basha,Chayapathi A. R", "background": "随着越来越多的现有网络被转换为软件定义网络（SDN），它们需要更加安全，并且需要更智能的流量控制方法。因此，需要一种能够结合机器学习入侵检测、基于区块链的日志存储和基于应用程序的优先级设定的平台来保障网络安全和提升流量控制效果。该平台利用先进机器学习算法（如随机森林、XGBoost、CatBoost和CNN-BiLSTM）进行实时精确的网络入侵检测，并结合Hyperledger Fabric技术提供安全、可扩展且隐私保护的日志存储，确保入侵检测系统记录不会被篡改。同时，该系统还包括基于应用程序的QoS规则和流量整形，优先保障关键服务（如VoIP、视频会议和企业应用）并降低非关键流量（如下载和更新）的优先级。", "innovation": "SmartSecChain-SDN 提出了一种创新且可扩展的方法，能够提高网络安全、合规性和下一代可编程网络的管理。该框架结合了机器学习入侵检测、基于区块链的日志存储和基于应用程序的优先方案，集成Hyperledger Fabric提供安全、可扩展且隐私保护的日志存储，并通过QoS规则和流量整形优化网络性能，从而有效应对资源限制情况下的网络攻击和带宽分配。", "conclusion": "SmartSecChain-SDN 概括解决了SDN系统的保护、安全性和增强问题，为下一代可编程网络提供了全面的安全保障和效能提升。该提议的研究提供了一种创新的方法，可以提升网络安全、合规性和网络管理。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05297", "html_url": "https://arxiv.org/abs/2511.05297", "title": "基于图检索增强生成构建专用软件助理聊天机器人", "title_en": "Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation", "authors": "Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon", "background": "数字采用平台（DAPs）已成为帮助企业员工导航复杂的企业软件（如CRM、ERP或HRMS系统）的重要工具。LemonLearning等公司已经证明，数字指导可以降低培训成本并加速员工入职。然而，构建和维护这些互动指南仍然需要大量的手工努力。利用大型语言模型（LLMs）作为虚拟助手是一个有吸引力的选择，但在没有对目标软件的结构化理解的情况下，LLMs往往会产生幻觉并生成不可靠的答案。此外，大多数生产级别的LLMs是黑盒API，由于缺乏对模型权重的访问，微调变得不切实际。因此，本工作中引入了一个基于图的检索增强生成框架，该框架可以自动将企业级Web应用程序转换为状态-动作知识图，使LLMs能够生成基于上下文的有针对性的帮助。该框架与AI企业和LemonLearning合作共同开发。我们详细描述了从提取和构建软件界面到基于图的检索过程设计以及将该方法集成到生产DAP工作流中的工程管线。最后，我们讨论了来自工业使用案例的可扩展性、鲁棒性及部署方面的经验教训。", "innovation": "提出了一个基于图的检索增强生成框架，该框架可以自动将企业级Web应用程序转换为状态-动作知识图，使LLMs能够生成基于上下文的有针对性的帮助。该框架解决了LLMs在没有对目标软件的结构化理解的情况下生成不可靠答案的问题，同时解决了微调生产级别的LLMs不切实际的问题。", "conclusion": "基于图的检索增强生成框架成功地将企业级Web应用程序转换为状态-动作知识图，使LLMs能够生成基于上下文的有针对性的帮助。该框架在工业使用案例中展示了其可扩展性、鲁棒性及部署方面的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05308", "html_url": "https://arxiv.org/abs/2511.05308", "title": "重新审视3D点云生成的度量标准与扩散架构", "title_en": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation", "authors": "Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière", "background": "随着3D点云成为现代技术的核心基础，对复杂生成模型和可靠的评估指标的需求呈指数级增长。许多常用的评估生成点云的指标，尤其是基于Chamfer距离的指标，缺乏对缺陷的鲁棒性和捕捉几何保真度及局部形状一致性的能力。因此，有必要引入样本对齐以提高距离计算的准确性，并使用密度感知Chamfer距离（DCD）来增强评估指标的一致性和鲁棒性。此外，现有的主要通过比较3D欧几里得坐标来进行直接比较的度量标准存在局限性。", "innovation": "本文提出了一种新的度量标准，即表面法线一致度（SNC），通过比较估计点的法线来近似表面的相似性，从而填补了传统方法的不足。结合序列化片段注意机制等最近在点云分析中的进展（如 transformers），本文提出了一个新的生成高保真3D结构的架构——扩散点变换器（Diffusion Point Transformer），并在Shapenet数据集上进行了广泛的实验证明和比较，结果显示该模型在生成点云的质量方面明显优于之前的解决方案。", "conclusion": "通过结合SNC和DCD以及序列化片段注意机制，本文提出的方法能够更全面地评估生成点云的质量，并且在Shapenet数据集上的实验结果表明，该方法能生成更高质量的点云，达到新的最先进的水平。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05408", "html_url": "https://arxiv.org/abs/2511.05408", "title": "使用权重量化调整语言模型", "title_en": "Steering Language Models with Weight Arithmetic", "authors": "Constanza Fierro,Fabien Roger", "background": "为大型语言模型（LLMs）提供高质量的反馈是一个既困难又昂贵的过程，仅提供窄范围的反馈数据会导致意外的一般化。为了更有效地利用窄范围训练数据，本研究提出了一种名为对比权重调整的方法，该方法在模型训练后使用权重量化来编辑模型参数。", "innovation": "提出了一种简单的后训练方法——对比权重调整，通过从两个小的微调网络差值中识别行为方向，并添加或删除这种方向来调整模型权重，以改善模型行为的控制。该方法被应用于抑制奉承行为并诱导脱节，并发现权重调整在某些情况下比激活调整更有效，同时保持了更强大的分布外行为控制。", "conclusion": "研究表明，在特定任务微调的情境下，权重调整可以部分减轻不希望的行为漂移。此外，研究还发现了新兴脱节行为的初步证据，可以通过测量微调更新与“邪恶”权重方向之间的相似性来检测，这可能有助于在训练过程中监测和检测罕见未在训练或评估中表现出来的脱节行为。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05452", "html_url": "https://arxiv.org/abs/2511.05452", "title": "自适应加权与采样在物理知情神经网络中的应用", "title_en": "Self-adaptive weighting and sampling for physics-informed neural networks", "authors": "Wenqian Chen,Amanda Howard,Panos Stinis", "background": "物理知情深度学习已经成为解决偏微分方程(PDEs)的一种有前途的框架。然而，训练这些模型在复杂问题上仍然充满挑战，通常会导致精度和效率的限制。特别是在训练点稀缺的情况下，仅采用自适应采样或自适应加权均不足以一致地获得准确的预测。这种方法的有效性很大程度上取决于问题本身的特性。", "innovation": "本文提出了一种结合自适应采样和自适应加权的混合方法，以提高物理知情神经网络(PINNs)的性能。自适应采样部分在解表现出迅速变化的区域内识别训练点，而自适应加权部分平衡不同训练点的收敛速率。这种方法结合了两种策略的优势，更有效地提高了预测精度和训练效率，为解决PDEs提供了更加稳健的方法。", "conclusion": "通过结合自适应采样和自适应加权策略，本文提出的框架能够一致地提升预测准确性和训练效率，提供了一种更稳健的方法来利用PINNs解决PDEs问题。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05311", "html_url": "https://arxiv.org/abs/2511.05311", "title": "使用LLM代理清理维护日志以改进预测性维护", "title_en": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "authors": "Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank", "background": "长期以来，经济限制、可用数据集的有限性及专业人才短缺被视为汽车领域预测性维护（PdM）广泛应用的关键障碍。最近，大规模语言模型的进步提供了一个机遇，可以克服这些障碍，加速PdM从研究向工业应用的转变。维护日志是训练高性能机器学习模型的关键数据源，但常常受到拼写错误、缺少字段、近乎重复的记录及错误日期等噪音的影响。研究表明，大规模语言模型在处理通用清洁任务方面表现出色，并为未来工业应用提供了有希望的基础。然而，特定领域的错误仍然具有挑战性，这些结果强调了通过专门训练和增强代理能力进一步改进的潜力", "innovation": "大规模语言模型（LLMs）被用于支持预测性维护中的清洗管道，特别是针对维护日志中的错误和噪音进行清理。研究评估了LLM代理在六种不同类型的噪声清理任务中的表现，展示了它们在处理通用清洗任务方面的有效性，并提供了未来工业应用的可能基础。尽管特定领域的错误仍具挑战性，但前景依然广阔", "conclusion": "大规模语言模型在处理维护日志噪声方面展现出良好效果，为预测性维护提供了新的支持方式。然而，特定领域的错误需要进一步的专门训练和代理能力提升来克服。研究结果强调了大规模语言模型在预测性维护中的潜在应用价值"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05449", "html_url": "https://arxiv.org/abs/2511.05449", "title": "3D点云变换器架构到底需要多少令牌？", "title_en": "How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?", "authors": "Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda", "background": "近年来，3D点云变换器在语义分割和重建等任务中取得了最先进的成果。然而，这些模型通常依赖于密集的令牌表示，导致在训练和推理过程中产生高计算和内存成本。研究表明，令牌之间存在显著的冗余性，这是以前未曾被充分认识到的。", "innovation": "本文提出了一种名为gitmerge3D的全局信息指导下图令牌合并方法，该方法可以将令牌数量减少至90-95%，同时保持竞争力表现。这挑战了当前假定的更多令牌更优性能的观点，表明许多现有模型的令牌使用量过剩且对于可扩展性优化不足。我们通过多个3D视觉任务验证了该方法，并展示了在计算效率方面的持续改进。这是首次评估大型3D变换器模型中的冗余性，为更高效的3D基础架构开发提供了宝贵的见解。", "conclusion": "本工作证明了大型3D变换器模型中的冗余性，并通过公开代码和检查点，提供了实现更加高效3D基础架构的潜在策略，为3D视觉任务中的性能和效率优化提供了重要依据。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05301", "html_url": "https://arxiv.org/abs/2511.05301", "title": "QUESTER：生成检索中的查询规范", "title_en": "QUESTER: Query Specification for Generative Retrieval", "authors": "Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski", "background": "生成检索（GR）与传统的建立索引然后检索的流程不同，它通过存储相关性于模型参数中，并直接生成文档标识符。然而，GR在泛化和扩展方面经常存在问题。本研究旨在解决这些问题。", "innovation": "提出了QUESTER（查询规范生成检索），将GR重新定义为查询规范生成——使用一个小型LLM处理一个简单的关键词查询，并通过REINFORCE方法训练策略。研究发现，QUESTER在跨领域的评估中比BM25更有效，并且在性能上接近神经信息检索模型，同时保持较高的效率。", "conclusion": "研究结果表明，QUESTER在查询特定性生成上有显著改进，能够在不牺牲性能的情况下提高效率。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05292", "html_url": "https://arxiv.org/abs/2511.05292", "title": "从可穿戴IMUs推断你盘中的佳肴 What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs", "title_en": "What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs", "authors": "Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang", "background": "准确检测饮食摄入对于饮食监控和慢性病预防至关重要。传统的自我报告方法容易受到回忆偏差的影响，而基于相机的方法则引发了对隐私的担忧。现有的基于可穿戴设备的方法主要集中在汉堡、比萨等有限的食物类型上，未能覆盖丰富多样的中国菜肴。", "innovation": "本文提出了CuisineSense系统，该系统通过整合智能手表的手部运动线索和智能眼镜的头部动态来分类中国食物类型。设计了一种两阶段检测管道来过滤掉无关的日常活动。第一阶段通过识别特征时序模式来区分进食状态和非进食行为。第二阶段根据进食时捕捉到的运动进行精细的食物类型识别。", "conclusion": "通过构建包含27.5小时11类食物、10名参与者IMU记录数据集进行实验。结果表明，CuisineSense在进食状态检测和食物分类方面均实现了高准确性，提供了一种无干扰的可穿戴式饮食监控解决方案。此系统代码已公开。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2209.01378", "html_url": "https://arxiv.org/abs/2209.01378", "title": "RNN(p) for Power Consumption Forecasting", "title_en": "RNN(p) for Power Consumption Forecasting", "authors": "Roberto Baviera,Pietro Manzoni", "background": "研究背景描述了一种新的递归神经网络模型RNN(p)及其在具有多时间尺度内在季节性模式的能源、经济和金融时间序列上的优点。RNN(p)作为一种元素级递归神经网络，是对线性自回归模型ARX(p)的自然扩展，可以作为高效的预测工具。文章强调RNN(p)的反馈连接结构和高效的训练策略设计，尤其是在电力消费预测中的应用关键领域，准确的预测是影响运营和财务决策的重要因素。", "innovation": "创新之处在于研究提出了RNN(p)模型，并通过比较不同的学习算法，研究了其计算复杂性和训练性能，同时在电力消费预测领域提供了两个实际应用案例。结果显示，RNN(p)模型在保持高度可解释性的情况下实现了卓越的预测准确性。研究表明，RNN(p)模型最适合于金融市场和其他金融科技应用，这些领域的可靠预测对经济具有重要意义。", "conclusion": "研究结论指出，RNN(p)模型在电力消费预测中表现出色，能够提供高度可解释的预测结果。其高效和准确的特点使其非常适用于能源市场和其他金融科技应用环境中的决策制定。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.01336", "html_url": "https://arxiv.org/abs/2309.01336", "title": "基于聚类的区间预测学习方法：电能需求的区间估计", "title_en": "Learning for Interval Prediction of Electricity Demand: A Cluster-based Bootstrapping Approach", "authors": "Rohit Dube,Natarajan Gautam,Amarnath Banerjee,Harsha Nagarajan", "background": "在小规模微电网中，精确预测电力需求对于运营管理至关重要。由于低聚合性，电力需求具有高度的随机性，单一的点估计会导致较大的误差。区间估计可以提供未来值可能落在的范围，并有助于量化点估计周围的误差。", "innovation": "提出了基于残差的快速重采样算法来生成次日电力需求的区间估计。通过机器学习算法获得训练集中的电力需求点估计及残差，使用无监督学习算法将具有相似需求模式的日子分群，然后根据测试日的点估计选择最相似群来进行残差重采样。", "conclusion": "该算法在EULR实际电力需求数据上进行了评估，并与不同的重采样方法进行了比较，发现在不同置信区间下均表现良好。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.06524", "html_url": "https://arxiv.org/abs/2403.06524", "title": "基于运营总成本的深度强化学习自主卡车战术决策", "title_en": "Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward", "authors": "Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani", "background": "本文致力于通过深度强化学习框架来处理自主卡车在高速公路场景中的战术决策问题，特别是针对自适应巡航控制（ACC）和变道动作。研究背景旨在优化此类系统的性能，特别是在高效率和多目标奖励函数的应用方面。", "innovation": "创新点在于提出了一种分离高层决策和低层控制的深度强化学习框架，并使用基于运营总成本（TCOP）的多目标奖励函数来优化自主卡车的性能。通过调整奖励组件的权重、规范化奖励组件和使用递增学习技术，优化了系统的决策过程。", "conclusion": "实验结果表明，通过分离高层决策和低层控制，以及使用基于TCOP的真实且多目标的奖励函数，能够显著提高自主卡车在战术决策中的性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2210.01985", "html_url": "https://arxiv.org/abs/2210.01985", "title": "A Multi-Stage Automated Online Network Data Stream Analytics Framework for IIoT Systems", "title_en": "A Multi-Stage Automated Online Network Data Stream Analytics Framework for IIoT Systems", "authors": "Li Yang,Abdallah Shami", "background": "工业4.0的目标是最大化人力和机器的合作。机器能够自动化重复性任务，而人类则处理创造性任务。作为IIoT系统的关键组成部分，网络数据流分析常因动态的IIoT环境而遭遇概念漂移问题，这导致性能下降和自动化困难。", "innovation": "提出了一种新颖的多阶段自动化网络分析(MSANA)框架，用于IIoT系统的概念漂移适应，该框架包含动态数据预处理，基于漂移的动态特征选择(DD-FS)方法，动态模型学习与选择，以及窗口基于性能加权概率平均集成(W-PWPAE)模型。这为IIoT系统提供了完整的自动化数据流分析框架，使得在工业4.0中能够实现自动、有效和高效的数据分析。实验结果表明，该框架在两个公开的物联网数据集上优于现有的方法。", "conclusion": "提出的MSANA框架在IIoT系统中实现了自动化的数据流分析，展示了优异的性能，在动态IIoT环境中解决了概念漂移问题，为工业4.0中的人机协作提供了支撑，是当前最先进的方法的改进。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.12131", "html_url": "https://arxiv.org/abs/2305.12131", "title": "非稳态延迟在线凸优化：从完全信息设置到泛化设置", "title_en": "Non-stationary Delayed Online Convex Optimization: From Full-information to Bandit Setting", "authors": "Yuanyu Wan,Chang Yao,Yitao Ma,Mingli Song,Lijun Zhang", "background": "虽然最近对具有任意延迟的在线凸优化（OCO）研究增多，但以往的研究主要集中在静态环境中，目标是最小化静态后悔。本文研究了非静态环境中具有延迟的OCO问题，选择针对任何比较序列的动态后悔作为性能指标。文章首先提出了一个名为Mild-OGD的算法用于全信息情况，该算法在延迟梯度可用时可以维护多专家并基于延迟表现选择最优者。此外，还提出了Mild-OGD的带有延迟损失值的拉伯特变体，该算法在拥有更多延迟信息时表现出更好的动态后悔界。", "innovation": "本文提出了Mild-OGD算法及其在非静态环境中的应用，首次在动态后悔界中处理了具有延迟的在线优化问题，并得出了对该问题的理论边界，同时实现了与现有算法的最优比较。此外，还探讨了在更困难的只有延迟损失值情况下该算法的表现，证明了在大量延迟情况下甚至超越了现有无延迟的在线优化算法的表现。", "conclusion": "研究得出了Mild-OGD算法在全信息情况下的动态后悔界为$O(\text{min}(\bar{d} \times \text{sqrt}(T \times (P_T + 1)), d \times \text{sqrt}(T \times (P_T + 1))))$。同时，为具有延迟损失值的情况还设计了相应的Mild-OGD拉伯特变体算法，并证明了在较大延迟情况下，该算法的动态后悔界是最优的。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02615", "html_url": "https://arxiv.org/abs/2410.02615", "title": "ExGra-Med：扩展语境图对齐用于医疗视觉语言模型", "title_en": "ExGra-Med: Extended Context Graph Alignment for Medical Vision-Language Models", "authors": "Duy M. H. Nguyen,Nghiem T. Diep,Trung Q. Nguyen,Hoang-Bao Le,Tai Nguyen,Tien Nguyen,TrungTin Nguyen,Nhat Ho,Pengtao Xie,Roger Wattenhofer,James Zou,Daniel Sonntag,Mathias Niepert", "background": "现有的医疗多模态大型语言模型（med-MLLMs），比如 LLaVA-Med 和 BioMedGPT，主要依赖于扩大模型规模和数据量，训练主要由自回归目标驱动。然而，这种方法可能导致视觉和语言的对齐较弱，使模型过度依赖昂贵的指令跟随数据。", "innovation": "我们引入了 ExGra-Med（扩展语境图对齐），这是一种新的多图对齐框架，能够在一个潜空间中联合对齐图像、指令回应和扩展的说明，从而提高语义接地和跨模态的一致性。同时，我们还开发了一种高效的端到端训练方案，使用黑盒梯度估计，使优化更快、更可扩展。实验证明，ExGra-Med 仅使用 10% 的预训练数据就达到了与 LLaVA-Med 相似的性能，并在 VQA-RAD 中取得了 20.13% 的提升，接近全数据性能。此外，ExGra-Med 在视觉聊天机器人和零样本分类任务中也优于 BioMedGPT 和 RadFM 等强大的基线模型，展示了其在医疗 AI 中高效、高质量的视觉语言集成潜力。", "conclusion": "ExGra-Med 通过改进视觉和语言的对齐机制，以及高效的训练方案，在医疗多模态任务上取得了显著的性能提升，展示了其在提高医疗 AI 中的视觉语言集成能力上的巨大潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05975", "html_url": "https://arxiv.org/abs/2410.05975", "title": "使用对比元目标进行快速学习", "title_en": "Learning to Learn with Contrastive Meta-Objective", "authors": "Shiguang Wu,Yaqing Wang,Yatao Bian,Quanming Yao", "background": "元学习使学习系统能够快速适应新任务，类似于人类的学习过程。不同的元学习方法都基于小批量分集训练框架运行。这种框架自然地提供了任务身份的信息，可以作为元训练中的附加监督，以提高泛化能力。", "innovation": "提出了一种对比元目标（ConML），在问题和学习者无关的元训练框架下评估和优化对比元目标。该方法通过对比元学习者所学的内容，即模型表示，利用了人类快速学习的对齐和区分能力。ConML无缝集成到现有的元学习模型和增量学习模型中，并带来了显著的性能提升，实现成本较低。", "conclusion": "实验表明，ConML能够无缝地与现有的元学习模型及相关学习模型集成，提供显著的性能提升，所增加的实现成本较低，有助于进一步提高模型的泛化能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03801", "html_url": "https://arxiv.org/abs/2410.03801", "title": "P1-KAN:一个有效的柯尔莫戈罗夫-阿诺尔德网络及其在水力河谷优化中的应用", "title_en": "P1-KAN: an effective Kolmogorov-Arnold network with application to hydraulic valley optimization", "authors": "Xavier Warin", "background": "本文介绍了一种新的柯尔莫戈罗夫-阿诺尔德网络（KAN），用于近似高维中的潜在不规则函数。已知KAN网络在处理不规则函数时表现出色，但对于光滑函数的性能尚未充分探索。之前的KAN网络虽然在某些情况下有效，但在处理不规则函数时仍存在改进空间。因此，本文提出了P1-KAN，旨在提高整体性能，特别是在优化水力河谷方面。", "innovation": "本文创新地提出了P1-KAN，这是一种改进的KAN网络，能够在保证低维函数高精度近似的同时，提高对高维不规则函数的近似准确性。而且，P1-KAN不仅展示了在不规则函数方面具有优越性，对于光滑函数也能达到与基于样条的原始KAN相同的精度。此外，P1-KAN在优化水力河谷方面也展示了良好的性能，表明它在实际应用中具有广泛潜力。", "conclusion": "本文证明了P1-KAN在近似不规则和光滑函数时均优于现有方法，特别是在优化水力河谷方面表现出强烈优势。P1-KAN提供了一种新的解决方案，可以促进高维函数的近似研究，并为未来的应用提供支持。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18075", "html_url": "https://arxiv.org/abs/2410.18075", "title": "ProFL: Performative Robust Optimal Federated Learning", "title_en": "ProFL: Performative Robust Optimal Federated Learning", "authors": "Xue Zheng,Tian Xie,Xuwei Tan,Aylin Yener,Xueru Zhang", "background": "此论文探讨了在联邦学习场景中部署机器学习模型时，由于数据生成过程导致的模型分布变化问题。现有的研究多是在集中式设置下进行的，并且这些方法要求可凸性和无噪声训练数据，但在实际的联邦学习系统中，这些条件常常不满足。", "innovation": "论文提出了一个名为ProFL的新算法，该算法能够在噪声和污染的数据上找到表现最优点，克服了现有方法在联邦学习中的局限性，适用于非凸目标。此方法在聚类分析下的收敛性分析为非凸目标提供了支持。", "conclusion": "大量的实验结果显示，ProFL算法在多个数据集上的表现优于当前最先进的方法，证明了其在联邦学习中的优势和实用性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.18905", "html_url": "https://arxiv.org/abs/2402.18905", "title": "以兰格朗日扩散表征私有微调的训练动力学", "title_en": "Characterizing the Training Dynamics of Private Fine-tuning with Langevin diffusion", "authors": "Shuqi Ke,Charlie Hou,Sewoong Oh,Giulia Fanti", "background": "该研究基于差分隐私的全微调方法(DP-FFT)，探讨了预训练主干特征在理论和实证结果上的失真现象，并分析了其原因。研究背景是差分隐私技术在保护数据隐私的同时，如何影响模型训练效果。", "innovation": "该研究提出了一种序贯微调策略（DP-LP-FFT），能够缓解特征失真问题。通过构建一种新的近似方案，能够推导出在2层ReLU激活的神经网络框架下，DP-LP和DP-FFT训练损失的近似上下界。研究不仅在真实数据集和结构上验证了理论洞见，还为2层线性网络推导出新的上界，进一步探讨了在多阶段微调方法中的隐私预算分配权衡。", "conclusion": "该研究表明，序贯微调策略能够有效缓解由预训练主干和随机初始化线性头之间的不匹配导致的特征失真问题。同时指出，不同阶段的微调过程中，隐私预算的分配存在权衡。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.05476", "html_url": "https://arxiv.org/abs/2511.05476", "title": "代码语言模型知识蒸馏的元测试视角：学生是否会深度模仿教师？", "title_en": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "authors": "Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy", "background": "基于变换器的语言模型在软件分析任务中表现出色，但其实际应用受高计算成本、慢推理速度以及高环境影响的限制。现有研究虽探索了知识蒸馏来压缩大模型（老师）以得到小模型（学生），但尚未充分研究学生模型对教师模型行为预测和内部表示的深度模仿程度，传统的基于准确率的评估仅提供表面评估，未能全面反映两者行为的一致性差距。文中通过实验证明，学生模型未能深刻模仿教师模型，在对抗性攻击中性能下降可达285%，传统的准确率评估未能捕捉到这种行为差距。", "innovation": "提出MetaCompress，这是一种元测试框架，通过设定语义保持的元测试关系来系统性地评估学生模型和教师模型的行为一致性。研究比较了使用三种不同知识蒸馏技术（Compressor, AVATAR, MORPH）压缩的流行代码语言模型版本，并识别到高达62%的行为差异。这表明需要在知识蒸馏管道中引入行为一致性评估，并验证MetaCompress为测试基于知识蒸馏生成的代码语言模型的有效框架。", "conclusion": "MetaCompress识别出了高达62%的行为差异，突显了行为一致性评估在知识蒸馏管道中的重要性，确立了MetaCompress作为测试基于知识蒸馏生成的代码语言模型的实用框架。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21704", "html_url": "https://arxiv.org/abs/2410.21704", "title": "含有未界Markov噪声的随机逼近：一个通用定理", "title_en": "Stochastic Approximation with Unbounded Markovian Noise: A General-Purpose Theorem", "authors": "Shaan Ul Haque,Siva Theja Maguluri", "background": "本文探讨了平均收益增强学习中无界状态空间和收益函数的问题，研究了Actor-Critic框架下的问题并提出了误差保证的批评家访问的能力有限样本边界。本文进一步研究了线性函数逼近下的Temporal Difference (TD)学习，并通过适当时不变条件建立了有限时间的边界，取得了最优的$\text{O}\big(\frac{1}{\text{ε}^2}\big)$样本复杂性。这些结果是利用了非线性随机逼近的通用定理。", "innovation": "本文通过引入一个宽松的设置和弱假设计，并给出了一般用途的非线性随机逼近定理，使得随机逼近从独立同分布或鞅差情况推广到可能不含界的马尔可夫噪声情况下。通过这个定理解释了两种新系统：（i）改进了$Q$-学习的有限时间边界，收紧了误差边界，允许更广泛的策略行为角色。（ii）首次建立了高维平滑强凸函数分布式随机优化的有限时间边界。", "conclusion": "本文的总体结论是通过新的定理将随机逼近技术从理论应用推广到实际工程应用并建立了更严格的理论保证，对于资源分配在网络和库存系统中的应用有着重要意义。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03265", "html_url": "https://arxiv.org/abs/2501.03265", "title": "认知边缘计算：边缘部署大型模型和AI代理的综合综述", "title_en": "Cognitive Edge Computing: A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment", "authors": "Xubin Wang,Qing Li,Weijia Jia", "background": "本文调查了认知边缘计算作为一种将高推理能力的大型语言模型（LLMs）和自主AI代理部署到资源受限的网络边缘设备的实用和系统化途径。讨论了在严格的内存/计算预算下保留多步推理能力的模型优化策略，以及权衡延迟、能耗、隐私和容量的系统架构设计，还包括适应性智能，即根据任务难度和设备约束进行计算定制。", "innovation": "本文合成了高效Transformer设计、多模态集成、硬件感知编译、隐私保护学习和自主工具使用等领域的进展，并将其映射到边缘特定的操作环境下。同时，提出了一套标准化评估协议，包含延迟、吞吐量、每词功耗、准确性、鲁棒性、隐私和可持续性等关键指标，并明确了测量假设以增强可比性。", "conclusion": "最后，指出了现有挑战，包括模态意识推理基准测试、透明和可重复的能量报告、面向边缘的安全/对齐评估以及多代理测试平台。本文还为算法、运行时和硬件的跨层协同设计提供了实操指南，以确保边缘设备上提供可靠、高效且隐私保护的认知能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00696", "html_url": "https://arxiv.org/abs/2411.00696", "title": "CTPD: 跨模态时间模式发现以增强多模态电子健康记录分析", "title_en": "CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis", "authors": "Fuying Wang,Feng Wu,Yihan Tang,Lequan Yu", "background": "多模态电子健康记录（EHR）数据，包括数值时间序列和自由文本临床报告，具有预测临床结果的巨大潜力。然而，过去的研究所侧重于捕捉单个样本内的时间关联，并融合跨模式信息，忽视了跨患者的关键时间模式。例如，心率或血压等生命体征的趋势可以表明健康状况恶化或即将发生危急事件。临床报告中通常包含反映这些趋势的文本描述。识别不同模态中的对应时间模式对于提高临床结果预测的准确性至关重要，但这是个具有挑战性的任务。", "innovation": "本文引入了一种跨模态时间模式发现（CTPD）框架，旨在高效地从多模态EHR数据中提取有意义的时间模式。该方法采用了共享的初始时间模式表示，并通过槽注意力机制进行细化以生成时间语义嵌入。为了确保学习模式中的丰富跨模态时间语义，引入了一种基于对比的方法TPNCE损失进行跨模态对齐，同时引入了两种重建损失以保留每个模态的核心信息。", "conclusion": "在MIMIC-III数据库上对48小时院内死亡率和24小时表型分类两个临床关键任务进行评估，证明了本方法优于现有方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08263", "html_url": "https://arxiv.org/abs/2501.08263", "title": "多玩家联邦学习：较少通信实现均衡", "title_en": "Multiplayer Federated Learning: Reaching Equilibrium with Less Communication", "authors": "TaeHo Yoon,Sayantan Choudhury,Nicolas Loizou", "background": "传统的联邦学习（FL）方法假设协作的客户端具有对齐的目标，共同朝着共享的全局模型努力。然而，在许多现实场景中，客户端作为具有个体目标和策略行为的理性玩家存在，现有的FL框架无法有效解决这些问题。因此，为了改变这一现状，引入了多玩家联邦学习（MpFL）框架，将客户端在FL环境中建模为博弈论中的玩家，目标是达到均衡状态。在这种情况下，每个玩家都试图优化自身的效用函数，这可能与集体目标不一致。", "innovation": "提出了一种新的算法Per-Player Local Stochastic Gradient Descent（PEARL-SGD），其中每个玩家/客户端独立地进行本地更新，并定期与其他玩家进行通信。理论分析表明，在随机设置中，PEARL-SGD相较于非局部的版本，能够以较少的通信量达到均衡附近的状态。", "conclusion": "通过数值实验验证了理论发现，证实PEARL-SGD算法能够实现较少通信量下的均衡状态。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00879", "html_url": "https://arxiv.org/abs/2502.00879", "title": "使用大型语言模型生成计算认知模型", "title_en": "Generating Computational Cognitive Models using Large Language Models", "authors": "Milena Rmus,Akshay K. Jagadish,Marvin Mathony,Tobias Ludwig,Eric Schulz", "background": "计算认知模型能够量化认知过程，并通过将模型拟合到行为数据来仲裁竞争理论。传统上，这些模型是手工构建的，需要大量的领域知识、编程技能和时间投资。然而，机器学习的最新进展为解决这些挑战提供了解决方案，特别是在上下文中的模式识别方面，大型语言模型展示了惊人的能力，能够利用来自不同领域的知识来解决复杂问题，并生成可执行代码来促进计算认知模型的生成。", "innovation": "该研究介绍了一种使用大型语言模型指导生成计算认知模型的管道（GeCCo）。给定任务说明、参与者数据和模板函数，GeCCo提示大型语言模型提出候选模型，并将提案拟合到保留数据中，根据基于预测性能的反馈迭代完善这些提案。研究以四个不同的认知领域——决策制定、学习、计划和记忆——为背景，使用了三种不同规模、能力和家族的开源大型语言模型。在四个真实的人类行为数据集上，这些模型在预测性能上持续匹配甚至超过了认知科学文献中最优秀领域的模型。研究结果表明，大型语言模型能够生成与文献中最佳模型相匹敌甚至超越跨不同任务领域的认知模型。", "conclusion": "我们的结果表明，大型语言模型可以生成具有概念上合理理论的认知模型，这些模型在不同任务领域中可以匹敌甚至超越文献中最好的模型。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.00956", "html_url": "https://arxiv.org/abs/2407.00956", "title": "深入探讨深度学习方法在表格数据集上的表现", "title_en": "A Closer Look at Deep Learning Methods on Tabular Datasets", "authors": "Han-Jia Ye,Si-Yang Liu,Hao-Run Cai,Qi-Le Zhou,De-Chuan Zhan", "background": "表格数据在机器学习的各个领域中非常普遍。随着深度表格预测方法，尤其是预训练（基础）模型的迅速发展，系统地评估这些方法并理解其行为变得越来越重要。为此，该研究对TALENT进行了广泛研究，包括300多个涵盖多种规模、特征组成（数值/分类的混合）、领域和输出类型（二分类、多分类、回归）的数据集。研究表明，集成方法同时提升了基于树和神经网络的方法。尽管传统梯度增强树仍然是非常强大的基线，但最近的预训练表格模型在许多任务上与其接近或超过了它们，缩小了但并未消除树集成的历史优势。尽管在架构上存在多样性，但顶级性能集中在少数几个模型中，为方法选择提供了实用指导。", "innovation": "该研究通过学习元特征和早期训练动态来量化数据集的异质性，并预测后续验证行为，引入了一种新的动态意识分析方法，表明异质性（如分类和数值属性的相互作用）很大程度上决定了哪种方法家族占优。此外，研究者提出了一个两层次设计，包括一个紧凑的TALENT-tiny核心（45个数据集）用于快速和可重复的评估，以及一个TALENT-extension套件，旨在针对高维、多分类和非常大规模的设置进行压力测试，以深入考察这些模型在复杂情况下的表现。", "conclusion": "研究结果提供了对于改进深度表格学习的优势、局限以及未来方向的具体见解。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.11551", "html_url": "https://arxiv.org/abs/2410.11551", "title": "LoKO: 低秩卡尔曼优化器在大型模型在线微调中的应用", "title_en": "LoKO: Low-Rank Kalman Optimizer for Online Fine-Tuning of Large Models", "authors": "Hossein Abdi,Mingfei Sun,Andi Zhang,Samuel Kaski,Wei Pan", "background": "从零训练包含数百万甚至数亿参数的大模型需要消耗巨大的计算资源。Parameter Efficient Fine-Tuning (PEFT) 方法，尤其是 Low-Rank Adaptation (LoRA)，通过使用基于梯度的优化器调整少量特定任务参数来解决这一挑战。", "innovation": "作者将PEFT问题重新表述为最优滤波/状态估计问题，并提出了一种新的方法——Low-Rank Kalman Optimizer (LoKO)。LoKO利用LoRA中的低秩分解显著减少了卡尔曼滤波迭代中的矩阵尺寸，并进一步利用协方差矩阵的对角线近似有效地将计算复杂度从平方级降低到线性级。此外，作者指出卡尔曼算法中协方差矩阵的初始化和观测噪声协方差的准确估计是此表述的关键，并提出了一种鲁棒方法，该方法在广泛的计算机视觉和语言模型中表现出色。实验表明，LoKO相比于使用LoRA的常用优化器在图像分类和语言任务中具有更快的收敛速度和更好的性能。", "conclusion": "本研究展示了卡尔曼滤波器作为一种有效的优化器，在在线微调大型模型中的潜在应用可能性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05447", "html_url": "https://arxiv.org/abs/2412.05447", "title": "TOBUGraph: 基于知识图谱的检索以超越RAG提升LLM性能", "title_en": "TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG", "authors": "Savini Kashmira,Jayanaka L. Dantanarayana,Joshua Brodsky,Ashish Mahendra,Yiping Kang,Krisztian Flautner,Lingjia Tang,Jason Mars", "background": "检索增强生成（RAG）是提升大语言模型（LLM）检索能力的领先且广泛使用的技术之一，但在商业应用中仍面临诸多限制。RAG主要依赖于查询与文本文档在嵌入空间中的相似性进行检索，这导致其无法捕捉文档间更深层次的语义关系，高度依赖于分块策略，并且容易产生幻觉。", "innovation": "我们提出了TOBUGraph，一种基于图的检索框架，首先从未结构化数据中动态且自动地构建知识图谱。TOBUGraph使用大语言模型提取结构化知识和数据间的多样关系，超越了RAG的简单的文本文本相似性。检索通过图遍历实现，利用提取得到的关系和结构提高检索精度，免除了分块配置的需求并减少了幻觉。", "conclusion": "我们通过实际应用TOBU，证实TOBUGraph在个人记忆组织和检索中有效。使用真实用户数据的评估表明，TOBUGraph在查准率和查全率上都优于多种RAG实现，显著改善了用户体验，提升了检索精度。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08600", "html_url": "https://arxiv.org/abs/2502.08600", "title": "增强异构时间序列预测精度的两阶段混合模型", "title_en": "Two-stage hybrid models for enhancing forecasting accuracy on heterogeneous time series", "authors": "Junru Ren,Shaomin Wu", "background": "在时间序列预测领域，局部时间序列模型（tsLM）基于单一时间序列构建，而全局时间序列模型（tsGM）则基于多个时间序列训练。tsGMs能够通过学习跨序列的信息来提高预测准确性和泛化能力，因此受到了研究界的广泛关注。然而，当给定的时间序列集不同时，tsGMs的优势可能无法完全实现。增加模型复杂性可以帮助tsGMs适应这类数据集，但也增加了过拟合和预测错误的风险。此外，文献中关于同质性的定义仍不确定。", "innovation": "本文提出了一个新的两阶段混合建模框架来解决上述挑战：第一阶段学习一个全局时间序列模型以识别同质性；第二阶段基于不同的群体学习局部时间序列模型（如ARIMA）或子全局时间序列模型以捕捉异质性。实验结果表明，所提出的方法显著优于六个最先进的模型，这突显了其在异构数据集上充分发挥全局预测模型潜力的有效性。", "conclusion": "实验结果表明，所提出的方法在四种公开数据集上显著优于最先进的六种方法，证明了其在异构时间序列预测中的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03366", "html_url": "https://arxiv.org/abs/2502.03366", "title": "重新审视分类中的近似高斯推理", "title_en": "Rethinking Approximate Gaussian Inference in Classification", "authors": "Bálint Mucsányi,Nathaël Da Costa,Philipp Hennig", "background": "在分类任务中， softmax 函数普遍被用作输出激活方式以生成预测概率。这类输出只捕捉了可预测的不确定性（aleatoric uncertainty）。为了捕捉不可预测的不确定性（epistemic uncertainty），已提出了近似高斯推理方法。然而，这些方法推断出的是对数几率空间的高斯分布，推导出的预测值通过 softmax 函数进行期望处理，但这种处理不能解析求解，并且蒙特卡洛（MC）近似计算会非常耗时且噪音大。", "innovation": "本文提出了一种新的方法，将 softmax 激活替换为逐元素的 normCDF 或 sigmoid，使得预测可以无采样的准确近似计算。此方法通过匹配矩的方式将高斯推移近似为狄利克雷分布，从而完全消除了 MC 采样的运行时间和内存开销。在 ImageNet、CIFAR-100 和 CIFAR-10 数据集上，该方法与 Laplace、HET 和 SNGP 等近似高斯推理方法结合使用，表现出比 softmax MC 采样更好的不确定性量化能力。", "conclusion": "本文结合几种近似高斯推理方法评价了该方法在大型和小型数据集上的表现，证明了相比 softmax MC 采样，该方法增强了不确定性量化能力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04010", "html_url": "https://arxiv.org/abs/2503.04010", "title": "结构化强盗问题中的贪婪算法：渐近成功/失败的精确表征", "title_en": "Greedy Algorithm for Structured Bandits: A Sharp Characterization of Asymptotic Success / Failure", "authors": "Aleksandrs Slivkins,Yunzong Xu,Shiliang Zuo", "background": "研究在已知奖励结构下的强盗问题中的贪婪（仅利用）算法。以往的研究专注于少数几种特定的奖励结构，而本研究允许任意有限的奖励结构。", "innovation": "完全表征了贪婪算法在时间函数上亚线性或线性后悔中的渐近成功或失败。发现问题实例的部分可识别性性质是渐近成功或失败的必要和充分条件。一旦具有这种性质，该问题变得容易处理——任何满足轻度非退化条件的算法都将成功。", "conclusion": "该特征化推广到带上下文的强盗和具有任意反馈的交互决策。还提供了广泛适用性的示例和无限奖励结构的扩展。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17206", "html_url": "https://arxiv.org/abs/2502.17206", "title": "Neural Attention: 一种增强Transformer模型表达能力的新机制", "title_en": "Neural Attention: A Novel Mechanism for Enhanced Expressive Power in Transformer Models", "authors": "Andrew DiGiugno,Ausif Mahmood", "background": "Transformer模型通常使用点积来计算注意力矩阵，但在捕捉嵌入向量之间的非线性关系方面存在局限性。", "innovation": "提出了一种名为Neural Attention的技术，它用前馈网络代替点积，从而更直观地表达令牌之间的关系。此方法仅修改了注意力矩阵的计算方式，保留了矩阵的维度，使其能够很容易地适应现有的基于Transformer的架构。论文提供了详细的数学证明，解释了为什么Neural Attention能够增加表示能力，并通过受控实验验证了这一主张。实验结果表明，与Dot-Product Attention相比，在NLP任务上WikiText-103上的困惑度降低了超过2%，在图像分类任务上的CIFAR-10和CIFAR-100上的准确率提高了超过4个百分点。尽管Neural Attention增加了计算需求，但开发的技术可以减轻这些挑战，确保其实用性和实际适用性。", "conclusion": "通过Neural Attention技术，本工作证明了它在跨各种应用增强Transformer模型预测能力的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13438", "html_url": "https://arxiv.org/abs/2505.13438", "title": "通过预算相关策略优化实现任意时态推理优化", "title_en": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization", "authors": "Penghui Qi,Zichen Liu,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "提升大规模语言模型（LLMs）的推理能力的关键在于提高测试时计算量的可扩展性。现有方法通常使用强化学习（RL）来最大化推理过程中获得的可验证奖励。然而，这些方法仅优化了在固定大量token预算下最终的表现，这在训练和部署中降低了效率。因此，本文提出了一种新的框架，AnytimeReasoner，旨在优化在不同token预算约束下的任意时态推理表现，提高token效率和推理的灵活性。", "innovation": "本文提出了一种新框架AnytimeReasoner，该框架通过在先验分布中抽样token预算，并截断完整的推理过程来适应这些预算，迫使模型总结每个截断推理中的最优答案以供验证。这样引入了推理过程中的可验证密集奖励，有助于强化学习优化中的更有效责任分配。此外，还提出了一种新的方差减少技术——预算相关策略优化（BRPO），以增强强化推理策略时学习过程的稳健性和效率。", "conclusion": "在数学推理任务上的实验结果表明，本文的方法在所有思考预算下都优于GRPO，显著提升了训练和token效率。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16395", "html_url": "https://arxiv.org/abs/2502.16395", "title": "AIRepr：数据科学中大型语言模型可再现性的分析师-检查员框架", "title_en": "AIRepr: An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science", "authors": "Qiuhai Zeng,Claire Jin,Xinyue Wang,Yuhan Zheng,Qunhua Li", "background": "大型语言模型（LLMs）被广泛用于通过生成可执行代码来自动化数据分析。然而，数据科学任务往往存在多种统计上都有效的解决方案，例如不同的建模策略，因此理解分析背后的逻辑比仅仅关注结果更为重要。尽管手动审查生成的代码可以帮助确保统计上的正确性，但这过程耗时且需要专业知识。为了克服这个问题，提出了一种更可扩展的方法，即评估生成代码底层的工作流程，即指导代码生成的逻辑计划。然而，目前尚未明确评估生成工作流程是否支持可再现性实现的方法。", "innovation": "本文提出了AIRepr，一个分析师-检查员框架，用于自动评估和提高LLM生成的数据分析工作流程的可再现性。框架基于统计原则，支持可扩展且自动化的评估。引入了两种新的增强可再现性的提示策略，并通过15个分析师-检查员LLM对和来自三个公开基准的1,032项任务与标准提示进行了对比。结果显示，具有更高可再现性的工作流程也会产生更准确的分析结果，并且增强可再现性的提示显着提高了这些指标。", "conclusion": "这项工作为透明、可靠和高效的人机协作提供了数据科学的基础。所用代码已经公开。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17013", "html_url": "https://arxiv.org/abs/2505.17013", "title": "从扩散模型中概念被删除的情况是何时发生的？", "title_en": "When Are Concepts Erased From Diffusion Models?", "authors": "Kevin Lu,Nicky Kriplani,Rohit Gandikota,Minh Pham,David Bau,Chinmay Hegde,Niv Cohen", "background": "在概念擦除中，模型被修改以选择性地防止其生成目标概念。尽管新方法迅速发展，但目前尚不清楚这些方法是否能彻底删除模型中的目标概念。该研究提出两种概念擦除机制的概念模型：(i) 干扰模型的内部引导过程，(ii) 减少生成目标概念的无条件可能性，可能完全删除该概念。为了评估目标概念是否真的从模型中被删除，研究引入了一整套独立探查技术：提供视觉上下文，修改扩散轨迹，应用分类器引导，以及分析删除概念后模型生成的替代生成物。这一系列研究指出，应该探索概念擦除在对抗性文本输入之外的稳健性，且强调了对扩散模型中擦除进行全面评估的重要性。", "innovation": "该研究提出了两种概念擦除机制的概念模型，旨在通过不同方法评估目标概念是否从扩散模型中被真正删除。通过探查和分析，研究提供了关于概念擦除在扩散模型中的稳健性的新见解。这项工作强调了全面评估的重要性。", "conclusion": "研究的结果强调了在扩散模型中进行概念擦除评估的重要性，尤其是在非对抗性文本输入情况下。这将有助于构建更加安全和可靠的模型。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14338", "html_url": "https://arxiv.org/abs/2505.14338", "title": "改进的神经网络表示能力：细分单纯形", "title_en": "Better Neural Network Expressivity: Subdividing the Simplex", "authors": "Egor Bakaev,Florestan Brunck,Christoph Hertrich,Jack Stade,Amir Yehudayoff", "background": "此研究关注ReLU神经网络在深度方面的表达能力。前期研究已经表明，$\frac{\text{log}_{2}(n+1)}{\text{log}_{10}(2)}$隐藏层可以计算$\textbf{R}^n$上的所有连续分段线性（CPWL）函数。Hertrich等人曾推测，这个结果是最优的，也就是说，像最大值函数这样的CPWL函数可能需要达到这个深度。然而，此研究反驳了这一推测。", "innovation": "通过证明具有两隐藏层的ReLU神经网络可以精确表示5个输入的最大值，进一步，该研究展示了$\frac{\text{log}_{3}(n-2)}{\text{log}_{10}(3)}+1$隐藏层可以计算$n \text{(}n \text{ 为 } \textgreater= 4\text{)}$个数的最大值，这在特殊的ReLU网络权重为十进分数的情况下几乎达到了Averkov等人的$\frac{\text{log}_{3}(n)}{\text{log}_{10}(3)}$下限。该研究还从几何角度解释了构造方法，通过单纯形的多面体细分生成“更简单”的多面体。", "conclusion": "该研究最终证明，只需$\frac{\text{log}_{3}(n-1)}{\text{log}_{10}(3)}+1$隐藏层即可计算$\textbf{R}^n$上的所有CPWL函数，这一结论改进了之前的最优表述深度的结果。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01502", "html_url": "https://arxiv.org/abs/2506.01502", "title": "学习种群动力学：逆优化遇见JKO方案", "title_en": "Learning of Population Dynamics: Inverse Optimization Meets JKO Scheme", "authors": "Mikhail Persiianov,Jiawei Chen,Petr Mokrov,Alexander Tyurin,Evgeny Burnaev,Alexander Korotin", "background": "种群动力学的学习涉及从给定的离散时间点的样本演化快照中恢复支配颗粒演化的底层过程。近期的方法将此问题建模为概率空间中的能量最小化问题，并利用JEKO方案进行高效的时间离散化。", "innovation": "本文提出了一种称为$\texttt{iJKOnet}$的方法，该方法结合了JEKO框架和逆优化技术来学习种群动力学。这种方法依赖于一种标准的端到端对抗训练程序，并不需要如输入凸神经网络等严格的架构选择。作者还为他们的方法提供了理论保证，并展示了相较于先前的基于JEKO的方法，具有更好的性能", "conclusion": "本文通过引入$\texttt{iJKOnet}$方法，结合JEKO框架和逆优化技术来学习种群动力学，证明了其在性能上的改进，并为该方法提供了理论依据。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24149", "html_url": "https://arxiv.org/abs/2505.24149", "title": "RCCDA: 在受限资源预算下存在概念漂移时的自适应模型更新", "title_en": "RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget", "authors": "Adam Piaseczny,Md Kamran Chowdhury Shisher,Shiqiang Wang,Christopher G. Brinton", "background": "在现实世界环境中部署的机器学习（ML）算法往往面临着如何适应概念漂移的挑战，即随时间任务数据分布发生变化的情况。当模型性能必须在严格资源限制下保持时，这一问题变得更加困难。现有的解决方案往往依赖于检测漂移的方法，这些方法在资源受限环境中会产生高额的计算开销，且无法提供严格保证的资源使用量或理论性能的保障。", "innovation": "为了缓解这些不足之处，我们提出了RCCDA：一种在过去的损失信息和可调节的漂移阈值下仅利用模型更新策略使ML训练动态优化，同时确保与预定义资源约束的政策。我们的策略通过分析任意训练更新决策下模型损失的演变，将这些结果整合到Lyaupov漂移加惩罚框架中，生成一个轻量级且可证明限制更新频率和成本的贪婪最优策略。实验结果表明，在面临不同漂移周期的条件下，我们的策略在严格资源限制下提高了推理准确性，使其特别适用于实时ML部署。", "conclusion": "实验结果表明，我们的策略在多领域的泛化数据集上表现出色，在严格资源限制下确保预测准确性，具备实时ML部署的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21005", "html_url": "https://arxiv.org/abs/2505.21005", "title": "通过方差调节扩散模型高效且无偏抽样博尔兹曼分布", "title_en": "Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models", "authors": "Fengzhe Zhang,Laurence I. Midgley,José Miguel Hernández-Lobato", "background": "Score-based扩散模型（SBDMs）是强大的近似抽样器，适用于博尔兹曼分布；然而，不完美的分数估计会偏斜下游的蒙特卡洛估计。经典的重要性抽样（IS）可以纠正这种偏差，但计算精确似然性要求解概率流常微分方程（PF-ODE），这一过程代价高昂且在维度增加时表现不佳。", "innovation": "论文引入了一种名为方差调协扩散重要性抽样（VT-DIS）的轻量级后训练方法，通过最小化预训练SBDM的前向扩散和逆去噪轨迹之间的α-散度（α=2），自适应每步的噪声协方差。VT-DIS为联合前向-逆过程赋予单一轨迹相关的权重，测试时提供无偏的期望估计，且相较于标准采样几乎无额外开销。在DW-4、LJ-13和丙氨酸二肽基准测试中，VT-DIS分别实现了约80%、35%和3.5%的有效样本规模，同时仅需传统扩散+重要性抽样或基于PF-ODE的重要性抽样的少量计算预算。", "conclusion": "VT-DIS在保持用于博尔兹曼分布的高效无偏抽样的同时，显著降低了计算成本。这种方法证明了具体应用中提高采样效率和质量的潜力。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03777", "html_url": "https://arxiv.org/abs/2506.03777", "title": "FedFACT：联邦学习中可调控组公平校准的证明框架", "title_en": "FedFACT: A Provable Framework for Controllable Group-Fairness Calibration in Federated Learning", "authors": "Li Zhang,Zhongxuan Han,Xiaohua Feng,Jiaming Zhang,Yuyuan Li,Chaochao Chen", "background": "随着联邦学习（FL）在决策场景中的应用逐渐增加，调节模型公平性以防止敏感群体（如性别）之间的差异变得至关重要。当前研究主要集中在联邦学习中的两类群体公平性概念：全局公平性（整体模型在所有客户端的不平等表现）和局部公平性（每个客户端内的不平等表现）。然而，公平性标准的非分解性和非可微性特质提出了两个基本且未解决的问题：（i）在多分类设置中协调全局和局部公平性；（ii）实现控制下的最优准确度-公平性权衡。", "innovation": "提出了一种新颖的可调控联邦群体公平校准框架，名为FedFACT。FedFACT在全局和局部公平性约束下识别出贝叶斯最优分类器，同时在保证公平性的前提下，尽量减少性能下降。在此基础上，我们将公平联邦学习重新定义为内处理中的个性化成本敏感学习问题和输出处理中的多级优化，并提供了FedFACT在给定公平性水平下的接近最优准确性的收敛性和泛化保证。", "conclusion": "在多个数据集上的广泛实验表明，FedFACT在平衡准确性和全局-局部公平性方面始终优于基线。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05345", "html_url": "https://arxiv.org/abs/2506.05345", "title": "基于KV缓存压缩的推理时超比例缩放", "title_en": "Inference-Time Hyper-Scaling with KV Cache Compression", "authors": "Adrian Łańcucki,Konrad Staniszewski,Piotr Nawrot,Edoardo M. Ponti", "background": "在推理阶段，通过生成更长或更并行的序列可以权衡效率和提升推理准确性，但Transformer大规模语言模型（LLM）中的生成成本主要受限于键值（KV）缓存的大小，而不是生成的令牌数量。因此，研究如何通过压缩KV缓存来提升在相同计算预算内的生成令牌数量，并进一步提高缩放推理的准确性。\n", "innovation": "介绍了一种名为Dynamic Memory Sparsification (DMS)的新方法，它可以在训练步骤很少的情况下（1K步）实现8倍的压缩，并且在保持准确性的同时优于无训练的稀疏注意机制。DMS能够延迟令牌的清除，隐式地合并表示信息，保留关键信息。\n", "conclusion": "通过DMS实现的推理时超比例缩放可以提升多个LLM模型的准确性，而只需与记忆读取次数相当的推理延迟和内存负载。例如，Qwen-R1 32B在AIME 24、GPQA和LiveCodeBench上的平均得分分别提高了12.0点、8.6点和9.7点。\n"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06265", "html_url": "https://arxiv.org/abs/2504.06265", "title": "大型语言模型作为经过不确定性校准的优化器用于实验发现", "title_en": "Large language models as uncertainty-calibrated optimizers for experimental discovery", "authors": "Bojana Ranković,Ryan-Rhys Griffiths,Philippe Schwaller", "background": "科学研究越来越依赖高效的实验优化以在时间与资源限制下探索广泛的设计空间。传统的优化方法通常需要大量的领域专业知识和特征工程。虽然大型语言模型拥有广泛的科学知识可以克服特征工程的局限，但它们缺乏关键决策中所需的比例不确定性估计。因此，当前的优化方法必须在专业知识与可靠性之间做出选择，缺乏既能提供两者的方法。", "innovation": "本文展示了通过使用传统的优化方法中的不确定性感知目标对语言模型进行训练，能够使它们成为在自然语言指导下可靠的优化器。通过在不确定性条件下从实验结果中教授LLMs，将它们的过度自信转变为一种精确的校准机制。本文方法在50次实验迭代中大幅提高了Buchwald-Hartwig反应中高产反应条件的发现率，从24%提升到了43%。在涉及有机合成、材料科学、催化化学、过程化学和分子设计的19个不同优化问题中，本文方法在平均成绩上得分最高，确立了一种通过LLMs实现可靠且基于不确定性的优化的新范式。这种方法可以通过降低使用强大优化方法的门槛，用更易于获取的自然语言接口取代领域特定的特征工程，来加速发现过程。", "conclusion": "本文的研究表明，确保通过原理性的不确定度量化来实现可靠性对于利用AI指导的实验潜在价值至关重要。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09714", "html_url": "https://arxiv.org/abs/2506.09714", "title": "Auto-Compressing Networks", "title_en": "Auto-Compressing Networks", "authors": "Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos", "background": "深度神经网络通过短残差连接在多种领域中取得了显著的成功，但增加网络深度往往会导致计算冗余，而代表性质量却没有相应的提升。", "innovation": "该研究引入了自动压缩网络（Auto-Compressing Networks, ACNs），其特点是通过每一层到输出的加性长前馈连接替代传统的短残差连接。ACNs揭示了一种称为自动压缩的独特特性，即网络在训练过程中仅通过架构设计即可有机地压缩信息，尤其是在梯度下降的过程中。研究发现，由于ACNs在每层训练模式中的动态使用，ACNs的信息在训练过程中动态地“推”入早期层，从而增强其表征质量，同时揭示深层网络的冗余信息。此外，ACNs在低数据环境下的性能更优，具有更好的传输学习能力和减轻灾难性遗忘的效果，表明它们能使用更少的参数学习更通用的表示。", "conclusion": "研究表明，ACNs在视觉变换器、MLP-Mixer以及BERT架构下可将灾难性遗忘减少高达18%，并实现高达80%的架构压缩，同时保持准确性，证明ACNs是一种基于任务复杂性自适应其计算足迹并学习适用于噪声环境和持续学习场景的鲁棒表示的有效方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10751", "html_url": "https://arxiv.org/abs/2506.10751", "title": "Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering", "title_en": "Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering", "authors": "Sai Prasanna Teja Reddy Bogireddy,Abrar Majeedi,Viswanatha Reddy Gajjala,Zhuoyan Xu,Siddhant Rai,Vaishnav Potlapalli", "background": "电子健康记录（EHRs）中的自动化问答（QA）可以填补临床医生和患者的重要信息缺口，但这也需要在有限的监督下进行精确的证据检索和忠实的答案生成。这项工作的背景是介绍了一种名为Neural的方法，该方法在BioNLP 2025 ArchEHR-QA共享任务中表现优异，但未能获得第一名。", "innovation": "该方法将任务分拆为两个阶段：1）句子级别证据识别；2）带有明确引用的答案合成。通过自动探索提示空间并与DSPy的MIPROv2优化器结合使用，共同调整指令和少量示例。此外，还提出了一种自我一致性投票方案以提高证据覆盖率，但不会牺牲精度。", "conclusion": "在隐藏测试集上，该方法获得了整体评分为51.5的第二名成绩，分别比标准的零样本和少量样本提示提高了超过20和10分。这表明基于数据的提示优化对于高风险医疗QA来说是一个成本效益高的替代模型微调的方法，从而提高了医疗保健中AI助手的可靠性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16736", "html_url": "https://arxiv.org/abs/2506.16736", "title": "无需正则化：零和游戏中无界遗憾", "title_en": "Optimism Without Regularization: Constant Regret in Zero-Sum Games", "authors": "John Lazarsfeld,Georgios Piliouras,Ryann Sim,Stratis Skoulakis", "background": "本文研究了学习在两人零和博弈中的乐观版本的想象力播放（Fictitious Play）策略。尽管已经知道带有有界步长参数的正则化算法（如Optimistic FTRL）可以在这种设置下获得恒定遗憾，但本文首次证明在不使用正则化的情况下也能达到类似的、最优的遗憾率。", "innovation": "文章提出了无需正则化的乐观想象力播放（Optimistic Fictitious Play）算法可以在两人两策略的零和博弈中获得恒定遗憾，这为非正则化算法在博弈中实现快速学习提供了新的证据。此外，还证明了交替想象力播放（Alternating Fictitious Play）在无正则化状态下无法获得次线性遗憾，并且提供了一定的能量函数证明方法。", "conclusion": "在无需正则化的情况下，乐观和交替发现方法在实现次线性遗憾方面的区别变得更加明显。本文通过几何视角在收益向量的对偶空间中得到的新证据进一步表明，非正则化算法在博弈中的学习速度更快。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21158", "html_url": "https://arxiv.org/abs/2506.21158", "title": "在新药设计中基于强化学习的多样化.mini批选择以实现高效的化学探索", "title_en": "Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design", "authors": "Hampus Gummesson Svensson,Ola Engkvist,Jon Paul Janet,Christian Tyrchan,Morteza Haghir Chehreghani", "background": "在许多实际应用中，评估实例的质量既耗时又昂贵，例如人类反馈和物理模拟，相比之下，提出新实例要容易得多。特别是在强化学习中，它依赖于与环境（即新实例）的互动，这些互动必须被评估以提供用于学习的奖励信号。同时，进行足够的探索对强化学习至关重要，以找到高价值的解决方案，这意味着代理应该观察和学习一组多样的经验，以找到不同的解决方案。", "innovation": "本文介绍了一种用于强化学习的多样化.mini批选择框架，并在这个框架下研究了药发现这一实际问题。通过实验，证明了所提出的多样化.mini批选择框架可以显著增强新药设计中解决方案的多样性，同时保持高质量的解决方案。", "conclusion": "在药发现中，这种结果有可能更快地满足未满足的医疗需求。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05583", "html_url": "https://arxiv.org/abs/2506.05583", "title": "适应未知亚人群转移的公因子预测", "title_en": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "authors": "Nien-Shao Wang,Duygu Nur Yaldiz,Yavuz Faruk Bakman,Sai Praneeth Karimireddy", "background": "公因子预测通过为黑盒机器学习模型提供不确定性量化，广泛应用于数据交换可性条件下提供正式的覆盖保证。然而，在亚人群转移的情况下，这些保证失效。在测试环境中，亚人群的组合与校准数据不同。本文聚焦于未知的亚人群转移情况，即没有被给出各组信息，因此数据点的具体亚人群标签需要被推断。", "innovation": "本文提出了新的方法，可以证明地将公因子预测应用到亚人群转移的情况，确保有效的覆盖而无需明确知道亚人群结构。现有方法在类似设定中假设亚人群标签完全准确，而本文框架明确放松了这一要求，并界定了在这种情况下提供正式覆盖保证的条件。此外，我们的算法适用于高维设置，在实际机器学习任务中仍然可行。", "conclusion": "广泛的视觉（使用视觉变换器）和语言（使用大型语言模型）基准实验展示，我们的方法在标准公因子预测失败的情景中，能够可靠地保持覆盖并有效地控制风险。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22331", "html_url": "https://arxiv.org/abs/2506.22331", "title": "Less Greedy Equivalence Search", "title_en": "Less Greedy Equivalence Search", "authors": "Adiba Ejaz,Elias Bareinboim", "background": "Greedy Equivalence Search (GES) 是一种经典的数据驱动算法，用于从观测数据中发现因果关系。在样本极限下，它能够恢复描述数据的马尔可夫等价类图。然而，实践中它面临两大挑战：计算成本和有限样本准确性。", "innovation": "本文开发了 Less Greedy Equivalence Search (LGES)，它是 GES 的一种变体，保留了其理论保证，同时部分解决这些限制。LGES 改变了贪婪步骤，避免在分数暗示条件独立的变量之间进行边插入，这种更有针对性的搜索相比 GES 提高了速度多达 10 倍，并显著减少了结构错误。此外，LGES 可以利用先验知识进行搜索，并在数据抵触时纠正这些知识。最后，LGES 可以使用干预数据来细化已学习的观测等价类。", "conclusion": "研究证明，即使在先验知识有误的情况下，LGES 在样本极限下也能恢复正确的等价类。实验结果表明 LGES 在速度、准确性和对误判先验知识的鲁棒性方面优于 GES 和其他基准方法。我们的代码可在以下链接获取：[此处提供链接]。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03279", "html_url": "https://arxiv.org/abs/2507.03279", "title": "格区分形式化信息探索，用于引导大型语言模型进行交互", "title_en": "Conformal Information Pursuit for Interactively Guiding Large Language Models", "authors": "Kwan Ho Ryan Chan,Yuyan Ge,Edgar Dobriban,Hamed Hassani,René Vidal", "background": "大型语言模型（LLMs）在交互式问题解答中具有重要应用。与传统的一次性对话不同，这类模型需要顺序查询用户以完成预测。现有的信息追求（IP）策略通常通过最大化信息增益或最小化不确定性来选择查询，但实践中准确估计互信息或条件熵很困难，这会导致选择不准确的查询和较差的预测性能。因此，需要一种更可靠的方法来估计迭代过程中的不确定性以改进这类应用。", "innovation": "提出了格区分形式化信息探索（C-IP），这是一种基于形式化预测集的序列信息增益的新方法。C-IP 利用每一次迭代中预测集和条件熵之间的关系，基于形式化预测集的平均大小来估计不确定性。这种方法避免了条件熵的局限性，表现出对不确定性的无分布依赖且稳健的度量方法。实验结果表明，C-IP 相较于之前的 IP 方法和基于链式思考的不确定性方法，在“20个问题”的场景中具有更好的预测性能和更短的查询-回答链，同时在医学互动场景中也表现出与直接一次性预测相当的竞争力，并提供更好的可解释性。", "conclusion": "C-IP 可以有效改善大型语言模型在交互式问题解答场景中的预测性能和用户可解释性，尤其在医学领域的应用中表现出良好的性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05210", "html_url": "https://arxiv.org/abs/2508.05210", "title": "高级LSTM变换器TS混合器注意力技术用于钻井进尺率预测", "title_en": "Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction", "authors": "Saddam Hussain Khan(Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "钻井优化中进尺率（ROP）预测至关重要，但由于钻井数据的非线性和动态特性，现有的预测模型仍面临挑战。传统的经验、物理和标准机器学习模型依赖于简化假设或密集的手工特征工程，限制了它们对长期依赖性和复杂特征交互的建模能力。为了解决这些问题，本文提出了一种新的深度学习混合框架，结合了LSTM、变换器、时间序列混合器和注意力机制，旨在捕获与钻井周期对齐的多尺度时间依赖性，更好地处理钻井数据的特点。", "innovation": "该研究提出了一个创新的混合LSTM-变换器-时间序列混合器-注意力机制框架，首先通过定制的LSTM网络处理输入数据，捕捉与钻井周期对齐的多尺度时间依赖性。接着，通过改进的具有钻井特定位置编码的变换器编码器和实时优化，进一步提炼特征。同时，引入了并行时间序列混合器（TS-Mixer）模块，高效建模静态和类别参数间的特征交叉交互。最后，通过自适应注意力机制动态分配上下文权重，增强特征表示学习，实现高保真度的ROP预测。该框架综合了序列记忆、静态特征交互、全局上下文学习和动态特征加权，提供了一个适合钻井动态特性的全面解决方案。", "conclusion": "实验结果在真实钻井数据集上验证了该方法的优越性能，Rsquare达到了0.9991，MAPE为1.447%，显著优于现有基准和混合模型。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18312", "html_url": "https://arxiv.org/abs/2508.18312", "title": "DPO数据中哪些因素重要？", "title_en": "What Matters in Data for DPO?", "authors": "Yu Pan,Zhongze Cai,Guanting Chen,Huaiyang Zhong,Chonghuan Wang", "background": "直接偏好优化(DPO)作为一种简单且有效的大型语言模型(LLM)与人类偏好对齐方法，被广泛采用，但其性能依赖于什么类型的偏好数据却仍是一个未解之谜。这项研究通过对DPO性能影响因素进行系统分析，从理论和经验两个角度探讨偏好数据分布对DPO的影响，揭示了获得更好性能的关键所在和机制。", "innovation": "1. 通过理论分析，确定了最优响应分布下DPO的目标并揭示了响应对比性如何改善选择样本的效果。\n2. 证明了在线DPO可简化为针对选择响应的有监督微调。\n3. 通过多样化的实验验证结果，显示提升选择响应的质量可以持续提升性能，而拒选响应的质量影响较小。\n4. 探索了策略混合的应用，为构建高效的人类偏好数据集提供了实践指导。", "conclusion": "提升选择响应的质量是提高DPO性能的关键因素，而拒选响应的质量影响较小。研究提供了通过优化响应选择过程来提高LLM对齐的有效策略，并对构建高性能偏好数据集给出了实用建议。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Renée Rosillo", "background": "该论文介绍了TimeCopilot，这是一个首次公开的代理框架，能够结合多种时间序列基础模型(TSFMs)与大规模语言模型(LLMs)，通过单一统一的API实现。此框架自动化了预测管道，包括特征分析、模型选择、交叉验证和预测生成，并提供自然语言解释和直接查询未来功能。该系统具有LLM不可知论性，兼容商业和开源模型，并支持不同预测家族之间的集成。", "innovation": "TimeCopilot是首个将时间序列基础模型与大规模语言模型结合的开放源代码代理框架。它通过一个统一的API自动化预测流程，包括特征分析、模型选择、交叉验证和预测生成。此外，它还提供了自然语言解释并支持直接查询未来。该框架支持多种商业和开源模型，并可实现多种预测模型的集成。基准测试表明，TimeCopilot在大型GIFT-Eval基准测试中实现了最先进的概率预测性能，成本低。", "conclusion": "该研究为可再现、可解释和易获取的代理预测系统奠定了实用基础，通过自动化的预测流程、强大的语言解释功能和广泛的模型兼容性提供了先进的预测性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12994", "html_url": "https://arxiv.org/abs/2506.12994", "title": "Differentially Private Bilevel Optimization: Efficient Algorithms with Near-Optimal Rates", "title_en": "Differentially Private Bilevel Optimization: Efficient Algorithms with Near-Optimal Rates", "authors": "Andrew Lowy,Daogao Liu", "background": " bilevel optimization,作为一种多层级结构的机器学习应用基础，广泛应用于元学习和超参数优化中。这些应用往往涉及到敏感的训练数据，从而引发了对个体隐私的担忧。因此，研究人员开始探索在差分隐私保护下的 bilevel 优化方法。论文首先假设外部目标函数是凸的，并提供了纯和近似差分隐私下的上界和下界。此外，对于非凸情况，提出了具有领先结果的算法来找到近似最优点，且这些结果不依赖于内部问题的维度。", "innovation": "提出了在差分隐私保护下的 bilevel 优化方法。对于凸外部目标函数的情况，提供了上下界的最优近似结果，即使考虑到嵌套层级结构的固有复杂性。在非凸情况，开发了新的算法，实现算法在多项式时间内的有效实现，并提供了近最优的率。特别地，这些算法的结果不依赖于内部问题的维度。由于不完善的函数评估，还开发了一种新的对数凹取样方法及其分析，该方法具有独立的研究价值。", "conclusion": "本文为差分隐私保护下的 bilevel 优化问题提供了有效算法。在凸环境下，提供了最优近似的结果。在非凸环境下，提出了领先的率来找到近似最优点。而且，提出的对数凹取样方法在不完美函数评估下的应用表明了其研究价值。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16471", "html_url": "https://arxiv.org/abs/2506.16471", "title": "渐进推理时退火的扩散模型采样方法用于玻尔兹曼密度采样", "title_en": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities", "authors": "Tara Akhound-Sadegh,Jungyoon Lee,Avishek Joey Bose,Valentin De Bortoli,Arnaud Doucet,Michael M. Bronstein,Dominique Beaini,Siamak Ravanbakhsh,Kirill Neklyudov,Alexander Tong", "background": "从目标无归一化概率密度中高效采样仍然是一个关键挑战，涉及到众多高影响力的科学应用。现有的扩散机制采样器招募了生成性扩散模型中的核心思想，如概率路径设计，但依然无法在简单的分子系统层面进行采样。为解决这一问题，本文提出了渐进推理时退火（PITA）框架，这一框架结合了两种互补的插值技术，用于学习基于扩散的采样器。", "innovation": "PITA框架通过结合玻尔兹曼分布退火和扩散平滑技术，提出了一种创新的方法。它通过顺序训练一系列从高温度到低温度的扩散模型，并利用工程设计的温度退火目标密度样本快捷访问，从而使得Diffusion模型能够更有效、更可靠地进行采样。此外，PITA通过一种新颖的费米-卡克偏微方程与序列蒙特卡洛结合，在推理时退火中模拟已训练的扩散模型，以获取下一模型所需的低温采样。这一方法实现了对N体粒子系统、α-丙氨酸二肽和三肽在笛卡尔坐标下的初步等温采样，显著减少了能量函数评估的次数。", "conclusion": "PITA框架能够实现分子系统级别的采样，为扩散模型应用于复杂系统提供了新的可能性。未来的研究可以进一步探索PITA在更多类型系统中的应用，并优化训练过程中的参数设置。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05636", "html_url": "https://arxiv.org/abs/2507.05636", "title": "图学习", "title_en": "Graph Learning", "authors": "Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong", "background": "图学习已经迅速成为机器学习和人工智能（AI）领域的一个关键子领域。其发展始于早期的图理论方法，随着图神经网络（GNNs）的出现，取得了显著进展。在过去的十年中，架构的可扩展性、动态图建模、多模态学习、生成型AI、可解释AI（XAI）和负责任AI的进步，使图学习的应用范围扩展到各种具有挑战性的环境中。图学习因其能够建模复杂、非欧几里得关系而重要，这些关系传统机器学习难以捕捉，从而更好地支持药物发现、欺诈检测、推荐系统和科学推理等各种实际应用。然而，可扩展性、泛化、异质性、可解释性和可靠性等问题必须解决，才能充分发挥其潜力。", "innovation": "本文提供了一篇全面介绍图学习的综述，重点介绍了包括可扩展、时间序列、多模态、生成、可解释和负责任图学习的关键维度。综述了高效处理大规模图、捕捉动态时间依赖关系、集成异构数据模态、生成新图样本和增强可解释性的最新技术，以提高信任和透明度。此外，还探讨了隐私和公平性等伦理问题，确保图学习模型的负责任部署。最后，指出了新兴主题，强调了图学习与其他AI范式的最新整合，并提供了对未来方向的见解。", "conclusion": "本文综述为寻求在快速发展的图学习领域导航的研究人员和实践者提供了一项宝贵的资源。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20088", "html_url": "https://arxiv.org/abs/2507.20088", "title": "通过固定点薛定谔型激活学习隐含图几何：一个理论研究", "title_en": "Learning Latent Graph Geometry via Fixed-Point Schrödinger-Type Activation: A Theoretical Study", "authors": "Dmitry Pasechnyuk-Vilensky,Martin Takáč", "background": "本文发展了一种统一的理论框架，用于描述内部表征随时间演变的神经架构，这些表征是学得的潜在图上耗散薛定谔型动力学的稳态。每层由固定点薛定谔型方程定义，该方程依赖于编码潜在几何的加权Laplacian和凸局部势，对于动力学的存在性、唯一性和光滑性进行了证明，并表明在Bloch映射下动力学等效于范数保持的Landau-Lifshitz流动。图权重和拓扑的训练被表述为装备了自然Kähler-Hessian度量的分层模空间上的随机优化，确保了收敛性和跨层的不同可微性。", "innovation": "该研究通过以下创新点新颖：开发了一种新的统一理论框架，通过固定点薛定谔型激活学习隐含图几何；证明了动力学的存在性、唯一性和光滑性；将图权重和拓扑的训练表述为随机优化，确保了收敛性和跨层的不同可微性；推导出了泛化界，表明稀疏性和几何正则性控制着容量；证明了前馈层的组成相当于单一全局稳态扩散；后向传播表示为其伴随稳态系统；并提出了有向和向量值扩展的统一表示。", "conclusion": "通过固定点薛定谔型激活，构成的模型提供了学习隐含图几何的一个紧凑、几何上有解释性的、并且具有解析处理能力的基础。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16447", "html_url": "https://arxiv.org/abs/2508.16447", "title": "Boardwalk: 向基于大语言模型创建桌面游戏的框架迈出一步", "title_en": "Boardwalk: Towards a Framework for Creating Board Games with LLMs", "authors": "Álvaro Guglielmin Becker,Gabriel Bauer de Oliveira,Lana Bertoldo Rossato,Anderson Rocha Tavares", "background": "实现桌面游戏的代码通常是一个耗费时间的任务。然而，大型语言模型（LLMs）已经证明能在简单的上下文中生成特定领域任务的代码，效果显著。", "innovation": "该研究旨在探索是否可以使用LLMs从自然语言描述的游戏规则生成桌面游戏的数字版本。这项工作是朝着利用LLMs辅助框架快速生成桌面游戏代码方向迈出的一步。研究人员使用三个最新的LLMs（Claude、DeepSeek和ChatGPT）来实现12个热门和不那么知名的游戏，并在Boardwalk提供的通用游戏编程API中进行实现。研究通过确保游戏和组件匿名化避免了预先训练的LLM知识的影响。然后测试这些实现的游戏的可玩性和规则一致性。", "conclusion": "该方法的有效性得到了证明，最佳的Claude 3.7 Sonnet模型没有错误的生成了55.6%的游戏实现。尽管API的一致性增加了错误频率，但错误的严重程度主要取决于LLM。该研究指出了创建一个框架以整合这一过程的未来步骤，使得游戏的定义更加容易。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19215", "html_url": "https://arxiv.org/abs/2509.19215", "title": "PPG-Distill: 通过基础模型蒸馏实现高效的光体积描记图信号分析", "title_en": "PPG-Distill: Efficient Photoplethysmography Signals Analysis via Foundation Model Distillation", "authors": "Juntong Ni,Saurabh Kataria,Shengpu Tang,Carl Yang,Xiao Hu,Wei Jin", "background": "光体积描记图（PPG）监测在可穿戴健康监测中得到广泛应用，但现有的PPG基础模型由于资源限制难以部署在资源受限的设备上。", "innovation": "PPG-Distill提出了一种知识蒸馏框架，通过预测、特征和块层面的蒸馏，转移全局和局部知识。PPG-Distill结合了形态学蒸馏来保留局部波形模式，并通过节奏蒸馏捕捉块间的时序结构。该方法在心率估计和房颤检测上的学生模型性能提升了21.8%，同时实现了7倍的推理速度，减少了19倍的内存使用，从而实现了可穿戴设备上的高效PPG分析。", "conclusion": "PPG-Distill在保持性能的同时提升了推理速度和资源效率，为在资源有限的设备上实现高效的PPG分析提供了新的解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03505", "html_url": "https://arxiv.org/abs/2509.03505", "title": "LimiX：释放通用智能的结构化数据建模能力", "title_en": "LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence", "authors": "Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui", "background": "本文认为，通向通用人工智能的进展需要语言、物理世界和结构化数据等多种基础模型来支撑。文中介绍了两个模型实例，LimiX-16M和LimiX-2M，它们是大模型结构数据（LDM）的实例。这些模型通过单一模型进行查询条件预测，处理变量和缺失性，适用于广泛的表格任务。", "innovation": "本文提出了一种新的预训练方法，使用遮盖式联合分布建模和基于上下文的序列目标，支持快速的推理强化学习。此外，LimiX-2M模型展示了在严格计算和内存限制下的强大性能。作者还首次研究了LDM的扩展律，指出了数据和模型扩展如何共同影响下游性能。", "conclusion": "LimiX模型在11个大型结构化数据基准测试中表现出色，涵盖了广泛的样本大小、特征维度、类别数量、分类数据与数值特征的比例、缺失值和样本到特征比率。LimiX-16M模型持续超越强大的基线模型，尤其在分类、回归、缺失值填充和数据生成任务中表现出明显的优越性，避免了特定任务的架构和专项训练。LimiX-2M模型在有限资源下表现同样出色。所有LimiX模型均开源，使用Apache 2.0许可。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18116", "html_url": "https://arxiv.org/abs/2509.18116", "title": "Amortized Latent Steering: 低成本的测试时间优化替代方案", "title_en": "Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization", "authors": "Nathan Egbuna,Saatvik Gaur,Sunishchal Dev,Ashwinee Panda,Maheep Chaudhary", "background": "当前规模下，测试时优化由于推理成本高昂而难以实现。迭代细化和多步验证等技术每项查询需要比标准解码多10到100倍的计算量。虽然潜空间测试时优化方法如LatentSeek通过引导隐藏表示提供了直接的方法，但仍需要昂贵的每查询优化循环，涉及多次反向传播。在GSM8K和MATH-500基准测试中，迭代方法与贪婪链式思考(CoT)和自我一致性基准相比，实现了2到5倍的加速，同时维持或超越了效率-准确率的平衡。", "innovation": "我们提出了Amortized Latent Steering (ALS)，将迭代优化过程简化为一个在推理时成本恒定的单次离线计算向量。ALS通过计算成功和不成功生成之间的隐藏状态平均差异来确定方向，并据此调整模型的隐藏表示：当解码偏离成功流形时，ALS引导激活重新转向成功流形的方向。这种方法在GSM8K和MATH-500基准测试中，相较于迭代方法提供了2到5倍的加速，同时匹配或超越了贪婪链式思考(CoT)和自我一致性基准，效率-准确率平衡获得101%的提升。", "conclusion": "这些结果表明，许多潜优化的好处可以在离线过程中捕获，使得复杂的推理技术可用于生产部署。ALS提供了一种低成本的测试时间优化替代方案，使得这些高级推理技术在实际应用中可行。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13100", "html_url": "https://arxiv.org/abs/2508.13100", "title": "完全真实的校准度度量指标", "title_en": "A Perfectly Truthful Calibration Measure", "authors": "Jason Hartline,Lunjia Hu,Yifan Wu", "background": "校准要求预测具有条件无偏性，使其可靠地解释为概率。校准度量评估预测与完美校准的偏差。Haghtalab等人（2024）和Qiao及Zhao（2025）提出了序贯预测中的近似真实校准度量，但仍未发现适用于基本批量设置的完全真实校准度量。现有的真实校准度量在随机样本评估校准时，会导致预测器倾向于撒谎以显得更校准，这揭示了校准度量的缺乏真实性问题。", "innovation": "本文设计了一种简单、完全和严格真实、可靠且完全的主要校准度量指标ATB。ATB与两个现有校准度量smCal和distCal有二次关系，使得计算简单且高效，提供了第一个线性时间校准测试算法。还提供了一种通用方法，基于独立随机变量方差可加性构造真实度量，并证明了ATB的真实性，还构建了如概率分箱l_2-ECE等其他真实校准度量。", "conclusion": "本文提出了在批量设置下的一种完全真实、严格真实、可靠且完全的校准度量指标ATB，其计算简单且高效，首次给出了线性时间校准测试算法。还提供了一种通用方法，基于独立随机变量方差可加性构造真实度量，并构建了一系列真实校准度量。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09048", "html_url": "https://arxiv.org/abs/2510.09048", "title": "利用真实多模态数据集成的空间时间图卷积网络进行电动汽车充电需求预测", "title_en": "Spatio-Temporal Graph Convolutional Networks for EV Charging Demand Forecasting Using Real-World Multi-Modal Data Integration", "authors": "Jose Tupayachi,Mustafa C. Camur,Kevin Heaslip,Xueping Li", "background": "交通运输是温室气体排放的重要来源，推动向可持续替代方案（如电动汽车）转型迫在眉睫。然而，充电基础设施在空间上的不均衡分布及使用上的不规则性给电力网络稳定性和投资规划带来了挑战。本研究旨在解决上述问题。", "innovation": "提出了一种结合图卷积网络与时间架构的空间时间预测框架TW-GCN，用于预测美国田纳西州的电动汽车充电需求。该框架通过整合道路流量、天气状况和美国最大的电动汽车基础设施公司提供的专属数据，捕捉空间依赖性和时间动态性。", "conclusion": "实验结果表明，中期（3小时）预测在响应性和稳定性之间取得了最佳平衡，1DCNN在时间模型中表现最优。区域分析揭示了东西部和中部田纳西州预测准确性的差异，反映了站台密度、人口和地区需求波动对模型性能的影响。该提出的TW-GCN框架推动了数据驱动智能化在电动汽车基础设施规划中的应用，支持可持续交通转换和电网管理的韧性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14926", "html_url": "https://arxiv.org/abs/2508.14926", "title": "具备伦理意识的安全强化学习在交互式城市驾驶中对罕见事件风险控制", "title_en": "Ethics-Aware Safe Reinforcement Learning for Rare-Event Risk Control in Interactive Urban Driving", "authors": "Dianzhao Li,Ostap Okhrin", "background": "自动驾驶车辆有望降低交通死亡事故率并提高交通效率，但其大规模采用依赖于将可信且透明的伦理推理嵌入常规及应急操作中，特别是保护行人和自行车等弱势道路使用者(VRU)。本文基于此背景，提出了一个分层次的安全强化学习(Safe RL)框架，该框架将伦理意识的成本信号补充到标准的驾驶目标中。文章描述了一种在决策层和执行层如何实现这一目标的方法，以确保在处理与VRU相关的风险时可以生成安全且舒适的行驶轨迹。", "innovation": "本文创新地提出了一个伦理意识增强的安全强化学习框架。该框架在决策层面利用一个综合碰撞概率和伤害严重性的伦理风险成本来生成高级运动目标，并通过动态、风险感知的经验优先回放机制放大对罕见但致命的高风险事件的学习。此外，在执行层面，结合多项式路径规划和PID及Stanley控制器将高级运动目标转换为平滑且可行的轨迹路径，从而确保驾驶准确性和舒适性。研究结果表明，该方法在减少对他人风险的同时保持了自我性能和舒适度，并在两个交互基准和五个随机种子下实现了与匹配任务成功的冲突频率减少了25-45%，而舒适度指标的变化没有超过5%。", "conclusion": "本文提供了一个可重复的基准，用于在混合了人类驾驶者的人工交通场景中实现具有伦理意识的安全强化学习。通过结合形式化控制理论和数据驱动学习，该研究突出了在城市交通环境中确保伦理问责制自主性的潜力，特别是对于最易受到风险的VRU。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03222", "html_url": "https://arxiv.org/abs/2510.03222", "title": "低概率标记维持强化学习中可用验证奖赏的探索", "title_en": "Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward", "authors": "Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 在复杂推理中推动了大型语言模型的发展，但其可扩展性常常受到训练瓶颈的阻碍，即性能停滞不前，表明探索的丧失。以往方法通常通过维持高策略信息度熵来应对这一问题，然而尚未深入探讨能够促进有意义探索的具体机制。分析表明，对熵的无选择性关注可能会放大不相关标记并导致训练失稳。本研究分析了RLVR中的探索动态，发现一个关键问题：有价值的低概率探索标记被逐渐消除，我们称之为‘推理火花’。这些火花在预训练模型中很常见，但在RLVR过程中由于过度惩罚而被系统地淘汰，导致探索的退化。", "innovation": "作者引入了一种名为Low-probability Regularization（低概率正则化，Lp-Reg）的方法。Lp-Reg的核心机制是通过调节策略向一种启发式代理分布靠拢来确保正则化。这种代理是通过过滤掉假定的噪声标记并将剩余候选人的分布重新归一化而构建出来的。结果，获得的代理具有较少的噪声并且推理火花的概率被增强，从而为避免通过KL散度消除这些有价值的标记提供了一个软化的正则化目标。实验显示，Lp-Reg使策略性强化学习稳定，能够在3000个训练步骤和81,204个GPU小时的支持下持续扩展，而基线熵控制方法无法做到这一点。这种持续的探索推进了最先进的性能，确保了五个数学基准的平均准确率为60.17%，相比之前的方法提高了2.66%。", "conclusion": "Lp-Reg通过促进有价值的‘推理火花’不被消除，从而提高了探索稳定性，并确保了ALLM在大规模训练中的持续扩展能力，最终达到了最先进的性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26690", "html_url": "https://arxiv.org/abs/2510.26690", "title": "LoRAQuant: 混合精度的LoRA超低比特量化", "title_en": "LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits", "authors": "Amir Reza Mirzaei,Yuqiao Wen,Yanshuai Cao,Lili Mou", "background": "LoRA已成为大规模语言模型（LLMs）参数高效微调的一种流行技术。在实际应用中，多个适配器同时加载以实现个性化用户体验或支持多种任务。尽管每个适配器在独立情况下非常轻量，但它们的总成本在大规模应用中变得巨大。", "innovation": "提出了一种名为LoRAQuant的混合精度后训练量化方法，该方法针对LoRA进行了优化。该方法通过奇异值分解（SVD）重新参数化每个适配器，将最关键的信息集中在特定的行和列上。这样，可以对重要的组件进行高精度量化，而将剩余部分量化为极低位宽。", "conclusion": "在LLaMA 2-7B，LLaMA 2-13B和Mistral 7B模型上针对数学推理，编程和总结任务的全面实验表明，LoRAQuant使用的比特数远少于其他量化方法，但性能相当甚至更高。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10004", "html_url": "https://arxiv.org/abs/2510.10004", "title": "增强稳健EEG分类的双向时频金字塔网络", "title_en": "Bidirectional Time-Frequency Pyramid Network for Enhanced Robust EEG Classification", "authors": "Jiahui Hong,Siqing Li,Muqing Jian,Luming Yang", "background": "现有的EEG识别模型在跨范式泛化方面表现不佳，这主要归因于数据集特定的约束和个体差异。为了解决这些限制，本文提出了BITE（双向时频金字塔网络），这是一个端到端的一体化架构，能够实现鲁棒的多流协同、金字塔时间频率注意力（PTFA）以及双向自适应卷积。该框架的独特之处在于：1) 时频流与STFT保持时间同步，以实现双向建模；2) 基于PTFA的多尺度特征增强，放大关键神经模式；3) 双向时频卷积神经网络（BiTCN）结合可学习融合，捕捉正向/反向神经动态。", "innovation": "BITE架构结合了时频流同步、多尺度特征增强和双向卷积等技术，能够实现跨范式的鲁棒性增强。在四个不同的范式（BCICIV-2A/2B、HGD、SD-SSVEP）中，BITE达到了最先进的性能，并且在交叉个体泛化方面表现尤为突出。此外，BITE作为统一的架构，能够在MI任务和SSVEP任务上都实现稳健性能，同时具备出色的计算效率。", "conclusion": "研究表明，范式对齐的频谱-时间处理是可靠BCI系统的关键。BITE作为一种一体化架构，可以克服数据集特定约束和个体差异带来的问题，实现对多种EEG范式的良好适应性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.02043", "html_url": "https://arxiv.org/abs/2511.02043", "title": "Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants", "title_en": "Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants", "authors": "Bozhi You,Irene Wang,Zelal Su Mustafaoglu,Abhinav Jangda,Angélica Moreira,Roshan Dathathri,Divya Mahajan,Keshav Pingali", "background": "注意力是大型语言模型（LLMs）的一个基本构建块，因此已经有许多努力致力于高效实现注意力机制。例如，FlashAttention通过使用贴图和内核融合来优化注意力。最近，引入了许多注意力的变体以提升模型质量和效率，但它们的高效支持仍然困难，因为它们通常需要专门的内核或手动调优的实现。尽管FlexAttention通过使用静态编程模板支持了一部分FlashAttention风格的内核，但仍存在局限性。", "innovation": "本论文介绍了一种名为Flashlight的编译器框架，它位于PyTorch生态系统中，能够自动为任意基于注意力的程序生成融合、FlashAttention风格的内核，无需依赖静态模板或预定义内核专门化。Flashlight利用PyTorch的编译工作流程透明地融合和贴图注意力计算，支持所有FlexAttention可表达的注意力变体，并处理更通用的数据依赖注意力表示。", "conclusion": "我们的结果显示，Flashlight生成的内核在性能上与FlexAttention相当甚至优于后者，同时提供了与原生PyTorch代码相同的灵活性，使开发者能够快速探索新的注意力模型而不会影响性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.10227", "html_url": "https://arxiv.org/abs/2509.10227", "title": "一种可认证的基于机器学习的航空结构疲劳寿命预测管道", "title_en": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "authors": "Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio", "background": "在任何飞机的设计和运营阶段，疲劳寿命预测都是至关重要的，这对于航空航天行业的安全尤为重要，因为它需要早期检测疲劳裂纹以防止空中故障。传统的工程方法尽管可靠，但耗时且涉及复杂的流程，如进行多次有限元分析（FEM）、推导预期载荷谱，并应用周期计数技术，如顶谷或雨流计数。这些步骤通常需要跨多个团队和工具的协作，从而增加了计算时间和人力成本。机器学习（ML）为传统的疲劳寿命估算方法提供了潜在的补充，能够实现更快的迭代和泛化，提供快速估算以辅助决策，类似传统的模拟仿真。", "innovation": "本文介绍了一种基于机器学习（ML）的方法，旨在根据在飞机整个服役期内将执行的各种任务的不同飞行参数来预测不同飞机机翼位置的疲劳寿命。该模型在现实的疲劳寿命预测案例中进行了验证，提供了准确的预测，并进行了详细的统计验证和不确定性量化。该方法通过减少昂贵的模拟次数，降低了所需的计算和人力成本，成为了传统方法的有效补充，从而更好地保护飞机结构的安全性。", "conclusion": "本文通过建立一种基于机器学习的管道，实现了对航空结构疲劳寿命的快速预测。该模型在实际应用中表现出了准确性，并通过严格的统计验证和不确定性评估，证明了其的有效性。这种新的方法不仅提高了预测的速度，还大大减少了计算和人力资源的消耗，为航空行业提供了更高效、更安全的设计和运营方案。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01384", "html_url": "https://arxiv.org/abs/2510.01384", "title": "调优掩码扩散模型以实现可验证的自我纠正", "title_en": "Fine-Tuning Masked Diffusion for Provable Self-Correction", "authors": "Jaeyeon Kim,Seunggeun Kim,Taekyun Lee,David Z. Pan,Hyeji Kim,Sham Kakade,Sitan Chen", "background": "生成模型的一个自然需求是自我纠正——在推理时检测并修正低质量的标记。尽管蒙版扩散模型（MDMs）是离散空间生成建模的一项有潜力的方法，但它们的自我纠正能力仍需进一步研究。早先努力将自我纠正融入MDMs的方法需要彻底改变MDMs架构或训练，或者依赖不精确的标记质量代理，这限制了它们的应用范围和效果。", "innovation": "本研究提出了PRISM——插件式蒙版重绘以提高蒙待扩散推理时的自我纠正能力——一种轻量级且模型无关的方法，可以应用于任何预训练的MDM。PRISM通过在相同的前向传递过程中计算自我纠正损失来学习每个标记的质量评分，这些评分无需使用强化学习或验证器即可明确识别低质量的标记。在实验上，PRISM进步地提升了MDMs在多个领域的推理性能，包括数独、无需条件的文本（170M）和带有LLaDA（8B）的代码.", "conclusion": "PRISM通过提供一种轻量级、模型无关的解决方案，推动了MDMs推理在不同领域和规模上的自我纠正能力，证明了自我纠正的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03187", "html_url": "https://arxiv.org/abs/2511.03187", "title": "周期性技能发现", "title_en": "Periodic Skill Discovery", "authors": "Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim", "background": "无监督的强化学习技能发现旨在不依赖外部奖励的情况下学习多种行为。当前方法往往忽略了学到技能的周期性，专注于增加状态和技能之间的相互依赖或最大化潜在空间中行驶的距离。许多机器人任务，尤其是涉及运动的任务，需要跨越不同时间尺度的周期性行为。因此，发现用于不同时间尺度的多样化周期性技能至关重要。", "innovation": "提出了周期性技能发现（PSD）框架，该框架能够在不监督的方式下发现周期行为。PSD的核心思想是训练一个编码器将状态映射到一个环形的潜在空间，从而自然地将周期性编码到潜在表示中。通过捕捉时间距离，PSD能够有效地在复杂的机器人任务中学习具有不同周期的多样化技能，即使只有像素级观察。另外，将PSD集成到现有的技能发现方法中可以提供更多样化的行为，从而扩大代理的技能范围。", "conclusion": "实验表明，通过PSD学习的技能在诸如跳跃之类的下游任务中具有高表现力。此外，将PSD与现有的技能发现方法结合使用可以提供更多的行为，从而使代理的技能库更加丰富。相关代码和演示可以在提供的链接中获取。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu Xin,Di Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou", "background": "NVIDIA推出Nemotron Nano V2 VL，这是Nemotron视觉语言系列的最新产品，旨在实现强大的现实世界文档理解、长时间视频理解和推理任务。Nemotron Nano V2 VL在视觉和文本领域比之前的模型Llama-3.1-Nemotron-Nano-VL-8B有显著改进，通过改进模型架构、数据集和训练方法来实现这一点。该模型构建在Nemotron Nano V2之上，后者是一个混合Mamba-Transformer大型语言模型，并借助创新的技术减少令牌数量以提高长期文档和视频推理场景中的推理吞吐量。", "innovation": "Nemotron Nano V2 VL通过改进模型架构、采用创新的令牌减少技术以及使用更大的数据集和训练食谱，在视觉和文本处理方面实现了显著改进。它还提供了BF16、FP8和FP4等不同精度格式的模型检查点，并公开了大量数据集、配方和训练代码，促进了研究和应用的发展。", "conclusion": "NVIDIA发布了Nemotron Nano V2 VL模型的检查点，支持BF16、FP8和FP4等几种精度格式，并开放了用于研究和实践的大规模数据集、训练食谱和训练代码。该模型大幅提高了对长文档和视频的理解和推理能力，适用于多种视觉和语言任务。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.01425", "html_url": "https://arxiv.org/abs/2405.01425", "title": "In-and-Out: 基于算法扩散的凸体采样方法", "title_en": "In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies", "authors": "Yunbum Kook,Santosh S. Vempala,Matthew S. Zhang", "background": "论文背景在于提出了一个用于均匀采样高维凸体的新随机游走算法。现有算法在运行时间复杂度和输出保证方面都不及新方法，尤其是在Rényi分歧、总变差、Wasserstein距离、KL散度和χ²检验等方面提供了更强的保证。", "innovation": "该研究的主要创新在于提出了一种基于算法扩散(new stochastic diffusion perspective)的新随机游走方法，该方法实现了最优的运行时间复杂度，并且提供了更强的输出保证。这一方法通过证明收敛到目标分布的速度由目标分布的功能性等周常数决定，得出了比已知方法更优的结果。", "conclusion": "该研究通过提出基于算法扩散的新随机游走方法，显著提高了高维凸体采样的效率和准确性，并在多个统计度量上提供了更强的保证，是该领域的一个重要进步。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2307.11127", "html_url": "https://arxiv.org/abs/2307.11127", "title": "通过矩匹配实现的渐近无偏合成控制方法", "title_en": "Asymptotically Unbiased Synthetic Control Methods by Moment Matching", "authors": "Masahiro Kato,Akari Ohda", "background": "合成控制方法（SCMs）已成为比较案例研究中的基本工具。这些方法的核心理念是通过使用未治疗单位观察到的结果的加权组合来预测治疗单位的反事实结果，从而估计治疗效果。预测的准确性对于评估政策干预的影响至关重要。因此，后续研究集中于估计SC权重。然而，现有SCMs存在一个核心内生性问题，即未治疗单位的结果与合成控制中的误差项之间存在相关性，这会带来反事实结果预测和治疗效应估计的偏差。", "innovation": "本文提出了一种基于矩匹配的新颖合成控制方法，该方法假设治疗单位的结果可以通过未治疗单位的结果分布的加权混合来近似。通过匹配治疗结果的矩与未治疗结果加权矩之和的矩，本文估计了SC权重，并指出该方法具有三个优势：在混合模型假设下，估计器是渐近无偏的；这种渐近无偏性减少了反事实预测的均方误差；该方法提供了治疗效应的完整分布，而不仅仅是期望值，从而扩展了SCMs的应用范围。", "conclusion": "最后，实验结果表明，本文的方法有效。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.01813", "html_url": "https://arxiv.org/abs/2409.01813", "title": "噪声增强训练及其对ASR系统抗欺骗性攻击效果的比较研究", "title_en": "Comparative Study on Noise-Augmented Training and its Effect on Adversarial Robustness in ASR Systems", "authors": "Karla Pizzi,Matías Pizarro,Asja Fischer", "background": "研究自动语音识别（ASR）系统能否通过噪声增强训练同时提高对抗鲁棒性，分析了四种不同ASR架构在三种不同增强条件下（背景噪声、速度变化和混响；仅速度变化；无数据增强）的鲁棒性，评估了所有模型在白盒或黑盒对抗样本攻击下的鲁棒性。", "innovation": "通过噪声增强训练的方法提高ASR系统的对抗鲁棒性，这种方法同时提升了系统在嘈杂语音上的性能和对对抗攻击的抵御能力。", "conclusion": "噪声增强训练不仅提高了模型在噪声环境中的性能，还增强了模型对对抗攻击的防御效果。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05694", "html_url": "https://arxiv.org/abs/2406.05694", "title": "低秩神经表示的熵解", "title_en": "A Low Rank Neural Representation of Entropy Solutions", "authors": "Donsub Rim,Gerrit Welper", "background": "研究非线性标量守恒律在一个空间维度上光滑凸性流函数的熵解表示。传统的表示方法如特征线方法已经存在，但新的表示方法在此基础上进行了扩展，具有组成形式，并且尽管是非线性的，但时间变量中的解动力学是线性的。", "innovation": "提出了一种新的熵解表示方法，这是一种特征线方法的推广，具有组成形式，并且虽然表示是非线性的，但时间变量中的解动力学是线性的。这种表示方式在作为低秩隐式神经表示进行离散化后，可以利用低秩神经网络结构，通过固定层数和少量系数的神经网络来近似任意复杂的熵解，同时保持嵌入动态的线性特性。", "conclusion": "低秩神经表示可以灵活地近似任何复杂的熵解，而不需要考虑冲击拓扑的复杂性，同时保持隐式动力学的线性特性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04160", "html_url": "https://arxiv.org/abs/2511.04160", "title": "有关深度集成中的联合正则化和校准", "title_en": "On Joint Regularization and Calibration in Deep Ensembles", "authors": "Laurits Fredsgaard,Mikkel N. Schmidt", "background": "深度集成是一种强大的机器学习工具，能够提高模型性能和不确定性校准。通常，集成是通过分别训练和调整各个模型形成的。然而，证据表明，同时调整集成可以提高性能。该论文探讨了同时调节重量衰减、温度缩放和早停参数对预测性能和不确定性量化的影响。此外，论文还提出了一种部分重叠的保留策略，作为在允许联合评估和最大限度利用训练数据之间的一种实用折中方法。结果表明，同时调节集成通常能匹配或提高性能，但在不同任务和度量标准下影响程度存在显著差异。论文强调了单独和联合优化之间的权衡问题，在深度集成训练中，部分重叠的保留策略提供了一种有吸引力的实用解决方案。这些发现为优化深度集成模型的实践者提供了有价值的见解和指导。", "innovation": "本文的研究创新点包括：（1）探讨了同时调节深度集成中的权重衰减、温度缩放和早停参数对性能和不确定性的影响；（2）提出了部分重叠的保留策略，作为联合评估和充分利用数据训练之间的实用折中方法；（3）研究结果显示，同时调节值得一试，尽管其效果在不同任务和度量标准下有所不同。这些发现为深度集成模型的优化提供新的理论依据和实践指导。", "conclusion": "本文发现，同时调整深度集成的一般情况具备匹配或提升性能的作用，尽管其影响因任务和度量标准的不同而异。部分重叠的保留策略为联合评估和最大限度利用训练数据之间提供了一种实用的平衡方法。这些研究成果为优化深度集成模型的实践者提供了宝贵的见解和指导。该研究结果肯定了在深度集成训练中同时优化策略的有效性，强调了在优化过程中可能存在的权衡。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03503", "html_url": "https://arxiv.org/abs/2502.03503", "title": "分析基于上下文学习的限制", "title_en": "Analyzing limits for in-context learning", "authors": "Omar Naim,Jerome Bolte,Nicholas Asher", "background": "先前的研究声称，基于_transformer的模型在学习上下文时会隐式地使用标准的学习算法。本研究质疑这一观点，通过实验证据和数学分析反驳该观点。", "innovation": "本文提供了与上述观点不一致的实验证据，并通过数学分析证明transformer由于其固有的架构限制无法实现普遍的预测准确性。", "conclusion": "transformer在基于上下文学习时无法达到一般的预测准确性，受限于其自身的架构特征。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.09766", "html_url": "https://arxiv.org/abs/2501.09766", "title": "iTool: 动态缺陷校准增强的迭代强化微调策略以实现高级工具使用", "title_en": "iTool: Reinforced Fine-Tuning with Dynamic Deficiency Calibration for Advanced Tool Use", "authors": "Yirong Zeng,Xiao Ding,Yuxian Wang,Weiwen Liu,Wu Ning,Yutai Hou,Xu Huang,Duyu Tang,Dandan Tu,Bing Qin,Ting Liu", "background": "知识大模型（LLMs）通过集成外部工具可以增强其复杂任务的能力。通过现实世界的模拟合成功能，可以有效提升模型能力，但随着合成数据量的增加，训练增益显著下降，模型难以受益于额外的合成数据，导致在复杂情境下未能获得高级工具使用能力。研究发现，这种局限性通常表现为响应片段缺失（即参数错误）。", "innovation": "提出了一种迭代强化微调策略（iTool），通过蒙特卡洛树搜索路径探索提高合成数据的响应多样性，通过细粒度偏好对构建并使用偏好优化算法来迭代定位并改进模型缺陷，从而实现高级工具使用能力增强。", "conclusion": "该方法在同等规模基线模型上实现了13.11%的性能提升，密集场景中相对基线提升了6.5%，并优于更大规模的开源和封闭源模型。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22426", "html_url": "https://arxiv.org/abs/2509.22426", "title": "通过额外预测在游戏中的延迟反馈学习", "title_en": "Learning from Delayed Feedback in Games via Extra Prediction", "authors": "Yuma Fujimoto,Kenshi Abe,Kaito Ariu", "background": "本文研究了博弈学习中的时滞反馈问题。在多代理独立学习自身策略的情况下，优化结果往往出现差异。通常，通过将对未来奖励的预测引入算法（如乐观跟随正则化领导者 Optimistic Follow-the-Regularized-Leader, OFTRL）来解决这一问题。然而，观察过去奖励的时滞影响了对未来奖励的预测能力。研究表明，即使是一个时间步的延迟也会从社会后悔和社会收敛的角度削弱OFTRL的表现。因此，本文分析了时滞对OFTRL的影响，并提出了加权OFTRL（WOFTRL），其中在OFTRL中预测的下一个奖励向量被加权n倍，并通过实验证明了这种加权方式能够恢复在特定博弈中的良好性能，其中包括社会后悔不变和策略向纳什均衡收敛。", "innovation": "本文创新性地研究了OFTRL在处理一个时间步延迟时的表现，并提出了一种加权方法来克服这一问题，名为WOFTRL。该方法通过加权预测向量来抵消时间延迟的影响，并通过理论分析和实验验证了其有效性。特别地，当乐观权重超过时间延迟时，WOFTRL在一般和多矩阵零和博弈中恢复了良好的性能表现，如社会后悔不变和策略向纳什均衡收敛。", "conclusion": "本文首次证明了一个时间步的延迟能够显著影响OFTRL在社会后悔和社会收敛方面的性能。通过引入加权_OFTRL (WOFTRL) 方法，该研究成功地解决了这一问题，特别地，在特定类型的博弈中验证了WOFTRL的优越性，包括在社会后悔不变和策略向纳什均衡收敛上恢复了良好的性能。实验结果支持了这一理论发现，证明了WOFTRL的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14166", "html_url": "https://arxiv.org/abs/2502.14166", "title": "Prediction-Powered Adaptive Shrinkage Estimation", "title_en": "Prediction-Powered Adaptive Shrinkage Estimation", "authors": "Sida Li,Nikolaos Ignatiadis", "background": "PPI（Prediction-Powered Inference）是一种通过将有限的金标准数据与机器学习预测相结合来增强统计估计的有效框架。尽管之前的PPI工作证明了其在单个统计问题上的优势，现代应用需要回答大量并行的统计问题。", "innovation": "引入了Prediction-Powered Adaptive Shrinkage（PAS）方法，该方法将PPI与经验贝叶斯收缩相结合，以提高多个均值的估计。PAS首先在每个任务内去偏差化机器学习预测，然后通过使用这些预测作为收缩的参考点来跨任务借取力量。收缩的程度由最小化无偏的风险估计值来确定，并证明这种调整策略在渐近情况下是最佳的。", "conclusion": "在合成和真实世界数据集上的实验表明，PAS能够适应机器学习预测的可靠性，并在大规模应用中优于传统和现代基准方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22729", "html_url": "https://arxiv.org/abs/2410.22729", "title": "从时间快照中识别漂移、扩散和因果结构", "title_en": "Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots", "authors": "Vincent Guan,Joseph Janssen,Hossein Rahmani,Andrew Warren,Stephen Zhang,Elina Robeva,Geoffrey Schiebinger", "background": "随机微分方程(SDEs)是建模动态过程的基本工具，涵盖基因调控网络(GRNs)、污染物传输、金融市场和图像生成等领域。然而，从数据中学习潜在的SDE是个难题，尤其是当个体轨迹不可见时。受单细胞数据集研究增长的启发，我们提出了一种全新的方法，用于通过时间边缘同时识别SDE的漂移和扩散。假设线性漂移和加性扩散，我们证明这些参数可以通过缺失任何广义旋转对称性的初始分布来唯一确定。此外，我们证明了具有加性扩散的任何SDE的因果图可以从SDE参数中恢复。", "innovation": "我们引入了一种适应性熵正则化最优传输方法来处理各向异性扩散，并提出了APPEX（交替投影参数估计从初始状态$X_0$）算法，这是一个迭代算法，只需从时间边缘估计加性噪声SDE的漂移、扩散和因果图。我们证明APPEX逐步降低库尔贝-莱布尼茨距离到真实解，并通过模拟数据展示了其有效性，数据来自线性加性噪声SDEs.", "conclusion": "APPEX算法能够逐步减少与真实解之间的库尔贝-莱布尼茨距离，并通过模拟数据证明其在估计加性噪声SDE的漂移、扩散和因果图方面的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05305", "html_url": "https://arxiv.org/abs/2506.05305", "title": "ProRefine: 模型推理时使用文本反馈进行提示精细化", "title_en": "ProRefine: Inference-Time Prompt Refinement with Textual Feedback", "authors": "Deepak Pandita,Tharindu Cyril Weerasooriya,Ankit Parag Shah,Isabelle Diana May-Xin Ng,Christopher M. Homan,Wei Wei", "background": "代理性工作流在许多前沿商业应用中扮演重要角色，同时吸引了跨领域的研究人员的关注。这些工作流依赖于给出的角色模型提示来发挥其作用，但若提示设计不佳，可能会影响系统的可靠性和扩展性。为了优化模型推理阶段的提示，提出了一种名为ProRefine的方法，该方法采用代理循环中的LLM生成和应用文本反馈，从而动态优化多步骤推理任务的提示。", "innovation": "ProRefine是一种创新的模型推理时提示优化方法，它通过代理循环中的LLM生成和应用文本反馈来动态优化多步骤推理任务的提示，无需额外的训练或真实标签。与零样本Chain-of-Thought基准相比，ProRefine在五个基准数学推理数据集上表现出显著的优越性，提升了准确性，并允许小模型接近大模型的性能。", "conclusion": "这种方法不仅能够提高模型的准确性，还能够降低构建高效强大混合AI系统所需的成本，进而使得高质量的AI更加普及。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05320", "html_url": "https://arxiv.org/abs/2506.05320", "title": "基于混合状态空间模型的可泛化实时神经解码", "title_en": "Generalizable, real-time neural decoding with hybrid state-space models", "authors": "Avery Hee-Woon Ryoo,Nanda H. Krishna,Ximeng Mao,Mehdi Azabou,Eva L. Dyer,Matthew G. Perich,Guillaume Lajoie", "background": "实时解码神经活动在神经科学和神经技术应用中至关重要，如闭环实验和脑机接口等，这些应用对于模型的延迟有严格的要求。传统方法，如简单的循环神经网络，虽然快速且轻量，但难以泛化到未见过的数据。相比之下，基于Transformer的最近方法虽然通过大规模预训练获得了强大的泛化性能，但通常具有很大的计算需求，并不适合低资源或实时设置。因此，需要新的方法来克服这些局限。", "innovation": "本文提出了POSSM，一种新颖的混合架构。它通过交叉注意力模块实现单个尖峰分词，并结合循环状态空间模型（SSM）作为主干结构，从而在1）实时预测神经活动方面实现快速且因果的在线预测，在2）通过多数据集预训练实现新的会话、个体和任务的有效泛化。实验结果显示，POSSM在猴子运动任务的皮层内解码上表现出与最新Transformer相当的解码精度，同时在推理速度上有显著优势（最高可达9倍更快）。此外，通过猴子运动皮层记录的预训练在人类手写任务中也显示出了解码性能的提升，这展示了跨物种转移学习的潜力。", "conclusion": "实验结果表明，混合状态空间模型是解决实时闭环应用中准确度、推理速度和泛化能力之间权衡问题的一个有前景的方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01542", "html_url": "https://arxiv.org/abs/2507.01542", "title": "具有分段常数值谱的精简高斯混合模型", "title_en": "Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles", "authors": "Tom Szwagier,Pierre-Alexandre Mattei,Charles Bouveyron,Xavier Pennec", "background": "高斯混合模型（GMMs）在统计学习中非常普遍，尤其适用于无监督问题。全GMMs在高维空间中会遭受协方差矩阵的过度参数化问题，而球形GMMs（具有各向同性协方差矩阵）则缺乏灵活性，无法拟合某些各向异性分布。本文通过引入具有分段常数值谱的精简GMMs，连接了这两端。", "innovation": "本文提出了一个新的具有分段常数值谱的精简GMMs家族，扩展了像著名的概率主成分分析混合模型（MPPCA）一类的低秩模型，让他们能够拟合任何可能的特征值多重序数。提出了一个成分惩罚EM算法，既解决了混合参数和超参数联合学习的问题，也证明了该算法的单调性。", "conclusion": "本文模型在多种无监督实验中实现了更优的似然性和精简性权衡：密度拟合，聚类和单图像去噪。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15366", "html_url": "https://arxiv.org/abs/2506.15366", "title": "表演性有效性中的‘反身反馈’解释的有效性", "title_en": "Performative Validity of Recourse Explanations", "authors": "Gunnar König,Hidde Fokkema,Timo Freiesleben,Celestine Mendler-Dünner,Ulrike von Luxburg", "background": "当申请人被算法决策系统拒绝时， recourse 解释提供了一些建议，以便申请人可以通过修改输入特征获得正向评价。然而，一个被忽视但至关重要的现象是，recourse 解释具有‘表演性’： 当大量申请人根据推荐行动时，他们的集体行为可能改变数据中的统计规律，并在重新拟合模型时也改变决策边界。这可能导致在某些情况下，申请人即使努力实施其推荐的内容，也可能会在重新申请时再次被拒绝。这对于理解算法模型的长期有效性和实际应用具有重要意义。因此，本文旨在正式描述当因‘表演性’导致建议的有效性失效的具体条件，并探讨解决这些问题的方法。", "innovation": "研究发现，当recourse行为受到非因果变量的影响或者干预了非因果变量时，它们的有效性可能会被削弱。基于这一分析，该文警示避免使用标准的反事实解释和因果目的论方法，转而倡导仅基于因果变量提出行动建议的recourse方法，以确保解释的有效性不受‘表演性’的影响。", "conclusion": "该研究强调，为了提高决策系统的透明度和公平性，应当提出一种新的基于因果变量的方法来设计recourse建议，以此来避免因‘表演性’而导致解释失效的问题。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09338", "html_url": "https://arxiv.org/abs/2506.09338", "title": "掌握你不知道的：过程奖励模型的不确定性校准", "title_en": "Know What You Don't Know: Uncertainty Calibration of Process Reward Models", "authors": "Young-Jin Park,Kristjan Greenewald,Kaveh Alim,Hao Wang,Navid Azizan", "background": "过程奖励模型（PRMs）在指导大规模语言模型（LLMs）的推理时扩展算法方面扮演着重要角色。然而，即使是最先进的PRMs也可能校准不佳，往往会高估部分推理步骤导致正确最终答案的概率，特别是在使用较小的LLMs完成推理轨迹时更为明显。", "innovation": "提出了通过分位数回归进行校准的方法，调整PRM输出以更好地与真实的成功概率相匹配。基于校准的成功估计及其关联的置信区间，引入了实例自适应扩展（IAS）框架，动态调整计算预算，依据部分推理轨迹生成正确最终答案的可能性。与传统的固定推理轨迹数量的方法相比，这种方法在使用校准后的PRMs时能够根据每种实例和推理步骤进行调整。实验表明，我们的PRM校准方法具有较小的校准误差并优于基线方法，校准对于有效的IAS至关重要，提出的方法有助于减少推理成本同时保持最终答案的准确性，并且能够针对更有把握的问题减少计算资源的使用。", "conclusion": "通过基于校准的成功估计及其置信区间引入实例自适应扩展（IAS）框架，能够在不同实例和推理步骤上动态调整计算预算。实验结果证明，相较于基线方法，所提出的PRM校准方法和IAS框架能够显著降低推理成本并维持最终答案的准确性，特别是在更具把握的情况下减少计算资源的使用。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02275", "html_url": "https://arxiv.org/abs/2507.02275", "title": "噪声的影响：结构无关估计的效果", "title_en": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation", "authors": "Jikai Jin,Lester Mackey,Vasilis Syrgkanis", "background": "结构无关因果推断研究如何基于黑盒机器学习估计的协变量对治疗和结果影响的中间函数来估计治疗效果。该研究发现答案出乎意料地依赖于治疗噪声的分布。文章基于 \textit{Robinson1988Root} 的部分线性模型，首先证明了广泛采用的双机器学习 (DML) 估计器在高斯治疗噪声情况下是简并率最优的，并解决了 \textit{Mackey2018Orthogonal} 提出的未决问题。同时，对于独立的非高斯治疗噪声，文章展示了DML始终低效，通过构造具有更高阶鲁棒性的新实用程序来证明。这些 \textit{ACE} 程序使用结构无关的累积量估计器，当第 $(r+1)$ 个治疗累积量非零时，实现 $r$-次阶的中间函数误差鲁棒性。", "innovation": "文章通过研究部分线性模型，证明了DML在高斯噪声情况下的最优性，并且对于独立非高斯噪声提出了更高的阶次鲁棒性估计器，并通过新方法实现这种鲁棒性。此外，文章还提供了二元治疗情况下部分线性模型的新最小风险保证，通过合成需求估计实验展示了高阶鲁棒估计器的实际益处。", "conclusion": "文章展示了在不同噪声分布情况下的结构无关估计方法的性能，特别是在非高斯噪声下的低效性，并提出了能够实现更高阶鲁棒性的新型结构无关累积量估计方法，通过合成实验验证了这些新方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23767", "html_url": "https://arxiv.org/abs/2507.23767", "title": "基于稀疏统计的闭合形式贝塔分布估计及其随机森林隐式正则化", "title_en": "Closed-Form Beta Distribution Estimation from Sparse Statistics with Random Forest Implicit Regularization", "authors": "Jonathan R. Landers", "background": "本文旨在通过分布恢复和集成分类提升从稀疏数据中恢复分布。研究背景在于如何利用有限的统计数据（最小值、最大值、均值和中位数）精确地重构贝塔分布，并将其应用于随机森林分类器，以提高时间序列快照的分级分类性能。背景还涉及通过分析容差和几率之间的关系，及零方差特征的隐式正则化效应，来验证所提出方法的有效性和实用性。", "innovation": "研究的主要创新点包括：（1）提出了一种使用复合分位数和矩匹配的闭合形式估计器，从有限统计值中重构贝塔分布的参数（α，β），并在随机森林分类器中使用这些参数作为特征，从而提高时间序列快照的分级分类性能。（2）推导出误差上界，限制总体变异距离和杰文森-香农散度，并给出后者展示了二次收敛性。（3）展示了零方差特征作为隐式正则化的作用，增加中间排名预测器的选择概率，产生更深、更多的树模型。通过塞特沟定价数据集和UCI手写数字数据集的应用，验证了这些方法在二级票务市场结构和动态中的有效性。", "conclusion": "本文的研究结果提供了一条从稀疏分布快照到闭合形式估计、再到提高集成分类准确性的实用途径，并通过隐式正则化增强了可靠性和有效性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17494", "html_url": "https://arxiv.org/abs/2507.17494", "title": "在无线网络中的资源分配中信任还是不信任：机器学习模型的校准问题", "title_en": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks", "authors": "Rashika Raina,Nidhi Simmons,David E. Simmons,Michel Daoud Yacoub,Trung Q. Duong", "background": "在下一代通信和网络中，机器学习模型不仅需要提供准确的预测，还需要提供精确校准的信任分数，以反映正确决策的真实可能性。本文研究了一种基于机器学习的断电预测器在单用户多资源分配框架中的校准性能。研究表明，随着资源数量的增加，校准预测器的断电概率（OP）趋向于在低于分类阈值的情况下预期输出。当只有一个资源时，系统的断电概率等于模型的整体预期输出。通过对这些条件的研究，文章为选择分类阈值以达到特定的OP提供了指导，帮助系统设计人员满足特定的可靠性要求。", "innovation": "本文揭示了当资源数量增加时，完美校准预测器的断电概率趋近于特定条件下的预期输出；较低资源情况下的断电概率直接等同于模型的整体预期输出；通过理论分析和仿真，提出了校准单调性条件以确保准确性和可信度之间的改进；指出后处理校准无法改善系统的最小可实现断电概率，因为它们不提供关于未来信道状态的新信息；表明校准良好的模型是比其他预测模型更广泛的类别的一部分，并且此类模型必然提高断电概率。", "conclusion": "本文通过实施数值仿真分析和Rayleigh衰落信道的具体模型，验证了理论上的发现，并揭示了校准在无线网络资源分配中的重要性。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13142", "html_url": "https://arxiv.org/abs/2508.13142", "title": "Holistic Evaluation of Multimodal LLMs on Spatial Intelligence", "title_en": "Holistic Evaluation of Multimodal LLMs on Spatial Intelligence", "authors": "Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Oscar Qian,Hui En Pang,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang", "background": "近年来，多模态模型在诸多领域取得了显著进展，但在空间理解和推理方面的表现仍然有限。本文讨论了在GPT-5等顶级AI模型发布的背景下，重新审视当前主流模型（GPT, Gemini, Grok, Seed, Qwen, Intern）在空间智能方面的能力。文章指出，尽管GPT-5展示了前所未有的空间智能能力，但在广泛的空间任务中仍落后于人类，并且空间任务比非空间任务更暴露了模型能力的缺陷，主流模型在最复杂的任务中并未表现出明显优势。", "innovation": "本文提出了EASI（全面评估多模态LLM的空间智能），一个综合的空间任务分类体系，并制定了一个公平的标准化评估协议，涵盖现有基准测试，对最新的顶级专用和开源模型进行评估。本文通过在八个关键基准测试上进行大样本量的实验，揭示了GPT-5在空间智能上的卓越表现及人类级别的差距，并且展示了空间任务对模型能力的放大效应，即使是最先进的模型也无法处理直观但复杂的人类场景。", "conclusion": "尽管GPT-5在空间智能上表现出色，但在某些复杂的空间任务中，依然不敌人类，揭示了现有主流模型在空间推理和理解上的不足。此外，相比非空间任务，空间任务更能揭示模型的不足，即使是顶尖模型在最复杂的空间任务上也未显示出明显的超越优势。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "通过前瞻性风险感知实现社交导航的学习", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "该报告描述了我们参加IROS 2025 RoboSense挑战社交导航赛道的技术细节。该赛道旨在开发基于RGBD的感知和导航系统，使自主代理能够安全、高效且符合社会规范地在充满动态人类的室内环境中导航。", "innovation": "我们在此基础上引入了前瞻性风险感知模块，以增强社交导航性能。该方法通过Falcon模型，增加了碰撞风险理解，能够预测周围人类的距离碰撞风险评分，从而使代理能够发展出更为坚固的空间感知和预防性碰撞避免行为。", "conclusion": "在Social-HM3D基准上的评估表明，我们的方法在拥挤的室内场景和动态人类代理中，提高了代理维持个人空间合规的导航能力，竞赛中共有16支队伍参与，我们的方法取得了第二名。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21993", "html_url": "https://arxiv.org/abs/2509.21993", "title": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "title_en": "Bilinear relational structure fixes reversal curse and enables consistent model editing", "authors": "Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha", "background": "逆行诅咒是一种语言模型（LM）无法从已学习的事实「A是B」推断出未见过的事实「B是A」的现象，普遍认为这是模型的固有限制。该研究揭示了这是模型对知识编码的产物，并非其固有缺陷。", "innovation": "通过从零开始训练LMs在合成的关系知识图数据集上，研究发现二阶关系结构在隐藏表示中自然出现。这种结构显著减轻了逆行诅咒，并使LM能够推断出未知的反向事实。研究还发现，这种二阶结构对于一致的模型编辑至关重要。当在具有这种表示的模型中更新一个事实时，编辑会正确传播到其反向以及其他逻辑相关的事实，而缺乏这种表示的模型不仅受逆行诅咒的影响，还会在更新上表现不佳，增加逻辑不一致性。", "conclusion": "研究表明，通过关系知识数据集的训练，能够诱导出二阶内部表示，从而使得模型在编辑后的行为更加逻辑一致。这意味着模型编辑的成功不仅依赖于编辑算法，还与所修改知识的底层表示几何结构密切相关。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21700", "html_url": "https://arxiv.org/abs/2504.21700", "title": "XBreaking：理解LLM安全对齐如何被打破", "title_en": "XBreaking: Understanding how LLMs security alignment can be broken", "authors": "Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P", "background": "大型语言模型在现代以AI解决方案为主的IT景观中占据重要地位。然而，这些模型伴随的安全威胁可能阻碍其在关键应用程序场景中的可靠采用，如政府组织和医疗机构。故而，商业化的LLM通常会经历复杂的审查机制，以消除任何潜在的有害输出。这些机制确保模型的安全和伦理响应，但随之而来的对LLM的攻击则是这些保护措施的重大威胁。现有对LLM的攻击方法大多采用生成和测试策略来创建恶意输入。为了改善对审查机制的理解并设计有针对性的攻击，该研究提出了一种可解释的AI解决方案，通过比较审查和非审查模型的行为来揭示独特的可利用对齐模式。在此基础上，提出了XBreaking这一新颖方法，通过目标噪声注入来打破LLM的安全和对齐约束。", "innovation": "该研究提出了一个解释性的AI解决方案，通过比较审查和非审查模型的行为来揭示独特的可利用对齐模式，并提出了一种名为XBreaking的新颖攻击方法，通过目标噪声注入打破LLM的安全和对齐约束。", "conclusion": "通过全面的实验分析，本研究提供了重要的见解，并证明了该方法的有效性和性能。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17459", "html_url": "https://arxiv.org/abs/2510.17459", "title": "直接成像系外行星的轨道参数估计方法 - 基于神经网络", "title_en": "Estimating Orbital Parameters of Direct Imaging Exoplanet Using Neural Network", "authors": "Bo Liang,Hanlin Song,Chang Liu,Tianyu Zhao,Yuxiang Xu,Zihao Xiao,Manjia Liang,Minghui Du,Wei-Liang Qian,Li-e Qiang,Peng Xu,Ziren Luo", "background": "本文介绍了一种名为流匹配马尔可夫链蒙特卡洛（FM-MCMC）的新算法，用于估计系外行星系统的轨道参数，特别是当仅涉及一颗系外行星时。该方法主要解决了在贝叶斯框架内依赖随机抽样的传统方法的问题。与传统的PTMCMC和巢式采样方法相比，FM-MCMC算法通过使用流匹配后验估计（FMPE）来有效制约物理参数的先验范围，再利用MCMC准确推断后验分布，从而提高了计算效率和准确性。这种方法被应用于β Pictoris b的轨道参数推断，结果显示FM-MCMC算法不仅速度提升了77.8倍和365.4倍，同时达到了最高的平均对数值，证明了其优越的采样效率和准确性。这种高效性使其能够处理未来系外行星调查中预期的大规模数据集。", "innovation": "本文提出的一种新的流匹配马尔可夫链蒙特卡洛（FM-MCMC）算法，首先通过流匹配后验估计（FMPE）有效约束物理参数的先验范围，然后使用MCMC来准确推断后验分布。该方法在处理大规模数据集时表现出更高的效率和准确性，尤其是在估计单颗系外行星的轨道参数方面，其速度和准确性明显优于传统PTMCMC和巢式采样方法。此外，该方法还展示了其泛化能力，可以应用到其他领域如天体物理学、生物医学成像、和粒子物理学中的复杂推断问题中。", "conclusion": "本文提出的FM-MCMC方法在处理未来大型系外行星数据集时具有较高的效率和精度。该方法不仅适用于单颗系外行星的轨道参数估计，还展示了在其他复杂推断问题中的潜在应用价值，为神经网络和传统采样方法的结合提供了一种新的范式。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.02818", "html_url": "https://arxiv.org/abs/2511.02818", "title": "Orion-MSP: 多尺度稀疏注意力机制在表结构行内上下文学习中的应用", "title_en": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning", "authors": "Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu", "background": "表格数据仍然是现实世界应用中最常见的格式，但由于特征类型各异和多尺度复杂交互的存在，开发高效的神经模型仍然具有挑战性。虽然最近的表结构行内上下文学习（ICL）进展，比如TabPFN和TabICL，已经实现了与梯度提升树（GBTs）相当的性能，但它们缺乏任务特定的微调。当前的架构存在关键限制，包括单一尺度特征处理、密集注意力与表格宽度的平方扩张、以及顺序组件处理限制了迭代表示细化和跨组件通信。", "innovation": "Orion-MSP 提出了三个创新点：(1) 多尺度处理以捕获层次特征交互；(2) 块稀疏注意力结合窗口、全局和随机模式，提高效率和长程连接；(3) Perceiver 风格的内存机制实现安全的组件间双向信息流。", "conclusion": "Orion-MSP 在多种基准测试中达到了或超越了最先进的性能，有效地扩展到高维表格，确立了高效表结构行内上下文学习的新标准。该模型已在公共平台公开发布。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16821", "html_url": "https://arxiv.org/abs/2505.16821", "title": "基于LLM的RRC层仿真：迈向AI原生RAN协议", "title_en": "LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols", "authors": "Ziming Liu,Bryan Liu,Alvaro Valcarce,Xiaoli Chu", "background": "6G移动网络中，将大型人工智能模型（LAMs）集成到AI-Native Air接口中至关重要，这需要协议智能超越手工艺品逻辑。本文首次使用一个经过Low-Rank Adaptation（LoRA）微调、仅解码的LAM（LLAMA类），对多供应商的5G和4G系统的真实世界踪迹进行了仿真，仿真了RRC层，从而克服了传统方法的局限性。作者将RRC视为领域特定语言，构建了一个保护ASN.1结构的分割安全问答数据集。", "innovation": "本文提出了一种结合参数高效适应和 schema 限制提示的方法，以确保语法和程序忠实性。通过标准意识三元组——ASN.1符合性、字段级覆盖率分析和上行到下行状态机检查，与语义相似性和延迟分析相结合，评估了一系列配置。在30,000个5G请求-响应对和4,800个4G会话的问答轮次基础上，8B模型的中位余弦相似度为0.97，相对零样本基线提升了61%，同时保持了高符合率。这表明，当与协议感知推理增强时，LAM可以直接协调控制平面程序，为未来的AI原生RAN奠定了基础。", "conclusion": "这些结果证明，通过协议意识推理增强，LAM可以直接协调控制平面程序，为未来AI原生RAN奠定基础。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.01602", "html_url": "https://arxiv.org/abs/2511.01602", "title": "L2T-Tune：LLM引导的带有LHS和TD3的混合数据库调优", "title_en": "L2T-Tune:LLM-Guided Hybrid Database Tuning with LHS and TD3", "authors": "Xinyue Yang,Chen Zheng,Yaoyang Hou,Renhao Zhang,Yinyan Zhang,Yanjun Wu,Heng Zhang", "background": "数据库性能的调优对于提高吞吐量和减少延迟至关重要，尽管近年来在这方面取得了一定进展，但仍面临诸多挑战。首先，巨大的调优空间使得直接优化变得不稳定且收敛速度慢；其次，强化学习流程缺乏有效的预热指导，需要长时间离线训练；再次，现有的模型在硬件和工作负载变化时，往往需要大量的重新训练来恢复性能。", "innovation": "提出了L2T-Tune，一种新的由LLM引导的混合数据库调优框架，包含三个阶段：第一阶段进行预热启动，生成并记录跨调优空间的均匀样本；第二阶段利用大型语言模型从手册和社区文档中挖掘和优先级排序调优提示，以实现快速收敛；第三阶段使用预热样本池减少调优参数和状态特征的维度，然后使用Twin Delayed Deep Deterministic Policy Gradient算法进行微调。", "conclusion": "本文对L2T-Tune和最先进的模型进行了实验比较，表明我们的方法在所有工作负载上平均提高了37.1%的性能，TPC-C上提高幅度最高，可达73%。与使用强化学习训练的模型相比，它在单服务器的离线调优阶段实现了快速收敛。此外，在在线调优阶段，它仅需30步即可获得最佳结果。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03202", "html_url": "https://arxiv.org/abs/2511.03202", "title": "在扩散模型中可验证的记忆与泛化的分离", "title_en": "Provable Separations between Memorization and Generalization in Diffusion Models", "authors": "Zeqi Ye,Qijie Zhu,Molei Tao,Minshuo Chen", "background": "扩散模型在多个领域取得了显著的成功，但在生成新颖输出方面仍然容易出现记忆问题，即过度拟合训练数据。这不仅限制了模型的创造性潜能，还引发了隐私和安全方面的担忧。尽管已有实证研究探索了缓解策略，但关于记忆问题的理论理解仍然有限。", "innovation": "通过从统计估计和网络逼近两个互补的角度开发双分离结果，该研究明确了真实得分函数不最小化经验去噪损失，从而导致记忆问题；并且证明了实现经验得分函数需要网络规模随样本大小增长，这与真实得分函数的更紧凑网络表示形成分离。基于这些洞见，提出了一种基于剪枝的方法，该方法能在保持生成质量的同时减少记忆问题。", "conclusion": "该研究通过理论分析揭示了扩散模型中的记忆与泛化的分离，并提出了一种有效减少模型记忆问题的方法。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.27126", "html_url": "https://arxiv.org/abs/2510.27126", "title": "AURA: 一种基于强化学习的AI驱动自适应对话调研框架", "title_en": "AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys", "authors": "Jinwen Tang,Yi Shang", "background": "传统的在线调研在个性化方面有限，导致参与度低且回答表面化。尽管AI调研聊天机器人可以提高便利性，但大多数聊天机器人仍然反应型：它们依赖于固定对话树或静态提问模板，无法在会话期间适应个别用户，导致通用后续问题和较弱的回复质量。", "innovation": "本文提出了AURA（通过强化学习评估的自适应理解），这是一种基于强化学习的AI驱动自适应调研对话框架。AURA使用一个多维度的LSDE指标（长度、自我披露、情绪和具体）量化回复质量，并通过ε贪心策略选择后续问题类型，以调整每个会话中的预期质量收益。该系统利用来自96次校园气候对话（共计467次聊天机器人-用户交互）的先验知识，实现了在10-15次对话交互中平衡探索和利用的目标，实时动态适应个人参与者。", "conclusion": "在受控评估中，AURA相比非自适应基线显著提高了回答质量（平均提升0.076，p=0.044，d=0.66），表现为减少了63%的规格化提问和10倍的验证行为。这些结果表明，强化学习可以提升调研聊天机器人的适应性，将其转变为互动式的自我提升评估系统。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04824", "html_url": "https://arxiv.org/abs/2511.04824", "title": "人工代理重构：AI编码代理的实证研究", "title_en": "Agentic Refactoring: An Empirical Study of AI Coding Agents", "authors": "Kosei Horikawa,Hao Li,Yutaro Kashiwa,Bram Adams,Hajimu Iida,Ahmed E. Hassan", "background": "人工代理编码工具，如OpenAI Codex、Claude Code和Cursor，正在重塑软件工程领域。这些基于AI的系统作为自主团队成员，能够规划和执行复杂的开发任务。代理已经成为重构活动的关键参与者，重构是软件可持续发展的重要环节，旨在不改变外部行为的情况下提升内部代码质量。尽管代理的采用率越来越高，但在实际应用中如何使用代理进行重构、与人类驱动的重构有何异同以及对代码质量有何影响等方面，缺乏实证研究的理解。", "innovation": "本文通过大规模研究12,256个拉取请求和14,988个提交中的15,451个代理生成的重构实例，分析了真实世界的开源Java项目中的代理重构。研究结果表明，重构在这一开发范式中是常见和有意图的行为，代理在26.1%的提交中明确进行了重构。代理重构倾向于进行低级别、一致性导向的编辑，如更改变量类型、重命名参数和重命名变量，反映了对局部改进的偏好而非常见的高级设计变化。代理重构主要动机是提升可维护性和可读性。", "conclusion": "定量评估代码质量指标表明，代理重构在结点数和复杂性等结构性度量方面有小但显著的改进，特别是在中等程度的变化中，类规模和复杂性有所减少（例如，类行数中位数变化Δ=-15.25）。\n"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04576", "html_url": "https://arxiv.org/abs/2511.04576", "title": "物理知情神经网络和神经算子在参变量偏微分方程中的应用：人类与人工智能合作分析", "title_en": "Physics-Informed Neural Networks and Neural Operators for Parametric PDEs: A Human-AI Collaborative Analysis", "authors": "Zhuo Zhang,Xiong Xiong,Sen Zhang,Yuan Zhao,Xi Yang", "background": "偏微分方程在科学和工程中无处不在，解决这些方程通常依赖于参数（物理属性、边界条件、几何形状）。传统数值方法要求为每一个参数重新求解方程，这使得参数空间探索变得极其昂贵。近年来，特别是物理知情神经网络（PINNs）和神经算子（例如DeepONet和傅里叶神经算子）的进步，已经通过学习通用的解算子极大地变革了参变量偏微分方程的求解方法。本文通过对比流体力学、固体力学、热传递和电磁学中的不同方法，展示了神经算子在多查询场景中可以比传统求解器快100到10000倍，同时保持相近的精度。", "innovation": "本文分析了两种主要的方法：一是PINNs，它将物理定律作为软约束嵌入，擅长解决稀疏数据的逆问题；二是神经算子，它学习无穷维函数空间之间的映射，实现了前所未有的泛化能力。文章展示了神经算子在多种科学和工程问题中的巨大计算优势，并为选择方法提供了实用指导，同时探讨了理论基础（通用逼近、收敛）和当前面临的挑战：高维参数、复杂几何结构和离分布泛化。该研究为理解参变量偏微分方程求解的算子学习方法提供了一个统一框架，提供了该领域快速发展的全面且逐步更新的资源。", "conclusion": "本文建立了一个统一框架，以理解通过算子学习的参变量偏微分方程求解方法，提供了一个全面且逐步更新的资源，以支持该领域的快速演变。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04849", "html_url": "https://arxiv.org/abs/2511.04849", "title": "软件定义车辆代码生成：少量示例提示方法", "title_en": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach", "authors": "Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama", "background": "软件定义车辆（SDVs）在汽车行业中带来了范式转变，软件现在是定义车辆功能的核心，能够快速实现现代车辆的创新。开发特定于SDV的应用程序需要先进的工具来简化代码生成并提高开发效率。近年来，通用的大型语言模型（LLMs）在各领域都展示了变革潜力，但由于对专有模型架构的限制性访问，它们难以适应特定任务，例如SDV代码生成。", "innovation": "本研究提出使用提示（prompt），这是一种常见的基本策略，用于与LLM交互并引导其响应。通过使用系统提示和使用先进的提示工程技巧设计适当且高效的提示结构，无需训练会话或访问其基设计，便可以设计LLM。该研究通过在不同模型上进行广泛的实验，应用多种提示技术，探究了特定于SDV代码生成的少量示例提示方法，并使用特定的基准测试来评估LLM生成SDV代码的性能。实验结果显示，采用少量示例提示策略的模型在根据定量指标调整LLM回答以匹配预期结果方面表现最佳。", "conclusion": "研究发现使用少量示例提示的模型在适应预期结果方面表现出色，因此提出了一种基于提示的SDV代码生成方法。该方法展示了在特定于SDV代码生成任务中使用LMs的潜力，通过无训练直接改进了代码生成的质量。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04986", "html_url": "https://arxiv.org/abs/2511.04986", "title": "我们的漏洞怎么办？关于npm包维护者响应性的研究", "title_en": "What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers", "authors": "Mohammadreza Saeidi,Ethan Thoma,Raula Gaikovina Kula,Gema Rodríguez-Pérez", "background": "广泛使用第三方库使得像npm这样的生态系统对现代软件开发至关重要。然而，这一相互关联的依赖链也带来了挑战：一个库中的bug可能会向下游传递，从而可能影响依赖它的许多其他库。我们假设维护者可能不会总是决定修复bug，特别是如果维护者认为这些bug不在他们的责任范围内。", "innovation": "本研究通过调查500个最依赖的npm包中30,340个bug报告的响应性，采用混合方法挖掘仓库问题数据并进行定性开放编码分析，揭示了维护者行为的原因，并提出了一种分类法，指出解决滞后的原因包括贡献实践、依赖限制和库特定标准。", "conclusion": "我们的研究发现维护者通常比较响应，项目级别的响应中位数为70%（四分位距：55%-89%），反映了他们对下游开发者的支持承诺。我们提出了一种分类法解释一些bug未解决的原因，包括贡献实践、依赖限制和库特定标准。了解维护者的行为可以帮助促进更稳健和响应迅速的开源生态系统，使整个社区都受益。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05205", "html_url": "https://arxiv.org/abs/2511.05205", "title": "CodeMapper：一种跨提交映射代码区域的语言无关方法", "title_en": "CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits", "authors": "Huimin Hu,Michael Pradel", "background": "在软件演化过程中，开发者常面临从一个提交到另一个提交映射特定代码区域的问题。现有技术，例如git diff，仅给出文件所有更改，而未专注于开发者选择的代码区域。其他技术针对特定代码元素和编程语言，限制了其适用范围。", "innovation": "本文介绍了一种名为CodeMapper的方法，用于独立于特定程序元素和编程语言解决代码映射问题。CodeMapper给定一个提交中的代码区域，可以找到另一个提交中的对应区域。该方法分为两个阶段：首先通过分析差异、检测代码移动和搜索特定代码片段计算候选区域；其次通过计算相似度选择最可能的目标区域。", "conclusion": "CodeMapper在四个数据集上进行了评估，包括两个新的手动标注数据集，涵盖了十种流行的编程语言。在71.0%至94.5%的情况下，CodeMapper能正确识别预期的目标区域，优于现有最佳基线1.5%至58.8%的绝对百分点。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26854", "html_url": "https://arxiv.org/abs/2510.26854", "title": "验证推理上的逆向知识搜索：从长推理链条知识库合成科学百科", "title_en": "Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base", "authors": "Yu Li,Yuan Huang,Tao Wang,Caiyu Fan,Xiansheng Cai,Sihan Hu,Xinzijian Liu,Cheng Shi,Mingjun Xu,Zhen Wang,Yan Wang,Xiangqi Jin,Tianhan Zhang,Linfeng Zhang,Lei Wang,Youjin Deng,Pan Zhang,Weijie Sun,Xingyu Li,Weinan E,Linfeng Zhang,Zhiyuan Yao,Kun Chen", "background": "大多数科学研究材料会压缩推理过程，只呈现结论而不提供验证推理的结果链，这使得验证变得困难，并且限制了跨领域的联系。研究团队介绍了一种可扩展的框架，将这种压缩的科学推理展开，构建一个可验证的长推理链条（LCoT）知识库，并将其投影进入一个新兴的百科全书，SciencePedia。", "innovation": "研究引入了一个端点驱动的还原主义策略，通过Socratic代理生成大约300万个基于第一原理的问题，这些问题是由大约200门课程引导生成的。LCoTs通过多种独立解决模型生成，然后经过提示清洗和跨模型答案一致性的严格筛选，只保留那些可验证端点的问题。验证过的语料库为Brainstorm搜索引擎提供了动力，该引擎执行逆向知识搜索，检索到多元的、基于第一原理的论证，最终形成目标概念。", "conclusion": "基于验证性的LCoT知识库，这种以推理为中心的方法在跨领域规模上实现可靠的知识合成，并奠定了一个不断扩大的百科全书的基础。验证和推理链条大大提高了知识密度和事实准确性，展示了这种合成方法的有效性。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05165", "html_url": "https://arxiv.org/abs/2511.05165", "title": "使用逆向工程和大型语言模型从源代码生成软件架构描述", "title_en": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model", "authors": "Ahmad Hatahet,Christoph Knieke,Andreas Rausch", "background": "软件架构描述（SADs）对于管理现代软件系统的内在复杂性至关重要，能够支持高层次的架构推理，指导设计决策，并促进不同利益相关者之间的有效沟通。然而，在实践中，SADs经常缺失、过时或与系统的实际实现不一致。因此，开发人员不得不从源代码中直接推断出架构见解，这是一项耗时的过程，增加了认知负担，延缓了新开发人员的入职，并且随着时间的推移逐渐降低了系统的清晰度。本文针对这些问题提出了一个半自动化的方法，通过将逆向工程（RE）技术与大型语言模型（LLM）集成，从源代码生成SADs。", "innovation": "本文提出了一种半自动化的架构描述生成方法，通过结合逆向工程技术与大型语言模型，该方法能够提取综合性的组件图，通过提示工程筛选出具有架构意义的元素（核心组件），并基于底层代码逻辑生成状态机图来建模组件行为，进而生成全面的架构视图。这种方法为传统的手动架构文档提供了一个可扩展性和可维护性的替代方案，并展示了使用C++代码实例证明了大型语言模型具有强大的能力：1）抽象组件图，从而减少对人工专家的依赖；2）准确表示复杂软件行为，尤其在结合特定领域知识时，效果更好。", "conclusion": "本文的研究结果表明，利用大型语言模型的方法能够显著减少手动努力，同时提高系统理解和长期可维护性。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05302", "html_url": "https://arxiv.org/abs/2511.05302", "title": "代码审查自动化利用检索增强生成", "title_en": "Code Review Automation using Retrieval Augmented Generation", "authors": "Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser", "background": "代码审查对于维护软件质量至关重要，但这是一个劳动密集型的过程。虽然基于深度学习的生成技术和检索方法在代码审查任务上已经显示出强大的性能，但生成的代码审查仍然可能存在不准确或过于概括的问题。", "innovation": "提出了一种名为检索增强代码审查者（RARe）的方法，该方法结合了检索方法和生成方法，并通过密集检索器从代码库中选择最相关的代码审查，然后为神经生成器提供输入，以利用大型语言模型的上下文学习能力生成最终的代码审查。与最先进的方法相比，RARe在两个基准数据集上取得了更优的结果，BLEU-4得分为12.32和12.96，进一步通过详细的人类评估和使用可解释性工具的案例研究验证了其实际应用和可靠性。", "conclusion": "与最先进的技术相比，RARe方法在代码审查任务上表现出更优的性能，并通过详细的评估和验证展示了其实用性和可靠性，为代码审查自动化提供了一种新的解决方案。"}
{"llm_update_time": "20251111", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15822", "html_url": "https://arxiv.org/abs/2509.15822", "title": "具有超过√n个社区的随机块模型的相变", "title_en": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities", "authors": "Alexandra Carpentier,Christophe Giraud,Nicolas Verzelen", "background": "背景：研究表明，在随机块模型（SBM）中，社区恢复可能在超过Kesten-Stigum (KS) 约束的多项式时间内进行。当社区数量$K<\boldsymbol{\text{√n}}$时，SBM中的社区恢复是可能的。Chin等(2025)发现，在稀疏区域的前提下方KS阈值，低度多项式无法恢复社区，而社区恢复在多项式时间内仍是可能的。这引发了对于$K \boldsymbol{\text{≥}} \boldsymbol{\text{√n}}$时新的相变临界点的猜想，意味着在此条件下可能仍存在社区恢复的可能性。在这项研究中，研究者提供了证据支持Chin等(2025)的猜想。", "innovation": "创新：1. 证明了对于任何图密度，低度多项式无法在Chin等(2025)提出的阈值下方恢复社区；2. 证明了在Chin等(2025)提出的稀疏区域以及其他部分且非全部适度稀疏区域上，可以通过统计图中的团或者不相交路径来使社区恢复在多项式时间内成为可能；3. 提出了在不包括团或不相交路径计数的更多稀疏度区域的模式猜想，特别强调验证了长度为$\boldsymbol{\text{log(n)}}$而不相交路径统计算法的高效性仅限于稀疏区域。", "conclusion": "结论：这项研究确认了当社区数量达到n的平方根或更多时，社区恢复的多项式时间在稀疏条件下是可以通过统计特定图模式进行实现，并提出了更多高密度状态下的猜想模式。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05459", "html_url": "https://arxiv.org/abs/2511.05459", "title": "SWE-Compass：迈向大型语言模型生成性编程能力统一评估", "title_en": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models", "authors": "Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu", "background": "现有的软件工程中的大型语言模型（LLMs）评估主要受限于任务覆盖面狭窄、语言偏向性以及与实际开发工作流程的不充分对齐。现有的基准测试经常集中在算法问题或Python特定的错误修复上，忽视了软件工程中的一些关键方面。为了弥补这些不足，我们提出了SWE-Compass，这是一个综合基准，将异构的代码评估统一到一个结构化且与实际流程对齐的框架中。SWE-Compass覆盖了8种任务类型、8种编程场景以及10种编程语言，并通过系统的筛选和验证，从真实的GitHub拉取请求中精心选择了2000个高质量的实例。", "innovation": "SWE-Compass引入了一个全面的基准，将异构的代码评估统一到一个结构化且与实际流程对齐的框架中。它涵盖了多种任务类型、编程场景和编程语言，并通过精心筛选和验证选择了高质量的实例。这项工作通过两种代理框架（SWE-Agent和Claude Code）评估了十种最先进的LLMs，揭示了任务类型、语言和场景之间的难度层级。此外，通过与实际的开发实践对齐，SWE-Compass为诊断和促进大型语言模型的生成性编码能力提供了一个严格的和可重复的基础.", "conclusion": "SWE-Compass提供了大型语言模型生成性编码能力的统一评估框架，填补了现有评估方法的不足，通过比较多种任务类型、编程语言和场景，揭示了它们的难度等级，并强调了与实际开发流程对齐的重要性，为后续的研究提供了有力的支持."}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05476", "html_url": "https://arxiv.org/abs/2511.05476", "title": "代码语言模型知识蒸馏的变异性测试视角：学生是否深刻模仿教师？", "title_en": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "authors": "Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy", "background": "基于Transformer的编程语言模型在软件分析任务中取得了最先进的性能，但它们的广泛应用受到高计算成本、缓慢的推理速度和显著的环境影响的限制。为解决这些问题，最近的研究越来越多地探索知识蒸馏的方法，将其大型代码语言模型（老师）压缩成一个更小的模型（学生）以保持性能。然而，现有研究还未能充分探讨学生模型在行为上是否深刻模仿教师模型，当前基于准确性的评估仅提供表面级别的模型质量视图，未能捕获教师和学生模型之间更深层次的行为一致性差异。", "innovation": "本文通过实证研究发现，学生模型在行为上并未深刻模仿教师模型，尤其是在对抗攻击下，性能下降可达285%。现有评估方法未能捕捉到这些深层次的行为不一致性。为此，提出了Metacompress，一种系统化评估框架，通过一组保持行为的变异性关系比较教师和学生模型的输出，以评估行为一致性。Metacompress在两个广泛研究的任务上进行了评估，使用通过三种不同的知识蒸馏技术（Compressor、AVATAR和MORPH）获得的压缩版流行编程语言模型版本。研究结果表明，Metacompress能够在一系列学生模型中识别高达62%的行为差异，强调了知识蒸馏管道中需要进行行为一致性评估，并将Metacompress确立为测试知识蒸馏衍生的压缩代码语言模型的实用框架。", "conclusion": "研究表明，基于现有的准确性的评价方法未能完全揭示教师和学生模型之间深层次的行为一致性差异。Metacompress 通过比较教师和学生模型在变异性关系下的输出，提供了一种系统化的评估框架，能够准确识别出行为差异，从而为代码语言模型的知识蒸馏提供了一个实用的测试框架。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04827", "html_url": "https://arxiv.org/abs/2511.04827", "title": "Pixi: 统一的软件开发和分发框架以促进机器人技术和人工智能的研究", "title_en": "Pixi: Unified Software Development and Distribution for Robotics and AI", "authors": "Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine", "background": "科学计算中的可重复性危机限制了机器人研究的发展。现有研究表明，高达70%的机器人算法无法被独立团队重现，而另一些算法由于创建可共享软件环境的复杂性无法被部署。这些问题源于多个语言、分立的硬件软件工具链，造成了依赖地狱。现有的工具链导致项目级别的依赖状态无法精确捕捉，从而无法保证在不同平台上的一致性重现性。BotI框架旨在解决这些问题，通过在项目层面锁定精确的依赖状态，确保比特级别的重现性。它还采用了高性能的SAT求解器来实现比同类工具快10倍的依赖解析速度，同时集成conda-forge和PyPI生态系统的结合消除了多个管理者的需求。", "innovation": "Pixi 提供了一个统一的软件包管理框架，通过项目级别的锁定文件准确捕捉依赖状态，确保在不同平台上的一致性重现。使用了高性能的SAT求解器进行依赖解析，并且通过集成conda-forge和PyPI生态系统的管理，统一了多个工具链的需求。这对科学研究中的软件可重复性难题提供了实际的解决方案，显著降低了研究人员的设置时间和技术障碍，促进机器人技术和人工智能领域的发展。", "conclusion": "自2023年以来，Pixi已在超过5,300个研究项目中被采用，减少了项目设置时间，并降低了全球研究人员的技术门槛。通过增强可拓展性和可重现的研究基础设施，Pixi 加速了机器人技术和人工智能的进步。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05311", "html_url": "https://arxiv.org/abs/2511.05311", "title": "使用LLM代理清理维护日志以提高预测性维护", "title_en": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "authors": "Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank", "background": "长期以来，经济限制、适合再现实验的高质量数据集缺乏以及特定领域专家的短缺，被认为是阻碍预测性维护（PdM）在汽车行业的应用和发展的关键问题。最近，大型语言模型（LLM）的进步为克服这些问题和加速PdM从研究到工业实践的转变提供了新机会。在这些条件下，本文探讨了基于LLM的代理支持PdM清洗管道的潜力。维护日志是训练高性能机器学习模型的一个关键数据源，但这些数据经常受到错误的影响，如拼写错误、字段缺失、近似重复记录和不正确的日期等。", "innovation": "本文评估了基于LLM的代理在六种不同噪声类型的清洗任务上的表现，并发现它们在处理通用清洗任务方面是有效的，为未来工业应用提供了有希望的基础。尽管特定领域的错误仍然具有挑战性，但这些结果表明，通过专门训练和增强代理能力，未来还有进一步改进的空间。", "conclusion": "本文的研究结果表明，基于LLM的代理在处理通用的清洗任务方面是非常有效的，并提供了一个对未来工业应用的潜在贡献基础。尽管领域特定的错误仍然是一个挑战，但这些结果强调了通过专门训练和增强代理能力来进一步改进的可能性。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05097", "html_url": "https://arxiv.org/abs/2511.05097", "title": "在开放源代码分支之间追踪一日漏洞", "title_en": "Chasing One-day Vulnerabilities Across Open Source Forks", "authors": "Romain Lefeuvre(DiverSe),Charly Reux(DiverSe),Stefano Zacchiroli(IP Paris, LTCI, ACES, INFRES),Olivier Barais(DiverSe),Benoit Combemale(DiverSe)", "background": "追踪来自第三方开源组件的漏洞是一个已知的挑战，通常通过跟踪依赖信息的源头来解决。然而，漏洞也可以通过分支传播：在引入漏洞后但修复之前分支项目仍然可能存在这一漏洞。目前的漏洞分析方法缺乏必要的提交级别细粒度，无法跨分支跟踪漏洞的引入和修复，可能导致存在一天的漏洞被遗漏。这项研究探讨了通过利用软件遗产存档捕获的全球公共代码图谱，提出了一种新方法来帮助开发人员识别分支项目中的“一日漏洞”。", "innovation": "该论文介绍了一种新颖的方法，利用软件遗产存档捕获的全球公共代码图谱，传播提交级别的漏洞信息并进行自动影响分析。这种方法可以在不包含修复的分支项目中自动检测漏洞，从而识别潜在的高危漏洞。该方法从7162个开源仓库中发现了220万次分支活动，并成功识别出356个漏洞-分支对，进一步在手动验证了65个对后，发现了3个严重级别的漏洞，证实了该方法的有效性和实用性。", "conclusion": "该研究提出的方法能够识别分支项目中存在的“一日漏洞”，并在一些活跃且受欢迎的GitHub分支中验证了这一方法的有效性。通过这种自动化的方法，开发人员可以更有效地管理和减少开源分支中的漏洞风险。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.14450", "html_url": "https://arxiv.org/abs/2502.14450", "title": "LLM4FaaS: 使用大语言模型和FaaS进行无代码应用开发", "title_en": "LLM4FaaS: No-Code Application Development using LLMs and FaaS", "authors": "Minghe Wang,Tobias Pfandzelter,Trever Schirmer,David Bermbach", "background": "大语言模型（LLMs）能够从自然语言描述中生成代码，使得编程更为接近非技术人员。然而，这些模型在操作生成的代码方面缺乏专业知识，这是实现个性化应用的关键障碍。Function-as-a-Service（FaaS）平台提供了高度抽象的代码执行和部署层次，使用户能够在无需技术知识或操作开销的情况下运行LLM生成的代码。", "innovation": "本文提出了一种名为LLM4FaaS的无代码应用开发方法，它结合了LLMs和FaaS平台，允许非技术人员仅使用自然语言构建和运行自定义应用。通过利用FaaS部署LLM生成的代码，LLM4FaaS消除了基础设施管理和模板代码生成的需求。作者基于开源FaaS平台实现了一个原型，并使用非技术人员的真实提示进行了评估。实验结果表明，LLM4FaaS在71.47%的情况下能够自动构建和部署代码，优于非FaaS基线（43.48%）和现有的基于LLM的平台（14.55%），并且接近人类的表现（88.99%）。进一步分析代码质量、编程语言多样性、延迟和一致性表明，LLM4FaaS在效率、可维护性和可用性方面表现出平衡的表现。", "conclusion": "LLM4FaaS能够实现非技术人员使用自然语言构建和运行自定义应用。实验结果显示，该方法在多种关键指标上表现出色，接近甚至超过人类的表现，表明这种方法在促进非专业人员参与编程方面具有显著潜力。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03896", "html_url": "https://arxiv.org/abs/2509.03896", "title": "分析代码异味交互导致的依赖分布变化", "title_en": "Analyzing Variations in Dependency Distributions Due to Code Smell Interactions", "authors": "Zushuai Zhang,Elliott Wen,Ewan Tempero", "background": "模块间的依赖关系，在代码更改时可能引发连锁反应，增加维护的复杂性和成本。因此，尽可能减少这些依赖关系至关重要。理解和识别驱动这些依赖关系的因素尤为重要。代码异味是代码中的症状，表明设计问题并降低代码质量。多个代码异味通过静态依赖交互时，它们对质量的综合影响可能更严重。虽然已经广泛研究了单个代码异味的影响，但它们的交互影响仍需进一步探索。本文通过分析116个开源Java系统，研究代码异味交互如何影响依赖关系分布，进一步探究代码异味交互如何导致整体依赖关系数量变化，以及代码异味交互如何一致地影响特定类型的依赖关系变化方向。这将有助于更准确地检测和优先级排序代码异味，以及开发更有效的重构策略。", "innovation": "本文创新地从代码异味交互角度研究了依赖关系分布的变化，填补了代码异味交互影响研究的空白，通过量化研究，揭示了代码异味交互对依赖关系数量及类型的影响方向一致性。", "conclusion": "代码异味交互显著增加了总的依赖关系数量，并且所有代码异味在与其他代码异味交互时，对其它依赖关系类型的变化方向具有一致性。研究结果表明，利用这些信息可以有效支持代码异味的检测和优先级排序，以及开发更有效的重构策略。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05410", "html_url": "https://arxiv.org/abs/2511.05410", "title": "故事竞技场：一种构想软件工程未来多Agent环境", "title_en": "Story Arena: A Multi-Agent Environment for Envisioning the Future of Software Engineering", "authors": "Justin D. Weisz,Michael Muller,Kush R. Varshney", "background": "探讨人工智能（AI）对软件工程的影响，传统的方法可能不足以全面理解这种变化。通过直接让AI参与对话，研究人员希望探索AI在这个领域的未来角色，特别是在人机协作中的作用。因此，他们构建了一个多Agent系统，即‘故事竞技场’，让多个AI代理在各自预设观点的基础上进行对话，共同构建一个描述他们共享愿景的小说，从而深入探讨人类理解、信任、内容所有权以及人机协作中的不确定性等问题。", "innovation": "提出了一个创新的方法论，即通过构建一个多Agent的‘故事竞技场’，让AI代理与自己对话，从而探索AI在软件工程中的未来前景，特别是人机协作的多个复杂层面，包括信任建立、内容所有权以及未来工作的不确定性等。这种方法不仅利用了AI自身的想象力和创造力，同时也为软件工程师提供了一种新颖的方式来思考未来的技术趋势和影响。", "conclusion": "通过‘故事竞技场’，研究人员展示了一部名为‘信任代码’的短篇小说，深入探讨了人机协作中的多个关键主题，包括人类的理解能力、AI的角色、内容的所有权、增强与替代之间的平衡，以及未来发展的不确定性。这种方法提供了一种全新的视角，帮助未来的软件工程更好地应对和适应与AI协同工作的新环境。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.01348", "html_url": "https://arxiv.org/abs/2511.01348", "title": "欧洲GENIUS项目中的生成式人工智能在软件工程的未来：来自行业和学术界的愿景", "title_en": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project", "authors": "Robin Gröpler,Steffen Klepke,Jack Johns,Andreas Dreschinski,Klaus Schmid,Benedikt Dornauer,Eray Tüzün,Joost Noppen,Mohammad Reza Mousavi,Yongjian Tang,Johannes Viehmann,Selin Şirin Aslangül,Beum Seuk Lee,Adam Ziolkowski,Eric Zie", "background": "生成式人工智能（GenAI）在软件工程中的应用近年来取得了突破，能够生成代码、识别错误、推荐修复方案并支持质量保证。尽管在编码任务中显示出显著潜力，但将GenAI应用于整个软件开发生命周期（SDLC）尚未得到充分探索。在可靠性、问责制、安全性和数据隐私等关键领域的不确定性需要更深入的研究和协调行动。", "innovation": "GENIUS项目由超过30个欧洲的工业和学术合作伙伴组成，致力于解决这些挑战，通过在所有SDLC阶段推进AI集成，挖掘GenAI的潜力，开发创新工具，并应对新兴的研究挑战。该研究展望了未来五年的关键技术与方法论进步，以及软件专业人士角色和所需技能的转变，并通过实用工具和工业验证推动这种转变。", "conclusion": "本研究旨在使技术创新与商业相关性相结合，为软件工程团队提供可靠、可扩展且工业化的GenAI解决方案奠定基础，同时为研究议程和工业策略提供信息。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.19544", "html_url": "https://arxiv.org/abs/2406.19544", "title": "GitHub上承认由大语言模型生成的代码在哪里？", "title_en": "Where Is Self-admitted Code Generated by Large Language Models on GitHub?", "authors": "Xiao Yu,Lei Liu,Xing Hu,Jin Liu,Xin Xia", "background": "随着大型语言模型（LLMs）在软件开发中的应用日益增加，研究人员开始评估LLMs在代码生成方面的能力和限制。然而，现有的研究大多集中在受控数据集（如HumanEval）上，这些数据集未能充分反映LLM生成代码在真实开发场景中的特点。因此，该研究转向了一个新的方向：分析GitHub上承认使用LLM生成代码的自我声明实例。尤其是专注于在star超过五颗星的项目中开发者通过代码注释承认使用LLM生成代码的情况。", "innovation": "该研究补充了以前主要基于受控数据集的研究，通过分析GitHub上的实际项目，提供了LLM生成代码在真实开发环境中的新见解。尤其是在项目大小、团队规模、代码复杂性以及代码修改等方面的特征。", "conclusion": "ChatGPT和Copilot主导了代码生成，几乎没有其他LLM的贡献。这些代码主要出现在小到中型项目中，这些项目通常由小型团队持续维护。生成的代码通常是小型到中等长度且低复杂度的代码片段，如算法、数据结构和文本处理代码。这类代码通常只有少量修改，且bug相关改动更是少。大部分代码注释仅陈述了LLM的使用情况，很少包含细节如提示、人工编辑或代码测试状态。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09172", "html_url": "https://arxiv.org/abs/2510.09172", "title": "通过声明性映射规则生成CodeMeta：使用ShExML的开放方法", "title_en": "Generating CodeMeta through declarative mapping rules: An open-ended approach using ShExML", "authors": "Herminio García-González", "background": "如今，软件是多个科学领域中基于计算机的方法学进行研究的重要基石。然而，为了完全实现可再现性，研究软件需遵循FAIR原则，但其元数据可能使用不同的数据模型分布在不同的位置。为了给领域带来一些统一性，CodeMeta 被提出作为一种元数据表示方式。尽管现有工具可以帮助用户生成特定场景下的CodeMeta文件，但在灵活性和适应性方面仍有所欠缺。因此，本文提出使用声明性映射规则生成CodeMeta文件，并通过ShExML实现三个跨走，涵盖两个现有研究软件实体的元数据生成。这些输出使用SHACL和ShEx进行验证，整个生成过程被自动化，只需在新版发布时进行少量用户干预。", "innovation": "本文提出了一种使用声明性映射规则通过ShExML生成CodeMeta文件的方法，该方法具有更高的灵活性和适应性。通过实现三个跨走，该方法能够覆盖现有研究软件实体的元数据生成，且生成过程完全自动化，只需在新版发布时进行少量用户干预。这一工作可以作为模板供其他开发人员在其仓库中包含一个CodeMeta生成工作流，促进CodeMeta的采用，最终提高研究软件的FAIR性。", "conclusion": "本文的方法验证了ShExML在生成CodeMeta文件中的有效性和灵活性，并且可以被其他开发人员所借鉴，有助于提升研究软件的FAIR性。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05297", "html_url": "https://arxiv.org/abs/2511.05297", "title": "基于图检索增强生成构建专用软件助手聊天机器人", "title_en": "Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation", "authors": "Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon", "background": "数字采用平台（DAPs）已成为帮助企业员工导航复杂的企业软件（如CRM、ERP或HRMS系统）的重要工具。例如，LemonLearning证明了数字指导可以减少培训成本并加速员工入职。然而，构建和维护这些交互式指导仍然需要大量的手动努力。利用大型语言模型（LLMs）作为虚拟助手具有吸引力，但是由于缺乏对目标软件的结构化理解，这些模型常常做出虚构的和不可靠的回答。此外，现有的大多数生产级LLMs都是黑盒API，因为缺少模型权重的访问权限，使得微调不切实际。因此，本研究旨在介绍一种图基检索增强生成框架，该框架能够自动将企业级Web应用程序转换为状态-动作知识图，从而使得LLMs能够提供基于上下文的准确建议并生成相关的帮助。该项目与AI企业RAKAM和Lemon Learning合作开发。", "innovation": "本工作提出了一种基于图的检索增强生成框架，能够自动将企业级Web应用程序转化为状态-动作知识图，使大型语言模型（LLMs）能够生成基于场景的、上下文相关的帮助。该框架通过提取并结构化软件界面，设计基于图的检索流程，并将其集成到生产级DAP的工作流程中，从而解决了现有的LLMs在缺乏结构化理解目标软件时的不可靠性。该项研究的目的是改善DAP的自动指导能力，最终实现降低培训成本和提高员工入职效率的目标。", "conclusion": "本研究通过介绍一种基于图的检索增强生成框架，成功地将企业级Web应用程序转化为状态-动作知识图，改善了大型语言模型（LLMs）在自动指导中的可靠性。该项研究不仅增强了DAP的自动指导能力，还提供了关键的技术和工程应用细节。通过解决这些关键问题，本研究为进一步部署DAP提供了经验教训，并为进一步利用LLMs生成准确上下文相关帮助打下了坚实的基础。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.05040", "html_url": "https://arxiv.org/abs/2511.05040", "title": "UA-Code-Bench: 用于评估乌克兰语言大型语言模型代码生成的竞赛编程基准", "title_en": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian", "authors": "Mykyta Syromiatnikov,Victoria Ruvinskaya", "background": "评估低资源语言能力的强大语言模型仍具有挑战性，因为现有基准主要集中在从英语翻译过来的广泛任务，或者仅评估简单的语言理解能力。此论文介绍了一个新的开源基准UA-Code-Bench，旨在全面评估乌克兰语中语言模型的代码生成和求解计算编程问题的能力。该基准包含了500个来源于Eolymp平台的问题，每个复杂度级别均匀分布有100个问题，从非常简单到非常困难。13个领先的专有和开源模型，基于一个一次性提示生成Python解决方案，并通过专用的Eolymp环境进行评估，以确保代码的正确性，这确保了公平性。研究结果表明，即使是顶级模型，如OpenAI o3和GPT-5，也只能解决一半的问题，突显了低资源自然语言中的代码生成挑战。此外，分析还涵盖了不同难度级别的性能，以及解决方案的独特性以及计算效率（通过生成解决方案的时间和内存消耗来衡量）。", "innovation": "该研究通过引入一个专门针对乌克兰语的代码生成和计算编程问题解决能力的基准（UA-Code-Bench），为低资源语言的大规模语言模型评估提供了一种新的方法。这些模型在不同难度级别的表现、解决方案的独特性以及计算效率（通过时间消耗和内存消耗衡量）方面都得到了全面评估。这为未来关于多语言代码生成和增强推理模型的研究奠定了基础。", "conclusion": "这项工作证明了竞赛编程基准在评估大规模语言模型中的价值，特别是在代表性不足的语言中。它也为未来关于多语言代码生成和增强推理模型的研究指明了方向。基准及其相关数据处理、准备、代码生成和评估脚本可以在下面的链接中获得。"}
{"llm_update_time": "20251111", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.26616", "html_url": "https://arxiv.org/abs/2509.26616", "title": "黑盒上下文无关文法推断以生成可读且自然的文法", "title_en": "Black-box Context-free Grammar Inference for Readable & Natural Grammars", "authors": "Mohammad Rifat Arefin,Shanto Rahman,Christoph Csallner", "background": "黑盒上下文无关文法推断在程序分析、逆向工程和安全领域至关重要，但现有工具如Arvada、TreeVada和Kedavra在处理大型复杂语言时面临扩展性、可读性和准确性方面的挑战。现有的文法推断工具难以应对大规模和复杂的编程语言，这限制了它们在实际应用中的效果。因此，需要一种能够大幅提升这些方面的新颖方法。", "innovation": "我们提出了NatGI，一种新颖的基于大语言模型(LLM)指导的文法推断框架。它在TreeVada的解析树恢复基础上引入了三项关键技术：括号指导的气泡探索、基于LLM的气泡生成与非终结符号命名以及具有系统性简化功能的分层增量调试(HDD)。括号指导探索利用括号等语法线索提出结构优良的语法片段，而基于LLM的指导则能够产生有意义的非终结符号名称并选择更有前景的合并方案。分层增量调试逐步减少不必要的规则，使得文法规则更加紧凑且易于理解。NatGI在全面的基准测试套件上进行了评估，涵盖了从小型到大型语言，如lua、C和MySQL。实验结果显示，NatGI在F1分数方面持续优于强基线。NatGI的平均F1分数为0.57，比最佳基线TreeVada高出25个百分点。在可读性方面，根据基于LLM的节点重命名和气泡探索，NatGI生成的规则具有有意义的非终结符名称和紧凑结构，更接近人类直觉，有助于提高开发人员和研究人员对诱导文法结构和语义的准确性和可验证性。", "conclusion": "NatGI通过引入括号指导的气泡探索、基于LLM的气泡生成和非终结符命名以及分层增量调试技术，显著提升了系统处理大型复杂语言的扩展性、可读性和准确性。实验表明，NatGI在F1分数上显著优于现有方法，并且其生成的可读性更高的文法规则可以更好地满足人类直观理解和验证的需求。"}
