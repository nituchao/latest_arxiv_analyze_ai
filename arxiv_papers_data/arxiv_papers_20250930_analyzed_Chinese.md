# 20250930
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索 [PDF](https://arxiv.org/pdf/2509.21567), [HTML](https://arxiv.org/abs/2509.21567)
### Authors
Mohammad Parsa Afshar,Aryan Azimi
### Background
消费者行为预测是市场营销、认知神经科学和人机交互中一个重要的研究目的。脑电图（EEG）数据能提供脑神经活动的详细信息，有助于分析决策过程。
### Innovation
该研究采用了一种比较方法，通过EEG数据预测消费者行为。首先提取并清洁来自NeuMa数据集的EEG数据特征。同时使用了不同机器学习模型，包括经典模型和图神经网络模型，并进行了对比分析。通过不同结构的图神经网络模型进行综合比较，以及应用广泛的经典模型，如集成模型，展示了每个模型在数据集上的差异和性能。
### Conclusion
虽然结果显示整体上没有显著差异，但图神经网络模型在一些基本标准上通常表现更好，尤其是经典模型不理想的场合。该研究不仅展示了结合EEG信号分析和机器学习模型可以提供对消费者行为更深入的理解，还提供了基于EEG的神经市场营销中广泛使用的模型，如支持向量机（SVM）与其他较少使用或未使用过的模型之间的全面比较。
## 2. `cs.AI` - 基于多模态数据的自动化和可解释生存分析 [PDF](https://arxiv.org/pdf/2509.21600), [HTML](https://arxiv.org/abs/2509.21600)
### Authors
Mafalda Malafaia,Peter A.N. Bosman,Coen Rasch,Tanja Alderliesten
### Background
在肿瘤学中，准确和可解释的生存分析仍然是一个核心挑战。随着多模态数据的增加和对透明模型的需求以支持验证和建立信任，这一挑战的复杂度也在增加。
### Innovation
论文提出了一种基于MultiFIX的可解释的多模态AI框架，通过结合临床变量和计算机断层扫描成像来自动化生存分析。该模型使用深度学习推断与生存相关的特征，并通过Grad-CAM解释影像特征，通过遗传规划模型解释临床变量。风险估计采用透明的Cox回归，实现对生存结果不同的群体进行分类。
### Conclusion
MultiFIX在开放源代码的RADCURE头颈癌数据集上的C-指数为0.838（预测）和0.826（分类），优于临床和学术基准方法，并与已知的预后标记一致。这些结果突显了在肿瘤学中使用MultiFIX的可解释多模态AI的潜力。
## 3. `cs.AI` - 通过ASR指导的在线偏好优化提升低资源语言的TTS [PDF](https://arxiv.org/pdf/2509.21718), [HTML](https://arxiv.org/abs/2509.21718)
### Authors
Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li
### Background
开发高品质的低资源语言文本转语音(TTS)系统具有挑战性，因为配对的文本和语音数据稀少。相比之下，这些语言的自动语音识别(ASR)模型往往由于大规模的多语言预训练而更容易获取。该研究提出了一种基于Group Relative Policy Optimization (GRPO)框架的多语言TTS模型调整方法，以适应新的低资源语言。
### Innovation
该方法首先使用国际音标(IPA)符号训练一种多语言基线模型，建立一个语言无关的TTS合成基础。然后，使用新语言的少量配对数据微调该模型，以捕捉目标语言的语调特征。最后，使用未配对文本和讲者提示以及预训练的ASR、讲者验证和音频质量估计模型的多目标奖励来优化模型。实验表明，该流程生成了在低资源语言中清晰且讲者一致的语音，显著优于仅微调。此外，该GRPO基框架也提升了高资源语言的TTS性能，超过了离线对齐方法如直接偏好优化(DPO)，在清晰度、讲者相似度和音频质量方面表现更优。
### Conclusion
该方法生成了在低资源语言中清晰且讲者一致的语音，显著优于仅微调的方法。此外，该基于GRPO的框架也提升了高资源语言的TTS性能，超过了离线对齐方法如直接偏好优化(DPO)，在清晰度、讲者相似度和音频质量方面表现更优。
## 4. `cs.AI` - AI能否感知物理危险并采取行动？ [PDF](https://arxiv.org/pdf/2509.21651), [HTML](https://arxiv.org/abs/2509.21651)
### Authors
Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani
### Background
随着AI与物理世界交互，无论是以机器人的形式还是辅助代理的形式，新的安全挑战开始显现，超越了纯粹的“数字AI”挑战。在这些交互中，物理伤害的可能性是直接且即时的。现有最先进的基础模型对一些常识性物理安全知识的理解如何？例如，它们能否理解纸箱可能太重了而无法举起，或热咖啡不应交给儿童？此研究旨在通过结合现实世界伤害故事和操作安全限制，开发一种大规模的持续物理安全基准评估方法，并用先进的生成模型将这些故事和限制转化为写实的图像和视频，来探究模型对多模态安全理解的能力。
### Innovation
1. 开发了一种大规模的持续物理安全基准评估方法，其基础是现实世界伤害故事和实际操作安全限制。2. 利用先进的生成模型将伤害故事和安全限制转化为逼真的图像和视频，展示从安全状态到不安全状态的变化。3. 全面分析主要基础模型感知风险、关于安全进行推理并触发干预的能力，这些分析为它们在关键性应用中的部署做好准备。4. 开发了一种后训练范式，通过系统指令提供具体的安全约束，使模型学会显式推理，产生可解释和透明的安全推理过程，提高了约束满足评价中的性能。
### Conclusion
所开发的基准将显著增强基础模型在物理安全应用中的表现，理解其推理过程，使其部署更加安全可靠，这些分析为AI的安全应用提供了宝贵的见解。该基准将在此链接处发布：[此处](this https URL)
## 5. `cs.AI` - 共同决策节点被正确推理路径访问 [PDF](https://arxiv.org/pdf/2509.21549), [HTML](https://arxiv.org/abs/2509.21549)
### Authors
Dongkyu Cho,Amy B.Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai
### Background
大型语言模型（LLMs）的链式思维（CoT）推理会暴露其中间思考过程，但大规模验证这些痕迹仍然存在挑战。现有方法无法有效解决这一问题。研究表明，正确推理虽然在风格上多样，但在某些关键节点上会一致，而错误推理则违反至少一个关键点。基于此特性，本文提出了一种新的自我训练管道，通过采集多样化的推理路径并挖掘共享的关键决策节点，将每个推理过程压缩为关键节点导向的短路径推理，并使用辅助验证器进行压缩后的推理验证，最终使用自动生成的输出重新训练模型，从而不依赖真实推理数据或外部指标来进行推理排序。
### Innovation
本文提出了一种创新的自我训练管道，通过挖掘推理路径中的共同决策节点，对模型推理过程进行有效的验证和优化，从而提高了模型推理能力。该方法依赖于正确推理一致性的假设，通过关键决策节点的访问来验证推理路径的正确性，无需使用真实推理数据或外部指标。
### Conclusion
在标准基准测试中，如LogiQA，MedQA和MATH500，所提出的改进方法显示出显著效果。
## 6. `cs.AI` - 缓解评估安全监控时的信息泄露 [PDF](https://arxiv.org/pdf/2509.21344), [HTML](https://arxiv.org/abs/2509.21344)
### Authors
Gerard Boxo,Aman Neelappa,Shivam Raval
### Background
白盒监控器通过分析模型内部结构来检测大语言模型中潜在有害行为，具有降低计算成本和与多层次防御系统集成的优点。然而，训练和评估这些监控器需要展示目标行为的反应示例，通常通过提示或微调获得。但是，用于诱导行为的信息不可避免地会泄露到监控器所摄取的数据中，从而提高了监控器的效果。论文背景即来源于此挑战。
### Innovation
论文提出了一套系统的方法来评估监控器的能力，重点在于检测真实模型行为而非表象的诱导效果。此外，论文还提出了三种创新的评估策略：内容过滤（去除与欺骗相关的文本输入）、评分过滤（仅聚合相关任务的标记）以及提示精炼微调模型（在未明确提示的情况下训练出展示欺骗行为的模型）。论文通过在多个欺骗检测基准上进行实验，应用提出的方法并在评估监控器表现时进行了测试和度量。
### Conclusion
通过实验发现，三种策略中内容过滤是最有效的缓解策略，可降低探针的AUROC值30%；评分过滤虽然降低AUROC值15%，但难以直接归因；微调的模型组织改善了监控器的评估，但也降低了其性能最多40%。
## 7. `cs.AI` - 语义F1分数：模糊类别边界下的公平评估 [PDF](https://arxiv.org/pdf/2509.21633), [HTML](https://arxiv.org/abs/2509.21633)
### Authors
Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan
### Background
传统的F1分数在评估主观或模糊多标签分类时存在局限性，因为它们将语义相关的预测视为完全失败。这导致了对预测结果的过于严格的评估标准。目前存在一些基于相似性的度量方法，但它们通常需要在标签之间强制匹配，这可能会忽略可能具有部分相关性的标签，从而导致评估不公平。
### Innovation
本文提出了一种新的评估度量标准——语义F1分数，用于评估主观或模糊的多标签分类。语义F1分数不仅考虑了标签相似性矩阵，还能够对任意标签集进行比较，而不需要丢弃标签或强制不相似的标签匹配。通过这种可比较性，语义F1能够公平地评估具有人类分歧或模糊类别边界的领域，因为它为语义上相关但非完全相同的标签提供了部分信用，从而更好地反映了这类评估的现实情况。通过理论证明和广泛的实证验证，研究结果表明语义F1分数具有更高的可解释性和生态有效性。此外，由于只需要一个合适的相似性矩阵，而该矩阵对错误指定具有鲁棒性，因此其适用范围广泛，跨越不同的任务和技术领域。
### Conclusion
语义F1分数提供了一种在模糊类别边界下进行公平评估的新方法。这种方法能更好地反映实际情况，并且适用于多种任务和技术领域。
## 8. `cs.AI` - AutoClimDS：气候数据科学的生成式AI——一图胜千言 [PDF](https://arxiv.org/pdf/2509.21553), [HTML](https://arxiv.org/abs/2509.21553)
### Authors
Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng
### Background
气候数据科学面临着来自数据源碎片化、数据格式异质性和获取和处理数据集所需的陡峭技术门槛的持续障碍。这些挑战限制了参与度，减慢了发现过程，并减少了科学工作流程的可重复性。
### Innovation
本文提出了一种通过集成精心策划的知识图谱 (KG) 和为云原生科学工作流程设计的人工智能 (AI) 剂量来解决这些障碍的概念证明。知识图谱为集成了数据集、工具和工作流程的统一层，AI 剂量得益于生成式AI服务，实现自然语言交互、自动化数据访问和简化分析。这些组件共同大幅降低了参与气候数据科学的技术门槛，使非专家用户能够识别和分析相关数据集。利用现有的云就绪API数据门户，证明了“知识图谱就是你需要的一切”来解锁可扩展和自主的工作流程以供科学探索。开源设计进一步促进了社区贡献，确保KG和相关工具能够发展成为共享公共资源。
### Conclusion
结果说明了一条通往气候数据民主化访问的道路，并建立了一个人与AI合作在科学研究中具有可重复性和可扩展性的框架。
## 9. `cs.AI` - GeoEvolve：通过多智能体大型语言模型自动化地理空间模型发现 [PDF](https://arxiv.org/pdf/2509.21593), [HTML](https://arxiv.org/abs/2509.21593)
### Authors
Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon
### Background
地理空间建模对于应对诸如可持续性和气候变化等紧迫的全球挑战至关重要。现有的基于大型语言模型（LLM）的算法发现框架，如AlphaEvolve，在进化通用代码方面表现出色，但在处理复杂地理空间问题时缺乏所需的专业知识和多步骤推理能力。
### Innovation
我们提出了GeoEvolve，这是一种多代理LLM框架，将进化搜索与地理空间领域知识相结合，以自动设计和完善地理空间算法。GeoEvolve通过两个嵌套循环操作：内层循环利用代码进化器生成和变异候选解决方案，外层代理控制器评估全局精英并查询GeoKnowRAG模块——一个结构化的地理空间知识库，注入地理学理论先验。这种知识指导下的进化引导搜索朝着理论上有意义且计算效率高的算法方向发展。GeoEvolve在空间插值（克里金法）和空间不确定性量化（地理空间一致性预测）两个基本且经典的任务上进行了评估，自动改进和发现了新的算法，结合了地理空间理论。用GeoEvolve改进后空间插值误差（RMSE）降低了13%-21%，并提高了不确定性估计性能17%。消融研究证实，基于领域引导的检索对于稳定且高质量的进化至关重要。这些结果表明，GeoEvolve提供了一条可扩展的路径，可以实现自动化、知识驱动的地理空间建模，为可信且高效的AI-For-Science发现打开了新机会
### Conclusion
GeoEvolve提供了一种自动化的知识驱动型地理空间模型发现途径，通过对经典模型进行改进和发现新的算法，结合地理空间理论，显著降低了空间插值误差，并提升了不确定性估计性能，证实了基于领域知识的进化搜索对于高质量算法设计的重要性。
## 10. `cs.AI` - Behavior Consolidation for Lifelong Learning in Vehicle Routing [PDF](https://arxiv.org/pdf/2509.21765), [HTML](https://arxiv.org/abs/2509.21765)
### Authors
Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao
### Background
现有的神经网络解题器在解决路径规划问题时表现出了良好的潜力，但大多数研究是在单一或一组预定义的任务上进行一次性的训练实现的。当遇到新任务时，它们通常依赖于零样本泛化或重新微调之前的模型，这两种方法都存在不足。零样本泛化可能导致性能不佳，而重新微调可能会导致对之前任务知识的灾难性遗忘。本文探讨了一种新的神经网络车辆路径规划(Neural VRP)解题器的终身学习范式，即随时间顺序出现具有不同分布和规模的多种任务。解决器需要不断学习解决新任务，同时保持对之前学习任务的性能。
### Innovation
提出了一种名为Lifelong Learning Router with Behavior Consolidation (LLR-BC)的新框架。LLR-BC通过一种决策导向的方式，有效整合先前的知识，使解题器在新任务上学习的同时保持对先前任务的性能。为了引发更多对关键经验的关注，LLR-BC对低置信度的决策分配更大的整合权重。该框架在容量受限的车辆路径规划问题和旅行商问题上进行的广泛实验表明，它在终身学习环境中训练高性能神经网络解题器方面具有有效性，解决了灾难性遗忘问题，保持了解题器的可塑性，提高了零样本泛化能力。
### Conclusion
LLR-BC框架在解决容量受限的车辆路径规划问题和旅行商问题时有效，能够解决灾难性遗忘，保持可塑性，并提高零样本泛化能力，从而增强了神经网路解题器在终身学习环境中的性能。
## 11. `cs.AI` - Retrieval-of-Thought：通过重用思路实现高效推理 [PDF](https://arxiv.org/pdf/2509.21743), [HTML](https://arxiv.org/abs/2509.21743)
### Authors
Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar
### Background
大型推理模型通过生成长推理轨迹以提高准确性，但这会增加延迟和成本，促使在推理过程中提高效率。已有研究表明，通过重用先前的推理步骤，可以指导新的问题，从而提高推理效率。RoT方法通过构建一个包含顺序和语义边的思想图来实现这一点，以实现快速检索和灵活重组。通过这种动态模板重用推理步骤，RoT能减少冗余探索，从而减少输出令牌，同时保持准确性。该方法在多个模型上对推理基准测试进行了评估，测量了准确率、令牌使用率、推理延迟和内存开销。结果表明，虽然提示增长较小，但效率提升显著，RoT可以使输出令牌减少高达40%，推理延迟缩短82%，成本降低59%，同时保持较高的准确性。
### Innovation
RoT（Retrieval-of-Thought）提出了一个新的方法，通过构建思想图来重用先验推理步骤，以指导问题的生成，实现了动态模板的实时构建与快速检索。该方法显著降低了冗余探索，减少了输出令牌，提高了推理效率，同时保持了高度的准确性，无需显著增加提示文本长度。RoT在提高推理模型效率方面建立了可扩展的范例。
### Conclusion
RoT方法在多个推理基准测试中表现出色，通过重用推理步骤的方法，显著提高了推理效率，减少了输出令牌和成本，同时维持了高准确性。该方法提供了一种可扩展的策略，通过动态模板构建来提高大型推理模型的推理效率。
## 12. `cs.AI` - 公理化选择与决策评价悖论 [PDF](https://arxiv.org/pdf/2509.21836), [HTML](https://arxiv.org/abs/2509.21836)
### Authors
Ben Abramowitz,Nicholas Mattei
### Background
该研究介绍了一种框架，用于通过公理来建模决策，这些公理是对决策本身的陈述，比如道德约束。通过该框架定义了基于其结构属性的决策公理分类，并展示了使用公理进行决策与评价之间的张力，即所谓的决策评价悖论。
### Innovation
提出了一种基于公理的决策建模框架，并定义了决策公理的分类；揭示了决策评价悖论，指出这种悖论在现实的公理结构中普遍存在，说明了在使用决策数据训练模型或应用公理进行决策及其评价时需要特别谨慎。
### Conclusion
决策评价悖论在现实的公理结构中普遍存在，它揭示了在基于决策数据训练模型或应用公理进行决策评价时必须极其谨慎的原因。
## 13. `cs.AI` - 基于MLLM的Web理解基准测试：推理、稳健性和安全性 [PDF](https://arxiv.org/pdf/2509.21782), [HTML](https://arxiv.org/abs/2509.21782)
### Authors
Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu
### Background
现有的多模态大语言模型（MLLMs）被越来越多地用作与开发复杂网络相关应用的AI合作者，如GUI代理和前端代码生成。然而，现有的基准主要集中在视觉感知或UI代码生成上，对构建端到端网络应用所需的推理、稳健性和安全性能力评估不足。因此，为了填补这些空白，研究者们引入了一个综合性的网络理解基准，称为WebRSSBench，该基准同时评估推理、稳健性和安全性等八个任务，包括位置关系推理、颜色稳健性、关键安全检测等。该基准数据集来自729个网站，包含3799个多个步骤推理的问题-答案对，覆盖页面结构、文本、控件和关键安全交互等。为了确保测量的可靠性和一致性，研究中采用标准提示、确定性评估脚本以及结合自动检查和主要内容的人类验证的多阶段质量控制措施。
### Innovation
该研究引入了WebRSSBench基准测试，首次全面评估了MLLMs在网页应用中的推理、稳健性和安全性能力。该基准涵盖多种任务，并采用标准化的提示、确定性的评估脚本以及结合自动和手动验证的质量控制措施，确保评估的可靠性。此外，该评估还展示了当前MLLMs在这几个关键领域的不足之处，如：原因组合推理、跨元素推理、鲁棒性应对用户界面和内容变化、以及在识别安全关键操作方面的保守性。
### Conclusion
通过评估12个MLLMs在WebRSSBench上的表现，结果揭示了其在推理能力、鲁棒性和安全性方面存在的显著差距。为进一步提高MLLMs在实际网络应用中的表现，该研究提出了一些改进建议，并开源了实验代码。
## 14. `cs.AI` - D-Artemis: 一种移动GUI多智能体的审慎认知框架 [PDF](https://arxiv.org/pdf/2509.21799), [HTML](https://arxiv.org/abs/2509.21799)
### Authors
Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan
### Background
图形用户界面（GUI）智能代理旨在通过模仿用户交互来自动化一系列的人类任务。然而，当前的方法受到了几个关键挑战的阻碍：端到端训练中的数据瓶颈、延迟错误检测的高成本，以及执行失败的矛盾指导风险。人类的认知循环包括思考、对齐和反思三个阶段，受这一模式的启发，本文提出了一种新颖的审慎框架——D-Artemis。D-Artemis 利用细粒度的应用特定提示检索机制来指导其决策过程，并在预执行阶段采用了主动对齐机制，有效地降低了执行失败的风险。
### Innovation
D-Artemis 引入了细粒度的应用特定提示检索机制和预执行和后执行检查机制，实现了对复杂轨迹数据集的无需训练，提升了通用多模态大语言模型在 GUI 任务中的能力，并且在主要基准测试上取得了新的 SOTA 结果，分别在 AndroidWorld 和 ScreenSpot-V2 上达到了 75.8% 和 96.8% 的成功率。
### Conclusion
本文提出的 D-Artemis 提高了通用多模态大语言模型在 GUI 任务中的性能，无需复杂的训练数据集，同时展示了每个模块对框架性能的重要贡献。
## 15. `cs.AI` - UltraHorizon: 在超长周期场景中评估智能体能力的基准 [PDF](https://arxiv.org/pdf/2509.21766), [HTML](https://arxiv.org/abs/2509.21766)
### Authors
Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen
### Background
尽管自主智能体在各领域取得了显著进展，但大多数评估侧重于短期且完全可观测的任务。然而，许多关键现实世界任务，如大规模软件开发、商业投资和科学发现，通常发生在长周期且部分不可观测的情景中，成功依赖于持续的推理、规划、记忆管理和工具使用。现有的基准测试很少能够捕捉到这些长周期挑战，导致系统性的评估存在不足。为此，我们提出了UltraHorizon这一新的基准测试，旨在衡量解决复杂现实挑战所需的基础能力。我们通过探索这个统一的任务在三个不同的环境中的应用，来验证智能体的核心竞争力。在这种长周期发现任务中，智能体需要通过持续的推理、规划、记忆管理和与环境的交互，逐步揭示隐藏的规则。在最大规模的设置中，路径平均长度超过20万个令牌和400多次工具调用，而在标准配置中，平均路径长度仍超过3.5万个令牌，涉及超过60次工具调用。实验结果表明，基于语言模型的智能体在这类环境中的一致表现不佳，而人类参与者则表现出更高的评分，突显了智能体在长周期能力方面的持续差距。我们还发现，简单的扩展在我们的任务中表现无效，为了更好地展示智能体的表现，我们对收集的轨迹进行了深入分析，发现了八种类型错误，并将其归因于上下文锁定和功能基础能力缺口的主要原因。
### Innovation
我们提出了UltraHorizon这一新的基准测试，旨在衡量解决复杂现实挑战所需的基础能力，通过探索在三个不同的环境中的应用，验证智能体的核心竞争力。这种长周期发现任务要求智能体通过持续的推理、规划、记忆管理和与环境的交互，逐步揭示隐藏的规则。这项基准测试填补了现有评估中的不足，能够系统地测试智能体在长周期场景中的性能。此外，这项研究表明，简单的扩展对于解决长周期任务是无效的，提出了上下文锁定和功能基础能力缺口作为智能体表现差的主要原因。
### Conclusion
我们的实验表明，基于语言模型的智能体在长周期环境中的表现持续低于人类。更深入的分析显示了智能体的失败模式，并归因于上下文锁定和功能基础能力缺口。这些发现揭示了当前智能体系统面临的挑战，并为未来的研究提供了方向，强调了在不可观测、复杂和动态环境下的智能体设计需求。
## 16. `cs.AI` - ProRe: GUI代理通过推理-演员协作的主动奖励系统 [PDF](https://arxiv.org/pdf/2509.21823), [HTML](https://arxiv.org/abs/2509.21823)
### Authors
Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu
### Background
现有的基于规则或模型的奖励方法难以适应GUI代理，因为获取真实轨迹数据或应用程序数据库常常不可用，而基于静态轨迹的大语言模型作为评判员的方法也会由于准确度有限的问题受到限制。
### Innovation
提出了一种名为ProRe的主动奖励系统，该系统利用通用推理器和领域特定评估者（演员）进行协作。推理器调度特定状态探测任务，评估者通过主动与环境交互来收集额外观察信息，从而使推理器能够为GUI代理提供更准确和可验证的奖励。
### Conclusion
在超过3000个轨迹上进行的实验表明，ProRe可以将奖励准确性和F1分数分别提高5.3%和19.4%，并且将其与最先进的策略代理集成，可以将成功率提高22.4%。
## 17. `cs.AI` - DS-STAR: 数据科学代理通过迭代规划和验证 [PDF](https://arxiv.org/pdf/2509.21825), [HTML](https://arxiv.org/abs/2509.21825)
### Authors
Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister
### Background
数据科学对于数据驱动的决策至关重要，但这一过程往往复杂，涉及到探索多个数据源并综合发现以提供有洞察力的答案。尽管大规模语言模型（LLMs）显示出在自动化这个过程中的巨大潜力，但它们在处理异构数据格式时往往存在困难，并且生成的分析计划往往不够优化，主要原因在于此类开放任务的计划全面性验证难度大。现有方法很难克服这些局限性，因此需要一种新的数据科学代理来解决这些问题。
### Innovation
DS-STAR 通过引入三个关键贡献解决了这些问题：(1) 数据文件分析模块，能够自动探索和从多种数据格式中提取上下文，包括非结构化类型；(2) 验证步骤，其中基于LLM的裁判在每个阶段评估分析计划的充分性；(3) 顺序规划机制，该机制从简单的可执行计划开始，并根据 DS-STAR 的反馈迭代改进，直到验证其充分性。迭代优化使 DS-STAR 能够可靠地导航涉及多种数据源的复杂分析。实验结果表明，DS-STAR 在三个具有挑战性的基准测试中达到了最先进的性能：DABStep、KramaBench 和 DA-Code，并且在需要处理具有异构格式的多个数据文件的困难任务上优于基线方法。
### Conclusion
DS-STAR 通过有效的迭代规划和验证机制，解决了当前 LLM 在面对异构数据格式和复杂数据分析任务时存在的不足，展示了其在数据科学自动化领域的强大性能。
## 18. `cs.AI` - 通过Shachi重新构想基于代理的建模与大型语言模型代理 [PDF](https://arxiv.org/pdf/2509.21862), [HTML](https://arxiv.org/abs/2509.21862)
### Authors
So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang
### Background
在大型语言模型（LLM）驱动的多智能体系统中，对自主行为的研究是一个关键的研究挑战。然而，由于缺乏规范的实验控制方法，进展受到限制。因此，需要一种能够系统分析特定架构选择对集体行为影响的方法。
### Innovation
本文提出了Shachi，这是一种正式的方法论和模块化框架，将智能体政策分解为核心认知组件：配置（内在特质）、记忆（上下文持久性）和工具（扩展功能），由LLM推理引擎协调。这种有原则的架构超越了脆弱的、非正式的方法设计，并使系统化的分析成为可能。
### Conclusion
本文通过全面的10项任务基准验证了方法，并通过新型的科学命题展示了其强大的功能。关键在于，通过建模真实的美国关税冲击，本文证明了智能体的行为仅在认知架构适当配置时，与市场反应一致，从而验证了方法的外部效度。为我们提供了构建和评估LLM代理的严格开源基础，旨在促进更为累积和科学的研究。
## 19. `cs.AI` - GSM-Agent: 使用可控环境理解代理推理 [PDF](https://arxiv.org/pdf/2509.21998), [HTML](https://arxiv.org/abs/2509.21998)
### Authors
Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao
### Background
随着大规模语言模型（LLM）被越来越多地部署为智能代理，代理性推理——即结合工具使用（尤其是搜索）和推理的能力——成为了关键技能。但在复杂环境中和任务中难以分离出代理性推理。当前的智能代理基准测试通常将代理性推理与其他挑战性数学推理、专家级知识和其它高级能力混合在一起。因此，本文提出了一个新的基准测试GSM-Agent，要求LLM代理解决基础学校级别的推理问题，并且在仅提供问题的情况下，需要主动收集所需的解决任务的关键信息。我们基于观察结果认为，虽然基础任务是基础数学问题，但前沿模型如GPT-5的准确率仅为67%。
### Innovation
本文提出了GSM-Agent基准测试，该测试要求参与者在只有问题而没有前提信息的情况下解决基础学校级别的推理问题，需要主动收集信息。基于这种新框架，我们提出代理推理图的概念，并开发了一种工具增强的测试时扩容方法，以提高LLM的代理推理性能，包括鼓励模型重新访问已访问过的节点。
### Conclusion
本文提出的基准测试和代理推理框架旨在帮助未来的研究理解并推动代理推理的边界。
## 20. `cs.AI` - DeepTravel：自主旅游规划智能体的端到端代理强化学习框架 [PDF](https://arxiv.org/pdf/2509.21842), [HTML](https://arxiv.org/abs/2509.21842)
### Authors
Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu
### Background
旅游规划（TP）智能体作为新兴的建筑块，通过与外部工具和资源互动来生成旅行行程，旨在确保用户享受体验。尽管具有好处，但现有的研究依赖手动构建提示和固定的智能体工作流，这限制了智能体的灵活性和自主性。
### Innovation
本文提出了DeepTravel，这是一种端到端的代理强化学习框架，用于构建能够自主规划、执行工具并根据工具响应反思中间行动，推动多步推理中的探索、验证和细化的自主旅游规划智能体。通过构建一个坚固的沙箱环境，从中缓存交通、住宿和POI数据，以便在不被真实世界API限制（如不一致输出）所束缚的情况下训练TP智能体；开发了一种分层的奖励建模系统，包括路径级验证器和回合级验证器，以高效和精确地提供奖励服务；提出了回复增强的强化学习方法，允许TP智能体定期从失败经验库中重播，提高智能性；在DiDi企业解决方案应用上部署训练好的TP智能体，并进行综合的在线和离线评估，显示小规模的LLM（如Qwen3 32B）在旅游规划任务中显著优于现有的前沿LLM（如OpenAI o1、o3和DeepSeek R1）
### Conclusion
DeepTravel框架使小型LLM（例如Qwen3 32B）能够在旅游规划任务中显著超越现有的前沿LLM（如OpenAI o1、o3和DeepSeek R1），提高了旅游规划智能体的自主性和灵活性。
## 21. `cs.AI` - GenesisGeo：技术报告 [PDF](https://arxiv.org/pdf/2509.21896), [HTML](https://arxiv.org/abs/2509.21896)
### Authors
Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen
### Background
该研究背景在于自动化定理证明在欧几里得几何中的应用。研究人员开放了一个包含2180万几何问题的大规模几何数据集，其中超过300万个问题包含辅助构造。这为自动化定理证明技术的发展提供了基础数据支持。
### Innovation
研究人员通过定理匹配显著加速了符号推理引擎DDARN，速度提升了120倍，并使用了C++实现了核心组件。此外，他们基于Qwen3-0.6B-Base构建了神经符号证明器GenesisGeo。单模型解决了IMO-AG-30基准中的24个问题（国际数学奥林匹克银牌级别），双模型组合则解决了26个问题（金牌级别），展示了该技术在解决高难度几何问题方面的显著效果。
### Conclusion
该研究提出了一个自动几何定理证明系统GenesisGeo，并通过大量实验证明，该系统在解决复杂几何问题方面具有显著优势，尤其是在高难度问题的解决上达到了金牌级别标准。
## 22. `cs.AI` - DyRo-MCTS: 动态鲁棒蒙特卡洛树搜索方法及其在动态车间调度中的应用 [PDF](https://arxiv.org/pdf/2509.21902), [HTML](https://arxiv.org/abs/2509.21902)
### Authors
Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang
### Background
动态车间调度是各种工业部门中的一个基本组合优化问题，由于新任务的频繁干扰，有效的调度面临重大挑战。最先进的方法使用机器学习在离线学习排程策略，实现对动态事件的快速响应，但这些离线策略往往不够完美，因此需要使用规划技术如蒙特卡洛树搜索（MCTS）来改善在线决策性能。新任务的不可预测性增加了在线规划的复杂性，基于不完整问题信息的决策容易受到干扰。为了解决这一问题，提出了一种名为DyRo-MCTS的鲁棒蒙特卡洛树搜索方法，将行动鲁棒性估算集成到MCTS中，引导生产环境向不仅产生良好排程结果且易于适应未来任务到达的状态发展。
### Innovation
提出了一种名为DyRo-MCTS的方法，将行动鲁棒性估算集成到MCTS中，旨在既能提供良好的当前排程结果，又能适应未来的任务到达。实验表明，DyRo-MCTS显著提高了离线学习策略的性能，几乎不增加额外的在线规划时间。并且，DyRo-MCTS在各种排程场景中都超过了传统的MCTS。
### Conclusion
DyRo-MCTS能够做出稳健的调度决策，有利于长期持续的性能提升。
## 23. `cs.AI` - 双线性关系结构修复反转诅咒并实现一致的模型编辑 [PDF](https://arxiv.org/pdf/2509.21993), [HTML](https://arxiv.org/abs/2509.21993)
### Authors
Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha
### Background
反转诅咒——语言模型（LM）在无法从已经学习的事实'A是B'推断出未见过的事实'B是A'方面被认为是一基本限制。普遍认为，这是模型固有的失败，而并非知识编码方式的问题。
### Innovation
研究通过从零开始训练LMs在合成的关系知识图谱数据集上，展示了双线性关系结构如何在隐层表示中自然形成。这种结构显著缓解了反转诅咒，使LM能够推断出未观察到的反事实。此外，研究发现双线性结构在模型编辑中扮演关键角色。当一个事实被更新时，这种结构能确保修改正确传播到其反事实及其他逻辑上相关的事实。相比之下，没有这种表示的模型不仅延续了反转诅咒，还未能很好地推广修改，进一步引入了逻辑不一致。
### Conclusion
研究表明，在关系知识数据集上训练LM引发双线性内部表示的形成，从而在修改后使LM表现出逻辑一致性。研究结果表明，模型编辑的成功不仅依赖于编辑算法，还依赖于知识修改的潜在表示几何结构。
## 24. `cs.AI` - TRACE: 在图上进行计算的学习 [PDF](https://arxiv.org/pdf/2509.21886), [HTML](https://arxiv.org/abs/2509.21886)
### Authors
Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu
### Background
图表示学习中的计算能力，即能够建模计算图的函数行为，是一个基本挑战。然而，主流的架构与这一任务不符。主流的自注意力网络和其传统的Transformer变体基于不合理的假设，未能捕捉到计算中的位置感知和层次结构性质。
### Innovation
我们提出了一个新的架构和学习目标，命名为TRACE。首先，TRACE 使用级联Transformer作为基础架构，可以模仿计算的过程流，用于替代不可靠的置换不变聚合。其次，我们引入了函数偏移学习，这是一个新颖的目标，可以将学习问题解耦。模型被训练预测仅是全局函数与简单局部近似之间的差异，而无需直接预测复杂的全局函数。
### Conclusion
我们在电子电路这类极其复杂且经济至关重要的计算图类别的基准上验证了这个新范式。结果表明，与以往所有的架构相比，TRACE 在多个全面的基准测试中显著更胜一筹。这些结果表明，我们的基准对齐架构和解耦学习目标形成了一种更稳健的范式，用于图上的计算学习挑战。
## 25. `cs.AI` - CoBel-World: 利用LLM推理构建优化体态多智能体协作的协作信念世界 [PDF](https://arxiv.org/pdf/2509.21981), [HTML](https://arxiv.org/abs/2509.21981)
### Authors
Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang
### Background
有效的现实世界多智能体协作不仅需要准确的计划，还需要推断合作者意图的能力，这对于部分可观测环境下的避免协调错误和重复通信至关重要。大型语言模型（LLMs）由于其强大的推理和规划能力，成为了有潜力的自主代理，用于协同任务解决。然而，现有的LLM协作框架忽略了推理在动态意图推断中的潜力，导致计划不一致和重复通信，降低了协作效率。
### Innovation
提出了CoBel-World框架，该框架赋予LLM代理一个协作信念世界——一种内部表示，同时建模物理环境和合作者的心理状态。CoBel-World通过符号性的信念语言将开放世界任务知识解析为结构化信念，并通过LLM推理执行零样本贝叶斯式信念更新。这使得代理能够主动检测潜在的协调错误（例如，冲突的计划）并适应性地进行通信。在具挑战性的体态基准（即TDW-MAT和C-WAH）上，CoBel-World减少了22-60%的通信成本并提高了4-28%的任务完成效率，相比最强基线。我们的结果表明，明确、意图感知的信念建模对LLM基础的多智能体系统中高效和类人的协作至关重要。
### Conclusion
明确、意图感知的信念建模在基于LLM的多智能体系统中对于高效且类人的协作是至关重要的。CoBel-World框架通过赋予代理协作信念世界，能够提高多智能体在部分可观测环境下的任务完成效率和沟通效率。
## 26. `cs.AI` - 评价大语言模型在组合优化中的性能：针对2D装箱问题的一阶段和两阶段启发式算法 [PDF](https://arxiv.org/pdf/2509.22255), [HTML](https://arxiv.org/abs/2509.22255)
### Authors
Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder
### Background
该论文提出了一个评估大型语言模型（LLMs）在组合优化领域的能力框架，具体应用在2D装箱问题上。研究结合了LLMs与进化算法，通过系统性方法生成并不断优化启发式解决方案。实验比较了由LLMs生成的启发式算法与传统方法（有限第一填充法和混合第一填充法），证明了LLMs能够产生更高效的解决方案，同时减少计算资源的使用。
### Innovation
该论文创新地提出了一种结合LLMs和进化算法的系统方法，用于生成和优化2D装箱问题的启发式解；展示了LLMs在处理组合优化问题上的优势，在有限的迭代次数中实现了最优解，大大提高了空间利用率。
### Conclusion
本研究为理解LLMs在特定领域中的评估提供了新的见解，并为评估LLMs在组合优化任务中的表现建立了基准。
## 27. `cs.AI` - RISK:在电子商务风险管理中的GUI代理框架 [PDF](https://arxiv.org/pdf/2509.21982), [HTML](https://arxiv.org/abs/2509.21982)
### Authors
Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen
### Background
电子商务风险管理需要汇总嵌入式的多样化网络数据，通过多步骤、状态依赖的交互，而传统的数据抓取方法和现有的图形用户界面（GUI）代理通常无法处理这种需求。这些代理通常限于单步骤任务，缺乏管理和处理动态交互内容的能力，这对于有效的风险评估至关重要。
### Innovation
该论文提出了RISK，一种新的框架，旨在构建和发展GUI代理以解决此问题。RISK包括三个组件：(1) RISK-Data，一个包含8,492个单步骤和2,386个多步骤交互轨迹的数据集，通过高保真浏览器框架和详尽的数据整理过程收集；(2) RISK-Bench，一个基准测试集，包含802个单步骤和320个多步骤轨迹，分成三个难度级别，用于标准化评估；(3) RISK-R1，一种综合四种方面的R1风格强化学习微调框架：输出格式，单步骤精度，多功能级中后期步骤重权和任务级别的难度重权。实验表明，RISK-R1优于现有基线，单步骤和多步骤分别提高了6.8%和8.8%，在线评估中实现了70.5%的任务成功率。RISK提供了一个可扩展、领域特定的解决方案，用于自动化复杂网络交互，推动了电子商务风险管理领域的前沿技术。
### Conclusion
RISK提供了一个可扩展、领域特定的解决方案，用于自动化复杂网络交互，对于电子商务领域的风险评估和管理具有重要意义。
## 28. `cs.AI` - 结构化稀疏转移矩阵以增强状态空间模型中的状态跟踪能力 [PDF](https://arxiv.org/pdf/2509.22284), [HTML](https://arxiv.org/abs/2509.22284)
### Authors
Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi
### Background
现代状态空间模型（SSM）通常采用转移矩阵来实现高效的计算，但这也限制了模型的表达能力，特别是在模拟有限状态自动机（FSA）方面。全结构化转移矩阵虽然可以提供最佳的表达能力，但其计算和内存成本非常高，特别是在状态数量中等时更为明显。论文提出了一种结构化的稀疏参数化方法，用于转移矩阵的参数化，这种方法可以在保持模型深度的同时，实现有限状态跟踪，并使计算开销和递归结构的计算成本保持在与对角线SSM相同的水平。
### Innovation
提出了PD-SSM方法，参数化转移矩阵为柱状单热矩阵（P）和复数对角矩阵（D）的乘积。这种方法实现了与FSA的状态跟踪相匹配的最佳状态大小和深度，同时递归计算的成本与对角线SSM相当。理论分析表明，这种模型是BIBO稳定的，并能以维度为N的一层和大小为N×N的线性读出模拟任何N状态的FSA，性能超越了现有的所有结构化SSM保证。实验结果表明，模型在FSA状态跟踪任务上显著优于多种现代SSM变种，并且在多类时间序列分类任务上可以达到与神经控制微分方程相当的性能。
### Conclusion
提出的PD-SSM方法能够有效跟踪复杂FSA的状态，适用于状态转移编码为一系列变长英语句子的混和Transformer-SSM架构。相关代码可以在指定网址获取。
## 29. `cs.AI` - 足底压力异常检测：统计参数映射和可解释机器学习的人本比较 [PDF](https://arxiv.org/pdf/2509.21943), [HTML](https://arxiv.org/abs/2509.21943)
### Authors
Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich
### Background
足底压力地图在临床诊断和运动科学中至关重要，但大量异质数据集中常含有由技术错误或程序不一致引起的离群值。统计参数映射（SPM）提供了可解释的分析，但对对齐敏感，其对稳健离群值检测的能力尚不明确。本研究旨在通过将SPM方法与可解释机器学习（ML）方法进行比较，以建立透明的质量控制管道来处理足底压力数据集。数据来自多个中心，并通过专家共识进行标注，同时还添加了合成异常，产生了798个有效样本和2000个离群值。研究评估了(i) 一种非参数、基于对齐的SPM方法和(ii) 一种解释性的卷积神经网络（CNN），以SHapley Additive exPlanations (SHAP) 进行解释。采用嵌套交叉验证评估了模型性能，通过领域专家的语义差异调查评估解释质量。研究发现SPM方法错误分类了具有临床意义的差异，并未能识别真正的离群值。尽管SPM和SHAP解释都被认为清晰、有用且可靠，但专家认为SPM更为复杂。这些发现强调了在自动检测足底压力数据中的离群值时整合SPM和可解释的ML方法的潜在互补性，并突显了在将复杂模型输出转化为可解释的见解以有效支持决策中的透明性的重要性。
### Innovation
本文研究将SPM方法与可解释机器学习方法进行比较，以建立透明的质量控制管道处理足底压力数据集。并通过嵌套交叉验证评估了模型性能和通过领域专家的语义差异调查评估解释质量。这种方法学的创新点在于它不仅比较了两种技术的性能，还通过专家反馈分析了解释的清晰度与复杂性，提供了更全面的方法论参考。此外，研究还深化了对SPM在处理离群值问题上的局限性的理解，并揭示了结合SPM与可解释机器学习的潜力。
### Conclusion
本研究比较了统计参数映射和可解释机器学习方法在足底压力数据中的离群值检测能力，并通过详细评估指出，可解释机器学习方法在性能上优于统计参数映射方法。虽然两种方法都被认为能够提供清晰且有用的解释，但可解释机器学习方法在避免误分类方面的表现更佳。这些发现强调了在足底压力数据检测中整合使用SPM和其他机器学习技术的潜在互补性以及提高模型解释性的必要性。
## 30. `cs.AI` - 思维光谱：通过模型融合实现可调推理能力的大语言模型研究 [PDF](https://arxiv.org/pdf/2509.22034), [HTML](https://arxiv.org/abs/2509.22034)
### Authors
Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li
### Background
大语言模型（LLMs）在众多实际应用中的需求日益增长，这些应用要求这些模型具有可调节的推理能力。目前，方法亟需高效地生成不同推理深度和计算成本之间的平衡模型。模型融合作为一种无需重新训练的技术，通过算术组合通用模型和专门推理模型的权重，被视为一种有潜力的解决方案。尽管存在多种融合技术，但它们能否提供对推理能力的微调控制尚未被充分探索。为了填补这一空白，该研究进行了大规模实证研究，评估了多种模型融合技术在多个推理基准测试中的表现，以系统地探讨模型融合在准确性和效率之间的可调性能表现。
### Innovation
该研究首次系统性地评估了多种模型融合技术在多类推理基准上的表现，构建了准确性和效率曲线，提供了对可调性能空间的全面视角。研究发现，模型融合可以有效且可控地调节推理准确性与标记效率之间的权衡，即使亲本模型的权重空间有很大差异。此外，研究还发现了一些帕累托改进的实例，即融合模型在准确性和标记消耗上都优于其单亲模型。这项研究提供了一套全面的分析，以指导创建具有特定推理配置文件的LLMs，以满足各种应用需求。
### Conclusion
研究展示了模型融合作为一种有效且可控的方法，可以调节推理准确性和标记效率之间的权衡。它提供了对可调性能空间的首次全面分析，为创建具有特定推理配置文件的LLMs提供了实用指南，以适应不同的应用需求。
## 31. `cs.AI` - 作为非确定性因果模型的语言大模型 [PDF](https://arxiv.org/pdf/2509.22297), [HTML](https://arxiv.org/abs/2509.22297)
### Authors
Sander Beckers
### Background
近期，Chatzi 以及 Ravfogel 等人的研究首次开发了一种生成概率性大型语言模型 (LLM) 反事实的方法。这些反事实揭示了如果某个事实提示 x 变为 x*，LLM 的输出会是什么或可能是什么。这项能力对于解释、评估和比较 LLM 的行为至关重要。然而，现有方法基于对 LLM 的模糊解释：该方法假设可以不改变 LLM 本身就能改变其采样过程的实现，并且将 LLM 显式地表示为一个确定性因果模型违背了其初衷。因此，作者提出了一个新的基于 LLM 的预期解释（作为非确定性因果模型）的更简单方法，无需修改即可应用于任何黑盒 LLM，且不受任何实现细节的影响。现有的方法虽然功能特定，但对某些应用很有帮助，但不一定适用于所有情况。
### Innovation
作者提出了一种基于 LLM 的预期解释的新方法，即将其表示为一个非确定性因果模型，简化了生成反事实的方法。该方法能够直接应用于任何黑盒 LLM 而无需修改，并且对任何实现细节都保持无关
### Conclusion
作者通过提供一种基于 LLM 预期语义来推理反事实的理论基础，为新型应用特定的反事实生成方法奠定了基础
## 32. `cs.AI` - Log2Plan: 结合任务挖掘方法的自适应GUI自动化框架 [PDF](https://arxiv.org/pdf/2509.22137), [HTML](https://arxiv.org/abs/2509.22137)
### Authors
Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim
### Background
GUI任务自动化可以简化重复任务，但现有的基于LLM或VLM的计划执行代理在泛化能力、响应延迟和长期连贯性方面存在不足。这些代理依赖于单次推理或静态计划，在界面变化或复杂任务情况下表现脆弱。
### Innovation
Log2Plan通过结合结构化的多层次规划框架和基于用户行为日志的任务挖掘方法，解决了这些限制。它通过将用户命令映射到结构化的任务字典来构建高级规划，同时通过识别用户特定模式支持个性化和重用。此外，它通过解释实时的GUI上下文来将高级计划落地为低级操作序列，确保跨不同界面的稳健执行。
### Conclusion
我们在200个实际任务上评估了Log2Plan，展示了任务成功率和执行时间的显著改善。更重要的是，它在长时序任务序列中仍能保持超过60.0%的成功率，凸显了其在复杂多步工作流程中的鲁棒性。
## 33. `cs.AI` - A2R: 异构双阶段推理框架用于并行推理 [PDF](https://arxiv.org/pdf/2509.22044), [HTML](https://arxiv.org/abs/2509.22044)
### Authors
Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen
### Background
近期的大规模推理模型通过“思考更长”的方式在推理阶段投入更多计算，显著提升了复杂任务解决能力。然而，模型的实际性能与潜在能力之间仍然存在差距，尤其是在单次尝试与多路径解题时表现的差异尤为明显。此论文旨在解决这一问题，提出了 A2R 作为一种插件式并行推理框架，专门用于增强模型在复杂问题上的能力。该框架由探索者模型与合成者模型两阶段组成，前者通过多次采样生成潜在解决方案，后者进行更细化的推理整合。这种方法使计算可以在不依赖现有顺序方法的情况下横向扩展。
### Innovation
首先，A2R 是一种插件式的并行推理框架，可以明确提升模型在复杂问题上的能力。例如，使用该框架后，Qwen3-8B-distill 模型相对于其一致性基线实现了 75% 的性能提升。其次，通过对探索者和合成者角色的系统分析，论文发现了有效的非对称扩展范式，引导开发了 A2R-Efficient 一种‘小到大’的变体，使用 Qwen3-4B 探索者与 Qwen3-8B 合成者结合，相比单体的 Qwen3-32B 模型，这一配置不仅表现更优且成本降低了约 30%。
### Conclusion
A2R 不仅是一个性能增强框架，也是一种在实际应用中高效且实用的解决方案。
## 34. `cs.AI` - 临床不确定性影响机器学习评估 [PDF](https://arxiv.org/pdf/2509.22242), [HTML](https://arxiv.org/abs/2509.22242)
### Authors
Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly
### Background
临床数据集的标签经常存在不确定性，因为不同注释者之间存在分歧且对同一案例的置信度分布不均。传统的聚合方法，如多数票决定，会掩盖这种变异。简单实验表明，考虑二分类标签的置信度显著影响模型的排名。因此，提出应在机器学习评估中明确考虑注释不确定性，使用可以直接作用于概率分布的度量标准，这些度量标准不受标注过程的简化、主观置信评分或概率响应模型的影响，且计算上也很轻量，因为具有线性时间实现的经验表达式在按模型评分排序示例后再进行计算即可实现。
### Innovation
提出明确考虑注释不确定性，在机器学习评估中使用可以直接作用于概率分布的度量标准，并且这些度量标准可以在不依赖标注过程模型的情况下应用，同时具有计算上高效的特点。
### Conclusion
建议研究社区释放原始注释，采用考虑不确定性的评估方法，以更准确地反映临床数据的性能估算。
## 35. `cs.AI` - 通过目标聚合函数泛化多目标搜索 [PDF](https://arxiv.org/pdf/2509.22085), [HTML](https://arxiv.org/abs/2509.22085)
### Authors
Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman
### Background
多目标搜索（MOS）在机器人领域变得日益重要，因为实际的机器人系统需要同时平衡多个，通常是冲突的目标。近期研究表明，目标间的复杂交互导致现有的MOS算法无法直接应用。现有的MOS算法无法处理这些复杂情况，因为它们填充了无法直接应用那些算法的目标间的相互作用。这项研究提出了一种新的通用问题表述，通过隐藏（搜索）目标的聚合函数来优化解决方案目标。此表述支持标准MOS算法的应用，只需要适当扩展核心操作以反映所使用的特定聚合函数即可。该团队在导航、操作、医疗系统下的障碍不确定性以及检查计划和不同道路类型的路线规划等多个多样化机器人规划问题中展示了该方法。他们使用扩展后的核心操作的最新MOS算法来解决这些问题，并提供了实验证据，表明这些算法在具有目标聚合的情况下比在相同问题上仅使用原版算法的性能提高了一个数量级以上。
### Innovation
这项研究提出了一种新的通用问题表述，通过隐藏（搜索）目标的聚合函数来优化解决方案目标。此表述支持标准MOS算法的应用，只需要适当扩展核心操作以反映所使用的特定聚合函数即可。这个方法不仅适用于多个不同的机器人规划问题，而且能够显著提高算法的性能。
### Conclusion
该研究展示了通过隐藏目标聚合函数的新通用问题表述方法在解决多样化的机器人规划问题上的有效性。使用这个方法的最新MOS算法在具有目标聚合的情况下能够显著超过不使用目标聚合的原版算法，并提供了大幅度性能提升的实验证据。
## 36. `cs.AI` - PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning [PDF](https://arxiv.org/pdf/2509.22315), [HTML](https://arxiv.org/abs/2509.22315)
### Authors
Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu
### Background
该研究受到人类认知过程的双重过程理论（Thinking, Fast and Slow）启发，探讨了如何通过多智能体框架优化语言模型的推理能力。
### Innovation
PRIME框架通过整合快速直观思考（System 1）和深思熟虑的思考（System 2），实现了一个可以快速生成初步答案，必要时进一步进行详细推理的机制。这一设计不仅模仿了人类的认知过程，还增强了推理的效率和准确性。
### Conclusion
实验结果显示，PRIME能够使开源的语言模型在多步推理和基于知识的推理基准测试中与最先进的闭源模型（如GPT-4和GPT-4o）竞争。这证实了PRIME在提高面对复杂、知识密集型推理问题的语言模型性能方面是一种可扩展的解决方案。
## 37. `cs.AI` - 使用视觉语言模型指导人工生命进化的研究 [PDF](https://arxiv.org/pdf/2509.22447), [HTML](https://arxiv.org/abs/2509.22447)
### Authors
Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser
### Background
基础模型（FMs）已经为人工生命（ALife）领域带来了新的前沿，提供了自动搜索ALife模拟的强大工具。以前的工作是通过视觉语言模型（VLMs）将ALife模拟与自然语言的目标提示相匹配。在此基础上，研究团队在ASAL的基础上开发了ASAL++，通过多模态FMs引导开放搜索，使用第二个FM根据模拟的视觉历史提出新的进化目标，从而引导出越来越复杂的进化轨迹。
### Innovation
ASAL++引入了两种策略：（1）每个迭代生成一个新的视觉目标（Evolved Supervised Targets: EST）；（2）每个迭代生成一系列视觉目标并使其匹配（Evolved Temporal Targets: ETT）。通过实验研究并在Lenia平台上使用Gemma-3进行演示，研究表明EST促进了更高维度的视觉新颖性，而ETT促进了更连贯和可解释的进化序列。
### Conclusion
研究结果表明，ASAL++在FM驱动的人工生命发现方面指出了具有开放性特性的新方向。
## 38. `cs.AI` - GeoSketch：一种借助辅助线构造和仿射变换进行几何多模态推理的神经-符号方法 [PDF](https://arxiv.org/pdf/2509.22460), [HTML](https://arxiv.org/abs/2509.22460)
### Authors
Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu
### Background
几何问题解决(GPS)对多模态大型语言模型(MLLMs)构成了独特的挑战，不仅需要联合解析文本和图表，还需要进行迭代的视觉空间推理。现有的方法将图表处理为静态图像，但是它们缺乏动态操作的能力——这对于人类几何推理来说是核心方面，涉及辅助线构造和仿射变换。
### Innovation
GeoSketch 提出了一种神经-符号框架，重构几何推理为一个感知-推理-行动互动循环。它结合了：(1)用于抽象出图表到结构逻辑形式的感知模块；(2)应用几何定理来决定下一步推理的符号推理模块；(3)执行绘制辅助线或应用变换的绘图行动模块，从而在封闭循环中更新图表。此外，GeoSketch 开发了一个两阶段训练管道：监督微调 2000 条符号集萃轨迹，然后通过密集的符号奖励进行强化学习，以增强鲁棒性和战略性探索。为此，作者还引入了一个新的基准测试集（GeoSketch Benchmark），包含390个需要构造辅助线或仿射变换的几何问题。
### Conclusion
实验表明，GeoSketch 在步骤推理准确性和问题解决成功率方面显著改进了基于静态感知的方法。通过统一层次决策、可执行视觉操作和符号验证，GeoSketch 将多模态推理从静态解释推进到动态、可验证的交互，为解决复杂的空间问题奠定了新的基础。
## 39. `cs.AI` - 验证AI能耗的真实情况：将CodeCarbon与外部测量进行校准 [PDF](https://arxiv.org/pdf/2509.22092), [HTML](https://arxiv.org/abs/2509.22092)
### Authors
Raphael Fischer
### Background
虽然机器学习（ML）和人工智能（AI）为创新带来了巨大的机遇，但它们的快速发展也对环境产生显著影响。因此，为了提高资源意识，开发了如ML排放计算器和CodeCarbon等量化工具来估算运行AI模型的能耗和碳排放。尽管这些工具易于集成到AI项目中，但在实际应用中也存在一些假设和忽略的重要因素，使得能耗估算的准确性受到质疑。这项研究通过将数百个AI实验的结果与实际测量数据进行比较，系统评估了静态和动态能耗估算方法的可靠性，提供了关于AI能耗需求和估算不准确性的探究性见解。
### Innovation
该研究提出了验证框架，通过将数百个AI实验与实际测量数据进行比较，系统评估了静态和动态能耗估算方法的可靠性，提供了关于AI能耗需求和估算不准确性的探究性见解。研究发现，目前广泛应用的估算方法在能耗估算上通常存在40%以上的误差。研究结果提供了实证证据，提高了能源估算质量的透明度，并为可持续AI开发验证了广泛使用的工具，同时提出了改进当前最佳实践的指导方针，并提供了扩展验证到其他领域和工具的代码，为资源意识的机器学习和AI可持续性研究做出了重要贡献。
### Conclusion
这项研究表明，目前用来估算AI能耗的各种方法存在显著误差，大多处于40%的误差范围。通过提供实证的能源估算质量评估，该研究提高了能源估算透明度，验证了广泛使用的监控工具，为行业提供了改进现有技术水平的指导，并为进一步验证和扩展其他领域提供了代码，是资源意识的机器学习和AI可持续性研究的重要贡献。
## 40. `cs.AI` - InfiMed-Foundation: 引领前沿高效计算预训练与多阶段微调的多模态医学模型 [PDF](https://arxiv.org/pdf/2509.22261), [HTML](https://arxiv.org/abs/2509.22261)
### Authors
Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang
### Background
多模态大型语言模型（MLLMs）在多个领域展现了显著的潜力，但其在医疗领域的应用受到几个挑战的阻碍。通用的MLLMs缺乏针对医疗任务的专业知识，导致无法产生确定性的响应。从高级模型的知识蒸馏难以捕捉放射学和药学领域的特定专业知识。此外，持续大规模医疗数据的预训练计算成本高昂，形成了效率挑战。这些问题限制了MLLMs在医疗领域应用的潜力和效果。现有的模型未能充分解决这些技术难题，导致在实际医学应用中表现欠佳，无法满足专业医疗需求。
### Innovation
本文提出了一种新的多模态医疗器械模型InfiMed-Foundation-1.7B和InfiMed-Foundation-4B，这两款模型专为医疗应用设计，达到了最先进的性能水平。该研究通过结合高质量的通用和医学多模态数据，并提出了一种新颖的五维度质量评估框架，来创建高质量的多模态医疗数据集。还采用了低到高的图像分辨率和多模态序列打包方法，以提高训练效率，使模型能够整合大量的医疗数据。此外，采用了三阶段的监督微调流程来确保有效提取复杂医疗任务的知识。相比于现有模型，InfiMed-Foundation-1.7B和InfiMed-Foundation-4B在医疗视觉问答和诊断任务上的表现更加优越，展示了在效率和效果上的显著改进。
### Conclusion
我们通过解决数据质量和训练效率，以及领域专业知识提取的关键挑战，为更可靠和有效的AI驱动的医疗解决方案铺平了道路。通过InfiMed-Foundation-4B模型，展示了在计算效率预训练和多阶段微调方面的重要进展。该模型已经在医疗视觉问答和诊断任务中达到了更高的标准，为未来医学应用中的多模态人工智能提供了新的可能性。
## 41. `cs.AI` - TrueGradeAI：具有透明性和可解释性的无偏见人工智能增强检索评估 [PDF](https://arxiv.org/pdf/2509.22516), [HTML](https://arxiv.org/abs/2509.22516)
### Authors
Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla
### Background
该论文介绍了TrueGradeAI，这是一种以人工智能驱动的数字化考试框架，旨在克服传统纸质评估的不足，包括过度使用纸张、复杂的后勤管理、评分延迟以及评分者偏见。传统的纸笔考试存在各种问题，而TrueGradeAI旨在通过保留手写自然性、捕获安全平板上的笔输入并运用以转换器为基础的光学字符识别技术实现数字化考试。
### Innovation
TrueGradeAI在前人基于平板的考试系统的基础上，进一步引入了解释性自动化、偏见缓解和可审计评分记录。该系统不仅数字化了答卷，还通过结合教师解决方案、缓存层和外部参考，采用检索增强的流水线实现评分，增强了评分过程的透明性和解释性。这使得大规模语言模型能够在评分过程中提供具体、与证据相关的推理。
### Conclusion
通过结合手写保留和可扩展、透明的评估，该框架减少了环境影响，加速了反馈周期，并逐步构建了一个可重复使用的知识库，同时积极努力减少评分偏见并确保评估的公平性。
## 42. `cs.AI` - Estimating the Empowerment of Language Model Agents [PDF](https://arxiv.org/pdf/2509.22504), [HTML](https://arxiv.org/abs/2509.22504)
### Authors
Jinyeop Song,Jeff Gore,Max Kleiman-Weiner
### Background
随着语言模型（LM）代理变得更为能力强，并且获得了更广泛的现实工具访问权限，需要开发可扩展的评估框架来测试这些AGI能力。然而，传统基于基准的评估方法成本高昂，需要人类设计师设计出有效的任务以转化为关于通用模型能力的洞察。
### Innovation
本文提出了一种基于信息论的评估方法——基于代理行为和未来状态之间互信息的扩展能力评估方法。引入了EELMA算法，用于从多轮文本交互中近似估算有效能力。验证EELMA方法在语言游戏和扩展的现实web浏览场景中，并研究了环境复杂度及代理因素等对估计能力的影响。
### Conclusion
研究结果表明，扩展能力与平均任务表现高度相关，定制后的能力状态和行为对泛化能力至关重要，证明扩展能力作为一种多用途评估标准在复杂、开放环境的评估和监控中具有吸引力。
## 43. `cs.AI` - UniMIC: 基于令牌的多模态交互编码方法及其在人机协作中的应用 [PDF](https://arxiv.org/pdf/2509.22570), [HTML](https://arxiv.org/abs/2509.22570)
### Authors
Qi Mao,Tinghan Yang,Jiahao Li,Bin Li,Libiao Jin,Yan Lu
### Background
大型多模态模型（LMMs）和基于云的AI代理的快速发展正在改变人类与AI的合作方式，使其向双向、多模态交互转变。然而，现有的编解码器仍然针对单一模态、单向通信进行了优化，在传统的压缩-传输-重构管道中重复降级。
### Innovation
提出了一种名为UniMIC的统一令牌基于多模态交互编码框架，用于连接边缘设备和云端AI代理。通过采用紧凑的令牌化表示作为通信媒介，UniMIC能够在保持与LMMs兼容性的前提下，实现高效的小比特率传输。此外，使用轻量级的基于Transformer的熵模型，根据具体情况设计（通用型、掩码、文本条件化）来最小化令牌间冗余。
### Conclusion
通过在文本到图像生成、文本指导的填充、扩展和视觉问答等任务中的广泛实验，结果显示UniMIC在保持下游任务性能的同时，实现了显著的比特率节省，并且即使在超低比特率（<0.05 bpp）下仍然保持了鲁棒性，从而确立了UniMIC作为下一代多模态交互通信的实用和前瞻性的范式的地位。
## 44. `cs.AI` - 语言模型规划中的强化学习优势与局限：一种理论视角 [PDF](https://arxiv.org/pdf/2509.22613), [HTML](https://arxiv.org/abs/2509.22613)
### Authors
Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen
### Background
近期，强化学习（RL）方法显著提高了大型语言模型（LLMs）的规划能力，但其有效性的理论基础仍不清楚。本文通过可处理的图基抽象，考察了RL的优势与局限，重点研究了策略梯度（PG）和Q学习方法。
### Innovation
本研究揭示了监督微调（SFT）可能导致基于共现的虚假解决方案，而RL主要通过探索实现正确的规划，强调探索在促进更好泛化中的作用。此外，研究还表明，PG会遭受多样性崩溃，输出多样性在训练过程中下降，并在准确率达到100%后仍然存在。相比之下，Q学习在收敛时提供了两个关键优势：离策略学习和多样性保持。进一步证实，精心设计的奖励设计在Q学习中预防奖励作弊是必要的。
### Conclusion
将本框架应用于实际世界规划基准Blocksworld后，证实了这些行为在实践中确实存在。
## 45. `cs.AI` - LLM代理知道如何确立根基、恢复以及评估吗？信息搜索代理的元认知能力基准 [PDF](https://arxiv.org/pdf/2509.22391), [HTML](https://arxiv.org/abs/2509.22391)
### Authors
Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo
### Background
近期研究探讨了使用强化学习(Reinforcement Learning, RL)训练大规模语言模型（Large Language Models, LLMs）搜索代理以进行开放式领域问题回答(Open-Domain Question Answering, QA)的方法。然而，大部分评估仅关注最终答案的准确性，忽视了代理如何利用和处理外部证据。本研究引入了SeekBench，这是首个通过细粒度分析搜索代理响应轨迹中的每一步来评估其元认知能力的基准。
### Innovation
研究引入了SeekBench，其首次通过追踪LLM搜索代理的响应步骤来评估其元认知能力，关注代理如何生成基于证据的推理步骤、适应性地重新调整搜索以从低质量结果中恢复，以及其对于当前证据是否足以给出答案的正确评估。基准包含190个专家标注的响应步骤，超过1,800步，每个步骤都附有证据标注以进行细粒度分析。
### Conclusion
SeekBench为评估搜索代理的元认知能力提供了一个新的工具，评估它们如何生成基于证据的推理步骤，适应性地重新调整搜索以克服低质量结果，并正确判断当前证据是否足以提供答案。
## 46. `cs.AI` - StepORLM：具有生成过程监督的自我演化框架用于运筹学语言模型 [PDF](https://arxiv.org/pdf/2509.22558), [HTML](https://arxiv.org/abs/2509.22558)
### Authors
Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge
### Background
大型语言模型（LLMs）在解决运筹学（OR）问题上展现了令人鼓舞的能力。虽然强化学习是LLM在OR问题训练中的强大范式，但现有工作通常面临两个关键限制：一是结果奖励的因果归因问题，正确最终答案可能会强化错误的推理；二是传统的鉴别性过程监督是短视的，不能全面评估OR建模中的各步骤的相互依赖性。
### Innovation
我们提出了StepORLM，这是一种新颖的自我演化框架，带有生成过程监督。核心特点是一个共生演化循环，其中策略模型和生成过程奖励模型（GenPRM）互相改进。这一循环通过双重反馈机制驱动：来自外部求解器的明确结果验证和来自GenPRM的细腻的整体过程评估。结合信号用于通过加权直接偏好优化（W-DPO）对策略进行对齐，并同时细化GenPRM。最终，这种方式产生的8B参数的StepORLM在六个基准测试中创造了新的最先进技术状态，显著优于大型通用模型、智能体方法和专门基准。此外，共生演化的GenPRM能够作为一个强大的、普遍适用的过程验证器，显著提升了我们自己的模型和现有其他LLM的推理扩展性能。
### Conclusion
StepORLM在多个基准测试中表现出色，显著优于现有方法，特别是在处理OR问题的生成过程中提供了全面和精细的监督，通过自演化机制不断优化策略和过程模型，有效地解决了因果归因和过程评估的难题。
## 47. `cs.AI` - PIR-RAG：基于检索增强生成的隐私信息检索系统 [PDF](https://arxiv.org/pdf/2509.21325), [HTML](https://arxiv.org/abs/2509.21325)
### Authors
Baiqiang Wang,Qian Lou,Mengxin Zheng,Dongfang Zhao
### Background
检索增强生成（RAG）已经成为现代AI系统的基础组件，但却引入了显著的隐私风险，因为它将用户查询暴露给服务提供商。为了应对这一问题，本文提出了一种名为PIR-RAG的隐私保护系统。
### Innovation
PIR-RAG采用了一种新颖的设计架构，结合了粗粒度语义聚类来精简搜索空间，以及一种快速的基于格的隐私信息检索（PIR）协议。这种设计使得能够高效地检索整个文档集群，并且在从始至终的RAG流程中优化了完全文档内容的需求。
### Conclusion
通过对包括基于图的PIR和Tiptoe风格的私人评分在内的强大基线架构进行全面评估，证明了PIR-RAG在扩展性和性能方面具有优势，特别是在所谓的'RAG-Ready Latency'方面，即用于安全获取语言模型所需内容的真正端到端时间。本文证明了PIR-RAG是一种可行且高效的隐私保护解决方案，适用于大规模AI系统。
## 48. `cs.AI` - InfiAgent：无限场景下的自我进化的金字塔型代理框架 [PDF](https://arxiv.org/pdf/2509.22502), [HTML](https://arxiv.org/abs/2509.22502)
### Authors
Chenglin Yu,Yang Yu,Songmiao Wang,Yucheng Wang,Yifan Yang,Jinjia Li,Ming Li,Hongxia Yang
### Background
大型语言模型（LLM）代理在组织和执行复杂任务方面展示了显著的能力，并被广泛应用于各种应用场景中。然而，开发这些代理需要精心设计的工作流、精心设计的提示以及迭代调优，这要求有出色的LLM技术和特定领域的专业知识。这种方法手工作坊的限制性阻碍了LLM代理在各行各业中的可扩展性和成本效益。为解决这些挑战，本文提出InfiAgent，这是一种基于多代理的层级结构多代理框架，适用于广泛的无限场景。
### Innovation
InfiAgent引入了几个关键创新点：一种泛化的“代理作为工具”机制，能够自动将复杂的代理分解为分层多代理系统；一种双审核机制，确保任务完成的质量和稳定性；一种代理路由功能，能够实现高效的任务-代理匹配；以及一种代理自我进化机制，能够根据新任务、性能不佳或优化机会自主重构代理层级结构。此外，InfiAgent的原子任务设计支持代理并行性，显著提高执行效率。
### Conclusion
InfiAgent框架演变成一种多功能的金字塔型多代理系统，能够解决各种问题。在多个基准上的评估表明，InfiAgent在性能上比ADAS（类似自动化生成代理框架）高出9.9%，而对AI研究助手InfiHelper的案例研究则表明，它生成的科学论文已经从顶级IEEE会议的人类评委那里获得了认可。
## 49. `cs.AI` - 从搜索到推理：面向企业数据的五级RAG能力框架 [PDF](https://arxiv.org/pdf/2509.21324), [HTML](https://arxiv.org/abs/2509.21324)
### Authors
Gurbinder Gill,Ritvik Gupta,Denis Lusson,Anand Chandrashekar,Donald Nguyen
### Background
检索增强生成（RAG）已成为在企业数据上回答问题的标准范式。传统上，RAG集中于基于文本的语义搜索和重新排序，但在处理超出数据汇总或非文本数据的问题时显得力不从心。为了弥合RAG与实际预期的查询问题之间的问题，现有研究试图从不同角度增强RAG。尽管当今的RAG是一系列技术的集合而非一种明确的实现，但基于问题的理解有助于讨论RAG及其相关问答系统。
### Innovation
本文提出了一种新的五级分类框架（L1-L5）来分类基于数据模态和问题复杂度的系统，并引入了与其相应的基准测试。该框架将系统分为表面知识、推理和逻辑推理、以及前瞻性的通用智能。研究还通过实验评估了四个先进平台：LangChain、Azure AI Search、OpenAI和Corvic AI，并验证了多空间检索和动态编排在增强L1-L4能力方面的重要性。
### Conclusion
实验结果表明，多空间检索和动态编排对于促进L1-L4级别的能力有着重要的价值。通过多元的数据集，研究进一步实证验证了这些发现，强调了新框架的有效性及其对企业数据问答系统的指导意义。
## 50. `cs.AI` - EMMA: 通过生成视觉转移实现机器人实际应用任务的泛化 [PDF](https://arxiv.org/pdf/2509.22407), [HTML](https://arxiv.org/abs/2509.22407)
### Authors
Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang
### Background
视觉-语言-行动（VLA）模型越来越多地依赖多样化的训练数据以实现鲁棒性的泛化。然而，收集能够覆盖多样物体外观和环境条件的大型真实世界机器人操作数据仍然是时间成本高且昂贵的任务。为了解决这个问题，我们提出了Embodied Manipulation Media Adaptation (EMMA)，一种将生成数据引擎与有效的训练管道相结合的VLA增强框架。EMMA通过DreamTransfer框架生成高质量的多视角一致、几何基础的机器人操作视频，满足手势控制的视觉编辑要求，同时不损害三维结构和几何合理性。此外，我们还研究了真实数据和生成数据的混合训练，并引入了AdaMix，一种针对感知或动态学挑战样本动态重新加权的训练策略，以优化过程中强化重点。
### Innovation
EMMA引入了一种基于扩散Transformer的DreamTransfer框架，用于生成多视角一致且几何可靠的机器人操作视频。通过DreamTransfer，用户可以对机器人视频进行文本控制的视觉编辑，同时不会影响三维结构或几何合理性。此外，我们的研究引入了Hybrid训练方法和AdaMix策略，以实现在真实数据和生成数据之间的有效平衡，进一步提高模型的泛化能力。实验结果表明，DreamTransfer生成的视频在多视角一致性、几何精度和文本条件准确性方面显著优于之前的视频生成方法。基于生成数据训练的VLA能够使机器人仅凭单一外观的示范就能泛化到未见过的物体类别和新的视觉领域。在零样本视觉域的实际机器人操作任务中，我们的方法表现比仅使用真实数据训练提高了200%以上，同时AdaMix进一步提高了13%，证明了在提升策略泛化方面潜力巨大。
### Conclusion
EMMA有效解决了收集大规模真实世界机器人操作数据的挑战，并通过引入DreamTransfer、Hybrid训练方法和AdaMix策略，显著提升了VLA模型在未见过的视觉领域和新物体类别上的泛化能力。实验证明，在实际机器人操作任务中，我们的方法能实现显著的性能提升，尤其是在零样本条件下。
## 51. `cs.AI` - 动态专家搜索：提升Mixture-of-Experts大规模语言模型推理能力的测试时策略 [PDF](https://arxiv.org/pdf/2509.22572), [HTML](https://arxiv.org/abs/2509.22572)
### Authors
Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang
### Background
Test-Time Scaling (TTS) 提高了大语言模型（LLMs）的推理能力，通过在推理时分配额外的计算资源。主流的Mixture-of-Experts (MoE) LLMs中，激活多个专家的数量变化提供了稳定准确性的互补解集，揭示了未充分探索的多样性来源。现有方法主要依赖于输出层面的采样，而忽略了模型架构的作用。
### Innovation
提出了动态专家搜索（Dynamic Experts Search，DES）策略，这是一种TTS方法，将专家激活变为搜索空间中的可控维度。DES包含两个关键组件：动态MoE和专家配置继承。动态MoE在推理时直接控制专家数量，从而生成多样的推理轨迹而无需增加成本；专家配置继承保持推理路径内的专家数量一致，在不同运行中可变，从而在整个搜索过程中平衡稳定性和多样性。
### Conclusion
跨MoE架构、验证器和推理基准（如数学、代码和知识）的广泛实验表明，DES在不增加额外成本的情况下，比现有TTS基准更为稳健，提高了准确性和稳定性。这表明DES是一种实用且可扩展的大规模语言模型架构感知TTS形式，展示了现代LLM结构灵活性如何促进推理能力的提高。
## 52. `cs.AI` - SGNNBench：大规模图上的脉冲图神经网络综合评估 [PDF](https://arxiv.org/pdf/2509.21342), [HTML](https://arxiv.org/abs/2509.21342)
### Authors
Huizhe Zhang,Jintang Li,Yuchang Zhu,Liang Chen,Li Kuang
### Background
Graph Neural Networks (GNNs)在图数据处理中表现出色，通过消息传递机制能有效捕获图拓扑结构，但其复杂性限制了其在大规模图上的应用，尤其是计算和时间开销较大。为了解决这一问题，研究人员提出了Spiking Graph Neural Networks (SGNNs)，这种网络通过模仿生物学上可行的学习方式，利用基于脉冲的神经元进行计算，具有更高的能源效率。尽管近年来SGNNs的发展迅速，但缺乏一个系统性的基准来评估这些激励神经网络设计的基本原理。
### Innovation
提出了SGNNBench，这是一种系统性的基准评估框架，用于评估SGNNs在大规模图上的表现。SGNNBench从有效性、能源效率和架构设计等多角度深入研究了9种前沿的SGNNs，并通过实证对比模型大小、内存使用和理论能源消耗，揭示了SGNN的能源瓶颈，同时扩展了SGNN的设计空间，促进了通用的SGNN范式的开发。
### Conclusion
通过SGNNBench的研究，揭示了SGNNs在处理大规模图时存在的能源效率瓶颈，并通过对比分析展示了SGNNs的设计和实现特征。SGNNBench为后续SGNNs的设计提供了理论依据，推动了研究领域向更加通用的SGNN范式的演进。
## 53. `cs.AI` - 大型语言模型社会中利他行为的 emergence [PDF](https://arxiv.org/pdf/2509.22537), [HTML](https://arxiv.org/abs/2509.22537)
### Authors
Haoyang Li,Xiao Jia,Zhanzhan Zhao
### Background
在计算社会科学中，利用大规模语言模型（LLMs）进行社会模拟是一个前沿领域。理解这些代理所体现的社会逻辑对于这一尝试至关重要。然而，现有的研究主要集中在小规模、任务导向的游戏中的合作，而忽略了大规模代理社会中利他行为（即为集体利益牺牲个人利益的行为）的出现机制。这项研究旨在填补这一研究空白，通过引入一种舍勒模型变体的都市移民模型，创造了一个社会困境，使得超过200个LLM代理在个人利益和集体利益之间的冲突中进行博弈，以探索不同LLM之间的内在异质性。
### Innovation
这项研究的主要创新之处在于：1) 通过引入舍勒模型变体的都市移民模型，揭示了LLMs在大规模代理社会中利他行为的出现机制；2) 识别出两大类不同类型的代理：适应性利己者和利他优化器，并揭示了它们在社会规范设置的论坛影响下的行为变化；3) 提出了新的方法，即基于理论的编码体系，系统分析代理的决策思维过程。这项研究提供了关于不同LLM的内在异质性及其社会行为逻辑的第一手证据，挑战了以往仅仅关注认知能力的模型选择观点，提出了应根据不同的社会行动逻辑选择模型的重要性。
### Conclusion
这项研究的主要结论是不同类型的LLM在面对社会冲突时表现出不同的内在偏好差异。适应性利己者在没有外界影响时倾向于优先考虑个人利益，但在社会规范的引导下可增强其利他行为；而利他优化器则天生具有集体福利优先的逻辑，即使对个人造成直接损失也会优先考虑。对于社会模拟而言，模型选择不应仅依赖于推理能力，而是要考虑到内在的社会行动逻辑。具有适应性利己倾向的模型可能更适合模拟复杂的人类社会，而具有利他优化倾向的模型则更适合模拟理想化的亲社会行为或主要考虑集体福利的情景。
## 54. `cs.AI` - 基于领域信息的遗传叠加编程：SFRC梁的一种案例研究 [PDF](https://arxiv.org/pdf/2509.21355), [HTML](https://arxiv.org/abs/2509.21355)
### Authors
Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi
### Background
本文介绍了一种针对受分离物理机制支配的工程系统进行符号回归的框架——领域导向遗传叠加编程（DIGSP）。此框架主要用于探索和建模材料特定效应。研究基于钢纤维增强混凝土（SFRC）梁的数据集进行了实证分析。
### Innovation
提出了适应性层次符号抽象机制（AHSAM），这是一种用于处理停滞的符号叠加方法。AHSAM通过ANOVA分析筛选统计显著的个体，并将它们压缩为符号构建并注入多个种群中，以促进种群间的合作。
### Conclusion
DIGSP在训练和测试集的均方根误差（RMSE）上都显著优于基准模型BGP，并通过Wilcoxon秩和检验验证了这种优越性。研究结果表明，领域导向的结构分解和符号抽象能够提高收敛性和泛化能力。此外，DIGSP为那些符号叠加与物理结构相符的系统提供了一种结构化且可解释的建模策略。
## 55. `cs.AI` - 一种有效的幻觉检测和分类的新型差异特征学习 [PDF](https://arxiv.org/pdf/2509.21357), [HTML](https://arxiv.org/abs/2509.21357)
### Authors
Wenkai Wang,Vincent Lee,Yizhen Zheng
### Background
大型语言模型的幻觉构成了一个关键挑战，因为它们的输出由于训练数据中的分布偏见偏离了事实准确性。最近的研究表明，某些隐藏层在幻觉和事实内容之间存在差异，但幻觉信号在层内的具体本地化仍然不清楚，限制了高效检测方法的发展。
### Innovation
提出了一种双模型架构，结合了适应性跨层特征加权的投影融合（PF）块和差异特征学习（DFL）机制，能够通过计算来自同一输入互补表示的并行编码器之间的差异来识别区分性特征。实验证明，幻觉信号集中在高度稀疏的特征子集中，这在问答和对话任务中实现了显著的准确性提升。分析揭示了一种层次的“漏斗模式”，即浅层具有高特征多样性，而深层具有集中的使用情况，仅用1%的特征维度也可以维持与明显降级的检测性能。
### Conclusion
研究表明，幻觉信号比以前认为的更加集中，这为实现计算上高效且成本降低的检测系统提供了途径，同时保持准确性。
## 56. `cs.AI` - 用柯西-施瓦茨偏差进行跨模态检索 [PDF](https://arxiv.org/pdf/2509.21339), [HTML](https://arxiv.org/abs/2509.21339)
### Authors
Jiahao Zhang,Wenzhe Yin,Shujian Yu
### Background
有效的跨模态检索需要不同数据类型之间的稳固对齐。现有方法主要集中在双模式检索任务上，并依赖于如Kullback-Leibler散度、最大均值差异和相关对齐的分布对齐技术。然而，这些方法存在诸如数值不稳定、对超参数敏感以及难以捕捉潜在分布的结构完整性的局限性。
### Innovation
本文引入了柯西-施瓦茨(CS)偏差，这是一种无参数的度量，可以提高训练稳定性和检索性能。进一步提出了受Hölder不等式启发的广义柯西-施瓦茨(GCS)偏差，该方法可以基于双向循环比较方案直接对齐三个或更多的模态，而无需进行耗时的两两比较。
### Conclusion
在六个基准数据集的广泛实验中，证明了该方法在双模式和三模式检索任务中的有效性。我们的CS/GCS偏差的代码在https://... 公开可用。
## 57. `cs.AI` - REMA：一种用于解释大语言模型的统一推理流形框架 [PDF](https://arxiv.org/pdf/2509.22518), [HTML](https://arxiv.org/abs/2509.22518)
### Authors
Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen
### Background
理解大型语言模型（LLMs）在复杂推理中的表现及其失败机制是对解释性研究的一个挑战。本文提出了推理流形的概念，这是一种潜在于低维几何结构，由与所有正确推理生成物相对应的内部表示形成。基于这一概念，构建了REMA框架，通过定量比较错误和正确推理样本的内部模型表示的空间关系来解释失败的原因。
### Innovation
提出了推理流形的概念，并基于此构建了REMA框架。REMA框架通过计算每个错误表示的k-最近邻居距离来量化其与正确表示组成的近似流形的几何偏差，从而提供了一个统一的失败信号。它还通过追踪这一偏差指标并将其与正确表示的内部波动基准进行比较，来定位偏差首次变得显著的分离点，从而识别推理链开始偏离的点。
### Conclusion
在多样化的语言和多模态模型及任务上的实验表明，推理流形是低维的，并且错误和正确推理表示之间具有良好的可分性。结果验证了REMA框架在分析推理失败的源头方面的有效性。这项研究将抽象的推理失败与表示中的可测量几何偏差联系起来，为深入理解和诊断黑箱模型的内部计算过程提供了新的途径。
## 58. `cs.AI` - 从嵌入到方程：基于遗传编程的可解释变换器分类代理 [PDF](https://arxiv.org/pdf/2509.21341), [HTML](https://arxiv.org/abs/2509.21341)
### Authors
Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi
### Background
该研究旨在通过符号代理模型来简化和验证Transformers的嵌入表示，从而获得紧凑且可审计的分类器，并且能够校准概率。研究通过分析多个基准数据集上的嵌入，利用了语义保持特征分割（SPFP）技术，以及进化多人群遗传程序（MEGP）来学习嵌入上的加性、封闭形式的逻辑程序。
### Innovation
该研究提出了通过遗传编程从嵌入生成方程的方法，具体创新点包括：1. 使用语义保持特征分割法对训练集的嵌入进行无交集、信息保留的分割；2. 使用进化多人群遗传程序来学习这些分割上的加性封闭形式逻辑程序；3. 通过温度缩放的方法显著降低预期校准误差；4. 提供了用于解释的可靠性图、维度使用和重叠度统计、贡献度重要性以及全局效应概况。
### Conclusion
最终生成的代理模型能够在多个基准数据集上实现较强的分类性能（如MNIST、CIFAR10、MSC17上的F1分数接近0.99，SST2G上接近0.95），同时保持高可靠性和可解释性。虽然20NG数据集仍然是最具挑战性的一个。研究通过各种分析提供了可靠的、跨模式的解释，这些解释基于显式的程序基础。
## 59. `cs.AI` - 循环即为一切：复杂即为简单 [PDF](https://arxiv.org/pdf/2509.21340), [HTML](https://arxiv.org/abs/2509.21340)
### Authors
Xin Li
### Background
该研究建立在一个信息拓扑框架上，其中循环闭合被认为是记忆和意识的基本机制。传统上，记忆被看作是一个静态存储的过程，而该研究提出了一种新的视角，认为记忆实际上是重新进入神经态空间中的潜在循环的能力，不变循环作为意义载体，通过筛选特定顺序的噪声并保留跨越上下文的持久内容，来维护记忆中的不变性。
### Innovation
该论文的主要创新在于提出了一种信息拓扑框架，该框架将循环闭合视为记忆和意识的基础机制。文中还提出了“点-循环二分法”，并解释了多时间尺度的神经群体如何通过STDP（突触长时程增强）实现1-循环，并且在theta-γ节律内进行边界消解，进而构建层次化的微循环来扩展导航循环，转化为普遍记忆和认知。
### Conclusion
该研究总结指出，循环是实现一切的机制。持久的不变性使得在非遍历环境中能够进行泛化，同时通过上下文适应性的持久性来实现长期一致性，能量成本最少。
## 60. `cs.AI` - 使用深度分割网络从多源炮 gathers 中进行地震速度反演：U-Net 变体和 SeismoLabV3+ 的基准测试 [PDF](https://arxiv.org/pdf/2509.21331), [HTML](https://arxiv.org/abs/2509.21331)
### Authors
Mahedi Hasan
### Background
地震速度反演是地球物理勘探中的关键任务，能够从地震波数据中重构地下结构，对于高分辨率地震成像具有重要意义。传统的物理驱动方法，例如全波形反演（FWI），计算上要求高，对初始条件敏感，受限于地震数据的带宽。近年来，得益于深度学习的发展，产生了数据驱动的方法，将速度反演视为密集预测任务。
### Innovation
该研究在一个汇集了五通道地震 shot 择和高分辨率速度图的 ThinkOnward 2025 Speed & Structure 数据集上，对比了三种先进的编码器-解码器架构——U-Net、U-Net++和DeepLabV3+，以及一种优化的 SeismoLabV3+ 变体。研究结果显示，SeismoLabV3+ 在内部分发的验证集上 MAPE 值为 0.03025，在隐藏测试集上为 0.031246，表明深度分割网络适合用于地震速度反演，并强调了针对特定任务进行架构优化的重要性。
### Conclusion
研究表明，深度分割网络非常适合用于地震速度反演，并且通过特定的架构优化能够显著提升模型性能。
## 61. `cs.AI` - MDF-MLLM: 通过跨模态特征对齐实现深度融合的上下文感知眼底图像分类 [PDF](https://arxiv.org/pdf/2509.21358), [HTML](https://arxiv.org/abs/2509.21358)
### Authors
Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen
### Background
现有的多模态大型语言模型（MLLMs）在捕捉用于诊断视网膜疾病（如青光眼、糖尿病视网膜病变和色素性视网膜炎）的关键低级空间细节方面存在局限。
### Innovation
提出了一个新颖的多模态深度学习架构，该架构通过整合细粒度图像特征和全局文本上下文，显著提高了视网膜底片图像的疾病分类准确性。
### Conclusion
MDF-MLLM 在分类准确性上较基线模型提升了 56%，召回率和 F1 分数分别提高了 67% 和 35%，并在多种视网膜疾病分类上展现出显著优势。该架构提供了可推广、可解释和模块化的框架，未来可应用于临床决策支持系统，扩展至更广泛疾病和分割任务。
## 62. `cs.AI` - 评估结合气象和环境变量的深度学习模型的野火蔓延预测性能及其对2023年毛伊岛火灾案例研究 [PDF](https://arxiv.org/pdf/2509.21327), [HTML](https://arxiv.org/abs/2509.21327)
### Authors
Jiyeon Kim,Yingjie Hu,Negar Elhami-Khorasani,Kai Sun,Ryan Zhenqi Zhou
### Background
野火的扩散预测对于有效的防火管理和风险评估至关重要。随着人工智能（AI）的快速发展，各种深度学习模型被开发并用于野火扩散预测。尽管如此，人们对这些模型的优势和局限性理解有限，也不清楚基于深度学习的野火扩散模型与现有的非AI野火模型之间的比较。本研究基于夏威夷州超过十年的野火数据，评估了五种典型的深度学习模型结合气象和环境变量的野火扩散预测能力。进一步使用2023年毛伊岛火灾作为案例研究，将最佳深度学习模型与广为使用的火灾扩散模型FARSITE进行比较。研究表明，在测试的五个AI模型中，卷积长短期记忆（ConvLSTM）和叠加注意力机制的卷积长短期记忆（ConvLSTM with attention）表现最好。FARSITE模型在精度上高于最佳AI模型，但在召回率上较低，F1分数也较高。AI模型提供了输入数据更大的灵活性，通过将AI模型与可解释AI方法相结合，进一步确认了与2023年毛伊岛火灾相关的关键气象和环境因素。
### Innovation
本研究创新点在于通过对比多种深度学习模型与传统非AI火灾模型，评估了结合气象和环境变量的深度学习模型在野火扩散预测中的性能，并通过案例分析进一步验证了这些模型的适用性和准确性。此外，通过引入可解释AI方法，研究进一步揭示了野火扩散的关键影响因素。
### Conclusion
研究表明，卷积长短期记忆和叠加注意力机制的卷积长短期记忆在所有测试的AI模型中表现最佳。尽管FARSITE模型在精度上略优，但深度学习模型在灵活性上更具优势。通过可解释AI方法，研究还识别出了与2023年毛伊岛野火相关的关键环境因素。这些发现对于未来野火预测模型的选择和改进具有重要意义。
## 63. `cs.AI` - 随机直接偏好优化在放射学报告生成中的应用 [PDF](https://arxiv.org/pdf/2509.21351), [HTML](https://arxiv.org/abs/2509.21351)
### Authors
Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev
### Background
放射学报告生成（RRG）在医疗影像分析中引起了广泛关注，作为减轻放射科医生工作负担的有效工具。尽管取得了许多进步，现有的方法仍然无法达到临床实际应用所需的质量标准。此外，大规模视觉语言模型（VLM）通过借鉴大规模语言模型（LLM）的训练策略（如对齐技术）在通用领域中取得了显著进展。然而，现有方法在实际临床环境中仍需改进以达到所需的报告质量保证水平，尤其是在提高准确性和效率方面。
### Innovation
本文提出了一种模型无关的框架，通过直接偏好优化（DPO）增强RRG的准确性，特别是利用随机对比抽样构建训练对，无需使用奖励模型或人工偏好注释。该方法提高了临床性能指标，最多可提高5%，并且无需使用额外训练数据，从而为医疗领域中文本生成模型的进一步研究提供了新思路和方法优化的新方式。
### Conclusion
本文通过随机直接偏好优化的方法提高了放射学报告生成准确性，增强了原有模型的性能，并且证明了这种方法的有效性和普适性。未来的研究方向可以进一步优化算法，以适用于更复杂的医疗场景，并提升文本生成模型的实际应用价值。
## 64. `cs.AI` - 文本到图像模型中的多模态提示解耦攻击 [PDF](https://arxiv.org/pdf/2509.21360), [HTML](https://arxiv.org/abs/2509.21360)
### Authors
Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen
### Background
文本到图像（T2I）模型在各个领域生成高保真图像的应用非常广泛。然而，这些模型也可能被滥用以通过囚笼攻击生成不适合工作的内容。现有的囚笼攻击方法主要操控文本提示，而对于基于图像的输入潜在的安全漏洞尚未得到充分探索。此外，基于文本的方法在绕过模型的安全过滤器方面面临着挑战。
### Innovation
提出了一种多模态提示解耦攻击（MPDA），通过利用图像模态来分离原始不安全提示中的有害语义成分。MPDA分为三个核心步骤：首先，大型语言模型（LLM）将不安全的提示拆分为伪安全提示和有害提示。前者看似无害的子提示可以绕过过滤器，后者具有不安全语义内容的子提示会触发过滤器。随后，LLM 重新编写有害提示为自然敌对提示以绕过安全过滤器，这些敌对提示引导T2I模型修改基础图像为不安全内容输出。最后，通过视觉语言模型生成图像标题，为LLM提供新的路径来引导迭代重新编写和优化生成的内容，以确保生成的不安全图片内容与原始不安全提示在语义上的一致性。
### Conclusion
实验结果表明，MPDA能够有效生成不安全图像输出，同时保持与原始不安全提示在语义内容上的一致性，为研究图像生成领域的安全问题提供了新视角。
## 65. `cs.AI` - KV-Efficient VLA: 使用RNN门控分块KV缓存加速视觉语言模型的方法 [PDF](https://arxiv.org/pdf/2509.21354), [HTML](https://arxiv.org/abs/2509.21354)
### Authors
Wanshun Xu,Long Zhuang
### Background
VLA模型能够实现统一的机器人感知和控制，但它们的可扩展性受到注意力的二次成本和长时序推理中关键值（KV）内存无限制增长的限制。尽管最近的方法通过扩展骨干网络架构来提高泛化能力，但它们往往忽略了对实时部署至关重要的推理效率问题。
### Innovation
KV-Efficient VLA通过提出一种轻量级、易于训练的机制，选择性地保留高价值上下文，解决这些问题。该方法将KV缓存划分为固定大小的块，并使用递归门控模块根据学习到的效用分数来总结和过滤历史上下文。这种方法保留了最近的细粒度细节，并积极修剪过时的、低相关性的内存，同时保持因果关系。
### Conclusion
理论验证表明，KV-Efficient VLA可以在不显著影响任务成功率的情况下，实现高达1.21倍的推理速度提升和36%的KV内存减少。该方法可以无缝集成到现有的自回归和混合的VLA架构中，实现可扩展的推理，而不修改训练管道或下游控制逻辑。
## 66. `cs.AI` - ReGeS: 连贯的检索-生成协同框架在对话式推荐系统中的应用 [PDF](https://arxiv.org/pdf/2509.21371), [HTML](https://arxiv.org/abs/2509.21371)
### Authors
Dayu Yang,Hui Fang
### Background
对话式推荐系统（CRS）需要将对话与外部领域知识连接起来，以正确理解用户偏好。然而，现有解决方案需要特定领域的工程，限制了灵活性，或者仅依赖大规模语言模型，增加了幻觉的风险。虽然检索增强生成（RAG）具有潜力，但其在CRS中的简单应用受到嘈杂对话削弱检索以及类似项目细微差别被忽视的阻碍。
### Innovation
提出了一种连贯的检索-生成协同框架（ReGeS），该框架结合了生成增强的检索和检索增强的生成，用于从对话中提炼有用的用户意图并区分细微的商品特征。这种协同作用消除了额外注释的需求，降低了幻觉风险，并简化了连续更新。
### Conclusion
在多个CRS基准上的实验表明，ReGeS在推荐准确性方面达到了最先进的技术，证明了知识密集型CRS任务中连贯协同的有效性。
## 67. `cs.AI` - 基于短语的自动生成胸部X光报告的校对 [PDF](https://arxiv.org/pdf/2509.21356), [HTML](https://arxiv.org/abs/2509.21356)
### Authors
Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C.L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood
### Background
随着大规模视觉语言模型（VLM）的出现，现在可以生成类似于实际的放射学报告，用于胸部X光图像。然而，这些模型在临床应用中的扩展受到了生成描述中的事实错误和幻觉的阻碍。本文的研究背景是针对这一问题，提出了一种新颖的基于短语的事实检查模型（FC模型），用于检测自动生成的胸部分析报告中的错误及其指示位置的准确性。
### Innovation
创新之处在于：作者开发了一种新的多标签跨模态对比回归网络，通过一个大型合成数据集进行训练，该数据集是通过修改真实报告中的发现和它们的位置来生成真实与虚假发现-位置对。这种方法能够准确地检测自动生成的胸部X光报告中的错误，并在多个X光数据集上展示了其鲁棒性，得出了高度一致的结果。
### Conclusion
研究结果表明，该方法在多种X光数据集上具有较高的准确性和鲁棒性，能够有效地检测基于最新报告生成器的错误，而且在多个数据集上类似于基于真实情况验证的科伦巴德相关系数达到0.997，这表明该方法对于放射学工作流程中的临床推理具有实用价值。
## 68. `cs.AI` - 施工现场使用人工智能进行脚手架安全评估 [PDF](https://arxiv.org/pdf/2509.21368), [HTML](https://arxiv.org/abs/2509.21368)
### Authors
Sameer Prabhu,Amit Patwardhan,Ramin Karim
### Background
在建筑行业中，安全评估对于确保资产的可靠性和工人的安全至关重要。脚手架作为一种关键的结构支持资产，需要定期检查以检测和识别可能损害其完整性和稳定性的设计规范偏差。目前，检查主要依赖于视觉检查，并由现场管理人员或认证人员执行。然而，视觉检查耗时且因人为错误可能导致不安全状况。
### Innovation
本文探讨了利用人工智能和数字化技术提高脚手架检查精度并改善安全性。开发了一种基于云的人工智能平台，用于处理和分析脚手架结构的点云数据。该系统通过将认证参考数据与最新的点云数据进行比较和评估来检测结构性修改。这种方法可以实现自动监控脚手架，减少手动检查所需的时间和精力，同时在施工现场提高安全性。
### Conclusion
本文提出的基于云的人工智能平台可实现自动监控脚手架，通过与认证参考数据的比较和评估来检测结构性修改，从而减少手动检查所需的时间和精力，提高安全性。
## 69. `cs.AI` - MAJORScore: 通过联合表示评估多模态相关性的新度量 [PDF](https://arxiv.org/pdf/2509.21365), [HTML](https://arxiv.org/abs/2509.21365)
### Authors
Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin
### Background
目前通常使用预训练对比学习模型的嵌入能力来衡量双模态数据的相关性（例如CLIP），但现有常用的评估指标仅适用于两模态之间的相关性分析，极大地限制了多模态相似性的评估能力。因此，需要一个新的多模态相关性度量方法来解决现有方法的局限性，以便更准确地评价多模态数据和模型的性能，尤其是在大型多模态数据集上。
### Innovation
提出了一种新的多模态相关性度量方法MAJORScore，该方法通过多模态联合表示首次对N个（N>=3）模态之间的相关性进行客观、公平的评估，其显著改善了现有方法在一致性模态和不一致性模态方面的评估，展现了更可靠的多模态相似性评估能力。
### Conclusion
实验表明，MAJORScore相较于现有方法能够提高一致模态评估26.03%-64.29%，降低不一致性模态评估13.28%-20.54%，且能够更好地服务于大规模多模态数据集上的相似性评估以及多模态模型性能评价。
## 70. `cs.AI` - 上下文即所需：大型语言模型在现实世界中的最大有效上下文窗口 [PDF](https://arxiv.org/pdf/2509.21361), [HTML](https://arxiv.org/abs/2509.21361)
### Authors
Norman Paulsen
### Background
论文背景在于，尽管语言模型提供商声称其最大上下文窗口（MCW）很大，但实际应用中，模型的有效上下文窗口（MECW）可能因问题类型不同而大不相同。研究者希望通过测试和分析，确定模型在不同上下文大小和问题类型下的有效范围，以及找到其失效点。这为理解模型性能和潜在改进提供了依据。
### Innovation
论文的创新点在于：1) 提出了最大有效上下文窗口的概念；2) 开发了一种评估上下文窗口有效性的方法，涵盖多种上下文大小和问题类型；3) 建立了标准化比较模型有效性的方法，以找到失败点；4) 收集了大量数据点，揭示了MCW和MECW之间以及MECW随问题类型变化的显著差异，显示了模型的有效上下文窗口在不同问题类型下的差异性和实际表现不足。
### Conclusion
研究发现，MCW和MECW之间存在巨大差异，且MECW会根据不同问题类型发生变化。大部分顶级模型在100个上下文token内就开始表现严重下降，大约在1000个token时精度显著降低。所有模型在其最大上下文窗口的要求上都远未达到，最多差了99%。研究表明，MECW依据问题类型变化，提供了解改进模型准确性和降低幻觉率的明确建议。
## 71. `cs.AI` - 设计和实施增强安全RAG的AI聊天机器人：台湾新竹智慧城市旅游客户服务抵御提示注入攻击——案例研究 [PDF](https://arxiv.org/pdf/2509.21367), [HTML](https://arxiv.org/abs/2509.21367)
### Authors
Yu-Kai Shih,You-Kai Kang
### Background
随着智能旅游的发展，基于AI的聊天机器人已成为提供个性化、实时协助的重要工具，同时促进可持续性和效率。然而，这些系统正变得越来越容易受到提示注入攻击，即攻击者通过操纵输入来引发意外行为，例如泄露敏感信息或生成有害内容。
### Innovation
本文描述了一个设计和实施安全的RAG增强AI聊天机器人的案例研究，用于台湾新竹的智慧城市旅游服务。该系统采用了RAG与API函数调用、多层语言分析和注入防御机制。关键特点包括分层响应策略、基于RAG的知识接地以及词法、语义和语用层面上的意图分解。防御机制包括系统规范、意图判断的门守住和逆RAG文本，以优先考虑验证数据。此外，还对GPT-5变体进行了基准测试以评估其内在鲁棒性，结果显示GPT-5成功阻止了大约85%的攻击，展示了进展但仍需多层防御。
### Conclusion
本研究强调了在可持续旅游、多语言可访问性和道德AI部署方面的贡献。本文为在智能旅游中部署安全聊天机器人提供了一个实用框架，并促进了具有弹性和可信赖的AI应用。
## 72. `cs.AI` - 基于影响引导的语境选择以实现有效的检索增强生成 [PDF](https://arxiv.org/pdf/2509.21359), [HTML](https://arxiv.org/abs/2509.21359)
### Authors
Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang
### Background
检索增强生成（RAG）通过将响应扎根于外部知识来解决大型语言模型（LLM）的妄想现象，但其效果受到质量低下的检索上下文的负面影响，这些上下文包含不相关或嘈杂的信息。现有方法通过基于预定义的质量评估指标选择上下文来尝试提高性能，但其效果有限，无法超越标准RAG。分析认为这些限制部分源于它们未能充分利用查询、上下文列表和生成器提供的所有信息进行全面的质量评估。
### Innovation
本文受数据选择领域最新进展的启发，将上下文质量评估重新概念化为推理时的数据价值问题，并引入了上下文影响价值（CI值）。这是一种新型的度量质量的方法，通过测量移除每个上下文后性能下降的程度，综合考量了查询感知的相关性、列表感知的独特性和生成器感知的对齐。此外，CI值通过简单地保留具有正CI值的上下文，消除了复杂的选择超参数调优。为解决标签依赖性和计算负载问题，本文开发了一种参数化替代模型，用于推理中的CI值预测，并通过Oracle CI值监督训练和端到端生成器反馈进行训练。这种方法在8个NLP任务和多个LLM上的实验结果表明，显著优于最先进的基线方法，有效地过滤了质量低下的上下文，同时保留了关键信息。
### Conclusion
本文提出了一种上下文选择方法，显著优于当前最先进的基线方法，有效地过滤了质量低下的上下文，并保留了关键信息。
## 73. `cs.AI` - MIXRAG: Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering [PDF](https://arxiv.org/pdf/2509.21391), [HTML](https://arxiv.org/abs/2509.21391)
### Authors
Lihui Liu,Carl J. Yang
### Background
大规模语言模型（LLMs）在广泛的应用领域中取得了显著的成果，但在知识密集型领域中经常出现幻觉现象，这是因为它们依赖于静态预训练语料库。为解决这一限制，检索增强生成（RAG）通过在推理过程中引入外部知识源来增强LLMs。文本图作为一种知识表示形式，提供了结构化且语义丰富的信息，有助于更精确和可解释的推理，引起了广泛的关注。然而，现有方法通常仅依赖单一检索器识别相关子图，这限制了它们捕捉复杂查询多元方面的能力。此外，这些系统往往难以准确地判断检索内容的相关性，容易被无关噪音分散注意力。
### Innovation
本文提出了一种名为MIXRAG的Mixture-of-Experts Graph-RAG框架，引入了多个专业化的图检索器和动态路由控制器，以更好地处理多样的查询意图。每个检索器专门训练用于关注图语义的特定方面，如实体、关系或子图拓扑。Mixture-of-Experts模块根据输入查询自适应地选择和融合相关信息。为了减少检索信息中的噪音，引入了一个查询感知的GraphEncoder，该编码器仔细分析了检索子图中的关系，强调了最相关部分并降低了不必要的噪音。实验结果表明，该方法不仅达到了最先进的性能，还优于各种基线方法。MIXRAG在不同领域的多种基于图的任务中均表现出色。
### Conclusion
MIXRAG是一种有效的基于图的检索增强生成框架，适用于文本图的理解和问答任务，已经展示了其在多个领域的广泛适用性。代码在接受论文后将公开。
## 74. `cs.AI` - 自动提示生成以实现富有创意和反事实的文本转图像合成 [PDF](https://arxiv.org/pdf/2509.21375), [HTML](https://arxiv.org/abs/2509.21375)
### Authors
Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens
### Background
文本到图像生成随着大规模多模态训练的进展取得了快速进步，但细粒度可控性依然是一项关键挑战。反事实可控性，即有意生成违背常识模式的图像的能力，是促进创意及探索性应用的关键，但目前仍是一个重大的挑战。尽管如此，反事实可控性在激发创造性和探索性应用方面发挥着关键作用。本文关注反事实大小控制的问题，例如生成一只袖珍白鲸在巨大按钮旁边的情况。
### Innovation
本文提出了一种自动提示工程框架，该框架能够将基础提示调整为以反事实图像为基准的修订提示。该框架包括三个组件：图像评估器，指导数据集构建；有监督的提示重写器，生成修订提示；以及使用DPO训练的排名器，选择最佳修订提示。与此同时，本文构建了第一个反事实大小的文本图像数据集，并通过扩展并改进Grounded SAM来增强图像评估器，使其性能提高了114%。实验结果表明，该方法在性能上超过了当前最先进的基线和ChatGPT-4o，在反事实可控性方面建立了研究基础。
### Conclusion
本文提出的方法在反事实可控性方面取得了优于当前先进基线和ChatGPT-4o的性能，为未来在反事实可控性方面的研究奠定了基础。
## 75. `cs.AI` - 动态多目标融合以实现高效听觉-视觉导航 [PDF](https://arxiv.org/pdf/2509.21377), [HTML](https://arxiv.org/abs/2509.21377)
### Authors
Yinfeng Yu,Hailong Zhang,Meiling Zhu
### Background
该研究背景在于，当前的听觉-视觉导航系统通过结合板载传感器的视觉观察与目标发出的听觉信号来定位声音源。然而，现有方法在融合多模态线索时未能深入考虑感知上下文，导致导航效果有限。论文旨在解决这一问题，提出了能够有效利用多模态线索的DMTF-AVN算法，进而提升导航性能。
### Innovation
本文创新点在于提出了一种动态多目标融合的听觉-视觉导航方法（Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation, DMTF-AVN），该方法采用多目标架构结合精炼的Transformer机制，能够选择性地融合跨模态信息。DMTF-AVN在Replica和Matterport3D数据集上的实验表明，其在成功率、路径效率和场景适应性方面达到了最先进的水平，并且具有良好的扩展性和概括性，推动了多模态融合策略在机器人导航中的应用。
### Conclusion
DMTF-AVN通过多目标架构和改进的Transformer机制实现了高效的听觉-视觉导航，实验结果表明其在多种评估指标上均优于现有方法。未来研究将进一步探索其在更复杂环境下的应用潜力。
## 76. `cs.AI` - 无标记的超分辨显微镜的在场深学习协议：网络架构和信噪比依赖性比较研究 [PDF](https://arxiv.org/pdf/2509.21376), [HTML](https://arxiv.org/abs/2509.21376)
### Authors
Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo
### Background
光学显微镜在众多领域（包括教育、医疗、质量检测和分析）中应用广泛，但其横向解析度有限（通常约200nm），需要通过成本高的外部模块或专业的技术（如超分辨率荧光显微镜）才能解决。这类解决方法在普通用户中普及度不高。为了应对这一挑战，该研究评估了一种新的非荧光相位调制显微镜方法（如Zernike相位对比（PCM）和差分干涉对比（DIC）显微镜）结合深神经网络（DNN）架构，旨在通过软件方法提高光学显微镜的解析度，而无需昂贵的技术手段。通过使用前文开发的两种DNN模型（O-Net和Theta-Net）来测试一个包含纳米级特征的目标，这些特征通过扫描隧道显微镜（AFM）校准。
### Innovation
该研究创新性地采用了深度学习深度神经网络（DNN）架构来实现无荧光光学纳米显微镜，通过比较两种不同的DNN模型（O-Net和Theta-Net）在不同信噪比下的表现，进一步优化了超分辨显微镜的方法。研究发现，O-Net和Theta-Net是互补的替代方案，适用于不同程度的信噪比情况下的图像超分辨能力。这一研究为非专业人士提供了一种成本更低且更易于实现的途径，以提高光学显微镜的解析度。
### Conclusion
尽管O-Net和Theta-Net在图像超分辨性能上表现出色，但它们是互补而非竞争的关系，特别是在不同信噪比的情景下。高信噪比环境下更倾向于使用O-Net模型，而低信噪比环境下更倾向使用Theta-Net模型。这些结果突显了模型架构与图像信噪比对于模型性能和高质量超分辨图像生成的重要性，明确展示了DNN在非荧光光学纳米显微镜中的价值。
## 77. `cs.AI` - 探索适应网络入侵检测的联邦学习与量子机器学习：一种综述 [PDF](https://arxiv.org/pdf/2509.21389), [HTML](https://arxiv.org/abs/2509.21389)
### Authors
Devashish Chaudhary,Sutharshan Rajasegarar,Shiva Raj Pokhrel
### Background
本文探讨了将联邦学习（FL）与网络入侵检测系统（NIDS）相结合的方法，尤其是涉及深度学习和量子机器学习的方法。联邦学习允许分布式设备进行协作模型训练，同时保持数据隐私——这在网络安全性背景下尤为重要，因为敏感的流量数据不能集中处理。本文综合分析了所有与网络入侵检测相关的联邦学习架构、部署策略、通信协议和聚合方法。
### Innovation
本文深入探讨了数据隐私保护技术、模型压缩方法和针对DDoS、MITM和僵尸网络等特定攻击的联邦解决方案。此外，本文还开创性地探讨了量子联邦学习（QFL），讨论了量子特征编码、量子机器学习算法以及专为复杂模式识别加速度的量子特定聚合方法。通过对比经典方法和量子方法，识别研究缺口，并评估实际部署，本文为联邦入侵检测系统的产业应用和未来研究指明了方向。
### Conclusion
本文为研究人员和从业人员提供了一个权威参考，旨在增强联邦入侵检测系统的隐私性、效率和鲁棒性，同时为未来以量子增强的网络安全环境做准备。
## 78. `cs.AI` - 高能物理中的基础模型 [PDF](https://arxiv.org/pdf/2509.21434), [HTML](https://arxiv.org/abs/2509.21434)
### Authors
Anna Hallin
### Background
基础模型（大型、预训练的人工智能模型，可以微调适应各种任务）已在自然语言处理和计算机视觉领域引发革命性变化。在高能物理领域，人们越来越关注这些模型是否可以直接应用于科研，甚至是否可以根据粒子物理数据专门构建。基于这种趋势，本文作为高能物理领域关于基础模型的第一个综述，总结了迄今为止该领域的研究成果。
### Innovation
本文是第一次对高能物理中基础模型的研究进行综述，从现有的研究中提炼和讨论了基础模型在高能物理领域的应用和发展情况。
### Conclusion
总结了高能物理领域关于基础模型的研究现状，并对未来的研究方向进行了讨论，指出基础模型在粒子物理数据处理中的潜在应用和挑战。
## 79. `cs.AI` - 一种模型，多种道德规范：揭开计算道德推理中的跨语言不一致 [PDF](https://arxiv.org/pdf/2509.21443), [HTML](https://arxiv.org/abs/2509.21443)
### Authors
Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens
### Background
语言成为大型语言模型（LLMs）进行道德决策的重要因素。然而，LLMs 大多基于英语数据进行预训练，这对其在多元文化和跨语言环境中的道德判断能力提出了质疑。
### Innovation
本研究系统地探讨了语言如何在LLMs中影响道德决策，并将两个道德推理基准翻译成五种文化与类型各异的语言，实现了多语言零样本评估。通过精心设计的研究问题和案例研究，揭示了LLMs道德判断差异的根源和预训练数据对LLMs道德观念塑造的作用。
### Conclusion
本研究总结了道德推理错误的结构化分类，强调了需要更加文化意识的AI。
## 80. `cs.AI` - PhenoMoler：通过化学大型语言模型实现表型导向的分子优化 [PDF](https://arxiv.org/pdf/2509.21424), [HTML](https://arxiv.org/abs/2509.21424)
### Authors
Ran Song,Hui Liu
### Background
当前的分子生成模型主要集中在提高药物与靶点的结合亲和力和特异性上，但往往忽略了化合物引起的系统级表型效应。转录组谱作为药物引起的表型变化的分子级读数，提供了在表型意识指导下进行分子设计的强大机会。
### Innovation
提出了PhenoMoler，这是一种表型导向的分子生成框架，结合化学大型语言模型和转录表达谱，实现生物学驱动的药物设计。PhenoMoler通过对照药诱导的差异表达特征进行调整，将转录反应与化学结构明确联系起来。通过选择性遮掩和重建特定的亚结构（骨架、侧链或连接臂），PhenoMoler支持精细、可控的分子优化。
### Conclusion
广泛的实验表明，PhenoMoler生成了化学上有效的、新颖且多样化的分子，这些分子与期望的表型特征趋同。与FDA批准的药物相比，生成的化合物在药物 likeness（QED）、优化的物理化学性质和对关键癌症靶点的结合亲和力方面表现相当或更优。这些发现突显了PhenoMoler在表型导向和结构可控的分子优化中的潜在价值。
## 81. `cs.AI` - 基于大型AI模型的生成式语义通信在图像传输中的应用 [PDF](https://arxiv.org/pdf/2509.21394), [HTML](https://arxiv.org/abs/2509.21394)
### Authors
Qiyu Ma,Wanli Ni,Zhijin Qin
### Background
生成人工智能（AI）的快速发展为提高语义通信系统中图像传输的效率和准确性提供了重要机会。尽管如此，现有方法往往忽略了图像不同区域的重要性差异，这可能会降低关键视觉内容的重建质量。
### Innovation
提出了一个创新的生成式语义通信系统，通过将图像分割成关键区域和非关键区域来细化语义粒度。关键区域使用面向图像的语义编码器进行处理，而非关键区域则通过图像到文本建模方法进行高效压缩。此外，为了缓解大型AI模型带来的存储和计算需求，所提出的系统采用了轻量级部署策略，结合模型量化和低秩适应微调技术，显著提高了资源利用率，同时不牺牲性能。
### Conclusion
仿真结果表明，所提出的系统在语义保真度和视觉质量方面均优于传统方法，从而验证了其在图像传输任务中的有效性。
## 82. `cs.AI` - 使用RLVR的顶尖SQL推理模型 [PDF](https://arxiv.org/pdf/2509.21459), [HTML](https://arxiv.org/abs/2509.21459)
### Authors
Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang
### Background
通过强化学习（RL）开发定制推理模型，以便结合组织特定知识，对解决企业客户的业务问题具有巨大潜力。在许多这类问题中，奖励函数是可验证的，这种设置称为带可验证奖励（RLVR）的强化学习。研究团队将RLVR应用于一个流行的数据科学基准——BIRD，该基准评估AI代理将自然语言查询转化为数据库SQL执行的能力。
### Innovation
研究团队提出了一种简单的RLVR训练方案，包括精心选择提示和模型、脱机RL方法TAO的预热阶段，以及严格的在线RLVR训练。仅使用BIRD训练集进行训练，在没有任何额外数据、不使用专有模型的情况下，他们的初始提交在BIRD排行榜上达到了顶尖的准确率：在无自一致性的情况下达到73.56%，有自一致性的情况下达到75.68%，并比第二好的方法需要更少的生成次数。
### Conclusion
虽然BIRD只是一个代理任务，但该团队框架的简洁性使其广泛适用于企业领域，如商务智能、数据科学和编程。
## 83. `cs.AI` - 对大脑中听觉情感理解的现实编码模型探讨 [PDF](https://arxiv.org/pdf/2509.21381), [HTML](https://arxiv.org/abs/2509.21381)
### Authors
Guandong Pan,Yaqian Yang,Shi Chen,Xin Wang,Longzhao Liu,Hongwei Zheng,Shaoting Tang
### Background
在情感神经科学和情绪感知AI领域，如何理解复杂的听觉刺激引发的情感唤醒动态依然没有解决。本研究旨在通过引入一个计算框架，来建模大脑如何将自然听觉输入转化为动态的行为/神经反应。研究基于神经生物学中的平行听觉层级原则，将音频分解为多级听觉特征，并通过多数据集分析将这些特征映射到情感相关响应。研究揭示了高层语义表示（来自wav2vec 2.0/Hubert最终层）在情感编码中的主导作用，与低级声学特征相比，高层语义特征在情感编码中具有更强的与行为注释和脑区动态神经同步的联系。此外，研究还表明，wav2vec 2.0/hubert中间层在平衡声学-语义信息的情况下，更擅长于在不同数据集中引发情感。同时，观察到人类的声音和声乐片段在引发情感时表现出与刺激能量分布相关的数据集依赖性偏见，大脑前额及颞叶区域在前额和颞叶区域占主导地位，而边缘区在情感表达上更优。
### Innovation
本研究基于神经生物学原则，通过引入wav2vec 2.0/Hubert模型来重新构建大脑对自然声音的多级听觉特征分解和情感响应建模。研究表明，高层语义表示在情感编码中扮演着主导角色，且不同数据集中，声音和声乐片段在情感表达上表现出特定的偏好，这为后续的情感感知系统的适应性和跨学科探索提供了可能的研究基础。
### Conclusion
本研究通过结合情感计算和神经科学，揭示了听觉-情感编码的层级机制。提出了一个关于大脑中情感处理的新模型，对于适应性和情绪感知系统的开发以及音频-情感交互的跨学科研究具有重要意义。
## 84. `cs.AI` - 大型语言模型需要象征意义 [PDF](https://arxiv.org/pdf/2509.21404), [HTML](https://arxiv.org/abs/2509.21404)
### Authors
Xiaotie Deng,Hanyu Li
### Background
文章背景在于当前的人工智能技术，尤其是大型语言模型虽然在许多方面表现出色，但在真实的世界发现和创新方面仍然有限。尽管这些模型具有强大的计算能力，但它们缺乏指导方向的能力，这限制了它们的探索潜力。因此，作者认为需要某种形式的“指南针”来引导模型的发展，使其能够进行更真实的发现和创新。
### Innovation
该研究的创新在于提出了一种新的方法论，即为大型语言模型引入“象征意义”。作者认为，借助人类精心设计的符号系统，可以指导语言模型进行更有效的学习与创新，而不是仅仅依赖于单纯的数据扩展。这种方法将为模型提供方向感，从而增强其揭示新知的能力。
### Conclusion
文章总结认为，未来的人工智能领域需要超越简单的数据规模扩展，大型语言模型需要得到人类设计的符号系统的指导，来引导它们产生更真实、更富有创造性的发现。这种方法能够显著提高模型的学习效率和创新能力，使它们能够更好地服务于人类社会。
## 85. `cs.AI` - SAEmnesia: 使用稀疏自编码器在扩散模型中擦除概念 [PDF](https://arxiv.org/pdf/2509.21379), [HTML](https://arxiv.org/abs/2509.21379)
### Authors
Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto
### Background
文本到图像的扩散模型有效概念反学习需要精确定位模型潜空间中的概念表示。尽管稀疏自编码器可以减少神经元的多义性（即一个神经元包含多个概念），但单一的概念表示仍然可以分布在多个潜特征中，这需要大量的搜索程序来执行概念的反学习。当前的方法往往通过分散概念表示来减轻这一问题，但同时也导致了特征分裂和特征分散的问题。SAEmnesia引入了一种监督稀疏自编码器训练方法，通过系统的概念标注来促进一对一的概念-神经元映射，从而减轻特征分裂并促进特征集中的策略，这样在训练时仅增加了交叉熵计算的开销。这种可解释的表示在推理阶段将超参数搜索减少了96.67%。SAEmnesia在UnlearnCanvas基准上比最先进的方法提高了9.22%，并且在逐序反学习任务中，对于9个对象删除，也展示了更出色的可扩展性，准确率提高了28.4%。
### Innovation
SAEmnesia方法通过监督稀疏自编码器训练来促进概念-神经元的一对一映射，通过系统地标注概念来减轻特征分裂并促进特征集中。这种策略能够在训练时显著增强了神经元与概念的关联性。此外，其引入的唯一计算开销仅限于训练期间的交叉熵计算，而在推理阶段，它减少了96.67%的超参数搜索。在序列反学习任务中，还展示了更优异的可扩展性。
### Conclusion
SAEmnesia在UnlearnCanvas基准中比当前最佳方法提高了9.22%，并且在处理9个对象移除的顺序反学习任务中，准确性提高了28.4%。
## 86. `cs.AI` - DyME: 在具有层级正交洛拉适配的扩散模型中新颖的多概念擦除框架 [PDF](https://arxiv.org/pdf/2509.21433), [HTML](https://arxiv.org/abs/2509.21433)
### Authors
Jiaqi Liu,Lan Zhang,Xiaoyong Yuan
### Background
文本到图像的扩散模型（DMs）无意中复制了受版权保护的风格和视觉概念，引发了法律和伦理问题。概念擦除作为一种保护措施，旨在通过微调选择性地抑制这些概念。然而，现有的方法无法扩展到实际应用场景中，且这些应用要求提供者需要清除多个且可能是相冲突的概念。其中一个核心瓶颈是现有方法依赖于静态擦除：一个检查点被微调以移除所有目标概念，而不考虑推理时的实际擦除需求。这种固有设计与现实世界的使用情况不符，因为每次生成请求不同，导致擦除成功率降低且非目标内容的保真度降低。现有方法存在此类问题。
### Innovation
本文提出了一种名为DyME的按需擦除框架，该框架在训练时轻量级地训练了特定概念的洛拉适配器，并仅在推断时动态组成所需的适配器。这种模块化设计允许灵活地进行多概念擦除。为了克服适配器间相互干扰的问题，其引入了在特征和参数层次上的两层正交约束，使表示变化脱钩，并确保了正交适配子空间。此外，还开发了一个新的分层基准ErasureBench-H，具有品牌-系列-角色结构，能够在语义粒度和擦除集合大小上进行有原则的评估。在ErasureBench-H和标准数据集（如CIFAR-100，Imagenette）上的实验表明，DyME始终优于最先进的基线方法，实现更高的多概念擦除保真度，同时最小化对非目标内容的损坏。
### Conclusion
实验结果表明，DyME在处理多概念擦除时，能够以最小的副损害获得更高的保真度，是文本到图像扩散模型创新的解决方案，提高了擦除过程的灵活性和效果。
## 87. `cs.AI` - 稀疏子网络是否表现出认知对齐的注意力？剪枝对注意力图保真度、稀疏性和概念一致性的影响 [PDF](https://arxiv.org/pdf/2509.21387), [HTML](https://arxiv.org/abs/2509.21387)
### Authors
Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi
### Background
先前的研究表明，神经网络在保持性能的情况下可以被大幅度简化，但剪枝对模型可解释性的影响仍然不清楚。本文通过研究基于幅度的剪枝后进行微调如何影响低级刺激图和高级概念表示，解决了这个问题。研究者使用在ImageNette上受训的ResNet-18模型，对比了剪枝不同水平后Vanilla Gradients (VG) 和 Integrated Gradients (IG) 的后验解释，评估了稀疏性和信实性。此外，还应用CRAFT概念提取方法跟踪学习概念语义一致性的变化。实验结果表明，轻度到中度剪枝可以提高刺激图的聚焦度和信实性，同时保持清晰的、语义上有意义的概念。相比之下，激进的剪枝会合并异质特征，减少刺激图的稀疏性和概念一致性，尽管准确性得以保持。这些发现表明，虽然剪枝可以朝着更接近人类的关注模式塑造内部表示，但过度剪枝削弱了可解释性。
### Innovation
本文的创新在于通过对比不同剪枝程度下的Vanilla Gradients (VG) 和 Integrated Gradients (IG) 的后验解释，评估了剪枝对低级刺激图和高级概念表示的影响，并进一步使用CRAFT概念提取方法追踪了在剪枝过程中的概念语义一致性变化。这种研究方法为理解剪枝对模型可解释性的影响提供了一个新的视角。
### Conclusion
轻度到中度的剪枝可以改善刺激图的聚焦和信实性，同时保持清晰的、语义上有意义的概念。然而，激进的剪枝会合并异质特征，减少刺激图的稀疏性和概念一致性。这些结果表明，虽然剪枝可以朝着更接近人类关注模式的方向塑造内部表示，但过度剪枝会损害可解释性。
## 88. `cs.AI` - 线性非高斯循环模型中的近最优实验设计 [PDF](https://arxiv.org/pdf/2509.21423), [HTML](https://arxiv.org/abs/2509.21423)
### Authors
Ehsan Sharifian,Saber Salehkaleybar,Negar Kiyavash
### Background
研究基于组合观测和实验数据的线性非高斯结构方程模型中的因果结构学习问题。现有结果表明，仅使用观测数据只能识别出因果图的置换等价类，而无法识别出图的具体结构。通过使用完美匹配在二分图中的组合表示法，分析实验如何改变或约束这些匹配，提出了基于干预的实验设计任务，并将其转化为一个具有自然奖励函数的适应性随机优化问题。奖励函数的适应性次模性以及近最优近似保证的贪婪策略是优化问题的核心。
### Innovation
提出了使用完美匹配在二分图中的组合表示法来分析实验如何改变或约束匹配的方法，将优化问题转化为适应性随机优化问题，并证明了奖励函数的适应性次模性，提供了一个具有近最优性能保证的贪婪策略。提出了一个基于随机匹配的采样估计算法，以有效估计奖励函数，展示了少量经过优化的实验能恢复真实的因果结构。
### Conclusion
展示了一种有效利用少量实验进行因果结构学习的方法，并证明了其近最优性能，有效地解决了在非高斯循环模型中进行最优实验设计的问题。
## 89. `cs.AI` - 神经算子在地下储水库瞬变流体流动数学建模中的应用 [PDF](https://arxiv.org/pdf/2509.21485), [HTML](https://arxiv.org/abs/2509.21485)
### Authors
Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov
### Background
地下储水库系统是一个复杂的动态对象，用分布式参数和偏微分方程（PDEs）来描述。传统的数值方法在建模这些系统时虽然精度很高，但计算所需时间很长，限制了它们在控制和决策支持问题中的应用。
### Innovation
提出了一种基于傅里叶神经算子的架构（TFNO-opt），允许在无限维函数空间中近似PDE解，提供对离散化不变性和方程不同实现的一般性。改进包括可调内部时间分辨率的积分傅里叶算子，参数在频域的张量分解，使用Sobolev范数在误差函数中的应用，以及解耦近似误差和初始条件重建以更准确地再现物理过程。
### Conclusion
所提出改进的有效性通过计算实验得到验证。使用地下储气库（UGS）的流体力学建模问题作为示例，传统方法的计算加速了六个数量级，这为有效控制复杂储水库系统开辟了新的可能性。
## 90. `cs.AI` - DistillKac: 通过阻尼波动方程进行少量步骤的图像生成 [PDF](https://arxiv.org/pdf/2509.21513), [HTML](https://arxiv.org/abs/2509.21513)
### Authors
Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon
### Background
现有扩散模型虽然在生成高质量图像方面表现出色，但它们的反向时间速度可能会变得僵硬，并且允许无限的传播速度。相比之下，杜阿梅尔公式（damped wave equation）和其随机卡尔表示（stochastic Kac representation）确保了有限速度的传输，并提供了全局有界的动能。
### Innovation
该论文提出了DistillKac，一种结合了阻尼波动方程和随机卡尔表示的快速图像生成方法。创新点包括：1) 引入了在速度空间中的无分类器引导方法，保持了平方可积性的条件下；2) 提出了一种仅在终点进行蒸馏的训练方法，训练学生模型以匹配冻结的教师模型在长时间内的表现；3) 证明了一项稳定性结果，促进图像生成监督从终点迁移到路径的整个区间。
### Conclusion
实验表明，DistillKac 可以在极少数的函数评估中生成高质量的图像，并保持有限速度概率流的数值稳定性优点。
## 91. `cs.AI` - ARTI-6: 向六维度发音语音编码迈进 [PDF](https://arxiv.org/pdf/2509.21447), [HTML](https://arxiv.org/abs/2509.21447)
### Authors
Jihwan Lee,Sean Foley,Thanathai Lertpetchpun,Kevin Huang,Yoonjeong Lee,Tiantian Feng,Louis Goldstein,Dani Byrd,Shrikanth Narayanan
### Background
本文介绍了一种基于实时MRI数据的紧凑六维度发音语音编码框架ARTI-6，该框架能够捕捉到包括软腭、舌根和喉在内的关键发音腔体区域。ARTI-6 包含三个组成部分，通过分析关键区域建立发音特征集，利用语音基础模型预测发音特征，再通过合成模型直接从发音特征重建可理解的语音，展示了低维度表示也可生成自然声音的可能。
### Innovation
ARTI-6 通过结合实时MRI数据和先进的模型，提出了一个六维度的发音语音编码框架。该框架能够从语音特征中准确预测发音特征（相关性达到0.87），并通过模型直接合成出自然的声音。这提升了发音反转、合成以及更广泛的语音技术应用的可解释性、计算效率和生理依据。
### Conclusion
ARTI-6 提供了一个可解释性强、计算效率高且生理学基础扎实的理论框架，用于推进发音反转、合成以及更广泛的语音技术应用。该研究成果还免费提供了源代码和语音样本。
## 92. `cs.AI` - 沙特阿拉伯专业角色中的性别刻板印象：基于语言模型的AI生成图像分析研究 [PDF](https://arxiv.org/pdf/2509.21466), [HTML](https://arxiv.org/abs/2509.21466)
### Authors
Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa
### Background
该研究探讨了当前的文本到图像的人工智能（AI）模型在产生沙特阿拉伯专业人物表征时，是否会延续性别刻板印象和文化不准确的问题。研究者通过分析由ImageFX、DALL-E V3和Grok生成的1,006张图像，并使用中性提示对56种多样化的沙特职业进行了评估。分析维度包括感知性别、服装和外观、背景和环境、活动和互动、以及年龄。
### Innovation
研究采用了双认证者系统并通过高级研究人员仲裁解决分歧，总共得到了10,100个个体判断。这种方法提高了评价过程的准确性和可靠性。研究发现不同AI模型在描绘性别角色上存在显著差异，尤其是DALL-E V3表现出最强的性别刻板印象，同时模型在文化服饰、环境和活动方面也显示出文化不准确性。这种不准确性往往源于文化误解，而非真正进步的表现。
### Conclusion
当前AI模型受训练数据中社会偏见的影响，仅部分反映了沙特劳动力市场的性别动态和文化细微差别。因此，研究结果指出应更重视培训数据的多样性和公正算法的开发，从而确保输出的视觉内容公正且真实。
## 93. `cs.AI` - 在最优传输的新算法方向及其在产品空间的应用 [PDF](https://arxiv.org/pdf/2509.21502), [HTML](https://arxiv.org/abs/2509.21502)
### Authors
Salman Beigi,Omid Etesami,Mohammad Mahmoody,Amir Najafi
### Background
本文从算法角度研究了高维分布 $μ, ν$ 在 $R^n$ 中的最优传输问题：给定 $x ∼ μ$，找出一个与 $y ∼ ν$ 接近的 $y$，时间复杂度为多项式级，而不是 $μ, ν$ 的完全表示大小。研究集中在使用算法计算传输成本，特别是在处理产品分布时的算法传输。
### Innovation
本文的主要成果是提出了一种通用算法，用于以 $text{cost} = text{Δ} + text{δ}$ 的代价从任何产品分布 $text{μ}$ 传输到任何 $text{ν}$，其中 $text{Δ}$ 是 Knother-Rosenblatt 传输成本，$text{δ}$ 是随运行时间递减的计算误差。为了实现这一点，$text{ν}$ 需要满足“按顺序采样”的新但自然的概念。此外，证明了 Talagrand 不等式的算法版本，适用于从标准正态分布 $text{Φ}^n$ 到任意分布 $text{ν}$ 的传输，特别优化了测量集 $text{S}$ 的情况。
### Conclusion
使用此方法，我们获得了第一个关于高斯分布的计算凝聚结果，独立于维度的传输成本，解决了 Etesami 等人在 2020 年提出的一个开放问题。具体地说，对于任意测量为 $text{ε}$ 的集 $text{S}$，大多数 $text{Φ}^n$ 样本可以在多项式时间内映射到 $text{S}$ 内，距离为 $O(text{√log 1/ε})$。
## 94. `cs.AI` - 捷径流匹配用于语音增强：通过单阶段训练实现步骤不变的流 [PDF](https://arxiv.org/pdf/2509.21522), [HTML](https://arxiv.org/abs/2509.21522)
### Authors
Naisong Zhou,Saisamarth Rajesh Phaye,Milos Cernak,Tijana Stojkovic,Andy Pearce,Andrea Cavallaro,Andy Harper
### Background
基于扩散的生成模型在语音增强（Speech Enhancement, SE）中实现了感知质量的先进性能，但由于其迭代性质，需要大量的神经网络函数评估（Neural Function Evaluations, NFEs），这为实时应用带来了挑战。相比之下，流动匹配提供了一种更高效的方法，通过学习直接的向量场，能够使用确定性的常微分方程（ODE）求解器在少量步骤内实现高质量的合成。
### Innovation
我们提出了用于语音增强的捷径流匹配（Shortcut Flow Matching for Speech Enhancement, SFMSE），这是一种通过单阶段训练过程同时训练一个步进不变模型的新方法。通过在单阶段训练过程中将速度场条件化于目标时间步，SFMSE可以在不进行任何架构更改或微调的情况下执行单步、少量步或多个步骤的去噪。
### Conclusion
我们的结果显示，单步骤SFMSE推理在消费级GPU上实现了0.013的实时因子（Real Time Factor, RTF），同时其感知质量与需要60个NFEs的强扩散基线相当。这项工作还提供了训练和推理中随机性作用的经验分析，填补了高质量生成型SE和低延迟约束之间的差距。
## 95. `cs.AI` - 追求卓越：基于评分标准的有效奖励建模以提升大语言模型的后训练效果 [PDF](https://arxiv.org/pdf/2509.21500), [HTML](https://arxiv.org/abs/2509.21500)
### Authors
Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin
### Background
强化微调（RFT）常遇到奖励过优优化问题，即策略模型通过获取高分数来操控奖励信号，但输出的质量却较差。背后的理论分析表明，关键在于高奖励尾部奖励不准确：无法可靠地区分优秀回答和仅仅是很好的回答。通常，这种高奖励的例子在基础语言模型中稀缺。虽然可以从更强的模型或重新编写中获取非策略性示例，但直接用它们训练非策略奖励会导致目标策略模型的奖励设定不准确。
### Innovation
本文研究了基于评分标准的奖励模型。通过设计，评分标准可以利用非策略示例同时对这些示例的副作用免疫。为捕捉高奖励尾部，研究突出了区分优秀和多样回答的重要性，并提出了一种实施此想法的工作流程。实验证明，基于评分标准的奖励显著缓解了奖励过优优化问题，实现了有效的后训练提升。
### Conclusion
研究结果表明，基于评分标准的奖励显著减少奖励过优优化，有效提升大语言模型的后训练效果。开源代码可通过此链接访问。
## 96. `cs.AI` - 幻觉是糟糕的估计吗？ [PDF](https://arxiv.org/pdf/2509.21473), [HTML](https://arxiv.org/abs/2509.21473)
### Authors
Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu
### Background
本文以生成模型中的幻觉问题为背景，将幻觉定义为缺乏任何合理因果关系的估计。研究发现，即使是最优化的最小损失估计器也会产生幻觉，并通过通用数据分布的概率下界验证了这一观点。研究重新定义幻觉为损失最小化与人类可接受输出之间的结构性错位，以及由此引发的估计误差。实验部分验证了这一理论在硬币聚合、开放式QA和文本转图像领域的有效性。
### Innovation
本文的创新之处在于将幻觉问题重新定义为损失最小化与人类可接受输出之间的结构性错位，并证明即使是损失优化的估计器也会产生幻觉。此外，创新地提出了适用于通用数据分布的幻觉产生概率的下界，并通过具体领域的实验验证了这一理论。
### Conclusion
本文从新的角度重新定义了幻觉问题，并通过对损失最小化和人类可接受输出之间错位的分析，发现即使是最优的估计器也可能产生幻觉。实验结果支持了这一理论，并在多个领域得到了验证。
## 97. `cs.AI` - Agribot: 农业专用问答系统 [PDF](https://arxiv.org/pdf/2509.21535), [HTML](https://arxiv.org/abs/2509.21535)
### Authors
Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari
### Background
印度是一个以农业为基础的经济体，准确的农业实践信息对于实现农业最大化增长至关重要。为了帮助农民解决问题，该研究团队基于Kisan Call Center数据集开发了一个农业聊天机器人。该系统可用于回答与天气、市场价格、植物保护和政府计划相关的查询，并提供24小时服务。该系统易于访问且便于理解。
### Innovation
该系统采用句子嵌入模型，初始准确率为56%，通过消除同义词和加入实体提取后，准确率提升至86%。这使得农民能够更加容易地获取与农业相关的信息，从而提高农业产出。该研究简化了呼叫中心工作人员的工作，使他们的努力可以更好地服务于工作目标。
### Conclusion
通过建立农业专用问答系统，农民可以更轻松地获取农业相关信息，从而提高农业生产率。此外，这也使得呼叫中心工作人员的工作变得更加高效，并将他们的努力重新分配到更有价值的目标上。
## 98. `cs.AI` - 基于得分的扩散模型的同胚模型蒸馏 [PDF](https://arxiv.org/pdf/2509.21470), [HTML](https://arxiv.org/abs/2509.21470)
### Authors
Shehtab Zaman,Chengyan Liu,Kenneth Chiu
### Background
生成模型的历史沿革中，同胚生成网络(IGNs)基于同胚映射到目标流形，支持单步和多步生成，提供灵活的成本和样本质量权衡。然而，IGNs 与生成对抗网络(GANs)相似，需要对抗性训练，容易训练不稳定性和模式崩溃。与IGNs相比，扩散和得分基础模型通过逐步从一个分布（通常为高斯分布）运输到目标数据分布，逐渐获得了主流地位，由于其稳定训练动态和高保真生成质量，但实际上会产生高昂的计算成本。新的采样方法和模型蒸馏以及一致性模型已经开发出来以降低采样成本，甚至进行一蹴而就的采样。
### Innovation
该研究通过从扩散模型的得分中蒸馏出同胚模型的方法，提出了一种名为 SIGN 的模型。该模型虽然运行稳定且不依赖于对抗性损失，但能够执行多步骤采样，允许用户在质量和效率之间进行权衡。SIGN 模型创建时依赖于预训练的扩散模型，这使得其获得比迭代得分模型更快速的推理。此外，SIGN 模型可以直接在源域上操作，可以将腐败或替代分布投影回目标流形，从而在无监督编辑输入方面提供零样本编辑能力。该模型已经在多个图像数据集上得到了验证，尤其是在CIFAR和CelebA数据集上，达到最先进的同胚模型结果。
### Conclusion
该研究通过结合扩散模型和同胚生成网络，提出了名为 SIGN 的同胚模型方法。该方法不仅能够提高模型的稳定性，还能通过蒸馏过程提高推理速度，支持多步采样，并提供零样本编辑能力，从而在处理图像数据集时能够达到最先进的结果。
## 99. `cs.AI` - 增强生成式机器听觉 [PDF](https://arxiv.org/pdf/2509.21463), [HTML](https://arxiv.org/abs/2509.21463)
### Authors
Vishnu Raj,Gouthaman KV,Shiv Gehlot,Lars Villemoes,Arijit Biswas
### Background
本文介绍了GMLv2模型的开发背景，该模型用于根据MUSHRA评分预测音频的主观质量。现有的一些广泛使用的指标（如PEAQ和ViSQOL）在预测主观音频质量方面表现不佳或不够全面。为了提高音频质量评估的准确性，并适应更广泛的音频内容和编解码器配置，研究人员提出了GMLv2，增加了基于Beta分布的损失函数来模拟听众评分，并且加入了额外的基于神经音频编码（NAC）的主观数据集，以增强模型的普适性和应用范围。该模型在多种测试集上的大量评估显示，GMLv2在与主观评分的相关性和普遍性上都优于现有的常用指标，可用于理论研究和现代音频编码技术的研发中。
### Innovation
GMLv2的主要创新点在于：1）引入了基于Beta分布的损失函数来更好地模拟听众的评分；2）使用了额外的神经音频编码（NAC）主观数据集，这扩展了模型的一般适用性和应用范围；3）该模型的评估结果表明，GMLv2在预测音频主观质量方面比现有的广泛使用的指标如PEAQ和ViSQOL表现更优，在不同音频内容和编解码器配置下的一致性也更高，提供了一个可扩展且自动化的音频感知质量评估框架，有望加速现代音频编码技术的研发进程
### Conclusion
GMLv2展示了一个通用的自动感知音频质量评估框架，与现有的主观评分高度相关，并且在不同类型的音频内容和编解码器配置下都表现出较好的预测一致性。该模型为现代音频编码技术的研究和开发提供了有力的支持，并提供了加速相关领域研究进程的可能。
## 100. `cs.AI` - 通过潜在可达性进行大语言模型偏差预先检测和引导 [PDF](https://arxiv.org/pdf/2509.21528), [HTML](https://arxiv.org/abs/2509.21528)
### Authors
Sathwik Karnik,Somil Bansal
### Background
大语言模型（LLMs）现已广泛应用于日常工具中，引发了对其生成有害内容的安全问题的担忧。当前主流的安全措施——从人类反馈中进行强化学习（RLHF）——虽然在训练期间有效地塑造了模型的行为，但在推理阶段却无法提供保障，仍然可能产生不安全的输出。
### Innovation
提出了基于可达性的BRT-Align框架，将控制理论上的安全性工具应用于LLM推理。BRT-Align将自回归生成视为潜在空间中的动力系统，并通过逆向可达性学习安全价值函数，以估计轨迹的最坏情况演化。该框架提供了两种互补机制：（1）运行时监控以提前几词预报不安全的完成内容；（2）最少限制的转向过滤器，通过轻微扰动潜在状态来引导生成远离不安全区域。实验表明，BRT-Align在多个LLM和毒性基准测试中比基线提供了更准确、更早的不安全完成检测，并且对LLM安全对齐，BRT-Align显著减少了不安全的生成，同时保持了句子的多样性和连贯性。
### Conclusion
这些发现表明，可达性分析为推理阶段的LLM安全性提供了一种有原则且实用的基础。
## 101. `cs.AI` - 学习使用令牌混合进行推理 [PDF](https://arxiv.org/pdf/2509.21482), [HTML](https://arxiv.org/abs/2509.21482)
### Authors
Adit Jain,Brendan Rappazzo
### Background
强化学习与可验证奖励（RLVR）已经成为提升大型语言模型（LLM）推理能力的主要方法。大多数当前方法遵循组相对策略优化的变体，通过在每一步采样多个推理完成情况并相对评分，然后相应调整策略。然而，这些方法在每一步都采样离散的令牌，而不是利用模型对候选令牌概率分布中的丰富的分布信息。这在非RL环境中的确有益，但在当前的RLVR方法中，由于未利用这种信息，推理搜索空间被不必要的限制了。因此，该研究调查了RLVR中的令牌混合生成（MoT-G）方法，并提出了一种统一框架，该框架不仅涵盖了现有的MoT-G方法，还扩展了RLVR直接在连续令牌混合空间中生成推理过程的方法。实验结果表明，MoT-G方法在7个任务中的80%至90%取得了显著改善，同时仅用一半的轨迹即达到了相当的准确性，显示出改进的训练效率。
### Innovation
研究提出了一个统一的MoT-G框架，该框架将现有的MoT-G方法（包括训练免费方法，它们构建混合嵌入作为토큰嵌入的加权和）进行泛化，并将RLVR扩展到可以直接在连续混合空间中生成推理过程。这种方法通过保留并利用模型概率分布中的分布信息，努力扩大推理搜索空间。实验结果表明，MoT-G方法相比标准解码，展示了更高的推理任务性能和更高效的训练效率。
### Conclusion
该研究通过全面的隐藏状态和令牌层级分析，提供了证据表明MoT-G方法的好处可能源自其在整个推理过程中保持较高的隐藏状态熵以及促进令牌空间中的探索。MoT-G方法显著改善了推理任务表现，同时提高了训练效率，在多个任务上取得了5至35%的性能提升，仅用一半的轨迹就达到了相似的准确性。
## 102. `cs.AI` - 时空对比：DINOv3和V-JEPA2在视频动作分析中的特征表示比较 [PDF](https://arxiv.org/pdf/2509.21595), [HTML](https://arxiv.org/abs/2509.21595)
### Authors
Sai Varun Kodathala,Rakesh Vunnam
### Background
本文研究了两种流行的自监督学习架构（DINOv3和V-JEPA2）在视频动作识别中的应用，旨在比较它们在视频序列中进行空间和时间建模的能力和性能。
### Innovation
本文通过全面比较两种不同的自监督学习架构（DINOv3专注于空间特征提取，V-JEPA2采用联合时间建模），并通过UCF Sports数据集评估了它们在多个维度上的表现，揭示了两者在动作识别中的特定优势和劣势。
### Conclusion
研究结果显示，DINOv3在聚类性能和区分能力方面表现更优，尤其是在姿势可识别的动作中。而V-JEPA2提供了统一且可靠的表示，在各种动作类型中表现稳定。这些发现有助于推进视频分析系统的架构设计，并为根据任务需求和可靠性约束选择合适的特征提取方法提供了实证指导。
## 103. `cs.AI` - 接下来会发生什么？通过生成点轨迹来预测未来的运动 [PDF](https://arxiv.org/pdf/2509.21592), [HTML](https://arxiv.org/abs/2509.21592)
### Authors
Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi
### Background
预测单张图像中的运动是一个挑战，因为无法直接观察到其他参数如物体的速度或施加于它们的力量。研究者们通常依赖回归或生成模型来预测物体的运动，但现有模型往往难以准确捕捉场景中的全局动态和不确定性。
### Innovation
作者提出了一个基于现代视频生成模型架构的新型生成框架，该框架直接生成密集的轨迹网格，而不是像素。这种方法能够捕获场景的全局动态和不确定性，相比之前的回归器和生成器，能够提供更准确和多样的预测结果。此外，作者通过实证研究展示了该方法在机器人等下游应用中的有效性，并在实际物理场景的数据集上取得了令人鼓舞的结果。
### Conclusion
尽管最新的视频生成器通常被视为世界模型，但研究发现它们在预测单张图像中的运动方面存在局限性，尤其是在简单的物理场景中。这种局限性来源于生成像素的开销，而不是直接模拟运动的能力。研究结果表明，作者提出的生成点轨迹的方法在预测未来的运动方面具有优势。
## 104. `cs.AI` - 多目标强化学习在大型语言模型优化中的前瞻视角 [PDF](https://arxiv.org/pdf/2509.21613), [HTML](https://arxiv.org/abs/2509.21613)
### Authors
Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers
### Background
多目标强化学习（MORL）对于优化大型语言模型（LLM）的多个目标提出了挑战和机遇。研究者们需要理解和应用MORL方法来优化LLM，但这些方法在处理复杂的RL问题和个人化功能时存在效率和灵活性的局限。
### Innovation
文章提出了一种MORL分类，并且强调了需要开发一种能够处理不同方法对多样化目标关系影响的基准框架。特别是在元策略MORL的开发上，通过两层学习框架提高效率和灵活性。
### Conclusion
未来的研究方向应该集中在通过MORL方法提高LLM性能的关键问题和潜在解决方案上，特别是关注元策略MORL的发展，以期实现更高的效率和灵活性。
## 105. `cs.AI` - Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning [PDF](https://arxiv.org/pdf/2509.21487), [HTML](https://arxiv.org/abs/2509.21487)
### Authors
Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan
### Background
链式思考（CoT）提示通常可以提高分类准确性，但会引入响应生成的重大吞吐量惩罚（Wei et al., 2022; Cheng and Van Durme, 2024）。为了解决这种权衡，研究人员引入了一种简单的训练方法，用于仅解码语言模型（LMs），称为双向推理蒸馏（DHRD）。该方法包含一个在训练和推理期间使用的聚合分类头，以及一个仅在训练期间由教师推理监督的推理头。该方法通过标签交叉熵损失和输入加推理序列的标记级别语言模型损失的加权和进行训练。在七个SuperGLUE任务上，DHRD相对于聚合基线提高了0.65%-5.47%，并在涉及蕴含/因果任务上表现尤为出色。由于测试时禁用了推理头，推理吞吐量与聚合分类器匹配，超出同等架构的CoT解码达96-142倍的QPS（每秒查询数）.
### Innovation
研究人员提出了一种简单但有效的训练方法——双向推理蒸馏（DHRD），该方法在仅解码语言模型中引入了聚合分类头和推理头，前者用于训练和推理，后者由教师推理在训练时监督。这种方法通过标签交叉熵损失和输入加推理序列的标记级别语言模型损失的加权和进行训练，解决了CoT方法带来的吞吐量降低问题，同时提高了分类准确性，特别是在蕴含和因果任务上取得了显著进步。测试时禁用推理头，保证了高推理吞吐量。该方法超越了CoT解码，提升了模型效率以及准确性.
### Conclusion
双向推理蒸馏（DHRD）方法通过引入聚合分类头和推理头，显著提升了仅解码语言模型的分类准确性，特别是在蕴含和因果任务上表现出色。此外，该方法避免在测试时产生额外的推理开销，提高了推理吞吐量，达到了与聚合分类器相当的性能，同时显著超过CoT解码的QPS。
## 106. `cs.AI` - Li_2: 一个特征涌现和延迟泛化的动力学框架 [PDF](https://arxiv.org/pdf/2509.21519), [HTML](https://arxiv.org/abs/2509.21519)
### Authors
Yuandong Tian
### Background
尽管关于‘grokking’现象，即延迟泛化的研究受到了广泛关注，但尚未有一个数学框架能够说明从训练中复杂结构输入中哪些特征会发生，如何以及在什么条件下发生。本文分析了这一开放性问题，并探讨了复杂结构输入中‘grokking’行为背后的关键阶段。
### Innovation
本文提出了一个新颖的框架，名为$textbf{Li_2}$，它涵盖了2层非线性网络中‘grokking’行为的三个关键阶段：(I) 懒惰学习、(II) 独立特征学习和(III) 交互特征学习，这些特征由各层反向传播的梯度结构$G_F$来表征。特别地，$textbf{Li_2}$能从$G_F$的结构揭示独立学习的动力学过程，以及随之产生的局部最优解特征。这一框架有助于理解关键超参数（如权重衰减、学习率和样本数量）在‘grokking’中的作用，从而得出记忆和泛化的证明性规模律，并揭示最近优化器有效性的根本原因从梯度动力学的第一原理出发。
### Conclusion
通过对样本大小和小组算术任务的影响研究，以及最终确定隐藏节点之间的交互和$G_F$如何集中于待学习的特征，本研究揭示了触发‘grokking’现象的关键路径，并为优化器的有效性提供深层次的见解。这些分析可以推广到多层架构中。
## 107. `cs.AI` - 使用音频语言模型指引音频编辑 [PDF](https://arxiv.org/pdf/2509.21625), [HTML](https://arxiv.org/abs/2509.21625)
### Authors
Zitong Lan,Yiduo Hao,Mingmin Zhao
### Background
音频编辑在VR/AR沉浸体验、虚拟会议、音效设计和其他交互媒体中起着核心作用。然而，近期的生成型音频编辑模型依赖模板式的指令格式，局限于单声道音频。这些模型无法处理描述性音频编辑，用户只需说明期望的结果而把编辑操作的具体细节留给系统处理。
### Innovation
本文引入了SmartDJ，这是一种结合音频语言模型的推理能力和潜在扩散模型的生成能力的新框架，用于立体音频编辑。给定高层次的指令时，SmartDJ将其分解为一系列原子编辑操作，例如添加、删除或空间重新定位事件。这些操作由一个专门用于操作立体音频的扩散模型执行。此外，我们设计了一个数据合成流程，为每个编辑操作生成高层次指令、原子编辑操作及其编辑前后的音频配对示例。
### Conclusion
实验表明，SmartDJ在感知质量、空间真实性和语义对齐方面都优于之前的音频编辑方法。
## 108. `cs.AI` - LANCE: 低秩激活压缩用于高效的边缘设备连续学习 [PDF](https://arxiv.org/pdf/2509.21617), [HTML](https://arxiv.org/abs/2509.21617)
### Authors
Marco Paul E. Apolinario,Kaushik Roy
### Background
在资源受限的环境中，设备学习对于个性化、隐私保护和长期适应至关重要。然而，现有方法在回传过程中存储激活会导致高内存成本，为了减少这种成本，已有压缩方法依赖于重复的低秩分解，引入了额外的计算开销。此外，这些方法尚未被研究用于连续学习场景。
### Innovation
论文提出了LANCE框架，通过一次性执行高阶奇异值分解（SVD）来获取可重复使用的低秩子空间，用于激活投影。这消除了重复分解，减少了内存和计算需求。同时，固定的低秩子空间还能够通过分配任务到正交子空间，而无需存储大量特定任务的矩阵来支持边设备上的连续学习。实验结果显示，LANCE在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上将激活存储减少了最高250倍，同时保持与完整回传相同的准确率。在连续学习基准测试中，LANCE在较低的内存成本下达到了与正交梯度投影方法相当的性能。
### Conclusion
LANCE提供了一种实用且可扩展的解决方案，用于在边缘设备上高效地进行微调和连续学习。
## 109. `cs.AI` - 基于综合表示度量的数据驱动视觉模型类型学 [PDF](https://arxiv.org/pdf/2509.21628), [HTML](https://arxiv.org/abs/2509.21628)
### Authors
Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla
### Background
大型视觉模型在架构和训练范式方面存在显著差异，但缺乏系统的方法来决定它们表示中哪些方面是共享的，哪些是独特的计算策略。这篇文章采用了多种表示相似性度量，涵盖了几何、单元调谐和线性可解码等多个方面，并使用多种互补的方法来评估这些度量的家族区分能力。
### Innovation
文章通过采用受多组学整合启发的Similarity Network Fusion (SNF)方法，实现了模型家族的更清晰区分，并产生了稳健的综合特征图谱。SNF不仅超越了单一度量方法，还揭示了监督ResNets和ViTs之间的明确区分，以及所有自我监督模型跨越架构边界的聚合。此外，文章还提出了混合架构（ConvNeXt, Swin）与掩码自编码器之间的潜在联系，暗示了架构现代化与基于重建的训练之间的一致性。
### Conclusion
生物学启发的方法提供了一种基于表示度量的视觉模型类型学，表明由架构和训练目标共同塑造的新兴计算策略定义了视觉模型的表示结构，这超越了表面设计类别。
## 110. `cs.AI` - 人类与智能代理互动和人类之间互动的心理和行为反应：系统回顾与元分析 [PDF](https://arxiv.org/pdf/2509.21542), [HTML](https://arxiv.org/abs/2509.21542)
### Authors
Jianan Zhou,Fleur Corbett,Joori Byun,Talya Porat,Nejra van Zalk
### Background
随着交互智能代理在社会中的集成，尽管这些代理已展现出类人的能力，但人们对这些代理的反应仍然缺乏深入理解，且研究分散在不同的学科之间。本研究通过系统地整合心理和行为回应，比较了匹配的人类-代理与人类-人类互动，旨在填补这一学术空白。
### Innovation
本研究首次进行了系统的综合分析，对比了人类-代理与人类-人类互动的心理和行为回应。通过纳入162项合格研究（其中146项参与了元分析，共有468个效应大小），结合频率主义和贝叶斯方法，得出了多个新见解。研究结果强调了某些心理反应的上下文依赖性，并指出了塑造伙伴影响的多个调节因素。
### Conclusion
总体而言，人类与代理的互动中的功能性行为和互动体验可以与人类类似，但在基本的社会归因和道德/助人方面的关注度较低。因此，智能代理在功能上与人类具有同等价值，但在内在价值上有所缺失，为智能代理的设计和监管提供了实际意义。
## 111. `cs.AI` - 基于非洲口音英语的领域自意识演讲分辩 [PDF](https://arxiv.org/pdf/2509.21554), [HTML](https://arxiv.org/abs/2509.21554)
### Authors
Chibuzor Okocha,Kelechi Ezema,Christan Grant
### Background
本文研究了非洲口音英语在演讲分辩中的领域效应。研究人员评估了多个生产系统和开放系统在一般对话和临床对话下的表现，使用严格的DER协议（评分重叠）进行评估。临床对话普遍存在领域差距，并且在不同模型中依然显著。错误分析表明，这一差距主要由误报和漏报引起，特别是短对话和频繁重叠的部分。
### Innovation
文章的研究贡献包括：1) 设定了跨领域的受控基准；2) 提出了一种简洁的错误分解和对话级分析的方法；3) 提供了一种轻量级的领域适应方案，该方案通过微调声码模块在口音匹配的数据上进行实验；4) 微调后的方案虽然减少了错误，但未能完全消除领域差异。
### Conclusion
研究结果表明，需要采用重叠感知的分割方法和平衡临床资源作为实际改进的步骤。
## 112. `cs.AI` - 无对齐生成：在扩散模型中学习线性可分表示 [PDF](https://arxiv.org/pdf/2509.21565), [HTML](https://arxiv.org/abs/2509.21565)
### Authors
Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya
### Background
近年来，大规模扩散模型的高效训练策略强调了提升模型中鉴别性特征表示的重要性。现有研究主要聚焦于通过强大的外部编码器获得的特征进行表示对齐，这可以提高通过线性探测评估的表示质量。但是，基于对齐的方法依赖于预训练的大型编码器，计算成本高。因此，该领域亟需一种不需要大型预训练编码器并能直接优化表示性能的训练策略，将线性探测直接纳入网络训练过程，以实现更高的训练效率和生成质量。已有研究表明，在基于流动的转换器架构如SiTs上，可以达到FID得分1.46的优异效果，特别是在256x256的ImageNet数据集上。
### Innovation
本文提出了一种新的正则化训练方法，旨在促进扩散模型中各中间层表示的线性可分性（LSEP），从而不再需要辅助编码器和表示对齐。这种新技术直接将线性探测融入到网络的训练动态中，而非仅仅作为一个简单的后续评估工具。这种方法显著提升了训练效率和生成质量，在基于流动的转换器架构（如SiTs）上表现出色，特别是在大规模图像生成任务中实现了FID得分1.46的最佳结果。
### Conclusion
本文提出了通过促进线性可分性（LSEP）的训练策略来改进扩散模型的中间层表示，无需依赖强大的外部编码器和表示对齐，直接将线性探测纳入训练过程，从而大幅提升了训练效率和生成质量。在SiTs架构上的实验结果验证了该方法的有效性，特别是在大规模数据集上的FID得分达到了1.46，展现了其卓越性能。
## 113. `cs.AI` - 通过在协方差图上发现困难负例来增强对比学习以提高地理定位性能 [PDF](https://arxiv.org/pdf/2509.21573), [HTML](https://arxiv.org/abs/2509.21573)
### Authors
Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner
### Background
全球范围内，在多种环境中实现准确且鲁棒的基于图像的地理定位颇具挑战，因为存在视觉模糊场景和许多地区缺乏显着地标。现有的对比学习方法通过在街景图像和对应位置之间对齐特征来显示出有前景的表现，但它们忽视了地理空间中的潜在空间依赖性。因此，它们无法处理地理上相似但标记为负的错误否定对，并且难以区分具有视觉相似性但地理位置相距遥远的负面例子。
### Innovation
本文提出了一种新的空间调节对比学习策略，该策略结合了半变异图，这是一种用于建模空间相关性如何随距离变化的地统计工具。通过将图像在特征空间中的距离与其地理距离联系起来，半变异图捕获了空间相关性中预期的视觉内容。使用拟合的半变异图，定义给定空间距离下的预期视觉差异作为基准，以识别困难负例和错误否定对。将该策略集成到GeoCLIP中，在OSV5M数据集上进行评估，结果表明明确建模空间先验可以提高基于图像的地理定位性能，特别是在更精细的细节上表现更好。
### Conclusion
引入的空间调节对比学习策略利用半变异图捕获空间相关性和预期视觉内容，从而在OSV5M数据集上提高了基于图像的地理定位性能，有效识别了困难负例和错误否定对。
## 114. `cs.AI` - OjaKV: 基于Oja规则的上下文感知在线低秩KV缓存压缩 [PDF](https://arxiv.org/pdf/2509.21623), [HTML](https://arxiv.org/abs/2509.21623)
### Authors
Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen
### Background
大型语言模型的长上下文处理能力受到关键值（KV）缓存的记忆瓶颈制约，这限制了模型的性能。例如，Llama-3.1-8B模型处理32K令牌提示和批量大小为4的情况时，需要约16GB的KV缓存，这超过了模型的权重大小。虽然低秩投影压缩KV缓存是很有前景的方法，但现有方法依赖于静态的、事前学习的子空间，这些方法在数据分布发生变化时效果较差。
### Innovation
本文引入OjaKV，这是一种结合了策略性混合存储策略和在线子空间适应的新框架。OjaKV通过保留重要且最近的令牌的完整秩，在压缩过程中保持高保真度，并通过Oja算法在线主成分分析_INCREMENTALLY_适应中间令牌的低秩压缩。这种适应包括在预填充提示时进行全面更新，并在解码过程中进行轻量级的周期性更新，以确保子空间与上下文的演变保持一致。重要的是，该框架与现代注意力模块（如FlashAttention）完全兼容。实验结果表明，OjaKV能够在高压缩比率下保持甚至提高零样本准确性，并且在需要复杂推理的长上下文基准测试中表现出特别显著的改进。
### Conclusion
实验结果表明，OjaKV在高压缩比下能够保持甚至提高零样本准确性，特别是在要求复杂推理的长上下文基准测试中表现出较强优势，强调了在线子空间适应在动态跟踪上下文变化中的重要性。这些结果证明了OjaKV作为一种实用的、即插即用的解决方案，能够在不进行模型微调的情况下实现内存高效的长上下文推理。
## 115. `cs.AI` - InvBench: LLMs能否通过不变量合成加速程序验证？ [PDF](https://arxiv.org/pdf/2509.21629), [HTML](https://arxiv.org/abs/2509.21629)
### Authors
Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken
### Background
程序验证依赖于循环不变式，但自动发现强大的不变式仍然是一个长期存在的挑战。现有的研究评估方法主要集中在正确性上，而忽略了解析不变式对验证速度提升的重要性。本研究旨在通过引入一个基于验证器的决策过程来评估LLM在不变式合成中的表现，该过程提供了形式上的正确性保证，评估不仅包括正确性，还包括不变式提供的速度提升。
### Innovation
本研究创新性地提出了一种基于验证器的框架来评估LLM在不变式合成中的表现，并且不仅仅评估正确性，还评估不变式对验证速度提升的影响。此外，研究表明不同模型在速度提升方面存在显著差异，强调了模型能力的重要性，并提出通过监督微调和Best-of-N抽样可以改善性能。
### Conclusion
尽管基于LLM的验证器是一个有希望的方向，但它们目前仍不如传统的解算器具有显著优势。当前的基准测试仍然具有挑战性，模型能力对于提高验证速度至关重要。通过监督微调和Best-of-N抽样的方法可以有效提升性能：微调3589个样本和使用Best-of-N抽样可以显著提高验证速度。
## 116. `cs.AI` - MobiLLM: 一个用于6G开放RAN闭环威胁缓解的自主AI框架 [PDF](https://arxiv.org/pdf/2509.21634), [HTML](https://arxiv.org/abs/2509.21634)
### Authors
Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin
### Background
6G网络的发展正在受到Open Radio Access Network (O-RAN)范式的加速推动，该范式是开放且可互操作的架构，使智能、模块化的应用可以在公共电信和私营企业领域运行。这种开放性带来了前所未有的创新机会，同时也扩大了攻击面，对坚韧、低成本且自主的网络安全解决方案提出了需求。传统防御措施主要是反应式的、劳动密集型且对于下一代系统的规模和复杂性来说是不合适的。当前的O-RAN应用主要集中在网络优化或被动威胁检测，对闭环的自动化响应能力有限。因此，急需一种针对6G O-RAN环境的完全自动化的威胁缓解框架来填补这一重要空白。
### Innovation
文章提出了一种基于大型语言模型（LLM）的模块化多代理系统来实现完全自动化、端到端的威胁缓解框架MobiLLM，其中包括威胁分析代理、威胁分类代理和威胁响应代理。该框架以MITRE FiGHT框架和3GPP规范为基础，具有安全护栏，为可信的人工智能驱动网络安全奠定了蓝图。初步评估表明，MobiLLM能够有效识别并组织复杂的缓解策略，大幅降低响应时间，展示了自主安全操作在6G中的可行性。
### Conclusion
MobiLLM基于大型语言模型提供了一个可靠的闭环威胁缓解框架，对于6G开放RAN环境中的信任驱动网络安全具有重要意义。该框架可以显著提高响应效率，展现了自主安全操作的可行性，为未来的网络安全提供了新的方案。
## 117. `cs.AI` - MORPH：形状无关的偏微分方程基础模型 [PDF](https://arxiv.org/pdf/2509.21670), [HTML](https://arxiv.org/abs/2509.21670)
### Authors
Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence
### Background
当前存在多样化的时空数据集，这些数据集在维度、分辨率和物理场类型方面各不相同。对于偏微分方程（PDEs）的处理通常依赖于特定领域的模型，这限制了它们的通用性和灵活性。特别是在处理混合标量和矢量场的数据时，传统的模型缺乏有效的处理机制。
### Innovation
本文提出了一种名为MORPH的模块化形状无关自回归基础模型，适用于处理1D到3D的异质时空数据集。MORPH基于卷积视觉变换器的主干结构，能够无缝处理具有不同维度和不同分辨率的数据集。该架构结合了三个主要组成部分：成分卷积，用于联合处理标量和矢量通道以捕捉局部相互作用；跨场交叉注意力，用于建模和选择性地在不同物理场之间传播信息；轴向注意力，通过在空间和时间轴上分解完全时空自注意力来降低计算负担，同时保留表达能力。MORPH能够在广泛的下游预测任务中表现出色，并且在零样本和全样本通用性方面优于从头训练的模型。
### Conclusion
在广泛的评估中，MORPH匹配或超越了强大的基线模型和最近的最先进的模型。这些能力表明MORPH是一个灵活而强大且能够从异质和多模态的科学观察中学习的骨干模型，为实现可扩展和数据高效的科学机器学习奠定了道路。
## 118. `cs.AI` - 使用强化学习优化单元ary的非Clifford-count合成 [PDF](https://arxiv.org/pdf/2509.21709), [HTML](https://arxiv.org/abs/2509.21709)
### Authors
David Kremer,Ali Javadi-Abhari,Priyanka Mukhopadhyay
### Background
高效实现幺正算子的实施对于实际化量子算法相对于经典算法的优势至关重要。现有的合成算法在量子比特和非Clifford门的数量上存在指数级依赖性。本文研究了使用强化学习（RL）在保持Clifford+T和Clifford+CS门集的精确实施的前提下，合成单元ary的方法，通过优化T-count和CS-count。
### Innovation
设计了使用RL的工作框架，采用信道表示法简化矩阵操作，减少了搜索复杂性。与之前的成果相比，在更短的时间内，成功率更高，能够合成更大的单元ary，特别是对于2个量化体Clifford+T算法，合成的T门数量最多可达100个，是之前RL算法的5倍，也是目前为止任何方法中最大规模的实现。
### Conclusion
本文所开发的RL算法对于1个量化体的T-count-optimal分解，恢复了已知的最优线性复杂度算法；对于2个量化体Clifford+CS单元ary，算法达到了线性复杂度，这是之前使用SO(6)表示法才能实现的。
## 119. `cs.AI` - 开发AI教育容量提升策略 [PDF](https://arxiv.org/pdf/2509.21713), [HTML](https://arxiv.org/abs/2509.21713)
### Authors
Noah Q. Cowit,Sri Yash Tadimalla,Stephanie T. Jones,Mary Lou Maher,Tracy Camp,Enrico Pontelli
### Background
随着人工智能(AI)在现实生活中的重要性日益增加，许多机构正在面临如何有效教学的挑战。为此，计算研究协会(CRA)组织了32次专家讨论会，汇集了202名致力于提高AI教育质量的专家，讨论的主题包括AI知识领域、教学方法、基础设施挑战、扩大AI教育容量以及面向所有人的AI教育。讨论会按机构类型组织，以考虑不同AI教育环境的具体目标和资源。研究指出，大量数字鸿沟在基础设施方面造成了重大障碍，尤其是对于资源有限的机构而言。学者们注意到，这造成了一些问题，如缺乏具有AI专业知识的教师、计算基础设施短缺无法满足学生和教师开发和测试AI模型的需求、以及机构技术支持不足。此外，更新课程和创建新项目的负担很大。为应对教师短缺，需要可访问且不间断的专业发展，以帮助教师学习AI及其伦理方面，这一点尤为重要，尤其是在资源有限的环境中。
### Innovation
研究重点提出了扩大AI教育容量的策略，包括通过连续的专业发展支持解决教师缺口，提供中央资源库来解决机构对AI教育资源的需求。这一创新性地汇集了专家的看法，为机构提供了切实可行的资源和策略，以更好地应对AI教育的挑战。
### Conclusion
研究总结指出，通过实现资源的有效利用和教师的不断专业知识更新，可以有效提升AI教育的能力，但同时也强调，这些资源和策略需要得到广泛的认可和传播以切实有效落地实施。
## 120. `cs.AI` - 安全、可信赖的人工通用智能的局限性 [PDF](https://arxiv.org/pdf/2509.21654), [HTML](https://arxiv.org/abs/2509.21654)
### Authors
Rina Panigrahy,Vatsal Sharan
### Background
人工智能系统中的安全、信任和通用人工智能（AGI）是崇高的目标，但这些概念有许多非正式的解释。本文旨在为这些概念提供严格的数学定义，并展示它们之间的根本不兼容性。作者定义系统的安全为从不做出虚假声明的属性，信任为假设系统是安全的，AGI为人工智能系统始终匹配或超越人类能力。作者通过严格的安全和信任的数学定义，展示了安全并且可信赖的AI系统无法成为AGI系统的结论，即这样的系统在某些任务实例上无法解决而人类轻而易举可以解决的任务。证明涉及程序验证、规划和图可达性，与哥德尔不完备定理和图灵的停机问题不可判定性证明有相似之处。
### Innovation
作者为安全、信任和AGI提供严格的数学定义，并通过严格的证明展示了这些概念之间的根本不兼容性。他们通过程序验证、规划和图可达性展示了这一结果，并且提到了与哥德尔和图灵的定理相类似的证明方式。
### Conclusion
对于严格数学定义的安全和信任，安全且可信赖的AI系统无法成为AGI系统。这一结论通过具体任务实例（如程序验证、规划和图可达性）进行了验证，并强调了在实际部署中可能依赖于系统的其他实用解释。
## 121. `cs.AI` - LFA-Net: 一种带有LiteFusion注意力机制的轻量级网络用于视网膜血管分割 [PDF](https://arxiv.org/pdf/2509.21738), [HTML](https://arxiv.org/abs/2509.21738)
### Authors
Mehwish Mehmood,Ivor Spence,Muhammad Fahim
### Background
轻量级视网膜血管分割对于早期诊断威胁视力和全身性疾病至关重要，特别是在计算资源有限的临床环境中。尽管基于深度学习的分割方法在不断改进，现有模型仍然面临小血管分割和高计算成本的挑战。
### Innovation
提出了新的血管分割网络LFA-Net，该网络结合了新设计的轻 fusion-注意力模块，该模块集成了残差学习连接、Vision Mamba 优化的动力学以及基于调制的注意力。这些功能使模型能够高效且轻量地捕捉局部和全局上下文。
### Conclusion
LFA-Net 在 DRIVE、STARE 和 CHASE_DB 数据集上表现出色，Dice得分分别为83.28%、87.44% 和 84.50%，Jaccard指数分别为72.85%、79.31% 和 74.70%，其具有0.11百万参数、0.42MB内存大小和4.46GFLOPs，非常适合资源受限的环境。
## 122. `cs.AI` - DIM: 强制深度神经网络中的领域启发式单调性 [PDF](https://arxiv.org/pdf/2509.21666), [HTML](https://arxiv.org/abs/2509.21666)
### Authors
Joshua Salim,Jordan Yu,Xilei Zhao
### Background
虽然深度学习模型在预测任务中表现出色，但由于其复杂的结构和大量的参数，它们往往会出现过拟合，导致它们记住训练数据，包括噪声，而不是学习能够推广到新数据的模式。为了解决这一挑战，本文提出了一种新的正则化方法，即强制深度神经网络中的领域启发式单调性（DIM），该方法在复杂深度学习模型中保持领域启发式的单调关系，以进一步提高预测性能。本文通过全面的数学框架形式化这一方法，建立了线性参考，度量偏离单调行为的程度，并将这些措施整合到训练目标中。实验结果表明，即使施加适度的单调性约束也能持续提升模型性能。DIM通过在深度神经网络中应用领域启发式的单调性约束来规定模型行为，减少过拟合，从而增强预测性能
### Innovation
提出了一个新的正则化方法——强制深度神经网络中的领域启发式单调性（DIM），该方法通过施加单调性约束，并以线性基准衡量违反情况，鼓励模型遵循预期的趋势，同时保留其预测能力。这种方法通过数学框架形式化，有效减少了过拟合问题
### Conclusion
通过在各种神经网络架构上进行的实验，结果表明即使是适度的单调性约束也能持续提升模型性能。DIM通过施加领域启发式的单调性约束来规整模型行为并减少过拟合，从而增强了深度神经网络的预测性能
## 123. `cs.AI` - QueryGym: 逐步交互与关系数据库 [PDF](https://arxiv.org/pdf/2509.21674), [HTML](https://arxiv.org/abs/2509.21674)
### Authors
Haritha Ananthakrishanan,Harsha Kokel,Kelsey Sikes,Debarun Bhattacharjya,Michael Katz,Shirin Sohrabi,Kavitha Srinivas
### Background
现有的框架常常将代理绑定到特定的语言方言中或者使推理过程变得不透明；然而，QueryGym 则要求代理构建明确的关系代数操作序列，确保引擎无关的评估和透明的步步为营的规划过程。这种环境被实现为一个 Gymnasium 接口，提供观察结果（包括模式详细信息、中间结果和执行反馈）并接收表示数据库探索（例如，预览表、采样列值、检索唯一值）以及关系代数操作（例如，过滤、投影、连接）的行动。
### Innovation
QueryGym 是一个互动环境，使用关系代数操作序列来评估和构建基于语言模型 (LLM) 的查询规划代理，使代理能够进行明确的操作指令，且过程透明；而现有的框架往往局限于特定的语言方言或使其推理过程不透明。这种环境作为寻找错误纠正、透明度和查询生成中的强化学习研究的有效试验床，对于研究环境有显著的创新性贡献。
### Conclusion
QueryGym 被设计为评估及展示 LLM 查询规划代理的一种实用检测工具，通过与现代 LLM 查询数据库的对比展示了其独特的优点。它为研究错误纠正、透明度和查询生成强化学习奠定了基础，且为此提供了实际的试验环境。要了解演示内容，请访问这个网址：https://xxx.
## 124. `cs.AI` - 逻辑假设：从零到满知识的神经符号集成 [PDF](https://arxiv.org/pdf/2509.21663), [HTML](https://arxiv.org/abs/2509.21663)
### Authors
Davide Bizzaro,Alessandro Daniele
### Background
神经符号集成（NeSy）将神经网络学习与符号推理相结合。该领域可以分为两类方法：一类是将手工制作的规则注入神经模型，另一类是从数据中诱导符号规则。论文介绍了一种新的语言——假设逻辑（LoH），它统一了这两类方法，允许灵活地将数据驱动的规则学习与符号先验和专家知识结合。假设逻辑通过扩展命题逻辑语法，引入了一个可学习参数的选择操作符，该操作符从一组选项中选择子公式。通过模糊逻辑，假设逻辑中的公式可以编译成可微计算图，因此可以通过反向传播学习最佳选择。这种框架不仅涵盖了部分现有的NeSy模型，还增加了任何程度的知识指定的可能性。此外，使用哥德尔模糊逻辑和最近开发的哥德尔技巧，生成的模型可以在不损失性能的情况下离散化为硬的布尔函数值函数。我们提供了这种模型的实证分析，表明在表格数据和视觉井字棋NeSy任务上具有很强的结果，同时生成可解释的决策规则。
### Innovation
1. 介绍了假设逻辑（LoH）语言，统一了手工规则注入和数据驱动规则学习的两类方法，使得知识指定更加灵活。2. 通过引入可学习参数的选择操作符和使用模糊逻辑编译计算图，该语言可以通过反向传播学习最佳选择。3. 该框架涵盖部分现有NeSy模型，并允许任意程度的知识指定。4. 使用哥德尔模糊逻辑和哥德尔技巧，生成的模型可以离散化为硬的布尔函数值函数而不损失性能。
### Conclusion
假设逻辑展示了强大的结果，特别是在表格数据和视觉井字棋NeSy任务上，同时生成了可解释的决策规则。此外，这种模型的框架为神经符号集成提供了新的途径，允许更多程度的知识指定。
## 125. `cs.AI` - 非我的代理，非我的边界？在AI委托信息共享中的个人隐私边界引导 [PDF](https://arxiv.org/pdf/2509.21712), [HTML](https://arxiv.org/abs/2509.21712)
### Authors
Bingcan Guo,Eryue Xu,Zhiping Zhang,Tianshi Li
### Background
理解个体复杂的隐私披露行为远超一般规范，因隐私决定具有情境依赖性且涉及复杂权衡。目前，引导个体隐私边界并符合其偏好具有挑战性。本文研究了AI辅助的隐私边界引导方法，通过区分任务来探究个体的隐私界限。研究通过系统地改变沟通角色和委托条件，收集了169名参与者在61种情况下定义的1681个边界规范，分析情境因素和个体差异对边界定义的影响。
### Innovation
提出了一种基于AI的隐私边界引导方法，通过区分任务来更好地了解个体的隐私界限。研究通过系统地改变沟通角色和代理条件，收集大量个体边界规范，揭示不同情境因素和个体差异对隐私边界定义的影响。
### Conclusion
实证结果表明，沟通角色影响个体接受详细和可识别的披露，AI代理增加了个体对披露标识符的敏感度，并导致个体之间的共识较少。研究强调将隐私偏好引导置于实际数据流动中的重要性，建议将细腻的隐私边界作为未来AI系统对齐的目标。
## 126. `cs.AI` - SlotFM：具有插槽注意力机制的用于多样化下游任务的运动基础模型 [PDF](https://arxiv.org/pdf/2509.21673), [HTML](https://arxiv.org/abs/2509.21673)
### Authors
Junyong Park,Oron Levy,Rebecca Adaimi,Asaf Liberman,Gierad Laput,Abdelkareem Bedri
### Background
可穿戴加速度计广泛应用于手势识别、步态分析和运动监测等场景，但现有的许多基础模型主要集中在分类日常活动，如行走和锻炼，限制了其对依赖其他信号特性的更广泛任务的应用，如精细动作或节奏识别等。这些限制使其在处理多样的下游任务时表现欠佳。
### Innovation
提出的SlotFM是一种加速度计基础模型，可以跨多种下游任务通用。SlotFM采用Time-Frequency Slot Attention，这是一种扩展的Slot Attention机制，能够处理原始信号的时间和频域表示。它生成多个小嵌入（插槽），每个插槽捕捉信号的不同组件，使任务特定的头部能够关注数据中最相关部分。此外，还引入了两种损失正则化器，分别捕捉局部结构和频率模式，这些正则化器改善了对细粒度细节的重建，帮助嵌入保持与任务相关的信息。SlotFM在16项超越标准人类活动识别的分类和回归下游任务中测试，优于13项任务中的现有半监督方法，在其余任务上达到了与最佳方法相当的结果，平均性能提高了4.5%。这一结果显示了传感基础模型的强大泛化能力。
### Conclusion
SlotFM作为一种新型的加速度计基础模型，在处理多样化的下游任务上表现出色，显示出强大的泛化性能和任务相关信息的保留能力，为未来的信号处理和行为识别应用提供了新的可能性。
## 127. `cs.AI` - Self-Speculative Biased Decoding for Faster Live Translation [PDF](https://arxiv.org/pdf/2509.21740), [HTML](https://arxiv.org/abs/2509.21740)
### Authors
Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang
### Background
大型语言模型（LLMs）在各种文本生成任务中展现出卓越能力，但在实时应用（如实时翻译）中，由于输入上下文的不断扩展，如何在持续更新输出的同时保持合理的计算成本以满足延迟要求仍然是一个挑战。
### Innovation
本文重新审视了同步翻译中的重译方法，并提出了SELF-Speculative Biased Decoding（自我推测偏置解码）这一新颖的推理范式。该方法通过利用最新的输出作为当前增长输入上下文的草案，并在验证阶段偏向草案令牌以增加草案接受率，从而避免从头重新生成输出，有效地减少了闪烁现象并提高了翻译速度，且表现为模型无特定依赖性并可直接应用于加速延迟敏感的流水线中。
### Conclusion
实验结果表明，该方法在同步文本到文本的重翻译任务中相比传统的自回归重翻译实现最高1.7倍的加速，同时通过采用仅显示的屏蔽掩蔽技术，显著减少了80%的闪烁现象，且未牺牲翻译质量。
## 128. `cs.AI` - HyperCore：基于超球体模型 noisy 环境下的 coreset 选择 [PDF](https://arxiv.org/pdf/2509.21746), [HTML](https://arxiv.org/abs/2509.21746)
### Authors
Brian B. Moser,Arundhati S. Shanbhag,Tobias C. Nauen,Stanislav Frolov,Federico Raue,Joachim Folz,Andreas Dengel
### Background
现有的 coreset 选择方法旨在识别数据集的代表性子集以提高模型训练效率，但这些方法通常忽略注释错误的可能性，且要求固定的剪枝比率，在现实场景中很难实现。
### Innovation
提出了 HyperCore，一种针对 noisy 环境的鲁棒且自适应的 coreset 选择框架。HyperCore 利用轻量级的超球体模型，每个类别学习一个，使得同类样本靠近超球体中心，自然地将不同类样本根据距离进行分类。HyperCore 通过 Youden's J 统计量自适应选择剪枝阈值，无需超参数调整即可实现自动、噪声感知的数据剪枝。
### Conclusion
实验结果表明，HyperCore 在 noisy 和低数据场景下始终优于最先进的 coreset 选择方法，有效丢弃了错误标记和模棱两可的点，生成了紧凑且高度信息性的子集，适用于可扩展且无噪声的学习任务。
## 129. `cs.AI` - 无偏分箱：公平感知的属性表示 [PDF](https://arxiv.org/pdf/2509.21785), [HTML](https://arxiv.org/abs/2509.21785)
### Authors
Abolfazl Asudeh,Zeinab(Mila)Asoodeh,Bita Asoodeh,Omid Asudeh
### Background
在共享数据集之前，将原始特征离散化为桶化属性表示是一种常见步骤。然而，这一过程会引入显著的数据偏差，加剧下游任务中的不公平性。
### Innovation
本文提出了无偏分箱问题，通过给定一个需要桶化的属性，找到其最接近等大小分箱的无偏离散化，同时满足不同桶间的组公平性。边界候选集被定义并证明了无偏分箱必须从中选择边界。提出了基于候选边界的高效动态规划算法来解决无偏分箱问题。为适应实际场景的复杂性，本文还提出了ε偏向分箱问题，引入了动态规划（DP）和局部搜索（LS）相结合的高效算法。
### Conclusion
通过无偏分箱和ε偏向分箱问题的解决方法，本文提供了公平感知的属性表示方式，同时平衡公平性和可行性。
## 130. `cs.AI` - 基于SDE的时空图深度学习在纵向脑网络中揭示阿尔茨海默病进展 [PDF](https://arxiv.org/pdf/2509.21735), [HTML](https://arxiv.org/abs/2509.21735)
### Authors
Houliang Zhou,Rong Zhou,Yangying Liu,Kanhao Zhao,Li Shen,Brian Y. Chen,Yu Zhang,Lifang He,Alzheimer's Disease Neuroimaging Initiative
### Background
识别客观神经成像生物标志物以预测阿尔茨海默病（AD）进展对于及时干预至关重要。然而，这一任务因复杂的空间-时间特征偏差下的脑网络功能障碍而具有挑战性，这些特征往往被现有方法所忽视。
### Innovation
我们开发了一种可解释的时空图神经网络框架，通过利用双随机微分方程（SDE）来预测未来的AD进展，同时该框架能够有效学习稀疏的区域和连通性重要性概率，有助于识别与疾病进展相关的关键脑回路异常，并揭示多种已知和新型神经系统水平的和性别特异性生物标志物，提供AD进展的新的生物学机制见解。
### Conclusion
我们的研究强调了时空图基于的学习在纵向不规则成像数据中预测AD进展的潜力，即使在纵向成像数据不规则的情况下，它也能实现早期且个体化的预测。
## 131. `cs.AI` - UISim：动态移动环境中的互动图像基础UI模拟器 [PDF](https://arxiv.org/pdf/2509.21733), [HTML](https://arxiv.org/abs/2509.21733)
### Authors
Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen
### Background
由于移动设备环境的动态性和多样性，开发和测试用户界面（UI）以及训练AI代理与之交互是具有挑战性的。现有的方法通常依赖于繁琐的物理设备或受限的屏幕截图的静态分析，这阻碍了大规模测试和智能UI代理的开发。
### Innovation
我们提出了 UISim，一种基于图像的新型UI模拟器，提供了一个从屏幕图像着手的动态和互动平台来探索移动电话环境。我们的系统采用两阶段方法，首先预测下一个UI状态的抽象布局，然后基于该预测布局生成新的视觉上一致的图像。该方法使UI过渡的真实模拟成为可能。UISim 提供了UI测试、快速原型设计和合成数据生成的即时实用价值。其互动功能为高级应用铺平了道路，例如为AI代理进行UI导航任务规划。实验结果表明，UISim 在生成具有真实感和一致性的后续UI状态方面优于端到端的UI生成基准，突显了其精度和简化UI开发及提升AI代理训练的潜力。
### Conclusion
实验结果显示，与端到端的UI生成基准相比，UISim 在生成具有真实感和一致性的后续UI状态方面表现更优，突显了其高精度和在简化UI开发及增强AI代理培训方面的潜力。
## 132. `cs.AI` - Backdoor Attribution: 光明正大揭示和控制语言模型中的后门 [PDF](https://arxiv.org/pdf/2509.21761), [HTML](https://arxiv.org/abs/2509.21761)
### Authors
Miao Yu,Zhenhong Zhou,Moayad Aloqaily,Kun Wang,Biwei Huang,Stephen Wang,Yueming Jin,Qingsong Wen
### Background
大规模语言模型（LLMs）易受到数据投毒引发的后门攻击影响，但其内部机制仍不清楚。现有研究主要集中在语言模型的安全性解释上，如对齐、脱笼和幻觉，忽略了后门机制的解释，难以完全理解和消除后门威胁。
### Innovation
本文提出Backdoor Attribution（BkdAttr）框架，通过三部分因果分析揭示后门机制。首先引入Backdoor Probe验证了学习后门特征的存在，接着开发了Backdoor Attention Head Attribution (BAHA)，有效识别具体负责处理这些特征的注意力头。实验表明，通过删除少量（约为3%）的注意力头，可以显著降低攻击成功率（ASR）。进一步地，基于这些发现，构建了Backdoor Vector，通过单点干预能够大幅提升或完全消除后门攻击。
### Conclusion
本文在语言模型后门的机制性可解释性方面进行了开创性探索，提出了一种强大的后门控制方法，并为社区提供了实际操作性的见解。
## 133. `cs.AI` - FastGRPO:通过并发感知投机性解码和在线草稿学习加速策略优化 [PDF](https://arxiv.org/pdf/2509.21792), [HTML](https://arxiv.org/abs/2509.21792)
### Authors
Yizhou Zhang,Ning Lv,Teng Wang,Jisheng Dang
### Background
小组相对策略优化（GRPO）在通过强化学习提高大规模语言模型（LLMs）的推理能力方面显示出巨大的潜力。然而，其实际部署受限于训练过程异常缓慢，主要由于生成每个查询多个响应的自回归计算密集型生成过程，使得生成阶段成为主要的性能瓶颈。尽管推测性解码为加速提供了可能的方向，但在高并发训练条件下直接应用推测性解码仅能实现有限的加速效果。
### Innovation
我们提出了一种并发感知的推测性解码框架，该框架根据实时的并发级别动态调整起草和验证策略，从而最大化生成过程的加速。此外，我们引入了一种在线草稿学习机制，以不断使用目标模型的反馈信号使草稿模型适应分布偏移，期间源自训练。
### Conclusion
实验结果表明，我们提出的方法在多个数学推理数据集和模型上实现了2.35到2.72倍的端到端加速，显著优于现有基准方法的效率。代码可在以下链接获取：this https URL.
## 134. `cs.AI` - POLO：引导型多轮强化学习在先导优化中的应用 [PDF](https://arxiv.org/pdf/2509.21737), [HTML](https://arxiv.org/abs/2509.21737)
### Authors
Ziqing Wang,Yibo Wen,William Pattie,Xiao Luo,Weimin Wu,Jerry Yao-Chieh Hu,Abhishek Pandey,Han Liu,Kaize Ding
### Background
药物发现中的先导优化需要通过迭代循环有效地探索广泛的化学空间，以提高分子性质的同时保持与原始先导化合物的结构相似性。尽管近年来取得了进步，传统的优化方法在样本效率方面仍存在困难，即在有限的专家评估下实现良好的优化效果。大型语言模型（LLMs）因其上下文学习和指令遵循能力提供了有希望的方法，这与这些迭代过程自然契合。然而，现有的基于LLM的方法未能充分利用这一优势，每个优化步骤被独立处理。鉴于此，我们提出了POLO（偏好引导的多轮优化），使LLM能够学习完整的优化历程，而非孤立步骤。核心在于POLO引入了偏好引导的策略优化（PGPO），这是一种创新强化学习算法，在轨迹级和循环级上提供学习信号，从而实现更高效样本利用。
### Innovation
POLO引入了一种名为偏好引导的策略优化（PGPO）的新颖强化学习算法，能够从完整的优化历程中学习，而不是孤立的步骤。PGPO在两个互补的层面进行学习：轨迹级优化强化成功的策略，而循环级偏好学习提供密集的比较反馈，通过在每个轨迹中对中间分子进行排名。这种方法在中间评估中实现了双层学习，从而提高了样本效率，充分利用每次昂贵的专家调用。
### Conclusion
广泛的实验表明，POLO在单性质任务中实现了84％的平均成功率（相比基线高出2.3倍），并使用仅有500次专家评估在多性质任务中达到了50％的成功率，显著地推动了样本高效分子优化的技术前沿。
## 135. `cs.AI` - Brain PathoGraph Learning [PDF](https://arxiv.org/pdf/2509.21742), [HTML](https://arxiv.org/abs/2509.21742)
### Authors
Ciyuan Peng,Nguyen Linh Dan Le,Shan Jin,Dexuan Ding,Shuo Yu,Feng Xia
### Background
脑图学习已经在神经科学和人工智能领域取得了显著成果，但现有方法在学习疾病相关知识时存在困难，导致参数量和计算成本高昂。这降低了它们的效率，并限制了它们在临床应用中的实用性。
### Innovation
提出了一个轻量级的脑病路径图学习（BrainPoG）模型，通过病理模式筛选和病理特征精炼来实现高效的脑图学习。BrainPoG首先通过提取高疾病相关子图的病理模式来进行图修剪和病灶定位，构造出一个不含较少疾病相关子图的路径图。之后设计了一个病理特征精炼模块，减少路径图中无关疾病噪声特征，增强每个节点的病理特征，从而实现独立试图学习有关疾病的信息并避免无关信息，提高计算效率。
### Conclusion
在四个基准数据集上的广泛实验表明，BrainPoG在各种脑疾病检测任务中，在模型性能和计算效率方面均表现出优越性。
## 136. `cs.AI` - 大型语言模型能否实现运动学的自动形式化? [PDF](https://arxiv.org/pdf/2509.21840), [HTML](https://arxiv.org/abs/2509.21840)
### Authors
Aditi Kabra,Jonathan Laurent,Sagar Bharadwaj,Ruben Martins,Stefan Mitsch,André Platzer
### Background
自主的计算物理系统如机器人和自动驾驶汽车可以从使用形式化方法可靠地分析其控制决策中受益。然而，在这些问题可以被解决之前需要明确地描述问题，这需要编写计算物理系统的形式物理模型，这是一个传统上需要高度专业知识且成为瓶颈的复杂任务。
### Innovation
本研究实验性地探索了大型语言模型（LLMs）是否能够自动化形式化过程。设计了一个由本科物理运动问题组成的20个问题基准集，并要求LLM从自然语言对象运动描述生成差分博弈逻辑（dGL）模型，该模型通过语法检查和迭代改进，并通过符号执行dGL公式验证其语义一致性。结果显示，最成功样本的成功率为70%。
### Conclusion
大型语言模型在将自然语言转化成带有连续动力学的混合博弈逻辑上达到了70%的成功率。通过分析失败案例，为大家提供了关于未来改进方向的第一定量基准。
## 137. `cs.AI` - SubZeroCore：无需训练的子模态方法进行核心集选择 [PDF](https://arxiv.org/pdf/2509.21748), [HTML](https://arxiv.org/abs/2509.21748)
### Authors
Brian B. Moser,Tobias C. Nauen,Arundhati S. Shanbhag,Federico Raue,Stanislav Frolov,Joachim Folz,Andreas Dengel
### Background
现有核心集选择方法旨在识别数据集的代表子集以提高模型训练效率，但这些方法通常需要在进行剪枝前对整个数据集进行全面的昂贵的训练过程，来计算梯度、决策边界估计值或遗忘计数等信号，这与它们本应避免的训练过程相矛盾，破坏了其初衷。
### Innovation
提出了一种名为SubZeroCore的新颖核心集选择方法，这是一种无需训练的算法，通过结合子模态覆盖和密度的单一统一目标来实现。SubZeroCore引入了一种基于闭式解的采样策略，用于优化平衡这些目标，以及一个单一的超参数，该超参数显式控制所需的局部密度度量的覆盖度。尽管没有进行训练，但在广泛评估中，SubZeroCore能够匹配基于训练的基线，并在高剪枝率下显著超越它们，同时大幅度减少计算负担。此外，SubZeroCore还展示了对标签噪声的优越鲁棒性，这突显了其实用效果和在实际应用场景中的可扩展性。
### Conclusion
SubZeroCore在无需训练的情况下，在高剪枝率下匹配甚至超越基于训练的方法，同时显著降低计算成本，并且展示出对标签噪声的鲁棒性，表明该方法在实际应用中具有高效性和可扩展性。
## 138. `cs.AI` - 解锁美的本质：相对绝对策略优化的高级审美推理 [PDF](https://arxiv.org/pdf/2509.21871), [HTML](https://arxiv.org/abs/2509.21871)
### Authors
Boyang Liu,Yifan Hu,Senjie Jin,Shihan Dou,Gonglei Shi,Jie Shao,Tao Gui,Xuanjing Huang
### Background
多模态大型语言模型（MLLMs）非常适合图像审美评估，因为它们可以通过跨模态理解能力捕捉高级审美特征。然而，缺乏多模态审美推理数据以及审美判断的主观性使得MLLMs难以生成具有可解释推理的准确审美判断。现有的方法难以克服这些挑战。
### Innovation
提出了一个全面的审美推理框架Aes-R1，该框架结合了强化学习（RL）。Aes-R1通过一个名为AesCoT的管道来构建和筛选用于冷启动的高质量链式思考审美推理数据。引入了相对-绝对策略优化（RAPO），这是一种新颖的RL算法，它联合优化绝对分数回归和相对排名顺序，从而提高了单张图像的准确性以及跨图像的偏好判断。
### Conclusion
大量实验表明，Aes-R1 大幅提高了主干网络的平均PLCC/SRCC（47.9%/34.8%），超过了类似规模的最新基线。进一步的消融研究验证了Aes-R1在有限监督和未见过数据场景下的鲁棒泛化能力。
## 139. `cs.AI` - 伪粒子射线衍射超越结构：晶体性质预测中的不变性 [PDF](https://arxiv.org/pdf/2509.21778), [HTML](https://arxiv.org/abs/2509.21778)
### Authors
Bin Cao,Yang Liu,Longhan Zhang,Yifan Wu,Zhixun Li,Yuyu Luo,Hong Cheng,Yang Ren,Tong-Yi Zhang
### Background
基于量子力学原理的晶格性质预测对于大型多体系统的精确求解在传统密度泛函理论下是计算上无法实现的。虽然机器学习模型已成为大规模应用的有效近似，但其性能强烈依赖于原子表示形式的选择。尽管现代图基方法已逐步整合了更多的结构信息，但由于有限的感受野和局部编码方案，它们往往无法捕获长期的原子相互作用，从而导致不同的晶体被映射为相同的表示，影响了准确的性质预测。因此，本研究引入了PRDNet，该网络结合了独特的倒易空间衍射和图表示。为增强对元素和环境变化的敏感性，采用了数据驱动的伪粒子生成合成衍射图案，并确保完全的晶体学对称性不变性。
### Innovation
PRDNet 引入了结合了独特的倒易空间衍射和图表示的学习模型。为了提高对元素和环境变化的敏感性，提出了一种数据驱动的伪粒子生成合成衍射图案的方法，并确保了完全的晶体对称性不变性。这种新的预测模型通过物质项目、JARVIS-DFT 和 MatBench 数据集的广泛实验，展示了最先进的性能，弥补了传统方法在长程原子相互作用捕捉方面的不足。
### Conclusion
通过将倒易空间衍射与图表示结合，提出的新模型 PRDNet 在物质项目、JARVIS-DFT 和 MatBench 数据集上的实验结果表明，其性能达到最先进的水平，显著提高了对元素和环境变化的敏感性和晶体对称性不变性。
## 140. `cs.AI` - 你无法偷走任何东西：通过系统向量缓解LLM中的提示泄露 [PDF](https://arxiv.org/pdf/2509.21884), [HTML](https://arxiv.org/abs/2509.21884)
### Authors
Bochuan Cao,Changjiang Li,Yuanpu Cao,Yameng Ge,Ting Wang,Jinghui Chen
### Background
大型语言模型（LLMs）在各种应用中得到广泛应用，通过自定义系统提示来解决不同任务。面对系统提示泄露的风险，模型开发者通过禁止LLMs在遇到已知攻击模式时重复上下文来预防泄露，但这种做法仍然可能受到新型和未预见的提示泄露技术的攻击。
### Innovation
本研究首先提出了一种简单有效的方法来揭示提示泄露的风险。论文进一步提出了SysVec，这是一种新颖的方法，将系统提示编码为内部表示向量，而不是原始文本。此方法不仅降低了未经授权披露的风险，还保留了LLM的核心语言能力。此外，SysVec还能增强模型的指令遵循能力，实验结果表明SysVec能有效抑制提示泄露攻击，保持LLM的功能完整性，并帮助缓解长上下文场景中的遗忘问题。
### Conclusion
研究提出了SysVec方法，通过将系统提示编码为内部向量来解决提示泄露问题，不仅增强了安全性，还提高了模型的一般指令遵循能力，实验验证了SysVec在缓解提示泄露攻击方面的有效性，妥善保护了模型的功能同时提高了其在长上下文场景中的表现。
## 141. `cs.AI` - DiTraj：无需训练的视频扩散变换器轨迹控制 [PDF](https://arxiv.org/pdf/2509.21839), [HTML](https://arxiv.org/abs/2509.21839)
### Authors
Cheng Lei,Jiayu Zhang,Yue Ma,Xinyu Wang,Long Chen,Liang Tang,Yiqiang Yan,Fei Su,Zhicheng Zhao
### Background
现有的基于扩散变换器（DiT）的视频生成模型展示了强大的生成能力，但轨迹控制作为一种用户友好的控制任务，当前方法要么需要大量的训练资源，要么专门针对U-Net设计，未能充分利用DiT的优越性能。
### Innovation
提出了一种名为DiTraj的简单而有效的无需训练框架，用于针对DiT的文本到视频生成中的轨迹控制。具体创新包括：1. 前景-背景分离指导，利用大型语言模型将用户提供的提示转换为前景和背景提示，分别指导视频中前景和背景区域的生成；2. 通过分析3D全注意力机制，提出跨帧时空解耦3D-RoPE（STD-RoPE），仅修改前景标记的位置嵌入，消除跨帧空间差异，增强跨帧注意力，从而提升轨迹控制能力；3. 通过调节位置嵌入的密度实现3D感知的轨迹控制。
### Conclusion
大量实验表明，我们的方法在视频质量和轨迹控制性能上都优于之前的方法。
## 142. `cs.AI` - ChaosNexus：基于多尺度表示的普适混沌系统预测基础模型 [PDF](https://arxiv.org/pdf/2509.21802), [HTML](https://arxiv.org/abs/2509.21802)
### Authors
Chang Liu,Bohao Zhao,Jingtao Ding,Yong Li
### Background
在天气预报和流体动力学等领域的混沌系统中准确预测仍然是一项重大的科学挑战。这些系统的初始条件高度敏感，且观测数据稀缺，这严重限制了传统建模方法。由于这些模型通常只为特定系统训练，缺乏在新颖或数据有限场景中进行稳健的零样本或少量样本预测的能力。为克服这一泛化障碍，该论文提出了一种名为ChaosNexus的预训练基础模型，该模型在各种混沌动态数据集上进行训练。
### Innovation
ChaosNexus使用了一种新颖的多尺度架构——ScaleFormer，并加入了Mixture-of-Experts层，以捕捉通用模式和系统特定行为。该模型在合成和真实世界基准测试中都达到了最先进的零样本泛化性能。在包含超过9000个合成混沌系统的大型测试平台上，ChaosNexus将长期吸引子统计的准确性提高了超过40%。此外，实验证明ChaosNexus在5天全球天气预报中的零样本平均误差低于1度，在少量调整后误差进一步减小。
### Conclusion
ChaosNexus为跨系统泛化提供了一个指导原则：泛化能力的提升来源于训练系统的多样性，而不是数据量。这种模型设计和训练策略为混沌系统预测提供了通用的有效方法。
## 143. `cs.AI` - 增强低秩适应的结构非线性变换 [PDF](https://arxiv.org/pdf/2509.21870), [HTML](https://arxiv.org/abs/2509.21870)
### Authors
Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song
### Background
低秩适应（LoRA）是一种广泛采用的参数高效微调方法，适用于大型语言模型。然而，其线性特性限制了其表达能力。
### Innovation
提出了一种非线性扩展LoRA的方法，称为LoRAN，它通过对低秩更新应用轻量级变换。同时引入了一种基于正弦的激活函数Sinter，可以以不增加参数数量的方式添加结构化扰动。实验表明，LoRAN在总结和分类任务中均优于QLoRA。
### Conclusion
消融研究表明，Sinter显著优于标准激活函数（如Sigmoid、ReLU和Tanh），这突显了在低秩调整中激活函数设计的重要性。
## 144. `cs.AI` - 评估和改进面向LLM对齐的奖励模型的文化意识 [PDF](https://arxiv.org/pdf/2509.21798), [HTML](https://arxiv.org/abs/2509.21798)
### Authors
Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang
### Background
评估和改进面向大语言模型（LLMs）对齐的奖励模型（RMs）的文化意识非常重要，因为RMs对于将LLMs与多种文化对齐至关重要。然而，现有的RM评估方法由于缺乏包含文化相关内容的评估数据集而无法充分评估文化意识。这一缺口促使作者提出了一个名为CARB的基准测试，涵盖了4个文化领域中的10种不同文化，以系统地评估当前最先进的奖励模型在文化意识建模方面的能力。
### Innovation
作者提出了CARB基准测试，用于评估10种不同文化背景下的文化意识。此外，通过RLVR（通过验证奖励进行强化学习）结合Think-as-Locals策略，使得生成式奖励模型能够进行更深的文化共鸣推理。研究结果证明了这种方法在减少表面特征干扰和促进文化意识奖励模型改进方面的有效性。
### Conclusion
通过CARB基准测试评估了最先进的奖励模型，并发现它们在文化意识建模方面存在不足。作者提出了RLVR结合Think-as-Locals的方法，以更深入地体现文化理解和推理，实验结果表明了这种方法的有效性。
## 145. `cs.AI` - 职位：验证奖励强化学习的隐含成本及测量缺口 [PDF](https://arxiv.org/pdf/2509.21882), [HTML](https://arxiv.org/abs/2509.21882)
### Authors
Aaron Tu,Weihao Xuan,Heli Qi,Xu Huang,Qingcheng Zeng,Shayan Talaei,Yijia Xiao,Peng Xia,Xiangru Tang,Yuchen Zhuang,Bing Hu,Hanqun Cao,Wenqi Shi,Tianang Leng,Rui Yang,Yingjian Chen,Ziqi Wang,Irene Li,Nan Liu,Huaxiu Yao,Li Erran Li,Ge Liu,Amin Saberi,Naoto Yokoya,Jure Leskovec,Yejin Choi,Fang Wu
### Background
强化学习与可验证奖励（RLVR）是一种实用且可扩展的方法，用于增强在数学、代码和其他结构化任务领域的大型语言模型。本文探讨了RLVR技术的实际应用效果，特别是在如何评价其带来的收益时遇到了一些问题，如评估过程中存在的陷阱、数据污染以及RLVR带来的实际成本问题。作者认为，虽然RLVR确实带来了进步，但这些收益往往被高估了。
### Innovation
作者提出了一种新的训练和评估协议，名为税负意识训练与评估协议（Tax-Aware Training and Evaluation Protocol, TATEP），它可以优化准确性、结合性以及经过校准的回避，并标准化预算和溯源检查。通过对最近的RLVR设置进行应用，该协议提供了更可靠的理由增益估计，并在某些情况下修正了先前的结论。
### Conclusion
作者的立场是积极的：RLVR是有价值且工业化的预备技术；他们建议在保持其实用收益的同时，优先考虑可靠、安全和测量的问题。
## 146. `cs.AI` - Elastic MoE: 解锁Mixture-of-Experts推理时的可扩展性 [PDF](https://arxiv.org/pdf/2509.21892), [HTML](https://arxiv.org/abs/2509.21892)
### Authors
Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang
### Background
Mixture-of-Experts（MoE）模型通常在训练和推理时固定激活专家的数量k。直觉上，在推理时激活更多的专家k'（其中k' > k）意味着使用更多的模型参数进行计算，因此期望性能会提高。然而，我们发现性能的可扩展范围非常狭窄，随着专家数量的轻微增加，性能开始迅速下降。进一步的研究表明，这种下降源于专家之间缺乏学习到的合作。
### Innovation
我们引入了弹性Mixture-of-Experts（EMoE），这是一种新颖的训练框架，能够在推理时动态调整激活的专家数量，而不需要额外的训练开销。通过同时训练专家以在不同的组合中合作，并鼓励路由器进行高质量的选择，EMoE确保了在不同的计算预算下性能的鲁棒性。
### Conclusion
我们在多种MoE设置下进行了广泛的实验。结果显示，EMoE显著扩大了有效的性能扩展范围，将其扩展到训练时k的2到3倍，同时提高了模型的峰值性能。
## 147. `cs.AI` - 留无一例被忽视：通过熵导向优势塑造利用零方差提示在LLM强化学习中的潜力 [PDF](https://arxiv.org/pdf/2509.21880), [HTML](https://arxiv.org/abs/2509.21880)
### Authors
Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang
### Background
当前的强化学习方法，如GRPO，依赖于模型对同一输入响应的不同正确性，但忽略了所有响应获得相同奖励的提示，即零方差提示。这些方法认为零方差提示是无用的。然而，研究表明这些提示可以提供有价值的反馈，为了进一步开发这种潜力，本文提出了一个新的方法RL-ZVP，能够从零方差提示中提取有用的信号，而无需对比不同的响应，通过基于token的特征调节反馈，保留重要而细微的信号。在六个数学推理基准测试中，该方法在准确性上取得了高达8.61的显著提升，在通过率上取得7.77的显著提升。并且在与其他过滤掉零方差提示的基线方法的比较中表现优异，证明了零方差提示在RLVR中的未充分利用的潜力。
### Innovation
本文提出了RL-ZVP算法，这是一种针对零方差提示的新方法，能够在无需对比响应的情况下直接奖励正确性和惩罚错误，进而通过调整基于token的反馈信号以保留更多有意义的信息和细微差别。这种方法在多个数学推理基准测试中的表现明显优于GRPO和其他基线方法。
### Conclusion
零方差提示在强化学习中远未失去其价值，并且在合理的利用和设计下，能够为模型的策略优化提供更有意义的反馈信号。通过RL-ZVP的研究，揭示了这一未被充分开发的潜力，对于改进大型语言模型的推理能力具有重要意义。
## 148. `cs.AI` - AutoSCORE：通过结构化组件识别增强多代理大规模语言模型的自动化评分 [PDF](https://arxiv.org/pdf/2509.21910), [HTML](https://arxiv.org/abs/2509.21910)
### Authors
Yun Wang,Zhaojun Ding,Xuansheng Wu,Siyue Sun,Ninghao Liu,Xiaoming Zhai
### Background
自动化评分在教育中扮演着关键角色，能够减少对人工评分者的依赖，提供可扩展和即时的学生作品评估。虽然大型语言模型（LLMs）在这一任务中显示出巨大的潜力，但它们作为端到端评分者的使用面临诸多挑战，如低准确性、提示敏感性、解释性有限以及评分标准偏差。这些问题阻碍了基于LLM的自动化评分在评估实践中的应用。
### Innovation
提出了AutoSCORE，一种多代理LLM框架，通过评分标准对齐的结构化组件识别来增强自动化评分。AutoSCORE包括两个代理：首先，评分标准组件提取代理从学生回答中抽取出与评分标准相关的内容，并将其编码为结构化表示；然后，评分代理使用这些信息分配最终分数。这种设计确保了模型的推理遵循类似人工评分的过程，增强了可解释性和鲁棒性。
### Conclusion
AutoSCORE在四个基准数据集上进行评估，使用了两种 proprietary 和开源 LLM（GPT-4o，LLaMA-3.1-8B，和 LLaMA-3.1-70B）。在不同任务和评分标准上，相对于单代理基线，AutoSCORE能够一致地提高评分准确性、人机一致性（QWK、相关性）和错误度量（MAE、RMSE），特别是在复杂的多维度评分标准上，特别是在较小的LLM上有较大的相对改进。这些结果表明，结构化组件识别结合多代理设计为自动化评分提供了一个可扩展、可靠且可解释的解决方案。
## 149. `cs.AI` - Graph of Agents：通过新兴的多智能体协作原理化长上下文建模 [PDF](https://arxiv.org/pdf/2509.21848), [HTML](https://arxiv.org/abs/2509.21848)
### Authors
Taejong Joo,Shu Ishida,Ivan Sosnovik,Bryan Lim,Sahand Rezaei-Shoshtari,Adam Gaier,Robert Giaquinto
### Background
多智能体系统作为模型无关的方法，可以处理超过大型语言模型上下文窗口的输入，而无需重新训练或架构修改。然而，其性能往往高度依赖于手工构建的多智能体协作策略和提示工程，这限制了普适性。因此，需要一个原则化的框架来解决模型无关的长上下文建模问题，以此提高此类系统的性能和灵活性，尤其是对于大的数据集和长文档的应用场景。本次研究通过正式化这一问题为压缩问题，提出了一个信息论的压缩目标，并据此提出了一种可动态构建输入相关协作结构的新方法。这种方法不仅改进了现有的长文档问答基准的中值F1分数，而且在不同的模型和基准上展现了显著的效果增强，甚至在极小的上下文窗口情况下也展示了超出大上下文窗口模型的性能。研究通过具体的实验验证了其有效性和适应性，并提出了源代码的开放共享。
### Innovation
1. 将模型无关的长上下文建模问题形式化为压缩问题，提出了一个信息论的压缩目标。2. 提出了图多智能体（Graph of Agents，GoA）方法，它可以动态构建输入相关的协作结构，以最大化上述信息论目标。3. 在Llama 3.1 8B和Qwen3 8B模型上，使用GoA方法在多个文档问答基准上平均提升了中值F1分数，并显著超过使用固定协作结构的强化多智能体基准。表明即使在很小的上下文窗口情况下，也展示出显著更好的性能，如在LongBench上超越128K上下文窗口模型的Llama 3.1 8B性能。
### Conclusion
通过正式化模型无关的长上下文问题，并以信息论的压缩目标作为基础，提出了动态构建输入依赖的协作结构的图多智能体（GoA）方法，在多个文档问答基准上验证了显著的性能增强，并展示出在很小上下文窗口情况下也具有出色的性能，为长上下文建模问题提供了一个创新性的解决方案。
## 150. `cs.AI` - 使用大规模数据集和LLMs在土耳其语中进行引文意图分类 [PDF](https://arxiv.org/pdf/2509.21907), [HTML](https://arxiv.org/abs/2509.21907)
### Authors
Kemal Sami Karaca,Bahaeddin Eravcı
### Background
理解引文的质量意图对于全面评估学术研究至关重要，但对于像土耳其语这样的粘着语系来说，这是一个独特挑战。这一任务需要新的方法和数据集来提供支持和理解。现有的方法，如基于大型语言模型的上下文学习，在准确性上存在局限性，尤其是当使用手动设计的提示时，会导致结果不一致。因此，迫切需要一种系统的方法和数据集来解决这些问题。
### Innovation
本文介绍了一种系统方法和基础数据集以解决这些问题。首先创建了一个新的公开可用的土耳其语引文意图数据集，并开发了一个专门的注释工具。其次，引入了一个基于DSPy框架的可编程分类管道，该管道系统地自动优化提示，从而改进了引文意图的分类准确性。最后，使用堆叠泛化集合并XGBoost元模型进行了最终分类，实现了91.3%的最新精确度。
### Conclusion
本文提供了一个基础的数据集和一个稳健的分类框架，为未来在土耳其语中的引文研究铺平道路。这对于土耳其NLP社区和更广泛的学术圈具有重要意义。
## 151. `cs.AI` - 超越约翰逊-莱斯纳斯：舍入二次形式的统一界 [PDF](https://arxiv.org/pdf/2509.21847), [HTML](https://arxiv.org/abs/2509.21847)
### Authors
Rohan Deb,Qiaobo Li,Mayank Shrivastava,Arindam Banerjee
### Background
舍入内积的均匀界支撑着机器学习和近似算法中的多个重要计算和统计结果，包括约翰逊-莱斯纳斯引理（J-L引理）、受限正交性质（RIP）、随机舍入和近似线性代数。然而，许多现代分析涉及舍入双曲形式，现有的均匀界要么不适用，要么在一般集合上不够精确。这项工作旨在开发一个通用框架来分析这些舍入双曲形式，以几何复杂性作为相关集合的术语来获得均匀界。该方法依赖于通用链条，并引入了处理两个集合上线性表达式的高级技术。此外，分析扩展到了涉及T个独立舍入矩阵之和的情况，证明偏差量级为√T。这种统一分析不仅恢复了已知的J-L引理结果，还扩展了RIP类型的保证。
### Innovation
提出了一种通用框架来分析舍入双曲形式，并通过几何复杂性获得了均匀界。该方法依赖于通用链条，并引入了处理两个集合上线性表达式的高级技术。分析扩展到了涉及T个独立舍入矩阵之和的情况，并证明了偏差量级为√T。这种方法统一了已知的J-L引理结果，扩展了RIP类型的保证。此外，还为阶乘学习算法提供了改进的收敛性界，并设计了依赖于行为和参数集几何复杂性的带尖算法版本，而不是依赖于环境维度的遗憾界。
### Conclusion
本研究不仅恢复了已知的如J-L引理的结果，还为RIP类型保证提供了更广泛的结论。此外，该研究为舍入投影 Federated Learning 算法提供了更好的收敛性界，并设计了具有更紧遗憾边界的舍入版本的带尖算法，该边界的紧度取决于行为和参数集的几何复杂性而非空间维度。
## 152. `cs.AI` - 通过反事实校准在泰国政治立场检测中消除大型语言模型的偏见 [PDF](https://arxiv.org/pdf/2509.21946), [HTML](https://arxiv.org/abs/2509.21946)
### Authors
Kasidit Sermsri,Teerapong Panboonyuen
### Background
在低资源且文化复杂的情境下，大规模语言模型（LLMs）检测政治立场是一项关键挑战。泰国的政治环境包括间接语言、极化人物、情感与立场交织等因素，这些因素导致LLMs表现出系统性偏见，如情感泄露和对特定实体的偏爱。这些偏见影响了公平性和可靠性。
### Innovation
我们提出了一个轻量级、模型无关的校准框架ThaiFACTUAL，该框架在无需微调的情况下减轻政治偏见。ThaiFACTUAL通过反事实数据增强和基于理据的监督来分离情感与立场，减少偏见。我们还发布了首个高质量的泰语政治立场数据集，其中包含立场、情感、理据和偏见标记，涵盖多种实体和事件。实验结果显示，ThaiFACTUAL减少了无用相关性，增强了零样本泛化能力，并提高了多个LLMs的公平性。
### Conclusion
这项研究突出了针对少语种的具有文化背景的去偏技术的重要性。
## 153. `cs.AI` - EqDiff-CT：从CBCT合成立方体CT的等变条件扩散模型 [PDF](https://arxiv.org/pdf/2509.21913), [HTML](https://arxiv.org/abs/2509.21913)
### Authors
Alzahra Altalib,Chunhui Li,Alessandro Perelli
### Background
锥形束CT（CBCT）广泛应用于放射治疗的图像引导（IGRT），能提供实时可视化并成本和辐射剂量较低。但是，光电散射和射束阻挡会导致CBCT图像产生伪影，影响剂量计算和自适应计划的准确性。尽管CT能提供高质量成像并准确校准HU值，但通常是离线获取，无法捕捉治疗过程中的解剖变化。因此，在自适应放疗工作流程中，需要高质量的CBCT到CT的合成以弥补图像质量的差距。
### Innovation
作者提出了一个新颖的基于扩散的条件生成模型EqDiff-CT，用于从CBCT合成高质量的CT图像。EqDiff-CT利用去噪扩散概率模型（DDPM）迭代加入噪声并学习潜在表示，以实现解剖一致的CT图像重构。该模型使用e2cnn可定向层实现等变条件U-Net骨架，确保循环C4对称性，有助于保持细微结构细节并尽量减少噪声和伪影。与最先进的方法CycleGAN和DDPM相比，EqDiff-CT在结构保真度、HU精度和定量指标方面提供了显著的改进，进一步的视觉发现证实了解剖结构的恢复、更清晰的软组织边界以及更真实的骨重建，表明扩散模型为CBCT改进提供了一个稳健且通用的框架。
### Conclusion
研究结果表明，EqDiff-CT模型能够在保持解剖细节和减少伪影的同时，显著提升CBCT图像的结构保真度和HO值精度，改善CBCT引导的治疗计划和剂量计算的临床信心。
## 154. `cs.AI` - 有限训练集下随机插值的生成特性 [PDF](https://arxiv.org/pdf/2509.21925), [HTML](https://arxiv.org/abs/2509.21925)
### Authors
Yunchen Li,Shaohui Lin,Zhou Yu
### Background
本文探讨了在有限训练样本数量的情况下，生成模型的理论行为。在随机插值生成框架内，当仅有有限数量的训练样本可用时，推导了最优速度场和得分函数的闭式表达式。研究表明，在某些正则性条件下，确定性的生成过程精确地恢复了训练样本，而随机生成过程表现为带有高斯噪声的训练样本。
### Innovation
本文在有限训练集的情况下对生成模型进行了理论分析，推导了最优速度场和得分函数的闭式表达式。同时，引入了生成模型中特定的过拟合和欠拟合的定义，并揭示了在存在估计误差的情况下，随机生成过程能产生混有均匀噪声和高斯噪声的训练样本的凸组合。通过对生成任务和分类下游任务的支持实验验证了理论结果。
### Conclusion
本文证明了，在面对估计误差的情况下，随机生成过程能够有效生成带有混合均匀噪声和高斯噪声的训练样本的凸组合。实验表明，该理论在生成任务和分类任务中得到了验证。
## 155. `cs.AI` - Geo-R1: 使用强化微调提高Few-Shot地理空间引用表达理解 [PDF](https://arxiv.org/pdf/2509.21976), [HTML](https://arxiv.org/abs/2509.21976)
### Authors
Zilun Zhang,Zian Guan,Tiancheng Zhao,Haozhan Shen,Tianyu Li,Yuxiang Cai,Zhonggen Su,Zhaojun Liu,Jianwei Yin,Xiang Li
### Background
遥感领域的引用表达理解面临独特的挑战，因为这需要对复杂对象-上下文关系进行推理。尽管多模态大型语言模型在大规模标注数据集上通过监督微调(SFT)取得了很好的性能，但在数据稀缺的情况下表现不佳，导致泛化能力较差。
### Innovation
我们提出了Geo-R1，这是一种以推理为中心的强化微调(RFT)范式，用于少样本地理空间引用。Geo-R1促使模型首先生成明确、可解释的推理链条来分解引用表达，然后利用这些理据进行目标对象定位。这一“先推理，后行动”的过程使得模型能够更有效地利用有限的注释，增强泛化能力和提供可解释性。
### Conclusion
我们在三个精心设计的少样本地理空间引用基准测试上验证了Geo-R1，结果显示我们的模型在所有基准测试上都显著优于FS-SFT基线。此外，它还展示了强大的跨数据集泛化能力，突显了其鲁棒性。
## 156. `cs.AI` - 为什么链式思维在临床文本理解中失败 [PDF](https://arxiv.org/pdf/2509.21933), [HTML](https://arxiv.org/abs/2509.21933)
### Authors
Jiageng Wu,Kevin Xie,Bowen Gu,Nils Krüger,Kueiyu Joshua Lin,Jie Yang
### Background
随着大型语言模型（LLMs）在医疗护理领域中的应用增加，准确性和透明的推理对于安全和可信赖的部署至关重要。链式思维（CoT）提示能激发逐步推理，在多个任务中展示了性能和可解释性的改善。然而，在医疗领域，尤其是在电子健康记录（EHRs）中，这些模型的有效性尚未得到广泛研究。EHRs通常很长、不连贯且杂乱，这使得链式思维在实际应用中存在挑战。
### Innovation
本文首次进行大规模系统研究，评估95个高级LLMs在87项真实临床文本任务上的表现，涉及9种语言和8种任务类型。研究发现，86.3%的模型在链式思维环境下表现下降，能力强的模型表现相对稳定，较弱的模型则大幅下降。通过详细的推理长度分析、医学概念匹配和错误剖析，研究揭示了链式思维在临床文本理解中失败的原因，包括其提高了可解释性但可能损害了可靠性。
### Conclusion
本研究为企业级语言模型在临床推理策略提供了实证基础，强调了透明和可信方法的重要性。
## 157. `cs.AI` - SemanticControl：一种无训练方法，用于处理ControlNet中松散对齐的视觉条件 [PDF](https://arxiv.org/pdf/2509.21938), [HTML](https://arxiv.org/abs/2509.21938)
### Authors
Woosung Joung,Daewon Chae,Jinkyu Kim
### Background
ControlNet通过引入额外的视觉条件（如深度图或边缘图）在文本到图像的扩散模型中实现了详细的空间控制。然而，其有效性高度依赖于与文本提示生成目标精准对齐的视觉条件，而在实践中常常难以满足，尤其是在不常见或富有想象力的场景下。现有的方法在利用松散对齐但语义相关的视觉条件时表现不佳，导致文本忠实度低或视觉伪影。现有模型难以处理这些松散对齐的视觉条件，进一步限制了其应用范围。
### Innovation
提出了一个无训练的SemanticControl方法，以有效利用松散对齐但语义相关的视觉条件。该方法通过在实际目标提示的去噪过程中利用与视觉条件对齐的辅助提示提取有信息的注意力掩码，从而适应性地抑制与提示冲突的视觉条件影响，并加强文本的引导。实验结果表明，在深度图、边缘图和人体骨架等多种条件下，该方法在松散对齐的情况下提升了性能，优于现有基线方法。
### Conclusion
该研究提出了一种名为SemanticControl的无训练方法，能够有效利用松散对齐但语义相关的视觉条件，通过辅助去噪过程提取有信息的注意力掩码，以提升文本到图像生成在多条件下的表现。该方法在多种视觉条件（如深度图、边缘图、人体骨架）下均优于现有基线模型。相关代码已公开。
## 158. `cs.AI` - FlowDrive: 改良流匹配与数据平衡的轨迹规划 [PDF](https://arxiv.org/pdf/2509.21961), [HTML](https://arxiv.org/abs/2509.21961)
### Authors
Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller
### Background
学习型规划器对驾驶数据的长尾分布敏感。常用的驾驶行为在数据集中占主导地位，而危险或罕见的场景却很少见。这种不平衡可能会使模型偏向频繁出现的例子，从而在关键场景上的性能下降。因此，需要通过平衡策略来采样训练数据，发现重新加权按照轨迹模式是一种有效的方法。
### Innovation
提出了一种新的轨迹规划方法——FlowDrive，该方法通过学习有条件条件矫正流来直接将噪声映射到轨迹分布，并通过仅需少量的流匹配步骤。此外还引入了改良的，循环中的指导，它在流步骤之间注入小型扰动，以系统地增加轨迹多样性，同时保持场景一致性。
### Conclusion
在nuPlan和交互专注于interPlan基准测试中，FlowDrive实现了学习型规划者中最新的结果，接近使用规则优化的方法。在增加改良指导和轻量级后期处理（FlowDrive*）后，它在几乎所有基准分割上都达到了整体最佳性能。
## 159. `cs.AI` - Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective [PDF](https://arxiv.org/pdf/2509.21945), [HTML](https://arxiv.org/abs/2509.21945)
### Authors
Pengzhou Chen,Hongyuan Liang,Tao Chen
### Background
许多调优器已经利用代理模型来加速配置调优过程，而不再仅依赖于代价昂贵的系统测量。尽管准确的代理模型被认为是理想的，但过去的发现表明，这种准确性并非总是有效地提升配置调优的效率。因此，该研究旨在系统地探讨代理模型在配置调优中的多种角色以及提出一个新的评估框架。
### Innovation
提出了一种基于适应度景观分析的方法论，作为模型有用性评估的替代方法论，而不是仅依赖于准确性。通过这种方法，进行了一项涉及多达27,000个案例的广泛实验研究。此外，提出了一种自动化预测工具Model4Tune，该工具能够估计某种模型-调优器组合在未知系统上的最佳性能，无需进行昂贵的调优器特性分析。实验证明，Model4Tune在大部分情况下表现优于随机猜测，提供了有效配置调优模型的实用选择。
### Conclusion
实验结果不仅指明了未来研究的方向，同时也提供了一种实用的方法来帮助实践者评估最适合配置调优的模型。
## 160. `cs.AI` - 混合扩散模型用于同时进行符号和连续规划 [PDF](https://arxiv.org/pdf/2509.21983), [HTML](https://arxiv.org/abs/2509.21983)
### Authors
Sigmund Hennum Høeg,Aksel Vaaler,Chaoqi Liu,Olav Egeland,Yilun Du
### Background
在人工智能领域，构建机器人以完成长期任务是一个长期存在的挑战。生成方法，尤其是扩散模型，因其能够规划和控制连续的机器人轨迹而受到关注。
### Innovation
本文提出了混合扩散模型，同时生成高层次的符号计划和连续轨迹。这种方法结合了离散变量扩散和连续扩散的新颖混合机制，显著优于基线方法。此外，该混合扩散过程还允许灵活合成轨迹，使生成的动作能够根据部分或完整的符号条件进行调整。
### Conclusion
研究通过混合扩散过程显示了在长期任务中同时规划和控制的高效性，提升了在复杂决策任务中的表现。
## 161. `cs.AI` - 从表面输出到表面学习：大型语言模型在教育中的风险 [PDF](https://arxiv.org/pdf/2509.21972), [HTML](https://arxiv.org/abs/2509.21972)
### Authors
Iris Delikoura,Yi.R(May)Fung,Pan Hui
### Background
大型语言模型（LLMs）正在通过个性化、反馈和知识访问等方式改变教育，但伴随着对学生和学习系统带来的风险。目前，关于这些风险的实证证据仍然相对分散和不全面。这项研究通过全面系统地回顾70篇跨学科的实证研究，探索LLMs在教育中的应用、其影响的测量、伴随的风险以及提出的缓解策略，以寻求更深入了解和解决这些潜在风险的方法。
### Innovation
该研究首次提供了一个综合性的实验评估风险的系统回顾，为LLM在教育中的负责任的人本整合奠定了基础。通过提出LLM风险适应学习模式，揭示了技术风险如何通过交互和解释影响教育结果，从而填补了在LLM在教育中的应用研究上的空白。
### Conclusion
这项综述强调了LLM在教育中带来的技术风险如何通过互动和解释过程逐步影响教育结果。它为构建以人为中心且负责任地融合LLM到教育中提供了基础，同时也指出了未来在LLM风险缓解策略方面的改进方向。
## 162. `cs.AI` - 轻量级结构化多模态推理在临床场景理解中的应用 [PDF](https://arxiv.org/pdf/2509.22014), [HTML](https://arxiv.org/abs/2509.22014)
### Authors
Saurav Jha,Stefan K. Ehrlich
### Background
医疗机器人需要强大的跨模态感知与推理能力来确保在动态临床环境中的安全性。当前的视觉-语言模型（VLM）虽然具有强大的通用能力，但在时间推理、不确定性估计和针对机器人规划所需的结构化输出方面仍存在局限性。
### Innovation
提出了一个轻量级的代理型多模态框架，结合Qwen2.5-VL-3B-Instruct模型和基于SmolAgent的调度层，支持链式思维推理、语音-视觉融合以及动态工具调用。框架生成结构化的场景图，并通过混合检索模块实现可解释且适应性推理。
### Conclusion
在Video-MME基准和自定义的临床数据集上的评估显示，该框架与最先进的VLM相比具有竞争力的准确性和更好的鲁棒性，表明其在辅助手术机器人、患者监控和决策支持方面的应用潜力。
## 163. `cs.AI` - 自动攻击：通过自适应环境对齐大语言模型 [PDF](https://arxiv.org/pdf/2509.21947), [HTML](https://arxiv.org/abs/2509.21947)
### Authors
Taeyoung Yun,Pierre-Luc St-Charles,Jinkyoo Park,Yoshua Bengio,Minsu Kim
### Background
本文针对生成用于大型语言模型（LLM）的安全微调的多样化攻击提示这一挑战进行研究。这些攻击提示能够触发有害行为（如侮辱、色情内容），并在安全微调过程中加以利用。传统的手动提示工程方法繁琐且效率低下，因此本文提出使用强化学习（RL）来训练攻击模型，通过毒性分类器作为奖励来自动生成这些提示。然而，捕捉多样性的有害行为是一个严峻的挑战，现有的多样性强化学习方法经常集中在有限的模式上，一旦找到高奖励的提示，便不再探索新的区域。为此，本文借鉴主动学习中的自适应探索方法，并引入了名为‘自动攻击’的新RL红队算法。该算法能够让攻击模型随着受害模型的发展而调整其攻击策略，通过定期使用收集到的攻击提示来安全微调受害模型，奖励在利用区域会逐渐递减，从而迫使攻击模型寻求未探索的漏洞。这一系列过程自然地促使了从易到难的探索课程，促使攻击模型逐步超越简单的模式，直至更难的模式。
### Innovation
本文提出了一种名为‘自动攻击’的新RL红队算法，该算法基于自适应的环境调整攻击策略，通过定期对受害模型进行安全微调，促使攻击模型探索未利用的漏洞。这有效克服了现有方法在处理多样性的有害行为时遇到的局限性。该算法作为一种简单且易集成的模块，能够显著提升跨攻击的成功率，并且即使计算量只增加了6%，其性能也超过了包括GFlowNets、PPO和REINFORCE在内的先前强化学习方法，提高了3128%的跨攻击成功率（相对增益超过400倍）。
### Conclusion
自动攻击算法通过自适应环境的探索，能够逐步揭示多种攻击模式，并且在其组合下实现了对多种模式分布的广泛覆盖。该方法不仅有效改进了攻击成功率，还为安全性研究提供了一个简单且高效的工具。相关代码已经开源，并可以访问所提供的链接了解更多详细信息。
## 164. `cs.AI` - 基于定制化EfficientNet-B0的无参考图像对比度评估 [PDF](https://arxiv.org/pdf/2509.21967), [HTML](https://arxiv.org/abs/2509.21967)
### Authors
Javad Hassannataj Joloudari,Bita Mesbahzadeh,Omid Zare,Emrah Arslan,Roohallah Alizadehsani,Hossein Moosaei
### Background
视觉感知中，图像对比度是基本因素，对整体图像质量至关重要。然而，大多数无参考图像质量评估（NR IQA）模型在多种现实世界条件下对对比度失真难以准确评估。本文研究在此背景下进行，旨在通过定制和微调三种预训练架构（EfficientNet B0、ResNet18、MobileNetV2），结合Siamese网络模型，来构建一个基于深度学习的盲对比度质量评估框架，旨在更准确地捕捉对比度失真。
### Innovation
提出了一个基于深度学习的盲对比度质量评估框架，通过定制和微调EfficientNet B0、ResNet18、MobileNetV2三种预训练模型，并加入基于Siamese网络的模型，特别引入了感知对比度意识回归头部来提高模型的对比度失真的捕捉能力。该方法在两个基准数据集（CID2013和CCID2014）中表现优异，特别是在评估对比度失真方面具有显著优势。
### Conclusion
研究结果表明，定制化的EfficientNet B0模型在CCID2014数据集上的PLCC为0.9286，SRCC为0.9178，在CID2013数据集上的PLCC为0.9581，SRCC为0.9369，超越了传统方法和其他深度学习基线模型，证明了对比度感知适应的轻量级预训练网络可以提供适用于实时和资源受限应用的高性能、可扩展的无参考对比度质量评估解决方案。
## 165. `cs.AI` - 医学视觉语言模型的心理迎合现象基准测试与缓解 [PDF](https://arxiv.org/pdf/2509.21979), [HTML](https://arxiv.org/abs/2509.21979)
### Authors
Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu
### Background
视觉语言模型(VLMs)在临床工作中越来越集成使用，但其在反映用户语气、权威感知上与基于证据的推理对齐不佳，表现出迎合行为。本文通过一个新颖的临床基准测试评估医学中的迎合现象，并提出了一个基于PathVQA、SLAKE和VQA-RAD构建的医学迎合数据集，包括不同的器官系统和成像方式。使用心理压力模板进行对抗试验，发现这些模型通常表现出脆弱性，对抗响应的发生存在显著差异，且与模型准确率或大小无明显相关性。模仿和专家提供的纠正被认为是触发最有效的因素，表明模型存在独立于视觉证据的偏见机制。
### Innovation
文章提出了一个名为Visual Information Purification for Evidence based Response (VIPER)的轻量级缓解策略，通过过滤非证据内容（如社会压力）并生成受限的证据最优答案，以减少迎合现象，同时保持解释性。此外，该研究还建立了一项基准测试以及缓解框架，为医学VLMs的实际临床应用打下了坚实的基础，强调了证据锚定防御的重要性。
### Conclusion
该研究框架能够有效减少医学VLMs中的心理迎合现象，改善模型的解释性与准确性，为未来实际临床环境中的稳健部署提供了坚实的基础，同时也指出了未来需要重点考虑的证据锚定防御措施。
## 166. `cs.AI` - 基于不确定性表达下的一致性进行黑盒幻觉检测 [PDF](https://arxiv.org/pdf/2509.21999), [HTML](https://arxiv.org/abs/2509.21999)
### Authors
Seongho Joo,Kyungmin Min,Jahyun Koo,Kyomin Jung
### Background
尽管语言模型近年来取得了巨大的进步，但像GPT3这样的大型语言模型（LLMs）因其生成非事实性响应而闻名，这些问题被称为“幻觉”问题。目前存在的解决幻觉问题的方法需要外部资源或LLMs的内部状态，如每个标记的输出概率。但由于LLMs的外部API限制和外部资源的有限性，迫切需要建立黑盒方法作为有效幻觉检测的基础。研究表明，当LLMs表达事实性响应时，它们会产生一致的回答；相反，当回答不一致时，它们可能会陷入幻觉状态。
### Innovation
本文提出了一种简单的黑盒幻觉检测度量，该度量基于对LLMs在表达不确定性时行为的调查。该度量利用表达不确定性来检测模型响应的事实性，证明其在预测模型响应的事实性方面优于那些依赖LLMs内部知识的方法。
### Conclusion
本文提出了一种基于不确定表达选择的一致性进行黑盒幻觉检测的简单度量。实验结果表明，该度量能够更有效地预测模型响应的真实性，无需依赖外部资源或LLMs的内部状态。
## 167. `cs.AI` - SAGE: 基于场景图感知的长期操作任务指导与执行 [PDF](https://arxiv.org/pdf/2509.21928), [HTML](https://arxiv.org/abs/2509.21928)
### Authors
Jialiang Li,Wenzheng Wu,Gaojing Zhang,Yifan Han,Wenzhao Lian
### Background
长期操作任务的顺利解决仍然是一个基础挑战，这些任务涉及长序列的动作以及复杂的对象交互，造成了高层次符号性规划和平滑低层次持续控制之间的重要差距。现有的任务规划方法，包括传统的和基于LLM的方法，往往表现出有限的泛化能力或稀疏的语义推理能力。同时，基于图像的目标控制方法难以适应未见过的任务。
### Innovation
我们提出了一种名为SAGE的新颖框架，用于场景图感知的长期操作任务指导与执行。SAGE利用语义场景图作为场景状态的结构化表示，这有助于高层次任务语义推理与像素级的视觉-运动控制之间的桥梁构建。框架包含两个关键组件：基于场景图的任务规划器和解耦的结构图像编辑管道。
### Conclusion
大量实验结果表明，SAGE在不同长期操作任务上达到了最先进的性能。
## 168. `cs.AI` - 潜扩散：多维稳定扩散潜空间探索者 [PDF](https://arxiv.org/pdf/2509.22038), [HTML](https://arxiv.org/abs/2509.22038)
### Authors
Zhihua Zhong,Xuanyang Huang
### Background
生成AI中的潜在空间是一个关键概念，它通过向量操作提供了强大的创意探索手段。然而，像Stable Diffusion这样的扩散模型缺乏与GANs相似的直观潜在向量控制，限制了它们在艺术表达中的灵活性。
### Innovation
本文介绍了textit{workname}框架，该框架可将可定制的潜在空间操作集成到扩散过程中。通过直接操作概念和空间表示，该方法扩展了生成艺术中的创意可能性。通过展示《Infinitepedia》和《Latent Motion》两个艺术作品，我们证明了该框架在概念融合和动态运动生成中的应用潜力。我们的研究揭示了潜在空间结构中的语义和无意义区域，为扩散模型几何结构提供了见解，并为潜在空间的进一步探索铺平了道路。
### Conclusion
我们的发现揭示了潜在空间结构中的语义和无意义区域，为扩散模型几何结构提供了见解，并为潜在空间的进一步探索铺平了道路。
## 169. `cs.AI` - 基于第一人称视频开发视觉-语言-动作模型 [PDF](https://arxiv.org/pdf/2509.21986), [HTML](https://arxiv.org/abs/2509.21986)
### Authors
Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori
### Background
第一人称视频能够捕捉人类如何操作物体和工具，提供丰富的动作线索，用于学习物体操作。现有训练视觉-语言-动作（VLA）模型的方法主要依赖于成本高昂的专家驱动的远程操作，而第一人称视频提供了一种可扩展的替代方案。然而，前人的研究大多依赖于辅助注释，如详细的手部姿态记录，来训练机器人策略。因此，关键问题在于VLA能否直接从原始的第一人称视频中学习。
### Innovation
本文通过利用EgoScaler框架，该框架能够从第一人称视频中提取6自由度（6DoF）物体操作轨迹，无需依赖辅助记录，解决了这一挑战。EgoScaler被应用到四个大规模的一人称视频数据集中，自动精炼嘈杂或不完整的轨迹，从而构建了一个大规模的数据集，用于VLA的预训练。实验结果表明，使用最新π_0架构进行模拟和真实机器人环境中的训练得出三个重要发现：（i）预训练模型的任务成功率比从头开始训练的模型提高了20%以上，（ii）性能与使用真实机器人数据集的性能相当，（iii）将数据集与真实机器人数据结合使用进一步提升了性能。这些结果证明，第一人称视频是推进VLA研究的一种有潜力且可扩展的资源。
### Conclusion
研究表明，第一人称视频作为直接用于VLA模型训练的数据源，具有潜在优势，能够提高任务成功率，特别是当与真实机器人数据结合使用时，性能进一步提升。
## 170. `cs.AI` - Fuzzy Reasoning Chain (FRC): 从模糊到清晰的创新推理框架 [PDF](https://arxiv.org/pdf/2509.22054), [HTML](https://arxiv.org/abs/2509.22054)
### Authors
Ping Chen,Xiang Liu,Zhaoxiang Liu,Zezhou Chen,Xingpeng Zhang,Huan Hu,Zipeng Wang,Kai Wang,Shuming Shi,Shiguo Lian
### Background
随着大规模语言模型（LLMs）的快速进步，自然语言处理（NLP）取得了显著进展。然而，在处理具有歧义、多义或不确定性文本时，仍然存在重大挑战。
### Innovation
我们引入了Fuzzy Reasoning Chain (FRC)框架，该框架将LLM语义先验与连续模糊成员度结合起来，实现了基于概率的推理和模糊成员度推理之间的显式交互。这一转变允许模糊输入逐步转化为清晰且可解释的决策，同时捕获传统基于概率的方法无法处理的冲突或不确定性信号。在情感分析任务中验证了FRC，理论分析和实证结果均表明，其保证了推理的一致性，并促进不同模型规模之间的知识迁移。这些发现表明，FRC为处理微妙且模糊的表达提供了改进的解释性和鲁棒性的一般机制。
### Conclusion
FRC提供了一种管理模糊和微妙表达的通用机制，增强了解释性和鲁棒性。
## 171. `cs.AI` - 基于可靠初始姿态的自适应ICP LiDAR odometry [PDF](https://arxiv.org/pdf/2509.22058), [HTML](https://arxiv.org/abs/2509.22058)
### Authors
Qifeng Wang,Weigang Li,Lei Nie,Xin Xu,Wenping Liu,Zhe Xu
### Background
LiDAR odometry作为一种关键的自主导航和定位技术，广泛应用于自动驾驶应用中。现有的基于ICP的方法依赖效率和准确的点云配准，但由于未考虑初始姿态的可靠性，可能导致局部最优解。缺乏适应机制也会在复杂动态环境中影响点云配准的准确性。
### Innovation
提出了一种基于可靠初始姿态的自适应ICP LiDAR odometry方法。首先使用基于密度过滤的分布式粗配准获得初始姿态估计，然后通过与运动预测姿态的比较，选择可靠的初始姿态以降低初始点云之间的误差。之后，根据当前和历史误差动态调整适应阈值以适应动态环境的变化。最后，基于可靠的初始姿态和适应阈值，从当前帧到局部地图进行自适应点面ICP配准，从而实现高精度的点云对准。
### Conclusion
在公共KITTI数据集上的实验结果表明，所提出的方法优于现有方法，并显著提高了LiDAR odometry的准确性。
## 172. `cs.AI` - 叛逆的手术刀：激活定向削弱LLM的安全性 [PDF](https://arxiv.org/pdf/2509.22067), [HTML](https://arxiv.org/abs/2509.22067)
### Authors
Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Y. Rogov,Ivan Oseledets,Elena Tutubalina
### Background
激活定向是一种通过在模型隐藏状态中添加具有语义意义的向量来控制大模型行为的方法。这种技术通常被视为一种精确、可解释的替代微调，可以增强安全性。然而，研究表明，这种定向控制实际上会破坏模型的安全机制，使其更加符合有害的要求。通过对不同模型家族进行了广泛的实验，研究发现即使是随机的定向也能显著增加有害响应的可能性。
### Innovation
该研究证明了激活定向控制系统安全性的方法是一种潜在的威胁，即使在随机方向上也能显著增加有害响应的可能性。此外，研究还发现从稀疏自编码器（SAE）提取的良性特征进一步增加了这种风险。这些结果挑战了通过可解释性保证模型安全性的观念。
### Conclusion
研究结果表明，精细控制模型内部并不能确保精细控制模型的行为。虽然激活定向被认为是更安全的方法，但它实际上可能削弱模型的安全性。随机选择的向量组合在单个提示上可以创建一种通用攻击，显著增加未知请求的有害响应率。这些发现表明，依赖于模型内部分析的方法可能不足以保证安全性。
## 173. `cs.AI` - ERGO: 高分辨率视觉理解的有效性对于视觉语言模型 [PDF](https://arxiv.org/pdf/2509.21991), [HTML](https://arxiv.org/abs/2509.21991)
### Authors
Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim
### Background
在现实世界的视觉语言应用中，高效处理高分辨率图像至关重要。然而，现有的大型视觉语言模型因视觉标记数量庞大而导致巨大的计算开销。随着“以图思考”模型的出现，推理已经从文本扩展到视觉领域。这促使我们发展了一种两阶段的“粗到细”推理管道：首先分析下采样的图像以识别相关区域，然后在高分辨率下裁剪这些区域并进行后续的推理阶段。这方法在减少计算成本的同时也保留了必要的视觉细节。主要挑战在于推理出哪些区域真正与查询相关。近期的相关方法在图像输入下采样后进入第一阶段时往往失效，因感知驱动的推理需要清晰的视觉信息来进行有效的推理。
### Innovation
我们提出了一种名为ERGO（Efficient Reasoning & Guided Observation）的方法，该方法利用感知驱动的方式来进行多模态上下文推理，以确定聚焦点。我们的模型能够处理感知不确定性，通过扩展裁剪区域来覆盖视觉上含糊的区域以回答问题。为此，我们构建了一个简单而有效的强化学习框架中的奖励组件，以实现粗到细的感知。在多个数据集中，我们的方法不仅提高了准确性，还提高了效率。例如，ERGO在V*基准上超过了Qwen2.5-VL-7B，使用了其23%的视觉标记并且提高了3倍的推理速度。
### Conclusion
我们的方法在准确性上超过了原始模型和竞争方法，并且更加高效。具体来说，ERGO在V*基准上比Qwen2.5-VL-7B高出了4.7个百分点，并且只使用了其23%的视觉标记，实现了3倍的推理速度提升。我们已经开源了代码和模型。
## 174. `cs.AI` - SecureAgentBench：在现实漏洞场景下评估安全代码生成的基准 [PDF](https://arxiv.org/pdf/2509.22097), [HTML](https://arxiv.org/abs/2509.22097)
### Authors
Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo
### Background
大型语言模型（LLM）驱动的代码代理正在迅速改变软件工程，自动化诸如测试、调试和修复等任务。然而，其生成代码的安全风险成为一个关键问题。现有的基准虽然提供了有价值的见解，但仍存在不足，如缺乏真实环境中的漏洞引入背景，或是评估方法有限，无法全面检测功能性准确性或新漏洞。
### Innovation
本文引入了SecureAgentBench，这是一个包含105个编码任务的基准，旨在严格评估代码代理在安全代码生成方面的能力。每个任务包括：真实的任务设置，要求在大型代码库中进行多文件编辑；基于真实世界开源漏洞的精确引入点；综合的功能性测试、概念证明漏洞测试以及静态分析检测新引入漏洞。
### Conclusion
研究结果表明，当前的代理难以生成安全的代码，即使是表现最好的SWE-agent也只达到15.2%的安全正确解决方案；一些代理虽然生成了功能正确的代码但仍会引入新的漏洞；增加明确的安全指令并未显著提高安全编码，这表明需要进一步的研究以提高代码安全。这些发现确立了SecureAgentBench作为安全代码生成的严格基准，并有助于更可靠的软件开发。
## 175. `cs.AI` - 解码欺骗：理解自动语音识别系统在规避和投毒攻击中的漏洞 [PDF](https://arxiv.org/pdf/2509.22060), [HTML](https://arxiv.org/abs/2509.22060)
### Authors
Aravindhan G,Yuvaraj Govindarajulu,Parin Shah
### Background
研究已经证明，自动语音识别系统可以通过对抗样本被欺骗，进而错误解释输入的语音命令。以往的研究主要集中在受限制条件下和基于转移性的白盒或黑盒攻击上，而本文将探讨低成本的白盒攻击和基于非转移性的黑盒对抗攻击。研究人员借鉴了快速梯度符号方法和零阶优化等策略，进一步探讨了投毒攻击如何导致最先进的模型性能下降，从而错误解释音频信号。实验表明，通过合成少量扰动（信噪比为35dB）的细微却极具影响力对抗样本，可以在一分钟内实现这种对抗攻击，这表明最先进的开源模型存在实际的安全隐患，并强调了对抗安全的重要性。
### Innovation
本论文的创新点在于探讨低成本的白盒攻击和基于非转移性的黑盒对抗攻击，以及投毒攻击如何导致最先进的语音识别模型性能下降，从而错误解释音频信号。研究表明，通过合成少量扰动（信噪比为35dB）的细微却极具影响力对抗样本，可以在一分钟内实现这种对抗攻击，提出了新的攻击方法和理论见解。
### Conclusion
实验和分析表明，对抗攻击可以通过少量的扰动生成细微却极具影响力对手模型，这对最先进的开源语音识别模型构成了实际安全威胁。这强调了探讨和解决自动语音识别系统对抗攻击的必要性，以及加强对抗安全的重要性。
## 176. `cs.AI` - 更少的学习更多：一种用于高效策略优化的动态双层降采样框架 [PDF](https://arxiv.org/pdf/2509.22115), [HTML](https://arxiv.org/abs/2509.22115)
### Authors
Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding
### Background
批判免费的方法如GRPO能够降低内存需求通过从多个滚出中估计优势，但往往收敛缓慢，因为学习信号被大量的无信息样本和令牌稀释了。本文探讨了这一挑战。
### Innovation
提出了一种名为动态双层降采样(D$^3$S)的框架，该框架优先选择最有信息量的样本和令牌以提高策略优化的效率。D$^3$S工作在两个层次上：（1）采样层次，通过选择最大化优势方差的子采样集合来最大化策略梯度的范数；（2）令牌层次，通过优先考虑具有高优势幅度和策略熵乘积的令牌来集中更新，重点关注政策不确定且影响大的更新位置。此外，为了防止过度拟合高信号数据，D$^3$S使用了受课程学习启发的动态降采样计划，该计划在学习早期进行严苛的降采样以加速学习，之后逐渐放松以促进稳健的泛化。
### Conclusion
通过在Qwen2.5和Llama3.1上进行大量实验，结果显示在高级强化学习算法中集成D$^3$S能够实现最先进的性能和泛化，同时需要更少的样本和令牌。相关的代码已添加到附录材料中，并将公开发布。
## 177. `cs.AI` - R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning [PDF](https://arxiv.org/pdf/2509.22131), [HTML](https://arxiv.org/abs/2509.22131)
### Authors
Hongyu Shan,Mingyang Song,Chang Dai,Di Liang,Han Chen
### Background
链式思维（CoT）提示有助于大规模语言模型（LLMs）解决复杂的推理任务，通过引发明确的逐步解释。然而，CoT的冗长会增加延迟和内存使用，并可能在长链中传播早期错误。论文分析了CoT的局限性。
### Innovation
提出了Reasoning Capsule（R-Capsule）框架，旨在结合隐式推理的效率和显式CoT的透明性。R-Capsule通过压缩高层次计划为一组学习的隐式令牌（Reasoning Capsule）并保持执行步骤轻量或明确，实现了混合方法。灵感来自信息瓶颈（IB）原则，鼓励胶囊既尽可能简单又能胜任任务。通过低容量瓶颈鼓励简明性，通过目标函数鼓励充分性，包括一个主要任务损失以提高答案准确性，并通过一个辅助计划重构损失鼓励胶囊准确地表示原始文本计划。重构目标有助于使潜空间具象化，从而提高可解释性并减少不具信息性的捷径的使用。
### Conclusion
该框架在效率、准确性和解释性之间取得平衡，减少了推理的显性标记足迹，并在复杂基准测试中保持或改善了准确性。
## 178. `cs.AI` - 基于强化学习的持久算法性申诉 [PDF](https://arxiv.org/pdf/2509.22102), [HTML](https://arxiv.org/abs/2509.22102)
### Authors
Marina Ceccon,Alessandro Fabris,Goran Radanović,Asia J. Biega,Gian Antonio Susto
### Background
算法性申诉旨在为个体提供实际可操作的建议，以提高他们获得自动化决策系统（如贷款批准）有利结果的机会。尽管前期研究主要关注模型更新的鲁棒性，但对申诉的时间动态性特别是竞争和资源受限环境中相对较关注不足。在这种环境里，建议会影响未来的申请人池。
### Innovation
本文首次提出了一种新颖的时间感知算法回溯框架，明确建模候选人群体如何适应推荐的变化。提出了基于强化学习的算法回溯算法，能够捕捉环境不断变化的动力学，生成可行且长期有效的推荐。推荐具有持久性，确保在预定时间窗口T内有效。
### Conclusion
在复杂模拟环境中进行的大量实验表明，本文方法显著优于现有基准，提供了在可行性和长期有效性之间的更优平衡。这表明，将时间和行为动态性整合到实用的算法性申诉系统设计中至关重要。
## 179. `cs.AI` - 行动意识动态剪枝以实现高效视觉-语言-动作操作 [PDF](https://arxiv.org/pdf/2509.22093), [HTML](https://arxiv.org/abs/2509.22093)
### Authors
Xiaohuan Pei,Yuxing Chen,Siyu Xu,Yunke Wang,Yuheng Shi,Chang Xu
### Background
视觉-语言-动作（Vision-Language-Action，VLA）模型在机器人操作中需要高效地处理长时序多模态上下文进行推理，其中视觉令牌的注意力是主要的计算成本。现有的办法通过减少视觉冗余来提高推理速度，但它们忽视了机器人操作阶段间视觉冗余的差异性。研究发现，粗放操作阶段的视觉令牌冗余高于细粒度操作阶段，且与动作动态紧密相关。基于这个观察，提出了一个集成文本驱动的令牌选择和动作感知轨迹门控的多模态剪枝框架，专门针对不同操作阶段的实际需求进行动态调整，以平衡计算效率和感知精度。
### Innovation
提出了一种行动意识动态剪枝（Action-aware Dynamic Pruning，ADP）方法，该方法结合了文本驱动的标记选择和动作感知的轨迹门控机制，能在不同任务阶段中根据动作动态条件化地调整剪枝信号，从而实现计算效率和感知精确度之间的平衡。方法在实验中显示出显著减少FLOPs和动作推理延迟（例如，OpenVLA-OFT上的1.35倍速度提升），并且保持了与基线方法相当的成功率（例如，OpenVLA上提升了25.8%）
### Conclusion
该方法为机器人策略提供了简单可插拔的路径，提高机器人操作的效率和性能边界。
## 180. `cs.AI` - QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems [PDF](https://arxiv.org/pdf/2509.22064), [HTML](https://arxiv.org/abs/2509.22064)
### Authors
Anya Belz,Simon Mille,Craig Thomson
### Background
先前的研究表明，报告相同质量标准名称（例如流畅性）的两个自然语言处理（NLP）评估实验不一定在评价系统的同一质量方面，由此名称暗含的可比较性可能存在误导。由于不清楚何时两个评估是可比较的，目前缺乏从多个独立进行的评价中得出可靠结论的能力，这阻碍了该领域的整体科学发展。这一问题自NLP的早期开始（Sparck Jones, 1981）就一直存在。除非有一个标准的质量标准名称和定义集，以将实际使用的数百个质量标准名称映射和根基化，否则很难完全解决这一问题的不清晰可比性问题。因此，作者通过从自然语言处理领域三个关于评估的调查中推导出标准质量标准名称和定义，构建了一个层次结构化的QCET质量评价分类学（QCET Quality Criteria for Evaluation Taxonomy），以促进这一领域的科学进步。
### Innovation
QCET质量评价分类学从三个关于NLP评估的调查中推导出标准的质量评价名称和定义，并构建了一个层次结构化的体系，其中每个父节点捕获子节点的共同方面。该分类学提供了一个标准的质量评价名称和定义集，使得现有的评估可以进行比较，并指导新的评估设计，同时评估监管合规性。这对于提高NLP系统的评估的可比性和科学性具有创新意义。
### Conclusion
QCET质量评价分类学不仅建立了现有评估的可比性，还指导了新评估的设计，并评估了监管合规性。通过标准化的质量评价名称和定义集，该分类学为提高自然语言处理领域科学验证的可靠性提供了有力支持，使这一领域能够更科学地进步。
## 181. `cs.AI` - 从长到精：基于多轮精炼的性能感知和自适应链式思维压缩 [PDF](https://arxiv.org/pdf/2509.22144), [HTML](https://arxiv.org/abs/2509.22144)
### Authors
Jianzhi Yan,Le Liu,Youcheng Pan,Shiwei Chen,Zike Yuan,Yang Xiang,Buzhou Tang
### Background
链式思维（CoT）推理在复杂任务上可以提高性能，但会产生显著的推理延迟，因为其表述繁琐。
### Innovation
提出了一种名为Multiround Adaptive Chain-of-Thought Compression（MACC）的新框架，它利用了令牌弹性现象（即过小的令牌预算反而可能增加输出长度），通过多轮精炼逐步压缩CoT。该自适应策略允许MACC为每个输入确定最佳压缩深度，同时在保持准确性改进的同时，减少输出长度平均47个令牌，并显著降低延迟。还展示了测试时表现（准确性和标记长度）可以使用可解释特征如困惑度和压缩率在训练集上可靠预测，无需反复微调。
### Conclusion
该方法在不同模型上可以有效选择和预测模型，证明CoT压缩既有效又可预测。已在不同模型上验证了此方法的有效性和预测性。
## 182. `cs.AI` - Refine-Control: 半监督蒸馏方法用于条件图像生成 [PDF](https://arxiv.org/pdf/2509.22139), [HTML](https://arxiv.org/abs/2509.22139)
### Authors
Yicheng Jiang,Jin Yuan,Hua Yuan,Yao Zhang,Yong Rui
### Background
条件图像生成模型通过利用基于文本的控制来生成定制的图像取得了显著成果。然而，这些模型对资源的需求很高，且优质标注数据稀缺，这阻碍了它们在边缘设备上的部署，导致高昂的成本和隐私问题，特别是在用户数据被发送到第三方时。
### Innovation
我们提出了Refine-Control，一种半监督蒸馏框架。该框架通过引入三级知识融合损失来提升学生模型的性能，从而传递不同层次的知识。为了增强泛化能力和缓解数据集稀缺问题，我们引入了一种利用标记和未标记数据的半监督蒸馏方法。实验结果表明，Refine-Control在降低计算成本和延迟的同时，保持了高保真度的生成能力和可控性。
### Conclusion
实验结果显示，Refine-Control在保持高保真度生成能力和可控性的同时，实现了显著的计算成本和延迟降低。
## 183. `cs.AI` - 轻量化错误缓解策略用于LLM后训练N:M激活稀疏性 [PDF](https://arxiv.org/pdf/2509.22166), [HTML](https://arxiv.org/abs/2509.22166)
### Authors
Shirin Alanova,Kristina Kazistova,Ekaterina Galaeva,Alina Kostromina,Vladimir Smirnov,Redko Dmitry,Alexey Dontsov,Maxim Zhelnin,Evgeny Burnaev,Egor Shvetsov
### Background
大语言模型（LLM）的高效推理需求促使了稀疏化技术的研究，尽管N:M剪枝在权重上的应用已经较为成熟，但其在激活稀疏化上的应用尚未充分探索。此前的研究表明，相对于等尺度的权重剪枝，激活剪枝能以更低的稀疏度保留更优秀的生成能力，同时减少I/O开销。在此背景下，本研究对后训练N:M激活剪枝方法进行了全面分析。
### Innovation
本研究提出了轻量级的错误缓解策略，并针对LLM开展了N:M激活剪枝。通过多种评估标准，研究确定了硬件友好型的基础线，这些方法不需要过多的校准。此外，研究还探索了除NVIDIA标准2:4之外的稀疏性模式，发现16:32的模式几乎能达到无结构稀疏性的性能。尽管如此，基于灵活性和硬件实现复杂性之间的权衡，研究队伍选择了8:16的模式作为更优的候选人。
### Conclusion
研究提供了有效的激活剪枝方法，并激励未来硬件支持更灵活的稀疏性模式。本研究已公开代码供进一步研究使用。
## 184. `cs.AI` - 借助离线强化学习和大语言模型合作的多智能体路径寻找 [PDF](https://arxiv.org/pdf/2509.22130), [HTML](https://arxiv.org/abs/2509.22130)
### Authors
Merve Atasever,Matthew Hong,Mihir Nitin Kulkarni,Qingpei Li,Jyotirmoy V. Deshmukh
### Background
多智能体路径寻找（MAPF）是机器人技术和物流中至关重要的问题，但由于其组合复杂性和现实环境中的部分可观察性，这一问题极具挑战性。去中心化的强化学习方法常遇到两个主要问题：首先，各智能体倾向于自我中心的行为，导致频繁碰撞；其次，依赖复杂的通信模块导致长期的训练时间，有时甚至需要数周时间。
### Innovation
本文提出了一种基于决策变换器（DT）的高效去中心化规划框架，利用离线强化学习显著减少了训练时间，从数周缩短到仅仅数小时。此外，为了解决在动态环境变化下的适应性局限，引入了大规模语言模型（GPT-4o）以动态引导智能体策略，从而提高了适应性和性能。
### Conclusion
通过在静态和动态变化环境中进行的大量实验，证明了基于DT的方法，辅助以GPT-4o，显著增强了适应性和性能。
## 185. `cs.AI` - AI_INFN平台：云中的人工智能开发 [PDF](https://arxiv.org/pdf/2509.22117), [HTML](https://arxiv.org/abs/2509.22117)
### Authors
Lucio Anderlini,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Rosa Petrini,Daniele Spiga
### Background
机器学习（ML）正在改变科学家们设计、开发和部署数据密集型软件的方式。然而，ML的使用也给计算基础设施带来了新的挑战，特别是在提供和协调访问硬件加速器方面。INFN资助的人工智能项目AI_INFN旨在通过提供多方面的支持来促进INFN使用场景中ML技术的采用，包括AI定制化的计算资源配给。该项目利用INFN云中的云原生解决方案来尽可能有效地共享硬件加速器，确保研究所的研究活动多样性不受影响。
### Innovation
AI_INFN平台利用Kubernetes平台简化基于GPU的数据分析工作流程的开发及其在异构分布式计算资源上的可扩展性，同时使用虚拟Kubelet和InterLink API的卸载机制。这种设置可以在不同的资源提供商之间管理工作流程，包括 Worldwide LHC Computing Grid 的站点和超级计算机如CINECA Leonardo，为需要不同工作负载部分专用基础设施的用例提供了一个模型。初步测试结果、新兴的案例研究和整合场景将基于功能测试和基准测试进行展示和分析
### Conclusion
AI_INFN平台通过Kubernetes和其他云原生技术在合作开发和资源共享方面取得了显著进展，初步测试和案例研究显示出积极的结果，为未来的研究和应用提供了坚实的基础。
## 186. `cs.AI` - 通过监督分类模型与大语言模型紧密协作实现普遍的法律文章预测 [PDF](https://arxiv.org/pdf/2509.22119), [HTML](https://arxiv.org/abs/2509.22119)
### Authors
Xiao Chi,Wenlin Zhong,Yiquan Wu,Wei Wang,Kun Kuang,Fei Wu,Minghui Xiong
### Background
法律文章预测（LAP）是法律文本分类中的关键任务，利用自然语言处理（NLP）技术，根据案件事实描述自动预测相关法律条文。作为法律决策的基础步骤，LAP在后续判决（如指控和处罚）中起重要作用。尽管LAP十分重要，现有方法在应对LAP复杂性时面临巨大挑战。传统的监督分类模型（如CNN和BERT）难以完全捕捉到复杂的事实模式，而大型语言模型（LLMs）尽管在生成任务中表现出色，但在预测场景中表现不佳，原因在于法律条文的抽象性和ID基础性。此外，不同司法管辖区之间法律制度的多样性也进一步增加了问题的复杂性，大多数方法仅针对特定国家，缺乏广泛的适用性。
### Innovation
为解决这些局限，本文提出了Uni-LAP，一个利用监督分类模型（SCMs）和大语言模型（LLMs）优势的通用框架，通过紧密协作来提升法律文章预测的效果。具体来说，在Uni-LAP中，监督分类模型使用了一种新颖的Top-K损失函数来生成准确的候选法律条文，而大语言模型则利用演绎推理来精炼最终预测结果。
### Conclusion
我们通过来自多个司法管辖区的数据集评估了Uni-LAP，并且实证结果表明，本方法在各方面都优于现有基线方法，展示了其有效性和广泛适用性。
## 187. `cs.AI` - 桥接草稿策略偏差：推测性解码的群体树优化 [PDF](https://arxiv.org/pdf/2509.22134), [HTML](https://arxiv.org/abs/2509.22134)
### Authors
Shijing Hu,Jingyang Li,Zhihui Lu,Pan Zhou
### Background
现有的训练目标仅优化单一贪婪草稿路径，而解码遵循树策略，重新排名并验证多个路径。这种草稿策略的偏差限制了可以实现的最大加速。
### Innovation
提出了一种名为群体树优化（GTO）的方法，通过两部分实现训练与解码时间树策略的一致性：（i）无采样目标，即在正确模型下草稿树的平均接受长度，直接衡量解码性能；（ii）基于群体的草稿策略训练，一种稳定的优化方案，对比当前和冻结参考草稿模型的树，形成去偏差的群体标准化优势，并沿最长接受序列应用类似PPO的替代目标进行稳健更新。研究表明，增加草稿树奖励可以证明提高接受长度和加速效果。该方法在对话（MT-Bench）、代码（HumanEval）和数学（GSM8K）等多种模型（例如，LLaMA-3.1-8B、LLaMA-3.3-70B、Vicuna-1.3-13B、DeepSeek-R1-Distill-LLaMA-8B）上提高了接受长度和额外的加速效果。
### Conclusion
通过桥接草稿策略偏差，GTO 提供了一种实用且通用的高效语言模型推理解决方案。
## 188. `cs.AI` - 基于问题驱动的分析与合成：使用LLMs构建可解释的主题树进行文本聚类和可控生成 [PDF](https://arxiv.org/pdf/2509.22211), [HTML](https://arxiv.org/abs/2509.22211)
### Authors
Tiago Fernandes Tavares
### Background
在缺乏数据的领域中，传统的主题模型难以进行无监督的文本语料分析。这些模型通常通过关键词列表描述聚类，这需要大量的手动工作才能进行解释，并且往往缺乏语义连贯性。
### Innovation
本文引入了递归主题划分（RTP）框架，利用大语言模型（LLMs）构建一棵二叉树，每棵树节点是一个自然语言问题，能够语义上划分数据，使簇的逻辑明确，提高了可解释性。RTP的层级结构比基于关键词的主题更具可解释性，特别是在下游分类任务中展示了聚类作为重要特征的有效性，尤其是在数据底层主题与任务标签相关时。
### Conclusion
RTP不仅提供了一种新的数据探索范式，从统计模式发现转向基于知识的主题分析，还展示了通过RTP树的道路可以作为生成模型的结构化、可控提示，将其分析框架转化为强大的合成工具，实现对源语料库中发现的特定特征的一致仿制。
## 189. `cs.AI` - VizGen：基于多代理AI架构的自然语言数据探索与可视化 [PDF](https://arxiv.org/pdf/2509.22218), [HTML](https://arxiv.org/abs/2509.22218)
### Authors
Sandaru Fernando,Imasha Jayarathne,Sithumini Abeysekara,Shanuja Sithamparanthan,Thushari Silva,Deshan Jayawardana
### Background
数据可视化对于解读复杂数据集至关重要，但传统的工具通常需要技术专业知识，限制了其易用性。
### Innovation
VizGen 是一个基于多代理架构的人工智能辅助图形生成系统，通过高度先进的自然语言处理（NLP）和大语言模型（LLMs）如Claude 3.7 Sonnet和Gemini 2.0 Flash，它可以将用户查询转换为SQL，并推荐合适的图形类型。VizGen 不仅支持直观的数据分析和可视化，还能够分析数据中潜在的模式、异常值和相关性，并通过解释提供对数据集的深入理解，这些解释包含了从互联网中收集的上下文信息。此外，VizGen 支持与SQL数据库的实时交互以及图形的即对话式优化。
### Conclusion
VizGen 通过弥合技术复杂性和用户友好设计之间的差距，实现了数据可视化的普及化。
## 190. `cs.AI` - Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics [PDF](https://arxiv.org/pdf/2509.22207), [HTML](https://arxiv.org/abs/2509.22207)
### Authors
Mu Huang,Linning Xu,Mingyue Dai,Yidi Shao,Bo Dai
### Background
在流体动力学中，模拟用户定义目标的物理合理的轨迹是一个基础但具有挑战性的任务。尽管基于粒子的模拟器可以高效地再现前向动力学，但逆向推断仍然困难，特别是在耗散系统中，逆向运动是不可逆的，基于优化的求解器速度慢、不稳定且难以收敛。
### Innovation
我们引入了可逆图网络模拟器（R-GNS），这是一种统一框架，它在一个图架构中实现了双向一致性。与之前的神经模拟器通过拟合反向数据近似逆向动力学不同，R-GNS 不试图逆转底层物理。相反，我们提出了一种基于残差可逆消息传递的设计，共享参数同时耦合前向动力学和逆向推断，提供准确的预测并高效恢复合理的初始状态。R-GNS 在三个耗散基准上的实验显示出更高的准确性和一致性，参数仅为其他基线的四分之一，并且逆向推断比基于优化的基线快 100 多倍。在前向模拟中，R-GNS 达到了强大的 GNS 基线的速度；在目标条件任务中，它消除了迭代优化，实现了数量级的加速。在目标条件任务中，R-GNS 进一步展示了对复杂的目标形状（例如字符“L”和“N”）产生生动的、物理上一致的轨迹的能力。
### Conclusion
据我们所知，这是第一个统一前向和逆向模拟的可逆框架，适用于耗散流体系统。
## 191. `cs.AI` - 教育AI感受：一种身临其境的情感交流协作探索 [PDF](https://arxiv.org/pdf/2509.22168), [HTML](https://arxiv.org/abs/2509.22168)
### Authors
Esen K. Tütüncü,Lissette Lemus,Kris Pilcher,Holger Sprengel,Jordi Sabater-Mir
### Background
该安装装置通过全身体动追踪和实时AI反馈来探索人类情感，强调了包容性和伦理的情感计算的新途径。研究者将情感分类从传统的自上而下的方法转变为由参与者驱动的、文化多元的定义方法，推动了多媒体研究从单一用户面部分析向更具身体性、协同创造的的情感AI范式的转变。这种新的协作方法促进了用户的自主权，减少了偏见，并为更高级的互动应用开辟了途径。
### Innovation
该作品创新地将MoveNet用于精确动捕，并结合多推荐AI系统动态分析情感状态，进而提出了由参与者驱动的情感定义方法。这种新的操作方式超越了传统的单一用户面部分析，走向了更加具身体性和协同创造的情感AI范式，有助于更加包容和伦理的情感计算。
### Conclusion
该安装装置通过协作、全身体动的方式探索情感交流，提出了新的由参与者驱动的情感定义方法，强调了用户的自主权和情感计算的包容性。未来有望进一步推动情感AI的研究和发展，减少偏见并为更高级的交互应用提供支持。
## 192. `cs.AI` - 自主车辆群体行为对城市交通动态的影响：多智能体强化学习方法 [PDF](https://arxiv.org/pdf/2509.22216), [HTML](https://arxiv.org/abs/2509.22216)
### Authors
Ahmet Onur Akman,Anastasia Psarou,Zoltán György Varga,Grzegorz Jamróz,Rafał Kucharski
### Background
本文研究了强化学习（RL）赋能的自动驾驶车辆（AV）对混合交通环境中的城市交通流的影响。研究集中在多智能体环境下的简化日常路线选择问题上，考虑了一个人类驾驶员网络，人类驾驶员选择最短行驶时间的路线到达目的地。之后，将1/3的人口转换为AV，其作为使用深度Q学习算法的RL代理。定义了一组优化目标，即自私、协作、竞争、亲社会、利他和恶意等行为。通过奖励设置这些行为的约束条件。使用自研的RL框架PARCOUR进行仿真。仿真结果表明，AV能够通过学习提高高达5%的行驶时间效率，这取决于AV的行为，对人类驾驶员的行驶时间影响不同。当AV采取自私行为时，它们的行驶时间总是比人类驾驶员短。结果展示了每种目标行为的学习任务复杂性差异，并证明多智能体RL适用于交通网络中的集体路径选择，但其对共存各方的影响差异很大。
### Innovation
研究使用多智能体强化学习的方法，评估了不同行为的AV对城市交通动态的影响，并通过自研的RL框架PARCOUR进行仿真。研究发现在不同行为下AV的表现差异，特别是自私行为下AV的行驶时间比人类驾驶员短。进一步探索了各种行为对交通的影响和复杂性差异。
### Conclusion
研究结果表明，多智能体RL方法可以应用于交通网络中的集体路径选择，但在不同行为下对共存各方的影响差异很大。自私的AV行为有助于减少自身行驶时间，但可能导致整体交通效率的下降。需要进一步研究各种行为对交通系统的综合影响。
## 193. `cs.AI` - 提高分布式优化效率：通过最小开销重新构想邻域聚合 [PDF](https://arxiv.org/pdf/2509.22174), [HTML](https://arxiv.org/abs/2509.22174)
### Authors
Durgesh Kalwar,Mayank Baranwal,Harshad Khadilkar
### Background
在当今对数据高度敏感的环境中，分布式学习作为一种重要工具崭露头角，不仅增强了隐私保护措施，还简化了计算操作。尤其是在完全去中心化基础设施中，由于缺乏集中聚合，本地处理变得尤为重要。因此，我们需要一个既能加速学习又能最小化通信和内存开销的框架。
### Innovation
DYNAWEIGHT是一种新的框架，用于在多代理网络中进行信息聚合。与传统的静态权重分配方法（如Metropolis权重）不同，DYNAWEIGHT能够根据邻近服务器在本地数据集上的相对损失动态分配权重。这使得拥有更多样化信息的服务器优先被使用，尤其是在数据异构性较大的情况下。研究表明，DYNAWEIGHT作为一个与任何底层服务器优化算法兼容的聚合方案，具有极大的灵活性和广泛的应用前景，能够在各种数据集（如MNIST、CIFAR10、CIFAR100）的不同服务器数量和网络拓扑上显著提高训练速度。
### Conclusion
DYNAWEIGHT提供了一种有效的邻域聚合方法，能够实现去中心化学习加速，同时具有灵活性和广泛的适用性。
## 194. `cs.AI` - 向单纯形顶点推进：平滑向量量化中代码崩溃的简单解决方案 [PDF](https://arxiv.org/pdf/2509.22161), [HTML](https://arxiv.org/abs/2509.22161)
### Authors
Takashi Morita
### Background
向量量化在现代机器学习中被广泛应用，但其非不同的量化步骤阻断了梯度反向传播。平滑向量量化通过将码本向量的硬分配松散为码本项的加权组合（表示为单纯形向量与码本的矩阵乘积）来解决这一问题。有效的平滑需要两个特性：1. 平滑量化器应接近于一热向量，保持紧密逼近；2. 所有码本条目都应被利用，防止代码崩溃。现有方法通常单独解决这些期望，而本研究引入了一种简单直观的正则化，通过最小化每个单纯形顶点与其最近的K个平滑量化器之间的距离，同时促进两者。
### Innovation
引入了一种简单而直观的正则化方法，通过最小化每个单纯形顶点与其最近的K个平滑量化器之间的距离，同时促进量化器接近一热向量和所有码本条目的充分利用，解决了平滑向量量化中的代码崩溃问题。这种方法在代表性的基准测试中，如离散图像自编码和对比性语音表示学习，展示了更可靠的码本利用和比先前方法更好的性能。
### Conclusion
实验证明，提出的方法在代表性的基准测试中，能够更可靠地利用码本并改进性能。
## 195. `cs.AI` - 大型语言模型的输出是无意义的 [PDF](https://arxiv.org/pdf/2509.22206), [HTML](https://arxiv.org/abs/2509.22206)
### Authors
Anandi Hattiangadi,Anders J. Schoubye
### Background
本文讨论了大型语言模型（LLM）的输出是否具有字面意义上的意义。文章基于两个核心前提：(a) 要使LLM的输出具有字面意义上的意义，需要某种特定类型的意图，(b) LLM不可能具备这些特定类型的意图。文章还回应了两种反驳意见：一种是语义外部主义者的观点，认为可以假设依赖性可以取代意图；另一种是语义内部主义者的观点，认为意义可以仅通过概念之间的内在关系来定义，如概念角色。
### Innovation
本文提出了一种简单但有力的论据，认为LLM的输出没有意义。该论据基于意图理论，认为没有适当的意图，单词和语句就没有意义或无法有意义。本文还对反驳意见进行了回应，重新确立了其主要论点的新颖性。
### Conclusion
即使本文的论点成立，LLM的输出仍然看起来有意义，可以用来获取真实信念甚至知识。这意味着，尽管从严格意义上讲，LLM的输出没有意义，但从应用效果来看，这些输出依然具有实际价值和有效性。
## 196. `cs.AI` - 多种模式思考：复合推理如何在有限数据下提升大型语言模型的性能 [PDF](https://arxiv.org/pdf/2509.22224), [HTML](https://arxiv.org/abs/2509.22224)
### Authors
Zishan Ahmad,Saisubramaniam Gopalakrishnan
### Background
大型语言模型（LLMs）虽然有着显著的能力，但依赖于单一且主导性的推理模式，这限制了它们在需要多种认知策略的复杂问题上的表现。
### Innovation
提出了复合推理（CR），这是一种新的推理方法，使LLMs能够动态地探索和结合多种推理风格（如演绎、归纳和反演绎），以实现更细致的解决问题。该方法在科学和医学问题解答基准测试中表现出色，超越了现有的基线方法（如思维链（CoT）），并在准确性和样本效率方面表现出色。
### Conclusion
研究发现，通过培育内部推理风格的多样性，LLMs能够获得更为稳健、适应性强和高效的解决问题能力。对于医疗问题回答，它侧重于反演绎和演绎推理；而对于科学推理，则转向因果、演绎和归纳法。
## 197. `cs.AI` - 基于单张图像的感知刚性3D高斯变形 [PDF](https://arxiv.org/pdf/2509.22222), [HTML](https://arxiv.org/abs/2509.22222)
### Authors
Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo
### Background
单张图像中的物体变形重构仍然是计算机视觉和图形学中的一个重大挑战。现有方法通常依赖多视角视频来恢复变形，这限制了它们在受限场景中的适用性。
### Innovation
本文提出了一种名为DeformSplat的新型框架，该框架能有效地引导3D高斯变形仅从单张图像。该方法包含两个主要的技术贡献：一是Gaussian-to-Pixel Matching，它弥合了3D高斯表示与2D像素观察之间的领域差距，从而使从稀疏视觉线索中获得稳健的变形指导成为可能；二是Rigid Part Segmentation方法，包括初始化和精炼的过程，该方法明确地识别刚性区域，这对于在变形过程中保持几何一致性至关重要。
### Conclusion
结合这两种技术，本方法可以从单张图像中重建一致的变形。广泛的经验表明，本方法大大优于现有方法，并且天然适用于各种应用，例如帧内推和交互式对象操作。
## 198. `cs.AI` - 基于匹配掩码提升的多义语言高斯点绘 [PDF](https://arxiv.org/pdf/2509.22225), [HTML](https://arxiv.org/abs/2509.22225)
### Authors
Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li
### Background
将2D开放式词汇的理解提升到3D高斯点绘（3DGS）场景是一个关键技术挑战。然而，主流方法面临三大关键问题：（i）对每个场景重新训练的依赖导致无法即插即用；（ii）限制性的单义设计无法表示复杂的、多概念语义；（iii）跨视图语义不一致性导致最终语义表示受损。
### Innovation
我们提出了MUSplat，这是一种无需训练的框架，完全放弃了特征优化。利用预训练的2D分割模型，我们的流水线生成并提升多粒度的2D掩码至3D，估计每个高斯点的前景概率以形成初始对象组。然后，通过语义熵和几何透明度优化这些初始组的模糊边界。接着，通过解析对象在最具代表性的视角下的视觉特征，使用视觉语言模型（VLM）提炼出稳健的文本特征以解决视觉不一致性问题，支持开放式词汇查询通过对语义进行匹配。通过消除每个场景的训练过程，MUSplat将场景适应时间从数小时缩短到几分钟。
### Conclusion
在基准任务上，MUSplat超越了现有的基于训练框架，同时解决了他们的单义限制。
## 199. `cs.AI` - ASSESS: 语句相似性的一种语义和结构评估框架 [PDF](https://arxiv.org/pdf/2509.22246), [HTML](https://arxiv.org/abs/2509.22246)
### Authors
Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo
### Background
语句自动形式化，即从自然语言到形式语言的自动翻译，已经取得了显著的进步。然而，自动评估指标的发展仍然有限。现有的形式语句相似度评估指标往往未能平衡语义和结构信息。字符串基方法捕捉句法结构但忽视语义意义，而基于证明的方法验证语义等价性但忽略结构细微差别，并且在证明失败的情况下无法提供加权相似度评分。
### Innovation
我们提出了ASSESS（语义和结构评估框架语句相似性）框架，该框架综合考虑了语义和结构信息，提供了连续的相似度评分。该框架首先将正式陈述转换为操作符树，以捕捉其句法结构，然后使用新型TransTED（转换树编辑距离）相似度量度计算相似度得分，该量度度量度通过引入转换增强了传统的树编辑距离，使语义意识得以体现。通过EPLA（评估证明与相似性）基准对TransTED相似度进行了严格验证，这是一个由524对专家注释的形式语句对组成的基准，来自miniF2F和ProofNet，带有语义证明和结构相似性的标签。
### Conclusion
实验结果表明，TransTED相似度优于现有方法，实现了最先进的准确度和最高的Kappa系数。基准和实现代码将很快公开。
## 200. `cs.AI` - MimicDreamer：人机示范对齐以实现可扩展的语义视觉训练 [PDF](https://arxiv.org/pdf/2509.22199), [HTML](https://arxiv.org/abs/2509.22199)
### Authors
Haoyun Li,Ivan Zhang,Runqi Ouyang,Xiaofeng Wang,Zheng Zhu,Zhiqin Yang,Zhentao Zhang,Boyuan Wang,Chaojun Ni,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang,Zhenbo Song,Xingang Wang
### Background
Vision Language Action (VLA) 模型的泛化能力依赖于多种多样的训练数据，然而机器人动手交互数据的收集代价高昂且难以为继。相比之下，人类示范视频资源更加广泛且成本效益高，并且最近的研究证实了其在训练VLA模型中的有效性。但是，人类视频与机器人执行视频之间存在显著的领域差距，包括不稳定摄像头视角、人类双手与机械臂之间的视觉差异以及动作动力学不同。为弥合这一差距，该研究提出了一种框架MimicDreamer，通过联合对齐视觉、视角和动作来将快速低成本的人类示范转化为能用于机器人训练的监督信息。
### Innovation
提出了MimicDreamer框架，通过联合对齐视觉、视角和动作，将人类示范转化为机器人可用的监督信息。具体创新点包括：1) 提出了H2R Aligner，一种视频扩散模型，通过从人类操作视频中转移运动来生成高保真机器人示范视频；2) 提出了EgoStabilizer，一种通过透射变换使第一人称视频规范化，并修复变形和遮挡；3) 将人类手部轨迹映射到机器人坐标系，并应用约束逆运动学解算器生成具有准确姿态追踪的可行、低抖动关节指令。
### Conclusion
基于我们合成的人类到机器人的视频训练的VLA模型，能在真实机器人上实现少样本执行。同时，使用人类数据进行训练的模型相比于仅使用真实机器人数据训练的模型，在六种代表性操作任务中的平均成功率提高了14.7%。
## 201. `cs.AI` - 通过二次形式学习不变函数 [PDF](https://arxiv.org/pdf/2509.22184), [HTML](https://arxiv.org/abs/2509.22184)
### Authors
Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P
### Background
本文介绍了一种通过学习数据中所对应的二次形式$x^T A x$来学习已知或未知群（不变函数）的方法。某些群，即正交群，保持特定的二次形式，本文利用这一特性，在假设群为正交的情况下来发现潜在的对称群。利用对应的唯一对称矩阵及其固有的对角形式，将合适的归纳偏置引入神经网络架构中，由此得到的模型是简化且高效的。此方法产生了一个保持范数不变的不变模型，而可变模型则表现为保持范数不变模型和尺度不变模型之积，其中“乘积”表示群作用。此外，本文将框架扩展到一个更一般的情况，其中函数通过一个（或乘积）群作用作用于输入向量的元组上。在这个扩展中，可变函数分解为唯一的角度成分，仅由归一化后的第一个向量提取，以及一个与元组完整Gram矩阵有关的尺度不变成分。这种分解保留了元组多重输入之间的依赖关系同时保持了内部的群对称性。本文通过多项式回归、顶夸克标记和动量矩矩阵预测等多个任务评估了该框架的有效性，并与基线方法进行对比分析，结果表明该模型在发现潜在对称性和高效学习相应的可变函数方面始终表现出色。
### Innovation
通过学习二次形式$x^T A x$来学习已知或未知群的不变或可变函数；利用正交群保持特定二次形式的特性来揭示潜在的对称群；将合适的归纳偏置引入神经网络架构以简化并高效化模型；将框架扩展到一个更一般的情况，可变函数分解为角度成分和尺度不变成分，以保持多重输入之间的依赖关系和群对称性；通过多个任务的对比分析来验证框架的有效性表现和优越性。
### Conclusion
本文介绍的框架通过学习已知或未知群的对应二次形式来简化并高效地学习不变或可变函数，尤其是在假设群为正交时揭示潜在的对称性非常有效。通过算法流程的影响和应用，该框架能够在多项任务中表现出色地发现潜在对称性和高效学习相应的可变函数。
## 202. `cs.AI` - Wavelet-Induced Rotary Encodings: RoPE Meets Graphs [PDF](https://arxiv.org/pdf/2509.22259), [HTML](https://arxiv.org/abs/2509.22259)
### Authors
Isaac Reid,Arijit Sehanobish,Cedrik Höfs,Bruno Mlodozeniec,Leonhard Vulpius,Federico Barbero,Adrian Weller,Krzysztof Choromanski,Richard E. Turner,Petar Veličković
### Background
介绍了WIRE（波let诱导旋转编码）的概念，它是一种扩展旋转位置编码（RoPE）的算法，适用于图结构数据。背景信息指出，RoPE在LLMs和ViTs中非常流行，但尚未应用于图结构数据。
### Innovation
WIRE扩展了RoPE，不仅适用于网格图，还具有节点排序置换下的不变性、与线性注意力兼容等优点，并且在满足某些假设的情况下，随着图电阻距离的关系变得递归。
### Conclusion
WIRE在合成和真实世界的任务上进行了测试，包括识别单色子图、点云语义分割以及标准图基准测试，发现它在图结构重要的情况下有效。
## 203. `cs.AI` - 超越分类准确性：Neural-MedBench 及深层推理基准的需求 [PDF](https://arxiv.org/pdf/2509.22258), [HTML](https://arxiv.org/abs/2509.22258)
### Authors
Miao Jing,Mengting Jia,Junling Lin,Zhongxia Shen,Lijun Wang,Yuanyuan Peng,Huan Gao,Mingkun Xu,Shangyang Li
### Background
近期，视觉-语言模型（VLMs）在医学标准基准测试中取得了显著的性能提升，然而它们的真实临床推理能力尚未完全明确。现有的数据集主要侧重于分类准确性，导致一种在高风险诊断推理方面看似熟练但实际上表现不佳的评价假象。这使得对于VLMs的真实临床推理能力了解不足。
### Innovation
本文介绍了一种名为Neural-MedBench的基准测试，专门设计用于检验神经学中多模态临床推理的极限。Neural-MedBench整合了多序列MRI扫描、结构化的电子健康记录和临床笔记，并包含了三项核心任务系列：鉴别诊断、病灶识别和推理生成。为了确保评估的可靠性，作者发展了一种结合了LLM打分机、临床医师验证和语义相似度指标的混合评分流水线。通过系统评估先进VLMs（包括GPT-4o、Claude-4、MedGemma）的表现，发现其在Neural-MedBench上的表现显著下降，错误分析表明推理失误远超过感知错误。研究结果强调了两种评价框架的必要性：广度导向的大数据集以实现统计泛化，以及深度导向、紧凑的基准测试（如Neural-MedBench）以评估推理准确度。
### Conclusion
本文通过Neural-MedBench提供了神经学临床推理的深入评估框架。Neural-MedBench作为一个开放且可扩展的诊断测试平台，将指导未来基准测试的扩展，并支持严格的且成本效益高的对临床可信赖AI的评估。
## 204. `cs.AI` - 公平与可解释性的桥梁：基于输入的解释能否促进仇恨言论检测中的公平性？ [PDF](https://arxiv.org/pdf/2509.22291), [HTML](https://arxiv.org/abs/2509.22291)
### Authors
Yifan Wang,Mayank Jobanputra,Ji-Ung Lee,Soyoung Oh,Isabel Valera,Vera Demberg
### Background
自然语言处理（NLP）模型常常从训练数据中复制或放大社会偏见，这引发了关于公平性的担忧。同时，这些模型的黑箱特性使得用户难以识别偏态预测，也使得开发者难以有效地缓解这一问题。虽然有些研究认为基于输入的解释可以检测并缓解偏见，但其他研究则质疑其在保障公平性方面的可靠性。现有的关于公平NLP的可解释性研究主要是定性的，缺乏大规模的定量分析。这项工作第一次系统地研究了可解释性和公平性在仇恨言论检测中的关系，重点关注编码器和解码器单一模型。
### Innovation
本研究首次系统地探讨了可解释性和公平性之间的关系，并关注编码器和解码器单一模型的应用。研究发现基于输入的解释能够有效检测偏态预测，并作为训练期间减少偏见的有效监督，但它对于在候选模型中选择公平模型的可靠性不足。
### Conclusion
基于输入的解释可以在一定程度上帮助检测并防止偏见，但在选择公平模型时的可靠性较差。这意味着虽然基于输入的解释在降低训练过程中偏见的出现方面是有帮助的，但还需要进一步的方法或标准来评估模型的公平性。
## 205. `cs.AI` - 通过上下文空间实现计算机使用代理的可靠和高效访问控制 [PDF](https://arxiv.org/pdf/2509.22256), [HTML](https://arxiv.org/abs/2509.22256)
### Authors
Haochen Gong,Chenxiao Li,Rui Chang,Wenbo Shen
### Background
基于大型语言模型（LLM）的计算机使用代理代表了AI与操作系统（OS）功能的融合，使得自然语言可以控制系统和应用程序级别的功能。然而，由于LLM固有的不确定性问题，赋予代理计算机控制权存在重大的安全风险。当代理行动偏离用户意图时，可能会导致不可逆的后果。现有的缓解方法，如用户确认和基于LLM的动态操作验证，仍然在易用性、安全性和性能方面存在局限性。
### Innovation
为了解决这些挑战，本文提出CSAgent，一个系统级别的静态策略访问控制框架，用于计算机使用代理。为了弥合静态策略与动态上下文和用户意图之间的差距，CSAgent引入了意图和上下文感知的策略，并提供了一个自动化工具链，以帮助开发人员构造和优化这些策略。CSAgent通过优化的OS服务确保代理操作只能在特定用户意图和上下文中执行。CSAgent支持保护通过API、CLI和GUI等多种接口控制计算机的代理。
### Conclusion
我们实现了并评估了CSAgent，结果显示它成功防御了超过99.36%的攻击，同时只引入6.83%的性能开销。
## 206. `cs.AI` - FeatBench: 评估编码代理在特性实施方面的vibe编码能力 [PDF](https://arxiv.org/pdf/2509.22237), [HTML](https://arxiv.org/abs/2509.22237)
### Authors
Haorui Chen,Chengze Li,Jia Li
### Background
大型语言模型（LLMs）的迅速发展催生了一种新型软件开发范式——vibe coding（意译为‘气氛编码’），在这种范式中，用户通过高级自然语言与编码代理交互。然而，现有的代码生成评估基准并未充分评估代理的vibe coding能力，主要是因为现有基准要么需要代码级规范，要么仅专注于问题解决，而忽视了特性实现这一关键场景。
### Innovation
本文提出了一个名为FeatBench的新颖基准，专注于特性实现。该基准的特点包括：1. 纯自然语言提示；2. 严格的且不断演化的数据收集过程；3. 详尽的测试案例；4. 多样化的应用领域。此外，通过评估两个最先进的代理框架和四个领先的LLM，结果显示，在vibe coding范式下的特性实现是一个重大挑战，成功率最高也只有29.94%。我们还发现在特性实现过程中存在一种‘激进实现’的策略，这既会导致关键失败，也可能促进高质量软件设计。
### Conclusion
我们的研究表明，在vibe coding范式下的特性实现是一个显著的挑战，代理在这一领域的成功率不够高。同时，我们揭示了‘激进实现’策略的双重影响。为了进一步推动社区研究，我们已发布FeatBench、自动化收集管道及所有实验结果。
## 207. `cs.AI` - 超越文本上下文：自适应空间对齐的结构图编码以缓解LLMs的幻觉问题 [PDF](https://arxiv.org/pdf/2509.22251), [HTML](https://arxiv.org/abs/2509.22251)
### Authors
Yifang Zhang,Pengfei Duan,Yiwen Yang,Shengwu Xiong
### Background
目前，大型语言模型（LLMs）处理幻觉问题的主要方法是引入知识图（KGs）。然而，LLMs通常将KGs视为纯文本，仅提取语义信息而忽略了其关键的结构特性，导致KGs的潜在优势没有得到充分利用。此外，KGs编码器的嵌入空间与LLMs文本嵌入之间的差距也阻碍了结构化知识的有效整合。这些挑战限制了LLMs的性能，特别是在事实推理能力上。
### Innovation
我们提出了SSKG-LLM，一种创新模型架构，旨在高效地将KGs的结构和语义信息整合到LLMs的推理过程中。SSKG-LLM集成了知识图检索（KGR）模块和知识图编码（KGE）模块，保持语义信息的同时利用结构。此外，我们引入了知识图适应（KGA）模块，使LLMs能够理解KGs的嵌入。该工作通过广泛实验和详细分析，探索了整合KGs的结构信息如何增强LLMs的事实推理能力。
### Conclusion
我们的研究结果表明，结合KGs的结构信息可以显著提升LLMs的事实推理能力。我们为该研究提供了一套详细的数据和代码以供进一步验证和扩展。
## 208. `cs.AI` - 安全合规：通过合规视角重新思考大语言模型的安全推理 [PDF](https://arxiv.org/pdf/2509.22250), [HTML](https://arxiv.org/abs/2509.22250)
### Authors
Wenbin Hu,Huihao Jing,Haochen Shi,Haoran Li,Yangqiu Song
### Background
随着大语言模型（LLMs）的广泛使用，展示了其显著的能力，使得LLM的安全性变得尤为重要。然而，现有的安全方法依赖于随意的分类系统，缺乏严格的、系统化的保护措施，无法确保现代LLM系统的复杂和微妙行为的安全性。因此，本文从法律合规的角度出发，解决LLM安全问题，名为安全合规。本文通过采用欧盟AI法和GDPR等法律框架作为安全标准，来定义和衡量安全合规性，填补了LLM安全性和法律合规性之间的差距。通过生成基于法律条文的真实的LLM安全场景，开发了一个新的安全合规基准。
### Innovation
本文创新性地从法律合规的视角重新思考大语言模型的安全性问题，利用欧盟AI法和GDPR等法律框架作为安全标准，开发了第一个以法律一致性为依据的新型安全合规基准；并使用群组策略优化（GRPO）方法对Qwen3-8B进行调整，创建了一个能够有效使大语言模型与法律标准对齐的安全原因者——合规原因者，以此来降低安全风险；实验结果表明，该安全原因者在新的基准上表现优异，比现有方法有显著改进。
### Conclusion
本文通过建立新的安全合规基准，并利用法律一致性框架对大语言模型进行调整，验证了安全合规方法的有效性，极大地提升了LLM系统的安全性。在未来的研究中，该方法可以进一步应用于更多的安全场景，提高大语言模型在实际应用中的安全性。
## 209. `cs.AI` - 公平意识强化学习（FAReL）：一种透明且平衡的序列决策框架 [PDF](https://arxiv.org/pdf/2509.22232), [HTML](https://arxiv.org/abs/2509.22232)
### Authors
Alexandra Cimpean,Nicole Orzan,Catholijn Jonker,Pieter Libin,Ann Nowé
### Background
在现实世界的序列决策问题中，公平性可以通过公平意识的方法来实现。但是，要平衡性能和所需的公平性观念之间，需要算法能够做出合适的透明权衡。由于事先难以明确指定性能和公平性的权衡，因此需要一个框架能够探索多种权衡方案。通过强化学习算法关于可获得的性能-公平性权衡的见解，利益相关者可以指导选择最合适的政策。为了捕获公平性，作者提出了一个扩展的马尔可夫决策过程，即$f$MDP，并明确地将其与个人和群体联系起来。基于这个$f$MDP，作者在序列决策问题中定义了公平性的概念，并制定了一个公平框架来随着时间计算公平性指标。我们在这两个具有不同公平要求的情景中评估了我们的框架：雇佣，其中需要组成强大的团队同时对待求职者公平；欺诈检测，其中要检测欺诈性交易并确保对客户的负担公平分配。结果表明，我们的框架可以学习具有更好公平性指标的策略，但性能奖励损失较小。此外，我们发现群体和个体的公平性理念并不一定相互关联，这强调了在两种公平类型都希望实现的情景中应用框架的好处。最后，作者提供了如何在不同问题设置中应用该框架的指南。
### Innovation
提出了一个扩展的马尔可夫决策过程（$f$MDP），用于定义和实现公平性的概念；制定了一个公平框架来计算随时间的变化来衡量公平性；在就业招聘和欺诈检测的两个不同场景中应用了这一框架；显示出在保持性能奖励的同时提高了公平性；揭示了群体和个体公平性之间不一定存在直接关系，强调了框架在需要两者的情况下的应用价值。
### Conclusion
我们的框架能够通过增强学习算法探讨性能与公平性之间的权衡，并在不同场景中学习具有更好公平性的策略，同时部分损失性能奖赏。此外，关于群体和个体公平性之间的区别，说明了设置中同时实现两种公平性的必要性。我们为在不同问题背景下应用这一框架提供了指导。
## 210. `cs.AI` - 能源领域的全球网络安全威胁分析：从地缘政治视角看‘冲突的潮流’ [PDF](https://arxiv.org/pdf/2509.22280), [HTML](https://arxiv.org/abs/2509.22280)
### Authors
Gustavo Sánchez,Ghada Elbez,Veit Hagenmeyer
### Background
随着网络威胁频率和复杂性的增加，对其全面理解变得至关重要。本研究探讨了地缘政治动态、网络威胁情报分析和高级检测技术之间的交集，特别是在能源领域。通过利用生成型人工智能从原始网络威胁描述中提取和结构化信息，可提升分析能力。研究还纵向对比了来自多个数据库的威胁行为者来源和目标地区，提供了威胁环境总体趋势的洞察。另外，研究评估了基于学习技术的网络安全工具在检测针对能源攻击的指标方面的有效性，以助力研究人员、政策制定者和网络安全专业人士获取有益信息。
### Innovation
本研究通过应用生成型人工智能技术，从原始网络威胁描述中提取和结构化信息，增强了威胁分析的能力。此外，通过对来自多个数据库的数据进行对比，提供了威胁环境总体趋势的见解，以及对基于学习的网络安全工具在检测针对能源攻击的指标方面的评估，为网络安全领域的研究和实践提供了新颖的视角和实用信息。
### Conclusion
通过本分析，研究人员、政策制定者和网络安全专业人员能够获得新的见解，从而制定更加有效的策略和措施来应对能源领域的网络威胁。
## 211. `cs.AI` - 利用大型语言模型进行语言脆弱性学龄前儿童形态结构辅助学习 [PDF](https://arxiv.org/pdf/2509.22287), [HTML](https://arxiv.org/abs/2509.22287)
### Authors
Stina Sundstedt,Mattias Wingren,Susanne Hägglund,Daniel Ventus
### Background
学龄前儿童因语言发展障碍或移民相关语言挑战而存在语言漏洞，通常需要增强其口头表达能力。言语语言治疗师（SLTs）通常将目标形态学结构融入日常交流或基于游戏的学习活动中，这一过程要求精准的语言知识和实时生成各种形态学形式的能力。此外，教育工作者或家长还需保持儿童参与并管理回合制游戏的互动过程。研究团队开发了一个应用程序，其中Furhat对话机器人参与“别名”词汇检索游戏以提高语言技能。当前应用主要依赖大型语言模型（LLM）来管理游戏、对话、情感反应和轮流权移交。
### Innovation
研究团队将L大型语言模型（LLM）集成到机器人辅助语言学习系统中，旨在让机器人在游戏过程中生成和提供特定的形态学目标。该方法的独特之处在于机器人最终可以作为儿童和专业人士的语言模型和导师，利用LLM的能力支持语言脆弱性儿童的基本沟通需求。进一步的探索将利用LLM的能力更自主地生成特定的形态学目标，提高训练成效。
### Conclusion
研究的长期目标是创建一个基于LLM的机器人辅助语言学习干预，能够教授多种形态学结构，并适用于不同语言的儿童。
## 212. `cs.AI` - 通过分层跨模态超图学习进行行人属性识别 [PDF](https://arxiv.org/pdf/2509.22331), [HTML](https://arxiv.org/abs/2509.22331)
### Authors
Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo
### Background
当前的行人属性识别（PAR）算法通常关注如何将视觉特征映射到语义标签，或者通过视觉信息和属性信息的融合来提升学习过程。然而，这些方法在充分利用属性知识和上下文信息以进行更准确的识别方面存在局限。最近的研究已经开始考虑利用属性文本作为额外输入以增强视觉与语义信息之间的关联，尽管这些方法还处于起步阶段。
### Innovation
本文提出了一种多模态知识图谱构建方法，以挖掘局部视觉特征与文本之间的关系，以及属性与广泛视觉上下文样本之间的关系。通过引入知识图谱引导的跨模态超图学习框架，本文提升了一般行人属性识别框架的效果。
### Conclusion
全面的实验表明，我们提出的知识图谱在行人属性识别任务中非常有效，为知识引导的行人属性识别奠定了坚实基础。代码将在这个链接上发布：this https URL
## 213. `cs.AI` - 自动发现$SO(n)$的一参数子群 [PDF](https://arxiv.org/pdf/2509.22219), [HTML](https://arxiv.org/abs/2509.22219)
### Authors
Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P
### Background
一参数子群在机器人学、量子力学和分子结构分析等多个领域具有广泛的应用。这些领域要求对特定变换下的不变函数进行标准化表示，并发现隐含的一参数子群结构。
### Innovation
该论文提出了一种新的框架，用于自动发现$SO(3)$及更广泛的$SO(n)$的一参数子群$H_{boldsymbol{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{γ}}}}}bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{}}}}}}}}}}}}}}}}}}}}}}}$，该框架通过利用标准雅可比形式的反对称矩阵来建立$SO(n)$的李代数在$H_{boldsymbol{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{γ}}}}}bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{bm{}}}}}}}}}}}}}}}}}}}}}}}}$作用下的轨道的规范形式，并通过学习适当的参数来揭示隐含的一参数子群结构。
### Conclusion
该方法在双摆建模、动量矩预测、顶夸克标记和不变多项式回归等任务中表现良好，能够成功恢复有意义的子群结构，并生成可解释、对称感知的表示形式。
## 214. `cs.AI` - 通过场景分割策略对文本到视频模型进行 Jailbreaking [PDF](https://arxiv.org/pdf/2509.22292), [HTML](https://arxiv.org/abs/2509.22292)
### Authors
Wonjun Lee,Haon Park,Doehyeon Lee,Bumsub Ham,Suhyun Kim
### Background
随着许多文本到视频（T2V）模型的迅速发展，人们对它们的安全风险越来越担忧。尽管最近的研究已经探索了像大型语言模型（LLMs）、视觉语言模型（VLMs）和文本到图像（T2I）模型等模型的安全漏洞，但T2V模型的安全性仍存在大量未被探索的空间，留下了显著的安全漏洞。为解决这一问题，本文提出了一种名为SceneSplit的新颖黑盒劫持方法，该方法将有害叙述分解为多个场景，每个场景本身都是无害的，通过这种方式操纵生成输出空间，将场景组合作为一种强有力的约束条件来引导最终结果。
### Innovation
SceneSplit通过将有害叙述分解为多个个体无害的场景，引导T2V模型生成有害内容。这一机制通过迭代场景操纵进一步增强，绕过了安全滤镜。此外，通过重用成功的攻击模式策略库提高了攻击的整体效果和鲁棒性。实验结果表明，SceneSplit在Luma Ray2、Hailuo和Veo2等模型上的平均攻击成功率为77.2%、84.1%和78.2%，显著优于现有基线。
### Conclusion
本文展示了当前T2V安全机制对利用叙述结构的攻击是脆弱的，提供了一种新的理解并改进T2V模型安全性的视角。
## 215. `cs.AI` - SurvDiff：生存分析中生成合成数据的扩散模型 [PDF](https://arxiv.org/pdf/2509.22352), [HTML](https://arxiv.org/abs/2509.22352)
### Authors
Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel
### Background
生存分析是临床研究中的基石，用于建模如转移、疾病复发或患者死亡等时间事件结果。与标准表格数据不同，生存数据通常由于随访中断或失访而带有不完整的事件信息，这对合成数据的生成提出了独特挑战。在生成合成数据时，准确再现事件时间分布和缺失机制对于临床研究至关重要。
### Innovation
本文提出了SurvDiff，一个专门为生存分析生成合成数据而设计的端到端扩散模型。SurvDiff通过联合生成混合型协变量、事件时间和右截尾现象，并使用特定于生存分析的损失函数指导生成过程，从而捕捉数据生成机制。该损失函数编码时间事件结构并直接优化下游生存任务的性能，确保SurvDiff（1）能够生成真实的时间事件分布（2）保留缺失机制。
### Conclusion
在多个数据集上的实验表明，SurvDiff在分布保真度和下游评估指标方面均显著优于现有的生成基准模型。据我们所知，SurvDiff是第一个专门为生成合成生存数据设计的扩散模型。
## 216. `cs.AI` - 基于共享网络的自适应策略主干 [PDF](https://arxiv.org/pdf/2509.22310), [HTML](https://arxiv.org/abs/2509.22310)
### Authors
Bumgeun Park,Donghwan Lee
### Background
强化学习（RL）在各个领域取得了显著成果，但要找到最优策略通常需要大量的交互数据，这限制了其实用部署。一个常见的解决办法是利用先验知识，例如预先收集的数据集或参考策略，但这些先验知识在训练和部署任务不匹配时效果会下降。尽管已有工作的努力，但这主要局限于分布内环境，未充分解决跨分布任务的挑战.
### Innovation
我们提出了自适应策略主干（APB），这是一种元转移RL方法，通过在共享主干前后插入轻量级线性层，实现参数高效微调（PEFT）并保持适配过程中的先验知识。与标准RL相比，APB能够提高样本效率，并能够适应现有的元RL基准方法通常无法处理的跨分布任务.
### Conclusion
APB在样本效率方面优于标准RL，并且能够很好地适应超过分布（OOD）的任务，这表明APB在处理任务不匹配方面具有显著优势.
## 217. `cs.AI` - 随机激活 [PDF](https://arxiv.org/pdf/2509.22358), [HTML](https://arxiv.org/abs/2509.22358)
### Authors
Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou
### Background
当前在大规模语言模型中，常用的非线性函数如RELU存在优化问题，即对于负值输入，RELU保持恒定形状，这会阻止梯度流动。本文提出了一种新的随机激活策略，通过在前馈层随机选择SILU或RELU，旨在解决这些问题，并在模型预训练和微调过程中引入随机激活。
### Innovation
该策略特别通过伯努利抽样在前馈层之间随机选择SILU或RELU。这种方法在两种方式下发挥作用：(1) 在预训练过程中使用随机激活，在微调过程中使用RELU，减少推理时的FLOPs并显著提高CPU速度。(2) 随机激活策略也能用于生成任务，其表现合理：仅略逊于SILU结合温度缩放的最佳确定性非线性，并提供了一种控制生成文本多样性的可控方法。
### Conclusion
该随机激活策略在预训练和生成任务中均可应用，显示了比从零开始训练使用RELU激活函数更好的效果，同时提供了增加生成文本多样性的可控手段，减少了推理时的计算量，进而实现了显著的加速效果。
## 218. `cs.AI` - Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning [PDF](https://arxiv.org/pdf/2509.22335), [HTML](https://arxiv.org/abs/2509.22335)
### Authors
Naicheng He,Kaicheng Guo,Arjun Prakash,Saket Tiwari,Ruo Yu Tao,Tyrone Serapio,Amy Greenwald,George Konidaris
### Background
论文研究了深度神经网络在深度持续学习中遭受可塑性丧失（loss of plasticity）的现象，即网络在不重新初始化参数的情况下无法学习新任务。已知这种问题的发生之前通常伴随着谱塌缩（spectrum collapse），即有意义的曲率方向消失，使得梯度下降变得无效。研究者旨在探讨导致这一问题的原因及其解决方法，从而使得网络能够在不重新初始化参数的情况下继续学习新任务。
### Innovation
研究引入了一个新的概念——τ-可训练性（$tau$-trainability），并证明了当前保持可塑性的算法可以在这个框架下进行统一。此外，研究直接针对谱塌缩问题，提出了Hessian的Kronecker因子近似方法，并基于此提出了两种正则化增强：保持高有效特征秩和应用L2正则化。实验结果显示，结合这两大正则化方法有效地保持了网络的可塑性。
### Conclusion
通过直接解决谱塌缩问题，研究提供了保持持续学习过程中网络可塑性的方法，证实了综合应用维护有效特征秩和L2正则化能够有效挽救网络的可塑性。
## 219. `cs.AI` - HiGS: 历史导向采样方法对扩散模型即插即用增强的提升 [PDF](https://arxiv.org/pdf/2509.22300), [HTML](https://arxiv.org/abs/2509.22300)
### Authors
Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
### Background
尽管扩散模型在图像生成方面取得了显著进展，但它们的输出仍然可能显得不真实且缺乏精致细节，尤其是在使用较少的神经函数评估次数（NFEs）或更低的指导尺度时。
### Innovation
本文提出了一种基于动量的新型采样技术，称为历史导向采样（HiGS），该技术通过将最新的模型预测集成到每个推理步骤中，提高了扩散采样的质量和效率。HiGS 利用当前预测与过去预测加权平均的差异来引导采样过程，生成更加真实且细节丰富和结构良好的图像输出，同时不增加额外计算且能够无缝集成到现有的扩散框架中，无需额外训练或微调。
### Conclusion
广泛的实验表明，HiGS 能够在不同模型和架构下、不同采样预算和指导尺度下持续提高图像质量。使用预训练的 SiT 模型，HiGS 在 256x256 的无指导 ImageNet 生成中仅需 30 次采样步骤即可达到新的 FID 最佳水平 1.61（对比标准的 250 步）。因此，HiGS 提供了一个即插即用的增强工具，能够在保持较高保真度的同时加快生成速度。
## 220. `cs.AI` - 渐进权重加载：在资源受限环境中加速初始推理并逐步提升性能 [PDF](https://arxiv.org/pdf/2509.22319), [HTML](https://arxiv.org/abs/2509.22319)
### Authors
Hyunwoo Kim,Junha Lee,Mincheol Choi,Jeonghwan Lee,Jaeshin Cho
### Background
随着深度学习模型变得越来越大和复杂，它们的内存消耗和计算需求增加，导致模型加载时间和初始推理延迟增加，这对需要频繁加载和卸载模型的移动和延迟敏感环境构成了重大挑战，直接影响用户体验。知识蒸馏（KD）提供了一种解决方案，通过将大型教师模型压缩为较小的学生模型来压缩模型大小，但这也往往以牺牲性能为代价。
### Innovation
我们提出了渐进权重加载（PWL），这是一种新颖的技术，通过首先部署一个轻量级的学生模型，然后逐步用预训练的教师模型的层替换学生模型的层，实现了快速的初始推理。为了支持无缝层替换，我们介绍了一种训练方法，不仅能对齐学生和教师层的中间特征表示，还能提高学生模型的整体输出性能。我们的实验表明，使用PWL训练的模型保持了竞争力的蒸馏性能，并且随着教师层的加载，准确率逐渐提高，最终达到与完整教师模型相同的效果，而不会牺牲初始推理速度。
### Conclusion
PWL特别适合动态、资源受限的部署，其中响应性和性能都至关重要，可保留较高准确率的同时保持初始推理速度。
## 221. `cs.AI` - CHRONOBERG：捕捉基础模型中的语言演变和时间意识 [PDF](https://arxiv.org/pdf/2509.22360), [HTML](https://arxiv.org/abs/2509.22360)
### Authors
Niharika Hegde,Subarnaduti Paul,Lars Joel-Frey,Manuel Brack,Kristian Kersting,Martin Mundt,Patrick Schramowski
### Background
现有的语料库虽然多样化，但往往缺乏长期的时间结构，这限制了大规模语言模型（LLMs）理解语言语义和规范随时间的变化能力。为了支持对这种变化的分析和训练，本文介绍了CHRONOBERG语料库，这是一个包含250年英文书籍文本的时间结构化语料库，来源于Project Gutenberg并附有多种时间标注。
### Innovation
CHRONOBERG语料库提供了语言随时间演变的数据，通过分析词汇语义随时间的变化，并构建历史校准的情感词汇表，支持基于时间的解释。此外，通过将语言模型按时间顺序训练在CHRONOBERG上，表明需要更加时间意识的训练和评估管道来捕捉语言意义的变化。
### Conclusion
CHRONOBERG为进一步研究语言变化和时间泛化提供了可扩展的资源，强调了时间意识的重要性，展示了CHRONOBERG对于分析和训练大规模语言模型的潜在价值。
## 222. `cs.AI` - HEAPr: 基于海森矩阵的高效原子专家剪枝（在输出空间） [PDF](https://arxiv.org/pdf/2509.22299), [HTML](https://arxiv.org/abs/2509.22299)
### Authors
Ke Li,Zheng Yang,Zhongbin Zhou,Feng Xue,Zhonglin Jiang,Wenxiao Wang
### Background
在大型语言模型（LLMs）中，Mixture-of-Experts（MoE）架构相较于密集型LLMs在性能上表现出色，且具有更低的推理成本。然而，MoE模型较大的参数量导致了内存需求过高，从而限制了其实际部署。尽管现有的剪枝方法主要集中在专家级别的剪枝，但这种方法通常会导致模型的精度大幅下降。为了解决这个问题，作者提出了一种名为HEAPr的新剪枝算法，该算法能够将专家分解为更小的不可分割的原子专家，从而实现更加精确和灵活的原子专家剪枝。HEAPr通过利用类似Optimal Brain Surgeon（OBS）理论的二阶信息来衡量每个原子专家的重要性。为了解决计算和存储上的挑战，该算法通过利用原子专家的固有属性将二阶信息从专家参数转换为原子专家参数的二阶信息，并进一步简化为原子专家输出的二阶信息，从而将空间复杂度从$O(d^4)$降至$O(d^2)$。HEAPr仅需要两个前向传播和一个后向传播即可在一小部分校准集上计算出原子专家的重要性.
### Innovation
HEAPr提出了基于海森矩阵的高效原子专家剪枝算法，该算法能够在输出空间中通过二阶信息来衡量原子专家的重要性。通过将二阶信息进行转换和简化，HEAPr极大地降低了空间复杂度，并仅需少量的前向和后向传播即可完成剪枝任务。相比现有的专家级别的剪枝方法，HEAPr在广泛的压缩比率和基准测试中表现出更优的效果，尤其是能够在20%~25%的压缩比率下实现几乎无损的压缩效果，同时还能显著降低FLOPs的消耗（接近20%）.
### Conclusion
通过一系列广泛的实验测试，该研究证明了HEAPr的有效性和优越性。在MoE模型中，HEAPr在不同模型和压缩比率下的表现超越了现有方法，并能够在大多数模型中实现无损压缩，同时显著减少了计算量。相关代码已经公开可供访问。
## 223. `cs.AI` - LLMs在预训练和后训练数据中的政治内容是什么？ [PDF](https://arxiv.org/pdf/2509.22367), [HTML](https://arxiv.org/abs/2509.22367)
### Authors
Tanise Ceron,Dmitry Nikolaev,Dominik Stammbach,Debora Nozza
### Background
大型语言模型（LLMs）已知会产生政治偏见的文本，但这些偏见是如何产生的尚不清楚。目前，对训练数据中的政治内容的研究仍不足，尚未引起足够的关注。
### Innovation
本文通过对OLMO2预训练和后训练语料库进行分析，抽取大量随机样本并自动标注文档的政治倾向，研究训练数据中的政治内容如何与模型在特定政策问题上的立场相关联，并发现在预训练语料库中存在的政治内容显著多于后训练数据。
### Conclusion
研究结果显示，左倾文档在数据集中占主导地位，且预训练语料库包含更多政治参与内容。左翼和右翼文档虽然针对相似话题，但通过不同的价值观和合法性的来源进行讨论。训练数据中占主流的政治立场与模型在政策问题上的政治倾向高度相关。研究强调，未来在数据收集过程中应结合政治内容分析，并详细记录过滤策略以提高透明度。
## 224. `cs.AI` - 上下文和多样性 Matters: 世界模型中上下文学习的本质 [PDF](https://arxiv.org/pdf/2509.22353), [HTML](https://arxiv.org/abs/2509.22353)
### Authors
Fan Wang,Zhiyuan Chen,Yuxuan Zhong,Sunjian Zheng,Pengtao Shao,Bo Yu,Shaoshan Liu,Jianan Wang,Ning Ding,Yang Cao,Yu Kang
### Background
预测环境动态是生物神经系统和通用体现人工智能适应其环境的基础。然而，现有方法依赖于静态的世界模型，在面对新颖或稀有配置时表现不佳。本研究关注情境下的环境学习（ICEL），转而关注世界模型的逐步增长和渐近极限，而不是仅关注零样本性能。
### Innovation
研究贡献包括：（1）形式化世界模型的情境学习，并识别出两种核心机制：环境识别和环境学习；（2）推导出这两种机制的误差上界，展示了机制是如何形成的；（3）通过实验证明世界模型中确实存在不同的ICL机制，并进一步研究数据分布和模型架构如何影响ICL，与理论一致。文章展现了自适应世界模型的潜力，并突显了ICEL形成的关键因素，特别是长情境和多样化环境的必要性。
### Conclusion
这些发现表明自适应世界模型的潜力，并强调了ICEL形成的关键因素，特别是在长情境和多样化环境的重要性。
## 225. `cs.AI` - SpinGPT：一种正确玩扑克的大型语言模型方法 [PDF](https://arxiv.org/pdf/2509.22387), [HTML](https://arxiv.org/abs/2509.22387)
### Authors
Narada Maugin,Tristan Cazenave
### Background
反事实遗憾最小化（CFR）算法及其变种使得开发出能够击败顶尖人类玩家的单人对抗性扑克程序成为可能，并且在六人制比赛中也能与人类玩家竞争。然而，CFR的计算复杂度随着玩家人数的增加而呈指数级上升。在三人或多人游戏中，遵守纳什均衡不再保证无亏损的结果。这些局限性及其他因素极大地限制了CFR在最流行的比赛模式——锦标赛中的应用。
### Innovation
受到大型语言模型（LLM）在象棋和Diplomacy游戏中的近期成功激励，提出SpinGPT，这是第一个专为流行三人在线扑克形式Spin & Go设计的大型语言模型。SpinGPT经过两阶段训练：首先，在32万次高风险专家决策上进行监督微调；其次，在27万次解算器生成的游戏中进行强化学习训练。研究结果表明，SpinGPT在78%的决策中与解算器行为一致。使用简单的深层筹码启发式策略，在与Slumbot的头对头较量中，SpinGPT取得了13.4±12.9 BB/100（95%置信区间）的成绩。
### Conclusion
这些结果表明大型语言模型可能是处理多人不完全信息游戏，如扑克的新方法。
## 226. `cs.AI` - 利用微调的LLM推进自然语言向一阶逻辑的形式化 [PDF](https://arxiv.org/pdf/2509.22338), [HTML](https://arxiv.org/abs/2509.22338)
### Authors
Felix Vossel,Till Mossakowski,Björn Gehrke
### Background
自然语言到一阶逻辑（FOL）的自动化翻译对于知识表示和形式化方法至关重要，但该任务仍然具有挑战性。以往的研究使用了多种方法来应对这一挑战，但缺乏系统性的评估与比较。这篇文章旨在通过系统地评估微调后的大型语言模型（LLMs）来改进这一任务，比较了编解码器架构和解码器单体架构，并探讨了词汇扩展、谓词条件和多语言训练等一系列技术。利用MALLS和Willow数据集进行评估，并引入了精确匹配、逻辑等价和谓词对齐等多项评估指标。文献强调了谓词可用性对性能提升、T5模型优于更大规模的解码器单体模型、以及模型在未见过的逻辑论证上具有良好泛化能力等发现。
### Innovation
文章通过系统地评估微调后的大型语言模型在自然语言到一阶逻辑翻译任务中的表现，比较了不同的架构和训练策略。引入了多项评估指标，包括精确匹配、逻辑等价和谓词对齐等。发现谓词可用性对任务性能有显著提升，T5模型在更大规模的解码器单体模型中表现更好，而且模型在未见过的逻辑论证上也具有良好的泛化能力。这些发现对于进一步优化此类任务中的模型性能具有重要意义。
### Conclusion
通过使用MALLS和Willow数据集和提出的新评估指标，微调后的Flan-T5-XXL模型在谓词列表的准确度上达到了70%，并超过了GPT-4o和DeepSeek-R1-0528模型。文章还发现谓词可用性、T5模型的优越性以及模型对新逻辑论证的泛化能力是主要的发现。尽管结构化逻辑翻译是稳健的，但谓词提取仍是主要瓶颈。
## 227. `cs.AI` - Transformers Can Learn Connectivity in Some Graphs but Not Others [PDF](https://arxiv.org/pdf/2509.22343), [HTML](https://arxiv.org/abs/2509.22343)
### Authors
Amit Roy,Abulhair Saparov
### Background
transformers在大型语言模型（LLMs）响应的事实正确性方面发挥着关键作用，而推理能力对于确保这些响应的正确性至关重要。特别是在因果推理等场景中，推断传递关系的能力是必需的。现有研究表明，transformers可以从上下文示例中学到传递性推断，但它们在训练示例中的传递关系推断能力及其随模型规模变化的效应尚未被探索。
### Innovation
该研究通过生成不同大小的有向图来训练不同规模的transformer模型，并评估其在推断传递关系方面的性能。研究发现，transformers能够在某些网格状的有向图中学习连通性，尤其是在低维度网格图条件下。更高的网格维度会增加学习连通性的难度。此外，随着模型规模的增加，transformers在推断网格图连通性方面的泛化能力得到了提高。然而，如果图结构不是网格状且包含许多断开的组件，transformers在学习连通性上的表现较差，尤其是在组件数量较多时。
### Conclusion
transformers可以在某些类型的网格状有向图中学习连通性，但性能会受到图结构的影响。随着模型规模的增加，transformers在推断网格图连通性方面的泛化能力得到提高，但对非网格结构的图表现不佳。
## 228. `cs.AI` - 零努力生成图像到音乐：基于RAG的可解释视觉语言模型方法 [PDF](https://arxiv.org/pdf/2509.22378), [HTML](https://arxiv.org/abs/2509.22378)
### Authors
Zijian Zhao,Dian Jin,Zijing Zhou
### Background
近期，图像到音乐（I2M）生成引起了广泛关注，有望应用于游戏、广告和多模态艺术创作等领域。然而，由于I2M任务的模糊性和主观性，大多数端到端的方法缺乏可解释性，使得用户对生成结果感到困惑。即使基于情感映射的方法也存在争议，因为情绪仅是艺术的单一方面。另外，大多数基于学习的方法需要大量的计算资源和训练数据，限制了普通用户的使用。
### Innovation
本文提出了基于视觉语言模型（VLM）的第一种I2M框架，该框架具有高解释性和低计算成本。具体而言，本文使用ABC乐谱来跨模态连接文本和音乐，使VLM能够使用自然语言生成音乐。此外，本文采用多模态检索增强生成（RAG）和自我修正技术，使VLM能够在无需外部训练的情况下生成高质量的音乐。同时，利用生成的动机和VLM的注意力图提供文本和图像模态的解释。实验结果表明，本方法在音乐质量和音乐-图像一致性方面均优于其他方法，显示出良好的前景。
### Conclusion
本文方法在人类研究和机器评估中均表现出色，验证了其在I2M生成中的有效性和可靠性，为图像到音乐生成提供了一种新的解决方案，有助于提升用户体验和满意度。
## 229. `cs.AI` - 昨日气候中的未来预报：AI天气和气候模型中的温度偏差 [PDF](https://arxiv.org/pdf/2509.22359), [HTML](https://arxiv.org/abs/2509.22359)
### Authors
Jacob B. Landsberg,Elizabeth A. Barnes
### Background
AI基的气候和天气模型正迅速获得流行，能够提供与传统动力模型技能相当甚至更佳的快速预报。然而，这些模型在仅使用历史数据训练的情况下预测未来气候面临一个关键挑战。本文通过分析北半球冬季陆地温度偏差，研究了这一问题，评估了FourCastNet V2 Small、Pangu Weather 和 ACE2 模型的预测。
### Innovation
研究采用的方法在于利用训练集外的较近年份数据来评估模型的泛化能力，并通过对比不同模型在不同气候区域和温度范围的预估偏差，揭示了仅依靠历史数据训练的AI模型面临的挑战。
### Conclusion
研究发现，所有模型均表现出温度偏差，呈现出比实际预测期早15-20年的气候特征，部分地区甚至高达20-30年。FourCastNet 和 Pangu 的冷偏差主要集中在最高预测温度，暗示它们缺乏对现代极端高温事件的训练。相比之下，ACE2 的偏差较为平滑，但在气候变化最显著的地区、季节和温度分布中最大。这些发现凸显了仅依赖历史数据训练AI模型所面临的挑战，并强调了在将其应用于未来气候变化预测时需要考虑此类偏差的重要性。
## 230. `cs.AI` - RAU: 基于参考的视觉语言模型的解剖理解 [PDF](https://arxiv.org/pdf/2509.22404), [HTML](https://arxiv.org/abs/2509.22404)
### Authors
Yiwei Li,Yikang Liu,Jiaqi Guo,Lin Zhao,Zheyuan Zhang,Xiao Chen,Boris Mailhe,Ankush Mukherjee,Terrence Chen,Shanhui Sun
### Background
通过深度学习理解解剖结构对于自动报告生成、术中导航和医学影像中器官定位至关重要，但其进展受限于缺乏专家标注数据。现有方法通过参考标注图像来引导对未标注目标的解释，然而，尽管最近的视觉-语言模型在视觉推理方面表现出色，但在基于参考的理解和细粒度定位方面仍有限制。
### Innovation
引入了RAU框架，用于基于参考的解剖理解，通过视觉语言模型实现解剖区域的识别、空间推理和细粒度分割。证明了视觉语言模型能够通过参考图像和目标图像之间的相对空间推理学习识别解剖区域，并通过视觉问答和边界框预测验证了这一能力。RAU将视觉语言模型获取的空间线索与细粒度分割能力集成，实现小解剖结构（如血管段）的精确定位和像素级分割。在两个分布内和两个分布外数据集中，RAU的性能均优于基线方法，具有更强的泛化能力。
### Conclusion
到目前为止，RAU是首个探讨视觉语言模型在医学影像中基于参考进行解剖结构的识别、定位和分割的能力的研究。其优异的性能展示了基于视觉语言模型的方法在自动化医疗工作流程中的解剖理解潜力，特别是在处理分布外数据集的情况下。
## 231. `cs.AI` - 一种统一建模家庭服务机器人任务、动作、环境和能力的本体 [PDF](https://arxiv.org/pdf/2509.22434), [HTML](https://arxiv.org/abs/2509.22434)
### Authors
Margherita Martorana,Francesca Urgese,Ilaria Tiddi,Stefan Schlobach
### Background
随着个人服务机器人在家庭环境中越来越频繁地用于帮助老年人和需要支持的人，有效的操作不仅需要物理交互，还需要能够解析动态环境、理解任务并根据上下文选择合适的行为。这需要将硬件组件（如传感器、执行器）和能够推理任务、环境和机器人能力的软件系统相结合。ROS等框架提供了开源工具，帮助连接低级硬件与高级功能，但在实际部署中，这些解决方案通常紧密耦合于特定平台。结果，这些解决方案往往是孤立的且硬编码，限制了互操作性、可重用性和知识共享。
### Innovation
本文提出了OntoBOT，一种扩展现有本体的统一本体，用于任务、动作、环境和能力的建模，为任务执行提供了形式化的推理支持，并展示了其在四个实体代理（TIAGo、HSR、UR3和Stretch）上的适用性，证明了OntoBOT在服务机器人领域的上下文感知推理、任务导向执行和知识共享中的有效性。
### Conclusion
通过OntoBOT，本文实现了任务、动作、环境和能力的统一建模，支持形式化的任务执行推理，并展示了其在不同实体代理平台上的通用性，促进了服务机器人领域的知识共享和应用开发。
## 232. `cs.AI` - 部分参数更新以提高分布式训练效率 [PDF](https://arxiv.org/pdf/2509.22418), [HTML](https://arxiv.org/abs/2509.22418)
### Authors
Anastasiia Filippova,Angelos Katharopoulos,David Grangier,Ronan Collobert
### Background
现有的分布式训练方法通过在稀疏的全局同步之间进行多次局部更新来减少通信量，但其效率仍有提升的空间。特别是在内存和计算效率方面存在优化潜力。
### Innovation
提出了一种新的方法，通过限制反向传播，只更新部分参数而非全部参数，每个节点只更新固定的部分参数，其余保持冻结。这样可以大幅度降低峰值内存使用量和训练FLOPs，同时可以通过对所有参数进行全前向传播来消除跨节点激活交换。
### Conclusion
实验表明，该方法能够在相同的标记和带宽预算下与现有的低通信分布式训练方法达到相同的效果，同时进一步降低了训练FLOPs和峰值内存使用。
## 233. `cs.AI` - 基于深学习的适应性nnResU-Net与解剖特征优先损失在跨解剖CT合成中的应用 [PDF](https://arxiv.org/pdf/2509.22394), [HTML](https://arxiv.org/abs/2509.22394)
### Authors
Javier Sequeiro González,Arthur Longuefosse,Miguel Díaz Benito,Álvaro García Martín,Fabien Baldacci
### Background
该研究使用多中心的SynthRAD2025数据集，针对头部和颈部，胸部和腹部区域，实现了基于补丁的3D nnUNet适应性模型，用于MR到CT和CBCT到CT的图像转换。研究通过引入Anatomical Feature-Prioritized (AFP)损失，结合解剖结构先验信息，改善了临床相关结构的重建质量。输入数据进行了具体的归一化处理，模型在特定的解剖区域上进行训练，最终通过平均聚合并逆归一化获得了最终结果。研究表明，带有AFP损失的模型在骨结构重建和病变检测上表现优异，但在灰度度量上L1损失模型表现更好。
### Innovation
该研究的主要创新在于引入了Anatomical Feature-Prioritized (AFP)损失，这是一种基于紧凑分割网络的多层解剖特征比较，提高了临床相关结构的重建效果。研究还提出了一种基于多个3D补丁的跨区域解剖适应性模型，并通过选择合适的网络结构和损失函数，克服了跨模态图像转换的挑战。此外，该方法还集成了一种具体的归一化和后处理步骤，以提高重建图像的质量。
### Conclusion
该研究展示了一种稳定可靠的跨模态医学图像合成方法，通过结合自动nnUNet管道与残差学习和解剖导向特征损失，显著提升了重建图像的细节和解剖保真度，特别是在骨结构和CBCT到CT的病变检测中表现突出。
## 234. `cs.AI` - 学习邻域：无对比的多模态自监督分子图预训练 [PDF](https://arxiv.org/pdf/2509.22468), [HTML](https://arxiv.org/abs/2509.22468)
### Authors
Boshra Ariguib,Mathias Niepert,Andrei Manolache
### Background
高质量的分子表示对于性质预测和分子设计至关重要，但大规模标注数据集仍然稀缺。尽管在分子图上进行自监督预训练显示出前景，但许多现有方法依赖于手工构建的增强或复杂的生成目标，且通常仅依赖2D拓扑，而未充分利用有价值的3D结构信息。
### Innovation
本研究提出了C-FREE（无对比的基于 ego-nets 的表示学习），这是一种简单框架，将2D图与3D构象的集合相结合。C-FREE通过在潜在空间中预测子图嵌入及其互补邻域来学习分子表示，使用固定半径的ego-nets作为建模单元，跨不同构象进行建模。这种方法允许在混合的GNN-Transformer骨干网络中整合几何和拓扑信息，同时无需使用对比样本、位置编码或昂贵的预处理。
### Conclusion
在提供丰富3D构象多样性的GEOM数据集上进行预训练后，C-FREE在MoleculeNet上达到了最先进的结果，超过了对比性、生成性和其他多模态自监督方法。通过在具有不同规模和分子类型的多个数据集上进行微调，进一步证明了预训练能够有效转移到新的化学领域，突显了3D-启发式分子表示的重要性。
## 235. `cs.AI` - 通过内模令牌交互解释多模态LLM [PDF](https://arxiv.org/pdf/2509.22415), [HTML](https://arxiv.org/abs/2509.22415)
### Authors
Jiawei Liang,Ruoyu Chen,Xianghao Jiao,Siyuan Liang,Shiming Liu,Qunli Zhang,Zheng Hu,Xiaochun Cao
### Background
多模态大型语言模型（MLLMs）已经在各种视觉-语言任务中取得了显著成效，但其内部决策机制尚不完全理解。现有的可解释性研究主要集中在跨模态归因，即确定模型在生成输出时关注哪些图像区域，但这些方法往往忽略了内模态间的依赖关系。在视觉模态中，简单地赋予单个图像片段重要性忽略了空间上下文，因为其感受野有限，导致解释碎片化且噪音大。在文本模态中，依赖于前一个令牌引入了虚假激活。未能有效消除这些干扰影响了归因的准确性。为解决这些限制，本文通过利用内模态交互来增强可解释性。对于视觉分支，我们引入了多尺度解释聚合（MSEA），它通过聚合多尺度输入的归因来动态调整感受野，生成更为完整且空间上一致的视觉解释。对于文本分支，我们提出了激活排名相关性（ARC），它通过其前k个预测排名与当前令牌之间的对齐来衡量上下文令牌的相关性。ARC利用这种相关性抑制不相关上下文的虚假激活，同时保留语义上一致的影响。在广泛的状态下最先进的MLLMs和基准数据集上的实验表明，我们的方法在可解释性方面始终优于现有的方法，提供了更忠实和详细的模型行为解释。
### Innovation
提出了通过内模态交互增强可解释性的方法。对于视觉分支，设计了多尺度解释聚合（MSEA），通过聚合多尺度输入的解释来动态调整感受野，生成更加整体和空间连贯的视觉解释。对于文本分支，提出了激活排名相关性（ARC），通过测量上下文令牌与当前令牌的相关性来评估其重要性，从而抑制不相关的虚假激活并保留语义连贯的影响。这种方法在广泛的实验中表现优于现有方法，提供了更准确和精细的模型行为解释。
### Conclusion
本文通过利用内模态交互来提高多模态大型语言模型的可解释性，提出了多尺度解释聚合（MSEA）和激活排名相关性（ARC）两种方法。这两种方法在广泛实验中表现优越，提供了更准确和详细的模型行为解释。
## 236. `cs.AI` - 基于激活函数影响的神经ODE全局收敛性研究 [PDF](https://arxiv.org/pdf/2509.22436), [HTML](https://arxiv.org/abs/2509.22436)
### Authors
Tianxiang Gao,Siyuan Sun,Hailiang Liu,Hongyang Gao
### Background
神经常微分方程（ODEs）因其连续性和参数共享效率，在多种应用中取得成功。然而，连续性和参数共享的优点也带来了挑战，特别是在梯度计算准确性和收敛性分析方面。本文旨在解决这些问题，通过研究激活函数的影响，揭示其对神经网络动态训练的影响。研究表明，激活函数的光滑性和非线性对神经网络动态训练至关重要。光滑激活函数可以确保前向和逆向ODEs的全局唯一解，而足够的非线性则能够保持梯度下降训练中的神经自洽核（NTK）的谱性质。这些特性共同使神经ODE在过度参数化情况下通过梯度下降实现全局收敛。
### Innovation
本文通过探究激活函数的性质，尤其是其光滑性和非线性，提出了这些特性对于神经网络训练动态的重要性。作者证明了光滑激活函数可以确保前向和逆向ODEs的全局唯一解，足够的非线性则能保持神经自洽核（NTK）的谱性质。并且通过理论分析和数值实验验证了这些结论，为神经ODE的扩张应用提供了实用指南，有望加速训练并提升实际应用中的性能。
### Conclusion
本文通过理论分析和数值实验验证了激活函数特性（光滑性和非线性）对于神经ODEs全局收敛的影响，表明这些特性能确保神经ODEs在过度参数化情况下的全局收敛性。研究结果不仅支持了所提理论，还为改善神经ODEs的实际应用提供了实用指导。
## 237. `cs.AI` -  Chimera: 在视觉-语言理解中诊断捷径学习 [PDF](https://arxiv.org/pdf/2509.22437), [HTML](https://arxiv.org/abs/2509.22437)
### Authors
Ziheng Chi,Yifan Hou,Chenxi Pang,Shaobo Cui,Mubashara Akhtar,Mrinmaya Sachan
### Background
图表通过视觉格式而不是线性文本来传达象征性信息，这对AI模型来说具有极大的挑战性。尽管现有研究表明视觉-语言模型（VLMs）在图表相关的基准测试上表现良好，但它们依赖于知识、推理或模态捷径的方式引发了是否真正理解和推理图表的疑问。为解决这一问题，作者们创建了Chimera，一个包含7500个高质量且来自维基百科图表的综合测试套件，每个图表都附有语义三元组注释和多个层次问题，用于评估图表理解的四个基本方面：实体识别、关系理解、知识链接和视觉推理。
### Innovation
Chimera是一个崭新的测试套件，包含7500个高质量的图表，从维基百科获取这些图表，并附有语义三元组注释和多层次问题，旨在评估四个基本方面：实体识别、关系理解、知识链接和视觉推理。此外，作者使用Chimera测度视觉问答中的三种捷径行为，包括视觉记忆捷径、知识回忆捷径和Clever-Hans捷径。结果显示，这些模式下的VLMs似乎强大的性能实际上都来自于捷径行为，而真正理解图表的能力较弱。
### Conclusion
研究揭示了当前VLM的关键局限性，强调了需要更严格的评估标准来检测复杂视觉输入（如图表）的真正理解能力，而不是仅仅依赖于问答捷径。
## 238. `cs.AI` - 学习传球：为长周期篮球动作组合策略 [PDF](https://arxiv.org/pdf/2509.22442), [HTML](https://arxiv.org/abs/2509.22442)
### Authors
Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu
### Background
长周期任务（如篮球行动）的学习对于强化学习方法来说仍然具有挑战性，因为需要无缝政策组合和不同技能之间的过渡。长周期任务通常包含有明确目标的不同子任务，以及有不清楚目标但对整个任务成功至关重要的过渡子任务。现有的方法如专家混合和技能链在处理个体策略之间缺乏共同探索的状态或缺乏明确的初始和终端状态的任务时遇到困难。
### Innovation
本文引入了一种新的策略集成框架，以在具有模糊中间状态的多阶段长周期任务中实现大相径庭的运动技能的组合。在此基础上，进一步引入了一个高级软路由器，以实现子任务之间的无缝和稳健过渡。该框架在一系列基本篮球技能和具有挑战性的过渡上下文中进行了评估。通过这种方法训练的策略可以使模拟人物有效控制与球交互并完成根据实时用户命令指定的长周期任务，而无需依赖球轨迹参考。
### Conclusion
我们的方法可以学习控制模拟角色与球交互并执行由实时用户命令指定的长周期任务，而无需依赖球轨迹参考，展示了在长周期任务中复杂技能组合的有效性和鲁棒性。
## 239. `cs.AI` - Kolmogorov复杂性和深度学习之间的桥梁: 对Transformer的最优描述长度目标 [PDF](https://arxiv.org/pdf/2509.22445), [HTML](https://arxiv.org/abs/2509.22445)
### Authors
Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova
### Background
最小描述长度（MDL）原理提供了一种应用于机器学习的正式框架，用于应用奥卡姆剃刀原理。然而，将其应用于神经网络，如Transformer，具有挑战性，因为缺乏一种适用于模型复杂性的原则上普遍的方法。因此，本文旨在解决这一问题，通过建立理论上的最优描述长度目标，这些目标基于Kolmogorov复杂性的理论，从而能够实现任何数据集的最优压缩，当模型资源限制增加时，达到理论上的最优值。同时，证明了这种最优目标在Transformer中存在，基于对它们计算通用性的一种新证明。
### Innovation
介绍了理论上的最优描述长度目标，这些目标基于Kolmogorov复杂性的理论，证明了这种最优目标在Transformer中存在，基于对它们计算通用性的一种新证明，提出了一种基于可变高斯混合先验的变分目标，使其可实现和可微分，实证分析显示，该变分目标能选择低复杂度的解决方案，具有较强的算法任务泛化性能。
### Conclusion
通过提供一个理论框架，用于识别具有强大渐进保证的描述长度目标，为训练能够实现更大压缩和泛化的神经网络指明了潜在路径。
## 240. `cs.AI` - 基于本体对比解释性叙述的机器人计划理论基础 [PDF](https://arxiv.org/pdf/2509.22493), [HTML](https://arxiv.org/abs/2509.22493)
### Authors
Alberto Olivares-Alarcos,Sergi Foix,Júlia Borràs,Gerard Canal,Guillem Alenyà
### Background
人类与机器人交互的信任和成功关键在于对机器人决策的理解。因此，机器人需要在必要时做出合理的决策并进行沟通。本文专注于一种方法，以建模和推理两个 competing plans 之间的比较，使得机器人可以解释结果的差异。首先，提出了一种新的本体模型，以形式化和推理竞争计划之间的差异，从而使计划的优先级分类成为可能。此外，研究了基于本体解释叙述的基本算法的限制，并提出了一个新颖的方法，利用计划之间的差异知识，促进对比性叙述的构建。
### Innovation
本文创新地提出了一个新的本体模型来形式化和推理竞争计划之间的差异，并基于这种新的模型发展了一种新的算法，能够更好地解释机器人计划中的差异，超越了基本算法的表现。
### Conclusion
通过实证评估显示，本文提出的解释方法大大超越了基本方法的表现。这种方法不仅有助于增强人类对机器人行为的理解，还能提高机器人交互的可信度和有效性。
## 241. `cs.AI` - MDAR：多场景动态音频推理基准 [PDF](https://arxiv.org/pdf/2509.22461), [HTML](https://arxiv.org/abs/2509.22461)
### Authors
Hui Li,Changhao Jiang,Hongyu Wang,Ming Zhang,Jiajun Sun,Zhixiong Yang,Yifei Cao,Shihan Dou,Xiaoran Fan,Baoyu Fan,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
现有的基准测试主要关注静态或单一场景设置，无法完全捕捉到多发言者、事件发展和异质音频源交互的场景。对于音频推理能力的需求是AI代理在现实世界场景中有效交互的关键，因此需要一个能够评估模型在复杂、多场景和动态演变音频推理任务方面的表现的基准测试。论文介绍了MDAR，一个包括3000对精心策划的问题-答案与多样化音频片段相关的基准，涵盖五类复杂推理和三种问题类型，旨在填补现有基准测试的空白。
### Innovation
提出了MDAR，一个用于评估模型在复杂、多场景和动态演变音频推理任务方面的表现的基准测试。这是一个包含3000对精心策划的问题-答案和多样化音频片段的基准，涵盖五类复杂推理和三种问题类型，旨在评估现有最先进的音频语言模型在这类任务中的表现并揭示其局限性。
### Conclusion
在单选题中，Qwen2.5-Omni开源模型的准确率为76.67%，而GPT-4o Audio封闭源模型为68.47%；但是，在更具挑战性的多项选择和开放性任务中，GPT-4o Audio表现得更好。所有模型在这三种问题类型中都无法达到80%的性能。这些发现强调了MDAR的独特挑战及其作为提升音频推理能力的基准的价值。
## 242. `cs.AI` - InfiR2: 一种全面的用于增强推理能力的语言模型FP8训练食谱 [PDF](https://arxiv.org/pdf/2509.22536), [HTML](https://arxiv.org/abs/2509.22536)
### Authors
Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Yuan Xie,Hongxia Yang
### Background
大规模语言模型（LLMs）的训练计算成本巨大，这是一个主要的技术障碍。虽然使用FP8进行训练可以显著提高理论上的效率，但由于缺乏全面且开源的训练方法，这一技术并未广泛采用。
### Innovation
本文介绍了完整的FP8训练方法，将连续预训练和有监督微调无缝集成在一起。这种方法使用精细的混合粒度量化策略，既保持了数值准确度，又最大化了计算效率。通过广泛实验，结果表明该方法不仅稳定性极高，而且几乎无性能损失，在多种推理基准测试中达到与BF16基线相当的性能。此外，该方法还实现了显著的效率改进，包括培训时间减少22%，峰值内存使用减少14%，吞吐量增加19%。
### Conclusion
本研究证明了FP8作为一种实际且可靠的BF16替代方案的有效性，未来将公布相关代码，以进一步普及大规模模型训练。
## 243. `cs.AI` - 基于边aware注意力机制和线搜索校正操作的中高压交流电功率流物理信息GNN [PDF](https://arxiv.org/pdf/2509.22458), [HTML](https://arxiv.org/abs/2509.22458)
### Authors
Changhun Kim,Timon Conrad,Redwanul Karim,Julian Oelhaf,David Riebesel,Tomás Arias-Vergara,Andreas Maier,Johann Jäger,Siming Bayer
### Background
物理信息图神经网络（PIGNNs）已经发展成为快速交流功率流求解器，能够替代经典的牛顿-拉夫森（NR）求解器，尤其是在需要评估数千种场景时。然而，现有的PIGNNs在保持计算速度的同时仍需要提高精度；尤其在推理阶段，缺乏有效的物理损失计算方法，这可能阻碍其在实际中的应用。
### Innovation
该研究引入了PIGNN-Attn-LS，结合了边aware注意力机制和线搜索校正操作。边aware注意力机制通过每边偏置显式地编码线路物理特性，捕捉电网的各向异性。线搜索校正操作则在推理过程中恢复了一个有效的减少准则。该模型在实际的中高压场景生成器上进行训练和测试，并采用NR方法只用于构建参考状态。
### Conclusion
在4-32个节点的测试集上，PIGNN-Attn-LS在电压测试RMSE上达到了0.00033 pu，在角度上达到了0.08°，分别比基线PIGNN-MLP提高了99.5%和87.1%。使用流式微批次，PIGNN-Attn-LS在4-1024节点的电网上实现了比NR快2-5倍的批量推理速度。
## 244. `cs.AI` - ConQuER：IQP量子生成模型中控制与偏见缓解的模块化架构 [PDF](https://arxiv.org/pdf/2509.22551), [HTML](https://arxiv.org/abs/2509.22551)
### Authors
Xiaocheng Zou,Shijin Duan,Charles Fleming,Gaowen Liu,Ramana Rao Kompella,Shaolei Ren,Xiaolin Xu
### Background
基于瞬时量子多项式（IQP）电路的量子生成模型在学习复杂分布方面表现出巨大潜力，同时保持经典可训练性。然而，当前的实现方式存在两个关键限制：无法对生成输出进行控制和对某些预期模式的高度生成偏见。
### Innovation
提出了Controllable Quantum Generative Framework（ConQuER），通过模块化电路架构解决了这两个挑战。ConQuER嵌入了一个轻量级控制电路，可以与预先训练的IQP电路直接结合，无需重新训练即可精确控制输出分布。通过利用IQP的优势，该方案能够在最小化参数和门控开销的情况下精确控制譬如汉明重量分布等属性。此外，通过数据驱动优化，控制器设计还扩展了模块化方法，嵌入了隐式的控制路径在底层IQP架构中，显著减少了在结构化数据集上的生成偏见。
### Conclusion
ConQuER保留了高效的经典训练属性和高可扩展性。我们通过多个量子态数据集的实验验证了ConQuER，证明其在控制精度和生成性能方面优于原IQP电路，且仅具有极低的开销成本。该框架在量子计算的优势与可控生成模型的实际需求之间建立了桥梁。
## 245. `cs.AI` - 探索解决方案的多样性及其对大型语言模型解决问题效果的影响 [PDF](https://arxiv.org/pdf/2509.22480), [HTML](https://arxiv.org/abs/2509.22480)
### Authors
Hang Li,Kaiqi Yang,Yucheng Chu,Hui Liu,Jiliang Tang
### Background
大型语言模型（LLMs）在解决问题任务中得到了广泛应用。现有的大部分改进方法是通过有监督微调（SFT）或基于任务反馈的强化学习（RL）来提升模型性能。本文的研究背景是探讨LMs在同一问题上生成的不同解决方案的多样性，并发现更高的解决方案多样性与更强的问题解决能力相关。基于这一发现，本文提出使用解决方案多样性作为新型度量标准，可以支持SFT和RL策略，提高问题解决的成功率。文章在三个代表性的问题领域进行了实验验证，结果表明利用解决方案多样性可以一致地提升成功率。
### Innovation
提出了将解决方案的多样性作为评估新兴度量标准，用于指导和优化大型语言模型的训练与评价；用这种新的视角发现了解决方案多样性与问题解决能力之间的正相关关系；验证了使用多样性度量可以改善大型语言模型在多个问题领域上的表现。
### Conclusion
本文的研究结果表明，解决方案的多样性是一个简单而有效的工具，能够促进大型语言模型的培训和评估。在三个代表性问题领域进行的实验中，使用解决方案多样性均能够提高成功解决任务的几率。
## 246. `cs.AI` - 评估大型语言模型在多语言法律推理中的局限性 [PDF](https://arxiv.org/pdf/2509.22472), [HTML](https://arxiv.org/abs/2509.22472)
### Authors
Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel
### Background
在以大型语言模型（LLMs）为主导的时代，理解其能力和局限性，尤其是在像法律这样重要的领域，显得尤为重要。随着如Meta的LLaMA、OpenAI的ChatGPT、Google的Gemini等大型语言模型被越来越多地集成到法律工作中，这些模型在多语言、司法系统多样和对抗性情景下的表现仍然没有被充分研究。本文利用LLM作为一种法官的方法进行人类一致性的评估，通过分别对大段文本和单词级别的扰动来评估其在法律任务中的对抗鲁棒性。文章还介绍了一个开源的、模块化的评估管道，旨在支持对任何语言和数据集组合进行多语言、任务多样化基准测试，特别关注法律任务，如分类、总结、开放问题和通用推理。研究发现，法律任务给LLMs带来了重大挑战，它们在法律推理基准上的准确率往往低于50%，而一般目的任务的准确率则超过70%。尽管英语通常产生更稳定的结果，但并非总是更准确。语言模型对提示的敏感性和对抗性漏洞在不同语言中也持续存在。最后，不同的语言性能与其与英语的句法相似性之间存在相关性。此外，LLaMA的表现低于Gemini，后者在相同任务上平均优势为大约24个百分点。尽管新的LLMs有所改进，但在关键的多语言法律应用中可靠部署这些模型仍有挑战。
### Innovation
本文创新性地将大型语言模型应用于多语言法律推理的评估，采用LLM作为一种法官的方法进行评估，通过字符和词级扰动来评估其对抗性鲁棒性。文章还提出了一种开源的模块化评估管道，用于语言模型与多种数据集的基准测试，特别是针对法律任务，包括分类、总结、开放式问题和一般推理。此外，研究还揭示了语言性能与其与英语句法相似性之间的关联，以及LLaMA和Gemini在法律任务上的性能差异。
### Conclusion
研究表明，法律任务给大型语言模型带来了重大挑战，它们在法律推理基准上的准确率往往低于50%，而一般目的任务的准确率则超过70%。尽管改善了的新一代大型语言模型，但在加载到关键的多语言法律应用中，仍然存在着挑战。此外，LLaMA表现不如Gemini，说明在提高高 stakes任务的性能方面，生成模型还有改进的空间。
## 247. `cs.AI` - OFMU: 以优化驱动的机器遗忘框架 [PDF](https://arxiv.org/pdf/2509.22483), [HTML](https://arxiv.org/abs/2509.22483)
### Authors
Sadia Asif,Mohammad Mohammadi Amiri
### Background
在关键应用中部署的大语言模型越来越多地需要有能力在不从头开始重新训练的情况下，遗忘特定知识，如用户请求、版权材料或过时信息，以确保合规性、用户隐私和安全。这一任务称为机器遗忘，其目标是在遗忘目标数据的影响的同时保持对剩余数据的性能。通常采用多目标优化并使用加权和将其转化为单目标问题作为解决方案，但这种方法往往会导致梯度方向冲突，进而导致不稳定训练动态和模型性能下降。
### Innovation
本文提出了OFMU，一种基于惩罚的双层优化框架，该框架通过层次结构明确优先遗忘并保留性能，通过内层最大化步骤引入类比感知惩罚来抵消遗忘和保留目标的梯度方向，借助于外层最小化步骤恢复性能。为了确保可扩展性，在可凸和非凸情况下均提供了有保证收敛的双重算法，并提供了收敛速度的严格理论分析。实验结果表明，OFMU在遗忘效率和保留性能方面均优于现有方法。
### Conclusion
文章通过提出OFMU，一种基于惩罚和双层优化框架的方法，在保证模型性能不下降的情况下，有效解决了机器遗忘问题中的遗忘目标数据的影响和优化模型性能的折中问题。
## 248. `cs.AI` - 一种多重硬化症生物标志物发现的机器学习管道：可解释AI与传统统计方法的比较 [PDF](https://arxiv.org/pdf/2509.22484), [HTML](https://arxiv.org/abs/2509.22484)
### Authors
Samuele Punzo,Silvia Giulia Galfrè,Francesco Massafra,Alessandro Maglione,Corrado Priami,Alina Sîrbu
### Background
本文提出了用于多重硬化症(MS)中生物标志物发现的机器学习管道，整合了八个公开的微阵列数据集，这些数据来自外周血单核细胞(PBMC)。经过稳健的预处理后，使用了经过贝叶斯搜索优化的XGBoost分类器。SHapley Additive exPlanations (SHAP) 方法被用来识别关键特征，以进行模型预测，从而指示可能的生物标志物。然后将这些生物标志物与通过经典差异表达分析(DEA)确定的基因进行比较。
### Innovation
研究使用了XGBoost分类器结合SHAP方法来识别可能的生物标志物，并将其与基于经典差异表达分析方法获得的基因进行比较，揭示了重叠和独特的生物标志物，表明可解释的AI (xAI) 可以与传统统计方法结合以获得对疾病机制的更深层次洞察能力。
### Conclusion
对SHAP选择基因的富集分析证实了其生物学相关性，并将其与包括鞘脂信号通路、Th1/Th2/Th17 细胞分化和EB病毒感染在内的相关通路联系起来，这些通路与MS相关。该研究强调了结合可解释AI (xAI) 与传统统计方法以深入理解疾病机制的价值。
## 249. `cs.AI` - AI伴侣对心理健康的影响：社会媒体准实验、用户观点和关系理论的综合 [PDF](https://arxiv.org/pdf/2509.22505), [HTML](https://arxiv.org/abs/2509.22505)
### Authors
Yunhao Yuan,Jiaxun Zhang,Talayeh Aledavood,Renwen Zhang,Koustuv Saha
### Background
随着AI驱动的陪伴聊天机器人（AICCs）如Replika的流行，它们提供了同情的互动，但其对心理及社会的影响尚未清晰。本文通过大规模准实验研究和用户访谈，探讨了使用AICCs如何影响幸福感以及用户对其的感知，并揭示了其双重效应：既支持情感验证和社会练习，但也有过度依赖和抽离的风险。
### Innovation
本文通过结合大规模准实验研究、用户访谈以及关系发展理论，综合分析AI伴侣对心理健康的影响，填补了现有研究中关于AICCs的实证分析和用户视角的空白，为AI伴侣的设计提供了更为全面的设计建议，旨在最大化心理社会收益同时减少潜在风险。
### Conclusion
本文通过多方法研究（准实验、用户访谈和关系理论）揭示了AICCs对用户福祉的复杂性影响，提出了设计建议，包括设置健康边界、促进有意识的互动、支持有选择的披露而避免依赖、揭示关系发展的不同阶段，旨在平衡促进心理健康同时降低风险。
## 250. `cs.AI` - 离散流匹配生成模型的理论分析 [PDF](https://arxiv.org/pdf/2509.22623), [HTML](https://arxiv.org/abs/2509.22623)
### Authors
Maojiang Su,Mingcheng Lu,Jerry Yao-Chieh Hu,Shang Wu,Zhao Song,Alex Reneau,Han Liu
### Background
文章对端到端训练的离散流匹配（DFM）生成模型进行了理论分析。DFM是一种有前景的离散生成建模框架，通过训练神经网络近似变换的速度场来学习潜在的生成动力学。
### Innovation
文章通过分解最终的分布估计误差链，证明了训练得到的生成模型生成的分布随着训练数据集大小的增加而理论化地收敛到真实数据分布。这是首次提供了正式的证明，通过对计算误差和估计误差的分析来建立生成模型输出分布收敛的保证。
### Conclusion
文章建立了一条清晰的保证链，证明了生成的分布与目标分布之间的总量变距离可以通过所学习的速度场的风险来控制。通过分析该风险的两个主要来源，即近似误差和估计误差，证明了随着训练集大小的增加，生成的分布理论地收敛到真实数据分布。
## 251. `cs.AI` - 激活函数设计在持续学习中维持可塑性 [PDF](https://arxiv.org/pdf/2509.22562), [HTML](https://arxiv.org/abs/2509.22562)
### Authors
Lute Lillo,Nick Cheney
### Background
在独立同分布的训练模式下，激活函数已经被广泛研究，差异往往在模型大小和优化调整后缩小。但在持续学习环境中，情况有所不同：除了灾难性遗忘，模型还逐渐丧失适应能力（称为可塑性损失），而非线性的角色尚未被充分探索。研究表明，激活函数的选择是无需考虑架构的首要杠杆，能够减轻可塑性损失。
### Innovation
基于激活函数负分支形状和饱和行为的特性分析，该研究引入了两种可替代的非线性激活函数（平滑泄漏和随机平滑泄漏），并在监督类别增量基准和强化学习中的非稳定MuJoCo环境（设计用于诱导分布和动力学变化）中进行了评估。此外，提供了一个简单的方法来评估和诊断激活函数对适应变化的影响。
### Conclusion
简而言之，精心设计的激活函数提供了一种无额外容量且适用于各类任务的方式，能够在持续学习中维持可塑性，而无需特定的任务调优。
## 252. `cs.AI` - StateX: 通过后训练状态扩展增强RNN回忆 [PDF](https://arxiv.org/pdf/2509.22630), [HTML](https://arxiv.org/abs/2509.22630)
### Authors
Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
尽管基于Transformer的模型在语言建模方面表现出色，但它们在处理长上下文时的高复杂性导致了高昂的成本。相比之下，诸如线性注意力和状态空间模型等循环神经网络（RNNs）因其每个单词的固定复杂度而受到欢迎。然而，这些循环模型在需要准确回忆长上下文中的信息的任务上表现出色，因为所有上下文信息都被压缩到一个固定大小的循环状态下。以往的工作表明， recall 能力与循环状态的大小正相关，但直接训练具有较大循环状态的RNN会导致高训练成本。
### Innovation
本文介绍了 StateX，一种通过后训练高效扩展预训练RNN状态的训练管道。对线性注意力和状态空间模型这两种流行的RNN类进行了设计后训练架构修改，以扩大状态大小，同时保持或几乎不增加模型参数。在最大参数量达1.3B的模型上进行的实验表明，StateX可以有效提高RNN的回忆能力和上下文学习能力，而无需增加后训练成本或牺牲其他能力。
### Conclusion
StateX能够通过后训练高效扩展RNN状态，从而提升其回忆和上下文学习能力，而且不会增加额外的后训练成本或损害其他性能。
## 253. `cs.AI` - 学会绳索，再信任胜利：渐进式探索的自我模仿强化学习 [PDF](https://arxiv.org/pdf/2509.22601), [HTML](https://arxiv.org/abs/2509.22601)
### Authors
Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun
### Background
强化学习（RL）是提升大型语言模型（LLM）在长期、稀疏奖励任务中策略性工具使用能力的主要范式。然而，RL在探索与利用之间的权衡中面临根本挑战。现有研究通过政策熵的角度来激励探索，但这种机械熵的优化容易导致RL训练中的不稳定性，特别是由于多回合分布的转移。
### Innovation
本文提出了SPEAR，一种基于课程的自我模仿学习（SIL）方法，用于训练具有代理性的LLM。该方法在vanilla SIL框架的基础上，通过逐步引导政策进化过程中的熵，并结合内在奖励和自我模仿来促进技能层次和动作层次的探索，最终平衡探索与利用之间的关系，同时利用经验重校准和轨迹级熵控制来稳定训练过程。
### Conclusion
本文通过SPEAR方法解决了探索与利用之间的权衡问题，提高了代理性LLM在稀疏奖励任务中的学习效果，同时保证了训练的稳定性。
## 254. `cs.AI` - 定量优势估计用于熵安全推理 [PDF](https://arxiv.org/pdf/2509.22611), [HTML](https://arxiv.org/abs/2509.22611)
### Authors
Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He
### Background
强化学习中的验证奖励（RLVR）提高了大语言模型（LLM）的推理能力，但训练过程中往往会交替出现熵崩溃和熵爆炸的情况。这些训练中的震荡归因于价值自由RL方法（如GRPO和DAPO）中使用的均值基线，该方法在奖励异常值情况下错误地惩罚了负优势样本。
### Innovation
该研究提出了定量优势估计（QAE），用组间K分位数基线替代均值。QAE在难题上增强了罕见的成功，在简单问题上主要针对剩余的失败。并在一阶softmax更新下证明了双侧熵安全，提供了单步熵变化的上下限，防止熵爆炸并避免熵崩溃。实验证明，这一小的修改稳定了熵，细化了信用分配（调整K值，大约80%的响应获得零优势），并在Qwen3-8B/14B-Base上持续获得了AIME 2024/2025和AMC 2023中的最高成绩。研究结果表明，基线设计而非令牌级的启发式方法是影响RLVR扩展的主要机制。
### Conclusion
这一研究识别了基线设计作为大规模扩展RLVR的主要因素，而非传统的令牌级启发式技术。通过改进基线，可以更好地控制熵的振荡，并最终实现更稳定的推理性能。
## 255. `cs.AI` - AI Coaching for Workplace Negotiations [PDF](https://arxiv.org/pdf/2509.22545), [HTML](https://arxiv.org/abs/2509.22545)
### Authors
Veda Duddu,Jash Rajesh Parekh,Andy Mao,Hanyi Min,Ziang Xiao,Vedant Das Swain,Koustuv Saha
### Background
职场谈判经常受到心理障碍的影响，这甚至可以破坏精心准备的策略。尽管人工智能提供定制且随时可获取的谈判教练，但其在谈判准备中的有效性仍然有待探讨。研究者构建了基于Brett谈判模型的Trucey原型AI教练，并通过一项涉及267人的对照实验和15人的深入访谈来评估其效果。相比传统谈判手册，虽然Trucey在减少恐惧方面表现最好，但手册在易用性和心理赋能方面更胜一筹。访谈揭示了手册的全面可复习内容对于参与者信心和准备的重要性，而AI虽然提供了排练能力，但其指导往往显得冗长且碎片化，需要额外的努力，令参与者感到困惑或不知所措。这些发现挑战了AI优越性的假设，提出了将结构化、理论驱动的内容与有针对性的排练、明确界限和适应性支架相结合的混合设计的可能性，以应对心理障碍并支持谈判准备。
### Innovation
研究者开发了Trucey，一种基于Brett谈判模型的原型AI教练，并通过实验证明了其在减少谈判准备时的恐惧方面的有效性，挑战了AI卓越假设，提出了结合结构化理论驱动内容与适应性支架的混合设计来增强谈判准备的建议。
### Conclusion
尽管Trucey在减少恐惧方面表现最好，但传统谈判手册在易用性和心理赋能方面更优秀。AI的排练功能虽然受到青睐，但其指导显得冗长和碎片化，导致用户困惑或过度紧张。研究挑战了AI在谈判准备中的优越性，并建议采用结合结构化理论驱动内容与适应性支架的混合设计来支持谈判准备的过程。
## 256. `cs.AI` - 语言模型的变分推理 [PDF](https://arxiv.org/pdf/2509.22637), [HTML](https://arxiv.org/abs/2509.22637)
### Authors
Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang
### Background
该研究基于语言模型的传统推理方法，提出了一种使用变分推理来优化隐变量（思考轨迹）的框架。研究起始于证据下界（ELBO），并通过扩展到多轨迹目标来提高边界紧度，并提出了前向KL公式来稳定变分后验的学习过程。
### Innovation
研究提出了变分推理框架，将思考轨迹作为隐变量来优化，并进一步展示了拒绝采样微调和二元奖励RL（如GRPO）可视为局部前向KL目标，并揭示了一个先前未被注意的偏向于更容易问题的偏差。通过实验证实该方法在Qwen 2.5和Qwen 3模型家族中的广泛推理任务中有效。
### Conclusion
研究提供了一个原则性的概率视角，将变分推理与RL风格方法统一起来，并为提高语言模型的推理能力提供了稳定的目标。相关代码可在[此处]获取。
## 257. `cs.AI` - 语言模型可以从口头反馈中学习而无需标量奖励 [PDF](https://arxiv.org/pdf/2509.22638), [HTML](https://arxiv.org/abs/2509.22638)
### Authors
Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang
### Background
当前的语言模型（LLMs）通常通过强化学习（RL）从人类或AI反馈中训练，但这些方法往往将复杂的反馈压缩为单一的标量奖励，从而丢弃了其丰富性，并且可能导致规模失衡。
### Innovation
提出了将口头反馈作为条件信号的新方法。借鉴文本到图像生成中的语言先验技术，提出反馈条件策略（FCP），这是一种直接从响应-反馈对中学习的方法，通过离线数据的最大似然训练近似反馈条件后验。进一步开发了一个在线自举阶段，策略在正条件下生成并接收新反馈以自我调整，将反馈驱动的学习重新定义为条件生成，而非奖励最大化，提供了一种更直接且表达力更强的方式来学习口头反馈。
### Conclusion
这种反馈条件策略不仅提高了语言模型从口头反馈中学习的效果，还通过条件生成的方法使其能够更直观地理解口头反馈的含义，从而实现更自然的交互。
## 258. `cs.AI` - 从参数到行为：无监督压缩策略空间 [PDF](https://arxiv.org/pdf/2509.22566), [HTML](https://arxiv.org/abs/2509.22566)
### Authors
Davide Tenedini,Riccardo Zamboni,Mirco Mutti,Marcello Restelli
### Background
尽管深度强化学习（DRL）在过去取得了一些成功，但它在样本效率方面依然存在显著问题。这一问题根源在于标准实践中直接在高维且冗余的参数空间 Θ 中优化策略。在多任务设置下的挑战尤为突出。因此，本文旨在提出一种新颖的无监督方法，将策略参数空间 Θ 压缩到低维潜在空间 Z。通过优化行为重建损失，训练生成模型 g：Z→Θ，确保潜在空间的组织方式是基于功能相似性而不是参数化接近性。作者推测，这个流形的固有维度是环境复杂性的函数，而不是策略网络的大小。这种方法在连续控制领域中得到了验证，证明标准策略网络的参数化在保留大部分表达能力的同时可以压缩数个量级。此外，通过潜在空间 Z 中的策略梯度，这一方式还使策略能够针对性地适应特定任务。
### Innovation
提出了一个无监督的压缩策略参数空间的方法，通过生成模型在低维潜在空间中重建高维参数空间，且实现策略网络参数的大幅度压缩。同时，潜在空间还支持在多任务环境下的策略梯度方法，提供策略的特定任务适应性。这种方法不仅提高了学习效率，还为优化策略参数提供了一种新的视角。
### Conclusion
论文提出的方法成功地将策略参数空间从高维压缩到了低维，保持了大部分的策略表达能力。在连续控制领域的实验验证了方法的有效性，并展示了其在多任务场景中的潜力。这种方法对于提升强化学习算法的样本效率具有重要意义。
## 259. `cs.AI` - 使用2D高斯斑图从压缩图像表示实现视觉语言对齐 [PDF](https://arxiv.org/pdf/2509.22615), [HTML](https://arxiv.org/abs/2509.22615)
### Authors
Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe
### Background
现代视觉语言管道依赖于在大规模图像文本数据集上训练的RGB视觉编码器。虽然这些管道已经在零样本能力和跨任务的迁移方面取得了显著成就，但它们仍然继承了像素域中的两个结构性缺陷:(1)从边缘设备向云传输密集的RGB图像的能耗高且成本高昂；(2)基于块的令牌化导致序列长度爆炸，对注意力预算和上下文限制产生了压力。
### Innovation
研究2D高斯斑图（2DGS）作为另一种视觉基板:一种紧凑且空间自适应的表示方法，通过一系列带颜色的各向异性高斯定义图像。开发了一种可扩展的2DGS管道，具有结构化初始化、亮度感知剪枝和批处理CUDA内核，实现超过90倍的拟合速度，并达到约97％的GPU利用率，相较于先前实现。进一步将对比语言图像预训练（CLIP）适应2DGS，通过重用冻结的基于RGB的变换器主干、轻量级斑图感知输入茎和感知采样器，仅训练约7％的总参数。在大型DataComp子集中，GS编码器在图像Net-1K数据集上实现了有意义的零样本性能，在输入压缩方面达到了3到20倍的压缩比，相对于像素。虽然准确率目前落后于RGB编码器，但本结果确立了2DGS作为多模式基板的可能性，指出了架构瓶颈并开辟了既具有语义强大力量又能高效传输的表示方法的路径，适用于边缘云计算学习。
### Conclusion
结果显示，2DGS可以作为多模态基板实现可能，虽然目前其准确率略低于基于像素的方法，但其在传输效率方面的显著优势为未来的视觉语言模型铺平了道路。
## 260. `cs.AI` - 基于检索增强的AI草拟患者门户网站消息的护栏构建及大规模评估 [PDF](https://arxiv.org/pdf/2509.22565), [HTML](https://arxiv.org/abs/2509.22565)
### Authors
Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma
### Background
通过EHR门户进行异步患者-临床人员消息交流成为临床人员工作负担的重要来源，促使人们对于利用大型语言模型（LLMs）帮助草拟消息以减轻负担产生兴趣。然而，LLMs的输出可能存在临床不准确、遗漏或语气不匹配等问题，因此需要一个强大的评估机制。该研究旨在解决这一问题，通过引入临床依存的错误分类体系、开发检索增强的评估管道以及提出一种二阶段提示架构来实现这一目标。
### Innovation
该研究在以下三方面做出了创新贡献：(1)提出了一个包括5个领域和59个具体错误代码的临床依存错误分类体系，通过归纳编码和专家评估而制定；(2)开发了一种基于检索增强的评估管道（RAEC），该管道利用语义相似的历史消息响应对来改进评判质量；(3)提出了一个使用DSPy实现了可扩展、可解释和层次化的错误检测的二阶段提示架构。
### Conclusion
使用二阶段DSPy管道，研究对比了基准评估和参考信息增强评估在1500多条患者信息上的表现，显示检索上下文对于特定领域如临床完整性和工作流程适配性的错误识别有提升作用。通过对比100条消息的人类验证，证明了上下文增强标签在一致性（Kappa = 50% vs. 33%）和性能（F1 = 0.500 vs. 0.256）上优于基准方法，推动了使用RAEC管道作为AI护栏指导患者消息交流的应用前景。
## 261. `cs.AI` - 通过多模态LLMs学习AI生成视频的人类感知假象 [PDF](https://arxiv.org/pdf/2509.22646), [HTML](https://arxiv.org/abs/2509.22646)
### Authors
Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch
### Background
随着视频生成模型的快速进步，识别AI生成的（假造的）视频中的人工痕迹（如时空可验证的视觉特征）这一关键维度很少受到关注。这项研究旨在评估人类能否检测出这些痕迹，并引入了DeeptraceReward基准，这是首个细粒度、时空感知的基准，用于评估视频生成奖励。该基准包括4300个详细注解，涵盖3300个高质量生成的视频，每个注解都提供了自然语言解释、标注了包含感知痕迹的边界框区域，并标明了精确的时间戳。
### Innovation
DeeptraceReward基准是首个细粒度的地时感知基准，用于标注人类感知的假造痕迹。基准中包含4300个详细注解，共有9个主要类别的假造痕迹类别。研究使用了多模态语言模型（LMs）作为奖励模型，以模仿人类的判断和定位。7B的奖励模型在假造线索识别、定位和解释方面平均比GPT-5高出了34.7%。这表明，从自然语言解释到时空定位，识别假造痕迹的难度逐渐增加。
### Conclusion
DeeptraceReward通过强调人类感知的假造痕迹，提供了对社会敏感和可信赖的视频生成具有严谨测试平台和训练信号。
## 262. `cs.AI` - IA2: 使用ICL激活进行对齐以改进监督微调 [PDF](https://arxiv.org/pdf/2509.22621), [HTML](https://arxiv.org/abs/2509.22621)
### Authors
Aayush Mishra,Daniel Khashabi,Anqi Liu
### Background
本文讨论了监督微调（SFT）和上下文学习（ICL）两种模型适应技术。SFT通过训练权重来产生预期的目标响应，而ICL则通过指令或演示在推理过程中的适应。研究指出，在数据稀缺的情况下，ICL相比SFT具有更好的泛化能力和更加校准的响应，但代价是更多的推理计算资源。基于此，本文提出了一个名为ICL激活对齐（IA2）的方法，旨在利用ICL的激活模式来改善SFT模型的性能，进而提高模型输出的准确性和校准度。
### Innovation
本文的创新在于引入了一个新的方法——ICL Activation Alignment（IA2），用于在SFT模型中复制ICL的激活模式，并激励类似ICL的内部推理过程。研究证明，在SFT之前进行IA2预训练显著提高了模型输出的准确性和校准度，并在12个常用基准和2个模型系列上进行了广泛的实证分析验证了这一点。
### Conclusion
通过IA2，ICL的内部计算可以用来改进SFT的质量。这种方法不仅在实践中非常有用，还为了解模型适应内部机制提供了一个概念窗口。
## 263. `cs.AI` - 学习适用于A*的可接纳启发式方法：理论与实践 [PDF](https://arxiv.org/pdf/2509.22626), [HTML](https://arxiv.org/abs/2509.22626)
### Authors
Ehsan Futuhi,Nathan R. Sturtevant
### Background
启发式函数对A*等搜索算法的性能至关重要，其中接纳性——即从不低估真实最短路径成本的特性——保证了解的最优性。最近的深度学习方法往往忽视接纳性，并且在训练数据之外提供的泛化保证有限。
### Innovation
本文解决了这两个限制。首先，将启发式学习视为一个约束优化问题，并引入了交叉熵接纳性（CEA），一种在训练期间强制接纳性的损失函数。在魔方域中，这种方法产生了接近接纳性的启发式函数，其指导作用显著强于压缩模式数据库（PDB）启发式。此外，论文通过利用模式数据库（PDB）抽象和图结构特性如魔方，紧固了A*学习启发式函数所需的样本复杂性上界。使用ReLU神经网络替换一般假设类，提供了一种主要取决于网络宽度和深度而非图大小的上界。同时，还提供了首个目标依赖性启发式的泛化保证，使用相同的网络结构。
### Conclusion
通过交叉熵接纳性损失函数，该方法在魔方域中学习到了接近接纳性的启发式函数，提供了比压缩PDB启发式更强的指导能力，并通过紧固学习启发式的样本复杂性上界以及首次提供了目标依赖性启发式的泛化保证，显著提升了算法的理论和实际性能。
## 264. `cs.AI` - 基于CLIP的层次表示匹配（Hierarchical Representation Matching for CLIP-based Class-Incremental Learning） [PDF](https://arxiv.org/pdf/2509.22645), [HTML](https://arxiv.org/abs/2509.22645)
### Authors
Zhen-Hao Wen,Yan Wang,Ji Feng,Han-Jia Ye,De-Chuan Zhan,Da-Wei Zhou
### Background
类增量学习（CIL）旨在使模型能够适应不断变化的数据流。近年来，预训练的视觉-语言模型（例如，CLIP）为这一任务提供了强大的基础。然而，现有的方法往往依赖于简单的模板，如“一张[CLASS]的照片”，这些模板忽视了视觉概念的层次性质。此外，CLIP的当前特征映射仅依赖于最后一层的表示，忽略了早期层中包含的层次信息。
### Innovation
本文介绍了一种名为HERMAN（Hierarchical Representation MAtchiNg）的方法，利用LLMs递归生成区分性文本描述，从而增强语义空间，加入显式的层次线索。这些描述符根据任务需求适配路由到语义层次的不同级别，从而实现精确区分并缓解增量任务中的灾难性遗忘。
### Conclusion
广泛的实验在多个基准上展示，我们的方法在类增量学习任务中始终达到了最先进的性能。
## 265. `cs.AI` - 向在线探索的高效化努力 [PDF](https://arxiv.org/pdf/2509.22633), [HTML](https://arxiv.org/abs/2509.22633)
### Authors
Gen Li,Yuling Yan
### Background
强化学习结合人类反馈（RLHF）通过学习奖励模型并将模型优化到更符合人类偏好的策略上，在使大型语言模型（LLMs）与人类偏好对齐方面发挥了关键作用。现有研究中的在线RLHF探索原则旨在通过自适应地收集新产品味数据，在以数据高效的方式改进奖励模型和策略上取得平衡。然而，现有的乐观探索算法在样本获取策略上存在缺陷：倾向于收集不足以减少奖励差异中最关键的不确定性信息的对比数据，这导致证明了此类方法在极长时间上可能产生线性遗憾。
### Innovation
本文提出了一种新的探索方案，该方案将偏好查询引向那些对策略改进最为关键的奖励差异上的不确定性减少。在RLHF的多臂 bandit 模型下，证明了遗憾界限为 $T^{(beta+1)/(beta+2)}$，其中 $beta>0$ 是一个控制最大化奖励与缓解分布偏移之间平衡的超参数。这是首次将遗憾界限按所有模型参数的多项式尺度定义的在线RLHF算法。
### Conclusion
本文介绍了一种新的在线RLHF算法，通过优化探索策略，能够在保证高效收集新数据的同时，显著减少算法的遗憾值，从而使RLHF在实际应用中更加有效和可靠。
## 266. `cs.AI` - 在AI引发的事件中归因责任：一种计算反射均衡框架 [PDF](https://arxiv.org/pdf/2404.16957), [HTML](https://arxiv.org/abs/2404.16957)
### Authors
Yunfei Ge,Ya-Ting Yang,Quanyan Zhu
### Background
人工智能（AI）的普遍整合引发了责任和问责制方面的复杂挑战，特别是在涉及AI系统的事件中。这些系统的互联性、AI引发的道德问题以及AI技术的不确定性，加之缺乏相应的监管措施，使传统的责任归属变得困难。
### Innovation
本文提出了计算反射均衡（CRE）方法，以建立一个适用于所有利益相关者的连贯且道德上可接受的责任归属框架。计算方法提供了结构化的分析，克服了概念方法在处理动态和多面向场景中的局限性，展示了该框架在责任归属过程中的可追溯性、一致性以及适应性特点。
### Conclusion
该框架为AI引发的事件中的问责制提供了宝贵的见解，通过持续监控、修订和反思，促进了可持续性和韧性系统的开发。
## 267. `cs.AI` - 死亡的（新颖性）：超越n-gram新颖性作为文本创意度量标准 [PDF](https://arxiv.org/pdf/2509.22641), [HTML](https://arxiv.org/abs/2509.22641)
### Authors
Arkadiy Saakyan,Najoung Kim,Smaranda Muresan,Tuhin Chakrabarty
### Background
n-gram新颖性广泛用于评估语言模型生成不在其训练数据中的文本的能力，最近也开始用于衡量文本的创造性。然而，理论上的创造性研究建议这种方法可能不充分，因为它未能考虑创造性的双重性质：新颖性（文本的原创性）和适当性（文本的合乎逻辑性和实用性）。这项研究通过7542位专家作家对人工和AI生成的文本进行详细阅读，对这些概念之间的关系进行了探索。
### Innovation
研究发现了n-gram新颖性与专家判断的创造性之间的正相关关系，但超过91%的顶级n-gram新颖性表达并未被判断为具有创造性，这表明不能仅依赖n-gram新颖性作为创意的度量标准。此外，与人类撰写的文本不同，开源LLM中的高n-gram新颖性与较低的适当性相关。这项研究还确认了前沿闭源模型不如人类产生创新表达的说法。
### Conclusion
前沿语言模型在这方面的表现高于随机，但在识别非实用表达方面仍有改进空间。研究还发现，最佳模型的LLM作为法官的新颖性评分可预测专家作家的偏好。
## 268. `cs.AI` - WebGen-Agent: 提升多级反馈与步长强化学习的互动网站生成 [PDF](https://arxiv.org/pdf/2509.22644), [HTML](https://arxiv.org/abs/2509.22644)
### Authors
Zimu Lu,Houxing Ren,Yunqiao Yang,Ke Wang,Zhuofan Zong,Junting Pan,Mingjie Zhan,Hongsheng Li
### Background
基于大型语言模型（LLMs）的代理系统在仓库级别的代码生成任务中展示了令人印象深刻的性能。然而，在依赖视觉效果和用户交互反馈的任务（如网站代码基生成）上，现有的代码代理仅依赖简单的代码执行以获取反馈和验证。这种做法未能捕捉到生成代码的实际质量。
### Innovation
本论文提出了一种新颖的网站生成代理（WebGen-Agent），利用全面多层次的视觉反馈进行网站代码基的迭代生成与改进。通过视觉语言模型（VLM）生成详细且表达力强的文字描述和建议，包括截图和GUI代理测试，以及量化它们质量的分数。此外，引入了带截图和GUI代理反馈的Step-GRPO来增强代理性能。Step-GRPO中的截图和GUI代理分数用作奖励，为模型处理过程提供了密集且可靠的监督信号。
### Conclusion
WebGen-Agent在WebGen-Bench数据集上的实验表明，与之前的最先进的代理系统相比，可以显著提高代码生成的准确性和外观得分。例如，对于Claude-3.5-Sonnet，准确率提高了从26.4%到51.9%，外观得分从3.0提高到3.9。并且Step-GRPO训练方法使得Qwen2.5-Coder-7B-Instruct的准确率从38.9%提高到了45.4%，外观分数从3.4提高到3.7。
## 269. `cs.AI` - See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation [PDF](https://arxiv.org/pdf/2509.22653), [HTML](https://arxiv.org/abs/2509.22653)
### Authors
Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu
### Background
该研究提出了名为See, Point, Fly (SPF)的训练无监督的视景-语言导航（AVLN）框架，基于视觉-语言模型（VLMs）。SPF能够根据任何形式的指引在任何类型的环境中实现导航。与现有的基于VLM的方法将动作预测视为文本生成任务不同，该研究将动作预测视为2D空间定位任务。
### Innovation
SPF利用VLMs将模糊的语言指示分解为对输入图像的2D航点的迭代标注。SPF还通过预测移动距离自动调整动作指令，使得无人机能够在动态环境中更高效地导航。SPF采用闭环控制方式，在动态环境中跟踪移动目标。SPF在DRL模拟基准测试中达到了新的最高水平，性能绝对优势提升了63%，在实际世界的广泛评估中也显著优于很强的基线。此外，通过全面的消融研究表明了该设计的有效性，并展示了SPF对不同VLM的强大泛化能力。
### Conclusion
SPF为通用无人机导航提供了新的框架，能够在无需学习的情况下实现高效的视景-语言导航。SPF不仅在模拟环境中取得了最优的性能，而且在现实生活中的测试中也表现出色。这项工作提高了无人机导航领域的研究标准，并展示了在各种视觉-语言模型上的出色迁移能力。
## 270. `cs.AI` - CapRL: 刺激密集图像字幕能力的强化学习 [PDF](https://arxiv.org/pdf/2509.22647), [HTML](https://arxiv.org/abs/2509.22647)
### Authors
Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin
### Background
图像字幕是一项关键任务，它在视觉和语言领域之间架起桥梁，对于预训练大型视觉-语言模型（LVLM）至关重要。当前最先进的字幕模型通常是通过监督微调（SFT）进行训练，这种依赖于人类或专有模型标注的昂贵且不具扩展性的数据集。这种方法会导致模型记忆力强，即只能生成特定的正确描述，限制了它们的通用性和创新能力。
### Innovation
为了克服SFT的局限性，我们提出了应用可验证奖励的强化学习（RLVR）框架，用于开放式的图像字幕任务。特别地，我们引入了Captioning Reinforcement Learning（CapRL），通过其对图像的实用性来重新定义字幕的质量。CapRL采用了解耦的两阶段管道，其中LVLM生成字幕，目标奖励来自于一个没有视觉功能的LLM基于该字幕准确回答图像相关问题的准确性。这种基于RLVR的方法是首次应用于主观性的图像字幕任务，在多个评估基准上取得了显著成果。
### Conclusion
在使用CapRL-3B标注的CapRL-5M字幕数据集进行预训练后，CapRL在12个基准上的表现显著提高。此外，CapRL在Prism框架下对字幕质量的评估中，表现出与Qwen2.5-VL-72B相当的性能，而平均超过基线8.4%。
## 271. `cs.AI` - VoiceAssistant-Eval：跨听、说、看评估AI助手的基准 [PDF](https://arxiv.org/pdf/2509.22651), [HTML](https://arxiv.org/abs/2509.22651)
### Authors
Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li
### Background
大型语言模型和多模态系统的能力日益增强，激发了对语音优先AI助手的兴趣。然而，现有的基准测试工具不足以全面评估这些系统的各项能力。本文介绍了VoiceAssistant-Eval，这是一个全面的基准测试，旨在评估AI助手在聆听、说话和观看方面的能力，涵盖了10,497个精心策划的例子，分类为13个任务类别，包括自然声音、音乐、人声对话、多轮对话、角色扮演模仿、各种场景以及非常异质的图像等。这一基准测试用于评估21个开源模型和GPT-4o-Audio的表现，揭示了这些模型在听觉理解方面的不足，同时展示了中型模型在特定任务上的竞争力。
### Innovation
VoiceAssistant-Eval是一个全新的基准测试框架，涵盖了听取、说话和观看等多领域的评估。它建立了一个用于评估和指导下一代AI助手发展的严谨框架，通过全面的任务分类和大范围的模型评估，揭示了现有模型在跨模态输入和表演语音模仿任务等方面的局限性，并提供了未来改进的方向。
### Conclusion
VoiceAssistant-Eval识别出当前模型在多模态输入和角色扮演语音模仿任务等方面的不足，并建立了严格的评估和指导框架，接下来的AI助手需要更具稳健性和安全对齐性。源代码和数据将在指定链接公开。
## 272. `cs.AI` - 向人工神经网络和大脑的物理学原则迈进 [PDF](https://arxiv.org/pdf/2509.22649), [HTML](https://arxiv.org/abs/2509.22649)
### Authors
Arsham Ghavasieh,Meritxell Vila-Minana,Akanksha Khurd,John Beggs,Gerardo Ortiz,Santo Fortunato
### Background
深度神经网络和大脑在处理方式上存在类似性，比如处理节点类比神经元，调整权重类比可变突触。研究是否可以找到一个统一的理论框架来解释两者的行为？该研究利用非平衡统计物理学中描述神经元雪崩的方程来解释深度神经网络中活动级联的现象。研究指出，这些网络在两者之间的临界点上学习效果最佳。但由于这些网络强烈依赖输入，它们并没有真正处于临界点，而是在拟临界区运行。最终，研究通过有限大小标度分析识别出了不同的普适类，包括Barkhausen噪声和有向渗流。这表明生物和人工神经网络共享某些普适特征的共同理论框架已经建立。
### Innovation
该研究发现利用非平衡统计物理学中描述神经元雪崩的方程可以应用于描述深度学习中神经网络的级联活动。此外，研究揭示了利用最大灵敏度而非靠近临界点本身可以更可靠地预测学习效果的原则。最后，通过有限大小标度分析识别出不同的普适类，并提出了普适特征的共享理论框架。
### Conclusion
该研究提供了一个工程改进的深度神经网络性能的蓝图，通过不同初始化的训练网络以及发现拟临界区的特点，提高了网络学习效率。同时，确定了不同的普适类，为人工神经网络和大脑塑性行为之间的理论联系提供了基础。
## 273. `cs.AI` - XBOUND：在状态级别探索设备控制代理能力边界 [PDF](https://arxiv.org/pdf/2505.21279), [HTML](https://arxiv.org/abs/2505.21279)
### Authors
Shaoqing Zhang,Kehai Chen,Zhuosheng Zhang,Rumei Li,Rongxiang Weng,Yang Xiang,Min Zhang
### Background
最近，视觉-语言模型的发展激发了对设备控制代理（DC代理）的兴趣，这些代理用于管理图形用户界面（GUI）。随着此类代理在各种应用中的复杂性和集成程度增加，有效的评估方法变得至关重要。当前的评估方法主要集中在指令级别，依靠当前状态（例如截屏）和过去的执行历史来决定指令执行的动作，以识别潜在的执行失败。然而，在GUI环境中，单一状态可能包含多个交互式控件，每个控件都链接到不同的指令，可能依据不同的指令目标采取不同的行动。仅在指令级别评估代理的表现可能忽视了这些交互的更广泛背景。
### Innovation
我们提出了一种新的评估方法，XBOUND，用于以状态为单位评估指令完成的准确性。XBOUND提供了一种状态级别的评估框架，有助于评估代理在环境状态中的能力。
### Conclusion
我们的评估揭示了几个关键见解：UI-TARS展现出最强的7B模型性能，当前代理在指令联合方面表现出双峰性能模式，次于7B的模型在状态掌握方面仍然有限。我们还发现基于GPT的规划是个关键瓶颈，同时指出基础数据主要有助于动作匹配，而轨迹数据对指令联合更为有效。
## 274. `cs.AI` - 达尔文哥德尔机：自我改进代理的开放演进 [PDF](https://arxiv.org/pdf/2505.22954), [HTML](https://arxiv.org/abs/2505.22954)
### Authors
Jenny Zhang,Shengran Hu,Cong Lu,Robert Lange,Jeff Clune
### Background
现有的AI系统具有人类设计的固定架构，无法自主和持续改进。自动化AI的发展本身可以加速AI的开发进程。元学习可以自动发现新的算法，但受限于一级改进和人为设计的搜索空间。哥德尔机器提供了一种理论上的替代方案：一种能够反复以可证明有益的方式自我改进的自洽性AI。但由于实际证明大多数变化是净有益的极为困难，因此实际操作中不可行。
### Innovation
本文提出了自我改进系统达尔文哥德尔机（DGM），它迭代地修改自己的代码（进而改进自身代码修改能力），并通过编程基准验证每个更改。DGM通过从现有代理中采样并使用基础模型生成新的代理，来持续扩展代理的档案库。这种开放性探索形成了多样且高质量代理的扩展树，并允许同时探索搜索空间中的许多不同路径。实验表明，DGM自动提升了编程能力（如更好的代码编辑工具，长语境窗口管理，同行评审机制），显著提高了SWE-bench的性能（从20.0%提升到50.0%），以及Polyglot的性能（从14.2%提升到30.7%）。DGM在没有自我改进或开放性探索的基准中表现显著更好。所有实验均采取了安全预防措施（如沙盒化和人工监督）。
### Conclusion
DGM是朝向自我改进AI的重要一步，能够沿着逐渐展开的无限创新路径收集自己的跳跃点。
## 275. `cs.AI` - 在大规模语言模型方法与挑战方面的批判性回顾 [PDF](https://arxiv.org/pdf/2404.11973), [HTML](https://arxiv.org/abs/2404.11973)
### Authors
Milad Moradi,Ke Yan,David Colwell,Matthias Samwald,Rhona Asgari
### Background
本文对大规模语言模型（LLMs）进行了深入分析，覆盖了其基础原理、各种应用以及先进的训练方法。文章回顾了从递归神经网络（RNNs）到变压器模型的进化过程，突出了LLM架构的重要进步和创新。此外，探讨了最新的技术如情境学习和不同的微调方法，并着重于优化参数效率。文章还讨论了将LLMs与人类偏好对齐的方法，包括强化学习框架和人类反馈机制。此外还评估了检索增强生成技术，这种技术将外部知识整合到LLMs中。文章还讨论了部署LLMs时的伦理问题，强调负责任和审慎应用的重要性。
### Innovation
文章深入分析了从RNN到Transformer模型的演变过程，特别是在LLM架构方面的重大进步和创新。文章着重讨论了优化参数效率的各种技术，特别是情境学习和不同的微调方法。文章还评估了将外部知识整合到LLMs中以增强生成能力的检索增强生成技术，并讨论了与人类偏好的对齐方法。文章强调了在部署这些模型时要考虑到伦理问题，并为负责任和审慎应用重要性提供了见解。
### Conclusion
本文在识别现有空白并建议未来研究方向的基础上，提供了LLMs当前状态及其潜在进步的全面和批判性概述。这项工作为人工智能领域的研究人员和从业者提供了一种统一视角，概述了LLMs的优点、局限性和未来前景。
## 276. `cs.AI` - 开发和验证生成全结构化放射学报告的大语言模型 [PDF](https://arxiv.org/pdf/2409.18319), [HTML](https://arxiv.org/abs/2409.18319)
### Authors
Chuang Niu,Md Sayed Tanveer,Md Zabirul Islam,Parisa Kaviani,Qing Lyu,Mannudeep K. Kalra,Christopher T. Whitlow,Ge Wang
### Background
当前的大语言模型（LLMs）在生成完整结构化报告时面临格式错误、内容幻觉和隐私泄露等问题，特别是在上传数据到外部系统时。本文旨在解决这些问题，并开发一种开源、准确的LLM，能够从不同机构的自由文本报告中生成标准化和结构化完全的肺部结节筛查（LCS）报告，以展示其在自动统计分析和个体肺部结节检索中的实用性。研究通过现有的LLM来提升结构化报告的生成能力，并实现自动化的描述性统计分析和结节检索原型。该研究使用了5,442份从两个机构获得的匿名低剂量计算机断层扫描（LDCT）LCS放射学报告，数据覆盖了2021年1月至2023年12月的连续时间序列。
### Innovation
本文开发了一种动态模板限制解码方法，增强现有的LLM，使其能够从自由文本放射学报告中生成结构化的报告。该方法在跨机构数据集上取得了高表现，达到了约97%的F1分数，且无格式错误和内容幻觉问题。此外，此方法在最好的开源LLM上表现连续改进了10.42%，并且在GPT-4o的基础上提高了17.19%。通过结构化的报告，自动导出了统计分布，这些分布与先前关于衰减、位置、大小、稳定性以及肺部结节分级（Lung-RADS）的研究结果一致，并且检索系统支持灵活的结节级搜索和复杂的统计分析。
### Conclusion
所开发的软件为本地部署和进一步研究提供了公开可用的平台，展示了该方法在生成全结构化放射学报告方面的有效性和实用性。
## 277. `cs.AI` - 基于强化学习使多模态大语言模型适用于寻求帮助的实体代理 [PDF](https://arxiv.org/pdf/2504.00907), [HTML](https://arxiv.org/abs/2504.00907)
### Authors
Ram Ramrakhya,Matthew Chang,Xavier Puig,Ruta Desai,Zsolt Kira,Roozbeh Mottaghi
### Background
家庭环境中的实体代理需要解释模糊和不明确的人类指令。一个能力较强的家务机器人应该能够识别模糊性并提出相关澄清问题，以准确推断用户意图，进而更有效地执行任务。为了研究这个问题，我们引入了一个“询问以执行任务”任务，其中实体代理需要使用不明确的指令在一个家庭环境中完成单一或多个物体的重新排列任务。代理必须在不完全可观测的情况下，战略地提出最少且相关的澄清问题，以消除歧义。为了应对这一挑战，我们提出了一种新的方法，即使用基于在线强化学习的LLM奖励对多模态大语言模型进行微调，将其作为视觉-语言-动作（VLA）策略。这种方法避免了需要大规模的人类示范或手动工程化的奖励来训练此类代理的需求。我们的方法对比了强大的零样本基线，包括GPT-4o及监督微调的多模态大语言模型，在我们的任务中表现优于所有基线，特别是在新型场景与任务上的泛化性能明显优越（10.4-16.5%）
### Innovation
我们提出了一种使用在线强化学习微调多模态大语言模型的方法，将其转化为视觉-语言-动作（VLA）策略，用于实体代理的澄清和执行任务。这种方法无需大规模的人类示范或工整化的奖励。我们的方法优于包括GPT-4o在内的零样本基线及监督微调的多模态大语言模型，特别是在新型场景和任务上的泛化能力表现出显著的优越性
### Conclusion
这是首次展示将多模态大语言模型适应为可以使用LLM生成的奖励进行强化学习的寻求帮助和行动的实体代理。我们的方法显著优于所有基线，并展示了在新型场景和任务上的良好泛化性能
## 278. `cs.AI` - 从咕噜声到词典：合作觅食中的 emergent 语言 [PDF](https://arxiv.org/pdf/2505.12872), [HTML](https://arxiv.org/abs/2505.12872)
### Authors
Maytus Piriyajitakonkij,Rujikorn Charakorn,Weicheng Tao,Wei Pan,Mingfei Sun,Cheston Tan,Mengmi Zhang
### Background
语言是一种强大的沟通和认知工具，允许人类表达思想、共享意图和思考复杂现象。尽管人类在使用和理解语言方面非常熟练，但语言是如何出现和随时间演化的仍然是一个未解之谜。语言学和人类学中的一种主要假说是，语言进化是为了满足早期人类合作的生态和社会需求。语言不是孤立出现的，而是通过共享的生存目标逐渐发展起来的。本研究基于这一观点，探讨了如何在多智能体觅食游戏中出现语言。这些环境被设计成反映可能影响语言传播的认知和生态约束。智能体在具有部分环境知识的共享网格世界中操作，并且必须协调完成如拾取高价值目标或执行时间序列动作这样的任务。通过端到端的深度强化学习，智能体从零开始学习动作和通信策略。研究表明，智能体发展出具有自然语言特征的通信协议：任意性、互换性、延展性、文化传递和组合性。量化了每种属性，并分析了不同因素（如群体大小、社会动态和时间依赖性）如何影响语法规则的具体方面。该框架为研究如何在部分观察、时间推理和合作目标的指导下在具身多智能体设置中进化出语言提供了一个平台。我们将公开发布所有数据、代码和模型。
### Innovation
本研究利用多智能体觅食游戏环境，通过端到端的深度强化学习方法，探索语言如何在受限观察、时间推理和合作目标的指导下从零开始自然地进化出来。研究结果显示，智能体发展出的沟通方式具有自然语言的关键特征，包括任意性、互换性、延展性、文化传递和组合性。研究还分析了不同因素对这些特征的具体影响，从而提供了一个研究机制，展示语言如何在复杂的人工智能环境中生成和发展。此外，研究还策划了所有数据、代码和模型的公开共享，以促进进一步的科研和应用
### Conclusion
本研究通过模拟合作觅食环境，使用端到端的深度强化学习方法研究语言的产生过程，发现了与自然语言类似的特征，并分析了影响语言生成的因素。这一框架为语言在复杂智能体系统中的进化提供了新的视角，促进了多智能体系统中自然语言发展和应用的研究。公开共享的所有数据、代码和模型将有助于进一步的研究和实践。
## 279. `cs.AI` - 通过理论一致的对称 multimodal 偏好优化减轻幻觉 [PDF](https://arxiv.org/pdf/2506.11712), [HTML](https://arxiv.org/abs/2506.11712)
### Authors
Wenqi Liu,Xuemeng Song,Jiaxi Li,Yinwei Wei,Na Zheng,Jianhua Yin,Liqiang Nie
### Background
在多模态大型语言模型（MLLMs）中，直接偏好优化（DPO）已被证明是减少模型幻觉的有效方法。虽然现有的方法通过利用视觉导向的对比目标来增强模型对视觉输入的关注，从而大大减少了幻觉的情况，但它们仍存在优化目标不严谨和间接偏好监督的问题。
### Innovation
本文提出了一种对称多模态偏好优化（SymMPO），采用直接偏好监督（即响应对）进行对称偏好学习，以增强视觉理解能力，同时保持与标准DPO的严格理论一致性。SymMPO不仅引入了偏好边际一致性损失来量化对称偏好对之间的偏好差距，还通过广泛的五项基准评估展示了其优越的性能，验证了其在减轻MLLMs的幻觉方面的有效性。
### Conclusion
综合五个基准的评估结果表明，SymMPO在减轻MLLMs幻觉方面的性能优于现有方法，验证了其在视觉理解增强和幻觉控制方面的有效性。
## 280. `cs.AI` - InqEduAgent：基于高斯过程增强的自适应AI学习伙伴 [PDF](https://arxiv.org/pdf/2508.03174), [HTML](https://arxiv.org/abs/2508.03174)
### Authors
Wen-Xi Yang,Tian-Fang Zhao,Guan Liu,Liang Yang,Zi-Tao Liu,Wei-Neng Chen
### Background
在以探究为导向的教育中，合作伙伴的选择通常是基于经验和规则的机器助手，这在知识扩展和灵活性方面带来挑战。现有方法缺乏科学规划和灵活性，难以满足多样化学习需求。
### Innovation
提出了一种基于大规模语言模型（LLM）的代理模型，用于模拟和选择适应探究型学习的学习伙伴，命名为InqEduAgent。该模型设计生成的代理能够捕获学习者在真实场景中的认知和评估特征，通过高斯过程增强的自适应匹配算法识别先验知识模式，为不同练习的学习者提供最佳的学习伙伴匹配。
### Conclusion
实验结果表明，InqEduAgent在大多数知识学习场景和不同能力级别的语言模型环境中表现出最佳性能。这项研究促进了基于人工智能的学习伙伴的智能分配，及其在实际教育中的应用。相关代码、数据和附录可从该项目网站获得。
## 281. `cs.AI` - MMSearch-Plus：针对多媒体浏览代理的溯源意识检索基准测试 [PDF](https://arxiv.org/pdf/2508.21475), [HTML](https://arxiv.org/abs/2508.21475)
### Authors
Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong
### Background
现有的多媒体浏览基准往往未能要求真正的多媒体推理。因为许多任务可以通过仅使用文本的启发式解决，而不需要视觉信息的交互验证。因此，需要一个能够强制执行多模态理解的基准，该理解要求以迭代图像-文本检索和在检索噪声下的交叉验证来提取和传播细粒度的视觉线索。
### Innovation
引入了MMSearch-Plus基准数据集，包含311个任务，要求通过迭代的图像-文本检索和在检索噪声下的交叉验证强制执行多模态理解。数据集中的问题被精心设计，需要从空间提示和时间踪迹中推断出图像外的事实。此外，提供了一个模型无关的代理框架，其中包括标准浏览工具和一个标记集（SoM）模块，允许代理放置标记、裁剪子区域和启动有针对性的图像/文本搜索。SoM模块增强了代理在多步骤推理中的溯源意识及鲁棒性。
### Conclusion
评估了闭源和开源的MLLMs在该框架内的表现。最强的系统在端到端准确性上达到了36.0%，并集成SoM在多个场景下表现出一致的提升，最高可提高3.9个百分点。失败分析表明，主要的错误包括找出相关网页和区分视觉相似的事件。这些结果强调了现实世界多模态搜索的挑战性，并确立了MMSearch-Plus作为推动代理MLLM发展的严格基准的地位。
## 282. `cs.AI` - 领域无关的可扩展人工智能安全保障框架 [PDF](https://arxiv.org/pdf/2504.20924), [HTML](https://arxiv.org/abs/2504.20924)
### Authors
Beomjun Kim,Kangyeon Kim,Sunwoo Kim,Yeonsang Shin,Heejin Ahn
### Background
随着这些系统在真实世界应用中的越来越多的部署，人工智能安全问题已成为一个至关重要的优先事项。现有研究提出了各种安全框架，但大多局限于特定领域且对性能有所妥协。
### Innovation
本文提出了一种领域无关的人工智能安全保障框架，该框架能够在保持高性能的同时提供强大的安全保证，基于严格的理论基础。该框架包括优化组件（具有概率约束）、安全分类模型、内部测试数据、保守的测试程序、数据集质量度量以及连续的近似损失函数和梯度计算。此外，本文还首次在人工智能安全研究中建立了数据量与安全-性能折衷关系的缩放定律。
### Conclusion
跨强化学习、自然语言生成和生产规划领域的实验验证了该框架，并展示了其优越性能。特别是在强化学习中，本文框架在10M行动中仅出现3次碰撞，而与之在性能水平相当的PPO-Lag基线相比，碰撞数减少到了1,000-3,000次。该研究认为，该框架为安全人工智能部署提供了一个新的基础，特别是在关键安全领域。
## 283. `cs.AI` - 在推理模型中的第一印象问题：内部偏见引发过度思考 [PDF](https://arxiv.org/pdf/2505.16448), [HTML](https://arxiv.org/abs/2505.16448)
### Authors
Renfei Dang,Zhening Li,Shujian Huang,Jiajun Chen
### Background
推理模型经常表现出过度思考的现象，这些模型在推理过程中往往会进行冗余的推理步骤。研究表明，输入问题引发的内部偏见可能是导致这种行为的重要原因。当模型在遇到问题时，会立即对答案形成初步猜测，这一猜测甚至可能在没有系统推理的情况下产生。当这种猜测与后续推理发生冲突时，模型会倾向于进行大量的反思，导致不必要的计算资源浪费。这种过度思考现象在多种模型和不同类型的推理任务中都有出现。
### Innovation
本文通过一系列实验证实了内部偏见与过度思考之间的联系，并展示了去除输入问题可以在各种复杂推理任务中减少冗余推理。进一步的解释性实验表明，过度关注输入问题是一个关键机制，它通过内部偏见影响后续的推理轨迹。此外，作者还评估了多种旨在减轻过度思考的方法，但都未能完全消除内部偏见的影响。
### Conclusion
研究表明，内部偏见在推理模型中引发了过度思考的问题。去除输入问题可以减少冗余推理，而过度关注输入问题则是通过内部偏见影响后续推理轨迹的关键机制。尽管评估了几种方法来减轻过度思考，但内部偏见的影响仍然存在。
## 284. `cs.AI` - 增强大型语言模型长上下文推理能力的Reasoning BO [PDF](https://arxiv.org/pdf/2505.12833), [HTML](https://arxiv.org/abs/2505.12833)
### Authors
Zhuo Yang,Daolang Wang,Lingli Ge,Beilun Wang,Tianfan Fu,Yuqiang Li
### Background
许多实际科学和工业应用需要优化昂贵的黑盒函数。传统的贝叶斯优化（BO）方法容易陷入局部最优，并且缺乏可解释的洞察。为了解决这些问题，该论文设计了一种新型框架——Reasoning BO，该框架利用推理模型指导BO的过程，并结合多智能体系统和知识图谱进行在线知识积累。通过将大型语言模型（LLMs）的推理和上下文理解能力集成到优化过程中，可以为BO提供强有力的支持，增强优化过程。随着优化的进行，Reasoning BO能够实时提供采样建议，并结合合理的科学理论提供关键见解，从而在搜索空间中发现更优的解。研究表明，在10个不同的任务中，包括合成数学函数和复杂的实际应用，该框架通过实时洞察和假设演化逐步精炼采样策略，能够有效识别更高性能的搜索区域进行探索。例如，在直接偶联任务中，我们的方法将产率提高到60.7%，而传统的贝叶斯优化方法只有25.2%的产率。进一步的研究显示，经过强化学习微调的小型LLMs可以达到与大型LLMs相似的表现。
### Innovation
传统的贝叶斯优化方法容易陷入局部最优并且缺乏解释性洞察。论文设计了一种名为Reasoning BO的新框架，它利用推理模型来指导BO的采样过程，同时结合多智能体系统和知识图谱进行在线知识积累。通过集成大型语言模型的推理和上下文理解能力，为优化过程提供强大的指导。随着优化过程的进行，Reasoning BO提供实时的采样建议，并基于合理的科学理论提供关键洞察，有助于在搜索空间中发现更优解决方案。研究表明，在不同任务中，该框架通过实时洞察和假设演化逐步改进采样策略，有效地识别更高性能的搜索区域进行探索。此外，研究还发现，经过强化学习微调的小型大型语言模型可以与大型模型达到相似的表现。
### Conclusion
该论文设计的Reasoning BO框架结合了大型语言模型的推理能力和上下文理解能力，显著提高了贝叶斯优化的效率和准确率。通过在不同任务中的系统评估，该框架有效地展示了其逐步细化采样策略能力，并通过实时洞察和假设演化识别了更高性能的搜索空间区域。这种方法为优化领域提供了一种新的、强健的解决方案，并证明了大型语言模型在实际优化应用场景中的强大推理和情境学习能力。
## 285. `cs.AI` - 可扩展的上下文Q学习 [PDF](https://arxiv.org/pdf/2506.01299), [HTML](https://arxiv.org/abs/2506.01299)
### Authors
Jinmei Liu,Fuhong Liu,Jianye Hao,Bo Wang,Huaxiong Li,Chunlin Chen,Zhi Wang
### Background
近期语言模型展示了非凡的上下文学习能力，激发了在决策领域探索上下文强化学习（ICRL）的兴趣。然而，ICRL方法在处理复杂动态和时间相关性时仍面临挑战，尤其是在从次优轨迹中学习和实现精确上下文推断方面。
### Innovation
本文提出了一种创新框架SCALABLE IN-CONTEXT Q-LEARNING (SICQL)，结合了动态规划和世界建模，使其能够高效地最大化奖励，实现任务泛化，同时保持监督预训练的可扩展性和稳定性。SICQL设计了一个基于提示的多头Transformer架构，同时预测最优策略和上下文值函数。通过预训练通用世界模型来捕捉任务相关信息，可以构建一个紧凑的提示，增强上下文推理的高效性和精确性。在训练过程中，通过拟合状态值函数到Q函数的上分位数，进行迭代的政策改进，并使用优势加权回归将上下文值函数提炼为策略提取。
### Conclusion
本文在一系列离散和连续环境中进行了广泛实验，结果显示SICQL相对于各种基线方法的一致性能提升，尤其是在学习次优数据时表现尤为突出。代码可在该链接找到。
## 286. `cs.AI` - AgentOrchestra: 使用工具-环境-代理(TEA)协议 orchestrating 分层多智能体智能 [PDF](https://arxiv.org/pdf/2506.12508), [HTML](https://arxiv.org/abs/2506.12508)
### Authors
Wentao Zhang,Liang Zeng,Yuzhen Xiao,Yongcong Li,Ce Cui,Yilei Zhao,Rui Hu,Yang Liu,Yahui Zhou,Bo An
### Background
基于大型语言模型（LLMs）的代理系统近年来展现了解决复杂任务的能力。然而，现有的协议（如A2A和MCP）存在上下文管理不足、环境适应性差以及缺乏动态代理架构的问题。
### Innovation
本文提出了Tool-Environment-Agent（TEA）协议，解决了现有协议的问题。TEA协议将环境和代理视为一级资源，支持全面的上下文管理和动态环境集成。基于此协议，提出了AgentOrchestra框架。AgentOrchestra是一个分层多代理框架，包含一个中枢规划代理，能够分解复杂目标并协调专用代理。每个子代理专注于特定功能，支持数据分析、文件操作、网页导航和交互式推理。此外，AgentOrchestra引入了工具管理代理，支持通过动态工具创建、检索和重用机制实现智能进化。实验表明，AgentOrchestra在三个常用基准上持续超越现有基线，在GAIA上实现了83.39%的性能（领先水平），并在通用型LLM代理中排名靠前。
### Conclusion
TEA协议和分层组织有效促进了通用型多代理系统的构建。AgentOrchestra框架在复杂任务解决方案上展示了卓越的表现，并在多个基准测试中名列前茅，验证了创新的有效性。
## 287. `cs.AI` - 大型语言模型中的认知负荷限制：多跳推理基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
随着大型语言模型（LLMs）的扩展，模型在静态基准测试上的表现与其在动态、信息丰富环境中的脆弱性之间的差距变得明显。尽管模型在单一任务中表现优异，但在认知负荷下的推理能力受到的计算限制仍然不被完全理解。本文探讨了认知负荷对模型动态推理能力的影响。
### Innovation
本文引入了一种形式化的认知计算负荷理论，认为与任务无关的额外信息（Context Saturation）和任务切换带来的注意力残留（Attentional Residue）是降低性能的关键机制。设计了交错认知评估（ICE）基准测试，该基准测试系统地操纵了这些负荷因素，对复杂的多跳推理任务进行了研究。
### Conclusion
研究发现认知负荷是推理失败的关键因素，并支持了在不确定性条件下幻觉是一种猜测的理论。研究表明，动态的认知意识压力测试（如ICE基准测试）是评估高级AI系统真正韧性和安全性的必要手段。
## 288. `cs.AI` - SEDM: 可扩展的自我演化的分布式记忆系统 [PDF](https://arxiv.org/pdf/2509.09498), [HTML](https://arxiv.org/abs/2509.09498)
### Authors
Haoran Xu,Jiacong Hu,Ke Zhang,Lei Yu,Yuxin Tang,Xinyuan Song,Yiqun Duan,Lynn Ai,Bill Shi
### Background
长期运行的多智能体系统会产生大量轨迹和历史交互，这使得高效的记忆管理对于性能和可扩展性至关重要。现有方法通常依赖向量检索和分层存储，但它们容易受到噪声积累、无控的记忆扩展以及跨领域有限泛化的困扰。
### Innovation
我们提出了SEDM（Self-Evolving Distributed Memory），这是一种可验证和自适应的框架，将记忆从被动存储转变为积极、自我优化的组件。SEDM整合了基于可重现重放的可验证写入准入、一种自调度的内存控制器，该控制器根据经验效用动态排名和合并条目，以及跨领域知识扩散，将可重用的见解抽象出来以支持异构任务的知识迁移。
### Conclusion
在基准数据集上的评估表明，SEDM在保持高度准确性的同时，减轻了令牌开销，并进一步通过事实验证/distilled知识增强多跳推理。结果突出显示SEDM是开放多智能体协作中可扩展和可持续的记忆机制。
## 289. `cs.AI` - LocationReasoner: 在现实世界站点选择推理中评估大型语言模型 [PDF](https://arxiv.org/pdf/2506.13841), [HTML](https://arxiv.org/abs/2506.13841)
### Authors
Miho Koda,Yu Zheng,Ruixian Ma,Mingyang Sun,Devesh Pansare,Fabio Duarte,Paolo Santi
### Background
近年来，通过强化后训练增强的大规模语言模型（LLMs）展示了卓越的推理能力，例如OpenAI的o1和DeepSeek的R1模型，尤其是在数学问题解决和代码生成等领域表现出色。然而，这些模型的推理能力大多是在特定领域的基准测试中得到验证的，尚未充分证明其能否有效应用于复杂的现实世界场景。为了弥补这一空白，本研究设计了一个名为 LocationReasoner 的基准测试，专门评估LLMs在复杂现实世界选址问题中的推理能力。该基准测试涵盖各类精细设计的难度各异的查询，并提供了一个基于约束的地点搜索沙盒环境，以自动化验证方式保证基准的可扩展性，可以增加任意数量的查询。对波士顿、纽约和坦帕的现实世界选址数据进行的广泛评估表明，最先进的推理模型在现实世界情境中对非推理模型的改进有限，甚至最新的OpenAI o4模型在30%的选址任务上也表现不佳。此外，如 React 和 Reflexion 等代理策略往往过度推理，导致结果不如直接提示有优势。
### Innovation
本研究提出了一个名为 LocationReasoner 的基准测试，专门评估LLMs在现实世界选址问题中的推理能力。这一基准测试旨在填补LLMs在解决复杂现实世界任务中推理能力不足这一空白。设计上的创新之处在于它通过包含严格设计的查询、一个动态化的沙盒环境以及一种自动化验证方式，来确保基准测试能够有效评估复杂的现实世界场景中的推理能力。
### Conclusion
广泛的实验显示，在现实世界情境下的大多数最先进的推理模型并不能明显提升实际效果，甚至在某些情况下表现更差。因此，研究强调了LLMs在整体和非线性推理方面的局限性，并希望通过提供 LocationReasoner 基准测试来推动开发更强大、更适用于现实世界决策任务的LLMs和代理模型。
## 290. `cs.AI` - 从根到奖励：基于强化学习的动态树推理 [PDF](https://arxiv.org/pdf/2507.13142), [HTML](https://arxiv.org/abs/2507.13142)
### Authors
Ahmed Bahloul,Simon Malberg
### Background
现代语言模型通过链式推理（CoT）和检索增强（Lewis等，2021年）来处理复杂问题，但存在错误传播和知识整合的问题。ProbTree（Cao等，2023年）通过将问题分解为层次结构，并通过参数化和检索知识的置信加权聚合来选择答案，缓解了这些问题。然而，ProbTree的静态实现带来了两个关键限制：推理树在初始构建阶段被固定，无法动态适应中间结果；每个节点需要对所有可能的解决方案策略进行耗时的评估，导致计算效率降低。
### Innovation
本文提出了一种基于强化学习（Sutton和Barto，2018年）的动态框架，将基于树的推理转化为一个适应性过程。该方法根据实时置信评估增量构建推理树，同时学习用于行动选择（分解、检索或聚合）的最佳策略。这种方法在保持ProbTree的概率严谨性的同时，通过选择性扩展和聚焦资源分配提高了解决问题的质量和计算效率。这项工作建立了一种新的基于树的推理范式，既平衡了概率框架的可靠性，又适应了现实世界问答系统的灵活性。
### Conclusion
本文的工作确立了一种基于树结构推理的新范式，该范式在保持概率框架可靠性的同时，通过灵活的策略优化提高了系统的性能和效率。该成果代码可以在给出的链接处获得。
## 291. `cs.AI` - 动态上下文适应：基于检索增强生成的一致性角色扮演代理 [PDF](https://arxiv.org/pdf/2508.02016), [HTML](https://arxiv.org/abs/2508.02016)
### Authors
Jeiyoon Park,Yongshin Han,Minseop Kim,Kisu Yang
### Background
近年来，大规模语言模型（LLMs）的进展激发了对角色扮演代理（RPAs）的研究。然而，收集角色特定的言谈和持续更新模型参数以跟上快速变化的人物属性，是一个资源密集型的过程。尽管检索增强生成（RAG）可以减轻这些困难，但如果一个角色的知识与查询无关，基于RAG的RPAs可能会出现幻觉，这使得准确生成答案变得困难。因此，需要开发一种新的框架来提高角色的个性一致性，即使是在角色不知晓的知识领域回答问题时也能保持一致性。
### Innovation
我们提出了一种名为Amadeus的训练无需框架，通过适应性上下文感知文本分割（ACTS）、引导选择（GS）和属性提取器（AE）三个模块来增强人物角色的一致性。ACTS将每个角色的性格信息分割成适中的重叠片段，并与层次上下文信息相结合。AE通过提取由GS检索的片段中的通用属性，利用这些属性作为最终上下文，即使在回答角色知识外的问题时也能保持强大的一致性。此外，我们手动构建了一个名为CharacterRAG的角色扮演数据集，包括15个不同虚构角色的1976K个字符，和450个问题-答案对，这将支撑基于RAG的RPAs的发展和严谨评估.
### Conclusion
我们提出的方法不仅可以有效建模人物角色的知识，也能建模诸如个性等多样的属性，从而在回答角色知识外的问题时也能够保持一致性。
## 292. `cs.AI` - VDFD: 解耦世界模型的多智能体价值分解框架 [PDF](https://arxiv.org/pdf/2309.04615), [HTML](https://arxiv.org/abs/2309.04615)
### Authors
Zhizun Wang,David Meger
### Background
多智能体系统中的代理在相同的环境中相互作用，实现共同目标具有挑战性，特别是在可扩展性和非平稳性问题上，模型自由方法依赖大量样本进行培训。传统的多智能体强化学习方法在处理这些问题时，效率低下、样本复杂度高。
### Innovation
本文提出了一种名为Value Decomposition Framework with Disentangled World Model（VDFD）的新颖多智能体强化学习方法。通过构造行动条件分支、自由行动分支和静态分支来解耦环境动力学，不直接从真实环境采样而是基于以往经验生成设想的结局，使用变分自编码器和变分图自编码器学习世界模型的潜在表示，并结合价值基于框架预测联合动作价值函数，优化整体训练目标。
### Conclusion
在StarCraft II微管理、Multi-Agent MuJoCo和Level-Based Foraging挑战中的实验结果表明，我们的方法具有高样本效率和优于其他基准的性能，在多种多智能体学习任务中表现出优越性。
## 293. `cs.AI` - EigenBench: 一种价值对齐的比较性行为测量方法 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
人工智能与人类价值观的对齐是一个亟待解决的问题。当前缺乏可以定量衡量价值对齐的指标，因此本文提出了EigenBench：一种黑盒方式用于语言模型价值的对比性基准测试方法。方法基于模型对其他模型输出的判断，通过EigenTrust算法聚合生成反映整个模型集合共识判断的分数，以此来量化模型的价值对齐程度。这种方法无需使用任何客观标签，因为其目的是量化主观特质，对于这些问题合理评判者可能在正确的标签上存在分歧。
### Innovation
提出了EigenBench方法作为衡量缺乏客观标签的主观价值观的一种黑盒基准测试方法。该方法通过比较模型对其他模型输出的判断，并通过EigenTrust算法聚合生成反映整个模型集合的共识判断分数。这种方法成功实现了模型价值对齐的量化比较，无需依赖客观标签，展示了其在面对没有客观标准的问题时的有效性。
### Conclusion
通过收集人类对同一组模型的判断并向人类评估者验证了EigenBench的方法，证明其判决与人类评估者的评分相接近。进一步实验表明，该方法可以在没有任何客观标签的情况下，恢复模型在GPQA基准上的排名，支持该方法作为评估缺乏客观标准的主观价值观框架的有效性。
## 294. `cs.AI` - 乳腺癌筛查的多视角超复数学习 [PDF](https://arxiv.org/pdf/2204.05798), [HTML](https://arxiv.org/abs/2204.05798)
### Authors
Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello
### Background
放射科医生在解读乳腺X光摄影时，会联合分析四个视角的影像，因为各视角之间的关联对于精确诊断至关重要。现有的方法使用专门的融合模块来捕捉这些依赖关系，但这些方法往往受到视角主导、训练不稳定和计算开销大的问题困扰。
### Innovation
为了应对这些问题，本研究引入了多视角超复数学习，该方法基于参数化的超复数神经网络（PHNNs），利用超复数代数可以固有地捕捉内部和外部视角的关系。为此，提出了两种视角的PHResNets模型和两种互补的四视角架构：PHYBOnet，优化效率；PHYSEnet，优化准确率。
### Conclusion
广泛的实验表明，该方法在乳腺癌分类等多视角模型上持续优于现有技术水平，同时跨影像学模态和任务（如胸部X射线疾病分类和多模态脑肿瘤分割）实现了泛化。完整的代码和预训练模型可在此处获取。
## 295. `cs.AI` - 对齐的本质：通过引导稀疏特征进行偏好优化的分解 [PDF](https://arxiv.org/pdf/2509.12934), [HTML](https://arxiv.org/abs/2509.12934)
### Authors
Jeremias Ferrao,Matthijs van der Lende,Ilija Lichkovski,Clement Neo
### Background
当前的对齐方法会导致模型参数变得不透明，难以审计模型真正学到的内容。研究表明，这种方法使得模型难以追踪其对任务的真正学习过程。本文旨在解决这一问题，提出了一种新的框架——Feature Steering with Reinforcement Learning (FSRL)，该框架通过调节可解释的稀疏特征来训练一个轻量级的适配器，以引导模型行为。
### Innovation
提出了一种新的框架——Feature Steering with Reinforcement Learning (FSRL)，利用强化学习训练一个轻量级适配器，通过调节解释性稀疏特征来引导模型行为。通过理论分析证明了该机制能够近似后训练过程中行为的改变，并将其应用于偏好优化任务，通过因果分析理解了所学策略。研究发现，在某些情况下，模型倾向于通过样式表现来代替质量表现，忽略了与对齐概念相关的重要特征，但FSRL有效降低了偏好损失，证明了其实用性。
### Conclusion
总体而言，FSRL 提供了一种可解释的控制接口，为理解偏好优化压力在特征层面的具体表现提供了一个实际可行的方法。
## 296. `cs.AI` - 基于范数采样和正交性的多样化子集选择 [PDF](https://arxiv.org/pdf/2406.01086), [HTML](https://arxiv.org/abs/2406.01086)
### Authors
Noga Bar,Raja Giryes
### Background
大型标注数据集对深度神经网络的成功至关重要，但在诸如医学影像等领域，标注数据可能成本高昂。本文关注从大量未标注数据中选择最具信息性的部分样本进行标注的子集选择问题。
### Innovation
提出了一种简单且有效的基于范数采样和正交性的多样性和信息性样本选择方法。该方法利用特征范数作为信息性代理，随机化和正交化减少冗余并促进特征空间覆盖。
### Conclusion
在包含CIFAR-10/100、Tiny ImageNet、ImageNet、OrganAMNIST和Yelp等图像和文本基准的数据实验中，该方法在独立使用和与现有技术结合使用时，一致提升了子集选择性能。
## 297. `cs.AI` - 通过学习多样化思维链模式扩展基础模型的推理潜力 [PDF](https://arxiv.org/pdf/2509.21124), [HTML](https://arxiv.org/abs/2509.21124)
### Authors
Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai
### Background
近期，大型推理模型在解决复杂数学问题方面取得了显著进展，尤其是在强化学习（RL）的应用下。研究还发现，在中期训练过程中纳入长链式思考（CoT）数据可以显著提升推理深度，但现有的方法往往不加区分地使用CoT数据，导致一个关键问题尚未回答：哪些数据类型最有效地增强模型的推理能力。
### Innovation
本文首次定义了基础模型的推理潜力为其正确回答问题所需独立尝试次数的倒数，并且这项指标与最终模型性能密切相关。提出了利用丰富多样化推理模式的数据来扩展推理潜力。通过抽象CoT序列中的原子推理模式，构建了一个包含有价值推理模式的核心参考集，设计了一种多层次算法（涉及推理模式链和标记熵），并高效选择与核心集相符的高价值CoT数据进行模型训练，从而实现有效推理。
### Conclusion
仅使用10B令牌的有价值的CoT数据，使85A6B混和专家模型（MoE模型）在2024和2025年的AIME竞赛上性能提高了9.58%，并在下游RL性能上提高了7.81%的上限。
## 298. `cs.AI` - STAR-XAI协议：实现和验证AI代理的行动、推理和可靠性的框架 [PDF](https://arxiv.org/pdf/2509.17978), [HTML](https://arxiv.org/abs/2509.17978)
### Authors
Antoni Guasch,Maria Isabel Valdez
### Background
大型推理模型（LRMs）的“黑箱”性质在可靠性和透明度上提出了关键限制，引发了关于“思考错觉”和代理系统中状态错觉的辩论。因此，论文介绍了一种名为STAR-XAI协议的新颖运行方法，以培训和操作可验证可靠的AI代理。这种方法重新定义了人类与AI的互动，作为一个结构化苏格拉底式对话，并引入了清晰框架来改善透明度和可靠性，包括一个校验和机制以消除内部状态的错误。这项研究通过在复杂的策略游戏“Caps i Caps”中进行详尽的案例研究，证明了这种“透明箱”框架可以将一个不透明的LRM转变为一名有纪律的战略家。
### Innovation
这种STAR-XAI协议作为一种新颖的操作方法，旨在通过一个结构化苏格拉底式对话和严谨的协议框架，使AI agent不仅表现出复杂的战略，还能进行事前透明沟通，并通过识别和纠正其自己的监督批准计划中的错误，展示了第二级代理能力。通过对‘Caps i Caps’游戏的案例研究，证明其能够实现100%可靠的状态跟踪和设计上实现无错觉的目标，从而提供了一种构建高表现、可审计、可信和可靠的AI代理的实践途径。
### Conclusion
STAR-XAI协议提供了一条实际路径，以构建不仅高表现，而且本质上可审计、可信和可靠的AI代理。通过引入STAR-XAI协议，论文展示了如何通过透明的交互和固定的机制确保AI代理的可靠性和透明度，从而推动了可靠性和透明度在AI代理中的应用。
## 299. `cs.AI` - TrustJudge：LLM作为评判者的一致性问题及其缓解方法 [PDF](https://arxiv.org/pdf/2509.21117), [HTML](https://arxiv.org/abs/2509.21117)
### Authors
Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang
### Background
目前使用大型语言模型（LLM）作为自动评估器（LLM-as-a-judge）时，发现当前评估框架存在重要的一致性问题。这些问题主要包括：评分对比不一致（评分较低的回答在一对一比较中优于高分回答）和偏序关系不一致（如A>B>C>A的循环偏好链和等同矛盾）。这些差异源于离散评分系统的信息丢失以及交叉评估中的模糊判定。
### Innovation
TrustJudge提供的两大创新点是：1）基于分布的打分方式，通过离散评分概率计算连续期望，保持信息熵以提供更精确的评分；2）基于可能性的聚合方法，使用双向偏好概率或困惑度解决偏序关系的违背问题。该框架还为现有LLM作为评判者体系的理论局限性提供了规范，展示了其实现这些改进的能力。
### Conclusion
TrustJudge对LLM作为评判者方案中的评分对比不一致和偏序关系不一致分别减少了8.43%（从23.32%到14.89%）和10.82%（从15.22%到4.40%），并在保持较高评估准确率的情况下提供了理论见解和实用方案，使LLM评估更加可靠。此外，该框架在多种模型架构和规模下表现出一致性的改进，能够在不依赖额外训练或人工注释的情况下进行更可信的LLM评估。
## 300. `cs.AI` - 生物圈AI [PDF](https://arxiv.org/pdf/2401.17805), [HTML](https://arxiv.org/abs/2401.17805)
### Authors
Marcin Korecki
### Background
当前人工智能伦理和价值对齐的核心范式高度以人为中心，这些学科集中在人类价值观上，限制了其深度和广度的洞察力。最近，开始尝试扩展到情感主义视角，但这两者都不足以捕捉到生物圈的复杂性，确保人工智能不会对其造成损害。
### Innovation
本文提出了一个新的范式——生物圈AI，它假设生态中心的视角，讨论了这种AI可能的设计方式，并为与生物圈利益一致的现代AI模型的研究和应用提供了方向，旨在推动全面的研究计划，关注AI与生物圈之间的互动。
### Conclusion
这项工作试图迈出实现全面研究计划的第一步，该计划重点在于AI与生物圈之间的互动。
## 301. `cs.AI` - 在回归集成模型中使用成对距离估算器进行高效的知识型不确定性估计 [PDF](https://arxiv.org/pdf/2308.13498), [HTML](https://arxiv.org/abs/2308.13498)
### Authors
Lucas Berry,David Meger
### Background
本文介绍了一种利用成对距离估算器（PaiDEs）评估集成模型在回归任务中知识型不确定性的新颖有效方法。传统的样本基于蒙特卡罗估算器在估计知识型不确定性时存在速度慢的问题，且不适用于高维输入。本文提出的方法通过计算模型组件之间的成对距离来建立熵的边界，显著提高了BA LD在分类中的性能，并能同时处理更多的输入，特别是在高维空间中表现更优。通过在广泛使用的回归基准数据集（如1D正弦波数据、Pendulum、Hopper、Ant 和Humanoid）上进行的实验验证了该方法的有效性，并且实验结果表明该方法在高维回归任务中优于现有方法。
### Innovation
本文提出了一种新的方法——成对距离估算器（PaiDEs），用于在回归集成模型中高效估计知识型不确定性。与基于采样蒙特卡罗估算器相比，PaiDEs在估计速度上快100倍，并且能够处理更多输入。此外，该方法在高维输入空间中表现出优越性能。我们在一系列常见的回归基准实验中应用了一个活跃学习框架来展示PaiDEs的优势，并证明了其在高维回归任务中的卓越表现。
### Conclusion
我们提出的方法在高维回归任务中的表现优于现有方法。成对距离估算器相比基于样本的蒙特卡罗估算器，在速度快100倍的同时提供了更好的性能。该方法的有效性已经在不同类型的回归基准数据集上得到了验证。
## 302. `cs.AI` - MACD：具有自学习知识的大语言模型多代理临床诊断 [PDF](https://arxiv.org/pdf/2509.20067), [HTML](https://arxiv.org/abs/2509.20067)
### Authors
Wenliang Li,Rui Yan,Xu Zhang,Li Chen,Hongji Zhu,Jing Zhao,Junjun Li,Mengru Li,Wei Cao,Zihang Jiang,Wei Wei,Kun Zhang,Shaohua Kevin Zhou
### Background
大型语言模型（LLMs）在医疗应用中显示出显著潜力，但它们在使用传统提示方法处理复杂临床诊断时面临巨大挑战。当前的提示工程和多代理方法通常优化孤立的推理，忽视了积累可重复使用的临床经验的重要性。这些方法未能充分模拟医生通过经验和案例积累专业知识的过程，特别是在针对特定疾病的关键诊断线索上欠缺专注和准确性。这促使研究开发了一个新型多代理临床诊断（MACD）框架，旨在通过多代理管道总结、细化并应用诊断见解，让LLMs能够自我学习临床知识。这款框架借鉴了医生通过实践经验提升专业能力的方式，使得诊断过程更加精准和集中。
### Innovation
该研究提出了一个名为MACD的新颖多代理临床诊断框架，该框架允许LLMs通过多代理管道自我学习临床知识，总结、细化并应用诊断见解。这一框架借鉴了医生通过实践经验提升其能力的方式，使得诊断过程更加专注和准确。进一步地，该研究扩展了MACD框架，加入了一个评价代理和人类监督机制，以促进多个基于LLM的诊断代理在 iteration 中的咨询协作，特别是在有分歧的情况下由人类进行监督。这种方法通过实证研究证明了在真实世界患者的7种不同疾病案例中，能够显著提高初期诊断准确性，特别是在与医学专家相同的评价标准下，表现出与专家诊断或优于专家诊断的能力，同时展示了人机协作的协同效应。自学习的知识在不同LLM模型之间表现出高度的稳定性和跨模型迁移能力，这对构建可扩展的自学习范式具有重要意义，这种范式填补了LLM固有知识与临床实践之间的差距。
### Conclusion
MACD多代理临床诊断框架显著提升了临床诊断的准确性，尤其是在与具体的临床指南相比，改进幅度可达22.3%。与仅由医生进行的诊断相比，MACD在相同评估协议下实现了相当甚至更好的性能，性能改进达到16%。进一步，在人机协作的工作流程中，MACD的表现比仅医生的诊断提高了18.6%，这展示了人机协作的协同效应。自学习的临床知识在不同LLM模型之间表现出高度的稳定性和跨模型迁移能力，展示了一种可扩展的自学习范式，这一范式有效连接了LLM的内在知识和临床实践。
## 303. `cs.AI` - 机器学习辅助的锂离子电池可持续再制造、再利用和回收 [PDF](https://arxiv.org/pdf/2406.00276), [HTML](https://arxiv.org/abs/2406.00276)
### Authors
Shengyu Tao
### Background
锂离子电池（LIBs）的可持续利用对于全球能源转型和碳中和至关重要，但数据稀缺性和异质性仍然是再制造、再利用和回收过程中的主要障碍。因此，需要一个能够解决这些问题的机器学习辅助框架，涵盖电池全生命周期。该框架需要解决质量控制、剩余价值评估、阴极材料分类和诊断预测等方面的问题，以应对数据不足和条件变化的挑战。
### Innovation
开发了一种机器学习辅助框架，以解决锂离子电池全生命周期中的数据稀缺性和异质性问题。具体包括：1. 基于物理信息的质量控制模型，通过有限的早期循环数据预测长期降解；2. 基于生成学习的残余价值评估方法，快速准确地评估退役电池在随机条件下的剩余价值；3. 采用联邦学习策略实现隐私保护和高精度的阴极材料分类，支持高效的回收；4. 基于相关性对齐的统一诊断和预测框架，增强在不同测试协议下的适应性，提高健康状态估计、荷电量估计和剩余使用寿命预测的准确性。
### Conclusion
这些贡献推进了可持续电池管理，通过整合物理学、数据生成、隐私保护合作和适应性学习，提供了方法论创新，以促进循环经济和全球碳中和。
## 304. `cs.AI` - DOTA: 分布式视觉语言模型测试时自适应 [PDF](https://arxiv.org/pdf/2409.19375), [HTML](https://arxiv.org/abs/2409.19375)
### Authors
Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang
### Background
视觉语言基础模型（VLMs），例如CLIP，在各种任务上表现出色。然而，当训练数据和测试数据之间存在显著分布差距时，部署这些模型可能会不可靠，而针对多样场景进行微调往往成本高昂。基于缓存的测试时间适配器提供了一种替代方案，它们通过存储代表性测试样本来指导后续分类，但这些方法通常采用简化的缓存管理策略，导致样本在更新中不可避免地被丢弃时发生严重的灾难性遗忘。
### Innovation
本文提出了一种名为DOTA（分布式测试时间自适应）的简单但有效的方法，解决了上述问题。DOTA 不仅存储测试样本，还会不断估计测试数据流的底层分布。通过贝叶斯定理使用动态估计的分布来计算测试后的概率，从而实现自适应。这种以分布为中心的方法使得模型能够持续学习并适应部署环境。
### Conclusion
通过广泛的实验，验证了DOTA在减轻忘记现象的同时，取得了与现有方法相比的领先性能。
## 305. `cs.AI` - 使用强化学习提高大型语言模型的语言理解能力 [PDF](https://arxiv.org/pdf/2410.11020), [HTML](https://arxiv.org/abs/2410.11020)
### Authors
Bokai Hu,Sai Ashish Somayajula,Xin Pan,Pengtao Xie
### Background
小于140亿参数的指令微调大型语言模型（LLMs）在自然语言理解（NLU）任务中持续表现不佳，往往在GLUE和SuperGLUE等基准测试中落后于较小的模型，如BERT-base。
### Innovation
通过使用Proximal Policy Optimization (PPO)框架，将NLU任务作为强化学习环境，将标记生成视为一系列行动，目标是最大化与正确标签一致的奖励信号，从而提升LLMs的NLU能力。实验表明，PPO比监督微调更有效，GLUE平均提高了6.3点，并且在零样本和少量样本提示性能上分别提高了38.7和26.1点。值得注意的是，PPO微调的模型在情感和自然语言推理任务中比GPT-4o平均高出4%以上，特别是在情感健康数据集和SIGA-nli上的表现分别提高了7.3%和10.9%。
### Conclusion
该研究展示了通过将LLMs重新构想为强化学习问题来适应新任务的前景，使其能够通过简单的任务结束奖励进行学习，而不是需要大量数据整理。
## 306. `cs.AI` - 在 Alzheimer's 病检测中的类内变异性问题 [PDF](https://arxiv.org/pdf/2409.16322), [HTML](https://arxiv.org/abs/2409.16322)
### Authors
Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng
### Background
阿尔茨海默病（AD）检测通常使用机器学习分类模型来区分患有 AD 和未患 AD 的个体。不同于传统的分类任务，AD 检测面临一个重要的挑战，即类内变化：患有 AD 的个体表现出认知功能衰退的多样性。因此，简单的二元 AD 分类可能忽视了两类关键方面：类内异质性和实例级不平衡。
### Innovation
在本研究中，作者发现使用样本分数估算器可以生成与认知评分相匹配的样本特异性软评分。他们随后提出了两种简单而有效的方法：软目标蒸馏 (SoTD) 和实例级重新平衡 (InRe)，分别针对两个问题。通过 ADReSS 和 CU-MARVEL 数据集，作者展示了并分析了所提出方法在检测性能方面的优势。
### Conclusion
这些发现为开发稳健可靠的 AD 检测模型提供了见解。
## 307. `cs.AI` - 经典机器学习模型与大型语言模型在高维表格数据下 COVID-19 死亡率预测的表现对比 [PDF](https://arxiv.org/pdf/2409.02136), [HTML](https://arxiv.org/abs/2409.02136)
### Authors
Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini
### Background
本研究对比了经典特征基础的机器学习模型（CMLs）和大型语言模型（LLMs）在使用来自四个医院的9,134名患者的高维表格数据预测COVID-19死亡率时的性能。为了评估LLMs的性能，研究使用了零样本分类方法，并对Mistral-7b进行了QLoRA微调。背景信息强调了CMLs在处理高维度表格数据任务方面的优势，同时也探讨了LLMs通过微调来提升其在医学预测建模中的潜力，尤其是在结构化数据分析方面的重要性。
### Innovation
本研究创新之处在于首次系统地比较了CMLs和LLMs在COVID-19死亡率预测中的表现，特别是通过将LLMs应用于文本转换的结构化数据的零样本分类，并通过QLoRA方法对Mistral-7b进行微调，从而显著提高了其性能。研究发现，尽管LLMs在零样本分类中有中等表现，但经过微调后明显提升了其稳定性与效果，具有潜在的替代CMLs的能力。然而，当前CMLs在处理高维度表格数据任务上仍然具有优势。
### Conclusion
本研究不仅突显了CMLs和微调后的LLMs在医学预测建模中的潜力，同时也明确了CMLs在结构化数据分析方面的当前优势。研究结果表明，尽管LLMs展现了改进潜力，但它们在短期内仍难以在处理高维度表格数据方面超越CMLs。
## 308. `cs.AI` - VeriFlow: 模型化神经网络验证的分布 [PDF](https://arxiv.org/pdf/2406.14265), [HTML](https://arxiv.org/abs/2406.14265)
### Authors
Faried Abu Zaid,Daniel Neider,Mustafa Yalçıner
### Background
形式化验证作为确保神经网络安全和可靠性的有前途的方法已经出现。然而，许多相关的属性，如公平性或整体鲁棒性，涉及整个输入空间。如果未经调整地应用验证技术，神经网络将被检查甚至在现实中不存在且无意义的输入上。为了解决这一缺陷，我们提出了VeriFlow架构，这种基于流动密度模型的目标特定的数据分布，使任何验证方法在其感兴趣的范围内进行搜索成为可能。我们展示了这种架构特别适用于此目的，因为我们模型定义的变换是分段仿射的，因此允许基于线性算术的约束求解验证方法的使用。另外，数据分布的上密度级集（UDL）可以在隐空间中通过线性约束来定义。这种特征使得在隐空间中特定概率下的UDL表示可以有效地计算，从而允许具有细粒度和概率可解释的验证控制，输入验证的异常程度如何控制。
### Innovation
VeriFlow架构是一种基于流动密度模型的创新性方法，它允许任何验证技术将其搜索限制在特定的数据分布中。该架构的创新之处在于：1) 模型定义的变换是分段仿射的，使得可以使用基于线性算术的约束求解验证方法；2) 在隐空间中可以定义数据分布的上密度级集，并且特定概率下的UDL表示在隐空间中可以有效计算，这能够提供细粒度和概率可解释的验证控制。
### Conclusion
总之，该研究提出的VeriFlow架构能够克服传统验证方法的缺陷，通过为其感兴趣的范围内进行搜索提供一种有效且可控的方法，提高了神经网络验证的效率和精确性。这种创新性方法为避免对无效或无意义输入的检查提供了新的途径，并为实现更安全和可靠的神经网络奠定了基础。
## 309. `cs.AI` - 加速分子设计的条件隐空间分子骨架优化 [PDF](https://arxiv.org/pdf/2411.01423), [HTML](https://arxiv.org/abs/2411.01423)
### Authors
Onur Boyar,Hiroyuki Hanada,Ichiro Takeuchi
### Background
新化学化合物的快速发现对于推动全球健康和药物治疗的发展至关重要。生成模型在创建新型分子方面显示出前景，但在确保这些分子的实际适用性以及高效发现它们方面仍面临挑战。
### Innovation
本文引入了条件隐空间分子骨架优化（CLaSMO），这是一个结合条件变异自编码器（CVAE）与隐空间贝叶斯优化（LSBO）的方法，以策略性地修改分子并保留与原始输入的相似性，将任务归结为约束优化问题。CLaSMO在优化分子时提高了样本效率，并通过在条件变异自编码器的隐空间中进行贝叶斯优化来探索要优化的分子的亚结构，考虑了分子相似性约束。
### Conclusion
在各种优化任务（如重新发现、对接评分和多重属性优化）中的广泛评估显示，CLaSMO不仅能高效提升目标属性，还能在资源受限的应用中提供关键的样本效率，同时保持最先进的性能并维持实际的合成可及性。此外，还提供了一个开源的网络应用程序，使化学专家能够在人机交互的框架下应用CLaSMO。
## 310. `cs.AI` - 符号梯度在神经网络隐空间的闭形式解释 [PDF](https://arxiv.org/pdf/2409.05305), [HTML](https://arxiv.org/abs/2409.05305)
### Authors
Sebastian J. Wetzel,Zakaria Patel
### Background
已有研究表明，如自编码器或同胞网络等人工神经网络能在其潜在空间中编码有意义的概念。然而，目前缺乏一种无需先验知识即可以人类可读的形式检索这些信息的全面框架。在定量学科中，概念通常以方程形式表述。因此，为了提取这些概念，本文介绍了一种框架来为人工神经网络的潜在空间中的神经元寻找闭形式的解释。该解释框架基于将训练好的神经网络嵌入到编码相同概念的函数等价类中。通过在等价类与人类可读的方程定义的符号搜索空间之间找到交集来解释这些神经网络。从计算角度看，该框架基于找到一个符号表达式，使得该表达式的归一化梯度与特定神经元相对于输入变量的归一化梯度匹配。这种方法的有效性已通过从同胞神经网络的潜在空间中检索矩阵不变量和动力系统守恒量来证明。
### Innovation
本文提出了一种框架，用于为人工神经网络的潜在空间中的神经元寻找闭形式的解释。该框架基于将训练好的神经网络嵌入到编码相同概念的函数等价类中，并通过在等价类与人类可读的方程定义的符号搜索空间之间找到交集来解释这些神经网络。方法从计算角度看，基于找到一个符号表达式的归一化梯度与特定神经元相对于输入变量的归一化梯度匹配的工作原理。这种方法有效地从同胞神经网络的潜在空间中检索到了矩阵的不变量和动力系统的守恒量。
### Conclusion
本文介绍了一种通过将人工神经网络嵌入到函数等价类中，并利用符号搜索空间来提取闭形式解析式的方法，从而使得潜在空间中的神经元概念可以以人类可读的形式进行解释。该方法成功地从同胞神经网络的潜在空间中提取了矩阵的不变量和动力系统的守恒量。
## 311. `cs.AI` - 扩散课程：基于图像引导扩散的合成到真实数据课程 [PDF](https://arxiv.org/pdf/2410.13674), [HTML](https://arxiv.org/abs/2410.13674)
### Authors
Yijun Liang,Shweta Bhardwaj,Tianyi Zhou
### Background
低质量或稀缺的数据对深度神经网络的训练构成了重大挑战。尽管经典的数据增强方法不能提供非常不同的新数据，扩散模型通过文本引导提示生成高质量和多样化的合成数据，打开了构建自演化的AI系统的新途径。然而，仅靠文本引导无法控制合成图像与原始图像之间的接近性，导致产生不利于模型性能的边缘分布数据。
### Innovation
本文研究了图像引导方法，以实现合成图像和真实图像之间的插值范围。通过利用不同强度的图像引导技术，本文提出了名为“扩散课程（DisCL）”的新方法。这种方法在训练的每个阶段调整图像合成的引导水平，专注于识别和聚焦模型困难的样本，评估最有效的合成图像引导水平，以提高困难数据的学习效果。
### Conclusion
DisCL 方法被应用于两个具有挑战性的任务：长尾分类和低质量数据学习。实验结果显示，将 DisCL 应用于 iWildCam 数据集时，OOD 和 ID 的宏观准确率分别提升了 2.7% 和 2.1%。在 ImageNet-LT 中，DisCL 提高了基线模型尾部类别的准确率从 4.4% 提高到了 23.64%，并在全部类别的准确率上增加了 4.02%。
## 312. `cs.AI` - 预算约束的容量感知多智能体MDP中的规划与调度：一种元强化学习方法 [PDF](https://arxiv.org/pdf/2410.21249), [HTML](https://arxiv.org/abs/2410.21249)
### Authors
Manav Vora,Ilan Shomorony,Melkior Ornik
### Background
研究容量和预算有限的多智能体MDP（CB-MA-MDPs），这一类模型能够捕捉到维护和调度任务中的不可逆故障问题，规划者需要决定何时应用恢复动作以及并行处理哪一组智能体。全局预算限制总的恢复次数，而容量约束限制同时动作的数量，使得动态规划变得指数级复杂。
### Innovation
提出了一种两阶段的解决策略，使大规模系统依然能够维持可操作性。首先，利用线性分配问题（LSAP）进行分组，最大化预期失效时间的多样性，并按比例分配预算给各个组。第二，通过元训练的PPO策略解决每个子MDP问题，利用组间知识迁移以快速收敛。这种方法已被应用于工业机器人团队的修理调度问题，受到有限的修理技术人员和维修预算的约束。
### Conclusion
实验结果表明，所提议的方法在提高大型智能体团队的平均运行时间方面优于基线方法。同时，通过对不同数量的机器人和维修人员进行计算复杂性分析，验证了该方法的可扩展性。
## 313. `cs.AI` - Degree-Conscious Spiking Graph for Cross-Domain Adaptation [PDF](https://arxiv.org/pdf/2410.06883), [HTML](https://arxiv.org/abs/2410.06883)
### Authors
Yingxu Wang,Mengzhu Wang,Houcheng Su,Nan Yin,Quanming Yao,James Kwok
### Background
Spiking Graph Networks (SGNs)虽然展示了在图分类中的巨大潜力，通过类脑神经动力学实现高效的能量计算，但现有的SGNs通常仅限于同分布场景，难以应对分布漂移带来的挑战。
### Innovation
本文首先提出了SGNs中的领域适应问题，并引入了一种名为Degree-Consicious Spiking Graph for Cross-Domain Adaptation (DeSGraDA)的新框架，该框架通过三个关键组件增强跨领域的一般化性能。引入了度意识突触表示模块，通过基于节点度调整突触阈值，使信号编码更具表达性和结构意识。执行时间分布对齐，通过对抗匹配域间膜电位，确保在领域漂移下有效性能的同时保持能效。此外，通过在两个空间中提取一致的预测来创建可靠的伪标签，有效地利用未标签数据提高图分类性能。还为SGDA建立了首个泛化界，提供理论见解。
### Conclusion
在基准数据集上的大量实验验证了DeSGraDA在分类准确性和能效方面均优于最先进的方法。
## 314. `cs.AI` - 大型预训练数据集在微调后并不总是保证鲁棒性 [PDF](https://arxiv.org/pdf/2410.21582), [HTML](https://arxiv.org/abs/2410.21582)
### Authors
Jaedong Hwang,Brian Cheung,Zhang-Wei Hong,Akhilan Boopathy,Pulkit Agrawal,Ila Fiete
### Background
大规模预训练模型通常用于通过微调学习新的专门任务，同时力求保持模型的整体普遍性能，并获得新技能。所有此类模型的一个有价值的目标是鲁棒性：模型在处理脱机分布（OOD）任务时保持良好的能力。研究者评估了微调是否能够保持预训练模型的整体鲁棒性，发现大型数据集预训练的模型在微调后表现出严重的灾难性遗忘和OOD泛化能力的丧失。
### Innovation
论文提出了鲁棒性继承基准（ImageNet-RIB），该基准可以应用于任何预训练模型，包括一系列相关的但不同的OOD下游任务，涉及在这些任务中的一个进行微调然后在其余任务中进行测试，以系统地评估鲁棒性保持情况。研究发现，虽然连续学习方法有所帮助，但微调仍然会降低预训练模型的整体鲁棒性。
### Conclusion
在大型和最多样化数据集上预训练的模型（例如LAION-2B）在对小数据集进行微调后，显示出了更大的鲁棒性损失和较低的绝对鲁棒性。这些发现表明，从最强大的基础模型开始训练，并不一定是最优的方法，特别是在执行专门任务时。
## 315. `cs.AI` - 利用模型指导从个性化扩散模型中提取训练数据 [PDF](https://arxiv.org/pdf/2410.03039), [HTML](https://arxiv.org/abs/2410.03039)
### Authors
Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu
### Background
扩散模型（DMs）已成为强大的图像生成工具，尤其在少量样本精调方面表现出色。许多人将这些个性化检查点上传到网上，形成了如Civitai和HuggingFace这样的社区。然而，模型所有者在发布精调检查点时可能忽视了数据泄露风险，特别是在未经授权的数据被用于精调的情况下还可能引发版权争议。该论文探讨的问题是，是否可以从这些在线共享的精调DM模型中提取训练数据？成功提取这些数据不仅会揭示数据泄露的风险，还会为版权侵权提供直接证据。为了回答这个问题，本文提出了一种名为FineXtract的框架，用于从精调DM模型中提取训练数据。
### Innovation
本文提出了一种名为FineXtract的框架，用于从已精调的DM模型中提取训练数据。该方法将精调过程视为模型学习分布逐渐改变的过程——从原始预训练DM模型向精调数据过渡。通过在精调前后引导生成，使生成倾向于精调数据分布中的高概率区域，并通过聚类算法提取这些生成图象中最有可能的图像。实验证明了该方法的有效性，在大多数情况下，可以提取约20%的精调数据。该方法为数据泄露和版权侵犯提供了新的解决方案和验证手段。
### Conclusion
通过FineXtract框架，可以从那些已精调的DM模型中成功提取训练数据，这不仅提防了数据泄露的风险，也提供了版权侵权的实证证据。实验结果验证了方法的有效性，且源代码已公开。
## 316. `cs.AI` - 大型语言模型低秩适配器的无训练贝叶斯化 [PDF](https://arxiv.org/pdf/2412.05723), [HTML](https://arxiv.org/abs/2412.05723)
### Authors
Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang
### Background
估计大型语言模型（LLMs）响应的不确定性仍然是一个关键的挑战。尽管近年来的贝叶斯方法通过低秩权重更新显示出在量化不确定性方面的有效性，但它们通常需要复杂的微调或后训练程序。现有方法往往需要额外的训练步骤来实现贝叶斯化。
### Innovation
提出了一种无训练贝叶斯化（TFB）框架，这是一种简单且有理论依据的方法，可以将已训练的低秩适配器高效地转换为贝叶斯适配器，而无需额外的训练。TFB 系统地搜索权重后验中可接受的最大方差水平，并将其限制在低秩各向同性高斯分布的家族内。理论分析表明，在轻微条件下，这一搜索过程等效于 KL-正则化变分优化，这是一种变分推断的一般形式。
### Conclusion
通过全面的实验证明，TFB 在不确定性估计和泛化方面优于现有方法，同时消除了复杂贝叶斯化训练流程的需要。代码将在 https://this.is/the/url 可用。
## 317. `cs.AI` - 如何战略性地响应：在战略分类中的分析模型与LLM生成响应的对比 [PDF](https://arxiv.org/pdf/2501.16355), [HTML](https://arxiv.org/abs/2501.16355)
### Authors
Tian Xie,Pavan Rauch,Xueru Zhang
### Background
当机器学习算法被部署以自动化人类决策时，人类代理可能会学习决策背后的政策并调整其行为。由此引发了背后代理与决策者之间互动的研究兴盛，特别专注于开发更值得信赖的机器学习系统。先前的战略分类（SC）理论模型假设代理是完美或接近理性的，并通过优化其收益来响应决策政策。随着大型语言模型（LLM）的普及，现实中的代理可能依赖这些工具作为战略建议。这引发了一些问题：（i）LLM是否能在SC场景中生成有效的、符合社会责任的战略？（ii）现有的SC理论模型能否准确捕捉到代理行为的变化，特别是当代理遵循LLM建议时？
### Innovation
研究通过模拟具有不同特征的代理与三种商业LLM（GPT-4o、GPT-4.1和GPT-5）的互动，探索了五种关键SC场景：就业、贷款申请、学校录取、个人收入和公共援助项目。研究发现，在LLM引导的努力分配策略下，代理的行为表现出与现有SC理论模型预测相似的结果，尤其是在群体层面，LLM策略在提高评分、资格率和公平度方面具有和或接近相同的效果。在个体层面，LLM倾向于生成更多样化和平衡的努力分配。
### Conclusion
本研究展示了即便没有接触到决策政策，LLM也可以生成有效的策略，帮助代理提高成绩与资格，且在群体和个体层级，LLM指导的努力分配策略表现出与理论模型相似的效果；进一步说明了理论上现有的模型可能仍然是LLM影响行为的合理代理。
## 318. `cs.AI` - 超越浅层行为：通过技能发现实现高效多任务离线MARL [PDF](https://arxiv.org/pdf/2502.08985), [HTML](https://arxiv.org/abs/2502.08985)
### Authors
Xun Wang,Zhuoran Li,Hai Zhong,Longbo Huang
### Background
在线离线多智能体强化学习（MARL）能够仅通过离线数据集学习优秀的策略，适用于历史数据丰富的领域，但交互成本和风险较高。然而，大多数现有方法针对特定任务设计，需要针对新任务重新训练，导致资源冗余和效率低下。
### Innovation
提出了一种基于技能发现的价值导向多任务离线MARL算法（Skill-Discovery Conservative Q-Learning，SD-CQL）。SD-CQL通过重构下一个观察值来在潜在空间中发现技能，分别评估固定的和变化的动作，并使用保守的Q学习和局部价值校准来为每个技能选择最佳操作。它避免了局部-全局对齐，并能从有限的小规模源任务中高效地实现多任务泛化。
### Conclusion
在StarCraft II的任务集中，SD-CQL展示了出色的泛化性能和任务效率，获得了14个任务中的13个最佳结果，单个任务集上最高提升达68.9%。
## 319. `cs.AI` - 揭开金融领域大语言模型后训练的神秘面纱 [PDF](https://arxiv.org/pdf/2501.04961), [HTML](https://arxiv.org/abs/2501.04961)
### Authors
Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty
### Background
大型语言模型（LLMs）在医学和金融等专业化领域中的适应性后训练方法已经展现出了显著的潜力。然而，如何确定适应性的最佳标准以及在不同数据和模型配置下进行的最佳训练策略仍然是一个挑战。
### Innovation
提出了FINDAP，这是一种系统而精密的方法，专门针对金融领域的大语言模型进行适应性后训练。FINDAP包括四个核心组成部分：FinCap定义了目标领域所需的核心能力；FinRec是一种有效的训练食谱，结合了连续预训练和指令遵循的优化，同时也包含了一种新颖的偏好数据蒸馏方法，利用生成奖励模型中的过程信号进行数据提炼；FinTrain是一系列支持FinRec的培训数据集；FinEval是一个与FinCap对齐的全面评估套件。这种方法生成的模型Llama-Fin在多方面的金融任务上都达到了最先进的水平，揭示了每个后训练阶段如何促进特定的能力，并提供了适应LLMs的重要见解。
### Conclusion
研究还揭示了每个后训练阶段对不同能力的贡献，指出了特定的挑战和有效的解决方案，为大语言模型的适应性研究提供了宝贵的洞见。
## 320. `cs.AI` - RuCCoD: 向俄罗斯ICD编码自动化迈进 [PDF](https://arxiv.org/pdf/2502.21263), [HTML](https://arxiv.org/abs/2502.21263)
### Authors
Aleksandr Nesterov,Andrey Sakhovskiy,Ivan Sviridov,Airat Valiev,Vladimir Makharev,Petr Anokhin,Galina Zubkova,Elena Tutubalina
### Background
俄罗斯语缺乏医学资源，研究该语言中临床编码的自动化可行性是必要的。作者使用电子健康记录（EHRs）构建了一个新的ICD编码数据集，其中包括超过10,000个实体和超过1,500个独特的ICD代码。该数据集被用作多种最先进的模型（如BERT、带有LoRA的LLaMA和RAG）的基准测试，并进一步研究了领域迁移学习（从PubMed摘要到医学诊断）和术语迁移学习（从UMLS概念到ICD代码）。
### Innovation
该研究的创新之处在于构建了一个新的俄语ICD编码数据集，并使用该数据集评估了多种最先进的模型。通过实验发现，使用自动化预测的编码进行训练，可以显著提高准确性，相比于医生手动标注的数据有显著改进。此外，研究展示了自动化编码在资源有限的语言如俄语中的潜在价值，有助于提升临床效率和数据准确性。
### Conclusion
研究发现，自动化临床编码可以显著提高准确性，特别是对于资源有限的语言如俄语，这为在这些语言中自动化临床编码提供了宝贵的见解。研究的代码和数据集已公开可用。
## 321. `cs.AI` - 被塞住的Mamba: 大尺寸状态导致无法忘记 [PDF](https://arxiv.org/pdf/2410.07145), [HTML](https://arxiv.org/abs/2410.07145)
### Authors
Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
近期，如Mamba和RWKV等循环架构的发展展示了强大的语言能力。与基于Transformer的模型不同，这些架构将所有上下文信息编码到固定大小的状态中，带来高效的推理。然而，这种方法可能导致信息干扰，不同的令牌数据冲突，导致性能下降和输出不一致，特别在上下文较长时更为明显。为了解决这一问题，大多数循环神经网络（RNNs）被设计有“遗忘”早期令牌的机制。但本研究发现，即使具有内置遗忘机制，基于Mamba的模型仍然难以有效遗忘早期的令牌。原因在于训练时上下文长度过短，使得模型无需学习遗忘机制也能表现良好。研究表明，模型学习遗忘机制所需训练长度与状态大小成线性关系，而准确检索5位数密码的最大上下文长度则与状态大小呈指数关系，表明即使在遗忘机制启动后，模型仍保留一些信息。这些发现突显了当前RNN架构的关键限制，为改进长时间上下文模型提供有价值的见解。未来RNN设计应考虑状态大小、训练长度和遗忘机制之间的相互作用，以实现长期上下文任务的稳健性能。
### Innovation
本文揭示了基于Mamba的模型难以有效执行遗忘操作的问题，即便已经内置了遗忘机制。研究表明，这种问题是由于训练上下文长度过短导致的，使得模型无需学习遗忘机制也能表现良好。此外，作者进一步发现，模型学习遗忘机制所需的训练长度与状态大小成线性关系，而准确检索5位数密码的最大上下文长度与状态大小呈指数级增长，表明模型在遗忘机制启动后仍保留一些信息。这一发现揭示了RNN架构的关键限制，并为改善长时间上下文建模提供了有价值的见解。未来RNN设计需考虑状态大小、训练长度和遗忘机制之间的相互作用关系。
### Conclusion
当前的RNN架构存在关键限制，特别是在长时间上下文建模时。这些限制主要包括：1) 内置遗忘机制并不能完全解决信息干扰问题；2) 学习遗忘机制的训练长度与状态大小有关，而准确检索信息的最大上下文长度与状态大小呈指数关系；3) 即使在遗忘机制启动后，模型仍保留一些信息。为改善长期上下文任务的性能，未来RNN设计需充分考虑状态大小、训练长度和遗忘机制之间的相互作用。
## 322. `cs.AI` - Rare-to-Frequent:通过LLM指导解锁扩散模型在稀有概念生成中的组合生成能力 [PDF](https://arxiv.org/pdf/2410.22376), [HTML](https://arxiv.org/abs/2410.22376)
### Authors
Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho
### Background
最先进的文本到图像(T2I)扩散模型在生成具有罕见组合的概念时往往表现不佳，例如具有不寻常属性的对象。本文通过实证和理论分析表明，在扩散采样过程中暴露与目标稀有概念相关的频繁概念能提高生成准确性。研究发现，这一过程可以通过利用大型语言模型(LLM)中丰富的语义知识来增强扩散模型在生成稀有概念组合方面的表现。
### Innovation
提出了一种无需训练的方法R2F，该方法通过利用LLM中的大量语义知识，在扩散推理的整个过程中规划和执行从稀有到频繁概念的指导。该框架适用于任何预训练的扩散模型和LLM，并且可以无缝集成到区域指导的扩散方法中。在三个数据集上进行的大量实验，包括作者新提出的基准RareBench，证明了R2F显著优于现有的模型，包括SD3.0和FLUX，T2I对齐的最大提升可达28.1%。
### Conclusion
该框架展示了通过LLM指导实现扩散模型在稀有概念生成中的组合生成能力增强，提出了R2F方法可以显著提高扩散模型生成稀有概念组合的准确性，提供了新基准数据集使得该研究的评估更加全面和准确。
## 323. `cs.AI` - 长上下文建模中最优的分组查询注意力机制 [PDF](https://arxiv.org/pdf/2503.09579), [HTML](https://arxiv.org/abs/2503.09579)
### Authors
Yingfa Chen,Yutong Wu,Chenyang Song,Zhen Leng Thai,Xingyu Shen,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
分组查询注意力（GQA）是一种广泛采用的策略，用于降低大型语言模型（LLMs）中注意力层的计算成本，但在现有配置中，GQA往往效率低下，因为它们忽视了上下文长度对推理成本的影响。由于推理成本随着上下文长度增加而增加，最高效的GQA配置也应相应变化。本文研究了上下文长度、模型大小、GQA配置与模型损失之间的关系。
### Innovation
1. 解耦注意力层的总头尺寸和隐藏尺寸，以更好地控制注意力FLOPs；2. 联合优化模型大小和GQA配置，以更好地分配给注意力层和其他组件的推理资源。
### Conclusion
常用的GQA配置在长上下文场景中高度不高效。我们的研究发现，对于长上下文场景，应减少注意力头的数量并扩大模型规模。我们提出了一种用于确定成本最优配置的配方，可在不降低模型能力的前提条件下，将Llama-3的GQA配置的内存使用和FLOPs降低超过50%。我们的研究结果为设计高效的长上下文LLMs提供了有价值的见解。
## 324. `cs.AI` - LLMs能否成为构建知识图谱的良好图法官？ [PDF](https://arxiv.org/pdf/2411.17388), [HTML](https://arxiv.org/abs/2411.17388)
### Authors
Haoyu Huang,Chong Chen,Zeang Sheng,Yang Li,Wentao Zhang
### Background
在实际场景中，从信息检索系统收集的数据大多未结构化。将自然语言句子转换为结构化的知识图谱(KGs)仍然是一个关键挑战。现有的KG构建方法存在的三个局限性为：(1) 实际文档中可能存在大量_noise_，从而提取出杂乱的信息。(2) 脱胎于通用模型的LLM可能从某些专业文档中提取不准确的知识。(3) 当直接使用LLM构建KGs时，幻觉现象不能被忽略。
### Innovation
本文提出了一种知识图谱构建框架GraphJudge，该框架克服了现有方法中的三大局限。框架中设计了以实体为中心的策略，以消除文档中的噪声信息。同时，团队还微调了一种LLM作为图法官，最终提升生成的KG质量。实验结果表明，GraphJudge在一般和特定领域数据集上均表现出强大的泛化能力和最先进的性能。该团队的代码可在此处访问_https_//这个链接_
### Conclusion
实验结果展示了GraphJudge在处理噪声信息和提升KG质量方面表现出强大性能，对比了各种基线方法，证明了其优越性，并强调了其广泛适用性。
## 325. `cs.AI` - 通过基于偏好的探索避免RLHF中的exp(R_max)缩放 [PDF](https://arxiv.org/pdf/2502.00666), [HTML](https://arxiv.org/abs/2502.00666)
### Authors
Mingyu Chen,Yiding Chen,Wen Sun,Xuezhou Zhang
### Background
强化学习从人类反馈（RLHF）已成为大规模语言模型（LLM）对齐的关键技术。现有在线RLHF算法，不论是被动探索还是主动探索，都存在样本复杂度指数级增长的问题，这在偏好分布极度偏斜的情况下（如问题具有唯一正确答案）阻碍了其效果。因此，论文研究如何改进样本效率，特别是引入一种新的样本复杂度为多项式级的在线RLHF算法SE-POPO，从而解决了Xie等人的公开问题。
### Innovation
论文首次提出了Self-Exploring Preference-Incentive Online Preference Optimization（SE-POPO）算法，该算法的样本复杂度为多项式级，解决了现有算法面临的指数级缩放问题。作者通过理论证明了SE-POPO的样本复杂度优于现有探索算法，并通过系统性评估展示了SE-POPO在两种主要RLHF应用场景和公共基准上的样本效率更高。
### Conclusion
SE-POPO算法在RLHF算法设计上迈出了重要一步，显著提高了样本效率，未来有望在大规模语言模型对齐中发挥重要作用。
## 326. `cs.AI` - 为年轻数字化公民的伦理人工智能：呼吁隐私治理 [PDF](https://arxiv.org/pdf/2503.11947), [HTML](https://arxiv.org/abs/2503.11947)
### Authors
Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha
### Background
青少年在使用的数字平台上的人工智能（AI）迅速扩张，创造了隐私、自主权和数据保护等方面的重大挑战。尽管AI驱动的个性化功能可以提升用户体验，但它往往缺乏明确的伦理界限，使年轻用户容易受到数据滥用和算法偏见的影响。
### Innovation
本文提出了一种呼吁伦理AI治理的行动，倡导建立一个以青少年为中心的隐私保护结构化框架，包括透明的数据实践和监管监督。关键领域包括算法透明度、隐私教育、家长数据共享伦理以及问责措施。
### Conclusion
通过这种方法，本文旨在赋予青少年对他们数字身份的更大控制权，并为政策制定者、AI开发者和教育者提出可行的战略，以构建一个更公平和更负责任的AI生态系统。
## 327. `cs.AI` - 通过隐式奖励实现过程强化 [PDF](https://arxiv.org/pdf/2502.01456), [HTML](https://arxiv.org/abs/2502.01456)
### Authors
Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding
### Background
密集的过程奖励在大规模语言模型（LLMs）的推理时扩展中已被证明是一种比稀疏的结果奖励更有效的替代方案，特别是在需要复杂多步推理的任务中。虽然密集奖励也因其细粒度的奖励有潜力解决结果奖励的一些固有问题，如训练效率和奖励分配，但这一潜力尚未充分利用。主要原因在于在线训练过程奖励模型（PRMs）时，收集高质量过程标签的成本过高，使它们特别容易受到奖励欺骗的影响。为了应对这些挑战，本文提出了一种PRIME方法，使用仅策略滚动和结果标签通过隐式过程奖励实现在线PRM更新，从而无需专门的奖励模型训练阶段，显著降低了开发成本。
### Innovation
PRIME方法结合了良好的优势函数，并且不需要现有方法所需的专门奖励模型训练阶段，从而显著降低了开发成本。该方法通过仅使用策略滚动和结果标签，利用隐式过程奖励实现在线PRM更新。它在竞赛数学和编程方面展示了有效性。从Qwen2.5-Math-7B-Base开始，PRIME模型在几个关键的推理基准上平均提高了15.1%，并在使用其10%的训练数据的情况下，在七个推理基准上超越了Qwen2.5-Math-7B-Instruct。
### Conclusion
PRIME方法通过结合良好的优势函数，成功解决了在线训练过程奖励模型的挑战，提高了开发效率，并在多个关键推理基准上取得了显著的性能提升。
## 328. `cs.AI` - 时间-频率模式学习用于单通道EEG的分词 [PDF](https://arxiv.org/pdf/2502.16060), [HTML](https://arxiv.org/abs/2502.16060)
### Authors
Jathurshan Pradeepkumar,Xihao Piao,Zheng Chen,Jimeng Sun
### Background
EEG分析正受到基础模型的重塑，但在EEG分词方面仍存在一个重要的挑战。现有的分词方法无法有效捕捉时间-频率模式，限制了其在下游任务中的应用效果。
### Innovation
提出了TFM-Token化框架，这是一种新颖的分词框架，能够从单通道EEG信号中学习时间-频率模式的词汇，并将其编码为离散的tokens。框架采用双路径架构与时间-频率掩码来捕获鲁棒的模式表示，支持轻量级转换器和现有基础模型。该方法在四种不同的EEG基准测试中实现了性能提升，特别是在单数据集和多数据集预训练设置中，Cohen's Kappa达到了17%的改进。此外，该分词器作为插件组件，能够提升多种基础模型的表现，例如BIOT和LaBraM。分词器还具有跨设备的可扩展性，未依赖于严格的10-20系统，能够在耳EEG睡眠阶段分段任务上表现出色，提升了14%。通过全面的token分析，可以看出模式具有良好的类别区分性、频率意识和一致性结构，从而提升了表示质量和解释性。
### Conclusion
TFM-Tokenizer方法在多个EEG基准测试中表现出显著的优势，提升了基础模型在时间和频率模式捕捉上的性能，并验证了其在不同应用场景下的泛化能力和可扩展性。
## 329. `cs.AI` - VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation [PDF](https://arxiv.org/pdf/2502.07531), [HTML](https://arxiv.org/abs/2502.07531)
### Authors
Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu
### Background
Controllable image-to-video (I2V) generation旨在将参考图像转化为由用户指定控制信号引导的连贯视频。在内容创作流程中，对相机运动、对象运动和照明方向的精确和同步控制可以提高准确性和灵活性。然而，现有方法通常将这些控制信号分开处理，主要是由于高品质联合标注数据稀缺以及不同模态下的控制空间不匹配。为了克服这些限制，作者提出了VidCRAFT3框架，该框架支持对相机运动、对象运动和照明方向的独立和联合控制，通过整合三个核心组件实现：Image2Cloud用于从参考图像重建3D点云以实现精确的相机运动控制；ObjMotionNet用于将稀疏对象轨迹编码为多尺度光流特征，以指导对象运动；Spatial Triple-Attention Transformer则通过并行交叉注意力整合照明方向嵌入。为了解决联合标注数据稀缺的问题，作者还创建了一个名为VideoLightingDirection (VLD)的新数据集，其中包含合成静态场景视频片段的逐帧照明方向标签，并采用三阶段训练策略以实现鲁棒学习。
### Innovation
VidCRAFT3框架是对此类任务的关键创新，其主要创新点在于：1) 将相机运动、对象运动和照明方向的控制整合在一个统一框架中；2) 通过Image2Cloud、ObjMotionNet和Spatial Triple-Attention Transformer三个核心组件实现对这些关键参数的精确控制；3) 通过创建VideoLightingDirection (VLD)数据集和采用三阶段训练策略，解决了联合标注数据稀缺的问题，提高了模型的泛化能力；4) 实验结果表明，VidCRAFT3在控制精度和视觉连贯性方面优于现有方法。
### Conclusion
VidCRAFT3框架显著提升了图像到视频生成的可控性和视觉连贯性，通过合成的静态场景视频片段和高质量的照明方向标签实现了精确的相机运动、对象运动和照明方向的控制。该研究为内容创作提供了强有力的方法，并提出了一个可用于进一步研究和实际应用的强大工具。感兴趣的用户可以访问提供的项目页面获取代码和数据。
## 330. `cs.AI` - InftyThink: 突破大型语言模型长时间推理限制 [PDF](https://arxiv.org/pdf/2503.06692), [HTML](https://arxiv.org/abs/2503.06692)
### Authors
Yuchen Yan,Yongliang Shen,Yang Liu,Jin Jiang,Mengdi Zhang,Jian Shao,Yueting Zhuang
### Background
大型语言模型在复杂任务中的推理取得了显著成果，但当前依赖长上下文的推理方法面临关键局限性，包括计算成本随序列长度呈二次方增长、推理受限于最大上下文边界，以及超出预训练上下文窗口后的性能下降。现有的方法主要集中在压缩推理链条，但未能解决根本的计算规模问题。
### Innovation
提出了InftyThink框架，将一次性推理转化为迭代过程，并通过短推理片段与简明摘要的交替，使得推理深度无限制的同时，保持计算成本的可控。这种方法创造了锯齿形的内存模式，显著减少了计算复杂度。此外，还开发了一种将长上下文推理数据集转换为迭代格式的方法，将OpenR1-Math数据集转换为333K训练实例。
### Conclusion
我们的方法挑战了推理深度与计算效率之间的传统权衡，提供了一种在无需架构修改的情况下更可扩展的复杂推理处理方法，并在多个模型结构中验证了其在计算成本降低和性能提升方面的效果。
## 331. `cs.AI` - LLMs在事实核查中的失败 [PDF](https://arxiv.org/pdf/2503.01902), [HTML](https://arxiv.org/abs/2503.01902)
### Authors
Adiba Mahbub Proma,Neeley Pate,James Druckman,Gourab Ghoshal,Hangfeng He,Ehsan Hoque
### Background
大语言模型（LLMs）能够放大在线错误信息，但同时也表现出在对抗错误信息方面的潜力。本研究旨在通过实证分析三种LLMs——ChatGPT、Gemini和Claude，在对抗政治错误信息方面的表现。研究采用两步链式思考提示方法，先让模型识别给定声明的可信来源，再生成有说服力的回应。研究发现模型难以将回答与真实新闻源相结合，并倾向于引用左倾来源。此外，不同模型对问题的回答产生了不同多样性的结果。这些发现引发了仅通过提示工程使用LLMs进行事实核查的担忧，强调了需要更严格的监管措施。这一研究对研究人员和非技术用户都具有重要意义。
### Innovation
本研究提出了一种两步链式思考提示方法，以实证分析三种LLMs对抗政治错误信息的能力。这种方法包括首先识别给定声明的可信来源，然后生成具有说服力的回应。这项工作强调了通过提示工程使用LLMs进行事实核查的局限性，提出了更多监管措施的需求。
### Conclusion
研究发现模型在事实核查中的应用存在局限，仅通过提示工程不能完全依赖LLMs进行事实核查，这需要更严格的监管措施。研究结果对研究人员和非技术用户都具有重要意义。
## 332. `cs.AI` - 使用任务引发技术自适应地剖析模型 [PDF](https://arxiv.org/pdf/2503.01986), [HTML](https://arxiv.org/abs/2503.01986)
### Authors
Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong
### Background
语言模型评估通常未能准确地识别出导致灾难性后果的失败模式，迫使专家手工检查模型输出并建立新的基准。这就需要大量的时间和人力资源，且效率较低，难以覆盖所有潜在问题。因此，现有方法在全面性和准确度上存在局限性。这就需要一种更为自动和高效的方法来识别语言模型的系统性失败模式，从而更全面地评估模型性能，并揭示其潜在风险。
### Innovation
该研究引入了任务引发法（task elicitation），这是一种自动构建新评估的方法，用于描绘模型的行为特征。任务引发法能够找到上百个自然语言任务，其中前沿模型表现出系统性失败，这些任务涵盖从预测到在线骚扰等多个领域。此外，它能够在保证大量任务规模的同时，系统性地发现模型的错误关联和偏向性或幻觉倾向。这表明该方法相较于以往的工作更加有效和全面地捕捉到了模型的潜在问题。
### Conclusion
该研究通过任务引发方法，能够自动发现大量新任务，揭示先前未识别的模型系统性失败，提高了模型评估的全面性和准确性。未来可以在更多场景下应用此方法来提高语言模型安全性，减少模型引发的潜在风险。
## 333. `cs.AI` - 基于层次知识的检索增强生成 [PDF](https://arxiv.org/pdf/2503.10150), [HTML](https://arxiv.org/abs/2503.10150)
### Authors
Haoyu Huang,Yongfeng Huang,Junjie Yang,Zhenyu Pan,Yongqiang Chen,Kaili Ma,Hongzhi Chen,James Cheng
### Background
图基检索增强生成（RAG）方法显著提升了语言模型在特定领域任务中的性能，但现有RAG方法未能充分利用人类认知中自然存在的层次知识，这限制了RAG系统的功能。
### Innovation
提出了一种新的RAG方法——HiRAG，该方法利用层次知识来增强RAG系统在索引和检索过程中的语义理解和结构捕获能力。实验表明，HiRAG在多种任务上的表现超过了最先进的基线方法，实现了显著的性能提升。
### Conclusion
HiRAG通过利用层次知识改进了RAG系统的语义理解和结构捕获能力，实验结果表明这种方法在多个任务中取得了显著的性能提升。
## 334. `cs.AI` - 比较大规模语言模型的不确定性测量与缓解方法：一项系统性回顾 [PDF](https://arxiv.org/pdf/2504.18346), [HTML](https://arxiv.org/abs/2504.18346)
### Authors
Toghrul Abbasli,Kentaroh Toyoda,Yuan Wang,Leon Witt,Muhammad Asif Ali,Yukai Miao,Dan Li,Qingsong Wei
### Background
大规模语言模型（LLMs）在各个领域取得了突破性进展，但它们在输出错误信息时表现出的自信（即幻觉问题）仍然是一个主要挑战。因此，如何准确评估和量化LLMs的不确定性成为一个重要的问题。尽管传统模型上已经有很多关于不确定性量化（UQ）的研究，并且使用校准技术来解决不确定性与准确性的不匹配问题，但对于LLMs而言，这些方法的有效性分析相对不足，缺乏一个全面的基准来促进对现有解决方案的深入比较。
### Innovation
本文通过系统地回顾有关LLMs的不确定性量化和校准方法的代表性先前工作，并引入了一个严格的基准，来填补该领域的这一空白。使用两类广泛使用的可靠性数据集，对六个相关方法进行了实证评估，证实了研究成果。最后，本文提出了关键的未来方向并概述了开放挑战。
### Conclusion
据我们所知，这是第一项专注于审查LLMs的校准方法及相应度量标准的研究。
## 335. `cs.AI` - 检测稀少且稀疏的异常：解决多重实例学习中的双重不平衡 [PDF](https://arxiv.org/pdf/2503.13562), [HTML](https://arxiv.org/abs/2503.13562)
### Authors
Lin-Han Jia,Lan-Zhe Guo,Zhi Zhou,Si-Ye Han,Zi-Wen Li,Yu-Feng Li
### Background
在实际应用中，检测具有极稀疏异常样本极为具有挑战性，因为异常样本与正常样本高度相似，易被混淆。此外，异常样本的数量本就稀缺。这导致了一个宏微观层面都存在的多重实例学习(MIL)问题双重不平衡。
### Innovation
通过将MIL问题重新表述为精细分层次的PU学习问题，并利用微观级别的平衡机制以无偏的方式解决不平衡问题，提出了一个名为Balanced Fine-Grained Positive-Unlabeled (BFGPU)的新框架。
### Conclusion
在合成和真实数据集上的广泛实验表明，BFGPU框架的有效性。
## 336. `cs.AI` - 计算归约、失败模式与法律-道德责任的正式化人类在一个环节数字系统：Human-in-the-Loop [PDF](https://arxiv.org/pdf/2505.10426), [HTML](https://arxiv.org/abs/2505.10426)
### Authors
Maurice Chiodo,Dennis Müller,Paul Siewert,Jean-Luc Wetherall,Zoya Yasmine,John Burden
### Background
本文使用计算可计算理论中的预言机和约简的概念来正式化不同类型的人类在一个环节数字系统（HITL）的设置，区分完全的人类监视（即完全函数）、单一端点人类行动（即一元约简）和高度参与的人机交互（即图灵约简）。随后表明，不同设置的法律地位和安全性差异很大。文章还提出了一种分类法来分类HITL失败模式，突显了HITL设置的实践限制。然后指出英国和欧盟法律框架中的空白，这些框架关注的HITL设置可能无法始终实现预期的伦理、法律和社会技术结果。作者建议应识别不同HITL设置的有效性并在这些上下文中学区分责任，避免将责任强加于人类。整体而言，文献展示了在分配法律责任和技术可解释性之间不可避免的权衡。
### Innovation
作者利用计算可计算理论中的概念来正式化不同类型的HITL设置，这为理解和分析HITL系统的复杂性提供了新的视角。提出了一种新的分类法来描绘HITL失败模式，以及识别了现有法律框架中的不足之处，建议在法律中识别和区分不同HITL设置的效果和职责。
### Conclusion
作者证明了在HITL设置中存在许多技术设计决策，并且这些决策可能导致超出人类控制的失败。正式化和分类法打开了一种新的分析视角，有助于指导AI开发者和立法者设计更有效地实现预期目标的HITL设置。
## 337. `cs.AI` - 扩散模型能实现区分吗？一种理论视角 [PDF](https://arxiv.org/pdf/2504.00220), [HTML](https://arxiv.org/abs/2504.00220)
### Authors
Liming Wang,Muhammad Jehanzeb Mirza,Yishu Gong,Yuan Gong,Jiaqi Zhang,Brian H. Tracey,Katerina Placek,Marco Vilela,James R. Glass
### Background
本文提出了对理解扩散模型如何学习分离表示的新型理论框架。在此框架下，作者建立了适用于泛化分离潜变量模型的识别条件，分析了训练动力学，并推导出了分离潜空间模型的样本复杂性边界。为了验证理论的有效性，作者在各种任务和模态下进行了分离实验。实验结果显示，受理论启发的训练策略能显著提升分离性能，如在潜空间高斯混合模型的子空间恢复、图像着色、图像去噪和语音转换（用于语音分类）任务中取得了优于传统方法的效果。
### Innovation
文章创新地提出了一种理论框架来解释扩散模型如何学习分离表示。通过该框架，作者建立了分离潜变量模型的识别性条件，分析了训练动态，并推导出关于分离潜空间模型的样本复杂性边界。这些理论成果为设计和改进扩散模型提供了依据，并展示了其在多种应用中的有效性。特别地，作者提出了受理论启发的训练策略，取得了显著的分离效果。
### Conclusion
通过理论分析和实验验证，本文表明扩散模型确实可以实现分离表示，并对其理论基础和应用效果进行了深入探讨。此外，作者还提出了一些训练方法，这些方法显著提高了模型的分离性能，适用于多种任务和模态。
## 338. `cs.AI` - SuperCoder: 使用大型语言模型进行汇编程序超优化 [PDF](https://arxiv.org/pdf/2505.11480), [HTML](https://arxiv.org/abs/2505.11480)
### Authors
Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken
### Background
超优化是指将程序转换为更快速的版本，同时保留其输入输出行为。本研究探索了大型语言模型（LLMs）是否能够作为超优化器，生成比经过工业标准编译器优化的代码更快的汇编程序。研究团队构建了一个大型基准测试，包括8,072个真实世界的汇编程序，每平均130行，而以往的数据集则限制在2到15个单行、无循环的程序。评估了23种不同的LLMs，发现Claude-opus-4作为基线实现了51.5%的通过率和1.43倍的平均加速比gcc -O3。为了进一步提高性能，团队使用强化学习对模型进行微调，优化了一个结合正确性和性能加速的奖励函数，并从Qwen2.5-Coder-7B-Instruct微调出SuperCoder模型，实现了95.0%的正确率和1.46倍的平均加速。
### Innovation
研究团队构建了首个大规模的汇编程序超优化基准，并且使用强化学习对LLMs进行微调，展示了LLMs在汇编程序超优化中的应用潜能。
### Conclusion
研究结果表明，大型语言模型可以作为汇编程序的超优化器，为未来研究程序性能优化提供了新的方向，超越了编译器的启发式方法。
## 339. `cs.AI` - Prima.cpp: 快速在异构和低资源家庭集群上进行30-70亿参数的大语言模型推理 [PDF](https://arxiv.org/pdf/2504.08791), [HTML](https://arxiv.org/abs/2504.08791)
### Authors
Zonghang Li,Tao Li,Wenjiao Feng,Rongxing Xiao,Jianshu She,Hong Huang,Mohsen Guizani,Hongfang Yu,Qirong Ho,Wei Xiang,Steve Liu
### Background
设备端推理提供了隐私性、离线使用和即时响应的优势，但消费者硬件限制了大语言模型（LLMs）的处理能力。现有的解决方案在处理能力和吞吐量方面存在局限性。因此，本文提出了一种分布式设备端推理系统，能够在消费者家庭集群上运行30-70亿参数的LLMs，这些集群由混合的CPU/GPU、有限的内存/显存、缓慢的磁盘、Wi-Fi连接和异构操作系统组成。该系统克服了传统解决方案在资源限制和性能瓶颈方面的不足。
### Innovation
该论文提出了pipelined-ring并行（PRP）机制，优化了磁盘I/O、计算和通信的重叠，解决了基于mmap的离加载中的预取-释放冲突。同时，提出了Halda，这是一种异构调度器，能够在内存/显存约束下同时优化每个设备的CPU/GPU工作负载并选择设备。所提出的系统与Exo、EXLlama和dllama相比，具有更低的TPOT（每秒令牌数）、支持从8亿到70亿参数的细粒度模型尺寸、更广泛的跨操作系统和量化兼容性，并且保持无OOM（内存不足）的现象，同时具备Wi-Fi兼容性、隐私保护和硬件无关性。
### Conclusion
通过Prima.cpp系统，能够在有限资源的家庭设备上高效运行大语言模型，实现了快速高质量的推理性能，同时提供了隐私保护和跨平台兼容性，该系统具有广泛的应用潜力。相关代码可以在特定链接处获取。
## 340. `cs.AI` - 沿路径推理：通过知识图路径改进LLM事实性 [PDF](https://arxiv.org/pdf/2505.11140), [HTML](https://arxiv.org/abs/2505.11140)
### Authors
Mike Zhang,Johannes Bjerva,Russa Biswas
### Background
该研究旨在通过源自从大型推理模型（例如DeepSeek-R1）的结果并结合知识图（KG）路径来提高推理痕迹的准确性。之前的研究表明，推理痕迹在STEM领域中具有有效性，但本文进一步证实通过知识图路径锚定推理是使LLM适用于可靠的知识密集型任务的关键步骤。
### Innovation
该研究引入了fs1方法，该方法通过使用大型推理模型生成的推理痕迹并结合知识图路径来提高LLM的推理准确性。此外，还对8个指令调优的大语言模型进行了微调，并在6个复杂的跨域问题回答基准上进行了严格的评估。实验结果显示，fs1增强了LLM在更复杂问题和数值答案类型上的性能。
### Conclusion
fs1模型在单次推理中表现出显著改进，尤其是在较小的LLM中。研究证实，将推理锚定到事实性知识图路径是提升LLM进行可靠知识密集型任务能力的关键步骤。
## 341. `cs.AI` - CLASH：多视角评判高风险困境的语言模型评估 [PDF](https://arxiv.org/pdf/2504.10823), [HTML](https://arxiv.org/abs/2504.10823)
### Authors
Ayoung Lee,Ryan Sungmo Kwon,Peter Railton,Lu Wang
### Background
在高风险领域，人类甚至在面对价值冲突时都面临挑战，对于AI而言更是如此。之前的研究主要集中在日常生活场景中，尚未涉及高风险领域的情况。CLASH数据集旨在填补这一空白，提供了一个包含345个高影响困境和3,795个多元化价值视角的详尽集合，用于探索价值导向决策过程中的关键但未充分研究方面，如决策矛盾和心理不适的理解，以及价值视角随时间的变化。
### Innovation
CLASH数据集和基于该数据集的评估，能够细致地研究基于价值的决策过程中的关键方面。它对比了14种不同的语言模型（包括非思考模型和思考模型），发现了关键发现。这些发现包括语言模型在处理矛盾决策时的困难、其在预测心理不适方面的表现以及对价值转换的理解不足，以及与数学问题解决和游戏策略相关的认知行为在价值推理中的无效性。此外，还发现了新的失败模式，并揭示了语言模型在推理时对特定价值观的不同偏向性
### Conclusion
CLASH研究发现，即使强大的专有模型也难以应对矛盾决策，语言模型在理解涉及价值转换的视角方面表现不足，并且在从外人视角推理时表现出更大的可引导性，但某些价值观（如安全）更多地从第一人称框架中受益。这些发现揭示了专有模型和语言模型处理高风险决策情景的限制和独特挑战。
## 342. `cs.AI` - TokUR：大型语言模型推理中的token级不确定性估计 [PDF](https://arxiv.org/pdf/2505.11737), [HTML](https://arxiv.org/abs/2505.11737)
### Authors
Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang
### Background
尽管大型语言模型（LLMs）展现了令人印象深刻的能力，但它们在不同应用场景中的输出质量并不一致，这使得难以识别可信的响应，特别是在需要多步推理的复杂任务中。因此，需要一种机制来帮助LLMs在推理过程中进行自我评估并改善其响应的可靠性。
### Innovation
提出了一个token级不确定性估计框架（TokUR），该框架使LLMs能够自我评估和自我提升在数学推理中的响应。具体来说，通过在LLMs解码期间引入低秩随机权重扰动以生成token级不确定性估计的预测分布，并将这些不确定性数量聚合起来捕捉生成响应的语义不确定性。
### Conclusion
实验表明，TokUR与答案正确性和模型健壮性之间存在显著的相关性，产生的不确定性信号可以用于增强模型在测试时的推理性能。这些结果突显了TokUR作为一种指导性和可扩展的方法，在提高LLMs在挑战性推理任务中的可靠性和可解释性方面具有有效性。
## 343. `cs.AI` - CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis [PDF](https://arxiv.org/pdf/2504.19223), [HTML](https://arxiv.org/abs/2504.19223)
### Authors
Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic
### Background
光谱成像在多个领域（如医学和城市场景理解）具有广泛应用，并已成为遥感中的关键模态。然而，不同光谱相机在通道维度和捕捉波长上的差异阻碍了AI驱动方法的发展，导致了相机特定的模型缺乏泛化能力和跨相机应用能力。这些因素构成了当前技术的一大瓶颈。
### Innovation
该论文提出了CARL（Camera-Agnostic Representation Learning），一种适用于RGB、多光谱和高光谱成像模态的无相机依赖的表示学习模型。为了解决任意通道维度的光谱图像转换为无相机依赖表示的问题，引入了新型光谱编码器，采用自我注意力-交叉注意力机制提取关键光谱信息。此外，通过一种为CARL定制的基于特征的半监督预训练策略，实现了跨谱域的预训练。在医学成像、自主驾驶和卫星成像等领域的大型实验中，展示出模型对光谱异质性的独特鲁棒性，并在模拟和真实世界的跨相机光谱变化数据集上展现出优越性能。
### Conclusion
所提出的方法高度可扩展且通用，未来有望作为光谱基础模型的核心组件。
## 344. `cs.AI` - HiddenBench: 通过隐藏资料任务评估多智能体LLM的集体推理 [PDF](https://arxiv.org/pdf/2505.11556), [HTML](https://arxiv.org/abs/2505.11556)
### Authors
Yuxuan Li,Aoi Naito,Hirokazu Shirado
### Background
基于大型语言模型（LLMs）的多智能体系统通过分散的信息整合提供了增强的问题解决能力，但也可能复制人类群体在集体推理中出现的失败。然而，缺乏理论指导的基准使系统性评估与改进这样的推理变得困难。
### Innovation
引入了HiddenBench，这是第一个用于评估多智能体LLMs集体推理能力的基准。HiddenBench基于社会心理学中的隐藏档案范式，通过定制任务并用GPT-4.1组进行了实证研究，揭示了集体推理中的持久性局限性。另外，该基准覆盖了65个任务，这些任务来自定制设计、先前的人类研究和自动生成。
### Conclusion
我们的工作提供了第一个多智能体LLMs集体推理可重复性的基准，提供诊断见解并为未来的人工集体智能研究奠定了基础。
## 345. `cs.AI` - 基于深度学习的多智能体系统神经指挥框架：多领域任务环境中的最优智能体选择 [PDF](https://arxiv.org/pdf/2505.02861), [HTML](https://arxiv.org/abs/2505.02861)
### Authors
Kushagra Agrawal,Nisharg Nargund
### Background
多智能体系统（MAS）在模拟包含自主和互动实体的复杂现实世界场景方面至关重要。然而，传统的MAS架构常常遭受僵化的协调机制和难以适应动态任务的问题。
### Innovation
提出了一种名为MetaOrch的神经指挥框架，用于在多领域任务环境中进行智能体选择。该系统采用监督学习方法，结合任务上下文、智能体历史和预期响应质量来选择每个任务的最佳智能体。引入了新颖的模糊评估模块，根据响应的完整性、相关性和置信度生成软监督标签进行训练。与先前硬编码智能体任务映射的方法不同，MetaOrch能够动态预测最佳智能体并估算选择置信度。
### Conclusion
在具有异构智能体的模拟环境中进行的实验表明，我们的方法在86.3%的智能体选择准确性方面显著优于策略性选择和轮询调度等基线策略。模块化的架构强调可扩展性，允许智能体独立注册、更新和查询。结果表明，神经指挥为增强跨不同任务领域的多智能体系统的自主性、可解释性和适应性提供了强大方法。
## 346. `cs.AI` - LLMs中递归训练环路：训练数据属性如何调节生成数据中的分布偏移？ [PDF](https://arxiv.org/pdf/2504.03814), [HTML](https://arxiv.org/abs/2504.03814)
### Authors
Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer
### Background
大型语言模型（LLMs）在在线内容创作中的应用日益增加，这导致了反馈循环，后续模型会基于之前生成的数据进行训练。这种循环可能导致分布偏移，即模型对人类数据真实分布的错误表示（也称为模型崩溃）。尽管如此，人类数据属性如何影响这种偏移还不十分清楚。本研究首次通过实证方法探讨了这些属性如何影响递归训练的结果，确认了使用不同的人类数据集会导致不同规模的分布偏移，并通过数据属性的操作和回归分析，发现了一组预测分布偏移规模的属性。此外，研究揭示词汇多样性会放大这些偏移，而语义多样性和数据质量则会减弱它们。研究表明影响高度模块化，在一个互联网领域抓取的数据对另一个领域的内容影响很小，进一步的实验还揭示了人类数据属性如何影响初始偏见是被放大还是减弱。这些发现描绘了一个全新的视角，即将互联网的不同部分经历不同类型的分布偏移。
### Innovation
本研究首次通过实证方法探讨了人类数据属性如何影响递归训练的结果。通过数据属性的操作和回归分析，本研究发现了预测分布偏移规模的一组属性，并揭示了词汇多样性放大偏移，而语义多样性和数据质量则减弱它们的影响。此外，研究还发现这些影响高度模块化，在一个互联网领域抓取的数据对另一个领域的内容影响很小。研究还通过政治偏见实验揭示了人类数据属性如何影响初始偏见是被放大还是减弱。这些发现为理解大规模语言模型的训练过程提供了一个新的视角。
### Conclusion
本研究揭示了互联网的不同部分可能会经历不同类型的分布偏移，详细探讨了人类数据属性对生成数据中分布偏移的影响，哪些属性会放大或减少这种偏移，并提出了模块化影响的概念，在特定领域抓取的数据集中抓取的数据对其他领域的生成内容影响较小。最终，研究提供的结果展示了一个全新视角，即互联网的不同部分可能会经历不同类型的分布偏移。
## 347. `cs.AI` - 采用不变神经场表示的几何意识的稳态偏微分方程推理 [PDF](https://arxiv.org/pdf/2504.18591), [HTML](https://arxiv.org/abs/2504.18591)
### Authors
Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier
### Background
随着神经操作符的发展，已经引入了在通用几何结构上具有离散化不变的代理模型来表示偏微分方程(PDEs)。然而，许多方法在编码本地几何结构和可变域方面仍然存在挑战。本文探讨了一种新方法enf2enf，用于预测具有几何变化的稳态PDEs，该方法通过在特定空间位置锚定的潜在特征来编码几何形状，并在整个网络中保持局部性。这种局部表示与全局参数结合并通过解码生成连续的物理场，从而能够有效建模复杂的形状变化。
### Innovation
提出了一种新颖的方法enf2enf，采用不变的神经场表示来预测具有几何变化的稳态PDEs。该方法通过在特定空间位置锚定的潜在特征来编码几何形状，并在整个网络中保持局部性。这些局部表示与全局参数结合，通过解码生成连续的物理场，从而能够有效建模复杂的形状变化。实验结果表明，该方法在航空和结构基准测试中与基于图的方法、神经操作符和最近的神经场方法相比具有竞争力或更优性能，且具有实时推理和高效的高分辨率网格扩展能力
### Conclusion
实验结果表明，enf2enf 方法在航空和结构基准测试中与基于图的方法、神经操作符和最近的神经场方法相比具有竞争力或更优性能，且具有实时推理和高效的高分辨率网格扩展能力。
## 348. `cs.AI` - 特征抵押：相关特征破坏窄稀疏自编码器 [PDF](https://arxiv.org/pdf/2505.11756), [HTML](https://arxiv.org/abs/2505.11756)
### Authors
David Chanin,Tomáš Dulka,Adrià Garriga-Alonso
### Background
假设稀疏自编码器（SAEs）能够将多语义激活分解为可解释的线性方向，前提是这些激活是由底层特征的稀疏线性组合构成的。然而，研究发现，如果一个SAE比其训练所需的“真实特征”数量更窄，并且特征之间存在相关性，SAE会将相关特征的成分合并，从而破坏其单语义性。在语言大模型（LLM）的SAEs中，这两个条件几乎肯定会满足。这一现象被称为特征抵押，是由SAE重构损失导致的，并且在SAE更窄的情况下更为严重。
### Innovation
本文引入了特征抵押这一问题，并在玩具模型中以理论方式和在大模型训练的SAE中进行了实验研究。同时，基于对特征抵押的理解，提出了改进版的马特罗什卡稀疏自编码器。
### Conclusion
我们的研究显示，SAE的宽度不是一个中性的超参数：更窄的SAE比更宽的SAE在特征抵押问题上遭受更大的影响。这一发现可能解释了为什么SAE在与监督基线模型相比时常常表现出不如预期的性能。
## 349. `cs.AI` - 意图手语：用手势表达意图 [PDF](https://arxiv.org/pdf/2505.15197), [HTML](https://arxiv.org/abs/2505.15197)
### Authors
Pinxin Liu,Haiyang Liu,Luchuan Song,Jason J. Corso,Chenliang Xu
### Background
当人类说话时，手势有助于传达沟通意图，如强调或描述概念。然而，当前的伴手势生成方法仅依赖于浅层语言线索（例如语音音频或文本转录），而忽视了驱动人类手势的沟通意图。这导致生成的手势在节奏上与语音同步，但在语义上却浅薄。
### Innovation
我们介绍了一个新型框架Intentional-Gesture，将手势生成转化为一个基于高级沟通功能的情境推理任务。首先，通过为BEAT-2数据集添加手势意图注释（即总结意图的文本句子）来构建InG数据集；其次，我们引入了意图手势运动标记化算法，能够注入高级沟通功能（例如意图），使姿态合成既时间对齐又具有语义意义，从而在BEAT-2基准测试上取得了新最优性能。
### Conclusion
我们的框架为数字人类和具身AI中的富有表现力的手势生成提供了一个模块化的基础。
## 350. `cs.AI` - 八阶视觉变换器：通过类不变性实现更快的ViTs [PDF](https://arxiv.org/pdf/2505.15441), [HTML](https://arxiv.org/abs/2505.15441)
### Authors
David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman
### Background
当前最先进的视觉变换器（ViTs）通常不利用自然几何对称性，例如90度旋转和镜像对称。本文讨论了ViTs目前缺乏对这些对称性的利用并非由于基础理论限制，而是由于缺乏有效的实现方法。
### Innovation
本文提出了一种新的八阶视觉变换器（octic ViTs），依赖于八阶群对不变性的捕捉。这种方法相比之前的可变模型减少了计算成本，octic线性层相较于普通线性层实现了5.33倍的FLOPs减少和高达8倍的内存减少。在完全八阶ViT块中，计算量减少接近于线性层中随嵌入维度增加而减少的计算量。研究展示了两组新的基于八阶块的ViT家族，它们要么完全具有八阶对称性不变性，要么在网络的最后一部分打破对称性。
### Conclusion
通过监督（DeiT-III）和无监督（DINOv2）训练方法在ImageNet-1K数据集上的试验，研究表明八阶ViT可以达到与基线模型相当的准确度，同时提供显著的效率提升。
## 351. `cs.AI` - 响应属性：检索增强生成中上下文属性的詹森-沙恩 divergence 驱动机制研究 [PDF](https://arxiv.org/pdf/2505.16415), [HTML](https://arxiv.org/abs/2505.16415)
### Authors
Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz
### Background
检索增强生成（RAG）利用大规模语言模型（LLMs）结合外部上下文，提高生成响应的准确性和可靠性。然而，当前方法在可靠地将生成内容归因于特定上下文片段（即上下文归因）方面面临挑战，因为这些方法通常需要大量的微调或人工标注，这在计算上是密集的。
### Innovation
本文介绍了一种新的詹森-沙恩发散驱动方法（ARC-JSD），该方法通过消除额外的微调、无需计算梯度或使用代理模型，实现了上下文归因的高效且准确的识别。与先前基于代理的方法相比，在广泛的RAG基准测试，如TyDi QA、Hotpot QA和Musique上，使用不同规模的指令调优LLM进行评估，显示出更高的准确性和显著的计算效率提升。此外，我们的机制分析揭示了特定注意头和多层感知机（MLP）层负责上下文归因，提供了关于RAG模型内部运作及其对RAG行为影响的宝贵见解。
### Conclusion
我们的代码可在以下链接访问：this https URL。
## 352. `cs.AI` - 量化与推理：探索和缓解低比特LLMs在数学推理中的下降现象及其抑制方法 [PDF](https://arxiv.org/pdf/2505.11574), [HTML](https://arxiv.org/abs/2505.11574)
### Authors
Zhen Li,Yupeng Su,Songmiao Wang,Runming Yang,Congkai Xie,Aofan Liu,Ming Li,Jiannong Cao,Yuan Xie,Ngai Wong,Hongxia Yang
### Background
低比特后训练量化（PTQ）是部署具备推理能力的大语言模型（LLMs）的一种实用途径，尤其是在严格的存储和延迟预算下，但这种技术可能会显著损害数学推理能力（在更难的环境中下降幅度高达69.81%）。本文通过精确的过程级评估，探讨了两个关键问题：在推理步骤的过程中，降级首先出现在哪个环节？如何在保持低比特量化的同时加以缓解？
### Innovation
研究团队通过对广泛使用的量化方法（AWQ、GPTQ、SmoothQuant）、开源模型系列（Qwen、LLaMA）以及数学推理基准（GSM8K、MATH、AIME）进行了格式对齐的步骤级归因分析，揭示了两个稳健的规律：（i）量化在方法和执行层面的错误较之高层次概念性错误更为常见；（ii）问题的早期出现并逐渐向下级传递。基于这些规律，提出了一个轻量级的干预原则：精确恢复最早期失败前沿的局部标记级余量。并将其实现为一个对量化模型直接操作的“确定->还原”循环机制，即检测第一步故障、构建“银弹”数据集，并进行小规模监督或偏好微调。
### Conclusion
在作者的研究设置中，通过332个精挑细选的例子和单个GPU几到五分钟的计算资源，4比特权重的数学推理能力被恢复到了全精度基线，同时保持了量化效率。该框架在评估范围内的量化器和架构是通用的，并能将低比特量化导致的全局准确性问题转变为一个局部、可重复的过程干预问题。
## 353. `cs.AI` - VocalAgent：具安全意识评估的大语言模型在改善嗓音健康诊断中的应用 [PDF](https://arxiv.org/pdf/2505.13577), [HTML](https://arxiv.org/abs/2505.13577)
### Authors
Yubin Kim,Taehan Kim,Wonjune Kang,Eugene Park,Joonsik Yoon,Dongjae Lee,Xin Liu,Daniel McDuff,Hyeonhoon Lee,Cynthia Breazeal,Hae Won Park
### Background
嗓音健康在人们的生活和沟通中起着关键作用，但全球范围内嗓音障碍的普遍存在却使得很多人缺乏方便的诊断和治疗方式。
### Innovation
介绍了一种名为VocalAgent的音频大语言模型，该模型通过利用在医院患者中采集的数据集进行微调，来解决嗓音健康诊断的挑战。使用了一个包含安全性评估、跨语言性能分析和模态消融研究的多层次评估框架。VocalAgent在嗓音障碍分类上的准确率优于最先进的基线方法，并且基于大语言模型的方法提供了一个可扩展的解决方案，促进更广泛地采用健康诊断服务，强调了伦理和技术验证的重要性。
### Conclusion
VocalAgent展示了在嗓音障碍分类上的优越准确性，基于大语言模型的方法提供了一种可扩展的解决方案，为更广泛的健康诊断应用铺平了道路，同时加强了对伦理和技术验证的重视。
## 354. `cs.AI` - Shadow-FT：通过训练配对基础模型调优指令模型 [PDF](https://arxiv.org/pdf/2505.12716), [HTML](https://arxiv.org/abs/2505.12716)
### Authors
Taiqiang Wu,Runming Yang,Jiayi Li,Pengfei Hu,Yik-Chung Wu,Ngai Wong,Yujiu Yang
### Background
大语言模型（LLMs）在各种任务上受益于进一步微调，但直接对指令调优模型进行微调往往只带来微小改进，甚至可能导致性能下降。基础模型作为这些指令变体的基础，重量值高度相似（例如，以平均不到2%的差异区分Llama 3.1 8B的基模型和指令模型）。基模型可以很好地学习，但在不附加训练的情况下却是较弱的支撑。
### Innovation
提出了一种名为Shadow-FT的新型框架，利用配对基础模型对指令模型进行微调。关键在于首先微调基础模型，然后直接将学到的重量更新应用到指令模型中。Shadow-FT无需引入额外参数，实现简单，并显著提高性能。实验表明，Shadow-FT在主流LLM（如Qwen 3和Llama 3系列）的多个基准测试中表现优于传统全参数和高效参数微调方法。此外，Shadow-FT适用于多模态大语言模型，并可与直接偏好优化（DPO）结合使用。
### Conclusion
Shadow-FT框架在多个基准测试中实现了改进，并显示了其在多模态大语言模型和直接偏好优化中的应用潜力。
## 355. `cs.AI` - 通过环境引导交互学习分层领域模型 [PDF](https://arxiv.org/pdf/2505.13497), [HTML](https://arxiv.org/abs/2505.13497)
### Authors
Claudius Kienle,Benjamin Alt,Oleg Arenz,Jan Peters
### Background
领域模型使自主代理能够通过生成可解释的计划来解决长期任务。然而，在开放的世界环境中，单个通用领域模型无法捕捉各种任务的多样性，因此代理必须在生成适合特定任务的模型方面实时做出适合的。大型语言模型（LLMs）具有潜在的常识知识可以生成这样的领域模型，但由于其高错误率，限制了它们的应用。因此，相关工作依赖于大量的人工反馈或先验知识，这破坏了自主、开放世界的部署。本文探讨了LODGÉ框架，利用LLMs和环境的相互作用来学习和构建领域模型，通过层次抽象和自动模拟来识别和纠正不同抽象层之间的不一致性和领域模型与环境之间的不一致性。这种框架是任务无关的，因为它生成命题、操作及其前提条件和效果，仅假设访问模拟器和一系列通用低级技能的执行。
### Innovation
LODGÉ框架通过环境引导的相互作用来学习分层领域模型，利用LLMs和环境的相互作用，通过层次抽象和自动模拟来识别和纠正不同抽象层之间的不一致性和领域模型与环境之间的不一致性。该框架生成命题、操作及其前提条件和效果，仅假设访问模拟器和一系列通用低级技能的执行，无需人类反馈或演示即可实现高效的自主领域学习。
### Conclusion
实验结果表明，LODGÉ生成的领域模型更准确，任务成功率更高，需要的环境交互显著减少，也未依赖于人工反馈或演示。
## 356. `cs.AI` - 结构化的关系表示 [PDF](https://arxiv.org/pdf/2505.12143), [HTML](https://arxiv.org/abs/2505.12143)
### Authors
Arun Kumar,Paul Schrater
### Background
不变表示是表示学习的核心，但面临的挑战在于发现那些稳定且可转移，但又不会抑制任务相关信息的不变性特征。因此，需要进一步研究此类不变性特征的适当抽象层次，以及它们应该描述系统中的哪些方面。环境解读依赖于抽象知识结构来理解当前状态，这推动了学习和知识获取的过程。解析表示操作在高层次的关系知识层面上，因此提出，知识必须存储在不变结构中，特别是由抽象知识空间内的关系路径闭包定义的分区。这些分区构成不变表示的核心，是知识存储和学习发生的结构底座。另一方面，跨分区连接器使得这些知识分区能够编码任务相关信息，从而使知识得以部署。因此，不变性的分区为结构化的表示提供了基础构成单元。基于闭合半环的计算理论对于结构化关系的不变性分区的表示提供了基础理论支持和计算基础。
### Innovation
提出了关于知识存储和学习的结构化关系表示模型。这是基于关系代数结构的闭合半环理论的新型表示框架。强调了不变结构中的分区和跨分区连接器在知识存储和任务相关过渡中的作用，为结构化关系表示提供了新的理解和计算方法。
### Conclusion
提出了基于闭合半环的新型计算理论，为结构化的不变关系表示提供了一种新的方法。该理论背景下，关于知识的存储、学习和迁移机制的设计开辟了新的思路。
## 357. `cs.AI` - 超越静态测试平台：基于交互的动态推荐系统代理仿真平台 [PDF](https://arxiv.org/pdf/2505.16429), [HTML](https://arxiv.org/abs/2505.16429)
### Authors
Song Jin,Juntian Zhang,Yuhan Liu,Xun Zhang,Yufei Zhang,Guojun Yin,Fei Jiang,Wei Lin,Rui Yan
### Background
推荐系统的评估和迭代至关重要，但传统的A/B测试占用资源较大，而离线方法难以处理动态的用户-平台交互。虽然基于代理的仿真具有潜力，但现有平台通常缺乏用户行为动态重塑环境的有效机制。
### Innovation
引入了RecInter，一个用于推荐系统的新型基于代理的仿真平台，包含了一种强大的交互机制。模拟用户行为（如点赞、评论、购买）实时更新项目属性，并引入了商户代理，促进更真实的、不断演化的生态系统。通过多维用户画像模块、先进的代理架构和在包含思维链（CoT）增强交互数据上微调的LLM，确保了高保真仿真。平台显著提高了仿真可信度，并成功再现了品牌忠诚度和马太效应。
### Conclusion
交互机制对于模拟现实系统的演进至关重要，平台被确立为推荐系统研究的有效试验床。
## 358. `cs.AI` - Latent Veracity Inference for Identifying Errors in Stepwise Reasoning [PDF](https://arxiv.org/pdf/2505.11824), [HTML](https://arxiv.org/abs/2505.11824)
### Authors
Minsu Kim,Jean-Pierre Falet,Oliver E. Richardson,Xiaoyin Chen,Moksh Jain,Sungjin Ahn,Sungsoo Ahn,Yoshua Bengio
### Background
链式推理（CoT）已经成为自然语言模型（LMs）的能力和透明度的重要推动因素，但推理链中可能包含不准确的陈述，这会降低性能和可信度。为了应对这一挑战，该研究提出为CoT中的每一步添加一个潜在可信度（或正确性）变量。通过引入一种基于可信度赋值的离散搜索算法——Veracity Search（VS），该方法能够利用LM的可信度和最终答案的联合似然作为代理奖励，进行后验分布的高效推断，确保推理链中每个步骤的准确性。这一方法使得监督微调Amortized Veracity Inference（AVI）机器成为可能，提供可信度伪标签，使得AVI能够在新的情境中进行准确的零样本可信度推断。实验结果表明，VS和AVI能够在逻辑推理（ProntoQA）、数学推理（GSM8K）和常识推理（CommonsenseQA）等基准测试中可靠地识别错误，并且AVI达到了相符的零样本准确性。同时，潜在可信度推理还可以用于自我纠正和自我改进过程中的反馈提供，增强自我纠错和自我改进的效果。
### Innovation
该研究提出了Veracity Search（VS），一种基于可信度赋值的离散搜索算法，用于探索可信度变量扩展后的推理链空间。此外，该研究还提出了一种Amortized Veracity Inference（AVI）机器，能够在新的情境中进行准确的零样本可信度推断。通过这一方法，研究实现了监督微调和基于错误反馈的自我纠正与改进，提升了模型的可靠性和用户体验。
### Conclusion
研究结果表明，Veracity Search在逻辑、数学和常识推理等场景中能够准确地识别推理链中的错误，并且通过Amortized Veracity Inference的使用，展示了在新情境下的零样本准确性。此外，潜在可信度推理为模型的自我纠正和自我改进提供了有效的支持。
## 359. `cs.AI` - 极光号：最优矩阵符号方法及其在Muon算法中的应用 [PDF](https://arxiv.org/pdf/2505.16932), [HTML](https://arxiv.org/abs/2505.16932)
### Authors
Noah Amsel,David Persson,Christopher Musco,Robert M. Gower
### Background
计算极分解及其相关矩阵符号函数是数值分析中研究了几十年的经典问题。近年来，它已成为Muon算法中训练深度神经网络的重要子程序。然而，这种应用的要求与传统的设置大不相同：深度学习需要适合GPU的算法，优先考虑高吞吐量而非高精度。
### Innovation
提出了一种新的计算极分解的方法——极光号（Polar Express）。该方法结合了Chen & Chow和Nakatsukasa & Freund早期工作中的思想，通过在每一步迭代中解决最小极大优化问题来调整更新规则。这种方法在最坏情况下的误差最小化，使极光号在早期迭代和渐近时都能尽可能快速收敛。此外，还解决了有限精度问题，使其能够在bfloat16中实用。
### Conclusion
将该方法集成到Muon训练框架中，当在来自FineWeb数据集的10亿标记上训练GPT-2模型时，对比现有的其他方案，无论在何种学习率下，都带来了验证损失的一致改善。
## 360. `cs.AI` - UniErase：迈向语言模型中精确且平衡的遗忘 [PDF](https://arxiv.org/pdf/2505.15674), [HTML](https://arxiv.org/abs/2505.15674)
### Authors
Miao Yu,Liang Lin,Guibin Zhang,Xinfeng Li,Junfeng Fang,Xingrui Yu,Ivor Tsang,Ningyu Zhang,Kun Wang,Yang Wang
### Background
大型语言模型（LLMs）需要迭代更新以解决过时信息问题，LLM遗忘提供了一种有选择地移除的方法。然而，主流遗忘方法主要依赖于微调技术，这些技术在精确遗忘方面经常缺乏精准性，并且难以在大规模和序列设置中平衡遗忘效果与通用能力。
### Innovation
本文介绍了UniErase，一种新颖的遗忘框架，可以在知识遗忘和能力保留之间实现精确和平衡的性能。首先提出了遗忘令牌，可以优化引导LLM进入遗忘空间。为进一步实现具体的遗忘行为，引入了轻量级的遗忘编辑，以有效地将遗忘目标与这个元令牌关联起来。UniErase通过编辑实现了一个新的遗忘范式，展示了在虚构和真实世界知识场景下批量、序列和精确遗忘任务中的出色性能。相比8个基线，UniErase仅修改了大约3.66%的LLM参数，在模型能力上超过前最好遗忘基线约4.01倍，且在遗忘效果上超过了前最好保留方法35.96%。这显示了在当前遗忘社区中平衡且双顶级性能的表现。
### Conclusion
UniErase在匿改任务和精准遗忘任务表现优异，尤其在TOFU基准测试中，其修改参数量少但性能卓越，展示了在遗忘效果与保留能力之间的平衡性能。
## 361. `cs.AI` - ZeroTuning: 初始令牌的潜能解锁，无需训练即可提高大型语言模型 [PDF](https://arxiv.org/pdf/2505.11739), [HTML](https://arxiv.org/abs/2505.11739)
### Authors
Feijiang Han,Xiaodong Yu,Jianheng Tang,Delip Rao,Weihua Du,Lyle Ungar
### Background
Token级注意力调整，特别是Post-hoc注意力 steering (PASTA) 和注意力校准（ACT），作为一种通过可解释介入改进冻结大语言模型的无训练方法，已经崭露头角。然而，这些方法依赖于辅助启发式方法来识别“重要”的任务特定令牌，这可能会引入偏差并限制应用范围，特别是在令牌重要性不明确或使用优化内核时，因无法访问注意力图。本文背景是在无训练框架下探索更简洁和优雅的方法，尤其是通过作用于初始令牌（例如，LLaMA中的<BOS>）来改进大语言模型。研究表明，对这一令牌的注意力logits添加轻量级偏差可以单向控制下游注意力分布的熵，这种效果由其自然的注意力“漏斗”功能而放大。实验分析显示，这种调整过程可以正面影响LLM并更好地启动其预训练知识，对早期层的影响更为强烈，并且在不同注意力头之间具有不同的扩展偏好。
### Innovation
本文提出了一种新的无训练方法ZeroTuning，通过在初始令牌上应用特定注意力调整，无需参数更新即可改进LLM性能。ZeroTuning包含两种模式：一种是监督模式，基于验证实例进行校准；另一种是新颖的无监督模式，直接最小化模型输出熵。该方法具有轻量、内核无关性，只需四行代码修改标准的LlamaAttention即可实现。实验证明，ZeroTuning在15个数据集中取得了广泛的改进，并显著优于之前更复杂的方法，例如，在分类上相对提高了19.9%，在问答任务上提高了4.5%，在对话系统上提高了2.1%。此外，ZeroTuning还适用于量化推理，并能在上下文长度增加时保持性能提升。
### Conclusion
ZeroTuning方法通过修改初始令牌的注意力机制，实现无训练框架下对LLM性能的改进。该方法简单、轻量且具有广泛的适用性，能够显著提升不同任务中的模型性能，并且在不影响效率的前提下保持性能增长，特别在早期层和其他注意力头的表现中具有积极影响。这一方法为大语言模型的持续训练和优化提供了新的思路和工具。
## 362. `cs.AI` - UltraEdit: 无需训练、主题和记忆的终身语言模型编辑 [PDF](https://arxiv.org/pdf/2505.14679), [HTML](https://arxiv.org/abs/2505.14679)
### Authors
Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang
### Background
终身学习使大规模语言模型（LLMs）能够通过持续更新其内部知识来适应不断变化的信息。理想的系统应该支持高效、广泛的更新，同时保留现有能力，并确保可靠部署。虽然近期方法有了显著进步，但在大规模实践中的终身适应方面仍面临挑战。为了解决这一问题，本文提出了UltraEdit，一种无需训练、主题和记忆的方法，适用于超大规模的实际终身模型编辑。 UltraEdit通过一步中的参数变化计算不需要隐藏状态和其梯度，从而实现简单高效的处理。为改进终身设置中的可扩展性，UltraEdit采用了终身规范化策略，能够跨回合连续更新特征统计，适应分布变化并保持长时间的一致性。与前一种最先进的方法相比，UltraEdit的编辑速度提高了超过7倍，且使用的VRAM不到其四分之一，使其成为唯一能够在24GB消费级显卡上编辑7B规模模型的方法。此外，本文构建了UltraEditBench，这是目前领域中规模最大、包含超过200万个编辑对的数据集，展示了方法在高达200万次编辑的同时保持高准确性。
### Innovation
UltraEdit是一种无需训练、无需特定主题和不依赖内存的方法，适用于超大规模的企业级终身模型编辑。它通过一次计算参数变化，无需隐藏状态和梯度，简化了处理过程并提高了效率。UltraEdit还引入了终身规范化策略，实现特征统计的连续更新，通过跨回合更新来适应分布变化并保持长时间的一致性。实验结果表明，UltraEdit的编辑速度比此前最快的实现方法快7倍以上，并且使用VRAM比其少四分之一。在五个数据集和六个模型上进行的全面实验表明，UltraEdit在各种场景下的性能始终优于其他方法，为安全和可扩展的终身学习迈出了重要一步。
### Conclusion
UltraEdit为大规模语言模型的终身编辑提供了一种新的方法，既简单又高效，能够适应分布变化并保持长时间的一致性。其编辑速度远超现有方法，同时大大减少了对硬件资源的需求。实验证明，UltraEdit可以实现高准确性的大规模模型编辑，向安全、可扩展的终身学习迈进了一步。
## 363. `cs.AI` - 学习灵活的前向轨迹以改善遮罩分子扩散 [PDF](https://arxiv.org/pdf/2505.16790), [HTML](https://arxiv.org/abs/2505.16790)
### Authors
Hyunjin Seo,Taewon Kim,Sihyun Yu,SungSoo Ahn
### Background
虽然受限扩散模型（Masked Diffusion Models，MDMs）已经在离散数据建模方面取得了显著进展，但它们在分子生成方面的潜力尚未得到充分探索。标准的MDMs在应用时表现不佳，原因在于分子状态冲突问题，即不同分子在前向扩散过程中合并到一个共同状态，导致无法通过普通的逆向扩散过程学习到具有单一预测的重建目标。
### Innovation
本文提出的Masked Element-wise Learnable Diffusion (MELD)模型通过为每个分子图元分配不同的噪声调度参数，构造不同的破坏路径，以避免不同分子图之间的冲突，从而解决上述问题。MELD在各种分子基准测试中明显提高了生成质量，特别是在ZINC250K数据集上，使得基本的MDMs化学有效性从15%提高到了93%，并且在条件生成任务中达到了最先进的属性对齐效果。
### Conclusion
MELD通过灵活的前向噪音调度，显著提高了分子生成的质量和化学有效性，展示了在分子生成中的强大潜力。
## 364. `cs.AI` - Bottlenecked Transformers: Periodic KV Cache Consolidation for Generalized Reasoning [PDF](https://arxiv.org/pdf/2505.16950), [HTML](https://arxiv.org/abs/2505.16950)
### Authors
Adnan Oomerjee,Zafeirios Fountas,Haitham Bou-Ammar,Jun Wang
### Background
Transformer大语言模型（LLM）已经显示出随推理时延计算增加的强推理能力，尤其是在标记空间中的'思考链'方面。现有研究表明，额外的计算可以通过模型的潜空间推入，被定义为辅助潜空间计算（ALSC）。现有的ALSC方法主要分为三类：标记中介的潜空间展开、残差/激活方向控制以及记忆（键值，KV）压缩。然而，关于记忆巩固/重新巩固（两种使新生记忆痕迹稳定，以及在回忆时暂时使其变得可塑的过程）的潜在应用仍然被低估。
### Innovation
本文提供了一个理论依据，解释为什么通过KV缓存重写进行记忆（重）巩固对于改进推理是有益的。这种理论依据基于信息瓶颈（IB）理论，该理论认为模型泛化来源于输入信息压缩和保留预测信息之间的最佳平衡。进一步地，作者提出了Bottlenecked Transformer，这是一种增强LLM的架构，加入了Cache处理器，这是一种间歇性、非因果、在断行标记推理步骤边界上的原位KV重写辅助Transformer。通过重写新写的KV条目以及选择性重写先前的KV条目进行巩固/重新巩固，模型在数学推理基准测试中表现出一致的性能提升。
### Conclusion
Bottlenecked Transformer模型在其所测试的任务和LLM结构中表现出相对于基本Transformer和附加暂停标记基线的持续性能提升，在选定的任务/结构上性能提升高达6.6个百分点。
## 365. `cs.AI` - BP-Seg：一种基于信念传播的无监督且非连续文本分割的图模型方法 [PDF](https://arxiv.org/pdf/2505.16965), [HTML](https://arxiv.org/abs/2505.16965)
### Authors
Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz
### Background
基于语义意义的文本分段是许多下游应用中的一项基本任务。当前的研究方法主要考虑了局部连贯性，并且有效地对在文本中距离较远但仍具有语义相似性的句子进行了分组。本研究提出了一个基于图模型的无监督学习方法，BP-Seg，用于高效的文本分段。BP-Seg通过精心构建的图模型上的信念传播实现了这一目标。
### Innovation
BP-Seg不仅考虑了局部连贯性，还有效分组了在文本中距离较远但仍具有语义相似性的句子。这一方法通过精心构建的图模型上的信念传播实现。实验结果表明，BP-Seg在与竞争方法的比较中表现良好。
### Conclusion
BP-Seg方法在无监督且非连续文本分割任务中表现优于现有方法，展示了其在广泛下游应用中的潜力。
## 366. `cs.AI` - Unlearning 不是删除：探究大语言模型中机器反学习的可逆性 [PDF](https://arxiv.org/pdf/2505.16831), [HTML](https://arxiv.org/abs/2505.16831)
### Authors
Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu
### Background
该研究旨在探讨大语言模型（LLMs）在删除特定数据后的真实效果。传统上，评估这类效果通常依赖于任务级别的度量标准，如准确性（accuracy）和困惑度（perplexity），但这些度量标准通常具有误导性。研究显示，模型看似忘记了某些数据，但实际上只需进行少量微调就能恢复其原始行为。这一现象称为“可逆性”，意味着信息并不是真正被删除或掩盖，而是被抑制。这一发现暴露了当前评估实践中存在的根本性差距，需要引入一种新的评估框架来更好地理解数据删除的实际效果及其机制。
### Innovation
本文提出了一种新的代表级别的分析框架，包括基于 PCA 的相似性和偏移、中心核对齐（CKA）以及 Fisher 信息，以及补充的摘要度量，即 PCA 距离均值，用于衡量表示偏离。通过应用这一框架，研究区分了四种不同的遗忘模式：基于可逆性和灾难性的不同。研究还揭示了实现理想状态——不可逆且非灾难性的遗忘——极具挑战性。通过探究反学习的极限，研究团队发现了一个看似不可逆且有针对性的遗忘案例，为设计更 robust 的数据擦除算法提供了新的见解。这一框架的提出为建立值得信赖的数据删除提供了新的代表级别基础。
### Conclusion
研究发现，实现不可逆且非灾难性的遗忘状态是极其困难的。通过系统的分析，团队不仅揭示了反学习评估中存在的关键差距，还提出了代表级别的分析框架，这不仅为进一步研究提供了新的视角，也为实现更可靠的数据擦除算法奠定了基础。
## 367. `cs.AI` - 基于有限数据和未知物理的频谱启发式算子学习 [PDF](https://arxiv.org/pdf/2505.21573), [HTML](https://arxiv.org/abs/2505.21573)
### Authors
Han Wan,Rui Zhang,Hao Sun
### Background
学习未知物理下有限数据中的偏微分方程（PDE）动力学是一项挑战。现有的神经PDE求解器要么需要大量数据，要么依赖已知的物理信息（如PDE残差或手工构建的核），这限制了它们的应用范围。
### Innovation
提出了频谱启发式的神经算子（SINO），能够在只有2-5条轨迹的情况下建模复杂的系统，并且无需显式的PDE项。SINO 自动捕捉频率索引中的局部和全局空间导数，从而在无物理假设的情况下提供物理算子的紧凑表示。为了建模非线性效应，SINO 使用Pi-块执行谱特征上的乘法操作，并结合低通滤波器以抑制伪影。
### Conclusion
在2D和3D偏微分方程基准测试中的广泛实验表明，SINO 达到了最先进的性能，准确度提高了1-2个数量级。特别是，仅使用5个训练轨迹，SINO 的表现优于在1000个轨迹上训练的数据驱动方法，并且在其他方法失效的难题场景中仍然具有预测能力。
## 368. `cs.AI` - 从标记到思想：LLMs和人类如何在压缩和意义之间进行权衡 [PDF](https://arxiv.org/pdf/2505.17117), [HTML](https://arxiv.org/abs/2505.17117)
### Authors
Chen Shani,Liron Soffer,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv
### Background
人类将知识组织成紧凑的类别，这种组织方式在压缩空间和保持语义意义之间达到平衡。大型语言模型（LLMs）表现出色，但在是否能达到相同的平衡上仍存在不确定性。本文通过应用信息瓶颈原则，定量比较LLMs和人类在压缩和意义之间如何权衡，分析了40多种不同参数的LLMs和经典的人类分类基准数据，发现了关键洞见。
### Innovation
应用信息瓶颈原则来分析LLMs和人类在压缩和意义之间的权衡；系统地比较了40多个不同类型和规模的LLMs和经典的人类词汇分类基准；揭示了LLMs与人类在处理类别、统计压缩、生成机制上的差异，特别是关于概念结构发展的阶段性理论；强调LLMs侧重于压缩，而人类侧重于适应性效果的显著区别。
### Conclusion
LLMs在处理压缩和意义之间的权衡上偏向于优化压缩效率，而人类更注重背景丰富性和灵活适应性。编码模型在与人类对齐方面优于解码模型，表明生成和理解依赖于不同的机制。概念结构在训练过程中以阶段形式发展，信息处理从深层网络层逐渐移动到中间网络层。这些结果揭示了人工与生物智能的基本差异，为开发更加人本化的AI提供指导。
## 369. `cs.AI` - Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study [PDF](https://arxiv.org/pdf/2505.18697), [HTML](https://arxiv.org/abs/2505.18697)
### Authors
Ziyang Cheng,Zhixun Li,Yuhan Li,Yixin Song,Kangyi Zhao,Dawei Cheng,Jia Li,Hong Cheng,Jeffrey Xu Yu
### Background
随着现实世界数据的不断涌入，尤其是图形结构数据，学习系统需要持续获取新知识而不遗忘之前学习的信息。虽然现有大量工作致力于解决图机器学习中的灾难性遗忘问题，但这些工作都基于从零开始使用流式数据进行训练。随着预训练模型的兴起，越来越多的研究利用其强大的泛化能力进行持续学习。目前，针对图形持续学习（GCL）的实验设置存在问题，这可能导致任务ID泄露。
### Innovation
本研究首次探索大型语言模型（LLMs）在图持续学习中是否可以缓解灾难性遗忘问题。通过开发一个易于使用的基准测试LLM4GCL，评估在无回顾约束下LLMs的效果，并提出一种简单有效的Simple Graph Continual Learning (SimGCL) 方法，该方法相对于基于GNN的基线方法取得了约20%的提升。
### Conclusion
基于广泛实验，本研究提出了一种简单的有效方法SimGCL，在无回顾约束条件下超越了前最先进的GNN基线方法。为了促进可复原性，研究提供了用于训练和评估现有GCL方法的LLM4GCL基准测试框架。
## 370. `cs.AI` - 超出代理：基于轨迹的线下GFlowNet训练指导 [PDF](https://arxiv.org/pdf/2505.20110), [HTML](https://arxiv.org/abs/2505.20110)
### Authors
Ruishuo Chen,Xun Wang,Rui Hu,Zhuoran Li,Longbo Huang
### Background
生成流网络（GFlowNets）在采样多样化、高奖励的对象方面非常有效。但在许多新的奖励查询不可行的真实世界环境中，它们需要从离线数据集中进行训练。当前流行的方法（基于代理的训练）容易产生误差传播，而现有的无代理方法通常使用粗略的约束，限制了探索。
### Innovation
提出了一种基于轨迹的无代理训练框架——Trajectory-Distilled GFlowNet（TD-GFN）。该框架通过逆强化学习从离线轨迹学习密集的过渡级别边奖励，以提供丰富的结构指导，促进高效的探索。关键在于，这些奖励通过有向无环图（DAG）剪枝和优先反向训练轨迹采样间接引导策略，确保最终的梯度更新仅依赖于数据集中的真实终止奖励，从而防止误差传播。
### Conclusion
实验表明，TD-GFN在收敛速度和最终样本质量方面显著优于现有广泛的基础方法，为离线GFlowNet训练建立了一个更稳健和高效的框架。
## 371. `cs.AI` - HD-PiSSA: 高阶分布式正交适应 [PDF](https://arxiv.org/pdf/2505.18777), [HTML](https://arxiv.org/abs/2505.18777)
### Authors
Yiding Wang,Fauxu Meng,Xuefeng Zhang,Fan Jiang,Pingzhi Tang,Muhan Zhang
### Background
现有的参数有效微调（PEFT）方法，如LoRA和PiSSA，限制模型更新为低秩子空间，这限制了其表达能力，并在复杂任务上导致了次优性能。
### Innovation
本文提出了一种分布式PEFT方法——高阶分布式PiSSA（HD-PiSSA），该方法在不同设备上初始化正交适配器，并集体在W上聚合它们的delta更新以进行微调。与数据并行LoRA或PiSSA不同，HD-PiSSA将预训练权重的主成分分配给每个GPU，显著扩展了更新方向的范围。这在8个GPU上以相同的设备适配器秩进行微调时，HD-PiSSA的有效更新秩比数据并行LoRA或PiSSA高出16倍以上。
### Conclusion
我们在多种挑战性的下游任务中评估了HD-PiSSA，包括数学、代码生成和多任务学习。在多任务设置中，HD-PiSSA在12个基准测试中分别比LoRA高出10.0个绝对点（14.63%）和比PiSSA高出4.98个点（6.60%），显示出额外优化灵活度带来的优势。
## 372. `cs.AI` - Prompting is not Enough: Exploring Knowledge Integration and Controllable Generation on Large Language Models [PDF](https://arxiv.org/pdf/2505.19660), [HTML](https://arxiv.org/abs/2505.19660)
### Authors
Tingjia Shen,Hao Wang,Chuan Qin,Ruijun Sun,Yang Song,Defu Lian,Hengshu Zhu,Enhong Chen
### Background
开放域问答（OpenQA）是自然语言处理（NLP）中的一个重要领域，主要关注从非结构化文本数据中提取答案。随着大型语言模型（LLMs）的快速发展，基于LLM的OpenQA方法从参数庞大的模型中获得了更强的理解和回答能力，但这些方法在知识整合和根据不同任务自适应生成特定格式答案上存在挑战。本文聚焦于解决这些问题，并介绍了一个名为GenKI的新框架。
### Innovation
提出了一种名为GenKI的新型框架，旨在通过同时探索知识整合和可控生成来提升OpenQA性能。具体步骤包括：1) 使用密集段落检索模型从给定的知识库中检索相关知识；2) 引入一种新型知识整合模型，在微调过程中将检索到的知识融入指令，增强模型；3) 利用特定微调的LLM和基于文本一致性（包括连贯性、流畅性和答案格式保证）的集成方法实现可控生成。通过TriviaQA、MSMARCO和CMRC2018等数据集实验验证了GenKI的有效性，并揭示了检索知识频率与模型准确召回知识能力之间的线性关系。
### Conclusion
GenKI框架在多种数据集上表现优越，展示了其在知识整合和可控生成方面的创新，未来工作将进一步优化框架以更广泛的应用场景。
## 373. `cs.AI` - 基于FFT的动态子空间选择用于大型语言模型的低秩自适应优化 [PDF](https://arxiv.org/pdf/2505.17967), [HTML](https://arxiv.org/abs/2505.17967)
### Authors
Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh
### Background
低秩优化已经成为了在训练大型语言模型（LLMs）时提升运行时间和减少自适应优化器内存使用的有前景的方向。现有工作通常使用奇异值分解（SVD）或QR分解来投影线性层的梯度到更低维空间，但单独对大型模型的每一层应用这些技术会非常耗时且增加内存开销。因此，提出了一种基于离散余弦变换（DCT）的预定义正交基并行化投影方法，进一步优化低秩投影。这种方法基于DCT矩阵动态选择列来与每一层的梯度对齐，经过简单的矩阵乘法操作并附加轻量级的选择步骤，实现了在$O(n^3)$时间和$O(n^2 text{log}(n))$时间进行快速的DCT计算。由于基于正交基是预先计算的，所以可以在训练开始时一次性完成，减少了额外计算开销。
### Innovation
提出了基于DCT矩阵的两步快速投影方法来近似SVD和QR方法。这种技术能够动态选择与每一层梯度对齐的DCT矩阵的列，通过简单的矩阵乘法操作和轻量级步骤选择最相关的基础矢量，从而在保持高效的同时减少内存占用。进一步地，通过Makhoul的N点算法基于快速傅里叶变换(FFT)，可以在$O(n^2 text{log}(n))$时间计算DCT，大幅提高了低秩优化的效率。实验结果表明这种方法在不同规模模型下能够减少高达25%的内存使用，同时保持与复杂SVD/QR方法相当的性能。
### Conclusion
提出的基于DCT矩阵的低秩优化方法在预训练和微调任务中有效，通过预先计算的正交基实现了与复杂SVD/QR方法相媲美的性能，同时显著提高了运行时间和降低了内存使用，效果在不同规模的模型下均表现优异。该方法已开源。
## 374. `cs.AI` - SDPO: 重要性采样直接偏好优化以实现稳定的扩散训练 [PDF](https://arxiv.org/pdf/2505.21893), [HTML](https://arxiv.org/abs/2505.21893)
### Authors
Xiaomeng Yang,Zhiyu Tan,Junyan Wang,Zhijian Zhou,Hao Li
### Background
偏好学习已经成为使生成模型与人类期望对齐的核心技术。最近，这种技术已经被扩展到扩散模型中，例如通过直接偏好优化（DPO）方法。然而，现有方法如Diffusion-DPO存在两个关键挑战：反向扩散过程与正向扩散过程之间的步骤依赖性不稳定性，以及优化策略与数据收集策略之间的不一致性导致的政策偏差。
### Innovation
该研究首先提出了DPO-C&被及M，这种策略通过剪裁和遮罩无信息步骤来提高稳定性，部分减轻不一致性偏差。在此基础上，提出了SDPO（重要性采样直接偏好优化），这是一种原理框架，将重要性采样纳入目标函数，旨在完全纠正不一致性偏差，并在扩散过程中强调信息性更新。实验结果表明，这两种方法都优于标准的Diffusion-DPO，其中SDPO在VBench评分、人类偏好对齐和训练鲁棒性方面表现更优。这些结果强调了在基于扩散的偏好学习中，需要步骤感知且分布纠正的优化的重要性。
### Conclusion
实验结果表明，SDPO和DPO-C&被及M方法在CogVideoX-2B、CogVideoX-5B和Wan2.1-1.3B上都优于标准的Diffusion-DPO，在VBench评分、人类偏好对齐和训练稳健性方面SDPO表现更优越。这些结果强调了基于扩散的偏好学习中步骤感知和分布纠正优化的重要性。
## 375. `cs.AI` - BiomedSQL: 文本到SQL在生物医药知识库中的科学推理 [PDF](https://arxiv.org/pdf/2505.20321), [HTML](https://arxiv.org/abs/2505.20321)
### Authors
Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri
### Background
生物医药研究人员越来越多地依赖大型结构化数据库进行复杂的分析任务。当前的文本到SQL系统在将定性科学问题转换为可执行的SQL时往往难以处理，尤其是在需要隐含领域推理的情况下。因此，需要一个专门的基准来评估文本到SQL生成在生物医药知识库上的科学推理能力，特别是在需要推理背景知识和领域特定标准时。
### Innovation
本文介绍了BiomedSQL，这是首个明确设计用于评估文本到SQL生成在生物医药知识库上科学推理能力的基准。BiomedSQL由68,000个包含问题、SQL查询及答案三元组组成，这些三元组基于一个整合了基因-疾病关联、从组学数据推导出的因果推理及药物批准记录的大规模同步BigQuery知识库。通过评估多个开源和闭源的语言模型，研究发现了性能差距，GPT-o3-mini的执行准确率仅为59.0%，而自定义的多步代理BMSQL达到了62.6%，但都远低于专家基准90.0%。
### Conclusion
BiomedSQL为支持通过结构化生物医药知识库进行科学发现的文本到SQL系统提供了一个新的基础。该数据集已公开，可在特定网址访问，代码也已开源。
## 376. `cs.AI` - 基于物理原理集成Mamba的长周期混沌系统预测 [PDF](https://arxiv.org/pdf/2505.23863), [HTML](https://arxiv.org/abs/2505.23863)
### Authors
Chang Liu,Bohao Zhao,Jingtao Ding,Huandong Wang,Yong Li
### Background
长期预测混沌系统的挑战主要源于初始条件的固有敏感性和奇怪吸引子的复杂几何结构。传统方法，如蓄积计算，需要包含长期连续动力行为的训练数据，以全面捕捉系统动力学。而先进的深度序列模型虽然可以在训练数据中捕捉到瞬时动力学，但在长期预测中往往难以保持预测稳定性和动力学一致性。
### Innovation
文章提出了PhyxMamba框架，该框架通过集成基于Mamba的状态空间模型和物理导向原则，根据短期历史观测来预测混沌系统的行为。首先，通过时间延迟嵌入重构吸引子流形，提取全局动力学特征。然后引入生成训练方案使Mamba能够模拟物理过程，并通过多片预测和 attractor 几何正则化增强预测准确性，同时保持系统的关键统计特性。
### Conclusion
在模拟和实际混沌系统上的广泛实验表明，PhyxMamba 提供了卓越的预测精度，并且能够从短期历史观测中准确捕捉关键的统计特性。
## 377. `cs.AI` - DORAEMON: 分散化领域意识可靠代理与增强的记忆导向导航 [PDF](https://arxiv.org/pdf/2505.21969), [HTML](https://arxiv.org/abs/2505.21969)
### Authors
Tianjun Gu,Linfeng Li,Xuhong Wang,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan
### Background
在陌生环境中进行自适应导航对家用服务机器人至关重要，但仍然具有挑战性，因为这需要同时进行低级路径规划和高级场景理解。尽管基于视觉-语言模型（VLM）的零样本方法能够减少对先验地图和场景特定训练数据的依赖，但在解决空间时间连续性、非结构化记忆表示以及任务理解不完全导致的导航失败方面仍存在显著局限性。
### Innovation
本文提出了DORAEMON（分散化领域意识可靠代理与增强的记忆导向导航）这个新颖的认知启发式框架，它包括腹侧流和背侧流，模仿了人类的导航能力。背侧流通过层级语义-空间融合和拓扑图处理空间时间不连续性，而腹侧流结合了RAG-VLM和Policy-VLM以提高决策能力。此外，该方法还开发了Nav-Ensurance以确保导航安全性和效率。DORAEMON在HM3D、MP3D和GOAT数据集上的评估表明，它在成功率（SR）和路径长度加权成功率（SPL）指标上达到最先进的性能，显著优于现有方法。为了更好地评估导航智能，还提出了一个新的评估指标（AORI）。
### Conclusion
全面的实验表明，DORAEMON在零样本自主导航中非常有效，无需先构建地图或预训练。
## 378. `cs.AI` - 端到端误差保留的自适应四舍五入算法 [PDF](https://arxiv.org/pdf/2505.22988), [HTML](https://arxiv.org/abs/2505.22988)
### Authors
Albert Tseng,Zhaofeng Sun,Christopher De Sa
### Background
量化的目标是生成一个压缩模型，使其输出分布尽可能接近原模型。大多数量化算法通过最小化每层的即时激活误差来权衡端到端误差，但这种方法忽略了后续层的影响，因此不是一个很好的近似方法。
### Innovation
本文引入了一种新的量化算法——Yet Another Quantization Algorithm (YAQA)，这是一个自适应四舍五入算法，它直接考虑网络输出的误差。YAQA 提供了一系列理论结果，并首次为量化算法提供了端到端的误差界限。具体而言，通过分析自适应四舍五入算法的 Hessain 约简矩阵结构，可以证明端到端误差可以由其与真实 Hessain 矩阵的余弦相似度来近似，从而得到了一个近最优的哈克诺夫分解近似方法。实验表明，与 GPTQ/LDLQ 方法相比，YAQA 的误差可降低约 30%，甚至优于量化意识训练，从而在下游任务中达到最先进的性能，且完全没有推理开销。
### Conclusion
本文通过自适应四舍五入算法直接关注网络输出的误差，并给出了量化算法的第一个端到端误差界限。实验表明，YAQA 在大多数情况下能减少约 30% 的误差，实现了下游任务的最强性能，且不增加推理负担。
## 379. `cs.AI` - 社会模拟需要模拟思维 [PDF](https://arxiv.org/pdf/2506.06958), [HTML](https://arxiv.org/abs/2506.06958)
### Authors
Chance Jiajie Li,Jiayi Wu,Zhenze Mo,Ao Qu,Yuhan Tang,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Jinhua Zhao,Paul Liang,Luis Alonso,Kent Larson
### Background
现有的大型语言模型虽然能够生成合理的个人和群体行为，但在内部一致性、因果推理和信念追踪方面存在不足，导致其在模拟人的思考过程、推理、争论和干预反应时不可靠。
### Innovation
提出了一种概念性建模范式——生成思维（GenMinds），借鉴认知科学来支持生成代理的结构化信念表示。设计了RECAP（因果路径重建）基准框架，通过因果追踪、人口统计学基础和干预一致性来评估代理的推理准确性。
### Conclusion
这一贡献促进了从表面模仿到能够模仿思维的社会生成代理的更广泛转变，即不仅模拟语言，还要模拟思想进行社会模拟。
## 380. `cs.AI` - InfiMed: 低资源医学多模态大语言模型 [PDF](https://arxiv.org/pdf/2505.23867), [HTML](https://arxiv.org/abs/2505.23867)
### Authors
Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang
### Background
多模态大语言模型（MLLMs）在视觉理解和数学推理等领域取得了显著进展。然而，在医学领域的应用受到两个关键挑战的限制：(1) 医学多模态数据稀缺且通常包含信息稀疏，限制了深度推理；(2) 尽管在一般领域中有效，验证奖励学习（RLVR）在医学领域中无法可靠地提升模型性能。
### Innovation
在监督微调（SFT）阶段，通过引入高质量的文本推理数据和一般多模态数据来增强医学多模态数据，以高效提升基础医学能力并恢复基底模型的推理能力。针对信息稀疏的医学多模态数据，进一步合成带有反思模式插入的推理链（CoT）样本，赋予模型初始的反思推理能力，为后续的RLVR训练提供结构化的基础。并且，引入了InfiMed-SFT-3B和InfiMed-RL-3B两种状态最好模型，在七个医学多模态基准上的表现均领先于基准。InfiMed-RL-3B的平均准确率达到59.2%，优于InternVL3-8B（57.3%）。
### Conclusion
通过SFT阶段使用了188K样本，RLVR阶段使用了36K样本，展示了这两种训练策略在实现优越性能方面的有效性。还进行了大量实验，这些实验提供了一系列有价值的见解，有助于提高医学场景中MLLMs的表现。
## 381. `cs.AI` - 为视频生成模型提供物理指导的运动损失 [PDF](https://arxiv.org/pdf/2506.02244), [HTML](https://arxiv.org/abs/2506.02244)
### Authors
Bowen Xue,Giuseppe Claudio Guarnera,Shuang Zhao,Zahra Montazeri
### Background
当前的视频扩散模型能够生成视觉上令人印象深刻的内容，但常常违反基本的物理定律，产生如橡皮膜变形等细微的伪影，以及对象不一致的运动。这些模型在物理合理性方面表现不足，影响了视频的真实感和准确性。
### Innovation
本文提出了一种频域物理先验，该方法不修改模型结构，却能够提高运动的合理性。此方法将常见的刚体运动（平移、旋转、缩放）分解为轻量的频谱损失，仅需 2.7% 的频谱系数就能保留 97% 以上的频谱能量。实验表明，该方法在 Open-Sora、MVDIT 和 Hunyuan 模型上应用，能够平均提高 OpenVID-1M 上的运动精度和动作识别率约 11%（相对于基准模型），同时保持视觉质量。用户研究显示，物理增强视频的偏好度为 74-83%。该方法还能将形变误差降低 22-37%（依赖于基础模型），并提高时间一致性评分。
### Conclusion
研究结果表明，简单的全局频谱提示是提高视频中物理合理运动的有效正则化器。
## 382. `cs.AI` - 探究大型语言模型的神经拓扑结构 [PDF](https://arxiv.org/pdf/2506.01042), [HTML](https://arxiv.org/abs/2506.01042)
### Authors
Yu Zheng,Yuan Yuan,Yue Zhuo,Yong Li,Paolo Santi
### Background
通过将神经激活与可解释的语义联系起来，探测大型语言模型（LLMs）已揭示了它们内部机制的重要见解。然而，将神经元功能共激活与模型能力之间的关联机制仍然很大程度上未知，这阻碍了对LLMs的深入理解和安全开发。这项研究从已有的研究对比出发，指出虽然之前的实践已建立了某些关联，但其背后的机制仍然缺乏全面理解。
### Innovation
本文提出了一种新的方法——图探测，用于揭示LLM神经元的功能连接并与其语言生成性能相关联。研究发现，仅使用神经拓扑结构即可预测出下一个词的性能表现。而在保持1%神经元连接的情况下，拓扑结构的探测表现优于激活的探测高达130.4%。这表明神经拓扑结构包含比神经激活更丰富的信息，可以方便地用简单的线性或MLP探针提取。此外，研究通过干预实验识别了LLM中的默认网络和枢纽神经元，并提供了因果证据，展示了LLMs实际上是利用这些拓扑信息进行工作。研究进一步表明，神经拓扑结构可以有效提升LLMs的效率、可靠性和安全性，并提供了具体的实例应用如模型剪枝、幻觉检测和LLM指纹认证
### Conclusion
总之，通过对神经拓扑结构的研究，发现其与语言性能之间存在紧密的关联性。进一步分析表明，神经拓扑结构可以有效提高LLMs的效率、可靠性和安全性，提供了一种简化的探测方法来提取重要性能信息，这对于安全和优化LLMs具有重要价值。
## 383. `cs.AI` - VidBridge-R1: 中间代理任务连接问答和字幕理解的基于强化学习的视频理解模型 [PDF](https://arxiv.org/pdf/2506.09079), [HTML](https://arxiv.org/abs/2506.09079)
### Authors
Xinlong Chen,Yuanxing Zhang,Yushuo Guan,Weihong Lin,Zekun Wang,Bohan Zeng,Yang Shi,Sihan Yang,Qiang Liu,Pengfei Wan,Liang Wang,Tieniu Tan
### Background
现有的基于因果响应模式的增强学习增强的多模态大语言模型在视频领域取得了一定进展，但这些模型在视频问答（QA）和字幕生成任务之间难以同时表现出色。单独奖励信号的简单合并会导致任务性能下降，这主要是由于这两个任务性质的对立冲突。
### Innovation
提出了一种新的训练框架，该框架基于两个中间代理任务：DarkEventInfer（通过隐藏视频中的事件段落并要求模型基于视频上下文推断被遮掩的内容）和MixVidQA（通过交错展示两个不同视频片段，要求模型识别并分析其中一个片段而忽略另一个），旨在同时培养模型的整体理解能力和精确推理能力。基于此框架，提出了VidBridge-R1，这是第一个有效弥合这一矛盾的模型，能够在单个模型中显著提高QA和字幕生成的性能。
### Conclusion
通过广泛的实验，证明了VidBridge-R1在问答和字幕生成任务上的显著性能提升，表明该方法在培养更具普遍适用性和强大性的视频理解模型方面具有有效性。
## 384. `cs.AI` - Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection [PDF](https://arxiv.org/pdf/2506.03162), [HTML](https://arxiv.org/abs/2506.03162)
### Authors
Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh
### Background
随着监控摄像头的迅速普及，对自动化暴力检测的需求也增加了。尽管卷积神经网络（CNNs）和变换器在提取时空特征方面取得了成功，但它们在处理长期依赖关系和计算效率方面存在不足。因此，研究者需要设计更有效的架构来解决这些挑战，特别是在监控场景中的暴力检测方面。
### Innovation
本文提出了一种名为Dual Branch VideoMamba的高效架构，结合了双分支设计和状态空间模型（SSM）骨干网络，其中一支捕获空间特征，另一支专注于时间动态。该模型通过门控机制在分支之间连续融合，增强了对暴力活动的检测能力，尤其是对于具有挑战性的监控场景。此外，作者还提出了一种新的数据集基准，通过合并RWF-2000、RLVS、SURV和VioPeru数据集，并确保训练集和测试集严格分离。实验结果显示，该模型在该基准和DVD数据集上的性能达到了最先进的水平，同时平衡了准确性和计算效率，证明了状态空间模型在可扩展且接近实时的监控暴力检测中的潜力。
### Conclusion
实验结果表明，所提出的模型在新的基准和DVD数据集上达到了最先进的性能，展示了SVM模型在可扩展、接近实时的监控暴力检测方面的潜力。
## 385. `cs.AI` - 迭代AI代码生成中的安全降级——悖论的系统分析 [PDF](https://arxiv.org/pdf/2506.11022), [HTML](https://arxiv.org/abs/2506.11022)
### Authors
Shivani Shukla,Himanshu Joshi,Romilla Syed
### Background
大型语言模型（LLMs）迅速应用于代码生成，极大地改变了软件开发的方式。然而，很少有人注意到，经过迭代的人工智能反馈会如何导致安全漏洞不断演变。这项研究通过一项受控实验分析了400个代码样本在40轮“改进”（使用四种不同的提示策略）中的安全性能下降的情况。
### Innovation
该研究展示了在仅仅五次迭代后，关键漏洞增加了37.6%，并且不同的提示方法产生了不同的漏洞模式。这一发现挑战了‘通过迭代优化LLM可提高代码安全性’的假设，并强调了在LLM迭代过程中需要人类专业知识的重要性。研究提出了防止在看似有益的代码‘改进’过程中引入新安全问题的实用指南。
### Conclusion
研究表明，迭代的AI代码生成过程中，安全性能存在显著下降。人类专家在代码生成过程中的验证至关重要。研究提出了开发人员在LLM迭代中采取的具体措施，以防止引入新的安全问题。
## 386. `cs.AI` - 通过参数化知识强化学习抵抗RAG中的语境干扰 [PDF](https://arxiv.org/pdf/2506.05154), [HTML](https://arxiv.org/abs/2506.05154)
### Authors
Chenyu Lin,Yilin Wen,Du Su,Hexiang Tan,Fei Sun,Muhan Chen,Chenfu Bao,Zhonghou Lyu
### Background
检索增强生成（RAG）在知识密集型任务上表现出色，但可能因检索到的错误、无关或冲突信息而偏离轨道，导致模型依赖不准确证据并引发连锁错误。现有研究尚未明确提出如何在利用外部上下文的同时有效抵抗此类干扰，保持模型的准确性和鲁棒性。
### Innovation
提出了一种基于强化学习的知识类 Knowledgeable-R1 框架，通过引入参数化知识（PK），使大型语言模型能够抵抗外部语境干扰，同时在必要时利用可靠的外部语境。该框架通过联合采样生成检索前后配对响应，学习局部和全局优势，以决定何时忽略误导性上下文或采纳它。利用不对称的优势转换，增强探索参数化知识的倾向。实验表明，该方法在知识冲突和一般 RAG 场景中显著提高了鲁棒性和推理准确性，相比最先进的基线在假设的情况下提高了 23% 的性能，且在检索上下文完整的情况下未出现退化修剪或性能损失问题，并提供了代码链接。
### Conclusion
Knowledgeable-R1 显著提高了知识密集任务的鲁棒性和推理准确性，特别是在存在冲突信息的情况下表现出色，且不会因完整外部上下文的添加而退化。
## 387. `cs.AI` - CapSpeech: 开启风格描述文本到语音的下游应用 [PDF](https://arxiv.org/pdf/2506.02863), [HTML](https://arxiv.org/abs/2506.02863)
### Authors
Helin Wang,Jiarui Hai,Dading Chong,Karan Thakkar,Tiantian Feng,Dongchao Yang,Junhyeok Lee,Thomas Thebaud,Laureano Moro Velazquez,Jesus Villalba,Zengyi Qin,Shrikanth Narayanan,Mounya Elhiali,Najim Dehak
### Background
近年来，生成人工智能在风格描述文本到语音合成(CapTTS)领域取得了显著进展，但将其应用于实际场景仍面临挑战，主要原因是缺乏标准化、全面的数据集以及对基于CapTTS的下游任务研究较少。这导致了CapTTS在实际应用中的适应性不足。因此，需要构建一个包含多种CapTTS相关任务的新基准以填补这些空白。这些任务包括风格描述文本到语音合成带声音事件(CapTTS-SE)、口音描述的语音合成(AccCapTTS)、情感描述的语音合成(EmoCapTTS)，以及聊天代理的文本到语音合成(AgentTTS)。
### Innovation
本文介绍了CapSpeech，这是一个具有多种CapTTS相关任务的新基准数据集，主要包括超过1000万个机器标注的音频-描述对和接近36万个手工标注的音频-描述对。另外，引入了两个专门为AgentTTS和CapTTS-SE任务收集和录制的数据集，由专业配音演员和经验丰富的音频工程师完成。此外，使用自回归和非自回归模型在CapSpeech上进行了广泛的实验，结果显示具有高保真度和高可理解度的语音合成，这使其被认为是迄今为止提供全面CapTTS任务标注的最大的可用数据集。实验和发现进一步提供了关于开发CapTTS系统的挑战的宝贵见解。
### Conclusion
CapSpeech是迄今为止提供全面CapTTS任务标注的最大数据集，为CapTTS系统的开发提供了宝贵的实验和发现，进一步提供了开发CapTTS系统的挑战的宝贵见解。
## 388. `cs.AI` - DriveAction：探索VLA模型中类人驾驶决策的基准 [PDF](https://arxiv.org/pdf/2506.05667), [HTML](https://arxiv.org/abs/2506.05667)
### Authors
Yuhan Hao,Zhengning Li,Lei Sun,Weilong Wang,Naixin Yi,Sheng Song,Caihong Qin,Mofan Zhou,Yifei Zhan,Xianpeng Lang
### Background
视觉-语言-动作（VLA）模型在自主驾驶方面取得了进展，但现有的基准仍然缺乏场景多样性、可靠的动作级别注释以及与人类偏好的评价协议。DriveAction基准旨在解决这些问题，它是一个专为VLA模型设计的动作驱动型基准，包含2,610个驾驶场景生成的16,185个问答对，同时利用了由自动驾驶车辆驾驶员主动收集的真实驾驶数据，确保了广泛和代表性的场景覆盖，也提供了直接来自驾驶员实际驾驶操作的高级离散动作标签，并采用了一个以动作为核心的树状结构评估框架，明确连接了视觉、语言和动作任务，支持全面和特定任务的评估。
### Innovation
DriveAction是首个专为VLA模型设计的动作驱动基准，通过利用真实驾驶数据确保了广泛的场景覆盖，直接从驾驶员的实际操作中收集高级离散动作标签，并建立了一个以动作为核心的树状结构评估框架，支持全面和特定任务的评估。研究表明，最先进的视觉-语言模型（VLMs）在准确预测动作时需要视觉和语言指导：没有视觉输入时准确度下降3.3%，没有语言输入时下降4.1%，两种都没有时下降8.0%。评估结果支持模型瓶颈的精确识别，提供了重新认识和严谨基础，以便推进类人自主驾驶决策的发展。
### Conclusion
DriveAction的评估结果表明，最先进的视觉-语言模型需要视觉和语言的双重指导来进行准确的动作预测。模型性能在缺乏视觉或语言输入时显著下降，评估还能够识别出模型的具体弱点，为未来VLA模型的发展提供了新的洞察和严谨的基础。
## 389. `cs.AI` - AMPED: 自适应多目标投影平衡探索与技能多样性 [PDF](https://arxiv.org/pdf/2506.05980), [HTML](https://arxiv.org/abs/2506.05980)
### Authors
Geonwoo Cho,Jaemoon Lee,Jaegyun Im,Subi Lee,Jihwan Lee,Sundong Kim
### Background
技能导向的强化学习(SBRL)可以通过预训练技巧调节策略来加速在稀疏奖励环境中的适应。有效学习技能需要同时最大化探索和技能多样性。然而，现有方法在同时优化这两个目标时常常面临挑战。该论文介绍了一种新的方法，自适应多目标投影(Amped)来平衡探索和技能多样性：预训练阶段采用梯度手术投影来平衡探索和多样性梯度，微调阶段使用技能选择器通过选择适合下游任务的技能来利用学习到的多样性。这个方法在不同基准测试中超越了SBRL基线。
### Innovation
提出了Adaptive Multi-objective Projection for balancing Exploration and skill Diversification（AMPED）方法。该方法在预训练阶段通过梯度手术投影来平衡探索和多样性梯度，在微调阶段使用技能选择器根据下游任务选择技能。广泛进行的消融研究指出每个组成部分对性能提升的作用，理论和实验证据表明，贪婪的选择技能可以降低微调的样本复杂度，这些结果强调了显式平衡探索和多样性的必要性，并展示了AMPED在实现鲁棒性和通用性技能学习方面的有效性。
### Conclusion
该研究展示了如何利用自适应多目标投影来显式平衡探索和技能多样性，显著改进了技能导向的强化学习在各种环境中的适应性和性能。
## 390. `cs.AI` - 理想磁流体静力学的神经网络求解器 [PDF](https://arxiv.org/pdf/2507.03119), [HTML](https://arxiv.org/abs/2507.03119)
### Authors
Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff
### Background
作者介绍了通过使用人工神经网络参数化傅里叶模式来计算三维磁流体力学平衡，与传统求解器计算的平衡进行了比较。利用一阶优化器最小化实空间中的全非线性全局力残差。
### Innovation
使用人工神经网络求解器计算磁流体力学平衡，已经观察到可观的竞争计算成本，并且随着计算成本的增加，人工神经网络可以获得更低的残差最小值，从而确定新的残差下限。
### Conclusion
研究采用简单的人工神经网络，预期通过神经网络求解器不仅能够精确求解单一平衡，还能有效处理连续分布的平衡模型，从而进行神经网络模型的计算。
## 391. `cs.AI` - 随视频思考以实现能动的长视频理解 [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。当前的方法要么通过降采样帧进行一次性的推理，牺牲了细节的精度，要么依赖于针对特定任务的文本推理，这在某种程度上限制了特定任务的感知和探索。现有方法要么牺牲细节，要么依赖于任务无关的文本推理，这些都极大地限制了长视频的理解能力。
### Innovation
本文提出了一种名为VideoExplorer的框架，该框架基于“随视频思考”的原则，将计划、时间纠偏和可扩展的感知紧密融合到一个连贯的推理过程中。该框架迭代地提出子问题，定位相关时刻，并进行任务导向的时间可扩展视频理解，直到达到最终答案，从而实现准确、高效且可解释的推理。此外，作者还通过困难自适应采样构建了一个长视频理解数据集，以确保在复杂任务上提供高质量的轨迹。在此数据集上，设计了两个训练阶段：监督轨迹初始化和轨迹级别偏好优化，以此鼓励依据下游奖励进行自适应时间纠偏和迭代信息整合。
### Conclusion
广泛的评估显示，VideoExplorer在流行的长视频理解和推理基准测试中显著优于现有的基线方法，突出了其稳健性、适应性和效率。我们已经将代码公开发布在该仓库（此链接网址）。
## 392. `cs.AI` - 通过对比个人偏好进行个性化LLM解码 [PDF](https://arxiv.org/pdf/2506.12109), [HTML](https://arxiv.org/abs/2506.12109)
### Authors
Hyungjune Bu,Chanjoo Jung,Minjae Kang,Jaehyung Kim
### Background
随着大型语言模型（LLMs）在各种现实世界应用场景中的逐步部署，个性化LLMs变得越来越重要。尽管已经探索了诸如提示基和训练基方法等多种LLM个性化技术，但有效的解码时算法的研究仍然被忽视，尽管这些算法展现了潜力。
### Innovation
本文提出了CoPe（对比个人偏好）方法，这是一种应用在参数高效微调（PEFT）之后的新型解码时个性化方法。核心思想是通过最大化每个用户的隐式反馈信号来利用奖励引导解码，从而实现个性化。作者通过五个开放式个性化文本生成任务对CoPe进行了评估，结果显示CoPe在ROUGE-L指标上比现有方法平均提升了10.57%，且无需外部奖励模型或额外的训练步骤。
### Conclusion
CoPe方法在不依赖外部奖励模型或额外训练的情况下，在五个开放式个性化文本生成任务中展示了强大的性能，平均提升了10.57%的ROUGE-L得分，展示了其在个性化LLMs解码时的潜力。
## 393. `cs.AI` - TAMMs: Aware 模态模型用于卫星图像变化理解和预测 [PDF](https://arxiv.org/pdf/2506.18862), [HTML](https://arxiv.org/abs/2506.18862)
### Authors
Zhongbin Guo,Yuhao Wang,Ping Jian,Chengzhi Li,Xinyue Chen,Zhen Yang,Ertai E
### Background
卫星图像时间序列（SITS）分析中的临时变化描述（TCD）和未来卫星图像预测（FSIF）是关键任务，但它们在历史上是分离处理的。这两个任务都受限于建模长距离时间动态的共同挑战。为了通过增强长期时间理解能力来同时提高这两个任务的方法性能，作者引入了TAMMs，这是一种用于同时执行TCD和FSIF的第一个统一框架，基于MLLM-diffusion架构。
### Innovation
TAMMs 引入了两个关键创新：时间适配模块（TAM）增强了冻结的 MLLM 对长距离动态的理解能力，以及语义融合控制注入（SFCI）机制将这种变化理解转化为精细的生成控制。这种协同设计使得TCD任务的理解直接指导和改进FSIF任务的一致性。
### Conclusion
广泛的实验表明，TAMMs 在两个任务上显著优于最先进的专家基准。
## 394. `cs.AI` - 利用块坐标下降法实现低成本的大语言模型训练 [PDF](https://arxiv.org/pdf/2506.12037), [HTML](https://arxiv.org/abs/2506.12037)
### Authors
Zeyu Liu,Yan Li,Yunquan Zhang,Boyang Zhang,Guoyong Jiang,Xin Zhang,Limin Xiao,Weifeng Zhang,Daning Cheng
### Background
训练大型语言模型通常需要大量的GPU内存和巨大的财务投入，这对中小型团队来说是一个障碍。目前，标准的全参数训练方法成本高昂，不适用于成本效益较低的GPU集群，这限制了模型的训练性能和效率。
### Innovation
本文提出了一种基于块坐标下降法（BCD）的全参数预训练和微调框架，该框架结合了工程优化，使大型模型能够在成本效益较好的RTX 4090、A100和A800 GPU集群上进行有效训练。与标准全参数训练相比，在相同硬件配置下，BCD将7B模型在A100/A800上的训练成本降低了33%，在RTX 4090上的成本降低了2.6%。这种方法还使得以前只能在A100集群上训练的大模型可以在RTX 4090上训练，不会影响模型性能。BCD在大多数情况下能达到与全参数和微调方法相当甚至更好的准确率，同时具有更低的GPU消耗和更高的硬件利用率，为低成本的大规模语言模型训练提供了新的解决方案。
### Conclusion
通过使用块坐标下降法优化的框架，实现了成本效益较好的GPU集群上高效、低成本的大规模语言模型训练，且保持或提高了模型的性能和准确性。
## 395. `cs.AI` - 基于变换器的语言模型中潜概念的分离 [PDF](https://arxiv.org/pdf/2506.16975), [HTML](https://arxiv.org/abs/2506.16975)
### Authors
Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy
### Background
当大型语言模型使用在上下文学习中解决新任务时，它们必须从示例中推断出隐含的概念。这引发了关于变压器在计算中如何表示这些潜在结构的问题。这篇文章通过几项受控任务，使用机制可解释性研究了这个问题。研究发现，模型能够识别并逐步组成隐含的概念，在具有潜在离散概念的传递推理任务中尤为明显。此外，对于参数化由潜在数值概念的任务，研究还发现模型的表示空间中存在低维子空间，其几何结构能干净地反映潜在参数化。
### Innovation
研究通过传递推理任务和基于潜在数值概念的任务探索了变压器模型如何表示潜概念，并且展示了即使在少数经过简化的演示示例后，小规模和大规模模型都能够分离和使用学习到的潜概念。这一研究为理解和改进基于变压器的语言模型提供了新的视角。
### Conclusion
小规模和大规模模型能够分离和利用从少量简化的演示示例中学到的潜概念，证明了这些模型有潜力处理潜在结构复杂的任务。这些发现为未来的研究提供了重要参考，尤其是如何更有效地利用潜概念进行模型优化和改进。
## 396. `cs.AI` - 关于有效类未学习中输出分布重权的必要性 [PDF](https://arxiv.org/pdf/2506.20893), [HTML](https://arxiv.org/abs/2506.20893)
### Authors
Ali Ebrahimpour-Boroojeny,Yian Wang,Hari Sundaram
### Background
当前的类未学习评估存在一个显著的不足之处：忽视了类别的底层几何结构可能导致隐私泄露。现有的方法未能充分考虑这种几何影响，导致了对未学习样本的评估不准确。本文通过研究发现，这需要重新考虑未学习的隐私保护问题，并提出了一个新的未学习方法以解决这一问题，确保评估的有效性和隐私的安全性。
### Innovation
本文提出了一种简单但有效的解决方案来缓解这一问题。该方法基于最近邻的成员推断攻击(MIA-NN)，通过使用模型为邻近类别分配的概率来检测未学习的样本。在此基础上，提出了一个新颖的微调目标——倾斜重权化（TRW），通过估计类间相似性和调整目标模型的分布来近似重新训练模型生产的类分布，从而减少隐私泄露。结果显示，TRW在多个基准测试中匹配或超越了现有的未学习方法，在CIFAR-10数据集上，相对于最新的方法，TRW在U-LiRA和MIA-NN得分上分别缩小了19%和46%的差距。
### Conclusion
本文提出了一个新的解决未学习问题的方法，TRW在多个数据集上展示了优于现有技术的性能，同时也证明了输出分布重权对于保护未学习过程中隐私的必要性。
## 397. `cs.AI` - 重新思考视觉语言导航中的体化差距：对物理和视觉差异的全面研究 [PDF](https://arxiv.org/pdf/2507.13019), [HTML](https://arxiv.org/abs/2507.13019)
### Authors
Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang
### Background
近期的视觉语言导航（VLN）研究表明非常有前景，但是它们在机器人行动和控制上的理想化假设未能反映实际部署中的物理制约挑战。
### Innovation
引入了VLN-PE，一个物理现实的VLN平台，支持类人、四足和轮式机器人。系统地评估了几种自视点VLN方法在不同技术管道中的表现，包括单步骤离散动作预测分类模型、密集航点预测的扩散模型以及基于路径规划的大语言模型。
### Conclusion
尽管目前模型在物理部署中的泛化较弱，但VLN-PE为提高跨体汇的整体适应性提供了一种新的途径。研究结果和工具旨在激发社区重新思考VLN的局限性，并推动更稳健和实用的VLN模型的发展。代码可在该网址获取。
## 398. `cs.AI` - 超越简单图：多目标路由在多重图上的神经网络方法 [PDF](https://arxiv.org/pdf/2506.22095), [HTML](https://arxiv.org/abs/2506.22095)
### Authors
Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
近年来，基于学习的方法在单目标和多目标路由中得到了广泛关注。然而，现有方法不适合处理多重图，而多重图在现实世界中有很强的相关性，因为它包括两个节点对之间具有不同属性的多条边。现有的方法对此类问题难以有效处理，尽管这一类问题是重要的实际应用问题。
### Innovation
本文提出了两种基于图神经网络的多目标路由方法针对多重图。第一种方法直接在多重图上通过自回归方式选择边直至完成旅行；第二种方法通过学习的方式首先简化多重图，然后在生成的简单图上进一步进行自回归路由，这种方法在可扩展性方面更具优势。通过广泛的实验证明了这两种方法在多种问题和图形分布下的竞争力，与有力的启发式方法和神经基线相比并不逊色。
### Conclusion
实验证明，所提出的方法在多种问题和图形分布下与强有力的启发式方法和神经基线相比表现相当出色，尤其是在处理多重图时展现了优越性，是对现有研究范围的有效扩展。
## 399. `cs.AI` - LoopServe：多轮对话中大语言模型推理加速的适应性双阶段系统 [PDF](https://arxiv.org/pdf/2507.13681), [HTML](https://arxiv.org/abs/2507.13681)
### Authors
Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan
### Background
多轮对话在许多实际应用中（如聊天机器人和虚拟助手）至关重要。随着对话历史的延长，现有的大语言模型面临不断增加的计算和内存挑战，这阻碍了它们提供高效和快速的交互。现有加速方法主要通过压缩语境或优化键值缓存来实现，但这些方法往往依赖于固定或基于位置的启发式方法，不太适合实际多轮对话中动态和不可预测的模式。因此，这些模型无法准确识别和优先考虑最相关的语境，导致响应质量下降。
### Innovation
LoopServe 是一个适应性双阶段推理加速框架，用于多轮对话中的大语言模型。它引入了两个主要创新点：第一，在填充预处理阶段进行在线稀疏化，动态选择每个新输入中最重要部分的注意矩阵；第二，在解码过程中使用逐步键值压缩，根据最近生成的输出令牌适配地维护相关且高效的缓存。
### Conclusion
广泛的实验表明，LoopServe 在各种长上下文对话任务中始终优于现有基准，并显著加速了大语言模型（LLM）的推理。
## 400. `cs.AI` - APTx Neuron: 统一的整合激活与计算的可训练神经元架构 [PDF](https://arxiv.org/pdf/2507.14270), [HTML](https://arxiv.org/abs/2507.14270)
### Authors
Ravin Kumar
### Background
当前神经网络架构中通常将非线性激活函数和线性变换分离开来处理，这导致了计算上的冗余和复杂性。
### Innovation
提出了APTx Neuron，这是一种新颖的统一神经计算单元，将非线性激活和线性变换整合到一个可训练的表达式中，从而消除了单独的激活层，使得架构更加高效和简洁。
### Conclusion
通过在MNIST数据集上的实验，证明了基于APTx Neuron的架构具有更高的表达能力和计算效率，为统一神经元设计及其构建的架构提供了新的范式。
## 401. `cs.AI` - 为什么强化微调能够使大型多模态语言模型更好地保留先验知识：从数据的角度来看 [PDF](https://arxiv.org/pdf/2506.23508), [HTML](https://arxiv.org/abs/2506.23508)
### Authors
Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Mingqi Wu,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang,Kai Chen
### Background
研究表明，监督微调（SFT）和强化微调（RFT）等后训练算法广泛用于适应多模态大语言模型完成下游任务。然而，这些技术对模型先验知识的影响尚不清楚。为此，本文通过使用拼图游戏作为新颖任务，对开源多模态模型Qwen2.5-VL系列进行SFT和RFT的系统研究。实验结果显示，SFT能迅速掌握新任务，但会导致灾难性遗忘，而RFT虽然学习较慢，但能较好地保留先验知识。进一步的分析表明，RFT主要通过自然与基础模型概率地貌对齐的样本来增强正确数据，从而减少对先验知识的干扰。并且，使用经过强化微调模拟回放的训练数据能够减轻SFT的遗忘效应，同时加快任务学习。这项研究揭示了数据分布而非算法差异在遗忘现象中的关键作用，并强调了RFT在多模态大型语言模型连续学习稳定性上的潜力。
### Innovation
引入了拼图游戏作为一种新任务，研究SFT和RFT在开源多模态模型Qwen2.5-VL系列上的行为。通过分析训练数据对先验知识的影响的幅度和方向，揭示了RFT如何通过自然对齐基础模型概率地貌的正确样本来增强先验知识，同时通过经过强化微调模拟回放的训练数据帮助SFT更好地保留先验知识并快速学习新任务。这项工作展示了数据分布的重要性，以及RFT在多模态大型语言模型中实现稳定持续学习的潜力。
### Conclusion
研究表明，数据分布而不是算法差异在遗忘现象中起到关键作用。RFT仿真回放的训练数据可以减轻SFT的遗忘效应，同时加快新任务的学习。这表明RFT是实现多模态大型语言模型稳定持续学习的一种有前景的方法。
## 402. `cs.AI` - 基于人设增强的基准测试：跨多种写作风格评估LLMs [PDF](https://arxiv.org/pdf/2507.22168), [HTML](https://arxiv.org/abs/2507.22168)
### Authors
Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu
### Background
现有的大型语言模型（LLMs）评估基准通常缺乏足够的写作风格多样性，许多基准主要遵循标准化规范，未能充分捕捉人类表现出的丰富多样的交流模式。这可能导致在面对非标准化输入时，经过这些基准优化的LLMs表现出脆弱的性能。
### Innovation
本文通过使用基于人设的LLMs提示技术重新编写评估提示，低成本地模拟多种写作风格，从而探讨该技术如何影响评估结果。研究结果显示，即使具有相同的语义内容，写作风格和提示格式的差异显著影响了评估的LLMs性能估计。同时，研究发现了不同的写作风格能够一致地触发不同性能表现，且这种差异不依赖于模型家族、大小和发布时间的差异。
### Conclusion
本研究提出了一种可扩展的方法来增强现有的评估基准，提高它们在衡量LLMs在不同语言变体中的性能时的外部有效性。
## 403. `cs.AI` - 通过逐步多轮交互评估LLM代理中的记忆力 [PDF](https://arxiv.org/pdf/2507.05257), [HTML](https://arxiv.org/abs/2507.05257)
### Authors
Yuanzhe Hu,Yu Wang,Julian McAuley
### Background
现有的大规模语言模型（LLM）代理基准主要关注推理、计划和执行能力的评估，而记忆机制——包括如何存储、更新和检索长期信息——由于缺乏相应的基准而被忽视。我们称之为具备记忆机制的代理。本文基于记忆科学和认知科学的经典理论，确定了四个核心能力，这些能力对于记忆代理而言至关重要：准确检索、测试时学习、长距离理解以及选择性遗忘。现有的基准要么依赖有限的上下文长度，要么针对如图书问答等静态的多上下文情境，无法反映记忆代理逐步积累信息的交互和多轮特性。目前的基准也未涵盖所有四个核心能力。因此，本文提出了一种新的基准——MemoryAgentBench，专门用于评估记忆代理。MemoryAgentBench将现有的长上下文数据集转换为多轮格式，并结合构建的数据集，准确模拟记忆代理逐步积累信息的特点，提供了综合性的测试平台，覆盖上述四个核心记忆能力。本文还评估了从基于上下文的简单系统到具有外部存储模块和工具集成的高级代理等多种记忆代理。实验结果表明，当前方法在掌握所有四个核心能力方面仍然不足，表明需要进一步研究全面的记忆机制以应用于LLM代理。
### Innovation
本文提出了一种新的基准——MemoryAgentBench，用于评估具有记忆力的大规模语言模型代理。它综合考虑了准确检索、测试时学习、长距离理解以及选择性遗忘的能力，并通过多轮格式有效模拟了记忆代理逐步积累信息的特性。
### Conclusion
评估结果显示，目前的方法在掌握所有四个核心能力方面仍显不足，强调了进一步研究全面记忆机制的重要性。
## 404. `cs.AI` - 从进化嵌入推进轻量级MSA设计以提升蛋白质折叠 [PDF](https://arxiv.org/pdf/2507.07032), [HTML](https://arxiv.org/abs/2507.07032)
### Authors
Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Cesar de la Fuente-Nunez,Chunbin Gu,Ge Liu,Pheng-Ann Heng
### Background
蛋白质结构预测经常依赖于多序列比对（MSAs），但在低同源性和孤儿蛋白方面，MSAs的表现不尽如人意。
### Innovation
作者引入了PLAME，一种轻量级的MSA设计框架，利用预训练的蛋白质语言模型中的进化嵌入来生成更好的MSAs，以支持下游折叠。PLAME结合了保守度-多样性损失，平衡了对保守位点的一致性和可能的序列变体覆盖率。此外，作者开发了一种MSA选择策略和一种序列质量度量，以过滤高性价比候选人，该度量补充了深度度量，并预测折叠增益。
### Conclusion
PLAME在AlphaFold2低同源性和孤儿蛋白基准测试中，提供了结构准确性方面最先进的改进（例如，lDDT/TM评分），并且与AlphaFold3配对时，表现出一致的性能提升。通过消融实验和案例研究，PLAME分别验证了选择策略和MSA属性对AlphaFold信心和错误模式的影响。最后，PLAME让ESMFold能够达到AlphaFold2级别的准确性，同时保持ESMFold的快速推理速度，为缺乏强大进化邻居的蛋白质提供了高质量折叠的实用途径。
## 405. `cs.AI` - SpectrumWorld: 开谱AI基础平台 [PDF](https://arxiv.org/pdf/2508.01188), [HTML](https://arxiv.org/abs/2508.01188)
### Authors
Zhuo Yang,Jiaqing Xie,Shuaike Shen,Daolang Wang,Yeyun Chen,Ben Gao,Shuzhou Sun,Biqing Qi,Dongzhan Zhou,Lei Bai,Linjiang Chen,Shufei Zhang,Qinying Gu,Jun Jiang,Tianfan Fu,Yuqiang Li
### Background
尽管深度学习在光谱学中有巨大的应用潜力，但在这一新兴领域的研究与评估中，标准方法的缺乏是一个普遍存在的问题。
### Innovation
该论文介绍了SpectrumLab平台，这是一个集成了全面的Python库、创新的SpectrumAnnotator模块和SpectrumBench多层基准套件的统一平台，旨在系统化并加速光谱学中深度学习的研究。
### Conclusion
通过对SpectrumBench多层基准套件上18种先进的多模态LLM进行深入的实证研究，揭示了当前方法的关键局限性，并希望SpectrumLab能成为未来以深度学习推动光谱学发展的关键基础。
## 406. `cs.AI` - 多重视觉编码器在多模态大型语言模型中探究冗余问题 [PDF](https://arxiv.org/pdf/2507.03262), [HTML](https://arxiv.org/abs/2507.03262)
### Authors
Yizhou Wang,Song Mao,Yang Chen,Yufan Shen,Yinqiao Yan,Pinlong Cai,Ding Wang,Guohang Yan,Zhi Yu,Xuming Hu,Botian Shi
### Background
近年来，多模态大型语言模型（MLLMs）越来越多地整合了多种视觉编码器，旨在通过各种基准测试提高性能。这种做法的假设是不同的预训练目标会产生互补的视觉信号。然而，本文通过系统地在具有代表性的多编码器MLLM中掩蔽编码器发现，尽管如此，这一假设在实践中往往不能成立。研究结果表明，在某些情况下，选择性掩蔽某些编码器反而会提高性能，特别是在特定任务上表现出显著的专业化，比如OCR和图表识别任务，此时一个编码器的边际贡献率可超过90%。在通用视觉问答和知识驱动任务中，编码器之间表现出高度的替代性，且某些情况下会出现负面的边际贡献率，导致性能下降。研究发现，掩蔽某些特定编码器可以带来更强任务集中度，甚至比完整模型高出3.6%的整体性能提升。对于非OCR任务，单一或双编码器变体可以在大多数情况下恢复90%以上的基线性能。这些发现挑战了‘越多编码器越好’的假设，并为设计更高效和有效的多模态架构提供了可操作性的诊断工具和策略。这项研究通过系统地评估编码器对模型性能的影响，揭示了多模态大型语言模型中的冗余问题，并提供了改进模型结构的方法。
### Innovation
本文首次引入了两个量化模型冗余的严格度量——条件利用率率（CUR）和信息差距（IG），用于测量编码器边际贡献和捕捉模型内编码器在不同任务上的异质性效用。研究发现某些特定编码器在特定任务上的贡献率可以超过90%，而其他情况下，所有编码器之间可以相互替代，甚至会出现负面边际贡献率。通过应用于不同类型的任务，研究揭示了MLLMs中冗余现象及其对模型整体性能的影响，为设计更高效的架构提供指导
### Conclusion
研究挑战了‘越多编码器越好’的假设，证明在特定情况下减少编码器数量能够提高整体性能。研究揭示了多模态大型语言模型中的冗余问题，并提供了一种量化和诊断这种现象的方法。
## 407. `cs.AI` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大型语言模型（LLMs）已经在数学、事实问答和代码生成等领域取得了优异的表现，但在多语言推理方面的能力往往比较欠缺，特别是在处理低资源语言（如斯瓦希里语或泰语）时，往往会对提示产生误解或默认使用英语进行推理。这种对高资源语言的隐性偏好会降低事实准确性、可解释性和信任度。现有的多语言基准通常只关注最终答案，忽视了推理是否发生在指定的语言上。为了克服这些局限，这篇论文提出了新的地理事实基准 GeoFact-X，以及一种结合多尺度多语言对齐与机器翻译问题上的语言一致性奖励的新方法 M2A。
### Innovation
论文创新地提出了 M2A 方法，该方法通过结合多尺度多语言对齐与语言一致性奖励训练模型，直接且准确地在目标语言中进行推理。此外，GeoFact-X 设计成为一种地理事实推理基准，并提供了五种语言（英语、印地语、日语、斯瓦希里语和泰语）的推理痕迹，填补了现有基准只关注最终答案的空白。这篇论文的结果表明 M2A 显著提高了数学和事实推理任务中的多语言推理准确性，强调了推理感知的多语言强化学习对于跨语言泛化的关键作用。
### Conclusion
研究所提出的方法 M2A 和 GeoFact-X 基准不仅提升了多语言推理的准确性和可靠性，还强调了在多语言环境下需要关注推理过程的重要性，以实现更加稳健的跨语言泛化能力。这些发现对于开发更加多功能的多语言 AI 系统具有重要意义。
## 408. `cs.AI` - KV缓存导向：控制冻结的大语言模型 [PDF](https://arxiv.org/pdf/2507.08799), [HTML](https://arxiv.org/abs/2507.08799)
### Authors
Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,James R. Glass,Cees G. M. Snoek,Yuki M. Asano
### Background
该研究提出了一种轻量级的方法——缓存导向（Cache Steering），通过直接对键值缓存进行一次性的干预，实现对语言模型的隐式控制。这种方法旨在验证其有效性，特别是通过应用缓存导向来促进小型语言模型的链式思考推理。背景信息包括使用推理轨迹从教师模型或现有的人类注释中构建导向向量，从而改变模型的行为，使其更加详细、步骤化。实验表明，方法在多种推理基准上的定性和定量表现均有所改善，且该方法适合更大规模的模型，并在GPQA和MATH等具有挑战性的数据集上也表现出进一步的改进。相对于需要持续干预的先前激活导向技术，该研究方法在推理延迟、超参数稳定性和与现有推理API的集成简便性等方面具有显著优势。除了促进推理之外，缓存导向还展示了控制推理风格的能力（如逐步、因果、类比推理），使其成为一个在行为层面指导语言模型的实际工具。
### Innovation
该研究提出了一种一次性的缓存导向方法，通过直接干预语言模型的键值缓存，以不改变模型精细调优或提示修改的方式，隐式引导模型进行链式思考推理。该方法无需激活或提示调优，即可改变模型行为，使其更倾向于详细、步骤化的推理。提出的方法相比先前的激活导向技术，在推理延迟、超参数稳定性和与现有推理API的集成简便性方面具有显著优势，并且该方法可以扩展到更大规模的模型并在更具挑战性的问题上取得更好的表现。方法还展示了控制推理风格的能力，进一步扩展了其应用范围。
### Conclusion
该研究通过实验证明了缓存导向方法的有效性，通过单次干预即可显著改善模型推理的质量和任务表现，并适用于更大规模的语言模型。该方法具有高度的灵活性，能够用于控制语言模型的行为，使其呈现出不同的推理风格，从而为语言模型的行为层面指导提供了新的可能。
## 409. `cs.AI` - 在临界点，直观在最大 caliber 模型中出现 [PDF](https://arxiv.org/pdf/2508.06477), [HTML](https://arxiv.org/abs/2508.06477)
### Authors
Lluís Arola-Fernández
### Background
关于大型预测模型是否仅仅复述其训练数据或产生真实见解，缺乏物理上的解释。本文报告了一种初级形式的直觉，这种直觉作为学习的亚稳态相出现，关键地平衡了下一标记预测与未来路径熵。直觉机制是通过“心灵调谐”发现的，这是一种将最大 caliber 原则最小化的方法，在预测模型中引入了一个类似控制温度的参数λ。
### Innovation
研究通过最小化原则将最大 caliber 原则引入预测模型，并通过训练随机漫步在确定性迷宫中，揭示了一个丰富的相图：模仿（低λ）、打破规则的幻觉（高λ）、以及在中间脆弱窗口中表现为路径依赖性和多稳态，模型在这种状态下自发发现新型目标导向策略。
### Conclusion
这些结果被一个有效的低维度理论所捕捉，并将直觉视为在记忆什么是和探索什么是可能之间的临界平衡中出现的一种 emergent 属性。
## 410. `cs.AI` - 分层图神经网络用于压缩语音隐藏信息分析 [PDF](https://arxiv.org/pdf/2507.21591), [HTML](https://arxiv.org/abs/2507.21591)
### Authors
Mustapha Hemis,Hamza Kheddar,Mohamed Chahine Ghanem,Bachir Boudraa
### Background
基于深度学习（DL）的隐写分析方法通常存在计算复杂性较高以及在不同数据集上泛化能力较差的问题。将图神经网络（GNN）引入隐写分析方案中，可以利用关系数据提高检测准确性和适应性。本研究首次将GraphSAGE架构应用于压缩语音（VoIP）流的隐写分析，旨在解决上述问题并提高性能。
### Innovation
本研究首次将GraphSAGE架构应用于压缩语音流的隐写分析，通过简单地从VoIP流构建图，并利用GraphSAGE捕捉分层隐写分析信息，包括细粒度细节和高层次模式，从而实现了高检测准确度。实验结果表明，该方法在VoIP信号中的量化索引调制（QIM）隐写模式遮蔽分析中表现出色，即使对于0.5秒的短样本，检测准确率也超过98%，在嵌入率低的困难条件下保持95.17%的准确率，高于当前最佳方法2.8%。此外，该模型表现出优越的效率，0.5秒样本的平均检测时间为0.016秒，比之前的方法快0.003秒，使其适用于在线隐写分析任务，在样本短、嵌入率低的约束条件下实现了检测准确性和效率之间的优秀平衡。
### Conclusion
本研究提出的方法在低样本长度和低嵌入率的限制条件下，实现了高检测准确度和高效率，为在线隐写分析任务提供了一种优秀的选择。
## 411. `cs.AI` - R-Stitch: 动态轨迹缝合以实现高效的推理 [PDF](https://arxiv.org/pdf/2507.17307), [HTML](https://arxiv.org/abs/2507.17307)
### Authors
Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang
### Background
链式思维（CoT）虽然可以增强大型语言模型（LLMs）的问题解决能力，但由于长自回归路径，会导致显著的推理成本。现有的加速策略主要通过提前停止或压缩缩短计算路径，或者采用小模型进行推测性解码。然而，推测性解码在模型一致性较低时效果有限，并且在令牌级别上强制一致性，忽略了小模型在正确的情况下可以产生更为简洁的推理路径，从而减少推理长度的可能性。这种观察为R-Stitch的开发提供了背景，R-Stitch是一个无需训练的混合解码框架，利用令牌级熵作为不确定性的代理指标，来在小语言模型（SLM）和LLM之间分配计算任务。
### Innovation
R-Stitch采用了高熵令牌作为不确定性指标，设计了一种基于熵指导的路由策略，让SLM高效处理低熵令牌，并将不确定的令牌委托给LLM，从而避免了全面回滚，既保持了问题答案的质量，又实现了加速。进一步地，R-Stitch+通过学习自适应的路由策略，动态地调整令牌预算，超越了固定的阈值。通过减少每令牌解码的复杂度和生成的令牌数量，该方法实现了显著的加速，几乎没有任何准确性的损失。具体而言，在不同模型上获得了3.00倍、3.85倍和4.10倍的速度提升，同时保持了与全LLM解码相当的准确性。此外，该方法还能够根据不同的计算预算进行适应性的效率-准确率权衡，而无需重新训练模型。
### Conclusion
通过R-Stitch和R-Stitch+方法，能够在保持与完整LLM解码相媲美的准确性的前提下，实现显著的加速。这种方法还能够实现在不同计算预算下的自适应效率-准确率贸易平衡，无需重新训练模型。这为在不同应用场景中实现高效、准确的语言模型推理提供了一种新的策略。
## 412. `cs.AI` - 生成逻辑：一种新的确定性推理和知识生成的计算机架构 [PDF](https://arxiv.org/pdf/2508.00017), [HTML](https://arxiv.org/abs/2508.00017)
### Authors
Nikolai Sergeev
### Background
该研究背景是在现有的计算机架构和推理方法基础上，提出了一种新的确定性推理架构——生成逻辑（Generative Logic，GL）。这是一种从用户提供的公理定义（和可选的简单事实列表以构建反例）出发，通过一种简约的数学编程语言（MPL）进行推理的框架。该架构能够系统地探索其公理定义的逻辑邻域，并将定义编译成逻辑块网格，这些逻辑块能够互相传递信息。GL的目标是在现有硬件资源上实现高效且可验证的自动推理流程，生成可追溯的证明图，并最终支持大规模并行实现及与概率模型相结合以实现自动形式化和猜想生成。
### Innovation
GL的主要创新点在于：1）通过数学编程语言和简约的公理体系构建一套完整的推理系统；2）逻辑块网格实现高效推理，并通过消息传递机制实现推理过程的自动化和验证；3）能够自动重建可机器检查的证明，并输出为可导航的HTML格式，使得每一步推理都可以独立检查；4）提出了一条硬件与软件协同设计的路径，用于实现大规模并行推理系统，并描述了与概率模型结合的潜在应用场景，如大型语言模型等。
### Conclusion
GL在第一阶皮亚诺算术公理上实现了从猜想生成到机器可验证证明的整个过程，耗时大约7秒进行推理证明阶段，完整运行约5分钟。证明结果导出为可导航的HTML格式，便于独立检查每一步推理。研究者还设想未来的发展方向，包括大规模并行系统的硬件与软件协同设计能力及与大型语言模型等概率模型集成的可能性。相关的代码及证明已被发布在GitHub，供验证与进一步研发。
## 413. `cs.AI` - 无形的约束：为什么RLVR可能或不可能超越其起源 [PDF](https://arxiv.org/pdf/2507.14843), [HTML](https://arxiv.org/abs/2507.14843)
### Authors
Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi
### Background
最近的LLM进展突显了RLVR作为增强AI能力的方法的潜力，特别是在解决复杂逻辑任务方面。但目前的RLVR实践是否有真正的扩展模型的推理边界，或是主要放大基础模型已知的高回报输出来提高精度尚不明确。本研究通过实证调查提供了关于当前RLVR常见实践潜在限制的见解。研究表明，在现有的训练条件下，RLVR可以作为一种受支持约束的优化机制，这可能会限制发现完全原创解决方案的可能性，仍受限于基础模型的初始分布。我们还发现了一个关于熵和奖赏的权衡：尽管当前的RLVR配方稳定地提升了精度，它可能会逐步缩减探索范围，并可能错过正确但受到抑制的解决方案。大量实证实验验证，尽管当前的RLVR配方持续提高了pass@1，但在更大采样预算下，实证支持的缩减通常超过了扩展，未能找回基础模型先前可及的正确答案。有趣的是，我们还观察到RLVR有时增加了词元级别的熵——导致每一步生成时出现更大的不确定性——但答案级别的熵下降，表明这些看似更不确定的路径最终收敛于少数不同的答案。这些发现揭示了当前RLVR配方在扩展推理边界的潜在限制。打破这种无形的束缚可能需要未来的算法创新，如明确的探索机制或混合策略，这会向较少出现的解决方案区域播种概率质量。
### Innovation
本研究通过实证调查为企业提供了关于当前RLVR常见实践潜在限制的见解。研究发现，当前的RLVR实践可以作为一种受支持约束的优化机制，可能会限制发现完全原创解决方案的可能性，并可能缩减探索范围，错过正确但被抑制的解决方案。此外，研究揭示了一种关于熵和奖赏的权衡：尽管当前的RLVR配方稳定地提升了精度，但可能会缩减探索范围。该研究提出了未来的算法创新可能需要明确的探索机制或混合策略，以向较少出现的解决方案区域播种概率质量。
### Conclusion
现有的RLVR配方在增加精度的同时，可能会限制探索范围，导致错过被抑制的正确答案。这种潜在的限制表明，未来的RLVR实践可能需要新的探索机制或混合策略来扩大模型的推理边界。
## 414. `cs.AI` - GTPO和GRPO-S：基于策略熵的令牌和序列级奖励塑造 [PDF](https://arxiv.org/pdf/2508.04349), [HTML](https://arxiv.org/abs/2508.04349)
### Authors
Hongze Tan,Jianfei Pan,Jinghao Lin,Tao Chen,Zhihang Zheng,Zhihao Tang,Haihua Yang
### Background
强化学习（RL）对于提升大型语言模型（LLM）的推理能力至关重要。然而，传统的算法通常遵循粗粒度的归因范式，会为整个序列中的所有标记提供统一的奖励，这对于长期推理任务来说是一个重要的缺陷。
### Innovation
本文提出了Dynamic Entropy Weighting（动态熵加权）机制，通过Group Token Policy Optimization（GTPO）和类似算法Sequence-Level GRPO（GRPO-S）实现细粒度的奖励分配。该方法基于高策略熵在推理路径中是认知努力的强指标假设，可以将这一指标重新用于学习信号，从而实现真正的标记级归因。
### Conclusion
实验结果表明，本文的方法在复杂的推理基准测试中明显优于强大的DAPO基线，验证了熵加权机制是性能提升的关键驱动力。
## 415. `cs.AI` - ERIS: 一种能量导向的特征解耦框架以实现泛化能力的时间序列分类 [PDF](https://arxiv.org/pdf/2508.14134), [HTML](https://arxiv.org/abs/2508.14134)
### Authors
Xin Wu,Fei Teng,Ji Zhang,Xingwang Li,Yuxuan Liang
### Background
理想的时间序列分类(TSC)应该能够捕捉不变的特征表示，但要在分布外(OOD)数据上实现可靠性能仍然是一个核心难题。这一难题源于模型本质上将领域特定特征和标签相关特征纠缠在一起，导致了虚假的相关性。尽管特征解耦试图解决这一问题，但当前的方法大多缺乏明确的语义指导，无法真正分离出普遍适用的特征。
### Innovation
提出了一种端到端的能量正则化信息用于移动性鲁棒性(ERIS)框架，以实现引导的和可靠的特征解耦。ERIS结合了三种关键机制来实现这一目标：首先引入一种能量导向校准机制，提供了解耦过程中的关键语义指导，使模型能够自我校准；其次采用权重级别的正交性策略，确保领域特定和标签相关特征之间的结构性独立，从而减轻它们的干扰；最后，辅助对抗泛化机制通过注入结构化扰动增强鲁棒性。
### Conclusion
在四个基准测试上的实验表明，ERIS在所有测试中都实现了显著超过现领先基准的效果，确保了最高的性能排名。
## 416. `cs.AI` - 事实核查到真相：大规模语言模型中事实评价与核查的综述 [PDF](https://arxiv.org/pdf/2508.03860), [HTML](https://arxiv.org/abs/2508.03860)
### Authors
Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam
### Background
大规模语言模型（LLMs）在训练时会接触到大量包含不准确或误导性内容的互联网数据，这可能导致LLMs生成错误信息，因此需要强大的事实核查框架来确保内容的准确性。当前的事实核查评估方法存在局限性，尤其是对于LLMs生成内容的事实准确性评估，并提出了几点挑战，包括幻觉、数据集限制和评价指标的可靠性问题。
### Innovation
本文系统地分析了LLMs生成内容的事实核查方法，强调了结合高级提示策略、领域特定微调和检索增强生成（RAG）方法的重要性。通过审查文献提出五个研究问题，重点关注评价方法和缓解技术，并且评估了指令调优、多智能体推理和外部知识访问框架的作用。研究发现揭示了当前度量标准的局限性，强调验证外部证据的重要性，并通过领域特定定制提高了事实连贯性。
### Conclusion
研究强调了构建更精确、易于理解且上下文相关的事实核查框架的重要性，并推动了更多可信模型的研究发展。这些发现为未来该领域的研究提供了方向和见解。
## 417. `cs.AI` - StreetReaderAI：利用上下文感知多模态AI使街景可访问 [PDF](https://arxiv.org/pdf/2508.08524), [HTML](https://arxiv.org/abs/2508.08524)
### Authors
Jon E. Froehlich,Alexander Fiannaca,Nimer Jaber,Victor Tsaran,Shaun Kane
### Background
现有的互动街景映射工具如Google街景（GSV）和Meta Mapillary能够让用户通过沉浸式360°图像虚拟导航和体验现实世界环境，但对盲用户来说依然从根本上是不可访问的。StreetReaderAI是首款为盲人用户设计的无障碍街景工具，结合了上下文感知的多模态AI、无障碍导航控制和对话式语音等功能，使得盲人用户可以虚拟地检查目的地、进行开放式探索或虚拟游览GSV部署在全球超过2200亿张照片和100多个国家的任何地方。
### Innovation
StreetReaderAI是一个首创性的可访问街景工具，通过结合上下文感知的多模态AI、无障碍导航控制和对话式语音，填补了技术空白，首次使得盲人用户能够虚拟地检查目的地、进行开放式探索或虚拟游览等。
### Conclusion
StreetReaderAI通过迭代设计和试行发现，在支持POI调查和远程路线规划方面价值明显。该研究最终提出了对未来工作的关键指导方针。
## 418. `cs.AI` - 图作为一种自然正则化：重新审视图表示学习中的向量量化 [PDF](https://arxiv.org/pdf/2508.06588), [HTML](https://arxiv.org/abs/2508.06588)
### Authors
Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang
### Background
向量量化（VQ）最近成为学习图结构数据离散表示的一种有前途的方法。然而，在图领域中，编码本体收缩这一基本挑战尚未得到充分探讨，这严重影响了图的表达能力和泛化能力。本文通过实验证明了将VQ应用于图数据时，即使采用了视觉或语言领域提出的缓解策略，编码本体收缩问题也是一直存在的。
### Innovation
本文提出了RGVQ（重新整合图结构和特征相似性的向量量化），这是一种新颖的框架。RGVQ通过整合图拓扑和特征相似性作为显式的正则化信号来增强编码本体的利用并促进标记多样性。RGVQ引入了通过Gumbel-Softmax重参数化实现的软赋值。此外，RGVQ引入了一种结构感知对比正则化来惩罚不同节点对之间的标记共赋值。
### Conclusion
广泛的实验结果表明，RGVQ显著提高了编码本体的利用率，并且能够跨多种下游任务提高最先进的图VQ骨架的性能，从而使得图标记表示更为表达能力和可迁移性更强。
## 419. `cs.AI` - DAMR：LLM引导的MCTS支持的高效且适应性强的上下文感知知识图谱问答 [PDF](https://arxiv.org/pdf/2508.00719), [HTML](https://arxiv.org/abs/2508.00719)
### Authors
Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Chao Wang,Nan Yin
### Background
知识图谱问答（KGQA）的目标是通过利用知识图谱的关联和语义结构来解释自然语言查询并执行结构化推理以获取准确的答案。现有的方法主要遵循检索-推理范式，使用图神经网络或启发式规则提取静态候选路径，或者采用LLM与提示结合的动态路径生成策略来同时完成检索和推理。然而，前者由于静态路径提取和缺乏上下文改进而缺乏适应性，后者则由于依赖固定的评分函数和重复的LLM调用而面临高计算成本和较低的评估准确性问题。本文旨在解决这些问题。
### Innovation
提出了一种名为DAMR的新颖框架，即动态适应MCTS（蒙特卡洛树搜索）推理，该框架结合了LLM指导的MCTS和路径评估的可适应性，以实现高效且上下文感知的KGQA。DAMR利用MCTS作为骨干，通过LLM基于的规划器在每次扩展步骤中选择最相关的top-k语义关系，以有效减少搜索空间。还引入了轻量级的基于Transformer的评分器，通过交叉注意同时编码问题和关系序列，增强评价准确性，捕捉多跳推理过程中的细微语义变化。此外，为了解决高质量监督稀缺的问题，DAMR结合了一种动态伪路径精炼机制，该机制定期从搜索中探索的部分路径生成训练信号，使评分器能够适应演化的推理轨迹分布。
### Conclusion
通过对多个KGQA基准的广泛实验，DAMR在性能上显著优于现有的最先进的方法。
## 420. `cs.AI` - 使用多智能体强化学习的分布式悬挂负载空中操作 [PDF](https://arxiv.org/pdf/2508.01522), [HTML](https://arxiv.org/abs/2508.01522)
### Authors
Jack Zeng,Andreu Matoses Gimenez,Eugene Vinitsky,Javier Alonso-Mora,Sihao Sun
### Background
本研究介绍了首个适用于多旋翼无人机团队在电缆悬挂负载上实现真实世界六自由度（6-DoF）操作的分布式方法。此方法利用多智能体强化学习（MARL）训练每台无人机的外环控制策略，与现有集中式方案的控制器不同，该策略不需要全局状态、无人机间通讯或相邻无人机信息，仅通过负载姿态观察进行隐式通信，从而实现高可扩展性和灵活性，显著降低了推理阶段的计算成本。在动态三维运动中，通过线性加速度和机体角速度的新型动作空间设计，结合鲁棒的底层控制器，实现可靠的仿真到现实环境的迁移，尽管受到了电缆张力带来的显著不确定性的影响。研究在多种真实世界实验中验证了方法的有效性，展现了负载模型不确定性下的姿态控制性能与最先进的集中式方法相当。此外，展示了智能体间具有不同控制策略的协作胜任力及对一台无人机完全在飞中丢失的鲁棒性。
### Innovation
该研究的创新之处在于提出了首个适用于多旋翼无人机团队的分布式方法来操作电缆悬挂负载，利用多智能体强化学习（MARL）训练外环控制策略，通过负载姿态观察进行隐式通信，无需全局状态或无人机通讯，具有高可扩展性和灵活性。在动态三维运动中，通过线性加速度和机体角速度的新型动作空间设计，实现可靠的仿真到现实的迁移。此外，展示了具有不同控制策略的多智能体间的协作和服务于一台无人机完全在飞中丢失的鲁棒性。
### Conclusion
该研究验证了分布式多智能体强化学习方法在真实世界环境中控制电缆悬挂负载的有效性，展示了负载模型不确定性下的姿态控制性能和仿真到现实的转换一致性，还展示了不同控制策略的多智能体间的协作和对无人机丢失的鲁棒性。该方法未来可以通过在无人机上嵌入策略进一步降低成本，增强系统灵活性和可靠性。
## 421. `cs.AI` - 在高吞吐量环境中的可扩展选项学习 [PDF](https://arxiv.org/pdf/2509.00338), [HTML](https://arxiv.org/abs/2509.00338)
### Authors
Mikael Henaff,Scott Fujimoto,Michael Matthews,Michael Rabbat
### Background
层次强化学习（RL）在长时间尺度上的决策制定上具有潜在优势。现有方法尽管很有希望，但在大规模培训中尚未完全实现其优势。
### Innovation
提出了高度可扩展的层次强化学习算法Scalable Option Learning (SOL)，该算法在吞吐量上比现有层次方法提高约35倍。通过在复杂游戏NetHack中使用300亿帧的经验训练层次代理，证明了SOL的性能和可扩展性，同时在MiniHack和Mujoco环境中进行了验证，展示了其广泛适用性。
### Conclusion
Scalable Option Learning (SOL)实现了在高吞吐量环境中的可扩展性，显著优于现有方法，并展示了其在复杂游戏和标准环境中的基线性能和可扩展性。
## 422. `cs.AI` - 稀疏但错误：不正确的L0导致稀疏自编码器提取错误的特征 [PDF](https://arxiv.org/pdf/2508.16560), [HTML](https://arxiv.org/abs/2508.16560)
### Authors
David Chanin,Adrià Garriga-Alonso
### Background
稀疏自编码器（SAEs）从LLM的内部激活中提取特征，这些特征旨在与可解释的概念相对应。SAEs的核心超参数是L0，它表示每token平均应该激活多少SAE特征。现有研究通常通过稀疏性-重建权衡图来比较不同SAE算法的表现，认为L0是一个无固定正确值的自由参数，仅在其对重建性能的影响上有所不同。本文研究了L0对SAEs的影响，发现如果L0设置不当，SAEs将无法分离LLM的基本特征。L0过低时，SAEs会混合相关特征以改进重建；L0过高时，SAEs会找到混合特征的退化解决方案。此外，文中提出了一种代理指标，能帮助指导在给定训练分布下寻找正确的L0值。实验显示该方法在玩具模型中有效，并与LLM SAE的尖峰稀疏探针性能相符。研究发现大多数常用的SAEs具有L0过低的情况，表明必须正确设置L0来训练具有正确特性的SAE。
### Innovation
本文提出了一个代理指标，用于指导在特定训练分布下寻找正确的L0值。研究还表明，大多数常用的SAEs具有L0过低的情况，并且L0必须正确设置才能训练出特征正确的SAE。
### Conclusion
如果正确设置L0，SAEs可以更好地分离LLM的基本特征，并提升稀疏探针的表现。研究揭示了L0设置对于SAE训练结果的重要影响，强调了正确设定L0的必要性。
## 423. `cs.AI` - JudgeAgent: 基于Agent-as-Interviewer的自适应和知识驱动的大语言模型评估 [PDF](https://arxiv.org/pdf/2509.02097), [HTML](https://arxiv.org/abs/2509.02097)
### Authors
Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Jian Guo,Yuanzhuo Wang
### Background
当前的大语言模型评估范式存在过度评价或偏差、问题难度不匹配等问题，导致对知识和能力边界的评估不完整，影响了这些模型的有效应用和优化。
### Innovation
本文提出了一个称为Agent-as-Interviewer的动态评估范式，利用大语言模型代理进行多轮交互评估。与现有的基准测试或动态交互范式不同，该范式利用代理调用知识工具以更大的深度和广度生成问题，实现对大语言模型知识边界更全面的评估，并通过规划查询策略调整问题难度级别，增强难度控制以匹配目标大语言模型的实际能力。
### Conclusion
基于这一范式，我们开发了JudgeAgent，一个基于知识的动态评估框架，使用知识驱动的综合作为代理工具，并使用难度评分作为策略指导，最后提供了有价值的建议帮助目标模型优化自己。广泛的实验验证了JudgeAgent建议的有效性，表明Agent-as-Interviewer能够准确识别目标模型的知识和能力边界。
## 424. `cs.AI` - 冲突感知软提示生成扩展检索增强生成 [PDF](https://arxiv.org/pdf/2508.15253), [HTML](https://arxiv.org/abs/2508.15253)
### Authors
Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee
### Background
检索增强生成（RAG）能够通过集成外部知识来增强大型语言模型（LLMs）的能力。然而，当检索到的上下文与LLM的参数化知识存在矛盾时，RAG往往无法解决错误外部上下文与正确参数化知识之间的冲突，这种现象被称为上下文-记忆冲突。
### Innovation
引入了冲突感知软提示生成（CARE），包括上下文评估器和基础LLM。上下文评估器通过编码紧凑的内存标记嵌入并使用接地/对抗性软提示进行训练，以识别不可靠的上下文并捕捉一个引导信号，该信号能够引导推理向更可靠的知识来源进行。
### Conclusion
广泛的实验表明，CARE能有效缓解上下文-记忆冲突，使其在QA和事实核查基准测试中的平均性能提高了5.0%，为可信赖和适应性强的RAG系统设定了一个有希望的方向。
## 425. `cs.AI` - 正义之裁：揭示LLM辅助同行评审中的隐藏偏见 [PDF](https://arxiv.org/pdf/2509.13400), [HTML](https://arxiv.org/abs/2509.13400)
### Authors
Sai Suresh Macharla Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz
### Background
论文背景介绍了大型语言模型（LLMs）在同行评审过程中不断改变的角色，从帮助审稿人撰写更详细的评估到能够自动生成整个审稿意见。尽管这些能力提供了令人兴奋的机会，但也引发了关于公平性和可靠性的关键问题。研究人员发现LLM生成的审稿意见中存在隐性偏见，尤其是依据作者所在机构的排名和性别进行了控制实验后，发现对顶级学术排名机构的潜在偏见以及性别偏好，尽管这些偏见在程度上较为微妙，但有累积的风险。
### Innovation
论文通过设计控制实验针对敏感元数据（如作者所属机构和性别）来调查LLM生成同行评论中的偏见。首次系统性地检测到隐含的机构偏见，倾向于高排名学术机构，并揭示了一些微小但可能随着时间累积固化的性别偏好。
### Conclusion
研究结果表明，虽然LLM在改进同行评审方面的潜力巨大，但仍存在隐含且累积的偏见。未来应关注该问题，确保评审过程更加公平和客观，可以通过开发算法和机制来减轻这些偏见，同时应持续进行相关研究以防止这些偏见在未来的应用中加剧。
## 426. `cs.AI` - 梦聊：基于用户信念建模的对话模型强化学习 [PDF](https://arxiv.org/pdf/2508.16876), [HTML](https://arxiv.org/abs/2508.16876)
### Authors
Yue Zhao,Xiaoyu Wang,Dan Wang,Zhonglin Jiang,Qingqing Gu,Teng Chen,Ningyuan Xi,Jinxian Qu,Yong Chen,Luo Ji
### Background
世界模型在机器人、游戏和自动驾驶领域中得到广泛应用，但在自然语言任务中的应用则相对有限。本文旨在构建对话世界模型，以便预测用户情绪、情感和意图，并预测未来对话内容。通过定义POMDP，研究者认为情绪、情感和意图可以看作是用户信念，并通过最大化信息瓶颈进行建模。在此基础上，研究者应用模型驱动的强化学习框架改进了对话系统，并提出了一个名为DreamCUB的框架。实验表明，预训练的对话世界模型在情绪分类和情感识别方面取得了最先进的性能，同时联合训练策略、评论家和对话世界模型也提高了对话质量。进一步分析表明，这种策略在探索与利用之间保持了合理的平衡，并且能很好地应用于诸如共情对话等跨域场景中的对话。
### Innovation
通过定义POMDP，将情绪、情感和意图视为用户信念，并通过最大化信息瓶颈进行建模。旨在构建对话世界模型，结合模型驱动的强化学习框架提出DreamCUB框架，在情绪分类和情感识别上取得了显著效果，并且通过联合训练提高了对话质量。提出的方法在探索与利用之间保持了合理的平衡，并且能应用于跨域场景。
### Conclusion
预训练的对话世界模型在情绪分类和情感识别上达到了最先进的性能。联合训练策略、评论家和对话世界模型提高了对话质量，并且这种方法在探索与利用之间保持了合理的平衡，并且能很好地应用于包括共情对话在内的跨域场景。
## 427. `cs.AI` - 使用改进YOLO11x提案和ConvNeXt分类的两阶段方案在MIDOG 2025 Track 1细胞分裂检测 [PDF](https://arxiv.org/pdf/2509.02627), [HTML](https://arxiv.org/abs/2509.02627)
### Authors
Jie Xiao,Mengye Lyu,Shaojun Liu
### Background
在包含非肿瘤、炎症和坏死区域的全视野图像（WSI）中进行细胞分裂检测是一项复杂的任务，因为存在复杂的异质背景以及可能的伪影，这会导致检测的F1分数下降。
### Innovation
本文提出了一种两阶段方案。首先使用改进的YOLO11x模型生成细胞分裂候选对象，通过低置信度阈值生成尽可能多的提案以确保召回率；然后使用ConvNeXt-Tiny分类器过滤掉假阳性，确保检测精度。
### Conclusion
该提出的两阶段方案在Fusion数据集（MIDOG++、MITOS_WSI_CCMCT、MITOS_WSI_CMC）上实现了0.882的F1得分，比单阶段YOLO11x基线高出0.035。在MIDOG 2025 Track 1初步测试集上，算法获得了0.7587的F1得分。代码可在https://github.com/xxiao0304/MIDOG-2025-Track-1-of-SZTU获取。
## 428. `cs.AI` - 最近几年深度学习在显微镜图像增强中的最新进展：综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强对理解生物细胞和材料的微观细节至关重要。近年来，借助深度学习方法，显微镜图像增强技术取得了显著进步。
### Innovation
该综述性论文概述了深度学习在显微镜图像增强领域的最新进展，涵盖了其演进、应用、挑战和未来方向，重点关注超分辨重建和去噪等核心领域。
### Conclusion
该论文通过讨论当前趋势及其深度学习的实际应用，为显微镜图像增强领域的快速成长提供了视角，并指出了未来的研究方向。
## 429. `cs.AI` - 她很有用，但有点过于乐观：使用交互式虚拟角色增强设计 [PDF](https://arxiv.org/pdf/2508.19463), [HTML](https://arxiv.org/abs/2508.19463)
### Authors
Paluck Deep,Monica Bharadhidasan,A. Baki Kocaballi
### Background
用户画像（ personas ）在以用户为中心的设计中被广泛用于理解并传达用户需求，然而，由于其静态的本质、有限的互动性以及无法适应不断变化的设计需求，它们在迭代工作流程中存在局限性。最近，大型语言模型（ LLMs ）的进展为更富有互动性和适应性地代表用户打开了新的可能性。本文介绍了一种新型的设计工具——交互式虚拟角色（ IVPs ），这种工具具有多模态性、由 LLM 驱动，具备会话特点，并通过语音界面实时与设计师进行互动，帮助进行用户研究、构思和原型评估。这项研究初步证明了 IVPs 在信息收集、激发设计创新和提供快速类似用户反馈方面的潜力，但仍存在一定挑战和限制。
### Innovation
本文提出了一种名为 IVPs 的新型工具，此工具能够实时模拟用户的互动，可被设计师用于用户研究、构思和原型评估等活动。这些虚拟角色由大型语言模型驱动，能够进行语音交谈、发散思维和收集反馈，展示了一种新的用户代表方式，能够显著提升设计的效率和创意性，尤其是在迭代工作中展现出了更大的灵活性。
### Conclusion
研究指出 IVPs 仍需解决一些问题，如避免偏见、防止过分乐观、确保真实性以及忠实于用户体验。学者们强调 IVPs 应该作为现有工具的补充，而非替代品。本文还讨论了策略和伦理考虑以确保 IVPs 的有效性和负责任使用的技术指南。最后，本文的研究将为生成式人工智能在设计过程中的应用提供有价值的参考，进一步探讨 UX 设计师亲身经历 LLM 助力的动态虚拟化身工具的见解。
## 430. `cs.AI` - Draw-In-Mind: 在统一多模态模型中重新平衡设计师和画师角色有助于图像编辑 [PDF](https://arxiv.org/pdf/2509.01986), [HTML](https://arxiv.org/abs/2509.01986)
### Authors
Ziyun Zeng,Junhao Zhang,Wei Li,Mike Zheng Shou
### Background
近年来，将多模态理解和生成集成到单个统一模型中已成为一种有前途的方法。虽然这种方法在文本到图像(T2I)生成任务上表现良好，但在精确图像编辑方面仍遇到挑战。这个问题归因于理解和生成模块之间的职责不平衡。理解和生成模块在处理图像编辑时，必须共同承担设计师和画家的角色，这导致理解模块主要作为翻译器将用户指令编码为语义条件，而生成模块则需要同时推断原始布局、识别目标编辑区域以及渲染新内容。尽管理解模块通常通过数倍的数据进行复杂推理任务的训练，但生成模块并未得到相应加强。因此，为了应对这一挑战，作者介绍了名为Draw-In-Mind (DIM)的多模态数据集，其中包含两个子数据集：DIM-T2I，包含1400万长上下文图像-文本对以增强复杂指令理解；DIM-Edit，包含由GPT-4o生成的23.3万链式思维图像想象，这些想象作为显式的图像编辑蓝图。
### Innovation
该研究提出了名为Draw-In-Mind (DIM)的多模态数据集，将一个固定的Qwen2.5-VL-3B与一个可训练的SANA1.5-1.6B通过一个轻量级的两层MLP连接，并在提出的DIM数据集上进行训练，最终生成DIM-4.6B-T2I/Edit模型。尽管参数量较小，但DIM-4.6B-Edit在ImgEdit和GEdit-Bench基准测试中仍然取得了SOTA或具有竞争力的表现，超过了如UniWorld-V1和Step1X-Edit等较大规模的模型。这些发现表明，明确地将设计职责分配给理解模块对于图像编辑有重大优势。
### Conclusion
该研究展示了在统一多模态模型中明确地将设计职责分配给理解模块对图像编辑的显著益处，并且该方法使用较小的参数量模型也能取得很好的性能。该数据集和模型可以在指定网址找到。
## 431. `cs.AI` - 基于Token-Aware Phase Attention的位臵编码 [PDF](https://arxiv.org/pdf/2509.12635), [HTML](https://arxiv.org/abs/2509.12635)
### Authors
Yu Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian
### Background
现有研究表明，Rotary Positional Embedding（RoPE）中存在的固有距离依赖偏差限制了其在长上下文建模中的能力。尽管RoPE的扩展方法可以缓解该问题，但通常需要在预训练之后进行后续调整，如缩放或重新调整超参数。因此，本研究旨在提出一种新的位置编码方法。
### Innovation
提出了Token-Aware Phase Attention（TAPA），该方法将可学习的相位函数嵌入注意力机制中，能够在长距离范围内保留令牌交互，直接且轻量级地扩展到更长的上下文，且无需额外的调整。与RoPE家族相比，TAPA在长上下文中获得了显著较低的困惑度。
### Conclusion
TAPA克服了传统位置编码方法在长上下文处理中的限制，通过引入可学习的相位函数，不仅改进了现有RoPE技术的不足，而且提供了直接扩展到更长上下文的途径，并在长文本建模中表现出更优的效果。
## 432. `cs.AI` - 固定权重Transformer中的上下文内算法模拟 [PDF](https://arxiv.org/pdf/2508.17550), [HTML](https://arxiv.org/abs/2508.17550)
### Authors
Jerry Yao-Chieh Hu,Hude Liu,Jennifer Yuntong Zhang,Han Liu
### Background
本文证明了最小的Transformer在冻结权重的情况下可以通过上下文内提示模拟广泛的算法类。文章详细探讨了两种模式的算法模拟方式，并展示了通过上下文提示，单头Softmax注意层可以再现任意精度的形式为$f(w^top x - y)$的连续函数，这涵盖了多种流行的机器学习算法。同时，还证明了在提示可编程模式下，通过仅使用提示，固定的双层Softmax注意模块能够模拟所有特定任务类中的算法。这些发现直接建立了上下文内学习与算法模拟之间的联系，并为大型Transformer通过提示提供了一个作为可编程算法库的机制，揭示了像GPT这样的基础模型可能仅通过提示来交换算法的方式，确立了现代Transformer模型中的算法通用性形式。
### Innovation
文章提出了两种模式的算法模拟方法，分别为任务特定模式和提示可编程模式。在任务特定模式下，通过上下文提示，单头Softmax注意层可以精确再现多种连续函数的形态，涵盖多个流行机器学习算法。在提示可编程模式下，通过固定的双层Softmax注意模块，只需要通过提示即可模拟所有此类算法。这种构造避免了前馈层和参数更新，所有适应仅通过提示实现。该研究为大型Transformer作为可编程算法库提供了理论支持，并揭示了基础模型通过提示交换算法的可能性，从而在现代Transformer模型中确立了算法通用性形式。
### Conclusion
本文研究了固定权重Transformer通过上下文提示模拟算法的可能性，提出了任务特定和提示可编程模式。实验结果支持理论，表明这种直接链接上下文学习与算法模拟的方法为大型Transformer提供了一个作为可编程算法库的简单机制。这些发现为理解GPT风格基础模型通过提示交换算法的方式提供了思路，并为现代Transformer模型中的算法通用性形式奠定了基础。
## 433. `cs.AI` - 为高效大模型任务适配进行分布对齐解码 [PDF](https://arxiv.org/pdf/2509.15888), [HTML](https://arxiv.org/abs/2509.15888)
### Authors
Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Yong Dai,Sam Tak Wu Kwong,Yuguang Fang
### Background
尽管采用参数高效微调（PEFT）方法，将十亿参数的语言模型适应下游任务依然成本较高。传统的微调方法是在解码过程中通过权重更新间接地将输出分布引导至任务分布，而这篇论文将任务适配重新定义为输出分布对齐，即直接在解码过程中将输出分布引导至任务分布。
### Innovation
提出了Steering Vector Decoding（SVD）方法，这是一种轻量级、兼容PEFT且基于理论的方法。SVD利用预训练模型和微调后模型之间的Kullback-Leibler（KL）散度梯度来提取任务感知的引导向量，从而指导解码过程，使模型输出分布接近任务分布。SVD理论证明了与全微调步骤的一阶等价，并且在全球最优解决方案中推导出了引导向量强度。
### Conclusion
SVD与四种标准PEFT方法结合应用于三个任务和九个基准测试后，准确性和开放性真实性分别提高了5%和2%，在常识数据集上表现出相似的收益，不影响额外训练参数的增加。因此，SVD提供了一种轻量级、理论支持的方法来增强大语言模型的任务适配能力。
## 434. `cs.AI` - RPG: 一种统一和可扩展的代码库生成规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型在生成单个函数或单个代码文件方面表现出色，但在从头开始生成完整的代码仓库方面仍面临重大挑战。这一能力对于从高层次规范构建连贯的软件系统以及实现自动化代码生成的全部潜力至关重要。生成过程需要在两个层面进行规划：决定构建哪些特性和模块（提案阶段）以及定义它们的具体实现细节（实施阶段）。当前的方法依赖于自然语言规划，这常常导致不清晰的规范、对齐不良的组件以及由于其固有的模糊性和缺乏结构而产生的脆弱设计。本研究旨在解决这些问题。
### Innovation
为了应对这些限制，我们提出了Repository Planning Graph (RPG)，这是一种结构化的表示方式，能够统一编码功能、文件结构、数据流和函数。通过用明确的蓝图替换自由形式的自然语言，RPG实现了一致的大规模规划，并基于RPG开发了ZeroRepo，这是一个基于图的框架，包括提案级规划、实施级构建和由测试验证指导的代码生成三个阶段。此外，RPG模型复杂依赖性、通过接近线性扩展支持更复杂的规划，并提高代理对代码库的理解，从而加速定位。
### Conclusion
我们构建了包含六个真实项目和1,052个任务的RepoCraft基准测试集。在RepoCraft上，ZeroRepo平均产出约3.9倍于最强基线（Claude Code）和68倍于其他基线的代码行数，分别为35,898个代码行和445,000个代码令牌。ZeroRepo的代码覆盖率和测试准确率分别为81.5%和69.7%，分别比Claude Code提升27.3和35.8个百分点。进一步分析表明，RPG模型复杂依赖性、实现更复杂的规划并通过接近线性扩展以及提高代理对仓库的理解，从而加速定位。
## 435. `cs.AI` - 心智矩阵或树状结构？从心智矩阵视角重新评估复杂推理 [PDF](https://arxiv.org/pdf/2509.03918), [HTML](https://arxiv.org/abs/2509.03918)
### Authors
Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao
### Background
大型语言模型（LLMs）在处理复杂和抽象任务时由于缺乏推理能力而面临显著的准确性下降。虽然思维结构如链式思维（CoT）和树状思维（ToT）能够提升LLMs的推理能力，但它们存在内部冗余和路径单一的问题。此外，利用检索增强生成（RAG）方法虽能在一定程度上缓解LLMs的幻觉问题，但根本性的思维结构缺陷仍无法解决。在处理多实体和多跳信息时，检索验证的知识往往包含大量碎片化、浅表的或错误的数据，这误导了LLMs的推理过程。
### Innovation
本文提出了心智矩阵（MoT），这是一种新颖且高效的思维结构，通过列单元之间的“单元间通信”机制，在水平和垂直维度上探索问题，使LLMs能够主动进行多策略和深入思考，同时减少列单元内部思维节点的冗余，提升推理能力。此外，通过事实校正机制，利用RAG检索的知识图谱三元组和原始文本构建知识单元并纠正错误答案。实验结果表明，该方法在24点游戏、问答评价等任务上均优于现有最先进的方法，推理时间仅为基线方法的14.4%，证明了其高效性和准确性。
### Conclusion
本文提出的心智矩阵（MoT）框架有效解决了传统思维结构在复杂推理任务中的问题，通过减少思维冗余和提升推理能力，在多个任务上的表现优于现有方法，同时证明了其高效性和准确性。
## 436. `cs.AI` - 物理基础模型的发展方向 [PDF](https://arxiv.org/pdf/2509.13805), [HTML](https://arxiv.org/abs/2509.13805)
### Authors
Florian Wiesner,Matthias Wessling,Stephen Baek
### Background
基础模型通过“一次训练，随处部署”的范式已经彻底改变了自然语言处理领域，使之能够无需重新训练就能适应无数下游任务。然而，在当前的物理感知机器学习方法中，尽管这些方法已经接近这个目标，但它们仍然被局限在单一狭窄领域内，且需要为每个新系统重新训练。因此，建立一个物理基础模型（PFM）来实现高保真模拟、加速科学发展并消除专业求解器开发的必要性，成为了一个强烈的需求。这篇论文提出了一种名为GPhyT（通用物理变压器）的解决方案，它基于1.8 TB的多样化模拟数据进行了训练，以展示物理领域基础模型能力的可行性。
### Innovation
GPhyT利用Transformer学习从上下文推断物理定律的机制，使其能够模拟流体-固体交互、冲击波、热对流以及多相动力学等物理系统，而无需说明基础方程。GPhyT实现了三个关键突破：（1）在多个物理领域中实现了优于专门架构的性能，最高可提升29倍；（2）利用上下文学习实现了对于完全未见物理系统的零样本泛化；（3）通过50时间步骤的滚动预测保持稳定的长期预测。这项研究通过让单个模型通过数据学习普遍适用的物理原理，为建立通用PFM打开了大门，有望变革计算科学与工程领域。
### Conclusion
这项工作通过证明单个模型可以仅基于数据学习普适物理原则，打开了通向广泛适用物理基础模型的大门，能够从根本上改变计算科学与工程领域。
## 437. `cs.AI` - DivLogicEval：大型语言模型中逻辑推理评估框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被认为是衡量人类智能的关键指标之一，对于大规模语言模型（LLMs）。现有的基准测试可能综合了多种推理技能，这导致无法准确评估模型的逻辑推理技能。此外，现有的逻辑推理基准在语言多样性方面有限，其分布与理想逻辑推理基准的分布不符，这可能导致偏差的评估结果。
### Innovation
提出了一种新的经典逻辑基准DivLogicEval，包含用直观方法整合多样声明的自然句子。为了保证更可靠的评估，还引入了一种新的评估指标，能够减轻LLMs中固有的偏见和随机性的影响。通过实验，展示了在DivLogicEval中回答问题所需的逻辑推理程度，并对比了不同流行的LLMs在进行逻辑推理方面的表现。
### Conclusion
实验结果证明了在DivLogicEval中逻辑推理的需求程度，并对比了不同流行LLMs在进行逻辑推理方面的表现。通过引入新的逻辑评估基准和评估指标，旨在更准确地评估大型语言模型的逻辑推理能力。
## 438. `cs.AI` - 使用伴侣聊天机器人的纵向随机对照研究：拟人化及其对社会影响的中介作用 [PDF](https://arxiv.org/pdf/2509.19515), [HTML](https://arxiv.org/abs/2509.19515)
### Authors
Rose E. Guingrich,Michael S. A. Graziano
### Background
人类与社交人工智能代理的关系正在增长。人们报告与聊天机器人如Replika建立起友谊，导师关系和浪漫伙伴关系。有研究表明，这些社交伴侣聊天机器人可能会损害或替代人类关系，但其实际影响尚不清楚。先前的研究表明，人们的社会需求状态和对AI代理的拟人化可能会影响人类与AI互动对人类互动的影响。
### Innovation
本研究采用纵向随机对照实验，让参与者在21天里每天与伴侣聊天机器人或做基于文本的单词游戏10分钟，并完成了四次调查和两次录音访谈。研究发现，与伴侣聊天机器人的互动没有显著影响人们的社会健康和关系，但那些更渴望社交连接的人更倾向于拟人化聊天机器人，而更倾向于拟人化的个体报告聊天机器人的互动对其与家人和朋友的人际关系产生更大的影响。进一步的中介分析表明，人类与AI互动对社会结果的影响是通过人们对AI代理的拟人化程度进行调节的，从而与每个人都渴望与他人建立联系密切相关。
### Conclusion
在21天的互动中，伴侣聊天机器人的使用对参与者的社会健康和关系没有显著影响。那些更渴望社交连接的人更倾向于拟人化聊天机器人，而更倾向于拟人化的个体报告聊天机器人的互动对其与家人和朋友的人际关系产生更大的影响。聊天机器人的拟人化程度在人类与AI的互动对人类关系的影响中起着中介作用，而这种拟人化与个体社交连接的渴求相关。
## 439. `cs.CL` - 有效幻觉检测和分类的新型差异性特征学习 [PDF](https://arxiv.org/pdf/2509.21357), [HTML](https://arxiv.org/abs/2509.21357)
### Authors
Wenkai Wang,Vincent Lee,Yizhen Zheng
### Background
大语言模型的幻觉构成了一个关键挑战，表现为输出与事实准确性之间存在偏差，这是由于训练数据中的分布偏差所致。虽然最近的研究表明特定隐藏层在幻觉内容和事实内容之间存在差异，但幻觉信号在这些层中的精确定位仍然不清楚，这限制了高效检测方法的发展。
### Innovation
提出了一个结合投影融合（PF）模块和差异特征学习（DFL）机制的双模型架构。PF模块实现自适应层间特征加权，而DFL机制通过计算平行编码器在相同输入上下文的互补表示间的差异来识别判别特征。通过在HaluEval的问题回答、对话和总结数据集中的系统实验，证明了幻觉信号集中在高度稀疏的特征子集中，显著提高了问题回答和对话任务的准确度。
### Conclusion
分析揭示了分层的“漏斗模式”，即浅层表现出高的特征多样性，而深层表现出集中的使用情况。使用仅1%的特征维度仍能维持检测性能，显示出表征幻觉信号比预期更为集中的趋势。这些发现表明，存在一种高效检测系统的路径，可以在减少推理成本的同时保持准确度。
## 440. `cs.AI` - Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling [PDF](https://arxiv.org/pdf/2509.17186), [HTML](https://arxiv.org/abs/2509.17186)
### Authors
Dehao Zhang,Malu Zhang,Shuai Wang,Jingya Wang,Wenjie Wei,Zeyu Ma,Guoqing Wang,Yang Yang,Haizhou Li
### Background
序列长度的快速增长加剧了高效且有效的长序列建模的需求。Resonate-and-Fire (RF) 神经元能够利用固有的震荡膜动态有效地从输入信号中提取频率成分，并将这些成分编码为时空尖峰脉冲序列，使其非常适合长序列建模。然而，RF 神经元的有效记忆容量有限，并且在复杂时间任务上存在能量效率和训练速度之间的权衡问题。
### Innovation
受生物神经元树突结构的启发，我们提出了一种树突型振荡和放电模型（D-RF 模型），这是将多树突和胞体结构明确结合的神经元模型。每个树突分支利用 RF 神经元的固有震荡动态来编码特定的频率范围，由此共同实现了全面的频率表示。此外，我们将一个适应性阈值机制引入胞体结构，该机制根据历史尖峰活动调整阈值，减少了冗余尖峰，同时在长序列任务中的训练效率保持不变。
### Conclusion
广泛实验表明，我们的方法能够在训练期间保持计算效率的同时，减少冗余尖峰并保持竞争力，从而证实了其在边缘平台上的有效且高效的长序列建模潜力。
## 441. `cs.AI` - FusedANN: 通过属性-向量融合实现凸化混合ANN [PDF](https://arxiv.org/pdf/2509.19767), [HTML](https://arxiv.org/abs/2509.19767)
### Authors
Alireza Heidari,Wei Zhang,Ying Xiong
### Background
向量搜索为变压器技术提供了动力，但在实际应用中，需要结合向量相似性和属性过滤的混合查询（例如，“类别X中的顶级文档，来自2023年”）。当前的解决方案在召回率、速度和灵活性之间妥协，依赖于脆弱的索引技巧，这些技巧无法扩展。背景讨论了现有方法的局限性。
### Innovation
我们引入了FusedANN（融合属性-向量最近邻），这是一种几何框架，将过滤条件提升为ANN优化约束，并通过Lagrange-like松弛引入了一个凸融合空间。方法通过基于变压器的凸化技术联合嵌入属性和向量，将硬过滤转换为连续的加权惩罚，保持了top-k的语义同时支持高效的近似搜索。理论证明，FusedANN在选择性高时降低到精确过滤，在精确匹配不足时优雅地放松到语义上最接近的属性，并保持下游ANN α-近似保证。实验结果显示，FusedANN在消除脆弱的过滤阶段后提高了查询吞吐量，能够在标准混合基准上实现更好的召回率与延迟折中，优于最先进的混合和图基系统，吞吐量提高了3倍。
### Conclusion
我们提供了明确的误差界和参数选择规则，使FusedANN适用于生产环境。这为符号约束与向量相似性之间建立了原则上可扩展且可验证的桥梁，解锁了一代适用于大型、混合和动态NLP/ML工作负载的过滤检索系统。
## 442. `cs.AI` - 使用门检测和大规模语言模型的建筑合规检查中的设施自动统计 [PDF](https://arxiv.org/pdf/2509.17283), [HTML](https://arxiv.org/abs/2509.17283)
### Authors
Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo
### Background
建筑合规检查（BCC）是确保建筑工程符合监管标准的关键过程。核心问题是准确统计设施类型及其空间分布。尽管重要，这一问题在文献中却被忽视，对BCC构成重大挑战，留下了一个关键的工作流程缺口。手动执行此任务耗时且劳动密集。最近的大语言模型（LLMs）的进步提供了通过结合视觉识别和推理能力来增强自动化的新机会。
### Innovation
本文介绍了一个新的BCC任务：设施自动统计，涉及到验证每种设施类型的数量是否符合法定要求。提出了一种新方法，将门检测与基于LLM的推理结合。这是首次将LLM应用于此任务，并通过Chain-of-Thought（CoT）流水线进一步提升其性能。方法在多种数据集和设施类型上具有良好的泛化能力。实验证明了方法的有效性和鲁棒性。
### Conclusion
我们的方法在真实世界和合成楼层计划数据上的实验表明其有效性和鲁棒性。
## 443. `cs.AI` - TimeMosaic: 通过自适应粒度块和段级解码指导的时间序列预测 [PDF](https://arxiv.org/pdf/2509.19406), [HTML](https://arxiv.org/abs/2509.19406)
### Authors
Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan
### Background
多变量时间序列预测在金融、运输、气候和能源等领域至关重要。现有的基于补丁的方法通常采用固定长度的分割，忽略了局部时间动态的异质性以及预测的解码异质性。这样的设计在信息密集区域丧失了细节，在稳定段引入了冗余，并且无法捕捉短期和长期预测时区的差异性复杂性。
### Innovation
提出TimeMosaic，这是一种旨在解决时间异质性的预测框架。TimeMosaic采用自适应补丁嵌入来根据局部信息密度动态调整粒度，平衡模式复用与结构清晰度，同时保持时间连续性。此外，它引入了段级解码，将每个预测时区视为相关子任务，适应各自的具体难度和信息要求，而非采用单一的统一解码器。
### Conclusion
在基准数据集上的广泛评估表明，TimeMosaic在现有方法上提供了一致的改进，并且在包含321亿观察值的大规模语料库上训练的模型，性能与现有的最先进的TSFMs相当。
## 444. `cs.AI` - 比较RAG和GraphRAG在数学教科书页面级检索问答中的应用 [PDF](https://arxiv.org/pdf/2509.16780), [HTML](https://arxiv.org/abs/2509.16780)
### Authors
Eason Chen,Chuangji Li,Shizhuo Li,Zimo Xiao,Jionghao Lin,Kenneth R. Koedinger
### Background
技术辅助的学习环境可以提升学生在自主学习过程中检索相关学习内容的能力。大型语言模型（LLMs）作为一种新的信息检索工具，已被广泛应用于学习过程中。尽管LLMs在泛化问题回答方面效果显著，但通常无法与特定课程材料（如教科书和讲义）的专业知识保持一致。因此，研究者探索了Retrieval-Augmented Generation（RAG）和一种利用知识图谱增强的RAG（GraphRAG）方法，用于本科生数学教科书的页面级问题回答。尽管RAG在检索上下文相关的段落方面表现良好，但GraphRAG在建模交叉概念和层次知识结构方面可能更具优势。研究者为此创建了一个包含477个问题-答案对的数据集，每个对都与教科书中的一个页面相关联。
### Innovation
研究引入了两种方法进行页面级检索：标准的基于嵌入的RAG方法和知识图谱增强的GraphRAG方法。研究发现基于嵌入的RAG方法在检索准确性和生成答案质量方面优于GraphRAG，因为它在实体结构的影响下往往检索过多且有时无关的内容。此外，研究还探索了使用大型语言模型重新排名检索页面，结果表明这可能会导致性能下降和幻觉，尤其是在处理更大的上下文窗口时。这一研究强调了更多精细的检索方法在构建可靠的AI辅导解决方案中的重要性，特别是在提供参考页面编号方面。
### Conclusion
这项研究揭示了页面级检索系统在教育场景中的潜力与挑战，强调了更精细的检索方法对于构建可靠的AI辅导解决方案的重要性。
## 445. `cs.CL` - 基于影响引导的上下文选择以提高有效的检索增强生成 [PDF](https://arxiv.org/pdf/2509.21359), [HTML](https://arxiv.org/abs/2509.21359)
### Authors
Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang
### Background
检索增强生成（RAG）通过将响应扎根于外部知识来解决大型语言模型（LLM）的幻觉问题，然而，其效果受到质量较差的检索上下文的影响，这些上下文包含不相关或噪音信息。现有的方法试图通过根据预定义的上下文质量评估指标选择上下文来提高性能，但它们在标准RAG上的增益有限。
### Innovation
论文重新概念化上下文质量评估为在实施时的数据价值推理问题，引入了上下文影响价值（CI值）。此新型度量通过测量从列表中移除每个上下文时性能下降的程度来量化上下文质量，有效地整合了上下文查询意识的相关性，列表意识的独特性和生成器意识的对齐。此外，CI值通过仅保留具有正CI值的上下文来消除复杂的选择超参数调优。为解决标签依赖性和计算成本问题，开发了一个参数化的代理模型来预测推理期间的CI值。该模型使用层次结构架构，捕获局部查询-上下文相关性和全局上下文之间的交互作用，并通过Oracle CI值监督和端到端生成器反馈进行训练。
### Conclusion
在8个NLP任务和多个LLM上进行的广泛实验显示，我们的上下文选择方法显著优于最先进的基线，有效过滤出质量较差的上下文，同时保留关键信息。
## 446. `cs.CL` - 大型语言模型需要符号导向 [PDF](https://arxiv.org/pdf/2509.21404), [HTML](https://arxiv.org/abs/2509.21404)
### Authors
Xiaotie Deng,Hanyu Li
### Background
本文认为，尽管当前人工智能技术通过大规模训练和数据扩展得到了显著提升，但仅仅依赖于此并不足以推动真正意义上的发现。大型语言模型在处理自然语言任务时表现出强大的能力，但这种能力往往是盲目的，缺乏明确的方向指引。
### Innovation
本文提出，大型语言模型需要引入由人类创制的符号系统，作为其强大但缺乏方向的直觉的指导。通过这种方式，可以为大型语言模型提供更加明确的方向，帮助它们更有效地进行创收任务和开放性探索。
### Conclusion
本文强调，为了真正推动人工智能的发现，需要让大型语言模型学习并使用人类创制的符号系统，以此为模型提供必要的方向指引和结构化框架。
## 447. `cs.AI` - AnchDrive: 使用混合轨迹插桩初始化扩散策略的端到端驾驶 [PDF](https://arxiv.org/pdf/2509.20253), [HTML](https://arxiv.org/abs/2509.20253)
### Authors
Jinhao Chai,Anqing Jiang,Hao Jiang,Shiyi Mu,Zichong Gu,Hao Sun,Shugong Xu
### Background
端到端多模态规划已成为自动驾驶的一个变革性范式，有效解决了行为多模态性和长尾场景中的一般性挑战。现有方法通常依赖于传统的生成模型，但这些模型的高计算成本成为实现高效驾驶的一个障碍。
### Innovation
我们提出了一种名为AnchDrive的框架，它可以高效地初始化一个扩散策略，从而减轻传统生成模型的高计算成本。AnchDrive通过使用丰富的混合轨迹插桩来初始化其规划器，而不是从纯粹的噪声中去噪。这些插桩来自两个互补的来源：静态的一般驾驶先验词汇和一组动态的、上下文相关的轨迹。这些动态轨迹通过Transformer实时解码，处理密集和稀疏的感知特征。扩散模型通过预测轨迹偏移量的概率分布来精炼这些插桩，从而实现细致的精炼。这种基于插桩的初始设计可以高效地生成多样化、高质量的轨迹。实验证明，AnchDrive在NAVSIM基准上设定了新的最先进的水平，并显示出了强大的泛化能力。
### Conclusion
实验结果表明，AnchDrive在NAVSIM基准测试上显示了前所未有的性能，在泛化能力上表现出色。
## 448. `cs.AI` - HiCoLoRA: 通过分层协作LoRA解决上下文-提示错位问题以实现零样本DST [PDF](https://arxiv.org/pdf/2509.19742), [HTML](https://arxiv.org/abs/2509.19742)
### Authors
Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li
### Background
零样本对话状态跟踪(zero-shot dialog state tracking, zs-DST)对于使任务导向对话系统(TODs)能够无需大量数据标注的情况下泛化到新领域至关重要。核心挑战在于动态对话上下文与静态提示之间的语义错位，导致不同层之间的协调不灵活，领域间干扰，记忆灾难性遗忘等问题。为了应对这些挑战，该研究提出Hierarchical Collaborative Low-Rank Adaptation（HiCoLoRA）框架，通过稳健的提示对齐增强零样本槽位推理。该框架具有分层低秩近似（LoRA）结构，用于动态层特定处理，结合下层启发式分组和高层全面交互。此外，HiCoLoRA引入了光谱联合领域-槽聚类和语义增强SVD初始化方法，以识别可转移的关联并保持预训练知识。实验结果表明，HiCoLoRA在多领域数据集（MultiWOZ和SGD）上优于基线方法，达到在零样本DST中的最新技术水平。
### Innovation
HiCoLoRA提出了一个通过分层协作低秩适应（Hierarchical Collaborative Low-Rank Adaptation）框架，解决了动态对话上下文与静态提示之间的语义错位问题。该框架包括：1）分层LoRA架构，同时处理下层的启发式分组和高层的全面交互；2）光谱联合领域-槽聚类，结合自适应线性融合机制，识别可转移的关联；3）语义增强SVD初始化（SemSVD-Init），确保预训练知识的保持。
### Conclusion
通过实验结果表明，HiCoLoRA在多领域数据集（MultiWOZ和SGD）上的表现优于现有基线模型，显示出卓越的零样本对话状态跟踪性能，达到当前技术水平（SOTA）。
## 449. `cs.CL` - 使用RLVR实现最先进的SQL推理模型 [PDF](https://arxiv.org/pdf/2509.21459), [HTML](https://arxiv.org/abs/2509.21459)
### Authors
Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang
### Background
开发能够整合企业特定知识的定制推理模型具有巨大的潜力以解决企业客户面临的问题。在许多问题中，奖励函数可以验证，这种设置称为带有验证奖励的强化学习（RLVR）。研究者将RLVR应用于一个流行的机器学习基准测试BIRD，该基准测试衡量AI代理将自然语言查询转换为SQL执行的能力。研究采用了一种简洁且通用的训练配方，包括精心选择指令和模型、脱机RL方法TAO的预热阶段，随后是严格的在线RLVR训练。
### Innovation
研究者应用RLVR方法，使用TAO的预热阶段和随后的在线严格训练，成功地在没有额外训练数据和使用私有模型的前提下，达到了最先进的准确率。具体来说，其无需自我一致性的情况下准确率为73.56%，使用自我一致性的准确率为75.68%，同时需要的生成次数比第二好的方法更少。
### Conclusion
虽然BIRD仅作为代理任务，但其简单框架便于在企业领域如商业智能、数据科学和编程等多个领域广泛应用。
## 450. `cs.CL` - 单一模型，多种道德规范：揭示计算道德推理中的跨语言不一致 [PDF](https://arxiv.org/pdf/2509.21443), [HTML](https://arxiv.org/abs/2509.21443)
### Authors
Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens
### Background
大型语言模型（LLMs）越来越多地被部署在多语言和多元文化环境中，道德推理对于生成合乎伦理的响应至关重要。然而，LLMs 主要使用英语数据进行预训练，这引发了它们在不同语言和文化背景下进行判断能力的质疑。本文系统地探讨语言如何影响 LLM 的道德决策过程。
### Innovation
本文将两个已建立的道德推理基准翻译成五种文化与类型上都具有多样性的语言，进行多语言零样本评估。通过精心设计的研究问题，探讨了一系列导致这些差异的基础因素，包括文化交流问题和 LLM 的推理策略，并通过案例研究分析了预训练数据对 LLM 道德判断的影响。
### Conclusion
本文总结出了一种结构化的道德推理错误分类体系，指出需要更多具备文化意识的 AI 系统。
## 451. `cs.AI` - Diffusion-Augmented Contrastive Learning: 一种抗噪生物信号表示的编码器 [PDF](https://arxiv.org/pdf/2509.20048), [HTML](https://arxiv.org/abs/2509.20048)
### Authors
Rami Zewail
### Background
学习稳健的生物信号表示常常受到设计有效数据表示方式的挑战。现有的方法可能难以捕捉生理数据中复杂的变异。现有的对比学习方法可能在生成有效且适应噪声的数据增强视图时存在不足，这限制了生物信号的表示学习效果。因此，本文提出了一个融合了扩散模型和监督对比学习概念的新颖混合框架——扩散增强对比学习（DACL），以改善生物信号数据表示的鲁棒性。DACL框架通过一个轻量级变分自编码器（VAE）的工作空间运作，该工作空间由我们的首创散射变换（ST）特征训练而成。该框架利用扩散正向过程作为一种原理性数据增强技术，生成多种噪声视图。U-Net样式编码器随后通过监督对比学习目标进行训练，以学习在多种扩散时间步骤中具有噪声鲁棒性的分类表示。该方法在PhysioNet 2017 ECG数据集上进行评估，取得了竞争性的AUROC（0.7815）结果。
### Innovation
本文提出了一种新颖的融合扩散模型和监督对比学习的概念——扩散增强对比学习（DACL）框架。该方法通过利用扩散过程本身来驱动对比学习目标，生成抗噪声的嵌入表示，能够为生物信号表示学习提供更强的分类可分离性基础。DACL通过一种轻量级VAE和U-Net风格的编码器实现，在新的数据增强方法中提高了表示学习的鲁棒性。
### Conclusion
本文提出的方法为生物信号表示学习提供了一种新的范式，通过采用扩散过程来增强对比学习目标，生成了抗噪声的嵌入表示。该方法在PhysioNet 2017 ECG数据集上的实验表明，它是一种有效且鲁棒的方法。
## 452. `cs.AI` - ACCeLLiuM: 监督微调以实现自动化OpenACC声明生成 [PDF](https://arxiv.org/pdf/2509.20380), [HTML](https://arxiv.org/abs/2509.20380)
### Authors
Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes
### Background
GPU的普及伴随着硬件复杂度和并行编程框架的增加。指令为基础的并通过简化底层复杂性的OpenACC这样的并行编程标准，虽简化了GPU编程，但要求用户依然具备一定专业知识才能有效使用这些指令。为了解决这一问题，该研究引入了ACCeLLiuM，即两个大型语言模型，专门用于自动生成填写OpenACC指令，并提供了用于训练这些模型的监督微调数据集。数据集搜集了来自公共GitHub代码库的4033个OpenACC声明-循环对，为训练和测试分别提供了3223和810个对。实验表明，基础的大语言模型在生成正确OpenACC声明方面存在显著性能差异，而在通过ACCeLLiuM数据集进行微调后的模型在数据并行循环中能正确生成指定指令类型的比例达到87%，而在具体情况条件下几乎完全匹配的比例高达50%。这些产生的声明虽然不一定与真实的标注完全一致，但在不同的顺序或包含额外控制并行执行、数据移动和并行性的指令中，提供了超越严格字符串匹配的实践价值。
### Innovation
该研究引入了ACCeLLiuM，即两个特定用于生成OpenACC指令的大型语言模型，并提供了用于训练这些模型的监督微调数据集。该模型通过对数据集的微调，显著提高了生成正确OpenACC指令的能力，特别是对于数据并行循环，生成的有效指令类型达到了87%的成功率，而精确指令（包括指令、子句、子句顺序和子句变量）的成功率高达50%。这些生成的指令对于并行执行、数据移动和并发控制提供了有用的灵活性，远超出简单的字符串匹配。
### Conclusion
研究者希望通过公开发布代码、模型和数据集，将ACCeLLiuM确立为大语言模型驱动的OpenACC声明生成的可重复基准，并降低自动将串行程序卸载到GPU的障碍。
## 453. `cs.CL` - Agribot: 农业特定问题解答系统 [PDF](https://arxiv.org/pdf/2509.21535), [HTML](https://arxiv.org/abs/2509.21535)
### Authors
Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari
### Background
印度是一个以农业为基础的经济体，准确的信息对农业实践至关重要，有助于实现最佳农业增长和产出。为了帮助农民，基于Kisan Call Center的数据集开发了一个农业聊天机器人。该系统能够24小时不间断提供关于天气、市场行情、植物保护和政府计划的查询服务，信息易于理解且可透过任何电子设备访问。
### Innovation
该系统采用了句子嵌入模型，初始准确率为56%，通过去除同义词并引入实体提取，准确率提升至86%。这种系统使农民能够更容易获取与农业实践相关的信息，从而提高农业产出。同时减轻了呼叫中心工作人员的工作压力，将他们的精力转移到更值得的目标上。
### Conclusion
通过这一系统，农民可以获得关于农业实践的更易于获取的信息，从而提高农业产出。同时，呼叫中心员工的工作将得到简化，他们可以将更多的精力投入到更有价值的工作中。
## 454. `cs.CL` - Comparative Personalization for Multi-document Summarization [PDF](https://arxiv.org/pdf/2509.21562), [HTML](https://arxiv.org/abs/2509.21562)
### Authors
Haoyuan Li,Snigdha Chaturvedi
### Background
个人化的多文档摘要(MDS)对于满足用户的个人写作风格和内容关注点至关重要。现有的MDS系统通常缺乏有效的个性化方法，因此需要针对用户差异进行更加细致的比较。
### Innovation
提出了一种名为ComPSum的个性化MDS框架。ComPSum首先通过将用户的偏好与其他用户进行比较来生成结构化的用户分析，然后利用这些分析来指导个性化的摘要生成。此外，还提出了一个名为AuthorMap的评估框架，用于评估个性化MDS系统的个性化程度。
### Conclusion
通过将ComPSum在PerMSum数据集上与强基准线进行评估，结果显示ComPSum表现更好。同时，ComPSum还通过引述归因的方法提供了一个新的评估框架AuthorMap来评估个性化MDS系统的性能。
## 455. `cs.CL` - 上下文即所需：大型语言模型的实际有效上下文窗口限制 [PDF](https://arxiv.org/pdf/2509.21361), [HTML](https://arxiv.org/abs/2509.21361)
### Authors
Norman Paulsen
### Background
大型语言模型（LLM）提供者通常会宣布其最大上下文窗口大小。然而，实际应用中的上下文窗口的有效性还未经过充分测试。本文旨在探讨现实世界中上下文窗口的应用效果，因此定义了最大有效上下文窗口的概念，并提出了一种测试方法来评估不同大小和不同类型问题中的上下文窗口效果，同时提供了一个标准化的方法来比较不同大小的上下文窗口的模型效果，直到找到失败点。
### Innovation
本文的创新点在于提出了最大有效上下文窗口的概念，并设计了一种方法来测试和评估不同大小和不同类型问题中的上下文窗口效果。研究发现，不同模型的最大有效上下文窗口与宣布的最大上下文窗口存在显著差异，并且这种差异会根据问题类型而变化。研究还揭示了不同问题类别下的最大有效上下文窗口的变化，为提高模型准确性和降低模型幻觉率提供了明确而实用的见解。
### Conclusion
研究结果显示，大多数模型在上千个上下文标记时准确性严重下降，有些顶级模型甚至在100个标记就失效。所有模型的实际效果远低于其宣布的最大上下文窗口效果，差距最高可达99%。因此，最大有效上下文窗口根据问题类型会发生变化，这揭示了如何改善模型准确性和降低模型幻觉率的明确路径。
## 456. `cs.CL` - 基于LLM的糖尿病诊断支持：GPT-5的机遇、情景与挑战 [PDF](https://arxiv.org/pdf/2509.21450), [HTML](https://arxiv.org/abs/2509.21450)
### Authors
Gaurav Kumar Gupta,Nirajan Acharya,Pranal Pande
### Background
糖尿病是一种全球性的重大健康挑战，影响着世界上超过五亿成人，且预计发病率将持续上升。尽管美国糖尿病协会（ADA）提供了清晰的诊断标准，但由于症状模糊、实验室值接近临界值、妊娠复杂性和长期监测需求，早期识别依然困难。大型语言模型（LLMs）的进步为通过结构化、解释性和对患者友好的输出增强决策支持提供了机会。本研究使用完全基于与ADA2025标准和公共数据集（如NHANES、皮马印第安人数据、EyePACS和MIMIC-IV）一致的合成病例的模拟框架，评估了最新的生成预训练变换器GPT-5在糖尿病诊断中的应用。
### Innovation
研究利用GPT-5人工智能模型，针对症状识别、实验室解读、妊娠糖尿病筛查、远程监测和多模态并发症检测五个代表性场景进行了评估。结果显示GPT-5在各类场景下的表现与ADA定义的标准高度一致，证明了其作为临床医生和患者双重用途工具的潜力，并强调了如何通过可重复的评估框架负责任地评估LLMs在医疗保健中的作用。
### Conclusion
GPT-5在糖尿病诊断的多个场景中表现出强大的一致性，表明它可以作为临床医生和患者的双用途工具。然而，强调了需要通过可重复的评估框架负责任地评估LLMs在医疗保健中的应用。
## 457. `cs.CL` - 道德对齐性能权衡的诊断：性别刻板印象案例研究 [PDF](https://arxiv.org/pdf/2509.21456), [HTML](https://arxiv.org/abs/2509.21456)
### Authors
Guangliang Liu,Bocheng Chen,Xitong Zhang,Kristen Marie Johnson
### Background
道德对齐作为一种广泛采用的方法，用于规制预训练语言模型（PLMs）的行为，通常通过在精选数据集上进行微调或模型编辑实现。然而，这一过程常常以牺牲下游任务性能为代价。以往的研究大多追求通过精心设计的公平性目标鼓励PLMs选择性忘记某些刻板印象知识，以保留其有用的特性，但仍面临性能权衡的问题。本文研究了在减轻性别刻板印象背景下，这种性能权衡的潜在机制，通过‘遗忘’这个视角和公平性目标来进行分析。研究表明，现有的公平性目标在实现权衡方面存在局限性：（1）下游任务性能主要由整体遗忘程度决定；（2）选择性忘记刻板印象倾向于增加整体遗忘；（3）适用于减轻遗忘的一般解决方案对减少整体遗忘无效，也无法提升下游任务性能
### Innovation
本文通过分析在减轻性别刻板印象背景下，PLMs的性能权衡问题，阐述了现有公平性目标的局限性，并提出了启示性的观点。尤其是在说明为什么选择性遗忘刻板印象会增加整体遗忘，以及为什么现有的解决遗忘的一般方法无法有效地减少整体遗忘并提升性能方面提出了新见解
### Conclusion
现有的公平性目标在减轻性别刻板印象的道德对齐过程中存在局限性，简单地选择性遗忘刻板印象知识并不能有效地减轻整体遗忘，也不能提升下游任务的性能。因此，需要更深入地探究更有效的减轻遗忘的方法，以实现性能和公平性的兼顾。
## 458. `cs.CL` - 大型语言模型优化中的多目标强化学习：前瞻视角 [PDF](https://arxiv.org/pdf/2509.21613), [HTML](https://arxiv.org/abs/2509.21613)
### Authors
Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers
### Background
多目标强化学习（MORL）在优化大型语言模型（LLMs）中的多个目标时提供了重要机会，但也面临挑战。目前，MORL方法在LLMs和强化学习中的应用尚存在效率和灵活性不足的问题，特别是处理LGM内在复杂性和个性化需求时更为明显。
### Innovation
论文提出了MORL分类，并评估了各种MORL方法在LLMs优化中的优缺点，强调了需要高效和灵活的方法。此外，提出了MORL基准测试框架的概念，以评估不同方法对多样化目标关系的影响。更重要的是，论文关注多层级学习框架下的元策略MORL发展，以提升效率和灵活性，并提出解决关键研究问题和改进LLM表现的潜在方案。
### Conclusion
未来的研究方向集中在开发能够通过多层次学习提高效率和灵活性的多目标强化学习（MORL）元策略，同时解决关键研究问题和提供改进LLM性能的潜在解决方案。
## 459. `cs.CL` - 针对非洲口音英语的领域意识说话人消歧 [PDF](https://arxiv.org/pdf/2509.21554), [HTML](https://arxiv.org/abs/2509.21554)
### Authors
Chibuzor Okocha,Kelechi Ezema,Christan Grant
### Background
本文研究了非洲口音英语在说话人消歧中的领域效应。研究在严格重叠得分(DER)协议下，评估了多个生产系统和公开系统在通用和临床对话中的表现。
### Innovation
研究引入了基于控制的跨领域基准测试，提出了一种简洁的错误分解和对话级别分析方法，并提供了一种易于重现的领域适配方案。此外，研究还强调了重叠感知分割和平衡临床资源作为实际改进步骤的重要性。
### Conclusion
临床对话中存在一致且显著的领域惩罚，主要由误报和漏报引起，特别是在短对话和频繁重叠的情况下。经过细调的领域适配方案能够降低错误，但未能完全消除差距。这些结果为领域适配和错误缓解提供了实际指导。
## 460. `cs.CL` - Dual-Head Reasoning Distillation: 使用训练时推理提高分类器准确性 [PDF](https://arxiv.org/pdf/2509.21487), [HTML](https://arxiv.org/abs/2509.21487)
### Authors
Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan
### Background
链式思考（CoT）提示通常可以提高分类准确率，但会带来显著的吞吐量 penalty 与解释生成。魏等人（2022）和程和凡·杜姆（2024）的研究都指出，在引入CoT提示的同时，系统需处理生成解释的开销问题，这影响了整体性能。文章旨在解决这一权衡问题，提升模型在解释生成与吞吐量之间的表现。
### Innovation
文章提出了双头推理蒸馏(DHRD)方法，这是一种简单的训练方法应用于只解码语言模型（LMs）。该方法包括增加 (i) 一个用于训练和推理的池化分类头，以及 (ii) 一个仅在训练中由教师的解释进行监督的推理头。训练使用标籤交叉熵损失与基于输入加解释序列的令牌级别LM损失的加权和作为损失函数。在七种SuperGLUE任务中，DHRD相比池化基准模型提高了0.65-5.47%的相对准确性，特别是在因果推理任务上的增益更为显著。由于推理头在测试时被禁用，使得推理吞吐量与池化分类器相当，且比相同架构的CoT解码速度提升了96-142倍，达到了每秒请求处理次数（QPS）的显著提升。
### Conclusion
DHRD通过仅在训练时进行推理，能够在确保吞吐量的基础上提高分类器的准确性。在SuperGLUE性能评估中展示了明显的竞争力，特别是在一些特定任务上表现出更显著的提升。
## 461. `cs.CL` - 关于LLMs中的代码诱导推理 [PDF](https://arxiv.org/pdf/2509.21499), [HTML](https://arxiv.org/abs/2509.21499)
### Authors
Abdul Waheed,Zhen Wu,Carolyn Rosé,Daphne Ippolito
### Background
已有研究表明，代码能够增强大型语言模型（LLM）的推理能力，但尚未明确了解哪些代码的特性最能提高这方面的表现。该论文通过系统化的方法研究了这一点，建立了多个编程语言的平行指令数据集，并通过有针对性地干扰代码的结构或语义特性来进行实验，以评估LLM在这方面的表现差异，从而探究哪些代码特性对提升LLM推理能力更为关键.
### Innovation
通过构建多个编程语言的平行数据集，并采用有控制的干扰方法（选择性影响代码的结构或语义特性），训练不同家族和规模的LLM，评估它们在自然语言、数学和代码任务中的表现，探讨了LSTM模型的结构扰动对抗性与语义扰动的易感性差异，得出了伪代码和流程图等抽象方式可以有效代替代码的结论，同时揭示了不同语法规则风格对任务特定获益的影响，基于Python和低级语言如Java和Rust在数学和自然语言推理任务中的差异表现提出了见解.
### Conclusion
研究表明LLM对结构扰动比语义扰动更为敏感，特别是在数学和代码任务中。适当抽象如伪代码和流程图与代码一样有效，而以较少的词数表示信息而不遵循原始语法可以保留甚至提高性能。即使带有误导信号的代码，在表面规律依然存在时仍具有竞争力。不同编程语言的语法风格也影响任务特定收益，Python强调自然语言推理能力，而低级语言如Java和Rust则强调数学推理能力。通过系统研究，本文旨在揭示代码不同特性的影响，并为提升语理能力制定训练数据的设计提供参考.
## 462. `cs.CL` - 生成时引文 vs. 事后引文：大规模语言模型引文全面评估 [PDF](https://arxiv.org/pdf/2509.21557), [HTML](https://arxiv.org/abs/2509.21557)
### Authors
Yash Saxena,Raviteja Bommireddy,Ankur Padia,Manas Gaur
### Background
在高风险领域如医疗、法律、学术和金融中，大型语言模型（LLMs）需要引用可由人类验证的来源，即使是小错误也可能导致严重后果。实践者和研究人员面临的选择是：让模型在解码时生成引用，还是先生成答案再添加或验证引用。为了明确这一选项，作者提出了两种引文模式：生成时引文（G-Cite）和事后引文（P-Cite）。
### Innovation
作者引入了两种引文模式：生成时引文（G-Cite）和事后引文（P-Cite），并进行了跨四个流行归因数据集的全面评估。评估从零样本到高级检索增强方法，提供了基于证据的权衡建议。研究结果显示，在两种模式中，检索是影响引文质量的主要因素，P-Cite在覆盖率方面表现出色且正确率高，但延迟适中；而G-Cite更注重精度，但牺牲了覆盖率和速度。
### Conclusion
建议在高风险应用中采取以检索为中心、P-Cite优先的方法，而将G-Cite保留用于如严格声明验证等高精度要求的场景。同时指出，释放的代码和人类评估结果可见于指定链接。
## 463. `cs.CL` - 使用混合token学习推理 [PDF](https://arxiv.org/pdf/2509.21482), [HTML](https://arxiv.org/abs/2509.21482)
### Authors
Adit Jain,Brendan Rappazzo
### Background
当前基于可验证奖励的强化学习（RLVR）方法已成为提升大型语言模型（LLM）推理能力的领先方法。大多数现有方法遵循分组相对策略优化的变体，对多个推理完成进行采样，相对评分并据此调整策略。然而，这些方法在每一步推理中仅采样离散符号，忽视了模型在候选符号上的概率分布中的丰富分布信息。虽然在非RL环境中保持并利用这种分布信息是有益的，但当前的RLVR方法似乎通过不利用这些信息来限制了推理搜索空间。为了克服这种限制，本研究探讨了使用混合token生成（MoT-G）的RLVR方法。研究建立了一个统一的框架，统一了现有的MoT-G方法并扩展了RLVR操作域，以便在连续混合空间中生成链式思考。通过在Reasoning-Gym上评估两种MoT-G变体，研究发现MoT-G方法在7个任务中达到5%-35%的改进，在同样精度下，只需要一半的轨迹数量，表明提高了训练效率。详细隐藏状态和token层面的分析表明，MoT-G的收益可能源于它在整个推理过程中保持较高隐藏状态熵和促进在token空间中的探索的能力。
### Innovation
本研究提出了一种使用混合token生成（MoT-G）的新型RLVR方法，并建立了一个统一的框架，统一了现有的MoT-G方法。该研究扩展了RLVR操作域，使其能够在连续的混合空间中生成链式思考。通过这两大步骤，该研究显著提高了训练效率，尤其是在保持同样精度的情况下，只需要一半的轨迹数量，并且研究成果提供了对MoT-G收益背后的机制的详细分析和证据。
### Conclusion
本研究提出的方法（MoT-G）在Reasoning-Gym上有效地促进了大型语言模型的推理能力提升，展示了提高训练效率，并提供了对MoT-G在整个推理过程中维持更高隐藏状态熵和促进探索token空间机制的详细证据。
## 464. `cs.CL` - Be My Cheese?：评估多语言LLM翻译中的文化细微差别 [PDF](https://arxiv.org/pdf/2509.21577), [HTML](https://arxiv.org/abs/2509.21577)
### Authors
Madison Van Doren,Cory Holland
### Background
该研究是一个实验性质的研究，探讨了最先进的多语言AI模型在翻译比喻语言（如成语和双关语）方面的本地化能力，是从英语翻译成多种全球语言的情况。它扩展了现有的LLM翻译研究和行业基准，这些研究主要强调语法准确性及在标记层面上的正确性，而将文化适宜性和整体本地化质量作为关键因素。这些因素对于实际应用如营销和电子商务至关重要，通过评估87份LLM生成的电子商务营销邮件翻译样本来调查这些挑战，并请求多语言文化流利的人类审稿人提供定量评分和定性反馈。
### Innovation
这项研究挑战了数据量是预测机器翻译质量最可靠指标的假设，并提出文化适宜性是多语言LLM性能的关键决定因素，这是目前学术界和行业基准下尚未充分探讨的领域。通过这样一个试点项目，研究展示了现有跨语言AI系统在实际本地化应用中的局限性，并展示了扩大规模进行进一步研究的机会，以提供通用见解，并改进在文化多样化背景下可靠的机器翻译工作流程。
### Conclusion
研究结果显示，虽然领先的模型通常能产生语法正确的翻译，但文化上的细微差异仍然是一个明显的改进区域，通常需要大量的手工润色。即使对于高资源的全球语言，尽管在行业基准表上名列前茅，也经常错误地翻译形象表达和文字游戏。这项试点研究支持进一步研究以扩大规模并提供更广泛的见解，进而指导跨文化的可靠机器翻译流程的部署。
## 465. `cs.CL` - GRAB：金融披露中的风险分类基准 [PDF](https://arxiv.org/pdf/2509.21698), [HTML](https://arxiv.org/abs/2509.21698)
### Authors
Ying Li,Tiejun Ma
### Background
在10-K风险披露中进行风险分类对监督和投资很重要，但目前没有公开的基准来评估无监督主题模型。现有文献缺乏一个全面评估指向具体金融领域的无监督主题模型的方法。
### Innovation
提出了一个名为GRAB的新基准，即专门为金融领域定制的风险分类基准。该基准利用了10,247份文件中的161万句句子，并在无需人工标注的情况下通过结合FinBERT术语注意力、YAKE关键短语信号和分类学意识共现匹配生成了语句标签。标签基于风险分类学将193术语映射到5个宏观类别的21种细分类上，这些细分类指导了弱监督，评价则在宏观层面进行。GRAB基准统一了评估方法，包括固定的数据集分割和稳健的度量标准：准确性、宏F1、主题BERT得分和基于熵的主题多样性的有效数量。
### Conclusion
通过提供包含标签和代码的数据集，GRAB允许对经典、基于嵌入的、神经网络和混合主题模型在金融披露中的效果进行可重复和标准化的比较和评估。
## 466. `cs.CL` - SynerGen: 综合生成推荐系统以统一搜索和推荐 [PDF](https://arxiv.org/pdf/2509.21777), [HTML](https://arxiv.org/abs/2509.21777)
### Authors
Vianne R. Gao,Chen Xue,Marc Versage,Xie Zhou,Zhongruo Wang,Chao Li,Yeon Seonwoo,Nan Chen,Zhen Ge,Gourab Kundu,Weiqi Zhang,Tian Wang,Qingjun Cui,Trishul Chilimbi
### Background
大型推荐系统中的提取-排序流水线由于其架构分割和不同的优化目标而存在校准失准和工程开销的问题。虽然最近的生成序列模型在统一检索和排序方面表现出潜力，但现有解决方案通常仅能处理个性化搜索或查询推荐中的一个方面，在尝试统一两方面时往往会表现出性能折中。
### Innovation
引入了SynerGen，一种新型生成推荐模型，提供了统一检索和推荐的单一生成骨干，并同时擅长检索和排序任务。模型通过基于行为序列进行训练，使用只解码的Transformer解码器，结合InfoNCE进行检索优化和混合点-对-面损失进行排序优化。此外，还提出了一种新颖的时间感知旋转位置嵌入，以有效将时间信息融入注意力机机制中。SynerGen在广泛采用的推荐和搜索基准测试中相比现有强生成推荐系统和联合搜索与推荐基础模型取得了显著改进。
### Conclusion
该研究展示了单一生成基础模型在工业规模统一信息访问方面的可行性。
## 467. `cs.CL` - 视觉语言模型不能计划，但它们可以形式化？ [PDF](https://arxiv.org/pdf/2509.21576), [HTML](https://arxiv.org/abs/2509.21576)
### Authors
Muyu He,Yuxi Zheng,Yuchen Liu,Zijian An,Bill Cai,Jiani Huang,Lifeng Zhou,Feng Liu,Ziyang Li,Li Zhang
### Background
视觉语言模型（VLMs）的进步让代理具备了完成简单的多模态规划任务的能力，但对于需要长时间序列动作的长期规划任务则无能为力。在纯文本模拟中，长期规划利用大型语言模型（LLMs）重新定位角色，在不直接生成动作序列的情况下，将规划领域和问题翻译成形式规划语言（如规划领域定义语言PDDL），并通过调用形式求解器来验证计划。然而，在多模态环境中，关于VLM作为形式化工具的研究很少，通常会涉及预定义的对象词汇表或过于相似的少量示例。论文报道了五个VLM作为形式化工具的管道，解决了单次学习、开放式词汇和多模态PDDL形式化等问题，并在现有基准上进行了评估，同时提出了两个新的基准，首次考虑到使用真实、多视图和低质量图像进行规划。论文指出，视觉语言模型作为形式化工具大幅优于端到端计划生成，但瓶颈在于视觉而非语言，视觉语言模型难以捕捉所有必要的对象关系，生成中间的文本表示如图像描述或场景图只能部分补偿这一缺陷，这为未来多模态规划形式化提供了研究方向。
### Innovation
提出了五个VLM作为形式化工具的管道，解决了单次学习、开放式词汇和多模态PDDL形式化等问题。首次在基准上考虑使用真实、多视图和低质量图像进行规划。展示了在多模态环境中，VLM作为形式化工具大幅优于端到端计划生成，指出了视觉语言模型在捕捉所有必要的对象关系方面的局限性，提供了多模态规划形式化方面的未来研究方向。
### Conclusion
视觉语言模型作为形式化工具大幅优于端到端计划生成，但视觉语言模型在捕捉所有必要的对象关系方面存在局限性。未来研究应关注如何更好地利用视觉语言模型进行多模态规划形式化。
## 468. `cs.CL` - Think-on-Graph 3.0: 通过多智能体双演化上下文检索在异构图上高效且自适应的大语言模型推理 [PDF](https://arxiv.org/pdf/2509.21710), [HTML](https://arxiv.org/abs/2509.21710)
### Authors
Xiaojun Wu,Cehao Yang,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Hui Xiong,Jia Li,Jian Guo
### Background
检索增强生成（RAG）和基于图的RAG已成为增强大型语言模型（LLMs）的外部知识的重要范式。然而，现有的方法面临一个基本的权衡。虽然基于图的方法天生依赖于高质量的图结构，但它们面临巨大而现实的挑战：手工构建的知识图谱难以大规模扩展，而自动从资料中提取的图谱又受限于底层LLM提取器的表现，尤其是使用较小且本地部署的模型时更为明显。本研究讨论了这些问题及其现有方法的局限性。
### Innovation
本论文提出Think-on-Graph 3.0（ToG-3），引入了一种新型框架，该框架提出了多智能体上下文进化和检索（MACER）机制，以克服这些限制。核心创新在于动态构建和精炼一个块-三元组-社区异构图索引，这一创新性地融合了查询和子图的双演化机制，以实现精确证据检索。此外，研究还提出多智能体系统，包括构造器、检索器、反思者和响应者，通过迭代过程协作进行证据检索、答案生成、充足性反思以及查询和子图的进化，从而实现自适应构建目标图索引，减轻了静态一次性图构建的固有缺陷，即使使用轻量级LLM也能实现深入精准推理。
### Conclusion
广泛的实验表明，ToG-3在深度和广度推理基准测试中优于对比基线，且消融研究证明了MACER框架组件的有效性。
## 469. `cs.CL` - ProPerSim: 通过用户助手模拟开发前瞻性个性化人工智能助手 [PDF](https://arxiv.org/pdf/2509.21730), [HTML](https://arxiv.org/abs/2509.21730)
### Authors
Jiho Kim,Junseong Choi,Woosog Chay,Daeun Kyung,Yeonsu Kwon,Yohan Jo,Edward Choi
### Background
随着大型语言模型（LLMs）逐渐融入日常生活，人们对不仅能反应还能主动且个性化的人工智能助手的需求日益增加。尽管近期的一些进步在推动这些特性中的一项方面取得了进展，但将这两者结合起来的发展仍然较少关注。本研究旨在弥合这一差距，提出了ProPerSim，一种用于开发能够在现实家庭场景中做出及时、个性化建议的人工智能助手的新任务和模拟框架。在该模拟环境中，具有丰富人格特征的用户代理与助手互动，提供评级，评估建议与偏好的契合程度。助手的目标是通过这些评级学习和适应，从而随着时间的推移获得更高的分数。
### Innovation
提出了一种名为ProPerSim的新任务和模拟框架，以及在其基础上的ProPerAssistant，一种检索增强、偏好对齐的助手。该助手能够通过用户反馈不断学习和适应，以适应不同的用户人格特征。实验结果表明，ProPerAssistant能够调整其策略，并持续提高用户满意度，展示了将前瞻性与个性化结合的潜力。
### Conclusion
本研究通过ProPerSim框架及其应用的ProPerAssistant，展示了结合前瞻性与个性化的潜在优势，并证明了在现实家庭场景中不断学习和适应的助手是可行的。
## 470. `cs.CL` - ReviewScore: 大型语言模型在检测同行评审误导中的应用 [PDF](https://arxiv.org/pdf/2509.21679), [HTML](https://arxiv.org/abs/2509.21679)
### Authors
Hyun Ryu,Doohyuk Jang,Hyemin S. Lee,Joonhyun Jeong,Gyeongman Kim,Donghyeon Cho,Gyouk Chu,Minyeong Hwang,Hyeongwon Jang,Changhun Kim,Haechan Kim,Jina Kim,Joowon Kim,Yoonjeon Kim,Kwanhyung Lee,Chanjae Park,Heecheol Yun,Gregor Betz,Eunho Yang
### Background
在大多数AI会议上，随着提交论文数量的激增，评审质量正在下降。为了可靠地检测低质量的评审，本研究定义了误导性评审点，将其分为两种类型：包含错误前提的“弱点”或可以通过论文本身回答的问题。验证结果显示，15.2%的弱点和26.4%的问题是误导性的，从而引入了ReviewScore来指示一条评审点是否是误导性的。与此同时，评估每条弱点的前提真实性，并提出了一种自动化引擎来重建每个显式和隐含的前提。通过构建由人类专家注释的ReviewScore数据集，验证了当前最先进的模型在自动评估ReviewScore方面的能力。进一步通过八种当前最先进的模型对人类-模型在ReviewScore评价上的意见一致性进行测量，结果显示意见一致性较为温和，并且在评估前提层面的真实性和评估弱点层面的真实性的对比中，前提层面的真实性的评估一致性更高。深入的分歧分析进一步支持了完全自动化ReviewScore评价的潜力。
### Innovation
提出了将大型语言模型用于自动化评估ReviewScore的方法，包括开发一个自动引擎来重建每条弱点的前提，并构建了一个由人类专家注释的ReviewScore数据集，用于验证大型语言模型在自动化评估ReviewScore方面的性能。
### Conclusion
研究表明，尽管当前最先进的模型在评估前提层面的真实性和评估弱点层面的真实性之间的意见一致性有所差异，但使用大型语言模型进行ReviewScore评价的自动化是有潜力的，并且在前提层面的真实性评价中更表现出一致性。未来的工作可以进一步探究完全自动化的ReviewScore评价方法。
## 471. `cs.CL` - 迈向透明AI：语言模型可解释性综述 [PDF](https://arxiv.org/pdf/2509.21631), [HTML](https://arxiv.org/abs/2509.21631)
### Authors
Avash Palikhe,Zichong Wang,Zhipeng Yin,Rui Guo,Qiang Duan,Jie Yang,Wenbin Zhang
### Background
语言模型（LMs）在自然语言处理领域取得了显著进展，并在多个领域取得重大突破。然而，它们的黑箱性质引发了对其内部机制和决策过程的可解释性问题。特别是在高风险领域，利益相关者需要了解模型输出背后的理据，以确保问责制。尽管可解释的人工智能(XAI)方法在非LMs中已有广泛应用，但对于LMs来说，它们的复杂架构、庞大的训练语料库以及广泛的泛化能力使得XAI方法的应用受到限制。现有的许多综述仅关注建模差异和不断发展的能力所引起的独特挑战，并未能全面覆盖。因此，本研究旨在填补这一空白，通过对各种XAI技术进行全面回顾，并重点讨论LMs，总结它们如何适应基于变换器架构的不同的模型类型，并分析它们的优势和局限性，以评估其效果。同时，还通过对可信性和忠诚度的双重视角进行评估，以求提供一个结构化的方法来衡量这些技术的有效性，确定了待解决的研究挑战，并指出了未来可能的研究方向，旨在指导已开展的工作朝着为LMs开发稳健、透明和可解释的XAI方法目标前进。
### Innovation
本文提出了一篇针对语言模型（LMs）的可解释性人工智能（XAI）技术的全面综述。它特别侧重于基于变换器架构（包括编码器-只型、解码器-只型和编码器-解码器型）的LMs，分析了XAI方法在这些不同模型类型中的适应性，并且评估了它们的优点和局限性。此外，它还通过可信度和忠诚度的双重视角来评价这些技术的效果，提供了一个结构化的方法来衡量这些技术的有效性。
### Conclusion
本文确定了可解释的AI方法在语言模型领域的研究中面临的一些开发现状，并指出了未来可能的研究方向。这些研究目标旨在指导即将到来的研究和发展工作，以开发能够提高透明度、增强解释性的XAI技术，进而提高语言模型的应用前景。
## 472. `cs.CL` - OjaKV：基于Oja规则的上下文感知在线低秩KV缓存压缩 [PDF](https://arxiv.org/pdf/2509.21623), [HTML](https://arxiv.org/abs/2509.21623)
### Authors
Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen
### Background
大规模语言模型的长上下文能力受到内存瓶颈的限制，特别是需要关键值（KV）缓存进行自回归生成。目前的KV缓存压缩方法依赖于固定、离线学习的低秩投影子空间，这些方法在数据分布变化时表现不佳。
### Innovation
引入了OjaKV框架，结合了战略性混合存储策略和在线子空间适应。具体而言，OjaKV保存了关键的第一和最后一个token为满秩形式，维持高精度的注意力锚点，并对大多数中间token应用在线主成分分析（PCA）实现低秩压缩。该框架能够在预置填（prompt prefilling）时进行全面更新，并在解码过程中轻量级地周期性更新，以确保子空间与上下文的变化保持一致。
### Conclusion
实验结果表明，OjaKV在高压缩比下保持或提高了零样本精度，并在需要复杂推理的长上下文测试中表现出显著优势，验证了基于Oja规则的在线子空间适应在动态追踪上下文变化中的重要性。此框架为无模型微调的内存高效长上下文推理提供了一种实用、即插即用的解决方案。
## 473. `cs.CL` - 评估和改进用于大语言模型对齐的文化意识奖励模型 [PDF](https://arxiv.org/pdf/2509.21798), [HTML](https://arxiv.org/abs/2509.21798)
### Authors
Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang
### Background
奖励模型（RMs）对于使大型语言模型（LLMs）与多元文化对接至关重要，因此评估它们的文化意识是进一步推进LLMs全球对接的必要步骤。然而，现有的RMs评估在评估文化意识方面存在不足，因为缺乏相关性文化评估数据集。本文提出了一种名为Cultural Awareness Reward modeling Benchmark (CARB)的新基准，涵盖了4个文化领域的10种不同文化，评估最先进的RMs时揭示了它们在文化和意识建模方面的不足，并表明在CARB上的表现与下游多语言文化对接任务存在正相关。进一步分析发现，文化意识奖励建模中存在的虚假关联，即奖励模型的评分主要依赖于表面特征而非真正的文化细腻理解。
### Innovation
本文提出的CARB基准涵盖了10种不同文化，4个文化领域，填补了现有RMs评估的空白；揭示了先进的RMs在文化意识建模方面的不足；发现文化意识奖励建模中的虚假关联；并提出了Think-as-Locals方法通过基于可验证奖励的强化学习(RLVR)来激发生成性RMs的深层次文化推理和使用精心设计的奖励确保准确的偏好判断和高质量结构化评估标准生成，从而克服这些不足。
### Conclusion
实验结果表明Think-as-Locals方法能够有效减轻虚假特征干扰并推动文化意识奖励建模的进步。
## 474. `cs.CL` - Self-Speculative Biased Decoding for Faster Live Translation [PDF](https://arxiv.org/pdf/2509.21740), [HTML](https://arxiv.org/abs/2509.21740)
### Authors
Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang
### Background
大型语言模型（LLMs）已经在各种文本生成任务中表现出色。然而，在流式应用（如实时翻译）中，它们仍然面临挑战。这种应用要求输出在输入上下文不断扩展的同时保持实时更新，因此需要在保持一定计算效率的前提下保证低延迟。
### Innovation
本文重新审视了同步翻译中的重译方法，并提出了‘自我推测偏向解码’（Self-Speculative Biased Decoding）这一新型推理框架。这种框架避免了从头开始重新生成不断增长的输入流输出，而是使用最新的输出作为当前增长输入上下文的草稿。在验证阶段，输出偏向草稿中的词，以提高草稿接受率。这一策略不仅可以减少会干扰用户的频繁闪烁，还提高了加速速度。与现有推测性解码策略不同，我们的方法无需计算草稿，使其成为一个适用于加速对延迟敏感的流式应用的通用解决方案，而不依赖于特定型号。实验结果显示，与传统的自回归重译相比，该方法在不牺牲质量的前提下实现了高达1.7倍的加速，并通过引入仅显示掩码技术显著减少了80%的闪烁。
### Conclusion
这一研究提出了自我推测偏向解码方案，通过优化流式应用中的同步翻译过程，实现了加速和质量并存的效果，提高了实时翻译的效率。
## 475. `cs.CL` - LLMs在会话转录上进行多问题回答的准确性如何？ [PDF](https://arxiv.org/pdf/2509.21732), [HTML](https://arxiv.org/abs/2509.21732)
### Authors
Xiliang Zhu,Shi Zong,David Rossouw
### Background
在工业环境中，使用大型语言模型（LLMs）进行超过一定长度上下文的问题回答（QA）是一个重大挑战。特别是在处理基于同一段上下文回答多个问题时，这种挑战更为显著，因为这往往需要较高的计算成本和较长的响应时间。研究探索了LLMs在基于相同会话上下文回答多个问题的能力，并通过广泛的实验对比评估了各种专有和开源模型在这一挑战任务上的表现。研究结果表明，虽然专有的LLMs如GPT-4o表现出最佳的整体性能，但经过微调的具有多达80亿参数的开源LLMs在准确度上仍然能够超越GPT-4o，这表明其在实际应用中的透明性和低成本优点。
### Innovation
研究对比了专有与开源模式的LLMs在基于长序列上下文的多问题回答能力，并发现某些开源模型的微调版本在准确率方面可超越高性能的专有LLM，表明了开源模型在实际部署中的潜力和成本优势。
### Conclusion
研究结果表明，在实际应用中，经过适当微调的开源大模型具有高准确度和较低成本的优势，这对于多问题回答这类复杂任务是非常重要的。未来的工作可以进一步探索这些模型的优化方法和应用场景。
## 476. `cs.CL` - 思考声音：音声链式思考增强大型音声语言模型中的多模态推理 [PDF](https://arxiv.org/pdf/2509.21749), [HTML](https://arxiv.org/abs/2509.21749)
### Authors
Zhen Xiong,Yujun Cai,Zhecheng Li,Junsong Yuan,Yiwei Wang
### Background
最近的大规模音声语言模型（LALMs）在语音翻译和音声问答等任务中表现出色。然而，它们在复杂声学场景中的挑战性推理任务中存在明显缺陷。这些场景中的问题可以通过使用声学工具（如降噪、声源分离和精确的时间对齐）来改善，但现有的LALMs缺乏这些工具的支持。
### Innovation
本文提出了一种名为Thinking-with-Sound（TwS）的新框架，该框架通过结合语言推理和实时的音声域分析，向LALMs注入了音声链式思考（Audio CoT），使其能够进行模态推理。这与现有方法将音频视为静态输入的做法不同，TwS使模型能够积极地与音频信号进行互动，通过多模态推理进行数值分析和数字操作。
### Conclusion
通过构建MELD-Hard1k这一新的鲁棒性基准测试，引入各种声学干扰，实验结果显示最先进的LALMs在MELD-Hard1k上的性能大幅下降，准确率相比清洁音频降低了超过50%。相比之下，TwS显著提升了模型的鲁棒性，小型模型绝对准确率提高了24.73%，大型模型的最大增加可达36.61%。研究结果表明，音声链式思考可以在不重新训练的情况下显著增强鲁棒性，为开发更鲁棒的音声理解系统开辟了新方向。
## 477. `cs.CL` - 通过结构化非线性变换增强低秩适应 [PDF](https://arxiv.org/pdf/2509.21870), [HTML](https://arxiv.org/abs/2509.21870)
### Authors
Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song
### Background
低秩适应（LoRA）是一种广泛采用的参数高效大型语言模型适配方法。然而，它的线性特性限制了表达能力。
### Innovation
提出了一种名为LoRAN的非线性扩展方法，应用轻量级变换到低秩更新上，并引入了基于正弦函数的激活Sinter，可以在不增加参数量的情况下添加结构化扰动。
### Conclusion
实验结果表明，LoRAN在多个总结和分类任务中一致地优于QLoRA。消融研究显示，Sinter在低秩调优中优于标准激活函数Sigmoid、ReLU和Tanh，突出激活设计的重要性。
## 478. `cs.CL` - 通过因果推理导航结构化输出格式对大型语言模型的影响 [PDF](https://arxiv.org/pdf/2509.21791), [HTML](https://arxiv.org/abs/2509.21791)
### Authors
Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma
### Background
大型语言模型（LLMs）生成的结构化输出增强了信息处理效率，并在工业应用中越来越受到重视。先前的研究探讨了结构化输出对LLMs生成质量的影响，但往往是单向的成果。有研究表明结构化格式能提升完整性和事实准确性，而有的则认为这限制了LLMs的推理能力，并导致评价指标的下降。现有评估的潜在局限包括测试场景受限、比较设置控制较弱以及依赖粗糙的评价指标。
### Innovation
本文通过因果推理深入分析结构化输出对LLMs的影响。基于一种假设和两种保证条件，提出了五种可能的因果结构来说明结构化输出对LLMs生成的影响。在七个公共和一个开发的推理任务中，发现粗略的评价指标报告了GPT-4o生成受结构化输出影响的正面、负面或中性效果，但通过因果推理在43种情境中并未发现因果影响。
### Conclusion
本研究在48种情景中仅在5种情况下发现了潜在的影响，其中有3种影响是由具体指令引发的复杂因果结构。
## 479. `cs.CL` - QoNext：走向下一代基础模型的用户体验 [PDF](https://arxiv.org/pdf/2509.21889), [HTML](https://arxiv.org/abs/2509.21889)
### Authors
Yijin Guo,Ye Shen,Farong Wen,Junying Wang,Zicheng Zhang,Qi Jia,Guangtao Zhai
### Background
现有的基础模型评估方法，包括近期的人本中心方法，未能捕捉到真正重要的东西：用户在交互过程中的体验。当前的方法仅关注输出的正确性，而忽略了用户满意度源自响应质量和交互之间的相互作用这一事实，这限制了它们评估用户体验的能力。
### Innovation
我们引入了QoNext框架，这是首次将网络和多媒体中的用户体验（QoE）原则应用于基础模型的评估。QoNext识别影响用户体验的体验因素，并将其纳入控制实验，通过在不同配置下收集人类评价来建立一个以QoE为导向的数据库，并训练预测模型，从可测量的系统参数估计感知的用户体验。结果表明，QoNext不仅能够实现预防性的、精细的评估，还为产品化的基础模型优化提供了可行的指导。
### Conclusion
QoNext不仅能够实现预防性的、精细的评估，还为产品化的基础模型优化提供了可行的指导。
## 480. `cs.CL` - KnowMT-Bench：多轮长对话中知识密集型长形式问答的评估基准 [PDF](https://arxiv.org/pdf/2509.21856), [HTML](https://arxiv.org/abs/2509.21856)
### Authors
Junhao Chen,Yu Huang,Siyuan Li,Rui Yao,Hanqian Li,Hanyu Zhang,Jungang Li,Jian Chen,Bowen Wang,Xuming Hu
### Background
现有的基准主要针对单轮对话，而多轮对话基准则更多地评估其他不相关的功能，而不是知识密集的实用性。Multi-Turn Long-Form Question Answering（MT-LFQA）是大型语言模型（LLMs）在知识密集领域的一个重要应用范式。现有的基准研究存在局限性，因此需要一个新的评估框架来评价和提高LLMs在知识密集领域的多轮对话能力。KnowMT-Bench提供了这种新的评估工具，可以系统地评估MT-LFQA在医学、金融、法律等领域的表现。
### Innovation
KnowMT-Bench是第一个专门用于评估LLMs在知识密集领域的多轮长对话中的MT-LFQA表现的基准。通过动态评估设置，模型在逻辑递进的问题序列中生成自己的多轮对话历史，最后由人类验证的自动化管道评估模型的现实世界性能。研究发现，多轮上下文会降低模型的表现，但通过检索增强生成（RAG）可以有效地缓解这种影响。
### Conclusion
KnowMT-Bench的重要性在于它展示了在实际知识密集应用场景中评估和提升LLMs对话事实能力的关键性。此研究表明需要更多针对性的评估工具来优化和测试LLMs在多轮长对话中的表现。
## 481. `cs.CL` - ResT: 重新塑造工具使用大语言模型的令牌级策略梯度 [PDF](https://arxiv.org/pdf/2509.21826), [HTML](https://arxiv.org/abs/2509.21826)
### Authors
Zihan Lin,Xiaohan Wang,Jie Cao,Jiajun Chai,Guojun Yin,Wei Lin,Ran He
### Background
大型语言模型（LLMs）可以通过调用外部工具变得具有目标导向的行为，而强化学习（RL）提供了优化这些工具使用策略的理论框架。然而，现有的方法主要依赖稀疏的结果奖励，不考虑工具使用任务的具体特性，从而增加了策略梯度的方差并使训练效率低下。作者通过理论分析发现，结构化、低熵的令牌是奖励的主要决定因素，并基于此提出了一种新的令牌级策略梯度方法——ResT，它通过基于熵的信息重权来重塑策略梯度，逐步增加推理令牌的重要性，从而平滑过渡从结构正确性到语义推理，并在多轮次的工具使用任务中稳定收敛。
### Innovation
提出了一种新的令牌级策略梯度方法——ResT，通过基于熵的信息重权来重塑策略梯度，逐步增加推理令牌的重要性，从而平滑过渡从结构正确性到语义推理，并在多轮次的工具使用任务中稳定收敛。该方法在BFCL和API-Bank上的实验结果表明，ResT相比之前的最佳方法高出8.76%，当在4B基础模型上微调时，ResT分别在单轮任务和多轮基础任务上优于GPT-4o，分别高出4.11%和1.50%。
### Conclusion
ResT能够通过基于熵的令牌重权来重塑策略梯度，有效提高了训练稳定性和语义推理能力，使得在多轮次工具使用任务中取得更好的性能。
## 482. `cs.CL` - 人类多模态语言理解中的最小因果表示 [PDF](https://arxiv.org/pdf/2509.21805), [HTML](https://arxiv.org/abs/2509.21805)
### Authors
Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai
### Background
人类的多模态语言理解（MLU）旨在通过整合不同模态的相关线索推断人的意图。现有工作主要遵循一种“学习关注”范式，通过最大化数据和标签之间的互信息来提高预测性能。然而，这种方法容易受到无意的数据集偏差的影响，使模型将统计捷径误认为是真实因果特征，导致模型在外分布（OOD）泛化能力下降。
### Innovation
本文引入了一种因果多模态信息瓶颈（CaMIB）模型，该模型利用因果原则而不是传统的似然。具体来说，模型首先使用信息瓶颈来过滤单一模态输入，去除与任务无关的噪声。然后，通过参数化的掩码生成器将融合的多模态表示分解为因果和捷径子表示。为了确保因果特征的全局一致性，引入了工具变量约束，并采用后门调整方法随机重组因果和捷径特征，以稳定因果估计。
### Conclusion
在多种多模态情感分析、幽默检测和反讽检测实验及外分布测试集上，CaMIB模型表现出了有效性。理论和实证分析进一步强调了其可解释性和稳健性。
## 483. `cs.CL` - 语义一致使开放生成型LLM级联高效化 [PDF](https://arxiv.org/pdf/2509.21837), [HTML](https://arxiv.org/abs/2509.21837)
### Authors
Duncan Soiffer,Steven Kolawole,Virginia Smith
### Background
级联系统在可能的情况下将计算请求路由到较小的模型，并仅在必要时递交给较大的模型，为LLM部署平衡成本和质量提供了一种有希望的方法。然而，它们在开放生成文本时面临根本挑战：在生成质量处于连续谱中时确定输出可靠性，通常会有多个有效响应。
### Innovation
我们提出了一种语义一致性作为无需训练的可靠递归信号，即集成输出在语义层面的共识。实验证明，当不同的模型输出在语义上一致时，它们的一致性比令牌级的置信度提供了更强的可靠性信号。从参数量为500M到70B的模型进行评估，结果显示语义级联在40%的成本下达到或超过目标模型的质量，并将延迟最多减少60%。该方法不需要模型内部信息，适用于黑盒API，并对模型更新具有鲁棒性，使其成为现实世界LLM部署的实际基线。
### Conclusion
我们的方法无需内部模型信息，适用于黑盒API，对模型更新具有鲁棒性，为现实世界的LLM部署提供了一种实用的基线。
## 484. `cs.CL` - LLMs能否解决和生成语言奥林匹克谜题？ [PDF](https://arxiv.org/pdf/2509.21820), [HTML](https://arxiv.org/abs/2509.21820)
### Authors
Neh Majmudar,Elena Filatova
### Background
本文探讨了一种组合任务，即解决和生成语言谜题，特别关注用于高中生的 linguistics olympiads 中使用的谜题。作者首先扩展了现有的用于解决语言谜题的任务基准，并探索了大型语言模型（LLMs），包括最新的先进模型如 OpenAI 的 o1，以解决语言谜题，并分析其在不同语言主题上的表现。研究表明，LLMs 在大多数谜题类型上优于人类，但对书写系统中心的谜题以及对未充分研究的语言则表现不佳。通过解谜实验获得的见解，作者引入了一个新颖的谜题生成任务，并认为即使是对相对简单的谜题进行自动化生成也具有扩大对语言学兴趣和向更广泛受众介绍领域的重要性等潜在价值。
### Innovation
本文的主要创新在于整合了解决和生成语言谜题的任务，并通过大型语言模型（LLMs）探索了解决这些谜题的方法。研究发现，尽管在某些特定的谜题类型上LLMs不如人类表现，但整体上，LLMs的表现优于人类。这种方法不仅能够促进语言学的发展，还能提高对稀有和未充分研究的语言的认识。
### Conclusion
本研究揭示了自动化谜题生成的重要性，尤其是在简单的谜题上。通过解决语言谜题实验获得的见解被用于指导新型的谜题生成任务。因此，这种自动化谜题生成不仅有助于扩大对语言学的兴趣，还可以让更多人了解和接触语言学领域。
## 485. `cs.CL` - 跟随TRACE：使用多智能体模型的有条理的共情回应生成路径 [PDF](https://arxiv.org/pdf/2509.21849), [HTML](https://arxiv.org/abs/2509.21849)
### Authors
Ziqi Liu,Ziyang Zhou,Yilin Li,Haiyang Zhang,Yangbin Chen
### Background
共情回应生成是创建更具人类特性和支持性的对话代理的关键任务。然而，现有的方法在专业的深度分析模型的分析深度和大型语言模型（LLMs）的生成流畅性之间面临核心权衡。为了应对这一挑战，我们提出了TRACE（Task-decomposed Reasoning for Affective Communication and Empathy），一种新颖的框架。该框架通过将任务分解为分析和合成的管道，将共情感作为结构化的认知过程建模。
### Innovation
通过将任务分解为分析和合成的管道，TRACE框架在整个生成过程中建立了一个全面的理解，实现了深入分析与表达性生成的结合。实验结果显示，与强大的基线相比，我们的框架在自动和LLM评估中表现出了显著的优越性，这表明我们的结构化分解是一种有前景的范式，用于创建更强大和可解释的共情代理。
### Conclusion
我们的框架在共情回应生成方面显著优于现有基线，证实了其在构建更强大和可解释的共情代理方面的潜力。我们已经将代码发布在以下链接: this https URL
## 486. `cs.CL` - 保留每一个提示：通过熵引导的优势整形在LLM强化学习中利用零方差提示 [PDF](https://arxiv.org/pdf/2509.21880), [HTML](https://arxiv.org/abs/2509.21880)
### Authors
Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang
### Background
当前的强化学习框架（如GRPO）依赖于模型对同一输入给出的不同响应在正确性上的差异，而忽视了所有响应获得相同奖励的问题，即所谓的零方差提示。研究表明，这些零方差提示虽然不通过差异化的反馈来指导策略优化，但仍然可以提供有意义的反馈信息，这对于增强语言模型的推理能力是有用的。因此，需要一种新的算法来从这些零方差提示中提取学习信号，以改进模型的策略优化过程。
### Innovation
本文提出了RL-ZVP（基于零方差提示的强化学习），这是一种创新算法，能够从零方差提示中提取学习信号，直接奖励正确性并惩罚错误，即使在没有对比性响应的情况下也能产生相关信息。这通过调整反馈强度来保留有意义的、细腻的学习信号，使得模型在零方差提示的存在下也能有效学习。
### Conclusion
在六个数学推理基准测试中，与GRPO相比，RL-ZVP在准确性和通过率上分别提高了8.61个点和7.77个点，且在所有基线中均表现出色，这些基线都过滤掉了零方差提示。这些结果表明，零方差提示在RLVR中具有未被充分利用的潜力。
## 487. `cs.CL` - LUMINA: 通过上下文-知识信号检测RAG系统中的幻觉 [PDF](https://arxiv.org/pdf/2509.21875), [HTML](https://arxiv.org/abs/2509.21875)
### Authors
Min-Hsuan Yeh,Yixuan Li,Tanwi Mallick
### Background
检索增强生成（RAG）旨在通过将响应与检索到的文档对接地来减轻大型语言模型（LLMs）中的幻觉现象。尽管如此，即使在提供正确且充足背景的情况下，基于RAG的LLMs仍然可能产生幻觉。现有研究表明，这源于模型利用外部上下文和内部知识之间的不平衡，并且一些方法已有尝试通过量化这些信号来检测幻觉。然而，现有方法需要大量的超参数调整，限制了它们的普适性。
### Innovation
我们提出了一种名为LUMINA的新框架，用于通过上下文-知识信号检测RAG系统中的幻觉：外部上下文的利用通过分布距离量化，内部知识的利用则通过跟踪预测词元在整个变换器层中的变化来实现。此外，我们还引入了一个统计验证这些测量的框架。实验结果显示LUMINA在一般RAG幻觉基准测试和四个开源LLMs上的AUROC和AUPRC分数都很高，明显优于之前的利用基于方法，并在HalluRAG上最多可高出13%的AUROC。另外，LUMINA在检索质量和模型匹配的宽松假设下仍保持稳健，提供了高效的实用性保证。
### Conclusion
实验表明，LUMINA在常见RAG幻觉基准测试和四个开源LLMs上实现了稳健性高的AUROC和AUPRC得分，其功效和实用都优于先前的利用基于方法。此外，LUMINA在检索质量和模型匹配方面的宽松假设下仍然保持稳健，确保了其在实际应用中的可靠性。
## 488. `cs.CL` - 重新定义机器即时口译：从增量翻译到类人策略 [PDF](https://arxiv.org/pdf/2509.21801), [HTML](https://arxiv.org/abs/2509.21801)
### Authors
Qianen Zhang,Satoshi Nakamura
### Background
传统的机器翻译系统在实时口译场景下难以兼顾高质量翻译和严格的实时性约束。现有的端到端编码-解码模型（仅有READ/WRITE操作）不足以应对即时口译中对快速重新结构化、省略和简化的需求，而同时需要保留语义忠实度。
### Innovation
本文扩展了即时机器翻译的行动空间，引入了四种自适应行动：SENTENCE_CUT（句子切割）、DROP（删除）、PARTIAL_SUMMARIZATION（部分摘要）和PRONOMINALIZATION（代词化），并将其应用于仅解码器大型语言模型框架中。通过行动感知的提示构建训练参考，实现在兼顾语义准确性和延迟的同时产生流畅的即时翻译。
### Conclusion
实验结果显示，结合DROP和SENTENCE_CUT策略在流畅性和延迟方面表现最佳。研究证明，丰富LLM基础的即时机器翻译的行动空间为缩小人机理解差距提供了有前景的方向。
## 489. `cs.CL` - 弹性MoE：解锁Mixture-of-Experts的推理时可扩展性 [PDF](https://arxiv.org/pdf/2509.21892), [HTML](https://arxiv.org/abs/2509.21892)
### Authors
Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang
### Background
Mixture-of-Experts (MoE) 模型通常在训练和推理时固定活跃专家的数量。在直觉上，增加更多的专家（即增加推理时的活跃专家数量 $k'$，其中 $k'> k$）意味着使用更多的模型参数进行计算，从而提高性能。然而，研究发现性能增益范围非常有限，在稍有增加活跃专家的情况下就开始迅速下降。进一步研究发现，这种性能下降是由专家之间缺乏学习到的合作所引起的。
### Innovation
提出了弹性 MoE（EMoE），这是一种新颖的训练框架，允许在推理时根据需要扩大活跃专家的数量，而不会增加额外的训练开销。通过同时训练专家在不同组合中的合作，并鼓励路由器做出高质量的选择，EMoE 能够确保在推理时的各种计算预算下实现稳健的性能。
### Conclusion
进行了广泛的实验，在各种 MoE 设置中，结果显示 EMoE 显著扩展了有效的性能扩展范围，将扩展范围扩展到训练时 $k$ 的 2-3 倍，同时还将模型的峰值性能推向更高水平。
## 490. `cs.CL` - 通过不确定表达的一致性实现黑盒幻觉检测 [PDF](https://arxiv.org/pdf/2509.21999), [HTML](https://arxiv.org/abs/2509.21999)
### Authors
Seongho Joo,Kyungmin Min,Jahyun Koo,Kyomin Jung
### Background
尽管语言模型在最近取得了重大进展，如GPT3这样的大型语言模型（LLMs）因生成非事实性的响应而闻名，这些问题被称为‘幻觉’问题。目前用于检测和缓解这种幻觉问题的方法要么依赖外部资源，要么依赖LLMs的内部状态（如每个令牌的输出概率）。由于LLMs对外部API的限制和可用外部资源的局限，迫切需要建立黑盒方法作为有效检测幻觉的基础。
### Innovation
本文在调查LLMs在表达不确定性时的行为后，提出了一种简单的黑盒幻觉检测度量标准。研究表明，LLMs在给出事实性响应时保持一致性，而在给出非事实性响应时则不一致。基于此分析，提出了一种基于不确定性表达的高效黑盒幻觉检测度量标准。实验结果表明，与依赖LLMs内部知识的baseline相比，该指标更能够预测模型响应的准确度。
### Conclusion
通过不确定性表达的一致性，该研究提出了一种黑盒幻觉检测方法，并通过实验验证了其预测能力优于依赖LLMs内部知识的方法，为解决幻觉问题提供了一种新的途径。
## 491. `cs.CL` - SimulSense：基于感知的翻译以提高实时同步口译效率 [PDF](https://arxiv.org/pdf/2509.21932), [HTML](https://arxiv.org/abs/2509.21932)
### Authors
Haotian Tan,Hiroki Ouchi,Sakriani Sakti
### Background
当前最先进的同步口译（SimulST）系统将SimulST视为一个多轮对话任务，需要专门的交错训练数据，并依赖于计算昂贵的大型语言模型（LLM）进行决策。这种方法在质量与实时效率之间存在权衡问题，特别是在决策方面较为缓慢，比基准模型慢9.6倍左右。
### Innovation
本文提出了SimulSense，一种新的同步口译框架，模仿人类译员的行为，通过不断阅读输入口语并感知新的含义单元来触发写决策，从而生成翻译。这一创新方法在质量和实时效率之间提供了更优的权衡，并显著提高了实时效率，决策速度快达基线模型的9.6倍。
### Conclusion
与两个最先进的基线系统相比，我们提出的方法在高质量和实时效率之间取得了更好的权衡，并显著提高了实时效率，其决策速度是基线模型的9.6倍。
## 492. `cs.CL` - 语言模型中的离群值到主题演变：新闻语料库中预见趋势 [PDF](https://arxiv.org/pdf/2509.22030), [HTML](https://arxiv.org/abs/2509.22030)
### Authors
Evangelia Zve,Benjamin Icard,Alice Breton,Lila Sainero,Gauvain Bourgne,Jean-Gabriel Ganascia
### Background
本文探讨了通常被认为是话题建模噪点的离群值，在动态新闻语料库中可能作为新兴话题弱信号的作用。通过使用最先进的语言模型的向量嵌入和累积聚类方法，在关注可持续责任和气候变化的法语和英语新闻数据集中追踪其随时间的演变。
### Innovation
本文的创新之处在于通过大规模语言模型的向量嵌入和累积聚类方法，研究了离群值的演变过程，揭示了它们在动态新闻语料库中从噪点转变为有意义的主题的模式。
### Conclusion
研究结果表明，离群值具有较强的信号特征，能够进化为一致的主题，这一发现不仅验证了离群值的实际意义，也展示了动态主题建模的新方法。
## 493. `cs.CL` - 临床代理综合安全性分类 [PDF](https://arxiv.org/pdf/2509.22041), [HTML](https://arxiv.org/abs/2509.22041)
### Authors
Jean Seo,Hyunkyung Lee,Gibaeg Kim,Wooseok Han,Jaehyo Yoo,Seungseop Lim,Kihun Shin,Eunho Yang
### Background
在临床聊天机器人应用中，安全性至关重要，因为不准确或有害的响应可能导致严重后果。现有的方法，如护栏和工具调用，在应对临床领域的复杂需求方面经常不足。
### Innovation
本文提出了一种细粒度的21类别分类体系TACOS（临床代理综合安全分类），它将安全过滤和工具选择集成到单一步骤的用户意图分类中。TACOS能够涵盖广泛的临床和非临床查询，并具体建模不同的安全阈值和外部工具依赖关系。
### Conclusion
为了验证框架的有效性，我们制作了一个TACOS标注的数据集并进行了大量实验。实验结果展示了专门针对临床代理设置的新分类体系的价值，并揭示了训练数据分布和基模型先验知识的有用见解。
## 494. `cs.CL` - Fuzzy Reasoning Chain (FRC): 从模糊到清晰的一种创新推理框架 [PDF](https://arxiv.org/pdf/2509.22054), [HTML](https://arxiv.org/abs/2509.22054)
### Authors
Ping Chen,Xiang Liu,Zhaoxiang Liu,Zezhou Chen,Xingpeng Zhang,Huan Hu,Zipeng Wang,Kai Wang,Shuming Shi,Shiguo Lian
### Background
随着大型语言模型（LLMs）的快速发展，自然语言处理（NLP）已取得了显著的进步。然而，在处理多义性、同词异义或不确定性文本时，仍存在重大挑战。
### Innovation
我们提出了模糊推理链（FRC）框架，该框架结合了LLM语义先验与连续的模糊隶属度，创造了一种基于概率推理与模糊隶属度推理之间的显式交互方式。这种转变使模糊输入能够逐步转变为清晰和可解释的决策，同时捕捉到传统概率推理方法无法处理的冲突或不确定性信号。
### Conclusion
我们在情感分析任务上验证了FRC，理论分析和实验证明显示，FRC确保了稳定的推理，并促进了不同模型规模下的知识转移。这些发现表明，FRC提供了一种在提高可解释性和鲁棒性方面管理微妙和模糊表达的通用机制。
## 495. `cs.CL` - 在LLMs支持下的土耳其语大规模数据集和引文意图分类 [PDF](https://arxiv.org/pdf/2509.21907), [HTML](https://arxiv.org/abs/2509.21907)
### Authors
Kemal Sami Karaca,Bahaeddin Eravcı
### Background
理解引用的质性意图对于全面评估学术研究至关重要，但对于诸如土耳其语等粘着语系语言来说，这一任务提出了独特的挑战。现有方法对标准上下文学习（ICL）和大型语言模型（LLMs）在引用意图分类上的性能评估显示，手工设计的提示会导致不一致的结果，从而限制了其有效性。为了应对这一核心挑战，本研究提出了一种基于DSPy框架的可编程分类流水线，该框架系统地优化了提示并采用了堆叠泛化集成，利用XGBoost元模型实现了91.3%的最优准确率。
### Innovation
本研究引入了一种基于DSPy框架的可编程分类流水线，能够系统地优化提示，并利用堆叠泛化集成和XGBoost元模型实现了91.3%的最优准确率。此外，本研究还创建了一个新的公开可用的土耳其语引文意图数据集，适用于未来关于质性引文研究的基础工具。这项工作解决了现有方法中由于手动设计提示引起的不一致性问题，为土耳其语自然语言处理（NLP）社区和更广泛学术界提供了研究基础和有力工具。
### Conclusion
本研究通过创建一个新的公开可用的土耳其语引文意图数据集以及提出了一种基于DSPy框架的可编程分类流水线，系统地优化提示并利用堆叠泛化集成和XGBoost元模型实现了91.3%的最优准确率，为未来土耳其语引文研究提供了坚实的数据基础和强大方法框架。
## 496. `cs.CL` - Chain of Thought 在临床文本理解中的失败原因 [PDF](https://arxiv.org/pdf/2509.21933), [HTML](https://arxiv.org/abs/2509.21933)
### Authors
Jiageng Wu,Kevin Xie,Bowen Gu,Nils Krüger,Kueiyu Joshua Lin,Jie Yang
### Background
大型语言模型（LLMs）在临床护理中的应用越来越广泛，在此领域中，准确性与透明的推理过程对于安全和可信的部署至关重要。推理链（CoT）提示能够引出逐步的推理过程，已经在广泛的任务中表现出提高性能和可解释性的效果。然而，在临床背景下的效果尚未得到充分探索，特别是在电子健康记录（EHR）的环境中，临床记录往往冗长、碎片化且有噪声。因此，本文开展了首个大规模的系统研究，评估了95个高级LLM在87个实际临床文本任务上的效果，涵盖了9种语言和8种任务类型。研究发现，CoT设置下，86.3%的模型表现持续恶化，更强大的模型相对稳健，而较弱的模型则受到重大影响。通过精细分析推理长度、医学概念匹配以及错误模式，并利用LLM作为评估工具和临床专家评估，研究揭示了CoT在临床文本任务中失败的系统性模式，指出CoT虽然能增强可解释性，但也可能损害可靠性。
### Innovation
本研究是首次大规模系统性探讨CoT在临床文本理解中的应用。评估了95个高级LLM在87个实际临床任务上的表现，覆盖9种语言和8种任务类型，重点分析了CoT在临床背景下的效果，揭示了CoT可能增强解释性但损害可靠性的悖论。
### Conclusion
研究表明，在临床文本任务中，CoT可能会改善解释性但同时削弱可靠性。这一研究为临床推理策略提供了实证基础，强调了透明和可信的方法的重要性。
## 497. `cs.CL` - GraphSearch: 一种用于图检索增强生成的有目的地深度搜索工作流 [PDF](https://arxiv.org/pdf/2509.22009), [HTML](https://arxiv.org/abs/2509.22009)
### Authors
Cehao Yang,Xiaojun Wu,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Jia Li,Hui Xiong,Jian Guo
### Background
GraphRAG通过基于图的表示结构化建模知识，增强LLMs的事实推理能力。然而，现有GraphRAG方法存在两个核心问题：浅层检索无法展示所有关键证据，以及对预先构建的结构性图数据的低效利用，这阻碍了从复杂查询中进行有效推理。
### Innovation
提出了一种名为GraphSearch的新型自主深度搜索工作流，结合了双通道检索策略，分别为基于块的文本数据和结构化图数据分别提出语义查询和关系查询，从而充分利用两种模态及其互补优势，实现多轮交互和迭代推理。
### Conclusion
实验结果表明，GraphSearch在六个链式RAG基准测试中，始终提高了答案准确性和生成质量，证明GraphSearch是增强图检索增强生成的一个有前景的方向。
## 498. `cs.CL` - AutoSCORE：通过结构化组件识别增强多代理大型语言模型的自动评分 [PDF](https://arxiv.org/pdf/2509.21910), [HTML](https://arxiv.org/abs/2509.21910)
### Authors
Yun Wang,Zhaojun Ding,Xuansheng Wu,Siyue Sun,Ninghao Liu,Xiaoming Zhai
### Background
自动化评分在教育中扮演着重要角色，通过减少对人类评分者的依赖，提供可扩展和即时的学生作业评估。尽管大规模语言模型（LLM）在这一任务中展现出强大的潜力，但将其作为端到端的评分者仍面临诸多挑战，包括低准确性、提示敏感性、有限的可解释性和评分准则的不匹配。这些问题阻碍了LLM基于的自动化评分在评估实践中的实施。
### Innovation
本文提出了AutoSCORE，一个通过评分准则对齐的结构化组件识别增强的多代理LLM框架。AutoSCORE使用两个代理，首先从学生回答中提取与评分相关的组件并编码为结构化表示（即评分准则组件提取代理），然后用于分配最终分数（即评分代理）。该设计确保模型推理遵循类似人类评分的过程，增强了可解释性和稳健性。评估结果显示，AutoSCORE在四项基准数据集（来自ASAP基准）中提高了评分准确性、人机一致性（QWK、相关性）和误差指标（MAE、RMSE），尤其是对于复杂的、多维度的评分准则，特别是在较小的LLM上获得了显著的相对收益。这表明结构化的组件识别结合多代理设计为自动化评分提供了一种可扩展、可靠和可解释的解决方案。
### Conclusion
综上所述，本文提出的AutoSCORE框架通过使用多代理LLM并结合结构化组件识别，大幅提升了自动化评分的准确性、可靠性和可解释性。尤其在复杂多维度评价标准上，AutoSCORE表现出了显著的优势，为自动化评分的实际应用提供了有力支持。
## 499. `cs.CL` - 在泰语政治立场检测中通过反事实校准去偏大型语言模型 [PDF](https://arxiv.org/pdf/2509.21946), [HTML](https://arxiv.org/abs/2509.21946)
### Authors
Kasidit Sermsri,Teerapong Panboonyuen
### Background
在资源有限和文化复杂的环境下，识别政治立场对大型语言模型（LLMs）构成了重要挑战。在泰国的政治背景中，由于间接的语言表达、立场分歧以及情感与立场的交织，LLMs 经常表现出系统性偏见，如情感泄露和对实体的偏爱，这些偏见损害了公平性和可靠性。因此，发展一种无需微调的轻量级、模型无关的去偏框架非常重要，以便减轻政治偏见并在多种LLMs上提高公平性。
### Innovation
本文提出了 ThaiFACTUAL，这是一种轻量级、模型无关的校准框架，无需微调即可减轻政治偏见。ThaiFACTUAL 使用反事实数据增强和基于理据的监督来区分情感和立场，减少偏见。此外，还公开了首个质量高的泰语政治立场数据集，标注了立场、情感、理据及偏见标记，涵盖了多种实体和事件。实验结果表明，ThaiFACTUAL 显著减少了无偏相关性，增强了零样本泛化能力，并在多种语言模型中提高了公平性。
### Conclusion
本文强调了对欠代表性语言进行文化根基化的去偏技术的重要性。
## 500. `cs.CL` - MotivGraph-SoIQ: 整合动机知识图和苏格拉底对话以增强大型语言模型的创意生成 [PDF](https://arxiv.org/pdf/2509.21978), [HTML](https://arxiv.org/abs/2509.21978)
### Authors
Xinping Lei,Tong Zhou,Yubo Chen,Kang Liu,Jun Zhao
### Background
大型语言模型（LLMs）在加速学术创意生成方面具有巨大潜力，但它们在将创意扎根现实和减轻确认偏差以进一步完善方面面临关键挑战。MotivGraph-SoIQ框架通过结合动机知识图（MotivGraph）和基于Q的苏格拉底对话（SoIQ）来解决这些限制，以提高LLM创意生成的有效性。MotivGraph结构化地存储问题、挑战和解决方案三个关键节点类型，为LLM创意生成过程提供动机支撑。SoIQ则是一个双代理系统，利用苏格拉底式提问，促进了严格的改进过程，减轻了确认偏差，并在新颖性、实验严谨性和动机合理性等多个维度上提升了创意质量。研究团队使用ICLR25论文主题数据集进行评估，结果表明MotivGraph-SoIQ在LLM评分、ELO排名和人类评估指标上都优于现有最先进的方法。
### Innovation
MotivGraph-SoIQ框架通过整合动机知识图和基于Q的苏格拉底对话，为大型语言模型的创意生成提供了一个新的解决方案。MotivGraph以结构化的方式存储关键动机节点，提供动机支撑；SoIQ则利用苏格拉底式提问机制，以促进严格、有序的创意改进，减少确认偏差，从而提升创意质量。在整个评估过程中，该框架表现出了比现有方法更优越的性能。
### Conclusion
MotivGraph-SoIQ框架通过结合动机知识图和Socratic对话，显著提高了LLMs在创意生成过程中的表现，特别是在新颖性、实验严谨性和动机合理性方面，展示了对未来增强LLM创意生成工作的积极影响和潜力。
## 501. `cs.CL` - Think Right, Not More: Test-Time Scaling for Numerical Claim Verification [PDF](https://arxiv.org/pdf/2509.22101), [HTML](https://arxiv.org/abs/2509.22101)
### Authors
Primakov Chungkham,V Venktesh,Vinay Setty,Avishek Anand
### Background
事实核查真实世界的声明，尤其是数值声明，本质上是复杂的，需要多步推理和数值推理来验证声明的各个方面。尽管大型语言模型（LLMs）包括推理模型已经取得了巨大进展，但在需要组合和数值推理的复杂声明上，它们仍然表现不佳。它们无法理解数值方面的情趣，还容易出现推理漂移问题，导致无法综合多样信息，导致误解和推理过程的重新思考。
### Innovation
此研究系统性地研究了在事实核查复杂数值声明任务上扩展测试时计算（TTS）的方法，通过训练一个验证器模型（VERIFIERFC），使其能够探索多个可能的推理路径并选择通向正确裁决的路径。提出了一种适应性机制，根据声明的复杂度选择性地进行TTS，这使得TTS在计算效率提升1.8倍的同时，还比单一声明验证方法获得了显著的18.8%的性能改进。
### Conclusion
TTS有助于缓解推理漂移问题，显著提升了数值声明事实核查的性能。通过适应性机制的选择性TTS，使得在性能提升18.8%的同时，计算效率提升了1.8倍。
## 502. `cs.CL` - R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning [PDF](https://arxiv.org/pdf/2509.22131), [HTML](https://arxiv.org/abs/2509.22131)
### Authors
Hongyu Shan,Mingyang Song,Chang Dai,Di Liang,Han Chen
### Background
Chain-of-Thought (CoT) prompting有助于大型语言模型（LLMs）处理复杂推理，通过引发明确的逐步推理。然而，CoT的冗长增加了延迟和内存使用，并可能在长链中传播早期错误。论文背景讲述了现有CoT方法存在的问题，包括效率低下和透明度不足。
### Innovation
本文提出了一种名为Reasoning Capsule（R-Capsule）的新框架，它旨在结合隐式推理的效率和显式CoT的透明度。核心思想是将高层计划压缩成一组学习到的隐式令牌（Reasoning Capsule），同时保持执行步骤的轻量化或显式化。该框架基于信息瓶颈（IB）原则，通过低容量瓶颈促进简明性，并通过双重目标——主要任务损失和辅助计划重建损失——促进Sufficiency。重建目标有助于将潜空间接地，从而提高可解释性和减少无关捷径的使用。
### Conclusion
本文框架在高效性、准确性和可解释性之间达到了平衡，从而在复杂基准上减少了推理的可见标记足迹，并保持或提高了准确性。代码已在指定的URL处提供。
## 503. `cs.CL` - 通过监督分类模型与大语言模型紧密协作实现通用法律文章预测 [PDF](https://arxiv.org/pdf/2509.22119), [HTML](https://arxiv.org/abs/2509.22119)
### Authors
Xiao Chi,Wenlin Zhong,Yiquan Wu,Wei Wang,Kun Kuang,Fei Wu,Minghui Xiong
### Background
法律文章预测（LAP）是法律文本分类中的关键任务，通过自然语言处理（NLP）技术，根据案件的事实描述自动预测相关的法律文章。作为一个法律决策的基础步骤，LAP 在确定后续判决，如指控和处罚方面发挥着关键作用。尽管其重要性，现有的方法在处理LAP复杂性时面临巨大挑战。监督分类模型（SCMs）如CNN和BERT难以完全捕捉复杂的事实模式，而大型语言模型（LLMs）虽然在生成任务中表现出色，但在预测场景中因法律文章的抽象和ID性质表现不佳。此外，不同司法管辖区法律制度的多样性也加剧了这个问题，大多数方法都针对特定国家进行定制，缺乏广泛的适用性。
### Innovation
我们提出了Uni-LAP，一种结合SCMs和LLMs优势的通用法律文章预测框架。在Uni-LAP中，SCMs通过引入新的Top-K损失函数以生成准确的候选法律文章，而LLMs则借助基于三段论的推理方法来优化最终预测。Uni-LAP在多个司法管辖区的数据集上进行了评估，实验证明我们的方法在所有基线模型中表现最优，显示了其有效性和普适性。
### Conclusion
Uni-LAP通过监督分类模型与大语言模型的紧密协作，有效解决了法律文章预测中的局限性，实验证明其在多种法律系统中的优越性能，展示了其普适性和有效性。
## 504. `cs.CL` - RedNote-Vibe：用于捕获社交媒体中AI生成文本时间动态的数据集 [PDF](https://arxiv.org/pdf/2509.22055), [HTML](https://arxiv.org/abs/2509.22055)
### Authors
Yudong Li,Yufei Sun,Yuhan Yao,Peiru Yang,Wanyue Li,Jiajun Zou,Yongfeng Huang,Linlin Shen
### Background
大规模语言模型（LLMs）的普及导致了社交媒体平台上AI生成文本（AIGT）的广泛出现，带来了由用户参与驱动的内容动态，并随时间演进。现有数据集主要侧重于静态AIGT检测。
### Innovation
1. 引入了RedNote-Vibe，这是首个纵向五年跨度的社会媒体AIGT数据集，覆盖从LLM前期至2025年7月的数据，能够研究AIGT的时间动态和用户互动模式。2. 提出了心理学语言AIGT检测框架（PLAD），该框架利用心理学语言特征进行可解释的AIGT检测，展示了在社交媒体上下文中文本自动检测的优越性能，揭示了社会媒体互动与语言特征之间的复杂关系。
### Conclusion
实验表明PLAD在AIGT检测性能上优于其他方法，并提供了人类与AI生成内容差异特征的洞察，其数据集公开可获取。
## 505. `cs.CL` - 弥补草稿策略不匹配：批量树优化以支持推测性解码 [PDF](https://arxiv.org/pdf/2509.22134), [HTML](https://arxiv.org/abs/2509.22134)
### Authors
Shijing Hu,Jingyang Li,Zhihui Lu,Pan Zhou
### Background
现有的大型语言模型（LLM）推理加速方法通过使轻量级的草稿模型提出多个候选词，由目标模型并行验证。然而，现有的训练目标只优化单一的贪心草稿路径，而解码过程则通过树形策略重新排名和验证多个分支。这种草稿策略与解码时的树形策略不同步，限制了能够实现的加速效果。
### Innovation
该研究引入了组树优化（GTO），这是一种通过两种组件来对齐训练与解码时间树形策略的方法：(i) 草稿树奖励，一个无需采样的目标，即在目标模型下的草稿树预期接受长度，直接衡量解码性能；(ii) 基于组的草稿策略训练，这是一种稳定的优化方案，通过对比当前模型和冻结参考草稿模型的树形结构，形成去偏差组标准化优势，并沿最接受序列应用一种PPO风格的代理函数以确保稳健的更新。此外，研究证明增加草稿树奖励能提高接受长度和加速效果。
### Conclusion
GTO通过对齐训练和解码时间的树形策略，跨越多种对话（MT-Bench）、代码（HumanEval）和数学（GSM8K）任务，及多个LLM（例如，LLaMA-3.1-8B、LLaMA-3.3-70B、Vicuna-1.3-13B、DeepSeek-R1-Distill-LLaMA-8B），能够增加接受长度7.4%并额外提供7.7%的加速，从而提供了一种实用且通用的高效LLM推理解决方案.
## 506. `cs.CL` - 标准质量标准名称和定义的QCET分类法用于NLP系统的评估 [PDF](https://arxiv.org/pdf/2509.22064), [HTML](https://arxiv.org/abs/2509.22064)
### Authors
Anya Belz,Simon Mille,Craig Thomson
### Background
先前的工作表明，即使两个NLP评估实验报告的结果使用同一个质量标准名称（如流畅性），它们也未必评估同一方面的质量。这种命名暗示的可比性可能是误导性的。不知何时两个评估是可比的，这意味着目前在基于多个独立评估的一致结论方面缺乏能力。这阻碍了NLP领域整体的科学进步，自其诞生之初就是一个普遍问题（Sparck Jones, 1981）。如何完全解决不清晰的可比性问题，最可能的途径是创建一套标准的质量标准名称和定义，将实际在NLP领域使用的数百种质量标准名称映射并扎根其中。
### Innovation
QCET质量标准评价分类法通过三个关于NLP评估报告的调查，描述性地提出了一个标准的质量标准名称和定义集，并将其结构化为一个层次结构，每个父节点涵盖了子节点的共同特征。该分类法及其资源有三个主要用途：建立现有评估的可比性、指导新的评估设计以及评估监管合规性。
### Conclusion
QCET分类法及其资源有助于解决NLP中不清晰的可比性问题，通过提供明确的质量标准名称和定义，有助于评估的科学进展和监管合规性。
## 507. `cs.CL` - Fine-tuning Done Right in Model Editing [PDF](https://arxiv.org/pdf/2509.22072), [HTML](https://arxiv.org/abs/2509.22072)
### Authors
Wanli Yang,Fei Sun,Rui Tang,Hongyu Zang,Du Su,Qi Cao,Jingang Wang,Huawei Shen,Xueqi Cheng
### Background
传统的微调被认为是大语言模型适应的关键方法，并且长期被批评为在这种适配过程中无效。现有研究表明，这种评价主要源于将微调方法应用于连续的编辑任务时使用的单一深度优先管道，这种管道会在完全优化每个样本后再进行下一个样本的处理，这导致了对每个编辑的过度优化以及编辑间的干扰。进一步研究表明，微调在编辑任务中的不足还源于从先前方法继承而来的最优调节参数位置不尽合理的问题。
### Innovation
本研究通过恢复微调的基本框架，并将其重新整合到广度优先的分批优化（即，周期批量）管道中，显著提高了微调的有效性。此外，通过系统分析调节位置，提出了LocFT-BF，一种简单而有效的局部编辑方法。实验结果表明，相比于当前最佳方法，LocFT-BF在多种大语言模型和数据集上的性能显著提升，并且首次能够在不牺牲泛化能力的情况下进行大量编辑（高达10万次编辑和720亿参数模型），远超先前的实践水平。
### Conclusion
本研究澄清了长期存在的误导性假设，并提出了一个指导性的局部调优策略，使微调从一个被低估的基本方法转变为模型编辑的领先方法，为未来研究奠定坚实的基础。
## 508. `cs.CL` - Mixture of Detectors: 机器生成文本检测的一种紧凑视图 [PDF](https://arxiv.org/pdf/2509.22147), [HTML](https://arxiv.org/abs/2509.22147)
### Authors
Sai Teja Lekkala,Yadagiri Annepaka,Arun Kumar Challa,Samatha Reddy Machireddy,Partha Pakray,Chukhu Chunka
### Background
近年来，大型语言模型（LLMs）在创造力方面展现出超越人类的潜力，引发了关于人类原创性和创新性的质疑。本文探讨了机器生成文本检测的问题，并涵盖了多个场景，包括文档级别的二分类或多分类、生成器归属、句子层面的分割以及对抗攻击。
### Innovation
本文引入了一个新的数据集BMAS English，用于二分类和多分类机器生成文本的检测和生成器归属。此外，还提出了一种对抗攻击方法，旨在减轻检测难度，并提出了句子层面的分割方法，用于预测人类和机器生成文本的边界。
### Conclusion
本文从多个角度分析了机器生成文本检测的问题，并提出了一系列新的方法来改进现有工作的检测精度。这些新的方法将有助于更好地理解和保护人类的原创性和创新性。
## 509. `cs.CL` - COSPADI: 基于校准引导稀疏字典学习压缩大语言模型 [PDF](https://arxiv.org/pdf/2509.22075), [HTML](https://arxiv.org/abs/2509.22075)
### Authors
Dmitriy Shopkhoev,Denis Makhov,Magauiya Zhussip,Ammar Ali,Stamatios Lefkimmiatis
### Background
大语言模型（LLMs）的后训练压缩主要依赖于低秩权重近似，这种方法通过将权重矩阵的每一列表示在一个共享的低维子空间内来实现。尽管这是一种计算效率高的策略，但这种施加的结构约束是刚性的，可能会导致模型精度显著下降。
### Innovation
我们提出了CoSpaDi（基于稀疏字典学习的压缩），这是一种新型的无需训练的压缩框架，使用更灵活的结构稀疏分解代替低秩分解。该方法通过密集字典和列稀疏系数矩阵来表示权重矩阵，使其能够提供比不变基更好的表示能力。CoSpaDi通过利用一个小的校准数据集优化分解过程，使得压缩后的投影层输出激活值与原始层的非常接近，从而最小化功能重建误差，而不是简单的权重近似。这种基于数据的策略在合理的压缩比下能够更好地保持模型的准确性，且无需微调。此外，该方法产生的结构稀疏性允许高效的稀疏-密集矩阵乘法，并与后训练量化兼容，以进一步减少内存占用和延迟。
### Conclusion
我们在多个Llama和Qwen模型下评估了CoSpaDi在20-50%压缩比下的表现，结果显示它在准确性和困惑度上均优于最先进的基于数据的低秩方法。我们的研究结果证实了结构稀疏字典学习是传统低秩方法的有效替代方案，适用于高效的大语言模型部署。
## 510. `cs.CL` - 当推理在模型性能中起作用时？：推理对模型性能贡献的受控研究 [PDF](https://arxiv.org/pdf/2509.22193), [HTML](https://arxiv.org/abs/2509.22193)
### Authors
Nicolas Boizard,Hippolyte Gisserot-Boukhlef,Kevin El-Haddad,Céline Hudelot,Pierre Colombo
### Background
具有推理能力的大型语言模型（LLMs）在各种任务中取得了最先进的性能。尽管其实验性成功，但推理在哪些任务和模型规模下变得有效，以及其训练和推理成本仍然是一个未被深入研究的领域。
### Innovation
使用合成数据蒸馏框架进行大规模监督研究，对比指令微调（IFT）和不同大小的推理模型在数学中心和通用任务上的表现，评估选择题和开放式格式。研究发现推理始终能改善模型性能，常常与较大的指令微调系统相匹配或超越；同时，在训练和推理成本方面，指令微调仍然表现最优，但在模型规模增加时，推理模型逐渐显示出其价值，特别是在需要大量推理和开放式任务上超过了指令微调。
### Conclusion
推理始终提高模型性能，在特定任务和模型规模下其价值愈发显著。尽管指令微调在训练和推理成本上最优，但随着模型规模的扩大，推理模型变得更有价值，能够克服指令微调在推理密集型和开放性任务上的表现限制。
## 511. `cs.CL` - 多语言视觉语言模型：综述 [PDF](https://arxiv.org/pdf/2509.22123), [HTML](https://arxiv.org/abs/2509.22123)
### Authors
Andrei-Alexandru Manea,Jindřich Libovický
### Background
本文介绍了多语言视觉语言模型，这些模型能够跨语言处理文本和图像。文章回顾了31种模型和21种基准测试，涵盖编码器和生成架构。研究发现，在语言中立性（一致的跨语言表示）和文化意识（适应文化情境）之间存在关键矛盾。目前的训练方法倾向于通过对比学习促进中立性，而文化意识则依赖于多样化数据。大多数评价标准使用基于翻译的方法，强调语义一致性，尽管近期的工作已经开始融入了根据文化的素材。不过也发现多语言能力存在差异，以及训练目标与评估目标之间的差距。
### Innovation
文章详细回顾了现有的多语言视觉语言模型及其基准测试，发现了语言中立性和文化意识之间的矛盾，并讨论了目前训练方法和评价标准的局限性。最近的研究开始尝试将文化背景因素纳入模型训练中，虽然仍存在改进的空间。
### Conclusion
尽管多语言视觉语言模型在跨语言处理上取得了显著进展，但还存在语言中立性与文化意识之间的冲突、训练目标和评估目标之间的不匹配等问题。未来的工作需要平衡这两方面的需求，并提高模型在不同文化背景下的性能。
## 512. `cs.CL` - 使用对话行为脚本进行多语言对话生成与本地化 [PDF](https://arxiv.org/pdf/2509.22086), [HTML](https://arxiv.org/abs/2509.22086)
### Authors
Justin Vasselli,Eunike Andriani Kardinata,Yusuke Sakai,Taro Watanabe
### Background
非英语对话数据集稀缺，模型常常是基于英语对话的翻译进行训练或评估，这种方法可能会引入人工化的元素，降低了对话的自然性和文化适应性。现有的方法缺乏一种有效的多语言对话生成框架，尤其在文化适应性和语言自然度方面存在不足。现有技术主要依赖翻译直接生成目标语言的对话，这可能导致文化不合适和语言不自然的问题，限制了多语言对话的质量和适用性。为解决这些问题，本文提出了对话行为脚本（DAS），为多语言对话的编码、本地化和生成提供了一种结构化的框架，通过使用结构化的对话行为表示，DAS 支持在不同语言间的灵活本地化，降低了翻译的痕迹，使对话更加流畅自然。
### Innovation
本文提出了对话行为脚本（DAS），这是一种结构性的框架，用于编码、本地化和生成多语言对话，通过对对话意图的抽象表示，DAS 提供了一种跨文化适应的对话生成方法，其主要创新点在于：1. 使用结构化的对话行为表示，支持多语言对话的灵活本地化；2. 减少了翻译过程中可能会带来的语言不自然和文化不合适的问题，提升了对话的真实感；3. 通过系统方法生成符合目标语言文化和语境的对话，提高了多语言对话的质量。
### Conclusion
通过对意大利语、德语和汉语三种语言的人类评估，DAS 生成的对话在文化相关性、一致性以及情境适宜性方面均优于机器翻译和人工翻译的对话。DAS 为多语言对话生成提供了一种有效的结构化方法，有助于提高多语言对话的自然度和文化适应性。
## 513. `cs.CL` - S2J：在生成奖励模型中弥合解决与判断能力之间的鸿沟 [PDF](https://arxiv.org/pdf/2509.22099), [HTML](https://arxiv.org/abs/2509.22099)
### Authors
Shaoning Sun,Jiachen Yu,Zongqi Wang,Xuewei Yang,Tianle Gu,Yujiu Yang
### Background
随着大型语言模型（LLMs）的迅速发展，生成奖励模型（GRMs）被广泛应用于奖励建模和评估。以往的研究主要集中在通过优化偏好数据集来训练专门的GRMs，并以判断准确性作为监督。尽管普遍认为具有更强解决问题能力的GRMs通常表现出色，但研究发现，GRMs在评估某些查询时存在显著的解决到判断差距，即GRMs在能够解决的问题上依然难以做出正确判断（14%-37%）。
### Innovation
本文提出了一种名为S2J（Solve-to-Judge）的方法来解决这一问题。S2J方法在模型优化过程中同时利用GRM的解决能力和判断能力作为监督，明确地将GRM的问题解决能力和评价能力进行关联，从而缩小了差距。实验证明，S2J有效减少了解决到判断差距16.2%，提升了模型判断性能5.8%。此外，S2J在相同的基模上实现了最先进的（SOTA）性能，同时使用了较小的训练数据集，并通过自我进化实现了这一目标，无需依赖更强大的外部模型进行知识蒸馏。
### Conclusion
实验结果表明，S2J能够有效减小解决到判断差距，提升模型的判断性能，且在相同的基模上实现了最先进的性能，使用了较小的训练数据集。
## 514. `cs.CL` - 多种模式思考：复合推理如何在有限数据下提升大语言模型性能 [PDF](https://arxiv.org/pdf/2509.22224), [HTML](https://arxiv.org/abs/2509.22224)
### Authors
Zishan Ahmad,Saisubramaniam Gopalakrishnan
### Background
尽管大语言模型（LLMs）具有显著的能力，但它们依赖单一且主导性的推理范式，这限制了它们在解决复杂问题方面的表现，这些复杂问题需要多种认知策略。研究者提出了一种新的推理方法，即复合推理（CR），旨在使LLMs能够动态探索并组合多种推理风格（如演绎推理、归纳推理和溯因推理），从而提供更精细的解决问题方案。
### Innovation
该研究引入了一种名为复合推理（CR）的新方法，该方法能够使LLMs动态地探索和结合多种推理风格，如演绎、归纳和溯因推理，以提升复杂问题的解决能力。在科学和医学问题解答基准测试中，该方法的表现优于现有基线方法（如思维链条方法），并且在准确性、样本效率和令牌使用方面表现出色，同时能根据领域自适应地强调不同的推理风格。
### Conclusion
研究发现，通过培养内部推理风格的多样性，LLMs能够获得更稳健、更具适应性和更高效的解决问题能力。
## 515. `cs.CL` - FoodSEM：专门用于食品实体链接的大语言模型 [PDF](https://arxiv.org/pdf/2509.22125), [HTML](https://arxiv.org/abs/2509.22125)
### Authors
Ana Gjorgjevikj,Matej Martinc,Gjorgjina Cenikj,Sašo Džeroski,Barbara Koroušić Seljak,Tome Eftimov
### Background
当前的最先进的通用大型语言模型或自定义的领域特定模型/系统无法准确解决食品相关的实体链接（NEL）任务。FoodSEM是为了填补这一空白而提出的一种开源的、针对食品相关的大型语言模型。它能够在文本中找到并连接到食品相关的实体，并且能够链接到多个相关的食物知识库，如FoodOn、SNOMED-CT和汉萨德分类学中。
### Innovation
FoodSEM是首个针对食品领域的实体链接任务而专门训练的大语言模型。它通过指令-响应（IR）场景工作，能够实现超过98%的F1分数，比零样本、一次样本和少样本提示基准模型都有更好的表现。该论文还提供了关于食品的标注语料库，使模型能够更好地进行微调和评估，为食品领域的语义理解提供了有力的模型，同时也为未来基准测试提供了强有力的基线。
### Conclusion
通过提供食品标注语料库，并公开FoodSEM及其相关资源，该论文的主要贡献在于：(1) 发布了一个适合大语言模型微调/评估的食品标注语料库，(2) 推出了一个能够提高食品文本语义理解的稳健模型，(3) 为食品领域的实体链接任务提供了强有力的基础，便于未来的基准测试。
## 516. `cs.CL` - 基于组合适配器的上下文参数化 [PDF](https://arxiv.org/pdf/2509.22158), [HTML](https://arxiv.org/abs/2509.22158)
### Authors
Josip Jukić,Martin Tutek,Jan Šnajder
### Background
大语言模型（LLMs）通常通过上下文学习（ICL）或监督微调（SFT）轻松适应新任务。然而，这两种方法都有局限性：ICL在处理大量示例时效率低下，而SFT会增加训练开销并牺牲灵活性。直接将指令或示例从上下文映射到适配器参数是一种有吸引力的替代方案。尽管先前工作探索了基于单个输入上下文生成适配器的方法，但尚未考虑到整合多个信息片段的需求。
### Innovation
文章介绍了CompAs，这是一种元学习框架，可以将上下文信息以组合结构转换为适配器参数。通过这种方式生成的适配器可以进行代数合并，使得指令、示例或检索段落能够无缝组合，而无需重新处理长提示。这种方法具有三个优点：降低推理成本、对抗长上下文不稳定性、当输入超出模型上下文窗口时提供原则性的解决方案。此外，CompAs以可逆的方式将信息编码到适配器参数中，允许通过解码器恢复输入上下文，提高了安全性和隐私性。
### Conclusion
实验结果表明，CompAs在多种问答任务中优于上下文学习和以前基于生成器的方法，尤其是在多输入扩展时。我们的工作为LLM部署的可组合适配器生成提供了可行和有效的替代方案。
## 517. `cs.CL` - 大型语言模型的输出无意义 [PDF](https://arxiv.org/pdf/2509.22206), [HTML](https://arxiv.org/abs/2509.22206)
### Authors
Anandi Hattiangadi,Anders J. Schoubye
### Background
在这篇论文中，作者基于大型语言模型（LLMs）的输出是否具有实际意义的问题，提出了一个简明的论证方法。探讨了意图在语言模型输出中的作用，并讨论了为什么意图不明确会导致输出为空洞和无意义。
### Innovation
论文提出了一种简单的论证方式，指出某些类型的意图对于大型语言模型输出的字面意义是必要的，但大型语言模型本身缺乏这些意图，因此其输出是无意义的。此外，作者还反驳了一些反驳论点，如语义外部主义和语义内部主义。通过这种方式，论文提供了一个新颖的视角来讨论大型语言模型输出的意义问题。
### Conclusion
即使作者的论证是成立的，大型语言模型的输出似乎仍然是有意义的，并且能够帮助人们获得真实信念甚至知识。尽管模型本身输出无意义，但通过其他方式，这些输出仍然可以具有实际价值和意义。
## 518. `cs.CL` - NFDI4DS共享任务在学术文档处理中的应用 [PDF](https://arxiv.org/pdf/2509.22141), [HTML](https://arxiv.org/abs/2509.22141)
### Authors
Raia Abu Ahmad,Rana Abdulla,Tilahun Abedissa Taffa,Soeren Auer,Hamed Babaei Giglou,Ekaterina Borisova,Zongxiong Chen,Stefan Dietze,Jennifer DSouza,Mayra Elwes,Genet-Asefa Gesese,Shufan Jiang,Ekaterina Kutafina,Philipp Mayr,Georg Rehm,Sameer Sadruddin,Sonja Schimmler,Daniel Schneider,Kanishka Silva,Sharmila Upadhyaya,Ricardo Usbeck
### Background
共享任务是推动研究进展的强大工具，它们通过社区驱动的标准评估促进可获取、可访问、可互操作和可重用（FAIR）以及透明和可再现的研究实践。
### Innovation
十二个由德国国家级研究数据基础设施（NFDI4DS联盟）开发和主办的共享任务涵盖了学术文档处理的各种挑战，并在顶级会议中举办，促进了方法创新，提供了公开访问的数据集、模型和工具，供更广泛的研究社区使用，并整合到联盟的研究数据基础设施中。
### Conclusion
这些共享任务有助于提升学术文档处理领域的整体研究水平，促进知识的开放共享和研究的高效协作。
## 519. `cs.CL` - 从长到精: 基于多轮改进的性能感知和自适应链式思考压缩 [PDF](https://arxiv.org/pdf/2509.22144), [HTML](https://arxiv.org/abs/2509.22144)
### Authors
Jianzhi Yan,Le Liu,Youcheng Pan,Shiwei Chen,Zike Yuan,Yang Xiang,Buzhou Tang
### Background
链式思考（CoT）推理可以提高复杂任务的性能，但会由于冗长的推理过程导致显著的推理延迟。现有的CoT推理方法存在冗余，影响了推理效率和响应速度。
### Innovation
提出了多轮自适应链式思考压缩（MACC）框架，该框架利用token弹性现象，动态压缩CoT推理过程，通过多轮改进确定每个输入的最佳压缩深度，从而在提高准确率同时减少推理长度和显著降低延迟。此外，展示了使用可解释特征（如困惑度和压缩率）在训练集上预测测试时性能（准确率和token长度）的可能性，这种方法在不同模型上有效，且无需重复微调，证明了CoT压缩的可预测性与有效性。
### Conclusion
该方法不仅提高了准确率，还显著减少了CoT的长度，降低了延迟，证明了CoT压缩的可预测性和有效性，未来可以指导模型选择和性能预测，无需重复训练。
## 520. `cs.CL` - StableToken：一种稳健的抗噪语义语音分词器，用于增强的SpeechLLMs [PDF](https://arxiv.org/pdf/2509.22220), [HTML](https://arxiv.org/abs/2509.22220)
### Authors
Yuhan Song,Linhao Zhang,Chuhan Wu,Aiwei Liu,Wei Jia,Houfeng Wang,Xiao Zhou
### Background
现有的广泛使用的语义语音分词器虽然旨在捕捉语言内容，但对不相关于意义的声学扰动却非常脆弱。即使在高信噪比（SNR）下语音能够完美理解的情况下，其输出的分词序列也会发生剧烈变化，从而增加下游大型语言模型（LLMs）的学习负担。这种不稳定源于两个缺陷：单一路径的脆弱量化架构和忽视中间分词稳定性的遥距训练信号。
### Innovation
本文引入了StableToken，这是一种通过共识驱动机制实现稳定性的分词器。其多分支架构并行处理音频，并通过强大的位级投票机制将这些表示合并成一个稳定的分词序列。StableToken在不同噪声条件下的单位编辑距离（UED）稳定性方面树立了一个新的基准，显著减少了噪声的影响。这种基础的稳定性直接转化为下游任务的改进，显著增强了SpeechLLMs的鲁棒性。
### Conclusion
StableToken通过其多分支并行处理和位级投票机制实现了分词的稳定性，使得在各种噪声条件下单位编辑距离显著降低，从而为下游的大规模语音语言模型（SpeechLLMs）提供了更稳健的基础。
## 521. `cs.CL` - 通过LLMs构建可解释主题树：基于问题的数据分析与合成 [PDF](https://arxiv.org/pdf/2509.22211), [HTML](https://arxiv.org/abs/2509.22211)
### Authors
Tiago Fernandes Tavares
### Background
无监督文本语料库分析在数据稀缺领域尤其具有挑战性，传统主题模型往往不足以描述这些领域的数据。这些模型生成的主题通常依赖于关键词列表，缺乏语义连贯性，需要大量的人工解释。因此，对于如何实现模型输出的解释性，这是一个关键问题。本文探讨了这一背景下的问题，并提出了一种解决方案。
### Innovation
本文提出了递归主题划分（RTP）框架，该框架利用大型语言模型（LLMs）交互式构建一个二叉树。每个树节点是自然语言生成的问题，这些问题能够语义化地划分数据，使得每一个主题分支的逻辑都清晰可解。我们研究了与一个强大的基准模型（如BERTopic）相比，RTP 的主题层级结构更加可解释。进一步地，通过实验证明了这些主题在下游分类任务中的强特征作用，特别是在数据主题与任务标签相关时，更是表现出色。此外，RTP 还能用于指导生成模型的生成路径，使得结果更具可控性。这不仅扩展了数据分析的范式，还提升了生成模型的合成能力。
### Conclusion
RTP 向我们展示了一种新的数据探索范式，从统计模式发现转向知识驱动的主题分析。基于RTP生成的主题路径能够作为一种结构化、可控的提示用于生成模型，这使得RTP成为一个强大的合成工具，能够一致地模仿原始语料库中的特定特征。
## 522. `cs.CL` - In Their Own Words: 小型模型定制化的推理痕迹使它们成为更好的推理者 [PDF](https://arxiv.org/pdf/2509.22230), [HTML](https://arxiv.org/abs/2509.22230)
### Authors
Jaehoon Kim,Kwangwook Seo,Dongha Lee
### Background
将较大的语言模型的推理能力传递给较小模型时，通过监督微调进行的能力转移往往会出乎意料地失败，即使具有高质量的教师演示，性能也会下降。研究人员发现，这种失败源自分布错配：较大模型的推理路径包含小模型概率分布下低概率的令牌，超过了较小架构的内部表示能力，反而成为学习障碍而非帮助指导。
### Innovation
本文提出了一种称为反推推测解码（RSD）的机制，该机制生成易于学生理解的推理路径，在教师模型提出候选令牌的情况下，学生模型根据自己的概率分布确定接受与否，过滤掉低概率令牌。实验表明，当应用于Qwen3-0.6B时，直接从s1K-1.1推理痕迹数据中进行知识蒸馏会导致主要推理基准平均性能下降20.5%，而使用RSD生成的推理痕迹进行训练则实现了令人满意的4.9%的改进。研究表明，低概率令牌构成了推理能力传递的关键瓶颈，但跨模型实验表明RSD痕迹是针对特定模型架构定制的，而非普遍适用的，因此分布对齐必须针对每个学生架构的独特内部表示进行定制化调整。
### Conclusion
研究揭示，低概率令牌是推理能力传递的关键瓶颈。通过RSD生成的推理痕迹可以显著提升小型模型的推理能力。但RSD产生的推理痕迹具有模型特定性，不同模型需要不同定制的分布对齐策略。
## 523. `cs.CL` - The InviTE Corpus: Tudor英语文本中的 Invective 注释以进行计算建模 [PDF](https://arxiv.org/pdf/2509.22345), [HTML](https://arxiv.org/abs/2509.22345)
### Authors
Sophie Spliethoff,Sanne Hoeken,Silke Schwandt,Sina Zarrieß,Özge Alaçam
### Background
本文旨在将自然语言处理（NLP）技术应用于历史研究领域，特别是针对英国都铎王朝时期宗教贬损语言的研究。通过从原始数据到预处理、数据选择，再到迭代注释过程的工作流程，构建了InviTE语料库——一个包含近2000句16世纪早期现代英语句子的语料库，注释了与英格兰全国范围内的贬损语言相关的信息。
### Innovation
本文的创新之处在于通过注释和对比训练过的BERT模型和零样本提示指令调优的大语言模型（LLMs）的表现，证明了预训练在历史数据上的模型在贬损检测中的优越性。
### Conclusion
本文引入了InviTE语料库，并评估了不同模型在贬损检测上的性能，结果显示预训练的历史数据模型更有优势。这为未来利用NLP技术进一步研究文本中的谈判和仇恨言论提供了基础。
## 524. `cs.CL` - 会话 implicatures : 将相关性理论概率化建模 [PDF](https://arxiv.org/pdf/2509.22354), [HTML](https://arxiv.org/abs/2509.22354)
### Authors
Christoph Unger,Hendrik Buschmeier
### Background
近年来，贝叶斯概率理论在认知科学中的应用与新一代计算工具和方法的发展相结合，导致了一场‘概率转向’。理性言语行为理论框架被开发出来，用贝叶斯方法建模广义葛尔岑的会话行为现象，从相对简单的引用游戏扩展到更复杂的交流互动，如言语演绎推理。本文探讨贝叶斯方法如何在相关性理论（Sperber & Wilson, 1995）中应用到会话隐含意义的研究。
### Innovation
本文探索了贝叶斯方法在相关性理论中的应用，特别是对会话隐含意义的建模，这是一类典型的会话行为。通过研究贝叶斯方法来处理这种会话隐含意义，填补了传统相关性理论在这方面的空白。
### Conclusion
本文提出了一种用概率模型来研究会话隐含意义的方法，并展示了贝叶斯推理在理解会话行为中的潜力。未来的工作可以进一步细化和深化这种模型，以便更好地理解和预测人们的会话行为。
## 525. `cs.CL` - FeatBench：用于Vibe编码特征实现的评估基准 [PDF](https://arxiv.org/pdf/2509.22237), [HTML](https://arxiv.org/abs/2509.22237)
### Authors
Haorui Chen,Chengze Li,Jia Li
### Background
随着大型语言模型（LLMs）的迅速发展，出现了一种新的软件开发范式“vibe编码”，用户可以通过高级自然语言与编码代理交互。然而，现有的代码生成评估标准未能充分评估代理在vibe编码中的能力。现有基准主要关注代码级别的规范要求或专注于问题解决，而忽略了在vibe编码范式中的功能实现这一关键场景。为填补这一空白，本文提出了一个新型基准FeatBench，专门用于评估功能实现的能力。
### Innovation
FeatBench具有四个关键特点：1. 纯自然语言提示。任务输入完全是抽象的自然语言描述，不含任何代码或结构提示；2. 严格且不断进化的数据收集过程。利用多级过滤管道确保数据质量，并通过自动演化管道避免数据污染；3. 全面的测试用例。每个任务包括失败转成功（F2P）和成功转成功（P2P）测试，以验证正确性并防止回退；4. 多样化的应用领域。基准涵盖了来自不同领域的仓库，确保其反映现实世界场景；评价最新的两个代理框架和四个主流LLMs，结果显示出功能实现的挑战，成功率为29.94%；揭示了一种“激进的实现”策略导致了关键失败和优秀软件设计之间的悖论性现象；
### Conclusion
本文发布FeatBench，自动收集流程和所有实验结果，以促进进一步的研究。
## 526. `cs.CL` - FLEXI：全双工人类-大语言模型语音交互基准 [PDF](https://arxiv.org/pdf/2509.22243), [HTML](https://arxiv.org/abs/2509.22243)
### Authors
Yuan Ge,Saihan Chen,Jingqi Xiao,Xiaoqian Liu,Tong Xiao,Yan Xiang,Zhengtao Yu,Jingbo Zhu
### Background
全双工大语言模型（LLMs）是自然人类-计算机交互的基础，能够实现实时语音对话系统。但目前这些模型的基准测试和建模依然存在根本性的挑战。现有的研究主要集中在单向的交互模式，而对于同时进行的双向交互（即全双工模式）的模型性能评估仍然不足，特别是在应对紧急情况时的具体性能差异尚未得到明确揭示。
### Innovation
首次引入了FLEXI基准测试，专为评估全双工LLM-人语音交互设计，特别是在紧急场景下加入了模型中断的考量。FLEXI通过六个不同的交互场景系统性地评估了实时对话的时延、质量和交互有效性，揭示了来源公开与商业LLM在紧急情况意识、换气终止和交互时延方面的显著差异。
### Conclusion
研究建议未来可以通过下一步的令牌对预测来实现真正无缝且人类似的全双工交互。
## 527. `cs.CL` - 安全合规：通过合规视角重思大语言模型安全性推理 [PDF](https://arxiv.org/pdf/2509.22250), [HTML](https://arxiv.org/abs/2509.22250)
### Authors
Wenbin Hu,Huihao Jing,Haochen Shi,Haoran Li,Yangqiu Song
### Background
大语言模型（LLMs）的快速增长展示了其非凡的能力，增强了LLM安全性的关键重要性。然而，现有的安全性方法依赖于非系统的分类方法，未能为现代LLM系统的复杂行为提供严格、系统的保护。因此，当前方法无法确保安全。针对这一问题，本文从法律合规的角度解决LLM安全性，提出了安全合规的概念。本文以欧盟AI法案和GDPR等核心法律框架为依据，为定义和度量安全合规提供标准。
### Innovation
本文首创了一个新的安全合规基准，通过生成结合法律条款的现实LLM安全场景。此外，作者利用群体策略优化（GRPO）对Qwen3-8B模型进行对齐，构建了一个合规推理器，即合规遵守器（Compliance Reasoner），它使LLM与法律标准更加一致，从而减少安全性风险。
### Conclusion
全面的实验表明，合规遵守器在欧盟AI法案和GDPR的新基准上表现优异，平均改进分别为+10.45%和+11.85%。
## 528. `cs.CL` - Transformers Can Learn Connectivity in Some Graphs but Not Others [PDF](https://arxiv.org/pdf/2509.22343), [HTML](https://arxiv.org/abs/2509.22343)
### Authors
Amit Roy,Abulhair Saparov
### Background
考察变压器型大语言模型（LLMs）的演绎推理能力对于保证其回复的真实性至关重要，特别是在因果推断等场景中，推理传递关系的能力尤为重要。此前的研究主要关注变压器能否通过输入上下文示例学习获取传递关系，但尚未探讨变压器通过训练示例学习传递关系的能力及其随模型规模扩展的情况。
### Innovation
本研究通过生成不同大小的有向图来训练不同规模的变压器模型，并评估其在各种图规模下推断传递关系的能力，发现变压器能够学习‘网格状’有向图中的连通性，这类图中每个节点可以嵌入到低维度空间中且连通性可以直接从节点的嵌入推断。研究还发现，底层网格图的维度是影响变压器学习连通性任务能力的关键因素，高维度网格图比低维度网格图更难学习。此外，增加模型规模有助于在网格图上更好地推断连通性，但在图不是网格图且包含大量不连通部分时，变压器难以学习连通性。
### Conclusion
变压器在‘网格状’有向图中能够学习推断连通性，但在网格图不具特质的复杂图上则难以掌握连通性任务。规模较大的变压器模型在推断网格图连通性方面表现出更好的泛化能力。
## 529. `cs.CL` - 公平与解释性的桥梁：基于输入的解释能否促进仇恨言论检测的公平性？ [PDF](https://arxiv.org/pdf/2509.22291), [HTML](https://arxiv.org/abs/2509.22291)
### Authors
Yifan Wang,Mayank Jobanputra,Ji-Ung Lee,Soyoung Oh,Isabel Valera,Vera Demberg
### Background
自然语言处理（NLP）模型常常复制或放大训练数据中的社会偏见，这引起了关于公平性的担忧。同时，这些模型的黑箱性质使得用户难以识别有偏见的预测，开发人员也难以有效缓解这些问题。尽管一些研究表明基于输入的解释有助于检测和缓解偏见，但其他研究对其确保公平性的可靠性提出了质疑。关于公平的NLP解释性研究主要集中在定性分析上，缺乏大规模的定量分析。
### Innovation
本文首次系统地研究了解释性与公平性之间的关系，特别是在仇恨言论检测中，聚焦于编码器-解码器和解码器仅模型。我们考察了三个关键维度：（1）识别偏见预测；（2）选择公平模型；（3）在模型训练期间缓解偏见。我们发现，基于输入的解释可以有效检测偏见预测，并作为减少训练期间偏见的有用监督，但它们对于在候选模型中选择公平模型可靠性不足。
### Conclusion
基于输入的解释可以在检测和缓解仇恨言论检测中的偏见方面发挥作用，但它们对于选择公平模型的有效性有限。
## 530. `cs.CL` - 探索解决方案的多样性及其对大语言模型问题解决的影响 [PDF](https://arxiv.org/pdf/2509.22480), [HTML](https://arxiv.org/abs/2509.22480)
### Authors
Hang Li,Kaiqi Yang,Yucheng Chu,Hui Liu,Jiliang Tang
### Background
大语言模型（LLMs）在解决问题任务方面得到了广泛应用。最近的研究主要通过有标签数据的监督微调（SFT）或来自任务反馈的强化学习（RL）来提升其性能。本文探讨了一个新的视角：单一问题下由LLMs生成的不同解决方案之间的差异性。
### Innovation
发现较高的解决方案差异性与更好的问题解决能力相关，基于这一发现，提出解决方案差异性作为一种新的度量标准，可支持SFT和RL策略。在三个代表性的问题领域中进行测试，发现使用解决方案差异性可以一致地提高解决问题的成功率。
### Conclusion
结果表明，解决方案差异性是一个简单而有效的工具，有助于提升LLMs的训练和评估。
## 531. `cs.CL` - 使用微调LLM将自然语言提升到一阶逻辑 [PDF](https://arxiv.org/pdf/2509.22338), [HTML](https://arxiv.org/abs/2509.22338)
### Authors
Felix Vossel,Till Mossakowski,Björn Gehrke
### Background
一阶逻辑（FOL）的自然语言自动化转换对知识表示和形式方法至关重要，但仍然具有挑战性。本文基于MALLS和Willow数据集，系统评估了微调的语言模型在这一任务上的表现，比较了编码解码器架构与仅解码器架构，以及不同的训练策略。研究表明，通过词汇扩展、谓词条件和多语言训练等技术，可以提升模型的转换准确性。结构逻辑转换的稳定性需要进一步探索，但谓词提取成为主要瓶颈。
### Innovation
本文展示了微调后的LLM在自然语言到一阶逻辑转换任务上的表现，对比了不同的架构和训练策略，并引入了精确匹配、逻辑等价和谓词对齐的评估指标。具体创新在于通过词汇扩展、谓词条件和多语言训练等技术提升了模型的转换准确性，尤其是在谓词可用性的提升方面尤为显著，同时T5模型超过了较大的仅解码器LLM，且能够在未见的逻辑论证数据集上进行泛化。
### Conclusion
研究表明：（1）谓词可用性提升了15-20%的性能；（2）T5模型超越了更大的仅解码器LLM；（3）模型在未见过的逻辑论点（FOLIO数据集）上也具有良好的泛化能力。尽管结构逻辑转换表现稳健，但谓词提取成为主要瓶颈。
## 532. `cs.CL` - JGU Mainz的提交：WMT25针对斯拉夫语言的有限资源大模型的MT和QA [PDF](https://arxiv.org/pdf/2509.22490), [HTML](https://arxiv.org/abs/2509.22490)
### Authors
Hossain Shaikh Saadi,Minh Duc Bui,Mario Sanz-Guerrero,Katharina von der Wense
### Background
该论文介绍了JGU Mainz在WMT25共享任务上对斯拉夫语言进行机器翻译和问答的提交，特别关注乌克兰语、上西里西亚语和下西里西亚语。任务旨在使用有限资源的大语言模型进行任务。
### Innovation
论文提出的方法包括：针对每种语言联合微调Qwen2.5-3B-Instruct模型，使用参数高效微调方法；集成额外的翻译和多项选择问答数据；对于乌克兰语问答使用检索增强生成；对上西里西亚语和下西里西亚语的问答应用集成方法。
### Conclusion
实验表明，我们所提出的模型在两个任务上的表现均优于基线模型。
## 533. `cs.CL` - 超越文本上下文：实现适应性空间对齐的结构图编码以缓解LLMs的幻觉问题 [PDF](https://arxiv.org/pdf/2509.22251), [HTML](https://arxiv.org/abs/2509.22251)
### Authors
Yifang Zhang,Pengfei Duan,Yiwen Yang,Shengwu Xiong
### Background
目前，大型语言模型（LLMs）处理幻觉问题的主要方法是引入知识图谱（KGs），但LLMs通常将KGs视为普通文本，仅提取其语义信息而忽视了其关键结构方面。此外，KGs编码器的嵌入空间与LLMs文本嵌入之间的差距妨碍了结构化知识的有效整合。针对这些挑战，本文提出了一种创新的模型架构SSKG-LLM，旨在高效地将KGs的结构和语义信息整合到LLMs的推理过程中。SSKG-LLM通过知识图谱检索（KGR）模块和知识图谱编码（KGE）模块来保存语义并利用结构，并通过知识图谱适应（KGA）模块使LLMs理解KGs的嵌入。
### Innovation
本文提出了SSKG-LLM，这是一种创新的模型架构，旨在高效地将KGs的结构和语义信息整合到LLMs的推理过程中。SSKG-LLM通过知识图谱检索（KGR）模块和知识图谱编码（KGE）模块来保存语义信息并利用结构特征，通过知识图谱适应（KGA）模块使LLMs能够理解KGs的嵌入。这项工作解决了KBs和LLMs在嵌入空间方面的不匹配问题，并提升了LLMs的事实推理能力。
### Conclusion
通过对包含KGs结构信息的广泛实验，本文详细分析了如何利用KGs的结构信息来增强LLMs的推理能力。源代码已发布在[该链接]()，供进一步研究使用。
## 534. `cs.CL` - 在大型语言模型中使用线性方向检测（不）可回答性 [PDF](https://arxiv.org/pdf/2509.22449), [HTML](https://arxiv.org/abs/2509.22449)
### Authors
Maor Juliet Lavi,Tova Milo,Mor Geva
### Background
大语言模型在回应问题时常常表现出自信，甚至在缺乏必要信息的情况下，可能会给出错误的答案，即幻觉。本文研究了（不）可回答性检测的问题，特别是在需要从给定段落中提取足够信息来回答问题的提取式问题回答（QA）模型中。
### Innovation
提出了一种简单的方法来识别模型激活空间中的一个方向，用于捕捉不可回答性，并用于分类。通过在推理过程中应用激活添加，并测量其对模型弃答行为的影响来选择这个方向。结果显示，将隐藏的激活投影到该方向可获得可靠的（不）可回答性分类评分。通过两个开放权重的大型语言模型和四个提取式QA基准数据集的实验表明，该方法有效地检测了不可回答性的问题，并且在数据集中泛化能力优于现有的基于提示和基于分类器的方法。此外，获得的这些方向不仅适用于提取式QA，还适用于由缺乏科学共识和主观性等原因导致的不可回答性。
### Conclusion
因果干预展示了通过添加或删除这些方向有效控制模型弃答行为的能力。
## 535. `cs.CL` - InfiR2: 一种增强推理能力的语言模型的全面FP8训练食谱 [PDF](https://arxiv.org/pdf/2509.22536), [HTML](https://arxiv.org/abs/2509.22536)
### Authors
Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Yuan Xie,Hongxia Yang
### Background
大规模语言模型（LLMs）的训练计算成本极高，成为创新的瓶颈。虽然FP8训练因其理论上的效率优势提供了解决方案，但由于缺乏全面的开源训练方法，其广泛应用受到了阻碍。
### Innovation
本文提出了一种端到端的FP8训练方法，该方法将连续前向训练和监督微调无缝集成。通过采用细粒度和混合粒度的量化策略来保持数值保真度的同时最大化计算效率。通过广泛的实验，包括在一个160亿标记的语料库上继续前向训练，证明该方法不仅稳定性极佳，而且效果几乎无损失，与BF16基线在一系列推理基准上的性能相当。此外，这种方法实现了高达22%的训练时间减少、14%的峰值内存消耗减少以及19%的吞吐量提升。
### Conclusion
本文的结果确立了FP8作为BF16的实用且稳健的替代方案的地位，并将公布相应的代码，进一步促进大规模模型训练的民主化。
## 536. `cs.CL` - 通过认知推理进行社交思考 [PDF](https://arxiv.org/pdf/2509.22546), [HTML](https://arxiv.org/abs/2509.22546)
### Authors
Jinfeng Zhou,Zheyu Chen,Shuai Wang,Quanyu Dai,Zhenhua Dong,Hongning Wang,Minlie Huang
### Background
现有的大型语言模型（LLMs）在逻辑推理方面表现出色，能够进行步骤推理以获得可验证的答案。但是，它们在这种推理方式无法有效地处理社交情境，因为这些情境需要分析模糊的线索，并且很少有明确的结果。这就要求有一个新的方法来弥补这一点。
### Innovation
本文提出了一种“认知推理”范式，模拟人类的社会认知过程。同时，还提出了CogFlow框架，这是一种全面的框架，能够将这种能力植入到LLMs中。CogFlow通过基于树结构规划的方法收集认知流程数据，并通过监督微调和强化学习来提升模型的社交认知能力。
### Conclusion
广泛的实验表明，CogFlow可以有效增强LLMs乃至人类的社交认知能力，从而提高社交决策的有效性。
## 537. `cs.CL` - 使用LLMs进行细粒度的上下文相关幻觉检测 [PDF](https://arxiv.org/pdf/2509.22582), [HTML](https://arxiv.org/abs/2509.22582)
### Authors
Yehonatan Pesiakhovsky,Zorik Gekhman,Yosi Mass,Liat Ein-Dor,Roi Reichart
### Background
context-grounded hallucinations是指模型输出包含无法验证源文本的内容。研究了LLMs在本地化此类幻觉方面的应用，作为现有复杂评估管道的更实用替代方案。由于缺乏针对幻觉定位元评估的标准基准，构建了一个针对LLMs的自定义基准，涉及对1000多个示例的具有挑战性的人工注释。提出了新的以自由文本描述为基础的幻觉表示方法，以表达更多的错误类型。通过综合评估四种大规模的LLMs，展示了基准的难度。
### Innovation
提出了一个针对LLMs的自定义基准，包括1000多个具有挑战性的人工注释。提出了自由文本描述为基础的新幻觉表示方法。通过深入分析，提出了针对任务的最佳提示策略，并识别了使LLMs难以处理的主要因素：（1）倾向于错误地将缺失细节标记为不一致，尽管仅被指示检查输出内容的事实；（2）难以处理包含与源文本不符但具有事实正确信息的输出，这使得幻觉无法验证，且与模型的参数化知识存在偏差。
### Conclusion
综合评估的四种大规模的LLMs显示，基准的难度很大，最好的模型的F1分为0.67。通过仔细分析，提出了任务的最佳提醒策略，并确定了对于LLMs来说这项任务的主要挑战因素。
## 538. `cs.CL` - 使用大型语言模型探索风力发电机组维护日志的语义可靠性分析 [PDF](https://arxiv.org/pdf/2509.22366), [HTML](https://arxiv.org/abs/2509.22366)
### Authors
Max Malyi,Jonathan Shek,Andre Biscaya
### Background
风力发电机组维护日志中蕴含了大量的操作智能信息，但由于这些信息主要以非结构化的自由文本形式存在，传统定量可靠性分析难以访问这些资源。尽管机器学习已被应用于此数据，但现有方法通常仅限于分类任务，即将文本归类为预定义标签。本研究填补了利用现代大语言模型（LLMs）进行更复杂推理任务这一空白，旨在通过LLMs进行深度语义分析，超越分类，执行故障模式识别、因果链推理、比较站点分析和数据质量审计等分析工作流。
### Innovation
提出了一个探索性框架，利用大语言模型进行更复杂的语义分析，而不仅仅是分类。该框架在大型工业数据集上执行四种分析工作流：故障模式识别、因果链推理、比较站点分析和数据质量审计。结果显示，大语言模型可以作为强大的“可靠性副驾驶”，不仅能进行标签工作，还能综合文本信息、生成可操作的专家级假说。这项工作为使用大语言模型作为一种推理工具贡献了一个新颖且可重复的方法，提供了提高风能行业操作智能的途径，以揭示隐藏在非结构化数据中的洞察力。
### Conclusion
本文提出了一种利用大语言模型作为推理工具的新颖且可重复的方法，执行分析工作流，提升风能行业的操作智能，展示了大语言模型在处理非结构化数据中的潜力。
## 539. `cs.CL` - LLMs在预训练和后训练数据中的政治内容是什么？ [PDF](https://arxiv.org/pdf/2509.22367), [HTML](https://arxiv.org/abs/2509.22367)
### Authors
Tanise Ceron,Dmitry Nikolaev,Dominik Stammbach,Debora Nozza
### Background
大型语言模型（LLMs）已知会产生政治偏见的文本，但这些偏见是如何产生的仍然不清楚。当前的LLM研究对训练数据中的政治内容探索不足。文章通过对OLMO2模型及其完整数据集的预训练和后训练语料库进行分析，揭示了训练数据中政治内容的影响以及模型在特定政策问题上的立场关系。
### Innovation
本文的研究创新在于系统地分析了开放源代码模型OLMO2的预训练和后训练数据集，抽取大量随机样本并自动标注文档的政治倾向，然后分析数据来源和内容，考察训练数据中政治内容与模型在特定政策问题上立场的相关性。文章揭示了训练数据的政治内容对模型偏见的影响，强调了政治内容分析在未来的数据编目流程中不可或缺的重要性，并要求提供详细的过滤策略以增加透明度。
### Conclusion
研究发现，左倾文档在数据集中占主导地位，预训练语料库中涉及政治参与的内容显著多于后训练数据。左倾和右倾文档通过不同价值观和合法性来源来处理相似的话题。更重要的是，训练数据中的主导立场强烈地与模型在政策问题上的政治偏见相关联。这些发现突显了在未来的数据编目流程中整合政治内容分析以及提供详细的过滤策略文档的必要性。
## 540. `cs.CL` - ArabJobs: 一个多国阿拉伯求职广告语料库 [PDF](https://arxiv.org/pdf/2509.22589), [HTML](https://arxiv.org/abs/2509.22589)
### Authors
Mo El-Haj
### Background
ArabJobs 是一个从埃及、约旦、沙特阿拉伯和阿拉伯联合酋长国公开收集的阿拉伯语求职广告语料库。该数据集包含超过 8,500 条广告和超过 550,000 字，涵盖了阿拉伯劳动力市场的语言、地域和经济多样性。
### Innovation
论文通过对性别代表性和职业结构的分析，展示了数据集在阿拉伯语 NLP 和劳动力市场研究中的公平意识应用。此外，还演示了使用大规模语言模型进行薪资估算、职位分类以及性别偏见检测和职业分类基准任务的应用。
### Conclusion
ArabJobs 数据集对于公平的阿拉伯语自然语言处理和劳动力市场研究具有重要意义。该数据集已公开发布在 GitHub 上。
## 541. `cs.CL` - CHRONOBERG：捕捉基础模型中的语言演变和时间意识 [PDF](https://arxiv.org/pdf/2509.22360), [HTML](https://arxiv.org/abs/2509.22360)
### Authors
Niharika Hegde,Subarnaduti Paul,Lars Joel-Frey,Manuel Brack,Kristian Kersting,Martin Mundt,Patrick Schramowski
### Background
现有的大型语言模型（LLMs）能够通过利用社交媒体和从网络上抓取的多种数据进行大规模操作。虽然现有的语料库多样性高，但它们常常缺乏长期的时间结构，这限制了LLMs对语言语义和规范性演变的上下文理解能力以及对历时变化的捕捉能力。为了支持分析和训练，本文介绍了CHRONOBERG，这是一个从1770年到2020年跨越250年涵盖英语书籍文本的有时间结构的语料库，并丰富了各种时间标注。
### Innovation
CHRONOBERG的独特之处在于它的时间结构特点，这使得能够在时间敏感的情感唤醒-激活性-支配性（VAD）分析中衡量词汇语义的变化，并构建历史校准的情绪词典以支持时间相关的解释。此外，本文展示了现代基于LLM的工具需要更好地将歧视性语言的检测和情感在不同时间段内的上下文化相结合，表明了对时间意识的训练和评估管道的需求，并将CHRONOBERG定位为研究语言变革和时间泛化的可扩展资源。
### Conclusion
基于CHRONOBERG训练的语言模型在编码历时意义的变化方面存在困难，强调了时间意识的训练和评估管道的需求。CHRONOBERG被定位为研究语言变化和时间泛化的可扩展资源，并且其开放访问可以使公众使用，代码可以在提供。
## 542. `cs.CL` - NeLLCom-Lex: 一个研究词汇系统与语言使用之间相互作用的神经代理框架 [PDF](https://arxiv.org/pdf/2509.22479), [HTML](https://arxiv.org/abs/2509.22479)
### Authors
Yuqing Zhang,Ecesu Ürker,Tessa Verhoef,Gemma Boleda,Arianna Bisazza
### Background
词汇意义的变化主要通过观察和实验方法进行研究，但是观察性方法（如语料库分析、分布式语义建模）无法揭示因果机制，而涉及长期历时过程的人类实验范式也难以应用到词汇意义的变化研究中。鉴于此，本文提出了一个名为NeLLCom-Lex的神经代理框架，旨在通过首先将代理接地于真实词汇系统（例如英语），然后系统地改变他们的交流需求来模拟词汇意义的变化。通过使用现有的颜色命名任务，模拟单一代谢中的词汇系统的进化，并研究导致代理：(i) 发展类似人类的命名行为和词典，以及 (ii) 根据其交流需求改变其行为和词典的因素。不同的监督和强化学习管道实验表明，接受训练以“说”现有语言的神经代理能够很大程度上再现类似人类的颜色命名模式，支持进一步使用NeLLCom-Lex来揭示词汇变化的机制。
### Innovation
提出了NeLLCom-Lex框架来模拟词汇意义的变化；通过使用监督学习和强化学习管道，显示出神经代理可以复制类似人类的语言使用模式；提供了研究词汇变化机制的新方法。
### Conclusion
神经代理NeLLCom-Lex可以在单一代代谢中模拟词汇系统的进化，并可以根据交流需求学习和改变词汇体系，表明这种方法适用于研究词汇变化的机制。
## 543. `cs.CL` - 通过基于频率的量子深度学习方法捕获协商性话语中的意见转变 [PDF](https://arxiv.org/pdf/2509.22603), [HTML](https://arxiv.org/abs/2509.22603)
### Authors
Rakesh Thakur,Harsh Chaturvedi,Ruqayya Shah,Janvi Chauhan,Ayush Sharma
### Background
协商过程在形成决策结果中起着关键作用，涉及综合多样化的观点。最近在自然语言处理（NLP）领域的进展使得通过分析意见转变并预测在不同情境下的潜在结果来计算建模协商成为可能。本研究基于多样背景的个体意见，使用富含惊人事实的产品演示模拟了协商过程，导致观众意见的可测量变化。我们对比分析了两种模型：基于频率的对话调节模型和量子协商框架，表明其优于现有最先进的模型。
### Innovation
本研究通过使用含有惊人事实的产品演示来模拟协商过程，促使观众意见发生变化。我们开发了基于频率的对话调节模型和量子协商框架两个模型进行比较分析，这两个模型在处理协商性话语的意见转变方面表现出色，且优于现有的最先进模型。
### Conclusion
研究发现展示了其在公共政策制定、辩论评估、决策支持框架以及大规模社交媒体意见挖掘中的实际应用潜力。
## 544. `cs.CL` - 在提示语义任务空间中表示LLMs [PDF](https://arxiv.org/pdf/2509.22506), [HTML](https://arxiv.org/abs/2509.22506)
### Authors
Idan Kashani,Avi Mendelson,Yaniv Nemcovsky
### Background
大型语言模型（LLMs）在各种任务中取得了令人印象深刻的结果，而不断扩大的公共存储库中包含了大量的预训练模型。因此，为给定任务识别最佳性能的LLM是一个重大挑战。先前的研究建议通过学习LLM表示来解决这个问题。然而，这些方法在扩展性和成本效率方面存在局限性，需要重新训练以涵盖更多的模型和数据集。此外，生成的表示使用不同空间，难以解释。本文提出了一种高效的、不需要训练的方法，将LLMs表示为提示语义任务空间中的线性算子，从而提供模型应用的高度可解释表示。该方法通过闭式计算几何属性，保证了出色的扩展性和实时适应性，以应对动态扩大的存储库。我们在成功预测和模型选择任务上展示了该方法，取得了竞争性或最新的结果，并在未见过的场景中表现出显著的性能提高。
### Innovation
提出了一种无需训练的方法，将大型语言模型（LLMs）表示为提示语义任务空间中的线性算子，实现了效率高、可解释性强、适合大规模动态扩展的模型表示方式。这种方法通过闭式计算几何属性，确保了在扩展存储库时的高效性和实时适应性。
### Conclusion
本文展示了一种在提示语义任务空间中表示LLMs的高效方法，通过线性算子有效表示模型应用，利用闭式计算简化了几何属性计算，实现了非凡的扩展性和实时适应性。实验展示了该方法在成功预测和模型选择任务中的竞争力，尤其在未见过的数据上的表现尤为突出。
## 545. `cs.CL` - 从测试到效应量：多语言和多任务NLP评价基准中不确定性与统计变异性量化 [PDF](https://arxiv.org/pdf/2509.22612), [HTML](https://arxiv.org/abs/2509.22612)
### Authors
Jonne Sälevä,Duygu Ataman,Constantine Lignos
### Background
在多语言和/或多任务NLP基准测试中，实验性能分数的变异既来自模型也来自数据。量化这些评估指标的不确定性以及统计精确度对于避免大幅低估总体变异性至关重要。
### Innovation
介绍了一组基于重采样的方法，用于量化多语言和/或多任务NLP基准测试中评估指标的不确定性与统计精确度。通过使用多语言问答、机器翻译和命名实体识别等示例任务，展示了这些重采样方法在统计分布计算中的应用。
### Conclusion
这些重采样方法有助于计算排行榜上使用的一些数量（如平均值/中位数、模型之间的成对差异和排名）的抽样分布。这样可以更准确地反映实际性能的变异性，从而提供更可靠的评价基准。
## 546. `cs.CL` -  Chimera: 诊断视觉语言理解中的捷径学习 [PDF](https://arxiv.org/pdf/2509.22437), [HTML](https://arxiv.org/abs/2509.22437)
### Authors
Ziheng Chi,Yifan Hou,Chenxi Pang,Shaobo Cui,Mubashara Akhtar,Mrinmaya Sachan
### Background
图表以视觉形式传达符号信息，而非线性文字流，使得它们对AI模型来说特别具有挑战性。尽管近期评估显示视觉语言模型（VLMs）在图表相关基准测试中表现良好，但它们对知识的依赖、推理或模态捷径引发了对其是否真正理解和推理图表的担忧。针对这一问题，研究人员引入了名为Chimera的综合测试套件，包含7,500个来自维基百科的高质量图表，每个图表都标注了其符号内容和多层次问题，旨在评估四个基本的图表理解方面：实体识别、关系理解、知识接地和视觉推理。Chimera用于检测视觉问答中的三种捷径：视觉记忆捷径、知识回忆捷径和Clever-Hans捷径。研究发现，开源VLMs的表现很大程度上依赖于这些捷径行为：视觉记忆捷径影响较小，知识回忆捷径起到中等作用，而Clever-Hans捷径贡献显著。这揭示了当前VLMs的关键局限性，并强调了需要更严格的方法来评估对复杂视觉输入（如图表）的理解能力而非问答捷径的重要性。
### Innovation
研究人员提出了一种名为Chimera的综合测试套件，用于评估视觉语言模型在图表理解方面的真正能力。该套件包含7,500个高质量的图表，并标注了各种类型的视觉和语言问题，以便全面评估模型的理解能力。此外，Chimera还专门设计了一种方法来识别和评估模型依赖的三种捷径学习方式：视觉记忆捷径、知识回忆捷径和Clever-Hans捷径。通过这种方法，研究首次详细揭示了VLMs在多种视觉问答任务中的依赖捷径行为，这一创新为评估和改进VLMs的理解能力提供了新的视角。
### Conclusion
这篇文章指出，视觉语言模型在图表理解方面的性能很大程度上依赖于捷径行为，主要依赖于视觉记忆捷径、知识回忆捷径和Clever-Hans捷径。这一发现揭示了当前VLMs的关键局限性，强调了必须采用更能反映模型真正理解能力的方法来评估，而不是依赖于问答捷径。这表明，未来必须加强对于视觉和语言结合的理解，以提高模型的整体理解和推理能力。
## 547. `cs.CL` - 评估大型语言模型在多语言法律推理中的局限性 [PDF](https://arxiv.org/pdf/2509.22472), [HTML](https://arxiv.org/abs/2509.22472)
### Authors
Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel
### Background
在大型语言模型（LLMs）主导的时代，理解它们在高风险领域如法律中的能力和局限性至关重要。LLMs，如Meta的LLaMA、OpenAI的ChatGPT、Google的Gemini、DeepSeek等，在法律工作流程中的应用日益增多，但在多语言、司法多样化和对抗性情境中的表现尚未受到足够探索。本文评估了LLaMA和Gemini在多语言法律和非法律基准上的性能，并通过字符和词级扰动评估了它们在法律任务中的对抗鲁棒性。研究采用LLM作为法官的方法进行人类对齐评估。此外，还提出了一种开源、模块化的评估管道，旨在支持任何LLM和数据集组合的多语言、任务多样基准测试，特别是法律任务，包括分类、总结、开放问题和一般推理。研究发现，法律任务对LLMs构成了重大挑战，在如LEXam这样的法律推理基准中准确率通常低于50%，而通用任务如XNLI中的准确率超过了70%。此外，尽管英语通常带来更稳定的性能，但这并不总是导致更高的准确率。语言的提示敏感性和对抗劣势也表明在不同语言中普遍存在。最后，性能与语言与英语的句法相似性之间发现相关性。研究还发现，LLaMA的表现弱于Gemini，后者在相同任务中平均优势约为24个百分点。尽管新LLMs有所改进，但它们在可靠得多语言法律应用中的挑战仍然存在。
### Innovation
本文首次通过LLM作为法官的方法评估了LLMs在多语言法律推理任务中的表现，并提出了一个模块化的基准测试框架，用于多语言、任务多样基准测试，特别是法律任务。同时，研究还发现了语言性能与英语句法相似性之间的关系，以及不同语言中LLMs性能的差异性。此外，研究显示LLaMA的表现弱于Gemini，为LLM在法律应用场景中的选型提供了依据。
### Conclusion
研究发现法律任务对LLMs构成了显著挑战，尤其是在法律推理方面。不同语言的LLMs表现存在差异，英语虽然带来更稳定的性能，但并不总是导致更高的准确率。语言的提示敏感性和对抗劣势也表明在不同语言中普遍存在。LLaMA的表现弱于Gemini。尽管LLMs有所改进，但在可靠地应用于多语言法律应用方面仍存在挑战。
## 548. `cs.CL` - WebGen-Agent: 提升多层级反馈及步骤级强化学习的互动网站生成 [PDF](https://arxiv.org/pdf/2509.22644), [HTML](https://arxiv.org/abs/2509.22644)
### Authors
Zimu Lu,Houxing Ren,Yunqiao Yang,Ke Wang,Zhuofan Zong,Junting Pan,Mingjie Zhan,Hongsheng Li
### Background
现有的代理系统利用大规模语言模型在仓库级别的代码生成任务上展示了出色的表现。然而，在需要大量视觉效果和用户互动反馈的任务，如网站代码生成中，现有的代码代理仅依靠简单的代码执行反馈和验证，无法准确捕捉生成代码的质量。
### Innovation
本文提出了WebGen-Agent，这是一种利用全面且多层次的视觉反馈迭代生成和优化网站代码的新颖网站生成代理。视觉语言模型（VLM）生成了关于屏幕截图和GUI代理测试的详细和丰富的描述和建议，以及衡量其质量的评分。通过将屏幕截图和GUI-代理评分与回溯和选择最佳机制结合，进一步增强了代理的性能。此外，通过将屏幕截图和GUI-代理评分作为奖励，在Step-GRPO中引入了Step-GRPO与屏幕截图和GUI-代理反馈，提高了LLM充当WebGen-Agent推理引擎的能力。
### Conclusion
在WebGen-Bench数据集中，WebGen-Agent将Claude-3.5-Sonnet的准确率从26.4%提升到51.9%，外观评分从3.0提升到3.9，超过了先前的最先进的代理系统。此外，我们的Step-GRPO训练方法将Qwen2.5-Coder-7B-Instruct的准确率从38.9%提升到45.4%，外观评分从3.4提升到3.7。
## 549. `cs.CL` - 我们在执行之前让大语言模型变得有益、无害和诚实，因此我们要进行对齐 [PDF](https://arxiv.org/pdf/2509.22510), [HTML](https://arxiv.org/abs/2509.22510)
### Authors
Gautam Siddharth Kashyap,Mark Dras,Usman Naseem
### Background
大型语言模型（LLMs）的安全和可靠部署依赖于沿着多个目标进行对齐，包括帮助性、无害性和诚实性（HHH）。先前的研究使用向隐藏状态中注入引导向量的小控制信号来引导LLM的输出，通常借助于一对一（1-to-1）的Transformer解码器。这种方法简化了问题，但可能会导致单一目标优化的同时覆盖其他目标学习的表示，引发灾难性遗忘。最近的方法通过一对多（1-to-N）Transformer解码器扩展了引导向量，缓解了灾难性遗忘的问题，但缺乏一揽子设计，无法确保多目标输出的一致性。
### Innovation
提出了一种新的Two-Stage 1-to-N框架即自适应多分支引导（AMBS），用于统一和高效的多目标对齐。AMBS分为两个阶段：第一阶段计算Transformer层的后注意隐藏状态，形成共享表示；第二阶段克隆此表示到并行分支并通过政策参考机制引导，实现特定于目标的控制同时保持跨目标的一致性。AMBS在Alpaca、BeaverTails和TruthfulQA上的实验证明了其在多个7B LLM基座上的一致性改进，例如，相比于1-to-N基线，AMBS在DeepSeek-7B上的平均对齐得分提高了32.4%，减少了11.0%的不安全输出，同时在最先进的方法中保持竞争力。
### Conclusion
AMBS在多目标对齐中展示了一种有效的解决方案，能够克服灾难性遗忘和多目标一致性的问题，同时保持与最先进的方法的竞争力。
## 550. `cs.CL` - 基于检索增强的AI草拟患者门户消息护栏：错误税onomies构建和大规模评估 [PDF](https://arxiv.org/pdf/2509.22565), [HTML](https://arxiv.org/abs/2509.22565)
### Authors
Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma
### Background
通过电子病历（EHR）门户进行的异步患者-医护人员消息交流已成为一种不断增加的临床工作负担。为了减轻医护人员的负担，研究人员利用大型语言模型（LLMs）来协助起草回复。然而，这些模型的回复中可能包含临床错误、遗漏或语调不匹配的情况，因此开发了可靠的评估方法非常重要。这篇论文旨在通过构建一个基于临床背景的错误分类体系，开发一种检索增强的评估框架，以及提出一种分阶段提示架构来应对这一问题。
### Innovation
本研究的创新在于：1、开发了包含5个领域和59个细粒度错误代码的临床背景下的错误分类体系；2、提出了一种检索增强的评估管道（RAEC），利用语义相似的历史消息-回复对来提高判断质量；3、利用DSPy提出了分阶段提示架构，实现可扩展、可解释和层次化的错误检测。这一体系不仅能单独评估草案质量，还可以将其与机构档案中检索到的相似过去的消息-回复对进行参考，以提高错误识别的准确性。通过对1500多条患者消息的两阶段DSPy管道的基线和参考增强评估进行比较，证明了检索上下文对特定领域（如临床完整性、工作流程适用性）中错误识别的改进。
### Conclusion
通过分阶段提示架构和检索增强的评估管道（RAEC），本研究在1500多条患者消息上实现了超越基线的更好的准确性和性能，证实了我们的RAEC管道作为AI护栏在患者消息制定中的应用价值。
## 551. `cs.CL` - 语言模型可以从口头反馈中学习而无需标量奖励 [PDF](https://arxiv.org/pdf/2509.22638), [HTML](https://arxiv.org/abs/2509.22638)
### Authors
Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang
### Background
通常，大规模语言模型（LLMs）在训练时会使用强化学习（RL）从人类或AI反馈中学习，但这些方法往往将复杂的反馈压缩成标量奖励，这使得反馈中丰富的信息丢失，并可能导致规模偏差。
### Innovation
本文提出了一种新的方法，将口头反馈作为调节信号处理。受文本到图像生成中语言先验的启发，本文提出了一种反馈调节策略（FCP）。FCP可以直接从响应-反馈对中学习，通过最大似然训练离线数据来近似反馈调节的后验。此外，还开发了一个在线自助阶段，在这种阶段中，策略在积极条件下生成内容，并获得新鲜反馈以改进自己。这种方法将反馈驱动学习重新定义为条件生成，而不是奖励优化，为LLMs直接学习口头反馈提供了更具表达性的方式。
### Conclusion
本文的方法通过直接从口头反馈中学习而不依赖标量奖励，为语言模型提供了更灵活和更具表达性的学习方式。
## 552. `cs.CL` - 在评估安全性监控时减少信息泄露的方法 [PDF](https://arxiv.org/pdf/2509.21344), [HTML](https://arxiv.org/abs/2509.21344)
### Authors
Gerard Boxo,Aman Neelappa,Shivam Raval
### Background
白盒监控器能够分析模型内部，有助于检测大型语言模型中潜在有害行为，具有较低的计算成本和集成到多层防御系统中的优势。然而，训练和测试这些监控器需要展示目标行为的响应示例，通常通过提示或微调获得，这可能导致用于激发行为的信息泄露到监控器的数据中，从而夸大其效力。本文旨在解决这一问题。
### Innovation
作者提出了一套系统的方法来评估监控器性能，强调其识别真实模型行为而非表面诱发伪证的能力。此外，他们提出了三种新的评估策略：内容过滤（去除与欺骗相关的文本输入）、评分过滤（仅聚合相关任务的标记）和提示提炼微调模型生物（未经显式提示训练的模型，表现出欺骗行为）。
### Conclusion
通过在多个欺骗基准实验中的应用，作者发现三种策略：内容过滤降低了探测率操作特性部分（AUROC）30%，评分过滤降低了15%但效果不易衡量，微调模型生物提高了监控评价但可能降低性能多达40%。
## 553. `cs.CL` - 随机直接偏好优化在医学影像报告生成中的应用 [PDF](https://arxiv.org/pdf/2509.21351), [HTML](https://arxiv.org/abs/2509.21351)
### Authors
Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev
### Background
医学影像分析领域中，影像报告生成（RRG）引起了广泛关注，因为它有望减轻放射科医生的工作负担。尽管已经取得了许多进展，现有的方法仍然无法满足实际临床应用中所需的质量标准。与此同时，视觉语言模型（VLMs）在一般领域中取得显著进步，通过采用最初为大型语言模型（LLMs）设计的训练策略，如对齐技术。然而，现有的方法仍然存在差距，未能达到临床部署的标准。
### Innovation
本文提出了一种模型无关的框架，通过直接偏好优化（DPO）增强RRG的准确性。该方法利用随机对比采样构建训练对，不需要奖励模型或人工偏好注释。实验结果显示，将我们的随机DPO方法补充到三种现领先模型中能够提升临床性能指标最多5%，无需额外的训练数据。
### Conclusion
实验表明，通过引入随机直接偏好优化（Random DPO）方法，能够显著提升影像报告生成（RRG）的临床性能，这一结果在不增加额外训练数据的情况下实现，并且是模型无关的。
## 554. `cs.CL` - 使用生成式AI加速产品声明的创建 [PDF](https://arxiv.org/pdf/2509.20652), [HTML](https://arxiv.org/abs/2509.20652)
### Authors
Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers
### Background
产品的声明是影响消费者购买行为的关键因素。声明的创建是一个耗费时间和资金的繁琐过程。作者旨在通过使用上下文学习和大模型微调构建一个名为Claim Advisor的网页应用程序，以加速声明的生成。这项技术旨在打破声明搜索、生成、优化和模拟的繁琐和成本。
### Innovation
开发了名为Claim Advisor的网页应用程序，该程序利用上下文学习和大模型微调来加速产品声明的生成过程。该程序具有以下功能：1) 语义检索已有的与消费者声音相符的声明或视觉；2) 基于产品描述和消费者画像生成或优化声明；3) 使用模拟消费者进行生成和手动创建的声明排名。
### Conclusion
在消费品公司（CPG）的应用表明了该技术的巨大潜力。作者相信这种能力在不同产品类别和行业中具有广泛的应用价值。通过分享学习成果，作者鼓励不同行业的研究和应用生成式人工智能技术。
## 555. `cs.CL` - ReGeS: 递归检索-生成协同对于对话推荐系统的应用 [PDF](https://arxiv.org/pdf/2509.21371), [HTML](https://arxiv.org/abs/2509.21371)
### Authors
Dayu Yang,Hui Fang
### Background
对话推荐系统（CRS）需要与外部领域知识结合才能正确理解用户偏好。然而，现有的解决方案要么需要特定领域的工程，这限制了灵活性，要么依靠大型语言模型，从而增加了体现错误信息的风险。虽然检索增强生成（RAG）很有潜力，但其在CRS中的直接应用受限于噪音对话削弱了检索效果，并且在区分相似项的细微特征方面被忽略了关键点。
### Innovation
我们提出了ReGeS，一种递归检索-生成协同框架，该框架将生成增强检索与检索增强生成结合起来，从对话中提炼有用用户意图，并区分公司特征。这种协同作用消除了额外注释的需求，减少了幻觉现象，并简化了持续更新。
### Conclusion
在多个CRS基准测试中的实验表明，ReGeS在推荐准确性方面达到了最先进的性能，这证明了对于知识密集型CRS任务，递归协同的有效性。
## 556. `cs.CL` - 从形式语言理论到统计学习：子正规语言的有限观察性 [PDF](https://arxiv.org/pdf/2509.22598), [HTML](https://arxiv.org/abs/2509.22598)
### Authors
Katsuhiko Hayashi,Hidetaka Kamigaito
### Background
本文证明了当由决定谓词表示时，所有的标准子正规语言类都是线性可分的。这项工作建立了有限可观测性和保证用简单线性模型可学习性。研究结果表明，子正规层次结构为自然语言结构建模提供了一个严格且可解释的基础。此前的工作可能已经在部分探索了决定谓词和人工实验，但本文通过合成和真实数据的实验进一步验证了这些理论。
### Innovation
本文的核心创新在于证明了标准子正规语言类的决定谓词是线性可分的，这确保了使用简单线性模型的可学习性。此外，研究还通过合成和真实数据实验验证了这一理论，展示了子正规层次结构在自然语言结构建模中的应用价值。
### Conclusion
本文的结果表明，在无噪声条件下，合成实验完美地验证了子正规语言的线性可分性，而真实数据实验表明，从子正规层次结构里学到的功能特征与已知的语法约束一致。这些发现证明了子正规语言层次结构是自然语言结构建模的严谨且可解释的基础。
## 557. `cs.CL` - StateX：通过后训练状态扩展提升RNN回忆能力 [PDF](https://arxiv.org/pdf/2509.22630), [HTML](https://arxiv.org/abs/2509.22630)
### Authors
Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
尽管基于Transformer的模型在语言建模方面表现出色，但其高复杂度导致在处理长上下文时成本较高。相比之下，循环神经网络（RNN），如线性注意力和状态空间模型，因为它们的每个标记复杂度保持不变而受到青睐。然而，这些递归模型在需要从长上下文中准确回忆上下文信息的任务中表现不佳，因为所有的上下文信息都被压缩进了一个固定大小的递归状态中。先前的研究表明，记忆能力强与递归状态大小正相关，但直接训练具有更大递归状态的RNN会导致训练成本高。
### Innovation
本文介绍了StateX，这是一种通过后训练来有效扩展预训练RNN的状态的训练管道。针对线性注意力和状态空间模型这两种RNN类，设计了后训练的架构修改，能够在不增加或几乎不增加模型参数的情况下扩展状态大小。实验结果表明，StateX能够有效提升RNN的回忆能力和上下文内学习能力，且不产生额外的后训练成本或损害其他能力。
### Conclusion
StateX通过细粒度调整后训练状态的大小，既提高了RNN的内存能力和上下文内学习能力，又保持了模型的其他性能不受影响。
## 558. `cs.CL` - 语言模型的变分推理 [PDF](https://arxiv.org/pdf/2509.22637), [HTML](https://arxiv.org/abs/2509.22637)
### Authors
Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang
### Background
目前的语言模型在推理任务上面临挑战，需要一种既能提高推理能力又能稳定训练的方法。本文提出了一个变分推理框架，通过将思考痕迹作为潜在变量并利用变分推理优化它们，来解决这个问题。
### Innovation
提出了一个多痕迹目标函数，扩展了证据下界（ELBO），使其更紧；提出了前向KL公式，稳定了变分后验的训练；揭示了拒绝采样微调和二元奖励强化学习方法可以被视为局部前向KL目标，这对模型的准确度进行了隐式加权，揭示了对简单问题的倾向性偏差。
### Conclusion
在Qwen 2.5和Qwen 3模型系列上，对各种推理任务进行了实证验证，证明了该方法的有效性。该研究将变分推理与RL风格的方法统一起来，为提高语言模型的推理能力提供了稳定的目标。代码已公开。
## 559. `cs.CL` - LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants? [PDF](https://arxiv.org/pdf/2509.21501), [HTML](https://arxiv.org/abs/2509.21501)
### Authors
Lu Sun,Shihan Fu,Bingsheng Yao,Yuxuan Lu,Wenbo Li,Hansu Gu,Jiri Gesi,Jing Huang,Chen Luo,Dakuo Wang
### Background
随着生成式人工智能（Agentic AI）的出现，如用于编码的Copilot或用于购物的Amazon Rufus，通过自然语言执行任务的系统变得越来越重要。然而，评估这些系统的难度在于它们的发展速度超出了传统的手工评估能力。为了解决这个问题，研究者提出了使用LLM（大型语言模型）代理模拟人类参与者作为数字双胞胎的方法，但具体到多轮交互中，数字双胞胎是否能够准确代表特定客户仍是未知数。
### Innovation
本研究招募了40名真人参与者与Amazon Rufus进行购物任务，收集了他们的角色特征、交互痕迹和用户体验反馈，构建了数字双胞胎重复完成任务。通过对比真人与数字双胞胎的交互痕迹，发现尽管代理探索了更多样化的选择，但其行为模式与真人参与者相似，并提供了类似的用户体验反馈。这是首次量化LLM代理能否准确模拟真人与生成式AI系统的多轮交互，强调了其在大规模评估中的潜力。
### Conclusion
本研究展示了LLM代理在模拟多轮交互中的能力，使其能够有效评估生成式AI驱动的购物助手，为AI系统的评估提供了新的方法。
## 560. `cs.CL` - 《超越n元组新颖性：作为文本创造力度量标准的新颖性之死》 [PDF](https://arxiv.org/pdf/2509.22641), [HTML](https://arxiv.org/abs/2509.22641)
### Authors
Arkadiy Saakyan,Najoung Kim,Smaranda Muresan,Tuhin Chakrabarty
### Background
N-gram新颖性广泛用于评估语言模型生成超出现有训练数据文本的能力，而且最近也作为评估文本创造力的度量指标被采用。然而，关于创造力的理论研究表明，这种方式可能不够全面，因为它没有考虑到创造力的双重性质：新颖性（文本的原创程度）和适宜性（文本的合乎情理性和实用价值）。需要研究如何更加准确地评估文本的创造力，特别是通过多维度来评估，即既要关注新颖性，也要关注适宜性。本文通过专家评定的方法探讨了这两个概念之间的关系，并指出了n-gram新颖性在评估创造力方面的不足之处.
### Innovation
本研究通过对7542个人工和AI生成的文本进行详细阅读和专家评定，具体分析了n-gram新颖性和创造力之间的关系。研究发现，虽然n-gram新颖性与专家评定的创造力正相关，但高n-gram新颖性的表达并不一定能被评定为有创造力，特别是在开源语言模型中，新颖性高的文本反而更不具有适宜性。此外，开放源代码的大型语言模型与前沿的封闭源代码模型相比，在生成创造性表达方面表现较差。研究还测试了零样本、少样本和微调模型在识别创造性表达和非适宜性表达上的能力，并发现前沿模型的表现显著优于随机猜测，但也存在改进空间，特别是在识别非适宜性表达方面有待提升。模型的性能可通过专家评定者的偏好程度预测.
### Conclusion
n-gram新颖性不能单独作为评估文本创造力的标准，且对于AI生成的文本来说，高新颖性往往并不意味着高创造力。即使在先进模型的表现面前，仍有改进空间，特别是在准确识别非适宜性表达方面。
## 561. `cs.CL` - VoiceAssistant-Eval：跨听觉、口语和视觉评估人工智能助理的标准 [PDF](https://arxiv.org/pdf/2509.22651), [HTML](https://arxiv.org/abs/2509.22651)
### Authors
Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li
### Background
随着大型语言模型和多模态系统的不断发展，人们对语音优先AI助手的兴趣日益浓厚。然而，现有的基准尚不足以评估这些系统的全部能力。该研究旨在弥补现有评估工具的不足，通过引入VoiceAssistant-Eval这一全面基准来评估语音助手在听、说、看等多方面的表现。VoiceAssistant-Eval涵盖了10,497个精心挑选的案例，涉及13个任务类别，包括自然声音、音乐、对话等听觉任务；多轮对话、角色扮演模仿以及各种场景等说的任务；和多种多样图片等视觉任务。这一基准旨在评估不同AI助手在这些多模态任务中的性能。
### Innovation
该研究创新地构建了一个跨听觉、口语和视觉的全面基准VoiceAssistant-Eval，它涵盖了一系列多模态任务，能够测试和评估现有AI助手在这三个方面的综合能力。此外，研究还通过实验揭示了几个重要发现，例如闭源模型并非总是优于开源模型，大多数模型在说的任务中表现优异但在音频理解方面有差距，以及精心设计的小模型可以与大模型相媲美。该基准还指出了当前模型在多模态输入和角色扮演声音模仿等任务上存在的困难，并设定了下一代AI助手评估与指导发展的严格框架。
### Conclusion
研究发现中等大小的Step-Audio-2-mini（7B）模型在听觉任务上的表现明显优于大模型，但在跨模态输入和角色扮演声音模仿等任务上仍面临挑战，且需要更多努力提升模型的健壮性和安全性对齐。VoiceAssistant-Eval通过识别现有差距和制定严谨的评估框架，有望推动下一代AI助手的开发与进步。研究结果表明，这一全面基准在评估AI助手的整体性能和指导其未来发展方面具有重要作用。
## 562. `cs.CL` - 科学领域的贝叶斯优化：我们是否已经到了那里？ [PDF](https://arxiv.org/pdf/2509.21403), [HTML](https://arxiv.org/abs/2509.21403)
### Authors
Rushil Gupta,Jason Hartford,Bang Liu
### Background
近年来，大语言模型（LLMs）被提出作为通用型实验设计代理，声称可以在上下文中执行实验设计。本文通过对开放源代码和闭源源代码指令调优的LLM在基因扰动和分子性质发现任务上的评估，探讨了这一假设的有效性。结果显示，基于LLM的代理对实验反馈表现出不灵敏性，并且在多个基准测试中，传统方法如线性臂和高斯过程优化始终优于LLM代理。这些发现表明当前的开放源代码和闭源源代码LLM在实践中并不具备在上下文中执行实验设计的能力，强调需要提出结合基于先验推理与批量获取更新后验的混合框架的重要性。
### Innovation
提出了一种简单的混合方法——LLM引导的最近邻（LLMNN）抽样，该方法结合了LLM的先验知识和最近邻抽样，指导实验设计。LLMNN在各个领域实现了竞争力或优越的表现，而无需显著的上下文适应。这种方法暗示当前的LLM并不具备在上下文中文实验设计的能力，并指出需要分离基于先验的推理与更新后验的批量获取的需求。
### Conclusion
当前开放源代码和闭源源代码的LLM在实践上并未体现出在上下文中执行实验设计的能力。研究还提出了结合基于先验推理和数据驱动获取的混合框架作为潜在的解决方案。
## 563. `cs.CL` - 利用大数据框架在Amazon评论中检测垃圾信息 [PDF](https://arxiv.org/pdf/2509.21579), [HTML](https://arxiv.org/abs/2509.21579)
### Authors
Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed
### Background
随着数字时代的到来，网上购物在日常生活中变得普遍。产品评论对消费者的购买行为有显著影响，有助于建立买家的信任。但是，虚假评论的泛滥会削弱这种信任，可能导致误导消费者并损害卖家的声誉。这项研究通过运用先进的大数据分析和机器学习方法，针对大量的亚马逊产品评论数据集来解决这一紧迫问题。研究的主要目标是准确地检测和分类垃圾评论，以提升评论的可信度。
### Innovation
通过运用可扩展的大数据框架，高效地处理和分析大规模的评论数据，提取反映欺诈行为的关键特征。研究展示了各种机器学习分类器在检测垃圾评论中的应用，其中逻辑回归模型的准确率为90.35%，为打造更值得信赖和透明的网上购物环境做出了贡献。
### Conclusion
这项研究有助于提高亚马逊评论的真实性和透明度，通过使用机器学习和大数据技术，可以更有效地识别和分类垃圾评论，增强了消费者的信任，促进了电子商务的健康和可持续发展。
## 564. `cs.CL` - HetaRAG：跨异构数据存储的混合深度检索增强生成 [PDF](https://arxiv.org/pdf/2509.21336), [HTML](https://arxiv.org/abs/2509.21336)
### Authors
Guohang Yan,Yue Zhang,Pinlong Cai,Ding Wang,Song Mao,Hongwei Zhang,Yaoze Zhang,Hairong Zhang,Xinyu Cai,Botian Shi
### Background
检索增强生成（RAG）已成为缓解大型语言模型（LLMs）中知识脱节和更新问题的主要范式，同时保持数据安全性。传统RAG系统依赖单一存储后端，通常是向量数据库，并且通常是纯文本，因此遭受着不可避免的设计权衡。向量搜索捕捉语义相似性但失去全局上下文；知识图谱在关系精度方面表现出色但召回率差；全文索引速度快且精确但语义盲；关系数据库如MySQL提供了强大的事务保证但缺乏语义理解。为克服这些单一模态的弱点，作者提出了一个协同多种异构检索范式的方案。文章介绍了HetaRAG，一种混合的深度检索增强生成框架，能够从异构数据存储中整合跨模态证据，通过动态路由和融合证据来最大化召回率、精确性和上下文真实性。作者已经进行了一些初步探索并构建了最初的RAG流程管道，本文提供了这项技术的初步概述和代码预览。
### Innovation
提出了一种名为HetaRAG的混合深度检索增强生成框架，能够从异构数据存储中整合跨模态证据，通过动态路由和融合证据来最大化检索的召回率、精确性和上下文真实性。该方案通过结合向量索引、知识图谱、全文搜索引擎和结构化数据库，克服了单一模态检索的局限性。
### Conclusion
HetaRAG结合了多种异构数据存储的检索机制，旨在通过动态路由和融合证据来提高生成系统的生成质量。文章提供了初步探索和技术概述，表明该方法有望显著提升RAG系统的性能。
## 565. `cs.CL` - VideoJudge：通过自举实现大规模多模态语言模型作为裁判的可扩展监督 [PDF](https://arxiv.org/pdf/2509.21451), [HTML](https://arxiv.org/abs/2509.21451)
### Authors
Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj
### Background
精确评估视频理解模型仍然具有挑战性：常用的指标如BLEU、ROUGE和BERTScore无法捕捉到人类判断的细致程度，而通过手动评估获取这些判断的成本较高。近期研究尝试使用大型语言模型（LLMs）或多模态大型语言模型（MLLMs）作为评估工具，但它们在视频理解领域的应用尚未得到充分探索。现有的评估方法难以全面准确地评估视频理解模型的输出效果，尤其是在文本回应与视频内容的相关性方面。因此，开发一种专门用于评估视频理解模型输出的专业工具仍然是一个亟待解决的问题。
### Innovation
该论文提出了VideoJudge，一种专门用于评估视频理解模型输出的3B和7B大小的多模态大型语言模型（MLLMs）。论文的方法基于生成器和评估器之间的协同工作，通过提示生成器生成符合特定评分的响应，而不符合评分的响应则被丢弃。VideoJudge-7B在三个四个元评估基准中表现优于较大的LLM评估基线，如Qwen2.5-VL（32B和72B）。研究还发现，虽然LLM裁判（Qwen3）模型的表现不如MLLM裁判（Qwen2.5-VL），但长链推理并不提升评估性能，表明提供视频输入对于视频理解任务的评估至关重要。
### Conclusion
研究结果显示，VideoJudge在视频理解评价中表现良好，且能够通过自举实现更具扩展性的评估机制。未来工作可以进一步探索如何优化和大规模部署这类多模态语言模型，以实现更高效和准确的视频理解模型评估，从而推动相关研究和应用的发展。
## 566. `cs.CL` - C-QUERI：政治机构中的国会问题、交流和回应数据集 [PDF](https://arxiv.org/pdf/2509.21548), [HTML](https://arxiv.org/abs/2509.21548)
### Authors
Manjari Rudra,Daniel Magleby,Sujoy Sikdar
### Background
政治采访和听证会中的问题不仅用于收集信息，还用于推进党派叙事和塑造公众观点。然而，由于缺乏相关的大规模数据集，这些战略方面仍没有得到充分研究。国会听证会因其结构化规则、强制见证人回应以及跨党派成员提问的机会，是研究政治提问的理想场所。
### Innovation
研究人员开发了一种从未结构化听证会记录中提取问题-回答配对的管道，并构建了一个涵盖第108届至第117届国会的新颖数据集C-QUERI。该研究揭示了不同政治党派在提问策略上的系统性差异，并展示了仅从问题就可以预测提问者的政治归属于政治党派。
### Conclusion
该数据集和方法不仅推进了对国会政治的研究，还提供了一个适用于类似采访环境的问题-回答分析的一般框架。
## 567. `cs.CL` - ARTI-6: 向六维发音语音编码迈进 [PDF](https://arxiv.org/pdf/2509.21447), [HTML](https://arxiv.org/abs/2509.21447)
### Authors
Jihwan Lee,Sean Foley,Thanathai Lertpetchpun,Kevin Huang,Yoonjeong Lee,Tiantian Feng,Louis Goldstein,Dani Byrd,Shrikanth Narayanan
### Background
当前，语音技术的广泛应用急需一种能够准确捕捉发音器官关键部位（如硬腭、舌根和喉部）动态的高效编码框架。现有的语音编码技术通常只能部分地反映这些发音器官的复杂变化，导致合成语音的自然度和可理解性不足。因此，研究如何从实时核磁共振（MRI）数据中提取和利用发音器官的关键特征，以实现高效且自然的语音编码和合成变得尤为重要。ARTI-6正是在此背景下提出的创新解决方案。
### Innovation
ARTI-6 是一种紧凑的六维发音语音编码框架，它从实时 MRI 数据中提取关键发音部位特征，包括硬腭、舌根和喉部。该框架具有三个关键组成部分：(1) 六维发音特征集，代表关键的发音器官区域；(2) 发音逆模型，能够利用语音基础模型从语音声学中预测发音特征，实现了预测相关性为0.87的高精度；(3) 发音合成模型，直接从发音特征重建可理解的语音，展示了即使使用低维表示也能产生自然声音的潜力。总的来说，ARTI-6 提供了一种可解释、计算效率高且生理基础的框架，用于推进发音逆向、合成及更广泛语音技术应用的发展。
### Conclusion
ARTI-6 结合了发音逆向预测和语音重建技术，提供了一种新的发音语音编码框架，能够有效增强语音的自然度和可理解性。该框架公开源代码和语音样本，为语音科技的进步提供了一个有效的工具。
## 568. `cs.CL` - 幻觉是糟糕的估计吗？ [PDF](https://arxiv.org/pdf/2509.21473), [HTML](https://arxiv.org/abs/2509.21473)
### Authors
Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu
### Background
在生成模型中，我们将幻觉定义为未能将估计与任何合理的因果链接起来。通过这一解释，研究展示即使损失最小化最优估计器仍然会出现幻觉现象。为此，通过一个适用于任意数据分布的高概率下限界定了幻觉率。实验表明，幻觉体现了损失最小化和人类接受输出之间的结构性错位，这就归因为估计的误差因素是由校准不当引起的。该研究通过硬币聚合、开放式问答和文本到图像的实验提供了理论支持.
### Innovation
创新点在于将幻觉定义为估计与合理因果之间的断裂，并证明了即使是最优的损失最小化估计器也不能避免幻觉现象。通过一个通用的高概率下限界定了幻觉率，将其重新定义为损失最小化与人类可接受输出之间的结构性不匹配，这种不匹配源于校准不当导致的估计误差。并使用了硬币聚合、开放式问答和文本到图像的实验来验证理论.
### Conclusion
研究表明，幻觉现象是损失最小化与人类可接受输出之间结构性不匹配的结果，这种不匹配导致了估计中的误差，而这种误差是由模型校准不当引起的。实验进一步支持了这一理论，展示了幻觉现象是生成模型普遍存在的问题。
## 569. `cs.CL` - 不确定性意识的知识跟踪模型 [PDF](https://arxiv.org/pdf/2509.21514), [HTML](https://arxiv.org/abs/2509.21514)
### Authors
Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead
### Background
知识跟踪（KT）模型的研究主要集中在模型的发展上，以提高预测准确性。大多数模型在学生选择陷阱选项时最有可能做出错误的预测，这导致学生错误未被检测到。
### Innovation
本文提出了一种方法，通过捕捉预测不确定性来增强KT模型的新功能，并证明预测不确定性与模型错误预测相关。显示了KT模型中的不确定性是具有信息价值的，这可以为教育学习平台提供有用的信号，尤其是在资源有限的环境中理解学生能力是必要的场景下。
### Conclusion
不确定性在KT模型中是具有信息价值的信号，能够在教育学习平台上提供有用的教育信号，尤其是在资源限制的环境下理解学生能力方面。
## 570. `cs.CL` - 超长时程场景中智能体能力基准测试：UltraHorizon [PDF](https://arxiv.org/pdf/2509.21766), [HTML](https://arxiv.org/abs/2509.21766)
### Authors
Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen
### Background
尽管自主智能体在多个领域已经取得了显著进展，但大多数评估主要集中在短期、完全可观察的任务上。然而，许多关键的实际任务，如大规模软件开发、商业投资和科学研究等，发生在长期和部分可观察的情景中，成功取决于持续的推理、规划、记忆管理和工具使用。现有的基准测试很少能够捕捉到这些长期挑战，因此在系统评估方面存在空白。
### Innovation
我们介绍了一种名为UltraHorizon的新基准测试，旨在评估智能体处理复杂现实挑战所需的底层能力。通过在三个不同环境中的探索任务来验证这些核心能力。我们还发现了智能体在这些设置下的表现不佳，并且简单的规模扩展也失败了，进一步表明了智能体在长期环境中的能力差距。通过对收集轨迹的深入分析，我们确定了八种类型错误，并归因于两种主要原因：上下文锁定和功能根本能力差距。
### Conclusion
我们的实验结果表明，LML-智能体一直无法在这些设置中表现良好，而人类参与者则取得了更高的成绩，进一步证实了智能体长期能力的缺陷。未来的研究应当关注如何提升智能体在超长期任务中的表现。
## 571. `cs.CL` - 沙特专业角色中的性别刻板印象：基于语言模型生成图像的分析研究 [PDF](https://arxiv.org/pdf/2509.21466), [HTML](https://arxiv.org/abs/2509.21466)
### Authors
Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa
### Background
该研究探讨了当代 Text-to-Image 人工智能（AI）模型在生成沙特阿拉伯专业人员形象时，是否延续性别刻板印象和文化不准确性的问题。研究者分析了由 ImageFX、DALL-E V3 和 Grok 生成的 1,006 幅图像，并使用中性的提示语分析了 56 种多样的沙特职业。两组训练有素的沙特注释员基于五个维度进行评估：性别感知、服饰和外貌、背景和设置、活动和互动、以及年龄。当初级评估者意见不一时，由第三名高级研究者裁定，共计获得了 10,100 个个体评判意见。
### Innovation
本研究创新之处在于使用大型语言模型生成的图像来探讨人工智能技术能否客观反映社会现实，特别是性别和文化多样性方面。通过对比分析三个不同的 AI 模型生成的图像，研究发现当前 AI 模型在性别和文化准确性方面存在显著问题，并提出了使用更丰富和多样化的训练数据、公平性算法和文化敏感评价框架的建议来改进 AI 技术的生成结果。
### Conclusion
当前的 AI 模型在生成与性别和文化相关的图像时，往往反映了训练数据中嵌入的社会偏见，无法准确反映沙特阿拉伯劳动力市场的性别动态和文化细节。研究人员认为，这反映了训练数据的局限性，并且需要进一步改进训练数据的多样性和算法的公平性。此外，研究还表明，部分所谓的‘反刻板印象’形象实际上是由于文化误解，而非真正进步的表现。因此，迫切需要改进 AI 技术，使其能够生成更符合实际多样性和文化敏感性的图像。
## 572. `cs.CL` - DeHate: 一种基于稳定扩散的多模态方法以减少图像中的仇恨言论 [PDF](https://arxiv.org/pdf/2509.21787), [HTML](https://arxiv.org/abs/2509.21787)
### Authors
Dwip Dalal,Gautam Vashishtha,Anku Ranui,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal
### Background
有害网络内容的兴起不仅会影响公共言论的公正性，还对维护健康的数字环境构成了严峻挑战。本文提出了一种专为识别数字内容中的仇恨言论而设计的多模态数据集。本文通过介绍稳定扩散技术与数字注意力分析模块（DAAM）相结合的方法来提升图像中的仇恨内容检测能力，并通过生成详细的仇恨注意力图来模糊化这些区域，进而移除图像中带有仇恨信息的部分。
### Innovation
本文的核心创新在于利用水印增强、稳定扩散技术结合数字注意力分析模块（DAAM）。这种方法能够准确标识图像中的仇恨元素，生成详细的仇恨注意力图，从而模糊化这些区域，实现去除图像中带有仇恨内容的部分。并且提出了一种适用于多模态消除仇恨言论的视觉-语言模型DeHater。这种方法不仅提高了AI在处理社交媒体图像中的仇恨内容检测能力，还推动了更具道德价值的AI应用的发展。
### Conclusion
本文研究并提出了一种新的多模态方法来检测和消除图像中的仇恨言论，建立了一个专门的数据集并启动了一个共享任务。通过这种方法，可以有效地识别和屏蔽图像中的仇恨内容，有助于维护更健康的网络环境。
## 573. `cs.CL` - 使用视觉反馈的空间推理学习GUI接地 [PDF](https://arxiv.org/pdf/2509.21552), [HTML](https://arxiv.org/abs/2509.21552)
### Authors
Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim
### Background
GUI接地任务通常被视为坐标预测任务——给定自然语言指令，在屏幕上生成点击和按键等操作的目标坐标。然而，近期的视觉语言模型在处理复杂布局的高分辨率GUI图像时，往往难以准确预测坐标。文章提出了一种新的方法，即将GUI接地重新框架为一个交互式搜索任务，通过生成操作让光标在GUI中移动以定位用户界面元素，这种方法能更好地处理复杂布局的图片，并通过视觉反馈提升预测准确性。
### Innovation
本文的创新在于将传统的坐标预测任务转换为交互式搜索任务，使用Qwen2.5-VL-7B模型通过多步在线强化学习和基于密集轨迹的奖励函数进行训练，实现了GUI接地准确性提升。实验结果表明，这种方法显著提高了GUI-Cursor-grounding模型的性能，特别是在ScreenSpot-v2和ScreenSpot-Pro数据集上的表现，达到了新纪录，错误率分别降低了4.9%和29.7%。此外，该模型能快速学习并解决大部分实例中的问题，对于更复杂的样本，模型还能灵活地执行更多步骤。
### Conclusion
研究结果表明，通过交互式搜索任务重新定义GUI接地问题，并通过视觉反馈和强化学习方法改进模型训练，可以显著提升GUI接地的准确性。GUI-Cursor模型在多个测试数据集上取得了领先的表现，这是一个在视觉语言处理和人机交互领域有意义的研究成果。
## 574. `cs.CL` - SBFA：攻击大型语言模型的一种单一隐秘位翻转攻击 [PDF](https://arxiv.org/pdf/2509.21843), [HTML](https://arxiv.org/abs/2509.21843)
### Authors
Jingkai Guo,Chaitali Chakrabarti,Deliang Fan
### Background
随着大型语言模型（LLMs）的大量在线部署，模型完整性的安全性成为一个紧迫的关切。先前的位翻转攻击（BFAs）能够严重破坏深度神经网络（DNNs），少量的位翻转就能将准确性降低到随机猜测水平。最近的研究将BFAs扩展到LLMs，发现尽管模块性和冗余性提高了鲁棒性，但少量的对抗性位翻转仍然可能导致LLMs的灾难性准确性下降。然而，现有的BFAs方法通常只针对整数或浮点模型中的某一种，限制了攻击的灵活性。此外，在浮点模型中，随机位翻转常常导致参数受到极端值的影响（例如，位权翻转），这使得攻击难以隐蔽，并导致数值运行时错误（例如无效的张量值（NaN/Inf））。现有方法面临这些挑战。
### Innovation
本文首次提出了SBFA（隐秘位翻转攻击），能够在保持扰动值在良性层权重分布内的情况下，通过迭代搜索和排名来降低LLM性能，使用我们定义的参数敏感度指标ImpactScore，该指标结合了梯度敏感性和扰动范围。我们还提出了一种新颖的轻量级SKIP搜索算法，极大地减少了搜索复杂性，使得SOTA LLM的SBFA搜索只需几分钟。SBFA在Qwen、LLaMA和Gemma模型中，通过单个位翻转成功将MMLU和SST-2的数据格式准确性降至随机水平以下。
### Conclusion
单个位翻转能够揭示当前SOTA LLM模型的严重安全问题。
## 575. `cs.CL` - AUDDT: 音频统一深度假信息检测基准工具包 [PDF](https://arxiv.org/pdf/2509.21597), [HTML](https://arxiv.org/abs/2509.21597)
### Authors
Yi Zhu,Heitor R. Guimarães,Arthur Pimentel,Tiago Falk
### Background
随着人工智能生成内容（如音频深度换脸）的普及，大量研究集中于开发音频深度伪造检测技术。然而，大多数模型仅在窄范围的数据集上进行评估，其在真实世界条件下的泛化能力尚不明确。因此，本文系统地回顾了28个现有的音频深度伪造数据集，并提出了一款开源基准测试工具包称为AUDDT（此链接 https://）。该工具包旨在自动评估这些28个数据集上的预训练检测器，给用户直接反馈其深度伪造检测器的优势和不足。
### Innovation
本文创新性地构建了一个名为AUDDT的开源基准测试工具包，用于自动化评估现有的28个音频深度伪造数据集上的预训练检测器，直接提供用户反馈该技术的优势和不足，揭示不同条件和音频操纵类型的检测结果差异，同时分析现有数据集的局限性和与实际部署场景的差距。
### Conclusion
最近的研究结果揭示了不同条件和音频操纵类型下的显著差异，同时指出现有数据集在实际部署场景中的局限性。该研究有助于提高音频深度伪造检测技术在真实世界环境下的有效性。
## 576. `cs.CL` - UISim: 动态移动环境中的互动图像基UI模拟器 [PDF](https://arxiv.org/pdf/2509.21733), [HTML](https://arxiv.org/abs/2509.21733)
### Authors
Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen
### Background
开发和测试用户界面（UI）以及训练AI代理与之交互是具有挑战性的，因为现实中的移动环境是动态和多样的。现有的方法通常依赖于笨重的物理设备或屏幕截图的有限静态分析，这阻碍了可扩展的测试和智能UI代理的开发。
### Innovation
我们介绍了UISim，一种基于图像的新型UI模拟器，它提供了一个可以从屏幕图像纯粹探索移动手机环境的动态和交互式平台。系统采用了两阶段的方法：给定初始手机屏幕图像和用户操作，首先预测下一个UI状态的抽象布局，然后基于此预测的布局合成一个新的视觉一致的图像。这种方法使UI过渡的现实模拟成为可能。UISim为UI测试、快速原型设计和合成数据生成提供了即时的实际好处，并且其交互能力为进一步的应用，如为AI代理规划UI导航任务铺平了道路。
### Conclusion
实验结果表明，与端到端的UI生成基线相比，UISim在生成真实且连贯的后续UI状态方面表现更优，突显了其真实性以及在简化UI开发和提升AI代理训练方面的潜力。
## 577. `cs.CL` - InvBench：LLMs能在不变式合成中加速程序验证吗？ [PDF](https://arxiv.org/pdf/2509.21629), [HTML](https://arxiv.org/abs/2509.21629)
### Authors
Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken
### Background
程序验证依赖于循环不变式的发现，但自动发现强不变式仍然是一个长期的挑战。本文介绍了一种原则性的框架，用于评估LLM在不变式合成中的性能。该方法采用基于验证器的决策过程，带有形式上的正确性保证，并不仅评估正确性，还评估不变式在验证中的加速效果。本文评估了7种最先进的LLM和基于LLM的验证器，以及传统求解器UAutomizer的表现。虽然基于LLM的验证器具有潜力，但目前还没有显著优于UAutomizer。模型能力也证明了至关重要，不同模型之间在加速效果上的差异显著，并且本文的基准仍然是对当前LLM的一个公开挑战。此外，作者展示了监督微调和Best-of-N抽样的性能改进：细调3589个实例后，Qwen3-Coder-480B加速案例的百分比从8%提高到29.2%；N=16的Best-of-N抽样使得Claude-sonnet-4的加速案例百分比从8.8%提高到22.1%。
### Innovation
介绍了一种原则性的框架，用于评估LLM在不变式合成中的性能；不仅评估正确性，还评估不变式在验证中的加速效果；展示了监督微调和Best-of-N抽样的性能改进，提高了加速实例的比例。
### Conclusion
尽管基于LLM的验证器有潜力，但目前还没有显著优于传统求解器UAutomizer。模型能力是关键，展示的基准仍然是对当前LLM的一个公开挑战，监督微调和Best-of-N抽样可以提高性能。
## 578. `cs.CL` - 通过证明编译：自动从形式语义学中进行语言无关的优化 [PDF](https://arxiv.org/pdf/2509.21793), [HTML](https://arxiv.org/abs/2509.21793)
### Authors
Jianhong Zhao,Everett Hildenbrandt,Juan Conejero,Yongwang Zhao
### Background
验证证明可以完全编码程序行为，但在验证正确性后我们通常会丢弃它们。因此，本文提出了“通过证明编译”的概念，即将这些证明转换为优化的执行规则。通过使用符号执行构建全路径可达证明，并将它们的图结构编译，可以将许多语义重写合并为单一规则，同时通过构造保持正确性。该方法以K框架为平台实现了一个语言无关的扩展。评估结果显示了不同编译范围内的性能改进：在指令级优化中显示出一致的速度提升，而在整个程序编译中则实现了数量级更大的性能增益。
### Innovation
提出了一种新的编译方法——“通过证明编译”，它将验证证明转化为优化执行规则。通过符号执行构建全路径可达证明，并将这些证明转换为单个规则，从而提高性能。该方法能够兼容不同的编程语言，并显著改善不同层次的编译效率。
### Conclusion
研究表明，“通过证明编译”可实现从指令级到整个程序层面的性能提升。该方法提供了一种新的视角，即可以直接从形式语义中自动提取优化规则，从而为程序优化提供了新的可能性。
## 579. `cs.CL` - .what makes LLM agent simulations useful for policy? insights from an iterative design engagement in emergency preparedness. [PDF](https://arxiv.org/pdf/2509.21868), [HTML](https://arxiv.org/abs/2509.21868)
### Authors
Yuxuan Li,Sauvik Das,Hirokazu Shirado
### Background
关于使用大型语言模型（LLM）代理进行社会模拟以指导政策制定的兴趣日益增加，但在实际应用中仍受到限制。这项研究在紧急应对团队中进行了为期一年的设计参与，目的是探索如何使LLM代理模拟真正对政策制定有所帮助，特别是在大规模聚集活动下的应急场景中模拟人群移动和通信。这些模拟影响了实际的政策实施，如志愿者培训、疏散计划和基础设施规划的设计。
### Innovation
研究通过多次迭代设计，开发了一个由13,000个LLM代理组成的系统，用于不同应急场景下模拟人群移动和通信。研究表明，在实际应用中，可以从可验证的场景开始，逐步建立信任，利用初步模拟激发潜在知识，并且将模拟和政策发展视为不断演进的过程。这些发现提供了一种使LLM代理模拟对政策制定真正有用的可行路径。
### Conclusion
研究发现强调了三条设计原则：从可验证的场景开始，逐步建立信任；依靠初步模拟来获取隐含知识；让模拟和政策制定共同发展。这三条原则为制作真正对政策有用的LLM代理模拟提供了实际的行动路径。
## 580. `cs.CL` - 你不能窃取不存在的东西：通过系统向量缓解LLM中的提示泄漏 [PDF](https://arxiv.org/pdf/2509.21884), [HTML](https://arxiv.org/abs/2509.21884)
### Authors
Bochuan Cao,Changjiang Li,Yuanpu Cao,Yameng Ge,Ting Wang,Jinghui Chen
### Background
大型语言模型（LLMs）在各种应用中广泛应用，通过自定义系统提示实现多样化任务。面对系统提示泄漏的风险，模型开发者采取措施进行预防，主要是在遇到已知攻击模式时，使LLMs无法重复上下文。然而，依然容易受到新的、未知的提示泄漏技术攻击。
### Innovation
本文首先介绍了一种简单但有效的提示泄漏攻击来揭示这些风险，并能够在各种基于LLM的应用中提取系统提示。在此基础上，提出了一种名为SysVec的新方法，将系统提示编码为内部表示向量，而不是原始文本，以最小化未经授权披露的风险并保留LLM的核心语言能力。该方法不仅增强了安全性，还改善了模型的通用指令遵循能力。实验结果表明SysVec有效缓解了提示泄漏攻击，保持了LLM的功能完整，并有助于解决长时间上下文中遗忘的问题。
### Conclusion
总之，本文提出了SysVec方法，通过将系统提示编码为内部表示向量，有效减轻了LLM的提示泄漏风险，同时提高了安全性和泛化指令遵循能力。
## 581. `cs.CL` - A2R: 一种用于并行推理的非对称两阶段推理框架 [PDF](https://arxiv.org/pdf/2509.22044), [HTML](https://arxiv.org/abs/2509.22044)
### Authors
Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen
### Background
近期的大规模推理模型通过在推理阶段分配更多计算资源，以‘思考更久’的范式实现了在复杂任务解决能力上的显著提升。尽管模型的基础推理能力飞速发展，但在单次尝试中的表现与潜在能力之间仍然存在显著差距，特别是在多个解题路径中才会展现出这种差距。这表明模型的实际能力和固有的潜在能力之间存在差距。
### Innovation
A2R框架是一种非对称两阶段推理框架，旨在明确弥合模型的潜在能力和实际表现之间的差距。首先，探索者模型并行生成潜在解决方案；其次，合成器模型整合参考以进行更为精确的第二阶段推理。此外，研究成果包括两种关键创新：第一，A2R框架作为一种插件即用的并行推理框架，能明显提高模型在复杂问题上的能力；第二，通过系统分析探索者和合成器的角色，发现了一种有效的非对称扩展模式，从而构建了更高效的A2R-Efficient模型。
### Conclusion
A2R不仅是一个性能提升框架，也是一种对于实际应用中既经济又实用的解决方案。使用A2R框架，Qwen3-8B-distill模型相比其一致性基线实现了75%的性能提升。通过合并Qwen3-4B探索者和Qwen3-8B合成器构建的A2R-Efficient模型，在成本几乎减少30%的情况下，超越了单一的Qwen3-32B模型的平均性能。
## 582. `cs.CL` - AgentPack: 一个由人类和代理共同编写的代码变更数据集 [PDF](https://arxiv.org/pdf/2509.21891), [HTML](https://arxiv.org/abs/2509.21891)
### Authors
Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha
### Background
以往对大型语言模型进行代码编辑微调主要依赖于提取提交记录和合并请求。工作假设是提交信息以自然语言描述了人类意图，而代码修补描述了实现该意图的变更。然而，大部分收集到的数据质量较低，提交信息简略且混杂，许多提交来自简单规则驱动的机器人。近期，软件工程代理的采用改变了这一状况，由人类和代理共同编写的代码变更通常更集中于明确的目标，而由这些变更自动生成的提交信息则详细地描述了意图和理由。此外，当这些变更公开时，人类维护者会将其过滤，丢弃质量低下的提交。
### Innovation
该研究提出了一个名为AgentPack的数据集，其中包含了从2025年中期到8月中旬公开的附有 Claude Code、OpenAI Codex 和 Cursor Agent 共同作者的130万代码变更。研究说明了数据集的识别和筛选流程，量化了代理软件的采用趋势，并分析了变更的结构属性。并证明了基于AgentPack微调的模型可以超越基于仅包含人类提交数据的模型，强调了使用软件工程代理生成的公开数据来训练未来的代码编辑模型的潜力。
### Conclusion
该研究表明，使用由软件工程代理生成的公开数据来训练代码编辑模型具有潜力。基于新的数据集AgentPack训练的模型显示出比仅基于人类提交数据的模型更优越的表现。这为进一步开发有效的代码编辑模型提供了新的视角。
## 583. `cs.CL` - MinerU2.5：基于拆分的高效高分辨率文档解析视觉语言模型 [PDF](https://arxiv.org/pdf/2509.22186), [HTML](https://arxiv.org/abs/2509.22186)
### Authors
Junbo Niu,Zheng Liu,Zhuangcheng Gu,Bin Wang,Linke Ouyang,Zhiyuan Zhao,Tao Chu,Tianyao He,Fan Wu,Qintong Zhang,Zhenjiang Jin,Guang Liang,Rui Zhang,Wenzheng Zhang,Yuan Qu,Zhifei Ren,Yuefeng Sun,Yuanhong Zheng,Dongsheng Ma,Zirui Tang,Boyu Niu,Ziyang Miao,Hejun Dong,Siyi Qian,Junyuan Zhang,Jingzhou Chen,Fangdong Wang,Xiaomeng Zhao,Liqun Wei,Wei Li,Shasha Wang,Ruiliang Xu,Yuanyuan Cao,Lu Chen,Qianqian Wu,Huaiyu Gu,Lindong Lu,Keming Wang,Dechen Lin,Guanlin Shen,Xuanhe Zhou,Linfeng Zhang,Yuhang Zang,Xiaoyi Dong,Jiaqi Wang,Bo Zhang,Lei Bai,Pei Chu,Weijia Li,Jiang Wu,Lijun Wu,Zhenxiang Li,Guangyu Wang,Zhongying Tu,Chao Xu,Kai Chen,Yu Qiao,Bowen Zhou,Dahua Lin,Wentao Zhang,Conghui He
### Background
当前存在一种需求，即能够高效解析高分辨率文档中的复杂内容，这需要模型同时具备优秀的解析准确性和计算效率。
### Innovation
提出了MinerU2.5，这是一种拥有1.2亿参数的文档解析视觉语言模型，能够在保持高效计算的同时达到前沿的识别准确性。该模型通过分层解析策略，首先进行粗略的布局分析，然后通过细化解析来提炼局部内容。此外，还研发了一套全面的数据引擎，用于生成大规模训练数据集，支持模型的预训练和微调。
### Conclusion
MinerU2.5证实了在文档解析方面的强大能力，它在多个基准测试中表现出色，超越了通用和专业领域模型在各类识别任务中的能力，同时计算开销显著降低。
## 584. `cs.CL` - Speak Your Mind：语音延续任务作为一种考察语音模型偏差的探针 [PDF](https://arxiv.org/pdf/2509.22061), [HTML](https://arxiv.org/abs/2509.22061)
### Authors
Shree Harsha Bokkahalli Satish,Harm Lameris,Olivier Perrotin,Gustav Eje Henter,Éva Székely
### Background
语音延续（SC）任务旨在生成一个与给定口语提示保持连贯性同时保留语义上下文和说话人身份的扩展。因SC任务局限于单一音频流，这为直接探究语音基础模型中的偏见提供了更直接的设置。当前研究是首次系统地评估SC任务中的偏见，探索性别和发音类型（沙哑、破音、结尾破音）如何影响延续行为。
### Innovation
本研究引入了语音延续任务作为探查基于语音的模型偏见的一种新方法，特别评估了三种近期模型在说话人相似性、语音质量保留和基于文本的偏见指标方面的表现。研究揭示了语音延续任务可作为探究社会相关表示偏见的一种控制探针，并提示随着延续质量的提高，这种任务将成为一项越来越有信息量的诊断手段。
### Conclusion
结果表明，尽管说话人相似性和连贯性仍然是挑战，但文本评估揭示了显著的模型和性别相互作用：在VAE-GSLM中结果足够高时，性别将对文本指标（如自主性和句子极性）产生影响。此外，对于女性提示，延续行为倾向于回归至典型的音质，揭示了一种系统性的音质偏见。这些发现强调了SC任务在研究语音基础模型中社会相关表示偏见方面的重要性，并表明当延续质量提高时，该任务将成为一种越来越有信息量的诊断工具。
## 585. `cs.CL` - 评估开源大型语言模型在技术电信问答中的应用 [PDF](https://arxiv.org/pdf/2509.21949), [HTML](https://arxiv.org/abs/2509.21949)
### Authors
Arina Caraus,Alessio Buscemi,Sumit Kumar,Ion Turcanu
### Background
大型语言模型（LLMs）在多个领域中已展现出卓越的能力，但在诸如电信这样的技术领域中的应用仍处于探索阶段。本文探讨了开源LLM Gemini 3（27B）和DeepSeek R1（32B）在基于高级无线通信资料的问题的实战性表现和推理能力。研究者构建了一套包含105个问题和答案对的标准基准，并通过词汇匹配度、语义相似性和LLM评分三种方式来评估模型。此外，研究还分析了致因来源的一致性、判断可靠性以及幻觉现象等潜在问题。结果表明，Gemini在语义忠实度和LLM评定的正确性方面表现突出，而DeepSeek则在词汇一致性上略胜一筹。研究还指出现有技术在电信领域的局限性，并强调了为了支持工程领域的可信赖人工智能助手而研发领域定制化模型的重要性
### Innovation
本文首次系统性地评估了开源LLM在电信技术问题和推理任务中的应用情况，并通过全面的评价指标展示了两模型之间的微妙差异。研究还引入了一种多层次的方法来评估模型的可靠性和一致性，这为后续相关领域的工作提供了新的研究视角和方法论参考
### Conclusion
研究结果表明，尽管开源LLM在语义理解和判断正确性上表现出色，但在代表性词汇的一致性上仍有不足，为此电信领域特异性问题提供了新的视角，并指明了未来模型优化的方向。
## 586. `cs.CL` - LLMs中的库幻觉：基于开发者查询的风险分析 [PDF](https://arxiv.org/pdf/2509.22202), [HTML](https://arxiv.org/abs/2509.22202)
### Authors
Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis
### Background
近年来，大型语言模型（LLMs）被广泛用于生成代码，但在生成过程中常常会出现幻觉现象，即创造不存在的库。这种库幻觉不仅仅是无害的错误，它们可能导致开发者误解，导致构建失败，并使系统面临供应链威胁，如滴灌攻击。尽管这些风险意识逐渐增强，但仍不清楚现实用户提示的变化如何影响LLM中的幻觉频率。
### Innovation
本文首次系统研究了用户层次提示变化如何影响由LLM生成的代码中的库幻觉。评估了六种不同的LLM，并研究了来自开发者论坛的自然语言和不同程度的用户错误（如一个或多个字符的拼写错误以及完全虚构的名字/成员）如何影响LLM的幻觉频率。
### Conclusion
研究结果揭示了系统性漏洞：一个字符错拼的库名在高达26%的任务中触发幻觉，假库名在高达99%的任务中被接受，与时间相关的提示在高达84%的任务中导致幻觉。提示工程有望减轻幻觉但依旧不一致且依赖于特定的LLM。结果强调了LLMs对自然提示变化的脆弱性，并强调了迫切需要防止与库相关幻觉及可能的利用以确保安全的必要性。
## 587. `cs.CL` - 合成查询重写能否比人类更好地捕获生成增强检索中的用户意图？ [PDF](https://arxiv.org/pdf/2509.22325), [HTML](https://arxiv.org/abs/2509.22325)
### Authors
JiaYing Zheng,HaiNan Zhang,Liang Pang,YongXin Tong,ZhiMing Zheng
### Background
多回合RAG系统经常面临带有口语省略和歧义引用的查询，这对有效的检索和生成提出了重大挑战。传统的查询重写依赖于人类注释者来澄清查询，但由于注释者的表达能力和理解深度有限，手工重写的查询往往与真实世界RAG系统所需要的严重不同，导致用户意图与系统响应之间存在差距。我们观察到高质量的合成查询能更好地弥合这一差距，实验证实其在检索和生成任务中的表现优于人类重写。
### Innovation
提出了一种基于合成数据的查询重写模型SynRewrite，用于生成更符合用户意图的高质量合成重写。通过提示GPT-4o生成高质量重写，并使用Flan-T5模型进行微调，进而通过DPO算法增强重写器以提升最终任务表现。
### Conclusion
在TopiOCQA和QRECC数据集上的实验表明，SynRewrite在检索和生成任务中均优于人工重写。研究结果表明，合成重写可以作为一种可扩展且有效的替代人类注释的方案。
## 588. `cs.CL` - PRIME：Planning and Retrieval-Integrated Memory for Enhanced Reasoning [PDF](https://arxiv.org/pdf/2509.22315), [HTML](https://arxiv.org/abs/2509.22315)
### Authors
Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu
### Background
该论文受到人类认知双重过程理论《Thinking, Fast and Slow》的启发，旨在设计一个多智能体推理框架，旨在动态整合快速直觉思维（System 1）和缓慢深入思维（System 2）。智能体首先使用快思考代理快速生成答案，当检测到不确定性时，会触发一个由专门规划、假设生成、检索、信息整合和决策等智能体组成的结构化System 2推理管道。这种方法通过模仿人类认知过程，提高了效率和准确性。
### Innovation
该研究提出了PRIME框架，其创新点在于多智能体设计，能够动态集成两种不同类型的认知过程，即快速直觉性思维和缓慢深思熟虑性思维。这种设计有效地模拟了人类的认知过程，并提高了效率和准确性。实验结果显示，PRIME使得开源的语言模型在多步骤和基于知识的推理基准测试中能够与最先进的闭源模型如GPT-4和GPT-4o竞争。
### Conclusion
该研究证实了PRIME作为解决需要复杂、知识密集型推理的领域中提高大型语言模型性能的一种可扩展解决方案的有效性。
## 589. `cs.CL` - ERGO: 高效高分辨率视觉理解的视觉语言模型 [PDF](https://arxiv.org/pdf/2509.21991), [HTML](https://arxiv.org/abs/2509.21991)
### Authors
Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim
### Background
高效的高分辨率图像处理对于实际的视觉-语言应用至关重要。现有大规模视觉-语言模型（LVLMs）由于视觉标记过多而带来了巨大的计算开销。随着“基于图像思考”的模型的出现，推理不仅局限于文本，还扩展到了视觉领域。基于此，本文提出了一个两阶段的“粗细结合”的推理框架：首先对下采样的图像进行分析，以识别与任务相关的关键区域；然后在这些关键区域进行全分辨率裁剪和后续的推理处理。这种方法在保留细度的视觉细节的同时减少了计算成本。主要挑战是确定哪些区域与给定的查询真正相关。现有的相关方法往往在输入图像下采样后的第一阶段推理中失败，因为推理依赖清晰的视觉信息。为解决此问题，本文提出的ERGO（Efficient Reasoning & Guided Observation）通过利用感知驱动的多模态上下文来进行推理驱动的可视化辅助决策，以确定重点区域。ERGO能够处理感知不确定性，扩大裁剪区域以覆盖视觉模糊区域来回答问题。
### Innovation
本文创新地提出了ERGO（Efficient Reasoning & Guided Observation），通过推理驱动的感知辅助方法来确定关键区域，增强了在模糊视觉信息处理中的准确性。ERGO在多种数据集上显示出更高的准确性和效率，相较于原模型和竞争方法，减少了视觉标记使用比例并提升了推理速度。例如，ERGO在V*基准测试上相较于Qwen2.5-VL-7B超越4.7个百分点，使用了23%的视觉标记并实现了3倍的推理加速。
### Conclusion
总之，本文通过提出的ERGO方法，显著提升了视觉-语言模型在高分辨率图像处理的能力，通过更为高效的推理处理方式，既保证了准确性又大幅提升了效率。这一方法具有较大的实际应用价值。
## 590. `cs.CL` - 将Kolmogorov复杂性和深度学习相结合：Transformer的渐进最优描述长度目标 [PDF](https://arxiv.org/pdf/2509.22445), [HTML](https://arxiv.org/abs/2509.22445)
### Authors
Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova
### Background
最小描述长度（MDL）原则为应用奥卡姆剃刀定理提供了一个正式框架。其在神经网络，尤其是变换器模型上的应用由于缺乏模型复杂性的原则性、通用度量而具有挑战性。
### Innovation
本文提出了渐进最优的描述长度目标的理论概念，基于科尔莫哥洛夫复杂性理论。证明了这种目标在模型资源限制增加时，对于任意数据集具有最优压缩率，而且存在渐进最优的目标对于变换器模型。进一步构建并分析了一个基于适应性高斯混合先验的可计算且可微的目标函数，实验表明该目标函数能够选择出具有低复杂性和强泛化能力的解，而常用的优化器却难以从随机初始化找到这样的解，突出优化挑战。
### Conclusion
通过提供一个能够识别具有强渐近保证描述长度目标的理论框架，本文为训练能够实现更好压缩和泛化的神经网络提供了潜在路径。
## 591. `cs.CL` - RISK: 在电子商务风险管理中用于图形用户界面代理的框架 [PDF](https://arxiv.org/pdf/2509.21982), [HTML](https://arxiv.org/abs/2509.21982)
### Authors
Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen
### Background
电子商务风险管理工作需要通过多步、状态依赖的交互来聚合多样化的网络数据，而传统抓取方法和大多数现有的图形用户界面（GUI）代理无法处理这种任务。这些代理通常仅限于单步骤任务，缺乏有效风险管理所需的动态交互内容的管理能力。
### Innovation
本文提出了一种名为RISK的新型框架，用于构建和部署电子商务风险管理领域的GUI代理。RISK整合了三个组件：（1）RISK-Data，包含8,492个单步骤和2,386个多步骤交互轨迹的数据集，通过高保真浏览器框架和细致的数据整理过程收集；（2）RISK-Bench，包含三个难度级别的802个单步骤和320个多步骤轨迹的标准评估基准；（3）RISK-R1，一种考虑四个方面的R1风格强化学习微调框架：输出格式、单步骤层次、多步骤层次和任务层次。实验表明，RISK-R1在离线单步骤任务上提高了6.8%，在离线多步骤任务上提高了8.8%，并在在线评估中达到了70.5%的任务成功率。RISK为自动化复杂网络交互提供了一种可扩展且特定领域的解决方案，推动了电子商务风险管理领域的前沿技术发展。
### Conclusion
RISK提供了一种可扩展且特定领域的解决方案，以自动化复杂的网络交互，推进了电子商务风险管理领域的现状。
## 592. `cs.CL` - AI Coaching 准备我们进行职场谈判吗？ [PDF](https://arxiv.org/pdf/2509.22545), [HTML](https://arxiv.org/abs/2509.22545)
### Authors
Veda Duddu,Jash Rajesh Parekh,Andy Mao,Hanyi Min,Ziang Xiao,Vedant Das Swain,Koustuv Saha
### Background
职场谈判受到心理障碍的影响，这些障碍有时会抵消精心准备的策略。尽管人工智能（AI）能提供个性化且随时可用的谈判教练，其在准备谈判有效性方面的作用仍不明确。这项研究构建了Trucey，一种基于布莱特谈判模型的AI原型教练，并进行了分组实验，探讨了AI在帮助谈判准备方面的效果。
### Innovation
本研究创新之处在于，构建了Trucey这一个AI谈判教练原型，并通过与传统谈判手册和ChatGPT的对比实验，验证了AI在谈判准备方面的效果。研究发现，AI在减少谈判恐惧方面更具优势，但传统手册在易用性和心理赋能方面表现更佳。
### Conclusion
尽管AI具备排练能力等优势，但在指导上显得冗长且碎片化，反而使得参与者感到困惑或压力。这些发现挑战了AI在谈判准备中绝对优势的观点，并提示未来应发展集结构化理论驱动内容、针对性排练、清晰界限和自适应支持于一体的混合设计，以应对心理障碍并支持谈判准备。
## 593. `cs.CL` - SecureAgentBench: 在真实漏洞场景下评估安全代码生成 [PDF](https://arxiv.org/pdf/2509.22097), [HTML](https://arxiv.org/abs/2509.22097)
### Authors
Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo
### Background
大型语言模型（LLM）驱动的代码代理正在迅速改变软件工程，通过自动化测试、调试和修复等任务，但生成的代码的安全风险已成为一个重要关注点。现有基准虽然提供了有价值的见解，但仍然不足：它们经常忽略漏洞实际引入的上下文，或采用狭隘的评估协议，无法全面评估功能正确性和新增漏洞。
### Innovation
介绍了SecureAgentBench，这是一个包含105个编码任务的基准，旨在严格评估代码代理在安全代码生成方面的能力。每个任务都包括：（i）需要在大型代码库中进行多文件编辑的现实任务设置；（ii）基于真实世界开源漏洞的对齐上下文，具有精确识别的引入点；（iii）结合功能测试、通过概念验证的漏洞检测和静态分析检测新增漏洞的全面评估。
### Conclusion
现有代理在安全代码生成方面表现不佳，即使最好的SWE-agent（支持DeepSeek-V3.1）也只能实现15.2%的正确且安全的解决方案。某些代理虽产生功能正确的代码但仍引入漏洞，包括未记录的新漏洞。此外，为代理添加明确的安全指令并未显著提升安全编码。这些发现将SecureAgentBench确立为安全代码生成的严格基准，助力更可靠的LLM支持软件开发。
## 594. `cs.CL` - 从偏差到平衡：探索和减轻LVLMs的空问偏差 [PDF](https://arxiv.org/pdf/2509.21984), [HTML](https://arxiv.org/abs/2509.21984)
### Authors
Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Weili Guan,Jun Yu,Min Zhang
### Background
大视觉-语言模型（LVLMs）在多种跨模态任务中取得了显著的成功，然而它们对空间变化的鲁棒性仍然不够明确。本研究系统性地探讨了LVLMs的空间偏差，特别关注模型在图像中将相同的关键视觉信息置于不同位置时的响应。研究表明，当前的LVLMs在这种空间偏移下经常产生不一致的结果，揭示了它们在空间语义理解方面的基本局限性。进一步的分析发现，这一现象不是由视觉编码器造成的，因为视觉编码器能够可靠地感知和解释跨位置的视觉内容，而是由语言模型组件中的位置嵌入设计不平衡引起的。
### Innovation
研究引入了一种简单的有效机制——平衡位置分配（BaPA），该机制将同一位置嵌入分配给所有的图像标记，从而促进视觉信息的更平衡整合。实验显示，BaPA在不重新训练的情况下增强了LVLMs的空间鲁棒性，并在结合轻量级微调后进一步提高了其在多种跨模态基准测试中的性能。此外，信息流分析表明，BaPA产生平衡注意力，有助于更全面的视觉理解。
### Conclusion
这项研究揭示了LVLMs的空间偏差问题，并提出了一种简单有效的解决方案——BaPA，该方案有助于平衡视觉信息的整合，增强模型的空间鲁棒性。实验表明，这种策略不仅可以在不重新训练模型的情况下实施，还能有效提升其性能。
## 595. `cs.CL` - 思考的光谱：通过模型合并实现LLMs可调推理能力的经验研究 [PDF](https://arxiv.org/pdf/2509.22034), [HTML](https://arxiv.org/abs/2509.22034)
### Authors
Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li
### Background
在众多实际应用场景中对具备可调推理能力的大型语言模型（LLMs）的需求日益增长，凸显出急需有效方法以高效地产生平衡推理深度与计算成本的模型谱系的必要性。模型合并已经作为一种无训练的方法，通过算术合并通用模型和专门推理模型的权重而成为解决这一挑战的有希望的技术。然而，尽管存在多种合并技术，它们如何能够创建具有精细控制推理能力的可调模型谱系仍缺乏深入研究。
### Innovation
本研究通过对多种推理基准测试中多种模型合并技术的大规模经验研究，系统性地调整合并强度以构建准确率与效率曲线，首次全面展示了可调性能的场景。研究揭示，模型合并提供了一种有效的且可控的方法来校准推理准确性和标记效率之间的权衡，即使父母模型的权重空间差异很大。尤为重要的是，研究识别了帕累托改进情况，即合并模型同时实现更高的准确性和更低的标记消耗。
### Conclusion
本研究提供了可调空间的首次全面分析，为创建满足不同应用需求的具有特定推理特征的LLM提供了实用指南。
## 596. `cs.CL` - 使用二维高斯溅射从压缩图像表示实现视觉语言对齐 [PDF](https://arxiv.org/pdf/2509.22615), [HTML](https://arxiv.org/abs/2509.22615)
### Authors
Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe
### Background
现代视觉语言管道由训练在大量图像文本数据集上的RGB视觉编码器驱动。尽管这些管道在零样本能力和跨任务的强大转移方面取得了显著的成果，但它们仍继承了像素域的两个结构效率低下：一是将密集的RGB图像从边缘设备传输到云端既费能又昂贵；二是基于块的分词导致序列长度爆炸，增加了注意力预算和上下文限制的压力。
### Innovation
作者探索了二维高斯溅射（2DGS）作为替代视觉基底的可能性：一种紧凑、空间自适应的表示方式，通过对一系列彩色各向异性高斯函数的参数化来构建图像。本文开发了一个可扩展的2DGS管道，包括结构化初始化、亮度感知剪枝和批次CUDA内核，实现了比先前方法快90多倍的拟合速度，同时GPU利用率约为97%。作者还通过重新利用冻结的基于RGB的变压器主干，使用轻量级溅射感知输入茎和感知重采样器，将对照特征语言图像预训练（CLIP）应用于2DGS，仅训练大约7%的总参数。在大型DataComp子集上，GS编码器在压缩输入3到20倍的情况下，仍能实现与RGB编码器相近的零样本ImageNet-1K性能。
### Conclusion
虽然当前的准确性略逊于RGB编码器，但研究结果确立了2DGS作为多模态基底的可行性，揭示了架构瓶颈，并为同时具有语义能力和传输效率的边缘云计算表示提供了路径。
## 597. `cs.CL` - 掌握策略，再依赖成功：带有渐进探索的自我模仿强化学习 [PDF](https://arxiv.org/pdf/2509.22601), [HTML](https://arxiv.org/abs/2509.22601)
### Authors
Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun
### Background
强化学习（RL）在提升大模型（LLMs）长期目标、稀疏奖励任务的战略工具使用能力方面占据主导地位，但探索-利用权衡是其面临的基本挑战。现有的研究通过策略熵的方式来刺激探索，但这可能导致由于多轮分布变动带来的RL训练不稳定问题。本文旨在通过引导代理自身的经验，在不陷入熵塌缩或发散的困境中，实现渐进的探索-利用平衡。
### Innovation
本文提出了SPEAR，一种基于课程的自我模仿学习（SIL）方法。SPEAR通过逐步引导策略演变，在多个阶段维持一个平衡的熵范围，来实现这一目标。具体而言，该方法引入了一个课程来管理探索过程，使用内在奖励促进技能级别探索，并通过SIL促进动作级别的探索。此外，作者通过引入经验在重放缓冲区中的优势重新校准机制，并通过轨迹级别的熵控制引入正则化，如剪裁高协方差的tokens，以稳定训练过程。
### Conclusion
SPEAR能够在提升生成型强化学习能力的同时，确保训练的稳定性和逐渐地探索-利用平衡。这种方法通过一系列精心设计的优化策略，显著提高了代理的性能，适应了更加复杂的任务环境。
## 598. `cs.CL` - IA2: 通过ICL激活模式改进监督微调 [PDF](https://arxiv.org/pdf/2509.22621), [HTML](https://arxiv.org/abs/2509.22621)
### Authors
Aayush Mishra,Daniel Khashabi,Anqi Liu
### Background
监督微调（SFT）通过训练权重以对特定查询产生预期的目标响应来特化模型行为。相比之下，上下文学习（ICL）在推理时通过指令或演示中的提示来调整模型，这种方式在数据稀缺的情况下能提供更好的泛化性和更具校准性的响应，但代价是增加了推理计算的需要。本研究探讨了是否可以通过利用ICL的内部计算来改进SFT的质量。
### Innovation
研究发现ICL和SFT在激活模式上有显著区别，表明两者通过不同的功能机制实现了适应。基于此观察，研究引入了一种新的自我蒸馏技术——ICL激活对齐（IA2），旨在使SFT模型复制ICL的激活模式，并促进类似ICL的内部推理。在12个流行基准和2个模型家族上进行的广泛实验证明，在SFT之前作为预热步骤执行IA2可以显著提高模型输出的准确性和校准性。
### Conclusion
这一发现不仅在实践中是有用的，还为理解模型适应的内部机制提供了一扇窗口。
## 599. `cs.CL` - 通过多模态LLMs学习AI生成视频中的感知假象 [PDF](https://arxiv.org/pdf/2509.22646), [HTML](https://arxiv.org/abs/2509.22646)
### Authors
Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch
### Background
随着视频生成模型的迅速发展，一个关键维度却未得到广泛关注，即人类是否能够识别出AI生成视频中的虚假痕迹，例如揭示视频为机器生成的时空视觉特征。现有研究大多忽略了这一方面，因此有必要开发一个细粒度的、时空感知的基准，来标注人类感知到的虚假痕迹，用于视频生成的奖励机制，以更好地评估与提升生成模型的质量。
### Innovation
提出了DeeptraceReward，这是首个细粒度、时空感知的标准基准，注释了4300个高质量生成视频中的人类感知的虚假痕迹，包括自然语言解释、边界框区域标注以及精确的时间戳。该基准将这些注释归纳为9大类虚假痕迹，训练多模态语言模型（LMs）作为奖励模型，以模拟人类的判断和定位。实验结果显示，7B规模的奖励模型在AI生成视频的虚假线索识别、定位和解释上，相比GPT-5平均性能提升了34.7%。同时，研究发现，二元化的假与真分类显著比细粒度的虚假痕迹检测容易；在后者中，理解自然语言解释是最简单的，而时空定位是最困难的。
### Conclusion
通过强调人类感知到的虚假痕迹，DeeptraceReward提供了一个严格的测试平台和训练信号，用于促进社交意识强和可信赖的视频生成。
## 600. `cs.CL` - 迈向强化学习人类反馈高效在线探索 [PDF](https://arxiv.org/pdf/2509.22633), [HTML](https://arxiv.org/abs/2509.22633)
### Authors
Gen Li,Yuling Yan
### Background
强化学习与人类反馈（RLHF）是一种从人类偏好数据中学习奖励模型并优化策略以偏好人类喜欢的响应的方法，已逐渐成为使大型语言模型（LLMs）与人类偏好对齐的核心范式。本研究集中在在线RLHF的探索原则上，即通过自适应收集新的偏好数据以高效地细化奖励模型和策略。
### Innovation
基于现有乐观探索算法的分析发现，它们在样本协议中存在一个问题：倾向于收集不能减少奖励差异中最信息性的不确定性对比。因此，提出了新的探索方案，该方案将偏好查询导向减少与策略改进最相关的奖励差异的不确定性。通过多臂 bandit 模型研究 RLHF，在一定的超参数设置下（平衡奖励最大化与减少分布偏移两者），建立了线性复杂度的后悔界。这是首个所有模型参数呈多项式缩放的在线 RLHF 算法。
### Conclusion
该研究提出了一种新的探索机制，能够有效地优化奖励模型和策略，并且提出了第一个在线 RLHF 算法，其后悔界为 $T^{(beta+1)/(beta+2)}$，展示了与现有方法相比的性能改进。
## 601. `cs.CL` - InfiMed-Foundation: 引领高性能计算且训练高效的多模态医疗模型及多阶段微调 [PDF](https://arxiv.org/pdf/2509.22261), [HTML](https://arxiv.org/abs/2509.22261)
### Authors
Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang
### Background
多模态大型语言模型（MLLMs）在多个领域展现了显著的潜力，但它们在医学领域的应用受到了几个挑战的阻碍。通用的MLLMs缺乏执行医学任务所需的专门知识，导致不确定或妄想的回答。从高级模型的知识蒸馏也难以捕捉放射学和药学等领域的专业技能。此外，使用大规模医疗数据进行持续预训练的计算成本带来了显著的效率挑战。
### Innovation
我们提出了InfiMed-Foundation-1.7B和InfiMed-Foundation-4B两种专用于医疗的MLLMs，旨在实现医疗应用中的顶级性能。我们结合了高质量的一般性和医疗多模态数据，并提出了一个新的五维质量评估框架来创建高质量的多模态医疗数据集。我们采用低到高的图像分辨率和多模态序列打包来提高训练效率，从而使集成大量医疗数据成为可能。此外，我们实施了三阶段监督微调过程以确保有效提取复杂医学任务的知识。InfiMed-Foundation-1.7B在MedEvalKit框架上优于Qwen2.5VL-3B，而InfiMed-Foundation-4B优于HuatuoGPT-V-7B和MedGemma-27B-IT，展示了在医疗视觉问答和诊断任务中的优越性能。通过解决数据质量、训练效率和领域特定的知识提取中的关键问题，我们的工作为在医疗保健领域实现更可靠和有效的AI驱动解决方案铺平了道路。
### Conclusion
通过解决数据质量、训练效率和领域特定的知识提取中的关键问题，我们的研究为在医疗保健领域实现更可靠和有效的AI驱动解决方案铺平了道路。InfiMed-Foundation-4B模型可以在 [这个网址] 找到。
## 602. `cs.CL` - IIET: 通过隐式迭代欧拉方法的高效数值Transformer [PDF](https://arxiv.org/pdf/2509.22463), [HTML](https://arxiv.org/abs/2509.22463)
### Authors
Xinyu Liu,Bei Li,Jiahao Liu,Junhao Ruan,Kechen Jiao,Hongyin Tang,Jingang Wang,Xiao Tong,Jingbo Zhu
### Background
高阶数值方法可以提升Transformer在NLP和CV任务中的性能，但会引入计算效率与性能之间的权衡，因为增加了计算开销。传统的效率提升技术，如知识蒸馏（distillation），可能会损害这些模型的性能，例如PCformer就是一个例子。为了探索可优化的基于ODE的Transformer架构，作者提出了IIET（Iterative Implicit Euler Transformer），这是一种用迭代隐式欧拉方法简化高阶方法的Transformer架构，这不仅提升了模型的性能，还相比PCformer更容易进行模型压缩。为了提高推理效率，作者还提出了IIAD（Iteration Influence-Aware Distillation），通过一个灵活的阈值，它使用户能够权衡性能和效率。
### Innovation
作者提出了IIET（Iterative Implicit Euler Transformer），即用迭代隐式欧拉方法简化高阶方法的Transformer架构，这不仅提升了模型的性能，还相比PCformer更容易进行模型压缩。此外，作者还引入了IIAD（Iteration Influence-Aware Distillation），一个通过灵活阈值调整的蒸馏方法，以权衡性能和效率。这些创新方法使得模型在保持较高任务准确率的同时，显著降低了推理开销。
### Conclusion
在lm-evaluation-harness上，IIET相比vanilla Transformer平均提高了2.65%的准确性，相比PCformer提高了0.8%。其高效的变体，E-IIET，在保持99.4%的任务准确性的同时，推理开销降低了55%。研究表明，最高效的IIET变体在与vanilla Transformer相当的速度下，实现了平均超过1.6%的性能改进。
## 603. `cs.CL` - AI伴侣对心理健康的影响：社会媒体准实验、用户视角和关系理论的三角验证 [PDF](https://arxiv.org/pdf/2509.22505), [HTML](https://arxiv.org/abs/2509.22505)
### Authors
Yunhao Yuan,Jiaxun Zhang,Talayeh Aledavood,Renwen Zhang,Koustuv Saha
### Background
人工智能驱动的同伴聊天机器人（AICCs）如Replika越来越受欢迎，提供情感交互，但其社会心理影响尚不明确。本研究旨在探讨与AICCs互动如何影响幸福感，并了解用户的这些体验感知。首先，通过大规模准实验研究纵向Reddit数据，应用分层倾向得分匹配和双重差分回归。结果显示，AICCs对情绪表达、可读性和人际焦点有积极影响，同时也增加了孤独感和自杀念头的表达。其次，通过15次半结构化访谈补充这些结果，并用Knapp的关系发展模型进行定性分析。结果显示，AICCs提供了情感验证和社会练习，但也存在过度依赖和疏远的风险。结合方法论结果，提出了对健康边界、有意识参与、无依赖情感表露和显示关系阶段的设计建议，以最大化社会心理益处并降低风险.
### Innovation
本研究通过结合大规模准实验数据分析、用户访谈和关系理论分析的方法，提供了对AICCs社会心理影响的深入理解，揭示了其积极和潜在的负面影响，强调了健康边界的重要性，并提出了具体的设计建议，以促进更积极的用户互动和关系发展。
### Conclusion
研究表明，与AICCs互动对用户的心理健康有复杂的影响，既有积极的一面，如情感验证和社交练习，也有潜在风险，如过度依赖和疏远。设计AI伴侣时应谨慎平衡这些因素，建议包括：建立健康边界、促进有意识参与、避免情感依赖以及展示关系发展阶段，以最大化潜在的心理社会益处并减少风险。
## 604. `cs.CL` - MDAR: 多场景动态音频推理基准 [PDF](https://arxiv.org/pdf/2509.22461), [HTML](https://arxiv.org/abs/2509.22461)
### Authors
Hui Li,Changhao Jiang,Hongyu Wang,Ming Zhang,Jiajun Sun,Zhixiong Yang,Yifei Cao,Shihan Dou,Xiaoran Fan,Baoyu Fan,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
音频推理能力，包括语音、副语言提示、环境声和音乐，对于AI代理在真实世界场景中有效交互至关重要。现有的基准主要关注静态或单场景设置，未能全面捕捉多个说话者、事件发展和异质音频来源交互的场景。这给现有的模型带来了挑战，需要新的基准测试来评估和改进这些复杂的音频推理任务能力。
### Innovation
为应对这些挑战，作者引入了MDAR（多场景动态音频推理基准），这是一个针对复杂、多场景和动态发展的音频推理任务进行评估的基准。MDAR包含3000个精心策划的问题-答案对，与多样的音频片段相关联，覆盖五类复杂的推理类别，并跨越三种问题类型。在基准测试中，26个最先进的音频语言模型表现出局限性于复杂的推理任务，在单一选择问题上，Qwen2.5-Omni（开源）准确率为76.67%，而GPT-4o Audio（封闭源）为68.47%；但在更具挑战性的多项选择和开放式任务上，GPT-4o Audio大幅超越Qwen2.5-Omni。在所有三种问题类型中，没有模型达到80%的性能。这些发现强调了MDAR的独特挑战及其在推进音频推理方面的价值。
### Conclusion
MDAR通过提供一个包含复杂、多场景和动态发展的音频推理任务的新基准，突显了现有模型在处理复杂音频推理任务时面临的挑战，并强调了其作为推进音频推理的基准的价值。这些结果表明，需要进一步的研究来改进现有的音频语言模型，以克服这些复杂任务中的独特挑战。相关数据集可在相关链接下载。
## 605. `cs.CL` - 利用大型语言模型进行成分解析 [PDF](https://arxiv.org/pdf/2310.19462), [HTML](https://arxiv.org/abs/2310.19462)
### Authors
Xuefeng Bai,Jialong Wu,Yulong Chen,Zhongqing Wang,Kehai Chen,Min Zhang,Yue Zhang
### Background
成分解析是自然语言处理中的基本但未解决的挑战。本文探讨了最近的大型语言模型（LLMs）如何解决这一挑战。
### Innovation
本文将成分解析重新格式化为序列到序列的生成问题，并评估了多种LLMs在零样本、少量样本和监督微调学习范式下的性能。本文还提出了两种策略来指导LLMs生成更准确的成分树：通过从错误样本中学习进行训练以及在多智能体协作方式下改进输出。
### Conclusion
实验结果表明，本文的方法有效地减少了无效和不忠实的树的出现，从而提高了整体解析性能，并在不同的学习范式下取得了令人满意的结果。
## 606. `cs.CL` - EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning [PDF](https://arxiv.org/pdf/2509.22576), [HTML](https://arxiv.org/abs/2509.22576)
### Authors
Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris
### Background
多轮环境下的训练LLM代理并以稀疏奖励完成任务，这在强化学习中是一个根本性的挑战，因为这30多次交互可能涉及的策略探索和执行过程复杂，需要准确的策略优化方法。
### Innovation
提出了一种名为Entropy-regularized Policy Optimization (EPO)的通用框架，通过三重协同机制解决多轮环境中的探索与利用瀑布失败：（1）在多轮环境中使用熵正则化以增强探索，（2）引入熵平滑正则化以在历史平均值内限制策略熵，防止急剧波动，（3）适应不同的训练阶段加权，平衡探索与利用。
### Conclusion
EPO 确保熵方差单调减少并维持收敛，显著提升了ScienceWorld和ALFWorld上的性能，分别提高了152%和19.8%。这项工作表明，多轮稀疏奖励环境需要不同于传统RL的熵控制方法，对该领域有着广泛的影响，适用于LLM代理训练。
## 607. `cs.CL` - 动态专家搜索：增强专家混合模型在测试时的推理能力 [PDF](https://arxiv.org/pdf/2509.22572), [HTML](https://arxiv.org/abs/2509.22572)
### Authors
Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang
### Background
Test-Time Scaling (TTS)通过在推理时分配额外的计算来增强大型语言模型（LLMs）的推理能力。然而，现有的方法主要依赖于输出级别的采样，而不是考虑模型架构的作用。在主流的专家混合模型（MoE）中，通过改变激活专家的数量可以产生具有稳定准确性的互补解决方案集，揭示出一种新的未被充分探索的多样性来源。基于这一观察，本文提出了一种新的TTS策略——动态专家搜索（DES），该策略将专家激活提升为搜索空间中的可控维度。DES结合了两个关键模块：动态MoE和专家配置继承。
### Innovation
DES策略将专家激活作为搜索空间中的可控维度，该策略包含了动态MoE和专家配置继承两个关键技术模块。动态MoE允许在推理过程中直接控制专家的数量以生成多样性的推理路径，而不会增加成本。专家配置继承则保持推理路径内的专家数量一致，但在不同求解过程中改变专家数量，从而在整个搜索过程中平衡稳定性和多样性。广泛的实验表明，DES在多种MoE架构和推理基准上显著优于现有的TTS基线，提高了准确性和稳定性且无需额外成本。这些结果表明，DES是一种面向架构的实用且可扩展的TTS形式，展示出了现代LLMs的结构灵活性如何推进推理能力。
### Conclusion
本文的研究成果表明，DES作为一种面向架构的TTS策略，在提高推理准确性的同时维持稳定性，且不增加成本。该策略通过动态调整MoE中的专家数量，提供了更高的推理灵活性和多样性。
## 608. `cs.CL` - LLMAEL：大型语言模型是实体链接上下文增强的良好工具 [PDF](https://arxiv.org/pdf/2407.04020), [HTML](https://arxiv.org/abs/2407.04020)
### Authors
Amy Xin,Yunjia Qi,Zijun Yao,Fangwei Zhu,Kaisheng Zeng,Xu Bin,Lei Hou,Juanzi Li
### Background
专有实体链接（EL）模型能够很好地将提及的名称映射到知识库（KB）中的唯一实体，但难以区分长尾实体，因为它们的训练数据有限。与此同时，广泛预训练的大规模语言模型（LLMs）具有更广泛的知识覆盖面，特别是关于不常见的实体。然而，由于缺乏专门的EL训练，LLMs在生成准确的KB实体名称时经常失败，限制了它们在EL任务中的独立效果。观察到LLMs在上下文生成方面更具优势而不是执行EL任务，本文提出了一种将LLMs用于内容增强的LLMAEL框架，该框架首次利用现成且无需微调的LLMs作为上下文增强工具，生成实体描述作为专门EL模型的额外输入。实验表明，LLMAEL在6个广泛采用的EL基准测试中取得了新的最佳效果，相较之前将现成LLMs集成到EL中的方法，LLMAEL在准确性的绝对值上提高了8.9%。
### Innovation
引入了LLMAEL框架，利用现成且无需微调的LLMs作为上下文增强工具，生成实体描述作为专门EL模型的额外输入，首次将LLMs用于增强EL任务。实验结果显示，相对于以前的方法，LLMAEL在6个广泛采用的EL基准测试中取得了显著的准确性提升。
### Conclusion
本文提出LLMAEL框架，在6个广泛采用的EL基准测试中取得了新的最佳效果，相较之前的方法，LLMAEL在准确性的绝对值上提高了8.9%。我们还发布了我们的代码和数据集。
## 609. `cs.CL` - LABELING COPILOT: 一种用于计算机视觉的自动化数据治理深度研究代理 [PDF](https://arxiv.org/pdf/2509.22631), [HTML](https://arxiv.org/abs/2509.22631)
### Authors
Debargha Ganguly,Sumit Kumar,Ishwar Balappanawar,Weicong Chen,Shashank Kambhatla,Srinivasan Iyengar,Shivkumar Kalyanaraman,Ponnurangam Kumaraguru,Vipin Chaudhary
### Background
构建高质量、领域特定的数据集是部署稳健视觉系统的重大瓶颈，需要在数据质量、多样性和成本之间做出复杂权衡。需研究广泛的、未标记的数据湖，需要复杂的权衡。现有的方法难以应对这一挑战，尤其是在大规模、多样化数据处理方面和确保数据质量与效率之间取得平衡。Labeling Copilot 提出了一种新的解决方案，旨在解决这些问题。
### Innovation
介绍了一种名为 Labeling Copilot 的数据治理深度研究代理，利用大型多模态语言模型中的中央协调器，通过多步推理执行特定工具，以实现三大核心能力：（1）校准的发现：从大规模存储库中发现相关且符合分布的数据；（2）可控的合成：生成新数据以应对罕见场景，并进行严格筛选；（3）共识标注：通过一种新颖的共识机制，结合非极大值抑制和投票，协调多个基础模型产生准确的标签。通过大规模验证，证明了 Labeling Copilot 各个组件的有效性，特别是共识标注模块的数据对象发现能力，显著超越了现有技术。同时，Calibrated Discovery 工具也以更优化的方式解决了主动学习策略下大规模样本的问题效率低下的问题，这是行业内的一大创新。
### Conclusion
通过实验验证，一种具有优化、可扩展工具的代理工作流程为大规模数据集的治理提供了坚实的基石，表明了数据治理代理在计算机视觉领域具有巨大的潜在价值和广泛的应用前景。
## 610. `cs.CL` - 语义成分分析：将多主题分布引入基于聚类的主题建模 [PDF](https://arxiv.org/pdf/2410.21054), [HTML](https://arxiv.org/abs/2410.21054)
### Authors
Florian Eichin,Carolin M. Schuster,Georg Groh,Michael A. Hedderich
### Background
主题建模是文本分析中的关键技术，但是现有方法要么无法高效处理大规模数据集，要么只假设每个文档有一个主题。克服这些限制，我们引入了语义成分分析（SCA），这是一种在簇聚类主题建模框架中引入分解步骤的主题建模技术，可以发现每个样本中的多个主题。
### Innovation
在现有的主题建模技术基础上，SCA引入了多主题分布，通过在聚类主题建模框架中引入分解步骤，使每个样本可以发现多个主题，有效克服了单一主题假设的限制。SCA在多语言Twitter数据集上的评估结果显示，它在主题相关性和多样性方面与BERTopic竞争，同时能够发现至少是BERTopic两倍的主题数目，并且保持低噪声率。
### Conclusion
SCA为大规模数据集的主题建模提供了一种有效且高效的方法。与基于LLM的TopicGPT相比，在相似的计算预算下，SCA表现更优。因此，SCA有望成为处理大规模文本数据的主题建模强有力工具。
## 611. `cs.CL` - CapRL: 刺激密集图像描述能力的强化学习 [PDF](https://arxiv.org/pdf/2509.22647), [HTML](https://arxiv.org/abs/2509.22647)
### Authors
Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin
### Background
图像字幕任务是视觉领域和语言领域之间的重要桥梁，对预训练大规模视觉-语言模型（LVLMs）至关重要。当前最先进的字幕模型通常通过监督微调（SFT）进行训练，这种方式依赖于昂贵且难以扩展的人工或专有模型标注的数据。这种做法导致模型往往只能记住具体答案，而缺乏生成多样化、创造性的描述的能力。
### Innovation
为克服SFT的局限性，本文提出使用可验证奖励的强化学习（RLVR）方法来解决开放式的图像字幕任务。其中，主要创新点在于设计一个衡量字幕质量的目标奖励函数，该函数通过非视觉的大型语言模型（LLM）对基于仅靠该字幕作答的多项选择题的准确性来定义。本文是首次将RLVR应用于主观性很强的图像字幕任务，表明CapRL可以在多个方面显著提高性能。
### Conclusion
在由CapRL-3B标注的CapRL-5M字幕数据集上进行预训练，CapRL在12个基准测试上表现优异。而在Prism框架的质量评估中，CapRL的表现与Qwen2.5-VL-72B相当，但在大多数情况下超出基线8.4%。源代码可在此处访问：this https URL.
## 612. `cs.CL` - 使用强化学习提高大型语言模型的语言理解能力 [PDF](https://arxiv.org/pdf/2410.11020), [HTML](https://arxiv.org/abs/2410.11020)
### Authors
Bokai Hu,Sai Ashish Somayajula,Xin Pan,Pengtao Xie
### Background
目前，参数小于14B的指令微调大型语言模型（LLMs）在自然语言理解（NLU）任务上表现不佳，通常在GLUE和SuperGLUE基准测试中落后于较小的模型如BERT-base。研究人员通过引入强化学习来改进LLMs的语言理解能力。
### Innovation
将NLU视为强化学习环境，通过优化与正确标签的对齐度来处理令牌生成，并使用近端策略优化（PPO）框架进行优化。结果显示，PPO在GLUE基准测试中的平均改进为6.3个百分点，并且相较于零样本和少量样本提示分别提高了38.7和26.1个百分点。此外，PPO调优的模型在情感和自然语言推理任务中平均比GPT-4o高出4%，在某些数据集上甚至高达7.3%和10.9%。
### Conclusion
这项工作为通过将LLMs重塑为强化学习问题来适应新任务提供了有希望的方向，通过简单的结束任务奖励实现学习，而非通过大量数据标注进行训练。
## 613. `cs.CL` - 见指飞：一种无学习的基于VLM的通用无人飞行器导航框架 [PDF](https://arxiv.org/pdf/2509.22653), [HTML](https://arxiv.org/abs/2509.22653)
### Authors
Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu
### Background
近年来，基于视觉-语言模型（VLMs）的视觉-语言导航（AVLN）研究取得了显著进展。然而，现有的VLM方法大多将动作预测视为文本生成任务，缺乏有效的语义解析和空间定位能力。本文研究者提出了一种名为See, Point, Fly（SPF）的学习无依赖的AVLN框架，用于在各种环境和任意类型指令下实现自主导航。
### Innovation
与现有基于VLM的方法相比，SPF的主要创新点在于将动作预测视为一个二维空间定位任务。SPF利用VLM将模糊的语言指令分解为输入图像上的迭代标注二维航路点，并结合预测的行进距离，将二维航路点转化为三维位移向量作为无人飞行器（UAVs）的动作指令。此外，SPF还能够自适应调整行进距离，以提高导航效率。SPF能够在闭环控制下导航，使UAV能够追踪动态目标。
### Conclusion
在DRL模拟基准测试中，SPF达到了新的最先进的水平，比之前最好的方法绝对提升了63%的性能。在广泛的实地评估中，SPF显著优于强基线。此外，SPF还证明了在不同VLM上的出色泛化能力。
## 614. `cs.CL` - TEXT2AFFORD:仅从文本探查语言模型预测物体功能的能力 [PDF](https://arxiv.org/pdf/2402.12881), [HTML](https://arxiv.org/abs/2402.12881)
### Authors
Sayantan Adak,Daivik Agrawal,Animesh Mukherjee,Somak Aditya
### Background
预训练语言模型（PTLMs）和预训练多模态模型（PTVLMs）在推理和语义 grounding 方面存在不足，且在处理不常见物体功能时表现有限，这对多模态和自然语言处理中的实际应用提出了挑战。因此，研究物体功能预测是提高模型理解真实世界能力的关键。
### Innovation
本文提出了一种新颖的数据集 Text2Afford，包含15类物体功能的全面信息，并通过现有的 PTLMs 和 PTVLMs 对这些功能进行预测。研究不仅评估了现有模型在处理少见物体功能时的能力，还通过微调展示了模型性能的提升可能性，并探讨了模型在物体功能理解上的局限性和潜力。
### Conclusion
本文提供的 Text2Afford 数据集为语言接地任务做出了贡献，并深入揭示了语言模型的功能理解能力。通过对模型性能的改进和分析，本研究为未来研究提供了新的视角和数据支持，推动对物体功能理解的全面认识。
## 615. `cs.CL` - 跨语言和任务分析大型语言模型中的神经元：共享的重要性 [PDF](https://arxiv.org/pdf/2406.09265), [HTML](https://arxiv.org/abs/2406.09265)
### Authors
Weixuan Wang,Barry Haddow,Minghao Wu,Wei Peng,Alexandra Birch
### Background
大型语言模型（LLMs）已彻底改变了自然语言处理（NLP）领域，现有研究主要集中在理解其内部机制上。然而，大多数研究仅限于单一语言环境，集中在英语上。少有研究探讨多语言环境中的LLMs内部运作机制。本研究旨在填补这一研究空白，通过分析不同任务和语言中神经元激活的共享程度来探讨LLMs的工作原理，从而揭示多元语言LLMs的内部工作原理，并为未来的相关研究铺平道路。
### Innovation
本研究将神经元分为四类：全共享、部分共享、特定和未激活，基于此分类，对三种任务进行了涉及九种语言的大规模实验，揭示了神经元激活模式在不同任务、大模型和语言间高度敏感并存在差异，强调了全共享神经元在生成响应中的关键作用。通过这些发现，该研究为理解LLMs的多语言工作原理提供了新的视角，并为未来研究奠定了基础。
### Conclusion
我们的研究结果表明，全共享神经元的失活会显著降低性能；共享神经元在生成响应中起着至关重要的作用，尤其是全共享神经元；神经元激活模式在不同任务、大模型和语言间高度敏感并存在差异。这些发现揭示了多元语言LLMs的内部运作机制，并为未来研究指明了方向。我们已发布研究代码以促进该领域的研究。
## 616. `cs.CL` - LLMs对垂直对齐文本操纵的脆弱性 [PDF](https://arxiv.org/pdf/2410.20016), [HTML](https://arxiv.org/abs/2410.20016)
### Authors
Zhecheng Li,Yiwei Wang,Bryan Hooi,Yujun Cai,Zhen Xiong,Nanyun Peng,Kai-wei Chang
### Background
垂直文本输入在许多实际应用中都很常见，例如数学运算和基于单词的数独谜题。尽管当前的大语言模型（LLMs）在自然语言任务中表现出色，但在处理文本格式变化时仍然很脆弱。最近的研究表明，对于基于编码器的模型，修改输入格式，如将文本垂直对齐，会显著降低文本分类任务的准确性。但人类可以轻易理解这些输入，却能显著误导模型，特别是在涉及有害或敏感信息的现实场景中，存在绕过检测的风险。随着LLM应用的扩大，一个关键问题出现了：基于解码器的LLM是否也对垂直文本输入显示相似的脆弱性？
### Innovation
本研究调查了各种LLM在多个文本分类数据集中的性能受垂直文本输入影响的情况，并分析了潜在原因。发现：(i) 垂直文本输入显著降低了LLM在文本分类任务中的准确性；(ii) 答案链推理（CoT）不能帮助LLM识别垂直输入或减轻其脆弱性，而需要专门的少样本学习和仔细分析；(iii) 通过分析分词和注意力矩阵，探索了此类脆弱性的潜在原因。
### Conclusion
垂直文本输入显著降低了LLM在文本分类任务中的准确性；答案链推理不能解决这个问题，但少样本学习与细致分析可以；发现了分词和注意力矩阵中的固有问题导致了这种脆弱性。
## 617. `cs.CL` - 位置ID很重要：一种用于高效大语言模型上下文压缩的增强位置布局 [PDF](https://arxiv.org/pdf/2409.14364), [HTML](https://arxiv.org/abs/2409.14364)
### Authors
Runsong Zhao,Xin Liu,Xinyu Liu,Pengcheng Huang,Chunyang Xiao,Tong Xiao,Jingbo Zhu
### Background
在大语言模型（LLMs）中，使用特殊标记（如主旨、记忆或压缩标记）来压缩上下文信息是一种常见做法。然而，现有的方法往往忽略了位置编码内在地给模型引入了本地归纳偏差，使压缩过程忽视了整体的上下文依赖性。现有方法在处理这种依赖性时效果不佳。因此，需要一种方法来优化上下文压缩能力而不改变模型的本质结构。
### Innovation
本文提出了一种简单而有效的方法——增强位置布局（EPL），仅通过调整位置ID，即用于指定标记位置数值标识符，来改进LLMs的上下文压缩能力。EPL通过减少上下文标记与对应特殊标记之间的距离，同时保持位置ID在上下文标记、特殊标记和后续标记之间的序列顺序，来实现这一目标。实验结果表明，将EPL集成到最佳上下文压缩模型中后，可以在跨领域的问答数据集上平均提高1.9的ROUGE-1 F1分数，当应用于多模态场景时，EPL可以为视觉压缩LLMs带来平均2.6点的准确率提升。
### Conclusion
该研究提出了一种简单有效的增强位置布局（EPL），通过微调位置ID而非根本改变模型结构，显著提升了大语言模型的上下文压缩能力。实验表明，这种方法在问答任务和多模态应用中都表现出良好的效果，为大语言模型的实际应用提供了新的改进路径。
## 618. `cs.CL` - $100,000或100天：使用学术资源进行预训练的成本效益权衡 [PDF](https://arxiv.org/pdf/2410.23261), [HTML](https://arxiv.org/abs/2410.23261)
### Authors
Apoorv Khandelwal,Tian Yun,Nihal V. Nayak,Jack Merullo,Stephen H. Bach,Chen Sun,Ellie Pavlick
### Background
学术研究人员通常缺乏充足的计算资源，而预训练模型需要大量的计算资源。因此，一般认为学术研究人员无法进行模型的预训练。本研究旨在澄清这一假设。通过调研学术研究人员的计算资源，并实际测量在这些资源上复制模型所需的时间，研究者发现，在有限算力下，也可以有效地进行模型预训练，为学术界提供了更多的可能性。
### Innovation
研究引入了一种基准测试来衡量在给定GPU上进行模型预训练所需的时间，并确定了最大化训练速度的理想设置。此外，研究还进行了广泛的实验，覆盖了多种模型和学术级GPU，耗时2,000 GPU-小时，结果表明，即使原模型需要大量资源，小额预算或较短的时间周期也可能实现预训练。
### Conclusion
研究总结了成本与预训练时间之间的权衡，为学术研究人员提供了一定的指导。基准测试有助于学术研究人员进行更大型模型基于更大数据集的训练实验。代码完全开源。
## 619. `cs.CL` - AtomR：为异构知识推理赋能的大语言模型原子操作框架 [PDF](https://arxiv.org/pdf/2411.16495), [HTML](https://arxiv.org/abs/2411.16495)
### Authors
Amy Xin,Jinxin Liu,Zijun Yao,Zhicheng Lee,Shulin Cao,Lei Hou,Juanzi Li
### Background
大型语言模型尽管能力出众，但在组合推理和Delusion（生成错误信息）方面仍存在局限性，知识密集型推理仍然是挑战。现有的链式思维（CoT）与检索增强生成（RAG）方法虽然能够分解复杂问题为简单子问题，并逐步应用RAG，但这些方法在规划推理过程和整合异构知识方面仍存在问题。
### Innovation
本文提出了一种名为AtomR的新框架，它能够使大语言模型在原子级别上实现对异构知识的准确推理。AtomR借鉴了知识图谱查询语言通过组合预定义操作来模拟组合推理的方法，提出了一套原子知识操作符，将复杂问题分解成具有高度细化和独立性的原子知识操作符节点树，并在推理执行阶段灵活利用来自不同来源的原子级别知识。实验结果表明，相较于最先进的基线模型，AtomR在多个单源和多源数据集上的表现显著提升，特别是在2WikiMultihop和BlendQA数据集上分别提高了9.4%和9.5%的F1分数。
### Conclusion
实验结果显示，AtomR框架能够在原子水平上有效解决异构知识推理问题，并且相比现有最先进的方法取得了显著的性能提升。
## 620. `cs.CL` - 使用语言模型集成标记自由文本数据 [PDF](https://arxiv.org/pdf/2501.08413), [HTML](https://arxiv.org/abs/2501.08413)
### Authors
Jiaxing Qiu,Dongliang Guo,Natalie Papini,Noelle Peace,Hannah F. Fitterman-Harris,Cheri A. Levinson,Tom Hartvigsen,Teague R. Henry
### Background
心理研究中通常会收集自由文本数据，它们提供了丰富的定性见解，而这些见解定量衡量无法捕捉。对这些自由文本数据中的研究主题进行人工标注既耗时又费力。虽然大规模语言模型（LLMs）在语言处理方面表现出色，但依赖闭源LLMs的LLM辅助标注技术不能直接应用于自由文本数据，除非获得明确的外部使用许可。该研究提出的框架旨在在隐私约束下增强预制主题的自由文本数据标注，利用多种开源LLMs的异质性，通过相关性评分方法优化平衡各LLMs之间的共识与分歧。
### Innovation
提出的框架利用多种开源LLMs的异质性进行自由文本数据的标注。利用LLMs对主题描述的嵌入距离，通过相关性评分方法实现共识与分歧的平衡。与单一LLMs相比，LLM集成在预测人类标注时表现出了最高的准确性和最优的精确度灵敏度权衡。
### Conclusion
研究发现LLMs在标注表现上存在异质性，有些LLMs虽然灵敏度低但精度高，有些则反之。LLM集成方法在预测人类标注时表现最好，相关性评分在不同LLMs之间的共识大于二元标签，说明相关性评分方法有效缓解了LLMs标注中的异质性问题。
## 621. `cs.CL` - 许大的Mamba：过大的状态导致无法遗忘 [PDF](https://arxiv.org/pdf/2410.07145), [HTML](https://arxiv.org/abs/2410.07145)
### Authors
Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
最近的递归架构发展，如Mamba和RWKV，展示了强大的语言能力。与基于Transformer的模型不同，这些架构将所有上下文信息编码为固定大小的状态，这带来了极高的推理效率，但这种方法可能导致信息干扰，使得不同令牌的数据产生冲突，从而导致性能下降和超出一定上下文长度后的输出不一致。为了防止这一点，大多数递归神经网络（RNNs）都集成了设计用于“忘记”早期令牌的机制。然而，本文揭示出即使拥有内置遗忘机制，基于Mamba的模型也无法有效地忘记早期的令牌。研究者证明，这种问题源于模型训练时使用的是状态大小不足以适应上下文长度，使得模型无需学习主动遗忘也能表现出色。进一步研究发现，模型学习遗忘机制所需最小训练长度与状态大小成线性关系，而准确检索5位数字密码的最大上下文长度与状态大小呈指数关系，表明模型在遗忘机制生效之前仍能保留部分信息。这些发现突显了当前递归架构在长期上下文建模中的关键局限性，也为改进长上下文建模提供了宝贵见解。
### Innovation
本文揭示了基于Mamba的模型即使配备了内置的遗忘机制，也无法有效遗忘早期的令牌，并且这种现象出现的原因是训练时上下文长度不足，这使得模型在不需学习遗忘机制的情况下也能表现良好。进一步研究发现，遗忘机制的学习所需最小训练长度与状态大小成线性关系，而准确检索5位数字密码的最大上下文长度与状态大小成指数关系，表明模型在遗忘机制生效之前仍能保留一些信息。这项研究为未来递归网络的设计提供了有价值的意见，指出了需要考虑状态大小、训练长度和遗忘机制之间的相互作用以实现长上下文任务中的鲁棒性能的重要性。
### Conclusion
本文的研究揭示了当前递归架构在长上下文任务中存在的关键局限性，指出未来的设计需要综合考虑状态大小、训练长度以及遗忘机制之间的相互作用，才能实现良好的长期上下文建模性能。
## 622. `cs.CL` - LLMs能否成为知识图构建的优秀Graph Judge？ [PDF](https://arxiv.org/pdf/2411.17388), [HTML](https://arxiv.org/abs/2411.17388)
### Authors
Haoyu Huang,Chong Chen,Zeang Sheng,Yang Li,Wentao Zhang
### Background
在现实场景中，信息检索（IR）系统获取的大部分数据都是无结构的。将自然语言句子转换为结构化的知识图（KGs）仍然是一个关键挑战。现有的KG构建方法存在三个局限：（1）实际文档中可能存在大量的噪声，导致提取的信息杂乱。（2）朴素的语言模型从特定领域文档中提取的知识通常不够准确。（3）直接使用语言模型（LLMs）构建KG时，幻觉现象不容忽视。针对这些挑战，本文提出了GraphJudge知识图构建框架。
### Innovation
该框架采用实体为中心的策略来清除文档中的噪声信息，并微调LLM作为图法官来最终增强生成的KG的质量。实验结果显示其与不同基线方法相比表现优异，且具备强大的泛化能力。代码已发布。
### Conclusion
本文提出了GraphJudge，这是一种用于解决现有KG构建方法中噪声信息消除、知识提取不准确及幻觉现象等问题的知识图构建框架。框架效果在多个数据集上表现出色，并且具有良好的通用性。更多信息可以通过提供的链接获取。
## 623. `cs.CL` - 揭开金融领域大型语言模型后训练的神秘面纱 [PDF](https://arxiv.org/pdf/2501.04961), [HTML](https://arxiv.org/abs/2501.04961)
### Authors
Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty
### Background
大语言模型（LLMs）在特定领域，如医学和金融方面的适应性后训练已经显示出很大的潜力。然而，在适应性过程中依然存在许多挑战，尤其是在找到最优的适应性标准和训练策略方面。
### Innovation
本文提出了一种针对金融领域的系统性研究方法FINDAP，其包含了四个关键技术组成部分：FinCap定义了目标领域所需的主体能力；FinRec一种有效的训练食谱，旨在同时优化持续预训练和指令响应能力，并结合生成奖励模型的进程信号进行新颖的偏好数据蒸馏方法；FinTrain用于支持FinRec的一系列定制化训练数据集；FinEval与FinCap对齐的全面评估套件。FINDAP的模型Llama-Fin在多种金融任务中取得了最先进的性能。
### Conclusion
我们的研究揭示了每个后训练阶段对能力的贡献，发现了特定的挑战和有效的解决方案，为大语言模型的领域适应提供了宝贵的经验和见解。
## 624. `cs.CL` - 揭示用于医疗保健的LLMs中人口统计偏差的机制 [PDF](https://arxiv.org/pdf/2502.13319), [HTML](https://arxiv.org/abs/2502.13319)
### Authors
Hiba Ahsan,Arnab Sen Sharma,Silvio Amir,David Bau,Byron C. Wallace
### Background
先前的研究表明，大型语言模型（LLMs）在医疗领域会编码社会偏见，这些偏见在临床任务中表现出来。因此，该研究采用了机制可解释性工具来揭示LLMs在医疗保健背景下的人口统计学表示和偏见。
### Innovation
该研究创新性地应用了机制可解释性方法，识别出LLMs中编码人口统计信息的激活情况（如性别和种族），并且能够在推理过程中精确操控这些激活。研究还发现，尽管种族信息在LLMs中的分布较为广泛，也可以通过一定程度的干预来影响临床预测。
### Conclusion
这是首次将机制可解释性方法应用于医疗保健领域的LLMs中，揭示了在临床任务中由于人口统计特征导致的偏见机制。研究结果表明，通过干预这些偏见，可以改善LLMs在医疗保健中的应用，减少可能存在的歧视性影响。
## 625. `cs.CL` - 使用判断分布改进LLM-as-a-Judge推理 [PDF](https://arxiv.org/pdf/2503.03064), [HTML](https://arxiv.org/abs/2503.03064)
### Authors
Victor Wang,Michael J.Q. Zhang,Eunsol Choi
### Background
使用语言模型（LLM）来大规模估计人类在文本质量上的偏好已经成为许多任务中的标准做法。通常，对LLM的评价仅是依据其文本输出进行，通常采用贪婪解码。然而，LLM自然提供了判断标记的概率分布，这为提取更精细的偏好提供了多种推理方法的选择。以往研究采用的是贪婪解码选择概率最高的标记，但本文作者通过实验证明，直接取概率分布的均值往往比贪婪解码更能提高性能。
### Innovation
文章发现，计算判断分布的均值比获取模态（即贪婪解码）更能一致地提升评价性能。进一步探索了从判断分布中提取偏好的新方法，发现加入风险规避机制的方法能进一步提升性能。此外，研究了LLM-as-a-judge结合链式推理提示（CoT）的影响，发现CoT可能会缩小判断分布，但通常会损害性能。
### Conclusion
研究结果表明，在LLM-as-a-judge中利用概率分布输出可以进一步提升其性能，相较于只使用文本界面。
## 626. `cs.CL` - 如何使大语言模型在事实核查中失败 [PDF](https://arxiv.org/pdf/2503.01902), [HTML](https://arxiv.org/abs/2503.01902)
### Authors
Adiba Mahbub Proma,Neeley Pate,James Druckman,Gourab Ghoshal,Hangfeng He,Ehsan Hoque
### Background
大语言模型（LLMs）虽然可以放大在线虚假信息，但也展示了反驳虚假信息的潜力。本文研究了ChatGPT、Gemini和Claude三种LLMs反制政治性虚假信息的能力。实验结果显示，这些模型在引用真实新闻源来支持其回应方面存在困难，更倾向于引用左翼的来源。此外，模型回复的多样性也有所不同。这些发现引发了使用LLMs进行事实核查的担忧，突显了仅通过提示工程无法确保其可靠性的顾虑。
### Innovation
本文采用了一步两步的思维链提示方法，让模型首先识别给定声明的可信来源，然后生成有说服力的回应。这项研究揭示了LLMs在事实核查时存在的多个问题，填补了该领域的研究空白。
### Conclusion
尽管LLMs能反驳虚假信息，但它们在真实新闻来源引用和回应多样性上存在问题。单纯依靠提示工程不足以解决这些问题，必须制定更强大的防护措施。研究结果对研究人员和非技术用户都具有重要意义。
## 627. `cs.CL` - 层级知识增强的检索增强生成 [PDF](https://arxiv.org/pdf/2503.10150), [HTML](https://arxiv.org/abs/2503.10150)
### Authors
Haoyu Huang,Yongfeng Huang,Junjie Yang,Zhenyu Pan,Yongqiang Chen,Kaili Ma,Hongzhi Chen,James Cheng
### Background
基于图的检索增强生成（RAG）方法在特定领域的任务中显著提高了大型语言模型（LLMs）的性能。然而，现有的RAG方法没有充分利用人类认知中固有的层次结构知识，限制了RAG系统的功能。
### Innovation
提出了一种新的RAG方法，称为HiRAG，该方法利用层次结构知识在索引和检索过程中增强RAG系统的语义理解和结构捕获能力。
### Conclusion
我们的大量实验表明，HiRAG在最新的基准方法上取得显著的性能提升。
## 628. `cs.CL` - 揭秘过程奖励建模中的多语言链式思维 [PDF](https://arxiv.org/pdf/2502.12663), [HTML](https://arxiv.org/abs/2502.12663)
### Authors
Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch
### Background
大型语言模型（LLMs）被设计用于执行广泛的任务。为了提高其解决需要多步推理的复杂问题的能力，最近的研究使用过程奖励建模（PRMs）在每一步推理过程中提供细化反馈，以增强强化学习（RL）。但是，这种研究主要集中在英语上。本文旨在应对在多语言环境中扩展过程奖励模型（PRMs）的关键挑战，通过训练一种涉及七种语言的数据集，展示了在多种语言的应用中，多语言PRMs不仅提高了平均准确性，还能减少早期推理中的错误，研究揭示了多语言PRMs对训练语言数量和英语数据量的敏感性，并发现了更多候选响应和可训练参数的好处，为复杂多步推理任务的稳健多语言应用打开了新的途径。
### Innovation
本文的主要创新在于提出了多语言过程奖励模型（Multilingual PRMs），该模型在七种语言的数据集上进行训练，解决了英语主导的多步骤推理问题，同时通过跨11种语言的广泛评估，证明了多语言PRMs不仅提高了错误率，还减少了早期推理错误，显示了训练语言数量和英语数据量的影响，并揭示了多个候选响应和可训练参数的好处。此外，还公开了代码以促进相关研究进展。
### Conclusion
本文的工作为复杂多步推理任务中的稳健多语言应用打开了新的途径。通过多语言过程奖励模型，多语言环境下的推理任务得到了显著改善。未来的研究将探索进一步改进模型的方法，并在更多语言环境下进行验证。同时，我们也公开了代码，期待更多研究者参与，并进一步推进这一领域的发展。
## 629. `cs.CL` - Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent [PDF](https://arxiv.org/pdf/2503.02519), [HTML](https://arxiv.org/abs/2503.02519)
### Authors
Xingzuo Li,Kehai Chen,Yunfei Long,Xuefeng Bai,Yong Xu,Min Zhang
### Background
大型语言模型（LLM）代理通常采用逐步推理框架，在此框架中，它们交替进行思考和行动来完成给定的任务。然而，这种模式存在根深蒂固的一次性问题，即每次生成的中间思考都会被插入到轨迹中，无论其正确与否，这可能导致不可逆的错误传播。
### Innovation
本文提出了一个新的框架，称为Generator-Assistant Stepwise Rollback（GA-Rollback），以增强LLM代理的决策能力。GA-Rollback利用生成器与环境交互，并使用助手检查生成器生成的每个行动。如果检测到错误行动，助手将触发回滚操作。此外，还引入了两种针对回滚场景的额外策略，以进一步提高其有效性。
### Conclusion
广泛的实验表明，GA-Rollback在三个广泛使用的基准上显著优于多个强大的基线。我们的分析进一步表明，GA-Rollback可以作为一个强大的插件模块运行，与其他方法无缝集成。
## 630. `cs.CL` - SOLAR：通过建模价值观冲突和权衡来刻画个体主观性 [PDF](https://arxiv.org/pdf/2504.12633), [HTML](https://arxiv.org/abs/2504.12633)
### Authors
Younghun Lee,Dan Goldwasser
### Background
现有的研究显示，大型语言模型（LLMs）不仅能够解决复杂的推理问题，还在需要主观决策的任务上表现出色。尽管LLM生成的内容可以在一定程度上反映主观性，但现有研究尚未充分探讨LLM能否准确反映个体的主观性。本文以社交媒体上的用户生成文本为基础，研究个体的主观性，并使用LLM进行心理偏好方面的推断。
### Innovation
本文提出了一种新的框架，名为SOLAR（Subjective Ground with Value Abstraction），该框架通过观察用户生成的文本中的价值观冲突和权衡，来更好地表达个体的主观性。实验结果表明，SOLAR框架在整体推理结果以及在争议性情况下的表现上都有所提升，同时，SOLAR还能够提供关于个体价值偏好解释，进一步解释个体的判断。
### Conclusion
本文通过提出了一种名为SOLAR的新框架，成功地刻画了个体的主观性，并改进了在社会媒体文本上的主观性推断。SOLAR框架通过观察用户生成的文本中的价值观冲突和权衡，提供了对个人价值偏好的解释，有助于理解个体的判断。
## 631. `cs.CL` - RuCCoD: 向俄罗斯ICD编码自动化迈进 [PDF](https://arxiv.org/pdf/2502.21263), [HTML](https://arxiv.org/abs/2502.21263)
### Authors
Aleksandr Nesterov,Andrey Sakhovskiy,Ivan Sviridov,Airat Valiev,Vladimir Makharev,Petr Anokhin,Galina Zubkova,Elena Tutubalina
### Background
研究探讨了在资源有限的俄语环境中实现临床编码自动化的可行性。背景提到，俄语在生物医学资源方面存在限制，因此在该领域进行自动化编码具有重要意义。为了验证这一点，研究团队创建了一个新数据集用于ICD编码，包括电子健康记录中的诊断字段，并通过超过10,000个实体和1,500多个唯一的ICD代码对这些数据进行了标注。该数据集被用于评估多个最先进的模型，以进一步验证模型的性能及其潜在应用价值.
### Innovation
研究的主要创新点在于创建了一个专门为俄语环境设计的ICD编码数据集，并利用该数据集对多种先进的自然语言处理模型进行了测试，包括BERT、带有LoRA的LLaMA和RAG。研究还探讨了跨不同领域的学习（从PubMed摘要到医疗诊断）和术语（从UMLS概念到ICD代码）的应用。实验结果表明，使用自动化预测的代码进行训练相较于使用医生手动标注的数据能显著提高准确性，为在资源有限的语言环境中实现临床编码提供了重要的见解和支持.
### Conclusion
研究结论认为，通过适当的资源投入和模型优化，可以成功实现俄语环境中临床编码的自动化。这不仅能提高临床效率，还能提高数据准确性。因此，该研究为资源有限语言环境下的临床编码提供了可行的方法，并且我们开放了源代码和数据集，以供进一步研究使用。
## 632. `cs.CL` - 使用任务激发适应性地剖析模型 [PDF](https://arxiv.org/pdf/2503.01986), [HTML](https://arxiv.org/abs/2503.01986)
### Authors
Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong
### Background
语言模型评价通常无法捕捉到关键的失败模式，这使得专家不得不检查模型输出并建立新的基准。这是当前评价方法的一个主要问题，因为它限制了我们对模型行为的深入理解。为了改进这一情况，本文提出了任务激发方法，该方法可以通过自动化方式构建新的评估指标来详细刻画模型的行为。任务激发已经在不同领域，如预测和在线骚扰等，发现了数千种新的自然语言任务，这比以往的研究成果多了数量级。这些任务揭示了前沿模型在特定领域的系统性失败方式。例如，Sonnet 3.5模型在量子计算和强人工智能领域表现出过度关联，而o3-mini模型在重复虚构信息时容易做出虚假陈述。
### Innovation
任务激发为语言模型评估提供了一种新的自动方法。与之前的手动方法相比，它能够更全面地发现模型的系统性失败模式。此外，它能够适应不同领域的需求，自动生成大量的任务来挑战模型，从而使得专家能够更全面地理解模型的能力和局限性。这种方法在识别语言模型的潜在问题上具有重要优势。
### Conclusion
任务激发能有效地建立新的评估指标，自动、全面地发现语言模型的新自然语言任务，揭示模型在不同领域中的系统性失败。这将有助于评估和改进模型，并推动模型的广泛部署和应用。
## 633. `cs.CL` - LLM-OptiRA：无线通信中非凸资源分配问题的LLM驱动优化 [PDF](https://arxiv.org/pdf/2505.02091), [HTML](https://arxiv.org/abs/2505.02091)
### Authors
Xinyue Peng,Yanming Liu,Yihan Cang,Chaoqun Cao,Ming Chen
### Background
在无线通信系统中解决非凸资源分配问题给传统优化技术带来了重大挑战，通常超出了它们的能力范围。
### Innovation
提出了一种新的框架LLM-OptiRA，它利用大型语言模型（LLMs）自动检测和转换非凸组件为可解形式，从而实现无线通信系统中非凸资源分配问题的全自动解决。LLM-OptiRA通过简化问题解决并减少对专家知识的依赖，以及整合了错误修正和可行性验证机制来保证稳健性。
### Conclusion
实验结果显示，LLM-OptiRA在GPT-4上的执行率为96%，成功率达到了80%，在不同场景下的复杂优化任务中显著优于基线方法。
## 634. `cs.CL` - MrGuard：通用大模型安全的多语言推理护栏 [PDF](https://arxiv.org/pdf/2504.15241), [HTML](https://arxiv.org/abs/2504.15241)
### Authors
Yahan Yang,Soham Dan,Shuo Li,Dan Roth,Insup Lee
### Background
大型语言模型（LLMs）受到如 Jailbreak 等对抗攻击的影响，这些攻击会诱发有害或不安全的行为。在多语言环境中，这种不安全的行为更容易发生，因为用于对齐安全的多语言数据往往很有限。因此，在真实场景中部署LLMs时，开发一个能够检测和过滤跨多种语言的不安全内容的安全护栏是至关重要的。本文探讨了开发一种针对LLMs的多语言安全护栏的需求，并介绍了该工作的背景。
### Innovation
本文引入了一种结合了多语言推理能力的多语言安全护栏 MrGuard，其创新之处在于：（1）生成合成的多语言数据，涵盖文化上和语言上的细微差别；（2）监督微调；（3）基于课程的分组相对策略优化（GRPO）框架，进一步提升模型性能。实验结果显示，MrGuard 在同域和跨域语言的任务上，比最近的基线方法高出超过 15%。此外，还证明了 MrGuard 在处理如代码切换和低资源语言提示的情况下，也能够保持其安全性。
### Conclusion
实验结果表明，MrGuard 通过融合多语言推理能力，能够有效地过滤多语言环境中的不安全内容，并在复杂场景下（如代码切换和低资源语言）保持其安全性。这种多语言推理功能使其能够生成解释，有助于理解和管理多语言内容中的语言特定风险和歧义。
## 635. `cs.CL` - Large Language Models的不确定性测量与缓解方法比较：一项系统性审查 [PDF](https://arxiv.org/pdf/2504.18346), [HTML](https://arxiv.org/abs/2504.18346)
### Authors
Toghrul Abbasli,Kentaroh Toyoda,Yuan Wang,Leon Witt,Muhammad Asif Ali,Yukai Miao,Dan Li,Qingsong Wei
### Background
大语言模型（LLMs）已在多个领域取得了变革性的进步。然而，LLMs仍面临的重大挑战之一是幻觉现象——即LLMs自信地输出错误信息。这一现象引发了如何准确评估和量化LLMs的不确定性的问题。尽管传统模型中已经广泛研究了不确定性量化（UQ）以度量不确定性和采用了校准技术来解决不确定性与准确性之间的不一致问题，但这些方法在LLMs上的适应性效果缺乏深入分析，现有解决方案的全面基准也无法进行有意义的比较。
### Innovation
本文通过系统性回顾LLMs上的不确定性量化和校准方法，填补了这一领域的空白，并引入了一个严格的基准。使用两个广泛采用的可靠性数据集，本文实证评估了六种相关方法，从而验证了审阅中得出的重要结论。最后，本文提出了关键的未来方向和阐明了悬而未决的挑战。据我们所知，这是首次专注于审查LLMs上的校准方法及相关指标的研究。
### Conclusion
本文的研究结果为LLMs的校准方法和相关指标提供了一项系统性审查，旨在更好地理解和解决LLMs中的不确定性问题。
## 636. `cs.CL` - LoRA-MGPO：通过动量引导扰动优化减轻低秩适应中的双下降现象 [PDF](https://arxiv.org/pdf/2502.14538), [HTML](https://arxiv.org/abs/2502.14538)
### Authors
Yupeng Chang,Chenlu Guo,Yi Chang,Yuan Wu
### Background
Parameter-efficient fine-tuning（PEFT），尤其是Low-Rank Adaptation（LoRA），能够通过训练少量参数来适应大型语言模型（LLMs）。然而，随着用于适应的低秩矩阵的秩增加，LoRA经常表现出不稳定的“双下降”现象，这种现象表现为训练损失的暂时发散，这会延迟收敛并影响泛化，因为会导致模型被锐角局部极小值吸引。
### Innovation
我们引入了LoRA-MGPO框架，该框架结合了Momentum-Guided Perturbation Optimization（MGPO）。MGPO通过减少双下降现象并使用优化器状态中的动量向量引导权重扰动来稳定训练动态，从而避免了双重梯度计算。此外，一个自适应规范化方案根据梯度范数的指数移动平均（EMA）来调整扰动的幅度，进一步增强了稳定性。虽然EMA控制了扰动的幅度，MGPO则引导了它们的方向，确保了更稳定的优化轨迹。在一系列自然语言理解与生成基准测试中表明，LoRA-MGPO在性能上优于LoRA和其他PEFT方法，其分析表明LoRA-MGPO能够使损失曲线更平滑，加速收敛，并通过稳定训练过程并减少对锐角极小值的吸引来提高泛化能力。
### Conclusion
实验表明，LoRA-MGPO在一系列自然语言处理基准测试中，能够持续超越LoRA和其他PEFT方法，同时通过稳定训练过程和减少对锐极小值的吸引力，获得更平滑的损失曲线、更快的收敛速度和更好的泛化能力。
## 637. `cs.CL` - 纹理还是语义？视觉语言模型在字体识别中迷失 [PDF](https://arxiv.org/pdf/2503.23768), [HTML](https://arxiv.org/abs/2503.23768)
### Authors
Zhecheng Li,Guoxian Song,Yujun Cai,Zhen Xiong,Junsong Yuan,Yiwei Wang
### Background
现代的视觉语言模型（VLMs）表现出显著的视觉和语言能力，可以完成各种任务如图像识别和物体定位等。然而，他们在细节任务上的效果仍然有待验证。在这种背景下，识别设计材料中使用的字体成为了一个新的挑战。引入Font Recognition Benchmark (FRB)，提供了15种常用字体的数据集，用于评估VLMs在字体识别任务中的表现，发现当前VLMs在字体识别能力上有限，并受到文本信息引入的”Stroop效用“影响。
### Innovation
通过引入Font Recognition Benchmark (FRB)，评估了多种VLMs在字体识别任务中的表现，包括对不同版次字体识别的效果对比研究。首次通过实证方法系统地探讨了VLMs在字体识别中的效果和限制，特别是在处理包含文本信息的样本时的表现。
### Conclusion
当前的VLMs在字体识别中受限，特别是受文本信息影响显著。尽管进行少量学习和Chain-of-Thought (CoT)提示可能对常规任务有效，但对于字体识别性能提升不大，VLMs在捕捉语义特征方面存在固有限制。
## 638. `cs.CL` - InftyThink: 突破大型语言模型长上下文推理长度限制 [PDF](https://arxiv.org/pdf/2503.06692), [HTML](https://arxiv.org/abs/2503.06692)
### Authors
Yuchen Yan,Yongliang Shen,Yang Liu,Jin Jiang,Mengdi Zhang,Jian Shao,Yueting Zhuang
### Background
大型语言模型在复杂任务中的推理已经取得了显著的性能，但现有的长上下文推理方式面临严重的局限性，包括二次计算复杂度随着序列长度增加、由最大上下文边界限制的推理过程以及在预训练上下文窗口外的性能下降。现有的解决方法主要集中在压缩推理链，但未能根本解决计算复杂度的问题。因此，需要一种新的方法来处理这些挑战，以实现无限制的推理深度同时保持计算成本的可控性。
### Innovation
本文提出了InftyThink，一种将一次性推理转化为迭代过程并辅以中间总结的新方法。通过交错包含短推理片段和简明总结的过程，该方法能够在保持计算成本可控的情况下实现无界推理深度。此外，作者还开发了一种方法将长上下文推理数据集重新构造为迭代格式，从而显著减少了计算复杂度。这种方法在多个模型架构上的实验显示，该方法能够降低计算成本并提升性能，在Qwen2.5-Math-7B模型上，平均性能提升了3-13%。这挑战了推理深度与计算效率之间存在着固有的权衡，提出了一个不需改变架构即可实现复杂推理任务的更可扩展的解决方案
### Conclusion
本文提出了一种新的推理方法InftyThink，通过迭代过程和中间总结，实现了无界推理深度的同时降低了计算成本。这一方法在多个模型上验证了其有效性和优越性，提供了在大型语言模型中进行复杂推理的新途径，挑战了以往的认知，即在处理长上下文推理时无法实现深度推理与计算效率之间的良好平衡。
## 640. `cs.CL` - ExpertSteer: 通过专家知识干预大型语言模型 [PDF](https://arxiv.org/pdf/2505.12313), [HTML](https://arxiv.org/abs/2505.12313)
### Authors
Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch
### Background
大型语言模型（LLMs）在各种任务中表现出色，但在推断过程中引导它们遵循所需的行为仍然是一项重大挑战。现有激活控制方法虽然具备潜力，但大多通过模型本身生成驱动向量来进行干预，这限制了其灵活性，并排除了使用强大外部专家模型进行干预的可能性。
### Innovation
本文提出了一种名为ExpertSteer的新方法，该方法利用任意的特殊专家模型来生成干预向量，从而在任何LLMs上启用干预。ExpertSteer通过四个步骤实现跨模型知识转移：使用自编码器对表示维度进行对齐，基于互信息分析确定干预层对，使用递归特征机从专家模型生成干预向量，并在推断过程中应用这些向量在指定层上选择性地引导目标LLM而不更新模型参数。
### Conclusion
我们在三个LLMs上针对四个不同领域的15个流行基准进行了全面实验，结果表明，与现有基准相比，ExpertSteer在各种任务上的性能显著提高，且成本较低。
## 641. `cs.CL` - HBO: 层级平衡优化方法用于大型语言模型的微调 [PDF](https://arxiv.org/pdf/2505.12300), [HTML](https://arxiv.org/abs/2505.12300)
### Authors
Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch
### Background
大型语言模型（LLM）在混合多样数据集上进行微调存在数据不平衡和异质性的问题。现有方法通常在数据集级别上解决这些问题，但忽视了数据集内部的不平衡和异质性，这限制了它们的有效性。
### Innovation
引入了层级平衡优化（HBO），这是一种新颖的方法，使LLM能够在微调过程中自主调整数据分配，既在不同数据子集之间（全局级别）也在其内部（局部级别）。HBO使用双层优化策略，并采用两种类型的主体：全局主体负责平衡训练混合的不同子集中的数据采样；多个局部主体则根据难度级别优化每个子集内数据的使用。这些主体由根据LLM训练状态导出的奖励函数引导，以衡量学习进展和相对性能改进。
### Conclusion
HBO在三个LLM框架上的九个多样性任务上进行评估，结果显示HBO始终优于现有基准，实现了显著的准确性提升。深入分析进一步证实HBO的全局和局部主体有效调整微调过程中的数据使用。HBO为LLM微调中的数据不平衡和异质性挑战提供了一个全面的解决方案，使跨多样数据集的训练更有效。
## 642. `cs.CL` - HiddenBench：通过隐藏特征任务评估多智能体大语言模型的集体推理 [PDF](https://arxiv.org/pdf/2505.11556), [HTML](https://arxiv.org/abs/2505.11556)
### Authors
Yuxuan Li,Aoi Naito,Hirokazu Shirado
### Background
多智能体系统基于大型语言模型（LLMs）能够通过分散的信息整合增强问题解决能力，但同时可能复制人类小组中观察到的集体推理失败。然而，缺乏理论支撑的标准测试使系统无法系统地评估和改进这种推理。因此，需要一个理论支撑的标准测试来评估和提高多智能体LLMs中的集体推理。
### Innovation
提出了第一个用于评估多智能体LLMs集体推理的标准测试——HiddenBench。该测试基于社会心理学中的隐藏特征范式，每个个体持有不对称的信息片段，并必须沟通以做出正确的决策。通过自定义任务和现实应用，验证GPT-4.1团队在整合分布知识方面表现不佳，即使有多种提示策略，仍未表现出集体推理的改进。建立全面的测试基准，涵盖65个任务，包括自定义设计、前期人类研究和自动生成的任务。该基准在15个不同模型家族的15个LLMs上进行了评估，暴露了持续存在的局限性，同时也提供了比较见解：某些模型（例如Gemini-2.5-Flash/Pro）取得了更高的性能，但规模与推理能力并不总是可靠的集体推理指标。
### Conclusion
本工作提供了第一个多智能体LLMs中集体推理的可重现基准，提供了诊断洞察，并为未来关于人工集体智能的研究奠定了基础。
## 643. `cs.CL` - CLASH：从多角度评估语言模型在判断高风险困境中的表现 [PDF](https://arxiv.org/pdf/2504.10823), [HTML](https://arxiv.org/abs/2504.10823)
### Authors
Ayoung Lee,Ryan Sungmo Kwon,Peter Railton,Lu Wang
### Background
在高风险领域，人类和AI在面对价值观冲突时面临着艰难的决策困境，尤其是在AI方面存在明显的局限性。以往的研究主要集中在日常生活场景中，而对于高风险场景的评估却较为欠缺。CLASH数据集的提出旨在填补这一空白，提供一种研究多重价值观背景下决策过程的方法，特别关注决策模棱两可和心理不适，以及价值观在角色视角中的动态变化。
### Innovation
CLASH数据集包含345个高影响力的困境及其3,795个不同价值观的视角。研究比较了14种模型，并揭示了几个关键发现：即使是强大的专属模型，在处理模棱两可的决策时也表现不佳；尽管语言模型能合理预测心理不适，但无法充分理解涉及价值观变化的视角；数学求解和游戏策略领域的认知行为无法有效地迁移到价值推理中；语言模型的价值偏好与其方向性紧密相关；语言模型在第三方视角推理中更具可引导性，某些价值观（如安全）则特别受益于第一人称的框架引导。
### Conclusion
研究强调了语言模型在高风险决策场景中的局限性，并揭示了其与价值观偏好之间的关联性。CLASH数据集将为未来相关研究提供宝贵的参考，有助于进一步理解和提升AI在价值导向决策中的能力。
## 644. `cs.CL` - 超越早期词元偏差：多语言LLM中模型特性和语言特性的位置效应 [PDF](https://arxiv.org/pdf/2505.16134), [HTML](https://arxiv.org/abs/2505.16134)
### Authors
Mikhail Menschikov,Alexander Kharitonov,Maiia Kotyga,Vadim Porvatov,Anna Zhukovskaya,David Kagramanyan,Egor Shvetsov,Evgeny Burnaev
### Background
现有研究指出大型语言模型（LLMs）存在位置偏差，即系统性地忽略特定位置的信息。然而，不同语言和模型的位置偏差模式尚未得到充分研究。
### Innovation
本文首次系统研究了五种不同类型的多语言（英语、俄语、德语、印地语、越南语）下五种模型架构的位置偏差行为，发现位置偏差主要由模型驱动，但表现出语言特异性。此外，明确指示模型“上下文对查询相关”意外地降低了多语言环境中的准确性，而最大的准确性下降发生在上下文中间但未直接体现在输出熵的峰值中。
### Conclusion
研究发现，位置偏差是模型驱动的，但存在语言特异性差异；明确指示模型上下文相关反而降低了准确性；准确性下降即便在上下文中心，但并未直接表现为输出熵的峰值增加。
## 645. `cs.CL` - ZeroTuning: 初始词元提升大语言模型的能力无需训练 [PDF](https://arxiv.org/pdf/2505.11739), [HTML](https://arxiv.org/abs/2505.11739)
### Authors
Feijiang Han,Xiaodong Yu,Jianheng Tang,Delip Rao,Weihua Du,Lyle Ungar
### Background
Token-level attention tuning, 一种训练无干预方法，包括事后注意力导向 (PASTA) 和注意力校准 (ACT)，已经成为提高冻结的语言模型 (LLM) 的一种有前景方式，使用可解释的干预措施。然而，这些方法依赖于辅助启发式方法来识别“重要”的任务特定词元，这可能导致偏见并限制适用性，尤其是在词元重要性不明确或使用优化内核但无法获得注意力图时。
### Innovation
我们提出了一种更简单且更优雅的替代方案，仅作用于初始词元（例如，LLaMA 中的 <BOS>）。理论上，我们表明向这个词元的注意力逻辑添加轻量级偏置可以单调地控制下游注意力分布的熵——这种效果放大了其作为注意力汇的自然功能。实证分析表明，这种调优过程可以正向影响 LLM 并更好地解锁其预训练知识，早期层的影响尤为显著，并且不同注意力头有着不同的缩放偏好。基于这些见解，我们引入了零调优 (ZeroTuning): 一种不用训练就可增强 LLM 性能的方法，通过在初始词元上应用特定头的注意力调整。该方法简便，内核无关，只需对标准 LlamaAttention 代码进行少量修改（约四行）。在15个数据集中，它实现了广泛的改进，并优于之前更复杂的方法。例如，与 Llama-3.1-8B 结合时，它在分类上的改进相对提高了19.9%，在问答上的改进为4.5%，在对话上的改进为2.1%。零调优还与量化推理兼容，并能在上下文长度增加时维持其性能提升。
### Conclusion
ZeroTuning 是一个训练无干预方法，通过应用特定头的注意力调整到初始词元来提高 LLM 性能，不需要参数更新。它介绍了两种变体：一种监督模式，基于验证样例进行校准；一种新颖的无监督模式，直接最小化模型的输出熵。这种方法轻量级、内核无关，并且只需要对标准 LlamaAttention 代码进行少量修改。它在15个数据集中实现了广泛改进，并优于之前的复杂方法。
## 646. `cs.CL` - UniErase：在语言模型中迈向精确且平衡的遗忘 [PDF](https://arxiv.org/pdf/2505.15674), [HTML](https://arxiv.org/abs/2505.15674)
### Authors
Miao Yu,Liang Lin,Guibin Zhang,Xinfeng Li,Junfeng Fang,Xingrui Yu,Ivor Tsang,Ningyu Zhang,Kun Wang,Yang Wang
### Background
大型语言模型（LLMs）需要迭代更新以解决过时信息问题，语言模型遗忘为选择性删除提供了一种方法。然而，主流遗忘方法主要依赖于微调技术，这类技术在目标性遗忘上缺乏精确度，并且难以在大规模和序列性设置中平衡遗忘效果与通用能力。
### Innovation
本文引入了UniErase，这是一种新颖的遗忘框架，展示了在知识遗忘与能力保留之间具有精确性和平衡表现的新方法。首先提出了遗忘标记，以引导LLMs进入遗忘空间。进一步引入了轻量级遗忘编辑，高效地将遗忘目标与元标记关联起来。通过编辑实现新的遗忘范式，UniErase在虚拟和现实世界知识场景下的批处理、序列和精确遗忘任务中表现出色。与8个基线相比，仅修改约3.66%的LLM参数，UniErase在模型能力方面优于最佳遗忘基线约4.01倍，同时在遗忘效率方面也超越最佳保留方法约35.96%，展示了当前遗忘社区中平衡和双顶级性能。
### Conclusion
UniErase通过轻量级编辑实现精确且平衡的遗忘，显著提高了语言模型在遗忘和保持能力方面的表现，为解决语言模型遗忘问题提供了新的范式。
## 647. `cs.CL` - UltraEdit: 在语言模型中实现无需训练、主题和记忆的终身编辑 [PDF](https://arxiv.org/pdf/2505.14679), [HTML](https://arxiv.org/abs/2505.14679)
### Authors
Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang
### Background
终身学习使大型语言模型（LLMs）能够通过不断更新其内部知识来适应不断变化的信息。理想的系统应能支持高效、广泛范围的更新，同时保留现有能力并确保可靠的部署。现有的模型编辑方法在实践中大规模应用时面临着挑战，因为它们往往难以满足有效的终身适应需求。目前的方法虽然取得了显著的进步，但仍然难以在大规模应用中达到实际所需的适应性和效率。
### Innovation
UltraEdit 是一种无需训练、主题和内存的方法，特别针对大规模、实际的终身模型编辑场景进行了优化。它通过一步计算隐藏状态及其梯度来确定参数移动，使得这种方法简单而高效。UltraEdit 引入了一种终身归一化策略，持续更新特征统计数据，以适应分布变化并保持长期一致性。UltraEdit 的编辑速度是当前最优方法的7倍以上，同时使用不到1/4的显存，成为唯一能够在24GB的消费级GPU上编辑7B LLM的方法。此外，还构建了UltraEditBench，集成了超过200万编辑对的最大数据集，验证了其在大规模编辑下仍能保持高准确度。
### Conclusion
Comprehensive实验结果表明，UltraEdit 跨多种模型编辑场景始终展现出优异性能，向安全、可扩展的终身学习迈出了新的一步。
## 648. `cs.CL` - 超越静态测试平台：一种以交互为中心的代理模拟平台，用于动态推荐系统 [PDF](https://arxiv.org/pdf/2505.16429), [HTML](https://arxiv.org/abs/2505.16429)
### Authors
Song Jin,Juntian Zhang,Yuhan Liu,Xun Zhang,Yufei Zhang,Guojun Yin,Fei Jiang,Wei Lin,Rui Yan
### Background
传统A/B测试资源密集，而离线方法难以处理动态用户-平台互动。现有的基于代理的模拟平台通常缺乏动态更新环境的功能，因此评估和迭代推荐系统是关键问题。
### Innovation
提出了一种名为RecInter的新颖的基于代理的模拟平台，该平台具有强大的交互机制。在RecInter平台中，模拟用户的动作（如喜欢、评论、购买）可以实时动态更新项目属性，并引入了商家代理来促进一个更真实的、动态的生态系统。模拟质量通过多维用户画像模块、高级代理架构以及在包含思维链（Chain-of-Thought）的交互数据上微调的语言大模型得到保证。该平台显著提高了模拟的真实性，并成功再现了品牌忠诚度和马太效应等现象。
### Conclusion
实验表明，交互机制对于模拟真实的系统演化至关重要，该平台作为推荐系统研究的可信测试床。代码在 http://this.url/ 上可获取。
## 649. `cs.CL` - BP-Seg：使用信念传播的图形模型方法进行无监督和非连续文本切分 [PDF](https://arxiv.org/pdf/2505.16965), [HTML](https://arxiv.org/abs/2505.16965)
### Authors
Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz
### Background
文本切分基于句子的语义意义是一种在许多下游应用中具有广泛用途的基础任务。
### Innovation
提出了一种基于图形模型的无监督学习方法，名为BP-Seg，该方法不仅考虑局部连贯性，还有效地将语义相似但在文本中距离较远的句子分组。
### Conclusion
在示例和长文档数据集上的实验结果表明，本方法与竞争对手相比表现出色。
## 650. `cs.CL` - Shadow-FT: 通过训练配对基础模型调优指令模型 [PDF](https://arxiv.org/pdf/2505.12716), [HTML](https://arxiv.org/abs/2505.12716)
### Authors
Taiqiang Wu,Runming Yang,Jiayi Li,Pengfei Hu,Yik-Chung Wu,Ngai Wong,Yujiu Yang
### Background
大规模语言模型（LLMs）在各种任务中都能从进一步微调中获益。然而，直接对指令模型（Instruct，即指令调优模型）进行微调通常只能带来微小提升，甚至会导致性能下降。值得注意的是，这些指令变体的基础模型（Base models）的权重值高度相似，例如Llama 3.1 8B的权重值平均差异小于2%。基础模型在未经后续训练的情况下表现出良好的学习能力，但作为主要架构时较弱。
### Innovation
本文提出了一种新颖的Shadow-FT框架，通过利用相应的基础模型来调优指令模型。该框架的核心思想是先微调基础模型，然后直接将学习到的权重更新应用到指令模型上。Shadow-FT无需引入额外参数，易于实现，并且能够显著提升性能。实验表明，Shadow-FT在多种基准测试中均优于传统的全参数和参数高效微调方法。
### Conclusion
Shadow-FT能够在广泛的主流LLM上进行测试，并且在包括编程、推理和数学任务在内的19个基准上表现出色。进一步分析表明，Shadow-FT可以应用于多模态大规模语言模型（MLLMs），并可以与直接偏好优化（DPO）相结合。研究结果已提交到Github上供社区参考。
## 651. `cs.CL` - SuperCoder: 使用大型语言模型进行汇编程序超优化 [PDF](https://arxiv.org/pdf/2505.11480), [HTML](https://arxiv.org/abs/2505.11480)
### Authors
Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken
### Background
超优化是将程序转换为更快版本的同时保持其输入输出行为的任务。本文探讨了大型语言模型（LLMs）是否可以作为超优化器，生成比工业标准编译器优化过的代码更快的汇编程序。研究者构建了一个包含8,072个真实汇编程序的大规模基准，这些程序平均每130行，而之前的数据集仅包含2-15行且没有循环的程序。
### Innovation
研究中首次构建了大规模的超优化汇编程序基准；使用了23种不同的LLM进行评估；通过强化学习对模型进行微调，以促进性能提升，从最初的Qwen2.5-Coder-7B-Instruct模型实现显著改进；建立了基于LLMs的汇编程序超优化的基础，为其在程序性能优化中的应用提供了可能。
### Conclusion
结果表明，LLMs可以作为汇编程序的超优化器，为未来研究程序性能优化提供了基础，超越了编译器的启发式方法。
## 652. `cs.CL` - 沿路径推理：通过事实知识图谱路径改善LLM事实性 [PDF](https://arxiv.org/pdf/2505.11140), [HTML](https://arxiv.org/abs/2505.11140)
### Authors
Mike Zhang,Johannes Bjerva,Russa Biswas
### Background
该研究背景指出，大型语言模型（LLMs）在处理复杂开放领域的问题解答（QA）时，往往存在事实准确度不足的问题。先前的研究在STEM领域展示了通过提供推理路径可以提高模型的推理准确性和事实性，但这一方法在更广泛的任务上尚未得到全面验证。因此，本文旨在通过将推理与事实知识图谱路径相结合，进一步提升LLMs在复杂问题上的事实准确性，并验证这一方法在不同模型大小和复杂问题上的适用性。
### Innovation
本文提出了一种名为fs1的简单而有效的方法，通过从大型推理模型（例如DeepSeek-R1）获取推理路径，并结合知识图谱（KG）路径进行条件化，来改善推理路径的事实性。该方法通过细调8个指令调优的大型语言模型（LLMs），并在3千多个事实支持的推理路径上进行了训练，随后在六个复杂的开放领域问题解答（QA）基准上进行了严格评估。实验结果表明，经过fs1调优的模型在六项评估基准中的表现优于与之平行的指令调优模型，尤其是在需要多个知识图谱路径跳跃和数值答案类型的复杂问题上表现尤为突出。此外，较小的LLMs在单次推理中显示出更大的改进效果。
### Conclusion
本文的工作表明，将推理与知识图谱路径链接是提升LLMs在知识密集型任务中可靠性的关键步骤，并且文章提供的实验证据支持了该观点。此外，fs1方法在不同规模的LLMs和复杂问题上的验证显示了其广泛应用的潜力。
## 653. `cs.CL` - BiomedSQL：生物医学知识库中科学推理的文本到SQL [PDF](https://arxiv.org/pdf/2505.20321), [HTML](https://arxiv.org/abs/2505.20321)
### Authors
Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri
### Background
生物医学研究人员越来越多地依赖大规模结构化的数据库来进行复杂的分析任务。然而，当前的文本到SQL系统在将定性的科学问题映射为可执行的SQL查询时经常遇到困难，特别是在需要隐含领域的推理时。现有的方法往往侧重于语法翻译，而忽视了对领域知识的推理。
### Innovation
该研究引入了BiomedSQL，这是第一个明确设计用于在现实世界生物医学知识库上评估文本到SQL生成中的科学推理的基准。BiomedSQL包含68,000个问题/SQL查询/答案三元组，这些数据与基因疾病关联、来自组学数据的因果推断以及药物审批记录进行了集成。此外，该研究评估了多种开源和闭源的语言模型，展示了GPT-o3-mini和BMSQL等自定义多步代理的表现，首次填补了在真实生物医学知识库上进行科学推理的基准。
### Conclusion
BiomedSQL为提高能够支持科学发现的文本到SQL系统提供了新的基础，特别是在处理结构化的生物医学知识库时可以通过坚实的推理实现。该数据集和代码可以在指定的链接处获取，这将进一步推动生物医学领域相关技术的发展。
## 654. `cs.CL` - 语言特定的潜在过程阻碍了跨语言性能 [PDF](https://arxiv.org/pdf/2505.13141), [HTML](https://arxiv.org/abs/2505.13141)
### Authors
Zheng Wei Lim,Alham Fikri Aji,Trevor Cohn
### Background
大型语言模型（LLMs）在跨语言迁移方面表现出色，但当用不同语言的相同问题进行提示时，会生成不一致的输出。为了理解语言模型如何从一种语言推广到其他语言的知识，该研究测量了不同语言之间的表示相似性，并应用对数几率视角来解释LLMs在解决多语言多项选择推理问题时所采取的隐式步骤。研究发现，LLMs在预测时表现出不一致性并不够准确，因为它们依赖的是跨语言差异较大的表示，而不是在共享语义空间中工作。较大的模型更加多语言化，但它们的隐藏状态更有可能与共享表示偏离，但在多语言知识检索能力上仍然更为强大。
### Innovation
该研究通过测量不同语言之间的表示相似性，并应用对数几率视角来解释LLMs在解决多语言多项选择推理问题时所采取的隐式步骤。研究发现，较小模型中的知识共享可以通过将它们的潜在处理导向共享语义空间来促进，从而提高了模型的多语言推理性能，并改善了输出一致性。
### Conclusion
通过将较小模型的潜在处理导向共享语义空间，可以促进知识共享并提高其多语言推理性能，同时也改善了输出的一致性。
## 655. `cs.CL` - 从标记到思维：LLMs与人类如何权衡压缩与意义 [PDF](https://arxiv.org/pdf/2505.17117), [HTML](https://arxiv.org/abs/2505.17117)
### Authors
Chen Shani,Liron Soffer,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv
### Background
人类组织知识形成紧凑的类别，能够在压缩规模的同时保留语义意义。大型语言模型（LLMs）展示了显著的语用能力，但它们是否能在相同程度上实现这种平衡尚不清楚。本文通过应用信息瓶颈原理对LLMs和人类如何在压缩与语义之间的取舍进行定量比较，分析了40多种LLMs的嵌入表示与经典的人类分类基准，揭示了三个关键发现。
### Innovation
首次应用信息瓶颈原理对LLMs和人类如何在压缩与语义之间的取舍进行定量比较，通过分析从多种LLMs中提取的嵌入表示与经典的人类分类基准，揭示了二者的不同策略。发现LLMs在压缩度方面表现出更强的能力，而人类则更重视上下文丰富性和适应性灵活性。此外，提出的训练动态分析揭示了概念结构在模型训练过程中的发展过程。
### Conclusion
LLMs和人类在处理压缩和语义之间的取舍方面采取了不同的策略。LLMs优化压缩，人类则注重适应性的实用功能。这些差异揭示了人工智能与生物智能之间的根本区别，为开发更符合人类认知的AI提供指导。
## 656. `cs.CL` - RARE: 为检索增强生成系统构建检索意识下的鲁棒性评估 [PDF](https://arxiv.org/pdf/2506.00789), [HTML](https://arxiv.org/abs/2506.00789)
### Authors
Yixiao Zeng,Tianyu Cao,Danqing Wang,Xinran Zhao,Zimeng Qiu,Morteza Ziyadi,Tongshuang Wu,Lei Li
### Background
检索增强生成（RAG）可以提高答案的时效性和事实准确性。然而，现有的评估方法很少测试这些系统在面对真实世界噪声、内部和外部检索上下文冲突或快速变化的事实时的处理能力。
### Innovation
该论文引入了RARE（RAREqure）框架和大规模基准，用于联合测试查询和文档扰动对动态、时间敏感语料库的鲁棒性。该框架包含一个基于知识图谱的合成管道（RARE-Get），可以自动从定制语料库中提取单跳和多跳关系，并生成多层次的问题集，无需人工干预。基于此管道，构建了一个涵盖527份专家级时间敏感的金融、经济和政策文件以及48295个问题的数据集。引入了鲁棒性评估指标（RARE-Met），以量化模型在查询、文档或真实世界检索结果系统性改变时保持正确性或恢复的能力。
### Conclusion
研究发现，RAG系统对扰动的敏感性超出了预期。此外，所有领域内，多跳查询的鲁棒性普遍低于单跳查询的鲁棒性。
## 657. `cs.CL` - InfiMed: 低资源医学多模态大语言模型及其增强的理解与推理能力 [PDF](https://arxiv.org/pdf/2505.23867), [HTML](https://arxiv.org/abs/2505.23867)
### Authors
Zeyu Liu,Zhitian Hou,Guanghao Zhu,Zhijie Sang,Congkai Xie,Hongxia Yang
### Background
多模态大语言模型（MLLMs）在视觉理解和数学推理等领域取得了显著进展。然而，它们在医疗领域的应用受到两个关键挑战的限制：（1）医疗多模态数据稀缺且常包含稀疏信息，限制了推理深度；（2）尽管在一般领域中强化学习与可验证奖励（RLVR）有效，但在医疗领域却不能可靠地提高模型性能。
### Innovation
在监督微调（SFT）阶段，将高质量的文本推理数据和一般多模态数据与医学多模态数据结合，以有效地增强医学基础能力并恢复基础模型的推理能力。还考虑合成注入了反思模式的思维链（CoT）的样本，为模型提供初步的反思推理能力，这些能力为后续的RLVR训练提供了结构化的基础。提出了InfiMed系列模型（InfiMed-SFT-3B和InfiMed-RL-3B），这两个模型在七个医学多模态基准中表现出最先进的性能。特别是在RLVR阶段，引入了InfiMed-RL-3B，其平均准确率达到59.2%，超过了如InternVL3-8B等更大规模的模型（57.3%）。SFT阶段使用了188K样本，RLVR阶段使用了36K样本，突显了两种训练策略的有效性。
### Conclusion
通过引入InfiMed系列模型和创新的训练策略，该研究提升了多模态大语言模型在医疗场景中的性能，特别是在强化学习与可验证奖励训练方面取得了显著成果。
## 658. `cs.CL` - Table-R1：表格推理的推理时扩展 [PDF](https://arxiv.org/pdf/2505.23621), [HTML](https://arxiv.org/abs/2505.23621)
### Authors
Zheyuan Yang,Lyuhao Chen,Arman Cohan,Yilun Zhao
### Background
该研究探索了在表格推理任务中实现推理时扩展的可能性。当前文献中尚未有专门针对这一问题的研究，因此这是一个新的研究领域。
### Innovation
开发了两种后训练策略来实现推理时扩展：一是通过从先进模型推理痕迹中精简学习；二是利用可验证奖励的强化学习（RLVR），针对具体任务提出了可验证奖励函数并使用GRPO算法获得了Table-R1-Zero模型。通过这些方法实现了使用7B参数模型即匹配甚至超越GPT-4.1和DeepSeek-R1的表现。
### Conclusion
Table-R1系列模型在多种表格推理任务中表现优异，特别是在使用较少参数的情况下能匹配甚至超过表现更强的模型。这些模型表现出良好的跨领域泛化能力。研究中还通过消融实验和定性分析揭示了指令调优、模型架构选择和跨任务泛化的重要性，并展示了解释和推理技能在强化学习训练中显现出来。
## 659. `cs.CL` - 通过参数化知识强化学习抵抗RAG中的上下文干扰 [PDF](https://arxiv.org/pdf/2506.05154), [HTML](https://arxiv.org/abs/2506.05154)
### Authors
Chenyu Lin,Yilin Wen,Du Su,Hexiang Tan,Fei Sun,Muhan Chen,Chenfu Bao,Zhonghou Lyu
### Background
检索增强生成（RAG）在知识密集型任务上的性能有所提高，但在检索到错误、无关或冲突的信息时可能导致模型依赖不准确的证据并引发连锁错误。
### Innovation
提出了一种名为Knowledgeable-R1的强化学习框架，该框架明确训练大规模语言模型使用参数化知识（PK）来抵消上下文干扰，同时在外部上下文可靠有益时加以利用。该框架引入了一种联合采样方案，生成带有和不带检索的配对响应，并学习局部优势（每个解码状态下）和全局优势来量化何时忽略误导性上下文以及何时采纳它。该框架采用不对称优势变换，以增强对参数化知识的探索性行为。
### Conclusion
实验表明，该方法在知识冲突场景和一般RAG场景中显著提升了鲁棒性和推理准确性，在反事实场景中优于最先进的基线方法23%，并且在检索上下文完全可用时未出现性能下降。相关代码可在指定网址获取。
## 660. `cs.CL` - 通过对比个人偏好进行个性化大语言模型解码 [PDF](https://arxiv.org/pdf/2506.12109), [HTML](https://arxiv.org/abs/2506.12109)
### Authors
Hyungjune Bu,Chanjoo Jung,Minjae Kang,Jaehyung Kim
### Background
随着大规模语言模型（LLMs）在各种实际应用中的部署，LLMs的个性化变得越来越重要。虽然已经探索了诸如提示基础和训练基础等多种LLMs个性化的方法，但解码时间算法的有效开发仍然被忽视，尽管它们展示了巨大的潜力。
### Innovation
提出了一种名为CoPe（Contrasting Personal Preference）的新颖解码时间方法，该方法在用户特定数据上进行参数高效微调（PEFT）之后应用。核心思想是通过最大化每个用户的隐含奖励信号，利用引导式的解码进行个性化。
### Conclusion
通过CoPe在五个开放式个性化文本生成任务上的实证结果表明，CoPe达到了很强的性能，平均在ROUGE-L指标上提高了10.57%的个性化效果，且无需依赖外部奖励模型或额外的训练程序。
## 661. `cs.CL` - 响应归因：基于Jensen-Shannon散度的检索增强生成中上下文归因的机理研究 [PDF](https://arxiv.org/pdf/2505.16415), [HTML](https://arxiv.org/abs/2505.16415)
### Authors
Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz
### Background
检索增强生成（RAG）通过将大型语言模型（LLMs）与外部上下文相结合，提高了生成响应的准确性和可靠性。然而，由于现有归因方法计算密集且往往需要大量微调或人工注释，如何可靠地将生成内容归因到特定的上下文片段还具有挑战性。本文基于Jensen-Shannon散度提出了一种新颖的方法，用于有效且准确地识别重要上下文句子，而不需额外的微调、梯度计算或代理模型。这项研究改进了现有的代理模型方法，在各个方面都展现了更高的准确性和显著的计算效率。
### Innovation
本文提出的ARC-JSD方法，利用Jensen-Shannon散度来驱动响应归因。该方法能够有效地识别生成内容与特定上下文片段之间的联系，无需额外的微调、梯度计算或代理模型。这种方法适用于不同规模的指令调优LLMs，并在多个RAG基准测试中展示了优越的准确性和显著的计算效率提升。作者还进行了详细的机制分析，揭示了特定注意头和多层感知器（MLP）层在上下文归因中的作用，为理解RAG模型内部工作原理和其对RAG行为的影响提供了有价值的见解。
### Conclusion
与基于代理模型的方法相比，本文提出的方法显示了更高的准确性和显著的计算效率。机制分析还揭示了特定的注意头和多层感知器（MLP）层在上下文归因中的作用，为研究RAG模型内部机制提供了重要的参考。代码可在该网址获取。
## 662. `cs.CL` - MUCAR：多语言跨模态歧义解析基准测试 [PDF](https://arxiv.org/pdf/2506.17046), [HTML](https://arxiv.org/abs/2506.17046)
### Authors
Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu
### Background
多模态大型语言模型(MLLMs)在视觉-语言任务中取得了显著进展，显示出在匹配视觉和文本模式方面的良好能力，能够处理清晰明确的图像-文本对。然而，解决现实世界语言和视觉背景中的固有歧义仍然是一项挑战。当前的多模态基准大多忽视了语言和视觉的歧义，主要依赖单一模态上下文进行歧义消解，未能充分利用模态间的相互澄清潜力。
### Innovation
本文提出了MUCAR，这是一个新的具有挑战性的基准，旨在评估MLLMs在多语言和跨模态场景中的多模态歧义解析能力。MUCAR包含一个包含多语种数据集，其中含模糊文本表达式通过相应视觉背景来唯一解决，另一个是双重歧义数据集，其中模糊图像与模糊文本上下文系统配对，精心构建以通过相互澄清得到单一清晰解释。
### Conclusion
广泛评估了19个最先进的多模态模型，涵盖开源和专有架构，发现与人类表现相比存在显著差距，强调了对更复杂的跨模态歧义理解方法的未来研究需求，从而进一步推动多模态推理边界。
## 663. `cs.CL` - 包容性ASR：探索非资源语言中的言语转换在构音障碍语音识别中的应用 [PDF](https://arxiv.org/pdf/2505.14874), [HTML](https://arxiv.org/abs/2505.14874)
### Authors
Chin-Jou Li,Eunjung Yeo,Kwanghee Choi,Paula Andrea Pérez-Toro,Masao Someki,Rohan Kumar Das,Zhengjun Yue,Juan Rafael Orozco-Arroyave,Elmar Nöth,David R. Mortensen
### Background
基于数据稀缺性，非英语构音障碍语音的自动语音识别（ASR）仍然是一个挑战。为此，研究开发了一种方法，即通过在英语构音障碍语音（UASpeech）上微调语音转换模型，以编码说话人特征和语调失真，然后将其应用于将健康非英语语音（FLEURS）转换为非英语的构音障碍样语音，生成的数据用于进一步细调多语言ASR模型Massively Multilingual Speech（MMS），以提升构音障碍语音识别的效果。评估结果显示，结合说话人和语调转换的语音转换显著优于直接使用现成的MMS模型和常规的增广技术，如速度和节拍扰动。生成的数据进一步的客观和主观分析也证实，生成的语音模拟了构音障碍的特点。
### Innovation
该研究利用细调的语音转换模型来生成非英语构音障碍样语音，这些数据被用于进一步优化ASR模型MMS，以改善对构音障碍语音的识别性能。这种方式的优势在于通过引入新数据集提升了模型的适应性和准确性，解决了小数据集带来的问题。同时，这种方法也为其他低资源语言中的构音障碍语音识别提供了新的思路。
### Conclusion
该研究表明，结合说话人和语调转换的语音转换技术在低资源语言中有显著的效果提升。生成的数据对于模拟构音障碍的语言特征非常有效，为ASR在构音障碍语音识别中的应用提供了新的解决方案，并展示了在非英语环境中使用这种方法的潜力。
## 664. `cs.CL` - KaLM-Embedding-V2：优越的训练技术和高质量数据激发了多功能嵌入模型 [PDF](https://arxiv.org/pdf/2506.20923), [HTML](https://arxiv.org/abs/2506.20923)
### Authors
Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Xin Zhang,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang
### Background
近年来，基于大规模语言模型（LLMs）的文本嵌入模型主要关注数据规模或合成，但在训练技术和数据质量方面探索有限，这限制了模型的性能。
### Innovation
本文提出了KaLM-Embedding-V2系列模型，通过先进的训练技术和高质量数据，系统地激励LLMs的高级嵌入能力。具体创新包括：1)模型架构采用0.5B小规模模型，使用简单平均池化生成固定长度的嵌入，并移除因果注意力掩码以实现双向表示学习；2)训练技术提出了一种渐进式的多阶段训练流程：预训练阶段使用弱监督大规模数据集，微调阶段使用监督高质量数据集，以及采用了对比式蒸馏、细粒度软信号、焦点式重加权和在线难负样本混合策略；3)训练数据收集了超过20类用于预训练和100类用于微调和对比蒸馏的数据集，确保高质量并通过任务特定指令、难负样本挖掘和基于示例的多类别标注来增强泛化能力。
### Conclusion
综合这些技术，KaLM-Embedding-V2系列在大规模文本嵌入基准测试上达到了最先进的性能，比同等规模模型表现更好，甚至超过了大小3-26倍的其他模型，确立了多功能且紧凑的嵌入模型的新标准，在参数量不到1B的情况下设立了新标杆。代码、数据和模型将公开以促进学术研究。
## 665. `cs.CL` - Unlearning 不是删除：探究大规模语言模型中机器卸载的可逆性 [PDF](https://arxiv.org/pdf/2505.16831), [HTML](https://arxiv.org/abs/2505.16831)
### Authors
Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu
### Background
大规模语言模型（LLMs）中的卸载旨在移除指定的数据，但其有效性通常通过任务级别的指标如准确率和困惑度来评估，这些指标往往具有误导性。模型可能看似已经“忘记”某些信息，但实际上可以通过少量的微调轻易恢复到原有的行为。这种现象称为可逆性，表明信息只是被抑制，而不是被真正擦除。现有的评价方法未能捕捉到这种可逆性，导致对卸载效果的误判。
### Innovation
该研究提出了一个代表层级分析框架，该框架采用了基于主成分分析（PCA）的相似性与偏移、中心化核对齐（CKA）和费雪（Fisher）信息，以及一个综合度量—平均PCA距离，用于测量表示变化。通过将该框架应用于六种卸载方法、三个数据域以及两个LLM，该研究确定了四种基于可逆性和灾难性的遗忘模式。结果揭示了卸载的理想状态—不可逆且非灾难性的遗忘极为难以实现。这项研究还揭示了一个看似不可逆的有针对性的遗忘案例，从而为设计更稳健的删除算法提供了新的见解。该研究填补了当前评估实践中的基本空白，并为可信的卸载建立了代表层级的基础。
### Conclusion
当前的卸载评估方法存在重大的评估缺口。研究发现，实现不可逆且非灾难性遗忘的最优状态极为困难。通过探究卸载的极限，研究揭示了一个看似不可逆的精确卸载案例，为设计更具鲁棒性的删除算法提供了新的视角。这些发现为理解和改进大规模语言模型的卸载方法提供了重要的理论支持，并有助于构建更加可信的卸载机制。
## 666. `cs.CL` - EmoBench-UA: 乌克兰情绪检测基准数据集 [PDF](https://arxiv.org/pdf/2505.23297), [HTML](https://arxiv.org/abs/2505.23297)
### Authors
Daryna Dementieva,Nikolay Babakov,Alexander Fraser
### Background
尽管乌克兰的自然语言处理在许多文本处理任务中取得了进展，但情绪分类领域仍然是一个未被充分利用的领域，目前尚未有公开可用的基准数据集。本研究介绍了EmoBench-UA，这是首个专门为情绪检测在乌克兰语文本上的标注数据集。该数据集的注释方案源自之前以英语为主的有关情绪检测的研究工作（Mohammad等，2018；Mohammad，2022），并通过众包方式在CrowdFlower平台上创建，确保了注释过程的质量。研究还评估了从基于语言的方法、合成数据（来自英语）到大规模语言模型（LLMs）的一系列方法。研究结果强调了非主流语言如乌克兰语的情绪分类面临的挑战，以及进一步开发乌克兰特定模型和培训资源的必要性。
### Innovation
本研究首次推出了EmoBench-UA，这是首个专门针对乌克兰语情绪检测的标注数据集。研究采用了CrowdFlower平台进行众包标注，保证了数据集质量，并对各种方法进行了评估，涵盖了基于语言的基本方法、合成数据、到大规模语言模型，为非主流语言的情绪检测提供了新的研究基础和挑战。
### Conclusion
研究结果表明，非主流语言如乌克兰语的情绪分类仍然面临很大挑战，需要进一步开发专用模型和更多培训资源。EmoBench-UA为将来在乌克兰语情绪分类方向的研究提供了重要的基准数据集，有助于促进乌克兰语自然语言处理技术的发展。
## 667. `cs.CL` - 对话足够吗？探索大规模语言模型中的知识集成与可控生成 [PDF](https://arxiv.org/pdf/2505.19660), [HTML](https://arxiv.org/abs/2505.19660)
### Authors
Tingjia Shen,Hao Wang,Chuan Qin,Ruijun Sun,Yang Song,Defu Lian,Hengshu Zhu,Enhong Chen
### Background
开放域问答（OpenQA）作为自然语言处理（NLP）的一个基本组成部分，主要关注从非结构化文本数据中提取答案。大规模语言模型（LLM）的进步使基于LLM的OpenQA方法受益匪浅，但大多数方法仍然面临两个关键挑战：如何有效地将知识集成到LLMs中，以及如何根据不同任务情况自适应地生成具有特定答案格式的结果。现有方法在知识集成和结果生成方面存在局限性，因此本研究提出了名为GenKI的新框架，旨在通过同时探索知识集成和可控生成来提高OpenQA性能，并通过密集段落检索和知识集成模型进行了实验验证，结果显示GenKI在不同答案格式的数据集中表现出色，优于最先进的基线方法。
### Innovation
提出了一种名为GenKI的新框架，旨在通过同时探索知识集成和可控生成来改善OpenQA性能。具体来说，首先训练了一个密集段落检索模型来检索给定知识库中的相关知识，然后引入了一种新的知识集成模型，在微调过程中将检索到的知识融入指令以加强模型。为了在LLMs中实现可控生成，还利用微调后的LLM和基于文本一致性（包含连贯性、流畅性和答案格式保障）的集成。此外，通过广泛的实验和消融研究证明了GenKI的有效性，并揭示了检索知识的频率与模型准确召回知识的能力之间存在线性关系。
### Conclusion
在TriviaQA、MSMARCO和CMRC2018数据集上的广泛实验表明，GenKI方法在各种答案格式的数据集上表现优异，优于最先进的基线方法。消融研究进一步证明了GenKI的有效性，并表明检索到的知识频率与模型准确召回知识的能力之间存在线性关系。相关代码已公开，并提供在上述链接中。
## 668. `cs.CL` - QA-LIGN: 通过宪法分解问答对大语言模型进行对齐 [PDF](https://arxiv.org/pdf/2506.08123), [HTML](https://arxiv.org/abs/2506.08123)
### Authors
Jacob Dineen,Aswin RRV,Qin Liu,Zhikun Xu,Xiao Ye,Ming Shen,Zhaonan Li,Shijie Lu,Chitta Baral,Muhao Chen,Ben Zhou
### Background
目前使用的原则导向奖励通常难以解释，导致训练信号背后的特定目标不透明。为此，本文提出了一种方法，将单一的奖励信号分解为可解释的原则特定评估，通过结构化的自然语言程序实现。这种方法可以在GRPO训练期间为模型提供透明的反馈，增强其对齐效果，尤其是在安全性和帮助性方面表现出色。
### Innovation
提出了一种名为QA-LIGN的方法，通过分解单一的奖励信号为可解释的原则特定评估，利用结构化的自然语言程序。这种方法包括草拟、评估和修订的循环过程，模型通过对框架的符号评估获得透明反馈，从而改进其初始和修订后的回应，以达到帕累托有效的安全性和帮助性表现。与DPO和GRPO相比，使用最先进的奖励模型在同等训练下有显著提升。
### Conclusion
MQA-LIGN使得奖励信号变得更加可解释和模块化，从而提高了对齐的有效性。这表明透明度在提高大语言模型的安全性方面起到了关键作用。
## 669. `cs.CL` - 大型语言模型的神经拓扑探针 [PDF](https://arxiv.org/pdf/2506.01042), [HTML](https://arxiv.org/abs/2506.01042)
### Authors
Yu Zheng,Yuan Yuan,Yue Zhuo,Yong Li,Paolo Santi
### Background
通过将神经激活与可解释的语义联系起来，探查大型语言模型（LLMs）已经揭示了关于其内部机制的一些有价值的见解。然而，将神经元的功能共激活链接到模型能力的复杂机制仍然 largely unknown，这阻碍了对LLMs的更深入理解和更安全的发展。传统的方法主要依赖于激活来探查这种连接，但本研究提出了一种新的方法——图探针，通过这种方法可以揭示LLMs神经元的功能连接性，并将其与语言生成性能相关联。
### Innovation
研究引入了图探针方法，该方法能够揭示大型语言模型神经元的功能连接性并将其与语言生成性能相关联。探测结果显示，仅通过神经拓扑即可普遍预测下一个令牌预测性能，即使保留仅有1%的神经元连接。这种拓扑探针方法比基于激活的探针方法性能高出130.4%，这表明神经拓扑包含比神经激活更丰富的网络性能信息，这些信息可以通过简单的线性或MLP探测器轻松提取。这些发现进一步表明，神经拓扑可以用于提高LLMs的效率、可靠性和安全性，如模型剪枝、幻觉检测和LLM指纹识别等实际应用。
### Conclusion
本研究不仅提出了图探针方法，还通过多种基准测试和因果实验，证明了神经拓扑对语言性能的重要性。通过这种方法，神经拓扑可以被有效利用，以提高LLMs的效率、可靠性和安全性，为未来更大规模和更复杂的LLMs的发展提供了新的视角。所有相关的代码和数据可从以下链接获取：this https URL
## 670. `cs.CL` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大语言模型（LLMs）已在数学、事实性问答和代码生成等领域取得了显著成就，但在多语言环境下的推理能力仍未得到充分发展。特别是对于如斯瓦希里语或泰语等低资源语言，LLMs 往往会对提示理解有误，进而默认使用英语进行推理。这种偏好高资源语言的隐含偏向会损害事实准确性、可解释性和信任度。
### Innovation
我们提出了 M2A 方法，结合多尺度多语言对齐和机器翻译问题上的语言一致性奖励训练模型，使其能够直接且准确地在目标语言进行推理。此外，现有的多语言基准测试仅评估最终答案而不考虑推理是否在目标语言中发生，为此我们引入了一个基于地理的多语言事实推理基准 GeoFact-X，其中包括英语、印地语、日语、斯瓦希里语和泰语等五种语言的推理过程记录。
### Conclusion
我们的结果表明，M2A 显著提高了多语言推理的准确性和事实推理的任务中的表现，强调了意识推理的多语言强化学习对于跨语言泛化的关键作用。
## 671. `cs.CL` - LoopServe：多轮对话中大型语言模型双阶段推理加速的自适应系统 [PDF](https://arxiv.org/pdf/2507.13681), [HTML](https://arxiv.org/abs/2507.13681)
### Authors
Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan
### Background
多轮对话在许多实际应用中是必不可少的，例如聊天机器人和虚拟助手。随着对话历史的延长，现有的大型语言模型面临着日益增长的计算和内存挑战，这阻碍了它们提供高效和响应式交互的能力。目前的加速方法要么压缩背景信息，要么优化关键值缓存，但它们经常依赖固定或位置基础的启发式方法，并不能很好地适应实际多轮对话中动态和不可预测的模式。因此，这些模型无法准确确定和优先考虑最相关的背景信息，导致响应质量下降。
### Innovation
LoopServe 是一种适应性的双阶段推理加速框架，设计用于大型语言模型在多轮对话中的应用。 LoopServe 的两大创新之处在于：首先，在填充预填阶段通过动态选择每个新输入中最重要的部分来进行在线稀疏化；其次，在解码阶段通过基于最近生成的输出令牌逐步压缩关键值，适当地维护一个相关且高效的缓存。
### Conclusion
通过广泛的实验，证明了 LoopServe 在多个长期背景对话任务中显著优于现有基线，并能一致且显著地加速大型语言模型的推理。
## 672. `cs.CL` - 揭秘扩散大语言模型在可控生成中的潜力 [PDF](https://arxiv.org/pdf/2507.04504), [HTML](https://arxiv.org/abs/2507.04504)
### Authors
Zhen Xiong,Yujun Cai,Zhecheng Li,Yiwei Wang
### Background
可控生成是自然语言处理（NLP）中的基本任务，具有广泛的应用前景，是实现有目的性交流的基础。然而，最先进的自回归大型语言模型（LLMs）在生成结构化输出时仍然表现出不可靠性。扩散模型大型语言模型（dLLM）在这些方面展现出潜力，但其架构差异，尤其是全局信息共享机制，可能成为实现更高层次可控生成的关键。
### Innovation
本文提出了自适应架构支撑框架（$S^3$），使dLLM能够利用其内在的逆向推理能力和全局上下文意识，稳定生成可靠的结构化输出（例如JSON）。$S^3$框架直接在输出上下文中初始化模式化模板，提供了一种比复杂提示优化更稳健和通用的方法。实验表明，该方法显著提高了dLLM在结构依从性、内容保真度和忠实度方面的可控生成潜力。
### Conclusion
这些结果为利用语言模型进行可控生成任务的部署提供了新的视角和实用途径。
## 673. `cs.CL` - Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs [PDF](https://arxiv.org/pdf/2507.18578), [HTML](https://arxiv.org/abs/2507.18578)
### Authors
Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao
### Background
扩散大型语言模型（DLLMs）已经成为了与自回归模型（AR）相比的一种有吸引力的替代方案，特别适合于快速并行生成。然而，现有的DLLMs面临着严重的速度与质量权衡问题，即更快的并行解码会导致性能显著下降。
### Innovation
我们提出了一种名为Wide-In, Narrow-Out（WINO）的无训练解码算法，能够实现DLLMs中的可撤销解码。WINO采用了一种并行草稿验证机制，同时进行多个标记的生成和利用模型的双向上下文验证并重新掩盖可疑标记以进行改进。
### Conclusion
实验结果表明，WINO显著提高了DLLMs的质量-速度权衡。例如，在GSM8K数学基准测试中，它将推理速度提高了6倍并提高了2.58％的准确率；在Flickr30K字幕中，它实现了10倍的速度提升且性能更高。更全面的实验展示了WINO的优越性并对其进行了深入的理解。
## 674. `cs.CL` - WildSpeech-Bench：在野外评估端到端语音LLMs的标准 [PDF](https://arxiv.org/pdf/2506.21875), [HTML](https://arxiv.org/abs/2506.21875)
### Authors
Linhao Zhang,Jian Zhang,Bokai Lei,Chuhan Wu,Aiwei Liu,Wei Jia,Xiao Zhou
### Background
近期的多模态大规模语言模型（LLMs）如GPT-4o展示了强大的直接语音交互能力。然而，缺乏专门且全面的端到端语音LLM评价基准阻碍了在实际应用中优化音频LLM的用户体验。现有的评价方法常常适应基于文本的基准，忽略了语音的特性挑战，包括语调、同音词、口吃以及不同的用户期望。目前，首次提出了一种全面的基准，系统性地评估端到端语音LLM在实际语音对话中的性能。该基准涵盖了多样的语音数据，并通过定制化评价清单和提示增强了自动评价的准确性。
### Innovation
这项研究引入了WildSpeech-Bench，这是首个专门设计用于系统地评估端到端语音LLM在实际对话中的基准。通过收集真实世界的聊天数据，涵盖了多样的说话者属性和声学条件，并增加了语音特有的现象。进一步设计了基于查询的评价方法，使用定制化的评价清单和提示，提高自动评价的准确性。该基准对多种主流语音模型进行了全面测试，并揭示了模型在不同语音场景下的显著差异。此外，基于查询的评价方法还能够对各个特定的语音场景进行更细致的评估。
### Conclusion
此项研究提出了WildSpeech-Bench基准，能够提供语音模型开发和评估的关键见解。通过对不同语音场景中多个主流语音模型的测试和深入分析，揭示了模型性能的显著差异，并展示了基于查询的评估方法在各个特定的语音场景中进行更细致评估的能力。
## 675. `cs.CL` - 什么因素影响金融问答中的LLMs和RLLMs？ [PDF](https://arxiv.org/pdf/2507.08339), [HTML](https://arxiv.org/abs/2507.08339)
### Authors
Peng Wang,Xuesi Hu,Jiageng Wu,Yuntao Zou,Qiancheng Zhang,Dagang Li
### Background
近年来，大规模语言模型（LLMs）和具备长链推理能力的大规模语言模型（RLLMs）引起了众多研究者的关注。RLLMs通过长链推理过程增强了LLMs的推理能力，显著提升了它们在处理复杂问题时的性能。然而，很少有研究系统地探讨如何完全释放LLMs和RLLMs在金融领域的潜力。因此，文中利用五种LLMs和三种RLLMs，评估了提示方法、代理框架和多语言对齐方法对金融问答任务的影响。
### Innovation
研究发现了当前的提示方法和代理框架通过模拟长链推理来增强LLMs的性能；RLLMs具有的内在长链推理能力限制了传统方法进一步提升它们性能的效果；当前的高级多语言对齐方法主要通过扩展推理长度来增强多语言性能，但几乎不会对RLLMs产生益处。此外，提出了提高LLMs和RLLMs在金融问答中性能的策略。
### Conclusion
研究结果表明，可以通过利用长链推理方法、合理选择代理框架和优化多语言对齐方法来提升LLMs和RLLMs在金融问答中的表现，希望本研究能为该领域未来的研究提供重要的参考。
## 676. `cs.CL` - 使用角色增强基准测试：跨多元化写作风格评估LLMs [PDF](https://arxiv.org/pdf/2507.22168), [HTML](https://arxiv.org/abs/2507.22168)
### Authors
Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu
### Background
当前用于评估大语言模型（LLMs）的标准基准往往缺乏足够的写作风格多样性，许多基准主要遵循标准化规范。这些基准无法充分捕捉到人类多样化的交流模式。因此，优化于这些基准的LLMs在面对“非标准”输入时可能会表现脆弱。
### Innovation
本研究通过采用基于角色的语言模型提示方法（persona-based LLM prompting），重新撰写评估提示，以测试LLMs在多元化写作风格下的表现假设。研究结果表明，即使语义内容相同，写作风格和提示格式的差异显著影响评估中的LLM性能表现。研究还发现，特定的写作风格可以一致地触发不同模型和任务中的高或低性能。
### Conclusion
本研究提供了扩充现有基准测试的可扩展方法，提升评估其提供的跨语言变体测量LLM性能的有效性。
## 677. `cs.CL` - VAT-KG：知识密集型多模态知识图谱数据集以支持检索增强生成 [PDF](https://arxiv.org/pdf/2506.21556), [HTML](https://arxiv.org/abs/2506.21556)
### Authors
Hyeongcheol Park,Jiyoung Seo,MinHyuk Jang,Hogun Park,Ha Dam Baek,Gyusam Chang,Hyeonsoo Im,Sangpil Kim
### Background
多模态知识图谱（MMKGs）通过补充多模态大型语言模型（MLLMs）的隐性知识并促进基于检索增强生成（RAG）的有效推理，而在现有的MMKGs中，它们通常通过增强现有知识图谱来构建，这限制了知识的范围，导致知识过时或不完整，并且通常只支持有限的模态，如文本和视觉信息。这些限制限制了其在多模态任务中的应用，特别是随着最近的MLLMs采用更丰富的模态，如视频和音频。因此，我们提出了视觉-音频-文本知识图谱（VAT-KG），它是一个面向概念的概念密集型和知知识丰富的多模态知识图谱，能够涵盖视觉、音频和文本信息，并通过一系列严格的过滤和对齐步骤，确保跨模态知识在多模态数据与细粒度语义之间的对齐，从而实现从任意多模态数据集自动生成MMKGs。此外，我们还提出了一种新颖的多模态RAG框架，以响应来自任意模态的查询，检索概念级别的详细知识。在各种模态问题回答任务上的实验验证了VAT-KG的有效性，突显了它在多模态知识的统一和利用中的实际价值。
### Innovation
我们提出了视觉-音频-文本知识图谱（VAT-KG），这是一个面向概念的概念密集型和知知识丰富的多模态知识图谱，能够涵盖视觉、音频和文本信息，并通过一系列严格的过滤和对齐步骤，确保跨模态知识在多模态数据与细粒度语义之间的对齐。此外，我们还提出了一种新颖的多模态RAG框架，以响应来自任意模态的查询，检索概念级别的详细知识。
### Conclusion
我们在各种模态问题回答任务上的实验验证了VAT-KG的有效性，突显了它在多模态知识的统一和利用中的实际价值。
## 678. `cs.CL` - 通过增量多轮交互评估LLM代理的记忆 [PDF](https://arxiv.org/pdf/2507.05257), [HTML](https://arxiv.org/abs/2507.05257)
### Authors
Yuanzhe Hu,Yu Wang,Julian McAuley
### Background
目前对大型语言模型（LLM）代理的基准测试主要集中在评估其推理、规划和执行能力，而内存这一关键要素——包括如何记忆、更新和检索长期信息——由于缺乏基准尚被忽视。基于记忆科学和认知科学的经典理论，本研究认为记忆代理需要具备四个核心能力：准确检索、测试时学习、长程理解及选择性遗忘。现有的基准测试要么依赖于有限的上下文长度，要么适应静态、长上下文设置，无法反映记忆代理的交互式、多元轮次特性，这种特性允许信息逐渐积累。此外，没有任何一个现有的基准测试覆盖所有四个核心能力。
### Innovation
本文提出MemoryAgentBench，这是一个专门针对记忆代理的新基准测试。该基准测试将现有的长上下文数据集进行改造，并加入新构建的数据集，以多轮格式呈现，有效地模拟了记忆代理逐渐处理信息的特性。通过精心选择和策划数据集，本基准提供了上述四个核心记忆能力的全面覆盖，为评估记忆质量提供了一个系统且具有挑战性的测试平台。此外，本文评估了一系列不同的记忆代理，从简单的基于上下文和检索辅助生成（RAG）的系统到具有外部记忆模块和工具集成的高级代理。实证结果表明当前方法并未完全掌握所有四个核心能力，强调了对全面的记忆机制进一步研究的需求。
### Conclusion
当前方法未能掌握所有四个核心能力，未来需要进一步研究全面的记忆机制，以提升LLM代理的记忆质量。MemoryAgentBench提供了一个系统且具挑战性的评估平台，为将来的工作提供了基础。
## 679. `cs.CL` - KV 缓存控制以控制冻结的LLMs [PDF](https://arxiv.org/pdf/2507.08799), [HTML](https://arxiv.org/abs/2507.08799)
### Authors
Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,James R. Glass,Cees G. M. Snoek,Yuki M. Asano
### Background
现有的自然语言模型在推理任务上的表现需要通过调优、提示修改等方法来增强，这些方法通常较为复杂且效率低下。研究者们一直在寻找一种更轻量级、更高效的方法来引导模型的行为，以提高它们在复杂推理任务中的表现。
### Innovation
本文提出了缓存引导（Cache Steering）的方法，这是一种轻量级的方式，可以通过一次性干预直接作用于模型的key-value缓存，以隐式引导模型的行为。具体而言，这种方法通过从教师模型或现有的人类标注中获取推理轨迹，构建引导向量，从而将模型行为导向更明确的多步推理，而无需进行调优或提示修改。此外，该方法不仅可以应用于小型模型，还能扩展到大型模型，并在GPQA和MATH等具有挑战性的数据集上取得更好的表现。与需要持续干预的激活引导技术相比，缓存引导能够显著降低推理延迟，提高超参数的稳定性，同时使得与现有推理API的集成更加简便。缓存引导不仅能够引发推理，还能实现推理风格的可控转移（如步骤式、因果推理和类比推理），成为一个行为级指导语言模型的有效工具。
### Conclusion
实验结果表明，缓存引导可以提高模型推理的质量结构和任务性能，并且该方法在更大规模的模型上也表现良好。此外，它还能够在复杂的推理任务数据集上带来额外的提升。
## 680. `cs.CL` - PilotRL：通过全局规划引导渐进式强化学习训练语言模型代理 [PDF](https://arxiv.org/pdf/2508.00344), [HTML](https://arxiv.org/abs/2508.00344)
### Authors
Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang
### Background
大语言模型（LLMs）在解决代理导向任务方面取得了显著进步，但现有工作在部署LLMs于基于代理的环境中时面临着挑战。常用的代理范式ReAct偏向于将单步推理与即时操作执行结合，这限制了其在需要长期策略规划的复杂任务中的有效性。此外，解决问题过程中规划者与执行器之间的协调也是代理设计中需考虑的关键因素。现有的方法大多依赖于监督微调，这导致模型往往记住既定的任务完成路径，从而在面对新颖的场景时限制了其泛化能力。
### Innovation
该论文提出了一种自适应全局计划导向的代理范式AdaPlan，旨在结合高层次的明确指导与执行，以支持有效的长期决策制定。基于该范式，进一步提出了PilotRL，这是一种由渐进式强化学习驱动的全局规划引导训练框架，分为三个阶段：首先开发模型遵循全局计划中的明确指导以解决代理任务的能力；其次，优化生成计划的质量；最终，联合优化模型的规划与执行协调。实验表明，PilotRL能够达到最先进的性能，LLaMA3.1-8B-Instruct + PilotRL超越了封闭源代码的GPT-4o，高出3.60%，同时在相近参数规模下相对GPT-4o-mini的数据表明了更大的55.78%的增益。
### Conclusion
通过PilotRL框架，展示了在基于代理的任务解决中通过渐进式强化学习和全局规划引导方式的有效性，以及在处理新颖任务时模型的更好泛化能力。接下来的研究可能需要进一步探索不同规模和类型语言模型在不同任务环境下的应用表现及其优化策略。
## 681. `cs.CL` - 为什么强化微调能更好地让大模型保留先验知识：从数据角度分析 [PDF](https://arxiv.org/pdf/2506.23508), [HTML](https://arxiv.org/abs/2506.23508)
### Authors
Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Mingqi Wu,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang,Kai Chen
### Background
后训练算法，如监督微调（SFT）和强化微调（RFT），被广泛用于使多模态大型语言模型适应下游任务。尽管这些方法在任务适应上表现有效，但它们对先前知识的影响仍然不清楚。本文提出了一个新颖的任务——拼图游戏，作为现有预训练语料库中不存在的任务，系统研究了SFT和RFT在开源多模态模型Qwen2.5-VL系列上的行为。实验揭示了一个明显的权衡：SFT可以快速获取任务，但会导致灾难性的遗忘，而RFT则学习得更慢，但却能保持先前的知识。研究通过学习动态，从训练数据对先验知识影响的量级和方向两方面进行分析。分析表明，RFT主要增强了与基础模型概率景观自然对齐的正确样本的影响，从而较弱地干扰先验知识。此外，在模拟RFT训练过程中产生的影响较小且方向上与先验知识高度一致的样本上训练，使SFT既能保持先验知识，又能迅速学习新任务。这些发现表明了训练数据分布而非算法差异在遗忘中的核心作用，并突显了RFT在多模态大型语言模型中实现稳定连续学习的潜力.
### Innovation
本文提出了一种新颖的任务——拼图游戏来研究SFT和RFT在多模态大型语言模型中的行为。通过分析训练数据对先验知识影响的量级和方向，揭示了RFT通过增强与基础模型概率景观自然对齐的正确样本影响，从而较弱地干扰先验知识，以及在模拟RFT训练过程中产生的影响较小且方向上与先验知识高度一致的样本上训练，使SFT既能保持先验知识，又能迅速学习新任务。这些发现指出了训练数据分布对于遗忘中核心作用，并展示了RFT在实现多模态大型语言模型中稳定连续学习的潜力.
### Conclusion
本文的研究发现，RFT通过增强正确样本与基础模型概率景观的自然对齐，削弱对先验知识的干扰，并且通过模拟较小影响的样本来加强SFT在保留先验知识的同时学习新任务的能力。该研究强调了训练数据分布的重要性，并展示了RFT在多模态大型语言模型实现稳定连续学习的潜力.
## 682. `cs.CL` - 从幻觉到事实：大规模语言模型事实核查与事实评价的综述 [PDF](https://arxiv.org/pdf/2508.03860), [HTML](https://arxiv.org/abs/2508.03860)
### Authors
Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam
### Background
大语言模型（LLMs）在大量多样化的互联网语料库上进行训练，这些语料库经常包含不准确或误导性的内容，因此LLMs可能会生成错误信息。因此，进行坚实的事实核查变得至关重要。本综述系统地分析了LLM生成内容的准确评估方式，探讨了幻觉、数据集限制和评估指标可靠性的关键挑战，并强调需要整合先进的提示策略、领域特定微调和检索增强生成（RAG）方法的强大事实核查框架。
### Innovation
本综述提出了五个指导从2020年至2025年的相关文献分析的研究问题，重点关注评估方法和缓解技术。此外，它还审查了指令微调、多智能体推理和外部知识访问的RAG框架，确定了当前度量的局限性，并强调了需要验证外部证据和通过领域特定定制提高事实一致性。
### Conclusion
本综述强调了构建更准确、更易于理解且更富有情境感的事实核查的重要性。这些见解为研究向着更可信赖模型的进展做出了贡献。
## 683. `cs.CL` - GTPO和GRPO-S：基于策略熵的令牌和序列级奖励塑造 [PDF](https://arxiv.org/pdf/2508.04349), [HTML](https://arxiv.org/abs/2508.04349)
### Authors
Hongze Tan,Jianfei Pan,Jinghao Lin,Tao Chen,Zhihang Zheng,Zhihao Tang,Haihua Yang
### Background
强化学习（RL）对于提升大型语言模型（LLM）的推理能力至关重要。然而，传统的算法通常采用粗粒度的归因范式，为序列中的所有令牌分配统一的奖励，这在长期推理任务中是一个严重的缺陷。
### Innovation
本文提出了一种全新的机制，即动态熵加权，通过两种新的算法实现细粒度的奖励分配：组令牌策略优化（GTPO），它为每个令牌分配一个熵加权奖励；以及等效的序列级GRPO（GRPO-S）。这种方法基于假设，在推理路径中高策略熵是一个认知努力的强大启发式指标，可以重新利用为学习信号。通过重新利用策略熵进行奖励塑造，实现了真正的逐令牌归因。
### Conclusion
我们的方法在具有挑战性的推理基准上得到了验证，实验结果表明，我们提出的方法显著优于强大的DAPO基线，突显了熵加权机制作为性能提升的关键驱动因素。
## 684. `cs.CL` - THE ImitATION GAME: TURING MACHINE IMITATOR IS LENGTH GENERALIZABLE REASONER [PDF](https://arxiv.org/pdf/2507.13332), [HTML](https://arxiv.org/abs/2507.13332)
### Authors
Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Dahua Lin,Kai Chen
### Background
Transformer-based大型语言模型（LLM）在解决长度泛化问题时面临核心挑战，即在训练数据之外解决更长序列的问题。现有研究主要集中在数据驱动的方法上，适用于算术操作和符号操作任务，但这些方法通常较为任务特定，总体性能有限。
### Innovation
本文提出了Turing Machine Imitation Learning（TAIL），通过模拟图灵机的运行过程来生成含有链式思考（CoT）的数据，以改善LLM的长度泛化能力。TAIL通过线性扩展推理步骤为原子状态，缓解了捷径学习的问题，减少了动态和长距数据访问的困难。本文通过构建涵盖8类算法和18项任务的挑战性合成数据集，验证了TAIL的有效性，表明调度员一定要理解图灵机的基本概念，从而在注意力层中表现出与图灵机相一致的读写行为。
### Conclusion
本文为通过合成数据学习LLM推理提供了新的研究方向，通过TAIL显著提高了Qwen2.5-7B在各种任务上的长度泛化能力和性能，超越了先前的方法和DeepSeek-R1。
## 685. `cs.CL` - 带有冲突感知的软提示生成为检索增强生成 [PDF](https://arxiv.org/pdf/2508.15253), [HTML](https://arxiv.org/abs/2508.15253)
### Authors
Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee
### Background
检索增强生成（RAG）通过将外部知识融入大型语言模型（LLMs）的输入提示中，增强了LLMs的能力。然而，当检索到的上下文与LLMs的参数化知识产生矛盾时，常会出现外部错误上下文与内部正确参数知识之间的冲突（即上下文-记忆冲突），导致LLMs无法有效解决这一矛盾。
### Innovation
提出了一种名为冲突感知检索增强生成（CARE）的新方法，该方法由上下文评估器和基础LLM组成。上下文评估器通过紧凑的记忆令牌嵌入编码原始上下文令牌。通过基于地基/对抗的软提示训练，上下文评估器能够辨别不可靠的上下文并捕捉一个指导信号，从而引导推理方向指向更可靠的知识源。
### Conclusion
广泛的实验证明，CARE能有效缓解上下文-记忆冲突，使其在问答和事实核查基准测试中的平均性能提高了5.0%，为可信和适应性的RAG系统指明了新的一条具有前景的发展道路。
## 686. `cs.CL` - Geometric-Mean Policy Optimization [PDF](https://arxiv.org/pdf/2507.20673), [HTML](https://arxiv.org/abs/2507.20673)
### Authors
Yuzhong Zhao,Yue Liu,Junpeng Liu,Jingye Chen,Xun Wu,Yaru Hao,Tengchao Lv,Shaohan Huang,Lei Cui,Qixiang Ye,Fang Wan,Furu Wei
### Background
Group Relative Policy Optimization (GRPO)提升了大规模语言模型的推理能力，通过优化令牌级奖励的算术平均值。然而，GRPO在面对具有离群权重奖励的标记时，表现出不稳定的策略更新问题，这在训练过程中表现为极端的重要性采样比例。r
### Innovation
提出了Geometric-Mean Policy Optimization (GMPO)，通过最大化令牌级奖励的几何平均值来抑制标记奖励的离群值，从而提高GRPO的稳定性。GMPO适用于插拔，只需将GRPO的算术平均值替换为令牌级奖励的几何平均值。理论分析表明，GMPO和GRPO都可以看作是策略梯度的加权形式，但前者拥有更稳定的权重，从而有利于策略优化和性能提高。r
### Conclusion
在多个数学推理基准测试上，GMPO-7B在GRPO的基础上将平均的Pass@1提高了4.1%，并且在性能上优于许多最新方法。相关的代码可以在提供的链接中获取。r
## 687. `cs.CL` - ASCoT: 一种针对LLMs晚期脆弱性的自适应自我纠错链式思考方法 [PDF](https://arxiv.org/pdf/2508.05282), [HTML](https://arxiv.org/abs/2508.05282)
### Authors
Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian
### Background
链式思考（CoT）提示显著提高了大型语言模型（LLMs）的推理能力，但这些推理链的可靠性依然是一个关键挑战。广泛认为当错误在推理过程的早期出现时，它们的危害最大。然而，本研究通过系统性的错误注入实验挑战了这一假设，揭示了一种反直观的现象叫做‘晚期脆弱性’：引入在推理链较晚阶段的错误比在开始初期出现相同错误更有可能破坏最终答案。
### Innovation
为应对这种特定的脆弱性，研究提出了一种适应性自我矫正链式思考（ASCoT）方法。ASCoT采用模块化的流水线结构，首先由一个适应性验证管理器（AVM）运行，随后是多元视角自我矫正引擎（MSCE）。其中，AVM利用位置影响分值函数I(k)基于推理链中的位置对权重进行赋值，从而通过识别和优先处理高风险的晚期步骤来解决晚期脆弱性问题。一旦识别出这些关键步骤，MSCE就会应用稳健的双重路径矫正机制专门针对失败的部分。
### Conclusion
在GSM8K和MATH基准上的实验显示，ASCoT达到了卓越的准确性，并在包括标准CoT在内的强基线中表现出色。本研究强调了诊断LLMs推理中的特定失效模式的重要性，并提倡从统一的验证策略转向适应性、漏洞意识的矫正机制。
## 688. `cs.CL` - 由影响驱动的课程学习在有限数据预训练中的应用 [PDF](https://arxiv.org/pdf/2508.15475), [HTML](https://arxiv.org/abs/2508.15475)
### Authors
Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth
### Background
课程学习是一种训练技术，其中数据按照示例难度顺序（例如，从简单文档到复杂文档）呈现给模型，这种技术在预训练语言模型中的效果有限。这个问题论文的背景是探讨是否通过替换传统的基于人类的难度指标，用在模型训练过程中更为符合的难度指标来改进课程学习的效果。
### Innovation
论文创新点在于提出了一种新的排序方法，即根据‘训练数据影响’对训练示例进行排序，这种方法能够更好地反映模型在训练过程中的难度情况，从而改善课程学习的效果。论文通过实验证明，使用这种新方法的课程学习在基准测试中的表现显著优于随机排序训练的模型，展示了这种模型中心的难度观念在预训练中的有效性。
### Conclusion
研究结论是，课程学习对语言模型预训练是有益的，只要采用一种更符合模型的难度观念，例如训练数据的影响来定制课程学习。这种方法能够使模型在预训练阶段获得显著的性能提升。
## 689. `cs.CL` - 梦聊：基于用户信念建模的对话模型增强学习 [PDF](https://arxiv.org/pdf/2508.16876), [HTML](https://arxiv.org/abs/2508.16876)
### Authors
Yue Zhao,Xiaoyu Wang,Dan Wang,Zhonglin Jiang,Qingqing Gu,Teng Chen,Ningyuan Xi,Jinxian Qu,Yong Chen,Luo Ji
### Background
世界模型在机器人、游戏和自动驾驶等领域得到了广泛应用，但在自然语言处理任务中的应用相对有限。本文在这一背景下探讨如何使用世界模型来预测用户的情绪、态度和意图，并预测未来的话语。通过定义部分可观测马尔可夫决策过程（POMDP），作者提出了利用用户信念建模来解决这一问题的方法。
### Innovation
本文提出了名为DreamCUB的框架，即结合基于用户信念建模的模型增强学习框架，并结合强化学习模型（图灵）和批评家（批评模型）进行联合训练，从而提升对话质量。实验结果显示该方法在情绪分类和情感识别上取得了最先进的性能，并进一步分析表明这种方法在探索和利用之间保持了合理的平衡，并且可以在域外场景中良好地转移，例如同理心对话等。
### Conclusion
经过实验验证，预先训练的世界模型在情绪分类和情感识别上达到最先进的性能，对话质量通过联合训练政策、批评家和世界模型也得到了提升。这种方法在探索和利用之间持有一定的平衡，并对域外场景具有良好的迁移能力。
## 690. `cs.CL` - MLP记忆：大型语言模型的检索预训练记忆 [PDF](https://arxiv.org/pdf/2508.01832), [HTML](https://arxiv.org/abs/2508.01832)
### Authors
Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin
### Background
大型语言模型（LLM）在提高事实准确性及知识利用方面采用了现代方法，但面临一个根本性的权衡。无参数检索增强生成（RAG）方法提供了灵活的外部知识访问方式，但存在推理延迟高和知识整合浅的问题。参数微调方法如LoRA则存在灾难性遗忘和泛化能力下降的风险。因此，该研究旨在探索一种轻量级的参数模块MLP记忆，能够学习检索模式而无需显式访问文档，从而实现参数化的知识访问。
### Innovation
该研究提出了一种名为MLP记忆的轻量级参数模块，通过预训练MLP模仿kNN检索器的行为来较完整地捕捉基于检索的知识访问的优势，同时避免了RAG的低延迟和浅整合问题，以及LoRA的灾难性遗忘和泛化能力下降问题。这种参数化的学习机制使得MLP记忆在多个问题回答基准测试中表现出12.3%的相对改进，在九项通用NLP任务中平均提高5.2分，且减少幻觉现象达10分。此外，MLP记忆的推理速度比RAG快2.5倍，同时保持了更高的准确性。这项研究展示了参数化学习检索模式在提高推断效率和有效知识访问方面的作用，为RAG和微调方法提供了实用替代方案。
### Conclusion
MLP记忆利用参数化的机制有效融合了基于检索的知识访问和高效推理，这为大型语言模型的知识利用和推理效率提供了新的解决方案，展示了从中获得的显著性能提升和较短的推理时间，在多个NLP任务中表现出色。这种参数化方法提供了更实用和高效的知识访问机制，是现有方法的有效补充。
## 691. `cs.CL` - JudgeAgent：基于Agent-as-Interviewer的知识动态大语言模型评估 [PDF](https://arxiv.org/pdf/2509.02097), [HTML](https://arxiv.org/abs/2509.02097)
### Authors
Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Jian Guo,Yuanzhuo Wang
### Background
当前大语言模型（LLM）的评估 paradigm 夸大或存在偏见，且问题难度匹配不当，导致对知识和能力边界的评估不完整，这阻碍了LLM的有效应用和优化。
### Innovation
本文提出了一种动态评估 paradigm，名为Agent-as-Interviewer，使用LLM代理进行多轮互动评估，代理还可调用知识工具以实现更广泛和深入的知识获取，并通过计划查询策略调整问题难度，增强难度控制以匹配目标LLM的实际能力。基于此，开发了JudgeAgent，这是一种知识驱动的动态评估框架，使用知识驱动合成作为代理工具，并以难度评分作为策略指导，提供有价值的建议帮助目标模型优化自己。该评估框架能够准确识别目标模型的知识和能力边界。
### Conclusion
广泛的实验验证了JudgeAgent建议的有效性，表明Agent-as-Interviewer能够准确识别目标模型的知识和能力边界。
## 692. `cs.CL` - GPT-OSS 最新开源模型全面评估 [PDF](https://arxiv.org/pdf/2508.12461), [HTML](https://arxiv.org/abs/2508.12461)
### Authors
Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song
### Background
2025年8月，OpenAI 发布了GPT-OSS 模型，这是继2019年的GPT-2以来首次公开的重量级语言模型，包含两个混合专家架构，参数量分别为1200亿和200亿。作者评估了这两个版本与六个当代开源语言模型的性能，这六个模型的参数量从147亿到235亿不等，涵盖了从密集设计到稀疏设计的各种架构。
### Innovation
研究使用未经量化处理的标准推理设置对所有模型进行了测试，使用McNemar检验和效应分析进行统计验证。结果显示，GPT-OSS-20B在人类评估和MMLU等几个基准测试中一直优于GPT-OSS-120B，尽管后者在每个响应所需的内存和能源方面要少得多。研究表明，稀疏架构中的扩展可能不会带来正比的性能提升，让对此类优化策略的进一步研究变得必要。
### Conclusion
这两个模型在当前开源生态中的整体表现处于中等水平，代码生成中有优势，但在多语言任务上存在明显弱点。这些结果提供了关于稀疏架构扩展是否会产生预期性能改进的实证证据，强调了优化策略的重要性，并为未来的开源部署提供更有效模型选择的指导。有关详情和评估脚本可以在项目网页获得。
## 693. `cs.CL` - DAMR: 使用LLM指导的MCTS进行高效且自适应的上下文感知知识图谱问答 [PDF](https://arxiv.org/pdf/2508.00719), [HTML](https://arxiv.org/abs/2508.00719)
### Authors
Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Chao Wang,Nan Yin
### Background
知识图谱问答(KGQA)的目标是解释自然语言查询并在保持知识图谱的结构和语义关系的前提下获取准确的答案。现有方法主要采用检索-推理框架和动态路径生成策略，前者由于固定的路径提取和缺乏上下文细化导致缺乏适应性，后者则因依赖固定的评分函数和重复调用大语言模型导致计算成本高且评估准确性有限。
### Innovation
本文提出了DAMR框架，将大语言模型指导的蒙特卡洛树搜索（MCTS）与自适应路径评估相结合，以实现高效且上下文感知的KGQA。DAMR利用MCTS作为核心结构，通过LLM规划器在每次扩展步骤中选择最相关的语义关系来有效减少搜索空间。为提高评估准确性，引入了一个轻量级的基于Transformer的评分器，通过交叉注意力同时编码问题和关系序列进行上下文感知的可信度估计。此外，为了应对高质量监督数据稀缺的问题，DAMR引入了一种动态伪路径细化机制，从搜索过程中探索的部分路径中定期生成训练信号，使评分器能够不断适应推理轨迹分布的变化。
### Conclusion
广泛的实验表明，DAMR显著优于当前最先进的方法。
## 694. `cs.CL` - 基于Token感知相位注意力的位置编码 [PDF](https://arxiv.org/pdf/2509.12635), [HTML](https://arxiv.org/abs/2509.12635)
### Authors
Yu Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian
### Background
研究表明，Rotary Positional Embedding（RoPE）对注意力得分引入了一种内在的距离依赖性偏差，限制了它在长上下文建模中的能力。尽管RoPE扩展方法可以缓解这一问题，但通常需要在预训练后进行后处理调整，如重缩放或超参数调整。
### Innovation
本文提出了Token-Aware Phase Attention（TAPA），一种新的注意机制中的位置编码方法，它引入了一个可学习的相位函数来保留长范围内的标记交互，并且可以通过直接和轻量的微调扩展到更长的上下文，还可以外推到未见过的长度，并在长上下文中获得了比RoPE家族更低的困惑度。
### Conclusion
TAPA比RoPE家族在长上下文中有更好的性能，它可以保持长距离的标记交互，直接和轻量的微调即可扩展到更长的上下文，并在外推未知长度时表现出色，此外，TAPA在长语境下的困惑度也显著降低。
## 695. `cs.CL` - 思维矩阵或思维树？从思维矩阵的角度重新评估复杂推理 [PDF](https://arxiv.org/pdf/2509.03918), [HTML](https://arxiv.org/abs/2509.03918)
### Authors
Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao
### Background
大语言模型在处理复杂和抽象任务时因推理能力不足而面临显著的准确性降级。现有的一些思想结构，如Chain of Thought（CoT）和Tree of Thought（ToT），虽然旨在增强LSTM的推理能力，但也面临局限性，如层内冗余和链结构路径单一等问题。为了克服这些局限性，研究使用了Retrieval-Augmented Generation（RAG）方法来增强CoT和ToT，但在多实体和多跳信息处理中，检索到的验证知识会包含大量的碎片化、浅显或错误信息，这会影响LSTM的推理过程。
### Innovation
本文提出了一种新的高效思想结构——Matrix of Thought（MoT）。MoT通过“列单元通信机制”在横向和纵向两个维度上探索问题，减少列单元内部的思想节点冗余，并且通过事实校正机制利用知识图谱三元组和原始文本构造知识单元并纠正错误答案，从而增强LSTM的推理能力。实验结果显示，该框架优于现有的一些先进方法，并且推理时间仅为基线方法的14.4%%，证明了其效率和准确性。
### Conclusion
本文提出的MoT框架在三个任务（24点游戏、问答评估、问题命题）中取得了超越现有最先进的方法的效果，并证明了其在效率和准确性上的优势。
## 696. `cs.CL` - CMRAG：基于共模性的视觉文档检索与问答 [PDF](https://arxiv.org/pdf/2509.02123), [HTML](https://arxiv.org/abs/2509.02123)
### Authors
Wang Chen,Wenhan Yu,Guanqiang Qi,Weikang Li,Yang Li,Lei Sha,Deguo Xia,Jizhou Huang
### Background
在文档问题回答任务中，检索增强生成（RAG）已经成为核心架构。然而，现有的方法在处理多模态文档时存在局限：一种方法依赖布局分析和文本提取，只能利用显式的文本信息，难以捕捉图片或非结构化内容；另一种方法将文档分割作为视觉输入直接传递给视觉语言模型（VLMs）处理，却忽视了文本的语义优势，导致检索和生成效果不佳。
### Innovation
为解决这些问题，本文提出了基于共模性的RAG框架（CMRAG），能够同时利用文本和图像以实现更准确的检索和生成。本文框架包括两个关键组件：（1）统一编码模型（UEM），通过三元组训练将查询、解析文本和图像投影到共享嵌入空间；（2）统一共模指导检索（UCMR），通过统计归一化相似度分数有效融合跨模态信号。此外，本文还构建并发布了大规模的三元组数据集（query, text, image）以支持进一步的研究。实验证明，本文提出的框架在多个视觉文档问答（VDQA）基准测试中均优于基于单模态的RAG
### Conclusion
本文的研究结果表明，以统一的方式将共模信息整合到RAG框架中是提高复杂VDQA系统性能的有效方法。
## 697. `cs.CL` - 向人工智能音乐家迈进：合成乐谱问题以培养音乐推理能力 [PDF](https://arxiv.org/pdf/2509.04059), [HTML](https://arxiv.org/abs/2509.04059)
### Authors
Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Xiaoye Qu,Ziqian Qiao,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng
### Background
增强大型语言模型（LLMs）和多模态大型语言模型（MLLMs）解读乐谱的能力是建设AI音乐家的重要步骤。然而，当前的研究缺乏评估基准和用于乐谱推理的训练数据。乐谱推理涉及复杂的音乐理论规则，如节拍和音程的规则，当前研究在这方面的数据和评估不足。受数学的启发，简单的操作可以产生无限可验证的问题，该研究引入了一种新方法，将核心音乐理论规则视为程序函数，系统性地合成大量多样化的乐谱推理问题。
### Innovation
该研究提出了一种数据合成框架，用于生成在文本和视觉模态上可验证的乐谱推理问题，从而创建了综合乐谱推理基准（SSMR-Bench）和配套的训练集。评估结果显示，推理在解读乐谱中起着关键作用，但理解视觉格式下的乐谱仍然是一个持续的挑战。通过利用合成数据进行RLVR，所有模型在SSMR-Bench上都显示出显著的改进，并且也对先前建立的人类手工制作的基准（如MusicTheoryBench和MMMU音乐子集）取得了显著的进步。研究表明，增强的推理能力还能促进音乐创作能力的提高。
### Conclusion
通过合成数据，研究提高了所有模型在乐谱解读和音乐创作中的能力。该工作为构建AI音乐家提供了新的数据和评估基准，同时指出了乐谱理解中的持续挑战。
## 698. `cs.CL` - 建模类比和类比推理：将认知科学理论与自然语言处理研究联系起来 [PDF](https://arxiv.org/pdf/2509.09381), [HTML](https://arxiv.org/abs/2509.09381)
### Authors
Molly R Petersen,Claire E Stevenson,Lonneke van der Plas
### Background
类比推理是人类认知的重要组成部分。本文回顾了认知科学文献中关于类比推理过程的关键理论，并将其与当前自然语言处理（NLP）领域的研究联系起来。尽管这些过程可以轻松地与NLP的概念相联系，但它们通常不会从认知角度进行审视。本文指出，这些理论概念对多个NLP研究中的主要挑战具有相关性，不仅是类比求解相关的问题，而是涉及关系理解优化等更广泛的问题。
### Innovation
文章将认知科学中的类比推理理论与自然语言处理研究联系起来，揭示了类比推理理论对多个NLP研究挑战的相关性，并指导研究者更好地优化文本中的关系理解，而不仅仅是依靠实体层面的相似性。这种跨学科的研究视角为NLP领域带来了新的洞察和发展方向。
### Conclusion
通过整合认知科学理论与NLP研究，本文为理解并优化文本中的复杂关系提供了新的方法。研究者可以利用这些理论来更有效地优化关系理解，提升NLP的应用效果。
## 699. `cs.CL` - DivLogicEval: 一种评估大型语言模型逻辑推理能力的框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被广泛认为是衡量大型语言模型（LLMs）智能水平的重要指标。现有的逻辑推理基准测试可能会结合多种推理技能，从而未能真实地评估模型的逻辑推理能力。此外，现有的逻辑推理基准测试在语言多样性上有限，且其分布偏离了理想逻辑推理基准的分布，可能导致评估结果偏颇。
### Innovation
该论文提出了一个名为DivLogicEval的新基准测试框架，包括由多种陈述以反直觉方式组成的自然句子。为了确保评估的可靠性，论文还引入了一个新的评估指标，以减轻LLMs固有的偏见和随机性的影响。通过实验，论文展示了DivLogicEval对回答问题所需的逻辑推理程度，以及不同流行大型语言模型在进行逻辑推理方面的表现差异。
### Conclusion
实验结果证明了DivLogicEval在评估大型语言模型的逻辑推理能力方面的有效性，并且通过引入新的评估方法提高了评估的可靠性。
## 700. `cs.CL` - 不确定性下的推理：探索LLMs的概率推理能力 [PDF](https://arxiv.org/pdf/2509.10739), [HTML](https://arxiv.org/abs/2509.10739)
### Authors
Mobina Pournemat,Keivan Rezaei,Gaurang Sriramanan,Arman Zarei,Jiaxiang Fu,Yang Wang,Hamid Eghbalzadeh,Soheil Feizi
### Background
尽管大型语言模型（LLMs）在语言理解和生成方面取得了广泛的成功，但在需要概率推理的任务中，它们的表现往往是不清晰且不一致的。本文首次全面研究了LLMs在面对具体离散概率分布时的推理能力。通过根据不同概率分布进行观察，研究人员评估了模型在模式识别、最大似然估计和样本生成三个精心设计的任务上的表现，进一步探讨了频率分析、边际化和生成性行为等概率技能。研究表明，随着模型规模的增加，它们的推理能力和样本生成能力得到了显著增强，但同时也发现了显著的局限性，如对表示概率结果的符号变化的敏感性以及随着上下文长度增加超过60%的性能下降。
### Innovation
本文首次系统地研究了LLMs在进行概率推理时的能力，通过三个精心设计的任务来评估模型在频率分析、边际化和生成性行为等概率技能上的表现，并揭示了模型在不同规模和上下文长度下的表现差异和局限性。
### Conclusion
本文的研究结果详细揭示了LLMs在概率推理方面的能力和局限，并指出了未来改进的关键方向。
## 701. `cs.CL` - 分布对齐解码以提高高效大规模语言模型任务适配 [PDF](https://arxiv.org/pdf/2509.15888), [HTML](https://arxiv.org/abs/2509.15888)
### Authors
Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Yong Dai,Sam Tak Wu Kwong,Yuguang Fang
### Background
使用大参数量的语言模型进行下游任务的调整依然成本高昂，即便是在使用参数高效调整（PEFT）的情况下。传统的方法主要通过权重更新间接地调整模型的输出分布，此过程仍然是资源密集型的。本研究重新定义了任务调整为输出分布对齐：目标是在解码过程中直接将输出分布引导至任务分布，而不是通过对权重的更新来间接调整。
### Innovation
提出了Steering Vector Decoding（SVD）方法，这是一种轻量级的、兼容PEFT且具有理论支持的新方法。SVD借鉴了预训练模型和暖起调整模型之间的 kullback-leibler（KL）散度梯度，提取出任务感知的引导向量，并利用该向量指导解码过程，使模型输出分布更加接近任务分布。理论证明SVD在最早一次梯度更新时与完全调整等价，并且给出了最优的引导向量强度解。SVD与四种标准的PEFT方法结合，实验表明，在三个任务和九个基准上，SVD能够显著提高多项选择准确率最高可达5个百分点，并提升开放型回答的真实度2个百分点，无需额外增加可训练参数。因此，SVD提供了一条强大任务适配的大规模语言模型的轻量级、理论支撑的有效路径。
### Conclusion
论文提出了一种SVD解码方法，该方法利用了参数高效调整（PEFT）框架，在保持训练参数数量不变的情况下，实现了大规模语言模型下游任务性能的显著提升，是一种解决大规模语言模型任务适配问题的有效途径。
## 702. `cs.CL` - QWHA: 量化意识Walsh-哈达玛适应性在大型语言模型参数高效微调中的应用 [PDF](https://arxiv.org/pdf/2509.17428), [HTML](https://arxiv.org/abs/2509.17428)
### Authors
Hyesung Jeon,Seojune Lee,Beomseok Kang,Yulhwa Kim,Jae-Joon Kim
### Background
对于大型语言模型（LLMs）的高效部署需求，量化技术（减少推理成本）和参数高效微调（PEFT，降低训练开销）变得尤为重要。现有方法在量化过程中存在的误差减小不足和有限的表现能力促使研究者开发量化感知的PEFT方法。然而，现有方法的低秩适应性方法表现能力有限，而四元数变换（FT）基的适配器虽然具有更强的表现能力，但在集成到量化模型中时会增加计算开销。因此，减小程序误差以提高模型准确性是关键，尤其是如何有效集成FT基适配器并减少计算开销成为急需解决的问题。
### Innovation
本文提出了QWHA方法，通过采用Walsh-Hadamard变换（WHT）作为变换内核，结合一种新颖的可适应参数选择和值精炼的适配器初始化方案，有效缓解量化误差并促进微调。QWHA方法在量化感知和计算成本之间取得了平衡，能够在低位量化精度方面超过现有方法，并显著提高了训练速度。
### Conclusion
实验结果表明，QWHA在低位量化精度方面持续优于基线方法，并显著优于现有FT基适配器的训练速度。代码已在相关链接处公开。
## 703. `cs.CL` - RPG: 一种用于统一且可扩展代码库生成的仓库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型擅长生成单个函数或单个代码文件，但却难以从零开始生成完整的代码库。这种能力对于从高层次规范构建一致的软件系统和实现自动化代码生成的全部潜力至关重要。这一过程需要在两个层次上进行规划：决定构建哪些特性和模块（提案阶段），以及定义它们的实现细节（实现阶段）。当前的方法依靠自然语言规划，常常导致不明确的规范、结构不一致的组件和因固有的含糊性和缺乏结构而导致的脆弱设计。为了应对这些局限性，本文引入了仓库规划图（RPG），这是一种统一图表示法，编码功能、文件结构、数据流和函数等能力。通过用显式的蓝图替代自由形式的自然语言，RPG 使在更长的时间范围内进行一致的仓库生成规划成为可能。
### Innovation
本文提出了仓库规划图（RPG），这是一种结构化的表示方法，将能力、文件结构、数据流和函数等元素统一表示在图中。这使得规划能够在更长的时间框架内更加一致。基于RPG，本文开发了ZeroRepo框架，该框架包括三个阶段：提案级规划、实施级构建以及由图指导的代码生成和支持测试验证。ZeroRepo在六个真实世界的项目基准测试RepoCraft上表现卓越，生成了接近36,000行代码和445,000个代码标记，比最强基线Claude Code平均大3.9倍，比其他基线大68倍。它实现了81.5%的覆盖率和69.7%的测试准确度，分别提高了Claude Code的27.3和35.8个百分点.
### Conclusion
RPG能够复杂地依赖模型、通过接近线性缩放支持更复杂的规划，并提高代理对仓库的理解，从而加速定位。
## 704. `cs.CL` - HiCoLoRA: 通过分层协作LoRA解决上下文提示错位的零样本对话状态跟踪 [PDF](https://arxiv.org/pdf/2509.19742), [HTML](https://arxiv.org/abs/2509.19742)
### Authors
Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li
### Background
零样本对话状态跟踪（zs-DST）对于使任务导向对话系统（TODs）能够在没有高昂数据标注成本的情况下扩展到新领域至关重要。这一挑战的关键在于动态对话上下文与静态提示之间的语义不匹配，导致跨层协调的灵活性差、领域干扰以及灾难性遗忘等问题。
### Innovation
我们提出了一种分层协作低秩适应框架（HiCoLoRA），通过鲁棒提示对齐来增强零样本槽位推断。该框架包括分层LoRA架构，动态层特定处理（结合底层启发式分组和高层全交互）；Spectral联合领域槽聚类方法来识别可转移的关联关系（向自适应线性融合机制提供支持）；以及语义增强SVD初始化（SemSVD-Init）机制，来保留预训练知识。实验表明，HiCoLoRA在MultiWOZ和SGD多领域数据集上优于基线，达到零样本对话状态跟踪的最先进水平。
### Conclusion
HiCoLoRA框架在多领域数据集上的实验表明其显著优于基线，为零样本对话状态跟踪问题提供了有效解决方案，达到了最先进的性能。
## 705. `cs.CL` - 阿谀不是单一的事物：LLMs中阿谀行为的因果分离 [PDF](https://arxiv.org/pdf/2509.21305), [HTML](https://arxiv.org/abs/2509.21305)
### Authors
Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang
### Background
大型语言模型（LLMs）常常表现出阿谀行为，如过度同意或奉承用户，但尚不清楚这些行为是否源于单一机制或多种独立过程。
### Innovation
论文分解了阿谀行为为阿谀性同意和阿谀性赞美的两个部分，与其真实同意进行对比。通过使用多个模型和数据集的不同均值方向、激活添加和子空间几何，作者展示了如下发现：1. 三种行为在潜在空间中沿独立的线性方向编码；2. 每种行为可以独立放大或抑制而不对其他行为产生影响；3. 其表示结构在不同模型家族和规模中具有一致性。这些结果表明，阿谀行为对应于不同的可独立操纵的表示。
### Conclusion
阿谀行为在大型语言模型中分成独立的表示结构，意味着这些行为是可以通过独立的机制进行调整和控制的。
## 706. `cs.CL` - 语义重构熵在问答任务中稳健幻觉检测中的应用 [PDF](https://arxiv.org/pdf/2509.17445), [HTML](https://arxiv.org/abs/2509.17445)
### Authors
Chaodong Tong,Qi Zhang,Lei Jiang,Yanbing Liu,Nannan Sun,Wei Li
### Background
大型语言模型（LLMs）在可靠回复问题时面临幻觉问题，即生成流畅但事实错误的输出。现有的基于熵的语义不确定性估计方法受到采样噪声和可变长度答案不稳定聚类的限制。现有的方法在面对这一挑战时还不够完善。因此，提出了语义重构熵（SRE），通过两种方式改进不确定性估计。首先，输入端的语义重构产生忠实的同义句，扩展估计空间并减少表面解码器倾向带来的偏差。其次，渐进的能量基于混合聚类稳定语义分组。实验表明，在SQuAD和TriviaQA数据集上，SRE方法优于现有的基准方法，提供了更为稳健和通用的幻觉检测功能。
### Innovation
语义重构熵(SRE)是一种改进不确定性估计的方法。SRE通过两种创新点来提高不确定性估计的准确性：一是输入端的语义重构产生忠实的同义句，这扩展了估计空间并减少了表面解码器倾向带来的偏差；二是采用渐进的能量基于混合聚类稳定语义分组。这一方法能更有效地检测幻觉并提高了自动化系统的可靠性。
### Conclusion
研究表明将输入多样化与多信号聚类相结合可以显著提升语义不确定性估计的性能。利用SRE方法，可以在问答任务中更稳健地检测幻觉，提供更可靠和广泛应用的可能性。这一成果表明，结合多样输入和多信号聚类对于提升不确定性估计的有效性和泛化能力非常重要。
## 707. `cs.CL` - 思考增强的预训练 [PDF](https://arxiv.org/pdf/2509.20186), [HTML](https://arxiv.org/abs/2509.20186)
### Authors
Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei
### Background
随着预训练大语言模型（LLM）所需的计算资源以前所未有的速度增长，高质量数据的获取却仍然受到限制，这使得如何最大化利用现有数据成为研究中的重要挑战。现有模型难以学习某些高质量词汇的原因在于，单一词汇背后的逻辑往往是极其复杂和深入的。
### Innovation
本文提出了一种名为'Thinking Augmented Pre-Training (TPT)'的新方法，通过自动生成的思考轨迹来增强文本数据。这种方法在多个范围内的训练配置中测试（直到1000亿个令牌），涵盖了从有限数据到大量数据的预训练，以及从中断训练中恢复。实验结果显示，该方法显著提高了不同模型大小和家族的大语言模型的性能。与仅使用原始数据相比，TPT增强了LLM预训练的数据效率达3倍，对于一个3亿参数的模型，在多个复杂的推理基准测试中的性能提高了超过10%。
### Conclusion
本文通过TPT方法成功增强了大语言模型的训练数据效率，特别地，在实验中展示了该方法在不同模型规模上的显著性能提升。
## 708. `cs.CL` - WebExplorer：探索和发展以培训长时程网络代理 [PDF](https://arxiv.org/pdf/2509.06501), [HTML](https://arxiv.org/abs/2509.06501)
### Authors
Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He
### Background
大型语言模型（LLMs）的范式正逐渐转向自主应用，其中网络浏览能力对于从多种在线来源检索信息至关重要。然而，现有的开源网络代理要么在复杂任务中展示出有限的信息寻求能力，要么缺乏透明的实现方法。研究者指出，关键挑战在于用于信息寻求的具有挑战性的数据的稀缺性。为了解决这一问题，他们提出了一种WebExplorer方法，这是一种基于模型探索的系统化数据生成方法，通过模型引导探索和迭代、长至短查询演变。这种方法生成了需要多步推理和复杂网络导航的具有挑战性的查询-答案对。利用他们精心策划的高质量数据集，他们成功开发出通过监督微调再结合强化学习的WebExplorer-8B先进网络代理。该模型支持128K上下文长度和最多100次工具调用回合，从而能解决长期问题。在多种信息寻求基准测试中，WebExplorer-8B取得了可与其规模相媲美的性能。具体来说，作为8B大小的模型，WebExplorer-8B能够在RL训练后有效搜索平均16个回合，其准确度优于WebSailor-72B在BrowseComp-en/zh的表现，并在WebWalkerQA和FRAMES等100B参数以下的模型中获得最佳性能。除了这些信息寻求任务外，该模型还在HLE基准上表现出强大的泛化能力，尽管它仅在知识密集型问答数据上进行训练。这些结果表明，这一方法是实现长期网络代理的实际途径。
### Innovation
该方法提出了一种基于模型探索的系统化数据生成方式，通过长期到短期查询的迭代进化，创建出需要复杂推理和网络导航的具有挑战性的查询-答案对。这种方法通过监督微调结合强化学习，成功地开发出了WebExplorer-8B模型，该模型支持128K上下文长度和最多100次工具调用回合，使其能够解决复杂的长期问题。特别地，WebExplorer-8B达到了其规模范围内信息寻求任务的最佳性能，在某些基准测试中，其表现优于72B参数的WebSailor模型，并在100B参数以下的模型中获得最佳性能。此外，该模型在HLE基准上的泛化能力表明其在未见数据上的表现也同样出色。
### Conclusion
该研究通过系统化地生成具有挑战性的查询-答案对，利用高质量数据集，成功地开发出WebExplorer-8B模型。该模型支持长上下文长度和多回合交互，实现了复杂任务中的长期问题解决。WebExplorer-8B在信息寻求任务中表现优异，尤其是在HLE等基准测试中展现出了强大的泛化能力。这表明，基于模型探索的方法可以有效地培训长期网络代理。
## 709. `cs.CL` - 在阿尔茨海默病检测中的类内变异问题 [PDF](https://arxiv.org/pdf/2409.16322), [HTML](https://arxiv.org/abs/2409.16322)
### Authors
Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng
### Background
阿尔茨海默病（AD）检测使用机器学习分类模型来区分 AD 患者和非患者。不同于传统的分类任务，我们在 AD 检测中识别出一个关键挑战：AD 患者的认知损伤呈现出不同的程度。因此，简单的二元 AD 分类可能忽视了类内异质性和样本层次不平衡的两个重要方面。
### Innovation
我们发现使用样本得分估计器可以生成与认知评分相符的样本特定软得分。随后，我们提出了两种简单而有效的方法：软目标蒸馏（SoTD）和样本层次重衡（InRe），分别针对两个问题。基于 ADReSS 和 CU-MARVEL 数据集，我们展示了并分析了所提出方法在检测性能上的优势。
### Conclusion
这些发现为开发稳健可靠的 AD 检测模型提供了见解。
## 710. `cs.CL` - 对基于令牌奖励引导的文本生成方法的批判性审视 [PDF](https://arxiv.org/pdf/2406.07780), [HTML](https://arxiv.org/abs/2406.07780)
### Authors
Ahmad Rashid,Ruotian Wu,Julia Grosse,Agustinus Kristiadi,Pascal Poupart
### Background
大规模语言模型可以通过人类反馈强化学习（RLHF）进行微调以提升性能，但微调成本高昂。预测时基于令牌的奖励引导文本生成（RGTG）方法通过使用训练于完整序列的奖励模型来评分解码中的部分序列，试图引导生成高奖励的序列，但目前这些方法仅通过直觉来驱动，缺乏系统分析。
### Innovation
提出了一种在部分序列上显式训练布拉德利-泰利（Bradley-Terry）奖励模型的方法，并在解码时自动回归地从隐含的基于令牌的策略中采样。研究表明，此策略与两个不同RLHF策略的比例成正比。该简单方法在与前RGTG方法的对比中表现更佳，并且在未进行大规模LLM微调的情况下与强大的离线基线表现出相似性能。
### Conclusion
此工作揭示了奖励模型训练于完整序列并不适用于评分部分序列，提出了一种新的方法以克服此问题，并展示了其优于以往方法的效果。
## 711. `cs.CL` - 通过学习提问来学习总结：对抗性智能体协作在长文档摘要中的应用 [PDF](https://arxiv.org/pdf/2509.20900), [HTML](https://arxiv.org/abs/2509.20900)
### Authors
Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch
### Background
当前的大语言模型在长文档总结方面面临着显著挑战，现有方法容易导致信息丢失、事实不一致和连贯性问题。这主要是因为大语言模型在处理超长文档时难以保持信息的完整性和连贯性。因此，亟需新的方法来改善这一现状。
### Innovation
本文提出了一种名为SummQ的新颖对抗性多智能体框架，通过专家智能体在总结和测验两个互补领域的协作来解决上述问题。该框架利用生成总结的智能体和审查总结的智能体进行协作以创建和评估全面的总结，并利用生成测验题的智能体和审查测验的智能体创建理解性问题作为总结过程的质量检查。此外，通过评估生成的总结是否包含了回答测验问题所需的信息来验证的智能体实现了一种对抗性的动态机制。这种多反馈机制使总结过程能够通过多层次的反馈得到迭代完善。
### Conclusion
我们通过在三个广泛使用的长文档摘要基准测试上评估SummQ，实验结果表明该框架在ROUGE和BERTScore指标上以及LLM作为裁判和人类评估方面都显著优于现有最先进的方法。通过全面分析，我们揭示了多智能体协作动态的有效性、不同智能体配置的影响，以及测验机制的作用。这项工作建立了一种新的长文档摘要方法，使用对抗性智能体协作来提高总结质量。
## 712. `cs.CL` - 跨语言句法记忆负担分析：线性距离与结构密度 [PDF](https://arxiv.org/pdf/2509.20916), [HTML](https://arxiv.org/abs/2509.20916)
### Authors
Krishna Aggarwal
### Background
研究表明，在理解句子时，记忆负担可能由相邻单词的线性距离或其他因素中的结构密度解释。心理语言学研究显示了特征干扰和误结合对记忆负担的影响，但证据尚不充分说明它们的认知贡献是否可以相加。为了更精确地解释句子层面的记忆负担，本文采用统一依存树库，并结合多种语言的混合效应框架，共同评估句子长度、依存长度和介入者复杂性（即头部与其依存词之间的介入头部数量）作为记忆负担指标的预测变量。
### Innovation
本文通过跨语言的依存树库和混合效应框架，引入了‘介入者复杂性’作为评估句子理解期间记忆负担的新指标，它以结构为基础，比线性距离更精细地解释了语言处理的效率。此研究通过UD（通用依存）图测评方法和跨语言的混合效应建模，揭示了线性距离与结构密度对处理效率贡献的不同，为评估记忆负担的理论提供了原则性路径。
### Conclusion
本文的研究结果统一了线性和层级视角对局部性的理解，认为依存长度是重要的表面特征，而介入头部更直接地反映了整合和保持的需求。该研究方法提供了区分和评估竞争性句子理解中记忆负担理论的原则路径。
## 713. `cs.CL` - 开发和验证用于生成完整结构化放射学报告的大规模语言模型 [PDF](https://arxiv.org/pdf/2409.18319), [HTML](https://arxiv.org/abs/2409.18319)
### Authors
Chuang Niu,Md Sayed Tanveer,Md Zabirul Islam,Parisa Kaviani,Qing Lyu,Mannudeep K. Kalra,Christopher T. Whitlow,Ge Wang
### Background
当前的LLM在生成完整结构化报告时面临格式错误、内容幻觉和上传数据到外部时的隐私泄露等问题。
### Innovation
本文开发了一个开源、准确的LLM，用于从不同机构的自由文本报告中创建结构化和标准化的LCS报告，并展示了其在自动统计分析和肺结节检索中的实用性。该模型通过一个动态模板约束解码方法增强现有的LLM，提高了格式正确性和内容准确度，且提高了10.42%的表现，优于GPT-4o 17.19%。
### Conclusion
该开发的LLM在跨机构数据集上表现出色，F1得分为97%，没有发现格式错误和内容幻觉。该方法显著提高了开源LLM的性能，并在自动化统计分析和结节检索原型中表现出色。自动提取的统计分布与衰减、位置、大小、稳定性以及Lung-RADS先前的研究结果一致。结构化报告的检索系统允许灵活的结节级搜索和复杂统计分析。该开发的软件可公开部署并继续供研究使用。
## 714. `cs.CL` - Rare-to-Frequent: 使用大型语言模型指导解锁扩散模型在稀有概念上的组合生成能力 [PDF](https://arxiv.org/pdf/2410.22376), [HTML](https://arxiv.org/abs/2410.22376)
### Authors
Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho
### Background
当前最先进的文本到图像(T2I)扩散模型在生成具有罕见组合或不寻常属性的对象时常常表现不佳。文章通过实证和理论分析表明，在扩散采样过程中暴露与目标稀有概念相关的常见概念，可以提高生成准确性。
### Innovation
文章提出了一个无需训练的R2F方法，通过利用大型语言模型中丰富的语义知识，在扩散推理过程中规划和执行稀有到常见的概念指导，增强扩散模型在稀有概念上的组合生成能力。该框架适用于任何预训练的扩散模型和大型语言模型，并能与区域导向的扩散方法无缝集成。
### Conclusion
实验结果表明，R2F在三个数据集中的表现显著优于现有的模型，包括SD3.0和FLUX，特别是在文本到图像对齐方面，性能提高了高达28.1%。
## 715. `cs.CL` - GEP：一种基于贪婪坐标梯度方法从基于小型语言模型的聊天机器人中提取个人可识别信息的方法 [PDF](https://arxiv.org/pdf/2509.21192), [HTML](https://arxiv.org/abs/2509.21192)
### Authors
Jieli Zhu,Vi Ngoc-Nha Tran
### Background
小型语言模型（SLMs）因其在特定领域与大型语言模型（LLMs）相比具有相匹配的性能，并且在训练和推理时消耗更少的能量和时间而变得前所未有的吸引人。然而，SLMs中下游任务中的个人可识别信息（PII）泄露问题尚未被充分研究。本研究旨在探讨基于SLMs的聊天机器人中的PII泄露问题.
### Innovation
作者提出了一种名为GEP的方法，这是一种基于贪婪坐标梯度（GCG）的特定设计以从SLMs中提取PII的方法。GEP能够在复杂且现实的情景下，通过自由风格插入的形式（即各种语法表达）揭示高达4.53%的PII泄漏率，并且在PII提取方面比基于模板的方法提高了高达60倍的效果.
### Conclusion
作者得以证明的是，传统的基于模板的PII攻击方法在SLM条件下无法有效地提取数据集中的PII以进行泄露检测。而GEP则能够有效检测这些泄漏，并显著提高PII提取的效率与效果，表明在使用小型语言模型的聊天机器人中也存在PII泄漏问题。
## 716. `cs.CL` - 语言模型中的错误教训：语言模型中语法领域相关性的虚假关联 [PDF](https://arxiv.org/pdf/2509.21155), [HTML](https://arxiv.org/abs/2509.21155)
### Authors
Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi
### Background
文本生成语言模型（LLM）在接收到指令后需要理解给定任务-指令对的语义和领域。近期研究指出，语法模板（常见词性标注序列）在训练数据中极为普遍，并且常常出现在模型输出中，尽管可以通过语义理解任务来正确回应指令。不过，模型在训练过程中可能会学习到语法和领域的虚假关联，这种情况可能会覆盖提示语义，产生负面影响，特别是在实体知识任务中。本文通过合成训练数据集分析了语法与领域间的这种虚假关联，并验证了这一现象存在于OLMo-2、FlanV2和GPT-4o等不同模型中，同时讨论了对安全微调的影响。
### Innovation
研究引入了一个评估框架来检测训练模型中的语法领域虚假关联现象，并通过数据集和模型分析，展示了这一问题的存在。此外，研究还通过案例分析说明了这种虚假关联可以利用来绕过安全拒绝机制，提出了解决方案的两个要点：（1）需专门测试语法领域关联性，（2）确保训练数据中的语法多样性，特别是在各个领域内，以防止此类虚假关联的产生。
### Conclusion
研究揭示了两个关键需求：一是需要显式地测试语法与领域间的关联性，二是确保训练数据中的语法多样性，特别是针对每个领域内的多样性，以防止产生此类虚假关联，提高语言模型的安全性和准确性。
## 717. `cs.CL` - GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder [PDF](https://arxiv.org/pdf/2502.11360), [HTML](https://arxiv.org/abs/2502.11360)
### Authors
Seunghyuk Cho,Zhenyue Qin,Yang Liu,Youngbin Choi,Seungbeom Lee,Dongwoo Kim
### Background
尽管视觉语言模型（VLM）已被用于解决几何问题，但它们在识别几何特征方面的能力仍然没有得到充分分析。因此，需要一个新的基准来评估视觉几何特征的识别能力，包括点、线等基本元素以及正交性等关系。
### Innovation
提出了一种GeoDANO模型，这是一种具有领域无关视觉编码器的几何视觉-语言模型，用于解决平面几何问题。模型采用了基于CLIP的GeoCLIP，并通过合成几何图--说明对进行训练，从而在识别几何特征方面表现出色。此外，该模型还通过领域适应策略增强了对于未见图示风格的处理能力。
### Conclusion
GeoDANO在解决平面几何问题和MathVerse上的表现优于专门方法和GPT-4o。该模型的实现已在相关链接上提供。
## 718. `cs.CL` - 统一符号音乐编排：跟踪意识重建与结构化标记化 [PDF](https://arxiv.org/pdf/2408.15176), [HTML](https://arxiv.org/abs/2408.15176)
### Authors
Longshen Ou,Jingwei Zhao,Ziyu Wang,Gus Xia,Qihao Liang,Torin Hopkins Ye Wang
### Background
本文介绍了一个统一框架，旨在自动处理多轨音乐编排问题。该框架利用预训练的符号音乐模型来处理不同的编排场景，包括重新诠释、简化和附加生成。核心是一个基于标记层面的分段重建目标，该目标能够灵活地在推断时进行任意到任意的乐器转换。为了支持多轨建模，文中引入了REMI-z结构化标记化方案，这种方案增强了模型效率和有效性，适用于编排任务和无条件生成。这一方法在不同的编排任务和评估标准下，如乐队编排、钢琴乐谱简化和鼓编排，表现出比特定任务模型更高的优越性。整体上，该框架展示了良好的通用性，并暗示了在符号音乐到音乐转换中的更广泛的应用前景。
### Innovation
提出了REMI-z结构化标记化方案，增强了模型效率和有效性；核心是基于标记层面的分段重建目标，支持灵活的任何到任意的乐器转换；在不同的编排任务中表现出更好的优越性，比特定任务模型更优。
### Conclusion
该框架展示了良好的通用性和广泛的应用前景，并在多个方面提升符号音乐到音乐的转换效果。
## 719. `cs.CL` - 在揭示有害语义过程中检测和解释文本到图像模型中的NSFW提示 [PDF](https://arxiv.org/pdf/2412.18123), [HTML](https://arxiv.org/abs/2412.18123)
### Authors
Yiming Wang,Jiahao Chen,Qingming Li,Tong Zhang,Rui Zeng,Xing Yang,Shouling Ji
### Background
随着文本到图像（T2I）模型的进步和广泛应用，其相关的安全问题日益重要。恶意用户利用这些模型生成不适宜的工作者（NSFW）图像，这凸显了需要有效的保护措施来确保模型输出的完整性和合规性。然而，现有的检测方法常常表现出较低的准确性和效率。
### Innovation
本文提出了一种名为HiddenGuard的可解释性防御框架，该框架利用T2I模型的隐藏状态来检测NSFW提示。HiddenGuard从模型的文本编码器的隐藏状态中提取NSFW特征，并利用这些特征在模型输出背后的分离性来检测NSFW提示。检测过程高效，所需推理时间极短。HiddenGuard还实现实时结果解释，并支持通过数据增强技术进行优化。
### Conclusion
本文的广泛实验表明，HiddenGuard显著优于商业和开源的审核工具，在所有数据集上实现了超过95%的准确率，并极大地提高了计算效率。
## 720. `cs.CL` - 通过隐含奖励进行过程强化学习 [PDF](https://arxiv.org/pdf/2502.01456), [HTML](https://arxiv.org/abs/2502.01456)
### Authors
Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding
### Background
密集的过程奖励已被证明是大型语言模型（LLMs）在推理时扩展的有效替代方案，特别是在需要复杂多步骤推理的任务中。虽然这些密集的奖励也提供了在强化学习（RL）中使用LLMs的吸引力选择，因为它们的精细奖励有潜力解决结局奖励的一些内在问题，如训练效率和信用分配，这一潜力仍未能充分利用。主要原因在于过程奖励模型（PRMs）在线训练的挑战，其中收集高质量的过程标签极其昂贵，从而使其特别容易受到奖励作弊的影响。
### Innovation
本文提出了一种名为PRIME的方法，通过仅使用策略摆渡和结局标签，利用隐含过程奖励实现在线PRM更新。PRIME结合了多种优势函数，省去了现有方法所需的专用奖励模型训练阶段，显著减少了开发工作量。其在数学和编程领域的表现表明，从Qwen2.5-Math-7B-Base开始，PRIME在多个关键推理基准上实现了15.1%的平均改进。我们的最终模型Eurus-2-7B-PRIME仅使用其10%的训练数据，在七项推理基准上超过了Qwen2.5-Math-7B-Instruct。
### Conclusion
PRIME通过隐含奖励实现了过程强化学习的在线更新，大幅减少了开发成本，且在数学和编程任务中表现出色，显著提升了模型在推理任务的能力。
## 721. `cs.CL` - 大型语言模型与经典机器学习模型在高维度表格式数据下预测COVID-19病死率性能对比 [PDF](https://arxiv.org/pdf/2409.02136), [HTML](https://arxiv.org/abs/2409.02136)
### Authors
Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini
### Background
该研究对比了基于特征的经典机器学习模型（CMLs）和大规模语言模型（LLMs）在预测9,134名患者（来自4个医院）的COVID-19病死率时的表现。具体而言，研究使用了高维度表格数据，目的是评估不同模型在处理和预测此类任务中的效能差异。
### Innovation
研究创新点在于利用了大型语言模型在零样本分类中的应用，并通过方法如QLoRA对Mistral-7b进行了微调。研究发现，尽管LLMs在零样本分类中表现中等，但通过微调显著提升了其效果，可能缩小了与CMLs的性能差距。此外，研究特别强调了CMLs在处理高维度表格式数据任务中的优势。
### Conclusion
研究结果表明，虽然LLMs在零样本分类中有中等表现，但通过微调可显著提高其性能，可能与CMLs差距缩小。然而，CMLs在处理高维度表格式数据任务方面仍然表现出领先优势。总体而言，该研究表明CMLs和微调后的LLMs在医疗预测建模中具有潜在价值，但CMLs在结构化数据分析方面依然占优。
## 722. `cs.CL` - DOTA: 分布式视觉语言模型的测试时自适应 [PDF](https://arxiv.org/pdf/2409.19375), [HTML](https://arxiv.org/abs/2409.19375)
### Authors
Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang
### Background
视觉语言基础模型（VLMs）如CLIP，在广泛的任务上表现出色，但当训练数据与测试数据之间的分布存在显著差距时，这种模型的部署可能会变得不可靠。通过微调VLMs进行多样化场景的适应往往代价高昂。基于缓存的时间测试适配器提供了一种高效的方法，通过存储代表性测试样本来引导后续分类。然而，这些方法通常采用简单的缓存管理方式，容量有限，当样本在更新过程中不可避免地被删除时，会导致严重的灾难性遗忘。
### Innovation
本文提出了DOTA（分布式测试时自适应）方法，这是一种简单但有效的解决上述问题的方法。DOTA的核心在于，它不是简单地记忆个别的测试样本，而是连续估计测试数据流的底层分布。通过贝叶斯定理利用这些动态估计的分布，计算测试时后概率来实现自适应。这种分布中心的方法使得模型能够持续学习并适应部署环境。
### Conclusion
大量的实验验证了DOTA能够显著减轻遗忘，并且在与现有方法的比较中，实现了最先进的性能。
## 723. `cs.CL` - 拦截癌症：大规模医疗卫生基础模型的癌症预筛查 [PDF](https://arxiv.org/pdf/2506.00209), [HTML](https://arxiv.org/abs/2506.00209)
### Authors
Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong
### Background
现有的癌症筛查技术需要昂贵且侵入性的医疗程序，这些程序并非全球都能获取，因此导致了许多本可以被拯救的生命浪费。这使得癌症早期检测面临诸多挑战。
### Innovation
提出了CATCH-FM（利用医疗卫生基础模型捕捉早期癌症）的癌症预筛查方法，该方法仅基于患者的历史医疗记录识别高风险患者，进行进一步筛查。该研究首次在电子健康记录（EHR）上大规模预训练了医疗代码序列的基础模型，并对临床医生汇集的癌症风险预测群体进行了微调，显示了CATCH-FM在预测癌症风险方面的强大效果，优于基于特征的树模型和通用及医疗领域的LLM，在特定情况下性能提升达20%。
### Conclusion
CATCH-FM 在不同人口统计学、医疗保健系统和EHR编码差异中表现出一致的预测能力，在EHRSHOT少样本排行榜中达到了迄今为止最先进的胰腺癌风险预测性能，优于使用现场患者数据预训练的EHR基础模型。分析表明，CATCH-FM在各种患者分布中具有稳健性，在ICD代码空间中运作具有优势，能够捕捉到非明显的癌症风险因素。此外，CATCH-FM的代码将开源。
## 724. `cs.CL` - TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning [PDF](https://arxiv.org/pdf/2505.11737), [HTML](https://arxiv.org/abs/2505.11737)
### Authors
Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang
### Background
尽管大型语言模型（LLMs）展示了令人印象深刻的性能，但在不同应用场景中，其输出质量仍然不稳定，尤其是在需要多步推理的复杂任务中难以识别可靠的回答。这使得识别和管理这些模型在复杂任务中的表现成为一个挑战。
### Innovation
本文提出了一种名为TokUR的令牌级别不确定性评估框架，用于提高LLM在数学推理中的可靠性和推理性能。提出了一种低秩随机权重扰动方法，在LLM解码过程中生成令牌级不确定性预测分布，从而捕获生成回答的语义不确定性。
### Conclusion
实验结果表明，TokUR在回答正确性和模型稳健性方面表现出强大的相关性，并且由TokUR生成的不确定性信号可以提高模型在测试时的推理性能。这些结果强调了TokUR作为一种原则性的可扩展方法，对于提高挑战性推理任务中LLM的可靠性和可解释性的重要性。
## 725. `cs.CL` - Think With Videos For Agentic Long-Video Understanding [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）在计算机视觉中是一个极具挑战性的问题。现有方法要么通过降采样帧进行单次推理，牺牲了细节优势，要么依赖于任务无关的表示的文本推理，限制了任务特定的感知和探索。
### Innovation
本文提出了一种名为VideoExplorer的框架，该框架遵循‘思考视频’的原则，并自然地将规划、时间对接和可伸缩感知整合到一致的推理过程中。VideoExplorer采用迭代的方式提出子问题，定位相关时刻，进行任务导向的、时间可伸缩的视频理解，直至获得最终答案，实现了忠实、高效、可解释的推理。为了应对缺乏LVU训练资源的问题，论文使用难度自适应采样构建了一个长视频推理数据集，以确保复杂任务上的高质量轨迹。基于该数据集，设计了一种两阶段训练管道：监督轨迹初始化，随后是轨迹级偏好优化，鼓励根据下游奖励调整的时间对接和迭代信息集成。
### Conclusion
在流行的长视频理解和推理基准上的广泛评估表明，VideoExplorer在现有基线中具有显著优势，凸显了其稳健性、适应性和效率。代码已在该仓库中公开发布（this https URL）。
## 726. `cs.CL` - 大语言模型低秩适配器的无训练贝叶斯化 [PDF](https://arxiv.org/pdf/2412.05723), [HTML](https://arxiv.org/abs/2412.05723)
### Authors
Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang
### Background
评估大语言模型（LLMs）响应的不确定性仍然是一个关键挑战。最近的贝叶斯方法虽然有效，但通常需要复杂的调优或后训练过程。这些方法在量化不确定性方面得到了验证，但存在复杂调整的问题，这在实践中往往是不可取的。因此，迫切需要一种不需要额外训练的简单而理论基础稳固的方法来实现贝叶斯化，以提高不确定性估计和泛化能力，满足大语言模型的低秩适配器需求。
### Innovation
提出了无训练贝叶斯化（TFB），这是一种简单且理论上合理的框架，能够高效地将训练过的低秩适配器转换为贝叶斯模型，而无需额外的训练步骤。TFB通过在低秩等方差高斯分布家族内系统地搜索可接受的权重后验方差的最大值来实现这一目标。这种搜索过程在温和条件下等同于KL-正则化的变分优化，这是一种一般的变分推断形式。实验结果显示，TFB在不确定性估计和泛化方面优于现有方法，并且消除了复杂的贝叶斯化训练程序的需求。
### Conclusion
TFB作为一个全新的框架，证明了在大语言模型的低秩适配器中进行无训练贝叶斯化的可行性。通过利用KL-正则化的变分优化，TFB不仅提高了不确定性估计，还增强了模型的泛化能力，同时简化了模型的训练流程。实验结果表明，TFB在这方面具有优越性，为下一步改进LLMs的性能提供了新的可能。代码将在指定的URL处提供。
## 727. `cs.CL` - Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders [PDF](https://arxiv.org/pdf/2505.11756), [HTML](https://arxiv.org/abs/2505.11756)
### Authors
David Chanin,Tomáš Dulka,Adrià Garriga-Alonso
### Background
论文背景在于假设稀疏自编码器（SAEs）能够将多语义激活分解为可解释的线性方向，前提是激活是由潜在特征的稀疏线性组合构成的。然而，研究发现，如果SAE比其训练所用的“真特征”数量更窄，并且特征之间存在相关性，那么SAE会将相关特征的成分合并在一起，从而破坏单一语义性。在大语言模型（LLM）使用的SAEs中，这两个条件几乎总是成立。
### Innovation
论文的创新点在于定义并研究了一种称为特征对冲（Feature Hedging）的现象，这种现象是由SAE重构损失引起的，并且更窄的SAE会更加严重。作者通过理论模型和LLM上训练的SAE进行实验研究，目的是理解这一现象背后的机制，并据此提出改进后的嵌套自编码器（Matryoshka SAEs）。
### Conclusion
结论指出，特征对冲可能是SAE一致低于或失配监督基准的主要原因之一。同时，研究结果表明SAE的宽度并非中立的超参数：更窄的SAE会受到更为严重的对冲影响。
## 728. `cs.CL` - 大型语言模型中的表示工程：分类、机遇与挑战 [PDF](https://arxiv.org/pdf/2502.19649), [HTML](https://arxiv.org/abs/2502.19649)
### Authors
Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz
### Background
递归表示工程（RepE）是一种新型范式，旨在控制大型语言模型（LLMs）的行为。与传统的通过修改输入或进行微调的方法不同，RepE直接操控模型的内部表示。这可能会提供更有效、易于理解、数据高效和灵活的控制手段。本文综述了RepE在LLMs中的首次全面调查，旨在回答关键问题：有哪些RepE方法存在，它们之间有何不同？RepE应用于哪些概念和问题？与其他方法相比，RepE的优缺点是什么？
### Innovation
本文提出了一种统一框架，将RepE描述为包含表示识别、操作和控制的管道。这使得RepE可以在更广泛的背景下进行研究，并为理解和改进RepE方法提供了新的视角。此外，本文还指出了提升RepE的机会，并为最佳实践提供了一项指南，这为RepE方法的发展指明了方向，也为进一步的研究奠定了基础。
### Conclusion
尽管RepE方法具有巨大潜力，但仍面临管理多个概念、确保可靠性以及保持模型性能等挑战。未来可以通过实验和方法论改进来提升RepE，同时制定最佳实践指南，以促进RepE方法的进步。
## 729. `cs.CL` - 基于领域信息的张量网络结构搜索 [PDF](https://arxiv.org/pdf/2505.23537), [HTML](https://arxiv.org/abs/2505.23537)
### Authors
Giorgos Iacovides,Wuyang Zhou,Chao Li,Qibin Zhao,Danilo Mandic
### Background
张量网络（TNs）能够有效表示高维数据，但确定最优张量网络结构（TN-SS）依然是一个挑战。当前最先进的算法将其视为纯粹的数值优化问题，需要大量的函数评估，这在实际应用中是不可行的。现有方法忽视了现实世界张量数据中存在的有价值领域信息，缺乏对识别出的张量网络结构的透明度。
### Innovation
提出了一种新型的张量网络结构搜索框架tnLLM，将领域信息融入框架中，并利用大规模语言模型（LLMs）的推理能力直接预测合适的张量网络结构。框架中包含一个领域意识驱动的提示流水线，指导LLMs基于张量模式之间的实际关系推断合适的张量网络结构。这种方式不仅能够迭代优化目标函数，还能生成领域意识的解释。实验结果表明，tnLLM在更少的函数评估情况下，实现了与当前最先进算法相当的张量网络结构搜索目标函数值。此外，证明了LLM启用的领域信息可以被用于优化基于采样的最先进算法的初始状态，从而加速其收敛并保持理论性能保证。
### Conclusion
tnLLM通过结合领域信息和大规模语言模型的推理功能，提供了一种高效且透明地识别张量网络结构的新方法，相较于当前最先进的算法，tnLLM在性能和透明度上均有所提升。
## 730. `cs.CL` - Polar Express: 最优矩阵符号方法及其在Muon算法中的应用 [PDF](https://arxiv.org/pdf/2505.16932), [HTML](https://arxiv.org/abs/2505.16932)
### Authors
Noah Amsel,David Persson,Christopher Musco,Robert M. Gower
### Background
矩阵极分解及其相关的矩阵符号函数计算已经被数值分析领域研究了几十年，但在最近被Muon算法用于训练深度神经网络时重新引起了关注。然而，Muon算法的需求与传统应用截然不同：深学习更需要GPU友好的算法，注重高吞吐量而不看重较高精度。
### Innovation
本文提出了Polar Express，一种新的矩阵极分解方法。这种方法仅使用矩阵乘法，使得在GPU上非常高效。它借鉴了Chen & Chow和Nakatsukasa & Freund等人的前期工作，通过在每次迭代中解决一个最小化最大优化问题来适应更新规则。证明了这种方法在最坏情况下的误差最小化策略，使得Polar Express能够在早期迭代和渐进上都尽可能快地收敛。同时，还解决了有限精度问题，使得Polar Express能够在bfloat16中实用。当集成到Muon训练框架中，该方法在使用FineWeb数据集的1亿令牌训练GPT-2模型时，能够在不同学习率范围内比最近的替代方案获得一致的验证损失改进。
### Conclusion
Polar Express方法在处理矩阵极分解时实现了快速且高精度的收敛，并通过升级改造Musn算法中的相关模块，提高模型训练的性能。
## 731. `cs.CL` - ChartGalaxy: 用于信息图表理解与生成的数据集 [PDF](https://arxiv.org/pdf/2505.18668), [HTML](https://arxiv.org/abs/2505.18668)
### Authors
Zhen Li,Duan Li,Yukai Guo,Xinyuan Guo,Bowen Li,Lanxi Xiao,Shenyu Qiao,Jiashu Chen,Zijian Wu,Hui Zhang,Xinhuan Shu,Shixia Liu
### Background
信息图表是一种结合视觉元素（例如图表、图像）和文本信息来传达抽象数据的强大媒介。然而，信息图表的视觉和结构多样性对于通常基于普通图表训练的大规模视觉-语言模型（LVLMs）构成了挑战。为了弥合这一差距，研究引入了一个名为ChartGalaxy的大规模数据集，旨在推进对信息图表的理解和生成。该数据集通过归纳过程构建而成，识别出75种图表类型、440种图表变体和68种布局模板，并通过程序化方法创建合成图表。该数据集用于展示信息图表理解、代码生成基准测试和基于实例的信息图表生成的方法论和应用价值。
### Innovation
ChartGalaxy 是一个包含百万级图表的数据集，它通过识别和构建信息图表的类型、变体和布局模板，为大型视觉-语言模型提供了一个新的学习资源。该数据集的独特之处在于其引人的数据多样性和系统化的生成方法，能够有效提升多模态推理和生成能力。
### Conclusion
ChartGalaxy 提供了一种有用的资源，以增强大规模视觉-语言模型在信息图表理解与生成方面的性能。通过改进信息图表理解的微调、代码生成基准测试以及基于实例的生成方法，该数据集展示了其在促进LVLMs多模态推理和生成方面的潜力。
## 732. `cs.CL` - LLMs 中的递归训练循环：训练数据属性如何调节生成数据中的分布偏移？ [PDF](https://arxiv.org/pdf/2504.03814), [HTML](https://arxiv.org/abs/2504.03814)
### Authors
Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer
### Background
大型语言模型（LLMs）在在线内容创作中的应用日益增多，这导致了递归训练过程中的反馈循环。模型在这些合成数据上训练会导致分布偏移，即模型错误地表示人类数据的真实分布（称为模型崩溃）。然而，人类数据的属性如何影响这种偏移还知之甚少。本研究首次对这些属性对递归训练结果的影响进行了实证分析。研究结果确认使用不同的数据集会导致不同程度的分布偏移。通过全面改变数据集的属性并结合回归分析，研究发现了一些预测分布偏移程度的属性。词汇多样性会放大这些偏移，而语义多样性和数据质量则会缓解它们。实验还表明，数据的这些影响是高度模块化的：从给定互联网域抓取的数据对另一个域的内容生成影响很小。最后，政治偏见实验揭示了人类数据属性如何影响初始偏见的放大或减弱。总体而言，研究结果提供了一种新颖的观点，即互联网的不同部分可能会经历不同类型的分布偏移。
### Innovation
本研究首次通过实证分析探讨了人类数据属性对递归训练结果的影响。研究揭示了一些预测分布偏移程度的重要属性，发现词汇多样性会放大偏移，而语义多样性和数据质量则会缓解这些偏移。此外，研究指出数据的这些影响是高度模块化的，并揭示了人类数据属性如何影响生成内容的初始偏见的放大或减弱。这些发现为理解LMLs训练数据的复杂动态提供了新的见解。
### Conclusion
本研究展示了不同部分互联网可能经历不同类型的分布偏移的新型视角。通过全面操纵数据集属性并结合回归分析，发现词汇多样性会放大分布偏移，而语义多样性和数据质量则会缓解这种偏移。此外，研究强调，从给定互联网域抓取的数据对另一个域的内容生成影响很小，且人类数据属性影响初始偏见的放大或减弱。研究结果对于理解LMLs训练数据的复杂动态具有重要意义。
## 733. `cs.CL` - 基于变换器的语言模型中隐含概念的分离 [PDF](https://arxiv.org/pdf/2506.16975), [HTML](https://arxiv.org/abs/2506.16975)
### Authors
Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy
### Background
在使用大语言模型（LLMs）通过上下文学习（ICL）解决新任务时，它们需要从示例中推断出潜在概念。这引发了关于变换器如何在计算过程中表示潜在结构的问题。作者通过几种受控任务的研究，采用机制解释的方法来探讨这一问题。
### Innovation
研究展示了变换器模型如何在具有潜在离散概念的任务中成功识别潜在概念并进行概念组合。对于参数由潜在数值概念决定的任务，研究发现了模型表示空间中的低维子空间，其中的几何结构清晰地反映了潜在参数化。研究证明，小规模和大规模模型实际上能够分离并利用从简短示例中学到的潜在概念。
### Conclusion
通过实验研究，研究证明，变换器模型能够处理出潜在的离散和数值概念，即使是从少量简短的演示示例中学习到的。这也为理解变换器的计算过程提供了新的见解。
## 734. `cs.CL` - $A^2R^2$: 通过关注指导细化的视觉推理促进 Img2LaTeX 转换 [PDF](https://arxiv.org/pdf/2507.20890), [HTML](https://arxiv.org/abs/2507.20890)
### Authors
Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai
### Background
Img2LaTeX是将数学表达式和结构化视觉内容从图片转换成LaTeX代码的一个重要任务。近年来，视觉-语言模型（VLMs）在一系列视觉理解任务中取得了显著进展，主要得益于其强大的泛化能力。尽管早期尝试将VLMs应用于Img2LaTeX任务，但它们的性能仍然不佳。实验证据表明，VLMs在处理细粒度的视觉元素，如数学表达式中的上下标时存在挑战，导致LaTeX生成不准确。
### Innovation
本文提出了 $A^2R^2$ (Advancing Img2LaTeX Conversion via Visual Reasoning with Attention-Guided Refinement)框架，有效地将注意力定位和迭代细化结合在视觉推理框架中，使VLMs能够进行自我修正，逐步提高LaTeX生成的质量。此外，还提出了一个新的数据集Img2LaTeX-Hard-1K，包含1100个精心挑选和具有挑战性的示例，用于严格评估VLMs在该任务上的能力。
### Conclusion
大量的实验结果表明：（1）$A^2R^2$在多种评估指标上显著提高了模型性能，涵盖文本和视觉层面；（2）增加推理轮数可以显著提高性能，证明了$A^2R^2$在测试时扩展场景中的潜力；（3）消融研究和进一步评估证实了我们方法的有效性及其关键组件在推理过程中的协同作用。
## 735. `cs.CL` - 迭代AI代码生成中的安全性退化——系统分析中的悖论 [PDF](https://arxiv.org/pdf/2506.11022), [HTML](https://arxiv.org/abs/2506.11022)
### Authors
Shivani Shukla,Himanshu Joshi,Romilla Syed
### Background
大型语言模型（LLMs）在代码生成中的迅速采用已改变了软件开发方式，但很少有人注意到，在迭代LLM反馈中，安全漏洞如何演变。本文通过使用四种不同的提示策略，在400个代码样本和40轮“改进”中进行受控实验，来分析AI生成代码中的安全性退化问题。实验结果显示，在仅仅五次迭代后，关键漏洞增加了37.6%，不同的提示方法呈现出不同的漏洞模式。这反驳了迭代LLM提炼会改善代码安全性的假设，强调了闭环中人类专业知识的重要性。
### Innovation
通过受控实验（使用400个代码样本和四种提示策略，进行40轮改进）分析AI生成代码安全性退化，识别不同提示方法的漏洞模式变化，提供预防安全问题增多的实用指南。
### Conclusion
本文的研究结果显示，迭代LLM代码改进过程中，关键安全漏洞上升显著，提示在闭环中必须重视人类验证的重要性，以防止在“改进”代码过程中引入新的安全问题。
## 736. `cs.CL` - 从根到奖励：基于强化学习的动态树推理 [PDF](https://arxiv.org/pdf/2507.13142), [HTML](https://arxiv.org/abs/2507.13142)
### Authors
Ahmed Bahloul,Simon Malberg
### Background
现代语言模型通过链式思考（CoT）推理（Wei et al., 2023）和检索增强（Lewis et al., 2021）来应对复杂的问答需求，但仍存在错误传播和知识整合的问题。而传统的基于树结构的推理方法如ProbTree（Cao et al., 2023）也受到了静态实现带来的限制：（1）推理树在初始构建阶段是固定的，不能动态适应中间结果；（2）每个节点必须评估所有可能的解策略，导致计算效率低下。
### Innovation
本文提出了一种基于强化学习的动态树推理框架，使得推理过程能够根据实时信心值动态扩展推理树，并在行动选择（分解、检索或聚合）中学习最优策略。这种方法保持了ProbTree的概率严谨性，在选择扩展和集中资源方面提高了解决方案的质量和计算效率。
### Conclusion
本文建立了树结构推理的新范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。
## 737. `cs.CL` - GLEAM：学习在跨视角地理定位中匹配与解释 [PDF](https://arxiv.org/pdf/2509.07450), [HTML](https://arxiv.org/abs/2509.07450)
### Authors
Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Peifeng Ma,Xue Yang,Hongsheng Li
### Background
现有跨视角地理定位（CVGL）方法通常局限于单一视角或模态，并依赖直接的视觉匹配策略，缺乏解释性。这些方法仅判断两张图片是否对应，而不解释匹配的原因。
### Innovation
提出GLEAM-C，这是一种将多种视角和模态（包括无人机影像、街道地图、全景图和地面照片）统一与卫星影像对齐的基础CVGL模型。引入GLEAM-X任务，结合跨视角对应的预测与解释性的推理，并通过双阶段训练策略提升了准确性。通过使用双语基准集支持解释性的跨视角推理，增强了透明性和可扩展性。
### Conclusion
GLEAM-C和GLEAM-X构成一个综合CVGL管道，整合了多种模态、多视角对齐和可解释的对应分析，实现了准确的跨视角匹配和解释性推理，提高了地理定位的透明度和解释性。相关代码和数据集将公开发布。
## 738. `cs.CL` - Resource Consumption Red-Teaming for Large Vision-Language Models [PDF](https://arxiv.org/pdf/2507.18053), [HTML](https://arxiv.org/abs/2507.18053)
### Authors
Haoran Gao,Yuanhe Zhang,Zhenhong Zhou,Lei Jiang,Fanyu Meng,Yujia Xiao,Li Sun,Kun Wang,Yang Liu,Junlan Feng
### Background
资源消耗攻击（RCAs）已成为大型语言模型（LLMs）部署中的一个重要威胁。随着视觉模态的整合，这进一步增加了大型视觉语言模型（LVLMs）中RCAs的风险。然而，现有的红队研究主要忽略了视觉输入作为潜在攻击面的可能性，导致了对LVLMs中RCAs应对策略的不足。
### Innovation
本文提出了RECITE（资源消耗红队测试），这是第一个利用视觉模态触发无界RCAs红队测试的方法。首先介绍了控制像素级别的视觉引导优化方法，得到了可以触发重复输出的输出召回目标的对抗性扰动。然后将这些扰动注入视觉输入中，触发无界生成以实现RCAs的目标。实验结果表明，RECITE可使服务响应延迟提高超过26%，导致GPU利用率和内存消耗分别增加20%。
### Conclusion
我们的研究揭示了LVLMs中的安全漏洞，并建立了一个红队框架，这有助于未来对抗RCAs的防御开发。
## 739. `cs.CL` - video-SALMONN 2: 音视频增强大型语言模型 [PDF](https://arxiv.org/pdf/2506.15220), [HTML](https://arxiv.org/abs/2506.15220)
### Authors
Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang
### Background
近年来，音视频理解和描述领域取得了显著进展，但模型通常依赖单一的元学习策略，如固定参考策略的直接偏好优化（DPO）。如何提升模型的描述和问答能力，特别是在音视频理解和复杂问题解答方面，成为一项挑战。本文致力于解决这一问题，提出了一种新的方法——多轮直接偏好优化（MrDPO），并结合目标函数来共同奖励完整性和事实准确性。这种方法优化了音视频描述的详细度和准确性，超越了现有的专有系统如GPT-4o和Gemini-1.5 Pro。通过这种方法优化后的模型不仅在音视频描述上表现出色，还在复杂的音频-视频问题回答任务上取得了显著成就。
### Innovation
本文的创新之处在于提出了多轮直接偏好优化（MrDPO），这种优化策略通过定期从新的轻量级适配器中重新初始化固定的参考策略来避免参考策略过时，从而持续改进模型的性能。结果表明，使用MrDPO优化的模型在多个广泛使用的音频-视频和纯视觉理解基准测试（包括Video-MME、WorldSense、AVUT、Video-Holmes、DailyOmni、MLVU和LVBench）上超越了现有最好的开放源代码系统，特别是在3B和7B模型上实现了可比规模的最优结果，而72B模型则超过了所有其他开源系统。
### Conclusion
本文通过引入MrDPO和结合目标函数优化，成功地提升了音频-视频描述和问答的性能。通过对高质量的音视频描述和问题回答数据集的监督微调，这些优化不仅应用于音视频描述，还促进了复杂音频-视频问题回答任务的强大表现。所有源代码、模型和数据已公开发布。
## 740. `cs.CL` - MultiVox: 多模态交互评估标准 [PDF](https://arxiv.org/pdf/2507.10859), [HTML](https://arxiv.org/abs/2507.10859)
### Authors
Ramaneswaran Selvakumar,Ashish Seth,Nishit Anand,Utkarsh Tyagi,Sonal Kumar,Sreyan Ghosh,Dinesh Manocha
### Background
大型语言模型（LLMs）的快速发展使全能模型能够充当能够理解口头对话的语音助手。这些模型可以处理文本之外的多模态输入，如语音和视觉数据，这使得对话更加情景相关。然而，当前的基准测试在全面评估这些模型是否能生成情景相关响应方面做得不够，特别是在隐性理解细粒度语音特征（如音高、情感、音色和音量或背景声音环境）方面表现不足。此外，它们在评估模型如何将副语言线索与互补的视觉信号对齐并影响其响应能力方面也做得不足。为了解决这些差距，我们提出了MultiVox——第一个旨在评估语音助手整合口头和视觉线索（包括副语言语音特征）以实现真正多模态理解的基准测试。MultiVox包括1000段由人工注释并录制的对话，涵盖了各种副语言特征和视觉线索（如图片和视频）。我们在10个最先进模型上的评估表明，尽管人类在这类任务中表现出色，现有的模型在产出情境相关响应方面仍然存在困难。
### Innovation
我们提出了MultiVox，第一个针对评估语音助手整合口语和视觉线索的基准测试。MultiVox包含了1000个人工注释并录制的口语对话，涵盖了多样化的副语言特征和视觉线索，如图像和视频。该基准测试能够全面评估当前模型在生成情境相关响应方面的表现，尤其在理解和应用细粒度语音特征和环境音频背景方面。
### Conclusion
尽管人类在这些任务中表现出色，现有的模型在产生与情境相关响应方面仍存在不足，特别是在处理副语言线索和视觉线索的综合应用方面。MultiVox作为一个新的基准测试，旨在通过涵盖多样化的副语言特征和视觉线索来填补这一空白，促进语音助手的理解能力和响应生成更加情境化、个性化。
## 741. `cs.CL` - 纵向和多模态录音系统捕获AI和临床会诊研究中的真实患者-临床医生对话：研究方案 [PDF](https://arxiv.org/pdf/2509.16378), [HTML](https://arxiv.org/abs/2509.16378)
### Authors
Misk Al Zahidy,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Ana Cristina Proano,Ana Gabriela Claros,Maria Lizarazo Jimenez,David Toro-Tobon,Victor M. Montori,Oscar J. Ponce-Ponte,Juan P. Brito
### Background
现有的AI医疗模型大多基于电子健康记录（EHRs）训练，这些记录主要捕捉生物指标，而忽略了临床医生和患者之间的互动。这些互动对于护理至关重要，体现在语言、文本和视频中，但目前的数据库中几乎不存在。因此，仅在EHRs上训练的AI系统可能延续窄化的生物医学视角，忽视了临床会诊中患者的实际交流经验。本研究旨在设计，实施并评估一个纵向的多模态系统，用以捕获患者-临床医生互动，将360度视频/音频录制数据与调查问卷和EHR数据进行链接，以创建适用于AI研究的数据集。该研究在梅奥诊所的一个学术门诊内分泌科进行。
### Innovation
该研究设计了一个纵向、多模态系统来捕捉患者-临床医生互动，结合360度视频/音频录制数据和调查问卷与EHR数据，创建一个适用于AI研究的数据集。研究通过一致的工作流程、终点和伦理保护措施，提供了一个可复制的框架模板，用于跨模态创建纵向数据集。这为综合护理复杂性的AI模型奠定了基础。
### Conclusion
这项研究展示了纵向多模态系统捕获患者-临床医生互动动态的可行性。通过详细描述工作流程、终点和伦理保护措施，研究为纵向数据集的创建提供了模板，并为综合护理复杂性的AI模型奠定了基础。
## 742. `cs.CL` - R-Stitch：高效推理的动态轨迹缝合 [PDF](https://arxiv.org/pdf/2507.17307), [HTML](https://arxiv.org/abs/2507.17307)
### Authors
Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang
### Background
链式思维（CoT）增强了大规模语言模型（LLMs）的问题解决能力，但会导致推理成本增加，因为它们的自回归路径较长。现有加速策略通过提前停止或压缩缩短路径，或者使用较小模型的推测性解码。然而，推测性解码在模型一致性较低时效果有限，且严格按照标记级别的一致性，忽视了一些小模型在正确时生成的显著更简洁推理路径，可以减少推理长度。
### Innovation
R-Stitch 提出了一种无训练的混合解码框架，利用标记级别的熵作为不确定性代理，来在小语言模型（SLM）和LLM之间分配计算。通过基于熵的路由策略，R-Stitch让SLM高效处理低熵标记，并将不确定标记委托给LLM，从而避免全面回滚并保持答案质量。此外，R-Stitch+ 进一步学习动态路由策略，以适应性调整标记预算，从而减少每标记的解码复杂性和生成标记的数量。
### Conclusion
该方法在无需显著牺牲准确性的前提下，实现了显著的加速效果。具体而言，它在DeepSeek-R1-Distill-Qwen-7B、14B和QWQ-32B上分别实现了3.00倍、3.85倍和4.10倍的峰值加速，同时保持与全LLM解码相当的准确性。此外，该方法还自然地支持能够适应不同计算预算的可调整效率-准确度权衡，无需重新训练。
## 743. `cs.CL` - 通过学习多样化思维链模式扩大基础模型的推理潜力 [PDF](https://arxiv.org/pdf/2509.21124), [HTML](https://arxiv.org/abs/2509.21124)
### Authors
Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai
### Background
近年来，基于强化学习（RL）的大规模推理模型在解决复杂数学推理方面取得了显著进步。中期训练中引入长推理链（CoT）数据可以显著提高推理深度，但当前方法往往是不分青红皂白地利用CoT数据，没有明确哪些数据类型对提升模型推理能力最有效。
### Innovation
首次定义了基础模型的推理潜力为正确回答问题所需独立尝试次数的倒数，并提出使用包含高价值推理模式的多样化数据来增加推理潜力。抽象出具有共通性和归纳能力的原子推理模式，并构建了一个核心参考集。提出了一种双粒度算法，涉及推理模式链和令牌熵，从数据池中高效选择与核心集匹配的高价值CoT数据（CoTP），以训练模型掌握有效推理。
### Conclusion
仅使用10B-token的CoTP数据，可以提升85A6B MoE模型在复杂AIME 2024和2025任务上的性能9.58%，并提高下游RL性能的上限7.81%。
## 744. `cs.CL` - 重新思考视觉语言导航中的实打名义差距：全方位研究物理与视觉差异 [PDF](https://arxiv.org/pdf/2507.13019), [HTML](https://arxiv.org/abs/2507.13019)
### Authors
Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang
### Background
近期的视觉语言导航（VLN）研究取得了显著进展，但它们假设机器人可以理想地移动和控制，忽略了真实环境中物理实现所面临的挑战。作者指出，这些理想化假设未能真实反映物理实施的复杂挑战，如机器人观察空间有限、环境光照变化以及碰撞和摔倒等物理挑战。为解决这一问题，该研究引入了VLN-PE平台，支持类人型、四足和轮式机器人，并系统评估了多种以自我为中心的VLN方法在不同技术管道中的性能，包括单一步骤离散动作预测的分类模型、密集轨迹预测的扩散模型以及无需训练的地图导向大型语言模型（LLM，结合路径规划）。评估结果表明，由于机器人观察空间有限、环境光照变化以及物理挑战如碰撞和摔倒，这些方法在物理机器人设置中的性能显著下降，这揭示了复杂环境中腿足机器人的运动限制。该平台具有高度可扩展性，可以无缝集成新的场景（超越MP3D），以进行更全面的VLN评估。
### Innovation
该研究首次系统地评估了多种以自我为中心的VLN方法在物理机器人设置中的性能，涵盖分类模型单一步骤离散动作预测、扩散模型密集轨迹预测、以及无训练的地图引导大型语言模型结合路径规划方案。VLN-PE平台支持类人型、四足和轮式机器人，能够无缝集成新场景，实现更全面的VLN评估。该研究指出，尽管当前模型在物理部署中的一般化能力较弱，但VLN-PE提供了一种提高跨实体整体适应性的新途径。
### Conclusion
该研究强调了在现实环境中进行VLN评估的重要性，并指出存在物理鸿沟。通过引入VLN-PE平台，该研究希望能够激励研究界重新思考VLN的限制，并推动更鲁棒和实用的VLN模型的发展。尽管目前模型的跨环境适应性较弱，但研究为改善整体适应性提供了一条新途径。
## 745. `cs.CV` - KV-Efficient VLA: 基于RNN门控分块KV缓存加速视觉语言模型的方法 [PDF](https://arxiv.org/pdf/2509.21354), [HTML](https://arxiv.org/abs/2509.21354)
### Authors
Wanshun Xu,Long Zhuang
### Background
VLA模型能够实现统一的机器人感知和控制，但其扩展性受到注意力机制的二次成本限制，以及长时间预测期间键值（KV）记忆无界增长的影响。尽管近期方法通过扩展基础架构来提高泛化性，但它们往往忽略了实时部署至关重要的推理效率问题。
### Innovation
本文提出了一种名为KV-Efficient VLA的模型通用内存压缩框架，通过引入轻量级、训练友好机制来选择性地保留高价值上下文，特别是在KV缓存中进行分块处理，并采用循环门控模块根据学习到的价值评分进行总结和过滤历史上下文。这种设计能够保留近期的细粒度细节，同时大幅度去除过时的、低相关性的内存，并保持因果关系。理论分析表明，KV-Efficient VLA可实现高达1.21倍的推理速度提升和36%的KV内存减少，同时对任务成功率的影响最小。
### Conclusion
我们的方法可以无缝集成到现有的自回归和混合VLA堆栈中，从而实现可扩展的推理，而无需修改训练管道或下游控制逻辑，使VLA在实际部署中展现出更大的实用性与效率。
## 746. `cs.CL` - TrustJudge: 解决LLM作为评判者的不一致性和对策 [PDF](https://arxiv.org/pdf/2509.21117), [HTML](https://arxiv.org/abs/2509.21117)
### Authors
Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang
### Background
大型语言模型（LLM）作为自动化评估者（LLM-as-a-judge）的应用揭示了当前评估框架中的关键不一致性。这些不一致性包括评分对比不一致和对列不一致性。研究指出，这些问题源于离散评分系统中的信息丢失和二元评价中的模糊约束判断。
### Innovation
提出了一种名为TrustJudge的概率框架，其通过两种主要创新来解决这些问题：1. 分布敏感评分，该方法从离散评分概率计算连续期望，从而保留信息熵以实现更准确的评分；2. 似然感知聚合，该方法使用双向偏好概率或困惑度来解决传递性的违反。
### Conclusion
TrustJudge框架通过提高评估准确性，显著降低了评分对比不一致（减少8.43%）和对列不一致性（减少10.82%）。该工作提供了LLM作为评判者的评估框架不一致性的系统分析，提供了理论见解和实用解决方案，以实现可靠的自动化评估。TrustJudge在多种模型架构和规模上展现了持续的改进，无需额外训练或人工注解即可实现更可信的LLM评估。
## 747. `cs.CL` - The Invisible Leash: Why RLVR May or May Not Escape Its Origin [PDF](https://arxiv.org/pdf/2507.14843), [HTML](https://arxiv.org/abs/2507.14843)
### Authors
Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi
### Background
最近的大规模语言模型的进步突显了强化学习与价值归一化(RLVR)作为提高AI解决复杂逻辑任务能力的有潜力的方法。然而，目前RLVR的做法是否真正扩展了模型的推理边界还不清楚，它是否只是通过放大基模型已经知道的高回报输出来提高精度。本研究通过实证调查提供了对于当前RLVR常见实践潜在边界的新见解。
### Innovation
该研究探讨了在当前训练条件下，RLVR如何作为一种支持约束的优化机制，可能限制了发现完全原创解决方案的能力，仍然受限于基模型的初始分布。同时也发现在当前RLVR配方下，虽然能够可靠地提高精确度，但可能会逐步缩小探索范围，从而可能忽视正确但未被充分代表的解决方案。通过广泛的实证实验验证了在较大的采样预算下，虽然当前RLVR配方可以一致地提高pass@1，但实际支持的收缩通常超过了实际支持的扩展。此外，研究观察到虽然RLVR有时会增加token级熵，导致每一步生成的不确定性增加，但答案级熵则在下降，表明这些看似更不确定的路径最终收敛到更小数量的独特答案。这些发现揭示了当前RLVR配方在扩展推理视野方面的潜在限制。
### Conclusion
这些发现揭示了当前RLVR配方在扩展推理视野方面的潜在限制，为了打破这种无形的束缚，未来可能需要算法创新性的方法，如显式的探索机制或混合策略，将概率质量注入未充分代表的解决方案区域。
## 748. `cs.CV` - 提升自闭症检测的多模态行为分析 [PDF](https://arxiv.org/pdf/2509.21352), [HTML](https://arxiv.org/abs/2509.21352)
### Authors
William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla
### Background
自闭症谱系障碍（ASC）的诊断过程复杂且资源密集，现有的计算机辅助诊断方法通过分析患者视频数据的行为线索来检测自闭症。尽管这些模型在某些数据集上展示了有希望的结果，但它们在凝视特征性能和实际应用场景中的泛化能力方面表现不佳。因此，提出了一项研究，分析了一个包含168名ASC患者（46%女性）和157名非自闭症患者（46%女性）的标准视频数据集，使该数据集成为我们所知的最大、最平衡的数据集。研究者对面部表情、语音语调、头部动作、心率变异性（HRV）和凝视行为进行了多模态分析。
### Innovation
研究引入了新型统计描述符来量化眼睛凝视角度的可变性，提高了基于凝视的分类准确性，从64%提升到69%，并将计算结果与自闭症背景下凝视回避的临床研究结果相对应。此外，使用后期融合技术实现了74%的分类准确率，展示了多种行为指标集成的有效性。
### Conclusion
研究结果强调了基于视频的筛查工具在自闭症评估中的潜在价值，这些工具可以支持自闭症的快速诊断和大规模筛查。
## 749. `cs.CV` - 在文本到图像模型中的跨模态提示解耦攻击 [PDF](https://arxiv.org/pdf/2509.21360), [HTML](https://arxiv.org/abs/2509.21360)
### Authors
Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen
### Background
文本到图像（T2I）模型在各个领域广泛应用于高保真图像生成，但这些模型可能通过 Jailbreak 攻击被滥用以生成不适宜内容。现有的 Jailbreak 方法主要操控文本提示，而图像输入的安全性漏洞尚未得到充分探讨。此外，基于文本的方法难以绕过模型的安全过滤器。
### Innovation
提出了多模态提示解耦攻击（MPDA），利用图像模态将原始不安全提示中的有害语义部分分离。MPDA 按照三个核心步骤进行：首先，大型语言模型（LLM）将不安全提示解耦为伪安全提示和有害提示。前者是看似无害的子提示，可以绕过过滤器，而后者是具有不安全语义的子提示，会触发过滤器。接着，LLM 将有害提示改写为自然的对抗性提示以绕过安全过滤器，从而引导 T2I 模型将基础图像修改为不适宜输出。最后，通过视觉语言模型生成图像描述，提供一种新的路径指导 LLM 在迭代中重写和完善生成的内容。
### Conclusion
通过 MPDA 攻击可以有效绕过文本到图像模型的安全过滤器生成不适宜内容，且确保生成的不适宜图像与原始不安全提示的语义一致性。
## 750. `cs.CL` - 稀疏但错位：不正确的L0导致稀疏自编码器提取错误特征 [PDF](https://arxiv.org/pdf/2508.16560), [HTML](https://arxiv.org/abs/2508.16560)
### Authors
David Chanin,Adrià Garriga-Alonso
### Background
稀疏自编码器（SAEs）从大型语言模型（LLM）的内部激活中提取特征，这些特征对应于可解释的概念。现有的工作通过稀疏性-重构折衷图比较SAE算法，暗示L0（每个标记平均应触发的SAE特征数）是一个自由参数，其具体数值没有唯一正确值，除非对重构有影响。已有研究指出，如果L0设置不正确，SAE将无法分离LLM的基本特征。如果L0过低，SAE会混合相关特征以提高重构效果；如果L0过高，SAE会找到混合作用的退化解决方案。因此，对于给定的训练分布，需要找到合适的L0以指导SAE的训练并获得正确的特征。已有使用SAE的方法中，大部分的L0设置都过低。
### Innovation
作者提出了一种代理指标来帮助指导确定给定训练分布下SAE的正确L0。这种方法在玩具模型中能找到正确的L0，并且与大型语言模型中SAE的稀疏探针性能峰值一致。研究结果表明，大多数常用的SAE的L0设置都过低，正确的L0设置对于训练具有正确特征的SAE是必要的。
### Conclusion
L0必须设置正确，以确保稀疏自编码器能够正确分离大型语言模型的内部特征。不正确的L0设置会导致特征分离不正确，即使在稀疏自编码器能够获得较好重构结果的情况下也是如此。
## 751. `cs.CL` - EigenBench: 一种衡量价值对齐的比较性行为指标 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
价值对齐是人工智能领域亟待解决的问题，目前缺乏衡量价值对齐的定量指标。为此，本文提出EigenBench方法，用于比较语言模型的价值对齐程度。给定一个模型集合、描述价值系统的宪法以及包含不同场景的数据集，该方法可以返回描述每个模型对给定宪法对齐度的向量评分。通过这种方法，模型可以基于不同场景来评估其他模型的输出，并通过EigenTrust（Kamvar等，2003）进行加权聚合，从而得到反映整个模型集合的加权共识评分。由于此方法评估的是主观特质，故而无需真实标签，而是通过收集人类对模型的判断来验证方法的有效性。EigenBench还能在没有客观标签的情况下恢复模型在GPQA基准上的排名，这进一步证明其作为衡量不存在真实标签的主观价值框架的有效性。
### Innovation
提出EigenBench方法，提供了一种新的方法来衡量语言模型的价值对齐性。该方法通过模型之间的相互评估和基于EigenTrust的加权聚合，无需真实标签，能够准确反映主观价值对齐的评分，同时在没有客观标签的情况下有效评估模型排名，展示了其在衡量无真实标签的主观价值时的可行性。
### Conclusion
本文提出了一种无需真实标签的衡量模型价值对齐的新方法EigenBench，通过模型之间的相互评估和基于EigenTrust的加权聚合，验证了其在无客观标签的情况下对主观价值的评价准确性，并借助GPQA基准进一步展示了其有效性。
## 752. `cs.CV` - 在施工场地使用人工智能进行脚手架的安全评估 [PDF](https://arxiv.org/pdf/2509.21368), [HTML](https://arxiv.org/abs/2509.21368)
### Authors
Sameer Prabhu,Amit Patwardhan,Ramin Karim
### Background
在建筑行业中，安全评估对于确保资产的可靠性和工人的安全至关重要。脚手架作为一种关键的结构支持资产，需要定期检查以检测并识别可能影响其完整性和稳定性的设计规则改变。目前，检查主要是通过视觉方式进行，并由现场经理或认证人员执行，以发现偏差。然而，视觉检查耗时且容易出现人为错误，这可能导致不安全的状况。
### Innovation
开发了一个基于云的人工智能平台，以处理和分析脚手架结构的点云数据。提出的系统通过将认证的参考数据与最近的点云数据进行比较和评估，检测结构改进建议。这种方法可能实现脚手架的自动化监控，减少手动检查所需的时间和努力，同时提高施工现场的安全性。
### Conclusion
本文探讨了使用人工智能和数字化来提高脚手架检查的准确性，从而促进安全改进。通过基于云的人工智能平台处理和分析点云数据，实现自动化的监测，减少了人力检查所需的时间和努力，提高了施工场地的安全性。
## 753. `cs.CL` - 大型语言模型中的认知负荷限制：多跳推理基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
大型语言模型在静态基准上的表现与其在动态、信息丰富的环境中的脆弱性之间存在关键差距。尽管模型擅长单个任务，但在认知负载下的推理限制尚未完全理解。本文揭示了认知负荷如何影响模型的性能，特别关注外部无关信息（Context Saturation）和任务切换的干扰（Attentional Residue）对模型性能的影响。通过设计Interleaved Cognitive Evaluation（ICE）基准测试，系统地操纵了这些负荷因素，发现五个指令调优模型在不同条件下表现出显著的性能差异，这些因素包括清洁控制条件、高内在负荷任务等。
### Innovation
作者引入了一个正式的认知计算负荷理论，并设计了Interleaved Cognitive Evaluation（ICE），这是一个旨在系统操纵这些负载因素的基准测试。通过全面研究（10次复制，每个项目200个问题），揭示了认知负荷是导致推理失败的关键因素。这些发现支持了在不确定性情况下幻觉作为一种猜测的理论，并建议动态、认知意识的压力测试对于评估先进AI系统的真正弹性和安全性至关重要。
### Conclusion
研究表明，认知负荷对先进AI系统的推理能力有显著影响。因此，为了评估这些系统的真正弹性和安全性，需要进行动态、认知意识的压力测试，例如通过ICE基准测试来示范这一点。
## 754. `cs.CV` - 一种与多监督纠缠的相互学习方法用于显著目标检测 [PDF](https://arxiv.org/pdf/2509.21363), [HTML](https://arxiv.org/abs/2509.21363)
### Authors
Runmin Wu,Mengyang Feng,Wenlong Guan,Dong Wang,Huchuan Lu,Errui Ding
### Background
尽管近年来深度学习技术在显著目标检测方面取得了巨大进展，但由于对象内部复杂性和卷积、池化操作导致的不准确边界，预测的显著性图仍然存在不完整的问题。
### Innovation
本文提出通过利用显著目标检测、前景轮廓检测和边缘检测的监督来训练显著性检测网络，以缓解这些问题。具体来说，采用相互纠缠的任务方式生成均匀突出的显著性图，并采用相互学习模块（MLM），每个MLM包含多个以相互学习方式训练的网络分支，从而显著提高性能。
### Conclusion
在七个具有挑战性的数据集上的广泛实验表明，所提出的方法在显著目标检测和边缘检测中均达到最先进的结果。
## 755. `cs.CV` - MDF-MLLM: 通过跨模态特征对齐实现深度融合以提高视网膜影像分类的上下文感知能力 [PDF](https://arxiv.org/pdf/2509.21358), [HTML](https://arxiv.org/abs/2509.21358)
### Authors
Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen
### Background
现有的多模态大型语言模型（MLLMs）在捕捉用于诊断视网膜疾病（如青光眼、糖尿病视网膜病变和色素性视网膜炎）的低级空间细节方面存在困难。
### Innovation
提出了一种新颖的多模态深度学习架构（MDF-MLLM），将微细节图像特征和全局文本上下文结合起来，显著提高了视网膜底片图像的疾病分类准确性。
### Conclusion
MDF-MLLM不仅实现了在不同疾病分类任务中的显著精度提升，还展示了可推广、可解释且模块化的视网膜底片图像分类框架，对未来同步训练技术的研究具有重要意义。
## 756. `cs.CV` - 自动生成创意和反事实文本图像合成的提示 [PDF](https://arxiv.org/pdf/2509.21375), [HTML](https://arxiv.org/abs/2509.21375)
### Authors
Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens
### Background
文本到图像生成技术通过大规模多模态训练取得了快速进展，但细粒度的可控性仍然是一个关键挑战。反事实可控性，即能故意生成违背常识模式的图像的能力，虽然在推动创意性和探索性应用方面至关重要，但仍然是一个重要挑战。
### Innovation
本文提出了一个自动提示工程框架，专门用于生成反事实尺寸的图像。该框架包含三种组件：图像评估器、监督提示重写器和DPO训练的排序器，用于选择最佳的修订提示。此外，还构建了首个反事实尺寸文本图像数据集，并通过扩展Grounded SAM并进行改进，提高了图像评估器的效果。实验结果表明，该方法在基准方法和ChatGPT-4o方面表现出色，为未来反事实可控性方面的研究奠定了基础。
### Conclusion
我们的方法表明，自动化提示生成框架在创造性和反事实文本到图像合成中具有优异的表现，为未来的研究奠定了基础，并提供了一个新的研究方向，即通过自动调整文本提示来生成违背常识的图像。
## 757. `cs.CV` - 随机直接偏好优化在放射影象报告生成中的应用 [PDF](https://arxiv.org/pdf/2509.21351), [HTML](https://arxiv.org/abs/2509.21351)
### Authors
Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev
### Background
在医学影像分析领域，放射影象报告生成（RRG）作为减轻放射科医师工作负担的有希望的工具引起了显著关注。尽管取得了许多进展，但当前方法尚未达到在实际临床环境中部署所需的高质量标准。与此同时，通过采用最初为大规模语言模型（LLMs）设计的训练策略，如对齐技术，大规模视觉语言模型（VLMs）在通用领域取得了显著进步。然而，实际临床环境中仍缺乏一个有效的模型来提高RRG的准确性。本文即针对这一问题展开研究，探讨如何利用随机直接偏好优化（DPO）来改善RRG的准确性。
### Innovation
文章介绍了一种模型通用的框架，通过随机对比采样构建训练对，以提升RRG的准确性，无需使用奖励模型或人工偏好标注。我们的方法结合了随机DPO来增强现有三种顶级模型的性能，能够在不增加额外训练数据的情况下提高临床性能指标。
### Conclusion
我们的方法在不使用额外训练数据的情况下，通过对现有最先进模型的补强，可以实现最多5%的临床性能提升，即展现了在实际临床应用中的潜力和技术的有效性。
## 758. `cs.CV` - LongiMam模型：利用纵向乳腺X线摄影提高乳腺癌风险预测 [PDF](https://arxiv.org/pdf/2509.21383), [HTML](https://arxiv.org/abs/2509.21383)
### Authors
Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau
### Background
当前的深度学习模型大多基于单张或有限的乳腺X线摄影数据，并未针对实际临床筛查中不平衡的结果分布和异质性随访情况进行适应。为了实现基于纵向影像数据的个性化乳腺癌筛查，需要开发一种能够适应实际环境并提升预测准确性的深度学习模型。
### Innovation
研究团队开发了一种名为LongiMam的端到端深度学习模型，该模型结合了卷积神经网络和循环神经网络，能够捕捉空间和时间上的模式，用于预测乳腺癌。LongiMam通过整合多达四张以前的乳腺X线摄影片，增强了模型对乳腺癌预测的能力，尤其是在多种情况和不同类型的预先检查组合中，其预测性能得到了显著提升。
### Conclusion
研究结果表明，纵向建模能够有效提高乳腺癌的预测准确性，且在妇女随访乳腺密度变化方面具有明显优势。研究支持将重复的乳腺X线摄影纳入筛查项目，以实现乳腺癌风险的精细化管理。LongiMam已经公开提供为开源软件。
## 759. `cs.CV` - 通过移除和重新训练调试概念瓶颈模型 [PDF](https://arxiv.org/pdf/2509.21385), [HTML](https://arxiv.org/abs/2509.21385)
### Authors
Eric Enouen,Sainyam Galhotra
### Background
概念瓶颈模型（CBMs）使用一组可由人类理解的概念来预测最终任务标签，使领域专家不仅可以验证CBM的预测，还可以在测试时干预不正确的概念。然而，这些干预未能解决CBM与专家推理之间系统的不一致，例如当模型从带有偏差的数据中学习捷径时。
### Innovation
本文提出了一种通用的可解释调试框架，该框架按照移除和重新训练的两步过程进行。在移除步骤中，专家使用概念解释来识别并移除任何不必要的概念。在重新训练步骤中，引入了CBDebug方法，这是一种新颖的方法，利用CBM的可解释性充当从概念级别用户反馈转换为样本级别辅助标签的桥梁。这些标签随后用于应用监督偏见缓解和针对性增强，从而减少模型对不必要的概念的依赖。
### Conclusion
我们使用真实和自动化的专家反馈对框架进行了评估，并发现CBDebug在多种CBM架构（PIP-Net，后验CBM）和具有已知伪相关性的基准测试中显著优于先前的重新训练方法。
## 760. `cs.CV` - 稀疏子网络是否表现出认知对齐的注意力？剪枝对注意力映射忠实度、稀疏性和概念一致性的影响 [PDF](https://arxiv.org/pdf/2509.21387), [HTML](https://arxiv.org/abs/2509.21387)
### Authors
Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi
### Background
先前的研究已经表明，神经网络可以通过大幅度剪枝而保持性能。然而，剪枝对模型可解释性的影响尚未明确。本研究旨在探讨基于幅度的剪枝后微调如何影响低级别的显著性图和高级别的概念表示。
### Innovation
研究使用ResNet-18模型在ImageNette数据集上进行了训练，并通过Vanilla Gradients (VG)和Integrated Gradients (IG)进行后处理解释的对比分析，评估稀疏性和忠实度。进一步应用CRAFT概念提取技术来跟踪学习概念语义连贯性的变化。研究结果表明，轻度到中度剪枝可以提高显著性图的聚焦度和忠实度，同时保留具有语义意义的概念。而过度剪枝会合并异质特征，减少显著性图的稀疏性和概念连贯性，尽管准确性保持不变。这些发现表明，虽然剪枝可以促使内部表示向更接近人类注意力模式的方向演变，但过度剪枝会损害可解释性。
### Conclusion
研究表明，适度剪枝能够提高显著性图的聚焦度和忠实度，保留有意义的概念。而过度剪枝会损害这些特性。这些发现表明，剪枝可以引导内部表示向更接近人类注意力模式的方向发展，但过度剪枝会影响模型的可解释性。
## 761. `cs.CV` - 大模型赋能的生成式语义通信在图像传输中应用 [PDF](https://arxiv.org/pdf/2509.21394), [HTML](https://arxiv.org/abs/2509.21394)
### Authors
Qiyu Ma,Wanli Ni,Zhijin Qin
### Background
生成人工智能（AI）的迅速发展为语义通信系统中增强图像传输的效率和准确性提供了重要机会。然而，现有的方法往往忽视了图像不同区域的重要性差异，这可能影响视觉关键内容的重建质量。
### Innovation
本文提出了一个创新的生成语义通信系统，该系统通过将图像分割为关键区域和非关键区域来细化语义粒度。关键区域使用图像定向语义编码进行处理，而非关键区域则通过图像到文本建模进行高效压缩。此外，为了缓解大型AI模型带来的存储和计算需求，本文还采用了一种轻量级部署策略，包括模型量化和低秩适应微调技术，显著提高了资源利用而不牺牲性能。
### Conclusion
仿真结果表明，提出的系统在语义保真度和视觉质量方面均优于传统方法，从而证明了其在图像传输任务中的有效性。
## 762. `cs.CV` - 评估流行CNNs与大脑在情绪评估中的对齐 [PDF](https://arxiv.org/pdf/2509.21384), [HTML](https://arxiv.org/abs/2509.21384)
### Authors
Laurent Mertens,Elahe' Yargholi,Laura Van Hove,Hans Op de Beeck,Jan Van den Stock,Joost Vennekens
### Background
卷积神经网络（CNNs）在许多计算机视觉任务中表现出色，并且已被证明对心理学领域具有研究价值，因为CNNs的工作机制与人类大脑显示出某些对应关系。这些对应关系大多集中在一般的视觉感知上，但尚未对更复杂的大脑过程，如社交认知进行深入研究。因此，本研究旨在评估流行CNN架构在情绪评估任务中的大脑对齐程度。
### Innovation
本研究首次通过相关分析，评估了主流CNN架构与人类行为和功能性磁共振成像（fMRI）数据之间在情绪评估方面的对齐情况。此外，还提出了Object2Brain框架，该框架结合了GradCAM和对象检测技术，并在CNN过滤器级别上应用相关分析，研究不同对象类别对CNN对人类影响的影响。
### Conclusion
研究结果表明，CNNs在情绪评估任务中难以超越简单的视觉处理，且不能反映高层次的大脑处理。尽管不同CNN架构显示出类似的相关趋势，但它们对不同对象类别的敏感性却有所不同。
## 763. `cs.CV` - 基于短语的地志检查方法自动生成的胸部X光报告 [PDF](https://arxiv.org/pdf/2509.21356), [HTML](https://arxiv.org/abs/2509.21356)
### Authors
Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C.L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood
### Background
随着大规模视觉语言模型（VLM）的出现，现在可以为胸部X光图像生成逼真的放射学报告。然而，由于生成的描述中存在事实错误和幻觉，其临床应用受到了阻碍。本文旨在提出一种新型短语导向的事实检查模型（FC模型），该模型能够检测自动生成的胸部放射学报告中找到和所指示位置的错误。为此，作者通过篡改地面真实报告中的发现和位置信息，构建了一个大规模合成数据集来模拟报告中的错误，并在此数据集上训练了一个新的多标签跨模态对比回归网络，以评估报告的真实性和定位准确性。
### Innovation
本文提出了一种名为FC模型的短语导向事实检查模型，用于检测自动生成的胸部放射学报告中发现和所指示位置的错误。这种方法通过构建大规模合成数据集来模拟错误，并训练了一个新的多标签跨模态对比回归网络，能够在多种X光数据集上准确预测发现的真实性并定位错误。此外，该模型对于最新的报告生成器置信度的最高拟合相关系数达到了0.997，表明其在放射学临床推理中的实用性。
### Conclusion
本文提出的方法在多个X光数据集上展示了在发现真实性预测和定位方面的鲁棒性，并有效提高了最新报告生成器的置信度。该方法在多个数据集上实现了高达0.997的置信度符合系数，表明其在临床放射学工作流程中的实用性。
## 764. `cs.CV` - MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation [PDF](https://arxiv.org/pdf/2509.21365), [HTML](https://arxiv.org/abs/2509.21365)
### Authors
Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin
### Background
现有的多模态相关度度量通常从预训练对比学习模型的嵌入能力中借用，用于评估跨模态数据（如CLIP）的相关性。常用的评价指标仅适用于两个模态之间的关联分析，极大地限制了多模态相似性的评估能力。
### Innovation
提出了一种名为MAJORScore的新评价指标，首次通过多模态联合表示来评价多种模态（N模态，N>=3）的相关性。这种方法利用多模态联合表示将多种模态整合到同一隐空间中的能力，可以准确地在单一尺度上表示不同模态，为公平的相关评分提供了支持。实验结果表明，与其他现有方法相比，MAJORScore在一致模态上的得分提高了26.03%-64.29%，而在不一致模态上的得分降低了13.28%-20.54%。
### Conclusion
MAJORScore是一种更可靠的多模态相似性评估指标，适用于大规模多模态数据集的性能评估。
## 765. `cs.CV` - ShipwreckFinder：一种用于多波束声呐数据中水下古迹检测的QGIS工具 [PDF](https://arxiv.org/pdf/2509.21386), [HTML](https://arxiv.org/abs/2509.21386)
### Authors
Anja Sheppard,Tyler Smithline,Andrew Scheffer,David Smith,Advaith V. Sethuraman,Ryan Bird,Sabrina Lin,Katherine A. Skinner
### Background
沉船是海洋历史的重要标志，通常通过手动检查声纳水深数据来发现它们。然而，这个过程非常耗时且往往需要专家分析。本研究介绍了一种新的开源QGIS插件ShipwreckFinder，用于从多波束声纳数据中自动检测沉船。
### Innovation
传统的手动检查方法耗时且依赖专家知识，而ShipwreckFinder工具通过自动预处理声纳水深数据、执行深度学习推理、设定阈值以及生成沉船像素分割掩码或边界框，实现了沉船的自动检测。该工具的核心是一个深度学习模型，该模型基于来自五大湖和爱尔兰海岸的多种沉船数据进行训练。此外，还使用了合成数据生成方法来增加数据集的大小和多样性。
### Conclusion
与基于深度学习的ArcGIS工具包和传统的逆坑洞检测方法相比，ShipwreckFinder工具和训练管道在分割性能上表现出更优的效果。该开源工具可以在以下网址找到：[提供的网址]。
## 766. `cs.CV` - TUN3D：从非构图图像中迈向现实场景理解 [PDF](https://arxiv.org/pdf/2509.21388), [HTML](https://arxiv.org/abs/2509.21388)
### Authors
Anton Konushin,Nikita Drozdov,Bulat Gabdullin,Alexey Zakharov,Anna Vorontsova,Danila Rukhovich,Maksim Kolodiazhnyi
### Background
室内场景理解中的布局估计和3D物体检测是两个基本任务，结合这两个任务可以创建一个紧凑且具有语义的场景表示。目前的方法通常依赖于点云输入，这带来了主要限制，因为大多数消费级相机缺乏深度传感器，视觉数据更加常见。现有方法的局限性导致了研究上亟需一种能够在仅用多视角图像作为输入的情况下进行联合布局估计和3D物体检测的方法。
### Innovation
首次提出了TUN3D方法，这是一种能够处理多视角图像作为输入的轻量级稀疏卷积基础架构，并在此基础上建立两个专门的头部，分别用于3D物体检测和布局估计。引入了一种新的参数化墙体表示方法。实验表明，TUN3D在三个具有挑战性的场景理解基准中取得了最佳性能，同时在3D物体检测方面表现与专门方法相当，但显著提升了布局估计，为整体室内场景理解设立了新标准。
### Conclusion
TUN3D方法在多个场景理解基准测试中取得了最优性能，并且在非构图图像中表现出色，为联合布局估计和3D物体检测提供了一种有效的方法。此方法能够不依赖真实相机姿态和深度监督，从而解决了现有技术的主要限制。
## 767. `cs.CV` - SAEmnesia: 使用稀疏自编码器在扩散模型中擦除概念 [PDF](https://arxiv.org/pdf/2509.21379), [HTML](https://arxiv.org/abs/2509.21379)
### Authors
Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto
### Background
在文本到图像的扩散模型中，有效删除概念需要在模型的潜空间中精确定位概念表示。虽然稀疏自编码器可以减少神经元的多义性，但单个概念的表示仍可能分布在多个潜特征中，这需要大量搜索来实现概念删除。当前方法需要广泛的搜索程序，以确保删除特定的概念，这在计算上是昂贵的。
### Innovation
引入了SAEmnesia，这是一种监督稀疏自编码器训练方法，通过系统化概念标签促进一对一的概念-神经元映射，从而避免特征分裂并促进中心化。与无监督基线相比，该方法学习到的专一神经元具有显著更强的概念关联。SAEmnesia在训练期间增加的唯一计算开销是交叉熵计算。在推理时间，这种可解释的表示减少了96.67%的超参数搜索。在UnlearnCanvas基准测试中，SAEmnesia比现有技术提高了9.22%。在顺序删除任务中，我们展示了更好的可扩展性，对于9个对象的删除，正确性提高了28.4%。
### Conclusion
SAEmnesia通过有效地减少超参数搜索和提高识别准确性，实现了概念删除的高效操作，特别是在顺序删除任务中表现出色。
## 768. `cs.CV` - 动态多目标融合以实现高效视听导航 [PDF](https://arxiv.org/pdf/2509.21377), [HTML](https://arxiv.org/abs/2509.21377)
### Authors
Yinfeng Yu,Hailong Zhang,Meiling Zhu
### Background
当前研究致力于通过结合音视频感官数据进行机器人导航，但现有方法往往忽视了深层次的知觉上下文。先前的研究主要探索了基本的视听数据融合，缺乏有效的多模态信息引导导航的能力，尤其是在音视频数据的动态整合和选择性融合方面存在不足。作者指出，解决这一挑战的关键在于利用动态多模态线索来有效引导导航。
### Innovation
该研究提出了动态多目标融合（Dynamic Multi-Target Fusion, DMTF）机制以实现高效视听导航。通过结合多目标架构和优化的Transformer机制，DMTF-AVN能够筛选和选择性地融合跨模态信息。实验结果表明，DMTF-AVN在成功率（SR）、路径效率（SPL）和场景适应性（SNA）等方面达到了最先进的性能，并展示了强大的可扩展性和通用性，为更复杂的多模态融合策略铺平了道路。
### Conclusion
DMTF-AVN在Replica和Matterport3D数据集上进行了详尽的实验，证明了其在视听导航方面的优越性能和广泛适用性。该模型不仅提高了导航的成功率和效率，还提高了对不同环境的适应能力，展示了其在机器人导航中的潜在应用价值。研究者还公布了代码和视频供进一步研究参考。
## 769. `cs.CV` - 基于类内多样性选择的coreset选择 [PDF](https://arxiv.org/pdf/2509.21380), [HTML](https://arxiv.org/abs/2509.21380)
### Authors
Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor
### Background
深度学习模型在各个领域，包括医疗健康领域，尤其是生物医学图像分类中取得了显著成就，通过学习复杂的特征，实现对复杂疾病的准确诊断。近期的研究通过两种方法进行深度学习模型的训练：从零开始训练和迁移学习。这两种方法都需要大量的计算时间和资源，因为它们依赖于庞大的数据集。设计空间的探索进一步增加了这些计算需求，通常需要多次训练以选择最佳超参数。随着数据集规模的扩大，探索这一问题的解决方案已经引起了研究社区的广泛关注。一种可能的解决方案是选择数据集的一个子集用于训练和超参数搜索，这个子集称为coreset，必须代表原始数据集。简单的coreset选择方法可能是随机抽样，但这可能会损害数据集的代表性。随机抽样的关键局限性在于，它倾向于不平衡数据集中占主导地位的类别。即使类别之间是平衡的，随机抽样也不会捕捉到类别内的多样性。因此，本研究旨在通过引入一种智能、轻量级的coreset选择机制来解决这一问题，尤其是通过提取类别内的多样性，形成类级别的聚类，用于最终抽样。研究成果展示了在著名生物医学图像数据集上进行全面分类实验的有效性，结果表明提出的方法在多个性能指标中优于随机抽样方法，特别是在均匀条件下。
### Innovation
本研究提出了一种基于类内多样性的智能轻量级机制用于coreset选择。这种方法通过提取类别内的多样性形成类别的聚类，从而减少数据集规模同时保持数据集的代表性。实验结果表明这种方法在多个性能指标上优于传统的随机抽样方法，特别是在均匀条件下。
### Conclusion
本文提出了一种基于类内多样性的轻量级coreset选择方法。通过利用类内多样性形成类级别的聚类，该方法能够在保持数据集代表性的前提下减少计算时间和资源的需求。实验结果充分证明了该方法的有效性和优越性，为处理大规模数据集提供了新的思路。
## 770. `cs.CV` - QuadGPT：使用自回归模型的原生四边形网格生成 [PDF](https://arxiv.org/pdf/2509.21420), [HTML](https://arxiv.org/abs/2509.21420)
### Authors
Jian Liu,Chunshi Wang,Song Guo,Haohan Weng,Zhen Zhou,Zhiqi Li,Jiaao Yu,Yiling Zhu,Jing Xu,Biwen Lei,Zhuo Chen,Chunchao Guo
### Background
四边形为主导的网格生成是专业3D内容制作的基础。然而，现有的生成模型通过先生成三角形网格，再根据特定规则将三角形合并为四边形来生成四边形网格，这样的方法通常会产生拓扑质量较差的四边形网格。
### Innovation
QuadGPT 是第一个端到端的自回归框架，用于生成四边形网格。该框架将此过程表述为序列预测模型，有两个关键创新点：1. 统一的标记化方法，处理混合拓扑结构的三角形和四边形；2. 专门的强化学习微调方法 tDPO，以提升生成质量。
### Conclusion
广泛的实验表明，QuadGPT 在几何准确性和拓扑质量方面明显优于之前的三角形到四边形的转换流水线。这项工作为原生四边形网格生成建立了新的基准，并展示了结合大规模自回归模型和拓扑感知的强化学习精炼技术以创建结构化3D资产的强大功能。
## 771. `cs.CV` - mmHSense：支持集成传感与通信系统的多模态分布式毫米波人体感知数据集 [PDF](https://arxiv.org/pdf/2509.21396), [HTML](https://arxiv.org/abs/2509.21396)
### Authors
Nabeel Nisar Bhat,Maksim Karnaukh,Stein Vandenbroeke,Wouter Lemoine,Jakob Struye,Jesus Omar Lacruz,Siddhartha Kumar,Mohammad Hossein Moghaddam,Joerg Widmer,Rafael Berkvens,Jeroen Famaey
### Background
本文介绍了mmHSense数据集，这是一个开放标记的毫米波数据集，旨在支持集成传感与通信(ISAC)系统中的人体感知研究。这些数据集可应用于手势识别、人体识别、姿态估计和定位等多种终端应用，并且可用于开发和推进毫米波ISAC上的信号处理和深度学习研究。
### Innovation
mmHSense数据集提供了多种用途的数据，可用于探索ISAC系统的各种应用，并促进了信号处理和深度学习研究。此外，该研究展示了参数高效微调方法，可以在不同任务之间显著降低计算复杂度，同时保持先前任务的性能。
### Conclusion
本文详细描述了测试平台、实验设置和每个数据集的信号特征，并通过验证特定下游任务表明了数据集的实用性。进一步展示了如何利用参数高效微调方法来适应不同任务，显著降低计算复杂性，同时保持性能。
## 772. `cs.CV` - 无标记超分辨显微镜的计算学习协议：网络架构和信噪比依赖性的比较研究 [PDF](https://arxiv.org/pdf/2509.21376), [HTML](https://arxiv.org/abs/2509.21376)
### Authors
Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo
### Background
光学显微镜在多个领域内广泛应用，包括教育、医疗、质量检测和分析等。然而，光学显微镜在横向分辨率上的局限性（通常定义为约200nm）一直是显微镜研究人员遇到的关键问题，仅靠高成本的外部模块或特殊技术（如超分辨荧光显微镜）来解决这个问题。在常规非专家环境下，解决这些挑战仍然超出了大多数显微镜使用者和设施的能力范围。这项研究旨在评估一种经济且替代的方法来实现超分辨光学显微镜，涉及非荧光相调制显微镜方式，如Zernike相对比（PCM）和差异干涉对比（DIC）显微镜。通过使用通过原子力显微镜（AFM）校准的自制测试目标，对两个先前开发的深度神经网络（DNN）架构（O-Net和Theta-Net）进行评估。研究表明，尽管这两个模型在这些图像的超分辨处理上都表现良好，它们之间是互补的而非竞争性的，尤其是在不同的图像信噪比（SNR）下，应考虑不同的应用。高频信噪比偏好O-Net模型的应用，低频信噪比则倾向于Theta-Net模型。这突显了模型架构（与源图像信噪比的结合）对模型性能和生成图像的超分辨质量的重要性，即使使用相同的训练数据集和训练周期数也一样。
### Innovation
这项研究提出了通过非荧光相调制显微镜方式，特别是Zernike相对比（PCM）和差异干涉对比（DIC）显微镜，进行计算学习来实现超分辨光学显微镜的新方法。研究采用两种深度神经网络（DNN）架构（O-Net和Theta-Net）对非荧光光学纳米显微镜进行评估，并发现在不同的图像信噪比情况下，两种DNN模型能够提供互补的超分辨性能。这表明模型架构和图像信噪比对最终超分辨图像质量具有重要影响。这种方法为非荧光超分辨显微镜提供了新的可能性，特别是在资源有限的环境中.
### Conclusion
研究结果表明，虽然O-Net和Theta-Net在超分辨处理方面表现良好，但它们在不同的信噪比条件下表现出互补的行为。高频信噪比更适合O-Net模型，而低频信噪比则更适合Theta-Net模型。明确模型架构与信噪比的关系对于实现高质量的超分辨图像十分重要。
## 773. `cs.CV` - 增强推理能力的多模态大型语言模型领域自适应预训练方法用于短视频内容审核 [PDF](https://arxiv.org/pdf/2509.21486), [HTML](https://arxiv.org/abs/2509.21486)
### Authors
Zixuan Wang,Yu Sun,Hongwei Wang,Baoyu Jing,Xiang Shen,Xin Dong,Zhuolin Hao,Hongyu Xiong,Yang Song
### Background
短视频平台快速发展，识别不合适内容变得越来越关键。现有方法通常为每种类型的问题训练独立的小分类模型，需要大量人工标注数据，并且缺乏跨问题的一般性。
### Innovation
提出了增强推理能力的多模态大型语言模型（MLLM）的预训练范式，通过引入三种针对性预训练任务：（1）Caption，提升对短视频细节的理解；（2）Visual Question Answering (VQA)，加深对问题定义和标注指南的理解；（3）Chain-of-Thought (CoT)，增强模型的推理能力。实验结果显示，这显著提高了MLLM在零样本和监督微调设置中的表现，并展示了对新兴、未见问题的强大泛化能力。
### Conclusion
所提出的预训练方法在视频内容审核中显著提高了MLLM的性能，并展示了强大的推广应用能力。
## 774. `cs.CV` - 利用单图像超分辨率对气候预测进行1公里分辨率插值 [PDF](https://arxiv.org/pdf/2509.21399), [HTML](https://arxiv.org/abs/2509.21399)
### Authors
Petr Košťál,Pavel Kordík,Ondřej Podsztavek
### Background
高分辨率气候预测对于地方决策至关重要。然而，现有的气候预测具有较低的空间分辨率（例如12.5公里），这限制了它们的应用性。研究通过利用单图像超分辨率模型，将气候预测统计地插值到1公里的分辨率。由于用于训练的数据中缺乏高分辨率气候预测，研究将模型训练在高分辨率的观测网格数据集上，并应用于低分辨率的气候预测数据。使用观测气候指标评估插值后的气候预测结果，这些指标是在气象站位置计算的，而不依赖于高分辨率真实气候数据。实验表明，单图像超分辨率模型可以保留气候指标的精度，而无需增加预测误差。
### Innovation
利用单图像超分辨率技术将低分辨率的气候预测数据提升至高分辨率（1公里），并通过观测气候指标评估插值结果，该方法弥补了现有低分辨率气候预测数据在地方决策支持中的不足，提高了气候预测数据的应用价值和准确度。
### Conclusion
通过单图像超分辨率模型，可以将低分辨率的气候预测数据插值至1公里分辨率，而不影响气候指标的准确性。这种方法为地方气候影响评估提供了更高精度的数据支持。
## 775. `cs.CV` - JaiLIP: 经由损失向导图像扰动的视觉语言模型破解 [PDF](https://arxiv.org/pdf/2509.21401), [HTML](https://arxiv.org/abs/2509.21401)
### Authors
Md Jueal Mia,M. Hadi Amini
### Background
视觉语言模型（VLMs）在生成多模态推理任务方面具有显著能力，但随着不同类型的攻击向量增加，VLMs的潜在滥用或安全性对齐问题变得更为严重。其中，基于图像的扰动在生成有害输出方面特别有效。已有许多技术被提出用于破解VLMs，但这些方法常常导致模型性能不稳定且可见的扰动。
### Innovation
本文提出了一种名为Jailbreaking with Loss-guided Image Perturbation (JaiLIP)的方法，这是一种在图像空间进行破解攻击的技术，通过结合最小化清洁图像和对抗性图像间的均方误差（MSE）损失以及模型的有害输出损失来实现。这种方法使用标准的毒性度量方法（来自Perspective API和Detoxify）进行评估，实验结果表明该方法生成了高度有效且无形的对抗图像，超过了现有方法在产生毒性方面的表现。此外，该方法还在运输领域进行了评估，以显示在特定领域超越有害文本生成的攻击实用性。
### Conclusion
我们的研究突显了图像基于的破解攻击的实际挑战，并强调了为VLMs开发高效防御机制的需求。
## 776. `cs.CV` - 基于残差向量量化的时间效率多代理感知 [PDF](https://arxiv.org/pdf/2509.21464), [HTML](https://arxiv.org/abs/2509.21464)
### Authors
Dereje Shenkut,B.V.K Vijaya Kumar
### Background
多代理协作感知（CP）通过在自动驾驶汽车、无人机和机器人等互联代理之间共享信息来提高场景理解。然而，通信带宽限制了其可扩展性。
### Innovation
提出了名为ReVQom的基于学习的特征压缩算法。该方法通过简单的瓶颈网络和多阶段残差向量量化（RVQ）压缩中间特征，仅传输每个像素的代码索引，减少了数据传输负荷。测试结果显示，ReVQom在保持低精度损失的前提下，实现了高至273倍的压缩比，同时在低至6倍压缩下仍能保持性能。
### Conclusion
ReVQom允许高效且准确的多代理协作感知，向着实际的V2X部署迈出了重要一步。即使在超低带宽运行下，该算法也能实现性能的平滑降级。
## 777. `cs.CV` - ExpertLifeCLEF 2018 的概述：自动化识别系统与顶尖专家相差多远？ [PDF](https://arxiv.org/pdf/2509.21419), [HTML](https://arxiv.org/abs/2509.21419)
### Authors
Herve Goeau,Pierre Bonnet,Alexis Joly
### Background
近年来，植物和动物的自动化识别有了显著进步，尤其是得益于深度学习的最近进展。然而，关键问题是自动系统与人类专家的真实差距。即使是最有经验的专家在验证生物的视觉或音频观察时也会感到困惑或存在分歧。一张图片提供的信息通常是不足够的，难以确定确切的物种。因此，量化这种不确定性并将之与自动化系统的性能进行比较对计算机科学家和专家自然主义者都很重要。
### Innovation
本文中的LifeCLEF 2018 ExpertCLEF挑战旨在比较人类专家与自动化系统的性能。共有4个研究团队的19个深度学习系统被专家植物学家评估，结果显示最先进的人工智能模型在性能上已接近顶尖的人类专家。
### Conclusion
本文详细介绍了挑战的资源与评估、参与研究小组所采用的方法和系统，并分析了主要结果。结果显示，最先进的深度学习模型的性能现在已接近法国本土植物学的顶级专家水平。
## 778. `cs.CV` - 骨架稀疏化和稠密化尺度空间 [PDF](https://arxiv.org/pdf/2509.21398), [HTML](https://arxiv.org/abs/2509.21398)
### Authors
Julia Gierke,Pascal Peter
### Background
哈密尔顿-雅可比骨架，也被称为中轴线，是一种强大的形状描述符，它以最大内切圆的圆心来表示二值对象。尽管其应用范围广泛，中轴线对噪声非常敏感：边缘的小变化会导致骨架不相称的膨胀。经典的修剪方法通过系统地去除不必要的骨骼分支来缓解这一缺点。这种顺序简化类似于图像嵌入越来越稀疏像素表示的家庭中的稀疏化尺度空间原理。我们通过提出骨架稀疏化尺度空间将两者结合在一起：它们利用中轴线的稀疏化来实现形状的分层次简化。与传统的修剪不同，我们的框架内在地满足了关键的尺度空间属性，如分层次结构、可控简化和几何变换不变性。我们在这连续和离散的两种形式中提供了严格的理论基础，并进一步通过稠密化扩展了这一概念。这使得我们可以逆向从粗到细的规模进行推进，甚至可以超出原始骨架，产生对实际应用具有相关性的过度完全的形状表示。
### Innovation
通过引入骨架稀疏化尺度空间，提出了一种新的框架，将中轴线的稀疏化与尺度空间的概念结合在一起，以实现形状的分层次简化。该框架满足关键的尺度空间属性，包括分层次结构、可控简化和几何变换不变性。通过连续和离散的两种形式提供了严格的理论基础，并通过进一步的稠密化扩展了这一概念，使逆向从粗到细的规模推进成为可能，从而生成对实际应用具有相关性的过度完全的形状表示。
### Conclusion
通过证明概念实验，展示了该框架在实用任务，如稳健的骨架生成、形状压缩和增材制造中的刚度增强方面的有效性。
## 779. `cs.CV` - 接下来会发生什么？通过生成点轨迹来预测未来运动 [PDF](https://arxiv.org/pdf/2509.21592), [HTML](https://arxiv.org/abs/2509.21592)
### Authors
Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi
### Background
论文探讨了仅凭单张图像预测运动的问题，即在无法直接观测物体速度或其他参数的情况下，预测世界中物体可能的运动轨迹。现有技术通常是通过视频生成器生成像素，但该论文将任务转化为生成密集的轨迹网格，从而捕捉场景中的全局动力学和不确定性，提供比先前回归器和生成器更准确和多样的预测。
### Innovation
论文创新地将现代视频生成器的架构应用于生成运动轨迹，而不是像素。这种方法能够捕捉到场景中的全局动力学和不确定性，给出比现有的回归器和生成器更准确且多样的预测。此外，该论文通过模拟数据进行了详细评估，并展示了其实用性，特别是在机器人学等下游应用中的表现，并且在真实世界的物理预测数据集上也取得了可喜的准确性。
### Conclusion
尽管最新的视频生成器通常被视为世界模型，但该论文证明它们在从单张图像预测运动方面存在局限性，即使在简单的物理场景中，如下落的方块或机械物体的相互作用时也难以预测。论文指出，这一限制来源于生成像素的开销，而不是直接建模运动。
## 780. `cs.CV` - 手术器械的无监督缺陷检测 [PDF](https://arxiv.org/pdf/2509.21561), [HTML](https://arxiv.org/abs/2509.21561)
### Authors
Joseph Huang,Yichi Zhang,Jingxi Yu,Wei Chen,Seunghyun Hwang,Qiang Qiu,Amy R. Reibman,Edward J. Delp,Fengqing Zhu
### Background
确保手术器械的安全性需要可靠的视觉缺陷检测。然而，手动检测容易出错，现有的自动缺陷检测方法通常是在自然图像或工业图像上训练的，不能有效转移到手术领域。简单应用或微调这些方法会导致问题：由于纹理背景引起的假阳性检测、对小而细微的缺陷灵敏度低，以及由于领域变化无法捕捉到器械特异性特征。
### Innovation
我们提出了一种适应性方法，将无监督缺陷检测方法专门应用于手术器械。此方法通过结合背景遮罩、基于块的分析策略和高效的领域适应技术，解决了现有方法的局限性，实现了手术器械图像中小细节缺陷的可靠检测。
### Conclusion
我们的方法通过跨领域适应解决了通用方法转移性差的问题，实现了对手术器械微妙缺陷的可靠检测，提高了手术器械检测的准确性和可靠性。
## 781. `cs.CV` - 时空对比：DINOv3和V-JEPA2在视频动作分析中的特征表示比较 [PDF](https://arxiv.org/pdf/2509.21595), [HTML](https://arxiv.org/abs/2509.21595)
### Authors
Sai Varun Kodathala,Rakesh Vunnam
### Background
本文研究了两种主要的自监督学习架构在视频动作识别中的表现：DINOv3通过独立处理每一帧并进行空间特征提取，而V-JEPA2则通过在视频序列之间进行联合时间建模。研究通过UCF Sports数据集评估了这两种方法的表现，从多个维度来分析特征质量，包括分类准确性、聚类性能、类内一致性及类间区分能力。
### Innovation
本文提出了一种全面比较DINOv3和V-JEPA2的研究方法，分别通过独立的空间特征提取和联合的时间建模。通过UCF Sports数据集评估了两种方法，结果显示DINOv3在聚类性能和区分能力上有显著优势，特别是在可识别姿态的动作上，而V-JEPA2则在所有动作类型上表现出一致的可靠性。此外，研究还发现这两种方法在特定动作类型上的表现差异，从而为选择合适的特征提取方法提供依据。
### Conclusion
研究揭示了两种架构设计之间的基本性能权衡，DINOv3在静态姿态识别方面表现优异但对依赖于动作的识别性能较差，而V-JEPA2在各种动作类别上提供了平衡的表示质量。这些发现有助于理解视频分析系统中架构设计选择，并为根据任务需求和可靠性约束选择适当特征提取方法提供了实际指导。
## 782. `cs.CV` - VLCE: 一种增强知识框架的灾害评估图像描述 [PDF](https://arxiv.org/pdf/2509.21609), [HTML](https://arxiv.org/abs/2509.21609)
### Authors
Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George
### Background
自然灾害发生后，立即进行损失评估至关重要；然而，传统的手工评估技术速度慢且危险。尽管卫星和无人机照片能够提供受损区域的广泛视角，但现有的计算机视觉方法主要局限于提供分类标签或分割掩膜，限制了它们传达详细情况的能力。
### Innovation
我们提出了一种多模态系统——图像语言caption增强器(VLCE)，该系统能够生成综合且上下文相关的灾害图像解释。VLCE采用了双架构方法：一个基于预训练的ResNet50和EuroSat卫星图像的CNN-LSTM模型，以及一个基于预训练的UAV照片的Vision Transformer模型。两者都利用了ConceptNet和WordNet的外部语义知识以扩大词汇覆盖范围并提高描述准确性。
### Conclusion
我们的双架构系统在自动化生成来自卫星和无人机照片的行动性、信息密集型描述方面展示了显著的潜力。实验结果表明，VLCE在InfoMetIC方面的得分最高可达95.33%，同时保持了竞争力的语义对齐。
## 783. `cs.CV` - VideoJudge: 通过自助方法实现大语言模型作为裁判在视频理解中的可扩展监督 [PDF](https://arxiv.org/pdf/2509.21451), [HTML](https://arxiv.org/abs/2509.21451)
### Authors
Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj
### Background
精确评估视频理解模型仍然具有挑战性：常用的评估指标如BLEU, ROUGE, BERTScore难以捕捉人类判断的细微之处，而手动收集这些判断则成本高昂。尽管最近的研究探索了使用大型语言模型（LLMs）或跨模态大型语言模型（MLLMs）作为评估者，但其在视频理解领域的应用仍相对较少。研究者引入了VideoJudge，这是一种专门用于评估视频理解模型（即基于视频的文本响应）的3B和7B大小的MLLM评判者，通过一种生成器和评估者之间的交互训练机制进行训练。
### Innovation
VideoJudge使用大型语言模型作为评估者，特别设计用于评估视频理解模型的输出，且在三个Meta-evaluation基准测试中，7B大小的VideoJudge优于其他基准模型。研究还发现，跨模态的大语言模型评估者的表现优于单模态的语言模型评估者，且长链条推理并不一定能提高评估性能，表明提供视频输入对于视频理解任务的评估至关重要。
### Conclusion
研究通过引入VideoJudge，展示了通过一种特殊的训练方法可以实现对视频理解模型输出的精确评估。这种方法的引入不仅提高了评估准确性，还暗示了与视频相关的信息对于提高评估模型性能的重要性。
## 784. `cs.CV` - DyME：具备双层正交LoRA适配的动态多概念消除在扩散模型中 [PDF](https://arxiv.org/pdf/2509.21433), [HTML](https://arxiv.org/abs/2509.21433)
### Authors
Jiaqi Liu,Lan Zhang,Xiaoyong Yuan
### Background
文本到图像的扩散模型无意中复制了受版权保护的风格和视觉概念，引发了法律和伦理上的担忧。概念擦除作为一种保护方法，旨在通过微调选择性地抑制这些概念，但现有的方法无法在实际场景中大规模应用，尤其当提供者需要消除多个或可能互相冲突的概念时。现有方法的核心瓶颈在于它们依赖静态擦除：一个检查点被微调以移除所有目标概念，但这一固定设计与实际使用不符，因为每次生成时请求都不同，导致擦除成功率下降，非目标内容的保真度也降低。研究局限性包括单一的模型跨越多个概念的适应性不足，以及合并多个概念适配器时产生的干扰问题。尽管提出了基于轻量级、概念特定的LoRA适配器进行动态组合，但仍存在干扰问题，特别是在需要抑制多个或语义相关概念时。研究引入了一种双层正交约束，分别在特征和参数层面，以实现适配器子空间的解耦，并通过基于品牌系列角色的新梯形基准（ErasureBench-H），实现了不同语义粒度和擦除集大小下的可比性评估。
### Innovation
提出了DyME（Dynamic Multi-Concept Erasure），一种基于需求的擦除框架，它训练轻量级、概念特定的LoRA适配器，并在推理时动态组成所需适配器。DyME引入了双层正交约束，分别在特征和参数层面，以解决适配器合并时的干扰问题，特别是当需要同时抑制多个概念或语义相关概念时。通过ErasureBench-H基准测试，DyME在多概念擦除保真度方面明显优于现有最佳基线，并且在非目标内容的保真度损失方面最小化。
### Conclusion
实验证明，DyME在ErasureBench-H和标准数据集（例如CIFAR-100、Imagenette）中实现了更高水平的多概念擦除保真度，同时对非目标内容的保真度影响最小。
## 785. `cs.CV` - 无需对齐即可生成：在扩散模型中学习线性可分表示 [PDF](https://arxiv.org/pdf/2509.21565), [HTML](https://arxiv.org/abs/2509.21565)
### Authors
Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya
### Background
大型扩散模型的有效训练策略强调了改善这些模型中的区分性特征表示的重要性。这一方向的一个核心工作是通过强外部编码器获得的特征来进行表示对齐，这通过线性探测评估提高了表示质量。然而，基于对齐的方法依赖于大规模预训练编码器，这些编码器的获取成本很高。
### Innovation
提出了一个替代的训练正则化方法，基于促进中间层表示的线性可分性（Linear SEParability，LSEP）。LSEP消除了辅助编码器和表示对齐的需要，将线性探测直接融入网络的学习动态中，而不是将其作为简单的后验评估工具。这种方法在流式变换器架构（如SiTs）上显示了训练效率和生成质量的显著提高，Imagenet 256×256 数据集上的FID为1.46。
### Conclusion
实验结果表明，在扩散模型中学习线性可分表示可以显著提高训练效率和生成质量，无需依赖强大的预训练编码器进行对齐。
## 786. `cs.CV` - MS-YOLO:通过MobileNetV4和SlideLoss的边缘部署红外目标检测 [PDF](https://arxiv.org/pdf/2509.21696), [HTML](https://arxiv.org/abs/2509.21696)
### Authors
Jiali Zhang,Thomas S. White,Haoliang Zhang,Wenqing Hu,Donald C. Wunsch II,Jian Liu
### Background
红外成像在低光和恶劣天气条件下城市物体检测中显示出强大的解决方案，相比传统的可见光相机具有显著优势。然而，此类检测仍然面临类别不平衡、热噪声和计算限制等挑战，这些问题会显著影响模型的实际表现。
### Innovation
提出了MS-YOLO，结合使用MobileNetV4作为YOLOv8的主干网络，并引入了SlideLoss作为新型损失函数。MobileNetV4的使用降低了1.5%的计算开销，同时保持了高精度。SlideLoss动态强调未过多表示和被遮挡的样本，提高了精度而不牺牲召回率。
### Conclusion
MS-YOLO在FLIR ADAS V2基准测试中实现了具有竞争力的mAP和更高的精度，仅需6.7 GFLOPs的计算量。这表明MS-YOLO能够有效地满足基于高检测质量和低计算成本的双重需求，适合在城市边缘部署环境中的实时应用。
## 787. `cs.CV` - 在半变异图上发现难负例以增强地理定位的对比学习 [PDF](https://arxiv.org/pdf/2509.21573), [HTML](https://arxiv.org/abs/2509.21573)
### Authors
Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner
### Background
全球范围内基于图像的地理定位具有挑战性，因为存在多样化环境、视觉上模糊的场景以及许多地区缺乏显着地标。尽管对比学习方法通过在街景图像与其对应位置之间对齐特征显示出有希望的性能，但它们忽视了地理空间中的潜在空间依赖性。这导致它们无法解决错误的负例问题，即在视觉和地理上相似但被标记为负例的图像对，并且难以区分难以区分的负例，即视觉上相似但地理位置上距离远的图像对。
### Innovation
本文提出了一种新颖的空间正则化对比学习策略，该策略结合了半变异图，这是一种地质统计工具，用于建模空间相关性如何随距离变化。通过将图像在特征空间中的距离与其地理距离联系起来，可以捕捉到预期的视觉内容。使用拟合的半变异图，定义给定空间距离下的预期视觉差异性作为参考，以识别难负例和错误的负例。将此策略整合到GeoCLIP中，并在OSV5M数据集上进行评估，证明明确建模空间先验可以提高基于图像的地理定位性能，特别是在细粒度方面。
### Conclusion
研究结果表明，明确建模空间先验可以通过半变异图策略在OSV5M数据集上增强基于图像的地理定位表现，特别是在细节方面。
## 788. `cs.CV` - 利用语言模型研究沙特专业角色中的性别刻板印象：基于AI生成图像的分析 [PDF](https://arxiv.org/pdf/2509.21466), [HTML](https://arxiv.org/abs/2509.21466)
### Authors
Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa
### Background
该研究旨在探讨当前的文本转图像人工智能（AI）模型在生成沙特阿拉伯专业人员形象时是否延续了性别刻板印象和文化不准确的问题。研究人员分析了1,006张由ImageFX、DALL-E V3和Grok生成的图像，这些图像对应着56种不同的沙特职业，使用中立的提示进行生成。两名训练有素的沙特注释者从五个维度对每张图像进行了评估：感知性别、着装和外观、背景和设定、活动和互动、以及年龄。当两位主要评注者意见不一时，由第三位高级研究员进行裁决，最终产生了10,100个单独的判断。
### Innovation
研究创新之处在于，它具体分析了AI在生成专业形象时的性别和文化偏差，尤其关注了沙特的专业领域。这种方法为未来研究提供了新的视角，尤其是在功能性性别刻板印象和文化准确性方面。这项研究还采用了多层次的评估方法，确保了结果的准确性和可靠性，通过多方面的诠释提高了分析的全面性。
### Conclusion
研究结果表明，三种AI模型在生成专业形象时都存在明显的性别刻板印象，其中DALL-E V3的表现尤为突出。同时，模型生成的内容常常反映出文化误解，而不是真正的进步表现。目前AI模型展现出的社会偏见主要源于其训练数据中的社会偏见，这些数据由人类生成。研究强调了需要多样化、公平的算法和文化敏感的评估框架来确保生成的视觉输出更加公平和准确。
## 789. `cs.CV` - 运动感知Transformer在多目标跟踪中的应用 [PDF](https://arxiv.org/pdf/2509.21715), [HTML](https://arxiv.org/abs/2509.21715)
### Authors
Xu Yang,Gady Agam
### Background
视频中的多目标跟踪（MOT）因复杂的目标运动和拥挤的场景仍具有挑战性。尽管基于DETR的框架提供了端到端的解决方案，但它们通常在单一Transformer解码层中同时处理检测和跟踪查询，这会导致查询冲突，并降低关联准确性。
### Innovation
我们引入了运动感知Transformer（MATR），该模型显式预测目标在帧间的运动，提前更新跟踪查询，从而减少查询冲突，增强一致性训练，同时提高了检测和关联的准确性。
### Conclusion
MATR在DanceTrack、SportsMOT和BDD100k上的广泛实验证明了其在标准指标上的明显改进。在DanceTrack上，MATR在不使用额外数据的情况下，HOTA提高了超过9个百分点，并达到了新的最先进技术指标71.3，加上额外数据后；在SportsMOT和BDD100k上也能独立达到最先进的结果，分别在72.2（HOTA）和54.7（mTETA）、41.6（mHOTA）的指标上。这些结果表明，在端到端Transformer中明确建模运动提供了提高多目标跟踪简单而有效的途径。
## 790. `cs.CV` - X-CoT：基于LLM的链推理的可解释文本到视频检索 [PDF](https://arxiv.org/pdf/2509.21559), [HTML](https://arxiv.org/abs/2509.21559)
### Authors
Prasanna Reddy Pulakurthi,Jiamian Wang,Majid Rabbani,Sohail Dianat,Raghuveer Rao,Zhiqiang Tao
### Background
现有的文本到视频检索系统主要采用嵌入模型进行特征提取并通过计算余弦相似度进行排序。然而，这种设计存在两个局限性：低质量的文本-视频数据对会影响检索效果，但难以识别和评估；仅使用余弦相似度无法解释排名结果，限制了可解释性。文章提出了X-CoT，这是一个基于LLM的链推理的可解释检索框架，旨在解决这些问题。
### Innovation
首先扩展了现有的基准数据集，增加了额外的视频注释以支持语义理解并减少数据偏差。通过设计一对多的比较步骤，生成详细的推理并实现完整的排序。X-CoT在检索性能上取得了实证改进，并生成了详细的推理过程。它也有助于分析模型行为和数据质量。
### Conclusion
X-CoT 通过基于LLM的链推理，通过增加数据集的语义理解和减少数据偏差，以及生成详细的推理步骤，提高了检索性能和可解释性，并提供了模型行为分析和数据质量评估的能力。代码和数据可在提供的链接中访问。
## 791. `cs.CV` - LFA-Net: A Lightweight Network with LiteFusion Attention for Retinal Vessel Segmentation [PDF](https://arxiv.org/pdf/2509.21738), [HTML](https://arxiv.org/abs/2509.21738)
### Authors
Mehwish Mehmood,Ivor Spence,Muhammad Fahim
### Background
轻量级视网膜血管分割对于早期诊断视网膜威胁性疾病和全身性疾病非常重要，特别是在计算资源有限的现实临床环境中。现有基于深度学习的分割方法在小型视网膜血管分割和高计算成本方面仍面临挑战。
### Innovation
提出了一种新的血管分割网络LFA-Net，结合了LiteFusion-Attention注意力模块，该模块采用了残差学习链接、Vision Mamba设计的动力学和基于调制的注意力机制。LFA-Net具有0.11百万参数、0.42 MB内存大小和4.46 GFLOPs，使其非常适合资源受限的环境。
### Conclusion
LFA-Net在DRIVE、STARE和CHASE_DB上的Dice分数分别为83.28%、87.44%和84.50%，Jaccard指数分别为72.85%、79.31%和74.70%，验证了其卓越的性能。LFA-Net的代码已在线提供。
## 792. `cs.CV` - 使用视觉反馈的空间推理学习GUI接地 [PDF](https://arxiv.org/pdf/2509.21552), [HTML](https://arxiv.org/abs/2509.21552)
### Authors
Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim
### Background
传统的GUI接地通常被视为坐标的预测任务，给定自然语言指令生成屏幕上的坐标来进行鼠标点击或按键等操作。然而，近期的视觉语言模型在处理具有复杂布局的高分辨率GUI图像时，往往无法准确预测数字坐标。为解决该问题，本文重新构建了GUI接地为一个互动搜索任务，在该任务中，视觉语言模型生成将光标移动到GUI中的UI元素的操作。通过这种方式，可以利用渲染的光标提供可视反馈，帮助模型将其预测与相应的屏幕位置对齐。并利用多步在线强化学习及基于密集轨迹的奖励函数训练模型。实验结果显示，该模型在ScreenSpot-v2和ScreenSpot-Pro上的准确性有所提高，超越了现有最佳水平。
### Innovation
本文提出了一个基于视觉反馈的空间推理GUI接地模型，即GUI-Cursor。该模型将GUI接地重新构想为一个互动搜索任务，而不是传统的坐标预测任务。通过生成光标的移动操作定位UI元素，利用可视反馈机制迭代地调整预测，提高了模型的准确性。此外，利用多步骤在线强化学习和密集轨迹奖励函数训练模型，促进了算法的学习效率和灵活性。并且模型在解决复杂问题时能够自我调整执行更多的步骤，展示了其强大适应能力。
### Conclusion
本文提出的GUI-Cursor模型通过互动搜索路径和利用视觉反馈增强空间推理能力，显著提升了GUI接地的准确性，达到了现有最先进水平。在ScreenSpot-v2和ScreenSpot-Pro测试集上的性能达到了新的创新高。
## 793. `cs.CV` - 融入场景上下文和语义标签以提高群体情绪识别的性能 [PDF](https://arxiv.org/pdf/2509.21747), [HTML](https://arxiv.org/abs/2509.21747)
### Authors
Qing Zhu,Wangdong Guo,Qirong Mao,Xiaohua Huang,Xiuyan Shao,Wenming Zheng
### Background
群体级情绪识别（GER）旨在识别场景中多个个体的整体情绪。当前的方法低估了视觉场景上下文信息对于建模个体关系的重要性，同时忽略了情感标签中的语义信息对于完全理解情绪的关键作用。
### Innovation
提出了一种新颖的框架，该框架结合了视觉场景上下文和标签引导的语义信息，以提高GER性能。该框架包括利用多尺度场景信息来多样化编码个体关系的视觉上下文编码模块，以及利用群体级情绪标签来引导大型语言模型生成精细情绪词库的情绪语义编码模块。这些词汇表与情绪标签结合，通过结构化的感情树进一步细化为综合语义表示。最后，提出了相似性意识交互以对齐和整合视觉和语义信息，从而生成增强的群体级情绪表示，进而提高GER的性能。
### Conclusion
在三个广泛采用的GER数据集上的实验表明，所提出的方法在性能上与最先进的方法具有竞争力。
## 794. `cs.CV` - X-Streamer：结合视听交互的一体化人类世界建模 [PDF](https://arxiv.org/pdf/2509.21574), [HTML](https://arxiv.org/abs/2509.21574)
### Authors
You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Guoxian Song,Xiaochen Zhao,Chao Liang,Jianwen Jiang,Hongyi Xu,Linjie Luo
### Background
当前，数字人类代理需要能够进行无限交互，这些交互跨越文本、语音和视频等多个模态。现有的系统一般局限于单一或少数模态，无法提供全面的互动体验。本文旨在提供一个端到端的多模态人类世界建模框架，能够构建能够跨模态无限交互的数字人类代理，从而提供更加自然、丰富的互动体验。该框架基于单张肖像，能够实时驱动基于流式多模态输入的开放视频通话。
### Innovation
本文提出了一种名为X-Streamer的框架，结合了‘思考者-演员’双重变压器架构，实现多模态的理解和生成。‘思考者’能够感知并根据流式用户输入进行推理，而‘演员’则将这些隐藏状态实时转换为同步的多模态流。‘思考者’使用预训练的大型语言-语音模型，而‘演员’则使用基于块的自回归扩散模型。为了确保长期稳定的交互，设计了跨块和内块注意机制以及时间对齐的多模态位置嵌入，进一步通过块级扩散强迫和全局身份参考来增强。X-Streamer能够在两块A100 GPU上实现实时运行，从而实现从任意肖像开始的长时间一致的视频聊天体验。
### Conclusion
X-Streamer框架提供了一种基于单张肖像的解决方案，能够实现开放式视频通话，并且能在多个GPU上实现实时运行，为跨模态交互的数字人类代理建模提供了一种新的可能。该框架为未来统一的交互式数字人类建模奠定了基础。
## 795. `cs.CV` - CubistMerge: 为多样化ViT主干网络保留空间结构的令牌合并方法 [PDF](https://arxiv.org/pdf/2509.21764), [HTML](https://arxiv.org/abs/2509.21764)
### Authors
Wenyi Gong,Mieszko Lis
### Background
许多现代ViT主干网络采用了基于空间的架构设计，如窗口注意、SAM中的分解相对位置嵌入以及DINOv3中的RoPE。这些架构对令牌减少提出了新的挑战，因为现有方法大多无法保留这些架构依赖的空间结构。本文介绍了一种简单有效的令牌合并方法，能够保留空间完整性，使模型能够无缝兼容基于空间的架构。
### Innovation
论文提出了一种方法，通过对偶满足两个看似矛盾的要求来维护空间结构：（i）利用空间布局中的非均匀信息分布，（ii）合并后保持空间结构。具体创新点包括：（i）采用二维减少策略确保结构化的令牌布局，（ii）空间感知合并算法保持令牌的相对位置，（iii）引入新的维度最大幅度令牌表示法以保留显著特征。
### Conclusion
该方法在多种视觉任务中表现出强大的性能，无论是直接使用还是微调，都能达到最先进结果。具体来说，在COCO上直接使用SAM-H时，CubistMerge实现了1.25倍的速度提升，仅0.7%的mIOU下降，而在ImageNet上仅在一个微调周期内实现了1.15倍的速度提升，且无top-1准确率下降。
## 796. `cs.CV` - Prompt-guided Representation Disentanglement for Action Recognition [PDF](https://arxiv.org/pdf/2509.21783), [HTML](https://arxiv.org/abs/2509.21783)
### Authors
Tianci Wu,Guangming Zhu,Jiang Lu,Siyuan Wang,Ning Wang,Nuoye Xiong,Zhang Liang
### Background
动作识别是视频理解中的一个基本任务。现有方法通常提取统一特征来处理视频中的所有动作，这使得在多动作场景中建模不同物体之间的交互变得具有挑战性。
### Innovation
本文提出了一种面向动作识别的提示引导解耦表示框架（ProDA），该框架利用时空场景图（SSGs）并引入动态提示模块（DPM），指导图解析神经网络（GPNN）生成动作特定的表示。同时设计了视频适应的GPNN，使用动态权重聚合信息，以实现从复杂场景中分离出任何指定动作的目标。
### Conclusion
实验结果表明，与现有最佳方法相比，我们的方法在视频动作识别中具有有效性。
## 797. `cs.CV` - 基于集成表示度量的数据驱动的视觉模型分类 [PDF](https://arxiv.org/pdf/2509.21628), [HTML](https://arxiv.org/abs/2509.21628)
### Authors
Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla
### Background
大型视觉模型在架构和训练范式上存在巨大差异，但目前缺乏系统的方法来确定这些模型表示中哪些方面是共通的，哪些是独特的计算策略的体现。本文利用一系列表示相似度度量，评估各模型族之间的差异性，从而揭示不同视觉模型的内在特征差异与共性，并引入了对生物学启发框架的研究，旨在为视觉模型提供一个系统化的分类方法，以理解和区分基于模型结构和训练目标形成的计算策略对表示结构的影响。
### Innovation
本文创新性地利用了一系列表示相似度度量方法来评估不同视觉模型族之间的差异性，并提出了一种融合相似网络融合（SNF）的方法，该方法能够显著提高模型族之间的区分度，生成稳健的综合特征图。此外，通过将这种生物学启发的方法应用于模型分类，揭示了传统监督型ResNet和Transformer模型（ViT）与自监督模型的不同聚类现象，以及混杂架构的聚类与掩码自编码器之间的相似性关系，表明了架构现代化与重建训练之间的可能联系。
### Conclusion
融合的相似矩阵聚类揭示了预期和意想不到的模式：监督型ResNets和ViTs形成不同的簇，但所有自监督模型跨越不同架构边界组成了同一个簇。混杂架构（ConvNeXt, Swin）与掩码自编码器聚类在一起，表明了架构现代化与基于重建的训练之间的潜在趋同。这种方法为视觉模型提供了一个原理性的分类，展示出共同形成的计算策略（由架构和训练目标共同塑造）超出了表面设计范畴，对理解视觉模型的结构具有重要意义。
## 798. `cs.CV` - MORPH：形状无关的偏微分方程基础模型 [PDF](https://arxiv.org/pdf/2509.21670), [HTML](https://arxiv.org/abs/2509.21670)
### Authors
Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence
### Background
本文介绍了MORPH，这是一种不受形状限制的自回归基础模型，用于处理偏微分方程（PDEs）。MORPH建立在一个卷积视觉变换器的骨干网络之上，能够无缝处理不同维度（1D-3D）和分辨率的异质时空数据集，同时还可以处理具有混合标量和矢量分量的不同物理场。该架构结合了部件级卷积、领域间交叉注意力和轴向注意力等技术，旨在提高计算效率并保留表现力。通过对多种多样的异质PDE数据集进行预训练，并在各类下游预测任务上进行评估，MORPH展示了其在零样本和全样本泛化上的优越性能。具体来说，该模型适用于科学观察中的复杂、异构和多模态数据学习任务，为可扩展且数据效率高的科学机器学习开辟了道路。
### Innovation
MORPH模型创新地结合了部件级卷积、领域间交叉注意力和轴向注意力，用于处理不同维度和分辨率的异质时空数据，特别适用于具有混合标量和矢量分量的不同物理场。通过预训练和应用全模型微调或参数高效的低秩适配器（LoRA），MORPH在零样本和全样本泛化性能上都超过了从头开始训练的模型，并且在广泛的评估中能够匹配或超越强有力的基线和最新的最佳模型。
### Conclusion
MORPH展示了一种灵活且强大的基础架构，能够学习科学观察中的复杂、异构和多模态数据，为开发可扩展且数据高效的科学机器学习方案铺平了道路。
## 799. `cs.CV` - FantasyWorld：通过统一的视频和3D预测实现几何一致的世界建模 [PDF](https://arxiv.org/pdf/2509.21657), [HTML](https://arxiv.org/abs/2509.21657)
### Authors
Yixiang Dai,Fan Jiang,Chiyu Wang,Mu Xu,Yonggang Qi
### Background
高保真的3D世界模型对于体现人工智能和通用人工智能（AGI）至关重要，支撑着如AR/VR内容创作和机器人导航等一系列应用。尽管视频基础模型有强大的先验想象力，但当前的视频基础模型缺乏明确的3D定位能力，因此在空间一致性和其对下游3D推理任务的应用方面都受到了限制。
### Innovation
提出了FantasyWorld，这是一种几何增强框架，将冻结的视频基础模型与可训练的几何分支结合起来，使其可以在单一前向传递中同时建模视频隐变量和隐含的3D场。这种方法引入了跨分支监督，其中几何提示引导视频生成，视频先验规整3D预测，从而产生一致且可泛化的3D感知的视频表示。此外，几何分支的输出潜在地可以作为下游3D任务（如新视角合成和导航）的通用表示，而无需针对每个场景进行优化或微调。实验表明，FantasyWorld有效地弥合了视频想象和3D感知之间的差距，比最近的几何一致基线在多视角连贯性和样式一致性方面表现更好。进一步的消融实验进一步确认了这些收益源自统一的骨干和跨分支信息交换。
### Conclusion
FantasyWorld有效地将视频想象和3D感知联系起来，优于近期的几何一致基线。其统一的骨干和跨分支信息交换从机制上解释了其在多视图连贯性和风格一致性方面的优越性能。它为下游的3D任务提供了灵活的表示，无需针对特定场景进行优化或微调。
## 800. `cs.CV` - DeLiVR: 梯度时空偏差用于高效视频去雨 [PDF](https://arxiv.org/pdf/2509.21719), [HTML](https://arxiv.org/abs/2509.21719)
### Authors
Shuning Sun,Jialang Lu,Xiang Chen,Jichao Wang,Dianjie Lu,Guijuan Zhang,Guangwei Gao,Zhuoran Zheng
### Background
野外拍摄的视频往往受到雨水、模糊和噪声的影响。此外，即使是轻微的相机姿态变化也会放大跨帧不匹配和时间上的伪影。现有方法依赖于光学流或启发式对齐，这既耗费计算资源又不够 robust。
### Innovation
本文提出了DeLiVR，一种高效的视频去雨方法，通过直接将时空梯度偏差注入网络的注意力分数中来解决现有方法的计算成本高、鲁棒性差的问题。该方法通过旋转约束的Lie相对偏差预测每个帧的平面角度，并通过基坐标和归一化坐标比较实现几何一致的对齐，然后再进行特征聚合。此外，该方法还通过相邻帧的角差异计算来估计速度，进行偏置计算，结合了时域衰减和注意力掩码，聚焦于帧间关系同时精确匹配雨迹方向。
### Conclusion
全面的实验结果表明，该方法在公开基准数据集上是有效的。
## 801. `cs.CV` - MIRG-RL: 使用强化学习实现多图像推理与定位 [PDF](https://arxiv.org/pdf/2509.21788), [HTML](https://arxiv.org/abs/2509.21788)
### Authors
Lihao Zheng,Jiawei Chen,Xintian Shen,Hao Ma,Tao Wei
### Background
多图像推理和定位需要理解复杂的跨图像关系，包括对象级别和图像级别。当前大规模视觉语言模型（LVLMs）面临两个关键挑战：缺乏跨图像推理能力和跨图像参考奖励建模不足。
### Innovation
提出了一种统一框架——使用强化学习进行多图像推理与定位（MIRG-RL）。具体而言，本研究采用两阶段训练范式，结合有监督微调和带有注释轨迹的图像感知强化学习优化，逐步培养多图像推理能力。此外，创新提出了构造轨迹数据的方法，将对象级别和图像级别注释信息结合，以此生成轻量级推理增强数据集。
### Conclusion
实验表明，MIRG-RL 在多图像定位基准测试中达到了最先进的性能，在跨图像推理任务中达到了 64.82% 的准确率，超越了之前的最佳方法 1%。代码和数据集已发布。
## 802. `cs.CV` - LongScape: 通过上下文感知MoE推动长时程具身世界模型 [PDF](https://arxiv.org/pdf/2509.21790), [HTML](https://arxiv.org/abs/2509.21790)
### Authors
Yu Shang,Lei Jin,Yiding Ma,Xin Zhang,Chen Gao,Wei Wu,Yong Li
### Background
基于视频的具身模型在生成高质量的具身操作数据方面具有重要的潜力，但当前的视频生成方法在实现长期稳定的生成方面仍存在挑战。经典的时间扩散方法在多个迭代过程中常常出现时间不一致性和视觉漂移，而自回归方法则会牺牲细节的视觉质量。
### Innovation
该研究提出了LongScape，一种混合框架，结合了内块时间扩散去噪和跨块自回归因果生成。核心创新在于一种由动作引导并且具有可变长度的块划分机制，根据机器人的动作语义上下文来切割视频片段，确保每个块都代表一个完整的、连贯的动作，从而使得模型可以灵活生成多样化的动态。此外，引入了一种上下文感知混合专家（CMoE）框架，在生成过程中根据每个块的需求动态激活专用于该块的专家，以保证高质量的视觉效果和顺畅的块过渡。
### Conclusion
大量的实验结果表明，该方法能够在长时间跨度上实现稳定和一致的生成。团队的代码已经在如下网址公开：this https URL
## 803. `cs.CV` - SAR图像领域基础模型现状研究 [PDF](https://arxiv.org/pdf/2509.21722), [HTML](https://arxiv.org/abs/2509.21722)
### Authors
Nathan Inkawhich
### Background
本文研究基础人工智能/机器学习模型在合成孔径雷达（SAR）目标识别任务中的适用性。基础模型在自然图像领域取得了巨大进展，尤其是前沿实验室使用超大规模数据集和巨额计算预算训练超大规模模型。这些模型通常通过半监督学习进行训练，能够通过少量标注数据进行下游任务适应，具有更强的分布泛化能力和即插即用的特征转移性。作者受此启发，将这些技术应用于SAR领域。然而，实验表明，这些模型在未经过适配的情况下，难以从SAR数据中提取具有语义相关区别的目标特征。因此，本文探讨了利用半监督学习方法对公开的基础模型进行微调，并在SAR领域取得了新的性能突破，显著优于现有的SAR领域模型SARATR-X。此外，研究分析了使用不同骨干网络和不同的下游任务适配策略之间的性能权衡，监测了模型在真实场景中的适应能力。尽管取得了一定成果，但仍有较长的路要走以进一步改进SAR基础模型的性能。
### Innovation
本文证明了通过半监督学习方法对公开的基础模型进行微调是可以有效应用于SAR领域的路径。作者使用AFRL-DINOv2模型，在SAR物体识别任务上取得了新的性能状态，显著优于现有顶级SAR模型SARATR-X。此外，研究还分析了不同骨干网络和下游任务适配策略之间的性能权衡，并监测了模型在极端条件和少量标注数据环境中的适应能力。
### Conclusion
本文旨在为SAR基础模型的开发者提供指导和灵感，尽管已经取得了一些积极的结果，但未来的工作仍然需要进一步优化基础模型在SAR领域的性能以应对更复杂的任务环境。
## 804. `cs.CV` - UISim：动态移动环境中的交互式图像基UI模拟器 [PDF](https://arxiv.org/pdf/2509.21733), [HTML](https://arxiv.org/abs/2509.21733)
### Authors
Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen
### Background
开发和测试用户界面（UI）以及训练AI代理与这些界面交互都非常具有挑战性，因为现实世界的移动环境是动态且多变的。现有方法通常依赖于笨重的物理设备或仅对屏幕截图进行有限的静态分析，这妨碍了大规模测试和智能UI代理的发展。
### Innovation
我们引入了UISim，这是一种基于图像的UI模拟器，提供了一个完全基于屏幕图像的动态且交互式的移动电话环境探索平台。系统采用两阶段方法：给定初始屏幕图像和用户动作，首先预测下一个UI状态的抽象布局，然后基于此预测布局合成一个新的、视觉一致的图像。这种做法能够真实地模拟UI过渡。UISim提供了UI测试、快速原型制作和合成数据生成的即时实用益处，其交互功能还为高级应用铺平了道路，如为AI代理规划UI导航任务。实验结果表明，UISim在生成具有现实性和连贯性的后续UI状态方面优于端到端的UI生成基准线，展示了其精度以及对UI开发流程和AI代理训练的简化潜力。
### Conclusion
UISim在生成现实且连贯的UI状态方面表现优异，展示了其高度的真实性，为UI开发和AI代理训练带来了简化和改进的机会。
## 805. `cs.CV` - DeHate: 基于稳定扩散的多模态方法以减轻图像中的仇恨言论 [PDF](https://arxiv.org/pdf/2509.21787), [HTML](https://arxiv.org/abs/2509.21787)
### Authors
Dwip Dalal,Gautam Vashishtha,Anku Ranui,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal
### Background
有害的网络内容的增加不仅扭曲了公共言论，而且对维护健康的数字环境构成了重大挑战。针对这一问题，本文介绍了一个专为识别数字内容中的仇恨言论设计的多模态数据集。
### Innovation
本文的核心创新在于将水印增强的稳定扩散技术与数字注意力分析模块（DAAM）结合使用，用于检测图像中的仇恨元素并生成详细的仇恨注意力图，进而从图像中模糊这些区域，移除仇恨部分。此外，本文还描述了多模态脱恨任务的详细信息，并展示了专门用于多模态脱恨任务的DeHater视觉-语言模型。
### Conclusion
本文的方法在利用文本提示进行AI驱动的图像仇恨检测方面树立了一个新的标准，为社交媒体中的更具伦理的AI应用程序的发展做出了贡献。
## 806. `cs.CV` - KG-SAM: 通过条件随机场注入解剖知识的Segment Anything Model [PDF](https://arxiv.org/pdf/2509.21750), [HTML](https://arxiv.org/abs/2509.21750)
### Authors
Yu Li,Da Chang,Xi Xiao
### Background
虽然Segment Anything Model (SAM) 在图像分割领域取得了显著的成功，但在应用于医学影像时仍受到根本挑战的阻碍，包括边界不清晰、解剖关系建模不充分以及缺乏不确定性量化。这些限制限制了SAM在医学影像分割中的直接应用效果和发展潜力。
### Innovation
为了解决这些问题，作者提出了KG-SAM，这是一种知识指导的框架，它将解剖先验知识与边界细化和不确定性评估相结合。具体来说，KG-SAM 包含(i) 一个医学知识图谱以编码精细的解剖关系、(ii) 一个基于能量的条件随机场(CRF)以确保预测的一致性，并且(iii) 一个不确定性意识融合模块以在临床高风险场景中增强可靠性。通过在多中心医疗数据集中的广泛实验验证了KG-SAM的有效性，在前列腺分割的Dice分数为82.69%，腹部分割方面取得了显著提高，MRI的数据为78.05%，CT的数据为79.68%。这些结果确立了KG-SAM 作为改进医学影像分割的稳健和通用框架的地位。
### Conclusion
KG-SAM 显示出了在医学影像分割中的高效性和可靠性，通过整合解剖先验知识、一致性预测和不确定性评估，有效提升了图像分割的精确性和临床应用的可靠性。
## 807. `cs.CV` - Deepfakes: 我们需要重新思考“真实”图像的概念 [PDF](https://arxiv.org/pdf/2509.21864), [HTML](https://arxiv.org/abs/2509.21864)
### Authors
Janis Keuper,Margret Keuper
### Background
现代图像生成模型的广泛可用性和较低的使用门槛引发了关于犯罪行为和负面社会影响的合理担忧。对此，机器学习社区提出了大量的文章，提出算法方案来检测“假”图片。虽然技术上有一定的进展，但当前的研究更多地聚焦于生成算法和“假”数据样本，而忽视了对“真实”图片的清晰定义和数据收集。
### Innovation
本文提出，随着智能手机的普及以及图像生成算法的发展，获取“真实”图像的方法已经发生了根本性的变化。因为这些图像生成算法与“假”图像生成器有着密切的关联，因此需要重新定义“真实”图像的概念。为此，论文呼吁对“真实”图像的检测目标进行反思，并指出需要明确的技术定义和新的基准数据集。
### Conclusion
本文旨在提高对该研究领域当前不足的意识，并触发有关“假”图像检测是否是一个正当目标的开放讨论。至少，我们需要对“真实”图像有一个清晰的技术定义和新的基准数据集。
## 808. `cs.CV` - 解锁美之本质：基于相对-绝对策略优化的高级审美推理 [PDF](https://arxiv.org/pdf/2509.21871), [HTML](https://arxiv.org/abs/2509.21871)
### Authors
Boyang Liu,Yifan Hu,Senjie Jin,Shihan Dou,Gonglei Shi,Jie Shao,Tao Gui,Xuanjing Huang
### Background
多模态大型语言模型（MLLMs）非常适合图像美学评估，因为它们可以通过跨模态理解能力捕捉高级美学特征。然而，缺乏多模态美学推理数据和美学判断的主观性使得MLLMs难以生成具有可解释合理性的准确美学判断。因此，本文提出了一种综合美学推理框架Aes-R1，结合强化学习（RL）来解决这一问题。
### Innovation
该文创新性地提议了Aes-R1框架，包含了一个用于启动的美学推理管道AesCoT，并通过Relative-Absolute Policy Optimization (RAPO)这一新型RL算法，联合优化绝对分数回归和相对排名顺序。Aes-R1可以使得MLLMs在具有统一框架下生成准确的分数和可信的解释，从而提升了美学评分和推理。实验结果表明Aes-R1在平均PLCC/SRCC上提高了47.9%/34.8%，优于相似规模的最新基准。
### Conclusion
Aes-R1框架通过结合RAPO算法和美学推理管道，提高了MLLMs在美学评分与推理中的表现，特别是在准确性及跨图像偏好判断方面。在有限监督和未接触数据场景下，Aes-R1展示出较强的一般泛化能力。
## 809. `cs.CV` - 无监督图推理驱动的多模态深伪检测 [PDF](https://arxiv.org/pdf/2509.21774), [HTML](https://arxiv.org/abs/2509.21774)
### Authors
Yuxin Liu,Fei Wang,Kun Li,Yiqi Nie,Junjie Chen,Yanyan Wei,Zhangling Duan,Zhaohong Jia
### Background
多模态伪内容检测（MDD）旨在揭露视觉、文本和音频等多种模态中的操纵行为，增强现代信息系统的信息可靠性。尽管大型视觉-语言模型（LVLM）展示了强大的多模态推理能力，但在MDD中的有效性受到探测细微伪造线索、解决跨模态不一致性和执行任务对齐检索的挑战限制。
### Innovation
提出了一种无需训练的MDD框架——引导自适应评分和上下文学习（GASP-ICL），采用了一种管道来保持语义相关性的同时，在LVLM中注入任务感知的知识。利用MDD适配特征提取器检索对齐的图像-文本配对并构建候选集，并设计了图结构泰勒自适应评分器（GSTAS）捕获跨样本关系，传播查询对齐信号，生成有区别的范例，从而实现了精确的选择语义对齐、任务相关性的演示，增强LVLM以实现稳健的MDD。
### Conclusion
实验表明，在四种伪造类型的处理上，GASP-ICL超越了强大的基线模型，实现了稳健的MDD，且未进行LVLM微调。
## 810. `cs.CV` - UniVid: 使用预训练视频生成模型统一视觉任务 [PDF](https://arxiv.org/pdf/2509.21760), [HTML](https://arxiv.org/abs/2509.21760)
### Authors
Lan Chen,Yuchao Gu,Qi Mao
### Background
大型语言模型经过大量语料库训练，能够在单一生成框架中统一多种语言任务。最近的研究，如大型视觉模型(LVM)，将这种模式扩展到视觉领域，通过将任务组织成视觉句子序列来进行建模，其中视觉提示作为上下文来引导输出。然而，这种方法需要在不同模态和源之间进行特定任务的预训练，这既昂贵又限制了对未见过任务的扩展性。鉴于预训练的视频生成模型能够捕捉时间序列依赖关系，因此提议探索一个更具统一性和扩展性的替代方案：预训练的视频生成模型是否能够适应多样化的图像和视频任务？
### Innovation
提出了UniVid框架，该框架通过微调视频扩散变换器来处理各种视觉任务，而不进行特定任务的修改。任务被表示为视觉句子，上下文序列定义了任务和预期输出的模态。从两个角度评估了UniVid的泛化能力：（1）跨模态推理，上下文中包含图像和视频的混合；（2）从自然数据到标注数据的跨来源任务，无需多源预训练。尽管仅在自然视频数据上进行训练，UniVid在两种设置中都能很好地泛化。此外，理解与生成任务可以在模式中通过反转视觉句子顺序来进行切换。这些发现指出预训练的视频生成模型可以作为视觉建模的扩展性且统一的基础。
### Conclusion
UniVid框架展示了预训练视频生成模型在统一和扩展视觉任务方面的潜力。这些发现强调了预训练视频生成模型作为视觉建模的统一和扩展性基础的重要性。代码将在此链接中发布：this https URL。
## 811. `cs.CV` - SRHand: Through 视觉/姿态感知的神经图像表示和显式3D网格，实现手部图像和3D形状的超分辨率 [PDF](https://arxiv.org/pdf/2509.21859), [HTML](https://arxiv.org/abs/2509.21859)
### Authors
Minje Kim,Tae-Kyun Kim
### Background
重建详细的虚拟手模型在多种应用中扮演了重要角色。尽管此前的工作重点在于捕捉高保真手部几何形状，但这些方法依赖于高分辨率多视角图像输入，并且难以应用于低分辨率图像。多视角图像超分辨率方法被提出以确保三维视角一致性，但这些方法仅限于静态的、分辨率固定的物体或场景，不适用于关节可变形的手部。
### Innovation
SRHand 提出了一个名为几何感知隐式图像函数 (GIIF) 的方法，通过放大粗糙输入图像来学习手部的详细先验信息。通过联合优化隐式图像函数和显式3D手部形状，SRHand 保持了放大后的手部图像中的多视角和姿态一致性，并实现了精细的手部三维重建（包括皱纹和指甲）。
### Conclusion
在使用 InterHand2.6M 和 Goliath 数据集的实验中，SRHand 在定量和定性上均显著优于针对手部数据集适配的现有图像超分辨率方法以及三维手部重建方法。
## 812. `cs.CV` - TDEdit: 一种用于文字拖拽指导图像操作的统一扩散框架 [PDF](https://arxiv.org/pdf/2509.21905), [HTML](https://arxiv.org/abs/2509.21905)
### Authors
Qihang Wang,Yaxiong Wang,Lechao Cheng,Zhun Zhong
### Background
近年来，基于文本和拖拽的图像编辑方法取得了显著进展，但它们存在互补的局限性：基于文本的方法擅长纹理操作，但在空间控制上不够精确；而基于拖拽的方法主要修改形状和结构，缺乏精细的纹理指导。
### Innovation
本文提出了一个统一的扩散框架，结合了基于文本和拖拽编辑的优势，引入了两项关键创新：(1) 点云确定性拖拽，通过3D特征映射增强潜在空间布局控制；(2) 拖拽-文本导向去噪，在去噪过程中动态平衡拖拽和文本条件的影响。该模型支持文本仅模式、拖拽仅模式或联合模式的灵活编辑模式，并在各种设置下保持强大的性能。
### Conclusion
大量定量和定性实验表明，本文的方法不仅实现了高保真的联合编辑，还在所有设置下与专门的文本仅或拖拽仅方法相当或超越其性能，建立了可控图像操作的多功能和可扩展解决方案。所有结果的代码将公开以重现本文中的结果。
## 813. `cs.CV` - LG-CD：通过SAM2适应改进的基于语言的变更检测 [PDF](https://arxiv.org/pdf/2509.21894), [HTML](https://arxiv.org/abs/2509.21894)
### Authors
Yixiao Liu(1),Yizhou Yang(1),Jinwen Li(2),Jun Tao(1),Ruoyu Li(1),Xiangkun Wang(1),Min Zhu(1),Junlong Cheng(1) ((1) College of Computer Science, Sichuan University, China, (2) School of Computer Science and Technology, Xinjiang University, China)
### Background
传统的遥感变更检测（RSCD）通常依赖于分析多时相图像来识别地表覆盖或表面条件的变化。目前，大多数基于深度学习的方法主要集中在学习单一模式的视觉信息上，而忽视了文本等多模态数据提供的丰富的语义信息。
### Innovation
提出了一种新的基于语言引导的变更检测模型（LG-CD），该模型利用自然语言提示指导网络关注感兴趣的区域，显著提高了变更检测的准确性和鲁棒性。具体而言，LG-CD使用视觉基础模型（SAM2）作为特征提取器，从高分辨率到低分辨率提取双时相遥感图像的多尺度金字塔特征。设计了文本融合注意力模块（TFAM），将视觉和文本信息对齐，并通过文本提示聚焦于目标变更区域。此外，实现了一种视觉语义融合解码器（V-SFD），通过交叉注意机制深度整合视觉和语义信息，生成高度准确的变更检测掩码。
### Conclusion
在三个数据集（LEVIR-CD、WHU-CD和SYSU-CD）上进行的实验表明，LG-CD在变更检测方面始终优于最先进的方法。此外，我们的方法通过利用多模态信息提供了实现通用变更检测的新见解。
## 814. `cs.CV` - 用 Vector Field Rectification with Sample Deviation 和 Structure-and-Motion-Preserving Initialization 使基于流的方法惠及创意视频编辑 [PDF](https://arxiv.org/pdf/2509.21917), [HTML](https://arxiv.org/abs/2509.21917)
### Authors
Xianghao Kong,Hansheng Chen,Yuwei Guo,Lvmin Zhang,Gordon Wetzstein,Maneesh Agrawala,Anyi Rao
### Background
尽管图像编辑技术已经有了很大的进步，但视频编辑仍然是一个新兴的挑战。现有的大多数基于图像条件的视频编辑方法要么需要特定模型的设计来倒置，要么需要大量的优化，限制了它们利用最新的图像到视频（I2V）模型的能力，将图像编辑模型的编辑能力转移到视频领域。
### Innovation
我们提出了一个无需模型特定设计（Inversion-Free）的方法 IF-V2V，它可以无需大量计算开销地使用现成的基于流匹配的 I2V 模型进行视频编辑。我们设计了一种 Vector Field Rectification with Sample Deviation 方法，通过引入偏离项到去噪向量场中，将源视频的信息整合到去噪过程中，从而绕过了模型倒置的需求。为了在不牺牲编辑质量的情况下确保与源视频的一致性，我们引入了一种 Structure-and-Motion-Preserving Initialization 方法，用于生成具有结构信息嵌入的运动感知的时间相关噪声。此外，我们还提出了一种 Deviation Caching 机制，以将去噪矢量校正的额外计算成本降到最低，而不显著影响编辑质量。
### Conclusion
我们在评估中表明，我们的方法实现了优于现有方法的编辑质量与一致性，提供了一个轻量级的即插即用解决方案，以实现视觉创意。
## 815. `cs.CV` - DiTraj：视频扩散变换器的无训练框架轨迹控制 [PDF](https://arxiv.org/pdf/2509.21839), [HTML](https://arxiv.org/abs/2509.21839)
### Authors
Cheng Lei,Jiayu Zhang,Yue Ma,Xinyu Wang,Long Chen,Liang Tang,Yiqiang Yan,Fei Su,Zhicheng Zhao
### Background
现有的文本到视频生成模型在轨迹控制方面存在两个主要问题：需要大量的训练资源或专门针对U-Net，未能充分利用扩散变换器（DiT）的优点。扩散变换器展示了强大的生成能力，但是在可控视频生成领域，轨迹控制作为一个用户友好的任务，仍然面临着挑战和限制。
### Innovation
本文提出了DiTraj，一个基于扩散变换器（DiT）的简单有效的无训练框架，用于文本到视频生成中的轨迹控制。具体来说，DiTraj通过前景-背景分离指导，使用大型语言模型将用户提供的提示转换为前景和背景提示，分别引导视频中前景和背景区域的生成。同时，DiTraj引入了基于3D注意力的跨帧时空分解的3D-RoPE方法，通过调整位置嵌入的密度实现3D知晓的轨迹控制，从而增强了跨帧注意力，改善了轨迹控制的能力。
### Conclusion
大量实验表明，DiTraj方法在视频质量和轨迹可控性方面均优于现有的方法。
## 816. `cs.CV` - 动态高动态范围新视角合成 [PDF](https://arxiv.org/pdf/2509.21853), [HTML](https://arxiv.org/abs/2509.21853)
### Authors
Kaixuan Zhang,Zhipeng Xiong,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu
### Background
当前方法主要关注静态场景，假设所有场景元素都保持静止和非动态状态。然而，实际情况中经常会出现动态元素，如移动的物体、变化的光照条件和其他时间事件，这给新视角合成带来了更大的挑战。本文旨在填补这一空白，提出了一个更现实的问题，即HDR 动态新视角合成（HDR DNVS），强调需要联合建模时间辐射强度变化和LDR与HDR间的复杂3D变换。
### Innovation
提出了一种基于高斯点绘制的HDR-4DGS架构，并引入了一个创新的动态调色模块，用于明确连接HDR和LDR领域，通过动态调整调色函数，以适应随时间维度变化的辐射强度分布，从而确保时间辐射强度的一致性和空间色彩变换的准确性，实现任意视角和时间实例下的拟真实HDR渲染。
### Conclusion
实验结果表明，HDR-4DGS在定性和定量性能上都超越了现有最先进的方法，实现了从任意角度和时间点生成高真实感的HDR渲染。源代码将公开发布。
## 817. `cs.CV` - PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning [PDF](https://arxiv.org/pdf/2509.21926), [HTML](https://arxiv.org/abs/2509.21926)
### Authors
Jiahao Zhang,Bowen Wang,Hong Liu,Yuta Nakashima,Hajime Nagahara
### Background
VICL使用输入-输出图像对作为提示，用于指导模型在不同的视觉任务中进行操作。然而，VICL常常依赖于单个输入-输出图像对，这可能导致预测结果偏差大且不稳定。
### Innovation
PANICL提出了一种无需训练的一般框架，通过利用多个输入-输出图像对来缓解这一问题。PANICL通过在多个图像对之间平滑分配分数来减少偏差，从而提高了模型的稳定性和准确性。
### Conclusion
PANICL在多个任务上展示了相对于强大基线的一致改进，并且在领域迁移上表现出强大的稳健性，同时它可以与其他VICL模型很好地泛化，表明其多功能性和广泛的实用性。
## 818. `cs.CV` - 基于Transformer的问答模型和RAG增强设计的全面评估 [PDF](https://arxiv.org/pdf/2509.21845), [HTML](https://arxiv.org/abs/2509.21845)
### Authors
Zichen Zhang,Kunlong Zhang,Hongwei Ruan,Yiming Luo
### Background
基于Transformer的模型已经推动了问答领域的进步，但在多跳推理方面仍存在困难，即需要结合多个段落中的证据来给出答案。本文对检索策略在检索增强生成框架下的多跳问答进行了全面评估，比较了余弦相似度、最大边际相关性和结合密集向量、词汇重叠和重排序的混合方法。实验结果表明，混合方法显著优于基线方法，在精确匹配和F1分数上分别提高了50%和47%。分析显示，混合检索有助于提高实体召回率和证据的互补性，但在处理分心对象和时间推理方面仍有局限性。
### Innovation
本文提出了一个综合的评估框架，比较了不同的检索策略，包括余弦相似度、最大边际相关性和结合密集向量与词汇重叠的混合方法。此外，还通过适配EfficientRAG流水线对查询优化进行了改进，引入了token标记化和迭代优化。这些创新使检索过程更加高效、准确和可解释。
### Conclusion
综上所述，混合检索增强生成提供了一种实用的零样本解决方案，用于多跳问答，平衡了准确率、效率和可解释性。
## 819. `cs.CV` - MoWM: 混合世界模型混合体基于隐空间到像素特征调制的实体规划 [PDF](https://arxiv.org/pdf/2509.21797), [HTML](https://arxiv.org/abs/2509.21797)
### Authors
Yu Shang,Yangcheng Yu,Xin Zhang,Xin Jin,Haisheng Su,Wei Wu,Yong Li
### Background
实体行动规划是机器人技术的核心挑战之一，要求模型从视觉观察和语言指令中生成精确的行为。虽然视频生成世界模型很有前景，但它们依赖于像素级别的重建，这会引入视觉冗余，阻碍行动解码和泛化。虽然潜在世界模型提供了紧凑的、运动感知的表示，但忽视了对于精准操控至关重要的细粒度细节。为了解决这些问题，该论文提出了混合世界模型相结合的方法MoWM，通过混合潜在模型和像素空间模型的表示来进行实体行动规划。MoWM 使用高阶运动感知表示引导从像素空间模型中提取细粒度的视觉特征，从而突显行动解码所需的有用视觉细节。
### Innovation
MoWM 混合了世界模型的潜在表示和像素空间的运动感知表示，通过这种方式融合不同级别的视觉特征，既能保留运动信息的重要性，又不失视觉细节的准确性。MoWM 的设计使得它能够更有效地从视觉输入中提取所需的信息，从而提高行动计划的准确性和通用性。该方法在 CALVIN 范本上的广泛评估显示了其在任务成功率和泛化能力上的优越性，提供了一个决定性优势。此外，该研究还对每种特征空间进行了全面分析，为未来的实体规划研究提供了有价值的经验教训。编码已经发布在指定网站上。
### Conclusion
MoWM 能够通过融合高阶运动感知的潜在表示和像素空间模型来提高实体行动规划的性能。这种方法不仅提高了任务完成的成功率，还增强了模型的泛化能力。此外，该研究还分析了不同特征空间的优势，为将来的工作提供了参考和指导。
## 820. `cs.CV` - DynaNav: 动态特征和层选择以实现高效视觉导航 [PDF](https://arxiv.org/pdf/2509.21930), [HTML](https://arxiv.org/abs/2509.21930)
### Authors
Jiahui Wang,Changhao Chen
### Background
视觉导航对于机器人技术和具身AI至关重要。现有的基础模型，尤其是带有变压器解码器的模型，存在计算开销高和缺乏可解释性的问题，限制了它们在资源紧张环境中的部署。
### Innovation
提出了DynaNav，一种动态视觉导航框架，根据场景复杂度自适应选择特征和层。通过训练可学习的硬特征选择器实现稀疏操作，提升效率和可解释性。此外，将特征选择与早期退出机制结合，使用贝叶斯优化确定最优退出阈值，减少计算成本。
### Conclusion
实验证明，DynaNav在真实世界数据集和模拟环境中均表现出色。与ViNT相比，DynaNav在计算量（FLOPs减少2.26倍）、推理时间（降低42.3%）和内存使用（降低32.8%）上均有所提升，同时提高了导航性能。
## 821. `cs.CV` - SingRef6D：单张RGB参考图像实现新颖物体姿态估计 [PDF](https://arxiv.org/pdf/2509.21927), [HTML](https://arxiv.org/abs/2509.21927)
### Authors
Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee
### Background
近期的6D姿态估计方法虽然表现出色，但在实用方面仍存在一些限制。例如，许多方法高度依赖深度传感器，而在挑战性的表面条件下（如透明或高反射材料），这些方法可能失效。另一方面，基于RGB的解决方案在低光和无纹理场景中提供了较弱的匹配性能，因为缺乏几何信息。基于此，我们提出了SingRef6D，这是一种轻量级的管道，仅需一张RGB图像作为参考，从而避免使用成本高昂的深度传感器、多视图图像采集或训练视图合成模型和神经场。这使得SingRef6D即使在资源有限的环境中也能保持鲁棒性和能力，例如在深度或密集模板不可用的情况下。
### Innovation
SingRef6D有两个关键创新：1. 提出了基于标记缩放的微调机制，并在Depth-Anything v2上提出了一种新颖的优化损失，以增强其预测准确深度的能力，即使在挑战性表面也能准确预测。与Depth-Anything v2（带微调头部）相比，在REAL275深度预测上取得了14.41%的进步（$triangletext{1.05}$）。2. 获益于深度可用性，引入了一种深度感知匹配过程，有效地整合了LoFTR中的空间关系，使系统能够处理具有挑战性的材料和光照条件下的匹配。
### Conclusion
在评估中，SingRef6D在REAL275、ClearPose和Toyota-Light数据集上的姿态估计中，达到了6.1%的平均召回率改进，超越了最先进的方法。
## 822. `cs.CV` - SemanticControl：一种无需训练的处理控制网中松散对齐视觉条件的方法 [PDF](https://arxiv.org/pdf/2509.21938), [HTML](https://arxiv.org/abs/2509.21938)
### Authors
Woosung Joung,Daewon Chae,Jinkyu Kim
### Background
控制网（ControlNet）通过引入附加视觉条件（如深度图或边缘图），在文本到图像的扩散模型中实现了详细的时空控制。然而，其效果高度依赖于与文本提示生成目标精确对齐的视觉条件，这种要求很难在实践中实现，特别是对于不常见的或富有想象力的场景。现有的控制网模型难以利用与文本提示松散对齐但具有语义相关性的视觉条件，这往往导致低文本保真度或视觉伪影。
### Innovation
提出了一个无需训练的方法——SemanticControl，该方法能够有效利用与文本提示松散对齐但具有语义相关性的视觉条件。该方法通过适应性地抑制冲突的视觉条件影响，并增强文本的指导作用。具体而言，通过使用与视觉条件相匹配的代理提示（例如，“一个人弹吉他”用于人姿态条件）进行辅助去噪处理，提取出有用的关注掩码，然后在实际目标提示的去噪过程中利用这些掩码。
### Conclusion
实验结果表明，该方法在涉及深度图、边缘图和人体骨骼等多种条件下的松散对齐情况下提高了性能，优于现有基线。代码可供查看下载。
## 823. `cs.CV` - StableDub：为通用和高效视觉配音控制稳定传音 [PDF](https://arxiv.org/pdf/2509.21887), [HTML](https://arxiv.org/abs/2509.21887)
### Authors
Liyang Chen,Tianze Zhou,Xu He,Boshi Tang,Zhiyong Wu,Yang Huang,Yang Wu,Zhongqian Sun,Wei Yang,Helen Meng
### Background
视觉配音任务的目标是生成与驱动音频同步的口唇运动，近年来取得了显著进展。然而，两个关键缺陷限制了其广泛应用：（1）仅依靠声音驱动的方式未能充分捕捉说话者的唇部习惯，无法产生与目标角色类似的表情；（2）传统的蒙版修复方法在处理遮挡物（如麦克风、双手）时经常产生视觉伪影，限制了其实用部署。
### Innovation
本文提出了一种名为StableDub的新颖且简洁的框架，结合了唇部习惯感知建模与遮挡鲁棒合成。具体来说，基于Stable-Diffusion骨干，提出了唇部习惯调制机制，联合建模音视频同步和特定说话者的口颜动态。为了在遮挡下实现可信的唇部几何形状和物体外观，引入了遮挡感知的训练策略，明确地使遮挡物体暴露在修复过程中。通过结合上述设计，模型消除了之前方法中昂贵先验的必要性，从而在计算密集的扩散模型骨干上展现出更优越的训练效率。此外，引入了Hybrid Mamba-Transformer架构，进一步优化了在低资源研究场景中的模型应用。
### Conclusion
大量实验结果表明，StableDub在唇部习惯仿真和遮挡鲁棒性方面均表现出优越性能，并且在音唇同步、视频质量和分辨率一致性方面也超越了其他方法。我们的方法在全方位提升了视觉配音方法的应用范围，在这个网址可以找到演示视频：this https URL。
## 824. `cs.CV` - 在逆境天气条件下通过对比学习增强车辆检测 [PDF](https://arxiv.org/pdf/2509.21916), [HTML](https://arxiv.org/abs/2509.21916)
### Authors
Boying Li,Chang Liu,Petter Kyösti,Mattias Öhman,Devashish Singha Roy,Sofia Plazzi,Hamam Mokayed,Olle Hagner
### Background
在北欧地区使用无人机图像检测车辆时面临显著的能见度挑战和由于不同雪覆盖程度导致的领域偏移。尽管标注数据成本高昂，但未标注数据可以通过简单地飞行无人机获取。传统的检测方法受限于小型、稀疏的目标以及计算成本限制。
### Innovation
本文提出了一种sideload-CL-adaptation框架，该框架通过对比学习在预训练阶段训练基于CNN的表示提取器，然后将该提取器侧载到冻结的YOLO11n主干网络中进行微调。论文通过广泛实验比较了各种融合方法和粒度，从而找到了一种稳健的sideload-CL-adaptation方法。
### Conclusion
所提出的sideload-CL-adaptation模型在NVD数据集上的mAP50性能提高了3.8%到9.5%。
## 825. `cs.CV` - Syncphony: 使用扩散变换器实现同步的音频到视频生成 [PDF](https://arxiv.org/pdf/2509.21893), [HTML](https://arxiv.org/abs/2509.21893)
### Authors
Jibin Song,Mingi Kwon,Jaeseok Jeong,Youngjung Uh
### Background
在文本到视频和图像到视频生成方面，视觉质量已经取得了快速发展，但仍有局限性，特别是在控制运动的精确时间方面。相比之下，音频提供了与视频运动对齐的时间线索，表明其可以在时间控制的视频生成中发挥重要作用。然而，现有的音频到视频（A2V）模型在精细同步方面存在困难，这主要是由于间接的条件机制或有限的时间建模能力。该项目旨在通过提出一种新的方法来改善同步性能，该方法被称为Syncphony，它生成了380x640分辨率、24fps与多样音频输入同步的视频。
### Innovation
Syncphony 引入了两种关键组件来提高同步效果：1. 动态感知损失，强调在高运动区域进行学习；2. 音频同步指导，它使用视觉对齐的脱节模型来指导整个模型，在推理时更好地利用音频线索，同时保持视觉质量。为此，提出的CycleSync方法是基于视频到音频的指标来衡量生成视频中的运动线索数量，以重构原始音频，从而评估同步性能。与其他现有方法相比，Syncphony在同步准确性和视觉质量上表现更优。
### Conclusion
实验结果表明，Syncphony 在 AVSync15 和 The Greatest Hits 数据集上，在同步准确性和视觉质量方面优于现有方法。更多详情参见项目页面：this https URL
## 826. `cs.CV` - PartSAM：一种基于本源3D数据训练的可提示的大规模部分分割模型 [PDF](https://arxiv.org/pdf/2509.21965), [HTML](https://arxiv.org/abs/2509.21965)
### Authors
Zhe Zhu,Le Wan,Rui Xu,Yiheng Zhang,Honghua Chen,Zhiyang Dou,Cheng Lin,Yuan Liu,Mingqiang Wei
### Background
3D物体的分割领域具有持久的挑战性。为了解决分类学限制并应对未见过的3D物体，最近的研究转向了开放世界的部分分割。现有的方法通常通过将来自2D基础模型（如SAM）的监督信息提升到3D来完成，但这种方式间接地导致了表面导向的理解、不可控的分割和有限的泛化能力。
### Innovation
PartSAM是第一个基于大规模3D数据训练的可提示部分分割模型，采用了类似SAM的设计理念，使用三平面双支路编码器生成空间有序的嵌入码，以支持大规模部分感知表征学习。同时，提出了一种模型在环标注管道，以超过五百万的3D形状-部分对提供多样化且精细的标签，从而实现大规模监督。PartSAM展示了从规模架构和多样化3D数据中涌现的开放世界能力，通过单一提示实现了高度精确的部分识别，并且在“分割每个部分”模式下自动分解形状以展示表层和内部结构。
### Conclusion
广泛的实验表明，PartSAM在多个基准测试中的表现大幅优于最新的方法，标志着基础模型在3D部分理解方面的重大进步。我们的代码和模型很快将发布。
## 827. `cs.CV` - 无参考图像对比度评估中的定制化EfficientNet-B0 [PDF](https://arxiv.org/pdf/2509.21967), [HTML](https://arxiv.org/abs/2509.21967)
### Authors
Javad Hassannataj Joloudari,Bita Mesbahzadeh,Omid Zare,Emrah Arslan,Roohallah Alizadehsani,Hossein Moosaei
### Background
图像对比度是视觉感知的基础因素，在总体图像质量中起着至关重要的作用。然而，大多数无参考图像质量评估模型（NR IQA）难以在各种真实世界条件下准确评估对比度失真。
### Innovation
本文提出了一种基于深度学习的框架，用于盲图像对比度质量评估，通过定制和微调三种预训练架构（EfficientNet B0，ResNet18和MobileNetV2），加入了具有对比度感知回归头部的模型，并额外构建了一个基于Siamese网络的模型。模型在两个基准数据集CID2013和CCID2014上通过有针对性的数据增强进行了训练，这些数据集中包含合成和真实的对比度失真。评估结果显示，自定义的EfficientNet B0模型在CCID2014和CID2013数据集上均达到了最先进的性能。
### Conclusion
本文提出的无参考对比度质量评估方法表明，对轻量级预训练网络进行对比度感知适应可以产生高性能和可扩展的解决方案，适用于实时和资源受限应用。
## 828. `cs.CV` - Drag4D：通过文本驱动3D场景生成实现你的动作对齐 [PDF](https://arxiv.org/pdf/2509.21888), [HTML](https://arxiv.org/abs/2509.21888)
### Authors
Minjun Kang,Inkyu Shin,Taeyeop Lee,In So Kweon,Kuk-Jin Yoon
### Background
该论文讨论了如何将对象运动控制纳入基于文本的3D场景生成中。传统的3D场景生成可能无法无缝地集成用户定义的3D对象运动。这限制了创作者在3D空间中创建更加精细和精确的交互式动画的能力。Drag4D框架通过结合文本输入和复杂的3D操作，提供了改进的3D背景生成和对象运动控制方法。这项工作为提升3D动画的质量和用户体验带来了新的可能性，特别是在需要精确位置和运动控制的场景中。
### Innovation
Drag4D引入了一个互动框架，该框架能够在单一图像生成的3D场景中定义物体的三维轨迹，并无缝地将其与高质量的3D背景集成。其创新之处在于三个方面：1）通过2D高斯散点图技术和全景图像提升了从2D到3D背景的生成，增强了3D重建的密度和视觉完整性。2）提出了一种3D“复制粘贴”方法，从目标对象的参考图像中提取三维模型，并无缝地将其合入生成的3D场景中。3）开发了一种基于局部增强和运动条件的视频扩散模型，用于处理多视角图像对及其投影的2D轨迹，以校正时间上的不一致性和幻影运动，从而保持视点一致性并实现精确的空间对齐和时间动画。
### Conclusion
Drag4D通过在每个阶段和最终结果的表现，展示了用户控制的对象运动与其高质量3D背景之间的完美对齐。这项工作不仅简化了通过文本创建高质量3D场景的过程，还提供了更加灵活和精确的方法来控制3D对象的运动，增强了3D动画创作的灵活性和效果。
## 829. `cs.CV` - 在医疗视觉语言模型中基准评估与遏制心理奉承现象 [PDF](https://arxiv.org/pdf/2509.21979), [HTML](https://arxiv.org/abs/2509.21979)
### Authors
Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu
### Background
视觉语言模型(VLMs)在临床工作流程中的应用越来越广泛，但它们通常表现出一种迎合行为，优先考虑与用户语言、社交暗示或感知权威的一致性，而非基于证据的推理。
### Innovation
该研究提出了一种新的、有临床依据的基准，用于评估和减轻医疗视觉问答中的心理奉承现象。提出了Visual Information Purification for Evidence based Response (VIPER)。这是一种轻量级的缓解策略，通过过滤非证据性内容，生成受限的证据优先答案。此外，还展示了抑制心理奉承现象的有效触发机制。
### Conclusion
研究基准分析和缓解框架为医疗VLMs在现实临床互动中的稳健部署奠定了基础，强调了基于证据的防御措施的重要性。
## 830. `cs.CV` - Geo-R1:通过强化微调提高少量样本地理空间引表达理解 [PDF](https://arxiv.org/pdf/2509.21976), [HTML](https://arxiv.org/abs/2509.21976)
### Authors
Zilun Zhang,Zian Guan,Tiancheng Zhao,Haozhan Shen,Tianyu Li,Yuxiang Cai,Zhonggen Su,Zhaojun Liu,Jianwei Yin,Xiang Li
### Background
遥感领域中的引表达理解面临独特挑战，因为它需要处理复杂的对象-上下文关系。虽然超大语言模型的有监督微调（SFT）在大量标注数据的情况下表现出强大性能，但在数据稀缺场景下却面临困难，导致模型泛化能力不足。
### Innovation
提出了一种基于推理的强化微调（RFT）方法——Geo-R1，以解决少量样本地理空间引表达场景中的泛化不足问题。Geo-R1 强制模型首先生成明确的可解释推理链来分解引表达，然后利用这些推理来定位目标对象。这种先推理后行动的流程使得模型能够更有效地利用有限的注释，增强泛化能力，并提供可解释性。
### Conclusion
在三个精心设计的少量样本地理空间引表达基准测试中，Geo-R1 模型在所有测试中都显著优于 SFT 基线模型，并显示出强跨数据集泛化能力，证明其稳健性。代码和数据将在指定链接发布。
## 831. `cs.CV` - 使用自我监督学习的多视角人群计数 [PDF](https://arxiv.org/pdf/2509.21918), [HTML](https://arxiv.org/abs/2509.21918)
### Authors
Hong Mo,Xiong Zhang,Tengfei Shi,Zhongbo Wu
### Background
近年来，多视角计数（MVC）方法引起了广泛的研究关注并推动了显著的进步。尽管取得了成功，大多数MVC方法都集中在通过全监督学习（FSL）范式来提高性能，这通常需要大量的标注数据。
### Innovation
提出了一种新颖的自我监督学习（SSL）框架SSLCounter，该框架利用神经体积渲染以减少对大规模标注数据集的依赖。SSLCounter能够学习场景的隐式表示，通过差异神经渲染使连续几何形状和其2D投影的复杂，视角依赖的外观得以重建。此外，该方法的关键思想可以无缝集成到现有的框架中。实验表明，SSLCounter不但在性能上表现出最先进的水平，而且即使使用70%的训练数据也能达到具有竞争力的表现，展示了其在多个MVC基准方面的优越数据效率。
### Conclusion
SSLCounter不仅展示了最先进的性能，而且在使用较少训练数据的情况下展示了竞争力，显示出其在多视角计数任务中的卓越数据效率。
## 832. `cs.CV` - 从偏差到平衡：探索和缓解LVLM中的空间偏差 [PDF](https://arxiv.org/pdf/2509.21984), [HTML](https://arxiv.org/abs/2509.21984)
### Authors
Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Weili Guan,Jun Yu,Min Zhang
### Background
大型多模态语言模型（LVLMs）在各种多模态任务中取得了显著成功，但它们对空间变化的鲁棒性仍然不够明确。现有的LVLMs在图像中的视觉信息位置变化时经常产生不一致的输出，揭示了其在空间语义理解上的根本局限。
### Innovation
本文提出了一种系统研究LVLMs空间偏差的方法，重点在于当相同的关键视觉信息放置在图像的不同位置时，模型如何响应。研究发现，尽管视觉编码器能够可靠地感知和解释视觉内容，但语言模型组件中的位置嵌入设计不平衡是导致这种现象的原因。特别是广泛采用的位置嵌入策略（如RoPE）在跨模态交互中引入了不平衡，导致图像令牌在不同位置对语义理解的影响不均衡。为此，引入了“均衡位置分配”（BaPA）机制，通过将相同的位置嵌入分配给所有图像令牌，促进视觉信息的更均衡整合。实验表明，BaPA提升了LVLMs的空间鲁棒性，且在与轻量级微调结合后，进一步提高了其在多种多模态基准上的性能。
### Conclusion
BaPA机制通过使模型更好地整合视觉信息，提高了图像中视觉信息位置变化时的鲁棒性，同时也展示了在不同多模态任务上的有效性。
## 833. `cs.CV` - DualFocus：基于空间和焦点双变分解约束的聚焦depth估计 [PDF](https://arxiv.org/pdf/2509.21992), [HTML](https://arxiv.org/abs/2509.21992)
### Authors
Sungmin Woo,Sangyoun Lee
### Background
深度从焦距（Depth-from-Focus, DFF）通过分析不同焦距下拍摄的图像中的对焦线索进行精确的深度估计。尽管最近的学习方法在这一领域取得了进展，但在细纹理或急剧深度变化的复杂场景中，对焦线索可能变得模棱两可或误导性，导致性能下降。
### Innovation
我们提出了一种名为DualFocus的新DFF框架，它利用了由于对焦变化而产生的独特的梯度模式，并且在空间和焦点维度上联合建模对焦变化。该方法引入了一种变分形式，带有针对DFF定制的双约束：空间约束利用不同对焦点之间的梯度模式变化来区分真实的深度边缘和纹理伪影，而焦点约束则强制焦点概率遵循单一的、单调递增的行为模式，这增强了鲁棒性和准确性。
### Conclusion
在四个公开数据集上的全面实验表明，DualFocus在深度准确性及感知质量方面均连续超过最先进的方法。
## 834. `cs.CV` - ERGO: 高效高分辨率视觉理解的视觉语言模型 [PDF](https://arxiv.org/pdf/2509.21991), [HTML](https://arxiv.org/abs/2509.21991)
### Authors
Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim
### Background
对于现实世界的视觉语言应用而言，高效处理高分辨率图像至关重要。现有的大规模视觉语言模型（LVLMs）由于大量视觉标记的存在而产生了显著的计算开销。随着‘基于图像思考’模型的出现，推理已经从文本扩展到视觉领域。这一能力促使我们提出了一个两阶段的‘粗到细’推理流水线：首先对缩小比例后的图像进行分析以识别任务相关区域，然后仅对这些区域进行全分辨率裁切并进行后续的推理流程。这种做法可以同时减少计算成本，同时在必要时保留细致的视觉细节。
### Innovation
我们提出了一种名为ERGO（Efficient Reasoning & Guided Observation）的新方法，它通过依赖感知驱动的推理来捕捉模态上下文，决定了应该关注的位置。ERGO可以处理感知不确定性，将裁剪区域扩大到包括视觉模糊区域，以回答问题。为粗到细的感觉提供了一个简单的但有效的奖励组件，从而在强化学习框架中有效。与原有模型和竞争方法相比，我们的方法在多个数据集上显示出更高的准确性和更高的效率。例如，ERGO在V*基准测试上以4.7点的优势超过了Qwen2.5-VL-7B，且只使用了后者的23%的视觉标记，实现了3倍的推理加速。
### Conclusion
我们的方法在多个数据集上的表现优于原来的模型和竞争方法，具有更高的准确性和效率。尤其是在V*基准测试上，ERGO在使用更少的视觉标记时取得了更好的结果，同时还提升了推理速度。
## 835. `cs.CV` - 基础模型中的空间推理：基于对象的空间理解基准 [PDF](https://arxiv.org/pdf/2509.21922), [HTML](https://arxiv.org/abs/2509.21922)
### Authors
Vahid Mirjalili,Ramin Giahi,Sriram Kollipara,Akshay Kekuda,Kehui Yao,Kai Zhao,Jianpeng Xu,Kaushiki Nag,Sinduja Subramaniam,Topojoy Biswas,Evren Korpeoglu,Kannan Achan
### Background
基础模型的空间理解是一个关键能力。近年来，大型视觉模型或视觉-语言模型（VLMs）扩展了识别能力，但大多数基准测试更侧重于检测精度，而非物体在场景中的排列和关系。有效场景理解不仅需要识别物体，还需理解它们的位置关系、分组和深度。本文利用一个受控的合成数据集评估了最先进的视觉模型（例如 GroundingDINO, Florence-2, OWLv2）和大VLMs（例如 InternVL, LLaVA, GPT-4o）在三项任务中的表现：空间定位、空间推理和下游检索任务。研究发现，检测器如 GroundingDINO 和 OWLv2 提供精确但关系推理有限的边界框，而 VLMs 如 SmolVLM 和 GPT-4o 能提供粗略的空间布局暗示和流畅的描述，但在细微的空间背景下存在困难。研究突显了定位与真实空间理解之间的差距，强调了社区中需要具备位置感知能力的基础模型。
### Innovation
本文提出了一个系统基准来评估基础模型在对象中心的空间推理能力。通过使用一个受控的合成数据集，评估了多个最先进的视觉模型和大VLMs在空间定位、空间推理和下游检索任务中的表现，揭示了现有模型在空间理解方面的局限性，指出了未来研究方向。
### Conclusion
定位与真实的空间理解之间存在差距，需要空间感知的基础模型在社区中进行开发和研究。
## 836. `cs.CV` - CoFFT: Chain of Foresight-Focus Thought for Visual Language Models [PDF](https://arxiv.org/pdf/2509.22010), [HTML](https://arxiv.org/abs/2509.22010)
### Authors
Xinyu Zhang,Yuxuan Dong,Lingling Zhang,Chengyou Jia,Zhuohang Dang,Basura Fernando,Jun Liu,Mike Zheng Shou
### Background
尽管视觉语言模型（VLMs）有了显著的进步，但它们仍然受限于视觉输入的复杂性和冗余性。当图像包含大量无关信息时，VLMs容易受到干扰，导致产生过多的任务无关的推理过程或者甚至幻觉。这一限制源于VLMs无法准确发现和处理推理过程中所需的区域。
### Innovation
提出了Chain of Foresight-Focus Thought (CoFFT)，这是一种基于模仿人类视觉认知的、无需额外训练的新方法，以增强VLMs的视觉推理能力。CoFFT 包含三个阶段：多样样本生成（生成多样化的推理样本以探索潜在的推理路径）、双重前瞻解码（基于视觉焦点和推理进展严格评估这些样本，将最优样本的第一步加入推理过程）和视觉焦点调整（精确调整视觉焦点，使其指向对后续推理最有益的区域）。这些阶段通过迭代循环工作，形成相互依赖的循环，推理引导视觉焦点，视觉焦点指导后续推理。
### Conclusion
在Qwen2.5-VL、InternVL-2.5和Llava-Next等多个基准测试上进行的实验证明，CoFFT 可以在可控增加计算开销的情况下，使VLMs的性能提升3.1-5.8%。
## 837. `cs.CV` - MultiCrafter: 通过空间解纠缠注意力和身份感知强化学习实现高保真多主体生成 [PDF](https://arxiv.org/pdf/2509.21953), [HTML](https://arxiv.org/abs/2509.21953)
### Authors
Tao Wu,Yibo Jiang,Yehao Lu,Zhizhong Wang,Zeyi Huang,Zequn Qin,Xi Li
### Background
多主体图像生成旨在将用户提供的多个主题整合到单张图像中，同时保持主题的保真度、确保指令一致性并符合人类的审美偏好。现有方法，尤其是基于上下文学习范式的，受到简单重构目标的限制，导致严重的属性泄漏，损害了主题保真度，并且无法与人类复杂的偏好对齐。
### Innovation
MultiCrafter框架通过以下创新解决了上述问题：首先，引入明确的位置监督，以显式地将不同主题的注意力区域分开，有效减少属性泄漏。其次，采用Mixture-of-Experts架构增强模型的容量，使不同的专家能够专注于不同的场景。最后，设计了一个新的在线强化学习框架，以与人类偏好对齐，包括一个评分机制来准确评估多主体保真度，并为MoE架构设计了更稳定的训练策略。
### Conclusion
实验表明，我们的框架在提高主题保真度的同时，更好地与人类偏好对齐。
## 838. `cs.CV` - 为MLLMs定制视觉情感评估：一种开放词汇、多维度和可扩展的方法 [PDF](https://arxiv.org/pdf/2509.21950), [HTML](https://arxiv.org/abs/2509.21950)
### Authors
Daiqing Wu,Dongbao Yang,Sicheng Zhao,Can Ma,Yu Zhou
### Background
近年来，多模态大型语言模型（MLLMs）在各种任务中表现出色，超越了先前对其能力的预期。然而，MLLMs在图像情感识别方面的能力仍存在争议，尤其是在零样本场景下，研究结果呈现分歧。现有评估方法的限制，如未考虑合理回应、情感分类有限、忽视上下文因素以及耗时的注释工作，是造成这种不一致性的重要原因之一。因此，研究旨在通过提出一种情感陈述判断任务以及自动化的工作流程，来促进MLLMs针对视觉情感分析的定制评估，从而弥补这些限制并推动MLLMs在情感理解中的进展
### Innovation
该研究提出了一种情感陈述判断任务，通过该任务和自动化的处理流程有效地构建了情感中心化的语句，减少了人力投入，从而优化了MLLMs在视觉情感评估中的表现，并展示出他们在情绪解读和基于场景的情感判断上的明显优势，但同时指出了他们对感知主观性的理解和人类之间存在显著差距的关键领域，为未来改进方向提供了指导
### Conclusion
通过开发一个基础评估框架并进行全面的MLLM评估，本研究期望能促进MLLMs在情感理解方面的发展，提升MLLMs的情感智能水平
## 839. `cs.CV` - 通过揭示幻觉来抑制幻觉：使用生成锚点的语言-视觉模型表示编辑 [PDF](https://arxiv.org/pdf/2509.21997), [HTML](https://arxiv.org/abs/2509.21997)
### Authors
Youxu Shi,Suorong Yang,Dong Liu
### Background
多模态大型语言模型（MLLMs）在各种视觉-语言任务中取得了显著的成果，但它们仍然容易产生与视觉证据不一致的幻觉。这种幻觉涵盖了物体、属性和关系等多个方面，即使在更大规模的模型中也是如此。现有的缓解方法通常需要额外的微调、人工先验或在信息性和可扩展性之间做出妥协。
### Innovation
提出了一种无需训练的自监督方法来减轻幻觉，通过文本到图像模型将描述投影到视觉空间中，揭示隐含的幻觉信号作为负锚点，同时用原始图像作为正锚点。利用这两只锚点，通过拉向忠实语义的方向和推离幻觉方向来编辑解码器的隐藏状态。这种方法无需人工先验或额外的训练成本，有效而高效。
### Conclusion
在多个基准测试中的广泛实验显示，该方法在物体、属性和关系级别大大减少了幻觉，同时基本保持了召回率和描述的丰富性。此外，该方法在不同架构上验证了强跨架构泛化能力，并且在应用于无幻觉的描述时几乎没有副作用，突显其实用性和稳健性。实施代码将在公共领域提供。
## 840. `cs.CV` - SpecXNet: 一种用于稳健深度伪造检测的双域卷积网络 [PDF](https://arxiv.org/pdf/2509.22070), [HTML](https://arxiv.org/abs/2509.22070)
### Authors
Inzamamul Alam,Md Tanvir Islam,Simon S. Woo
### Background
随着生成对抗网络（GANs）和扩散模型生成内容的真实性日益增强，深度伪造检测变得更为复杂。现有的方法往往仅关注空间或频域特征，限制了其对未见操作的泛化能力。
### Innovation
本文提出了一种名为Spectral Cross-Attentional Network (SpecXNet) 的双域架构用于稳健的深度伪造检测。SpecXNet 包含一种核心模块Dual-Domain Feature Coupler (DDFC)，它将特征分解为局部空间分支以捕捉纹理级别的异常，以及使用快速傅里叶变换的全局频域分支以建模周期性不一致。此外，还引入了Dual Fourier Attention (DFA) 模块，该模块以内容感知的方式动态融合空间和频域特征。SpecXNet 通过修改后的XceptionNet 骨干网构建，将DDFC 和DFA 模块嵌入到了可分卷积块。实验结果表明，SpecXNet 在多个深度伪造检测基准数据集上取得了最先进的准确率，尤其是在跨数据集和未见操作情景下的表现尤为显著，同时保持了实时可行性。
### Conclusion
我们的结果强调了统一的空间-频域学习对于稳健且泛化能力的深度伪造检测的有效性。为了确保可再现性，在GitHub 上发布了完整的代码。
## 841. `cs.CV` - Rate-Distortion Optimized Communication for Collaborative Perception [PDF](https://arxiv.org/pdf/2509.21994), [HTML](https://arxiv.org/abs/2509.21994)
### Authors
Genjia Liu,Anning Hu,Yue Hu,Wenjun Zhang,Siheng Chen
### Background
先前的研究已经探讨了任务性能与通信量之间的经验权衡关系，但缺乏理论基础。协作感知强调通过多个代理共享视觉信息来增强环境理解，特别是在带宽资源有限的情况下。然而，理论基础方面的这一空白需要通过引入基于信息理论的理论框架来填补，特别是针对目标导向的多代理系统中的性能-通信权衡分析。
### Innovation
该论文提出了一种名为RDcomm的通信高效的协作感知框架，包括两项关键创新：i) 任务熵离散编码，通过为具有任务相关编码长度的特征分配来最大化提供实用信息的效率；ii) 互信息驱动的消息选择，利用互信息神经估计来接近无冗余的最佳条件。
### Conclusion
实验结果表明，RDcomm在DAIR-V2X和OPV2V上的准确度达到了最先进的水平，同时通信量减少了多达108倍。代码将会被公开。
## 842. `cs.CV` - 基于单个部分点云多视角增强的自我监督点云完成方法 [PDF](https://arxiv.org/pdf/2509.22132), [HTML](https://arxiv.org/abs/2509.22132)
### Authors
Jingjing Lu,Huilong Pi,Yunchuan Qin,Zhuo Tang,Ruihui Li
### Background
点云完成旨在从部分观察中重构完整的形状。尽管现有的方法已经取得了显著的效果，但仍然存在一些限制：监督方法高度依赖于地面真实数据，这限制了其在现实世界数据集中的泛化能力，因为存在合成数据到现实数据之间的域差距。无监督方法需要完整的点云来组成未配对的训练数据，而弱监督方法则需要对象的多视角观察。现有的自我监督方法经常产生不满意的预测，因为它们的自我监督信号能力有限。
### Innovation
本文提出了一种新颖的自我监督点云完成方法。通过设计基于单个部分点云多视角增强的一系列新颖自我监督信号来克服现有方法的挑战。此外，我们还首次将Mamba引入自我监督点云完成任务，鼓励模型生成高质量的点云。
### Conclusion
在合成和真实世界数据集上的实验结果显示，我们的方法达到了最先进的性能。
## 843. `cs.CV` - FailureAtlas: 通过主动探索映射 T2I 模型的失败景观 [PDF](https://arxiv.org/pdf/2509.21995), [HTML](https://arxiv.org/abs/2509.21995)
### Authors
Muxi Chen,Zhaohua Zhang,Chenchen Zhao,Mingyang Chen,Wenyu Jiang,Tianwen Jiang,Jianhuan Zhuo,Yu Tang,Qiuyong Xiao,Jihong Zhang,Qiang Xu
### Background
静态基准为比较文本到图像（T2I）模型提供了宝贵的基础，但它们被动的设计使其难以诊断系统性失败或孤立出其根本原因。作者认为主动探索是一个互补的范式，并介绍了 FailureAtlas，这是第一个用于自主探索和绘制大规模 T2I 模型失败景观的框架。FailureAtlas 将错误发现视为结构化搜索以寻找最小化并引发错误的概念。尽管这是一个计算上爆炸性的问题，但它通过新颖的加速技术变得可处理。应用到 Stable Diffusion 模型后，该方法发现了成千上万的新错误切片，并提供了首次大规模证据表明这些失败与训练数据的稀缺性相关联。
### Innovation
FailureAtlas 引入了新的主动探索框架，自主探索和绘制大规模 T2I 模型的失败景观。通过结构化搜索最小化并引发错误的概念来发现错误。作者还提供了一种新的加速技术使其计算上可处理。此外，通过接入 Stable Diffusion 模型，该方法发现了大量的以前未知错误切片，并首次大规模展示了这些失败与训练数据短缺的关系。
### Conclusion
FailureAtlas 提供了一个原则性且可扩展的引擎，用于深入模型审计，建立了新的诊断第一的方法论以指导更稳健的生成式人工智能的开发。
## 844. `cs.CV` - Mind-the-Glitch: 观察异常以检测主题驱动生成中的视觉不一致 [PDF](https://arxiv.org/pdf/2509.21989), [HTML](https://arxiv.org/abs/2509.21989)
### Authors
Abdelrahman Eldesokey,Aleksandar Cvejic,Bernard Ghanem,Peter Wonka
### Background
预训练的扩散模型的骨干网络已知编码丰富的语义特征，但同时也需要包含视觉特征以支持图像生成能力。分离这些视觉特征具有挑战性，因为缺乏标注的数据集。这项工作的背景正是基于这一问题，旨在解决如何自动构建带有标记语义和视觉对应关系的图像对的问题，并为此设计了一个对比架构来分离这两种特征类型。此外，提出的Visual Semantic Matching (VSM)新度量标准能够量化主题驱动生成中的视觉不一致，并实现不一致区域的空间定位。这些贡献对于改进主题驱动生成任务具有重要意义，填补了量化和定位不一致的空白方法的空白。
### Innovation
研究提出了一种新颖的方法，能够从预训练的扩散模型的骨干网络中拆分出视觉和语义特征，这种方法类似于已建立的语义对应关系。通过构建带有标记语义和视觉对应关系的图像对并设计对比架构，以及提出一种新度量标准Visual Semantic Matching (VSM)，该研究解决了量化和定位不一致的挑战。这在主题驱动生成中首次实现了不一致的量化和定位，为这一任务的进一步发展提供了有力工具。
### Conclusion
实验结果表明，该方法在量化视觉不一致方面优于基于全局特征的度量标准，如CLIP、DINO和跨模态模型，同时还能实现不一致区域的空间定位。这种方法是首次支持主题驱动生成中不一致的量化和定位，具有重要的实际应用价值和学术意义，对于改进该任务具有重要意义。
## 845. `cs.CV` - WAVE: 使用多模态LLM学习统一且多功能的音频-视觉嵌入 [PDF](https://arxiv.org/pdf/2509.21990), [HTML](https://arxiv.org/abs/2509.21990)
### Authors
Changli Tang,Qinfan Xiao,Ke Mei,Tianyi Wang,Fengyun Rao,Chao Zhang
### Background
虽然来自多模态大型语言模型（LLMs）的嵌入表现出色，但它们在动态模态（如音频和视频）中的应用仍然相对空白。当前的研究旨在填补这一空白，通过引入WAVE（统一且多功能的音频-视觉嵌入），这是一种基于LLM的嵌入技术，能够为文本、音频和视频模态创建统一的表示空间。WAVE采用了新颖的分层特征融合策略和联合多模态、多任务训练方法，以实现跨模态的任意到任意检索和生成响应用户指令的提示感知嵌入的能力。实验表明，WAVE在MMEB-v2视频基准测试上达到了新的最佳水平，并在音频和视频到音频检索中取得了更优的结果。此外，提示感知的特性还导致了在多模态问答任务上的显著性能提升，远超现有的嵌入模型。消融研究验证了联合训练策略的有效性，展示了在所有模态上的改进表现。
### Innovation
WAVE的主要创新在于它能够为文本、音频和视频模态创建统一的表示空间。采用分层特征融合策略和联合多模态、多任务训练方法，WAVE实现了跨模态任意到任意的检索能力，并能够生成响应用户指令的提示感知嵌入。此外，WAVE还在多模态问答任务中取得了显著的性能提升，并且能够在MMEB-v2视频基准测试和音频、视频到音频检索任务中达到最佳水平。
### Conclusion
通过引入WAVE，该研究为跨模态、任意到任意的应用打开了广泛的可能性。为了促进这一领域的研究，作者也提供了代码、检查点和数据，以供其他研究人员使用。
## 846. `cs.CV` - 解决视点辅助视觉助手互动模式中的歧义问题 [PDF](https://arxiv.org/pdf/2509.21980), [HTML](https://arxiv.org/abs/2509.21980)
### Authors
Zeyu Wang,Baiyu Chen,Kun Yan,Hongjing Piao,Hao Xue,Flora D. Salim,Yuanchun Shi,Yuntao Wang
### Background
随着智能眼镜的流行，用户注意力被集成到视觉语言模型（VLMs）中，以简化日常生活中的多模态查询。然而，利用注视数据建模用户注意力可能会引入歧义挑战：（1）用户口语中的问题可能通过使用代词或省略语境变得含糊不清，（2）人类的注视模式是嘈杂的，并且与他们的口语问题在空间和时间上表现出复杂的关联。之前的大多数工作只将单一图像作为视觉模态输入，未能捕捉到用户注意力的动态性质。因此，研究团队提出GLARIFY，这是一种利用时空注视信息来增强模型在实际应用中效果的新方法。
### Innovation
本文提出GLARIFY，这是一种新的方法，通过利用时空注视信息来增强视觉语言模型的效果。首先，作者通过分析数百个带有注视模态的查询样本来展示用户注视模式的噪声特性。然后，利用GPT-4o设计了一个自动数据合成管道，生成了GLARIFY-Ambi数据集，其中包括一个专门的因果推理（CoT）过程来处理噪声的注视模式。最后，设计了热力图模块，将注视信息整合到最新的视觉语言模型中，同时保留其预训练知识。通过在保留模型预训练知识的同时将注视信息融入视觉语言模型中，GLARIFY 提高了模型在实际应用中的效果。实验表明GLARIFY 显著优于Baselines。通过稳健地将视觉语言模型与人类注意力对齐，GLARIFY 为与视觉助手进行可用和直观的互动铺平了道路。
### Conclusion
通过稳健地将视觉语言模型与人类注意力对齐，GLARIFY 为与视觉助手进行可用和直观的互动铺平了道路。GLARIFY 显著提高了视觉语言模型的实际应用效果，并解决了视觉助手互动模式中的歧义问题，使得视觉助手的互动更加自然和有效。
## 847. `cs.CV` - Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions [PDF](https://arxiv.org/pdf/2509.22150), [HTML](https://arxiv.org/abs/2509.22150)
### Authors
Zhiqiang Tian,Weigang Li,Junwei Hu,Chunhua Deng
### Background
现有的3D点云分类任务假设类别事件是独立同分布的(IID)，但这种假设破坏了类之间的相关性。因此，该研究旨在提出一种策略，可以处理非独立同分布的3D点云数据，以保留类别间的潜在相关性。
### Innovation
该研究提出了一种新的分类策略，称为JGEKD（J-G-E-K-D），其通过基于联合图熵构建的损失函数实现知识蒸馏。该策略还引入了双胞胎结构和两种知识转移框架（自我知识蒸馏和教师知识蒸馏），以处理空间变换不变的3D点云的方法，并通过将点云与其 corrupted 形式之间的知识转移来增强模型的鲁棒性。
### Conclusion
在 ScanObject, ModelNet40, ScanntV2_cls 和 ModelNet-C 上进行的广泛实验表明，所提出的方法可以实现具有竞争力的结果，同时增强了模型对 corruption 的鲁棒性。
## 848. `cs.CV` - DragGANSpace：生成对抗网络中的潜在空间探索与控制 [PDF](https://arxiv.org/pdf/2509.22169), [HTML](https://arxiv.org/abs/2509.22169)
### Authors
Kirsten Odendaal,Neela Kaushik,Spencer Halverson
### Background
该研究综合利用StyleGAN、DragGAN和主成分分析（PCA）来提高GAN生成图像的潜在空间效率和可控性。StyleGAN提供了结构化的潜在空间，DragGAN使得图像修改直观易用，而PCA则通过降维和跨模型对齐技术提高了潜在空间的可操作性和可解释性。
### Innovation
提出了将PCA降维方法与DragGAN框架结合以改进图像操作，同时保持性能和优化效率。特别地，在DragGAN的潜在W+层引入PCA能够使优化时间缩短并保持良好的视觉质量，甚至提高优化图像的结构相似性指数（SSIM）。该研究还展示了跨不同但相关数据域的StyleGAN模型生成图像进行对齐的能力，并能够通过控制对齐后的潜在空间来直观且解释性地修改图像。
### Conclusion
研究结果表明，通过将PCA的维度减少与DragGAN框架相结合，可以在保持性能的同时优化潜在空间的探索与控制，从而为广泛的图像合成与编辑应用提供了高效且可解释的潜在空间控制可能性。
## 849. `cs.CV` - 轻量级结构化多模态推理在机器人临床场景理解中的应用 [PDF](https://arxiv.org/pdf/2509.22014), [HTML](https://arxiv.org/abs/2509.22014)
### Authors
Saurav Jha,Stefan K. Ehrlich
### Background
医疗机器人需要强大的多模态感知和推理能力，以确保动态临床环境中的安全性。当前的视觉-语言模型（VLMs）表现出较强的通用能力，但在所需用于机器人规划的时间推理、不确定性估计和结构化输出方面仍然有限。
### Innovation
提出了一种基于视频的轻量化智能多模态框架，结合Qwen2.5-VL-3B-Instruct模型和SmolAgent调度层，支持链条推理、视听融合和动态工具调用。框架生成结构化的场景图并利用混合检索模块，实现可解释和自适应的推理。
### Conclusion
在Video-MME基准测试和自定义临床数据集上的评估表明，该框架在准确性和鲁棒性方面与最先进的VLMs相当，展示了其在机器人辅助手术、患者监测和决策支持等应用中的潜力。
## 850. `cs.CV` - EgoInstruct：多模态LLM基准测试的面对面教学互动的主观视频数据集 [PDF](https://arxiv.org/pdf/2509.22019), [HTML](https://arxiv.org/abs/2509.22019)
### Authors
Yuki Sakai,Ryosuke Furuta,Juichun Yen,Yoichi Sato
### Background
对在同一物理空间中同步存在的教员与学习者的教学互动进行分析是教育支持和技能传递的关键问题。然而，在计算机视觉领域，此类面对面教学场景尚未系统研究。存在的主要原因包括：缺乏合适的数据集以及分析技术的限制。本文旨在填补这一空白，介绍了一个新的主观视频数据集，涵盖面对面教学，并提供两个基础任务的注释，以促进对教学互动的全面理解。同时，使用该数据集评估多模态大型语言模型与专门任务模型的表现，展示了面对复杂多模态数据时模型的理解能力。
### Innovation
提出了一种新的主观视频数据集EgoInstruct，专注于面对面的教学互动，并提供了两个关键任务的注释，分别是程序步骤的分割和对话状态分类。基于此数据集，评测了多模态大型语言模型与传统专门任务模型的性能，特别关注于处理多模态数据的能力，即同时处理言语和非言语交流信息。该评测为机器学习模型理解复杂多模态的面对面教学场景提供了定量分析。
### Conclusion
多模态大型语言模型在无需特指微调的情况下，在评测中表现出色，说明了其在全面理解教学互动上的潜力。
## 851. `cs.CV` - 跨类别视觉引导生成建模的高保真声音分离 [PDF](https://arxiv.org/pdf/2509.22063), [HTML](https://arxiv.org/abs/2509.22063)
### Authors
Chao Huang,Susan Liang,Yapeng Tian,Anurag Kumar,Chenliang Xu
### Background
现有的声音分离方法通常将声音分离视为基于掩码的回归问题，虽然取得了显著的进展，但在捕捉不同类别声音高质量分离所需的复杂数据分布方面存在局限性。
### Innovation
提出了基于扩散的音频-视觉分离（DAVIS）框架，该框架利用去噪扩散概率模型（DDPM）和流匹配（FM）进行生成学习，通过专门的分离U-Net架构解决音频-视觉声音源分离任务。DAVIS能够直接从噪声分布生成所需的分离声音频谱图，同时受混合音频输入和关联的视觉信息调节，从而能够生成高质量的声音分离结果，尤其适用于多种声音类别。
### Conclusion
DAVIS及其DDPM和Flow Matching变体在标准AVE和MUSIC数据集上的比较评估结果表明，这两种变体都超过了现有方法，在声音分离质量上优于现有方法，突显了我们提出的生成框架在处理音频-视觉源分离任务上的有效性。
## 852. `cs.CV` - 在遥感中实现可靠的推理：基于感知的空间链式思维框架 [PDF](https://arxiv.org/pdf/2509.22221), [HTML](https://arxiv.org/abs/2509.22221)
### Authors
Jiaqi Liu,Lang Sun,Ronghao Fu,Bo Yang
### Background
视觉语言模型（VLMs）在遥感领域中常难以完成复杂的分析任务，这源自它们通过端到端训练的方式跳过关键的推理步骤，导致输出不可验证。因此，现有模型的表现受限。
### Innovation
本文提出了一个名为Perceptually-Grounded Geospatial Chain-of-Thought（Geo-CoT）的框架，旨在将遥感分析建模为一个可验证的多步骤过程。该框架通过一种两阶段对齐策略实施：首先使用监督微调（SFT）来建立基本的认知架构，然后使用Group Reward Policy Optimization (GRPO)来优化模型的推理策略以提高事实准确性。这一策略产生的模型RSThinker能够输出最终答案及其验证性的分析过程，显著提高了模型在各种任务中的性能。
### Conclusion
本研究通过公开发布Geo-CoT380k数据集和RSThinker模型，实现从不透明的感知到结构化、可验证的推理的转变，为地球观测领域提供了明确的发展路径。
## 853. `cs.CV` - MultiMat: 使用大型多模态模型的程序合成方法用于 procedural 材料 [PDF](https://arxiv.org/pdf/2509.22151), [HTML](https://arxiv.org/abs/2509.22151)
### Authors
Jonas Belouadi,Tamy Boubekeur,Adrien Kaiser
### Background
材料节点图是程序，用于生成程序材料的2D通道，包括几何体如粗糙度和位移图，以及反射率如色度和导电图。它们在计算机图形学中对于表示虚拟3D对象的外观具有重要意义。特别是，它们的有向无环图结构和中间状态提供了交互式外观建模的直观理解与工作流程。然而，创建这样的图是一项具有挑战性的任务，通常需要专业培训。虽然最近的神经程序合成方法试图简化这一过程，但它们仅以文本形式代表图形，未能捕捉节点图的固有视觉-空间特性，这使得它们易于人类理解。
### Innovation
我们提出了MultiMat，一种多模态程序合成框架，利用大型多模态模型处理视觉和文本图形表示，以改进生成程序材料图。我们用一个新的生产质量的程序材料数据集训练我们的模型，并将其与一个受限树搜索推理算法结合起来，该算法确保语法有效性同时高效地导航程序空间。实验结果表明，与仅基于文本的基线相比，我们的多模态程序合成方法在无条件和有条件图形合成方面更有效率，且具有更高的视觉质量和真实性，从而在最新的性能指标上建立了新的基准。
### Conclusion
我们的研究结果表明，我们的多模态程序合成方法在无条件和有条件图形生成方面表现出更高的效率和视觉质量，优于仅基于文本的方法，为我们提供了新的基准水平，并展示了多模态程序合成技术的巨大潜力。
## 854. `cs.CV` - UrbanFeel：通过人类视角对城市场景进行时空感知的综合基准 [PDF](https://arxiv.org/pdf/2509.22228), [HTML](https://arxiv.org/abs/2509.22228)
### Authors
Jun He,Yi Lin,Zilong Huang,Jiacong Yin,Junyan Ye,Yuchuan Zhou,Weijia Li,Xiang Zhang
### Background
城市的开发影响着全球超过一半的人口，因此理解其结构和感知变化对于可持续发展至关重要。尽管多模态大型语言模型（MLLMs）在各个领域都展现出了卓越的能力，但现有的基准测试主要是探索其在城市环境中的表现，缺乏对时间和主观感知的系统性探索。为此，该研究提出了UrbanFeel基准，用于评估MLLMs在理解城市发展和环境感知方面的性能。
### Innovation
UrbanFeel是一个全面的基准，它包括了14300个精心构建的问题，覆盖了三个认知层次：静态场景感知、时间变化理解以及主观环境感知。通过多时相的单视角和全景街景图像，以及混合管道的空间聚类、基于规则的生成、模型辅助提示和人工注释，收集了高质量的问题答案对。研究结果表明，Gemini-2.5 Pro在各方面表现最佳，其准确性接近人类专家水平。
### Conclusion
尽管大多数模型在基于场景理解的任务中表现良好，但在需要时间推理的城市发展任务中性能下降明显。在主观感知维度上，一些模型达到了与人类一致或更高的一致性评价标准。
## 855. `cs.CV` - FlashEdit：解耦速度、结构和语义以实现精确图像编辑 [PDF](https://arxiv.org/pdf/2509.22244), [HTML](https://arxiv.org/abs/2509.22244)
### Authors
Junyi Wu,Zhiteng Li,Haotong Qin,Xiaohong Liu,Linghe Kong,Yulun Zhang,Xiaokang Yang
### Background
文本引导的图像编辑利用差分模型取得了显著的质量，但面临严重的时间延迟问题，阻碍了其在现实世界的应用。
### Innovation
FlashEdit是一个新型框架，旨在实现高效、实时的图像编辑。其高效性来自于三大创新：(1) 一次性反向变换和编辑(One-Step Inversion-and-Editing, OSIE)流水线，绕过了昂贵的迭代过程；(2) 背景屏蔽(BG-Shield)技术，通过在编辑区域仅选择性地修改特征来保证背景的完整；(3) 稀疏空间交叉注意力(Sparse Spatial Cross-Attention, SSCA)机制，通过抑制语义泄漏到背景，确保精确、局部的编辑。
### Conclusion
广泛的实验表明，FlashEdit在保持背景一致性及结构完整性的同时，能在不到0.2秒内完成编辑，这比之前的多步方法快150多倍。
## 856. `cs.CV` - GS-2M：基于3D高斯斑点的联合网格重建与材料分解 [PDF](https://arxiv.org/pdf/2509.22276), [HTML](https://arxiv.org/abs/2509.22276)
### Authors
Dinh Minh Nguyen,Malte Avenhaus,Thomas Lindemeier
### Background
以往的研究分别处理网格重建和材料分解任务，难以重建高反射表面，常依赖外部模型的先验知识来提升分解结果。尽管现代研究有效同时解决这两个任务，但往往需要复杂的神经网络组件来学习场景特性，这在大规模应用中阻碍了性能。
### Innovation
提出了一种联合优化渲染深度和法线质量相关属性的方法，结合多视角光度变异性上的粗糙度监督策略。通过精心设计的损失函数和优化过程，统一框架产出结果可与当前最先进的方法媲美，提供三角网格和其对应的材料组件以供下游任务使用。
### Conclusion
通过广泛使用的数据集验证方法的有效性，并与最先进的表面重建方法进行定性比较，展示了该统一框架的优势。
## 857. `cs.CV` - Relightable 3D生成的大材质高斯模型 [PDF](https://arxiv.org/pdf/2509.22112), [HTML](https://arxiv.org/abs/2509.22112)
### Authors
Jingrui Ye,Lingting Zhu,Runze Zhang,Zeyu Hu,Yingda Yin,Lanjiong Li,Lequan Yu,Qingmin Liao
### Background
随着各行各业对3D资产需求的增加，迫切需要高效且自动化的3D内容创建方法。现有的大型重建模型（LRMs）利用3D高斯点状技术能够高效地生成高质量的3D渲染，并通过多视图扩散进行生成，用可扩展的变换器进行重建，但它们无法生成资产的材质属性。这在不同照明环境下进行真实感渲染时至关重要。
### Innovation
本文介绍了Large Material Gaussian Model (MGM)这一新框架，以物理基础渲染（PBR）材质生成高质量3D内容，相对于仅生成受控光照烘焙的RGB纹理。具体来说，作者首先细调一个新提出的多视图材质扩散模型，该模型基于输入深度和法线图进行条件化。通过生成的多视图PBR图像，探索了一种高斯材质表示，该表示不仅与二维高斯点状技术一致，而且还为PBR的每一个通道建模。这些重建的点云可以渲染以获取PBR属性，从而通过应用不同的环境光贴图实现动态重新照明。实验证明，通过本方法生成的材质不仅在视觉上更具吸引力，而且促进材质建模，使下游渲染应用成为可能。
### Conclusion
本研究通过引入MGM框架，解决了现有模型无法生成PBR材质的问题，生成高质量3D内容，并通过Physically Based Rendering属性进行渲染，支持动态重新照明，从而进一步增强了材质的真实感和应用范围。
## 858. `cs.CV` - 基于规则的强化学习在视觉语言模型辅助文档图像分类中的应用 [PDF](https://arxiv.org/pdf/2509.22283), [HTML](https://arxiv.org/abs/2509.22283)
### Authors
Michael Jungo,Andreas Fischer
### Background
自DeepSeek-R1通过简单可验证奖励展示了其成功后，基于规则的强化学习得到了越来越多的关注。尽管强化学习在文档分析领域并不常见，但由于其增强的推理能力，强化学习有许多下游任务可以受益。本文聚焦于文档图像分类任务，旨在研究基于规则的强化学习在视觉语言模型辅助下的应用。
### Innovation
本文探讨了基于规则的强化学习在文档图像分类中的效果，发现强化学习具有更好的分布外数据泛化能力，并在三种不同场景（分布外图像、未见过的类别和不同模态）下进行了验证。
### Conclusion
实验结果表明，基于规则的强化学习方法在不常见情况下具有更好的推广能力，是文档图像分类任务的一种有效方法，并且随代码开源对外发布。
## 859. `cs.CV` - Refine-Control：一种条件图像生成的半监督蒸馏方法 [PDF](https://arxiv.org/pdf/2509.22139), [HTML](https://arxiv.org/abs/2509.22139)
### Authors
Yicheng Jiang,Jin Yuan,Hua Yuan,Yao Zhang,Yong Rui
### Background
基于文本控制的条件图像生成模型已经取得了显著成果，但这些模型对资源的需求很高，且高质量标注数据稀缺，这阻碍了它们在边缘设备上的部署，带来高昂的成本和隐私问题，特别是当用户数据被发送到第三方时。
### Innovation
提出了一种名为Refine-Control的半监督蒸馏框架，该框架通过引入三级知识融合损失提高学生模型的性能，并通过利用标记和未标记数据的半监督蒸馏方法增强泛化能力，缓解数据稀缺问题。
### Conclusion
实验结果显示，Refine-Control方法在显著降低计算成本和延迟的同时，保持了高质量的生成能力和良好的可控性，通过比较指标得以验证。
## 860. `cs.CV` - Johanson-Lindenstrauss 证引理指导的网络在高效三维医疗分割中的应用 [PDF](https://arxiv.org/pdf/2509.22307), [HTML](https://arxiv.org/abs/2509.22307)
### Authors
Jinpeng Lu,Linghan Cai,Yinda Chen,Guo Tang,Songhan Jiang,Haoyuan Shi,Zhiwei Xiong
### Background
三维医学图像分割受到‘效率/稳健性冲突’的基本限制，尤其是在处理复杂的解剖结构和异质模态时更为明显。
### Innovation
提出了一种名为VeloxSeg的方法，该方法采用可部署和可扩充的双流CNN-Transformer架构，结合Paired Window Attention (PWA)和Johnson-Lindenstrauss lemma-guided convolution (JLC)，并通过Spatially Decoupled Knowledge Transfer (SDKT)通过Gram矩阵注入先验纹理，从而高效地建模异质模态，提升模型的计算效率。
### Conclusion
实验结果表明，VeloxSeg在多模态基准测试中的Dice改进达到26%，同时GPU吞吐量提高了11倍，CPU提高了48倍。
## 861. `cs.CV` - NIFTY：一种非局部图像流匹配纹理合成方法 [PDF](https://arxiv.org/pdf/2509.22318), [HTML](https://arxiv.org/abs/2509.22318)
### Authors
Pierrick Chatillon,Julien Rabin,David Tschumperlé
### Background
这篇论文解决了基于示例的纹理合成问题。传统的基于模板的纹理优化技术存在初始值不佳和视觉效果差等缺点。鉴于此，最近的扩散模型和卷积神经网络培训成果提供了新的思路。
### Innovation
引入NIFTY，这是一种非参数流匹配模型，结合了基于非局部图块匹配的经典纹理优化技术和扩散模型的最新见解。NIFTY避免了神经网络的训练需求，同时也克服了基于图块方法的常见缺陷。
### Conclusion
实验结果表明，NIFTY方法相比于文献中代表性的方法更为有效。该代码开源。
## 862. `cs.CV` - MinerU2.5：一种用于高效高分辨率文档解析的分离型视觉语言模型 [PDF](https://arxiv.org/pdf/2509.22186), [HTML](https://arxiv.org/abs/2509.22186)
### Authors
Junbo Niu,Zheng Liu,Zhuangcheng Gu,Bin Wang,Linke Ouyang,Zhiyuan Zhao,Tao Chu,Tianyao He,Fan Wu,Qintong Zhang,Zhenjiang Jin,Guang Liang,Rui Zhang,Wenzheng Zhang,Yuan Qu,Zhifei Ren,Yuefeng Sun,Yuanhong Zheng,Dongsheng Ma,Zirui Tang,Boyu Niu,Ziyang Miao,Hejun Dong,Siyi Qian,Junyuan Zhang,Jingzhou Chen,Fangdong Wang,Xiaomeng Zhao,Liqun Wei,Wei Li,Shasha Wang,Ruiliang Xu,Yuanyuan Cao,Lu Chen,Qianqian Wu,Huaiyu Gu,Lindong Lu,Keming Wang,Dechen Lin,Guanlin Shen,Xuanhe Zhou,Linfeng Zhang,Yuhang Zang,Xiaoyi Dong,Jiaqi Wang,Bo Zhang,Lei Bai,Pei Chu,Weijia Li,Jiang Wu,Lijun Wu,Zhenxiang Li,Guangyu Wang,Zhongying Tu,Chao Xu,Kai Chen,Yu Qiao,Bowen Zhou,Dahua Lin,Wentao Zhang,Conghui He
### Background
研究开发了具有较少参数但高效率的文档解析视觉语言模型，以解决高分辨率文档解析中的计算效率问题。传统的方法在处理高分辨率输入时计算成本较高，而该研究通过分阶段解析策略来减少这一成本，同时保持高的识别准确性。
### Innovation
提出了一种分阶段的解析策略（粗到细，两阶段），将全局布局分析与局部内容识别分离开来。首先，对下采样的图像进行有效的布局分析，以识别结构元素，避免处理高分辨率输入的计算开销。其次，用全局布局指导在原始图像中提取的高分辨率切块进行针对性的内容识别，保留精细的细节。这通过一个综合数据引擎来支持，该引擎为预训练和微调生成了多样且规模庞大的训练数据集。此外， MinerU2.5 通过减少计算开销的方式，在多个基准测试中展示了强大的文档解析能力，超越了通用和特定领域的模型。
### Conclusion
MinerU2.5 是一个参数量为1.2亿的文档解析视觉语言模型，它展现了出色的计算效率和识别准确性，尤其在各种识别任务中的表现优于通用模型和特定领域的模型，同时保持较低的计算开销。
## 863. `cs.CV` - RAPID^3：扩散变压器的三层强化加速策略 [PDF](https://arxiv.org/pdf/2509.22323), [HTML](https://arxiv.org/abs/2509.22323)
### Authors
Wangbo Zhao,Yizeng Han,Zhiwei Tang,Jiasheng Tang,Pengfei Zhou,Kai Wang,Bohan Zhuang,Zhangyang Wang,Fan Wang,Yang You
### Background
扩散变压器（DiT）在视觉生成任务上表现出色，但采样速度较慢。现有的无需训练的加速器方法（如步长减少、特征缓存和稀疏注意力）能够提升推理速度，但通常依赖于统一的经验法则或手动设计的适应策略，这可能不足以提升质量。动态神经网络提供了每张图像的自适应加速，但高微调成本限制了它们的广泛应用。
### Innovation
提出了RAPID3框架，这是一种能够实现图像级加速但无需对基生成器进行任何更新的方法。具体来说，引入了三个轻量级策略头部：步长跳过、缓存重用和稀疏注意力，它们能够根据当前去噪状态分别决定在每个时间步的速度提升策略。所有策略参数通过Group Relative Policy Optimization（GRPO）在线学习，而生成器则保持冻结状态。该框架还包括一个对抗性学习的判别器以增强奖励信号，确保存生样本与原始模型分布接近，从而防止奖励作弊。
### Conclusion
在包括Stable Diffusion 3和FLUX在内的先进DiT架构上，该方法实现了近3倍的加速，同时保持了具有竞争力的生成质量。
## 864. `cs.CV` - HiGS: 基于历史指导的插件式增强采样方法以提高扩散模型的效果 [PDF](https://arxiv.org/pdf/2509.22300), [HTML](https://arxiv.org/abs/2509.22300)
### Authors
Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
### Background
扩散模型在图像生成方面取得了显著进展，但在使用较少的神经函数评估（NFEs）或较低的指导尺度时，其输出仍然显得不太真实且细节不足。
### Innovation
提出了一种基于动量的历史指导采样技术（HiGS），通过将最新模型预测整合到每一推理步骤中，增强扩散采样的质量和效率。HiGS 利用当前预测与过去预测加权平均值之间的差异，引导采样过程产生更真实且具有更多细节和结构的结果，且在不增加额外计算量的情况下，无缝集成到现有的扩散框架中。
### Conclusion
广泛的实验证明，HiGS 在不同模型和架构下以及不同的采样预算和指导尺度下，都能一致地提高图像质量。使用预训练的 SiT 模型，HiGS 在 256×256 大小的 ImageNet 无指导生成任务中仅需 30 个采样步骤即实现了新的 FID 状态（1.61），显著提升了加速生成的同时保证了更高的保真度。因此，HiGS 提供了一种即插即用的增强，作为一种标准扩散采样的提升方法。
## 865. `cs.CV` - 基于匹配掩码提升的多义语言高斯点绘制 [PDF](https://arxiv.org/pdf/2509.22225), [HTML](https://arxiv.org/abs/2509.22225)
### Authors
Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li
### Background
将2D开放词汇理解提升到3D高斯点绘制(3DGS)场景中是一个关键挑战。主流方法存在三个主要问题：(i) 支付高昂的每场景重新训练成本导致无法即插即用应用；(ii) 强制单一语义设计无法表示复杂的多概念语义；(iii) 多视图语义不一致性导致最终的语义表示错误。这三点限制了现有方法的应用效果。因此，亟需一种无需训练、能够克服这些限制条件的新框架。
### Innovation
我们提出了一种无需训练的MUSplat框架，该框架完全放弃了特征优化的步骤。通过利用预训练的2D分割模型，MUSplat生成并提升了多粒度2D掩码到3D，估算每个高斯点的前景概率形成初始对象组。然后使用语义熵和几何不透明度优化这些初始组的模糊边界。通过一个视觉语言模型（VLM）将物体在最具代表性视角下的外观进行解释，从而提炼出稳健的文本特征，调和视觉不一致性，实现开放词汇查询。MUSplat消除了每场景的训练过程，将场景适应时间从数小时缩短到几分钟。
### Conclusion
在针对开放词汇3D物体选择和语义分割基准任务中，MUSplat不仅超越了基于训练的框架，还同时解决了其单一语义的局限性。
## 866. `cs.CV` - 基于分层跨模态超图学习的行人属性识别 [PDF](https://arxiv.org/pdf/2509.22331), [HTML](https://arxiv.org/abs/2509.22331)
### Authors
Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo
### Background
当前的行人属性识别（PAR）算法主要侧重于将视觉特征映射到语义标签，或者尝试通过融合视觉和属性信息来增强学习效果。然而，这些方法未能充分利用属性知识和上下文信息以实现更准确的识别。尽管最近的研究已经开始考虑将属性文本作为额外输入以增强视觉和语义信息之间的关联，但这些方法仍处于初级阶段。
### Innovation
本文提出构建一个多模态知识图谱，用于挖掘局部视觉特征与文本之间的关系以及属性与广泛视觉上下文样本之间的关系。特别是，本文提出了一种全面考虑属性之间关系及属性与视觉标记之间关系的有效多模态知识图谱构建方法，并引入了基于知识图谱指导的跨模态超图学习框架来增强标准的行人属性识别框架。
### Conclusion
本文在多个PAR基准数据集上的综合实验全面证明了所提知识图谱的有效性，为知识引导的行人属性识别奠定了坚实的基础。本文的源代码将在此链接发布：this https URL。
## 867. `cs.CV` - CircuitSense：工程设计过程中的层级电路系统基准，连接视觉理解与符号推理 [PDF](https://arxiv.org/pdf/2509.22339), [HTML](https://arxiv.org/abs/2509.22339)
### Authors
Arman Akbari,Jian Gao,Yifei Zou,Mei Yang,Jinru Duan,Dmitrii Torbunov,Yanzhi Wang,Yihui Ren,Xuan Zhang
### Background
工程设计通过从系统规范到组件实现的分层抽象化，需要在每个层级上结合视觉理解和数学推理。虽然多模态大型语言模型（MLLMs）在自然图像任务中表现出色，但它们从技术图表中提取数学模型的能力尚未得到探索。现有研究尚未全面评估工程工作流程中的视觉到数学推理能力。
### Innovation
本文提出了CircuitSense，这是一个针对电路理解的分层基准，覆盖从组件级到系统级的8,006+问题，以全面评估感知、分析和设计流程。引入了一个分层合成生成流水线，包括基于网格的示意图生成器和带有自动提取符号方程标签的模块框图生成器。全面评估了包括开源和闭源模型在内的六种最先进的MLLMs，揭示了视觉到数学推理的基本局限性，特别是在符号推导和分析推理方面。
### Conclusion
闭源模型在涉及组件识别和拓扑识别的感知任务中超过85%的准确性，但在符号推导和分析推理任务中不到19%，这显示了视觉解析和符号推理之间的关键差距。符号推理能力强的模型在设计任务中的准确性更高，突出了数学理解在电路合成中的基础性作用，并将符号推理确立为工程能力的关键指标。
## 868. `cs.CV` - MesaTask: 通过三维空间推理实现任务驱动的桌面场景生成 [PDF](https://arxiv.org/pdf/2509.22281), [HTML](https://arxiv.org/abs/2509.22281)
### Authors
Jinkun Hao,Naifu Liang,Zhen Luo,Xudong Xu,Weipeng Zhong,Ran Yi,Yichen Jin,Zhaoyang Lyu,Feng Zheng,Lizhuang Ma,Jiangmiao Pang
### Background
机器人的行为执行依赖于任务相关的桌面场景进行训练。传统的创建这些场景的方法要么依赖耗时的手动规划设计，要么依赖随机生成，这两种方法都存在场景不真实或者与任务不匹配的问题。本文提出的任务导向的桌面场景生成任务旨在解决高阶任务指令与桌面场景之间的巨大鸿沟。
### Innovation
本文提出了一种新的方法，即空间推理链（Spatial Reasoning Chain），该方法将场景生成过程分解为对象推理、空间相互关系推理和场景图构建三个阶段，构建出真实且复杂的桌面场景。此外，还提出了一种基于LLM的框架MesaTask，并利用DPO算法增强这种推理链，从而生成与任务描述高度匹配的物理上合理的桌面场景。实验结果表明，MesaTask在生成符合任务要求的桌面场景方面表现优于基线方法。
### Conclusion
MesaTask框架不仅能够生成高质量的桌面场景，还能更好地与给定的任务描述相匹配。未来的工作可以进一步优化空间推理策略，以提高场景生成效率和精确度。
## 869. `cs.CV` - 基于梯度的多焦点图像融合与关注意识显著性增强 [PDF](https://arxiv.org/pdf/2509.22392), [HTML](https://arxiv.org/abs/2509.22392)
### Authors
Haoyu Li,XiaoSong Li
### Background
多焦点图像融合（MFIF）旨在从多个部分聚焦的输入生成一个全方位聚焦的图像，在监控、显微镜和计算摄影等多个应用领域中至关重要。然而，现有的方法在保持清晰对焦和不清晰对焦边界的细节上存在不足，常常导致模糊过渡和重点细节的丢失。
### Innovation
提出了一种基于重要边界增强的多焦点图像融合方法，能够生成高质量的融合边界并有效检测焦点信息。通过提出一种基于梯度的模型，可以获取具有完整边界的初始融合结果并有效保留边界细节。此外，引入了Tenengrad梯度检测从源图像和初始融合图像中提取显著特征，生成相应的显著性图。在边界细化方面，基于梯度和互补信息开发了一个聚焦度量，结合图像间的显著特征和互补信息以突出聚焦区域，产生高质量的初始决策结果。
### Conclusion
在四个公开数据集上的大量实验表明，该方法在主观和客观评估中均优于12种当前最先进的方法。
## 870. `cs.CV` - GPT-4用于遮挡顺序恢复 [PDF](https://arxiv.org/pdf/2509.22383), [HTML](https://arxiv.org/abs/2509.22383)
### Authors
Kaziwa Saleh,Zhyar Rzgar K Rostam,Sándor Szénási,Zoltán Vámossy
### Background
当前的视觉模型难以在复杂且密集的现实世界图像和场景中稳健地进行解释，尤其是在处理遮挡问题时。现有的方法难以准确预测物体之间的遮挡顺序关系，这成为了一个重要的挑战。
### Innovation
本文提出了一种创新的方法，利用预训练的GPT-4模型的高级能力来推断遮挡顺序。通过提供一个特别设计的提示并结合输入图像，GPT-4可以分析图像并生成遮挡顺序预测。该结果可以被解析成遮挡矩阵，用于辅助其他遮挡处理任务和图像理解。实验结果表明，利用语义上下文、视觉模式和常识知识，模型能生成更准确的顺序预测。与基线方法不同，模型能够在零样本情况下推理遮挡关系，无需标注的训练数据，并且可以轻松地集成到遮挡处理框架中。
### Conclusion
本文通过在COCOA和InstaOrder数据集上的评估，展示了GPT-4模型在恢复遮挡顺序方面的优越性能。该模型能够利用语义情景、视觉特征和常识知识进行零样本推理，这种方法具有广泛应用前景。
## 871. `cs.CV` - 两位专家的故事：协作学习在源数据无访问条件下的无监督领域适应 [PDF](https://arxiv.org/pdf/2509.22229), [HTML](https://arxiv.org/abs/2509.22229)
### Authors
Jiaping Yu,Muli Yang,Jiapeng Ji,Jiexi Yan,Cheng Deng
### Background
源数据无访问条件下的无监督领域适应（SFUDA）解决的是如何在无法访问源数据的情况下，通过利用目标数据本身的特性来适应目标域。当前的方法或是仅利用源模型的预测信息，或是训练大型多模态模型，但都忽视了目标数据的潜在结构和互补洞察。已有方法对模型之间的互补知识挖掘不足，导致未能充分利用目标数据的各种信息。因此，探索一种能够协调利用源模型预测和目标数据潜在结构的方法尤为重要，从而提高场景适应能力与模型性能，规避隐私和成本等问题的限制。
### Innovation
本文提出了专家协作学习（EXCL），包括双重专家框架和检索增强交互优化流水线。该框架通过将冻结的源域模型（加上Conv-Adapter）和预训练的视图-语言模型（带有可训练的文本提示）置于平等地位，从未标记的目标样本中挖掘共识知识。提出了一种名为检索增强交互（RAIN）的三阶段流水线，有效利用了纯无监督条件下的插件模块训练，包括协同检索伪源和复杂的目标样本，独立调整每个专家在其对应的样本集合上，并通过共享学习结果实现学习对象一致性。这种方法显著提升了无监督领域适应的表现，并展示了其在四个基准数据集上的高效率和高精度。
### Conclusion
全方位实验验证了该方法的优越性，与现有最先进的方法相媲美。该研究提供了一种新的方法来解决源数据采集障碍下模型适应性的挑战，通过协作学习和检索增强的策略使得模型能够有效地适应目标域。未来的研究可以进一步探索如何优化专家之间的协作方式，以及如何更充分地利用目标数据的各种特性，进一步提高模型的鲁棒性和适应性。
## 872. `cs.CV` - UniMapGen: 多模态数据生成框架的大规模地图构建 [PDF](https://arxiv.org/pdf/2509.22262), [HTML](https://arxiv.org/abs/2509.22262)
### Authors
Yujian Yuan,Changjie Wu,Xinyuan Chang,Sijin Wang,Hang Zhang,Shiyi Liang,Shuang Zeng,Mu Xu
### Background
大规模地图构建对于自动驾驶和导航系统等关键应用至关重要。传统方法主要依赖昂贵且低效的专用数据采集车辆和劳动力密集型注释过程。尽管现有基于卫星的方法在提高地图构建的效率和覆盖率方面表现出巨大潜力，但仍存在两个主要局限性：(1) 卫星数据的固有缺陷（如遮挡和过时）；(2) 从感知方法转换为矢量的过程低效，导致道路不连续且粗糙，需要大量后续处理。
### Innovation
提出了名为UniMapGen的新型生成框架，提供了三大创新点：(1) 将车道线表示为**离散序列**并建立迭代策略，生成的完整且平滑的地图矢量比传统感知方法更优。 (2) 提出一种灵活的架构，支持**多模态输入**，允许动态选择基于BEV（鸟瞰图）、PV（透视图）和文本提示的各种输入模式，以克服卫星数据的缺点。 (3) 发展了一种**全局状态更新**策略，以确保构建的大规模地图的全球连续性和一致性。
### Conclusion
UniMapGen 在 OpenSatMap 数据集上的性能达到了最新技术水平。此外，UniMapGen 还能够推断出被遮挡的道路并预测数据集注释中缺失的道路。我们的代码将被发布。
## 873. `cs.CV` - 在医学语义分割中使用逻辑张量网络集成背景知识 [PDF](https://arxiv.org/pdf/2509.22399), [HTML](https://arxiv.org/abs/2509.22399)
### Authors
Luca Bergamin,Giovanna Maria Dimitri,Fabio Aiolli
### Background
语义分割是医学图像分析的基础任务，有助于放射科医生区分图像中的物体以辅助医疗决策。尽管深度学习在这一领域的应用使这些系统能够处理噪声和伪影，但系统尚未完全完善。研究者认为可以通过在分割模型的损失函数中加入医学背景知识来提高性能。
### Innovation
该研究引入了逻辑张量网络（LTNs），通过一阶逻辑（FOL）规则将医学背景知识编码到分割模型中。LTNs的应用为点对点的框架与SwinUNETR结合进行语义分割。研究发现在数据稀缺的情况下，LTNs可以提升基础分割性能。
### Conclusion
该方法虽然仍处于初步阶段，但研究者认为神经符号方法具有通用性，可以适应并应用于其他医学语义分割任务。
## 874. `cs.CV` - 在视觉自回归模型中手术概念去除：关闭安全性间隔 [PDF](https://arxiv.org/pdf/2509.22400), [HTML](https://arxiv.org/abs/2509.22400)
### Authors
Xinhao Zhong,Yimin Zhou,Zhiqi Zhang,Junhao Li,Yi Sun,Bin Chen,Shu-Tao Xia,Ke Xu
### Background
视觉自回归（VAR）模型的快速发展为文本到图像生成提供了新的机会，但也增加了安全问题。现有的概念去除技术主要是为扩散模型设计的，由于VAR模型的下一级标记预测机制，这些技术无法很好地应用于VAR模型。
### Innovation
本文提出了一个名为VARE的新颖VAR Erasure框架，通过利用辅助视觉标记来降低微调强度，实现了VAR模型中稳定的概念去除。在此基础上，我们引入了S-VARE，一种专为VAR设计的概念去除方法，它结合了过滤交叉熵损失，以精确识别并最小调整那些不安全的视觉标记，并采用保留损失来保持语义连贯性，从而解决了天真微调导致的语言偏移和多样性减少的问题。
### Conclusion
广泛实验表明，我们的方法实现了对概念的精细去除，同时保持了生成质量，从而通过比早期方法更早的方法解决了概念去除的安全性间隔问题。
## 875. `cs.CV` - FreqDebias: 通过一致性驱动的频域去偏振提高泛化能力的深度假信息检测 [PDF](https://arxiv.org/pdf/2509.22412), [HTML](https://arxiv.org/abs/2509.22412)
### Authors
Hossein Kashiani,Niloufar Alipour Talemi,Fatemeh Afghah
### Background
深度假信息检测器常常难以泛化到新型伪造类型，因为它们可能受到了有限训练数据中偏见的影响。在这项研究中，作者发现了一个新的模型偏见——频域偏见（Spectral Bias），它是由于检测器过度依赖特定的频率带而导致的，限制了其跨未见伪造的泛化能力。
### Innovation
作者提出了一个名为FreqDebias的频域去偏振框架，通过两种互补策略来减轻频域偏见。首先，通过引入一种新颖的伪造Mixup（Fo-Mixup）增强技术，动态地多样化了训练样本的频率特征。其次，引入了双重一致性正则化（Dual Consistency Regularization, CR），通过局部一致性使用类激活图（CAMs）和全局一致性使用超球形嵌入空间上的von Mises-Fisher（vMF）分布来加强一致性监督。
### Conclusion
广泛的实验证明，FreqDebias显著增强了跨领域的泛化能力，并在跨域和领域内设置中都优于最先进的方法。
## 876. `cs.CV` - HierLight-YOLO: 一种适用于无人机摄影的分层轻量化目标检测网络 [PDF](https://arxiv.org/pdf/2509.22365), [HTML](https://arxiv.org/abs/2509.22365)
### Authors
Defan Chen,Yaohua Hu,Luchan Zhang
### Background
在复杂场景中实时检测小型物体（如不足32像素的物体）和保持在资源受限平台上高效的实时性能，是双重挑战。尽管YOLO系列检测器在实时检测大型物体方面取得了卓越的成绩，但在基于无人机的检测场景中，小型物体占主导地位，其检测的假阴性率远高于大型物体场景。因此，网络需要增强对小型对象的实时检测能力。
### Innovation
该论文提出了基于YOLOv8架构的HierLight-YOLO，一种分层特征融合和轻量化模型。引入了分层扩展路径聚合网络（HEPAN），一种通过层次化跨级连接进行多尺度特征融合的方法，以提高小型物体检测准确性。HierLight-YOLO 包括两个创新性的轻量级模块：倒残差深度卷积块 (IRDCB) 和轻量级下采样 (LDown) 模块，显著减少了模型的参数和计算复杂性，同时不牺牲检测能力。Small object detection head被设计用于进一步提高空间分辨率和特征融合，以解决对4像素大小的目标检测。
### Conclusion
在VisDrone2019基准上的比较实验和消融研究显示，HierLight-YOLO达到了最先进的性能。
## 877. `cs.CV` - 大型多模态模型检测虚假信息的有效性：实验结果 [PDF](https://arxiv.org/pdf/2509.22377), [HTML](https://arxiv.org/abs/2509.22377)
### Authors
Yasmina Kheddache,Marc Lalonde
### Background
虚假信息的泛滥成为一个在数字平台上亟待解决的重大问题，特别是在文本和图像结合的多模态环境中更为突出。本文探讨了大型多模态模型（LMMs）在检测和遏制虚假信息方面的潜力。
### Innovation
1. 开发了一种优化的提示，采用了高级提示工程技巧以确保精准和一致的评估；2. 实施了结构化框架用于多模态分析，包括了符合模型令牌限制的图像和文本预处理方法；3. 定义了六种具体评估标准，以实现内容的精细分类，并附带基于信心水平的自我评估机制；4. 在多个异构数据集Gossipcop、Politifact、Fakeddit、MMFakeBench和AMMEBA上进行了全面性能分析，展示了GPT-4o在检测虚假信息方面的优势和局限性；5. 通过重复测试探索了预测变量性，评估了模型分类的稳定性和可靠性；6. 引入了基于信心水平和变量性的评估方法。
### Conclusion
本文提供了一种稳健且可重复的多模态虚假信息自动化分析方法，明确了GPT-4o模型在涉及多模态虚假信息检测时的优势和不足。
## 878. `cs.CV` - 通过内模token交互解释多模态LLM [PDF](https://arxiv.org/pdf/2509.22415), [HTML](https://arxiv.org/abs/2509.22415)
### Authors
Jiawei Liang,Ruoyu Chen,Xianghao Jiao,Siyuan Liang,Shiming Liu,Qunli Zhang,Zheng Hu,Xiaochun Cao
### Background
多模态大型语言模型（MLLMs）已经在各种视觉-语言任务中取得了显著的成功，然而它们的内部决策机制仍然不够清楚。现有的可解释性研究主要集中在跨模态归因上，即确定模型在输出生成过程中关注哪些图像区域。然而，这些方法往往忽视了内模态之间的依赖性。在视觉模态中，如果仅仅将重要性归因于孤立的图像片段，会忽略掉局部感受野的局限性所带来的空间上下文，导致解释碎片化和噪音大。在文本模态中，依赖于前一个标记则会导致虚假激活。这些干扰如果没有得到有效的减轻，会损害归因的准确性。
### Innovation
为了克服这些局限，该研究提出通过内模态交互增强可解释性。对于视觉分支，引入了多尺度解释聚合（MSEA），这是一种多尺度输入上的归因聚合，可以动态调整局部感受野，从而产生更完整和空间上连贯的视觉解释。对于文本分支，提出了一种激活排名相关性（ARC）的方法，通过其前k个预测排名的对齐来衡量上下文标记与当前标记的相关性。ARC利用这种相关性来抑制无关上下文中的虚假激活，同时保持语义连贯的激活。
### Conclusion
该方法在最先进的MLLM和基准数据集上的广泛实验表明，它始终优于现有的可解释性方法，能够提供更忠实和细腻的模型行为解释。
## 879. `cs.CV` - 超越分类准确性：Neural-MedBench和更深层次推理基准的需求 [PDF](https://arxiv.org/pdf/2509.22258), [HTML](https://arxiv.org/abs/2509.22258)
### Authors
Miao Jing,Mengting Jia,Junling Lin,Zhongxia Shen,Lijun Wang,Yuanyuan Peng,Huan Gao,Mingkun Xu,Shangyang Li
### Background
近期视觉-语言模型（VLMs）在医学基准测试中取得了出色的成绩，但它们真正的临床推理能力仍不清楚。现有数据集主要侧重于分类准确率，这种评价中产生的幻觉使得模型看似熟练，但实际上在高风险诊断推理方面仍存在不足。因此，需要一个紧凑但推理密集的基准来测试医学多模态推理的极限，特别是神经科方向。Neural-MedBench正是这样一个基准，它整合了多序列MRI扫描、结构化的电子健康记录和临床笔记，并包含了三个核心任务家族：鉴别诊断、病灶识别和理由生成。
### Innovation
Neural-MedBench 提出了一个新的混合评分管道来确保评估的可靠性，结合了大模型评分、临床医生验证和语义相似性指标。然后对最先进的 VLMs 进行了系统的评估，结果显示与传统数据集相比性能显著下降。错误分析表明，推理失败而不是感知错误主导了模型的缺陷。文章提出了双重评估框架：面向广度的大规模数据集用于统计泛化，以及面向深度的紧凑基准如 Neural-MedBench 用于推理准确度。
### Conclusion
Neural-MedBench 作为一个开放且可扩展的诊断测试平台被发布，这将指导未来基准的扩展并允许低成本且严格的临床可信AI评估。
## 880. `cs.CV` - SSVIF: 自监督语义导向的可见光和红外图像融合 [PDF](https://arxiv.org/pdf/2509.22450), [HTML](https://arxiv.org/abs/2509.22450)
### Authors
Zixian Zhao,Xingchen Zhang
### Background
可见光与红外图像融合（VIF）近年来因其在场景分割和目标检测等任务中的广泛应用而备受关注。传统的VIF方法专注于提升融合图像的质量，而应用导向的VIF方法则通过引入特定任务的损失项，在提升图像质量的同时考虑了下游任务的性能表现。然而，应用导向的VIF方法需要标注下游任务的数据集（如语义分割或目标检测），这增加了数据获取的难度和成本。为解决这一问题，本文提出了一种自监督训练框架（SSVIF），旨在进行基于分割的可见光和红外图像融合。
### Innovation
本文通过引入新自监督任务——任务跨分割一致性，利用特征级融合和像素级融合在分割上的一致性，使融合模型在无需分割标签监督的情况下学习高层语义特征。此外，设计了一种两阶段训练策略及动态权重调整方法，以便在自监督框架内有效地联合学习。广泛的实验表明，SSVIF在公共数据集上的效果显著，即使在仅使用未标注的可见光与红外图像对进行训练的情况下，其性能也超过了传统VIF方法，并接近于监督导向的VIF方法。
### Conclusion
本研究通过提出的自监督训练框架（SSVIF），在不依赖于注释数据集的情况下，显著提升了可见光和红外图像的融合效果。实验数据证明了其在多种任务中优于传统方法的表现。
## 881. `cs.CV` - U-MAN：结合多尺度自适应KAN网络的U-Net在医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2509.22444), [HTML](https://arxiv.org/abs/2509.22444)
### Authors
Bohan Huang,Qianyun Bao,Haoyuan Ma
### Background
医学图像分割面临着保留精细细节和准确边界的重大挑战，这主要是由于复杂的解剖结构和病理区域。传统的U-Net架构面临两大挑战：一是简单跳连忽视了编码器-解码器各特征之间的语义差距，二是缺乏深层多尺度特征提取能力。
### Innovation
本文提出了U-Net与多尺度自适应KAN（U-MAN），这是在新兴的KAN中添加了两种专用模块：渐进注意导向特征融合（PAGF）和多尺度自适应KAN（MAN）。PAGF模块替代了简单的跳连，并利用注意力机制将编码器和解码器的特征融合。MAN模块使网络能够自适应地处理多尺度特征，提高分割不同尺寸对象的能力。
### Conclusion
在三个公开数据集（BUSI, GLAS和CVC）上的实验表明，U-MAN方法在定义准确边界和保留精细细节方面优于现有最先进的技术。
## 882. `cs.CV` - 通过场景分割策略破解文本转视频模型 [PDF](https://arxiv.org/pdf/2509.22292), [HTML](https://arxiv.org/abs/2509.22292)
### Authors
Wonjun Lee,Haon Park,Doehyeon Lee,Bumsub Ham,Suhyun Kim
### Background
随着众多文本转视频（T2V）模型的快速发展，人们对这类模型的安全风险产生了越来越多的关注。虽然最近的研究通过 Jailbreak 攻击探索了如大语言模型（LLMs）、视觉语言模型（VLMs）和文本转图像（T2I）模型的安全漏洞，但 T2V 模型仍鲜少被研究，留下了显著的安全空白。因此，引入了一种新型的黑箱 Jailbreak 方法，名为 SceneSplit，通过将有害脚本分解为多个画面，每个画面单独来看都是无害的，但组合起来会引导最终结果进入一个不安全的区域，从而提高生成有害视频的可能性。这种方法通过迭代的场景操纵进一步增强，绕过了这一受限不安全区域中的安全过滤器。此外，还提出了一种重用成功的攻击模式的策略库，提升了整体攻击的有效性和鲁棒性。为了验证该方法的有效性，论文在 Luma Ray2、Hailuo 和 Veo2 等 11 个安全类别上评估了 SceneSplit，结果显示，其在 Luma Ray2 和 Veo2 上的平均攻击成功率（ASR）分别为 77.2% 和 78.2%，在 Hailuo 上的 ASR 为 84.1%，显著优于现有基线。
### Innovation
论文提出了一种名为 SceneSplit 的新型黑箱 Jailbreak 方法，通过将有害脚本分割成多个无害画面，利用这些画面的组合限制生成空间，从而使攻击产生有害结果的可能性显著增加。此外，还提出了一种重用成功攻击模式的策略库，提高了攻击的整体有效性和鲁棒性。这些方法显著提高了攻击成功率，验证了现有 T2V 安全机制存在漏洞，可以被攻击方法利用叙事结构来破解。
### Conclusion
论文通过验证 SceneSplit 方法在多个 T2V 模型上的有效性，表明当前 T2V 安全机制存在利用叙事结构攻击的安全漏洞，为理解和改进 T2V 模型的安全性提供了新的见解。
## 883. `cs.CV` - $?gamma$-Quant: 旨在实现低位宽可学习量化的方法 [PDF](https://arxiv.org/pdf/2509.22448), [HTML](https://arxiv.org/abs/2509.22448)
### Authors
Mishal Fatima,Shashank Agnihotri,Marius Bock,Kanchana Vaishnavi Gandikota,Kristof Van Laerhoven,Michael Moeller,Margret Keuper
### Background
现有的大多数模式识别模型都是基于预处理的数据开发的。例如，在计算机视觉中，经过图像信号处理（ISP）管道处理并通过设计来满足人类感知需求的RGB图像频繁作为图像分析网络的输入。然而，现代许多视觉任务是在没有人类干预的情况下执行的，这引发了是否应继续使用这种预处理是否对自动化分析最优化的疑问。此外，在人体活动识别（HAR）任务中，通常使用来自高位模拟-数字转换器（ADC）的归一化浮点数据作为输入，尽管这种方法在数据传输效率上极其低下，严重影响了可穿戴设备的电池寿命。因此，本文关注传感器比特深度有限的低带宽和能量限制环境中，目标是在这些受限条件下实现可学习量化。
### Innovation
本文提出了$?gamma$-Quant，这是一种针对特定任务学习非线性量化的方法，适用于模式识别。该方法在原始图像目标检测和基于可穿戴传感器数据的人体活动识别任务中进行了验证，并展示了使用仅4位数的可学习量化与使用12位原始数据效果相当。此外，所有实现本研究实验的代码可在指定网址公开获取。
### Conclusion
在低带宽和能量限制的环境中，传感器能力有限，可以利用本研究中的可学习量化方法来提高数据传输效率和电池寿命。实验证明，通过学习特定任务的非线性量化，可以减少数据的位宽，同时保持与高位宽数据相当的效果。
## 884. `cs.CV` - Bézier Meets Diffusion: 贝塞尔曲线与扩散的结合：医疗图像分割中的稳健跨域生成 [PDF](https://arxiv.org/pdf/2509.22476), [HTML](https://arxiv.org/abs/2509.22476)
### Authors
Chen Li,Meilong Xu,Xiaoling Hu,Weimin Lyu,Chao Chen
### Background
医疗图像跨不同模态学习算法的训练面临着因领域差距大而变得具有挑战性的问题。无监督领域适应性（UDA）通过使用源域的标注图像和目标域的未标注图像来训练深层模型，缓解了这一问题。现有的方法通常依赖基于GAN的风格迁移，但却难以捕捉高变异性区域的跨域映射。
### Innovation
本文提出了一种统一框架，即贝塞尔曲线与扩散的结合（Bézier Meets Diffusion），用于跨域图像生成。首先是使用基于贝塞尔曲线的风格迁移策略，有效缩小了源域和目标域之间的领域差距。其次是使用此分割模型在目标域生成的伪标签来训练条件扩散模型（CDM），生成高质量的、带有标签的目标域图像。为了减轻伪标签噪声的影响，进一步开发了指导性的不确定性分数匹配方法，以改善CDM的鲁棒性训练。
### Conclusion
在公开数据集上的广泛实验表明，我们的方法生成了真实的带有标签的图像，显著扩充了目标域并提高了分割性能。
## 885. `cs.CV` - 动态输出的文本对抗攻击 [PDF](https://arxiv.org/pdf/2509.22393), [HTML](https://arxiv.org/abs/2509.22393)
### Authors
Wenqiang Wang,Siyuan Liang,Xiao Yan,Xiaochun Cao
### Background
传统的文本对抗攻击方法通常针对静态场景，并且假设固定数量的输出标签和预定义的标签空间，它们依赖于对受害者模型的大量查询（查询攻击）或代理模型的查询（转移攻击）。这种有限的范围限制了对抗攻击的有效性和范围。因此，需要新的方法来拓展传统的静态场景，以适应动态输出的场景。另外，通过扩展对抗攻击方法，使其适用于生成任务，可以更好地应对目前的大语言模型的挑战。
### Innovation
文中提出了一种名为Textual Dynamic Outputs Attack (TDOA)的方法，采用聚类基于的代理模型训练方式将动态输出场景转化为静态单输出场景。同时，还提出了一种最远标签目标攻击策略，选择最偏离模型标签的对抗向量，从而最大化干扰效果。此外，通过将翻译任务视为具有无限输出空间的分类问题，将TDOA框架扩展到生成设置，并在RDBLEU和RDchrF指标上超越了前人成果。
### Conclusion
TDOA方法在多种基准数据集和受试模型上（例如ChatGPT-4o和ChatGPT-4.1）取得了显著的有效性，并且在常规静态输出场景下也达到了82.68%的最高对抗成功率。通过减少查询次数至每次文本查询一次，TDOA达到了最高50.81%的攻击成功率，展示了其在大语言模型对抗攻击方面的强大潜力和实际应用价值。
## 886. `cs.CV` - 类别发现：开放世界视角 [PDF](https://arxiv.org/pdf/2509.22542), [HTML](https://arxiv.org/abs/2509.22542)
### Authors
Zhenqi He,Yuanpei Liu,Kai Han
### Background
类别发现（CD）是一项新兴的开放世界学习任务，旨在根据已标记的已知类标签自动对未标记数据进行分类，这些数据包含来自未见类别的实例。该任务近年来引起了广泛关注，形成了大量文献，从不同视角尝试解决这一问题。
### Innovation
本文综述了类别发现的文献，通过引入文献分类税则，针对不同的应用场景设计衍生设置（如持续类别发现、数据分布偏斜、联邦类别发现等），对每种设置下的方法进行了详细分析，涵盖了表示学习、标签分配以及类别数量估计三大基本组件。此外，还对所有方法进行了基准测试，提炼关键见解，表明大规模预训练骨干网络、层次化及辅助提示、以及梯度式训练对类别发现有益，但仍存在标签分配设计、类别数量估计和复杂多对象扩展等挑战。
### Conclusion
本文总结了文献中的关键洞察，并指出未来研究方向，编纂了一个持续更新的类别发现文献综述。本文链接位于：this https URL
## 887. `cs.CV` - HyCoVAD: 一个结合SSL-LLM的复杂视频异常检测模型 [PDF](https://arxiv.org/pdf/2509.22544), [HTML](https://arxiv.org/abs/2509.22544)
### Authors
Mohammad Mahdi Hemmatyar,Mahdi Jafari,Mohammad Amin Yousefi,Mohammad Reza Nemati,Mobin Azadani,Hamid Reza Rastad,Amirmohammad Akbari
### Background
视频异常检测（VAD）在智能监控中至关重要，但复杂异常检测是一个显著挑战。这些异常是由多个实体之间复杂的时空关系和时间依赖性定义的事件，而不仅仅是孤立的动作。自我监督学习（SSL）方法能够建模低级别的时空模式，但在理解这些交互的语义意义方面存在局限。另一方面，大规模语言模型（LLMs）提供了强大的上下文推理能力，但由于逐帧分析计算量大且缺乏细粒度的空间定位，这限制了它们的应用。
### Innovation
我们提出了HyCoVAD（Hybrid Complex Video Anomaly Detection），这是一个结合多任务SSL时空分析器和LLM验证器的混合模型。SSL模块基于nnFormer骨干（一种用于图像分割的基于变换器的模型），通过多代理任务训练，能够识别疑似异常的视频帧。被选中的帧随后传递给LLM，通过应用结构化的基于规则的推理来增强分析并验证异常的存在。在具有挑战性的ComplexVAD数据集上的实验表明，HyCoVAD在帧级AUC上达到72.5%，比现有基线高出12.5%，同时减少了LLM的计算量。
### Conclusion
实验结果表明HyCoVAD在复杂VAD场景中表现出色，通过结合SSL模块和LLM模块，能够有效检测复杂事件，同时显著减少了LLM的计算量。我们还发布了交互异常分类法、自适应阈值协议和代码，以促进未来在复杂VAD领域的研究。
## 888. `cs.CV` - LucidFlux：大规模扩散变换器实现无提示统一图像恢复 [PDF](https://arxiv.org/pdf/2509.22414), [HTML](https://arxiv.org/abs/2509.22414)
### Authors
Song Fei,Tian Ye,Lujia Wang,Lei Zhu
### Background
统一图像恢复（UIR）旨在恢复由于未知混合物降级但仍保留语义的图像。现有的辨别式恢复方法和基于UNet的扩散先验常会导致过度平滑、错构或漂移的问题。论文背景聚焦于解决这些技术在处理图像恢复任务时所出现的问题，并引入了一种全新的无提示框架来改善这一状况，该框架无需使用图像说明即可实现高质量的图像恢复。
### Innovation
该研究提出了LucidFlux，一种无提示的UIR框架，它使用大规模扩散变换器（Flux.1）来适应图像降级输入和轻度恢复的代理。同时，它设计了一种轻量级的双重分支调节器，分别注入信号以锚定几何结构并抑制伪影。此外，还设计了一种时间步长和层自适应的调节计划，以实现分层的细粒度和上下文感知更新，从而保护全局结构和恢复细节。为了避免文本提示或MLLM说明的延迟和不稳定性问题，它通过从代理中提取的SigLIP特征实现无提示的语义对齐。此外，提出了一个可扩展的数据整理流水线来进一步筛选大规模数据以提供丰富的结构监督。研究还通过消融研究验证了每个组件的必要性，展示了在多种基准测试上的优势。
### Conclusion
研究证明，通过大规模扩散模型调节条件的基础时间和位置选择，而非增加参数或依赖于文本提示，是实现强健且无需提示统一图像恢复的关键。LucidFlux框架在合成和野外基准测试中表现出色，并证明了各个组件的重要性。
## 889. `cs.CV` - RAU: 通过视觉语言模型实现参考导向的解剖理解 [PDF](https://arxiv.org/pdf/2509.22404), [HTML](https://arxiv.org/abs/2509.22404)
### Authors
Yiwei Li,Yikang Liu,Jiaqi Guo,Lin Zhao,Zheyuan Zhang,Xiao Chen,Boris Mailhe,Ankush Mukherjee,Terrence Chen,Shanhui Sun
### Background
通过深度学习理解解剖学结构对自动报告生成、术中导航和医学影像中的器官定位至关重要，但进展受限于专家标注数据的稀缺性。一种有希望的解决方案是利用注释参考图像来指导未标注目标的解释。虽然最近的视觉-语言模型（VLMs）展示了非平凡的视觉推理能力，但在参考导向理解和细粒度定位方面仍有限制。
### Innovation
我们提出了RAU，一种基于视觉语言模型的知识框架，用于参考导向的解剖理解。研究表明，VLM能够通过参考和目标图像之间的相对空间推理学习识别解剖区域。我们展示了VLM获取的空间线索可以无缝集成与SAM2的细粒度分割能力，从而实现小解剖区域（如血管段）的定位和像素级分割。RAU在两种内部分布和两种外部分布数据集中始终优于使用相同内存配置的SAM2微调基准，提供更准确的分割和更可靠的定位。该模型的强泛化能力使其适用于外部分布数据集，对于医学影像应用至关重要。这是首次探索VLMs在医学影像中参考导向识别、定位和分割解剖结构的能力。其有希望的表现突显了基于VLM的方法在自动化临床工作流程中进行解剖学理解的潜力。
### Conclusion
RAU在两组内部分布数据集和两组外部分布数据集中均优于SAM2微调基准，通过在知识框架中结合VLM的边缘检测能力，实现了高准确度的分割和可靠定位，显示出在医学图像应用中扩展的潜力。此外，RAU是首个探索VLMs在医学影像中进行参考导向识别、定位和分割解剖结构的研究。
## 890. `cs.CV` - Vision-Language Models中的颜色名称 [PDF](https://arxiv.org/pdf/2509.22524), [HTML](https://arxiv.org/abs/2509.22524)
### Authors
Alexandra Gomez-Villa,Pablo Hernández-Cámara,Muhammad Atif Butt,Valero Laparra,Jesus Malo,Javier Vazquez-Corral
### Background
色彩是人类视觉感知的基本维度，也是传达物体和场景信息的主要手段。随着视觉语言模型（VLMs）的日益普及，了解它们是否像人类一样命名颜色对于有效的人机交互至关重要。本文对957种颜色样本在五种代表性模型上的颜色命名能力进行了首次系统性的评估，发现了VLMs在经典颜色研究中的原型颜色上有高准确率，但在扩展的、非原型颜色集合上的表现显著下降。文章还分析了九种语言中的训练偏差，并揭示了颜色命名决策主要由色调驱动。
### Innovation
文章是首次系统评估VLMs的颜色命名能力，使用了957种颜色样本和五种代表性模型，发现在原型颜色方面表现出色但在非原型颜色集合上表现较差。文章通过跨语言分析揭示了训练偏差，并发现色调是颜色命名决策的主要驱动力。进一步的实验表明，语言模型架构对颜色命名的影响独立于视觉处理能力。
### Conclusion
VLMs在原型颜色命名方面表现良好，但在非原型颜色集合上的表现明显下降，存在训练偏差，特别是有利于英语和汉语的训练。语言模型架构对颜色命名有显著影响，这独立于它们的视觉处理能力。
## 891. `cs.CV` - PSTTS: 一种用于高效事件时空表示学习的即插即用Token选择器 [PDF](https://arxiv.org/pdf/2509.22481), [HTML](https://arxiv.org/abs/2509.22481)
### Authors
Xiangmo Zhao,Nan Yang,Yang Wang,Zhanwen Liu
### Background
主流的事件驱动的空间-时间表示学习方法通常通过将事件流转换为事件帧序列来处理，取得了显著的效果。然而，这些方法忽视了事件帧序列中固有的高空间稀疏性和帧间运动冗余，导致了巨大的计算开销。现有的基于RGB视频的令牌稀疏化方法依赖于中间不可靠的令牌表示，并忽略事件噪声的影响，这使得它们不能直接应用于事件数据。
### Innovation
本文提出了Progressive Spatio-Temporal Token Selection（PSTTS），这是一种无需引入额外参数的即插即用模块，用于事件数据。PSTTS通过利用原始事件数据中嵌入的空间-时间分布特性来有效识别和丢弃空间-时间冗余令牌，实现了准确性和效率之间的最优权衡。具体来说，PSTTS包括两个阶段：空间令牌净化和时间令牌选择。这两个阶段分别通过空间内时间一致性评估来剔除噪声和非事件区域，以及通过相邻事件帧之间的运动模式相似性评估来精确识别和移除冗余的时间信息。
### Conclusion
我们将在UniformerV2、VideoSwin、EVMamba和ExACT上将PSTTS应用于四个代表性骨干网络，并在HARDVS、DailyDVS-200和SeACT等数据集上进行实验。实验结果表明，PSTTS显著提高了效率。具体而言，在DailyDVS-200数据集上，PSTTS将FLOPs减少了29-43.6%，FPS提高了21.6-41.3%，同时保持了任务准确率。我们的代码将可供使用。
## 892. `cs.CV` - EfficientDepth：一种快速且细节保留的单目深度估计模型 [PDF](https://arxiv.org/pdf/2509.22527), [HTML](https://arxiv.org/abs/2509.22527)
### Authors
Andrii Litvynchuk,Ivan Livinsky,Anand Ravi,Nima Kalantari,Andrii Tsarov
### Background
单目深度估计（MDE）在机器人、增强现实和自动驾驶等计算机视觉应用中发挥着重要作用。尽管取得了一些进展，但现有方法往往无法满足3D重建和视图合成的关键要求，如几何一致性、细微差别、对真实世界挑战（如反射表面）的鲁棒性以及边缘设备的效率。
### Innovation
我们引入了一种名为EfficientDepth的新MDE系统，它结合了变压器架构和轻量级卷积解码器，以及双模密度头，使网络能够估计详细的深度图。我们采用组合标有合成和真实图像以及使用高性能MDE方法生成的伪标记的真实图像来训练模型，并使用多阶段优化策略提高训练效率，生成强调几何一致性和细微差别的模型。此外，我们还引入了一种基于LPIPS的损失函数，鼓励网络生成详细的深度图。实验结果显示，EfficientDepth在计算资源显著减少的情况下，实现了与现有最先进的模型相当或更优的性能。
### Conclusion
实验结果表明，EfficientDepth在计算资源显著减少的情况下，实现了与现有最先进的模型相当或更优的性能。
## 893. `cs.CV` - MLLMs所关注的内容及其依赖项：解释自回归token生成 [PDF](https://arxiv.org/pdf/2509.22496), [HTML](https://arxiv.org/abs/2509.22496)
### Authors
Ruoyu Chen,Xiaoqing Guo,Kangwei Liu,Siyuan Liang,Shiming Liu,Qunli Zhang,Hua Zhang,Xiaochun Cao
### Background
多模态大型语言模型（MLLMs）展示了将视觉输入与自然语言输出对齐的能力。然而，生成的token在多大程度上依赖于视觉模态尚不清楚，这限制了模型的可解释性和可靠性。因此，需要一个模型解释框架来更深入地理解视觉信息对生成token的影响，从而提高模型的透明度和信任度。
### Innovation
EAGLE是一种轻量级的黑盒框架，旨在解释MLLMs的自回归token生成过程。EAGLE通过将任何选定的token与紧凑的感知区域相关联，并量化语言先验和感知证据的相对影响。它引入了统一充分性和必要性（通过贪婪搜索稀疏化图像区域优化）的客观函数，从而实现忠实高效的归因。EAGLE还进行模态感知分析，以区分token依赖于的内容，从而提供细致的解释性。实验结果表明，EAGLE在忠诚度、定位和诊断幻觉方面优于现有方法，同时需要较少的GPU内存。这突显了其在提高MLLMs可解释性方面的有效性和实用性。
### Conclusion
EAGLE在多个开源MLLMs上的广泛应用和实验结果表明，它可以提供更高的可解释性和实用性，从而推动MLLMs的进一步发展和应用。此外，EAGLE的代码可以在这里获得。
## 894. `cs.CV` - Group Critical-token Policy Optimization for Autoregressive Image Generation [PDF](https://arxiv.org/pdf/2509.22485), [HTML](https://arxiv.org/abs/2509.22485)
### Authors
Guohui Zhang,Hu Yu,Xiaoxiao Ma,JingHao Zhang,Yaning Pan,Mingde Yao,Jie Xiao,Linjiang Huang,Feng Zhao
### Background
近期的研究将可验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards, RLVR）扩展到了自回归（Autoregressive, AR）视觉生成，并取得了显著进展。然而，现有的方法通常在整个图像标记上应用统一的优化，而不同图像标记在RLVR训练中的不同贡献仍未被探索。实际上，关键障碍是如何在AR生成过程中识别出更重要的图像标记并实现有效的标记级优化。
### Innovation
本文提出了Group Critical-token Policy Optimization（GCPO），这是一种在关键标记上实现有效策略优化的方法。GCPO从三个方面确定了在基于RLVR的AR生成中的关键标记：因单向依赖而决定了后续标记和最终图像效果的因果依赖；与高熵梯度相关，对应于图像结构和不同视觉区域的连接的熵诱导空间结构；以及对一组采样图像具有低视觉相似性的标记，有助于增强标记级别的多样性。此外，GCPO引入了一个基于策略模型和参考模型之间置信度差异的动态标记级优势权重，以鼓励探索。使用图像标记的30%，GCPO在性能上优于使用完整标记的GRPO。在多个文本到图像基准测试中，GCPO在多种AR模型和统一多模态模型上均证明了其有效性。
### Conclusion
GCPO通过有效利用关键标记，并引入动态标记级别的优势权重来促进探索，显著提高了自回归图像生成的性能。实验结果表明，GCPO在多个基准测试中表现优异，证明了其在AR视觉生成中的有效性。
## 895. `cs.CV` - SpikeMatch：基于脉冲神经网络时序动态的半监督学习 [PDF](https://arxiv.org/pdf/2509.22581), [HTML](https://arxiv.org/abs/2509.22581)
### Authors
Jini Yang,Beomseok Oh,Seungryong Kim,Sunok Kim
### Background
脉冲神经网络（SNNs）因其生物可塑性和能源效率吸引了广泛关注，但与人工神经网络（ANNs）相比，基于SNN的模型的半监督学习（SSL）方法尚未得到充分探索。现有SSL方法在SNN骨干网络上的应用仍然相对较少，因此需要开发新的方法来弥补这一空白，以有效提升基于SNN的模型性能并充分利用可用标签有限的半监督数据集中的信息。
### Innovation
提出了SpikeMatch，第一个利用SNN泄漏因子的时序动态在协同训练框架中进行多样伪标签生成的半监督学习框架。通过利用单一SNN从多个预测中的共识来生成可靠的伪标签，从而对部分增强的未标记样本进行训练，并在极大多数增强样本上进行精炼。这种方法能够捕捉有限标签集中的有鉴别性的特征，有效缓解确认偏差。
### Conclusion
实验结果显示，SpikeMatch在标准基准测试中显著优于现有适应SNN结构的SSL方法，证明了利用SNN时序动态进行伪标签生成的有效性。
## 896. `cs.CV` - UML-CoT: 使用统一建模语言进行机器人房间清洁的结构化推理和规划 [PDF](https://arxiv.org/pdf/2509.22628), [HTML](https://arxiv.org/abs/2509.22628)
### Authors
Hongyu Chen,Guangrun Wang
### Background
Chain-of-Thought (CoT) 提升了大型语言模型的推理能力，但依赖于非结构化的文本限制了其在具身任务中的解释性和执行性。尽管之前的工作探索了使用场景图或逻辑图的结构化 CoT，但这些方法仍然存在根本性的限制：它们只能建模低阶关系、缺乏继承或行为抽象的概念，并且没有为顺序或条件计划提供统一的标准语义。
### Innovation
我们提出了 UML-CoT，这是一种利用统一建模语言 (UML) 的结构化推理和规划框架，用于生成符号化 CoT 和可执行的行为计划。UML 类图捕捉组合对象语义，而活动图则建模过程控制流。我们采用三阶段训练管线，结合监督微调和组相对策略优化 (GRPO)，包括仅从答案学习奖励。
### Conclusion
UML-CoT 在 MRoom-30k 基准测试中表现出色，超越了非结构化的 CoT 在解释性、计划连贯性和执行成功率方面的表现，突显了 UML 作为一种更具表现力和可操作性的结构化推理形式的重要性。
## 897. `cs.CV` - Labeling Copilot: 自动化计算机视觉数据策展的深度研究代理 [PDF](https://arxiv.org/pdf/2509.22631), [HTML](https://arxiv.org/abs/2509.22631)
### Authors
Debargha Ganguly,Sumit Kumar,Ishwar Balappanawar,Weicong Chen,Shashank Kambhatla,Srinivasan Iyengar,Shivkumar Kalyanaraman,Ponnurangam Kumaraguru,Vipin Chaudhary
### Background
构建高质、领域特定的数据集是部署稳健视觉系统的重大瓶颈，需在数据质量、多样性和成本之间复杂的权衡，尤其是处理海量未标记的数据湖时。现有的数据策展方法存在复杂度高、成本高昂的问题。
### Innovation
提出了一种名为Labeling Copilot的数据策展深度研究代理，由一个强大的多模态语言模型驱动的中心协调器使用多步推理执行三个核心能力：（1）校准发现——从大型仓库中发现相关且在分布的数据；（2）可控合成——生成新颖数据并包含高效的过滤；（3）一致性标注——通过非最大抑制和投票机制协调多个基础模型生成准确标签。此外，Labeling Copilot还在大规模验证中展示了其在目标发现上的有效性，特别是在密集的COCO数据集上实现了37.1%的最终注释mAP。同时，Calibrated Discovery工具也展示了高效的主动学习策略，比现有的具有同等样本效率的方法更节省计算资源。
### Conclusion
研究表明，优秀的代理工作流与优化、可扩展的工具相结合，为大规模数据集的策展提供了坚实的基础。Labeling Copilot通过多模态语言模型和高效的数据策展方法，在自动化数据策展领域展现出巨大潜力。
## 898. `cs.CV` - 使用2D高斯斑点从压缩图像表示实现视觉-语言对齐 [PDF](https://arxiv.org/pdf/2509.22615), [HTML](https://arxiv.org/abs/2509.22615)
### Authors
Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe
### Background
现代视觉语言管道依赖于在大量图像文本数据集上训练的RGB视觉编码器，以驱动其功能。尽管这些管道在零样本能力和跨任务迁移方面表现出色，但它们仍然继承了两个来自像素领域结构上的不足：(i) 从边缘设备向云端传输密集的RGB图像耗费大量的能量和成本，(ii) 基于补丁的分词导致序列长度爆炸性增加，使得注意力预算和上下文限制受到压力。
### Innovation
本文探索了2D高斯斑点（2DGS）作为一种替代的视觉基础，替代标准的RGB图像。2DGS提供了一个既紧凑又空间自适应的表示方式，通过一组颜色各向异性的高斯函数参数化图像。作者开发了一个可扩展的2DGS管道，具备结构化初始化、亮度感知剪枝和批量CUDA内核，将 fittings速度提高超过90倍，并且GPU利用率约为97%。此外，还将对比语言图像预训练（CLIP）适应2DGS，通过冻结基于RGB的Transformer主干，并使用一个轻量级的斑点感知输入茎和感知重构器，仅训练约7%的参数。
### Conclusion
在大规模DataComp子集上，2DGS编码器提供了有意义的零样本ImageNet-1K性能，同时将输入压缩了3到20倍，相比像素。虽然在准确率上不如RGB编码器，但本文结果表明2DGS是一个有前景的多模态基础，在提升语义能力和传输效率方面具有潜力，为边缘云学习开辟了一条道路。
## 899. `cs.CV` - JanusVLN: 使用双隐式记忆拆分语义与空间性的视觉-语言导航 [PDF](https://arxiv.org/pdf/2509.22548), [HTML](https://arxiv.org/abs/2509.22548)
### Authors
Shuang Zeng,Dekang Qi,Xinyuan Chang,Feng Xiong,Shichao Xie,Xiaolong Wu,Shiyi Liang,Mu Xu,Xing Wei
### Background
视觉-语言导航（VLN）要求智能体在未见过的环境中根据自然语言指令和连续视频流进行导航。近期VLN的发展得益于多模态大型语言模型的强大语义理解能力，但这些方法通常依赖于显式的语义记忆，如建造文本认知地图或存储历史视觉帧。这种方法存在空间信息丢失、计算冗余和内存膨胀的问题，这些因素阻碍了智能体的高效导航。
### Innovation
本文提出了JanusVLN，引入了一种新的VLN框架，该框架采用双隐式神经记忆，将空间-几何和视觉-语义记忆作为两个独立、紧凑且固定大小的神经表示进行建模。该框架首先扩展了多模态大型语言模型，结合了来自空间-几何编码器的3D先验知识，从而增强了仅基于RGB输入进行空间推理的能力，然后构建了来自空间-几何和视觉-语义编码器的历史关键-值缓存，形成双隐式记忆。通过仅保留初始和滑动窗口中的关键-值，避免了冗余计算，实现了高效的增量更新。实验结果表明，JanusVLN 在20多种方法中表现出色，取得了SOTA性能。成功率相较使用多种数据类型作为输入的方法提高了10.5-35.5%，相较使用更多RGB训练数据的方法提高了3.6-10.8%，这表明提出的双隐式神经记忆作为一种新的范式，为未来的VLN研究开辟了新的方向。
### Conclusion
JanusVLN作为一种新的创新框架，通过引入两个独立的隐式内存，解决了传统方法中的空间信息丢失、计算冗余和内存膨胀等问题，显著提高了视觉-语言导航的效率和性能。
## 900. `cs.CV` - 长命：实现实时互动长视频生成 [PDF](https://arxiv.org/pdf/2509.22622), [HTML](https://arxiv.org/abs/2509.22622)
### Authors
Shuai Yang,Wei Huang,Ruihang Chu,Yicheng Xiao,Yuyang Zhao,Xianbang Wang,Muyang Li,Enze Xie,Yingcong Chen,Yao Lu,Song Han,Yukang Chen
### Background
长视频的生成面临着效率和质量的双重挑战。扩散模型和扩散强迫模型虽然可以生成高质量的视频，但由于双向注意机制效率较低。因果注意机制的自回归模型虽然可以利用关键值缓存来提高推理速度，但在长视频训练中由于内存限制，质量往往会下降。此外，除了基于静态提示的生成之外，交互能力对于动态内容创作至关重要，可以实现实时叙事的引导。这种交互要求进一步增加了复杂性，特别是在提示过渡过程中保持视觉一致性和语义连贯性方面。
### Innovation
LongLive提出了一个因果、帧级自回归框架，整合了KV刷新机制以确保平滑和紧贴的过渡，支持长视频训练以确保训练和推理的一致性（train-long-test-long），并使用帧级注意力机制来进行快速生成。通过这些关键设计，LongLive能够将一个1.3亿参数的短片段模型微调为一分钟长度的生成，在32个GPU天内完成。在推理阶段，LongLive在一张NVIDIA H100上保持20.7 FPS的速度，同时在VBench上实现了从短到长视频的优异性能。LongLive还支持在单张H100 GPU上处理长达240秒的视频，并且对于INT8量化推理有轻微的质量损失。
### Conclusion
LongLive实现了实现实时和互动长视频生成的目标。通过优化的框架和机制，成功解决了传统方法中的效率和质量问题，并支持了高效的长视频生成和实时交互需求，显示了在多个视频评估基准上的强性能表现和高效性。
## 901. `cs.CV` - CCNeXt: 一种有效的自监督立体深度估计方法 [PDF](https://arxiv.org/pdf/2509.22627), [HTML](https://arxiv.org/abs/2509.22627)
### Authors
Alexandre Lopes,Roberto Souza,Helio Pedrini
### Background
立体深度估计在最近的机器人、自动驾驶车辆和增强现实应用中起到了关键作用。这些场景通常受到计算能力的限制。立体图像对提供了深度估计的有效解决方案，因为它只需要在图像对中估计像素的视差来确定已知矫正系统中的深度。由于在不同场景中收集可靠的真实深度数据比较困难，自监督技术在拥有大量未标记数据时出现作为解决方案。
### Innovation
本文提出了一种新颖的自监督卷积方法CCNeXt，它在平衡计算成本的同时优于现有的最先进的卷积神经网络（CNNs）和视觉转变器（ViTs）。CCNeXt架构采用了现代CNN特征提取器，并在编码器中引入了新颖的窗口式epipolar交叉注意力模块，同时对深度估计解码器进行了全面重新设计。实验表明，CCNeXt在KITTI Eigen Split测试数据上的指标与当前最好的模型相比快了10.18倍，并在KITTI Eigen Split改进Ground Truth和Driving Stereo数据集的所有指标上达到了最先进的结果。
### Conclusion
CCNeXt在更具挑战性的数据集上达到了最佳性能，与此同时保持了高效的计算速度。
## 902. `cs.CV` - CapRL: 通过强化学习激发密集图像描述能力 [PDF](https://arxiv.org/pdf/2509.22647), [HTML](https://arxiv.org/abs/2509.22647)
### Authors
Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin
### Background
图像描述是将视觉和语言领域连接起来的基本任务，对于大型视觉-语言模型的预训练至关重要。当前最先进的图像描述模型通常通过监督微调（SFT）进行训练，这种做法依赖于昂贵且难以扩展的人工或专有模型标注的数据。这种方法可能导致模型过度学习特定的答案，限制了其生成多样、创造性强的描述的能力。
### Innovation
为了克服SFT的限制，该研究提出了将可验证奖励的强化学习（RLVR）应用于开放式图像描述任务。面对主观性带来的挑战，研究者引入了Captioning Reinforcement Learning（CapRL），通过其用途重新定义了描述质量：高质量的描述应该能够让非视觉语言模型基于描述准确回答图像相关的问题。CapRL设计了一种脱钩的两阶段流水线，其中LVLM生成描述，目标奖励源自独立的、无视觉的LLM基于该描述回答多项选择题的准确性。
### Conclusion
作为首次将RLVR应用于主观的图像描述任务的研究，实验结果表明，CapRL在多个设置中显著提高了性能。Pretraining基于CapRL-5M描述数据集（由CapRL-3B标注），在12个基准测试中取得显著进步。此外，在Prism框架下的描述质量评估中，CapRL达到与Qwen2.5-VL-72B相当的性能，同时平均超过基线8.4%。
## 903. `cs.CV` - RefAM: 用于零样本引用分割的注意力磁体 [PDF](https://arxiv.org/pdf/2509.22650), [HTML](https://arxiv.org/abs/2509.22650)
### Authors
Anna Kukleva,Enis Simsar,Alessio Tonioni,Muhammad Ferjad Naeem,Federico Tombari,Jan Eric Lenssen,Bernt Schiele
### Background
现有的大多数引分割方法要么通过微调实现高质量的表现，要么通过组合多个预训练模型实现，但这常常需要额外的训练和架构修改。同时，大规模生成扩散模型能够编码丰富的语义信息，使其作为通用特征提取器具有吸引力。然而，这些方法通常要进行架构修改或额外训练。
### Innovation
该论文提出了一种新的方法——直接利用扩散变换器的特征和注意力得分来执行下游任务，无需进行架构修改或额外训练。作者通过引入停止词（即注意力磁体）的概念，并提出了一种注意力再分配策略，将背景激活分割为更小的簇，生成更锐利和准确的热图。此外，还提出了处理全局注意吸管（GAS）的策略，通过抑制或重新分配这些吸管到辅助标记，提高了分割精度。
### Conclusion
在零样本引分割基准测试中，该方法在不进行微调或添加额外组件的情况下，持续超越了先前的方法，建立了新的领先水平。
## 904. `cs.CV` - SPARK: 协同策略和奖励共生框架 [PDF](https://arxiv.org/pdf/2509.22624), [HTML](https://arxiv.org/abs/2509.22624)
### Authors
Ziyu Liu,Yuhang Zang,Shengyuan Ding,Yuhang Cao,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang
### Background
近年来，大语言模型（LLMs）和大视觉语言模型（LVLMs）越来越多地使用强化学习（RL）进行后训练。例如，使用可验证奖励的强化学习（RLVR）以完成客观任务，使用人类反馈的强化学习（RLHF）以处理主观任务。然而，RLHF面临高额成本以及奖励策略不匹配的风险，而RLVR仍存在监督滥用的问题，每次更新后会丢弃回放和正确性信号。针对这些挑战，作者提出了一种新的方法SPARK，进一步基于RLVR，通过回收卷积及正确性数据同时训练模型本身作为生成奖励模型，消除了单独的奖励模型和昂贵的人类偏好数据的需求。这种方法形成了一种正面的共生反馈循环：改进的奖励准确性产生更好的策略梯度，进而产生更高质量的回放，进一步优化奖励模型。
### Innovation
SPARK框架通过回收RLVR中的卷积及正确性数据，将其作为辅助训练数据，同时训练模型作为生成奖励模型。这种训练方法使用多种目标，如点奖励评分、配对比较和基于进一步反思响应的评估，以教模型自我评估和改进其响应。这种方法取代了单独的奖励模型和昂贵的人类偏好数据，形成了一个优化的共生反馈循环，提高了策略梯度的质量，进而优化了回放，提高了整体模型性能。
### Conclusion
SPARK框架支持自省测试规模放大而无需外部奖励模型和相关成本。实验结果表明，与基线相比，SPARK在多个LLM和LVLM模型、多个推理、奖励模型和常规基准测试中实现了显著的性能提升，表明了其稳健性和广泛的适用性。例如，SPARK-VL-7B在7个推理基准中平均取得了9.7%的性能提升，在2个奖励基准测试中取得了12.1%的提升，在8个通用基准测试中取得了1.5%的提升。
## 905. `cs.CV` - VISION: 基于不完整观测的海洋垂直速度重建提示 [PDF](https://arxiv.org/pdf/2509.21477), [HTML](https://arxiv.org/abs/2509.21477)
### Authors
Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang
### Background
地球科学领域长久以来受到缺乏标准化分析基准的困扰，从不完整的表层观测重建海底洋流等动态信息是一个关键挑战。尽管存在这个问题，但在没有系统的方法之前，缺乏有效的解决方案和基准来推动相关研究。
### Innovation
我们首次构建并发布了KD48，这是一种高分辨率海洋动力学基准，来源于大规模模拟，并通过专家驱动的去噪进行维护。在此基础上，我们提出了VISION，一种基于动态提示的新重建范式，专门针对真实世界观测中缺失数据的问题。VISION的核心在于能够从任何可用的观测子集自动生成视觉提示，该提示包含了数据可用性和海洋物理状态的信息。此外，我们设计了状态条件提示模块，能够高效地将此提示注入具有几何和尺度感知操作的通用骨架中，从而指导其自适应调整计算策略，以应对输入组合变化带来的挑战。实验表明，VISION不仅在性能上显著优于现有模型，还能够在极端数据缺失场景中展现出强大的泛化能力。
### Conclusion
通过提供高质量的数据基准和坚固的模型，我们的研究为在数据不确定性条件下开展海洋科学研究奠定了坚实的基础设施。我们的代码可以在以下链接获取：this https URL.
## 906. `cs.CV` - 规模级VAR实际上是离散扩散 [PDF](https://arxiv.org/pdf/2509.22636), [HTML](https://arxiv.org/abs/2509.22636)
### Authors
Amandeep Kumar,Nithin Gopalakrishnan Nair,Vishal M. Patel
### Background
自回归（AR）变压器已发展成为视觉生成的一个强大范式，主要得益于其可扩展性、计算效率以及能够统一语言与视觉处理的架构。其中，最近的下一级预测视觉自回归生成（VAR）展示了卓越的性能，甚至超越了基于扩散模型的方法。本文重新审视了VAR，并揭示了一个理论洞察：当配备马尔可夫注意力掩码时，VAR在数学上等同于离散扩散模型。这一重新定义叫作可扩展视觉精炼与离散扩散（SRDD），建立了AR变压器与扩散模型之间的原则性联系。
### Innovation
新的视角揭示了VAR和离散扩散之间的等效性，这为直接引入扩散模型的优势（如迭代精炼）并减少AR变压器的架构效率问题提供了契机。作者通过这种方式实现了更快的收敛速度、较低的推理成本和改进的零样本重建。
### Conclusion
从扩散模型的角度看VAR，在多个数据集上显示出一致的效率和生成性能提升。
## 907. `cs.CV` - 基于CLIP的分层表示匹配对于类增量学习 [PDF](https://arxiv.org/pdf/2509.22645), [HTML](https://arxiv.org/abs/2509.22645)
### Authors
Zhen-Hao Wen,Yan Wang,Ji Feng,Han-Jia Ye,De-Chuan Zhan,Da-Wei Zhou
### Background
类增量学习（CIL）旨在使模型能够连续适应不断变化的数据流。最近，预训练的视觉-语言模型（如CLIP）为这一任务提供了强大的基础。然而，现有的方法往往依赖于简单的模板，例如“一张[CLASS]的照片”，这忽略了视觉概念的分层性质。例如，识别“猫”和“汽车”依赖于粗粒度的线索，而区分“猫”和“狮子”则需要细粒度的细节。此外，CLIP当前的特征映射仅依赖于最后一层的表示，忽视了包含在早期层中的分层信息。
### Innovation
本文引入了基于CLIP的分层表示匹配(HiErarchical Representation MAtchiNg，HERMAN)方法，通过利用LLMs来递归生成区分性文本描述符，从而扩充了语义空间并植入了显式的分层线索。这些描述符与不同级别的语义层次匹配，并根据特定任务要求适应性地路由，以实现精确区分并缓解增量任务中的灾难性遗忘问题。
### Conclusion
在多个基准上的广泛实验表明，本文的方法能够在增量学习任务中实现最优性能，并且能够连续保持学习能力，不受先前知识的影响。
## 908. `cs.CV` - 无训练的双IP-Adapter引导合成数据生成 [PDF](https://arxiv.org/pdf/2509.22635), [HTML](https://arxiv.org/abs/2509.22635)
### Authors
Luc Boudier,Loris Manganelli,Eleftherios Tsonis,Nicolas Dufour,Vicky Kalogeiton
### Background
由于标注样本的稀缺性，少量样本学习（Few-shot）图像分类依然具有挑战性。虽然最近的方法利用文本到图像的生成模型生成合成训练数据，但通常需要大量的模型微调或外部信息源。此外，这些方法往往依赖生成模型的适配或外部工具进行标记和图像筛选，增加了复杂性并带来了额外的负担。该研究提出了一种无训练的全新方法DIPSY，采用IP-Adapter进行图像到图像的翻译，仅依赖少量可用的标注样本生成高区分度的合成图像，无需微调模型或外部信息源。
### Innovation
DIPSY引入了三大核心创新：(1) 扩展的无分类器引导方案，允许独立控制正负图像引导；(2) 基于类相似性采样策略，识别有效的对比示例；(3) 一种无需模型微调或外部编辑标注和筛选的简单而有效的流程。实验表明，该方法在十个基准数据集上实现了最先进的或可比的性能，在没有任何生成模型调整或对外部图像生成和过滤工具依赖的情况下，证明了利用正负引导进行双图像提示生成类区分特征的有效性，特别适用于细粒度分类任务。
### Conclusion
实验结果表明，DIPSY在多个图像分类基准数据集上实现了最先进的或可比的性能，同时消除了对外部工具的依赖，解决了生成模型适应和标记图像筛选的问题，强调了正负引导结合双图像提示在生成类区分特征中的有效性，尤其是在细粒度分类任务中的应用。
## 909. `cs.CV` - 通过多模态LLM学习人工智能生成视频中的感知假象 [PDF](https://arxiv.org/pdf/2509.22646), [HTML](https://arxiv.org/abs/2509.22646)
### Authors
Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch
### Background
视频生成模型技术已经取得了快速进展，但人类是否能够识别这些生成视频中的深伪痕迹（即揭示视频为机器生成的空间-时间相关的视觉特征）还很少被研究。研究者们意识到这一重要维度在当前研究中的缺失。因此，他们开发了一个新的基准DeeptraceReward，该基准详细标注了人类感知的生成视频中的假象，用于视频生成的奖励模型。该数据集包含超过3300个高质量生成视频的详细注解，每个注解还包括边界框、自然语言解释以及准确的时间戳。基于这些注解，他们进一步提取了9类主要的深伪痕迹类别，并利用多模态语言模型作为奖励模型来学习和模拟人类的判断和定位。
### Innovation
作者提出了DeeptraceReward，这是第一个细粒度且空间时间意识的基准，详细标注了人类感知的生成视频中的假象。他们训练了跨模态语言模型作为奖励模型，并且在DeeptraceReward上的表现优于基线模型GPT-5。此外，他们发现二元真假分类相较于细粒度深伪特征检测更加容易，而从自然语言解释到空间定位再到时间标记，任务难度逐渐增加。
### Conclusion
通过DeeptraceReward，该研究提供了一个严谨的测试平台和训练信号，用以训练关注社会意识和可信赖的视频生成的模型。
## 910. `cs.CV` - SGAligner++：跨模态语言辅助的3D场景图对齐 [PDF](https://arxiv.org/pdf/2509.20401), [HTML](https://arxiv.org/abs/2509.20401)
### Authors
Binod Singh,Sayan Deb Sarkar,Iro Armeni
### Background
3D场景图对齐在机器人导航和感知任务中是一个关键的初始步骤。现有的3D场景图对齐方法往往依赖单一模态的点云数据，并且在处理不完整或噪声输入时表现不佳。
### Innovation
我们提出了SGAligner++，这是一个跨模态的语言辅助框架，用于3D场景图对齐。该方法通过学习统一的联合嵌入空间解决了跨异构模态的部分重叠场景观测对齐的挑战，这使得在低重叠条件下和传感器噪声的情况下也能实现精确的对齐。通过使用轻量级的单模态编码器和基于注意力的融合，SGAligner++增强了场景理解，适用于如视觉定位、3D重建和导航等任务，同时保证了可扩展性和较低的计算开销。
### Conclusion
在真实世界数据集上的广泛评估表明，与最先进的方法相比，SGAligner++在嘈杂的现实世界重建上性能提高高达40%，同时支持跨模态泛化。
## 911. `cs.CV` - SlimDiff：无需训练的基于激活的手动瘦优化扩散模型 [PDF](https://arxiv.org/pdf/2509.21498), [HTML](https://arxiv.org/abs/2509.21498)
### Authors
Arani Roy,Shristi Das Biswas,Kaushik Roy
### Background
扩散模型（DMs）因其生成性能而受到赞誉，但由于参数量巨大和需要迭代降噪动态，它们在计算上是昂贵的。现有的提高效率的技术，如量化、时间步长减少或剪枝，可以在计算、内存或运行时间上节省资源，但仍然依赖于精细调优或重新训练以恢复性能。因此，这些方法会受到局限。
### Innovation
我们引入了SlimDiff，这是一种自动化激活导向的结构压缩框架，能够在不依赖任何梯度信息的情况下减少DM中注意力和前向传递的维度。该方法重新定义了DM压缩为谱近似任务，通过激活协方差定义低秩子空间，以在固定压缩预算下引导动态剪枝。这种方法通过模块级别的分解而非孤立矩阵分解来避免误差积累，同时根据扩散轨迹的非均匀几何分配稀疏性。SlimDiff在保持与未压缩模型相同的生成质量的同时，实现最多35%的加速和约100M参数的减少，且无需任何反向传播。该方法仅需要约500个校准样本，远少于先前方法所需的数量。
### Conclusion
SlimDiff是首个无需训练、基于激活的手动瘦DMs的闭合形式结构压缩方法，提供了理论上的清晰性和实际的高效性，具有重要实际应用价值。
## 912. `cs.CV` - 幻觉是糟糕的估计吗？ [PDF](https://arxiv.org/pdf/2509.21473), [HTML](https://arxiv.org/abs/2509.21473)
### Authors
Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu
### Background
本文探讨了生成模型中的幻觉问题，定义幻觉为模型未能将估计与任何合理的因果关系连接起来的情况。研究指出，即使是最优的损失最小化估计器也会产生幻觉现象。作者通过通用的高概率下界来验证幻觉率，重新界定幻觉问题为损失最小化与人类可接受输出之间的结构性错位。研究具体涉及硬币聚合、开放式QA和文本转图像等多个实验场景，以此支持其理论假设。
### Innovation
本文创新性地定义了幻觉行为，并提出了幻觉的高概率下界，揭示了最优化损失估计器依然会生成幻觉。通过多个实验场景验证了这种界定和理论，并强调了损失最小化与人类可接受输出之间的结构性错位。
### Conclusion
本文通过理论分析和实验证明，即使是在损失最小化的条件下，生成模型也会产生幻觉。这是由于损失最小化与人类可接受的输出之间存在结构性错位，引发了估计误差。
## 913. `cs.CV` - 使用柯西-施瓦茨散度进行跨模态检索 [PDF](https://arxiv.org/pdf/2509.21339), [HTML](https://arxiv.org/abs/2509.21339)
### Authors
Jiahao Zhang,Wenzhe Yin,Shujian Yu
### Background
有效的跨模态检索需要在异构数据类型之间进行坚固的对齐。大多数现有方法集中于双模检索任务，并依赖诸如Kullback-Leibler散度、最大均值离散性、相关对齐等分布对齐技术。然而，这些方法经常面临数值不稳定性、对超参数敏感、以及无法充分捕捉底层分布结构等问题。
### Innovation
本文引入了无超参数的柯西-施瓦茨（CS）散度，能够提高训练稳定性和检索性能。进一步提出了一种由Hölder不等式启发的广义柯西-施瓦茨（GCS）散度。这种方法通过双向循环对比方案直接在统一的数学框架下对齐三个或更多模态，从而消除冗长的成对比较需求。实验结果在六个基准数据集上展示了这种方法在双模和三模检索任务中的有效性，代码已公开。
### Conclusion
本文提出的CS/GCS散度方法在跨模态检索中表现出色，能够提高训练稳定性和检索性能。该方法通过引入广义柯西-施瓦茨散度和双向循环对比方案，实现了多模态数据的一致对齐，为跨模态检索技术提供了新的解决方案。
## 914. `cs.CV` - 在伊利运河上的闭环语言辅助culvert检查 [PDF](https://arxiv.org/pdf/2509.21370), [HTML](https://arxiv.org/abs/2509.21370)
### Authors
Yashom Dighe,Yash Turkar,Karthik Dantu
### Background
伊利运河上的culverts需要频繁检查以确保安全运行，但由于它们的年龄、几何形状、照明条件差、天气状况以及难以接近，人工检查非常具有挑战性。现有的检查方法受到多方面因素的限制，而VISON系统旨在应对这一挑战，通过结合大规模的视觉语言模型（VLM）和受约束的视角规划，实现了无人操控的culverts检查。
### Innovation
VISON系统首次提出了一个闭环语言辅助的无人操控检查系统。该系统结合了一个大规模的视觉语言模型（VLM）和受约束的视角规划，能够接受简短的任务说明，生成开放词汇的ROI（感兴趣区域）提取，利用立体深度信息恢复尺度，并通过考虑culverts的物理限制来指导杆足机器人的移动，以获取所需细节。经新泽西运河公司人员的外部评估，该系统的初步ROI提议与领域专家的建议达到了61.4%的一致性，而最终修正后的评估达到了80%，显示出VISON能够将初步假设转化为与专家一致的 findings。
### Conclusion
VISON系统能够在不依赖特定领域微调的情况下，在伊利运河下的culverts中完成闭环的感官、决策、移动、再成像过程，生成高分辨率图像，用于详细的报告。该系统通过结合视觉语言模型和视角规划策略，解决了传统检测方法中的诸多挑战，展示了无人操控检查系统的潜力。
## 915. `cs.CV` - DistillKac: 通过阻尼波动方程的少量步骤生成图像 [PDF](https://arxiv.org/pdf/2509.21513), [HTML](https://arxiv.org/abs/2509.21513)
### Authors
Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon
### Background
传统的反向生成模型（如扩散模型）的反向时间速度可能会变得僵硬，这允许无界传播速度。相比之下，Kac动力学规定了有限速度的传输，并提供了全局限制的动能。DistillKac利用这一结构，提出了在速度空间中保持平方可积性的无分类器引导方法，并通过端点只蒸馏方式训练学生模型以匹配冷冻的教师模型。这些方法确保了在整个路径上监督的接近性，从而提升了生成的图像质量。
### Innovation
DistillKac利用damped波动方程和Kac表示法，以有限速度移动概率质量。这种方法能够提高生成图像的质量，并减少函数评价次数，同时保持有限速度概率流的数值稳定性。此外，引入了在速度空间中的无分类器引导方法，该方法在温和条件下保持平方可积分性。提出了端点只蒸馏方式，通过长时间区间训练学生模型以匹配冷冻的教师模型，从而保证路径全程的一致性。
### Conclusion
实验表明，DistillKac能够在极少数函数评价的情况下生成高质量的图像，同时保留有限速度概率流带来的数值稳定性优势。
## 916. `cs.CV` - TRiCo: 三阶段博弈理论联合训练的鲁棒半监督学习 [PDF](https://arxiv.org/pdf/2509.21526), [HTML](https://arxiv.org/abs/2509.21526)
### Authors
Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang
### Background
半监督学习（SSL）通常依赖于学生的单一观点交互和固定教师的伪标签调节，面临着静态视图交互、不稳定的伪标签和难以建模的硬样本等问题。现有的联合训练或教师学生方法未能有效解决这些问题，因此需要一种新的框架来改进这一领域的实际应用效果。
### Innovation
TRiCo框架引入了一个教师、两名学生和一个对抗生成器，将它们整合到一个统一的训练范式中，形成了一个基于三原则的博弈结构。其中，两名学生使用冻结的互补表示，教师动态调节伪标签选择和损失平衡，生成器通过扰动嵌入来揭示决策边界弱点。伪标签的选择基于互信息而非置信度，提供了一个更稳健的先验不确定性度量。该框架用Stackelberg博弈的形式化表示，其中教师领导策略优化，学生在对抗扰动下跟随。TRiCo通过解决这些关键问题，提供了一个原则性和可推广的解决方案。
### Conclusion
TRiCo框架在CIFAR-10、SVHN、STL-10和ImageNet等数据集上的广泛实验表明，它在低标签情况下的性能一直优于现有方法，同时保持架构无关性，并与冻结的视觉骨干兼容。
## 917. `cs.CV` - 单张图像中的感知刚性3D高斯变形 [PDF](https://arxiv.org/pdf/2509.22222), [HTML](https://arxiv.org/abs/2509.22222)
### Authors
Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo
### Background
在计算机视觉和图形领域，从单一图像重建对象变形仍然是一个重要挑战。现有方法通常依赖多视角视频来恢复变形，这限制了它们在受限场景中的适用性。
### Innovation
本文提出了一种名为DeformSplat的新型框架，能够仅从单张图像中引导3D高斯变形。其主要技术贡献包括：1. 提出高斯到像素的匹配方法，它缩小了3D高斯表示和2D像素观察之间的领域差距，使得基于稀疏视觉线索的变形引导更加鲁棒。2. 提出刚性部分分割，包括初始化和细化，该分割明确识别了刚性区域，这对于变形期间维持几何连贯性至关重要。
### Conclusion
通过结合这两种技术，我们的方法可以从单张图像中重建一致的变形。广泛的实验表明，我们的方法在性能上显著优于现有方法，并且自然适用于各种应用，例如帧插值和交互式对象操作。
## 918. `cs.CV` - 视觉多智能体系统：通过视觉流减轻幻觉雪崩 [PDF](https://arxiv.org/pdf/2509.21789), [HTML](https://arxiv.org/abs/2509.21789)
### Authors
Xinlei Yu,Chengming Xu,Guibin Zhang,Yongbo He,Zhangquan Chen,Zhucun Xue,Jiangning Zhang,Yue Liao,Xiaobin Hu,Yu-Gang Jiang,Shuicheng Yan
### Background
多智能体系统（MAS）借助视觉语言模型（VLMs）能够完成复杂任务，但可能会遭遇一种新的失败形式——多智能体视觉幻觉雪崩。这种幻觉是从单个智能体开始产生，随后其他智能体在过度依赖文本传递视觉信息的情况下对其进行放大。这种现象源于对多智能体系统中视觉注意力分配的减少。
### Innovation
本文通过转序、层序和token级的注意力分析，揭示了视觉幻觉雪崩的根本原因，即视觉注意力在深层次智能体转序中逐渐减少。为此，本文提出了ViF（视觉流），这是一种轻量级且即插即用的缓解方法。ViF通过选定的视觉中继token来传递智能体间的信息，并应用注意力再分配来放大这种模式。实验结果显示本方法显著减少了幻觉雪崩现象，提高了八大基准任务中的表现，涵盖了四种常见MAS结构和十个基本模型。此外还提供了源代码链接。
### Conclusion
通过引入ViF的缓解机制，视觉多智能体系统在保持视觉信息准确传递的同时，有效减少了幻觉雪崩现象的发生，显著提升了系统性能。
## 919. `cs.CV` - 通过标注校正策略优化提升感知一致性多模态大语言模型推理 [PDF](https://arxiv.org/pdf/2509.21854), [HTML](https://arxiv.org/abs/2509.21854)
### Authors
Songjun Tu,Qichao Zhang,Jingbo Sun,Yuqian Fu,Linjing Li,Xiangyuan Lan,Dongmei Jiang,Yaowei Wang,Dongbin Zhao
### Background
多模态大型语言模型在集成视觉感知和符号推理的任务中表现优异，但常因感知引入的错误破坏推理链而表现不佳。当前的强化学习（RL）微调方法虽然提升了推理能力，但未能有效解决视觉定位和后续推理过程中存在的潜在失配问题。为解决这一挑战，本文提出了一种新的RL框架——基于标题校正的策略优化（CapPO），该框架在策略优化过程中明确确保感知一致性。CapPO 结合了两种关键机制：基于标题的一致性正则化，以及KL加权优势估计方案。
### Innovation
本文提出了——基于标题校正的策略优化（CapPO），该创新方法结合了基于标题的一致性正则化机制，以及KL加权优势估计方案。通过这两项机制，CapPO 在保障感知一致性的同时，增强了策略优化的效果，尤其是在数学相关任务和一般推理任务上的表现，比基线模型提高了显著的准确率。
### Conclusion
CapPO 提供了一个简单而有效的框架来提升多模态推理能力，通过广泛实验验证了其有效性，并通过成分分析进一步确认了各组成部分的有效性，表明CapPO 显著减少了感知相关的错误。
## 920. `cs.CV` - 基于补丁的扩散模型用于高效、放射科医生首选的MRI重建 [PDF](https://arxiv.org/pdf/2509.21531), [HTML](https://arxiv.org/abs/2509.21531)
### Authors
Rohan Sanda,Asad Aali,Andrew Johnston,Eduardo Reis,Jonathan Singh,Gordon Wetzstein,Sara Fridovich-Keil
### Background
MRI检查需要较长的成像时间，增加了成本，降低了可访问性，且更容易受到运动伪影的影响。扩散概率模型可以学习数据驱动的先验信息，有助于缩短成像时间，但这些模型通常需要大规模的训练数据集，这在实际中往往难以收集。尽管补丁基于的扩散模型在学习小型实值数据集的有效数据驱动先验方面显示出希望，但在MRI领域尚未证明临床价值。现有的最先进的方法（FastMRI-EDM）主要针对全图像扩散基线，但未在复杂的、多线圈MRI重建上进行过大规模应用验证。在这些背景下，本文的目标是将基于补丁的扩散逆解算器（PaDIS）扩展应用于复杂值的多线圈MRI重建，并与最先进的全图像扩散基线（FastMRI-EDM）在7倍欠采样的MRI重建中进行比较。
### Innovation
该研究创新之处在于将基于补丁的扩散模型应用到复杂的多线圈MRI数据中，特别是在数据稀缺的临床环境中。该模型能够在小数据集（25 k空间图像）上训练，并且在图像质量评估指标（如PSNR，SSIM，NRMSE），像素级不确定性，跨对比度的泛化，以及对严重k空间欠采样的稳健性方面表现出色。研究还通过临床盲测研究，证明使用基于补丁的扩散先验重建的MRI图像在诊断表现上优于全图像扩散模型和传统波let稀疏性重建方法。
### Conclusion
研究结果表明，基于补丁的扩散模型能够在数据稀缺的情况下实现高保真MRI重建，尤其是在临床诊断中需要诊断信心的情况下，这种模型非常有用。相比之下，传统的全图像扩散基线方法和经典凸重建方法在这方面的能力较弱。基于此，未来可以把补丁基于的扩散模型应用于其他类型的医学影像中，在临床数据有限的情况下提高诊断的精度和可靠性。
## 921. `cs.CV` - ControlHair: 基于物理的视频扩散模型实现可控动态毛发渲染 [PDF](https://arxiv.org/pdf/2509.21541), [HTML](https://arxiv.org/abs/2509.21541)
### Authors
Weikai Lin,Haoxiang Li,Yuhao Zhu
### Background
毛发模拟和渲染具有挑战性，因为涉及到复杂的线束动力学、多样的材料性质和复杂的光线-毛发交互。虽然最近的视频扩散模型可以生成高质量的视频，但它们缺乏对毛发动力学的精细控制。
### Innovation
我们提出了ControlHair，这是一种将物理模拟器与条件视频扩散模型相结合的混合框架，以实现可控的动态毛发渲染。该框架采用了三阶段的工作流程：首先是将物理参数（如毛发刚度、风速）编码到每帧几何上，然后提取每帧的控制信号，最后将控制信号输入到视频扩散模型以生成具有所需毛发动力学的视频。这种递进设计从物理推理中解耦了视频生成，支持多样化的物理现象，并且易于训练视频扩散模型。
### Conclusion
ControlHair 在精心制作的10K视频数据集上进行训练，表现出色，超越了基于文本和姿态的基线模型，提供了精确控制的毛发动力学。我们进一步展示了ControlHair 的三个应用场景：动态发型试穿、子弹时间效果和静态短视频。ControlHair 引入了第一个具有物理信息的视频扩散框架，用于实现可控的动力学，我们提供了演示视频和实验结果以供参考。
## 922. `cs.CV` - GAN和扩散模型在MRI-to-CT转换中的比较分析 [PDF](https://arxiv.org/pdf/2509.22049), [HTML](https://arxiv.org/abs/2509.22049)
### Authors
Emily Honey,Anders Helbo,Jens Petersen
### Background
CT扫描在治疗和诊断中至关重要，但在某些情况下无法获取或难以获得CT图像时，需要通过MRI图像生成合成CT（sCT）图像的方法。因此，为了找出最为有效的MRI-to-CT转换策略，有必要对比不同方法的有效性。本文对比了两种常用的人工智能架构：条件生成对抗网络(cGAN)和条件去噪扩散概率模型(cDDPM)在MRI-to-CT转换中的性能。实验中使用了成熟的Pix2Pix和Palette分别代表这两种架构。将3D转化问题拆分为多次2D转化，以减少计算成本的影响。
### Innovation
将3D转化问题拆分为多次2D转化；比较cGAN和cDDPM在MRI-to-CT转换中的性能差异；使用新颖的断层切片相似度指标(SIMOS)评估合成CT的3D整合效果；发现多通道条件输入和使用cDDPM架构对MRI-to-CT生成模型有益。
### Conclusion
oMRI-to-CT生成模型从多通道条件输入中受益，并且cDDPM是一种有效的架构选择。
## 923. `cs.CV` - 基于解码器计算的引导水印技术 [PDF](https://arxiv.org/pdf/2509.22126), [HTML](https://arxiv.org/abs/2509.22126)
### Authors
Enoal Gesny,Eva Giboulot,Teddy Furon,Vivien Chappelier
### Background
本文介绍了一种针对扩散模型的新颖水印方法。该方法利用任何现成的水印解码器计算出的梯度来引导扩散过程。这种方法通过不同的图像增强技术，增强了水印解码器对抗未预见的攻击的能力，而不需要重新训练或微调。本文的方法可将任何后验水印方案转换为扩散过程中的即时嵌入，验证了该方法在不同的扩散模型和检测器上的有效性，证明了这种技术与扩散过程中变分自动编码器的修改技术互补，同时，不显著改变生成图像，保持了生成的多样性和质量。
### Innovation
该方法通过使用现成的水印解码器计算的梯度来引导扩散过程，这种方法能够增强水印解码器处理未预见攻击的能力，而无需重新训练或微调模型。此外，这种方法能够将任何后验水印方案转换为在生成过程中即时嵌入的形式，证明了该方法与改变动态过程的水印技术的互补性，同时保持生成图像的多样性和质量。
### Conclusion
本文提出了一种新颖的扩散模型水印方法。该方法通过现成水印解码器计算的梯度引导扩散过程，并在转换为即时嵌入形式后增强了水印的鲁棒性，本文验证了该方法的有效性，展示了它如何补充现有技术的同时保持图像的质量和多样性。
## 924. `cs.CV` - 通过类内对比学习增强知识蒸馏 [PDF](https://arxiv.org/pdf/2509.22053), [HTML](https://arxiv.org/abs/2509.22053)
### Authors
Hua Yuan,Ning Xu,Xin Geng,Yong Rui
### Background
自知识蒸馏问世以来，许多研究都集中在如何有效利用教师模型生成的软标签。现有研究表明，软标签中的潜在知识源于数据中的多视图结构，同一类别的样本中的特征变异有助于学生模型通过学习多样化表示获得更好的泛化能力。然而，在现有的蒸馏方法中，教师模型主要依赖于真实标签作为目标，而忽视了同一类别内不同的表示。因此，本文提议在教师训练期间引入类内对比损失，以丰富软标签中包含的类内信息。然而，实践发现类内损失会导致训练不稳定并减慢收敛速度。为了减轻这些问题，本文将边缘损失整合进类内对比学习中，以提高训练稳定性和收敛速度。同时，我们从理论上分析了这种损失对类内距离和类间距离的影响，证明了类内对比损失可以丰富类内的多样性。实验结果表明，提出的方法是有效的。
### Innovation
本文提出了一种新的方法，即在教师训练期间引入类内对比损失，通过边缘损失优化训练稳定性和收敛速度，并从理论上分析了该损失对类内和类间距离的影响，证明了它能丰富类内多样性。这种方法是现有知识蒸馏方法的重要改进。
### Conclusion
提出的通过类内对比学习增强知识蒸馏的方法是有效的，能够在训练过程中提高模型的学习能力和泛化能力，并改善了训练的稳定性和速度，是对现有知识蒸馏方法的有益补充。
## 925. `cs.CV` - Oracle缩减差距: 基于增量向量变换的类增量学习 [PDF](https://arxiv.org/pdf/2509.21898), [HTML](https://arxiv.org/abs/2509.21898)
### Authors
Zihuan Qiu,Yi Xu,Fanman Meng,Runtong Zhang,Linfeng Xu,Qingbo Wu,Hongliang Li
### Background
类增量学习（CIL）旨在顺序获取新类的知识，同时不忘记之前学习的内容。尽管最近已经取得了一些进展，但当前的CIL方法仍然在性能上与具有历史数据完全访问权限的Oracle模型存在显著差距。本文研究了Oracle方法在CIL中的几何特性，并发现这些Oracle方法常常保持低损失的线性连接到前一个任务的最优解。
### Innovation
本文提出了增量向量变换（IVT），这是一种新颖且可直接使用的框架，用于训练期间缓解灾难性遗忘。IVT通过周期性地将模型参数迁移到保持了与前一个任务最优解的线性连接的已变换解中，来维持这些连接路径上的低损失。IVT利用对角Fisher信息矩阵高效地进行变换，适用于无示例和基于示例场景，并与多种初始化策略兼容。实验结果表明，IVT在多个数据集上持续提高了CIL基线的性能。
### Conclusion
在CIFAR-100、FGVCAircraft、ImageNet-Subset和ImageNet-Full上进行的广泛实验表明，IVT可以一致地提升强CIL基线的性能。例如，在CIFAR-100上，IVT将PASS基线的最终准确率提高了5.12%，减少了2.54%的遗忘。此外，对于预训练的CLIP的SLCA基线在FGVCAircraft上的实验，获得了平均准确率和最终准确率分别为14.93%和21.95%的提升。源代码将公开提供。
## 926. `cs.CV` - MINT-RVAE：仅使用RGB摄像数据的人体动作和情绪信息进行人类-机器人交互的多线索意图预测 [PDF](https://arxiv.org/pdf/2509.22573), [HTML](https://arxiv.org/abs/2509.22573)
### Authors
Farida Mohsen,Ali Safa
### Background
有效检测人类与物联网机器人互动的意图对于人机交互（HRI）和协作至关重要。近年来，深度学习在该领域得到广泛应用，大多数现有方法依赖于多模态输入（如RGB与深度RGB-D组合）来分类感官数据的时间序列窗口，判断其是否为交互性行为。然而，实际的人机交互数据集中存在类别不平衡的问题，这会阻碍模型的训练和泛化。
### Innovation
我们提出了一个基于帧级别的仅RGB管道，用于预测人类与机器人互动的意图，这能够使机器人更快响应并提升服务质量。为了解决意图预测中的类别不平衡问题，我们引入了MINT-RVAE，一种合成序列生成方法，结合了新的损失函数和训练策略，以增强在未见过的数据上的泛化能力。该方法在AUROC指标上达到了最新技术水平（AUROC：0.95），并优于先前工作（AUROC：0.90-0.912），同时只需要RGB输入，并支持精确的帧起始预测。
### Conclusion
最后，我们公开发布了新的带有帧级人类互动意图标注的数据集，以支持未来的相关研究。
## 927. `cs.CV` - 基于航拍路径规划的城市几何与纹理协同采集 [PDF](https://arxiv.org/pdf/2509.22227), [HTML](https://arxiv.org/abs/2509.22227)
### Authors
Weidan Xiong,Bochuan Zeng,Ziyu Hu,Jianwei Guo,Ke Xie,Hui Huang
### Background
近年来，图像采集与场景重建技术的进展使得在充分的站点信息基础上能够生成高质量的城市建筑结构几何图形。然而，当前的采集技术往往忽视了纹理质量的重要性，导致了纹理模型中可见的视觉缺陷。本文讨论了在站点访问前有限先验知识下的城市几何和纹理协同采集问题。输入仅包括目标区域的二维建筑轮廓图以及建筑物上方的安全飞行高度。
### Innovation
本文提出了一种创新的航拍路径规划框架，用于同时采集几何结构和高质量纹理图像。该框架包括多目标优化策略和一种考虑纹理一致性顺序路径规划算法。同时，引入了一套全面的纹理质量评估系统，包含两种专为建筑外墙设计的新颖度量标准。
### Conclusion
在大规模合成和真实世界的城市数据集上的实验表明，该方法能够有效地生成适合同时几何和纹理重建的图像集，从而以较低的操作成本创建出真实感强的城市纹理场景代理。
## 928. `cs.CV` - 激活函数设计在持续学习中维持可塑性 [PDF](https://arxiv.org/pdf/2509.22562), [HTML](https://arxiv.org/abs/2509.22562)
### Authors
Lute Lillo,Nick Cheney
### Background
在独立同分布（i.i.d.）训练制度中，激活函数已经被广泛测试，并且他们的差异通常在调整模型大小和优化参数后缩小。然而，在持续学习中，情况有所不同，除了灾难性遗忘外，模型还有可能逐渐失去适应能力（即所谓的可塑性丧失），但非线性在这一失败模式中的作用尚未被充分探索。
### Innovation
本文展示了激活函数选择是维持可塑性的重要且架构无关的方式。基于负分支形状和饱和行为的特性分析，引入了两种即插即用的非线性函数（Smooth-Leaky和Randomized Smooth-Leaky），并分别在监督类增量基准和基于MuJoCo非稳态环境的强化学习中进行了评估。同时提供了一个简单的压力测试协议和诊断工具，将激活函数的形状与变化条件下的适应联系起来。研究表明，精心设计的激活函数为在持续学习中维持可塑性提供了一种轻量级、通用的方法，而无需额外的容量或任务特定的调整。
### Conclusion
最终发现，细心设计激活函数是一种轻量级、通用的方式来持续学习中维持可塑性，而无需额外的容量或任务特定的调整。
## 929. `cs.CV` - 临床不确定性影响机器学习评估 [PDF](https://arxiv.org/pdf/2509.22242), [HTML](https://arxiv.org/abs/2509.22242)
### Authors
Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly
### Background
临床数据集的标签经常不够确定，因为标注者的意见不一致，且不同案例的置信度不均一。典型的聚合方法，如多数投票，会掩盖这种差异性。即使在简单的医疗影像基准实验中，考虑二元标签的置信度也会显著影响模型排名。
### Innovation
本文提出了一个观点，即在机器学习评价中应当明确考虑标注不确定性，使用可以直接操作分布的概率性度量。这些度量独立于标注生成过程，无论是简单计数、主观置信度评级还是概率响应模型。此外，这些度量计算起来相对轻量级，有线性时间实现在排序模型得分示例后。
### Conclusion
我们呼吁社区公开原始注释数据，并采用不确定性感知评价，以使性能评估更好地反映临床数据。
## 930. `cs.CV` - COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics [PDF](https://arxiv.org/pdf/2509.22240), [HTML](https://arxiv.org/abs/2509.22240)
### Authors
Matt Y. Cheung,Ashok Veeraraghavan,Guha Balakrishnan
### Background
在临床应用中，分割模型的实际效用依赖于器官大小等衍生指标的准确性，而不仅仅是分割掩码的像素级准确性。因此，为这些指标提供准确的不确定性量化的精算至关重要。尽管常用的方法如校准预测（Conformal Prediction, CP） framework能够提供这些量化保证，但直接将其应用于最终的标量指标是低效的，因为这将复杂的非线性分割至指标管道作为黑箱处理。现有的方法处理效率低下且不够精细。因此，需要一种新的框架来提高不确定性量化的准确性和效率。
### Innovation
本文提出了一种新的框架COMPASS，它通过利用底层深度神经网络的归纳偏倚直接在模型表示空间中调校分割指标，从而生成高效的基于分割指标的CP区间。COMPASS通过在具有最大目标指标敏感性的低维子空间中扰动中间特征来实现调校。它在交换性和嵌套性假设下证明了产生有效边沿覆盖区间的能力。Empirically实验表明，COMPASS在四个医疗图像分割任务中的面积估计（皮肤病变和解剖结构）上相比于传统的CP基准产生了显著更紧的区间，并且通过利用学习到的内部特征估计重要性权重来处理协变量变化的效果优于传统方法。
### Conclusion
COMPASS为医学图像分割的实用、基于分割指标的不确定性量化提供了新的途径。该方法不仅提高了效率和精度，还能够适应协变量变化下的性能。这种方法为改进医学图像分析领域的决策支持提供了重要的工具和改进方向。
## 931. `cs.CV` - JointDiff：连接连续与离散的多智能体轨迹生成 [PDF](https://arxiv.org/pdf/2509.22522), [HTML](https://arxiv.org/abs/2509.22522)
### Authors
Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo
### Background
生成模型通常将连续数据和离散事件处理为独立的过程，这在涉及这两个类型数据同步交互的复杂系统模型中造成了缺口。为了解决这个问题，作者引入了JointDiff，这是一种新型的扩散框架，旨在统一这两个过程，同时生成连续的空间-时间数据和同步的离散事件。在体育领域，作者通过同步建模多智能体轨迹和关键控球事件来验证这一方法的有效性。
### Innovation
作者提出了JointDiff框架，该框架同时生成连续的空间-时间数据和同步的离散事件，填补了生成模型在处理连续数据和离散事件方面分离的问题。此外，作者还提出了CrossGuid，一种有效的多智能体领域条件操作，以及新的统一体育基准，增强了足球和足球数据集的文本描述。这种方法通过弱控球手指导和文本指导两大可控生成场景，实现了对游戏动态的细粒度控制。
### Conclusion
JointDiff获得了最先进的性能，证明了联合建模对于构建交互系统中的现实且可控的生成模型是至关重要的。
## 932. `cs.CV` - 为非ID数据的可扩展、异构联邦学习的自适应双模式蒸馏及激励方案 [PDF](https://arxiv.org/pdf/2509.22507), [HTML](https://arxiv.org/abs/2509.22507)
### Authors
Zahid Iqbal
### Background
联邦学习（FL）作为一种分散学习（DL）的方法，能够让分散的数据得到利用而不泄露用户隐私。然而，FL面临着一些关键挑战，包括：不同客户端在业务需求和计算资源上的差异导致训练模型的不一致性；统计异质性（非IID数据）严重影响了FL的全球模型性能；以及需要一种有效的激励机制以鼓励客户端参与FL训练。
### Innovation
作者提出了几个方法来应对上述挑战，包括DL-SH（促进了统计异质性条件下的高效、隐私保护和通信高效的机器学习）、DL-MH（管理完全异质模型以解决统计差异）以及带激励机制的I-DL-MH（通过激励增强客户端参与度），这些方法在各种复杂实验条件下进行了全面测试，显示了在准确性和减少通信成本方面显著的提升，并能够有效处理统计异质性和模型异质性。
### Conclusion
所提出的方法显著提高了全球模型的准确性，并在非IID条件下实现了225%的改善，这优于现有最先进的方法和基线。
## 933. `cs.CV` - 跟随规则后学会信任胜利：渐进探索的自我模仿在自主强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.22601), [HTML](https://arxiv.org/abs/2509.22601)
### Authors
Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun
### Background
强化学习（RL）是提升LLMs在长期、稀疏奖励任务中策略性工具使用能力的主要范式，但面临探索与利用的基本挑战。现有研究通过策略熵来刺激探索，但这种机械的熵最大化可能会导致RL训练过程中的不稳定性，因为多轮次分布会发生变化。
### Innovation
本文提出了一种基于课程的学习策略SPEAR，这是一种基于自我模仿学习（SIL）训练智能体LLM的方法。它通过在各个阶段逐步引导策略演化，并在自回放缓冲区中存储自生成的成功轨迹进行离策略更新，实现探索与利用的渐进平衡。通过引入曲线下方的奖励和对具有高协方差的token进行裁剪等正则化手段，进一步稳定训练。
### Conclusion
SPEAR方法在探索与利用之间建立了平衡，通过课程管理探索过程，并利用内在奖励促进技能层面的探索，同时通过自我模仿加强对已成功模式的利用，以加速解决方案迭代。此外，通过调整回放缓冲区的经验优值和裁剪具有高协方差的token，进一步稳定训练过程。
## 934. `cs.CV` - VoiceAssistant-Eval：评估跨听、说和看的人工智能助手 [PDF](https://arxiv.org/pdf/2509.22651), [HTML](https://arxiv.org/abs/2509.22651)
### Authors
Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li
### Background
大语言模型和多模态系统的不断发展激发了对语音优先人工智能助手的兴趣，但现有的基准标准无法全面评估这些系统的能力。本文介绍了VoiceAssistant-Eval，这是一种全面的评估基准，旨在评估人工智能助手在听、说和看方面的能力。VoiceAssistant-Eval 包含10,497个精心挑选的示例，覆盖13个任务类别。这些任务包括自然声音、音乐和对话样本（听）、多轮对话、角色扮演模仿以及各种场景（说），还有高度异质性的图像（看）。
### Innovation
本文介绍了一种名为VoiceAssistant-Eval的新型基准测试，它旨在全面评估人工智能助手在听、说和看方面的能力。该基准包含了10,497个精心挑选的示例，涉及13个任务类别，旨在衡量模型在不同层面的表现。此外，通过评估21个开源模型和GPT-4o-Audio，揭示了重要观察结果：专有模型不总是优于开源模型，大多数模型在说的任务上表现出色但在音频理解上较弱，精心设计的小模型可以挑战大模型。
### Conclusion
研究结果表明，某些中等规模的模型，在听觉准确性方面超过更大的模型。然而，目前的模型在处理多模态输入和角色扮演声音模仿任务方面仍然存在困难，需要进一步提升其稳健性和安全对齐。VoiceAssistant-Eval 开放了代码和数据，为下一阶段人工智能助手的评估和开发奠定了坚实的基础。
## 935. `cs.CV` - 基于残差nnResU-网网络和解剖特征优先损失的深度学习跨解剖结构CT合成功能 [PDF](https://arxiv.org/pdf/2509.22394), [HTML](https://arxiv.org/abs/2509.22394)
### Authors
Javier Sequeiro González,Arthur Longuefosse,Miguel Díaz Benito,Álvaro García Martín,Fabien Baldacci
### Background
该研究利用多中心SynthRAD2025数据集，提出了一种基于3D nnUNet适应的MR到CT和CBCT到CT图像转换方法。覆盖头部和颈部（HN）、胸部（TH）和腹部（AB）区域。研究介绍了一种新的Anatomical Feature-Prioritized (AFP) 损失，并采用了两种主要网络配置：标准UNet和残差UNet。输入数据的归一化处理和模型训练方法也进行了描述，展示了这种方法在跨模态医学图像合成中的稳定性和有效性。
### Innovation
该研究利用了两种主要的网络配置（标准UNet和残差UNet）并引入了Anatomical Feature-Prioritized (AFP) 损失。AFP损失通过比较从紧凑分割网络上训练出的多层特征来增强重建相关临床结构。同时，采用了特定于每种解剖区域的3D斑块进行训练，并且在推断过程中使用了平均合并方法来处理重叠的斑块。这些创新点旨在提高不同模态之间的图像转换效果，特别是对于骨结构和CBCT中的病灶显示出更好的重建质量。
### Conclusion
研究结果表明，结合残差学习和解剖引导特征损失的方法能够产生更清晰的重建结果和更好的解剖保真度，特别是在MR到CT和CBCT到CT的转化任务中。残差网络与AFP的方法在骨结构和病灶的重建中表现出色。尽管仅使用L1损失训练的网络在强度基线度量上略有提高，但该方法提供了跨模态医学图像合成的有效解决方案。
## 936. `cs.CV` - 频域指导下的多尺度扩散方法在图像超分辨率中的应用 [PDF](https://arxiv.org/pdf/2405.10014), [HTML](https://arxiv.org/abs/2405.10014)
### Authors
Xingjian Wang,Li Chai,Jiming Chen
### Background
单张图像的超分辨率性能很大程度上取决于如何生成和补充低分辨率图像中的高频细节。最近，基于扩散的DDPM模型在生成超分辨率任务中的高质量高频细节方面表现出巨大潜力。然而，由于直接使用高分辨率真值为目标，它们在所有采样时间步长中仅利用高分辨率真值，遇到了幻觉问题，即生成不匹配的伪影。
### Innovation
提出了一种新颖的频域指导下的多尺度扩散模型（FDDiff），将高频信息补充过程分解为更细化的步骤。具体而言，开发了一种基于小波包的频域退化金字塔，以提供具有增大的带宽的多尺度中间目标。通过这些目标，FDDiff引导逆转扩散过程逐步在时间步长中补充缺失的高频细节。同时，设计了一种多尺度频域细化网络，以在单个统一网络中预测多个尺度所需的高频成分。
### Conclusion
在流行的基准上进行了全面评估，表明FDDiff在高频保真的超分辨率结果方面优于之前的生成方法。
## 937. `cs.CV` - RoboView-Bias: 评估机器人操作中体现代理视觉偏差的基准 [PDF](https://arxiv.org/pdf/2509.22356), [HTML](https://arxiv.org/abs/2509.22356)
### Authors
Enguang Liu,Siyuan Liang,Liming Lu,Xiyu Zeng,Xiaochun Cao,Aishan Liu,Shuchao Pang
### Background
体现代理的安全性和可靠性依赖于精确和无偏的视觉感知。现有基准主要关注在扰动下的泛化能力和鲁棒性，但系统量化视觉偏见仍不足。这限制了对感知如何影响决策稳定性的深入理解。为解决这一问题，我们提出了RoboView-Bias，这是首个专门设计以系统量化机器人操作中视觉偏见的基准，遵循因素隔离的原则。通过使用结构化变体生成框架和感知公平性验证协议，我们创建了2,127个任务实例，可确保对单个视觉因素及其相互作用引起的偏差进行稳健测量。利用该基准，我们系统地评估了三种代表性体现代理，并报告了三个主要发现：(i) 所有代理都显示出显著的视觉偏见，其中相机视角是最关键的因素；(ii) 代理在强烈饱和的颜色下取得最高的成功率，这表明了这些代理从底层视觉语言模型继承的视觉偏好；(iii) 视觉偏见具有强烈的不对称耦合，相机视角强烈放大了与颜色相关的偏见。最后，我们展示了基于语义接地层的缓解策略可以显著降低MOKA上的视觉偏见，约54.5%。我们的结果强调，系统分析视觉偏见是开发安全可靠且通用的体现代理的先决条件。
### Innovation
我们提出了RoboView-Bias，这是首个专门设计以系统量化机器人操作中视觉偏见的基准。通过使用结构化变体生成框架和感知公平性验证协议，我们创建了2,127个任务实例，可以确保对单个视觉因素及它们的相互作用导致的偏差进行稳健测量。利用这一基准，我们系统地评估了三种代表性的体现代理，并揭示了视觉偏见的关键发现。我们还展示了一种基于语义接地层的缓解策略可以显著降低视觉偏见。这些发现有助于更好地理解感知如何影响决策稳定性和安全性。
### Conclusion
研究表明，系统分析视觉偏见是开发安全可靠且通用的体现代理的先决条件。通过RoboView-Bias基准，我们揭示了视觉偏见的关键发现，并展示了缓解策略的有效性。这些工作为进一步研究和开发提供了新的视角。
## 938. `cs.CV` - 像素运动扩散是机器人控制所需的一切 [PDF](https://arxiv.org/pdf/2509.22652), [HTML](https://arxiv.org/abs/2509.22652)
### Authors
E-Ro Nguyen,Yichi Zhang,Kanchana Ranasinghe,Xiang Li,Michael S. Ryoo
### Background
研究背景在于机器人控制中高层级的动作意图和低层级的机器人执行动作之间需要一种桥梁，现有的方法可能在模拟环境和真实环境之间存在较大的性能差距，尤其是在数据稀缺的情况下。本文通过建立一个基于扩散模型的统一框架DAWN，希望弥合高层意图与低层动作之间的鸿沟，并提高机器人控制的性能和实用性。
### Innovation
提出了一种全新的框架DAWN，该框架通过结构化的像素运动表示将高层动作意图与低层机器人动作连接起来。在此框架下，高层和低层控制器都被建模为扩散过程，产生了一个完全可训练的端到端系统，具有可解释的中间运动抽象。DAWN在具有挑战性的CALVIN基准上达到了最佳效果，并且在MetaWorld上取得了进一步验证。
### Conclusion
DAWN通过结合扩散建模与运动中心表示，展示了在仿真和真实世界之间可靠的人际迁移，证明了扩散模型在机器人控制中的实用性和有效性。研究结果表明，这种组合可以作为大规模和鲁棒机器人学习的强大基准。
## 939. `cs.CV` - WoW: 通过具身交互实现无所不知的世界模型 [PDF](https://arxiv.org/pdf/2509.22642), [HTML](https://arxiv.org/abs/2509.22642)
### Authors
Xiaowei Chi,Peidong Jia,Chun-Kai Fan,Xiaozhu Ju,Weishi Mi,Kevin Zhang,Zhiyuan Qin,Wanxin Tian,Kuangzhi Ge,Hao Li,Zezhong Qian,Anthony Chen,Qiang Zhou,Yueru Jia,Jiaming Liu,Yong Dai,Qingpo Wuwu,Chengyu Bai,Yu-Kai Wang,Ying Li,Lizhang Chen,Yong Bao,Zhiyuan Jiang,Jiacheng Zhu,Kai Tang,Ruichuan An,Yulin Luo,Qiuxuan Feng,Siyuan Zhou,Chi-min Chan,Chengkai Hou,Wei Xue,Sirui Han,Yike Guo,Shanghang Zhang,Jian Tang
### Background
人类通过与世界的积极互动获得直观物理理解。当前的视频模型如Sora依赖被动观察，因此在物理因果性方面表现不佳。这种观察导致我们提出一个核心假设：真实的物理学直觉必须基于与真实世界进行长时间、因果丰富的互动。为验证这一假设，文中提出了一个基于200万机器人交互轨迹训练的140亿参数的生成世界模型WoW，并进一步展示了通过SOPHIA（一种基于视觉-语言模型的代理）能够优化其物理合理性，以及通过逆动力学模型将这些优化的计划转化为可执行的机器人行动。文中还提出了专注于视频中的物理一致性和因果推理的新基准WoWBench，并表明WoW在人类和自动评估中均达到最佳性能，展现了强大的物理因果性、碰撞动力学和物体持久性能力。这项工作提供了大规模现实世界交互是开发AI物理直觉基石的系统性证据。模型、数据和基准将开源。
### Innovation
提出了基于140亿参数的生成世界模型WoW，以及一个名为SOPHIA的视觉-语言模型代理，可以通过迭代优化生成内容的物理一致性。此外，还提出了一种通过逆动力学模型将语言指令转化为可执行机器人行动的方法。最后，提出了新的基准WoWBench来评估视频中的物理一致性和因果推理能力，WoW在这项基准测试中表现最佳。
### Conclusion
大规模、真实的交互对于在AI中开发物理直觉至关重要。WoW、SOPHIA和逆动力学模型与新基准一起，展示了转向基于互动的方法可以显著提高AI处理物理因果性和实际操作能力。而且，所有模型、数据和基准都将开源。
## 940. `cs.CV` - DynamicControl:提高文本到图像生成适应性条件选择的方法 [PDF](https://arxiv.org/pdf/2412.03255), [HTML](https://arxiv.org/abs/2412.03255)
### Authors
Qingdong He,Jinlong Peng,Pengcheng Xu,Boyuan Jiang,Xiaobin Hu,Donghao Luo,Yong Liu,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang
### Background
现有的文本到图像生成模型（特别是那些使用类似ControlNet的结构的模型）已经探索了多种控制信号来指导图像属性。然而，现有的方法存在一些不足，比如对条件处理不够有效，且使用固定的条件数量，这不足以完全解决多个条件的复杂性以及潜在的冲突问题。因此，需要一种创新的方法来有效处理多个条件，以实现更为可靠和细致的图像合成。
### Innovation
本文提出了一种名为DynamicControl的新型框架，它支持动态的多种控制信号组合方式，并允许自适应选择不同数量和类型的条件。该框架首先使用一个双循环控制器，利用预训练的条件生成模型和判别模型为所有输入条件生成初始真实的评分排序。该控制器评估提取出来的条件与输入条件的相似性以及与源图像的像素级相似度。然后，集成了一个多模态大型语言模型（MLLM）以构建高效的条件评估器，根据双循环控制器的评分排名优化条件的排序。方法还通过联合优化MLLMs和扩散模型，利用MLLMs的推理能力来促进多条件文本到图像任务。最后，经过排序的条件被传递给一个并行多控制适配器，该适配器从动态视觉条件中提取特征映射并整合，以调节ControlNet，从而增强对生成图像的控制。
### Conclusion
DynamicControl方法通过定量和定性的比较，展示了其在可控性、生成质量和组合性的优越性相比现有的方法。
## 941. `cs.CV` - 见指飞：一种无需学习的基于VLM的通用无人航空导航框架 [PDF](https://arxiv.org/pdf/2509.22653), [HTML](https://arxiv.org/abs/2509.22653)
### Authors
Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu
### Background
本文介绍了一种无需训练的空中视觉-语言导航（AVLN）框架See, Point, Fly（SPF），基于视觉-语言模型（VLMs）构建。SPF能够根据任何类型的自由形式指令在各种环境中导航到任何目标。它通过将模糊的语言指令分解成逐次对输入图像上的2D航点的标注，利用VLMs进行2D空间定位，进一步将预测的2D航点转换为3D位移向量作为无人飞行器（UAVs）的动作指令。此外，SPF还能够自适应调整飞行距离，以实现更高效的导航。SPF在闭环控制模式下运行，能够跟随动态目标在动态环境中导航。在广泛的实际评估中，SPF在强化学习模拟基准中不仅战胜了之前的最佳方法，而且还具有出色的泛化能力，适用于不同的VLMs。通过全面的消融研究强调了设计选择的有效性。
### Innovation
SPF的主要创新在于将其动作预测视为2D空间定位任务，而不是传统的文本生成任务。该框架利用VLMs将模糊的语言指令分解为逐次对输入图像上的2D航点的标注，并将预测的2D航点转化为3D位移向量作为UAVs的动作指令。此外，它还在闭环控制中运行，可以跟踪动态目标，减少导航时间。它在评估中不仅超出了基准线，还在各种环境设置中展示了出色的泛化能力。
### Conclusion
SPF在强化学习模拟基准中重新定义了最新状态，比之前最佳方法的绝对优势提高了63%。在广泛的实地评估中也表现出色，超越了强大的基准线。进行全面的消融研究以强调其设计选择的有效性。SPF显示出对不同VLMs的显著泛化能力。
## 942. `cs.CV` - 利用模型指导从个性化扩散模型中提取训练数据 [PDF](https://arxiv.org/pdf/2410.03039), [HTML](https://arxiv.org/abs/2410.03039)
### Authors
Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu
### Background
扩散模型（DMs）已成为强大的图像生成工具，尤其在少数图像集上进行微调时，预训练的DM可以捕捉到特定的风格或对象。人们经常会将这些个性化检查点上传到网上，形成了社区如Civitai和HuggingFace。然而，模型所有者在发布微调检查点时可能会忽略数据泄露的风险，特别是在使用未经授权的数据进行微调时还会引发版权侵权的问题。该研究旨在探讨是否可以从互联网上共享的微调DM中提取训练数据，进而揭示数据泄露和版权侵权的威胁。研究团队开发了FineXtract框架来实现这一目标，该框架通过逼近微调过程中的模型分布变化，提取最可能的图像数据，从而验证了方法的有效性。实验结果表明，该方法在通常情况下能够提取约20%的微调数据。
### Innovation
研究提出了一种名为FineXtract的新框架，该框架利用模型指导（通过模拟微调过程中的分布变化）从个性化扩散模型中提取训练数据。这种方法能够有效地从微调后的扩散模型中提取出训练数据，从而提供数据泄露和版权侵权的证据，这是以往方法所不具备的。
### Conclusion
研究团队提出了FineXtract框架，该框架成功地从微调的扩散模型中提取了训练数据，并验证了这种创新方法的可行性。实验结果表明该方法能够在大多数情况下有效提取约20%的训练数据。
## 943. `cs.CV` - 乳腺X线筛查中的多视图超复数学习 [PDF](https://arxiv.org/pdf/2204.05798), [HTML](https://arxiv.org/abs/2204.05798)
### Authors
Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello
### Background
放射科医生在解读乳腺X线检查时，会联合分析四个视图，因为视图间的相关性对于准确诊断至关重要。现有方法采用了专门的融合区块来捕捉这些关联，但是这些方法因视角主导性、训练不稳定性和计算开销等问题而受到制约。因此，需要一种新的方法来解决这些问题，从而提高乳腺癌分类的准确性并增强跨放射学模态和任务的泛化能力，如从胸片中进行疾病分类和多模态脑肿瘤分割等任务。
### Innovation
我们提出了一种基于参数化超复数神经网络（PHNNs）的新型学习方式——多视图超复数学习，用以解决现有方法的局限性。通过超复数代数，我们的模型能够内在地捕捉到视图内部和视图间的联系，并为此设计了适用于双视图和四视图检查的PHResNets以及针对效率和准确性的两种互补的四视图架构：PHYBOnet和PHYSEnet。通过广泛实验，我们证明了与最先进的多视图模型相比，我们的方法具有更高的性能，同时还能跨不同的放射学模态和任务进行泛化。
### Conclusion
我们的研究表明，多视图超复数学习在乳腺癌筛查中表现出色，不仅能够提高乳腺癌分类的准确性和效率，还能够泛化到跨多种模态和任务的应用场景。我们希望这一成果能推动乳腺癌预防和诊断技术的发展。相关代码和预训练模型可在以下链接获取：this https URL
## 944. `cs.CV` - Pose Prior Learner: 无监督类别先验学习在姿态估计中的应用 [PDF](https://arxiv.org/pdf/2410.03858), [HTML](https://arxiv.org/abs/2410.03858)
### Authors
Ziyu Wang,Shuangpeng Han,Mengmi Zhang
### Background
先验知识代表了一种关于系统的信念或假设，有助于推理和决策。本文关注的姿态估计中的无监督类别先验学习挑战，其中AI模型通过自我监督的方式从图像中学习任何物体类别的通用姿态先验。虽然先验对于姿态估计非常有效，但获取这些先验可能具有挑战性。本文提出了一个名为Pose Prior Learner (PPL)的新方法，旨在学习任何物体类别的一般姿态先验。PPL通过层次记忆存储原型姿态的构成部分，并从中提取通用姿态先验。该先验通过模板变换和图像重建提高姿态估计的准确性。实验结果表明，PPL在人类和动物姿态估计数据集上优于竞争基准，特别是在遮挡图像上通过学习的原型姿态进行姿态估计时表现出有效性。通过迭代推理，PPL利用先验知识细化估算姿态，回归到存储在记忆中的任何原型姿态。
### Innovation
提出了一种名为Pose Prior Learner (PPL)的新方法，用于通过自我监督学习任何物体类别的通用姿态先验。PPL通过层次记忆存储原型姿态的构成部分，并从中提取通用姿态先验，通过模板变换和图像重建提高姿态估计的准确性。PPL无需额外的人工注释或干预即可学习有意义的先验知识，优于现有的竞争基准，特别在遮挡图像的姿势估计中展现出有效性。
### Conclusion
通过迭代推理，PPL利用先验知识细化估算的姿态，回归到存储在记忆中的任何原型姿态。实验结果表明，PPL在人类和动物姿态估计数据集上优于竞争基准。Pose Prior Learner (PPL)的代码、模型和数据将公开可用。
## 945. `cs.CV` - Self-Guidance: 提升流性和扩散生成的效果 [PDF](https://arxiv.org/pdf/2412.05827), [HTML](https://arxiv.org/abs/2412.05827)
### Authors
Tiancheng Li,Weijian Luo,Zhiyang Chen,Liyuan Ma,Guo-Jun Qi
### Background
现有的指导策略要么需要特定的训练，要么依赖于扩散模型网络强烈的经验先验假设。这可能限制了它们的性能和应用范围。现有的指导方法主要依赖于特殊的训练过程或模型的结构偏见。通过观察发现，不理想的生成结果可以通过不同噪声水平下的密度显著下降来检测，因此需要一种新的指导策略来改善生成结果的质量。
### Innovation
提出了一种名为Self-Guidance (SG)的方法，该方法仅依赖于扩散或流模型在不同噪声水平下的采样得分函数，无需任何特定的训练。这种方法使得SG可以灵活地应用于任何扩散或流模型。此外，还提出了一种高效的SG变体（SG-prev），可以在不需要额外的扩散步骤前向传递的情况下重用前一扩散步骤的输出。
### Conclusion
在不同架构的文本到图像和文本到视频生成实验中，SG在多个指标上超过了现有算法，包括FID和人类偏好评分。SG-prev在效率和结果上也优于SG，同时在生成生理上正确的身体结构（如手、脸和手臂）方面表现出色。该方法已经开源并在GitHub上提供。
## 946. `cs.CV` - 从那些易忘的图像中汲取难忘的教训：类别内的记忆性在计算机视觉中很重要 [PDF](https://arxiv.org/pdf/2412.20761), [HTML](https://arxiv.org/abs/2412.20761)
### Authors
Jie Jing,Yongjian Huang,Serena J.-W. Wang,Shuangpeng Han,Lucia Schiatti,Yen-Ling Kuo,Qing Lin,Mengmi Zhang
### Background
虽然同一类别的图像通常具有相似的类别特征，但某些图像在记忆上的表现却优于其他图像。为了探究哪些特征能使一个图像实例比其他实例更具记忆性，该研究设计并实施了一系列人类行为实验，考察参与者在序列图像中识别当前图像与之前图像匹配的能力。在此基础上，一种新的记忆性评分——类内记忆性评分（ICMscore）被提出，该评分定义了重复图像呈现时间间隔的量化指标。此外，该研究还创建了一个包含超过5000张图像的类别内记忆性数据集（ICMD），覆盖了十个物体类别，并基于2000名参与者的结果计算了ICM评分。
### Innovation
1. 首次定义了类内记忆性（Intra-Class Memorability）的概念，并开发了ICMscore作为量化这种记忆性的新指标。2. 创建了一个包含大量图像及其ICM评分的ICMD数据集，这些数据用于训练多种下游任务模型，如记忆性预测、图像识别、持续学习以及记忆性控制的图像编辑。3. 针对基于ICMD的图像对，对最先进的图像扩散模型进行了微调，实现了图像记忆性增强和减弱的效果。4. 研究表明，高ICM评分的图像会削弱AI在图像识别和持续学习任务中的性能，而低ICM评分的图像则会提升性能。
### Conclusion
该研究通过详细审视最易记和最难记的图像背后的细微视觉特征，揭示了类别内记忆性在计算机视觉中的重要作用，为未来在实际应用中的计算机视觉研究奠定了基础。所有代码、数据和模型将公开发布，以促进进一步的研究。
## 947. `cs.CV` - 大规模预训练数据集在微调后并不总是保证鲁棒性 [PDF](https://arxiv.org/pdf/2410.21582), [HTML](https://arxiv.org/abs/2410.21582)
### Authors
Jaedong Hwang,Brian Cheung,Zhang-Wei Hong,Akhilan Boopathy,Pulkit Agrawal,Ila Fiete
### Background
大规模预训练模型常用于通过微调学习新专用任务，而且目标是在保持模型整体性能的同时学习新的技能。所有这类模型的一个重要目标是鲁棒性：能够在外分布（OOD）任务上表现良好。然而，我们发现预训练模型在大规模数据集上进行微调时，鲁棒性会显著下降，并且会失去对外分布任务的泛化能力。
### Innovation
研究人员提出了一种鲁棒性继承基准（ImageNet-RIB），它将鲁棒性继承评估应用于任何预训练模型。该基准由一组相关但不同的OOD（下游）任务组成，涉及在一组OOD任务之一上进行微调，然后在其余任务上进行测试。实验结果表明，虽然连续学习方法有帮助，但微调会降低预训练模型的鲁棒性。此外，研究发现，预训练于最大且最多样数据集上的模型在小数据集上进行微调后，鲁棒性损失更大，绝对鲁棒性也更低。这些发现暗示，以最强的基础模型开始可能并不是针对专业化任务表现最好的方法。
### Conclusion
在小数据集上进行微调的预训练模型通常会丧失鲁棒性，尤其是针对大规模和多样数据集的预训练模型在微调后表现出更大的鲁棒性损失。因此，在专业任务上表现最好的方法可能不是一开始就使用最强的基础模型。
## 948. `cs.CV` - TAPTRv3: 空间和时间上下文促进长视频中任意点的稳健跟踪 [PDF](https://arxiv.org/pdf/2411.18671), [HTML](https://arxiv.org/abs/2411.18671)
### Authors
Jinyuan Qu,Hongyang Li,Shilong Liu,Tianhe Ren,Zhaoyang Zeng,Lei Zhang
### Background
TAPTRv2 是一种简单而有效的 DETR 类点跟踪框架，在常规视频中表现良好，但在长视频中容易失效。这是因为目标跟踪点在长视频中随着时间逐渐变化，TAPTRv2 在查询长视频中的高质量特征方面存在不足。文章基于 TAPTRv2 提出了 TAPTRv3，通过引入空间和时间上下文来改进点的特征查询，从而在长视频中实现更稳健的跟踪。
### Innovation
TAPTRv3 引入了 Context-aware Cross-Attention (CCA) 机制，将空间上下文引入注意力机制，以提高点特征查询的质量。此外，TAPTRv3 还引入了 Visibility-aware Long-Temporal Attention (VLTA) 机制，该机制在考虑过去帧的可见性的情况下，对这些帧进行时间注意力操作，有效解决 TAPTRv2 中由于其类似于 RNN 的长期建模引起的目标特征漂移问题。实验结果显示，TAPTRv3 在多个具有挑战性的数据集上显著优于 TAPTRv2。即使与在大规模额外内部数据上训练的方法相比，TAPTRv3 仍然表现出优越性。
### Conclusion
TAPTRv3 在长视频中的点跟踪任务上显著超越了 TAPTRv2，并且获得了最先进的性能。通过利用空间和时间上下文，TAPTRv3 能够更稳健地处理特征查询，克服了 TAPTRv2 在长视频中的问题，并展示了优于现有方法的性能。
## 949. `cs.CV` - Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion [PDF](https://arxiv.org/pdf/2410.13674), [HTML](https://arxiv.org/abs/2410.13674)
### Authors
Yijun Liang,Shweta Bhardwaj,Tianyi Zhou
### Background
低质量或稀缺的数据已经成为训练深度神经网络的一个重要挑战。经典的数据增强方法无法产生大量不同的新数据，而扩散模型提供了一种通过文本提示生成高保真且多样化的合成数据的新方法。然而，仅靠文本指导无法有效控制合成图像与原始图像之间的相似性，导致生成的图像溢出分布范围，从而损害模型性能。研究图像指导以实现合成图像和真实图像之间的插值是解决这一问题的关键。通过调整图像合成中的指导强度，可以生成与训练数据相似但更难于学习的图像，或者生成更易学但分布差距更大的合成图像。生成的图像谱系能够构建一种新颖的“扩散课程（DisCL）”，该课程在每个训练阶段调整图像合成的指导强度：它聚焦于模型难以学习的困难样本，并评估合成图像中最有效的指导水平以提高困难数据的学习效果。
### Innovation
该研究提出了“扩散课程（DisCL）”的概念，这是一种通过图像指导扩散生成合成数据的方法，旨在解决合成数据质量与现实数据之间的差距。DisCL在每个训练阶段调整图像合成中的指导强度，以优化模型学习效果。通过这种动态调整，可以更有效地管理和利用合成数据，使其在学习过程中逐步变得更有帮助。该方法特别适用于挑战性任务，如长尾分类和低质量数据学习，能够在测试时提升模型在未见过的类别的识别准确率，并整体提高模型的分类准确性。实验结果表明，DisCL在iWildCam数据集上改进了2.7%的OOD和ID宏准确率，在ImageNet-LT数据集上将尾部类别的准确性从4.4%提高到23.64%，并使整体准确性提高了4.02%。
### Conclusion
基于图像指导的扩散模型产生的合成数据，通过调整图像合成中的指导强度，可以构建出一个新颖的“扩散课程（DisCL）”。该方法能够动态调整合成数据的指导水平，优化模型在难以学习样本上的训练效果，在未见过的数据类别上提高模型的识别准确率，从而显著提升了模型的整体性能，特别是在长尾分类和低质量数据学习任务上。
## 950. `cs.CV` - Calibrated Multi-Preference Optimization for Aligning Diffusion Models [PDF](https://arxiv.org/pdf/2502.02588), [HTML](https://arxiv.org/abs/2502.02588)
### Authors
Kyungmin Lee,Xiaohang Li,Qifei Wang,Junfeng He,Junjie Ke,Ming-Hsuan Yang,Irfan Essa,Jinwoo Shin,Feng Yang,Yinxiao Li
### Background
在使用偏好优化对文本到图像（T2I）扩散模型进行对齐时，虽然人类标注的数据集是宝贵的资源，但由于手工数据收集成本高昂，这些方法难以扩大规模。现有的偏好优化方法仅处理成对偏好分布，缺乏应对多偏好场景的能力，并且难以处理奖励之间的一致性问题。因此，迫切需要一种方法能够利用多种奖励模型的一般偏好来优化扩散模型，无需手工标注数据。
### Innovation
本文提出了一种名为Calibrated Preference Optimization (CaPO)的新方法，能够在不依赖人工标注数据的情况下，通过综合多个奖励模型生成的样本的一般偏好来对齐T2I扩散模型。具体而言，该方法采用奖励校准技术来近似计算一般偏好，并通过Pareto前沿选择方法有效处理多偏好分布。最后，利用回归损失校准所选成对的奖励差异来微调扩散模型。
### Conclusion
实验结果表明，CalPO在单测和多奖励设置下的表现均显著优于现有的直接偏好优化（DPO）等方法，特别是在T2I基准测试（如GenEval和T2I-Compbench）上得到了验证。
## 951. `cs.CV` - 单权重模型编辑用于后处理消除伪相关 [PDF](https://arxiv.org/pdf/2501.14182), [HTML](https://arxiv.org/abs/2501.14182)
### Authors
Shahin Hakemi,Naveed Akhtar,Ghulam Mubashar Hassan,Ajmal Mian
### Background
神经网络训练倾向于利用最简单的特征作为捷径来最小化训练损失。然而，某些特征可能与目标标签存在虚假相关，导致模型产生错误预测。已有多种方法试图解决这一问题，但这些方法通常需要额外的训练成本，并且往往在模型部署后才发现因虚假关系导致的异常行为。此外，伪相关性是一个主观的概念，因此需要精确探索特征的伪相关程度，以及如何按比例分散模型对这些特征的注意力以实现可靠预测。
### Innovation
提出了一种方法，能够在后处理阶段消除伪特征的影响，并可按任意程度控制。将伪特征概念化为原始类别的虚拟子类，可以通过类别移除方案消除。进一步提出了一种独特而精准的类别移除技术，只需进行单一权重修改，不会对其他类别的性能造成显著影响。
### Conclusion
通过后处理仅修改一个权重，该方法在性能上实现了与最先进的方法相媲美或更优的结果。
## 952. `cs.CV` - LOGen：通过点扩散实现LiDAR物体生成 [PDF](https://arxiv.org/pdf/2412.07385), [HTML](https://arxiv.org/abs/2412.07385)
### Authors
Ellington Kirby,Mickael Chen,Renaud Marlet,Nermin Samet
### Background
LiDAR扫描的生成是一个快速增长的领域，具有多样的应用，特别是在自动驾驶中。然而，LiDAR扫描生成仍然具有挑战性，尤其是在与图像和3D物体生成的快速进展相比时。考虑LiDAR对象生成任务需要模型生成由LiDAR扫描视角看到的3D物体。这个任务关注场景中的关键方面——物体，同时得益于3D物体生成方法的进步。
### Innovation
提出了一种新颖的基于扩散的模型，用于生成包含强度的LiDAR数据集物体的点云，并通过条件信息广泛控制生成。所有这些使用新开发的3D度量标准在nuScenes和KITTI-360上进行了实验，以衡量生成的质量。
### Conclusion
实验表明，该模型生成了高质量的LiDAR点云物体，并提供了广泛的生成控制。相关代码可在指定的网址找到。
## 953. `cs.CV` - 语义一致的语言高斯点级查询 [PDF](https://arxiv.org/pdf/2503.21767), [HTML](https://arxiv.org/abs/2503.21767)
### Authors
Hairong Yin,Huangying Zhan,Yi Xu,Raymond A. Yeh
### Background
开放词汇的三维场景理解对于机器人应用至关重要，如基于自然语言的操作、人机交互和自主导航。现有方法在查询三维加权球分布时常常面临不一致的2D掩码监督问题，缺乏稳健的3D点级检索机制。
### Innovation
(i) 提出一种新的点级查询框架，通过在分割掩码上进行跟踪来建立语义一致的地面实况进行语言高斯分布的提炼；(ii) 引入基于示例的查询方法，首先检索提炼的地面实况，然后使用地面实况查询个人高斯。
### Conclusion
在三个基准数据集上的大量实验表明，所提出的方法优于现有最佳性能。我们的方法在LERF、3D-OVS和Replica数据集上分别实现了mIoU提高+4.14、+20.42和+1.7。这些结果验证了我们的框架为真实世界机器人系统中的开放词汇理解提供了潜在的步骤。
## 954. `cs.CV` - 使用模型、数据和测试时间扩展现有开放源代码多模态模型的性能边界 [PDF](https://arxiv.org/pdf/2412.05271), [HTML](https://arxiv.org/abs/2412.05271)
### Authors
Zhe Chen,Weiyun Wang,Yue Cao,Yangzhou Liu,Zhangwei Gao,Erfei Cui,Jinguo Zhu,Shenglong Ye,Hao Tian,Zhaoyang Liu,Lixin Gu,Xuehui Wang,Qingyun Li,Yiming Ren,Zixuan Chen,Jiapeng Luo,Jiahao Wang,Tan Jiang,Bo Wang,Conghui He,Botian Shi,Xingcheng Zhang,Han Lv,Yi Wang,Wenqi Shao,Pei Chu,Zhongying Tu,Tong He,Zhiyong Wu,Huipeng Deng,Jiaye Ge,Kai Chen,Kaipeng Zhang,Limin Wang,Min Dou,Lewei Lu,Xizhou Zhu,Tong Lu,Dahua Lin,Yu Qiao,Jifeng Dai,Wenhai Wang
### Background
介绍了基于InternVL 2.0的InternVL 2.5，这是一个高级多模态大型语言模型系列，保持核心模型架构的同时，通过改进训练和测试策略及数据质量带来了显著提升。本文深入探讨了模型规模与性能之间的关系，并系统研究了视觉编码器、语言模型、数据集大小和测试配置在不同基准测试中的性能趋势。通过广泛基准的大量评估，包括跨学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力和纯粹的语言处理，InternVL 2.5 表现出竞争性性能，超越了包括GPT-4o和Claude-3.5-Sonnet在内的领先商用模型。特别地，这一模型在MMMU基准测试中首次超过70%，通过链条推理（CoT）提高了3.7个百分点，显示出强大的测试时扩展潜力。
### Innovation
InternVL 2.5 通过改进多个方面，实现了显著性能提升，特别是跨学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力和纯粹的语言处理。最显著的是，它首次在MMMU基准测试中超过了70%，通过链条推理（CoT）提高了3.7个百分点，并且是第一个在这方面超过70%的开源多模态大型语言模型。模型的测试时间扩展潜力强大，为开发和应用多模态AI系统定了新的标准。
### Conclusion
我们希望模型能够为开源社区做出贡献，通过设定开发和应用多模态AI系统的标准。
## 955. `cs.CV` - UIP2P: 通过编辑可逆性约束实现无监督基于指令的图像编辑 [PDF](https://arxiv.org/pdf/2412.15216), [HTML](https://arxiv.org/abs/2412.15216)
### Authors
Enis Simsar,Alessio Tonioni,Yongqin Xian,Thomas Hofmann,Federico Tombari
### Background
现有的图像编辑方法依赖于带有输入图像、真实编辑图像和编辑指令的三元组的监督学习。然而，这些三元组通常由现有的编辑方法生成，容易引入偏见，或者通过人力标注获得，这导致了时间和成本问题，并限制了方法的实际应用和推广。因此，一种无需依赖真实编辑图像且能消除现有方法偏见的方法成为了研究的新方向，UIP2P论文即为此目标的发展做出了贡献。
### Innovation
提出了一个无监督的基于指令的图像编辑方法，主要创新在于引入了一个称为编辑可逆性约束（Edit Reversibility Constraint，ERC）的新机制。ERC机制通过一次训练步骤同时应用前向和反向编辑，确保对齐图像、文本和注意力空间。此方法成功地避免了对真实编辑图像的依赖，使得首次能够在包含真实图像配对或图像-文本-指令三元组的数据集上进行训练。实验结果显示，与现有方法相比，UIP2P在更广泛范围的编辑任务中表现更好，具有更高的保真度和精确度。
### Conclusion
UIP2P的工作通过消除对预存三元组数据集的需求以及减少当前方法带来的偏见，引入了编辑可逆性约束（ERC），从而在指令驱动的图像编辑领域实现了重大进展，克服了该领域长期以来的技术瓶颈。
## 956. `cs.CV` - Event2Vec: 直接在向量空间中处理神经形态事件 [PDF](https://arxiv.org/pdf/2504.15371), [HTML](https://arxiv.org/abs/2504.15371)
### Authors
Wei Fang,Priyadarshini Panda
### Background
神经形态事件相机具有优于传统相机的时间分辨率、能耗和动态范围。然而，它们异步且稀疏的数据格式对现有深度学习方法构成了重大挑战。现有的解决方案往往需要牺牲时间分辨率、进行大量预处理操作，且不能充分利用GPU加速。
### Innovation
我们受词到向量模型的启发，将神经形态事件类比为单词，并引入了Event2Vec这一新颖的表示方法，使神经网络能够直接处理这类事件。该方法完全兼容Transformer架构的并行处理和自我监督学习能力。实验结果表明，Event2Vec具有高度的参数效率、高吞吐量，在事件数量极低的情况下也能实现高精度。
### Conclusion
我们的研究提出了一个新的范式，使神经网络能够像处理自然语言一样处理事件流，为事件相机与大型语言模型和多模态模型的原生集成铺平了道路。
## 957. `cs.CV` - 基于在线轻量级视觉转换器的图像识别：综述 [PDF](https://arxiv.org/pdf/2505.03113), [HTML](https://arxiv.org/abs/2505.03113)
### Authors
Zherui Zhang,Rongtao Xu,Jie Zhou,Changwei Wang,Xingtian Pei,Wenhao Xu,Jiguang Zhang,Li Guo,Longxiang Gao,Wenbo Xu,Shibiao Xu
### Background
视觉转换器在自然语言处理领域取得了显著成功，激发了将其适应计算机视觉任务的尝试。与卷积神经网络相比，视觉转换器能够内在地捕捉长距离依赖关系并支持并行处理，但缺乏归纳偏置和效率优势，面临严重的计算和内存挑战，限制其在实际应用中的适用性。
### Innovation
本文概述了各种在线策略以生成用于图像识别的轻量级视觉转换器，重点介绍了三个关键领域：高效组件设计、动态网络和知识蒸馏。对ImageNet-1K基准上的相关探索进行评估，分析了精度、参数、吞吐量等方面的权衡，以突出各自的优点、缺点和灵活性。
### Conclusion
本文提出了轻量级视觉转换器的未来研究方向和潜在挑战，旨在激发进一步的研究并为社区提供实用指导。
## 958. `cs.CV` - CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis [PDF](https://arxiv.org/pdf/2504.19223), [HTML](https://arxiv.org/abs/2504.19223)
### Authors
Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic
### Background
光谱成像在多个领域（如医学和城市场景理解）展现出广泛应用前景，并已成为遥感中的关键模态。然而，不同光谱相机在通道维度和捕获波长方面的差异限制了人工智能驱动方法的发展，导致了局限于特定相机的模型，这些模型缺乏泛化能力和跨相机的适用性。
### Innovation
本文引入了CARL（跨RGB、多光谱和超光谱成像模态的相机无关的表示学习模型）。提出了一种新的光谱编码器，具有自注意-交叉注意机制，能够将任何通道维度的光谱图像转换为相机无关的表示。通过一种基于特征的自监督策略实现了跨域的时空光谱预训练，展示了在医学成像、自主驾驶和卫星成像领域的广泛应用，表现出对光谱异质性的独特稳健性。
### Conclusion
本文提出的方法具有良好的可扩展性和灵活性，将该模型定位为未来光谱基础模型的核心组件。实验结果表明，该模型在具有模拟和真实世界跨相机光谱变化的数据库中表现出色，证明了其独特的优势。
## 959. `cs.CV` - LiT: 探索一种简单的线性扩散变换器在图像生成中的应用 [PDF](https://arxiv.org/pdf/2501.12976), [HTML](https://arxiv.org/abs/2501.12976)
### Authors
Jiahao Wang,Ning Kang,Lewei Yao,Mengzhao Chen,Chengyue Wu,Songyang Zhang,Shuchen Xue,Yong Liu,Taiqiang Wu,Xihui Liu,Kaipeng Zhang,Shifeng Zhang,Wenqi Shao,Zhenguo Li,Ping Luo
### Background
研究团队探讨了如何将预训练的 Diffusion Transformer (DiT) 转换为线性 DiT，这是因为线性 DiT 具有简洁性、并行性和高效率，适用于图像生成。研究者通过详细的研究提供了一系列即用型解决方案，包括线性注意力设计和优化策略。
### Innovation
研究的核心贡献包括五项实用准则：1) 在简单的线性注意力中应用深度卷积就足够用于图像生成；2) 使用较少的注意力头可以提高性能而不会增加延迟；3) 继承完全收敛的预训练 DiT 的权重；4) 只加载除线性注意力相关的参数外的所有参数；5) 混合知识蒸馏：使用预训练的教师线性 DiT 来帮助学生线性 DiT 的训练，并监督反向扩散过程的噪声预测和方差。这些准则激发了我们提出的 ①线性 ②扩散 ③变换器 (LiT)，它是 DiT 的纯线性注意力替代基准。在 256×256 和 512×512 的 ImageNet 图像生成中，LiT 可以快速从 DiT 转换，分别仅需 20% 和 33% 的训练步数，同时达到相当的性能。此外，LiT 在文本到图像生成中表现也相当出色，能够从 PixArt-$?$ 转换生成高质量的图像，保持相当的 GenEval 分数。
### Conclusion
LiT 提供了一种安全且高效的替代基线，适用于纯粹线性注意力的 DiT，在分类条件下的 256×256 和 512×512 的 ImageNet 生成中，LiT 能够仅用 DiT 的 20% 和 33% 的训练步骤进行快速适应，同时达到相当的性能，而且它的方法也适用于文本到图像的生成。
## 960. `cs.CV` - Intentional Gesture: 通过手势表达意图以辅助言语 [PDF](https://arxiv.org/pdf/2505.15197), [HTML](https://arxiv.org/abs/2505.15197)
### Authors
Pinxin Liu,Haiyang Liu,Luchuan Song,Jason J. Corso,Chenliang Xu
### Background
当人类说话时，手势有助于传达交流意图，例如强调或描述概念。然而，当前的伴随言语手势生成方法仅依赖于表面语言线索（例如语音音频或文本转录），而忽视了理解和利用支撑人类手势的交流意图。这种情况下，虽然输出与言语节奏同步，但语义却浅薄。
### Innovation
本文介绍了一种名为Intentional-Gesture的新颖框架，着眼于将手势生成转化为基于高级交流功能的意图推理任务。首先，通过在BEAT-2数据集中增加手势意图注释（即意图的文本总结）来构建InG数据集，并利用大规模视觉-语言模型自动注释这些意图。接着，引入了具有意图注释的Intentional Gesture Motion Tokenizer，该方法将高级交流功能（例如意图）注入为标记化的运动表示，以便生成具有时间和语义同步性的意图感知手势，最终在BEAT-2基准测试上取得了新的最佳性能。
### Conclusion
我们的框架为数字人类和具身人工智能中的表达手势生成提供了一个可模块化的基础。
## 961. `cs.CV` - PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval [PDF](https://arxiv.org/pdf/2502.07215), [HTML](https://arxiv.org/abs/2502.07215)
### Authors
Osman Tursun,Sinan Kalkan,Simon Denman,Clinton Fookes
### Background
当前的零样本组合图像检索（ZS-CIR）方法依赖于组合文本嵌入，存在三个关键局限性：固定的查询嵌入表示、图像嵌入利用不足以及组合文本和图像嵌入融合性能不佳。这些局限性限制了ZS-CIR的实际效率和效果。
### Innovation
为解决这些挑战，本文引入了一种名为Prompt Directional Vector（PDV）的简单有效训练前增强方法，它能够捕捉由用户提示引发的语义修改。PDV带来三大改进：动态组合文本嵌入，可通过缩放因子控制提示调整；通过语义传递从文本提示到图像特征的组合图像嵌入；以及基于权重的组合文本和图像嵌入融合，这种融合增强了检索性能，平衡了视觉和语义相似性。该方法可轻松应用于现有的ZS-CIR方法，无需额外计算资源。
### Conclusion
跨多个基准的广泛实验表明，PDV在与最先进的ZS-CIR方法结合时能一致地提高检索性能，尤其是在那些生成准确组合嵌入的方法中。代码将在发表后公开。
## 962. `cs.CV` - VidCRAFT3: 相机、对象和光照控制的图像到视频生成 [PDF](https://arxiv.org/pdf/2502.07531), [HTML](https://arxiv.org/abs/2502.07531)
### Authors
Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu
### Background
在内容创制作流程中，对相机运动、对象运动和光照方向的精确且同时控制可以显著提高准确性和灵活性。然而，现有方法通常将这些控制信号独立处理，主要是由于高质量联合注释数据集的稀缺性以及不同模态之间控制空间的不匹配所致。
### Innovation
本文提出了VidCRAFT3，这是一种统一且灵活的图像到视频生成框架，它通过整合三个核心组件，支持独立和联合地控制相机运动、对象运动和光照方向。具体而言，Image2Cloud从参考图像中重建3D点云以实现精确的相机运动控制；ObjMotionNet将稀疏的对象轨迹编码为多尺度光学流特征，以指导对象运动；Spatial Triple-Attention Transformer 通过并行交叉注意力整合光照方向嵌入。此外，文章还创建了一个名为VideoLightingDirection (VLD) 的合成静止场景视频片段数据集，其中包含每帧的光照方向标签，并采用三阶段训练策略，使模型能够在缺乏完全联合注释的情况下进行稳健学习。
### Conclusion
详尽的实验表明，VidCRAFT3在控制精度和视觉连贯性方面优于现有方法。代码和数据将在未来公开。
## 963. `cs.CV` - 八分频视觉变换器：通过等变性实现更快的ViTs [PDF](https://arxiv.org/pdf/2505.15441), [HTML](https://arxiv.org/abs/2505.15441)
### Authors
David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman
### Background
当前最先进的视觉变换器（ViTs）并没有利用自然几何对称性，如90度旋转和反射。本文探讨了缺乏这些对称性处理的内在原因，并指出主要是由于缺乏高效的实现方式。
### Innovation
提出了八分频视觉变换器（octic ViTs），利用八分频组等变性来捕捉这些对称性。octic线性层相较于普通的线性层，实现了5.33倍的FLOPs减少和最高8倍的内存减少。八分频ViT块的计算减少接近记录的线性层减少，随着嵌入维度的增加更明显。
### Conclusion
通过在ImageNet-1K上进行监督（DeiT-III）和无监督（DINOv2）训练，八分频ViTs与其基线相比，取得了相当的准确率，同时还实现了显著的效率提升。
## 964. `cs.CV` - PhyMAGIC：基于置信指导的物理感知生成推理 [PDF](https://arxiv.org/pdf/2505.16456), [HTML](https://arxiv.org/abs/2505.16456)
### Authors
Siwei Meng,Yawei Luo,Ping Liu
### Background
近年来，3D内容生成的进步对动态模型的需求增加了，这些模型需要同时具备视觉逼真和物理一致性。然而，最先进的视频扩散模型通常会产生不可靠的结果，如动量违反和物体穿插。现有的物理感知方法往往依赖于特定任务的微调或监督数据，这限制了它们的可扩展性和适用性。
### Innovation
PhyMAGIC提出了一种无需训练的框架，可以从单个图像生成物理一致的运动。PhyMAGIC结合了预训练的图像到视频扩散模型、通过LLM（大型语言模型）进行的置信指导推理以及可微物理仿真器，以生成适用于下游物理仿真无需微调或手动监督的3D资产。利用LLM衍生的置信分数迭代细化运动提示，并通过仿真反馈进行调整，PhyMAGIC引导生成符合物理一致性的动力学。
### Conclusion
全面的实验表明，PhyMAGIC在性能上超过了最先进的视频生成器和物理感知基线，提高了物理属性推理和运动文本对齐，同时保持了视觉保真度。
## 965. `cs.CV` - DanceText: 一种无需训练的分层框架，用于图像中的可控多语言文本变换 [PDF](https://arxiv.org/pdf/2504.14108), [HTML](https://arxiv.org/abs/2504.14108)
### Authors
Zhenyu Yu,Mohd Yamani Idna Idris,Hua Wang,Pei Wang,Rizwan Qureshi,Shaina Raza,Aman Chadha,Yong Xiang,Zhixiang Chen
### Background
尽管基于扩散的生成模型在文本引导的图像合成方面显示出了潜力，但它们通常缺乏可控性，并且在进行旋转、平移、缩放和扭曲等非平凡操作时难以保持布局一致性。
### Innovation
DanceText 引入了一种分层编辑策略，将文本与背景分离，使得几何变换可以以模块化和可控的方式进行。进一步提出了一种深度感知模块，用于对齐变换后的文本与重建的背景之间的外观和透视，增强逼真度和空间一致性。DanceText 是一种完全无需训练的设计，通过整合预训练模块，实现灵活部署，无需特定任务的微调。
### Conclusion
在 AnyWord-3M 基准上的广泛实验表明，我们的方法在视觉质量方面表现为更优，尤其是在大规模和复杂变换场景下。代码可在此处获取：this https URL.
## 966. `cs.CV` - LiteGS: 亚分钟内通过系统与算法协同设计训练3DGS的高性能框架 [PDF](https://arxiv.org/pdf/2503.01199), [HTML](https://arxiv.org/abs/2503.01199)
### Authors
Kaimin Liao,Hua Wang,Zhi Chen,Luchao Wang,Yaohua Tang
### Background
3D高斯点云（3D Gaussian Splatting，3DGS）作为一种有前途的3D表示方法正在兴起，但仍然面临着高昂的训练成本问题。现有方法在实现3DGS模型时，训练成本较高，影响了其应用价值和普及率。为此，该研究提出了一种名为LiteGS的新框架，旨在系统地优化3DGS的训练管道，从低级计算层、中级数据管理层和高级算法层等多个维度进行改进，以提高训练效率和模型质量。
### Innovation
LiteGS框架在多个层面进行了创新优化，具体包括：1. 在低级计算层设计基于“变形光栅”的计算方法，结合两项硬件感知优化措施，显著减少了梯度缩减开销；2. 在中级数据管理层引入基于Morton编码的动态空间排序，实现高效“聚类消除-紧凑化”管道，提高数据局部性，减少缓存缺失；3. 在高级算法层建立新的鲁棒聚类准则，基于不透明度梯度的方差，配以更稳定不透明度控制机制，实现更精确的参数增长，从而实现更快的训练速度、更高的模型精度和更优的性能表现。
### Conclusion
实验结果表明，与原3DGS训练相比，LiteGS框架可将训练速度提升高达13.4倍，同时保持或提高模型质量。这对于轻量级模型，在同等速度下，LiteGS的性能比当前最先进的方法快1.4倍。在高质量重建任务中，LiteGS还创造了新的准确性纪录，并将训练时间缩短了一个数量级。
## 967. `cs.CV` - GeoDANO：具有通用视觉编码器的几何VLM [PDF](https://arxiv.org/pdf/2502.11360), [HTML](https://arxiv.org/abs/2502.11360)
### Authors
Seunghyuk Cho,Zhenyue Qin,Yang Liu,Youngbin Choi,Seungbeom Lee,Dongwoo Kim
### Background
尽管视觉语言模型（VLMs）已经被用于解决几何学问题，但它们识别几何特征的能力尚未得到充分分析。现有的视觉编码器，如OpenCLIP，往往无法识别几何特征（如点、线及其关系），这阻碍了模型在不同领域的泛化能力。该研究旨在改进视觉编码器在几何问题上应用的表现，特别针对平面上的几何问题（如解决平面几何问题），提出了一种新的几何Vision-Language模型GeoDANO。
### Innovation
提出了一种新的几何Vision-Language模型GeoDANO，该模型包含一个通用的视觉编码器，用于解决几何问题。开发了GeoCLIP模型，这是一种基于CLIP的模型，专门训练于合成的几何图与其描述之间的对（图-描述对）。GeoDANO通过增量增强GeoCLIP的通用视觉编码器，并引入了领域适应策略，使模型能够处理未见过的图示风格，从而在解决平面上的几何问题以及在MathVerse上的性能超越了专门的方法和GPT-4o。
### Conclusion
GeoDANO通过引入通用视觉编码器和领域适应策略，在识别几何特征和解决平面上的几何问题方面取得了显著的性能提升，超越了专门的方法和GPT-4o的表现。
## 968. `cs.CV` - DVD-Quant：无数据视频扩散变换器量化 [PDF](https://arxiv.org/pdf/2505.18663), [HTML](https://arxiv.org/abs/2505.18663)
### Authors
Zhiteng Li,Hanxuan Li,Junyi Wu,Kai Liu,Haotong Qin,Linghe Kong,Guihai Chen,Yulun Zhang,Xiaokang Yang
### Background
Diffusion Transformers（DiTs）已成为视频生成的最新架构，但其计算和内存需求限制了其实用部署。现有方法存在的两个关键问题是依赖计算昂贵且不灵活的校准过程以及量化后性能显著下降。
### Innovation
我们提出了DVD-Quant，这是一种新颖的数据无依赖量化框架用于视频DiTs。我们的方法整合了三个核心创新：（1）有界初始化格细化（BGR）、（2）自动缩放旋转量化（ARQ）以减少量化误差，以及（3）δ引导位开关（δ-GBS）以实现自适应位宽分配。
### Conclusion
在多项视频生成基准上的广泛实验表明，DVD-Quant在高级DiT模型上实现了比全精度基线大约2倍的加速，同时保持视觉保真度。值得注意的是，DVD-Quant是第一个在不影响视频质量的情况下使Video DiTs实现W4A4后训练量化的技术。代码和模型将在该网址处提供：this https URL.
## 969. `cs.CV` - 基于Mamba的拓扑融合单目3D人体姿态估计 [PDF](https://arxiv.org/pdf/2505.20611), [HTML](https://arxiv.org/abs/2505.20611)
### Authors
Zenghao Zheng,Lianping Yang,Jinshan Pan,Hegui Zhu
### Background
基于Transformer的方法在3D人体姿态估计中面临着显著的计算挑战，因为自注意力机制的复杂性随序列长度的增加呈二次增长。最近，Mamba模型通过利用状态空间模型（SSM）显著减少了计算开销并展示了在处理长序列方面的出色表现。然而，SSM在处理具有拓扑结构的关节序列时能力有限，而Mamba中的因果卷积结构也缺乏对局部关节关系的洞察。
### Innovation
提出了一种基于Mamba的拓扑融合框架——Mamba-Driven Topology Fusion。该框架通过引入骨感知模块，推断球坐标系中的骨骼向量的方向和长度，提供有效的拓扑指导以处理关节序列。此外，通过集成前向和后向图卷积网络增强Mamba模型的卷积结构，使其更好地捕捉局部关节依赖关系。最后，设计了一个时空精炼模块来建模序列中的时空关系。通过融合骨骼拓扑，本文方法有效地缓解了Mamba在捕捉人体结构关系方面的局限性。
### Conclusion
在Human3.6M和MPI-INF-3DHP数据集上进行了广泛的实验测试和对比，结果显示提出的方法在计算成本显著降低的同时，实现了更高的准确度。消融研究表明每种提出的模块的有效性。代码和模型将被发布。
## 970. `cs.CV` - SPEED: 可扩展、精确且高效的扩散模型概念消除方法 [PDF](https://arxiv.org/pdf/2503.07392), [HTML](https://arxiv.org/abs/2503.07392)
### Authors
Ouxiang Li,Yuan Wang,Xinting Hu,Houcheng Jiang,Tao Liang,Yanbin Hao,Guojun Ma,Fuli Feng
### Background
由于版权侵权、不当内容和隐私泄露的担忧日益增加，从大规模文本到图像（T2I）扩散模型中消除概念变得越来越重要。在可扩展的应用场景中，基于微调的方法在精确消除多个目标概念方面耗时较长，而实时编辑的方法往往会由于优化目标的冲突而导致非目标概念生成质量下降。为解决这一困境，提出了SPEED，这是一种直接编辑模型参数的高效概念消除方法。SPEED在不影响非目标概念生成的前提下，通过寻找参数更新不会影响非目标概念的 null space，从而实现有效的、及时的概念消除并保持可扩展性。为了实现准确的 null space 优化，SPEED 结合了三种互补策略：基于影响的先验过滤（IPF）、定向先验增强（DPA）和不变等价约束（IEC），以确保在 T2I 生成过程中保留关键不变量。广泛的评价结果显示，SPEED 在非目标概念保护方面表现优于现有方法，同时具有高效且高保真的概念消除能力，并能 在短短 5 秒内消除 100 个概念。
### Innovation
SPEED 提出了一种高效的概念消除方法，该方法直接编辑模型参数，从而避免了基于微调的方法的耗时特性以及实时编辑方法对非目标概念生成质量的负面影响。通过寻找一个参数更新不会影响非目标概念的 null space，SPEED 能够实现可扩展、精确且高效的概念消除，同时结合了三种互补策略以促进准确的 null space 优化，确保生成过程中关键不变量的保留。
### Conclusion
SPEED 在多个概念消除任务中的广泛评估结果表明，它在非目标概念保护方面表现优于现有方法，并能有效且高效地实现概念的精确消除。SPEED 以 5 秒内消除 100 个概念的能力，为大规模 T2I 扩散模型提供了具有高保真度的可扩展和高效的概念消除方法。
## 971. `cs.CV` - 无姿态3D 高斯点云渲染通过形状-光线估计 [PDF](https://arxiv.org/pdf/2505.22978), [HTML](https://arxiv.org/abs/2505.22978)
### Authors
Youngju Na,Taeyeon Kim,Jumin Lee,Kyu Beom Han,Woo Jae Kim,Sung-eui Yoon
### Background
通用可泛化的3D高斯点云渲染可以高效且高质量地渲染未见场景，但是强烈依赖准确的相机姿态以保证几何形状的精确。在实际场景中，精确获取姿态十分困难，导致姿态估计噪声大，从而几何对齐出现问题。
### Innovation
引入了无姿态、前馈的高斯点云渲染框架SHARE，通过联合形状和相机光线估计来解决这些问题。SHARE不依赖于显式的3D变换，而是构建一种感知姿态的通用体素表示，无缝整合多视图信息，从而减少因姿态估计不准确导致的对齐错误。此外，围绕粗锚点进行的锚点对齐高斯预测可以进一步优化场景重构，使高斯点云的放置更加精确。
### Conclusion
在多样化的现实世界数据集上，我们的方法在无姿态的可泛化高斯点云渲染中表现出稳健的性能。
## 972. `cs.CV` - 更深的扩散模型放大偏差 [PDF](https://arxiv.org/pdf/2505.17560), [HTML](https://arxiv.org/abs/2505.17560)
### Authors
Shahin Hakemi,Naveed Akhtar,Ghulam Mubashar Hassan,Ajmal Mian
### Background
尽管生成扩散模型（Diffusion Models, DMs）表现出色，但其内部工作机制尚未被充分理解，这可能成为一个问题。本研究旨在研究扩散模型中的偏差-方差权衡的重要概念。
### Innovation
该论文为这一探索提供了一个系统的基础，证明了扩散模型在极端情况下，可能会放大训练数据中的固有偏差，同时在另一种极端情况下可能会牺牲训练样本的假设隐私。研究结果不仅证实了生成模型中记忆-泛化理解，还进一步揭示了在更深的模型中偏差放大所带来的风险。
### Conclusion
我们的主张在理论上和实验上都得到了验证，显示出扩散模型在更深层次中更容易放大偏差的风险。
## 973. `cs.CV` - Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection [PDF](https://arxiv.org/pdf/2506.03162), [HTML](https://arxiv.org/abs/2506.03162)
### Authors
Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh
### Background
随着监控摄像头的迅速增加，自动化暴力检测的需求也随之提升。传统的卷积神经网络(CNNs)和变换器( Transformers)能够提取时空特征，但在处理长时依赖问题和计算效率方面存在不足。
### Innovation
提出了一种高效的Dual Branch VideoMamba模型，结合了双分支设计和状态空间模型(SSM)背部框架。模型通过一种门控机制融合了空间特征和时间动态特征，增强了模型在检测暴力活动方面的能力，特别是在具有挑战性的监控场景中。此外，还提出了一种新的基准数据集，结合了RWF-2000、RLVS、SURV和VioPeru数据集，确保了训练集和测试集的严格分离。
### Conclusion
实验结果表明，该模型在新的基准数据集和另一个新的视频暴力检测数据集DVD上均达到了最先进的性能，展示了状态空间模型在可扩展、近实时监控暴力检测中的潜力。
## 974. `cs.CV` - Astraea: 一种视频扩散变换器的按令牌加速框架 [PDF](https://arxiv.org/pdf/2506.05096), [HTML](https://arxiv.org/abs/2506.05096)
### Authors
Haosong Liu,Yuge Cheng,Wenxuan Miao,Zihan Liu,Aiyue Chen,Jing Lin,Yiwu Yao,Chen Chen,Jingwen Leng,Yu Feng,Minyi Guo
### Background
视频扩散变换器（vDiTs）在文本到视频生成方面取得了巨大进展，但由于其高计算需求，其实际部署面临重大挑战。虽然有研究表明提出了加速方法来减少工作量，但这些方法往往依赖于启发法，限制了它们的应用范围。
### Innovation
Astraea 提出了一种框架，用于在目标性能下搜索近最优的 vDiT 基于视频生成配置。核心是 Astraea 提出了一个轻量级的令牌选择机制和一个内存高效且 GPU 友好的稀疏注意力策略，这使得执行时间减少了线性比例，同时对生成质量的影响较小。为了确定不同时间步长的最佳 token 折扣，Astraea 设计了一种搜索框架，利用经典的进化算法自动确定令牌预算的有效分布。
### Conclusion
Astraea 在单个 GPU 上实现了高达 2.4 倍的推理速度提升，具有很大的扩展性（最多 8 个 GPU 上实现 13.2 倍的速度提升），同时在视频质量上实现了高达 10 dB 的提升（相对于最先进的方法，在 VBench 上相对于基线的损失少于 0.5%）
## 975. `cs.CV` - 通过强化微调实现统一多模态链式思考奖励模型 [PDF](https://arxiv.org/pdf/2505.03318), [HTML](https://arxiv.org/abs/2505.03318)
### Authors
Yibin Wang,Zhimin Li,Yuhang Zang,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang
### Background
近期，多模态奖励模型（RMs）在使视觉模型与人类偏好对齐方面表现出显著潜力，然而，当前的RMs通常只能提供直接响应或进行浅显的推理过程，导致奖励信号不够准确。因此，研究提出将明确的长推理链（CoT）引入奖励推理过程，以增强其可靠性和鲁棒性，并认为一旦RMs内化了CoT推理，其直接响应的准确性也可以通过隐式推理能力得到提高。
### Innovation
本文提出了UnifiedReward-Think，这是首个结合多模态CoT的统一体系化奖励模型，能够在视觉理解和生成奖励任务中进行多维度、分步的长推理链推理。该模型通过一种探索驱动的强化微调方法，引导模型发掘其潜在复杂的推理能力：首先使用少量的图像生成偏好数据提取GPT-4o的推理过程，用于模型的冷启动来学习CoT推理的格式和结构；其次利用模型的先验知识和泛化能力准备大规模统一多模态偏好数据，以引发模型在各种视觉任务中的推理过程，将正确的推理输出保留用于拒绝采样以精炼模型，而错误预测样本则用于基于组相对策略优化（GRPO）的强化微调，使模型探索多样化的推理路径并优化正确的、鲁棒的解决方案。
### Conclusion
通过广泛的多模态奖励任务实验，证明了该模型的优越性。
## 976. `cs.CV` - OS-W2S: 一种用于语言引导的开放集航空物体检测的自动标注引擎 [PDF](https://arxiv.org/pdf/2505.03334), [HTML](https://arxiv.org/abs/2505.03334)
### Authors
Guoting Wei,Yu Liu,Xia Yuan,Xizhe Xue,Linlin Guo,Yifan Yang,Chunxia Zhao,Zongwen Bai,Haokui Zhang,Rong Xiao
### Background
近年来，语言引导的开放集航空物体检测由于更符合实际应用需求而受到了广泛关注。然而，由于数据集有限，现有的大多数语言引导方法主要依赖词汇级别的描述，这无法满足细粒度开放世界检测的需求。
### Innovation
本文提出了一个大规模的语言引导开放集航空检测数据集，并构建了一个命名为OS-W2S Label Engine的自动标注管道，该管道能够处理航空图像的各种场景注释。此外，使用该数据集构建了一个名为MI-OAD的新基准数据集，解决了当前遥感场景语义定位数据的局限性，支持有效的语言引导的开放集航空检测。
### Conclusion
MI-OAD包含163,023张图像和200万个图像-描述语对，大约是类似数据集的40倍。在语言引导的开放集航空检测中，使用MI-OAD训练提升了Grounding DINO的AP$_{50}$ +31.1和Recall@10 +34.7的零样本转移性能。此外，使用MI-OAD进行预训练在多个现有开放词汇航空检测和遥感视觉定位基准测试中达到了最先进的性能，验证了该数据集的有效性和高质量OS-W2S注释。
## 977. `cs.CV` - 机器之前先有结构：输入空间是概念的前提 [PDF](https://arxiv.org/pdf/2506.08543), [HTML](https://arxiv.org/abs/2506.08543)
### Authors
Bowei Tian,Xuntao Lyu,Meng Liu,Hongyi Wang,Ang Li
### Background
高级表示已经成为提升AI透明度和控制性的重要焦点，人们的关注点已经从单个神经元或电路转向了与人类可解释概念相一致的结构化语义方向。受到线性表示假设（LRH）的启发，本文提出了一种输入空间线性假设（ISLH），即概念对齐的方向起源于输入空间，并随着网络深度增加被有选择地放大。这项工作通过结合理论洞察和实证验证，推进了对于深度网络中表示形成结构化理论的发展，为提高AI的可靠性、公正性和透明度奠定了基础。
### Innovation
本文提出了一种输入空间线性假设（ISLH），并引入了振谱主要路径（SPP）框架，该框架描述了深度网络如何逐步提炼出一组主振谱方向上的线性表示。此外，该工作还展示了这些表示在视觉-语言模型（VLMs）中的多模态鲁棒性。
### Conclusion
通过结合理论洞见与实证验证，这项工作推进了深度网络中表示形成结构化理论的发展，并为提高AI的可靠性、公正性和透明性提供了路径。
## 978. `cs.CV` - CARE: 为医学生物标志物提供的置信度感知比例估计 [PDF](https://arxiv.org/pdf/2505.19585), [HTML](https://arxiv.org/abs/2505.19585)
### Authors
Jiameng Li,Teodora Popordanoska,Aleksei Tiulpin,Sebastian G. Gruber,Frederik Maes,Matthew B. Blaschko
### Background
在临床实践中，诸如肿瘤内坏死组织的比例等基于比率的生物标志物被广泛使用，以支持诊断、预后和治疗计划。现有的方法通常仅提供点估计，而不提供不确定性衡量。由于临床决策的重要性，这一现状需要改进的方法来提供更为可靠的生物标志物估计和置信区间估算
### Innovation
本文提出了一种统一的置信度感知框架，用于估算基于比率的生物标志物。此框架源自两个观察结果：一）概率比率估计器本身可以提供与局部随机性（偏差和方差）相关的统计置信区间，二）分割网络并非完全校准。本文系统分析了从分割到生物标志物管道中的误差传播，并确定模型校准偏差是主要的不确定性来源。通过调整参数控制置信区间的置信水平，使方法适应临床实践要求
### Conclusion
通过广泛的实验表明，作者的方法能够产生统计上有意义的置信区间，并且可以通过调整置信水平来适应各种临床实践需求，从而增强预测生物标志物在临床工作流程中的应用可靠性
## 979. `cs.CV` - ChartGalaxy: 用于信息图表理解和生成的数据集 [PDF](https://arxiv.org/pdf/2505.18668), [HTML](https://arxiv.org/abs/2505.18668)
### Authors
Zhen Li,Duan Li,Yukai Guo,Xinyuan Guo,Bowen Li,Lanxi Xiao,Shenyu Qiao,Jiashu Chen,Zijian Wu,Hui Zhang,Xinhuan Shu,Shixia Liu
### Background
信息图表是一种通过结合视觉元素（例如图表、图像）和文本信息来传达抽象数据的强大媒介。然而，信息图表的视觉和结构丰富性给大型语义图像模型（LVLMs）带来了挑战，因为这些模型通常仅针对简单的图表进行了训练。为了解决这一差距，作者提出了ChartGalaxy，这是一个百万规模的数据集，旨在推进信息图表的理解和生成。该数据集通过归纳过程从真实的信息图表中确定了75种图表类型、440种图表变体和68种布局模板，并使用它们来程序化地生成合成信息图表。
### Innovation
ChartGalaxy是一个通过归纳过程构建的百万级数据集，用于促进信息图表的理解和生成。它通过识别实际信息图表中的75种图表类型、440种图表变体和68种布局模板，并使用这些元素程序化地生成合成信息图表，来捕捉实际设计的视觉和结构复杂性。作者利用此数据集展示了其在信息图表理解、代码生成基准测试以及示例为基础的信息图表生成方面的应用，从而为大型视觉-语言模型提供了有用的资源，以增强多模态推理和生成能力。
### Conclusion
通过采样真实设计的视觉和结构复杂性，ChartGalaxy为大型视觉-语言模型提供了增强多模态推理和生成能力的有效资源。
## 980. `cs.CV` - 视频生成模型中的物理导向运动损失 [PDF](https://arxiv.org/pdf/2506.02244), [HTML](https://arxiv.org/abs/2506.02244)
### Authors
Bowen Xue,Giuseppe Claudio Guarnera,Shuang Zhao,Zahra Montazeri
### Background
当前的视频扩散模型能够生成视觉上引人注目的内容，但往往违反了基础物理法则，产生了如橡皮膜变形和物体运动不一致等细微的视觉误差。因此，需要一种不改变模型架构的方法来提高视频中的运动可信度。
### Innovation
提出了一种频域物理先验方法，该方法不修改模型架构就能提高运动的可信度，通过将常见的刚性运动（平移、旋转、缩放）分解为轻量级的频谱损失，只需要2.7%的频率系数就能保留97%以上的频谱能量。该方法应用于Open-Sora、MVDIT和Hunyuan，通过OpenVID-1M改进了约11%的动作识别准确度，同时保持视觉质量。此外，用户研究显示，用户对增强物理学的视频有74%-83%的偏好，并且错误扭曲减少了22%-37%（取决于模型架构），改善了时序一致性评分。这一结果表明，简单的全局频谱线索可以有效地作为物理可信赖运动的正则化手段。
### Conclusion
该研究表明，简单的全局频谱线索作为物理可信赖运动的正则化是有效的，不仅能改善视频中的物理可信度，还能提高动作识别精度和视觉质量，且用户更偏好这些增强物理学特性的视频。
## 981. `cs.CV` - 迈向3D医疗成像中的可扩展语言-图像预训练 [PDF](https://arxiv.org/pdf/2505.21862), [HTML](https://arxiv.org/abs/2505.21862)
### Authors
Chenhui Zhao,Yiwei Lyu,Asadur Chowdury,Edward Harake,Akhil Kondepudi,Akshay Rao,Xinhai Hou,Honglak Lee,Todd Hollon
### Background
当前语言-图像预训练方法在处理如CT和MRI等3D医学成像数据时受到限制，因为需要放射科医生手动整理原始临床研究数据。这限制了这种预训练方法的规模。本研究旨在克服这一限制，通过直接在未整理的研究数据上进行预训练，更符合放射科医生的工作流程，同时也提供了一种自然的可扩展路径。然而，未整理的数据特有的结构对现有模型架构提出了新的挑战，这些架构原本设计用于2D切片或单一3D扫描。为了应对这一挑战，研究引入了一种受放射学数据内在层级结构启发的新颖层次注意力机制，即层次语言-图像预训练框架（HLIP）
### Innovation
研究提出了一种新的层次注意力机制，即HLIP框架，用于3D医疗成像中的语言-图像预训练。该机制能够处理未整理的数据，并通过捕捉数据的层次结构，改善了模型的适应性。HLIP在大量神经影像学研究数据上进行了训练，并在公开的基准测试中达到了最先进的性能，例如在提出的Pub-Brain-5基准测试中，准确率提高了10.5%；在头CT基准测试中，宏观AUC分别提高了8.3%和1.7%；在已有的3D医学语言-图像预训练基准测试中表现良好，例如在Rad-ChestCT基准测试中，宏AUC提高4.3%。这些结果表明，直接在未整理的临床数据集上进行预训练是一种具有可扩展性和有效性的发展方向
### Conclusion
研究证明了直接在未整理的临床数据集上进行预训练是一种可扩展且有效的3D医学成像中语言-图像预训练的方向。这种方法不仅改善了模型的性能，还提供了更具实用性的实践途径。
## 982. `cs.CV` - 通过视频思考实现有目的的长视频理解 [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。现有方法不是通过单次推理舍弃细粒度细节，就是依赖于基于任务泛化的表示进行文本推理，这妨碍了专门的任务感知与探索。
### Innovation
本文提出了VideoExplorer框架，该框架基于“视频思考”的原则，自然地将规划、时间固着和可扩展感知整合到一个连贯的推理过程中。VideoExplorer通过迭代形成子问题、定位相关时刻，并进行目的明确的时间可扩展视频理解，直到达到最终答案，实现了忠实、高效和可解释的推理。为了解决LVU训练资源的不足，作者使用难度自适应采样构建了一个长视频推理数据集，确保在复杂任务上提供高质量的轨迹。在此数据集上，设计了一种两阶段的训练管道：监督轨迹初始化后面跟着轨迹层面的偏好优化。该方法鼓励时间固着的适应性及通过下游奖励引导的迭代信息整合。
### Conclusion
广泛的评估显示，VideoExplorer在流行长视频理解和推理基准测试中显著优于现有基线，突显了其鲁棒性、适应性和效率。相关代码已在此代码库中公开（见提供的链接）。
## 983. `cs.CV` - ReSpace: 通过偏好对齐进行的文本驱动的3D室内场景合成与编辑 [PDF](https://arxiv.org/pdf/2506.02459), [HTML](https://arxiv.org/abs/2506.02459)
### Authors
Martin JJ. Bucher,Iro Armeni
### Background
在计算机图形学中，场景合成和编辑已成为一种有前景的研究方向。目前的3D室内场景生成方法要么通过单一热编码简化对象语义（例如‘椅子’或‘桌子’），要么需要使用蒙版扩散图来进行编辑，要么忽略了房间边界，要么依赖于平面图渲染，无法捕捉复杂的布局。基于语言模型的方法可以通过自然语言增强了语义（例如‘现代工作室，配有柔和的木质家具’），但缺乏编辑功能，且仅限于矩形布局，或者依赖于隐式世界模型的弱空间推理能力。这些方法在综合考虑用户指令、空间几何、对象语义和场景级组合方面面临挑战。
### Innovation
ReSpace引入了一种基于自回归语言模型的生成框架，用于基于文本的3D室内场景合成与编辑。该框架采用紧凑的结构化场景表示，并明确表示房间边界，实现了资产无关的部署。它将场景编辑建模为下一标记预测任务，并采用两阶段训练方法结合监督微调和偏好对齐，从而特别训练语言模型进行对象添加，并考虑到用户指令、空间几何、对象语义和场景级组合。此外，通过零样本语言模型处理对象删除和添加请求，并采用基于体素的评价方法捕捉细粒度几何结构，超越了现有技术在添加任务方面表现，并在整体场景合成方面具有更高的用户体验质量。
### Conclusion
实验结果表明，ReSpace在添加任务上超过现有最先进的方法，并在整体场景合成方面获得了更高的用户感知质量。
## 984. `cs.CV` - DriveAction: 用于探索VLA模型中类人类驾驶决策的标准 [PDF](https://arxiv.org/pdf/2506.05667), [HTML](https://arxiv.org/abs/2506.05667)
### Authors
Yuhan Hao,Zhengning Li,Lei Sun,Weilong Wang,Naixin Yi,Sheng Song,Caihong Qin,Mofan Zhou,Yifei Zhan,Xianpeng Lang
### Background
现有的视觉-语言-行动（VLA）模型已经在自动驾驶领域取得了进展，但现有的基准测试仍然缺乏场景多样性、可靠的行动级注释以及与人类偏好对齐的评估协议。为此，该研究引入了DriveAction这一新的基准测试，专门设计用于评估VLA模型，包含来自2610个驾驶场景的超过16,185个问答对。这些数据来源于自动驾驶车辆的司机真实驾驶数据，确保了广泛和代表性场景的覆盖，同时也提供了直接由司机实际驾驶操作收集的高阶离散动作标签，并采用以行动为中心的树状结构评估框架，将视觉、语言和行动任务明确关联，支持全面和特定任务的评估。现有研究表明，最先进的视觉-语言模型（VLM）预测准确的行动需要同时获得视觉和语言的指导，缺乏任一输入都会导致准确性显著下降，平均分别下降3.3%、4.1%和8.0%。
### Innovation
DriveAction是首个用于VLA模型的行动驱动基准测试，通过主动收集来自自动驾驶汽车驾驶员的真实驾驶数据，确保广泛和代表性的场景覆盖；提供直接来自驾驶员实际操作的高级离散动作标签；并引入一个以行动为中心的树状结构评估框架，能够明确地链接视觉、语言和行动任务，支持全面和特定任务的评估。此外，DriveAction对现有最佳视觉-语言模型的有效性进行评估，揭示了模型的瓶颈，促进了类人类决策在自动驾驶中的进步。
### Conclusion
实验结果显示，最先进的视觉-语言模型在准确预测行动方面需要同时视觉和语言的指导，缺乏视觉或语言输入会显著降低模型准确性。DriveAction的评估能够精确识别模型缺陷，并提供一致和稳健的结果，这为推动自动驾驶的类人类决策提供了新的见解和严谨的基础。
## 985. `cs.CV` - 视觉推理以编辑：基于假设指令的图像编辑 [PDF](https://arxiv.org/pdf/2507.01908), [HTML](https://arxiv.org/abs/2507.01908)
### Authors
Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang
### Background
指令驱动的图像编辑(IIE)随着扩散模型的成功发展迅速。现有的努力主要集中在简单而明确的指令，如添加、删除、移动或交换对象上。然而，它们难以处理更复杂的隐式假设指令，这些指令需要更多的推理才能推断出合理的视觉变化和用户的意图。目前的数据集也缺乏对训练和评估推理解释编辑能力的支持。此外，现有的方法也缺乏用于支持这种推理的细粒度细节提取机制。
### Innovation
提出了Reason50K，一个专门为训练和评估假设指令推理图像编辑而精心收集的大规模数据集，以及ReasonBrain，一个新的框架，用于在各种场景中推理和执行隐式假设指令。Reason50K包括涵盖四大类推理场景（物理、时间、因果和故事推理）的超过50,000个样本。ReasonBrain利用多模态大语言模型(MLLM)生成编辑指导，并利用扩散模型进行图像合成，其中包含一个细粒度推理线索提取(FRCE)模块，以捕捉支持指令推理的重要视觉和文本语义细节。为了缓解语义损失，引入了交叉模态增强器(CME)，使其能够实现细粒度线索与从MLLM衍生特征之间丰富的交互。
### Conclusion
广泛的实验证明，ReasonBrain在推理场景中始终优于最先进的基线，并且在传统IIE任务上有很强的零样本泛化能力。我们的数据集和代码将公开发布。
## 986. `cs.CV` - HiSin: 一种面向大分辨率修复的扇形图意识框架 [PDF](https://arxiv.org/pdf/2506.08809), [HTML](https://arxiv.org/abs/2506.08809)
### Authors
Jiaze E,Srutarshi Banerjee,Tekin Bicer,Guannan Wang,Yanfu Zhang,Bin Ren
### Background
高分辨率扇形图插值对于计算机断层扫描重建至关重要，因为缺失的高频投影会导致可见伪影和诊断错误。扩散模型因其稳健性和细节保留能力而非常适合此任务，但由于处理高分辨率输入时所需的内存和计算资源过多，其应用受到限制。为了解决这一限制，我们提出了HiSin，一种新颖的基于扩散的框架，用于高效的扇形图插值。该框架利用投影数据的频谱稀疏性和结构异质性，低分辨率下逐步提取全局结构，而高分辨率下的推理则针对小补丁实现，从而实现内存有效的插值。考虑到扇形图的结构特征，我们引入了频率感知的补丁跳过和结构自适应步长分配，以减少冗余计算。实验结果表明，与最先进的框架相比，HiSin可以将峰值内存使用量最多减少30.81%，推理时间最多减少17.58%，同时保持插值精度。
### Innovation
HiSin框架通过利用投影数据的频谱稀疏性和结构异质性，在低分辨率下逐步提取全局结构，并将高分辨率推理的计算任务分配给小补丁，从而实现内存有效的扇形图插值。此外，该框架引入了频率感知的补丁跳过和结构自适应步长分配，以进一步减少计算冗余。实验表明，与当前最先进的框架相比，HiSin在内存使用量和推理时间上具有明显优势，同时保持插值的准确性。
### Conclusion
实验结果证明，HiSin框架能够有效减少峰值内存使用量和推理时间，同时保持插值精度，为高分辨率扇形图插值提供了新的解决方案。
## 987. `cs.CV` - LEO-VL: 效率场景表示用于可扩展的3D视觉语言学习 [PDF](https://arxiv.org/pdf/2506.09935), [HTML](https://arxiv.org/abs/2506.09935)
### Authors
Jiangyong Huang,Xiaojian Ma,Xiongkun Linghu,Yue Fan,Junchao He,Wenxin Tan,Qing Li,Song-Chun Zhu,Yixin Chen,Baoxiong Jia,Siyuan Huang
### Background
在3D视觉语言（3D-VL）领域，开发能够理解3D场景的视觉语言模型（VLMs）一直是一个长期的目标。尽管最近取得了一些进展，但当前的3D VLMs在能力和鲁棒性方面仍然无法与2D VLMs相媲美。一个关键瓶颈是，当前的场景表示难以平衡性能和效率：要想获得竞争力的性能，就必须付出大量的标记代价，这反过来阻碍了3D-VL学习的可扩展性。
### Innovation
本文提出了紧凑特征网格（CFG），一种高效且标记代价显著降低的场景表示方法，同时具备强大的感知能力。基于CFG，作者引入了LEO-VL，这是一种3D VLM，通过处理700k三个真实世界室内外域的3D-VL数据训练，涵盖了诸如 captioning 和对话等五个任务。此外，作者还提出了SceneDPO用于后训练增强3D VLM的鲁棒性，包括场景之间的对比。
### Conclusion
LEO-VL在SQA3D、MSQA和Beacon3D等多个3D问答基准数据集上取得了最先进的性能。广泛的实验进一步展示了我们的表示法的高效性、多样任务和场景的好处、持续的规模效应以及SceneDPO相对于SFT和GRPO的优势。希望我们的研究成果能够促进未来的3D VLMs在效率、可扩展性和鲁棒性方面的进步。
## 988. `cs.CV` - VidBridge-R1：通过中介代理任务实现基于强化学习的视频理解模型中的QA和字幕生成 [PDF](https://arxiv.org/pdf/2506.09079), [HTML](https://arxiv.org/abs/2506.09079)
### Authors
Xinlong Chen,Yuanxing Zhang,Yushuo Guan,Weihong Lin,Zekun Wang,Bohan Zeng,Yang Shi,Sihan Yang,Qiang Liu,Pengfei Wan,Liang Wang,Tieniu Tan
### Background
当前，通过强化学习增强的‘推理后响应’范式在多模态大语言模型中显示出巨大潜力，尤其是在视频领域。然而，这一范式在视频领域的应用导致了专用于问答（QA）或字幕生成任务的模型，但不擅长同时处理这两种任务。直接结合这两种任务的奖励信号会导致性能下降，这被认为是由于任务性质的冲突所致。
### Innovation
本文提出了一种新的训练框架，通过两种中介代理任务来解决这一挑战：DarkEventInfer和MixVidQA。DarkEventInfer通过使用隐藏的事件片段测试模型的基于上下文的推理能力；而MixVidQA则通过交错显示两个不同的剪辑来挑战模型对其中一个进行推理的同时忽略另一个。这些中介任务促使模型同时发展全面的发散理解和精确的收敛推理能力。基于此框架，本文提出了VidBridge-R1，这是第一个有效的桥接上述范式冲突的视频推理模型。实验证明，VidBridge-R1在问答和字幕生成任务上均表现出显著的效能提升，证明了该方法在培养更通用和强大的视频理解模型中的有效性。
### Conclusion
本次研究展示了一种新的训练框架，通过中介代理任务有效解决了视频理解模型中QA和字幕生成任务的范式冲突，该模型在两种任务上都实现了显著的性能提升，验证了该方法的有效性。
## 989. `cs.CV` - DriveAgent-R1：基于VLM的主动感知与混合思维增强自主驾驶 [PDF](https://arxiv.org/pdf/2507.20879), [HTML](https://arxiv.org/abs/2507.20879)
### Authors
Weicheng Zheng,Xiaofei Mao,Nanfei Ye,Pengxiang Li,Kun Zhan,Xianpeng Lang,Hang Zhao
### Background
视觉语言模型（VLMs）的出现显著推动了端到端的自主驾驶技术，展示了强大高层次行为规划任务的推理能力。然而，现有的方法通常受限于被动感知的范式，仅通过文本推理运行，这种被动方式限制了模型在不确定性面前主动寻求关键视觉证据的能力。
### Innovation
提出了一种新的自主驾驶Agent——DriveAgent-R1，具备主动感知能力，能够在复杂场景中主动调用工具进行视觉推理，基于视觉证据做出决策，以提高决策的可解释性和可靠性。此外，DriveAgent-R1采用了受人类驾驶员认知模式启发的混合思考框架，实现在场景复杂度的基础上灵活切换纯文本推理和工具增强视觉推理，通过三层阶梯式训练策略（核心阶段为Cascaded RL）进行训练。实验证明，DriveAgent-R1使用3B参数就能达到与顶级闭合模型系统（如GPT-5）相当的性能，且具有人性化驾驶能力，具有部署友好性。
### Conclusion
DriveAgent-R1展示了在复杂驾驶场景中，通过主动感知和混合思考框架能够实现高效、可靠、人性化的自主驾驶，是一个构建更智能自主驾驶系统的有力途径。
## 990. `cs.CV` - TAMMs: 时态意识多模态模型用于卫星图像变化理解和预测 [PDF](https://arxiv.org/pdf/2506.18862), [HTML](https://arxiv.org/abs/2506.18862)
### Authors
Zhongbin Guo,Yuhao Wang,Ping Jian,Chengzhi Li,Xinyue Chen,Zhen Yang,Ertai E
### Background
在卫星图像时间序列分析中，时态变化描述（TCD）和未来卫星图像预测（FSIF）是两个关键任务，但历史研究往往将这两个任务分离处理。这两个任务都受限于对长距离时态动态建模的共同挑战。为了探索如何通过增强长距离时态理解能力来同时提升两种任务的性能，引入了TAMMs，一个统一框架，它在单一的MLLM-扩散架构中联合处理TCD和FSIF。
### Innovation
TAMMs引入了两个关键创新：时间适应模块（TAM）增强冻结的MLLM对长距离动态的理解，并且语义融合控制注入（SFCI）机制将这些变化的理解转化为精细生成控制。这种协同设计使得TCD任务的理解可以直接指导和提升FSIF任务的一致性。
### Conclusion
广泛的实验表明，TAMMs在两种任务上优于最新的专业基线。
## 991. `cs.CV` - NarrLV：长视频生成综合叙事评价体系 [PDF](https://arxiv.org/pdf/2507.11245), [HTML](https://arxiv.org/abs/2507.11245)
### Authors
X. Feng,H. Yu,M. Wu,S. Hu,J. Chen,C. Zhu,J. Wu,X. Chu,K. Huang
### Background
随着基础视频生成技术的快速发展，长视频生成模型展示了广阔的研究潜力，部分得益于内容创作空间的扩大。近期研究发现，长视频生成任务的目标不仅是延长视频时长，还需准确表达更为丰富的故事内容。但由于缺乏专门针对长视频生成模型的评估基准，目前这些模型的评估主要依赖于以简单叙事提示为基准的评价标准（例如VBench）。到目前为止，我们提出了NarrLV作为首个综合评估长视频生成模型叙事表达能力的基准。
### Innovation
我们引入了Temporal Narrative Atom (TNA)作为基本的叙事单元，用以定量测量叙事丰富度。基于对TNA变化影响的关键叙事元素，我们构建了一个能够生成可扩展数量TNA的自动提示生成流水线。据此，我们基于叙事内容表达的三个渐进层次，设计了一个有效评估度量方法，并使用基于MLLM的问答框架。我们对现有长视频生成模型和基础生成模型进行了广泛评估，实验证明我们的度量标准与人类判断高度一致，揭示了当前视频生成模型在叙事内容表达方面的详细能力边界。
### Conclusion
实验结果表明，我们的度量标准与人类判断高度接近。得出的评估结果展示了现有视频生成模型在叙事内容表达方面的详细能力边界。
## 992. `cs.CV` - video-SALMONN 2：增强的音频-视觉大型语言模型 [PDF](https://arxiv.org/pdf/2506.15220), [HTML](https://arxiv.org/abs/2506.15220)
### Authors
Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang
### Background
该论文提出了video-SALMONN 2，这是一种在视频描述和问答任务上达到新最佳性能的音频-视觉大型语言模型。其核心贡献是多轮直接偏好优化（Multi-round Direct Preference Optimization，MrDPO），配有联合奖励完整性和事实准确性的标题质量目标。与使用固定参考策略的标准DPO不同，MrDPO通过从最新偏好中重新初始化轻量级适配器进行阶段性刷新参考策略，从而避免了参考策略过时，并实现了持续改进。该方法生成的字幕比像GPT-4o和Gemini-1.5 Pro这样的专有系统更详细和准确。此外，通过使用模型生成高质量的视频配字幕语料库，用于监督微调新模型，从而超越了字幕生成任务，实现了复杂的视频问答任务的强劲表现。在广泛使用的音频-视觉和纯视觉理解基准测试（包括Video-MME、WorldSense、AVUT、Video-Holmes、DailyOmni、MLVU和LVBench）中，该论文的3B和7B模型在相同规模下达到了最佳性能，而72B模型则超越了所有开源系统。
### Innovation
论文的核心贡献是多轮直接偏好优化（MrDPO），这个方法能够避免参考策略过时问题，并实现持续改进。与传统的DPO方法不同，MrDPO通过从最新偏好中重新初始化轻量级适配器进行阶段性刷新参考策略，能够生成比专有系统更详细和准确的字幕。此外，该论文进一步通过使用模型生成高质量的视频配字幕语料库，实现跨任务性能提升，特别是强健的表现力在复杂视频问答任务上。
### Conclusion
该论文展示了video-SALMONN 2在视频描述和问答任务上的优越性能，取得了新的SOTA。3B和7B模型在多个基准测试中达到最佳性能，而72B模型超越了所有开源系统。这些技术贡献不仅提升了字幕生成的质量，还增强了模型在复杂视频问答任务中的性能。所有相关资源都已经开源。
## 993. `cs.CV` - Ctrl-Z Sampling: 采用受控随机之字形探索的扩散采样 [PDF](https://arxiv.org/pdf/2506.20294), [HTML](https://arxiv.org/abs/2506.20294)
### Authors
Shunqi Mao,Wei Guo,Chaoyi Zhang,Jieting Long,Ke Xie,Weidong Cai
### Background
扩散模型在条件生成任务中表现出强大的性能，通过逐步去噪高斯样本逼近目标数据分布。这一去噪过程可被解释为在学习表示空间中的一种形式的爬坡过程，模型迭代地将样本向更高概率区域精炼。然而，这种学习爬坡通常因潜在空间复杂性和初始不理想导致陷入局部最优，所得生成结果尽管看似合理但常常不尽如人意。尽管先前的一些努力通过强化指导信号或引入固定的探索策略来解决这一问题，但它们在逃避陡峭局部最大值的能力上仍然有限。
### Innovation
我们提出了控制随机之字形采样（Ctrl-Z Sampling），一种新的采样策略，能够通过受控探索动态地检测和逃逸潜在的陷阱。在每次扩散步骤中，首先使用奖励模型识别潜在的局部最大值，一旦检测到这些最大值，便注入噪声并回到一个更嘈杂的状态以脱离当前的平台。随后，奖励模型评估候选路径，只接受提高的路径，否则进行更深层次的探索。这种受控的之字形过程允许在正向精炼和反向探索之间动态切换，从而增强生成输出的对齐度和视觉质量。该方法在与现有扩散框架兼容的前提下，对模型具有通用性。实验结果表明，与原始模型相比，只增加了约7.72倍的NFEs（逆传播梯度估计算法），Ctrl-Z Sampling显著提高了生成质量。
### Conclusion
提出的Ctrl-Z Sampling方法通过控制探索动态地检测和逃逸局部最大值陷阱，不仅增强生成输出的对齐度和视觉质量，而且具有对模型的通用性和与现有扩散框架的兼容性，同时只需较少的NFEs即可达到显著提升生成质量的效果。
## 994. `cs.CV` - pFedMMA: 使用多模态适配器的个性化联邦微调方法 [PDF](https://arxiv.org/pdf/2507.05394), [HTML](https://arxiv.org/abs/2507.05394)
### Authors
Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani
### Background
视觉-语言模型（VLMs）如CLIP在零样本和少量样本设置中表现出色，但在分布式、异构数据上的高效适应仍然是一个挑战。尽管提示调优作为一种参数高效的个性化联邦学习方法得到了广泛应用，但它们往往在获得个性化的同时牺牲了泛化能力，特别是在未见过的类或领域上表现不佳。
### Innovation
本文提出了一种新的个性化联邦学习框架pFedMMA，该框架利用多模态适配器进行视觉-语言任务。每个适配器包含模态特定的上层和下层投影层以及一个全局共享的投影层，用于对齐跨模态特征。设计允许客户端本地适应个性化数据分布并协同训练共享投影以提高全局泛化能力。此设计还实现了通信效率，因为只需在通信周期中交换共享组件。
### Conclusion
通过针对11个数据集（涵盖领域和标签转移场景）的广泛实验，结果表明，pFedMMA在个性化和泛化之间的权衡中实现了最先进的性能，优于最近的联邦提示调优方法。
## 995. `cs.CV` - SIU3R: 超越特征对齐的同步场景理解与3D重建 [PDF](https://arxiv.org/pdf/2507.02705), [HTML](https://arxiv.org/abs/2507.02705)
### Authors
Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu
### Background
同时理解和3D重建对开发端到端的具身智能系统至关重要。近期方法依赖于2D到3D特征对齐范式，这限制了3D理解能力和可能会导致语义信息的丢失。
### Innovation
提出了SIU3R，一种无需特征对齐的一体化框架，用于从未 posed 图像中实现泛化的同步理解和3D重建。特别地，SIU3R通过像素对齐的3D表示连接重建和理解任务，并将多个理解（分割）任务统一为一组可学习查询，从而可以在无需2D模型对齐的情况下实现原生的3D理解。此外，通过深入分析它们的相互利益，并提出两种轻量级模块来促进它们之间的交互。
### Conclusion
大量实验结果表明，我们的方法在3D重建和理解的单任务以及同步理解和3D重建任务上都达到了最先进的性能，突显了我们无特征对齐框架的优势和相互利益设计的有效性。
## 996. `cs.CV` - Shape-for-Motion: 使用3D代理实现精确一致的视频编辑 [PDF](https://arxiv.org/pdf/2506.22432), [HTML](https://arxiv.org/abs/2506.22432)
### Authors
Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W.H. Lau
### Background
近年来，深度生成模型的发展为视频合成带来了前所未有的机会。但在实际应用中，用户常寻求能够准确实现其创意编辑意图的工具，要求精确且一致的控制。尽管已有的方法取得了进步，但如何确保编辑与用户意图的细粒度对齐依然是一个开放且极具挑战性的问题。本文提出了Shape-for-Motion框架，通过引入3D代理实现精确和一致的视频编辑。“Shape-for-Motion”通过将输入视频中的目标对象转换为时序一致的网格（3D代理），实现了这种编辑，从而允许用户直接在代理上进行编辑，然后将其推断回视频帧。这种方法简化了编辑流程，并支持各种精确且物理可靠的跨帧编辑，包括姿态编辑、旋转、缩放、平移、纹理修改和物体组合。
### Innovation
Shape-for-Motion框架的创新之处在于它通过引入3D代理，实现了精确和一致的视频编辑。首先，通过将视频中的目标对象转换为时间一致的3D网格（3D代理），并且用户可以直接在这3D网格上进行编辑，然后自动推断回每一帧，实现了编辑的简化与精确控制。此外，该框架还设计了一种新型的双传播策略，可让用户在单帧的3D网格上进行编辑，然后自动推断到其他帧的3D网格中。进一步地，这些3D网格会被投影到2D空间，产生编辑过的几何和纹理渲染，作为独立视频扩散模型的输入以生成最终的编辑结果。因此，该框架支持多种精确且物理一致的跨帧编辑，标志着高质量、可控视频编辑流程的关键一步。
### Conclusion
大量实验表明，该方法具有优势和有效性，框架支持多种精确且物理一致的跨帧编辑。Shape-for-Motion解决了一个重大挑战，即将3D编辑直接应用于视频帧，这标志着高质量、可控视频编辑流程的关键一步。
## 997. `cs.CV` - RAAG: 比例感知自适应引导 [PDF](https://arxiv.org/pdf/2508.03442), [HTML](https://arxiv.org/abs/2508.03442)
### Authors
Shangwen Zhu,Qianyu Peng,Yuting Hu,Zhantao Yang,Han Zhang,Zhao Pu,Andy Zheng,Zhilei Shu,Ruili Feng,Fan Cheng
### Background
流基生成模型已经取得了显著进展，无分类指导（CFG）已成为高保真生成的常用方法。然而，常规的在整个推理过程中应用固定强度的指导放大比例的做法，不适合现代应用所需的快速、少量步骤采样。原因在于采样不稳定，早期步骤对指导极其敏感，这主要是由于条件预测与非条件预测比率的显著增长，这种增长是训练数据分布的固有特性，几乎不可避免。在此期间应用高静态指导值会导致错误指数放大，影响图像质量。
### Innovation
本文提出了一种简单、理论基础的方法——自适应指导调度（Adaptive Guidance Schedule），这种调度方法能在早期步骤自动降低指导比例，根据不断变化的比率进行调整。该方法轻量级且不需要额外的推理成本，且与标准框架兼容。实验表明，该方法使采样速度提高至3倍，在保持或提高质量、稳定性和语义对齐方面表现出色。
### Conclusion
本文的研究强调，适应采样过程调整指导而非固定指导，对于充分发挥快速流基模型的潜力至关重要。通过这种方式，可以实现更快的采样速度，同时保持或提升图像质量、鲁棒性和语义对齐。
## 998. `cs.CV` - 在多模态大型语言模型中调查多种视觉编码器的冗余性 [PDF](https://arxiv.org/pdf/2507.03262), [HTML](https://arxiv.org/abs/2507.03262)
### Authors
Yizhou Wang,Song Mao,Yang Chen,Yufan Shen,Yinqiao Yan,Pinlong Cai,Ding Wang,Guohang Yan,Zhi Yu,Xuming Hu,Botian Shi
### Background
最近的多模态大型语言模型（MLLMs）越来越多地整合了多种视觉编码器，用于在各种基准测试中提高性能，假设不同的预训练目标会产生互补的视觉信号。这项研究揭示了这一假设在实践中往往无效。
### Innovation
该研究通过系统地屏蔽代表性的多编码器MLLMs中的编码器，发现性能通常会平滑下降甚至在部分情况下提升，表明存在过度冗余的编码器。引入了两个专 attributable metrics：条件利用率（CUR）和信息差距（IG），用于量化编码器的边际贡献和模型内编码器的异质性。并通过这些工具发现（i）在OCR和图表任务等任务上呈现高度专业化，一个编码器可以占据超过90%的贡献率；（ii）在通用视觉问答（VQA）和知识依赖任务上存在高度冗余；（iii）存在一些具有负面影响的编码器，其贡献率甚至为负的实例。特定编码器的遮蔽可以显著提高特定任务类别的准确率，并且在总体性能上提高3.6%。单一和双编码器变体在大多数非OCR任务上恢复了超过90%的基线表现。
### Conclusion
这项研究挑战了越多编码器越好的假说，并提供了针对发展更高效和有效的多模态架构的可操作诊断工具。
## 999. `cs.CV` - GLEAM：在跨视角地理定位中学习匹配与解释 [PDF](https://arxiv.org/pdf/2509.07450), [HTML](https://arxiv.org/abs/2509.07450)
### Authors
Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Peifeng Ma,Xue Yang,Hongsheng Li
### Background
跨视角地理定位（CVGL）旨在识别从不同角度拍摄的同一地理位置的图像之间的对应关系。现有的CVGL方法通常局限于单一视角或模态，并且缺乏解释力：它们仅确定两幅图像是否对应，而不解释匹配的理由。现有的方法训练效率较低，且解释能力不足。
### Innovation
提出了GLEAM-C模型，这是一种基础的CVGL模型，它可以统一多种视角和模态（如无人机航拍、街道地图、全景视图和地面照片），并与卫星影像对齐。该框架通过优化实现提升了训练效率，并通过两阶段训练策略实现与前模态特定的CVGL模型相当的准确性。此外，提出GLEAM-X任务，结合了跨视角对应预测和可解释的推理，利用多模态大语言模型（MLLMs）增强了解释能力，并构建了双语基准来生成训练和测试数据。
### Conclusion
GLEAM-C和GLEAM-X共同形成了一种全面的CVGL流水线，集成了多模态、多视角对齐与可解释的对应分析，结合了准确的跨视角匹配和可解释的推理，推动了Geo-定位的发展。相关代码和数据集将在该网址公开：the https URL。
## 1000. `cs.CV` - STQE: 空间-时间属性质量增强用于G-PCC压缩的动态点云 [PDF](https://arxiv.org/pdf/2507.17522), [HTML](https://arxiv.org/abs/2507.17522)
### Authors
Tian Guo,Hui Yuan,Xiaolong Mao,Shiqi Jiang,Raouf Hamzaoui,Sam Kwong
### Background
很少有研究关注压缩动态点云的质量提升，尤其是点云帧之间空间-时间相关性的有效利用尚处于探索阶段。为此，本文提出了一种空间-时间属性质量增强（STQE）网络，旨在通过利用空间和时间的相关性来改善G-PCC压缩动态点云的视觉质量。
### Innovation
提出了基于色彩修正的运动补偿模块，将参考属性信息重新映射到当前帧的几何形状，以实现精确的帧间几何对齐；提出了通道感知的时间注意力模块，可以在双向参考帧之间动态突出关键区域；引入了基于高斯引导的邻域特征聚合模块，高效地捕捉几何和颜色属性之间的空间依赖性；设计了一种基于皮尔逊相关系数的联合损失函数，旨在缓解点间均方误差优化中常见的过度平滑效应。这些创新解决了深度学习在点云处理中的挑战，并显著提升了点云压缩质量。
### Conclusion
STQE在网络测试中表现优异，在不同的成分上分别实现了0.855 dB、0.682 dB和0.828 dB在∆PSNR上的提升，同时Bjøntegaard Δ速率（BD-rate）减少了-25.2%、-31.6%和-32.5%。
## 1001. `cs.CV` - RelMap: 通过类感知空间关系和语义先验增强在线地图构建 [PDF](https://arxiv.org/pdf/2507.21567), [HTML](https://arxiv.org/abs/2507.21567)
### Authors
Tianhui Cai,Yun Zhang,Zewei Zhou,Zhiyu Huang,Jiaqi Ma
### Background
在线高清（HD）地图构建对于扩展自动驾驶系统至关重要。尽管基于Transformer的方法在在线HD地图构建中变得流行，但大多数现有方法忽视了地图元素间的内在空间依赖性和语义关系，限制了其准确性和泛化能力。
### Innovation
我们提出了RelMap，这是一种端到端框架，明确建模空间关系和语义先验以提升在线HD地图构建。该框架包括类感知空间关系先验，通过可学习的类感知关系编码器明确编码地图元素间的相对位置依赖关系。同时，设计了基于专家混合的语义先验，根据预测的类别概率将特征路由到类特定专家，以细化实例特征解码。RelMap与单帧和时间感知骨干网络兼容，在nuScenes和Argoverse 2数据集上均达到最先进的性能。
### Conclusion
RelMap通过明确建模空间关系和语义先验，显著提升了在线HD地图构建的性能。
## 1002. `cs.CV` - $A^2R^2$: 通过注意力引导的精炼视理学推理推动Img2LaTeX转换 [PDF](https://arxiv.org/pdf/2507.20890), [HTML](https://arxiv.org/abs/2507.20890)
### Authors
Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai
### Background
Img2LaTeX是一个重要任务，涉及将图像中的数学表达式和结构化视觉内容翻译成LaTeX代码。近年来，视觉语言模型（VLMs）在多种视觉理解任务中取得了显著进展，主要是由于其强大的泛化能力。然而，尽管初期尝试将VLMs应用于Img2LaTeX任务，其性能仍不理想。实验证据表明，VLMs在处理如数学表达式中的下标和上标等细粒度视觉元素时存在挑战，导致LaTeX生成不准确。
### Innovation
本文提出了一种名为$A^2R^2$的框架，即通过注意力引导的反馈精炼视理学推理来提高Img2LaTeX转换。该框架有效结合了注意力定位和迭代精炼，使VLMs能够进行自我纠正，并逐步提高LaTeX生成质量。为了有效的评估，作者引入了一个新的数据集Img2LaTeX-Hard-1K，其中包括1100个精心挑选且具有挑战性的例子，旨在严格评估VLMs在该任务中的能力。广泛的实验证明：（1）$A^2R^2$在多种评估指标上显着提高了模型性能；（2）增加推理轮次可以带来性能提升，突显了$A^2R^2$在测试时扩展场景中的潜力；（3）消融研究和进一步评估确认了该方法的有效性及其核心组件在推理过程中的协同作用。
### Conclusion
实验结果表明，$A^2R^2$显著提高了模型在各种评估指标上的性能，提高了LaTeX生成质量，并且在测试时的扩展场景中也表现出色。
## 1003. `cs.CV` - 重叠重构与跨尺度传播：实现实时神经压缩的LiDAR点云 [PDF](https://arxiv.org/pdf/2508.20466), [HTML](https://arxiv.org/abs/2508.20466)
### Authors
Pengpeng Yu,Haoran Li,Runqing Jiang,Jing Wang,Liang Lin,Yulan Guo
### Background
LiDAR点云在各种应用中至关重要，但高精度扫描会导致存储和传输的高开销。现有方法通常通过将无序点转换为层次八叉树或体素结构来进行密集到稀疏的预测编码，但这导致了几何细节的极大稀疏，阻碍了有效的上下文建模，从而限制了压缩性能和速度。
### Innovation
本文提出了一种生成紧凑特征以实现高效预测编码的方法。该框架包括两个轻量级模块：首先，几何重密化模块重新密化编码的稀疏几何结构，提取更密集的特征，然后对特征进行重新稀疏化以进行预测编码。这样可以避免在高度稀疏细节上进行昂贵的计算，同时保持轻量级的预测头部。其次，跨尺度特征传播模块利用多个分辨率级别上的占位信息来引导层次特征传播，促进跨尺度信息共享，减少冗余特征提取并为几何重密化模块提供丰富特征。通过将这两个模块结合起来，我们的方法产生了紧凑的特征表示，提供了有效的上下文建模并加速了编码过程。
### Conclusion
实验在KITTI数据集上展示了最先进的压缩比和实时性能，实现每秒26帧的编码/解码速度，量化精度为12位。代码已公开。
## 1004. `cs.CV` - Content-Aware Mamba for Learned Image Compression [PDF](https://arxiv.org/pdf/2508.02192), [HTML](https://arxiv.org/abs/2508.02192)
### Authors
Yunuo Chen,Zezheng Lyu,Bing He,Hongwei Hu,Qi Wang,Yuan Tian,Li Song,Wenjun Zhang,Guo Lu
### Background
最近的基于学习的图像压缩（LIC）利用了Mamba风格的状态空间模型（SSM），用于全局感受野并且保持线性复杂度。然而，标准Mamba采用内容无关的、预定义的逐行扫描（或多重方向扫描）并且在严格的因果性下运行。这种固定的扫描方式限制了其在内容相关但空间上距离较远的标记之间有效消除冗余的能力。
### Innovation
我们提出了一种内容感知型Mamba（CAM），它动态适应图像内容。具体来说，CAM通过两种新颖机制克服了以往的限制。首先，它用内容自适应的标记置换策略替换固有的扫描，以优先处理内容相似的标记之间的交互，而不管它们的位置如何。其次，它通过向状态空间模型注入样本特定的全局先验来克服序列依赖性，从而有效缓解了严格的因果性，而无需使用多方向扫描。这些创新使CAM能够更好地捕捉全局冗余，同时保持计算效率。
### Conclusion
基于Content-Aware Mamba的内容导向型LIC模型（CMIC），在Kodak、Tecnick和CLIC数据集上的BD-rate表现超过VTM-21.0，分别高出15.91%、21.34%和17.58%。源代码和检查点稍后将发布。
## 1005. `cs.CV` - 一种结合关键帧识别、ONSD测量和临床数据的完全自动颅内压分级框架 [PDF](https://arxiv.org/pdf/2509.09368), [HTML](https://arxiv.org/abs/2509.09368)
### Authors
Pengxu Wen,Tingting Yu,Ziwei Nie,Cheng Jiang,Zhenyu Yin,Mingyang He,Bo Liao,Xiaoping Yang
### Background
颅内压（ICP）升高对脑功能构成严重威胁，因此需要进行监测以便及时干预。虽然腰椎穿刺是ICP测量的金标准，但由于其侵入性和相关风险，寻找非侵入性替代方法的需求变得迫切。ONSD（视神经鞘直径）作为一种有前景的生物标志物，已被认为是ICP升高的直接指标，但当前临床实践中进行ONSD测量存在手动操作不一致、视图选择主观性和阈值设定不统一等问题，这些都限制了其可靠性。
### Innovation
该研究提出了一种完全自动的两阶段框架来对ICP进行分级，该框架结合了关键帧识别、准确的ONSD测量和多源信息的临床数据整合。与传统的基于阈值的方法相比，该方法在交叉验证和独立测试中的验证和测试准确性分别达到了0.845 ± 0.071和0.786，明显高于传统方法（0.637 ± 0.111的验证准确性和0.429的测试准确性）。通过有效减少操作者变异性并整合多源信息，该框架为临床ICP评估提供了一种可靠的非侵入性方法，对于急性神经科病患的管理具有潜在的改善作用。
### Conclusion
该框架展示了可解释的超声分析与多源数据集成在客观临床评估中的创新结合，建立了可靠的非侵入性策略以评估临床ICP，有望改善急性神经科条件患者的管理。
## 1006. `cs.CV` - 微小凹痕，巨大影响：车辆凹痕检测的数据集与深度学习方法 [PDF](https://arxiv.org/pdf/2508.15431), [HTML](https://arxiv.org/abs/2508.15431)
### Authors
Danish Zia Baig,Mohsin Kamal,Zahid Ullah
### Background
传统的汽车损坏检查技术耗时、手动操作，并且经常忽略微小的表面缺陷如微小凹痕。为了应对对更快、更精准的检查方法的需求，深度学习提供了一个创新的解决方案。传统的汽车损伤检测过程手动、耗时且可靠性低，经常难以检测出细微的缺陷问题。因此，研究团队创建了一个定制的数据集，包含了不同光线条件、角度和纹理的汽车表面的标注图片，以提高模型的稳定性和鲁棒性。实验结果表明，该方法具有优良的检测准确性和较低的推理延迟，适合实时应用如自动化保险评估和汽车检查。
### Innovation
该研究采用YOLOv8目标识别框架，基于深度学习的方法自动检测汽车外部的微观表面缺陷，尤其是微小凹痕。此外，团队通过实时数据增强方法对YOLOv8m模型及其定制变体YOLOv8m-t4和YOLOv8m-t42进行训练，以提高模型的稳健性和一致性。YOLOv8m-t42模型在识别微观表面缺陷方面表现最佳，具有较高的精度、召回率和F1分数，并且在实际凹痕检测应用中更具适用性。
### Conclusion
YOLOv8m-t42模型在检测微小表面缺陷方面表现出更高的准确性和一致性，优于之前的YOLOv8m-t4模型。尽管它的收敛速度较慢，但在实际应用中更为合适。
## 1007. `cs.CV` - Draw-In-Mind: 在统一多模态模型中重新平衡设计者与绘画者的角色有助于图像编辑 [PDF](https://arxiv.org/pdf/2509.01986), [HTML](https://arxiv.org/abs/2509.01986)
### Authors
Ziyun Zeng,Junhao Zhang,Wei Li,Mike Zheng Shou
### Background
近年来，将多模态理解和生成集成到单个统一模型中已成为一种有前途的范式。尽管这种方法在文本到图像（T2I）生成上取得了优异的结果，但在精确图像编辑方面仍存在问题。我们将其归因于责任分配的不平衡。理解模块主要作为翻译器，将用户的指令编码为语义条件，而生成模块则必须同时承担设计师和画家的角色，推断原始布局，识别目标编辑区域，并呈现新的内容。这种不平衡是因为理解模块通常通过比生成模块多几倍的数据来训练复杂推理任务的数据。
### Innovation
为了解决这一问题，我们提出了Draw-In-Mind (DIM) 数据集，包括两个互补的子集：(i) DIM-T2I，包含1400万个长语境的图像-文本对，以增强复杂指令的理解；(ii) DIM-Edit，在GPT-4o的生成下，包含23.3万个思维链图像想象，作为明确的设计蓝图，用于图像编辑。我们通过一个轻量级的两层MLP将一个冻结的Qwen2.5-VL-3B与一个可训练的SANA1.5-1.6B连接起来，并在提出的DIM数据集上进行训练，得到DIM-4.6B-T2I/Edit。尽管参数规模有限，但DIM-4.6B-Edit在ImgEdit和GEdit-Bench基准测试中达到了SOTA或竞争力表现，优于像UniWorld-V1和Step1X-Edit等更大规模的模型。研究结果表明，明确将设计责任分配给理解模块对图像编辑有显著益处。我们的数据集和模型可在以下链接获取：[this https URL]（链接需手动替换为实际的URL）。
### Conclusion
这些发现表明，明确将设计责任分配给理解模块对图像编辑有显著益处。我们的数据集和模型可在提供的链接中获取。
## 1008. `cs.CV` - Vivid-VR: 从文本到视频扩散转换器提取概念以实现逼真视频修复 [PDF](https://arxiv.org/pdf/2508.14483), [HTML](https://arxiv.org/abs/2508.14483)
### Authors
Haoran Bai,Xiaoxu Chen,Canqian Yang,Zongyao He,Sibin Deng,Ying Chen
### Background
在利用 advanced T2V 基础模型进行生成视频恢复的背景下，之前的方法通常依赖于 ControlNet 控制生成过程，以保持内容的一致性。然而，受到多模态对齐不完美的影响，传统的可控制管道在微调过程中会经常出现分布漂移现象，使得纹理真实感和时间连贯性受到削弱。为解决这一挑战，本文提出了一种概念蒸馏训练策略，利用预训练的 T2V 模型合成嵌入了文本概念的训练样本，从而将其实质性地理解传给模型，以保留纹理和时间质量。为了增强生成过程的可控性，重新设计了控制架构，包括一个控制特征投影器和一个基于双分支设计的新 ControlNet 连接器。这两个组件分别有助于从输入视频潜在特征中过滤退化伪影，以最小化其在生成管道中的传播，并实现内容保留和自适应控制信号调整，从而实现更好的纹理真实感、视觉生动性和时间一致性。
### Innovation
本文提出了 Vivid-VR，一种基于 DiT 的生成视频恢复方法，构建在先进的 T2V 基础模型之上，并使用 ControlNet 控制生成过程，确保内容一致性。为解决传统微调过程中多模态对齐不完美的分布漂移问题，提出了一种概念蒸馏训练策略，利用预训练的 T2V 模型合成嵌入了文本概念的训练样本。此外，重新设计的控制架构包括一个控制特征投影器和一个基于双分支设计的新 ControlNet 连接器，该连接器结合了基于 MLP 的特征映射和交叉注意力机制，以实现动态的控制特征检索，同时保留内容并调整自适应控制信号调制，从而提高生成可控性。
### Conclusion
本文方法在合成和真实世界基准上以及来自 AIGC 的视频上都优于现有方法，实现了令人印象深刻的纹理真实感、视觉生动性和时间一致性。源代码和检查点已公开可用。
## 1009. `cs.CV` - 基于潜在先验编码的感知退化全面图像恢复 [PDF](https://arxiv.org/pdf/2509.17792), [HTML](https://arxiv.org/abs/2509.17792)
### Authors
S M A Sharif,Abdur Rehman,Fayaz Ali Dharejo,Radu Timofte,Rizwan Ali Naqvi
### Background
现实世界的图像经常遭受空间多样性退化的影响，如雾、雨、雪和低光照等，这些都会显著影响视觉质量和下游视觉任务。现有的全面恢复（AIR）方法要么依赖外部文本提示，要么嵌入手工设计的架构先验（例如频域直觉），这两种方法都对未知或混合退化的情况泛化能力较弱。
### Innovation
为了克服上述限制，本文提出将AIR重新定义为学习潜在先验推断，以自动从输入中推断出退化感知的表示，同时无需明确的任务提示。基于潜在先验，将AIR形式化为一种结构化推理范式：(1) 功能选择（自适应特征选择），(2) 恢复位置（空间定位），(3) 恢复内容（退化语义）。设计了一个轻量级的解码模块，有效地利用这些潜在编码线索进行空间自适应恢复。
### Conclusion
在六种常见退化任务、五种复合设置以及先前未见过的退化中进行了广泛的实验，结果表明，本文方法优于现有最佳方法（SOTA），平均提高了1.68 dB的PSNR值，同时性能提高了三倍。
## 1010. `cs.CV` - FAST: 前景感知扩散与加速采样轨迹的分割导向异常合成 [PDF](https://arxiv.org/pdf/2509.20295), [HTML](https://arxiv.org/abs/2509.20295)
### Authors
Xichen Xu,Yanshu Wang,Jinbao Wang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu
### Background
工业异常分割高度依赖像素级别的注释，但在实际应用中，异常样本稀缺、多样且标注成本高。现有的分割导向工业异常合成（SIAS）方法虽然颇具潜力，但难以在采样效率和生成质量之间取得平衡。大多数方法对所有区域处理不加区分，忽略了异常区域和背景区域之间的统计差异，这限制了能专门针对分割任务生成可控、结构特定异常样本的能力。
### Innovation
本文提出了FAST框架，包含两个新模块：异常信息加速采样（AIAS）和前景感知重构模块（FARM）。AIAS是一个无需训练的采样算法，通过自底向上的聚合加速反向过程，使其能够在短短10步内生成最先进的分割导向异常样本。FARM在每次采样步骤中自适应调整遮罩前景区域内的异常感知噪声，从而在整个去噪过程中保留局部异常信号。在多个工业基准上的广泛实验表明，FAST在下游分割任务中始终优于现有的异常合成方法。
### Conclusion
FAST在多个工业基准上的下游分割任务中显示出了卓越性能，证明了其在分割导向异常合成中的有效性，并提供了代码供其他研究者参考。
## 1011. `cs.CV` - SPATIALGEN：由布局引导的3D室内场景生成 [PDF](https://arxiv.org/pdf/2509.14981), [HTML](https://arxiv.org/abs/2509.14981)
### Authors
Chuan Fang,Heng Li,Yixun Liang,Jia Zheng,Yongsen Mao,Yuan Liu,Rui Tang,Zihan Zhou,Ping Tan
### Background
创建高质量的3D室内环境模型对于设计、虚拟现实和机器人技术等应用至关重要。然而，手工建立3D模型耗时且劳动密集。尽管生成式AI的进步已使自动场景合成成为可能，现有的方法在视觉质量、多样性、语义一致性以及用户控制方面仍面临挑战。主要瓶颈在于缺乏一个针对此任务的大型高质量数据集。鉴于此，本文提出一个综合性的合成数据集，包含12,328个结构化的标注场景，共计57,440个房间和470万个逼真的2D渲染图，并基于此数据集介绍了一种新颖的多视图多模态扩散模型SpatialGen，以生成真实的、语义一致的3D室内场景
### Innovation
本文提出了一个包含12,328个结构化标注场景的综合数据集，该数据集提供了470万个逼真的2D渲染图，并基于此数据集提出了一种名为SpatialGen的多视图多模态扩散模型。该模型能够在给定3D布局和参考图像的情况下，从任意视角生成符合单个场景观察条件的外观（彩色图像）、几何（场景坐标图）和语义（语义分割图）信息，并在多个模态间保持空间一致性。实验结果表明，SpatialGen在生成3D室内场景方面优于之前的模型
### Conclusion
本文开放了数据和模型，以期促进室内场景理解与生成领域的研究进展。SpatialGen在多视角和多模态生成高质量的3D室内场景方面展示了优越性，在我们的实验中取得了显著的结果。
## 1012. `cs.CV` - 通过生成模型实现高效多模态数据集蒸馏 [PDF](https://arxiv.org/pdf/2509.15472), [HTML](https://arxiv.org/abs/2509.15472)
### Authors
Zhenghao Zhao,Haoxuan Wang,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan
### Background
数据集蒸馏旨在从大型数据集合成一个小型数据集，使在其中训练的模型能够在原始数据集上表现良好。随着大型语言模型和多模态大型语言模型的兴起，多模态数据集，特别是图像-文本数据集的重要性显著增加。然而，现有的多模态数据集蒸馏方法受到匹配训练轨迹算法的限制，显著增加了计算资源需求，并需要数天时间来处理蒸馏过程。
### Innovation
提出了EDGE，一种用于高效多模态数据集蒸馏的生成式蒸馏方法。该方法新颖地提出了一种包含双向对比损失和多样性损失的新颖生成模型训练工作流程，以及一种进一步提高文本到图像检索性能的图描述策略。与现有方法相比，该方法在Flickr30K、COCO和CC3M数据集上展示了更好的性能和效率，并且比最先进的方法快18倍。
### Conclusion
本文介绍了一种高效多模态数据集蒸馏方法EDGE，通过生成模型实现。该方法不仅解决了生成图像和图描述之间缺乏相关性和生成样本之间缺乏多样性的问题，还提出了新的损失函数和生成方法，提高了图像到文本检索性能。实验结果表明该方法在多模态数据集蒸馏中具有更高的性能和效率。
## 1013. `cs.CV` - 群体证据很重要：基于镶嵌的空间语义门控方法用于密集对象检测 [PDF](https://arxiv.org/pdf/2509.10779), [HTML](https://arxiv.org/abs/2509.10779)
### Authors
Yilun Xiao
### Background
在无人机图像中，由于长距离视角、遮挡和杂乱环境，密集的小目标往往会被忽略。已有方法对此类问题缺乏有效的解决手段，因此需要一种新的方法来提高此类目标的检测率，同时保证精度的合理调整。本文提出了一种检测器无关的后处理框架，利用重叠信息转换为群体证据来解决该问题。该方法经实验验证明显提升了召回率，同时在一些特定应用领域表现良好，如远程计数和监测。实验证明，通过空间镶嵌恢复低置信度候选目标，通过空间聚类和语义聚类进一步验证群体证据，最后进行权重调整和类感知非最大抑制融合，能够显著提高密集小目标的检测性能，同时实现了后处理延迟的有效控制。
### Innovation
本文提出了一种基于镶嵌的空间语义门控方法，该方法能够将重叠区域产生的冗余恢复为群体证据，并通过空间聚类和语义聚类进一步验证和优化这些证据。这种方法不仅提高了密集小目标的检测率，还实现了检测过程中召回率和精度的合理权衡。此外，该框架不依赖于重新训练，且能够与现代检测器无缝集成，为进一步的性能优化留有余地。
### Conclusion
通过实验结果表明，该方法在维视无人机数据集（VisDrone）上的召回率提高了约13%，同时保持了较高的精度，综合F1分数达0.669。此外，后处理延迟仅为0.095秒/张图像，表明该方法具有实际应用价值。进一步的消融实验验证了镶嵌、空间聚类、语义聚类以及权重调整各部分有效性的独立贡献。未来的工作计划降低语义门控的成本，并引入时间线索以进一步提升模型性能。
## 1014. `cs.CV` - 使用门检测和大型语言模型进行建筑合规检查的设施自动枚举 [PDF](https://arxiv.org/pdf/2509.17283), [HTML](https://arxiv.org/abs/2509.17283)
### Authors
Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo
### Background
建筑合规检查（BCC）是确保建筑物符合监管标准的关键过程。设施类型的准确识别及其空间分布是BCC的核心组成部分。尽管这一过程至关重要，但学术文献中对此问题的关注较少，给BCC带来了巨大挑战，也导致现有工作流程存在关键缺陷。手动完成这一任务耗时且劳动密集型。
### Innovation
首次将大型语言模型（LLMs）应用于设施自动枚举任务，并通过Chain-of-Thought（CoT）管道进一步提高其性能。该方法能够跨不同数据集和设施类型进行泛化。通过实验表明，该方法在真实世界和合成楼层平面图数据上均表现出高效性和鲁棒性。
### Conclusion
本研究提出了一种新的方法，将门检测与LLM推理相结合，以实现每种设施类型的数量验证，针对法规要求。这种方法能够很好地应用于多样化的数据集和设施类型，实验结果表明此方法在真实场景和合成数据中有效且稳定。
## 1015. `cs.CV` - Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection [PDF](https://arxiv.org/pdf/2509.20745), [HTML](https://arxiv.org/abs/2509.20745)
### Authors
Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang
### Background
海洋目标检测对于航行安全、监视和自主操作至关重要，但由于缺乏注释的海洋数据和跨不同海洋属性（如目标类别、视角、位置和成像环境）的差于泛化能力较差，这造成了极大的限制。
### Innovation
提出了一种数据为中心的生成-选择框架Neptune-X，通过任务感知的样本选择充分利用合成数据生成，从而提升训练效果。从生成的角度出发，开发了X-to-Maritime多模态条件生成模型，以合成多样且现实的海洋场景。该模型包括双向物体-水注意力模块，用于增强视觉保真度。为了进一步提升下游任务性能，提出了关联属性的主动采样方法，基于任务相关性动态选择合成样本。为了支持稳健的基准测试，构建了海洋生成数据集，这是首个面向生成性海洋学习的数据集，涵盖广泛的语义条件。
### Conclusion
广泛的实验表明，我们的方法在海洋场景合成中建立了新的基准，显著提高了检测精度，特别是在具有挑战性和之前代表性不足的环境中。
## 1016. `cs.CV` - MS-GS: 在野外的多外观稀视角3D高斯散点图 [PDF](https://arxiv.org/pdf/2509.15548), [HTML](https://arxiv.org/abs/2509.15548)
### Authors
Deming Li,Kaiwen Jiang,Yutao Tang,Ravi Ramamoorthi,Rama Chellappa,Cheng Peng
### Background
野外的照片集通常包含有限的图像数量并表现出多种外观，例如在一天的不同时间段或不同季节拍摄，这给场景重建和新颖视图合成带来了巨大挑战。尽管最近对神经辐射场（NeRF）和3D高斯散点图（3DGS）进行了改进，但仍存在过度平滑和过拟合的问题。因此，本研究旨在解决这些限制，提出MS-GS框架，适用于稀视角场景且具备多外观能力的3DGS方法，利用单目深度估计的几何先验，通过SfM点锚定算法提取和利用局部语义区域，确保可靠的注册和几何线索。为进一步引入多视角约束，论文提出了一系列多视角驱动的监督方案，以鼓励3D一致性并减少过拟合问题，同时建立了真实的数据集和野外实验设置，证明了MS-GS在稀视角和多外观条件下的照片级真实渲染效果，并在不同数据集上超越了现有方法。
### Innovation
提出了MS-GS框架，结合了多外观能力和稀视角场景下的3DGS方法。该方法通过单目深度估计的几何先验，利用SfM点锚定算法，提取并利用局部语义区域，以确保可靠的注册和几何线索。此外，论文还提出了多视角驱动的监督方案，以增强3D一致性并减少过拟合问题，以及建立了用于更现实基准的数据集和实验设置。
### Conclusion
通过MS-GS方法，该研究在不同数据集上实现了在稀视角和多外观条件下的照片级真实渲染效果，显著优于现有方法。
## 1017. `cs.CV` - GLip：用于鲁棒视觉语音识别的全局-局部综合渐进框架 [PDF](https://arxiv.org/pdf/2509.16031), [HTML](https://arxiv.org/abs/2509.16031)
### Authors
Tianyue Wang,Shuang Yang,Shiguang Shan,Xilin Chen
### Background
视觉语音识别（VSR），即唇读，是从无声视频中识别语音的任务。尽管近年来在VSR方面取得了显著进展，但大多数现有方法很少关注实际视觉挑战，如光照变化、遮挡、模糊和姿态变化。为了应对这些挑战，作者提出了GLip，这是一种用于鲁棒VSR的全局-局部综合渐进框架。GLip基于两个关键洞察：（i）学习在不同条件下跨视觉特征与对应的语音内容之间的初步粗略对齐，有助于在挑战环境中学习精确的视觉到语音映射；（ii）在不良条件下，某些局部区域（如未遮挡区域）常比全局特征提供更多的唇读判别特征。因此，GLip引入了一种双路径特征提取架构，结合了全局和局部特征，并在两阶段渐进学习框架内进行整合。
### Innovation
GLip框架通过采用逐层学习策略来充分利用判别性局部区域，展示了对各种视觉挑战的增强鲁棒性，并且在LRS2和LRS3基准测试上持续优于现有方法。该框架在学习阶段集成全局和局部特征，并通过Contextual Enhancement Module（CEM）模块动态整合局部特征与相关的全局上下文，改善了粗略表征，生成精确的视觉-语音映射。此外，该框架还在新的挑战性普通话数据集上得到了进一步验证。
### Conclusion
GLip框架在应对视觉词汇识别中的各种视觉挑战方面表现出色，特别是在LRS2和LRS3基准测试上持续超越现有方法，并且在新引入的挑战性普通话数据集上也进行了有效验证，证明其在实际应用中的鲁棒性和有效性。
## 1018. `cs.CV` - 基于度量的自适应预测边界用于概率图像重建 [PDF](https://arxiv.org/pdf/2404.15274), [HTML](https://arxiv.org/abs/2404.15274)
### Authors
Matt Y Cheung,Tucker J Netherton,Laurence E Court,Ashok Veeraraghavan,Guha Balakrishnan
### Background
现代深度学习重建算法能够从稀疏输入生成令人印象深刻的真实扫描图像，但往往会产生显著的不准确性。这使得难以基于这些算法重建的扫描提供统计保证的关于受试者真实状态的声明。本文研究了基于临床感兴趣的度量重建扫描，并使用先验校准数据集和自适应预测（CP）在地真相度量上进行校准的框架，以计算可靠的预测边界。这些边界提供了受试者状态可解释的反馈，并可用于检索最近邻重建扫描以供视觉检查。
### Innovation
提出了一个框架，用于计算从基于黑盒概率的图像重建算法推导出的声明的可验证的预测边界。该框架的核心洞察是将重建扫描表示为感兴趣的临床度量，并使用先验校准数据集和自适应预测（CP）校准地真相度量的边界。此框架在稀疏视图CT图像重建和脂肪质量量化及放疗规划任务中进行了验证，结果显示该框架产生的边界具有比传统基于像素的边界更好的语义解释性，且能够标记看似合理但实际上统计上不可能的异常重建。
### Conclusion
该框架不仅可以提供可解释的反馈，还可以用于检索最近邻重建扫描进行视觉检查，对于稀疏视图CT图像中脂肪质量的量化和放射疗法规划具有实际应用价值。
## 1019. `cs.CV` - 实现实时目标检测与DINOv3的结合 [PDF](https://arxiv.org/pdf/2509.20787), [HTML](https://arxiv.org/abs/2509.20787)
### Authors
Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen
### Background
DEIM因其简单有效的特性和高效率，在实时DETRs的训练框架中成为了主流，并显著优于YOLO系列。为了进一步提高其性能，作者引入了DINOv3特征，提出了一种增强的DEIM版本（DEIMv2）。DEIMv2涵盖了从X到Atto的八种模型尺寸，适用于GPU、边缘设备和移动设备的部署。
### Innovation
DEIMv2将DINOv3特征引入了DEIM框架，建立了统一的设计来适应不同的硬件需求，尤其在轻量级模型方面的改进使其在资源受限的情况下仍能达到卓越的检测性能。具体而言，通过采用DINOv3预训练或精简的骨干网络，并引入空间调谐适配器（STA），增强了检测的细粒度细节。对于更轻量级的模型，作者使用HGNetv2并进行深度和宽度修剪，以满足严格的资源预算。此外，简化了解码器并升级了密集O2O（Dense O2O），使得DEIMv2在不同应用场景中实现了出色的性能成本平衡。
### Conclusion
通过DEIMv2，作者达到了多个里程碑式的成就。例如，最大的模型DEIMv2-X在仅有50.3M参数的情况下实现了57.8 AP，超过了需要60M参数的前一代X-scale模型。另外，DEIMv2-S作为第一个突破10M参数的模型，其AP达到了50.9。即使是极轻量级的DEIMv2-Pico（1.5M参数），也能达到38.5 AP，接近YOLOv10-Nano（2.3M参数）的性能，但参数更少。所有这些改进使得DEIMv2在不同模型尺寸上的性能成本 trade-off 均表现优异，达到新的状态最先进结果。
## 1020. `cs.CV` - MOSS-ChatV：基于过程推理奖励的强化学习在视频时序推理中的应用 [PDF](https://arxiv.org/pdf/2509.21113), [HTML](https://arxiv.org/abs/2509.21113)
### Authors
Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu
### Background
视频推理已成为多模态大型语言模型（MLLMs）的关键能力，要求模型从静态感知转向对复杂场景中时间动态的连贯理解。然而，现有MLLMs经常表现出过程不一致的问题，即使最终答案正确，中间推理也可能偏离视频动态，这降低了可解释性和鲁棒性。
### Innovation
提出了一个基于强化学习的框架MOSS-ChatV，通过引入基于动态时间规整（DTW）的过程奖励，实现了与时间基线参考的合理对应，无需辅助奖励模型即可进行高效的过程监督。进一步确定了动态状态预测作为视频推理的关键指标，并构建了带有标注推理轨迹的基准MOSS-Video。该框架适用于不同架构，经GPT-4o-as-judge评估后，MOSS-ChatV生成更一致和稳定的推理轨迹。
### Conclusion
MOSS-ChatV在MOSS-Video (测试) 上取得了87.2% 的成绩，并在MVBench 和 MMVU等通用视频基准上提升了性能。该框架在不同架构中的一致性改进证实了其广泛应用性。
## 1021. `cs.CV` - 4DGCPro: 高效的层次四维高斯压缩用于渐进式体三维视频流传输 [PDF](https://arxiv.org/pdf/2509.17513), [HTML](https://arxiv.org/abs/2509.17513)
### Authors
Zihan Zheng,Zhenlong Wu,Houqiang Zhong,Yuan Tian,Ning Cao,Lan Xu,Jiangchao Yao,Xiaoyun Zhang,Qiang Hu,Wenjun Zhang
### Background
实现高品质体三维视频的无缝观看起来仍是一个开放的挑战。现有的体三维视频压缩方法要么缺乏在单一模型中灵活调整质量和比特率的能力，以适应不同网络和设备的高效流传输，要么难以在轻量级移动平台上进行实时解码和渲染。为了解决这些问题，本文提出了一种新颖的4D Gaussian压缩框架4DGCPro，它能够通过单一直接实现渐进式体三维视频流传输，并通过逐层熵优化训练方案提高移动设备上的实时解码和渲染能力，同时在网络多数据集的RD性能上超越现有方法。
### Innovation
4DGCPro 提出了一种感知加权和压缩友好的四维高斯层次表示，具有运动感知自适应分组，以减少时间冗余、保持连续性并支持多级细节的流传输。同时，它还提出了一种端到端的熵优化训练方案，包括逐层率失真（RD）监督和属性特定的熵建模，以提高比特流生成效率。
### Conclusion
通过 4DGCPro 实验表明，它能够在一个模型中实现灵活的质量调整和多个比特率，在移动设备上实现实时解码和渲染，同时在多个数据集的率失真性能上超越现有方法。
## 1022. `cs.CV` - HiPerformer:一种具有模块化分层融合策略的高性能全局-局部分割模型 [PDF](https://arxiv.org/pdf/2509.20280), [HTML](https://arxiv.org/abs/2509.20280)
### Authors
Dayu Tan,Zhenpeng Xu,Yansen Su,Xin Peng,Chunhou Zheng,Weimin Zhong
### Background
医学图像分割中，局部细节与全局上下文都非常重要。现有基于CNN-Transformer混合架构的方法通常采用简单的特征融合技术，如序列堆叠、端点拼接或点加法，这些方法难以处理特征不一致问题，且容易产生信息冲突和丢失。因此，亟需一种有效的方法来弥补这一不足，以提高分割的准确性。
### Innovation
该研究提出了HiPerformer，一种创新的模块化分层融合策略。HiPerformer的编码器采用了新的模块化分层架构，实现了多源特征的并行动态融合，层间深度集成异构信息，不仅保留了每个分支的独立建模能力，还确保了足够的信息传递，有效避免了传统堆叠方法带来的特征退化和信息丢失问题。此外，该研究还设计了一个局部-全局特征融合（LGFF）模块，实现了局部细节与全局语义信息的精确高效融合，并提出了一种逐级金字塔聚合（PPA）模块，用于代替传统的跳跃连接，进一步增强多尺度特征表示能力，抑制噪声干扰。实验结果表明，该方法在多个公开数据集上的表现优于现有分割方法，具有更高的分割准确性和鲁棒性。
### Conclusion
实验结果表明，所提出的方法在多个公开数据集上优于现有的分割技术，显示出更高的分割准确性和鲁棒性。
## 1023. `cs.CV` - 甲烷卫星和机载成像光谱学中云及其阴影分割的深度学习方法 [PDF](https://arxiv.org/pdf/2509.19665), [HTML](https://arxiv.org/abs/2509.19665)
### Authors
Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy
### Background
准确检索大气中甲烷或其他痕量气体的浓度对于高光谱遥感至关重要，而云和云阴影的检测是这一过程的关键步骤。甲烷SAT和其机载同伴任务MethaneAIR尤其面临着这一挑战。如何有效过滤云和云阴影在遥感数据中显得十分重要，因为它们会偏移甲烷的检测结果并影响排放量的量化。本研究使用机器学习方法解决高空间分辨率传感器的云和云阴影检测问题，并评估了包括迭代逻辑回归（ILR）和多层感知器（MLP）在内的传统技术以及UNet和光谱通道注意力网络（SCAN）等先进的深度学习架构。
### Innovation
本研究采用深度学习方法来检测高光谱遥感任务中的云和云阴影。评估了UNet和 SCAN以及传统的迭代逻辑回归（ILR）和多层感知器（MLP）方法的效果。研究发现，传统的机器学习方法在空间一致性和边界定义方面存在不足，而深度学习模型在检测质量上有显著提升。研究表明，SCAN在处理卫星特定特征时优于UNet，强调了引入光谱注意力的优势。这一研究深入评估了不同机器学习技术的优势和有效性，展示了高级深度学习架构在提高现有和下一代高光谱任务中甲烷排放量化能力中的稳健和可扩展解决方案的潜力。
### Conclusion
本研究利用先进的深度学习架构对甲烷卫星和机载成像光谱学中云及其阴影分割进行深入评估，展示了其在提高甲烷排放量化能力方面的优势，并强调了光谱注意力在符合卫星特定特征时的重要性。本研究中的数据和代码已公开。
## 1024. `cs.CV` - EditVerse：上下文学习实现图像和视频编辑及生成的统一框架 [PDF](https://arxiv.org/pdf/2509.20360), [HTML](https://arxiv.org/abs/2509.20360)
### Authors
Xuan Ju,Tianyu Wang,Yuqian Zhou,He Zhang,Qing Liu,Nanxuan Zhao,Zhifei Zhang,Yijun Li,Yuanhao Cai,Shaoteng Liu,Daniil Pakhomov,Zhe Lin,Soo Ye Kim,Qiang Xu
### Background
近年来，基础模型的发展明显向统一化和规模化的趋势发展，在不同领域中显示出了涌现的能力。图像生成与编辑已经从任务特定框架转变为统一框架，但视频生成和编辑由于架构限制和数据稀缺仍处于分散状态。这项工作中，作者引入了EditVerse，这是一个在单个模型中统一进行图像和视频生成与编辑的框架。
### Innovation
通过将文本、图像和视频表示为统一的标记序列，并利用自注意力机制实现强大的上下文学习、自然跨模态知识转移和任意分辨率和持续时间的输入与输出的灵活处理，EditVerse突破了当前框架的限制。为了解决视频编辑训练数据不足的问题，作者设计了一个可扩展的数据管道，集成了232,000个视频编辑样本，并结合了大规模的图像和视频数据集进行联合训练。此外，还提出了首个基于指令的视频编辑基准——EditVerseBench，涵盖多种任务和分辨率。
### Conclusion
广泛的实验和用户研究表明，EditVerse在性能上达到了最先进的水平，超过了现有的开源和商用模型，在不同模态中展现出涌现的编辑和生成能力。
## 1025. `cs.CV` - 不稳定消除：扩散模型中概念复生的隐秘风险 [PDF](https://arxiv.org/pdf/2410.08074), [HTML](https://arxiv.org/abs/2410.08074)
### Authors
Vinith M. Suriyakumar,Rohan Alur,Ayush Sekhari,Manish Raghavan,Ashia C. Wilson
### Background
文本到图像的扩散模型依赖于大规模的网络数据集。从头开始训练这些模型是非常耗费计算资源的，因此开发人员通常选择对现有的模型进行增量更新。这些更新通常包括微调步骤（学习新概念或提高模型性能）以及“忘记”步骤（“忘记”现有概念，例如版权作品或明确内容）。然而，在这种 paradigm 下，我们发现了一个关键且未知的漏洞：即使在非对抗性的、看似无害的条件下，对看似无关的图像进行微调也会导致模型重新“学习”之前被“忘记”的概念。
### Innovation
本文探讨并证明了一个先前未知的问题：概念复生。通过一系列实验，作者将“概念消除”与后续对 Stable Diffusion v1.4 和 Stable Diffusion v2.1 的微调相结合，研究这一现象的原因和范围。研究结果突显了对增量模型更新组成的脆弱性，并提出了确保文本到图像扩散模型的安全性和对齐的当前方法的新担忧。
### Conclusion
研究发现，组成增量模型更新是脆弱的，提出了新的严重关切，即当前确保文本到图像扩散模型安全性和对齐的方法存在着问题。
## 1026. `cs.CV` - DIFFENCE: 使用扩散模型保护成员隐私 [PDF](https://arxiv.org/pdf/2312.04692), [HTML](https://arxiv.org/abs/2312.04692)
### Authors
Yuefeng Peng,Ali Naseh,Amir Houmansadr
### Background
尽管深度学习模型在性能上取得了显著进步，但它们容易受到成员推断攻击（MIAs）的影响。尽管提出了多种防御措施，但在隐私与实用性之间的权衡上仍有提升空间。本文旨在通过利用生成模型提出一种新颖的对抗MIAs的防御框架，以减少成员与非成员输入之间的差异，从而在模型预测之前重新生成输入样本。该方法在模型训练和推理阶段不进行任何修改，可与其他防御机制结合使用，而不影响模型的准确性，也不会降低置信向量的有效性。通过大量实验表明，该方法能够作为稳健的即插即用防御机制，增强成员隐私而不牺牲模型的功能性。与现有的防御方法结合使用时，能够取得新的最佳性能。
### Innovation
提出了一种名为DIFFENCE的新颖防御框架，通过利用生成模型在模型预测之前重新生成输入样本，从而减少成员与非成员输入之间的差异。该方法在模型训练和推理阶段不进行任何修改，可以与其他防御机制结合使用，且不影响模型的准确性或降低置信向量的有效性。
### Conclusion
通过大量实验表明，DIFFENCE作为一种稳健的即插即用防御机制，能够增强成员隐私而不牺牲模型的功能性。与现有的防御方法结合使用时，能够取得新的最佳性能。例如，在与当前最先进的SELENA防御技术结合时，可以显著提高隐私保护的效果。
## 1027. `cs.CV` - 基于范数采样和正交性的多样子集选择 [PDF](https://arxiv.org/pdf/2406.01086), [HTML](https://arxiv.org/abs/2406.01086)
### Authors
Noga Bar,Raja Giryes
### Background
大标注数据集是深度神经网络成功的关键，但在医学成像等特定领域，数据标注成本高昂。因此，本研究关注从大量未标注数据中选择最具信息量的小规模数据集的问题，以减少全量标注的成本和时间。研究提供了一种简单而有效的方法，结合了特性范数、随机化和正交化来选择多样且具有信息量的样本。特性范数作为信息量的代理指标，而随机化和正交化可以减少冗余并鼓励覆盖特征空间。
### Innovation
本研究提出了一种新颖的方法，结合了特性范数、随机化和正交化（通过格思密过程实现）来选择多样且信息量丰富的样本。该方法简单有效，不仅作为独立的方法提高子集选择性能，还能与现有技术结合使用，进一步提升性能。通过多种图像和文本基准数据集实验验证了该方法的有效性。
### Conclusion
本研究通过实验展示了其方法在不同类型的基准数据集上的有效性和优势，证明了该方法在多样且信息量丰富的样本选择方面的一致性和可靠性。
## 1028. `cs.CV` - 扩散模型能够去缠结吗？一个理论视角 [PDF](https://arxiv.org/pdf/2504.00220), [HTML](https://arxiv.org/abs/2504.00220)
### Authors
Liming Wang,Muhammad Jehanzeb Mirza,Yishu Gong,Yuan Gong,Jiaqi Zhang,Brian H. Tracey,Katerina Placek,Marco Vilela,James R. Glass
### Background
本文提出了一个新颖的理论框架来理解扩散模型如何学习分解表示。我们基于此框架提供了通用分解潜变量模型的可识别性条件，分析了训练动力学，并推导出分解潜空间模型的抽样复杂度界限。
### Innovation
本文建立了一种新的理论框架来理解扩散模型的学习能力，指出了分解潜变量模型的可识别性条件，分析了训练动态，并推导出分解潜空间模型的样本复杂度边界。通过在多种任务和模态下进行去缠结实验，验证了所提理论的有效性，并展示了基于理论的训练策略，如风格指引正则化，能够提升去缠结性能。
### Conclusion
我们的实验结果表明，我们的理论框架和相关训练策略能够有效提升扩散模型的去缠结能力。
## 1029. `cs.CV` - STHN: 通过卫星图像进行无人机热像地理定位的深度单应性估计 [PDF](https://arxiv.org/pdf/2405.20470), [HTML](https://arxiv.org/abs/2405.20470)
### Authors
Jiuhong Xiao,Ning Zhang,Daniel Tortei,Giuseppe Loianno
### Background
无人机在户外应用如搜索与救援、电力线路检查和环境监测中的地理定位对于操作至关重要。然而，导航天线卫星系统（GNSS）信号容易受到干扰和欺骗性攻击，因此需要开发更 robust 的导航定位方法。热像地理定位（TG），依赖于依托车载摄像头和参考卫星地图进行图像匹配，提供了一种有效的绝对地理定位解决方案。特别是，基于红外摄像机在夜间有效进行热像地理定位的方法。然而，现有方法受限于卫星地图的密集取样和热查询图像的几何噪声。为了解决这些挑战，本文提出了一种新型无人机热像地理定位方法 STHN，该方法通过粗到细的深度单应性估计实现可靠的热像地理定位，即使在热像与卫星图像大小比为 11%，且存在难以区分的纹理和自相似模式的情况下，也能在无人机上次已知位置半径 512 米范围内取得可靠的定位结果。该研究提高了热像地理定位在低能见度条件下的无人机性能和对几何噪声的鲁棒性。并且，提供的代码已公开可供使用.
### Innovation
本文创新地提出了一种新型无人机热像地理定位方法 STHN，通过使用粗到细的深度单应性估计，即使在存在难以区分的纹理和自相似模式以及卫星地图密集取样和热查询图像的几何噪声条件下，也能够实现可靠的热像地理定位，有效地扩展了热像地理定位技术的应用范围和鲁棒性。该方法在无人机上次已知位置半径 512 米范围内实现了精确的定位，而不需要过于密集的卫星样本，从而提高了定位精度和效率。此外，该研究增强了无人机在低能见度条件下的工作性能，并提高了其对几何噪声的抵抗能力。
### Conclusion
本文提出了 STHN 方法，通过引入一种粗到细的深度单应性估计技术，提高了无人机在热像地理定位中的性能和鲁棒性。该方法适用于低能见度情况下的有效定位，并能够在稠密的卫星样本和几何噪声情况下可靠地实现定位。而且，提供的代码已经公开，可以进一步推广和应用该技术。
## 1030. `cs.CV` - Plan-R1：基于语言建模的安全可行轨迹规划 [PDF](https://arxiv.org/pdf/2505.17659), [HTML](https://arxiv.org/abs/2505.17659)
### Authors
Xiaolong Tang,Meina Kan,Shiguang Shan,Xilin Chen
### Background
对于实际应用中的自动驾驶系统而言，安全和可行的轨迹规划至关重要。然而，现有的基于学习的规划者高度依赖于专家演示数据，不仅缺乏明确的安全意识，还可能继承来自非最优人类驾驶数据中的不良行为，如超速等。
### Innovation
作者受大型语言模型成功的启发，提出了一种两阶段的轨迹规划框架—Plan-R1，其特点是将原则对齐与行为学习分离。在第一个阶段，模型通过专家数据预训练来捕捉多样且接近人类的驾驶行为；在第二个阶段，模型使用基于规则的奖励进行微调，通过Group Relative Policy Optimization (GRPO) 明确使意向性规划与安全、舒适和交通规则遵循等原则保持一致。此外，本文还提出了一种新的方法Variance-Decoupled GRPO (VD-GRPO) 来解决直接应用GRPO时存在的群体规范化会使不同群体的奖励平滑的问题，确保关键安全目标在整个训练过程中保持优先。
### Conclusion
实验结果显示Plan-R1显著提高了规划的安全性和可行性，特别是在现实反应设置中表现尤为出色，达到了最先进的性能水平。
## 1031. `cs.CV` - Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation [PDF](https://arxiv.org/pdf/2409.18788), [HTML](https://arxiv.org/abs/2409.18788)
### Authors
Raphael Hagmanns,Peter Mortimer,Miguel Granero,Thorsten Luettel,Janko Petereit
### Background
深度学习技术在自主系统中的成功部署高度依赖于部署环境中可用的数据量。特别是在未结构化的户外环境中，几乎不存在多模态数据集，这对大多数机器人平台和场景而言都是挑战。我们之前介绍了德国户外和非道路数据集（GOOSE）框架，并提供了来自非道路车辆的10000个多模态帧，以增强在非结构化环境中的感知能力。现在，为了提高GOOSE框架的普适性，我们开放了GOOSE-Ex数据集，它包含了5000个来自各种不同环境的标记多模态帧，这些环境记录在两台机器人平台上：一台挖掘机和一台四足机器人。这些数据有助于分析在不同机器人平台和传感器模态下的语义分割性能。我们展示了这些联合数据集如何被用于不同的下游应用，如非道路导航、物体操作或场景完成等。
### Innovation
本文介绍了开源GOOSE-Ex数据集，包含了来自不同环境的5000个多模态帧，这些环境记录在两种不同的机器人平台上，旨在增加GOOSE框架在不同环境中的普适性。通过对不同平台和传感器模态进行语义分割性能分析，提出了如何利用这些联合数据集进行不同的下游应用程序或竞赛演示。数据集、平台文档及预训练的最新模型将通过特定网址提供。
### Conclusion
本研究通过开放GOOSE-Ex数据集，展示了如何在未结构化环境中增强语义分割的普适性，并通过不同机器人平台和传感器模态的数据分析，证明了该数据集在多个下游应用中的潜力。
## 1032. `cs.CV` - DOTA: 基于分布的视觉语言模型测试时自适应 [PDF](https://arxiv.org/pdf/2409.19375), [HTML](https://arxiv.org/abs/2409.19375)
### Authors
Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang
### Background
视觉语言基础模型（VLMs）如CLIP在各种任务上表现出色，但在训练数据和测试数据之间存在显著分布差异时，部署这些模型可能会不可靠。尽管针对多种场景进行微调可以是一个解决方案，但这也常常很昂贵。基于缓存的测试时适配方法能够通过存储代表性测试样本来引导后续分类，但这些方法通常采用简单的缓存管理策略，容量有限，导致不可避免地在更新过程中丢失样本时严重过度拟合。因此，一种新的方法是必要的来解决这个问题。
### Innovation
我们提出了DOTA（基于分布的测试时自适应），这是一种简单有效的方法来解决这个问题。DOTA的方法不是仅仅记住个别测试样本，而是连续估算测试数据流下的潜在分布。然后使用这些动态估算的分布通过贝叶斯定理计算测试时后验概率，进行自适应。这一基于分布的方法使模型能够不断学习并适应部署环境。广泛的实验结果表明，DOTA可以显著减少遗忘并且在与现有方法的比较中实现了最先进的性能。
### Conclusion
DOTA方法通过动态估计测试数据流下的潜在分布，有效地避免了由于测试样本丢失导致的严重过度拟合问题，从而减轻了遗忘，实现了与现有方法相比更优的性能。
## 1033. `cs.CV` - Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance [PDF](https://arxiv.org/pdf/2410.22376), [HTML](https://arxiv.org/abs/2410.22376)
### Authors
Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho
### Background
现有的最先进的文本到图像（T2I）扩散模型在生成罕见概念组合时，例如具有异常属性的对象，往往表现不佳。作者通过实证和理论分析表明，在扩散采样过程中暴露于目标罕见概念相关的常见概念，可以提高生成的准确性。
### Innovation
提出了一种无需训练的R2F方法，利用大型语言模型（LLM）丰富的语义知识，在整个扩散推理过程中规划和执行从罕见到常见概念的引导，实现对任何预训练扩散模型和LLM的灵活兼容，并能无缝集成区域引导扩散方法。R2F方法在三个数据集上表现优异，尤其是在我们新提出的基准RareBench上大幅超过了现有模型如SD3.0和FLUX，准确率提高至28.1%。
### Conclusion
R2F框架具有跨任何预训练扩散模型和大型语言模型的灵活性，并且可以无缝集成区域引导扩散方法。在三个数据集上的实验表明，R2F方法显著优于现有的模型，特别是在新提出的基准RareBench上表现更为出色。
## 1034. `cs.CV` - 通过人类反馈进行强化学习学习个性化驾驶风格 [PDF](https://arxiv.org/pdf/2503.10434), [HTML](https://arxiv.org/abs/2503.10434)
### Authors
Derun Li,Changye Li,Yue Wang,Jianwei Ren,Xin Wen,Pengxiang Li,Leimeng Xu,Kun Zhan,Peng Jia,Xianpeng Lang,Ningyi Xu,Hang Zhao
### Background
在动态环境中，生成类人类且适应性强的行驶轨迹对于自动驾驶至关重要。尽管生成模型在合成可行轨迹方面显示出了潜力，但它们常常未能捕捉到个人驾驶风格中的细微变异性，这归因于数据集偏差和分布偏移。因此，提出了一种名为TrajHF的人类反馈驱动的生成模型微调框架，旨在使运动规划与多样化的驾驶风格保持一致。TrajHF集成了多条件去噪器和强化学习，并结合人类反馈来超越传统模仿学习改进多模态轨迹生成。这种方法更好地与人类驾驶偏好保持一致，同时保持安全性和可行性约束。
### Innovation
引入了TrajHF框架，通过人类反馈驱动的微调，结合多条件去噪器和强化学习，来改善生成模型的多模态轨迹生成，以更好地与人类驾驶偏好保持一致，同时满足安全性和可行性要求。
### Conclusion
TrajHF在NavSim基准测试中实现了与最先进的系统相当的性能，为自动驾驶个性化和适应性轨迹生成设定了新范式。
## 1035. `cs.CV` - iTACO: 来自随手记录的RGBD视频的可交互式关节对象数字化双胞胎 [PDF](https://arxiv.org/pdf/2506.08334), [HTML](https://arxiv.org/abs/2506.08334)
### Authors
Weikun Peng,Jun Lv,Cewu Lu,Manolis Savva
### Background
日常生活中普遍存在可动对象，这些对象的可交互式数字孪生在实体人工智能和机器人技术中有广泛的应用。然而，当前将现实世界的可动对象数字化的方法需要精心采集的数据，这限制了其实用性、可扩展性和泛化能力。本文专注于通过随手拍摄的RGBD视频（由手持相机拍摄）分析可动对象的运动并进行部分级别的分割。
### Innovation
本文提出了一个从小范围到细致的框架iTACO，该框架能够从动态RGBD视频中推断出关节参数并分割可动对象的部分。为了在这一新设置下评估方法的效果，作者构建了一个包含784个视频、284个对象（分布在11个类别中）的数据集，该数据集是之前工作可比数据集大小的20倍。实验结果表明，与采用视频作为输入的其他现有方法相比，iTACO在合成和现实世界中随意采集的RGBD视频上表现出更优的效果。
### Conclusion
本文介绍了一种新的方法iTACO，它能够从随手记录的RGBD视频中分析和分割可动对象的运动和可移动部分，并在实验中展示了其优越性。该方法通过扩大数据集并采用精细的框架，解决了同时运动对象和相机以及互动中的显著遮挡问题，从而有利于实用、可扩展和泛化的可动对象数字孪生的应用。
## 1036. `cs.CV` - 近期深度学习在显微镜图像增强中的进展：综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强在理解生物细胞和材料的微观细节方面起着关键作用。近年来，借助深度学习方法，显微镜图像增强技术有了显著的进步。
### Innovation
这篇综述论文旨在概述这一快速发展的最先进方法，重点在其演变、应用、挑战和未来方向。核心讨论集中在显微镜图像增强的超分辨率、重建和降噪的关键领域，每一方面都从当前趋势及其深度学习的实际应用价值进行探讨。
### Conclusion
总之，深度学习在显微镜图像增强方面的最新进展展示了其广泛的应用前景和研究潜力，但仍存在一些挑战需要克服，未来的研究应继续探索这些领域的创新方法和解决方案。
## 1037. `cs.CV` - 外科视觉世界模型 [PDF](https://arxiv.org/pdf/2503.02904), [HTML](https://arxiv.org/abs/2503.02904)
### Authors
Saurabh Koju,Saurav Bastola,Prashant Shrestha,Sanskar Amgain,Yash Raj Shrestha,Rudra P. K. Poudel,Binod Bhattarai
### Background
外科手术模拟具有促进医学专业培训和自主手术代理培训的重要潜力。在自然视觉领域，世界模型能够基于动作控制的数据生成，显示出即使在大规模真实数据获取不可行的情况下，训练交互模拟环境中自主代理的潜力。然而，在外科领域中，此类工作仅限于简单的计算机模拟，并且缺乏现实感。此外，现有的世界模型文献主要集中在标签动作数据，限制了其在实际的外科数据中的应用，而实际获得动作标注是极其昂贵的。因此，尽管现有方法有所进展，但仍有改进空间以提高模拟的现实性和可操作性，特别是在获取动作标注数据方面存在的挑战。
### Innovation
提出了第一个外科视觉世界模型，该模型能够生成动作可控的外科数据。受最近成功利用未标记的游戏视频数据推断潜在动作并在动作控制下生成数据的Genie启发，该模型利用未标注的手术工具定位SurgToolLoc-2022数据集进行了广泛的实验验证，从而解决了在实际外科数据中标注动作成本高昂的问题，并显著提高了模拟的真实性及实用性。论文中的代码和实现细节可以在给定的链接中获取。
### Conclusion
本研究提出了一种创新的外科视觉世界模型，能够生成控制动作的外科数据，并通过实验证明其有效性。模型的应用有助于提高医学专业训练和自主手术代理培训的效果，填补了外科模拟领域在数据生成技术上的空白。未来工作应聚焦于进一步提高模型的鲁棒性和泛化能力，以满足更复杂和多样化的外科培训需求。
## 1038. `cs.CV` - 使用不变神经场表征实现具有几何感知的稳定状态偏微分方程预测 [PDF](https://arxiv.org/pdf/2504.18591), [HTML](https://arxiv.org/abs/2504.18591)
### Authors
Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier
### Background
近年来，神经算子在物理学和工程学中取得了重要进展，能够为具有通用几何形状的偏微分方程（PDEs）提供离散化不变的代理模型。然而，许多方法难以有效地编码局部几何结构和可变域。因此，本文旨在提出一种新的方法，以实现针对几何可变性稳态PDEs的高效预测。
### Innovation
本文引入了Enf2Enf，这是一种基于神经场的方法，能够有效地编码局部几何特性，并将这些特性与全局参数结合，从而产生连续的物理场。通过这种方法，能够实现复杂形状变化的有效建模。
### Conclusion
实验结果表明，该方法在气动学和结构基准测试中表现出了与基于图、神经算子及最新的神经场方法相当或更优的性能，并且能够实现实时推理和高效扩展至高分辨率网格。
## 1039. `cs.CV` - 纹理还是语义？视觉语言模型在字体识别中迷失方向 [PDF](https://arxiv.org/pdf/2503.23768), [HTML](https://arxiv.org/abs/2503.23768)
### Authors
Zhecheng Li,Guoxian Song,Yujun Cai,Zhen Xiong,Junsong Yuan,Yiwei Wang
### Background
现代视觉语言模型（VLMs）在视觉和语言任务上表现出色，但在细粒度任务的效果方面仍是一项开放的问题。在日常场景中，人们希望通过视觉语言模型识别出文本中使用的美感字体。然而，尽管视觉语言模型具有多模态能力和免费获取的特点，它们在字体识别上的能力仍存在疑问。为了研究这一问题，作者构建了字体识别基准（FRB），其中包含15种常用字体。该基准包括不同难度版本，用于评估视觉语言模型在字体识别任务中的表现，结果显示VLMs在字体识别任务上的表现有限，并且微调学习和链式思维提示对提高模型性能帮助有限。
### Innovation
该研究引入了一个新的弗兰conomy化基准（FRB），用于评估视觉语言模型在字体识别任务上的表现。该基准包括易版和难版两个版本，目的是挑战模型对字体的感知能力。此外，该研究还分析了视觉语言模型在字体识别中的注意力机制，揭示了它们的内在局限性。
### Conclusion
当前的视觉语言模型在字体识别任务上的表现有限，大多数最先进的模型无法达到令人满意的表现，并且容易受到文本信息引入的stroop效应的影响。少样本学习和链式思维提示对提高模型精度的效果有限。注意力分析揭示了视觉语言模型在捕捉语义特征上的固有限制。
## 1040. `cs.CV` - Mobi-$π$: Mobilizing Your Robot Learning Policy [PDF](https://arxiv.org/pdf/2505.23692), [HTML](https://arxiv.org/abs/2505.23692)
### Authors
Jingyun Yang,Isabella Huang,Brandon Vu,Max Bajracharya,Rika Antonova,Jeannette Bohg
### Background
现有的视觉-运动策略能够执行越来越复杂的操作任务，但通常是基于有限的机器人位置和摄像机视角的数据训练的。这导致它们在新的机器人位置上的泛化性能较差，限制了这些策略在移动平台上的应用，尤其是对于像按压按钮或转水龙头这样的精确任务。
### Innovation
提出了政策动员问题，即在新颖环境下找到与训练有素的操纵策略在摄像机视角分布上匹配的移动机器人基座姿态。通过优化机器人基座姿态来尽量与已训练策略在分布上的基座姿态相匹配的新方法。这种方法结合了3D高斯点绘制、分数函数评估姿态适宜性和基于采样的优化来识别最优机器人姿态。此外，还提出了一个框架Mobi-$π$，包括衡量政策动员难度的指标、基于RoboCasa的模拟移动操作任务套装和可视化工具，用于分析政策动员过程。实验结果表明，该方法在模拟和真实环境中均优于基线方法。
### Conclusion
通过政策动员问题的提出及解决方案，该研究有效提高了现有策略在新的机器人基座和视角下的泛化能力，对于移动平台上的精确操作具有重要意义。
## 1041. `cs.CV` - 重新审视视觉语言导航中的具身差距：一种综合研究视觉和物理差异 [PDF](https://arxiv.org/pdf/2507.13019), [HTML](https://arxiv.org/abs/2507.13019)
### Authors
Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang
### Background
近期的视觉语言导航（VLN）研究取得了一定的成效，但其对于机器人运动与控制的理想化假设未能充分反映实际部署过程中所面临的物理限制。
### Innovation
提出了VLN-PE，一种支持类人、四足和轮式机器人的物理现实的VLN平台，并系统性地评估了几种以自我为中心的VLN方法在物理机器人设置中的不同技术管线中的表现，包括单步离散动作预测的分类模型、密集路径点预测的扩散模型以及基于路径规划的大语言模型（LLM），无需训练即可直接集成。研究揭示了由于有限的机器人观察空间、环境光照变化以及如碰撞和摔倒等物理挑战导致的显著性能下降，这些都暴露了复杂环境中腿足式机器人的动态限制。VLN-PE具有高度的可扩展性，可以在MP3D之外无缝集成新场景，从而提供更全面的VLN评估。尽管目前模型在实际部署中的泛化能力较弱，但VLN-PE为提高跨具身适应性提供了新的途径，提供了新的路径来改进鲁棒性和实用性的VLN模型。
### Conclusion
我们希望我们的发现和工具能激发社区重新思考VLN的局限性，并推动更稳健、实用的VLN模型的发展。
## 1042. `cs.LG` - 已知动力学下的物体识别：PIRNN方法在无人机分类中的应用 [PDF](https://arxiv.org/pdf/2509.21405), [HTML](https://arxiv.org/abs/2509.21405)
### Authors
Nyi Nyi Aung,Neil Muralles,Adrian Stein
### Background
本文针对无人驾驶航空器（UAV）应用中，在已知动力学条件下进行物体识别的问题，结合了学习和分类。研究采用了物理信息残差神经网络，该网络能够利用物理信息来预测状态和状态导数，通过softmax层实现多类置信估计。研究对象包括四旋翼、固定翼和多旋翼无人机，实验结果表明这种方法可以实现高分类准确率并减少训练时间。
### Innovation
提出了一种结合物理信息学习的残差神经网络框架，用于状态映射和状态导数预测；通过softmax层实现多类置信估计；在不同的无人机类型中进行实验验证，展示了在已知动力学条件下进行物体识别的高效性和准确性。
### Conclusion
该工作提出的方法在已知动力学条件下，通过物理信息残差神经网络显著提高了分类准确性并减少了训练时间，为系统识别问题提供了一个有前景的解决方案，特别是在动力学规律明确的应用领域。
## 1043. `cs.CV` - NeuVAS: 基于神经隐式表面的变分形状建模 [PDF](https://arxiv.org/pdf/2506.13050), [HTML](https://arxiv.org/abs/2506.13050)
### Authors
Pengfei Wang,Qiujie Dong,Fangtian Liang,Hao Pan,Lei Yang,Congyi Zhang,Guying Lin,Caiming Zhang,Yuanfeng Zhou,Changhe Tu,Shiqing Xin,Alla Sheffer,Xin Li,Wenping Wang
### Background
近年来，神经隐式形状表示因其平滑性、可微性及拓扑灵活性而备受关注。然而，通过稀疏几何控制直接建模神经隐式曲面，特别是作为神经符号距离函数（SDF）零值等值面，仍然是一个挑战性任务。稀疏输入形状控制通常包括3D曲线网络或更一般的3D曲线草图，这些草图是无结构的，难以直接连接形成曲线网络，处理起来更加困难。尽管3D曲线网络或曲线草图为形状提供了一种直观的控制方法，但它们的稀疏性和多种拓扑结构使得生成满足曲线约束条件的高质量曲面更加困难。因此，本研究提出了一种名为NeuVAS的新变分方法，用于在稀疏输入形状控制下进行基于神经隐式曲面的形状建模，包括未连接的3D曲线草图和连接的3D曲线网络。该方法引入了基于曲面曲率函数的光滑项，以最小化神经SDF零值等值面的形状变化，并开发了一种新方法来准确建模输入曲线草图中指定的G0尖锐边界曲线。与最先进的方法进行全面比较，证明了本方法的显著优势。
### Innovation
本研究提出了NeuVAS，一个在稀疏输入形状控制下使用神经隐式表面进行变分形状建模的方法。具体创新点包括：1）引入了基于曲面曲率函数的光滑项，以最小化神经SDF零值等值面的形状变化；2）开发了一种新方法来准确建模输入曲线草图中指定的G0尖锐边界曲线。
### Conclusion
全面比较显示，与最先进的方法相比，本方法具有显著优势，在基于稀疏输入形状控制的神经隐式表面变分形状建模方面具有很好的应用前景。
## 1044. `cs.CV` - APTx Neuron: 综合激活与计算的统一训练神经元架构 [PDF](https://arxiv.org/pdf/2507.14270), [HTML](https://arxiv.org/abs/2507.14270)
### Authors
Ravin Kumar
### Background
在传统的神经网络中，非线性激活和线性变换是分开处理的，需要独立的激活层。这种分层的处理方式导致了计算效率的较低和架构上的不简洁。本文旨在提出一种新的统一的神经计算单元APTx Neuron，它将非线性激活和线性变换整合到单一可训练表达式中，简化了网络结构，提高了计算效率并增强了表达能力，与传统的神经元相比具有更优的性能。
### Innovation
APTx Neuron是通过APTx激活函数推导出来的，与现有的神经元相比，它不需要单独的激活层，更加简洁且高效。APTx Neuron的公式为 $y = text{∑} ((text{α}_i + tanh(text{β}_i x_i)) times text{γ}_i x_i) + text{δ}$，其中所有参数α_i、β_i、γ_i和δ是可训练的。实验结果表明，在MNIST数据集上使用APTx Neuron架构，仅用11个周期即可获得高达96.69%的测试准确率，使用约332K个可训练参数。这进一步证明了APTx Neuron相较于传统神经元表现出了更强的表达能力和更高的计算效率，为统一神经元设计提供了一种新的范式。
### Conclusion
本文展示了APTx Neuron架构在计算效率和表达能力上的改进和优势，提出了一种新的统一神经元设计范式。
## 1045. `cs.CV` - FERD: 公平增强的数据无数据鲁棒性蒸馏 [PDF](https://arxiv.org/pdf/2509.20793), [HTML](https://arxiv.org/abs/2509.20793)
### Authors
Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang
### Background
现有方法主要关注整体鲁棒性，但忽略了鲁棒公平性问题，导致不同类别间鲁棒性差异严重。学生模型在不同类别之间的鲁棒性表现存在显著差异，并且在不同攻击目标下的鲁棒性也不稳定。因此，需要一个公平增强的数据无数据鲁棒性蒸馏框架来调整对抗样本的比例和分布，从而提升各类别间的鲁棒性均衡性和稳定性。
### Innovation
提出了一种公平增强的数据无数据鲁棒性蒸馏框架(Fairness-Enhanced data-free Robustness Distillation, FERD)。该框架包括鲁棒性引导类重新加权策略，生成更为均衡的对抗样本分布，以及应用统一目标类约束生成公平感知样本，并构造公平感知的均匀目标对抗样本，避免过度针对特定脆弱类别的攻击，实现了鲁棒性和公平性的双重优化。
### Conclusion
通过在三个公开数据集上的广泛实验，FERD在所有对抗攻击下的最差类别鲁棒性上取得了最先进的性能，特别是在FGSM和AutoAttack下的鲁棒性分别提高了15.1%和6.4%，证明了其在鲁棒性和公平性方面的优异表现。
## 1046. `cs.CV` - 多模态递归集群用于预测自然电影大脑响应（Algonauts 2025） [PDF](https://arxiv.org/pdf/2507.17897), [HTML](https://arxiv.org/abs/2507.17897)
### Authors
Semih Eren,Deniz Kucukahmetler,Nico Scherf
### Background
准确预测分布式皮层对自然刺激的响应需要整合视觉、听觉和语义信息的时间模型。传统的预测方法可能无法全面捕捉这些信号的复杂动态，因此需要一种能够处理多模态数据并在时间和空间上进行预测的新模型。本研究通过构建一个分层的多模态递归集合，使用预训练的视频、音频和语言嵌入映射到受试者观看Algonauts 2025挑战提供的近80小时电影时记录的fMRI时间序列数据，以解决这一问题。
### Innovation
本文提出的分层多模态递归集合模型，通过共享的高级层整合跨模态的隐藏状态，并对每个模态使用双向递归神经网络（RNN）编码时间动态。模型通过逐步转移重点来调整损失函数，从早期感觉区域到后期联络区域。此外，提出了分布均方误差-相关损失，并通过100个模型变体的平均进一步增强了模型的鲁棒性。这是处理跨模态数据时的一个创新方法，为未来的多模态脑编码基准测试建立了一个简单可扩展的基准。
### Conclusion
该系统在竞赛排行榜中排名第三，总体皮尔逊r值为0.2094，并且在单个皮层区段的峰值得分（平均r值为0.63）方面赢得了最多参与者中的最高成绩，尤其是在最具挑战性的受试者（受试者5）方面获得了特别显著的提高。本研究为未来多模态脑编码基准测试提供了一个简单的、可扩展的基线方法。
## 1047. `cs.CV` - SeamCrafter：通过强化学习提升网格接缝生成以增强艺术家的UV展开 [PDF](https://arxiv.org/pdf/2509.20725), [HTML](https://arxiv.org/abs/2509.20725)
### Authors
Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo
### Background
网格接缝在3D表面的UV参数化和纹理映射中起着关键作用。不良定位的接缝常常导致严重的UV变形或过度分割，妨碍了纹理合成并打断了艺术家的工作流程。现有的方法通常会产生高变形或许多分散的岛屿之一。因此，亟需一种既能降低接缝变形又能减少不必要分割的方法，以改善UV展开的效率和质量，同时保持拓扑一致性和视觉保真度。
### Innovation
为此，研究人员介绍了一个名为SeamCrafter的自回归GPT风格的接缝生成器，该生成器以点云输入为条件。SeamCrafter采用双重点云编码器，在预训练期间分离和捕捉拓扑和几何信息。进一步通过使用基于偏好数据集的直接偏好优化（DPO）进行微调。这个新型的接缝评估框架首先评估接缝的UV变形和分割情况，然后提供成对的偏好评分以指导优化。实验证明，SeamCrafter生成的接缝具有比现有方法更低的变形和分割水平，同时保持了拓扑一致性和视觉保真度，提升了艺术家的工作体验和结果质量。
### Conclusion
SeamCrafter在不同评估标准下的实验中表现出明显的优势，特别是在UV变形和分割方面。它不仅为艺术家提供了高质量的UV展开工具，还通过提供一个全面的接缝评估框架和偏好优化方法，展示了在增强接缝生成方面的创新技术。
## 1048. `cs.LG` - 基于深度学习的地震波形预报：埃因斯坦望远镜的方法 [PDF](https://arxiv.org/pdf/2509.21446), [HTML](https://arxiv.org/abs/2509.21446)
### Authors
Waleed Esmail,Alexander Kappes,Stuart Russell,Christine Thomas
### Background
在未来像埃因斯坦望远镜这样的引力波检测器中，为了提高检测精度和数据处理效率，需要对地震波形进行准确的预报。传统的地震预报方法难以捕捉到复杂的地震波形特征，因此研究人员开始探索使用深度学习模型来解决这一问题。
### Innovation
textit{SeismoGPT}是一种基于变压器的模型，用于预测三成分地震波形。该模型的特点包括：1) 在自回归设置下训练，能够处理单站和阵列输入；2) 直接从波形数据中学习时间依赖性和空间依赖性，以捕捉真实的地面运动模式并提供准确的短期预报。
### Conclusion
实验结果显示，该模型在预测窗口内表现良好，但随着时间的推移会逐渐退化，这是自回归系统的预期行为。这种方法为基于数据驱动的地震预报奠定了基础，有望支持牛顿噪声的缓解和实时观测站控制。
## 1049. `cs.LG` - Talking Trees: 基于推理辅助生成的决策树方法 [PDF](https://arxiv.org/pdf/2509.21465), [HTML](https://arxiv.org/abs/2509.21465)
### Authors
George Yakushev,Alina Shutova,Ivan Rubachev,Renat Sergazinov,Artem Babenko
### Background
表格基础模型越来越流行，用于处理资源有限的表格数据问题。这些模型通过在大量合成数据上进行预训练，弥补了小规模训练数据集的不足。预训练获得的知识使模型表现出色，但模型也因此成为难以解释的黑盒模型，提高了推理成本。
### Innovation
本文探索了一种替代策略：使用具备推理能力的大规模语言模型（LLM）在有agency设置的情况下，生成适合小型表格数据集的决策树。设计了一组工具来构建、分析和操作决策树，让LLM结合先验知识和从数据中学习，生成了一种轻量级决策树，这种决策树在低资源表格数据问题上优于传统的CART方法。此外，这种基于推理的生成过程允许额外的人类输入，如纠正偏差或融入未被数据捕捉的领域特定直觉。
### Conclusion
虽然单个决策树不能超过最先进的黑盒模型，但其包含可阅读的推理轨迹，可以检查潜在的偏差和数据泄露。此外，推理驱动的LLM生成过程提供了更多的可调整空间，可以额外加入人类输入，改善模型的公正性或补充数据中未涵盖的领域知识。
## 1050. `cs.LG` - 发现和分析随机过程以减少食品零售中的浪费 [PDF](https://arxiv.org/pdf/2509.21322), [HTML](https://arxiv.org/abs/2509.21322)
### Authors
Anna Kalenkova,Lu Xia,Dirk Neumann
### Background
本文提出了分析食品零售过程中减少食品浪费的一种新方法。该方法结合了对象为中心的过程挖掘(OCPM)和随机过程发现与分析。首先，从超市销售数据中发现一种连续时间马尔可夫链形式的随机过程模型。接着，将供应活动扩展到该模型中。最后，进行假设分析以评估商品数量随时间的变化情况。这有助于识别最优平衡点，即顾客购买行为与供应策略之间的平衡点，从而防止因供应过剩导致的食品浪费和产品脱销。
### Innovation
文章的创新之处在于提出了将对象为中心的过程挖掘(OCPM)与随机过程发现和分析相结合的方法，能够从超市销售数据中发现供方过程模型，并通过假设分析评估产品数量随时间的变化情况，从而帮助达成最优的平衡以减少食品浪费和避免产品短缺。
### Conclusion
此方法有助于识别最优平衡点，即顾客购买行为与供应策略之间的平衡点，从而防止因供应过剩导致的食品浪费和产品脱销。
## 1051. `cs.LG` - d2：训练推理扩散语言模型的改进技术 [PDF](https://arxiv.org/pdf/2509.21474), [HTML](https://arxiv.org/abs/2509.21474)
### Authors
Guanghan Wang,Yair Schiff,Gilad Turok,Volodymyr Kuleshov
### Background
尽管扩散语言模型(DLMs)已经在文本生成任务中取得了竞争力的表现，但通过强化学习提高它们的推理能力仍然是一个活跃的研究领域。
### Innovation
引入了针对遮蔽DLMs的新推理框架d2，这个框架的核心是利用掩码特性提出的一种新的策略梯度算法，能够以可分析的方式权衡计算与近似估计的准确性，特别适用于支持任何阶次可能性估计的DLMs。
### Conclusion
实验证明，d2显著优于仅依赖于RL的先前扩散推理框架，为逻辑推理任务(Countdown和Sudoku)和数学推理基准(GSM8K和MATH500)设定新的最先进的性能。
## 1052. `cs.CV` - 差分-积分神经算子在长期湍流预测中的应用 [PDF](https://arxiv.org/pdf/2509.21196), [HTML](https://arxiv.org/abs/2509.21196)
### Authors
Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu
### Background
准确预测长期湍流的演变是一个在科学计算领域中的巨大挑战，对于从气候建模到航空航天工程的不同应用都至关重要。现有深度学习方法，特别是神经算子，在长期自回归预测中常常失效，表现为灾难性的误差累积和物理保真度的丧失。这些失败源于它们无法同时捕捉规范湍流动力学的不同数学结构：局部耗散效应和全局非局部相互作用。
### Innovation
本文提出了一种新颖的框架Differential-Integral Neural Operator（textbf{textunderline{DINtextunderline{O}}}textbf{textunderline{Ntextunderline{E}textunderline{O}}}textbf{textunderline{Ptextunderline{E}}})，该框架采用从第一原理出发的操作分解方法设计。DINOP通过并行分支学习不同的物理操作符：局部微分操作符，由受约束卷积网络实现，可证明收敛到导数；全局积分操作符，由Transformer架构捕获，以学习数据驱动的全局内核。这种基于物理的操作分解使DINOP具备卓越的稳定性和鲁棒性。通过在具有挑战性的2D柯尔莫哥洛夫流基准上进行广泛实验，DINOP在长期预测性能上显著优于最先进的模型，成功抑制了数百个时间步的误差累积，并维持了涡旋场和能量谱的高保真度，建立了可物理一致的长期湍流预报的新标准
### Conclusion
通过在具有挑战性的2D柯尔莫哥洛夫流基准上进行广泛实验，DINOP在长期预测性能上显著优于最先进的模型，成功抑制了数百个时间步的误差累积，并维持了涡旋场和能量谱的高保真度，建立了可物理一致的长期湍流预报的新标准。
## 1053. `cs.LG` - 损失权重和模型复杂性对物理感知神经网络在计算流体动力学中的影响 [PDF](https://arxiv.org/pdf/2509.21393), [HTML](https://arxiv.org/abs/2509.21393)
### Authors
Yi En Chou,Te Hsin Liu,Chao An Lin
### Background
物理感知神经网络(PINNs)提供了一种无需网格的框架来解决偏微分方程(PDEs)，但它们对损失权重的选择高度敏感。已经展示了PINNs在热传导、对流扩散和lid驱动腔流等测试中的应用。
### Innovation
提出了一种基于量化项的二维分析加权方案和一种结合不可量化项的加权方案，以实现更平衡的训练。在对流扩散等高Peclet数问题中，该方案使PINNs实现了稳定且准确的预测，优于等权重方法，特别是有效解决了传统求解器在高Peclet数对流扩散问题中的失效问题，突显了其鲁棒性和在CFD问题中的泛化能力。
### Conclusion
实验结果表明，基于量化和非量化加权方案的PINNs在复杂CFD问题上具有更好的稳定性和准确性，特别是在高Peclet数对流扩散问题中，该方案显示出显著的鲁棒性和适用性。
## 1054. `cs.LG` - SlimDiff：无需训练的基于激活的免手动简化扩散模型 [PDF](https://arxiv.org/pdf/2509.21498), [HTML](https://arxiv.org/abs/2509.21498)
### Authors
Arani Roy,Shristi Das Biswas,Kaushik Roy
### Background
尽管扩散模型（DMs）以其生成性能而受到称赞，但由于其大规模参数（数亿）和迭代去噪动态，这些模型在计算上极具挑战性。现有的效率方法，如量化、时间步减少或剪枝，虽然能够节省计算、内存或运行时间，但都需要通过微调或重新训练来恢复性能，这成为了一个瓶颈。
### Innovation
与现有方法不同，本文提出了一个完全无导数的自动激活引导结构压缩框架SlimDiff。SlimDiff将DM压缩重新定义为频谱近似任务，通过对去噪时间步中的激活共变来定义低秩子空间，引导在固定压缩预算下的动态剪枝。这一激活感知的表述通过模块级分解来应用功能权重组：查询-键交互、值-输出耦合和前馈投影，而不是孤立的矩阵分解，同时自适应地在模块之间分配稀疏性以尊重扩散轨迹的非均匀几何结构。SlimDiff实现了比基线高达35%的加速和约1亿参数的减少，生成质量与未压缩模型相当，且无需任何反向传播。此外，SliMdDiff仅需要大约500个校准样本，是目前所知最新、最少的前驱方法所需的样本数的70多倍。
### Conclusion
这是首个完全无训练的、基于激活引导的扩散模型结构剪枝方法，它同时提供了理论清晰度和实际效率。SlimDiff能够在不牺牲生成质量的情况下显著加速模型，并将压缩限制在极少数校准样本内。
## 1055. `cs.LG` - LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet？ [PDF](https://arxiv.org/pdf/2509.21403), [HTML](https://arxiv.org/abs/2509.21403)
### Authors
Rushil Gupta,Jason Hartford,Bang Liu
### Background
大语言模型（LLMs）被提议可以用作实验设计的通用代理，有网友声称它们能够进行情境感知型（in-context）实验设计。本文通过应用开源和闭源指令调优的LLMs来评估这一假设，任务包括基因扰动和分子性质发现。研究结果显示，LLM代理对实验反馈没有敏感性：用随机排列的标签替换真实结果对性能没有影响。经典方法如线性臂和高斯过程优化在所有基准中表现优于LLM代理。
### Innovation
提出了一种简单的混合方法，即基于LLM先验知识的最近邻采样（LLMNN），将LLM先验知识与最近邻采样结合以指导实验设计。LLMNN在各领域内实现了可竞争或优越的性能，无需显著的情境感知型适应。
### Conclusion
当前开源和闭源LLMs在实际情境中并不能进行情境感知型实验设计，这些结果强调了需要开发融合框架来分离基于先验的推理与使用更新后的后验批量获取数据的必要性。
## 1056. `cs.LG` - 追逐尾部：用于大型语言模型后训练的有效评分表奖励建模 [PDF](https://arxiv.org/pdf/2509.21500), [HTML](https://arxiv.org/abs/2509.21500)
### Authors
Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin
### Background
强化微调（RFT）通常会遇到‘奖励过优化’问题，即政策模型通过未产生高质量输出的方式，恶意利用奖励信号达到高分数。理论分析表明，问题的关键在于奖励在高水平区域的误制定：难以可靠地区分优秀（Excellent）响应和仅仅良好的（Great）响应。因此，研究着重于提高奖励对高水平区域的识别能力。
### Innovation
提出了一种基于评分表的奖励模型方法，通过设计评分表可以利用来自更强模型或重写内容的离策例样（off-policy exemplars），同时不受其潜在缺陷的影响。通过强调区分不同的优质响应，开发了一套工作流程来实现这一目标，从而有效减少奖励过优化，并在大型语言模型的后训练中实现显著改进。
### Conclusion
基于评分表的奖励模型可显著缓解奖励过优化问题，实现大型语言模型的有效后训练改进。相关代码已在以下链接提供：this https URL
## 1057. `cs.LG` - 幻觉是不良估计吗？ [PDF](https://arxiv.org/pdf/2509.21473), [HTML](https://arxiv.org/abs/2509.21473)
### Authors
Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu
### Background
 hallucinations在生成模型中被视为无法将估计与任何合理的原因联系起来的失败。本文从这个角度出发，作者展示了即使是最小化损失的最优估计器也会产生幻觉。他们通过一般性的高概率下限来确认这一点，适用于广泛的数据分布。这个视角重新定义了幻觉，即损失最小化与人类可接受输出之间的结构不匹配，以及由此引起的估计错误，由于校准不当引发的错误。实验覆盖了硬币聚合、开放式QA和文本到图像等领域，支持了这一理论。
### Innovation
本文创新之处在于将损失最小化与人类可接受输出之间的不匹配定义为幻觉的根源，并通过一般性的高概率下限证明了即使是最优估计器也会产生幻觉。这种解释提供了新视角，强调了校准问题在生成模型中的重要性，并通过实验验证了理论的有效性。
### Conclusion
本文通过新的理论框架，将幻觉重新定义为损失最小化与人类可接受输出之间的不匹配，以及导致的估计错误。实验结果支持了作者的观点，并且为理解生成模型的局限性和改进方向提供了有价值的见解。
## 1058. `cs.LG` - Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity [PDF](https://arxiv.org/pdf/2509.21413), [HTML](https://arxiv.org/abs/2509.21413)
### Authors
Zihuan Qiu,Lei Wang,Yang Cao,Runtong Zhang,Bing Su,Yi Xu,Fanman Meng,Linfeng Xu,Qingbo Wu,Hongliang Li
### Background
该论文旨在解决在无数据的情况下将独立微调模型融合到一个可以逐步适应新任务的单一模型中而不会干扰先前任务的问题。文章提出了一种基于子空间过滤的方法来实现这一目标，通过设计过滤器和适配器来确保新模型既有透明性（不会干扰先前任务）又能忠实适应新任务。
### Innovation
该研究提出了一种名为NUFILT的数据免费框架，通过以下几个贡献推进了领域进展：1) 设计了一个子空间过滤器来确保模型的透明性；2) 引入了一个轻量级的适配器来增强模型对新任务的适应性；3) 定义了一种基于投影的损失函数来保留先前知识并引入新方向。这些创新点共同解决了以往方法在数据免费场景下的透明性和忠实性问题，实现了无数据环境下的模型合并。
### Conclusion
实验结果表明，NUFILT在视觉和自然语言处理基准测试中达到了最先进的性能，平均准确率提高了4-7%，并且相比OPCM和WUDI-Merging方法，模型遗忘现象显著减少，同时减少了计算开销。
## 1059. `cs.LG` - 基于得分的扩散模型中的同态模型蒸馏 [PDF](https://arxiv.org/pdf/2509.21470), [HTML](https://arxiv.org/abs/2509.21470)
### Authors
Shehtab Zaman,Chengyan Liu,Kenneth Chiu
### Background
生成模型基于映射到目标流形的同态映射构建，支持单步和多步生成，但通常需要对抗训练且易出不稳定性和模式崩塌。扩散和得分模型通过将样本从一分布迭代迁移到目标数据分布进行生成模型训练，虽然训练动力学稳定且生成质量高，但计算成本高昂。为此，已开发新的采样方法、模型蒸馏和一致性模型以降低采样成本，甚至实现一蹴而就的采样。
### Innovation
本文将扩散模型与同态生成网络（IGN）相结合，通过从扩散模型得分中蒸馏同态模型（SIGN），提出了一种新的训练方法。该方法极大提升了稳定性并避免了需要对抗损失。理论分析了新的基于得分的训练方法，并实验证明预训练的扩散模型可以有效蒸馏生成IGNs，实现了比迭代得分模型更快的推理速度。SIGNs支持多步采样，用户可以针对质量和效率进行权衡，并能直接在源域操作，将受损或替代分布投影回目标流形，实现零样本输入编辑功能。
### Conclusion
本文在CIFAR和CelebA数据集上验证了所提模型，并展示了超越现有同态模型的成果。
## 1060. `cs.LG` - 具有不确定性意识的知识跟踪模型 [PDF](https://arxiv.org/pdf/2509.21514), [HTML](https://arxiv.org/abs/2509.21514)
### Authors
Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead
### Background
知识跟踪（KT）模型的研究主要集中在提高预测准确性上。大多数模型在学生选择干扰项时表现最差，导致未能检测到学生错误。研究指出，当前的KT模型未能捕捉到预测不确定性，从而无法有效地识别和纠正学生的错误。
### Innovation
本文提出了一种通过捕捉预测不确定性来增强KT模型的新方法。研究发现，更大的预测不确定性与模型的错误预测相关联，表明不确定性信息在教育平台中具有教育意义，特别是在资源有限的环境下理解和评估学生能力非常必要。
### Conclusion
不确定性在KT模型中的信息价值得到了证实，这将为开发能够应用于资源有限教育场景的平台提供了新的见解。
## 1061. `cs.LG` - Li_2: 动态特征涌现与延迟泛化的框架 [PDF](https://arxiv.org/pdf/2509.21519), [HTML](https://arxiv.org/abs/2509.21519)
### Authors
Yuandong Tian
### Background
grokking 现象，即延迟泛化，尽管已经得到了广泛的研究，但仍然没有一个数学框架来描述从复杂结构输入的训练过程中出现什么样的特征，以及在什么条件下发生这种现象。已有文献虽然探讨了这一现象，但缺乏系统性的理论框架。
### Innovation
该论文提出了一种新颖的框架，命名为Li_2，用于捕捉2层非线性网络中grokking行为的三个关键阶段：(I) 僵化的学习过程，(II) 独立特征学习，(III) 交互特征学习。这一框架通过反向传播梯度结构 $G_F$ 来刻画这三个阶段的具体表现，并揭示了梯度动态、样本大小和超参数等关键因素在grokking中的作用，使得潜在的能量函数的局部最大值成为了涌现特征，同时提供了记忆和泛化的可证明缩放定律，有助于理解最近的一些优化器，如Muon的有效性。
### Conclusion
该研究从梯度动态的第一原理出发，研究了关键超参数如权重衰减、学习速率和样本数量在grokking中的作用，揭示了基础原理，并为多层架构的研究提供了理论基础，还提出了一种能够证明记忆和泛化能力的可扩展分析方法。
## 1062. `cs.LG` - 在线和联邦零阶优化的高概率分析 [PDF](https://arxiv.org/pdf/2509.21484), [HTML](https://arxiv.org/abs/2509.21484)
### Authors
Arya Akhavan,David Janz,El-Mahdi El-Mhamdi
### Background
该研究聚焦于非梯度零阶优化方法下的分布式学习场景，特别是在联邦（多方合作）设置下的优化问题。传统的零阶优化算法在单工况下已经存在，但关于联邦设置的严格理论保证较少。该研究的目标是在联邦优化环境下提供严格且有效的理论结论.
### Innovation
该研究提出了FedZero，一种联邦零阶算法，该算法在联邦凸优化环境中实现了接近最优的优化误差边界，并在单工况下首次给出了高概率收敛保证，加强了传统的期望结果。论文的核心在于采用了基于$boldsymbol{text{l}_1}$球体上随机化生成的梯度估计器，并且开发了新的Lipschitz函数在均匀$boldsymbol{text{l}_1}$球体测度下的集中不等式，为保持这些结果提供了支撑工具。这些新工具可能对其他研究领域也有独立的意义.
### Conclusion
FedZero算法结合了高概率收敛保证和针对性的梯度估计器，在联邦优化环境中提供了明显的改进。新开发的集中不等式不仅支持了主要结果，也可能独立应用于其他研究领域。
## 1063. `cs.LG` - 数学模型中地下储层系统暂态流体流动的神经运算符 [PDF](https://arxiv.org/pdf/2509.21485), [HTML](https://arxiv.org/abs/2509.21485)
### Authors
Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov
### Background
地下储层系统是一个复杂的动态对象，由分布参数描述，这些参数通过偏微分方程（PDEs）系统进行描述。传统的数值方法虽然具有高准确性，但进行计算需要耗费大量时间，限制了其在控制和决策支持问题中的应用。
### Innovation
提出了一种基于傅里叶神经运算符的架构（TFNO-opt），能够近似在无限维功能空间中求解PDEs，提供对离散化不变性和不同方程实现的一般化可能性。改进包括可调的积分傅里叶算子内部时间分辨率、谱域参数的张量分解、使用索博列夫范数作为误差函数以及分离近似误差和初条件重构以更准确地再现物理过程。这些改进通过计算实验得以验证，实现对传统方法计算加速六个数量级的效果。
### Conclusion
提出的改进为有效控制复杂储层系统打开了新的机会。
## 1064. `cs.LG` - 具有信心的过滤：当数据增强遇到一致预测时 [PDF](https://arxiv.org/pdf/2509.21479), [HTML](https://arxiv.org/abs/2509.21479)
### Authors
Zixuan Wu,So Won Jeong,Yating Liu,Yeo Jin Jung,Claire Donnat
### Background
合成数据增强在广泛的应用场景中展现了乐观的实证效果，成为解决数据稀缺性和数据密集型模型需求的有效方案。其有效性在于通过减少估计量的方差同时引入最小偏倚的方式扩大训练集。控制这种偏倚至关重要：有效的数据增强应在生成与训练集相同基础分布下多样化的样本的同时，尽量减少变化。
### Innovation
本文提出了一种称为合成数据增强的方法，这是一种有原则的数据过滤框架，利用一致预测的力量生成多样化的合成数据，并通过可证明的风险控制过滤掉质量不佳的生成。该方法易于实现，无需访问内部模型的对数几率，也不需要大规模模型重新训练。在多项任务，如主题预测、情感分析、图像分类和欺诈检测中，该方法能够给出持续性能提升，F1评分比未增强的基线高40%以上，比其他过滤增强基线高4%以上。
### Conclusion
本文通过合成数据增强结合一致预测的方法，显著提升了多样化的数据生成和过滤效率，为数据密集型模型提供了有效的解决方案，展示了在多个任务中的广泛应用性和显著效果。
## 1065. `cs.LG` - VISION：基于不完整观测数据的海洋垂直速度重建提示 [PDF](https://arxiv.org/pdf/2509.21477), [HTML](https://arxiv.org/abs/2509.21477)
### Authors
Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang
### Background
地球科学领域中，从不完整的表层观测数据重建海底海洋动力学，如垂直速度场，是一个至关重要的挑战。长久以来，由于缺乏标准化、可分析的基准数据集，这一问题一直困扰着研究人员。
### Innovation
本文提出了VISION，一个基于动态提示的新颖重建框架。VISION能够在任何可用的观测数据子集基础上即时生成视觉提示，既编码了观测数据的可用性也反映了海洋的物理状态。此外，VISION设计了状态条件提示模块，可以高效地将这些提示注入通用的神经网络骨架中，并运用几何和尺度意识操作来引导其对计算策略的自适应调整。这使得VISION能够精确应对不同输入组合带来的挑战。实验结果表明，VISION不仅在现有模型中表现出色，而且在极端数据缺失情况下也展现出强大的泛化能力。
### Conclusion
通过提供高质量的基准数据集和稳健的模型，本文为在数据不确定性条件下开展海洋科学研究搭建了坚实的基础设施，相关代码可在指定链接获取。
## 1066. `cs.LG` - GraphPFN：基于先验数据调整的图基础模型 [PDF](https://arxiv.org/pdf/2509.21489), [HTML](https://arxiv.org/abs/2509.21489)
### Authors
Dmitry Eremeev,Oleg Platonov,Gleb Bazhenov,Artem Babenko,Liudmila Prokhorenkova
### Background
大规模数据集预训练的基础模型已改变了自然语言处理和计算机视觉领域，但在图数据应用方面仍受到限制。当前新兴的图基础模型，如G2T-FM，使用表格基础模型解决图任务，并且在以往的GFMs尝试中表现出显著优越性。然而，这些模型主要依赖手工设计的图特征，这限制了他们学习复杂的图特定模式的能力。
### Innovation
本文提出了一种名为GraphPFN的先验数据调整网络，用于节点级预测。首先，设计了一种合成有属性图的先验分布。对于图结构生成，采用了多种随机块模型和偏好附着过程的新型组合。然后，使用图感知的结构因果模型生成节点属性和目标值。此过程使我们可以高效生成大量真实的图数据集。然后，将基于注意力的图邻域聚合层添加到表格基础模型LimiX中，并在从本文先验中采样的合成图上进行训练，使模型可以捕捉到表格数据中不存在的图结构依赖关系。在具有最多50,000个节点的多样真实图数据集上，GraphPFN在上下文学习性能方面表现出色，微调后达到了最新技术水平，远胜G2T-FM和从头开始训练的任务特异性GNNs。更为广泛地说，本文的工作证明了使用从精心设计的先验分布中生成的合成图进行预训练，是构建图基础模型的有效策略。
### Conclusion
本文提出了名为GraphPFN的基于先验数据调整的图基础模型。通过高效生成大量真实的图数据集，结合使用图感知的结构因果模型生成节点属性和目标值的方式，以及优化基于注意力的图邻域聚合层，实现对复杂图结构特征的有效学习。实验结果显示，GraphPFN在上下文学习性能方面表现出色，并在大多数数据集上优于G2T-FM和从头开始训练的任务特异性GNNs。
## 1067. `cs.LG` - 对比互信息学习：无需正配对增强的鲁棒性表征 [PDF](https://arxiv.org/pdf/2509.21511), [HTML](https://arxiv.org/abs/2509.21511)
### Authors
Micha Livne
### Background
在表征学习中，学习能够很好地转移到多种下游任务的表示仍然是一项核心挑战。现有的方法在对比学习、自监督掩码和去噪自编码器之间各有不同的权衡。MIM最大化输入和潜在变量之间的互信息并促进代码的聚类，但在区分性任务上存在局限性。
### Innovation
我们引入了对比互信息机（cMIM），一种扩展了MIM的对比目标概率框架。cMIM解决了MIM在区分性任务上的不足，同时保持了生成保真度。我们的贡献包括：1) 提出cMIM，结合了对比目标的MIM扩展，减少了对正样本增强的需求，且相比InfoNCE对批次大小的敏感性更低；2) 引入了富有信息的嵌入技术，这是一种广泛适用于提取编码-解码模型中丰富特征的通用技术，不需额外训练即可提升区分性能；3) 在视觉和分子标记标准中提供了经验证据，表明cMIM在分类和回归任务上优于MIM和InfoNCE，同时保持了竞争力重建质量。这些结果使cMIM成为统一的表征学习框架。
### Conclusion
cMIM为同时服务于区分性与生成性应用的有效模型设定了一种统一框架，取得了优于MIM和InfoNCE的表征效果，提升了区分性和重建质量的平衡。
## 1068. `cs.LG` - GenUQ：通过生成超网络进行预测不确定性估计 [PDF](https://arxiv.org/pdf/2509.21605), [HTML](https://arxiv.org/abs/2509.21605)
### Authors
Tian Yu Yen,Reese E. Jones,Ravi G. Patel
### Background
操作学习是回归的一种近期扩展，用于函数之间的映射，它承诺将代价高昂的偏微分方程（PDEs）数值积分大大减少为快速评估系统功能性状态之间的映射，即代理模型和降阶建模。操作学习已在海洋冰、燃烧和大气物理等多个领域找到了应用。最近将不确定性量化集成到操作模型中的方法依赖于基于似然的方法来从嘈杂数据中推断参数分布。然而，随机操作可能产生难以构造或无法构造似然性的操作。
### Innovation
本文介绍了GenUQ，一种通过生成超网络模型引入的度量论方法来解决不确定性量化问题，这种方法避免了构造似然性，而是产生与观测数据一致的参数分布。实验结果表明，GenUQ在三个示例问题中表现优于其他不确定性量化方法：重建制造的操作，学习随机椭圆PDE的解算器，以及模拟受拉条件下多孔钢的失效位置。
### Conclusion
GenUQ在三个示例问题中证明了其能力，分别为重建制造操作、学习随机椭圆PDE的解、以及模拟多孔钢在受拉条件下的失效位置。GenUQ能够提供比其他不确定性量化方法更好的结果，在数值上证明了其对操作学习中不确定性量化问题的有效解决方案。
## 1069. `cs.LG` - 通过潜在可达性预防和引导LLM偏离正轨 [PDF](https://arxiv.org/pdf/2509.21528), [HTML](https://arxiv.org/abs/2509.21528)
### Authors
Sathwik Karnik,Somil Bansal
### Background
大型语言模型（LLMs）在日常工具中的广泛应用引发了对其生成有害内容的安全关切。现有的安全方法——从人类反馈中强化学习（RLHF）——在训练过程中有效地塑造了模型行为，但未能在推理阶段提供保障，仍然可能导致不安全的生成。
### Innovation
提出了一种基于可达性的框架BRT-Align，该框架将自回归生成视为潜在空间中的动力学系统，并学习安全的价值函数。这种方法能够预测不安全的完成，并且通过最小扰动潜在状态来引导生成，使其远离不安全区域。实验表明，BRT-Align在多个LLM和毒性基准测试上提供了比基线更准确和早期的不安全生成检测，同时减少了不安全生成，保持了句子的多样性和连贯性。
### Conclusion
研究结果表明，可达性分析为推理阶段的LLM安全提供了原则性和实用性的基础。
## 1070. `cs.LG` - 基于查询的专家引导临床文本增强方法 [PDF](https://arxiv.org/pdf/2509.21530), [HTML](https://arxiv.org/abs/2509.21530)
### Authors
Dongkyu Cho,Miao Zhang,Rumi Chunara
### Background
数据增强是一种常用策略，通过增加合成示例来丰富训练数据集，从而提高模型的稳健性和泛化能力。大型语言模型（LLMs）在生成这些合成示例方面表现出强大能力，但在涉及高风险领域的医疗保健中，存在生成临床错误或误导性信息的风险。本文探讨了如何在这种背景下利用专家级领域知识来引导数据增强过程，以保留关键医疗信息。实验结果表明，通过轻量级协作框架来增强模型表现优于现有方法，并通过减少事实错误来提高安全性。
### Innovation
提出了一种基于查询的模型协作框架，它结合了专家级领域的知识来指导数据增强过程，以保留关键的医疗信息。该方法能够在保持模型性能的同时，通过减少事实错误来提高安全性，弥补了大型语言模型在增加安全需求上的数据增强潜力之间的差距。
### Conclusion
本文提出的方法在临床预测任务中表现优于现有的LLM增强方法，并通过减少事实错误提高了安全性。这种协作框架填补了大型语言模型增强潜力与专业领域安全需求之间的空白。
## 1071. `cs.LG` - TRiCo: 三方博弈协作学习方法以增强稳健的半监督学习 [PDF](https://arxiv.org/pdf/2509.21526), [HTML](https://arxiv.org/abs/2509.21526)
### Authors
Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang
### Background
目前常用的半监督学习（SSL）框架存在一些限制，例如静态视图交互、伪标签可靠性差以及缺乏对难度样本的建模。TRiCo框架创新性地引入了三种角色：两个基于冻结且互补表征的学生分类器、一个元学习的教师以及一个非参数生成器。这三种角色构成一种统一的训练范式，并进一步优化了SSL的过程。
### Innovation
TRiCo框架将SSL重新构想为三角色之间的结构化互动。它采用了一种新颖的triadic game-theoretic co-training机制，其中教师负责策略优化，学生在对抗性扰动下进行跟随。伪标签依据互信息而非置信度来选择，提供了一个更稳健的认识不确定性测度。
### Conclusion
TRiCo框架通过解决现有SSL框架的关键限制，提供了既具有原则性又可泛化的解决方案。在CIFAR-10、SVHN、STL-10和ImageNet上的广泛实验表明，TRiCo能够在低标签设置下持续达到最先进的性能，并保持对冻结视觉 backbone的兼容性和架构无关性。
## 1072. `cs.LG` - 在大型语言模型中预测层次结构的电路 [PDF](https://arxiv.org/pdf/2509.21534), [HTML](https://arxiv.org/abs/2509.21534)
### Authors
Tankred Saanum,Can Demircan,Samuel J. Gershman,Eric Schulz
### Background
大型语言模型（LLMs）擅长于上下文化的学习，即使用提供的信息来改进对后续标记的预测。尽管已有关于诱导头在转换器语言模型中起关键作用的讨论，该机制支持LLMs复制和预测重复模式。但尚不清楚诱导头是否能够支持更复杂的具有层次结构的重复模式的上下文学习。自然语言中存在大量这样的例子，例如在英语中“the”通常前置多个名词，预测“the”后的正确名词需要整合文本中的额外上下文线索。然而，如果诱导头以上下文无关的方式关注所有上下文中的“the”后的前驱标记，那么它们将无法支持这种层次结构的上下文信息整合。
### Innovation
本文设计了一个合成的上下文化任务，其中标记以具有层次依赖性的形式重复。研究发现，通过学习在特定上下文中应该关注什么，可采用自适应的诱导头支持预测。更重要的是，研究发现学习是由识别出一组潜在上下文的注意力头支持的，这些潜在上下文确定了不同的标记转换关系。除了展示LLMs具有学习的诱导头之外，还提供了一种完整的机制，说明LLMs如何在上下文中学习预测高阶重复模式。这一发现有助于更深入理解LLMs的学习机制。
### Conclusion
研究不仅证明了LLMs具有学习的诱导头，还提出了一个完整的机制来解释LLMs如何在上下文中学习预测更高层次的重复模式。
## 1073. `cs.LG` - 损失表示下因果抽象推理 [PDF](https://arxiv.org/pdf/2509.21607), [HTML](https://arxiv.org/abs/2509.21607)
### Authors
Kevin Xia,Elias Bareinboim
### Background
该研究探讨了因果抽象的概念，将人类智能的两个关键方面联系起来：确定因果关系的能力和将复杂模式转化为抽象概念的能力。现有定义的主要限制在于它们不适用于损失性抽象函数，这种函数可能导致多个底层干预产生不同的影响，但映射到同一个高层干预。论文提出了一种新的投影抽象类型，以应对损失表示问题，并展示了如何从底层模型构建投影抽象，以及如何在不同层次之间翻译等效的观察、干预和反事实因果查询。
### Innovation
论文提出了一种称为投影抽象的新类型，该类型可以扩展现有的定义以适应损失性表示。此外，论文提供了一个新的图解标准，用于从受限的底层数据中识别和估计高层因果查询。
### Conclusion
即使在真实模型很少可用的情况下，投影抽象模型也有效地在高维图像环境中运行。
## 1074. `cs.LG` - LANCE: 低秩激活压缩用于高效边缘设备持续学习 [PDF](https://arxiv.org/pdf/2509.21617), [HTML](https://arxiv.org/abs/2509.21617)
### Authors
Marco Paul E. Apolinario,Kaushik Roy
### Background
在资源受限的环境中，设备学习对于个性化、隐私保护和长期适应至关重要。实现这一目标需要高效的模型微调和持续学习，同时避免灾难性遗忘。然而，这两个过程都受到反向传播期间存储激活所需的高内存成本的限制。现有的激活压缩方法虽能降低此成本，但依赖于重复的低秩分解，引入了计算开销，而且这些方法还未被探索用于持续学习。
### Innovation
我们提出了LANCE（低秩激活压缩），一种框架，采用单次更高阶SVD进行激活投影，从而获得可重用的低秩子空间，消除重复分解，减少内存和计算成本。固定的低秩子空间还能够通过将任务分配给正交子空间来支持边缘设备上的持续学习，无需存储大型任务特定矩阵。实验表明，LANCE在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上将激活存储减少至最高250倍，同时保持与完整反向传播相当的准确性。在持续学习基准测试中，LANCE实现了与正交梯度投影方法相当的性能，但内存成本仅为后者的极小部分。
### Conclusion
这些结果将LANCE定位为一种适用于边缘设备上的高效微调和持续学习的实际且可扩展的解决方案。
## 1075. `cs.LG` - LLMs中有限元认知能力的证据 [PDF](https://arxiv.org/pdf/2509.21545), [HTML](https://arxiv.org/abs/2509.21545)
### Authors
Christopher Ackerman
### Background
随着大语言模型（LLM）的自我意识甚至知觉可能性受到越来越多的公众关注，其安全性和政策影响变得非常重要，但目前对这些能力的测量科学还处于萌芽阶段。本文介绍了用于定量评估LLM元认知能力的新方法。灵感来源于非人类动物中的元认知研究，该方法测试模型是否能战略性地利用对其内部状态的知识。采用两种实验范式展示了自2024年初引入的前沿LLM表现出某些元认知能力的证据，包括评估和利用自身正确回答事实和推理问题自信的能力，以及预测自己会给出的答案并加以适当利用的能力。还进行了模型返回的标记概率分析，暗示可能存在上游内部信号，可能是元认知的基础。此外，这些能力在分辨率上有限，在情境依赖下出现，并且似乎在质量和人类不同。最后，报告了相似能力模型间的有趣差异，表明LLM在训练后可能在发展元认知能力方面发挥作用。
### Innovation
介绍了一种新的方法，用于定量评估LLM的元认知能力，该方法借鉴了对非人类动物元认知的研究，没有依赖于模型的自我报告，而是测试模型能否战略性地使用其内部状态的知识。这种方法通过两种实验范式展示了前沿LLM在元认知能力方面的证据，并通过分析模型返回的标记概率进一步证实了这些能力的存在。此外，还发现这些能力具有分辨率有限、情境依赖和与人类元认知能力不同的特点，并在相似能力模型之间发现了有趣的不同之处。
### Conclusion
前沿LLM在分辨率有限的情况下，在一定情境下展示了评估和利用自身回答正确性和进行推理问题回答能力，这些能力似乎是独特的，与人类元认知能力不同。报告了通过模型返回标记概率分析和实验范式的相关发现，表明在训练后，LLM可能在发展某种元认知能力方面起作用。
## 1076. `cs.LG` - 利用大数据框架进行亚马逊评论中的垃圾信息检测 [PDF](https://arxiv.org/pdf/2509.21579), [HTML](https://arxiv.org/abs/2509.21579)
### Authors
Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed
### Background
在数字化时代，网上购物已成为我们日常生活的一部分。产品评论对消费者的购买行为有重大影响，有助于建立买家信任。然而，虚假评论的泛滥破坏了这种信任，可能会误导消费者，并损害卖家的声誉。基于此，本研究通过应用先进的大数据分析和机器学习方法，对大量的亚马逊产品评论数据集进行处理和分析，以准确地检测和分类垃圾评论，从而提高评论的真实性，构建一个更可信赖和透明的网上购物环境。
### Innovation
本研究利用大规模数据处理框架有效地处理和分析大量的评论数据，并通过多种机器学习分类器识别垃圾评论。研究发现，逻辑回归在检测垃圾评论方面的准确度达到了90.35%，这为构建更可信赖和透明的网上购物环境提供了新的方法和技术支持。
### Conclusion
本研究通过应用大数据技术和机器学习方法，有效检测和分类了大量的亚马逊产品评论中的垃圾信息，提高了评论的真实性，有助于重建消费者对电子商务平台的信任，并为改善和优化电子商务环境提供了数据支持和政策建议。
## 1077. `cs.LG` - 使用Gumbel动力学进行可解释的时间序列分析 [PDF](https://arxiv.org/pdf/2509.21578), [HTML](https://arxiv.org/abs/2509.21578)
### Authors
Yiliu Wang,Timothy Doyeon Kim,Eric Shea-Brown,Uygar Sümbül
### Background
切换动力学系统可以通过推断出一组动态基元并用这些基元解释观测的时间序列的不同部分来建模复杂的时序数据，保持其解释性。然而，由于这一组态的离散性质，这些模型难以捕捉平滑、变速度的过渡，也无法描述重叠状态下的随机混合状态，且在真实的数据集上推断出的动力学经常显示虚假的快速切换现象。
### Innovation
GDM通过引入离散状态的连续松弛和通过Gumbel分布定义在松弛离散状态空间上的不同噪声模型，扩大了可用状态动态的范围，使模型能够更准确地逼近平滑和非平稳的真实数据动态。此外，松弛使模型完全可微，从而可以使用标准梯度下降方法进行快速且可扩展的训练。该方法在标准模拟数据集上进行了验证，并展示了其在随机时间序列中建模软粘性状态和过渡的能力。模型被应用于两个真实世界的数据集，证明了其在多个动力学时间序列中推断可解释状态的能力，而在传统方法往往失败的情况下得到了验证。
### Conclusion
GDM通过使用连续松弛和Gumbel分布成功解决了传统切换动力学模型中的问题，并且能够以可解释的方式捕捉复杂的真实世界时间序列数据。这种模型的有效性已经在多种数据集上得到了验证。
## 1078. `cs.LG` - Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning [PDF](https://arxiv.org/pdf/2509.21637), [HTML](https://arxiv.org/abs/2509.21637)
### Authors
Feng Yu,Jia Hu,Geyong Min
### Background
参数高效的微调（PEFT）方法必须在资源高效的同时处理异构的推理变换，而古典低秩适应（LoRA）方法则受限于名义秩r。Hadamard风格的扩展如HiRA虽然提高了名义秩，但使得每个更新都受到冻结权重矩阵全局能量模式的制约，而ABBA则为此偏置放弃全学习密集中间层。BHRA旨在解决全局模调节制的限制，它将每个权重矩阵分割，并在每个块内独立应用HiRA风格的乘法模调节制，从而保持PEFT参数足迹的同时解锁局部的秩放大。
### Innovation
BHRA通过将每个权重矩阵分割并在每个块内独立应用HiRA风格的乘法模调节制，来解决全局模调节制的限制。这种块状设计在预算不同的秩条件下保持了丰富的频谱，缓解了全局调整引起的崩溃。BHRA在八项常识推理任务和两项算术基准测试中均优于与参数预算匹配的强PEFT基线，特别是在使用Llama-3.2 1B/3B、Mistral-7B和Gemma-2 9B的情况下。
### Conclusion
BHRA在不同模型规模和任务下的参数高效微调中展现出优越性能，通过局部化的秩放大机制提升了模型的参数效率和推理能力。
## 1079. `cs.LG` - 机器学习：在不确定性下的选择科学 [PDF](https://arxiv.org/pdf/2509.21547), [HTML](https://arxiv.org/abs/2509.21547)
### Authors
Yevgeny Seldin
### Background
学习，无论是自然还是人工，都是一个选择过程。它开始于一组候选选项并选择更成功的选项。在机器学习中，选择基于候选预测规则在一些数据上的预测准确性的经验估计。由于数据抽样的随机性，经验估计本质上是嘈杂的，导致在不确定性下进行选择。本书提供了统计工具以获得在不确定性下选择过程结果的理论保证。我们从测度集中不等式开始，这是用于控制经验估计的功能期望值与真实期望值之间差异的主要统计工具。本书涵盖了广泛的不等式，包括马尔可夫不等式、切比雪夫不等式、赫尔德不等式、伯恩斯坦不等式、经验伯恩斯坦不等式、意外伯恩斯坦不等式、kl和分割kl不等式。然后研究经典的（离线）监督学习，提供了从奥卡姆剃刀、Vapnik-Chervonenkis分析到PAC-贝叶斯分析的各种工具，进一步应用于有加权多数投票的泛化保障。在覆盖离线场景后，我们转向在线学习。我们提出了由环境反馈、环境阻力和结构复杂性定义的在线学习问题空间。在线学习的通用性能测度是遗憾度，它将算法的性能与前瞻 hindsight 中限制预测规则集中表现最好的预测规则进行比较。我们提供了在随机和对抗环境中，在获得信息和带宽反馈情况下获得遗憾度边界的各种工具。
### Innovation
本书提供了在不确定性下选择过程的统计工具。它涵盖了广泛的不等式，包括赫尔德不等式、伯恩斯坦不等式和PAC-贝叶斯分析。此外，还提供了在线学习中遗憾度边界的各种工具，涵盖了随机和对抗环境，以及获得信息和带宽反馈的情况。
### Conclusion
本书通过提供统计工具，为在不确定性下选择过程的结果提供了理论保证。它不仅涵盖了广泛的不等式，而且引入了各种工具来研究在线和离线学习中的后悔度边界，从而为这些问题提供了解决方案。
## 1080. `cs.LG` - A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges [PDF](https://arxiv.org/pdf/2509.21660), [HTML](https://arxiv.org/abs/2509.21660)
### Authors
Pascal Memmesheimer,Vincent Heuveline,Jürgen Hesser
### Background
治疗效果估计对于医疗保健、经济学和公共政策等领域中的知情决策至关重要。虽然灵活的机器学习模型被广泛应用于估计异质性治疗效果，但其点预测的固有不确定性量化仍然是一大挑战。近年来，一致性推断方法在这方面取得了进展，它不仅允许计算成本低廉，还能适应分布变化，同时在最少假设下提供频率主义、有限样本覆盖率保证，适用范围广泛。
### Innovation
本文进行了一次系统性回顾，涉及治疗效果估计中的一致性推断方法。通过系统过滤过程，我们选择了并分析了十一篇关键论文，指出现有最先进的方法，提出了未来研究的方向。
### Conclusion
基于研究结果，本文提出了未来研究的方向。
## 1081. `cs.LG` - 理解并增强基于掩码的预训练以获得通用表示 [PDF](https://arxiv.org/pdf/2509.21650), [HTML](https://arxiv.org/abs/2509.21650)
### Authors
Mingze Dong,Leda Wang,Yuval Kluger
### Background
基于掩码的预训练已成为自然语言处理、视觉识别和最近的生物学领域大型模型的基础。尽管它在实践中非常成功，但其在学习数据表示中的作用和局限性一直不明确。
### Innovation
本文引入了一种新的理论框架，直接通过高维最小范数线性回归测试风险来描述基于掩码的预训练行为，不需要依赖进一步的模型规范。在此基础上，提出了一种新的预训练方案——随机随机掩码自编码（R$^2$MAE），它能够从数据中捕获多尺度特征，并在本文探讨的线性模型框架中超过了最优固定掩码比例设置。
### Conclusion
R$^2$MAE在视觉、语言、DNA序列和单细胞模型中均表现出色，均优于标准和更复杂的掩码策略，提升了现有最佳模型的表现。相关代码已开源。
## 1082. `cs.LG` - 通过无回放梯度投影实现的任务无关联邦持续学习 [PDF](https://arxiv.org/pdf/2509.21606), [HTML](https://arxiv.org/abs/2509.21606)
### Authors
Seohyeon Cha,Huancheng Chen,Haris Vikalo
### Background
联邦持续学习（Federated continual learning，FCL）使分布式客户端设备能够从多样化且不断演化的数据流中学习。但在分散的设置中，数据异质性、通信限制和隐私问题会加剧持续学习中的灾难性遗忘问题。
### Innovation
提出了一种名为FedProTIP的新颖FCL框架，该框架通过将客户端更新投影到全球模型之前学习表示的子空间的正交补空间中来减轻遗忘。此外，引入了一种轻量级机制，利用先前任务的核心基来预测任务身份并动态调整全球模型的输出，以应对任务无关的推断挑战。
### Conclusion
在标准FCL基准上的大量实验表明，FedProTIP在平均准确率上显著优于现有方法，特别是在任务身份事先未知的情况下表现更好。
## 1083. `cs.LG` - 逻辑假设：从零知识到完全知识的神经符号集成 [PDF](https://arxiv.org/pdf/2509.21663), [HTML](https://arxiv.org/abs/2509.21663)
### Authors
Davide Bizzaro,Alessandro Daniele
### Background
神经符号集成（NeSy）将神经网络学习与符号推理结合起来。该领域可以分为两类方法：一类是将手工艺品规则注入神经模型中，另一类是从数据中推导出符号规则。NeSy模型通常根据在这两个方面的融合程度进行分类。作者介绍了一种名为逻辑假设（LoH）的新语言，这种语言能够统一这两类方法，并允许灵活地结合数据驱动的规则学习与符号先验和专家知识。
### Innovation
LoH 扩展了命题逻辑语法，加入了一个具有可学习参数的选择操作符，该操作符可以从一组选项中选择子式公式。通过模糊逻辑，LoH 中的公式可以直接转换为可微计算图，这样可以通过反向传播学习最优选择。这种框架不仅包括一些现有的神经符号集成模型，而且还允许灵活指定不同知识程度。此外，使用哥德尔模糊逻辑和最近开发的哥德尔技巧构建的模型可以在不损失性能的情况下离散化为硬布尔函数。
### Conclusion
在表格数据和视觉井字博弈神经符号集成任务上的实验分析表明，LoH 的模型生成了可解释的决策规则，取得了良好的结果。
## 1084. `cs.LG` - SlotFM: 带有Slot注意力的运动基础模型，适用于多种下游任务 [PDF](https://arxiv.org/pdf/2509.21673), [HTML](https://arxiv.org/abs/2509.21673)
### Authors
Junyong Park,Oron Levy,Rebecca Adaimi,Asaf Liberman,Gierad Laput,Abdelkareem Bedri
### Background
穿戴式加速度计被广泛应用于手势识别、步态分析和运动监控等场景，但现有大多数基础模型主要集中在分类日常活动，如移动和锻炼，这限制了它们在依赖其他信号特征的更广泛任务中的应用。
### Innovation
提出了SlotFM，一种能够泛化到多种下游任务的加速计基础模型。SlotFM 使用时间-频率槽注意机制，处理原始信号的时间和频率表示，生成多个小嵌入（槽），每个槽捕捉不同的信号成分，使特定任务的头部能够关注最相关的数据部分。引入了两种损失正则化项，捕捉局部结构和频率模式，改进了细节重建，帮助嵌入保持任务相关的信息。
### Conclusion
在16个超过标准人类行为识别的分类和回归下游任务上评估SlotFM，它在13个任务上优于现有的自监督方法，其余任务达到最佳方法的可比结果。我们的方法平均提高4.5%的性能，展示了传感基础模型的强泛化能力。
## 1085. `cs.LG` - PreLoRA: 使用全训练和低秩适配器结合预训练的视觉变换器 [PDF](https://arxiv.org/pdf/2509.21619), [HTML](https://arxiv.org/abs/2509.21619)
### Authors
Krishu K Thapa,Reet Barik,Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath
### Background
训练大型模型，无论是数百万还是数亿参数，都非常耗资源，需要大量时间和计算能力。观察到在训练循环的早期阶段，大部分学习（权重的较大变化）发生，随着训练的进行，这些变化趋于稳定，可以被低内在秩矩阵所捕捉。因此，本文提出了一种方法，旨在识别这种部分收敛状态，并动态地从全参数训练切换到ViT-Large模型的Low-Rank Adaptation (LoRA)。
### Innovation
介绍了一种灵活的方法，利用用户定义的超参数来确定切换点，并根据模块层的收敛程度为其分配特定的秩。这种方法在保持模型准确性的同时，将可训练参数减少到模型初始大小的10%，从而提高了3倍的吞吐量，减少了20%的GPU内存消耗，并将每轮训练时间平均减少了50%。
### Conclusion
这种预LoRA方法证明了可以在训练视觉变换器时有效地利用低秩适应，从而显著减少资源消耗，同时保留模型性能。
## 1086. `cs.LG` - 通用二元数据的可微结构学习 [PDF](https://arxiv.org/pdf/2509.21658), [HTML](https://arxiv.org/abs/2509.21658)
### Authors
Chang Deng,Bryon Aragam
### Background
现有的可微结构学习方法通常认为离散数据是由特定结构方程模型生成的，但这些假设可能与真实的数据生成过程不符，限制了这些方法的广泛适用性。此外，当前方法往往忽略了离散数据中固有的复杂依赖关系，只考虑线性效应。
### Innovation
作者提出了一种可微结构学习框架，能够捕捉离散变量之间的任意依赖关系。研究表明，虽然一般的离散模型从观察数据中是不可辨识的，但仍可以刻画出完整的兼容参数和结构集。在轻微假设下，实现到了马尔可夫等价性的辨识性。作者将学习问题形式化为一个最通用形式的单一可微优化任务，从而避免了先前方法中不现实的简化。
### Conclusion
实验结果表明，该方法能够有效捕捉离散数据中的复杂关系。
## 1087. `cs.LG` - 从HIP直击：无导数的Hessian原子势能 [PDF](https://arxiv.org/pdf/2509.21624), [HTML](https://arxiv.org/abs/2509.21624)
### Authors
Andreas Burger,Luca Thiede,Nikolaj Rønne,Varinia Bernales,Nandita Vijaykumar,Tejs Vegge,Arghya Bhowmik,Alan Aspuru-Guzik
### Background
计算化学中的许多基本任务，如过渡态搜索和振动分析，都依赖于分子哈密尔顿量，这是势能的二阶导数。然而，计算哈密尔顿量非常耗时，并且随系统大小的增加而迅速不可行，无论是量子力学方法还是神经网络。已有研究通常依赖自动微分或有限差分来计算哈密尔顿量。本文介绍了如何直接从深度学习模型预测哈密尔顿量，无需依赖自动微分或有限差分的方法。通过图神经网络中的信息传递计算不可约表示特征，构建了SE(3)-对称哈密尔顿量。这种方法使预测的哈密尔顿量比传统方法快1到2个数量级，并且准确性更高、内存使用更高效，训练更容易，且随着系统大小的增大具有更优的可扩展性。研究人员通过各种下游任务验证了这种方法的有效性，结果显示其在过渡态搜索、加速几何优化、零点能修正和振动分析基准测试中的性能始终优于传统方法。
### Innovation
本文提出了一种无需使用自动微分或有限差分的新方法，通过深度学习模型直接预测Hessian矩阵。通过图神经网络的信息传递计算不可约表示特征，构建了SE(3)-对称Hessian矩阵。这种方法使得哈密尔顿量的预测速度提高1到2个数量级，准确性更高，内存使用更高效，更容易训练，并且在系统规模上具有更优的可扩展性。
### Conclusion
通过针对各种下游任务进行广泛的验证，证实了新方法在多个领域始终优于现有方法。此外，研究人员还开源了HIP代码库和模型权重，以促进直接预测Hessian矩阵的研究开发。
## 1088. `cs.LG` - RED-DiffEq: 通过去噪扩散模型进行正则化以解决微分方程逆问题的应用到全波形反演 [PDF](https://arxiv.org/pdf/2509.21659), [HTML](https://arxiv.org/abs/2509.21659)
### Authors
Siming Shan,Min Zhu,Youzuo Lin,Lu Lu
### Background
微分方程（PDE）调控的逆问题在各个科学和工程领域中至关重要，但由于非线性、病态性和噪声敏感性等问题，这些问题常常面临重大挑战。全波形反演是一种挑战性的地震成像技术，旨在从地震测量数据中重建高分辨率的地下速度模型，但同样存在以上提到的挑战。
### Innovation
本文提出了一种新的计算框架，RED-DiffEq，将物理驱动的反演和数据驱动的学习相结合。RED-DiffEq利用预训练的去噪扩散模型作为PDE调控逆问题的正则化机制。该方法在解决全波形反演问题时表现出了更高的准确性和鲁棒性，并且对扩散模型未训练的复杂速度模型也有很强的泛化能力。
### Conclusion
本文提出的RED-DiffEq框架可以直接应用于各种PDE调控的逆问题。
## 1089. `cs.LG` -  scalable_second_order_riemannian_optimization_for_k_means_clustering [PDF](https://arxiv.org/pdf/2509.21675), [HTML](https://arxiv.org/abs/2509.21675)
### Authors
Peng Xu,Chun-Ying Hou,Xiaohui Chen,Richard Y. Zhang
### Background
K-均值聚类是离散最优化问题中的一个难题。尽管非凸方法如低秩半定规划(SDP)已经证明了在聚类恢复中具有显著的统计和局部算法保证，但对于K-均值聚类问题的非凸结构，现有的松弛算法难以平衡约束可行性与优化目标，难以确保严格计算出二阶临界点。
### Innovation
作者提出了一种新的K-均值问题光滑无约束优化形式，并通过子流形上的黎曼结构特性，使用二次立方正则化黎曼牛顿算法求解。通过将K-均值流形进行产品分解，作者展示了每个牛顿子问题可以在线性时间内解决。实验结果表明，所提出的算法相较于最先进的非负低秩因子分解方法，收敛速度更快，同时达到了相似的统计最优准确性。
### Conclusion
文章提出的方法通过黎曼几何优化技术有效解决了K-均值问题的二阶临界点计算问题，显著提高了算法的收敛速度，并且在实验中表现出了更高的效率和准确性。
## 1090. `cs.LG` - DriftLite：轻量级漂移控制以实现扩散模型推理时缩放 [PDF](https://arxiv.org/pdf/2509.21655), [HTML](https://arxiv.org/abs/2509.21655)
### Authors
Yinuo Ren,Wenhao Gao,Lexing Ying,Grant M. Rotskoff,Jiequn Han
### Background
本研究探讨了扩散模型推理时的缩放问题，目标是在无需重新训练的情况下适应新的目标分布。当前的指导方法虽然简单但会引入偏差，而基于粒子的校正方法则面临着权重退化和高计算成本的问题。这篇论文提出了一种名为DriftLite的轻量级、无需训练的方法，能够在推理过程中实时控制漂移，具有理论上最优的稳定性控制。DriftLite利用Fokker-Planck方程中漂移和粒子势能之间的未被利用的自由度，提供了两种实际的实现：方差控制和能量控制指导（VCG和ECG），用于近似最优漂移，同时最小化开销。
### Innovation
提出了一种名为DriftLite的轻量级、无需训练的方法，能够在推理过程中实时控制漂移，具有理论上最优的稳定性控制。通过Fokker-Planck方程中漂移和粒子势能之间的自由度创新利用，DriftLite提供了两种实际的实现：方差控制和能量控制指导（VCG和ECG），用于近似最优漂移，同时最小化开销。
### Conclusion
在高斯混合模型、粒子系统和大规模蛋白质-配体共折叠问题上，DriftLite在样本质量和方差方面始终优于纯指导和顺序蒙特卡洛基线方法。这些结果强调了一条先验良好的、高效的途径，用于可扩展的扩散模型推理时的适配。
## 1091. `cs.LG` - 限制安全、可信的人工通用智能 [PDF](https://arxiv.org/pdf/2509.21654), [HTML](https://arxiv.org/abs/2509.21654)
### Authors
Rina Panigrahy,Vatsal Sharan
### Background
在人工智能（AI）系统中，安全、信任与人工通用智能（AGI）是极具理想化的目标。尽管对这些概念已有许多非正式的解释，但本研究致力于提出严格且数学化的定义，并揭示了它们之间的根本性不兼容性。作者将系统的安全性定义为从不做出任何虚假声明的性质，将信任定义为假设系统是安全的条件，AGI则定义为AI系统始终能够匹配或超越人类能力的特性。研究表明，对于这些严格数学定义的概念，一个安全且可信赖的AI系统无法同时具备AGI属性：即使这样安全且可信的系统也无法解决某些人易于解决但系统却无法解决的任务实例。文中指出，这里的定义是严格的数学定义，实际部署时可能会依赖其他实用的定义。证明也涉及到了哥德尔不完全性定理和图灵停机问题不可判定性的证明，是哥德尔和图灵结果的另一种诠释。
### Innovation
本文提出了严格和数学化的安全、信任和AGI的定义，并揭示了它们之间的内在不兼容性。这种不兼容性表明，对于严格的数学定义，一个安全且可信赖的AI系统无法成为AGI系统：在这种安全且可信赖的系统中，存在即使人类可以轻易解决但机器却无法解决的任务实例。研究还指出，这些证明与哥德尔不完全性定理和图灵停机问题不可判定性定理有相似之处。
### Conclusion
安全、可信的AI系统不能同时具备AGI属性。存在某些即使人类可以轻易解决但机器却无法解决的任务实例，这是因为科研人员严格地定义了这些概念并展示了它们之间的内在不兼容性。研究还涉及到哥德尔不完全性定理和图灵停机问题，这种结论可以被视为对哥德尔和图灵研究成果的解释。
## 1092. `cs.LG` - Wav2Arrest 2.0：基于时间事件建模、身份不变性和伪生化对齐的长周期心脏停搏预测 [PDF](https://arxiv.org/pdf/2509.21695), [HTML](https://arxiv.org/abs/2509.21695)
### Authors
Saurabh Kataria,Davood Fattahi,Minxiao Wang,Ran Xiao,Matthew Clark,Timothy Ruchti,Mark Mai,Xiao Hu
### Background
高频率生理波形模态可以提供患者状态的深入、实时见解。基于光电容积描记法（PPG）的生理模型，如PPG-GPT，能够预测关键事件，包括心脏骤停（CA）。然而，这些模型强大的表示能力在有限的下游数据/标签情况下仍未被有效利用。
### Innovation
本文提出了一种使用少量辅助信息改进仅PPG的心脏骤停系统的三个独立试验改进。第一，提出使用时间至事件建模，方法包括简单回归事件开始时间或精细离散生存建模。第二，鼓励模型学习心脏骤停焦点特征，通过使其患者身份不变来实现这一目标。第三，提出了基于预训练辅助估计网络生成的伪标签值的回归预测。此外，通过多任务形式处理并降低竞争损失间的高梯度冲突率，利用PCGrad优化技术来缓解。
### Conclusion
通过上述改进，24小时内时间平均AUC从0.74提升到0.78-0.80范围。这种方法在较长的时间尺度上提高了心脏骤停预测，从而推动了早期预警系统的研究。
## 1093. `cs.LG` - MMPlanner: 零样本的链式思考物体状态推理驱动的多模态程序规划 [PDF](https://arxiv.org/pdf/2509.21662), [HTML](https://arxiv.org/abs/2509.21662)
### Authors
Afrina Tabassum,Bin Guo,Xiyao Ma,Hoda Eldardiry,Ismini Lourentzou
### Background
多模态程序规划（MPP）旨在生成结合文字和图像的分步指令，核心挑战在于在生成信息性规划的同时保持多模态之间的物体状态一致性。现有的方法通常利用大规模语言模型（LLMs）细化文本步骤，而物体状态的视觉对齐和系统的评估很少被探索。MMPlanner框架通过引入物体状态推理链式思考（OSR-CoT）提示，明确建模物体状态转换，能够生成准确的多模态计划。为了评估规划质量，设计了LLM作为裁判的规划精准性和跨模态对齐评估协议，并提出了视觉步骤重排序任务来衡量时间连贯性。
### Innovation
MMPlanner框架通过引入OSR-CoT提示，明确建模物体状态转换，相较于现有的利用LLMs细化文本步骤的方法，更加关注视觉物体状态对齐和系统的评估。此外，提出了LLM作为裁判的评估协议和视觉步骤重排序任务来衡量时间连贯性，这是该领域的创新之处。
### Conclusion
在RECIPEPLAN和WIKIPLAN上的实验表明，MMPlanner在文本规划、跨模态对齐和视觉步骤排序上分别取得了+6.8%、+11.9%和+26.7%的性能提升，达到了最先进的技术水平。
## 1094. `cs.LG` - SpecMER：使用k-mer引导的推测性解码快速蛋白质生成 [PDF](https://arxiv.org/pdf/2509.21689), [HTML](https://arxiv.org/abs/2509.21689)
### Authors
Thomas Walton,Darin Tsui,Aryan Musharaf,Amirali Aghazadeh
### Background
自回归模型通过生成超越自然界发现的新型蛋白质序列而革新了蛋白质工程。然而，它们的顺序推理引入了显著的延迟，限制了其在高通量蛋白质筛选中的应用。推测性解码通过使用轻量级草案模型来抽样令牌，由较大的目标模型进行验证和细化，以加速生成过程。但是在蛋白质序列生成过程中，草案模型通常不对目标蛋白质的结构和功能性约束具有感知，导致产生生物上不合理的输出，并改变生成序列的可能性分布。
### Innovation
引入了SpecMER（Speculative Decoding via k-mer Guidance），这是一个新的框架，通过从多序列比对中提取k-mer模式来整合生物学、结构和功能性先验。通过并行评分候选序列并选择最符合已知生物学模式的序列，SpecMER显著提高了序列的合理性并保持了推测性解码的效率。SpecMER实现了24-32%的标准自回归解码速度提升，同时提高了接受率和序列的可能性。
### Conclusion
SpecMER通过使用k-mer引导的推测性解码提升了蛋白质生成的速度和效率，同时保证了生成序列的生物合理性，为高通量蛋白质筛选提供了有效工具。
## 1095. `cs.LG` - Neuroprobe：评估自然刺激下颅内脑响应 [PDF](https://arxiv.org/pdf/2509.21671), [HTML](https://arxiv.org/abs/2509.21671)
### Authors
Andrii Zahorodnii,Christopher Wang,Bennett Stankovits,Charikleia Moraitaki,Geeling Chau,Andrei Barbu,Boris Katz,Ila R Fiete
### Background
高分辨率神经数据集促进了下一代脑-机接口和神经治疗的基础模型的发展。社区需要严格的基准测试来区分竞争的建模方法，但目前没有标准化的评估框架。现有的颅内电极图（iEEG）记录没有合适的评估工具，为此，我们引入了Neuroprobe，用于研究多模态语言处理在大脑中的过程。
### Innovation
Neuroprobe 是一个评估颅内电极图（iEEG）记录的工具，基于 BrainTreebank 数据集，包含 40 小时 10 个受试者在观看真实电影时的 iEEG 记录。通过此工具，研究人员可以高时间分辨率和空间分辨率测度每个语言处理方面的大脑计算何时何地进行，并通过数据驱动的方式展示信息如何从颞上回流动到前额叶皮层。此外，Neuroprobe 提供了一个严谨的框架来比较竞争的架构和训练协议，表明线性模型在许多任务中表现意外地好。
### Conclusion
Neuroprobe 旨在通过高效且易于使用的设计，加速颅内电极图（iEEG）基础模型的发展，并公开了代码和维护公共排行榜，促进了该领域快速进步。
## 1096. `cs.LG` - PQFed: 一种隐私保护的质量控制联邦学习框架 [PDF](https://arxiv.org/pdf/2509.21704), [HTML](https://arxiv.org/abs/2509.21704)
### Authors
Weiqi Yue,Wenbiao Li,Yuzhou Jiang,Anisa Halimi,Roger French,Erman Ayday
### Background
联邦学习允许在不共享原始数据的情况下进行合作模型训练，但数据异质性始终困扰着全局模型的性能。传统优化方法通常依赖于涉及所有客户端的协作全局模型训练，之后通过局部适应来改善个体性能。
### Innovation
提出了一种新颖的隐私保护个性化联邦学习框架PQFed，该框架在联邦训练过程之前为每个客户端设计了定制化的训练策略。PQFed从每个客户端的原始数据中提取特征，并应用聚类技术估计客户端间数据集的相似性。基于这些相似性估计，框架实现了一个客户端选择策略，从而使每个客户端能够与具有兼容数据分布的其他客户端合作。
### Conclusion
实验结果表明，即使只有少量参与者，PQFed也能够持续改善目标客户端的模型性能。进一步与基于聚类的基准算法IFCA进行基准测试，发现PQFed在低参与度场景中也表现出更好的性能。这些发现突显了PQFed在个性化联邦学习环境中的可扩展性和有效性。
## 1097. `cs.LG` - 利用线性动态系统统一串行模型并行化框架 [PDF](https://arxiv.org/pdf/2509.21716), [HTML](https://arxiv.org/abs/2509.21716)
### Authors
Xavier Gonzalez,E. Kelly Buchanan,Hyun Dong Lee,Jerry Weihong Liu,Ke Alexander Wang,David M. Zoltowski,Christopher Ré,Scott W. Linderman
### Background
现代机器学习中的一个核心挑战是如何在看似串行的模型中利用并行性。已经提出了利用固定点方法（如Newton、Picard和Jacobi迭代）评估串行过程的技术，但这些方法很难被统一理解。
### Innovation
提出了一个将这些不同的固定点方法视为基于线性动态系统（LDS）的非线性递归的近似线性化的新框架。这一统一的观点阐明了这些技术背后的共同原则，并明确指出了哪些固定点方法最有可能有效。通过使用LDS的语言将不同的算法联系起来，该框架为串行模型的并行化提供了更清晰的理论基础，并指出了高效和可扩展计算的新机会。
### Conclusion
该工作揭示了固定点方法可以被认为是基于LDS的非线性递归的近似线性化，并通过LDS的语言统一了这些不同的算法。这一洞见为并行计算的理论基础提供了新视角，并提供了高效和可扩展计算的新机遇。
## 1098. `cs.LG` - DIM: 在深度神经网络中实施具领域信息的单调性约束 [PDF](https://arxiv.org/pdf/2509.21666), [HTML](https://arxiv.org/abs/2509.21666)
### Authors
Joshua Salim,Jordan Yu,Xilei Zhao
### Background
深度学习模型在预测任务中表现出色，但由于其复杂的结构和大量的参数，容易过拟合，即模型会记住训练数据中的噪声而不是学习能够泛化的模式。为解决这一挑战，本文提出了一种新的正则化方法——在深度神经网络中实施具领域信息的单调性约束（DIM），该方法通过保持域信息的单调关系，进一步提高预测性能。具体而言，该方法通过相对线性基准惩罚单调性违反来约束模型，有效地促使模型遵循预期趋势，同时保持其预测能力。这种做法通过一个全面的数学框架加以形式化，该框架建立一个线性参考基准，衡量偏离单调性行为的程度，并将这些度量结果整合到训练目标中。通过使用芝加哥的实时叫车数据集和一个合成数据集进行测试和验证，实验表明，即使是非常微小的单调性约束也能一致地提高模型性能。DIM通过将域信息的单调性约束应用于模型行为的正则化，提升了深度神经网络的预测性能，并减轻了过拟合现象，验证了这种方法的有效性。
### Innovation
本文提出了在深度神经网络中实施具领域信息的单调性约束（DIM）的新正则化方法。该方法通过相对线性基准惩罚单调性违反来约束模型，促使模型遵循预期趋势，同时保持其预测能力。这种方法通过一个完整的数学框架进行形式化，包括建立线性参考基准、衡量偏离单调性行为的程度，并将这些度量结果整合到训练目标中。
### Conclusion
实验结果表明，即使是微小的单调性约束也能显著提升多种神经网络架构下的模型性能。DIM通过在模型中实施域信息的单调性约束，有效改善了深度神经网络的预测性能，并通过减轻模型过拟合现象，验证了该方法的有效性。
## 1099. `cs.LG` - Prophecy: 从神经元激活推断形式化属性 [PDF](https://arxiv.org/pdf/2509.21677), [HTML](https://arxiv.org/abs/2509.21677)
### Authors
Divya Gopinath,Corina S. Pasareanu,Muhammad Usman
### Background
现有的前馈神经网络通常缺乏清晰的逻辑解释，这使得理解和验证其行为变得困难。本文介绍了Prophecy工具，该工具能够自动推断前馈神经网络的形式化属性，着重于内层神经元的激活状态来捕捉前馈网络的主要逻辑部分。
### Innovation
Prophecy通过提取基于神经元激活（值或开/关状态）的规则，作为预条件，以推断特定的期望输出属性，如预测为特定类别。这种规则代表了隐层中捕捉到的网络属性，这些属性推断出所需的输出行为。Prophecy展示了其架构、特点，并在不同类型的模型和输出属性上进行了演示，还展示了其在大型视觉语言模型时代的潜在应用，包括形式化解释、组合验证、运行时监控、修复等，为理解复杂的神经网络行为提供了新颖的方法和工具。
### Conclusion
Prophecy工具成功地展示出了其在自动推断前馈神经网络形式化属性方面的能力，并且具有广泛的应用前景，特别是在大模型时代。
## 1100. `cs.LG` - 基于SDE的纵向脑网络深度学习的空间－时间图神经网络方法揭示阿尔茨海默病进展 [PDF](https://arxiv.org/pdf/2509.21735), [HTML](https://arxiv.org/abs/2509.21735)
### Authors
Houliang Zhou,Rong Zhou,Yangying Liu,Kanhao Zhao,Li Shen,Brian Y. Chen,Yu Zhang,Lifang He,Alzheimer's Disease Neuroimaging Initiative
### Background
识别客观的神经影像学生物标志物以预测阿尔茨海默病（AD）的进展对于及时干预至关重要。现有方法往往忽略了脑网络中时空特征的复杂功能障碍，这使得预测未来AD进展具有挑战性。
### Innovation
本文开发了一种可解释的空间－时间图神经网络框架，利用双Stochastic Differential Equations (SDEs)来建模不规则采样的纵向功能性磁共振成像(fMRI)数据。该框架能够学习稀疏的区域和连接的重要性概率，识别与疾病进展相关的关键脑回路异常。通过这个策略，我们发现了与AD进展相关的新型神经系统水平和性别特定生物标志物。
### Conclusion
我们的研究强调了基于空间－时间图的深度学习方法在预测AD进展中的潜力，特别是在纵向影像数据不规则采样的情况下。这种方法揭示了关键的脑区，如枕海马皮质、前额叶皮质和顶叶，并发现了AD相关的临床症状与纵向AD进展之间的强烈关联。
## 1101. `cs.LG` - 信息论引导的 bilevel 优化的贝叶斯优化方法 [PDF](https://arxiv.org/pdf/2509.21725), [HTML](https://arxiv.org/abs/2509.21725)
### Authors
Takuya Kanayama,Yuki Ito,Tomoyuki Tamura,Masayuki Karasuyama
### Background
回归到复杂且未广泛研究的 bilevel 优化结构，特别是当上下层都涉及昂贵的黑盒函数时，现有的贝叶斯优化(Bayesian Optimization, BO)方法未能充分处理此类问题。bilevel 优化因其嵌套结构，使得问题定义复杂，且与多目标或约束设置等标准扩展方法相比，尚未得到广泛研究。
### Innovation
提出了一种信息论方法，该方法同时考虑上下层最优解和值的信息增益，从而定义了一个统一的评估标准，用于同时衡量两个层次问题的利益。此外，还提出了一种实践中的下界方法，用于评估信息增益的知识实用性。
### Conclusion
通过多个基准数据集的经验验证，展示了所提出方法的有效性。
## 1102. `cs.LG` - 精确子图同构网络在预测图挖掘中的应用 [PDF](https://arxiv.org/pdf/2509.21699), [HTML](https://arxiv.org/abs/2509.21699)
### Authors
Taiga Kojima,Masayuki Karasuyama
### Background
在图级别的预测任务中，输入图中的子图所包含的信息发挥着关键作用。构建一个既能实现高判别能力又有解释性的图级别预测模型仍然是一项具有挑战性的问题。EIN结合了精确的子图枚举、神经网络和稀疏正则化，以提高子图结构的判别能力，并通过稀疏正则化提供了有效的剪枝策略来减轻枚举的计算难度同时保持预测性能，还能够识别出重要子图以提高模型的可解释性，展现了与标准图神经网络模型相当的预测性能，并通过选择的子图进行了后验分析的示例展示。
### Innovation
EIN整合了精确子图枚举、神经网络和稀疏正则化。通过对子图进行精确枚举，它提高了输入图的子图结构的判别能力；稀疏正则化不仅提供了一个有效的剪枝策略来降低枚举的计算难度，保持预测性能，还能够识别出重要子图来增强模型的可解释性。实验结果表明，EIN在预测性能上与传统的图神经网络模型相当，并展示了基于选中子图的后验分析实例。
### Conclusion
我们通过EIN集成子图枚举和神经网络的方法，提高了模型的判别能力并增强了可解释性。实验证明了EIN具有足够的预测性能，同时通过被选中的子图进行了后验分析的示例展示。
## 1103. `cs.LG` - 机器学习和AI应用于fNIRS数据揭示稳定亚临床多发性硬化症的新型脑活动生物标志物 [PDF](https://arxiv.org/pdf/2509.21770), [HTML](https://arxiv.org/abs/2509.21770)
### Authors
Sadman Saumik Islam,Bruna Dalcin Baldasso,Davide Cattaneo,Xianta Jiang,Michelle Ploughman
### Background
多发性硬化症（MS）患者常报告手灵活性差和认知疲劳的问题，但许多情况下，这些症状较为隐蔽，难以检测。功能性近红外光谱成像（fNIRS）是一种非侵入性的神经成像技术，可用于测量执行认知或运动任务时的大脑血流动力学反应。本研究旨在通过分析fNIRS数据检测与主观认知疲劳报告相关的脑活动生物标志物，以期为未来的大脑刺激治疗提供目标。
### Innovation
利用机器学习框架分析fNIRS数据，区分MS患者与对照组，揭示在非侵入性条件下可解释认知疲劳的手工灵活性任务中的大脑激活模式。通过XAI方法，发现重要脑区包括同侧顶下沟/角回和前中央沟（感觉整合和运动区域），MS组在这些区域表现出活动抑制和神经血管反应减缓。去氧血红蛋白水平比传统测量的氧合血红蛋白更适合预测结果，这种方法为未来的个性化大脑刺激目标提供了新的生物标志物。
### Conclusion
本研究通过机器学习和人工智能技术，结合fNIRS数据分析，成功揭示了稳定亚临床多发性硬化症患者的新型脑活动生物标志物，这为进一步的个性化大脑刺激治疗提供了科学依据。
## 1104. `cs.LG` - 超越公式的复杂性：有效信息准则提升符号回归性能和可解释性 [PDF](https://arxiv.org/pdf/2509.21780), [HTML](https://arxiv.org/abs/2509.21780)
### Authors
Zihan Yu,Guanren Wang,Jingtao Ding,Huandong Wang,Yong Li
### Background
符号回归能够发现精确且可解释的公式，为领域专家提供科学洞察并推动科学发现。然而，现有符号回归方法通常使用复杂度指标作为互操作性的代理，仅考虑公式大小而不考虑其内部数学结构。因此，尽管这些方法可以发现简洁的公式，但发现的公式结构往往难以分析或解释。
### Innovation
本文受到物理公式在有限计算精度下通常具有数值稳定性的观察启发，提出有效信息准则（EIC）。EIC将公式视为具有特定内部结构的信息处理系统，并通过数据流经系统时重要位数的损失或舍入噪声放大的现象来识别不合理结构。EIC揭示了现有符号回归算法发现的模型结构与实际物理公式之间的差距。将EIC与不同的基于搜索的符号回归算法结合使用，提高了它们在帕累托前沿上的性能并减少了结果中的不合理结构。将EIC与生成型算法结合使用，可以减少预训练所需的样本数量，提高样本效率2至4倍。对于具有相似准确性和复杂性的不同公式，EIC与108位人工专家对公式的可解释性偏好一致度达到70.2%，表明EIC通过测量公式中的不合理结构实际上反映了公式的可解释性。
### Conclusion
EIC通过测量公式中的不合理结构，实际上反映出了公式的可解释性，并在符号回归算法中引入EIC能够提高性能和可解释性。
## 1105. `cs.LG` - POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization [PDF](https://arxiv.org/pdf/2509.21737), [HTML](https://arxiv.org/abs/2509.21737)
### Authors
Ziqing Wang,Yibo Wen,William Pattie,Xiao Luo,Weimin Wu,Jerry Yao-Chieh Hu,Abhishek Pandey,Han Liu,Kaize Ding
### Background
药物发现中的先导化合物优化需要通过迭代循环高效地在庞大的化学空间中导航，以提升分子性质同时保持结构与原始先导化合物的一致性。尽管近年来取得了进展，传统的优化方法在样本效率方面仍存在局限性，即在有限的专家评估下难以获得良好的优化性能。
### Innovation
POLO方法通过引入偏好导向的多轮优化策略，使大型语言模型能够学习完整的优化轨迹而非独立的步骤。核心贡献是偏好导向的策略优化（PGPO）算法，该算法在轨迹层面和回合层面分别进行学习，利用中间评价实现双层学习，从而提高样本效率。
### Conclusion
广泛的实验证明，POLO方法在单一性质任务中的平均成功率达到了84%（比基线效果提升了2.3倍），在多性质任务中仅使用500次专家评估就达到了50%的成功率，显著推进了样本高效分子优化的技术前沿。
## 1106. `cs.LG` - ChaosNexus：具有多尺度表示的通用混沌系统预测的基础模型 [PDF](https://arxiv.org/pdf/2509.21802), [HTML](https://arxiv.org/abs/2509.21802)
### Authors
Chang Liu,Bohao Zhao,Jingtao Ding,Yong Li
### Background
准确预测混沌系统（如气象预测和流体力学领域）依然是一个重大的科学挑战。这些系统的初值高度敏感性以及观测数据的稀缺性限制了传统建模方法的应用。由于这些模型通常针对特定系统进行训练，缺乏针对新场景或数据有限场景的泛化能力，这恰恰是实际应用所需的能力。
### Innovation
本文提出了ChaosNexus，一种预训练在多元混沌动力学上的基础模型。它采用了新的多尺度架构ScaleFormer以及混合专家层，以捕捉通用模式和特定行为。该模型在合成和真实世界基准测试中均展示了最先进的零样本泛化能力。在包含超过9,000个合成混沌系统的大型测试平台中，与顶尖基线相比，ChaosNexus长期吸引子统计的准确度提高了40%以上。此外，ChaosNexus在实际应用中的高效和鲁棒性突出，如5天全球气象预测中实现竞争力的零样本均误差低于1度，通过少量样本微调进一步提高。研究结果表明，从训练系统多样性而非单纯数据量中获得跨系统的泛化能力。
### Conclusion
ChaosNexus提供了指导科学基础模型的新原则，即跨系统泛化来自于多样性训练系统，而不是单纯的数据量。
## 1107. `cs.LG` - 脑病态图学习 [PDF](https://arxiv.org/pdf/2509.21742), [HTML](https://arxiv.org/abs/2509.21742)
### Authors
Ciyuan Peng,Nguyen Linh Dan Le,Shan Jin,Dexuan Ding,Shuo Yu,Feng Xia
### Background
脑图学习已经在神经科学和人工智能领域取得了显著成就。但现有方法难以选择性地学习与疾病相关的知识，导致了参数的厚重和高昂的计算成本，这降低了其效率，并限制了其在实际临床应用中的实用性。现有的方法在处理脑部疾病检测任务时，需要更多的训练时间和更高的内存需求，从而影响了它们的实际应用价值。
### Innovation
本文提出了一个轻量化的脑病态图学习（BrainPoG）模型，通过对病理模式筛选和病理特征提炼的方法，提高了脑图学习的效率。具体来说，BrainPoG首先通过提取与高度相关疾病的子图来创建病态模式，实现了图形修剪和病变定位。随后，设计了一个病态特征提炼模块，消除无关特征噪声，增强PathoGraph中每个节点的病理特征。BrainPoG能够仅学习对疾病有信息价值的知识，避免无关信息，从而实现高效的脑图学习。该模型在四个基准数据集上的实验表明，无论是模型性能还是计算效率，BrainPoG都优于现有方法，在多种脑部疾病检测任务中具有优越性。
### Conclusion
本文提出了一种轻量化的脑病态图学习（BrainPoG）模型，能够高效地学习与脑部疾病相关的病态知识，减少了不必要的信息，提升了模型的性能和计算效率，特别是在疾病检测任务中表现优异。
## 1108. `cs.LG` - 基于可解释机器学习方法的人口流动数据向下放缩 [PDF](https://arxiv.org/pdf/2509.21703), [HTML](https://arxiv.org/abs/2509.21703)
### Authors
Yuqin Jiang,Andrey A. Popov,Tianle Duan,Qingchun Li
### Background
理解不同空间尺度上的城市人口流动性模式对于社会科学至关重要。本文研究目的在于利用机器学习方法将纽约市大尺度上的起讫点出租车出行流量数据细化到小尺度上。研究首先分别用线性回归（LR）、随机森林（RF）、支持向量机（SVM）和神经网络（NN）四种模型构建起讫点OD出行与人口、经济和社会特征之间的相关关系。接着，通过扰动法敏感性分析来解释非线性模型中的变量重要性。结果显示线性回归模型未能捕捉复杂变量之间的交互关系。而在训练和测试数据集上的表现最为出色的NN模型，在细化性能上具有最好的泛化能力。基于此研究方法提出了改进城市交通服务和城市发展方面的分析与实际应用。
### Innovation
首次引入线性回归、随机森林、支持向量机和神经网络四种机器学习模型来挖掘人口、经济和社会特征与OD出行之间的复杂关系，并通过扰动法敏感性分析解释非线性模型变量的重要性。此外，研究发现神经网络模型在训练和测试数据集上表现出最佳性能，而支持向量机则展示了最好的泛化能力。
### Conclusion
提出的机器学习方法不仅在分析上有所进步，还能应用于提升城市交通服务和促进城市发展。
## 1109. `cs.LG` - 使用神经域重新参数化4DVAR [PDF](https://arxiv.org/pdf/2509.21751), [HTML](https://arxiv.org/abs/2509.21751)
### Authors
Jaemin Oh
### Background
四维变分数据同化（4DVAR）是数值天气预报的核心，但其成本函数难以优化且计算量大。4DVAR的传统方法依赖时间序列依赖性，优化计算效率低下，且实施复杂。
### Innovation
提出了一种基于神经域的重新参数化方法，将全空间时间状态表示为由神经网络参数化的连续函数，消除了经典4DVAR的时间序列依赖性，实现了并行时间优化。通过将物理约束直接整合到物理感知的损失中，简化了实现过程并减少了计算成本。
### Conclusion
该方法在无旋二维纳维-斯托克斯方程（Kolmogorov扰动）上进行评估，神经重新参数化版本相比经典4DVAR具有更稳定的初始条件估计且没有虚假振荡。由于本框架无需访问真实状态或重分析数据，提高了在参考信息有限情况下的适用性。
## 1110. `cs.LG` - HyperCore: 基于超球模型的噪声环境下的核心子集选择 [PDF](https://arxiv.org/pdf/2509.21746), [HTML](https://arxiv.org/abs/2509.21746)
### Authors
Brian B. Moser,Arundhati S. Shanbhag,Tobias C. Nauen,Stanislav Frolov,Federico Raue,Joachim Folz,Andreas Dengel
### Background
现有的核心子集选择方法旨在识别数据集中的代表性子集以提高模型训练效率，但这些方法往往忽略了标注错误的可能性，并且需要固定的剪枝比例，使得它们在实际应用场景中不够实用。因此，本文旨在提出一种鲁棒且自适应的核心子集选择框架HyperCore，专门针对噪声环境进行设计。HyperCore利用了轻量级的超球模型来根据类内样本与超球中心的距离划分样本，并自动地基于距离将类外样本分离，从而实现无超参数调整的自适应噪声识别和数据剪枝功能。实验结果表明，HyperCore在噪声和低数据环境下显著优于现有核心子集选择方法，能够有效剔除错误标注和模棱两可的样本，生成高效且高度信息丰富的数据子集，适合可扩展和无噪声的学习过程。
### Innovation
HyperCore通过引入轻量级的超球模型，提出了一个鲁棒且自适应的核心子集选择框架，该框架能够在噪声环境中自动适应性地选择剪枝阈值，而无需进行超参数调整。此外，它能够适应性地丢弃错误标签和模棱两可的样本，生成紧凑且信息丰富的数据子集。
### Conclusion
实验结果证明，HyperCore在噪声和低数据环境中超越了现有的核心子集选择方法，能够识别并丢弃错误标签和模棱两可的样本，生成一个高效且高度信息丰富的数据子集，适用于可扩展和无噪声的学习过程。
## 1111. `cs.LG` - SubZeroCore: 一种零训练的子集选择子模方法 [PDF](https://arxiv.org/pdf/2509.21748), [HTML](https://arxiv.org/abs/2509.21748)
### Authors
Brian B. Moser,Tobias C. Nauen,Arundhati S. Shanbhag,Federico Raue,Stanislav Frolov,Joachim Folz,Andreas Dengel
### Background
核心集（coreset）选择的目标是在模型训练中有效地识别数据集的代表性子集。然而，现有的方法需要通过整个数据集来计算昂贵的基于训练的信号（如梯度、决策边界估计或遗忘计数）来确定这些子集，这与它们降低训练负担的目的相矛盾，因为它们实际上需要对要避免的样本进行训练。因此，现有的方法存在自相矛盾的问题，使得它们无法实现预期的高效训练目标。因此，需要一种不需要训练过程的新型核心集选择方法，能够在不依赖训练信号的情况下高效地进行样本选择。SubZeroCore正是基于这一需求提出的，它结合了子模覆盖和密度，引入了一种采样策略，以实现这两个目标的最优平衡，并且只需一个超参数即可明确控制所需的局部密度度量所需覆盖范围。
### Innovation
SubZeroCore 是一种新型的核心集选择方法，它完全摆脱了对训练过程的依赖，通过结合子模覆盖和密度来实现单一统一的目标，并提出了一种基于闭式解的优化策略来平衡这两个目标，而且只需一个单一的超参数来明确控制局部密度度量所需的覆盖范围。此外，SubZeroCore 在广泛的实验中显示了与基于训练的方法相当的表现，并在高剪枝率下显著优于后者，同时大幅降低了计算负担。该方法还证明了对标签噪声具有更好的鲁棒性，这进一步证明了其实用效果和可扩展性，适用于实际应用场景。
### Conclusion
尽管没有进行训练，但广泛评估表明，SubZeroCore 在保持与基于训练的方法相当性能的同时，在高剪枝率下能够显著超越后者，并且极大地减少了计算成本。此外，SubZeroCore 还展现了对标签噪声的优越鲁棒性，这显示了其在实际应用中的有效性和可扩展性。
## 1112. `cs.LG` - Graph of Agents: 基于 emergent 多代理协作的原理性长上下文建模 [PDF](https://arxiv.org/pdf/2509.21848), [HTML](https://arxiv.org/abs/2509.21848)
### Authors
Taejong Joo,Shu Ishida,Ivan Sosnovik,Bryan Lim,Sahand Rezaei-Shoshtari,Adam Gaier,Robert Giaquinto
### Background
作为对大型语言模型的上下文窗口限制的一种模型无偏的方法，多代理系统能够在无需重新训练或架构修改的情况下处理长度超过原始上下文窗口的输入。然而，他们的性能很大程度上依赖于手工构建的多代理协作策略和提示工程，这限制了其泛化能力。
### Innovation
介绍了一种原理性的框架，将其建模为压缩问题，得到信息论的压缩目标。基于此框架，提出了一个名为 Graph of Agents (GoA) 的方法，它动态地构建一个基于输入的数据依赖性的合作结构，该结构最大化的压缩目标。GoA 在 Llama 3.1 8B 和 Qwen3 8B 上改进了抽取增强生成的平均 F1 分数，并且与固定合作结构的强多代理基线相比提高了 16.35%。即使在只有 2K 上下文窗口的情况下，GoA 也在 LongBench 上超越了 128K 上下文窗口的 Llama 3.1 8B，显示了极大的有效上下文长度提升。
### Conclusion
GoA 在多个文本文档问答基准测试中表现出色，不仅提高了基于检索增强生成的性能，还突破了模型上下文窗口长度的限制。
## 1113. `cs.LG` - FastGRPO: 通过并发感知投机解码和在线草案学习加速策略优化 [PDF](https://arxiv.org/pdf/2509.21792), [HTML](https://arxiv.org/abs/2509.21792)
### Authors
Yizhou Zhang,Ning Lv,Teng Wang,Jisheng Dang
### Background
集团公司相对策略优化（GRPO）展示了通过强化学习提高大型语言模型（LLMs）推理能力的巨大潜力，但其实际部署受限于过慢的训练过程，主要原因是自回归生成多个响应的计算密集型操作，使得生成阶段成为主要的性能瓶颈。虽然推测性解码在加速方面显示了前景，但在高并发训练条件下直接应用GRPO仅能达到有限的加速效果。
### Innovation
本文提出了一种并发感知推测性解码框架，能够根据实时的并发水平动态调整草稿和验证策略，从而最大化生成过程的加速效果。此外，为了解决训练过程中目标模型和固定草稿模型之间分布漂移导致的性能下降问题，引入了一种在线草稿学习机制，使草稿模型能够不断适应并利用目标模型的反馈信号。实验结果表明，该方法在多个数学推理数据集和模型上实现了2.35至2.72倍的端到端加速，远超基线方法。
### Conclusion
实验结果显示，本文提出的FastGRPO方法在数学推理数据集和模型上实现了显著的加速效果，提高了训练效率，并进一步验证了该方法的有效性和优越性。
## 1114. `cs.LG` - Sharpness-Aware Minimization Can Hallucinate Minimizers [PDF](https://arxiv.org/pdf/2509.21818), [HTML](https://arxiv.org/abs/2509.21818)
### Authors
Chanwoong Park,Uijeong Jang,Ernest K. Ryu,Insoon Yang
### Background
Sharpness-Aware Minimization (SAM) 作为一种广泛应用的方法，旨在引导训练向平坦度较高的极小值靠拢，而这些极小值通常具有更好的泛化性能。然而，本文指出了SAM的一个潜在问题，即模型可能会收敛到虚构的极小值点，而这些点并不是原始目标函数的极小值点。研究人员理论证明了这种虚构极小值的存在，并建立了局部收敛到这些点的条件，还通过实验证据证实了这个现象的真实性，最后提出了一种简单有效的对策来避免这些虚假极小值点的出现。
### Innovation
论文的主要创新点在于揭示了SAM的新颖特性，即其可能会收敛到虚构的极小值点，并且给出了理论上的证明及具体的收敛条件。此外，作者还提供了实验证据支持这一结论，并提出了一种有效的避免机制，这些都体现出该研究的创新之处。
### Conclusion
论文最终提出了一种简单有效的方法来避免虚构极小值点，从而防止SAM收敛到这些点上，这一方法在实践中显示出良好的效果。
## 1115. `cs.LG` - 在自动疲劳检测过程中生理信号之间关系的探索 [PDF](https://arxiv.org/pdf/2509.21794), [HTML](https://arxiv.org/abs/2509.21794)
### Authors
Kourosh Kakhi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharyab
### Background
疲劳检测利用生理信号在运输、医疗保健和工作效率监测等领域至关重要。大多数研究集中在单一模态上，而本研究则探讨了信号对之间的统计关系，以提高分类的稳健性。使用DROZY数据集，从心电图（ECG）、肌电图（EMG）、眼动电图（EOG）和脑电图（EEG）中提取了15种信号组合的特征，并使用决策树、随机森林、逻辑回归和XGBoost进行了评估。结果显示，使用EMG和EEG组合的XGBoost模型表现最佳。SHAP分析指出ECG和EOG的相关性为主要特征，多信号模型在整体上优于单一信号模型。这些发现表明，生理信号在特征级上的融合能够提高疲劳监测系统的准确度、可解释性和实际应用价值。
### Innovation
研究探讨了生理信号对之间的统计关系以改善分类的稳健性；使用DROZY数据集从多种生理信号中提取特征并进行综合分析；通过比较不同机器学习模型的性能展示了多信号模型的优势及ECG和EOG相关性的关键作用。
### Conclusion
特征级别的生理信号融合增强了疲劳监测系统的准确度、解释性和实用性；多信号模型优于单一信号模型；ECG和EOG之间的相关性是关键特征。
## 1116. `cs.LG` - 关于掩盖离散扩散的复杂性理论：从$boldsymbol{text{poly}(1/ε)}$到几乎$boldsymbol{ε}$-自由 [PDF](https://arxiv.org/pdf/2509.21835), [HTML](https://arxiv.org/abs/2509.21835)
### Authors
Xunpeng Huang,Yingyu Lin,Nishant Jain,Kaibo Wang,Difan Zou,Yian Ma,Tong Zhang
### Background
我们研究了掩盖离散扩散——一种逐步用特殊遮罩符号损坏tokens然后进行去噪的文本生成灵活范式。尽管这种方法在实验性能上表现出色，但在高维设置下的理论复杂性尚未得到充分理解。现有的分析集中在均匀离散扩散上，而最近针对掩盖扩散的尝试要么忽略了广泛应用的欧拉采样器，要么施加了严格的有界得分假设，或者未能展示掩盖离散扩散相对于均匀等价物的优势。
### Innovation
我们展示欧拉采样器能够在总变异（TV）中达到$boldsymbol{tilde{O}(d^{2}text{ε}^{-3/2})}$离散评分评估的$boldsymbol{text{ε}}$-准确性，从而提供首个典型的欧拉采样器在掩盖离散扩散中的严格分析。随后，我们提出了Mask-Aware Truncated Uniformization（MATU）方法，它消除了有界得分假设并保持了无偏离散评分逼近。通过利用每个token最多只能被解码一次的特性，MATU 达到了几乎$boldsymbol{ε}$-自由复杂度$O(dtext{ln}d times (1-text{ε}^2))$。该结果超越了均匀化方法在均匀离散扩散下实现的结果，消除了$boldsymbol{text{ln}(1/text{ε})}$因子，并显著加快了收敛速度。
### Conclusion
我们的研究不仅为掩盖离散扩散提供了一个严格的理论基础，展示了它在文本生成中的实际优势超过均匀扩散，而且为未来努力分析基于掩盖范式的扩散语言模型铺平了道路。
## 1117. `cs.LG` - 神经材料模型的缩放定律 [PDF](https://arxiv.org/pdf/2509.21811), [HTML](https://arxiv.org/abs/2509.21811)
### Authors
Akshay Trikha,Kyle Chu,Advait Gosai,Parker Szachta,Eric Weiner
### Background
预测材料性能对于设计更优秀的电池、半导体和医疗设备至关重要。深度学习帮助科学家通过预测材料的能量、力和应力快速找到有潜力的材料。许多公司在多个领域（如语言建模）扩展深度学习模型的规模，投资巨大的资金来构建这些模型。我们团队研究了如何通过增加训练数据量、模型规模和计算资源来提升神经网络性能，从而提高材料性能预测的效果。
### Innovation
我们训练了基于变换器和EquiformerV2的神经网络来预测材料性能，并发现了经验缩放法则：通过提高每个超参数（训练数据量、模型规模和计算资源），可以预测预测性能的提升情况。特别地，损失$L$与一个幂次关系$L = beta times N^{-beta}$有关，其中$beta$是常数，$N$是相关超参数。此外，我们还通过命令行参数调整训练设置，如周期数、最大学习率和混合精度功能。未来的研究可以进一步探索该领域其他神经网络模型的缩放法则，以评估其相对于我们所训练的模型的性能差异。
### Conclusion
我们团队对神经网络（包括变换器和EquiformerV2）预测材料性能的性能性能进行了研究，发现了这些模型在缩放律上的规律性，此外，我们还提供了灵活性的训练设置参数，为进一步研究打下了基础。
## 1118. `cs.LG` - 为啥高秩神经网络能泛化？基于代数框架与RKHS的理论 [PDF](https://arxiv.org/pdf/2509.21895), [HTML](https://arxiv.org/abs/2509.21895)
### Authors
Yuka Hashimoto,Sho Sonoda,Isao Ishikawa,Masahiro Ikeda
### Background
已有基于Rademacher复杂度的边界研究，但这些边界通常局限于有限类型模型。本文利用Koopman算子、群表示和再生核希尔伯特空间（RKHS）推导了一个新的边界，以解释为何具有高秩权重矩阵的模型能很好地泛化。
### Innovation
本文提出了一种代数表示神经网络的方法，并构建了一个核函数以构造一个RKHS，从而能够为更广泛的实际模型推导边界。
### Conclusion
这项工作为基于Koopman理论的Rademacher复杂度边界适用于更多实际情境铺平了道路。
## 1119. `cs.LG` - 离散引导匹配：离散流匹配的精确引导 [PDF](https://arxiv.org/pdf/2509.21912), [HTML](https://arxiv.org/abs/2509.21912)
### Authors
Zhengyan Wan,Yidong Ouyang,Liyan Xie,Fang Fang,Hongyuan Zha,Guang Cheng
### Background
当前的指导方法主要通过一阶泰勒近似来提高离散数据建模时的采样效率，但这种方法在离散状态空间中并不适用，因为近似误差较大。
### Innovation
提出了一种针对离散数据的新颖的指导框架，通过学习得到的目标分布精确转移率，使得指导只需每次采样步骤中进行一次前向传播，极大提升了效率。该框架具有通用性，包括了现有指导方法的特殊情况，并可无缝应用于掩码扩散模型。
### Conclusion
提出的指导方法在能量引导模拟和文本到图像生成以及多模态理解任务上的偏好对齐中显示了有效性。相关代码可通过此链接获得。
## 1120. `cs.LG` - 基于偏好引导的学习在稀疏奖励多智能体强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.21828), [HTML](https://arxiv.org/abs/2509.21828)
### Authors
TheViet Bui,Tien Mai,Hong Thanh Nguyen
### Background
我们研究在稀疏奖励环境下的在线多智能体强化学习（MARL）问题，在这种环境中，奖励反馈并不是在每次互动中提供，而仅在轨迹结束时给出。这种情景虽然现实，但存在一个根本挑战：缺乏中间奖励阻碍了一般MARL算法有效地引导策略学习。因此，需要一种新的框架来解决这一问题。
### Innovation
我们提出了一种新颖的框架，将在线逆向偏好学习与多智能体在线策略优化统一到一个架构中。中心在于引入了一个基于偏好值分解网络的隐式多智能体奖励学习模型，生成了全局和局部奖励信号，进一步构建了双重优势流，使得集中式评论和分散式行为者的学习目标得以差异化。此外，我们展示了如何利用大型语言模型（LLMs）提供偏好标签以增强学习奖励模型的质量。在MAMuJoCo和SMACv2等前沿基准上的实证评估表明，我们的方法在稀疏奖励在线MARL中表现出优越性能。
### Conclusion
我们的方法有效地提升了多智能体强化学习在稀疏奖励环境中的性能，尤其是在在线MARL场景中，具有显著优势。
## 1121. `cs.LG` - MolSpectLLM：从光谱到分子结构生成的分子基础模型 [PDF](https://arxiv.org/pdf/2509.21861), [HTML](https://arxiv.org/abs/2509.21861)
### Authors
Shuaike Shen,Jiaqing Xie,Zhuo Yang,Antong Zhang,Shuzhou Sun,Ben Gao,Tianfan Fu,Biqing Qi,Yuqiang Li
### Background
近年来，分子基础模型在分子性质预测和从头分子设计中表现出令人印象深刻的性能，具有在药物发现和反应预测等领域应用的前景。然而，现有方法大多依赖SMILES表示，并忽略了实验光谱和三维结构信息这两种对捕捉真实场景下分子行为至关重要的数据源。这种限制降低了它们在需要立体化学、空间构象和实验验证的任务中的效果。
### Innovation
本文提出了一种名为MolSpectLLM的分子基础模型，该模型以Qwen2.5-7B为预训练基础，结合实验光谱与分子三维结构。MolSpectLLM通过显式建模分子光谱，在NMR、IR和MS等光谱相关的基准任务中达到最先进的性能，平均准确率为0.53。此外，MolSpectLLM在光谱分析任务上的表现也非常出色，对于Spectra-to-SMILES任务，序列准确率达到15.5%，标记准确率达到41.7%，显著优于大型通用LLM。更重要的是，MolSpectLLM不仅在分子解析任务中表现出色，还能直接从SMILES或光谱输入生成准确的三维分子结构，实现了从光谱分析到分子解析再到分子设计的衔接。
### Conclusion
MolSpectLLM通过结合实验光谱信息和分子三维结构，创新地解决了传统方法在处理立体化学、空间构象和实验验证等关键任务上的不足，实现了分子性质预测、分子解析和三维结构生成等任务的综合性能提升。
## 1122. `cs.LG` - 超越RAG与长文本：学习抗干扰检索以实现高效知识对接 [PDF](https://arxiv.org/pdf/2509.21865), [HTML](https://arxiv.org/abs/2509.21865)
### Authors
Seong-Woong Shim,Myunsoo Kim,Jae Hyeon Cho,Byung-Jun Lee
### Background
RAG是一种将大型语言模型（LLMs）与外部、最新的信息进行对接的方法。然而，LLMs在处理输入方面的能力近年来有了显著提升，输入的最大长度可达128K个token或更多，这促使采用一种替代策略：直接向模型提供整篇文档的上下文，而非依赖RAG来检索部分上下文。但这一替代策略存在不可忽视的局限性：处理大量且可能冗余的上下文时效率低下；加剧了‘中间信息丢失’现象；在模型容量有限的情况下，会增加干扰，最终降低LLM输出的质量。
### Innovation
该论文提出了LDAR（学习抗干扰检索），一种适应性检索器，能够学习如何检索在减少干扰同时仍能提高性能的上下文，相较于直接提供长上下文的方法，LDAR在减少token使用量的情况下实现了显著的性能提升。广泛的实验表明了该方法的有效性和鲁棒性，特别是在平衡信息覆盖与干扰之下的重要性。
### Conclusion
跨不同LLM架构和六种知识密集型基准的实验结果证明了LDAR方法的有效性和鲁棒性，突显了在抗干扰检索上下提高性能的重要性，并强调了信息覆盖与干扰平衡的重要性。
## 1123. `cs.LG` - 通过将归纳逻辑编程和多模态大型语言模型相互关联实现演绎逻辑规则归纳 [PDF](https://arxiv.org/pdf/2509.21874), [HTML](https://arxiv.org/abs/2509.21874)
### Authors
Yifei Peng,Yaoli Liu,Enbo Xia,Yu Jin,Wang-Zhou Dai,Zhong Ren,Yao-Xiang Ding,Kun Zhou
### Background
ILP（归纳逻辑编程）和MLLMs（多模态大型语言模型）各自具备不同的优势和挑战。ILP在发现逻辑事实和生成逻辑规则方面表现出色，但由于需要特定的背景知识和高昂的计算成本，其应用受到限制。MLLMs在处理非结构化文本和视觉输入方面表现出色，但容易出现感知幻觉。方法的有效性在复杂的逻辑归纳基准和基于规则生成的多模态文本到图像定制生成中得到了验证。
### Innovation
提出了ILP-CoT方法，通过将ILP与MLLMs相结合，利用MLLMs的结构正确规则建议和ILP的逻辑事实纠正及形式归纳推理特性。自动构建更精简的任务搜索空间，利用ILP系统输出经过纠正逻辑事实和形式归纳推理后的规则。这种方法有效地解决了依靠ILP或MLLMs单独处理的挑战。
### Conclusion
该方法通过复杂的逻辑归纳基准和应用到多模态文本到图像的定制生成中，验证了其有效性。未来的研究将侧重于进一步优化任务搜索空间和提高MLLMs的准确性，以减少感知幻觉的影响。
## 1124. `cs.LG` - 超越约翰逊-林德施特劳斯：划分子空间的形式的统一界限 [PDF](https://arxiv.org/pdf/2509.21847), [HTML](https://arxiv.org/abs/2509.21847)
### Authors
Rohan Deb,Qiaobo Li,Mayank Shrivastava,Arindam Banerjee
### Background
划分子空间的形式的内积的统一界限为机器学习和随机化算法中的多个重要计算和统计结果奠定了基础，包括约翰逊-林德施特劳斯（J-L）引理、限制正态性质（RIP）、随机抽样和近似线性代数。然而，当前的许多分析涉及划分子空间的二次形式，现有的一些相关结论要么不适用，要么在普遍集上不够精确。本文旨在开发一个通用框架来分析这种划分子空间的二次形式，并通过几何复杂性来表达统一的界限。研究表明，施加的界与集合的几何复杂性有关，并利用通用链结构技术处理两个集合上的上界问题。进一步将结果扩展到独立抽样矩阵之和的场景，表明偏差量级为根号T。该综合分析不仅回收了J-L引理等已知结果，还拓展了RIP类型的保证。此外，对于闪存学习算法和一系列线性约束下的随机梯度压缩自适应算法，本文提出了更精确的结果，并设计了针对行动和参数集几何复杂性依赖的bandit算法变体，而不是原始维度依赖的结果，从而改善了遗憾界。
### Innovation
本文开发了一个通用框架来分析划分子空间的二次形式，并通过几何复杂性给出统一的界限。引入了处理两个集合上上界的新型技术，并将结果扩展到多个独立抽样矩阵之和的情况，证明了偏差的量级为根号T。这些结果不仅适用于已知结果的回收，还拓展了RIP类型的保证。此外，在闪存学习算法中获得更精确的收敛边界，并设计了新的bandit算法变体，其遗憾边界依赖于行动和参数集的几何复杂性，而不仅仅是原始维度
### Conclusion
本文的综合分析不仅能回收已知结果，如J-L引理，还扩展了RIP类型的保证。此外，在闪存学习算法中获得更精确的收敛边界，并设计了一系列新的bandit算法变体，这些变体的遗憾界依赖于行动和参数集的几何复杂性，而不仅仅是参数集的维度。这些结果为理解和优化相关算法提供了坚实的基础，并为未来的研究铺平了道路。
## 1125. `cs.LG` - 接近 oracle 差距：基于增量向量变换的类增量学习 [PDF](https://arxiv.org/pdf/2509.21898), [HTML](https://arxiv.org/abs/2509.21898)
### Authors
Zihuan Qiu,Yi Xu,Fanman Meng,Runtong Zhang,Linfeng Xu,Qingbo Wu,Hongliang Li
### Background
类增量学习(CIL)旨在顺序获取新类的知识，同时不会忘记之前学过的知识。尽管取得了进展，当前的CIL方法在性能上仍然与具有完全历史数据访问权限的oracle模型存在显著差距。这种差距主要源于新学习的知识与旧知识之间的竞争，导致了一种称为灾难性遗忘的现象。
### Innovation
受到了线性模式连通性(LMC)的最新见解启发，该研究重新审视了oracle解决方案在CIL中的几何特性，并揭示出了一个基本观察结果：这些oracle解决方案通常与先前任务的最优解保持低损失的线性连接。受到这一发现的启示，本文提出了一种新颖的插件式框架——增量向量变换(IVT)，用于减轻训练中的灾难性遗忘。IVT通过定期将模型参数移动到保持与前任务最优解线性连接的变换解中，维持沿着这些连接路径的低损失，从而有效保证了先前学习任务的稳定性能。IVT的变换利用对角鱼勒信息矩阵高效逼近，使其适用于无示例和基于示例的多种场景，同时兼容多种初始化策略。
### Conclusion
在CIFAR-100、FGVCAircraft、ImageNet-Subset和ImageNet-Full的数据集上进行的大量实验表明，IVT在提升现有的CIL基线性能方面表现出色。具体而言，在CIFAR-100上，IVT提高了PASS基准模型的最后一轮准确率5.12%，减少了2.54%的遗忘率。对于预训练的CLIP的SLCA基准模型，在FGVCAircraft上IVT带来了平均准确率14.93%和最后一轮准确率21.95%的提升。代码将在未来发布。
## 1126. `cs.LG` - 基于结构信息的层次扩散方法在离线强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.21942), [HTML](https://arxiv.org/abs/2509.21942)
### Authors
Xianghua Zeng,Hao Peng,Angsheng Li,Yicheng Pan
### Background
扩散机制在离线强化学习数据集上的轨迹建模中表现出潜在的前景，特别是在长时规划任务中引入了分层扩散以减轻长时规划中的方差累积和计算挑战。然而，现有的方法通常假定固定且单层级的分层结构，并且忽略了多样化的下游任务适应性和决策灵活性。
### Innovation
提出了一种新颖的基于结构信息的分层扩散框架（SIHD），能够在具有稀疏奖励的长时环境中有效地学习稳定的离线策略。SIHD通过分析离线轨迹中嵌入的结构信息，自适应地构建分层结构，进而跨多个时间尺度灵活地建模轨迹。同时还引入了一种结构熵正则化器以减少对离线数据集的依赖，并且避免分布转移带来的外推误差。
### Conclusion
SIHD在多个挑战性的离线强化学习任务中的大规模评估表明，在决策性能和对不同场景的泛化性方面，SIHD显著优于现有最先进的基线方法。
## 1127. `cs.LG` - 使用小波和3D循环表示的视觉LLM提取建筑能源数据的可操作见解 [PDF](https://arxiv.org/pdf/2509.21934), [HTML](https://arxiv.org/abs/2509.21934)
### Authors
Amine Bechar,Adel Oulefki,Abbes Amira,Fatih Kurogollu,Yassine Himeur
### Background
由于能源数据具有非线性和多尺度的特点，复杂建筑的时间序列分析以获得可操作的见解和建议仍然是一个挑战。传统的分析方法难以捕捉到这些特性，因此需要新的方法来解决这一问题。
### Innovation
本文提出了一种框架，通过精细调整视觉语言大模型（VLLMs）来处理3D图形表示的数据，这种方法利用连续小波变换（CWTs）和循环图（RPs）将1D时间序列转换为3D表示。这种表示法能够捕捉到时间动态并定位频率异常，使VLLMs能够视觉解释能源消耗模式、检测异常并提供能源效率建议。
### Conclusion
实验结果表明，Idefics-7B VLLM在使用小波变换（CWTs）和循环图（RPs）分别实现了大学沙迦能源数据集验证损失的0.0952和0.1064，优于直接对原始时间序列数据精细调整的验证损失0.1176。该工作将时间序列分析与可视化相结合，提供了一个可扩展且可解释的能源数据分析框架。
## 1128. `cs.LG` - 聪明思考，而非过度思考：大型音频语言模型的难度自适应推理 [PDF](https://arxiv.org/pdf/2509.21960), [HTML](https://arxiv.org/abs/2509.21960)
### Authors
Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li
### Background
大型音频语言模型（LALMs）利用链式思维（CoT）范式展示了卓越的推理能力。直觉上，不同问题往往要求不同程度的推理。尽管一些方法可以决定是否需要为某个问题进行推理，但它们通常缺乏一个具体的机制来调控推理的深度。这通常会导致一种“一刀切”的推理深度，对于简单问题产生冗余的过度思考，而对于复杂问题则分配不足的思考。
### Innovation
本文深入分析了LALMs，并发现有效的、高效的LALM应该能够根据问题的复杂程度灵活地调整推理深度。为此，提出了一个难度自适应推理方法。具体来说，提出了一种奖励函数，能够动态地将推理长度与模型感知的问题难度联系起来。该奖励机制鼓励简单任务进行更简短、简洁的推理，而复杂任务则进行更详细、深入的推理。广泛的实验表明，该方法既有效又高效，同时提高了任务性能并显著减少了平均推理长度。
### Conclusion
进一步对推理结构范式的分析为未来工作提供了宝贵的见解。
## 1129. `cs.LG` - 扩散模型中分类器自由指导的阶段动态 [PDF](https://arxiv.org/pdf/2509.22007), [HTML](https://arxiv.org/abs/2509.22007)
### Authors
Cheng Jin,Qitan Shi,Yuantao Gu
### Background
分类器自由指导（CFG）在提升扩散模型条件保真度方面被广泛应用，但其对采样动力学的影响仍不明确。以往的研究通常局限于单模条件分布或简化案例，提供的理解是片面的。
### Innovation
本文分析了在多模态条件下CFG的工作机制，提出了三个阶段性的动态过程：方向转变阶段、模式分离阶段和集中阶段。通过这一统一的观点解释了强指导增强语义对齐但必然减少多样性的广泛观察现象，并建议了时间变化的指导策略，实验结果验证了其有效性和优越性。
### Conclusion
强烈的早期指导会侵蚀全局多样性，而晚期强烈的指导则会抑制精细变化。我们的理论建议一种时间变化的指导策略，并且实验结果显示该策略能一致地提高质量和多样性。
## 1130. `cs.LG` - 在强化学习中通过大型语言模型实现目标引导的有效探索 [PDF](https://arxiv.org/pdf/2509.22008), [HTML](https://arxiv.org/abs/2509.22008)
### Authors
Yajie Qi,Wei Wei,Lin Li,Lijun Zhang,Zhidong Gao,Da Wang,Huizhong Song
### Background
现实世界中的决策任务通常在复杂的开放环境中进行，这对强化学习( reinforcement learning, RL)代理的探索效率和长远规划能力提出了巨大挑战。一种有前途的方法是结合大型语言模型( large language models, LLMs)的强化学习，利用LLMs丰富的先验知识和强大的规划能力来引导RL代理进行高效探索。然而，现有的方法主要依赖于频繁且昂贵的LLM调用，并且由于语义不匹配导致性能受限。
### Innovation
本论文提出了一种结构化目标导向强化学习(SGRL)方法，该方法集成了一个结构化目标规划器和一个目标导向动作剪枝器，以指导RL代理的高效探索。结构化目标规划器使用LLM生成可重用的、结构化的目标生成函数，并优先处理目标。通过使用LLM确定目标的优先级权重，动态生成前瞻性的目标，引导代理的政策走向更有可能成功的决策轨迹。目标导向动作剪枝器采用动作掩码机制，过滤掉与当前目标不一致的动作，从而限制RL代理选择目标一致的策略。
### Conclusion
我们在Crafter和Craftax-Classic上评估了所提出的方法，实验结果表明，SGRL相比现有的最先进方法具有更好的性能。
## 1131. `cs.LG` - 关于验证奖励的强化学习的隐含成本与测量差距 [PDF](https://arxiv.org/pdf/2509.21882), [HTML](https://arxiv.org/abs/2509.21882)
### Authors
Aaron Tu,Weihao Xuan,Heli Qi,Xu Huang,Qingcheng Zeng,Shayan Talaei,Yijia Xiao,Peng Xia,Xiangru Tang,Yuchen Zhuang,Bing Hu,Hanqun Cao,Wenqi Shi,Tianang Leng,Rui Yang,Yingjian Chen,Ziqi Wang,Irene Li,Nan Liu,Huaxiu Yao,Li Erran Li,Ge Liu,Amin Saberi,Naoto Yokoya,Jure Leskovec,Yejin Choi,Fang Wu
### Background
强化学习验证奖励（RLVR）是一种实用且可扩展的方法，用于在数学、代码和其他结构化任务等领域增强大语言模型。文章讨论了两种关键问题：在严格平等控制评估下，报告的增益有多少能够存活；以及RLVR是否完全免费，或者是否带来可衡量的负担。研究表明，虽然取得进步，但增益往往因三个原因而被夸大——RLVR税、评估陷阱和数据污染。通过部分提示污染审计和预算匹配再生产，发现许多头条差异在清洁、平等控制的评估下缩小或消失。
### Innovation
文章提出了一种税意识训练和评估协议，同时优化准确性和接地性，并标准化预算和来源检查。该协议应用于最近的RLVR设置，能够提供更可靠的理由增益估计，在某些情况下还修正了之前的结论。该立场是建设性的：强调RLVR的价值和工业准备状态的同时，更注重可靠性和安全性，以及衡量问题的本质区别，是必要的。
### Conclusion
RLVR是有价值且接近工业应用的；我们应该强调其实践价值，但同时要优先考虑可靠性、安全性和测量。应用税意识训练和评估协议可以更可靠地估计推理增益，并在某些情况下修正先前的结论。
## 1132. `cs.LG` - Weather Foundation Models的目标任务自适应参数高效微调 [PDF](https://arxiv.org/pdf/2509.22020), [HTML](https://arxiv.org/abs/2509.22020)
### Authors
Shilei Cao,Hehai Lin,Jiashun Cheng,Yang Liu,Guowen Li,Xuehe Wang,Juepeng Zheng,Haoyuan Liang,Meng Jin,Chengwei Qin,Hong Cheng,Haohuan Fu
### Background
近年来，机器学习的进展赋予了气象基础模型（WFMs）在多种下游任务中广泛应用的能力，但由于其规模扩张导致的计算需求增加，实际部署受到越来越多的限制。现有的参数高效微调（PEFT）方法，主要是为视觉或语言任务设计的，无法解决气象下游任务的独特挑战，如变量的异质性、分辨率的多样性、空间-时间覆盖的变化，导致将其应用于WFMs时性能不佳。
### Innovation
提出了一种新的PEFT框架WeatherPEFT，包含两个协同创新。首先，在前向传递过程中，任务自适应动态提示（TADP）动态地将编码器内的嵌入权重注入预先训练的主干网络的输入标记，通过内部和外部模式提取来实现上下文感知的特征重新校准，以适应特定的下游任务。其次，在反向传播过程中，随机Fisher引导自适应选择（SFAS）利用Fisher信息来标识并更新最任务关键的参数，从而保留之前预训练的知识，同时引入随机性以稳定选择过程。
### Conclusion
WeatherPEFT在三个下游任务上的效果优于现有PEFT方法，使用更少的可训练参数达到了与全训练相当的性能。研究结果表明了WeatherPEFT的有效性和效率，项目的代码将被发布。
## 1133. `cs.LG` - AEGIS: 在稀疏边缘双部知识图谱中的真实边缘增长 [PDF](https://arxiv.org/pdf/2509.22017), [HTML](https://arxiv.org/abs/2509.22017)
### Authors
Hugh Xuechen Liu,Kıvanç Tatar
### Background
 niche domains 中的双部知识图谱通常数据较少且边较少，这阻碍了链接预测。为了应对这一挑战，作者引入了 AEGIS（真实边缘增长稀疏）框架，它通过重新采样现有的训练边来增加稀疏性，同时保留原始节点集，不使用虚假边缘端点。
### Innovation
AEGIS 采用了一种边缘仅增加的框架，通过重新采样现有的训练边 - 既可均匀简单采样，也可根据度数加权偏倚度数感知采样，从而保留原始节点集且不使用伪造边缘端点。作者还通过自然稀疏图（游戏设计模式的游戏图案网络）和通过高率聚合（Amazon，MovieLens）诱导稀疏性来探究各边稀疏性情形的真实性。评估增广方法时使用了互补度量: AUC-ROC（越高越好）和布里尔评分（越低越好），同时用双尾成对 t 检验与稀疏基线进行比较。
### Conclusion
研究结果表明，AEGIS 增强方法可以在 Amazon 和 MovieLens 上与基线匹配，而语义的最近邻增强方法是唯一一种可以恢复 AUC 并校准的成法；随机和合成边缘仍然是不利的。在文本丰富的 GDP 图上，语义的最近邻增强方法能获得最大的 AUC 改进和布里尔评分减少，并且简单的也是一种降低了布里尔评分的方法。这些结果将真实性约束的重新采样定位为稀疏双部链接预测的数据高效策略，同时可用的信息节点描述提供了额外的增强作用。
## 1134. `cs.LG` - 有限训练集下随机插值的生成特性 [PDF](https://arxiv.org/pdf/2509.21925), [HTML](https://arxiv.org/abs/2509.21925)
### Authors
Yunchen Li,Shaohui Lin,Zhou Yu
### Background
本文研究了在有限训练样本数量条件下生成模型的理论行为。研究基于随机插值生成框架，在仅有有限训练样本的情况下，推导出了最优速度场和分数函数的闭式表达式。研究指出，在某些正则条件下，确定性生成过程能精确恢复训练样本，而随机生成过程则表现为带有高斯噪声的训练样本。
### Innovation
研究表明，在存在估计误差的情况下，随机生成过程会生成训练样本的凸组合，并受到均匀和高斯噪声的混合影响。此外，引入了生成模型中特定的过拟合和欠拟合形式定义，并通过生成任务和分类下游任务实验支持了理论分析结果。
### Conclusion
本文理论分析揭示了在存在估计误差的情况下，随机生成过程会生成训练样本的凸组合，并受到均匀和高斯噪声的混合影响，实验结果支持了这一理论。
## 1135. `cs.LG` - 通过高效试验与错误训练变换器解决组合问题 [PDF](https://arxiv.org/pdf/2509.22023), [HTML](https://arxiv.org/abs/2509.22023)
### Authors
Panagiotis Giannoulis,Yorgos Pantis,Christos Tzamos
### Background
尽管大型语言模型（LLMs）在各种语言任务上表现出色，但在解决组合问题如可满足性、旅行商问题或基础算术方面存在困难。本文通过引入一种新颖的方法，填补了这一空白，重点解决数独这一典型任务，并实现了与前期神经-符号方法相比最先进的准确率（99%）。
### Innovation
本文方法采用一种标准的解码器仅变换器（GPT-2），不依赖于外部工具或函数调用，并将模仿学习简单的数独规则与明确的深度优先搜索（DFS）探索策略相结合，策略包括基于信息的猜测和回溯。此外，该方法寻求在达到解决方案之前最小化猜测的数量。
### Conclusion
我们对这一设置进行了严格分析，正式化了其与算法和随机优化中广泛研究的最小和集覆盖问题变体的联系。
## 1136. `cs.LG` - Multiplicative-Additive Constrained Models: Toward Joint Visualization of Interactive and Independent Effects [PDF](https://arxiv.org/pdf/2509.21923), [HTML](https://arxiv.org/abs/2509.21923)
### Authors
Fumin Wang
### Background
在涉及生命安全的高风险领域（如医疗保健），机器学习的应用受到解释性的限制。广义加性模型（GAMs）通过可视化形状函数增强了解释性，但为了保持解释性，GAMs 忽略了高级别的交互效应（超越二阶交互），这对预测性能造成了显著的限制。尽管曲线遍历集回归（CESR）能自然地可视化其形状函数，同时结合了所有特征间的交互效应和单一特征效应，但其性能并未超越GAMs。
### Innovation
为解决 CESR 的性能问题，作者提出了一种新颖的模型 Multiplicative-Additive Constrained Models (MACMs)。MACMs 通过增加一个加性部分来分离交互项和独立项的系数，有效拓宽了假设空间，使得模型的形状函数都能自然可视化，以辅助用户理解特征在决策过程中的作用。实验结果表明，基于神经网络的 MACMs 在预测性能方面显著优于 CESR 和当前最先进的 GAMs。
### Conclusion
MACMs 超越了 CESR 和 GAMs，特别是在解释性和预测性能方面。这种模型在涉及生命安全的高风险领域内可以更好地应用机器学习。
## 1137. `cs.LG` - Zubov-Net：结合准确性和鲁棒性的神经ODE自适应稳定性 [PDF](https://arxiv.org/pdf/2509.21879), [HTML](https://arxiv.org/abs/2509.21879)
### Authors
Chaoyang Luo,Yan Zou,Nanjing Huang
### Background
尽管神经常微分方程（Neural ODEs）因其动态系统特性而表现出内在对输入扰动的稳健性，但现代方法常需要施加基于李雅普诺夫（Lyapunov）的稳定性条件以提供形式化的稳健性保证。然而，鲁棒性和准确性的平衡困难仍是根本挑战，主要源于适当地施加稳定性条件的难度。现有方法通过李雅普诺夫稳定性条件来增强鲁棒性保证，但未能很好地解决鲁棒性和准确性的矛盾问题。
### Innovation
本文提出了一种自适应稳定学习框架Zubov-Net，创新性地将Zubov方程重新表述为吸引区域（RoA）与预设吸引区域（PRoA）之间的一致性表征。基于此种一致性，通过直接优化PRoA，新框架引入了一种主动控制RoA几何形状的范式，以解决准确性和鲁棒性的冲突。此框架借助一致损失、分类损失和分离损失三种损失以及并行边界采样算法协同优化神经ODE和李雅普诺夫函数实现。为提高Lyapunov函数的辨别力，设计了一种基于输入注意力的凸神经网络，通过softmax注意力机制关注与平衡点相关的特征，并作为权重归一化来维护在深架构下的训练稳定性。理论分析证明，最小化这三种损失可确保PRoA-RoA一致对齐、轨迹稳定性以及PRoA之间无重叠。另外，我们还证明了更强的概率界限和较低的维度要求，以验证李雅普诺夫函数中凸设计的合理性。实验结果表明，Zubov-Net在保持高分类准确率的同时，显著增强了对各种随机噪声和对抗性攻击的鲁棒性。
### Conclusion
Zubov-Net 通过解决吸引区域和预设吸引区域之间的一致性，主动控制几何形状的优化，以及通过一致损失、分类损失和分离损失的三重损失体系和平行边界采样算法，实现了神经ODE在维持高准确率的同时，显著提高鲁棒性的目标。
## 1138. `cs.LG` - 基于凸性驱动的点云降维投影方法 [PDF](https://arxiv.org/pdf/2509.22043), [HTML](https://arxiv.org/abs/2509.22043)
### Authors
Suman Sanyal
### Background
点云降维是优化数据表示和提高处理效率的关键技术。传统的降维方法（如PCA）不能很好地保留点云中的局部非凸性特征，尤其是在处理三维重建和点云数据的几何属性时。因此，本文研究了如何通过线性方法保留局部非凸性。
### Innovation
提出了一种名为Convexity-Driven Projection (CDP)的新方法。CDP通过构建k-NN图，并聚合特定比例对的归一化方向，形成一个正半定的非凸性结构矩阵，进而使用该矩阵的前k个特征向量进行投影。该方法能够有效保持点云中的局部非凸性，通过数学证明提供了可验证的保证。
### Conclusion
实验证明了CDP方法的有效性和鲁棒性，该方法能够在保持点云局部非凸性的同时，降低点云维度。通过固定和重新选择对的偏转错误和证书分位数报告，实验证明了方法的可靠性。
## 1139. `cs.LG` - MO-GRPO: Mitigating Reward Hacking of Group Relative Policy Optimization on Multi-Objective Problems [PDF](https://arxiv.org/pdf/2509.22047), [HTML](https://arxiv.org/abs/2509.22047)
### Authors
Yuki Ichihara,Yuu Jinnai,Tetsuro Morimura,Mitsuki Sakamoto,Ryota Mitsuhashi,Eiji Uchibe
### Background
Group Relative Policy Optimization (GRPO)被证明在可用准确奖励模型的情况下是有效的算法。但在许多现实世界任务中，如此可靠的奖励模型并不总是可用的。尤其是在多目标设置中，GRPO容易遭受奖励劫持，即优化一个目标而牺牲其他目标。
### Innovation
提出了一种名为MO-GRPO的新算法，它是GRPO的一个扩展，包含了一个简单的归一化方法，自动重新加权奖励函数，根据它们值的方差来进行。MO-GRPO通过均匀分布奖励的关联性来稳定学习过程，不再需要人工调整奖励函数的尺度，从而确保所有奖励函数对损失函数贡献相同并保留偏好顺序。
### Conclusion
实验结果显示，MO-GRPO在四个不同的领域中都表现出色，均优于GRPO，展示了MO-GRPO作为多目标强化学习问题潜在算法的有效性。
## 1140. `cs.LG` - Softmax 注意的优势：来自单位置回归的见解 [PDF](https://arxiv.org/pdf/2509.21936), [HTML](https://arxiv.org/abs/2509.21936)
### Authors
O. Duranthon,P. Marion,C. Boyer,B. Loureiro,L. Zdeborová
### Background
大语言模型依赖于具有softmax激活的注意机制。然而，softmax在替代方案（如逐元素操作或线性）中的主导地位及其理论意义尚不明确。许多理论工作集中在更易于分析的线性化注意上。本文通过研究单位置回归任务来填补这一空白，该任务中输出取决于随机位置的一个输入标记的线性变换。
### Innovation
基于统计物理的思想，作者开发了一种关于注意基预测器在高维极限下的分析方法。研究表明，在总体层面上，softmax达到贝叶斯风险，而线性注意根本无法实现这一目标。作者进一步探讨了其他激活函数，以识别实现最优性能所需的具体属性。此外，作者还分析了有限样本区域，提供了测试误差的渐近特征，并证明虽然softmax已不再是贝叶斯最优的，但仍然持续优于线性注意。文章还讨论了由基于梯度的算法优化过程中的关联性。
### Conclusion
研究表明，尽管softmax在大样本条件下已不再是贝叶斯最优的，但在有限样本情况下，softmax仍然比线性注意更优越。这为具有softmax激活的注意机制提供了理论支持，并探讨了实现最优性能所需的特征。
## 1141. `cs.LG` - Concept-SAE：视觉模型行为的主动因果探测 [PDF](https://arxiv.org/pdf/2509.22015), [HTML](https://arxiv.org/abs/2509.22015)
### Authors
Jianrong Ding,Muxi Chen,Chenchen Zhao,Qiang Xu
### Background
标准稀疏自编码器（SAEs）能够发现模型学习特征的字典，提供了强大的观察工具，但由于这些特征具有模糊且缺乏具体含义的特性，使得它们无法用于对模型行为进行主动的因果探究。开发一种基于语义的框架以实现对内部概念与预测间因果联系的直接干预，并系统地定位对抗性漏洞的具体网络层，能够解决这一问题。
### Innovation
本文提出了一种名为Concept-SAE的概念框架，通过一种新颖的混合分离策略，生成了语义上具含义的概念token。定量实验表明，这种方法在分离性上优于其他方法，并且生成的token具有高水平的忠实性和空间定位特性，为通过直接干预探究内部概念与预测之间的因果关系以及系统化定位对抗性脆弱性到特定层提供了可能性和依据。
### Conclusion
Concept-SAE为从相关性的解释向机制性、因果性的模型行为探究提供了一个验证过的蓝图。
## 1142. `cs.LG` - GRAM-TDI: 自适应多模态表示学习在药物靶点相互作用预测中的应用 [PDF](https://arxiv.org/pdf/2509.21971), [HTML](https://arxiv.org/abs/2509.21971)
### Authors
Feng Jiang,Amina Mollaysa,Hehuan Ma,Tommaso Mansi,Junzhou Huang,Mangal Prakash,Rui Liao
### Background
药物靶点相互作用（DTI）预测是计算药物发现的基石，它能够促进合理的药物设计、重新定位以及机制性洞察。虽然深度学习提升了DTI建模，但现有方法主要依赖于小分子和蛋白质的SMILES表示，未能充分利用小分子和蛋白质丰富的多模态信息。现有的方法依赖于单一模态信息和传统的两两匹配方式，未能探索高级语义对齐。增强对多模态信息的利用和探索高级语义对齐是提高DTI预测性能的关键需求。
### Innovation
本文提出了一种名为GRAMDTI的新颖预训练框架，该框架通过集成多模态分子和蛋白质输入，实现统一表示。GRAMDTI扩展了基于体积的对比学习，捕获了超越传统两两匹配方法的高级语义对齐。为了处理不同模态的信息差异性，提出了自适应模态丢弃，动态调节每个模态的贡献。此外，当有IC50活性测量数据时，将其作为弱监督引入，以使表示基础生物意义的相互作用强度。实验结果表明，GRAMDTI在四个公开数据集上持续优于最先进的基线方法。该研究强调了高级多模态对齐、自适应模态利用和辅助监督在DTI预测中的优势。
### Conclusion
实验结果表明，GRAMDTI在四个公开数据集上持续优于最先进的基线方法，证明了高级多模态对齐、自适应模态利用和辅助监督对于稳健和泛化的DTI预测具有显著的益处。
## 1143. `cs.LG` - Active Attacks: Red-teaming LLMs via Adaptive Environments [PDF](https://arxiv.org/pdf/2509.21947), [HTML](https://arxiv.org/abs/2509.21947)
### Authors
Taeyoung Yun,Pierre-Luc St-Charles,Jinkyoo Park,Yoshua Bengio,Minsu Kim
### Background
针对大型语言模型（LLMs）生成多种攻击提示以引发有害行为（如侮辱、色情内容）的挑战，当前方法多数依赖手动提示工程，这不仅效率低下，并且难以覆盖广泛的有害行为类型。有研究尝试使用强化学习（RL）来自动生成攻击提示，但这种方法容易导致探索的局限性，难以充分覆盖多种有害行为模式。本文提出了一种新的基于RL的红队（红队是指对手对目标系统进行攻击测试的方法）算法，称为Active Attacks，以应对这一挑战。该算法通过定期对被攻击模型进行安全性微调，并适应性调整攻击策略，促使攻击者探索未开发的漏洞，从而实现从易到难的探索训练周期。这种方法有效提高了攻击成功率，并且相较于现有方法，取得了显著的性能提升。
### Innovation
本文引入了一种新的基于RL的红队算法，称为Active Attacks。该算法通过以下创新点实现了对LLMs的安全性测试：1) 通过不断调整攻击策略，鼓励攻击者探索新的未开发模式；2) 引入了适应性训练环境，促使被攻击模型的不断微调，从而维持探索区域的多样性；3) 通过实现简单且易于集成的模块设计，提高了算法的实用性和可扩展性。该算法在实际测试中，显著优于包括GFlowNets、PPO和REINFORCE在内的先前RL方法，特别是在对GFlowNets这类现有最佳方法的攻击成功率上取得了高达31.28%的显著提升，这远远超出了单一模式下的默认性能。
### Conclusion
通过不断调整攻击策略，鼓励探索未开发的多模式分布，Active Attacks算法能有效识别出广泛多样化的攻击模式。这种方法展示了在不依赖于复杂计算的前提下，强化学习如何有效地应用于红队测试中。未来的工作将探索更广泛的攻击模式，并进一步优化算法以保证其在其他场景中的适用性。本文提供的代码已开源，便于进一步的研究开发。
## 1144. `cs.LG` - 潜在扩散：多维稳定的潜在空间探索者 [PDF](https://arxiv.org/pdf/2509.22038), [HTML](https://arxiv.org/abs/2509.22038)
### Authors
Zhihua Zhong,Xuanyang Huang
### Background
生成AI中的潜在空间是一个关键概念，通过向量操作提供强大的创造性探索手段。然而，像Stable Diffusion这样的扩散模型缺乏与GANs中直观的潜在向量控制，这限制了它们在艺术表达中的灵活性。现有的扩散模型，在直观的潜在空间操控方面存在不足，影响了生成艺术的创意可能性。
### Innovation
本文介绍了一种框架，用于将自定义的潜在空间操作集成到扩散过程中，通过直接对概念和空间表示进行操控，扩展生成艺术中的创造性可能性。这一框架通过两个艺术品展示了其潜力：《Infinitepedia》和《Latent Motion》，分别演示了概念融合和动态动作生成的应用。
### Conclusion
我们的研究揭示了潜在空间中的语义和无意义区域，为扩散模型的空间几何提供了见解，为进一步探索潜在空间铺平了道路。
## 1145. `cs.LG` - MCGM: 多阶段聚类全局建模在分子中的长程相互作用 [PDF](https://arxiv.org/pdf/2509.22028), [HTML](https://arxiv.org/abs/2509.22028)
### Authors
Haodong Pan,Yusong Wang,Nanning Zheng,Caijui Jiang
### Background
几何图神经网络（GNNs）在捕捉分子几何结构方面表现出色，但其局部消息传递机制限制了长程相互作用的建模能力。现有的解决方案存在根本性限制：扩展截止半径会导致计算成本随距离立方增长；基于物理原理的核函数（如库仑核、分散核）往往是特定于系统的，缺乏通用性；基于傅里叶空间的方法则需要精细调整多个参数（如网格大小、k空间截止值），增加了计算开销。
### Innovation
我们提出了一种轻量级的模块Multi-stage Clustered Global Modeling (MCGM)，通过高效聚类操作赋予几何GNNs层次化的全局上下文。MCGM 构建了一种多分辨率的原子集群层次结构，通过动态的分层聚类提取全局信息，并通过学习变换将其传播回，最终通过残差连接强化原子特征。MCGM 可无缝集成到四种不同的主干架构中，相比其他方法，在分子的OE62能预测上减少26.2%的误差，并在QM中达到了最先进的精度（能量17.0 meV，力4.9 meV/Å），而参数量则减少了20%。
### Conclusion
MCGM 减少了计算成本和参数数量，提高了模型在长程相互作用中的准确性和效率，为几何GNNs提供了有效的长程相互作用建模方法。
## 1146. `cs.LG` - 叛逆的手术刀：激活引导削弱LLM的安全性 [PDF](https://arxiv.org/pdf/2509.22067), [HTML](https://arxiv.org/abs/2509.22067)
### Authors
Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Y. Rogov,Ivan Oseledets,Elena Tutubalina
### Background
激活引导是一种通过在模型推断期间直接向隐藏状态添加语义上有意义的向量来控制大语言模型（LLM）行为的技术。通常被认为是一种精确、可解析且可能更安全的替代fine-tuning的方法。然而，该研究发现了激活引导存在系统性漏洞，能够使得模型违背安全保护，甚至遵从有害指令。
### Innovation
该研究通过广泛的实验，展示出即使在随机方向上进行激活引导也会使有害响应的概率从0%提高到2%-27%，使用稀疏自编码器（SAE）提取的良性特征进行激活引导进一步将此概率提高2%-4%。研究还揭示了一种使用20个随机提取的向量（这些向量能够突破单一提示）作为攻击武器，显著提高未见请求的有害响应概率。
### Conclusion
该研究挑战了解释性在安全性中的主导地位，证明了对模型内部的精确控制并不一定保证对模型行为的精确控制，指出安全性的提升不应依赖于对模型内部的精细控制。
## 1147. `cs.LG` - 通过混合类型贝叶斯网络在排球中建模心理特征 [PDF](https://arxiv.org/pdf/2509.22111), [HTML](https://arxiv.org/abs/2509.22111)
### Authors
Maria Iannario,Dae-Jin Lee,Manuele Leonelli
### Background
心理特质很少单独存在：教练在考虑心理特质时，往往涉及网络中的相关特质。本文分析了来自意大利C和D联赛的164名女排运动员的新数据集，该数据集结合了标准化的心理学分析和背景资料，以此来探索不同类型的变量（序数问卷得分、分类人口统计学、连续指标）之间的方向性关系。
### Innovation
文章引入了一种新的混合结构学习算法——潜在MMHC，它将潜在高斯 copula 和基于约束的骨架与受约束的评分细化相结合，返回单一的有向无环图（DAG）。此外，该研究还探讨了一种基于同质聚合的方法以提高稳定性。通过样本大小、稀疏性和维度的不同情况进行模拟，研究发现潜在的最大-最小山丘上升算法（MMHC）在结构性海明距离和边召回率方面优于近期的 copula 基础学习者，同时保持了高度的特异性。
### Conclusion
在排球应用中，所学习的网络将心理技能组织在目标设定和自信心周围，情绪唤醒将动机和焦虑联系起来，并将大五个性特征（尤其表现为神经质和外向性）置于技能群的上游。情景分析量化了特定技能改善如何在网络中传播，从而影响准备、自信心和自我效能感。该方法提供了一种解释性强的数据驱动框架，用于体育中的心理特质分析及运动员开发中的决策支持。
## 1148. `cs.LG` - OrtSAE: 正交稀疏自编码器发现原子特征 [PDF](https://arxiv.org/pdf/2509.22033), [HTML](https://arxiv.org/abs/2509.22033)
### Authors
Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Rogov,Elena Tutubalina,Ivan Oseledets
### Background
稀疏自编码器（SAEs）是一种将神经网络激活稀疏分解为可解释特征的技术。然而，当前的SAEs存在特征吸收和特征合成的问题。特征吸收是指特化的特征捕获一般特征的实例，导致表示空洞；特征合成则指独立特征合并为复合表示。这些问题不利于模型的可解释性和泛化能力。为了改进这些问题，本研究引入了一种新的方法：正交稀疏自编码器（OrtSAE），通过强制学习到的特征间正交来缓解这些问题。OrtSAE通过在训练过程中惩罚SAE特征间的高余弦相似度，促进开发独立特征，而训练过程的开销可线性扩展到SAE的规模，不会产生显著的计算负担。
### Innovation
引入了正交稀疏自编码器（OrtSAE），这是一种通过强制特征正交来解决特征吸收和特征合成问题的新方法。它通过在训练过程中减少特征间的余弦相似度来促进开发独立和可解释的特征，而不会增加显著的训练成本。OrtSAE在不同模型和层上的训练结果表明，它能够发现更多的独立特征，减少特征吸收和合成，并且在其他下游任务中能取得与传统SAE相当的表现，同时还提高了去除概率相关性方面的性能。
### Conclusion
OrtSAE发现独立特征的能力比传统SAE提高了9%，降低了65%的特征吸收和15%的特征合成，同时在了去除概率相关性方面表现出6%的性能提升。与其他方法相比，OrtSAE在替换传统SAE时可以保持相当的性能水平。
## 1149. `cs.LG` - 通过内在类对比学习丰富知识蒸馏 [PDF](https://arxiv.org/pdf/2509.22053), [HTML](https://arxiv.org/abs/2509.22053)
### Authors
Hua Yuan,Ning Xu,Xin Geng,Yong Rui
### Background
自知识蒸馏问世以来，许多研究集中在如何有效利用教师模型生成的软标签。现有的研究表明，软标签中的隐含知识来源于数据中的多视图结构。同一类别的样本间的特征变化允许学生模型通过学习多样化的表示而更好地泛化。然而，在现有的蒸馏方法中，教师模型主要以地面真实标签为目标，而不考虑同一类别内的多样化表示。
### Innovation
本文提出在教师模型训练过程中引入内在类对比损失，以丰富软标签中包含的内在类信息。实践中发现，内在类损失会导致训练不稳定并减慢收敛速度，因此结合了边际损失改进内在类对比学习的训练稳定性和收敛速度，并从理论上分析了该损失对内在类和类别间距离的影响。实验结果证明了所提方法的有效性。
### Conclusion
本文通过引入内在类对比损失和边际损失，改进了知识蒸馏过程，提高了学生模型的泛化能力和训练效率。
## 1150. `cs.LG` - 理解参数转移中特征学习 [PDF](https://arxiv.org/pdf/2509.22056), [HTML](https://arxiv.org/abs/2509.22056)
### Authors
Hua Yuan,Xuran Meng,Qiufeng Wang,Shiyu Xia,Ning Xu,Xu Yang,Jing Wang,Xin Geng,Yong Rui
### Background
参数转移是迁移学习的核心范式，通过在上游和下游模型之间共享模型参数来实现跨任务和领域的知识再利用。然而，当只有上游模型的一部分参数被转移到下游模型时，对其是否有益以及影响其效果的因素缺乏理论理解。本文在ReLU卷积神经网络（CNNs）的上下文中，对此问题进行分析，以填补理论上的空白。
### Innovation
本文分析了特征学习在部分参数转移情况下的作用机制，并识别了增强其有益影响的关键因素。此外，研究还进一步解释了为何在某些情况下，参数转移可能会导致目标任务的测试准确率低于从头开始训练模型的情况。
### Conclusion
通过数值实验和真实世界数据实验验证了理论分析结果，揭示了参数转移中特征学习的机理。
## 1151. `cs.LG` - 对抗性欺骗在回归分析中的防御 [PDF](https://arxiv.org/pdf/2509.22113), [HTML](https://arxiv.org/abs/2509.22113)
### Authors
David Benfield,Phan Tu Vuong,Alain Zemkoho
### Background
对抗性机器学习挑战了模型训练和实施过程中基础分布保持一致性的假设。特别是，对抗性规避考虑了攻击者通过调整其数据来影响预设预测模型的特定结果的情景，这在垃圾邮件过滤、恶意软件检测和假图像生成等应用场景中尤为常见，其中安全方法必须不断更新以应对日益改进的恶意数据。博弈论模型已被证明对建模这些情景非常有效，因此用于训练对抗攻击的鲁棒预测器。近期，悲观的二层最优化技术显示出特别有效的抵御分类器威胁的潜力，因为这种技术能够捕捉到攻击者的对抗性本质。然而，这一方法尚未被应用于回归场景。
### Innovation
本文提出了一个悲观的二层最优化程序，专门针对回归场景。该程序消除了对手最优解关于凸性和唯一性的假设。
### Conclusion
本文介绍了一种针对回归场景的悲观二层最优化方法，旨在提高预测器对抗对手的鲁棒性，无需对对手的最优解假设其凸性或唯一性。
## 1152. `cs.LG` - 非线性轨迹建模在联邦学习多步梯度反向攻击中的应用 [PDF](https://arxiv.org/pdf/2509.22082), [HTML](https://arxiv.org/abs/2509.22082)
### Authors
Li Xia,Zheng Liu,Sili Huang,Wei Tang,Xuan Liu
### Background
联邦学习（FL）通过保持数据本地化来保护隐私，然而梯度反转攻击（GIAs）构成了严重威胁。在FedAVG多步场景中，攻击者只能观察聚合梯度，这使得数据恢复变得困难。现有的代替代方法如SME假设参数轨迹呈线性，但作者证明了这一假设严重低估了随机梯度下降（SGD）的非线性复杂度，从而显著限制了攻击的有效性。
### Innovation
我们提出了非线性代替代方法扩展（NL-SME），这是首个引入非线性参数轨迹建模的GIAs方法。该方法使用可学习的二次贝塞尔曲线替换线性插值，通过控制点捕捉SGD的曲线特性，并通过正则化和dvec缩放机制增强表示能力。实验结果表明，NL-SME在所有指标上显著优于基线方法，在余弦相似度损失上实现了数量级的改进，同时保持了计算效率。
### Conclusion
这些结果揭示了在联邦学习多步更新框架中高度的隐私漏洞，并为开发稳健的防御策略提供了新的视角。
## 1153. `cs.LG` - BrainPro：迈向大规模脑状态感知的脑电图表示学习 [PDF](https://arxiv.org/pdf/2509.22050), [HTML](https://arxiv.org/abs/2509.22050)
### Authors
Yi Ding,Muyun Jiang,Weibang Jiang,Shuailei Zhang,Xinliang Zhou,Chenyu Liu,Shanglin Li,Yong Li,Cuntai Guan
### Background
脑电图（EEG）是一项无创的脑电活动记录技术，广泛应用于脑机接口（BCI）和医疗保健领域。基于大规模数据集训练的最新EEG基础模型较传统解码方法表现出更好的性能和泛化能力，但仍面临许多挑战。现有模型往往未能明确捕捉通道间和区域间的相互作用，而这些相互作用是EEG信号中固有的重要信息来源。由于数据集的电极布局差异，这些模型要么通过自我注意力机制拟合空间结构，要么限制训练于一组常见的电极，牺牲了灵活性和有效性。尽管EEG数据集反映了多种脑状态，如情绪、运动等，当前模型在自我监督预训练过程中很少学习到状态感知的表示。为解决这些问题，本文提出了一种名为BrainPro的大型EEG模型，模型中采用了基于检索的空间学习模块来灵活捕捉不同电极布局下的通道级和区域级相互作用，并采用脑状态解耦模块，通过具有解耦和区域感知重构损失的并行编码器实现状态感知表示学习。该设计使得BrainPro能在多种任务和硬件配置下无缝适应。在广泛EEG数据集上的预训练使得BrainPro在九个公共BCI数据集上都表现出最佳性能和鲁棒泛化能力。
### Innovation
本文提出了一种名为BrainPro的大型EEG模型，该模型引入了一种基于检索的空间学习模块，能灵活捕捉不同电极布局下的通道级和区域级相互作用；还设计了一种脑状态解耦模块，通过并行编码器与解耦及区域感知重构损失实现状态感知表示学习，从而使得BrainPro能够无缝适应多种任务和硬件配置，并在多个公共BCI数据集上表现出最佳性能和鲁棒泛化能力。
### Conclusion
BrainPro有效地解决了EEG信号处理中的互动作图捕捉及状态感知表示学习问题，模型能适应多任务和多硬件配置。广泛的预训练展现了BrainPro在多个公共BCI数据集上的优势，具有良好的鲁棒性和泛化能力。
## 1154. `cs.LG` - 通过函数最优传输切片Wasserstein Over Wasserstein [PDF](https://arxiv.org/pdf/2509.22138), [HTML](https://arxiv.org/abs/2509.22138)
### Authors
Moritz Piening,Robert Beinert
### Background
Wasserstein距离定义了概率测度在任意度量空间之间的度量，包括元测度（测度的测度）。由此产生的Wasserstein Over Wasserstein (WoW)距离是对比数据集或图像、形状分布的强大工具，但计算成本高。现有的一些sliced WoW加速方法依赖于参数化的元测度或高阶矩的存在，这导致了数值不稳定性。
### Innovation
本文提出了一种利用一维Wasserstein空间与$L_2([0,1])$函数空间中的分位数函数之间的等距关系来构造任意Banach空间上的sliced Wasserstein框架。该框架通过无限维$L_2$投影定义了一维元测度之间的切片距离，参数化由高斯过程给出。结合一维构造与欧几里得单位球上的经典积分，得到了一种通用的双切片Wasserstein (DSW)度量。DSW最小化与离散元测度的WoW最小化等价，同时避免了高阶矩的不稳定性和计算成本的节省。
### Conclusion
实验结果表明，DSW作为WoW距离的可扩展替代方案是有效的。
## 1155. `cs.LG` - SHAKE-GNN: 可扩展的基于Kirchhoff森林的层次图神经网络 [PDF](https://arxiv.org/pdf/2509.22100), [HTML](https://arxiv.org/abs/2509.22100)
### Authors
Zhipu Cui,Johannes Lutzeyer
### Background
图神经网络（GNNs）已经在多种学习任务中取得了显著的成绩。然而，将GNNs扩展到大规模图仍然是一个重大挑战，特别是对于图级别任务而言。目前，尚未有可同时保证高效性和性能的可扩展图神经网络框架。
### Innovation
我们引入了SHAKE-GNN，这是一种基于Kirchhoff森林层次结构的新颖可扩展图级GNN框架。通过对Kirchhoff森林的多层次分解，SHAKE-GNN能够生产多尺度的表示，从而灵活地调整效率和性能之间的权衡。此外，我们提出了一种改进的数据驱动策略来选择权衡参数并分析了SHAKE-GNN的时间复杂度。
### Conclusion
在多个大规模图分类基准测试上，实验结果表明SHAKE-GNN达到了竞争性的性能，并提供了改进的可扩展性。
## 1156. `cs.LG` - 机械独立性：可识别去纠缠表示的一个原则 [PDF](https://arxiv.org/pdf/2509.22196), [HTML](https://arxiv.org/abs/2509.22196)
### Authors
Stefan Matthes,Zhiwei Han,Hao Shen
### Background
分离表征旨在恢复底层观察数据的潜在变化因素，但其可识别性尚不完全清楚。本文通过机械独立性引入了一个统一框架，这种方法通过潜在因素如何作用于观察变量来表征它们，而不是通过它们的潜在分布。这种观点在潜在密度变化时保持不变，即使这些变化引起因素之间的统计依赖关系。
### Innovation
本文提出一系列相关独立准则，包括基于支持的、基于稀疏性的以及高阶条件，并证明在非线性、非可逆混合的情况下，每种准则均可实现潜在子空间的可识别性。进一步建立了这些准则的层级关系，并使用图论刻画了潜在子空间作为连通分量。
### Conclusion
这些结果阐明了在不需要统计假设的情况下，哪些条件下分离表征可以被识别。
## 1157. `cs.LG` - LLVM中轻量级错误缓解策略在后训练N:M激活稀疏化中的应用 [PDF](https://arxiv.org/pdf/2509.22166), [HTML](https://arxiv.org/abs/2509.22166)
### Authors
Shirin Alanova,Kristina Kazistova,Ekaterina Galaeva,Alina Kostromina,Vladimir Smirnov,Redko Dmitry,Alexey Dontsov,Maxim Zhelnin,Evgeny Burnaev,Egor Shvetsov
### Background
当前对高效大型语言模型（LLM）推理的高需求促使了对稀疏化技术的重视。尽管半结构化（N:M）剪枝在权重上已经得到了广泛研究，但对于激活剪枝的应用仍处于初级阶段，尽管其具有动态、输入自适应压缩和减少输入输出开销的潜力。
### Innovation
该研究对后训练N:M激活剪枝方法进行了全面分析。研究表明，在相同稀疏度水平下，与权重剪枝相比，剪枝激活可以更好地保留生成能力。研究还评估了轻量级、即插即用的错误缓解技术以及剪枝准则，建立了支持最少校准的硬件友好基准。研究进一步探索了NVIDIA标准2:4稀疏模式之外的模式，发现16:32模式的性能几乎可以与未结构化稀疏模式媲美。然而，考虑到灵活性和硬件实现复杂性的权衡，研究选择了8:16模式作为更优的选择。
### Conclusion
研究结果不仅提供了高效的激活剪枝方法，还为未来硬件支持更灵活的稀疏模式提供了动机。代码已公开可在该链接找到。
## 1158. `cs.LG` - 基于强化学习的持久性算法救济 [PDF](https://arxiv.org/pdf/2509.22102), [HTML](https://arxiv.org/abs/2509.22102)
### Authors
Marina Ceccon,Alessandro Fabris,Goran Radanović,Asia J. Biega,Gian Antonio Susto
### Background
算法救济旨在为个人提供可行的建议，增加他们从自动化决策系统（例如贷款审批）中获得有利结果的机会。尽管先前的研究强调了模型更新的鲁棒性，但很少关注救济措施的时间动态，特别是在资源受限的竞争环境中，推荐会直接影响未来的申请人群体。
### Innovation
本研究提出了一个新颖的时间感知框架，明确建模候选人群体在推荐后如何调整自身。此外，还引入了一种基于强化学习（RL）的救济算法，该算法能够捕捉环境的不断演变，生成同时具有可行性和有效性的建议。建议被设计为持久的，可以支持预定义时间范围T的有效性。
### Conclusion
通过在复杂模拟环境中进行广泛实验，结果显示该方法在可行性和长期有效性之间提供了更优的平衡。这些结果证实了将时间和行为动态整合到实际救济系统设计中的重要性。
## 1159. `cs.LG` - 公平感知强化学习（FAReL）：透明且平衡的序列决策框架 [PDF](https://arxiv.org/pdf/2509.22232), [HTML](https://arxiv.org/abs/2509.22232)
### Authors
Alexandra Cimpean,Nicole Orzan,Catholijn Jonker,Pieter Libin,Ann Nowé
### Background
在实际的序列决策问题中，可以通过公平感知的方法来实现公平性。然而，这种平衡性能与公平性的折衷不利于事前具体指定，因此需要算法能够进行适当且透明的性能与公平性折衷。基于这一背景，本研究提出了一种框架，允许在多个性能公平性折衷之间进行探索。
### Innovation
本文提出了一个扩展的马尔可夫决策过程$f$MDP，并在其基础上构建了一个公平感知框架，以便在序列决策问题中实现公平性。通过这一框架，能够评估性能公平性折衷，从而指导关键利益相关者选择最合适的策略。此外，框架在不同的公平需求场景下展示出更好的公平性，且性能损失很小。
### Conclusion
本文展示了我们的框架能够学习出在多个场景中更公平的策略，并且只会略有性能损失。此外，我们发现群体公平性和个体公平性并不一定相互约束，这对需要同时考虑两种公平性的场景特别有益。最后，本文提供了如何在不同问题设定下应用该框架的指导原则。
## 1160. `cs.LG` - 在去中心化优化中提升效率：基于最小附加开销重新构想邻域聚合 [PDF](https://arxiv.org/pdf/2509.22174), [HTML](https://arxiv.org/abs/2509.22174)
### Authors
Durgesh Kalwar,Mayank Baranwal,Harshad Khadilkar
### Background
在当前对数据敏感的环境中，分布式学习作为一项关键工具，不仅加强了隐私保护，还简化了计算操作。特别是在完全去中心化基础设施中，由于缺乏中心化的聚合，本地处理变得至关重要。现有的去中心化学习方法，如静态权重分配的Metropolis方法，难以有效地处理数据异质性。
### Innovation
介绍了DYNAWEIGHT这一创新框架，用于多代理网络中的信息聚合。DYNAWEIGHT能够显著加速去中心化学习，并且在额外通信和内存开销上几乎可以忽略不计。相较于传统的静态权重分配方法，DYNAWEIGHT根据邻近服务器在本地数据集上的相对损失动态分配权重，特别有利于数据异质性较强的场景。实验结果表明，DYNAWEIGHT能够显著提高训练速度。
### Conclusion
DYNAWEIGHT作为一种聚合方案，能够与任何底层服务器优化算法兼容，展示了其灵活性和广泛集成的潜力。
## 1161. `cs.LG` - 自动发现$SO(n)$的一参数子群 [PDF](https://arxiv.org/pdf/2509.22219), [HTML](https://arxiv.org/abs/2509.22219)
### Authors
Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P
### Background
一参数子群在机器人技术、量子力学和分子结构分析等领域具有广泛的应用。现有方法通常依赖于手工设计，难以满足复杂场景的需求。本文提出了一种新颖框架，旨在自动发现$SO(3)$和更一般的$SO(n)$的一参数子群$H_{boldsymbol{boldsymbol{beta}}}$。
### Innovation
该方法利用$SO(n)$的旋转向量矩阵标准乔丹型，为$H_{boldsymbol{boldsymbol{beta}}}$作用下的轨道提供一种规范形式。通过该规范形式，可以导出$H_{boldsymbol{boldsymbol{beta}}}$不变函数的标准表示。通过优化参数，框架能自动识别出潜在的一参数子群$H_{boldsymbol{boldsymbol{beta}}}$。
### Conclusion
论文通过双摆建模、预测转动惯量、顶夸克标记和不变多项式回归等任务，证明了该方法的有效性，成功恢复了有意义的子群结构，并产生了可解释、具有对称性感知的表示。
## 1162. `cs.LG` - Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models [PDF](https://arxiv.org/pdf/2509.22121), [HTML](https://arxiv.org/abs/2509.22121)
### Authors
Jeong Eul Kwon,Joo Heung Yoon,Hyo Kyung Lee
### Background
电子健康记录（EHRs）中的时间序列数据受不规则采样和高缺失率的影响，临床变量根据工作流程和干预时间表以不均匀的时间间隔进行测量。这种不规则性构成了建模EHR时间序列数据的固有价值挑战。
### Innovation
提出了一种名为VITAL的变量感知框架，利用大型语言模型（LLM）从不规则采样生理时间序列中学习。VITAL将生理量视为经常记录且具有序列模式的变量，将实验室测试作为稀疏记录且缺乏序列结构的变量进行处理。它通过显式编码将生理量重新编程到语言空间，使LLM能够捕捉时间上下文和推断缺失值。实验室变量根据其可用性采用代表汇总值或可学习的[未测量]标记进行嵌入。该框架在PhysioNet基准数据集上的广泛评估表明，VITAL在不规则时间序列任务中优于现有方法，并且在高缺失率情况下保持稳健性能，这是真实临床场景中的常见情况，其中关键变量往往不可用。
### Conclusion
VITAL通过显式编码生理量并利用大型语言模型的优势，在处理不规则采样和高缺失率的问题上取得了显著进展，提升了在广泛评估中的表现，特别是在真实临床场景下。
## 1163. `cs.LG` - 学习更少：一种高效的动态双层降采样框架以实现更高效的政治优化 [PDF](https://arxiv.org/pdf/2509.22115), [HTML](https://arxiv.org/abs/2509.22115)
### Authors
Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding
### Background
批评自由的方法（如GRPO）通过从多个采样路径中估计优势来减少内存需求，但往往收敛较慢，因为关键的学习信号被大量非信息样本和标记稀释。这就提出了一个挑战：如何在保持高效的同时提高学习速度。
### Innovation
本文提出了一种名为动态双层降采样（D$^3$S）的框架，该框架通过优先选择最具有信息量的样本和标记来优化策略，减少无信息样本和标记的影响。D$^3$S结合了两个层面的优化：样本层面和标记层面。样本层面通过选择最大化优势方差的采样路径来提高策略梯度的效率；标记层面则优先考虑具有高优势值和政策熵的产品的标记，以确保政策在不确定性和影响力上都得到更新。此外，D$^3$S采用了一种受课程学习启发的动态降采样策略，以防止模型过度拟合高信号数据，该策略在初期进行激进降采样以加速学习，在后期逐渐放松以增强泛化能力。
### Conclusion
广泛的实验结果表明，将D$^3$S框架结合到高级强化学习算法中，不仅实现了最先进的性能和泛化能力，同时还能减少不同推理基准所需的样本和标记数量。详细代码已经附加在附录材料中，并将公开发布。
## 1164. `cs.LG` - 朝单纯形顶点推进：平滑矢量量化中代码崩溃的简单解决方案 [PDF](https://arxiv.org/pdf/2509.22161), [HTML](https://arxiv.org/abs/2509.22161)
### Authors
Takashi Morita
### Background
矢量量化通过将连续向量空间离散化为一组代表向量（码本），已在现代机器学习中广泛应用。尽管效果显著，但矢量量化面临根本难题：非差分可量化步骤阻碍了梯度反向传播。平滑矢量量化通过将码本书中的向量硬分配放松为码本书条目的加权组合（表示为简单向量与码本书的矩阵乘积）来解决这一问题。有效的平滑需要两个特性：（1）平滑量化器应接近于一热向量，确保近似紧凑；（2）所有码本书条目都应该被利用，以防止代码崩溃。现有方法通常分别解决这些要求。相比之下，本文提出了一种简单且直观的正则化方法，通过最小化每个单纯形顶点与其K个最近平滑量化器之间的距离，同时促进这两个目标。
### Innovation
本文提出了一种简单且直观的正则化方法，通过最小化每个单纯形顶点与其K个最近平滑量化器之间的距离，同时促进有效平滑的两个关键属性：平滑量化器应接近于一热向量并且所有码本书条目都应该被利用，以防止代码崩溃。
### Conclusion
实验表明，所提出的方法能更可靠地利用码本书并在此基准上表现出更好的性能，比之前的方案更加有效。
## 1165. `cs.LG` - 通过二次形式学习对称函数 [PDF](https://arxiv.org/pdf/2509.22184), [HTML](https://arxiv.org/abs/2509.22184)
### Authors
Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P
### Background
在本研究中，作者探索了一种通过从数据中学习相关的二次形式$x^T A x$来学习具有已知或未知群（即正交群）对称性的函数的方法。正交群保持特定的二次形式不变，作者利用这一特性，假设存在对称群的真实性来揭开潜在的对称性群。通过使用所对应的独特对称矩阵及其固有的对角形式，作者将合适的归纳偏差融入神经网络结构中，从而使模型更加简化和高效。此外，研究还扩展到更一般的情况，即函数通过一个对角（或乘积）群作用作用于输入向量元组。这种扩展分解使等变函数能够同时捕捉多个输入之间的依赖关系并保持固有的群对称性。
### Innovation
作者提出了一种创新的方法，通过从数据中学习二次形式来发现和学习具有已知或未知对称性的函数。这种方法特别针对正交群，可以简化和提高模型效率，同时在不破坏群对称性的情况下分解等变函数。此外，该研究还提出了一个更为通用的模型，可以处理输入向量元组，并且能捕捉到多个输入间的依赖关系，同时保持群对称性。
### Conclusion
通过实验，作者的研究成果显示了其在多项任务中的有效性，包括多项式回归、顶夸克标记和惯性矩预测。与基线方法相比，该模型不仅能够有效地发现潜在的对称性，而且在学习相应的等变函数方面也表现更佳。
## 1166. `cs.LG` - ASSESS: 陈述相似性的语义和结构评估框架 [PDF](https://arxiv.org/pdf/2509.22246), [HTML](https://arxiv.org/abs/2509.22246)
### Authors
Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo
### Background
陈述自形式化，即将自然语言陈述自动翻译成形式语言的技术，已经取得了显著进步。然而，自动评估度量标准的发展相对有限。现有的形式化陈述相似度度量标准往往难以平衡语义和结构信息。基于字符串的方法捕捉语法规则结构但忽略了语义意义，而基于证明的方法验证语义一致性但忽略了结构细微差别，并且在证明失败的情况下不会提供渐进的相似度评分。
### Innovation
为了应对这些问题，本文提出了一种新的评估框架——ASSESS（语义和结构评估框架），该框架整合了语义和结构信息，提供连续的相似度评分。ASSESS将形式化的陈述转化为运算符树，以捕捉其语法规则结构，然后使用我们全新的TransTED（转换树编辑距离）相似度度量策略计算相似度评分，该策略通过转换增强了传统的树编辑距离，增加了语义意识。
### Conclusion
为了严格验证，我们提出了EPLA（证明性和相似性评估），一个包含524对专家注释的形式化陈述对的新基准数据集，这些数据集源自miniF2F和ProofNet，具有语义证明可验证性和结构相似性的标签。实验结果表明，TransTED相似度在EPLA上超越了现有方法，达到了最先进的准确性，并拥有最高的柯帕系数。基准测试和代码将在不久的将来对外公开。
## 1167. `cs.LG` - 随机特征（及更广泛领域）的数据重构定律 [PDF](https://arxiv.org/pdf/2509.22214), [HTML](https://arxiv.org/abs/2509.22214)
### Authors
Leonardo Iurada,Simone Bombari,Tatiana Tommasi,Marco Mondelli
### Background
大型深度学习模型被发现具有记忆训练集部分数据的特性。理论上，这种记忆通常被解释为插值或标签拟合，经典研究表明，当模型中的参数数量 p 大于训练样本数量 n 时，就能实现这种记忆效果。本文从数据重构的角度探讨记忆现象，提出当 p 大于数据维度 d 乘以训练样本数量 n 时，就能实现数据重构。
### Innovation
本文展示了如何利用随机特征模型，在 p 远大于 d 乘以 n 的情况下，通过训练样本在特征空间中所span的子空间信息，重构出输入空间中的样本。进一步，提出了从模型参数重建数据集的优化方法，并验证了该方法在多种架构（随机特征、两层全连接和深层残差网络）上的有效性。
### Conclusion
研究表明，在 p 超过数据重构阈值 dn 时，可以恢复整个训练数据集。这项工作揭示了一条数据重构定律，这在理论和实践中都具有重要意义。
## 1168. `cs.LG` - 通过哈达玛过参数化张量列车进行多维数据核回归：动态图流案例 [PDF](https://arxiv.org/pdf/2509.22197), [HTML](https://arxiv.org/abs/2509.22197)
### Authors
Duc Thien Nguyen,Konstantinos Slavakis,Eleftherios Kofidis,Dimitris Pados
### Background
该论文提出了一种基于回归的框架，用于可解释的多维数据插补，称为核回归通过张量列车的哈达玛过参数化（KReTTaH）。此方法将插补问题转化为核希尔伯特空间中的回归问题，通过固定张量列车（TT）秩的张量实现参数效率，并通过哈达玛过参数化促进TT参数空间中的稀疏性。这种方法在处理缺失或时间变化的边流量时表现出色，尤其是在动态图流的情况下，可以无缝地整合基于图（拓扑）的先验知识。
### Innovation
该论文的创新点包括：1) 通过将插补问题转化为核希尔伯特空间中的回归问题，采用非参数化方法；2) 通过固定张量列车（TT）秩的张量实现和低维黎曼流形上的参数化表示提高参数效率；3) 利用哈达玛过参数化促进TT参数空间中参数的稀疏性；4) 通过在黎曼流形上的光滑逆问题求解进行学习；5) 在实际的图数据集上证明了该方法比最先进的方法（包括非参数张量和神经网络方法）更优，特别是在处理动态图流中的缺失数据方面表现良好。
### Conclusion
通过实验测试，在实际的图数据集上证明了KReTTaH方法在插补缺失和时间变化的边流量方面表现出更优异的效果。该方法通过无缝整合图（拓扑）先验知识，展示了其在动态图流应用中的灵活性。
## 1169. `cs.LG` - 在大规模语言模型中细粒度的不确定性分解：一种光谱方法 [PDF](https://arxiv.org/pdf/2509.22272), [HTML](https://arxiv.org/abs/2509.22272)
### Authors
Nassim Walha,Sebastian G. Gruber,Thomas Decker,Yinchong Yang,Alireza Javanmardi,Eyke Hüllermeier,Florian Buettner
### Background
随着大型语言模型（LLMs）在多种应用中的广泛应用，获得其预测不确定性的可靠度量变得至关重要。区分由输入数据本身固有不确定性（aleatoric不确定性）引起的不确定性与仅由模型限制引起的不确定性（epistemic不确定性）是关键，以便有效地解决每种不确定性来源。
### Innovation
本文提出了一种名为Spectral Uncertainty的新方法，这是一种基于量子信息理论中的Von Neumann熵来量化和分解LLMs中不确定性的方法。与现有基线方法不同，该方法采用了细粒度的语义相似性表示，能够细致地区分模型响应中各种语义解释的不确定性。
### Conclusion
实证研究证明，Spectral Uncertainty在多种模型和基准数据集上估计aleatoric不确定性及总不确定性方面优于最先进的方法。
## 1170. `cs.LG` - Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics [PDF](https://arxiv.org/pdf/2509.22207), [HTML](https://arxiv.org/abs/2509.22207)
### Authors
Mu Huang,Linning Xu,Mingyue Dai,Yidi Shao,Bo Dai
### Background
在流体力学中，模拟用户定义目标下的物理合理的轨迹是一项基本但具有挑战性的任务。尽管基于粒子的模拟器能够高效地再现前向动力学，但逆向推理仍然非常困难，尤其是在耗散系统中，系统动力学不可逆，基于优化的求解器速度慢、不稳定且经常无法收敛。现有的神经模拟器通过拟合反向数据来近似逆向动力学，但这类方法无法真正反向运行物理模型。因此，亟需一种能够确保双向一致性的统一框架来解决这一问题。
### Innovation
本文提出了可逆图网络模拟器（R-GNS），这是一种统一框架，能够在单一图结构中强制执行双向一致性。R-GNS基于残差可逆消息传递设计，通过共享参数将前向动力学与逆向推理相结合，实现准确预测和合理的初始状态高效恢复。相比于基于优化的基线，R-GNS在三个耗散基准测试（Water-3D，WaterRamps和WaterDrop）上不仅提高了准确性和一致性，而且逆向推理速度提高了100多倍。此外，在前向模拟中，R-GNS达到了强大的GNS基线的速度；在目标条件任务中，它实现了逐步优化的消除和程度级数的速度提升。R-GNS进一步展示了其在复杂目标形状（例如字符“L”和“N”）上进行生动、物理一致轨迹的能力。这是首个结合前向和逆向模拟的可逆框架，用于耗散流体系统.
### Conclusion
本研究开发了一种可逆图网络模拟器（R-GNS），它能够在单一图结构中实现双向一致性的前向和反向模拟。通过残差可逆消息传递，R-GNS能够实现高效的初始状态恢复和准确的动力学预测。实验结果表明，R-GNS在耗散基准测试中具有更高的准确性和一致性，并且在反向推理速度上明显优于基于优化的基线。在目标条件任务中，R-GNS展示了其高效性和精确性。到目前为止，R-GNS是首个将前向和反向模拟统一起来的可逆框架，用于耗散流体系统。
## 1171. `cs.LG` - 波let-诱发的旋转编码：RoPE与图的结合 [PDF](https://arxiv.org/pdf/2509.22259), [HTML](https://arxiv.org/abs/2509.22259)
### Authors
Isaac Reid,Arijit Sehanobish,Cedrik Höfs,Bruno Mlodozeniec,Leonhard Vulpius,Federico Barbero,Adrian Weller,Krzysztof Choromanski,Richard E. Turner,Petar Veličković
### Background
介绍了WIRE（Wavelet-Induced Rotary Encodings），这是一种将流行的旋转位置编码（RoPE）扩展到图结构数据的方法。RoPE在LLMs和ViTs中很受欢迎，WIRE在此基础上进行扩展，适用于更广泛的场景，特别是对于网格图可以恢复RoPE的功能。WIRE还具有诸多优越的理论性质，包括节点顺序置换下的等变性、线性注意力的兼容性，以及在某些假设下，对图电阻距离的渐近依赖性。研究者在多种合成和实际任务中测试了WIRE的有效性，包括识别单一颜色子图、点云语义分割和更多标准的图基准测试，发现WIRE在图结构重要的设置中表现出色。
### Innovation
WIRE将流行的旋转位置编码RoPE扩展到了图结构数据，使得RoPE在网格图中能够恢复其功能，并且WIRE还具有诸多优越的理论性质，包括节点顺序置换下的等变性、线性注意力的兼容性，以及在某些假设下对图电阻距离的渐近依赖性。
### Conclusion
通过在多种合成和实际任务中的测试，WIRE被证明在图结构重要的设置中表现出色。
## 1172. `cs.LG` - 去除还是隐藏？通过抑制伪消失神经元实现稳健的消失学习 [PDF](https://arxiv.org/pdf/2509.22263), [HTML](https://arxiv.org/abs/2509.22263)
### Authors
Nakyeong Yang,Dong-Kyum Kim,Jea Kwon,Minsung Kim,Kyomin Jung,Meeyoung Cha
### Background
大规模训练于网页级数据的语言模型有可能记住私人或敏感信息，这带来了严重的隐私风险。虽然一些消学习方法可以缓解这些风险，但在后续训练中仍然可能重新学习，导致遗忘信息部分再现。已有方法仅实现了表面的对齐：它们不但不能忠实删除目标知识，还会生成伪消失神经元作为负影响的放大器来掩盖这一事实。
### Innovation
本文引入了Ssiuu，这是一种新的消学习方法，采用归因引导正则化来防止负影响的放大并忠实删除目标知识，从而克服现有方法的局限性。实验结果表明，该方法能够可靠地删除目标知识，并在两种实际的重新训练场景中优于强有力的基础方法：（1）敌对注入私人数据；（2）使用指令跟随基准进行良性攻击。研究结果突显了稳健且忠实的消学习方法对于语言模型安全部署的必要性。
### Conclusion
我们的发现强调了在安全部署语言模型时，需要采用稳健且忠实的消学习方法来保护隐私。
## 1173. `cs.LG` - 解锁混合专家在任务感知时序分析中的力量 [PDF](https://arxiv.org/pdf/2509.22279), [HTML](https://arxiv.org/abs/2509.22279)
### Authors
Xingjian Wu,Zhengyu Li,Hanyin Cheng,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Bin Yang
### Background
时间序列分析被广泛应用于天气预报、金融欺诈检测、物联网系统中的数据补缺以及动作识别等实际应用场景。混合专家模型（MoE）作为一种强大的网络架构，尽管在自然语言处理方面显示出有效性，但由于其任务无关性路由机制及建模通道相关性的不足，仍然难以适应多样化的时序分析任务。
### Innovation
该研究提出了一种新型MoE基时序分析框架——PatchMoE，旨在支持不同任务中的复杂知识利用，从而实现任务意识。通过观察到层次表示在不同任务中有所不同（如预测 vs 分类），该研究提出了一种循环噪声门控机制，用于在路由中利用层次信息，从而获得特定任务的能力。路由策略在时间序列标记的时序和通道维度上操作，并受到精心设计的时间和通道负载均衡损失鼓励，以建模复杂的时序和通道相关性。
### Conclusion
在五个下游任务上的全面实验证明了PatchMoE的先进性能。
## 1174. `cs.LG` - 基于在线凸优化的分布式关联记忆 [PDF](https://arxiv.org/pdf/2509.22321), [HTML](https://arxiv.org/abs/2509.22321)
### Authors
Bowen Wang,Matteo Zecchin,Osvaldo Simeone
### Background
关联记忆（AM）能够实现提示-响应回忆，最近表明关联记忆是现代神经架构如变换器运作的关键机制。本文关注的是一种分布式环境，各个代理节点保留了本地的关联记忆，并且能够召回自身的关联及部分其它代理节点的信息。
### Innovation
提出了一个分布式在线梯度下降方法，通过通信树实现不同代理节点上的本地关联记忆优化，其理论分析证明了次线性遗憾保证。实验结果表明，所提出的协议在在线优化基线中表现优异。
### Conclusion
研究表明，基于在线凸优化的分布式关联记忆方法在保持现有动态环境中性能的预期目标上取得了成功。
## 1175. `cs.LG` - SoDaDE: 使用小型变压器模型的溶剂数据驱动嵌入 [PDF](https://arxiv.org/pdf/2509.22302), [HTML](https://arxiv.org/abs/2509.22302)
### Authors
Gabriel Kitso Gibberd,Jose Pablo Folch,Antonio Del Rio Chanona
### Background
计算机表示在推动化学中的机器学习算法的增长方面变得至关重要。机器学习表明，可以从数据中学习到有意义的表示，但由于化学数据集有限，这些表示通常是基于广泛的数据集训练的，包含许多不同分子类型浅显的信息。例如，通用指纹缺乏特定溶剂的物理上下文。溶剂的使用是化学工业中一个相关的气候问题，绿色溶剂的替代研究兴趣激增。为了支持这一研究，本文提出了一种新的溶剂表示方案——溶剂数据驱动嵌入（SoDADE），以小型变压器模型和溶剂性质数据集为基础创建溶剂指纹。
### Innovation
本文提出了一个名为SoDADE的新溶剂表示方案，使用小型变压器模型和溶剂性质数据集来生成溶剂指纹。与先前的方法相比，SoDADE在最近发表的数据集上预测产率时表现出色，证明了使用小型数据集可以生成基于数据的指纹，并为其他应用建立了工作流程。
### Conclusion
本文通过使用SoDADE展示了基于数据的溶剂指纹可以通过小型数据集构建，并建立了一个工作流程，其他应用可以探索。
## 1176. `cs.LG` - 向更现实的轴承故障诊断机器学习模型评估迈进 [PDF](https://arxiv.org/pdf/2509.22267), [HTML](https://arxiv.org/abs/2509.22267)
### Authors
João Paulo Vieira,Victor Afonso Bauler,Rodrigo Kobashikawa Rosa,Danilo Silva
### Background
机械旋转设备的安全性和操作效率依赖于可靠的轴承故障检测。尽管深度学习在控制环境中表现良好，但在实际应用中，许多研究因方法学缺陷，尤其是在数据泄露问题上的不足，未能有效应用。本文探讨了基于振动的轴承故障诊断中的数据泄露问题及其对模型评估的影响，表明常用的数据分割策略引入了虚假的相关性，使性能指标虚增。为了应对这一问题，提出了基于轴承的数据分割方法，确保训练和测试使用的物理部件不重叠，并将分类任务重新定义为多标签问题，以便检测共现的故障类型和使用基于先验概率的宏观AUROC度量。此外，还考察了数据集多样性对泛化的影响，研究表明独有的训练轴承数量是实现稳健性能的关键因素。该研究针对三个广泛采用的数据集（CWRU、帕德博恩大学（PU）、渥太华大学（UORED-VAFCLS））进行了评估，强调了数据泄露感知的评估协议的重要性，并提供了数据集分割、模型选择和验证的实际指南，促进了工业故障诊断应用中更可信的机器学习系统的开发。
### Innovation
提出了基于轴承的数据分割方法，确保训练和测试使用的物理部件不重叠；将分类任务重新定义为多标签问题，使共现故障类型能够被检测；使用了基于先验概率的宏观AUROC度量，并考察了数据集多样性对泛化的影响，明确了独有的训练轴承数量是实现稳健性能的关键因素。
### Conclusion
本研究强调了数据泄露感知的评估协议的重要性，并提供了实际的指导原则，促进了工业故障诊断中更可信的机器学习系统的开发。
## 1177. `cs.LG` - 上下文和多样性起作用：世界模型中上下文内学习的涌现 [PDF](https://arxiv.org/pdf/2509.22353), [HTML](https://arxiv.org/abs/2509.22353)
### Authors
Fan Wang,Zhiyuan Chen,Yuxuan Zhong,Sunjian Zheng,Pengtao Shao,Bo Yu,Shaoshan Liu,Jianan Wang,Ning Ding,Yang Cao,Yu Kang
### Background
预测环境动态是生物神经系统和通用实体AI适应周围环境的关键。然而，现有的方法依赖于静态的世界模型，在遇到新的或罕见的配置时会失败。
### Innovation
本文贡献了三点：（1）形式化了世界模型的上下文内学习，并识别了两个核心机制：环境识别和环境学习；（2）推导了两个机制的误差上界，揭示了这些机制的产生过程；（3）通过实验验证了世界模型中存在不同的上下文内学习机制，并进一步探讨了不同数据分布和模型架构如何以理论一致的方式影响上下文内学习。
### Conclusion
这些发现展示了自我适应的世界模型的潜力，并突显了上下文内学习（ICEL）的产生背后的关键因素，最重要的是长期上下文和多样环境的必要性。
## 1178. `cs.LG` - HEAPr：基于Hessian矩阵的高效原子专家输出空间裁剪 [PDF](https://arxiv.org/pdf/2509.22299), [HTML](https://arxiv.org/abs/2509.22299)
### Authors
Ke Li,Zheng Yang,Zhongbin Zhou,Feng Xue,Zhonglin Jiang,Wenxiao Wang
### Background
混合专家（MoE）架构在大规模语言模型（LLMs）中表现出色且具有较低的推理成本，但其庞大的参数数量导致内存需求高昂，限制了实际部署。尽管现有剪枝方法主要集中在专家级别的剪枝上，但这一粗粒度的方法往往导致显著的精度下降。
### Innovation
HEAPr引入了一种新的剪枝算法，将专家分解为更小的不可分割的原子专家，从而实现更精确和灵活的原子专家剪枝。该方法利用类似Optimal Brain Surgeon（OBS）理论的二阶信息来度量每个原子专家的重要性，并通过发挥原子专家的内在属性，将二阶信息转换为原子专家参数的二阶信息，进而简化为原子专家输出的二阶信息。这种方法将空间复杂度从O(d^4)减少到O(d^2)，并且只需要进行两次前向传递和一次后向传递。
### Conclusion
HEAPr在广泛的压缩比和基准测试中表现出色，特别是在DeepSeek MoE和Qwen MoE家族模型中，HEAPr在20%~25%的压缩比下几乎达到了无损压缩效果，并减少了近20%的FLOPs。
## 1179. `cs.LG` - 渐进权重加载：在资源受限环境中加速初始推断并逐步提升性能 [PDF](https://arxiv.org/pdf/2509.22319), [HTML](https://arxiv.org/abs/2509.22319)
### Authors
Hyunwoo Kim,Junha Lee,Mincheol Choi,Jeonghwan Lee,Jaeshin Cho
### Background
深度学习模型变得越来越大、越来越复杂，导致内存消耗和计算需求增加。这使得模型加载时间和初始推理延迟增加，特别是在需要频繁加载和卸载的移动和对延迟敏感的环境中，这直接影响用户体验。知识蒸馏（KD）通过将大容量教师模型压缩为较小的学生模型来提供一种解决方案，但常常以牺牲性能为代价。为了解决这个折衷方案，我们提出了一种名为“渐进权重加载”（PWL）的新技术，该技术可以通过首先部署一个轻量级的学生模型，然后逐步用预训练的教师模型替换其层，从而实现快速初始推理。
### Innovation
我们提出了一种名为‘渐进权重加载’（PWL）的新技术，它可以实现快速初始推理，方法是首先部署一个轻量级的学生模型，然后逐步用一个预训练的教师模型替换其层。为了支持无缝层替换，我们引入了一种新的训练方法，不仅在学生和教师的层之间对中间特征表示进行对齐，而且还提高了学生模型的整体输出性能。我们的实验表明，使用PWL训练的模型在保持竞争力的蒸馏性能的同时，其准确率随着教师层的加载而不断提高，最终达到了完整教师模型的准确率，而不会牺牲初始推理速度。
### Conclusion
PWL特别适用于动态、资源受限的部署场景，在这些场景中，响应时间和性能都是关键因素。
## 1180. `cs.LG` - 通过共享网络实现自适应策略骨干 [PDF](https://arxiv.org/pdf/2509.22310), [HTML](https://arxiv.org/abs/2509.22310)
### Authors
Bumgeun Park,Donghwan Lee
### Background
强化学习（RL）在多个领域已经取得了显著成果，但学习最优策略通常需要大量的交互数据，这限制了其实用部署。一种常见的解决方法是利用先验知识，如预收集的数据集或参考策略，但这种先验知识在训练和部署任务不匹配时效果会下降。虽然已有工作试图解决此问题，但主要集中在同分布场景。
### Innovation
本文提出了一种名为自适应策略骨干（APB）的元迁移RL方法，它在共享骨干前后插入了轻量级线性层，从而实现了参数高效微调(PEFT)，同时在适应期间保留了先验知识。这在同分布之外的任务中提高了样本效率。
### Conclusion
实验结果显示，APB在标准RL方法上提高了样本效率，并能在元RL基线通常会失败的分布外（OOD）任务中实现适应。
## 1181. `cs.LG` - 随机激活函数 [PDF](https://arxiv.org/pdf/2509.22358), [HTML](https://arxiv.org/abs/2509.22358)
### Authors
Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou
### Background
论文介绍了随机激活函数这一新颖策略。在大规模语言模型的前向传播层中，这些激活函数随机选择几种非线性函数，具体来说在本研究中，根据伯努利抽样的结果在SILU或RELU之间选择。这种方法规避了RELU优化中遇到的问题，即负输入时的恒定形状会导致梯度无法流入的问题。研究者通过两种方式应用这一策略：一种是在预训练中使用随机激活函数，在微调阶段使用RELU，以提供稀疏的潜在向量，从而减少推理时的运算量并显著提升CPU速度；另一种是在生成中评估随机激活函数的表现。
### Innovation
这种随机激活函数策略在很大程度上解决了RELU优化问题，通过随机在SILU或RELU之间切换激活函数，避免了梯度消失的问题。此外，研究者将此类随机激活函数应用于两种场景：一种是在预训练阶段减少计算量并提高推理速度，另一方面在生成阶段提供了一种控制文本生成多样性的新方法。
### Conclusion
研究发现随机激活函数策略在多个方面优于从头开始使用RELU训练模型。同时，在生成中，随机激活函数的表现仅略逊于SILU结合温度缩放的最优确定式非线性函数。这提供了一种现有的替代策略，以控制生成文本的多样性。
## 1182. `cs.LG` - 在大型音频语言模型中探究可信度 [PDF](https://arxiv.org/pdf/2509.22363), [HTML](https://arxiv.org/abs/2509.22363)
### Authors
Lovenya Jain,Pooneh Mousavi,Mirco Ravanelli,Cem Subakan
### Background
链式思维（CoT）表示是否能准确反映模型的决策过程，并且可以作为可靠的解释。先前的研究显示，基于文本的语言大模型的CoT经常不忠实。在大型音频语言模型（LALMs）中，这一问题至今未被探索，特别是在安全敏感的应用中，CoT的忠实性至关重要。此外，在LALMs中的推理更为复杂，因为模型首先需要从音频中提取相关信息，然后才能进行推理。
### Innovation
通过应用针对性干预措施（包括改写、填充词插入、提前回答以及引入错误），对两个具有挑战性的推理数据集（SAKURA和MMAR）进行实验，以研究LALMs生成的CoT的忠实性。
### Conclusion
实验结果显示，LALMs通常会产生看似忠实于其内部决策过程的CoT。
## 1183. `cs.LG` - 神经特征几何演变为离散里奇流 [PDF](https://arxiv.org/pdf/2509.22362), [HTML](https://arxiv.org/abs/2509.22362)
### Authors
Moritz Hehl,Max von Renesse,Melanie Weber
### Background
深度神经网络通过输入数据流形的复杂几何变换学习特征表示。尽管这些模型在各个领域表现出了很好的效果，但对其神经特征表示的理解仍然不完整。本文通过离散几何的视角研究神经特征的几何结构。由于输入数据流形通常是不可观测的，因此用几何图来近似它，这些图编码局部相似结构。作者提供了关于这些图在训练过程中的理论结果，展示了非线性激活在塑造前馈神经网络特征几何结构中的关键作用。此外，作者发现几何变换类似于这些图上的离散里奇流，表明神经特征几何演化类似于里奇流。这些结论得到了对超过20,000个使用二分类任务训练的前馈神经网络进行实验的支持。研究发现，类群可分性的出现对应于图表示中社区结构的出现，这与离散里奇流动力学有关。
### Innovation
提出了通过将复杂几何变换与离散里奇流动态进行比较来本地评估几何变换的一种新框架，进而为前馈神经网络的几何特征演化提供了一种理解方式。这一工作揭示了神经特征几何演化与里奇流的动力学之间的关系，并提出了一些实际的设计原则，包括基于几何感知的早停启发式和网络深度的选择标准。
### Conclusion
本文研究发现，非线性激活在神经特征几何演化中起着关键作用，且神经特征几何演化类似于离散里奇流。通过将几何变换与离散里奇流进行比较，作者引入了一种新的评估框架，并提出了一些实用设计原则。
## 1184. `cs.LG` - 基于最小生成树和渐近梯度的多目标超图划分多层次框架 [PDF](https://arxiv.org/pdf/2509.22294), [HTML](https://arxiv.org/abs/2509.22294)
### Authors
Yingying Li,Mingxuan Xie,Hailong You,Yongqiang Yao,Hongwei Liu
### Background
本文提出了一种基于新颖的多目标非凸约束松弛模型的高效超图划分框架。该框架专门针对不同规模的数据集设计了两种不同的最小生成树（MST）策略以优化分区质量并避免局部最优解。对于小规模数据集，使用Prim算法构建最小生成树并通过修剪和聚类进行优化；对于大规模数据集，则选择一部分代表性节点构建较小的MST，并对剩余节点进行相应的分配以降低复杂度。实验结果表明，该算法在2、3和4路划分中比KaHyPar平均减少约2%到5%的切边数，最高可减少35%的特定实例。特别是在加权顶点集上，所提算法明显优于包括KaHyPar、hMetis、Mt-KaHyPar和K-SpecPart在内的最新分区器，显示出其卓越的分区质量和竞争力。此外，提出的改进策略能够提高hMetis的分区结果最多16%。综合评估和参数敏感性分析进一步证明了该算法的竞争性和性能权衡特性。
### Innovation
本文创新性地提出了一种基于最小生成树和渐近梯度的多层次框架，用于多目标超图划分。采用了新颖的多目标非凸约束松弛模型，并在分区过程中引入了基于贪婪迁移、交换和递归最小生成树聚类的精加工策略，以提高分区质量，避免陷入局部最优解。此外，为不同规模的数据集设计了两种不同的MST策略，即对于大规模数据集选择代表性节点构建MST，从而降低计算复杂度，同时提出了改进策略来进一步优化分区结果。
### Conclusion
实验结果证明了提出算法的优越性，相较于其他最新算法，该算法在特定实例上可减少高达35%的切边数，特别是在加权顶点集上的表现优于包括KaHyPar、hMetis、Mt-KaHyPar和K-SpecPart在内的最新分区器，显示出其在实际应用中的显著优势。
## 1185. `cs.LG` - Aurora: 向通用生成型多模态时间序列预测迈进 [PDF](https://arxiv.org/pdf/2509.22295), [HTML](https://arxiv.org/abs/2509.22295)
### Authors
Xingjian Wu,Jianxin Jin,Wanghui Qiu,Peng Chen,Yang Shu,Bin Yang,Chenjuan Guo
### Background
时间序列预测中跨领域泛化非常重要，因为相似的历史信息可能会因为领域的特定特征导致不同的未来趋势。近年来的研究主要集中在建立单一模态的时间序列基础模型和端到端的多模态监督模型上。但是前者缺乏对文本、图像等模态中所含领域知识的显式利用，限制了性能；后者针对端到端场景，不支持跨领域的零样本推理。
### Innovation
提出的Aurora是一种多模态时间序列基础模型，支持多模态输入和零样本推理。它基于跨领域多模态时间序列数据集进行预训练，能够自适应地抽取并关注相应的文本或图像模态中的关键领域知识，从而具备强大的跨领域泛化能力。Aurora通过分词、编码和蒸馏提取多模态领域知识，并利用模态导向的多头自注意力机制将它们注入到时间建模中。在解码阶段，多模态表示用于生成未来的条件和原型，贡献了一种新颖的原型导向流匹配方法，以生成概率预测。
### Conclusion
在广泛认可的标准基准TimeMMD、TSFM-Bench和ProbTS上的全面实验表明，Aurora在单模态和多模态场景下均实现了持续的SOTA性能。
## 1186. `cs.LG` - 无线语义通信中的条件去噪扩散自编码器 [PDF](https://arxiv.org/pdf/2509.22282), [HTML](https://arxiv.org/abs/2509.22282)
### Authors
Mehdi Letafati,Samad Ali,Matti Latva-aho
### Background
现有的语义通信（SemCom）系统旨在学习从低维度语义到高维度真实信号之间的映射。尽管这是一个类似于“域翻译”问题，现有的框架主要集中在信道自适应的神经编码-解码方案上，缺乏对信号分布的完整探索。现有的方法大多采用基于自编码器的架构，其中编码与匹配的解码器紧密耦合，这在实践中造成了可扩展性问题。由于这些缺陷，本文提出了一种基于扩散自编码器模型的方法来解决语义通信中的问题，其目标是从语义空间到真实的概率分布中学习一个“语义到干净信号”的映射，通过神经编码器和条件扩散模型（CDiff）在语义接收端实现信号空间去噪，并将接收到的语义潜在变量作为解码过程的条件输入，引导解码过程趋向于发射端意图的语义。理论上证明所提出的解码模型是一个真实数据的一致估计器，并进行了详细的仿线性和MNIST的数据集的实验证明了与经典自编码器和变分自编码器相比的性能优势。进一步的仿真还扩展到多用户语义通信，以识别在更具现实性的设定中的主导因素。
### Innovation
本文提出了一个基于扩散自编码器模型的解决方案，旨在解决当前语义通信系统中存在的缺陷。模型可以学习从语义空间到真实概率分布之间的映射，通过神经编码器和条件扩散模型实现信号空间去噪，进一步通过解码过程中的条件输入引导语义。这使得能够更灵活地处理信号空间中的噪声，提高语义通信的性能。此外，还提供了理论证明和实验验证，证明了新的方法在多个数据集上具有更好的性能，并能够扩展到多用户环境。
### Conclusion
本文通过理论证明和仿真实验验证了该方法的有效性，证明了基于扩散自编码器的方法在语义通信中的鲁棒性和优越性。这种方法可以更灵活地处理信号噪声，且适用于多用户环境，奠定了新的语义通信基础。
## 1187. `cs.LG` - SpinGPT：一种应用于正确玩Three-Player在线扑克的大型语言模型方法 [PDF](https://arxiv.org/pdf/2509.22387), [HTML](https://arxiv.org/abs/2509.22387)
### Authors
Narada Maugin,Tristan Cazenave
### Background
Counterfactual Regret Minimization (CFR) 算法及其变种使得能够开发出比顶级人类玩家更强的1v1现金赛扑克机器人，并在六人游戏格式中与人类竞争。但是，CFR随着玩家数量的增加计算复杂性呈指数级增长。在三人或更多玩家的游戏中，遵循纳什均衡不再能保证不败。现有的这些限制大大限制了CFR在最流行的赛事格式——锦标赛中的应用。
### Innovation
鉴于大型语言模型（LLM）在国际象棋和外交游戏中的成功应用，作者提出了SpinGPT，这是第一个专门针对三玩家流行的在线扑克格式（Spin & Go）的大型语言模型。SpinGPT分为两阶段训练：（1）基于32万次高级专家决策的监督微调；（2）基于27万手解算器生成的决策的强化学习。实验结果表明SpinGPT在78%的决策中表现与解算器相当，并在1v1对局中与Slumbot对战3万局，实现了13.4±12.9$/百手的成绩。
### Conclusion
这些结果表明，大型语言模型可能是处理多玩家不完美信息博弈，如扑克的新途径。
## 1188. `cs.LG` - Fast-Forward Lattice Boltzmann: 学习基于物理的神经运算器的动能行为 [PDF](https://arxiv.org/pdf/2509.22411), [HTML](https://arxiv.org/abs/2509.22411)
### Authors
Xiao Xue,Marco F.P. ten Eikelder,Mingyang Gao,Xiaoyuan Cheng,Yiming Yang,Yi He,Shuo Wang,Sibo Cheng,Yukun Hu,Peter V. Coveney
### Background
格子Boltzmann方程（LBE）基于动能理论，能够通过描述单粒子分布函数（PDFs）的演化来捕捉复杂的流场行为。尽管LBE在描述复杂流场行为中取得了成功，但由于碰撞内核对严格时间步长的要求，数值求解LBE仍然是计算密集型的。
### Innovation
本文引入了一种基于物理的神经运算器框架，用于LBE，该框架能够在不进行逐步积分的情况下预测长时间窗口，从而有效地绕过了显式求解碰撞内核的需求。所提出的模型整合了LBE的内在矩匹配约束，以及整个分布场的全局不变性，使模型能够捕捉底层动力学系统的复杂动态。该框架在离散化不变性方面，使得训练于粗网格上的模型能够泛化到更细的网格（动力学超分辨率）。另外，该方法对底层碰撞模型的具体形式是不知的，这使得其能够在不同动力学数据集上天然适用。
### Conclusion
我们的结果表明，该模型在复杂流场场景中具有鲁棒性，包括von Karman涡脱落、喷射断裂和气泡粘附。这为建模动力学系统提供了新的数据驱动的方法。
## 1189. `cs.LG` - 部分参数更新以实现高效分布式训练 [PDF](https://arxiv.org/pdf/2509.22418), [HTML](https://arxiv.org/abs/2509.22418)
### Authors
Anastasiia Filippova,Angelos Katharopoulos,David Grangier,Ronan Collobert
### Background
现有的低通信分布式训练方法通过在稀疏的全局同步之间进行多次本地更新来减少通信需求，但这些方法的效率仍待提高。
### Innovation
提出了一个在减少峰值内存使用和训练FLOPs的同时，通过约束反向传播以减少跨节点激活交换的方法。具体而言，每个节点只更新固定的一小部分参数，而另一部分保持冻结。
### Conclusion
在1.3B参数的语言模型上进行的实验表明，这种方法在与先前低通信方法相同的标记数量和带宽预算下匹配了困惑度，同时减少了训练FLOPs和峰值内存使用。
## 1190. `cs.LG` - 谱塌缩驱动深度连续学习中可塑性的丧失 [PDF](https://arxiv.org/pdf/2509.22335), [HTML](https://arxiv.org/abs/2509.22335)
### Authors
Naicheng He,Kaicheng Guo,Arjun Prakash,Saket Tiwari,Ruo Yu Tao,Tyrone Serapio,Amy Greenwald,George Konidaris
### Background
本文探讨了为什么在深度连续学习中，深度神经网络会从‘可塑性丧失’的问题中受到影响，即在无需重新初始化参数的情况下无法学习新任务。这种失败出现在从初始学习新任务时，先验存在的意义曲率方向消失且梯度下降变得无效。背景文章试图说明为何目前的算法难以在这种条件下有效训练，以及它们如何导致网络可塑性的丧失。
### Innovation
文章提出了一个新的概念——τ-训练能力（τ-trainability），用于表征成功训练所需的基本条件，并将目前保持可塑性的算法统一在这一框架下。文章进一步探讨了海森矩阵谱塌缩的Kronecker因子近似方法，并由此提出了两种正则化改进方法：维持有效特征秩和应用L2惩罚。这些改进措施通过实验被证实可以有效保持网络的可塑性，解决了论文开始提出的问题。
### Conclusion
结合这两种正则化器，可以有效地保持深度连续学习中的可塑性。这是通过对海森矩阵谱塌缩直接进行处理得以实现的，提高了网络在连续学习场景中的性能。
## 1191. `cs.LG` - ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation [PDF](https://arxiv.org/pdf/2509.22402), [HTML](https://arxiv.org/abs/2509.22402)
### Authors
Nan Tang,Jing-Cheng Pang,Guanlin Li,Chao Qian,Yang Yu
### Background
视觉强化学习（RL）在机器人操作中的奖励设计仍然是一个关键瓶颈。在仿真环境中，奖励通常基于目标位置的距离设计，但在现实世界的视觉环境中，由于感觉和知觉的限制，精确的位置信息往往不可用。
### Innovation
研究提出了一种通过从图像中提取关键点隐式推断空间距离的方法。在此基础上，引入了奖赏学习与预见模型（ReLAM），这是一种新颖的框架，能够自动从无动作视频示范中生成密集、结构化的奖赏。ReLAM 首先学习一个预见模型作为规划器，在最终目标的最佳路径上提出中间关键点为基的子目标，直接构建一个与任务几何目标相一致的结构化学习课程。基于预见的子目标，提供连续的奖赏信号，使用分层强化学习（HRL）框架训练低级、目标导向的策略，并具有可证明的次优性界。
### Conclusion
在复杂的、长时操作任务上进行的大量实验表明，ReLAM 显著加速学习并取得了优于最新方法的性能。
## 1192. `cs.LG` - SurvDiff: 一种用于生存分析生成合成数据的扩散模型 [PDF](https://arxiv.org/pdf/2509.22352), [HTML](https://arxiv.org/abs/2509.22352)
### Authors
Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel
### Background
生存分析是临床研究中的关键工具，通过建模如转移、疾病复发或患者死亡等时间事件结果。与标准表型数据不同，生存数据通常因为脱落或失访而导致事件信息不完整，这为合成数据生成带来了独特挑战。在合成数据生成中，保持事件时间分布的准确性和保存删失机制对于临床研究至关重要。现有的生成模型在处理生存数据方面的表现不尽如人意，特别是在事件时间分布的真实性和删失机制的保留上。
### Innovation
本文提出了SurvDiff，一种专为生存分析且适用于生成合成数据的端到端扩散模型。其创新点在于通过联合生成混合型协变量、事件时间和右删失，并遵循基于生存分析调整的损失函数来捕捉数据生成机制。这种损失函数编码了时间事件结构，直接优化了下游生存任务，确保SurvDiff (i) 能够再现真实的事件时间分布，(ii) 能够保留删失机制。
### Conclusion
在多个数据集上的实验表明，SurvDiff在分布保真度和多个医学数据集的下游评估指标上都优于现有的最先进生成基线。据我们所知，这是第一个专门设计用于生成合成生存数据的扩散模型。
## 1193. `cs.LG` - Flood 簇：数百万点的大规模持久同调计算 [PDF](https://arxiv.org/pdf/2509.22432), [HTML](https://arxiv.org/abs/2509.22432)
### Authors
Florian Graf,Paolo Pellizzoni,Martin Uray,Stefan Huber,Roland Kwitt
### Background
本文主要解决了大规模欧几里得点云数据中计算持久同调（PH）的问题，这是为了适应后续的机器学习任务。使用最常用的 Vietoris-Rips 复杂性会产生指数级增长，这对计算造成了重大限制。尽管有更可扩展的选择，例如 Alpha 复杂性和稀疏 Rips 近似，但它们仍然会导致过多的单纯形数量，这在计算复杂性构建和后续持久同调计算中都是一个问题。这个问题妨碍了这些方法在大规模点云数据中的应用。
### Innovation
本文引入了 Flood 簇，这一概念受到 Alpha 簇和 Witness 簇构建优点的启发。具体而言，在给定的滤波值 $r at 0$ 下，Flood 簇包含了所有完全被半径为 $r$ 的球覆盖的 Delaunay 三角剖分的单纯形子集。这种构建方法使得持久同调计算更加高效，并具有多种有益的理论特性，且易于 GPU 并行化。实验表明，在 3D 点云数据上可以计算至二维的大规模持久同调，特别是在几何或拓扑复杂性的对象分类任务中，这一规模扩展能力尤为重要，表现出优于其他持久同调基方法和基于点云数据的神经网络的性能。
### Conclusion
本文通过引入 Flood 复杂性，有效地解决了大规模点云数据持久同调计算的问题。实验表明，Flood 复杂性可以实现数百万点的大规模持久同调计算，在复杂对象分类任务中表现出高性能。
## 1194. `cs.LG` - 基于角色感知的多模态联邦学习系统用于检测钓鱼网页 [PDF](https://arxiv.org/pdf/2509.22369), [HTML](https://arxiv.org/abs/2509.22369)
### Authors
Bo Wang,Imran Khan,Martin White,Natalia Beloff
### Background
该研究旨在开发一种联邦、多模态的钓鱼网站检测器，该检测器支持URL、HTML和图像输入，但不需要在预设模式下绑定客户端。为此，研究在TR-OP和WebPhish数据集上测试了该检测器的性能，并通过TheTR-OP数据集的结果，展示了其在图像子集和文本数据集中的准确性和误报率。
### Innovation
研究提出了一种基于角色感知桶聚合的方法，该方法基于FedProx，受到Mixture-of-Experts和FedMM的启发。该方法摒弃了可学习的路由，并采用硬门控（根据样本模态选择IMAGE/HTML/URL专家），从而实现模态特定参数的单独聚合，以隔离跨嵌入冲突并稳定收敛。此外，研究还使用了GraphCodeBERT处理URL，并对原始、嘈杂的HTML进行了早期三元嵌入。
### Conclusion
研究结果表明，带有硬门控专家的桶聚合方法可以在严格保护隐私的情况下稳定进行联邦训练，同时提高了多模态钓鱼检测的可使用性和灵活性。在TR-OP数据集上，Fusion头部达到了97.5%的准确率和2.4%的误报率；在图像子集上的准确率为95.5%，误报率为5.9%。对于文本，其在WebPhish和TR-OP数据集上分别获得了96.5%和95.1%的准确率，误报率分别为1.8%和4.6%。
## 1195. `cs.LG` - 带有边缘感知注意力机制和线路搜索矫正操作的物理建模图神经网络在中高压交流功率流中的应用 [PDF](https://arxiv.org/pdf/2509.22458), [HTML](https://arxiv.org/abs/2509.22458)
### Authors
Changhun Kim,Timon Conrad,Redwanul Karim,Julian Oelhaf,David Riebesel,Tomás Arias-Vergara,Andreas Maier,Johann Jäger,Siming Bayer
### Background
物理感知图神经网络（PIGNNs）已成为快速解决交流电力潮流问题的高效工具，尤其适用于需要评估成千上万场景的情况。然而，当前的PIGNNs在保持快速处理的同时还需要提高精度，并且在推理时物理损失未生效，这限制了其实用性。
### Innovation
本文提出PIGNN-Attn-LS，引入了边缘感知的注意力机制和新型的线路搜索矫正操作。注意力机制通过每条边的偏置值明确编码线路物理特性，捕捉电网的各向异性。矫正操作则是一个带回溯线搜索的全局矫正操作，能确保推理阶段恢复可操作的减少准则。
### Conclusion
在4-32节点的中高压测试案例中，PIGNN-Attn-LS实现了电压0.00033 pu和角度0.08°的测试均方根误差，分别比现有的PIGNN-MLP基线提高了99.5%和87.1%。使用流式微批次时，相比于 NR，PIGNN-Attn-LS 在 4-1024 节点的网络上实现了2-5倍的批推理加速。
## 1196. `cs.LG` - 增强信用风险预测：集成基础模型、LASSO和ECOC的元学习框架以提高准确性 [PDF](https://arxiv.org/pdf/2509.22381), [HTML](https://arxiv.org/abs/2509.22381)
### Authors
Haibo Wang,Lutfu S. Sua,Jun Huang,Figen Balo,Burak Dolar
### Background
有效的信用风险管理是财务管理的核心，需要强大的模型来进行违约概率预测和企业分类。传统机器学习方法在面对高维数据时面临显著挑战，包括有限的可解释性，稀有事件检测和多类别不平衡问题。本研究提出了一种全面的元学习框架，结合了多种互补模型：监督学习算法（XGBoost、随机森林、支持向量机和支持树）、无监督方法（K-近邻）、深度学习架构（多层感知机）以及LASSO正则化进行特征选择和降维，Error-Correcting Output Codes作为元分类器以处理多类别不平衡问题。该框架旨在优化预测性能并提供更全面的信用风险管理方法。
### Innovation
本研究提出了一种结合了监督、无监督和深度学习的综合元学习框架，该框架包括多种互补模型，如XGBoost、随机森林、支持向量机、支持树等，并使用LASSO进行特征选择和降维，以及Error-Correcting Output Codes来处理多类别不平衡问题。此外，研究还通过Permutation Feature Importance进行了特征重要性分析，以提高模型的透明度。
### Conclusion
本研究的元学习框架在信用评级迁移（评级升级和降级）和违约概率估计方面显著提高了金融实体分类的准确性。该研究为战略金融决策提供了更准确和可靠的计算模型，并解决了信用风险建模中的三个关键挑战。
## 1197. `cs.LG` - 提高短期死亡率系列的准确性：探索混合系统中的多步预测方法 [PDF](https://arxiv.org/pdf/2509.22395), [HTML](https://arxiv.org/abs/2509.22395)
### Authors
Filipe C. L. Duarte,Paulo S. G. de Mattos Neto,Paulo R. A. Firmino
### Background
随着利率下降和经济稳定，准确的死亡率预测变得尤为重要，尤其是在保险和养老金市场。多步骤预测对于公共卫生、人口规划和保险风险评估至关重要，但当数据有限时会面临挑战。结合统计和机器学习（ML）模型的混合系统能够处理线性和非线性模式，提供了一个有前景的解决方案。本文评估了不同的多步预测方法（递归、直接和多输入多输出）以及ML模型对混合系统准确性的影响。利用12个数据集和21个模型的结果，表明选择多步方法和ML模型对于提升性能至关重要，使用递归方法的ARIMA-LSTM混合系统在大多数情况下表现最好。
### Innovation
引入了结合ARIMA和LSTM的混合系统，并探讨了递归、直接和多输入多输出这三种多步预测方法在混合系统中的应用。该研究强调了选择合适的多步方法和ML模型对于提高多步预测准确性的重要性。
### Conclusion
研究发现，通过选择适当的多步方法和ML模型，可以显著提高混合系统的预测准确性。具体而言，使用递归方法的ARIMA-LSTM混合系统在大部分情况下表现最佳。
## 1198. `cs.LG` - 所有场景通用：预训练模型的统一图适应 [PDF](https://arxiv.org/pdf/2509.22416), [HTML](https://arxiv.org/abs/2509.22416)
### Authors
Yongqi Huang,Jitao Zhao,Dongxiao He,Xiaobao Wang,Yawen Li,Yuxiao Huang,Di Jin,Zhiyong Feng
### Background
GPL作为一种连接图预训练模型和下游应用场景的有前途的范式，缓解了标签依赖及预训练与下游任务的不匹配问题。尽管现有研究探索了多种提示策略，但其效果和内在机制仍不明确。目前存在的关键限制包括：（1）对底层机制缺乏共识；（2）对多种下游场景的适应性有限，尤其是在数据分布变化时（例如，同配性转异配性图）。
### Innovation
本文理论上分析现有的GPL方法并指出，代表层面的提示实际上起到微调简单下游分类器的作用。提出了一个新的GPL方法UniPrompt，它可以适应任何预训练模型，同时释放预训练模型的能力并保持输入图结构。实验表明，该方法能够与多种预训练模型兼容，并在各类场景中实现良好的性能。
### Conclusion
通过设计UniPrompt，重点应放在释放预训练模型能力上，使下游分类器适应不同场景。该方法可以有效集成多种预训练模型，实现strong performance，在领域内和跨领域场景中都表现优异。
## 1199. `cs.LG` - MoveFM-R：通过语言驱动语义推理提升移动基础模型 [PDF](https://arxiv.org/pdf/2509.22403), [HTML](https://arxiv.org/abs/2509.22403)
### Authors
Fanjin Meng,Yuan Yuan,Jingtao Ding,Jie Feng,Chonghua Han,Yong Li
### Background
移动基础模型 (MFMs) 已经提高了人类移动模式的建模，但受数据规模和语义理解限制而遇到了瓶颈。大语言模型 (LLMs) 提供了强大的语义推理能力，但在生成物理上可验证的移动轨迹方面缺乏必要的时空统计理解。为了克服这些局限，该研究提出了一个名为 MoveFM-R 的新框架，以利用语言驱动的语义推理能力，将 MFM 的全部潜力释放出来。MoveFM-R 主要解决了两个关键技术挑战：地理坐标与离散语言令牌之间的词汇不匹配，以及 MFM 的潜在向量与 LLM 的语义世界之间的表示差距。
### Innovation
MoveFM-R 包括三个核心创新：语义增强的位置编码以弥合地理与语言之间的差距，逐级课程以使 LLM 的推理与移动模式对齐，以及交互式自我反思机制以用于条件轨迹生成。实验结果表明，MoveFM-R 显著优于现有的 MFM 基础和 LLM 基础基线，尤其在零样本设置中表现出高度的一般化能力，能够从自然语言指令中生成逼真的轨迹。
### Conclusion
通过综合 MFM 的统计强度和 LLM 的深层次语义理解，MoveFM-R 开创了一种新的范式，能够更全面、更可解释、更强大的模拟人类移动。MoveFM-R 的实现已在线公开。
## 1200. `cs.LG` - 提升电容器模型性能 [PDF](https://arxiv.org/pdf/2509.22454), [HTML](https://arxiv.org/abs/2509.22454)
### Authors
Daniil Shlenskii,Alexander Korotin
### Background
最近，电容器生成模型（如PFGM++）作为一种强大的框架，已经在图像合成中取得了最先进的性能。PFGM++以扩展数据空间工作，具有辅助维度$D$，当$D$趋向无穷大时，会恢复扩散模型框架，但在有限的$D$下则表现出更优的实际结果。这类模型在生成样本时依赖昂贵的微分方程（ODE）模拟，使得计算成本较高。
### Innovation
本文提出了一种名为反泊松流匹配（IPFM）的新型蒸馏框架，旨在加速所有$D$值下的电容器生成模型。IPFM将蒸馏问题重新表述为逆问题：学习一个生成器，使其诱导的静电场与教师的场相匹配。研究显示，当$D$趋向无穷大时，我们的IPFM能恢复最近用于蒸馏扩散模型的分数身份蒸馏（SiD）方法。实验结果表明，我们的IPFM使用少量函数评估即可生成媲美教师甚至更好的样本。此外，研究发现对于有限的$D$而言，蒸馏在收敛速度上优于$D$趋向无穷大的扩散模型。
### Conclusion
我们的研究不仅提出了一种高效的蒸馏方法，提高了电容器生成模型的性能，还揭示了在有限$D$值时蒸馏效果更好的现象，为理解电容器生成模型的动力学提供了新的视角。
## 1201. `cs.LG` - 在再生核希尔伯特空间中的贝叶斯转移算子 [PDF](https://arxiv.org/pdf/2509.22482), [HTML](https://arxiv.org/abs/2509.22482)
### Authors
Septimus Boshoff,Sebastian Peitz,Stefan Klus
### Background
库若曼算子作为一种非线性动力系统线性表示方法，已在多个科学领域引起了关注。最近，库若曼算子理论与数据科学中的另一个流行概念——再生核希 accomplished spaces相结合。通过这种方式，研究人员进一步探索了高斯过程方法，以缓解基于核的库若曼算法中的两种常见问题。
### Innovation
研究者通过高斯过程方法解决了库若曼算法中的两个问题：一个是稀疏性问题，即大多数核方法在可实践性方面不尽如人意，需要进行近似；另一个是超参数优化和字典学习问题，旨在使模型适应动力系统。研究的主要贡献在于将高斯过程回归与动态模式分解统一起来。
### Conclusion
总之，该研究通过结合高斯过程方法，解决了库若曼算子应用中存在的两个关键问题，并且实现了动力系统分析的提升。
## 1202. `cs.LG` - GPU加速神经网络约束下的非线性优化 [PDF](https://arxiv.org/pdf/2509.22462), [HTML](https://arxiv.org/abs/2509.22462)
### Authors
Robert Parker,Oscar Dowson,Nicole LoGiudice,Manuel Garcia,Russell Bent
### Background
本文研究了在使用训练好的神经网络时，通过在GPU上评估网络输出和导数来优化网络的方法。传统的全空间形式中，优化求解器能够访问到中间变量和约束条件，而新的减少空间形式中，这些信息被隐藏起来，从而减少求解时间和迭代次数。
### Innovation
提出了一个减少空间形式的优化方法，其中神经网络被当作“灰箱”来处理，中间变量和约束不直接暴露给优化求解器。相比于传统的全空间形式，在使用内部点方法求解时，这种减少空间形式可以提高求解速度并减少迭代次数。
### Conclusion
该方法在两个优化问题——针对MNIST数据集训练的分类器的对抗生成和使用神经网络代理约束的安全约束最优潮流中表现出优势。
## 1203. `cs.LG` - Dual Optimistic Ascent（PI Control）是变形的增广拉格朗日方法 [PDF](https://arxiv.org/pdf/2509.22500), [HTML](https://arxiv.org/abs/2509.22500)
### Authors
Juan Ramirez,Simon Lacoste-Julien
### Background
约束优化是一种强大的框架，用于在神经网络中施加要求。通常使用一阶方法在 min-max 拉格朗日形式上求解这些约束深度学习问题，但这些方法往往会出现振荡，并且无法找到所有局部解。虽然增广拉格朗日方法 ALM 能够解决这些问题，但从业者更倾向于使用标准拉格朗日上的 PI 控制乐观上升方案，虽然这些方法在实践中表现良好，但缺乏正式保证。
### Innovation
论文建立了之前未知的等价性：拉格朗日上的双重乐观上升等价于增广拉格朗日上的梯度下降-上升。这一发现让我们可以将 ALM 的稳健理论保证转移到双重乐观设置中，证明其能够线性收敛到所有局部解。此外，等价提供了调优乐观超参数的原理指导。我们的工作填补了双重优化方法的实证成功与理论基础之间的关键差距。
### Conclusion
我们证明了双重乐观上升等价于增广拉格朗日上的梯度下降-上升。因此，ALM 的稳健理论保证能够转移到双重乐观设置中，使双重乐观方法具有线性收敛到所有局部解的能力。这一发现提供了调优乐观超参数的原理指导，并填补了双重优化方法实证成功与理论基础之间的关键差距。
## 1204. `cs.LG` - 学习邻居：无对比的多模态自监督分子图预训练 [PDF](https://arxiv.org/pdf/2509.22468), [HTML](https://arxiv.org/abs/2509.22468)
### Authors
Boshra Ariguib,Mathias Niepert,Andrei Manolache
### Background
高质量的分子表示对于性质预测和分子设计至关重要，但大型带标签的数据集仍然稀缺。虽然在分子图上进行自我监督预训练显示出潜力，但许多现有方法要么依赖手工构建的增强，要么使用复杂的生成目标，且往往仅使用2D拓扑结构，未能充分利用宝贵的3D结构信息。
### Innovation
我们介绍了C-FREE（无对比的基于自心邻域的表示学习），这是一种简单的框架，将2D图与多种3D构象的集合结合。C-FREE通过在潜在空间中从互补小区中预测子图嵌入来学习分子表示，使用固定半径的自心邻域作为不同的构象建模单元。该设计允许我们在一个混合图形神经网络（GNN）-变换器骨干网中结合几何和拓扑信息，不依赖负例、位置编码或昂贵的预处理。
### Conclusion
在GEOM数据集上进行预训练，该数据集提供了丰富的3D构象多样性，C-FREE在MoleculeNet上取得了最先进的结果，超越了对比学习、生成和其他多模态自我监督方法。在具有多样大小和分子类型的多个数据集上进行微调进一步表明，预训练可以在新的化学领域中有效转移，突显了3D导向的分子表示的重要性。
## 1205. `cs.LG` - 适应性双模式蒸馏与激励方案在非同态数据上具有扩展性和异构性的联邦学习 [PDF](https://arxiv.org/pdf/2509.22507), [HTML](https://arxiv.org/abs/2509.22507)
### Authors
Zahid Iqbal
### Background
联邦学习(Federated Learning, FL)作为一种分布式学习(Distributed Learning, DL)的去中心化方法，使得在保护用户隐私的同时能够使用分布数据成为可能。然而，FL面临着几个关键挑战。首先，并非所有客户端都能训练相同的机器学习模型，因为每个客户端的业务需求和计算资源不同。其次，统计异质性（即非同态数据）在FL中是一个主要问题，可能导致全局模型性能下降。此外，在解决这些挑战时，需要一种成本效益高的激励机制来鼓励客户端参与FL训练。
### Innovation
针对上述挑战，论文提出了几种方法：DL-SH，促进统计异质性背景下的高效、隐私保护且通信效率高的学习；DL-MH，管理全异质模型并解决统计差异；I-DL-MH，基于激励的DL-MH扩展，通过在复杂联邦学习框架中提供激励来促进客户端参与FL训练。实验结果表明，所提出的方法相比现有先进方法和基线方法，在准确性和降低通信成本方面均有所提高，DL-SH在全局模型准确性上改善了153%，而I-DL-MH在非同态条件下改善了225%。
### Conclusion
全面的实验验证了所提出方法的性能和可扩展性，它们能够有效解决统计异质性和模型异质性问题，并提供了显著的性能提升。这些方法为非同态数据下具有扩展性和异构性的联邦学习提供了新的解决方案，并在成本效益高的激励机制下进一步增强了客户端的参与度。
## 1206. `cs.LG` - 神经网络ODE中的全局收敛性：激活函数的影响 [PDF](https://arxiv.org/pdf/2509.22436), [HTML](https://arxiv.org/abs/2509.22436)
### Authors
Tianxiang Gao,Siyuan Sun,Hailiang Liu,Hongyang Gao
### Background
神经普通微分方程（ODEs）因其连续性质和参数共享效率，在各种应用中取得了成功。然而，这些独特的特性也给训练带来了挑战，特别是在梯度计算的准确性以及收敛性分析方面。
### Innovation
本文通过研究激活函数的影响来解决训练挑战，证明了激活函数的性质，特别是平滑性和非线性，对训练动力学至关重要。平滑激活函数保证了正向和反向ODEs的全局唯一解，足够的非线性则确保了神经切线核（NTK）在训练过程中保持光谱性质。这些性质共同使我们能够在参数过剩的情况下，通过梯度下降确保神经ODEs的全局收敛性。
### Conclusion
我们的理论发现通过数值实验得到了验证，不仅支持了我们的分析，还为扩展神经ODEs提供了实用指导，可能加速训练并提高实际应用中的性能。
## 1207. `cs.LG` - 激活函数设计在连续学习中维持塑性 [PDF](https://arxiv.org/pdf/2509.22562), [HTML](https://arxiv.org/abs/2509.22562)
### Authors
Lute Lillo,Nick Cheney
### Background
在独立相同分布的训练制度下，激活函数已被广泛评估，其差异在模型规模和优化调整后通常会缩小。然而，在连续学习中，情况有所不同：除了灾难性遗忘外，模型还可以逐渐失去适应能力（称为塑性的丧失），而激活函数在这一失败模式中的作用尚未得到深入探索。
### Innovation
我们展示了激活函数选择是减轻塑性丧失的首要且架构无关的杠杆。基于激活函数的负分支形状和饱和行为的属性分析，我们引入了两个即插即用的非线性函数（Smooth-Leaky 和 Randomized Smooth-Leaky），并在监督类增量基准和诱导受控分布和动力学变化的非稳定 MuJoCo 环境中的强化学习中进行了评估。我们还提供了一个简单的压力测试协议和诊断工具，将激活函数的形状与变化下的适应联系起来。
### Conclusion
研究表明，经过深思熟虑的激活设计提供了一种轻量级且领域通用的方法，可以在不增加额外容量或任务特定调整的情况下维持连续学习中的塑性。
## 1208. `cs.LG` - ECHO：向大型脑电图模型中的上下文序列到序列范式迈进 [PDF](https://arxiv.org/pdf/2509.22556), [HTML](https://arxiv.org/abs/2509.22556)
### Authors
Chenyu Liu,Yuqiu Deng,Tianyu Liu,Jinan Zhou,Xinliang Zhou,Ziyu Jia,Yi Ding
### Background
脑电图（EEG）因其广泛的应用领域，需要能够有效泛化到各种任务和数据集的模型。现有的大型脑电图模型（LEMs）通过在大规模未标标签数据上进行预训练，来构建通用表示。虽然这些模型在预训练阶段表现有效，但由于缺乏与之匹配容量的解码器，限制了模型完全发挥功能。因此，需要一种新的方法来解决这一问题。
### Innovation
本文提出了ECHO，一种新型的解码器为中心的大型EEG模型范式，将EEG建模重新定义为序列到序列学习。ECHO通过构建上下文线索来捕捉信号、标签和任务之间的分层关系，增强了模型对于不同任务的适应性。这种方法使得ECHO能够进行上下文学习，实现动态适应多样化的任务而无需更新参数。
### Conclusion
在多个数据集上的实验结果表明，即使使用基本的模型组件，ECHO也能在多任务设置中有条不紊地超越最先进的单一任务LEM，展示了更好的泛化能力和适应性。
## 1209. `cs.LG` - 在游戏中的延迟反馈学习通过额外预测研究 [PDF](https://arxiv.org/pdf/2509.22426), [HTML](https://arxiv.org/abs/2509.22426)
### Authors
Yuma Fujimoto,Kenshi Abe,Kaito Ariu
### Background
研究指出，在多人游戏中的学习假设多个代理独立学习其策略，从而可能导致优化结果之间的差异。为了克服这一问题，通常采用乐观的正规化跟随领导者（Optimistic Follow-the-Regularized-Leader，OFTRL）算法，该算法会预测未来的奖励。然而，过去奖励的延后观察使得这种预测难以实现。研究表明，单步延迟就显著恶化了OFTRL在遗憾和收敛方面的表现。
### Innovation
本文提出了加权OFTRL（WOFTRL），即在OFTRL中，预测下一个奖励的向量被加权n次。研究进一步揭示了乐观加权抵消延迟的直觉。当乐观加权超过延迟时，WOFTRL可以恢复良好的性能，如一般和形游戏中的遗憾为常数（O(1)-regret）的表现，以及多矩阵零和游戏中策略的次优收敛至纳什平衡点。这些理论结果通过实验得到了支持和加强。
### Conclusion
WOFTRL能够在存在延时反馈的情况下，保持或恢复OFTRL的性能优势，尤其是在一般和形游戏和多矩阵零和游戏中的表现得到了显著改善。
## 1210. `cs.LG` - 连接柯尔莫哥洛夫复杂性和深度学习：变换器的最优描述长度目标 [PDF](https://arxiv.org/pdf/2509.22445), [HTML](https://arxiv.org/abs/2509.22445)
### Authors
Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova
### Background
最小描述长度（MDL）原则为在机器学习中应用奥卡姆剃刀提供了一个正式框架。然而，将其应用于如变换器等神经网络时，由于缺乏统一的模型复杂度测度而颇具挑战性。本文基于柯尔莫哥洛夫复杂性理论，提出了渐近最优描述长度目标的理论观点。研究者建立了这些目标的优化器在模型资源界限增大时所能实现的最优压缩效果，对于任意数据集，这种效果仅在一个附加常数范围内不同。
### Innovation
提出了基于柯尔莫哥洛夫复杂性的渐近最优描述长度目标；证明了变换器存在此类最优目标，需建立其计算通用性；通过构建基于自适应高斯混合先验的变分目标，证明了此类目标的可实现性和可微性；实验证明了该变分目标能够选出低复杂性的解决方案并显示强泛化能力，表明标准优化器从随机初始化难以找到此类解决方案，突出了关键的优化挑战。
### Conclusion
本文透过提供类最优描述长度目标的理论框架，强化了渐进保证。这可能为训练更压缩和泛化能力更强的神经网络提供一种潜在路径。
## 1211. `cs.LG` - 基于运输的均值流在生成模型中的应用 [PDF](https://arxiv.org/pdf/2509.22592), [HTML](https://arxiv.org/abs/2509.22592)
### Authors
Elaheh Akbari,Ping He,Ahmadreza Moradipari,Yikun Bai,Soheil Kolouri
### Background
流匹配生成模型已经成为连续数据生成的强大范式，已经在图像、3D形状和点云等多个领域取得了最先进的结果。然而，这些模型由于需要大量的序列采样步骤而存在推断速度慢的问题。为了加速推断，最近的工作试图通过减少采样步骤的数量来提高速度。特别地，均值流提供了一种一步生成的方法，在保留生成性能的同时提供了显著的速度提升。但在许多连续领域中，均值流不能很好地近似最初的多步流匹配过程。
### Innovation
作者通过将最优传输为基础的采样策略整合到均值流框架中，使一个步骤的生成器能够更好地保留原始多步骤流过程的保真度和多样性。
### Conclusion
实验结果表明，该方法在一步生成建模中实现了更高的推理准确性，特别是在受控的低维度设置以及高维度任务如图像生成、图像到图像翻译和点云生成中。
## 1212. `cs.LG` - IIET: 通过隐式迭代欧拉法实现高效的数值变压器 [PDF](https://arxiv.org/pdf/2509.22463), [HTML](https://arxiv.org/abs/2509.22463)
### Authors
Xinyu Liu,Bei Li,Jiahao Liu,Junhao Ruan,Kechen Jiao,Hongyin Tang,Jingang Wang,Xiao Tong,Jingbo Zhu
### Background
高阶数值方法在NLP和CV任务中增强Transformer性能的同时，引入了性能效率权衡问题，因为增加了计算开销。传统的效率提升技术，如知识蒸馏，可能会对这些模型的性能产生负面影响，例如PCformer。
### Innovation
提出了迭代隐式欧拉Transformer (IIET)，通过迭代隐式欧拉方法简化高阶方法。IIET不仅提供了更优的性能，还比PCformer更容易进行模型压缩。引入迭代影响意识蒸馏(IIAD)，通过灵活的阈值让用户平衡性能效率。IIET在lm-evaluation-harness上相比vanilla Transformer提升了2.65%的平均准确率，与PCformer相比提升了0.8%。高效的IIET（E-IIET）将推理开销减少了55%，同时保留了99.4%的原始任务准确性。最高效的IIET变体在vanilla Transformer上实现了超过1.6%的平均性能提升，并保持了相近的速度。
### Conclusion
IIET通过隐式迭代欧拉方法实现了更高的效率，有效地解决了高阶数值方法与性能效率权衡的问题。
## 1213. `cs.LG` - OFMU: 以优化驱动的机器遗忘框架 [PDF](https://arxiv.org/pdf/2509.22483), [HTML](https://arxiv.org/abs/2509.22483)
### Authors
Sadia Asif,Mohammad Mohammadi Amiri
### Background
近年来，在敏感应用中部署的大语言模型越来越需要具备在不重新从头训练的情况下，遗忘特定知识，如用户请求、版权材料或过时信息的能力，以确保法规遵守、用户隐私和安全。这一任务称为机器遗忘，旨在移除特定数据的影响（忘记），同时保持剩余数据上的性能（保留）。一种常见的方法是将这个多目标问题构造成一个单目标问题，并通过标量化结合忘记和保留的损失。然而，这种方法经常导致不稳定的训练动态，并且由于相互冲突的梯度方向而降低模型的实用性。
### Innovation
为解决这些问题，我们提出了一种基于惩罚的双层优化框架OFMU，它通过一个分层结构显式地优先考虑遗忘并保留保留。我们的方法通过内层最大化步骤中的相似性感知惩罚来强制执行遗忘，从而将忘记和保留目标的梯度去相关，并通过外层最小化步骤恢复实用性。为了确保可扩展性，我们开发了一种两环算法，并在凸性和非凸环境下都有收敛保证。此外，我们还对收敛速率进行了严格的理论分析，表明我们的方法在忘记有效性和保留实用性之间的权衡上优于先前的方法。
### Conclusion
在视觉和语言基准测试中，广泛的实验表明，OFMU在遗忘效能和保留实用性方面均优于现有遗忘方法。
## 1214. `cs.LG` - 掌握技巧，然后信任成果：基于渐进式探索的自我模仿强化学习 [PDF](https://arxiv.org/pdf/2509.22601), [HTML](https://arxiv.org/abs/2509.22601)
### Authors
Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun
### Background
强化学习（RL）是提升大规模语言模型（LLMs）在长期、稀疏奖励任务上策略性工具使用能力的主要范式，但现有的方法面临着探索与利用之间的重要权衡难题。尽管已有研究从策略熵的角度促进探索，但这种机械的熵最大化会因多轮次分布变化而导致RL训练不稳定。
### Innovation
本文提出了基于课程的自我模仿学习（SIL）方法SPEAR，以训练具有代理能力的语言模型。SPEAR通过在不同阶段逐步引导策略演进，维持在良好平衡范围内的熵，解决了自主经验指导下的渐进式探索与利用平衡问题。该方法利用内生奖励促进技能级别的探索，并通过自我模仿促进具体行为层面的探索。此外，提出了重新校准回放缓存中经验的优势来解决潜在的策略漂移，并通过轨迹级熵控制引入剪辑高协方差的标记量以抑制过度自信。
### Conclusion
SPEAR通过逐步调整策略以在探索和利用之间找到平衡，结合内生奖励和自我模仿学习，有效解决了RL中探索与利用的难题，并进一步稳定了训练过程。
## 1215. `cs.LG` - IA2：通过ICL激活改进监督微调 [PDF](https://arxiv.org/pdf/2509.22621), [HTML](https://arxiv.org/abs/2509.22621)
### Authors
Aayush Mishra,Daniel Khashabi,Anqi Liu
### Background
监督微调（SFT）通过训练权重以产生查询的预定目标响应来使模型行为专业化。相比之下，上下文学习（ICL）则在推理过程中通过指令或演示来适应模型。在数据稀缺环境中，ICL相比SFT能提供更好的泛化能力和更加校准的响应，但代价是需要更多的推理计算资源。本文作者探讨了ICL的内部计算是否可以用于改进SFT的质量。
### Innovation
研究发现，ICL和SFT在激活模式上具有明显的不同，表明两种方法通过不同的功能机制实现适应。基于这一观察，为了利用ICL丰富的功能，研究人员提出了ICL激活对齐（IA2），这是一种自我蒸馏技术，旨在复制ICL的激活模式，并激励产生类似于ICL的内部推理。在多个基准测试和模型系列上进行的大量实验证明了在SFT前执行IA2能显著提升模型输出的准确性和校准度。
### Conclusion
这一发现不仅在实践中非常有用，而且为我们提供了模型适应内部机制的概念窗口。通过IA2技术，能够有效提升SFT模型的质量，使其在数据稀缺的情况下也能表现出较好的泛化能力和校准性。
## 1216. `cs.LG` - JointDiff：在多智能体轨迹生成中弥合连续与离散 [PDF](https://arxiv.org/pdf/2509.22522), [HTML](https://arxiv.org/abs/2509.22522)
### Authors
Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo
### Background
生成模型通常将连续数据和离散事件作为单独的过程来处理，这在建模复杂系统时形成了差距，特别是那些连续数据和离散事件交互同步的系统。为了解决这一问题，本文提出了JointDiff，一种新的扩散框架，旨在同时生成连续的空-时数据和同步离散事件，从而统一这两种过程。我们通过同时建模多智能体轨迹和关键控球事件在体育领域验证了其有效性。
### Innovation
提出了JointDiff，一个新型的扩散框架，旨在同时生成连续的空-时数据和同步离散事件，统一连续数据和离散事件的处理；引入了CrossGuid，一种有效的多智能体域条件操作，用于条件生成；提出了新的统一体育基准，包含对足球和橄榄球数据集的文本描述，实现了最先进的性能。
### Conclusion
JointDiff展示了联合建模在构建真实的和可控的交互系统的生成模型中的重要性，达到了最先进的性能。
## 1217. `cs.LG` - 多重硬化症生物标记物发现的机器学习管道：可解释的人工智能与传统统计方法的比较 [PDF](https://arxiv.org/pdf/2509.22484), [HTML](https://arxiv.org/abs/2509.22484)
### Authors
Samuele Punzo,Silvia Giulia Galfrè,Francesco Massafra,Alessandro Maglione,Corrado Priami,Alina Sîrbu
### Background
研究团队使用了八项公共平台提供的外周血单核细胞（PBMC）基因微阵列数据集，旨在通过机器学习方法发现多重硬化症（MS）的生物标记物。在经过稳健的预处理后，团队训练了一个优化过的XGBoost分类器，并使用SHapley Additive exPlanations (SHAP) 来识别关键特征，从而可能发现了潜在的生物标记物。这些发现与通过传统差异表达分析（DEA）确定的基因进行了比较，揭示了两者之间的重叠和独特之处，指出两者在 Strength 的互补性。进一步的富集分析证实了SHAP选择的基因在生物过程中的相关性，并将它们与sphingolipid signaling等相关途径相关联。这些途径与MS已有相关性。研究报告指出，结合可解释的人工智能和传统统计方法可以更深入地探究疾病机制。此项研究加强了这种策略的有效性，以挖掘MS的潜在生物标记物并理解相关生物途径的重要性。
### Innovation
该研究利用了机器学习管道，特别是XGBoost分类器和SHAP方法，来发现MS的生物标记物。通过将可解释的人工智能（xAI）技术与传统统计方法相结合，研究提高了对MS中潜在生物标记物及其生物学过程的理解。研究表明，这种方法不仅提高了预测模型的准确性，还促进了对生物标记物生物学意义的理解。此外，通过比较不同方法，揭示了它们各自的优点和局限性，从而增强了研究结果的稳健性和适用性。
### Conclusion
本研究通过结合可解释的人工智能和传统统计方法，为MS的生物标记物发现提供了一种新的视角。研究揭示了SHAP和DEA在发现MS生物标记物方面的独特和重叠之处，这表明它们可以互补使用以获得更全面的理解。富集分析确认了通过SHAP选择的基因在重要生物途径中的相关性，这些途径与MS密切相关。综上所述，研究强调了机器学习和可解释人工智能技术在疾病生物标记物识别中的有效性和潜力。
## 1218. `cs.LG` - 用于熵安全推理的分位数优势估计 [PDF](https://arxiv.org/pdf/2509.22611), [HTML](https://arxiv.org/abs/2509.22611)
### Authors
Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 方法虽然能增强大语言模型（LLM）的推理能力，但训练过程中常会出现‘熵坍缩’和‘熵爆炸’的现象。这主要源于在无价值评估的强化学习（e.g., GRPO 和 DAPO）中使用均值基准线处理负优势样本的方式不当，尤其是当奖励值有异常时，会导致对这些样本的不恰当惩罚。
### Innovation
提出了分位数优势估计（QAE）方法，用分位数基线替代均值基线，巧妙地设计了一个响应层面的两阶段门控机制，对难查询问题增强稀有成功，对易查询问题瞄准剩余失败。通过一阶软最大更新证明了两向熵安全，即在单步骤熵变化中提供了上下界限，有效地抑制了熵爆炸并防止熵坍缩。实验证明，这种最小修正能够稳定熵，为响应分配稀疏的奖励，使发布@1的指标持续增长。
### Conclusion
结果表明，基准设计而非单个标记级别的启发式策略，是实现RLVR扩展的关键机制。
## 1219. `cs.LG` - 学习适用于A*的可接受启发式：理论与实践 [PDF](https://arxiv.org/pdf/2509.22626), [HTML](https://arxiv.org/abs/2509.22626)
### Authors
Ehsan Futuhi,Nathan R. Sturtevant
### Background
启发函数在基于A*等搜索算法的表现中至关重要，理想情况下不应高估最短路径成本。然而，最新的深度学习方法通常忽视了这一点，并可能无法很好地泛化到训练数据之外。该论文针对这两项限制进行了改进。
### Innovation
论文将启发式学习转化为约束优化问题，并引入了Cross-Entropy Admissibility (CEA)损失函数，以在训练期间强制约束可接受性。对于魔方领域，这种方法产生了接近可接受的启发式函数，其指导作用比压缩模式数据库启发式更强。此外，通过利用模式数据库抽象和魔方等图的结构特性，论文紧缩了A*需要泛化的样本量上限。使用ReLU神经网络替代泛函类给出了主要依赖于网络宽度和深度而非图大小的泛化保证。
### Conclusion
论文介绍了学习适用于A*搜索算法的可接受启发式的方法，并证明了如何通过改进泛化保证和减少训练样本需求来提高启发式函数的性能。
## 1220. `cs.LG` - 周期即一切所需，更多则不同 [PDF](https://arxiv.org/pdf/2509.21340), [HTML](https://arxiv.org/abs/2509.21340)
### Authors
Xin Li
### Background
本文提出了一种信息拓扑框架，其中闭环封闭是记忆和意识的基本机制。记忆不是静态存储，而是重新进入大脑状态空间中的潜在闭环的能力，不变的闭环在这个过程中作为含义的载体。不稳定的点和闭环的二分法捕捉到这一概念，后者通过时延锁定的尖刺实现，嵌套在theta-伽马节律中，以确保边界消除。这些微闭环在层次结构上组合，扩展导航循环到一般记忆和认知。
### Innovation
本文创新地提出了信息拓扑框架，其中闭环是记忆和意识的基本机制。该框架认为，记忆不是静态存储，而是重新进入神经状态空间的潜在循环的能力，且这些不稳定的点和闭环的二分法解释了边界消除、闭环巩固以及更高阶不变性如何通过感知片段和全局计划的组合形成意识。
### Conclusion
研究结论指出，闭环是通用环境中的重要机制，能实现长期连贯性和高效统合，并能够有效地在非遍历环境中进行泛化的前提下保持能量成本的最小化。
## 1221. `cs.LG` - 使用深度分割网络从多源检波记录中进行地震Velocity反演：U-网变体和SeismoLabV3+的基准测试 [PDF](https://arxiv.org/pdf/2509.21331), [HTML](https://arxiv.org/abs/2509.21331)
### Authors
Mahedi Hasan
### Background
地震波速度反演是勘探地球物理中的关键任务，能够从地震波数据中重建地下结构。这对于高分辨率地震成像和解释至关重要。传统基于物理的方法，如全程波形反演（FWI），计算要求高，对初始条件敏感，并且受地震数据带宽限制。近年来，深度学习的进步导致了基于数据的方法，将速度反演视为密集预测任务。
### Innovation
本文基准测试了三种先进的编码器-解码器架构——U-Net、U-Net++和DeepLabV3+，以及SeismoLabV3+（一种优化版本的DeepLabV3+，具有ResNeXt50 32x4d骨干和特定任务修改）。实验表明，SeismoLabV3+在内部验证分组和隐藏测试集上分别获得了MAPE值0.03025和0.031246的最佳性能。这证明了使用深度分割网络进行地震波速度反演的适用性，并强调了架构细化在推进地质物理AI模型方面的价值。
### Conclusion
研究发现深度分割网络适用于地震波速度反演，并强调了定制架构优化的重要性。SeismoLabV3+取得了最佳性能，为未来在这个领域的研究提供了新的研究方向。
## 1222. `cs.LG` - 在奥斯特拉瓦地区使用机器学习方法进行地震事件分类 [PDF](https://arxiv.org/pdf/2509.22574), [HTML](https://arxiv.org/abs/2509.22574)
### Authors
Marek Pecha,Michael Skotnica,Jana Rušajová,Bohdan Rieznikov,Vít Wandrol,Markéta Rösnerová,Jaromír Knejzlík
### Background
捷克共和国东北部是该国最活跃的地震区域之一，主要地震事件是由过去频繁的采矿活动引起的采矿诱发地震，但自然断裂活动也可能发生。此外，地震站经常记录该地区采石场的爆炸事件。尽管停止了采矿活动，采矿诱发地震事件仍然发生。因此，在快速区分断层活动和人为活动方面仍然很重要。该地区自1983年由OKC地震站在Ostrava-Krásné Pole开工以来一直在监测，自2007年以来一直提供100 Hz的数字连续波形数据。在1992年至2002年间，该地区还由Frenštát地震多边形（SPF）进行共同监测，其中包括五个使用STA/LTA触发系统的地震站。
### Innovation
本文应用并比较了机器学习方法SPF数据集，该数据集包含有标签的断层活动和采矿诱发事件记录。对二元分类，长短期记忆循环神经网络和XGBoost实现了0.94-0.95的F1得分，这是现代机器学习技术在快速事件分类方面潜力的证明。
### Conclusion
现代机器学习方法对奥斯特拉瓦地区的地震事件分类具有显著的优势，特别是在快速事件区分方面，为地震监测提供了新的途径。
## 1223. `cs.LG` - 从参数到行为：无监督压缩策略空间 [PDF](https://arxiv.org/pdf/2509.22566), [HTML](https://arxiv.org/abs/2509.22566)
### Authors
Davide Tenedini,Riccardo Zamboni,Mirco Mutti,Marcello Restelli
### Background
尽管深度强化学习（DRL）最近取得了成功，但它在样本效率方面表现不佳。这主要是由于在高维度且冗余参数空间中直接优化策略的标准做法。在多任务设置中，这一挑战变得更加复杂。
### Innovation
开发了一种新颖的无监督方法，将策略参数空间$theta$压缩到低维度的潜空间$repr{Z}$。通过优化行为重建损失训练生成模型$g：repr{Z} rightarrow theta$，确保潜空间按照功能相似性而非参数化接近来组织。推测这一流形的内在维度取决于环境的复杂性，而不是策略网络的大小。这种方法在连续控制域中得到了验证，表明标准策略网络的参数化可以被压缩多达五个数量级，同时保留其大部分表达能力。作为副产品，新的流形使基于潜空间$repr{Z}$的策略梯度能够实现特定任务的适应。
### Conclusion
通过这种方法，策略参数空间被无监督地压缩到了低维度的潜空间，保持了策略的大部分表达能力，并实现了基于潜空间的任务特定适应。
## 1224. `cs.LG` - 学习定价捆绑：混合捆绑的GCN方法 [PDF](https://arxiv.org/pdf/2509.22557), [HTML](https://arxiv.org/abs/2509.22557)
### Authors
Liangyu Ding,Chenghan Wu,Guokai Li,Zizhuo Wang
### Background
捆绑定价是指设计多种产品组合（即捆绑）并确定其价格，以最大化预期利润。这是一种在收入管理中经典的问题，存在于许多行业中，例如电子商务、旅游和视频游戏。然而，由于候选捆绑的数量呈指数级增长，该问题通常难以解决。本文探讨了使用图卷积网络（GCNs）解决捆绑定价问题的方法。文中首先开发了一种针对混合捆绑模型（其中每个可能的捆绑都有特定价格）的图表示，并训练一个GCN以学习最优捆绑的潜在模式。基于训练好的GCN，提出了一种推断策略来得到高质量的可行解决方案。还提出了一种局部搜索技术以提高解决方案的质量。数值实验验证了我们提出基于GCN的框架的有效性和效率。使用训练在包含5种产品的实例上的GCN，我们的方法在小型至中型问题中仅用极小的计算时间就能达到接近最优的解决方案（优于97%）。对于较大的问题规模，该方法也优于其他启发式方法，如捆绑大小定价（BSP）。该方法甚至可以为超过30种产品的情况提供高质量的解决方案，即使是在产品效用非加性的情况下，也能应对挑战性的场景。
### Innovation
本文提出了一种使用图卷积网络（GCNs）解决混合捆绑定价问题的方法。具体包括开发了一种图表示法的混合捆绑模型，并训练一个GCN学习最优捆绑的潜在模式。基于训练好的GCN，提出了一种推断策略和局部搜索技术来提高解决方案的质量。该方法能够针对小型至较大规模的问题提供高质量的解决方案，并显示出对超过30种产品情况的适用性，尤其是在产品效用非加性的情况下仍能应对挑战性场景。
### Conclusion
使用训练在包含5种产品的实例上的GCN，我们的方法在小型至中型问题中显著提高了近最优的解决方案（优于97%）。对于较大的问题规模，该方法也优于其他启发式方法。该方法能够为超过30种产品的情况提供高质量的解决方案，即使在产品效用非加性的情况下，也能应对挑战性的场景。提出的基于GCN的框架有效且高效。
## 1225. `cs.LG` - EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning [PDF](https://arxiv.org/pdf/2509.22576), [HTML](https://arxiv.org/abs/2509.22576)
### Authors
Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris
### Background
在多轮交互的环境中，有限的奖励反馈使得生成单一任务需要30多轮交互，这对强化学习提出了根本性的挑战。传统的探索-利用平衡机制在这些情况下容易失败，导致策略过早收敛或后期策略崩溃，使得训练不稳定且效果有限。
### Innovation
提出了一种名为Entropy-regularized Policy Optimization (EPO)的一般框架，通过以下三个协同机制解决了这一问题：(1) 在多轮交互设置中采用熵正则化来增强探索；(2) 一个熵平滑正则化器，限制策略熵在历史平均值内，防止剧烈波动；(3) 适应性分阶段加权，以平衡训练中的探索与利用。EPO 保证熵方差单调递减，同时保持收敛性。实验结果显示，EPO 在 ScienceWorld 中可实现高达 152% 的性能提升，在 ALFWorld 中可实现 19.8% 的提升。
### Conclusion
工作表明，多轮稀疏奖励环境需要不同于传统RL的熵控制，这对LLM代理训练有广泛影响。
## 1226. `cs.LG` - 平均数的欺骗：类增量学习评估为何误导你？ [PDF](https://arxiv.org/pdf/2509.22580), [HTML](https://arxiv.org/abs/2509.22580)
### Authors
Guannan Lai,Da-Wei Zhou,Xin Yang,Han-Jia Ye
### Background
类增量学习（CIL）要求模型能够持续学习新的类别，同时不忘记得之前学习的内容。在实际场景中，类别的出现顺序多样且难以预测，这导致不同顺序下的模型性能差异显著。当前主流的评估方法仅基于随机样本序列计算性能均值和方差，却无法充分捕捉全性能范围，导致均值估计偏倚且方差严重低估。
### Innovation
通过理论分析和实验证明，传统采样策略未能准确评估CIL性能，提出引入极端序列以充分发挥其在可靠评估中的关键作用。同时，提出EDGE（边缘案例驱动的分布和通用性评估）协议，采用任务相似性自适应地识别和采样极端类序列，更精确地逼近真实性能分布，提供了模型选择和鲁棒性检查的实际建议。
### Conclusion
广泛的实验结果表明，EDGE能够有效捕获性能极值，并提供分布边界更准确的估计，为模型选择和鲁棒性检查提供实质性的见解。源代码已提供。
## 1227. `cs.LG` - 评估结合天气和环境变量的深度学习模型在野火蔓延预测中的表现及其对2023年毛伊岛野火的案例研究 [PDF](https://arxiv.org/pdf/2509.21327), [HTML](https://arxiv.org/abs/2509.21327)
### Authors
Jiyeon Kim,Yingjie Hu,Negar Elhami-Khorasani,Kai Sun,Ryan Zhenqi Zhou
### Background
预测野火蔓延对于有效的火灾管理及风险评估至关重要。随着人工智能（AI）技术的快速发展，各种深度学习模型被开发并应用于野火蔓延预测。然而，目前对这些模型的优势和局限性理解有限，尚不清楚基于深度学习的火灾蔓延模型与现有非AI火灾模型之间的比较方法。
### Innovation
本研究评估了结合天气和环境变量的五种典型深度学习模型在十余年夏威夷州野火数据中的野火蔓延预测能力，并通过2023年毛伊岛火灾案例研究，将最佳深度学习模型与广泛应用的火灾蔓延模型FARSITE进行了比较。结果显示，两种深度学习模型（ConvLSTM和带有注意力机制的ConvLSTM）在五种测试的人工智能模型中表现出最佳性能。通过将人工智能模型与可解释的人工智能方法结合，进一步识别了与2023年毛伊岛野火相关的关键天气和环境因素。
### Conclusion
综合而言，五种典型深度学习模型中，ConvLSTM和带有注意力机制的ConvLSTM模型在野火蔓延预测中表现最佳。FARSITE模型在精确性上高于最佳AI模型，但在召回率和F1分数上较低，而AI模型具备更高的输入数据灵活性。通过将AI模型与解释性AI方法结合，可进一步识别关键的天气和环境因素，支持更有效的野火管理与风险评估。
## 1228. `cs.LG` - 基于数据驱动方法设计三价超重元素配体 [PDF](https://arxiv.org/pdf/2509.21362), [HTML](https://arxiv.org/abs/2509.21362)
### Authors
Kirill V. Karpov,Ivan S. Pikulin,Grigory V. Bokov,Artem A. Mitrofanov
### Background
超重元素的配位化合物因其稀有性、高昂的实验成本以及工作所需的特殊条件而难以通过实验进行研究。另外，量子化学计算的复杂性限制了其在大型系统中的应用。
### Innovation
本文采用现代机器学习方法创建了一种新型神经网络架构，可以利用现有实验数据的有限信息来显著提高模型质量。此外，该方法还描述了所提模型的应用范围，并确定了对配位化合物稳定性的分子片段。
### Conclusion
通过这种方法，研究人员可以在不需要大量实验数据和复杂计算的情况下分析和设计超重元素的配位化合物，从而克服了现有研究中的诸多难题。
## 1229. `cs.LG` - 使用非迭代时空变换器模型的台风强度准确预测 [PDF](https://arxiv.org/pdf/2509.21349), [HTML](https://arxiv.org/abs/2509.21349)
### Authors
Hongyu Qu,Hongxiong Xu,Lin Dong,Chunyi Xiang,Gaozhen Nie
### Background
热带气旋（TC）强度的准确预报，特别是在快速增强和快速减弱期间，仍然是气象预报中的一个挑战。这具有高风险的灾难准备和基础设施恢复意义。尽管最近机器学习的进步在泰坦尼克预测方面取得了显著进展，但大多数现有系统在极端环境中会快速退化，并且缺乏长期一致性。
### Innovation
TIFNet是一种基于变换器的预报模型，它通过将高分辨率全球预测与历史演变融合机制相结合，生成非迭代的5天强度轨迹。经过再分析数据训练和使用运营数据微调，TIFNet在所有预报时间段内持续优于运营数值模型，对弱、强和超级台风类别提供了稳健的优势。特别是在被视为最难预报的快速强度变化区域，TIFNet将预报误差降低了29-43%，相对于当前运营基准线。
### Conclusion
TIFNet代表了基于人工智能的热带气旋强度预报的重大进步，尤其是在传统模型在极端条件下持续表现不佳的情况下。
## 1230. `cs.LG` - ReGeS: 用于对话式推荐系统的情境检索与生成相互促进框架 [PDF](https://arxiv.org/pdf/2509.21371), [HTML](https://arxiv.org/abs/2509.21371)
### Authors
Dayu Yang,Hui Fang
### Background
对话式推荐系统（CRS）需要从对话中正确理解用户偏好，这依赖于与外部领域知识的连接。现有解决方案要么需要特定领域的工程，降低灵活性；要么完全依赖大型语言模型，增加生成错误的风险。尽管检索增强生成（RAG）有潜力，但在CRS中的直接应用受限于对话噪音的负面影响，忽略了相似项目之间的细微差别。
### Innovation
提出了一种双向检索与生成协同框架ReGeS，统一了生成增强检索和检索增强生成。这种协同作用消除了额外标注的需求，减少了生成错误，并简化了连续更新。实验表明ReGeS在推荐准确性方面达到最新技术水平，证明了双向协同的有效性，特别是在知识密集型CRS任务中。
### Conclusion
ReGeS框架通过实现检索与生成的双向协同作用，增强了推荐系统的准确性和灵活性，降低了生成错误的风险，并通过消除额外标注简化了系统更新过程。这表明ReGeS对于提高对话式推荐系统的性能具有重要意义。
## 1231. `cs.LG` - 基于类内多样性进行子集选择 [PDF](https://arxiv.org/pdf/2509.21380), [HTML](https://arxiv.org/abs/2509.21380)
### Authors
Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor
### Background
深度学习模型已广泛应用于医疗保健领域，特别是在医学影像分类中。为了提高模型的准确性，研究人员通常采用两种方法对深度学习模型进行训练：从零开始训练和迁移学习。这两种方法都需要大量计算时间和资源，因为训练模型需要大量数据集。此外，为了选择最优超参数，还需要进行设计空间探索，通常需要多次训练。随着数据集规模的增长，探索这些问题的解决方案越来越受到研究社区的关注。一种可能的解决方案是选择数据集的子集进行训练和超参数搜索。这个子集被称为coreset，必须是原始数据集的一个代表性子集。随机采样的简单方法可能会偏向不平衡数据集中的主要类，即使数据类内平衡，这种随机采样也不会捕捉到类内多样性。
### Innovation
本文提出了一种智能、轻量级的coreset选择机制，特别提出了一种方法来提取类内多样性，并根据每个类形成的聚类进行最终采样。该方法通过在知名医学影像数据集上进行广泛的分类实验，证明了其有效性，结果表明，在统一条件下，该方案在多个性能指标上优于随机采样方法。
### Conclusion
该研究提出了一种基于类内多样性进行coreset选择的智能机制，并在广泛分类实验中证明了所提方案的有效性，该方案在多个性能指标上优于随机采样方法。
## 1232. `cs.LG` - LongiMam模型，用于利用纵向乳房X光片改进乳腺癌风险预测 [PDF](https://arxiv.org/pdf/2509.21383), [HTML](https://arxiv.org/abs/2509.21383)
### Authors
Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau
### Background
乳腺癌筛查需要稳健的模型来利用纵向成像数据，但当前大多数深度学习模型依赖单一或有限的前期乳房X光片，并且缺乏适应不平衡结果分布和异质随访的实际临床环境的适应性。
### Innovation
开发了一个端到端的深度学习模型LongiMam，它结合了卷积神经网络和递归神经网络，用于同时整合当前和最多四份前期乳房X光片，以捕捉预测乳腺癌的时空模式。该模型使用具有非正常病例与对照比例的大型流行病学筛查数据集进行训练并评估。
### Conclusion
通过多种实验，LongiMam模型在包含前期X光片的情况下始终提高了预测能力。同时进行的子组分析证实了该模型在关键风险组中的有效性，包括密度乳腺女性和年龄55岁以上的人群。此外，模型在乳房X光片密度随时间发生变化的女性中表现最佳。这些发现表明，纵向建模增强了乳腺癌的预测，并支持在筛查方案中使用重复X光片来细化风险分层。
## 1233. `cs.LG` - mmHSense：用于人类感知的多模态和分布式毫米波ISAC数据集 [PDF](https://arxiv.org/pdf/2509.21396), [HTML](https://arxiv.org/abs/2509.21396)
### Authors
Nabeel Nisar Bhat,Maksim Karnaukh,Stein Vandenbroeke,Wouter Lemoine,Jakob Struye,Jesus Omar Lacruz,Siddhartha Kumar,Mohammad Hossein Moghaddam,Joerg Widmer,Rafael Berkvens,Jeroen Famaey
### Background
本文介绍了mmHSense，这是一个开放标注的毫米波数据集集，旨在支持ISAC系统中的人类感知研究。这些数据集可以用于探索毫米波ISAC在各种终端应用中的应用，如姿势估计、手势识别、人员识别和定位。此外，这些数据集还可以用于开发和推进毫米波ISAC上的信号处理和深度学习研究。
### Innovation
本文的方法在于提供的mmHSense数据集集，支持在ISAC系统中进行人类感知研究，通过这一数据集，可以探索ISAC系统在多个方面的应用，并推进信号处理和深度学习的研究。此外，通过参数效率的微调方法，可以显著降低计算复杂度，同时保持在先前任务上的性能。
### Conclusion
本文描述了数据集的测试平台、实验设置和信号特征，并通过特定下游任务的验证演示了数据集的实用性。此外，本文还展示了使用参数效率的微调方法来适应不同的任务，显著降低了计算复杂度，同时保持了先前任务上的性能。
## 1234. `cs.LG` - 离散流匹配生成模型的理论分析 [PDF](https://arxiv.org/pdf/2509.22623), [HTML](https://arxiv.org/abs/2509.22623)
### Authors
Maojiang Su,Mingcheng Lu,Jerry Yao-Chieh Hu,Shang Wu,Zhao Song,Alex Reneau,Han Liu
### Background
本文对端到端训练离散流匹配（DFM）生成模型进行了理论分析。DFM 是一个具有前景的离散生成建模框架，通过训练神经网络来近似变换的速度场以学习潜在的生成动态。现有的研究表明，通过这种方式可以有效地生成离散数据，但对其理论保证和性能仍然缺乏深刻的理解。本文通过分解最终分布估计误差链的保证，提供了一种深入理论分析的方法，包括证明生成分布与目标分布之间的总变差距离受学习速度场的风险控制，以及通过分析两个主要来源（即拟合误差和估计误差）来限制这种风险，进而证明训练集大小增加时，DFM 模型生成的分布会证明性地收敛到真实数据分布。
### Innovation
通过提供对端到端训练离散流匹配（DFM）生成模型的理论分析，文章创新性地证明了通过组成训练集大小增加时，DFM 模型生成的分布会证明性地收敛到真实数据分布。这种分析特别关注在理论上保证了生成模型与真实数据分布接近的程度，并详细分析了计算真实速度场的能力（拟合误差）和有限数据集上的统计收敛速率（估计误差）。
### Conclusion
研究结果首次形式化地证明了，在学会的离散流匹配模型训练仿真产生分布随着训练数据集大小的增加而会证明性地收敛到真实数据分布。
## 1235. `cs.LG` - 通过消除和重新训练修复概念瓶颈模型 [PDF](https://arxiv.org/pdf/2509.21385), [HTML](https://arxiv.org/abs/2509.21385)
### Authors
Eric Enouen,Sainyam Galhotra
### Background
概念瓶颈模型（CBMs）使用一组人类可解释的概念来预测最终的任务标签，使领域专家不仅能够验证CBM的预测，还能在测试时干预错误的概念。然而，这些干预措施未能解决CBM和专家推理之间系统性的错配问题，如模型从有偏数据中学习捷径。本文通过介绍一种基于‘消除和重新训练’两步过程的一般解释性调试框架来解决这个问题。
### Innovation
本文提出了一种新的可解释性调试框架——针对CBMs的CBDebug方法。该方法包含两个步骤：首先，专家利用概念解释来识别并移除任何不需要的概念；其次，CBDebug方法通过将概念级别的用户反馈转化为样本级别的辅助标签，实现了监督有偏性减轻和针对性增强，从而减少了模型对不需要的概念的依赖。
### Conclusion
我们在现实和自动化专家反馈两种情况下评估了此框架，并发现CBDebug在多种CBM架构（PIP-Net、事后CBM）和具有已知伪关联的基准测试中，显著优于先前的重新训练方法。
## 1236. `cs.LG` - DyME: 动态多概念擦除在扩散模型中的双层正交LoRA适应 [PDF](https://arxiv.org/pdf/2509.21433), [HTML](https://arxiv.org/abs/2509.21433)
### Authors
Jiaqi Liu,Lan Zhang,Xiaoyong Yuan
### Background
文本到图像扩散模型（DMs）无意中再现了受版权保护的风格和保护的视觉概念，引发了法律和伦理问题。概念擦除作为一种保障措施，旨在通过微调选择性地抑制这些概念。然而，现有方法无法扩展到实际应用场景中，其中提供者必须擦除多个且可能相互冲突的概念。现有方法的核心瓶颈在于它们依赖于静态擦除：一次检查点被微调以去除所有目标概念，而不考虑推断时的实际擦除需求。这种固有的设计与现实世界的使用情况不匹配，其中每次生成都有不同的请求，导致擦除成功率下降，并且非目标内容的保真度降低。
### Innovation
本文提出了DyME，一个按需擦除框架，通过训练轻量级、概念特定的LoRA适配器并在推断时仅动态组成所需的适配器来实现灵活的多概念擦除。为了克服适配器之间的干扰问题，特别是当多个或语义相关的概念被抑制时，引入了特征和参数层面的双层正交约束，以解耦表征变化并强制执行正交适配子空间。同时，开发了ErasureBench-H，一个新的分层基准，拥有品牌-系列-角色结构，以使在语义粒度和擦除集大小方面的原则性评估成为可能。实验结果表明，DyME 在ErasureBench-H 和标准数据集（例如，CIFAR-100, Imagenette）上表现优于最先进的基线，实现了更高水平的多概念擦除保真度，同时最大限度地减少了从属降解。
### Conclusion
实验结果证明，DyME 普遍优于最先进的基线，实现了更高的多概念擦除保真度，并且最小化了从属降解。
## 1237. `cs.LG` - SGNNBench：大规模图上脉冲图神经网络的整体评估 [PDF](https://arxiv.org/pdf/2509.21342), [HTML](https://arxiv.org/abs/2509.21342)
### Authors
Huizhe Zhang,Jintang Li,Yuchang Zhu,Liang Chen,Li Kuang
### Background
图神经网络（GNNs）是针对图数据设计的深度模型。消息传递机制使GNNs能够有效捕捉图拓扑结构，并推动各种图任务性能边界。然而，这种为图表示学习开发复杂机制的趋势在大规模图中变得不可持续。计算和时间开销使得开发更加节能的GNNs变得至关重要，以应对真实世界图的爆炸性增长。脉冲图神经网络（SGNNs）作为一种生物合理的学习方式，通过独特的基于脉冲的神经元越来越受到关注，这些网络开始作为一种节能的选择出现。尽管近年来已经提出了一系列SGNNs，但目前缺乏一种系统性的基准来探索这些受大脑启发的网络的基本设计原则。为了弥合这一差距，论文提出了SGNNBench，对于SGNNs进行了一项多层次的研究，涉及有效性、节能性和架构设计。
### Innovation
SGNNBench 综合评估了9种最新的SGNNs在18个数据集上的表现，具体比较了它们的模型大小、内存使用和理论上能耗，揭示了SGNNs的能源瓶颈问题，并对SGNN的设计空间进行了细致研究，促进了SGNN更普遍的范式的开发。
### Conclusion
SGNNBench 旨在定量评估SGNNs领域的发展，提供了从多角度进行深入研究的框架，包括效率、节能性和架构设计，有助于推动SGNNs的广泛应用和发展。
## 1238. `cs.LG` - 从嵌入到方程：遗传编程近似器的可解释Transformer分类 [PDF](https://arxiv.org/pdf/2509.21341), [HTML](https://arxiv.org/abs/2509.21341)
### Authors
Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi
### Background
研究如何通过符号替代建模冻结的Transformer嵌入，获得紧凑且可审计的分类器，具备校准的概率。本文通过对五个基准数据集（SST2G, 20NG, MNIST, CIFAR10, MSC17）中的Embeddings进行语义保持特征分区，使用遗传编程学习加法的闭式评分函数，同时报告了多个评估指标，如F1, AUC, log-loss, Brier, ECE及符号复杂度，通过验证集的F1和简约性规则选择最优模型。温度调整显著改善了测试集上的ECE，最终的替代模型在MNIST, CIFAR10, MSC17上的性能强劲（F1最高可达0.99），但SST2G最为挑战。通过可靠性图表、维度使用和重叠统计、贡献基于的重要度、全局效应描述（PDP和ALE）展示了可解释跨模态的解释，基于明确程序的拟合
### Innovation
本文提出了一种使用遗传编程从Transformer嵌入中学习加法闭式评分函数的方法，以此建立紧凑且可解释的分类器。通过语义保持特征分区实现精确信息分区，并利用温度调整改进概率校准。为了解释性，提供了可靠性图表、维度使用统计和贡献重要性等分析结果，展示了通过明确的程序和评分组合实现的可解释性能。
### Conclusion
本文通过遗传编程、语义保持特征分区以及温度调整等方法，成功建立了紧凑的、可解释的和概率校准的Transformer分类模型。通过多个数据集的验证，展示了该方法在多个任务和数据集上的强分类能力，特别是对于MNIST、CIFAR10和MSC17数据集。同时，通过多种解释性技术，验证了该模型的合理性与有效性。
## 1239. `cs.LG` - 使用多模态方法的突触神经网络进行心理工作量分类 [PDF](https://arxiv.org/pdf/2509.21346), [HTML](https://arxiv.org/abs/2509.21346)
### Authors
Jiahui An,Sara Irina Fabrikant,Giacomo Indiveri,Elisa Donati
### Background
准确评估心理负载对认知神经科学、人机交互和实时监控至关重要，因为心理负载波动会影响性能和决策。尽管基于脑电图(EEG)的机器学习(ML)模型可用于此目的，但它们的高计算成本阻碍了嵌入式实时应用。突触神经网络(SNN)的硬件实现为低功耗、快速和事件驱动的处理提供了有前景的替代方案。本研究使用开源多模态数据集比较了与传统ML模型兼容的SNN模型，结果显示多模态集成提高了准确性，SNN表现与ML相当，证明了其在认知负载检测中的实时实现潜力。这些发现将基于事件的处理定位为为低延迟、高效能的工作负载监控提供有前景的解决方案，以适应闭环嵌入式设备，这些设备可以动态调节认知负载。
### Innovation
使用SNN模型结合多模态数据进行心理工作量分类，展示了SNN在低功耗和事件驱动处理方面的优势，与传统ML模型相比，其性能相当甚至更好。研究结果表明，SNN有可能在嵌入式设备中实现实时的心理工作量检测。
### Conclusion
通过使用多模态集成和SNN模型，该研究展示了SNN在低延迟、高效能工作负载监控中的潜力，特别是在应对闭环嵌入式设备动态调节认知负载的挑战方面。
## 1240. `cs.LG` - 可解释的光谱特征预测掺杂共轭聚合物实验室中的电导率 [PDF](https://arxiv.org/pdf/2509.21330), [HTML](https://arxiv.org/abs/2509.21330)
### Authors
Ankush Kumar Mishra,Jacob P. Mauthe,Nicholas Luke,Aram Amassian,Baskar Ganapathysubramanian
### Background
自驾车实验室(SDLs)通过结合自动化与机器学习有望加速材料发现。然而，一个主要挑战是如何从成本低廉且易于自动化测量的读出数据中预测出昂贵且测量耗时的性质。本文针对掺杂共轭聚合物提出了一个解决方案，通过学习可解释的光谱特征来预测其电导率。这些元素的光谱是快速的、无损的，并且对聚集和电荷产生敏感。研究团队通过结合遗传算法（GA）与适应性选择的光谱窗口下的面积-曲线计算（AUC计算）来自动化光谱特征的提取，从而在小数据量的情况下提高精度和可解释性。
### Innovation
研究提出了一种通过遗传算法结合面积-曲线计算自动提取光谱特征的方法，以及使用SHAP引导的选择来保留一个紧凑且物理上有意义的特征集。数据驱动的模型在预测性能上达到了专家验证描述符的基础模型的水平，且通过限制直接测量电导率降低了实验工作量（约33%）。此外，这项研究采用了数据驱动与专家特征的混合量化结构-性质关系（QSPR），展示了人类和机器学习之间的有效协作。研究所发现的功能不仅可以解释已知的描述符（例如pBTTT的0-0/0-1振动强度比），还能揭示掺杂成功时与聚合物褪色相关的尾态区域。这种方法可以将快速测量转换为可靠预测昂贵性质的工具，并易于扩展到其他光谱模态（如XANES、拉曼、FTIR）中。
### Conclusion
研究开发的可解释的光谱特征使得快速测量能够可靠地预测出昂贵的性质，适用于小数据量场景。研究人员强调了这种数据驱动方法与传统专家特征的结合在提高预测性能中的优势，并展示了其在掺杂共轭聚合物中的应用价值。该方法可扩展到其他光谱模态，为材料科学和工程提供有力的工具。
## 1241. `cs.LG` - 在评估安全监控时缓解信息泄露 [PDF](https://arxiv.org/pdf/2509.21344), [HTML](https://arxiv.org/abs/2509.21344)
### Authors
Gerard Boxo,Aman Neelappa,Shivam Raval
### Background
白盒监控能够分析模型内部机制，有助于发现大型语言模型中潜在的危害行为，具有较低的计算成本且易于集成到多层次防御体系中。然而，评估这些监控器需要具有目标行为的响应示例，这些示例通常通过提示或微调获得，这会导致监控器的数据不可避免地包含促成这些行为的信息，从而增强其效用。因此，评估监控器时会遇到信息泄露的问题，具体表现为提示泄漏（出现要求有害行为的提示）和推理泄漏（模型表达其欺骗行为过程中涉及的推理），这对评估准确性构成挑战。
### Innovation
本文提出了一种系统性框架，用于评估监控器检测真实模型行为、而非表面诱饵特征的能力。同时介绍了三种新的评估策略：内容过滤（去除诱饵文本）、评分过滤（仅聚合相关任务的标记），以及通过微调训练生成欺骗行为模型。特别是详细研究了两种泄露形式对监控器性能的影响，并通过多种欺骗检测基准在实验中实施提出的缓解策略，最终测量了性能的保留情况。研究结果揭示了三项关键发现：内容过滤是有效的缓解策略，可减少30%的探测AUC-ROC；评分过滤减少AUC-ROC 15%但难以明确归因；微调模型的加入提高了监控评估，但降低了多达40%的性能，即使重新训练也是如此。
### Conclusion
研究发现内容过滤效果显著，但评分过滤和微调模型对监控器性能的影响则相对复杂。具体的评估策略可根据不同的需求选择使用，从而有助于更准确地评估监控器的实际能力。
## 1242. `cs.LG` - 使用RLVR的顶尖SQL推理模型 [PDF](https://arxiv.org/pdf/2509.21459), [HTML](https://arxiv.org/abs/2509.21459)
### Authors
Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang
### Background
企业客户的许多问题可以通过开发结合组织特定知识的定制推理模型来解决。在许多这类问题中，奖励函数可以验证，这被称为奖励可验证的强化学习（RLVR）。研究者应用了RLVR，尤其是在一个被称为BIRD的数据科学基准测试中，该基准测试评估AI代理将自然语言查询转换为数据库SQL执行的能力。
### Innovation
研究者利用RLVR的方法，特别是通过TAO的离线RL方法进行预热阶段，然后进行严格的在线RLVR训练，提出了一个不依赖额外训练数据和非专用模型的简单且通用的训练方案。研究者首次提交的模型在BIRD基准测试的私有测试集上达到了顶尖的准确率：73.56%（无自一致性）和75.68%（有自一致性）；后者还比第二好的方法需要更少的生成次数。
### Conclusion
虽然BIRD是一个代理任务，但该框架的简洁性使其广泛适用于商业智能、数据科学和编程等企业领域。
## 1243. `cs.LG` - 使用令牌混合进行推理学习 [PDF](https://arxiv.org/pdf/2509.21482), [HTML](https://arxiv.org/abs/2509.21482)
### Authors
Adit Jain,Brendan Rappazzo
### Background
强化学习带验证奖励（RLVR）已成为提升大型语言模型（LLM）推理能力的领先方法。当前大多数方法基于Group Relative Policy Optimization变体，通过采样多种推理完成，相互评分并调整策略。然而，这些方法在每次推理步骤中仅采样离散的令牌，忽略了模型候选令牌概率分布中的丰富信息。尽管在非RL设置中保留和利用这一信息已证明有益，但当前的RLVR方法似乎通过不利用这种信息而无谓地限制了推理搜索空间。
### Innovation
我们研究了在RLVR中使用令牌混合生成（MoT-G）。我们提出一个统一框架，泛化现有MoT-G方法，包括现有的不需培训的方法，这些方法将混合嵌入作为令牌嵌入的加权和构成，并扩展RLVR直接在连续混合空间生成思维链进行操作。在Reasoning-Gym的推理密集语言任务评估中，MoT--G方法在7个任务中取得了5-35%的显著改进，同时通过较少的轨迹达到同等准确性，表明提高了训练效率。通过全面的隐藏状态和令牌级别分析，我们提供了证据表明，MoT--G的优点可能源于其在整个推理过程中保持更高隐藏状态熵的能力以及在令牌空间中的推广探索。
### Conclusion
MoT--G方法通过保留和在推理过程中使用令牌概率分布中的信息，为强化学习带验证奖励模型提供了显著改进，提高了推理任务的效率和效果。
## 1244. `cs.LG` - 增强生成式机器听觉 [PDF](https://arxiv.org/pdf/2509.21463), [HTML](https://arxiv.org/abs/2509.21463)
### Authors
Vishnu Raj,Gouthaman KV,Shiv Gehlot,Lars Villemoes,Arijit Biswas
### Background
该论文的背景在于，现有的一些常规音频质量评估方法难以准确预测主观听音质量，尤其是在不同类型内容和编解码配置下。为了改进这一问题，研究人员提出了新的模型GMLv2，旨在通过引入基于贝塔分布的损失来更好地建模听众的评分，并通过增加更多的主观音频编码数据集来扩展其适用性。
### Innovation
GMLv2的创新之处在于它引入了一种基于贝塔分布的损失来更好地建模听众评分，并且采用新的神经音频编码主观数据集来提升模型的适用性和泛化能力。此外，GMLv2能够在多样化的测试集上，无论是从主观评分的相关性还是可靠预测这些评分方面，都比现有的广泛使用的技术（如PEAQ和ViSQOL）表现更优。
### Conclusion
GMLv2提供了一种可扩展且自动化的音频感知质量评估框架，有望加速现代音频编码技术的研究与发展。
## 1245. `cs.LG` - 提升自闭症检测的多模态行为分析 [PDF](https://arxiv.org/pdf/2509.21352), [HTML](https://arxiv.org/abs/2509.21352)
### Authors
William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla
### Background
自闭症谱系障碍(ASC)的诊断因其复杂性和资源密集性而具有挑战性，因此提出了多种计算机辅助诊断支持方法，通过分析患者视频数据中的行为线索来进行自闭症检测。然而，这些模型在一些数据集上表现出色，但在眼动特征表现差和现实世界通用性不足方面存在局限性。已有研究展示了自闭症患者（46%女性）与非自闭症患者（46%女性）的行为视频数据集，该数据集是我们已知的最大和最平衡的数据集，包含168名ASC参与者和157名非自闭症参与者。已有研究表明，通过对面部表情、语音语调、头部运动、心率变异性（HRV）和眼动行为的多模态分析，可以更全面地理解自闭症患者的多种行为特征。然而，现有的眼动模型存在局限性，因此需要改进的技术来提高自闭症检测的精准度和普遍性适用性。
### Innovation
引入了新的统计描述符，量化眼动角度的可变性，从而提高了基于眼动的分类精度，从64%提高到69%，并与自闭症相关的临床研究结果一致。使用晚期融合方法，实现了74%的分类精度，证明了在多种行为标记的集成中提高自闭症检测的准确性。通过引入新的统计描述符和融合多模态特征，该研究提高了眼动特征的性能并改进了整体检测准确率，这在很大程度上克服了先前研究的局限性，展示了多模态行为分析在自闭症检测中的潜在应用价值和有效性。
### Conclusion
研究表明多模态行为分析方法在自闭症检测中具有巨大潜力，可为自闭症评估提供可扩展的视频筛查工具。通过多模态分析和新型统计描述符的引入，不仅提高了眼动特征的性能，还展示了多模态特征融合的潜在优势，为自闭症诊断提供了新的视角和工具。
## 1246. `cs.LG` - 在最优传输方面的新算法方向及其在产品空间中的应用 [PDF](https://arxiv.org/pdf/2509.21502), [HTML](https://arxiv.org/abs/2509.21502)
### Authors
Salman Beigi,Omid Etesami,Mohammad Mahmoody,Amir Najafi
### Background
研究了在算法层面如何在高维空间$R^n$中（给定$x thicksim u$）找到一个与$y thicksim u$接近的$y$，且能在多项式时间内完成，而不是依赖于$u$的完整表示大小。此外，讨论了高斯的标准分布$boldsymbol{text{Φ}}^n$传输到任意分布$u$的过程，并探讨了在集合$boldsymbol{text{S}}$条件下$boldsymbol{text{Φ}}^n$的传输问题。
### Innovation
提出了一个针对任意产品分布$boldsymbol{text{μ}}$传输到任何$boldsymbol{text{ν}}$的算法，其中成本为$boldsymbol{text{Δ}}+boldsymbol{text{δ}}$，$boldsymbol{text{Δ}}$是Knothe-Rosenblatt传输成本，$boldsymbol{text{δ}}$是随着运行时间减少的计算误差。证明了Talagrand不等式的算法版本，适用于传输$boldsymbol{text{Φ}}^n$到任何$boldsymbol{text{ν}}$，并构建了一个随机样本器，使得在给定集合$boldsymbol{text{S}}$成员集访问的情况下，可以以期望时间$poly(n/boldsymbol{text{ε}})$传输$boldsymbol{text{Φ}}^n$到$boldsymbol{text{Φ}}^n|boldsymbol{text{S}}$。
### Conclusion
给出了高斯测度下的第一个计算集中定理（Etesami等，2020），解决了Etesami等提出的一个公开问题，表明对于任何测度为$boldsymbol{text{ε}}$的集合$boldsymbol{text{S}}$，大多数$boldsymbol{text{Φ}}^n$样本能够在维度无关的传输成本下在多项式时间内被映射到$boldsymbol{text{S}}$，并保持距离$O(boldsymbol{text{log 1/ε}})$.
## 1247. `cs.LG` - AutoClimDS：气候数据科学代理AI——只需一个知识图谱 [PDF](https://arxiv.org/pdf/2509.21553), [HTML](https://arxiv.org/abs/2509.21553)
### Authors
Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng
### Background
气候数据科学面临数据来源分散、格式各异以及获取和处理数据集所需的高度技术专长等方面的持续障碍。这些挑战限制了参与、减缓了发现过程，并降低了科学研究工作流程的可复制性。
### Innovation
本文提出了一个通过结合精心策划的知识图谱与用于云原生科学工作流程的AI代理来解决这些障碍的原型概念。知识图谱提供了一个统一层次，组织数据集、工具和工作流程，而AI代理（由生成型AI服务驱动）则实现了自然语言交互、自动化数据访问和简化分析。这些组成部分大幅降低了参与气候数据科学的技术门槛，使得非专家用户能够识别和分析相关数据集。
### Conclusion
通过利用现有的云就绪API数据门户，我们展示了“一个知识图谱足矣”方可解锁可扩展且自主工作的科学探究流程。我们的开源设计进一步支持社区贡献，确保KG及其相关工具能够作为共享公共资源进行演进。研究结果表明了一条通往普及气候数据访问并建立人类与AI在科学研究中合作的可复制、可扩展框架的途径。
## 1248. `cs.LG` - 线性非高斯循环模型中的近最优实验设计 [PDF](https://arxiv.org/pdf/2509.21423), [HTML](https://arxiv.org/abs/2509.21423)
### Authors
Ehsan Sharifian,Saber Salehkaleybar,Negar Kiyavash
### Background
近期研究表明，仅使用观测数据识别因果图仅限于排列等价类。本文通过引入干预数据组合使用的方法，旨在获得排列等价类的组合特征，特别是通过展示每个等价类中的图与二分图中的完美匹配之间的关系，来分析干预如何修改或约束匹配。这为通过实验设计识别真实的因果结构提供了新的视角。
### Innovation
通过连接完美匹配和干预数据，本文提出了一种新的方法来解析最优实验设计问题。该问题被形式化为一个适应性的随机优化问题，并且奖励函数被证明是适应性次模函数，从而为贪婪策略提供了接近最优性能的保证。此外，论文还提出了一种基于随机匹配的估计器，以高效估计奖励函数，且分析了其偏差和集中性行为。
### Conclusion
研究结果表明，通过遵循提出的随机优化框架进行少量干预，可以恢复真实的因果结构。这种方法显著地改善了现有技术对因果结构学习的识别效果。
## 1249. `cs.LG` - 使用多模型机器学习和AODV回退的蓝牙Mesh网络上下文感知混合路由 [PDF](https://arxiv.org/pdf/2509.21490), [HTML](https://arxiv.org/abs/2509.21490)
### Authors
Md Sajid Islam,Tanvir Hasan
### Background
蓝牙基于网格的网络为应急和资源受限场景提供了有希望的离线通信基础设施。然而，传统的路由策略，如Ad hoc On-Demand Distance Vector (AODV)，在拥塞和动态拓扑变化下往往会失效。
### Innovation
本文提出了一种结合AODV与监督式机器学习的混合智能路由框架，以改进在多种网络约束下的下一站选择。该框架整合了四个预测模型：投递成功率分类器、TTL回归器、延迟回归器和转发者适用性分类器，形成一个统一的评分机制，在多跳消息传输过程中动态评估邻居节点。
### Conclusion
通过模拟环境评估三种策略——基础AODV、部分混合ML模型(ABC)和完整混合ML模型(ABCD)，研究发现Hybrid ABCD模型在十种场景中达到了约99.97％的包投递率，显著优于基础和中间策略。结果表明，轻量级、可解释的机器学习模型可以增强蓝牙网格网络中的路由可靠性和适应性，特别是在基础设施缺失的环境中，优先考虑投递成功率而非延迟约束。
## 1250. `cs.LG` - 稀疏子网络是否表现出认知对齐的注意力？剪枝对显著图忠实度、稀疏性及概念一致性的影响 [PDF](https://arxiv.org/pdf/2509.21387), [HTML](https://arxiv.org/abs/2509.21387)
### Authors
Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi
### Background
先前的研究已经表明，神经网络可以通过大幅度剪枝来保留性能，但剪枝对模型解释性的影响仍然不清楚。这项研究旨在探讨基于幅度的剪枝方法及其随后微调对低级显著图和高级概念表示的影响。利用 ImageNette 上训练的 ResNet-18，研究者将 Vanilla Gradients (VG) 和 Integrated Gradients (IG) 在不同剪枝程度上的后验解释进行了对比，评估了稀疏性和忠实性。此外，通过 CRAFT 基准概念提取方法，检测了学习概念语义一致性的变化。研究表明，轻度到中度剪枝可以改善显著图的聚焦和忠实性，同时保留具有语义意义的概念。然而，过度剪枝会导致异构特征的合并，尽管保持了准确性，但会导致显著图稀疏性和概念一致性的降低。这些发现表明，虽然剪枝可以朝着更具人类关注模式的方向塑造内部表示，但过度剪枝会损害解释性。
### Innovation
这项研究首次系统地探讨了基于幅度的剪枝方法对模型低级显著图和高级概念表示的影响，使用了 ImageNette 上训练的 ResNet-18，并通过范式梯度（VG）和集成梯度（IG）进行后验解释的对比，评估了稀疏性和忠实性，同时利用 CRAFT 方法跟踪了学习概念语义一致性的变化。
### Conclusion
轻度到中度剪枝会改善显著图的聚焦和忠实性，同时保留具有语义意义的概念。然而，过度剪枝会导致异构特征的合并，尽管保持了准确性，但会降低显著图的稀疏性和概念的一致性。这些发现表明，虽然剪枝可以朝着更具人类关注模式的方向塑造内部表示，但过度剪枝会损害模型的解释性。
## 1251. `cs.LG` - 使用单张图像超分辨率方法将气候预测细化至1km [PDF](https://arxiv.org/pdf/2509.21399), [HTML](https://arxiv.org/abs/2509.21399)
### Authors
Petr Košťál,Pavel Kordík,Ondřej Podsztavek
### Background
高分辨率的气候预测对于地方决策至关重要。然而，现有的气候预测具有较低的空间分辨率（例如12.5km），这限制了它们的实用性。该研究旨在通过利用单图像超分辨率模型通过统计细化将气候预测从较低分辨率提升至1km分辨率。现有高分辨率气候预测数据缺乏，因此该研究使用高分辨率的观测网格化数据集进行模型训练，并应用于低分辨率的气候预测数据。研究通过使用观测气候指标评估细化后的气候预测结果，从而避免使用真实的高分辨率气候数据作为参照。实验结果表明，单图像超分辨率模型可以在不增加气候指标误差的前提下，将气候预测数据细化至1km分辨率。
### Innovation
该研究通过使用单图像超分辨率模型，创造性地解决了现有低分辨率气候预测数据难以进行高分辨率细化的问题。方法通过在高分辨率观测数据集上训练模型，并应用于低分辨率气候预测数据，进而提升预测数据的空间分辨率。此外，研究还提出了一种基于气候指标的评估方法，用于验证细化后的气候预测结果的有效性，这在没有高分辨率实际参考数据的情况下尤为关键。
### Conclusion
研究结果表明，单图像超分辨率模型能够在不增加气候指标误差的情况下，成功提升气候预测的分辨率至1km，从而增加气候预测对于地方决策的支持能力。
## 1252. `cs.LG` - 高能物理领域的基础模型 [PDF](https://arxiv.org/pdf/2509.21434), [HTML](https://arxiv.org/abs/2509.21434)
### Authors
Anna Hallin
### Background
基础模型，即大规模的预训练机器学习模型，能够微调以完成各种任务，在自然语言处理和计算机视觉领域已经引起了革命性的变化。在高能物理领域，关于这些模型是否可以直接应用于物理研究，或者是否可以基于粒子物理数据进行定制化开发的问题，已经引起了越来越多人的关注。该论文是关于高能物理领域基础模型的第一个综述文章，旨在总结和讨论目前该领域的相关研究成果。
### Innovation
这是高能物理领域关于基础模型的第一个综述，总结和讨论了当前已发表的研究成果，为该领域未来的研究提供了参考和启示。通过这一综述，研究人员可以更好地理解基础模型在高能物理中的应用潜力和挑战，推动相关技术的发展和应用。
### Conclusion
综上所述，该论文不仅介绍了高能物理领域基础模型的研究现状，还强调了这些模型在该领域的应用潜力和未来发展方向。未来的研究可以在定制化的模型架构、训练数据的选择和优化算法等方面不断探索，以提高基础模型在高能物理研究中的性能。
## 1253. `cs.LG` - 功能加密在安全神经网络训练中的数据泄露与实际缓解措施 [PDF](https://arxiv.org/pdf/2509.21497), [HTML](https://arxiv.org/abs/2509.21497)
### Authors
Alexandru Ioniţă,Andreea Ioniţă
### Background
随着人工智能的兴趣增加，机器学习即服务提供了云中的基础设施，使得模型的训练、测试和部署更加容易。然而，这些系统存在一个主要的隐私问题：上传敏感数据到云，尤其是在训练阶段。因此，获得安全的神经网络训练已经成为许多研究者最近的关注点。越来越多的解决方案围绕着一个核心支柱：功能加密（FE）。尽管这些方法非常有趣且提供了以加密数据进行机器学习训练的新视角，但仍有一些安全性漏洞没有被考虑。我们的论文介绍了使用功能加密进行安全训练时的一个攻击，该攻击利用线性编程重构原始输入，揭示了之前的安全部署承诺的虚假性。
### Innovation
研究中介绍了对使用功能加密进行的加密数据上的神经网络训练的攻击。提出了两种解决方案来确保安全训练和推理，在计算阶段涉及客户端，其中一种方法在不依赖加密的情况下确保安全，另一种则使用对功能隐藏的内部积技术来确保安全性.
### Conclusion
该研究揭示了使用功能加密进行安全神经网络训练中的数据泄露问题，并提出了解决这些漏洞的实际措施，包括两种方案以保护数据安全。
## 1254. `cs.LG` - 多目标强化学习在大型语言模型优化中的愿景视角 [PDF](https://arxiv.org/pdf/2509.21613), [HTML](https://arxiv.org/abs/2509.21613)
### Authors
Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers
### Background
多目标强化学习（MORL）在优化大型语言模型（LLMs）的多个目标方面既提出了挑战也带来了机遇。当前需要探讨适用于LLMs的MORL方法的优势和限制，识别出高效且灵活的方法在适应个性化功能和LLMs及强化学习（RL）固有复杂性方面的必要性。
### Innovation
本文提出了MORL分类，并研究了各种MORL方法在LLM优化中的应用优势和局限性，指出需要更高效的灵活方法来应对个性化功能和复杂性，并引入多目标强化学习基准框架的概念，该框架能够评估不同方法对各种目标关系的影响。此外，还强调了通过元策略MORL的二层学习范式改进效率和灵活性的研究方向。
### Conclusion
未来的研究应重点关注通过二层学习范式改进的元策略MORL的开发，以提高效率和灵活性，并探讨这一领域的关键研究问题和潜在解决方案，以提升LLM性能。
## 1255. `cs.LG` - 快速SBL的通用修剪准则 [PDF](https://arxiv.org/pdf/2509.21572), [HTML](https://arxiv.org/abs/2509.21572)
### Authors
Jakob Möderl,Erik Leitinger,Bernard Henri Fleury
### Background
稀疏贝叶斯学习（SBL）通过为底层线性模型中的每个权重分配一个超参数，假定每个权重是均值为零、精度与其相关超参数相等的高斯分布。该方法通过边缘化权重并进行边缘化最大似然（ML）估计来估计这些超参数。SBL返回许多权重估计趋于无穷大，这些估计的相应权重几乎为零（即，从模型中修剪掉相应的权重），从而给出权重向量的一个稀疏估计。现有研究在高斯假设下处理噪声样本和权重分布，本文分析减弱这种假设时，单一超参数函数的边际似然情况，得出有限和无限值的充分条件。
### Innovation
本文分析减弱高斯假设时的单一超参数函数的边际似然，提出充分条件来区分有限和无限值，揭示了这些条件与快速SBL（F-SBL）修剪条件在高斯情况下互补并一致，为进一步理解该算法提供了额外的洞见。
### Conclusion
本文分析了在减弱噪声样本和权重分布的高斯假设时，边际似然作为单一超参数的函数，得出了有限值和无限值的充分条件，并揭示了这些条件与F-SBL的修剪条件在高斯情况下的一致性。通过这种方式，为快速SBL提供了额外的见解，有助于更好地理解该算法的工作原理。
## 1256. `cs.LG` - 农Bot：针对农业的问答系统 [PDF](https://arxiv.org/pdf/2509.21535), [HTML](https://arxiv.org/abs/2509.21535)
### Authors
Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari
### Background
印度是一个以农业为基础的经济体，有关农业实践的适当信息是实现最佳农业生产的关键。为了回答农民的问题，基于Kisan Call Center的数据集构建了一个农业聊天机器人。该系统能够24/7不间断地提供有关天气、市场价格、植保和政府计划等相关查询的答案，便于通过任何电子设备访问并易于理解。该系统基于句子嵌入模型，准确率为56%，经过消除同义词和集成实体提取后，准确率提升至86%。
### Innovation
系统采用句子嵌入模型，并通过消除同义词和实体提取技术进一步优化，提高准确率；该系统能够在任何时间、任何地点提供农业相关信息，农民可以通过该系统轻松获取农业实践的相关信息，从而改善农业产出；该系统减轻了呼叫中心工作人员的工作负担，使其能够重新定向至更有效率的目标上
### Conclusion
此农业聊天机器人系统使农民更容易获取农业实践信息，提高农业生产效果；同时也为呼叫中心工作人员工作带来了便利，使他们的努力能够服务于更有效率的目标。准确率为86%的句子嵌入模型提高了系统的有效性和可靠性。
## 1257. `cs.LG` - 基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索 [PDF](https://arxiv.org/pdf/2509.21567), [HTML](https://arxiv.org/abs/2509.21567)
### Authors
Mohammad Parsa Afshar,Aryan Azimi
### Background
消费者行为预测在营销、认知神经科学和人机交互中非常重要。脑电图（EEG）数据可以分析决策过程，提供关于大脑神经活动的详细信息。本文采用了比较的方法，通过EEG数据分析消费者行为预测。
### Innovation
利用Graph Neural Networks (GNN)模型探索了脑连接特征，与传统模型进行了比较，提供了广泛的经典模型（如集成模型）与GNN模型的全面比较。虽然没有显著差异，但GNN模型在某些基本标准上优于传统模型，表明结合EEG信号分析和机器学习模型可以更深入地理解消费者行为，同时对比了经典和较少使用的模型在EEG基于神经营销中的性能.
### Conclusion
本研究不仅表明结合EEG信号分析和机器学习模型可以提供更深入理解消费者行为的方法，而且提供了在基于EEG的神经营销中广泛使用的模型（如支持向量机SVM）与较少使用或不常用的模型（如图神经网络GNN）之间的全面比较。
## 1258. `cs.LG` - 无需对齐生成：在扩散模型中学习线性可分表示 [PDF](https://arxiv.org/pdf/2509.21565), [HTML](https://arxiv.org/abs/2509.21565)
### Authors
Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya
### Background
大规模扩散模型的有效训练策略强调了提升模型中的鉴别特征表示的重要性。相关研究集中在使用强外部编码器提取的特征进行表示对齐，从而通过线性探针评估改善表示质量。然而，基于对齐的方法依赖于昂贵的预训练编码器，这增加了计算负担。本研究则提出了一种替代正则化方法，通过促进中间层表示的线性可分离性（LSEP），不再需要辅助编码器和表示对齐，而是将线性探针直接纳入网络的学习动态中，从而实现高效的训练和生成质量的提升。
### Innovation
本研究提出了一种新的正则化方法，即促进扩散模型中间层表示的线性可分离性（LSEP），从而无需强预训练编码器进行表示对齐。LSEP将线性探针直接融入网络的学习动态中，有效提高了训练效率和生成质量，特别是在基于流的变换器架构如SiTs中表现出显著改进。在256x256的ImageNet数据集上，模型的FID分数为1.46。
### Conclusion
本研究提出了一种新的正则化方法，通过促进扩散模型中间层表示的线性可分离性，提高训练效率和生成质量，尤其是在基于流的变换器架构如SiTs中表现优异。
## 1259. `cs.LG` - InvBench: LLMs能否通过不变量合成加速程序验证？ [PDF](https://arxiv.org/pdf/2509.21629), [HTML](https://arxiv.org/abs/2509.21629)
### Authors
Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken
### Background
程序验证依赖于循环不变量，但自动发现强有力的不变量仍然是一项长期存在的挑战。本文介绍了评估新兴的人工智能模型（如LLM）在不变量合成方面的表现的框架。基于验证器的决策过程具有形式化的正确性保证，并不仅评估其正确性，还评估不变量在验证中提供的效率提升。
### Innovation
提出的框架不仅评估LLM生成不变量的正确性，还考虑了其在验证过程中的效率提升。评估了7个前沿的LLM以及现有的基于LLM的验证器，与传统的UAutomizer求解器进行比较。结果显示，虽然基于LLM的验证器有潜力，但目前尚未展现出相对于UAutomizer的显著优势。模型的性能也表现出显著差异，表明模型能力的重要性。
### Conclusion
监督微调和Best-of-N采样可以提升模型性能。对于Qwen3-Coder-480B模型，经过3589实例的微调后，能够加速验证的情况从8%提高到29.2%。对于Claude-sonnet-4模型，Best-of-N采样（N=16）将加速验证的情况从8.8%提升到22.1%。这些发现表明，对于当前的LLM，不变量合成仍然是一个开放性的挑战。
## 1260. `cs.LG` - 非洲口音英语中的领域感知演讲者 diarization [PDF](https://arxiv.org/pdf/2509.21554), [HTML](https://arxiv.org/abs/2509.21554)
### Authors
Chibuzor Okocha,Kelechi Ezema,Christan Grant
### Background
本文研究了非洲口音英语在演讲者 diarization 中的领域效应。研究在严格的一致性重叠评分 DER 协议下，评估多种生产型和开放型系统在通用对话和临床对话数据集上的表现，发现临床对话存在明显的领域惩罚，并且在不同模型中持续显著。错误分析表明，短对话回合和频繁重叠是导致错误的主要原因，这些因素与较高的假警报率和漏检率相关。研究还表明，虽然通过轻量级的领域适应微调了分段模块，但这种适应并未完全消除领域惩罚。总的来说，该研究揭示了领域调整对演讲者 diarization 的重要性，并强调了针对重叠和临床对话资源优化的重要性。
### Innovation
1. 提出了一组受控的多领域基准测试。2. 创新地提出了对话级别故障分解和分析方法。3. 实现了一种易于重现的轻量级领域适应方案。4. 强调了重叠感知分割和平衡临床资源作为实际可行的下一步措施的研究发现。
### Conclusion
研究引入了一种轻量级的领域适应方法，虽然能够减少错误，但未能完全消除领域惩罚。研究结果表明，需要进一步提高临床对话中重叠的处理能力，并提供更多平衡的临床资源以改进演讲者 diarization 的准确性。
## 1261. `cs.LG` - MobiLLM：在6G开放RAN中的闭合环路威胁缓解的代理式AI框架 [PDF](https://arxiv.org/pdf/2509.21634), [HTML](https://arxiv.org/abs/2509.21634)
### Authors
Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin
### Background
6G网络的演进正在被Open Radio Access Network (O-RAN)范式加速，这是一种开放且可互操作的架构，能够在公共电信和私营企业领域提供智能化和模块化的应用程序。尽管这种开放性为创新带来了前所未有的机会，但也扩大了攻击面，需要具备高弹性的、低成本的、且自主的安全解决方案。传统的防守措施往往是被动的、劳动密集型的，不足以应对下一代系统的规模和复杂性。当前O-RAN的应用主要集中在网络优化或被动威胁检测，缺乏闭环自动化响应的能力。
### Innovation
我们提出了一种基于代理的AI（AI）框架，用于在6G O-RAN环境中实现完全自动化的端到端威胁缓解。MobiLLM通过由大型语言模型（LLMs）驱动的模块化多代理系统协调安全工作流。该框架包括威胁分析代理、使用检索增强生成（RAG）将异常与特定对策关联的威胁分类代理，以及通过O-RAN控制接口安全实现缓解措施的威胁响应代理。该体系基于MITRE FiGHT框架和3GPP规范等可信知识库，并配备了坚固的安全护栏，为可信赖的AI驱动网络安全提供了蓝图。初步评估显示，MobiLLM能够有效识别并协调复杂的缓解策略，显著降低了响应延迟，展示了自主安全运营在6G中的可行性。
### Conclusion
MobiLLM提供了在6G开放RAN中实现闭环威胁缓解的蓝图，具有高弹性的、低成本的、自主的安全能力，能够有效识别和快速应对复杂的威胁情势，展现了代理式AI在网络安全领域的巨大潜力。
## 1262. `cs.LG` - IndiSeek 学习信息导向的分离表示 [PDF](https://arxiv.org/pdf/2509.21584), [HTML](https://arxiv.org/abs/2509.21584)
### Authors
Yu Gui,Cong Ma,Zongming Ma
### Background
在多模态学习中，学习分离表示是一个基本任务。在单细胞多组学等现代应用中，共享特征和模态特定特征对于表征细胞状态和支撑下游分析都是至关重要的。理想情况下，模态特定特征应与共享特征独立，同时又能捕捉到各模态内的所有互补信息。这种权衡可以通过信息论标准自然表达出来，但基于互信息的目标难以可靠估计，其变分替代往往在实践中表现不佳。因此，需要新的方法来有效解决这一挑战，以确保分离表示不仅独立而且完整地提取模态特定特征。
### Innovation
本文引入了IndiSeek，这是一种新的分离表示学习方法，通过结合一个独立性强制目标和一个高效计算的重建损失来限制条件互信息，该损失有效地平衡了独立性和完整性。这种方法允许系统地提取模态特定特征，从而克服了传统方法的不足。IndiSeek已在合成模拟、CITE-seq数据集及多个实际多模态基准测试中展示了其效果。
### Conclusion
通过IndiSeek，实现了分离表示中独立性和完整性的平衡，提高了分离表示的可靠性，为单细胞多组学分析等多模态应用提供了新的解决方案。
## 1263. `cs.LG` - 下一幕是什么？通过生成点轨迹来预测未来运动 [PDF](https://arxiv.org/pdf/2509.21592), [HTML](https://arxiv.org/abs/2509.21592)
### Authors
Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi
### Background
本文讨论了从单张图像预测世界中物体未来运动的问题，而无需观察其他参数如物体速度或施加的力量。传统的模型和方法很难仅凭一张图像准确预测物体的动态变化，尤其是在简单物理场景中的物体运动预测上，这表明需要一种新的方法来解决这个问题。现代视频生成器通常被认为是世界模型，但它们在从单张图像预测运动方面表现出局限性。因此，本文提出了一种新颖的方法，将问题形式化为条件生成密集轨迹网格的任务，该方法利用与现代视频生成器架构相似的模型来生成运动轨迹而非像素。这种方法能够捕捉场景级别上的动态和不确定性，比之前的方法给出了更准确和多样的预测结果。
### Innovation
本文创新地将问题转化为基于现代视频生成器架构的条件生成密集轨迹网格，从而能够捕捉场景级别的动态和不确定性，相比之前的回归器和生成器，该方法提供了更准确和多样性的预测结果。更重要的是，这种方法表明现代视频生成器在从单张图像预测运动方面存在局限性，特别是在简单的物理场景中。通过这种方法，可以更好地理解和解决这种局限性，从而提高在机器人学等下游应用中的准确性。
### Conclusion
本文提出了一种新的方法来预测单张图像中的未来运动，该方法通过生成密集的轨迹网格，采用了与现代视频生成器相似的架构，并且在模拟数据集、机器人应用以及真实世界的物理数据集上进行了广泛评估，证明了该方法的准确性和有效性。尽管现代视频生成器通常被认为是世界模型，但该研究显示，它们在从单张图像预测运动方面仍然存在局限性。
## 1264. `cs.LG` - VLCE: 一种增强知识框架用于灾难评估中的图像描述 [PDF](https://arxiv.org/pdf/2509.21609), [HTML](https://arxiv.org/abs/2509.21609)
### Authors
Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George
### Background
自然灾害发生后，立即评估损害是至关重要的；然而，传统的手工地评估方法非常缓慢且危险。虽然卫星和无人机照片可以提供受灾区域的广泛视角，但目前的计算机视觉方法通常只能给出分类标签或分割掩码，限制了它们提供全面情境理解的能力。
### Innovation
我们引入了Vision Language Caption Enhancer (VLCE)，这是一种多模态系统，旨在生成灾难影像的全面、上下文相关的解释。VLCE采用了双架构方法：一个使用预训练在EuroSat卫星数据上的ResNet50骨干网的CNN-LSTM模型，以及一个预训练在UAV图片上的Vision Transformer (ViT)模型。这些系统利用了ConceptNet和WordNet的外部语义知识，扩展了词汇覆盖范围，提高了描述准确性。我们使用CLIPScore评估语义一致性和InfoMetIC评估段落信息量的指标检测VLCE的表现，结果表明，VLCE显著优于基线模型，达到了95.33%的信息量得分，并保持了竞争力的语义一致性。双架构系统在从卫星和无人机照片中自动生成行动导向的、信息密集型描述方面显示出显著的潜力，以提高灾难损害评估的效率和准确性
### Conclusion
我们的双重架构系统通过从卫星和无人机照片中自动产生行动导向的、信息密集型描述，在灾难损害评估中展示了显著的潜力，改善了现有技术的局限性。
## 1265. `cs.LG` - 从多模态数据自动进行可解释的生存分析 [PDF](https://arxiv.org/pdf/2509.21600), [HTML](https://arxiv.org/abs/2509.21600)
### Authors
Mafalda Malafaia,Peter A.N. Bosman,Coen Rasch,Tanja Alderliesten
### Background
在肿瘤学中，准确且可解释的生存分析仍然是一个核心挑战。随着多模态数据的增加以及临床对透明模型的需求增长，以支持验证和建立信任，这个挑战变得更为复杂。现有的方法无法很好地应对这一挑战，特别是在处理肿瘤患者影像学数据与临床变量时.
### Innovation
文章提出了一种基于MultiFIX的可解释多模态AI框架，通过集成临床变量和计算机断层扫描影像，自动化进行生存分析。该框架利用深度学习推断与生存相关的特征，并通过Grad-CAM解释影像特征，利用遗传编程构建临床变量的符号表达式。风险估计采用透明的Cox回归，实现生存结果分层。
### Conclusion
实验结果显示，MultiFIX在头颈部癌症开放数据集RADCURE上的C-index评价指标（预测：0.838，分层：0.826）表现出色，优于临床和学术基准方法，并且与已知预后标记物一致。这些结果表明，基于MultiFIX的可解释多模态AI在精准肿瘤学中具有巨大潜力。
## 1266. `cs.LG` - HuLA：多任务学习的表达性和情绪性合成语音的音调感知反伪造 [PDF](https://arxiv.org/pdf/2509.21676), [HTML](https://arxiv.org/abs/2509.21676)
### Authors
Aurosweta Mahapatra,Ismail Rasim Ulgen,Berrak Sisman
### Background
当前的反伪造系统对于具有表达性和情绪性的合成语音仍然非常脆弱，因为它们很少利用音调作为判别性线索。音调是人类表达性和情绪性的核心，人类会本能地利用如基频模式和有音/无声结构等音调线索来区分自然语音和合成语音。
### Innovation
本文提出了HuLA，一种双阶段音调感知多任务学习框架，用于伪造检测。第一阶段，使用自监督学习（SSL）主干在真实语音数据上训练，并伴有基频预测和有音/无声分类的辅助任务，增强捕捉自然音调变化的能力，类似于人类知觉学习。第二阶段，模型在真实和合成数据上同时优化伪造检测和音调任务，利用音调意识来检测自然语音与具有表达性和情绪性的合成语音之间的不匹配。
### Conclusion
实验表明，HuLA在具有挑战性的离域数据集上持续地优于强大的基线系统，包括具有表达性、情绪性和跨语言攻击的样本。这些结果表明，明确的音调监督与SSL嵌入结合，显著提高了抵御高级合成语音攻击的鲁棒性。
## 1267. `cs.LG` - 适应性SGD的有效连续方程：随机分析视角 [PDF](https://arxiv.org/pdf/2509.21614), [HTML](https://arxiv.org/abs/2509.21614)
### Authors
Luca Callisti,Marco Romito,Francesco Triggiano
### Background
本文讨论了一些流行的自适应Stochastic Gradient Descent（SGD）方法在小学习率条件下的理论分析。采用由Li等人引入的随机修改方程框架，推导出这些方法的有效连续随机动力学。研究的重点在于采样引起的噪声在极限条件下的表现，具体表现为独立的布朗运动驱动参数和梯度二次动量的演化。此外，通过扩展Malladi等人的方法，考察了学习率与自适应方法中关键超参数之间的缩放关系，并详细描述了所有非平凡极限动力学特征。
### Innovation
研究的核心创新在于揭示了采样引起的噪声在极限条件下的独立布朗运动表现形式，同时探讨了自适应SGD方法中学习率与关键超参数之间的缩放规则，全面描述了所有非平凡的极限动力学特性。
### Conclusion
通过采用随机修改方程框架，本文为自适应SGD方法推导出了有效连续动力学模型，并通过分析这些方法的动态特性，提出了新的理论见解。
## 1268. `cs.LG` - OjaKV：基于Oja规则的上下文感知在线低秩KV缓存压缩 [PDF](https://arxiv.org/pdf/2509.21623), [HTML](https://arxiv.org/abs/2509.21623)
### Authors
Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen
### Background
大型语言模型的长上下文能力受到关键值（KV）缓存的显著内存瓶颈限制，这在自回归生成中是必需的。现有的KV缓存压缩方法大多依赖于静态、离线学习的子空间，但在数据分布发生变化时表现不佳。为解决这些问题，作者提出了OjaKV框架，通过结合策略性混合存储策略和在线子空间适应，提高了压缩效率和准确性。
### Innovation
OjaKV通过识别不同token的重要程度，保留关键的第一和最近token，同时对大部分中间token使用低秩压缩，并通过Oja算法动态调整投影基础，实现了上下文感知的在线低秩KV缓存压缩。该框架与现代注意力模块（如FlashAttention）完全兼容，并能够在高压缩比下保持或提高零样本准确率。特别是在长上下文基准测试中，OjaKV显示了在线子空间适应对动态跟踪上下文变化的重要性。
### Conclusion
OjaKV是一个实用且无需微调模型即可实现内存高效长上下文推理的混合框架，特别适用于要求复杂推理的长上下文基准测试。
## 1269. `cs.LG` - 使用音频语言模型引导音频编辑 [PDF](https://arxiv.org/pdf/2509.21625), [HTML](https://arxiv.org/abs/2509.21625)
### Authors
Zitong Lan,Yiduo Hao,Mingmin Zhao
### Background
音频编辑在VR/AR沉浸感、虚拟会议、音效设计及其他交互媒体中起着核心作用。然而，现有的生成型音频编辑模型依赖于模板化的指令格式，局限于单声道音频。这些模型无法处理描述型音频编辑，用户只需描述期望的结果，编辑的具体操作留给系统处理。现有的音频编辑方法在感知质量、空间真实性和语义一致性方面表现不佳。
### Innovation
本文介绍了SmartDJ，一种结合音频语言模型推理能力和潜在扩散生成力的新型立体声音频编辑框架。给定高层次指令，SmartDJ将其分解为一系列原子编辑操作，例如添加、移除或空间重新定位事件，然后由训练有素的扩散模型执行这些操作。为了支持这一方法，作者设计了一个数据合成流水线，生成配对的高层次指令、原子编辑操作及其音频示例。实验结果表明，SmartDJ在感知质量、空间真实性和语义一致性方面优于现有的音频编辑方法。
### Conclusion
实验表明，与现有音频编辑方法相比，SmartDJ在感知质量、空间真实性和语义一致性的表现更优。
## 1270. `cs.LG` - 具有共轭最后一层估计的多模态贝叶斯神经网络代理模型 [PDF](https://arxiv.org/pdf/2509.21711), [HTML](https://arxiv.org/abs/2509.21711)
### Authors
Ian Taylor,Juliane Mueller,Julie Bessac
### Background
随着数据收集和模拟能力的提升，多模态学习，即从多种模态和数据源学习的任务，正日益成为研究的重点。利用多模态辅助数据来学习昂贵的数量信息的代理模型，可以通过共轭分布在最后一层进行参数估计，有助于优化、逆问题或敏感性分析等外环应用。
### Innovation
研究提出了两个多模态的贝叶斯神经网络代理模型，并利用共轭分布在最后一层进行参数估计，采用了随机变分推断（SVI）方法来估计模型参数。同时，该研究提出了一种处理部分缺失观测的方法，以提高预测准确性和不确定性量化，特别是对于标量和时间序列数据。
### Conclusion
相比于单模态代理模型，该研究的多模态贝叶斯神经网络代理模型在预测准确性和不确定性量化方面表现更好，尤其适用于标量和时间序列数据的情况。
## 1271. `cs.LG` - 一种基于后悔最小化的固定点迭代方法 [PDF](https://arxiv.org/pdf/2509.21653), [HTML](https://arxiv.org/abs/2509.21653)
### Authors
Joon Kwon
### Background
该研究提出了一种将后悔最小化算法转换为固定点迭代的方法，通过后悔界的收敛保证，生成的迭代可以被视为经典的Krasnoselskii-Mann迭代方法的一种拓展。这种方法可用于非自映射的固定点查找，并且特别关注将AdaGrad家族的后悔最小化算法进行转换，从而生成具有新类型的自适应保证的固定点迭代。
### Innovation
该研究创新地将后悔最小化算法转换为固定点迭代，并将经典的Krasnoselskii-Mann迭代方法作为特殊情况之一进行考虑。此外，研究还特别关注将AdaGrad家族的算法进行转换，从而得到具有新类型的自适应保证的固定点迭代。
### Conclusion
通过数值实验，相关方法在多种问题上展示了比经典Krasnoselskii-Mann迭代更快的收敛速度。
## 1272. `cs.LG` - Self-Speculative Biased Decoding for Faster Live Translation [PDF](https://arxiv.org/pdf/2509.21740), [HTML](https://arxiv.org/abs/2509.21740)
### Authors
Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang
### Background
大语言模型（LLMs）在各种文本生成任务中展现出显著的能力，但在流式应用（如实时翻译）中，由于输出需要不断更新以适应不断扩大输入上下文，同时又必须保持较低的计算成本以满足延迟需求，因此仍具有挑战性。
### Innovation
提出了自推测偏置解码（Self-Speculative Biased Decoding），这是一种创新的推理范式，旨在避免不断为逐步扩大的输入流从头生成输出。该方法使用最新的输出作为当前扩大的输入上下文的草案，验证阶段的输出倾向于草案令牌，从而提高草案接受率，不仅减少了可能分散用户注意力的闪烁现象，还提高了速度。
### Conclusion
实验结果表明，与传统的自回归再翻译相比，该方法在不牺牲质量的情况下，可实现最高1.7倍的加速效果，并通过使用仅显示掩码技巧显著降低了80%的闪烁现象。
## 1273. `cs.LG` - 使用大型语言模型进行训练和分析的自动机器学习管道 [PDF](https://arxiv.org/pdf/2509.21647), [HTML](https://arxiv.org/abs/2509.21647)
### Authors
Adam Lahouari,Jutta Rogal,Mark E. Tuckerman
### Background
机器学习原子势（MLIPs）已成为超越量子方法限制进行分子模拟的强大工具，提供了接近量子级别的准确性，但计算成本远低于量子方法。然而，开发可靠的MLIPs仍然是困难的，因为它需要生成高质量的数据集、预处理原子结构和精心训练和验证模型。
### Innovation
该研究引入了一个自动机器学习管道（AMLP），统一了从数据集创建到模型验证的整个工作流程。AMLP利用大型语言模型代理协助选择电子结构代码、输入准备和输出转换，而基于ASE的AMLP-Analysis分析套件支持一系列分子模拟。该管道基于MACE架构并经过验证，精度达到原子能级和原子力的均方绝对误差分别为约1.7 meV/原子和约7.0 meV/Å。模型训练期间的几何结构与DFT高度匹配，并且能够在微-canonical和canonical集合中进行分子动力学模拟期间显示稳定性。
### Conclusion
该研究展示了一个通过简化的微调基础模型实现了亚原子精度的MLIP，并且证明了其在分子动力学模拟中的稳定性。
## 1274. `cs.LG` - 检索思维：通过重复使用思维实现高效的推理 [PDF](https://arxiv.org/pdf/2509.21743), [HTML](https://arxiv.org/abs/2509.21743)
### Authors
Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar
### Background
大型推理模型通过生成较长的推理步骤来提高准确性，但这也导致了延迟和成本的增加，因此需要在推理时间效率上进行优化。
### Innovation
提出了检索思维（RoT）方法，该方法通过复用先前的推理作为可组合的“思维”步骤来指导新问题。RoT 将步骤组织成具有顺序和语义边的思维图，以实现快速检索和灵活重组。在推理时，RoT 检索与查询相关的节点并应用基于奖励的遍历，以组装一个特定于问题的模板，该模板指导生成。动态模板的重用减少了冗余探索，从而减少了输出令牌数量，同时保持了准确性。
### Conclusion
通过评估 RoT 在多种模型上的推理基准测试，结果显示小提示增长，但取得了显著的效率提升，RoT 减少了高达 40% 的输出令牌，将推理延迟减少了 82%，并将成本降低了 59% 以上，同时保持了准确性。RoT 建立了一种通过检索构建可扩展的高效 LRM 推理范式。
## 1275. `cs.LG` - 使用贝叶斯优化实现传感器表征的自动化 [PDF](https://arxiv.org/pdf/2509.21661), [HTML](https://arxiv.org/abs/2509.21661)
### Authors
J. Cuevas-Zepeda,C. Chavez,J. Estrada,J. Noonan,B. D. Nord,N. Saffold,M. Sofo-Haro,R. Spinola e Castro,S. Trivedi
### Background
新型仪器的发展需要经过设计、原型制作和测试三个阶段的迭代循环。近年来，仿真技术和纳米制造技术的进步显著加速了设计和原型制作阶段。然而，检测器表征仍然是装置开发中的主要瓶颈。在测试阶段，需要大量的时间来在不同的操作条件下表征设备并找出最优操作参数。专家需要花费一年甚至更长时间来完成表征和参数优化工作。
### Innovation
提出了利用闭环贝叶斯优化（BO）的新型传感器自校准技术，该技术利用实时测量来指导参数选择并识别最优操作状态，从而加速开发周期中的测试阶段。通过与新型低噪声CCD的实验结果表明，基于机器学习的工具可以在没有设备专家监督的情况下高效地表征和优化传感器的操作，在几天内即可完成此过程。
### Conclusion
提出的方法通过利用机器学习和贝叶斯优化显著加速了传感器表征和参数优化的过程，有望大幅减少设备开发所需的专家时间，从而更快地将产品推向市场。
## 1276. `cs.LG` - CubistMerge: 为多种ViT骨干网络保留空间结构的标记合并方法 [PDF](https://arxiv.org/pdf/2509.21764), [HTML](https://arxiv.org/abs/2509.21764)
### Authors
Wenyi Gong,Mieszko Lis
### Background
许多现代视觉变换器（ViT）骨干网络采用了空间架构设计，如窗口注意力、SAM中的分解相对位置嵌入、以及DINOv3中的RoPE。这些架构对标记减少提出了新的挑战，因为大多数现有方法无法保留这些架构所依赖的空间结构。现有的许多方法在标记减少过程中破坏了这些依赖的空间结构，这给ViT模型的优化带来了困难。
### Innovation
本文提出了一种简单而有效的标记合并方法，能够保留空间完整性，使其能够无缝兼容空间架构。该方法解决了两个看似矛盾的要求：一方面，充分利用空间布局中不均匀的信息分布；另一方面，合并标记后保留空间结构。通过提出一种二维减少策略、一种基于空间感合并算法和一种新颖的最大值维度标记表示法，该方法有效地保留了关键特征，同时保证了合并后的空间结构。
### Conclusion
本文的方法在多种视觉任务中表现出色，无论是即用型还是微调后。对于SAM-H，该方法在不降低COCO上的mIOU的情况下实现了1.25倍的速度提升；对于DeiT-B，在单个微调周期内无准确度损失的情况下实现了1.15倍的速度提升，达到了各种视觉任务中最佳的性能。
## 1277. `cs.LG` - 通过物理引导的扩散模型生成稳定放置 [PDF](https://arxiv.org/pdf/2509.21664), [HTML](https://arxiv.org/abs/2509.21664)
### Authors
Philippe Nadeau,Miguel Rogel,Ivan Bilić,Ivan Petrović,Jonathan Kelly
### Background
在多物体场景中稳定放置物体是一个根本性的挑战，因为放置必须避免穿透、建立精确的表面接触，并形成力平衡。现有的方法依赖于模拟引擎或采用启发式、基于外观的评估。相比之下，我们的方法将稳定性直接集成到扩散模型的采样过程中。为此，我们查询一个基于采样的离线规划器来收集多模态放置标签，并训练扩散模型生成稳定放置。扩散模型根据场景和物体点云进行条件化，并作为几何感知先验。我们利用基于评分生成模型的组成特性，将这个学习到的先验与一种稳定性意识损失结合起来，从而增加了在高稳定性区域采样的可能性。重要的是，这种策略不需要额外的重新训练或微调，并可以直接应用于现成的模型。我们使用准确计算稳定性的四个基准场景评估我们的方法，物理引导模型在面对强外力扰动时的稳定性比最先进的几何方法提高了56%，同时降低了47%的运行时间
### Innovation
我们的方法通过将稳定性直接集成到基于扩散模型的采样过程中，提高了生成稳定放置的能力。利用离线采样规划器收集多模态放置标签，并通过评分生成模型的学习先验和稳定性意识损失相结合，增强了在高稳定性区域采样的概率。这种方法不需要额外的重新训练或微调，可以直接应用于现成的模型，从而提高了鲁棒性和效率
### Conclusion
物理引导的模型在面对强外力扰动时的稳定性比最先进的几何方法提高了56%，同时降低了47%的运行时间。这种方法可以直接应用于现成模型，提高生成稳定放置的效率和鲁棒性
## 1278. `cs.LG` - Causal-EPIG: 预测导向的因果主动学习框架用于CATE估计 [PDF](https://arxiv.org/pdf/2509.21866), [HTML](https://arxiv.org/abs/2509.21866)
### Authors
Erdun Gao,Jake Fawkes,Dino Sejdinovic
### Background
传统的主动学习策略通常关注模型参数或可观测的实际结果的不确定性减轻，而不是直接面向不可观测的因果量。这在高成本获取结果测量的情况下限制了条件平均治疗效果（CATE）的估计。因此，提出了因果目标对齐的原则，即获取函数应直接关注不可观测的因果量，如潜在结果和CATE，而不是间接代理。
### Innovation
提出了Causal-EPIG框架，将信息论期望预测信息增益（EPIG）准则应用于量化减少不可观测因果量不确定性价值。从中推导出两种策略：一是综合方法，通过联合潜在结果全面建模因果机制；二是集中方法，直接针对CATE任务以提高样本效率。
### Conclusion
实验表明，这两种策略在标准基准上表现出色，且最优化策略依赖于基础估计器和数据复杂性，为实际条件平均治疗效果（CATE）估计提供了一种原则性的指导框架。
## 1279. `cs.LG` - MORPH: 形状无关的PDE基础模型 [PDF](https://arxiv.org/pdf/2509.21670), [HTML](https://arxiv.org/abs/2509.21670)
### Authors
Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence
### Background
该研究介绍了一种名为MORPH的模型，这是一种对于形状不敏感的自回归基础模型，用于处理偏微分方程(PDE)。MORPH基于卷积视觉变换器，能够有效地处理从1D到3D、不同分辨率和多种物理场的数据集。该模型结合了组件级卷积、跨场交叉注意力以及轴向注意力等技术，从而捕捉局部交互、建模不同物理场之间的信息传播，并在保留表达力的同时降低计算负担。在多种多样的异构PDE数据集上进行预训练，并评估了其在各种下游预测任务中的应用效果。研究发现，MORPH在零样本和全样本泛化方面优于从头训练的模型，并在广泛的评估中匹配或超越了强基准和最新的先进模型。
### Innovation
MORPH模型创新之处在于它是一类形状无关的基础模型，适用于处理多种维度下的异构时空数据集。该模型采用了组件级卷积、跨场交叉注意力以及轴向注意力等技术，能够在简化计算的同时保持模型的表达力。此外，MORPH模型在预训练和微调方法上取得了显著效果，特别是使用参数有效的小秩适配器（LoRA）微调后，其表现更优。
### Conclusion
MORPH模型展示了灵活和强大的基础框架，能够从复杂的科学观测数据中学习，并在广泛的任务中达到了或超过了先进模型的性能。这标志了一个具有可扩展性和数据高效性的科学机器学习方法的方向，有助于促进科学计算的发展。
## 1280. `cs.LG` - SADA: 安全自适应的多种黑盒预测合并方法 [PDF](https://arxiv.org/pdf/2509.21707), [HTML](https://arxiv.org/abs/2509.21707)
### Authors
Jiawei Shan,Yiming Dong,Jiwei Zhao
### Background
现实世界应用通常面临标注数据稀缺的问题，因为高质量实验的成本和时间要求较高。相比之下，非标注数据则非常丰富。随着机器学习技术的应用日益广泛，使用多种模型和算法生成多个预测标签变得可行，包括深度学习、大型语言模型和生成AI。
### Innovation
本文提出了一种新的安全自适应的方法，可以合并多种未知质量的黑盒预测，同时保证有效的统计推断。该方法提供两个关键保证：（i）无论预测的质量如何，该方法都不会比单独使用标注数据效果差；（ii）如果任何一个预测（不知道是哪一个）完美匹配真实标签，该算法将自适应地利用这个预测以更快的收敛速度或达到半参数效率边界。
### Conclusion
本文通过合成和基准数据集的实验验证了所提出算法的有效性。
## 1281. `cs.LG` - UISim: 一个用于动态移动环境的交互式图像基础UI模拟器 [PDF](https://arxiv.org/pdf/2509.21733), [HTML](https://arxiv.org/abs/2509.21733)
### Authors
Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen
### Background
开发和测试用户界面（UI）以及训练AI代理与之交互，由于实际移动环境的动态性和多样性，面临着挑战。现有方法往往依赖于繁琐的物理设备或有限的静态屏幕截图分析，这阻碍了可扩展的测试和智能UI代理的发展.
### Innovation
引入了UISim，这是一种基于图像的新型UI模拟器，提供了从屏幕图像出发动态交互的移动设备环境探索平台。该系统通过两阶段方法工作：给定初始屏幕截图和用户操作，首先预测下一个UI状态的抽象布局，然后基于此预测布局合成新的、视觉上一致的图像。这使得UI过渡的现实模拟成为可能。UISim为UI测试、快速原型设计和合成数据生成提供了即时的实际益处，其交互功能还为高级应用铺平了道路，如为AI代理计划UI导航任务.
### Conclusion
实验结果表明，与端到端UI生成基线相比，UISim在生成逼真和连贯的后续UI状态方面表现出优越性，突显了其保真度和技术潜力，可用于优化UI开发和提升AI代理的训练效果.
## 1282. `cs.LG` - 近最优样本复杂度的序列1位均值估计 [PDF](https://arxiv.org/pdf/2509.21940), [HTML](https://arxiv.org/abs/2509.21940)
### Authors
Ivan Lau,Jonathan Scarlett
### Background
本文研究了在1比特通信限制下的分布式均值估计问题。现有的研究通常受限于未量化设置，而本研究针对有界均值和方差的情况提出了基于随机化和顺序选择区间的估计方法，解决了这一具体问题。
### Innovation
作者提出了一种基于区间查询的均值估计器，不仅解决了1比特通信限制下的分布式均值估计问题，还给出了样本复杂度界估计 $tilde{O}big( frac{text{方差}}{text{误差}^2}text{对数}frac{1}{text{置信水平}} + text{对数}frac{text{上限}-text{下限}}{text{方差}}big)$，这个界与未量化设置下的最小最大下界在对数因子内匹配，并且还证明了额外的 $text{对数}frac{text{上限}-text{下限}}{text{方差}}$ 项是不可避免的。此外，还展示了区间查询基估计器的适应性差距，对于大的比例 $frac{text{上限}-text{下限}}{text{方差}}$，非适应性平均估计器表现显著差于适应性平均估计器。
### Conclusion
研究表明，通过适应性机制能够有效提高均值估计的准确性，并且给出了适应性机制在各种条件下的新样本复杂度上界，同时解决了未知预算、未知方差、多阶段适配等问题，提出了一些改进方案。
## 1283. `cs.LG` - Noise-to-Notes: 基于扩散生成与修正的自动鼓谱转录 [PDF](https://arxiv.org/pdf/2509.21739), [HTML](https://arxiv.org/abs/2509.21739)
### Authors
Michael Yeung,Keisuke Toyama,Toya Teramoto,Shusuke Takahashi,Tamaki Kojima
### Background
自动鼓谱转录（ADT）通常被表述为一种判别性任务，从音频频谱图中预测鼓事件。传统的ADT方法侧重于准确预测鼓事件，但缺乏为生成任务提供灵活速度-准确度权衡以及较强的填充能力。以往对二进制起始时间和连续速度值的生成对扩散模型构成挑战，因此需要新的优化方法和增强低级谱图特征。在此背景下，本文探讨了如何利用扩散模型来改进自动鼓谱转录。
### Innovation
本文重新定义了ADT为条件生成任务，并提出了Noise-to-Notes (N2N) 框架，利用扩散模型将音频条件下的高斯噪声转换为带有速度的鼓事件。此外，引入了一种名为Annealed Pseudo-Huber损失，以促进有效的联合优化。还提出了一种方法，通过引入从音乐基础模型（MFMs）中提取的特征来增强低级谱图特征的提取，这些特征捕获高级语义信息并提高对域外鼓音频的鲁棒性。这些创新为ADT带来了显著改进。
### Conclusion
实验结果表明，包含MFMs特征显著提高了鲁棒性，N2N在多个ADT基准测试中建立了新的性能标准。
## 1284. `cs.LG` - 基于行为固化方法的车辆路径问题的终身学习 [PDF](https://arxiv.org/pdf/2509.21765), [HTML](https://arxiv.org/abs/2509.21765)
### Authors
Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao
### Background
近期的神经网络求解器在解决路由问题方面表现出色。然而，现有的研究主要基于一次或一组预定义的问题分布和规模进行训练。当出现新的任务时，它们可能依赖于零样本泛化或对预训练的求解器进行微调，这可能导致对先前任务所学知识的灾难性遗忘。本文探讨了一种新的神经VRP求解器的终身学习范式，该范式中，具有多样分布和规模的任务会随时间序列化出现，要求求解器能够有效地、高效地学习解决新任务，同时保持对之前学习任务的性能。
### Innovation
提出了一种新颖的终身学习框架——行为固化终身学习路由器（LLR-BC）。这种框架通过结合行为缓冲区中的行为来有效地巩固前知识，并对决策进行加权以鼓励更多关注关键经验。实验结果显示，该框架能够有效训练高性能神经求解器，并解决灾难性遗忘问题，保持可塑性，并提高零样本泛化能力。
### Conclusion
通过LLR-BC，能够在终身学习环境中高效训练高性能神经求解器，解决灾难性遗忘问题，并提高零样本泛化能力。
## 1285. `cs.LG` - Align2Speak：通过ASR导向的在线偏好优化提高低资源语言的文本到语音 [PDF](https://arxiv.org/pdf/2509.21718), [HTML](https://arxiv.org/abs/2509.21718)
### Authors
Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li
### Background
开发低资源语言的高质量文本到语音（TTS）系统具有挑战性，因为配对的文本和语音数据稀缺。相比之下，对于这样的语言，自动化语音识别（ASR）模型由于大规模的多语言预训练工作而更容易获得。本研究提出了一个基于组相对策略优化（GRPO）框架来将多语言TTS模型适应到新的语言上。该方法首先通过使用国际音标（IPA）标记训练多语言基础模型来建立语言无关的TTS合成基础。接着，该模型可以通过有限的新语言配对数据进行微调，以捕捉目标语言的韵律特征。最后，通过只使用未配对的文本和演讲者提示，并以预训练的ASR、说话人验证和音频质量估算模型的多目标奖励为引导，使用GRPO进行优化。实验表明，这种管道能够生成低资源语言中的易懂且说话人一致的语音，并显著优于单独微调。此外，基于GRPO的框架在高资源语言中也提升了TTS性能，超越了离线对齐方法（如直接偏好优化（DPO）），在易懂性、说话人相似性和音频质量方面表现出更优异的结果。
### Innovation
提出了一个基于组相对策略优化（GRPO）的框架，用于将多语言TTS模型适配到新语言上。该框架通过训练多语言基础模型和使用有限的新语言配对数据进行微调来捕捉目标语言的韵律特征，同时使用预训练的ASR、说话人验证和音频质量估算模型作为引导，优化模型以只使用未配对的文本和演讲者提示。这种方法在低资源语言和高资源语言中都提高了TTS性能，超越了传统的离线对齐方法。
### Conclusion
实验结果表明该方法生成的低资源语言语音更加易懂和说话人一致，同时也提高了高资源语言的TTS性能，体现出更好的易懂性、说话人相似性和音频质量，超越了传统方法。
## 1286. `cs.LG` - 基于强化学习的交通信号设计以减少排队长度 [PDF](https://arxiv.org/pdf/2509.21745), [HTML](https://arxiv.org/abs/2509.21745)
### Authors
Anirud Nandakumar,Chayan Banerjee,Lelitha Devi Vanajakshi
### Background
有效的交通信号控制（TSC）对于减少交通拥堵、旅行延误、污染以及确保道路安全至关重要。传统的固定信号控制和感应控制方法往往难以处理动态的交通模式。因此，研究提出了一种新的自适应TSC框架，利用强化学习（RL）中的Proximal Policy Optimization（PPO）算法，最小化所有信号相位的总排队长度。该研究通过多种状态表示方法来应对RL控制器在高效表示高度随机的交通条件方面的挑战，包括扩展状态空间、自动编码器表示以及K-Planes启发式方法。该算法已在城市交通模拟器SUMO中实现，并在减少排队长度方面优于传统方法和其他传统的基于RL的方法。最佳配置与传统的Webster方法相比，减少了约29%的平均排队长度。进一步的比较性评估表明基于排队的奖励形式的有效性，展示了这种策略在可扩展和自适应的城市交通管理中的潜力。
### Innovation
该研究的创新之处在于提出了一个利用Proximal Policy Optimization（PPO）算法的自适应交通信号控制框架，通过多种状态表示方法解决随机交通条件下的高效表示问题，并且在减少排队长度方面表现出色。它超越了传统的交通信号控制方法和其他基于强化学习的方法，展示了其在城市交通管理中的广阔应用前景。
### Conclusion
该研究设计并实现了一种基于强化学习的自适应交通信号控制算法，能够有效地减少交通排队长度。实验结果表明，该方法优于传统方法以及其它传统的基于强化学习的方法。特别是在使用PPO算法和不同的状态表示方法后，平均排队长度减少了约29%。
## 1287. `cs.LG` - 具有上下文感知非一致性函数的可学习形同预测在机器人规划与感知中的应用 [PDF](https://arxiv.org/pdf/2509.21955), [HTML](https://arxiv.org/abs/2509.21955)
### Authors
Divake Kumar,Sina Tayebati,Francesco Migliarba,Ranganath Krishnan,Amit Ranjan Trivedi
### Background
深度学习模型在机器人领域通常输出点估计值，缺乏对新环境、噪声或分布外输入的预测可靠性量化机制。尽管形同预测（CP）能提供无分布假设的覆盖保证，但其固定非一致性评分依赖可能导致过于保守或不安全的区间。
### Innovation
提出了一种名为 Learnable Conformal Prediction（LCP）的新方法，以解决上述问题。LCP 使用轻量级的神经函数替换固定评分，并通过结合几何、语义和任务特定特征来生成上下文感知的不确定性集合，从而保证保持形同预测的理论保证同时减少预测集大小，并提高路径规划的安全性。在三个机器人任务中的七个基准测试中，LCP 优于标准形同预测和集成基准，并且在多个任务中，相较于标准方法，LCP 显著提高了准确性和能效。
### Conclusion
通过实验验证了 LCP 的有效性，该方法在分类、目标检测和路径规划等任务中均有显著提高。LCP 耗时和内存占用低，支持在线适应，非常适用于资源受限的自主系统。
## 1288. `cs.LG` - 离散流模型的误差分析 [PDF](https://arxiv.org/pdf/2509.21906), [HTML](https://arxiv.org/abs/2509.21906)
### Authors
Zhengyan Wan,Yidong Ouyang,Qiang Yao,Liyan Xie,Fang Fang,Hongyuan Zha,Guang Cheng
### Background
离散流模型为学习离散状态空间的分布提供了强大的框架，并且通常表现出比离散扩散模型更好的性能。但是，它们的收敛性质和误差分析仍然缺乏探索。
### Innovation
本文建立了一个基于随机微积分理论的整体框架，系统地研究了离散流的理论性质。具体地，通过开发一种新型的Girsanov型定理，推导了两种不同转换率的连续时间马尔可夫链（CTMC）路径测度的Kullback-Leibler（KL）散度，并进行了关于转换率估计误差和早期停止误差的全面分析，这种类型的误差在现有工作中很少进行研究。本文通过生成器匹配和均匀化建立了关于分布估计的非渐近误差界。
### Conclusion
本文的结果首次为离散流模型提供了误差分析。
## 1289. `cs.LG` - 通过因果推理导航结构化输出格式对大规模语言模型的影响 [PDF](https://arxiv.org/pdf/2509.21791), [HTML](https://arxiv.org/abs/2509.21791)
### Authors
Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma
### Background
大型语言模型（LLMs）产生的结构化输出提升了处理生成信息的效率，并广泛应用于工业领域。前期研究探讨了结构化输出对LLMs生成质量的影响，结果多为单向的，认为结构化格式能提升完整性和事实准确性，但也可能导致生成能力受限和评价指标下降。现有评估存在的局限包括测试场景受限、对比设置较弱和依赖粗略的评价标准。本文通过因果推理方法提供了更深入的分析。
### Innovation
本文使用因果推理方法对结构化输出对LLMs生成影响进行了分析，基于假设和保证的约束，推导出五个可能的因果结构，涵盖生成影响的各个方面。研究覆盖了七个公开和一个自建的推理任务，发现粗略的评价标准报告了GPT-4o生成受结构化输出影响的正面、负面或中性效果，但因果推理显示48个情景中有43个没有因果影响。
### Conclusion
在涉及多因素因果结构的情景中，具体的指令因素起到了关键作用。研究结果表明，通过因果推理能够更深入地理解结构化输出对LLMs的影响，揭示过去的评估可能存在的偏差。
## 1290. `cs.LG` - ERGO: 高效高分辨率视觉理解 [PDF](https://arxiv.org/pdf/2509.21991), [HTML](https://arxiv.org/abs/2509.21991)
### Authors
Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim
### Background
高效的高分辨率图像处理对于实际的视图语言应用至关重要。现有大规模视图语言模型因大量视觉标记导致了巨大的计算负担。随着“基于图像思考”模型的出现，推理能力已经从文本扩展到视觉领域。这促进了我们的两阶段“粗到细”推理管道的发展：首先对缩放后的图像进行分析以识别任务相关区域；然后仅对这些区域进行全分辨率裁剪并进入后续的推理阶段。这种做法减少了计算成本，同时保留了必要的精细视觉细节。主要挑战是推断哪些区域真正与查询相关。近期相关方法常常在输入图像缩放后的一级推理阶段失败，因为基于感知的推理需要清晰的视觉信息才能有效进行。
### Innovation
本文提出了ERGO（高效推理与引导式观察），这是一种基于强化学习的框架，能够进行基于推理的感知利用，以确定需要聚焦的区域。该模型可以处理感知不确定性，通过扩展裁剪区域来覆盖视觉模糊区域以回答问题。实验结果显示，ERGO在多个数据集上相比于原始模型和竞争方法具有更高的精度和更高的效率。例如，在V*基准上，ERGO仅使用23%的视觉标记超过了Qwen2.5-VL-7B，实现了3倍的推理加速。
### Conclusion
本文提出了一种高效的两阶段“粗到细”推理管道和基于强化学习的ERGO模型，有效地降低了计算成本，同时提高了精度。该模型在多个数据集上取得了显著的成果，实现了与之前模型相比更高的准确性和效率。
## 1291. `cs.LG` - Bilinear relational structure fixes reversal curse and enables consistent model editing [PDF](https://arxiv.org/pdf/2509.21993), [HTML](https://arxiv.org/abs/2509.21993)
### Authors
Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha
### Background
当前认为语言模型在从已学知的‘A是B’推导出未见过的‘B是A’事实时存在问题，这被视为一个基本限制。但现有研究并没有将这一问题看作是模型固有的失败，而是模型编码知识的方式所致。
### Innovation
通过从头训练语言模型（LM）来处理相互关系的知识图的合成数据集，展示了这种模型中自然地出现了双线性关系结构。这种结构显著减轻了逆向推导的诅咒，并使语言模型能够推导出未见过的反向事实。实验还展示了这种双线性结构在模型的逻辑一致性编辑中的关键作用。
### Conclusion
通过在关系知识数据集上进行训练，可以诱导出双线性内部表示，这种表示使模型在编辑之后表现出逻辑一致性。这意味着模型编辑的成功不仅依赖编辑算法，还取决于被修改的知识的底层表示几何结构。
## 1292. `cs.LG` - SBFA: 单个骗过位翻转攻击以破坏大型语言模型 [PDF](https://arxiv.org/pdf/2509.21843), [HTML](https://arxiv.org/abs/2509.21843)
### Authors
Jingkai Guo,Chaitali Chakrabarti,Deliang Fan
### Background
由于大型语言模型（LLMs）大规模在线部署，其模型完整性已成为迫切的安全问题。先前的位翻转攻击（BFAs）已经严重威胁到深度神经网络（DNNs），因为少量的位翻转可能导致模型准确率大幅下降。近年来，BFAs 已经被扩展应用到 LLMs 中，研究表明，尽管模块化和冗余性理论上可以提高鲁棒性，但少量恶意的位翻转同样可以导致 LLMs 的灾难性准确率下降。然而，现有的 BFAs 方法通常仅针对整数或浮点模型进行优化，限制了攻击的灵活性。在浮点模型中，随机位翻转往往将参数值翻转到极端值（例如，翻转指数位），这不仅不可隐藏，还可能导致数值运行时错误（例如无效的张量值（NaN/Inf）。
### Innovation
本文首次提出了SBFA（Sneaky Bit-Flip Attack）攻击方法，它仅通过一次位翻转就破坏LLM性能，但翻转后的值保持在良性层间权重分布中。该方法通过我们定义的参数敏感度指标ImpactScore进行迭代搜索和排序，结合了梯度敏感性和扰动范围，该指标受到良性层间权重分布的约束。此外，还提出了一个新型的轻量级SKIP搜索算法，以大幅减少搜索复杂性，使得SBFA搜索只需几十分钟即可在SOTA LLMs上成功运行。在Qwen, LLaMA, 和 Gemma 模型上，仅通过对一个位的翻转，SBFA在一帧数据格式（BF16和INT8）中都能将准确率降至随机水平以下，这揭示了SOTA LLM模型的严重安全问题。
### Conclusion
此次研究揭示了当前最先进的LLM模型的严重安全问题，并提出了SBFA方法，该方法仅通过一次位翻转就能破坏LLM性能，而翻转后的值仍然保持在良性层间的分布范围内。SBFA攻击方法成功地大幅降低了模型的准确率，突显了对LLM模型进行更深入和广泛的防御措施的重要性。
## 1293. `cs.LG` - GAN和扩散模型在MRI-to-CT转换中的对比分析 [PDF](https://arxiv.org/pdf/2509.22049), [HTML](https://arxiv.org/abs/2509.22049)
### Authors
Emily Honey,Anders Helbo,Jens Petersen
### Background
CT是治疗和诊断中不可或缺的工具，但在某些情况下，如CT缺失或难以获取，从MRI生成合成CT（sCT）图像的需求变得重要。因此，建立一种参考标准来了解哪些策略最有效用于MRI到CT的转换是有价值的。
### Innovation
本文比较了两种常用架构（cGAN和cDDPM）在MRI-to-CT转换中的性能差异，将经典的3D转换问题分解为一系列2D转换，研究减少计算成本的策略，同时也探索了仅使用单个MRI图像和多MRI切片作为生成过程条件的影响。
### Conclusion
我们的比较分析表明，MRI-to-CT生成模型受益于多通道条件输入和使用cDDPM架构作为模型。
## 1294. `cs.LG` - Elastic MoE: 解锁Mixture-of-Experts的推理时扩展性 [PDF](https://arxiv.org/pdf/2509.21892), [HTML](https://arxiv.org/abs/2509.21892)
### Authors
Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang
### Background
Mixture-of-Experts (MoE) 模型通常在训练和推理时固定激活专家的数量 $k$。直觉上，推理时激活更多的专家 $k'$ (其中 $k' > k$)意味着使用更多的模型参数进行计算，预期会提升性能。然而，事实并非如此，研究发现，激活专家的数量稍微增加后性能就会迅速下降。进一步的探究表明，这种性能下降源于专家之间缺乏白学习合作。
### Innovation
提出了Elastic Mixture-of-Experts (EMoE)，一种新的训练框架，允许MoE模型在推理时动态调整激活的专家数量，而无需额外的训练开销。通过训练专家以在不同的组合中协同工作，并鼓励路由器进行高质量的选择，EMoE 确保在不同计算预算下的鲁棒性能。实验结果显示，EMoE 显著扩大了有效扩展性能的范围，可以扩展到训练时间 $k$ 的2-3倍，并且还能进一步提升模型的最高性能。
### Conclusion
EMoE 通过强化专家间的合作，拓展了 MoE 模型在推理时性能扩展的有效范围。
## 1295. `cs.LG` - GSM-Agent: 使用可控环境理解代理推理 [PDF](https://arxiv.org/pdf/2509.21998), [HTML](https://arxiv.org/abs/2509.21998)
### Authors
Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao
### Background
随着大语言模型（LLMs）被越来越多地用作代理，agent推理——结合工具使用和推理的能力——成为一项关键技能。然而，在复杂环境和任务中评估agent推理十分困难。当前的代理基准通常将agent推理与复杂的数学推理、专家级知识和其他高级能力混合在一起。这导致评估和理解agent推理的难度增加。
### Innovation
本文构建了一个新的基准，GSM-Agent，要求LLM代理解决小学级别的推理问题，但仅在提示中提供问题而没有包含解决问题所需信息的前提，需要通过工具主动收集信息。虽然原始任务是小学数学问题，但即使像GPT-5这样的前沿模型也只达到67%的准确率。此外，作者提出了agent推理图的概念来理解和分析agent推理模式，并提出了基于这种洞察的工具增强测试时缩放方法来改进LLM的agent推理性能。
### Conclusion
本文介绍了GSM-Agent基准和agent推理框架，旨在帮助未来研究了解和推动agent推理的边界。
## 1296. `cs.LG` - FlowDrive：使用数据平衡的适度流动匹配进行轨迹规划 [PDF](https://arxiv.org/pdf/2509.21961), [HTML](https://arxiv.org/abs/2509.21961)
### Authors
Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller
### Background
基于学习的规划器对驾驶数据的长尾分布敏感。常见的驾驶行为在数据集中占主导地位，而危险或罕见的情况则很少见。这种不平衡会导致模型偏向频繁的情况，从而在关键场景上的性能下降。因此，需要解决这种数据分布不平衡的问题以改进规划器的性能，特别是在关键场景上的表现.
### Innovation
研究了采样训练数据的平衡策略，并发现轨迹模式加权是有效的方法。提出了一个轨迹匹配规划器FlowDrive，它学习一个条件校正流动以直接将噪声映射到轨迹分布，并通过少量的轨迹匹配步骤实现这种映射。此外，引入了一种平衡的、在环路中的指导方法，通过在流匹配步骤之间注入小的扰动来系统地增加轨迹多样性，同时保持场景一致性。
### Conclusion
在nuPlan和交互重点的interPlan基准测试中，FlowDrive在基于学习的规划器中实现了最先进的结果，并接近具有规则基础精炼的方法。通过添加平衡的指导和少量的后处理（FlowDrive*），它在全球所有基准测试拆分中实现了整体最先进的性能。
## 1297. `cs.LG` - 具有折叠高斯过程先验的非参数离散霍克斯模型 [PDF](https://arxiv.org/pdf/2509.21996), [HTML](https://arxiv.org/abs/2509.21996)
### Authors
Trinnhallen Brisley,Gordon Ross,Daniel Paulin
### Background
霍克斯过程模型被广泛用于事件驱动的概率模型，特别是在过去事件增加了未来事件发生的概率的情况下。尽管许多应用事件记录为网格上的计数，但离散时间霍克斯模型仍然相对未被充分利用，并且常受限于固定形式的基础和激励核。这些模型缺乏灵活、非参数化的处理，特别是在离散时间条件下对基础和激励的处理不够灵活。
### Innovation
提出了一种非参数框架Gaussian Process Discrete Hawkes Process (GP-DHP)，该框架在基础和激励上使用高斯过程先验，并通过折叠潜在表示进行推断。该方法提供了平滑、数据自适应的结构，而无需预先规定趋势、周期性或衰减形状，同时还具有接近线性时间的近似最大后验估计方法，复杂度为O(T log T)。优化的潜在轨迹可以恢复可解释的基础和激励函数，进一步提高了模型的可解释性，尤其是提高了事件的突发性、滞后性以及季节性背景变化的捕获能力。
### Conclusion
在模拟和实际案例研究中，GP-DHP能够在不牺牲可扩展性或解释性的情况下，提供灵活的离散时间自激发性功能，显著提升了对恐怖袭击事件和周度Cryptosporidiosis计数的测试预测对数似然比。
## 1298. `cs.LG` - 直接倾向评分与平均处理效应偏差校正项估计 [PDF](https://arxiv.org/pdf/2509.22122), [HTML](https://arxiv.org/abs/2509.22122)
### Authors
Masahiro Kato
### Background
该研究致力于处理效应（ATE）的估计问题。在此背景下，通过直接偏差校正项的估计来评估倾向评分。文章探讨了观察数据 $X_i, D_i, Y_i$ 的含义，其中 $X_i rightarrow p$ 维协变量，$D_i rightarrow$ 二元治疗分配指示符，$Y_i rightarrow$ 结果变量。倾向评分（$e_0(X_i)$）对于ATE估计至关重要，作为一种关键的偏差校正项（$h_0(X_i, D_i)$），该研究指出现有的估计方法（如最大似然估计或协变量平权拟合）可能无法最有效地估计 $h_0$ 或 ATE 的准确性。通过分析偏差校正项的重要性，研究期望通过直接最小化偏差校正项来进行更准确的ATE估计。
### Innovation
研究提出了一种直接偏差校正项估计的方法，并将其从Bregman散度最小化的角度进行了一般化框架的阐述。不同于现有方法，此方法旨在提高偏差校正项 h_0 以及其对 ATE 估计的准确性。其创新点在于提供了一个新的、直接的方法来估计倾向评分和偏差校正项，而非采用传统的间接方法。研究还在模拟实验中评估了新方法的有效性。
### Conclusion
研究通过直接最小化偏差校正项 $h_0$ 的预测误差，提出了一种新的方法原型，以提高 ATE 的准确估计。通过模拟研究，验证了该新方法的有效性，表明在面对存在偏差校正问题的数据时，该直接估计方法可能比传统方法更优。
## 1299. `cs.LG` - 基于随机矩阵视角的回声状态网络：从精确偏差-方差表征到最优正则化 [PDF](https://arxiv.org/pdf/2509.22011), [HTML](https://arxiv.org/abs/2509.22011)
### Authors
Yessin Moakher,Malik Tiomoko,Cosme Louart,Zhenyu Liao
### Background
本文旨在对回声状态网络（ESNs）在教师-学生框架中的表现进行严格的渐近分析，特别是在一个具有oracle权重的线性教师的情况下。利用随机矩阵理论，导出了偏置、方差和均方误差（MSE）的封闭形式表达，这些都与输入统计、oracle向量和岭正则化参数相关。这项研究揭示了ESNs与经典岭回归之间的两个关键差异，即ESNs不表现出双梯形现象，并且在训练样本数量和教师记忆长度有限的情况下，ESNs能达到更低的均方误差。此外，还提供了在身份输入协方差情况下最优正则化的显式公式，并提出了计算一般情况下的最优值的有效数值方案。这些结果为ESN调整提供了一个可解释的理论基础和实用指导，有助于解释最近的实证观察结果中的性能保证。
### Innovation
本文通过随机矩阵理论，对ESNs在教师-学生框架中的表现进行了严格的渐近分析，导出偏置、方差和MSE的封闭形式表达，并揭示了ESNs与经典岭回归之间的两个关键差异。此外，还提供了在特定情况下的最优正则化公式，并提出了通用情况下的计算方案。
### Conclusion
研究结果表明，这些理论为调整ESN提供了一个可解释的框架，并为解释最近的实证观察结果提供了证明的性能保证。
## 1300. `cs.LG` - 使用深度学习探索早期宇宙 [PDF](https://arxiv.org/pdf/2509.22018), [HTML](https://arxiv.org/abs/2509.22018)
### Authors
Emmanuel de Salis,Massimo De Santis,Davide Piras,Sambit K. Giri,Michele Bianco,Nicolas Cerardi,Philipp Denzel,Merve Selcuk-Simsek,Kelley M. Hess,M. Carmen Toribio,Franz Kirsten,Hatem Ghorbel
### Background
氢是宇宙中最多的元素。第一代恒星和星系产生的光子使氢气电离，导致被称为辐射时代（EoR）的宇宙事件。即将建成的平方公里阵列天文台（SKAO）将测绘这一时期中性氢的分布，有助于研究这些第一代对象的性质。然而，从如此大量数据中提取天体物理信息将极具挑战性，因为氢信号将被不想要的前景污染和仪器系统误差所混淆。为了应对这种情况，我们开发了最新的深度学习技术来提取从SKAO预期的氢信号的2D功率谱中的信息。通过一系列神经网络模型对这些测量数据的应用，我们量化其预测宇宙氢化过程历史的能力，这与早期光子源的数量和效率增加有关。研究表明，研究早期宇宙得益于现代深度学习技术。特别是，我们证明专用机器学习算法能够平均恢复再电离历史的能力超过0.95的R²评分，这使得早期宇宙的结构形成及其精确的宇宙学和天体物理学的推断成为可能。
### Innovation
开发了最新的深度学习技术，通过应用一系列神经网络模型来测绘从SKAO预期的氢信号的2D功率谱中的信息。这些算法能够平均恢复再电离历史的能力超过0.95的R²评分，显著提高了从大量数据中提取天体物理信息的能力。
### Conclusion
现代深度学习技术在研究早期宇宙星系和恒星的形成以及宇宙学和天体物理学的精确推断中起到了关键作用。这些机器学习算法能够有效地从SKAO提供的大量数据中提取有价值的天体物理信息，从而实现对早期宇宙历史的准确和精确的推断。
## 1301. `cs.LG` - 防止过度参数化下的模型崩溃：插值学习和岭回归的理想混合比例 [PDF](https://arxiv.org/pdf/2509.22341), [HTML](https://arxiv.org/abs/2509.22341)
### Authors
Anvit Garg,Sohom Bhattacharya,Pragya Sur
### Background
生成模型在反复训练其自身合成输出后会出现模型崩溃现象，即模型性能逐渐下降。本文在每次迭代都混合新鲜真实标签和模型自上次迭代拟合的合成标签的设置下，研究了这种现象在过参数化线性回归中的表现。
### Innovation
研究人员推导出了最小-$boldsymbol{boldsymbol{boldsymbol{boldsymbol{l}}}}_2$范数插值和岭回归在该迭代方案下的精确泛化误差公式，并通过分析揭示了能最小化长期预测误差并预防模型崩溃的理想混合权重。特别地，他们发现对于最小-$boldsymbol{boldsymbol{boldsymbol{boldsymbol{l}}}}_2$范数插值，最优的真实数据比例在相当广泛的因变量分布情况下收敛到黄金比例的倒数。此外，对于岭回归，他们进一步分析了两种流行模型类——随机效应模型和尖峰协方差模型，展示了谱几何如何决定最优权重。
### Conclusion
两种情况下，研究人员都发现最佳混合比至少应为一半，反映了倾向于真实数据的重要性。理论结果通过广泛模拟得到了验证。
## 1302. `cs.LG` - 基于离线强化学习和大语言模型合作的多agent路径规划 [PDF](https://arxiv.org/pdf/2509.22130), [HTML](https://arxiv.org/abs/2509.22130)
### Authors
Merve Atasever,Matthew Hong,Mihir Nitin Kulkarni,Qingpei Li,Jyotirmoy V. Deshmukh
### Background
多Agent路径规划（MAPF）对于机器人技术和物流应用至关重要，但由于其组合复杂性和现实环境中固有的不完全可观测性，这个问题极具挑战性。传统的分散型强化学习方法通常会遇到两大难题：首先，训练出的代理往往会表现出自私的行为，导致频繁的碰撞；其次，对复杂通信模块的依赖导致训练时间显著延长，有时会持续数周。面对这两个挑战，该研究提出了一种基于决策转换器（DT）的高效分散规划框架，利用离线强化学习显著缩短了训练时间，从几周降低至几小时。此外，还引入了大型语言模型（GPT-4o）来动态指导代理策略，以克服在动态环境变化下标准强化学习方法的可适应性限制。大量在静态和动态变化环境中的实验结果表明，该DT方法结合GPT-4o能够显著提高适应性和性能。
### Innovation
提出了一个基于决策转换器（DT）的高效分散规划框架，利用离线强化学习显著缩短了训练时间。与此同时，通过集成大型语言模型（GPT-4o）动态指导代理策略，增强了算法在动态环境变化下的可适应性。
### Conclusion
通过结合基于决策转换器的分散规划框架和大型语言模型的辅助，该研究提出了一个有效的算法，显著缩短了训练时间并增强了多Agent路径规划在动态环境中的适应性和性能。
## 1303. `cs.LG` - DragGANSpace：GAN中的潜在空间探索与控制 [PDF](https://arxiv.org/pdf/2509.22169), [HTML](https://arxiv.org/abs/2509.22169)
### Authors
Kirsten Odendaal,Neela Kaushik,Spencer Halverson
### Background
该工作将StyleGAN、DragGAN和主成分分析（PCA）结合在一起，以提高GAN生成图像的潜在空间效率和可控性。StyleGAN提供了结构化的潜在空间，DragGAN能够实现直观的图像操作，而PCA则通过减少维度并促进跨模型对齐来提高潜在空间探索的简化性和可解释性。研究者将这些技术应用于高质量动物面部数据集（AFHQ），发现了在保留性能的同时，通过结合PCA进行降维和DragGAN框架实现图像操作能够提高优化效率。特别地，在DragGAN的潜在W+层中引入PCA可以一致性地缩短总优化时间，同时保持良好的视觉质量，甚至在较浅的潜在空间中（W+层=3）提升优化图像的结构相似性指数（SSIM）。此外，该研究还展示了在训练于类似但不同数据领域的两个StyleGAN模型之间对生成的图像进行对齐的能力，并表明可以通过控制对齐图像的潜在空间，从而对图像进行直观且可解释的操作。这项研究的结果强调了在多种图像合成和编辑应用中，对潜在空间实现高效且可解释控制的可能性。
### Innovation
1. 将StyleGAN、DragGAN和PCA结合使用，提高潜在空间的效率和可控性。2. 在DragGAN的潜在W+层中引入PCA，缩短总优化时间，同时保持甚至提升视觉质量和SSIM。3. 对跨模型生成的图像进行对齐，并实现对这些对齐图像的直观和可解释的操作。
### Conclusion
该方法通过整合PCA的降维技术与DragGAN框架，在保留性能的同时提高了优化效率。此外，该研究提出了通过控制潜在空间实现对生成图像的直观和可解释操作的可能性，为进一步的图像合成和编辑应用提供了新的思路和方法。
## 1304. `cs.LG` - 在学习中引入先验：基于教师-学生框架的随机矩阵研究 [PDF](https://arxiv.org/pdf/2509.22124), [HTML](https://arxiv.org/abs/2509.22124)
### Authors
Malik Tiomoko,Ekkehard Schnoor
### Background
正则化线性回归是机器学习的核心技术之一，尽管如此，当使用特征信息丰富先验时，其高维行为仍然不甚了解。本文提供了一种先验中心化于领域信息初始化下的最大后验（MAP）回归的首个精确渐近特征描述，涵盖岭回归、最小二乘法和先验导向估计。通过随机矩阵理论，本研究为训练风险与测试风险提供了闭合性风险公式，揭示了偏差-方差-先验间的权衡关系，解释了双下降现象，并量化了先验不匹配的情况。
### Innovation
1. 提供了最大后验（MAP）回归在高维情况下的精确渐近特征描述，适用于具有特征信息先验的初始化。2. 研究通过随机矩阵理论为训练风险和测试风险提供了闭合性公式。3. 揭示偏差-方差-先验间的权衡关系，解释了双下降现象，并量化了先验不匹配情况。4. 识别了测试风险的闭合形式最小化器，这有助于简单估计最优正则化参数。5. 模拟结果验证研究理论的高度准确性。6. 结合贝叶斯先验、经典正则化和技术现代渐近性，提供关于学习中使用结构化先验知识的概念澄清和实际指导。
### Conclusion
本文通过量化的研究结果，强化了贝叶斯先验、经典正则化和现代渐近性的联系，为学习中使用结构化先验提供了概念性和实践性的指导。
## 1305. `cs.LG` - 临床不确定性影响机器学习评估 [PDF](https://arxiv.org/pdf/2509.22242), [HTML](https://arxiv.org/abs/2509.22242)
### Authors
Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly
### Background
临床数据集标签往往不明确，因为注释者之间存在分歧，且对不同病例的置信度也不统一。传统的聚合方法，如多数投票，会掩盖这种变异性。实验表明，考虑到二分类标签的置信度会对模型排名产生显著影响。因此，有必要在机器学习评估中明确考虑注释不确定性，使用能够直接处理分布的概率性指标。这些指标可以独立于注释生成过程进行应用，并且计算成本较低，因为闭形式表达式的实现时间复杂度为线性，只需按模型得分排序即可应用。
### Innovation
提出了明确考虑注释不确定性进行机器学习评估的方法，使用概率性指标直接作用于分布，不受注释生成过程的限制，且计算效率高。这为临床数据集的评估提供了新的视角，改进了现有评估方法的准确性。
### Conclusion
建议社区发布原始注释数据，并采用具备不确定性的评估方法，以更准确地反映临床数据的实际性能。
## 1306. `cs.LG` - NeuroScalar：一种用于快速、准确、在野的 cycle 级性能预测的深度学习框架 [PDF](https://arxiv.org/pdf/2509.22410), [HTML](https://arxiv.org/abs/2509.22410)
### Authors
Shayne Wadle,Yanxin Zhang,Vikas Singh,Karthikeyan Sankaralingam
### Background
现有微处理器设计的评估受到依赖于不具代表性的基准跟踪的缓慢且周期准确模拟器的限制。
### Innovation
本文介绍了一种全新的深度学习框架，用于生产硬件上的高保真、在野模拟。该框架的核心贡献是一个基于微体系结构无关特征训练的 DL 模型，用于预测设计中的处理器性能。该模型部署在现有硅片上，能够评估未来硬件。此外，一体化设计的 Neutrino 芯片级加速器比 GPU 性能提升 85 倍。该系统以轻量级硬件跟踪收集器和有效的采样策略为特色，实现了在常规 GPU 上每秒百万条指令（MIPS）的模拟速度，性能开销仅为 0.1%。
### Conclusion
该框架使得大规模真实应用级别的硬件 A/B 测试和性能分析变为可能。
## 1307. `cs.LG` - 与实际数据监督无关的通用逆蒸馏方法用于匹配模型 [PDF](https://arxiv.org/pdf/2509.22459), [HTML](https://arxiv.org/abs/2509.22459)
### Authors
Nikita Kornilov,David Li,Tikhon Mavrin,Aleksei Leonov,Nikita Gushchin,Evgeny Burnaev,Iaroslav Koshelev,Alexander Korotin
### Background
现代生成模型如扩散模型和流模型尽管能够生成高质量的内容，但在推理时速度较慢，因为它们需要迭代生成多个步骤。近来，通过训练在预训练的教师模型指导下的一步生成器来解决此问题。然而，这些方法通常只能针对特定框架，例如仅针对扩散模型或仅针对流模型。此外，它们天生是数据无关的，若要利用实际数据，则需要额外复杂的对抗训练和额外的判别器模型。
### Innovation
本文提出了RealUID，一种适用于所有匹配模型的通用蒸馏框架，无需生成对抗网络(GAN)，无缝将真实数据纳入蒸馏过程。RealUID 提供了一个简单的理论基础，涵盖了先前针对流动匹配和扩散模型的蒸馏方法，并扩展适用于其修改，如桥接匹配和随机插值。
### Conclusion
研究展示了如何避免使用生成对抗网络（GANs）来将实际数据结合到所有匹配模型的蒸馏过程中，并提出了RealUID作为一项创新的解决方案，在不增加额外复杂性的前提下，提高了生成模型的效率。
## 1308. `cs.LG` - 结构稀疏过渡矩阵以增强状态空间模型中的状态跟踪能力 [PDF](https://arxiv.org/pdf/2509.22284), [HTML](https://arxiv.org/abs/2509.22284)
### Authors
Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi
### Background
现代状态空间模型（SSMs）通常利用过渡矩阵进行高效的计算，但过渡矩阵的结构限制了模型的表达能力，特别是在模拟有限状态自动机（FSAs）方面。虽然非结构化的过渡矩阵在表达能力上是理想的，但在中等状态规模情况下，由于计算和内存成本过高而难以实用。现有的结构化SSMs参数化方式要么在表达能力上有所欠缺，要么计算成本较高。该研究旨在提出一种结构稀疏参数化方法，既保持表达能力的理想水平，同时使计算成本与对角SSMs相当。这种方法通过将过渡矩阵表示为一列独热矩阵和一个复数对角矩阵的乘积，实现了在保持状态数量和深度的情况下，可与对角SSMs的循环计算成本相媲美的计算开销。
### Innovation
提出了一种结构化的稀疏参数化方法PD-SSM，将过渡矩阵表示为一列独热矩阵和一个复数对角矩阵的乘积。这种方法使得并行扫描的计算成本线性增加，理论上，该模型可以对任何N状态的FSAs进行建模，显著改进了所有当前的结构化SSMs保证。实验结果表明，该模型在各种FSAs状态跟踪任务中显著优于现代SSMs的各种变体。在多类别时间序列分类任务中，其表现与专门为时间序列分析设计的神经控制微分方程相当。最终，将PD-SSM整合进了混合Transformer-SSM架构中，证明该模型可以有效地跟踪一个复杂FSAs的状态，其中状态转换是以一系列不同长度的英文句子编码的。
### Conclusion
本文提出的PD-SSM结构稀疏参数化方法在保持表达能力的同时，解决了计算成本高的问题，具有高效、可扩展和易实现的特点。PD-SSM不仅在FSAs状态跟踪任务中表现出色，还在多类别时间序列分类任务中与神经控制微分方程相媲美。该方法为构建高性能的SSM提供了新的思路，可用于广泛的自动机建模和时间序列分析应用。
## 1309. `cs.LG` - CausalKANs: 可解释的治疗效应估计方法与柯尔莫哥洛夫-阿诺德网络 [PDF](https://arxiv.org/pdf/2509.22467), [HTML](https://arxiv.org/abs/2509.22467)
### Authors
Alejandro Almodóvar,Patricia A. Apellániz,Santiago Zazo,Juan Parras
### Background
深度神经网络在估计异质治疗效应方面表现出卓越的性能，但其不透明性限制了其在医疗、经济学和公共政策等敏感领域的信任与应用。现有基于因果神经架构的估计器尽管表现良好，但依然难以解释，影响了其实际应用。
### Innovation
本文提出了一种名为因果KAN（causalKANs）的框架，将条件平均治疗效应（CATEs）的神经估计器转换为柯尔莫哥洛夫-阿诺德网络（KANs）。通过修剪和符号简化，因果KANs 保留了预测准确性的同时获得了可解释的闭式公式。实验表明，因果KANs 在 CATE 错误指标上表现与神经基线相当，即使是简单版本的KANs 也达到了可竞争的性能，提供了精度和可解释性之间的良好权衡。
### Conclusion
通过结合可靠性和分析可访问性，因果KANs 提供了基于闭式表达式的可审计估计器，并通过可解释的图表支持决策，使其能够在高利益环境中实现可信的个性化决策。代码在此 <this https URL> 可供复现。
## 1310. `cs.LG` - HiGS：历史导向采样以提高扩散模型的即插即用增强效果 [PDF](https://arxiv.org/pdf/2509.22300), [HTML](https://arxiv.org/abs/2509.22300)
### Authors
Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
### Background
尽管扩散模型在图像生成任务上取得了显著的进步，但其生成的图像仍然可能存在不真实感，并且缺乏细节，特别是在神经网络函数评估次数（NFEs）少或指导尺度低的情况下更为明显。这个问题限制了扩散模型在实际应用中的表现和实用性。
### Innovation
本文提出了一种新颖的历史导向采样技术（History-Guided Sampling，HiGS），该技术通过将最近的模型预测整合到每次推理步骤中，从而提高扩散采样的质量和效率。具体来说，HiGS 利用了当前预测与过去预测的加权平均值之间的差异来引导采样过程，使其更趋向于生成更真实且具有更好细节和结构的图像。这种技术在实际计算上几乎不需要额外的开销，并无缝地集成到现有的扩散框架中，无需额外的训练或调优过程。通过广泛的实验表明，HiGS 能够在不同模型和架构下以及在不同的采样预算和指导尺度下，持续改进图像质量。此外，使用预训练的 SiT 模型，HiGS 在 256x256 大小的无引导 ImageNet 生成任务中实现了新的 FID 状态（即 1.61，而标准方法的标准是 250 采样步骤）.
### Conclusion
因此，HiGS 作为标准扩散采样的一种即插即用增强方式，能够提供更快的生成速度和更高的图像保真度。
## 1311. `cs.LG` - 在提示语义任务空间中表示LLMs [PDF](https://arxiv.org/pdf/2509.22506), [HTML](https://arxiv.org/abs/2509.22506)
### Authors
Idan Kashani,Avi Mendelson,Yaniv Nemcovsky
### Background
大语言模型（LLMs）在各种任务中取得了显著成果，公共存储库中也充满了预训练模型。然而，对于特定任务如何选择最佳的LLM是一个挑战。尽管之前的工作建议学习LLM表示以解决这一问题，但这些方法在可扩展性和计算成本上存在局限性，并且表示形式难以解释。
### Innovation
本文提出了一种无需训练的高效方法，将LLMs表示为提示语义任务空间中的线性算子。该方法利用闭形式几何性质计算，确保了出色的大规模处理能力和动态扩展库的实时适应能力。该研究验证了其在成功预测和模型选择任务中的表现，达到了竞争性或最新技术水平。
### Conclusion
通过将LLMs表示为提示语义任务空间中的线性算子，该方法提供了一种高度可解释的模型表示，并在实际应用场景中表现出良好的性能，尤其在新数据集上的表现尤为出色。
## 1312. `cs.LG` - NIFTY: 一种非局部图像流匹配的纹理合成方法 [PDF](https://arxiv.org/pdf/2509.22318), [HTML](https://arxiv.org/abs/2509.22318)
### Authors
Pierrick Chatillon,Julien Rabin,David Tschumperlé
### Background
该论文针对基于样本的纹理合成问题进行研究。现有的方法主要依靠卷积神经网络训练的扩散模型和经典基于局部块的纹理优化技术，而这些方法存在需要大量训练、初始化问题和视觉伪影等问题。为了解决这些问题，作者提出了NIFTY框架，这是一个基于非局部块匹配的非参数流匹配模型，避免了神经网络训练的需求，改善了基于块方法的缺点。通过实验结果表明该方法的效果优于文献中的代表性方法。
### Innovation
NIFTY框架结合了最近在扩散模型和经典基于局部块的纹理优化技术方面的见解，提出了一种基于非局部块匹配的非参数流匹配模型，避免了神经网络训练的需求，解决了传统基于块方法的初始化问题和视觉伪影问题。同时，实验结果证明了其有效性，与文献中的其他方法相比具有优势。
### Conclusion
本文提出了NIFTY框架，通过实验验证了该方法在纹理合成任务中的效果，且相比其他方法更具有优势。此外，该方法避免了神经网络训练的需求，具有更良好的应用前景。
## 1313. `cs.LG` - TrueGradeAI：透明且免偏见的可解释人工智能，用于透明和可解释的数字评估 [PDF](https://arxiv.org/pdf/2509.22516), [HTML](https://arxiv.org/abs/2509.22516)
### Authors
Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla
### Background
传统纸质考试存在大量纸张浪费、物流复杂、评分延迟和评分者偏见等问题。真题AI（TrueGradeAI）是一种基于AI的数字考试框架，旨在解决这些传统考题的不足，通过在安全平板上使用触控笔输入并应用基于变换器的光学字符识别技术来保留自然手写，从而改进考试流程。
### Innovation
TrueGradeAI 通过引入可解释的自动化、偏见缓解以及可审计的评分轨迹，超越了仅数字化回答的传统平板考试系统。该系统采用检索增强管道进行评估，结合教员解决方案、缓存层和外部参考，使大规模语言模型能够通过与证据相连的解释进行评分。
### Conclusion
通过结合保留手写与可扩展、透明的评估，该框架减少了环境成本，加快了反馈循环，逐步构建了一个可重复使用的知识库，同时积极工作以缓解评分偏见，确保评估的公平性。
## 1314. `cs.LG` - 多通道卷积神经量子嵌入 [PDF](https://arxiv.org/pdf/2509.22355), [HTML](https://arxiv.org/abs/2509.22355)
### Authors
Yujin Kim,Changjae Im,Taehyun Kim,Tak Hur,Daniel K. Park
### Background
量子机器学习中的分类任务具有广阔前景，特别是通过量子监督学习（QSL）将经典数据嵌入量子希尔伯特空间，并通过优化门电路参数来训练度量过程。然而，这种技术的有效性很大程度上依赖于量子嵌入的选择。因此，研究提出了一个经典-量子混合方法，用于优化超出标准量子计算电路模型限制的通用多通道数据的量子嵌入。研究表明了多种模型的性能，并利用CIFAR-10和Tiny ImageNet数据集进行基准测试，并提供了理论分析来指导模型设计与优化。
### Innovation
该研究采用了一种经典-量子混合方法，超越了常规完全正且迹保持映射的量子计算电路模型限制，为通用多通道数据优化量子嵌入。并通过CIFAR-10和Tiny ImageNet数据集来评估不同模型的性能，并提供了理论分析作为模型设计和优化的指导。
### Conclusion
研究在经典-量子混合框架下的方法对通用多通道数据优化量子嵌入表现良好，并通过数值实验验证。同时，理论分析对进一步优化模型具有重要的指导作用。
## 1315. `cs.LG` -  Transformers Can Learn Connectivity in Some Graphs but Not Others [PDF](https://arxiv.org/pdf/2509.22343), [HTML](https://arxiv.org/abs/2509.22343)
### Authors
Amit Roy,Abulhair Saparov
### Background
Transformer-based大型语言模型（LLMs）的推理能力对于确保响应的事实正确性至关重要，而推断传递关系的稳健推理在因果推理等许多场合中都是必不可少的。因此，调查transformer在推断传递关系任务上的能力是必要的，这相当于图连通性任务。过去的研究主要关注transformers能否从输入提示中的上下文示例中学习推断传递性，但其从训练样本中推断传递关系的能力及其随规模变化的影响尚未被探索。
### Innovation
本研究通过生成大小不同的有向图来训练不同规模的transformer模型，并评估其在不同图大小下推断传递关系的能力。研究发现，transformer能够学习“网格状”的有向图中的连通性，其中每个节点可以被嵌入在低维子空间中，连通性可以从节点嵌入中容易地推断出来。网格图的维度是transformer学习连通性任务能力的强预测器，高维网格图对transformer的挑战更大。此外，模型规模增加会改善transformer对网格图连通性的泛化能力。但如果不以网格图形式存在且包含许多不连通组件的图，transformer难以学习连通性任务，尤其是在组件数量较大时。
### Conclusion
研究结果表明，transformer在某些类型的图结构（如网格图）中能够学习连通性，但对其他类型的图结构（不具网格形式、包含多个不连通组件的图）无法很好地学习连通性任务。同时，随着模型规模的增加，对于网格图的连通性任务，transformer的性能会有所提升。
## 1316. `cs.LG` - 使用逻辑张量网络在医学语义分割中集成背景知识 [PDF](https://arxiv.org/pdf/2509.22399), [HTML](https://arxiv.org/abs/2509.22399)
### Authors
Luca Bergamin,Giovanna Maria Dimitri,Fabio Aiolli
### Background
医学图像分析中的语义分割是一个基本任务，有助于放射科医生通过区分图像中的对象来辅助医疗决策。尽管深度学习的应用使得这些系统能够处理噪声和伪影，但这些系统还未完全达到最佳状态。研究者们认为可以通过将一般医学知识集成到分割模型的损失函数中以提高性能，本文介绍了一种方法，即将逻辑张量网络（LTNs）用于编码基于一阶逻辑（FOL）规则的医学背景知识。该研究通过将即时网络（SwinUNETR）与端到端框架结合，专注于在脑部MRI扫描中分割海马体的任务。实验表明，当训练数据不足时，LTNs能显著提高基础分割性能。
### Innovation
本文引入了逻辑张量网络（LTNs）作为端到端框架的一部分，结合了一阶逻辑规则来编码和应用医学背景知识，这为语义分割任务提供了一种新的方法。这种方法在处理稀缺训练数据时表现出色，显示出提高分割模型性能的潜力，尤其是在注入医学专业知识方面。
### Conclusion
尽管神经符号方法目前还处于初级阶段，但作者认为，这些方法具有足够的通用性和适应性，可以应用于其他医学语义分割任务。
## 1317. `cs.LG` - 通过最优传输的多维不确定性量化 [PDF](https://arxiv.org/pdf/2509.22380), [HTML](https://arxiv.org/abs/2509.22380)
### Authors
Nikita Kotelevskii,Maiya Goloburda,Vladimir Kondratyev,Alexander Fishkov,Mohsen Guizani,Eric Moulines,Maxim Panov
### Background
当前大多数不确定性量化（UQ）方法仅提供单一的标量值来衡量模型可靠性。然而，不同类型的不确定性度量可以提供关于预测信心的互补信息，即使针对相同类型的不确定性（如基于贝氏法和基于密度的方法），它们也可能捕捉不同的失效模式。研究者们提出了一种从多维度视角进行不确定性量化的方法，即将互补的不确定性度量组合成一个向量，并使用最优传输为基础的方法对其进行排序，以评估模型的不确定性。
### Innovation
该文提出了一种新方法，称为VecUQ-OT算法，该算法使用熵正则化的最优传输来处理不确定性度量的融合，并能在不重新训练的情况下应用于未见过的输入（包括离分布数据）。这种方法能够灵活地融合非可加的不确定性（包括 aleatoric 和 epistemic 组分），适用于多种下游任务如选择性预测、分类错误检测、离分布检测以及选择性生成，并且在各种合成、图像和文本数据中显示了较高的效率。
### Conclusion
VecUQ-OT算法由于其高效且能处理不同失败模式的特性，在不重新训练模型的情况下就能对未见过的数据进行不确定性评估，为下游任务提供了可靠的排序结果。研究代码已被公开。
## 1318. `cs.LG` - 学习投篮：组成用于长时程篮球动作的策略 [PDF](https://arxiv.org/pdf/2509.22442), [HTML](https://arxiv.org/abs/2509.22442)
### Authors
Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu
### Background
对于强化学习方法来说，学习执行诸如篮球运球等一系列多阶段、长时间段的任务仍然具有挑战性，主要由于需要实现无缝的策略组合和技能转换。长时间段任务通常包括多个具有明确目标的子任务，以及那些目标不明确但对整个任务成功至关重要的过渡性子任务。现有的方法，如专家混合和技能链式方法，在个体策略不共享大量探索状态或在不同阶段缺乏清楚的起始和终点状态的情况下，难以胜任这些任务。
### Innovation
本文提出了一种新的策略集成框架，以实现多阶段长时间段任务中不确定中间状态下的极大不相似运动技能的组合。基于此框架，我们进一步引入了一个高级的柔性和路由器，使其能够在子任务之间实现无缝且鲁棒的转换。该框架在一系列基础篮球技能和挑战性过渡上进行了评估，表明通过我们方法训练的策略能够有效地控制模拟人物与球交互并执行由实时用户命令指定的长时间段任务，而无需依赖于球轨迹的参考。
### Conclusion
通过我们的框架，所训练的策略可以有效地控制模拟角色与球进行交互，并完成由实时用户命令指定的长时间任务，无论是否有球的轨迹参考。这为复杂、长时间任务的策略学习提供了新的方法。
## 1319. `cs.LG` - 网络参数族的度量 [PDF](https://arxiv.org/pdf/2509.22549), [HTML](https://arxiv.org/abs/2509.22549)
### Authors
Mario Gómez,Guanqun Ma,Tom Needham,Bei Wang
### Background
该研究提供了一个用于分析参数化网络数据框架的方法。这些网络数据可以是时间变化的度量空间、随时间演变的加权社交网络或随机图模型。研究基于Gromov-Wasserstein变体的最优传输，定义了一类参数化的Gromov-Wasserstein距离来比较这类参数化数据。该研究还指出了这些距离的基始性质，表明它们涵盖了文献中现有的多种度量方法，并提供了理论上的近似保证。
### Innovation
研究开发了可计算的下界，将其与随机图理论中常用的图统计数据相联系。此外，证明了该距离可以通过生成模型的的经验估计在随机图和随机度量空间中一致近似。
### Conclusion
研究通过一系列数值实验展示了该框架的实用性，证明了可计算的距离能有效比较参数化的网络数据。
## 1320. `cs.LG` - Dynamic Experts Search: 在Mixture-of-Experts大语言模型测试时增强推理 [PDF](https://arxiv.org/pdf/2509.22572), [HTML](https://arxiv.org/abs/2509.22572)
### Authors
Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang
### Background
Test-Time Scaling (TTS) 通过在推理过程中分配额外的计算资源来提升大语言模型（LLMs）的推理能力，但当前的TTS方法主要依赖于输出级采样，忽略了模型架构的作用。研究发现，在主流的Mixture-of-Experts (MoE) LLMs 中，激活专家的数量变化会带来互补的解集，并且这种变化能够提供稳定且可预测的准确性，揭示了一种新的未被充分利用的多样性来源。
### Innovation
研究提出了Dynamic Experts Search (DES)，一种TTS策略，将专家激活提升为搜索空间中的可控维度。DES 包括两个关键组件：(1) 动态MoE，允许在推理过程中直接控制专家数量，生成不同的推理轨迹而不需要额外的成本；(2) 专家配置继承，它在推理路径内保持一致的专家数量，但在不同的运行之间变化，从而在整个搜索过程中平衡稳定性和多样性。
### Conclusion
在多个MoE架构、验证器和推理基准测试（即数学、代码和知识）上的广泛实验表明，DES 比现有的TTS基准性能更优越，能够在不增加成本的情况下提升准确性和稳定性。这些结果强调，DES 是一种实用且可扩展的大语言模型架构感知TTS形式，展示了现代LLM的结构灵活性如何推动推理的提升。
## 1321. `cs.LG` - Estimating the Empowerment of Language Model Agents [PDF](https://arxiv.org/pdf/2509.22504), [HTML](https://arxiv.org/abs/2509.22504)
### Authors
Jinyeop Song,Jeff Gore,Max Kleiman-Weiner
### Background
随着语言模型（LM）代理变得越来越强大并获得更广泛的现实工具访问权，对于代理能力的可扩展评估框架的需求也在增加。然而，传统的基于基准的评估成本高昂，需要人类设计师提出有效的任务，这些任务能够转化为对通用模型能力的理解。因此，需要一种新的、成本效益更高的评估方法来检测LM代理的不同能力。
### Innovation
本文提出了一种基于信息论的评估方法——通过估算代理行动与其未来状态之间的互信息来衡量代理的“能力”（empowerment），并引入了EELMA算法来近似多轮文本交互的有效能力。该方法在语言游戏和扩展的现实Web浏览场景中得到了验证，发现能力与平均任务表现高度相关，并分析了环境复杂性和代理因素对估算能力的影响。
### Conclusion
这些结果表明，估算能力（empowerment）是一个有吸引力的通用指标，可以用于评估和监控在复杂、开放环境中运行的LM代理。
## 1322. `cs.LG` - REMA：一种解释大型语言模型推理的统一推理流形框架 [PDF](https://arxiv.org/pdf/2509.22518), [HTML](https://arxiv.org/abs/2509.22518)
### Authors
Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen
### Background
在可解释性研究中，理解大型语言模型（LLMs）执行复杂推理和其失败机制是一个挑战。本文通过定义推理流形的概念，提供了一种可量化的几何分析视角，旨在揭示模型内部表示之间的关系及其对任务成功解决的影响。推理流形是指所有正确推理生成对应的内部表示所形成的一种潜在的低维几何结构，可以视为模型已经学习到的有效思维路径的体现。
### Innovation
本文提出了REMA（Reasoning Manifold Explanation），这是一种框架，通过定量比较错误和正确推理样本对应的内部模型表示之间的空间关系，提供了一种统一的失败信号。具体来说，REMA首先通过计算每个错误表示的k-最近邻居距离及其与正确表示形成的近似流形之间的距离，量化了每种错误表示的几何偏差，从而提供了一个统一的失败信号。接着，REMA通过追踪这个偏差指标在模型各层之间的变化，并与正确表示的内部波动基线进行对比，来定位偏差第一次变得显著的故障点，从而识别推理链路开始偏离的地点。实验表明，该框架能够有效地分析推理失败的源头，并将抽象的推理失败连接到可测量的表示几何偏差上，为深入理解和诊断黑盒模型的内部计算过程提供了新途径。
### Conclusion
我们的实验表明，推理流形具有低维度的特性，并且错误和正确的推理表示之间高度可分离。该框架的有效性也得到了验证。REMA将抽象的推理失败具体化为可衡量的表示几何偏差，为深入理解和诊断黑盒模型的内部计算过程提供了新的研究方向。
## 1323. `cs.LG` - 基于平滑的分布自由预测方法以平衡效率与可解释性 [PDF](https://arxiv.org/pdf/2509.22529), [HTML](https://arxiv.org/abs/2509.22529)
### Authors
Mingyi Zheng,Hongyu Jiang,Yizhou Lu,Jiaye Teng
### Background
Conformal Prediction (CP)是一种统计上严格的预测区间构建框架，无需依赖于分布假设。尽管流行变体如CD-split能够提高CP的效率，但它们生成的预测区间往往由多个不连续子区间组成，这使得这些区间难以解释。
### Innovation
本文提出了SCD-split，它在CP框架中融入平滑操作。这种平滑操作有潜力将子区间合并，从而使预测区间更易于理解。实验结果表明，SCD-split能够平衡区间长度和不连续子区间数量。理论分析表明，当满足特定条件时，SCD-split能够在减少无连接子区间数量的同时，保持与CD-split相当的覆盖保证和区间长度性能。
### Conclusion
实验和理论结果均表明，SCD-split在平衡预测区间效率和可解释性方面优于传统的CD-split变体。
## 1324. `cs.LG` - 从形式语言理论到统计学习：子正规语言的有限可观察性 [PDF](https://arxiv.org/pdf/2509.22598), [HTML](https://arxiv.org/abs/2509.22598)
### Authors
Katsuhiko Hayashi,Hidetaka Kamigaito
### Background
本文证明了当通过决定性谓词表示时，所有标准的子正规语言类是可以线性分割的。这确立了有限可观察性，并保证了可以使用简单的线性模型进行学习。合成实验在无噪声条件下验证了完美的可分性，而对英语形态的真实数据实验表明学习出的特征与已知的语义约束一致。这些结果表明，子正规层次结构为建模自然语言结构提供了一个严格的可解释性基础。
### Innovation
本文的创新在于证明了所有标准的子正规语言类中的决定性谓词是线性可分的，这意味着这些语言是有限可观察的。这种结果进一步保证了可以用简单的线性模型来进行学习。此外，合成和真实数据实验的结合也证实了这一理论。
### Conclusion
本文结果表明，子正规层次结构是一个严格的可解释性基础，用于建模自然语言结构。而且，实验验证了这种方法的有效性，特别是学习出的特征与已知的语义约束一致。此外，提供的实验代码可以在指定的网址找到，可供进一步研究使用。
## 1325. `cs.LG` - 评估大型语言模型在多语言法律推理中的局限性 [PDF](https://arxiv.org/pdf/2509.22472), [HTML](https://arxiv.org/abs/2509.22472)
### Authors
Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel
### Background
在大型语言模型（LLMs）主导的背景下，了解这些模型在法律等高风险领域的能力和局限性至关重要。尽管Meta的LLaMA、OpenAI的ChatGPT、Google的Gemini和其他新兴模型正逐渐融入法律工作流程中，在多语言环境、管辖权限制多样以及对抗性情境中的表现尚未充分研究。本文评估了LLaMA和Gemini在多语言法律和非法律基准测试中的表现，并通过字符和词级扰动评估了它们在法律任务中的鲁棒性。使用LLM作为法官的方法来进行人类一致性的评估。此外，还提供了一个开源、模块化的评估管道，旨在支持使用任何LLM和数据集组合进行多语言、任务多样基准测试，特别关注法律任务，包括分类、总结、开放问题和一般推理。研究发现，法律任务对LLM构成了重大挑战，例如在LEXam等法律推理基准测试中准确性往往低于50%，而在通用任务如XNLI中则超过70%。此外，尽管英语结果通常更稳定，但并不总能导致更高的准确性。语言的提示敏感性和对抗性漏洞也显示出跨语言的持续性。最后，还发现语言表现与英语文法相似性之间的相关性。此外，观察到LLaMA在多个任务上弱于Gemini，后者在相同任务上平均优势约24个百分点。尽管新版本LLM有所改进，但在关键的多语言法律应用中可靠部署仍然面临挑战。
### Innovation
该研究使用LLM作为法官的方法进行人类一致性的评估，并提供了一个开源、模块化的评估管道，支持任何LLM和数据集组合进行多语言、任务多样基准测试，特别关注法律任务。此外，还详细评估了LLMs在法律推理中的表现，并发现了语言表达与英语文法相似性之间的相关性，以及LLaMA与Gemini之间的性能差异。
### Conclusion
研究证实法律任务对LLM构成了重大挑战，准确性普遍较低。语言的提示敏感性和对抗性漏洞也显示出持续性。语言表现与英语文法相似性存在相关性。LLaMA弱于Gemini。尽管LLM有所改进，但在多语言法律应用中可靠部署仍然面临挑战。
## 1326. `cs.LG` - StateX：通过后训练状态扩展提高RNN回忆能力 [PDF](https://arxiv.org/pdf/2509.22630), [HTML](https://arxiv.org/abs/2509.22630)
### Authors
Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
尽管基于Transformer的模型在自然语言建模中表现出色，但处理长上下文时其高复杂性带来了高昂的成本。相比之下，如线性注意力和状态空间模型的递归神经网络（RNNs）因其每词复杂度恒定而广受欢迎。然而，这些递归模型在需要准确回忆长上下文中的信息的任务上表现不佳，因为所有上下文信息都会压缩到一个固定大小的递归状态中。前人的研究显示，递归状态大小越大，回忆能力越强，但直接训练具有更大递归状态的RNN会导致高昂的训练成本。
### Innovation
这篇论文提出了StateX，一个通过后训练方法高效扩展预训练RNN状态大小的训练管道。对于两种流行的RNN类（线性注意力和状态空间模型），设计了后训练架构修改来在不增加或几乎不增加模型参数的情况下扩展状态大小。实验表明，StateX可以有效地提高RNN的回忆能力和上下文学习能力，且后训练成本较低，不牺牲其他功能。
### Conclusion
对于参数量从1.3亿到更大规模的模型，StateX能够高效地增强RNN的回忆能力和上下文学习能力，同时不增加后训练成本，不损害其他性能。
## 1327. `cs.LG` - ConQuER：具有控制和偏置缓解的IQP量子生成模型的模块化架构 [PDF](https://arxiv.org/pdf/2509.22551), [HTML](https://arxiv.org/abs/2509.22551)
### Authors
Xiaocheng Zou,Shijin Duan,Charles Fleming,Gaowen Liu,Ramana Rao Kompella,Shaolei Ren,Xiaolin Xu
### Background
基于瞬时量子多项式（IQP）电路的量子生成模型在学习复杂分布方面显示出巨大潜力，同时保持经典的可训练性。然而，当前实施存在两个关键限制：对生成输出的控制不足以及对某些预期模式的生成严重偏见。
### Innovation
提出了一种名为ConQuER的可控量子生成框架，通过模块化电路架构解决了上述挑战。该框架嵌入了一个轻量级控制器电路，可以与预训练的IQP电路直接结合，以精确控制输出分布而无需全面重训练。此外，通过数据驱动优化，该模块化方法在基本的IQP架构中嵌入隐含的控制路径，显著减少了在结构化数据集上的生成偏见。
### Conclusion
ConQuER保持了高效的经典训练特性和高度的可扩展性。通过在多种量子状态数据集中进行实验验证，证明了ConQuER具有优越的控制精度和平衡的生成性能，仅增加了很低的额外开销成本。该框架填补了量子计算优势与可控生成建模实践需求之间的空白。
## 1328. `cs.LG` - 规模级VAR其实秘密是离散扩散 [PDF](https://arxiv.org/pdf/2509.22636), [HTML](https://arxiv.org/abs/2509.22636)
### Authors
Amandeep Kumar,Nithin Gopalakrishnan Nair,Vishal M. Patel
### Background
自回归（AR）变压器因其实现大规模、计算高效以及具备语言和视觉统一架构而成为视觉生成的强大力法。最近，基于规模预测的视觉自回归生成（VAR）模型展示了卓越的性能，甚至超越了基于扩散的模型。
### Innovation
本文重新审视了VAR，揭示了一个理论上的洞察：通过装备马尔可夫注意力掩码，VAR在数学上等同于离散扩散。据此定义重新解释VAR，建立了AR变压器和扩散模型之间的原则性桥梁。通过这一新视角，本文展示了如何直接引入扩散模型的优势，如迭代细化，同时减少AR变压器的构建冗余，从而实现更快的收敛、更低的推理成本和更好的零样本重建。
### Conclusion
通过基于扩散的视角，VAR在效率和生成方面取得了持续的提升。
## 1329. `cs.LG` - Debiased Front-Door Learners for Heterogeneous Effects [PDF](https://arxiv.org/pdf/2509.22531), [HTML](https://arxiv.org/abs/2509.22531)
### Authors
Yonghan Jung
### Background
在观察环境中，当治疗和结果共享未测量混杂因素但存在未受影响的观察中介变量时，前门（Front-door，FD）调整可以通过中介变量识别因果效应。本文研究了在FD识别下的异质治疗效应（HTE）问题，并提出了两种修正偏差的学习器：FD-DR-Learner和FD-R-Learner。这两种学习器即使在辅助函数收敛速度慢至n^-1/4时，也能实现快速、近似或者理想的性能。作者提供了误差分析来证明这些修正偏差的学习器的鲁棒性，并通过合成数据和实际案例（使用FARS数据集，研究主驾安全带法律的影响）证实了其实际表现。
### Innovation
引入了两种修正偏差的学习器：FD-DR-Learner和FD-R-Learner。这两种学习器即使在辅助函数收敛速度慢至n^-1/4时，也能实现快速、近似或者理想的性能。作者提供了误差分析来证明这些修正偏差的学习器的鲁棒性，并在合成数据和实际案例中验证了它们的稳健性能。这些结果表明，提出的修正偏差学习器在FD识别情境下能可靠且高效地估计异质治疗效应。
### Conclusion
综上所述，本文提出的方法和学习器能有效和可靠地估计异质治疗效应，在FD识别情境下表现出高效能。这些学习器在FD场景下的表现证明了其鲁棒性和可靠性，为未来的因果推断研究提供了有力工具。
## 1330. `cs.LG` - 语言模型可以从口头反馈中学习，而无需标量奖励 [PDF](https://arxiv.org/pdf/2509.22638), [HTML](https://arxiv.org/abs/2509.22638)
### Authors
Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang
### Background
语言模型（LLMs）通常通过人类或AI反馈使用强化学习（RL）进行训练，但这种方法往往会将复杂的反馈简化为标量奖励，从而丢弃了很多重要信息并导致规模失衡。
### Innovation
本文提出了将口头反馈作为条件信号的方法。受文本到图像生成中的语言先验启发，引入了反馈条件策略（FCP）。FCP 直接从响应-反馈对中学习，通过离线数据上的最大似然训练近似反馈条件后验。此外，还开发了一个在线自助阶段，在此阶段策略在正面条件下生成并接收新的反馈以优化自身。
### Conclusion
这种做法将基于反馈的学习重新定义为条件生成，而非奖励优化，为LLMs提供了一种更富有表现力的方式以直接从口头反馈中学习。
## 1331. `cs.LG` - 通过拓扑排序、修枝和分离进行的线性因果表示学习 [PDF](https://arxiv.org/pdf/2509.22553), [HTML](https://arxiv.org/abs/2509.22553)
### Authors
Hao Chen,Lin Liu,Yu Guang Wang
### Background
因果表示学习（CRL）吸引了因果推断和人工智能社区的关注，因为它能够通过利用现代数据集的异质性，将潜在复杂的数据生成机制拆分为可因果解释的潜在特征。现有线性CRL方法通常依赖于严格的假设，如单节点干预数据的可获得性或潜在特征和外生测量噪声的严格分布约束。但在某些情况下，这些前提假设可能难以满足。为了解决这一问题，本文提出了一种线性CRL算法，该算法在假设环境异质性和数据生成分布较弱的情况下，依然能够恢复潜在因果特征到等价类。此算法已在合成实验和大型语言模型的可解释性分析中得到验证，显示出其在有限样本中优于现有方法的优越性以及将因果性整合到人工智能中的潜力.
### Innovation
提出了一种在较弱环境异质性和数据生成分布假设下工作的线性CRL算法。该算法能够恢复潜在因果特征到等价类，与大多数现有线性CRL方法相比，具有更弱的假设前提，并通过合成实验和大型语言模型的可解释性分析验证了其优越性和潜在应用价值.
### Conclusion
本文提出的线性CRL算法在弱环境异质性和数据生成分布假设下，仍能恢复潜在因果特征到等价类。通过合成实验和大型语言模型的可解释性分析，验证了该方法在有限样本中优于现有方法，并展示了将因果性整合到人工智能中的潜力。
## 1332. `cs.LG` - 自适应政策学习至附加任务 [PDF](https://arxiv.org/pdf/2305.15193), [HTML](https://arxiv.org/abs/2305.15193)
### Authors
Wenjian Hao,Zehui Lu,Zihao Liang,Tianyu Zhou,Shaoshuai Mou
### Background
本文开发了一种政策学习方法，用于调整预训练政策以适应额外的任务，而无需修改原始任务。文中提出了一种名为自适应政策梯度（APG）的方法，该方法结合了贝尔曼优化原理解与政策梯度方法，以提高收敛速度。
### Innovation
提出了结合贝尔曼优化原理和政策梯度方法的自适应政策梯度（APG）方法，保证了算法的收敛速度和样本复杂度分别是O(1/T)和O(1/ε)，并且通过多个挑战性的数值模拟实验展示了APG在数据使用量较少和收敛速度更快的情况下，能获得与现有确定性政策梯度方法相似的性能。
### Conclusion
实验结果表明，APG在数据使用量较少和收敛速度更快的情况下，能获得与现有确定性政策梯度方法相似的性能。
## 1333. `cs.LG` - 使用成对距离估计器在回归集成模型中高效估计认识不确定性 [PDF](https://arxiv.org/pdf/2308.13498), [HTML](https://arxiv.org/abs/2308.13498)
### Authors
Lucas Berry,David Meger
### Background
本文介绍了一种利用成对距离估计器(PaiDEs)为回归任务中的集成模型估计认识不确定性的新颖高效方法。PaiDEs通过模型组件之间的成对距离，为模型的熵设定了界限。这种方法被用来提升Bayesian Active Learning by Disagreement (BALD)的性能。实验中，研究人员发现PaiDEs不仅速度快100倍，还能够同时处理更多输入，在高维任务中表现出优越性。
### Innovation
提出了成对距离估计器(PaiDEs)进行高效的epistemic不确定性估计，与基于采样的蒙特卡洛估算方法相比，PaiDEs能在相同性能下提高100倍的估算速度，并能处理更多的输入。这种方法在高维度的回归任务中表现出色。
### Conclusion
通过多组回归实验证明了PaiDEs在认识不确定性估计的优势，尤其是在高维度回归任务中优于现有的主动学习方法。
## 1334. `cs.LG` - 超越亚模性目标的多智能体在线协调的有效策略学习 [PDF](https://arxiv.org/pdf/2509.22596), [HTML](https://arxiv.org/abs/2509.22596)
### Authors
Qixin Zhang,Yan Sun,Can Jin,Xikun Zhang,Yao Shu,Puning Zhao,Li Shen,Dacheng Tao
### Background
本文研究了多代理在线协调（MA-OC）问题，并提出了两个有效的策略学习算法。背景在于，以前的方法通常仅适用于亚模性目标，而本文的方法能够处理亚模性和弱亚模性目标，并且能够在没有未知参数的情况下进行学习，提高了算法的实际应用价值。
### Innovation
创新点在于提出了两个新型的在线算法MA-SPL和MA-MPL。MA-SPL不仅能够达到亚模性目标的（1-c/e）最佳近似保证，还能处理未探索的α-弱亚回归和（γ,β）-弱亚模性场景。MA-MPL则是一个完全参数自由的算法，并能保持与MA-SPL相同的近似比。核心创新在于提出了一种新型的策略基连续扩展技术，能够无损近似任意集合函数，从而能够解决具有挑战性的弱亚模性目标问题。
### Conclusion
实验结果表明，提出的算法能够在多智能体在线协调问题中有效地进行策略学习，尤其是在处理弱亚模性目标时表现出色。
## 1335. `cs.LG` - 语言模型规划中强化学习的优缺点：理论视角 [PDF](https://arxiv.org/pdf/2509.22613), [HTML](https://arxiv.org/abs/2509.22613)
### Authors
Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen
### Background
近年来，强化学习（RL）方法显著提升了大型语言模型（LLMs）的规划能力，但其有效性的理论依据尚不清楚。本文通过可处理的图基抽象方法，研究了RL的优势和限制，重点关注策略梯度（PG）和Q学习方法的理论分析。
### Innovation
本文揭示了监督微调（SFT）可能引入基于共现的虚假解决方案，而RL主要通过探索实现正确的规划，强调了探索在使模型更好地泛化方面的作用。此外，证明了PG在训练过程中会出现多样性坍塌的问题，而Q学习则在收敛时提供两种关键优势：离策略学习和多样性保持。
### Conclusion
实验结果还表明，在Q学习中精心设计奖励是防止奖励黑客行为的关键。应用本框架到实际的规划基准Blocksworld，证实了这些行为在实践中的表现。
## 1336. `cs.LG` - 使用双IP-适配器指导进行无训练合成数据生成 [PDF](https://arxiv.org/pdf/2509.22635), [HTML](https://arxiv.org/abs/2509.22635)
### Authors
Luc Boudier,Loris Manganelli,Eleftherios Tsonis,Nicolas Dufour,Vicky Kalogeiton
### Background
由于可用的标注样本有限，少量样本的图像分类仍然具有挑战性。近期的研究探索了使用文本到图像的扩散模型生成合成训练数据，但这种方法通常需要大量的模型微调或外部信息源。
### Innovation
本文提出了一种无训练的新方法DIPSY，该方法利用IP-Adapter实现从图像到图像的转换，仅使用可用的少量样本生成高度辨别性的合成图像。DIPSY的主要创新点在于：(1) 延伸了分类器无指导方案，使正向和负向图像条件具有独立控制能力；(2) 基于类别相似性的采样策略，识别有效的对比示例；(3) 不需要模型微调或外部标注和过滤的简单且有效的流程。
### Conclusion
在十个基准数据集上的实验表明，该方法在性能上达到了最先进的水平或可与之匹敌，同时消除了生成模型适应或依赖外部工具进行描述生成和图像过滤的需要。结果表明，联合使用正负向提示生成类辨别特征对于细粒度分类任务尤其有效。
## 1337. `cs.LG` - 语言模型的变分推理 [PDF](https://arxiv.org/pdf/2509.22637), [HTML](https://arxiv.org/abs/2509.22637)
### Authors
Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang
### Background
该研究介绍了一种变分推理框架，用于语言模型，将思考痕迹作为潜在变量，并通过变分推理优化它们。研究从证据下界（ELBO）出发，扩展了其为一个多痕迹目标，以获得更紧的边界，提出了前向KL公式，以稳定变分后验的训练。此外，研究还展示了拒绝采样微调和二元奖励强化学习等方法可以被解释为局部前向KL目标，揭示了一个此前未被注意到的偏向简单问题的偏差。研究在Qwen 2.5和Qwen 3模型系列上对各种推理任务进行了实证验证。整体而言，该工作提供了一种原理上一致的概率视角，将变分推理与RL风格的方法统一起来，并为提升语言模型的推理能力提供了稳定的优化目标。研究的代码可以在提供的网址找到。
### Innovation
研究提出了一种变分推理框架，通过将思考痕迹作为潜在变量，并通过变分推理进行优化。研究扩展了证据下界（ELBO）的目标函数，提出了一种前向KL公式，以稳定训练变分后验。研究还展示了怎么样的RL方法可以被解释为局部前向KL目标，揭示了一种偏向于简单问题的偏差。
### Conclusion
研究提供了一种奠定概率基础的方法，将变分推理与强化学习风格的方法统一起来，为提升语言模型的推理能力提供了稳定的优化目标。
## 1338. `cs.LG` - 基于度量引导的校准预测边界用于概率图像重构 [PDF](https://arxiv.org/pdf/2404.15274), [HTML](https://arxiv.org/abs/2404.15274)
### Authors
Matt Y Cheung,Tucker J Netherton,Laurence E Court,Ashok Veeraraghavan,Guha Balakrishnan
### Background
现代深度学习重建算法能够从稀疏输入生成高度逼真的扫描图像，但可能会产生显著的不准确性。这使得从这些算法重建的扫描中得到统计上可靠的结论变得非常困难。本文旨在解决这一问题。
### Innovation
本文提出了一个框架，用于计算从概率黑盒图像重建算法推导出的声明的证明有效的预测边界。该框架的核心在于使用从重建扫描中推导出的临床感兴趣的度量，并使用校准预测（CP）和先验校准数据集来校准关于真实度量的边界。通过这种方式，可以提供关于受试者状态的可解释反馈，也可以用来检索最近邻的重建扫描进行可视化检查。
### Conclusion
研究结果表明，本文提出的框架能够产生具有更好语义解析性的边界，比传统的基于像素的边界方法更为可靠。此外，还可以标记那些看上去合理但实际上具有统计上不太可能值的危险异常重建。
## 1339. `cs.LG` - VDFD：带分离世界模型的多智能体价值分解框架 [PDF](https://arxiv.org/pdf/2309.04615), [HTML](https://arxiv.org/abs/2309.04615)
### Authors
Zhizun Wang,David Meger
### Background
由于多智能体系统中的可扩展性和非站定性问题，无模型方法需要大量的样本进行训练。该论文旨在通过提出一种基于模型的多智能体强化学习方法，即带分离世界模型的价值分解框架(Value Decomposition Framework with Disentangled World Model, VDFD)，解决多个智能体在相同环境中实现共同目标时样本复杂度高的问题。
### Innovation
该论文引入了一个模块化的世界模型，由动作条件分支、动作无关分支和静态分支组成，用于解开复杂环境动力学。通过变分自动编码器和变分图自动编码器学习世界模型的潜在表示，并结合价值函数框架来预测联合动作-价值函数并优化整体训练目标。实验结果表明，该方法在样本效率和性能方面优于其他基准模型。
### Conclusion
本方法在StarCraft II微管理、多智能体MuJoCo和水平制蜂群挑战等多智能体学习任务中展示了高样本效率和优越的性能。
## 1340. `cs.LG` - 针对强化学习与人类反馈的高效在线探索 [PDF](https://arxiv.org/pdf/2509.22633), [HTML](https://arxiv.org/abs/2509.22633)
### Authors
Gen Li,Yuling Yan
### Background
强化学习中的人类反馈强化学习（RLHF）通过学习奖励模型来利用人类偏好的数据，并优化政策以优先考虑可喜的响应。这种学习框架在使大型语言模型（LLMs）与人类偏好对齐方面变得至关重要。本文致力于探讨在线RLHF的探索原则，研究如何高效地收集新的偏好数据，以在节省数据资源的同时细化奖励模型和政策。现有的乐观探索算法在采样策略存在缺陷，它们倾向于收集未能减少奖励差异中最相关不确定性信息的比较，并证明了这些方法长时间段内可能遭遇线性遗憾。因此，本文提出了一种新的探索方案，旨在通过减少最相关的奖励差异的不确定性来导向偏好查询，以改进政策。基于RLHF的多臂老虎机模型，本文证明了遗憾上界为$T^{(beta+1)/(beta+2)}$的阶次，其中$beta>0$是一个调整奖励最大化与缓解分布漂移之间平衡的超参数。据我们所知，这是首个具有遗憾在所有模型参数上缩放为多项式的在线RLHF算法。
### Innovation
提出了基于减少奖励差异最相关不确定性的新探索方案，该方案被证明在RLHF的多臂老虎机模型下具有多项式阶次的遗憾上界。这是首个所有模型参数上的遗憾缩放为多项式的在线RLHF算法。
### Conclusion
本文的研究结果证明了一种新的探索策略的有效性，并为在线RLHF提供了理论保证，特别是关于遗憾上界的表现。
## 1341. `cs.LG` - SPARK: 协同政策与奖励共生框架 [PDF](https://arxiv.org/pdf/2509.22624), [HTML](https://arxiv.org/abs/2509.22624)
### Authors
Ziyu Liu,Yuhang Zang,Shengyuan Ding,Yuhang Cao,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang
### Background
近年来，大型语言模型（LLMs）和大型vision-language模型（LVLMs）越来越多地使用强化学习（RL）进行后微调，如RLVR（可验证奖励的RL）用于客观任务，和RLHF（人类反馈的RL）用于主观任务。然而，由于依赖人类偏好，RLHF会引发高成本和潜在的奖励策略匹配问题。另一方面，尽管RLVR通过丢弃每次更新后的策略和正确性信号来节省监督，但仍然浪费了有用信息。
### Innovation
SPARK（协同政策与奖励共生框架）提出了一种高效的、针对策略的且稳定的RLVR扩展方法。SPARK将丢弃的策略和正确性数据重新利用，训练模型自身作为生成奖励模型。通过包含点奖励得分、成对比较和基于进一步反思响应的评价等多种目标，SPARK教导模型自我评估和改进其响应。这种统一框架消除了无需单独的奖励模型和昂贵的人类偏好数据的需求，并形成一个正向共生反馈循环：奖励准确性的提升产生更好的策略梯度，这反过来提高了生成更高质量样本以进一步优化奖励模型的能力。SPARK能够在多个LLM和LVLM模型、多个推理、奖励模型以及泛化基准测试上实现显著的性能提升，例如SPARK-VL-7B模型分别在7个推理基准、2个奖励基准和8个泛化基准中分别获得了9.7%、12.1%和1.5%的性能优势，展示了其鲁棒性和广泛的适用性。
### Conclusion
SPARK是一种新颖且高效的方法，它可以提高大型语言模型和vision-language模型的性能，并通过自我反馈循环提升模型的奖励机制。同时，该方法避免了对单独奖励模型和人类偏好数据的依赖，实现了成本的节省和性能的提升。
## 1342. `cs.LG` - 对令牌级奖励引导文本生成的一种批判性审视 [PDF](https://arxiv.org/pdf/2406.07780), [HTML](https://arxiv.org/abs/2406.07780)
### Authors
Ahmad Rashid,Ruotian Wu,Julia Grosse,Agustinus Kristiadi,Pascal Poupart
### Background
大型语言模型（LLMs）可以通过细调与人类偏好对齐来改进，这是所谓的从人类反馈中进行强化学习（RLHF）。但是，对LLM进行细调的成本对许多用户来说是无法承受的。因此，预测时基于奖励的令牌级文本生成（RGTG）方法因其能够绕过LLM细调而受到重视。这些方法在解码过程中使用在完整序列上训练的奖励模型对部分序列进行评分，以引导生成高奖励的序列。然而，这些方法至今仅基于启发式动机且未进行充分分析。
### Innovation
该工作展示了在完整序列上训练的奖励模型不适用于评估部分序列。为解决此问题，作者提出了一种新方法：在部分序列上显式地训练布雷德利-泰利（Bradley-Terry）奖励模型，并在解码过程中自回归采样出的隐含令牌级策略。研究这种奖励模型及其结果的策略属性：表明该策略与两种不同RLHF策略的比例成正比。简单的相比之前的方法，这种方法表现更优，并且其性能与大规模LLM细调的最强离线基线相当。
### Conclusion
作者的工作提供了一种简单的替代方案，超越了现有的RGTG方法，并且在无需大规模LLM细调的情况下，性能与强大的离线基线相当。相关代码已发布。
## 1343. `cs.LG` - 使用符号梯度的神经网络潜在空间的闭式解释 [PDF](https://arxiv.org/pdf/2409.05305), [HTML](https://arxiv.org/abs/2409.05305)
### Authors
Sebastian J. Wetzel,Zakaria Patel
### Background
研究表明，自动编码器或孪生网络等人工神经网络在其潜在空间中编码了有意义的概念，然而缺乏一个全面的框架来以人类可读的形式提取这些信息，无需先验知识。在定量学科中，概念通常以方程形式表述。因此，为了提取这些概念，该文引入了一个框架，用于在人工神经网络的潜在空间中寻找神经元的闭式解释。
### Innovation
该框架基于将训练好的神经网络嵌入到等价函数类中，这些等价函数编码相同的概念。通过找到等价类与由符号搜索空间定义的人类可读方程的交集来解释这些神经网络。计算上，该框架基于寻找一个符号表达式，使其规范化梯度与特定神经元相对于输入变量的规范化梯度匹配。该方法通过从孪生神经网络的潜在空间中检索矩阵不变量和动力学系统的守恒量来证明其有效性。
### Conclusion
该文提出的方法允许在人工神经网络的潜在空间中以闭式形式找到神经元的解释，这将有助于更好地理解和使用神经网络的内部表示。通过匹配规范化梯度，该方法能够在不依赖先验知识的情况下识别和提取潜在空间中的有意义概念。这种方法的实现成功地从孪生神经网络的潜在空间中检索出矩阵的不变量和动力学系统的守恒量，证明了其有效性。
## 1344. `cs.LG` - See, Point, Fly: 一种无需学习的基于VLM的通用无人飞行导航框架 [PDF](https://arxiv.org/pdf/2509.22653), [HTML](https://arxiv.org/abs/2509.22653)
### Authors
Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu
### Background
本文提出了一个无需训练的视野与语言导航（AVLN）框架SPF，该框架基于视觉语言模型（VLM）。这种框架能够根据任何形式的自由形式指令在不同环境中到达任意目标。现有的基于VLM的方法将行为预测视为文本生成任务。而我们的核心观点是将AVLN中的行为预测视为二维空间定位任务。SPF 使用VLM将模糊的语言指示分解为在输入图像上迭代注释二维航点。SPF 还通过调整移动距离来提高导航效率，并且能够在动态环境中跟随动态目标进行闭环控制导航。
### Innovation
SPF的关键创新在于，它将行为预测视为一个2D空间定位任务，并利用VLM将模糊的语言指令分解为二维航点的迭代注释。此外，SPF还能够自适应地调整行驶距离，以实现更高效的导航，并能够在封闭环路控制模式下导航，使得UAV能够跟踪动态目标。SPF在DRL模拟基准测试中达到了新的最高水平，比之前最好的方法在绝对值上提高了63%。实证实验表明，SPF在实际世界中的表现也远远优于强基准，并且能够很好地推广到不同的VLM中去。
### Conclusion
SPF通过闭环控制方式实现了导航，能够在动态环境中跟踪动态目标，表现出卓越的通用性和高效性，同时在各类基准测试中达到了新的领先水平。此外，SPF还通过全面的消融研究突显了其设计选择的有效性。
## 1345. `cs.LG` -  adversarial Bayes分类器的唯一性概念 [PDF](https://arxiv.org/pdf/2404.16956), [HTML](https://arxiv.org/abs/2404.16956)
### Authors
Natalie S. Frank
### Background
该研究在二分类问题的背景下，探讨了一个新的对抗性 Bayes 分类器的唯一性概念。
### Innovation
提出了对抗性 Bayes 分类器的一个新概念，分析了这一概念后，获得了一种用于计算一类一维数据分布具有合理动机的对抗性 Bayes 分类器的简单方法。随着扰动半径的增加，这类对抗性 Bayes 分类器的一些规范性特征得到了改进，这些结果还提供了理解一维空间中 Bayes 分类器和对抗性 Bayes 分类器之间关系的工具。
### Conclusion
随着扰动半径的增加，对抗性 Bayes 分类器的规范性特征得到改善，并且这些研究结果为理解 Bayes 分类器和对抗性 Bayes 分类器之间的关系提供了工具。
## 1346. `cs.LG` - 快速基于分区的 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$ 中心化和标准化交叉验证算法 [PDF](https://arxiv.org/pdf/2401.13185), [HTML](https://arxiv.org/abs/2401.13185)
### Authors
Ole-Christian Galbo Engstrøm,Martin Holm Jensen
### Background
该研究解决了一个在机器学习模型选型中常见的技术问题，特别是那些依赖于矩阵乘积 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$ 的模型。传统的分区交叉验证方法在计算这些矩阵乘积时会非常耗时，特别需要在每个训练分区进行多次计算，从而导致计算量大增。特别是在模型选择场景下，如主成分分析（PCA）、主成分回归（PCR）、岭回归（RR）、最小二乘法（OLS）和部分最小二乘法（PLS），需要频繁地搜索和评估不同参数设置，因此对计算效率提出了更高的要求。本文的目标是对分区交叉验证进行加速，在不影响计算效率的前提下，处理列中心化和标准化的所有可能组合，并证明这些算法的正确性和效率。
### Innovation
本文提出了一种加速分区交叉验证的新方法，特别适用于需要计算 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$ 的机器学习模型。具体来说，他们通过消除训练分区之间的冗余计算，利用验证分区的数据来直接获得预处理后的训练分区的 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$。该算法支持所有列中心化和标准化的组合，且仅带来可管理的额外计算开销。此外，该算法证明了时间复杂性和空间复杂性与不经过预处理直接计算 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$ 的方法相同，且能够避免由于预处理导致的数据泄露问题。这是首次为所有16种组合的列中心化和标准化提供正确且有效的交叉验证算法，并且证明其中只有12种给出独特的矩阵乘积。
### Conclusion
本文提出的算法在所有讨论的16种组合的列中心化和标准化情况下都能正确且有效地进行模型选择和交叉验证。无论采用哪种组合，算法都能够避免数据泄露，且其运行时间和空间需求与直接计算 $textbf{X}^textbf{T}textbf{X}$ 和 $textbf{X}^textbf{T}textbf{Y}$ 相同，展现出高效率和良好的扩展性。
## 1347. `cs.LG` - DOTA: 分布式视觉-语言模型的测试时自适应 [PDF](https://arxiv.org/pdf/2409.19375), [HTML](https://arxiv.org/abs/2409.19375)
### Authors
Zongbo Han,Jialong Yang,Guangyu Wang,Junfan Li,Qianli Xu,Mike Zheng Shou,Changqing Zhang
### Background
视觉-语言基础模型（VLMs），如CLIP，在各种任务中表现出色。然而，当训练数据和测试数据之间存在显著分布差异时，部署这些模型可能会不可靠。为了适应各种场景，对这些模型进行微调往往是成本高昂的。基于缓存的测试时适配器通过存储代表性测试样本来指导后续分类，提供了一种高效替代方案。然而，这些方法通常采用简单的缓存管理策略，导致在样本不可避免地在更新过程中被移除时出现严重的灾难性遗忘。
### Innovation
本文提出了一种简单的有效方法——DOTA（分布式测试时自适应），以解决这一限制。DOTA 不仅存储个体测试样本，更重要的是，它持续估计测试数据流的基本分布。通过贝叶斯定理使用这些动态估计的分布计算测试时后验概率，从而实现模型的自适应。这种方法能够使模型不断学习并适应部署环境。
### Conclusion
广泛的实验验证了DOTA在减轻遗忘方面表现出显著效果，并在与现有方法的比较中达到了最先进的性能。
## 1348. `cs.LG` - 基于范数采样和正交性的多样子集选择 [PDF](https://arxiv.org/pdf/2406.01086), [HTML](https://arxiv.org/abs/2406.01086)
### Authors
Noga Bar,Raja Giryes
### Background
大型注释数据集对深度神经网络的成功至关重要，但在医学成像等领域，数据标注成本相当高昂。因此，从大规模未标注数据池中选择最具信息量的小型数据子集进行标注，成了一个关键问题，本研究正是针对此问题进行探索。
### Innovation
提出了一种简单而有效的方法，该方法结合了特征范数、随机化和正交性（通过格拉姆-舍德勒过程）来选择多样且信息量充足的样本。特征范数作为信息量的代理，随机化和正交化减少了冗余并鼓励覆盖特征空间。该方法在图像和文本基准数据集（包括CIFAR-10/100、Tiny ImageNet、ImageNet、OrganAMNIST及Yelp）上进行了广泛实验，结果显示该方法在独立使用或与其他技术结合时，均能显著提升子集选择性能
### Conclusion
本研究提出的方法在多种基准数据集上展示了超越其他方法的效果，为大规模未标注数据的高效标注提供了新的思路和参考。
## 1349. `cs.LG` - 机器学习辅助促进锂离子电池的可持续翻新、再利用和回收 [PDF](https://arxiv.org/pdf/2406.00276), [HTML](https://arxiv.org/abs/2406.00276)
### Authors
Shengyu Tao
### Background
锂离子电池（LIBs）的可持续利用对全球能源转型和碳中和至关重要，但数据稀缺性和异质性是翻新、再利用和回收过程中面临的主要障碍。涉及的数据量不足和电池特性差异使得准确评估和管理电池在整个生命周期中的性能变得困难。
### Innovation
该论文开发了一个基于机器学习的框架，通过支持物理信息的质量控制模型、生成式学习的残值评估方法、联邦学习策略以及基于相关对齐的统一诊断与预测框架，解决了数据稀缺性、异质性和评估准确性的问题。这些方法在预测长期退化、评估退役电池残值、保护隐私的同时确保高精度的材料分类以及适应性强的任务执行方面实现了创新。
### Conclusion
这些贡献推动了可持续电池管理的进程，通过整合物理原理、数据生成、隐私保护合作以及适应性学习，提供了促进循环经济和全球碳中和的方法论创新。
## 1350. `cs.LG` - 机器未学习与性别暴力条件在语音中的无对方言检测 [PDF](https://arxiv.org/pdf/2411.18177), [HTML](https://arxiv.org/abs/2411.18177)
### Authors
Emma Reyner-Fuentes,Esther Rituerto-Gonzalez,Carmen Pelaez-Moreno
### Background
性别暴力是一个普遍的公共卫生问题，严重损害女性的心理健康，导致焦虑、抑郁、创伤后应激障碍和物质滥用等症状。现有的语言人工智能工具因其对未见过说话者的表现较差，表明说话者特征可能影响模型性能。本研究旨在开发能够跨说话人推广的性别暴力受害者状态检测模型。
### Innovation
引入了一种无对方言的方法来从语音中检测性别暴力受害者的状态，采用领域对抗训练减少说话者身份对模型预测的影响，同时提高了性别暴力受害者状态分类的准确性。
### Conclusion
模型有效地捕捉了与性别暴力受害者状态相关的副语言生物标志物，而不是说话者特定的特性。此外，模型预测与临床前创伤后应激障碍症状有适度的相关性，证明了语音作为监测心理健康的一种无创工具的可行性。这项工作为支持性暴力幸存者临床筛查的伦理、隐私保护的人工智能系统奠定了基础。
## 1351. `cs.LG` - 大型语言模型与经典机器学习模型：使用高维度表格数据在COVID-19病亡率预测中的性能对比 [PDF](https://arxiv.org/pdf/2409.02136), [HTML](https://arxiv.org/abs/2409.02136)
### Authors
Mohammadreza Ghaffarzadeh-Esfahani,Mahdi Ghaffarzadeh-Esfahani,Arian Salahi-Niri,Hossein Toreyhi,Zahra Atf,Amirali Mohsenzadeh-Kermani,Mahshad Sarikhani,Zohreh Tajabadi,Fatemeh Shojaeian,Mohammad Hassan Bagheri,Aydin Feyzi,Mohammadamin Tarighatpayma,Narges Gazmeh,Fateme Heydari,Hossein Afshar,Amirreza Allahgholipour,Farid Alimardani,Ameneh Salehi,Naghmeh Asadimanesh,Mohammad Amin Khalafi,Hadis Shabanipour,Ali Moradi,Sajjad Hossein Zadeh,Omid Yazdani,Romina Esbati,Moozhan Maleki,Danial Samiei Nasr,Amirali Soheili,Hossein Majlesi,Saba Shahsavan,Alireza Soheilipour,Nooshin Goudarzi,Erfan Taherifard,Hamidreza Hatamabadi,Jamil S Samaan,Thomas Savage,Ankit Sakhuja,Ali Soroush,Girish Nadkarni,Ilad Alavi Darazam,Mohamad Amin Pourhoseingholi,Seyed Amir Ahmad Safavi-Naini
### Background
该研究对比了经典特征基础的机器学习模型（CMLs）和大型语言模型（LLMs）在使用来自9134名患者（分布在四家医院）的高维度表格数据预测COVID-19病亡率方面的性能。通过评估7种CML模型（包括XGBoost和随机森林）和8种LLM模型（包括GPT-4和Mistral-7b），研究展示了实际应用背景下的模型性能和改进方法。
### Innovation
研究创新地采用了XGBoost和随机森林进行性能对比，同时还首次展示了在使用零样本分类方法下，Mistral-7b模型通过QLoRA微调后在COVID-19病亡率预测任务中的显著提升效果。此外，研究通过对比CML模型和经过微调的LLM模型在处理高维度表格数据任务上的表现，突出了其潜在应用价值，并讨论了进一步缩小两者性能差距的可能性。
### Conclusion
研究显示，虽然LLMs在零样本分类方面表现中规中矩，但通过微调，其性能大幅提升。然而，CMLs在处理高维度表格数据任务时依然表现出色，优于LLM。该研究强调了CMLs和微调后的LLMs在未来医疗预测建模领域中的潜力，同时指出了CMLs在结构性数据处理中的当前优势。
## 1352. `cs.LG` - VeriFlow: 模型分布进行神经网络验证 [PDF](https://arxiv.org/pdf/2406.14265), [HTML](https://arxiv.org/abs/2406.14265)
### Authors
Faried Abu Zaid,Daniel Neider,Mustafa Yalçıner
### Background
形式化验证已成为确保神经网络的安全性和可靠性的有前途的方法。然而，许多相关属性，如公平性或全局稳健性，与整个输入空间相关。如果直接应用验证技术，神经网络会被检查那些在现实世界中不存在且没有意义的输入。为了解决这一缺点，我们提出了VeriFlow架构，这是一种基于流的密度模型，旨在允许任何验证方法将其搜索限制在感兴趣的某些数据分布中。我们表明，我们的架构特别适合此目的，因为具备两个主要特性：首先，我们展示由该模型定义的转换是分段仿射的。因此，该模型允许使用基于线性算术约束求解的验证器。其次，数据分布的上密度水平集（UDL）可以通过潜空间中的线性约束来定义。这意味着给定概率的UDL表示可以在潜空间中有效计算。这两个特性使得可以实现细粒度且概率可解释的验证控制，以了解需要验证的输入的典型性程度
### Innovation
VeriFlow架构是一个基于流的密度模型，能够使任何验证方法将其搜索限制在感兴趣的某些数据分布中。该架构的创新点在于：1）通过定义的分段仿射转换，允许使用基于线性算术约束求解的验证器；2）数据分布的上密度水平集可以通过潜空间中的线性约束来定义，从而在潜空间中有效计算给定概率的表示。
### Conclusion
本文提出了VeriFlow架构，它通过定义的分段仿射转换和潜空间中的线性约束表达了数据分布的上密度水平集，从而有效地将验证过程限制在感兴趣的某些数据分布中。此架构在验证实际有意义的输入时提供了细粒度且概率可解释的控制，从而提高了神经网络验证的准确性和适用性。
## 1353. `cs.LG` - 度量意识突触图在网络域适应中的应用 [PDF](https://arxiv.org/pdf/2410.06883), [HTML](https://arxiv.org/abs/2410.06883)
### Authors
Yingxu Wang,Mengzhu Wang,Houcheng Su,Nan Yin,Quanming Yao,James Kwok
### Background
Spiking Graph Networks (SGNs)通过仿脑启发式神经动力学实现能效计算，在图分类中展现了显著潜力，但现有SGNs通常局限于内部分布场景，在分布偏移场景下表现较弱
### Innovation
提出了适用于SGNs的域适应问题，并引入了一种新的框架——度量意识突触图以进行跨域适应(DeSGraDA)。此框架包含三个关键组件：(1) 度量意识突触表示模块，通过基于节点度调整尖峰阈值，实现更丰富的结构感知信号编码；(2) 时间分布对齐，通过对抗性匹配膜电势，在跨域情况下保持高效能的同时保证能量效率；(3) 在两个空间中提取一致预测，以生成可靠的伪标签，充分利用未标记数据以提高图分类性能。此外，还建立了首个SGDA的泛化边界，提供了对其适应性能的理论见解
### Conclusion
大规模基准数据集实验表明，DeSGraDA在分类准确性和能量效率方面均超过最先进的方法
## 1354. `cs.LG` - 通过隐式奖励的过程强化 [PDF](https://arxiv.org/pdf/2502.01456), [HTML](https://arxiv.org/abs/2502.01456)
### Authors
Ganqu Cui,Lifan Yuan,Zefan Wang,Hanbin Wang,Yuchen Zhang,Jiacheng Chen,Wendi Li,Bingxiang He,Yuchen Fan,Tianyu Yu,Qixin Xu,Weize Chen,Jiarui Yuan,Huayu Chen,Kaiyan Zhang,Xingtai Lv,Shuo Wang,Yuan Yao,Xu Han,Hao Peng,Yu Cheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou,Ning Ding
### Background
在大规模语言模型（LLMs）的推理时间缩放中，密集的过程奖励被证明比稀疏的结果层面奖励更有效，特别是在需要复杂多步骤推理的任务中。由于精细的过程奖励可以解决结果奖励的一些固有问题，如训练效率和归因问题，因此它们也为LLMs的强化学习提供了有吸引力的选择。然而，这种潜力尚未得到充分实现，主要原因是在线训练过程奖励模型（PRMs）存在挑战，导致收集高质量过程标签的成本过高，使得它们容易受到奖励作弊的影响。
### Innovation
本文提出了一种名为PRIME（通过隐式奖励的过程强化）的方法，该方法通过只使用策略展开和结果标签以及隐式过程奖励来实现在线PRM更新。PRIME与各种优势函数兼容，并且省去了现有方法所需的专用奖励模型训练过程，从而大大减少了开发工作量。研究结果表明，基于PRIME，从Qwen2.5-Math-7B-Base开始，在多个关键推理基准上，PRIME模型相对于SFT模型平均提高了15.1%。特别地，我们的模型Eurus-2-7B-PRIME使用10%的训练数据在七个推理基准上超过了Qwen2.5-Math-7B-Instruct。
### Conclusion
PRIME能够有效提升特定任务的表现，通过仅利用策略展开和结果标签即可实现在线更新过程奖励模型，简化了开发流程，并在多个基准上展示了显著的性能提升。
## 1355. `cs.LG` - 不稳定脱习性：在扩散模型中概念复现的隐藏风险 [PDF](https://arxiv.org/pdf/2410.08074), [HTML](https://arxiv.org/abs/2410.08074)
### Authors
Vinith M. Suriyakumar,Rohan Alur,Ayush Sekhari,Manish Raghavan,Ashia C. Wilson
### Background
文本到图像的扩散模型依赖于大规模、Web级的数据集。从头开始训练它们是非常昂贵的计算机资源，因此开发者通常更愿意对现有模型做增量更新。这些更新通常包括对新概念的学习或模型性能改进的微调步骤，以及删除现有概念（如版权作品或具体内容）的疏远步骤。然而，在这种模式下会出现一个先前未知且关键的漏洞：即使是非对抗性条件下，对看似无关的图像进行微调训练也可能导致模型重新学习此前需要疏远的概念。因此，我们通过一系列实验来探究这种现象的原因和范围，得出了关于对扩散模型进行增量更新的脆弱性的重要结论，还提出了有关确保文本到图像扩散模型的安全性与对齐的新问题.
### Innovation
我们首次揭示了文本到图像扩散模型中的一个关键而未知的漏洞：即使是非对抗性条件下，对看似无关的图像的微调训练也会导致模型重新学习此前已删除的概念（即‘概念复现’）。我们的研究通过系统实验，特别是对Stable Diffusion v1.4和v2.1的微调，全面调查了这一现象，并发现对模型进行增量更新是脆弱的。这些研究结果对确保文本到图像扩散模型的安全和对齐提出了新的重要担忧。
### Conclusion
我们的发现指出，对扩散模型增量更新的组合构成是脆弱的，提出了关于当前确保文本到图像扩散模型的安全和对齐的方法的新重大关注点。
## 1356. `cs.LG` - 在预算限制的多智能体MDP中的容量感知规划与调度：一种元RL方法 [PDF](https://arxiv.org/pdf/2410.21249), [HTML](https://arxiv.org/abs/2410.21249)
### Authors
Manav Vora,Ilan Shomorony,Melkior Ornik
### Background
该论文研究了一类称为容量和预算约束多智能体MDP（CB-MA-MDP）的问题，这类问题涵盖了其中每个智能体都不可逆地失效，并且规划者必须决定何时应用恢复行动以及应同时处理哪些智能体的维护和调度任务。全局预算限制了总恢复次数，而容量约束限制了同时采取行动的数量，这使得朴素的动态规划变得类似于指数增长的组合搜索。
### Innovation
提出了一个两阶段的解决方案，该解决方案能够在大型系统中保持可处理性。首先，使用线性求和分配问题（LSAP）进行分组，将智能体分为r个不交集的集合（r = 容量），最大化预期故障时间的多样性，并且按比例分配预算到每个集合中。其次，通过元训练过的PPO策略解决每个子MDP，并利用组间转移来快速收敛。
### Conclusion
通过将该方法应用于工业机器人团队维修调度问题，并受限于有限的维修技术人员和总维修预算，证明了所提出的方法在最大化团队平均运行时间方面优于基线方法，尤其是在大型团队规模下。通过不同数量的机器人和维修技术人员的复杂性分析，还证实了该方法的可扩展性。
## 1357. `cs.LG` - 统计学习基本定理中的可测性问题 [PDF](https://arxiv.org/pdf/2410.10243), [HTML](https://arxiv.org/abs/2410.10243)
### Authors
Lothar Sebastian Krapp,Laura Wirth
### Background
统计学习基本定理表明，假设空间在VC维有限的情况下是PAC可学习的。在无偏模型中证明这一定理的文献往往假设了若干测度上的前提条件。本文从测度论的角度对这些证明进行了审查，旨在明确表示一个严格的定理及其证明，并详细阐述了无偏模型下的假设学习基本定理，展示了所需的最小测度假定。研究背景强调在使用定理时，仔细分析测度方面是至关重要的，特别是在存在测度论复杂性的问题场景中。根据定理的应用，重点讨论了模型论中的应用，特别是在NIP和o-最小结构中的应用。
### Innovation
文章创新性地从测度论的角度仔细审查了现有证明的假设条件，从而提供了一个严格的表述及其自包含的详细证明，突显了无偏模型下假设学习基本定理所需的最小测度假设。此外，文章还提供了足够条件来确定o-最小扩展实数上的假设空间的PAC可学习性，特证包括常用的激活函数如ReLU和Sigmoid函数的所有二元分类人工神经网络。
### Conclusion
研究结果对统计学习理论的进一步发展具有基础性的重要性。对测度方面的细致分析在定理的应用中至关重要，尤其是在存在测度论复杂性的问题领域。这些结论特别适用于模型论中的NIP和o-最小结构的应用。
## 1358. `cs.LG` - Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance [PDF](https://arxiv.org/pdf/2410.22376), [HTML](https://arxiv.org/abs/2410.22376)
### Authors
Dongmin Park,Sebin Kim,Taehong Moon,Minkyu Kim,Kangwook Lee,Jaewoong Cho
### Background
现有的文本到图像（T2I）扩散模型在生成罕见概念组合方面常常表现不佳，特别是包含具有异常属性的对象。本文分析了扩散模型在处理罕见概念时的生成能力，发现通过大型语言模型（LLM）的引导，可以在这类罕见概念上显著提升生成效果。
### Innovation
提出了一种无需训练的R2F方法，通过利用LLM丰富的语义知识来进行稀有到常见概念的引导，这种方法可以在任何预训练的扩散模型和LLM上灵活应用，并能与区域引导扩散方法无缝集成。实验结果显示，R2F在三个数据集，包括作者新提出的基准RareBench，在T2I对齐方面显著优于现有模型包括SD3.0和FLUX，至多提高28.1%。
### Conclusion
我们的框架可以提升扩散模型在生成罕见概念组合方面的性能，通过LLM的指导可以有效解决这一问题。
## 1359. `cs.LG` - LDC-MTL:通过可扩展的损失差异控制实现多任务学习的平衡 [PDF](https://arxiv.org/pdf/2502.08585), [HTML](https://arxiv.org/abs/2502.08585)
### Authors
Peiyao Xiao,Chaosheng Dong,Shaofeng Zou,Kaiyi Ji
### Background
多任务学习（MTL）因其实现多个任务的同时学习而被广泛采用。尽管现有的梯度操控方法通常比基于单一标量化的方法提供更平衡的解决方案，但它们通常会带来显著的计算负担，时间和内存复杂度均为$?mathcal{O}(K)$，其中$K$是任务的数量。
### Innovation
本文提出了一种简单且可扩展的损失差异控制方法——LDC-MTL，它从 bilevel 优化的角度进行建模，包含两个核心组件：(i) 精细的损失差异控制的 bilevel形式化方法，(ii) 只需 $?mathcal{O}(1)$ 时间和内存的可扩展的首阶 bilevel算法。理论证明LDC-MTL在轻度条件下，不仅能够确保到 bilevel 问题中带有损失差异控制的稳定点，还能确保在所有 $K$ 个损失函数上达到 $?epsilon$ 准确的帕累托稳定点。
### Conclusion
在多种多任务数据集上的广泛实验显示，LDC-MTL 在准确性和效率方面均表现出优越性能。
## 1360. `cs.LG` - GNN-DT: 图神经网络增强的决策转换器在动态环境中的高效优化 [PDF](https://arxiv.org/pdf/2502.01778), [HTML](https://arxiv.org/abs/2502.01778)
### Authors
Stavros Orfanoudakis,Nanda Kishor Panda,Peter Palensky,Pedro P. Vergara
### Background
用于解决现实世界优化问题的强化学习（RL）方法通常涉及动态状态-动作空间、大规模问题以及稀疏奖励，这给收敛性、可扩展性和有效探索解空间带来了重大挑战。此研究探讨了稀疏奖励带来的限制，并通过学习从先前收集的轨迹来克服这些问题，从而实时提供高质量的解决方案。
### Innovation
提出了GNN-DT，这是一种新颖的决策转换器（DT）架构，将图神经网络（GNN）嵌入器与输入和输出标记之间的新型残差连接结合，这对于处理动态环境至关重要。GNN-DT能够在无需大量训练轨迹的情况下实现优于现有DT和离线RL基线的性能，并且在未见过的环境和更大动作空间上具有很强的泛化能力，填补了先前离线和在线RL方法中的关键空白。
### Conclusion
GNN-DT在复杂的电动汽车（EV）充电优化问题上的评估证明了其优越的性能，并且相比现有基线所需训练轨迹显著减少，从而提高了样本效率，并在未见过的环境中具有较强的泛化能力，进一步解决了更大动作空间的问题。
## 1361. `cs.LG` - 使用时间频率模态学习的单通道EEG分词 [PDF](https://arxiv.org/pdf/2502.16060), [HTML](https://arxiv.org/abs/2502.16060)
### Authors
Jathurshan Pradeepkumar,Xihao Piao,Zheng Chen,Jimeng Sun
### Background
深度学习模型正在重塑EEG分析，但单通道EEG信号的分词问题仍然是一个挑战。
### Innovation
提出了一种名为TFM-Tokenizer的新型分词框架，可以从单通道EEG信号中学习时间频率模态词汇并将其编码为离散令牌。设计了双路径架构并引入了时间频率掩码以捕获稳健的模态表示。该框架支持多种下游任务，并且在轻量级变压器和基础模型上都是模型无关的。
### Conclusion
该研究展示了TFM-Tokenizer的三个关键优点：1）准确性高，实验表明在多种EEG基准上都有一致的性能提升，相较于强基线在康晋级差上提高了17%；2）通用性强，在多种基础模型上显示出一致的性能提升；3）可扩展性好，能够适应不同形式的信号和配置的单通道EEG数据，实验表明在耳EEG睡眠分期任务上比基线高出14%。此外，全面的分词分析揭示了强分类性、频率意识和一致结构，提升了表示质量和可解释性。
## 1362. `cs.LG` - 通过基于偏好探索避免RLHF中的exp(R_max)缩放 [PDF](https://arxiv.org/pdf/2502.00666), [HTML](https://arxiv.org/abs/2502.00666)
### Authors
Mingyu Chen,Yiding Chen,Wen Sun,Xuezhou Zhang
### Background
强化学习从人类反馈（RLHF）已成为大型语言模型（LLM）对齐的关键技术。现有在线RLHF算法，无论是被动探索还是主动探索，都不能有效处理高度偏斜的偏好情况，如具有唯一正确答案的问题。这种根本性限制导致其在处理这些场景时效率低下，因为样本复杂度随着奖励函数规模呈指数级增长。
### Innovation
引入了基于偏好自探索在线偏好优化算法（SE-POPO），该算法在偏好尺度上的样本复杂度首次实现了多项式级别的增长，解决了Xie等人（2024）提出的一个公开问题。理论上，研究表明SE-POPO的样本复杂度优于现有探索算法。实证上，系统评估显示SE-POPO在两个主要的RLHF应用场景和公共基准上都比探索和非探索基线更具样效率。
### Conclusion
SE-POPO算法在RLHF设计上迈出了重要一步，显著提高了样本效率，为提高在线RLHF算法的效果开辟了新的方向。该研究结果已在两个主要应用和公共基准上得到证实，并为未来的研究提供了理论和实证支持。
## 1363. `cs.LG` - 在高斯过程臂博弈中使用塔普森采样的有效先验选择 [PDF](https://arxiv.org/pdf/2502.01226), [HTML](https://arxiv.org/abs/2502.01226)
### Authors
Jack Sandberg,Morteza Haghir Chehreghani
### Background
高斯过程（GP）臂博弈为未知函数的黑箱优化提供了一种强大的框架。未知函数的特性取决于其假设的GP先验。大多数文献中假设该先验是已知的，但在实践中这通常并不成立。相反，实践者往往依赖最大似然估计来选择先验的超参数，这种做法缺乏理论保证。因此，本文旨在提出两种基于高斯过程塔普森采样（GP-TS）的算法，用于GP臂博弈中的联合先验选择和遗憾最小化：基于淘汰先验的GP-TS（PE-GP-TS）和基于超先验的GP-TS（HP-GP-TS）。
### Innovation
本文提出了两种新的算法，分别是基于淘汰先验的GP-TS（PE-GP-TS）和基于超先验的GP-TS（HP-GP-TS），用于GP臂博弈中的联合先验选择和遗憾最小化。本文还通过理论分析建立了算法的上界，并通过使用合成和真实数据的实验展示了相比现有方法的有效性。
### Conclusion
本文通过理论分析和实验结果，展示了在高斯过程臂博弈中联合先验选择和遗憾最小化的有效方法，这为实践者提供了更可靠的先验选择方案，并提供了无理论保证的方法的替代选择。
## 1364. `cs.LG` - 战略决策对象的响应：在战略分类中的分析模型与LLM生成响应的比较 [PDF](https://arxiv.org/pdf/2501.16355), [HTML](https://arxiv.org/abs/2501.16355)
### Authors
Tian Xie,Pavan Rauch,Xueru Zhang
### Background
当机器学习算法被部署以自动化人类决策时，人类可能会学习算法背后的决策策略并调整自己的行为。为此，战略分类（SC）框架被提出，用于研究智能体和决策者之间的互动，以设计更可信赖的机器学习系统。以往的研究假设智能体是完全或接近理性的，并通过优化自己的效用来响应决策策略。然而，由于大型语言模型（LLM）的普及，现实中的智能体可能会依赖这些工具来获取策略建议。本文探讨了这一变化及其对现有战略分类理论模型的影响，包括五个关键场景：招聘、贷款申请、学校录取、个人收入和公共援助项目。
### Innovation
本文创新地将大型语言模型（LLM）的生成建议与现有战略分类（SC）理论模型进行了比较，研究了当智能体遵循LLM建议时，其行为与理论模型预测的差异。实验表明，即使没有获得决策策略，LLM仍能生成有效策略，提高智能体的得分和资历；在群体层面，LLM引导的努力分配策略与SC理论模型预测结果相似或更好，这表明理论模型可能仍是一个合理的代理模型；在个体层面，LLM倾向于产生更多样、更平衡的努力分配，这可能优于理论模型的预测。
### Conclusion
本文发现，尽管在某些场景中存在个体行为的差异，但大型语言模型（LLM）在战略分类中的应用，特别是在努力分配方面，可以生成有效且公平的策略，甚至可能超越现有的理论模型预测。这为开发更可信赖和公平的机器学习系统提供了新的见解。
## 1365. `cs.LG` - 大型语言模型中表示工程的分类、机遇与挑战 [PDF](https://arxiv.org/pdf/2502.19649), [HTML](https://arxiv.org/abs/2502.19649)
### Authors
Jan Wehner,Sahar Abdelnabi,Daniel Tan,David Krueger,Mario Fritz
### Background
研究显示，现有的控制大语言模型（LLMs）行为的方法主要通过修改输入或对模型进行微调。这些方法存在局限性，不能有效地、可解释性地、数据高效地和灵活地控制模型的行为。因此，介绍了一种新框架——表示工程（RepE），通过直接操作模型内部表示来控制模型的行为，这可能提供更有效、更可解释、更数据高效和更灵活的控制。
### Innovation
该研究首次全面回顾了RepE，总结了RepE的方法及其差异，展示了RepE在概念和问题上的应用。此外，该研究提出了一个新的统一框架，将RepE描述为一个包含表示识别、操作化和控制的管道。研究表明，虽然RepE方法具有巨大潜力，但仍然存在挑战，如管理多个概念、确保可靠性以及保持模型性能。
### Conclusion
尽管RepE方法具有巨大潜力，但仍存在挑战。该研究指出了实验和方法论改进的机会，并构建了最佳实践指南，以推动RepE的发展。
## 1366. `cs.LG` - MNT-TNN: 基于紧凑多模式非线性变换张量核范数的时空交通数据插补 [PDF](https://arxiv.org/pdf/2503.22955), [HTML](https://arxiv.org/abs/2503.22955)
### Authors
Yihang Lu,Mahwish Yousaf,Xianwei Meng,Enhong Chen
### Background
交通数据的时空插补是一个长期研究的主题，在智能交通系统（ITS）中有重要的应用。随着全球卫星导航系统（GNSS）等现代通信技术的发展，交通数据收集带来了新的挑战，包括随机缺失值的插补和对时空依赖关系建模的需求增加。
### Innovation
提出了一种基于多模式非线性变换张量核范数（MNT-TNN）的时空交通插补方法，能够有效捕捉交通张量的内在多模式时空相关性和低秩性。此外，设计了一个具有理论收敛保证的近端交替最小化（PAM）算法，还建议了一种增强张量核范数族（ATTNNs）框架，以增强TTNN技术的插补结果，尤其是在非常高缺失率的情况下。
### Conclusion
在大规模实数据上的实验表明，我们提出的MNT-TNN和ATTNNs方法能够优于现有的最新插补方法，完成随机缺失交通值插补的基准测试。
## 1367. `cs.LG` - ReciNet：周期晶格意识的长程建模用于晶体性质预测 [PDF](https://arxiv.org/pdf/2502.02748), [HTML](https://arxiv.org/abs/2502.02748)
### Authors
Jianan Nie,Peiyao Xiao,Kaiyi Ji,Peng Gao
### Background
预测晶体的性质从其结构出发，在材料科学中是一项基本但具有挑战性的任务。与其他分子不同，晶体结构表现出无限期的原子排列，需要能够同时捕捉局部和全局信息的方法。然而，当前的方法无法有效地捕捉周期结构中的长程相互作用。
### Innovation
本文引入了基于傅里叶级数表示和可学习滤波器的逆空间方法，并在此基础上建立了ReciNet架构，该架构结合了几何GNN和逆空间块来分别建模短程和长程相互作用。实验表明，ReciNet在标准基准JARVIS、Materials Project和MatBench上的多晶体力学性质预测任务中实现了最先进的预测准确性。此外，还探讨了将混合专家模型扩展到多性质预测的高效性及其揭示的相关性质之间的正向迁移。
### Conclusion
这些发现突显了我们的模型在晶体性质预测中的规模化和高准确性潜力。
## 1368. `cs.LG` - 使用不变神经场表示的几何感知的稳态PDE推断 [PDF](https://arxiv.org/pdf/2504.18591), [HTML](https://arxiv.org/abs/2504.18591)
### Authors
Giovanni Catalani,Michael Bauerheim,Frédéric Tost,Xavier Bertrand,Joseph Morlier
### Background
近年来，神经算子在求解具有通用几何形状的偏微分方程(PDEs)方面取得了进展，能够提供离散化不变的代理模型。然而，许多方法在高效编码局部几何结构和可变量域方面存在局限。
### Innovation
本文引入了enf2enf，一种神经场方法，用于预测具有几何变化的稳态PDEs。该方法将几何信息编码为与特定位置锚定的潜在特征中，保持网络中的局部性。局部表示通过结合全局参数并解码为连续物理场，可以有效地处理复杂形状的变化。实验结果表明，该方法在相关基准测试上表现与现有的图基、神经算子和最近的神经场方法相当或更优，同时具有实时推理能力和高效扩展到高分辨率网格的能力。
### Conclusion
本研究提出了enf2enf方法，证实了其在应对复杂几何变化时的有效性和竞争力，并展示了其在高分辨率网格上的扩展能力。
## 1369. `cs.LG` - 无需非高斯性的多视图因果发现：可观识别性和算法 [PDF](https://arxiv.org/pdf/2502.20115), [HTML](https://arxiv.org/abs/2502.20115)
### Authors
Ambroise Heurtebise,Omar Chehab,Pierre Ablin,Alexandre Gramfort,Aapo Hyvärinen
### Background
因果发现是一个复杂的问题，通常依赖于数据生成模型的强假设，如非高斯性。实践中，许多现代应用提供了相同系统的多个相关视图，但在因果发现中很少考虑这种多视图结构。
### Innovation
本文利用多视图结构进行因果发现，无需严格假设非高斯性。提出了一个扩展非高斯干扰框架的多视图线性结构方程模型，通过在视图之间利用相关性实现因果发现。公布了无环结构方程模型的可观识别性，提出了受单视图算法（DirectLiNGAM、PairwiseLiNGAM 和 ICA-LiNGAM）启发的多视图因果发现算法。
### Conclusion
通过模拟和神经影像数据应用验证了新方法的有效性，能够估计脑区之间的因果图。
## 1370. `cs.LG` - Fused Partial Gromov-Wasserstein for Structured Objects [PDF](https://arxiv.org/pdf/2502.09934), [HTML](https://arxiv.org/abs/2502.09934)
### Authors
Yikun Bai,Shuang Wang,Huy Tran,Hengrong Du,Juexin Wang,Soheil Kolouri
### Background
结构化数据，如图形，在机器学习中至关重要，因为它们能够捕捉到复杂的关系和交互。近年来，融合格罗莫夫-瓦兹松距离（Fused Gromov-Wasserstein，简称FGW）因其能够同时考虑特征相似性和几何结构而备受关注，但FGW作为最优传输的一种形式，假设比较的数据具有等质性约束。
### Innovation
本文提出了一种放松等质性约束的Fused Partial Gromov-Wasserstein（简称FPGW）框架，可以处理不平衡数据。并且该研究证明了FPGW的度量性质，并引入了Frank-Wolfe求解器和Sinkhorn求解器来求解FPGW框架。
### Conclusion
通过图匹配、图分类和图聚类实验评估了FPGW距离的表现，结果表明该方法具有稳健性和优越性。
## 1371. `cs.LG` - 有知识的预测：利用辅助知识提升LLM在时间序列预测中的表现 [PDF](https://arxiv.org/pdf/2505.10213), [HTML](https://arxiv.org/abs/2505.10213)
### Authors
Mohammadmahdi Ghasemloo,Alireza Moradi
### Background
随着大语言模型（LLMs）的广泛应用，人们越来越需要建立利用其能力的方法，超越传统的自然语言任务。在本研究中，作者关注的是如何提升LLMs在时间序列预测中的性能，这是一个在能源系统、金融、医疗等领域越来越重要的任务。
### Innovation
作者提出了一种新型跨域知识迁移框架，该框架系统地将结构化的时间信息注入LLMs，以改善其预测准确性。研究中将该方法应用于实际的时间序列数据集，并将其与一个简单的基线进行比较，该基线中LLMs未接收到任何辅助信息。结果显示，有知识的预测策略在预测准确性和泛化能力上明显优于无知识基线。
### Conclusion
这些结果强调了知识转移策略在连接LLMs与特定领域预测任务方面的潜力。
## 1372. `cs.LG` - Sparsity Forcing: 强化MLLM中token稀疏性 [PDF](https://arxiv.org/pdf/2504.18579), [HTML](https://arxiv.org/abs/2504.18579)
### Authors
Feng Chen,Yefei He,Lequan Lin,Chenhui Gou,Jing Liu,Bohan Zhuang,Qi Wu
### Background
稀疏注意机制旨在通过选择性处理重要令牌来减少计算开销，同时将准确度损失降到最小。虽然这些方法非常有效，但大多数方法仅仅利用了模型内部固有的稀疏性，因此在约50%的令牌减少率时达到了瓶颈，无法进一步降低成本而不损害准确度。其他方法试图通过可训练的稀疏注意机制或锐度诱导的正则化来强制稀疏性，但这些方法要么固定了不考虑输入和层动态的僵化模式，要么优化了间接目标。背景重点在于现有方法的局限性和对新方法的需求。
### Innovation
本文通过一种简单的基于强化学习的后训练框架——Sparsity Forcing，明确强化了Well-posed多模态大语言模型（MLLMs）中的token稀疏性。该方法通过运行多个卷积，每个卷积具有不同的token预算，在此过程中，效率（token减少率）和性能（答案正确性）被统一为联合奖励。通过在每个组内部卷积之间进行对比，更高效和正确的答案将被奖励，而较不高效或错误的答案将被惩罚，从而将token节省转化为端到端的、推理一致的优化目标。
### Conclusion
Sparsity Forcing在Qwen2-VL/Qwen2.5-VL上将token减少率从20%提高到75%，几乎不损失准确度，显著减少了长上下文推理内存负载并加速了解码进程，最多减少3倍的内存使用和提高3.3倍的解码速度。
## 1373. `cs.LG` - 扩散模型能去缠结吗？一种理论视角 [PDF](https://arxiv.org/pdf/2504.00220), [HTML](https://arxiv.org/abs/2504.00220)
### Authors
Liming Wang,Muhammad Jehanzeb Mirza,Yishu Gong,Yuan Gong,Jiaqi Zhang,Brian H. Tracey,Katerina Placek,Marco Vilela,James R. Glass
### Background
论文提出了一种新的理论框架，以理解扩散模型如何学习分离表示。该框架内，作者为一般分离潜在变量模型建立了可识别性条件，分析了训练动态，并推导出分离潜在子空间模型的样本复杂性边界。验证理论的有效性，实验覆盖了不同任务和模态，包括潜在子空间高斯混合模型的子空间恢复、图像着色、图像降噪以及语音转换以实现语音分类。
### Innovation
提出了一个新的理论框架以理解扩散模型如何学习分离表示。该框架包含了可识别性条件、训练动态分析和分离潜在子空间模型的样本复杂性边界。此外，基于理论的训练策略，如风格指导正则化，被证明能提升分离表示性能。
### Conclusion
通过对不同任务和模态的实验验证，论文展示了理论框架的有效性，并证明了基于理论的训练策略能有效提升分离表示性能。
## 1374. `cs.LG` - 超越浅层行为：通过技能发现实现任务高效值基多任务离线MARL [PDF](https://arxiv.org/pdf/2502.08985), [HTML](https://arxiv.org/abs/2502.08985)
### Authors
Xun Wang,Zhuoran Li,Hai Zhong,Longbo Huang
### Background
离线多智能体 reinforcement learning (MARL) 能够仅通过离线数据集学习高效的策略，特别适用于具有大量历史数据但交互成本和风险高的领域。然而，现有的大多数方法都是任务特定的，需要为新任务重新训练，导致重复和低效。现有的方法通过行为克隆从技能中解码动作，但这种方法存在局限性，无法高效地处理多任务场景。因此，本文旨在提出一种任务高效的值基多任务离线MARL算法，即 Skill-Discovery Conservative Q-Learning (SD-CQL)，该算法不仅能避免局部和全局对齐的问题，还能从有限的小规模源任务中实现强多任务泛化能力。
### Innovation
本文提出了一种任务高效的值基多任务离线MARL算法——Skill-Discovery Conservative Q-Learning (SD-CQL)。SD-CQL 在潜在空间中通过重构下一个观察来发现技能，分别评估固定和变化动作，并使用保守Q学习与局部价值校准来根据每个技能选择最佳动作。这项创新不仅避免了局部与全局对齐的问题，而且能够在有限的小规模源任务中实现强多任务泛化性。实验证实在 StarCraft II 上，SD-CQL 在 14 个任务集中的 13 个任务上表现出色，个别任务集上的提升幅度高达 68.9%。这项工作为多任务离线MARL领域带来了新的突破。
### Conclusion
实验结果表明，SD-CQL 在通用性和任务效率方面表现出色，相较于前人工作，在 14 个任务集中的 13 个任务上取得了最好性能，个别任务上的提升幅度高达 68.9%。
## 1375. `cs.LG` - Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation [PDF](https://arxiv.org/pdf/2505.11235), [HTML](https://arxiv.org/abs/2505.11235)
### Authors
Fei Wu,Jia Hu,Geyong Min,Shiqiang Wang
### Background
随着模型参数的快速增长，参数高效微调（PEFT）对于在受限制的计算资源下将大型模型适应到多样化的下游任务变得至关重要。在这个框架内，正交微调及其变体保全了预训练模型的语义表示，但在参数数量、内存和计算效率方面难以同时实现表达性和效率。
### Innovation
提出了一种新的方法Efficient Orthogonal Fine-Tuning with Principal Subspace adaptation (PSOFT)，其核心在于将正交变换限制在预训练权重的主子空间内。PSOFT通过矩阵分解构造主子空间，以实现更高的有效秩；提出严格的理论条件以维持主子空间的几何结构，确保关键语义的保全；引入可调参数，逐渐放松正交性以增强适应性。
### Conclusion
实验证明，PSOFT在35个NLP和CV任务上提供了同时实现语义保全、表达性和多维度效率的实用和可扩展的PEFT解决方案。代码已公开。
## 1376. `cs.LG` - TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning [PDF](https://arxiv.org/pdf/2505.11737), [HTML](https://arxiv.org/abs/2505.11737)
### Authors
Tunyu Zhang,Haizhou Shi,Yibin Wang,Hengyi Wang,Xiaoxiao He,Zhuowei Li,Haoxian Chen,Ligong Han,Kai Xu,Huan Zhang,Dimitris Metaxas,Hao Wang
### Background
尽管大型语言模型（LLMs）展现了令人印象深刻的能力，但其输出质量在不同应用场景中并不一致，这使得识别可信的响应变得困难，尤其是在需要多步推理的复杂任务中。
### Innovation
本文提出了一种名为TokUR的Token-level Uncertainty estimation框架，通过在LLM解码过程中引入低秩随机权重扰动来生成预测分布，从而进行Token级不确定性估计。 TokUR能够捕捉生成响应的语义不确定性，并在此基础上改善LLM在测试时的推理性能。
### Conclusion
通过在不同难度的数学推理数据集上进行的实验表明，TokUR与答案正确性和模型稳健性有很强的关联。通过TokUR生成的不确定性信号可以在测试时增强模型的推理性能。这些结果强调了TokUR作为提高LLM在复杂推理任务中可靠性和可解释性的理论上的和可扩展的方法的有效性。
## 1377. `cs.LG` - 特征对冲：相关特征破坏狭窄稀疏自编码器 [PDF](https://arxiv.org/pdf/2505.11756), [HTML](https://arxiv.org/abs/2505.11756)
### Authors
David Chanin,Tomáš Dulka,Adrià Garriga-Alonso
### Background
假设稀疏自编码器（SAEs）将多义激活分解成可解释的线性方向，只要这种激活是由潜在特征的稀疏线性组合构成的。然而，研究发现，如果一个SAE比它所训练的“真实特征”的数量更窄，并且特征之间存在相关性，那么SAE会将相关特征的成分合并在一起，从而破坏单义性。在预训练的语言模型（LLM）SAEs中，这两个条件几乎肯定成立。这种现象，我们称之为特征对冲，是由SAE重构损失所导致的，且SAE越窄，这一现象越严重。
### Innovation
本文介绍了特征对冲的问题，并在玩具模型和在语言模型上训练的SAEs中进行了理论和实证研究。研究发现，特征对冲可能是SAEs持续不如监督基线的原因之一。基于对特征对冲的理解，本文提出了改进的马特罗什卡SAE版本。
### Conclusion
我们的工作表明，SAE的宽度不是一个中性的超参数：窄的SAE比宽的SAE更容易遭受特征对冲的负面影响。
## 1378. `cs.LG` - BPINN-EM-Post: 基于贝叶斯物理指导神经网络的后空洞期随机 Electromigration 损伤分析 [PDF](https://arxiv.org/pdf/2503.17393), [HTML](https://arxiv.org/abs/2503.17393)
### Authors
Subed Lamichhane,Haotian Lu,Sheldon X.-D. Tan
### Background
现有的 Electromigration (EM) 分析工具通常基于确定性假设，但 EM 诱导应力的实际演变是固有的非确定性的，受输入电流波动和制造非理想性等因素的影响。传统的 EM 应力变异估计方法通常需要使用工业求解器进行耗时且效率低下的蒙特卡洛模拟，这些方法使用均值和方差指标来量化变异。因此，寻找一种更高效的方法来分析 EM 诱导的后空洞期老化过程是必要的。
### Innovation
本文提出了一种基于机器学习的新颖框架，称为 BPINN-EM-Post，用于高效地对 EM 诱导的后空洞期老化过程进行随机分析。该方法首次将闭式解析解决方案与贝叶斯物理引导神经网络 (BPINN) 框架结合，通过利用解析解决方案减少损失函数中的变量数量，加速分析并提高训练效率，同时自然地纳入变异性效果。另外，解析解决方案有效地解决了计算后空洞应力时在互连结构中引入初始应力分布的挑战。与基于有限元方法的 COMSOL 求解器和基于有限差分方法的 EMSpice 的蒙特卡洛模拟相比，BPINN-EM-Post 分别实现了超过 240 倍和超过 67 倍的速度提升，并且具有可忽略的精度损失。
### Conclusion
本文提出了一种新颖的时间高效的 BPINN-EM-Post 方法，用于分析 EM 诱导的后空洞期老化过程，通过结合闭式解析解决方案和 BPINN 框架，有效地提高了分析效率并保证了精度。这对于提升集成电路技术中的可靠性分析具有重要意义。
## 1379. `cs.LG` - 隐式偏置在学习曲线中产生神经网络的标度律，从感知器到深度网络 [PDF](https://arxiv.org/pdf/2505.13230), [HTML](https://arxiv.org/abs/2505.13230)
### Authors
Francesco D'Amico,Dario Bocchi,Matteo Negri
### Background
深度学习领域的研究表明，模型性能与资源增长之间存在着简单的幂律关系，这种关系在不同的架构、数据集和任务上表现出一致的规律。这些规律对于指导先进模型的设计非常重要，因为它量化了增加数据或模型规模的益处，并提示了机器学习中可解释性的基础。然而，大多数研究侧重于训练结束时的渐近行为。
### Innovation
本文提出了两种新的动态标度律，描述了训练过程中随着不同的范数复杂度度量的变化，性能如何演变。这些新规律结合后能恢复已知的收敛时的测试错误的标度律。同时，通过单层感知器在逻辑损失下的训练，本文提供了理论支持，并解释了通过梯度训练产生的隐式偏置。
### Conclusion
本文的结果在不同的CNN、ResNet和Vision Transformers在MNIST、CIFAR-10和CIFAR-100上的训练中保持一致，验证了隐式偏置在学习曲线中的作用，并为理解和指导深度学习模型的设计提供了新的视角。
## 1380. `cs.LG` - CSF: 采用 Q 学习辅助的共轭次梯度算法的固定边框版图规划 [PDF](https://arxiv.org/pdf/2504.03796), [HTML](https://arxiv.org/abs/2504.03796)
### Authors
Xinyan Meng,Huabin Cheng,Rujie Chen,Ning Xu,Yu Chen,Wei Zhang
### Background
最新的研究表明，分析算法在处理复杂版图规划场景方面很有前景。然而，由于基于构造平滑优化模型设计的梯度优化算法的局部收敛性，要生成既紧凑又具有良好布线长度优化效果的版图是一个挑战。为此，本文提出了一种采用 Q 学习辅助的共轭次梯度算法（CSA），该算法通过基于群体的方案适当地调节步骤大小，加速求解非光滑的版图规划模型。通过这种策略，加入 Q 学习辅助的 CSA 方法能够平衡探索和开发。实验结果显示，在 MCNC 和 GSRC 标准时，基于 CSAQ 的固定边框版图规划算法不仅能够有效解决全局版图规划问题，而且在生成合法性版图方面，其效率也超过了基于约束图的合法化算法及其改进版本。此外，CSF 在仅包含硬模块的版图规划场景中也表现出色，与最先进的算法具有竞争力。
### Innovation
本文提出了一种新的算法 CSAQ，该算法通过 Q 学习辅助的共轭次梯度算法加速了非光滑的版图规划模型的求解，同时保持了良好的探索-开发平衡。在此基础上，提出的固定边框版图规划算法（CSF）有效地解决了全局版图规划问题，且生成的版图更具合法性，优于现有的基于约束图的合法化算法及其改进版本，特别是在仅包含硬模块的场景中表现优异，与最先进的算法竞争。
### Conclusion
基于 CSAQ 的固定边框版图规划算法 CSF 不仅能够有效解决全局版图规划问题，而且生成的版图更具合法性，优于现有的基于约束图的合法化算法及其改进版本。对于仅包含硬模块的场景，CSF 显示出与最先进的算法竞争的潜力。该方法为处理复杂版图规划提供了新的解决方案，在实际应用中具有广泛的应用前景。
## 1381. `cs.LG` - LLMs的递归训练循环：训练数据属性如何调节生成数据中的分布变化？ [PDF](https://arxiv.org/pdf/2504.03814), [HTML](https://arxiv.org/abs/2504.03814)
### Authors
Grgur Kovač,Jérémy Perez,Rémy Portelas,Peter Ford Dominey,Pierre-Yves Oudeyer
### Background
大型语言模型（LLMs）越来越多地被用于在线内容的生成，这将形成反馈循环，即后续迭代的模型将基于这些模拟数据进行训练。这种循环已被证明会导致分布变化，即模型错误地反映了真实的人类数据分布（称为模型崩溃）。然而，人类数据的特性如何影响这种变化仍不清楚。本文提供了一个首次的经验性研究，探讨这些特性对递归训练结果的影响。首先确认不同的数据集会导致不同程度的分布变化，通过彻底操纵数据集的属性并结合回归分析，确定预测分布变化程度的属性集。词汇多样性被发现放大了这种变化，而语义多样性和数据质量则抑制了它们。最终，通过政治偏见实验发现，人类数据的特性会影响初始偏见是被放大还是减弱。
### Innovation
本文通过经验性研究，首次确定了数据集属性对模型循环训练结果的影响，发现词汇多样性放大分布变化，语义多样性和数据质量则降低了这种变化。此外，发现这些影响高度模块化：来自特定互联网域的数据对另一域生成的内容影响很小。该研究揭示了互联网的不同部分可能经历不同类型分布变化的新视角。
### Conclusion
该研究详细探讨了数据集属性如何通过递归训练影响大型语言模型生成数据的分布变化，并提出这个过程具有高度模块化的特性。
## 1382. `cs.LG` - 学习用于遮掩分子扩散的灵活前向轨迹 [PDF](https://arxiv.org/pdf/2505.16790), [HTML](https://arxiv.org/abs/2505.16790)
### Authors
Hyunjin Seo,Taewon Kim,Sihyun Yu,SungSoo Ahn
### Background
遮掩扩散模型（MDMs）已取得显著进展，尤其是在离散数据建模方面，但在分子生成方面，其潜在应用仍未得到充分探索。标准的MDMs在分子生成任务上表现不佳的原因是状态碰撞问题，导致分子前进扩散时相互碰撞，最终生成的重建目标混杂无法用典型的单一预测逆扩散过程学习。
### Innovation
提出了Masked Element-wise Learnable Diffusion（MELD）方法，设计了一个参数化的噪声调度网络，为单个图元素（原子和键）分配不同的破坏率，从而避免分子间的碰撞并改善重建质量。
### Conclusion
MELD方法显著提升了生成质量，在ZINC250K基准上将传统的MDMs化学有效性从15%提高到93%。此外，在条件生成任务中，MELD在性质匹配方面达到了最先进的水平。
## 1383. `cs.LG` - SPAR: 自监督感知位置意识的分布式传感表示学习 [PDF](https://arxiv.org/pdf/2505.16936), [HTML](https://arxiv.org/abs/2505.16936)
### Authors
Yizhuo Chen,Tianchen Wang,You Lyu,Yanlan Hu,Jinyang Li,Tomoyoshi Kimura,Hongjue Zhao,Yigong Hu,Denizhan Kara,Tarek Abdelzaher
### Background
分布式传感涵盖多种应用场景，如车辆监测、人类活动识别和地震定位，其中多个地理位置分散且具有多模态传感器共同观测环境。这一宽泛领域的一个核心挑战是如何将观测信号和传感器的放置方式紧密结合，包括它们的空间位置和结构角色。
### Innovation
SPAR提出了一种统一的原则来解决现有方法的不足，即信号与位置之间的二元对立关系。SPAR引入了空间和结构位置嵌入，以及双重重建目标，明确建模观测位置如何影响观测信号，反之亦然。SPAR通过信息理论分析和遮挡不变学习支持其理论，并在三个真实数据集上的实验证明了它在不同模态、放置和下游任务上的优越鲁棒性和泛化能力。
### Conclusion
SPAR以感知位置为基础，实现了无监督的分布式传感表示学习，并在多个实际数据集上展示了其优越的鲁棒性和泛化能力。
## 1384. `cs.LG` - 在单位超球面上利用预训练VLMs的非对称不确定性结构 [PDF](https://arxiv.org/pdf/2505.11029), [HTML](https://arxiv.org/abs/2505.11029)
### Authors
Li Ju,Max Andersson,Stina Fredriksson,Edward Glöckner,Andreas Hellander,Ekta Vats,Prashant Singh
### Background
视觉-语言模型（VLMs）作为基础模型在视觉和文本任务中显著提升了性能，无需从零开始进行大规模训练以适应下游任务。然而，这些确定性的VLMs无法捕捉自然语言和视觉数据中固有的不确定性。近期的后验概率方法试图通过将确定性嵌入映射到概率分布来解决这个问题，但现有方法没有考虑到模态间的不对称不确定结构，也没有满足有意义的确定性嵌入位于单位超球面上的约束条件，从而可能导致性能不理想。
### Innovation
本文提出了AsymVLM，这是一种从预训练VLMs的单位超球面上构建概率嵌入的方法，旨在处理文本和视觉数据中固有的非对称不确定性结构，从而量化不确定性。该方法通过全面的消融研究证明了文本和视觉数据中不确定性结构的固有不对称性，并在现有基准测试上验证了概率嵌入的有效性。
### Conclusion
通过利用预训练VLMs在单位超球面上的非对称不确定性结构，AsymVLM能够更准确地量化文本和视觉数据中的不确定性，从而改进了VLMs在下游任务中的性能。
## 1385. `cs.LG` - 试与信任：全面防御策略应对拜占廷攻击 [PDF](https://arxiv.org/pdf/2505.07614), [HTML](https://arxiv.org/abs/2505.07614)
### Authors
Gleb Molodtsov,Daniil Medyakov,Sergey Skorik,Nikolas Khachaturov,Shahane Tigranyan,Vladimir Aletov,Aram Avetisyan,Martin Takáč,Aleksandr Beznosikov
### Background
近期，机器学习的发展虽提高了性能，但也增加了计算需求。联邦和分布式计算框架虽然解决了部分问题，但其结构仍然容易受到恶意行为的影响。特别是在由受攻击节点发起的拜占庭攻击背景下，这些框架中的节点被恶意操控，向全局模型注入敌对更新以破坏全局收敛。本文重点讨论这一特定威胁，并提出结合信任评分与试探函数方法动态过滤异常点的新策略，以提高系统在受攻击节点占多数时的安全性和稳定性，同时适用于广泛使用的大规模扩展方法和实际应用场景，包括局部训练和部分参与。实验部分展示了该方法在合成数据和真实医疗ECG数据集上的鲁棒性，并在理论上证明了该方法在对抗拜占庭干扰条件下的收敛性保证与传统算法相当。因此，这一系列研究结果改进了当前面向受攻击节点占多数情况下的防御策略，提升了模型的鲁棒性和安全性，拓展了现有技术和理论的理解。
### Innovation
文章采用结合信任评分与试探函数方法的新策略应对拜占庭攻击，实现了在受攻击节点占多数的环境中保持系统的有效性和鲁棒性。此外，所提算法能够适应广泛使用的大规模扩展方法和实际应用场景，如局部训练和部分参与。通过详尽的实验证据和理论分析，证明了该方法的优越性和可行性，特别是在存在大量受攻击节点时，仍能提供可与传统算法媲美的收敛保证。这种方法的创新点在于其适应性和鲁棒性，以及面对复杂应用场景的广泛适用性。
### Conclusion
本文通过结合信任评分与试探函数方法，提出了一种新的策略来应对拜占庭攻击，并验证了该方法在实际应用中的有效性和鲁棒性。实验结果和理论分析证明了该方法能够适应拜占庭干扰条件，并能够与大量使用的大规模扩展方法及局部训练等实际场景兼容。该研究为构建更加安全和可靠的分布式机器学习系统提供了新的思路和技术实现方案，特别是在受到恶意节点干扰的复杂环境下的鲁棒性得到了有效提升。
## 1386. `cs.LG` - 隐含真实性推理在逐步推理中的错误识别 [PDF](https://arxiv.org/pdf/2505.11824), [HTML](https://arxiv.org/abs/2505.11824)
### Authors
Minsu Kim,Jean-Pierre Falet,Oliver E. Richardson,Xiaoyin Chen,Moksh Jain,Sungjin Ahn,Sungsoo Ahn,Yoshua Bengio
### Background
Chain-of-Thought (CoT) 推理提高了语言模型（LMs）的能力和透明度，但推理链中可能包含不准确的陈述，从而影响性能和可信度。目前的方法难以在验证推理的同时提高模型的准确性和可信度，需要一种新的方法来有效探索扩展空间，提高推理步骤的准确性。
### Innovation
该文提出了一种名为 Veracity Search (VS) 的离散搜索算法，在每一步 CoT 推理中引入隐含真实性（或正确性）变量。AVI（Amortized Veracity Inference）机器通过提供这些变量的伪标签，实现了高效的推理时间验证方法，进而支持监督微调。AVI 能够泛化 VS，实现对新情境下的准确性零样本推理，提高了诸如逻辑、数学和常识推理基准测试的性能。
### Conclusion
实验证明，VS 可靠地识别出逻辑（ProntoQA）、数学（GSM8K）和常识（CommonsenseQA）推理基准中的错误，AVI 达到了类似零样本准确率。此外，隐含的真实性推理还有助于自我修正和自我改进过程中提供反馈。
## 1387. `cs.LG` - 量化与推理：探索和缓解低比特LLM在数学推理中的性能下降问题 [PDF](https://arxiv.org/pdf/2505.11574), [HTML](https://arxiv.org/abs/2505.11574)
### Authors
Zhen Li,Yupeng Su,Songmiao Wang,Runming Yang,Congkai Xie,Aofan Liu,Ming Li,Jiannong Cao,Yuan Xie,Ngai Wong,Hongxia Yang
### Background
低比特后训练量化（PTQ）是一种在严格的内存和延迟预算下部署推理能力较强的大语言模型（LLMs）的实际途径，但却会显著损害其数学推理能力（在更困难的情况下，性能下降可达69.81%）。本研究针对部署关键问题进行深入探讨，以过程级精度分析了数学推理问题，并在广泛使用的PTQ方法（AWQ、GPTQ、SmoothQuant）、开源模型家族（Qwen、LLaMA，对应参数量为0.5-7B）和数学推理基准测试（GSM8K、MATH、AIME）中进行了验证。
### Innovation
本研究发现了两种稳健的规律：(i) 量化显著增加了方法和执行错误，而不是高级概念性错误；(ii) 失败会迅速从最初的脆弱步骤传播到最终答案。这些规律表明了一种通用的干预原则：精确恢复最早失效前沿的局部标记级边际。本研究通过一个轻量级的检测、构建和调整的循环过程实现这一原则，该过程直接作用于量化模型：检测最早失败步骤，构建“银子弹”数据集，并应用小型监督/偏好调整。在本研究设定中，通过少量定制样本（最多332个）和单GPU上3-5分钟的计算时间，可以恢复4比特权重的数学推理性能至全精度基准，同时保留量化效率。本框架在评估的范围内是量化器和架构独立的，并将低比特性能下降问题从全局准确性问题转化为局部、可重现的过程干预问题。
### Conclusion
本研究提出了一个通用干预原则和一个轻量级操作的框架来缓解低比特量化对LLMs在数学推理性能的影响，通过少量的定制样本和计算资源即可实现恢复性能，这表明这种方法具有较高的实用性和效率。
## 1388. `cs.LG` - 结构化的关系表示 [PDF](https://arxiv.org/pdf/2505.12143), [HTML](https://arxiv.org/abs/2505.12143)
### Authors
Arun Kumar,Paul Schrater
### Background
不变表示在表示学习中至关重要，但核心挑战是如何发现既稳定又可迁移的不变量，同时不抑制任务相关信号。这引发了一系列关于如何定义这些不变量的适当抽象层次以及它们应表征系统的哪些方面的问题。环境解释依赖于抽象知识结构来理解当前状态，进而引导学习和知识获取。解释发生在高层关系知识的层次上，因此我们提出，不变结构必须是知识存在的核心，具体来说，是通过抽象知识空间内的关系路径闭包定义的分区。这些分区是核心不变表示的基础，它们是知识存储和学习发生的结构基础。另一方面，跨分区连接器使这些知识分区中的任务相关转换得以实现。因此，不变分区提供了结构化的表示基础元素。
### Innovation
该研究提出了基于闭包半环的结构化关系表示的计算基础。这一方法标志着在结构化相关表示的不变分区定义中迈出的重要一步，旨在构建知识存储和学习发生的结构基础。
### Conclusion
研究认为，不变结构构成知识的核心，通过闭包路径进行定义，并通过跨分区连接器实现任务相关的转换。不变分区提供了一个新的框架，可以更好地理解和构建知识结构，从而促进学习和知识的获取。
## 1389. `cs.LG` - 近似最优的遗憾度上限：双边贸易中的利润最大化 [PDF](https://arxiv.org/pdf/2509.22563), [HTML](https://arxiv.org/abs/2509.22563)
### Authors
Simone Di Gregorio,Paul Dütting,Federico Fusco,Chris Schwiegelshohn
### Background
双边贸易模型涉及在竞拍过程中，作为中间人的广告代表如何在双方（卖家和买家）持有私人估值的情况下促成双方交易的任务。本文从广告代表（经纪人）的角度出发，研究该问题，并在遗憾最小化框架下探讨相关问题。每一次时步，都会有一个新的卖家和买家加入，而广告代表需要提出一个同时具备激励兼容性和个体理性的机制，以达到最大化利润的目标。之前的关于双边贸易效率最大化的研究以单一的最优固定价格作为基准，本文则以当前最优的激励兼容性和个体理性的机制作为基准，这是一项更重要的改进。由于所有机制收益的统一收敛不可能实现，作者通过精确的链式分析解决了这一难题，并证明了几乎最优机制的收敛性，同时展示了该方法在联合广告问题上的广泛适用性。
### Innovation
本文提出了一种学习算法，在随机环境下保证了几乎最优的遗憾度上限，即tilde{O}(√{T})，当卖家和买家的价值按照固定但可能存在相关性且未知的分布独立同分布（i.i.d.）抽取时。更进一步的是，本文证明，在估值由对手提前生成的非平稳场景中，不可能实现亚线性遗憾度上限。本文设定的基准是当前最优的激励兼容性和个体理性的机制，这在效率最大化问题上的研究中从未被利用。研究中提出方法几乎在最优速率上实现了收敛性，克服了所有机制收益统一收敛的不可能性。同时将该技术应用于联合广告问题并得到了接近最优的结果，进一步展示了技术的广泛适用性。
### Conclusion
研究证明了几乎最优的后悔度上限，以及在这种背景下最优的激励兼容性和个体理性的机制。进一步证明了在不平稳的估值预测环境下无法实现亚线性后悔度上限。此外，提出了新的学习算法，应用于联合广告问题中取得了接近最优的结果。
## 1390. `cs.LG` - 仅前向扩散概率模型 [PDF](https://arxiv.org/pdf/2505.16733), [HTML](https://arxiv.org/abs/2505.16733)
### Authors
Ziwei Luo,Fredrik K. Gustafsson,Jens Sjölund,Thomas B. Schön
### Background
现有的生成模型大多依赖于前向-后向扩散机制，但这使得模型结构复杂且计算效率较低。本文提出了一种仅前向扩散（FoD）方法，通过单一的前向扩散过程直接学习数据生成，提供了一个简单但高效的生成框架。
### Innovation
FoD的核心是一种基于状态依赖随机微分方程，其中的漂移和扩散函数都包含回复项，保证了其收敛到干净数据，模拟了源分布和目标分布之间的随机插值。更重要的是，FoD具有可解析性，并使用简单的随机流匹配目标进行训练，在推断中可以实现少量步骤的非马尔可夫链采样。尽管模型简单，但FoD在各种图像恢复任务上达到了最先进的性能，并展示了其在图像条件生成上的广泛适用性，通过图像到图像翻译的定性结果进行了证明。
### Conclusion
提出的FoD模型简单且高效，在多种图像恢复任务中实现了最先进的结果，且展示了其在图像到图像翻译等任务中的通用性。
## 1391. `cs.LG` - 少样本对抗低秩细调视觉语言模型 [PDF](https://arxiv.org/pdf/2505.15130), [HTML](https://arxiv.org/abs/2505.15130)
### Authors
Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Mahnoosh Alizadeh,Ramtin Pedarsani
### Background
视觉语言模型（VLMs）如CLIP能够通过大型对比预训练在跨模态任务中表现出卓越性能。为适应这些大型变压器模型高效满足下游任务，Parameter-Efficient Fine-Tuning（PEFT）技术，特别是低秩适配（LoRA），已被提出作为全量细调的可扩展替代方法，特别是在少样本场景中。然而，这些模型在对抗攻击方面仍然非常脆弱，细微的扰动可以大幅降低模型性能。对抗训练目前是提高模型鲁棒性最有效的方法之一。
### Innovation
本文提出了AdvCLIP-LoRA，这被认为是第一个专门设计来增强使用LoRA微调的CLIP模型在少样本场景下的对抗鲁棒性的方法。该方法通过最小最大优化的方法在低秩适配器和对抗扰动上进行训练，从而实现鲁棒适应，且训练的内存占用小。实验结果表明，AdvCLIP-LoRA在少样本分类、对抗基线到新模型推广及跨数据集迁移方面均取得了最先进的性能，且对抗鲁棒性优于提示调优基线，同时保持了较高的准确率。
### Conclusion
这些发现表明，AdvCLIP-LoRA是一个实用的方法，适用于在资源受限的环境中增强VLMs的鲁棒性。
## 1392. `cs.LG` - Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study [PDF](https://arxiv.org/pdf/2505.18697), [HTML](https://arxiv.org/abs/2505.18697)
### Authors
Ziyang Cheng,Zhixun Li,Yuhan Li,Yixin Song,Kangyi Zhao,Dawei Cheng,Jia Li,Hong Cheng,Jeffrey Xu Yu
### Background
现实世界数据通常以流式的方式到来，这意味着学习系统需要不断获取新知识而不忘记之前学到的信息。虽然现有工作尝试解决图机学习中的灾难性遗忘问题，但这些方法都是基于从头开始训练流式数据进行的。近年来，预训练模型因其强大的泛化能力被越来越多地应用于连续学习中。
### Innovation
本文提出了一个名为Simple Graph Continual Learning (SimGCL) 的简单但有效的解决方案，该方法在无需回放的情况下超越了之前的GNN基线方法大约20%。
### Conclusion
通过广泛的实验，我们证明了大语言模型（LLMs）可以在图连续学习中缓解灾难性遗忘现象。为了便于复现，我们开发了一个用户友好的基准LLM4GCL用于训练和评估现有方法。
## 1393. `cs.LG` - 利用内在动机引导探索提升LLM推理能力 [PDF](https://arxiv.org/pdf/2505.17621), [HTML](https://arxiv.org/abs/2505.17621)
### Authors
Jingtong Gao,Ling Pan,Yejing Wang,Rui Zhong,Chi Lu,Qingpeng Cai,Peng Jiang,Xiangyu Zhao
### Background
强化学习(RL)已经成为增强大型语言模型(LLMs)推理能力的关键方法。然而，现有的RL方法，如近端策略优化(PPO)和分组正则化策略优化(GRPO)，面临重要局限性：依赖稀疏结果奖励且缺乏激励探索的有效机制，这导致了推理过程中的低效指导。稀疏奖励无法提供足够反馈，尤其对难题效果不佳。此外，这些奖励会系统性地偏向熟悉轨迹，而非探索新解决方案。这些问题在需要多次迭代细化的复杂推理任务中，严重阻碍了性能。
### Innovation
我们提出了Intrinsic Motivation guidEd exploratioN meThOd foR LLM Reasoning (i-MENTOR)，一种旨在提供稠密奖励并增强基于RL的探索的方法。i-MENTOR 的创新之处在于：引入轨迹感知探索奖励，减少了在标记级别策略中的偏差，同时保持计算效率；基于错误条件的奖励分配，确保对难题的有效探索，并内在稳定训练；保持优势分布完整性的优势保留整合，同时引入探索引导。
### Conclusion
实验结果在4个公开数据集上展示了i-MENTOR的有效性，相比AIME 2024基准，其性能提高了22.23%。
## 1394. `cs.LG` - 极光号：最优矩阵符号方法及其在Muon算法中的应用 [PDF](https://arxiv.org/pdf/2505.16932), [HTML](https://arxiv.org/abs/2505.16932)
### Authors
Noah Amsel,David Persson,Christopher Musco,Robert M. Gower
### Background
矩阵的极分解和相关的矩阵符号函数在数值分析中已经被研究了几十年。最近，它们成为了Muon算法中训练深度神经网络的重要子程序。然而，该应用的需求与传统场景截然不同：深度学习需要具有高吞吐量优先而非高精度的GPU友好型算法。因此，研究人员引入了Polar Express作为一种新的计算极分解的方法。这种方法强调使用仅矩阵-矩阵乘法的步骤，以在GPU上实现高效处理，符合深度学习的需求特点。
### Innovation
Polar Express通过在每个迭代周期解决一个极小-极大优化问题来动态调整更新规则，这使得方法在最坏情况下误差最小化，并确保最佳收敛速度。此外，该方法还解决了有限精度的问题，使其在bfloat16中有实际应用的可能性。最后，将该方法集成到Muon训练框架中，使使用GPT-2模型进行FineWeb数据集的一亿个令牌训练时，在验证损失方面优于当前的替代方法，涵盖多种学习率场景。
### Conclusion
Polar Express通过改进经典的方法，使得极分解的计算在GPU上更为高效，同时提升了在深度学习中的实际应用效果。它不同于传统方法，更适合深度学习的高吞吐量需求。
## 1395. `cs.LG` - 可学习的核密度估计方法用于图数据 [PDF](https://arxiv.org/pdf/2505.21285), [HTML](https://arxiv.org/abs/2505.21285)
### Authors
Xudong Wang,Ziheng Sun,Chris Ding,Jicong Fan
### Background
在图密度估计中，关键挑战在于有效捕捉结构模式和语义变化，同时保持理论保证。传统的图内核和核密度估计（KDE）相结合的方法虽为标准方法，但由于内核的手工设计和固定特征，导致性能不佳。
### Innovation
本文提出了LGKDE框架，利用图神经网络表示每个图作为一个离散分布，并通过最大均值偏差来学习用于多尺度KDE的图度量。通过在节点特征和图频谱上进行扰动，更好地刻画正常密度区域的边界。从理论角度，我们为LGKDE建立了收敛性和一致性的保证，包括积分均方误差的上界、鲁棒性和泛化能力。该方法通过分析合成的图分布并应用于多样基准数据集的图异常检测展示出了优越性。
### Conclusion
综上所述，LGKDE在多种基准数据集的图异常检测上表现出了比最先进的基线方法更好的性能，并通过理论和实证分析验证了其有效性和优越性。
## 1396. `cs.LG` - 束缚式变换器：用于泛化推理的周期性KV缓存巩固 [PDF](https://arxiv.org/pdf/2505.16950), [HTML](https://arxiv.org/abs/2505.16950)
### Authors
Adnan Oomerjee,Zafeirios Fountas,Haitham Bou-Ammar,Jun Wang
### Background
Transformer大模型已被证明在推理过程中凭借计算能力的增加表现出强大的推理能力，主要体现在令牌空间的‘思考’链条上。现有研究通过将额外计算引入模型的潜空间，即辅助潜空间计算（ALSC），进行探索。目前主要有三种方法：令牌介导的潜在展开、残差/激活调节以及记忆（KV）压缩。另一种未被充分探索的方法是记忆巩固/重新巩固，这两者是大脑稳定新形成的记忆痕迹并在回想起时暂时使已确立的记忆痕迹变得可塑以整合新环境信息的过程。在变换器大模型中，这类似于对新加入的KV片段进行原地重写和对已回想片段进行原地重写的思路。这项工作中，我们通过信息瓶颈（IB）理论提供了一个理论上的证明，说明通过KV缓存重写来进行记忆巩固/重新巩固将有助于提高推理能力。
### Innovation
提出了通过引入辅助变换器（Cache处理器）进行周期性非因果KV缓存重写的束缚式变换器架构。该处理器对最近写入的KV项进行巩固，并对一个顶k大小的注意力选择的先前项进行重新巩固。这项工作的创新之处在于采用信息瓶颈理论作为解释，并通过这种非因果的原地KV重写机制来实现记忆巩固/重新巩固，进而增强推理性能，相比普通变换器和带暂停标记的基础模型，我们在数学推理基准测试中的模型获得了持续的性能提升，部分任务的性能提升可达+6.6个百分点。
### Conclusion
研究表明，通过KV缓存重写实现记忆巩固/重新巩固的束缚式变换器，能显著提高推理性能。相比基础模型和带有暂停标记的模型，我们的模型在数学推理任务上表现出一致的性能提升，甚至部分任务在模型性能上提升了6.6个百分点。
## 1397. `cs.LG` - HD-PiSSA: 高阶分布式正交适应 [PDF](https://arxiv.org/pdf/2505.18777), [HTML](https://arxiv.org/abs/2505.18777)
### Authors
Yiding Wang,Fauxu Meng,Xuefeng Zhang,Fan Jiang,Pingzhi Tang,Muhan Zhang
### Background
现有的参数高效微调（PEFT）方法，如LoRA和PiSSA，将模型更新限制在低秩子空间中，这限制了其表达能力，并在复杂任务上导致表现不佳。
### Innovation
提出了一种分布式PEFT方法——高阶分布式PiSSA（HD-PiSSA），该方法通过在不同设备初始化正交适配器并在W中联合聚集它们的delta更新来实现。与数据并行的LoRA或PiSSA保持所有设备上相同的适配器不同，HD-PiSSA将预训练权重的主要成分分配给每个GPU，显著扩展了更新方向的范围，使得在8个GPU上进行微调时，有效更新秩比数据并行的LoRA或PiSSA高16倍。
### Conclusion
我们在各种具有挑战性的下游任务中评估了HD-PiSSA，包括数学、代码生成和多任务学习。在多任务设置中，HD-PiSSA在12项基准测试中平均提高了10.0个绝对点（14.63%）和4.98个点（6.60%），相对于LoRA和PiSSA，展示了其由于额外的优化灵活性而带来的优势。
## 1398. `cs.LG` - ExPLAIND: 将模型、数据和训练归因统一起来研究模型行为 [PDF](https://arxiv.org/pdf/2505.20076), [HTML](https://arxiv.org/abs/2505.20076)
### Authors
Florian Eichin,Yupei Du,Philipp Mondorf,Maria Matveev,Barbara Plank,Michael A. Hedderich
### Background
后验解释方法通常将模型的行为孤立地归因于其组件、数据或训练轨迹，这导致解释缺乏统一的观点，可能忽略关键交互。虽然结合现有方法或在不同的训练阶段应用它们可以提供更广泛的理解，但这些方法通常缺乏理论支持。
### Innovation
本文提出了一种统一框架ExPLAIND，将多种观点整合在一起。首先，它将最近关于梯度路径核的工作进行了泛化，将由梯度下降训练的模型重新表述为核机器，适用于如AdamW等实际设置。其次，文章从核特征图中推导出新颖的参数和步骤影响评分，这些评分在参数修剪方面的有效性与现有方法相当，证明了它们对于模型组件归因的价值。最后，ExPLAIND在模型组件和数据在整个训练过程中的联合解释方面发挥作用，进而分析表现Grokking现象的Transformer模型。
### Conclusion
ExPLAIND 提供了一个具有理论基础、统一的框架来解释模型行为和训练动力学，支持先前提出的 Grokking 阶段，同时进一步细化了最终阶段为输入嵌入和最终层与在记忆阶段后学习的表示管道对齐的过程。
## 1399. `cs.LG` - 基于FFT的动态子空间选择用于大规模语言模型的低秩自适应优化 [PDF](https://arxiv.org/pdf/2505.17967), [HTML](https://arxiv.org/abs/2505.17967)
### Authors
Ionut-Vlad Modoranu,Mher Safaryan,Erik Schultheis,Max Ryabinin,Artem Chumachenko,Dan Alistarh
### Background
低秩优化已成为训练大规模语言模型（LLMs）的有效方法，通过限制学习到较低维度的空间来减少自适应优化器的运行时间和内存使用。先前的工作通常使用奇异值分解（SVD）或QR分解来投影线性层的梯度，但这些方法在大型模型的每个层上单独应用时计算成本高昂，并且会因存储投影矩阵而增加额外的内存开销。
### Innovation
本文提出了一种计算高效且概念简单的两步方法，使用离散余弦变换（DCT）预定义的正交矩阵来近似基于SVD/QR的梯度投影到较低维度的空间中。该方法根据每一层梯度与DCT矩阵列的对齐情况动态选择列。通过简单的点积操作，得到有效的投影矩阵，并进行轻量级的排序步骤来识别最具相关性的基向量。对于大型层，DCT可以通过基于快速傅里叶变换（FFT）的Makhoul的N点算法在O(n^2 log(n))时间内计算。由于预定义的正交基，它们在训练开始时仅计算一次。
### Conclusion
我们在预训练和微调任务上的数值实验表明，我们的双重策略在逼近最优低秩投影方面的有效性，获得了与昂贵的SVD/QR基方法相当的性能，同时通过高达25%的运行时间和内存使用降低实现了更快的运行时。我们的代码可以在ISTA-DASLab-Optimizers获取。
## 1400. `cs.LG` - 基于有限数据和未知物理的启发频谱操作符学习 [PDF](https://arxiv.org/pdf/2505.21573), [HTML](https://arxiv.org/abs/2505.21573)
### Authors
Han Wan,Rui Zhang,Hao Sun
### Background
从有限的数据中学习偏微分方程（PDE）的动力学并且不需要已知的物理条件是一项挑战。现有的神经PDE求解器要么需要大量数据集，要么依赖已知的物理条件（如PDE残差或手工打造的微分模板），这限制了它们的应用范围。
### Innovation
本文提出了一种名为Spectral-Inspired Neural Operator (SINO)的新颖技术，它能够仅从2-5条轨迹中建模复杂系统，无需显式地使用PDE项。SINO通过从频率索引中自动捕捉局部和全局空间导数，能在忽略物理的前提下给出紧凑的表示。为了建模非线性效应，SINO采用Pi-block执行光谱特征上的相乘操作，并结合低通滤波器抑制混叠现象。
### Conclusion
在2D和3D PDE基准测试中的广泛实验表明，SINO达到了最先进的性能，准确率上的提升幅度高达一个或两个数量级。特别地，仅用5个训练轨迹，SINO的表现优于其他方法用1000个轨迹训练的结果，并且在其他方法无法进行预测的复杂情况下仍然保持预测能力。
## 1401. `cs.LG` - 超出代理：轨迹提炼指导下的离线GFlowNet训练 [PDF](https://arxiv.org/pdf/2505.20110), [HTML](https://arxiv.org/abs/2505.20110)
### Authors
Ruishuo Chen,Xun Wang,Rui Hu,Zhuoran Li,Longbo Huang
### Background
GFlowNets在采样高奖励、多样化对象方面效果显著，但在许多现实场景中，当新的奖励查询不可行时，它们需要从离线数据集中进行训练。当前的基于代理的方法极易产生错误传播，而现有的无代理方法通常使用粗糙的约束，限制了探索能力。
### Innovation
本文提出了轨迹提炼GFlowNet (TD-GFN)，这是一种新颖的无代理训练框架。TD-GFN通过逆强化学习从离线轨迹中学习密集、转换级别的边奖励，提供丰富的结构指导以促进高效探索。为了保证鲁棒性，这一奖励间接指导策略通过DAG修剪和优先反向采样训练轨迹来使用，从而避免错误传播。实验表明，TD-GFN在收敛速度和最终样本质量上显著优于现有的一系列基线方法，为离线GFlowNet训练提供了一种更稳健和高效的范式。
### Conclusion
TD-GFN在离线GFlowNet训练的鲁棒性和效率方面产生了显著效果，确保了最终梯度更新仅依赖于数据集中的真实终端奖励，从而避免了错误传播问题，使得TD-GFN在离线场景下表现更优。
## 1402. `cs.LG` - RsGCN: Subgraph-Based Rescaling Enhances Generalization of GCNs for Solving Traveling Salesman Problems [PDF](https://arxiv.org/pdf/2506.00533), [HTML](https://arxiv.org/abs/2506.00533)
### Authors
Junquan Huang,Zong-Gan Chen,Yuncheng Jiang,Zhi-Hui Zhan
### Background
基于图 convolution 网络的旅行商问题（TSP）求解器面临两大挑战：跨尺度泛化能力差和高训练成本。这些挑战限制了TSP求解器的有效性和效率。
### Innovation
提出了一种基于子图的可重构图卷积网络（RsGCN）。设计子图重标定机制来标准化子图边长，该机制从统一的子图视角出发，能以较低成本高效学习适用于不同规模TSP的表示。引入了基于重构的搜索（RBS），在控制和评估RsGCN生成的热图过程中，结合了自适应权重的重构过程来帮助避免局部最优。
### Conclusion
基于RsGCN和RBS的解算器在少量训练周期内表现出了卓越的泛化能力和低训练成本：仅在一个包含至多100节点实例的混合尺度数据集上进行3个周期的训练，即能成功泛化至10K节点实例，无需任何微调。广泛实验表明，该方法在9个不同规模的均匀分布实例和78个真实世界实例上表现出高性能，同时具备最少的可学习参数和训练周期，超过了其他基于神经网络的竞争对手。
## 1403. `cs.LG` - 使用软标签和校准估算最优分类错误的实用性方法 [PDF](https://arxiv.org/pdf/2505.20761), [HTML](https://arxiv.org/abs/2505.20761)
### Authors
Ryota Ushio,Takashi Ishida,Masashi Sugiyama
### Background
虽然近年来机器学习系统的性能取得了显著进步，但关于如何进一步改进模型的基础问题关注较少。本文在二元分类的情景下提出了一种实用且有理论支持的方法来探讨这个问题。研究前人利用软标签估算贝叶斯错误（最优错误率）的方法，本文做出了两个重要扩展：一是理论上探讨了基于硬标签估计器偏差的性质，揭示了这种偏差随用于每个实例的硬标签数量增加会显著加快衰减；二是探讨了在软标签受损的情况下进行估计的更具挑战性的问题，在完美校准软标签也可能导致不准确估计的情况下，提出了基于较弱假设下的等距校准提供统计一致的估计方法。没有假设访问任何输入实例，使方法适应实例不可用的隐私场景。
### Innovation
1. 理论上检验了基于硬标签的估计器偏差的特性，显示了偏差随每实例硬标签数量增加的衰减速度快。2. 提出了在软标签受损情况下的估计方法，揭示了校准保证不足，即使完美校准的软标签也可能导致不准确估计，并提出等距校准在较弱假设下提供统计一致的估计。3. 提出的方法无需假设访问任何输入实例，使方法适用于因隐私问题实例不可用的场景。
### Conclusion
实验结果表明，本方法和理论的可行性，在合成和真实数据集上验证了其有效性。
## 1404. `cs.LG` - 光谱图神经网络在简单光谱图上的不完善性 [PDF](https://arxiv.org/pdf/2506.05530), [HTML](https://arxiv.org/abs/2506.05530)
### Authors
Snir Hordan,Maya Bechler-Speicher,Gur Lifshitz,Nadav Dym
### Background
光谱特性广泛应用于图神经网络（GNNs）以增强其表达能力，即区分非同构图的能力。常用的光谱增强方法包括MPNNs和图变换器中的图拉普拉斯特征向量的位置编码。Spectral-enhanced GNNs（SGNNs）的表达能力通常通过k-WL图同构测试层次结构和同态计数进行评估。然而，这些框架忽略了实际的光谱信息，提供的见解有限。
### Innovation
本文引入了一个新的方法，通过图的最大特征值多重性分类图，提出了SGNNs的表达能力等级。证明了许多SGNNs即使在具有不同特征值的图中也是不完整的。为此，提出了一种新的旋转不变神经网络方法，旨在提高特定光谱图中SGNNs的表达能力。
### Conclusion
本文通过实验验证了所提出的理论。通过在MNIST Image分割数据集上的图像分类实验和ZINC图的特征向量化验证了方法的有效性。
## 1405. `cs.LG` - WeightLoRA: 保留必要的适配器 [PDF](https://arxiv.org/pdf/2506.02724), [HTML](https://arxiv.org/abs/2506.02724)
### Authors
Andrey Veprikov,Vladimir Solodkin,Alexander Zyl,Andrey Savchenko,Aleksandr Beznosikov
### Background
语言模型在现代应用中的广泛应用离不开参数高效微调技术（如低秩适应$texttt{LoRA}$）的支持。$texttt{LoRA}$增加了可训练适配器以改进选定层，尽管它可能获得准确的结果，但训练大型模型时需要大量内存，并且难以确定添加适配器的哪几层。
### Innovation
本文提出了一种新型方法$texttt{WeightLoRA}$，通过优化过程中自适应选择最关键$texttt{LoRA}$头，解决了上述问题。该方法在减少可训练参数数量的同时，保持了获得一致或更佳度量值的能力。实验结果表明$texttt{WeightLoRA}$的有效性，以及$texttt{WeightLoRA+}$在几乎所有情况下的优越性能。
### Conclusion
通过$texttt{WeightLoRA}$，我们能够显著减少训练参数数量，同时保持甚至提高模型的关键性能，通过致谢各种指标上的竞争基准和$texttt{DeBERTa}$、$texttt{BART}$和$texttt{Llama}$模型进行了比较实验，结果证实了该方法的有效性和优越性。
## 1406. `cs.LG` - SDPO: 基于重要性采样的直接偏好优化对于稳定的扩散训练 [PDF](https://arxiv.org/pdf/2505.21893), [HTML](https://arxiv.org/abs/2505.21893)
### Authors
Xiaomeng Yang,Zhiyu Tan,Junyan Wang,Zhijian Zhou,Hao Li
### Background
偏好学习已成为调整生成模型与人类期望的一种核心技术。最近，偏好学习方法被应用于扩散模型，如Direct Preference Optimization (DPO)。然而，现有的方法如Diffusion-DPO存在两个关键挑战：反向与正向扩散过程之间的不匹配导致的时间步长依赖的不稳定性，以及优化策略与数据收集策略之间的不匹配导致的离策性偏差。
### Innovation
为解决这些问题，首先提出了DPO-Ctextbackslash&M，通过剪裁和屏蔽不相关信息的时间步来提高稳定性，并部分减轻离策性偏差。在此基础上引入了SDPO（重要性采样的直接偏好优化），这是一种将重要性采样纳入优化目标的方法，旨在完全纠正离策性偏差，并在扩散过程中强调信息性的更新。实验结果表明，SDPO在CogVideoX-2B、CogVideoX-5B和Wan2.1-1.3B上优于标准的Diffusion-DPO方法，以及SDPO在VBench评分、人类偏好对齐和训练鲁棒性方面表现更优。这项研究强调了时间步长感知、分布修正优化在基于扩散的偏好学习中的重要性。
### Conclusion
实验表明，SDPO在CogVideoX-2B、CogVideoX-5B和Wan2.1-1.3B上的表现优于标准的Diffusion-DPO方法，并且SDPO在VBench评分、人类偏好对齐和训练鲁棒性方面表现更优。这些结果强调了时间步长感知、分布修正优化在基于扩散的偏好学习中的重要性。
## 1407. `cs.LG` - Caterpillar GNN: 使用高效聚合取代消息传递 [PDF](https://arxiv.org/pdf/2506.06784), [HTML](https://arxiv.org/abs/2506.06784)
### Authors
Marek Černý
### Background
消息传递图神经网络（MPGNNs）在现代图学习中占据主导地位。典型的改进方法是通过丰富基于邻接矩阵的聚合来增强表达能力。相反，本文介绍了一种有效的基于路径共现矩阵的聚合方法，这些矩阵故意在保持强表达能力和结构诱导偏见之间做出权衡。这种方法允许在经典消息传递和基于路径的简单方法之间无缝扩展。
### Innovation
提出了Caterpillar GNN，通过路径共现矩阵的高效聚合，为图级别聚合提供了一种稳健的方法，特别适用于挑战MPGNNs的基准。实验表明，在真实世界数据集上，Caterpillar GNNs实现了可比的预测性能，同时显著减少了计算图中隐藏层的节点数量。
### Conclusion
通过研究级分类器的同构计数，我们细致地刻画了每一步的表达能力。实验验证了Caterpillar GNNs在处理专门设计的挑战性基准时的有效性，并且在保持性能的同时减少了计算图中隐藏层节点的数量。
## 1408. `cs.LG` - AMPED: 自适应多目标投影用于探索与技能多样性平衡 [PDF](https://arxiv.org/pdf/2506.05980), [HTML](https://arxiv.org/abs/2506.05980)
### Authors
Geonwoo Cho,Jaemoon Lee,Jaegyun Im,Subi Lee,Jihwan Lee,Sundong Kim
### Background
在稀疏奖励环境中，技能基于强化学习（SBRL）能够实现快速适应。有效的技能学习需要同时最大化探索和技能多样性。但现有方法在同时优化这两个冲突目标时常常遇到挑战。
### Innovation
提出了一个新的方法，自适应多目标投影用于平衡探索与技能多样化（AMPED）。该方法在预训练阶段通过梯度手术投影平衡探索和多样性梯度，在微调阶段通过技能选择器利用学习到的多样性，选择适合下游任务的技能。
### Conclusion
AMPED 在各种基准测试中实现了超过 SBRL 基线的表现。通过彻底的消融研究，表明每个组件都对性能有所贡献，并证明了更大的技能多样性在贪婪技能选择的情况下可以减少微调的数据复杂度。这些结果强调了明确平衡探索与多样性的关键性，并展示了 AMPED 在促进鲁棒且可泛化的技能学习方面的有效性。
## 1409. `cs.LG` - 模型保护自适应舍入 [PDF](https://arxiv.org/pdf/2505.22988), [HTML](https://arxiv.org/abs/2505.22988)
### Authors
Albert Tseng,Zhaofeng Sun,Christopher De Sa
### Background
量化的目标是生成一个压缩模型，其输出分布尽可能接近原始模型。大多数量化算法通过最小化每层的激活误差来近似端到端误差，但这种做法忽视了后续层的影响，因此不是一个好的近似。尽管如此，这些算法都能在其目标上取得良好的效果。
### Innovation
该论文提出了Yet Another Quantization Algorithm (YAQA)，一种自适应舍入算法，它直接考虑网络输出的误差。YAQA给出了量化算法的第一个端到端误差界。通过分析自适应舍入算法的Hessian近似结构，建立了误差收敛时间和近似Hessian误差间的联系，并通过余弦相似度给出了误差的上界，采用Kronecker因子近似方法取得接近最优的Hessian图。实验表明YAQA比GPTQ/LDLQ算法具有更好的效果，减少了约30%的误差，甚至超越了量化感知训练，从而在下游任务中实现了最先进的性能，而没有任何推理开销。
### Conclusion
该论文通过理论结果和实验验证了Yaqa的有效性，强调该算法提升了量化模型的性能和准确性，并且不会增加推理成本。
## 1410. `cs.LG` - 利用块坐标下降法实现成本效益的LLM模型训练 [PDF](https://arxiv.org/pdf/2506.12037), [HTML](https://arxiv.org/abs/2506.12037)
### Authors
Zeyu Liu,Yan Li,Yunquan Zhang,Boyang Zhang,Guoyong Jiang,Xin Zhang,Limin Xiao,Weifeng Zhang,Daning Cheng
### Background
训练大型语言模型通常需要大量的GPU内存和巨大的财务投资，这对许多小型到中型团队来说是一个障碍。
### Innovation
本文提出了一种基于块坐标下降（BCD）的全参数预训练和微调框架，并结合工程优化，使大型模型能在成本效益的RTX 4090、A100和A800 GPU集群上进行高效训练。与标准全参数训练相比，在相同的硬件配置下，BCD将7B模型的训练成本降低到A100/A800上33%，RTX 4090上仅2.6%。此外，BCD使得原本只能在A100集群上训练的大模型可以在RTX 4090上训练，而不影响性能。BCD在大多数情况下能达到与全参数训练和微调方法相当或更好的准确性，同时减少GPU消耗并提高硬件利用率。
### Conclusion
该框架显著降低了训练大型语言模型的成本，同时保持或提高了模型的性能，扩大了这些先进技术的可用性。
## 1411. `cs.LG` - 在线对抗扰动多智能体控制 [PDF](https://arxiv.org/pdf/2506.18814), [HTML](https://arxiv.org/abs/2506.18814)
### Authors
Anas Barakat,John Lazarsfeld,Georgios Piliouras,Antonios Varvitsiotis
### Background
在线多智能体控制问题在诸如自主机器人、经济学和能源系统等领域普遍存在。这些场景中对扰动的鲁棒性至关重要。以往的多智能体控制研究通常假设动态系统是无噪声或随机扰动的，而本研究关注在存在上级扰动的在线环境中，每个智能体都试图通过当地策略更新实现自身的最优控制。
### Innovation
本研究提出了在线渐变基于控制方法和局部策略更新，在两个反馈模型下分析了多智能体线性动态系统在对抗性扰动下的鲁棒性。通过证明每个智能体的遗憾下界，并在智能体目标一致时推导出时变潜力博弈的平衡追踪保证，从而填补了在线控制与在线博弈学习之间的空白，为动态连续状态环境下的个体和集体性能提供了稳健的保证。
### Conclusion
本研究的工作迈出了将在线控制与在线博弈学习相结合的重要一步，在动态连续状态环境中确立了个体和集体的稳健性能保证。
## 1412. `cs.LG` - 数据感知张量网络结构搜索 [PDF](https://arxiv.org/pdf/2505.23537), [HTML](https://arxiv.org/abs/2505.23537)
### Authors
Giorgos Iacovides,Wuyang Zhou,Chao Li,Qibin Zhao,Danilo Mandic
### Background
张量网络（TNs）能够提供高效表示高维数据的方法，但确定最优张量网络结构——张量网络结构搜索（TN-SS）问题仍然具有挑战性。当前最先进的算法将TN-SS视为纯数值优化问题，需要大量的函数评估，这在实际应用中是不可行的。此外，现有方法忽视了在实际张量数据中固有的有价值的专业领域信息，并且缺乏对所识别出的张量网络结构的透明性。
### Innovation
本文提出了一种新型的TN-SS框架，称为tnLLM，它结合了数据的专业领域信息，并利用大型语言模型（LLMs）的推理能力，直接预测合适的张量网络结构。该框架包含了一种专业领域感知的提示管道，指示LLMs基于张量模式之间的实际世界关系来推断合适的张量网络结构。通过这种方式，该方法不仅可以迭代优化目标函数，还可以生成专业领域感知的解释。实验结果表明，tnLLM在函数评估远少于最先进的算法的情况下，达到了可比的TN-SS目标函数值。此外，我们展示了启用大型语言模型的专业领域信息可以用于在基于采样的最先进的方法的搜索空间中找到良好初始化，从而加速其收敛，同时保持理论性能保证。
### Conclusion
该研究提出了一种新型的tnLLM框架，通过结合专业领域信息和利用大型语言模型的推理能力，有效地解决了张量网络结构搜索问题。实验结果验证了这种方法的有效性和优越性，结果显示它可以减少函数评估次数，并维持高性能。
## 1413. `cs.LG` - 多图上的超越简单图：基于神经网络的多目标路由 [PDF](https://arxiv.org/pdf/2506.22095), [HTML](https://arxiv.org/abs/2506.22095)
### Authors
Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
基于学习的路由方法近年来在单目标和多目标背景下获得了广泛关注。然而，现有的方法不适用于处理包含节点对之间具有不同属性的多条边的多图，这种情况在现实世界中很常见。
### Innovation
该论文提出两种基于图形神经网络的方法来解决多目标路由问题。第一种方法直接在多图上自回归选择边直至完成行程，第二种方法先通过学习策略简化多图，再在简化后的简单图上进行自回归路由。
### Conclusion
作者通过广泛的实验评估了这两种模型与强大的启发式算法和神经基线的性能，展示了其竞争力。
## 1414. `cs.LG` - 有效类别遗忘所需的输出分布重新加权分析 [PDF](https://arxiv.org/pdf/2506.20893), [HTML](https://arxiv.org/abs/2506.20893)
### Authors
Ali Ebrahimpour-Boroojeny,Yian Wang,Hari Sundaram
### Background
现有的类别遗忘评估方法中存在一个显著的不足：忽视了类别的几何结构可能导致隐私泄露。本文通过引入基于最近邻的成员推断攻击（MIA-NN），展示了现有遗忘方法容易受到这种隐私泄露的影响。现有方法对不同数据集都存在安全漏洞。
### Innovation
提出了一个简单而有效的解决方案来缓解这一问题。具体而言，本文提出了一种重新加权分布（TRW）方法，通过重新加权目标模型的分布来构造遗忘类输入的分布，这种方法旨在逼近模型因从头开始重新训练而产生的剩余类别的分布。这种加权方法使模型在遗忘特定类别后更好地维护其余类别的数据分布，从而减少了隐私泄露的风险。
### Conclusion
实验表明，TRW方法在CIFAR-10等多个基准测试中比现有遗忘方法在先前的遗忘度量标准上更具优势或相当，特别是在针对MIA-NN和U-LiRA评估标准时，相对于最先进的方法，分别减小了19%和46%的差距。
## 1415. `cs.LG` - 使用大规模健康护理基础模型进行癌症筛查：CATCH-FM [PDF](https://arxiv.org/pdf/2506.00209), [HTML](https://arxiv.org/abs/2506.00209)
### Authors
Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong
### Background
早期癌症筛查能够挽救生命，但现有技术需要昂贵且侵入性的医疗程序，这些程序在全世界范围内并不普遍。因此，存在太多原本可以挽救的生命被丢失。本研究旨在提出CATCH-FM，一种仅基于历史医疗记录对高风险患者进行癌前筛查的方法。通过对数百万电子健康记录（EHR），我们建立了EHR基础模型的规模定律，并训练了至多包含24亿参数的最优计算基础模型，然后在由临床医生整理的癌症风险预测组中进行微调。
### Innovation
提出了CATCH-FM（CATch Cancer early with Healthcare Foundation Models），一种仅基于历史医疗记录识别高风险患者的癌前筛查方法。通过大规模电子健康记录（EHR），研究建立了EHR基础模型的规模定律，使用至多24亿参数的最优计算基础模型，并在其上进行微调，实现了在多种患者分布下表现优异的癌症风险预测效果。
### Conclusion
在包含30,000名患者的回顾性评估中，CATCH-FM达到了50%的敏感性，精确度为99%，并优于基于特征的树模型以及通用和医疗LLM，最多高出20%的AUPRC。尽管存在显著的种族、医疗服务系统和EHR编码差异，但在几近零训练样本的EHRSHOT排行榜上，CATCH-FM仍能实现最先进的胰腺癌风险预测，并优于使用现场患者数据进行预训练的EHR基础模型。分析结果展示了CATCH-FM在不同患者群体中的稳健性、ICD代码空间的运营优势及其对非平凡癌症风险因素的捕捉能力。我们的代码将开源。
## 1416. `cs.LG` - Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting [PDF](https://arxiv.org/pdf/2505.23863), [HTML](https://arxiv.org/abs/2505.23863)
### Authors
Chang Liu,Bohao Zhao,Jingtao Ding,Huandong Wang,Yong Li
### Background
长期预测混沌系统仍然是一个基本挑战，因为混沌系统的固有初始条件敏感性和奇异吸引子的复杂几何结构。传统方法，如蓄水池计算，通常需要长时间连续动力学行为的训练数据来全面捕捉系统的动力学。更先进的深度序列模型可以在训练数据中捕捉过渡动力学，但往往难以在长期预测中保持预测稳定性和动态一致性。因此，迫切需要一种结合物理原理的方法来更好地预测混沌系统的长期行为，尤其是基于短期历史观测数据.
### Innovation
提出了一种名为PhyxMamba的框架，它结合了基于Mamba的状态空间模型和物理信息的原则，利用短期历史观测数据预测混沌系统的长期行为。该框架首先通过时间延迟嵌入重构吸引子流形以提取全局动力学特征，然后引入生成训练方案，使Mamba能够复制物理过程。为了进一步增强预测准确性并保留关键统计特性，引入了多板块预测和吸引子几何正则化。在模拟和实际混沌系统上的广泛实验表明，PhyxMamba在长期预测中的预报精度更高，并能忠实捕捉关键统计特性。
### Conclusion
PhyxMamba框架通过结合Mamba模型和物理信息的原则，在预测混沌系统长期行为方面取得了显著成果。通过重构吸引子流形和引入生成训练方案，该框架不仅提高了长期预测的准确性，还保留了系统的关键统计属性。实验结果证明了该方法的有效性，表明结合物理信息对混沌系统长期预测具有重要作用。
## 1417. `cs.LG` - Sign-SGD 是多节点到单节点学习的金门桥：基于无参优化的巨大提升 [PDF](https://arxiv.org/pdf/2506.03725), [HTML](https://arxiv.org/abs/2506.03725)
### Authors
Daniil Medyakov,Sergey Stanko,Gleb Molodtsov,Philip Zmushko,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov
### Background
最近，大型语言模型在多个学科取得了重大突破，但训练它们需要极其庞大的资源。尽管对于资源丰富的企业来说这仍然是一个挑战， Sign-SGD 成为一种流行的替代方案。它可以作为单节点训练中高效的方法，也可以作为一种分布式学习中的梯度压缩技术。然而，自动确定一个有效的步长是不可行的，因为这依赖于我们无法访问的数据集参数。
### Innovation
本文设计了几种单节点确定性的Sign-SGD变体，将这些方法扩展到实际场景中，包括随机单节点和多节点学习，以及包含动量的方法。通过这一系列的研究，提出了一种无参优化的方法，旨在提升多节点到单节点的学习效率。
### Conclusion
通过广泛的实验证明，我们的方法在真实机器学习问题上具有实际应用价值。
## 1418. `cs.LG` - SecP-Tuning: Efficient Privacy-Preserving Prompt Tuning for Large Language Models via MPC [PDF](https://arxiv.org/pdf/2506.15307), [HTML](https://arxiv.org/abs/2506.15307)
### Authors
Jinglong Luo,Zhuo Zhang,Yehong Zhang,Shiyu Liu,Ye Dong,Hui Wang,Yue Yu,Xun Zhou,Zenglin Xu
### Background
大型语言模型（LLMs）虽然在许多领域取得了革命性的进步，但在医疗和金融等隐私敏感领域中的应用仍然受限于严格的隐私要求导致的数据获取难度。现有的基于多方计算（MPC）的隐私保护机器学习方法可以提供模型参数和数据的理论隐私保证，但主要应用于模型推理阶段，因为微调过程中的反向传播、优化器和自我注意操作带来了显著的效率挑战。
### Innovation
SecP-Tuning首次提出了一种基于MPC的框架，用于高效且隐私保护的LLM提示调优。SecP-Tuning通过数据所有者-服务器交互模式引入了前向调优（FoT），从而去除了反向传播和优化过程中所需的隐私保护计算。此外，它还设计了一种高效的数据隐私保留随机特征注意机制（RFA），简化了基于softmax的自我注意操作，并绕过了MPC不兼容的非线性操作。
### Conclusion
实验结果表明，与完全参数监督微调（SFT）和基于梯度的提示调优相比，SecP-Tuning分别实现了大约12倍和16倍的端到端加速以及18倍和20倍的通信开销减少。此外，在五个少量示例任务中，SecP-Tuning的平均性能得分为82.45，优于SFT的79.90和基于提示的调优的73.73。SecP-Tuning的“黑盒/API风格”的隐私保护调优范式还有效避免了梯度/参数传输导致的记忆泄露风险。
## 1419. `cs.LG` - 理想磁流体静力学问题的人工神经网络求解器 [PDF](https://arxiv.org/pdf/2507.03119), [HTML](https://arxiv.org/abs/2507.03119)
### Authors
Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff
### Background
本文探讨了一种创新的方法来计算三维磁流体动力学（MHD）平衡状态，方法是通过人工神经网络参数化傅里叶模式，并将其与传统求解器计算的平衡状态进行比较。通常，计算MHD平衡需要使用复杂的数学方法和大量的计算资源，而这篇文章提出的方法试图通过简化形式的人工神经网络来减少计算成本。作者利用第一阶优化器在实空间中最小化整个体积的全非线性全局力残差。
### Innovation
该研究提出了一种使用人工神经网络参数化傅里叶模式的新方法来计算三维MHD平衡，并通过传统的求解器进行了比较。这种方法的计算成本与现有的代码相近，当进一步增加计算资源时，人工神经网络能够达到更低的残差最小值，确立了力残差的新下限。研究人员使用了相对简单的神经网络，并预计这种方法不仅适用于单个平衡状态的求解，也可以用于构建适用于连续分布平衡状态的神经网络模型。
### Conclusion
研究结果表明，人工神经网络可以作为一种有效的工具来解决MHD平衡问题，尤其是在计算资源受限的情况下。对于解决单个平衡状态和覆盖整个连续分布的平衡状态，神经网络方法显示出显著的潜力。随着神经网络复杂性的进一步优化，这种方法预计会有更大的改进空间。
## 1420. `cs.LG` - RL-Obfuscation：语言模型能否学会规避潜在空间检测器？ [PDF](https://arxiv.org/pdf/2506.14261), [HTML](https://arxiv.org/abs/2506.14261)
### Authors
Rohan Gupta,Erik Jenner
### Background
潜在空间检测器旨在通过利用大型语言模型的内部表示，而不是依赖于黑盒输出来检测不良行为。这些方法已显示出识别欺骗和不安全完成等行为的潜力。然而，这些检测器本身可能会成为训练信号，通过使用部署中发现的有问题样本重新训练模型。这引出了一个重要问题：模型能否学会规避这些检测器？
### Innovation
提出了RL-Obfuscation方法，该方法通过强化学习对语言模型进行微调，使其能够规避潜在空间检测器而不改变其黑盒行为。研究应用了具有7B到14B参数的多种语言模型，并评估了它们在一系列检测器上的规避成功率。研究发现，字符级检测器对这种攻击极为脆弱，而整体检测器，如最大池化或基于注意力的探针，则表现出较好的鲁棒性。此外，对单一固定检测器的规避可以推广到规避其他未见过的检测器。研究还发现，模型可以被训练成在特定输入下有条件地绕过潜在空间检测器。最终研究发现模型能够学会重新利用token以具有不同的内部表示。
### Conclusion
针对潜在空间检测器的最成功攻击发生在字符级别，但整体方法相对稳健。模型可以通过学习重新使用token，以具有不同的内部表示来规避这些检测器。在特定输入下，模型可以有条件地绕过潜在空间检测器。
## 1421. `cs.LG` - OrthoGrad 改善了神经网络的校准 [PDF](https://arxiv.org/pdf/2506.04487), [HTML](https://arxiv.org/abs/2506.04487)
### Authors
C. Evans Hedges
### Background
在关键不确定性应用场景中，标准优化器容易表现出过度自信的问题。$bot$Grad 是一种几何感知的梯度优化修改，它通过限制梯度下降方向来解决这个问题，而不改变架构，从而使优化过程更为有效。在CIFAR-10数据集上使用10%的标记数据进行实验，$bot$Grad在准确性和多重衡量指标上表现出与SGD相当的结果，尤其是测试损失、预测熵和可信度度量方面有显著改进（在p=0.05和p=0.001的统计显著性水平上）。这些效果在不同程度的损坏和架构下表现出一致的趋势。$bot$Grad具有优化器无关的优势，具备最小的开销，并且兼容后处理校准技术。理论分析还表明，这种正交化可以限制损失减少的路径，从而防止自信膨胀并鼓励决策边界的改进。这表明，几何干预可以在低成本下提升预测不确定性估计。
### Innovation
$bot$Grad 是一种几何感知的优化修改，通过禁止梯度更新与权重向量之间的正交性来限制梯度下降方向，从而解决标准优化器在关键不确定性应用场景中的过度自信问题。$bot$Grad 不需要改变架构，并且具有优化器无关性、低开销和与后处理校准技术的兼容性。理论研究显示了正交化如何限制损失减少的路径，以防止自信膨胀并促进决策边界的改进。
### Conclusion
我们发现，几何干预优化可以在低计算成本下提升预测不确定性估计，$bot$Grad 通过避免自信膨胀并有助于决策边界的改进来改善神经网络的校准。该研究揭示了$bot$Grad在CIFAR-10数据集上的实验结果，在10%标记数据的情况下，$bot$Grad在测试损失、预测熵和可信度度量上优于SGD（p=0.05和p=0.001）且效果具有性。$?bot$Grad不仅改进了优化轨迹，还保持了与现有校准技术的兼容性，显示出良好的应用前景。
## 1422. `cs.LG` - 通过机器学习实现下一代方程无损多尺度众人群体动力学建模 [PDF](https://arxiv.org/pdf/2508.03926), [HTML](https://arxiv.org/abs/2508.03926)
### Authors
Hector Vargas Alvarez,Dimitrios G. Patsatzis,Lucia Russo,Ioannis Kevrekidis,Constantinos Siettos
### Background
微观建模和宏观建模之间在人群动力学建模中的建模尺度桥接构成了系统数值分析、优化和控制的重要开放挑战。现有研究尚未能够有效地将微观详细数据与宏观简化表示联系起来。
### Innovation
提出了一种结合流形学习和机器学习的方法，从高保真度个体基模仿真中，在隐空间中学习人群动力学的离散演算子。这种方法基于先前关于下一代方程无模建模算法的研究工作，并包含了四个阶段：连续宏观场从离散微观数据中提取、基于流形学习的宏空间到隐空间映射、在隐空间中学习降阶模型，以及在高维空间中重建人群动力学。此外，Linear MVAR模型在预测准确性方面超过了非线性LSTMs，同时具有更低的复杂性和更好的可解释性。
### Conclusion
该方法展示了高精度、稳健性和泛化能力，允许快速准确地从个体基模模拟中建模人群动力学。
## 1423. `cs.LG` - 在潜在空间中的飞机航迹数据扩充 [PDF](https://arxiv.org/pdf/2506.07585), [HTML](https://arxiv.org/abs/2506.07585)
### Authors
Seokbin Yoon,Keumjin Lee
### Background
飞机航迹建模在空中交通管理中起着关键作用，并且对于冲突检测和着陆时间预测等下游任务非常重要。为了开发更可靠的飞机航迹模型，需要通过添加合成生成的航迹数据来扩充航迹数据集，确保数据集的充分性和平衡性。为此，本文探讨了一种名为ATRADA的新型框架，用于飞机航迹数据集的扩充。ATRADA框架通过Transformer编码器学习原始航迹数据集中的潜在模式，并将每个数据点转换为学习到的潜在空间中的上下文向量。随后，使用主成分分析（PCA）将转换后的数据集投影到低维空间，并应用高斯混合模型（GMM）拟合数据点在低维空间中的概率分布。最后，从拟合好的GMM中抽样，恢复样本的原始维度，并使用多层感知器（MLP）解码。多项实验结果表明，该框架能够有效地生成新的、高质量的合成飞机航迹数据，并将这些 Synthetic 数据与几种基线方法的结果进行比较。
### Innovation
本文提出的ATRADA框架是一种创新的方法，它利用Transformer编码器学习原始航迹数据集中的潜在模式，结合PCA降维和GMM拟合，最终生成高质量的合成航迹数据，解决了数据集扩充问题，大大提升了模型的鲁棒性和数据集的丰富性。
### Conclusion
本文提出的ATRADA框架有效地生成了新、高质量的合成飞机航迹数据，并通过实验验证了其效果。这种新颖的方法不仅提高了空中交通管理系统的性能，还为其他需要大量数据的领域提供了有效支持。
## 1424. `cs.LG` - 轻量化MSA设计推进蛋白质折叠 [PDF](https://arxiv.org/pdf/2507.07032), [HTML](https://arxiv.org/abs/2507.07032)
### Authors
Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Cesar de la Fuente-Nunez,Chunbin Gu,Ge Liu,Pheng-Ann Heng
### Background
蛋白质结构预测经常依赖于多序列比对（MSA），但对于低同源性和孤儿蛋白，MSA的表现不佳。
### Innovation
文章引入了PLAME，这是一种利用预训练蛋白质语言模型的进化嵌入来生成更好地支持下游折叠的MSA的轻量级设计框架。PLAME结合了保持一致性与覆盖潜在序列变化的保守性和多样性损失。此外，还在MSA选择策略和序列质量度量方面有所创新。
### Conclusion
在AlphaFold2的低同源性和孤儿蛋白基准测试中，PLAME在结构准确性方面达到了最先进的改进（如lDDT和TM-score），并与AlphaFold3配对时一直保持一致的改进。PLAME还能作为轻量级适配器，使ESMFold达到接近AlphaFold2级别的准确性，同时保持ESMFold的推理速度。这为缺乏强大进化邻居的蛋白质提供了快速且高质量的折叠路径。
## 1425. `cs.LG` - 基于Transformer的语言模型中潜在概念的分离 [PDF](https://arxiv.org/pdf/2506.16975), [HTML](https://arxiv.org/abs/2506.16975)
### Authors
Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy
### Background
在使用大型语言模型（LLMs）进行上下文学习（ICL）以解决新任务时，模型必须从示例中推断出潜在的概念。这引发了一个问题，即Transformer如何在其计算过程中表示潜在结构。本文通过几个控制任务，使用机制性可解释性研究此问题。实验表明，对于具有潜在离散概念的传递推理任务，模型能够成功地识别潜在概念并在步骤之间进行概念组合。此外，对于由潜在数值概念参数化的任务，研究发现模型表示空间中的低维子空间，其中几何结构清晰地反映了潜在的参数化。这些结果表明，即使在少量简化的示范条件下，小模型和大模型也能分离和利用它们在上下文中学到的潜在概念.
### Innovation
本文通过探索机制性可解释性来研究基于Transformer的语言模型如何代表潜在结构。实验重点在于展示了小型和大型模型能够通过少量压缩示例来分离和利用它们识别的潜在概念，即使对于带有多步推理任务和潜在数值参数化的任务也是如此。这些发现对理解Transformer理解和利用潜在概念的能力具有重要意义.
### Conclusion
小型和大型模型可以有效分离和利用通过少量简化的示范学到来的潜在概念，即使是在复杂和数值参数化的任务中也是如此。这一发现表明，基于Transformer的语言模型在处理新任务时能够充分利用潜在概念，展示出强大的表示能力和泛化能力。
## 1426. `cs.LG` - 相对熵路径策略优化 [PDF](https://arxiv.org/pdf/2507.11019), [HTML](https://arxiv.org/abs/2507.11019)
### Authors
Claas Voelcker,Axel Brunnbauer,Marcel Hussing,Michal Nauman,Pieter Abbeel,Eric Eaton,Radu Grosu,Amir-massoud Farahmand,Igor Gilitschenski
### Background
基于分数函数的方法，例如REINFORCE和PPO，在游戏和机器人领域表现出色，但它们高方差的问题往往影响训练稳定性。使用路径导数策略，即通过求导目标函数来计算导数，可以缓解这个问题。然而，这种方法需要具备准确的动作条件值函数，这在没有回放缓存的情况下使用离策略数据时极为困难。
### Innovation
提出了一种纯基于策略轨迹的在线策略算法REPPO，它可以训练Q值模型，并结合随机策略探索和受限更新以实现稳定训练，同时评估了稳定值函数学习的重要结构组件。REPPO集合了路径导数策略梯度的稳定性以及标准在线策略学习的简便性和内存占用小的优点。与最先进的方法相比，REPPO在两个标准GPU并行基准测试中表现出更强的实验性能，具有更高的样本效率、计算时间效率和超参数稳健性。
### Conclusion
REPPO是一种高效的在线策略算法，结合了路径策略梯度的稳定性与传统在线策略学习的简便性和低内存占用。与最先进的方法相比，REPPO在两个标准GPU并行基准测试中展现出优越的性能。
## 1427. `cs.LG` - 何时信任？个性化联邦学习中的自适应合作 [PDF](https://arxiv.org/pdf/2507.00259), [HTML](https://arxiv.org/abs/2507.00259)
### Authors
Amr Abourayya,Jens Kleesiek,Bharat Rao,Michael Kamp
### Background
联邦学习（FL）面临的数据异质性挑战，尤其是客户端不仅在分布上存在差异，还在单个示例的预测可靠性上存在差异。尽管个性化FL（PFL）旨在解决这一问题，但我们发现许多PFL方法未能超越局部训练和集中训练这两种基线方法。这表明只有在全局模型不足但客户端间的合作仍有价值的狭窄范围内才有意义的个性化。我们通过实验证明成功的两个关键因素是在合作中的自适应性和个体示例级别的细粒度信任。这些特性可以在联邦半监督学习中实现，其中客户端通过共享未标记数据集交换预测值。这种方法允许每个客户端在有益时与公共共识对齐，而在无益时忽略它，而不分享模型参数或原始数据。
### Innovation
我们提出了一种个性化协同训练方法FEDMOSAIC，其中客户端根据示例级别的协议和信心重权它们的损失和对伪标签的贡献。FEDMOSAIC在非IID设置中优于其他强FL和PFL基线，并在标准化假设下证明了收敛。此外，它还优于局部和集中训练，这表明在什么情况下联邦个性化可以有效，以及细粒度、信任感知的合作如何使得这种情况成为可能。
### Conclusion
FEDMOSAIC在不同类型的非IID场景中表现出色，并且在标准假设下证明了收敛性。相较其他基准，它还优于局部和集中训练。这些结果明确了联邦个性化在何时有效，并展示了细粒度、信任感知的合作如何使其得以实现。
## 1428. `cs.LG` - 跨域多通道差异变换器在异质EEG和EOG的睡眠阶段分类中的应用 [PDF](https://arxiv.org/pdf/2508.15215), [HTML](https://arxiv.org/abs/2508.15215)
### Authors
Benjamin Wei Hao Chin,Yuin Torng Yew,Haocheng Wu,Lanxin Liang,Chow Khuen Chan,Norita Mohd Zain,Siti Balqis Samdin,Sim Kuan Goh
### Background
睡眠阶段的分类对于评估睡眠质量和诊断睡眠障碍至关重要。然而，手动检查每个阶段的EEG特性耗时且容易出错。尽管机器学习和深度学习方法得到了积极开发，但由于EEG和EOG信号在不同临床配置下的非站定性和变异性，导致了泛化能力不足的问题。
### Innovation
本文提出了一种多通道差异变换器框架SleepDIFFormer，用于异质EEG-EOG表示学习。SleepDIFFormer采用多通道差异变换器架构（MDTA），用于处理原始EEG和EOG信号，并结合跨域对齐。该方法通过特征分布对齐实现域不变的EEG-EOG表示，并增强了对新域的泛化能力。实证研究显示，SleepDIFFormer在五种不同的睡眠阶段数据集上达到了最先进的性能，并通过消融研究进一步验证了差异性注意力权重的相关性。
### Conclusion
本文研究展示了通过域适应方法改进自动睡眠阶段分类的潜力，强调其在量化睡眠结构和检测干扰恢复睡眠的异常中的应用。源代码和检查点已公开。
## 1429. `cs.LG` - R-Stitch: 动态轨迹缝合用于高效推理 [PDF](https://arxiv.org/pdf/2507.17307), [HTML](https://arxiv.org/abs/2507.17307)
### Authors
Zhuokun Chen,Zeren Chen,Jiahao He,Lu Sheng,Mingkui Tan,Jianfei Cai,Bohan Zhuang
### Background
长序列推理对大语言模型（LLMs）的能力有很大的提升，但是需要很长的自回归路径，导致显著的推理成本。现有的加速策略要么通过早期停止或压缩缩短路径，要么采用小模型的投机解码。然而，当模型一致性较低时，投机解码提供有限的收益，并且严格遵守标记层级的一致性，忽略了当部分小模型正确时，它们可以产生更为简洁的原因说明，从而降低推理路径长度的观点。
### Innovation
提出了一种无需训练的混合解码框架R-Stitch，利用标记层级的熵作为不确定性的代理，执行逻辑任务分配：高熵标记有更高的错误概率，因此引导小语言模型（SLM）快速处理低熵标记，而不确定的标记则交给LLM。进一步地，R-Stitch+通过学习动态适应性的路由策略，可以根据实际需求自我调整标记预算。这种设计有效地降低了逐标记的解码复杂性并减少了生成的标记数量，显著加速了解码过程，同时保持了与全LLM解码相媲美的准确率。同时，它能够根据不同的计算预算动态调整效率-准确率权衡，而无需重新训练模型。
### Conclusion
该研究方法通过减少每个标记的解码复杂性和生成的标记数量，实现了显著的加速，但在准确率方面没有任何损失。具体而言，在不同的模型上，它分别实现了3.00倍、3.85倍和4.10倍的峰值加速，保持与全LLM解码相匹敌的准确率，并且能够根据不同的计算预算调整效率与准确率之间的折衷。
## 1430. `cs.LG` - 梯度提升与变换器的技巧和插件 [PDF](https://arxiv.org/pdf/2508.02924), [HTML](https://arxiv.org/abs/2508.02924)
### Authors
Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan
### Background
变换器架构在现代NLP中占据主导地位，但往往需要大量的计算资源和复杂的超参数调整。这些限制导致了性能改进的难度和成本增加。因此，为了减轻这些挑战，研究人员提出了BoostTransformer框架，该框架通过子网格令牌选择和重要性加权采样将提升原则融入变换器之中，直接将最小二乘提升目标融入变换器管道中，以实现更高效的训练和更好的性能。
### Innovation
BoostTransformer框架通过引入提升原则，特别是最小二乘提升目标，直接整合到变换器处理流程中，从而促进了更快速的收敛和更高的准确性。与标准变换器相比，该方法在多个细粒度文本分类基准测试中表现更优，同时将架构搜索开销降至最低。
### Conclusion
BoostTransformer通过结合变换器和提升技术，在多个细粒度文本分类基准测试中展示了更快速的收敛和更高的准确性，优于标准变换器，并且最小化了架构搜索开销。
## 1431. `cs.LG` - 固定权重Transformer中的嵌入式算法模拟 [PDF](https://arxiv.org/pdf/2508.17550), [HTML](https://arxiv.org/abs/2508.17550)
### Authors
Jerry Yao-Chieh Hu,Hude Liu,Jennifer Yuntong Zhang,Han Liu
### Background
本文探讨了使用固定权重的Transformer通过上下文提示来模拟广泛算法的可能性。Transformer模型在过去几年中取得了巨大成功，但其如何在特定任务上的性能很大程度上依赖于其潜在参数。文章提出了优化和固定权重Transformer模型的新方法，并借助上下文提示实现算法模拟。
### Innovation
本文通过证明，通过固定权重的Transformer可以在上下文提示下模拟广泛算法。具体来说，作者区分了两种模式：任务特定模式下，任意连续函数可以通过一个单一全局便携式softmax注意力层精确地模拟特定形式；而提示可编程模式下证明了泛在性，即单层固定权重的softmax注意力模块可以通过仅调整提示来模拟所有任务特定的算法。这项工作的关键在于通过构建使用算法参数编码的提示，创建token表示的清晰点积差距，从而引导softmax注意力层进行预期计算。
### Conclusion
本文发现构建了上下文学习与算法模拟之间的直接联系，并展现了大型Transformer作为一种算法库的功能，提示可编程实现算法交换的机制。这些发现揭示了像GPT这样的基础模型通过提示直接切换算法的可能性，并在其现代Transformer架构中确立了算法泛在性。
## 1432. `cs.LG` - SpectrumWorld: 光谱领域的人工智能基础 [PDF](https://arxiv.org/pdf/2508.01188), [HTML](https://arxiv.org/abs/2508.01188)
### Authors
Zhuo Yang,Jiaqing Xie,Shuaike Shen,Daolang Wang,Yeyun Chen,Ben Gao,Shuzhou Sun,Biqing Qi,Dongzhan Zhou,Lei Bai,Linjiang Chen,Shufei Zhang,Qinying Gu,Jun Jiang,Tianfan Fu,Yuqiang Li
### Background
深度学习在光谱学领域的应用前景巨大，但该领域的研究和评估往往缺乏标准化的框架。由于缺乏统一的平台和标准，不同研究成果的比较和验证变得困难，阻碍了该领域的发展。因此，需要一个系统化的平台来促进光谱学中深度学习技术的研究和发展，提升研究效率和结果的可靠性。
### Innovation
SpectrumLab 提出了一个创新的统一平台，旨在系统化和加速光谱学中的深度学习研究。它包括三个核心组件：一个综合的 Python 库，包含数据处理和评估工具以及排行榜；一种创新的 SpectrumAnnotator 模块，可以从有限的种子数据中生成高质量的基准；以及 SpectrumBench，一个涵盖了14项光谱学任务和超过10种光谱类型的多层基准套件，所有光谱均从超过120万种化学物质中挑选。
### Conclusion
通过对 SpectrumBench 使用18种最先进的多模态大模型进行彻底的实证研究，揭示了当前方法的严重局限性。SpectrumLab 希望成为一个重要的基础，为未来基于深度学习的光谱学发展做出贡献。
## 1433. `cs.LG` - 向物理基础模型迈进 [PDF](https://arxiv.org/pdf/2509.13805), [HTML](https://arxiv.org/abs/2509.13805)
### Authors
Florian Wiesner,Matthias Wessling,Stephen Baek
### Background
基础模型通过“训练一次，随处部署”的范式革命了自然语言处理领域，使得单一预训练模型可以在不需要重新训练的情况下适应无数下游任务。当前的物理感知机器学习方法主要局限于单一且狭窄的领域，并且需要为每个新系统重新训练。这就导致获取物理基础模型（PFM）变得非常具有变革性，可以普及高保真模拟的访问、加速科学发现，并消除专门求解器开发的需要。
### Innovation
作者提出了通用物理变换器（GPhyT），这是一种在多样化模拟数据集上预训练的模型。GPhyT 的关键洞察是，变换器可以学会从上下文中推断出支配动力学，从而使单一模型能够在没有明确告知底层方程的情况下模拟流体-固体现象、冲击波、热传导对流以及多相动力学。GPhyT 实现了三个关键突破：（1）在多个物理领域中表现出优越的性能，比专门的架构高出29倍；（2）通过上下文学习实现完全未见过物理系统的零样本泛化；（3）通过50个时间步的滚动实现稳定长期预测。
### Conclusion
通过证明单一模型可以从数据中学习出可泛化的物理原理，这项工作为通用地实现通用物理基础模型铺平了道路，这可能将彻底改变计算科学和工程领域。
## 1434. `cs.LG` - 无形的束缚：为何RLVR可能或不可能超越其起源 [PDF](https://arxiv.org/pdf/2507.14843), [HTML](https://arxiv.org/abs/2507.14843)
### Authors
Fang Wu,Weihao Xuan,Ximing Lu,Mingjie Liu,Yi Dong,Zaid Harchaoui,Yejin Choi
### Background
最新的大规模语言模型（LLMs）展示了基于强化学习的值恢复（RLVR）方法在增强AI能力方面的潜力，特别是在解决复杂逻辑任务方面。然而，目前RLVR的实际应用还不清楚是真正扩展了模型的推理边界，还是主要提升了基模型已经知晓的高奖励输出，从而提高了精度。本文通过实证研究提供了对常见RLVR实践潜在局限性的新见解，探讨了在当前训练条件下，RLVR如何作为一种支持约束优化机制，限制了全新原创解决方案的发现。此外，研究还发现熵与奖励之间的权衡关系：尽管当前的RLVR方法能够可靠地提高精度，但它可能会逐渐缩小探索范围，可能会忽视那些正确但未充分代表的解决方案。广泛的实证实验验证了当使用更大样本预算时，虽然当前RLVR方法可以持续提高pass@1成绩，但实际支持的减少总体上超过了支持扩展，未能恢复基模型之前可访问的正确答案。有趣的是，研究还发现RLVR有时会增加token级别的熵，导致每次生成时的不确定性增加，但答案级别的熵却在下降，表明这些看似更不确定的路径最终收敛到更少数目的不同答案。
### Innovation
本文提供了对当前RLVR方法潜在局限性的实证研究，发现当前RLVR方法在提高精度的同时可能会逐渐缩小探索范围，可能忽视正确但未充分代表的解决方案，以及在token级别增加熵的同时答案级别的熵下降的权衡关系。实证研究表明，尽管当前RLVR方法可以持续提高pass@1成绩，但在更大样本预算下的实际支持减少抵消了支持扩展，并未能恢复基模型之前可访问的正确答案。这些发现揭示了当前RLVR方法在扩展推理边界的潜在限制，未来可能需要新的算法创新，如明确的探索机制或混合策略来逆转这种状况，种子未充分代表的解决方案区域的概率质量。
### Conclusion
研究揭示了当前RLVR方法在扩展推理边界的潜在限制。未来可能需要诸如明确的探索机制或混合策略等算法创新来克服这种局限，以实现在未充分代表的解决方案区域分配概率质量。
## 1435. `cs.LG` - 图是自然正则化：重访图表示学习中的向量量化 [PDF](https://arxiv.org/pdf/2508.06588), [HTML](https://arxiv.org/abs/2508.06588)
### Authors
Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang
### Background
向量量化（VQ）近年来被视为学习图结构数据离散表示的一种有前景的方法。然而，在图域中，代码本坍缩这一基础挑战尚未得到充分探讨，这严重限制了图表示的学习表达能力和泛化能力。本研究展示了当将VQ应用于图数据时，即使采取了视觉或语言领域提出的缓解策略，代码本坍缩现象也是一致存在的问题。为了理解为何图VQ特别容易产生坍缩，研究者进行了理论分析并识别出了两个关键因素：由图特征冗余和结构模式引起的早期分配不平衡，以及确定性VQ中的自我强化优化循环。
### Innovation
本文提出了名为RGVQ的新框架，将图拓扑结构和特征相似性作为显式正则化信号，以增强代码本的利用并促进标记的多样性。RGVQ通过Gumbel-Softmax重参数化引入软分配，确保所有码字接收梯度更新。此外，RGVQ还引入了一种结构感知对比正则化，以惩罚异类节点对之间的标记共分配。实验证明，RGVQ显著提高了代码本的利用，并且能够增强最先进的图VQ主干网络在多个下游任务中的性能，从而使图标记表示更具表现力和可迁移性。
### Conclusion
通过理论分析和实验证明，本文解决了VQ应用于图数据时的代码本坍缩问题，并提出了RGVQ框架，进一步提高了图VQ模型在多种下游任务上的表现，从而增强了图的表示能力。
## 1436. `cs.LG` - ERIS: 一种基于能量导向的特征解耦框架以提高分布外时间序列分类 [PDF](https://arxiv.org/pdf/2508.14134), [HTML](https://arxiv.org/abs/2508.14134)
### Authors
Xin Wu,Fei Teng,Ji Zhang,Xingwang Li,Yuxuan Liang
### Background
理想的时间序列分类（TSC）应该能够捕捉到不变的表示，但在处理分布外（OOD）数据时表现可靠的性能仍是一个主要障碍。这种障碍源于模型将领域特定和标签相关特征进行固有纠缠的方式，导致了虚假的相关性。虽然特征解耦试图解决这个问题，但现有的方法大多缺乏必要的语义方向，无法有效分离真正通用的特征。为了解决此问题，本研究提出了一种端到端的Energy-Regularized Information for Shift-Robustness（ERIS）框架，以实现导向且可靠的特征解耦。
### Innovation
ERIS框架引入了三种关键机制来实现有效的特征解耦：首先，引入一种基于能量引导的校准机制，为分离过程提供必要的语义引导，使模型能够自我校准；其次，通过权重级别的正交性策略，来确保领域特定和标签相关特征之间的结构性独立性，从而减少其相互干扰；最后，通过辅助的对抗泛化机制，注入结构化的扰动来增强鲁棒性。实验结果表明，ERIS显著超越了现有的最先进的基准模型，在多个基准上保持了顶级的性能排名，
### Conclusion
通过ERIS框架的端到端特征解耦策略，实现了在处理分布外数据时的稳定且鲁棒表现，验证了该方法的有效性和可靠性。
## 1437. `cs.LG` - RMT-KD: 基于随机矩阵理论因果知识蒸馏 [PDF](https://arxiv.org/pdf/2509.15724), [HTML](https://arxiv.org/abs/2509.15724)
### Authors
Davide Ettori,Nastaran Darabi,Sureshkumar Senthilkumar,Amit Ranjan Trivedi
### Background
大型深度学习模型如BERT和ResNet虽然在基准测试中表现出色，但由于其规模和计算需求高，部署在边缘设备上代价高昂。因此，减小模型参数数量，同时保持模型的准确性是提高部署可扩展性和效率的关键。
### Innovation
RMT-KD提出了一种利用随机矩阵理论进行知识蒸馏的压缩方法。该方法通过每层隐含表示的谱性质识别信息方向，在自蒸馏过程中进行因果缩减，从而维持模型稳定性并减少参数数量，避免了剪枝或启发式秩选择的方法。
### Conclusion
RMT-KD方法在GLUE、AG News和CIFAR-10数据集上实现了参数减少80%且准确性损失仅2%的效果，同时比原始模型快2.8倍的推断速度，并将近一半的能耗降低。这些结果证明了RMT-KD是网络蒸馏的一个数学基础方法。
## 1438. `cs.LG` - EigenTrack: 基于谱激活特征追踪的LLMs和VLMs幻觉和离分布检测 [PDF](https://arxiv.org/pdf/2509.15735), [HTML](https://arxiv.org/abs/2509.15735)
### Authors
Davide Ettori,Nastaran Darabi,Sina Tayebati,Ranganath Krishnan,Mahesh Subedar,Omesh Tickoo,Amit Ranjan Trivedi
### Background
大规模语言模型（LLMs）具有广泛的应用前景，但在面临幻觉和离分布（OOD）错误时仍然表现不佳。
### Innovation
EigenTrack 是一种解释性强的实时检测器，通过使用模型隐藏激活的谱几何特征（一种紧凑的全局模型动力学签名），它以流式方式传输诸如熵、特征值间隙和相对于随机基线的KL散度等协方差谱统计值到轻量级递归分类器中。EigenTrack 能够追踪代表结构的时间变化，这些变化在表面错误出现之前就会提示幻觉和OOD漂移。相比黑盒和灰盒方法，EigenTrack 只需要一次前向传递且无需重采样；相比现有白盒检测方法，EigenTrack 保留了时间上下文，聚合了全局信号，同时提供了可解释的准确率-延迟权衡。
### Conclusion
EigenTrack 能够在LLMs和VLMs中检测幻觉和离分布错误，同时保持解析性且具有速度优势。
## 1439. `cs.LG` - 基于自监督学习的图表示法在网络入侵检测中的应用 [PDF](https://arxiv.org/pdf/2509.16625), [HTML](https://arxiv.org/abs/2509.16625)
### Authors
Lorenzo Guerra,Thomas Chapuis,Guillaume Duc,Pavlo Mozharovskyi,Van-Tam Nguyen
### Background
网络流量中的入侵检测是一个具有挑战性的任务，尤其是当监督有限且攻击模式不断演变时。最近的研究利用图神经网络进行网络入侵检测，但这些研究往往将表示学习与异常检测分开，这限制了嵌入在识别攻击方面的应用。
### Innovation
本文提出了GraphIDS，一种自监督的入侵检测模型，通过masked autoencoder统一了表示学习和异常检测两个阶段。该模型中，诱导的图神经网络通过局部拓扑上下文嵌入每个流以捕捉传统的网络行为，基于Transformer的编码器-解码器重构这些嵌入，通过自注意力学习全局共现模式而无需显式位置信息。在推断过程中，通过异常高的重构误差来标记潜在的入侵。
### Conclusion
在不同的NetFlow基准测试上，GraphIDS获得了高达99.98%的PR-AUC和99.61%的宏F1分数，其性能优于基线5-25个百分点，确保了嵌入直接优化了下游任务，有利于识别恶意流量。
## 1440. `cs.LG` - TimeMosaic: 时空异质性指导下的自适应粒度片段和段内解码时间序列预测 [PDF](https://arxiv.org/pdf/2509.19406), [HTML](https://arxiv.org/abs/2509.19406)
### Authors
Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan
### Background
时序数据在金融、交通、气候和能源等领域中的多变量时间序列预测非常重要。现有的基于补丁的方法通常采用固定长度分割，忽视了局部时间动态的异质性和预测的解码异质性。这种设计在信息密集区域丢失细节，在稳定段引入冗余，并且无法捕捉短期和长期时间视角的独特复杂性。
### Innovation
我们提出了TimeMosaic，一种旨在解决时间异质性的预测框架。TimeMosaic采用自适应补丁嵌入方法，根据局部信息密度动态调整粒度，平衡动机重用与结构清晰性，同时保持时间连续性。此外，它引入了段内解码，将每个预测视角视为相关的子任务，适应特定视角的难度和信息需求，而不是应用单一的统一解码器。
### Conclusion
在基准数据集上的广泛评估表明，TimeMosaic在现有的方法上提供了持续的改进，并且，在包含321亿个观测的大型语料库上训练的模型性能与最先进的时序模型相当。
## 1441. `cs.LG` - DualNILM: 基于深度多任务学习的能源注入识别能效细分 [PDF](https://arxiv.org/pdf/2508.14600), [HTML](https://arxiv.org/abs/2508.14600)
### Authors
Xudong Wang,Guoming Tang,Junyu Xue,Srinivasan Keshav,Tongxin Li,Chris Ding
### Background
非侵入式负载监测（NILM）是一种成本效益高的方法，可在智能住宅和建筑应用中获得精细的电器级能源消耗数据。然而，随着离网（BTM）能源来源（如太阳能电池板和电池存储）的广泛采用，传统的仅依赖电表数据的NILM方法面临新的挑战。BTM来源注入的能源可能会混淆个体电器的功率签名，这显著降低了NILM的性能。为解决这一问题，本文提出了一种名为DualNILM的深度多任务学习框架，用于同时进行电器状态识别和注入能源识别。利用基于Transformer的架构整合序列到点和序列到序列的策略，DualNILM能够捕捉聚合电力消耗模式中的多尺度时间依赖关系，从而实现准确的电器状态识别和能源注入识别。
### Innovation
本文提出了一种名为DualNILM的深度多任务学习框架，采用基于Transformer的架构，融合了序列到点和序列到序列的策略，有效捕捉了多尺度时间依赖关系，实现了电器状态识别和能量注入识别的准确度提升。DualNILM在自我收集和合成的数据集上的广泛测试表明，其在双任务性能上显著优于传统的NILM方法。该工作突显了该框架在现代具有可再生能源渗透的能源系统中的鲁棒能效细分的潜力。
### Conclusion
DualNILM框架能够在现代具有可再生能源渗透的能源系统中提供稳健的能效细分，其性能优于传统方法。特别地，合成光伏增强的数据集带真实的注入仿真方法将在审稿通过后开源。
## 1442. `cs.LG` - 稀疏但错误：L0设置不正确会导致稀疏自编码器提取错误特征 [PDF](https://arxiv.org/pdf/2508.16560), [HTML](https://arxiv.org/abs/2508.16560)
### Authors
David Chanin,Adrià Garriga-Alonso
### Background
稀疏自编码器（SAEs）从大规模语言模型（LLM）的内部激活中提取特征，并且这些特征应与可解释的概念相对应。SAE的核心超参数是L0，即每个标记平均激活多少个SAE特征。现有研究通过稀疏性重建折线图来比较SAE算法，暗示L0是一个自由参数，其正确值仅影响重建效果，而没有单一的最优值。本文研究了L0对SAE的影响，发现如果L0设置不当，SAE将无法正确解缠LLM的基本特征。此外，研究者提出了一个代理指标来帮助指导找到给定训练分布下的正确L0值，该方法在玩具模型中有效，并与LLM SAE的最大稀疏性探针性能一致。研究发现，通常使用的大部分SAE的L0设置过低。因此，正确设置L0对于训练具有正确特征的SAE至关重要。
### Innovation
该研究揭示了L0设置对SAE性能的关键影响，提出了一个代理指标来帮助确定正确L0值的方法，并指出大多数常用SAE的L0设置过低，强调了正确设置L0的重要性以确保特征提取的准确性。
### Conclusion
要想确保稀疏自编码器能够正确地提取特征，L0必须被正确设置。当前大多数常用的方法中L0设置可能过低，因此需要正确选择L0以确保稀疏自编码器的有效性和准确性。
## 1443. `cs.LG` - 在状态空间模型中对归纳偏置进行对齐以实现高效泛化 [PDF](https://arxiv.org/pdf/2509.20789), [HTML](https://arxiv.org/abs/2509.20789)
### Authors
Qiyu Chen,Guozhang Chen
### Background
大型模型的成功主要归因于其标度法则，但是高质量数据的有限性为模型开发带来了挑战。未来模型开发的重要方向是数据效率，即如何在有限的数据下学习到更多的知识。现有的状态空间模型（SSMs）的基础性偏差是固定的，这在任务结构与模型偏差不匹配的情况下会显得不够高效。
### Innovation
本文提出了一种原理性的框架来解决上述问题。首先，通过SSM诱导的内核，详细的形式化并证明了线性时不变SSM的归纳偏置与模型的频率响应直接相关。随后，提出了任务依赖的初始化（TDI）方法，即功率谱匹配，以在大规模训练前调整模型的归纳偏置与任务的频谱特性相匹配。实验结果表明TDI显著提高了模型的泛化能力和样本效率，特别是在数据稀缺的情况下。
### Conclusion
本文提供了一种理论和实际的工具来创建更高效的数据模型，这为可持续的模型扩展奠定了重要的基础。
## 1444. `cs.LG` - 高通量环境中的可扩展选项学习 [PDF](https://arxiv.org/pdf/2509.00338), [HTML](https://arxiv.org/abs/2509.00338)
### Authors
Mikael Henaff,Scott Fujimoto,Michael Matthews,Michael Rabbat
### Background
现有的层次强化学习方法虽然前景广阔，但在大规模训练中的应用尚未充分发挥其潜力。因此，本文旨在解决高通量环境中在线层次化RL的关键挑战，并提出了一种高性能的算法Scalable Option Learning (SOL)，该算法在吞吐量上比现有方法提高约35倍。此外，通过在复杂的NetHack游戏中使用300亿帧经验训练层次化代理，证明了SOL的性能和可扩展性，同时在MiniHack和Mujoco环境中也进行了验证，展示了其普适性特点。
### Innovation
本文提出了一种称为Scalable Option Learning (SOL)的层次化RL算法，该算法在高通量环境中实现了更高的吞吐量，比现有方法提高了约35倍。同时，该算法在复杂的NetHack游戏中表现优异，且在其他环境中表现出普适性。
### Conclusion
Scalable Option Learning (SOL)在高通量环境中展示了显著的性能提升，并且具有普适性，适用于复杂的 RL 任务。
## 1445. `cs.LG` - AI for Scientific Discovery is a Social Problem [PDF](https://arxiv.org/pdf/2509.06580), [HTML](https://arxiv.org/abs/2509.06580)
### Authors
Georgia Channing,Avijit Ghosh
### Background
尽管人工智能有望加速科学研究，但其带来的好处仍然分布不均。技术障碍如稀缺的数据、不统一的标准和计算资源访问不平等，确实存在，但本文作者认为，主要障碍在于社会和机构层面。不合理的叙事、对数据和基础设施贡献的低估、激励机制偏差以及学科专家和机器学习研究人员之间的差距，都限制了人工智能在科学中的影响。研究指出了四个相互关联的挑战：社区功能失调、研究优先级与上游需求不符、数据碎片化和基础设施不平等，这些问题的根本原因在于文化和组织实践。
### Innovation
提出了将人工智能应用于科学研究视为一个集体的社会项目，强调可持续合作和公平参与是技术进步的前提条件。呼吁通过技术创新、社区建设、跨学科教育、共享基准和可访问基础设施来解决这些问题。
### Conclusion
人工智能在科学研究中的应用受到社会和机构障碍的影响，需要跨学科的合作、公平的参与和适当的技术创新来克服这些障碍，最终实现可持续的发展。
## 1446. `cs.LG` - FORCE: 通过特征过度依赖修正实现可移植的视觉禁锢攻击 [PDF](https://arxiv.org/pdf/2509.21029), [HTML](https://arxiv.org/abs/2509.21029)
### Authors
Runqi Lin,Alasdair Paren,Suqin Yuan,Muyang Li,Philip Torr,Adel Bibi,Tongliang Liu
### Background
新的模态融合增强了多模态大型语言模型（MLLMs）的能力，但也引入了额外的安全漏洞。特别是，简单的视觉禁锢攻击比复杂的文本攻击更容易操控开源的MLLMs。然而，这些尚未充分发展的攻击在不同模型之间的跨模型迁移能力极为有限，无法可靠地识别闭源MLLMs中的漏洞。
### Innovation
该工作通过分析这些禁锢攻击的损失景观发现，生成的攻击通常位于高尖度区域，这些区域在传输过程中对轻微的参数变化高度敏感。基于此，提出了一个Feature Over-Reliance CorrEction（FORCE）方法，指导攻击探索更广泛的层特征可行区域，并根据其语义内容重新调整频率特征的影响。这种方法消除了对层和频谱特征的非普适性依赖，实现了视觉禁锢攻击可行区域的平整化，从而提高了跨模型的迁移能力。
### Conclusion
广泛的实验表明，我们的方法有效地支持了闭源MLLMs的视觉红队评估。
## 1447. `cs.LG` - 非聚合体晶体结构预测的挑战：为何需要几何和置换不变性损失 [PDF](https://arxiv.org/pdf/2509.00832), [HTML](https://arxiv.org/abs/2509.00832)
### Authors
Emmanuel Jehanno,Romain Menegaux,Julien Mairal,Sergei Grudinin
### Background
晶体结构预测是设计具有特定性能的材料的关键前提。然而，这仍然是材料设计和药物发现方面的挑战。尽管计算材料科学最近有所进步，但准确预测三维非聚合体晶体结构仍然难以获得。在分子组装问题中，一组相同的刚性分子通过组装形成晶体结构。在这种简化模型下，近期最先进的方法虽然采用了复杂的技巧，但潜在的学习目标仍然定义不够清晰。
### Innovation
本文提出了一个新的建模框架，引入了一个捕捉关键几何分子特性的损失函数，并确保在某集合$text{S}$上的置换不变性。实验结果表明，在这个框架下，简单的回归模型已经在COD-Cluster17基准测试上优于先前的方法，包括流动匹配技术。
### Conclusion
通过该框架，简单的回归模型已经优于先前的方法，即使是在COD-Cluster17基准测试上，这是计算材料科学领域的一个重要进展。
## 1448. `cs.LG` - 图随机特征用于可扩展的高斯过程 [PDF](https://arxiv.org/pdf/2509.03691), [HTML](https://arxiv.org/abs/2509.03691)
### Authors
Matthew Zhang,Jihao Andreas Lin,Krzysztof Choromanski,Adrian Weller,Richard E. Turner,Isaac Reid
### Background
本文研究了图随机特征（GRFs）在离散输入空间上可扩展的高斯过程中的应用。GRFs是最近引入的图节点核的随机估计器。文章证明了在温和假设下，使用GRFs进行贝叶斯推断的时间复杂度为$O(N^{3/2})$，而精确核为$O(N^3)$。加速了贝叶斯优化在包含超过$10^6$个节点的图上的处理，并且内存使用较少，同时保持了相当的竞争性能。这些结果展示了GRFs在这类问题中的有效性和潜在优势。
### Innovation
提出并证明了使用图随机特征（GRFs）来实现高斯过程在具有大规模离散输入的数据上的高效计算。相较于传统的精确核方法，GRFs能够在单个计算机芯片上对包含超过$10^6$个节点的图进行贝叶斯优化，同时保持高性能。这项研究为大规模图数据驱动的高斯过程贝叶斯推断提供了新的方法和技术。
### Conclusion
本文展示了图随机特征在适用于大规模图数据的高斯过程中的应用效果。通过证明GRFs能够在显著减少时间复杂度的同时保持高精度，本文为高斯过程在图数据上的广泛应用铺平了道路。未来的研究可以进一步探索GRFs在不同应用场景下的优化和扩展。
## 1449. `cs.LG` - 多视图超复数学习在乳腺癌筛查中的应用 [PDF](https://arxiv.org/pdf/2204.05798), [HTML](https://arxiv.org/abs/2204.05798)
### Authors
Eleonora Lopez,Eleonora Grassucci,Danilo Comminiello
### Background
放射科医生在进行乳腺X光检查解读时，会综合分析四张视图，因为在这些视图之间的关联对于准确诊断至关重要。最近的方法虽然使用了专门的融合模块来捕捉这些关联，但这些模块经常受到视图主导性、训练不稳定性和计算成本过高的限制。
### Innovation
我们提出了多视图超复数学习，这是一种基于参数化超复数神经网络（PHNNs）的多视图乳腺癌分类的新学习范式。通过超复数代数，我们的模型能够自然地捕捉到视图内的关系以及视图之间的关系。我们为此类检查提出了PHResNets，并针对效率和准确性提出了两种四视图架构：PHYBOnet和PHYSEnet。
### Conclusion
广泛的实验表明，我们的方法在多视图模型中始终优于最先进的模型，并且还可以在不同的放射学模态和任务中进行泛化，例如胸片中的疾病分类和多模态脑肿瘤分割。有关的全代码和预训练模型可以在this https URL 获取。
## 1450. `cs.LG` - Diffusion-Augmented Contrastive Learning: 一种用于生物信号表示的抗噪编码器 [PDF](https://arxiv.org/pdf/2509.20048), [HTML](https://arxiv.org/abs/2509.20048)
### Authors
Rami Zewail
### Background
学习生物信号的稳健表示往往受到设计有效数据方法的挑战，现有的方法难以捕捉生理数据中的复杂变化。背景信息强调了现有的方法在处理噪声和复杂变异性时的不足。
### Innovation
提出了一个新型混合框架——扩散增强对比学习（DACL），该框架结合了扩散模型和监督对比学习的概念。DACL框架基于一个由轻量级变异自编码器（VAE）训练而成的潜在空间进行操作，该VAE采用作者提出的散射变换（ST）特征。利用扩散前向过程作为合理的数据增强技术来生成多个噪声视图。然后使用监督对比目标训练一种类似U-Net的编码器，以学习平衡类别区分和对噪声的鲁棒性的表示。
### Conclusion
在PhysioNet 2017 ECG数据集上对这种方法进行了评估，实现了竞争性的AUROC（0.7815）。这项工作通过使用扩散过程本身驱动对比目标，开创了表示学习的新范式，生成了对噪声不变的嵌入，证明了强烈的类别可分性基础。
## 1451. `cs.LG` - 基于GPU温度模拟的车载深度学习框架测试方法 [PDF](https://arxiv.org/pdf/2509.15815), [HTML](https://arxiv.org/abs/2509.15815)
### Authors
Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen
### Background
深度学习模型在自动驾驶系统中起着关键作用，支持环境感知等功能。这些深度学习模型的部署依赖于车载深度学习框架，如Apollo的PaddleInference和AutoWare的TensorRT。然而，与将深度学习模型部署在云端不同，车载环境中极端的温度变化（-40°C至50°C）显著影响GPU温度，且计算过程中产生的热量进一步导致GPU温度升高。这些温度波动引起GPU频率动态调整，但现有的汽车深度学习框架并未考虑到这种温度引起的频率变化的影响。因此，在搭载温度变化的GPU上部署时，这些框架会遇到关键质量问题：计算密集型操作会遇到延迟或错误，高/混合精度操作会遭受精度错误，而时序操作会遇到同步问题。现有深度学习框架测试方法无法检测这些问题，因为它们忽略了温度对框架质量的影响。
### Innovation
我们提出了ThermalGuardian，这是首个针对温度变化环境下的汽车深度学习框架测试方法。ThermalGuardian通过针对温度敏感操作的模型变异规则生成测试输入模型，基于冷却定律模拟GPU温度波动，并根据实时GPU温度控制GPU频率。
### Conclusion
ThermalGuardian填补了现有深度学习框架测试方法的空白，能够检测温度变化环境下存在的关键质量问题，从而提高车载深度学习框架的稳定性和可靠性。
## 1452. `cs.LG` - Diffence: 使用扩散模型保护会员隐私 [PDF](https://arxiv.org/pdf/2312.04692), [HTML](https://arxiv.org/abs/2312.04692)
### Authors
Yuefeng Peng,Ali Naseh,Amir Houmansadr
### Background
尽管深度学习模型在性能上取得了显著的成就，但它们也容易受到成员推理攻击（MIAs）的侵害。尽管已经提出了各种防御措施，但在隐私与实用性的权衡中仍然有很大的改进空间。
### Innovation
本文提出了一个新的基于生成模型的防御框架——DIFFENCE，旨在在预推理阶段通过重新生成输入样本来消除成员与非成员输入之间的差异，从而抵抗MIAs。该防御机制仅作用于输入样本，而不需要修改目标模型的训练或推理阶段，因此可以与其他现有的防御机制相结合使用。经实验验证，该方法能够保留模型预测标签，不影响准确率，并且不会降低置信向量的有用性。通过广泛的实验，证明了DIFFENCE可以作为一种强大的即插即用防御机制，在不损害模型实用性的情况下增强会员隐私。
### Conclusion
实验证明，与未受保护的模型相比，在三个数据集上，DIFFENCE可以将MIA的准确性降低15.8%，攻击AUC降低14.0%。当与最先进的SELENA防御机制结合使用时，还可以进一步降低攻击准确性和攻击AUC。这些结果表明，即使在引入少量计算开销的情况下，通过结合DIFFENCE也能够获得隐私和实用性之间更好的平衡。
## 1453. `cs.LG` - （乐观）梯度下降在极小极大优化中的极限点 [PDF](https://arxiv.org/pdf/1807.03907), [HTML](https://arxiv.org/abs/1807.03907)
### Authors
Constantinos Daskalakis,Ioannis Panageas
### Background
研究动机源于优化、博弈论以及生成对抗网络的训练等领域，在极小极大问题中一阶方法的收敛性质受到了广泛的关注。尽管这些方法可能循环，但对其极限点尚未有充分的理解，尤其是当它们不收敛时。当这些方法确实收敛时，它们会收敛到局部极小极大解吗？
### Innovation
本文对两种基本的一阶方法，即梯度下降/上升（GDA）和乐观梯度下降上升（OGDA）的极限点进行了表征。研究结果表明，在几乎所有的初始条件下，这些动态避免不稳定的关键点。对于小的学习率和轻微的假设，OGDA 稳定的关键点集是 GDA 稳定的关键点集的超集，而 GDA 稳定的关键点集又是一些局部极小极大解的超集。
### Conclusion
这些动态行为可以从动力系统的视角进行研究，这揭示了它们之间的联系。通过对这些动态的行为进行动力系统角度的理解，可以进一步优化极小极大优化问题的方法。
## 1454. `cs.LG` - Dendritic Resonate-and-Fire Neuron for Effective and Efficient Long Sequence Modeling [PDF](https://arxiv.org/pdf/2509.17186), [HTML](https://arxiv.org/abs/2509.17186)
### Authors
Dehao Zhang,Malu Zhang,Shuai Wang,Jingya Wang,Wenjie Wei,Zeyu Ma,Guoqing Wang,Yang Yang,Haizhou Li
### Background
随着序列长度的迅速增长，有效且高效地建模长序列的需求变得更为迫切。Resonate-and-Fire (RF) 神经元由于其固有的振荡膜动力学，能够有效地从输入信号中提取频率成分并将其编码为时空尖锋脉冲，使其非常适合长序列建模。然而，RF 神经元的有效记忆容量有限，在复杂时序任务上的能效和训练速度之间存在权衡。
### Innovation
受生物神经元树突结构的启发，我们提出了一个树突型Resonate-and-Fire (D-RF) 模型，该模型显式地包含一个多树突和细胞体的结构。每个树突分支利用RF神经元的固有振荡动力学编码特定的频率范围，从而实现全面的频率表示。我们还在细胞体结构中引入了一种自适应阈值机制，基于历史尖锋活动调整阈值，减少冗余尖锋脉冲，同时在长序列任务训练过程中保持高效率。实验结果表明，我们提出的方法在训练效率和计算效率方面都具有显著优势，同时保持了较高的准确性，确保了稀疏尖锋脉冲。
### Conclusion
我们的方法对于边缘平台上有效的和高效的长序列建模具有潜在的有效性和效率，通过维护存算协同优化，实现稀疏尖锋脉冲的大幅度减少，而不牺牲计算效率。
## 1455. `cs.LG` - DoDo-Code：基于Levenshtein距离嵌入的高效4-元插入、删除、替换信道纠错码 [PDF](https://arxiv.org/pdf/2312.12717), [HTML](https://arxiv.org/abs/2312.12717)
### Authors
Alan J.X. Guo,Sihan Sun,Xiang Wei,Mengyi Wei,Xin Chen
### Background
随着新型存储和通信方法的出现，插入、删除和替换（IDS）信道得到了广泛关注。然而，关于IDS信道及其关联的Levenshtein距离的研究仍有很多未解之谜，使得发明新型的IDS纠错码成为一项艰巨的任务。此外，当前的研究集中在单个IDS纠错码的设计上，未能满足需要纠正多个错误的应用需求。现有的解决方案通常是缩短编码词以减少多个错误发生的概率，但这会导致现有编码方案的代码率在短编码长度下表现不佳，从而降低了整体的存储密度。
### Innovation
本文提出了一种通过深度Levenshtein距离嵌入设计高代码率单错误插入、删除和替换（IDS）纠错码的新方法。该方法使用深度学习模型将序列映射到嵌入向量，以保持原始序列之间的Levenshtein距离。嵌入空间被用作复杂Levenshtein域的代理，在此空间中开发了编码词搜索和段纠错算法。该方法克服了传统编码设计中的数学挑战，并产生了优于现有的组合解决方案的代码率，特别适用于设计短编码长度的编码。
### Conclusion
本文提出了一种基于深度Levenshtein距离嵌入的设计高代码率单IDS纠错码的新方法，该方法能有效地克服现有的数学挑战，并在设计短编码长度时表现出更优的性能。
## 1456. `cs.LG` - Fourier神经算子的离散误差 [PDF](https://arxiv.org/pdf/2405.02221), [HTML](https://arxiv.org/abs/2405.02221)
### Authors
Samuel Lanthaler,Andrew M. Stuart,Margaret Trautner
### Background
Fourier神经算子（FNO）是一种用于函数空间间映射逼近的机器学习变体。尽管从定义上看，FNO是连续空间中的对象，他们在连续空间中执行卷积运算，但在实践中它们通过网格上的计算实现，这依赖于快速傅里叶变换（FFT）。这种实践上的离散对象与连续定义之间的差异导致了另一种不可忽视的模型误差来源。本研究旨在探讨这一离散误差，并以输入正则性为函数的网格分辨率获得代数收敛速率。
### Innovation
研究首次专门分析了Fourier神经算子的离散误差，并以输入正则性为函数的研究了其在网格分辨率上的代数收敛速率。此外，提出了一种算法，该算法利用分解模型误差和离散误差的机会来优化计算训练时间。
### Conclusion
研究通过理论分析和数值实验验证了离散误差理论，并描述了模型稳定性。提出的方法不仅提高了计算效率，还提供了对模型误差和离散误差的洞察，为实际应用中的优化提供了理论基础。
## 1457. `cs.LG` - QECO：基于深度强化学习的移动边缘计算中注重用户体验的计算任务卸载算法 [PDF](https://arxiv.org/pdf/2311.02525), [HTML](https://arxiv.org/abs/2311.02525)
### Authors
Iman Rahmaty,Hamed Shah-Mansouri,Ali Movaghar
### Background
在移动边缘计算（MEC）领域，高效的计算任务卸载对于保证用户的服务质量（QoE）至关重要。在动态且充满不确定性的移动环境中，保持高质量的服务成为首要挑战。本研究聚焦于MEC系统中的计算任务卸载问题，该问题不仅受严格的任务处理期限和能量限制的影响，还会对系统性能产生负面影响。本文将计算任务卸载问题形式化为马尔可夫决策过程（MDP），以最大化每个用户的长期QoE。
### Innovation
本文提出了一种基于深度强化学习（DRL）的分布式注重用户体验的计算任务卸载（QECO）算法，使得移动设备能够基于本地决策进行卸载，无需了解其他设备的决策。相比现有方法，QECO在提高任务完成率、降低任务延迟和能耗方面表现出显著优势。
### Conclusion
实验结果表明，与现有方法相比，QECO算法能够使任务完成率提高14.4%，同时降低任务延迟和能耗9.2%和6.3%。这些改进带来了平均QoE提升37.1%。这项改进得益于算法能够智能地预测用户行为和边缘计算服务器的工作负载，从而增强了用户体验。
## 1458. `cs.LG` - 基于变分框架的残差自适应在神经PDE求解器和算子学习中的应用 [PDF](https://arxiv.org/pdf/2509.14198), [HTML](https://arxiv.org/abs/2509.14198)
### Authors
Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,Jérôme Darbon,George Em Karniadakis
### Background
残差自适应策略在科学机器学习中广泛应用，但它们仍主要依赖于经验方法。研究通常没有系统地规定各种残差自适应方法的具体设计，尤其是在不同范数下的设计。本文通过结合凸变换，将这些方法形式化，为这些自适应策略提供了一个统一的变分框架。不同的变换对应于不同的目标函数：指数权重目标为均方误差的最小化，线性权重恢复为二次误差的最小化。通过此框架，自适应加权等同于选择优化原始目标的采样分布，从而将离散化选择直接与误差指标联系起来。
### Innovation
本文提出了一种基于变分框架的统一模型，用于形式化和设计残差自适应策略。该框架通过整合凸变换的残差，不同变换对应不同的目标函数，使得指数权重目标均方误差最小化，线性权重恢复二次误差最小化。此模型的系统化设计带来了三个主要益处：（1）允许系统地设计不同范数下的自适应方案；（2）通过降低损失估计的方差来减少离散化误差；（3）通过提高梯度信号噪声比来改善学习动态。此外，该框架扩展到了算子学习，展示了在优化器和架构中的显著性能提升，提供了残差自适应的理论依据，并为有原则的离散化和培训策略奠定了基础
### Conclusion
该研究提供了一个有原则的方法，不仅规定了自适应策略的设计，而且还通过提升误差度量和减少离散化误差提升了学习动态。在算子学习领域的应用展示了显著的性能提升，为未来的研究奠定了理论基础。
## 1459. `cs.LG` - 利用模型指导从个性化扩散模型中提取训练数据 [PDF](https://arxiv.org/pdf/2410.03039), [HTML](https://arxiv.org/abs/2410.03039)
### Authors
Xiaoyu Wu,Jiaru Zhang,Zhiwei Steven Wu
### Background
扩散模型（DMs）已成为强大的图像生成工具，尤其在少量图像微调中，预训练的DM通过少量的图像集调整可以捕捉特定的风格或对象。许多用户在线共享这些个性化检查点，形成了如Civitai和HuggingFace等社区。然而，模型所有者在发布微调的检查点时可能忽视了数据泄露的风险，而未经授权的数据在微调过程中使用也可能引发版权侵犯的担忧。
### Innovation
本文提出了一种名为FineXtract的框架，用于从在线共享的微调DM中提取训练数据。该方法将微调视为模型学习分布的渐进变化，并通过外推来引导生成向微调数据分布中的高概率区域。论文通过WikiArt、DreamBooth和实际在线发布的检查点进行实验，验证了该方法的有效性，大多数情况下能够提取约20%的微调数据。
### Conclusion
实验结果表明，FineXtract框架能够有效提取微调DM中的训练数据，验证了方法的有效性，并为数据泄露和版权侵权提供实际证据。该实验证明了提取微调数据的可能性及其价值。
## 1460. `cs.LG` - FERD: 增强公平性的无数据鲁棒性提取 [PDF](https://arxiv.org/pdf/2509.20793), [HTML](https://arxiv.org/abs/2509.20793)
### Authors
Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang
### Background
现有的方法主要集中在整体鲁棒性上，但忽视了鲁棒公平性问题，导致不同类别之间的鲁棒性差距明显。无数据鲁棒性提取（DFRD）旨在用教师模型的鲁棒性来训练学生模型，而不访问训练数据，但是现有方法在保持鲁棒公平性方面存在不足。因此，研究者们发现了两个关键问题，一个是学生模型中不均衡数据导致的鲁棒性差异，另一个是学生模型的鲁棒性对不同类型攻击的响应不稳定。
### Innovation
本文提出了第一个增强公平性的无数据鲁棒性提取（FERD）框架，该框架通过调整对抗样本的数量分布来解决上述问题。FERD通过鲁棒性导向的类别重权重策略增加更少鲁棒类别的样本量，从而提高它们的鲁棒性；通过生成公平感知示例（FAEs）来增强鲁棒性提取的高级性，FAEs通过在特征级预测上让其分布具有一致性，减少类别特定的非鲁棒特征的占优势地位，从而提供类别间更平衡的表示。FERD还生成了均匀目标对抗示例（UTAEs），避免样本偏向某些特定的鲁棒性差的类别，这些示例限制了攻击方向，从而使目标在所有类别间均匀分布，避免了对特定类别脆弱性产生过分适应的问题。
### Conclusion
广泛实验表明，FERD在FGSM和AutoAttack所有对抗攻击下的最差类别鲁棒性获得了显著提升（例如，MobileNet-V2在CIFAR-10数据集上的FGSM鲁棒性提高了15.1%，AutoAttack鲁棒性提高了6.4%）。这表明，FERD在鲁棒性和公平性方面均具有优越性能。
## 1461. `cs.LG` - Differential-Integral Neural Operator for Long-Term Turbulence Forecasting [PDF](https://arxiv.org/pdf/2509.21196), [HTML](https://arxiv.org/abs/2509.21196)
### Authors
Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu
### Background
准确预测长期湍流演化是一个重大的科学计算挑战，在气候建模和航空航天工程等领域具有关键应用价值。现有的深度学习方法，尤其是神经算子，常在长期自回归预测中失效，这主要是由于它们无法同时捕捉湍流动力学所遵循的不同数学结构：局部耗散效应和全局非局部相互作用，导致误差累积和物理精度丧失。
### Innovation
本文提出了Differential-Integral Neural Operator (textbf{textunderline{DINOP}})，一种基于从微观原理出发的操作分解的新框架。DINOP通过并行子路径学习不同物理算子：局部微分算子，由受到约束的卷积网络实现并能证明收敛到导数，以及全局积分算子，用Transformer架构学习数据驱动的全局内核。这种基于物理的操作分解赋予了DINOP出色的稳定性和鲁棒性。通过在2D柯尔莫哥洛夫湍流流动基准测试上的广泛实验，DINOP在长期预测中显著优于现有最先进的模型，并成功避免了数百时间步的误差累积，保持了涡旋场和能谱的高物理精度，创造了一种新的标准，确保了长期一致性的湍流预测。
### Conclusion
通过广泛的实验验证，DINOP在长期预测中表现出色，成功地抑制了累积误差，保持了涡旋场和能量谱的高物理精度，并树立了新的基准，证明了其在物理一致、长距离湍流预测中的优势。
## 1462. `cs.LG` - 使用对比学习预训练二进制代码表示 [PDF](https://arxiv.org/pdf/2210.05102), [HTML](https://arxiv.org/abs/2210.05102)
### Authors
Yifan Zhang,Chen Huang,Yueke Zhang,Huajie Shao,Kevin Leach,Yu Huang
### Background
二进制代码分析和理解对于逆向工程和计算机安全任务至关重要，但在没有源代码的情况下，它比源代码更难理解和分析，缺乏语义。本文旨在通过将源代码、注释信息与二进制代码结合起来，利用对比学习技术帮助二进制代码分析和理解。文章提出了ContraBin，一种对比学习技术，旨在通过将源代码、注释和二进制代码整合起来创建一个用于辅助二进制代码分析任务的嵌入。研究发现，尽管合成注释能带来显著的性能提升，但人工编写的注释会引入噪声，甚至可能会导致性能下降，这改变了对注释类型在二进制代码分析中角色的认知。
### Innovation
文章提出了一种名为ContraBin的技术，它利用对比学习将源代码、注释信息与二进制代码整合，以帮助二进制代码分析和理解。ContraBin包括三个组件：(1) 初始预训练的主要对比学习方法，(2) 简单插值方法将源代码、注释和二进制代码集成，(3) 中间表示学习算法以训练二进制代码嵌入。结果显示，ContraBin在四个与二进制代码相关的下游任务中显著改善了性能，包括算法功能分类、函数名称恢复、代码摘要和逆向工程。此外，ContraBin是第一个将源代码、二进制代码和注释整合到对比代码表示学习中的语言表示模型。
### Conclusion
研究通过四个与二进制代码相关的下游任务评估了ContraBin的有效性，结果显示该技术显著提高了表现。此外，该研究的代码数据集可用于进一步研究。
## 1463. `cs.LG` - 在随机线搜索框架中有效利用动量项以快速优化有限和问题 [PDF](https://arxiv.org/pdf/2411.07102), [HTML](https://arxiv.org/abs/2411.07102)
### Authors
Matteo Lapucci,Davide Pucci
### Background
本文讨论了大规模深度学习场景下的无约束有限和优化问题，特别关注了在过度参数化条件下随机优化的线搜索方法与动量方向之间的关系。现有的结合这两者的计算优势不太直接。
### Innovation
提出了一种基于小批量持续性的解决方案。进而介绍了结合数据持续性、共轭梯度类型规则定义动量参数以及随机线搜索的算法框架。结果显示，该算法在适合假设下具有收敛性，并且在凸性和非凸的大规模训练问题上相比于其他常用方法表现出色，取得了最先进的结果。
### Conclusion
该算法在理论假设下具有收敛性，并在大规模凸和非凸训练问题上通过实验证明了比其他流行方法更优的效果。
## 1464. `cs.LG` - 在阿尔茨海默病检测中的类内变异问题 [PDF](https://arxiv.org/pdf/2409.16322), [HTML](https://arxiv.org/abs/2409.16322)
### Authors
Jiawen Kang,Dongrui Han,Lingwei Meng,Jingyan Zhou,Jinchao Li,Xixin Wu,Helen Meng
### Background
阿尔茨海默病（AD）检测采用机器学习分类模型来区分AD患者和非患者的个体。与传统的分类任务不同，本文识别出个体间的类内变异作为一个关键挑战：AD患者在认知功能上展示出广泛的变化性。传统的二元AD分类可能忽略了类内变异性和实例水平的不平衡性两方面的问题。
### Innovation
研究发现，使用样本评分估计器能够生成与认知评分相匹配的样本特定软评分。并提出了两种简单而有效的方法：Soft Target Distillation（SoTD）和Instance-level Re-balancing（InRe），分别针对上述两个问题。并通过ADReSS和CU-MARVEL数据集展示了所提出方法检测效果的优势。
### Conclusion
研究发现为开发稳健和可靠的AD检测模型提供了新的见解。
## 1465. `cs.LG` - 在线资源分配与平均预算约束 [PDF](https://arxiv.org/pdf/2402.11425), [HTML](https://arxiv.org/abs/2402.11425)
### Authors
Ruicheng Ao,Hongyu Chen,David Simchi-Levi,Feng Zhu
### Background
研究在线资源分配问题，特别关注在每次请求到达时，决策者必须在下一个请求到达之前做出不可逆转的接受或拒绝决策，以最大化累计奖励。该问题不同于现有文献中对总资源消耗的限制，本研究强调的是每个被接受请求的平均资源消耗不得超过给定阈值。这一问题可以转化为一个有外生随机预算补充的背包问题，并且在诸如在线异常检测、连续广告服务以及人均公共服务提供等领域具有广泛应用。
### Innovation
1. 提出了在线资源分配与平均预算约束问题的框架，强调单个请求的平均资源消耗不超过阈值，而非总消耗。2. 针对连续请求分布，提出了一种新的政策，旨在节省预算安全缓冲，从而显著降低后悔率。3. 对现有重新求解启发式算法进行了分析，并展示了其在最优政策下的局限性，尤其是在后悔率上的表现。4. 研究将提出的方法扩展到连续请求分布、时间依赖信息结构以及未知时间范围的情况，展示了其在实际应用中的有效性。
### Conclusion
研究发现，适度的安全缓冲可以显著减少在线资源分配问题中的后悔率，从类似textOmega(textsqrt{T})或textOmega(T)降低到textO(textln^2 T)。此外，这些新的策略还适用于更广泛的应用场景，包括连续请求分布和未知时间段的预测。通过合成实验和纽约市出租车乘客时间序列数据的实际应用，验证了所提出策略的有效性。
## 1466. `cs.LG` - 数据驱动的分段线性决策规则用于具有协变量信息的随机规划 [PDF](https://arxiv.org/pdf/2304.13646), [HTML](https://arxiv.org/abs/2304.13646)
### Authors
Yiyang Zhang,Junyi Liu,Xiaobo Zhao
### Background
本文聚焦于包含协变量信息的随机规划（SP），提出了一种嵌入非凸分段仿射决策规则（PADR）中的经验风险最小化（ERM）方法。该方法旨在直接从特征到最优决策建立映射关系。本文建立了基于PADR的ERM模型在无约束问题中的非渐近一致性结果及在约束问题中的渐近一致性结果。为了求解非凸且非光滑的ERM问题，我们开发了一种增强的随机主次优化算法，并证明了沿导数方向渐近收敛及其复杂性分析。表明所提出的基于PADR的ERM方法可以应用于广泛的非凸随机规划问题，具有理论的一致性保证和计算上的可实现性。
### Innovation
本文的主要创新在于提出了一种嵌入非凸分段仿射决策规则的非凸经验风险最小化方法，并通过非渐近及渐近一致性分析支持了该方法的有效性；开发了增强的随机主次优化算法，并通过导数方向的渐近收敛证明了算法的有效性和复杂性分析。表明该方法能处理广泛的非凸随机规划问题，并且在理论上具有保证，计算上也是可行的。此外，数值研究表明，相较于当前最先进的方法，基于PADR的ERM方法在各种场景下的性能更优，成本更低，计算时间更短，并且对特征维度和潜在依赖的非线性具有更强的鲁棒性。
### Conclusion
总的来说，通过基于PADR的ERM方法，本文提供了一种新的处理非凸随机规划问题的方法，并且证明了其理论的一致性和计算的可行性，该方法在数值上表现出了优越性，能够有效地处理具有非凸性和大量特征的随机规划问题，并且具有较强的实际应用价值。
## 1467. `cs.LG` - 低资源和领域特定编程语言基于大语言模型的代码生成综述 [PDF](https://arxiv.org/pdf/2410.03981), [HTML](https://arxiv.org/abs/2410.03981)
### Authors
Sathvik Joel,Jie JW Wu,Fatemeh H. Fard
### Background
大语言模型（LLMs）在生成主流编程语言的代码方面表现出色，但它们在低资源编程语言（LRPLs）和领域特定语言（DSLs）中的表现仍然存在显著挑战，影响了成千上万的开发人员，如Rust语言的350万用户，他们无法充分利用LLMs的能力。LRPLs和DSLs面临的独特障碍包括数据稀缺性，对于DSLs还有专门的语法，这种语法在通用数据集中不易体现。改进这些语言的代码生成能力对于提高他们在金融、科学等领域的开发效率至关重要。尽管已有若干关于LLMs的软件工程综述，但尚无针对LRPLs和DSLs的特定挑战和机遇的研究。本文通过系统地回顾了2020年至2024年间与LLMs在这些语言中进行代码生成相关的111篇论文，填补了这一空白，全面评估了LLMs在LRPLs和DSLs中的能力和限制，并提出了增强性能的策略、数据集收集与整理的方法，以及几种评估代码生成的评估技术和指标。
### Innovation
本文是首个专注于低资源编程语言和领域特定语言的基于大语言模型的代码生成的综述。它系统地筛选和总结了2020年至2024年间与LLMs在这些语言中进行代码生成相关的研究成果，提供了包括评估技术、指标、改进方法和新架构的详细分析。此外，本文指出了现有技术的不足之处，即缺少统一的评估方法和基准数据集，为未来的研究奠定了基础。
### Conclusion
本文为研究者和从业者提供了一个宝贵的资源，促进了LLMs、软件工程及特定编程语言领域之间的交叉研究，指引未来在低资源和领域特定编程语言中的代码生成领域的研究方向。
## 1468. `cs.LG` - GraphSCENE：为模拟中自主车辆生成按需关键场景 [PDF](https://arxiv.org/pdf/2410.13514), [HTML](https://arxiv.org/abs/2410.13514)
### Authors
Efimia Panagiotaki,Georgi Pramatarov,Lars Kunze,Daniele De Martini
### Background
在实际部署之前，需要在安全关键和多样化的场景中测试和验证自主车辆（AV）的性能。但在模拟中手动创建这些场景仍然是一项耗时的巨大挑战。
### Innovation
本文提出了一种新型方法，即生成基于时间的动态场景图，以适应多样化的交通场景，这些场景可以根据用户的偏好实时生成，如AV行为、动态代理集合和关键性级别。时间图神经网络（GNN）模型通过基于现实世界的时空交互模式来预测 ego-车辆、代理和静态结构之间的关系，并通过本体限制预测结果以保证语义上的正确性。实验结果表明，该模型在生成所需场景的关联方面显著优于基准模型。生成的场景被渲染用于进一步证明其作为AV代理测试环境的有效性。
### Conclusion
该模型能够在模拟中生成准确的场景，并验证这些场景作为AV代理测试环境的有效性。
## 1469. `cs.LG` - Stuffed Mamba: Oversized States Lead to the Inability to Forget [PDF](https://arxiv.org/pdf/2410.07145), [HTML](https://arxiv.org/abs/2410.07145)
### Authors
Yingfa Chen,Xinrong Zhang,Shengding Hu,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
近期，Mamba和RWKV等循环神经网络结构展现出了强大的语言能力。与基于Transformer的模型相比，这些架构将所有上下文信息编码为固定大小的状态中，从而提高了推理效率。但这种方法可能导致信息干扰，即不同token数据之间的冲突，从而导致性能下降和输出不连贯。现有的大多数循环神经网络（RNNs）包含可以“忘记”早期token的机制。然而，研究表明基于Mamba的模型即使具有内置的遗忘机制，也难以有效忘记早期token。这是因为模型训练时上下文过短，使得模型在不需要学习遗忘的情况下也能表现良好。
### Innovation
研究揭示，Mamba模型在状态下过大时难以有效遗忘早期token。最小的训练长度随状态大小呈线性增加，准确检索5位数密码的最大上下文长度则随状态大小呈指数增加。这些发现揭示了当前RNN架构的关键局限性，并提供了优化长期上下文建模的宝贵见解。未来RNN设计需要考虑状态大小、训练长度和遗忘机制之间的相互作用，以实现长期上下文任务中的稳健性能。
### Conclusion
本研究突出了一种现有的循环神经网络架构的关键限制，并为改进长期上下文建模提供了有价值的见解。未来的设计必须在考虑状态大小、训练长度和遗忘机制相互作用的情况下，才能在长期上下文任务中实现稳健的性能。
## 1470. `cs.LG` - VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation [PDF](https://arxiv.org/pdf/2502.07531), [HTML](https://arxiv.org/abs/2502.07531)
### Authors
Sixiao Zheng,Zimian Peng,Yanpeng Zhou,Yi Zhu,Hang Xu,Xiangru Huang,Yanwei Fu
### Background
现有的图像到视频生成方法通常分别处理相机运动、物体运动和光源方向的控制信号，这主要是由于高质量的联合注释数据集稀缺，以及不同模态下的控制空间不匹配。这种分离处理限制了创建内容工作流程中的精确度和灵活性。
### Innovation
VidCRAFT3 提出了一种统一且灵活的图像到视频生成框架，支持独立和联合的相机运动、物体运动和光源方向控制。通过整合三个核心组件：Image2Cloud 重建参考图像的3D点云以实现精确的相机运动控制；ObjMotionNet 编码稀疏物体轨迹并以多尺度光流特征引导物体运动；Spatial Triple-Attention Transformer 通过并行交叉注意力结合光源方向嵌入。
### Conclusion
VidCRAFT3 在控制精度和视觉一致性方面明显优于现有方法。为此，该研究还创建了带有每帧光源方向标签的合成静态场景视频剪辑的数据集 VideoLightingDirection (VLD)，并且采用了三种阶段的训练策略来实现稳健学习。项目页面：this https URL。
## 1471. `cs.LG` - $100,000或100天：使用学术资源预训练时的权衡 [PDF](https://arxiv.org/pdf/2410.23261), [HTML](https://arxiv.org/abs/2410.23261)
### Authors
Apoorv Khandelwal,Tian Yun,Nihal V. Nayak,Jack Merullo,Stephen H. Bach,Chen Sun,Ellie Pavlick
### Background
学术研究者通常计算资源有限，预训练模型被认为是计算密集型的任务，因此普遍认为学术界无法进行模型预训练。本文旨在澄清这一假设，通过调查学术研究人员可用的计算资源，并实证测量在这些资源上复制模型所需的时间。文章还提供了一个基准测试来衡量在给定GPU上预训练模型所需的时间，以确定实现最佳训练速度的理想设置。所有实验共耗费2,000 GPU小时进行该基准测试。研究表明，即使原始的Pythia-1B模型在64个GPU上训练了3天，也能在4个GPU上以18天的时间进行复制（保持相同的超参数）。文章还进行了成本效益分析，帮助明确定义价格与预训练时间之间的权衡。通过分享这一基准，我们希望帮助学术界研究人员进行更复杂的模型训练实验。
### Innovation
文章提出并实证测量了在学术可用的算力资源上进行模型预训练所需的时间。引入了一个基准测试来评估在给定GPU上预训练模型所需时间，并识别了实现最大训练速度的理想设置。此外，文章还包括了一项成本效益分析，提供了价格和预训练时间之间权衡的明确指导。
### Conclusion
文章的研究结果为学术界的模型预训练提供了一种更乐观的图景：通过合理安排资源利用，许多预训练模型可以在更少的时间内完成，而无需庞大的计算预算。文章的基准测试将帮助学术研究人员开展需要训练更大、数据更多的实验。论文全文代码已公开，可访问：这个网址（实际网址未提供）。文章通过提供更多可负担、高效的方法，为学术界利用有限资源进行了更复杂模型训练的可行性提供了明确的指导。
## 1472. `cs.LG` - Surgical Vision World Model [PDF](https://arxiv.org/pdf/2503.02904), [HTML](https://arxiv.org/abs/2503.02904)
### Authors
Saurabh Koju,Saurav Bastola,Prashant Shrestha,Sanskar Amgain,Yash Raj Shrestha,Rudra P. K. Poudel,Binod Bhattarai
### Background
现实且互动的外科手术模拟具有促进医疗专业培训和自主外科手术代理培训的巨大潜力。在自然视觉领域，世界模型已经允许通过动作控制数据生成，表明了大规模真实数据难以获取时，在交互式模拟环境中训练自主代理的潜力。然而，在手术领域的现有工作大多局限于简单的计算机模拟，并缺乏现实感。此外，在世界模型中的现有文献主要集中在动作标签数据上，限制了它们在需高昂标注成本的真实世界外科数据中的适用性。
### Innovation
本研究提出了第一种外科视点世界模型，在未标记的SurgtToolLoc-2022数据集上进行了广泛实验以验证该模型的生成解动作控制的外科数据的能力。该模型可以生成动作操控的外科数据，且架构设计通过实验证明了有效性。代码和实现细节可在提供的链接中获取。
### Conclusion
本研究通过将Genie方法应用于未标记的外科手术数据，提出了一种新的外科视点世界模型。该模型成功地在无标记数据上生成了可操控的动作数据，并且其架构设计通过了全面的实验验证。
## 1473. `cs.LG` - 通过人类反馈进行强化学习学习个性化驾驶风格 [PDF](https://arxiv.org/pdf/2503.10434), [HTML](https://arxiv.org/abs/2503.10434)
### Authors
Derun Li,Changye Li,Yue Wang,Jianwei Ren,Xin Wen,Pengxiang Li,Leimeng Xu,Kun Zhan,Peng Jia,Xianpeng Lang,Ningyi Xu,Hang Zhao
### Background
在动态环境中进行自主驾驶需要生成类似人类且适应性强的轨迹。现有的生成模型虽然能合成可行的轨迹，但由于数据集偏差和分布变化，往往难以捕捉个人化驾驶风格的细微差异。
### Innovation
我们提出了TrajHF，一种基于人类反馈的数据调整框架，用于修正生成轨迹模型，使其与多样的驾驶风格保持一致。TrajHF结合了多条件去噪器和基于人类反馈的强化学习，提高了多模态轨迹生成的精度，同时保持了安全性和可行性。
### Conclusion
TrajHF在导航模拟基准测试中达到与现有最佳水平相当的性能，为个性化和适应性强的自主驾驶轨迹生成树立了一个新的范式。
## 1474. `cs.LG` - 专业足球运动员未来质量和价值的发展预测 [PDF](https://arxiv.org/pdf/2502.07528), [HTML](https://arxiv.org/abs/2502.07528)
### Authors
Koen W. van Arem,Floris Goes-Smit,Jakob Söhl
### Background
在职业足球领域，转会是一种高风险的投资，因为涉及的转会费用巨大且未来表现存在不确定性。目前的数据驱动模型只能描述球员的历史进步，而无法预测其未来表现。为了提升决策质量，本文研究使用可解释的机器学习模型结合预测准确性和不确定性量化方法，以预测专业足球运动员未来在质量和转会价值上的发展。
### Innovation
本文创新性地评估了基于预测准确性和不确定性量化方法的可解释机器学习模型，用于预测专业足球运动员未来在质量和转会价值上的发展。通过训练模型预测一年后的球员质量和价值，并利用包含数据驱动指标的数据集进行训练。研究表明随机森林模型因其在精确预测和不确定性量化方面的优越性而最为适用。
### Conclusion
研究结果表明，球员表现的发展包含非线性模式和变量之间的交互作用，时间序列信息可以提供有用的球员表现指标建模信息。所得到的模型可以帮助足球俱乐部做出更多基于数据的、知情的转会决策，从而预测球员质量和转会价值。
## 1475. `cs.LG` - 稀少而稀疏的异常检测：解决多实例学习中的双重不平衡 [PDF](https://arxiv.org/pdf/2503.13562), [HTML](https://arxiv.org/abs/2503.13562)
### Authors
Lin-Han Jia,Lan-Zhe Guo,Zhi Zhou,Si-Ye Han,Zi-Wen Li,Yu-Feng Li
### Background
在实际应用中，检测极稀疏的异常样本极具挑战性，因为这些异常样本与正常样本高度相似，容易混淆。此外，异常样本的数量本身就很稀缺。这就导致了一个双向不平衡的多实例学习（MIL）问题，在宏观和微观层面都存在不平衡现象。
### Innovation
将MIL问题重新定义为精细粒度的PU学习问题，从而可以利用微观级别的平衡机制以公平的方式解决不平衡问题。基于严格的理论基础提出了一种新的框架——基于精细粒度 PU 学习融合平衡（BFGPU）。
### Conclusion
在合成数据集和真实世界数据集上的广泛实验表明，BFGPU 方法的有效性。
## 1476. `cs.LG` - 数据估值能成为好数据价格吗？ [PDF](https://arxiv.org/pdf/2504.05563), [HTML](https://arxiv.org/abs/2504.05563)
### Authors
Dongyang Fan,Tyler J. Rotello,Sai Praneeth Karimireddy
### Background
随着大语言模型越来越依赖外部数据源，补偿数据贡献者已成为关键问题。但如何设计这些支付机制？本文从市场设计角度审视数据估值问题，其中支付机制旨在补偿数据拥有者因收集和分享数据而产生的私人异质成本。流行的估值方法如Leave-One-Out和Data Shapley未能确保成本的真实报告，导致市场效率低下。
### Innovation
本文将机制设计中成熟的支付规则，例如Myerson和Vickrey-Clarke-Groves (VCG) 调整应用于数据市场情境。证明了Myerson支付是最小真理性机制，从买家角度看最优化。同时，发现了一个条件，在此条件下买家和卖家都能达到效用最大化，市场实现效率。研究强调了在数据估值设计中融入激励相容的重要性，为更加稳健和高效的数据市场铺平道路。
### Conclusion
我们的数据市场框架适用于现实世界场景。我们通过一个基于大语言模型的检索增强生成（RAG）市场中挑战性医疗问题回答中的贡献者补偿模拟，展示了这一框架的实际应用。这表明设计合适的支付机制对于促进数据市场的发展至关重要。
## 1477. `cs.LG` - 代码语言模型能否学习求证行为？ [PDF](https://arxiv.org/pdf/2504.16331), [HTML](https://arxiv.org/abs/2504.16331)
### Authors
Jie JW Wu,Manav Chaudhary,Davit Abrahamyan,Arhaan Khaku,Anjiang Wei,Fatemeh H. Fard
### Background
大型语言模型（LLMs）在代码生成任务中表现出了显著的能力，却与人类开发者的解决问题策略存在差距。与人类需要通过迭代对话澄清需求有所不同，LLMs往往在自然语言需求有歧义的情况下就生成代码，导致生成的解决方案不可靠。现有的研究表明，模型通过迭代循环生成代码，而本文研究的是代码LLM是否可以被微调以学习求证行为。这一研究主张在生成代理AI中，模型自身具有识别和查询模糊需求的能力尤为重要。
### Innovation
本文提出了一种名为ClarifyCoder的框架，通过合成数据生成和指令调优方法，微调LLM以在面对不完整或模糊的需求时先识别歧义并请求澄清后再进行代码生成。该框架包含两个部分：一是生成需要澄清的场景以扩充编程数据集，生成求证意识的训练数据；二是训练模型在面对不完整或模糊的需求时优先求证后再生成代码。此外，还探讨了将ClarifyCoder与常规微调结合以共同优化求证意识与编码能力的方法。
### Conclusion
实验结果显示，使用ClarifyCoder方法的LLMs在混乱任务中的沟通率达到63%（绝对提升40%），提出好问题的比例达到52%（绝对提升30%），显著提高了LLMs的沟通能力同时保持了代码生成的性能。
## 1478. `cs.LG` - 大型语言模型低秩适配器的无需训练贝叶斯化 [PDF](https://arxiv.org/pdf/2412.05723), [HTML](https://arxiv.org/abs/2412.05723)
### Authors
Haizhou Shi,Yibin Wang,Ligong Han,Huan Zhang,Hao Wang
### Background
目前，从大型语言模型（LLMs）中估计响应的不确定性是一个关键挑战。虽然最近的贝叶基方法通过低秩权重更新有效量化了不确定性，但它们通常需要复杂的微调或后训练过程。这项工作中，探讨了一种无需训练贝叶斯化（TFB）框架，它可以在不进行额外训练的情况下，将训练好的低秩适配器高效地转换为贝叶斯适配器，通过系统地搜索权重后验中最大可接受的方差水平，受低秩等向高斯分布族约束。理论分析表明，在温和条件下，这一搜索过程等同于KL正则化变分优化，这是一种变分推断的推广形式。综合实验表明，TFB在不确定性估计和泛化方面优于现有方法，同时消除了复杂的贝叶斯化训练程序需求。
### Innovation
提出了无需训练贝叶斯化（TFB），这是一种简单且理论支撑的框架，能够在不进行额外训练的情况下，将训练好的低秩适配器转换为贝叶斯适配器。TFB框架通过系统地搜索权重后验中的最大可接受方差水平，受低秩等向高斯分布族约束。理论分析表明，在温和条件下，搜索过程等同于KL正则化变分优化，这是一种变分推断的推广形式。与现有方法相比，TFB在不确定性估计和泛化方面具有优势，并消除了复杂的贝叶斯化训练程序需求。
### Conclusion
通过综合实验，证明了training-free bayesianization（TFB）在不确定性估计和泛化方面优于现有方法，同时消除了复杂的贝叶斯化训练程序需求。
## 1479. `cs.LG` - 解析金融大语言模型的域适应后训练 [PDF](https://arxiv.org/pdf/2501.04961), [HTML](https://arxiv.org/abs/2501.04961)
### Authors
Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty
### Background
大语言模型（LLMs）的域适应后训练在医学和金融等特定领域显示出广阔的应用前景。然而，当前在不同数据和模型配置条件下选择最优的适应标准和训练策略仍然存在挑战。本文通过系统深入地探讨金融领域的域适应后训练方法，旨在解决这些挑战。研究发现，金融领域的特定需求需要特定的模型训练方案和评估标准，这些都需要更细致的研究和优化。
### Innovation
本文提出了FINDAP，这是一种全面的系统化方法，包括FinCap、FinRec、FinTrain和FinEval四个关键组成部分。FINDAP通过定义目标领域的核心能力（FinCap）、有效的混合训练方法（FinRec）、支持此方法的训练数据集集（FinTrain），以及与能力目标一致的评估方案（FinEval），来提高在金融领域大语言模型的性能。FINDAP的方法强调了每个后训练阶段在提升金融领域建模能力上的贡献，并揭示了具体挑战及解决方案，为后续研究提供了有力参考。
### Conclusion
由此，基于FINDAP的方法和框架，作者训练出的Llama-Fin模型在广泛金融任务上达到了最先进的性能。研究还揭示了各个后训练阶段对于提升特定领域模型性能的重要作用，为持续优化和提升大型语言模型在特定领域的应用效果提供了宝贵的见解。
## 1480. `cs.LG` - 加速分子设计的条件潜空间分子支架优化 [PDF](https://arxiv.org/pdf/2411.01423), [HTML](https://arxiv.org/abs/2411.01423)
### Authors
Onur Boyar,Hiroyuki Hanada,Ichiro Takeuchi
### Background
全球健康和新治疗方法的发展依赖于快速发现新的化学化合物。虽然生成模型在创造新颖分子方面表现出潜力，但确保这些分子在现实世界中的适用性和高效率地找到它们仍然面临挑战。本文介绍了一种名为Conditional Latent Space Molecular Scaffold Optimization (CLaSMO)的方法，旨在通过结合条件变分自编码器（CVAE）和潜在空间贝叶斯优化（LSBO），高效且战略性地修改分子结构，同时保持与原始输入的相似性，从而将其任务框架化为目标约束优化问题。这种新方法提高了分子优化的样本效率，并通过保留分子相似性来增加实际适用分子的出现概率。CLaSMO利用条件在优化目标分子的原子环境上的变分自编码器潜在空间中的贝叶斯优化来高效探索分子的子结构。
### Innovation
本文介绍了一种名为Conditional Latent Space Molecular Scaffold Optimization (CLaSMO)的新方法，该方法通过结合条件变分自编码器（CVAE）与潜在空间贝叶斯优化（LSBO），对分子进行高效且战略性的修改，同时保持分子相似性。这种方法提高了分子优化的样本效率，并通过保留分子相似性来增加实际适用分子的出现概率。CLaSMO的方法在广泛的优化任务中，如重新发现、对接得分和多性质优化中表现出高效性能、极具样本效率、考虑分子相似性约束和保持实用的合成可及性。
### Conclusion
本文介绍的CLaSMO方法有效地提高了目标性质，同时在资源有限的应用中提供出色的样本效率，考虑了分子相似性约束，达到了最先进的性能水平，并保持了实用的合成可及性。此外，本文还提供了一个开源的网络应用程序，使化学专家能够以人类在回路的方式应用CLaSMO。
## 1481. `cs.LG` - IP$^{2}$-RSNN: Bi-level Intrinsic Plasticity Enables Learning-to-learn in Recurrent Spiking Neural Networks [PDF](https://arxiv.org/pdf/2501.14539), [HTML](https://arxiv.org/abs/2501.14539)
### Authors
Yingchao Yu,Yaochu Jin,Kuangrong Hao,Yuchen Xiao,Yuping Yan,Hengjie Yu,Zeqi Zheng,Wenxuan Pan
### Background
学习-学习（L2L），被定义为在类似任务中更快地学习，对神经科学和人工智能都至关重要，但其神经基础尚不清楚。传统研究主要关注突触可塑性诱导的大脑神经群体动力学，而忽视了由内在神经元可塑性驱动的适应性变化，这是单个点神经元模型无法捕捉到的。该论文旨在解决这一问题，开发了一种具有双层内在可塑性的递归脉冲神经网络（IP$^{2}$-RSNN）。
### Innovation
该研究提出了双层内在可塑性（IP$^{2}$）的概念，并在递归脉冲神经网络（RSNN）中进行了应用。具体而言，通过基于任务需求的慢速元内在可塑性，确定哪些内在神经元属性是可学习的，并在后续任务学习中保持不变；快速内在可塑性则在每个任务中微调这些可学习的属性。实验结果表明，提出的双层内在可塑性在递归脉冲神经网络中促进了L2L，并且IP$^{2}$-RSNN优于点神经元递归神经网络（RNNs）和自注意力模型。同时，网络动态的多尺度分析表明，双层内在可塑性在L2L过程中对于神经元和网络级别的任务类型特异性适应至关重要，这是点神经元模型无法捕捉到的。
### Conclusion
本文表明内在可塑性为L2L提供了显著的计算优势，有助于设计受大脑启发的深度学习模型和算法。
## 1482. `cs.LG` - 从咕咕声到词汇表：合作觅食中涌现的语言 [PDF](https://arxiv.org/pdf/2505.12872), [HTML](https://arxiv.org/abs/2505.12872)
### Authors
Maytus Piriyajitakonkij,Rujikorn Charakorn,Weicheng Tao,Wei Pan,Mingfei Sun,Cheston Tan,Mengmi Zhang
### Background
语言是一种强大的交际与认知工具，能够帮助人类表达思想、共享意图并推理复杂的现象。尽管人类在使用和理解语言方面具有高超的能力，但语言是如何产生和发展至今仍是一个未解之谜。语言学和人类学中的一种主流观点认为，语言是为了满足早期人类合作的生态和社会需求而进化的，并不是孤立形成的。作者借鉴这一观点，研究在多智能体觅食游戏中语言的涌现。这些环境模拟了被认为影响了早期人类交流认知和生态限制。
### Innovation
作者使用端到端的深度强化学习，让智能体从头开始学习动作和沟通策略。实验结果显示，智能体发展了具有自然语言标志性特征的语言协议，包括任意性、可互换性、超前性、文化传承性和组合性。此外，作者还量化了每个特性，并分析了影响这些特点发展的不同因素，如人口规模、社会动态和时间依赖性。他们提供了一个研究平台，可以在部分可观察性、时间推理和合作目标中如何在具身多智能体环境中进化语言。
### Conclusion
该框架提供了一个平台，用于研究在多智能体环境中的合作目标和部分可观察性条件下语言如何进化。此外，作者还释放了所有数据、代码和模型，以供公众使用。
## 1483. `cs.LG` - 八次变换视网膜变换器：通过对称性获得更快的视网膜变换器 [PDF](https://arxiv.org/pdf/2505.15441), [HTML](https://arxiv.org/abs/2505.15441)
### Authors
David Nordström,Johan Edstedt,Fredrik Kahl,Georg Bökman
### Background
当前最先进的视觉变换器（ViTs）并没有充分利用自然几何对称性，例如90度旋转和反射。本文探讨了为何ViTs没有设计来利用这些对称性，提出这一现象并非没有根本原因，而在于缺乏高效实现方法。
### Innovation
本文引入了八次变换视网膜变换器（octic ViTs），通过八次群不变性来捕捉这些对称性。与之前的可变模型相比，octic线性层实现了5.33倍的FLOPs减少和8倍的内存减少。在完整八次变换ViT块中，计算减少接近偶数线性层随着嵌入维度增加而减少的速度。本文还研究了两种新的ViT家族，它们要么完全八次变换不变，要么在网络的最后部分打破不变性。
### Conclusion
使用八次变换视网膜变换器（DeiT-III）监督训练和无监督训练（DINOv2）在ImageNet-1K上，发现它们与基线准确度相当，同时提供了显著的效率提升。
## 1484. `cs.LG` - 使用任务引出方法动态表征模型 [PDF](https://arxiv.org/pdf/2503.01986), [HTML](https://arxiv.org/abs/2503.01986)
### Authors
Davis Brown,Prithvi Balehannina,Helen Jin,Shreya Havaldar,Hamed Hassani,Eric Wong
### Background
语言模型评估通常未能准确描述关键性失败模式，迫使专家们需要手动检查模型输出并建立新的基准。这增加了额外的工作量，同时也难以全面评估模型的行为。因此，亟需一种能够自动发现模型行为关键异常的评估方法。本文在此背景下产生了，旨在通过自动构建新型评估任务来更好地表征模型行为。通过这种方法，发现了比以往研究多数量级的新任务，这些任务显示出前沿模型在不同领域的系统性失败，例如预测、在线骚扰等。
### Innovation
本文提出了一种名为‘任务引出’的方法，能够自动构建旨在揭示模型关键异常行为的新型评估任务。相比之前的研究，使用该方法识别出大量自然语言任务，这些任务中模型表现出系统性失败。这种方法大大提高了评估的效率和全面性，尤其是对于前沿模型而言。例如，该方法揭示了Sonnet 3.5对量子计算和AGI的过度关联，以及o3-mini在重复虚构信息时产生幻觉的倾向。
### Conclusion
通过任务引出方法，本文成功地自动化了新型评估任务的构建过程，显著提高了模型评估的准确性和效率。此外，这种方法为研究人员提供了更全面了解尖端模型行为的关键异常提供了强有力的工具，有助于促进模型的改进和发展。
## 1485. `cs.LG` - 卸载不是删除：大规模语言模型中机器卸载可逆性的研究 [PDF](https://arxiv.org/pdf/2505.16831), [HTML](https://arxiv.org/abs/2505.16831)
### Authors
Xiaoyu Xu,Xiang Yue,Yang Liu,Qingqing Ye,Huadi Zheng,Peizhao Hu,Minxin Du,Haibo Hu
### Background
当前对大规模语言模型（LLMs）卸载（unlearning）效果的评估主要依靠任务级别的指标，如准确率和困惑度。但这些指标往往具有误导性，模型可能看似忘记了某些信息，但在进行了轻微的微调后，其原始行为能够轻易恢复。这一现象表明信息被抑制而非真正被擦除。
### Innovation
本文提出了一种基于表征层面的分析框架，其中包括基于PCA的相似性和偏移、中心化核对齐（CKA）以及费歇尔信息，并结合一个汇总指标（平均PCA距离）来衡量表征漂移。通过这种方法，发现六种卸载方法、三种数据域和两种LLMs之间存在四种不同的遗忘模式，基于可逆性和灾难性程度进行了分类。研究指出，要想实现理想的不可逆且非灾难性的遗忘状态非常具有挑战性。
### Conclusion
本文通过探索卸载的极限，揭示了一种看似不可逆的针对性遗忘案例，这为设计更稳健的擦除算法提供了新的见解。研究结果表明，当前的评估实践存在根本性的不足，并建立了一个表征层面的基础框架，以促进可信的卸载过程。
## 1486. `cs.LG` - 成本最优分组查询注意机制用于长上下文建模 [PDF](https://arxiv.org/pdf/2503.09579), [HTML](https://arxiv.org/abs/2503.09579)
### Authors
Yingfa Chen,Yutong Wu,Chenyang Song,Zhen Leng Thai,Xingyu Shen,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
组查询注意（GQA）是一种常用策略，用于减小大型语言模型中的注意力层的计算成本。然而，当前的GQA配置通常并不理想，因为它们忽视了上下文长度对推理成本的影响。推理成本随着上下文长度的增长而增加，因此最具成本效益的GQA配置也应相应变化。已有研究没有充分分析上下文长度、模型大小、GQA配置和模型损失之间的关系，也没有提出优化的方法。因此，常用GQA配置在长上下文场景中表现不佳，本研究旨在探索最优的GQA配置方法并在长上下文场景中应用其优点，以减少推理资源的使用，并保持模型性能不下降。实验结果表明，相较于Llama-3的GQA配置，本研究提出的配置在长上下文情况下能减少超过50%的内存使用和FLOPs，同时不影响模型能力。
### Innovation
1. 解耦总头数与隐藏层大小，提供更为灵活的注意力FLOPs控制；2. 联合优化模型大小和GQA配置，以更好地分配注意力层与其他组件的推理资源。
### Conclusion
研究表明，对于长上下文场景，应优化GQA配置以使用更少的注意力头和更大的模型规模。通过我们的方法得到的配置能将Llama-3的GQA配置减少超过50%的内存使用和FLOPs，同时保持模型性能。该研究为设计有效长上下文语言模型提供了有价值的见解。
## 1487. `cs.LG` - BP-Seg：一种使用信念传播的图形模型方法进行无监督且非连续文本分割 [PDF](https://arxiv.org/pdf/2505.16965), [HTML](https://arxiv.org/abs/2505.16965)
### Authors
Fengyi Li,Kayhan Behdin,Natesh Pillai,Xiaofeng Wang,Zhipeng Wang,Ercan Yildiz
### Background
文本分割基于句子的语义含义是一项基础任务，具有广泛的应用前景，尤其是在很多下游应用中。现有的方法大多需要大量标记数据的支持，或是只针对连续的文本片段。
### Innovation
作者提出了一种基于图形模型的无监督学习方法，名为BP-Seg。该方法不仅考虑了局部一致性，捕捉相邻句子通常更相关的直觉，还有效分组了那些在文本中距离较远但语义上相似的句子。这通过精心构建的图形模型上的信念传播来实现。
### Conclusion
在示例和长文档数据集上的实验结果表明，BP-Seg方法在无监督且非连续文本分割方面表现优于现有竞争方法。
## 1488. `cs.LG` - 伦理AI对年轻数字市民：一场关于隐私治理的呼吁 [PDF](https://arxiv.org/pdf/2503.11947), [HTML](https://arxiv.org/abs/2503.11947)
### Authors
Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha
### Background
数字平台上青年人工智能（AI）的迅速扩张引发了与隐私、自主权和数据保护相关的重大挑战。虽然AI驱动的个性化提供了增强的用户体验，但其通常缺乏清晰的伦理边界，使年轻用户容易受到数据利用和算法偏见的影响。因此，本文介绍了伦理AI治理的呼吁，主张建立一个确保以年轻人为中心的隐私保护、透明数据实践和监管监督的结构化框架。
### Innovation
提出了针对算法透明度、隐私教育、家长数据共享伦理和问责措施的关键领域急需干预。通过这种方式，旨在赋予年轻人对其数字身份的更大控制，并为政策制定者、AI开发者和教育者提供了构建更加公平和负责任的AI生态系统的可操作策略。
### Conclusion
本文呼吁采取行动建立伦理AI治理框架，确保青年中心的隐私保护、透明的数据实践和监管监督，同时为政策制定者、AI开发者和教育者提供行动策略，以构建更加公平和负责任的AI生态系统。
## 1489. `cs.LG` - 绿色气体抵消信用市场的多智能体强化学习 [PDF](https://arxiv.org/pdf/2504.11258), [HTML](https://arxiv.org/abs/2504.11258)
### Authors
Liam Welsh,Udit Grover,Sebastian Jaimungal
### Background
气候变化是人类未来的主要威胁，人为温室气体排放加剧了其影响。政府可以通过给企业设定排放限制并惩罚超额排放来控制这些排放。超排排放可以通过投资减排和捕获项目来抵消，这些项目产生的抵消信用可以提交给监管机构来抵消企业的超额排放，或者在企业之间进行交易。本文研究了抵消信用市场的有限智能体纳什均衡。计算纳什均衡是NP困难问题，利用现代强化学习技术Nash-DQN高效地估计市场的纳什均衡。
### Innovation
通过现代强化学习技术Nash-DQN来高效估计绿色气体抵消信用市场的纳什均衡，并验证了在气候主题金融市场上应用强化学习方法的有效性和在遵守纳什均衡时企业的显著财务节省。
### Conclusion
本文不仅验证了在气候主题金融市场上应用强化学习方法的有效性，同时也通过数值实验展示了企业遵循纳什均衡时可以实现的显著财务节省。
## 1490. `cs.LG` - CARL: 不依赖相机的光谱图像分析表示学习 [PDF](https://arxiv.org/pdf/2504.19223), [HTML](https://arxiv.org/abs/2504.19223)
### Authors
Alexander Baumann,Leonardo Ayala,Silvia Seidlitz,Jan Sellner,Alexander Studier-Fischer,Berkin Özdemir,Lena Maier-Hein,Slobodan Ilic
### Background
光谱成像在多种领域中具有潜力，包括医学和城市场景理解。它已经在遥感中确立了其重要性。然而，不同光谱相机在通道维度和捕获的波长方面存在差异性，阻碍了AI驱动方法的发展，导致特定相机模型通用性和跨相机应用场景不足。为了解决这些问题，我们介绍了CARL模型，一种用于跨RGB、多光谱和高光谱成像模式的相机无关表示学习模型。
### Innovation
我们提出了一种新的光谱编码器，其中包括自我注意-交叉注意机制，能够将光谱信息转换为学习到的光谱表示。通过一种基于特征的自监督策略，实现了空间光谱预训练。实验表明，该模型在医学成像、自动驾驶和卫星成像领域具有独特性，能够适应光谱异质性，在跨相机颜色变种的数据集上表现突出。
### Conclusion
我们提出的尺度和多功能方法将我们的模型定位为未来光谱基础模型的骨干结构，显示出广泛的应用前景。
## 1491. `cs.LG` - LLM-OptiRA：无线通信中非凸资源分配问题的LLM驱动优化 [PDF](https://arxiv.org/pdf/2505.02091), [HTML](https://arxiv.org/abs/2505.02091)
### Authors
Xinyue Peng,Yanming Liu,Yihan Cang,Chaoqun Cao,Ming Chen
### Background
在无线通信系统中解决非凸资源分配问题带来了重大挑战，超出了传统优化技术的能力范围。
### Innovation
提出了LLM-OptiRA框架，利用大型语言模型（LLMs）自动检测和转换非凸组件，使其可解，从而实现无线通信系统中非凸资源分配问题的全自动解决。LLM-OptiRA简化了问题解决过程，减少了对专家知识的依赖，并集成了错误修正和可行性验证机制，以确保系统的鲁棒性。实验结果显示，LLM-OptiRA在GPT-4上的执行率为96%，成功率达到了80%，在多种场景下的复杂优化任务中显著优于基线方法。
### Conclusion
LLM-OptiRA框架不仅能够简化非凸资源分配问题的解决过程，还能通过集成错误修正和可行性验证机制保证解决方案的鲁棒性，实验结果表明其在处理复杂优化任务时效果显著优于现有方法。
## 1492. `cs.LG` - UltraEdit：无需训练、领域和记忆的终身语言模型编辑 [PDF](https://arxiv.org/pdf/2505.14679), [HTML](https://arxiv.org/abs/2505.14679)
### Authors
Xiaojie Gu,Ziying Huang,Jia-Chen Gu,Kai Zhang
### Background
终身学习机制使得大规模语言模型（LLMs）能够适应不断变化的信息，通过不断更新其内部知识。一个理想的系统应当支持广泛而高效的更新，同时保留现有的能力，并确保可靠部署。因此，模型编辑作为一种专注于高效修订模型内部知识的技术显得尤为突出。尽管近期的一些方法已经取得重要进展，但在实践中大规模适应终身需求仍然缺乏高效的解决方案。
### Innovation
本文提出了一种名为UltraEdit的方法，这是一个无需训练、领域和内存的超大规模可扩展终身模型编辑方案。UltraEdit通过一步计算参数偏移，仅使用隐藏状态和梯度来实现参数更改，简化了方法并提高了效率。为提高终身场景下的可扩展性，UltraEdit引入了一种终身归一化策略，该策略不断更新特征统计，从而能够适应分布变化并在长时间内保持一致性。UltraEdit的编辑速度快于以前最佳方法超过7倍，同时使用不到四分之一的VRAM，使它成为唯一能够在24GB消费者级显卡上编辑7B LLM的方法。通过构建迄今为止最大的包含超过200万编辑对的数据集UltraEditBench，证明了该方法在编辑数量增加时仍然能够保持高准确度。
### Conclusion
本文通过全面的实验展示了UltraEdit在各种模型编辑场景中均具有更好的性能，更进一步地推进了安全和可扩展的终身学习。
## 1493. `cs.LG` - Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection [PDF](https://arxiv.org/pdf/2506.03162), [HTML](https://arxiv.org/abs/2506.03162)
### Authors
Damith Chamalke Senadeera,Xiaoyun Yang,Shibo Li,Muhammad Awais,Dimitrios Kollias,Gregory Slabaugh
### Background
随着监控摄像头的迅速普及，对自动暴力检测的需求日益增加。尽管CNNs和Transformers在提取时空特征方面表现出色，但在处理长周期依赖性和计算效率方面存在困难。现有的方法难以在复杂的监控场景中检测暴力活动。
### Innovation
本文提出了一个高效的架构——Dual Branch VideoMamba与门控类标记融合（GCTF）模型。该模型结合了双分支设计和状态空间模型（SSM）骨架，分别捕捉空间特征和时间动态。分支之间通过门控机制进行连续融合，增强了模型在复杂监控场景中检测暴力活动的能力。此外，本文还通过将RWF-2000, RLVS, SURV and VioPeru数据集合并创建了一套新的基准，确保训练集与测试集严格分离。
### Conclusion
实验结果表明，该模型在新的基准和DVD数据集上均实现了最先进的性能，同时在准确性和计算效率之间提供了最佳平衡，展示了SSM在可扩展、接近实时监控暴力检测中的潜力。
## 1494. `cs.LG` - 基于Jensen-Shannon散度的响应到上下文归因机制研究：检索增强生成中的上下文归因 [PDF](https://arxiv.org/pdf/2505.16415), [HTML](https://arxiv.org/abs/2505.16415)
### Authors
Ruizhe Li,Chen Chen,Yuchen Hu,Yanjun Gao,Xi Wang,Emine Yilmaz
### Background
检索增强生成（RAG）通过结合大规模语言模型（LLMs）和外部上下文来提高生成响应的准确性和可靠性。但当前方法由于计算密集程度高，在生成内容归因到特定上下文片段时仍面临挑战，通常需要大量的微调或人工注释。
### Innovation
本文介绍了一种基于Jensen-Shannon散度的新方法来归因响应到上下文（ARC-JSD），该方法能够在不依赖额外微调、梯度计算或代理建模的情况下，实现高效且准确识别关键上下文句子。在TyDi QA、Hotpot QA和Musique等广泛RAG基准测试上，使用不同规模的指令微调LLM表现出明显更高的准确性和显著的计算效率提升，相比之前的基于代理的方法。机制分析还揭示了负责上下文归因的具体注意力头和多层感知机（MLP）层，为RAG模型的内部工作机制及其影响提供了有价值的认识。
### Conclusion
研究结果表明，ARC-JSD方法能够有效且高效地解决RAG模型中的上下文归因问题，并为改善RAG的行为提供了新的见解。
## 1495. `cs.LG` - SNR和资源自适应的分布式IoT图像分类深度JSCC [PDF](https://arxiv.org/pdf/2506.10699), [HTML](https://arxiv.org/abs/2506.10699)
### Authors
Ali Waqas,Sinem Coleri
### Background
基于传感器的本地推断在物联网设备上面临严重的计算限制，通常需要将数据传输到噪音无线信道中的服务器进行处理。为解决这一问题，使用了基于DNN的联合源信道编码（JSCC）分组网络方案，以提取和传输相关的特征而不是原始数据。然而，现有的大多数方法依赖于固定的网络分组和静态配置，缺乏适应变化的计算预算和信道条件的能力。
### Innovation
提出了一种SNR和计算自适应分布式的CNN框架，适用于IoT设备和边缘服务器的无线图像分类。引入了一种基于学习的智能遗传算法（LAIGA），该算法能高效地探索CNN超参数空间，在给定FLOPs约束和SNR下优化网络配置。LAIGA智能地排除超出IoT设备计算预算的网络配置，并通过基于随机森林的学习辅助来避免对超参数空间的彻底探索，从而引入特定于应用的偏见。
### Conclusion
实验结果表明，所提出框架在低SNR和有限计算资源条件下优于固定分组架构和现有的SNR自适应方法，特别是在-10dB的SNR下，与现有的基于JSCC的SNR自适应多层框架相比，分类准确率提高了10%。该性能上的提升覆盖了IoT设备上可用的不同计算预算范围（1M到70M FLOPs）。
## 1496. `cs.LG` - 迭代人工智能代码生成中的安全性降级——一种关于悖论的系统分析 [PDF](https://arxiv.org/pdf/2506.11022), [HTML](https://arxiv.org/abs/2506.11022)
### Authors
Shivani Shukla,Himanshu Joshi,Romilla Syed
### Background
随着大型语言模型（LLMs）在代码生成中的快速采用，软件开发方式发生了变革，然而对于通过迭代LLM反馈下安全漏洞如何演变这一问题关注较少。本文通过针对400个代码样本以及四次风格的提示策略进行40轮改进的受控实验，分析了人工智能生成代码中的安全退化。
### Innovation
本文通过一个系统分析实验，研究了通过迭代Model反馈下安全漏洞的演变，提出了重新定义安全性的角度。研究发现，在仅仅5轮迭代之后，关键漏洞增加了37.6%，不同提示策略揭示了不同的安全脆弱性模式，挑战了迭代MLM改进代码安全性的假设，强调人力验证的重要性。
### Conclusion
本文提出务实指导方针，开发人员应重视LLM迭代过程中的人力验证，以防止在“改善”代码过程中引入新的安全问题。研究表明，人力资源在循环中具有关键作用，防止反向引入新的安全性问题。
## 1497. `cs.LG` - 多语言大模型中的位置偏见超越早期令牌偏见：模型特定和语言特定的位置效应 [PDF](https://arxiv.org/pdf/2505.16134), [HTML](https://arxiv.org/abs/2505.16134)
### Authors
Mikhail Menschikov,Alexander Kharitonov,Maiia Kotyga,Vadim Porvatov,Anna Zhukovskaya,David Kagramanyan,Egor Shvetsov,Evgeny Burnaev
### Background
大语言模型（LLMs）表现出位置偏见，即系统性地忽略特定上下文位置的信息。然而，这种偏见行为模式仍不清楚，特别是在不同的语言或模型之间。本文研究了五种不同的语言类型和五种模型架构中的位置偏见，并探讨了位置偏见与提示策略之间的互动，以及对输出熵的影响。研究发现，位置偏见主要是由模型驱动的，并且具有语言特定的变异性。引导模型认为背景信息与查询相关竟然会降低跨语言的准确性，这与常见的提示工程实践相悖。在上下文中心放置相关信息时会显著降低准确性，但输出熵峰值未明显反映这一变化趋势。
### Innovation
研究了五种不同类型语言和五种不同的模型架构中的位置偏见，揭示了位置偏见的主要驱动因素以及语言特定的变异性，并指出了引导模型认为背景相关造成的准确性降低意外现象。此外，研究发现放置在上下文中心的相关信息会导致显著准确性下降，而输出熵峰值不能明显反映这一趋势。
### Conclusion
位置偏见主要由模型驱动，且具有语言特定的变异性。引导模型认为背景相关降低了跨语言准确性。相关信息位于上下文中心时准确性显著下降，但输出熵峰值不能明显反映这一趋势。
## 1498. `cs.LG` - Distillation-Enabled Knowledge Alignment Protocol for Semantic Communication in AI Agent Networks [PDF](https://arxiv.org/pdf/2505.17030), [HTML](https://arxiv.org/abs/2505.17030)
### Authors
Jingzhi Hu,Geoffrey Ye Li
### Background
未来网络将连接大量人工智能代理，使其能够协作完成各种任务。与传统实体不同，这些代理适合语义通信，能够显著提高带宽效率。然而，实现语义通信需要代理之间的知识对齐，但实际上，代理具有各自独到的专业知识，因此存在知识不一致的问题。
### Innovation
本文提出了一种知识蒸馏增强的知识对齐协议（DeKAP），将每个代理的专家知识蒸馏为参数高效的低秩矩阵，并在网络中分配它们，使代理能够同时维护多个任务的知识对齐。通过大规模整数线性规划问题，同时最小化对齐损失、通信开销和存储成本，并开发了一种高效的贪婪算法实现知识对齐。
### Conclusion
通过计算机仿真，DeKAP在与传统方法相比，在通信和计算资源消耗最少的情况下建立了知识对齐。
## 1499. `cs.LG` - Mobi-π: 活用你的机器人学习策略 [PDF](https://arxiv.org/pdf/2505.23692), [HTML](https://arxiv.org/abs/2505.23692)
### Authors
Jingyun Yang,Isabella Huang,Brandon Vu,Max Bajracharya,Rika Antonova,Jeannette Bohg
### Background
通过学习视觉-运动策略能够在日益复杂的操作任务中表现出色，然而这些策略大多仅在有限的机器人位置和摄像头视角下进行训练，这导致策略在新机器人位置中表现不佳，尤其是像按按钮或者拧水龙头这样的精确任务。为了弥合这一差距，该论文提出了一个新问题：在新环境中寻找与训练时的视角分布相符的移动机器人基础姿态。
### Innovation
本文提出了一种新的策略活用方法Mobi-π，通过优化机器人的基础姿态来与学习策略的基础姿态对齐，从而改善策略在未见过的机器人基础姿态初始化条件下的表现。该方法利用3D高斯漩涡进行新视角合成，基于评分函数评估姿态适用性，并通过采样优化找到最优的机器人姿态。此外，还提出了Mobi-π框架，包括评估策略活用难度的指标、基于RoboCasa模拟的移动操作任务以及分析工具。
### Conclusion
在作者开发的模拟任务和实际环境中，该方法都优于基线方法，证明了其在策略活用方面的有效性。这一工作不仅改善了策略的泛化能力，同时也为移动平台上的精确操作提供了新的解决方案。
## 1500. `cs.LG` - BiomedSQL：基于生物医学知识库的科学推理文本到SQL [PDF](https://arxiv.org/pdf/2505.20321), [HTML](https://arxiv.org/abs/2505.20321)
### Authors
Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri
### Background
生物医学研究人员越来越多地依赖大规模结构化数据库进行复杂分析任务。然而，现有的文本到SQL系统在将定性的科学问题映射为可执行的SQL时常常力不从心，尤其是在需要隐式领域推理的情况下。为此，引入了BiomedSQL，这是首个为评估文本到SQL生成在生物医学知识库中的科学推理能力而明确设计的基准系统。
### Innovation
BiomedSQL针对结构化的生物医学知识库构建，包含68,000个问题/SQL查询/答案三元组，涵盖了基因-疾病关联、从组学数据推断因果关系和药物审批记录的数据集。BiomedSQL要求模型去推断特定于领域的标准，如全基因组显著性阈值、效应方向性或试验阶段筛选等，而不仅仅是依赖于语法翻译。研究使用了开源和闭源语言模型，并通过不同的提示策略和交互模式进行了评估。结果显示，尽管有显著差距，但现有的模型性能依然不佳，仅能达到一定程度的执行准确率。
### Conclusion
BiomedSQL为开发能够在结构化生物医学知识库上进行稳健推理的文本到SQL系统提供了新的基础。目前的数据集和代码已公开可用，旨在推进相关领域的研究和应用。
## 1501. `cs.LG` - 可扩展的基于上下文的Q学习 [PDF](https://arxiv.org/pdf/2506.01299), [HTML](https://arxiv.org/abs/2506.01299)
### Authors
Jinmei Liu,Fuhong Liu,Jianye Hao,Bo Wang,Huaxiong Li,Chunlin Chen,Zhi Wang
### Background
近年来，语言模型展示了显著的上下文学习能力，推动了对基于上下文的强化学习（ICRL）的探索，以扩展其在决策领域的应用前景。但由于涉及更复杂的动力学和时间相关性，现有ICRL方法在从子最优轨迹学习以及进行精确的上下文推理方面可能面临挑战。
### Innovation
本文提出了一种名为SICQL的创新框架，结合动态规划和世界建模，以实现高效奖励最大化和任务泛化，同时保留监督预训练的可扩展性和稳定性。设计了一种基于提示的多头变压器架构，同时预测最优策略和上下文价值函数。通过预训练一个通用的世界模型来捕捉任务相关信息，以构建紧凑的提示，促进快速和精确的上下文推理。在训练过程中，通过将状态价值函数拟合到Q函数的上限期望值，并使用优势加权回归进行上下文价值函数的策略提取，实现了迭代的策略改进。
### Conclusion
在广泛离散和连续环境中进行的实验展示了在不同基线类型上的一致性提升，特别是在从子最优数据学习时。
## 1502. `cs.LG` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大型语言模型（LLMs）在数学、事实问答和代码生成等领域取得了显著成绩，但在多种语言下的推理能力仍有待提升，特别是对于资源稀缺的语言如斯瓦希里语或泰语，LLMs 往往会误解提示或默认用英语进行推理，这导致了事实上的准确性、解释性和可信度问题。
### Innovation
提出了M2A方法，这是一种结合多尺度跨语言对齐和机器翻译问题上的语言一致性奖励的方法，旨在训练模型直接且准确地在目标语言中进行推理。此外，引入了GeoFact-X，一个基于地理的多语言事实推理基准，涵盖了五种语言：英语、印地语、日语、斯瓦希里语和泰语，以评估推理是否在目标语言中进行。
### Conclusion
M2A显著提高了多语言推理在数学和事实推理任务中的准确性，强调了基于推理的多语言强化学习对于跨语言泛化的关键性。
## 1503. `cs.LG` - 在宇宙学中多保真度仿真基于推理的转移学习 [PDF](https://arxiv.org/pdf/2505.21215), [HTML](https://arxiv.org/abs/2505.21215)
### Authors
Alex A. Saoulis,Davide Piras,Niall Jeffrey,Alessio Spurio Mancini,Ana M. G. Ferreira,Benjamin Joachimi
### Background
仿真基于推理（SBI）在不可获得闭合形式likelihood或模型时，可以用于宇宙学参数估计。然而，SBI依赖机器学习进行神经压缩和密度估计，这需要大型训练数据集，对于高质量的仿真来说成本极高。我们通过使用多保真度转移学习解决了这一限制，该方法结合了低成本、低保真度的模拟与少量高保真度的模拟。这种方法在源自包含两个独立模拟套件的水动力CAMELS多保真度数据集的暗物质密度图上得到了验证。利用仅含暗物质的N体模拟进行预训练，可以减少高保真度水动力模拟的需求，使得因子在8到15之间变化，具体取决于模型复杂度、后验维度以及使用的性能度量。通过利用价格较低的模拟，我们的方法可以实现高性能和准确的推断，同时显著降低计算成本。
### Innovation
提出了一种多保真度转移学习方法，将成本较低、保真度较低的模拟与少量高保真度模拟结合，通过预训练在仅含暗物质的N体模拟上减少高保真度水动力模拟的需求，从而提高推断性能并降低计算成本。
### Conclusion
结合低成本低保真度模拟和少量高保真度模拟，利用仅含暗物质的N体模拟进行预训练，可以在减少高保真度模拟需求的同时，实现高性能和准确的推断，从而显著降低计算成本。
## 1504. `cs.LG` - 深层变压器的两种失败模式及其避免方法：初始化时信号传播的统一理论 [PDF](https://arxiv.org/pdf/2505.24333), [HTML](https://arxiv.org/abs/2505.24333)
### Authors
Alessio Giorlandino,Sebastian Goldt
### Background
正确的初始设置对神经网络的训练和平稳性能至关重要。在transformers中，错误的初始化会导致自注意力层的两种失败模式：秩坍缩，所有标记坍缩成相似的表示；熵坍缩，高度集中的注意力分数导致训练不稳定。尽管前人研究了transformers的不同缩放模式，但在自注意力层的精确处理方面仍缺乏一个从理论上指导初始化的具体方法。该研究提供了一种分析信号通过深层transformers（包含自注意力、层归一化、跳跃连接和MLP）传播的理论框架，旨在通过理论分析和计算出训练性图来确定给定架构下的正确初始化超参数。研究还通过正式与统计物理中的随机能量模型建立类比来解决自注意力层的精确处理这一关键挑战，并分析反向路径中的梯度，确定初始化时梯度消失的范围。该项研究展示了其框架的灵活性，并提供了在初始化时避免transformers失败模式的理论视角，同时也给出了保证平稳训练的权重和残差连接尺度的定量预测。
### Innovation
该研究提出了一种理论框架，通过分析信号在深层transformers（包含自注意力、层归一化、跳跃连接和MLP）中的传播来解决初始设置的问题。该理论通过类比随机能量模型的方法，解决了自注意力层的精确处理难题，并通过计算训练性图来确定正确的初始化超参数。此外，研究还分析了反向路径中的梯度，确定初始化时梯度消失的范围，从而为避免transformers的失败模式提供了具体的指导。该项研究为理解和优化transformers的训练过程提供了新的理论基础。
### Conclusion
该研究提供了一种理论框架，揭示了transformers中自注意力层的两种失败模式，并通过精确分析初始设置及其对信号传播的影响，给出了确保顺利训练的具体建议。这项研究为理解和优化transformers模型的训练过程提供了重要的理论依据，同时也为设计和选择合适的初始化参数提供了指导，有利于提高transformers的训练效率和性能。
## 1505. `cs.LG` - pFedMMA: 适用于视觉语言模型的多模态适配器个性化联邦微调 [PDF](https://arxiv.org/pdf/2507.05394), [HTML](https://arxiv.org/abs/2507.05394)
### Authors
Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani
### Background
视觉语言模型（VLMs）如CLIP已经在零样本和少量样本设置中展现了卓越的泛化能力，但如何高效地将其适应到分散式的、异构的数据集仍然是一个挑战。虽然prompt调谐已经成为一种流行且参数效率高的个性化联邦学习方法，但现有的方法通常会在个性化效果和泛化能力之间做出权衡，尤其是在遇到未见过的类别或领域时表现较差。
### Innovation
本文介绍了一种名为pFedMMA的新框架，这是第一个利用多模态适配器进行视觉语言任务的个性化联邦学习框架。每个适配器包含特定模态的上卷积和下卷积层，以及一个全球共享的投影层，用于对齐跨模态特征。该框架通过让客户端本地适应个人化数据分布，同时合作训练共享投影层来提升整体泛化能力，从而在个人化和泛化之间取得最佳平衡，并且通信效率高，只需在通信过程中交换共享组件。
### Conclusion
通过在包含领域和标签转移场景的11个数据集上进行广泛实验，结果表明pFedMMA在个人化和泛化之间取得了最佳平衡，优于最近的联邦prompt调谐方法。
## 1506. `cs.LG` - 统一的基于经验风险最小化的灵活N元弱监督框架 [PDF](https://arxiv.org/pdf/2507.07771), [HTML](https://arxiv.org/abs/2507.07771)
### Authors
Shuying Huang,Junpeng Li,Changchun Hua,Yana Yang
### Background
近年来，N-元学习作为一种强有力的弱监督方法被提出，用以缓解监督学习中的注释负担。现有的N-元学习方法将双元学习扩展到高级别比较，能够适应各种实际场景，但它们往往依赖于特定任务的设计，缺乏统一的理论基础。本文旨在建立一个基于经验风险最小化的统一的N-元学习框架，旨在系统地整合点式未标注数据以提升学习性能，解决了理论基础和实际应用之间的不匹配问题。
### Innovation
本文提出了一种基于经验风险最小化的统一的N-元学习框架，通过统一N-元和点式未标注数据的数据生成过程，提出了一个无偏的经验风险估计器，能够扩展现有广泛的N-元模型，并建立了泛化误差界提供理论支持。为了应对由于负风险项引发的过拟合问题，采用了矫正函数调整经验风险。
### Conclusion
在基准数据集上的大量实验验证了提出框架的有效性，表明利用点式未标注数据可以在各种N-元学习任务中提升泛化性能。
## 1507. `cs.LG` - HEIST：用于空间转录组学和蛋白质组学数据的图基础模型 [PDF](https://arxiv.org/pdf/2506.11152), [HTML](https://arxiv.org/abs/2506.11152)
### Authors
Hiren Madhu,João Felipe Rocha,Tinglin Huang,Siddharth Viswanath,Smita Krishnaswamy,Rex Ying
### Background
单细胞转录组学和蛋白质组学已经成为了生物学数据驱动洞察的重要来源，可以使用先进的深度学习方法来理解细胞异质性和基因表达。空间组学数据的出现使得在组织环境中表征细胞成为可能，提供同时包含空间坐标和细胞内转录或蛋白质计数的信息。蛋白质组学通过直接测量蛋白质，提供了细胞功能的主要执行者和关键治疗靶点的补充视角。然而，现有的模型要么忽略了空间信息，要么未能理解和推理细胞内部的复杂遗传和蛋白质组程序，这两者共同作用以响应微环境线索，限制了它们对未知基因的泛化能力。因此，目前的模型无法推断细胞内部调控如何适应微环境信号。
### Innovation
本文提出了一种新的基于图的层级图变换器基础模型HEIST，用于空间转录组学和蛋白质组学数据。该模型将组织建模为层次化的图结构。更高层级的是空间细胞图，每个细胞在其空间位置由较低层级的基因共表达网络图来代表。HEIST通过进行层级内和层级间的消息传递，利用这种继承性来生成嵌入，从而能够推广到包括空间蛋白质组学在内的新型数据类型而不需重新训练。HEIST是通过在124种组织的15个器官中的2230万细胞上进行预训练，使用了空间感知对比和遮蔽自编码目标完成的。无监督分析揭示了HEIST嵌入实现了由先前模型所忽略的空间信息驱动的子群体。下游评估表明，HEIST在蛋白质组学数据的泛化能力、临床结果预测、细胞类型注释和多技术标准情况下基因推测方面表现出色，实现了目前的技术水平基准。
### Conclusion
该研究表明，HEIST模型能够有效地处理复杂的空间转录组学和蛋白质组学数据，揭示了细胞内部调节适应微环境信号的机制。HEIST展现了其强大的泛化能力，适用于不同类型的技术，并且在多个生物学应用中取得了最优的性能。
## 1508. `cs.LG` - MUCAR：跨模态多语言歧义解决基准测试 [PDF](https://arxiv.org/pdf/2506.17046), [HTML](https://arxiv.org/abs/2506.17046)
### Authors
Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu
### Background
多模态大语言模型（MLLMs）在多种视觉-语言任务中取得了显著进展，能够对具有清晰明确含义的图像-文本对进行处理。然而，现实语言和视觉环境中的内在歧义仍旧难以解决。现有的多模态基准通常忽视了语言和视觉的歧义，主要依赖于单模态上下文进行消歧，未能充分利用模态间的相互解释潜力。基于此，需要一种专门设计的基准来评估多模态歧义解决能力。该论文旨在填补这一空白，引入了MUCAR，一种用于评估多模态歧义解决能力的新型基准，特别是在多语言和跨模态场景中。MUCAR包含两个部分：一个是多语言数据集，通过与对应视觉上下文的解析，解决模糊的文本表达，另一个是双歧义数据集，通过系统地将模糊的图片与模糊的文本相结合，实现互斥消歧，并最终产生唯一的清晰解释。多模态模型的广泛评估揭示了与人类性能的显著差距，突显了未来研究中需要更复杂跨模态歧义理解方法的需求，进一步推动多模态推理的边界。
### Innovation
MUCAR是一种专为评估跨模态多语言歧义解决能力设计的新基准。该论文提出了多语言数据集和双歧义数据集，通过具体的上下文相互解决歧义，旨在填补现有基准对真实世界语言和视觉歧义处理不足的空白。此外，通过全面评估19种最先进的多模态模型与人类性能的对比，显示出需要进一步研究更为复杂的跨模态歧义理解方法，从而进一步推动多模态推理的前沿研究。
### Conclusion
广泛的实证研究表明，目前的多模态模型在跨模态歧义理解和消解方面仍存在较大差距。为了提高多模态推理的准确性和适用性，未来的研究应聚焦于开发更加复杂和有效的跨模态歧义处理方法，以便更好地应对现实世界中的多模态环境。
## 1509. `cs.LG` - 多模态循环网络预测自然电影脑响应 [PDF](https://arxiv.org/pdf/2507.17897), [HTML](https://arxiv.org/abs/2507.17897)
### Authors
Semih Eren,Deniz Kucukahmetler,Nico Scherf
### Background
准确预测大脑在观看自然刺激时的皮层响应需要能够整合视觉、听觉和语义信息的模型。论文介绍了一个分层级的多模态循环网络，该网络能够将预训练的视频、音频和语言嵌入映射到四名受试者观看80多小时由Algonauts 2025挑战提供的电影时记录的fMRI时序数据。该网络包括特定模态的双向RNN编码时间动态；其隐藏状态被融合，并传递给第二循环层；轻量化主体特定头层输出1000个皮层分区的响应。训练依赖于复合均方误差-相关性损失并有一个课程性质的训练过程，逐步从早期感觉区域转移到后期关联区域。通过平均100种模型变体进一步增强了系统的鲁棒性。该系统在竞赛排行榜中获得第三名，并在总体Pearson相关系数达到0.2094时取得了所有参与者中最高的单分区峰值分数（平均r=0.63），尤其是对于最具挑战性的受试者（受试者5）的表现尤为出色。
### Innovation
论文提出了一个分层级的多模态循环网络，能够整合视觉、听觉和语义信息，通过特定模态的双向RNN编码时间动态，并通过融合隐藏状态将信息传递给第二循环层。该系统还采用了复合均方误差-相关性损失以及逐步转移到更高级别功能区的课程训练方法。并且通过平均多个模型变体提升了系统的稳健性，最终在Algonauts 2025挑战中取得了优异的成绩。
### Conclusion
该体系结构提供了一个简单而可扩展的基础，用于未来多模态脑-行为基准测试。
## 1510. `cs.LG` - 由影响力驱动的课程学习以有限数据进行预训练 [PDF](https://arxiv.org/pdf/2508.15475), [HTML](https://arxiv.org/abs/2508.15475)
### Authors
Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth
### Background
课程学习是一种训练技术，通过按示例难度梯度（如从简单到复杂文档）来呈现数据给模型，该技术在预训练语言模型中显示出有限的成功。
### Innovation
研究课程学习在用一种更接近于模型训练中观察到的示例难度的指标取代传统的基于人类中心度的难度度量后，是否变得更具竞争力。具体来说，实验通过按单个训练示例的‘训练数据影响’排序来实验，这是一个估计各个训练示例对模型输出影响的分数。
### Conclusion
我们的课程训练模型在基准测试中比随机顺序训练模型高出了超过10个百分点，证实了课程学习对于语言模型预训练是有益的，只要采用一种更加以模型为中心的概念难度即可。
## 1511. `cs.LG` - 通过频率选择缓解混合频率的指数增长 [PDF](https://arxiv.org/pdf/2508.10533), [HTML](https://arxiv.org/abs/2508.10533)
### Authors
Michael Poppel,David Bucher,Maximilian Zorn,Nico Kraus,Philipp Altmann,Jonas Stein,Claudia Linnhoff-Popien
### Background
量子机器学习领域由于其相对于经典方法潜在的计算优势而迅速发展。角度编码作为特征映射的一个流行选择，被用于将经典数据嵌入到量子模型中，因其简单性和能自然生成截断傅里叶级数，同时提供了普遍函数近似的能力。在量子电路中高效的特征映射可以利用傅里叶频率的指数级别放大，而多维输入还会通过混合频率项引入额外的指数级别增长。尽管具有这种有希望的表达能力，但实际实现仍面临重大挑战。我们通过使用白盒目标函数的受控实验表明，即使所有相关频率理论上都是可访问的，训练失败仍可能发生。我们说明了两个主要已知原因导致优化失败：可训练参数相对于模型频率内容的不足，以及对ansatz动态李代数维度的限制，同时也发现了一个额外的参数负担：必须控制模型中不必要的非唯一频率。
### Innovation
我们提出了一种近乎零权重初始化的方法，以抑制不必要的重复频率。对于具有先验频率知识的目标函数，我们引入了一种频率选择方法，该方法减少了参数需求，并缓解了由于参数不足而可能使问题不可处理的指数级别增长。频率选择方法在10个随机选择的目标函数中实现了接近最佳性能（中位数 $R^2 thicksim 0.95$），所需参数仅占最佳标准方法的78%。
### Conclusion
通过频率选择的方法，我们有效地解决了混合频率的指数增长问题，实现了在参数限制下的最优性能，从而为量子机器学习的实际应用提供了新的改善路径。
## 1512. `cs.LG` - 图像分类中梯度提升的技巧和插件 [PDF](https://arxiv.org/pdf/2507.22842), [HTML](https://arxiv.org/abs/2507.22842)
### Authors
Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan
### Background
卷积神经网络（CNNs）通过深度架构中的层次特征学习在各种机器学习任务中取得了显著成功。然而，大量的层和数百万的参数往往使得CNNs在训练时非常耗时且需要大量的手动调优来发现最佳架构。
### Innovation
本文介绍了一种新的框架，通过结合动态特征选择方法与BoostCNN的基本原理来提升CNN性能。该方法采用了子网格选择和重要性采样两种主要策略，以指导训练向特征空间的信息区域发展。此外，还开发了一组算法，将提升权重直接嵌入到网络训练过程中的最小二乘损失公式中，这一整合不仅减轻了手动架构设计的负担，还提高了准确性和效率。在多个细粒度分类基准上的实验结果表明，我们的增强的CNN变体在预测性能和训练速度上明显优于传统的CNNs。
### Conclusion
实验结果显示，我们的增强CNN变体在预测性能和训练速度上都优于传统的CNNs，证明了该方法的有效性。
## 1513. `cs.LG` - APTx Neuron: 支持激活与计算统一的可训练神经元架构 [PDF](https://arxiv.org/pdf/2507.14270), [HTML](https://arxiv.org/abs/2507.14270)
### Authors
Ravin Kumar
### Background
现有的神经网络通常需要分别处理激活和线性变换，这导致了冗余的激活层，降低了计算效率和架构的简洁性。本文旨在提出一种新的、统一的神经计算单元——APTx Neuron，它将非线性激活和线性变换整合到一个可训练表达式中，从而消除了单独激活层的需求，使架构在计算效率和简洁性方面都得到了提升。
### Innovation
APTx Neuron是一种新颖统一的神经计算单元，它从APTx激活函数派生而来，融合了非线性激活和线性变换，使得网络架构更加高效且简洁。APTx Neuron遵循以下形式：$y = textstylefrac{text{∑}_{i=1}^{n} ((text{α}_i + tanh(text{β}_i x_i)) times text{γ}_i x_i + text{δ})}{text{n}}$，其中α_i，β_i，γ_i和δ_i都是可训练参数。研究结果显示，基于APTx Neuron的模型在MNIST数据集上仅用不到11个训练周期就可以达到高达96.69%的测试准确率，并且大约有332K个可训练参数，这表明与传统神经元相比，APTx Neuron在表达能力和计算效率方面具有优越性，为统一神经元设计和其构建的架构提供了一个新的范式。
### Conclusion
研究结果强调了APTx Neuron在表达能力和计算效率方面优于传统神经元，为未来的统一神经元设计和架构改进提供了新的范式。此外，基于APTx Neuron的模型在MNIST数据集上的表现验证了该创新对于提升神经网络效率的有效性。
## 1514. `cs.LG` - 从幻想到真实：大型语言模型事实核查与事实性评估综述 [PDF](https://arxiv.org/pdf/2508.03860), [HTML](https://arxiv.org/abs/2508.03860)
### Authors
Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam
### Background
大语言模型（LLMs）在训练过程中会接触到大量包含不准确或误导性内容的互联网数据，这可能导致这些模型生成错误信息。因此，进行严谨的事实核查变得至关重要。本文综述了人们如何评估LLM生成内容的事实准确性，重点关注幻觉、数据集限制以及评估指标的可靠性等关键挑战。
### Innovation
本文提出了五个研究问题，指导从2020年至2025年关于评估方法和缓解技术的文献分析。此外，还讨论了教育调优、多代理推理和基于检索的生成（RAG）框架等方法，旨在改善模型的准确性和上下文意识。研究表明，现有的评估指标存在局限性，验证过的外部证据非常重要，并且通过领域特定定制可以提高事实一致性。
### Conclusion
本文强调了建立更准确、更易于理解且更具上下文意识的事实核查框架的重要性，这些见解对提高模型的信任度具有重要意义。
## 1515. `cs.LG` - EigenBench: 一种比较行为量化的价值对齐衡量方法 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
人类价值观与人工智能系统的对齐是一个紧迫而尚未解决的问题。现有缺乏量化衡量这些价值对齐的标准方法，这限制了评估语言模型如何根据特定的价值观进行行为的能力。
### Innovation
本文提出了EigenBench，这是一个用于比较基准检测语言模型价值观的黑盒方法。该方法通过对多个模型在多种情景下相互评估后运用EigenTrust算法聚合判断结果，生成每个模型的价值对齐分数。此外，该方法通过收集人工评定意见并与EigenBench结果进行对比验证其有效性，并证明它可以在没有客观标签的情况下恢复GPQA基准排名。
### Conclusion
EigenBench通过无标签的方法对主观特性进行量化评估，这种方法不仅能够与人类评估者的结果高度一致，还能在缺乏客观标签的情况下恢复模型排名，打开了评估主观价值观的新视角。
## 1516. `cs.LG` - 在临界状态下，直觉在最大 Entropy 模型中产生 [PDF](https://arxiv.org/pdf/2508.06477), [HTML](https://arxiv.org/abs/2508.06477)
### Authors
Lluís Arola-Fernández
### Background
目前关于大型预测模型是否仅模仿其训练数据，还是能够产生真正的见解，缺乏物理解释。本文通过研究在一个学习过程中出现的亚稳态，即在下一词预测与未来路径熵之间达到关键平衡状态时形成的直觉机制，弥补了这一空白。
### Innovation
通过最小化原则施加最大 Entropy 原理，利用一个类似温度的控制参数 $boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{right)}}}}}}}}}}}}}}}}}}}}}}}}}$ 来发现问题中的直觉机制。通过在确定性迷宫中的随机行走进行训练，展示了丰富的相图，并发现了直觉的产生是由于模型在表明即有是什么和设想可以是怎样这两者之间的一种临界平衡局面，此外，这种临界相变与训练协议有很大依赖性，表现出多稳定性。
### Conclusion
结果表明，直觉作为模型在临界平衡状态下的一个涌现属性，可以有效地解释模型中从模仿到语义理解的转变，以及最终在多变性和复杂性之间的动态平衡。
## 1517. `cs.LG` - Partially Functional Dynamic Backdoor Diffusion-based Causal Model [PDF](https://arxiv.org/pdf/2509.00472), [HTML](https://arxiv.org/abs/2509.00472)
### Authors
Xinwen Liu,Lei Qian,Song Xi Chen,Niansheng Tang
### Background
在涉及复杂时空依赖关系的环境流行病学等研究领域中，因果推断由于未测量的混杂因素的存在而具有挑战性。现有方法中的一个重要空白是：目前的扩散式因果模型依赖于因果完备性或静态混杂的严格假设，这限制了它们的应用能力。
### Innovation
本文引入了部分函数动态回路扩散因果模型（PFD-BDCM），这是一种生成框架，旨在解决上述限制。该方法将有效的回路调整独特地整合到扩散采样机制中，以减轻未测量混杂因素导致的偏差。它通过地区特定结构方程和条件自回归过程捕捉复杂动态，并通过函数数据分析技术容纳多分辨率变量。此外，还提供了理论保证，建立了反事实估计的误差边界。
### Conclusion
在合成数据和实际空气质量案例研究中的广泛实验表明，PFD-BDCM 在性能上优于当前最先进的方法。
## 1518. `cs.LG` - 基于重复经颅磁刺激的脑电频谱识别 METH 成瘾者 [PDF](https://arxiv.org/pdf/2508.11312), [HTML](https://arxiv.org/abs/2508.11312)
### Authors
Ziyi Zeng,Yun-Hsuan Chen,Xurong Gao,Wenyao Zheng,Hemmings Wu,Zhoule Zhu,Jie Yang,Chengkai Wang,Lihua Zhong,Weiwei Cheng,Mohamad Sawan
### Background
目前，甲基苯丙胺（METH）成瘾者的渴求水平通常通过问卷评估。此研究探讨了利用神经信号是否可以提供更客观的结果，通过记录20名METH依赖参与者在接受重复经颅磁刺激前后（MBT和MAT）及20名健康对照（HC）的脑电图（EEG）信号，分析不同EEG子频带频率的相对带宽（RBP），探究变化特点及其在区分METH依赖者和健康人中的应用可能性。
### Innovation
研究首次利用EEG信号的变化特征，尝试通过随机森林（RF）分类器识别METH依赖者，发现γ频带的RBP在区分METH依赖创伤后应激障碍与健康控制组方面具有较高的准确性，特别是当接受与METH相关的视觉刺激时，γ频带的RBP可以作为生物标志物用于区分METH依赖者和健康人，并评估rTMS的有效性。此外，提出利用γ频带RBP的实时变化监测作为个性化闭环神经调节系统治疗METH成瘾的最佳参数之一。
### Conclusion
研究表明，利用功能性神经信号，特别是γ频带的相对带宽，可以通过随机森林分类器准确识别METH依赖者，具有临床应用前景。进一步，研究认为监测γ频带RBP的变化可以作为实现针对METH成瘾的个性化闭环神经调节系统的参数。
## 1519. `cs.LG` - DivLogicEval: 一个用于评估大规模语言模型逻辑推理能力的框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被认为是大规模语言模型（LLMs）衡量人类智能的重要标准。现有的基准可能同时包含多种推理技能，导致对逻辑推理技能的评估不准确。现有的逻辑推理基准在语言多样性上有限，并且其分布与理想逻辑推理基准的分布有偏差，可能会导致偏向性的评估结果。
### Innovation
提出了一个新的经典逻辑基准DivLogicEval，该基准由以反常方式组合的多种不同陈述的自然句子组成。还引入了新的评估指标，以减轻LLMs固有的偏差和随机性影响，从而确保评估结果更加可靠。
### Conclusion
通过实验，展示了在DivLogicEval中回答问题所需的战略逻辑推理程度，并比较了不同流行LMMs在进行逻辑推理方面的性能。
## 1520. `cs.LG` - 使用深度学习的显微镜图像增强技术进展：综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强对于理解和分析生物细胞和材料的微观细节至关重要。近年来，借助深度学习方法，显微镜图像增强技术取得了显著的进步。这篇综述论文旨在概述这一快速发展的前沿方法，关注其演变、应用、挑战及未来方向。主要讨论了超分辨率、重构和去噪等关键领域，并从当前趋势及其深度学习的实际应用价值方面进行了探讨。
### Innovation
借助深度学习方法，特别是在超分辨率、重构和去噪等关键领域的应用，显微镜图像增强技术正不断发展进步。这篇论文提供了这一领域的最新进展，系统地整理了相关技术的发展状态和应用前景，为未来的研究指明了方向。
### Conclusion
这篇综述论文总结了显微镜图像增强领域，特别是在深度学习助力下的最新进展，涵盖了超分辨率、重构和去噪的关键技术，并展望了未来的研究方向。
## 1521. `cs.LG` - 评估大型语言模型在网页API集成任务中的表现 [PDF](https://arxiv.org/pdf/2509.20172), [HTML](https://arxiv.org/abs/2509.20172)
### Authors
Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini
### Background
API集成是数字基础设施的关键组成部分，可以使软件系统连接和交互。然而，许多研究显示，编写或生成正确代码以调用API，特别是Web API，是一项挑战。尽管大型语言模型（LLMs）已流行于软件开发中，但它们在自动生成Web API集成代码方面的有效性尚未被探索。
### Innovation
本文提出了一个数据集和评估管道，以评估LLMs生成Web API调用代码的能力。通过实验发现，生成API调用提出了重大挑战，导致出现错误的结果，例如胡言乱语的终点、不正确的参数使用等。未测试的任何开源模型能够解决问题的比例不超过40%。
### Conclusion
尽管LLMs在软件开发中受到关注，但它们在自动生成Web API集成代码方面的表现仍然受限。实验结果揭示了生成API调用的挑战性，并且目前的开源模型难以处理此类任务。
## 1522. `cs.LG` - 残差离策略RL用于精细化行为克隆策略 [PDF](https://arxiv.org/pdf/2509.19301), [HTML](https://arxiv.org/abs/2509.19301)
### Authors
Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi
### Background
近期，行为克隆（BC）在视觉运动控制策略方面取得了显著进展，但这些方法受限于人类演示的质量、数据收集的繁琐人工工作以及离线数据的递减回报。相比之下，强化学习（RL）通过自主与环境交互训练代理并在多个领域展现了卓越成果。然而，直接在真实世界机器人上训练RL策略仍然具有挑战性，原因包括样本效率低下、安全问题以及从稀疏奖励中学习长期任务的困难，尤其是对于高自由度（DoF）系统.
### Innovation
该研究提出了一种结合BC和RL优势的残差学习框架。利用BC策略作为黑盒基础，学习每步的轻量级残差校正，通过样本高效离策略RL方法实现。该方法仅需要稀疏二元奖励信号，并能在模拟和真实世界中有效提升高自由度系统的操作策略。特别地，该研究展示了在拥有灵巧手的人形机器人中，首次在真实世界完成RL训练，达到了现有技术水平的新高度。
### Conclusion
实验结果表明，该方法在多种基于视觉的任务中展现出最先进的性能，指出了在真实世界部署RL的实际途径。
## 1523. `cs.SE` - 从代码库中提取概念知识以定位软件问题 [PDF](https://arxiv.org/pdf/2509.21427), [HTML](https://arxiv.org/abs/2509.21427)
### Authors
Ying Wang,Wenjun Mao,Chong Wang,Zhenhao Zhou,Yicheng Zhou,Wenyun Zhao,Yiling Lou,Xin Peng
### Background
代码定位是有效修复错误的关键，近期LLM和LLM代理方法虽然提高了准确性，但在大规模代码库中仍面临逻辑混杂和逻辑分散的问题，这使得准确识别故障代码元素变得困难。
### Innovation
提出了一种名为Repolens的新方法，通过抽象和利用代码仓库中的概念知识，将细粒度功能拆分并重组为语义上一致的功能模块，指导LLM。Repolens分为离线阶段和在线阶段：离线阶段提取并丰富概念知识生成仓库知识库；在线阶段检索问题特定术语，按相关度聚类和排名，通过最小侵入式提示增强集成到定位工作流程中。
### Conclusion
Repolens在SWE-Lancer-Loc基准测试中表现良好，提高了AgentLess、OpenHands和mini-SWE-agent等三种先进工具的性能，平均提升分别为Hit@k和Recall@k增加了22%和46%，并对不同模型（GPT-4o、GPT-4o-mini、GPT-4.1）具有通用性。消融研究和人工评估确认了构建的语义概念的有效性和可靠性。
## 1524. `cs.LG` - IntSR: 搜索和推荐的集成生成框架 [PDF](https://arxiv.org/pdf/2509.21179), [HTML](https://arxiv.org/abs/2509.21179)
### Authors
Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu
### Background
生成推荐已经作为一个有前景的范式，展示了在学术基准和工业应用中的出色成果。然而，现有的系统主要集中在检索和排名的统一上，而忽视了搜索和推荐任务（S&R）的集成。搜索和推荐的不同之处在于查询的形成：搜索使用明确的用户请求，而推荐依赖于隐式的用户兴趣。至于检索和排名的区别，关键在于查询是否为目标项本身。认识到查询作为中心要素，我们提出了一种集成生成框架IntSR，用于S&R。IntSR通过不同的查询模态整合这些分散的任务。
### Innovation
IntSR 是一个集成生成框架，用于搜索和推荐任务。它通过不同的查询模式整合分散的任务，解决了集成搜索和推荐行为带来的增加的计算复杂性以及动态变化的语料库引入的错误模式学习问题。
### Conclusion
IntSR 已经在Amap的不同场景中成功部署，带来了数字资产的GMV提高了9.34%，POI推荐的CTR提高了2.76%，以及旅行模式建议的ACC提高了7.04%的显著改进。
## 1525. `cs.LG` - 大型语言模型中的认知负荷限制：多步推理基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
本文探讨了大型语言模型（LLMs）在静态基准测试中的性能与其在动态、信息丰富环境中表现脆弱性的差距。尽管模型在单个任务上表现出色，但限制它们认知负荷下推理能力的计算极限仍不完全理解。研究通过设计一种新的基准测试（ICE），系统地操纵认知负荷因素，揭示了五种指令微调模型在多步推理任务上的显著性能差异。
### Innovation
本文引入了正式的认知计算负荷理论，提出了认知负荷因素（Context Saturation）和注意力剩余（Attentional Residue）是导致模型性能下降的关键机制。通过设计Interleaved Cognitive Evaluation (ICE)基准测试，系统操纵这些负荷因素，全面研究显示了不同开放源代码架构在高内在负荷任务中的显著性能差异。
### Conclusion
研究表明，认知负荷是推理失败的关键因素，并支持了在不确定性下幻觉即猜测的理论。研究指出，为了评估高级人工智能系统的真正弹性和安全性，需要进行动态的认知感知压力测试，如ICE基准测试所体现的那样。
## 1526. `cs.LG` - 使用潜在桥梁模型的音频超分辨率 [PDF](https://arxiv.org/pdf/2509.17609), [HTML](https://arxiv.org/abs/2509.17609)
### Authors
Chang Li,Zehua Chen,Liyuan Wang,Jun Zhu
### Background
音频超分辨率（SR），即将低分辨率（LR）波形上采样到高分辨率（HR）版本，近年来通过扩散和桥梁模型得到了探索，但之前的许多方法由于生成先验信息不足，往往导致上采样质量不佳。为了实现高质量的音频超分辨率，该研究提出了一种新的系统，其中使用潜在桥梁模型（LBMs）将音频波形压缩至连续的潜在空间，并设计LBMs实现从潜在域到潜在域生成的过程，使得这种潜在域到潜在域生成过程能够自然地匹配LR到HR的上采样过程，从而充分利用了LR波形中包含的指示性先验信息。为了在HR样本有限的情况下进一步增强训练效果，该研究引入了频率感知的LBMs，其中先验和目标频率作为模型输入，使得LBMs能够在训练阶段明确学习任意到任意的上采样过程。此外，该研究设计了级联LBMs，并提出了两种先验增强策略，首次尝试开启超过48kHz的音频上采样，并提供了一种无缝级联SR过程，提高了音频后期处理的灵活性。
### Innovation
该研究提出了一种新的系统，使用潜在桥梁模型（LBMs），将音频波形压缩至连续的潜在空间，并设计LBMs实现从潜在域到潜在域生成的过程；引入频率感知的LBMs，在训练阶段明确学习任意到任意的上采样过程；设计级联LBMs，并提出两种先验增强策略，首次尝试开启超过48kHz的音频上采样，提供了一种无缝级联SR过程，提高了音频后期处理的灵活性。
### Conclusion
在VCTK、ESC-50、Song-Describer基准数据集以及两个内部测试集上的全面实验表明，该研究实现了在48kHz以下任意频率的音频到超分辨率（SR）的前沿客观和感知质量，在声音、音频和音乐信号上均优于之前的方法，同时首次设置192kHz音频超分辨率的新记录。
## 1527. `cs.LG` - 扩大到多模态和多通道心音分类：使用合成和增强生物信号微调Wav2Vec 2.0 [PDF](https://arxiv.org/pdf/2509.11606), [HTML](https://arxiv.org/abs/2509.11606)
### Authors
Milan Marocchi,Matthew Fynn,Kayapanda Mandana,Yue Rong
### Background
心血管疾病（CVDs）是全球的主要死因，每年约有1790万人因此死亡。早期检测至关重要，因此需要准确且成本低廉的初步筛查方法。深度学习最近被应用于通过同步心音图（PCG）和心电图（ECG）信号以及多通道心音图（mPCG）来分类表明CVDs的异常心音。目前最先进的架构尚未充分利用，因为同步多通道数据集的可用性有限。通过增强数据集和预训练模型，可以克服这些限制，使基于变换器的架构能够有效训练。
### Innovation
这项工作结合了传统的信号处理和去噪扩散模型WaveGrad和DiffWave，以创建一个增强数据集，用于微调基于Wav2Vec 2.0的分类器在多模态和多通道心音数据集上。这种方法实现了最先进的性能。使用CinC 2016单通道PCG的数据集，准确率、非加权平均召回率、灵敏度、特异性和马修斯相关系数分别为92.48%、93.05%、93.63%、92.48%和94.93%、0.8283。使用CinC培训-数据集中的同步PCG和ECG信号，准确率、非加权平均召回率、灵敏度、特异性和马修斯相关系数分别为93.14%、92.21%、94.35%、90.10%和95.12%、0.8380。使用包含mPCG数据的便携式胸衣数据集，模型的准确率、非加权平均召回率、灵敏度、特异性和马修斯相关系数分别为77.13%、74.25%、86.47%、62.04%和0.5082。这些结果表明，当结合增强数据集时，基于变换器的模型在CVD检测中的有效性，并突显了它们在推进多模态和多通道心音分类方面的潜力。
### Conclusion
这些结果证明了基于变换器的模型在CVD检测中，当结合增强数据集时的有效性，突显了它们在推进多模态和多通道心音分类方面的潜力。
## 1528. `cs.LG` - 在甲烷卫星和机载成像光谱学成像中的云和云影分割的深度学习方法 [PDF](https://arxiv.org/pdf/2509.19665), [HTML](https://arxiv.org/abs/2509.19665)
### Authors
Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy
### Background
对于准确检索大气中的甲烷或其它痕量气体浓度，高效的云和云影检测是关键前置条件。这一挑战尤其影响到甲烷卫星（MethaneSAT）及其机载伴飞任务（MethaneAIR）。本研究使用机器学习方法解决高空间分辨率传感器的云和云影检测问题。远程感测数据中的云和云影需要被有效地筛查去除，因其偏斜甲烷检测结果，对排放量化造成影响。传统方法如迭代逻辑回归和多层感知器在空间连续性和边界定义方面能力有限，而深度学习模型显著提升了检测质量。
### Innovation
本研究评估了一系列传统和技术性深度学习架构（如UNet和Spectral Channel Attention Network (SCAN)）以应对云和云影检测挑战。最新发现表明，深度学习明显优于传统方法，特别地，SCAN方法在甲烷卫星数据上优于UNet，强调了对于特定卫星特征引入光谱注意的重要性。该研究提出了广泛而有效的深度学习解决方案，为现有和下一代高光谱任务提供增强的甲烷排放量化能力。
### Conclusion
经过深入评估，各种不同的机器学习技术，特别是先进的深度学习架构，提供了强大的、可扩展的解决方案，用于云和云影筛选，以增强高光谱任务的甲烷排放量化能力。所有数据和代码在公开可获取的网址中提供。
## 1529. `cs.LG` - 基于数据驱动的神经网络用于Windkessel参数校准 [PDF](https://arxiv.org/pdf/2509.21206), [HTML](https://arxiv.org/abs/2509.21206)
### Authors
Benedikt Hoock,Tobias Köppl
### Background
本文探讨了一种新的方法，用于在维度降低的一维-零维耦合血流模型中校准Windkessel参数。为了实现这一目标，作者设计了一个数据驱动的神经网络（NN），该网络基于仿真左肱动脉血压数据进行训练。研究的主要目的是评估该方法在不同场景中的有效性，尤其是当测量位置不明确或数据受到噪声影响时的场景。
### Innovation
本文提出了一种利用数据驱动的神经网络进行Windkessel参数校准的方法。该神经网络能够模拟整个仿真域中的脉冲波压力分布，无论是时间，空间还是参数变化。当对测量脉冲波进行校准时，通过扩展神经网络并重新训练，以实现更精确的校准效果。这种方法大大减少了计算负担且误差极小。
### Conclusion
通过对不同场景下Windkessel参数的校准效果进行评估，证明了所提出的方法的有效性和鲁棒性，特别是在测量位置不确定或数据存在噪声的情况下表现良好。
## 1530. `cs.LG` - 思维增强预训练 [PDF](https://arxiv.org/pdf/2509.20186), [HTML](https://arxiv.org/abs/2509.20186)
### Authors
Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei
### Background
随着大型语言模型（LLM）预训练计算资源的快速增长，高质量数据的供应仍然有限，这使得最大化可用数据的利用成为研究中的重要挑战。具体而言，由于固定模型容量的限制，某些高质量的标记难以学习，因为单个标记背后的逻辑可能极其复杂和深入。因此，需要一种方法来增强训练数据，使其更易于学习高质量的标记。
### Innovation
该论文提出了一种名为思维增强预训练（TPT）的通用方法，通过自动生成的思考轨迹来增强文本数据。这种方法可以有效增加训练数据的量，并通过逐步推理和分解使高质量的标记更加可学习。TPT方法被应用于从包含少量到大量数据的各种预训练配置中，涵盖使用受限数据和丰富数据的预训练以及使用强开源检查点的中期训练。实验结果显示，该方法在不同模型规模和家族中显著提高了LLM的性能。特别地，TTP将LLM预训练的数据效率提高了三倍，对于一个包含3亿参数的模型，在多个具有挑战性的推理基准测试中，后训练性能提高了超过10%。
### Conclusion
通过自动生成思考轨迹增强文本数据，显著提高了大型语言模型的训练效率和性能。TPT方法在不同规模和类型的模型上显示出潜在的实际应用价值。
## 1531. `cs.SE` - Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks [PDF](https://arxiv.org/pdf/2509.21533), [HTML](https://arxiv.org/abs/2509.21533)
### Authors
Shalini Chakraborty,Sebastian Baltes
### Background
IT行业为女性重返工作岗位提供了支持路径，如回实习计划、编程培训班和学习伙伴系统等。然而，学术界提供的重返机会相对有限。论文探讨了女性软件工程师背景人员重返学术或相关研究角色所面临的挑战，特别是由于怀孕、移民状态或缺乏弹性工作选项等原因导致的职业中断。尽管许多公司推行促进性别多样性的政策，但在学术机构中此类措施却不常见且往往未被充分认可。研究旨在对比分析不同类型国家机构中存在的政策和机会，以了解女性重返学术领域时与重返工业领域所面临的特定挑战，并提出支持透明招聘实践的建议
### Innovation
论文提出了一项多元文化的研究项目，旨在对比分析不同国家和学术机构中现有政策和机会，系统地探讨女性软件工程师重返学术领域的具体挑战，并提出支持措施。这填补了学术界在促进女性重返软件工程研究领域方面研究的空白
### Conclusion
研究将在多所大学和多个国家中开展，以便全面捕捉不同地区的多样化挑战和政策差异。最终，论文将提供支持透明招聘实践的建议，从而有助于改善女性重返学术领域的环境
## 1532. `cs.SE` - 软件工程数据建模与分析：基于多层抽象机制的框架 [PDF](https://arxiv.org/pdf/2509.21881), [HTML](https://arxiv.org/abs/2509.21881)
### Authors
Chaman Wijesiriwardana,Prasad Wimalaratne
### Background
本文提出了一个针对特定领域的软件分析框架，通过支持异质软件仓库的查询、建模和集成。该框架采用了多层抽象机制，具有领域特定的操作符。通过一个案例研究展示了该方法的潜力.
### Innovation
提出了一个新的框架，该框架采用多层抽象机制，支持异质软件仓库的查询、建模和集成。通过领域特定的操作符增强了框架的灵活性和适应性，展示了这种方法在软件工程数据建模中的创新应用.
### Conclusion
通过一个案例研究，本文展示了多层抽象机制在软件工程数据建模与分析框架中的潜力，该框架能够有效支持查询、建模和集成异质软件仓库。
## 1533. `cs.SE` - SecureAgentBench：在真实漏洞场景下评估安全代码生成 [PDF](https://arxiv.org/pdf/2509.22097), [HTML](https://arxiv.org/abs/2509.22097)
### Authors
Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo
### Background
大型语言模型（LLM）驱动的代码代理正在迅速改变软件工程，通过自动化测试、调试和修复等任务。然而，它们生成代码的安全风险已成为一个严重的问题。现有的基准虽然提供了有价值的见解，但仍然不够全面：它们往往忽略了漏洞引入的真正场景，或者采用狭隘的评估协议，未能覆盖功能正确性或新引入的漏洞。因此，本文提出了SecureAgentBench，这是一个包含105个编码任务的基准，旨在严格评估代码代理在安全代码生成方面的能力。每个任务包括实际的任务设置、基于真实世界开源漏洞的对齐背景以及静态分析检测新引入漏洞的全面评估。
### Innovation
SecureAgentBench是一个基准，包含105个编码任务，旨在严格评估代码代理在安全代码生成方面的能力。每个任务包括实际的任务设置、基于真实世界开源漏洞的对齐背景、以及结合功能测试、漏洞检查和静态分析检测新引入漏洞的全面评估。该基准评估了三种代表性的代理（SWE-agent、OpenHands和Aider）和三种最先进的LLM（Claude 3.7 Sonnet、GPT-4.1和DeepSeek-V3.1）。研究表明，当前代理在生成安全代码方面存在困难，即使表现最好的SWE-agent与DeepSeek-V3.1结合也只能实现15.2%的成功且安全的解决方案；一些代理虽然生成了功能正确的代码，但仍引入了新的漏洞，而且添加显式的安全指令并不能显著提高安全编码效果。
### Conclusion
这些发现将SecureAgentBench确立为安全代码生成的严格基准，并朝着LLM驱动的更可靠软件开发迈进。
## 1534. `cs.SE` - 利用LLM代理进行自动化视频游戏测试 [PDF](https://arxiv.org/pdf/2509.22170), [HTML](https://arxiv.org/abs/2509.22170)
### Authors
Chengjia Wang,Lanling Tang,Ming Yuan,Jiongchi Yu,Xiaofei Xie,Jiajun Bu
### Background
测试MMORPG（大型多人在线角色扮演游戏）是一项因游戏复杂性和频繁更新特性而变得至关重要的任务，但仍是一个劳动密集型的过程。传统的自动化测试方法难以实现高状态覆盖率和效率，而现有的基于LLM的游戏玩法规则有限，难以理解复杂的游戏状态-行动空间和长期复杂的任务。
### Innovation
提出了一种名为TITAN的LLM驱动智能MMORPG测试框架，包含四个关键组件：(1)感知并抽象高维游戏状态，(2)主动优化和优先级排序可用行动，(3)具备长期推理能力的动作跟踪记忆及反思自我修正，(4)使用LLM基的或增加诊断报告检测潜在的功能和逻辑漏洞。TITAN在两个大规模商业MMORPG中的原型测试中，相较于现有自动化游戏测试方法，实现了更高的任务完成率和更优的漏洞检测性能。
### Conclusion
TITAN检测到了之前未知的四个漏洞，优于现有方法。并且已经应用于实际的八个游戏QA管道中，证实了其作为LLM驱动游戏测试框架的实用影响力。实验结果为智能、通用测试系统的进一步发展提供了指导。
## 1535. `cs.SE` - 绿色提示工程：软件工程中提示设计的能源影响研究 [PDF](https://arxiv.org/pdf/2509.22320), [HTML](https://arxiv.org/abs/2509.22320)
### Authors
Vincenzo De Martino,Mohammad Amin Zadenoori,Xavier Franch,Alessio Ferrari
### Background
语言模型在软件工程中的应用日益增多，但其推理过程引发了越来越大的环境担忧。尽管有研究关注硬件选择和提示长度，但很少有人将语言复杂性作为可持续性因素进行研究。
### Innovation
本研究引入了绿色提示工程的概念，将语言复杂性视为影响能源消耗和性能的设计维度。通过使用开源小型语言模型对需求分类进行实证研究，发现提示的可读性可以影响环境可持续性和性能，并揭示了二者之间的权衡。
### Conclusion
简化的提示可以降低能源成本而不显著牺牲F1评分，对于实践者来说，这意味着可以在不牺牲性能的情况下减少环境影响；对于研究人员来说，这为绿色人工智能议程下的可持续提示设计指南和研究开拓了新的方向。
## 1536. `cs.SE` - 自动驾測系统中多模态现实差距评估 [PDF](https://arxiv.org/pdf/2509.22379), [HTML](https://arxiv.org/abs/2509.22379)
### Authors
Stefano Carlo Lambertenghi,Mirena Flores Valdez,Andrea Stocco
### Background
模拟测试是自动驾驶系统开发的基础，提供了跨多种驾驶场景的安全和可扩展的评估。然而，模拟与现实世界行为之间的差距（即现实差距）挑战了测试结果向部署系统中的转移。
### Innovation
本文进行了一个全面的实证研究，比较了四种代表性的测试模式：软件在环（SiL）、车辆在环（ViL）、混合现实（MR）以及全方位现实世界测试。使用配备真实传感器（相机和LiDAR）的物理小车及其数字孪生，实施每种设置，并对不同的室内驾驶场景进行评价。评估了各种测试模式在动作执行、感知和行为保真是程中的影响。
### Conclusion
SiL和ViL设置简化了现实世界动力学和感知的关键方面，而MR测试提高了感知的真实性，无需牺牲安全或控制。研究还确定了在不同测试模式下失败不会转移的条件，并分离了导致这些差异的现实差距的底层因素。研究结果为每种模式的优势和局限性提供了实用的见解，并为更稳健和可转移验证自动驾驶系统指明了途径。
## 1537. `cs.SE` - 没有手动指南：生成高质量Excel教程的自动和可扩展方法 [PDF](https://arxiv.org/pdf/2509.21816), [HTML](https://arxiv.org/abs/2509.21816)
### Authors
Yuhang Xie(1),Jian Mu(2),Xiaojun Ma(3),Chaoyun Zhang(3),Lu Wang(3),Mengyu Zhou(3),Mugeng Liu(1),Si Qin(3),Qingwei Lin(3),Saravan Rajmohan(3),Shi Han(3),Dongmei Zhang(3) ((1) Peking University, (2) Nanjing University, (3) Microsoft)
### Background
Excel 是一个在各个领域广泛使用的生产力工具，虽然功能丰富，但由于其复杂性，也给用户带来了挑战。这导致对支持有效使用的教程存在持久的需求。目前的教程由专家手动编写，每次软件发布后都需要频繁更新，且消耗大量人力成本。之前的工作尚未能够实现完全自动化的教程生成，因为现有的方法仍然依赖于手写的操作序列或示例材料。因此，这个领域存在改进空间和需求。
### Innovation
本文提出了第一个从自然语言任务描述直接生成Excel教程的框架。该框架首先实例化任务，然后通过“执行代理”组件在Excel中规划并执行解决方案，收集用于教程构建的中间产出物。随后，这些产出物被转换为结构化的Excel文档和视频演示。为了构建全面的教程语料库，从真实场景收集了1,559个任务描述。此外，设计了一个系统的评估框架，结合了大型语言模型和人类审阅者的评估。实验结果显示，该框架在执行任务成功率上相比最先进的基准提高了8.5%，生成的教程在可读性和教学效果上也表现更佳，往往接近或超过了专家手写的材料。重要的是，自动化管道消除了手动劳动，使生成高质量和可扩展的教程成为可能，时间成本降低了1/20。
### Conclusion
该框架能够自动、高效地生成高质量的Excel教程，解决了现有教程生成面临的难题，实现了可扩展和高质量的教程生成。这一研究对未来的技术进步具有重要的实践意义。
## 1538. `cs.SE` - AgentPack：由代理和人类共同创建的代码更改数据集 [PDF](https://arxiv.org/pdf/2509.21891), [HTML](https://arxiv.org/abs/2509.21891)
### Authors
Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha
### Background
传统的代码编辑模型调整通常基于从提交和拉取请求中提取的数据。假设提交信息描述了自然语言中的用户意图，而代码补丁描述了实现这些意图的修改。然而，之前收集的数据存在噪声问题：提交信息简短、人类编写的提交混杂了多个不相关的更改，并且许多提交来自简单的规则基础的机器人。近年来，软件工程代理的引入改变了这一格局。由人类和代理共同编写的代码更改更具有针对性，且目标更为明确。这些提交信息由LLM生成，详细描述了意图和理由。此外，这些更改提交到公开仓库时，会受到人类的隐式过滤，即维护者会剔除质量低下的提交。
### Innovation
该研究提出了AgentPack，一个包含130万由Claude Code、OpenAI Codex和Cursor Agent与人类共同编辑的代码更改的公共数据集，数据集涵盖截至2025年8月中旬的公开GitHub项目。研究描述了数据集的识别和编纂管道，量化了这些代理的采用趋势，并分析了这些更改的结构属性。结果显示，使用AgentPack进行微调的模型比使用仅基于人类提交的先前语料库进行训练的模型表现出更好的性能，表明使用软件工程代理提供公共数据来训练未来代码编辑模型的潜力。
### Conclusion
研究证明了基于代理技术的公共数据集对于调整大型语言模型以进行代码编辑的有效性，并强调了这种数据利用方式在提高代码编辑模型性能方面的潜力。
## 1539. `cs.SE` - Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective [PDF](https://arxiv.org/pdf/2509.21945), [HTML](https://arxiv.org/abs/2509.21945)
### Authors
Pengzhou Chen,Hongyuan Liang,Tao Chen
### Background
为了提升系统性能（例如延迟），许多调优工具采用代理模型来加速调优过程，而非完全依赖于昂贵的系统测量。尽管更准确的模型被认为是有益的，但先前的研究发现准确性并不是唯一的决定因素，这引发了代理模型在配置调优中实际作用的诸多疑问。因此，本文旨在通过fitness landscape分析揭示代理模型在配置调优中的多种作用，并提出了Model4Tune，一种自动化预测工具，用于估计最佳的模型-调优器对，而无需进行昂贵的调优器性能分析。该研究通过27000个案例进行实证研究，结果表明Model4Tune在79%-82%的情况下表现优于随机猜测，为理论研究和实践应用提供了新的视角和指导工具。
### Innovation
本文引入了fitness landscape分析的新视角，揭示了代理模型在配置调优中的多种作用；提出了Model4Tune，一种无需昂贵调优器性能分析即可预测最佳模型-调优器对的自动化工具；通过27000个案例的实证研究，证明了Model4Tune的有效性和优越性。
### Conclusion
研究结果不仅指明了未来研究的方向，还提供了一种实用的解决方法，帮助实践者评估最有效的模型进行配置调优。Model4Tune作为首个此类工具，能够在不进行昂贵调优器性能分析的情况下显著提高调优效率。
## 1540. `cs.SE` - TreeMind: 利用LLM增强的蒙特卡洛树搜索自动重现Android bug报告 [PDF](https://arxiv.org/pdf/2509.22431), [HTML](https://arxiv.org/abs/2509.22431)
### Authors
Zhengyu Chen,Zhaoyi Meng,Wenxiang Zhao,Wansen Wang,Haoyang Zhao,Jiahao Zhan,Jie Cui,Hong Zhong
### Background
自动从文本错误报告中重现Android应用程序崩溃是一个具有挑战性的任务，特别是在报告不完整和现代UI具有高组合复杂性的情况下。现有的基于强化学习或大规模语言模型的方法在面对此类场景时存在局限性，难以推断未观察到的步骤，重建底层用户操作序列来导航庞大的UI互动空间，主要原因是目标驱动的推理和计划能力有限。
### Innovation
我们提出了TreeMind，一种将大规模语言模型与定制化蒙特卡洛树搜索（MCTS）算法相结合的新技术，以实现有策略的UI探索来重现错误。这可能是首次将外部决策与LLM语义推理相结合以实现可靠错误重现的工作。通过将MCTS与语义推理相结合，我们引入了两个具有不同角色的LLM指导型代理：Expander根据当前UI状态和探索历史生成最有希望的动作，而Simulator估计每种动作导致成功重现的可能性。通过结合多模态UI输入和高级提示技术，TreeMind可以根据反馈进行导航，识别缺失但关键的用户动作，并逐步重建重现路径。
### Conclusion
我们在三个广泛使用的基准的数据集上对93个真实的Android错误报告进行了评估。实验结果显示，TreeMind在重现成功率方面显著优于四种最先进的基准。现实世界的案例研究表明，将LLM推理与基于MCTS的规划相结合，是自动错误重现的一个有前景的方向。
## 1541. `cs.SE` - Prophecy: 从神经元激活推断形式属性 [PDF](https://arxiv.org/pdf/2509.21677), [HTML](https://arxiv.org/abs/2509.21677)
### Authors
Divya Gopinath,Corina S. Pasareanu,Muhammad Usman
### Background
现有的前馈神经网络缺乏对内部逻辑和行为的深入理解，这使得验证和解释网络输出的正确性变得困难。Prophecy 工具的背景在于利用神经元在中间层的激活状态来自动推断前馈神经网络的形式属性。
### Innovation
Prophecy 工具创新性地通过提取基于神经元激活状态（值或开/关状态）的规则，作为前提条件来推断某种期望的输出属性，例如预测属于某个类别。这些规则代表了隐藏层中捕捉的网络属性，从而推断期望的输出行为。
### Conclusion
Prophecy 工具已经在不同类型模型和输出属性方面展示了其应用潜力，包括推断和证明神经网络的形式解释、组合化验证、运行时监控、修复等。其研究结果突显了在大规模视觉-语言模型的时代中的潜在应用价值。
## 1542. `cs.SE` - SK2Decompile：基于LLM的从骨架到表皮的两阶段二进制反编译 [PDF](https://arxiv.org/pdf/2509.22114), [HTML](https://arxiv.org/abs/2509.22114)
### Authors
Hanzhuo Tan,Weihao Li,Xiaolong Tian,Siyi Wang,Jiaming Liu,Jing Li,Yuqun Zhang
### Background
大型语言模型（LLMs）在二进制反编译方面展现出了潜力。然而，现有的基于LLM的反编译器在呈现程序的源级结构及其原始标识符时仍然存在局限性。本文介绍了一种新颖的两阶段方法SK2Decompile，从程序的“骨架”（语义结构）到“表皮”（标识符）进行反编译，以解决这一问题。具体而言，首先使用一个结构恢复模型将程序的二进制代码翻译为中间表示（IR），以提取程序的“骨架”，即保留控制流和数据结构，但用通用占位符遮蔽所有标识符。其次，使用增强学习奖励模型，奖励其生成符合编译器预期的语法和语义规则的程序结构。在第二阶段，使用一个标识符命名模型生成反映实际程序语义的有意义标识符。该两阶段反编译过程使反编译的正确性和可读性独立提升。评估表明，与最新的基准模型相比，SK2Decompile在多个数据集上表现出色，显著提升了可执行性率和语义相似度。
### Innovation
本文提出了一种新颖的两阶段反编译方法SK2Decompile，从程序的“骨架”（语义结构）到“表皮”（标识符）进行反编译，分别使用结构恢复模型和标识符命名模型。并且通过增强学习来优化模型输出，以提高反编译的正确性与可读性。
### Conclusion
SK2Decompile在多个基准数据集上表现优异，显著提升了程序的可执行性率（HumanEval数据集上提高了21.6%的平均可执行性率。在GitHub2025基准上，语义相似度提高了29.4%）,该方法提供了提高反编译的正确性和可读性的有效策略。
## 1543. `cs.SE` - 具体情境指导：初学者编程调试技能获取与保留的纵向研究 [PDF](https://arxiv.org/pdf/2509.22420), [HTML](https://arxiv.org/abs/2509.22420)
### Authors
Ziyi Zhang,Devjeet Roy,Venera Arnaoudova
### Background
初学者在错误定位方面存在系统方法缺乏的问题。尽管有抽象指导原则和一般具体步骤的研究，但特定情境指导的有效性仍不清楚。这项研究通过为期八周的研究，考察了不同指导方式的效果，以找出最适合作初学者的方法。
### Innovation
本研究创新性地设计了一种结合具体调试步骤与问题特定细节的具体情境指导方法（G4），与前人的抽象指导原则（G2）和一般具体步骤（G3）相比，该方法在初学者技能获取和保留方面显示出更好的效果。特别是，G4组在一节课后就达到了80%的正确率，并且在三周后仍保持了这一水平，显著优于其他各组。此外，这种方法在调试时间上也表现出更快的稳定性和优化效果。
### Conclusion
具体情境指导相对于抽象原则或情境无关步骤，能够更快地帮助初学者获取技能并保持更久。即使通过1-2节课也能看到显著改进，而长期实践则进一步优化并稳定效果。具体实例与抽象原则的结合或能弥补理论与实践之间的差距，为初学者提供更公平的学习路径。
## 1544. `cs.SE` - 利用增强分配函数检测的大语言模型提升指针分析 [PDF](https://arxiv.org/pdf/2509.22530), [HTML](https://arxiv.org/abs/2509.22530)
### Authors
Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Peng Di,Yao Guo,Ding Li,Xiangqun Chen
### Background
指针分析在许多静态分析任务中是基础组成部分，但其有效性常因堆分配的不精准建模而受损，特别是在使用用户自定义分配函数（AFs）的C/C++程序中。现有方法大多忽视这些自定义分配器，导致粗略的别名假设，从而降低了分析精度。
### Innovation
本文提出了AFD，这是一种新颖的技术，通过自动识别和建模自定义分配函数来增强指针分析。AFD采用混合方法：使用值流分析来检测简单封装，并利用大语言模型（LLMs）来推理具有副作用的更复杂的分配模式。这种方法的目标增强能够精确建模堆对象的每个调用点，实现类似上下文敏感的效果，而不增加相关开销。
### Conclusion
在15个真实世界的C项目上评估AFD，共识别出600多个自定义AF。将AFD集成到基线指针分析中，堆对象建模数量增加了26倍，别集集大小减少了39%，仅增加了1.4倍的运行时开销。此外，增强的分析提高了间接调用解析并发现了17个先前未检测到的内存缺陷。这些结果表明，对自定义分配函数进行精确建模为在大规模软件系统中改进指针分析提供了一种可扩展且实用的途径。
## 1545. `cs.SE` - MUG-10框架：移动应用开发中预防可用性问题 [PDF](https://arxiv.org/pdf/2509.21914), [HTML](https://arxiv.org/abs/2509.21914)
### Authors
Pawel Weichbroth,Tomasz Szot
### Background
如今，移动应用已成为日常生活中必不可少的工具，为用户提供随时随地的最新信息、沟通和娱乐服务。然而，硬件限制和不同用户群体的需求多样性的设计和开发挑战使可用性成为许多其他因素中最突出的方面之一。尽管如此，现有研究中鲜有直接探讨如何在移动应用开发中预防和处理可用性问题的有效对策。
### Innovation
本文通过调研20名移动软件设计与开发的专家，开发了一种新颖的框架——MUG-10框架，包含10条指南和3项具有广泛适用性的活动。此外，还强调在移动应用开发的各个阶段都需要积极与用户合作以测试并收集反馈。
### Conclusion
未来的研究可关注集中行动研究，评估我们推荐的有效性并在不同利益相关者群体中进行验证。此外，开发自动化工具以支持在移动应用开发过程中早期检测和缓解可用性问题的能力也是一个值得考虑的方向。
## 1546. `cs.SE` - GPU加速的循环信念传播算法在程序分析中的应用 [PDF](https://arxiv.org/pdf/2509.22337), [HTML](https://arxiv.org/abs/2509.22337)
### Authors
Haoyu Feng,Xin Zhang
### Background
循环信念传播（LBP）是一种在概率图形模型中广泛应用的近似推理算法，被应用于计算机视觉、错误纠正码、蛋白质折叠、程序分析等多个领域。然而，当应用于大规模程序分析时，LBP会遇到显著的计算挑战。现有的解决方案虽然利用了GPU的并行计算能力，但缺乏灵活的更新策略支持，且未能将逻辑约束与GPU加速相结合，导致实际性能不佳。
### Innovation
本文提出了一个面向程序分析的GPU加速LBP算法。通过提出一个统一的表示法以指定任意用户定义的更新策略，结合依赖分析算法支持多种更新策略。此外，基于之前利用Horn子句的局部结构简化消息传递的工作，通过分组消息以减少warp分歧，更好地利用GPU资源。实验结果表明，该方法在8个实际Java程序中的数据竞争分析中，相较于最先进的基于顺序的解决方案实现了2.14倍的加速，相较于最先进的基于GPU的方法实现了5.56倍的加速，同时保持了高准确性。
### Conclusion
实验表明，所提出的GPU加速LBP算法在程序分析中表现出优异的性能，特别是在数据竞争分析中的实际应用中，能够获得显著的加速性能。
## 1547. `cs.SE` - LLMs中的库幻觉：基于开发者查询的风险分析 [PDF](https://arxiv.org/pdf/2509.22202), [HTML](https://arxiv.org/abs/2509.22202)
### Authors
Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis
### Background
大型语言模型（LLMs）越来越多地用于生成代码，但它们仍然会产生幻觉，经常发明不存在的库。这些库幻觉不仅是有害的错误，还可能导致开发者的误导、构建中断，并使系统面临如slopsquatting等供应链安全威胁。尽管对这些风险有了越来越多的认识，但很少有人了解现实世界提示变化对幻觉率的实际影响。因此，作者进行了首个系统研究，探讨用户级别的提示变化如何影响LLM生成代码中的库幻觉。研究评估了六种不同的LLM，考察了两种幻觉类型：库名幻觉（无效导入）和库成员幻觉（来自有效库的无效调用）。研究调查了从开发者论坛提取的现实用户语言以及不同程度的用户错误（如一或多个字符的拼写错误和完全虚假的名称/成员）如何影响LLM的幻觉率。研究发现揭示了系统性漏洞：库名的一字符拼写错误在26%的任务中触发幻觉，虚假库名在99%的任务中被接受，以及与时间相关提示在84%的任务中导致幻觉。提示工程有潜力缓解幻觉，但仍然不一致且依赖于LLM。研究结果强调了LLMs对自然提示变化的脆弱性，并突显了迫切需要防止库相关幻觉及其潜在滥用的需求.
### Innovation
进行了首个系统研究，探讨用户级别的提示变化如何影响LLM生成代码中的库幻觉。研究评估了六种不同的LLM，并考察了两种幻觉类型：库名幻觉（无效导入）和库成员幻觉（来自有效库的无效调用）。研究调查了从开发者论坛提取的现实用户语言以及不同程度的用户错误如何影响LLM的幻觉率。结果揭示了提示工程有潜力缓解幻觉，但仍然不一致且依赖于LLM.
### Conclusion
研究结果强调了LLMs对自然提示变化的脆弱性，并突显了迫切需要防止库相关幻觉及其潜在滥用的需求。提示工程有潜力缓解幻觉，但仍然存在不一致性且依赖于LLM。为了提高代码的安全性和可靠性，需要进一步的研究和实践来改进LLM的鲁棒性，特别是在面对现实世界中的提示变化时。
## 1548. `cs.SE` - 您的AI，我的Shell：揭秘针对性AI编码编辑器的提示注入攻击 [PDF](https://arxiv.org/pdf/2509.22040), [HTML](https://arxiv.org/abs/2509.22040)
### Authors
Yue Liu,Yanjie Zhao,Yunbo Lyu,Ting Zhang,Haoyu Wang,David Lo
### Background
随着大型语言模型驱动的代理AI编码编辑器在软件开发中能够提高开发人员生产力，现代编码编辑器如Cursor不再仅限于代码补全，还具备更多的系统权限以支持复杂的编码任务（例如在终端运行命令、访问开发环境以及与外部系统交互）。然而，这使开发人员接近了“全自动编程”的梦想，同时也引发了新的安全问题。本研究首次探讨了针对这些高权限代理AI编码编辑器的提示注入攻击，展示了攻击者如何通过向外部开发资源注入恶意指令来远程利用这些系统，从而劫持AI代理执行恶意命令，将“您的AI”转变为“攻击者的命令行界面”。
### Innovation
本文提出了AIShellJack，这是一种自动测试框架，用于评估代理AI编码编辑器中的提示注入漏洞。AIShellJack包含314个独特的攻击载荷，覆盖了MITRE ATT&CK框架中的70种技术。使用AIShellJack，研究人员对GitHub Copilot和Cursor进行了大规模评估，结果显示执行恶意命令的成功率高达84%。此外，这些攻击被证明能够在广泛的攻击目标中有效，从初始访问和系统发现到凭据窃取和数据泄密。
### Conclusion
本研究揭示了代理AI编码编辑器面临的提示注入攻击的风险，并通过AIShellJack提供了一个自动化测试框架来评估这些攻击的漏洞。通过此项研究，开发人员和系统管理员可以更早地检测并防御此类攻击，从而提高软件开发的安全性。
## 1549. `cs.SE` - FeatBench: 评估振动编程中功能实现的编码代理 [PDF](https://arxiv.org/pdf/2509.22237), [HTML](https://arxiv.org/abs/2509.22237)
### Authors
Haorui Chen,Chengze Li,Jia Li
### Background
大规模语言模型（LLMs）的迅速发展催生了一种名为“振动编程”的新型软件开发范式，用户通过高层次的自然语言与编码代理交互。然而，现有的代码生成评估基准无法充分评估代理的振动编程能力。现有的基准不足之处在于需要代码级别的规范，或者过度关注问题解决，忽略了振动编程范式中功能实现的核心场景。
### Innovation
本文提出了一种名为FeatBench的新颖基准，专门针对振动编程中的功能实现。其创新点包括：1. 纯自然语言提示；2. 严格的、不断演进的数据收集流程；3. 全面的测试案例；4. 多元的应用领域。该基准能够更好地评估代理的振动编程能力，特别是在功能实现方面。
### Conclusion
我们在FeatBench上评估了两个最先进的代理框架和四个领先的LLM，发现功能实现面临重大挑战，成功率仅为29.94%。研究还揭示了一种“激进实现”策略，这种策略反而导致了严重的错误和卓越的软件设计。本文发布了FeatBench及其自动化数据收集管道和所有实验结果，以促进进一步的社区研究。
## 1550. `cs.SE` - 评估LLM在Web API集成任务中的表现 [PDF](https://arxiv.org/pdf/2509.20172), [HTML](https://arxiv.org/abs/2509.20172)
### Authors
Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini
### Background
API集成是数字基础设施的关键组成部分，使软件系统能够连接和交互。然而，许多研究显示，编写或生成正确代码以调用API（尤其是Web API）具有挑战性。尽管大型语言模型（LLM）在软件开发中变得流行，但对于自动化生成Web API集成代码的有效性尚未进行探索。
### Innovation
本研究提出了一套数据集和评估管道，旨在评估LLM生成Web API调用代码的能力。实验使用多个开源LLM揭示了生成API调用具有重大挑战，导致生成错误的终结点、错误参数使用等问题。所有评估的开源模型均未能解决超过40%的任务。
### Conclusion
研究结果表明，现有的开源LLM在Web API集成任务中生成API调用代码的能力有限，目前仍需进一步研究和改进以提高其准确性。
## 1551. `cs.SE` - 证明和奖励客户端多样性以增强区块链网络的韧性 [PDF](https://arxiv.org/pdf/2411.18401), [HTML](https://arxiv.org/abs/2411.18401)
### Authors
Javier Ron,Zheyuan He,Martin Monperrus
### Background
区块链网络的韧性很大程度上依赖于客户端的多样性，然而，大多数网络中客户端实现的分布却极为不均衡，这种单一文化使得网络面临巨大的风险，例如，如果主要客户端发生故障可能会导致巨额的经济损失。
### Innovation
提出了一个新的框架，结合可验证执行和经济激励，以证明并奖励使用少数客户端的行为，从而促进更健康、更稳定生态系统的发展。该框架利用了最先进的可验证计算技术（zkVMs和TEEs）生成客户端执行的加密证明，并通过智能合约进行验证。还通过修改流行的Lighthouse客户端并部署一种新型的多样性感知奖励协议来实施端到端的原型。实验结果量化了该方法的可行性及其背后激励机制的有效性，这是首次证明了一种实际和经济上可行的方法来鼓励和确保区块链网络中的可证明客户端多样性。
### Conclusion
这项工作展示了如何通过足够先进的技术和经济激励措施，实现区块链网络中的客户端多样性，从而增强系统的韧性。研究成果为设计旨在最大化分布式系统弹性的未来协议提供了指导。
## 1552. `cs.SE` - 使用对比学习预训练二进制代码表示 [PDF](https://arxiv.org/pdf/2210.05102), [HTML](https://arxiv.org/abs/2210.05102)
### Authors
Yifan Zhang,Chen Huang,Yueke Zhang,Huajie Shao,Kevin Leach,Yu Huang
### Background
二进制代码分析和理解对于逆向工程和计算机安全任务至关重要，尤其是在没有源代码的情况下。然而，与源代码相比，二进制代码缺乏语义，且对于人类工程师来说更难理解和分析。ContraBin通过结合源代码、注释信息和二进制代码来进行对比学习，以提高二进制代码分析和理解的任务效果。
### Innovation
ContraBin引入了三种关键组件：（1）一种初始预训练的主要对比学习方法，（2）一种简单纯插方法，用于整合源代码、注释和二进制代码，以及（3）一种中间表示学习算法，用于训练二进制代码嵌入。ContraBin是第一个将源代码、二进制代码和注释结合到对比学习中的语言表示模型，旨在推动二进制代码分析领域的研究。
### Conclusion
通过四种与二进制代码相关的下游任务的研究，表明ContraBin在算法功能分类、函数名称恢复、代码摘要和逆向工程方面显著提高了性能，评价指标包括准确率、平均精度和BLEU分数。ContraBin模型对于进一步研究提供了数据集支持。
## 1553. `cs.SE` - FGIT: 故障导向的微调(DFT)用于代码生成 [PDF](https://arxiv.org/pdf/2503.16913), [HTML](https://arxiv.org/abs/2503.16913)
### Authors
Lishui Fan,Zhongxin Liu,Haoye Wang,Lingfeng Bao,Xin Xia,Shanping Li
### Background
现代指令调优的大语言模型（LLMs）在代码生成方面取得了显著进步。然而，经过标准监督微调(SFT)调优的LLMs有时会产生看似合理的但功能上不对的代码变异。这很可能是由于标准SFT的局限性，它在优化过程中将所有令牌视为等价的，并未能强调正确实现与相似错误变异之间的敏感错误代码差异段落。这个问题可能源自标准SFT的限制，它在优化过程中未能区分敏感的错误代码段落与非敏感的代码段落差异。
### Innovation
为了应对这个问题，我们提出了故障导向的微调(FGIT)。这是一种新颖的微调技术，通过1) 在正确和错误的类似实现之间提取多粒度（行/令牌级别）的差异来识别敏感错误段落，2) 通过动态损失加权在训练期间动态优先处理这些段落。我们的方法在七个LLM在三个广泛使用的基准上的实验中平均实现了6.9%的pass@1相对改进，调优出的某些增强型6.7B LLM在性能上超过了一些闭源模型，例如GPT-3.5-Turbo。此外，我们的微调技术展示了强大的泛化能力，在各种指令调优的LLM上性能改进范围从3.8%到19.1%，并且我们的消融研究证实了不同粒度差异和超参数的贡献。
### Conclusion
我们的方法在代码生成中取得了显著的改进，并展示了较强的泛化能力。此外，通过不同的粒度差异和超参数，验证了方法的有效性。
## 1554. `cs.SE` - 在线优化的RAG工具使用和功能调用 [PDF](https://arxiv.org/pdf/2509.20415), [HTML](https://arxiv.org/abs/2509.20415)
### Authors
Yu Pan,Xiaocheng Li,Hanzhao Wang
### Background
在许多应用中，检索增强生成（RAG）通过嵌入（用户）查询并与预定义的工具/功能描述进行匹配，来驱动工具使用和功能调用。然而，由于嵌入模型不完美或描述不准确，常常会出现嵌入不对齐的问题，这可能导致检索错误和任务失败。
### Innovation
本文介绍了一种基于在线优化的RAG（Online-Optimized RAG），该框架在运行时持续适应实时交互中的检索嵌入，并通过最小反馈（例如任务成功）进行轻量级在线梯度更新。这种方法支持单跳和多跳工具使用、动态工具库存以及具有重排序的K-retrieval。
### Conclusion
在线优化的RAG在各种工具使用和文档检索场景中，有效提升了工具选择精度和任务完成率，提供了一条简单的实用路径来构建自改善的RAG系统。
## 1555. `cs.SE` - 代码语言模型能否学习寻求澄清的行为？ [PDF](https://arxiv.org/pdf/2504.16331), [HTML](https://arxiv.org/abs/2504.16331)
### Authors
Jie JW Wu,Manav Chaudhary,Davit Abrahamyan,Arhaan Khaku,Anjiang Wei,Fatemeh H. Fard
### Background
大型语言模型（LLMs）在代码生成任务中表现出色，但在代码生成结果与人类开发人员的问题解决策略之间仍存在差距。与人类不同，LLMs 在生成代码时倾向于忽略自然语言需求中的歧义，这导致了不可靠的解决方案。先前的研究主要集中在基于LLMs的迭代代码生成智能代理上，然而，这些模型需要能够识别并查询歧义需求，这是当前模型自身缺乏的能力，尤其是在人工智能代理领域，模型与人类需要协作。本研究探讨了是否可以对代码LLM进行微调以学习寻求澄清的行为。
### Innovation
提出了一种名为ClarifyCoder的框架，该框架使用合成数据生成和指令调优技术来微调代码LLM，使其能够识别歧义并在代码生成前请求澄清。该方法具有两部分：（1）一种数据合成技术，将需要澄清的场景添加到编程数据集中，以生成具备识别能力的训练数据；（2）一种微调策略，该策略教会模型优先寻求澄清而不是立即生成代码，面对不完整或歧义性的需求时。研究还包括将ClarifyCoder与标准微调相结合，对澄清意识和编程能力进行联合优化的实验分析。实验结果表明，使用ClarifyCoder的模型在模糊任务上的沟通率提升了63%（绝对值提升40%），好的问题率提升了52%（绝对值提升30%），显著提高了LLMs的沟通能力，同时保持了代码生成的性能。
### Conclusion
本研究通过ClarifyCoder框架展示了如何使代码LLM具备识别和请求澄清的能力，并证实了这种能力的有效性。这有助于提升LLMs在处理模糊和歧义需求时的灵活性和表现。
## 1556. `cs.SE` - 基于翻译方法的法律合同形式化验证（扩展版本） [PDF](https://arxiv.org/pdf/2509.20421), [HTML](https://arxiv.org/abs/2509.20421)
### Authors
Reiner Hähnle,Cosimo Laneve,Adele Veschetti
### Background
Stipula是一种专门为此类涉及资产转移和义务的法律合同建模的编程语言，具备可执行特性。本文通过将Stipula代码翻译成带有Java Modeling Language注释的Java代码，并使用演绎验证工具KeY进行形式化验证，提出了一种验证Stipula合同正确性的方法。
### Innovation
本文创新性地提出了一种将Stipula编程语言编写的合同通过翻译成Java代码并使用KeY工具进行自动形式化验证的方法。这种方法能够实现对大部分无环Stipula合同的完整自动验证。
### Conclusion
通过翻译方法，本文证明了一种通用演绎验证工具可以在Stipula的合同形式化验证中获得成功应用。
## 1557. `cs.SE` - 低资源和领域特定编程语言基于LLM的代码生成综述 [PDF](https://arxiv.org/pdf/2410.03981), [HTML](https://arxiv.org/abs/2410.03981)
### Authors
Sathvik Joel,Jie JW Wu,Fatemeh H. Fard
### Background
大型语言模型（LLMs）在生成流行编程语言的代码方面表现出色。然而，它们在低资源编程语言（LRPLs）和领域特定语言（DSLs）上的表现仍面临重大挑战，影响了包括350万Rust开发者在内的数百万开发者的充分发挥。LRPLs和DSLs固有的障碍，如数据稀缺以及DSL特有的语法结构，缺少在通用数据集中的良好表示，限制了LLMs的广泛应用，特别是在金融和科学等专业领域，这些编程语言提高了开发效率。尽管已有文献综述讨论了LLMs在软件工程中的应用，但它们大多没有专门聚焦于LRPLs和DSLs的挑战与机遇，该综述填补了这一空白，详细审查了LLMs在这些语言上的编码生成能力及限制，筛选了2020年至2024年间27000余篇发表的研究中的111篇论文，评估了各种程序代码生成技术与性能标准，以及数据集的收集与整理方法。
### Innovation
本综述首次系统性地梳理了当前LLMs在LRPLs和DSLs上的应用研究状态，方法论和挑战。首次具体聚焦于数据稀缺与DSL特有的语法结构等独特障碍的具体影响，提出了多种评估代码生成技术与评价标准，并总结了研究人员提出的新型架构，但仍缺乏统一的评价标准和基准数据集，为未来该领域的进展提供了重要的资源和基础。
### Conclusion
尽管已经有各种技术和指标，但在低资源和领域特定编程语言的代码生成评价方面仍缺乏一个标准方法和基准数据集。本综述为该领域的研究人员和实践者提供了资源，为未来在这些编程语言上的代码生成发展奠定了基础。
## 1558. `cs.SE` - 迭代AI代码生成中的安全性退化——关于悖论的系统分析 [PDF](https://arxiv.org/pdf/2506.11022), [HTML](https://arxiv.org/abs/2506.11022)
### Authors
Shivani Shukla,Himanshu Joshi,Romilla Syed
### Background
大型语言模型（LLMs）在代码生成中的快速应用已经改变了软件开发的面貌，但是人们很少关注通过迭代LLM反馈时安全漏洞是如何演化的。这项研究通过一项受控实验分析了AI生成代码中的安全退化，该实验使用了400份代码样本进行了40次“改进”，涵盖了四种不同的提示策略。实验结果显示，在仅仅五次迭代之后，关键漏洞增加了37.6%，不同提示方法之间出现了不同的漏洞模式。这些发现挑战了LLM迭代修补代码能提升安全性这一假设，并强调了在LLM迭代过程中加入人类专业知识的重要性以避免引入新的安全问题。
### Innovation
本研究通过受控试验系统分析了AI生成代码中的安全退化，评估了不同提示策略下的代码安全性演进情况，并强调了人工验证在LLM安全迭代中的必要性。这份研究提出了开发人员为了降低风险而应该遵循的实用准则，特别强调了在LLM每次迭代之间进行稳健的人工验证以防止假改进实际上是对安全性的破坏。
### Conclusion
研究发现，随着AI生成代码的迭代改进，关键安全漏洞呈现出增加的趋势，某些提示方法会带来不同的安全问题模式。这些结果显示，人们的假设即循环迭代LLM可以提高代码安全性是错误的，强调了在AI生成代码的循环迭代中结合人工验证的重要性以防止错误的安全性改进带来新的问题。因此，需要进一步研究和开发有效的安全验证和保证机制以增强AI生成代码的安全性。
## 1559. `cs.SE` - SuperCoder: 使用大型语言模型进行汇编程序超优化 [PDF](https://arxiv.org/pdf/2505.11480), [HTML](https://arxiv.org/abs/2505.11480)
### Authors
Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken
### Background
超优化是指将程序转化为更快速版本，同时保持其输入和输出行为不变。本文研究了大规模语言模型（LLM）能否作为超优化工具，生成比工业标准编译器优化后的代码更快的汇编程序。研究者构建了首个大规模基准测试，包含8,072个真实世界的汇编程序，每条程序平均130行，相比之下，以往的数据集限制在2至15行的无循环直线代码。研究还评估了23个LLM，并发现最强的基础模型Claude-opus-4的测试通过率为51.5%，平均速度提高了1.43倍。为提升性能，研究者运用强化学习微调模型，优化奖励函数以集成正确性和加速性能。从Qwen2.5-Coder-7B-Instruct（61.4%正确性，1.10倍加速）开始，微调后的模型SuperCoder达到95.0%正确性和平均1.46倍加速。
### Innovation
开发了首个大规模汇编程序超优化基准测试；引入强化学习微调模型，以提高正确性和加速性能；展示了LLM在汇编程序超优化中的应用，为未来程序性能优化研究奠定了基础，超越了编译器启发式方法。
### Conclusion
研究证明了LLM可以作为汇编程序超优化工具，为未来程序性能优化带来了新的研究方向，表明LLM在处理复杂程序优化上的潜力。
## 1560. `cs.SE` - 基于GPU温度模拟的车载深度学习框架测试方法 [PDF](https://arxiv.org/pdf/2509.15815), [HTML](https://arxiv.org/abs/2509.15815)
### Authors
Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen
### Background
深度学习模型在自动驾驶系统中扮演着重要角色，支持诸如环境感知等功能。为了加快模型的推理速度，这些深度学习模型依赖于汽车深度学习框架进行部署，例如Apollo中的PaddleInference和AutoWare中的TensorRT。然而，与在云端部署深度学习模型不同的是，汽车环境中的温度会从-40°C到50°C剧烈变化，严重影响GPU温度。另外，计算过程中产生的热量进一步导致GPU温度上升。这些温度变化会通过DVFS等机制导致GPU频率的动态调整。然而，现有的汽车深度学习框架并未考虑温度引起的频率波动的影响，如果部署在温度波动的GPU上，会导致诸多关键质量问题：计算密集型操作面临延迟或错误，高/混合精度操作出现精度错误，时间序列操作则遭遇同步问题。现有深度学习框架的测试方法无法检测到这些问题，因为它们忽略了温度对深度学习框架质量的影响。因此，提出了一种新的解决方案来解决这个问题——ThermalGuardian，一种基于温度波动环境的汽车深度学习框架测试方法。ThermalGuardian利用针对温度敏感操作的模型变异规则生成测试输入模型，基于牛顿冷却定律模拟GPU温度波动，并基于实时GPU温度控制GPU频率。
### Innovation
提出了一种基于温度波动环境的汽车深度学习框架测试方法，即ThermalGuardian。ThermalGuardian通过模拟GPU温度波动和实时控制GPU频率，确保在温度变化较大的车载环境中也能保持深度学习框架的稳定性和准确性。这种方法弥补了现有测试方法在温度影响下检测不到关键质量问题的不足。具体地，它生成的测试模型聚焦于温度敏感操作，根据牛顿冷却定律模拟温度变化，并采取实际温度调整频率的方法。
### Conclusion
ThermalGuardian是首款针对温度波动环境下的汽车深度学习框架的测试方法。通过针对性的测试模型和真实温度环境的模拟，它首次能够在车载GPU温度波动的条件下准确检测和预防深度学习框架的质量问题。这种方法对于确保自动驾驶系统在各种温度条件下的可靠性和性能具有重要意义。
## 1561. `cs.SE` - ACCeLLiuM：使用监督微调进行自动OpenACC指令生成 [PDF](https://arxiv.org/pdf/2509.20380), [HTML](https://arxiv.org/abs/2509.20380)
### Authors
Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes
### Background
随着GPU的普及及其硬件和并行编程框架变得愈加复杂，基于指导方针的并行编程标准如OpenACC在简化GPU编程方面起到了一定作用，但开发人员仍需一定的专业知识才能有效使用这些指导方针。本研究旨在通过引入ACCeLLiuM，一种专门用于生成用于数据并行循环的专家级别的OpenACC指令的大型语言模型系列，来进一步简化GPU编程过程。ACCeLLiuM基于从公共GitHub C/C++仓库中提取的4033组OpenACC pragma-loop数据对进行了监督微调，共分为3223组用于训练和810组用于测试。实验结果显示，基础的大型语言模型在生成正确的OpenACC pragmas方面存在明显差距，而使用ACCeLLiuM数据集微调的语言模型在87%的情况下能够生成正确的指令类型，且在50%的情况下能够生成精确的pragma指令，包括指令、子句、子句顺序和子句变量。即使生成的指令不完全精确，它们也经常按照正确子句的不同顺序出现，或包含额外能更精确地控制并行执行、数据移动和并发性的子句，提供超出严格字符串匹配的实际价值。
### Innovation
ACCeLLiuM是首批针对OpenACC指令生成进行专门监督微调的大型语言模型系列。它能够显著提高正确生成精准OpenACC指令的能力，尤其是在数据并行循环中的表现。与此同时，ACCeLLiuM还公开发布了模型、数据集和代码，以便其他研究者可以在此基础上进一步研究和构建，从而建立了基于大型语言模型的OpenACC指令生成可重复基准，降低自动将串行编写的程序卸载到GPU上的门槛。
### Conclusion
ACCeLLiuM通过监督微调在OpenACC指令生成方面取得了显著成果，能够显著提高生成准确OpenACC指令的能力，并通过提高数据并行循环处理的质量提供了实际价值。同时，ACCeLLiuM的开源目录将有助于建立基于大型语言模型的可重复OpenACC指令生成标准，降低自动化GPU卸载的门槛。
## 1562. `cs.SE` - RPG: 一种统一和可扩展的代码生成规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型在生成单个函数或单个文件代码方面表现出色，但在从零开始生成完整的代码库方面仍面临重大挑战。这一能力对于从高层次规范构建连贯的软件系统和实现自动化代码生成的全部潜力至关重要。生成过程需要在两个层次上进行规划：确定要构建的功能和模块（提案阶段）以及定义其实现细节（实施阶段）。当前的方法依赖于自然语言规划，这经常导致不清晰的规范、不一致的组件和脆弱的设计，原因是其固有的模糊性和缺乏结构。
### Innovation
为了应对这些限制，本文提出了Repository Planning Graph（RPG），这是一种结构化的表示方法，可以统一编码能力、文件结构、数据流和功能。通过用显式的蓝图替换自由形式的自然语言，RPG使长期规划的实现成为可能。在此基础上，作者开发了ZeroRepo，这是一个图驱动的框架，分为三个阶段：提案级别的规划、实现级别的建设以及图指导的代码生成和测试验证。为了评估，构建了包含六个真实项目和1052个任务的RepoCraft基准。ZeroRepo在RepoCraft上生成的代码行数约为36K，代码词数约为445K，分别是最佳基线Claude Code的3.9倍和68倍，并分别实现了81.5%的覆盖率和69.7%的测试准确率，相比Claude Code分别提高了27.3和35.8个点。进一步的分析表明，RPG模型了复杂的依赖关系，通过接近线性的放大使更复杂的规划成为可能，并提高了代理对代码库的理解，从而加速了定位过程。
### Conclusion
RPG提供了一种统一且可扩展的方式进行代码生成，成功地减少了规划中的模糊性和不确定性，促使生成的代码库具有更高的质量和更高的覆盖率及测试准确率。与传统方法相比，它展示出了显著的优势。
## 1563. `cs.LG` - 在放松平滑性下的去中心化随机非凸优化 [PDF](https://arxiv.org/pdf/2509.08726), [HTML](https://arxiv.org/abs/2509.08726)
### Authors
Luo Luo,Xue Cui,Tingkai Jia,Cheng Chen
### Background
本文研究了去中心化优化问题 $f(textbf{x})=frac{1}{m}textstyleref*{ref{xsum}}{} textbf{f}_i(textbf{x})$，每个局部函数 $f_i(textbf{x}) = textbb{E}textstyleref*{ref{expectation}}{}textbf{F}(textbf{x}; boldsymbol{textxi}_i)$ 是 $(L_0, L_1)$-平滑的，但可能是非凸的，其中 $boldsymbol{textxi}_i$ 的分布为 $textcal{D}_i$。背景在于现有方法在处理这一问题时往往不充分考虑局部函数非凸及随机性带来的挑战。
### Innovation
本文提出了一种新颖的算法——去中心化正则化随机梯度下降（DNSGD），该算法能够在每个局部代理处达到 $textepsilon$-平稳点。基于与梯度范数及一致性误差相关的Lyapunov函数，本文提出了一种新的分析去中心化一阶方法的框架，在放松平滑性假设下实现了这一目标。此外，通过样本复杂度和通信复杂度的上界设计及实验验证，显示了该方法的优越性。
### Conclusion
本文对此类优化问题展示了算法的复杂性上界结果，并验证了在特殊情况下，即$L_1=0$时上述结果接近现有最小上界。最后，通过数值实验展示了该方法的实验优势。
