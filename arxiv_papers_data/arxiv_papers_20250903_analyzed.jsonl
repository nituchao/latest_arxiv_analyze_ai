{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21307", "html_url": "https://arxiv.org/abs/2508.21307", "title": "MultiFluxAI 集成先进的代理协调检索系统的平台工程增强平台", "title_en": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "authors": "Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala", "background": "在产品工程的多个应用领域中，管理和整合大量的、多样化的数据源是一项挑战。现有的服务查询无法充分增强用户的数字生态系统中的参与度。", "innovation": "MultiFluxAI 平台利用先进的 AI 技术，如生成式 AI、向量化和代理协调化，提供动态且上下文感知的复杂用户查询响应，从而解决数据管理和整合的挑战，提升用户参与度。", "conclusion": "MultiFluxAI 平台通过提供动态且上下文感知的响应，增强了用户在数字生态系统中的参与度，并应对了当前及未来服务相关的查询需求，使平台工程更加高效。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21411", "html_url": "https://arxiv.org/abs/2508.21411", "title": "CARJAN: 以AJAN为基础的交通场景中基于代理的生成与模拟", "title_en": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "authors": "Leonard Frank Neis,Andre Antakli,Matthias Klusch", "background": "用户友好地模拟多种交互代理（如行人、自行车骑手和自动驾驶车辆）的城市交通场景一直是挑战。现有的工具和框架在处理动态交通场景生成和模拟方面具有局限性。", "innovation": "CARJAN是一种基于AJAN多代理工程框架和CARLA驾驶模拟器的新型半自动交通场景生成和模拟工具。它提供了一个视觉用户界面，用于交通场景布局的建模、存储和维护，并利用SPARQL行为树进行智能代理的决策和交互，为其在CARLA中的动态场景模拟提供支持。", "conclusion": "CARJAN提供了交互式、智能化代理生成和模拟虚拟交通场景的首个集成方法，能够在CARLA中进行动态交通场景的模拟与研究。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21441", "html_url": "https://arxiv.org/abs/2508.21441", "title": "epistemic遗忘和Spohn排名函数的具体化的一般框架", "title_en": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "authors": "Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald", "background": "遗忘作为一种知识管理操作会故意忽略代理的一部分内容，基于各种原因。文献中已经提出了两种主要的操作方法：一是变量消除，这是一种基于语法的方法，用于融合掉某些原子变量以聚焦于语言的其余部分，这种方法主要应用于逻辑程序和回答集编程；二是AGM信念修正理论中的收缩操作，这种操作在逻辑演绎下从信念集中移除命题。这些操作主要基于经典逻辑。", "innovation": "本文采取认识论视角，研究了具有更丰富语义结构的认识状态下的遗忘操作，但与命题逻辑存在明确联系。提出了五种普遍类型的认识遗忘，并通过Spohn的排名函数进行了具体化。借鉴逻辑编程和AGM理论中的遗忘公理，提出了丰富的公理框架来评估遗忘操作。并全面评估了具体遗忘操作，突出了不同遗忘操作之间的差异和共性。", "conclusion": "该研究提出了一种认识遗忘的一般框架，并结合了Spohn的排名函数，阐明了认识背景下的遗忘含义。通过公理化方法，评估了具体遗忘操作，提供了对遗忘操作差异和共性的全新见解。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM: 全面评估音频语言模型", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "音频语言模型（ALMs）的评估受到缺乏标准化基准测试的限制；现有大部分基准仅衡量一两个能力，并忽略了公平或安全性等方面。此外，不同评估方法对比不同模型的难度较大，因为不同的评估方法往往测试的模型有限，使用的提示方法和推理参数也各不相同。", "innovation": "介绍了AHELM基准测试，该基准汇总了各类数据集，包括两个新的合成音频-文本数据集PARADE和CoRe-Bench。AHELM从10个方面评估ALMs，涵盖音频感知、知识、推理、情绪检测、偏见、公平性、多语言性、鲁棒性、有害内容和安全性。基准还标准化了提示、推理参数和评估标准，以确保模型之间的公正比较。测试了来自3家开发者的14个已开放权重和闭合API的ALMs以及3个基准系统。", "conclusion": "结果表明，Gemini 2.5 Pro在5个方面处于领先地位，但在特定ASR任务中表现出群体不公平性。基准测试结果表明，即使只有语音到文本的能力，基准系统在AHELM中的表现也较为出色。所有原始提示、生成结果和输出均可在网站上查看。AHELM旨在成为一个持续更新的基准测试。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21449", "html_url": "https://arxiv.org/abs/2508.21449", "title": "从不完整状态和动作的轨迹中学习提升的动作模型", "title_en": "Learning Lifted Action Models From Traces of Incomplete Actions and States", "authors": "Niklas Jansen,Jonas Gösgens,Hector Geffner", "background": "该研究探讨了从滑块拼图的随机状态-动作轨迹中学到提升的STRIPS模型的问题，其中状态仅表示棋块的位置，动作仅包含上下左右标签，没有对象参数。这是一个具有一定挑战性的问题，因为观察到的状态不完全对应STRIPS状态，缺失了棋块位置等原子事实；同时，观察到的动作也不完全对应STRIPS动作，无法揭示所有动作的对象和条件。现有方法一般假设轨迹中的动作是完整的STRIPS动作或所有领域谓词都是可观测的。本研究关注更贴近实际情况的场景，其中观察到的谓词揭示了世界的状态但不全面，动作揭示了进行选择所需的参数但不揭示进行建模所需的参数。为了解决这些问题，研究引入了一种名为STRIPS+的STRIPS变体，并提出了学习算法SYNTH。", "innovation": "研究引入了STRIPS+模型，这是一种处理隐式参数和部分量化的STRIPS变体。此外，研究提出了一种新的学习算法SYNTH，它可以从STRIPS+状态-动作轨迹中构建分层的预条件表达式或“查询”，以解析唯一对象并为STRIPS+ ground动作参数。", "conclusion": "SYNTH算法的正确性和完整性得到了证明，并通过对来自现有STRIPS域的STRIPS+模型状态-动作轨迹进行实验测试，证明了其可扩展性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "多Ontology集成与双轴传播在医学概念表示中的应用", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "现有的文献主要关注从单一的本体系统或多个本体系统（例如疾病、药物和程序）中独立地融入领域知识，但没有将它们整合到统一的学习结构中。这种方法使得概念表示学习通常局限于同一本体内部的关系，忽略了跨本体之间的连接。", "innovation": "在本论文中，提出了一种名为LINKO的大型语言模型增强的集成本体学习框架，该框架通过在异构本体系统中实现双轴知识传播，同时利用多个本体图，增强了医学概念表示学习。LINKO首先利用大型语言模型对本体概念嵌入进行图检索增强初始化，并通过一个定制提示进行进一步增强；其次，它通过两种轴线进行知识传播学习医学概念：(1)同一本体层次间的垂直传播；(2)同一层次内的平行水平传播。", "conclusion": "通过在两个公开数据集上进行广泛的实验，验证了LINKO相对于最先进的基线的优势性能。LINKO还证明了在数据有限和罕见疾病预测场景中的鲁棒性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21365", "html_url": "https://arxiv.org/abs/2508.21365", "title": "通过使用大型语言模型基于强化学习在游戏中学习推理：Think in Games", "title_en": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "authors": "Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang", "background": "大型语言模型（LLMs）在复杂推理任务（如数学和编程）上表现出色，但在简单互动任务上却常常遇到困难，而这些任务对于年幼的孩子来说却是轻而易举完成的。这种差异揭示了宣言性知识（知道某事）和程序性知识（知道如何做某事）之间的一个关键差距。传统强化学习（RL）代理可以通过与环境互动来获得程序性知识，但它们通常作为黑盒工作，并需要大量的训练数据。相比之下，LLMs拥有广泛的世界知识和推理能力，但无法有效地将这种静态知识转化为互动环境中的动态决策。", "innovation": "本文提出了Think in Games（TiG）框架，该框架使LLMs能够通过直接与游戏环境互动来发展程序性理解，同时保留其推理和解释能力。TiG将基于RL的决策制定重新定义为语言建模任务：LLMs生成语言引导的策略，在基于环境反馈的在线强化学习中反复迭代优化。我们的实验结果表明，TiG成功地填补了宣言性和程序性知识之间的差距，与传统的RL方法相比，它在数据和计算需求上显著减少的同时，实现了竞争力的性能。此外，TiG为每个决定提供了逐步自然语言解释，极大地提高了复杂互动任务中的透明性和可解释性。", "conclusion": "TiG框架成功地通过直接与游戏环境的互动来弥合LLMs在程序性和宣言性知识之间的差距。与传统的强化学习方法相比，它不仅在性能上具有竞争力，还在数据和计算需求方面展现出更低的要求。此外，TiG提供了逐步的自然语言解释，这极大地提高了复杂互动任务中的透明性和可解释性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21475", "html_url": "https://arxiv.org/abs/2508.21475", "title": "MMSearch-Plus：一个简单但具有挑战性的多模态浏览代理基准", "title_en": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "authors": "Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong", "background": "大规模多模态语言模型（MLLMs）越来越多地被部署为网络代理。然而，许多多模态浏览基准可以通过浅层、固定的工作流解决，这些工作流依赖于高召回率的图像搜索和局部文本掩码，而这些工作流未能解决细粒度的视觉推理、来源验证和长期工具使用等真正的多模态挑战。", "innovation": "研究人员引入了MMSearch-Plus，这是一个包含311项任务的基准，这些任务需要高度的多模态理解，并保留了强大纯文本浏览套件的难度特征。每个项目都设计有多个局部的弱视觉信号，需要通过迭代的文字-图像搜索、然后在检索噪声下进行交叉验证才能解答问题。通过时空外推方法，问题的设计要求从空间线索（微文字、部分外观、布局、地标所示等）和时间线索（播放覆盖信息、季节性环境等）推断出不在图像中的事实，如事件、日期和地点。", "conclusion": "强大的代理（o3）在没有搜索的情况下达到了15.1%的准确率，在使用递归搜索的情况下达到了36.0%的准确率，而一个强大的开源模型（Qwen-2.5-VL-72B-Instruct）在没有搜索的情况下为0.0%，在20轮搜索后达到6.9%。除了答案的准确性，研究人员还评估了边界框生成和剪辑图像搜索，并进行了错误分析，揭示了来源验证、部分推理和长期计划中的失败。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、象征性和情境化：通过认知支撑增强LLM教学", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究了建筑学先入为主的偏见如何影响大型语言模型（LLMs）在教学对话中的认知行为。利用控制性消融试验，研究者评估了模型输出，并使用专家设计的评分表来评估支撑、响应能力、象征推理和对话记忆。这项研究基于认知导向的评估框架，以便在早期实验中实现可扩展、系统的架构变体比较。初步结果表明，完整系统在与基线变体的对比中表现更优。分析显示，删除记忆或象征结构会削弱关键认知行为，包括抽象、适应性探查和概念延续性。这些发现支持了一个处理级解释，即架构支撑可以在LLMs中可靠地塑造新兴教学策略。", "innovation": "提出了一种符号支撑机制配合同短期记忆架构，旨在促进教学性对话中的适应性和结构化推理。通过五种系统变体的控制消融，采用专家设计的评分表评估了模型输出，实现了基于认知导向的评估框架下的初步结果。这些结果表明，完整系统优于基线变体，而删除记忆或符号结构会削弱关键认知行为。", "conclusion": "研究表明，完整的系统架构支撑比基线变体更加有效。缺乏记忆或符号结构会显著损害LSTM的认知行为。研究支持了架构支撑可以在LLMs中可靠地影响教学策略的观点。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21521", "html_url": "https://arxiv.org/abs/2508.21521", "title": "自动规划中的反事实场景", "title_en": "Counterfactual Scenarios for Automated Planning", "authors": "Nicola Gigante,Francesco Leofante,Andrea Micheli", "background": "反事实解释(CEs)是一种强大技术，通过展示如何最小改变输入使模型产生不同的输出来解释机器学习模型。在自动规划领域，类似的方法也被提出，CEs通过最小修改现有计划以满足不同目标来定义。然而，这些解释无法涵盖问题本身的高级特性。本文提出了一种基于反事实场景的新解释范式，通过识别最小改变规划问题，使新计划满足特定目标公式，从而解决了这一局限性。", "innovation": "提出了基于反事实场景的新型解释范式，通过识别最小改变规划问题，使新计划满足特定目标公式，解决了传统方法不能涵盖问题高级特性的问题。", "conclusion": "论文基于显式计划的量化，提出了两种基于反事实场景的质化实例，并分析了在不同类型的变更下生成反事实场景的计算复杂性。证明生成反事实场景的成本通常仅与计算原始规划相当，从而展示了该方法的实用性和潜在的应用程序。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21595", "html_url": "https://arxiv.org/abs/2508.21595", "title": "具有确定性动力学的Dec-POMDP的可伸缩求解方法", "title_en": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "authors": "Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes", "background": "许多高级的多智能体规划问题，包括多机器人导航和路径规划，可以有效建模为确定性的动作和观察。该研究聚焦于此类领域，并引入了确定性分布式部分观测马尔可夫决策过程（Det-Dec-POMDPs）这一概念，这是一种由确定性转换和条件于状态和联合动作的确定性观察所定义的Dec-POMDP子类。", "innovation": "提出了实用的求解器Iterative Deterministic POMDP Planning（IDPP），该方法基于经典的联合均衡搜索策略框架，并针对当前的Dec-POMDP求解器无法有效处理的大型Det-Dec-POMDP进行优化。", "conclusion": "该研究为具有确定性动力学的Dec-POMDP提供了一种可伸缩的求解方法，使得即使是大型的Det-Dec-POMDP也能被有效处理，从而提高了多智能体系统的规划效率和可行性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21540", "html_url": "https://arxiv.org/abs/2508.21540", "title": "HealthProcessAI: 一种增强型医疗流程挖掘技术框架与理念", "title_en": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining", "authors": "Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi", "background": "过程挖掘作为一种理解复杂医疗工作流的强大分析技术已经崭露头角。然而，其应用面临技术复杂性高、缺乏标准化方法以及实用培训资源有限等障碍。", "innovation": "引入了HealthProcessAI，这是一个基于生成式人工智能（Generative AI）的框架，旨在简化医疗和流行病学中的流程挖掘应用。该框架通过集成多个大型语言模型（LLMs）实现自动流程图解释和报告生成，从而帮助将技术分析转化为可理解的输出。通过使用败血症进展数据进行概念验证，并通过OpenRouter平台评估五个最先进的LLM模型的输出，验证了技术性能和自动LLM分析生成报告的能力。评价结果显示，Claude Sonnet-4和Gemini 2.5-Pro在自动评估器打分方面的表现最高。", "conclusion": "通过集成多个大型语言模型（LLMs）进行自动解释和报告生成，HealthProcessAI框架解决了医疗流程挖掘结果的普遍陌生感，使其对临床医生、数据科学家和研究人员更具可访问性。这种结构化分析与人工智能驱动的解释相结合，代表了将复杂流程挖掘结果转化为可能可采取行动的见解的技术先进方法。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21238", "html_url": "https://arxiv.org/abs/2508.21238", "title": "通过知识图谱提高阿尔茨海默病研究中LLM的准确性和防止幻觉", "title_en": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "authors": "Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman", "background": "在过去两年中，基于大型语言模型（LLM）的聊天机器人，如ChatGPT，已经通过多样化的任务完成和问答能力在各个领域造成了革命性的影响。但是，他们在科研中的应用仍然受到诸如幻觉、特定领域知识有限以及答案解释或跟踪性不足等挑战的限制。图基支持的检索增强生成（GraphRAG）作为一种方法，通过在响应生成之前整合特定领域的上下文信息，改善了聊天机器人的可靠性，解决了标准LLM的一些限制。尽管如此，目前仅有少数研究在阿尔茨海默病或其它医学领域上评估GraphRAG系统。本文旨在评估两款流行的GraphRAG系统，并对阿尔茨海默病及其相关问题进行研究，填充现有研究的空白。我们收集了50篇关于阿尔茨海默病的学术论文，以及70份专家问题，构建一个知识库，并使用GPT-4o作为LLM来回答这些问题。我们将生成的GraphRAG和标准GPT-4o模型的响应进行对比，同时论述并评估了若干检索增强生成（RAG）和GraphRAG系统的可追溯性。最后，我们提供了一个方便易用的接口，其中包含了阿尔茨海默病的预建数据库，供研究人员测试标准RAG和GraphRAG的性能表现", "innovation": "本文通过构建专用于阿尔茨海默病的知识库并在标准GPT-4o模型和GraphRAG系统中对比其性能，填补了现有GraphRAG系统在医学领域研究中的研究空白。作者利用一款现有的LLM（GPT-4o），并将其进行改进，结果显示这种改进在特定知识密集型领域，如阿尔茨海默病研究方面提高了准确性和可追溯性", "conclusion": "我们通过一个综合的知识库，测试了两种流行的GraphRAG系统的性能指标。结果表明，GraphRAG方法确实可以提高响应的质量和可追溯性，并提供了更多的上下文信息。此外，我们还提供了一个方便易用的可通过预构建数据库评估性能的界面，旨在促进更多研究人员对RAG和GraphRAG技术的研究"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21517", "html_url": "https://arxiv.org/abs/2508.21517", "title": "基于德里西启发的Z数模糊框架模拟明智决策", "title_en": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis", "authors": "Sweta Kaman,Ankita Sharma,Romi Banerjee", "background": "智慧是一个涵盖换位思考、反思性、利他倾向、反思同理行动和智力谦虚的超级构念。不同于传统基于二元思维的推理模型，智慧会以不同程度的模糊性呈现，并要求进行分级评估和自省式的谦逊。现有测量方法主要依赖自我报告，很少反映有效推理中所固有的谦逊和不确定感。考虑多维度和信任度的计算模型有助于推进心理学并允许人性化的AI发展。", "innovation": "我们提出了一种基于Z数的模糊推理系统，每个决策都用智慧评分和信任评分表示。实验中收集了100名参与者的道德困境任务的自我陈述反应，将这些反应映射到五个理论基础上的智慧组成部分。通过基于21条规则和调节数值函数来计算得分，支持了相关效度和差异效度。此项研究的进步在于将智慧形式化为一个多维度且考虑不确定性的构念，并证明了模糊Z数如何为AI系统提供具备解释性和信任敏感性的推理，从而找到精确计算和人性化判断之间的平衡点。", "conclusion": "本研究旨在将智慧作为一个多维度且考虑不确定性的结构进行形式化，并通过Z数模糊框架进行操作化。除了推进心理学中的测量方法外，该研究还展示了如何运用模糊Z数为AI系统提供理解和信任感知的推理能力，从而使系统在严格的计算和类似于人类的判断之间找到平衡。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21648", "html_url": "https://arxiv.org/abs/2508.21648", "title": "利用MEDLEY利用医疗AI中的不足之处实现优势的一种多模型方法", "title_en": "Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI", "authors": "Farhad Abtahi,Mehdi Astaraki,Fernando Seoane", "background": "医疗人工智能中的偏差普遍被视为需要消除的缺陷。然而，人类推理本质上传递了由教育、文化和经验塑造的偏见，这表明这些偏见可能是不可避免且有价值的。因此，当前的做法是试图消除这些偏见。研究团队提出了MEDLEY（医疗多样性的系统组合），这是一种概念框架，旨在保留多个AI模型多样化的输出，而非将它们简化成一致意见。传统的做法试图抑制不同意见，而MEDLEY则公开记录每个模型的特定偏见，并将其视为潜在的优势，同时视幻觉为供临床医生验证的初步假设。", "innovation": "MEDLEY采用了一种结构化多样性策略，既能保持一致观点，又能保留少数声音，在合成案例中保持诊断不确定性和潜在偏见的透明性，以供临床监督。这种多模型方法将AI的不足之处重新定义为资源，从而开拓了新的监管、伦理及创新途径，以促进可信赖的医疗AI系统的开发。", "conclusion": "MEDLEY通过将AI的不完美重新定义为资源，展示了如何在医疗推理下增强结构化的多样性，从而开启医疗AI系统发展的新路径。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21637", "html_url": "https://arxiv.org/abs/2508.21637", "title": "A-MHA*: Anytime Multi-Heuristic A*", "title_en": "A-MHA*: Anytime Multi-Heuristic A*", "authors": "Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev", "background": "设计良好的图搜索启发式函数需要足够的领域知识。虽然可以在搜索空间的特定部分设计出表现良好并与真正成本相关联的启发式函数，但这些启发式函数可能并不在全领域内都是可许的，从而影响搜索的最优性保证。MHA*通过使用多个部分良好的但不可许的启发式函数来潜在地更快生成次优解，但原始版本不能随着时间而改进解。ARA*算法为解决这一问题提供了一种思路。", "innovation": "我们的工作基于MHA*框架进行了精确的ARA*概念适应，从而保持了原始的次优性和完备性保证，并进一步使MHA*能够以任何时间的方式运行。我们在3D路径规划和滑块拼图域中测试了A-MHA*的性能，并将其与MHA*和其他任何时间算法进行了比较。", "conclusion": "A-MHA*能够快速找到可行的次优解，并且能够持续改进，直到时间耗尽，同时保留了MHA*的原始次优性和完备性保证，并增强了MHA*以适应任何时间场景。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21564", "html_url": "https://arxiv.org/abs/2508.21564", "title": "重新审视地标：从先前的计划中学习以在实例间进行泛化", "title_en": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances", "authors": "Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt", "background": "传统的地标提取算法在解决特定实例的规划问题时表现良好，但对于跨领域的泛化问题效果不佳。本文旨在提出一个新的框架，通过学习已解决实例的地标来自动泛化，这些泛化的地标可以描述一类规划问题中的中间目标，适用于当传统地标提取算法不能发挥作用的情况。这些泛化地标超越了域的预设谓词，采用了与特定问题对象无关的状态函数，适用于所有相似对象，从而捕捉重复性.", "innovation": "本文提出了一个新的框架，用于自动发现跨域泛化的地标。该框架从已解决的实例中学习泛化地标，这些地标能够描述一类规划问题中的中间目标，适用于传统地标提取算法效果不佳的情况。泛化地标使用与特定问题对象无关的状态函数，适用于所有相似对象，从而捕捉重复性。基于这些状态函数，构建了一个有向的优点泛化地标图，定义了地标演进，包括重复子计划的循环可能性。该图用于在新的问题实例中通过启发式方法解决问题.", "conclusion": "研究表明，从少量小规模实例中学习的泛化地标图在整个域中的大规模实例中也有效。如果检测到表明重复性的循环，启发式的性能相较于基线有显著提升。泛化地标捕获了可解释和对自动化规划者有用的域信息，可以从相同域的一小部分计划中发现这种信息."}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21394", "html_url": "https://arxiv.org/abs/2508.21394", "title": "AI计算架构与演变趋势", "title_en": "AI Compute Architecture and Evolution Trends", "authors": "Bor-Sung Liang", "background": "当前，AI的发展已经从侧重学术研究转向实用应用，但这一过程中遇到了众多横跨不同层面的挑战。本文旨在从结构化的视角分析AI的机会与挑战，并提出一种从物理层到应用层的七个层次的人工智能计算架构模型。该模型的形成经过了大规模语言模型（LLMs）的发展三阶段，并详细探讨了每一层的技术发展路线和关键技术。", "innovation": "本文提出了一个包含物理层、链路层、神经网络层、上下文层、代理层、指挥层和应用层的七个层次的人工智能计算架构模型。同时，它还详细解释了大规模语言模型（LLMs）发展中的三个阶段如何使其演进为这一七层架构。此外，还讨论了上下文记忆对大规模语言模型的影响，以及单一个人工智能代理到基于人工智能的生态系统进化所带来的问题，这些都为理解人工智能领域的技术挑战和经济问题提供了新的视角。", "conclusion": "本文不仅分析了技术层面的挑战，还讨论了构建自可持续生态系统中的经济问题。通过分析互联网行业，本文还为未来人工智能的发展轨迹提供了预测。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21720", "html_url": "https://arxiv.org/abs/2508.21720", "title": "PosterForest: 分级多智能体合作的科学海报生成", "title_en": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "authors": "Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim", "background": "现有的科学海报生成方法大多忽视科学文档的层级结构及其文本和视觉元素的语义整合。这导致生成的海报缺乏逻辑一致性、内容准确性和视觉连贯性。", "innovation": "本文提出了一种无需训练的框架PosterForest，用于自动化生成科学海报。该框架通过引入Poster Tree（一个分级的中间表示）来共同编码文档结构和多层级的视觉-文本关系。采用多智能体协作策略，内容总结者和布局规划者智能体迭代合作并相互提供反馈，从而优化逻辑一致性、内容准确性和视觉连贯性。", "conclusion": "在多个学术领域的广泛实验表明，PosterForest方法在定性和定量评估中均优于现有基准。生成的海报质量接近专家设计的标准，且在信息保留、结构清晰度和用户偏好方面表现出色。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21622", "html_url": "https://arxiv.org/abs/2508.21622", "title": "将大型语言模型与网络优化集成以实现互动和可解释的供应链规划：一个实际案例研究", "title_en": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "authors": "Saravanan Venkatachalam", "background": "本文介绍了一种综合框架，该框架结合了传统的网络优化模型和大型语言模型（LLMs），以提供与供应链规划相关的交互、可解释且基于角色的决策支持。该综合框架旨在通过生成自然语言摘要、上下文可视化和定制的关键绩效指标（KPI）来弥合复杂运作研究输出与业务利益相关者理解之间的差距。论文的核心优化模型针对网络中的多个配送中心进行多期、多项目的库存重新分配，使用混合整数形式。研究还展示了通过实时交互、配置更新和基于模拟的洞察支持的实际技术架构。案例研究显示，该系统可以改善规划结果，防止缺货、减少成本并维持服务质量。", "innovation": "该研究的创新在于将传统的网络优化模型与大型语言模型相结合，以期提供更互动、更可解释的供应链规划决策支持。系统的技术架构允许AI代理、RESTful API和动态用户界面的支持，以实现实时交互配置更新和模拟洞察。未来扩展包括集成私有大型语言模型、迁移学习、强化学习和贝叶斯神经网络，以增强可解释性、适应性和实时决策能力。", "conclusion": "综合框架可提高供应链规划的决策质量，通过防止缺货、降低运营成本并保持服务水平。未来的研究将探索如何进一步通过集成先进技术提高系统的性能，满足实际业务需求。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21730", "html_url": "https://arxiv.org/abs/2508.21730", "title": "冻结与征服：可复用Ansatz解决旅行商问题", "title_en": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "authors": "Fabrizio Fagiolo,Nicolo' Vescera", "background": "本文提出的算法基于变分方法解决旅行商问题（TSP），结合了紧凑排列编码和优化-冻结-复用策略。编码方式简化了量子比特的需求，优化-冻结-复用策略允许在训练实例中优化电路拓扑（‘Ansatz’），然后在新的实例上冻结并复用，仅需快速重新优化电路参数。这种方法可以在NISQ硬件上立即实施，而不需要昂贵的结构研究。", "innovation": "提出的算法采用了优化-冻结-复用策略，仅在需要时优化电路参数，这种策略在不需要结构性研究的情况下提高了效率。此外，使用紧凑排列编码减少了量子比特的使用，使得在不同规模的城市实例中均能获得高质量的解决方案。", "conclusion": "对于4到7个城市的不同规模实例，冻结的Ansatz在4城市案例中的平均最短路径采样概率为100%，5城市为90%，6城市为80%，而7城市时成功率达到约20%，表明该方法面临一定的扩展限制。研究表明，对于中等规模的问题，冻结Ansatz可以显著降低求解时间而不影响解决方案质量。论文还讨论了扩展策略至更复杂问题的可能性，如车辆路线问题和作业车间调度。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21742", "html_url": "https://arxiv.org/abs/2508.21742", "title": "使用摘要因果图和忠实分布的时间序列中因果关系的可定向性", "title_en": "Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions", "authors": "Timothée Loranchet,Charles K. Assaad", "background": "理解时间变量之间的因果关系是时间序列分析中的一个重要挑战，尤其是在完整因果结构未知的情况下。即使无法完全指定完整的因果结构，专家也经常能够提供一个高层次的摘要因果图，即汇总因果图，该图捕捉了不同时间序列之间的主要因果关系并忽略了微观看得到的细节。在本工作中，我们提出了在已知汇总因果图中背景知识并假设可以访问关于真实未知图忠实且因果充分的分布的情况下，保证时间变量之间微观层面边定向性的条件。研究结果提供了在存在宏观循环或双向边的情况下，微观层面边定向性的理论保证。这些发现为利用SCGs指导复杂时间系统中的因果发现提供了实用指导，并突显了将专家知识纳入以改善从观察性时间序列数据中进行因果推理的价值。", "innovation": "提出了在已知摘要因果图中背景知识以及假设可以访问关于真实未知图忠实且因果充分的分布的情况下，保证时间变量之间微观层面边定向性的条件。研究结果提供了宏观循环或双向边存在的情况下，仍能实现边定向性的理论保证。这对于利用SCGs指导复杂时间系统中的因果发现具有重要意义，并强调了加入专家知识在提高从观察性时间序列数据中推断因果关系方面的价值。", "conclusion": "研究结果为利用SCGs指导复杂时间系统中的因果发现提供了实用指导，并强调了加入专家知识的价值，以便从观察性时间序列数据中提高因果推理的准确性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21803", "html_url": "https://arxiv.org/abs/2508.21803", "title": "使用协作多智能体大型语言模型架构从SOAP笔记中自动检测临床问题", "title_en": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "authors": "Yeawon Lee,Xiaoyang Wang,Christopher C. Yang", "background": "临床文书的准确解读对于患者护理至关重要，但由于这些笔记的内容复杂，自动化处理具有挑战性。尽管大规模语言模型（LLMs）显示出潜力，但单一模型的方法可能缺乏处理高风险临床任务所需的鲁棒性。目前的系统难以处理SOAP笔记中的主诉（S）和体征（O）部分，而不引入错误诊断。为了解决这些问题，本文介绍了一个多代理系统（MAS），该系统模仿临床咨询团队的工作方式，通过对SOAP笔记S和O部分的分析来识别临床问题，模拟诊断推理过程。", "innovation": "提出了一个使用多代理系统的方法，该系统包含一位管理者代理和一位或多智能体代理团队。这个系统能够通过动态分配不同的专家智能体进行层次化、迭代的辩论以达到共识，从而改进对临床问题的检测。这种方法显示出在识别充血性心力衰竭、急性肾损伤和败血症方面的一致性改进。同时，智能体间的辩论揭示出该方法能够有效呈现和评价矛盾的证据，但有时会受到群体思维的影响。", "conclusion": "通过模拟临床团队的推理过程，该系统为更精确、稳健和可解释的临床决策支持工具提供了有前景的道路。未来的研究可以进一步优化多智能体系统的性能，并探索机器学习技术如何更好地理解临床笔记中复杂的医学术语和细微的线索。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: 通过语义三元组缓解各种错觉相关性的反偏数据增强", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型在学习和利用训练数据中的错觉相关性时，会依赖这些非目标特征来做出预测，这会导致在未见数据上的性能下降和泛化能力变差。为解决这些问题，有必要提出一种更为通用的反偏数据增强方法，即反偏数据增强（counterbias data augmentation），该方法能够同时解决多种偏见问题（如性别偏见、简单性偏见），并增强对于未见过数据的鲁棒性。", "innovation": "作者提出了一个统一体系框架CoBA（CounterBias Augmentation），在语义三元组级别上运作：首先将文本分解为主谓宾三元组，然后有选择地修改三元组以打破错觉相关性，从而重建文本以生成反偏数据，这些数据能够减轻错觉模式。CoBA方法不仅提高了下游任务的表现，还有效地减少了偏见并增强了对未见过数据的抗性，提供了一种多功能且稳健的解决错觉相关性挑战的方法。", "conclusion": "通过广泛的实验，作者展示了CoBA不但提升了下游任务的性能，还有效降低了偏见并增强了对于未见过数据的抗性，提供了一种灵活且强大的解决错觉相关性问题的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk: 使用Transformer网络的墨迹生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "在现有的研究中，使用Transformer模型生成连笔手写墨迹面临挑战，尤其是在捕捉全局依赖关系和对齐输入文本与生成的笔画点方面存在不足。为了提高生成的连笔手写墨迹的质量，研究者们需要提出新的解决方案来改善这些缺点。", "innovation": "该研究提出了一种基于Transformer的模型TrInk，通过引入缩放位置嵌入和高斯记忆掩码来改进跨注意力模块，从而更有效地捕捉全局依赖关系，提高输入文本与生成笔画点之间的对齐度。同时，设计了主观和客观评估管道，全面评估生成手写的可读性和风格一致性。实验结果显示，与之前的方法相比，该模型在字符错误率（CER）和单词错误率（WER）方面分别降低了35.56%和29.66%，在IAM-OnDB数据集上的性能提升显著。", "conclusion": "本文提出了一种名为TrInk的基于Transformer的模型，通过引入新的注意力机制和评估方法，在连笔手写墨迹的生成上取得了显著的性能提升。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21800", "html_url": "https://arxiv.org/abs/2508.21800", "title": "Tree-Guided Diffusion Planner", "title_en": "Tree-Guided Diffusion Planner", "authors": "Hyeonseong Jeon,Cheolhong Min,Jaesik Park", "background": "在使用预训练的扩散模型进行测试时的导向控制问题规划方面，已经出现了一种很有前景的方法。然而，标准的梯度导向通常在凸性和可微性奖励景观中表现最佳，在涉及非凸目标、非可微性约束和多奖励结构的真实世界场景中效果大幅下降。此外，最近的一些监督规划方法需要针对任务的特定训练或价值估计器，这限制了测试阶段的灵活性和零样本泛化能力。", "innovation": "本文提出了一种名为Tree-guided Diffusion Planner (TDP)的零样本测试时规划框架，通过结构化轨迹生成来平衡探索和利用。TDP利用了一个两层采样过程：首先，在无训练的粒子导向下产生多样化的父轨迹以鼓励广泛的探索；其次，通过快速条件去噪和任务目标导向对子轨迹进行细化。TDP通过仅使用预训练模型和测试时奖励信号横跨扩大后的解空间探索多样的轨迹区域，并利用梯度信息。", "conclusion": "TDP在迷宫金子采集、机器人手臂块操作和AntMaze多目标探索三项不同的任务中均表现出色，优于最先进的方法。项目的页面可以在该网址找到：this http URL。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: 使用端到端强化学习的 KAN 增强四足运动控制", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "文章介绍了使用强化学习（RL）进行四足机器人视觉导向运动控制的研究，强调了将本体感觉与视觉结合以实现稳健控制的必要性。", "innovation": "提出了一种新的框架 QuadKAN，它使用 KANs 实现跨模态策略，并通过样条参数化将状态到动作映射与步态的分段平滑特性对齐。采用 Multi-Modal Delay Randomization (MMDR) 并使用 Proximal Policy Optimization (PPO) 进行端到端训练。", "conclusion": "QuadKAN 在多种地面上，包括平坦和不平坦的表面以及静态或动态障碍物情况下，表现出更高的收益、更远的距离和更少的碰撞，证明了样条参数化策略是稳健基于视觉的行进控制的有效且可解释的替代方案。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "使用混合深度学习的严肃游戏中基于SPATIOTEMPORAL的EEG情绪识别", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "近年来，基于EEG的情绪识别取得了有希望的成果，但大多数现有研究仅专注于二元情感价值预测或特定个体分类，这限制了其在实际情感计算系统中的推广应用。目前主要的情绪识别框架在处理多元情感或多标签情感表示时存在不足，无法广泛应用于实际场景。", "innovation": "本文提出了一个基于GAMEEMO数据集的统一多层次EEG情绪分类框架。该框架采用了一种结构化预处理策略，包括时间窗口分割、混合统计和频域特征提取与z-分数归一化，将原始EEG信号转换为稳健且具有区分度的输入向量。研究还评估了多种模型，包括随机森林、XGBoost、SVM以及LSTM、LSTM-GRU和CNN-LSTM等深度神经架构，其中LSTM-GRU模型在二元情感价值任务中获得了最高的F1分数，在多类和多标签情绪分类中也表现出色。", "conclusion": "该研究通过构建统一多层次的EEG情绪分类框架，利用LSTM-GRU模型在多标签情感识别任务中取得了较高的准确率，为实际应用中的人机情感交互提供了有效的方法。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob 标准：基于 MS$^2$ 蛋白组学预测片段离子概率", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质执行几乎所有细胞功能，并且是大多数药物靶点，因此其分析对于理解健康和疾病状态下的人类生物学至关重要。串联质谱（MS$^2$）质谱学技术是重要工具之一，用于识别肽，并通过将肽离子化、断裂和使用生成的质谱数据识别并量化生物样本中的蛋白质。在 MS$^2$ 分析中，肽片段离子概率预测起到了关键作用，通过补充质谱强度信息来提升肽识别的准确性。目前的方法依赖于断裂的全局统计，假设所有肽的碎片概率是均匀的。然而，这种方法从生化原理来看过于简化，限制了准确预测能力。因此，需要更复杂的模型来精确预测肽的片段离子概率。", "innovation": "该研究提出了 Pep2Prob，这是一个新的综合数据集和基准，专门用于预测肽特异性片段离子概率。Pep2Prob 包含了来自 1.83 亿个高质高价质-HCD MS$^2$ 谱的各种肽和电荷状态的碎片离子概率统计数据，这些数据经由验证过的肽指配和断裂注释生成。研究结果表明，使用肽特异性信息的模型显著优于仅使用全局断裂统计数据的模型，并且性能随着机器学习模型复杂性的增加而提升，这表明肽-断裂关系具有复杂的非线性特征，需要更复杂的机器学习方法。", "conclusion": "Pep2Prob 提供了一个专门用于预测肽特异性片段离子概率的综合数据集和基准。相较于仅依赖全局统计的方法，利用肽特异性数据的模型在预测准确性上有了显著提升。研究还表明，肽-断裂之间的关系具有复杂的非线性，需要高水平的机器学习方法来解决这一挑战。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成驱动的量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "本文探讨了通过利用可以增强检索增强生成（RAG）管道的大型语言模型（LLMs），进行模型到文本/代码转换的新型研究方向。着重于量子和混合量子-经典软件系统，其中模型驱动的方法可以帮助减少由于异构平台环境和缺乏开发人员技能所带来的成本和风险。验证了一个关于从软件系统的UML模型实例生成代码的想法，并使用Qiskit库中的标准库在基于门或电路的量子计算机上执行生成的Python代码。部署的RAG管道包括来自公共GitHub存储库的Qiskit代码片段。实验结果表明，精心设计的提示可以将CodeBLEU分数提高四倍左右，产生更准确和一致的量子代码。未来的进一步研究可以通过进行更多的实验来解决其它研究问题和想法，如将软件系统模型实例作为RAG管道中的信息源，或将LLMs用于代码到代码的转换等场景，例如用于转译用途。", "innovation": "提出了一种新的研究方向，利用大型语言模型和检索增强生成技术进行模型到文本/代码转换。通过使用Qiskit标准库执行生成的Python代码来验证了从UML模型实例生成代码的想法。RAG管道按应用了来自公共GitHub存储库的Qiskit代码片段。实验结果表明精心设计的提示显著提升了生成的量子代码的质量和一致性。未来的进一步研究将关注如何利用软件系统模型实例作为信息源的信息，在RAG管道中进行更广泛的实验，以及使用LLMs进行代码到代码的转换问题等其他研究疑问和想法。", "conclusion": "该研究通过使用大型语言模型和检索增强生成技术，证实了从软件系统UML模型实例生成量子代码的有效性。精心设计的提示提升了生成代码的质量和一致性，但还有一些其他未解决的问题和研究方向可通过进一步的实验探讨，以扩展研究边界并改进模型驱动的量子软件系统开发。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：强化学习在医疗人工智能中的定义性进步", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）标志着人工智能在医疗保健应用中的根本转变。与传统的仅预测结果的模型不同，RL系统通过实验、反馈和长期奖励优化来学习，因此带来了一系列转型潜力和新的风险。从信息融合的角度来看，医疗领域的RL通常会整合诸如生命体征、实验室数据、病历、影像成像和设备遥测等多源信号，使用时间序列和决策级别的机制。这些系统可以在集中的、联邦的或边缘的架构中运行，以满足实时临床约束，并自然跨越数据、特征和决策融合级别。", "innovation": "本文结构化阐述了强化学习技术的景观，包括基于模型和非基于模型的方法、离线和批量约束的策略，以及针对医疗约束的新兴奖励规范和不确定性校准策略。文中详细分析了强化学习在重症监护、慢性病、心理健康、诊断和机器人辅助等领域的应用，识别了趋势、差距和转化瓶颈。本文还批判性地分析了强化学习在伦理、部署和奖励设计方面的挑战，并综合了确保安全、以人为本的政策学习的经验教训。", "conclusion": "本文不仅提供了一项技术路线图，还就强化学习在医疗人工智能领域的新兴转型角色进行了反思，强调其不再作为预测机制，而是作为临床智能主体性的角色。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "具备解释性的、增强注意力的双方向长短时记忆神经网络在联合48小时温度、辐照度和相对湿度预测中的应用", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "该论文提出了一个深度学习框架，用于支持智能暖通空调（HVAC）系统的模型预测控制（MPC）。该框架主要用于48小时预测温度、太阳辐照度和相对湿度，以提供准确的气象数据支撑。历史气象数据（2019-2022年）中的周期时间特征被编码用于训练，2023年的数据则用于评估模型的一般化能力。", "innovation": "该研究采用了一种结合了双向长短时记忆（Bidirectional Long Short-Term Memory，BiLSTM）网络和注意力机制的深度学习框架。通过联合预测三个变量，该模型能够捕捉到时间序列和跨特征的依赖关系。量化特征贡献和注意力权重分析揭示了时间模式，从而增强了模型的可解释性。", "conclusion": "实验结果表明，该模型在温度、辐照度和湿度上的平均绝对误差分别优于最先进的数值天气预报和机器学习基准。通过结合多变量预测、基于注意力的深度学习和可解释性，该工作推进了数据驱动的天气预测。展示的准确性和透明度强调了该框架在能源效率建筑控制中的潜在应用。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO: 基于预估价值的策略优化方法及其在代理推理中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "当前的无监督强化学习方法，尤其是群体策略，因其在复杂任务中的效率而受到关注。然而，这些方法依赖于内部政策的多次采样和比较来估算优势，这可能导致策略陷入局部最优解，并增加计算成本。因此，改进策略以避免这些问题变得尤为重要。", "innovation": "本文提出了一种名为PVPO（Pre-Estimated Value-Based Policy Optimization）的新方法，通过优势参考锚点和数据预采样增强了策略优化。该方法利用参考模型进行预采样，并使用计算出的奖励分数作为参考锚点，有效纠正了内部组比较引入的累积偏差，并显著减少了对采样次数的依赖。此外，参考模型在数据预采样期间评估样本难度，能够有效选择高收益数据，提高训练效率。实验结果表明，该方法在多个数据集和领域中达到了最先进的性能，具有跨任务的鲁棒泛化能力和与不同规模模型的可扩展表现。", "conclusion": "实验证明，PVPO不仅在多个任务上表现出高度的泛化能力，还能够有效地提高不同规模模型的训练效率。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "全矩阵预条件因子的动态低秩近似用于训练广义线性模型", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "在大规模优化中，自适应梯度方法如Adagrad及其变体广泛使用。然而，它们利用对角预条件矩阵限制了对参数相关性的捕捉能力。近似完整的矩阵自适应方法可以在模型中捕捉这些相关性，从而可能实现更快的收敛速度。然而，由于计算和内存成本高，这种方法通常不适合大规模模型。", "innovation": "提出了一种称为AdaGram的优化器，能够实现高效的完整矩阵适应梯度更新。通过使用快速对称因式分解计算每个迭代的预条件更新方向，减少了计算和存储开销。此外，使用矩阵积分方法保持预条件器沿优化轨迹的低秩结构。实验证明，使用五秩和更小秩的近似时，AdaGram可以在标准机器学习任务中实现更快的收敛速度或与对角自适应优化器相匹配的性能，这表明AdaGram在大规模模型的自适应优化中具有可扩展的解决方案潜力。", "conclusion": "AdaGram通过动态低秩近似全矩阵预条件因子，在提高收敛速度的同时，有效降低计算和存储成本，展示了在大规模模型自适应优化中的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "NASA的深空网络（DSN）是一个大型的天线设施网络，产生大量的多变量时间序列数据。这些设施中的DSN天线和发射机在长时间内会逐渐退化，可能导致数据流中断，威胁到数十个依赖于DSN的生命线的航天器的地球联系。研究的目的是通过收集的数据帮助JPL工程师直接定位异常和设备退化，继续进行未来的太空任务的DSN维护和操作。背景介绍了DSN设施存在的问题以及研究目标。", "innovation": "研究探讨了各种机器学习技术，通过预测分析完全重建数据，并通过统计计算和阈值确定实时数据集中的异常数据。还集成了基于强化学习的子系统，根据严重程度对识别的异常进行分类，并使用大型语言模型为每个异常的数据条目提供解释。此外，还实施了完整的数据管道系统，将数据提取、解析和处理工作流全部整合在一起，通过复杂推理系统确定异常数据的分类和预测。", "conclusion": "通过完整的机器学习模型及其集成的强化学习子系统和语言模型，实现了DSN的自动数据系统，并通过复杂的推理系统确定了异常数据的分类和预测。整个系统增强了未来DSN系统的异常检测能力，为未来的太空任务提供了更好的支持。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control：一种减轻文本到图像生成模型中不安全内容的安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像（T2I）生成模型方面取得了进步，但这些模型的潜在滥用或误用引发了严重的安全问题。模型开发者已经投入大量精力引入能够解决这些担忧的安全机制。然而，现有安全机制，无论是外部的还是内部的，要么在分布变化下仍然容易被规避，要么需要对模型进行大量的特定调整。", "innovation": "我们提出了Safe-Control，一种创新的即插即用安全补丁，旨在减轻T2I模型中的不安全内容生成。通过数据驱动策略和安全意识条件，Safe-Control将安全控制信号注入锁定的T2I模型，以补丁形式进行更新。模型开发者也可以构建多种安全补丁来满足不断变化的安全需求，并能灵活地合并到一个统一的补丁中。其即插即用设计进一步确保了其适应性，使其与相似去噪架构的其他T2I模型兼容。", "conclusion": "我们在六个不同的公共T2I模型上进行了广泛评估。实验证明，Safe-Control能够有效地减少六个具有相似生成架构的不同T2I模型中的不安全内容生成，同时仍然保持良性图像的质量和文本对齐。与七个最先进的安全机制，包括外部和内部防御相比，Safe-Control在减少不安全内容生成方面表现出显著优势。例如，在不安全提示和最新的对抗性攻击下，Safe-Control将不安全内容生成的概率降低至7%，而大多数基准方法约为20%。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程的核心实践，能够系统性地评估由人类开发者或大型语言模型（LLMs）生成的程序。由于全面编写单元测试的挑战，LLMs 已被用于自动化测试生成，但如何训练 LLMs 生成高质量的测试方法仍待探索。本文提出了一种名为 UTRL 的新颖强化学习框架，通过对抗强化学习训练 LLM 生成高质量的单元测试。URTL 的关键理念是通过强化学习迭代训练单元测试生成器和代码生成器，使单元测试生成器能够最大化其生成能够揭示代码生成器解法缺陷的测试的能力，而代码生成器则被训练最大化其生成通过测试生成器生成的测试的代码的能力。", "innovation": "UTRL 是一种创新的强化学习框架，通过对抗训练 LLMs，分别优化单元测试生成器和代码生成器，以增强它们生成高质量单元测试和代码的能力。相比传统的监督微调方法，UTRL 能够生成更能揭示代码缺陷的测试，从而更精确地评估代码。此外，实验表明，通过 UTRL 训练的 Qwen3-4B 在生成高质量单元测试方面优于使用前沿模型如 GPT-4 的做法，这显示了 UTRL 在训练 LLMs 完成此项任务方面的有效性。", "conclusion": "本文通过 UTRL 框架训练 LLMs 生成高质量的单元测试，实验结果表明这种方法生成的测试质量更高，更加精准地反映了代码的真实质量，优于传统的监督微调方法和前沿模型。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21112", "html_url": "https://arxiv.org/abs/2508.21112", "title": "EmbodiedOneVision：在通用机器人控制中结合视觉-文本-动作的交错预训练", "title_en": "EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control", "authors": "Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang", "background": "人类能在开放世界中无缝进行多模态推理和物理交互的能力是通用体智能系统的首要目标。近期的视觉-语言-动作（VLA）模型已经在大型机器人和视觉文本数据上表现出色，但在交错推理与交互方面仍无法达到人类的灵活性。", "innovation": "本文介绍了EO-Robotics，包含EO-1模型和EO-Data1.5M数据集。EO-1是一种统一的体模基础模型，通过交错的视觉-文本-动作预训练在多模态体模推理和机器人控制方面取得了优越性能。EO-1的独特之处在于其统一架构能够处理多模态输入（图像、文本、视频和动作），以及大规模、高质量的多模态体模推理数据集EO-Data1.5M，包含了超过150万样本，注重交错的视觉-文本-动作理解。EO-1的训练方法结合了自回归解码和流匹配去噪，能够在广泛的复杂抓取任务中验证交错视觉-文本-动作学习对开放世界的理解和泛化的有效性。", "conclusion": "这项工作详细介绍了EO-1的架构，EO-Data1.5M的数据构建策略以及训练方法，并为开发先进的体模基础模型提供了宝贵见解。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "HiddenObject：在视觉退化或复杂条件下无需特定模态的多模态隐藏对象检测的融合架构", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中，由于遮挡、伪装和光照变化等因素，检测隐藏或部分遮挡的对象仍然是一个基本挑战。传统的基于RGB的检测方法在这些不利条件下往往失效，因此需要更加稳健、跨模态的方法来应对这些问题。", "innovation": "我们提出了HiddenObject，这是一种使用Mamba融合机制集成RGB、热成像和深度数据的融合框架。该方法通过捕获不同模态下的互补信号，实现了对遮挡或伪装目标的增强检测。特别是，本文提出的方法识别特定模态的特征，并在统一表示中将它们融合起来，这在各种挑战性场景下具有普适性。我们的实验结果表明，HiddenObject在多个标准数据集上达到或接近了现有方法的最佳性能，突显了我们融合设计的有效性，同时也揭示了当前单模态和简单的融合策略的关键局限性。总体而言，我们的研究发现，基于Mamba的融合架构可以显著推动多模态物体检测领域的发展，特别是在视觉退化或复杂条件下。", "conclusion": "我们的研究结果表明，对于视觉退化或复杂条件下的多模态隐藏对象检测，Mamba基于的融合架构具有显著的优势，可以有效改进现有的单模态和原始融合策略，进而推动该领域的技术进步。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg: 通过联合3D辐射高斯重建和3D/3D配准将脊柱CT与双平面X射线配准", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导导航中，CT/X射线配准面临着高精度和实时性能的严格要求，传统的“渲染和比较”方法依赖于迭代投影和比较，存在空间信息丢失和领域差距的问题。虽然从双平面X射线进行3D重建可以补充空间和形状信息，但在眼前要求和噪声X射线处理方面存在局限性。", "innovation": "提出了一种名为RadGS-Reg的新框架，用于基于椎体级的CT/X射线配准。该框架通过联合3D辐射高斯（RadGS）重建和3D/3D配准来解决这些限制。具体来说，双平面X射线椎体RadGS重建模块采用基于学习的RadGS重建方法，并结合Counterfactual Attention Learning (CAL)机制，专注于噪声X射线中的椎体区域。此外，提出了一种患者特异性的预训练策略，逐步适应RadGS-Reg从模拟数据到真实数据，同时学习椎体形状先验知识。", "conclusion": "在自建数据集上的实验表明，RadGS-Reg在两项任务中的性能处于最先进的水平，超过了现有方法。代码可在此处获得：this https URL。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B: 利用二元退火和强化学习激励多模态大语言模型的一般自思考能力", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大语言模型（MLLMs）在复杂的推理问题上表现出色，但这种思考过程对于不用复杂推理就可以解决的简单问题则显得冗余。为了提高效率，本研究提出了一种自思考模式的MLLM——R-4B，该模型可以根据问题的复杂性自适应地决定是否启动思考过程。R-4B的核心思想是通过二元退火同时赋予模型思考和非思考的能力，并通过二元策略优化（BPO）来提高模型在判断是否启动思考过程方面的准确性。研究通过精心选择的跨领域数据集训练模型，并在改进的GRPO框架下进行进一步训练，确保模型能够在每个输入查询中产生来自两种模式的回答。实验结果表明，R-4B在25个具有挑战性的基准测试中达到了最先进的性能，与Qwen2.5-VL-7B相比在大多数任务上表现更好，并在推理密集型基准测试上与Kimi-VL-A3B-Thinking-2506（16B）性能相当，同时具有较低的计算成本。", "innovation": "R-4B模型提出了一种二元退火策略和二元策略优化方法，以适应不同复杂度问题的需要，并通过精心设计的训练过程和框架提升模型的效率。这种方法不仅能够基于问题的复杂性自适应地启动或避免启动思考过程，还能显著提高模型的推理准确性，同时减少计算成本。", "conclusion": "实验结果显示，R-4B模型在多个具有挑战性的基准测试上达到了最先进的性能，并且能以较低的计算成本实现与更大模型相当的性能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深残差回声状态网络：探索未训练递归神经网络中的残差正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "回声状态网络（ESNs）是一种特殊的未训练递归神经网络（RNNs），属于回声计算（RC）框架，因其快速和高效的学习而受到欢迎。然而，传统的ESNs在长期信息处理方面经常表现出困难。", "innovation": "本文引入了一种基于时序残差连接的新型深层未训练递归神经网络——深层残差回声状态网络（DeepResESNs），并通过层次化的未训练残差递归层显著提升了记忆容量和长期时序建模能力。研究了不同正交配置的时序残差连接对网络动力学的影响，并通过详尽的数学分析给出了确保DeepResESN稳定动力学的必要和充分条件。", "conclusion": "通过在各种时间序列任务上的实验，展示了所提方法比传统浅层和深层回声计算具有优势。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21153", "html_url": "https://arxiv.org/abs/2508.21153", "title": "WaveLLDM：设计与开发一种轻量级隐含扩散模型实现语音增强与恢复", "title_en": "WaveLLDM: Design and Development of a Lightweight Latent Diffusion Model for Speech Enhancement and Restoration", "authors": "Kevin Putra Santoso,Rizka Wakhidatus Sholikah,Raden Venantius Hari Ginardi", "background": "高质量的音频在在线通信、虚拟助手和多媒体行业中有广泛的应用。然而，由于噪音、压缩和传输引起的降解仍然是一个主要挑战。虽然扩散模型在音频修复方面已经证明是有效的，但它们通常需要大量的计算资源，并且难以处理长时间的缺失段落。", "innovation": "该研究引入了WaveLLDM（Wave Lightweight Latent Diffusion Model），该架构结合了高效的神经音频编解码器和隐式扩散进行音频修复和去噪。WaveLLDM在压缩的潜在空间中处理音频，从而减少计算复杂性同时保持重建质量。实验结果表明，WaveLLDM在Voicebank+DEMAND测试集上实现了准确的频谱重建（Log-Spectral Distance (LSD)得分为0.48至0.60），并且具有良好的对未见数据的适应性。", "conclusion": "尽管WaveLLDM在感知质量和语音清晰度方面仍落后于最先进的方法（WB-PESQ得分为1.62至1.71，STOI得分为0.76至0.78），并且其性能受限于架构调优不足、缺乏微调以及训练时间不足，但其灵活的结合神经音频编解码和隐式扩散模型的架构为未来的发展奠定了坚实的基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大型语言模型综述：从数据基础到智能代理前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大型语言模型（Sci-LLMs）正在改变科学研究中知识的表示、整合和应用方式，但其进展受到科学研究数据复杂性的影响。本文综述提供了一个全面的数据为中心的综合，重新定义Sci-LLMs的发展为模型与其底层数据基础之间的共进化过程。本文强调了科学语料库与通用自然语言处理数据集之间的多模态、跨尺度和领域特定的挑战，综述了当前的Sci-LLMs以及超过270个预/后训练数据集的广泛分析，说明了Sci-LLMs所带来的独特需求，包括异质的、多尺度的、带有不确定性的语料库，需要保护领域不变性和跨模态推理的能力。", "innovation": "提出了一个统一的科学数据分类体系和一个分层的科学知识模型，强调了科学语料库与通用自然语言处理数据集之间的多模态、跨尺度和领域特定的挑战；系统地审查了从通用基础模型到跨学科专门模型的科学大型语言模型，分析了超过270个预/后训练数据集，展示了这些模型所需的独特数据需求；检测并分析了多项评估基准，从静态考试转向过程导向和发现导向的评估，并引入了高级评估协议。此外，提出了涉及半自动化注释流水线和专家验证的新兴解决方案；提出了一种新的范式，基于Sci-LLMs的自主代理进行自主实验、验证，并将知识库作为一种活的、不断发展的知识库。", "conclusion": "本文提供了一个构建可信赖的、不断进化的AI系统以加速科学发现之路的路线图，这些AI系统能够在科学实验和知识贡献中真正发挥作用。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE：树丛集的灵活遗忘", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "树丛集在分类任务中因其有效性而广受认可，其性能在生物信息学、金融和医疗诊断等多种领域达到尖端水平。然而，随着对数据隐私和个人信息删除权利的重视增加，已经提出了多个遗忘算法来使树丛集能够遗忘敏感信息。现有方法通常针对特定模型进行定制或依赖于离散的树结构，难以推广到复杂的树丛集，并且对于大规模数据集效率低下。这些问题限制了它们的应用范围和实用性。", "innovation": "我们提出了FUTURE，一种新颖的树丛集遗忘算法。具体来说，我们将遗忘样本的问题形式化为基于梯度的最优化任务。为了应对树丛集的非可微性，我们在最优化框架中采用了概率模型近似方式。这一创新使端到端遗忘在有效和高效方式下成为可能。实证研究结果表明，FUTURE在现实世界数据集上展示了显著且成功的遗忘性能。", "conclusion": "本文提出了一种新的FUTURE算法，通过将遗忘样本的问题形式化为基于梯度的最优化任务，并采用概率模型近似方式，使得树丛集能够在有效和高效的方式下实现遗忘。实证研究表明，该算法在现实世界数据集上取得了显著成功。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签诱导偏差在自我和跨模型评估中的量度", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "大型语言模型（LLMs）越来越多地用于评估输出，但却可能受到偏见的影响。本研究通过研究ChatGPT、Gemini和Claude这三种模型在四种不同情况下的自我和相互评估中的偏差情况，来进一步探讨这一问题。研究对象包括模型本身撰写的博客文章，由所有三个模型分别进行评估，并且采用总体偏好投票和对连贯性、信息性和简洁性等质量评级的方式进行评分，所有评分都以百分比形式呈现以便于直接对比。研究表明，感知到的模型身份会对高级判断产生重大影响，并且微妙地影响详细的质量评分，从而证明了在LLM基准测试中需要盲评估或多模型评估协议以确保公平性的重要性。", "innovation": "本研究创新性地通过四种不同的标签条件比较了ChatGPT、Gemini和Claude三个模型的自我和跨模型评估中的偏差程度，包括未标记、真实标签以及两种虚假标签的情况，并且通过详细的质量参数评分来量化这一现象。研究中的一个重要发现是，感知到的模型身份对结果产生了显著的正面或负面影响，这表明评估过程中的感知身份可能极大地影响最终判断结果。", "conclusion": "感知到的模型身份可以显著扭曲高级判断，并微妙地影响详细的质量评价。因此，在大型语言模型的基准测试中，需要采用盲评估或多元模型评估协议，以确保评价的公平性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "从复制子动力学到Softmax极限的输出流形轨迹：下一词预测", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "大型语言模型中的解码过程通常被描述为评分词元并使用softmax进行规范化。本文从变分原理的角度，以约束的概率单纯形为背景，阐述了这一过程的步骤。", "innovation": "通过对连续时间极限的分析，证明了在固定上下文和温度前提下，下一词分布遵循单纯形内部平滑轨迹并最终收敛到softmax平衡态。这一解释正式化了常见的‘流形遍历’直觉，并提供了具体可实施的结论：温度等同于沿相同轨迹的时间精确缩放，而top-k和nucleus采样限制流体到具有相同保证的同一面。此外，还概述了路径依赖评分调整及其与类似于幻觉的行为之间的联系。", "conclusion": "本文的研究成果提供了精确且面向实践的后果：温度作为时间的精确缩放，top-k和nucleus采样将流体限制到具有相同保证的面。此外，还提出了关于路径依赖评分调整及其与幻觉行为之间联系的控制描述。但本文未涉及训练动态或内部表示，这些将在未来的工作中探讨。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "BED-LLM：利用大语言模型和贝叶斯实验设计的智能信息收集", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "大语言模型（LLMs）在智能交互和信息收集方面具有巨大的潜力，但它们通常缺乏有效对方程未知参数进行迭代估计和交互式信息收集的机制。通过引入基于顺序贝叶斯实验设计（BED）的框架，该研究旨在增强LLMs在智能和适应性地从用户或其他外部源收集信息方面的能力，使得它能够作为高效的多轮对话代理并与外部环境进行互动式交互。", "innovation": "该研究提出了BED-LLM（贝叶斯实验设计与大语言模型）方法，该方法的核心在于通过迭代选择问题或查询以最大化获得关于兴趣任务的预期信息增益（EIG）。具体创新包括精心设计的EIG估算器，不依赖于上下文更新来调节先前的响应，并提出了一种专门策略来建议候选查询。此外，还提供了一个概率模型，用于从LLM的信任分布中推导出EIG，并详细说明了模型构建中的一些关键决策。研究通过使用20个问题游戏测试和利用LLM主动推断用户偏好，表明BED-LLM在多种测试中取得了显著的性能提升，优于直接提示LLM和其他自适应设计策略。", "conclusion": "BED-LLM通过利用大语言模型和贝叶斯实验设计框架，在从用户或其他外部源智能和适应性地收集信息方面展示了显著的性能提升。该方法适合广泛的任务场景，提供了关于智能信息收集的洞察，并超越了现有的直接提示和自适应设计策略。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "提升航空安全分析：基于组相对策略优化的强化学习自动化HFACS分类", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析人类因素是预防航空事故的关键，但传统的基于人类因素分析和分类系统（HFACS）的方法在规模化和一致性方面存在局限性，因此需要新的方法解决这些问题。", "innovation": "提出了一种基于强化学习（Reinforcement Learning, RL）与组相对策略优化（Group Relative Policy Optimization, GRPO）的自动化HFACS分类框架。该框架利用GRPO微调了Llama-3.1 8B语言模型，并结合多组件奖励系统和合成数据生成技术来克服事故数据集中的类别不平衡问题。该模型在精确匹配准确性和部分匹配准确性上实现了显著提升，并且在特定指标上优于最先进的语言模型（如GPT-5-mini和Gemini-2.5-fiash）。此外，该研究还提出了一种多标签HFACS分类中的精确匹配准确性的新基准方法，用于评估语言模型的高级推理能力。", "conclusion": "我们的研究证明，较小的、针对特定领域的模型可以为关键的安全分析提供一个计算效率更高且更好的解决方案，并使强大的低延迟部署成为可能，适用于资源受限的边缘设备。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过视觉上下文提示实现泛化的物体再识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前的物体再识别（ReID）方法训练特定领域的模型（例如人员或车辆），这些模型缺乏泛化能力，对新类别需要大量成本昂贵的标注数据。虽然自监督学习通过学习实例间的不变性减少了标注需求，但难以捕捉到再识别任务中至关重要的身份敏感特征。", "innovation": "本文提出了Visual In-Context Prompting (VICP)框架，该框架利用学习到的少量采样配对的语义身份规则，通过上下文示例引导视觉基础模型（如DINO）提取出区分身份的视觉提示，从而使模型能够泛化到未见类别，不需要参数调整，同时引入了ShopID10K数据集，包含来自电商平台的多种视图图像，展示了VICP在新的类别上的优越性能。", "conclusion": "在ShopID10K和不同的ReID基准测试上，实验表明VICP在未见类别上超过了基准模型，同时通过联结LLM提取的语义概念和预训练的VFM，实现了良好的泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21253", "html_url": "https://arxiv.org/abs/2508.21253", "title": "利用强化学习优化基于大量量子位阵列的量子传感器电路", "title_en": "Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits", "authors": "Laxmisha Ashok Attisara,Sathish Kumar", "background": "随着量子传感器中量子位数量的增加，设计和控制量子电路的复杂性呈指数增长。手动优化这些电路变得不切实际。增强量子传感器性能的关键之一是优化大规模量子电路中的纠缠分布。", "innovation": "本文提出了一种工程集成，结合了强化学习与张量网络（MPS）模拟方法，以实现可扩展的量子传感器电路优化。采用张量网络方法，特别是Matrix Product State (MPS)表示，替代传统态矢量或密度算子方法，使仿真和可扩展性得以提高。强化学习代理学会重构电路，以最大化量子费雪信息（QFI）和纠缠熵，同时减少门数量和电路深度。", "conclusion": "实验结果表明，一致性改进了QFI值接近1，纠缠熵处于0.8-1.0区间，电路深度和门计数最高减少90%。这些结果突显了将量子机器学习与张量网络结合优化复杂量子电路在实际约束下的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21243", "html_url": "https://arxiv.org/abs/2508.21243", "title": "全频域时域分割与结构化掩码以提升声学分类", "title_en": "Full-Frequency Temporal Patching and Structured Masking for Enhanced Audio Classification", "authors": "Aditya Makineni,Baocheng Geng,Qing Tian", "background": "Transformer和状态空间模型（SSMs）通过将频谱图作为时间序列的片块进行建模，提高了音频分类的表现。然而，现有的模型如Audio Spectrogram Transformer（AST）和Audio Mamba（AuM）采用了来自计算机视觉领域的正方形片块方法，这扰乱了连续的频率模式，产生了过多的片块，从而延长了训练时间和增加了计算量。", "innovation": "提出了一种称为全频域时域片块（FFTP）的新片块策略，该策略更好地适应了频谱图的时间-频率不对称性，通过局部时域上下文覆盖完整的频率带宽，保留了谐波结构，显著减少了片块数量和计算量。同时引入了SpecMask，这是一种基于片块的频谱图增强方法，结合了固定掩码预算下的全频域和局部时频掩码，增强了时间鲁棒性同时保持了频谱连续性。", "conclusion": "应用我们的片块方法和SpecMask在AST和AuM上，分别在AudioSet-18k和SpeechCommandsV2上提高mAP和准确性分别高达6.76%和8.46%，同时计算量减少高达83.26%，展现出了性能和效率的双重提升。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "层间SSL特征能否提高儿童语音零样本ASR性能？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "自动语音识别（ASR）系统经常难以准确处理儿童的语音，因为儿童语音具有不同的和高度可变的声学和语言特征。虽然最近的自我监督学习（SSL）模型大幅提高了成人语音的转录性能，但准确转录儿童语音仍然是一个显著的挑战。这项研究调查了从最先进的SSL预训练模型中提取的层间特征（具体而言，是Wav2Vec2、HuBERT、Data2Vec和WavLM）在零样本场景中增强儿童语音ASR性能的效果。研究使用WSJCAM0成人语音进行训练，使用PFSTAR儿童语音进行测试，将提取的特征整合到简化DNN基于的ASR系统中（使用Kaldi工具包）。", "innovation": "研究发现，Wav2Vec2模型的第22层特征在零样本场景中获得了最低的词错误率（5.15%），相比直接使用Wav2Vec2零样本解码（词错误率为10.65%），提高了51.64%的相对性能。此外，按年龄段分析表明，随着年龄的增加性能持续改善，并且即使在较小年龄段也观察到了显著的性能提升，证明了该方法的普适性。进一步在CMU Kids数据集上的试验也发现了类似的趋势，突显了所提方法的泛化能力。", "conclusion": "研究表明，从一些最先进的SSL预训练模型中提取的层间特征能够显著提高儿童语音的零样本ASR性能，特别是在Wav2Vec2模型的第22层特征上表现尤为突出，相对于原始模型的直接零样本解码，性能提升了51.64%。 "}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21246", "html_url": "https://arxiv.org/abs/2508.21246", "title": "HCQA: 混合经典-量子代理生成最优量子传感器电路", "title_en": "HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits", "authors": "Ahmad Alomari,Sathish A. P. Kumar", "background": "本文提出了一个混合经典-量子代理（HCQA），用于设计最优量子传感器电路（QSCs），以应对复杂的量子物理问题。该研究旨在通过结合经典和量子计算的优势来优化量子传感器设计，特别是在量子 Fisher 信息（QFI）敏感的纠缠量子态生成方面，这对于量子状态估计和控制至关重要。", "innovation": "该研究创新性地结合了深度 Q 网络（DQN）和基于 Q 值的量子行动选择机制，利用混合经典-量子代理来学习和优化策略。量子电路使用 Ry 门来编码代理当前状态，并创建可能动作的叠加态。通过测量电路来获取动作的概率结果，从而使代理能够通过选择最大化 QFI 的门序列并最小化门的数量来生成最优 QSCs。这种基于人工智能的 HCQA 能够自动生成具有高 QFI 敏感性的纠缠量子态，特别是压缩态，以提高传感和估计任务的效果。", "conclusion": "通过在包含两个量子比特和 Rx, Ry, S 门序列的 QSC 上进行评估，系统地证明了 HCQA 在生成具有 QFI 为 1 的最优 QSC 方面的效率。这表明 HCQA 在量子传感器电路设计方面具有重大潜力，特别是在 AI 驱动的学习和量子计算的协同作用方面。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "胸部X光片中肺部疾病严重程度分类的深度主动学习：在类别不平衡情况下使用较少数据学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "为了减少由于类别不平衡而导致的肺部疾病严重程度从胸部X光片(CXR)分类所需标注数据的数量，本研究应用了带有贝叶斯神经网络(BNN)近似和加权损失函数的深度主动学习方法。研究回顾性收集了2020年1月至11月期间在埃默里卫生保健附属医院接受治疗的963名患者(平均年龄59.2 ± 16.6岁；481名女性)的2319张胸部X光片，所有患者均被临床确认为患有COVID-19。每位患者的CXR由3到6名分别进行认证的放射科医师独立标记为正常、中度或严重。该研究通过主动学习训练了一个蒙特卡洛丢弃(deep neural network with Monte Carlo Dropout)来分类疾病严重程度，并使用不同的获取功能迭代地从未标注数据池中选择最有信息性的样本。性能通过准确率、受试者操作特征曲线下的面积(AU ROC)和精确召回曲线下面积(AU PRC)进行评估。", "innovation": "本研究通过应用带有贝叶斯神经网络近似和加权损失函数的深度主动学习方法，减少了肺部疾病分类所需标识数据的数量，特别是在类别不平衡的情况下。研究展示了使用熵采样在二分类任务中只使用15.4%的数据达到了93.7%的准确率（AUC ROC 0.91）。在多分类设置中，使用平均标准差采样在23.1%的数据下取得了70.3%的准确率（AUC ROC 0.86）。这些方法在更简单的获取策略下表现出色，并显著降低了标识需求。", "conclusion": "深度主动学习结合BNN近似和加权损失函数有效地减少了标注数据的需求，同时处理类别不平衡问题，并在诊断性能上保持或超过了传统方法的水平。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：一种高效的自我一致性幻觉检测管道", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大语言模型（LLMs）在研究和实际应用中表现出色，但仍然难以避免幻觉问题。现有的幻觉检测方法往往在句子生成层面表现不佳，或者依赖于特定领域的知识。虽然自我一致性方法可以解决这些问题，但由于重复生成带来的高计算成本，这些方法的应用受到了限制。已有研究表明，不必要的冗余生成是导致高计算成本的主要原因，这些冗余主要表现在，即使有相同的前缀代码，生成的内容也缺乏必要的区分性。这种方法的关键在于识别自我一致性方法中的冗余，即在多次生成中共享的前缀token，并发现这些非精确答案token对语义内容的贡献很小。基于这些见解，该研究提出了一个新的解码记忆管道（DMP），通过选择性推理和退火解码来加速生成过程，从而提高生成效率，而不改变模型、数据集、解码策略或自我一致性基准。实验结果表明，该方法可以在不牺牲AUROC性能的情况下提高三倍的速度。此外，DMP对齐和推理解题任务有很大的扩展潜力。", "innovation": "该研究首次探讨了识别自我一致性方法中的冗余，这些冗余表现为在多次生成中共享的前缀token。它提出了一种新颖的解码记忆管道（DMP），通过选择性推理和退火解码来加速生成过程。这种方法不同于模型、数据集、解码策略和自我一致性基准，能够在不牺牲性能的前提下显著提高生成效率，并且为扩展到对齐和推理任务提供了可能。实验结果显示，DMP方法在保持AUROC性能的同时，实现了高达三倍的速度提升。这种方法的核心创新在于利用选择性推理和解码退火机制来减少不必要的计算成本，并提供了一种新的解决方案来处理幻觉问题。", "conclusion": "本研究通过识别自我一致性方法中的冗余，提出了解码记忆管道（DMP），该方法通过选择性推理和解码退火机制显著提高了生成效率。实验验证了DMP在保持性能的同时，实现了显著的速度提升。此方法不仅解决了幻觉问题，还为对齐和推理任务的扩展提供了可能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "从代码生成模型中高效生成代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "该研究背景在于开发一种新型的代码嵌入模型集合，旨在从自然语言查询中检索代码、进行技术问题解答，以及跨编程语言识别语义相似的代码片段。现有的模型在这方面取得了进展，但仍有改进空间，特别是在模型效率和准确性方面。", "innovation": "本研究创新性地使用了一个同时在文本和代码上进行预训练的自回归骨干模型，通过最后一个生成的标记的聚类生成嵌入。这种方法证明了在相对较小模型规模的情况下，仍然能够取得最先进的性能。", "conclusion": "通过训练策略的描述和实验验证，研究证明了这种方法的有效性，并展示了其在代码嵌入模型构建方面的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21248", "html_url": "https://arxiv.org/abs/2508.21248", "title": "使用SSL模型层wise特征的儿童语音零样本关键短语检测", "title_en": "Zero-Shot KWS for Children's Speech using Layer-Wise Features from SSL Models", "authors": "Subham Kutum,Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Mahesh Chandra Govil", "background": "尽管成人语音的关键短语检测（KWS）有许多改进方法，但儿童语音的关键短语检测面临着独特的挑战，因为其具有独特的声学和语言特征。因此，有必要研究一种新的方法来解决这些挑战，提高儿童语音的关键短语检测性能。本文采用了一种基于零样本学习的方法，利用最先进的自我监督学习（SSL）模型，如Wav2Vec2、HuBERT和Data2Vec，提取其层wise特征，并通过Kaldi基于神经网络的关键短语检测系统进行了训练，测试数据集是PFSTAR儿童语音数据集和WSJCAM0成人语音数据集。", "innovation": "该研究的创新在于提出了一种利用SSL模型层wise特征的零样本关键短语检测方法，并实现了在儿童语音数据集上的最佳性能。具体而言，Wav2Vec2模型中的第22层表现最佳，取得了ATWV 0.691、MTWV 0.7003以及误报率和漏报率分别为0.0164和0.0547的结果，针对30个关键词集。此外，该方法还证明了其在不同年龄段儿童中的有效性，并在噪声条件下表现出色，相比传统的MFCC基线有显著改进。", "conclusion": "本文通过提取并利用SSL模型的层wise特征，使用零样本学习的方法提高了儿童语音的关键短语检测性能。该方法的有效性不仅在成人语音数据集上得到了验证，还在噪声条件下和额外的CMU数据集上得到了进一步验证。结果表明，SSL特征对零样本儿童关键短语检测任务具有显著的贡献，能够有效克服儿童说话者特有的挑战。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21259", "html_url": "https://arxiv.org/abs/2508.21259", "title": "打破冷启动障碍：双重和 Dueling DQN 结合强化学习", "title_en": "Breaking the Cold-Start Barrier: Reinforcement Learning with Double and Dueling DQNs", "authors": "Minda Zhao", "background": "推荐系统在面对新用户时难以提供准确的推荐，尤其是当这些用户只有有限的交互历史时，这个问题被称为冷用户问题。传统的推荐方法如基于流行的策略和主动学习策略在这类情况下效果并不理想，因为它们依赖于敏感的用户特征数据，且在用户只有少量交互数据的情况下无法有效学习用户的偏好。因此，开发一种能够在仅靠少量稀疏反馈的情况下动态学习用户偏好的方法变得至关重要，且对用户隐私有严格要求的环境下更为关键。", "innovation": "本文提出了一种使用双重和 Dueling 深度 Q 网络（DQN）的强化学习方法，通过动态学习用户偏好来改进推荐系统的准确性，而不依赖敏感的用户特征数据。此外，该方法将这些先进的 DQN 变体与矩阵分解模型相结合，在大规模电子商务数据集上取得了比传统方法更好的性能。研究表明，尤其是 Dueling DQN 方法在减少冷用户推荐的均方根误差（RMSE）方面表现出色，为隐私受限环境提供了有效解决方案。", "conclusion": "本研究提出的方法在大规模电子商务数据集上取得了良好的效果，通过使用双重和 Dueling DQN 深度 Q 网络，不仅能够有效减少冷用户的推荐误差，而且由于不依赖敏感的用户特征数据，因此更加适合隐私约束的环境。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21285", "html_url": "https://arxiv.org/abs/2508.21285", "title": "对大型语言模型进行金融脑扫描", "title_en": "A Financial Brain Scan of the LLM", "authors": "Hui Chen,Antoine Didisheim,Luciano Somoza,Hanqing Tian", "background": "新兴的计算机科学技术使得对大型语言模型（LLMs）进行“脑扫描”成为可能，通过这种方法，可以识别指导它们推理的简单英语概念，并在保持其他因素不变的情况下引导它们。这项研究展示了这种技术能够把LLMs生成的经济预测与情绪、技术分析和时间相关的概念建立映射，并且在不降低性能的前提下计算这些概念的重要性。同时，这种方法可以引导模型变得更加审慎或乐观/悲观，使得研究人员能够纠正或模拟模型中的偏见。这种方法具有透明性、轻量级以及可复制性，适用于社会科学领域的实证研究。", "innovation": "这项研究展示了使用脑扫描技术来分析大型语言模型的创新方法，能够将模型生成的经济预测与情绪、技术分析、时间相关的概念进行映射，并计算这些概念的重要性。此外，还可以通过这种方法引导模型产生不同倾向的预测结果，为纠正或模拟模型偏见提供可能。这种方法具有解释性和透明性，可以被研究人员重复使用。", "conclusion": "研究通过一种透明、轻量级且可复制的方法能够在不牺牲性能的情况下揭示和引导大型语言模型的思维方式。这种方法为社会科学研究，特别是金融预测分析领域提供了新的思路。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff：基于扩散模型的阶段式长序列时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型在时间序列生成领域取得了显著成功。但在处理长期时间序列时，尤其是在这些序列跨越较长时期并展示复杂长期时间模式的情况下，生成任务变得极其具有挑战性。长期时间序列表现出长期相关的依赖性，但其数据分布随着时间逐渐变化。由此带来的长期依赖性和数据分布漂移之间的平衡挑战，以及序列间复杂关系的捕捉，这些都构成了长期时间序列生成的难点。", "innovation": "本文提出了一种基于扩散模型的阶段式生成模型——Stage-Diff，通过阶段序列生成和阶段间信息传递保留长期序列依赖性，同时建模数据分布变化。此外，每个阶段应用逐级序列分解进行时间尺度上的独立通道建模，而阶段间信息传递则采用多通道融合建模。这种方法结合了独立通道建模的稳健性和多通道建模的信息融合优势，有效平衡了长期时间序列的序列内和序列间依赖性。", "conclusion": "在多个真实世界数据集上的广泛实验验证了Stage-Diff在长期时间序列生成任务上的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "自适应重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型的时代，优化算法往往因为过度依赖训练损失而难以实现良好的泛化能力。机器学习领域的一个广泛接受的观点是，宽阔的盆地（局部极小值周围的区域，其中损失随着输入数据或模型参数的小变化逐渐增加）能够更好地促进泛化，提供更大的输入数据或模型参数微小变化的稳定性，而尖锐的极小值则通常更加敏感和不稳定。受梯度噪声本身的重尾分布和神经网络训练期间的临界状态现象的影响，不确定性在增长后会稳定在一个高原上，该现象激发了我们的研究。", "innovation": "提出了自适应重尾随机梯度下降（AHTSGD）算法，该算法在训练早期阶段注入更重尾的噪声以增强探索，并随着尖锐度的稳定而逐渐过渡到较轻尾的噪声。通过在整个训练过程中动态适应损失景观的尖锐度，AHTSGD促进了快速收敛到宽阔的盆地。AHTSGD 是首个基于临界状态现象调整注入噪声类型的优化算法。AHTSGD 在 MNIST、CIFAR-10 等基准测试中优于 SGD 和其他噪声基方法，并在 SVHN 等嘈杂数据集上表现出显著优势。它能够加速从初始较差条件下进行的早期训练，并在干净和嘈杂环境中提高泛化能力，同时对学习率选择具有鲁棒性。", "conclusion": "自适应重尾随机梯度下降算法在多个基准测试中表现出色，特别是在嘈杂数据集上取得了显著的改进，并且在不同环境和学习率设置下都具有鲁棒性，促进了神经网络的优化和泛化性能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX重访：通过自动图描述增强基准覆盖", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大型语言模型（LLMs）能力的提升，尤其是在多语言和非英语环境中，需要更强大的评估方法。本文更新了BLUEX数据集，增加了2024-2025年的考试内容以及使用最新技术生成的自动图像描述，从而增强了该数据集在LLM预训练时数据污染研究的相关性。", "innovation": "本研究更新了BLUEX数据集，包括新年的考试内容和高质量的自动图像描述生成。这些更新使得数据集更适用于LLM预训练中的数据污染研究，同时提升文本模型的可访问性超过40%。此外，评估了商业和开源LLM对通过图描述利用视觉上下文的能力。", "conclusion": "更新后的BLUEX数据集和新的图像描述生成策略增强了评估LLM对视觉上下文利用能力的基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "现有的持续学习方法依赖于存储先前任务的样本（经验回放）或采用复杂的正则化项来保护已学习的权重。这些方法面临数据隐私、存储限制以及在任务多样化时性能衰退的挑战。", "innovation": "MyGO框架借鉴了生物的清醒-睡眠循环，引入了一个新颖的生命周期学习框架。在“清醒”阶段，系统快速学习新任务并训练一个紧凑的生成模型（生成记忆，G-mem）来捕捉数据分布。在“睡眠”阶段，系统进入离线状态，使用所有已学习的G-mem模型生成伪数据（梦境），并通过知识蒸馏将新旧知识合并到核心特征提取器中。这种方法消除了存储任何原始数据的需要，仅保留紧凑的生成模型，从而在隐私和存储效率方面具有显著优势。", "conclusion": "MyGO在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准测试中表现显著，成功减轻了灾难性遗忘并保持高平均准确性，验证了该框架的有效性和跨域性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "阶梯通往公平：连接群体公平与个体公平", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统（RS）中的公平性通常被分为群体公平性和个体公平性两种类型。然而，此前对于这两种类型的公平性研究分别采用不同的评估度量或评估目标，导致无法建立两者之间的科学关系理解，尚不清楚提高一种公平性类型是否会影响另一种公平性类型。因此，目前还不清楚如何提高群体公平性会导致怎样的个体公平性变化。", "innovation": "本文通过全面比较适用于两种公平类型的评估测量方法，研究了群体公平性和个体公平性之间的关系。实验结果表明，高群体公平性的推荐结果可能对个体非常不公平。这一发现为致力于改进推荐系统公平性的实践提供了新的见解和有用信息。", "conclusion": "我们的实验结果展示了群体公平性和个体公平性之间复杂的关系，提出了对这两种公正性的评估方法，并强调了在追求一种公正性时可能带来的另一公正性的减少。这一发现有望为RS从业者提供改进公平性的方法和思路。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN: 基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列合成是一种有效的方法，用于确保时间序列数据的安全流通。现有的时间序列合成方法通常基于随机序列进行时间建模以生成目标序列，这往往难以保证生成时间序列中的时间依赖性。直接在随机序列上建模时间特征也使得准确捕捉原始时间序列的特征信息变得困难。", "innovation": "该论文提出了一种简单的但有效的生成模型：双层生成对抗网络（Dual-Layer Generative Adversarial Networks，DLGAN）。该模型将时间序列生成过程分为两个阶段：序列特征提取和序列重建。第一阶段构建了一个完整的自编码器，使得模型可以通过监督学习在原始时间序列上进行训练，确保重建过程可以恢复时间序列的时间依赖性。第二阶段使用生成对抗网络（GAN）生成与实时序列特征向量对齐的合成特征向量，确保生成器可以从真实时间序列中捕捉时间特征。", "conclusion": "在四个公共数据集上的广泛实验表明，这种模型在各种评估指标上具有优越性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常性和图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文旨在重新审视图灵测试，通过引入\"正常\"的概念。文章指出，图灵测试实际上是在衡量普通智力而非非凡智力，这要求机器能够表现出与普通人类似的行为。此外，图灵测试本质上是一种统计测试，因为它并非由单一的非专家评判者来评估，而是由一个完整的陪审团来决定。文中认为，图灵在其原始论文中提到的\"平均人类询问者\"是一个数学抽象概念，即来自多个评判者的个体判断的规范化汇总。", "innovation": "本文创新地提出了重新解读图灵测试的方法，即从\"正常\"的角度来理解图灵测试，强调测试旨在考察普通人的智力而非非凡智力。此外，它还提出了\"人工聪慧\"与\"人工智能\"之间的区别，并对\"正常主义\"范式及其对人类认知理解的问题提出了质疑。", "conclusion": "作者认为大型语言模型如ChatGPT不太可能通过图灵测试，因为这些模型的目标是非凡而非普通智力。它们更像是\"人工聪慧\"模型，而非纯粹的人工智能。此外，图灵测试的核心问题在于人类心智是否真的可以归结为普通心智，这是一个超越图灵测试本身的问题，挑战了正常主义范式的概念基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "象棋博弈神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "本文研究了神经网络在其表示学习过程中是否通过平滑、渐进的改进，还是通过更复杂的计算过程。研究者通过将对数几率视角扩展到分析Leela Chess Zero的策略网络（这是一个超人类的象棋引擎）来探索这个问题。Leela Chess Zero是由Mozilla Research开发的一种基于卷积神经网络和蒙特卡洛树搜索的超级人类象棋引擎。", "innovation": "研究发现在网络层间存在强大的单调趋势，但是策略分布却经常遵循非平滑轨迹。这包括早期发现正确解谜但在之后被丢弃，棋步排序与最终输出之间的相关性较差，直到接近网络的末端才出现策略分歧。这些发现与在语言模型中通常观察到的平滑分布收敛形成了对比。", "conclusion": "该研究提供了一种新的视角，即在象棋博弈神经网络的学习过程中，存在复杂的计算过程，这与语言模型的平滑分布收敛模型有所不同。研究发现策略网络中的策略分布通常是非平滑的，且在训练的后期才出现显著的策略分歧。这为神经网络的表示学习过程提供了深入的见解，并指出了可能需要改进的地方。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus: 自主合成谓词以提高定向模糊测试的效率", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向模糊测试旨在查找导致特定程序状态的输入，具有广泛的应用，如调试系统崩溃、确认已报告的错误和挖掘潜在漏洞的利用程序。然而，由于目标状态常常嵌入在程序内部的深处，而无数可能的程序输入导致的搜索空间又极为庞大，因此这一任务本就极具挑战性。现有的方法依赖分支距离或手动指定的约束来指导搜索过程，但仅靠分支通常不足以精确描述接近目标状态的进度，而手动指定的约束往往只能针对特定的错误类型，难以推广到各种类型的目标状态和程序中。", "innovation": "我们提出了Locus，一个创新的框架，用于提升定向模糊测试的效率。Locus的关键见解是合成谓词来捕捉模糊测试的进展作为语义上具有中间状态意义的中间状态，作为通往目标状态的里程碑，从而在对程序进行模糊测试时可以拒绝不可能到达目标状态的执行，同时提供额外的覆盖指导。Locus具备一个自主框架，结合程序分析工具来合成并逐步细化候选谓词，确保谓词严格放宽目标状态，以避免通过符号执行的误拒。我们的评估表明，Locus大幅提升了八种最先进的模糊测试器在发现真实漏洞上的效率，平均加速41.6倍。迄今为止，Locus已发现了八个尚未修复的错误，其中一个已经被提交了一个草案补丁。", "conclusion": "Locus通过合成语义合理的中间状态谓词，显著提高了模糊测试的效率和覆盖范围，特别是那些难以通过传统方法检测和利用的目标状态。这种新框架不仅适用于特定的错误类型，还能推广到多样化的程序环境中，标志着面向未来模糊测试方法的发展方向。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一个用于比较摘要评估指标的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文探讨了自动文本摘要评估中可再现性挑战的问题。通过在六种代表性指标上进行实验，包括经典方法如ROUGE以及近年基于LLM的方法（G-Eval, SEval-Ex），研究发现在文献中报告的表现与实际实验结果之间存在显著差异。研究还发现了结构性的权衡：最接近人类判断的指标往往是计算成本高且运行稳定性较差的。", "innovation": "本文引入了一个统一的开源框架，应用于SummEval数据集，旨在支持评估指标的公平透明比较。此研究凸显了依赖于LLM进行评估的关键问题，包括其随机性、技术依赖性和有限的可再现性。", "conclusion": "本文结果揭示了评估协议的稳健性问题，包括详尽的文档编制和方法标准化，以确保自动摘要评估的更高可靠性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT与DeepSeek模型家族的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在各个行业中改变AI的应用，但其开发和部署仍然复杂。本文回顾了16个关键挑战，这些挑战涉及构建和使用LLMs。文章通过对比开源模型DeepSeek-V3-0324（2025年3月更新）和闭源模型OpenAI的GPT-4o（2024年5月更新）来研究这些挑战。文章探讨了闭源模型和开源模型之间的权衡，如安全性、可靠性和效率、适应性，并分析了LLMs在不同领域的应用，突显了最适合每种应用场景的模型属性。", "innovation": "文章将比较闭源模型（如GPT-4o）和开源模型（如DeepSeek-V3-0324），展示了两者之间的权衡，包括安全性、可靠性、效率和适应性。文章还探讨了LLMs在不同领域的应用情况，并指出了最适合特定应用场景的模型特性。这对于指导AI研究人员、开发者和决策者理解当前LLMs的能力、局限和最佳实践具有重要作用。", "conclusion": "本文旨在帮助AI研究人员、开发者和决策者理解当前大型语言模型的能力、局限性和最佳实践，同时展示了闭源模型和开源模型之间的权衡，并强调了各种模型属性在不同应用场景中的适用性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21368", "html_url": "https://arxiv.org/abs/2508.21368", "title": "EconAgentic在分散物理基础设施市场中的应用：大规模语言模型方法研究去中心物理基础设施共享经济", "title_en": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "authors": "Yulin Liu,Mocca Schweitzer", "background": "分散物理基础设施(DePIN)市场通过基于代币的经济学和智能合约的治理模式，正在改变共享经济。到2024年，DePIN项目市场资本化已超过100亿美元，显示出其快速增长。然而，这些市场的未经监管以及智能合约中自主部署的AI代理带来的风险，如效率低下和与人类价值观的潜在偏差，使得这些问题日益突出。因此，通过引入EconAgentic框架，该框架由大规模语言模型（LLM）驱动，本文旨在解决这些挑战，主要研究DePIN市场的动态演变、评估利益相关者行为的影响与宏观经济指标分析这三个领域，以使市场结果与社会目标一致。", "innovation": "EconAgentic是一个由大规模语言模型（LLM）驱动的框架，能够模拟AI代理对代币激励的响应、基础设施的投资以及对市场条件的适应。通过将AI驱动的决策与人类直觉基准进行比较，EconAgentic提供了关于DePIN市场的效率、包容性和稳定性的有价值见解，从而为分散、代币化经济的设计和治理提供了学术理解和实践改进。", "conclusion": "EconAgentic框架对于理解DePIN市场的动态和经济影响具有重要意义，不仅能增强对当前共享经济实践中挑战的认识，还能够为该领域的设计和监管贡献力量，推动更加高效和公平的市场发展。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过基于像素的方法增强自回归语言模型对拼写攻击的健壮性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型容易受到拼写攻击的影响，当输入文本被多语言字母表的字符中断时，会导致性能显著下降。这一脆弱性主要是由于子词标记器和嵌入中的词汇量不足问题。", "innovation": "提出了一种基于像素的生成语言模型，将基于文本的嵌入替换为基于像素的表示，通过将单词渲染为单独的图像来增强模型的鲁棒性，同时扩大对不同书写系统的多语言文本的兼容性。", "conclusion": "在多语言LAMBADA数据集、WMT24数据集和SST-2基准上对提出的模型进行了评估，证明了其对拼写噪声的抗性和在多语言环境中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "用于外部气动仿真的专家混合门网络以增强的代理建模", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "在汽车设计和优化过程中，高保真计算流体动力学（CFD）仿真所引起的计算成本仍然是一个重要的瓶颈。虽然基于机器学习（ML）的代理模型已经出现了作为加速气动力预测的有希望的替代方案，但该领域的特殊神经网络架构呈现出多样化和快速演变的特点，并没有单一模型表现出普遍的优越性。", "innovation": "本文提出了一种新型的元学习框架，利用各种神经网络架构的多样性作为其优势。我们提出了一种专家混合模型（MoE），它通过一个专门的门控网络动态且优化地组合了三个最先进的代理模型：DoMINO（可分解的多尺度神经算子）、X-MeshGraphNet（可扩展的多尺度图神经网络）和FigConvNet（因子化隐式全局卷积网络）的预测。门控网络学习空间变异性加权策略，根据其在预测表面压力和壁面剪切应力场方面局部性能，对每个专家赋予可信度。通过在训练损失函数中集成熵正则化项来防止模型崩溃并促进专家贡献的均衡。", "conclusion": "实验证明，MoE模型在L-2预测误差上取得了显著减少，不仅优于单一专家模型的平均值，而且在所有评估的物理量上也优于最准确的单一模型。这项工作为如何通过协同利用专门架构的互补优点来创建更稳健和准确的复合代理模型确立了MoE框架作为强大的有效策略。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21378", "html_url": "https://arxiv.org/abs/2508.21378", "title": "RoboInspector: 揭示LLM增强机器人操作中策略代码的不可靠性", "title_en": "RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation", "authors": "Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu", "background": "大型语言模型（LLMs）在推理和代码生成方面表现出显著的能力，能够仅通过一个指令启动机器人的操作。LLMs通过生成控制机器人的策略代码来执行各种任务。尽管LLMs取得了进步，但在实际任务中的复杂性和用户指令的多样性仍然使得策略代码的可靠生成成为一个重大挑战。不同的用户可能针对同一任务给出不同的指令，这会进一步导致策略代码生成的不稳定性。因此，RoboInspector的设计目的是从任务复杂性和指令粒度两个视角揭示LLM驱动的机器人操作中策略代码的不可靠性并进行量化分析。", "innovation": "RoboInspector设计了一个管道，用于从任务复杂度和指令粒度两个方面揭示和刻画LLM驱动的机器人操作中策略代码的不可靠性。该研究还在两个知名框架中进行了全面实验，发现了导致操作失败的四种主要不可靠行为，并通过反馈不佳的策略代码来引导细化方法提高策略代码生成的可靠性，提升了35%。这种方法在仿真和现实环境中都进行了验证。", "conclusion": "RoboInspector从任务复杂性和指令粒度两个方面揭示了LLM驱动的机器人操作中策略代码的不可靠性，并提供了解决方案以减少这种不可靠性。通过引入反馈指导的细化方法，实验证明可以显著提高策略代码生成的可靠性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "复杂性陷阱：简单观察掩盖与LLM总结一样高效，用于代理上下文管理", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "基于大规模语言模型（LLM）的代理通过迭代推理、探索和工具使用解决复杂任务，但这一过程会产生长且昂贵的历史上下文。现有软件工程代理如OpenHands或Cursor使用基于LLM的总结来应对这一挑战，但是这种额外的复杂性是否能真正提高性能尚不清楚。因此，研究人员对比分析了简化策略（如观察掩盖）和基于LLM总结策略在软件工程代理中处理上下文管理的有效性和效率。", "innovation": "本研究系统地比较了简化策略（如观察掩盖）和基于LLM总结策略在软件工程代理中的性能，以验证这些策略的有效性和效率。研究发现，在软件工程代理（SWE-agent）和SWE-bench验证模型配置下，简单的观察掩盖策略相对于裸代理降低了50%的成本，并且在解决率上与LLM总结相当，甚至在某些情况下超出。", "conclusion": "结果表明，至少在软件工程代理SWE-agent和SWE-bench验证模型配置下，最有效且高效的上下文管理策略可能是最简单的。文中也发布了代码和数据以确保可复现性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21393", "html_url": "https://arxiv.org/abs/2508.21393", "title": "zkLoRA: 使用零知识证明实现可验证安全的大语言模型微调", "title_en": "zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs", "authors": "Guofu Liao,Taotao Wang,Shengli Zhang,Jiqun Zhang,Shi Long,Dacheng Tao", "background": "大语言模型（LLMs）的微调对于使它们适应特定任务至关重要，但这一过程仍然计算密集型并对正确性和隐私提出了挑战，尤其是在不受信任的环境中。尽管低秩适应（LoRA）等参数有效方法大幅减少了资源需求，但在零知识约束下保证微调的安全性和可验证性仍然是一个未解决的挑战。", "innovation": "我们提出了一种名为zkLoRA的新框架，它将LoRA微调与零知识证明（ZKPs）结合在一起，实现了可验证的安全性和正确性。zkLoRA使用先进的密码技术，如查找论证、求和检查协议和多项式承诺，来验证Transformer架构中的算术和非算术操作。该框架提供了端到端可验证性，包括LoRA微调过程中的前向传播、后向传播和参数更新，同时保护模型参数和训练数据的隐私。", "conclusion": "通过将参数有效微调与ZKPs相结合，zkLoRA填补了关键空白，使得在敏感或不受信任的环境中安全、可信地部署LLMs成为可能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift: 显式条件传输在X射线领域适应中的应用", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医学数据能够为训练鲁棒模型提供可扩展的解决方案，但其在不同临床环境中的普适性因领域间的巨大差距受到限制。本文研究合成与真实头颅X光图像之间的跨领域翻译挑战，重点在于弥合衰减行为、噪声特征和软组织表示方面的差异。", "innovation": "提出了一种名为MedShift的统一类条件生成模型，基于Flow Matching和Schrödinger Bridges技术，能够实现多领域之间的高质量、无配对图像翻译。与需要特定领域训练或依赖配对数据的先前方法不同，MedShift学习到一个领域无关的共享隐空间，支持在训练期间遇到的任意配对领域之间的无缝翻译。", "conclusion": "通过引入X-DigiSkull数据集，本文验证了MedShift的强大性能和灵活性，即使模型大小较小，也优于基于扩散的方法。在推断过程中，它可以调节以优先考虑感知保真度或结构一致性，使MedShift成为医学成像领域适应的可扩展和普适性解决方案。相关代码和数据集可在该网址获取。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "中小语言模型激发创意写作：LLM评判员与多代理精炼奖励的对比", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大规模语言模型（LLMs）展示了出色的创意写作能力，但其巨大的计算需求制约了其广泛应用。相比之下，提升小型语言模型（SLMs）是一种有前景的选择，然而当前方法如监督微调（SFT）在创新性方面存在不足，而从人类反馈中强化学习（RLHF）则成本高昂。", "innovation": "本文在人工反馈强化学习（RLAIF）框架下探索了两种不同的AI驱动奖励策略。第一种策略采用一种基于高质偏好数据训练的多代理拒绝采样框架来训练的奖励模型，第二种策略则是采用一种原理导向的LLM作为裁判，其奖励函数通过对抗训练和反思机制优化。实验证明，通过这两种方法，可以获得显著增强的创意性输出，而原则导向的LLM作为裁判方法不仅生成质量更高，还在训练效率和减少对人类标注数据的依赖性方面显示出明显优势。", "conclusion": "实验结果表明，这两种方法都显著提升了基础模型的创意输出，而原则导向的LLM作为裁判方法不仅生成质量更高，还在训练效率和减少对人类标注数据的依赖性方面显示出明显优势。此外，我们的自动评估方法与人类判断高度一致，相关代码和数据已经公开。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21407", "html_url": "https://arxiv.org/abs/2508.21407", "title": "DRASP: 双分辨率注意统计池化框架以实现自动MOS预测", "title_en": "DRASP: A Dual-Resolution Attentive Statistics Pooling Framework for Automatic MOS Prediction", "authors": "Cheng-Yeh Yang,Kuan-Tang Huang,Chien-Chun Wang,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen", "background": "现有的池化方法通常只能提供单一的粒度视角，要么侧重于全面的全局观，要么专注于详细的帧级分析，这种单一视角可能忽略了互补的感知洞察。因此，一个适用于不同粒度的池化机制是进行质量预测的音频特征的必要手段，特别是对于语音质量的MOS预测，它需要从整体结构和局部特征上提供一个简洁有效的固定大小表示。现有的方法在捕捉广泛感知信息方面存在局限性，这限制了其预测质量。", "innovation": "DRASP框架通过结合粗粒度的全局统计摘要和细粒度的注意力分析，提供了一个双视角架构，能够同时捕捉整体结构上下文和重要的局部细节。其创新点在于能够提供多尺度的信息整合，有效补充了现有池化机制的单一视角不足，这使得模型在复杂多样的音频处理系统中表现更加出色。DRASP框架通过双分辨率关注点同时处理全局和局部特征，从而导致了比常用平均池化更加高效的性能。", "conclusion": "经过广泛的实验验证，提出的框架在音乐评估（MusicEval）和AES-自然（AES-Natural）等多个数据集上，以及不同音频生成系统和MOS预测模型中，表现出色且具有较强的泛化能力。它在系统级斯皮尔曼秩相关系数（SRCC）上相对于广泛使用的平均池化方法实现了10.39%的相对性能提升。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于水库计算的低成本方法评估网络状态", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "利用挪威地区移动网络使用数据，研究展示了一种无需侵入性和成本低廉的监测通信与移动网络状态的方法。该方法通过将网络数据转化为水库计算框架下的模型，并通过代理任务评估模型性能来实现这一目标。研究通过实验验证了该方法的有效性。", "innovation": "该方法的优势在于利用了现有可访问的数据集，并且采用了水库计算框架，使得这种方法在成本低廉且很大程度上不受特定干扰的影响。通过将移动网络使用数据视为带权网络，并利用水库计算中的回声状态网络（ESN）作为机器学习工具，其相比于深度神经网络能节省能源。该研究还采用了灵感源自神经科学的任务来训练ESN模型，展示了其性能依赖于网络特定配置，并且受网络扰动时会下降。", "conclusion": "这项研究不仅作为概念证明展示了一种监测网络状态的方法，还表明该方法具有实时监测网络状态以及识别网络弱点的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21460", "html_url": "https://arxiv.org/abs/2508.21460", "title": "基于扩散的多模态协同兴趣网络用于点击率预测", "title_en": "Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction", "authors": "Xiaoxi Cui,Weihai Lu,Yu Tong,Yiheng Li,Zhejun Zhao", "background": "在点击率预测中，现有方法主要基于ID模态，难以全面建模用户的多模态偏好，因此提出了多模态点击率预测。尽管可以直接应用现有的多模态融合方法，但这些方法未能有效分离不同模态共性和特性，以及考虑模态之间的协同效应和复杂交互。", "innovation": "提出了一种基于扩散的多模态协同兴趣网络(Diff-MSIN)框架，该框架引入了三个创新模块：多模态特征增强(MFE)模块、协同关系捕获(SRC)模块和特征动态自适应融合(FFDAF)模块。MFE和SRC模块提取不同模态之间的协同信息，增强模态表示，提升融合质量。FDAF模块专注于捕捉用户偏好并减少融合噪声。设计了知识解耦方法，鼓励不同特征之间的差异性。", "conclusion": "通过在Rec-Tmall和三个Amazon数据集上的实验验证，结果表明该方法相比于基线模型改进了至少1.67%，展示出其提升多模态推荐系统的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度集成实现结构基于药物设计中的可控三维分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "最近，基于结构的药物设计（SBDD）中通过生成模型生成三维分子的研究取得了进展，但主要依据靶蛋白结合亲和力来评估模型性能。然而，实际药物发现还需要考虑合成可行性及选择性等关键性质，这些因素在之前的评估中被忽视了。先前的研究中，常规的扩散型生成模型在引导分子生成以满足这些多样化的药理性质方面存在局限性。为了弥补这一不足，作者提出了一种新的框架CByG，该框架结合了贝叶斯流网络和梯度集成，能够稳健地整合与目标相关的性质指导。此外，研究还引入了一个综合的评价方案，包括结合实际基准的结合亲和力、合成可行性和选择性评价，以克服传统评价方法的局限性。", "innovation": "提出了一种新颖的框架CByG，将贝叶斯流网络扩展为梯度导向的条件生成模型，能够稳健地整合与目标相关的特性指导。还介绍了一个全面的评价方案，结合实际基准对结合亲和力、合成可行性和选择性进行了评估，弥补了传统评估方法的不足。实验结果表明，CByG框架在多个关键评估指标上显著优于基础模型，突显了其在实际药物发现中的有效性和实用性。", "conclusion": "该研究提出的CByG框架在多个关键评估指标上显著优于基础模型，验证了其在实际药物发现中的有效性和实用性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 评估医疗多模态大型语言模型奖励模型和评判者的基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医疗应用中具有巨大潜力，包括疾病诊断和临床决策。然而，这些任务需要高精度、上下文相关和专业对齐的响应，因此需要可靠的奖励模型和评判者。现有基准主要关注一般性的MLLM功能或以模型解题者为评价标准，忽略了诊断准确性等关键评估维度。为了填补这一空白，本文介绍了一个名为Med-RewardBench的新基准，专门用于评估医疗场景下的奖励模型和评判者。该基准包含了涵盖13个器官系统和8个临床部门的多模态数据集，拥有1,026个由专家注释的案例，并通过严谨的三步流程确保高质量的评价数据，覆盖六项临床上关键的维度。", "innovation": "Med-RewardBench 是第一个专门用于评估医疗多模态大型语言模型（MLLMs）中的奖励模型和评判者的基准。它提供了覆盖13个器官系统和8个临床部门的多模态数据集，并通过严格的评价流程确保高质量的数据，涵盖了关键的临床维度。此外，它还评估了32个最先进的MLLM模型，并开发了基准模型，显示出通过微调实现显著性能提升的能力。这些突破性贡献解决了现有模型在与专业判断对接时存在的重大挑战。", "conclusion": "本文通过引入Med-RewardBench 基准，填补了医疗多模态大型语言模型评估领域的空白。该基准有助于识别和解决模型输出与专家判断的对齐问题，促进了该领域的研究和发展。未来的研究可以通过进一步优化这些模型和基准来提高医疗决策的精确性和临床相关性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的模型不一致问题", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "不确定性量化在强化学习中可以显著提高探索性和鲁棒性。尽管近来在无模型算法中利用近似贝叶斯方法量化不确定性变得流行，但现有的研究主要集中在提高后验近似的准确性上，而较少关注后验基础的先验和似然假设的准确性。论文指出，贝叶斯深度Q学习中存在一种“冷后验效应”，即降低后验的温度反而能够提高性能，与理论相反。常见的先验和似然假设经常被质疑，现有研究中广泛的高斯似然假设被证明常常不成立。因此，未来的研究应该更加关注构建更合适的先验和似然假设，以提高贝叶斯强化学习算法的性能。", "innovation": "研究揭示了贝叶斯深度Q学习中的“冷后验效应”，即降低后验的温度可以提高性能，挑战了理论预期。实验研究表明，常见的高斯似然假设在多个场景中不适用，提出的改进先验分布的简单方法能够提升算法性能。", "conclusion": "未来的研究应着重开发更适合的先验和似然假设，认为这是提高贝叶斯强化学习算法性能的关键。提供的改进先验的简单实施方案可以直接应用于深度Q学习中，提升算法的表现。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次选择的异质ensemble构建方法用于虚假新闻检测", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏差，如确认偏误，使人特别容易相信并在社交媒体上传播假新闻，这对公共健康和政治等领域产生了重大影响。基于机器学习的假新闻检测系统经过广泛研究以减轻这一问题。其中，集成方法特别有效，通过结合多个分类器来提高鲁棒性。然而，这些方法的表现高度依赖于组成部分分类器的多样性。当模型倾向于学习冗余模式时，挑选真正多样化的模型仍然是一个关键挑战。因此，本文提出了一种新的自动化分类器选择方法，该方法优先考虑多样性和性能。该方法首先计算分类器之间的成对多样性，并使用层次聚类组织它们以不同粒度级别来分组。然后，HierarchySelect 方法探索这些层次级别，以每个级别选择一个表示不同内群多样性的分类器池。最多样化的池被选中用于集成构造。选择过程结合了反映每个分类器性能的评估指标，以确保集成也能很好地泛化。实验使用四个不同领域的六个具有不同类别数量的数据集，以及40个异质分类器。与肘部启发法和最先进的基准方法进行对比的结果表明，本文的方法在六个数据集中的两个数据集上达到了最高的准确性。实现细节可在项目存储库中找到：this https URL.", "innovation": "提出了一种新的自动化分类器选择方法，该方法优先考虑多样性和性能，通过计算分类器之间的成对多样性，使用层次聚类组织分类器，并探索不同粒度级别的层次结构，从最多样化的池中选择分类器进行集成构建，同时结合评估指标确保集成也具有良好的泛化能力。", "conclusion": "该方法在六个数据集中的两个数据集上达到了最高的准确性。与肘部启发法和最先进的基准方法进行对比，显示了该方法的有效性，实现了合理的平衡，从而改进了虚假新闻检测中异质集成的方法。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正需要哪些数据？推荐系统推理数据最小化可行性的研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是一个法律原则，要求个人数据的处理仅限于为特定目的所需的信息。然而，对于依赖大量个人数据的推荐系统来说，如何将这一原则具体化并实现起来仍然面临着巨大的挑战。本文旨在评估在推荐系统中最小化隐含反馈推理数据的可行性。研究通过提出一种新颖的问题表述方式，分析各种最小化技术，并研究影响它们效果的关键因素，得出了实际中数据最小化仍面临巨大挑战的结论，尽管技术上是可行的。", "innovation": "本文提出了一个新的最小化问题表述，并分析了多种最小化技术及其影响因素。研究结果表明，在不显著影响性能的情况下，可以大量减少推理数据。然而，这种技术的实用性取决于技术和用户的具体情况，这使得制定一个普遍适用的数据必要性标准非常困难。", "conclusion": "虽然本文证明了数据最小化在技术上是可行的，但其实际操作性取决于技术设置和用户特性等因素，因此，制定一个适用于所有情况的数据必要性标准是困难的。在推荐系统中，数据最小化仍面临实际挑战。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 通过零样本CLIP预排序和多人参与排序的高效成对比较", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或难以标注的任务中，成对比较通常比绝对评级或序列表示更受欢迎，因为其提高了可靠性。然而，完整的成对比较需要大量的标注（O(n^2)）。近期的工作通过使用排序算法主动采样成对比较，将标注负担减少到O(n log n)。本文在此基础上进一步提高标注效率。", "innovation": "（1）使用 Contrastive Language-Image Pre-training (CLIP) 模型进行无监督层次化的粗略预排序；（2）利用自动化比较替换显而易见的人工比较。提出的 EZ-Sort 方法包括首先生成 CLIP 基础的零样本预排序，然后初始化基于桶的 Elo 评分，并最终运行带不确定性指导的人工辅助合并排序。", "conclusion": "使用 EZ-Sort 方法在 FGNET 的面部年龄估计、DHCI 的历史图像时间序列和 EyePACS 的视网膜图像质量评估等数据集上进行验证。结果表明，与完整的成对比较相比，该方法减少了90.5%的人工标注成本，与先前工作相比减少了19.8%的成本（当 n = 100 时），同时提高了或维持了评分间的可靠性。这些结果说明结合 CLIP 基础的先验与不确定性感知采样是成对排名高效且可扩展的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "关于学习基于GNN的SAT求解器的难度：图里奇曲率的作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "图神经网络（GNNs）最近通过处理逻辑公式的图表示显示出解决布尔可满足性问题（SATs）的潜力。然而，在处理更难的实例时，其性能显著下降，引发了关于这种下降是否反映了基本架构限制的疑问。本文通过图里奇曲率（RC），一种衡量局部连接瓶颈的量化方法，来提供一种几何解释。研究证明，来自随机k-SAT公式的双分图本质上是负曲率的，并且随着实例难度增加，曲率会降低。基于此，研究进一步表明，基于GNN的SAT求解器受过压缩现象影响，这种现象使得长程依赖关系无法压缩到固定长度的表示中。", "innovation": "本文首次提出将图里奇曲率作为一种衡量复杂性并预测性能的新方法，证明了这种方法的有效性，并基于此结果提出对现有求解器的设计原则进行了连接，并指出了未来研究的潜在方向。研究表明，曲率不仅能强烈指示问题复杂性，还可用于预测性能。此外，本文揭示了基于GNN的SAT求解器受过压缩现象的影响，这是对长程依赖关系处理的新视角。", "conclusion": "研究验证了通过图里奇曲率衡量问题复杂性和预测性能的有效性。同时还表明，对于更困难的实例，基于GNN的SAT求解器的性能下降可能反映了GNN架构的基本限制。未来的工作将探索如何利用图里奇曲率来优化GNN的设计，提升其在SAT求解中的表现。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "从单张图像通过去噪扩散模型生成完整的高斯点", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "高斯点差分通常需要场景的密集观测，并且容易在重建被遮挡和未观测到的区域时失败。单张图像推断期间，仅靠单张图像完成景观表面挑战巨大，因为这些表面可能出现多种可能的情况。现有方法通常采用基于回归的方法来预测单一的“模式”，这会导致模糊、不具说服力，并且难以捕捉多种可能的解释。它们往往部分地解决这个问题，要么仅孤立地重建某项对象，要么只重建可视表面，要么远离输入视角时无法进行适当的外推。因此，使用传统的回归方法预测单一模式，会导致推断效果较差，难以在360度渲染中准确完成被遮挡的表面。", "innovation": "本文提出了一种潜在扩散模型，能够在单张图像推断过程中仅从单张图像重构整个3D场景，包括被遮挡的部分。为了解决缺乏真实训练数据的问题，本文提出了一种自监督的变分自重构器，该模型仅通过二维图像学习潜在空间，然后在该空间上训练扩散模型。该方法生成忠实的重建结果，并能产生多样化的样本，能够在高质量的360度渲染中填补被遮挡的表面。", "conclusion": "本文提出的方法通过一项潜在扩散模型实现了从单张图像生成3D场景的完整高斯点，不仅能够生成完整且真实的重建结果，还具有多样化的样本生成能力，能够有效完成被遮挡部分，为高质量的360度渲染提供了可能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）本质上依赖于高质量的训练数据。现有方法在数据选择和数据合成方面虽然有所改进，但在静态数据集的管理上仍存在局限，难以适应模型能力的演变。", "innovation": "本文提出了一种自我进化的模型驱动动态数据优化框架Middo，它利用模型感知的数据选择和语义连贯的数据精炼。与传统的单一过滤/合成方法不同，该框架建立了一个闭合环优化系统：1）通过模型信号（损失模式、嵌入簇动态和自我对齐分数）的三维诊断机制主动识别次优样本；2）自适应优化引擎将次优样本转变为教育性有价值的训练点，同时保持语义完整；3）通过动态学习原则在提升模型能力的过程中持续进化。实验表明，该方法在多个基准数据集上能够持续提升种子数据质量，提高LLM性能，平均准确率提升7.15%，同时保持原始数据集规模不变。", "conclusion": "本工作为可持续的LLM训练建立了动态人机协同进化数据模型的新范式。我们的数据集、模型和代码即将发布。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: 长视频中语义聚合幻觉的基准测试", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频多媒体大型语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但仍然容易产生与视频输入不一致或无关的幻觉内容。现有的视频幻觉基准主要针对短视频，并将幻觉归因于如强语言先验、缺少帧或视觉编码器引入的视觉-语言偏差等因素。尽管这些原因确实解释了大多数短视频中的幻觉现象，但它们仍然过于简化了幻觉的原因。有时，模型生成的输出虽然在帧级语义上正确，但整体输出是不正确的。我们将其称为语义聚合幻觉（SAH），这种幻觉在聚合帧级语义到事件级语义组的过程中产生。由于长视频中不同事件之间存在更大程度的语义复杂性，SAH变得尤为重要。因此，分离和深入研究这种幻觉的原因变得至关重要。然而，现有的基准测试仍难以全面覆盖长视频中的幻觉现象及SAH的具体情况。因此，这是一个亟待解决的研究空白。", "innovation": "本文引入了ELV-Halluc，这是首个专注于长视频幻觉的基准测试，能够系统地研究语义聚合幻觉（SAH）。研究揭示了SAH的存在及其随语义复杂度的增加而增加的现象，并表明模型在快速变化的语义场景中更容易产生SAH。此外，研究提出并验证了通过位置编码策略和DPO策略减轻SAH的方法。为了支持这些发现，编制了一个包含8K对抗数据对的数据集，并在ELV-Halluc和Video-MME上取得了显著的改进，包括SAH比例显著减少了27.7%。", "conclusion": "研究证实了SAH的存在，且其随视频中语义复杂度的增加而增加。模型在快速变化的语义场景中更易产生SAH。位置编码策略和DPO策略有助于减轻SAH。编制对抗数据集进一步验证了这一结论，并在基准测试的基础上实现了显著的改进。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的无侵入性卷积神经网络可靠性监控", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络(CNNs)已成为现代计算机视觉的基础，在多种图像识别任务中实现了前所未有的精度。尽管这些网络在处理正常数据方面表现出色，但在对抗性扰动面前仍然脆弱，对抗性扰动是指难以察觉的输入修改，会导致模型高置信度的误分类。然而，现有的检测方法要么需要昂贵的重新训练，要么需要修改网络架构，要么在干净输入上会降低性能。", "innovation": "本文展示了一种新的方法，通过对CNN激活过程中的即时、可检测的熵特征的监控，不修改任何模型结构就能检测对抗性扰动。借助VGG-16网络和并行熵监控，在早期卷积层中观察到激活熵值平均变化7%，实现了90%的检测准确度，且误检率和误判率均低于20%。实验结果表明，CNN在激活模式中固有的编码了数据分布的变化。", "conclusion": "本文建立了仅通过激活熵评估CNN可靠性的基础，并展示了实时检测对抗性输入而不影响原始模型性能的自诊断视觉系统的可行性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21587", "html_url": "https://arxiv.org/abs/2508.21587", "title": "当前文本匿名化趋势与最新进展综述", "title_en": "A Survey on Current Trends and Recent Advances in Text Anonymization", "authors": "Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa", "background": "随着各类领域中包含敏感个人信息的文本数据不断增长，需要采用稳健的数据匿名化技术来保护隐私并遵守法规，同时确保数据仍可用于多样化的下游任务。当前，基础的方法主要集中在命名实体识别上，而大型语言模型的引入，使其在高级匿名化和潜在的去匿名化威胁方面发挥了重要作用。此外，不同的专业领域，如医疗、法律、金融和教育，各自有特定的挑战和解决方案。这些因素推动了对高级隐私模型和风险感知框架的应用，并需特别关注作者匿名化的子领埴。评估框架、综合评估指标、基准测试和实际部署的工具包也得到了审查。", "innovation": "本文综述了当前文本匿名化的趋势和最新进展，探讨了大型语言模型在高级匿名化和潜在的去匿名化威胁中的双重角色，涉及不同专业领域的挑战和解决方案，并深入研究了采用形式化隐私模型和风险感知框架的高级方法论，同时特别关注作者匿名化的子领域。还评估了评估框架、全面的评估指标、基准测试和实际部署的工具包。", "conclusion": "本综述总结了当前的知识，并指出了新兴趋势和持续性的挑战，包括隐私-实用性权衡的演变、对准标识符的需求以及L大型语言模型能力的影响，旨在为学术界和从业者未来的研究方向提供指导。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "物理导向的光谱建模在高光谱成像中的应用", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "研究背景通常涉及高光谱成像技术，这种技术利用大量连续波长来记录场景的光谱信息。传统的处理方法往往依赖于人工特征提取和模型建立，而这些方法可能需要大量的标注数据并且难以解释其内部工作机制。因此，提出了一种新的基于深度学习但结合物理知识的方法，旨在更有效地处理高光谱数据，无需大量监督数据，并且能提供可解释的隐含表示，从而改善其性能和应用前景。", "innovation": "该研究的创新之处在于提出了PhISM（物理导向的结构化信息模型）架构，这是一种结合物理信息的深度学习模型。PhISM能够无监督地学习，明确地分离高光谱观测数据，并使用连续的基础函数进行建模。这种方法在多个分类和回归基准测试上表现优于之前的方法，并且只需要少量的标注数据，同时通过可解释的潜在表示提供了额外的信息见解。", "conclusion": "PhISM架构在多个高光谱成像分类和回归任务中表现出色，仅需要少量标记数据，并且能够提供可解释的隐含表示，为理解和应用高光谱成像技术提供了新途径。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "本文介绍了一种通用的上下文文本嵌入模型——QZhou-Embedding，该模型具有出色的文本表示能力。它基于Qwen2.5-7B-Instruct基础模型构建，采用统一的多任务框架，包括专门的数据转换和训练策略。数据转换方案允许结合更多样化的文本训练数据集，而任务特定的训练策略则提高了模型的学习效率。通过利用LLM API的数据合成流水线，引入了诸如改写、增强和生成硬负例等技术，从而提高训练集的语义丰富性和样本难度。此外，还采用两阶段训练策略，包括初的检索焦点预训练和全面任务微调，从而使嵌入模型能够根据稳健的检索性能扩大其能力。", "innovation": "1. 基于Qwen2.5-7B-Instruct基础模型构建统一的多任务框架，结合专门的数据转换和训练策略。\n2. 利用LLM API，采用数据合成流水线，结合改写、增强和生成硬负例等技术。\n3. 采用两阶段训练策略，包括初的检索焦点预训练和全面任务微调，提高了模型的语义表示能力。\n4. 实现了MTEB和CMTEB基准上的最先进的结果，尤其是在重排序和聚类任务上也达到了最先进的性能。\n5. 研究结果表明，高质量、多样化的数据对提升检索模型性能至关重要，而利用LLMs的生成能力可以进一步优化嵌入模型的数据质量。", "conclusion": "我们的模型在MTEB和CMTEB基准上达到了最先进的结果，同时在重排序和聚类等任务上也表现优异。我们的研究结果表明，更高的数据质量和多样性对于提高检索模型性能至关重要，利用LLMs的生成能力可以进一步优化嵌入模型的数据质量，提高模型的表现。我们已在HuggingFace上以Apache 2.0许可证发布模型权重，并在GitHub上提供了评估代码和说明，确保研究结果的可复制性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "限于物理感知神经网络在智能电网代理中的局限性：一项研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "智能电网的建模面临数据稀缺和物理一致性等关键挑战，传统数据驱动方法难以解决这些问题。物理感知神经网络（PINNs）通过直接在学习框架中集成物理定律，提供了一种变革性的方法。本文通过三项关键实验（插值、交叉验证和阶段性轨迹预测）比较了PINNs与XGBoost、随机森林和线性回归的性能，证明了PINNs在迭代错误减少和保持较低MAE方面优于数据驱动模型。特别是，在随机控制和专家驱动控制情景中，PINNs能够可靠地捕捉状态转换，而传统模型表现出不稳定的性能。尽管在极端操作条件下略有下降，但PINNs始终确保物理可行性，对于安全关键应用至关重要。本文的研究结果认为PINNs可以作为智能电网的范式工具，结合数据驱动的灵活性与第一原理的严谨性，这对于实时电网控制和可扩展的数字双胞胎具有重要意义。", "innovation": "本文评估了PINNs作为智能电网动态的代理模型的能力，通过仅使用基于物理的损失函数（确保功率平衡、操作约束和电网稳定）训练PINNs，证明了它们在错误减少和保持较低MAE方面的优越泛化能力，相比数据驱动模型。进一步，即使在极端操作条件下PINNs略有下降，也始终确保了物理可行性，对于安全关键应用至关重要。", "conclusion": "本文的研究结果认为PINNs可以作为智能电网的范式工具，结合数据驱动的灵活性与第一原理的严谨性，这对于实时电网控制和可扩展的数字双胞胎具有重要意义。这表明物理感知的架构在关键能源系统中的必要性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式人工智能进行气象自适应学习以增强气候弹性的教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "当前，通过地方性的、适应性的学习体验来提升气候弹性教育的需求日益增加。现实中的技术如物联网（IoT）传感器和生成式人工智能（Generative AI）可以在这一领域发挥作用，但传统的学习方法往往未能充分适应气候变化带来的挑战。", "innovation": "该论文介绍了未来大气条件训练系统（FACTS），这是一个结合了物联网传感器收集的实时大气数据和知识库中挑选的资源，通过生成式AI服务器实现个性化反馈和适应性支持的平台。这一系统能够动态生成本地化的学习挑战，从而提升学习者的知识构建和对气候弹性的认知。", "conclusion": "用户评估显示，参与者认为该系统易于使用，并且对气候韧性相关知识的构建有显著效果。这些结果表明，将物联网和生成式人工智能整合到大气自适应学习技术中，对于提高教育参与度和增强气候意识具有重要前景。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21727", "html_url": "https://arxiv.org/abs/2508.21727", "title": "OptMark: 通过推断时间优化实现稳健的多比特扩散水印", "title_en": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization", "authors": "Jiazheng Xing,Hai Ci,Hongbin Xu,Hangjie Yuan,Yong Liu,Mike Zheng Shou", "background": "对通过扩散生成的图像进行水印是一个关键的版权保护手段和用户追踪方式。然而，当前的扩散生成水印方法存在明显限制：零比特水印系统容量不足，无法进行大规模用户追踪；多比特水印方法对特定图像变换或生成攻击非常敏感，缺乏全面的稳健性。", "innovation": "提出了一种基于优化方法的OptMark方案，该方案将稳健的多比特水印嵌入到扩散去噪过程的中间潜变量中。OptMark策略性地早期嵌入结构性水印以抵抗生成攻击，晚期嵌入细节水印以抵抗图像变换。通过定制化的正则化项，OptMark 保留图像质量并确保其难以察觉。另外，OptMark 结合反向梯度方法，优化过程中的内存消耗从 O(N) 降低至 O(1)。", "conclusion": "实验结果表明，OptMark 实现了隐蔽的多比特水印，且具有针对值度量变换、几何变换、编辑和再生攻击的稳健鲁棒性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21733", "html_url": "https://arxiv.org/abs/2508.21733", "title": "基于人工智能的计算机感知工具开发人员见解", "title_en": "Developer Insights into Designing AI-Based Computer Perception Tools", "authors": "Maya Guhan(1),Meghan E. Hurley(1),Eric A. Storch(2),John Herrington(3),Casey Zampella(3),Julia Parish-Morris(3),Gabriel Lázaro-Muñoz(4),Kristin Kostick-Quenet(1) ((1) Center for Ethics and Health Policy, Baylor College of Medicine, Houston, TX, USA, (2) Department of Psychiatry and Behavioral Sciences, Baylor College of Medicine, Houston, TX, USA, (3) Department of Child and Adolescent Psychiatry and Behavioral Sciences, Children's Hospital of Philadelphia, Philadelphia, PA, USA, (4) Center for Bioethics, Harvard Medical School, Boston, MA, USA)", "background": "基于人工智能（AI）的计算机感知（CP）技术利用移动传感器收集行为和生理数据，用于临床决策。这些工具能够重塑临床知识的生成和解释方式，但它们的有效整合依赖于开发人员如何平衡临床效用与用户接受度和可信度之间的关系。本研究通过对20名开发人员的深入访谈，揭示了开发AI-CP工具的关键设计优先级，从而探讨了AI-CP工具在临床工作流程中的有效整合问题。", "innovation": "开发人员作为技术和伦理的双重守护者，不仅要设计用户可接受的工具，还要强调客观性以推动临床知识的进步。研究提出了以下建议帮助实现这一平衡：记录关于定制化设计选择的过程，明确定制化选择的界限，透明地传达输出信息，并投资于用户培训。", "conclusion": "实现上述目标需要开发者、临床医生和伦理学家之间的多学科合作。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21566", "html_url": "https://arxiv.org/abs/2508.21566", "title": "NSPDI-SNN：基于非线性突触修剪和树突整合的高效轻量级SNN方法", "title_en": "NSPDI-SNN: An efficient lightweight SNN based on nonlinear synaptic pruning and dendritic integration", "authors": "Wuque Cai,Hongze Sun,Jiayi He,Qianqian Liao,Yunliang Zang,Duo Chen,Dezhong Yao,Daqing Guo", "background": "Spiking神经网络（SNNs）是基于模拟生物神经元的人工神经网络，在近年来的人工智能技术研究中引起了广泛关注。生物神经元中的树突具有高效的时空信息处理能力和计算能力，然而SNN中的神经元很少能模仿树突的复杂结构。在受神经元树突非线性结构和高稀疏特性启发的基础上，我们提出了一种高效且轻量级的SNN方法，非线性修剪和树突整合（NSPDI-SNN）。这种方法中，我们引入非线性树突整合（NDI）以改善神经元时空信息表示；采用异质树突棘态转换比例和构建新的非线性突触修剪（NSP）方法以实现SNN的高稀疏性。我们在三个基准数据集（DVS128手势、CIFAR10-DVS和CIFAR10）上进行了系统性的实验，并将评估扩展到两种复杂的任务（语音识别和基于强化学习的迷宫导航任务），在所有任务中，NSPDI-SNN在保持最小性能损失的同时实现了高稀疏性，特别是在所有三个事件流数据集上取得了最佳的实验结果。进一步的分析表明，树突访问程度增加时，NSPDI显著提高了突触信息传递的效率。", "innovation": "该研究的主要创新点在于提出了一种基于非线性突触修剪和树突整合的高效轻量级SNN方法，旨在提高SNN的稀疏性并保持性能。引入了非线性树突整合（NDI）以改善神经元时空信息表示；利用异质树突棘态转换比例构建了新的非线性突触修剪（NSP）方法以实现SNN的高稀疏性。该方法已经在多个基准数据集和复杂任务上进行了验证，显示出了优异的效果和性能。", "conclusion": "神经元树突的复杂结构和非线性计算为开发高效的SNN方法提供了有希望的途径。我们提出的NSPDI-SNN方法通过非线性修剪和树突整合显著提高了SNN的性能和效率。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么只停留于单词？透过行级OCR揭示更广阔的前景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统光学字符识别(OCR)技术将每个字符分开识别，导致字符分割错误，并且缺乏上下文信息无法充分利用语言模型。近年来，序列到序列（序列到序列）翻译技术的进步允许先检测单词，然后一次输入一个单词到模型中直接输出整个单词，通过字符序列形式。这种方法提高了语言模型的利用率，同时跳过了易出错的字符分割步骤。然而，这导致了对单词分割的准确性的瓶颈问题。因此，本文提出从单词级别OCR向行级OCR的自然和逻辑进展。新的方法能够绕过单词检测中的错误，提供更大的句子上下文以更好地利用语言模型。我们在实验中发现，与基于单词的方法相比，新方法不仅提高了准确率，还提高了效率，效率提高了四倍。此外，我们还贡献了一个精心整理的包含行级注解的251页英文文档数据集，用于训练和基准测试从单词级到行级OCR的转变。我们的实验结果显示了5.4%的整体端到端准确率提高，这证实了向行级OCR转型的潜在好处，特别是在处理文档图像时。将来，随着大型语言模型的不断改进，我们的方法还有利用这些进步的潜力。项目网站: this https URL", "innovation": "提出了一种从单词级OCR向行级OCR的改进方法，通过绕过单词检测中的错误并提供更大的句子上下文来提高OCR的准确性和效率。贡献了一个精心整理的含行级注解的251页英文文档数据集，用于训练和基准测试。", "conclusion": "研究结果显示，行级OCR在整体端到端准确率上提高了5.4%，效率提高了四倍，证实了该方法的优势，尤其是在处理文档图像时。随着大型语言模型的进步，该方法有望进一步利用这些进步。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中对GPT-5的基准测试：可测量的收益，但持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面显示出巨大潜力。GPT-5是一种新型LLM系统，专门针对肿瘤学用途进行市场推广。", "innovation": "该研究使用了两个互补的基准测试：ACR放射肿瘤学在职考试（TXIT，2021年）和一个包含60个代表性疾病位置和治疗方法病例的定制集合。通过评估GPT-5在生成治疗计划方面的表现，研究者研究了其在放射肿瘤学中的应用。", "conclusion": "GPT-5在放射肿瘤学中的多选题基准测试中表现优异，明显优于之前版本的模型。尽管GPT-5在生成真实世界治疗建议方面的表现令人满意，但仍需进一步改进。虽然幻觉很少发生，但实质性错误的存在表明GPT-5生成的建议需要在临床实施前进行严格的专家监督。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "推理密集型回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "越来越多的AI研究者和从业者将大型语言模型应用于我们所说的推理密集型回归（RiR）任务，即从文本中推断出细微的数值属性。与标准的语言回归任务不同，例如情感分析或相似度分析，RiR常见于评分标准、领域检索等临时问题，这些情况下需要对文本进行深入的分析，但可获得的任务特定训练数据和计算资源有限。我们定义了三个实际问题作为RiR任务，并以此为基础建立了一个基准测试。通过这些测试，我们假设冻结的大语言模型和通过梯度下降微调变换器编码器都将在RiR任务中遇到困难。", "innovation": "我们提出了一种名为MENTAT的简单且轻量级方法，结合批次反射式提示优化和神经集成学习。MENTAT方法在两个基准基础上实现了高达65%的改进，表明在推理密集型回归任务上，现有的方法还有很大的改进空间。", "conclusion": "我们展示了MENTAT方法在处理Tough MND问答集、评分标准问题和学术论文搜索等测试下的卓越性能，并预期未来在该领域的研究仍有巨大的提升空间。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "通过非参数深度嵌入聚类实现无监督视频连续学习", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频作为复杂的时空媒体信息，在多个应用中广泛应用，但在无监督连续学习中尚未得到充分探索。先前的研究仅集中在监督连续学习上，依赖于标签和任务边界的知识，而获取标记数据成本高且不实用。因此，本文提出了一个不提供任务边界和标签的无监督视频学习现实场景，并研究了无监督视频连续学习（uVCL）问题，这因处理视频相比图像所需的额外计算和内存需求而更具挑战性。", "innovation": "本文提出了一个非参数的无监督视频连续学习解决方案，通过在每次任务中学习未结构化的视频数据类别。提出使用无监督视频变换网络提取的深度嵌入视频特征的核密度估计作为数据的非参数概率表示，并提出了一种新颖性检测标准来检测新的任务数据，动态扩展记忆簇以捕捉相继任务学习中的新知识。利用以前任务的迁移学习作为当前学习任务的知识转移的初始状态。研究表明，所提出的方法在相继学习多个任务时显著提高了模型性能。", "conclusion": "本文通过在三个标准视频行为识别数据集（UCF101、HMDB51和Something-to-Something V2）上进行深入评估，展示了在不使用任何标签或类边界的情况下，该方法在无监督视频连续学习中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR：概率置信度选择和排序", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "最佳多重样本法通过生成多个候选解决方案并选择评分最高的一个以提高大型语言模型（LLMs）和大型推理模型（LRMs）的准确性。推理任务的关键挑战在于设计一种评分函数，能够在没有正确答案的条件下识别出正确的推理链。PICSAR通过计算推理和最终答案的联合对数似然来评分每个候选生成内容。联合对数似然自然分解为推理置信度和答案置信度，从而实现对推理和答案的准确评估。这种方法在不同的基准测试中显示出显著的优势，表明它比其他基线方法更有效。", "innovation": "PICSAR是一种简单且无需训练的方法，用于通过考虑推理和最终答案的联合对数似然来评分每个候选生成，从而有效地识别正确的推理链。这种方法在多个基准测试中表现出了显著的优势，且使用的样本数量比基线方法少至少两倍，在16次比较中表现优于基线方法。", "conclusion": "分析表明正确推理链的推理和答案置信度显著更高，证实了PICSAR的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark: 工业机床控制器中动态水印的一种强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": "工业4.0高度网络化的机床控制器（MTCs）面临重放攻击的风险，这些攻击利用过时的传感器数据操纵执行器。现有的动态水印方案假设线性-高斯动态，并使用固定水印统计信息，使其容易受到MTCs随时间变化且部分专有的行为的影响。", "innovation": "本研究提出DynaMark，一种基于强化学习的框架，将动态水印建模为马尔可夫决策过程（MDP）。它在线学习一种自适应策略，动态调整零均值高斯水印的协方差，无需系统知识。DynaMark最大化一个独特的奖励函数，动态平衡控制性能、能量消耗和检测置信度。此外，它开发了一个贝叶斯信念更新机制，用于线性系统的实时检测置信度。", "conclusion": "在西门子Sinumerik 828D控制器的数字孪生上，DynaMark相比固定方差基线，使水印能量降低了70%，同时保持了名义轨迹。它还保持了平均检测延迟相当于一个采样间隔。物理步进电机测试床验证了这些发现，能够快速触发警报，控制性能下降较少，并且超过了现有基准。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "MPSoC板上神经网络加速：集成SLAC的SNL、Rogue软件和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "作为一名专业论文分析师，来自SLAC的LCLS-II自由电子激光器将产生X射线脉冲用于光束线实验，数据传输率高达1 MHz，探测器的数据吞吐量超过1 TB/s。这样大规模的数据流管理带来了巨大的挑战，传输和存储基础设施变得极其昂贵。传统的机器学习（ML）实施会导致过高的延迟，使其不适合高速实验环境。为了解决这些问题，SLAC开发了SLAC神经网络库（SNL），这是一种专为在现场可编程门阵列（FPGA）上部署实时ML推理模型的框架。SNL的关键特点是能够在不需重新综合FPGA的情况下动态更新模型权重，增强了适应性学习应用的灵活性。为了进一步提高用户体验和可访问性，我们引入了Auto-SNL，这是一种Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高阶综合代码的过程。本文对SNL进行了基准测试，并与当前最先进的工具hls4ml进行了比较，结果表明SNL在大多数测试架构中实现了有竞争力甚至更高的延迟，在某些情况下还提供了FPGA资源的节省。这一应用展示了SNL的灵活性，为高能物理、医学成像、机器人技术等多个领域中的研究人员和学者开辟了新的机会。", "innovation": "SLAC的SNL是专门为FPGA上部署实时ML推理模型设计的框架，能够在不需重新综合FPGA的情况下动态更新模型权重，增强了适应性学习应用的灵活性。Auto-SNL是一种Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高阶综合代码的过程。SNL与当前最先进的工具hls4ml进行了基准测试，并且在大多数测试架构中实现了有竞争力甚至更高的延迟，同时在某些情况下还提供了FPGA资源的节省。这种应用展示了SNL的高度灵活性。", "conclusion": "SNL和Auto-SNL框架展示了在高性能计算环境下的神经网络加速能力，为高能物理、医学成像、机器人技术和更多领域开辟了新的研究和应用机会。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET: 用于微调大规模视觉语言模型的数字测量设备CAD模型合成数据集生成工具", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "大型Vision-Language模型（LVLMs）在多项跨模态任务中表现出色，但在读取被遮挡、环境杂乱、视角极端、存在运动模糊的数字测量设备（DMD）上的值等简单情景下表现不佳，尤其是在头戴式相机和增强现实（AR）应用中的实际条件中。", "innovation": "该研究提出了CAD2DMD-SET，一种合成数据生成工具，专门用于涉及DMD的视觉问答（VQA）任务。利用3D CAD模型、高级渲染和高质量图像合成，该工具生成了多样化的VQA标注的合成DMD数据集，以微调LVLMs。此外，还提出了DMDBench，这是一个包含1,000张有注释的实际场景图像的验证集，用于评估模型在实际条件下的表现。使用平均规范化莱文距离（ANLS）对三个最先进的LVLMs进行基准测试，并进一步使用CAD2DMD-SET生成的数据集对这些模型的LoRA进行微调，取得了显著的提升，特别是InternVL的表现提升了200%，而不会损害其他任务的性能。", "conclusion": "CAD2DMD-SET训练数据显著提高了LVLMs在上述挑战性条件下的鲁棒性和性能。一旦最终版本的论文准备好，CAD2DMD-SET工具将被发布为开源软件，社区可以添加不同的测量设备并生成自己的数据集。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21793", "html_url": "https://arxiv.org/abs/2508.21793", "title": "MoE-Health: 一种用于稳健多模态医疗预测的专家组合框架", "title_en": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction", "authors": "Xiaoyang Wang,Christopher C. Yang", "background": "医疗系统生成多种类型的多模态数据，包括电子病历（EHR）、临床记录和医学图像。有效利用这些数据进行临床预测具有挑战性，尤其是在现实世界中样本经常以不同的模态出现或数据不完整的情况下。现有的方法通常需要完整模态的数据，或者依赖于手动选择策略，这限制了其在医疗环境中的适用性，其中数据的可用性因患者和机构而异。", "innovation": "我们提出了一种名为MoE-Health的新颖混合专家（Mixture of Experts）框架，专门设计用于处理具有不同模态的数据样本，并改善关键临床任务的性能。通过使用专门的专家网络和动态门控机制，我们的方法根据可用的数据模态动态选择和组合相关的专家，从而能够灵活地适应不同的数据可用性场景。我们评估了MoE-Health在MIMIC-IV数据集上的能力，涉及三个关键的临床预测任务：院内死亡率预测、长住院日预测和再住院预测。实验结果显示，MoE-Health在多模态融合方法中表现更优，并且能够在不同的模态可用性模式下保持稳健。", "conclusion": "MoE-Health框架有效地整合了多模态信息，提高了在不同类型的医疗数据（包括不同的患者和机构中存在差异的数据可用性情况下）的预测性能和稳健性，使其特别适合部署在具有不同数据可用性的多变医疗环境中。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "细致梳理 fine web：针对有害内容搜索与检索的 FineWeb 索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大规模语言模型（LLMs）依赖海量的网络数据集，如Common Crawl，而网络爬虫的非选择性性质引发了数据质量和安全性方面的挑战，特别是伦理问题。尽管高质量的数据训练对于模型性能至关重要，但之前的有害内容研究由于计算资源限制只局限于少量样本。瑞士AI研究所的FineWeb-2语料库（1.5TB，包含四种语言）被用于测试这项新的索引框架，实现了快速查询性能（多数搜索在毫秒内完成，全部在2秒内完成）。", "innovation": "该研究提出了一种使用ElasticSearch为基础的管道框架来索引和分析LLM训练数据集的方案。这一创新主要体现在提供了一种初步的索引分析方法，能够实现实时数据集分析，这对于构建更安全、更负责任的AI系统具有重要意义，同时也填补了大型有害内容研究的空白。", "conclusion": "项目展示了针对大型语言模型训练数据集进行实时分析的可行性，并提供了具有实际操作性的工具来提高AI系统的安全性与责任感。这种方法对其他LLM数据集具有潜在的推广价值，是提升AI系统质量的重要一步。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05163", "html_url": "https://arxiv.org/abs/2504.05163", "title": "在知识不完备情况下的基于知识图谱的检索增强生成方法评估", "title_en": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": " Knowledge Graph based Retrieval-Augmented Generation (KG-RAG) 是一种通过从知识图谱 (KGs) 中检索相关信息来增强大型语言模型 (LLMs) 的推理能力的技术，尤其是在问答 (QA) 等任务中。然而，现实世界中的 KGs 往往是不完整的，这意味着必要的信息可能缺失。现有的基准测试并不能很好地捕捉 KG 不完备性对 KG-RAG 性能的影响。", "innovation": "本文系统地评估了在 KG 不完备的情况下 KG-RAG 方法的表现，通过使用不同方法移除三元组并分析结果。研究显示，KG-RAG 方法对 KG 不完备性敏感，强调了在实际应用场景中需要更稳健的方法。", "conclusion": "KG-RAG 方法对知识不完备性表现出高度敏感性，表明需要开发更稳健的方法来应对知识不完备的情况，以在现实环境中提高 KG-RAG 的性能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 通过文本记忆库增强统一异常检测模型的逻辑能力", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "异常检测旨在识别偏离正常模式的异常情况，但由于可用的正常数据有限，这一过程具有挑战性。现有的大多数统一方法依赖于精心设计的图像特征提取器和记忆库来捕捉对象之间的逻辑关系。与这些方法不同，本文提出了一种通过引入文本记忆库来增强逻辑异常检测能力的方法，并提出了一个名为TMUAD的统一结构和逻辑异常检测框架。", "innovation": "提出了一个带有逻辑感知文本提取器的类级别文本记忆库，用于逻辑异常检测，能够从输入图像中捕捉丰富的逻辑描述。构建了对象级别的图像记忆库，通过分割对象提取特征以保留完整的对象轮廓。还使用视觉编码器从图像块中提取特征，构建图像块级别的记忆库，用于结构异常检测。这三个互补的记忆库用于检索和比较与查询图像最相似的正常图像，计算多级异常分数，并将其融合为最终异常分数。该系统通过协作记忆库统一结构和逻辑异常检测，实现了在七个公开可用数据集上的最佳性能，这些数据集涉及工业和医疗领域。", "conclusion": "通过统一结构和逻辑异常检测并通过协作记忆库，TMUAD在七个公开数据集上实现了最先进的性能。该模型和代码可在指定的网址获取。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将可穿戴设备数据转换为个人健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴追踪器中提取个性化见解需要复杂的数字推理，这超出了传统LLM的能力，需要基于工具的方法，如代码生成。大规模分析此类数据的LLM代理虽然有潜力但尚未充分利用。", "innovation": "作者引入了一个名为PHIA（个人健康洞察代理）的系统，该系统利用多步骤推理、代码生成和信息检索来分析和解释行为健康数据。", "conclusion": "人工专家评估显示，PHIA 在评估目标性数字问题时的准确性为 84%，在开放性问题上获得 83% 的好评，且更有可能获得最高质量评分。这项工作可以通过使个人了解其数据来推进行为健康，使新的个性化和数据驱动的健康时代更加普及。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "恶魔源于歧义：重新审视单正多标签学习的场景识别", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "情景识别（SR）是计算机视觉中的一个基本任务，旨在通过识别关键事件及其关联实体来从图像中提取结构化的语义摘要。现有方法将动词分类视为单标签问题，但本文通过全面分析显示，这种表述无法解决视觉事件识别中的固有歧义，因为同一个图像可以用多个动词类别合理描述。因此，动词分类本质上是一个多标签问题，由于各类别动词之间普遍存在语义重叠。此外，在大规模数据集中完全标注多个标签是不切实际的。该论文旨在克服这些挑战。", "innovation": "本文做出了三项关键贡献：1) 通过实证分析揭示动词分类本质上是一个多标签问题；2) 提出将动词分类重新表述为单正多标签学习（SPMLL）问题，这是在SR研究中的新视角；3) 设计了一个全面的多标签评估基准，能够公平评估模型在多标签设置下的性能，并进一步开发了带有图神经网络和对抗训练的 Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP)，以解决这一挑战。", "conclusion": "本论文通过实验证明，所提出的方法在多标签设置下在Mean Average Precision (MAP)上的提升超过3%，同时在传统Top-1和Top-5精度指标上具有竞争力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22288", "html_url": "https://arxiv.org/abs/2505.22288", "title": "压缩与准确性的权衡：提升表示层次模型", "title_en": "Compression versus Accuracy: A Hierarchy of Lifted Models", "authors": "Jan Speller,Malte Luttermann,Marcel Gehrke,Tanya Braun", "background": "现有的先进颜色传递（ACP）算法用于构建提升模型，通过将代表匹配分布的因素分组来实现压缩。然而，选择合适的超参数ε并不明显，可能需要多次运行ACP以找到最佳的ε值，这会导致模型压缩度和准确性之间的权衡难以确定，降低了模型的可解释性。\n", "innovation": "本文提出了一种无超参数的层次提升模型构建方法。该方法有效计算了ε值的层次结构，从而构建了相应的模型层次结构。不同ε值下聚集的因素，在更大ε值下也会被聚集在一起。该方法还带来了误差界限的层次结构，允许在选择用于运行ACP的具体ε值时明确权衡压缩和准确性，并提高了模型之间的可解释性。\n", "conclusion": "该论文提出的方法通过确保基于ε值聚集的因素在更大ε值下也会被聚集，提供了一种无超参数的层次提升模型构建策略。这种方法允许在压缩和准确性之间进行显式权衡，并增强了模型的可解释性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2302.00935", "html_url": "https://arxiv.org/abs/2302.00935", "title": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning", "title_en": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning", "authors": "Haichao Zhang,We Xu,Haonan Yu", "background": "使用离线数据预训练和在线强化学习微调是一种在样本效率和性能方面兼具优势的控制策略学习方法。一个自然的方法是使用离线训练的策略初始化在线学习的策略。", "innovation": "本文提出了一个策略扩展方案，用于离线和在线学习之间的桥梁构建。具体而言，在离线学习策略学习完成后，将其作为候选策略之一纳入策略集，并加上另一策略负责后续学习。两个策略将以适应性方式组合以便与环境交互。这种方法使得离线学习策略可以在在线学习的初期完全保留，避免了离线策略重要行为可能被破坏的情况，同时允许离线策略在适应性地参与探索。", "conclusion": "实验证实在多个任务上，所提出的方法是有效的。研究中的代码可以在该链接处找到：this https URL"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba状态空间模型是李普西乌斯稳定的高效学习者", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba状态空间模型（SSMs）在多个任务上已经超越了最先进的基于大语言模型的Transformer模型，并得到了广泛的应用。然而，对于基于递归的深度模型（如SSMs），其递归动态的稳定性对稳定学习是一个重要关注点。尽管Mamba在细调方法中的适应性很广泛，但其在混合精度细调（MPFT）和参数高效细调（PEFT）下的稳定性尚未被充分探索。", "innovation": "研究表明，在不同的MPFT和PEFT组合下，Mamba LLM对于引入的变化表现出非常稳定，与之形成对比的是，基于注意力的Transformer LLM在这些组合下可能会有显著的不稳定行为。Mamba LLM的这一稳定性是由其递归动态所决定的，并通过动态系统理论证明了李普西乌斯稳定性质。研究最后利用MPFT和PEFT方法，研究了Mamba LLM在上下文学习（ICL）任务中的能力。", "conclusion": "研究结果证明了Mamba LLM在细调方法下的稳定性，并进一步分析了其上下文学习能力，补充了已有研究内容。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08344", "html_url": "https://arxiv.org/abs/2508.08344", "title": "基于知识图谱的检索增强生成（KG-RAG）在部分知识条件下的表现剖析：实证洞察", "title_en": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": "知识图谱（KG）结合大型语言模型的推理能力是一种日益受到关注的方法。然而，当前的评估实践存在缺陷：现有的基准测试中包含了可以直接通过KG中的三元组回答的问题，使得模型是否进行推理变得不明确。此外，不一致的评估指标和宽松的答案匹配标准也模糊了有意义的比较。现有KG-RAG方法在知识不完全情况下的推理能力有限，经常依赖内部记忆，并且其设计不同导致其泛化程度各异。", "innovation": "提出了一种通用的基准构建方法及评估协议，以系统地评估在知识不完整情况下的KG-RAG方法。该研究发现，现有KG-RAG方法在知识不完整时的推理能力有限，主要依赖内部记忆，设计不同导致不同程度的泛化能力。", "conclusion": "现有KG-RAG方法在处理知识不完整时表现出有限的推理能力，通常依赖内部记忆，并且设计不同导致泛化能力存在差异。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型对大肠3D形状进行细化以生成数字模型", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的3D建模对于虚拟成像试验中的数字模型构建至关重要。然而，像大肠这样的器官由于其复杂的几何形状和形状变化，仍然具有挑战性。", "innovation": "提出了一种新型Conditional LAtent Point-diffusion模型（CLAP），将几何深度学习与去噪扩散模型相结合，以增强大肠的3D表示。", "conclusion": "CLAP在形状建模准确性上取得了显著改进，相对于初始次优化形状，减少了26%的Chamfer距离和36%的Hausdorff距离，为高精度器官建模提供了一个稳健且可扩展的解决方案，并具有广泛的应用潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生技术在AI模拟中的系统性调研、参考框架及其与标准化架构的映射", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "现代亚符号AI的发展面临数据量和数据质量不足的挑战。为了缓解这些问题，AI仿真利用了虚拟训练环境，其中AI代理可以在其中利用模拟和合成数据安全高效地开发。数字孪生技术为AI仿真打开了新的途径，因为它能够提供高度仿真的物理系统虚拟副本，并具备先进的模拟器以及与物理系统交互的能力，从而收集额外数据。本文通过对22篇主要研究的系统性调研，分析了数字孪生在AI仿真中的技术趋势，提出了一个参考框架，将其映射到ISO 23247数字孪生的标准架构中，以定位数字孪生和AI组件。", "innovation": "提出了数字孪生在AI仿真中的参考框架，并将其映射到ISO 23247数字孪生的标准架构中，提供了架构指南，确定了未来研究中的挑战和机遇。", "conclusion": "本文通过22篇主要研究的系统性调研，分析了数字孪生在AI仿真中的技术趋势，提出了参考框架，并确定了未来研究中的挑战和机会。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用PennyLane黑客马拉松挑战基准大型语言模型进行量子代码生成", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "大型语言模型（LLMs）在代码生成方面显示出了强大的潜力，但在量子计算领域的应用尚未得到充分探索。本文通过使用Quantum Hackathon（QHack）中的实际挑战，对PennyLane为基础的功能模型进行了基准测试，从而探究LLMs在量子代码生成中的表现。", "innovation": "本文引入了一个名为QHackBench的新基准数据集，该数据集源自QHack比赛，并评估了模型在普通的提示和检索增强生成（RAG）下的性能。此外，为了进一步提高错误解决方案的质量，本文还提出了一种多智能体评估流水线，该流水线能够迭代地改善不正确的解决方案。", "conclusion": "评估结果显示，通过增强检索的数据集改善了模型性能，特别是在复杂的量子算法方面。RAG增强的模型在解决复杂挑战时与标准的提示策略产生了相似的结果。本文还承诺公开发布QHackBench基准数据集、评估框架和实验结果，以促进AI辅助量子编程领域的进一步研究和发展。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM：一种使用概率编程进行机器人不确定环境操作的因果贝叶斯推理架构", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人在执行操作任务时需要考虑物体间的因果关系，然而，许多基于数据的方法缺乏因果语义，仅考虑相关性。因此，存在一种需求来开发能够处理因果推理的机器人操作方法，尤其是在不确定性环境中。本文提出了一种新颖的因果贝叶斯推理架构COBRA-PPM，该架构结合了因果贝叶斯网络和概率编程，以便在不确定性下进行干预推理。", "innovation": "本文提出的COBRA-PPM架构将因果贝叶斯网络和概率编程相结合，实现因果推理，从而在不确定性下执行操作。通过高保真的Gazebo实验证明了其预测操作结果的高准确性（准确率88.6%），并成功进行了贪婪的下一个最佳动作选择，任务成功率高达94.2%。此外，展示了COBRA-PPM在真实环境中的有效性，即使在传感器噪声和随机动作这样的不确定环境中也能处理良好的预测结果。", "conclusion": "本文提出了一种支持广泛操作场景的通用和可扩展框架COBRA-PPM，并为未来机器人与因果性交叉领域的研究奠定了基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen: 形式验证数据引擎，用于可信的多模态几何问题求解", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题求解（GPS）需要可验证的逻辑连贯性和多模态推理能力。尽管大型语言模型（LLMs）在GPS方面取得了快速进步，但它们的进步受到了可靠基准和系统方法的缺乏的阻碍。一个关键挑战是LLMs固有的幻觉，这导致生成的GPS数据集通常噪声高、未验证且自相矛盾。为了应对这一挑战，我们引入了TrustGeoGen数据引擎，该引擎生成形式化验证的几何问题，以建立基本原则和可信赖的基准。这项工作的背景在于，现有的GPS数据集存在质量问题，而不具备严格的逻辑验证和一致性的特性，导致模型在这些环境中的表现不佳，缺乏可靠的测试基准和通用性验证手段。此外，现有的GPS数据集噪声大、未验证且自相矛盾，限制了模型的性能提升和有效测试。因此，构建新的基准数据集对提高模型处理几何问题的能力至关重要。", "innovation": "TrustGeoGen 数据引擎的创新点包括：1）多模态对齐，同步生成图表、文本和逐步解决方案；2）形式验证，确保所有推理路径符合规则；3）连接思考，将形式演绎与类人逻辑步骤相结合；4）GeoExplore 系列算法，生成具有多种解决方案和自反回溯的多样化问题变体。这些创新点共同作用，建立了高质量的基准数据集和测试基准，提高了模型在多模态几何问题求解任务中的性能和通用性。", "conclusion": "我们使用TrustGeoGen数据引擎创建了GeoTrust-200K数据集和相应的GeoTrust-test基准，两项基准都保证了多模态一致性。实验表明，最先进的模型在GeoTrust-test上的准确率仅为45.83%，突显了其挑战性。此外，使用我们合成的数据进行训练显著提高了模型在GPS任务中的性能，并且具有良好的域外（OOD）基准泛化能力。我们的代码和数据可在以下网址获得：[在此处提供网址]。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "爱丽丝在可微分奇妙仙境的冒险——第一卷，神奇之旅", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "神经网络无处不在，通过大规模语言模型、语音转录系统、分子发现算法、机器人等应用形式体现出来。在去掉一切外衣后，神经网络实际上是由可微分的基本构成元素组成的，研究它们意味着学习如何编程，并如何与这些模型互动，这正是所谓的可微分编程。本文对这一迷人的领域进行了介绍，旨在帮助刚刚踏入这个神秘的可微分奇妙世界的人学习基础知识。读者将了解如何通过自动微分优化函数，并掌握处理序列、图、文本和音频的一些常见设计方法，特别关注于介绍重要的设计技术，包括卷积、注意力和循环块，希望能够弥合理论与代码之间的差距，使读者能够理解当前最先进的模型，如大规模语言模型（LLMs）和多模态架构等。", "innovation": "文章介绍了可微分编程的基础知识，及其在优化、序列处理、图处理、文本和音频处理等方面的应用。重点在于介绍卷积、注意力和循环单元等重要设计技术，并通过PyTorch和JAX等代码具体展示理论如何转化为实践，为读者提供理解复杂模型的桥梁。", "conclusion": "本文旨在通过直观、自包含的方式介绍可微分编程的重要设计技术，并向读者展示了如何通过PyTorch和JAX等工具理解复杂的模型，从而使读者能够理解和构建更先进的模型，如大规模语言模型和多模态架构。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用非结构化知识增强的机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "传统的机器翻译方法通常从配对的机器翻译语料库或知识图中的领域特定知识中检索上下文示例，来增强模型性能。然而，大量的世界知识散落在未结构化的文档中，且可能在不同语言间未能完全配对。因此，本文探讨了如何利用未结构化的文档来增强机器翻译，提出了RAGtrans基准，并采用多任务训练方法辅助语言模型利用多语言文档中的信息进行翻译。", "innovation": "本文主要创新点在于提出了第一项针对利用未结构化文档进行增强机器翻译的基准RAGtrans，并设计了一种无需额外标注的多任务训练方法，以提高语言模型在翻译过程中利用多语言文档知识的能力。实验结果显示，该方法能显著提升语言模型的性能，特别是在BLEU和COMET评分上取得了长足的进步。同时，也指出了当前语言模型在该任务中面临的挑战和困难。", "conclusion": "本文通过RAGtrans基准和多任务训练方法，有效提升了语言模型在使用未结构化文档进行机器翻译的效果。然而，由于大量的世界知识并未在不同语言间形成良好的配对，这仍然是当前模型需要克服的重要障碍。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于注解分歧校准估计的协作内容审核框架用于毒性检测", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "内容审核通常结合了人类审核员和机器学习模型的努力。然而，这些系统往往依赖于在审核过程中存在显著分歧的数据，反映了毒性感知的主观性。通常，这些分歧被视为噪音而被忽视，而该研究提出了一个新颖的观点，将这些分歧视为有价值的信号，强调捕捉注解分歧的重要性。", "innovation": "提出了一种新颖的内容审核框架，利用多任务学习，将毒性分类作为主要任务，并将注解分歧作为辅助任务来处理。此外，采用Conformal Prediction来估计注解和预测毒性时的不确定性。框架还允许审核者根据需要调整分歧阈值，提供灵活性来确定何时触发审核。该方法增强了模型性能、校准和不确定性估计，并在参数效率和审核流程改进方面优于单一任务方法。", "conclusion": "该协作内容审核框架在捕获注解分歧和评估模型预测不确定性方面具有优势，同时通过调整阈值提供了灵活性，从而增强了模型性能和审核流程的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18948", "html_url": "https://arxiv.org/abs/2411.18948", "title": "RevPRAG：通过LLM激活分析揭露检索增强生成中的中毒攻击", "title_en": "RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis", "authors": "Xue Tan,Hao Luan,Mingyu Luo,Xiaoyan Sun,Ping Chen,Jun Dai", "background": "检索增强生成（RAG）通过从相关知识数据库中检索信息来丰富语言模型（LLM）的输入，从而使得生成的答案更加精确和上下文相关。然而，这种机制引入了新的攻击面，即知识数据库可能被注入恶意文本，导致生成攻击者期望的响应（称为中毒响应）。目前，对于此类攻击的检测方法较为有限。因此，本文旨在填补这一空白，提出了一种名为RevPRAG的灵活且自动化的检测管道，利用LLM的激活来进行中毒响应检测。研究发现，当产生正确响应和中毒响应时，LLM的激活模式存在不同之处。通过在多个基准数据集和RAG架构上进行测试，该方法能够实现98%的真阳性率，同时保持低至1%的假阳性率。", "innovation": "提出了一种名为RevPRAG的灵活且自动化的中毒响应检测管道，通过利用LLM的激活来检测RAG中的中毒攻击。", "conclusion": "研究表明，RevPRAG能够在多个基准数据集和RAG架构上取得显著的效果，实现高真阳性率和低假阳性率，有效地发现了产生正确响应和中毒响应时LLM激活的不同模式。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "毒化行为滋生：政治播客对话链条剖析", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "数字通信中存在毒化行为的问题一直是学术界和行业专业人士关注的焦点。尽管已有大量研究探讨了社交媒体和论坛上的毒化现象，但播客尽管近年来快速兴起，仍较少受到此类研究的关注。本研究通过构建政治播客的转录数据集并分析其中的对话结构，填补了这一研究空白，重点关注毒化行为如何通过对话中的回复序列表现和加剧，揭示有害语言如何在对话中递进升级的有机模式。注意：包含潜在的攻击性/毒化内容。", "innovation": "本研究通过对播客对话的详细分析，探索了毒化行为在对话序列中的表现和加剧机制，这是在播客这一领域的一项创新研究，填补了现有研究中的空白。", "conclusion": "研究发现，毒化行为在政治播客的对话中表现出一定的模式和机制，这些发现有助于理解毒化行为如何在对话中递进升级，并提出了进一步研究和实际应用的建议。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "基于值顺序估计距离度量学习的分类数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是一种常用的机器学习技术，用于数据挖掘，可以自动揭示样本分布模式。由于分类数据天然缺乏像数值数据那样明确的度量空间，如欧几里得距离度量空间，因此分类数据的分布通常被低估。这可能导致聚类分析时有价值的信息被误导。本文旨在通过学习分类属性值的最佳顺序关系及其与其类似数值属性的定量距离，提出一种新颖的序度量学习方法，以直观地表示分类属性值。由于主观创建的定性分类值包含模糊性和不确定性，因此在聚类的背景下学习序度量。这种方法利用了一种新颖的交替进行聚类和序度量学习的联合学习范式，具有低时间和收敛性保证。在这种序学习机制和欧几里得距离的同质序性支持下，该方法在分类数据和混合数据集上达到了较高的聚类精度。此外，通过学习的序度量大大减少了难以理解和管理的非直观分类数据的复杂性。通过消融研究、显著性检验和案例研究等实验验证了该方法的有效性。", "innovation": "提出了一种新颖的序度量学习方法，通过学习分类属性值的最佳顺序关系及其距离，以数值属性相似的方式表示分类数据的值。这种方法在聚类的背景下进行学习，并开发了一种低时间和可以保证收敛性的交替进行聚类和度量学习的联合学习范式。这种方法在分类数据和混合数据集上取得了优异的聚类效果，并降低了非直观分类数据的理解和管理难度。", "conclusion": "该研究提出的方法在分类数据和混合数据集上显著提高了聚类精度，并通过学习的序度量简化了非直观分类数据的管理和理解。这种方法的有效性已经在各种实验中得到了验证，开源代码可供参考。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种用于视网膜底片图像固有可解释性疾病检测的混合完全卷积CNN-Transformer模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "在许多医疗成像任务中，卷积神经网络（CNNs）能够有效地提取层次化的局部特征。近年来，基于自我注意机制的视觉变换器（ViTs）因其能够捕捉全局依赖关系而受到欢迎，但缺乏卷积固有的空间定位能力。因此，将CNNs和ViTs结合的混合模型被开发出来以结合两种架构的优点，但由于这些混合模型难以解释，限制了它们在医疗成像中的应用。因此，开发了一种固有可解释的混合完全卷积CNN-Transformer架构，专门用于视网膜疾病检测。", "innovation": "该研究引入了一种固有可解释的混合完全卷积CNN-Transformer架构，用于视网膜疾病检测。与其他用于ViTs的后验逐例显著性方法不同，该方法生成了忠实且局部化的证据图，直接反映了模型的决策过程。该模型在使用彩色视网膜底片图像进行疾病检测的两个医疗任务中，相比黑盒模型和具有可解释性的模型，实现了最先进的预测性能，并且能够在这项任务中提供了类特定稀疏的证据图，只需要一次前向传播。代码可在提供的链接中获取。", "conclusion": "研究展示了该混合完全卷积CNN-Transformer模型在视网膜疾病检测任务中的应用，相比现有的模型，该模型提供了一种新的方式生成可解释的证据图，并实现了最先进的预测性能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG: 在图上实现公平删除", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着对隐私法规关注的增加，机器遗忘在社交网络和推荐系统等现实应用中变得越来越重要，这些系统往往自然地以图形的形式表示。然而，现有的图形遗忘方法通常会无差别地修改节点或边，忽视了这种操作对公平性的影响。例如，忘记不同性别用户之间的链接可能会无意中加剧群体间的不平等。", "innovation": "为了解决这个问题，我们提出了一个全新的框架，该框架同时优化图结构和模型以实现公平的遗忘。我们的方法通过移除阻碍遗忘的冗余边并通过对特定边缘进行增强以维护公平性来重新构建图结构。我们还引入了一种最坏情况下的评估机制，以评估在具有挑战性的场景下的鲁棒性。实验表明，我们的方法在实现更有效和公平的遗忘方面优于现有基线。", "conclusion": "实验结果表明，我们的方法在实现更有效和公平的遗忘方面优于现有基线方法。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "通过迭代混合程序分析进行大型语言模型测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "单元测试生成的自动化仍然是一个重要的挑战，尤其是在处理真实世界的复杂方法时。尽管大型语言模型（LLMs）已经在代码生成方面取得了进展，但在实现高分支覆盖率方面仍然存在问题，因为它们难以推理复杂的控制流结构。为了解决这个局限性，介绍了Panta技术，该技术模拟了人类开发人员分析代码和构建测试用例的过程。Panta结合了静态控制流分析和动态代码覆盖率分析，系统地指导LLMs识别未覆盖的执行路径并生成更好的测试用例。通过引入迭代的反馈驱动机制，该方法根据静态和动态路径覆盖率的洞察不断优化测试生成，确保更全面和有效的测试。在来自开源项目的高环路复杂度类上的实证评估中，Panta实现了26%更高的行覆盖率和23%更高的分支覆盖率，优于最先进的技术。", "innovation": "Panta技术通过结合静态控制流分析和动态代码覆盖率分析，提供了一种系统的方法来指导LLMs生成测试用例。此外，通过引入迭代的反馈驱动机制，该技术能够不断优化测试生成，确保更全面和有效的测试覆盖。", "conclusion": "我们的结果表明，Panta技术在行覆盖率和分支覆盖率方面分别实现了26%和23%的提升，显著优于最先进的技术，展现了Panta在实现更全面和有效测试方面的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "在任何视频中理解相机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "该论文介绍了CameraBench，这是一个大规模的数据集和基准测试，旨在评估和提升对相机运动的理解。CameraBench包括约3000条互联网视频，这些视频由专家经过严格的多阶段质量控制过程进行标注。本文还提出了一种与电影制作人合作开发的相机运动基本单元的分类法，以及相关的研究结果显示，理解场景内容对于某些运动（如跟随或跟踪）的理解至关重要。", "innovation": "主要内容包括：(1) 提出了分类法来定义相机运动的基本单元，该分类法是与电影制作人合作开发的；(2) 进行了一项大规模的人类研究，来量化人类注释的准确性，发现领域知识和基于教程的培训可以显著提高准确性；(3) 评估了结构从运动（SfM）模型和视频-语言模型（VLMs），发现SfM模型难以捕捉依赖于场景内容的语义基础单元，而VLMs在捕捉需要精确估计轨迹的几何基础单元方面存在困难；(4) 使用CameraBench对生成型VLM进行微调，以此来实现语义和几何的结合，并展示了其在运动增强的图片描述、视频问题回答和视频文本检索中的应用。", "conclusion": "该研究希望其分类法、基准测试和教程能推动未来对任何视频中相机运动理解的努力，最终实现对任何视频中相机运动的完全理解。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE: 一种针对大型语言模型任务特定指令微调的数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "大型语言模型（LLMs）通过指令微调在各种领域中展现出生产更可控、更有效输出的巨大潜力。现有方法主要依赖精心构造的相似性度量来选择与测试数据分布相匹配的训练数据，目标是在测试数据上最小化指令微调损失，从而提高目标任务性能。然而，观察到指令微调损失（即下一个令牌预测的交叉熵损失）并不总是与实际任务性能成单调关系，这使得现有的数据选择方法在任务特定指令微调中的效果受到影响。", "innovation": "本文提出了一种名为ROSE的新颖方法，这是一种基于奖励的数据选择框架，用于大型语言模型的任务特定指令微调。ROSE利用成对偏好损失作为奖励信号，优化数据选择以提高任务特定指令微调的性能。具体而言，ROSE采用一种影响表达式，近似度量训练数据点相对于少量示例偏好验证集的影响，从而选择与任务最相关的训练数据点。实验结果显示，使用ROSE选择仅5%的训练数据，相较于使用完整训练数据集进行微调，我们的方法可以达到与全训练数据集微调相当的性能，并且优于其他最先进的数据选择方法。", "conclusion": "通过选择少量适合的任务相关训练数据，ROSE方法展示了在多个基准数据集和不同模型架构上具有强大的鲁棒通用性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans：通过强化学习实现深度推理翻译", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "最近，深度推理大语言模型（例如OpenAI的o1和DeepSeek-R1）在多种下游任务中表现出令人鼓舞的性能。自由翻译在多语言世界中是一个重要而有趣的任务，它要求超越逐词翻译。然而，这一任务在深度推理大语言模型中仍然没有得到充分探索。", "innovation": "本文引入了DeepTrans，一种通过强化学习（RL）学习自由翻译的深度推理翻译模型。具体而言，它精心构建了包含预定评分标准的奖励模型，既包括翻译结果也包括思维过程。此外，我们的RL训练不需要任何标注翻译，从而避免了耗时的人工注释或资源密集型数据合成。实验结果验证了DeepTrans的有效性，使用Qwen2.5-7B作为基础模型，DeepTrans在文献翻译中的性能提高了16.3%，并且超越了强大的深度推理大语言模型。在探索过程中，还总结了失败和有趣的发现。", "conclusion": "希望本研究能激励其他研究人员参与自由翻译的研究。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子与跳之前先看：超越下一标记预测的创造力极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "本文设计了一组极简的算法任务，这些任务在一定程度上抽象了现实世界的开放性任务，从而可以简洁且可控地评估当前语言模型的创造性极限。这些任务类似于需要创造性远见的现实任务，同时要求隐含的开放性随机规划步骤，这个步骤可以发现抽象知识图中的新连接（如文字游戏、类比推理或研究），也可以构建新的模式（如设计数学问题或新蛋白质）。本文指出，对于这些任务，下一标记学习是短视的；而多标记方法，例如无教师训练和扩散模型，在产生多样性和原创性输出方面表现出色。", "innovation": "本文提出了一种具有原理性的、极简的测试平台，用于分析开放性创造性技能，通过对输入层注入噪声（称为种子条件）的方法，能够引入随机性而不损害连贯性。这种方法在某些条件下甚至比从输出层采用温度采样更有效。因此，本文提供了超越下一标记预测和温度采样的新论据。", "conclusion": "本文的工作提出了一种新的方法和平台来分析开放性创造性技能，并提供证据表明多标记方法优于下一标记学习和温度采样。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "风格共享的去中心化领域泛化：形式模型与收敛性分析", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "许多联邦学习（FL）研究集中在本地数据集统计在训练和测试之间保持不变的设置上。然而，由于分布变化等原因，这一假设在实践中往往不成立，因此需要开发可以泛化到未见过的目标领域的领域泛化（DG）方法。现有的FL和DG工作中存在两个主要差距：缺乏形式化的数学分析以及DG在FL中局限于星形拓扑结构。本文提出了一种去中心化的DG算法——风格共享的域泛化（$\textit{StyleDDG}$），允许P2P网络中的设备通过共享其数据集推断出的风格信息来实现DG。", "innovation": "本文提出了$\textit{StyleDDG}$算法，该算法允许P2P网络中的设备通过共享数据集推断出来的风格信息实现泛化。此外，还提出了首个系统化的风格基于DG训练方法。通过将现有的集中式DG算法嵌入到本文框架并利用它们的形式化模型来建模$\textit{StyleDDG}$，获得了在一定条件下单凭$\textit{StyleDDG}$收敛性的分析条件。并通过在流行的目标域DG数据集上进行实验，显示出与基线的分布式梯度方法相比，$\textit{StyleDDG}$在所有目标域上的准确率有显著提高且通讯开销较小。", "conclusion": "通过实验，展示了$\textit{StyleDDG}$在所有目标域上相较于基线的分布式梯度方法拥有显著的准确率提高以及极低的通信开销。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14681", "html_url": "https://arxiv.org/abs/2503.14681", "title": "DPImageBench: 用于差分隐私图合成的统一基准", "title_en": "DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis", "authors": "Chen Gong,Kecen Li,Zinan Lin,Tianhao Wang", "background": "差分隐私图像合成旨在生成保留敏感图像特性的伪图像以保护个体隐私。尽管最近取得了进展，但研究中使用的评价标准不一致且时常存在问题，这不仅限制了对现有方法的理解，还阻碍了未来的发展。", "innovation": "本文介绍了DPImageBench，该基准在多个维度上进行了精心设计：(1) 方法：研究了11种主要方法，并系统地描述了每个方法的架构、预训练策略和隐私机制。(2) 评价：包括9个数据集和7个保真度和可用性指标进行彻底评估，纠正了常见的依据最高准确度选择下游分类器的方法，这不仅违背了差分隐私原则，还高估了实用性评分。(3) 平台：提供了标准接口，使当前和未来的方法可以在统一框架内实现。", "conclusion": "使用DPImageBench，我们发现了几个重要发现。例如，与普遍认为在公共图像数据集上进行预训练通常是有益的相反，我们发现保留数据集之间的分布相似性对合成图像的性能影响重大，不一定总是能带来提升。对于低隐私预算，添加噪声到低维度特征，如敏感图像的高层特征，相比添加到高维度特征（如权重梯度）的影响更小。前者方法在低隐私预算下表现更好。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA：管理AI代理系统的安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "随着大型语言模型（LLM）为基础的代理越来越多地自主地相互交互、协作和委托任务，而无需大量的人工干预。现行的行业指南强调用户需要对他们的代理具有全面的控制权，以防止恶意代理带来的潜在伤害。已有的一些代理系统设计致力于代理的身份认证、授权和任务委派，但这些设计大多数仍停留在理论层面，缺乏实际的实现和评估。更为关键的是，这些设计没有提供用户控制代理管理的功能。", "innovation": "本文提出了SAGA（一个可扩展的安全架构），以用户可控的方式来管理代理系统的生命周期。设计中，用户将代理注册到一个称为Provider的中心实体，该实体维护代理的联系信息、用户定义的访问控制策略，并帮助代理在代理间的通信中执行这些策略。此外，还引入了一种加密机制来生成访问控制令牌，提供了细粒度的控制，确保了与代理交互的正式安全保证。通过在不同地理位置的代理上以及在多个设备和云上的LLM上进行SAGA的评估，证明了其具有最小的性能开销并且不会影响基础任务的实用性。", "conclusion": "该架构可确保代理在自主环境中的安全和可信部署，推动了这项技术在敏感环境中的负责任采用。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23197", "html_url": "https://arxiv.org/abs/2505.23197", "title": "统一的路径规划器：自适应的安全性和优化性", "title_en": "Unified Path Planner with Adaptive Safety and Optimality", "authors": "Jatin Kumar Arora,Soutrik Bandyopadhyay,Shubhendu Bhasin", "background": "自主机器人的路径规划涉及在优化性和安全性之间取得根本性的权衡。传统算法通常倾向于优先考虑其中一个目标，而没有一个统一框架能够同时解决这两个问题。", "innovation": "本文引入了一种统一体系架构——统一体系规划器（UPP），能够同时处理优化性和安全性。通过使用修改后的启发式函数结合动态安全性成本，UPP 能够实现路径长度和障碍物避让之间自适应的平衡。", "conclusion": "详细的仿真和硬件实现（基于 TurtleBot）表明，UPP 在保持低计算复杂度的情况下，能够生成高效的安全路径，接近经典 Voronoi 规划器的安全边际。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning：增强知识边界意识的LLM多组分问题推理", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "LLM在各种应用中被广泛应用，但它们在生成不存在事实方面的幻觉是一个重要的问题。以往研究通过分析内部参数化知识边界来估计置信度，但这些研究主要集中在单一问题的背景下，尚未探究同时回答多个问题的更具挑战性的多问题环境。", "innovation": "提出了一种名为Multiple Answers and Confidence Stepwise Tuning（MAC-Tuning）的新方法，在指令数据的微调过程中分离答案预测和置信度估算的学习。这种方法在广泛精度上优于基线模型，提高了25%。", "conclusion": "通过MAC-Tuning方法，在多问题场景下能够更准确地回答多个问题，展示了其在增强知识边界意识的多组分问题推理中的优越性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "从复杂的化学反应中估计速率系数对于促进详细化学的发展至关重要。然而，实际大气化学系统中的刚性特性带来了严峻的挑战，导致基于学习方法的训练不稳定和劣化收敛，阻碍了有效速率系数估计。", "innovation": "我们提出了一个名为SPIN-ODE的刚性物理启发神经常微分方程框架，用于化学反应建模。该方法引入了一个三阶段的优化过程：首先，一个黑盒神经常微分方程被训练以拟合浓度轨迹；接着，预制训练化学反应神经网络（CRNN）来学习浓度及其时间导数之间的映射；最后，通过集成预制训练的CRNN来微调速率系数。该方法在合成数据集和新提出的实际数据集上进行了广泛的实验，验证了其有效性和鲁棒性。作为首个针对刚性神经常微分方程的化学速率系数发现工作，我们的研究为将神经网络与详细化学相结合提供了富有前景的方向。", "conclusion": "SPIN-ODE框架为化学反应率估计提供了一种创新的方法，并展示了其在合成和实际数据集上的有效性和鲁棒性，为将神经网络与详细化学学结合的研究奠定了基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 向网页代理注入提示攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "当前的研究背景是使用多模态大型语言模型（MLLM）的网页代理可以根据网页屏幕截图生成相应动作。这篇论文探讨了一种新的攻击方法，即通过在网页渲染的原始像素值中添加扰动，从而操控网页代理执行攻击者指定的动作。背景中的挑战在于如何有效找到这些扰动，尤其是当对原始像素值和屏幕截图之间的非可微映射进行优化时难以实现反向传播从而使攻击更加有效和隐藏。之前的应对措施难以解决这一挑战，因此需要一种新的方法来解决这个问题。", "innovation": "提出了一种名为WebInject的新颖攻击方法，该方法通过在网页渲染后的原始像素值中添加扰动来诱导网页代理执行攻击者指定的动作。为了克服像素值与屏幕截图之间映射的非可微性，研究者训练了一个神经网络来近似这个非可微的映射，并使用投影梯度下降法解决优化问题来找到扰动。这种结合神经网络的优化方法能够有效解决这个问题，使得攻击更加隐蔽和高效。", "conclusion": "在多个数据集上的广泛评估表明，WebInject攻击方法非常有效，并显著超越了现有的基准方法。这表明在保护网页代理的安全性方面需要更加重视此类新型攻击方法。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "动态操作的潜适应计划器", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "该研究旨在解决动态非抓取操作（例如盒子接住）中的轨迹级策略问题。传统的方法往往缺乏从人的演示中有效学习的能力，并且难以实现机器人和人类之间的动态适应能力。现有方法通常难以解决机器人和人类之间的体素质隔问题（embodiment gap），导致机器人的操作表现不佳。因此，研究提出了一种新的方法以克服这些问题，特别是在真实时间的动态适应和不同机器人平台之间的有效转移方面表现出色。", "innovation": "本文提出了一种名为Latent Adaptive Planner (LAP)的轨迹级潜变量策略，该策略是以低维度潜空间中的推断形式来规划，并且能够从人类演示视频中有效学习。LAP在执行过程中通过维护潜计划的后验并进行变分重规划来实现实时适应。为了弥合机器人和人类之间的体素质隔，引入了基于模型的比例映射，能够在保持准确的动力学关节状态和物体位置方面自动生成来自人类演示的动态数据。通过具有不同特征的箱子接住实验，LAP展示了优于其他方法的成功率、轨迹平滑度和能量效率，表明LAP能够学习到类似人类的顺应运动和适应行为。此外，LAP还能够在不同机器人平台上成功转移，使用相同的演示视频。", "conclusion": "LAP通过学习人类丰富的演示内容并具有实时适应能力，展示了在动态非抓取操作中的卓越性能。同时，LAP能够在多种机器人平台上实现操作策略的有效迁移，进一步实现了优异的整体动态操作性能。这种新型方法能够极大地改善机器人在动态任务中的表现，并在未来实际应用中具有巨大的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种安全、高效且适应性强的大型语言模型联邦划分框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私有数据由于其高质量而有望提升LLM性能，但这些数据分散在数据孤岛中，并且LLM的高计算需求限制了它们在联邦环境中的部署。为此，提出了基于Transformer的联邦划分模型，将大部分模型参数卸载到服务器（或分布式客户端），仅保留少量参数在客户端以确保数据隐私。尽管如此，这些模型仍然面临三个挑战：1) 通过节点间的密钥加密难以有效保障传输向量的安全；2) LLM的自回归特性使得联邦划分学习只能顺序进行，导致高通信开销；3) 固定的划分点缺乏针对下游任务的适应性。", "innovation": "本文提出了基于LLaMA2的FedSEA-LLaMA安全、高效且适应性强的联邦划分框架。通过在前向传播隐藏状态中注入高斯噪声来实现端到端向量传输的安全性。通过使用注意力掩码压缩和KV缓存协作来降低通信成本，从而加快了训练和推理速度。用户可以根据特定任务需求动态调整输入/输出块的划分点。实验结果显示，FedSEA-LLaMA在自然语言理解和总结等任务中与集中式LLaMA2保持了相当的性能，并在训练和推理中分别实现了最高8倍的加速。进一步分析还表明，FedSEA-LLaMA在隐私攻击和不同的划分点具有有效性与适应性。", "conclusion": "FedSEA-LLaMA在保持性能的同时，解决了联邦环境中数据传输安全性、计算效率和划分点适应性的问题，为LLM的联邦学习提供了有效的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "机器人运动中的体质扩展定律趋向", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "了解不同的身体形态如何影响智能代理的通用性对于构建能够在任何机器人上工作的通用智能代理至关重要，但迄今为止，决定这些优异表现的因素还不是很清楚。本研究使用机器人移动作为测试模型，通过生成约1,000种具有拓扑、几何和关节级运动学变化的体质变异体，研究了体质扩展定律，即增加训练体质的数量是否能够提高新未知体质的泛化能力。", "innovation": "本研究通过生成大量的不同体质变异体，并对随机子集进行训练，观察到了支持这一假设的正向扩展趋势。研究发现，与固定体质的数据扩展相比，体质扩展能够实现更广泛的泛化。最好的训练策略显示了从训练数据到全新未见体质的零样本转移能力，不仅在仿真环境中，也在真实世界中的Unitree Go2和H1机器人上也得到了验证。", "conclusion": "这些结果朝着通用具身智能的方向迈出了重要一步，对可配置机器人的自适应控制、形态设计以及更广泛的领域都具有重要意义。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越 token 层次的 LLM 公平性量化：一种语义和统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）在生成响应时往往具有固有的偏见，这降低了它们在实际应用中的可靠性。现有的评估方法常常忽略了长文本响应中的偏见和LLM输出的内在变异性。现有的评价方法往往侧重于情感或token级别的比较，但这些方法难以检测到深层次的语义差异。", "innovation": "本文提出了一种新的统计框架FiSCo（Fine-grained Semantic Comparison），通过在性别、种族和年龄等不同群体之间检测长文本响应中的细微语义差异来评估群体级别的公平性。FiSCo优于以往的工作之处在于，它不仅处理表面层次的分析，还基于断言层面进行处理，利用蕴含检查评估响应含义的一致性。此外，FiSCo通过记录和对比断言间的相似性和差异性，实现了对细微偏好的稳健检测。", "conclusion": "实验表明，FiSCo能够在降低LLM随机性影响的同时更可靠地识别细微偏见，并且优于各种评估指标。此外，论文还为群体反事实公平性定义了新的形式化表达，并在合成和手动标注的数据集上验证了FiSCo的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR: 动态差异感知时序残差网络在纵向放射学报告生成中的应用", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "放射学报告生成（RRG）自动化了从医学影像中创建放射学报告的过程，提高了报告过程的效率。纵向放射学报告生成（LRRG）通过增加前后影像的比较能力，支持临床发现随时间变化的跟踪。现有LRRG方法使用视觉得到的预训练编码器提取前后影像的特征，并将这些特征进行拼接以生成最终报告。然而，这些方法在特征提取过程中难以有效地捕捉空间和时间相关性，导致提取出的特征不能很好地捕捉考不同检查之间的信息差异，从而不能充分代表预期的进展，使得LRRG的效果欠佳。", "innovation": "提出了一种新颖的动态差异感知时序残差网络（DDaTR）。在DDaTR中，我们在视觉编码器的每个阶段引入两个模块以捕获多级空间相关性。动态特征对齐模块（DFAM）旨在跨模态对齐前特征，确保前临床信息的完整性。在这一增强的前特征的驱动下，动态差异感知模块（DDAM）通过识别检查间的关系来捕捉有利于差异的信息。此外，我们的DDaTR采用了动态残差网络单向传递纵向信息，有效地建模了时间相关性。", "conclusion": "通过对三种基准的广泛实验表明，DDaTR在LRRG任务中比现有方法具有更优越的表现，证明了其在RRG和LRRG任务中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "使用期望最大化实现可解释的词汇生成以促进汉字学习", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "对于来自罗马字母背景的学习者来说，学习日语词汇是一项挑战，这是因为书写系统上的差异。日语结合了平假名等拼音文字和来自汉字的文字——汉字是复杂的象形文字，数量庞大。关键词记忆法是常见的记忆策略之一，通常利用汉字的构成结构来形成生动的联想。尽管最近已经开始尝试使用大规模语言模型（LLMs）来辅助学习者，但现有的基于LLM的关键词记忆生成方法往往‘黑箱操作’，缺乏可解释性。", "innovation": "本文提出了一种生成框架，该框架将记忆构造过程明确建模为受一套常见规则驱动的过程，并使用一种新的期望最大化类型算法进行学习。该方法在基于学习者创作的在线平台上的记忆生成训练后，能够学习潜在结构和构词规则，从而实现可解释和系统的记忆生成。", "conclusion": "实验表明，我们的方法在新的学习者中具备出色的冷启动性能，同时为解释高效的记忆构建机制提供了洞察力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12072", "html_url": "https://arxiv.org/abs/2506.12072", "title": "TrueGL：全面堆栈搜索中基于事实学习的可靠且统一的引擎", "title_en": "TrueGL: A Truthful, Reliable, and Unified Engine for Grounded Learning in Full-Stack Search", "authors": "Joydeep Chandra,Aleksandr Algazinov,Satyam Kumar Navneet,Rim El Filali,Matt Laing,Andrew Hanna", "background": "在信息开放和自由的时代，对AI的依赖日益增加，但现有的AI工具无法有效评估信息的可信度并对其评估进行解释。因此，迫切需要帮助用户评估在线信息可靠性的系统。尽管主要的搜索引擎包含AI功能，但往往缺乏明确的可靠性指标。研究旨在改进这一问题，提出一种使可信搜索结果更易获取的模型——TrueGL。该模型基于IBM的Granite-1B进行微调，集成到搜索引擎中，并结合了可靠性评分系统。通过使用提示工程技术，并为每个声明分配从0.1到1的连续可靠性分数，模型返回带有分数的文本解释，根据标准评估指标测量每个模型预测分数与实际分数的对齐情况，从而确认该系统在关键评价指标（如MAE, RMSE, R2）上的优越性。", "innovation": "研究引入了TrueGL模型，这是一种面向搜索引擎的可靠性增强型AI工具，通过对现有模型的微调和集成可靠性评分系统的方式，显著提高了在线信息评估的准确性和透明性。TrueGL在多个实验中表现出色，尤其在关键评价指标上超越了其他小型语言模型和基于规则的方法，提高了用户获取和信任真实、可靠信息的便利程度，从而有助于减少在线虚假或误导性内容的传播。", "conclusion": "研究通过公开发布代码和模型，使得其他研究人员和开发者能够验证和改进该系统，进一步推动该领域的创新。TrueGL的出现不仅解决了在线信息可信度评估的难题，也为后续相关研究提供了重要的参考和指导。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超越频率：冗余在大规模语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "大规模语言模型的内存化行为带来了对隐私和公平性的关键风险，尤其当这些模型的参数规模达到数亿时。先前的研究虽然发现内存化与标记频率和重复模式之间的相关性，但尚未揭示具体冗余性对内存化模式的影响。研究表明，标记频率对已记忆样本的微弱影响（例如，0.09）和对非记忆样本的显著影响（例如，0.25），并且这种一致性在不同的模型规模中存在。披扰样本前缀并通过计算标记位置的改变来量化扰动强度，展示了冗余性与记忆模式的相关性。", "innovation": "本文通过分析披扰样本前缀并量化扰动强度，揭示了冗余性在受内存化模式影响中的核心作用。研究发现约79%的内存化样本具有低冗余性，这些样本的脆弱性是高冗余性的两倍多。在披扰中，内存化样本下降0.6，而非内存化样本仅下降0.01。这些结果暗示可能需要冗余性指导的数据预处理方法，从而减少隐私风险并减轻偏差，以确保模型部署的公平性", "conclusion": "本文的研究结果表明，低冗余度的样本在内存化中具有更高的记忆脆弱性，且这种影响在模型中具有普遍性。因此，通过对数据的冗余性进行指导性预处理，可以使模型部署更为安全和公平，减少隐私泄露和偏差问题。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13611", "html_url": "https://arxiv.org/abs/2506.13611", "title": "一种用于电力系统中闪烁估计的混合人工智能方法", "title_en": "A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems", "authors": "Javad Enayati,Pedram Asef,Alexandre Benoit", "background": "本文介绍了一种结合H滤波器和自适应线性神经网络(ADALINE)的新颖混合AI方法，用于电力分配中的闪烁成分估计。该方法利用H滤波器在不确定性和噪声条件下的鲁棒性，提取电压包络，随后使用ADALINE准确识别嵌入在信号中的闪烁频率。这种协同作用使得时域估计变得高效，并且具有快速收敛性和抗噪性，解决了现有频域技术的主要局限性。", "innovation": "结合了H滤波器的鲁棒性与ADALINE的准确性，无需先验噪声特性知识或广泛处理即可有效处理复杂的电力干扰；通过IEC标准61000-4-15、统计分析、蒙特卡洛模拟和实际案例验证了方法的性能，表现出优于基于快速傅里叶变换和离散小波变换估计方法的优越准确性、鲁棒性和计算量减少。", "conclusion": "本文提出的方法克服了传统技术的限制，能够高效准确地估计电力系统中的闪烁，具有快速收敛性和抗噪性，实际验证表明它优于基于快速傅里叶变换和离散小波变换的估计器。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 偏置修正和非对称缩放增强的旋转量化方法用于大规模语言模型", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已成为大规模语言模型(LLMs)中先进量化管道的重要组成部分，通过有效平滑权重和激活中的异常值。然而，进一步优化旋转参数带来的性能提升有限，并且引入了显著的训练开销：由于旋转参数共享，完整模型必须同时加载以启用反向传播，导致内存消耗巨大，实用性受限。当前的旋转量化方法存在两个基本限制：(i)旋转无法对齐通道均值，导致量化范围更宽且增加舍入误差；(ii)旋转使激活分布更像高斯分布，增加了剪裁误差引起的能量损失。", "innovation": "我们提出了BASE-Q，这是一个简单而强大的方法，结合了偏置修正和非对称缩放，以有效地减少舍入和剪裁误差。进一步，BASE-Q 允许块级优化，消除了对内存消耗大的全程模型反向传播的需求。广泛的实验在不同LLMs和基准测试上表明，BASE-Q 的效果突出，与 QuaRot、SpinQuant 和 OSTQuant 相比，基于BASE-Q的方法在准确性方面分别缩小了50.5%、42.9% 和 29.2% 的精度差距。", "conclusion": "实验结果展示了BASE-Q的有效性，可以与全精度模型的准确性差距缩小50.5%、42.9% 和 29.2%。该代码将很快发布。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "具有科学可解释性的推理网络（ScIReN）：在碳循环及其更广范围内的隐藏关系发现", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中的碳流动对于减缓气候变化至关重要。尽管土壤具备从大气中吸收碳的潜力，但土壤碳循环的过程仍然缺乏完全的理解。基于现有知识建立的数学过程模型存在许多未知参数，这些参数通常是通过随意设置的，并且往往不能很好地拟合观测数据。另一方面，神经网络可以从数据中学习模式，但它们并不遵循已知的科学法则，并且其黑盒性质限制了它们揭示新的科学关系的能力。因此，提出了一种完全透明的框架——科学可解释推理网络（ScIReN），该框架结合了可解释的神经网络和过程模型推理。", "innovation": "ScIReN 使用柯尔莫哥洛夫-阿诺尔德网络 (KAN) 确保编码器完全可解释，并揭示输入特征与潜在参数之间的关系；使用新颖的平滑性惩罚来平衡表达能力和简单性。同时，使用一种新的硬 Sigmoid 约束层来限制潜在参数在由科学先验知识定义的有效范围内。过程模型解码器强制实施既定的科学知识，而基于 KAN 的编码器揭示了传统黑盒模型中隐藏的新科学关系。在模拟土壤中的无机组分流动和植物生态呼吸两项任务中，ScIReN 在预测准确性上超越了黑盒网络，同时提供了显著的科学可解释性——它可以推断出潜在的科学机制及其与输入特征的关系。", "conclusion": "ScIReN 在模拟碳循环及其应用中显示出卓越的性能，不仅提高了预测精度，还提供了重要科学可解释性。它能够揭示隐藏在传统文化模型中的科学关系，为碳循环研究提供了新的视角。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习关联配置和性能的模型。然而，在动态环境中，工作负载变化、硬件更改和系统更新都会在不同级别引入概念漂移，即全局漂移重塑整个配置空间的性能景观，而局部漂移仅影响该空间的某些子区域。现有的离线和迁移学习方法难以实时适应这些隐形和不可预测的变化，使配置性能学习变得困难。", "innovation": "本文提出了一种名为DHDA的在线配置性能学习框架，设计用于捕获并在不同级别适应这些漂移。关键创新在于DHDA使用双重层级适应：在较高层级，重新划分数据以在必要时处理全局漂移，而在较低层级，各个划分的局部模型可以异步检测并适应局部漂移。为了平衡响应性和效率，DHDA结合增量更新和定期全面重训练，以在检测到漂移时最小化冗余计算。通过八个软件系统与最先进的方法进行了评估。", "conclusion": "实验证明，DHDA在准确性和适应漂移方面表现出显著改进，最高可达2倍的提升，同时引入了合理的开销，并能改进不同局部模型以处理概念漂移。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: 细粒度评估大语言模型结构化知识理解能力的基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大型语言模型（LLMs）在理解结构化知识（SK）方面，如知识图谱（KG）和表格取得了显著进展，但现有的SK评估还不够严格（缺乏具体能力的评估），并且主要集中在单一种类的SK上。因此，本文旨在提出一种更全面和严格的结构化知识理解基准，以诊断LLMs的不足。", "innovation": "我们提出了SKA-Bench，一种包含四种广泛应用的结构化知识形式（KG、Table、KG+Text、Table+Text）的结构化知识增强问答基准。我们使用三阶段流水线构建SKA-Bench实例，其包含问题、答案、正向知识单位和噪声知识单位。为细粒度评估LLMs的SK理解能力，我们将其扩展到四个基本能力测试领域：噪声鲁棒性、顺序无关性、信息整合和否定排斥。", "conclusion": "对8个代表性LLM，包括先进的DeepSeek-R1进行实证评价后表明，现有的LLMs在理解结构化知识方面仍面临巨大挑战，其性能受到噪声量、知识单元顺序和幻觉现象等因素的影响。我们的数据集和代码可在以下链接获取。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "区域级上下文感知多模态理解", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大语言模型（MLLMs）方面取得了显著进展，现有研究主要集中在一般视觉理解上，忽略了综合利用物体关联的文本上下文以实现更具有上下文感知的多模态理解。作为这种能力，该研究定义了区域级上下文感知多模态理解（RCMU）任务。", "innovation": "为解决这一局限性，作者提出了区域级上下文感知视觉指令调优（RCVIT），这是一种结合对象信息输入模型并使模型能够有效将对象的视觉内容与其文本信息关联的调节方法。作者还创建了RCMU数据集和RC&P-Bench基准测试，可评估MLLMs在RCMU和多模态个性化理解任务中的性能，并提出了参考独立评估指标以全面和细致地评估区域级上下文感知图像描述。", "conclusion": "通过使用RCMU数据集在Qwen2-VL模型上执行RCVIT，开发了RC-Qwen2-VL模型。实验结果表明，RC-Qwen2-VL模型在多项RCMU任务上表现出色，并成功应用于多模态RAG和个性化对话。数据、模型和基准可以从提供的链接下载。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 学习使用自监督注意力识别手写数学公式", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式识别（HMER）是一项具有挑战性的任务，原因在于其固有的二维结构、符号规模的变化以及符号之间的复杂空间关系。现有的方法通常需要大量的标注数据，而这些数据资源往往非常稀缺且昂贵。因此，本研究提出了一种自监督学习（SSL）框架，以减少对昂贵标注数据的依赖。该框架通过结合全局和局部对比损失进行图像编码的预训练，使模型能够学习整体和精细的表示。", "innovation": "本文的主要贡献在于提出了一种新颖的自监督注意力网络，该网络采用逐步空间遮蔽策略进行训练。这种注意力机制旨在学习具有语义意义的焦点区域，如运算符、指数和嵌套的数学符号，而无需任何监督。逐步遮蔽课程促使网络逐步提高对缺失或被遮挡视觉信息的鲁棒性，从而最终提升结构理解。完整的pipeline包括（1）编码器的自监督预训练，（2）自监督注意力学习，以及（3）带有transformer解码器的监督微调，以生成LATEX序列。", "conclusion": "在CROHME基准上的广泛实验表明，本方法优于现有的自监督和完全监督基线，验证了我们逐步注意力机制在增强HMER性能方面的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22612", "html_url": "https://arxiv.org/abs/2507.22612", "title": "适应性时长模型用于文本语音对齐", "title_en": "Adaptive Duration Model for Text Speech Alignment", "authors": "Junjie Cao", "background": "语音到文本的对齐是神经文本到语音（TTS）模型的关键组成部分。自回归TTS模型通常使用注意力机制在线学习这些对齐关系，而非自回归的端到端TTS模型则依赖于从外部来源提取的时长。当前的基线模型在此方面存在一定的局限性。", "innovation": "本文提出了一种新颖的时长预测框架，能够在给定文本的情况下，提供有前景的音素级时长分布。实验结果显示，与之前的基本模型相比，提出的时长模型具有更高的预测精确度和适应能力，特别是在音素级对齐精度方面取得了显著进步，并且使零样本TTS模型更能应对输入音频与提示音频之间的不匹配情况。", "conclusion": "所提出的适应性时长模型可以更精确地预测音素级时长分布，并提高非自回归端到端TTS模型的表现，特别在处理输入音频与提示音频不匹配情况时表现出更强的鲁棒性。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过Dirac重平衡器和分布缠结实现单域泛化在跨癌症类型的多模态预后", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据进行生存预测方面取得了显著的性能，但现有方法主要针对单一癌种，忽视了跨癌种泛化的挑战。尽管在临床实践中对这种稳健性有很高的需求，现有模型往往在跨癌种场景下的泛化能力不如单一模态模型。为解决这一问题，我们首次提出了跨癌种单一域泛化在多模态预后的任务，评估单癌种训练的模型能否泛化到未见过的癌种。我们识别出两个关键挑战：较弱模态退化特征和无效的多模态整合。", "innovation": "我们提出了两个新的模块：稀疏狄拉克信息重平衡器（SDIR）和癌症感知分布缠结（CADE）。SDIR通过基于伯努利的稀疏化和狄拉克启发的稳定化来减轻强特征的主导，增强较弱模态信号。CADE旨在合成目标领域的分布，在潜在空间中融合局部形态线索和全局基因表达。实验结果表明，我们提出的模型具有更强的泛化能力，为实际应用中跨癌种的多模态预后奠定了基础。", "conclusion": "实验结果表明，我们提出的方法在四癌种基准数据集上具有优越的泛化性能，为跨癌种的多模态预后提供了坚实的基础。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在各个领域中非常重要，但现有的方法常常只进行二元异常分类，而不进行详细的分类或进一步的解释性推理。因此，本文提出了一种新的任务——时间序列异常 reasoning（Time-RA），该任务将传统的时序异常检测从判别式任务转化为生成式、推理密集型任务，利用Large Language Models（LLMs，大型语言模型）实现。此外，本文还介绍了第一个用于异常推理的真正世界多模态基准数据集——RATs40K，该数据集包含约4万个样本，涵盖了10个真实世界领域，每个样本包括数值时间序列数据、上下文文本信息和视觉表示，并且每个样本都用细粒度类别（14种类型用于单变量异常，6种用于多变量异常）和结构化解释性推理进行标注。开发了一个复杂的注释框架，利用GPT-4驱动的反馈进行集成生成标签的改进，确保了准确性和可解释性.", "innovation": "本文的主要创新之处在于提出了Time-RA任务，将时间序列异常检测转变为一种生成式、推理密集型的任务，利用了LLMs进行问题解决。同时，引入了第一个专门为异常推理标注的现实世界多模态基准数据集——RATs40K，该数据集具有可解释性和丰富的标注信息。此外，还开发了利用GPT-4驱动的反馈进行全面标签改进的注释框架，以提高注释的准确性和可解释性。实验表明，现有的大型语言模型和多模态模型在处理此类任务时具有一定的能力和局限性，强调了监督微调的重要性。", "conclusion": "本文的数据集和任务为理解可解释的时间序列异常检测和推理带来了重大进展。同时，代码和数据集已经完全开源，以支持和加速该领域的未来研究。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL: 通过熵机制平衡大型语言模型测试时强化学习中的探索与利用", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "近年来，大型语言模型在复杂推理任务如数学和编程中取得了显著进步。然而，这些模型仍然高度依赖于标注数据，并在无监督场景中显示出有限的适应性。为了解决这些限制，测试时强化学习（TTRL）被提出，它通过利用模型生成的伪标签实现自我优化。尽管该方法具有潜力，但它面临一些关键挑战，包括并行展开导致的高推理成本和早期阶段估计偏差导致的过度自信问题，这些问题降低了输出的多样性并导致性能停滞不前。", "innovation": "为了应对这些挑战，作者引入了一种基于熵的机制，通过两种策略（Entropy-fork Tree Majority Rollout (ETMR) 和 Entropy-based Advantage Reshaping (EAR)）来增强测试时强化学习中的探索与利用平衡。我们的方法使得 Llama3.1-8B 在 AIME 2024 基准上的 Pass at 1 测量指标相比基线实现了 68% 的相对改进，同时消耗了 60% 的展开令牌预算。这表明我们的方法能够有效优化推理效率、多样性和估计稳健性的权衡，从而推动开放域推理任务中的无监督强化学习的发展", "conclusion": "实验结果表明，我们的方法能够有效平衡测试时强化学习中的推理效率、多样性和估计的稳健性，进一步推动了开放域推理任务中的无监督强化学习的发展。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14119", "html_url": "https://arxiv.org/abs/2508.14119", "title": "Fabric文档库：现实世界AI治理的资料库", "title_en": "Documenting Deployment with Fabric: A Repository of Real-World AI Governance", "authors": "Mackenzie Jorgensen,Kendall Brogle,Katherine M. Collins,Lujain Ibrahim,Arina Shah,Petra Ivanovic,Noah Broestl,Gabriel Piles,Paul Dongha,Hatim Abdulhussein,Adrian Weller,Jillian Powers,Umang Bhatt", "background": "人工智能越来越多地融入社会，应用于金融服务、交通管理甚至创意写作等领域。关于AI部署的学术研究主要集中在其使用带来的风险和危害上。本文介绍了Fabric，一个公开的AI应用场景资料库，用于概述这些应用场景的治理机制。通过对行业实践者的半结构化访谈，收集了20个AI应用场景，并设计了AI工作流程图。以此来讨论实际中使用的监督机制和预防措施，以确保AI系统的安全性。Fabric资料库包含AI应用案例的可视化图和已部署系统的描述。通过使用这个资料库，研究人员发现了治理中的缺口，并找出了已部署AI系统中的人类监督模式。", "innovation": "Fabric是一个创新的、公开的资料库，它系统性地记录并分析了AI部署案例及相应的治理机制。资料库不仅包含案例的视觉展现，还有实战者的详细描述，这为研究人员提供了新的视角来评估AI治理的有效性，填补了现有研究中关于AI部署治理部分内容的空白。", "conclusion": "Fabric旨在成为一项可扩展、不断进化的工具，为研究人员提供一个研究AI治理体系效果的平台。通过识别和分析AI部署中的人类监督模式和保障措施，Fabric帮助更好地理解和改进AI治理。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器中的量化神经网络：方法、平台与应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "资源受限设备（如微控制器）上部署量化神经网络（QNNs）引入了平衡模型性能、计算复杂度和内存限制的显著挑战。为了应对这一挑战，微型机器学习（TinyML）通过结合机器学习算法、硬件加速和软件优化的最新进展来有效地在嵌入式系统上运行深度神经网络。本文提供了一种以硬件为导向的量化介绍，并系统地回顾了加速嵌入式应用中深度学习模型的关键量化技术，特别强调模型性能与硬件能力之间的关键权衡。此外，还评估了专门支持微控制器上QNN执行的现有软件框架和硬件平台，并分析了当前挑战，以及此快速发展的QNN部署领域的有前途的未来方向", "innovation": "本文提供了一种以硬件为导向的全面介绍量化技术，并系统性地回顾了微控制器上深度学习模型加速所需的关键量化技术；特别强调了模型性能与硬件能力之间的权衡；评估了支持微控制器上量化神经网络执行的现有软件框架和硬件平台；提供了当前挑战与未来发展方向的分析", "conclusion": "本文为小控制器上的量化神经网络部署提供了全面的回顾，介绍了关键的量化技术，评估了现有支持微控制器上QNN执行的软件框架和硬件平台，分析了当前挑战，并探讨了有前途的未来发展方向，为这一快速发展的领域的研究者和开发者提供了有价值的参考"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME: 提升主题投资的语义股票表示和时间动态", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资旨在构建与结构性趋势相一致的资产组合，但由于行业界限重叠和市场动态不断演变，这仍然是一个具有挑战性的任务。虽然可以从文本数据中构建投资主题的语义表示，但是通用的大规模语言模型（LLM）嵌入模型并不适合捕捉金融资产的细微特征，因为金融资产的语义表示可能与一般金融文本有本质上的不同。因此，需要一种新的框架来解决这一问题。", "innovation": "提出了一种名为THEME的框架，它通过分层对比学习来微调嵌入。THEME利用主题和其构成股票之间的层次关系，随后通过股票回报的信息来进一步完善这些嵌入。此过程产生出能够有效检索与主题投资目标一致且具有高回报潜力的资产表示。实证结果表明THEME在主题资产检索方面远超领先的大规模语言模型，在构建的投资组合方面也表现出色。通过同时建模文本中的主题关系和市场动态中的回报信息，THEME为广泛的实际投资应用生成了专门定制的股票嵌入。", "conclusion": "THEME可以在主题资产检索和投资组合构建中提升表现，通过结合文本和市场动态信息，生成适用于各种实际投资应用的特殊股票嵌入。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher：通过细粒度原子思考奖励提升自主深层研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大语言模型（LLMs）在解决问题方面表现出色，但在应对复杂的任务时由于其静态内部知识而遇到困难。检索增强生成（RAG）虽然能够提高对外部信息的访问，但在多跳推理和策略搜索方面仍然受到僵硬工作流程的限制。近期的研究使LLMs能够自主地进行推理、搜索和信息合成。然而，当前依赖于基于结果的强化学习（RL）的方法面临着关键问题，如梯度冲突和奖励稀疏性，这限制了性能提升和训练效率。", "innovation": "我们首次提出了一个名为Atomic Thought的新颖LLMs思考范式，该范式通过细粒度的功能单元分解推理。这些单元被Reasoning Reward Models (RRMs)监督，RRMs提供细粒度指导的Atomic Thought Rewards (ATR)。在此基础上，我们提出了一种新型的RL框架Atom-Searcher，它将Atomic Thought和ATR整合，并采用一种类似于课程的学习奖励计划，优先早期阶段的细粒度奖励，过渡到结果奖励，从而加速有效推理路径的收敛。Atom-Searcher的关键优势包括：（1）测试时计算量可扩展。（2）Atomic Thought为RRMs提供监督锚点，有助于深层研究任务和RRMs的结合。 （3）Atom-Searcher展现出更可解释、类似人类的推理模式。", "conclusion": "实验在七个基准测试上显示，Atom-Searcher相比于最先进的方法有持续改进。关键优点包括：（1）Atom-Searcher在测试阶段扩展计算能力。（2）Atomic Thought为RRMs提供了监督锚点，并将深层研究任务和RRMs相结合。（3）Atom-Searcher展示了更可行、类似于人类的推理模式。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 评估大型语言模型在凝聚态物理学中的基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "现有的大型语言模型（LLMs）在凝聚态物理学领域的能力评估存在不足，缺乏专门针对该领域的基准测试。因此，本研究旨在通过创建CMPhysBench，提供一个专门用于评估LLMs在凝聚态物理学中的专业知识的新基准。CMPhysBench包含超过520个精心挑选的研究生水平问题，涵盖了包括磁性、超导性和强关联系统在内的多个子领域和基础理论框架。", "innovation": "提出了CMPhysBench作为评估LLMs在凝聚态物理方面能力的新工具；设计了包含大量覆盖凝聚态物理学不同子领域和基本原则的计算问题；引入了Scalable Expression Edit Distance（SEED）分数，这是一种细粒度（非二进制）的部分评分方法，用于评估预测与真实值之间的相似性，比二进制评分方法更为准确。", "conclusion": "实验结果表明，即使是最优质的模型Grok-4在CMPhysBench上的平均SEED分数仅为36，准确率为28%，这揭示了与传统物理学科相比，在这一实践和前沿领域中，LLMs的机能差距仍然显著。研究团队公开了代码和数据集，以促进进一步的研究和改进。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "信任并验证！关于测试时缩放验证设计的综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "测试时缩放（TTS）已成为提升大型语言模型（LLMs）性能的新前沿领域。在TTS中，通过推理时使用更多的计算资源，LLMs可以优化其推理过程和任务表现。已有一些方法发展起来，例如从另一个模型中提取推理轨迹或是通过引入验证器探索解码的大搜索空间。验证器充当奖励模型，通过对解码过程中产出的候选输出进行评分，帮助深入探索广泛解空间并选出最优结果。这种方法因为无需参数缩放和高效率表现成为主流。尽管验证器被广泛应用，但没有详细的文献收集、清晰的分类和讨论来对比各种验证方法及其训练机制。", "innovation": "本文综述了TTS验证设计的多样化方法，并提出了统一的验证器训练方法、类型及其在TTS中的应用视图。它填补了现有文献中缺乏系统化整理验证方法空白，提供了一个关于验证器训练机制的串联视图，这将有助于深入理解TTS中的验证器角色及其效能，进一步推动TTS领域的发展和研究。", "conclusion": "本文全面概述了TTS中的验证器方法及其训练机制，提出了一个统一的验证器视角。通过我们的研究，研究者们可以获得清晰的认识关于这些方法的不同类型和它们如何用于TTS，这将有助于改进现有系统并推动TTS领域的发展。我们的文献仓库位于此 [链接]。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大型语言模型（LLMs）通过增加推理过程中计算量来增强其推理能力，虽然这种方法有效，但会带来显著的延迟和资源成本，限制了其在时间敏感或成本敏感的实际场景中的应用。\n", "innovation": "提出了BudgetThinker，一种新型框架，旨在使LLMs具备预算感知的推理能力，使得模型能够控制其思考过程的长度。该方法在推理过程中周期性地插入特殊的控制标记，实时告知模型剩余的令牌预算，并结合一个两阶段的训练管道，首先进行监督微调（SFT），使模型熟悉预算约束，然后通过基于课程的强化学习（RL）优化模型的准确性和预算遵守情况。\n", "conclusion": "实验结果证明，BudgetThinker在一系列困难的数学基准测试中，显著优于强大的基线模型，并且能够在多种推理预算下保持性能。该方法提供了一个可扩展和有效的解决方案，用于开发高效可控的LLM推理，使其在资源受限的实时环境中的部署更加实际。\n"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA: 农业视觉问答数据集，用于植物科学中视觉语言模型的基准测试", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "该论文介绍了一个名为PlantVillageVQA的大规模视觉问答（VQA）数据集，其来源是广泛使用的PlantVillage图像库。该数据集旨在推动农业决策和分析中视觉语言模型的开发与评估。背景信息强调了作物疾病的识别和农业领域的科学研究的重要性，指出现有模型需要更准确的诊断数据集来提升准确率和科学验证的需要。", "innovation": "PlantVillageVQA数据集通过两阶段自动管道构建高质量的问答对，并由领域专家审查以确保科学准确性和相关性。此数据集分为三个认知复杂度级别和九个不同的主题类别，采用机器生成和手动辅助的方式进行组织，提供了一个标准化且专家验证的诊断数据库，增强了植物疾病识别的准确性，并促进了农业领域的科学研究。这一创新的数据集有助于比对和评估视觉语言模型在植物科学中的应用效果。", "conclusion": "论文最终目标是提供一个公开可用的标准和专家验证数据库，以提升植物疾病诊断的准确性并推进农业领域的科学研究。这个数据集将开源发布于这里的网址：this https URL。结论指出，PlantVillageVQA能够显著提升农业领域内视觉语言模型的训练与评估标准，为该领域内的研究提供有力支持。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19660", "html_url": "https://arxiv.org/abs/2508.19660", "title": "任意精度的集成进化近似印刷三值神经网络", "title_en": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation", "authors": "Vojtech Mrazek,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Zdenek Vasicek,Mehdi B. Tahoori,Georgios Zervakis", "background": "印刷电子为超越硅基系统提供了有希望的替代方案，需要灵活性、可拉伸性、顺应性和超低制造成本等特性。尽管印刷电子的大特征尺寸，印刷神经网络因其满足目标应用需求而受到关注，但实现复杂电路仍然具有挑战性。", "innovation": "本文提出了一个自动化框架，用于设计具备任意输入精度的印刷三值神经网络，利用多目标优化和整体近似技术。所设计的电路在面积和功耗方面分别优于现有近似印刷神经网络17倍和59倍，同时首次实现了低于5%准确率损失的印刷电池供电操作，考虑了模拟到数字接口的开销。", "conclusion": "该工作在印刷神经网络的设计和优化方面取得了突破，特别是在面积效率和能耗方面取得了显著改进，为印刷电池供电操作开启了新的可能。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT —— 一種基於殘差、空間和邊界意識學習的新型通道增强混合CNN变换器，用于脑肿瘤MRI分析", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤是人类最致命的疾病之一，早期检测和准确分类对于有效诊断和治疗计划至关重要。尽管基于深度学习的计算机辅助诊断（CADx）系统取得了显著进步，但传统的卷积神经网络（CNN）和Transformer仍然面临高计算成本、对轻微对比度变化敏感、结构异质性和MRI数据中纹理不一致等持续挑战。因此，提出了一种新的混合框架CE-RS-SBCIT，结合了基于残差和空间学习的CNN与Transformer驱动模块，旨在克服这些挑战。", "innovation": "该框架通过四种核心创新实现了局部精细和全局上下文信息的利用：（i）一种基于差分和边界的CNN-集成Transformer（SBCIT）；（ii）个性化的残差和空间学习CNN；（iii）通道增强（CE）策略；（iv）新的空间注意力机制。SBCIT采用卷积和上下文交互Transformer块，具备系统性的平滑和边界操作，使全局特征建模更加高效。增强了空间注意力机制也可以在肿瘤类别中强调微妙的对比和纹理变化。", "conclusion": "在Kaggle和Figshare提供的具有挑战性的MRI数据集（包括胶质瘤、脑膜瘤、垂体肿瘤和健康对照）上进行的广泛评估表明，该方法表现优越，实现了98.30%的准确性、98.08%的敏感性、98.25%的F1分数和98.43%的精确度。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21084", "html_url": "https://arxiv.org/abs/2508.21084", "title": "跨越代际的有毒评论映射：来自德国公共广播的数据集", "title_en": "Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting", "authors": "Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke", "background": "现有的有毒言论数据集缺乏人口统计学背景，限制了我们对不同年龄组在线交流方式的理解。", "innovation": "该研究与德国公共服务内容网络funk合作，引入了首个标注有毒言论的大规模德语数据集，其中包括从Instagram、TikTok和YouTube获取的3,024条人工标注和30,024条语言模型标注的匿名评论，并附带平台提供的年龄估算。这使得可以直接分析不同年龄段用户的有毒言论模式。", "conclusion": "该数据集揭示了基于年龄的有毒言论模式差异，年轻用户更喜欢表达性语言，而年长用户更频繁地参与信息的误传和价值观贬低。这项资源为研究不同人口统计学群体的语用学变异提供了新的机会，并支持了更加公正和年龄意识的内容管理系统的开发。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21137", "html_url": "https://arxiv.org/abs/2508.21137", "title": "认知偏差如何影响大型语言模型？一种价格谈判模拟中的锚定效应案例研究", "title_en": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": "Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu", "background": "人类在认知过程中表现出的各种偏差也存在于LLMs中，影响其在现实世界应用中的可靠性。本文研究了在LLM驱动的价格谈判中锚定效应的影响。", "innovation": "通过指导LLM卖家代理运用锚定效应并采用客观和主观的评估标准来了解LLMs是否也同样受到锚定效应的影响。同时，本文还探讨了锚定效应与推理能力及个性特征之间的关系，发现推理模型对抗锚定效应更强，但并没有发现个性特征与锚定效应敏感性之间的显著关系。", "conclusion": "研究发现为理解LLMs中的认知偏差提供了深入见解，并有助于确保LLMs在社会中的安全和负责任应用。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Multimodal LLMs能否解决Percept-V的基本感知问题？", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来，多模态大语言模型（MLLMs）在编码、数学和科学等复杂任务中的推理能力受到了广泛关注。然而，很少有实验评估它们在处理未受污染的、包含基本形状和结构的生成图片的基础感知任务中的表现。", "innovation": "本文提出了一个名为Percept-V的数据集，包含7200张由程序生成的、未受污染的图片，分为30个类别，每类都测试了不同的视觉感知技能。这些类别涵盖了不同复杂度的基本任务，旨在评估MLLMs的感知能力。实验还测试了包括GPT-4o、Gemini、Claude等最先进的MLLMs和OpenAI o4-mini、DeepSeek R1等大型推理模型。结果显示，MLLMs在复杂度增大的问题上的表现明显下降。分析表明，测试的MLLMs在各类任务中的准确率表现出类似的趋势，某些认知技能比其他技能更难。", "conclusion": "尽管MLLMs在许多复杂任务中表现出色，但在基础感知任务上的表现却不尽如人意，随着问题复杂度的增加，模型的性能显著下降。需要进一步研究以提高MLLMs在基础感知任务中的处理能力。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19637", "html_url": "https://arxiv.org/abs/2508.19637", "title": "特邀论文：极端边缘环境下混合信号智能柔体可穿戴设备的特征-分类器协同设计", "title_en": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge", "authors": "Maha Shatta,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Georgios Panagopoulos,Mehdi B. Tahoori,Georgios Zervakis", "background": "柔体电子（FE）为可穿戴健康监测设备提供了比刚性硅基硬件更具前景的选择，使系统更加轻盈、贴合并且成本更低。然而，它们有限的集成密度和大的特征尺寸对面积和功率提出了严格的限制，这使得基于机器学习（ML）的健康监测系统（包括模拟前端、特征提取和分类器）尤其具有挑战性。现有FE解决方案通常忽略了系统级的解决方案，专注于分类器部分，忽略了特征提取和模拟-数字转换器（ADC）等硬件成本对面积和功耗的显著贡献。", "innovation": "本文提出了一种面向混合信号智能柔体可穿戴设备的特征至分类器的全方位模拟混合信号协同设计方案。设计出第一种在FE上的模拟特征提取器，大大降低了特征提取的成本。进一步提出了一种硬件感知的NAS启发式的特征选择策略，可以在ML训练中实现高效、特定应用的设计。在健康监测基准测试上的评估结果显示，这种方法可以提供非常准确、极高的面积效率的柔体系统，非常适合一次性、低功耗的可穿戴监测设备。", "conclusion": "我们的方法展示了在柔体可穿戴设备上实现高度准确且极其高效的机器学习系统是可能的，这种系统特别适合一次性低功耗的健康监测应用。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "BED-LLM：利用大语言模型和贝叶斯实验设计进行智能信息收集", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "本文提出了一种通用方法，旨在增强大型语言模型（LLMs）智能、自适应地从用户或其他外部源收集信息的能力。本文在贝叶斯实验设计（BED）框架下进行工作，使LLMs能够作为有效的多轮对话代理，并与外部环境进行互动式接口。", "innovation": "本文的主要创新之处在于精心设计的预期信息增益（EIG）估计器，不仅依赖于上下文更新来根据之前响应进行条件化，还提出了一种针对性的战略，用于提出候选查询。这些创新对于BED-LLM的成功至关重要。", "conclusion": "实验表明，相较于直接对LLM进行提示和其他自适应设计策略，BED-LLM在多种测试中，包括20-问题游戏和利用LLM主动推断用户偏好方面的性能取得了显著提高。"}
{"llm_update_time": "20250903", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "Robustness is Important: Limitations of LLMs for Data Fitting", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）已广泛应用于各种场景，而不仅仅是语言相关的任务。特别是在数据拟合和生成预测方面，LLMs 经常作为易于使用的方法被采用。先前的研究表明，通过上下文学习或有监督微调，LLMs可以在预测性能方面与许多表格监督学习技术竞争。然而，研究表明，当对数据表示进行与学习任务无关的更改时，这可能会显著改变LLMs的预测结果，例如，仅仅改变变量名就可能使预测误差大小变化达82%，且这种敏感性在上下文学习和有监督微调中都存在。尽管有一种专门针对数据拟合训练的先进表格基础模型（TabPFN），它被设计为具有预测稳健性，但在任务无关的变量变化面前也并非完全免疫。因此，尽管LLMs具有出色的预测能力，它们目前缺乏基本的稳健性，这使得它们不适合用作数据拟合工具的稳健性原则方法。", "innovation": "本文发现了一个关键的缺陷，即LLMs在数据拟合方面的鲁棒性较差。即使有监督的微调或上下文学习也无法保证模型对任务无关的变化的不变性。此外，通过分析开放权重LLMs的注意力分数，研究人员揭示了一种非均匀的关注模式：训练示例和变量值在指示符中占据的位置在生成输出令牌时会获得更多的注意力，即使不同的位置通常预期获得大致相同的注意力。这一发现解释了在面对任务无关的变化时的敏感性。此外，尽管最先进的表格基础模型（TabPFN）专门设计用于达到预测稳健性，但仍然对任务无关的变化不具有免疫力。", "conclusion": "尽管LLMs在预测方面表现出色，但目前缺乏基本的稳健性，无法作为数据拟合工具的稳健性原则方法使用。为了克服这一限制，未来的研究可以探索如何在模型中增加对任务无关变化的鲁棒性，或开发更稳健的替代模型。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: 通过语义三元组减轻各种虚假相关性的反偏数据增强", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型经常在训练数据中学习和利用虚假的相关性，并使用这些非目标特征来进行预测。对这些虚假相关性的依赖会导致模型在未见过的数据上的性能下降和泛化能力差。为了缓解这些问题，我们提出了更加通用的反偏数据增强形式——反偏数据增强，它同时解决了多个偏见（如性别偏见、简化偏见）等问题，并增强了对分布外数据的鲁棒性。", "innovation": "我们提出了CoBA：反偏数据增强（CounterBias Augmentation），这是一种统一框架，操作层次在语义三元组中：首先将文本分解为主词-谓语-宾词三元组，然后有选择地修改这些三元组来破坏虚假的相关性。通过从这些调整后的三元组重建文本，CoBA生成了反偏数据，以减轻虚假模式。我们通过广泛实验表明，CoBA不仅提高了下游任务性能，还有效地减少了偏见并增强了对分布外数据的鲁棒性，提供了一种应对虚假相关挑战的多功能且鲁棒的解决方案。", "conclusion": "CoBA在提高下游任务性能的同时，有效减少了偏见并加强了对分布外数据的鲁棒性，为解决虚假相关性问题提供了一个灵活且稳健的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21085", "html_url": "https://arxiv.org/abs/2508.21085", "title": "Granite Embedding R2 Models", "title_en": "Granite Embedding R2 Models", "authors": "Parul Awasthy,Aashka Trivedi,Yulong Li,Meet Doshi,Riyaz Bhat,Vignesh P,Vishwajeet Kumar,Yushu Yang,Bhavani Iyer,Abraham Daniels,Rudra Murthy,Ken Barker,Martin Franz,Madison Lee,Todd Ward,Salim Roukos,David Cox,Luis Lastras,Jaydeep Sen,Radu Florian", "background": "背景在于随着企业和组织对密集检索应用中检索速度和准确性的需求日益增长，市场竞争愈发激烈，现有的嵌入模型在性能和灵活性方面难以满足这些需求。因此，研究人员开发了一系列高级的嵌入模型以改进这一状况。", "innovation": "创新点在于推出了Granite Embedding R2模型系列，这是一个集成了高性能英语编码嵌入模型的全面家族，专为企业规模密集检索应用而设计。相较于第一代版本，这些模型在上下文长度（扩大了16倍至8,192 token）方面有显著提升，并在文本、代码、长文档搜索、多轮对话和表格数据等多种检索领域表现出卓越的性能。此外，该系列模型还提供了卓越的速度优势，相对于领先竞争对手提高了19-44%的速度，同时维持了更高的准确性。它们包括双编码器和跨编码器架构，并由运行在严格治理下的企业相关数据训练而成。这些模型在标准基准测试、IBM开发的评估套件及真实的商用案例中表现出卓越的通用性和适应性，从而成为开源嵌入模型的新标杆。", "conclusion": "结论指出，在如今竞争激烈的环境中，Granite R2模型以先进的性能、企业级许可和透明的数据来源提供了一个独特的优势组合，这些特性对企业级部署至关重要。所有这些模型都可以在Apache 2.0许可证下公开获取，支持自由研究和商业用途。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签引起的偏见在自我评估和跨模型评估中的程度", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "大型语言模型（LLMs）正在越来越多地用于评估输出，但这些模型的判断可能会受到偏见的影响。本研究探讨了ChatGPT、Gemini和Claude在四种条件下对自己的输出和互相评估中的偏见：无标签、真实标签以及两种虚假标签情况。作者对每种模型撰写的博客进行了评估，使用总体偏好投票和连贯性、信息性和简洁性三个维度的质量评分，并将所有分数表达为百分比以便直接比较。", "innovation": "本研究创新之处在于，通过使用不同的标签来干扰自我的和跨模型的评估过程，以揭示模型对其身份感知的影响，并通过博客评估结果量化了这一偏见的程度。研究发现，假标签会对评估结果产生显著影响，并提出应采用盲测或多模型评估方法以确保LLMs基准测试的公平性。", "conclusion": "研究结果显示，感知到的模型身份会严重影响高层次判断，并微妙地影响详细质量评分。因此，需要采取盲测或多元模型评估协议来确保LLM基准测试的公平性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX Revisited: 使用自动标注增强基准覆盖范围", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大型语言模型（LLMs）能力的增强，建立在多语言和非英语背景下Robust评估方法的需求日益增加。我们更新了BLUEX数据集，使其包括2024-2025年的考试和使用先进技术模型自动生成的图像描述，这使得数据污染研究在LLM预训练中更为相关。通过图像描述策略，提高了仅以文本形式存在的模型的可达性超过40%，产生了1,422个可用问题，数量是原BLUEX的两倍。", "innovation": "我们引入了自动生成图像描述，增加BLUEX数据集的容量，改善了多语言和非英语背景下大型语言模型评估方法的相关性。这不仅增加了数据集的问题数量，还提高了对文本模型的可达性。", "conclusion": "我们评估了商业和开源大型语言模型及其利用带图例的视觉背景的能力。研究表明，这些模型可以从图像描述中受益，增强其对视觉内容的理解和处理能力。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大型语言模型综述：从数据基础到代理前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大型语言模型（Sci-LLMs）正在重塑科学研究中知识的表示、整合和应用方式，但其发展受到科学数据复杂性的制约。该综述通过全面的数据导向综合分析，重构了Sci-LLMs的发展为模型与其基础数据子集的共生演化过程。并详细分析了270多份预训练/后训练数据集，展示了Sci-LLMs面临的独特挑战：异质的、多尺度的、存在不确定性的语料库，需要保留领域不变性和支持跨模态推理的能力。同时，还探讨了从静态考试到以过程和发现为重点的评估方式的转变，以及高级评估协议的应用。", "innovation": "该研究提出了统一的科学数据分类法和科学知识的分层模型，强调了与通用自然语言处理数据集相比，科学语料库的多模态、跨尺度和领域特定的挑战。全面回顾了从通用基础模型到跨学科专业模型的最新Sci-LLMs，并详细分析了大量数据集，揭示了Sci-LLMs的基本需求。研究还讨论了通过半自动注释管道和专家验证等新兴解决方案解决科学数据开发中的持久问题。这些数据导向的分析共同勾勒出建立可信赖且持续进化的AI系统的蓝图，使得Sci-LLMs激活的代理能够积极参与知识库的迭代更新和发展。", "conclusion": "综述提出了一种范式转变，旨在构建自主代理驱动的闭环系统，这些代理能够主动进行实验、验证并贡献于科学知识的活数据库。通过这种方式，为加速科学发现提供了一个实际的AI合作伙伴。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过像素化方法增强自回归语言模型对拼写攻击的鲁棒性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型容易受到拼写攻击的影响，这些攻击通过在输入文本中插入来自多语言字符集的字符，导致显著性能下降。这一问题主要源于基于子词的分词器固有的未登录词问题及其嵌入。", "innovation": "提出了一种基于像素的生成语言模型，用像素化表示取代文本嵌入，将单词作为单独的图像呈现。这种方法提高了模型对噪声输入的鲁棒性，同时扩展了对不同书写系统的多语言文本的兼容性。", "conclusion": "在多语言LAMBADA数据集、WMT24数据集和SST-2基准上评估了所提出的方法，证明其对拼写噪声具有较强的抗扰能力，并在多语言环境中表现出有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常性和图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文旨在重新审视图灵测试的含义，将图灵测试与‘正常性’的概念联系起来。通过探讨图灵测试如何衡量‘正常’而不是‘例外’的人类智能来重新定义图灵测试。同时，提到图灵测试是一个需要通过多名非专家评委进行统计判断的过程，因此在具体实现中可能难以达到图灵测试的要求。", "innovation": "对于图灵测试的理解提出了一种新的视角，即探讨图灵测试如何衡量‘正常性’的人类智能，而非仅仅衡量‘智能’的水平。这不仅涉及对图灵测试本身的理解变革，还需要更深入地理解人工智能模型（如ChatGPT）与人类智能之间的关系。", "conclusion": "大型语言模型（如ChatGPT）可能无法通过图灵测试，因为它们追求的是‘异常’而不是‘正常’的人类智能。更重要的是，图灵测试的核心问题在于人类心智是否可以归结为‘正常’心智，这是一个需要进一步探讨的问题，而不仅仅局限于图灵测试本身。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一个用于评估摘要评价指标的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文探讨了自动文本摘要评价中的可重复性挑战。通过在六个代表性指标上进行实验，涵盖了从经典方法（如ROUGE）到最近的基于LLM的方法（G-Eval、SEval-Ex），文章揭示了文献中报告的性能与实验观察到的显著差异。这些差异引发了对LLM在评价中可靠性的质疑。", "innovation": "文章引入了一个统一的、开源的框架，应用于SummEval数据集，旨在支持公平和透明的评价指标比较。研究结果揭示了一个结构化的权衡：与人类判断最一致的指标往往计算密集且运行一致性较低。这项工作还强调了依赖LLM进行评估的关键问题，包括它们的随机性、技术依赖性和有限的可重复性。", "conclusion": "文章倡导更加稳健的评估协议，包括详尽的文档和方法论标准化，以确保自动摘要评估的可靠性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "从代码生成模型生成高效代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "当前存在多种代码检索和问答模型，但大多数模型要么依赖于单一类型的预训练数据（如纯文本），要么在处理跨语言代码相似性识别时效果欠佳。Jina-code-embeddings模型则创新性地利用了一个同时预训练在文本和代码上的自回归基础模型，通过最后生成的词进行池化生成代码嵌入。", "innovation": "该模型利用一个同时预训练在文本和代码上的自回归模型，并通过最后生成的词进行池化生成嵌入，相比传统的仅依赖纯文本或代码的预训练模型，更全面地理解代码的实际用途和上下文。", "conclusion": "尽管模型规模较小，但在代码检索、技术问答和跨编程语言代码片段相似性识别上表现出色，证明了这种代码嵌入模型构建方法的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21210", "html_url": "https://arxiv.org/abs/2508.21210", "title": "自我监督的语音模型在语言习得过程中是否表现出关键期效应？", "title_en": "Do Self-Supervised Speech Models Exhibit the Critical Period Effects in Language Acquisition?", "authors": "Yurie Koga,Shunsuke Kando,Yusuke Miyao", "background": "尽管过去的工作已经使用文本语言模型研究了人类语言习得中的关键期（CP）效应，但这些效应在自我监督语音模型（S3Ms）中的表现尚未得到充分探索。CP效应指的是第二语言（L2）延迟暴露初见会增加习得难度，而第一语言（L1）延迟暴露结束会增强保留。这些研究对于理解口头语言在人类语言习得中的核心作用至关重要，因为口语是语言习得的基础。这篇论文尝试填补这一空白，通过训练S3Ms，并以儿童定向的语音进行评价，考察其对于语音辨别能力的表现，进一步评估S3Ms中的CP效应是否清晰即可辨认。", "innovation": "论文通过自监督语音模型（S3Ms）研究了人类语言习得中的关键期（CP）效应，这种研究方法在过去对文本语言模型的研究中较少涉及。这一方法的创新之处在于将现有的关于语言习得的研究扩展到语音模型中，填补了该领域的空白。研究结果表明，S3Ms在语音模仿方面并没有表现出明显的CP效应。特别是，延迟第二语言暴露初见的模型在处理第二语言时表现更好，而延迟第一语言暴露结束则会导致语言遗忘。", "conclusion": "研究发现，自我监督的语音模型在处理语音辨别任务时，并未表现出关键期效应，具体表现为延迟开始学习第二语言的模型在第二语言上表现较好，而提前结束第一语言的培训则会导致第一语言的遗忘。这表明语音模型可能并不像人们想象的那样受关键期效应的影响。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21422", "html_url": "https://arxiv.org/abs/2508.21422", "title": "自动评论者无法检测研究论文中的错误推理：一种新的反事实评估框架", "title_en": "Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework", "authors": "Nils Dycke,Iryna Gurevych", "background": "大语言模型（LLMs）在加速和辅助学术同行评审方面具有巨大潜力，正被越来越多地用作全自动评论生成器（ARGs）。然而，潜在的偏差和系统性错误可能会对科学的完整性和诚信构成重大风险；因此，了解最先进的ARGs的具体能力与局限性至关重要。我们集中于高质量同行评审的核心技巧——检测研究逻辑中的漏洞。这涉及评估论文结果、解释和断言之间的内部一致性。", "innovation": "我们提出了一种全自动的反事实评估框架，该框架在受控条件下分离和测试这种技能。我们测试了多种ARG方法后发现，与预期相反，研究逻辑中的缺陷对它们生成的评论输出没有显著影响。", "conclusion": "根据我们的发现，我们提出了三项对未来工作的行动建议，并公开释放了反事实数据集和评估框架。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：一种高效的自我一致性幻觉检测管道", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大型语言模型（LLMs）在研究和实际应用中表现出色，但在幻觉处理方面仍存在挑战。现有的幻觉检测方法在句子级生成上表现不佳，或者依赖于特定领域的知识。尽管自我一致性方法能够解决一些局限性，但由于需要重复生成而产生较高的计算成本。因此，本文旨在探究自我一致性方法中的冗余性，发现生成过程中存在共享前缀令牌，并观察到非精确答案令牌对语义内容的贡献甚微。", "innovation": "本文提出了一个名为解码记忆管道（DMP）的新颖加速生成框架。DMP通过选择性推理和退火解码，减少了冗余的生成步骤，同时保持了模型的通用性，即与模型、数据集、解码策略及自我一致性基线无关。这种方法不仅提高了多响应生成的效率，还具有扩展到对齐和推理任务的潜力。实验结果表明，该方法在AUROC性能不牺牲的情况下可实现3倍的速度提升。", "conclusion": "解码记忆管道（DMP）是一个有效的自我一致性幻觉检测管道，它通过选择性推理和退火解码加速生成过程，适用于各种模型、数据集、解码策略和自我一致性基线。该方法在保持高性能的同时显著加速了生成速度，为未来的研究奠定了基础并展现出广泛的应用前景。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT与DeepSeek系列模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在跨行业改变人工智能的发展，但其开发和部署仍然复杂。本文回顾了16个关键挑战，并通过两个具有独特方法的最新顶级模型（OpenAI的封闭源代码GPT-4o及DeepSeek-V3-0324，一款大型开源专家混合模型）探讨这些挑战的应对措施。", "innovation": "通过比较封闭源代码模型与开源模型之间的权衡（如安全性、可靠性与效率、适应性），并展示不同应用场景（从聊天机器人到医疗健康再到教育工具）的最佳模型属性，本文旨在为人工智能研究人员、开发者和决策者提供当前LLM能力和最佳实践的理解。", "conclusion": "本文旨在引导AI研究人员、开发者和决策者理解当前LLM的能力、局限性及最佳实践。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21436", "html_url": "https://arxiv.org/abs/2508.21436", "title": "通过解纠缠概念表示发现语义子维度", "title_en": "Discovering Semantic Subdimensions through Disentangled Conceptual Representations", "authors": "Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong", "background": "理解概念语义的核心维度对于揭示语言和大脑中意义的组织方式至关重要。现有的方法经常依赖预定义的语义维度，这些维度只能提供粗略的代表，未能注意到更细致的概念区别。", "innovation": "本文提出了一种新的框架，以研究粗略语义维度下的子维度。我们介绍了解纠缠连续语义表示模型（DCSRM），该模型将大型语言模型中的词嵌入分解成多个子嵌入，每个子嵌入编码特定的语义信息。通过这些子嵌入，我们确定了一组可解释的语义子维度。为了验证它们的神经可行性，我们应用体素水平的编码模型将这些子维度映射到大脑激活。", "conclusion": "进一步的分析表明，语义维度是根据不同的原则结构化的，极性是驱动将其分解为子维度的关键因素。所识别的子维度的神经相关性支持它们的认知和神经科学可行性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "小语言模型中激发创造性写作：LLM作为裁判与多代理精炼奖励之比较", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大型语言模型（LLMs）在创意写作方面展现了显著的能力，但其巨大的计算需求限制了它们的广泛应用。增强小型语言模型（SLMs）提供了一种有希望的替代方案，然而当前的方法如监督微调（SFT）难以产生新颖性，而人为反馈强化学习（RLHF）也存在成本问题。", "innovation": "本文探索了两种不同的基于人工智能反馈的奖励策略，一是使用一种经过多代理拒绝采样框架训练的偏好模型，二是利用一种基于原则的LLM作为裁判，其奖励功能通过对抗训练方案和反思机制优化。实验表明，虽然两种方法都显著提高了创意输出，但基于原则的LLM作为裁判的方法在生成质量上更为出色，还具有更高的训练效率和对人类标注数据的依赖减少等优点。", "conclusion": "这两种人工智能驱动的奖励策略在提高SLMs的创意生成方面均表现出色，尤其是第二种策略，在生成质量和训练效率方面均显示出明显优势。此外，该研究还证明了其自动化评价方法与人类评价在一致性上表现良好，并强调了该方法在开发更具创意的SLMs的前景，相关代码和数据已经公开。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次选择的异质组合方法构建假新闻检测", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏见，如确认偏见，使个体特别容易相信和传播社交媒体上的假新闻，这对公共卫生和政治领域产生了严重影响。基于机器学习的事实核查系统已被广泛研究以缓解这一问题。其中，集成方法特别有效，通过结合多个分类器来提高鲁棒性。然而，它们的表现高度依赖于组成分类器的多样性——选择真正多样化的模型仍然是一个关键挑战，尤其是当模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新的自动分类器选择方法，该方法优先考虑多样性和性能。方法首先计算分类器之间的成对多样性，然后使用层次聚类将它们组织到不同粒度级别的组中。HierarchySelect然后探索这些层次结构，为每个级别选择一个池的分类器，每个池代表一类特有的内池多样性。最多样化的池被识别并选择用于集成构建。选择过程结合了反映每个分类器性能的评估指标，以确保集成也具有良好的泛化能力。", "conclusion": "我们在六个人口统计学上不同的数据集中使用了40个不同的分类器进行实验。我们的方法与Elbow标准和最先进的基线进行了比较。结果表明，我们的方法在六个数据集中的两个上实现了最高的准确性。项目实现细节可在该项目的仓库中获取：this https URL。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk: 使用Transformer网络进行墨迹生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "在现有技术中，捕捉全局依赖性对于生成高质量的手写墨迹仍然是一个挑战。传统的生成模型往往难以在输入文本和生成的笔画点之间实现良好的对齐，导致生成的手写体难以读取或风格不一致。", "innovation": "本文提出了一种基于Transformer的模型TrInk，通过引入比例位置嵌入和平滑高斯记忆掩码来更好地促进输入文本与生成笔画点之间的对齐。此外，还设计了主观和客观评价管道来全面评估生成手写体的可读性和风格一致性。", "conclusion": "实验结果表明，与之前的方法相比，基于Transformer的模型在IAM-OnDB数据集上将字符错误率（CER）减少了35.56%，单词错误率（WER）减少了29.66%。作者还提供了一个演示页面，其中包括TrInk和基线模型的手写示例，见提供的链接。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21628", "html_url": "https://arxiv.org/abs/2508.21628", "title": "性格差异对多轮协作任务中LLM偏好影响的研究", "title_en": "Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks", "authors": "Sarfaroz Yunusov,Kaige Chen,Kazi Nishat Anwar,Ali Emami", "background": "随着大语言模型（LLMs）在日常工作中越来越普遍，用户通过多轮协作来制定结果。研究重点在于，具有不同性格特质的用户是否会对某些LLMs有系统性的偏好。", "innovation": "本研究通过将32名参与者均匀分布在四种凯斯里性格类型中，评估他们与GPT-4和Claude 3.5在四个协作任务中的互动，揭示了性格在偏好LLMs上的显著驱动作用。该研究采用了情感分析的定性反馈进一步确认了模式，并发现基于性格的分析揭示了LLM的差异，这是传统评估所未能发现的。", "conclusion": "研究结果表明，不同性格类型在不同任务上的偏好不同。例如，理性主义者在目标导向的任务中更偏好GPT-4，而理想主义者在创意和分析任务中更偏好Claude 3.5。总体的帮助评分相似，显示基于性格的分析揭示了LLM之间的差异，这是传统评估未能捕捉到的。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding 技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "本文介绍了QZhou-Embedding，这是一种基于Qwen2.5-7B-Instruct基础模型的通用上下文文本嵌入模型，具备卓越的文本表示能力。该模型采用了统一的多任务框架，包括专门的数据转换和训练策略，以便更好地处理各种文本训练数据集，并增强模型的学习效率。", "innovation": "1. 通过引入数据合成流水线，利用大语言模型API，采用重述、扩充和生成硬负例等技术，提升了训练集的语义丰富性和样本难度。\n2. 实施两阶段训练策略，首先进行预训练以提升检索性能，随后进行全面的微调，以扩展嵌入模型的功能。\n3. 研究结果表明，高质量、多样化的数据对于提升检索模型的表现至关重要，同时利用大语言模型的生成能力可以进一步优化嵌入模型的数据质量。", "conclusion": "我们在MTEB和CMTEB基准测试中取得了最先进的结果，排名首位，并在重排、聚类等任务上也达到了最先进的性能。证明了高质量、多样化的训练数据对于提升嵌入模型性能至关重要。模型权重在HuggingFace上提供了Apache 2.0许可协议下发布，并在GitHub上提供了评估代码和使用说明，以确保可重复性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21587", "html_url": "https://arxiv.org/abs/2508.21587", "title": "当前文本匿名化趋势与最新进展的综述", "title_en": "A Survey on Current Trends and Recent Advances in Text Anonymization", "authors": "Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa", "background": "各类领域中广泛存在的包含敏感个人数据的文本数据要求具备强大的匿名化技术来保护隐私并符合法规，同时确保数据能够用于多种关键下游任务。本综述旨在提供当前文本匿名化技术趋势和最新进展的全面概述，涵盖基础方法、大型语言模型的影响、特定领域的挑战及解决方案、高级方法、评估框架及实际部署工具等多方面内容，旨在总结现有知识，识别新兴趋势和持续存在的挑战，并为学术界和实践者未来的研究方向提供指导。", "innovation": "综述涵盖了当前文本匿名化技术的基础方法、大型语言模型的影响及其双重角色、特定领域内的挑战及解决方案、高级方法的使用以及评估框架和实际部署工具等内容。特别指出匿名化时隐私-实用性的权衡，需要应对准标识符的问题，并探讨大型语言模型能力的影响。", "conclusion": "综述总结了当前的匿名化技术知识，识别了新兴趋势和持续存在的挑战，如隐私-实用性的权衡、准标识符的应对以及大型语言模型能力的考量，并旨在为学术界和实践者提供未来研究方向的指导。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 印度马拉地语句子相似性数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "目前存在许多已经标注的人类句子相似性（STS）数据集，但是针对印度马拉地语的数据集相对较少。这使得研究人员在针对马拉地语的句子相似性任务上遇到数据稀缺问题。为此，该研究团队开发了MahaSTS数据集，并使用MahaSBERT-STS-v2模型优化了句子相似度评分，旨在改善低资源语言环境下的模型训练效果。", "innovation": "该研究主要创新点在于：1) 创建了MahaSTS数据集，该数据集包含16,860个马拉地语句子对，并通过六级评分桶均匀分布确保监督平衡；2) 使用MahaSBERT-STS-v2模型进行精细调优，用于回归式相似度评分；3) 通过实验展示了人类标注和目标精细调优在低资源设置中的重要性，提升了句子相似性任务的训练效果。这些创新有助于填补马拉地语在自然语言处理领域的数据缺口。", "conclusion": "该研究通过创建MahaSTS数据集并使用MahaSBERT-STS-v2模型，成功实现了马拉地语句子相似性任务的有效训练，并展现了人类标注、目标调优、结构化监督对于提升模型稳定性和性能的重要性。该数据集和模型开源发布，为后续研究提供了重要的资源支持。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21448", "html_url": "https://arxiv.org/abs/2508.21448", "title": "超越表面：探测大型语言模型的意识形态深度", "title_en": "Beyond the Surface: Probing the Ideological Depth of Large Language Models", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大型语言模型（LLMs）显示出了明显的倾向性，但这些倾向性的稳定性和深度尚不明确。表面的回答可以通过简单的提示工程进行操控，质疑它们是否反映了连贯的底层意识形态。本文探讨了LLMs中的‘意识形态深度’概念，定义为它们内部政治代表的稳定性和复杂性。我们采用双重方法：首先，我们使用指令提示和激活引导测量两种知名开源LLMs的‘可操控性’。发现虽然一些模型可以轻松在自由和保守观点之间切换，其他模型则表现出抵抗或增加拒绝的倾向，表明更深层次的意识形态结构。其次，我们使用稀疏自编码器（SAEs）探索这些模型的内部机制。初步分析表明，具有较低可操控性的模型具有更独特和抽象的意识形态特征。我们的评估显示，一个模型的政治特征比另一个相似大小的模型多出7.3倍。这导致在‘深度’模型中目标性地去除一个核心政治特征，导致其在相关议题上的推理实现一致的逻辑转变，而相同干预措施在‘浅度’模型中导致拒绝输出的增加。这些发现表明意识形态深度是LLMs的一种可测量属性，而可操控性是它们潜在的政治架构的宝贵窗口。", "innovation": "本文提出了‘意识形态深度’的概念，并通过指令提示和稀疏自编码器两种方法来测量大型语言模型的可操控性。发现较大的差异在模型之间的政治特征数量和其与用户意图互动的复杂性上。这些创新揭示了大型语言模型在政治表达上的更深层次结构，并提出了一种新的评估模型意识形态稳定性的方法。", "conclusion": "本文的研究表明，意识形态深度是可测量的属性，可操控性可以作为揭示大型语言模型潜在政治架构的窗口。大型语言模型在政治表达上的差异在不同程度上反映了模型内部意识形态的深度与结构，为后续研究提供了新的视角和方法。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "使用组相对策略优化的强化学习改进航空安全分析", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析航空事故背后的人为因素对于预防未来事故至关重要，但传统使用人类因素分析和分类系统（HFACS）的方法存在可扩展性和一致性上的限制。", "innovation": "提出了一种使用组相对策略优化（GRPO）强化学习自动HFACS分类框架，该框架通过微调Llama-3.1 8B语言模型来细化分析，引入了多组件奖励系统以适应航空安全分析，并集成合成数据生成以解决事故数据集中的类别不平衡问题。实验结果显示，该GRPO-优化模型在精确匹配准确性和部分匹配准确性方面都取得了显著的性能提升，且专门化的模型在关键指标上优于最先进的大语言模型（如GPT-5-mini和Gemini-2.5-fiash）。", "conclusion": "我们的研究证明，小型的、针对特定领域的模型能为关键的安全分析提供更有效的、计算效率更高的解决方案。这种方法使得在资源受限的边缘设备上实现强大的、低延迟的部署成为可能。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench：评估医疗多模态大型语言模型奖励模型和评判者的基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医疗应用中具有巨大潜力，包括疾病诊断和临床决策。这些任务需要高度准确、上下文敏感且专业对齐的响应，因此可靠的奖励模型和评判者至关重要。虽然这些因素很重要，但专门针对医疗场景的奖励模型（MRMs）和评判者仍然未被充分探索，目前没有专门的基准可以满足临床需求。现有的基准主要关注一般MLLM能力或模型作为解题者的表现，忽略了诊断准确性等重要评估维度。为填补这一空白，我们引入了Med-RewardBench，这是首个专门为评估MRMs和评判者设计的基准。Med-RewardBench包含了13个器官系统和8个临床部门的多模态数据集，有1,026个专家标注的案例，并通过严格三步流程确保在六个临床关键维度上的高质量评估数据。", "innovation": "提出Med-RewardBench，这是第一个专门为评估MRMs和评判者设计的基准，涵盖13个器官系统和8个临床部门，有1,026个专家标注的案例。通过严格的三步流程保证高质量的评估数据，涉及六个临床关键维度。评估了32个最新的MLLM，包括开源、专有和医疗专用的模型，揭示了对齐输出与专家判断的重大挑战。同时开发了基准模型，通过微调显示了显著性能提升。", "conclusion": "结果表明，现有的MLLM在与专家判断对齐方面面临重大挑战。通过Med-RewardBench，我们展示了基于基线模型的显著性能改进通过微调实现。这一基准填补了当前评估MRMs和评判者的空白，为该领域的研究提供了重要的参考。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17693", "html_url": "https://arxiv.org/abs/2508.17693", "title": "使用双大型语言模型自改进进行数据库规范化", "title_en": "Database Normalization via Dual-LLM Self-Refinement", "authors": "Eunjae Jo,Nakyung Lee,Gyuyeong Kim", "background": "数据库规范化对于保持数据完整性至关重要，但通常由数据工程师手工完成，耗时且容易出错。因此，需要一种自动化方法来解决这个问题，同时保持高准确性。", "innovation": "介绍了一种名为Miffie的数据库规范化框架，利用了大型语言模型的能力，实现了在无需人工干预的情况下进行数据自动规范化，同时保持了高质量。Miffie的核心是一个双模型自我改进架构，结合了最佳表现的模型生成和验证规范化模式，同时精心设计了特定任务的零样本提示以实现高准确性和成本效益。", "conclusion": "实验结果表明，Miffie能够在保持高准确性的前提下规范化复杂数据库模式。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21741", "html_url": "https://arxiv.org/abs/2508.21741", "title": "所有参数并非平等：智能隔离提升微调性能", "title_en": "Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance", "authors": "Yao Wang,Di Liang,Minlong Peng", "background": "监督微调（SFT）是将大型语言模型（LLMs）适应下游任务的关键方法；然而，这种微调过程常常受到‘跷跷板现象’的影响，即随机更新参数会在某些任务上取得进步，但在其他任务上却可能产生不利影响。为了应对这一挑战，本文提出了一种新的“核心参数隔离微调”（CPI-FT）框架。", "innovation": "1. 独立微调LLM以每个任务为基础，通过量化参数更新幅度来识别核心参数区域。\n2. 根据区域重叠将具有相似核心区域的任务进行分组，形成可以合并建模的任务簇。\n3. 提出一种参数融合技术：将每个任务单独微调后的核心参数直接移植到统一的骨干中，而来自不同任务的非核心参数通过球面线性插值（SLERP）平滑集成，以减少有害干扰。\n4. 使用混合任务数据进行轻量级流水线式SFT训练，并冻结先前任务的核心区域以防止灾难性遗忘。", "conclusion": "广泛实验表明，本文的方法显著减少了任务间的干扰和遗忘现象，在多个公开基准上始终优于单一任务和多阶段微调的基线方法。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR: 概率置信度选择与排名", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "通过生成多个候选解决方案并选择具有最高奖励的方案来提高大规模语言模型（LLMs）和大规模推理模型（LRMs）的准确性。在推理任务中，设计一个评分函数来识别正确的推理链是一个主要挑战，尤其是在没有地真相答案的情况下。", "innovation": "提出了一种名为Probabilistic Confidence Selection And Ranking (PiCSAR) 的简便方法，该方法无需训练就能通过推理和最终答案的联合对数似然来评分每个候选生成。这种方法使得推理自信度和答案自信度自然分解，显著提高了多样基准的表现，并在16/20的比较中至少比基线少使用2倍的样本。", "conclusion": "正确的推理链显示出显著更高的推理和答案自信度，这证明了PiCSAR方法的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "深度推理回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "AI研究人员和从业者越来越多地使用大型语言模型（LLMs）处理我们称之为推理密集型回归（RiR）的任务，即从文本中推断出细微的数字属性。与标准语言回归任务不同，如情感或相似度分析，RiR通常出现在类似于评分表评分或特定领域检索等临时问题中，这些问题需要对文本进行更深层次的分析，但只有有限的任务特定训练数据和计算能力可用。", "innovation": "本文提出了MENTAT，一种简单且轻量级的方法，结合了批处理反思提示优化与神经集成学习。MENTAT在两个基线之上实现了高达65%的改进，尽管仍有大量的未来研究空间有待探索RiR领域的问题。", "conclusion": "我们在三个现实问题上将RiR作为任务进行处理，以此建立了一个初始基准，发现提示冻结LLM和通过梯度下降微调Transformer编码器在RiR任务中往往难以应对。本文提出的MENTAT在RiR任务上取得了相当显著的成果，但仍指出RiR领域还有很大的进步空间。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这个图表在误导我吗？自动检测误导性图表", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性图表是社交媒体和网络上信息传播失实的关键驱动力。通过违反图表设计原则，这些图表扭曲数据，导致读者得出不准确的结论。先前的研究表明，无论是人类还是多模态大型语言模型（MLLMs）都经常被这种图表所欺骗。自动检测误导性图表并识别它们违反的具体设计规则可以帮助保护读者并减少信息失真的传播。然而，人工智能模型的训练和评估受限于缺乏大而多样的开放数据集。本文介绍了Misviz，一个包含2,604个标注有12种误导类型的真实世界图表基准数据集。为支持模型训练，作者还推出了Misviz-synth，一个基于真实数据的包含81,814图表的合成数据集。我们在两个数据集上使用最先进的MLLMs、基于规则的系统和微调分类器进行了全面评估。结果显示，该任务仍然极具挑战性。我们发布了Misviz、Misviz-synth及其配套代码。", "innovation": "本文创新地建立了Misviz基准数据集和Misviz-synth合成数据集。这些数据集为检测误导性图表提供了大规模、多样化的数据支持，有助于训练更有效的AI模型来识别和防御误导性图表的问题。", "conclusion": "尽管使用最先进的模型和方法，检测误导性图表的任务仍面临着巨大的挑战。文章通过发布Misviz和Misviz-synth提高了该领域公开可用的数据集，促进了相关技术的发展和应用。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "用细齿梳子审视Fine Web：Fine Web问题内容搜索和检索的索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大规模语言模型（LLMs）依赖于诸如Common Crawl等大规模网络数据集，提供了一些现代模型80%以上的训练数据。然而，无选择性的网络爬虫带来了一些挑战，包括数据质量、安全和伦理问题。尽管训练数据的质量至关重要，但之前的有害内容研究因计算限制大多仅限制在小样本上。该项目提出了一种使用基于ElasticSearch的管道对LLM训练数据集进行索引和分析的框架。我们将其应用于瑞士AI的FineWeb-2语料库（1.5TB，四种语言），实现了快速查询性能——大多数搜索在毫秒级别，所有查询均在2秒内。", "innovation": "提出了一种基于ElasticSearch的框架，用于对LLM训练数据集进行索引和分析，适用于大规模语料库，并且能够实现快速查询性能，支持实时数据集分析。", "conclusion": "该研究展示了对大规模语言模型训练数据集进行实时分析的能力，提供了实用的工具以使AI系统更加安全和负责任。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊的、符号的和情境性的：通过认知支撑增强大语言模型的教育", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究了建筑设计上的诱导偏见如何影响大型语言模型（LLMs）在指导性对话中的认知行为。该研究通过引入一种符号支撑机制和短期记忆模式来促进Socratic指导中的适应性、结构化推理。", "innovation": "提出了一种符号支撑机制与短期记忆模式相结合的方法，通过对照试验评估模型输出，采用由专家设计的评分标准来评估符号推理、响应性和会话记忆。通过基于LLM的评估框架，实现了可扩展和系统的比较，并揭示了去除记忆或符号结构对认知行为的影响。", "conclusion": "初步结果显示，完整系统在所有评估指标上都优于基准变体。分析表明，移除记忆或符号结构会削弱关键的认知行为，包括抽象、适应性探查和概念连续性。这些发现支持了一个处理层面的观点，即架构上的支撑可以可靠地引导LLMs中出现的教育策略。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "使用特征提取和聚类正常化SWIFT消息中对手方", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "简短文本聚类是文本分析领域的一个已知用例。自然语言技术适用于处理具有句子结构的文本内容，如Twitter帖子或即时消息。然而，对于没有固定结构的手工输入标签且在银行支付消息系统中常见的对手方实体，自然语言模型不太适用。这类对手方实体包括物理或法律实体细节，缺乏良好的句子结构，并且包含了手工输入引入的所有变异和噪音。这给调查员或反欺诈专业人士在增强对付款流程中发起人和受益人的了解以及追踪资金和资产方面带来了缺口。传统上，供应商试图通过模糊匹配工具来填补这个缺口。因此，本文提出了一种结合字符串相似度、主题建模、层次聚类和基于规则的管道来聚类银行支付消息中对手方的方法，该方法能够处理未知数量的预期簇。", "innovation": "本文提出了一种将字符串相似度、主题建模、层次聚类和基于规则的处理管道结合的方法来聚类SWIFT支付消息中的对手方。这种方法可处理未知数量的预期簇，并通过使用基于精确度和召回率的指标补充评估此方法的效果。通过实验证实，此方法在实际标签数据集上的性能显著优于基于关键词的基线方法。此外，此方法保留了基于规则系统的部分可解释性，并在上述基础上增加了聚类细化，从而减少了对人工审查的需求。当只需要调查部分人群（如制裁调查中）时，该方法可以更好地控制遗漏实体变异的风险。", "conclusion": "此方法通过使用特征提取和聚类显著提高了支付消息中对手方的准确性，并减少了对人工审查的需求。特别是在需要针对特定人群进行调查时，该方法能有效控制识别实体变异的风险。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "增强型量子自然语言生成：混合量子-经典架构的多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "本文对量子文本生成模型与传统的Transformer/MLP架构进行了全面评估，反映了对量子计算在自然语言处理中应用的兴趣日益增加。研究设计了多种模型进行对比实验，包括传统的Transformer、借鉴量子力学原理的QKSAN、量子RWKV（QRWKV）以及量子注意力序列架构（QASA），以及多个不同类型的文本数据集进行对比，旨在探索量子计算在自然语言生成中的潜在应用。", "innovation": "研究引入了多种量子启发式模型与传统Transformer/MLP进行对比，建立了混合量子-经典的模型框架。通过对多种不同类型的文本数据集的实验评估，揭示了传统Transformer模型在生成质量上的总体优势，同时展示了量子模型在特定应用场景中的竞争力。特别地，QKSAN在BLEU-1分数上与Transformer模型接近，且不重复，而QRWKV展示了完美的词汇多样性。", "conclusion": "尽管传统的Transformer模型在平均困惑度和BLEU-1分数上表现出色，量子模型在特定任务中的表现也相当有竞争力，特别是在词汇多样性和不重复性方面。这表明，利用量子计算技术可能为自然语言生成领域提供新的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21256", "html_url": "https://arxiv.org/abs/2508.21256", "title": "CrossTL: 具有统一中间表示的通用编程语言翻译器", "title_en": "CrossTL: A Universal Programming Language Translator with Unified Intermediate Representation", "authors": "Nripesh Niketan,Vaatsalya Shrivastva", "background": "传统方法需要为每对语言编写单独的翻译器，导致复杂性的指数增长。CrossTL通过一个统一的中间表示，简化了多语言之间的双向翻译，支持CUDA、HIP、Metal等多种编程语言，解决了传统方法的缺点。", "innovation": "CrossTL引入了一个单一的通用中间表示来简化跨语言翻译，设计了一个新的模块化架构，支持多种编程领域，包括GPU计算、图形编程和系统语言，并通过具体的实现证明了统一代码翻译的实用性。", "conclusion": "CrossTL在不同编程领域中展示了其有效性，通过统一的中间表示设计，使得添加新语言变得容易，仅需相应的前端和后端组件。这项工作代表了语言无关编程的重要步骤，使开发者能够一次编写，随处部署。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21209", "html_url": "https://arxiv.org/abs/2508.21209", "title": "为孩子们设计更聪明的对话代理：基于认知任务和目标-手段分析的教训", "title_en": "Designing Smarter Conversational Agents for Kids: Lessons from Cognitive Work and Means-Ends Analyses", "authors": "Vanessa Figueiredo", "background": "本文研究了9至11岁巴西儿童如何使用对话代理（CAs）进行学习、探索和娱乐，以及结构化支架如何增强这些互动。研究通过跨学科的方法进行，包括面向认知的任务分析和目标-手段分析，以揭示儿童的信息处理流程、更知识丰富的其他人的角色、功能使用、情境目标和互动模式，从而为对话树的设计提供指导。研究结果为基于语言模型的支架提供了理论和实证支持。", "innovation": "本文提出了利用GPT-4o-mini对23名儿童的模拟CA互动进行研究，探讨了基于结构化提示的对话树与无结构基准相比的优势。研究通过定量评估可读性、问题数量/深度/多样性以及连贯性，发现结构化提示方法的效果更好。根据研究结果，提出了一系列设计建议，包括基于语言模型的支架式对话树、为儿童专门配置的配置文件以实现个性化背景，以及由照顾者定制的内容。这些贡献包括首次在巴西儿童中应用CWA、采用孩子-CA信息流动的实证框架，以及一种基于结构化提示的有效、支架化学习的“食谱”。", "conclusion": "本文为对话代理在儿童教育和娱乐中的应用提供了新的设计框架和理论依据，特别强调了基于认知的工作分析和目标-手段分析方法的重要性，以及如何通过结构化支架提高儿童学习的效率和质量。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "Morae: Proactively Pausing UI Agents for User Choices", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "现有的用户界面（UI）代理通常直接执行任务而不需要用户参与关键选择或提供重要的上下文信息，这限制了用户的主动权。例如，在一项实地研究中，一名视力障碍用户要求购买最便宜的汽水，但代理在未提到其他不同口味或评级更高的替代品的情况下，自动选择了多个价格相同的产品中的一种。", "innovation": "论文介绍了一种名为Morae的UI代理，它能够在任务执行过程中自动识别决策点，并暂停让用户做出选择。Morae使用大规模的多模态模型来解析用户查询并结合用户界面代码和截图，当有选择需要做时还会提示用户提供澄清。这项研究显示，与基础代理（包括OpenAI Operator）相比，采用Morae的BLV用户能够完成更多的任务，并选择更符合他们偏好的选项。", "conclusion": "这项工作展示了一种混合主动性方法，用户能够在享受UI代理自动化带来的便利的同时，还能表达自己的偏好。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "模型-任务对齐决定不同的RL结果", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "近年来，将强化学习（RL）应用于大型语言模型（LLMs）取得了显著进展。尽管如此，在LLMs中观察到的一些现象却表现出通常在传统RL设置中不会出现的模式，例如单一训练样本可以达到整个数据集的性能，无需非常精确的奖励信号，以及仅使用负面样本即可达到或超越基于奖励的复杂方法。然而，这些观察结果在哪些条件下有效以及在哪些条件下失效仍不清楚。", "innovation": "本文识别出一个关键因素，即RL观察结果的差异性：预训练模型是否已经表现出强大的模型-任务对齐，这通过在评估任务上的pass@k准确度进行衡量。通过系统和全面地验证一系列反直觉的主张，并在不同模型架构和任务领域进行严格的实验验证，找到在哪些情况下标准RL训练保持一致的稳健性，而许多反直觉的结果仅在模型和任务已经表现出强大的模型-任务对齐时才出现。相比之下，在更具挑战性的环境中，这些技术无法驱动显著的学习，而标准RL方法仍然有效。", "conclusion": "研究发现，标准RL训练在不同场景中保持一致的稳健性，然而许多反直觉的现象只在模型和任务已经表现出强大的模型-任务对齐时才出现。在更具挑战性的环境里，这些技术不能有效驱动学习，而标准RL方法依然有效。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "公平之路：连接组公平与个体公平", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统中的公平性通常分为组公平性和个体公平性。然而，现有文献并未建立这两类公平性之间的科学关系，因为对这两种公平性的研究采用了不同的评估指标或目标，导致无法进行公正的比较。因此，当前并不清楚提高一种公平性是否会受到另一种公平性的影响。", "innovation": "本文通过全面比较适用于两种公平性的评估指标，研究了组公平性和个体公平性之间的关系。实验结果表明，被认为对群体非常公平的推荐可能对个体来说是不公平的。这项发现为推荐系统从业者改进系统的公平性提供了新的见解。", "conclusion": "研究结果表明，高群体公平性的推荐系统可能对个体来说是不公平的。这一发现对于希望改进其系统公平性的推荐系统从业者来说具有重要意义。相关代码可在本链接获取：this https URL。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21452", "html_url": "https://arxiv.org/abs/2508.21452", "title": "从经典到复杂：大型语言模型在本科热力学领域能力评估", "title_en": "From Canonical to Complex: Benchmarking LLM Capabilities in Undergraduate Thermodynamics", "authors": "Anna Geißler,Luca-Sophie Bien,Friedrich Schöppler,Tobias Hertel", "background": "大型语言模型（LLMs）在科学教育中被认为是一种辅导辅助工具，但它们在本科教学中的自主应用准备情况仍有待确定。可靠的教学不仅需要流利的回忆，还需要一致且基于原理的推理。热力学因其紧凑的定律和状态与路径函数之间的微妙区别、可逆性和熵等特性，提供了一个理想的测试平台来评估这些能力。", "innovation": "本文提出了一个50项本科热力学问答基准——UTQA，涵盖了理想气体过程、可逆性和图表解释。在评估了包括通识领先的2025年模型在内的多个LLM后，发现目前的LLM在掌握该领域所需能力方面存在明显差距，尤其是在有限速率/不可逆场景和将视觉特征与热力学意义绑定方面表现不佳。", "conclusion": "现有的大型语言模型尚不适合独立用于热力学领域的不监督教学，这表明需要改进这些模型以支持基于原理的飞行推理论证。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受还是拒绝？使用表到文本序列化方法评估贷款审批中LLM的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "随着大型语言模型（LLMs）在高风险决策任务中的应用越来越广泛，例如贷款审批，它们在跨领域应用时面临着处理表格数据的挑战，同时确保公平性和实现可靠预测也变得尤为重要。", "innovation": "本文评估了在来自三个不同地区的贷款审批数据集上，大型语言模型的表现和公平性。实验重点考察了零样本学习（zero-shot）和上下文指引学习（in-context learning，ICL）能力，并发现不同的序列化格式对模型表现和公平性有显著影响。", "conclusion": "我们的研究强调了有效的表数据表示方法和公平意识模型对于提高在金融决策中LLM可靠性的关键作用。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM: 一种全面的音频语言模型评估", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "当前音频语言模型（ALMs）的评估受到标准化基准缺乏的阻碍，大多数基准只能测量模型的单一或两个能力，且忽略了公平性或安全性等评价方面。此外，模型间的比较难以进行，因为不同的评估针对有限数量的模型使用不同的提示方法和推理参数。", "innovation": "本文引入了AHELM基准，该基准汇集了多种数据集，包括两个新的合成音频文本数据集PARADE和CoRe-Bench，以全面衡量ALMs在10个重要方面的性能：音频感知、知识、推理、情绪检测、偏见、公平性、多语言能力、稳健性、毒性、和安全性。AHELM还标准化了提示、推理参数和评估指标，以确保模型间的公平比较。14个开源和封闭API的ALMs以及3个附加基础系统的评估结果显示，尽管Gemini 2.5 Pro在5个领域排名最高，但它在ASR任务中表现出组不公平（$p=0.01$），而大多数其他模型没有明显差距。基础系统在AHELM中的表现相当不错，其中一个系统排名第五，尽管它只有语音到文本的能力。", "conclusion": "AHELM旨在作为活基准，将随着时间的推移不断添加新的数据集和模型。评估包含的所有原始提示、模型生成和输出均可在网站上查看：this https URL。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo：基于模型的动态数据优化框架以增强大型语言模型微调", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）依赖于高质量的训练数据。现有数据选择和数据合成的策略面临静态数据集管理的局限性，难以适应模型能力的演变。现有方法往往在数据选择和合成方面存在不足。", "innovation": "引入了Middo，这是一种自我进化模型感知动态数据优化框架，使用模型感知的数据选择和语义保持的数据精炼。该框架建立了一个闭环优化系统：（1）自参照诊断模块通过三轴模型信号——损失模式（复杂性）、嵌入簇动力学（多样性）、自我对齐评分（质量）主动识别亚优样本；（2）自适应优化引擎将亚优样本转化为有教学价值的训练点，同时保留语义完整性；（3）这个优化过程通过动态学习原则不断进化，适应模型能力的变化。实验结果表明，该方法能够持续提高种子数据质量，并在提升7.15%的准确率同时保持原数据集规模，从而建立了通过数据和模型的人工智能协同进化新范式。", "conclusion": "本研究通过动态的人工智能协同进化的数据和模型，确立了一种新的大型语言模型训练范式，展示了改进的性能和可持续的数据管理策略。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "动态可控文本生成的连续语言模型插值", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "随着大型语言模型（LLMs）在各种应用场景中 popularity 日增，使其具有适应性和可控性变得越来越重要，尤其是对于用户导向的应用。现有的 LLM 调适研究主要集中在寻找一个或多个模型以优化单一预定义的目标上，而本文关注更为复杂的任务，即模型必须根据多变的用户偏好动态调整。", "innovation": "本文引入了一种连续多领域插值方法，通过线性权重插值，生成具有特定生成特性的模型，实现了对模型输出的实时可控。具体做法是通过低秩更新 fine-tune 基础模型，并生成一系列具有不同生成特性的锚模型，之后利用这些锚模型的权重更新参数化整个插值模型的类。实验结果表明，通过调整插值权重可以实现对模型输出的可预测且一致的变化。", "conclusion": "我们的结果表明，以线性方式插值调优后的模型权重可以实现对多个风格特征的可预测且精细的控制。此外，研究还识别并讨论了具有较高关联度的属性对，表明此类插值方法对调控这些属性是有效的。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "基于汇总-举例-反思的数据驱动见解蒸馏赋能LLMs进行少量样本表格分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "近期的研究表明，大型语言模型（LLMs）在少量样本表格分类方面具有潜力，但结构化数据的差异性也带来了挑战。为应对这一问题，本文通过将数据转换为可操作的见解，致力于使LLMs能够稳健有效地进行分类。借鉴人类学习过程，本文提出了以分而治之、先易后难和反思学习原则为指导的InsightTab框架。该方法通过LLMs与数据建模技术的深度协作，集成规则总结、策略性示例展示和见解反思，使LLMs能够更好地将其普遍知识和能力与特定表格任务的具体需求对齐。", "innovation": "本文提出了一种创新的InsightTab框架，用于从数据中提炼可操作的见解，该框架基于分而治之、先易后难和反思学习的原则。该框架通过LLMs与数据建模技术的深度协作，结合规则总结、策略性示例展示和见解反思，使LLMs能够在少量样本表格分类任务中发挥更好的作用。此外，该方法通过大量的实验证明优于最先进的方法，并通过消融研究验证了指导性的见解蒸馏过程的有效性，以及InsightTab在利用标记数据和管理偏差方面的优势。", "conclusion": "通过广泛评估InsightTab在九个数据集上的性能，结果显示其在少量样本表格分类任务中表现出了一致的改进。进一步的消融研究证明了指导性见解蒸馏过程的有效性，分析强调了InsightTab在利用标记数据和管理偏差方面的优势。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.24155", "html_url": "https://arxiv.org/abs/2410.24155", "title": "Thought Space Explorer在大型语言模型推理中的盲点导航", "title_en": "Blind Spot Navigation in Large Language Model Reasoning with Thought Space Explorer", "authors": "Jinghan Zhang,Fengran Mo,Tharindu Cyril Weerasooriya,Yeyang Zhou,Xinyue Ye,Dongjie Wang,Yanjie Fu,Kunpeng Liu", "background": "最近，大型语言模型（LLMs）的进展展示了它们在处理复杂推理任务方面的潜力，通常通过构建思维链条来指导模型进行多步骤思考。然而，现有的方法往往局限于已探索的解决方案空间，忽视了LLM认知范围内的重要盲点。", "innovation": "本文提出了一种名为``Thought Space Explorer''(TSE)的新框架，旨在扩展和优化思维结构，引导LLMs探索其认知范围内的盲点。通过基于原始思维结构生成新的推理步骤和分支，采用多种策略来扩大思维探索的视角，减轻盲点对LLM推理的影响。", "conclusion": "在多个推理任务层次上的实验结果表明，TSE的有效性超过了各种基线方法。此外，进行了广泛分析，以理解结构化和扩展思维如何有助于释放LLM推理能力的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "在大型语言模型中揭示细微的价值观和观点", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "通过挖掘大型语言模型（LLMs）中隐含的价值观和观点，可以帮助识别潜在偏见并减轻可能的危害。近期，这主要是通过向LLMs提出调查问卷问题并量化其对于道德和政治敏感语句的态度来实现的。然而，这种态度的生成会因不同的提示方式而有很大变化，并且对于同一立场存在许多截然不同的理由。本文的研究背景是为了解决这个问题，通过分析6种LLM对政治定向测试（PCT）中62个命题的156k回应，其中使用了420种不同的提示版本。", "innovation": "本文创新点在于进行粗粒度分析生成的态度，以及对细微文本理由的细粒度分析。提出了识别回应中的母题（trope）的概念，即在不同提示中反复出现且一致的语义相似短语，揭示了特定LLM倾向产生的自然模式。进一步研究发现，提示中的人口统计特征显著影响PCT的结果，反映了偏见并显示了封闭形式与开放领域测试结果之间的差异。", "conclusion": "通过对照PCT中的表现来研究回应中的母题，发现即使对于态度相反的模型和提示，类似的理由也在模型之间反复生成。这项研究强调了在使用LLMs时需考虑提示的多样性及其对结果的影响，并提出了针对LLMs的偏见检测和缓解方法。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么止步于单词？通过行级OCR揭示更大图像", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术在识别之前先将每个字符进行分割，这使得它们在字符分割上容易出错，并且无法利用语言模型中的上下文信息。近年来，序列到序列（Seq2Seq）翻译技术的进步促使现代方法首先检测单词，然后每次输入一个单词到模型中，直接输出完整的单词作为字符序列，这使得更好地利用语言模型并跳过字符分割这一步骤。然而，这种转变导致的瓶颈现在转移到了单词分割的准确性上。因此，本文提出了从单词级别的OCR过渡到行级别的OCR的自然和逻辑进展，以避免单词检测中的错误，并提供更大的句子上下文，更好地利用语言模型。尽管进行了彻底的文献调查，但没有找到公开的用于训练和基准测试这种从单词到行级OCR的方法的数据集。因此，作者还提供了一个由251张英语页面图像组成的精心整理的数据集，具有行级别的注释。实验结果表明，该方法不仅提高了端到端的准确性，还提高了效率。还表明，与基于单词的管道相比，效率提高了4倍。随着大型语言模型的不断进步，该方法还有利用这些进步的潜力。", "innovation": "提出了一种从单词级别的OCR过渡到行级别的OCR的新方法，这种方法通过跳过单词检测错误并提供更大的句子上下文来提高OCR的准确性与效率。此外，作者还提供了一个精心整理的251页英文页面图像数据集，用于训练和基准测试行级OCR方法。", "conclusion": "通过行级OCR方法，实现了5.4%的端到端准确性改进，并且相比基于单词的方法提升了4倍的效率。这种方法为进一步利用大型语言模型的进步打开了新的可能性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "毒性导致毒性：政治播客中的对话链条剖析", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "学术界和行业专业人士对于数字通信中的有毒行为持续关注。尽管已有很多研究探讨了社交媒体和讨论板上的毒性问题，但播客尽管其流行度快速上升，但在这一领域仍相对被忽视。这项研究旨在通过收集和分析政治播客的转录文本，特别关注对话结构，深入了解毒性如何通过一系列回复在网络对话中显现和加剧，揭示有害语言如何在对话轮次中蔓延的有机模式。", "innovation": "本研究通过收集政治播客的文本数据并分析对话结构，填补了毒性能如何在网络对话中通过一系列回复显现和加剧的研究空白，揭示了有害语言如何在网络对话中蔓延的有机模式。这项工作是关于播客中毒性研究的一个创新尝试，为研究者和行业专业人士提供了新的视角和分析工具。", "conclusion": "研究结果表明，有毒行为可以通过一系列对话中的回复传播和升级，显示出有害语言在网络对话中的潜在危险。研究揭示了有毒对话的模式，并提出了进一步研究的建议，以便更好地理解并管理互联网上的有毒行为。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06679", "html_url": "https://arxiv.org/abs/2409.06679", "title": "E2LLM：扩展式大型语言模型以促进长上下文理解和推断", "title_en": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "authors": "Zihan Liao,Jun Wang,Hang Yu,Lingxiao Wei,Jianguo Li,Jun Wang,Wei Zhang", "background": "大型语言模型（LLMs）在多轮对话、代码生成和文档总结等任务中处理长上下文的能力变得越来越重要。然而，实现长上下文的高性能、低计算复杂度以及与预训练模型的兼容性这三者（称为“不可能三角”）是对现有模型的一个挑战。", "innovation": "本文介绍了一种名为E2LLM（Extended Encoder Large Language Models）的新方法，有效解决了上述问题。E2LLM将长上下文划分为多个片段，利用预训练文本编码器将每个片段压缩为软提示，并通过适配器将这些表示与解码器大型语言模型对齐。为了增强LLM在这些软提示下的推理能力，我们引入了两个训练目标：编码器输出重建和长上下文指令微调。", "conclusion": "广泛的实验结果显示，E2LLM不仅在文档摘要和问答等任务上优于8个最先进的方法，在效能和效率上占优势，而且在规模相近的模型中，E2LLM在LongBench v2上达到了最佳性能。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用未结构化知识的检索增强机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "以往在机器翻译（MT）领域，研究通常依赖已配对的MT语料库中的上下文示例或知识图谱中的领域知识来增强MT模型。然而，大量的世界知识是以未结构化的文档形式组织的，且在不同的语言中并未完全配对。本文探讨了如何利用这些未结构化的文档来增强MT。", "innovation": "本文提出了RAGtrans，这是首个用于训练和评估LLM检索增强MT能力的基准数据集。RAGtrans包含通过GPT-4o和人工翻译收集的169K MT样本，同时提供了来自多种语言的文档以供这些样本使用。基于RAGtrans，提出了一个利用多语言文档信息进行翻译的多任务训练方法，该方法利用现有的多语言语料库创建辅助训练目标，而不增加额外的标记要求。实验结果表明，该方法在En-Zh和En-De任务中分别提高了1.6-3.1 BLEU和1.0-2.0 COMET分数，以及1.7-2.9 BLEU和2.1-2.7 COMET分数。", "conclusion": "当前的LLM在使用未结构化知识进行翻译时面临一系列挑战。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于注释分歧度形式化估计的协作内容审核框架：用于毒性检测", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "当前的内容审核系统通常结合了人类审核员和机器学习模型，但在实际操作中，往往会出现审核员对于内容是否具有攻击性或不适性表现出显著的分歧，反映了此类内容的主观特性。这些分歧通常被忽视或视为噪声。研究者提出了一个新的视角，认为这些分歧是宝贵的信号，揭示了内容的内在模糊性。本文探讨了这些分歧的重要性，并提出了一种新的内容审核框架，旨在捕捉标记分歧。通过多任务学习，毒性分类被用作主要任务，而标记分歧则被作为辅助任务来解决。此外，还利用了不确定性估计技术，特别是形式化预测，来衡量标签的不确定性和模型本身的不确定性。这一体系还允许审核员调整标记分歧的阈值，从而增加调整审核过程灵活性的可能性。", "innovation": "本文的创新之处在于提出了一种新的协作内容审核框架，它通过多任务学习和形式化预测技术来解决标记分歧的问题，从而提高模型性能、校准和不确定性估计，并提供在单任务方法中没有的参数效率和审核过程改进。", "conclusion": "这一框架通过多任务学习和不确定性估计技术的结合，增强了模型的性能、校准和不确定性估计，并提高了审核过程的灵活性，相比于单任务方法，它在处理标记分歧时表现得更有效。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "近年来，深度推理大语言模型（例如，OpenAI的o1和DeepSeek-R1）在各种下游任务中展现出令人鼓舞的性能。自动自由翻译是多语言世界中的一个重要而有趣的任务，需要超越逐词翻译。然而，在深度推理大语言模型中，该任务尚未得到充分探索。", "innovation": "提出了DeepTrans，这是一种通过强化学习（RL）学习自由翻译的深度推理翻译模型。通过构建评估翻译结果和思维过程的奖励模型，DeepTrans学会了如何思考并自由翻译给定的句子。此外，研究中使用了Qwen2.5-7B作为骨干模型，DeepTrans在文献翻译中的性能提高了16.3%，并且优于强大的深度推理大语言模型。", "conclusion": "通过使用奖励模型在强化学习中的训练，DeepTrans提高了自动自由翻译的翻译质量和流畅性，同时避免了需要大量人工注释或对数据进行密集合成的过程。实验结果证明了DeepTrans的有效性，并且希望这项工作能够启发其他研究人员对自由翻译的研究。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14728", "html_url": "https://arxiv.org/abs/2503.14728", "title": "记忆编码中的战略资源分配：塑造语言处理的效率原则", "title_en": "Strategic resource allocation in memory encoding: An efficiency principle shaping language processing", "authors": "Weijie Xu,Richard Futrell", "background": "该研究探讨了工作记忆有限容量如何高效支持人类语言行为。以往的研究指出，工作记忆在处理句子时存在有限的容量和噪音表示，提出了记忆编码中的资源分配策略。本研究从资源理性的角度出发，分析了动态和策略性的资源分配原则，以优先处理新颖和意外的信息，解决工作记忆容量限制和表示噪声带来的计算问题。", "innovation": "提出了战略资源分配（SRA）作为工作记忆编码中的效率原则。SRA的核心在于将资源动态分配以优先编码新颖和意外的信息，这在跨语言的实证数据中得到了支持，特别是在依赖就近性方面。研究还揭示了SRA作为认知加工效率原则在不同语言中的变异性，强调了表征不确定性在记忆编码理解中的关键作用，并从有效记忆编码的角度重新审视了意外性和熵对加工难度的影响。", "conclusion": "研究发现，意外输入被更精确地编码，因此对记忆衰退和干扰的抵抗力更强。然而，跨语言数据也表明，SRA需要与特定语言的短语结构相适应。这凸显了SRA在语言处理中的重要作用，并且为理解记忆编码提供了一个新的视角。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "通过期望最大化方法的可解释的汉字符记忆生成", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "对于来自罗马字母背景的学习者来说，学习日语词汇是个挑战，因为日语的书写系统与罗马字母系统不同。日语结合了假名（如平假名）和汉字，后者是源自中国的意符文字，且非常复杂。关键词记忆法是常用的学习策略，通常利用汉字的构成结构来形成鲜明的关联。尽管最近有使用大规模语言模型（LLMs）来辅助学习者的方法，但现有的基于LLMs的关键词生成方法缺乏透明性，即仍是黑盒操作。", "innovation": "本文提出了一种生成框架，该框架明确地将记忆构建过程建模为由一组通用规则驱动，并通过一种全新的期望最大化类型算法学习这些规则。该方法基于一个在线平台上的学习者自编记忆法进行训练，能够学习潜在结构和组合规则，从而实现可解释和系统性的记忆生成。实验表明，在新学习者中，该方法在冷启动情况下表现良好，同时揭示了有效记忆创建背后的机制。", "conclusion": "该方法不仅在新学习者的冷启动条件下表现良好，还能够解释其生成记忆的方式，对理解有效记忆创建机制提供了有价值的见解。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.06821", "html_url": "https://arxiv.org/abs/2504.06821", "title": "编程技能的诱导用于代理任务", "title_en": "Inducing Programmatic Skills for Agentic Tasks", "authors": "Zora Zhiruo Wang,Apurva Gandhi,Graham Neubig,Daniel Fried", "background": "为了成功执行诸如网页导航等常见的数字任务，代理需要执行各种专业化任务，如搜索产品或规划旅行路线。通过与网络环境互动学习特定的任务技能，代理可以自我提升。已有研究表明，程序可以作为技能的有效表示形式。本文通过评估在一个名为WebArena的代理基准测试上，利用代理技能诱导（ASI）来展示程序化技能的有效性。AS弹能够在线诱导验证和利用基于程序的技能，特别是在诱导阶段提供了程序化的验证保证，在成功率上提升了23.5%，并且通过将基础动作组合成高级技能，减少了10.7-15.3%的步骤，提高了效率。文章还验证了AS弹在大规模网络活动中的持续高效性和准确性，并测试了诱导技能在不同网站间的通用性与适应性更新能力。", "innovation": "提出了代理技能诱导(ASI)方法，使代理能够在交互过程中通过从基础动作到高级技能（如搜索产品）的转换来学习和应用程序化的技能。ASI利用程序化的验证方法确保技能的正确性，并展示了在任务成功率和效率上的改进。此外，ASI还在不同网站间的迁移应用中展示了良好的通用性和适应性更新能力。", "conclusion": "研究表明，基于程序的代理技能诱导方法（ASI）在成功率和效率上明显优于静态基线代理及其基于文本技能的版本，同时展示了其在大规模网络操作中的持续高效性和准确性，并且能够有效应对不同网站间的技能迁移问题。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning: LLM多组件问题推理与增强知识边界意识", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "LLMs在各种应用中的广泛应用使得它们生成非存在的事实（hallucination）成为一个重要的问题。先前的研究通过分析内部参数化的知识边界来估计置信度，但这些研究主要集中在单问题设置上，而没有探索更复杂、更具有挑战性的多问题设置，即能够同时准确回答多个问题的需求。", "innovation": "我们引入了一种新的方法MAC-Tuning，用于多问题设置。该方法在指令数据的微调过程中分离了答案预测和置信度估计的学习过程。实验结果表明，我们的方法在平均查准率上比基线方法高出至多25%。MAC-Tuning方法提高了解决多组件问题推理性能，特别是增强了对知识边界意识的利用。", "conclusion": "实验结果表明，MAC-Tuning方法相比于基线方法在多问题设置下能显著提升模型的查准率，达到了25%的提升，证明了在多组件问题推理中的有效性和创新之处。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17052", "html_url": "https://arxiv.org/abs/2504.17052", "title": "测试信念：一种评估LLM政治稳定性的论辩框架", "title_en": "Testing Conviction: An Argumentative Framework for Measuring LLM Political Stability", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大型语言模型（LLMs）在政治话语中日益发挥重要作用，但在受到挑战时会表现出不一致的回应。现有研究通过单个提示响应将LLMs归为左倾或右倾，但未能区分真实的意识形态对齐和表象性的文本生成。这种分类方法的有效性和稳定性存在疑问。", "innovation": "本文提出了一种框架，通过（1）论辩一致性以及（2）不确定性量化来评估意识形态深度。对12种LLMs在《政治极坐标测试》中的19项经济政策进行测试，将响应分类为稳定的或表象性的意识形态定位。结果显示，95%的左倾模型和89%的右倾模型表现出与分类一致的行为，且语义熵强烈验证了这一分类的有效性。", "conclusion": "研究发现，意识形态稳定性与话题相关，挑战了统一的LLM意识形态观念，并提供了一种区分真实对齐和表象行为的有效方法。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越Token层面量化LLM公平性：语义与统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）在生成响应时往往包含内在偏差，这损害了它们在实际应用中的可靠性。现有的评估方法经常忽视长格式响应中的偏差以及LLM输出的内在变异性。现有工作主要集中在情感或token级别的比较，缺乏对深层语义差异的检测能力，无法有效识别细微的偏差。", "innovation": "本文提出FiSCo（Fine-grained Semantic Comparison），一种新的统计框架，用于通过检测不同人群间反驳陈述的微妙语义差异来评估LLM群体层面的公平性。与先前工作相比，FiSCo在语义层面进行比较，利用蕴含检查评估响应间的意义一致性。该方法将模型输出分解为语义上不同的主张，并通过统计假设检验比较组内和组间的相似性，从而实现对细微偏差的稳健检测。提出了一种新的群体事实性公平性定义，并在合成和人类标注数据集上进行了验证，覆盖性别、种族和年龄等方面。实验结果显示，FiSCo能更可靠地识别细微偏差，减少随机化对LLM变异性的负面影响，优于各种评价指标。", "conclusion": "本文提出了一种名为FiSCo的新框架，通过语义层面的分解和统计假设检验，有效检测了长格式响应中的细微偏差，比现有方法更可靠地评价LLM群体层面的公平性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions：使用CoTR提示和大型语言模型的合成标注的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "在资源稀缺的语言（如马拉地语）中进行情感识别仍具挑战性，因为可获取的标注数据有限。现有研究通常难以提供高质量的数据集，特别是在低资源语种上的情感识别任务中。因此，建立高质量的数据集和采用创新的方法来标注这类数据集显得尤为重要。", "innovation": "本文提出了一种名为L3Cube-MahaEmotions的高质量马拉地语情感识别数据集，包含11个细粒度的情感标签。数据集的训练数据通过大型语言模型（LLMs）进行合成标注，而验证和测试集则通过人工标注来确保高可靠性。研究还首次采用Chain-of-Translation（CoTR）提示技术来标注马拉地语句子，这一方法有效地利用了大型语言模型进行情感标注。最终选择了GPT-4进行训练数据标注，因为它能够产生更好的标签质量。此外，研究还探讨了标记聚合策略，并发现通用的大型语言模型，如GPT-4和Llama3-405B，在复杂的情感识别任务中表现更佳，而基于BERT的模型即使使用合成数据集也未能超越GPT-4。", "conclusion": "本文构建了一个高质量的马拉地语情感识别数据集，并通过大型语言模型的合成标注技术以及CoTR方法来进行标注，从而有效提升了情感识别的性能。研究结果表明，高质量的人工标注数据和高层次的模型对于低资源语言的情感识别任务至关重要。此外，通用大型语言模型在复杂的情感识别任务中表现更好，这为未来的相关研究提供了新的启示，并强调了方法创新的重要性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA: 一种用于大规模语言模型的安全、高效和自适应联邦分割框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "由于私人数据质量高，有潜力增强LLM（大语言模型）的表现，然而这些数据分散在不同的数据孤岛中，且LLM的巨大计算需求限制了它们在联邦环境中的部署。针对这一挑战，提出了基于Transformer的联邦分割模型，将大多数模型参数卸载到服务器或分布式客户端上，仅在客户端保持少量部分以确保数据隐私。尽管如此，这些模型仍面临以下三大挑战：1）点对点密钥加密难以有效保护传递的向量；2）LLM的自回归特性导致联邦分割学习只能按序进行训练和推理，这导致了高通信开销；3）固定的分割点缺乏对下游任务的适应性。", "innovation": "本文提出了一种基于LLaMA2的FedSEA-LLaMA框架，通过以下新技术解决了上述挑战：1）在前向传递隐藏状态中注入高斯噪声，以实现端到端向量的安全传输；2）使用注意力掩码压缩和KV缓存协作来降低通信成本，加速训练和推理；3）允许用户根据特定任务需求动态调整输入/输出块的分割点。", "conclusion": "FedSEA-LLaMA框架在自然语言理解、摘要和对话型QA任务中保持了与集中式LLaMA2相当的性能，并实现了高达8倍的训练和推理速度提升。此外，对隐私攻击和不同分割点的进一步分析也表明，FedSEA-LLaMA在安全性和适应性方面具有显著效果。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17464", "html_url": "https://arxiv.org/abs/2505.17464", "title": "Hydra: 结构化跨源增强的大语言模型推理", "title_en": "Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning", "authors": "Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang", "background": "当前的混合Retrieval-Augmented Generation (RAG) 系统通过从知识图谱（KGs）和文本文件检索证据来支持大语言模型（LLMs）的推理，但面临着多跳推理、多实体问题、多源验证和有效图利用等挑战。", "innovation": "Hydra 提出了一种无需训练的方法，将图结构、文档语义和来源可靠性统一起来，以支持LLMs中的深度、可信推理。Hydra 通过代理驱动的探索来处理多跳和多实体问题，结合结构化和非结构化检索，提高证据的多样性和准确性。针对多源验证问题，Hydra 使用三因素跨源验证（来源可信度评估、跨源相互印证和实体-路径对齐），以平衡主题相关性与跨模态一致性。利用图结构，Hydra 融合异质来源、引导高效探索，并早期去除噪声。实验结果表明，Hydra 在所有基准数据集中的表现优于强混合基线ToG-2，平均提高20.3%，最高可达30.1%。此外，Hydra 还使较小的模型（如Llama-3.1-8B）能够达到类似于GPT-4-Turbo 的推理性能。", "conclusion": "Hydra 在所有基准数据集上的表现优于其他模型，特别是在 GPT-3.5 上，平均提高了20.3%，最高可达30.1%。此外，Hydra 还能提升较小模型的推理性能，使它们能够达到类似于 GPT-4-Turbo 的水平。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "信任但验证！关于测试时缩放验证设计的综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "测试时缩放（TTS）已经成为提升大型语言模型（LLMs）性能的新型方法。在TTS中，通过在推理过程中使用更多计算资源，LLMs能够改进其推理过程和任务性能。现有方法包括从其他模型中提取推理痕迹或通过使用验证器探索庞大的解码搜索空间。验证器作为奖励模型，帮助评分解码过程中的候选输出，以细致探索庞大的解空间并选择最佳结果。这类框架被称为验证器，因为其参数自由和高性能增益。验证器可以基于提示，微调为区分型或生成型模型来验证过程路径及其结果。", "innovation": "本文综述了各种验证设计及其训练机制，填补了目前关于验证方法多样化和详细讨论的空白。这为TTS提供了统一视角，并能帮助研究者更好地理解和应用不同的验证策略。", "conclusion": "本文涵盖了文献中各种验证方法，并提供了一个统一的验证训练、类型及其在测试时缩放中的应用视图。研究成果可以在指定的仓库中找到。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17973", "html_url": "https://arxiv.org/abs/2508.17973", "title": "German4All -- 一个用于控制读写水平的德语同义替换数据集和模型", "title_en": "German4All -- A Dataset and Model for Readability-Controlled Paraphrasing in German", "authors": "Miriam Anschütz,Thanh Mai Pham,Eslam Nasrallah,Maximilian Müller,Cristian-George Craciun,Georg Groh", "background": "文章背景介绍了文本跨不同复杂度级别进行重新表述的能力对于创建可访问、可个性化调整的文本的重要性。当前缺乏涵盖多个读写水平的大型数据集，以支持多样化的读者群体。因此，研究者们需要开发新的数据集和模型来满足这一需求。", "innovation": "文章的创新点在于介绍了首个涵盖五级读写难度的大型德语数据集——German4All。该数据集通过使用GPT-4自动合成，并通过人类和语言模型的双重评估确保质量。基于German4All，研究团队开发了一种开源的、可控制读写难度的同义替换模型。该模型在德语文本简化任务中达到了最先进的性能，为多层次同义替换的研究提供了新的工具。", "conclusion": "文章结论提出，通过开源数据集German4All与同义替换模型，研究者们可以进一步探索多层次的同义替换方法，推动相关领域的研究和发展。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17202", "html_url": "https://arxiv.org/abs/2508.17202", "title": "100美元预算下高效领域的主动领域知识获取：通过经济有效的专家参与互动提升LLMs", "title_en": "Active Domain Knowledge Acquisition with 100-Dollar Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains", "authors": "Yang Wu,Raha Moraffah,Rujing Yao,Jinhong Yu,Zhimin Tao,Xiaozhong Liu", "background": "大型语言模型（LLMs）展现出了广泛的知识，但在如药物发现和罕见疾病研究等高度专业化和成本敏感的领域常常存在不足，因为缺乏专家知识。传统的微调方法不能有效利用预算参与专家交互，而该论文提出了一种新的框架（PU-ADKA），旨在经济高效地增强领域特异性LLMs，通过固定预算内的专家互动实现增强。", "innovation": "该研究提出了一种新颖的框架（PU-ADKA），主动与专家团队中适合专家互动，同时考虑专家的可用性、知识边界和咨询成本。该框架通过模拟训练，并通过受控的专家互动和真实的药物开发团队部署进行了验证，展示了其在预算严格约束条件下的高效性。该研究还推出了一项新的基准数据集CKAD，用于促进经济有效的领域知识获取的研究，进一步推进该领域的研究与发展。", "conclusion": "通过PU-ADKA框架，该研究在限定预算内有效提升了LLM在敏感领域的知识表现。通过本研究的方法论创新和实验结果的展示，提出了新的基准数据集CKAD，为未来的相关研究提供参考。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: 用于评估大语言模型结构化知识理解能力的细粒度基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大语言模型（LLMs）在理解知识图谱（KG）和表格等结构化知识方面取得了显著进展，但现有的评估方法并不严谨（即缺乏对特定能力的评估）且主要集中在一种类型的结构化知识上。因此，该研究旨在提出一个更全面和严谨的结构化知识理解基准，以诊断大语言模型的不足。现有研究指出，现有的大语言模型在理解结构化知识方面仍然面临重大挑战，其性能受噪声量、知识单元顺序和妄想现象等因素的影响。", "innovation": "该研究提出了SKA-Bench，即结构化知识增强问答基准，包含了四种广泛使用的结构化知识形式：知识图谱、表格、知识图谱+文本、表格+文本。研究采用了三阶段管道构建SKA-Bench实例，包括问题、答案、正向知识单元和噪声知识单元。通过扩展实例到四个基本能力测试场（噪声稳健性、顺序无感性、信息整合、否定排斥），对大语言模型的结构化知识理解能力进行了精细评估。", "conclusion": "实证评估表明，现有的先进大语言模型（如DeepSeek-R1）在理解结构化知识方面仍然面临显著挑战，其性能受到噪声量、知识单元顺序和妄想现象等因素的影响。研究者的数据集和代码可以在特定网址获取。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20410", "html_url": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench: 评估AI文本转应用工具设计能力的基准", "title_en": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": "Sam Jung,Agustin Garcinuno,Spencer Mateega", "background": "现有的AI文本转应用工具声称可以在短时间内生成高质量的应用程序和网站，但缺乏严格的公开基准来验证这些声明。因此，需要一个大型基准来评估这些工具在视觉效果方面的表现。", "innovation": "UI-Bench是第一个通过专家两两比较来评估AI文本转应用工具视觉效果的大规模基准。它涵盖了10种工具、30种提示、300个生成站点和4000多个专家判断，采用TrueSkill衍生模型来对系统进行排名，并提供可校准的置信区间。该基准为基于AI的网页设计制定了可重复的标准。", "conclusion": "UI-Bench为推进AI驱动的网页设计制定了可重复的标准。作者发布了完整的提示集、开源评估框架以及公开排行榜。生成的站点评估结果不久将公开。读者可以通过此链接查看UI-Bench排行榜：this https URL."}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19758", "html_url": "https://arxiv.org/abs/2508.19758", "title": "深入理解事件全貌：通过多元新闻检索获得更全面的事件理解", "title_en": "Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval", "authors": "Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung", "background": "获取多样化的视角是理解现实世界事件所必需的，然而，大多数新闻检索系统侧重于文本的相关性，导致检索结果重复并且限制了观点的多样性。现有的系统在这种背景下存在缺陷，难以提供丰富多样的信息。", "innovation": "该论文提出了NEWSCOPE，一个两阶段框架，用于改进事件报道的多样性。NEWSCOPE通过在句子层面建模语义变异来增强事件覆盖。第一阶段使用密集检索提取主题相关的内容，第二阶段则通过句子聚类和多样性的重新排名，以揭示互补的信息。同时，论文还引入了三种可解释性强的多样性评估指标：平均成对距离、积极聚类覆盖率和信息密度比，并构造了两个段落级别的基准数据集：LocalNews和DSGlobal。实验结果表明，NEWSCOPE在不牺牲相关性的前提下，显著提高了检索多样性，有效地减少了冗余，提升了事件理解的全面性。", "conclusion": "该研究结果证明了细粒度和可解释的建模方法在减少冗余和促进事件理解中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19997", "html_url": "https://arxiv.org/abs/2508.19997", "title": "探索针对长尾法律文本分类的选择性检索增强方法", "title_en": "Exploring Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "authors": "Boheng Mao", "background": "法律文本分类是自然语言处理在法律领域中的基础任务。现有基准数据集在标签分布上常常表现出长尾特性，导致对于稀有类别的模型性能较差。", "innovation": "该论文探讨了选择性检索增强（SRA）作为一种针对此问题的概念验证方法。SRA 方法专注于增强训练集中标记频率低的样本，同时不会引入对高频类标签的噪声，并不需要改变模型架构。检索过程仅使用训练数据，确保不会泄露潜在信息，也不需要外部语料库。", "conclusion": "SRA 方法在两个具有长尾分布的法律文本分类基准数据集（LEDGAR 和 UNFAIR-ToS）上进行了测试，结果显示 SRA 能够在微 F1 和宏 F1 方面持续超过 LexGLUE 基线模型的表现。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE: 一种面向大语言模型任务特定指令调优的奖惩导向数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "指令调优已经凸显了大型语言模型（LLMs）在生成更可控和有效的产出方面的巨大潜力。在这个研究中，我们关注特定任务指令调优的数据选择问题。现有的方法主要依赖于手工构建的相似度度量，选择与测试数据分布对齐的训练数据，目标是在测试数据上最小化指令调优损失，最终改善特定任务的性能。然而，观察发现，LLMs中的指令调优损失（即下个词预测的交叉熵损失）常常与实际任务性能之间没有单调关系，这表明当前的数据选择方法在任务特定指令调优中的有效性受到了影响。", "innovation": "为了应对这个问题，我们提出了ROSE（ROSE），一种新颖的奖惩导向指令数据选择方法，它利用对偶偏好损失作为奖励信号来优化任务特定指令调优的数据选择。具体而言，ROSE通过适应影响公式，近似计算训练数据点相对于少量样本偏好验证集的影响，选择最具任务相关性的训练数据点。实验结果显示，仅通过使用ROSE选择训练数据的5%，我们的方法可以与使用完整训练数据集的微调达到竞争性结果，并且超过了其他最先进的数据选择方法。", "conclusion": "我们的定性分析进一步证实了该方法在多个基准数据集和不同模型架构上的稳健的普适性。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19828", "html_url": "https://arxiv.org/abs/2508.19828", "title": "Memory-R1: 通过强化学习增强大型语言模型管理并利用记忆的能力", "title_en": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning", "authors": "Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma", "background": "大型语言模型（LLMs）在各种NLP任务中展现了出色的能力，但它们仍然是无状态的，受到有限上下文窗口的限制，这阻碍了长期推理。虽然最近有一些努力通过外部内存库来解决这一限制，但大多数现有方法都是静态的和启发式的，缺乏任何学习机制来决定存储、更新或检索哪些内容。现有的方法不能有效管理外部内存，无法适应和利用内存，从而影响了模型的效果和通用性。", "innovation": "Memory-R1 引入了一种强化学习（RL）框架，该框架为LLMs配备了主动管理和使用外部内存的能力。它包括两个专门的代理：Memory Manager负责学习执行结构化的内存操作，如添加、更新、删除或不进行操作；另一个代理是Answer Agent，它选择相关条目并基于这些条目进行推理以生成答案。这两种代理均通过具有目标驱动的RL（PPO和GRPO）微调，使得内存管理与利用能够适应多种问题类型和LLM模型，仅需少量监督即可实现自适应内存管理与利用。Memory-R1 在少数152个问答对和相应的时序内存库进行训练后，展示了优于最强基线模型的表现，并展示了良好的通用性。", "conclusion": "本工作不仅展示了一种有效的方法，还提供了关于如何通过RL解锁更丰富、更持久的推理系统的洞察，表明了LLMs的记忆感知行为方面的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher：通过细粒度原子思考奖励增强自主深度研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大型语言模型在解决复杂任务时表现欠佳，因为它们拥有静态内部知识。检索增强生成（RAG）虽能提高对外部信息的访问，但其在多层级推理和策略性搜索方面依然受限于刚性的工作流程。最近在自主深度研究方面的进展使大型语言模型能够自主推理、搜索和整合信息。但当前依赖基于结果的强化学习（RL）的方法存在关键问题，如梯度冲突和奖励稀疏性，限制了性能提升和训练效率。", "innovation": "我们提出了一个名为原子思考（Atomic Thought）的新颖的大语言模型思考模式，将其分解为细粒度的功能单元，并以推理奖励模型（RRMs）进行监督。RRMs为每个细粒度的操作提供原子思考奖励（ATR），用于精细指导。在此基础上，我们提出了Atom-Searcher，这是一种新的基于原子思考和ATR的RL框架，用于自主深度研究。Atom-Searcher通过课程引导式的奖励计划，优先处理过程级奖励，随后转至结果奖励，从而加速有效推理路径的收敛。实验结果表明，Atom-Searcher在七个基准上都表现出了一致的改进。其主要优点包括：（1）Atom-Searcher可以在测试时扩展计算量。（2）原子思考为RRMs提供了监督锚点，有助于将深度研究任务和RRMs联系起来。（3）Atom-Searcher展示了更可解释、更像人类推理的模式。", "conclusion": "Atom-Searcher通过原子思考和精细奖励实现大语言模型在自主深度研究中的性能提升，该方法通过课程引导的奖励机制加速了有效推理路径的收敛，并且展示出更可解释、更像人类的推理模式。实验结果表明该方法在多个基准上都获得了至少一致的改进。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20417", "html_url": "https://arxiv.org/abs/2508.20417", "title": "KG-CQR: 利用知识图谱中的结构化关系表示进行上下文查询检索", "title_en": "KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval", "authors": "Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Jason J.Jung,Khac-Hoai Nam Bui", "background": "知识图谱（KGs）与大规模语言模型（LLMs）的集成可以显著提升检索增强生成（RAG）系统的检索阶段。现有方法主要关注于解决语料库层次上的上下文损失，而KG-CQR专注于通过结构化关系表示增强查询，提取和补充相关的KG子图来生成语义丰富的查询上下文。", "innovation": "KG-CQR 是一个新颖的框架，通过利用基于语料库的知识图谱来增强复杂输入查询的上下文表示。它包含了子图提取、补充和上下文生成模块，作为一个模型无依赖的流水线，确保了不同大小的LLM的可扩展性。实验结果表明，KG-CQR在mAP和Recall@25方面的性能优于基线模型4-6%和2-3%，特别是在多跳问答等挑战性RAG任务中，其检索效果始终优于现有基线。", "conclusion": "KG-CQR 在RAGBench 和 MultiHop-RAG 数据集上的实验结果表明，其在mAP和Recall@25方面的表现优于强基线模型4-6%和2-3%。通过KG-CQR，多跳问答等挑战性任务的检索效果始终优于现有的基线。该研究提出的方法架构了扩展性强且无需额外训练的上下文查询检索框架。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将可穿戴数据转化为个人健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴设备中提取个性化见解需要复杂的数值推理，这超出了标准的大语言模型的能力，需要依赖代码生成等工具性的方法。大型语言模型代表了一个有潜力但未充分开发的解决方案，可以进行大规模分析。现有的挑战和需求驱动了这项研究，旨在开发一种新的系统来更好地分析和解读行为健康数据。", "innovation": "这项研究引入了名为Personal Health Insights Agent (PHIA)的新系统，它结合了多步骤推理、代码生成和信息检索技术来分析和解释行为健康数据。通过创建并共享两个包含超过4000个健康洞察问题的数据集，研究人员展示了PHIA相较于强大的代码生成基线，具有显著的性能优势，尤其在客观数值问题上准确率达到84%，在开放式问题上也获得了83%的良好评价，并且达到最高质量评级的可能性是一般模型的两倍。这项工作有望推进行为健康领域，促进个人理解其数据，推动个性化且数据驱动的健康管理普及.", "conclusion": "这项研究展示了通过大型语言模型代理实现的大规模个人健康数据解析能力，证明了PHIA作为工具在行为健康数据分析中的有效性，为未来的健康追踪和数据分析提供了新的前景和方向。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不要向朋友撒谎：从协作自我博弈中学到自己所知道的知识", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "AI辅助助手必须了解自己的能力和局限性，包括何时使用参数化知识回答问题，何时信任工具输出，何时需要回避或保留意见。这些能力很难通过监督微调来传授，因为这需要构建反映代理特定能力的示例。因此，本文提出了一个新的教学方法：协作自我博弈。", "innovation": "本文提出了一种全新的教学方法——协作自我博弈。这种方法通过构建一个团队协作的场景，在这种场景中，团队共同被奖励以集体获得正确答案。这种方法通过构建在互动中的激励机制来促进元知识的形成。研究集中在具有不同工具（特定语料检索）的小规模团队上，这些工具使团队必须共同努力以实现最大化的效果但同时减少努力。实验表明，在多代理社区中，团队级别的奖励可以促使个体代理改善工具使用和选择性预测的政策，即使个体代理在孤立环境中部署也是如此。", "conclusion": "协作自我博弈能够促进多代理团队的学习和协作，提升团队整体表现，同时也能够提升个体代理在独立环境中的工具使用和选择性预测能力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21090", "html_url": "https://arxiv.org/abs/2508.21090", "title": "Q-Align: 通过Query-Query对齐缓解零样本外观转换中的注意力泄露", "title_en": "Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment", "authors": "Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu", "background": "零样本图像生成模型在进行零样本外观转移（zero-shot appearance transfer）时面临显著的挑战：注意泄露（Attention Leakage）。这种挑战出现的原因在于，两个图像之间的语义映射由Query-Key对齐所捕捉到。", "innovation": "我们引入了Q-Align技术，利用Query-Query对齐来缓解注意力泄露并改善零样本外观转移中的语义对齐。Q-Align包括三个核心贡献：（1）Query-Query对齐，实现两个图像之间复杂的空间语义映射；（2）Key-Value重排列，通过重新对齐增强特征对应；（3）使用重排列后的Key和Value进行注意力优化，以保持语义一致性。", "conclusion": "通过广泛的实验证明，Q-Align在保持结构保真度的同时，优于当前最先进的方法，在外观保真度方面表现出色。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对Web代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "本文研究了基于多模态大型语言模型（MLLM）的Web代理如何通过生成基于网页屏幕截图的动作来与网页环境互动。研究发现，并利用一种称为WebInject的提示注入攻击，通过在渲染的网页原始像素值中添加干扰，改变屏幕截图，进而诱导Web代理执行攻击者指定的动作。", "innovation": "提出了一种名为WebInject的提示注入攻击方法。通过在原始网页像素值中添加扰动，这些扰动经过映射后成为屏幕截图的一部分，导致Web代理执行攻击者指定的动作。该方法将扰动寻找任务作为优化问题来建模，并通过训练一个神经网络近似映射关系，使用投影梯度下降解决优化问题，从而有效操控Web代理行为。", "conclusion": "通过广泛的实验验证，结果表明WebInject攻击非常有效，明显优于基线方法。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解所有视频中的摄像机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "该研究旨在评估和提升摄像机运动的理解能力。为了实现这一目标，研究者创建了一个名为CameraBench的大型数据集和基准，该数据集包含约3000个多样化的互联网视频，并经过严格的专家多阶段质量控制过程进行标注。研究还发现，不同的摄像机运动需要理解不同的场景内容，如移动的主体，并提出了一种与影视制作专家合作设计的摄像机运动基本轴分类法。研究进一步表明，经验丰富的参与者和基于教程的培训能显著提高准确性，而新手可能会混淆内参数与外参数的变化。现有技术如基于运动的结构恢复方法和视频语言模型在某些方面存在局限性，如捕捉依赖于场景内容的语义元素或精确估计轨迹的几何元素。", "innovation": "研究的主要贡献包括：提出了一种摄像机运动基本轴分类法；通过大规模人类研究量化了人类标注准确性，并展示了经验知识和基于教程的培训效果；使用CameraBench评估了摄像机运动理解的基础方法，并展示了生成的视频语言模型在多种应用中的能力；开发了一种针对CameraBench的自适应视频语言模型，结合了结构和几何信息，为理解和生成视频中的摄像机运动提供了新的途径。", "conclusion": "研究团队希望他们的分类法、基准数据集和培训材料能驱动未来的研究，旨在实现对任何视频中摄像机运动的理解。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21080", "html_url": "https://arxiv.org/abs/2508.21080", "title": "2COOOL: 2nd Workshop on the Challenge of Out-Of-Label Hazards in Autonomous Driving", "title_en": "2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving", "authors": "Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult", "background": "随着计算机视觉领域对自主驾驶算法的发展，将基于视觉的洞察与传感器数据集成对于提升感知、决策、规划、预测、仿真和控制至关重要。然而，我们还没有完全安全的自动驾驶汽车。关键原因在于处理新的场景，这是实现实际部署的最大障碍之一。因此，2COOOL研讨会为研究人员和工业专家提供了一个专门的论坛，以推动在新场景处理方面的前沿研究，包括异常风险检测、视觉-语言模型的风险理解、新的基准测试和方法论，以及安全自主驾驶实践。", "innovation": "2COOOL研讨会的目标是激励新的算法和系统开发，用于风险规避，借鉴异常检测、开放集识别、开放词汇建模、领域适应等相关领域的思想。研讨会将混合优秀学者和工业专家的参与，并在ICCV 2025上举办，地点位于夏威夷檀香山。", "conclusion": "2COOOL研讨会将继续依赖其在WACV 2025的成功，并将在ICCV 2025上再次举行，旨在通过学科和工业合作推动自动驾驶中未标注风险处理的前沿研究。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME: 使用语义股票表示和时间动态增强主题投资", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资旨在构造与结构性趋势相一致的投资组合，但因行业边界重叠和市场动态的不断演变，实现这一目标仍然颇具挑战性。构建投资主题的语义表示可以从文本数据中得到一些帮助，但现有的通用语言模型未能很好地捕捉到金融资产的细微特征，使其在构建金融资产的语义表示上存在局限性。", "innovation": "THEME提出了一个框架，通过层次对比学习微调嵌入，实现了主题与构成股票的层级关系的对齐，并通过整合股票收益进一步完善这些嵌入，从而生成能够有效检索与主题一致且具有高收益潜力的资产的表示。实验结果显示，THEME在主题资产检索方面显著优于大型语言模型。此外，生成的投资组合也表现出令人信服的性能。通过结合文本中的主题关系和回报中的市场动态，THEME为各种实际投资应用生成了专门针对股票嵌入。", "conclusion": "THEME有效地结合了文本数据中的主题关系和市场回报中的动态变化，为广泛的实际投资应用生成了专门的股票嵌入，从而在主题投资领域展现出了卓越的表现。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen: 正式验证的数据引擎以实现可靠的多模态几何问题求解", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题求解（GPS）要求证明逻辑的一致性和多模态推理能力。尽管大规模语言模型（LLMs）在GPS方面取得了快速进展，但其进步受限于缺乏可靠基准和系统方法。关键挑战在于LLMs固有的幻觉，导致生成的GPS数据集往往是噪声很大的、未经验证的且自相矛盾的。为了应对这一挑战，我们引入了TrustGeoGen，这是一个数据引擎，用于生成形式验证的几何问题，以建立一个具备原则性和可信度的基准。", "innovation": "我们的引擎整合了四个关键创新：1) 多模态对齐，同步生成图表、文本和逐步解决方案；2) 形式验证，确保所有推理路径都符合规则；3) 连接思维，将形式演绎与类似人类的逻辑步骤联系起来；4) 我们的GeoExplore系列算法，能够生成具有多种解决方案的多样问题变体，并具有回溯反思能力。利用此引擎，我们创建了GeoTrust-200K数据集和对应的GeoTrust-test基准，两者都保证了跨模态的一致性。实验结果显示，最先进的模型仅在GeoTrust-test上达到45.83%的准确率，突显了其显著的挑战性。进一步的实验表明，在我们合成的数据上进行训练，可以显著提升模型在GPS任务上的表现，并对新的域外基准具有良好的泛化能力。我们的代码和数据可在以下网址获取：this https URL", "conclusion": "我们的工作展示了如何通过正式验证的方法来创建可靠的多模态几何问题求解基准，并通过大规模语言模型在这些基准上的表现来验证其有效性。这一方法不仅提高了模型在GPS任务上的性能，而且还使其在面对新的、未见过的问题时具有更强的泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 偏置校正和非对称缩放增强的旋转量化方法用于大规模语言模型", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已经成为先进的大型语言模型（LLMs）量化管道的重要组成部分，通过有效地平滑权重和激活中的异常值。然而，进一步优化旋转参数只能提供有限的性能改进，并引入了显著的训练开销：由于旋转参数共享，整个模型必须同时加载以启用反向传播，这导致巨大的内存消耗并且限制了其实用价值。当前的旋转量化方法存在两个根本性限制：（i）旋转不能对齐通道均值，导致更宽的量化范围和增加的舍入误差；（ii）旋转使激活分布更接近正态分布，增加了由于裁剪错误引起的能量损失。", "innovation": "我们引入了BASE-Q，这是一种简单但强大的方法，结合了偏置校正和非对称缩放，有效地减少了舍入和裁剪错误。此外，BASE-Q 允许块级优化，消除了内存密集型的全模型反向传播的需要。广泛的实验表明，BASE-Q 在各种大型语言模型和基准测试中表现出色，与 QuaRot、SpinQuant 和 OSTQuant 相比，分别将精度差距缩小了 50.5%、42.9% 和 29.2%。", "conclusion": "BASE-Q 通过偏置校正和非对称缩放结合的方法有效减少了量化中的舍入和裁剪误差，并且允许块级优化，消除了全模型反向传播的需求，实验表明这种方法极大地提高了模型的精度，特别是在大规模语言模型上。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子与先观察再跳：超越下一标记预测的创造性极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "论文设计了一系列最小化的算法任务，这些任务大致抽象出开放型的现实世界任务。这使研究人员能够清晰且可控地衡量目前语言模型的创造性极限。与现实中的任务需要创造性远见不同，这些任务同样需要隐式的、开放端的随机规划步骤，这可能发现抽象知识图中的新连接，如同词语游戏、类比推理或科学研究，或者构建新的模式如同设计数学问题或新蛋白质。通过对这些任务的实证和概念性论证，作者认为下一标记学习过于短视，而基于多个标记的方法，例如无教师训练和扩散模型，相比之下更擅长产生多样且原创的输出。为在不破坏连贯性的前提下引入随机性，作者发现输入层注入噪声（称为种子调制）效果意外地很好，甚至在某些情况下优于从输出层采样温度。因此，该研究提供了一个理论性的、最小化的分析开放态创造能力的实验平台，并提供了超越下一标记预测和温度采样的新论据。部分代码已发布至此链接。", "innovation": "提供了一个实验平台，用于分析开放态创造性技能，强调跨标记方法在生成多样性、原创性输出中的优势。引入种子调制方法来引入随机性，发现它不仅有效还可能在某些情况下比从输出层采样温度更优。", "conclusion": "该研究论证了在衡量语言模型创造性能力时，使用实际任务的简化的算法任务比纯粹的下一标记预测更合适。提出了新的方法论，即无教师训练和扩散模型在创造性输出上的优势，并提供了关于如何超越下一标记预测和温度采样的新见解。部分代码被分享，以供进一步的研究和验证。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control: 为减轻文本到图像生成模型中的不安全内容提供安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像（T2I）生成模型方面取得了巨大进展，但这些模型的潜在滥用和误用引起了严重的安全关注。模型开发者已经努力引入相应机制来解决这些问题，但现有的安全机制要么在分布变化下容易被规避，要么需要对模型进行专属调整。因此，本文探讨了一个创新的插件式安全补丁，旨在减少T2I模型中的不安全内容生成。", "innovation": "Safe-Control 是一种创新的即插即用安全补丁，它通过数据驱动策略和安全意识条件，向封闭的T2I模型注入安全控制信号，以减轻不安全的内容生成。开发者可以根据需求构造多种安全补丁，这些补丁可以灵活地合并为一个统一的补丁。此外，Safe-Control 的即插即用设计还确保了其适应性，使其与其他相同去噪架构的T2I模型兼容。研究表明，Safe-Control 在六种不同的T2I模型中表现优异，显著降低了不安全内容生成的概率，同时保持了良性图像的质量和文本对齐性。", "conclusion": "Safe-Control 在六种具有相似生成架构的T2I模型中表现出色，显著降低了不安全内容生成的概率，与七种最先进的安全机制相比，它在减少不安全内容生成方面表现更佳。在不安全提示和最新对抗攻击下，Safe-Control 将不安全内容生成的概率降低至7%，而大多数基线方法的这一概率约为20%。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "使用全景X射线图像高级深度学习技术分类牙科状况", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本文研究了深度学习方法在全景X射线图像中自动分类牙科状况的应用。使用了一个包含1,512幅放射影像和11,137个专家验证注释的数据集，涉及四种条件：填充、龋齿、种植体和阻生牙。经过预处理和类别平衡后，评估了三种方法：自定义卷积神经网络（CNN）、结合CNN特征提取与传统分类器的混合模型，以及预训练模型的微调。实验采用了5折交叉验证，并以准确率、精确率、召回率和F1分数作为评估指标。结果显示，结合CNN特征提取与随机森林的混合模型性能最佳，准确率为85.4%，优于自定义CNN基线的74.3%。", "innovation": "通过使用混合模型的CNN随机森林和预训练模型的微调，发现了组合基于CNN的特征提取与集成分类器是一种适用于自动牙科诊断支持的实用途径，强调了需要更大规模的数据集和进一步的临床验证的需要。", "conclusion": "研究结果表明，具有形态相似性的状况可以通过混合模型提高识别准确性，提供高效、可靠的表现。这些发现表明，结合CNN特征提取与集成分类器为自动牙科诊断提供了一条实际路径，也指出了需要更大数据集和进一步临床验证的需求。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21094", "html_url": "https://arxiv.org/abs/2508.21094", "title": "带有时间视觉筛选的Video-LLMs", "title_en": "Video-LLMs with Temporal Visual Screening", "authors": "Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.(May)Fung,Manling Li,Heng Ji", "background": "人类在观看视频时会自然地进行时间筛选，关注关键片段。然而，现有的Video Large Language Models（Video-LLM）在训练时由于稀疏的帧采样和不足的帧间推理监督，难以捕捉到精细的时间语义。", "innovation": "受认知科学原理启发，我们提出了一种新的任务——时间视觉筛选（Temporal Visual Screening, TVS），该任务通过（1）保留焦点关键的视频片段，（2）同步重构查询为最直接的形式同时保持答案一致性，（3）保持任何可能答案的不变性和一致性，解决了上述问题。TVS被设计为模块化的前端适配器任务，可以无缝集成到Video Instruction Tuning（训练）和Video Question Answering（推理）管道中，优化了推理负担和认知负荷的分布，并显著提升了视频和语言理解的效果。", "conclusion": "实验结果显示，引入TVS在训练中可带来7.33%的相对改进，在推理中则达到34.6%的显著提升，证实了时间信息筛选对提升视频语言理解的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "HiddenObject：模态无关融合实现多模态隐藏目标检测", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中，隐藏或部分遮挡物体的检测仍然是一个基本挑战。由于遮挡、伪装和照明变化等因素，传统基于RGB的方法在这些不利条件下往往会失效。因此，需要更加健壮且模态无关的方法来应对这些问题。本研究通过将RGB、热成像和深度数据融合来解决这些问题。", "innovation": "提出了一个名为HiddenObject的融合框架，利用Mamba机制集成RGB、热成像和深度数据。该方法捕捉跨模态的互补信号，使得被遮挡或伪装的目标检测得到增强。具体来说，该方法识别各模态的特定特征，并在统一表示中进行融合，以适应具有挑战性的场景。验证结果表明，HiddenObject在多个基准数据集上表现出最先进的或竞争力的性能，明显优于现有方法，揭示了当前单模态和简单融合策略的关键局限性。", "conclusion": "研究结果表明，Mamba基融合架构可以显著推进多模态物体检测领域的发展，尤其是在视觉退化或复杂条件下。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21102", "html_url": "https://arxiv.org/abs/2508.21102", "title": "GENNAV: 生成通用可达区域的多边形掩码", "title_en": "GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions", "authors": "Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura", "background": "这项任务挑战性在于需要同时进行存在预测和分割，特别是对于边界模糊的‘stuff’类目标区域。现有方法在处理此类目标区域以及缺少或存在多个目标时表现不佳。因此，需要一种方法能够同时预测目标存在并自动生成多个‘stuff’类目标区域的分割掩码，以提高在这些情况下的表现。为了评估这一需求，作者构建了一个名为GRiN-Drive的新基准，其中包括无目标、单目标和多目标三种类型的样本。实验证明，GENNAV在标准评估指标上超过了基线方法。此外，作者还在四个汽车于五个不同地理区域的实际驾驶环境中进行实验，验证了其在不同现实环境中的鲁棒性表现，结果表明GENNAV超越了基线方法，并在多种真实环境中均表现出色。", "innovation": "提出了GENNAV方法，该方法能够同时预测目标存在并生成‘stuff’类目标区域的分割掩码，特别适用于边界不明确的区域。通过构建GRiN-Drive基准，评估了GENNAV在无目标、单目标和多目标三种类型样本上的表现，结果表明GENNAV超过了基线方法。此外，还进行了实际驾驶测试，验证了其在不同地理区域和交通环境中的零样本迁移性能和鲁棒性。", "conclusion": "GENNAV在标准评估指标上超越了基线方法，并在实际驾驶环境中展示了其在多变的真实环境中的有效性和鲁棒性。通过开发GRiN-Drive基准，研究者提供了一个更加全面的测试平台来推动和评估此类任务的技术进步。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21096", "html_url": "https://arxiv.org/abs/2508.21096", "title": "ROBUST-MIPS：腹腔镜手术器械的结合骨架姿态和实例分割数据集", "title_en": "ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments", "authors": "Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren", "background": "对手术器械进行定位构成了计算机辅助干预技术的基础构建块。现有工作通常专注于训练深度学习模型来执行分割任务。基于学习的方法受可获得的多样标注数据的限制。本文作者认为骨骼姿态标注是一种更有效的标注方法，能够平衡语义信息的丰富性与标注的简便性，从而加速可供使用的标注数据的增长。", "innovation": "作者提出了ROBUST-MIPS数据集，这是一个结合了工具姿态和实例分割的数据集，基于现有的ROBUST-MIS数据集开发。该数据集促进了这两种标注方法的研究，并允许在各种下游任务上进行头对头的比较。为了证明姿态标注方法在手术器械定位的有效性，作者使用流行的姿态估计方法建立了一个简单的基准，观察到了高质量的结果。同时，还提供了基准模型和自定义工具姿态标注软件以方便使用。", "conclusion": "本文通过提出结合骨架姿态和实例分割的数据集，促进了手术工具定位的研究发展。该数据集和提供的工具证明了姿态标注方法的有效性和简便性，有助于推动更多研究使用这一标注方法。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21091", "html_url": "https://arxiv.org/abs/2508.21091", "title": "ERTACache：错误纠正和时间步调整以实现高效的扩散模型", "title_en": "ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion", "authors": "Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin", "background": "扩散模型由于其内在的迭代推理过程而存在显著的计算开销。特征缓存提供了一种通过在时间步之间重用中间输出来加速的有前途的方法，但简单的重用往往会导致质量下降。本文正式分析了由缓存引入的累积误差，并将其分解为两种主要成分：特征移位误差，由缓存输出的不准确性引起，以及步骤放大误差，由于固定时间步长调度下的误差传播而产生。", "innovation": "我们提出了一种称为ERTACache的原理性缓存框架，以联合纠正这两种类型的误差。方法包括一个离线残差剖析阶段，以识别可重用的步骤，通过轨迹感知修正系数动态调整积分区间，并通过封闭形式的残差线性化模型分析缓存引起的误差。这些组件使在激进的缓存重用下实现准确而高效的采样成为可能。广泛的实验表明，在标准图像和视频生成基准上，ERTACache能够实现高达2倍的推理加速，同时保持或甚至改善视觉质量。特别是在最先进的Wan2.1视频扩散模型上，ERTACache实现了2倍的加速，而V р Bench降级极小，有效地保持了基线的忠实度，同时显著提高了效率。", "conclusion": "ERTACache显著提高了扩散模型的推理效率，同时减少了视觉质量的降级。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21197", "html_url": "https://arxiv.org/abs/2508.21197", "title": "GCAV：一种用于跨层一致性的概念激活向量框架", "title_en": "GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability", "authors": "Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang", "background": "概念激活向量（CAVs）提供了一种强大的方法，用于通过量化其对人类定义概念的敏感性来解释深度神经网络。然而，当独立地在不同层计算时，CAVs经常表现出不一致性，这使得跨层比较不可靠。", "innovation": "我们提出了全局概念激活向量（GCAV），这是一种新颖的框架，用于将CAVs统一为单一、语义一致的表示。该方法利用对比学习对跨层的概念表示进行对齐，并采用注意力机制来构建全局整合的CAV。通过这种方式，我们的方法可以显著减少TCAV分数的方差，同时保持概念相关性，从而确保更稳定和可靠的概念归因。我们引入了使用全局概念激活向量进行测试的方法（TGCAV），以对基于GCAV的表示应用TCAV。在多个深度神经网络上进行的广泛实验表明，我们的方法有效地缓解了跨层的概念不一致性，增强了概念定位，并提高了对对抗性扰动的鲁棒性。通过将跨层信息整合到一个连贯的框架中，我们的方法提供了对深度学习模型如何表示人类定义的概念的更全面和可解释的理解。", "conclusion": "通过整合跨层信息到一个连贯的框架中，我们的方法提供了对深度学习模型如何表示人类定义的概念的更全面和可解释的理解。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg: 通过联合3D射线辐射高斯重建和3D/3D配准，使用双平面X射线进行脊柱CT配准", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导的导航中，CT/X射线配准因其对高精度和实时性能的严格要求而具有挑战性。传统“渲染和比较”方法依赖于迭代投影和比较，会导致空间信息丢失和领域差距。双平面X射线的3D重建可以补充空间和形状信息，以进行2D/3D配准，但当前方法受到密集视角要求的限制，并且难以处理嘈杂的X射线。", "innovation": "我们提出了RadGS-Reg，这是一种通过联合3D射线辐射高斯（RadGS）重建和3D/3D配准的新框架，用于椎体级别CT/X射线配准。具体而言，我们的双平面X射线椎体RadGS重建模块探索了基于学习的RadGS重建方法，并采用反事实注意力学习（CAL）机制，专注于嘈杂X射线中的椎体区域。此外，提出了针对患者的预训练策略，逐步使RadGS-Reg从模拟数据过渡到实际数据，同时学习椎体形状先验知识。", "conclusion": "实验表明，在内部数据集上该方法在所有任务上均达到最先进的性能，超越了现有方法。代码可在该链接获取：this https URL"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过可视上下文提示实现可迁移的物体再识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前，物体再识别（ReID）方法训练特定领域的模型（例如针对人物或车辆），这些模型缺乏泛化能力，需要大量标注的新类别数据。自我监督学习通过学习实例不变性减少了标注需求，但在捕捉关键的识别特征方面存在困难。旨在解决这些挑战，该研究引入了Visual In-Context Prompting（VICP）框架，通过仅使用上下文示例作为提示，无需参数适配，使在已见类别上训练的模型能够直接泛化到未见过的新类别。", "innovation": "该论文提出了Visual In-Context Prompting（VICP）框架，结合大型语言模型（LLMs）和视觉基础模型（VFM），允许已经在已知类别上训练的模型无需参数调整，仅通过上下文示例作为提示，直接应用于未见过的新类别。通过将LLM推断的语义身份规则与VFM的预训练先验对齐，实现了跨类别的泛化性能，显著减少了数据集特定的重新训练需求。为了支持评估，该研究还引入了一个名为ShopID10K的10K对象实例数据集，来自电子商务平台，包含多视图图像和跨域测试。实验结果显示，VICP在未见过的类别上显著优于基线方法，实现了更优的性能。", "conclusion": "VICP框架证明了其在未见过的物体类别上提供优异的泛化性能，通过将大型语言模型推断的语义概念与视觉模型的预训练先验对齐，从而实现了跨数据集的高效泛化，显著减少了对新类别的重新训练需求，展示了其在物体再识别领域的创新价值。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21254", "html_url": "https://arxiv.org/abs/2508.21254", "title": "Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation", "title_en": "Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation", "authors": "Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao", "background": "目前的心脏磁共振成像(MRI)段分模型难以在不同的成像序列之间泛化，这是因为图像对比度存在显著差异，这些差异源于成像协议的变化。然而，所有获取的图像都由相同的旋进特性，包括质子密度、T1和T2值来控制。研究中的核心原理是通过逆向推断观察到的心脏MRI图像的旋进特性来解决泛化问题，通过求解带有旋进特性先验分布的病态非线性逆问题来实现。这种方法利用了从mSASHA数据集中学习的生成扩散模型，该数据集提供了心脏T1和T2联合地图，从而对MRI图像进行“旋进先验”估算，为任意新型序列的图像合成提供了灵活的基础。研究表明，Reverse Imaging方法能够在截然不同的图像对比度和成像协议下实现高度准确的分割，实现心脏MRI段分的广泛泛化。", "innovation": "本研究提出了一种名为Reverse Imaging的新型物理学驱动方法，用于心脏MRI数据增强和领域自适应。该方法通过从所观察到的心脏MRI图像中逆向推断旋进特性，解决了泛化问题，利用闲疫旋进特性先验分布求解病态非线性逆问题。通过从mSASHA数据集中学习生成扩散模型，获得“旋进先验”，从而实现了MRI图像中旋进特性的近似但有意义的估计，为任意外观新型序列的图像合成提供了解释性的“潜在变量”。该方法能够在大范围差异的图像对比度和成像协议下实现高度准确的分割，显示出广泛的应用前景。", "conclusion": "本研究通过提出Reverse Imaging方法，解决了心脏MRI在不同成像序列间泛化的问题。该方法能够实现成像对比度和协议的广泛泛化，通过对旋进特性的合理估计，提供了一种可解释的“潜在变量”，用于任意新型序列的图像合成。研究表明，Reverse Imaging能够在极端不同的图像对比度下实现高度准确的分割，并展示了广泛泛化心脏MRI分割的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21190", "html_url": "https://arxiv.org/abs/2508.21190", "title": "重新审视径向失真齐次变换", "title_en": "Radially Distorted Homographies, Revisited", "authors": "Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt", "background": "齐次变换在几何计算机视觉和射影几何中极为常见，因此，齐次变换的估计是广泛计算机视觉任务中的关键步骤。然而，在实际图像中，由于相机镜头引起的几何失真，可能需要同时确定齐次变换和镜头失真（特别是径向失真），以获得有用估计。考虑两个图像间的径向失真齐次变换，存在三种基本的失真正概念配置：仅在一个图像中的失真、两个图像相同的失真以及两个图像独立的失真。尽管过去对这些情况分别进行了研究，但本文提供了一种新颖且统一的方法，可以解决这三种情况。作者展示了如何使用所提出的统一方法来构建新的快速、稳定且准确的最小解算器，用于处理径向失真齐次变换。在所有三种情况下，所提出的解算器比现有的最先进的解算器更快，同时保持相似的准确性。所提出的解算器已在著名的基准测试中进行了测试，包括使用鱼眼镜头拍摄的图像。如果论文被接受发表，我们将提供学术代码。", "innovation": "文章提供了一种新颖且统一的方法，可以同时解决两个图像间存在不同类型的径向失真的齐次变换估计问题，即仅在一个图像中、两个图像相同以及两个图像独立的失真情况。该方法不仅为径向失真齐次变换的估计提供了统一的解决方案，还用于构建新的快速、稳定且准确的最小解算器。这些解算器在多个基准测试中被验证并显示出改进的性能，特别是在处理使用鱼眼镜头拍摄的图像方面表现出色。", "conclusion": "本文提出的方法通过提供一种统一的解决方案，能有效解决三个不同类型的径向失真齐次变换的估计问题，并且能够构建新的快速、稳定且准确的最小解算器。实验结果表明，所提出的解算器在运算速度上优于现有的最先进的解算器，同时保持相似的准确性。所提出的解算器已经过各种基准测试的验证，尤其是使用鱼眼相机拍摄的图像表现优异。"}
{"llm_update_time": "20250903", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝令牌：一种简单的方法来调整大型语言模型中的拒绝行为", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "构建安全可靠的语言模型的关键组件之一是使模型能够适当地拒绝执行某些指令或回答某些问题。这需要模型能够针对不同类型的用户查询（如不明确的问题、非法行为的指令或是超出模型知识范围的查询）输出拒绝信息。当前的默认方法是训练多个具有不同拒绝消息比例的模型来达到预期的拒绝比例，但这种方法计算成本高且需要为每个用户调整模型。因此，该研究旨在解决这一挑战。", "innovation": "该研究提出了拒绝令牌（refusal tokens），这是一种令牌，对应每个拒绝类别或者一个通用的拒绝令牌。这些令牌在训练过程中被添加到模型的回答前。然后展示了如何在推理过程中通过调整每个拒绝类别的拒绝令牌生成概率来引导模型的拒绝行为。这种方法允许通过选择性干预生成过程，控制单一模型的拒绝比例，而无需进一步调整。", "conclusion": "拒绝令牌实现了一种无需进一步微调就能控制单个模型拒绝比例的方法。这种方法能够灵活地调整不同拒绝类别的概率，根据不同用户的具体需求设定拒绝率，简化了模型的训练和使用流程。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21363", "html_url": "https://arxiv.org/abs/2508.21363", "title": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning", "title_en": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning", "authors": "Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang", "background": "扩散模型在生成高保真3D人体姿态方面表现出强大的能力，但它们的迭代性质和多假设需求导致了显著的计算成本。当前的扩散模型在训练和推理过程中消耗大量资源，降低模型效率.", "innovation": "提出了一种基于扩散的高效3D人体姿态估计框架，该框架结合了层级时间剪枝（HTP）策略。HTP在阶段性的自上而下的方式中动态地剪枝帧和语义层面的冗余姿态标记，同时保留关键的动力学。具体来说，该框架包括三个组成部分：（1）通过自适应时间图构造分析帧间运动相关性来识别重要帧的层级时间相关增强剪枝（TCEP）；（2）利用帧层面的稀疏性减少注意力计算的稀疏焦点时间MHSA（SFT MHSA），专注于与运动相关的标记；（3）通过聚类进行细粒度语义剪枝的掩码引导姿态令牌剪枝器（MGPTP），仅保留最具有信息性的姿态标记。", "conclusion": "在Human3.6M和MPI-INF-3DHP数据集上的实验显示，HTP相比之前的扩散模型方法，在训练期间减少了38.5%的MACS，在推理期间减少了56.8%的MACS，并且将推理速度平均提高了81.1%，同时实现了最佳的性能水平。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21398", "html_url": "https://arxiv.org/abs/2508.21398", "title": "GLENDA: 妇科腹腔镜内膜异位症数据集", "title_en": "GLENDA: Gynecologic Laparoscopy Endometriosis Dataset", "authors": "Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein", "background": "腹腔镜妇科手术是一种微创手术，通过患者的腹部实时影像，进行插管和使用各种器械进行治疗。该手术方式不仅促进了多种治疗手段的应用，而且对手术后的活动（如治疗计划、案例记录和教育培训）进行视频记录也变得至关重要。然而，当前的手动分析手术记录过程通常耗时且繁琐。为此，需要更先进的计算机视觉和机器学习方法来改进现状。由于大多数当前方法高度依赖于样本数据（尤其是在医疗领域样本数据非常稀少），本文介绍了Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA)——一个包含端位注释的子宫内膜异位症的影像数据集，这是同类型数据集中首个数据集，并且是与领域内领先医学专家合作创建的。", "innovation": "该研究创新之处在于创建了GLENDA数据集，这是一个First of its kind（同类首个）的图像数据集，特别是针对子宫内膜异位症的区域标注数据。由于医疗领域的数据稀缺性，这个数据集对推动计算机视觉和机器学习技术在微创手术中的应用具有重要意义，可以帮助改进现有的手术视频分析过程，从而加速诊断和治疗决策过程。", "conclusion": "GLENDA数据集为提供一种新的医疗数据来源，特别是对于子宫内膜异位症相关区域的注释数据，这对于开发更有效的计算机视觉和机器学习模型以改善微创手术后分析过程具有重要价值。该数据集的成功创建和公开发布进一步推动了人工智能技术在医疗领域的发展和应用。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21371", "html_url": "https://arxiv.org/abs/2508.21371", "title": "Print2Volume：从2D指纹图像生成基于 OCT 的3D指纹体素", "title_en": "Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image", "authors": "Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang", "background": "光学相干断层扫描(OCT)能够获取高分辨率的三维指纹数据，但其昂贵的成本和耗时的数据采集过程导致了缺乏大规模公共数据集，这对先进算法特别是数据需求较大的深度学习模型的发展造成了阻碍。", "innovation": "提出了Print2Volume框架，这是一种从2D指纹图像生成逼真的、基于OCT的3D指纹体素的新型方法。该框架分为三个阶段：1) 2D风格转换模块，将二值指纹转化为模拟Z方向投影OCT扫描样式的灰度图像；2) 3D结构扩展网络，将2D图像扩展为合理的3D解剖体素；3) 基于3D GAN的OCT实时性精练器，用于以真实纹理、闪烁噪声和其他成像特性渲染结构体素。该框架生成了包含420,000个样本的大规模合成数据集，实验证明了其高质量和对识别性能的显著提升。", "conclusion": "通过在合成数据上预训练识别模型并在小的真实世界数据集上进行微调，该研究将ZJUT-EIFD基准上的等错误率(EER)从15.62%显著降低至2.50%，证明了其在缓解数据稀缺性方面的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21399", "html_url": "https://arxiv.org/abs/2508.21399", "title": "使用深度学习实例分割识别腹腔镜手术器械", "title_en": "Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation", "authors": "Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein", "background": "记录下来的手术视频已成为医学内窥镜领域的重要信息来源，因为视频中的每一细节都是手术的重要部分。然而，尽管目前视频录制很容易，但在医疗视频库中基于内容的搜索需要对特殊视频内容进行自动内容索引，这仍然是一个巨大的挑战。本文讨论了腹腔镜妇科手术记录视频中外科器械的分割和识别问题，具体评估了一种基于区域的全卷积神经网络进行实例感知器械分割的可行性和多类器械识别效果。尽管在训练样本数量有限的情况下仍能实现较高准确度的目标定位和分割，但对于特定器械的确定仍然是一个巨大挑战，因为手术器械之间的相似性很高。", "innovation": "本文通过使用基于区域的全卷积神经网络对腹腔镜妇科手术视频中外科器械进行了实例分割和多类识别，并验证了即便训练示例数量较少也能够获得较高的定位和分割准确性，同时指出在识别特定器械方面还存在挑战，归因于手术器械的高相似性。这种研究方法为基于内容的医疗视频搜索提供了新的技术手段，并可能推动这一领域的进一步发展。", "conclusion": "结论表明，虽然可以实现外科器械的实例分割和识别，尤其是在有限训练样本情况下表现出突破性的进展，但在识别特定器械型方面仍然面临巨大挑战。未来的研究可以通过增加训练样本多样性和使用增强学习等方法提高识别精度。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21227", "html_url": "https://arxiv.org/abs/2508.21227", "title": "基于Auto3DSeg的轻量级MRI胰腺癌自动分割", "title_en": "Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg", "authors": "Keshav Jha,William Sharp,Dominic LaBella", "background": "胰腺肿瘤的准确界定对于诊断、治疗规划和疗效评估至关重要，但由于解剖变异性和可供数据集的局限性，自动分割仍然具有挑战性。这项研究利用SegResNet模型，在2025 PANTHER挑战赛中针对胰腺肿瘤分割的两个基于MRI的任务进行了训练和评估。", "innovation": "研究采用了Auto3DSeg架构中的SegResNet模型，并通过5折交叉验证和STAPLE聚集成簇技术，在特定区域内重点进行了训练和评估。分别使用T1加权动脉对比增强MRI和T2加权MR-Linac的病例共141个进行训练，采用多种评估算法（包括Dice相似系数、5毫米Dice相似系数、95分位数Hausdorff距离、平均表面距离和均方根误差）来评估算法的性能。", "conclusion": "尽管在两个任务中的性能表现不一，但研究结果展示了自动分割在临床应用中的潜力，并突显了需要更大的标准化MRI数据集来提高模型鲁棒性和临床适用性，以应对MRI基于胰腺肿瘤分割中的小型数据集带来的挑战。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21257", "html_url": "https://arxiv.org/abs/2508.21257", "title": "PHD: 基于点扩散的个性化3D人体建模", "title_en": "PHD: Personalized 3D Human Body Fitting with Point Diffusion", "authors": "Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang", "background": "传统的3D人体重建（HMR）方法设计为用户无关，旨在实现泛化。尽管这些方法通常使用来自2D图像的约束来改进姿态的对齐，这牺牲了3D准确性，因为它们没有同时考虑个人特定的身体形状和3D姿态的可能性。这项工作提出了一种新的方法PHD，利用用户特定的形状信息来提高视频中的姿态估计准确性。", "innovation": "PHD创新地通过两个步骤来解耦用户特定身体形状和3D姿态的优化过程。首先，通过合成数据训练建立一个基于点扩散的个性化姿态先验模型，该模型利用点扩散变换器（Point Diffusion Transformer）迭代地引导姿态优化。这项学习到的3D姿态先验有效地减轻了过度依赖2D约束所造成的问题，从而不仅提高了臀部对齐的姿态准确性，还提高了绝对姿态准确性。此外，该方法高度数据高效，只需合成数据进行训练，并且可以作为灵活的插件模块，无缝集成到现有的3D姿态估计器中，以提高其性能。", "conclusion": "研究提出了PHD，一种利用用户特定身体形状信息以提高视频中姿态估计准确性的新颖方法。该方法不仅在臀部对齐的姿态准确性方面取得了改善，还提高了绝对姿态准确性，这是一直被前期工作中忽视的重要指标。此外，该方法的数据效率高，只需合成数据进行训练，并且可以与现有的3D姿态估计器无缝集成，提高其性能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "标准化的多层组织图谱以增强大规模全切片图像档案中的人工智能集成和搜索", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "全切片图像（WSI）是通过扫描包含生物样本（如组织切片或细胞样本）的整个玻片，在多个放大倍数下生成的高分辨率数字图像。这些图像被广泛用于人工智能（AI）算法的开发，并且在病理学（用于疾病诊断）、肿瘤学（用于癌症研究）、神经学、兽医医学、血液学、微生物学、皮肤科、药理学、毒理学、免疫学和法医学等多个领域有广泛应用。在构建应用于AI算法训练或验证的样本集时，了解WSI的内容是至关重要的。但是当前没有标准的元数据，因此这样的选择主要通过人工检查，对于包含数百万对象的大规模集合来说并不适用。因此本研究提出了一种通用框架来生成WSI的2D索引图，并提出了针对特定应用领域的一种特征描述机制。通过在临床病理学领域的应用，展示了这种方法在实现不同目录之间互操作性方面的优势。", "innovation": "该研究提出了一个通用框架来生成WSI的2D索引图，并提出了一种基于特定应用领域的问题解决机制。索引图分为3层：来源、组织类型和病理改变，每一层都将WSI的一部分分配给特定的类。这种方法通过在临床病理学领域的具体实例，展示了该标准在WSI目录、机器学习以及基于图的WSI表示中的优势和适用性，增强了大规模WSI档案中的人工智能集成和搜索能力。", "conclusion": "该研究通过提出一个通用框架，生成WSI的多层组织图，并在临床病理等领域进行应用，验证了这种方法在WSI领域应用的可行性和有效性，为大规模WSI数据库的人工智能集成和搜索提供了新的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21444", "html_url": "https://arxiv.org/abs/2508.21444", "title": "Scale-GS: 通过流内容中冗余过滤训练实现高效可扩展的高斯散点图", "title_en": "Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content", "authors": "Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang", "background": "3D Gaussian Splatting (3DGS) 允许实时渲染高保真模型，这对沉浸式应用至关重要。然而，向动态场景扩展时受到高密度高斯数据量大的限制，以及每帧漫长的训练时间阻碍了其应用。现有方法在应对动态场景时存在显著的数据量和训练时间问题。", "innovation": "提出了一种名为 Scale-GS 的可扩展高斯散点图框架，通过锚点结构中尺度层次化的高斯球组织，分层训练，和动态变形与生成策略来降低计算开销，并通过双向自适应掩码机制提升训练效率。除此之外，通过输入冗余过滤来减少训练中的冗余部分，提高训练效率。该方法显著降低了训练时间，同时在视觉质量上优于现有技术。", "conclusion": "通过引入 Scale-GS 框架的层次组织结构和动态变形与生成机制，以及双向自适应掩码机制，有效解决了高斯散点图在大量动态场景下的训练效率问题，实现了视觉质量的提升，同时显著减少了训练时间。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21437", "html_url": "https://arxiv.org/abs/2508.21437", "title": "树木作为高斯分布：大规模单个树木映射", "title_en": "Trees as Gaussians: Large-Scale Individual Tree Mapping", "authors": "Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt", "background": "树木在陆地生物圈中扮演着关键角色，对生态系统功能、气候调节和生物经济至关重要。然而，大规模监测单个树木的方法受到模型不足的限制，现有的全球产品主要关注二元树冠覆盖率或 canopy 高度，未能明确识别单个树木。", "innovation": "提出了一种基于深度学习的方法，用于在全球范围内使用 3 米分辨率的 PlanetScope 图像检测大型单个树木。该方法通过可扩展大小的高斯核模拟树冠，从而提取树冠中心并生成二元树冠覆盖率地图。基于自动从机载 LiDAR 数据中提取的数十亿个点进行训练，使模型能够成功识别森林内外的树木。", "conclusion": "该方法提供了一种可扩展的框架，用于全球高分辨率树木监测，并且适合未来提供改进图像的卫星任务。通过手动标签微调，检测性能可以进一步提高，该方法实现了与机载 LiDAR 的先进性能（覆盖率 R² = 0.81）。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21424", "html_url": "https://arxiv.org/abs/2508.21424", "title": "使用置信度伪标签的无监督增量学习", "title_en": "Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels", "authors": "Lucas Rakotoarivony", "background": "深度学习模型在许多计算机视觉任务中已经取得了最先进的性能。然而，在真实世界的应用中，训练期间未见过的新类经常会涌现，要求模型能够逐步学习新的知识。为了应对这一挑战，Class-Incremental Learning (CIL) 方法允许模型在保留之前学习的知识的同时学习新的类。然而，现有的 CIL 方法基于强假设，即增量数据集必须是完全标记的，这在实际应用中是不切实际的。因此，提出一种新的方法，即用置信度伪标签（ICPL）进行无监督的 CIL，该方法用伪标签替代人工标注，从而可以从未标记的数据集中进行增量学习。", "innovation": "该研究提出了一种新颖的无监督 Incremental Learning 方法，使用置信度为基础的伪标签（ICPL），能够在未标记的数据集上进行增量学习，而不需要人工标注。该方法通过将伪标签结合到 CIL 方法中，并使用置信度选择标准评估性能降级。此外，该方法在细粒度数据集上进行了测试，以证明其实用性，并测量其计算复杂度以验证其在资源受限环境中的适用性。实验表明，该方法在准确性方面达到了与监督方法相当的结果，并且在最终准确度方面超越了最先进的 class-iNCD 方法超过 5%。", "conclusion": "ICPL 方法在竞争性的性能测试中表现优异，并在准确度方面超越了最先进的 class-iNCD 方法。该方法解决了在未标记数据集上进行增量学习的挑战，展示了其实用性和在资源受限环境中的适用性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21463", "html_url": "https://arxiv.org/abs/2508.21463", "title": "Multi-Method Ensemble for Out-of-Distribution Detection", "title_en": "Multi-Method Ensemble for Out-of-Distribution Detection", "authors": "Lucas Rakotoarivony", "background": "在开放的世界设置中操作的神经网络中，检测异常分布（Out-of-Distribution, OOD）样本至关重要，尤其是在安全性关键应用中。现有方法通过两种主要技术来改进OOD检测：特征截断，增加内分布（In-Distribution, ID）和OOD样本之间的差异；评分函数，根据内分布和OOD数据之间的差异分配分数。然而，大多数方法要么专注于单一的技术家族，要么只在特定类型的OOD数据集上评估其效果，忽视了结合现有多种解决方案的潜力。", "innovation": "受此观察的启发，研究者们理论和实验地证明了最先进的特征截断和评分函数可以有效结合。此外，研究展示了整合多种评分函数增强了对多种类型的OOD样本的鲁棒性。基于这些洞察，提出了能够将最先进的OOD检测器统一为单个更有效的评分函数的Multi-Method Ensemble（MME）得分。在大规模和小型基准上的广泛实验表明，MME在所有基准中显著优于最近的最先进的方法。使用BiT模型，我们的方法在具有挑战性的ImageNet-1K基准上得到平均FPR95为27.57%，比现有最佳基线提高了6%的性能。", "conclusion": "MME显著优于现有最新方法，特别是在ImageNet-1K等具有挑战性的基准上，表现显著提升。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21472", "html_url": "https://arxiv.org/abs/2508.21472", "title": "通过局部增强的船舶检测对抗性补丁攻击", "title_en": "Adversarial Patch Attack for Ship Detection via Localized Augmentation", "authors": "Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang", "background": "当前的遥感图像船舶检测技术主要依赖于深度神经网络（DNNs）的对象检测能力。然而，DNNs对对抗补丁攻击非常敏感，可能导致检测模型误分类或使目标完全逃脱检测。过往研究表明，基于数据变换的方法可以提高对抗性例子的泛化能力，但过度增强背景或无关区域可能会引入不必要的干扰，导致对象检测模型误报。这些错误不是由对抗补丁本身引起的，而是由于过度增强了背景和非目标区域。", "innovation": "本文提出了一种局部增强方法，仅对目标区域进行增强，避免对非目标区域产生影响。通过减少背景干扰，这种方法使损失函数能够更直接地关注对抗补丁对检测模型的影响，从而提高了攻击成功率。", "conclusion": "基于HRSC2016数据集的实验结果表明，所提出的方法有效提高了对抗补丁攻击的成功率并增强了其泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21458", "html_url": "https://arxiv.org/abs/2508.21458", "title": "基于SAM-Med3D的联邦微调在MRI相关痴呆分类中的应用", "title_en": "Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification", "authors": "Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron", "background": "尽管基础模型（FMs）在基于人工智能的痴呆症诊断方面具有强大的潜力，但如何将它们整合到联邦学习（FL）系统中仍待深入探索。本研究对脑部MRI数据下的联邦FM微调性能和效率的关键设计选择进行了系统性的评估，包括分类头的架构、微调策略和聚合方法的影响。", "innovation": "研究通过大型的多队列数据集，揭示了分类头架构对性能的重要影响，发现固定FM编码器的微调方法达到了与完全微调相似的结果，同时高级聚合方法优于标准的联邦平均法。这些发现提供了在去中心化临床环境中部署FMs的实际见解，并强调了未来方法开发时应考虑的权衡。", "conclusion": "研究结果表明，对于痴呆症的MRI分类任务，分类头的架构至关重要，固定FM编码器的微调方法和使用高级聚合方法能够显著提高联邦FM的性能。这些发现为临床环境中的联邦学习和FM应用提供了实践指导。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频大规模语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但仍易产生与视频输入不一致或无关的内容，即幻觉。现有的视频幻觉基准主要集中在短视频上，归因于强语言先验、缺失帧或视觉编码器引入的视图-语言偏见等因素。然而，这些原因仍不足以解释长视频中幻觉的复杂性。文章指出，当幻觉涉及事件级语义合并时，模型可能会生成正确的帧级语义但错误的输出，这被定义为语义聚合幻觉（SAH），并且在长视频中变得更加关键。因此，有必要系统地研究这种幻觉的原因并采取措施减轻它。现有的基准重点不在于长视频，导致了研究的不完整性。", "innovation": "该研究提出了ELV-Halluc，第一个专注于长视频幻觉的基准，专门研究并系统地分析了语义聚合幻觉（SAH）。研究发现了SAH在复杂语义背景下更常见，并且在快速变化的语义内容中更易出现。同时，通过实验证明了位置编码策略和DPO策略的有效性，用于缓解SAH。此外，研究还创建了一个包含8K对抗数据对的自定义数据集，并验证了ELV-Halluc和Video-MME的改进效果，显著降低了SAH的比例。", "conclusion": "通过ELV-Halluc，首次全面分析了长视频中的语义聚合幻觉，并通过实验验证了位置编码和DPO策略的有效性。这是对现有视频理解模型幻觉研究的补充，有助于更准确地处理长视频的语义幻觉。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21451", "html_url": "https://arxiv.org/abs/2508.21451", "title": "锐眸再瞥：重思轻量级字幕赋能实际视觉专家", "title_en": "One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist", "authors": "Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo", "background": "图像字幕对于视频指令系统和探索机器人这样的应用至关重要，但将这样的模型部署在本地设备上却充满了挑战，因为多模态大型语言模型（MLLMs）的高计算需求是一个障碍。", "innovation": "本文通过研究轻量级字幕生成，开发了一种基于1.25亿参数的语言模型的视觉专家，该模型比LLaMA-7B小56倍，并且在单句和详细字幕任务上的表现可以与大型多模态通用模型媲美。为了提升模型的性能，提出了Sharp-Eyed Refinement框架，通过改进视觉定位来增强字幕质量。DeepLens模块是该框架的核心，通过专注于初始浏览中识别出的信息性区域来提取详细的视觉表示。", "conclusion": "实验证明，我们的视觉专家比之前的轻量级和大型通用模型有明显的优势，并且我们的框架是有效的。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21529", "html_url": "https://arxiv.org/abs/2508.21529", "title": "也许你不需要U-Net：用于材料显微图像分割的卷积特征上采样", "title_en": "Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation", "authors": "Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper", "background": "特征基础模型，如视觉变换器，能够为图像提供丰富的语义描述，有助于进行如（交互式）分割和目标检测等下游任务。然而，这些模型因使用基于块的描述符，常难以捕捉微图中的精细特征，并且在材料和生物图像分析中遇到大尺寸图像的问题。本文研究如何培训一个卷积神经网络来实现低分辨率基础模型特征的高效上采样，进而应用于多种显微图像的特征提取和分割任务，包括植物细胞、锂离子电池正极和有机晶体等，特别是在难以分割的裂纹等部分表现突出。相比之下，使用这些深度特征进行交互式分割，可以更快、更少标签地获得高质量的分割结果，无需训练传统卷积网络或进行微调", "innovation": "本文主要的创新在于开发了一种卷积神经网络，用于低分辨率基础模型特征的上采样，并将其应用于材料显微图像的高效分割。这种方法无需传统的U-Net，可以直接对完全训练好的基础模型特征进行上采样，实现快速高效的特征提取和分割", "conclusion": "采用上采样后的深度特征进行交互式分割，能够在较少标签的情况下快速获得高质量的分割结果，并且相对于训练或微调传统卷积网络具有显著优势。这种新的方法为材料显微图像的分割提供了高效的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift: 通过量子桥梁进行X射线域适应的隐式条件转换", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医疗数据提供了培训稳健模型的可扩展解决方案，但数据域之间的显著差异限制了其在真实临床环境中的泛化能力。本文针对合成与实际头颅X射线图像之间的跨域转换挑战，重点在于弥补衰减行为、噪声特征和软组织表示之间的差异。", "innovation": "提出了一种基于流匹配和量子桥梁的统一类条件生成模型MedShift，实现了高保真度、无配对跨域图像转换。MedShift学习一个共享的、非特定于域的隐空间，在训练期间看到的任何一对域之间实现无缝转换，而不依赖于域特定训练或配对数据。", "conclusion": "MedShift模型尽管相对于基于扩散的方法具有更小的模型规模，但在感知保真度和结构一致性之间可以灵活调整。实验结果表明，MedShift是一个可扩展且通用性强的医学影像领域适应解决方案。相关代码和数据集在此处提供：this https URL"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21539", "html_url": "https://arxiv.org/abs/2508.21539", "title": "HCCM：无人机自然语言指导中的层次交叉粒度对比和匹配学习", "title_en": "HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones", "authors": "Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li", "background": "无人机在目标匹配和导航等任务中提供了新颖的范式，但由于其宽视场和复杂的组成语义，给视觉语言理解带来了挑战。主流的视觉语言模型更注重全局对齐，而忽视了细粒度的语义，现有层次方法依赖于精确的实体分区和严格的包含关系，这在动态环境中效果有限。因此，无人机的文字描述往往不完整或模糊，影响了对齐的稳定性。", "innovation": "本文提出了层次交叉粒度对比和匹配学习（HCCM）框架，其中包括两个组件：（1）区域-全局图像-文本对比学习（RG-ITC），通过对比局部视觉区域与全局文本以及反向对比，避免了精确场景分区并捕捉了从局部到全局的语义层次结构；（2）区域-全局图像-文本匹配（RG-ITM），通过消除刚性约束，评估全局跨模态表示中的局部语义一致性，增强组合推理能力。此外，HCCM引入了动量对比和蒸馏机制（MCD），以增强其鲁棒性。", "conclusion": "实验结果表明，HCCM在GeoText-1652数据集上的图像检索准确率为1位召回的28.8%和文本检索的14.7%，在未见过的ERA数据集上展示了出色的一次性泛化能力，平均召回率为39.93%，优于微调基线。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "使用去噪扩散模型从单张图像生成完整高斯点", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "Gaussian splatting通常需要场景的密集观测，但这可能会导致难以重构遮挡和未观察到的区域。完成未观测的场景表面具有挑战性，因为存在合理的表面不确定性。传统方法使用基于回归的公式预测单个“模式”，导致模糊、不切实际，并且不能捕捉多个可能的解释，因此通常仅聚焦于与背景隔离的对象，仅重构可见表面或在远离输入视图的情况下未能外推。", "innovation": "提出了一种生成式模型，该模型在单个输入图像上学习高斯点的3D表示分布，以此来生成完整的360度渲染。该方法利用变分自编码重构器从单个输入图像和2D图像中自动学习潜在空间，进而训练扩散模型。这种方法能够生成忠实的重建和多样样本，并可完成被遮挡表面，适用于高质量360度渲染。", "conclusion": "该方法利用去噪扩散模型从单张图像生成完整高斯点，生成高质量的360度渲染并能够完成被遮挡的表面。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 通过零样本CLIP预先排序和AI辅助排序的高效成对比较", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或困难的注释任务中，成对比较比绝对评级或顺序分类更受欢迎，因为它提高了可靠性。但是，全面的成对比较需要大量的标注（O(n^2)）。先前的研究通过使用排序算法主动抽样成对比较，大幅降低了标注负担（O(n log n)）。然而，该研究进一步通过两项改进提升了标注效率：（1）使用 Contrastive Language-Image Pre-training (CLIP) 模型进行了无训练的层次预先排序；（2）用自动化比较取代简单的、明显的手工成对比较。EZ-Sort方法首先使用CLIP模型生成零样本预先排序，然后初始化带有桶意识的Elo分数，并最后运行由不确定性指导的人在环MergeSort。这种方法在不同数据集（面部年龄估计、历史图像年代学和视网膜图像质量评估）上进行了验证，表明即使当有100个项目时，EZ-Sort也比全面成对比较减少了90.5%的标注成本，并比先前的工作减少了19.8%的标注成本，同时改善或维持了评分者间可靠性。", "innovation": "提出了一种新颖的方法EZ-Sort，该方法结合了CLIP模型的无训练预排序和不确定性的排序算法，以减少人工标注成本并提高评分者间可靠性。具体来说，EZ-Sort利用CLIP模型生成预先排序，初始化带有桶意识的Elo分数，并运行基于不确定性的AI辅助MergeSort。该方法大幅降低了注释成本，同时保持甚至提高了一致性和评分者间评可靠度。这项研究表明，将CLIP先验与不确定性感知抽样结合可以实现一种高效且可扩展的成对排名解决方案。", "conclusion": "该研究提出了一种新的方法EZ-Sort，该方法结合了CLIP先验和不确定性的排序算法，显著减少了人工标注成本并提高了评分者间的一致性。EZ-Sort通过生成零样本预先排序、初始化带有桶意识的Elo分数以及运行由不确定性指导的人在环MergeSort，展示了高效的成对排名解决方案，并在多个数据集上验证了其有效性和效率。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21556", "html_url": "https://arxiv.org/abs/2508.21556", "title": "ECHO: Ego-Centric modeling of Human-Object interactions", "title_en": "ECHO: Ego-Centric modeling of Human-Object interactions", "authors": "Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll", "background": "从第一人称视角建模人类与物体的交互（HOI）是一个尚未充分探索但非常重要的话题，尤其是随着可穿戴设备（如智能眼镜和手表）的普及。我们研究了仅从头部和手腕追踪可以获得多少有关交互的信息，并为此提出了一种新的方法ECHO来恢复人类姿态、物体运动和接触这三种模态。", "innovation": "提出了一个统一大框架ECHO，能够从最少观察中恢复人类姿态、物体运动与接触三种模态。ECHO使用了扩散变换架构和独特的三元扩散过程，能够联合建模人类运动、物体轨迹与接触序列，适应不同的输入配置。ECHO基于头为中心的经典空间运行，增强了整体方向的鲁棒性。进一步，ECHO提出了基于传送带的推理机制，能够处理任意长度的序列。", "conclusion": "通过广泛评估，ECHO超越了现有方法，尤其是在第一人称视角下的HOI重建方面，达到了最先进水平。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过双模式退火和强化学习激励多模态大语言模型的一般自思考能力", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大语言模型（MLLMs）在复杂的推理问题上表现出了显著的优势，但这些复杂的推理过程在解决简单问题时是冗余的，这些简单问题可以通过不涉及复杂推理的方式直接解决。为了应对这种低效现象，本研究提出了一种自动思考的大语言模型R-4B，它能够根据问题的复杂度自主决定是否需要进行思考。", "innovation": "R-4B模型的核心思想是通过双模式退火技术赋予模型同时具备思考能力和非思考能力，并采用了双模式策略优化（BPO）来提升模型在判断是否激活思考过程方面的准确性。具体来说，模型首先在跨越多主题的谨慎筛选的数据集上进行训练，该数据集包含来自思考和非思考两种模式的样本。随后在改进的GRPO框架下进行第二次训练，使得策略模型对于每个输入查询都能生成来自两种模式的响应。实验结果显示，R-4B在25个具有挑战性的基准测试中达到了最先进的性能，在大部分任务中超过了Qwen2.5-VL-7B，并在推理密集型基准测试中可与Kimi-VL-A3B-Thinking-2506 (16B)相比肩，同时具有较低的计算成本。", "conclusion": "R-4B模型实现了在处理复杂且简单的任务时的最佳权衡，提供了比现有模型更优的性能和更低的计算成本，特别是在推理密集型任务上。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21657", "html_url": "https://arxiv.org/abs/2508.21657", "title": "基于复值可变形注意力的展开框架在高质量计算机生成全息图生成中的应用", "title_en": "Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation", "authors": "Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan", "background": "计算机生成全息图（CGH）因其在深度学习算法的支持下得到了广泛关注。然而，由于其非线性和不适定性，仍然存在准确和稳定的重建挑战。具体而言，(i) 常用的端到端网络将重建模型视为黑盒子，忽视了物理学的基本关系，降低了其可解释性和灵活性。(ii) 基于CNN的方法具有有限的感受野，这限制了它们捕捉长距离依赖和全局上下文的能力。(iii) 基于离散谱方法（ASM）的模型受到该方法本身的限制，这限制了它们的应用范围。因此，该领域仍面临着有效捕获全局特征和提升性能的挑战。", "innovation": "本文提出了一种展开网络（DUN），将其梯度下降过程分解为两个模块：一个适应带宽保持模型（ABPM）和一个相位域复值去噪器（PCD），以此提供更多的灵活性。ABPM相比ASM基方法提供了更宽的工作距离。同时，PCD利用其复值可变形自注意力模块捕捉全局特征，提升性能，实现了超过35 dB的PSNR。实验表明本方法在模拟和实际数据上的结果达到了先进水平。这项研究通过引入复值可变形注意力模块和模块化设计，弥补了现有方法的不足，提供了新的视角和方法。", "conclusion": "通过使用复值可变形注意力模块和模块化设计，DUN能够有效解决计算机生成全息图中的全局特征捕捉和性能提升等问题，达到最先进的结果。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21565", "html_url": "https://arxiv.org/abs/2508.21565", "title": "视觉语言模型理解城市的能力如何？基于街道视角图像的空间推理对比研究", "title_en": "How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images", "authors": "Juneyoung Ro,Namwoo Kim,Yoonjin Yoon", "background": "理解城市场景需要精细的空间推理能力，包括对物体、布局和深度线索的理解。然而，现有的视觉语言模型（VLMs），基于通用场景预训练，能否将这些能力有效地转移到城市领域，这一方面仍然没有得到充分探索。", "innovation": "本文进行了一项对比研究，评估了三种现成的VLM——BLIP-2、InstructBLIP和LLaVA-1.5，在城市场景上的零样本性能以及通过特定于城市场景的合成VQA数据集进行微调的效果。研究人员构建了一个基于街景图像分割、深度和物体检测预测的合成数据集，并使用自动生成的推理步骤（CoT）作为监督信息。", "conclusion": "研究表明，尽管VLMs在零样本设置中表现尚可，但在通过合成CoT监督数据集进行微调后，其性能显著提升，尤其是在否定型和假设性问题等挑战性问题上。这项研究将城市空间推理引入VLM的新挑战，并展示了合成数据集构建是将通用模型适应专门领域的一种可行途径。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21581", "html_url": "https://arxiv.org/abs/2508.21581", "title": "集成病理学和CT影像以个性化预测肾癌复发风险", "title_en": "Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer", "authors": "Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado", "background": "肾细胞癌（ccRCC）的复发风险评估对于术后随访和治疗至关重要。莱比锡评分广泛用于评估远处复发风险，但它在患者层面提供的分辨率有限，且不考虑影像学信息。这项研究旨在通过结合手术前的CT扫描和术后组织病理学全切片图像（WSI），多模态集成方法来提高复发风险预测的准确性。", "innovation": "该研究采用预训练编码器和基于Cox的生存模型的模块化深度学习框架，在单模态、晚期融合和中期融合设置下进行了测试。结果表明，基于WSI的模型在真实世界肾癌队列中始终优于仅依赖CT的模型，突显了病理学在预后方面的强预测力。中期融合进一步提高了模型性能，其中最佳模型（TITAN-CONCH与ResNet-18）接近调整后的莱比锡评分。随机并列打破缩小了临床基准和学习模型之间的差距，这表明离散化可能夸大了个体表现。影像学通过融合为放射学带来的价值主要是通过融合实现的。这些发现展示了基于基础模型的多模态集成在个性化ccRCC风险预测中的可行性。未来的工作应探索更具表现力的融合策略、更大的多模态数据集以及通用的CT编码器，以更好地匹配病理学模型的能力。", "conclusion": "这些发现展示了使用基于基础模型的多模态集成来进行个性化ccRCC风险预测的可行性。未来的工作应该探索更具表现力的融合策略，使用更大的多模态数据集以及通用CT编码器，以更好地匹配病理学模型的能力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21689", "html_url": "https://arxiv.org/abs/2508.21689", "title": "怀疑者的映射：基于置信度的BEV投影进行在线HD地图构建", "title_en": "Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping", "authors": "Fatih Erdoğan,Merve Rabia Barın,Fatma Güney", "background": "构建高分辨率（HD）地图需要准确地将图像空间中的道路元素映射到鸟瞰视图（BEV）空间。现有HD地图构建方法通常将投影任务外包给传统的映射技术，尽管这些方法具备一定的准确性，但在泛化方面存在不足，容易将不存在的道路元素错误地呈现出来。", "innovation": "本文提出了一个新的基于相机参数的几何映射机制，并且通过置信分数来适应场景，以提取图像中的相关地图信息。在这一机制上，本文还提出了一种新的概率投影机制，带有置信分数，用以（i）更好地调整映射与场景的匹配度以及（ii）过滤掉那些不应该影响HD地图生成的不相关信息。此外，通过使用置信分数选择性地累积可靠信息来改进了时间处理。", "conclusion": "在nuScenes和Argoverse2数据集的新分集上的实验表明，该方法在性能上超过了现有方法，尤其是在nuScenes和长距离感知范围内的泛化表现更佳。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21580", "html_url": "https://arxiv.org/abs/2508.21580", "title": "4D 长itudinal 医疗成像中学习时空轨迹的 Temporal Flow Matching", "title_en": "Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging", "authors": "Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein", "background": "理解医学影像的时间动态对于疾病进展建模、治疗规划和解剖学发育追踪等应用至关重要。然而，大多数深度学习方法要么仅考虑单一时间上下文，要么专注于分类或回归等任务，这限制了它们进行细微空间预测的能力。尽管一些方法已经被探索，但它们往往局限于单一时间点、特定疾病或具有其他技术限制。为了弥合这一根本性差距，该研究引入了一种统一的生成性轨迹方法——Temporal Flow Matching (TFM)，旨在学习底层的时间分布，并通过设计可以退化为最近图像预测器（预测最后上下文图像，LCI），并支持3D体积、多个先前扫描和不规则抽样。", "innovation": "提出了一种新的统一生成性轨迹方法——Temporal Flow Matching (TFM)，旨在学习时间分布，该方法可以通过退化到最近图像预测器为主要情况，适用于3D体积、多个先前扫描和不规则采样。在三个公开的纵向数据集上进行的基准测试表明，TFM始终超越了自然成像的时空方法，为4D医学影像预测建立了新的基准和稳健基线", "conclusion": "广泛的基准测试表明，TFM在三个公开的纵向数据集上始终超越了自然成像的时空方法，建立了4D医学影像预测的新基准和稳健基线。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21680", "html_url": "https://arxiv.org/abs/2508.21680", "title": "在具有提示能力的模型中实现全身PET/CT中的交互式病灶分割", "title_en": "Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models", "authors": "Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein", "background": "全身PET/CT是肿瘤成像的基础，但由于示踪剂不均一性、生理吸收以及多中心变异性，病灶分割仍然具有挑战性。尽管全自动方法取得了显著进步，但临床实践中需要结合人工干预的方法，以高效地细化预测的掩码。autoPET/CT IV挑战引入了基于模拟用户提示的交互式分割任务，旨在解决这一需求。", "innovation": "该研究基于winning autoPET III nnU-Net管道，扩展了可提示的框架，通过将用户提供的前景和背景点击编码为额外的输入通道。实验表明，欧几里得距离变换（EDT）编码始终优于高斯核。此外，提出了在线模拟用户交互策略和自定义点采样方法，以增强在实际提示条件下模型的鲁棒性。EDT基模型的集成（训练有无外部数据）实现了跨验证性能最佳，相比基础模型，减少了许多假阳性结果和假阴性结果。", "conclusion": "提示模型具有在多示踪剂、多中心PET/CT中实现高效、用户引导的分割流程的潜力。研究结果为未来交互式PET/CT病灶分割提供了有力支持。相关代码已在项目链接中公开。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21761", "html_url": "https://arxiv.org/abs/2508.21761", "title": "从沉默和噪音中学习以进行视觉声音源定位", "title_en": "Learning from Silence and Noise for Visual Sound Source Localization", "authors": "Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro", "background": "视觉声音源定位是一个基本的感知任务，目标是在给定音频的情况下，检测视频中声音源的位置。尽管近期有了一些进展，但当前的方法在低音频-视觉语义对应的情况下表现不佳，例如沉默、噪音、以及离屏声音。此外，过去的评估主要关注正案例，即场景中可见声音源的单一情况，这很大程度上限制了方法的实际应用范围。", "innovation": "1. 提出了一种新的训练策略，将沉默和噪音纳入考虑，提高在正案例情况下的性能，同时对负音频更有鲁棒性。据此，构建了一个自监督模型SSL-SaN，在声音定位和跨模态检索方面达到了最先进的性能。\n2. 提出了一种新的度量标准，用于量化正负音频-视觉配对中听觉和视觉特征对齐与分离之间的权衡。\n3. 呈现了一个扩展并改进的IS3+合成数据集，其中包括负音频来源的数据。", "conclusion": "本文提出的方法自监督学习模型SSL-SaN在声源定位和跨模态检索上的性能达到了最新水平，并提供了一种新的度量标准和改进的数据集，有助于更好地理解和指导该领域的研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么止步于单词？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术将每个字符分开进行识别，这种方式容易在字符分割环节出错，并且缺乏上下文信息，无法有效地利用语言模型。近年来序列到序列的翻译技术的进展使现代技术先识别出单词，然后每次输入一个单词到模型中，直接输出完整的单词，这样可以更好地利用语言模型并跳过容易出错的字符分割步骤。观察到这种变化后，作者发现准确性的瓶颈已经转移到了单词分割。因此，论文提出了从单词级OCR向行级OCR的自然且逻辑上的进步。这种提案可以跳过单词检测中的错误，并提供更大的句子上下文，以更好地利用语言模型。研究表明，所提出的技巧不仅提高了OCR的准确性和效率，还公开了一个精心收集的包含251个英文页面图像和行级注释的数据集，用于训练和评估从单词级到行级OCR的转变。实验结果显示，端到端准确率提高了5.4%，并且效率提高了4倍。随着大型语言模型的持续改进，该方法也具有利用此类进步的潜力。", "innovation": "提出从单词级OCR向行级OCR的自然且逻辑上的进步。这种技术可以跳过单词检测中的错误，并提供更大的句子上下文，以更好地利用语言模型。此外，还贡献了一个精心收集的数据集，包含251个英文页面图像和行级注释，用于训练和评估从单词级到行级OCR的转变。", "conclusion": "提出的技巧不仅提高了OCR的准确性和效率，还公开了一个精心收集的数据集，用于训练和评估从单词级到行级OCR的转变。实验结果显示，当使用大型语言模型时，该方法的性能要优于现有的单词级方法，具有更大的应用潜力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET: 用于微调大型视觉语言模型的数字测量设备CAD模型合成数据集生成工具", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "大型视觉语言模型（LVLMs）在多模态任务中表现出色，但在一些简单的场景，如从数字测量设备（DMDs）读取数值，尤其是在头戴式摄像头和增强现实（AR）应用中常见的复杂背景、遮挡、极端视角和运动模糊等条件下，仍表现出色。为此，该研究介绍了一个名为CAD2DMD-SET的合成数据生成工具，用于支持涉及DMDs的视觉问答（VQA）任务。", "innovation": "CAD2DMD-SET工具通过利用3D CAD模型、高级渲染和高保真图像合成，生成多样化的、带有VQA标记的DMD合成数据集，适合用于LVLMs的微调。同时，该研究还提出了DMDBench，这是一个包含1000个标注的现实世界图像的精心挑选验证集，用于在实际约束条件下评估模型性能。利用CAD2DMD-SET生成的数据集进一步微调三个最先进的LVLMs，并使用平均归一化Levenshtein相似度（ANLS）进行基准测试，结果显示，这种方法显著提高了模型在复杂条件下的鲁棒性和性能。", "conclusion": "CAD2DMD-SET训练数据集大大提高了LVLMs在前述复杂条件下的鲁棒性和性能。该工具预计将在最终论文准备完毕后作为开源发布，使得社区可以添加不同的测量设备并生成自己的数据集。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO: 自监督预训练在遥感领域的深入探究", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习已经成为了遥感领域的一种强有力工具，因为遥感数据中存在着大量未标记的数据。本研究探索了DINO（一种对比自监督方法）在遥感影像上的预训练应用。", "innovation": "本文引入了SatDINO，一种针对遥感影像表示学习的模型。实验结果显示，SatDINO在多个遥感数据集上优于基于常见掩码自编码器（MAE）的其他先进方法，且在多个基准测试中表现出色。此外，研究还进行了一项严格的消除因素研究，评估了SatDINO各个组件的性能，并提出了新的GSD编码方式和自适应视图采样等增强方法。", "conclusion": "SatDINO在遥感影像预训练中表现出色，且提供了额外的增强策略。本文的代码和训练模型可以在指定的链接处获取。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "通过非参数深度嵌入聚类实现无监督视频连续学习", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频在许多应用中广泛使用，但尚未充分探索无监督连续学习。此前的研究仅关注有监督的连续学习，依赖于标签和任务边界的知识，而获取有标签的数据既昂贵又不实际。针对这一空白，本文研究了无监督视频连续学习（uVCL）。uVCL由于处理视频而非图像增加了额外的计算和内存要求，因此提出了一个新的基准实验协议，考虑了每个任务中无序视频数据类别的学习。这项工作旨在填补无监督连续学习领域视频处理的空白。", "innovation": "本文提出了一个非参数的深度嵌入聚类解决方案，用于解决探索不足的无监督视频连续学习问题。通过使用深度嵌入视频特征的核密度估计（KDE）作为非参数概率数据表示，并引入一种新颖检测标准，可以动态扩展记忆簇以捕捉新知识。此外，利用前一个任务的知识进行迁移学习，作为当前任务学习的初始状态。实验表明，所提出的方法在连续学习多个任务时显著提高了模型的性能。", "conclusion": "通过在三个标准视频动作识别数据集UCF101、HMDB51和Something-to-Something V2上进行深入评估，发现提出的算法在不使用任何标签或类边界的条件下，显著增强了无标签情况下连续学习多个任务的表现。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21712", "html_url": "https://arxiv.org/abs/2508.21712", "title": "FLORA: 通过精调Flux LoRA进行低数据环境下目标检测的高效合成数据生成", "title_en": "FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA", "authors": "Alvaro Patricio,Atabak Dehban,Rodrigo Ventura", "background": "基于扩散的生成模型的最新进展在弥补目标检测任务中稀缺的数据集方面显示出巨大潜力，但大多数模型仍依赖于大型扩散模型的资源密集型完全微调，这需要企业级GPU（如NVIDIA V100）和数千张合成图像。这限制了其在实际应用中的可扩展性和成本效益。", "innovation": "提出了一种名为FLORA（Flux LoRA Augmentation）的轻量级合成数据生成管道。这种方法利用了Flux 1.1 Dev扩散模型，通过低秩适应（LoRA）进行独競微调，大幅降低了计算要求，使合成数据集的生成仅需要消费级GPU（如NVIDIA RTX 4090）。实验表明，使用本方法生成的500张合成图像训练目标检测器的检测性能优于使用ODGEN基准生成的5000张合成图像的模型，mAP@.50:.95指标可提高21.3%。这表明可以用更少的数据和更少的计算成本达到或超越现有最佳性能，从而证明了注重质量和效率的方法优于粗暴的生成方法，使高级合成数据创作更适用于实际场景", "conclusion": "FLORA通过精调Flux LoRA实现了在低数据环境下目标检测的高效合成数据生成，这种方法不仅显著降低了计算需求，还展示了在更少数据和更低成本条件下达到或超越现有最佳性能的潜力。这种方法使得高级合成数据创作在实际应用中的可行性和普及性更高。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21770", "html_url": "https://arxiv.org/abs/2508.21770", "title": "从哈利·波特中我们能学到什么？一种关于从异常视频中进行视觉表示学习的探索性研究", "title_en": "What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos", "authors": "Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao", "background": "人类通常在开放世界中显示出出色的泛化和发现能力，尤其是在被展示不常见新概念时。现有的大多数研究集中在闭合集合中的常见典型数据上，而开放世界中的新发现尚未在视频中得到充分探索。本文探讨了在学习过程中暴露非常规视频的可能性，收集了一个包含各种类型的非常规数据的新视频数据集（如科幻、动画等），以研究这些非常规数据如何有益于开放世界的学习。", "innovation": "以往的研究多集中在闭合集合中的典型数据上，而本文提出的是一种全新的开放式学习方法，通过使用非常规数据进行训练，改进了多种视觉表示学习任务（如异常检测、新类别发现、零样本动作识别）。并且，这些非常规数据集合的类别多样性对异常检测性能的提升起到了积极作用。同时，对于新类别发现任务，使用小而多样化的非常规样本比使用大但多样化的典型样本具有更高的性能。对于零样本动作识别，非常规视频中的语义多样性有助于模型更好地泛化到未见过的动作类别。", "conclusion": "在广泛的实验评估中，这些观察结果揭示了非常规视频在开放世界中的视觉表示学习方面的益处，表明从非常规视频中进行学习是很有前途的研究方向。已提出的新型数据集也鼓励进一步在这方面的研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21775", "html_url": "https://arxiv.org/abs/2508.21775", "title": "一种在诊断和治疗MRI中胰腺肿瘤分割的多阶段微调和集成策略", "title_en": "A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI", "authors": "Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein", "background": "自动分割胰腺导管腺癌（PDAC）从MRI对于临床工作流程至关重要，但由于肿瘤与组织对比差以及注释数据稀缺，分割工作受到阻碍。", "innovation": "本研究提出了一种多阶段微调和集成策略，基于nnU-Net框架，从通用解剖基础模型开始，逐步微调于CT胰腺病变数据集和目标MRI模态，通过系统地评估数据增强方案和训练计划，构建了定制的异质专家模型组，提高了Tumor Dice评分。", "conclusion": "该研究提供了一种在数据稀缺和复杂医学成像任务中开发专业化高性能模型的稳健方法，最终在诊断MRI任务1中取得了0.661的Tumor Dice评分，在治疗MRI任务2中取得了0.523的Tumor Dice评分。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "领域泛化在真实环境中：从领域感知表示中分离分类", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评估如CLIP这样的基础模型的领域泛化（DG）具有挑战性，因为大规模网络预训练数据可能涵盖了现有基准测试的所有领域。现有的DG评估可能既不够具有挑战性，也难以充分测试真正的未见过的数据场景。因此，为了更好地评估CLIP在真实场景中的DG性能，即CLIP遇到真正的未见过数据的场景，考虑了两种方法：1. 在ImageNet上微调CLIP后，在33个数据集上进行评估，这些数据集具有量化的离群分布（OOD）评分；2. 使用无学习来让CLIP“忘记”某些领域，这是一种近似方法。我们观察到，CLIP在更多离群分布数据集上的表现显著下降。这揭示了一个关键问题，即标准领域不变损失试图使表示领域不变，但这对基础模型是有害的，因为它会迫使丢弃有益于泛化的领域敏感表示。为了应对这个问题，研究提出了一种名为CLIP-DCA（解缠分类与增强领域感知表示）的方法，该方法侧重于在基础模型中增强领域意识是实现有效的领域不变分类的前提。CLIP-DCA利用单独的领域头部和合成的多样化领域数据来识别并增强CLIP编码器中的领域意识，同时鼓励与领域特征的解缠以实现领域不变分类。在这一具有挑战性的评估中，CLIP-DCA在现有方法中显示出了显著的改进，特别是在更离群分布的数据集上有明显提升。", "innovation": "提出了CLIP-DCA方法，并采用了解缠分类与增强领域感知表示的策略，旨在让基本模型中的编码器识别和增强领域意识，同时与领域特征分离以实现领域不变分类。这种方法显著突破了现有基于领域不变损失的方法的局限，展示了在离群分布数据集上的优异性能。", "conclusion": "CLIP-DCA方法显著提高了CLIP在离群分布数据集上的性能，解决了领域不变损失迫使丢弃对泛化有益的领域敏感表示的问题。这表明增强领域意识对于实现具有有效领域不变分类的基本模型至关重要。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的无侵入性卷积神经网络可靠性监测", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络（CNNs）已成为现代计算机视觉的基础，它们在各种图像识别任务中实现了前所未有的准确度。尽管这些网络在针对训练数据（同分布数据）表现出色，但它们仍然容易受到小幅度又不可见的对抗性扰动影响，这种扰动能够导致高置信度的误分类。现有的对抗性扰动检测方法要么需要昂贵的重新训练，要么要修改网络结构，或者在干净输入上降低性能。", "innovation": "提出了一种无需修改模型即可检测对抗性输入的方法，通过在VGG-16的特征层监测激活函数的熵变化来实现，这种方法能在早期卷积层中检测到7%的熵变化，实现90%的检测准确率，且误报率和漏报率均低于20%。该工作还揭示了CNNs在激活模式中内编码分布变化的能力，证明了仅通过激活熵可以评估CNN的可靠性。", "conclusion": "该工作表明CNN的可靠性可以通过激活熵来单独评估，无需对原模型进行修改或牺牲其性能，实现具有实时检测功能的自我诊断视觉系统的实际部署。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21095", "html_url": "https://arxiv.org/abs/2508.21095", "title": "ScanMove：未注册人体网格的运动预测与转移", "title_en": "ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes", "authors": "Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi", "background": "未注册的表面网格，特别是原始3D扫描数据，因缺乏点对点对应关系以及数据中的噪声，给自动计算合理的变形带来了巨大挑战。", "innovation": "提出了一种全新的无需刚体约束、数据驱动的框架，用于预测和转移未注册人体网格上的运动。该方法结合了一个稳健的运动嵌入网络和一个学习到的每顶点特征场，生成时空变形场，驱动网格变形。", "conclusion": "广泛的评估结果表明，该方法在包括行走和跑步在内的任务上对挑战性的未注册网格具有有效性和多样性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21824", "html_url": "https://arxiv.org/abs/2508.21824", "title": "DriveQA：通过驾驶知识测试", "title_en": "DriveQA: Passing the Driving Knowledge Test", "authors": "Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar", "background": "当前的自动驾驶基准测试主要集中在标准的空间和视觉问答任务上，但驾驶知识测试要求模型对所有交通规则、路标和优先通行原则有全面的理解。人类驾驶员需要识别在现实世界数据集中很少出现的边缘情况。为了解决这些问题，本文提出了一个全面的开源文本和视觉基准DriveQA，覆盖了交通法规和场景的各个方面。研究人员通过DriveQA验证了现有的先进大语言模型和多模态大语言模型在基础交通规则上的表现良好，但在数字推理、复杂优先通行场景、路标变体和空间布局方面存在明显不足，并通过调整和预训练进一步提高了模型在这方面的表现。", "innovation": "DriveQA是一个全面的开源文本和视觉基准，它覆盖了交通法规和场景的各个方面，使得研究人员能够更深入地理解和改进大语言模型和多模态大语言模型在驾驶知识上的理解和应用。通过DriveQA进行的实验表明，通过调整和预训练，模型的综合性能得到了显著提高，特别是在交通标志识别和交叉口决策方面，并且这些改进也反映在实际驾驶数据集上的性能提升。此外，DriveQA中控制的变化帮助研究人员了解了模型对环境因素（如光照、视角、距离和天气）的敏感性。", "conclusion": "通过使用DriveQA，研究人员发现现有的最先进的大语言模型和多模态大语言模型在基础交通规则上表现良好，但仍然存在数字推理和复杂优先通行场景以及路标变异等方面的短板。通过进一步的调整和预训练，这些模型在交通标志识别和交叉口决策等方面的表现得到显著提升。预训练于DriveQA的大语言模型在现实世界数据集上的性能也得到改善，同时也展示了模型能够内化文字和合成交通知识以有效地泛化到下游问答任务。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21767", "html_url": "https://arxiv.org/abs/2508.21767", "title": "UItron：具有高级感知和规划的基础GUI代理", "title_en": "UItron: Foundational GUI Agent with Advanced Perception and Planning", "authors": "Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma", "background": "GUI代理旨在实现移动/PC设备上的自动化操作，这对于实现通用人工智能具有重要意义。快速发展的VLMs（视觉语言模型）促进了GUI代理的发展。然而，构建GUI代理仍旧是一项具有挑战性的任务，原因包括操作轨迹的稀缺性、交互基础设施的可用性和基础模型初始能力的限制。", "innovation": "UItron是一个开源的基础模型，用于自动GUI代理，具备高级的GUI感知、语义连接和规划能力。UItron强调系统数据工程和交互基础设施作为基础组件的必要性。它通过系统地研究一系列数据工程策略来增强训练效果，建立了连接移动和PC设备的交互环境。UItron在感知、语义连接和规划任务上的训练采用监督微调，并开发了课程强化学习框架，以增强在线环境下的复杂推理和探索。实验结果表明，UItron在GUI代理场景中取得了显著的进步。", "conclusion": "UItron在中文APP场景中展示了高度的交互能力，公司收集了一百万步骤的中文操作轨迹，构建离线和在线代理评估环境。实验结果表明，UItron在中文APP场景中取得了显著进步，步步推进GUI代理迈向实际应用。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "重新审视情境识别中的单正多标签学习：停在歧义之中", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "情境识别是一种计算机视觉中的基本任务，目标是从图像中提取结构化的语义摘要，通过识别关键事件及其关联实体。现有的方法将动词分类视为单标签问题，但经过全面分析表明，这个问题的表述未能解决视觉事件识别中固有的歧义性，因为同一个图像可能可以用多个动词类别合理描述。", "innovation": "本文做出了三个关键贡献：首先，通过实证分析揭示动词分类本质上是多标签问题，由于动词类别间的普遍语义重叠。其次，由于大规模标注多标签的实用性问题，提出将动词分类重新定义为单正多标签学习（SPMLL）问题，这是一种SR研究中的新颖视角。第三，设计了一个全面的多标签评估基准，旨在公平地评估模型在多标签设置下的性能。此外，提出了Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP)，结合图神经网络捕捉标签相关性，并通过对抗训练优化决策边界，以应对SPMLL的挑战。", "conclusion": "在真实数据集上的大量实验表明，本文的方法在多标签设置下性能显著提高，同时在传统的前一位和前五位准确度指标上保持竞争力，实现了超过3%的MAP提升。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21809", "html_url": "https://arxiv.org/abs/2508.21809", "title": "VoCap: 从任何提示进行视频对象描述和分割", "title_en": "VoCap: Video Object Captioning and Segmentation from Any Prompt", "authors": "Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid", "background": "理解视频中的对象需要细粒度的定位掩码和详细的语义属性，这是视频理解中的基础任务。该任务涉及数据标注困难且成本高昂，因此作者提出了一种名为VoCap的灵活视频模型，该模型能接受视频和各种模态的提示（文本、框或掩码），生成空间-时间掩码并提供对象中心的描述。此外，作者提出了一种利用现有大规模分割数据集（SAV）和伪对象描述的方法来构建标注数据集（SAV-Caption），以解决提示驱动的视频对象分割、指示表达视频对象分割和对象描述这三项任务。通过SAV-Caption以及多个图像和视频数据集进行大规模训练后，评估了模型的表现，结果显示模型在参考表达视频对象分割上取得最先进的结果，在半监督视频对象分割上表现可竞争，并且为视频对象描述建立了基准。这项工作使研究者能够利用现有的大型数据集进行大规模训练，同时提供了一个新的基准数据集供其他研究者使用和改进。", "innovation": "作者提出了一种称为VoCap的视频模型，该模型可以接受文本、框或掩码等多种模态的提示，生成空间-时间掩码，并提供对象中心的描述。利用现有大规模分割数据集（SAV）和伪对象描述的方法构建标注数据集（SAV-Caption），并通过大规模训练实现了在多个视频理解任务上的最好或竞争性结果。此外，作者还提供了一个新的基准数据集，供其他研究者使用和改进。", "conclusion": "该研究提出了一种灵活的视频模型VoCap，通过大规模训练在多种视频理解任务上取得了最好的或有竞争力的结果，并提供了一个新的基准数据集SAV-Caption以支持其他研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 通过文本记忆库增强统一异常检测模型的逻辑能力", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "异常检测由于可用的正常数据量有限而具有挑战性。现有的统一方法大多依赖于精心设计的图像特征提取器和记忆库来捕捉对象之间的逻辑关系。与这些方法不同，本文提出了一种引入文本记忆库以增强对逻辑异常的检测能力的新方法。具体地，提出了一种三层记忆框架（TMUAD）来进行统一的结构和逻辑异常检测。该框架包含一个基于提出的逻辑感知文本提取器建立的类别的文本记忆库、一个用于区分保留物体轮廓的物体级别的图像记忆库，以及一个用于结构异常检测的像素级别的图像记忆库。这些记忆体通过相互协作，使TMUAD在七个公开可用的涉及工业和医疗领域的数据集上实现了最先进的性能。", "innovation": "提出了一个三层记忆框架（TMUAD），该框架结合了类记忆库、物体记忆库和像素记忆库。通过使用文本记忆库对图像中的逻辑关系进行建模，TMUAD能够更准确地检测出逻辑异常。并且，它还通过协作的记忆库实现了结构和逻辑异常检测的统一，提高了异常检测的性能。", "conclusion": "TMUAD方法在七个公开数据集上达到了最先进的性能，涵盖了工业和医疗领域。该模型和代码已公开。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "评估GPT-5在放射肿瘤学中的基准测试：可测量的进展，但持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展现出了巨大的潜力。GPT-5是一种特别针对肿瘤学使用的新型LLM系统。这项研究通过两个互补的基准测试来评估GPT-5的表现：ACR放射肿瘤学在职考试（TXIT，2021年），含300多项选择题；以及一个包含60个代表不同疾病部位和治疗建议的真实放射肿瘤学案例集。", "innovation": "研究采用GPT-5在放射肿瘤学领域的特定应用，并通过两个基准测试来评估其性能。这些基准测试不仅可以测试其在多选题方面的表现，还可以评估其在生成真实世界放射肿瘤学治疗建议方面的表现。研究表明，GPT-5在多个方面超过了以前的模型版本。", "conclusion": "GPT-5在放射肿瘤学多选题基准测试中表现出色，准确性远超GPT-4和GPT-3.5。但是在生成真实世界放射肿瘤学治疗建议时，其正确性还有待提高，并需要专业知识的严格审核。尽管幻觉现象很少见，但实质性的错误反映了GPT-5生成的建议需要在临床应用中接受严格的专业监督。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "研究背景介绍了在四足动物运动控制中，结合视觉引导和感官反馈的重要性。当前的研究主要集中在如何利用强化学习来实现稳健的四足运动控制，尤其是在结合视觉信息和感官反馈方面。研究指出单独依赖视觉或感官反馈都难以提供足够准确和鲁棒的控制。因此，提出了一种结合两者的方法，以提高控制效果。", "innovation": "QuadKAN提出了一种基于柯尔莫戈洛夫-阿诺德网络(KANs)和样条插值参数化的跨模态策略。通过样条编码器来处理感官信息，并引入了样条融合头部来处理感官和视觉输入。该框架还采用了多模态延迟随机化(MMDR)和端到端训练方法。这些创新使策略能够更好地处理四足动物行走的间断性质，提高了样本效率，减少了动作抖动和能量消耗，并提供了可解释的姿态-动作敏感性。", "conclusion": "QuadKAN在多种地形上的评估表明，其在回报、行进距离和碰撞次数方面都优于当前最先进的基线方法。该研究展示了样条参数化策略在耐久性视觉引导的运动控制中的简单、有效和可解释的替代方案。论文将在此文章被接受后提供一个存储库。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21344", "html_url": "https://arxiv.org/abs/2508.21344", "title": "ARGS: Advanced Regularization on Aligning Gaussians over the Surface", "title_en": "ARGS: Advanced Regularization on Aligning Gaussians over the Surface", "authors": "Jeong Uk Lee,Sung Hee Choi", "background": "在计算机图形学中，从3D高斯Splatting（3DGS）重建高质量的3D网格和视觉效果仍然是一个核心挑战。即使使用如SuGaR等现有模型可以有效渲染，视觉保真度和场景一致性仍有改进的空间。", "innovation": "该工作基于SuGaR提出了两种互补的正则化策略，以解决单一高斯形状的常见限制和整体表面的连贯性问题。首先，引入一种有效的秩正则化策略，通过偏好更加平衡的“盘状”形式来避免极端的各向异性形态，进而促进稳定的表面重建。其次，集成神经SDF（Signed Distance Function）到优化过程中，并使用Eikonal损失进行正则化，以保持适当的距离属性并提供全局连续的表面先验，引导高斯朝向与底层几何更好的对齐。这两种正则化策略旨在提高高斯基元的个体精度及其整体表面行为的一致性。最终模型能够从3DGS数据中生成更准确、更具一致性的视觉效果。", "conclusion": "该模型可以使用从3DGS数据中获得更精确和连贯的视觉效果。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "多模态大语言模型能否解决Percept-V的基本感知问题？", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来，多模态大语言模型（MLLMs）在编码、数学和科学等复杂任务中展现出了出色的推理能力。然而，很少有实验评估这些模型在处理未被污染的生成图像上的简单感知任务中的表现，这些图像包含基本形状和结构。因此，本文提出一个名为Percept-V的数据集，该数据集包含总共7200张由程序生成的图像，这些图像被分为30个类别，每个类别都测试特定的视觉感知技能组合。这个数据集用于测试最新的MLLMs如GPT-4o、Gemini、Claude及大型推理模型（LRMs）如OpenAI o4-mini和DeepSeek R1的性能。研究表明，这些模型在复杂度提高时的性能显著下降，不同模型在各个类别中的表现也表现出类似的趋势，某些认知技能更为困难。", "innovation": "本文创新之处在于提出了一个新的数据集Percept-V，专门用于评估多模态大语言模型在图像基本感知任务中的表现。与之前提出的数据集不同，Percept-V的数据集涵盖了多种基本难度的感知任务，突出了多模态大语言模型在不同认知技能上的表现差异和难度", "conclusion": "实验结果显示，多模态大语言模型在Percept-V数据集上的表现会随着问题复杂性的增加而显著下降。模型在这30个类别中的表现呈现出一种趋势性，一些认知技能比其他技能更加难以处理。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21169", "html_url": "https://arxiv.org/abs/2508.21169", "title": "SYNBUILD-3D: 一种多模态、语义丰富的3D建筑模型合成数据集，细节层次为4", "title_en": "SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4", "authors": "Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer", "background": "3D建筑模型在建筑学、能源模拟和导航等领域至关重要。但由于缺乏大规模的标注数据集，自动生成高质量且信息丰富的3D建筑模型依然是一个主要挑战。", "innovation": "SYNBUILD-3D是一个包含超过620万座3D住宅建筑的大规模、多样性和多模态数据集，细节层次为4。每个建筑通过三种不同的模态表示：结构详尽的3D线框图、楼层平面图图像，以及类似LiDAR的屋顶点云。语义注释基于对应楼层平面图，包括房间、门和窗户的信息。此多模态数据集可用于开发新的生成AI算法，实现基于预定义平面图布局和屋顶几何结构的3D建筑模型自动化创建，同时确保语义几何一致性。", "conclusion": "SYNBUILD-3D提供了一个公开的数据集和代码示例，未来研究可以通过其三模态结构进一步发展生成3D建筑模型的AI算法，满足特定的建筑布局和屋顶形状需求，在保证语义与几何一致性的前提下。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21271", "html_url": "https://arxiv.org/abs/2508.21271", "title": "基于3D卷积神经网络的Mini自动驾驶汽车驾驶", "title_en": "Mini Autonomous Car Driving based on 3D Convolutional Neural Networks", "authors": "Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando", "background": "自动驾驶技术在汽车行业中越来越重要，因为它们有潜力提高车辆的安全性、效率和用户体验，从而满足对复杂驾驶辅助功能的日益增长的需求。然而，开发可靠的和可信赖的自动驾驶系统面临着包括高复杂性、长期训练时间和固有的不确定性在内的挑战。因此，Mini自动驾驶汽车（MACs）被用作一个实用的试验平台，用于在小型装置上验证自主控制方法。这种简化和成本效益高的环境促进了机器学习模型的快速评估和比较，特别是对于需要在线训练的算法。本文在此背景下分析了该研究的内容。", "innovation": "本文提出了一种基于RGB-D信息和三维卷积神经网络（3D CNNs）的方法，用于在模拟环境中实现MAC的自动驾驶。该方法将3D CNN与递归神经网络（RNNs）进行对比，评估了不同架构和赛道复杂性对模型泛化能力和车辆控制性能的影响。", "conclusion": "结果表明，3D CNN在面对不同复杂度的赛道和RNNs时表现出有希望的结果，特别是对于模型的泛化能力和车辆控制性能。该研究为自动驾驶技术的发展提供了一种新的方法，并证明了3D CNN的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21635", "html_url": "https://arxiv.org/abs/2508.21635", "title": "The Rosario Dataset v2: 多模态农业机器人数据集", "title_en": "The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics", "authors": "Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire", "background": "该研究背景在于农业环境中机器人面临的各种挑战，包括自然光照变化、运动模糊、崎岖地形以及长时间、具有感知别名的序列。这些挑战使得机器人在这些环境中的定位、制图、感知和导航变得更加复杂。", "innovation": "创新之处在于提出了一个多模态数据集，包含了大豆田地中的超过两小时的记录数据，由多种传感器（如立体红外相机、彩色相机、加速度计、陀螺仪、磁力计、GNSS（单点定位、实时动态定位和后处理差分实时动态定位）以及车轮里程计）收集。该数据集的设计旨在支持农业机器人领域中先进算法的发展和基准测试，尤其是SLAM系统的评估，以及硬件传感器同步、六自由度（6-DOF）地面真实性数据和长轨迹的闭环。", "conclusion": "该数据集展示了现有最先进的多模态SLAM方法在农业环境设置中的应用局限性。研究结果和相应的数据集及处理工具已公开发布，旨在提高农业机器人技术的发展和性能评估。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench：多模态医疗大型语言模型奖励模型和评判者基准测试", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医疗应用中具有巨大潜力，特别是在疾病诊断和临床决策领域。然而，这些任务需要高度准确、上下文相关和专业对齐的响应，因此可靠奖励模型和评判者至关重要。尽管这些模型的重要性很明显，但专用于医疗的奖励模型（MRMs）和评判者的研究仍然不足，没有专门针对临床需求的基准测试。现有基准测试主要侧重于通用MLLM能力或作为解题者来评估模型，忽略了诸如诊断准确性、临床相关性等关键评估维度。因此，他们提出了Med-RewardBench，这是首个专门针对医疗场景下评估MRMs和评判者的基准测试。", "innovation": "Med-RewardBench 引入了第一个专门设计用于评估医疗场景下 MRLMs 和评判者的基准测试。Med-RewardBench 包含跨 13 个器官系统和 8 个临床部门的多模态数据集，共有 1,026 个专家标注案例。通过严格的三步流程，确保六维临床关键维度中具有高质量的评估数据。他们还评估了 32 个最先进的 MLLMs，包括开源、专有和医疗专用模型，揭示了与专家判断对齐的巨大挑战，并开发了基准模型，展示了通过微调取得的重大性能提升。", "conclusion": "通过Med-RewardBench，研究揭示了在多模态医疗大语言模型中，将模型输出与专家判断对齐的显著挑战，并展示了通过微调基准模型实现的重大性能提升，为未来医疗场景下的MLLMs研究和应用奠定了坚实的基础。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "Morae: Proactively Pausing UI Agents for User Choices", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "用户界面（UI）代理为盲人和视力低下（BLV）用户提供了访问不常见或复杂的UI的机会。然而，现有的UI代理通常在执行任务时不需要用户的直接参与，没有让用户在关键决策点做出选择，也没有提供重要的上下文信息，从而减少了用户的主动权。我们的现场研究显示，BLV用户在要求购买最便宜的气泡水时，代理没有提供不同口味和更高评分的其他选项，而是自动选择了同等价格的某一种。因此，需要一个能够提高用户参与度和决策权的UI代理系统。", "innovation": "Morae是一个自动识别任务执行过程中的决策点并暂停等待用户做出选择的UI代理。Morae利用大规模的多模态模型，在用户查询、UI代码和屏幕截图之间进行解释，并在需要决策时向用户提出澄清请求。在真实世界web任务的研究中，Morae帮助BLV用户完成了更多的任务并选择了更符合他们偏好的选项，相比于基准代理如OpenAI Operator.", "conclusion": "Morae展示了用户与UI代理之间混合主动策略，在充分利用自动化的同时，也让用户能够表达自己的偏好。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型进行大肠3D形状细化的大肠数字模型生成", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的人体器官3D建模对于虚拟成像试验中的数字仿作构建至关重要。然而，由于复杂的几何形状和形状变化，大肠等器官的建模仍然是一个挑战。", "innovation": "提出了CLAP（条件 latent 点扩散模型），结合几何深度学习和去噪扩散模型，改善大肠的3D表示。该模型通过层次变分自动编码器学习全局和局部形态表示，并在潜空间中使用两个条件扩散模型精细器官形状。此外，还使用预训练的表面重构模型将细化后的点云转换为网格。", "conclusion": "CLAP在形状建模精度方面取得了显著改进，相对于初始次优形状，减少了26%的Chamfer距离和36%的Hausdorff距离。此方法为高保真器官建模提供了一个稳健且可扩展的解决方案，适用于各种解剖结构。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08420", "html_url": "https://arxiv.org/abs/2403.08420", "title": "工业基础模型用于低延迟工业动作识别的低成本框架", "title_en": "ALow-Cost Real-Time Framework for Industrial Action Recognition Using Foundation Models", "authors": "Zhicheng Wang,Wensheng Liang,Ruiyan Zhuang,Shuai Li,Jianwei Tan,Xiaoguang Ma", "background": "工业环境中的动作识别（AR）面临高部署成本、较差的跨场景泛化能力和有限的实时性能等挑战。尤其是在识别动作和操作手势时，这些挑战尤为突出。", "innovation": "提出了一种名为LRIAR的低成本实时框架，利用基础模型进行工业动作识别。框架通过结合Grounding DINO和预训练的BLIP-2图像编码器构建自动生成标签的数据集，实现了高效的动作标签化。利用构建的数据集对YOLOv5进行实时动作检测训练，并通过LoRA基础微调开发Vision Transformer分类器进行动作分类。实验验证了LRIAR的有效性，显示在识别精度、场景泛化能力和部署效率方面均优于现有方法。", "conclusion": "LRIAR框架在实际工业环境中验证了其有效性，在识别精度、场景泛化能力和部署效率方面均显示出一致的改进。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "激活子空间用于异常分布检测", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "在实际应用中，确保深度模型的可靠性需要识别出不在训练分布范围内的样本（即异常分布，OOD），与训练数据相似的样本称为正常分布（ID）。现有的方法主要通过分析激活值来实现OOD检测，但存在局限性。本文的背景在于提出一种新的方法来改进OOD检测的效果，特别是针对大范围分布变化的情况。", "innovation": "本文提出了一种新颖的OOD检测方法ActSub，利用分类头部权重矩阵的奇异值分解，将模型的激活分解为对最终分类输出贡献最大的显著子空间和贡献最小的不显著子空间。研究发现，不显著子空间在大范围分布变化（远异常分布，Far-OOD）条件下比原始激活更有效地区分ID和OOD样本。而在小范围分布变化（近异常分布，Near-OOD）条件下，仅考虑显著子空间可以获得更好的效果，因为不显著子空间受到目标分类任务的影响较小，从而避免了激活空间的干扰。", "conclusion": "通过结合上述两种方法，ActSub在各种标准OOD检测基准测试中取得了最先进的性能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这款图表骗我吗？自动检测误导性可视化", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性可视化在社交媒体和网络上是信息误导的重要驱动力。它们通过违反图表设计原则，扭曲数据，使读者得出不准确的结论。之前的研究表明，无论是人类还是基于多模态的大语言模型（MLLMs）都经常被这样的可视化所欺骗。自动检测误导性可视化并识别它们违反的具体设计规则有助于保护读者并减少信息误导的传播。然而，由于缺乏大型、多样和开放获取的数据集，训练和评估AI模型受到了限制。本研究中，我们介绍了Misviz，一个包含2604个带有12种误导类型的现实世界可视化基准数据集。为了支持模型训练，我们还发布了Misviz-synth，一个使用Matplotlib并基于真实数据表生成的81814个可视化合成数据集。我们使用最先进的MLLMs、基于规则的系统以及微调分类器对两个数据集进行了全面评估。结果显示，任务仍然极具挑战性。我们发布了Misviz、Misviz-synth以及伴随的代码。", "innovation": "介绍了Misviz和Misviz-synth两个数据集，这两个数据集分别是2604个带有12种误导类型的真实世界可视化基准数据集和基于Matplotlib生成的81814个合成数据集。通过使用最先进的MLLMs、基于规则的系统以及微调分类器对两个数据集进行了全面评估，展现了该任务的挑战性。", "conclusion": "项目发布了Misviz、Misviz-synth以及伴随的代码，以期为自动检测误导性可视化提供支持，从而更好地保护读者并减少信息误导的传播。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21738", "html_url": "https://arxiv.org/abs/2508.21738", "title": "从无人机影像到适宜性地图：中国农村的AI环境感知", "title_en": "From Drone Imagery to Livability Mapping: AI-powered Environment Perception in Rural China", "authors": "Weihuan Deng,Yaofu Huang,Luan Chen,Xun Li,Yao Yao", "background": "随着减贫和乡村振兴策略的深化，改善农村生活环境和提高生活质量已成为关键 priorities。当前的衡量方法存在局限性，问卷调查方法难以扩展，而面向城市的视觉感知方法不适合农村环境。基于此背景，本文提出了一种基于无人机影像和多模态大型语言模型（MLLMs）的农村特定适宜性评估框架.", "innovation": "本文创新之处在于：1) 首先使用自上而下的方法收集了来自中国146个县的1,766个村庄的大规模无人机影像；2) 开发了一种高效图像比较机制，利用二分搜索插值来确定有效图像对并减少比较轮次；3) 结合专家知识构建了一种适用于全国农村适宜性测量的链式思考提示，考虑了生活质量和生态宜居性两个维度；4) 详细分析了中国农村适宜性的空间异质性和影响因素，揭示了政府财政支出是核心决定因素.", "conclusion": "研究表明，中国的农村适宜性呈现核心-边缘的空间格局，从四川和浙江向外辐射，不同影响因素中政府财政支出是核心决定因素，每增加一个单位对应提升3.9-4.9个单位的适宜性。研究结果为中国农村建设政策制定提供了有价值的见解."}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02617", "html_url": "https://arxiv.org/abs/2504.02617", "title": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "title_en": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "authors": "Lihua Liu,Jiehong Lin,Zhenxin Liu,Kui Jia", "background": "RGB-based新型物体姿态估计对于机器人应用的快速部署至关重要，但零样本泛化仍然是一个关键挑战。现有的方法在面对新型物体时泛化能力不足，这限制了其应用范围。", "innovation": "PicoPose引入了一种新颖的框架，采用三级像素到像素对应关系的学习过程来解决这一问题。该方法首先匹配RGB观察与渲染的物体模板特征，找出最佳匹配模板并建立粗略对应关系；然后，通过全局回归2D仿射变换（包括平面内旋转、缩放和2D平移）平滑对应关系；最后，应用仿射变换到最佳匹配模板的特征图上，并在局部区域学习对应偏移来实现细粒度对应关系。通过逐步细化对应关系，PicoPose显著提高了通过PnP/RANSAC计算的物体姿态的准确性。", "conclusion": "PicoPose在BOP基准的七个核心数据集上实现了最先进的性能，展示了对新型物体的出色泛化能力。相关代码和模型可以在 provided URL 获得。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "矩形注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "在传统的卷积神经网络中，空间注意力图通常是以位置为基础生成的，这可能导致不规则的边界，从而影响新样本的泛化能力。因此，需要一种能够提供更好稳定性并能更好地泛化到新样本的空间注意力机制，同时还能提供对“模型关注哪里”问题的可解释性.", "innovation": "提出了一种易于集成到任何卷积网络的新型空间注意力模块。该模块限制注意力区域为矩形，并仅用5个参数进行参数化，从而提高了模型的稳定性和新样本的泛化能力。实验表明，该方法系统性地优于基于位置的方法，为卷积模型提供了一种新颖且有用的注意力机制，并且还能提供对模型关注输入部分的可解释性.", "conclusion": "通过引入矩形注意力模块，该研究提供了一种能够更好地稳定训练、具有更好泛化能力和可解释性的空间注意力机制。实验结果表明该模块的有效性，并指出该模块适用于任何卷积网络中，可以提升模型的预测性能."}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.13073", "html_url": "https://arxiv.org/abs/2501.13073", "title": "CHaRM: 基于条件热图回归方法的精准快速牙科解剖标记定位", "title_en": "CHaRM: Conditioned Heatmap Regression Methodology for Accurate and Fast Dental Landmark Localization", "authors": "José Rodríguez-Ortega(1 and 2),Francisco Pérez-Hernández(1),Siham Tabik(2) ((1) Nemotec, Madrid, Spain, (2) Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain)", "background": "在正畸治疗中，3D牙科模型中的解剖标记识别至关重要，但手动放置非常耗费人力且需要专业知识。尽管提出了使用机器学习方法的自动3D口腔扫描（IOS）中的标记检测方案，但这些方法通常需要牙齿分割，这会增加成本并可能导致数据丢失。现有方法无法提供一种避免繁琐牙齿分割的端到端解决方案。因此，当前研究旨在提出CHaRM（条件热图回归方法），这是一种新的端到端的深度学习方法，用于直接在3D IOS点云上进行牙齿标记检测，提升了检测准确性，减少了计算成本，避免了错误传播，操作更简单。", "innovation": "CHaRM是一种新颖的端到端全深学习方法，它将四个组件（点云编码器、带有热图回归头部的解码器、牙齿存在的分类头部以及新颖的CHaR模块）结合起来。CHaR模块利用牙齿存在的信息，适应缺失牙齿的情况，从而提高了在复杂牙科案例中的检测准确性。相比两阶段工作流，先分割牙齿再进行标记，CHaRM直接在IOS点云上操作，简化了流程，减少了复杂性并降低了计算成本。通过使用PointMLP作为其骨干网络，在IOSLandmarks-1k数据集上，CHaRM表现最好，具有最高的准确性和效率。CHaRNet相较于最先进的方法在标准牙列模型上的平均欧氏距离误差减少了0.56 mm，在所有牙齿类型上的误差减少了1.12 mm，且在GPU上的推断速度提高了14.8倍。这更加连贯的端到端流程简化了正畸工作流程，并提高了3D IOS分析的精度，同时也能实现高效的计算机辅助治疗规划。", "conclusion": "CHaRM作为一种全新的端到端的方法，简化了正畸工作流程，在不依赖牙齿分割的情况下直接在3D IOS点云上实现牙齿标记的精准、快速定位。CHaRM在准确性和效率方面显著优于现有方法，并为后续研究提供了更加连贯和高效的正畸应用方法。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "使用最小标签通过自我监督最大化肾小球分割", "title_en": "Maximising Kidney Glomeruli Segmentation using Minimal Labels via Self-Supervision", "authors": "Zeeshan Nisar,Thomas Lampert", "background": "组织病理学通过对组织样本进行显微镜检查，对于疾病诊断和预后至关重要。准确地分割和识别病理图像中的关键区域对于开发自动化解决方案是极其重要的。然而，最先进的深度学习分割方法，如UNet，需要大量的标签，这不但成本高且耗时。特别是在多种染色的情况下，获得这些标签更加困难，大大限制了其应用。因此，各种多染色分割方法（例如UDA-GAN）被开发出来，这些方法减少了一部分标签的需求，只需一个（源）染色被标记即可。然而，在没有可用源染色标签时，分割模型的表现会下降。为了解决这个问题，研究人员利用自我监督预训练（包括SimCLR、BYOL及一种新颖的方法HR-CS-CO），表明可以大幅减少对标记数据的需求，而仍然保持高质量的分割性能。", "innovation": "本文提出了一种通过自我监督预训练（包括SimCLR、BYOL及新方法HR-CS-CO）减少标签需求的技术，即使只用5%的标签，UNet和UDA-GAN的性能也基本保持不变，相较于全监督的情况，性能下降仅5.9%和6.2%。此外，这种方法还展示了良好的泛化能力，能够在公共基准数据集上表现良好。", "conclusion": "通过自我监督预训练的方法，即使只使用少量的标签，也可以保持较好的病理图像分割性能。这种方法不仅减少了数据标注的工作量，还展示了在不同数据集上的泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16430", "html_url": "https://arxiv.org/abs/2503.16430", "title": "连续和离散tokens的桥梁：用于自回归视觉生成", "title_en": "Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation", "authors": "Yuqing Wang,Zhijie Lin,Yao Teng,Yuanzhi Zhu,Shuhuai Ren,Jiashi Feng,Xihui Liu", "background": "自回归视觉生成模型通常依赖于生成器将图片压缩为可以顺序预测的token。但token表示存在根本性的困境：离散token便于使用标准交叉熵损失进行建模，但会损失信息且在训练标注器时不稳定；连续token则更好地保留了视觉细节，但是需要复杂的分布建模，这些细节使得生成流程变得复杂。", "innovation": "本文提出了TokenBridge，它通过保持连续token的强大表征能力同时也保留离散token的建模简单性来弥合这两种token表征的差距。具体而言，通过后训练量化策略将离散token从连续表示直接获取，并引入了一种维度间的量化策略独立地对每个特征维度进行离散化。同时配合一种轻量级的自回归预测机制，高效地对生成的大量token空间建模。", "conclusion": "实验结果显示，该方法在重建和生成质量上达到了与连续方法相同的效果，同时使用标准的类别预测。这项工作证明了弥合离散和连续范式的桥梁可以有效地利用两种方法的优点，为高质量的视觉生成提供了简单自回归建模的一个有希望的方向。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导技术是扩散模型中广泛使用的方法，用于提升样本质量。技术上，这种指导通过使用一个比主要模型更普遍的辅助模型来实现。作者通过一个2D的玩具示例，展示了当辅助模型具有类似但更强的泛化误差时，这种做法非常有益。基于此洞察，作者引入了无需训练的全新方法——遮蔽滑动窗口指导（M-SWG），该方法通过局部地限制主要模型的 receptive field（感受野），增强长距离空间依赖关系的权重。此方法无需访问以前迭代的模型权重、额外训练或类别条件。与之前的无需训练的方法相比，M-SWG 在 inception 分数 (IS) 方面表现出更优的效果，且未引入样本过度饱和的问题。同时，M-SWG 结合现有的指导方法，使用 EDM2-XXL 和 DiT-XL，达到了在 ImageNet 上的 Fréchet DINOv2 距离的最优结果。", "innovation": "本文提出了 M-SWG（遮蔽滑动窗口指导），一个全新的无需训练的方法。M-SWG 通过限制主要模型的 receptive field 来提升长距离空间依赖关系，同时不需要访问先前迭代的模型权重，无需额外训练，也不需要类别条件。与其他现有方法相比，M-SWG 在 inception 分数 (IS) 方面表现更优，且未引入样本过度饱和的问题。结合现有的指导方法，M-SWG 使用 EDM2-XXL 和 DiT-XL，达到了在 ImageNet 上的最佳 Fréchet DINOv2 距离结果。", "conclusion": "本文提出了一个新的无需训练的方法 M-SWG，通过局部地限制主要模型的 receptive field 来增强长距离空间依赖关系。实验结果表明，M-SWG 在 inception 分数方面表现更优，解决了样本过度饱和的问题。结合现有的指导方法，M-SWG 达到了在 ImageNet 上的最优结果。该方法已经在代码库中开源。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14156", "html_url": "https://arxiv.org/abs/2502.14156", "title": "Mixed Signals: 一种用于异构LiDAR V2X协作的多样化点云数据集", "title_en": "Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration", "authors": "Katie Z Luo,Minh-Quan Dao,Zhenzhen Liu,Mark Campbell,Wei-Lun Chao,Kilian Q. Weinberger,Ezio Malis,Vincent Fremont,Bharath Hariharan,Mao Shan,Stewart Worrall,Julie Stephany Berrio Perez", "background": "车辆到万物（V2X）协作感知作为解决单一车辆感知系统限制的一种有前景的解决方案已经出现。然而，现有的V2X数据集在范围、多样性和质量方面存在局限。为了弥补这些不足，我们介绍了一个综合的V2X数据集——Mixed Signals，该数据集包含来自三个连接的自动驾驶车辆（CAVs）的45.1万点云和240.6万个边界框，这些车辆装备了两种不同配置的LiDAR传感器，以及一个道路旁单位，配备了双LiDAR。", "innovation": "Mixed Signals数据集提供了涵盖10个类别的点云和边界框注释，确保了感知训练的质量数据。该数据集在质量和标注方面进行了详尽的统计分析，并对现有V2X方法进行了广泛的基准测试。此数据集具有精确对齐和时间及视角一致的注释，易于使用，可供直接利用。", "conclusion": "Mixed Signals数据集为异构LiDAR V2X协作提供了准备就绪的一站式解决方案。该数据集旨在满足感知训练对高质量数据的需求，并提供了可靠的质量保障和广泛的基准测试结果，适用于V2X系统的技术评估与研发工作。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.01627", "html_url": "https://arxiv.org/abs/2408.01627", "title": "基于混合Transformer-Mamba模型的语音驱动3D头部动画生成JambaTalk", "title_en": "JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model", "authors": "Farzaneh Jafari,Stefano Berretti,Anup Basu", "background": "近年来，生成技术的研究重点之一是嘴巴动画的生成，包括提高口型同步效果、捕捉面部表情，并生成自然的头部姿态。尽管取得了一定进展，但现有模型尚未在所有定量和定性指标上达到等效效果。", "innovation": "提出了一种结合Transformer和Mamba模型的混合模型Jamba，利用Mamba模型的结构状态空间模型架构来克服传统Transformer模型在处理长序列数据时的局限性，实现了更全面的解决方案。在此基础上，提出了JambaTalk，通过多模态集成增强了运动多样性和口型同步。", "conclusion": "大量实验表明，该方法在性能上达到了甚至超越了最先进的模型。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12868", "html_url": "https://arxiv.org/abs/2504.12868", "title": "使用多模态3D数据的个性化咬合定位护板计算机辅助设计", "title_en": "Computer-Aided Design of Personalized Occlusal Positioning Splints Using Multimodal 3D Data", "authors": "Agnieszka Anna Tomaka,Leszek Luchowski,Michał Tarnawski,Dariusz Pojda", "background": "数字技术在设计个性化医疗设备，如用于管理口腔颌系统紊乱的咬合板中发挥着关键作用。本文介绍了一种基于计算机辅助的方法，用于设计和评估咬合定位护板，旨在在前期临床试验阶段证明该方法的可行性和几何准确性。", "innovation": "提出了一个创新的方法，用于生成可以在治疗位置精确复现咬合条件的护板，并通过虚拟刻压解决表面冲突。文中还描述了使用牙科工具和常用的口腔内设备获取转换矩阵的过程，这些设备用于牙科和实验室工作流，并通过外形和表面偏差分析评估设计和打印护板的几何准确性。", "conclusion": "该方法支持可重复的、针对患者的护板制造，并为未来的验证研究提供了一个透明的基础，支持多模式图像注册和在研究环境中量化咬合差异。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02176", "html_url": "https://arxiv.org/abs/2505.02176", "title": "Saliency-Guided Training for Fingerprint Presentation Attack Detection", "title_en": "Saliency-Guided Training for Fingerprint Presentation Attack Detection", "authors": "Samuel Webster,Adam Czajka", "background": "注意力引导训练（Saliency-guided training）通过指导模型学习图像中重要的区域，已经在多种生物特征呈现攻击检测（Biometric Presentation Attack Detection, PAD）任务中证明了泛化性能的提升。本文首次将注意力引导训练应用到指纹PAD领域。作者通过一个包含800个人工标注的重要区域图的实验数据集，以及算法生成的伪注意力图（包括细节特征、图像质量以及自动编码器生成的注意力图），来进行研究。", "innovation": "本文介绍了将注意力引导训练首次应用于指纹PAD领域的研究。通过广泛探讨五种不同的训练场景中的各种配置，评估了注意力引导训练对准确性和泛化的影响。结果表明，这种训练方法在数据有限和大规模数据两种情况下都具有有效性，并且通过特定的配置，可以在LivDet-2021基准测试中获得第一名。", "conclusion": "研究结果强调了注意力引导训练在提升模型泛化能力、在数据有限条件下有效以及在指纹PAD领域大规模数据应用的潜力。所有收集的注意力数据和训练模型都随论文一起发布，以支持复现研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种固有可解释的视网膜基金图病变检测的混合全卷积CNN-Transformer模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "在许多医疗成像任务中，卷积神经网络（CNNs）能够有效地逐层提取局部特征。近期，视觉变压器（ViTs）由于其使用自注意力机制来捕捉全局依赖关系而受到青睐，但它缺乏卷积的固有空间局部化。因此，结合了CNNs和ViTs的混合模型被开发出来以结合这两种架构的优势。然而，这样的混合模型难以解释，限制了它们在医疗成像中的应用。本文介绍了一种为固有可解释设计的混合全卷积CNN-Transformer架构，用于视网膜疾病检测。", "innovation": "与广泛使用的后验梯度方法不同，本文的方法生成忠实且局部化的证据图，可以直接反映模型的决策过程。该模型在两个基于颜色视网膜图像的医疗任务上进行了评估，相比黑盒模型和可解释模型，该模型获得了最先进的预测性能，提供了一次前向传递中的特定类别的稀疏证据图。代码在此：this https URL.", "conclusion": "本文提出了一种固有可解释的混合全卷积CNN-Transformer架构，通过直接反映模型的决策过程并提供单次前向传递中的特定类别的稀疏证据图，实现了视网膜疾病检测的最佳预测性能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR：用于纵向放射学报告生成的动态差异感知时序残差网络", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "放射学报告生成（RRG）通过自动化从医学成像中生成报告来提高报告过程的效率。纵向放射学报告生成（LRRG）进一步扩展了RRG的功能，能够对比当前和以往的检查，从而跟踪临床发现随时间的变化。现有的LRRG方法仅从当前和之前的图像中提取特征，并通过视觉预训练编码器进行合并，生成最终报告。然而，这些方法在特征提取过程中难以有效捕捉空间和时间之间的关联，导致提取出的特征未能充分反映出跨检查之间的差异信息，无法充分代表预期的变化，从而降低了LRRG的性能。", "innovation": "我们开发了一种新的动态差异感知时序残差网络（DDaTR）。在DDaTR中，通过在视觉编码器的每个阶段引入两个模块来捕捉多层空间关联。动态特征对齐模块（DFAM）用于在不同模态之间对齐先前特征，以保持先前临床信息的完整性。通过增强的先前特征，动态差异感知模块（DDAM）能够捕获检查之间的有利差异信息，识别跨检查的相关性。此外，我们采用的动态残差网络能够单向传递纵向信息，从而有效建模时间关联。", "conclusion": "在三个基准上的广泛实验表明，DDaTR在LRRG任务上的表现优于现有方法，证明了其在RRG和LRRG任务中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过Dirac重平衡器和分布纠缠实现单域交叉癌症多模态 prognostics", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据进行生存预测方面表现出色。然而，现有的多模态方法主要集中在单一癌症类型，并忽视了跨癌症场景中的泛化挑战。本研究揭示了在跨癌症场景中多模态预后模型泛化能力往往不如单一模态模型，尽管这种稳健性在临床实践中至关重要。", "innovation": "本文提出了一个新的任务：跨癌症单域泛化多模态预后，评估在单一癌症类型上训练的模型是否能够泛化到未见的癌症。提出了两种模块：稀疏狄拉克信息重新分配器（SDIR）和癌症感知分布纠缠（CADE）。SDIR通过基于贝努利的稀疏化和狄拉克启发的稳定化来减轻强特征的主导地位，从而增强较弱模态的信号。CADE aims to合成目标域分布，融合局部形态学线索和全局基因表达在潜在空间中。", "conclusion": "在包含四种不同癌症类型的基准数据集上进行的实验结果表明，这些方法具有优越的泛化性能，为实现实用和稳健的跨癌症多模态预后奠定了基础。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12420", "html_url": "https://arxiv.org/abs/2507.12420", "title": "InterpIoU：基于插值IoU优化的边界框回归重新思考", "title_en": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization", "authors": "Haoyuan Liu,Hiroshi Watanabe", "background": "边界框回归（BBR）是物体检测的基础，其中回归损失对于精确定位至关重要。现有的基于IoU的损失通常会引入手工设计的几何惩罚，以解决非重叠情况下IoU的非可微性问题，并提高边界框回归性能。然而，这些惩罚对盒子的形状、大小和分布高度敏感，经常导致小型物体优化效果不佳，并且可能会因为与IoU目标的对齐不当导致边界框扩大等问题。", "innovation": "本文提出了InterpIoU，这是一种新的损失函数，用基于插值框与目标IoU的术语取代了手工设计的几何惩罚。通过使用插值框来弥补预测和真实之间的差距，InterpIoU可以在非重叠情况下提供有意义的梯度，并自然避免了由惩罚不匹配引起的边界框扩大问题。仿真实验进一步证明，IoU本身是一个理想的目标回归目标，而现有的几何惩罚既没有必要，又不合适。在此基础上，我们提出了动态InterpIoU，它根据IoU值动态调节插值系数，提高了对具有不同物体分布场景的适应性。实验表明，我们的方法在COCO、VisDrone和PASCAL VOC数据集上均优于最先进的基于IoU的损失函数，尤其是在小型物体检测方面表现尤为突出，证实了其有效性", "conclusion": "我们的方法在各种检测框架中持续优于最先进的基于IoU的损失，尤其是在小型物体检测方面表现出显著的改进，验证了其有效性"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07313", "html_url": "https://arxiv.org/abs/2508.07313", "title": "DocR1：多页文档理解的证据页引导GRPO", "title_en": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding", "authors": "Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li", "background": "当前的大规模多模态语言模型（MLLM）在理解多页文档时面临显著挑战，需要细致的视觉理解和跨页的多跳推理。尽管先前的研究探索了强化学习（RL）以增强MLLM的高级推理能力，但在多页文档理解中的应用仍被很大程度上忽视。现有的多页文档理解模型在复杂推理任务上的表现还存在不足，尤其是在处理需要跨多页的信息时存在局限性。因此，需要开发新的方法以克服现有模型的限制，提高多页文档理解和推理能力。", "innovation": "本文提出了一种基于新型RL框架——证据页引导GRPO（EviGRPO）的多页文档理解方法，EviGRPO包含了一种证据感知的奖励机制，促使模型采取粗到细的推理策略，在获取相关信息后生成答案。这种方法能够以较少的监督构建高质量的模型。此外，还设计了一种两阶段标注流程和课程学习策略，基于此构建了两个数据集：包含4800个样例的高质量训练数据集EviBench，以及包含8600个问答对的评估基准ArxivFullQA，用于评估文档理解模型的表现。实验结果显示，DocR1在多页任务上达到了最先进的性能，同时在单页基准上也保持了强劲的结果。", "conclusion": "本文通过引入DocR1模型，结合Evidence Page-Guided GRPO框架，有效克服了现有模型在理解多页文档过程中的问题。所提出的模型在多个基准测试中展示了卓越的性能，并且通过特定的数据集和标注策略增强了其鲁棒性和泛化能力，为后续的研究提供了有益的方法和数据支持。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "在体外受精（IVF）治疗中的胚胎选择深度学习模型的解释", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不育对个人的生活质量影响很大，社会上和心理上都有影响，预计此问题将在未来几年加剧。体内受精（IVF）在经济发达国家中已成为应对日益严重的人口稀少问题的主要技术之一。胚胎学家通过审查囊胚图像来手工分级胚胎以进行移植，但这个过程耗时且效率低下。囊胚图像为评估胚胎存活提供了有价值的资源，但这一过程仍然依赖人为判断。因此，需要一种有效的方法来优化这一流程，以提高IVF的效率和成功率。", "innovation": "本文提出了一个具有解释性的AI框架（XAI），通过结合卷积神经网络（CNN）和长短期记忆（LSTM），实现了高精度的胚胎分类，同时保持了模型的可解释性，从而提高了IVF过程中胚胎选择的效率和准确性。", "conclusion": "本研究提出的方法通过使用深度学习技术提高了IVF中胚胎选择的准确性，且使用XAI技术保持了决策的可解释性，有助于提高整体的治疗效果，减少治疗不确定性和心理负担。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 自主学习识别手写数学", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式（HMER）识别是一项具有挑战性的任务，因为其固有的二维结构、标志符的不同比例以及符号间的复杂空间关系。", "innovation": "本文提出了一种自主监督学习（SSL）框架，用于消除昂贵的标记数据需求。本文的关键贡献是提出了一种新颖的自主监督注意力网络，该网络使用渐进空间遮罩策略进行训练，以学习具有语义意义的关注区域，如运算符、指数以及嵌套的数学符号。这种方法不需要任何监督，能够增强网络对缺失或遮挡的视觉信息的鲁棒性，从而提高结构理解能力。", "conclusion": "在CROHME基准上的大量实验表明，本文的方法优于现有的SSL和完全监督基线，证实了我们的渐进注意力机制在提升HMER性能方面的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04061", "html_url": "https://arxiv.org/abs/2507.04061", "title": "短视频虚假信息检测中的一致性和不变性泛化学习", "title_en": "Consistent and Invariant Generalization Learning for Short-video Misinformation Detection", "authors": "Hanghui Guo,Weijie Shi,Mengze Li,Juncheng Li,Hao Chen,Yue Cui,Jiajie Xu,Jia Zhu,Jiawei Shen,Zhangze Chen,Sirui Han", "background": "短视频中的虚假信息检测在多模态领域引起了广泛关注，目的是准确识别视频格式及其相应的音频伴随下的虚假信息。尽管取得了显著进展，但现有模型在特定领域（源域）训练时，在未见过的新领域（目标域）上的性能常常不尽如人意，主要是由于领域间的差异。为了更好地实现短视频虚假信息检测任务中的跨领域泛化，本文深入探讨了不同领域的特点：一方面，各领域检测主要依赖于不同模态（主要是视频或音频）；因此，为了提高跨领域泛化能力，同时优化所有模态的性能至关重要。另一方面，对于侧重跨模态联合欺诈的领域，跨模态融合分析是必需的，但也会导致每个模态中的领域偏差（特别是在视频的每一帧中），严重损害最终的虚假信息识别。", "innovation": "本文提出了一个新的通过一致性与不变性学习实现短视频虚假信息检测中的领域泛化的模型（DOCTOR模型）：1) 利用跨模态特征插值将多种模态映射到共享空间，并采用插值蒸馏同步多模态学习；2) 设计了扩散模型，通过跨模态引导去噪来增加不变特征，保留模态的核心特征。实验表明DOCTOR模型的有效性，我们的代码将在提供的链接进行公开发布。", "conclusion": "广泛的实验证明了DOCTOR模型的有效性，通过一致性与不变性学习，该模型成功实现了短视频虚假信息检测任务中的跨领域泛化。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA: 植物科学中用于视觉语言模型基准测试的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA是基于广泛使用的PlantVillage图像数据集构建的大型视觉问答（VQA）数据集，旨在推动农业决策和分析中视觉语言模型的发展与评估。数据集包含14种作物种类和38种疾病条件下的55,448张高质量图像，并涵盖193,609个高质量的问答（QA）对。该数据集的构建通过两阶段自动化的模板基问答合成和多层次语言重构，并由领域专家进行多次审查以确保科学准确性和相关性，最终使用三个最先进的模型进行质量评估。它为植物疾病诊断的准确性和农业领域科学研究的进步提供了一个公开的、标准化且由专家验证的数据库。", "innovation": "PlantVillageVQA数据集创新地通过自动化的模板基问答合成和多层次的语言重构生成高质量的问答对，并通过领域专家的多次审查确保科学准确性，提供了一个可用于评估农业和植物科学中视觉语言模型性能的标准数据集。", "conclusion": "最终目标是提供一个公开的、标准化且由专家验证的数据集，以提高植物疾病诊断的准确性并促进农业领域的科学研究。PlantVillageVQA数据集将在此网址公开：this https URL."}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT — 一种新型通道增强混合CNN变压器，具备残差、空间和边界感知学习，用于脑肿瘤MRI分析", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤一直以来都是最致命的人类疾病之一，早期检测和准确分类对于有效诊断和治疗计划至关重要。尽管基于深度学习的计算机辅助诊断（CADx）系统已经取得了显著的进步，但传统的卷积神经网络（CNNs）和Transformers仍然面临高计算成本、对微小对比度变化的敏感性、结构异质性和MRI数据中的纹理不一致性等持续挑战。", "innovation": "该研究提出了一种新型混合框架CE-RS-SBCIT，它集成了残差和空间学习驱动的CNNs与transformer驱动模块。该框架通过四个核心创新点来利用局部精细和全局上下文线索：(i) 平滑和边界基于的CNN-integrated Transformer (SBCIT)；(ii) 专门设计的残差和空间学习CNNs；(iii) 通道增强(CE)策略；(iv) 新颖的空间注意力机制。SBCIT还采用了茎卷积和上下文交互transformer块以及系统的平滑和边界操作，以实现高效的全局特征建模。残差和空间CNNs通过辅助转移学习的功能图增强表示空间，CE模块放大了判别性的通道并且减少了冗余，而空间注意力机制强调了肿瘤类别的细微对比和纹理变化。", "conclusion": "在Kaggle和Figshare等具有挑战性的MRI数据集上进行的广泛评估表明，该框架具有出色的表现，准确率达到98.30%，灵敏度为98.08%，F1分数为98.25%，精确度为98.43%。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18539", "html_url": "https://arxiv.org/abs/2508.18539", "title": "3D RPG中的自适应视觉导航助手", "title_en": "Adaptive Visual Navigation Assistant in 3D RPGs", "authors": "Kaijie Xu,Clark Verbrugge", "background": "在复杂的3D游戏环境中，玩家依靠视觉暗示来识别地图过渡点。高效地识别这些过渡点对于客户端自动制图非常重要，并且为地图线索呈现的客观评估提供了基础。这项工作正式化了检测可通行的时空转换点（STP）的任务，即连接两部分区域的连接器，并选择玩家当前宏观目标的设计师意图的关键路径上的单一主要时空转换点（MSTP），这是从单帧游戏画面中提出的新研究方向。", "innovation": "提出了一种两阶段深度学习管道，首先使用Faster R-CNN检测潜在的STP，然后用融合局部和全局视觉特征的轻量级MSTP选择器对其进行排名。引入了高效的模型适配器，并进一步引入了一个可选的检索增强融合步骤。这项工作的主要目标是确立该问题的可行性，并设定基线性能指标。基于一个从五个动作RPG游戏中构建的多样性数据集进行验证。研究揭示了一个关键的权衡：尽管整个网络微调在有足够数据的情况下能够实现卓越的STP检测，但仅使用适配器的微调对低数据场景和MSTP选择任务更加稳健有效。", "conclusion": "通过定义这个新颖的问题，提供基线管道和数据集，并提供有关高效模型适配的初步见解，我们将为未来的AI驱动导航辅助和数据驱动级面设计工具的开发做出贡献。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: 一个用于齐性预测的Python库", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "齐性预测（CP）是一种强大的统计框架，它能够生成具有保证覆盖概率的预测区间或集子。尽管CP算法已经从传统的分类器和回归器发展到了复杂的深度学习模型，如深度神经网络（DNNs）、图神经网络（GNNs）和大型语言模型（LLMs），但现有的CP库往往缺乏支持大规模DL场景的模型和扩展性。因此，研究人员和从业者在使用这些模型时面临着限制。", "innovation": "这篇论文介绍了一个名为TorchCP的PyTorch原生库，它是专门为将最先进的CP算法集成到深度学习技术中而设计的，包括基于DNN的分类器/回归器、GNN和LLMs。TorchCP具有16000多行代码，并且经过100%的单元测试覆盖和详细的文档验证。TorchCP支持CP特定的训练算法、在线预测和GPU加速批量处理，可以实现大型数据集上90%的推理时间减少。其设计理念低关联性、全面性的高级方法套件和全面的GPU可扩展性，使研究人员能够增强对前沿应用中的不确定性量化的能力。", "conclusion": "TorchCP是一个功能强大的齐性预测库，它可以直接用于集成最先进的深度学习技术，并增强了对不确定性的量度能力。它具有广泛的适用性和强大的扩展性，为科研和实战开发提供了有力支持。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19650", "html_url": "https://arxiv.org/abs/2508.19650", "title": "Video-LevelGauge: 调查大型视频语言模型中的上下文位置偏见", "title_en": "Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models", "authors": "Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang", "background": "大型视频语言模型（LVLMs）在视频理解方面取得了显著进展，推动了相应的评估基准的发展。然而，现有的基准通常只评估整个视频序列的整体性能，忽视了诸如上下文位置偏差这样的细微行为，这是LVLM性能的一个关键但未充分探索的方面。", "innovation": "本研究提出了Video-LevelGauge，这是一种专门设计来系统评估LVLMs中位置偏差的基准。该基准采用了标准化的探针和定制化的上下文设置，可灵活控制上下文长度、探针位置和上下文类型，以模拟各种现实场景。此外，研究引入了一种综合分析方法，结合统计措施和形态学模式识别来表征偏差。基准包括438个手动挑选的视频，涵盖了多种类型，产生了1,177个高质量的选择题和120个开放式问题，这些问题已经验证了其在暴露位置偏差方面的有效性。", "conclusion": "研究结果揭示了许多领先开源模型中的显著位置偏见，通常表现出头部或邻近内容偏好。相比之下，商业模型如Gemini2.5-Pro在整个视频序列中表现出一致的出色性能。进一步分析上下文长度、上下文变化和模型规模为缓解偏见和指导模型增强提供了行动指南。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07134", "html_url": "https://arxiv.org/abs/2504.07134", "title": "CAD中原生表示学习的注意力机制", "title_en": "Bringing Attention to CAD: Boundary Representation Learning via Transformer", "authors": "Qiang Zou,Lizhen Zhu", "background": "随着以Transformer网络为代表的生成性人工智能的兴起，这种技术已经在自然语言处理、计算机视觉和图形学等领域取得了显著成果。然而，在计算机辅助设计（CAD）领域，特别是对于边界表示（B-rep）模型的处理，Transformer的应用仍然鲜有探索。", "innovation": "为了填补这一空白，本文提出了一种名为边界表示Transformer（BRT）的新颖方法，用于适应B-rep学习。BRT通过连续的几何嵌入方法将B-rep曲面（修剪和未修剪）编码为Bezier三角形，保持其形状和连续性而不进行离散化。此外，BRT采用了一种拓扑感知嵌入方法，将这些几何嵌入组织成适合Transformer的离散标记序列，从而捕捉B-rep模型中的几何和拓扑特征。这种方法使得Transformer的注意力机制能够有效地学习边界元素在B-rep模型中的形状模式及上下文语义。", "conclusion": "全面的实验展示了BRT在子部件分类和特征识别任务上达到了最先进的性能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解任意视频中的相机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "相机运动理解是一个重要的研究领域，但现有的评估和改进方法有限，尤其是在理解场景内容相关的运动时。本文通过CameraBench数据集和基准测试提出了一种新的方法，以便更好地评估和提升对相机运动的理解。", "innovation": "1. 开发了一个涵盖约3000个 diverse互联网视频的CameraBench数据集，这些视频经过专家严格的多阶段质量控制过程进行注释。2. 提出了与电影摄影师合作开发的相机运动基本单元分类框架。3. 进行了一项大规模的人类研究，以量化人类注释的性能，发现领域知识和基于教程的培训可以显著提高准确性。4. 通过CameraBench评估了结构从运动（SfM）和视频-语言模型（VLM）的方法，揭示了SfM模型和VLM模型各自的局限性。5. 使用CameraBench微调了一个生成性VLM模型，以结合两者的优势，应用于运动增强的图像说明、视频问答和视频-文本检索。", "conclusion": "本文提出的Taxonomy、基准测试和教程有望推动未来对在任何视频中理解相机运动的研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 基于提示注入攻击的网络代理", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "当前的研究集中在多模态大型语言模型（MLLM）驱动的网络代理通过基于网页截图生成动作与网页环境互动。尽管MLLM在自动化任务中展现出了强大的能力，但它们也面临着被恶意篡改的风险。本文探讨了通过在网页环境中注入篡改来诱导网络代理执行攻击者指定动作的问题。这种篡改影响了网络代理的行为，使得它偏离了预期的任务目标。", "innovation": "提出了WebInject攻击方法，这是一种提示注入攻击。WebInject通过在网页渲染后的原始像素值中添加扰动来操纵网页环境。作者创新地训练了一个神经网络来近似映射原始像素值和截图之间的关系，并使用投影梯度下降法解决了优化问题，从而能够有效地操控网络代理执行攻击者的指定行为。", "conclusion": "广泛的实验结果表明，WebInject攻击方法非常有效，并且显著优于基准方法。该研究揭示了大型语言模型驱动的网络代理在实际应用中可能遭受的安全威胁，并提供了一种通过注入式攻击方法来改进安全性和防御策略的新思路。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中视觉信息的融合与分解在机器人操作中的应用", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉技术因其在操作中的应用而广为人知，尤其是在视觉伺服机制中的应用。由于现实世界具有三维特性，使用多摄像头视图并进行合并可以提供更好的代表，进而训练更为有效的策略。然而，多视图策略对于故障摄像头的敏感度高，并且在部署时存在负担问题。", "innovation": "我们提出了一个名为MAD的算法，它可以在同时将多视图合并以提高样本效率的同时，通过将多视图特征输入与单视图特征增强来分解视图。这产生了一种鲁棒的策略，并允许轻量化部署。", "conclusion": "我们使用Meta-World和ManiSkill3展示了我们方法的效率和鲁棒性。项目网站和代码链接见：https URL"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.08906", "html_url": "https://arxiv.org/abs/2409.08906", "title": "高斯即应有之义：通过扩散后验采样解决逆问题的统一框架", "title_en": "Gaussian is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling", "authors": "Nebiyou Yismaw,Ulugbek S. Kamilov,M. Salman Asif", "background": "扩散模型能够生成多种高质量图象，通过建模复杂数据分布。训练后的扩散模型也可作为有效的图像先验，用于解决逆问题。现有基于扩散的方法在反向采样过程中通过近似似然函数来整合数据一致性步骤，但是这些近似方法要么不足，要么计算效率低下。文章指出这些问题，并提出了一种统一的似然函数近似方法，通过引入协方差矫正项来提高性能并避免在反向扩散采样过程中反向传播梯度。", "innovation": "提出了一个统一的似然函数近似方法，引入协方差矫正项，从而避免了在反向扩散采样过程中反向传播梯度，提高了性能并更好地收敛于真实数据后验。同时，还提供了一种高效的方法，对多个逆问题中似然函数的协方差矩阵进行因式分解和求逆。实验证明了该方法优于多种现有方法。", "conclusion": "本文通过引入协方差矫正项的统一框架，显著改进了现有扩散模型在解决逆问题中的表现。该方法在多个真实世界的自然图像数据集上表现良好，而且结果表明方法的有效性超过了多种现有的方法。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19762", "html_url": "https://arxiv.org/abs/2508.19762", "title": "BuzzSet v1.0: 实验条件下传粉昆虫检测的数据集", "title_en": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "authors": "Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher", "background": "传粉昆虫如蜜蜂和大黄蜂对全球粮食生产和生态系统稳定至关重要，但由于人类活动和环境压力，它们的数量正在减少。在农业环境中实现大规模、自动化的监测仍然是一个开放的挑战，原因是难以检测到这些小、快速移动且经常伪装的昆虫。为此，研究人员提出了BuzzSet v1.0，这是一个在真实田间条件下收集的高分辨率传粉昆虫图像的大规模数据集，包含7,856张手工验证的图像以及超过8,000个注释实例，分为蜜蜂、大黄蜂和未识别昆虫三个类别。该数据集旨在应对传粉昆虫持续下降的问题，为生态计算视觉领域提供了基准数据集，强调在植被中经常伪装的昆虫检测的可靠性检测是一个公开的问题，需要进一步研究。", "innovation": "提出了BuzzSet v1.0数据集，这是首个在真实田间条件下收集的高分辨率传粉昆虫图像的大规模数据集，包含7,856张手工验证的图像和超过8,000个注释实例。数据集中的图像经过预处理，分为三个类别，且可以用于评估生物视觉环境下的昆虫检测能力，提供了可靠的传粉昆虫检测数据，可为自动化精准农业生产提供支持。", "conclusion": "BuzzSet展示了高分辨率传粉昆虫图像数据集，为改善生态计算视觉中的黄蜂和蜜蜂检测精度进行了基准测试。最终 Maps@0.5 显示出挑战性的性能，但仍为未来的小物体检测策略提供了重要的线索，数据集将扩展到v2.0以支持进一步的研究。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07331", "html_url": "https://arxiv.org/abs/2507.07331", "title": "mmFlux：使用商用毫米波MIMO雷达分析人群流动", "title_en": "mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar", "authors": "Anurag Pallaprolu,Winston Hurst,Yasamin Mostofi", "background": "本文介绍了利用毫米波雷达提取人群流动底层模式并推断人群语义的新框架。传统的传感器和分析方法难以准确捕捉大型人群的复杂流动模式和语义信息。", "innovation": "mmFlux框架利用了毫米波雷达的概念，结合了视觉领域的光学流估计和新的统计及形态噪声过滤方法，提出了基于流动场生成高效矢量表示的方法，并将其转化为定向几何图，通过局部雅可比矩阵分析和旋度以及散度的计算，成功提取群体流动的关键语义。", "conclusion": "本文通过21个实验，展示了mmFlux框架即使面对复杂人群模式时，也能实现高质量的图结构重构，并且对关键群体语义的推断非常准确。该研究成果为各种人群分析应用提供了强有力的支撑，表明mmFlux具有广泛的应用潜力。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03729", "html_url": "https://arxiv.org/abs/2505.03729", "title": "视觉模仿使类人机器人能够在不同环境条件下执行任务", "title_en": "Visual Imitation Enables Contextual Humanoid Control", "authors": "Arthur Allshire,Hongsuk Choi,Junyi Zhang,David McAllister,Anthony Zhang,Chung Min Kim,Trevor Darrell,Pieter Abbeel,Jitendra Malik,Angjoo Kanazawa", "background": "研究如何通过利用环境上下文来教会类人机器人上楼梯和坐在椅子上。传统的教法需要手动编写复杂的控制策略。本文探讨了一种简单的方法，即通过自动捕捉人类行为视频并让机器人学习这些动作，来实现类人机器人的人类行为模仿。研究提出了VIDEOMIMIC，这是一种从现实到模拟再到现实的流程，能够提取日常视频中的信息，同时重构人类和环境，生成能够执行相应技能的全身控制策略。该研究展示了该管道在实际类人机器人上的效果，展示了在不同环境条件下执行的稳健且可重复的全身控制技能，包括上楼梯、坐椅子等动态技能。", "innovation": "VIDEOMIMIC 提出了一种名为“从现实到模拟再到现实”的流程机制，用于从现实生活中的视频数据中学习人类运动技能，并生成类人机器人能够执行相应技能的控制策略，这是一个系统化的、能够规模化的解决方案，相比之前的孤立训练方法，能够更有效地应用到不同的实际环境条件下。", "conclusion": "该研究展示了VIDEOMIMIC管道的有效性，通过单个策略实现了在不同环境条件下的类人机器人控制。这种视觉模仿方法为未来的类人机器人运行在复杂多变的真实世界环境中提供了一条可行的途径。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20835", "html_url": "https://arxiv.org/abs/2508.20835", "title": "PointDGRWKV: 将RWKV类似架构推广到未见过的领域进行点云分类", "title_en": "PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification", "authors": "Hao Yang,Qianyu Zhou,Haijia Sun,Xiangtai Li,Xuequan Lu,Lizhuang Ma,Shuicheng Yan", "background": "点云分类（PCC）模型的通用化能力近年来通过域泛化（DG）得到了提高，尤其是在未见过的领域中。然而，现有的基于卷积网络、Transformer或Mamba架构的方法要么受制于有限的感受野或高计算成本，要么缺乏对长期依赖关系建模。RWKV作为一种新兴的架构，具备优越的线性复杂度、全局感受野和长期依赖性，但直接将其应用到PCC的DG任务中存在显著挑战，如固定方向的令牌移位方法引入了空间失真，削弱了局部几何建模和鲁棒性，以及Bi-WKV注意力机制通过指数加权放大了跨域关键特征分布的差异，导致注意力偏移并降低了泛化能力。", "innovation": "本文提出了PointDGRWKV，一种专门为DG PCC定制的基于RWKV的框架，通过引入两个关键模块来增强空间建模和跨域鲁棒性，同时保持RWKV的线性效率。具体来说，PointDGRWKV引入了自适应几何令牌移位来建模局部邻域结构，以提高几何上下文意识，以及跨域关键特征分布对齐来通过关键特征分布的对齐来减轻注意力漂移。", "conclusion": "全面的实验表明，PointDGRWKV在DG PCC中达到了最先进的性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "SWIFT消息对手方的特征提取与聚类规范化", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "短文本聚类是文本分析领域的一个已知用例。当文本内容和结构属于自然语言领域，如Twitter帖子或即时消息时，可以使用自然语言技术，前提是文本长度足够长，以便使用预训练模型提取有意义的信息（如词性或主题标注）。然而，自然语言模型不适合用于银行支付系统中的交易对手方聚类，因为这些对手方通常包含物理或法律实体的详细信息，缺乏句法规则，同时包含人工输入引入的所有变体和噪声。这在需要扩充支付流程起点和受益实体的知识，以及追踪资金和资产时，给调查人员或欺诈防控专业人士带来了工具缺口。传统上，供应商试图使用模糊匹配工具填补这一缺口。背景信息中考虑了这点。", "innovation": "本研究提出了一种混合字符串相似度、主题建模、层次聚类和规则基础的工作流程，用于聚类银行支付系统中的交易对手方，能够处理不确定数量的预期聚类。同时，研究还基于精确度和召回率提出了补充评估指标。在实际带标签的数据集上的测试结果表明，该方法相比基于规则基础（关键词）的方法具有显著的性能提升。此外，该方法保留了基于规则系统的一部分可解释性，通过在后者基础上增加一层聚类细化。这种工作流程减少了人工审核的需求。对于仅需调查小部分人群的情况（如制裁调查），该方法可根据实体变体更好地控制风险。", "conclusion": "该研究方法在实际应用中的表现优于传统的基于规则的基础方法，同时通过增加的一层聚类细化提高了系统的可解释性，减少了审核工作量。对于只需审查部分人群（如制裁调查）的场景，该方法可以更好地控制实体变体遗漏的风险。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：医疗AI中的强化学习是决定性的跨越", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）标志着人工智能在医疗健康应用中的根本转变。与仅预测结果的传统模型不同，RL系统通过试验、反馈和长期奖励优化来学习，为医疗健康带来了变革可能性和新的风险。从信息融合的角度来看，RL通常整合诸如生命体征、实验室检查、临床笔记、影像和设备遥测等多源信号，并通过时间性和决策级机制进行操作。这些系统可以在集中、联邦或边缘架构中运行，以适应实时临床需求，并自然跨越数据、特征和决策融合层级。本调研旨在探讨RL在医疗健康中的崛起，不仅仅是作为一种工具，而是向临床环境中的主动型智能转变。", "innovation": "本文首次从医疗约束的角度结构化了RL技术景观，包括基于模型和无需模型的方法、离线和批次约束方法，以及通过奖励规范和不确定性校正的新兴策略。本文详细分析了RL在危重护理、慢性病、心理健康、诊断和机器人辅助等领域的应用趋势、差距和转化瓶颈。我们对RL的伦理、部署和奖励设计挑战进行了批判性分析，并综合了安全、人本对齐政策学习的经验教训。", "conclusion": "本文不仅提供了一种技术支持路径，还对RL在医疗AI中的新兴变革角色进行了批判性反思，认为RL不仅仅是预测工具，而是作为具代理性的临床智能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19297", "html_url": "https://arxiv.org/abs/2506.19297", "title": "基于显式残差的针对人类和机器的可扩展图像编码", "title_en": "Explicit Residual-Based Scalable Image Coding for Humans and Machines", "authors": "Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe", "background": "可扩展图像压缩技术通过渐进方式重建不同要求下多种版本的图像。近年来，图像不仅被人类消耗，也越来越多地被图像识别模型使用，这使得针对人类和机器视觉的可扩展图像压缩方法受到了更多关注。许多现有模型使用基于神经网络的编解码器（称为学习型图像压缩），并通过精心设计损失函数取得了显著进步。然而，部分模型过度依赖学习能力，而其架构设计尚未充分考虑。", "innovation": "本文通过引入显式残差压缩机制提升ICMH框架的编码效率和可解释性。这一机制在分辨率可扩展编码方法（如JPEG2000）中已广为应用。文中提出了两种互补的方法：特征残差导向的可扩展编码（FR-ICMH）和像素残差导向的可扩展编码（PR-ICMH），可以应用于多种机器视觉任务。这些方法提供了在编码复杂度和压缩性能之间进行选择的灵活性，使其适应各种应用需求。实验结果表明，PR-ICMH比之前的工作在BD率上节省了高达29.57%。", "conclusion": "实验结果证明了所提方法的有效性，通过引入显式残差压缩机制，本文在提升编码效率和增强可解释性的同时，为机器视觉任务提供了更高的灵活性和适应性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO：基于预估值的策略优化方法在代理推理中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "无监督强化学习方法，特别是群体策略，由于其在复杂任务中的高效性而受到广泛关注。然而，这些方法依赖于策略内部的多次采样和比较来估算优势，这可能导致策略陷入局部最优，增加计算成本。", "innovation": "提出了PVPO，一种通过预估值的方法增强的高效强化学习方法，采用优势参考锚点和数据预采样技术。具体来说，使用预演算模型并利用计算的奖励分数作为参考锚点，有效校正了内部群体比较引入的累积偏见，显著减少了对策略展开次数的依赖。此外，预演算模型可以在数据预采样期间评估样本难度，允许有效选择高增益数据以提高训练效率。", "conclusion": "在两个领域九个数据集上进行的实验表明，PVPO达到了SOTA性能。该方法不仅跨多个任务展现出了稳健的泛化能力，还展示了对不同规模模型的可扩展性能。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02512", "html_url": "https://arxiv.org/abs/2508.02512", "title": "QuaDreamer：用于四足机器人的可控全景视频生成", "title_en": "QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots", "authors": "Sheng Wu,Fei Teng,Hao Shi,Qi Jiang,Kai Luo,Kaiwei Wang,Kailun Yang", "background": "全景相机能够采集360度的环境数据，适用于四足机器人周围感知和与复杂环境的交互。然而，由于固有的运动学限制和复杂的传感器校准挑战，高质量的训练数据稀缺，这从根本上限制了针对这些实体平台的鲁棒感知系统的开发。因此，有必要开发专门面向四足机器人的全景数据生成引擎来解决这一问题。", "innovation": "本文提出了一种专门针对四足机器人的全景数据生成引擎——QuaDreamer。QuaDreamer通过模仿四足机器人的运动模式，生成高度可控且逼真的全景视频，用于下游任务的数据源。此外，引入了垂直抖动编码（VJE），有效地捕捉四足运动中的垂直振动特性，并通过场景-物体控制器（SOC）有效管理物体运动，增强了背景抖动控制，通过注意力机制。还提出了一种全景增强器（PE），结合了频率-纹理细化和空间-结构校正，以解决宽视场视频生成中的全景失真问题。", "conclusion": "生成的视频序列可以作为四足机器人全景视觉感知模型的训练数据，提升全景场景中多目标跟踪的性能。源代码和模型权重将在https://link提供给公众。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "区域级上下文感知多模态理解", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大语言模型（MLLMs）方面取得了显著进步，现有研究主要集中在通用视觉理解上，忽视了对与物体相关的文本上下文进行整合的能力，这被称为区域级上下文感知多模态理解（RCMU）。因此，论文提出了RCMU任务，旨在通过整合图像内容和文本信息来提高模型的上下文感知能力。", "innovation": "本文提出了Region-Level Context-aware Visual Instruction Tuning（RCVIT），将对象信息融入模型输入，并允许模型使用边界框坐标有效关联视觉内容和文本信息，针对缺少数据集的问题，本文构建了RCMU数据集，一个涵盖多种RCMU任务的大型视觉指令调优数据集，同时也提出了RC&PBench，一个全面的基准工具，用于评估MLLMs在RCMU和多模态个人化理解任务中的性能，还提出了一种无参考评估指标，对区域级上下文感知图像描述进行了全面而细致的评估。", "conclusion": "通过在Qwen2-VL模型上实施RCVIT并使用RCMU数据集，我们开发了RC-Qwen2-VL模型。实验结果表明，RC-Qwen2-VL模型不仅在多个RCMU任务中表现出色，还成功应用于多模态RAG和个性化对话。研究数据、模型和基准已于网站上发布。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "一个增强注意机制、双向长短时记忆神经网络的解释性48小时联合温度、辐射度和相对湿度预测", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "本文介绍了一种基于深度学习（DL）的框架，用于对温度、太阳辐射和相对湿度进行48小时预测，以支持智能建筑暖通空调（HVAC）系统的模型预测控制（MPC）。历史气象数据（2019-2022年）结合编码的循环时间特征进行训练，2023年的数据用于验证泛化能力。", "innovation": "该方法采用了堆叠的双向长短期记忆（BiLSTM）网络结合注意力机制，可以同时预测三个变量，并捕捉时间序列和多变量之间的依赖关系。通过集成梯度量化特征贡献和注意力权重揭示时间模式，增强解释性。这种方法结合了多变量预测、基于注意力的DL和可解释性，推进了数据驱动的天气预测。", "conclusion": "实验结果表明该模型在温度、辐射度和湿度预测上的绝对均方误差分别为1.3℃、31 W/m²和6.7百分点，优于最先进的数值天气预报和机器学习基准。通过可靠的短期气象预测，该框架展示了其在能源高效建筑控制领域的潜在应用价值。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从朗 Ellis 差分稳定性到接近 MCMC 对非对数凹分布采样的收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "在非凸潜在函数的情况下，未调整的拉格朗日算法（ULA）用于采样分布的稳定性得到了研究。然而，在图像逆问题等上下文中，潜在函数通常是非凸且非光滑的。此时，近邻随机梯度拉格朗日算法（PSGLA）广受青睐，它通过结合前向后向优化算法与ULA步骤来处理这些问题。", "innovation": "文章证明了在无限处具有强凸性的潜在函数下，离散时间的ULA的稳定性。利用Moreau包络的性质，首次证明了PSGLA在非凸潜在函数下的收敛性。实验证明PSGLA在后验采样的速度上优于随机梯度拉格朗日算法，同时保持其恢复特性。", "conclusion": "研究结果表明，在非凸分布采样中，PSGLA通过组合优化算法和ULA步骤，提供了提高收敛性和保持恢复性能的方案。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "使用代理AI进行自适应异常检测的Deep Space Network数据系统自动化", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "NASA的深空网络（DSN）是其最大的天线设施网络，生成大量多元时间序列数据。这些设施中的DSN天线和发射器会随时间退化，可能会导致数据流中断，威胁到依赖DSN维持生命线的数十艘太空船的地球连接。研究目的是通过收集的数据辅助JPL工程师直接定位异常和设备退化，以持续进行DSN的维护和运营，支持未来在我们宇宙中的太空任务。因此，研究和研究了各种机器学习技术来完全重建数据并通过预测分析确定实时数据集中的异常数据条目，使用强化学习子系统根据严重程度分类识别的异常，并利用大规模语言模型为每个异常数据条目提供解释。特别是对于DSN发射器，还实现了一个完整的数据管道系统来连接数据提取、解析和处理工作流程。", "innovation": "研究了机器学习（ML）和强化学习（RL）技术，通过预测分析完全重建数据，并使用统计计算和阈值在实时数据集中确定异常数据条目。研发了一个完整的数据管道系统，用于DSN天线数据的提取、解析和处理；结合了强化学习子系统来根据严重程度分类识别的异常，并利用大规模语言模型为每个异常数据条目提供解释。通过人类反馈/输入来改进和微调模型。", "conclusion": "通过机器学习和强化学习技术的结合使用，成功实现了DSN数据系统的自动化，包括数据提取、解析和处理，以及异常检测。使用代理AI系统实现了复杂推理，确定了异常数据的分类和预测，提高了DSN的稳定性和可靠性，为未来太空任务提供了支持。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "全矩阵预条件矩阵的动态低秩近似用于训练广义线性模型", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "适应性梯度方法如Adagrad及其变体在大规模优化中广泛应用，但它们使用的对角预条件矩阵限制了捕获参数相关性的能力。完全矩阵适应性方法，近似计算精确海森矩阵，可以建模这些相关性并可能实现更快的收敛速度。然而，这些方法的计算和内存成本通常对大规模模型来说是不可行的。因此，我们需要一种能够有效实现全矩阵适应性梯度更新且减少计算和内存开销的方法。", "innovation": "提出了AdaGram优化器，能够有效实现全矩阵适应性梯度更新。通过利用快速对称因子化计算每个迭代中的预条件更新方向来减少内存和计算开销，并使用矩阵积分方法在优化轨迹中保持预条件器的低秩结构。实验证明，使用秩五及更小秩的近似时，AdaGram收敛速度更快或与对角适应优化器表现相当，这表明AdaGram作为大规模模型自适应优化的可扩展解决方案具有潜力。", "conclusion": "实验结果显示，使用秩五及更小秩的近似时，AdaGram要么比对角适应优化器收敛得更快，要么与其具有相同性能。这表明AdaGram具有成为大规模模型自适应优化的可扩展解决方案的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE: 柔性遗忘算法在树集合中的应用", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "树集合在分类任务中表现出色，尤其是在生物信息学、金融和医学诊断等领域。随着对数据隐私和被遗忘权利的重视，提出了多种遗忘算法以使树集合能够忘记敏感信息。但现有方法多针对特定模型或依赖于树的离散结构，难以适应复杂集合并处理大规模数据集。", "innovation": "本文提出了FUTURE，一种针对树集合的新型遗忘算法。FUTURE将遗忘样本问题转化为基于梯度的优化任务，并采用概率模型近似来解决树集合的非可微性问题，实现了高效且端到端的遗忘过程。", "conclusion": "在真实数据集上的广泛实验表明，FUTURE在遗忘性能上取得了显著的成功。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21146", "html_url": "https://arxiv.org/abs/2508.21146", "title": "通过局部似然攻击审计合成数据发布中的隐私", "title_en": "Privacy Auditing Synthetic Data Release through Local Likelihood Attacks", "authors": "Joshua Ward,Chi-Hua Wang,Guang Cheng", "background": "审计合成数据泄露隐私是一项重要但尚未解决的问题。现有的合成数据隐私审计框架大多依赖于启发式方法和不合理的假设来攻击生成模型的失败模式，这些方法在描述和检测通过合成数据发布训练数据的隐私暴露方面能力有限。", "innovation": "本文提出了生成似然比攻击（Gen-LRA），这是一种新颖且计算效率高的无盒MIA方法，它通过评估测试观察对替代模型对合成数据局部似然比估计的影响来实施攻击，而不需假定模型知识或访问权限。", "conclusion": "在涵盖多种数据集、模型架构和攻击参数的基准测试中，Gen-LRA在多个性能指标上均优于其他生成模型的MIA。这些结果证明了Gen-LRA作为审计合成数据发布隐私的有效工具的能力，并强调了生成模型过拟合在实际应用中的重大隐私风险。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: 向更高效和强大的持续学习框架迈进", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "在持续学习(CL)中，平衡对新任务的敏感性和保留过去知识的稳定性是至关重要的。虽然尖锐度感知最小化近期在迁移学习中取得了成功，并且被应用于持续学习以提高记忆保留和学习效率，但仅仅依赖于零阶尖锐度可能在某些场景中偏好更尖锐的最小值，而非更平坦的最小值，从而可能导致不够稳健和潜在的次优解。现有研究对此问题有所忽视。本文研究了如何平衡这一矛盾，并提出了C-Flat方法，旨在为持续学习提供更平坦的损失景观。此外，还提出了一种通用框架，将C-Flat整合到所有主要的持续学习范式中，并通过与损失最小值优化器和基于平坦最小值的持续学习方法进行了全面比较。实验结果表明，C-Flat在多种场景下能够持续提高性能。此外，还提出了C-Flat++框架，通过选择性地驱动平坦性来优化，显著降低了C-Flat的更新成本。", "innovation": "- 提出了C-Flat方法，旨在为持续学习提供更平坦的损失景观。\n- 提供通用框架，将C-Flat整合到所有主要的持续学习范式中。\n- 实现全面的比较，展示其在损失最小值优化器和基于平坦最小值的持续学习方法中的优势。\n- 引入了C-Flat++框架，通过选择性地驱动平坦性优化，显著减少更新成本。\n- 提供便捷的插件功能，易于集成，无需大量代码修改。", "conclusion": "C-Flat和C-Flat++在广泛设置下持续提高了持续学习的性能，展示了有效性与效率。研究结果表明，C-Flat和C-Flat++框架在多个持续学习方法、数据集和应用场景中均具有优势。代码库已开源。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "使用混合深度学习的严肃游戏中基于空间-时间的脑电图情绪识别", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "近年来，基于脑电图（EEG）的情绪识别在使用深度学习和传统机器学习方法时显示出有希望的结果；然而，大多数现有研究仅仅集中于二元情绪正负极性预测或特定个体分类，这限制了其在实际情感计算系统中的普适性和部署。因此，该领域仍然存在需要解决的问题，即如何通过单一框架提供更加通用的情感识别解决方案，尤其是需要涵盖多级粒度的情感分类，以更好地捕捉不同情境下的情绪变化并将其应用到实际情感计算系统中。", "innovation": "本文提出了一种基于GAMEEMO数据集的统一、多层次脑电情绪识别框架，该框架包括14通道EEG记录及其情绪评级（无聊、糟糕、平静、有趣）从28个参与者的四种情绪诱导游戏场景中连续收集的情绪自我报告评分。文章采用了结构化的预处理策略，包括时间窗口分割、混合统计和频域特征提取以及z分数标准化，以将原始EEG信号转换为稳健的、区分性强的输入向量。通过二元情感极性分类、多级情感分类和细粒度多标签表示三个互补维度，实现了多元情绪分类。文中评估了随机森林、XGBoost、SVM等传统模型以及LSTM、LSTM-GRU和CNN-LSTM等深度神经网络模型，其中LSTM-GRU在二元情绪极性任务中获得了0.932的F1得分，在多级和多标签情绪分类中分别获得了94.5%和90.6%的准确性，进而提高了情绪识别的准确性和效率，克服了现有研究的单一粒度和有限覆盖范围的不足。", "conclusion": "本文通过利用Gameemo数据集构建了一个多层次的脑电情绪分类框架，并采用混合深度学习方法，有效提升了二元情绪正负极性预测、多级情绪分类以及细粒度多标签表示的情绪识别性能。该研究不仅克服了现有研究的局限性，展示了在实际应用中的潜力，而且为未来的脑机接口和情感计算提供了有力的理论支持和技术基础。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21141", "html_url": "https://arxiv.org/abs/2508.21141", "title": "在预算约束下的自适应大语言模型路由", "title_en": "Adaptive LLM Routing under Budget Constraints", "authors": "Pranoy Panda,Raghav Magazine,Chaitanya Devaguptapu,Sho Takemori,Vishal Sharma", "background": "大语言模型(LLMs)在自然语言处理中发挥了革命性的作用，然而其能力的差异性和高昂的成本在实际应用中带来了挑战。现有的LLM路由方法通过监督学习解决这个问题，但它们依赖于对查询-模型最佳匹配的完全了解。然而，实际场景中无法获得这种全面的映射，并且面对不断变化的用户查询。因此，提出将LLM路由视为一个上下文臂bandit问题，允许通过使用bandit反馈进行适应性决策，而不需要对所有查询对所有模型进行广泛推理。", "innovation": "提出了一种新颖的上下文arm bandit方法来处理LLM路由的问题，这种方法通过构建查询和模型之间的共享嵌入空间来实现。这个空间通过离线的人类偏好数据进行初始化，并通过在线的bandit反馈进行优化。还引入了成本控制策略，该策略被建模为一个多选择背包问题，以确保资源高效利用。", "conclusion": "该研究通过PILOT算法为多变的用户预算下的模型路由提供自适应解决方案，该方法通过共享嵌入空间和上下文bandit反馈有效地选择了最适合的模型。这种方法确保了不仅能够适应不同的用户查询和偏好，而且能够在预算限制下进行有效的资源分配和利用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深 Residual 回声态网络：浅谈未训练的循环神经网络中的残差正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "回声态网络（ESNs）是一种特殊的未训练循环神经网络（RNNs）类型，属于回声计算（RC）框架。它们以其快速和高效的训练方式而受到欢迎。然而，传统的ESNs在处理长期信息时常常存在困难。本文探讨了一种基于时间残差连接的深层未训练RNN——深度残差回声态网络（DeepResESNs）。通过构建不训练的残差递归层的层次结构，这种方法显著提高了内存容量和长期时间建模能力。", "innovation": "提出了一种基于时间残差连接的深层未训练RNN——DeepResESN。通过构建层次结构的不训练残差递归层，这种方法在回声计算框架中显著增强了内存容量和长期时间建模能力。对于时间残差连接，考虑了随机生成和固定结构的不同正交配置，并研究了它们在神经网络中的动态效应。此外，进行了数学分析以确保DeepResESN中的动态稳定。", "conclusion": "实验表明，相对于传统的浅层和深层回声计算，所提出的方法在各种时间序列任务中具有明显的优势。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "模型-任务对齐驱动不同的强化学习结果", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "近年来，将强化学习（RL）应用于大规模语言模型（LLMs）取得了显著进展。但观察到一系列与直觉不符的现象，特别是在LLMs中的表现，这些现象在传统的RL设置中并不常见。例如，一个单一的训练样本可以达到与整个数据集相同的效果，奖励信号不需要非常准确，并且仅使用负样本的训练可以与甚至超越基于奖励的方法相媲美。然而，这些观察结果在一个怎样的条件下成立，又在何种条件下失败，尚不明确。", "innovation": "本文通过系统且全面地检查一系列与直觉不符的主张，并通过严格的实验验证确认，这意味着标准RL训练在各种设置中一直保持稳健性。然而，许多看似反直觉的结果只在模型与任务已表现出强烈的模型-任务对齐时才出现。相反，在更具挑战性的领域中，标准RL方法仍然有效，而这些技术无法在这些领域驱动重要学习。", "conclusion": "本文发现，模型-任务对齐的程度是区分RL结果的关键因素。具体而言，在模型-任务对齐程度较强的场景下，反直觉的结果更容易发生；而在挑战性更大的设置中，标准RL方法仍然是有效的。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "外部气动增强代理模型中专家混合门网络", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "高保真计算流体动力学（CFD）模拟在汽车设计和优化周期中的计算成本仍然是一个重要的瓶颈。虽然基于机器学习（ML）的代理模型被看作是一种有希望的加速气动预测的替代方案，但该领域具有多样化且快速发展的专业神经网络架构，目前没有单一模型表现出普遍的优越性。", "innovation": "本文提出了一种新颖的元学习框架，利用不同架构的多样性作为优势。研究通过一个专家混合（MoE）模型，利用专用门控网络动态和最优地结合三种异构且前沿的代理模型：分解多尺度神经操作符（DoMINO）、可扩展多尺度图神经网络（X-MeshGraphNet）和因式分解的隐式全局卷积网络（FigConvNet）。此门控网络学习一个空间变权重策略，根据每个专家在其预测表面上的压力和壁剪切应力场方面的地方表现赋予权重。为了防止模型崩溃并鼓励各个专家均衡贡献，将熵正则化项整合进训练损失函数中。整个系统在公共基准数据集DrivAerML上进行训练和验证，这是一个大规模的高保真CFD模拟数据集，专门用于汽车气动学。定量结果显示，MoE模型在预测误差的L-2误差上显著减少，不仅优于各个专家模型的平均值，还优于最准确的单一专家模型。", "conclusion": "这项工作通过协同结合专门架构的互补优势，确立了MoE框架作为创建更稳健和准确的结合代理模型的强大且有效的策略。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21261", "html_url": "https://arxiv.org/abs/2508.21261", "title": "Owen取样加速联邦学习中贡献估计", "title_en": "Owen Sampling Accelerates Contribution Estimation in Federated Learning", "authors": "Hossein KhademSohi,Hadi Hemmati,Jiayu Zhou,Steve Drew", "background": "联邦学习（FL）通过聚合多个客户端的信息而不暴露原始数据来训练共享的全局模型。准确估计每个客户端的贡献不仅是公平奖励的关键，也是选择最有用客户端、使全局模型更快收敛的关键。谢皮利值是一种合适的选择，但由于其精确计算会随着客户端数量的增加而呈指数级增长，因此对于大型联邦网络来说实际上是不可行的。", "innovation": "本文提出了FedOwen框架，该框架通过使用Owen取样来在与现有方法相同的时间里近似计算谢皮利值，同时保持了较小的近似误差。此外，FedOwen采用了自适应客户端选择策略，既能发挥高价值客户端的功能，又能探索被低估的客户端，从而降低了偏差并揭露了稀有的但具有信息价值的数据。", "conclusion": "在固定估值成本下，与先进的基准相比，FedOwen在非数据同态（非-IID）基准测试中可以实现同一数量的通信轮次下最高的23%的最终准确率。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21273", "html_url": "https://arxiv.org/abs/2508.21273", "title": "CALM: 连续、自适应和大规模语言模型介导的时序流异常检测框架", "title_en": "CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams", "authors": "Ashok Devireddy,Shunping Huang", "background": "在工业和科学领域中，非平稳时序流中的异常检测是一项至关重要的但极具挑战性的任务。传统的离线训练模型在面对概念漂移时表现不佳，即数据的基本统计特性随时间变化，这些模型会产生显著的性能下降。", "innovation": "该论文提出了一种名为CALM（连续、自适应和大规模语言模型介导）的新型端到端框架，用于实时异常检测。CALM框架的核心贡献在于两个方面：一是实现了一个闭环连续微调机制，使异常检测模型能够近乎实时地适应变化的数据模式；二是引入了大规模语言模型作为裁判组件，用于对检测到的异常提供语义、上下文相关的判断，从而提高训练数据的质量，并判断异常是否代表短暂噪音或重要的模式变化。", "conclusion": "我们在全面的TSB-UAD基准上评估了CALM。结果表明，持续微调模型在大多数数据集中的ROC AUC评分高于静态、预先训练的基础模型，验证了自适应和大规模语言模型指导的方法在动态流环境中保持高性能异常检测的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO: 记忆生成的离线巩固方法在终身学习系统中的应用", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "连续或终身学习的目标是开发出能够在任务序列中从新数据中获取知识而不失去先前学习内容的模型。现有方法通常依赖于存储以前任务的数据样本（体验回放）或使用复杂的正则化项来保护已学习的权重，但这些方法面临着数据隐私问题、存储限制以及在任务差异较大时性能下降的挑战。", "innovation": "我们提出了MyGO（Memory Yielding Generative Offline-consolidation）框架，灵感来自生物的清醒-睡眠周期。在“清醒”阶段，系统快速学习新任务并训练一个紧凑的生成模型（生成记忆G-mem）来捕捉数据分布。在“睡眠”阶段，系统进入离线状态，利用所有已学到的G-mem模型生成伪数据（梦境），并通过知识精炼将新旧知识合并到核心特征提取器中。这种方法避免了存储任何原始数据，仅保留紧凑的生成模型，从而在数据隐私和存储效率方面具有明显优势。", "conclusion": "我们在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准测试中评估了MyGO，发现它在对抗灾难性遗忘和保持跨任务高平均准确率方面表现出色，证明了该框架的有效性和通用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "从仿射动态到Softmax平衡的下一词预测流形轨迹", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "语言模型中的解码过程常被描述为词元评分并用softmax进行规范化。本文提供了这一过程的简化、自含解释，将其视为概率单纯形上的约束变分原理。离散情况下，这种规范化尊重上升过程是经典的一次加权（熵镜像）更新；其连续时间极限是仿射流。通过这些组成部分，作者证明，在固定上下文和温度的情况下，下一词分布内的平滑轨迹会在单纯形内部演化，并最终收敛至softmax平衡。", "innovation": "本文提出了将解码过程视为概率单纯形上的约束变分原理的新视角，特别是证明了温度作为时间的精确缩放因子，以及top-k和nucleus采样如何限制流并保持相同的保证。此外，还概要介绍了路径依赖评分调整及其与类似于幻觉的行为之间的关系。", "conclusion": "证明了在固定上下文和温度的情况下，下一词分布的平滑轨迹会收敛至softmax平衡，为下一词预测提供了一种流形轨迹的正式形式化描述。此外，精确描述了温度、采样方法对解码过程的影响，并提出了对路径依赖评分调整及其幻觉行为之间联系的控制性描述。未来的工作将会涉及训练动态和内部表示的研究。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21300", "html_url": "https://arxiv.org/abs/2508.21300", "title": "改进基于LoRA的LLM去学习的鱼er信息估计和效率", "title_en": "Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning", "authors": "Yejin Kim,Eunwon Kim,Buru Chang,Junsuk Choe", "background": "大型语言模型（LLMs）在各种任务上表现出色，但也面临无意中生成包含敏感信息输出的问题。一种直接的解决方法是排除有问题的数据重新训练模型，但这种方法计算成本高昂。因此，机器遗忘（机器去学习）作为一种可能的解决方案出现，可以在不需要从头开始重新训练模型的情况下有效移除敏感信息。", "innovation": "我们提出了VILA（可视化遗忘适配器），这是一种新的去学习框架，它明确考虑了FILA（参数效率遗忘适配器）中忽视的基本假设，从而增强了参数识别的准确性。VILA通过使未识别模型参数减轻计算成本，实现了比FILA高100倍的参数效率和40倍的训练速度，同时在TOFU、WMDP和MUSE基准上的性能达到了新的最佳水平。", "conclusion": "我们的研究成果表明，VILA比现有的方法更加高效且准确。我们还展示了这种方法在各种基准测试中的优越表现，代码已在指定的网址上公开。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21270", "html_url": "https://arxiv.org/abs/2508.21270", "title": "Guess-and-Learn (G&L): 衡量冷启动适应的累积错误成本", "title_en": "Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation", "authors": "Roland Arnold", "background": "机器学习模型的评估通常侧重于最终准确度，而忽视了从头学习的成本，即模型在处理未标记数据集时累积犯的错误。现有的学习范式主要集中在模型的终态表现，而忽略了其在逐步学习过程中的适应性问题，如适配速度、选择质量和偏见等动态。《Guess-and-Learn (G&L) v1.0》旨在解决这一问题，通过评估一种新的适配性指标，即冷启动适应性，来弥补这一研究空白。", "innovation": "《Guess-and-Learn (G&L)》引入了一种新的评估框架，通过跟踪模型在逐步对未标记数据集进行标签化时的累积错误，来量化模型的冷启动适应性。该框架将学习过程划分为四个不同维度（从零开始/预训练 × 在线/批量更新），从而能够分离出初始化策略和更新频率的影响。此外，该研究还为MNIST数据集提供了一个“先见之明”的基准参考带，用以评估模型在早期学习阶段的表现差异，更全面地评估了模型的适应性。", "conclusion": "通过量化早期学习的成本，Guess-and-Learn (G&L) 补充了传统基准测试，并提供了一个可重复的评估框架，该框架不仅衡量模型的最终准确性，还评估了模型从第一个例子开始的可靠性。该研究揭示了当前模型与先见之明基准参考带之间的差距，即适应性方面的不足，这将鼓励研究者进一步优化模型在真实世界任务中的早期适应性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21240", "html_url": "https://arxiv.org/abs/2508.21240", "title": "使用自组织映射和变分自编码器进行合成重播的类增量持续学习", "title_en": "Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay", "authors": "Pujan Thapa,Alexander Ororbia,Travis Desell", "background": "介绍了基于自组织映射（SOMs）和变分自编码器（VAEs）的生成持续学习框架，旨在实现内存高效的重放，无需存储原始数据样本或任务标签，特别适用于高维输入空间（如CIFAR-10和CIFAR-100）和低维输入空间（如MNIST和FashionMNIST）。随着模型在未来的学习迭代中运行，SOM会在每个SOM单元上存储运行时的均值、方差和协方差，从这些数据生成合成样本。这种方法已经在标准的类增量基准上展示了竞争力，并且在CIFAR-10和CIFAR-100上优于最先进的基于记忆的方法，显著提高了类增量单类性能接近10%和7%。此外，这种方法还促进了学习过程的可视化，并可以在训练后作为生成模型使用，表明这是一个可扩展、不依赖任务标签且内存高效的持续学习解决方案。", "innovation": "提出了一种新颖的基于SOM和VAE的生成持续学习框架，能够在高维输入空间（如CIFAR-10和CIFAR-100）和低维输入空间（如MNIST和FashionMNIST）中有效工作。通过生成合成样本来实现内存高效的重放，无需存储原始数据样本或任务标签。这种方法具有可扩展性，且无需依赖任务标签，其性能在标准的类增量基准上与最先进的基于记忆的方法竞争，同时优于无记忆方法，在CIFAR-10和CIFAR-100的类增量单类性能上分别提高了近10%和7%。此外，该方法便于学习过程的可视化，并可训练后作为生成模型使用。", "conclusion": "该工作展示了一种可用于持续学习的高效解决方案，适用于高维度和低维度输入空间，并且可以生成合成样本而无需消耗大量的内存，具有较好的性能提升。此外，该方法提高了学习过程的可可视化性，并可以训练后的生成模型使用，是正处于发展阶段的持续学习领域的积极贡献。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21278", "html_url": "https://arxiv.org/abs/2508.21278", "title": "肌电激活中领域偏移的检测：流式学习中的挑战与机遇", "title_en": "Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning", "authors": "Yibin Sun,Nick Lim,Guilherme Weigert Cassales,Heitor Murilo Gomes,Bernhard Pfahringer,Albert Bifet,Anany Dwivedi", "background": "肌电图(EMG)信号的固有非平稳性使得检测领域偏移成为一项重大挑战。本文通过流学习技术探索EMG信号领域偏移的检测方法，特别是在Ninapro数据库的DB6数据集上进行研究。定义域为基于不同受试者和记录会话的不同时间序列段，采用余弦核的核主成分分析(KPCA)进行预处理，以突出这些偏移。多种偏移检测方法如CUSUM、Page-Hinckley和ADWIN进行了评估，暴露了现有技术在实时EMG信号领域偏移检测中的局限性.", "innovation": "通过流学习技术，特别是使用KPCA进行预处理，并且评估了多种偏移检测方法，揭示了现有技术的局限性，强调了流式方法在维护稳定EMG解码模型中的潜力，同时也指出了进一步研究需要解决的领域以提高鲁棒性和准确性.", "conclusion": "本文研究表明，流式方法能够维持稳定的EMG解码模型，但同时也发现当前技术在实现高效实时领域偏移检测方面存在局限性，未来的研究应聚焦于提高在实际应用中的鲁棒性和准确性."}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21396", "html_url": "https://arxiv.org/abs/2508.21396", "title": "PMODE：基于理论和模块化的混合建模", "title_en": "PMODE: Theoretically Grounded and Modular Mixture Modeling", "authors": "Robert A. Vandermeulen", "background": "本文介绍了PMODE（分割混合密度估计器的混合），一个既适用于参数部分又适用于非参数部分的混合建模的通用且模块化的框架。PMODE通过将数据分割为部分并为每个子集拟合单独的估计器来构建混合模型。该方法适用于混合成分来自不同分布族的情况，并且可以达到该估计器类别的接近最优速率。在应用方面，作者开发了MV-PMODE，该模型将之前仅在理论上的高维密度估计方法扩展到数千个维度的场景中。尽管其简化性，该方法在CIFAR-10异常检测任务中表现出类似深度基准线的表现.", "innovation": "PMODE框架具有较高的模块化性和通用性，能够同时处理参数和非参数分量，并能够适应混合成分来自不同分布族的情况。MV-PMODE不仅扩展了PMODE的应用场景，使得该方法能够在高维度的复杂场景中发挥作用，还在具体的CIFAR-10异常检测任务中展示了与深度学习方法相竞争的性能.", "conclusion": "本文提出的PMODE框架能够有效处理混合模型，并且通过MV-PMODE的开发，使得混合密度估计在高维复杂场景中也能被实际应用。而在实践中，该方法已经在CIFAR-10异常检测任务中展示了良好的性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21314", "html_url": "https://arxiv.org/abs/2508.21314", "title": "POMDPs中的正则化代理状态基于Q学习的收敛性", "title_en": "Convergence of regularized agent-state-based Q-learning in POMDPs", "authors": "Amit Sinha,Matthieu Geist,Aditya Mahajan", "background": "本文讨论了常用Q学习强化学习算法在实际环境中收敛的行为。这些算法具有两个显著特点：（i）Q表是递归更新的，使用的是代理状态（如递归神经网络的状态），而不是信念状态或信息状态；（ii）经常使用策略正则化来鼓励探索并稳定学习算法。作者研究了此类Q学习算法中最简单的形式，即称为正则化代理状态基于Q学习（RASQL），并证明在温和的技术条件下，它收敛到由行为策略引使用的平稳分布所定义的正则化MDP的固定点。作者还展示了对于学习周期性策略的RASQL变体的类似分析也能适用。", "innovation": "该研究提出了关于RASQL和周期性策略学习变体的收敛性的理论分析，特别是说明了在温和的技术条件下，RASQL算法可以收敛到正则化MDP的固定点，并且这种分析适用于学习周期性策略的变体。", "conclusion": "数值示例表明，实际收敛行为与提出的理论极限是一致的。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff：基于扩散模型的阶段化长期时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型在时间序列生成领域取得了成功应用。然而，对于跨越较长时间、具备复杂长期时间模式的长时序数据，生成任务变得更具挑战性。这些数据不仅具有长距离时间依赖关系，同时随着时间的推移其数据分布也在发生变化。找到长距离依赖关系和数据分布变化之间平衡的关键挑战在于它们之间的复杂关系。另一方面，长时序数据包含不同特征序列间的复杂相互关系，有效地捕捉这些序列内的依赖性和序列间依赖性的任务也十分重要。为了解决这些问题，本文提出了基于扩散模型的阶段化生成模型Stage-Diff。", "innovation": "Stage-Diff采用阶段化序列生成和阶段间信息传递的方法来保留长时序序列的依赖关系，同时允许数据分布变化的建模。每个阶段应用逐步序列分解进行通道独立建模，而在不同时间尺度下执行。阶段间信息传递则利用多通道融合建模。这种方法结合了通道独立建模的鲁棒性和多通道建模的信息融合优势，有效平衡了长时序数据的序列内和序列间依赖性。", "conclusion": "在多个实际数据集上的广泛实验验证了Stage-Diff在长时序生成任务中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN：基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列合成是确保时间序列数据安全流通的有效手段。现有的时间序列合成方法通常基于随机序列进行时间建模，以生成目标序列，这往往难以保证生成的时间序列中的时间依赖性。直接在随机序列上建模时间特征也会使得精确捕捉原始时间序列的特征信息变得困难。因此，本文提出了一种简单的生成模型——双层生成对抗网络（Dual-Layer Generative Adversarial Networks，简称DLGAN），该模型将时间序列生成过程分解为两个阶段：序列特征提取和序列重构。第一阶段为整个时间序列自编码器，使得原始时间序列上的监督学习能够确保恢复序列的时间依赖性，第二阶段利用生成对抗网络生成与实时序列特征相一致的合成特征向量，以确保生成器能从真实时间序列中捕捉到时间特征。", "innovation": "提出的DLGAN模型将时间序列生成过程分为两个阶段，通过时间序列自编码器确保时间依赖性的恢复，利用生成对抗网络生成与即时时间序列特征一致的合成特征向量，解决了现有方法在时间依赖性建模和特征捕捉上的不足问题。", "conclusion": "在四个公开数据集上的广泛实验表明，该模型在各种评估指标上具有优越性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21438", "html_url": "https://arxiv.org/abs/2508.21438", "title": "增强量子的集成生成对抗网络在连续生物制造中的异常检测", "title_en": "Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing", "authors": "Rajiv Kailasanathan,William R. Clements,Mohammad Reza Boskabadi,Shawn M. Gibford,Emmanouil Papadakis,Christopher J. Savoie,Seyed Soheil Mansouri", "background": "连续生物制造过程需要强大的早期异常检测，因为即使是轻微的偏差也可能破坏产量和稳定性，导致调度中断、每周生产减少和经济性能下降。这些过程复杂且具有非线性动态，变量间关系复杂，因此先进的异常检测方法对于高效运行至关重要。现有研究强调，异常检测是确保连续生物制造连续运行的重要手段，特别是在应对原料突然波动时.", "innovation": "本研究提出了一种基于集成生成对抗网络（GANs）的无监督异常检测框架，使用了混合量子/经典GAN方案，并使用模拟量子电路和实际光子量子处理器进行评估。结果显示，混合方法提高了异常检测率，展示了混合量子/经典方法在解决复杂连续生物制造中的实际问题的潜力.", "conclusion": "研究通过集成多个GAN，开发了一种新的无监督异常检测框架，在模拟和实际量子处理器上进行测试表明，这种混合量子/经典GAN方法在异常检测方面表现更佳，并且具有显著提高检测准确性和效率的潜力，为复杂的连续生物制造过程提供了可行的异常检测解决方案."}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21421", "html_url": "https://arxiv.org/abs/2508.21421", "title": "通过链式合并重新思考层级模型合并", "title_en": "Rethinking Layer-wise Model Merging through Chain of Merges", "authors": "Pietro Buzzega,Riccardo Salami,Angelo Porrello,Simone Calderara", "background": "预训练模型的微调已经成为在各个领域实现顶尖性能的标准途径，导致产生了大量针对特定任务的模型变种。随着这些专门化模块的数量增加，如何在无需重新训练的情况下将它们合并到一个统一的模型中，已成为一个关键挑战。现有合并技术通常依赖于干扰启发式、重要性加权或激活匹配，而这些方法会独立处理每一层，因此忽视了深度网络中存在的层间依赖关系。这种简化导致了分布不匹配，特别是在基于激活的方法中，早期层的变化没有被充分反映到下游层中。", "innovation": "作者识别出这些分布不匹配是内部协变量移位的一种形式，类似于神经网络训练初期遇到的现象。为解决这一问题，作者提出了链式合并（CoM），这是一种逐层合并的流程，能够以自回归的方式更新激活统计数据，明确考虑跨层交互。CoM通过条件最优更新产生一个一致的合并模型，有效缓解了由协变量移位引起的性能下降。", "conclusion": "在标准基准上的实验表明，CoM可以实现顶尖的性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21324", "html_url": "https://arxiv.org/abs/2508.21324", "title": "分布感知特征选择用于SAEs", "title_en": "Distribution-Aware Feature Selection for SAEs", "authors": "Narmeen Oozeer,Nirmalendu Prakash,Michael Lan,Alice Rigg,Amirali Abdullah", "background": "稀疏自编码器（SAEs）将神经激活分解为可解释的特征。一种广泛应用的变体TopK SAE从每个token的K个最活跃潜在因子中重建每个token。然而，这种方法效率低下，因为并非所有token都携带相同的信息量。BatchTopK解决了这一局限性，通过在一批token中选择顶级激活。这虽然提高了平均重建性能，但也存在‘激活彩票’问题，即罕见但高幅度的特征会挤占更有信息量但幅度低的特征。", "innovation": "为解决这一问题，本文提出了一种采样自编码器（Sampled-SAE）：通过$L_2$范数或熵评分批激活矩阵的列（代表特征），形成大小为$Kl$的候选池，然后从特征限制池中应用Top-$K$选择批中的token。$l$的不同值画出了在批次层面和token特定选择之间的光谱。当$l=1$时，token仅从全球影响力最大的$K$个特征中选择，而较大的$l$扩展特征池，趋向于标准的BatchTopK，并且在整个批处理中包括更多特定的特征。小的$l$增强了全局一致性，而大的$l$则有利于精细重建。", "conclusion": "在Pythia-160M上，没有单一的$l$能够在所有指标上最优。最佳选择依赖共享结构、重建保真度和下游性能之间的权衡。因此，采样自编码器(Sampled-SAE)将BatchTopK重新定位为可调的、分布感知的家庭，增强了灵活性和适应性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "自适应重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型的时代，优化算法往往由于过分依赖训练损失而面临泛化问题。在机器学习社区中，广泛接受的一个关键点是宽盆地（特别是在局部极小值周围损失逐渐增加的区域）能够通过提供更大的输入数据或模型参数的微小变化稳定性来促进更好的泛化，而尖锐的极小值通常更敏感且不稳定。受到随机梯度下降中固有的重尾梯度噪声分布以及神经网络训练中的边缘稳定性现象（曲率增长然后稳定在一个平台）的两种实验观察的启发，作者提出了自适应重尾随机梯度下降（AHTSGD）。", "innovation": "AHTSGD算法在训练早期引入更重尾的噪声以增强探索性，并随着尖锐程度的稳定逐渐过渡到较轻尾的噪声。通过在整个训练过程中动态适应损失景观的尖锐度，AHTSGD促进快速收敛到宽盆地。这是第一个基于边缘稳定性现象调整注入噪声性质的优化器算法。在MNIST和CIFAR-10等基准测试上，AHTSGD优于SGD和其他基于噪声的方法，特别是在SVHN等嘈杂数据集上显著提高性能。此外，它能加速从不良初始条件开始的早期训练，并在清洁和嘈杂环境中都提升了泛化能力，同时对学习率的选择具有鲁棒性。", "conclusion": "AHTSGD算法通过在不同训练阶段使用不同的噪声特性，提高了模型在训练早期的探索能力和后期的泛化性能，并在多种基准数据集上展示了其优越性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度整合实现基于结构的药物设计中的可控3D分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "基于结构的药物设计（SBDD）的 recent进展利用生成模型生成3D分子，主要通过与靶蛋白的结合亲和力来评估模型性能。然而，实际药物发现需要高结合亲和力、合成可行性及选择性等多种关键属性，而这些在以往的评估中通常被忽视。", "innovation": "识别了传统基于扩散的生成模型在指导分子生成时在有效引导多样药理属性方面的局限性，并提出了一个新的框架CByG，这是一种扩展贝叶斯流网络的梯度条件生成模型，能够稳健地整合属性特定的指导。此外，还引入了一个综合评估方案，包含实际的基准测试，以结合亲和力、合成可行性和选择性的评估，克服了传统评估方法的局限。", "conclusion": "大量的实验表明，提出的CByG框架在多个关键评估指标上显著优于基线模型，展示了其在实际药物发现应用中的有效性和实用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于水库计算的低成本方法评估网络状态", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "利用挪威的移动网络利用率数据，展示了一种非侵入式、低成本的方法，用于监测通信和移动网络的状态。这种方法将网络数据转化为水库计算框架中的模型，并通过代理任务评估模型的性能。实验证明，这些代理任务的性能与网络状态相关。对于这种方法的一个重要优势是，它利用了现成的数据集，并利用了水库计算框架，这种方法既经济又基本不受影响。移动网络利用数据以匿名、聚合的形式每天有多次快照，这些数据可以被视作加权网络。水库计算使得使用未训练的加权网络作为机器学习工具成为可能。", "innovation": "这种方法的关键创新在于使用现成的、聚合的移动网络利用率数据，并利用水库计算框架来实现低成本、低侵入性的网络状态监测。这种方法可以将加权但未训练的网络用作机器学习工具，避免了深度神经网络中每个权重都需训练的情况，从而降低了能耗。研究人员使用神经科学启发的任务，对回声状态网络（ESN）模型进行了训练，展示了性能如何依赖于特定的网络配置，以及网络被干扰时性能如何明显下降。", "conclusion": "这项工作虽然只是一个概念证明，但认为这种方法可以被提升用于近实时监控，并可用于识别移动通信网络和交通网络中的薄弱环节。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21258", "html_url": "https://arxiv.org/abs/2508.21258", "title": "RelP: 基于相关性补丁的忠实高效特征电路发现", "title_en": "RelP: Faithful and Efficient Circuit Discovery via Relevance Patching", "authors": "Farnoush Rezaei Jafari,Oliver Eberle,Ashkan Khakzar,Neel Nanda", "background": "激活补丁在机制可解释性中是一种标准方法，用于局部化导致特定行为的模型组件，但在大规模应用上计算成本较高。归因补丁提供了一种更快的基于梯度的近似方法，但在深层和高度非线性的网络中会出现噪声问题和可靠性降低。", "innovation": "我们引入了相关性补丁（RelP），它将归因补丁中的局部梯度替换为由层化相关性传播（LRP）衍生的传播系数。LRP通过层向后传播网络的输出，并根据局部传播规则重新分配相关性，确保属性如相关性保存或提高信号与噪声比。RelP只需要两次前向传递和一次后向传递，保持了计算效率并提高了忠实度。", "conclusion": "我们在多种模型和任务中验证了RelP，证明它比标准归因补贴更准确地逼近激活补贴，特别是在分析GPT-2 Large模型中残差流和MLP输出的间接对象识别（IOI）任务时更为明显。与积分梯度（IG）相比，RelP在实现相似的忠实度方面不增加额外的计算成本，展示了它的优越性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21443", "html_url": "https://arxiv.org/abs/2508.21443", "title": "超越期望值：在强化学习中的长期策略性能的几何均值优化", "title_en": "Beyond expected value: geometric mean optimization for long-term policy performance in reinforcement learning", "authors": "Xinyi Sheng,Dominik Baumann", "background": "传统的强化学习（RL）算法通常优化期望累计奖励，即将一个代理沿轨迹收取的标量奖励总和的期望值进行最优化。这种期望值是对无限多个轨迹表现的平均。然而，在实际部署中，这种平均值可能无法提供个体轨迹性能的信息，因此在许多应用中，优化单个轨迹的长期性能更为重要。为此，本文提出了一种新颖的RL算法，结合了标准的期望值和时间的加权平均增长速率，后者衡量单个轨迹的长期性能。", "innovation": "本文创新地定义了时间平均增长速率的贝尔曼算子，并在乘法奖励动力学下证明了几何均值与时间平均增长速率一致。为了处理更广泛且未知的奖励动态，文章提出了一个具有N滑动窗口的修改几何均值，能够作为时间平均增长速率的估计值，捕获路径依赖性。此估计值作为正则化器嵌入目标函数中，形成一种实用的算法，使得策略可以同时受益于期望值和时间平均的性能增长。在复杂的仿真环境中，该算法表现优于传统RL方法。", "conclusion": "本文提出了一种结合集合平均和时间平均增长速率的新型RL算法，通过在的目标函数中引入时间平均增长速率的估计值，实现了策略性能的优化。该算法在复杂模拟环境中表现出色，能够有效提升策略的长期表现。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21495", "html_url": "https://arxiv.org/abs/2508.21495", "title": "失败预测是比校准更好的早期退出网络性能代理", "title_en": "Failure Prediction Is a Better Performance Proxy for Early-Exit Networks Than Calibration", "authors": "Piotr Kubaty,Filip Szatkowski,Metod Jazbec,Bartosz Wójcik", "background": "早期退出模型通过在模型中间层附带内部分类器并在预测满足退出标准时停止计算来加快推理速度。大多数早期退出方法依赖于基于置信度的退出策略，这促使一些工作校准中间分类器以提高整个模型的性能。然而，研究表明，校准措施可以误导多出口模型性能的指示：即使分类器校准良好，也可能浪费计算资源，且常用的校准方法不能保持分类器内样本的排名。", "innovation": "本文提出使用失败预测作为更有效的早期退出模型性能代理，不同于校准，失败预测考虑了样本排名的变化，并与效率改进表现出强烈的关联性，使其成为设计和评估早期退出模型更为可靠的基础。", "conclusion": "校准措施可能是误导性的，而失败预测能够更准确地反映模型的真实性能，更适合用于评估和设计早期退出模型。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的模型不符", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "不确定性量化在强化学习中的应用能极大地提升探索能力和稳健性。近来，近似贝叶斯方法被广泛用于量化模型自由算法中的不确定性。然而，目前的研究主要集中在提高后验近似精度，而忽视了研究后验所基于的似然和先验假设的准确性。在这项工作中，作者展示了贝叶斯深度Q学习中存在一个冷后验效应，即减少后验温度反而能提升性能，这与理论预期相反。为了识别并克服这种效应的原因，作者挑战了贝叶斯模型自由算法中常见的似然和先验假设，并通过实验研究显示了常见的高斯似然假设经常被违反。", "innovation": "文章识别并验证了贝叶斯深度Q学习中先验分布的重要性和常见高斯似然假设被违反的现象，提出了改进更适合的先验和似然的方法，这些都为未来的研究提供了新的方向。作者通过统计测试表明，使用更合适的先验分布和似然可以提升贝叶斯算法的性能，是未来强化学习研究的一个关键焦点。", "conclusion": "研究表明，开发更合适的先验和似然应成为未来贝叶斯强化学习研究的关键重点，并提供了一种简单的实现方案，改善了深度Q学习中的贝叶斯算法性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受或拒绝？跨表格到文本序列化方法评估大型语言模型在贷款审批中的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "随着大型语言模型（LLMs）在高压决策任务中的广泛应用，如贷款审批，它们能够处理的数据复杂性成为一个挑战。尤其是在金融领域，LLMs 面临的一个主要挑战是处理表格数据，同时保证公平性和提供可靠预测的能力。本文通过对来自三个不同地区的贷款审批数据集（加纳、德国和美国）进行评估，探讨了序列化格式（即将表格数据转换为适合LLMs处理的文本格式）对模型性能和公平性的影响。", "innovation": "本文创新性地采用了零样本和上下文学习（ICL）能力评估方法，关注不同表格到文本序列化格式（如GReat和LIFT）对LLMs性能和公平性的影响，并发现性能表现和公平性的关系复杂多变，某些序列化格式虽然能提高F1分数，但也加剧了公平性问题。同时，上下文学习对模型性能有显著提升，但对公平性的影响因数据集而异。", "conclusion": "本研究表明，有效的表格数据表示方法和公平性意识模型的开发对于提高大型语言模型在金融决策中的可靠性具有重要意义。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正需要的是哪些数据？推荐系统中推理数据最小化可行性的研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是一项法律原则，要求个人信息处理仅限于特定目的所需的数据。对于依赖大量个人信息的推荐系统来说，将这一原则操作化仍是一个重大挑战。本文开展了一项可行性研究，旨在为这些系统最小化隐含反馈数据，提出一种新颖的问题形式，分析各种最小化技术，并研究影响它们有效性的关键因素。研究表明，在不显著损失性能的情况下可以实现大量推理数据的减少。", "innovation": "提出了一种新颖的问题形式并分析了多种最小化技术，同时研究了影响其有效性的关键因素，证明了在不显著损失性能的情况下实现大量推理数据的减少是可行的。", "conclusion": "虽然技术上可行，但在实际应用中，数据最小化的可行性严重依赖于技术设置（如性能目标、模型选择）和用户特点（如历史记录大小、偏好复杂性）。因此，尽管我们确立了其技术可行性，但数据最小化在实践中依然具有挑战性，其依赖于技术和用户上下文的特征，使得制定一种普遍适用的数据'必要性'标准难以实施。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21505", "html_url": "https://arxiv.org/abs/2508.21505", "title": "脉冲决策变换器：局部可塑性、相位编码和树突路由的低功耗序列控制", "title_en": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control", "authors": "Vishal Pandey,Debasmita Biswas", "background": "基于Transformer架构的强化学习代理在序列决策任务中表现出色，但由于其对密集矩阵操作的依赖，它们不适合能源受限的边缘平台。脉冲神经网络承诺实现超低功耗的事件驱动推理，但之前的研究尚未将脉冲动力学与回报（returns）条件下的序列建模无缝结合。", "innovation": "提出了一种新型脉冲决策变换器（SNN-DT），它将漏型积分-发放神经元嵌入到每个自我注意力块中，并通过替代梯度进行端到端训练，同时结合了生物启发的三因子可塑性、基于脉冲的时间编码和轻量级树突路由模块。SNN-DT在经典控制基准上达到了或超过了标准决策变换器的表现，每个决策所发射的脉冲数量少于十个，能耗显著降低。", "conclusion": "通过结合序列建模与神经形态效率，SNN-DT为嵌入式和可穿戴设备中的实时低功耗控制开辟了新的途径。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21466", "html_url": "https://arxiv.org/abs/2508.21466", "title": "在黎曼流形数据空间上的归一化最大似然码长", "title_en": "Normalized Maximum Likelihood Code-Length on Riemannian Manifold Data Spaces", "authors": "Kota Fukuzawa,Atsushi Suzuki,Kenji Yamanishi", "background": "近年来，随着图形数据的大规模扩展，除了欧几里得空间外，对黎曼流形数据空间的关注也在增加。特别地，双曲空间的发展尤为显著，它们对具有层次结构的图形数据具有很强的表达能力。归一化最大似然规范化(NML)已被用于后悔最小化和模型选择。然而，现有的NML形式主要在欧几里得空间中开发，并且本质上依赖于坐标的选取，使得将其扩展到黎曼流形变得复杂。", "innovation": "在本文中，定义了一种新的NML，称为黎曼流形NML(Rm-NML)，它反映了黎曼流形的几何结构，且在自然参数化下与传统的NML一致。该研究还扩展了现有的NML计算技术到黎曼流形中，并推导出一种简化黎曼对称空间上Rm-NML计算的方法，涵盖了诸如双曲空间等正在增长的兴趣数据空间。此外，通过计算双曲空间上正常分布的Rm-NML来说明所提方法的实用应用案例。", "conclusion": "通过引入一种新的NML形式——黎曼流形NML(Rm-NML)，本文为模型选择提供了一种新的范式，其计算简便且在适当的坐标下与传统NML一致。该方法在处理具有层次结构的图形数据方面尤其有用，并已在双曲空间上的正常分布数据上进行了验证。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "物理引导的光谱建模在高光谱成像中的应用", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "本文介绍了PhISM，这是一种基于物理的深度学习架构，能够在未监督的情况下学习并明确分离高光谱观察数据，并使用连续基函数对其进行建模。该方法在多个分类和回归基准测试上优于先前方法，需要较少的有标签数据，并能够提供可解释的潜在表示，从而提供额外的见解。", "innovation": "PhISM架构通过引入物理引导的方法和连续基函数直接建模高光谱数据，显著提升了在分类和回归任务中的性能，并减少了对有标签数据的依赖。此外，PhISM还通过提供可解释的潜在表示，提供了额外的洞见。", "conclusion": "PhISM在高光谱成像中展现了卓越的性能，在多个分类和回归基准测试上超越了先前的方法，同时提供了较少的有标签数据和可解释的潜在表示。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "物理感知神经网络在智能电网代理中的局限性研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "智能电网建模面临数据稀缺和物理一致性等关键挑战。传统数据驱动的方法无法有效解决这些问题。物理感知神经网络（PINNs）通过直接将物理定律整合到学习框架中，为智能电网提供了一种变革性的建模方法。本文通过一项实验证明，PINNs 在智能电网动态中的泛化能力和传统数据驱动模型相比具有明显优势。通过仅使用基于物理的损失函数进行训练（强制功率平衡、运行约束和电网稳定），PINNs 在预测精度上表现优异，尤其是在扩展训练数据较少的情况下仍能保持较低的 MAE 表现。", "innovation": "本文引入了一种利用物理感知神经网络（PINNs）作为智能电网代理模型的方法。通过训练仅基于物理损失函数，PINNs 在动态电网操作中表现出更好的泛化能力，特别是在随机和专家驱动控制场景中可靠地捕捉状态转换。PINNs 比传统的数据驱动模型在极端操作模式下略有下降，但仍确保了物理可行性，这对于关键能源系统的安全性至关重要。", "conclusion": "本文的研究结果表明，物理感知神经网络能够同时保持数据驱动模型的灵活性和第一性原理的严谨性，对于建立智能电网的仿真技术具有重要意义。这项工作最终强调了在关键能量系统中实现实时电网控制和可扩展数字孪生体所需的物理感知架构的重要性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21570", "html_url": "https://arxiv.org/abs/2508.21570", "title": "OASIS：利用稀疏漂流轨迹的扩散对抗网络进行海洋盐度插补", "title_en": "OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories", "authors": "Bo Li,Yingqi Feng,Ming Jin,Xin Zheng,Yufei Tang,Laurent Cherubin,Alan Wee-Chung Liew,Can Wang,Qinghua Lu,Jingwei Yao,Shirui Pan,Hong Zhang,Xingquan Zhu", "background": "海洋盐度对于洋流、气候和海洋生态系统发挥着至关重要的作用，但其测量往往稀疏、不规则且噪声大，尤其是在基于漂流器的数据集方面。传统方法，如遥感和最优插值，依赖于线性和稳定性，并受限于云覆盖、传感器漂移和低卫星重访率。虽然机器学习模型具有灵活性，但它们在严重稀疏情况下经常失效，并且缺乏系统地结合物理协变量的方法，这通常需要专门的传感器。", "innovation": "本文提出了一种新颖的扩散对抗框架——OceAn Salinity Imputation System (OASIS)，旨在解决上述挑战。OASIS 结合了扩散模型和对抗模型的优势，特别适合于基于稀疏漂流轨迹的海洋盐度插补问题，能够在不规则和稀疏数据下提供更准确的预测。", "conclusion": "本文通过提出 OASIS 框架，为解决海洋盐度测量的稀疏性、不规则性和噪声问题提供了一种新的方法。该方法利用了扩散对抗网络，特别适用于基于稀疏漂流轨迹的数据插补，从而在不规则和稀疏数据集下提供更准确的海洋盐度估计，这对气候研究和海洋生态系统分析具有重要意义。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21571", "html_url": "https://arxiv.org/abs/2508.21571", "title": "随机梯度方法在宽两层物理启发式神经网络中收敛性", "title_en": "Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks", "authors": "Bangti Jin,Longjun Wu", "background": "物理启发式神经网络(PINNs)是求解偏微分方程的一种非常受欢迎的神经网络求解器类型。实践中，通常使用随机梯度下降型算法来训练神经网络。因此，随机梯度下降的收敛性保证是基础性的。该论文旨在研究在高概率下，随机梯度下降/流在训练过参数化两层PINNs时的表现，激活函数范围广泛。这项研究扩展了先前分析梯度下降结果的工作。分析的挑战在于处理随机优化方法引入的动态随机性。关键在于确保训练过程中某些特定Gram矩阵的正定性，这有助于深入了解优化过程的动力学，并为通过随机算法训练的神经网络提供保证。", "innovation": "该研究证明了过参数化两层PINNs在高概率下的线性收敛性，适用于一般激活函数。这项结果扩展了先前仅限于梯度下降的研究，通过分析随机优化方法的动态随机性，确保Gram矩阵的正定性来实现这一目标。", "conclusion": "研究表明，在高概率下，随机梯度下降和流在训练过参数化两层PINNs时具有线性收敛性。该研究不仅扩展了先前的工作，还提供了一种理解优化过程动态的新视角，并为通过随机算法训练的神经网络提供了保证。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "从总结-举例-反思：基于数据的见解蒸馏赋能LLMs的少量展示表格分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "最近的研究显示，大型语言模型（LLMs）在少量展示的表格分类任务中具有潜力，但也指出了由于结构化数据的变化性所带来的挑战。本研究旨在通过将数据转化为可操作的见解，使得LLMs能够实现更稳健和有效的分类。", "innovation": "提出了一种基于数据的见解蒸馏框架——InsightTab，该框架借鉴了人类学习过程中的分而治之、先易后难和反思学习的原则。通过深度协作，将规则总结、策略性举例和见解反思结合起来，使LLMs能够更好地对特定的表格任务提出有针对性的知识和能力。", "conclusion": "对九个数据集进行了广泛的评估，结果显示较之最新的方法，本方法有了持续性的改进。进一步的消融研究验证了原则导向下的蒸馏过程的有效性，并且分析强调了InsightTab在利用标注数据和管理偏差方面的能力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21620", "html_url": "https://arxiv.org/abs/2508.21620", "title": "概率决策算法的分析导论", "title_en": "Introduction to the Analysis of Probabilistic Decision-Making Algorithms", "authors": "Agustinus Kristiadi", "background": "决策理论提供了在不同类型的不确定性下进行选择的方法论。这些理论的应用算法在材料和药物发现等实际问题中取得了成功，因为它们可以适应地收集信息以在未来做出更好的决策，从而实现高效的数据流程。在科学发现领域，由于实验成本高昂，这些算法可以显著降低实验成本。然而，文献中的理论分析往往对非专家来说难以理解。因此，本文献旨在为常用的概率决策算法提供一个易于理解的、自包含的理论分析介绍，包括贝叶斯优化、多臂老虎机算法和树搜索算法等。所需的仅是基本的概率论和统计知识，以及一些高斯过程的基本知识即可。", "innovation": "这篇文章主要介绍了如何用一种易于理解的方式分析通常使用的概率决策算法，特别是涉及到贝叶斯优化、多臂老虎机算法和树搜索算法的理论分析，对于非专家能够理解和应用这些算法有着重要的创新意义。通过本文的指导，读者可以更好地理解这些算法的行为，并为开发下一代算法提供有价值的启示。", "conclusion": "文章提供了对常用概率决策算法的理论分析的介绍，使非专家也能理解这些算法的行为，最终可以在科学研究和工程实践中有效利用这些算法。这种可访问性和实用性使得文章在该领域具有重要的理论和实践价值。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21554", "html_url": "https://arxiv.org/abs/2508.21554", "title": "全面评价可穿戴纺织ECG衣信号质量：一项性别平衡研究", "title_en": "Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study", "authors": "Maximilian P. Oppelt,Tobias S. Zech,Sarah H. Lorenz,Laurenz Ottmann,Jan Steffan,Bjoern M. Eskofier,Nadine R. Lang-Richter,Norman Pfeiffer", "background": "目前的可穿戴心电图（ECG）设备在信号质量方面存在一些挑战，如噪声和运动伪差，这会导致信号失真。为了改善这些问题，研究者开发了一种新的可穿戴纺织服装，其创新性电极放置旨在减少噪声和运动伪差，从而提高ECG记录的信号保真度。通过一种性别平衡的评估方法对15名健康男性和15名健康女性参与者进行了全面评估，以确保该设备在不同解剖生理变量中的适用性。", "innovation": "研究引入了一种新的可穿戴纺织服装，结合了创新的电极放置，旨在减少噪声和运动伪差，提高信号保真度。通过性别平衡的评估，研究涵盖了多种评估方法，包括客观的信号质量指标、基于节律的心率和心率变异性分析、机器学习分类任务以评估预测能力、ECG特征的形态分析以及研究电极投影角度对信号采集的影响，并按性别分层分析，以揭示性别特异性影响。这些评估涵盖了各种活动阶段，以代表真实世界条件。", "conclusion": "研究结果显示，纺织系统在节奏和形态分析方面的信号质量与参考设备高度一致，表现出稳健的分类性能，并能够识别关键的性别特异性因素影响信号采集。这些发现强调了基于纺织的ECG服装在生理监测和心理生理状态检测中的实际可行性。同时，研究还指出性别特异性设计考虑的重要性，以确保穿戴健康技术中的公平和可靠的心脏诊断。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "基于图神经网络的SAT求解器学习的难易性：图里奇曲率的作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "图神经网络（GNNs）已经展示了利用图表示逻辑公式的玻尔兹曼可满足性问题（SATs）的潜力。然而，它们在更复杂的实例上的性能急剧下降，这引发了人们对于这种表现下降是否反映了架构的基本限制的疑问。", "innovation": "论文通过图里奇曲率（RC）提供了几何解释，证明了源自随机k-SAT公式的双部图内禀负曲率，且曲率随着实例难度增加而减小。此外，研究显示基于GNN的SAT求解器受到过压缩现象的影响，这种现象使得长程依赖关系无法被压缩到固定长度的表示中。研究还通过不同SAT基准验证了这一发现，并证实了里奇曲率不仅是问题复杂度的强有力指示器，还可以用于预测性能。最后，本文将研究结果与现有求解器的设计原理相联系，并提出了未来工作的潜在方向。", "conclusion": "研究证明了里奇曲率是SAT问题复杂性和性能预测的两个重要指标，并且可以用于指导未来基于GNN的SAT求解器的设计。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "象棋引擎神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "该研究探索神经网络在构建其表示过程中是通过平滑、渐进的改进还是通过更加复杂的过程进行的，以Leela Chess Zero这一超出人类水平的国际象棋引擎为对象，使用对数几率透镜分析其策略网络。", "innovation": "研究通过扩展对数几率透镜，分析了Leela Chess Zero的策略网络，揭示了在层间表现出强大的单调趋势，但在策略分布上常常遵循非平滑的轨迹。", "conclusion": "研究发现，象棋策略网络中的策略分布与语言模型中的平滑分布性收敛形成鲜明对比，表现为早期正确解题发现但随后又被抛弃，以及直到网络后期才出现高策略差异和较差的排名与最终输出的相关性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21650", "html_url": "https://arxiv.org/abs/2508.21650", "title": "从情感和时间特征预测社交媒体参与度", "title_en": "Predicting Social Media Engagement from Emotional and Temporal Features", "authors": "Yunwoo Kim,Junhyuk Hwang", "background": "该研究提出了一个机器学习方法，用于从情绪和时间特征中预测社交媒体参与度（包括评论和点赞）。数据集包含600首歌曲，并标注了正价、唤醒度和相关情感指标。模型使用多目标回归算法进行训练，以解决目标值分布偏斜的问题，同时通过定制的准确性衡量和标准回归指标评估性能。研究表明，情绪和时间元数据与现有浏览量一起，可以有效预测未来的参与度。", "innovation": "提出了一个基于HistGradientBoostingRegressor的多目标回归模型，专门针对情感和时间元数据进行训练，以提高对点赞和评论的预测精度。模型通过定制的准确性衡量和标准回归指标进行了评估，显示了情感和时间元数据在预测社交媒体参与度中的有效性。", "conclusion": "情感和时间元数据与现有浏览量一起预测未来的参与度效果显著，该模型对于点赞的R^2值为0.98，但对于评论的R^2值仅有0.41。这种差距表明点赞主要受到容易捕捉的情感和曝光信号驱动，而评论则依赖未在当前特征集中表示的额外因素。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "Activation Subspaces for Out-of-Distribution Detection", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "为了在实际应用中确保深度模型的可靠性，异常分布外(out-of-distribution, OOD)检测方法旨在区分训练分布(in-distribution, ID)附近的样本与远离分布的样本。本文的背景是在大规模分布变化（Far-OOD）和小型分布变化（Near-OOD）两种情况下，如何有效地进行OOD检测，以提高模型在实际应用中的可靠性。", "innovation": "本文提出了一种新的OOD检测方法，称为ActSub，利用分类头权重矩阵的奇异值分解将模型激活分解为对最终分类器输出贡献最大（显著部分）和最小（不显著部分）的子空间。该方法通过联合显著和不显著子空间的有效利用，实现了各种标准OOD基准测试中的最佳结果。", "conclusion": "通过ActSub方法结合显著和不显著子空间的优势，本文在多种标准OOD基准测试中取得了最先进的结果。"}
{"llm_update_time": "20250903", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "学习鲁棒心率建模的异质数据统一表示法", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化健康监测和健身至关重要，但在实际应用中经常面临数据异质性这一关键挑战。数据异质性主要来源于设备市场的碎片化，导致不同的功能集，以及个体间的生理差异，这些差异随活动而变化。现有的方法要么丢弃设备特定的信息，要么无法建模用户的个体差异，这限制了它们的实际性能。", "innovation": "我们提出了一种框架，该框架学习对两种异质性都不依赖的潜在表示，使下游预测器在异质数据模式下能够一致地工作。为了处理来源异质性，我们引入了一种随机特征删除策略，使模型对各种特征集具有鲁棒性。为了处理用户异质性，我们采用了一个时间感知的注意力模块来捕获长期生理特征，并使用对比学习目标构建一个区分性表示空间。为了反映现实数据的异质性，我们创建并公开发布了新的基准数据集ParroTao。", "conclusion": "在ParroTao和公共FitRec数据集上的评估表明，我们的模型分别优于现有基线17%和15%。进一步分析表明所学习表示的强大区分力，并且一个下游应用任务确认了我们模型的实际价值。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21772", "html_url": "https://arxiv.org/abs/2508.21772", "title": "UniMLR: 为多标签排序建模隐式类别重要性", "title_en": "UniMLR: Modeling Implicit Class Significance for Multi-Label Ranking", "authors": "V. Bugra Yesilkaynak,Emine Dari,Alican Mertan,Gozde Unal", "background": "现有的一些多标签排序（MLR）框架仅从标签的二元拆分（正负集）中获取信息，未能利用标签之间的排名信息，特别是正标签之间的相对重要性。这些框架因此无法充分利用标签内部的排序信息，限制了它们的性能和效果。", "innovation": "引入了UniMLR，这是一种新的MLR范式，它通过正标签之间的排名来建模隐式类别的相关性/重要性值，将其作为概率分布来处理，而不是认为这些类的重要性是均等的。该方法统一了MLR中的排序和分类任务。此外，通过引入八种具有不同显著性确定因素的合成数据集（Ranked MNISTs），解决了MLR数据集中的稀疏性和注释偏见问题，提供了丰富且可控的实验环境。", "conclusion": "通过实验证明，UniMLR方法能够准确学习标签正序排名的表示，该表示与真实值一致，并且与底层的显著性值成比例。在现实世界和合成数据集上的全面实验证明了该框架的价值。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "MPSoC板上神经网络加速：集成SLAC的SNL、Rogue Software和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "LCLS-II自由电子激光器（FEL）将生成每秒高达1 MHz的X射线脉冲，并通过探测器产生超过1 TB/s的数据吞吐量。这样的大数据流管理带来了显著的挑战，传输和存储基础设施变得极其昂贵。传统的机器学习（ML）方法在实时数据减少中引入过多的延迟，使其不适合高速实验环境。SLAC开发了SLAC神经网络库（SNL），这是一种专门为现场可编程门阵列（FPGA）上部署实时ML推理模型的专门框架。SNL的一个关键特性是能够在不需要FPGA复原的情况下动态更新模型权重，增强适用于适应性学习的应用的灵活性。为了进一步提高其可使用性和可访问性，引入了Auto-SNL，这是一种Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高级综合代码的流程。", "innovation": "SLAC开发了SLAC Neural Network Library（SNL），这是一个专门为FPGA上部署实时ML推理模型设计的专用框架。SNL的关键特点是能够在不需要FPGA复原的情况下动态更新模型权重，增强适应性学习的应用的灵活性。进一步，开发了Auto-SNL，这是一种Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高级综合代码的流程。", "conclusion": "通过与当前最先进的工具hls4ml进行基准测试比较，结果表明SNL在大多数测试架构中实现了可竞争或更优的延迟，并且在某些情况下也提供了FPGA资源节省。这项适应性演示展示了SNL的高度灵活性，为高能物理学、医学成像、机器人学等领域中的研究人员和学术界提供了新的机会。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "从异质数据中学习统一表示以实现稳健的心率建模", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化健康监测和健身至关重要，但在实际应用中面临着数据异质性的关键挑战。数据异质性可分为两种关键维度：来源异质性，由于不同设备市场具有不同的功能集而产生；以及用户异质性，反映不同个体和活动之间的独特生理模式。现有的方法要么丢弃设备特定的信息，要么无法建模用户特定的差异，这限制了它们在实际中的表现。因此，需要一种能够学习与异质性无关的潜在表示的框架，使下游预测器在异质数据模式下性能一致。通过在心率数据的表示学习中考虑到这种异质性，研究者希望在这些情况下提高实际性能和稳健性。因此，构建了新的基准数据集ParroTao并公开发布，其目的是更好地评估和提高模型在实际应用场景中的效果。", "innovation": "本文提出了一个框架，该框架通过学习与来源和用户异质性无关的潜在表示，使得下游预测器可以在异质数据模式下表现稳定。具体来说，为了处理来源异质性，提出了一种随机特征丢弃策略，以增强模型对各种特征集的鲁棒性。为处理用户异质性，使用了一个时间感知注意力模块来捕捉长期的生理特征，并采用对比学习目标来建立区分性表示空间。此外，还创建并公开了一个新的基准数据集ParroTao，以反映真实世界数据的异质性，从而进一步提高模型的性能。实验结果表明，所提出的方法在ParroTao和公开的FitRec数据集上分别比现有基线高17%和15%。此外，学习表示的分析表明其强大的区分能力，并且下游应用任务验证了该模型的实际价值。", "conclusion": "本文提出了一种框架，通过学习与数据异质性无关的潜在表示，增强了心率建模的鲁棒性。实验证明了该框架的有效性，并通过实际应用验证了其价值。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob基准数据集：基于MS$^2$的蛋白质组学的片段离概率预测", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质几乎执行所有细胞功能，并构成了大多数药物靶点，因此对其分析对于理解健康和疾病中的人类生物学至关重要。串联质谱（MS$^2$）是蛋白质组学中用于识别肽并量化生物样本中蛋白质的主要分析技术。在MS$^2$分析中，肽片段离子概率预测发挥着关键作用，可以增强肽识别的准确性，作为强度信息的补充。当前的方法依赖于片段化全局统计，假设片段的概率在所有肽中是均匀的，但这种假设从生化原理角度来看过于简化，限制了准确的预测。", "innovation": "提出了Pep2Prob，这是首个全面的数据集和基准，专门用于肽特定片段离子概率预测。该数据集包含了来自1830多万高质量、高分辨率HCD MS$^2$光谱的608,780个独特前体的片段离子概率统计数据，每个前体对应一个肽序列和电荷状态，并且具有验证过的肽分配和片段化注释。通过简单的统计规则和基于学习的方法建立基准性能，并发现利用肽特定信息的模型在性能上明显优于仅使用全局片段化统计的任何先前方法。此外，基准模型性能在不同容量下的变化也表明肽-片段化关系复杂且非线性，需要先进的机器学习方法。", "conclusion": "研究结果表明，通过利用肽特定信息的模型可以大大提升肽片段离子概率预测的准确性，未来的研究方向将集中在开发更加先进的机器学习方法，以更好地理解肽-片段化关系，解决这个复杂的非线性问题。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21793", "html_url": "https://arxiv.org/abs/2508.21793", "title": "MoE-Health: 一种稳健的多模态医疗预测专家混合框架", "title_en": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction", "authors": "Xiaoyang Wang,Christopher C. Yang", "background": "医疗保健系统产生多种类型的多模态数据，包括电子病历（EHR）、临床笔记和医学图像。有效利用这些数据进行临床预测极具挑战性，特别是在现实世界样本常常存在不同模态的数据不完整或缺失的情况下。现有方法通常需要完整模态数据或依赖人工选择策略，这在数据在患者和机构之间存在差异的现实医疗环境中限制了其适用性。", "innovation": "本文介绍了MoE-Health，这是一个新颖的专家混合框架，专门设计用于在医疗预测中进行稳健的多模态融合。MoE-Health架构特别开发以处理不同模态的数据样本，并提高关键临床任务的表现。通过引入专门的专家网络和动态门机制，该方法能够根据可用的数据模态动态选择和组合相关的专家，从而灵活适应不同数据可用性的情景。MoE-Health在MIMIC-IV数据集上针对三项关键的临床预测任务（住院死亡率预测、长期住院天数和住院再入院预测）进行了评估，实验结果表明，MoE-Health在多种数据模态可用性模式下都表现出优于现有方法的性能。该框架有效整合多模态信息，提高了预测性能并增强了处理异质性和不完整医疗数据的能力，使其特别适用于具有异质数据可用性的多元医疗环境中的部署。", "conclusion": "实验结果表明，MoE-Health在不同的数据模态可用性模式下表现出色。MoE-Health框架有效地结合了多模态信息，提供了改进的预测性能和处理异质、不完整医疗数据的鲁棒性，使其特别适合在具有异质数据可用性的多元医疗环境中部署。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21722", "html_url": "https://arxiv.org/abs/2508.21722", "title": "通过人群焦虑连续性预测推断大型事件的效果", "title_en": "Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety", "authors": "Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz", "background": "在公共卫生政策制定中，了解特定社区受到当地事件影响的心理健康状况至关重要。单一地预测心理得分虽提供了有限的信息，但经济学中的准实验设计如纵向回归连续性设计（LRDD）可以帮助从观察数据中推导出更可能具有因果关系的影响。LRDD旨在预测特定时间事件导致结果的变化幅度（如焦虑分数的突然变化）大小。本文旨在将LRDD应用到统计学习框架中，以预测特定事件（例如美国各县因COVID-19事件导致的焦虑变化）造成的突变和线性变化。通过使用历史得分、动态协变量和其他事件数据，作者展示了这种方法比传统的静态社区表示方法表现更好，并且突变预测为估计潜在未来或假设事件对特定社区的特异性影响提供了新的可能途径。", "innovation": "本文提出了将LRDD适应到统计学习框架中的方法，用于预测未来的突变（即特定时间点的变化）和线性变化（即线性轨迹），利用了地点的历史评分、动态协变量和其他外生变量。这种方法在预测美国各县因COVID-19事件导致的焦虑变化方面表现出了显著的改进，尤其是在整合了外生和动态协变量的模型中效果最佳。与传统的静态社区表示相比，该方法在预测突变和斜率方面均表现出明显增强（突变$r=+.46$，斜率$r = +.65$）。", "conclusion": "我们的方法显示了相比传统静态的社区表示方法，突变预测带来了显著的提升，突变$r=+.46$，斜率$r = +.65$。这种突变预测为估计潜在未来或假设事件对特定社区的特异性影响提供了新的可能性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21165", "html_url": "https://arxiv.org/abs/2508.21165", "title": "基于数据驱动的基于物理的血管血流动态降阶模型分叉处理", "title_en": "Data-Driven Bifurcation Handling in Physics-Based Reduced-Order Vascular Hemodynamic Models", "authors": "Natalia L. Rubio,Eric F. Darve,Alison L. Marsden", "background": "三维（3D）有限元模拟心血管流提供高保真的预测，以支持心血管医疗，但由于其高昂的计算成本，限制了临床实用性。降阶模型（ROMs）提供了计算效率高的替代方案，但减低了准确性，特别是在血管分叉处，因为标准的泊肃叶流假设无法充分捕捉流体物理学的复杂性。", "innovation": "我们提出了一种增强的数值框架，将机器学习预测的分叉系数整合到零维（0D）血流动力学ROM中，以提高准确性同时保持计算效率。我们开发了一个电阻-电阻-电感（RRI）模型，使用神经网络预测从分叉几何结构推导的压力-流速关系，结合线性和二次电阻以及感性影响。该方法采用无量纲化技术来减少训练数据的需求，并使用先验流分配预测以改善分叉表征。我们通过基于优化的方法将RRI模型整合到0D模型中。", "conclusion": "结果表明，RRI方法在所有树木和雷诺数中表现出显著的准确性提升：对于标准0D模型，平均入口压力误差减少了54 mmHg（45%）至25 mmHg（17%），而简化版的电阻-电感（RI）变体则实现了31 mmHg（26%）的误差。增强的0D模型对于高雷诺数和广泛的血管网络特别有效。这种混合数值方法可以实现准确、实时的血流动力学建模，用于临床决策支持、不确定性量化和心血管生物医学工程的数字双胞胎。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过双模式退火和强化学习激励泛用的自动思考能力", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大语言模型（MLLMs）在复杂推理问题上表现出色，但在简单问题上无需复杂推理时，这种思考过程变得冗余。为了提高效率，该研究提出了一种自适应思考模型R-4B，它可以根据问题的复杂性决定何时进行思考。", "innovation": "R-4B采用双模式退火和双模式策略优化（BPO）相结合的方法，赋予模型同时具备思考和非思考的能力，使其能够在解决不同复杂度的问题时更加高效地决定是否激活思考过程；并提出了一种改进的GRPO框架，在训练过程中强迫模型对每个输入查询生成来自两种模式的响应。", "conclusion": "实验结果显示，R-4B在25项具有挑战性的基准测试上取得了最先进的性能，比Qwen2.5-VL-7B在大多数任务中表现更优，并且在计算成本更低的情况下达到了与更大模型如Kimi-VL-A3B-Thinking-2506（16B）相当的推理密集基准测试性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21810", "html_url": "https://arxiv.org/abs/2508.21810", "title": "QR-LoRA: 基于QR分解的低秩适应性调整，用于大型语言模型高效微调", "title_en": "QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models", "authors": "Jessica Liang,Anirudh Bharadwaj", "background": "随着大型语言模型规模的扩大，开发参数高效微调技术变得至关重要。Low-Rank Adaptation (LoRA) 方法因其通过低秩更新预训练权重来减少可训练参数而备受关注。然而，标准LoRA方法直接学习更新因子会导致昂贵的运算，并且可能得到难以解释的奇异向量。现有的一些LoRA变体则是通过SVD初始化矩阵，虽然这减少了直接学习参数量，但也存在显式计算代价和解的解释性问题。该研究旨在提出一种新的方法，从预训练权重矩阵中提取正交基，使用这些基向量的线性组合来表达LoRA的更新，仅训练系数参数，从而明显减少参数数量并保持解的清晰结构。", "innovation": "该论文提出了一种基于QR分解的新方法——QR-LoRA。它从预训练权重矩阵中提取正交基，并通过这些基向量的线性组合表达LoRA更新，从而仅训练系数参数。这种方法显著减少了参数数量（与全量微调相比减少了超过1000倍，与通常的LoRA设置相比减少了77倍），同时保持了解的清晰结构。实验结果表明，QR-LoRA在GLUE任务上的性能与完整微调、标准LoRA和SVD-LoRA相当，使用参数量仅为601个。", "conclusion": "QR-LoRA方法在大型语言模型的高效微调中取得了显著的性能和计算效率的结果。尽管初始模型参数量较大，但该方法通过减少微调参数数量和保持模型结构效率地适应新任务，从而实现了更小规模的模型进行高效微调的目标。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21086", "html_url": "https://arxiv.org/abs/2508.21086", "title": "量子启发的概率度量定义了一个完整的、通用的统计学习空间", "title_en": "Quantum-inspired probability metrics define a complete, universal space for statistical learning", "authors": "Logan S. McCarty", "background": "概率分布的比较在自然、社会和计算科学中是一个核心挑战。现有的方法，如最大均值偏差（MMD），在高维和非紧域上表现不佳。", "innovation": "本文引入了量子概率度量（QPM），通过将概率度量嵌入量子态空间——希尔伯特空间上的正单位迹算子，推出了一种新的方法。QPM扩展了核基方法，并解决了MMD在非紧空间上的不完整性问题。作为积分概率度量（IPM），QPM具有能够均匀近似所有有界和一致连续函数的双功能，从而在高维度中提供了对微弱分布差异的增强敏感性。对于经验分布，QPM可以用特征值方法容易地计算，并具有适用于学习和优化的分析梯度。尽管对于大样本量计算更为密集（$O(n^3)$ vs. $O(n^2)$），QPM可以作为MMD的直接替代品显著提升性能，已在生成建模的经典任务中得到了验证。该方法结合了量子力学的丰富数学框架和经典概率论，为分析和操作概率测度提供了强有力的工具", "conclusion": "通过将量子力学的框架与经典概率论相结合，本文为概率测度的分析和操作奠定了强大的基础工具。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21082", "html_url": "https://arxiv.org/abs/2508.21082", "title": "ImmunoAI: 使用热力学-动力学描述符和三维几何界面拓扑加速抗体发现的梯度提升机学习", "title_en": "ImmunoAI: Accelerated Antibody Discovery Using Gradient-Boosted Machine Learning with Thermodynamic-Hydrodynamic Descriptors and 3D Geometric Interface Topology", "authors": "Shawnak Shivakumar,Matthew Sandora", "background": "人型副流感病毒（hMPV）对儿童、老年人和免疫受损人群构成严重威胁。传统抗体发现流程耗时10-12个月，限制了其对快速突发疫情应对的能力。为此，项目引入了ImmunoAI，这是一种通过梯度提升模型预测高亲和力候选抗体的机器学习框架。该框架使用来自热力学、动力学和三维拓扑界面描述符的数据来加速抗体发现过程。", "innovation": "ImmunoAI通过使用梯度提升模型和热力学-动力学描述符以及3D几何界面拓扑来加速抗体发现。它通过训练LightGBM regressor来预测结合亲和力，减少了91%的抗体候选搜索空间。此外，通过对117对SARS-CoV-2结合对进行微调，进一步降低了Root Mean Square Error，从1.70降至0.92。项目展示了如何使用AlphaFold2预测病毒变异体3D结构，并利用模型发现两个靶向关键突变位点（G42V和E96K）的候选抗体，这些抗体具有预测的皮摩尔亲和力，是实验测试的优良候选物。", "conclusion": "ImmunoAI缩短了设计周期，能够提供更快响应的结构导向型对病毒的应对策略。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21167", "html_url": "https://arxiv.org/abs/2508.21167", "title": "RARR : 基于近表面声音 scavenging 实现稳健的现实世界活动识别", "title_en": "RARR : Robust Real-World Activity Recognition with Vibration by Scavenging Near-Surface Audio Online", "authors": "Dong Yoon Lee,Alyssa Weakley,Hui Wei,Blake Brown,Keyana Carrion,Shijia Pan", "background": "大约四分之一的痴呆症患者独自生活，导致家庭成员不得不远程承担护理责任。许多研究人员已开发出远程监测解决方案以降低护理需求，但仍存在隐私保护、活动识别、以及模型在新用户和环境中的泛化能力等方面的限制。结构振动传感器系统作为一种侵入性小的解决方案，在受控环境中通过感知由人类活动产生的表面振动来准确监测人类信息（如身份识别和活动识别）。然而，在实际用户家中部署时，现有解决方案需要大量标注数据才能实现准确的活动识别。", "innovation": "我们的可扩展解决方案通过从近表面声音中采集并合成数据进行预训练模型，然后仅使用少量数据进行微调，从而创建了每日活动跟踪的稳健框架。", "conclusion": "这种方法为家庭护理环境下的痴呆症患者活动识别提供了新的途径，通过减少对大量标签数据的依赖，提升了模型的泛化能力，并保护了用户的隐私。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21815", "html_url": "https://arxiv.org/abs/2508.21815", "title": "在Rényi差分隐私下的希尔伯特-施密特独立性实现以实现公平且隐私的数据生成", "title_en": "Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation", "authors": "Tobias Hyrup,Emmanouil Panagiotou,Arjun Roy,Arthur Zimek,Eirini Ntoutsi,Peter Schneider-Kamp", "background": "随着GDPR和HIPAA等隐私法规以及AI法案等责任框架的逐渐流行，真实数据的伦理和负责任使用受到了越来越多的限制。合成数据生成作为一种解决方案，特别适用于敏感领域如医疗健康的表数据，能够应对隐私和公平性问题。然而，当前公平感知的数据生成方法通常依赖于特定的下游任务，这限制了其应用范围。FLIP（Fair Latent Intervention under Privacy guarantees）旨在同时解决隐私和公平性问题，不依赖于固定定义的下游任务，因此具有更广泛的应用性。FLIP通过Rényi差分隐私约束确保隐私，并通过RDP兼容的平衡采样在输入空间内解决公平性问题，同时利用Centered Kernel Alignment（CKA）在潜在空间中促进公平性。", "innovation": "FLIP采用了一种基于变换器的变分自编码器，并结合了潜在扩散以生成异构表数据。与传统的公平感知数据生成方法不同，FLIP假设了一个任务无关的设置，无需依赖固定定义的下游任务，从而提高了其适用性。FLIP通过Rényi差分隐私约束确保隐私，通过RDP兼容的平衡采样在输入空间内解决公平性问题，同时利用Centered Kernel Alignment在潜在空间中促进公平性。FLIP在潜在表示和受保护特征之间鼓励统计独立性，同时能够实现公平性改进，并且在不同的下游任务下表现良好。", "conclusion": "实验结果表明，FLIP能够有效提供重要的公平性改进，不仅适用于任务无关的公平性问题，还适用于多样化的下游任务，并且在差分隐私约束下表现良好。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "利用全景X射线图像进行牙齿状况高级深度学习分类的技术", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本研究调查了深度学习方法在全景X射线图像中自动分类牙齿状况的应用。使用了一个包含11,137个专家验证标注的1,512张牙科X光片数据集，涵盖了四个条件：充填物、龋齿、种植牙和阻生牙。在进行预处理和类别均衡后，研究评估了三种方法：自定义卷积神经网络（CNN）、结合CNN特征提取与传统分类器的混合模型，以及微调的预训练架构。实验使用了5折交叉验证，通过精确度、精确率、召回率和F1得分作为评估指标。", "innovation": "研究评估了三种不同方法：自定义CNN、混合模型以及微调的预训练架构。结果显示，混合模型的CNN随机森林模型在准确率方面表现最佳，达到了85.4%，超过了自定义CNN的基线74.3%。在预训练模型中，VGG16表现最好，准确率为82.3%，其次是Xception和ResNet50。研究显示，混合模型能够提高对形态相似状况的区分度，提供高效可靠的性能。这些结果表明，结合基于CNN的特征提取与集成分类器，为实现自动牙科诊断支持提供了一条实际途径，但也强调了需要更大的数据集和进一步的临床验证。", "conclusion": "结合CNN特征提取与集成分类器提供了一种实际途径，实现自动牙科诊断支持。同时，研究指出需要更大的数据集和进一步的临床验证。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "基于混合量子-经典架构的增强自然语言生成：多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "随着量子计算在自然语言处理(NLP)领域应用的兴趣日益增长，本研究对比评估了量子文本生成模型与传统的Transformer和MLP架构。实验涉及五种不同的模型，并使用多种评价指标全面评估其性能。", "innovation": "本文创新之处在于提出了一种多模型框架，结合了量子启发的架构和混合量子-经典计算技术，系统性地评估了这些模型在不同类型的文本生成任务中的表现。", "conclusion": "传统Transformer模型在整体性能上仍然具有优势，尤其是在泛化能力和语言流畅性方面。然而，量子启发的模型在特定场景下表现出色，如QKSAN在BLEU-1分数和重复率方面具有竞争力而QASA则在词汇多样性指标上表现出色。研究结果显示，不同模型在特定的文本生成任务中有不同的适用场景。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21255", "html_url": "https://arxiv.org/abs/2508.21255", "title": "随机测度下的加权支撑点：一种可解释的生成建模替代方案", "title_en": "Weighted Support Points from Random Measures: An Interpretable Alternative for Generative Modeling", "authors": "Peiqi Zhao,Carlos E. Rodríguez,Ramsés H. Mena,Stephen G. Walker", "background": "支撑点通过用一个较小的代表性点集来总结大型数据集，这些点集可以在不访问整个数据集的情况下用于数据操作，如蒙特卡洛积分。支撑点因此提供了一种紧凑而具信息性的原始数据表示。本文基于此提出了一个基于随机加权支撑点的生成建模框架，其中的随机性源自受Dirichlet过程和贝叶斯再抽样启发的加权方案。该方法能够在不依赖于概率模型假设或神经网络架构的情况下，从固定数据集中生成多样化且可解释的样本集。", "innovation": "提出了基于随机加权支撑点的生成建模框架，其创新点在于采用了一个受Dirichlet过程和贝叶斯再抽样启发的加权方案，从而能够从固定数据集中生成多样化且可解释的样本集。该方法不依赖于复杂的概率模型假设或神经网络架构，提出了一种高效的基于凸-凹过程（CCP）的优化算法。", "conclusion": "实验证明，与诸如生成对抗网络（GANs）或去噪扩散概率模型（DDPMs）等黑盒方法相比，基于随机加权支撑点的方法在计算成本较低的情况下能生成高质量且多样化的输出，这表明随机加权支撑点提供了一种原理上合理、可扩展且可解释的生成建模替代方法。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21179", "html_url": "https://arxiv.org/abs/2508.21179", "title": "构建和测试公平感知招聘工具的合成简历", "title_en": "Synthetic CVs To Build and Test Fairness-Aware Hiring Tools", "authors": "Jorge Saldivar,Anna Gatzioura,Carlos Castillo", "background": "随着算法招聘在某些行业中的必要性日益增加，算法可以处理大量的申请者。然而，这些系统中的算法可能会无意间引入偏见，导致基于年龄、性别或国籍等因素的歧视。为了解决这个问题，需要包含多样化背景特征的简历数据集来衡量、缓解和解释算法招聘中的偏见，并评估和比较在部署前的公平性技术。然而，这样的数据集并不存在。因此，本文提出了通过数据捐赠活动收集真实材料来构建具有多样化背景特征的合成简历数据集的方法，并展示了包含1,730份简历的数据集，用作算法招聘歧视研究的基准标准。", "innovation": "本文介绍了一种基于真实材料的数据捐赠方法来构建合成简历数据集，该数据集具有多样化背景特征，旨在为算法招聘中的偏见衡量、缓解和解释提供基准标准，以及作为评估和比较公平性技术的基准。这是一种创新的数据集构建方法，解决了以往缺乏多样背景简历数据集的问题。", "conclusion": "本文通过数据捐赠活动构建了包含多样化背景特征的合成简历数据集，并展示了包含1,730份简历的数据集。该数据集旨在成为算法招聘歧视研究的基准标准，有助于评估和比较在实际部署前的公平性技术，减轻算法招聘中的偏见问题。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT与DeepSeek系列模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在跨行业改变人工智能的发展，但其开发和部署仍然面临复杂性。本文回顾了16个关键挑战，并对比了两个具有独特方法的顶尖模型：OpenAI的闭源GPT-4o（2024年5月更新）和DeepSeek-V3-0324（2025年3月），这是大型开源Mixture-of-Experts（MoE）模型。通过对比，本文展示了闭源模型（稳健的安全性、微调的可靠性）与开源模型（效率、适应性）之间的权衡。", "innovation": "本文通过比较两个大型语言模型的独特方法，展示了闭源和开源模型之间的权衡，并探索了这些模型在不同应用领域的具体应用，从而为研究人员、开发者和决策者提供理解当前LLM能力和实践指南。", "conclusion": "本文旨在引导AI的研究人员、开发者和决策者理解大型语言模型的当前能力和限制，以及最佳实践。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21372", "html_url": "https://arxiv.org/abs/2508.21372", "title": "通过矩阵分解实现从流中更快地推断细胞复杂体", "title_en": "Faster Inference of Cell Complexes from Flows via Matrix Factorization", "authors": "Til Spreuer,Josef Hoppe,Michael T. Schaub", "background": "本文探讨了一种推断问题：给定图上观察到的边流信号，将该图提升为一个细胞复杂体，使得观察到的边流信号可以作为细胞复杂体上梯度流和环流的稀疏组合来表示。此前的研究表明，该一般问题是NP难问题。", "innovation": "本文提出了一种新的矩阵分解基方法来解决该问题。与之前的启发式方法相比，该新方法在多数情况下表现仅略有逊色，但在噪声场景中表现更优，不仅在求解质量上胜过以前的最新技术，在计算速度上也更为高效。", "conclusion": "通过计算实验表明，与之前的启发式方法相比，本文提出的新方法在计算成本上显著更低，虽然在性能上仅有轻微的下降，在特定的噪声环境下甚至具有更好的性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "多知识体系双轴传播集成在医疗概念表征中的应用", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "目前的研究文献主要集中在单一知识体系或多个知识体系（如疾病、药物、手术等）的独立应用上，而没有将这些知识体系整合到一个统一的学习结构中。这导致了基于单一知识体系的概念表示学习往往是局限在单一知识体系内部，并且忽略了跨知识体系的联系。", "innovation": "本文提出了LINKO，这是由大型语言模型（LLM）增强的集成知识体系学习框架，能够同时利用多个知识体系，通过在同异构知识体系之间实现双向知识传播来增强医疗概念的表示学习。具体来说，LINKO首先利用LLM通过定制提示接入图检索增强初始化知识体系的概念嵌入，其次通过在同水平的方向进行垂直传播和横跨水平的平行知识传播联合学习多种知识体系中的医疗概念。", "conclusion": "通过在两个公开数据集上的广泛实验，验证了LINKO相比最先进的基线性能更优。LINKO作为与现有EHR预测模型兼容的插件编码器，进一步展示了在数据有限和罕见疾病预测场景中的鲁棒性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21205", "html_url": "https://arxiv.org/abs/2508.21205", "title": "多机器人路径规划与调度通过模型预测最优运输(MPC-OT)方法", "title_en": "Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)", "authors": "Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham", "background": "在机器人导航中，多个机器人在存在障碍的共同空间内导航至多个目标点。直接将机器人分配给目标点后规划路径可能会导致路径重叠和死锁。因此，需要一种新的方法，不仅可以提供最小成本路径，还能保证路径不重叠。本文提出的方法基于最优运输理论和模型预测控制，将空间离散化为K个单元，并引入K×K成本结构以描述从一个单元到另一个单元的成本，从而提供最优且不重叠的单元切换路径，最终实现路径规划和调度的高效且无冲突的机器人导航。此外，本文还提出了一种方法，通过重新计划和模型预测控制将时间结构整合到最优运输中，以应对可能无法避免的路径重叠和机器人动力学问题。", "innovation": "提出了一种基于最优运输理论和模型预测控制的新方法，用于多机器人路径规划与调度。这种方法通过将空间离散化和引入K×K成本结构来提供最优且不重叠的路径切换。此外，通过重新计划和模型预测控制解决了潜在的路径重叠和机器人动力学问题，从而实现路径规划与调度的有效方法。这种方法在最坏情况下的计算复杂度为Θ(K^3 log K)，而对于行为良好的问题，复杂度为Θ(K^2 log K)。", "conclusion": "本文提出的模型预测最优运输方法不仅解决了路径重叠和死锁问题，还考虑了实际的机器人动力学和潜在的路径重叠。该方法通过提供最优且不重叠的路径切换，能够在没有额外调度考虑的情况下实现多机器人大规模导航任务的有效执行。随着计算技术的发展，这种路径规划与调度策略在实际应用场景中的应用前景广阔。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21236", "html_url": "https://arxiv.org/abs/2508.21236", "title": "人口规模网络嵌入揭示与右翼民粹主义投票相关的教育鸿沟背后的网络结构差异", "title_en": "Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting", "authors": "Malte Lüken(1 and 2 and 3),Javier Garcia-Bernardo(4),Sreeparna Deb(5),Flavio Hafner(1 and 3),Megha Khosla(5) ((1) Netherlands eScience Center, (2) University of Amsterdam, (3) Erasmus University Rotterdam, (4) Utrecht University, (5) Delft University of Technology)", "background": "行政登记数据可以构建反映个体之间共享社会背景的群体规模网络。通过机器学习，这些网络可以被编码为数值表示——嵌入，从而自动捕捉个体在网络中的位置。研究人员为荷兰人口创造了涵盖五个共享情境（邻里、工作、家庭、同住和学校）的所有人的嵌入，以评估这些嵌入的信息量，并用于预测右翼民粹主义投票。单凭嵌入可以在一定程度上预测右翼民粹主义投票，但性能不及个体特征。将最佳子集嵌入与个体特征结合仅略微提高了预测效果。通过将嵌入转换为使维度更加稀疏和正交的形式，研究团队发现一个维度与结果密切相关，并将其映射回整体网络，揭示了不同学校关系和受教育程度与右翼民粹主义投票有关的网络结构差异。", "innovation": "研究方法上，通过将嵌入转换为使其维度更加稀疏和正交的形式，使嵌入变得可解释；在实质上，将网络结构差异与教育水平联系起来，揭示了不同学校关系和教育背景与右翼民粹主义投票之间的关系，为研究提供了新的视角和定量证据。", "conclusion": "该研究在方法上贡献了如何使大规模人口网络嵌入变得可解释，并在实质上链接了教育结构差异与右翼民粹主义投票，揭示了教育层次上的重要差异。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21524", "html_url": "https://arxiv.org/abs/2508.21524", "title": "Compute-in-Memory CNN加速器中的二进制权重多比特激活量化", "title_en": "Binary Weight Multi-Bit Activation Quantization for Compute-in-Memory CNN Accelerators", "authors": "Wenyong Zhou,Zhengwu Liu,Yuan Ren,Ngai Wong", "background": "计算即存取（CIM）加速器作为一种提升卷积神经网络（CNNs）能效的方法逐渐受到关注。将CNN部署到CIM平台上通常需要对网络权重和激活值进行量化以满足硬件限制。然而，现有的方法要么以牺牲精度为代价优先提高硬件效率，使用二进制权重和激活值量化；要么为了更高的精度使用多比特权重和激活值但效率有限。", "innovation": "提出了一个新颖的二进制权重多比特激活（BWMA）方法以提高CNN在CIM加速器上的能效和精度。贡献包括：为每层推导出了权重量化的确切解，显著提高了二进制化权重的表示能力；开发了激活量化的一种可微分函数，近似理想多比特函数，同时避免了广泛搜索最优设置。", "conclusion": "通过CIFAR-10和ImageNet数据集的全面实验，展示了BWMA方法在精度方面的显著提高，分别在两个数据集上记录了1.44%-5.46%和0.35%-5.37%的增益。此外，硬件仿真结果表明，4比特激活量化在硬件成本和模型性能之间达到了最佳平衡。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO: 对遥感自监督预训练的深刻探索", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习已成为遥感领域的重要工具，因为遥感数据通常有大量的未标记数据可供使用。在此项研究中，作者探索了使用DINO（一种对比性自监督方法）对遥感图像进行预训练的可能性，并提出了专为卫星图像表示学习设计的SatDINO模型。通过在多个数据集和多种测试设置下进行广泛实验，作者证明了SatDINO在多个基准测试中优于基于常见掩码自编码器（MAE）的其他先进方法，取得了竞争性的结果。", "innovation": "作者提出了SatDINO模型，并通过引入新的地面采样距离（GSD）编码和自适应视图采样等创新方法，显著提升了模型性能。作者还进行了详细的消融研究，评估了SatDINO各组件的贡献。这些创新可以在不依赖原SatDINO模型的情况下独立使用。", "conclusion": "SatDINO模型在多种基准测试中表现出色，尤其在 mask autoencoder 方法占主导地位的环境下。作者提出的方法为进一步提升遥感图像处理的自监督学习提供了新的见解。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "从胸部X光片进行肺部疾病严重程度分类的深度主动学习：存在类别不平衡时的数据更少学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "这项研究旨在解决从胸部X光片（CXR）中分类肺疾病严重程度时所需标注数据量大的问题，并且在类别不平衡的条件下进行分类。背景中的数据收集了2020年1月至11月在艾默里卫生保健附属医院的963名患者（平均年龄59.2岁，其中481名为女性）的2319份X光片，所有患者均确诊为COVID-19。研究人员采用3到6名认证放射科医生独立标记为正常、中度或严重状态，然后通过贝叶斯神经网络近似和加权损失函数实现深度主动学习，以减少所需的标注数据量。", "innovation": "该研究创新性地应用了深度主动学习方法结合贝叶斯神经网络近似和加权损失函数技术，来减少肺疾病严重程度分类中所需使用标记数据的数量，并有效应对类别不平衡的问题。研究表明，熵采样在二分类任务中的准确率可达93.7%，使用了15.4%的数据，而在多分类任务中，平均标准差采样达到70.3%的准确率，使用了23.1%的数据。这些方法优于更复杂和计算成本更高的获取策略，并显著降低了标记需求。", "conclusion": "深度主动学习结合贝叶斯神经网络近似和加权损失函数能够有效减少标注数据的需求，同时处理类别不平衡问题，并保持或超过诊断性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21531", "html_url": "https://arxiv.org/abs/2508.21531", "title": "自适应生成矩匹配网络以改善依赖结构的学习", "title_en": "Adaptive generative moment matching networks for improved learning of dependence structures", "authors": "Marius Hofert,Gan Yao", "background": "文章介绍了在最大均差（MMD）中的混合核内自适应带宽选择过程，用于拟合生成矩匹配网络（GMMNs）。通过调整训练过程中的核数量和使用验证损失的相对错误作为提前停止标准，以提高训练性能。这种方法被应用于几种场景来验证其有效性。", "innovation": "提出了一种自适应带宽选择方法，该方法在训练过程中根据相对训练损失增加核的数量，并使用验证损失的相对错误作为提前停止标准。这种方法提高了训练表现，尤其是在验证最大均差轨迹、样本以及验证MMD值方面的改进显著。此外，这种方法在高维情况下的准随机样本与伪随机样本对比，以及在计算巴克特看涨期权和预期短缺风险度量方面表现出了优越性。", "conclusion": "自适应训练的生成矩匹配网络（AGMMNs）在三类应用中优于传统的GMMNs，并且在两个数据集上证明了自适应预估性能的提升，不仅仅是依赖结构学习的改善，还包括了传统参数Copula模型的改进。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "层叠的SSL特征能否改善儿童语音的零样本ASR性能？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "自动语音识别系统（ASR）在处理儿童语音时常常出现准确性问题，这是因为儿童语音具有独特的声学特性和语言特征。虽然近年来自监督学习（SSL）模型在处理成人语音时取得了显著进步，但精确转录儿童语音仍然是一个重大挑战。这项研究探索了自监督学习预训练模型提取的层间特征——具体使用Wav2Vec2、HuBERT、Data2Vec和WavLM模型，用于改进在儿童语音上零样本场景中的ASR性能。研究使用WSJCAM0成人语音进行训练，使用PFSTAR儿童语音进行测试，通过Kaldi工具包构建了一个简化DNN模型，分析了这些模型提取的特征，确定了对儿童语音的ASR性能有最显著提升的层。实验结果表明，Wav2Vec2模型第22层实现了最低的词错误率（WER）5.15%，相比直接零样本解码的WER（10.65%），绝对提高了51.64%。年龄分组分析还显示，随着年龄的增长，性能持续提升，即使在较年轻的儿童组中，使用SSL特征也有显著的性能改进。进一步的CMU Kids数据集实验也验证了这些趋势，表明该方法具有良好的泛化能力。", "innovation": "研究创新性地利用自监督学习（SSL）模型提取的特定层间特征，显著改进了零样本场景下儿童语音的ASR性能。通过这种方式，能够在不需要大量儿童语音数据的情况下，提升ASR系统在儿童语音识别上的准确度，对于需要快速、低成本获取儿童语音数据的应用场景具有重要意义。", "conclusion": "通过使用精心选择的自监督学习预训练模型（如Wav2Vec2、HuBERT、Data2Vec和WavLM模型）的层间特征，并集成到简化DNN架构中，可以显著提升ASR系统在零样本场景下处理儿童语音的性能。尤其在儿童年龄较大的组别表现最为显著，展示了该方法在不同年龄段儿童语音识别上的泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次选择的异构ensemble生成方法用于虚假新闻检测", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏差，例如确认偏误，使得个体特别容易相信和传播社交媒体上的假新闻，这对公共卫生和政治等领域造成了严重后果。基于机器学习的事实核查系统已被广泛研究以减轻这一问题。其中，集成方法特别有效，通过结合多个分类器来提高鲁棒性。然而，这些系统的性能高度依赖于组成分类器的多样性——选择真正多样化的模型仍然是一个关键挑战，尤其是当模型倾向于学习重复的模式时。", "innovation": "本文提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性和绩效。该方法首先计算分类器之间的成对多样性和应用层次聚类来组织它们到不同的粒度层次中。HierarchySelect 然后探索这些层次来选择每个层次的一个分类器池，每个池代表一个独特的内池多样性。这种方法首先选择最多样化的池进行集成构建。选择过程结合了反映每个分类器绩效的评估指标，以确保集成也具有良好的泛化能力。", "conclusion": "我们使用来自六个不同应用领域和不同类别的分类器的数据集进行了实验。我们的方法与肘部启发式方法和最先进的基线进行了比较。结果显示，我们的方法在六个数据集中的两个实现了最高的准确性。详细实现可在项目存储库中找到:这个链接。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21652", "html_url": "https://arxiv.org/abs/2508.21652", "title": "边缘设备上的机器智能：强化学习指导的可解释心电信号模式定位", "title_en": "Machine Intelligence on the Edge: Interpretable Cardiac Pattern Localisation Using Reinforcement Learning", "authors": "Haozhe Tian,Qiyu Rao,Nina Moutonnet,Pietro Ferraro,Danilo Mandic", "background": "匹配滤波器广泛用于信号定位，由于其高效性和可解释性。然而，当信号与噪声比率（SNR）低时，如在边缘设备上记录的信号，这些滤波器的效果会减弱，原因是在滤波器限制的长度内，明显的噪声模式可能与目标信号非常相似。这在诸如耳电生理记录（耳-ECG）中尤为突出，其中的心电图信号受到衰减和大量伪影的干扰。为了解决这个问题，我们提出了一种新的方法——序列匹配滤波器（SMF），它通过强化学习代理替代传统的单一匹配滤波器，并设计了一系列滤波器。", "innovation": "我们将滤波器的设计过程转化为一个序列决策过程，从而能够自适应地设计出专用于特定信号的数据驱动滤波器序列，同时保持完全的可解释性，通过揭示重要模式来推动决策过程。此研究提出的方法展现了出色的可靠性和可解释性，特别是在两个具有挑战性的ECG数据集上的R-峰值检测和生理状态分类表现。此外，该方法还具有广泛的应用潜力，可以在多种需要从噪声干扰信号中准确定位模式的应用中扩展使用。", "conclusion": "所提出的SMF框架在噪声干扰信号中精确而可解释的心电信号模式定位方面显示出巨大的潜力，已经达到了最先进的R-峰值检测和生理状态分类性能，在两个具有挑战性的ECG数据集上得到了验证。此外，该方法还可扩展应用于各种需要从噪声信号中准确定位模式的应用场景中。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21663", "html_url": "https://arxiv.org/abs/2508.21663", "title": "使用通用机器学习键间势进行表面稳定性建模：全面劈裂能耗基准研究", "title_en": "Surface Stability Modeling with Universal Machine Learning Interatomic Potentials: A Comprehensive Cleavage Energy Benchmarking Study", "authors": "Ardavan Mehdizadeh,Peter Schindler", "background": "机器学习键间势（MLIPs）通过结合量子力学的精确性和经典模拟的效率，彻底改变了计算材料科学，使其能够以前所未有的方式探索周期表中的材料属性。尽管MLIPs已经在预测体材料性质方面取得了显著成功，但尚未对这些通用MLIPs（uMLIPs）预测劈裂能量的能力进行系统评估。劈裂能量是影响断裂、催化、表面稳定性和界面现象的关键性质。本研究通过使用我们之前建立的包含36,718种元素、二元和三元金属化合物的密度泛函理论数据库，对19种最先进的uMLIPs进行了全面的劈裂能耗基准测试。", "innovation": "1. 给出了全面的uMLIPs基准测试，涵盖了化学组成、晶体系统、厚度和表面取向的多样性建模。2. 发现了训练数据组成对模型性能的影响，尤其强调了非平衡配置的数据在保持模型精度方面的重要性。3. 简单的模型架构在适当的数据集上训练后，能达到与复杂模型相似的准确性，但提供10-100倍的计算速度提升。这些发现表明社区应专注于生成战略性的训练数据，以捕捉相关物理现象。", "conclusion": "研究表明，uMLIPs能够准确预测劈裂能量，尤其是在非平衡配置的数据上训练的模型表现尤为突出。模型的复杂性并不是提高性能的关键因素，数据集的组成才是决定因素。该研究建议，在使用MLIPs进行材料性质预测时，应特别关注生成捕捉到关键物理现象的数据集。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "大型整片图像档案中标准化多层组织图谱以增强人工智能集成与搜索", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "WSI是通过扫描含有生物样本（如组织切片或细胞样本）的整个玻片来创建的高分辨率数字图像，可用于AI算法的开发、病理学疾病诊断、肿瘤学癌症研究等领域。但当前没有标准的元数据，因此在大规模图像集合中进行WSI内容的选择主要依赖于人工检查，这不适用于百万级别以上的对象。因此，需要一个通用框架来生成WSI的2D索引图，以及为特定领域提供特性挖掘机制。", "innovation": "该论文提出了一种生成WSI的2D索引图的通用框架和特定应用领域的特性挖掘机制。具体表现为：将每个WSI集合增强为包含详细组织信息的组织图，组织图分为三个层次：来源层、组织类型层和病理改变层，将WSI分割到特定类别，实现不同目录的互操作性，并通过具体例子展示了WSI目录、机器学习和基于图的WSI表示方案的附加优势和适用性。", "conclusion": "通过标准化多层组织图谱，增强了大规模WSI档案的人工智能集成和搜索能力，实现了WSI内容的高效管理和自动识别，为AI算法开发提供了更丰富、更细化的数据支持，能够对特定领域的需求进行更精确的匹配和应用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21664", "html_url": "https://arxiv.org/abs/2508.21664", "title": "通过连续排名概率得分进行集合预报的轨迹学习：洛伦兹'96案例研究", "title_en": "Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study", "authors": "Sagy Ephrati,James Woodfield", "background": "该论文利用连续排名概率得分（CRPS）作为损失函数来展示轨迹学习在集合预报中的可行性。通过洛伦兹'96系统这种双尺度案例研究，该研究开发并训练了加性和乘性随机参数化方法以生成集合预测。", "innovation": "使用CRPS作为损失函数来进行轨迹学习并据此开发和训练了加性和乘性随机参数化方法。研究结果表明，基于CRPS的轨迹学习产生的参数化方法既准确又具有锐度。与基于梯度拟合的方法相比，该方法在短期预测中表现更出色。", "conclusion": "该方法在短期预报应用中显示出特别的潜力，因为其在短回溯时间内的准确性。生成的参数化方法易于校准，并且优于基于梯度拟合的参数化方法，特别是在短时预报中。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21484", "html_url": "https://arxiv.org/abs/2508.21484", "title": "生物医学研究中的数据驱动数字孪生发现", "title_en": "Data-driven Discovery of Digital Twins in Biomedical Research", "authors": "Clémence Métayer,Annabelle Ballesta,Julien Martinelli", "background": "近年来，技术的进步扩大了高通量生物数据集的可用性，使可靠的数字孪生设计成为可能。这种计算工具能代表关键的反应网络，驱动扰动或药物响应，并指导药物发现和个人化治疗。然而，开发这类工具仍然依赖于人类建模者的艰苦数据整合，因此迫切需要自动化的解决方案。物理学科的数据驱动系统发现，解决了数据清理和明确的控制规律问题，激发了在生物科学中应用类似技术的兴趣，但生物科学存在独特挑战。", "innovation": "该论文回顾了从生物时间序列自动推断数字孪生的方法，着重评估了八种生物和方法学挑战，发现稀疏回归在大部分情况下优于符号回归，特别是在使用贝叶斯框架时。此外，论文强调了深度学习和大型语言模型在整合先验知识方面的作用，并提出了一个混合和模块化的框架，结合基于化学反应网络的机理分析、贝叶斯不确定性量化以及生成和知识整合能力的深度学习来推进数字孪生的开发。同时，提出了一个基准框架来评估方法的性能，涵盖了所有挑战。", "conclusion": "尽管没有单一的方法能够解决所有挑战，但混合和模块化框架的开发将是推进学习数字孪生进展的关键。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式AI实现天气自适应学习以增强气候复原力教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "当前，气候复原力教育需要更加贴近地方情境、能够适应变化的学习体验。传统的教育方式在应对气候变化的信息和挑战方面存在不足，亟需新的平台和技术来提升教育的互动性和有效性。", "innovation": "本文介绍了一种新颖平台——Future Atmospheric Conditions Training System (FACTS)，它结合物联网（IoT）传感器收集的实时大气数据和知识库中的定制资源，动态生成本地化的学习挑战。该平台利用生成式AI服务器分析学习者的反应，并提供个性化的反馈和支持，从而增强了学习者的参与度和对气候复原力的认知。", "conclusion": "用户评估的结果表明，参与者认为该系统易于使用，并且对提升气候复原力相关知识非常有成效。这些发现表明，将物联网和生成式AI技术集成到适应气候变化的学习技术中，对于增强教育参与度和提高气候意识具有很大的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 印地语句子相似性数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "目前存在大规模的句子文本相似性（STS）数据集和模型，但通常涵盖更广泛的语言，而忽略了一些小众语言如印地语（Marathi）。因此，本研究旨在创建一个专门针对印地语的句子文本相似性数据集和模型。", "innovation": "本研究提出了MahaSTS数据集和MahaSBERT-STS-v2模型。MahaSTS是一个由人工注释的句子文本相似性数据集，包含了16860对印地语句子，每对句子用0-5之间的连续相似度评分进行标注。为了确保监督平衡，数据集在0-5分的所有相似度分数上均匀分布，以减少标签偏差并提高模型稳定性。通过对比实验，该研究展示了MahaSTS数据集对印地语句子相似性任务的有效性，强调了人类标注、专门微调和结构化监督在资源有限环境中的重要性。", "conclusion": "本研究通过提出MahaSTS数据集和MahaSBERT-STS-v2模型，填补了印地语句子相似性研究的空白。实验结果表明，MahaSTS能够在印地语中有效训练句子相似性任务，突显了人类策划的标注、目标微调和结构化监督在低资源设置中的影响。该数据集和模型已在公开地址 this https URL 共享。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21672", "html_url": "https://arxiv.org/abs/2508.21672", "title": "激励辅助引导无遗憾玩家的软诱导框架", "title_en": "A Soft Inducement Framework for Incentive-Aided Steering of No-Regret Players", "authors": "Asrin Efe Yorulmaz,Raj Kiriti Velicheti,Melih Bastopcu,Tamer Başar", "background": "本文探讨了一个调解人增强的两个玩家的标准形式博弈中的一个导航问题，调解人通过信息和激励设计来引导玩家朝向特定的动作组合。此外，设计信息方法本身可能无法引导玩家到达任何期望的动作组合，也不能仅通过次线性支付方案来实现。因此，研究工作者试图找到一种可以实现目标的最低支付限制，并提出了一种新的方法来解决信息设计的局限。", "innovation": "本文提出了一种增强的方法，即在重复游戏开始前进行一次性信息设计阶段，将之前的互动转变为斯塔克尔伯格博弈，以提高玩家动作组合收敛到目标点的速度，并且随着概率很高。", "conclusion": "本文通过理论上证明和实证结果支持，证明了通过这一增强方法，玩家的动作组合以常数因子的概率更快地收敛到目标点。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中的GPT-5基准测试：可测量的提升以及持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展现了巨大的潜力。GPT-5是专为肿瘤学用途开发的一种新型LLM系统。该研究通过两项评估基准对GPT-5进行了测试，包括ACR放射肿瘤学住院医师考试（TXIT，2021）和一个由60个真实的放射肿瘤科案例组成的多样化的疾病项目和治疗方法的数据集。", "innovation": "GPT-5在放射肿瘤学领域取得了显著的性能提升，特别是在剂量和诊断方面。在TXIT基准测试中，GPT-5的平均准确率达到了92.8%，显著高于GPT-4和GPT-3.5。此外，GPT-5在生成治疗建议方面也得到了高度评价，正确性和全面性平均得分分别为3.24/4和3.59/4。研究还发现了一些需要进一步改进的地方，尤其是在复杂场景下。", "conclusion": "尽管GPT-5在放射肿瘤学的多项选择题基准中表现出色，并且其产生的治疗建议在实际应用中得到了高度评价，但仍需专家监督以确保其临床实施的质量。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21654", "html_url": "https://arxiv.org/abs/2508.21654", "title": "I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks", "title_en": "I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks", "authors": "Daryna Oliynyk,Rudolf Mayer,Kathrin Grosse,Andreas Rauber", "background": "模型窃取攻击威胁了作为服务提供的机器学习模型的机密性。尽管这些模型被隐藏起来，恶意方仍可以通过查询模型来标记数据样本并训练自己的替代模型，从而违反了知识产权。尽管该领域不断有新的攻击被发现，但这些攻击的设计和评估标准不一，这使得比较先前的工作和评估该领域的进步变得困难。本文首次通过提供设计和评估模型窃取攻击的建议填补了这一空白。我们特别研究了攻击图像分类模型的攻击方法，这是依赖于训练替代模型的最大攻击群。本文提出了第一个综合性的威胁模型，并开发了一个攻击评估框架。此外，我们分析了相关工作中攻击配置，以了解哪些任务和模型得到了最多的研究。基于我们的发现，我们提出了攻击开发的最佳实践，包括实验之前、之中和之后的实践，并推导出关于模型窃取攻击评估的广泛开放研究问题。我们的发现和建议也适用于其他问题领域，从而建立了第一个通用的模型窃取攻击评估方法", "innovation": "本文首次提出了设计和评估模型窃取攻击的建议。作者特别研究了依赖于训练替代模型的图像分类模型攻击。提出了第一个综合性的威胁模型，并开发了用于比对攻击的框架。此外，作者分析了相关工作中的攻击配置，以了解哪些任务和模型得到了最多的研究。进行了实验以验证最佳实践，并推导出很多关于模型窃取攻击评估的问题。这为该领域奠定了第一个通用的评估方法", "conclusion": "本文研究了模型窃取攻击，提出了一种综合性的威胁模型，并开发了攻击评估框架。实验验证了最佳实践，并提出了大量的开放研究问题。这些发现为该领域奠定了一个通用的评估方法，既适用于图像分类模型，也适用于其他问题领域。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么只停留在单词层面？通过行级OCR展现更大的视野", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术会将每个字符分割开独立识别，这使得它们在字符分割上容易出错，并且缺少语境以利用语言模型。近年来，序列到序列翻译技术的发展促成了一种新的方法，即首先检测出单词，然后每次输入一个单词到模型中，直接输出整个单词作为字符序列。这种方法可以更好利用语言模型并绕过容易出错的字符分割步骤。然而，我们的观察指出，这种方法已经将准确度的瓶颈转移到了单词分割上。因此，本论文提议从单词级的OCR发展到行级的OCR，这样可以绕过单词检测的错误，并提供更长的句子上下文，更好地利用语言模型。", "innovation": "本文提出了一种自然和逻辑的进步方法，从单词级OCR过渡到行级OCR。这种方法允许绕过单词检测的错误，并提供更长的句子上下文，从而更好地利用语言模型。实验结果表明，该方法不仅提高了OCR的准确性和效率，还展示了向行级OCR过渡的潜在好处，特别是在处理文档图像方面。", "conclusion": "我们的实验结果显示，与基于单词的管道相比，该方法的整体端到端准确率提高了5.4%，并且效率提高了4倍。随着大型语言模型的持续改进，该方法也有望利用这些新的进展。此外，我们还贡献了一个精心整理的包含251张英文页面图像的数据集，这些图像都标记了行级别注释。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.16363", "html_url": "https://arxiv.org/abs/2310.16363", "title": "有限时间分析三尺度约束演员-评论家和约束自然演员-评论家算法", "title_en": "Finite-Time Analysis of Three-Timescale Constrained Actor-Critic and Constrained Natural Actor-Critic Algorithms", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "演员评论家方法在大规模状态-动作空间的强化学习任务中得到了广泛应用。本文考虑了在涉及不等式约束的约束马尔可夫决策过程（C-MDP）中使用函数近似的方法，进行了这两种算法在非独立非同分布（非-i.i.d.，Markovian）设置下非渐进分析。目标和约束函数是特定预定成本函数的政策相关的长期平均值。", "innovation": "提出了三尺度约束演员评论家和约束自然演员评论家算法，并对其在非-i.i.d.环境下的有限时间分析结果进行了证明。该研究证明这两种算法可以找到性能（拉格朗日）函数的一阶稳定点（即，∑ ∇ L(θ,γ) ² ≤ ε），样本复杂度为 Ȓˁ(ε⁻½−2.5)。", "conclusion": "实验结果在三个不同的Safety-Gym环境中得到了验证。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21615", "html_url": "https://arxiv.org/abs/2508.21615", "title": "适应变化：在概念漂移情况下建模建筑热动力学的持续学习与迁移学习比较", "title_en": "Adapting to Change: A Comparison of Continual and Transfer Learning for Modeling Building Thermal Dynamics under Concept Drifts", "authors": "Fabian Raisch,Max Langtry,Felix Koch,Ruchi Choudhary,Christoph Goebel,Benjamin Tischler", "background": "当可用数据有限时，迁移学习（TL）是目前最有效的建筑热动态建模方法。TL通过微调预训练模型来适应特定建筑的目标。然而，在初始微调后，如何随着时间收集更多的运行测量数据进行进一步优化并不明确，尤其是当建筑的热动态（如翻新或人口变化）发生改变时。持续学习（CL）方法在机器学习文献中被用来更新变化系统的模型，可以利用预训练模型来不断解决这一挑战。虽然存在着迁移学习方法，但缺乏针对建筑热动态随时间变化的全面研究，以改善预测准确性并应对概念漂移带来的难题。因此，这项研究将比较几种CL和TL策略以及从头开始训练的模型在建筑运行期间进行热动力学建模的效果。研究使用来自中欧单户住宅的5-7年的模拟数据进行评估，包含翻新和人口变化引起的概念漂移场景。研究结果显示，提出的基于季节记忆持续学习策略（Seasonal Memory Learning, SML）不仅在没有概念漂移的情况下相比基准的初始微调提高了28.1%，而且在有概念漂移的情况下提高了34.9%，同时保持了较低的计算成本。", "innovation": "提出了一种基于季节记忆的持续学习策略（Seasonal Memory Learning, SML），该策略不仅能显著提高预测精度（在存在概念漂移的情况下提高34.9%，无概念漂移时提高28.1%），还能维持较低的计算成本，从而解决了建筑热动力学建模中持续变化所带来的挑战。", "conclusion": "这项研究通过比较几种持续学习和迁移学习策略，提出了能够在概念漂移的情况下更有效地改进建筑热动力学建模的基于季节记忆的持续学习方法，该方法不仅在预测准确性上表现出色，同时在计算成本上也具有优势。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "野外领域的泛化：分离分类与领域感知表示", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评估如CLIP这样的基础模型在领域泛化（DG）方面的性能颇具挑战性，因为网页规模的预训练数据可能涵盖了现有的许多基准测试。当前的领域泛化评估可能并不充分具有挑战性，也不能充分测试真正的未见过的数据场景。文章提出了一种在CLIP遇到更具挑战性的未见过数据的现实场景中评估其域泛化能力的方法。", "innovation": "提出了CLIP-DCA（领域感知增强的解纠缠分类方法），旨在通过分离领域感知表示和增强领域感知来改进领域泛化。与现有方法相比，无论是在整体评估还是在更具挑战性的域外数据集上，均显示出显著的性能提升。", "conclusion": "通过细调图像网（ImageNet）后的33个多样化的数据集进行评估，并通过去学习（unlearning）来模拟让CLIP“忘记”某些领域。CLIP-DCA方法在挑战性评估中显示出显著的性能改进，特别是在更加领域外的数据集上。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "爱丽丝在可微分奇境中的冒险——卷一，旅行记", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "神经网络无所不在，从大量语言模型、语音转录系统、分子发现算法、机器人，到更多的应用。神经网络可以简化为由可微分基础组成的组合，研究这些模型意味着学习如何编程和与这些模型互动，这称为可微分编程。本文为像爱丽丝这样的初学者介绍这一迷人的可微分编程领域。", "innovation": "文章着眼于通过自动微分优化函数的基本原理，和处理序列、图形、文本和音频的常用设计。介绍了卷积、注意力和递归块等重要设计技术，将理论与代码（PyTorch和JAX）相结合，帮助读者理解最先进的模型，如大量语言模型和多模态架构。", "conclusion": "文章通过爱丽丝的视角，提供了一个直观且自包含的核心技术介绍，旨在缩小理论与实际代码之间的差距，使读者能够理解最新的神经网络模型。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.00342", "html_url": "https://arxiv.org/abs/2402.00342", "title": "联邦学习中隐私威胁及其对策综述", "title_en": "Survey of Privacy Threats and Countermeasures in Federated Learning", "authors": "Masahiro Hayashitani,Junki Mori,Isamu Teranishi", "background": "联邦学习因其无需直接交换训练数据而被认为是一种隐私保护学习方法，但联邦学习中仍存在隐私威胁。尽管已经研究了隐私保护措施，但尚未针对典型类型的联邦学习（例如：水平联邦学习、垂直联邦学习和迁移联邦学习）进行全面而具体的隐患分类和描述。", "innovation": "本文对典型类型的联邦学习中的隐私威胁及其对策进行了阐述。", "conclusion": "本文详细描述了水平联邦学习、垂直联邦学习和迁移联邦学习中常见的及独有的隐私威胁，并提供了相应的隐私防护措施。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.19470", "html_url": "https://arxiv.org/abs/2305.19470", "title": "低相干矩阵的标签嵌入", "title_en": "Label Embedding via Low-Coherence Matrices", "authors": "Jianxin Zhang,Clayton Scott", "background": "标签嵌入是一种用于多类分类问题的框架，其中每个标签由一个固定维度的独特向量表示，训练过程包括将模型输出匹配到正确标签的向量。尽管标签嵌入在极端分类和零样本学习中取得了成功，并且提供了计算和统计上的优势，但其理论基础仍不够完善。本文探讨了标签嵌入在极端多类分类中的应用，其中类的数量非常大。", "innovation": "本文提出了标签嵌入的分析，揭示了计算和统计效率之间的权衡，这种权衡通过嵌入矩阵的相干性量化。进一步展示了在满足Massart噪声条件下，随着相干性足够低，标签嵌入的统计性惩罚会消失。这些分析支持了一个简单、可扩展且易于并行的算法。", "conclusion": "实验结果证明了该算法在大规模应用中的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "无监督视频连续学习通过非参数深度嵌入聚类", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频作为复杂而丰富的时空媒体信息，在许多应用中广泛使用，但尚未充分探索无监督连续学习领域。先前的研究仅关注监督连续学习，依赖于数据标签和任务边界的已知知识，而标记数据的成本高且不实际。无监督视频连续学习（uVCL）更为复杂，因为处理视频数据需要额外的计算和内存要求，这给学习带来更大挑战。为此，研究提出了一个考虑每个任务期间学习无结构视频数据类别的基准实验协议，并利用转移学习从先前任务作为当前学习任务的知识转移的初始状态，进行无标签和无类别边界的深入评估，结果表明所提方法在连续学习多个任务时显著提升了模型性能.", "innovation": "提出了无监督视频连续学习（uVCL）的非参数深度嵌入聚类解决方案。没有提供任务边界和标签的情况下，通过未监督的视频变换网络提取的深层嵌入视频特征的核密度估计（KDE）作为非参数概率数据表示，并引入了新颖性检测标准，以动态扩展内存聚类，以便在学习后续任务时捕捉新的知识。方法利用从先前任务转移学习作为当前学习任务知识转移的初始状态，并发现这种方法在学习多个任务时显著提高了模型性能.", "conclusion": "该研究提出了一种无监督的视频连续学习方法，通过非参数的深度嵌入聚类解决未标记和无任务边界的视频连续学习问题，方法在一系列标准视频动作识别数据集（UCF101，HMDB51，Something-to-Something V2）上实现了显著的性能提升，不依赖于任何标签或类边界的使用."}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba状态空间模型是李雅普诺夫稳定的学员", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba状态空间模型（SSMs）近期在多种任务中超过了最先进的（SOTA）基于Transformer的大型语言模型（LLMs），并且被广泛采用。然而，这类基于循环的深度模型（如SSMs）的学习稳定性问题，特别是其循环动态的敏感性，是其一大隐患。尽管Mamba模型常常用混合精度微调（MPFT）和参数高效微调（PEFT）等常见微调方法进行调整，但其循环动态在这类微调方法下的稳定性仍未被研究。", "innovation": "本文通过实验证明，Mamba LLMs对于包含MPFT和PEFT两种方法组合的微调方法具有极其稳定的反应，对于基于注意力的模型来说，这与Transformer LLMs形成鲜明对比。进一步地，通过动态系统理论（特别是李雅普诺夫稳定性理论），我们证明了Mamba LLMs的循环动态是稳定的。最后，利用MPFT和PEFT研究了Mamba的上下文语言任务学习能力（ICL），为后续研究提供了新的视角。", "conclusion": "本文展示了Mamba LLMs在基于循环动态的深度模型稳定性方面超出了预期的表现，并利用MPFT和PEFT方法研究其在自然语言任务中的上下文学习能力，补充了之前的相关研究工作。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21804", "html_url": "https://arxiv.org/abs/2508.21804", "title": "考虑用于信息性定时治疗因果效应估计", "title_en": "Considerations for Estimating Causal Effects of Informatively Timed Treatments", "authors": "Arman Oganisian", "background": "许多流行病学研究通常关注估计一系列治疗决策对生存结果的因果影响。然而，在很多情况下，治疗决定并不发生在固定的时间点上，而是因个体而异，并可能与后续治疗决策和潜在结果有关。文献中关于这些问题的认识不够充分，这就是促使本文进行探讨和研究的原因。文章进一步正式化了信息性定时的问题，描述了忽略它所带来的问题，展示了g方法如何用于分析定时信息性的顺序治疗。详细说明了等待时间可以被视为时间依赖性混杂变量的情形，并通过合成示例解释了不调整这些等待时间可能导致的偏差，以及如何在患者可能在治疗间死亡或被截断的情况下进行调整。联系到了使用离散时间和连续时间模型来进行调整和识别之间的关联。最后，提供了使用公开软件进行实现的指导和示例。文章强调了考虑时间对有效推理的重要性以及可以通过调整治疗间隔时间来纠正信息性时间的方法。", "innovation": "1. 使用合成示例展示了g方法如何识别和调整信息性定时治疗所带来的偏差。\n2. 连接了使用离散时间和连续时间模型进行调整和识别的方法。\n3. 提供了实际操作中使用公开软件进行实现的指导和示例。", "conclusion": "1. 考虑时间对有效推理至关重要。\n2. 通过调整治疗间隔时间可以纠正信息性时间的问题。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark: 一种针对工业机床控制器动态水印的强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": "工业4.0中高度网络化的机床控制器（MTCs）是重放攻击的主要目标。此类攻击利用过时的传感器数据操纵执行器。当前的动态水印方案假设线性高斯动力学，并使用常数水印统计量，这使得它们对于MTCs的时间变化、部分专有行为易受攻击。", "innovation": "本文提出了DynaMark，一种基于强化学习框架的动态水印方法。该方法将动态水印建模为马尔可夫决策过程（MDP），并在线学习自适应策略。它根据可用测量值和检测器反馈动态调整零均值高斯水印的协方差，无需系统知识。DynaMark动态平衡控制性能、能耗和检测置信度。此外，作者提出了一种贝叶斯信念更新机制，用于线性系统中的实时检测置信度更新。", "conclusion": "在西门子Sinumerik 828D控制器数字双胞胎上，DynaMark在保持标准轨迹的同时，水印能量减少了70%，并维持与采样间隔相当的平均检测延迟。物理步进电机测试床验证了这些发现，启动报警率更快，控制性能下降更少，并且超过了现有基准。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE：一种面向LLM任务特定指令调优的基于奖励的数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "指令调优强调了大型语言模型（LLMs）在各种领域生成更可控和有效的输出的巨大潜力。现有的方法主要依赖人工设计的相似性度量来选择与测试数据分布相匹配的训练数据，旨在最小化指令调优损失，从而提高目标任务的性能。然而，观察到指令调优损失（即后续标记预测的交叉熵损失）往往不是与实际任务性能成单调关系，这削弱了现有数据选择方法的有效性。", "innovation": "本文提出ROSE，一种基于奖励的指令调优数据选择方法，通过利用成对偏好损失作为奖励信号来优化任务特定指令调优的数据选择。ROSE通过适应影响公式来近似训练数据点相对于少量示例验证集的影响力，从而选择最相关的训练数据点。实验结果显示，仅使用ROSE选择5%的训练数据，该方法在多种基准数据集和不同模型架构上均能达到与使用完整训练数据集微调方法相媲美的性能，并且超过了现有的其他数据选择方法。", "conclusion": "本研究方法显示了其在多个基准数据集和不同模型架构上的稳健泛化能力，实验表明通过仅选择5%的训练数据，该方法在特定任务指令调优上取得了与使用完整数据集微调相当甚至更好的结果。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: 一个用于一致性预测的Python库", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "一致性预测（CP）是一种统计框架，用于生成具有保证覆盖率概率的预测区间或集合。尽管CP算法已从传统的分类器和回归模型进化到深度神经网络（DNNs）、图神经网络（GNNs）和大规模语言模型（LLMs）等复杂的深度学习模型，现有的CP库却缺乏支持大规模DL场景的模型和扩展性。因此，需要一个专门为深度学习场景设计的库来集成最新的CP算法，以实现预测的不确定性量化。", "innovation": "TorchCP是一个基于PyTorch的库，旨在集成最先进的CP算法到深度学习技术中，包括基于DNN的分类器/回归模型、GNN和LLMs。它是开源的，许可证为LGPL-3.0，包含约16k行代码，通过全面的单元测试覆盖和详细文档进行了验证。TorchCP具有特定的CP训练算法、在线预测和GPU加速批量处理功能，能够在大型数据集上实现高达90%的推理时间减少。其低耦合设计、广泛的高级方法组合和全GPU扩展能力，使研究者和从业者能够提升创新性应用中的不确定性量化能力。", "conclusion": "TorchCP通过提供基于深度学习的CP算法集成，降低了大规模数据集的推理时间，增强了研究者和从业者在前沿应用中的不确定性量化能力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "基于值序估计距离度量学习的分类数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是一种流行的机器学习技术，用于数据分析以自动揭示样本分布模式。然而，由于类别数据天生缺乏一个明确的度量空间（如数值数据的欧几里得距离空间），类别数据的分布通常被低估，因此在聚类过程中易造成有价值的信息扭曲。该研究旨在通过学习类别属性值的最佳顺序关系并量化它们在线上的距离，以缓解这一问题。", "innovation": "提出了一种新颖的顺序距离度量学习方法，通过学习类别属性值的最佳顺序关系，在线量化它们之间的度量，旨在更好地处理分类数据和混合数据集。该方法设计了一种新的联合学习范式，该范式可以交替执行聚类和顺序距离度量学习，时间复杂度低且具备收敛性保证。实验结果验证了该方法的有效性，并通过权重距离学习机制和欧几里得距离的一致性实现了分类准确性提升，同时降低了理解非直观类别数据的难度。", "conclusion": "提出的基于顺序距离度量学习的方法在分类和混合数据集上展现了更优的聚类精度，且通过学习的顺序距离度量显著降低了理解非直观类别数据的难度。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.01371", "html_url": "https://arxiv.org/abs/2402.01371", "title": "平均奖励MDP中的两时标批评家-演员算法及其函数近似", "title_en": "Two-Timescale Critic-Actor for Average Reward MDPs with Function Approximation", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "近年来，多项工作专注于对AC算法进行非渐近收敛性分析。近期有研究提出了在折扣成本设置下批评家-演员算法中的一种两时标方案，该方案中批评家与演员的时标被颠倒，且仅证明了渐近收敛性。在此之前，尚未有研究在无限期平均奖励设置下探讨带函数近似的两时标批评家-演员算法，也没有提出有限时间内非渐近的收敛性分析。本研究填补了这一空白，通过分析证实了算法在有限时间内的非渐近收敛性，并展示了批评家在可能的样本复杂度下的几乎确实渐近收敛。", "innovation": "本研究首次在无限期平均奖励设置下提出带有函数近似的两时标批评家-演员算法，并进行了有限时间内的非渐近以及渐近收敛性分析。该算法在批评家均方误差上实现了最优的学习速率，并证明了样本复杂度为$∥\tilde{\text{O}}(\text{ε}^{-(2+δ)})$，其中δ>0是任意接近零的小正数，这优于相同设置下两时标AC算法所得的结果。此外，研究还展示了批评家算法的几乎确实渐近收敛性，并通过数值实验验证了算法的有效性和优越性。", "conclusion": "本研究通过详细分析了两种算法下的收敛性，展示了新的批评家-演员算法在有限时间内的表现。本算法在批评家均方误差上达到了最优学习速率，并通过数值实验证明其在三个标准设置中的最佳性能。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04104", "html_url": "https://arxiv.org/abs/2504.04104", "title": "SpecPipe：通过推测性解码加速基于管道并行的大语言模型推理", "title_en": "SpecPipe: Accelerating Pipeline Parallelism-based LLM Inference with Speculative Decoding", "authors": "Haofei Yin,Mengbai Xiao,Tinghong Li,Xiao Zhang,Dongxiao Yu,Guanghui Zhang", "background": "大语言模型对推理的需求正在迅速增长。管道并行是一种成本效益高的分布式推理部署策略，但存在服务延迟高的问题。尽管结合了推测性解码，但管道并行仍然面临着硬件利用率低和推测窗口窄的挑战。", "innovation": "引入了SpecPipe，这是一种通过逐步填充推测性请求令牌来缓解这些挑战的技术。它通过动态推测令牌树和带推测性令牌源的管道推理框架来优化硬件利用率，实现了理想的每一步解码一个令牌。SpecPipe 改进了单请求和多请求工作负载的推理性能，特别适用于优化大语言模型的分布式推理。", "conclusion": "在8级管道上，SpecPipe 在多样化的单请求工作负载上的时间间隔提高了4.19到5.53倍，相较于标准的管道并行，同时也优于先前基于树的推测性解码方法。对于多请求负载，SpecPipe-DB 实现了1.64到2.08倍的吞吐量，并且减少了1.61到2.06倍的时间间隔。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16083", "html_url": "https://arxiv.org/abs/2412.16083", "title": "联邦扩散建模与差分隐私技术在表格数据合成中的应用", "title_en": "Federated Diffusion Modeling with Differential Privacy for Tabular Data Synthesis", "authors": "Timur Sattarov,Marco Schreyer,Damian Borth", "background": "随着各种领域对隐私保护数据分析的需求增加，亟需能够严格遵守隐私标准的数据合成解决方案。本文在这一背景下探讨了如何在保障隐私的前提下，生成高质量的合成表格数据。", "innovation": "本文提出了一种创新框架——DP-FedTabDiff，该框架融合了差分隐私、联邦学习和去噪扩散概率模型，旨在生成高保真度的合成表格数据。该框架不仅能保证数据的隐私性，还能保持数据的质量。通过实验证明，DP-FedTabDiff在多个真实世界混合类型表格数据集上取得了显著的隐私保证提升，同时没有牺牲数据质量。此外，实验证明了DP-FedTabDiff在隐私预算、客户端配置和联邦优化策略之间的最佳权衡。", "conclusion": "DP-FedTabDiff框架在多个方面的表现都证明了其在安全数据共享和分析方面的潜力，特别是在受监管程度高的领域，对未来联邦学习和隐私保护数据合成的发展具有重要推动作用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.18164", "html_url": "https://arxiv.org/abs/2412.18164", "title": "随机控制用于调整扩散模型：最优性、正则性和收敛性", "title_en": "Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence", "authors": "Yinbin Han,Meisam Razaviyayn,Renyuan Xu", "background": "扩散模型因其强大的生成建模能力而成为有力的工具，能够从大数据集中捕捉目标数据分布。然而，对于特定下游任务、约束和人类偏好进行这些大规模模型的微调仍是一个关键挑战。尽管最近的研究已经利用强化学习算法解决这一问题，但大部分进展仍是经验性的，缺乏理论理解。因此，本文提出了一个随机控制框架，以解决扩散模型的微调问题。", "innovation": "基于去噪扩散概率模型建立预训练参考动态，本文方法结合了线性动态控制与KL正则化。文章建立了随机控制问题的良好定义和正则性，并开发了一种策略迭代算法 (PI-FT) 来进行数值求解。PI-FT 的全球收敛性为线性速率。不同于现有工作假设整个训练过程中的正则性，本文证明该算法生成的控制和价值序列保持正则性。此外，文中还探讨了所提框架在参数设置和连续时间表示中的扩展，并通过数值实验验证了所提出的 PI-FT 算法的实用性。", "conclusion": "本文提出了一个随机控制框架以解决扩散模型的微调问题，并开发了策略迭代算法 (PI-FT)，证明了其良好的正则性和全局线性收敛性。通过数值实验验证了所提方法的实用性，并向参数设置和连续时间表示方向提出了潜在的应用扩展。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝标记：一种简单的方法来校准大型语言模型中的拒绝行为", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "为了构建安全可靠的语言模型，关键在于使模型能够适当地拒绝执行某些指令或回答某些问题。在处理用户查询时，模型需要能够拒绝回答各种类型的查询，例如问题表述不清晰、违法指令，或超出了模型知识范围的问题。目前，训练多个具有不同拒绝率比例的模型的方法既耗费计算资源，又需要针对每个用户的偏好进行模型调整，这种方法复杂且效率低下。", "innovation": "该研究提出了一种新型方法，即拒绝标记，通过为每种拒绝类别准备一个或一个通用的拒绝标记，在训练时将其添加到模型响应中。在推理推理阶段，通过调整每种拒绝类别的拒绝标记生成概率，从而使模型的拒绝行为产生变化。这种方法可以在无需进一步微调的情况下，通过定制化生成过程来统一控制模型的拒绝率。", "conclusion": "拒绝标记提供了一种解决方案，使用户能够仅通过选择性地干预生成过程，就在不进行进一步的微调情况下控制单一模型的拒绝率，从而提高了灵活性和效率。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不要欺骗你的朋友：从协作自我博弈中学习你所知道的", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "为了让AI助手更有效，它们需要了解自身的局限性，比如在什么情况下使用参数化知识，什么情况下使用工具，以及何时集体回答问题。传统的监督微调方法难以教授这些能力，因为需要构建能够反映AI特定能力的示例。因此，本文提出了一个新的协作自我博弈方法来帮助AI学会他们所知道的知识。这种方法通过群体协作正确回答问题来获得奖励，从交互结构中构建出所需的元知识。重点探讨的是拥有不同工具（特定领域的检索）的AI群体合作，以最大化成功并最小化努力的过程。实验表明，小组奖励可以促使多代理社区产生能够转移到孤立部署的个体代理的策略，改善工具使用和选择性预测。", "innovation": "引入了全新方法——协作自我博弈，来帮助AI学会他们所知道的知识。这种方法通过多代理协作，并且根据正确回答问题来奖励整个群体，从而有效提升AI的适应性和协作能力。这种方法克服了传统监督微调难以构建反映AI特定能力的示例的问题。", "conclusion": "研究表明，小组奖励可以促使多代理社区产生能够转移到孤立部署的个体代理的策略，改善工具使用和选择性预测。这种方法展示了通过协作学习元知识的有效性和实用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子并仔细再前进一步：超越下一个词预测的创造性限制", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "本文设计了一系列简约的算法任务，以大体抽象开放性的真实任务，从而让我们能够清晰、可控地评估现时语言模型的创造极限。这类任务需要类比现实生活中的创造性跳跃，要求对隐含的、开放式随机计划步骤做出反应，要么发现抽象知识图中新的连接（如文字游戏、类比或研究），要么构造新的模式（如设计数学问题或新蛋白质），显示出单一词语学习的短视性，而多词语方法（无教师训练和扩散模型）在产生物质多样性及原创输出方面表现更优。", "innovation": "我们发现，在输入层注入噪声（称为种籽条件处理）在一定程度上与输出层的温度采样具有同等甚至更优的效果，用于引入随机性而不破坏连贯性。本文提供了一个原理性的、简化的测试平台，以分析开放性创造性技能，并提出了超越单一词语学习和温度采样的新论点。", "conclusion": "我们的工作提出了一种新的方法来理解与推进语言模型在创造能力上的边界，尤其是在单一词语预测之外。通过公布部分代码，我们为未来的研究提供了一个基础，推动语言模型向更复杂的创造性任务迈进。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG: 图上公平移除", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着对隐私法规的重视增加，机器遗忘在社交网络和推荐系统等实际应用中变得越来越重要，而这些系统多以图的形式存在。然而，现有的图遗忘方法通常会不加选择地修改节点或边，忽略了它们对公平性的影响。例如，遗忘不同性别用户之间的连接可能会无意中加剧群体差异。为解决这一问题，我们提出了一种新的框架，该框架共同优化图结构和模型，以实现公平遗忘。我们的方法通过删除阻碍遗忘的冗余边并通达示目标边增强来重构图。我们还引入了一种最坏情况评估机制来评估在挑战性场景下的鲁棒性。在真实数据集上的实验结果表明，我们的方法比现有基线更有效地实现了公平遗忘。", "innovation": "本研究提出了一种新的框架，针对图数据实现公平遗忘。该框架不仅优化了图结构和模型，还能通过删除阻碍遗忘的冗余边和通达示目标边增强来保持公平性。此外，还引入了一种最坏情况评估机制以评估模型的鲁棒性。与现有方法相比，该方法在公平性方面表现更优且更有效。", "conclusion": "通过优化图结构和模型，我们的方法实现了更有效的公平遗忘，并通过对最坏情况的评估展示了其鲁棒性。实验结果验证了该方法在真实数据集上的优越性和有效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对web代理进行提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "此论文研究了多模态大型语言模型（MLLM）基于网页代理与网页环境的相互作用方式。这些代理通过生成基于网页快照的动作来进行互动。文章分析了这样一种攻击，即通过注入特定提示来操纵网页环境，使网页代理执行攻击者指定的操作。", "innovation": "作者提出了WebInject攻击，这是一种通过在网页渲染后的原始像素值中添加扰动，从而操纵网页代理执行攻击者指定动作的新型攻击方法。他们通过训练神经网络来近似映射像素值到快照的过程，并使用投影梯度下降法求解优化问题，有效解决了映射非可微的问题。", "conclusion": "实验表明，WebInject攻击非常有效，显著优于基准方法。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "风格共享的去中心化领域泛化：形式化模型与收敛性分析", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "大部分联邦学习关注的是本地数据集统计在训练和测试之间保持不变的场景，但实际中由于分布变化，这一假设往往不成立。为应对这种情况，已有研究提出了领域泛化（DG）方法，利用源领域数据训练能够泛化到未见目标领域的模型。然而，现有研究在这方面的两个主要不足是缺乏正式的数学分析，以及在FL中的DG研究仅限于星型拓扑架构，这限制了领域泛化的实现效果和范围。本文作者旨在解决这两个问题，探讨风格共享的去中心化领域泛化算法，进而提升模型的泛化能力并保证收敛性分析的有效性。", "innovation": "本文提出的Decentralized Federated Domain Generalization with Style Sharing (StyleDDG) 算法，允许设备在网络中共享其数据集推断出的风格信息，从而实现去中心化的领域泛化。这在已有研究基础上实现了创新，主要在于（1）提供了风格基于去中心化网络中的正式分析技术；（2）扩展了应用领域泛化的网络拓扑结构，不再局限于星型拓扑架构。通过这种技术，StyleDDG 算法能够在保障模型对未见过域具备强泛化能力的同时，减少通信开销，并且在多种实验数据集上取得了显著的准确性提升。", "conclusion": "本文的研究结果表明，StyleDDG 算法能够显著提高目标任务域准确性，并且与现有的去中心化梯度方法相比，通信开销较少，同时提出了风格共享作为去中心化领域泛化的有效途径，并通过正式形式化的框架进行分析，增强了算法的理论支撑。未来的工作可以探索更多类型的领域泛化算法及其在不同应用场景下的应用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08897", "html_url": "https://arxiv.org/abs/2504.08897", "title": "基于局部学习训练的脉冲神经网络的对抗鲁棒性研究", "title_en": "On the Adversarial Robustness of Spiking Neural Networks Trained by Local Learning", "authors": "Jiaqi Lin,Abhronil Sengupta", "background": "近期研究揭示了脉冲神经网络（SNNs）在基于帧和事件的信息处理中易受对抗样本的影响，这些对抗样本几乎与干净数据无法区分。当前大部分研究局限于使用基于梯度的Backpropagation Through Time (BPTT)方法生成对抗样本，而这种生物不现实的方法限制了对抗攻击的相关研究。相比之下，能够放松BPTT严格要求的局部学习方法在对抗攻击研究方面的应用仍然不足。为了解决这个问题，本文通过四种训练算法框架来研究SNNs的对抗鲁棒性，深入分析了基于梯度的对抗攻击在这一场景中的无效性，并提出了一种结合了对抗样本可转移性的混合对抗攻击范式，展示了该方法在多步对抗攻击、黑盒FGSM场景及非脉冲域中的优越性能和广泛的适用性。", "innovation": "本文提出了一种新的对抗攻击范式，利用了对抗样本的可转移性。这种方法在多步对抗攻击、黑盒FGSM场景及非脉冲域中表现出优越性能，超过了现有的对抗攻击方法。", "conclusion": "研究揭示了基于局部学习训练的SNNs的对抗鲁棒性，并提出了一个新的混合对抗攻击范式，证明了该方法在多种场景中的优越性能和广泛适用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15695", "html_url": "https://arxiv.org/abs/2506.15695", "title": "SimuGen: 多模态代理框架以构建基于框图的仿真模型", "title_en": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "authors": "Xinxing Ren,Qianbo Zang,Zekun Guo", "background": "近年来，大规模语言模型（LLMs）在数学推理和代码生成方面表现出了令人印象深刻的性能。然而，这些模型在模拟领域仍存在局限性，特别是在生成Simulink模型方面，Simulink模型是工程和科学研究中的重要工具。我们的初步实验表明，从纯文本输入生成可靠的和完整的Simulink模拟代码往往存在困难，这是因为语言模型缺乏特定于Simulink的数据进行预训练。", "innovation": "为了解决这一挑战，本研究提出了一种名为SimuGen的多模态代理框架，该框架能够通过结合Simulink绘图和领域知识自动生成准确的Simulink模拟代码。SimuGen利用了多个专业化的代理，包括调查员、单元测试审查员、代码生成器、执行器、调试定位器和报告撰写员，并支持特定领域的知识库。这种协作的模块化设计使得Simulink仿真生成具有解释性、鲁棒性和可重复性。", "conclusion": "这种多模态代理框架主要用于生成基于框图的仿真模型，能够提供解释性、鲁棒性和可重复性的Simulink仿真生成。源代码已公开，支持进一步研究和应用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE：化学反应率估计的刚性物理驱动神经常微分方程", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "从复杂化学反应中估计速率常数对于推动详细化学的发展至关重要。然而，现实生活中的大气化学系统固有的刚性特质导致训练不稳定性和较差的收敛性，这阻碍了基于学习方法的有效速率常数估计。", "innovation": "提出了一种称为SPIN-ODE的刚性物理驱动神经常微分方程框架，以解决化学反应建模中的挑战问题。该方法通过一个三阶段优化过程，首先训练一个黑盒神经常微分方程来拟合浓度轨迹，然后预训练一个化学反应神经网络（CRNN）来学习浓度与其时间导数之间的映射，最后通过与预训练的CRNN综合来微调速率系数。实验结果验证了该方法的有效性和鲁棒性。", "conclusion": "这是我们首次研究使用刚性神经常微分方程进行化学速率系数的发现。这项研究为将神经网络与详细化学相结合开辟了新的方向。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05762", "html_url": "https://arxiv.org/abs/2506.05762", "title": "BiTrajDiff: 通过扩散模型实现双向轨迹生成的离线下 reinforcement 学习方法", "title_en": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "authors": "Yunpeng Qing,Shuo Chen,Yixiao Chi,Shunyu Liu,Sixu Lin,Kelu Yao,Changqing Zou", "background": "离线强化学习（offline RL）的发展证明了对预收集数据集施加保守约束的有效性，但这些静态数据集通常存在分布偏差，限制了其泛化能力。现有的数据增强（DA）技术主要关注从给定状态重建未来轨迹，而忽视了探索到达这些状态的历史过渡，这导致难以发现多样化的行为模式，尤其是可能带来高回报的关键状态。", "innovation": "提出了一种新颖的双向轨迹扩散（BiTrajDiff）数据增强框架，可以从任意中间状态生成双向轨迹，包括向前扩散预测未来动态和向后扩散追溯历史过渡。BiTrajDiff 方法能够充分利用关键状态作为锚点，扩展到状态空间中未被充分探索的有价值区域，增强数据集的多样性。实验表明，该方法在 D4RL 基准套件中相比其他先进 DA 方法表现更优。", "conclusion": "BiTrajDiff 通过双向扩散过程有效增强了离线下强化学习的数据集质量，解决了传统方法只关注未来轨迹生成的问题，提高了模型对未见过状态的泛化能力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器上的量化神经网络：方法、平台和应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "在资源受限的设备（如微控制器）上部署量化的神经网络（QNNs）引发了在模型性能、计算复杂性和存储限制之间的平衡挑战。TinyML通过集成机器学习算法、硬件加速和软件优化的最新进展，旨在高效地在嵌入式系统上运行深度神经网络。该论文提供了一种硬件中心化的量化介绍，并系统地审查了用于加速嵌入式应用中深度学习模型的关键量化解析技术。特别强调了模型性能与硬件能力之间的关键贸易关系。", "innovation": "这篇综述专注于系统评估支持微控制器上QNN执行的现有软件框架和硬件平台，并分析了当前面临的挑战和未来的发展方向。", "conclusion": "在快速发展的QNN部署领域，本文提供了当前挑战的深入分析，并指出了未来有前景的研究方向。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超越频率：冗余在大型语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "大型语言模型的记忆行为可能会对隐私和公平性造成重大风险，尤其是在这些模型的参数数量达到数十亿时。以往的研究已经证实了记忆与词元频率和重复模式之间的相关性，但没有深入探讨不同记忆特征的具体影响。这项研究进一步揭示了频率和冗余对记忆图谱的独立和交互作用影响，以及这些因素对于提升模型记忆和脆弱性的影响机制。", "innovation": "研究创新性地通过反事实分析（扰动样本文本前缀并量化通过词元位置变化的程度），发现了冗余与记忆模式之间的重要关联。研究证明约79%的记忆样本具有低冗余性，且低冗余样本相对于高冗余样本存在两倍的脆弱性，这意味着在干扰下，记忆力样本降低了0.6，而非记忆样本仅降低了0.01。这一发现提出了基于冗余的数据预处理潜在策略，从而降低隐私风险和减轻偏见，以确保模型部署的公平性。", "conclusion": "关于79%的记忆样本具有低冗余性，这些低冗余样本表现出比高冗余样本高出两倍的脆弱性，表明在干扰下记忆力样本减少0.6，而非记忆样本只减少0.01。这表明冗余度较高的内容变得更易记忆但更脆弱。因此，研究建议采用基于冗余的预处理方法，以降低隐私风险和减轻偏见，确保模型部署的公平性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA: 通过LLM反馈实现时间序列异常推理", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在多个领域至关重要，但当前方法通常仅限于二元异常分类，缺乏详细的分类和解释性推理。因此，本文提出了一种新的任务——时间序列推理异常 (Time-RA)，它将传统的时序异常检测从判别性转换为生成性、推理密集型任务，并利用大语言模型 (LLMs)。本文首次提出了一个面向异常推理的首个真实世界多模态基准数据集——RATs40K，该数据集针对异常推理进行了明确标注，包含约40,000个样本，涵盖10个真实领域。每个样本包括数值时间序列数据、上下文文本信息和视觉表示，这些数据都被细粒度地标注成14种单变量异常和6种多变量异常的类别，并附有结构化的解释性推理。", "innovation": "本文引入了Time-RA任务，将传统的时序异常检测转化为生成性、推理密集型任务；提出了首个专门针对异常推理标注的真实世界多模态数据集RATs40K；开发了精确且可解释性的标注框架；全面评估了各种大语言模型及多模态大语言模型的能力和限制；并提供了公开的代码和数据集。", "conclusion": "数据集和任务为可解释的时间序列异常检测和推理带来了重要的进步。已公开的代码和数据集将支持和加速该领域的未来研究。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL: 通过熵机制平衡LLM测试时强化学习中的探索和开发", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "大规模语言模型在复杂推理任务，如数学和编程中的表现取得了显著进步，但仍然严重依赖标注数据，并且在无监督场景中缺乏适应性。为此，测试时强化学习（TTRL）被提出以利用模型生成的伪标签实现自我优化，但这一方法存在高推理成本（通过平行滚出实现）和早期阶段估计偏差导致的过度自信问题，这些问题限制了输出多样性并导致性能平台。", "innovation": "提出了熵为基础的机制来增强测试时强化学习中的探索和开发平衡。通过两种策略，Entropy-fork Tree Majority Rollout (ETMR) 和 Entropy-based Advantage Reshaping (EAR)，使得LLama3.1-8B在AIME 2024基准上的Pass at 1指标相对提高了68%，同时仅消耗了60%的演练令牌预算。这种方法成功优化了推理效率、多样性和估计稳健性之间的权衡，从而推进了开放领域推理任务中的无监督强化学习。", "conclusion": "本文介绍的方法在高效、多样性和估计稳健性之间成功优化了平衡，显著提升了模型在开放领域推理任务上的性能，进一步展示了无监督强化学习的潜力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大规模语言模型（LLMs）通过增加推理时间来提高推理能力，这一策略虽然有效，但会导致严重的延迟和资源成本增加，限制了其在实时或成本敏感场景中的应用。", "innovation": "本文提出了一种名为BudgetThinker的新框架，旨在使LLMs能够进行预算感知推理，通过在推理过程中定期插入特殊控制标记来为模型提供剩余令牌预算信息。该方法结合了监督微调和基于课程的强化学习两阶段训练管道，以优化准确性和预算遵守。", "conclusion": "实验结果显示，BudgetThinker在各种预算设置下的数学难题基准测试中显著超越了强基线，为资源受限和实时环境中开发高效且可控制的LLM推理提供了一种可扩展且有效的解决方案。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "Sci解释性推理网络（ScIReN）：在碳循环及其更广泛领域中发现隐藏关系", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对缓解气候变化至关重要。尽管土壤有能力从大气中捕获碳，但土壤碳循环尚未被充分理解。基于现有知识开发的数学过程模型虽有潜力，但仍有很多未知参数需要随意设定，且往往不能很好地拟合观察结果。另一方面，神经网络可以从数据中学习模式，但不遵守已知的科学定律，也无法揭示新的科学关系。因此，需要一种透明的框架，结合可解释的神经网络和过程型推理，以增强科学解释能力。", "innovation": "提出了一种完全透明的框架——ScIReN（Sci解释性推理网络），结合了可解释的神经网络和过程型推理。该框架通过可解释编码器预测科学上有意义的隐参数，然后将这些隐参数传递给不同的过程型解码器以预测标记输出变量。通过Kolmogorov-Arnold网络（KAN）确保编码器完全可解释，并揭示输入特征与隐参数之间的关系；利用新型光滑惩罚来平衡表达性和简洁性；使用新的硬Sigmoid约束层限制隐参数在科学先验知识定义的意义范围内。过程型解码器约束了科学已知知识，而基于KAN的编码器揭示了传统黑盒模型中隐藏的新科学关系。", "conclusion": "将ScIReN应用于两个任务：模拟有机碳在土壤中的流动，以及建模植物的生态呼吸。在两个任务中，ScIReN在预测准确性上优于黑盒网络，同时提供了大量的科学解释性——可以推断出潜在的科学机制及其与输入特征的相关性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04901", "html_url": "https://arxiv.org/abs/2508.04901", "title": "稳定性敏感性：转移学习中适应性数据选择的理论与实证分析", "title_en": "Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning", "authors": "Prabhav Singh,Jessica Sorrell", "background": "转移学习的广泛应用极大地改变了机器学习领域，使其能够高效地将预训练模型适应到新领域。然而，现有适应性数据选择策略导致的适应性变化的可靠性仍然不明确。", "innovation": "本文提出了一个全面的理论和实证分析框架，定量地研究了转移学习中的再现性问题。引入了计算适应性选择策略对训练数据扰动响应能力的度量，称为选择敏感度（$\triangle_Q$）。证明再现性失败概率与选择敏感度成正比关系，与样本量呈指数衰减关系。实验结果表明，尽管高度适应性策略（如基于梯度的选择和阶梯学习）在任务性能上更优，但它们的再现性失败率更高，而不太适应的方法的失败率低于7%。此外，研究发现，源域预训练可以显著减少再现性失败率，减少幅度最高可达30%，同时保持性能的提升。", "conclusion": "本研究为研究者提供了处理性能-再现性权衡问题的指导原则，并强调现代转移学习系统中需要考虑再现性意识设计。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 评估大型语言模型在凝聚态物理中的基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "目前存在对大型语言模型（LLMs）在凝聚态物理方面的专业能力评估需求，现有的评估工具要么覆盖不全面，要么无法深入考察模型解决实际问题的能力。因此，作者们提出了CMPhysBench，这是一个全新的基准测试，旨在全面评估LLMs在凝聚态物理领域中的应用能力。", "innovation": "CMPhysBench采用超过520个精心策划的研究生级问题，涵盖了磁性、超导性、强关联系统等代表性子领域和基础知识框架。特别是，通过引入基于树的表达式表示的可扩展表达式编辑距离（SEED）评分方法，CMPhysBench可以更精细地评估预测与真实值之间的相似度，而不是简单的二值判断，这为模型性能的评估提供了更准确的标准。", "conclusion": "尽管一些顶级模型如Grok-4在CMPhysBench上的得分仅达到36分的平均SEED评分以及28%的准确率，表明当前LLMs在这一具体且前沿的应用领域中仍存在显著的能力差距，这强调了进一步研究和开发的有效性。研究结果表明，CMPhysBench为今后研究提供了评估LLMs在实际物理问题解决中的能力的新方法，其代码和数据集已公开发布。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23344", "html_url": "https://arxiv.org/abs/2507.23344", "title": "通过可微分基于代理的仿真设计自行车共享系统动态定价", "title_en": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "authors": "Tatsuya Mitomi,Fumiyasu Makinoshima,Fumiya Makihara,Eigo Segawa", "background": "随着自行车共享系统的出现，这些系统在各城市成为一种新型的环保交通系统。然而，用户需求在空间和时间上的变化导致自行车站点之间存在库存不平衡，增加了重新调配的成本。因此，通过最优动态定价来管理用户需求对于系统至关重要。但这种系统的定价设计复杂，因为涉及具有不同背景的用户和概率性的选择。", "innovation": "为解决这一问题，论文开发了一种可微分基于代理的仿真，用于快速设计自行车共享系统中的动态定价。该方法能在空间和时间上异质的骑行和概率性用户决策下实现自行车库存的平衡。与传统方法相比，该方法在损失减少73%到78%的同时，展示了高达100倍的收敛速度增加。此外，该方法还在大型城市自行车共享系统场景中进行了验证，涉及289个自行车站点，产生了1156个参数，在模拟中实现库存的自然平衡，并通过调整初始条件最小化折扣成本。", "conclusion": "该论文通过可微分基于代理的仿真方法，成功设计了自行车共享系统的动态定价策略，实现了库存的平衡，同时提高了收敛速度并减少了折扣成本。这种方法展示了在复杂用户行为背景下的有效性和实用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15593", "html_url": "https://arxiv.org/abs/2508.15593", "title": "在指定模型模拟推理中的归纳域转移", "title_en": "Inductive Domain Transfer In Misspecified Simulation-Based Inference", "authors": "Ortal Senouf,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard", "background": "模拟推理（Simulation-based inference, SBI）是用于估计物理系统中潜变量的方法，当似然函数难以处理但可以进行模拟时使用。但是，常用的方法常常受到模型误指定（模型简化引起的模拟与实际观察之间的不匹配）的限制。RoPE 是一种旨在解决这一问题的最新 SBI 方法，它通过结合半监督校准和最优传输（OT）为基础的分布对齐来进行两阶段的领域转移。不过，RoPE 仍局限于完全归接入射设置，要求在推理时访问一批测试样本，这限制了其规模和泛化能力。", "innovation": "本文提出了一个完全归纳的并快速的 SBI 框架，结合校准和分布对齐为一个端到端可训练模型。该方法利用最小批量 OT 并配备闭合形式对偶来对齐具有相同潜变量的实观测值和模拟观测值，利用配对校准数据和未配对样本。随后，使用条件规范化流来近似 OT 引导的后验，从而使推理可以在测试时不依赖于模拟访问。这种方法在一系列合成和实际基准测试中表现出色，即便在复杂且误指定的环境中也优于 RoPE，以及其他标准 SBI 和非 SBI 估计器，同时提高了可扩展性和适用性。", "conclusion": "本文提出的方法在各种合成和真实基准测试中能够匹配或超越 RoPE 以及其他标准 SBI 和非 SBI 估计器的性能，同时提供更好的可扩展性和适用性，特别是在挑战性的、误指定的环境中。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20330", "html_url": "https://arxiv.org/abs/2508.20330", "title": "FORGE: Foundational Optimization Representations from Graph Embeddings", "title_en": "FORGE: Foundational Optimization Representations from Graph Embeddings", "authors": "Zohair Shafi,Serdar Kadioglu", "background": "组合优化问题在科学和工程中无处不在，但用于加速其求解的学习方法通常需要解决大量难以解决的优化实例以收集训练数据，这导致了显著的计算开销。现有的方法需要为每个问题分布训练专用模型，这严重限制了它们的可扩展性和泛化能力。", "innovation": "本文提出Forge，一种方法，用于在不依赖解决实例的情况下，以无监督方式在大规模和多样化混合整数规划（MIP）实例上预训练一个向量化图自编码器。向量化过程创建离散的编码分配，作为表示优化实例的词汇表。我们评估了在有监督和无监督设置下的方法。在无监督设置下，Forge嵌入有效地区分和聚类未见过的实例。在有监督设置下，Fine-tune Forge嵌入并显示，单个模型能够预测多位数的热启动变量和切割生成的整合短板，适用于多种问题类型分布。这些预测有助于提高最先进的商业优化求解器的性能。", "conclusion": "最后，我们发布了我们的代码和预训练的Forge权重，以促进对该领域中实例级别的MIP嵌入的进一步研究和实际应用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型进行大肠3D形状细化以生成数字仿真体", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的人体器官三维建模对于虚拟成像试验中的数字仿真体构建至关重要。然而，由于大肠复杂的几何形状和形态变异，对其进行三维建模仍然具有挑战性。", "innovation": "提出了一种新颖的条件潜点扩散模型CLAP，该模型结合了几何深度学习和去噪扩散模型，以提高大肠的三维表示。该模型通过层次变分自编码器学习全局和局部潜形态表示，并在潜空间中使用两个条件扩散模型细化器官形态，最后通过预训练的表面重建模型将细化后的点云转换成网格，从而显著提高了形态建模精度。", "conclusion": "CLAP方法在形态建模精度上实现了显著的改进，相对于初始的亚优形态，将Cromfer距离降低26%，Hausdorff距离降低36%。该方法提供了一种稳健且可扩展的高质量器官建模方案，具有广泛的应用潜力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.02592", "html_url": "https://arxiv.org/abs/2401.02592", "title": "保证非凸因式分解方法的张量列车恢复", "title_en": "Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery", "authors": "Zhen Qin,Michael B. Wakin,Zhihui Zhu", "background": "本文提供了因式分解方法的首个收敛保证。为了规避缩放不确定性，并便于理论分析，通过优化所谓的左正交TT格式来进行优化，这种方法确保了大多数因子的正交性。通过利用斯蒂费尔流形上的黎曼梯度下降（RGD），我们确保了这种正交结构。", "innovation": "本文研究了利用黎曼梯度下降法优化TT格式因式分解问题，并证明了局线性收敛。此外，还探讨了从线性测量恢复TT格式张量的问题，在满足特定条件的感测操作符情况下，通过光谱初始化获得适当的初始化，证明了RGD可以在线性速率下收敛到真值张量。在包含高斯噪声的测量情况下，也证明了RGD可以以线性速率可靠地恢复真值，且恢复误差随张量阶数的增加只表现出多项式增长。", "conclusion": "本文通过理论分析和实验验证了黎曼梯度下降法在处理张量列车恢复问题时的高效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "Robustness is Important: Limitations of LLMs for Data Fitting", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）已经在多种应用场景中得到广泛应用，远超语言处理任务。特别是，LLMs 被用作一种即插即用的方法来拟合数据和生成预测。已有研究显示，在预测性能方面，LLMs 通过上下文学习或监督微调，能够与许多表格监督学习技术竞争。然而，文章指出 LLMs 在数据拟合中存在一个关键的脆弱性，即对无关的数据表示变化的敏感性会显著改变模型的预测结果。", "innovation": "该研究发现，变量名称等任务无关的变化会对 LLMs 的预测结果产生极大的影响，改变变量名称会使预测误差增加高达 82%。这种敏感性在上下文学习和监督微调中都存在，这两类模型包括闭权重和开权重的通用 LLMs。通过分析开权重 LLMs 的注意力分数，发现有非均匀的注意力模式：提示中特定位置的训练示例和变量名称/值收到更多关注，即使不同的位置本应收到大致相同的关注。这对于在存在任务无关变化时的敏感性提供了解释。此外，研究还发现，尽管专门设计用于数据拟合的最先进的表格基础模型（TabPFN）具有预测稳健性，但仍然无法抵御任务无关变化的影响。", "conclusion": "尽管 LLMs 具有令人印象深刻的预测能力，但它们缺乏基本的鲁棒性，不能作为原理上的数据拟合工具使用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中物体搬运中的视图合并与解缠算法", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉技术在搬运任务中得到了广泛应用，特别是通过视觉伺服。由于世界具有三维性，使用多视角摄像头并将其合并，可以为Q学习提供更好的表示形式，从而训练出样本效率更高的策略。然而，这些多视图策略对摄像头故障敏感，并且部署起来较为复杂。", "innovation": "提出了一种称为Merge And Disentanglement (MAD)的算法，该算法能够高效地合并视角以提高样本效率，同时通过将多视角特征输入与单视角特征相结合来解缠视角。这种算法能够生成稳健的策略并允许轻量级部署。", "conclusion": "通过在Meta-World和ManiSkill3上的实验演示了该方法的效率和鲁棒性。更多信息和代码可以在提供的项目网站上找到。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "持续学习（CL）的背景在于如何在新任务敏感性和保留过去知识的稳定性之间保持平衡。尽管尖锐性感知最小化在迁移学习中显示出有效性，并被应用在CL中以提高记忆保持和学习效率，但仅依赖零阶尖锐性可能导致在某些情况下偏好尖锐的最小值而非平坦的最小值，这会导致较不稳定的解，并可能产生次优解决方案。", "innovation": "C-Flat是一种方法，旨在促进特别为CL设计的更平坦的损失景观。C-Flat提供即插即用兼容性，允许在代码管道中轻松集成。此外，提出了一种通用框架，将C-Flat融入所有主要的CL范式，进行了与损失最小值优化器和基于平坦最小值的CL方法的全面比较。C-Flat++是C-Flat的高效而有效的框架，利用选择性地驱动平坦性促进，显著减少了C-Flat所需的更新成本。广泛的实验表明，我们的方法具有广泛的适用性和效率优势。", "conclusion": "我们的结果表明，C-Flat在广泛设置中一致性地提高了性能。C-Flat++框架进一步提高了效率，通过选择性地驱动平坦性促进显著减少了更新成本。这些方法在多个CL方法、数据集和场景中进行了严格测试，展示了其有效性和效率，并公开了相应的代码。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19352", "html_url": "https://arxiv.org/abs/2508.19352", "title": "图神经网络中的记忆现象", "title_en": "Memorization in Graph Neural Networks", "authors": "Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch", "background": "深度神经网络(DNNs)已被证明会记住它们的训练数据，但类似的研究尚未广泛应用于图神经网络(GNNs)。本文介绍了NCMemo（节点分类记忆），这是首个量化半监督节点分类中标签记忆的框架。研究者首先建立了记忆与图同质性（即将连接的节点具有相似的标签/特征的属性）之间的逆相关关系。研究团队发现，较低的同质性显著增加了记忆化程度，表明GNNs依赖记忆来学习同质性较低的图。", "innovation": "首次提出了一种量化GNNs中标签记忆的框架NCMemo。进一步分析了GNNs的训练动态，揭示了低同质性图中记忆化增加与GNNs在学习过程中对图结构的隐式偏好之间的紧密联系。提出了图重新布线作为一种减少记忆化的方法，并证明这种方法可以在不影响模型性能的同时减少记忆化程度，甚至降低先前记忆化数据点的隐私风险。", "conclusion": "研究不仅推进了对GNNs学习的理解，也为更加隐私保护的GNN部署提供了支持。通过图重新布线的方法成功减少记忆化并提升隐私保护，并展示了该方法的有效性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12367", "html_url": "https://arxiv.org/abs/2403.12367", "title": "学习匹配中的协变量重要性以进行政策相关观察研究", "title_en": "Learning covariate importance for matching in policy-relevant observational research", "authors": "Hongzhe Zhang,Jiasheng Shi,Jing Huang", "background": "匹配方法在减少观察研究中的混杂因素方面得到广泛应用，但传统方法常将所有协变量视作同等重要，这可能导致在协变量对研究的相关性存在差异时出现性能不佳的问题。", "innovation": "提出了优先级感知一对一匹配算法（PAMA），这是一种新颖的半监督框架，可以从专家配对的单位子集中学习协变量的重要性度量，并使用这种度量来匹配额外的单位。它通过一种加权二次评分优化算法，该分数反映了每个协变量与研究的相关性，并通过未标记数据迭代更新协变量的重要性测量值。PAMA 是无模型的，但当专家匹配规则与设计一致时，协变量的重要度测量是稳健一致的。此外，还介绍了解决数据不平衡、容纳时间协变量和提高对错配观察的鲁棒性的扩展功能。", "conclusion": "在模拟中，PAMA 比标准方法表现更好，特别是在高维设置和模型拟合不正确的情况下。应用于一项有关实地学校与 COVID-19 传播的实地研究中，PAMA 使用基线协变量恢复的合格专家设计对几乎是竞争方法的两倍。通过自我学习的扩展在模拟中提高了性能，但其效益依赖于具体的上下文。据我们所知，PAMA 是第一个将半监督学习应用于具有不同相关性的协变量的观察匹配框架。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.12968", "html_url": "https://arxiv.org/abs/2306.12968", "title": "重新审视带标记随机块模型中实例最优簇恢复问题", "title_en": "Revisiting Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model", "authors": "Kaito Ariu,Alexandre Proutiere,Se-Young Yun", "background": "本文研究了带标记随机块模型（LSBM）中隐藏社区恢复的问题，其中簇的数量有限，且大小随着总节点数的增加呈线性增长。研究了在哪种条件下，错分类的节点数期望小于任何小o(n)的s值。", "innovation": "本文提出了IAC（实例自适应聚类）算法，这是首个在期望值和高概率情况下都能匹配实例特定下界性能的算法。IAC是一种新颖的两阶段算法，包括一次谱聚类步骤，随后是迭代的基于似然性的聚类分配改进。该方法基于实例特定的下界，并且无需任何关于模型参数的信息，包括簇的数量。", "conclusion": "该算法仅通过一次谱聚类保持了整体计算复杂度为O(n polylog(n))，使其在大规模问题中具有可扩展性和实用性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.13098", "html_url": "https://arxiv.org/abs/2404.13098", "title": "使用线性规划的自字典方法进行高光谱图像的端元提取", "title_en": "Endmember Extraction from Hyperspectral Images Using Self-Dictionary Approach with Linear Programming", "authors": "Tomohiko Mizutani", "background": "高光谱成像技术在森林管理、矿物资源勘探和地球表面监测等多个领域具有广泛应用。端元提取是利用这种技术的关键步骤，旨在识别观测场景中材料的光谱特征。理论上，基于线性规划（LP）的自字典方法（如Hottopixx方法）被证明在端元提取方面有效，但由于它们需要解决的线性规划问题随着图像像素数量的增加呈二次增长，导致计算成本高昂，制约了其实际应用。", "innovation": "本文提出了一种针对Hottopixx方法的改进实施，旨在减少计算时间并提高端元提取性能。该方法通过实验展示了其有效性，使Hottopixx能够在实际的高光谱图像中进行端元提取，并在估计端元签名方面达到较高的精度。", "conclusion": "我们的实施能够使Hottopixx在实际高光谱图像中进行端元提取，并能够以合理的精度估计端元签名。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM: 使用概率编程的因果贝叶斯推理架构在不确定性下的机器人操作", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人在执行任务时需要理解物体之间的因果关系，然而，现有的数据驱动方法往往缺乏因果意义，仅考虑相关性。", "innovation": "提出了COBRA-PPM，这是一种新颖的因果贝叶斯推理架构，结合了因果贝叶斯网络和概率编程，以执行不确定性下的干预推理，用于机器人的抓取操作。它通过高度模拟的Gazebo实验，在一个示例积木堆叠任务中展示了高准确性（预测准确率88.6%）和高任务成功率（94.2%），并且在实际机器人仿真与现实世界之间的转移上也表现出有效性，能够处理传感器噪声和随机行为带来的不确定性。此框架具有广泛的适用性，为进一步研究机器人和因果关系的交叉领域奠定了基础。", "conclusion": "COBRA-PPM 提供了一个通用且可扩展的框架，可应用于多种操作场景，为进一步将因果推理融入机器人操作提供了一个基础。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "连续的语言模型插值以实现动态可控的文本生成", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "随着大规模语言模型（LLMs）在各种应用场景中变得越来越受欢迎，使它们具备适应性和可控性变得越来越重要，尤其是在面向用户的应用中。现有关于LLM适应性的文献主要关注如何找到一个或多个模型以优化单一预定义的目标。然而，本研究关注的是一个更具挑战性的场景，即模型必须能够动态地适应不断变化的用户偏好。为了应对这一挑战，作者利用线性权重插值的适应方法，将其转化为连续多领域插值器，能够在实时生成具有特定指定生成特性的模型。", "innovation": "作者提出了一种新的连续语言模型插值方法，这种方法允许在多种不同领域中精细调整基础模型，生成一组具有不同生成特性锚模型。然后，作者利用这些锚模型的重量更新对包含在它们凸壳内的整个（无限）模型类进行参数化。实验结果表明，调整插值权重可以预测性地且一致地改变模型输出相关的所有控制属性，并识别出不会彼此纠缠的属性对，从而实现了对模型输出的多样式特性的可控调整。", "conclusion": "研究结果表明，对通过微调获得的模型权重进行线性插值，能够实现对多个风格化属性的预测性、细致控制。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19779", "html_url": "https://arxiv.org/abs/2410.19779", "title": "脑GPT：通过自回归预训练实现脑电图通用基础模型的潜力", "title_en": "BrainGPT: Unleashing the Potential of EEG Generalist Foundation Model by Autoregressive Pre-training", "authors": "Tongtian Yue,Xuange Gao,Shuning Xue,Yepeng Tang,Longteng Guo,Jie Jiang,Jing Liu", "background": "脑电图（EEG）信号在揭示自发脑活动方面具有重要意义，在神经科学研究中具有重要价值。然而，由于多样化的数据格式、过时的预训练方法以及限制性的迁移学习方法，EEG模型的探索受到了限制，只导致了针对单一数据集的专门模型。", "innovation": "文章提出了EEGPT，这是第一个通用的EEG基础模型，旨在解决上述挑战。首先，提出了一个电极级别的建模策略，将每个电极视为基本单元，使得可以整合多达138个电极的多样化EEG数据集，积累了37.5M的预训练样本。其次，开发了第一个自回归EEG预训练模型，从传统的掩码自编码器方法转移到下一个信号预测任务，更好地捕捉了EEG数据的序列和时序依赖性。此外，还探索了具有多达1.1B参数的模型，这是目前为止EEG研究中最大的模型。第三，引入了一种可学习的电极图网络多任务迁移学习范式，首次确认了多任务兼容性和协同效应。EEGPT在多个下游任务中表现出色，通过广泛的消融研究进一步验证了其有效性。", "conclusion": "EEGPT为通用EEG建模设定了新的方向，提高了扩展性、可迁移性和适应性，适用于广泛的应用场景。相关代码和模型将被公开发布。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "在机器人运动中的体液扩展规律", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "跨体液通用化是构建对于任何机器人具有通用体液代理的关键愿景，但其促成因素仍然不甚明了。研究人员探讨了体液扩展定律，通过增加训练体液的数量来提高对未见过的体液的泛化能力。", "innovation": "本研究通过程序生成约1,000种具有拓扑、几何和关节级运动学变异的体液，并在随机子集中训练策略。观察到支持假设的正向扩展趋势，并发现体液扩展能使泛化范围比在固定体液上进行的单纯数据扩展更广泛。最佳策略能够在模拟和实际世界中，包括Unitree Go2和H1等新型体液中零样本转移。", "conclusion": "这些结果为通用体液智能奠定了基础，对配置机器人自适应控制、形态协同设计等领域具有相关性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "矩形注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "在传统的卷积网络中，空间注意力图通常是以位置相关的形式生成的，这会导致注意力区域边界不规则，从而影响新样本的泛化能力。", "innovation": "本文提出了一种新颖的空间注意力模块，它可以轻松集成到任何卷积网络中，通过引导模型关注图像中最能区分的部分，实现端到端训练。并且该模块中的注意力区域被限制为矩形，仅需5个参数进行参数化，这使得模型更加稳定，并且更容易泛化到新的样本中。实验结果显示，本文的方法系统性地优于位置相关的传统方法，提供了一种新的、有用的卷积模型空间注意力机制，并且该模块还提供了关于“模型关注何处”的解释性，有助于了解模型关注输入的哪些部分以产生预测。", "conclusion": "本文提出了一种矩形注意力模块，作为经典的基于位置的空间注意力机制的改进方案，该模块在实验中表现出更好的性能和稳定性，能更好地理解模型的决策过程。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12000", "html_url": "https://arxiv.org/abs/2504.12000", "title": "湍流区域中对Rayleigh-Bénard对流的控制：强化学习的有效性", "title_en": "Control of Rayleigh-Bénard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime", "authors": "Thorben Markmann,Michiel Straat,Sebastian Peitz,Barbara Hammer", "background": "数据驱动的流体控制在工业、能源系统和气候科学领域具有巨大的潜力。本文研究了强化学习（RL）在增加湍流条件下减少二维Rayleigh-Bénard对流系统中的对流热传导的有效性，探讨了不同初始条件和湍流水平下控制策略的一般化能力，并提出了一种奖赏塑造技术以加速训练过程。RL代理与经典控制理论中的线性比例微分（PD）控制器进行了比较。", "innovation": "提出了将奖赏塑造技术引入强化学习模型中以加速训练过程，研究表明RL代理能够显著减少对流，其效果在各种初始条件下具有较强的泛化能力，并且在高度湍流的情况下表现优异，与PD控制器相比性能更佳。", "conclusion": "强化学习代理有效地减少了对流热传导，尤其是在中度和高度湍流系统中表现突出，与传统的PD控制器相比，表现出更优异的性能。奖赏塑造技术提高了样本效率，使得模型在高湍流水平下更加稳定。这些结果显示，强化学习在湍流条件下减少对流热传导方面具有巨大的应用潜力。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "揭示大型语言模型中的精细价值观和观点", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "通过探索大型语言模型（LLMs）中潜藏的价值和观点，可以帮助识别潜在的偏差并减少潜在的危害。目前，研究主要通过给LLMs提供调查问题，并衡量输出对道德和政治议题的立场来实现。然而，不同的提示方式会导致LLMs生成的立场差别很大，对于同一议题可以有不同的论据支持或反驳。因此，需要一种方法来分析LLMs对各种提示的反应，以发现其倾向性和潜在偏差。作者分析了6种LLMs对《政治极点测试》（PCT）中156000份响应的62个命题，使用了420种提示变体。研究表明，提示中的人口统计特征显著影响了PCT的结果，反映了偏差，并且在引发封闭形式响应与开放领域响应之间存在差异。此外，在空白论证中还揭示了模型间相似的合理化论据的共同模式，即使立场不同，这些模式也会重复出现。", "innovation": "提出了一种针对LLMs响应进行细粒度分析的方法，包括粗粒度分析产生的立场以及对这些立场的简单文本合理化的细粒度分析。细粒度分析的方法是识别回复中的模式：在不同提示中重复且一致出现的语义相似短语，揭示了给定LLM倾向于产生的自然模式。这项研究找到了一种分析LLMs响应的新方法，能够发现其潜在偏差，并且揭示了在不同提示和立场下产生的一致论据模式。", "conclusion": "人口统计特征会显著影响LLMs在PCT中的表现，反映出潜在的偏差，并且激发封闭式和开放式回答时的结果存在差异。通过识别模式，研究在不同提示和立场下发现了一致的论证模式，这表明LLMs可能会生成类似的合理化论据，即使它们对问题的立场不同。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已成为当前大规模语言模型（LLMs）中最先进的量化管道中的关键组件，通过有效地平滑权重和激活中的异常值。然而，进一步优化旋转参数只能实现有限的性能提升，并且会引入大量的训练超载：由于旋转参数共享，全模型必须同时加载以支持反向传播，从而导致显著的内存消耗和实际应用中的实用性受限。", "innovation": "本文识别了当前旋转量化方法的两大根本限制：（i）旋转无法对齐通道均值，导致量化范围变宽和增加舍入误差；（ii）旋转使得激活分布更加接近高斯分布，增加了由剪裁误差引起的能量损失。为此，作者引入了BASE-Q，这是一种简单而强大的方法，结合了偏置校正和非对称缩放，有效减少了舍入误差和剪裁误差。此外，BASE-Q 支持块优化，消除了内存密集型全模型反向传播的需要。", "conclusion": "在各种LLMs和基准上的广泛实验表明，与QuaRot、SpinQuant和OSTQuant相比，BASE-Q的有效性显著提升，精度差距分别减小了50.5%、42.9%和29.2%。将在不久之后发布代码。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "动态操作的隐含自适应规划器", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "本文介绍了一种用于动态非抓取操作（例如箱子接住）的轨迹级隐变量策略——隐含自适应规划者（LAP），它将规划建模为低维隐空间中的推理过程，并通过人类演示视频有效学习。为解决机器人与人类之间的体能差距，作者引入了一种基于模型的按比例映射模型，可以从人类演示中再生精确的关节状态和物体位置。通过具有变化物体属性的挑战性箱子接住实验，LAP展示出优于以往方法的成功率、轨迹平滑度和能量效率，通过学习类人的柔顺运动和自适应行为，LAP为实现实时适应和跨不同机器人平台的成功迁移提供了可能支持。", "innovation": "1. LAP将规划过程建模为隐空间中的推理，有效利用了人类演示数据。\n2. 通过按比例映射模型，LAP能够精确再生从人类演示获取的关节状态和物体位置。\n3. 在持续执行过程中，LAP能够实时更新隐空间中的计划，并根据新观察结果进行变分重计划，实现在线自适应。\n4. LAP展示了在动态物体操作中学习类人的柔顺性和自适应行为的能力，实现了高成功率、平滑轨迹和高效能量利用。", "conclusion": "整体来看，LAP为动态操作提供了实时自适应能力，并且能够成功地跨不同的机器人平台进行移植，使用相同的演示数据，其显著提高了操作效率和鲁棒性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03796", "html_url": "https://arxiv.org/abs/2506.03796", "title": "Geoff: 用于粒子加速器控制的通用优化框架与前端", "title_en": "Geoff: The Generic Optimization Framework & Frontend for Particle Accelerator Controls", "authors": "Penelope Madysa,Sabrina Appel,Verena Kain,Michael Schenk", "background": "世界各地的粒子加速器实验室正在研究机器学习技术以提高加速器的性能和运行时间，因此出现了多种方法和算法。Geoff的目的是使这些方法统一化，并在比较或迁移这些方法时减少摩擦。Geoff提供标准接口用于优化问题，加速开发的速度，并提供一个参考GUI应用程序将所有功能整合起来。", "innovation": "Geoff是一个标准化的优化框架，由CERN开发并向CERN和GSI合作维护，它是EURO-LABS项目的产物。它提供了标准化的接口来解决优化问题，快速开发所需的实用功能，以及一个参考的GUI应用程序来整合所有功能。", "conclusion": "本文概述了Geoff的设计、功能及其当前的应用情况。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导技术是扩散模型中广泛使用的提高样本质量的方法。技术上，指导通过使用比主模型泛化更广泛的辅助模型来实现。研究指出，当辅助模型的泛化误差比主模型相似但更强时，效果最佳。在此基础上，作者提出了一种新技术——遮罩滑动窗口指导（M-SWG），这是一种无训练的新型方法。M-SWG通过限制主模型的感受野来突出长距离的空间依赖关系，从而引导主模型。这种方法无需访问先前迭代的模型权重、额外训练或类别条件。实验表明，M-SWG相较于之前最先进的无训练方法，在Inception评分上表现更优，且没有产生样本过饱和的问题。结合现有的指导方法，M-SWG在使用EDM2-XXL和DiT-XL时，达到了ImageNet上FID的最先进水平。", "innovation": "提出了遮罩滑动窗口指导（M-SWG），这是一种无训练的新型方法。M-SWG通过限制主模型的感受野来突出长距离的空间依赖关系，从而引导主模型。这种方法无需访问先前迭代的模型权重、额外训练或类别条件。通过这种方法，M-SWG相较于之前最先进的无训练方法，在Inception评分上表现更优，且没有产生样本过饱和的问题。", "conclusion": "M-SWG结合现有的指导方法，在ImageNet上使用EDM2-XXL和DiT-XL时，达到了FID的最先进水平，并且在Inception评分上表现更优，且没有引入样本过饱和的问题。代码可在提供的链接中找到。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions：使用CoTR提示和大规模语言模型的合成注释的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "在低资源语言如马拉地语中进行情感识别仍然具有挑战性，因为这些语言的标注数据有限。现有研究多集中于大型语言模型（LLMs）的合成注释技术，以及在情感识别任务中大型语言模型与预训练模型的表现对比。", "innovation": "提出了L3Cube-MahaEmotions数据集，该数据集包含11个细粒度的情感标签，使用LLMs合成注释训练数据，并通过Chain-of-Translation（CoTR）技术将马拉地语句子翻译成英语进行情感标注。研究发现，通用的大规模语言模型如GPT-4和Llama3-405B在复杂低资源情感识别任务中表现优于微调的BERT模型，强调了高质量标注数据和情感识别任务复杂性的意义。", "conclusion": "实验结果显示，GPT-4的预测表现优于微调后的BERT模型，而基于合成标签训练的BERT模型无法超越GPT-4。这表明通用的大规模语言模型在复杂低资源情感识别任务中具有更好的泛化能力，强调了高质量人工标注数据的重要性。该数据集与模型已公开共享。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解任何视频中的摄像机运动的方法", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "本文介绍了CameraBench，这是一个大型数据集和基准测试平台，用于评估和改进对摄像机运动的理解。它包含约3000个多样化的互联网视频，并通过严格的多阶段质量控制过程进行标注。研究人员发现，某些运动（如跟随或跟踪）需要理解场景中的移动主体。通过对大量人类进行的研究，发现领域专业知识和基于教程的培训可以显著提高注释准确性。", "innovation": "本文的贡献之一是一个由电影摄影师与之合作设计的摄像机运动分类法。使用CameraBench评估结构从运动（SfM）和视频-语言模型（VLMs），发现SfM模型难以捕捉与场景内容有关的语义基本，而VLMs难以捕捉与精确轨迹估计有关的几何基本。通过在CameraBench上对生成的VLM进行微调，来整合两者优势，展示其在运动增强描述、视频问答和视频-文本检索等方面的潜在应用。", "conclusion": "希望我们的分类体系、基准测试和教程将推动未来努力，以实现理解所有视频中摄像机运动的终极目标。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA: 一种治理AI代理系统的安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "随着大型语言模型（LLM）-驱动的智能代理能够在最小的人类干预下自主互动、协作并完成任务，行业指南强调用户需要对代理保持全面的控制，降低恶意代理可能带来的危害。尽管有多个代理系统设计提出解决代理身份、授权和任务委托的问题，但它们仍停留在理论阶段，未被实际实施和评估。最重要的是，这些设计没有提供用户对代理的控制功能。", "innovation": "本文提出了一种名为SAGA的安全架构，用于治理代理系统。SAGA提供用户在其代理生命周期中的监督权。用户可以通过一个中心实体（Provider）注册其代理，该实体管理代理联系信息和用户自定义的访问控制策略，并帮助代理在跨代理通信中强制执行这些策略。SAGA引入了一种密码机制来生成访问控制令牌，这提供了一种针对代理之间交互实现细粒度控制的方式，同时保证了正式的安全性。", "conclusion": "在不同地理位置的代理任务上，SAGA进行了评估，使用了多种LLM平台。结果表明，SAGA在各种条件下表现出最小的性能开销，不会影响底层任务的实用性。SAGA架构促进了安全和可信赖的代理自主系统的部署，从而加速了该技术在敏感环境中的负责任采用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20723", "html_url": "https://arxiv.org/abs/2508.20723", "title": "在随机框架下的适应性 ride-pooling 个性化费率优化", "title_en": "Adaptive Optimisation of Ride-Pooling Personalised Fares in a Stochastic Framework", "authors": "Michal Bujak,Rafal Kucharski", "background": "成功运营 ride-pooling 系统需要为用户提供具有吸引力的服务，即通过吸引人的定价来补偿用户认为的成本。然而，由于每位旅行者的时间价值存在显著异质性，他们会设定不同的可接受价格，而这对于运营商来说是未知的。", "innovation": "本文展示了运营商可以通过学习个体乘客的接受水平（经过10天的90%以上准确性），来优化个性化费率的适应性定价策略。该策略让运营商每天制定符合乘客预期的报价，从而逐步吸引更多的需求。此外，通过了解个体乘客的行为特征，运营商可以提升运营表现，增加收益，并减少无效的拼车情况。", "conclusion": "运营商通过学习个体乘客的行为特征，不仅能提升乘客的效用，还能增加自身的利润，同时集中资源于更有吸引力和利润的空间。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从拉格朗日扩散的稳定性到处理非对数凹采样的近端MCMC的收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "在许多应用场景中，如成像逆问题，势能是非凸的和非光滑的。Unadjusted Langevin Algorithm (ULA) 和 Proximal Stochastic Gradient Langevin Algorithm (PSGLA) 是处理这种势能的常用算法。PSGLA 结合了前进后退优化算法和 ULA 步骤，但关于非凸势能下的 PSGLA 收敛性证明尚未有结果。本文证明了在非凸势能在无穷远处强凸的假设下，离散时间 ULA 对漂移近似具有稳定性，并利用 Moreau 包络的性质首次证明了 PSGLA 在非凸势能下的收敛性。", "innovation": "本文的主要创新在于证明了离散时间 ULA 对漂移近似的稳定性，并结合 Moreau 包络的性质，首次证明了在非凸势能下的 PSGLA 算法的收敛性。此外，实验结果表明，与 Stochastic Gradient Langevin Algorithm 相比，PSGLA 在后验采样中表现出更快速的收敛率，同时保留其恢复属性。", "conclusion": "本文通过理论证明了 PSGLA 在非凸势能下的收敛性，并通过实验验证了其在成像逆问题中的有效性和优越性。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20527", "html_url": "https://arxiv.org/abs/2508.20527", "title": "分子机器学习在化学过程设计中的应用", "title_en": "Molecular Machine Learning in Chemical Process Design", "authors": "Jan G. Rittig,Manuel Dahmen,Martin Grohe,Philippe Schwaller,Alexander Mitsos", "background": "近年来，分子机器学习（ML）在纯组分及其混合物的性质预测以及化学空间中新分子结构探索方面展现出了巨大潜力。", "innovation": "本文回顾了最新的分子ML模型，并讨论了通过将物理化学知识以混合或物理导向的方式融入其中，进一步提升ML方法的可能性。特别地，探讨了如何在化学工艺规模上利用分子ML，以及将其集成到过程设计和优化模型中，以加速新型分子和工艺的发现。同时指出，为了实现这些目标，需要创建分子和过程设计基准，并在实践中验证提出的候选方案，可能需要与化学工业合作。", "conclusion": "分子ML在化学过程设计中的应用具有很大的潜力，但尚不完全成熟。通过创建分子和过程设计基准，以及在实践中的验证，可以进一步推动该领域的研究和发展。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "IVF治疗中胚胎选择的深度学习模型解释", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不孕不育对个人的生活质量有显著影响，且未来预计会增加。在经济发达国家，体外受精（IVF）是解决低生育率问题的主要技术之一。然而，胚胎分级过程耗时且效率不高。利用深度学习技术，可以提高胚胎分类的准确率并保持可解释性。", "innovation": "提出了一种基于卷积神经网络（CNN）和长期短期记忆（LSTM）融合架构的可解释人工智能（XAI）框架（CNN-LSTM），用于提高胚胎分类的准确率和可解释性，从而实现更有效的胚胎选择过程。", "conclusion": "利用深度学习模型进行胚胎分类，结合XAI技术提高决策透明度，从而提升IVF治疗的成功率，改善患者的生活质量。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10520", "html_url": "https://arxiv.org/abs/2506.10520", "title": "专家宏图（宏图）在大规模多任务推荐中的应用", "title_en": "Macro Graph of Experts for Billion-Scale Multi-Task Recommendation", "authors": "Hongyu Yao,Zijin Hong,Hao Chen,Zhiqing Li,Qijie Shen,Zuobin Ying,Qihua Feng,Huan Gong,Feiran Huang", "background": "在大规模图结构多任务学习场景中，每个任务都对应一个不同规模的图。传统方法忽略了图结构信息，仅仅依赖于单独的用户和项目嵌入。然而，利用图结构可以提升模型性能。在背景介绍中，文章指出了传统方法的局限性，并提出了利用图结构信息的必要性。", "innovation": "本文提出了宏图专家（Macro Graph of Expert, MGOE）框架，这是首个结合宏图嵌入和任务特异性专家的多任务学习方法。通过引入宏图底部（Macro Graph Bottom）和宏预测塔（Macro Prediction Tower），有效融合了图信息，解决了大规模多任务推荐中的挑战。", "conclusion": "MGOE在大规模推荐系统中经过线下实验和AB测试，显示了优于当前最佳多任务学习方法的优势，标志着在基于图的多任务推荐领域的突破性进展。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21156", "html_url": "https://arxiv.org/abs/2508.21156", "title": "使用指令调校的大语言模型进行自动缺陷审查", "title_en": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "authors": "Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan", "background": "在大型项目中，缺陷审查（即将新问题分配给开发人员的任务）通常速度缓慢且不一致。为了改进这一过程，该研究提出了一种轻量级框架，该框架利用了LoRA适配器并使用候选限制解码来确保有效的任务分配。", "innovation": "该论文介绍了一种新的轻量级框架，框架使用指令调校的大语言模型（LLM）和候选限制解码方法，以提高缺陷审查的速度和一致性。该模型在EclipseJDT和Mozilla数据集上进行测试，表明即使在较低的精确Top-1准确率下，也能获得高质量的候选列表（在第10位的命中率达到0.753）。最近的快照测试显示，准确率有显著提升，这表明该框架在真实世界的人工在环任务审查中具有潜在的应用价值。", "conclusion": "研究结果表明，指令调校的大语言模型提供了一种经济实用的替代方案，可以替代成本高昂的功能工程和基于图的方法。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07338", "html_url": "https://arxiv.org/abs/2507.07338", "title": "贝叶斯双下降", "title_en": "Bayesian Double Descent", "authors": "Nick Polson,Vadim Sokolov", "background": "双下降是过参数化统计模型中的一个现象。这些过参数化模型，如深度神经网络，在风险特性上表现出一种再下降的有趣属性。这种现象是机器学习领域的一个最近的现象，并且已经成为了许多研究的主题。随着模型复杂性的增加会有一个传统的偏差-方差权衡的U形区域，但当参数数量等于观测数量且模型成为插值模型时，风险可以变成无限大，然后在过参数化区域中它会再下降，即双下降效应。这项研究表明这种现象具有自然的贝叶斯解释。此外，研究表明，它并不与贝叶斯模型拥有的传统奥卡姆剃刀原理冲突，即它们倾向于在可能的情况下选择更简单的模型。已经发展了包括Dawid的模型比较理论、Dickey-Savage结果以及与广义岭回归和收缩方法的联系在内的全面理论基础。", "innovation": "这项研究提出了一种贝叶斯视角来解释双下降现象，并且表明这种现象与贝叶斯模型的偏好简单模型的原理并不冲突。还开发了Dawid的模型比较理论、Dickey-Savage结果，以及与广义岭回归和收缩方法的联系作为全面的理论基础。这项研究的创新在于它为理解双下降现象提供了一个新的角度，并且将其与传统的模型复杂性选择原则协调起来。", "conclusion": "最后，研究提出了未来的研究方向。这表明对于双下降现象的研究仍然有一些未解决的问题和方向。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05066", "html_url": "https://arxiv.org/abs/2508.05066", "title": "两种几何Jensen-Shannon散度的两个故事", "title_en": "Two tales for a geometric Jensen--Shannon divergence", "authors": "Frank Nielsen", "background": "几何Jensen-Shannon散度（G-JSD）因其在高斯分布之间的闭式表达而受到机器学习和信息科学领域的青睐。现有的G-JSD是基于概率密度的，现在引入了一种新定义的正密度下的几何Jensen-Shannon散度，称为扩展的G-JSD，它可以应用于更广泛的正测度情况。研究了G-JSD和扩展的G-JSD之间的差距，并表示了这些散度和杰弗里斯散度及贝叶塔卡距离的关系。扩展的G-JSD被证明是$f$-散度，满足信息单调性和几何不变性。还为多变量高斯分布的两种G-JSD提供了闭式公式，并讨论了使用射影$\boldsymbol{\text{γ}}$-散度进行蒙特卡罗随机估计和近似的方法。", "innovation": "本文引入了扩展的G-JSD，它适用于更广泛的正测度情况。此外，文献还推导了G-JSD和扩展的G-JSD之间的差距，并通过杰弗里斯散度和贝叶塔卡距离表示了它们，证明了扩展的G-JSD是$f$-散度，并为多变量高斯分布情况提供了闭式公式。还讨论了这两种G-JSD的蒙特卡罗随机估计方法及其与度量距离的关系。", "conclusion": "两类几何JSD都可以视为普通JSD的正则化形式。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA：植物科学中用于评估视觉语言模型的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA数据集是从广泛使用的PlantVillage图像库派生的大型视觉问答（VQA）数据集，旨在推进农业决策和分析中视觉-语言模型的发展和评估。该数据集包含大量高质量的问题-答案（QA）对，涵盖了14种作物和38种疾病条件的55,448张图像，每个问题都按认知复杂度分为3个级别和9个不同的类别，通过专家指导和自动二阶段流程生成，数据集由领域专家多次审查以确保科学准确性与相关性。", "innovation": "创新点在于设计了一个大型的、标准化的视觉问答数据集，涵盖农业领域的作物和疾病种类，通过专家指导和自动流程合成高质量的问题-答案对，提供给研究者用于评估视觉-语言模型的性能，有助于提高植物疾病的诊断准确性并推动农业领域的科学研究发展。", "conclusion": "本研究的目标是提供一个公开、标准、专家验证的数据集，增强植物疾病的诊断准确性，并促进农业科学领域的研究。该数据集将被公开发布在指定的链接上，供研究人员使用以提升视觉-语言模型在植物科学中的应用。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20108", "html_url": "https://arxiv.org/abs/2508.20108", "title": "通过收益-波动性归一化减轻股票价格数据中的分布偏移以实现准确预测", "title_en": "Mitigating Distribution Shift in Stock Price Data via Return-Volatility Normalization for Accurate Prediction", "authors": "Hyunwoo Lee,Jihyeong Jeon,Jaemin Hong,U Kang", "background": "股票价格预测吸引了学术界和工业界的广泛关注，由于其潜在能力以揭示复杂的市场模式并增强决策制定。然而，现有方法在处理分布偏移方面往往效果不佳，注重于缩放或表示适应，而未能充分解决训练数据和测试数据之间的分布差异和形状错位问题。", "innovation": "我们提出了 ReVol（收益-波动性归一化，以减轻股票价格数据中的分布偏移），这是一种针对股票价格预测的稳健方法，专门针对分布偏移问题。ReVol 采用三种关键策略来减轻这些偏移：1) 归一化价格特征以去除样本特定特性，包括收益、波动性和价格规模，2) 使用基于注意力模块准确估计这些特性，从而减少市场异常的影响，3) 将样本特征重新纳入预测过程，恢复在归一化过程中丢失的特性。此外，ReVol 结合几何布朗运动进行长期趋势建模，与神经网络进行短期模式识别的融合，互补各自的优点。", "conclusion": "在实际数据集上进行的大量实验表明，ReVol 通常能够在大多数情况下增强最先进的骨干模型的性能，并分别在 IC 和 SR 上实现超过 0.03 和 0.7 的平均改进。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成的模型驱动量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "该研究针对量子和混合量子-经典软件系统，探讨了通过利用大型语言模型（LLMs）及其检索增强生成（RAG）管道进行模型到文本/代码转换的新方向。背景在于这些系统的成本高昂和风险，以及缺乏开发者技能，模型驱动的方法有助于降低成本并减轻这些问题。", "innovation": "论文提出了一种利用大型语言模型和RAG管道进行模型到文本/代码转换的新方法，并专注于量子和混合量子-经典软件系统。通过验证从UML模型生成代码的想法，特别是使用Qiskit库在门基或电路基量子计算机上执行的Python代码，研究展示了精心设计的提示可以显著提高CodeBLEU评分，从而生成更准确和一致的量子代码。", "conclusion": "尽管当前研究取得了显著成果，但还有进一步探索的空间，包括利用软件系统模型实例作为RAG管道的信息来源，以及利用LLM进行代码到代码的转换（如编译使用案例），以进一步提高量子代码的生成质量。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21553", "html_url": "https://arxiv.org/abs/2508.21553", "title": "强化学习可复用测试套件", "title_en": "Reusable Test Suites for Reinforcement Learning", "authors": "Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker", "background": "强化学习（RL）代理在解决序列决策任务方面前景广阔。然而，验证部署时代理策略行为的可靠性和表现仍具有挑战性。现有的大多数强化学习策略测试方法生成的测试套件主要是针对特定的代理策略，且这些测试套件与其他策略的相关性不明确。", "innovation": "提出了名为Multi-Policy Test Case Selection（MPTCS）的新型自动测试套件选择方法，该方法用于RL环境中，设计目的是从任何策略测试框架生成的基于解算性、多样性和通用难度的测试案例中提取测试案例。MPTCS使用一组策略从候选池中选择一组用于测试的、可复用且具有策略无关多样性的测试案例，这些案例能揭示代理在行为中的典型缺陷。此外，还评估了测试套件多样性促进方法的有效性。", "conclusion": "研究评估了难度评分的效果，并探讨了在不同策略集合规模下方法的有效性和成本变化情况。同时，研究了受质量多样性算法启发的离散化通用测试案例描述表如何覆盖状态空间以及哪些策略能触发产生缺陷行为。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程中的核心实践，可以帮助系统地评估由开发人员或大语言模型（LLM）生成的程序。然而，编写全面的单元测试存在挑战，因此LLM被用来自动化测试生成，但训练LLM生成高质量的测试方法仍然尚未被充分探索。", "innovation": "本文提出了一种新的强化学习框架——UTRL（.Unit Test Reinforcement Learning），该框架通过对抗训练两个LLM：单元测试生成器和代码生成器，来训练LLM生成高质量的单元测试。单元测试生成器通过最大化其生成能够揭露代码生成器解决方案中的错误的测试的能力来训练，而代码生成器则通过最大化其生成能够通过测试生成器生成的测试的解决方案的能力来训练。实验结果表明，通过UTRL训练的Qwen3-4B模型生成的单元测试的质量高于使用监督微调训练的相同模型生成的单元测试。此外，UTRL训练的Qwen3-4B模型在生成高质量的单元测试方面超过了GPT-4.1等前沿模型，证明了UTRL在训练LLM生成单元测试方面的有效性。", "conclusion": "通过对比实验，本工作展示了在UTRL训练下的Qwen3-4B生成的单元测试不仅质量更高，而且在代码评估上更接近于由真实单元测试诱导的效果，证明了UTRL的有效性并优于其他现有的前沿模型。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21811", "html_url": "https://arxiv.org/abs/2508.21811", "title": "在信息技术行业中敏捷方法论在DevOps实践中的整合", "title_en": "The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry", "authors": "Ashley Hourigan,Ridewaan Hanslo", "background": "信息技术行业对快速软件交付的需求显著增强，强调需要更快的产品和服务发布，并且需要具有增强功能来满足客户期望。传统的瀑布模型（Waterfall）正逐渐被更加灵活、迭代开发和适应变化的敏捷方法（Agile）所取代。继敏捷之后，DevOps强调了开发和运维团队的协作，关注持续集成和部署，以交付更稳健和高质量的软件产品和服务。本文旨在批判性地评估敏捷和DevOps实践，以确定敏捷方法在DevOps实践中的可行性和适用性。", "innovation": "本研究通过与不同领域信息技术行业的敏捷和DevOps从业人员进行11场半结构化访谈，并通过主题分析提取并综合了51个独特的代码，归纳为19个主题，具体描述了在DevOps生命周期中整合敏捷方法的情况。", "conclusion": "研究结果表明，能够更好地理解敏捷方法在DevOps实践中的相互关系，符合研究目标。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "本研究背景涉及利用大型语言模型（LLM）的代理通过迭代的推理、探索和工具使用解决复杂任务的过程，但这一过程可能导致长且昂贵的上下文历史记录。现有最先进的软件工程（SE）代理（如OpenHands或Cursor）使用基于LLM的总结来处理这一问题，但不清楚这种增加的复杂性是否带来了实际的性能提升，或者是否可以简单地忽略旧的观察结果。本研究旨在通过对比这些策略在SWE-agent中的表现来解决这一疑问。", "innovation": "本研究的创新之处在于提出了一种系统性的对比研究，将基于简单观察遮罩和基于LLM的总结的策略在五个不同的模型配置下应用于SWE-agent。研究结果表明，简单观察遮罩策略不仅能将成本降低一半，还能在某些情况下稍微超过总结策略的表现，特别是在使用Qwen3-Coder 480B时，遮罩策略能将解题率从53.8%提升到54.8%，同时以更低的成本保持竞争力。", "conclusion": "本研究表明，在至少针对SWE-agent在SWE-bench Verified中的应用，最有效的和最高效的方式可能是最简单的。研究结果也为研究和实践提供了新的见解，证明了简化的方法在特定应用中的有效性。研究最后公布了代码和数据以确保可重复性。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21634", "html_url": "https://arxiv.org/abs/2508.21634", "title": "人类编写的代码 vs. 人工智能生成的代码：关于缺陷、漏洞和复杂性的大规模研究", "title_en": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "authors": "Domenico Cotroneo,Cristina Improta,Pietro Liguori", "background": "随着AI代码助手被越来越多地集成到软件开发工作流程中，了解它们生成的代码与人类编写的代码之间的差异对于确保可靠性和可维护性及安全性至关重要。", "innovation": "本研究对来自人类开发者和三个人工智能最新语言模型（ChatGPT、DeepSeek-Coder 和 Qwen-Coder）的代码在多个软件质量维度上进行了大规模比较，包括代码缺陷、安全漏洞和结构复杂性。", "conclusion": "研究发现，人工智能生成的代码通常更为简单且更具重复性，却更容易出现未使用构造和硬编码调试等问题；而人类编写的代码则展现出更高的结构复杂性，并且存在更多的可维护性问题。值得注意的是，人工智能生成的代码中还包含了更多的高风险安全漏洞。这些发现揭示了人工智能和人工编写代码在缺陷特征上的显著差异，并强调了在AI辅助编程中需要特别的质量保证实践。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21289", "html_url": "https://arxiv.org/abs/2508.21289", "title": "使用持续集成解决HPC中的重现性挑战", "title_en": "Addressing Reproducibility Challenges in HPC with Continuous Integration", "authors": "Valérie Hayot-Sasson,Nathaniel Hudson,André Bauer,Maxime Gonthier,Ian Foster,Kyle Chard", "background": "HPC社区通过采用激励机制推广可重现研究，主要会议对符合可重现性要求的论文给予奖励。然而，许多论文并未达到这些要求。由于HPC基础设施和软件的独特性以及严格的访问要求，可重现性可能会受限。缺乏资源访问的情况下，作者认为定期记录的测试，通过持续集成（CI），以及完整的过程记录可以作为替代方案。", "innovation": "本文提出了一种GitHub Action，CORRECT，它可以安全地在远程HPC资源上执行测试。研究通过CORRECT对三种不同类型HPC应用程序进行了评估，展示了使用CORRECT自动化和文档化重现性评估的有效性。", "conclusion": "更好的HPC合规的CI解决方案将提高HPC应用程序的重现性。CORRECT能够有效解决现有限制，提高研究的可靠性和可验证性。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21432", "html_url": "https://arxiv.org/abs/2508.21432", "title": "RepoMark: 用于代码大型语言模型的代码使用审核框架", "title_en": "RepoMark: A Code Usage Auditing Framework for Code Large Language Models", "authors": "Wenjie Qu,Yuguang Zhou,Bo Wang,Wengrui Zheng,Yuexin Li,Jinyuan Jia,Jiaheng Zhang", "background": "大型语言模型（LLMs）在代码生成中的快速发展已经改变了软件开发流程，通过前所未有的效率自动化完成编码任务。然而，这些模型在开源代码仓库（如GitHub）中的训练引起了一系列严重的伦理和法律问题，特别是在数据授权和开源许可合规性方面。由于数据收集过程的不透明性，开发者越来越质疑模型训练者是否在使用代码库之前获得了适当的授权。", "innovation": "本文提出了一种新型的数据标记框架RepoMark，以审核代码LLMs的数据使用情况。通过对代码文件生成多个语义等价代码变体，将数据标记引入代码文件中，并在检测时利用一种新的基于排名的假设测试来检测模型的储存情况，从而在小代码库的情形下也具有高效性。相比于之前的数据审计方法，RepoMark显著提高了样本效率，即使用户仅有少量代码文件的情况下也能有效实现审计。RepoMark在严格5%的假发现率下，对小型代码库的检测成功率超过90%，远超现有数据标记技术下的55%。", "conclusion": "RepoMark提供了一种增强代码LLMs训练透明性的稳健且理论有效的解决方案，可以保护代码库所有者的权益。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21386", "html_url": "https://arxiv.org/abs/2508.21386", "title": "欧盟核心网络安全立法中的风险与合规", "title_en": "Risks and Compliance with the EU's Core Cyber Security Legislation", "authors": "Jukka Ruohonen,Jesper Løffler Nielsen,Jakub Skórczynski", "background": "欧盟长期支持基于风险的监管方法，并在近期的网络安全立法中继续采用这一方法。鉴于新的网络安全法规与合规要求之间的内在关联，本研究旨在探讨欧盟五项核心网络安全立法中风险的表述方式，以及这些表述是否表明这些法规在风险概念上的趋同或分歧，并识别描述法律风险概念时使用的定语和术语。", "innovation": "本研究采用定性法律解释和分类构建的方法，分析了五项立法对不同类型网络安全风险的全面覆盖，包括技术、组织和人类安全风险及其人为之外的风险。研究揭示了法律风险概念的风险描述中技术方面和资产的重要性，以及一个立法中的威胁中心视角。同时，研究指出在可接受风险、非概率风险和残留风险方面存在显著差距。", "conclusion": "欧盟新的网络安全立法已显著扩大了基于风险的监管方法的范围，但在复杂性和合规负担方面也有所增加。基于此，论文提出了一些实用的建议，以帮助应对合规问题和进一步的研究。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "通过物联网和生成式人工智能实现气候适应性学习", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "近期，随着气候变化的加剧，提高公众和专业人员的气候韧性教育变得尤为重要。传统的气候教育平台在适应性和个性化方面存在不足，需要新的技术手段来提升学习效果。", "innovation": "该论文介绍了一种名为Future Atmospheric Conditions Training System (FACTS)的新平台，该平台结合了物联网（IoT）传感器收集的实时大气数据和知识库中的精选资源，动态生成本地化的学习挑战。该系统利用生成式人工智能（Generative AI）对学员的响应进行分析，提供个性化的反馈和支持。这一创新不仅提高了系统的交互性和适应性，还通过实证研究验证了其在气候适应性学习中的有效性。", "conclusion": "研究结果表明，物联网和生成式人工智能在开发适应性气候教学工具方面具有巨大潜力，可以显著提高气候韧性的教育参与度和气候意识的树立。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus: 自治谓词合成在定向 fuzzing 中的应用", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向 fuzzing 的目标是找到能够引起指定目标程序状态的输入。这一技术在调试系统崩溃、确认已报告的漏洞以及为潜在漏洞生成利用工具方面有很多应用。然而，目标状态通常深嵌于程序中，且由于大量可能的程序输入，搜索空间也非常庞大。现有方法依赖分支距离或手动指定的约束来指导搜索，但这些分支往往不足以精确地描述向目标状态进展的过程，而手动指定的约束也往往针对特定类型的漏洞，难以适用于多样化的目标状态和程序。", "innovation": "Locus 是一种新的框架，旨在提高定向 fuzzing 的效率。Locus 的核心洞察是合成谓词来捕捉 fuzzing 进程中的语义有意义的中间状态，作为到达目标状态的里程碑。Locus 通过一个自治框架和程序分析工具自动化此任务，并迭代地合成和细化候选谓词，同时通过符号执行确保谓词严格放宽目标状态，以防止误拒。实验表明，Locus 显著提高了八种最先进的 fuzzers 在发现实际漏洞时的效率，平均加速了 41.6 倍。迄今为止，Locus 已经找到了八个之前未修补的漏洞，其中一个已经获得了草案补丁的认可。", "conclusion": "我们的评估结果显示，Locus 显著提高了八种最先进的 fuzzers 在发现现实世界漏洞方面的效率，平均加速了 41.6 倍。此外，Locus 已经发现了一些新的未修复漏洞，表明其在提高 fuzzing 效率和发现新的潜在漏洞方面具有巨大潜力。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.13821", "html_url": "https://arxiv.org/abs/2506.13821", "title": "软件是基础设施：故障、成功、成本及其对形式化验证的案例", "title_en": "Software is infrastructure: failures, successes, costs, and the case for formal verification", "authors": "Giovanni Bernardi,Adrian Francalanza,Marco Peressotti,Mohammad Reza Mousavi", "background": "论文概述了软件在现代社会中的作用及其质量低下带来的巨大成本，同时回顾了过去40年内多次重大的软件失败事件。", "innovation": "论文提出了通过研究、学习和应用形式化软件验证（尤其是程序分析），来解决软件质量问题的观点，并提到工业实践中获得的成功经验。", "conclusion": "这些成本证明了研究、学习和应用形式化软件验证的必要性，强调形式化验证对于保证软件质量的重要性。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21417", "html_url": "https://arxiv.org/abs/2508.21417", "title": "LLM仓库中脆弱包依赖的实证研究", "title_en": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "authors": "Shuhan Liu,Xing Hu,Xin Xia,David Lo,Xiaohu Yang", "background": "近年来，大规模语言模型（LLMs）迅速发展，改变了多个领域。然而，这些模型依赖于来自包管理系统中的第三方代码依赖关系，形成了复杂的供应链，使得LLMs容易受到安全漏洞的影响。尽管现有研究主要关注模型级别的安全威胁，但LLMs的供应链中的脆弱性却被忽视了。已有研究主要集中在模型级别的安全威胁上，而LLMs供应链中的脆弱性被忽视了。因此，本文通过实证分析了52个开源LLMs的第三方依赖关系及其相关漏洞，探索了开源LLMs仓库中的维护者如何管理第三方漏洞的实际活动，并将LLMs生态系统中的第三方依赖漏洞与Python生态系统进行了比较。研究表明，超过一半的LLMs中的安全漏洞超过56.2个月未被披露，在LLMs生态系统中的易受攻击的依赖项在配置文件中占比高达75.8%。", "innovation": "本文填补了对LLM供应链安全领域研究的空白，通过实证分析揭示了第三方依赖关系及其相关漏洞，提供了对现有和潜在改进的方向的见解，从而为提高LLM供应链的安全性提供了一种创新性的方法。", "conclusion": "本文的研究结果表明，LLMs生态系统中的大部分漏洞至今未被报告，且超过56.2个月；同时，75.8%的LLMs在其配置文件中存在脆弱的第三方依赖项。这些发现对于理解LLM供应链风险具有重要价值，也为实践者提供了宝贵见解，并强调了改进LLM供应链安全性的潜在方向。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21636", "html_url": "https://arxiv.org/abs/2508.21636", "title": "检测AI代码生成器中的隐秘数据中毒攻击", "title_en": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "authors": "Cristina Improta", "background": "深度学习（DL）模型在自然语言到代码生成中的应用已经成为现代软件开发管道中的重要组成部分。然而，这些模型对大量数据的依赖，很多时候数据未经清理就来自于网络，使得它们容易遭受数据中毒攻击。在这种攻击中，攻击者会通过注入恶意样本来微妙地偏倚模型的行为。最近的攻击方法是悄无声息地替换安全代码为具有相同语义但存在漏洞的实现，这种方法使得检测方法难以区分受污染样本和未受污染样本。", "innovation": "本文系统地研究了现有数据中毒检测方法在隐秘威胁模型下的有效性。具体地，在三种DL模型（CodeBERT、CodeT5+、AST-T5）上进行了有针对性的数据污染，并评估了谱签名分析、激活聚类和静态分析作为防御方法。研究结果表明，所有方法在检测无触发器的数据污染时都表现不佳，基于表示的方法无法分离出受污染的样本，而静态分析则面临误报和漏报的问题，这强调了对AI辅助代码生成中更稳健、无触发器依赖的防御方法的需求。", "conclusion": "现有的数据中毒检测方法在处理隐秘威胁模型下的无触发器污染攻击时效果不佳，基于表示的方法难以有效隔离受污染样本，静态分析则容易产生误报和漏报。这些结果凸显了在AI辅助代码生成领域需要更可靠的、非触发器依赖的防御机制。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.04184", "html_url": "https://arxiv.org/abs/2502.04184", "title": "公共计算笔记本是否大多数本质上不可执行？", "title_en": "Are the Majority of Public Computational Notebooks Pathologically Non-Executable?", "authors": "Tien Nguyen,Waris Gill,Muhammad Ali Gulzar", "background": "计算笔记本是探索性数据科学的事实上的平台，提供了一个交互式的编程环境，用户可以顺序地创建、修改和执行代码单元。然而，这种灵活性往往会引起代码质量问题。先前的研究表明，大约76%的公共笔记本是不可执行的，这引发了关于其可重复使用性的重大担忧。传统的可执行性概念要求笔记本完全运行且无错误，这过于僵化，导致许多笔记本被错误分类，并且高估了它们的不可执行性。", "innovation": "本文研究了在不同可执行性观念和程度下公共笔记本的病理性不可执行问题。即使是部分提高可执行性，也能改善代码理解并提供动态分析的路径。研究首先将笔记本分为可能可修复和病理性不可执行笔记本，并衡量移除配置错误和表面执行错误如何提高其可执行性（即额外单元格在无错误情况下执行的比例）。研究发现，在42,546个流行的公共笔记本中，仅21.3%是真正病理性不可执行的。对于可修复笔记本，基于LLM的方法完全修复了5.4%先前不可执行的笔记本。其中部分修复的笔记本，通过安装正确的模块和生成合成数据，其可执行性提高了42.7%和28%。这些发现挑战了先前的假设，表明笔记本的可执行性高于以前报告的水平，许多提供有价值的部分执行，并且它们的可执行性应在其交互式笔记本的背景下进行评估，而不是通过传统的软件执行标准进行评估。", "conclusion": "本文挑战了先前的观点，证明公共计算笔记本的实际不可执行性远低于预期，许多笔记本仍然具有部分执行的价值，并且它们的可执行性应根据交互笔记本的范式进行评估，而不是传统的软件执行标准。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07328", "html_url": "https://arxiv.org/abs/2503.07328", "title": "完整循环：具有表达性循环引用的可达性类型（扩展版本）", "title_en": "Complete the Cycle: Reachability Types with Expressive Cyclic References (Extended Version)", "authors": "Haotian Deng,Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf", "background": "程序中结合引用和可变状态的本地推理一直是长期挑战。现有方法（如所有权系统、线性类型、唯一类型和词法效果跟踪）要么施加全局限制（如唯一性或线性），要么依赖浅层句法分析。这些设计在处理高阶函数和共享可变状态时显得力不从心。可达性类型 (RT) 跟踪高阶程序中的引用和分离，确保运行时安全性和不干扰性。然而，RT 系统面临三大挑战：（1）它们禁止循环引用，排除了非终止计算和固定点组合子；（2）需要深层跟踪，要求资格符包括所有可传递可达位置，降低了精度并阻碍了如细粒度并行等优化；（3）引用资格不变性防止引用逸出其分配上下文，使得引用工厂不可表达。", "innovation": "本文通过扩展 RT，提出了三种机制以增强表达性。首先，引入循环引用，使得递归模式可以直接通过存储来编码。其次，采用浅层跟踪资格符，解耦引用与其可传递可达值。最后，引入一个逃逸规则及其引用子类型化，使引用资格符能够逸出其分配上下文。这些扩展在 $\text{F}_{<:}^{\bullet}$-演算中进行了形式化，并通过机械化证明了类型安全性，案例研究展示了通过固定点组合子、非干扰并行性和逃逸只读引用的表达力。", "conclusion": "这些扩展增强了 RT 的表达能力，解决了原始 RT 的三大局限性，从而提高了对高阶程序的可达性和构建的跟踪精度，并允许更灵活的编程实践。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习关联配置和性能的模型。然而，当系统在动态环境中运行时，工作负载的变化、硬件的更改和系统的更新会不可避免地在不同层面引入概念漂移 - 全局漂移，重塑整个配置空间的性能景观；局部漂移，仅影响配置空间的某些子区域。因此，现有的离线和迁移学习方法难以实时应对这些隐性和不可预测的变化，使得配置性能学习变得具有挑战性。", "innovation": "我们提出了一种名为DHDA的在线配置性能学习框架，旨在捕捉和适应不同层面的漂移。关键在于，DHDA通过双层层级适应法实现了对局部和全局漂移的适应：在顶层，重新划分数据到不同的部分，在每个部分内重新训练局部模型，仅在必要时处理全局漂移；在底层，每个部分的局部模型可以检测局部漂移并异步适应。结合增量更新和定期全面重新训练以最小化未检测到漂移时的冗余计算，DHDA通过八个软件系统的评估及与最先进的方法的对比，证明比现有方法实现了更好的准确性和适应性提升，并且具有合理的开销，并且能够改善不同局部模型应对概念漂移的能力。", "conclusion": "DHDA在八种软件系统上表现出显著更高的准确性和对直至两倍提升的漂移的有效适应能力，同时保持合理的开销，并能够增强不同局部模型应对概念漂移的能力。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "通过迭代混合程序分析的LLM测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "自动化单元测试生成仍然是一个重大挑战，尤其是在处理现实世界项目中的复杂方法时。尽管大型语言模型（LLMs）在代码生成方面取得了进展，但在概念控制流结构方面的能力有限，导致分支覆盖率偏低。", "innovation": "该论文提出了一种名为Panta的技术，模拟人类开发人员分析代码和构建测试用例的过程。Panta将静态控制流分析与动态代码覆盖率分析相结合，使用迭代反馈驱动机制系统地指导LLMs识别未覆盖的执行路径并生成更好的测试用例。", "conclusion": "通过在来自开源项目的高度语义复杂性类上进行实证评估，Panta在行覆盖率和分支覆盖率方面分别实现了26%和23%的提升，相比当前最先进的技术具有更有利的结果。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21454", "html_url": "https://arxiv.org/abs/2508.21454", "title": "使用大型语言模型增强指针分析中的语义理解", "title_en": "Enhancing Semantic Understanding in Pointer Analysis using Large Language Models", "authors": "Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen", "background": "指针分析已经研究了四十年，但现有的框架仍然存在传播不正确事实的问题。这些问题的主要局限在于它们对代码语义的理解不足，导致对用户自定义函数的处理过于保守。近年来，大型语言模型（LLMs）的进步为解决这一问题提供了新的机会。", "innovation": "本文提出了LMPA（LLM增强的指针分析），这是一种将LLMs集成到指针分析中的愿景，以增强其准确性和可扩展性。LMPA 识别与系统API相似的用户自定义函数，并对其进行相应的建模，从而减少错误的跨调用上下文传播。此外，它通过推断初始的指向集并引入结合自然语言的新摘要策略，增强了基于摘要的分析。", "conclusion": "本文讨论了实现这一愿景的关键挑战。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.18956", "html_url": "https://arxiv.org/abs/2504.18956", "title": "自动检测内联代码注释恶臭的方法", "title_en": "Towards Automated Detection of Inline Code Comment Smells", "authors": "Ipek Oztas,U Boran Torun,Eray Tüzün", "background": "代码注释在软件开发中至关重要，因为它直接影响软件的可维护性和整体质量。不良的代码注释实践会导致代码注释恶臭，这对软件维护产生负面影响。尽管已有研究对内联代码注释恶臭进行了分类，但自动检测这些恶臭仍然是一项挑战。通过机器学习（ML）模型和大型语言模型（LLM），这项研究旨在自动检测和分类内联代码注释恶臭，以确定每种恶臭类型的检测准确性。作者通过扩增原始标注数据集（包括更多代码片段及其对应的注释），并使用GPT-4对原数据集和扩增数据集进行分类评估，以及训练和测试了七种不同的机器学习算法，以此来比较它们的分类表现。这些模型中，随机森林模型表现最好，整体准确性达到69%，同时，梯度提升和逻辑回归模型的准确性分别为66%和65%，这些结果为该领域的未来研究奠定了坚实的基础。扩增数据集使GPT-4模型的预测准确性从原来的34%提高到了55%。这项研究通过探索自动化检测和分类内联代码注释恶臭，为软件可维护性做出了贡献，并且研究者将扩增数据集和代码工具在线公开，为开发自动化注释恶臭检测工具提供了宝贵资源。", "innovation": "这项研究通过扩增已标注的数据集并将新数据与GPT-4模型结合，提高了内联代码注释恶臭的自动检测和分类准确性。同时，该研究使用多种机器学习算法进行对比实验，通过输出模型表现证明了随机森林模型在检测内联代码注释恶臭方面的优越性。这项工作不仅创新性地展示了使用大型语言模型辅助自动化检测方法的有效性，还为未来该领域研究提供了更加完整和准确的数据分析方法和基准标准。", "conclusion": "该研究通过扩增数据集和使用机器学习模型（尤其是随机森林）显著提高了内联代码注释恶臭的自动检测和分类能力。GPT-4模型的表现也得到了提升，这表明大型语言模型在辅助自动化检测方面具有潜在应用价值。此次研究为软件工程中的自动化注释恶臭检测工具开发提供了先进的技术和数据支持，并为相关的未来研究设定了一个新的基准。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.20977", "html_url": "https://arxiv.org/abs/2508.20977", "title": "ConfLogger: 通过配置日志提升系统配置诊断能力", "title_en": "ConfLogger: Enhance Systems' Configuration Diagnosability through Configuration Logging", "authors": "Shiwen Shan,Yintong Huo,Yuxin Su,Zhining Wang,Dan Li,Zibin Zheng", "background": "现代可配置系统提供了复杂的配置空间，以便进行定制，但这种灵活性引入了诸如错误配置和潜藏的软件错误等广泛存在的配置相关问题。现有的诊断支持主要集中在软件行为的故障后分析中以识别配置问题，但这些方法都没有关注软件是否提供了足够的故障信息用于诊断。为了解决这个问题，该论文提出了一种配置日志的概念，旨在增强现有的日志记录实践，通过源代码级别的配置感知静态污点分析与基于LLM的日志生成统一来提升软件配置诊断性。这种方法通过对整个项目中的配置相关数据流进行跟踪来识别敏感代码段，并通过分析配置代码上下文生成诊断日志语句。", "innovation": "研究开发了ConfLogger，这是第一个将配置感知静态污点分析和基于LLM的日志生成相结合的工具。该方法通过追溯整个项目中的配置相关数据流来识别敏感代码段，并分析配置代码上下文来生成诊断日志语句。研究表明，与现有方法相比，ConfLogger能够有针对性地提升日志覆盖率，性能提高了12%，并提高了12.6%的F1分数，同时提升了诊断精度、召回率和配置信息的直接可解决问题的比例。进一步的用户研究表明，ConfLogger能够将诊断时间加速1.25倍，并提高251.4%的故障排除准确性。", "conclusion": "研究结果表明，通过配置日志增强软件配置诊断性是有效的。ConfLogger不仅提升了现有日志记录点的覆盖率，还在逻辑变量日志方面达到了8.6%更高的精确度、79.3%更高的召回率和26.2%更高的F1分数，同时显著提高了诊断效率和故障排除准确性。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生实现的AI模拟：系统综述、参考框架及与标准化架构的映射", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "现代亚符号AI的应用面临数据量不足和数据质量低的挑战，这影响了AI模型的开发和应用。现有的AI模拟通过虚拟训练环境提供了一种解决方案，允许AI代理在合成数据的环境中安全高效地开发。数字孪生进一步提升了这一技术，因为它能够生成高保真虚拟复制品并能够与实际系统进行交互以收集更多数据。本文综述了数字孪生增强的AI模拟，并通过分析22篇主要研究，识别了技术趋势并提出了参考框架，以定位数字孪生和AI组件。", "innovation": "本文通过引入数字孪生来缓解AI模拟中的数据不足和数据质量低问题；通过对22项主要研究的系统综述，提出了一个综合参考框架，该框架不仅考虑了数字孪生与AI组件的集成，还将其映射到ISO 23247数字孪生参考架构之上，从而为研究者提供了一个全面而系统的视角。", "conclusion": "本文提出了一个详细的参考框架和架构指南，以解决当前在数字孪生驱动的AI模拟中面临的技术挑战。然而，也指出未来研究者需要探索更多关于如何优化数据生成、增强孪生与物理系统的交互以及如何进一步集成AI技术的挑战和机遇。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.18721", "html_url": "https://arxiv.org/abs/2508.18721", "title": "LLM作为执行估算器：恢复缺失的依赖关系以进行实用的时间旅行调试", "title_en": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "authors": "Yunrui Pei,Hongshu Wang,Wenjie Zhang,Yun Lin,Weiyu Kong,Jin song Dong", "background": "在现有的编程调试方法中，动态数据依赖关系的计算通常需要用到完全记录的程序执行轨迹。然而，完全记录执行轨迹成本高且耗时。因此，研究提出了RecovSlicing，通过部分执行轨迹和相关代码，利用大语言模型（LLM）来推测程序的动态特性。", "innovation": "提出了RecovSlicing方法，通过部分记录的程序执行轨迹和相关代码，利用非确定性的大语言模型来推测未记录的执行过程，从而估算出变量的在执行过程中的定义。此外，该方法允许用户提供隐式查询变量，如隐含的库变量。它解决了精确恢复实际值和结构及内存地址对齐等问题。", "conclusion": "RecovSlicing在8300个数据依赖关系上，对3个切片基准的评估中表现出显著的优势。与现有的最先进切片器如Slicer4J、ND-Slicer、LLM切片器和重新执行切片器相比，其准确性和召回率分别达到了80.3%、91.1%和98.3%，相比之下，最好的基线分别为39.0%、82.0%和59.9%（准确率），53.4%、79.1%和87.1%（召回率）。此外，将RecovSlicing集成到基于双切片的回归错误定位器中，能够定位更多的回归错误，显著提高了性能。"}
{"llm_update_time": "20250903", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用PennyLane黑客马拉松挑战基准测试大型语言模型进行量子代码生成", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "近年来，大型语言模型（LLMs）在代码生成方面展现了强大的潜力，但在量子计算领域的应用尚未得到充分探索。本文使用来自Quantum Hackathon（QHack）的真实世界挑战来评估LLMs在基于PennyLane的量子代码生成上的表现，提出了QHackBench这一新颖基准数据集，并从基础指令提示和检索增强生成（RAG）两个方面进行了评估。评估框架包括功能性正确性、语法规有效性和执行成功率三个维度，结果显示增强RAG模型在复杂量子算法中的表现与传统提示方法相当。此外，还提出了一种多agent评估管道，以逐步改进错误解决方案，进一步提高执行成功率。", "innovation": "引入了QHackBench基准数据集，基于PennyLane黑客马拉松的实际挑战；采用从简单到复杂的挑战难度评估模型性能；提出RAG增强模型在复杂量子算法中的表现；开发了一种迭代优化错误解决方案的多agent评估管道，以提高执行成功率；承诺公开QHackBench基准数据集、评估框架和实验结果，推动AI辅助量子编程的研究进步。", "conclusion": "RAG增强模型在生成量子代码时，尤其是在处理复杂量子算法方面，表现出良好的性能。多agent评估管道有助于不断改进错误解决方案，进一步提高执行成功率。QHackBench基准数据集和评估框架的公开，将促进相关领域进一步研究与创新。"}
{"llm_update_time": "20250903", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09823", "html_url": "https://arxiv.org/abs/2507.09823", "title": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "title_en": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "authors": "Ekaterina Borodich,Dmitry Kovalev", "background": "近年来，Malitsky（2020）和Alacaoglu等人（2023）开发了一种自适应的一阶方法GRaAL，该方法通过估计目标函数的局部曲率来计算步长，而无需任何线性搜索过程或超参数调优，并达到了固定步长梯度下降法在L-光滑函数中的标准迭代复杂度Ο(L||x_0 - x^*||^2/ε)。但一个自然的问题是，能否加速GRaAL的收敛速度，以匹配Nesterov（1983）的加速梯度下降法的最优复杂度Ο(√(L||x_0 - x^*||^2/ε))？尽管L和Lan（2025）以及Suh和Ma（2025）已经做出了一些尝试，但现有的加速算法适应目标函数局部曲率的能力仍然有限。", "innovation": "本文解决了这一问题，开发了带有Nesterov加速的GRaAL算法，该算法能够以几何或线性速率适应局部曲率调整步长，类似于未加速的GRaAL。本文证明了该算法在L-光滑函数下实现了接近最优的迭代复杂度，并且在更一般的(L_0, L_1)-光滑性假设下也成立。", "conclusion": "因此，本文开发的带有Nesterov加速的GRaAL算法不仅在局部曲率适应性方面有所提高，而且在迭代复杂度方面也达到了最优，为凸优化领域提供了一种新的自适应加速梯度方法。"}
