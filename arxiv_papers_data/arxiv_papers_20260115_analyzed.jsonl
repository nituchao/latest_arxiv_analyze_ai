{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.07964", "html_url": "https://arxiv.org/abs/2601.07964", "title": "游戏开发中的可执行本体：从算法控制到语义世界建模", "title_en": "Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling", "authors": "Alexander Boldachev", "background": "本文分析了通过boldsea框架实现的可执行本体（EO）在游戏开发中的应用。讨论了从行为编程到语义世界建模的转型，指出EO在游戏AI架构中弥补了语义过程的差距。", "innovation": "本文展示了如何通过数据流条件而不是显式的抢占逻辑实现基于优先级的任务中断。研究表明，EO与行为树（BT）和目标导向动作规划（GOAP）的不同在于，EO能够表述任务何时成为可能，这对游戏AI的架构来说是一个根本性的区别。", "conclusion": "讨论了整合策略，时间事件图的调试优势，以及由LLM驱动的运行时模型生成的潜力。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08065", "html_url": "https://arxiv.org/abs/2601.08065", "title": "一种验证神经反馈系统中接近避免规范的新策略", "title_en": "A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems", "authors": "Samuel I. Akinwande,Sydney M. Katz,Mykel J. Kochenderfer,Clark Barrett", "background": "目前，向前可达性分析是验证神经反馈系统中达成避免性质的主要方法，这种方法的优势在于现有后向可达性方法的局限性导致其在可扩展性方面存在不足。", "innovation": "本文提出了一种新的算法，用于计算神经反馈系统中的后向可达集的上下界，并将这些后向算法与传统的前向分析技术相结合，形成了一种统一的验证框架。", "conclusion": "这种新的验证框架有助于提高对神经反馈系统中接近避免性质验证的效率和准确性。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.07965", "html_url": "https://arxiv.org/abs/2601.07965", "title": "当模型知道何时不知道：校准、级联和清洗", "title_en": "When Models Know When They Do Not Know: Calibration, Cascading, and Cleaning", "authors": "Chenjie Hao,Weyl Lu,Yuko Ishiwaka,Zengyi Li,Weier Wan,Yubei Chen", "background": "在许多情况下，模型需要识别其自身的不确定性。现有研究已经在特定领域展示了校准可以提供可靠的置信度估计。该研究的重点是从模型内部信号计算置信度，以反映其不确定性。", "innovation": "提出了一个简单、有效且通用的无训练方法，适用于视觉和语言模型，该方法涉及模型校准、级联和数据清洗，以更好地利用模型识别不确定性的能力。引入了两种应用：一是具有校准优势路由的模型级联，二是基于模型集成的数据清洗，利用校准置信度的可比性进行数据清洗。", "conclusion": "使模型能够识别其不确定性的能力是一个实用的步骤，向着更加高效、可靠和值得信赖的AI迈进。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08005", "html_url": "https://arxiv.org/abs/2601.08005", "title": "AI监管中内部部署的漏洞", "title_en": "Internal Deployment Gaps in AI Regulation", "authors": "Joe Kwon,Stephen Casper", "background": "现有的前沿人工智能（AI）监管主要关注对外部用户部署的系统，这些部署更为显见且容易受到外界监督。然而，当公司在内部部署高度有能力的系统用于提升研发（R&D）、加速关键业务流程和处理敏感专有数据时，高风险的应用也可能发生在内部。文章探讨了2025年美国和欧盟关于内部部署的前沿AI监管中存在的三个关键缺口：（1）范围模糊导致内部系统逃避监管责任；（2）点火评估无法反映内部系统的持续演变；（3）信息不对称导致监管意识和监督失效。", "innovation": "文章通过分析指出，在2025年美国和欧盟的AI监管中，针对内部部署系统存在三个关键漏洞，并探讨了这些漏洞持续存在的原因，即可衡量性、激励机制和信息准入方面的紧张关系。", "conclusion": "通过理解这些模式，文章希望政策制定者在制定与内部部署AI系统相关的政策时能够做出有意识的决策，而不是偶然的决策。文章最后映射出了可能的方法以及相应的权衡。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08049", "html_url": "https://arxiv.org/abs/2601.08049", "title": "增强智能教室中学生参与度的出勤跟踪和情绪检测集成", "title_en": "Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms", "authors": "Keith Ainebyona,Ann Move Oguti,Joseph Walusimbi,Ritah Kobusingye", "background": "智能教室技术在高等教育中的应用侧重于自动化考勤，而较少关注学生在讲堂期间的情绪和认知参与度，这阻碍了教师及时发现学生失去注意力并调整教学策略。", "innovation": "提出了一种基于物联网的SCASED系统（智能教室出勤系统结合情绪检测），该系统整合了自动考勤跟踪和面部情绪识别，用于支持课堂参与度监测。该系统使用树莓派摄像头和OpenCV进行面部检测，fine-tuned版MobileNetV2模型来分类与学习相关的情绪状态，包括专注、无聊、困惑和挫败感。通过会话机制管理出勤和情绪监测以增强教学响应性。", "conclusion": "实验结果表明，通过使用DAiSEE数据集，情感分类准确率达到89.5%，结合出勤数据与情绪分析可为教师提供有关教室动态的额外洞察，并支持更及时的教学实践。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08079", "html_url": "https://arxiv.org/abs/2601.08079", "title": "MemoBrain：作为推理主脑的执行记忆", "title_en": "MemoBrain: Executive Memory as an Agentic Brain for Reasoning", "authors": "Hongjin Qian,Zhao Cao,Zheng Liu", "background": "在工具增强的人工智能框架中，复杂的推理本就是长期的（long-horizon），导致推理轨迹和临时工具制品不断积累，对大型语言模型有限的工作区域造成压力。缺乏显式的记忆机制，这些积累会破坏逻辑连续性，影响任务对齐。因此，记忆不仅是一个辅助的效率问题，而是支持长期连贯、目标导向推理的核心组件。", "innovation": "MemoBrain 提出了一种执行记忆模型，用于工具增强的代理，它构建了一个关注依赖的记忆，捕捉重要的中间状态及其逻辑关系。作为推理代理的副驾，Memobrain 组织推理进程而不阻碍执行，并有效管理工作区，通过修剪无效步骤、折叠已完成的亚轨迹，并在固定的工作区间预算内保持一个紧凑、高相关性的推理脊梁，从而提供明确的认知控制，而非被动的上下文积累。", "conclusion": "通过在具有挑战性的长期推理基准测试（如 GAIA、WebWalker 和 BrowseComp-Plus）上评估 MemoBrain，展示了与强大的基线相比的一贯改进。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08070", "html_url": "https://arxiv.org/abs/2601.08070", "title": "语义重力深坑：为什么负面约束会失效", "title_en": "Semantic Gravity Wells: Why Negative Constraints Backfire", "authors": "Shailesh Rana", "background": "负面约束（即“不要使用X单词”的指令）是对大型语言模型指令遵循能力的一项基本测试。尽管这些约束看似简单，但在执行中却频繁失败，而这些失败的条件仍不清晰。因此，这份论文进行了第一个全面的机制性调查，研究负面指令失效的原因。", "innovation": "1. 提出了语义压力的概念，这是一种模型生成禁止词汇的内在概率的定量测量。\n2. 通过分层分析和利用对数递归技术，揭示了负面指令激发表现为两种具有不同机制的失败模式：触发失败和覆盖失败。", "conclusion": "发现负面约束设计中存在一项根本性的紧张关系：禁用一个单词的行为所引发的激活实际会细化模型产生该单词的倾向，导致负面约束反其道而行之。这一发现揭示了底层机制问题，即越试图禁用某个单词，它反而更容易被生成。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.07866", "html_url": "https://arxiv.org/abs/2601.07866", "title": "弥合信任鸿沟：基于临床验证的混合可解释AI在孟加拉国产科健康风险评估中的应用", "title_en": "Bridging the Trust Gap: Clinician-Validated Hybrid Explainable AI for Maternal Health Risk Assessment in Bangladesh", "authors": "Farjana Yesmin,Nusrat Shirmin,Suraiya Shabnam Bristy", "background": "尽管机器学习方法在产科健康风险预测方面展现出潜力，但在资源受限的环境中，临床应用面临一个关键障碍，即缺乏可解释性和信任度。", "innovation": "该研究提出了一种结合前-后处理模糊逻辑和SHAP解释的混合可解释AI (XAI) 框架，并通过系统临床反馈进行了验证。研究开发了一种模糊-XGBoost模型，实现了88.67%的准确率（ROC-AUC: 0.9703）。SHAP分析发现医疗服务可及性是主要预测因素，而工程化模糊风险评分位居第三，验证了临床知识的整合。临床医生认为综合临床参数是有价值的，但指出了一些关键缺口：产科史、孕周以及连通性障碍。", "conclusion": "结合可解释模糊规则与特征重要性解释，不仅增强了实用性和信任度，还提供了可解释AI在产科健康中的实际部署见解。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08000", "html_url": "https://arxiv.org/abs/2601.08000", "title": "考察先例与法典共谋：LLM安全的案例增强调控", "title_en": "Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety", "authors": "Can Jin,Rui Wu,Tong Che,Qixin Zhang,Hongwu Peng,Jiahui Zhao,Zhenting Wang,Wenqi Wei,Ligong Han,Zhao Zhang,Yuan Cao,Ruixiang Tang,Dimitris N. Metaxas", "background": "大型语言模型（LLMs）在遵循安全原则的同时，如何不拒绝善意请求仍然是一个重大挑战。虽然OpenAI通过详细“代码式”的安全规则进行推理来增强其o系列模型的安全性，但这种方法在缺乏高级推理能力的开源LLMs中的有效性尚未充分研究。", "innovation": "该研究系统性地评估了显式指定详尽安全代码与通过实例展示它们之间的影响差异。研究发现，引用显式代码对减少危害性存在不一致的效果，反而会导致实用性下降，而通过实例增强简化的安全代码能产生更稳定和泛化的安全行为。为此，研究提出了一种基于实例增强推理的调控方法CADA，利用自我生成的安全推理链进行强化学习，以提高安全性，增强对抗攻击的鲁棒性，减少过度拒绝，同时保持实用性。", "conclusion": "CADA方法能够有效提升安全性，增强对抗攻击的稳定性，减少过度拒绝，同时在各种基准测试中保持实用性，为在不牺牲实用性的前提下改善安全性提供了一种实际可行的方法。"}
{"llm_update_time": "20260115", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.08052", "html_url": "https://arxiv.org/abs/2601.08052", "title": "基于短期预测的深度强化学习在奶牛场高效电力负荷调度中的应用", "title_en": "Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms", "authors": "Nawazish Alia,Rachael Shawb,Karl Mason", "background": "奶牛养殖是一个能耗密集型行业，依赖于电网电力。随着可再生能源的不断融入，能源管理的可持续性变得至关重要，旨在降低对电网的依赖，同时支持联合国可持续发展目标7，即获得负担得起的清洁能源。然而，可再生能源的间歇性性质给实时平衡供给与需求带来了挑战。这意味着智能负载调度变得至关重要，不仅要降低运营成本，还要保障可靠性。强化学习已显示出提高能源效率和降低能耗的潜力。然而，大多数基于强化学习的调度方法都假设对未来价格或发电量有完全的了解，而在动态环境中这是不现实的。此外，标准的PPO变体依赖于固定的剪辑或KL散度阈值，这往往在动态费率下导致训练不稳定。", "innovation": "该研究提出了一个深度强化学习框架，用于在奶牛场进行高效负载调度，特别关注电池储能和水加热，在实际操作约束下。提出的方法结合了基于日和月的残差校准的短期需求和可再生能源生成预测，以及使用比例积分微分控制器调节KL散度，以实现稳定的策略更新。基于真实世界奶牛场数据训练的方法，相较于PPO，表现出了1%的更低的电费；相较于DQN，降低了约4.8%的电费；相较于SAC，降低了1.5%的电费。对于电池调度，PPO将电网进口减少了13.1%，展示了在现代奶牛场可持续能源管理中的可扩展性和有效性。", "conclusion": "通过组合短期需求和可再生能源生成预测、以及使用比例积分微分控制器来调节KL散度的PPO变体，研究方法在降低电费成本和电网进口上展现出显著的优势，为现代奶牛场的可持续能源管理提供了新的解决方案。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08383", "html_url": "https://arxiv.org/abs/2601.08383", "title": "拆解预训练：MoE与密集模型中的知识归因分析", "title_en": "Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models", "authors": "Bo Wang,Junzhuo Li,Hong Chen,Yuanlin Chu,Yuxuan Fan,Xuming Hu", "background": "MoE架构通过将模型容量与每令牌计算脱钩，允许可扩展性超越密集模型的计算限制。然而，MoE架构在预训练过程中如何塑造知识获取，以及与密集架构有何不同，仍不清楚。", "innovation": "研究人员提出了Gated-LPI（Log-Probability Increase）作为一种神经元级别的归因度量方法，能够分解跨神经元的log-probability增加。通过比较MoE和密集模型在120万训练步和60万训练步时的知识获取动态，发现了三个模式：低熵主干、早期汇聚以及功能稳健性。", "conclusion": "这些模式表明，稀疏性从训练早期就开始培养一个内在稳定且分布式计算基础结构，这有助于弥合稀疏架构和训练时可解释性之间的差距。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08545", "html_url": "https://arxiv.org/abs/2601.08545", "title": "适应学习者编程修复：具有迭代编辑驱动检索增强的解决方案生成器", "title_en": "Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement", "authors": "Zhenlong Dai,Zhuoluo Zhao,Hengning Wang,Xiu Tang,Sai Wu,Chang Yao,Zhipeng Gao,Jingyuan Chen", "background": "随着编程领域大语言模型（LLMs）的发展，智能编程辅导系统受到了广泛关注。然而，大部分研究集中在修复编程学习者的错误代码，而忽略了提供错误背后的原因。为弥补这一不足，本文提出了一个新的任务——LPR（针对学习者的编程修复），并提出了一种新的有效框架L-SG（学习者导向的解决方案生成器），旨在提升编程修复效果的同时提供错误描述。", "innovation": "提出了一个新颖的任务LPR，专注于修复编程学习者的错误代码及其原因；设计了L-SG框架，包括两阶段解决方案：第一阶段利用修复解决方案检索框架构建解决方案检索数据库，并采用编辑驱动的代码检索方法检索有价值解决方案，指导LLMs识别并修复错误代码；第二阶段提出解决方案引导的程序修复方法，在检索解决方案的指导下修复代码并提供解释；此外，提出了迭代检索增强方法，利用生成代码的评估结果迭代优化检索方向，探索更合适的修复策略，从而在实际编程辅导场景中提高性能。", "conclusion": "实验结果表明，我们的方法显著优于一组基线，验证了我们框架对于新提出的LPR任务的有效性。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08777", "html_url": "https://arxiv.org/abs/2601.08777", "title": "渐近普遍对齐：通过测试时缩放的新对齐框架", "title_en": "Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling", "authors": "Yang Cai,Weiqiang Zheng", "background": "大型语言模型（LLMs）需要被调整以适应具有不同甚至可能冲突偏好的用户，这是个性化和可信人工智能中的核心挑战。该论文试图通过测试时缩放的方式提供一个理想的普遍对齐概念。", "innovation": "论文引入了$(k,f(k))$-稳健对齐这一概念，要求$k$输出模型在与任何单一输出模型的对战中达到$f(k)$的胜率。随着$k$趋向无穷，这被定义为渐近普遍对齐（U-对齐），并且$f(k) \to 1$。该论文的主要结果是确定了最优收敛速率，并且展示了现有的流行方法，如人类反馈纳什学习（NLHF），在利用测试时缩放的优势方面存在根本性的不足。", "conclusion": "本文提出了一个渐近普遍对齐的框架，通过测试时缩放来实现。与现有方法相比，该框架能够保持输出多样性，实现最优测试时缩放速率。进一步，该框架通过一组对称多玩家对齐博弈得到验证，并为这些博弈的自我学习动态提供了理论收敛保证。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08763", "html_url": "https://arxiv.org/abs/2601.08763", "title": "奖励稀有：基于独特性的大型语言模型创造性问题解决的强化学习", "title_en": "Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs", "authors": "Zhiyuan Hu,Yucheng Wang,Yufei He,Jiaying Wu,Yilun Zhao,See-Kiong Ng,Cynthia Breazeal,Anh Tuan Luu,Hae Won Park,Bryan Hooi", "background": "强化学习（RL）已成为训练后大型语言模型（LLMs）的核心范式，尤其适用于复杂的推理任务，但RL经常遭受探索崩溃的问题：策略过早地集中于一小组主导的推理模式，这虽然提升了pass@1，但限制了rollout级别的多样性和pass@k上的收益。这种问题的根本原因在于通过定期化局部令牌行为来维持多样性，而非维持解集的多样性。", "innovation": "我们提出了一种基于独特性的强化学习方法，该方法在rollout级别中明确奖励能够展示罕见高水平策略的正确解决方案。我们的方法使用基于大型语言模型的评判者对同一问题的不同rollout进行高层次策略的聚类，忽略表面差异，并根据聚类规模反向重置策略的优势。这使得新的正确策略比冗余策略获得了更高的奖励。", "conclusion": "在数学、物理学和医学推理基准测试中，我们的方法在大规模采样预算下始终如一地提高了pass@$k$，并且在不牺牲pass@1的前提下增加了pass@$k$曲线下的面积（AUC@$K$），同时保持了探索并发现了更多的具有多样性的解决方案策略。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08297", "html_url": "https://arxiv.org/abs/2601.08297", "title": "揭开注意力中的斜线模式之谜：RoPE的角色", "title_en": "Demystifying the Slash Pattern in Attention: The Role of RoPE", "authors": "Yuan Cheng,Fengzhuo Zhang,Yunlong Hou,Cunxiao Du,Chao Du,Tianyu Pang,Aixin Sun,Zhuoran Yang", "background": "大型语言模型（LLMs）通常表现出斜线注意力模式，其中注意力分数集中在某个偏移量Δ的次对角线。这些模式在跨词元传递信息方面起关键作用，但它们是如何出现的呢？本文从经验与理论两个层面揭开这种斜线主导头部（SDH）的起源之谜。通过对开源LLM的研究，发现SDHs是模型的固有特性，并在整个分布之外保留一致。通过研究查询、键和旋转位置嵌入（RoPE），详细探讨注意力分数的决定因素，初步提出了SDHs的两种特征条件：（1）查询和键几乎呈秩一矩阵，（2）RoPE主要受中高频分量支配。", "innovation": "通过分析开源模型、实验证据和理论推导，本文揭示了斜线主导头部（SDHs）的内在出现条件。具体地，研究表明当查询和键几乎呈秩一矩阵且RoPE主要受中高频分量支配时，会产生SDHs。此外，通过分析浅层Transformer在特定条件下的训练动态，证明了采用梯度下降训练的模型中会出现SDHs。", "conclusion": "斜线主导头部在跨词元传递信息过程中发挥重要作用，通过对查询、键和RoPE的分析以及理论证明，本文解释了SDHs的内在机制，并验证了其在不同分布中的泛化能力。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08343", "html_url": "https://arxiv.org/abs/2601.08343", "title": "当KV缓存重用在多智能体系统中失败时：跨候选交互对于LLM法官至关重要", "title_en": "When KV Cache Reuse Fails in Multi-Agent Systems: Cross-Candidate Interaction is Crucial for LLM Judges", "authors": "Sichu Liang,Zhenglin Wang,Jiajia Chu,Pengfei Xia,Hui Zang,Deyu Zhou", "background": "在多智能体系统中，LLM会生成多个候选响应，这些响应再由一个LLM评审员进行聚合。为了降低预填充成本，近期研究提倡在部分共享上下文中重用KV缓存，并报告了显著的加速效果。研究表明，这类效率提升在执行代理身上表现较好，但在评审员为中心的推理中效果并不一致。作者在GSM8K、MMLU和HumanEval上进行了验证，发现重用策略会影响评审员的行为，导致终点任务准确率看似稳定，但评审员的选择却与密集预填充的行为不一致。", "innovation": "本文揭示了KV缓存重用机制在评审员为中心的推理中存在失效模式，即在执行代理有效的情况下，对评审员的决策产生显著影响。作者提出了法官一致性率（JCR）来量化这一风险，并通过诊断展示了重用策略如何系统地削弱跨候选交互，尤其是在后续候选块中。进一步的消融实验表明，明确的跨候选交互对于保留密集预填充决策至关重要。", "conclusion": "本研究表明KV缓存重用在多智能体系统中并非一个普遍适用的解决方案，特别是在评审员为中心的推理中。评审员所需的特定系统设计需要更加重视这些风险，以确保一致性和决策的可靠性。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08509", "html_url": "https://arxiv.org/abs/2601.08509", "title": "What If TSF: 一个重新定义预测为情景导向多模态预测的基准", "title_en": "What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting", "authors": "Jinkwan Jang,Hyunbin Jin,Hyungjin Park,Kyubyung Chae,Taesup Kim", "background": "时间序列预测对于现实世界中的决策至关重要，但大多数现有方法仍然单一且依赖于历史模式的外推。尽管大规模语言模型（LLMs）的进步显示了多模态预测的潜力，现有基准通常提供的是回顾性或不一致的原始背景信息，这使得不明确这些模型是否真正利用了文本输入。实际上，人类专家会结合假设场景与历史证据，往往在不同的假设下对同一观察结果产生不同的预测。", "innovation": "作者引入了What If TSF（WIT），这是一种多模态预测基准，旨在评估模型是否能够基于情境文本调整其预测，特别是未来场景。WIT通过提供专家设计的合理或反事实场景，提供了一个情景导向的多模态预测的严格测试平台。", "conclusion": "该基准提供了一个系统的方法来测试多模态预测模型在考虑情境信息时的能力，并通过现实世界中的假设和历史证据展示了模型表现力的真实潜力。基准可在以下链接访问：[这里](this https URL)"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08670", "html_url": "https://arxiv.org/abs/2601.08670", "title": "Parallel Context-of-Experts Decoding for Retrieval Augmented Generation", "title_en": "Parallel Context-of-Experts Decoding for Retrieval Augmented Generation", "authors": "Giulio Corallo,Paolo Papotti", "background": "在检索增强生成中存在权衡关系：一个长提示中拼接文档可以执行多文档推理，但会形成预填充瓶颈；而单独编码文档KV缓存虽然快速，但会破坏跨文档交互。", "innovation": "提出了一种名为Parallel Context-of-Experts Decoding (Pced)的无需训练的框架，将证据聚合从注意机制转移到解码。Pced将检索到的文档视为隔离的“专家”，通过一种新颖的检索感知对比性解码规则来同步专家的预测，这种规则将专家得分与模型先验相结合。此方法恢复了跨文档推理能力，而无需跨越文档构建共享的注意机制。", "conclusion": "Pced方法能够促进多文档推理能力而不增加训练负担，通过解码阶段的协调机制实现了跨文档的交互和推理，同时保持了解码速度。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08457", "html_url": "https://arxiv.org/abs/2601.08457", "title": "探讨少有研究的编码混合印地语-英语可解释多模态Misogyny检测应用", "title_en": "An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English", "authors": "Sargam Yadav(1),Abhishek Kaushik(1),Kevin Mc Daid(1) ((1) Dundalk Institute of Technology)", "background": "数字平台拥有不断扩大的用户基础，扮演着沟通、商业和连接的角色，同时也促进了仇恨言论和性别主义的传播。虽然人工智模型可以有效应对线上仇恨言论，但它们在低资源和混合编码语言中的应用尚未得到充分探索，并且缺乏解释性。在敏感如仇恨言论检测的领域，可解释人工智能（XAI）可以提高深度学习模型决策的透明度。在此研究中，提出了一种多模态和可解释的网络应用，用于检测混合编码印地语-英语中的性别主义言论和网络表情包。系统使用先进的变压器模型支持多语言和多模态环境。", "innovation": "该研究创新地提出了一个多模态和可解释的网络应用，针对混合编码印地语-英语环境中的性别主义言论和网络表情包进行检测。应用使用XLM-RoBERTa、mBERT等最先进的模型，结合Shapley Additive Values（SHAP）和Local Interpretable Model Agnostic Explanations（LIME）等解释性技术提供特征重要性得分，以提高系统的透明度。", "conclusion": "该应用旨在为研究人员和内容审核员提供一个工具，促进该领域的进一步研究，对抗基于性别的人际数字暴力，并确保安全的数字空间。通过人类评估者对聊天机器人可用性问卷（CUQ）和用户体验问卷（UEQ）的反馈衡量整体可用性。"}
{"llm_update_time": "20260115", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.08363", "html_url": "https://arxiv.org/abs/2601.08363", "title": "PosIR：具备位置感知能力的异构信息检索基准", "title_en": "PosIR: Position-Aware Heterogeneous Information Retrieval Benchmark", "authors": "Ziyang Zeng,Dun Zhang,Yu Yan,Xu Sun,Yudong Zhou,Yuqing Yang", "background": "虽然密集检索模型已经取得了显著的成功，但对于这些模型对相关信息位置（即位置偏差）的敏感性的严格评估仍然没有得到充分的探索。现有的基准测试通常采用位置无关的相关性标签，混淆了处理长上下文的挑战和对特定证据位置的偏差。为了应对这一挑战，本文提出了PosIR（位置感知信息检索），这是一个全面的基准测试，旨在诊断各种检索场景中的位置偏差。PosIR涵盖了310个跨越10种语言和31个领域、通过严格的管道建立的数据集，将相关性与精确的参考片段联系起来，从而严格解开了文档长度和信息位置之间的关系。", "innovation": "PosIR通过设计一个集成的基准测试来解决现有评估方法中存在的问题，这些基准包括310个跨10种语言和31个领域的数据集，通过严格的方法将相关性与精确的参考片段联系起来，从而严格解开了文档长度和信息位置之间的关系。此外，通过与10种最先进的嵌入模型进行广泛实验，揭示了位置偏差是一个普遍存在的问题，尤其是在长上下文设置中，大多数模型表现出重心偏差，而某些模型则表现出意外的近时效偏差。进一步的梯度基显著性分析还揭示了驱动这些位置偏好差异的内部注意机制的不同。", "conclusion": "PosIR作为一个有价值的诊断框架，用于促进抗位置偏差检索系统的开发。"}
