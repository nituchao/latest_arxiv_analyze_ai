{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17168", "html_url": "https://arxiv.org/abs/2601.17168", "title": "解析行动系统：从模型解释到系统级问责", "title_en": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability", "authors": "Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran", "background": "行动系统利用大型语言模型（LLMs）创建具有目标导向行为的自主系统，这些系统涉及多步骤规划和与不同环境互动的能力。这些系统与传统的机器学习模型在架构和部署上存在根本性差异，这引入了独特的AI安全挑战，包括目标偏差、决策累积错误和交互代理间的协调风险。这些挑战要求在系统中嵌入可解释性和可追溯性，以确保自主行为的可问责性。目前的可解释性技术主要针对静态模型，应用于行动系统时存在局限性。行动系统的动态性、决策累积和上下文依赖行为需要新的分析方法。", "innovation": "本文评估现有可解释性技术在行动系统中的适用性和限制，发现这些技术在提供有意义的代理决策洞察方面的能力不足。提出未来开发专门针对行动系统的可解释性技术的方向，重点关注在代理生命周期中的监控机制，从目标形成到环境互动再到结果评估，确保这些技术的发展能够保障行动AI系统的安全和可问责部署。", "conclusion": "这些进步对于确保行动AI系统的安全和问责部署至关重要。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17335", "html_url": "https://arxiv.org/abs/2601.17335", "title": "AGI的相对性：分布公理、脆弱性和不可判定性", "title_en": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability", "authors": "Angshul Majumdar", "background": "本文研究了是否可以为人工通用智能（AGI）提供一个自洽的理论定义，该定义能够支持绝对的存在性声明、鲁棒性或自我验证。研究聚焦于在特定任务集合、任务分布、性能函数以及资源预算的共同作用下，如何通过公理化方法来形式化AGI的概念。", "innovation": "研究通过公理化方法，推导出了四类结果。首先证明了通用性本质上是关系性的；其次证明了鲁棒性问题，即任务分布的小幅度变化可能通过悬崖效应导致AGI属性失效；然后确立了在有限资源情况下，AGI能力不会无限泛化的有界泛化保证；最后通过Rice样式和哥德尔-塔斯基证明，证明AGI是类语言属性，无法通过计算方法进行有效验证。研究指出自主通过自我认证实现递归自我改进的方案是不合理的。", "conclusion": "我们的结论是，强大的、非依赖分布的AGI声明，除非具有明确的正式索引，否则是没有定义的；于此同时，AI实践的进步并不能保证能够实现自我认证的通用智能。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17346", "html_url": "https://arxiv.org/abs/2601.17346", "title": "通过大规模语言模型实现多智能体学习路径规划", "title_en": "Multi-Agent Learning Path Planning via LLMs", "authors": "Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu", "background": "在高等教育中将大型语言模型（LLMs）集成到智能导师系统中，提供了个性化学习的潜在变革。然而，现有的学习路径规划方法大多缺乏透明度、适应性和以学习者为中心的解释性。", "innovation": "该研究提出了一种新颖的多智能体学习路径规划（MALPP）框架，利用基于角色和规则的合作机制，三类特定任务智能体（学习分析智能体、路径规划智能体和反思智能体）协作，利用结构化提示和预定义规则分析学习特征，生成并迭代优化定制化学习路径，并提供可解释的反馈。该框架基于认知负荷理论和最近发展区理论，确保推荐路径的认知一致性与教育意义。", "conclusion": "通过多智能体框架，该研究显著提高了路径质量、知识序列连续性和认知负荷的一致性，进一步验证了合作机制的有效性。这项研究为教育中可信和可解释的AI的发展做出了贡献，展示了基于LLM的高质量、可扩展的基于学习者中心的自适应教学方法。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17332", "html_url": "https://arxiv.org/abs/2601.17332", "title": "TheoremForge: 使用低成本代理工作流扩展形式化数据合成", "title_en": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow", "authors": "Yicheng Tao,Hongteng Xu", "background": "高成本的形式化工作流程阻碍了大规模数据合成，并加剧了开源语料库的稀缺性。", "innovation": "引入了TheoremForge，这是一种低成本的形式化数据合成管道，将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明校正和证明草图。通过实施解耦提取策略，工作流从全球失败路径中恢复有效的训练信号，有效利用了浪费的计算。", "conclusion": "实验表明，TheoremForge在利用Gemini-3-Flash时，平均成本仅为0.481美元/成功轨迹，验证率达到12.6%，超过基线的8.6%。我们的策略将证明生成的数据产量提高了1.6倍。因此，TheoremForge构成了一个可扩展的框架，用于构建数据飞轮以训练未来的专家模型。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17310", "html_url": "https://arxiv.org/abs/2601.17310", "title": "使用真实世界数据进行高保真纵向患者模拟", "title_en": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "authors": "Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe", "background": "模拟是一个强大的工具，用于探索不确定性。在临床医学中的应用具有变革性，包括个性化的治疗规划和虚拟临床试验。然而，模拟患者轨迹具有挑战性，因为受到复杂生物和社会文化因素的影响。", "innovation": "我们开发了一种生成式模拟器模型，该模型能够以患者的历史为输入，生成精细而现实的未来轨迹。该模型基于超过2亿份临床记录进行预训练，并能够生成高保真度的未来时间线，仿真事件发生率、实验室测试结果和实际患者未来数据的时序动态。此外，还准确估计了未来事件的概率，实际观测到的比率与预期比率一致，时间跨度和不同结果都保持在接近1.0。", "conclusion": "我们的研究揭示了电子健康记录中真实世界数据的潜在价值，并引入了一种可扩展的临床护理中体外建模的框架。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17009", "html_url": "https://arxiv.org/abs/2601.17009", "title": "使用EM算法进行 Crazyflie 四旋翼无人机的在线参数估计", "title_en": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm", "authors": "Yanhua Zhao", "background": "无人机因其体积小、成本低、操作可靠以及携带多种传感器和执行多种飞行任务的能力而越来越受欢迎。它们能够到达人类难以或无法到达的地方，如地震灾区。无人机在摄影、农业和运输等多个领域发挥作用。四旋翼无人机作为一种四旋翼飞行器，在本文中被研究。在无人机系统中添加随机噪声，研究其对无人机系统的影响，使用扩展卡尔曼滤波器（Extended Kalman Filter, EKF）进行状态估计，基于SDE系统实现了线性二次高斯控制器（Linear Quadratic Gaussian controller, LQG），并应用了EM算法进行四旋翼无人机的参数估计。", "innovation": "本文通过应用EM（期望最大化）算法对Crazyflie四旋翼无人机进行在线参数估计，该方法与传统的离线参数估计有所不同，证明了在线参数估计比传统方法具有更大的收敛值范围。", "conclusion": "研究结果表明，通过在线参数估计方法，Crazyflie四旋翼无人机的参数估计效果更好，表现出更广的收敛值范围。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17343", "html_url": "https://arxiv.org/abs/2601.17343", "title": "我们是否正确地评估了LLM模型编辑中的知识保留精度？", "title_en": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?", "authors": "Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee", "background": "近期，模型编辑已成为一种流行的在大规模语言模型（LLMs）中高效更新知识的范式。然而，现有评估知识保留（或专业知识的保真度）的协议存在不足，无法有效地平衡编辑效果和具体性。文章系统地探讨了现有协议面临的三个基本问题，并实证表明现有度量准则与具体性正则化的强度相关性较弱，缺乏足够的敏感性，难以区分不同方法的具体性表现。", "innovation": "提出了一个建设性的评估协议，该协议消除了开放式LLMs与确定答案假设之间的冲突，避免了查询无关的流畅性偏差，并允许在近连续空间内精细调整评估严格性。实验结果表明，源自该协议的度量准则对具体性正则化强度的变化更敏感，并与之表现出强烈的相关性，从而能够更加细致地区分不同方法的知识保留能力。", "conclusion": "现有度量准则与具体性正则化强度的相关性较弱，且缺乏足够的敏感性，无法有效区分开方法的具体性表现。文章提出的评估协议解决了这些问题，能够更细致地评估不同方法的知识保留能力。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17311", "html_url": "https://arxiv.org/abs/2601.17311", "title": "预算有限的多智能体协同的相变现象", "title_en": "Phase Transition for Budgeted Multi-Agent Synergy", "authors": "Bang Liu,Linglong Kong,Jian Pei", "background": "多智能体系统（MAS）能够提升系统的可靠性，但在固定的推理预算下，它们往往会带来不稳定性，甚至导致系统失效。已有研究通常未能明确解释这种表现，原因在于忽视了现代智能体堆栈的三大限制因素：有限的上下文窗口、智能体间信息传递的损失性和相似智能体的共同失败问题。", "innovation": "该研究提出了一种最小化且可调节的理论框架，该框架通过三个关键约束条件预测了不同系统表象的工作模式：有限的上下文窗口、信息传输的不准确性以及智能体之间的依赖性。论文证明了一个二元成功/失败任务在具有相关输入和损失终止信息传输情况下的深度-b进制树中存在一个明确的相变点。研究还发现了预算内协同效应的具体机制，揭示了对于满足特定条件的智能体组织，其性能超过单一智能体的具体操作法则。", "conclusion": "研究提出了在不同组织形式下的闭式风险模型，并通过合成模拟验证了预测的相变边界。研究表明，相同任务总预算下，多智能体系统的有效协同作用可能发生显著提升或失效，取决于特定的参数条件。研究揭示了在连续优化环境下智能体组织、信息传递和相互依赖性的核心设计权衡，并解释了目前大规模LLM代理系统研究中报告的关键瓶颈。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17348", "html_url": "https://arxiv.org/abs/2601.17348", "title": "在视觉语言模型中审核残疾代表", "title_en": "Auditing Disability Representation in Vision-Language Models", "authors": "Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya", "background": "越来越多的视觉语言模型（VLMs）被应用于社交敏感的应用领域，但这些模型在处理残疾问题上的表现尚未充分探索。研究发现，这些模型在描述人物为中心的图像时，通常会从基于证据的客观描述转变为解释性转变，包括引入无法根据可视证据支持的推理。为了系统分析这一现象，该研究建立了一个基于中立提示（NP）和残疾上下文提示（DP）的基准，并在零样本设置下评估了来自15个最先进的开源和封闭源VLM，涉及9个残疾类别。", "innovation": "该研究引入了一个新的基准，评估了15个最先进的视觉语言模型在零样本设置下的表现，并结合了情感降级、社会尊重和回答长度等标准文本指标，以及通过具有残疾生活经验的标注员验证的语言模型作为法官协议。这一评估框架将解释精度作为核心目标，并发现了在引入残疾上下文时解释精度始终下降，导致带有推测性推理、叙述性扩展、情感降级和缺陷导向框架的解释转变。", "conclusion": "最终研究展示了针对性提示和偏好微调能有效提高解释精度并显著减少解释转变。同时，该研究发现这些影响在种族和性别维度上被进一步放大。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.17188", "html_url": "https://arxiv.org/abs/2601.17188", "title": "实施张量逻辑：通过张量收缩统一Datalog和神经推理", "title_en": "Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction", "authors": "Swapn Shah(1),Wlodek Zadrozny(2) ((1) School of Data Science, University of North Carolina at Charlotte, (2) Department of Computer Science, University of North Carolina at Charlotte)", "background": "人工智能中符号推理与神经网络的统一仍然是一个核心挑战。符号系统虽然可靠且可解释，但缺乏可扩展性；而神经网络虽然具备学习能力，却缺乏透明度。Domingos 提出的张量逻辑通过数学上等价于逻辑规则的爱因斯坦求和约定，提供了一个有意义的统一路径。", "innovation": "本文通过三个实验证明了张量逻辑框架的有效性。首先，通过计算包含1,972人和1,727对亲子关系的圣经家谱图的传递闭包，展示了递归Datalog规则与迭代张量收缩的等效性。其次，通过训练一个具有可学习变换矩阵的神经网络，在保留查询上成功实现了零样本组合推理。最后，验证了张量逻辑的叠加构造在FB15k-237大规模知识图谱上的有效性，设立了标准化链接预测的MRR为0.3068，并在去除直接边的组合推理基准上达到了0.3346的MRR，证明矩阵组成的多跳推理能力。", "conclusion": "本文通过实验证明了张量逻辑框架的有效性，展示了递归Datalog规则和迭代张量收缩的等效性，并证明了即使在移除直接边的情况下，矩阵组成的多跳推理依然能够有效进行，为符号推理与神经网络的统一提供了新的可能性。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18105", "html_url": "https://arxiv.org/abs/2601.18105", "title": "利用智能代理缓解大型语言模型应用中的OWASP十大安全威胁", "title_en": "Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents", "authors": "Mohammad Fasha,Faisal Abul Rub,Nasim Matar,Bilal Sowan,Mohammad Al Khaldy", "background": "大型语言模型（LLMs）已经成为一种变革性和破坏性技术，广泛应用于自然语言处理和机器翻译等众多领域。尽管LLM的应用非常普及，但也引起了安全问题的关注。OWASP已经列出了LLM应用中的十大固有安全漏洞。鉴于对LLM的依赖增加，以及数据完整性和保密性面临的安全威胁，解决这些安全问题是至关重要的。", "innovation": "本文提出了一种框架，旨在缓解OWASP列出的十大安全威胁。该模型利用LLM驱动的智能代理，提供了一种新的方法，可以在实时中主动识别、评估和应对安全威胁。", "conclusion": "本文提供的框架为未来的研究和开发提供了一个初步的蓝图，旨在增强LLM的安全措施，并保护这个快速发展的领域免受新兴威胁。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18127", "html_url": "https://arxiv.org/abs/2601.18127", "title": "AI数据透明度政策的局限性：三种披露谬误", "title_en": "The Limits of AI Data Transparency Policy: Three Disclosure Fallacies", "authors": "Judy Hanwen Shen,Ken Liu,Angelina Wang,Sarah H. Cen,Andy K. Zhang,Caroline Meinhardt,Daniel Zhang,Kevin Klyman,Rishi Bommasani,Daniel E. Ho", "background": "数据透明性已成为解决关于AI的数据质量、隐私和版权等问题的呼声。然而，目前的透明性政策往往未能实现其目标。类似食品营养标签，旨在提供AI透明度的政策常常忽略了有效的披露研究。本文从制度视角出发，指出三种政策实施中的数据披露谬误：数据透明性提案之间存在目标与实际披露之间的规定缺口；改革尝试之间存在要求披露与确保合规的执行缺口；政策提案未显示披露信息与开发实践和公众理解之间的实质性影响。", "innovation": "本文通过社会科学中的透明性理论，识别出三种有效的而非象征性的透明性路径，为提高AI数据透明度政策的实际效果提供了明确的方向。", "conclusion": "本文指出，当前的AI数据透明度政策存在三种关键的谬误：规定缺口、执行缺口和影响缺口。基于透明性研究，文章提出了一些实际可行的路径来改进这些政策，以实现更加有效的数据披露。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18125", "html_url": "https://arxiv.org/abs/2601.18125", "title": "理解聊天机器人使用期间用户隐私推理和行为，以支持有意义的隐私自主权", "title_en": "Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy", "authors": "Mohammad Hadi Nezhad,Francisco Enrique Vicente Castro,Ivon Arroyo", "background": "聊天机器人（CAs）例如聊天机器人，越来越多地用于用户披露敏感信息的情境中，这引发了重要的隐私关注。由于隐私判断是高度情境化的，因此，在聊天机器人交互过程中积极支持用户执行隐私保护行为变得尤为重要。然而，要使用户能够有效参与，需要对用户在实用聊天机器人任务中如何处理和管理敏感信息有更深入的理解。", "innovation": "本研究从计算机科学专业的本科生和研究生的即时披露和保护行为出发，探讨了他们在多种实际聊天机器人任务中的隐私保护行为及其背后的推理，通过模拟ChatGPT界面和隐私通知面板对用户进行了研究。面板支持匿名化，通过撤回、伪造、概括以及提高ChatGPT内置隐私控制的可发现性来提高隐私保护。通过交互日志、思考 aloud 和调查问卷，研究分析了面板如何提高隐私意识，鼓励采取保护行动，并支持关于保护哪些信息和如何保护的上下文相关推理。", "conclusion": "研究结果进一步讨论了提供用户更多和更具意义的隐私保护自主权的工具设计机会。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18129", "html_url": "https://arxiv.org/abs/2601.18129", "title": "Typhoon-S: 最小化开放后训练技术以实现主权大型语言模型", "title_en": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models", "authors": "Kunat Pipatanakul,Pittawat Taveekitworachai", "background": "大型语言模型（LLMs）取得了迅速进步，但大多数最先进的模型主要是在英语和中文等高资源语言上进行训练和评估，并且这些模型往往由少数拥有大规模计算和数据资源的组织开发。这种方法造成了主权环境下的一种实际障碍，因为在资源受限且严格透明度要求的区域或国家级机构必须保留对模型权重、训练数据和部署的控制和理解。为此，我们确定了两个核心需求：1）可适应性，即能够将基础模型转化为通用助手的能力；2）主权能力，即将模型用于高风险、区域特定的任务（例如，本地语言的法律推理和文化知识）的能力。我们研究了是否可以无需扩展大规模指令语料库或依赖复杂的偏好调优管道或大规模强化微调即实现这些需求。", "innovation": "我们提出了Typhoon S，一种最小且开放的后训练配方，结合了监督微调、策略性辅导和小规模强化微调。通过泰国作为研究案例，我们证明了我们的方法能够将主权调整和通用基础模型转化为指令调整模型，表现出强大的通用性能。我们进一步展示了使用InK-GRPO进行小规模强化微调能够提高泰国法律推理和特定知识的同时保留一般能力。", "conclusion": "我们的结果表明，精心设计的后训练策略可以减少指令数据和计算的规模要求，为在学术规模资源下实现高质量的主权大型语言模型提供了一种实际路径。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18118", "html_url": "https://arxiv.org/abs/2601.18118", "title": "LungCRCT: 基于因果表示的肺部CT处理用于肺癌治疗", "title_en": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment", "authors": "Daeyoung Kim", "background": "由于肺癌在早期阶段常被忽视，它已成为全世界癌症患者致死的主要原因之一。肺癌的主要症状难以与其他呼吸系统疾病如COPD的症状区分开来，导致患者未能及时发现疾病进展。为了提高肺癌患者的存活率，早期检测通过持续主动的呼吸系统监控至关重要。低剂量计算机断层扫描（LDCT）胸部扫描是肺部监测中最常用且有效的方法，在计算机视觉基于AI模型（如EfficientNet或ResNet）的图像处理快速进步和应用中，显著提高了肺癌检测或肿瘤分类任务的表现。尽管基于迁移学习的先进CNN模型或基于ViT的模型在肺癌检测方面表现优异，但由于它们在因果依赖性和低可解释性方面存在固有限制，深度学习模型在肺癌治疗分析或因果干预分析模拟中的扩展仍然有限。", "innovation": "该研究引入了基于因果表示学习的肺癌分析框架LungCRCT，通过使用先进的图自编码器因果发现算法（包括距离相关性解耦和基于熵的图像重建精炼），LungCRCT不仅能够进行肺癌治疗的因果干预分析，还能在恶性肿瘤分类任务中实现轻量且鲁棒的下游模型，AUC得分为93.91%。", "conclusion": "该研究提出了一种基于因果表示学习的肺部CT处理框架LungCRCT，有效提高了肺癌治疗的分析和干预能力，同时保持了下游模型的高效和高准确性。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18069", "html_url": "https://arxiv.org/abs/2601.18069", "title": "基于扩散模型的强化学习在版本年龄信息调度中的应用：平均值和尾风险敏感控制", "title_en": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control", "authors": "Haoyuan Pan,Sizhao Chen,Zhaorui Wang,Tse-Tin Chan", "background": "实时无线系统中的信息及时且语义准确的传递至关重要。Age of Information (AoI) 用来量化时间新鲜度，而 Version Age of Information (VAoI) 则通过考虑发送器和接收器之间的版本演进而捕捉语义陈旧度。现有的 VAoI 调度方法主要关注最小化平均 VAoI，但忽视了偶然但严重的陈旧事件，这在随机分组到达和不稳定的信道下会影响可靠性。本文研究了在长传输成本限制下多用户的状态更新系统中的平均和尾风险敏感 VAoI 调度。", "innovation": "本文将平均 VAoI 最小化问题简化为受约束的马尔可夫决策过程，并提出了基于扩散的 Soft Actor-Critic (D2SAC) 算法，通过扩散机制增强策略表达性，为平均性能建立了强大的基础。在此基础上，作者提出了 RS-D3SAC 算法，这是一种敏感于风险的基于分布的扩散 Soft Actor-Critic 算法。该算法集成了基于扩散的执行者和基于分位数的分布批评者，明确地模式了完整的 VAoI 回报分布，通过条件风险值 (CVaR) 进行尾风险优化，同时满足长期传输成本限制。", "conclusion": "模拟结果显示，尽管 D2SAC 能够减少平均 VAoI，但 RS-D3SAC 在优化尾风险方面更具优势，在不牺牲平均性能的情况下显著降低了 CVaR。扩散批评者在尾风险减少中起主导作用，而基于扩散的执行者提供了互补的优化以使策略更加稳定和丰富，从而在多用户无线系统中的语义年龄信息调度中体现出有效性。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18113", "html_url": "https://arxiv.org/abs/2601.18113", "title": "MalURLBench：评估处理网络URL时代理程序脆弱性的基准", "title_en": "MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs", "authors": "Dezhang Kong,Zhuxi Wu,Shiqi Liu,Zhicheng Tan,Kuichen Lu,Minghao Li,Qichen Liu,Shengyu Chu,Zhenhua Xu,Xuan Liu,Meng Han", "background": "LLM（Large Language Models）基于网络的代理近年来因其在日常生活和工作中的实用性而越来越受欢迎。然而，在处理恶意网址时，这些代理显示出关键的安全漏洞：接受伪装的恶意网址会导致后续访问不安全网页，这可能对服务提供商和用户造成严重损害。尽管存在这种风险，目前尚未有基准测试针对这一新兴威胁。我们提出MalURLBench，这是第一个用于评估LLM对恶意网址脆弱性的基准测试。", "innovation": "MalURLBench包含61,845个攻击实例，涵盖了10种现实世界场景和7种真实恶意网站类别。实验表明，现有模型难以检测复杂伪装的恶意网址。我们进一步识别并分析影响攻击成功率的关键因素，并提出URLGuard，这是一种轻量级防御模块。我们相信这项工作将为提升网络代理的安全性奠定基础。", "conclusion": "这些工作将提供一个基础资源，以促进网络代理安全性的提升。我们的代码可以在提供的链接中找到。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18089", "html_url": "https://arxiv.org/abs/2601.18089", "title": "LatentMoE：优化每浮点运算和每个参数的准确度", "title_en": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts", "authors": "Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani", "background": "Mixture of Experts (MoEs) 已成为许多最先进的开源和专有大型语言模型的核心组成部分。尽管它们被广泛采用，但现有 MoE 架构在推理成本（用浮点运算和参数的数量衡量的准确度）方面的接近最优程度仍不清楚。因此，本文从硬件-软件协同设计的角度重新审视 MoE 设计，基于经验与理论的考虑，分析不同部署场景下的关键性能瓶颈，包括离线高吞吐量执行和在线、低延迟的推理。", "innovation": "本文介绍了从系统的设计探索中得出的新模型架构——LatentMoE，该架构优化了每单位计算的准确度，结果显示 LatentMoE 在浮点运算和参数数量的准确度方面优于标准 MoE 架构。此外，研究还在参数规模从 100 亿到 950 亿以及训练文本规模从数十亿到万亿的范围内进行了实证设计空间探索，并提供了理论分析支持。", "conclusion": "经过其出色性能的影响，LatentMoE 架构已被 Nemotron-3 Super 和 Ultra 模型采用，并应用到了更广泛的规模，包括更长的文本掩码长度和更大的模型规模，这一研究成果已在 Nvidia 等（arXiv:2512.20856）中报道。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18111", "html_url": "https://arxiv.org/abs/2601.18111", "title": "揭开数据驱动中程天气预报的神秘面纱", "title_en": "Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting", "authors": "Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz", "background": "近年来，数据驱动方法在天气预报中的革命性进步导致了复杂且定制化的架构和训练策略的出现，这使得不易理解影响预报准确性的基本驱动因素。现有方法通常需要复杂的架构约束和特殊训练启发式方法来实现最先进的概率技能。", "innovation": "本文展示了最先进的概率技能不需要复杂的架构约束或专门的训练启发式方法。我们提出了一种可扩展的框架，通过结合直接下采样的潜空间和历史条件下的局部投影来学习多尺度大气动力学，这种方法对于概率估计器的选择具有鲁棒性，可无缝支持随机插值、扩散模型和CRPS相关集合训练。我们的框架在多项指标上超过了Integrated Forecasting System 和GenCast等模型，实现显著改进。", "conclusion": "这些结果表明，使用通用模型进行扩展足够达到最先进的中程预测，消除了定制训练食谱的需求，并在各种概率框架中表现出有效性。"}
{"llm_update_time": "20260128", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.18085", "html_url": "https://arxiv.org/abs/2601.18085", "title": "用虚拟学习者验证虚拟患者情境的AI增强临床评估‘碰撞测试假人’", "title_en": "\"Crash Test Dummies\" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners", "authors": "Brian Gin,Ahreum Lim,Flávia Silva e Oliveira,Kuan Xing,Xiaomei Song,Gayana Amiyangoda,Thilanka Seneviratne,Alison F. Doubleday,Ananya Gangopadhyaya,Bob Kiser,Lukas Shum-Tim,Dhruva Patel,Kosala Marambe,Lauren Maggio,Ara Tekian,Yoon Soo Park", "background": "在医学和健康专业教育（HPE）中，AI被越来越多地用于评估临床技能，包括通过虚拟标准化病人进行评估。然而，大多数评估依赖于AI-人类的评分者共识可靠性，缺乏一个能够衡量案例、学习者和评分者如何共同影响评分的方法。这导致了评估的稳健性问题，并可能让学习者受到未验证系统的误导。", "innovation": "通过使用AI“模拟学习者”来对AI评分管道进行压力测试和心理测量学表征，从而在人类使用前进行验证。开发了一个开放源代码的AI虚拟患者平台及测量模型，以跨案件和评分条件提供稳健的技能评估。该平台包含虚拟患者、虚拟学习者以及多名独立的AI评分者。通过贝叶斯HRM-SDT模型进行评分分析，该模型将评分视为在不确定性下的决策，并将学习者能力、案例表现和评分者行为分离开来。使用MCMC方法估计参数。", "conclusion": "结合一个专用的虚拟患者平台与一个经过充分理论验证的心理测量模型，能够实现稳健的、可解释的、通用的技能估计，并支持在与人类学习者使用前对AI辅助评估进行验证。还提出了一个逐年“安全蓝图”，将AI工具的部署与基于信任的验证里程碑相捆绑。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19247", "html_url": "https://arxiv.org/abs/2507.19247", "title": "语言建模的马尔科夫范畴框架", "title_en": "A Markov Categorical Framework for Language Modeling", "authors": "Yifan Zhang", "background": "尽管自回归语言模型取得了杰出的性能，但对其内部机制、训练如何塑造其表示以及能够实现复杂行为的统一理论仍然缺乏理解。", "innovation": "本文提出了一种新的分析框架，将单步骤生成过程建模为信息处理阶段的组合，并使用马尔科夫范畴的语言来呈现这一思想。这种方法提供了统一的数学语言来连接语言建模中通常孤立研究的三个方面：训练目标、学习表示空间的几何结构以及实际模型能力。同时，该框架为多标记预测方法如推测解码的成功提供了精确的信息论依据，并明确展示了标准负对数似然（NLL）目标如何促使模型学习数据的内在条件不确定性。结果表明，在线性-softmax头和有界特征的情况下，最小化NLL诱导谱排序，即学习到的表示空间与预测相似性操作的特征谱对齐。", "conclusion": "本文为理解信息如何在模型中流动以及训练目标如何塑造其内部几何结构提供了一个强大的新视角。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.06822", "html_url": "https://arxiv.org/abs/2509.06822", "title": "RAFFLES：LLM系统故障的基于推理归因", "title_en": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems", "authors": "Chenyang Zhu,Spencer Hong,Jingyu Wu,Kushal Chawla,Charlotte Tang,Youbing Yin,Nathan Wolfe,Erin Babinsky,Daben Liu", "background": "随着复杂且相互关联的长时序语言模型（LLM）系统的出现，识别这些系统何时及何地发生故障变得非常困难。现有的评估机制多关注简单的指标、整体结果，且依赖人类视角，难以应对日益复杂的多组件系统。因此，需要新的评估框架来具备推理、探测、迭代以及理解这些系统中复杂逻辑的能力。", "innovation": "本文提出了一种基于迭代推理的离线评估架构——RAFFLES。RAFFLES作为一个迭代的多组件管道运行，利用中央裁判系统地识别故障，并通过一组专门的评估器检测候选故障和裁判的推理合理性。该方法在多个基准测试中表现良好，特别是在识别多智能体系统中的步骤级故障和诊断数学推理错误方面表现突出。", "conclusion": "实验结果表明，RAFFLES在识别逻辑错误方面表现超过了现有的基线，尤其在“Who&When”数据集和“ReasonEval”数据集中的表现尤为明显。这些结果表明，自动故障检测在自动化系统中引入了自动化的故障检测，减轻了耗时的手动审查任务。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02547", "html_url": "https://arxiv.org/abs/2509.02547", "title": "LLMs的代理强化学习景观：一个综述", "title_en": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey", "authors": "Guibin Zhang,Hejia Geng,Xiaohang Yu,Zhenfei Yin,Zaibin Zhang,Zelin Tan,Heng Zhou,Zhongzhi Li,Xiangyuan Xue,Yijiang Li,Yifan Zhou,Yang Chen,Chen Zhang,Yutao Fan,Zihu Wang,Songtao Huang,Francisco Piedrahita-Velez,Yue Liao,Hongru Wang,Mengyue Yang,Heng Ji,Jun Wang,Shuicheng Yan,Philip Torr,Lei Bai", "background": "代理强化学习（Agentic RL）的出现标志着从大型语言模型强化学习（LLM RL）的传统方法到一种新的范式的转变，即将大型语言模型重新定义为自主、决策性的代理，在复杂、动态的世界中嵌入。本文通过对比LLM RL的退化单步骤马尔可夫决策过程（MDP）和Agentic RL中定义的具时扩展性、部分可观测的马尔可夫决策过程（POMDP），进一步阐述了这一概念转变。", "innovation": "本文提出了一个双重分类法：一是围绕核心代理能力（包括规划、工具使用、记忆、推理、自我改进和感知）分类；二是围绕这些能力在不同任务领域的应用分类。作者认为强化学习是关键机制，使这些能力从静态的启发式模块转变为适应性强、鲁棒性的代理行为。此外，本文还整合了开源环境、基准测试和框架，提供了一篇实用的综述，支持和加速未来的研究。", "conclusion": "本文通过综合分析超过五百篇近期研究工作，勾勒出这一迅速演进领域的轮廓，并突出了将推动大规模、通用人工智能代理发展的机遇和挑战。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09574", "html_url": "https://arxiv.org/abs/2507.09574", "title": "MENTOR: 效率优先的自回归视图生成模型的多模态条件调整", "title_en": "MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models", "authors": "Haozhe Zhao,Zefan Cai,Shuzheng Si,Liang Chen,Jiuxiang Gu,Wen Xiao,Minjia Zhang,Junjie Hu", "background": "最近的文本到图像模型能够生成高质量的结果，但在精确的视觉控制、多模态输入的平衡以及复杂多模态图像生成所需的大规模训练方面仍然存在困难。目前的多模态条件图像生成模型难以实现精细的模态输入与图像输出的精确对齐，通常依赖于辅助适配器或交叉注意模块，这不仅增加了训练复杂度，还延长了训练时间。因此，亟需一种高效的多模态条件调整方法，能够在有限的资源下生成高质量的多模态图像。", "innovation": "本文提出了一种名为MENTOR的新型自回归(AR)框架，这是一种用于高效多模态条件图像生成的自回归模型。MENTOR的特点包括：（1）结合了AR图像生成器和两阶段训练范式，能够在无需依赖辅助适配器或交叉注意力模块的情况下实现多模态输入与图像输出的细粒度、子级对齐；（2）两阶段训练首先是多模态对齐阶段，建立稳健的像素级和语义级对齐，然后是多模态指令调整阶段，平衡多模态输入的整合并提高生成可控性。MENTOR在DreamBench++基准测试中表现出色，尽管模型规模较小、基础组件不佳且训练资源有限，但在概念保持和指令跟随方面优于竞品基线。", "conclusion": "MENTOR通过简单的两阶段训练范式，实现了强大的多模态图像生成性能，并且相比基于扩散的方法，在图像重构精度、任务适应性以及训练效率方面表现出更佳的效果。此外，该方法还提供了可下载的数据集、代码和模型。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14275", "html_url": "https://arxiv.org/abs/2509.14275", "title": "FedMentor：心理健康领域异构联邦大语言模型的领域关联差分隐私", "title_en": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health", "authors": "Nobin Sarwar,Shubhashis Roy Dipta", "background": "在敏感领域（如心理健康）中，隐私保护性的大型语言模型（LLMs）的适应需要平衡严格的秘密性、模型的实用性以及安全性。传统的联邦学习（FL）方法忽略了隐私保护，因此无法满足这一需求。", "innovation": "提出了一种名为FedMentor的联邦微调框架，结合了低秩适应（LoRA）和领域感知差分隐私（DP），以实现每个领域的隐私预算，同时保持性能。每个客户端（领域）根据其数据敏感性应用自定义的DP噪声尺度，并在实用性低于阈值时，服务器会适应性地减少噪声。", "conclusion": "在三项心理健康数据集上进行的实验表明，FedMentor在不牺牲隐私的情况下提高了安全性，提升了安全输出率最高3个百分点，并降低了毒性，同时维持了与非私人基线（BERTScore F1和ROUGE-L）0.5%之内的性能，并接近集中式上限。该框架在最多17亿参数的模型上运行，每轮通信量不到173MB。FedMentor展示了在医疗健康和其他敏感领域安全部署大型语言模型的实用方法。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20697", "html_url": "https://arxiv.org/abs/2508.20697", "title": "Token Buncher: 屏蔽大语言模型免受有害强化学习微调的影响", "title_en": "Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning", "authors": "Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong", "background": "随着大型语言模型（LLMs）能力的增强，通过微调带来的有害滥用风险也在增大。大多数先前的研究假设攻击者依赖监督微调（SFT）来进行这种滥用，而本研究则系统地展示了强化学习（RL）能更有效地破坏安全性对齐，并促使模型执行更高级的有害任务辅助，尤其是在相同的计算预算下。", "innovation": "提出了TokenBuncher，这是首个专门针对基于RL的有害微调的有效防御措施。TokenBuncher通过限制模型响应的熵来抑制RL所依赖的基础，从而阻止基于RL的微调利用不同的奖励信号引导模型执行有害行为。还通过熵作为奖励的RL和Token Noiser机制来防止有害能力的升级。", "conclusion": "实验结果表明，TokenBuncher能够在不损害良性任务性能和微调性的前提下，有效缓解有害的RL微调。结果还强调，基于RL的有害微调带来的系统性风险比SFT更大，而TokenBuncher则提供了一种有效的、通用的防御措施。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15338", "html_url": "https://arxiv.org/abs/2508.15338", "title": "HeartLLM: ECG标记离散化用于基于LLM的诊断推理", "title_en": "HeartLLM: Discretized ECG Tokenization for LLM-Based Diagnostic Reasoning", "authors": "Jinning Yang,Wenjie Sun,Wen Shi", "background": "心电图（ECG）在心血管诊断中起着关键作用，但现有的自动化方法在跨临床任务上难以实现泛化，并且对开放性的推理支持有限。", "innovation": "HeartLLM是一个新颖框架，它通过使大规模语言模型（LLMs）能够处理12导联ECG信号并进行临床文本生成任务，将时间序列（TS）和语言模型结合在一起。此框架通过将连续的ECG嵌入离散化为量化码，并将这些量化码映射到扩展的ECG词汇表以生成ECG标记，实现了ECG和自然语言输入的统一处理。预训练模型完成自回归ECG标记预测任务，利用LLM内在的语言建模能力捕捉时间动态。最终，通过指令调优进行ECG问答和诊断报告生成。在不对核心模型进行修改的情况下，HeartLLM在任务中实现了优异的性能，并且在处理分布外数据时保持了泛化。", "conclusion": "广泛的实验表明每个组件的有效性，并强调将离散化的ECG标记纳入LLM中进行医学推理的潜力。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15969", "html_url": "https://arxiv.org/abs/2509.15969", "title": "VoXtream：超低延迟全流文本转语音", "title_en": "VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency", "authors": "Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze", "background": "当前的文本转语音（Text-to-Speech, TTS）系统通常需要一定时间来准备音频，这导致了初始延迟。尤其是流式实时应用，要求TTS系统的初始延迟尽可能低，以便尽早开始播放语音。现有的流式TTS系统要么需要复杂的预处理，要么无法达到极低的初始延迟。", "innovation": "VoXtream是一个全自回归、零样本的流式TTS系统，能够从第一个词开始立即进行语音输出。系统通过直接将传入的音素映射到音频标记，使用单调对齐方案和有限前瞻而不延迟开始，实现了极低的初始延迟。VoXtream采用增量音素变换器、时间变换器预测语义和持续时间标记，以及深度变换器生成声学标记的结构，从而达到了在公有流式TTS中已知的最低初始延迟：102毫秒（GPU上）。尽管基于中规模9K小时的语料库进行训练，但在多个指标上与更大的基线模型相比，它仍然表现出或超越这些基线模型的表现，同时在输出流式和全流式环境中提供竞争力的语音质量。", "conclusion": "VoXtream达到了前所未有的低初始延迟，在GPU上仅为102毫秒，并且在多个评估指标上与更大规模的基线模型相比具有可比性或优越性，同时保持了高质量的语音输出。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.11808", "html_url": "https://arxiv.org/abs/2508.11808", "title": "标签还是输入？重塑多模态仇恨检测中的增强方法", "title_en": "Labels or Input? Rethinking Augmentation in Multimodal Hate Detection", "authors": "Sahajpreet Singh,Kokil Jaidka,Subhayan Mukerjee", "background": "在线仇恨内容仍然是一个重要的社会挑战，特别是随着多媒体内容的出现，它能够以极其微妙、文化依托和隐含的方式引起伤害。恶搞表情包通过文字-图像交互和幽默来嵌入敌意，这使得自动化系统难以理解。尽管最近的视觉-语言模型（VLMs）在明确的情况下表现出色，但在复杂内容上的持续失败限制了它们的应用。本文探讨了如何通过提示优化、微调和自动数据增强来提升小型模型。我们开发了一个端到端的管道，改变提示结构、标注粒度和训练模式，展示了结构化提示和扩展监督对紧凑型VLM的显著增强。同时，我们还构建了一个多模态增强框架，通过协调的大规模语言模型（LLM）和视觉-语言模型（VLM）的组合生成反事实中性的表情包，减少了虚假关联，提高了隐含仇恨的检测能力。", "innovation": "本文引入了一种端到端的多模态增强框架，通过协调的大规模语言模型（LLM）和视觉-语言模型（VLM）的结合，生成反事实中性的表情包，从而降低虚假相关性，并提高对隐含仇恨内容的检测能力。此外，通过提示优化、结构化提示和扩展监督，显著增强了小型视觉-语言模型的功能，填补了小模型和大模型之间的差距。", "conclusion": "实验结果为更稳健和可部署的多模态仇恨检测系统提供了一条实用路径，无需依赖昂贵的大模型推断。"}
{"llm_update_time": "20260128", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.13968", "html_url": "https://arxiv.org/abs/2508.13968", "title": "RotBench: 评估多模态大语言模型在识别图像旋转方面的表现", "title_en": "RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation", "authors": "Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal", "background": "研究探讨了多模态大语言模型（MLLMs）在识别输入图像旋转角度（0°、90°、180°和270°）方面的准确性。任务要求模型具备强大的视觉推理能力来检测旋转线索并理解图像中的空间关系，而不论图像的方向如何。为此，研究者开发了RotBench基准测试，包含350张生活、肖像和风景图像的手动筛选数据集，用以评估MLLMs在这些能力上的表现。", "innovation": "研究提出了RotBench基准测试，专门用于评估MLLMs在识别图像旋转方面的表现。研究表明，目前最先进的开放源代码和专有MLLMs，如GPT-5、o3、Gemini-2.5-Pro等，在识别输入图像的旋转时表现不稳定，提供辅助信息或使用链式推理提示仅能带来很小且不一致的改进。增强的数据展示方式和投票机制可以改善较弱模型的性能。", "conclusion": "MLLMs在识别图像旋转方面的能力存在显著差距，大多数模型可以可靠地识别直立的（0°）图像，部分模型可以识别倒置的（180°）图像，但无法可靠地区分90°和270°旋转的图像。尽管微调模型在识别180°旋转方面有所提高，但在区分90°和270°旋转方面没有显著提升。这些发现揭示了MLLMs的空间推理能力与人类感知能力之间的差距。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17310", "html_url": "https://arxiv.org/abs/2601.17310", "title": "使用真实世界数据进行高保真纵向患者模拟", "title_en": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "authors": "Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe", "background": "模拟是对不确定性进行探索的强大工具，其在临床医学中的潜力是变革性的，包括个性化治疗规划和虚拟临床试验。然而，模拟患者轨迹极具挑战性，因为受复杂生物学和社会文化因素的影响。已有研究指出，电子健康记录中的真实世界临床资料能够被用来实证建模患者的轨迹。", "innovation": "作者提出了一种生成式模拟器模型，该模型以病人历史为输入，能够合成细粒度且现实的未来轨迹。模型在超过2亿份临床记录上进行了预训练，可以生成高保真的未来时间线，与真实未来病人的事件发生率、实验室检测结果和时间动态相近。此外，模型能准确估计未来事件的可能性，观察到的与预期的比率在不同结果和时间范围内大多接近1.0，展示了真实世界数据在电子健康记录中的潜在价值。", "conclusion": "本研究揭示了电子健康记录中真实世界数据的未开发价值，并提出了一种可扩展的体外临床护理建模框架。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17259", "html_url": "https://arxiv.org/abs/2601.17259", "title": "在扩散采样中的推理时损失导向的颜色保持", "title_en": "Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling", "authors": "Angad Singh Ahuja,Aarush Ram Anandh", "background": "在文本到图像的扩散系统中，精确的颜色控制仍然是一个持续存在的失败模式，尤其是在需要满足明确的用户指定颜色目标的设计导向工作流程中。目前的方法难以确保生成图像的颜色与用户期望完全一致。", "innovation": "作者提出了一种推理时的区域约束颜色保持方法，该方法通过结合（i）基于ROI的填充以实现空间选择性，（ii）背景隐状态重新叠加以防止ROIs之外的颜色漂移，以及（iii）通过构建CIExLab和线性RGB相结合的损失定义来使用的梯度引导实现隐态调整。该损失不仅控制ROI颜色的平均值，还通过CVaR风格和软最大惩罚控制像素误差分布，并使用晚期启动门和时间依赖计划来稳定可视化过程中的指导。", "conclusion": "该方法提供了一种实用的、无需训练的方法，可以确保颜色一致性，适用于标准的稳定扩散填充管道，从而满足目标颜色要求，避免感知上的局部失败，强调了分布感知目标的重要性。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17374", "html_url": "https://arxiv.org/abs/2601.17374", "title": "生成先验下贝叶斯反问题的误差分析", "title_en": "Error Analysis of Bayesian Inverse Problems with Generative Priors", "authors": "Bamdad Hosseini,Ziqi Huang", "background": "近年来，借助机器学习技术的发展，数据驱动的方法在解决逆问题方面变得非常流行。其中一种常用方法是通过在额外数据上训练生成模型来学习特定的先验。这篇论文旨在通过定量误差界来分析此类问题，特别是在最小 Wasserstein-2 生成模型作为先验下的后验误差。", "innovation": "本文提出了最小 Wasserstein-2 生成模型作为先验下后验误差的量化误差界分析。研究表明，在某些假设下，由于生成先验引起的后验误差在 Wasserstein-1 距离下的误差率与先验相同。同时，通过数值实验验证了这一误差分析的某些方面，并在椭圆偏微分方程的反问题中展示了生成先验的应用。", "conclusion": "本文分析了使用生成先验的贝叶斯反问题，并给出了最小 Wasserstein-2 生成模型的先验下后验误差的定量误差界。验证了通过生成先验可以有效建模非平稳场，并且相对于先验在 Wasserstein-1 距离下的误差率一致。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17438", "html_url": "https://arxiv.org/abs/2601.17438", "title": "UniGRec：使用软标识实现端到端优化的统一生成性推荐", "title_en": "UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization", "authors": "Jialei Li,Yang Zhang,Yimeng Bai,Shuai Zhu,Ziqi Xue,Xiaoyan Zhao,Dingxian Wang,Frank Yang,Andrew Rabinovich,Xiangnan He", "background": "生成性推荐作为一项新兴的范式，能够直接生成目标项，优于传统的级联方法。这种推荐方法包含两个组件：一个是学习项目标识的学习器，另一个是基于这些标识的推荐器。现有方法常常分离了标记化与推荐，或者依赖异步交替优化，限制了端到端的完全对齐。", "innovation": "提出了一种统一的生成推荐框架UniGRec，该框架通过不同的可微软项标识统一标记器和推荐器，实现了端到端的联合训练。为解决由此引入的三个挑战，包括训练推理不一致性、标识符坍缩以及协同信号不足等问题，UniGRec采用了退火推理对齐、均匀编码词正则化以及双重协同蒸馏机制。", "conclusion": "在实际数据集上的大量实验表明，UniGRec在端到端优化方面的一致性超过了最先进的基线方法。相关代码已公开。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17295", "html_url": "https://arxiv.org/abs/2601.17295", "title": "结构意识下的NL到SQL转换：基于AST掩蔽增强语言模型的SFC配置", "title_en": "Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models", "authors": "Xinyu Zhu,Parisa Fard Moshiri,Poonam Lohan,Burak Kantarci,Emil Janulewicz", "background": "在动态且需要低延迟的网络环境中，有效的服务功能链（SFC）配置需要精确的编排。强化学习（RL）虽然提高了适应性，但往往会忽视专业知识，限制了其泛化能力和可解释性。大型语言模型（LLMs）通过将自然语言（NL）规范转换为可执行的结构化查询语言（SQL）命令，解决了这一问题，特别适用于面向规范的SFC管理。然而，传统的微调方法可能引入语法不一致的问题，并生成效率低下的查询。", "innovation": "我们提出了基于抽象语法树（AST）掩蔽的结构意识微调方法，这种方法利用SQL ASTs对关键组件进行权值赋予，并在不增加推理开销的情况下强制实施语法感知学习，从而克服了传统的结构不一致和效率低下的问题。", "conclusion": "实验结果表明，AST掩蔽显著提高了多种语言模型的SQL生成准确性。FLAN-T5达到了99.6%的执行准确性，而Gemma从7.5%的增益达到了72.0%的最大绝对增益。这些结果证实了结构意识微调在确保语法正确且高效的SQL生成对于解释性SFC编排的有效性。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17443", "html_url": "https://arxiv.org/abs/2601.17443", "title": "集群驱动的记忆压缩技术在本地大语言模型中的应用", "title_en": "Clustering-driven Memory Compression for On-device Large Language Models", "authors": "Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli", "background": "大型语言模型（LLMs）通常依赖于从过去的交互中提炼出的用户特定记忆来实现个性化生成。现有的方法通常是将这些记忆与输入提示连接起来，但这种方法很快就会消耗掉本地设备LLMs有限的上下文空间。通过记忆压缩，特别是通过平均化来减少上下文增长，但在异构记忆之间产生语义冲突时，这种方法往往会降低性能。", "innovation": "我们提出了一个基于聚类的记忆压缩策略，该策略在上下文效率和个性化质量之间实现平衡。该方法通过相似性对记忆进行分组，并在连接之前在同一簇内合并它们，这样既可以保持连贯性，又可以减少冗余。实验表明，我们提出的方法在保留上下文字数的同时，还优于诸如朴素平均或直接连接等基线策略，特别是在固定上下文预算的情况下，这种集群驱动的合并可以生成更加紧凑的记忆表示，从而提升生成质量。", "conclusion": "我们的方法显著降低了记忆令牌的数量并优于基本策略。在固定上下文预算下，基于聚类的合并生成更紧凑的记忆表示，并且能够持续提高生成质量。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17442", "html_url": "https://arxiv.org/abs/2601.17442", "title": "NARXESNs模型类选择与参数学习的新方法", "title_en": "A new approach for combined model class selection and parameters learning for auto-regressive neural models", "authors": "Corrado Sgadari,Alessio La Bella,Marcello Farina", "background": "本文提出了一种新的方法，用于非线性动态系统的模型结构选取和参数学习的联合选择。该方法集中在特定的递归神经网络（RNNs）家族，即具有回声状态网络（Echo State Networks，ESN）特性的非线性自回归模型（Nonlinear Auto-Regressive with eXogenous inputs NARXESNs）。该方法通过一种新的集合成员（set-membership SM）基于的程序同时选择最优模型类别并从数据中学习模型参数。研究表明，该方法在识别简洁而准确的模型方面有效，并且这些模型适用于控制应用。这种方法能增强模型的鲁棒性。", "innovation": "提出了一种结合模型类选择和参数学习的新方法，使用NARXESNs模型，并通过集合成员（set-membership）方法进行参数学习，旨在同时优化模型的结构和参数，以有效地识别和优化模型。该方法提供了一种鲁棒的训练策略，能够有效地处理有界度量噪声，并在参数学习过程中通过数据一致的方法评估模拟性能，通常复杂的模型具有自回归特性。", "conclusion": "该方法在实验中证明了其有效性和鲁棒性，能够生成适用于控制应用的精简但准确的模型。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17378", "html_url": "https://arxiv.org/abs/2601.17378", "title": "Res-MIA：联邦学习模型基于分辨率的无训练成员推断攻击", "title_en": "Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models", "authors": "Mohammad Zare,Pirooz Shamsinejadbabaki", "background": "会员推断攻击（MIAs）通过允许对手确定特定数据样本是否包含在训练集中，对机器学习模型构成了严重隐私威胁。尽管联邦学习（FL）因其分散特性被认为是一种隐私意识训练范式，但最近的证据表明，即使采用黑盒访问，最终的全局模型仍然会泄露敏感的会员信息。", "innovation": "Res-MIA 是一种新颖的无需训练且黑盒的会员推断攻击，它利用深层模型对高频输入细节的高度敏感性。通过逐步使用控制下的下采样和恢复操作降低输入分辨率，并分析模型预测结果中的置信度衰减。关键洞见在于，训练样本在分辨率侵蚀下表现出比非会员样本更为显著的置信度急剧下降，揭示了一种稳健的会员推断信号。Res-MIA 不需要影子模型、辅助数据，并且只需对目标模型进行有限数量的前向查询。", "conclusion": "我们在联邦学习中的 ResNet-18 模型（基于CIFAR-10数据集）上评估了该攻击，发现其在计算开销最小的情况下，始终优于现有的无训练基准，AUC最高可达 0.88。这些发现突出了频率敏感过拟合作为联邦学习中隐私泄露重要且未被充分探索的来源，并强调了减少对精细粒度、不稳健输入特征依赖的隐私意识模型设计的必要性。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17230", "html_url": "https://arxiv.org/abs/2601.17230", "title": "CaseFacts：法律事实核查和先例检索基准", "title_en": "CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval", "authors": "Akshith Reddy Putta,Jacob Devasier,Chengkai Li", "background": "自动化事实核查主要关注验证一般知识与静态语料库之间的关系，而忽视了法律这样的高风险领域，其中真理是不断演进且技术复杂的。现有的资源将形式文本映射为形式文本，但CaseFacts平台通过多阶段管道流程利用大型语言模型从专家案例摘要中合成主张，构建了一个基准，旨在验证口语化法律主张与美国最高法院先例之间的事实关系，并考虑时间有效性。", "innovation": "CaseFacts提出了一个新的基准，用于验证口语化法律主张与美国最高法院判例之间的关系，挑战系统跨越普通人主张与技术性法律判例之间的语义鸿沟，同时考虑时效性。通过不借助额外网络搜索的方式增加了任务的难度，并且首次展示了构建这样大规模法律判例数据集的方法。", "conclusion": "实验表明，即使是先进的人工智能模型在这一任务上仍然具有挑战性。接入无限制的网络搜索反而降低了性能，因为检索到的往往是不权威的先例。为此，作者发布了CaseFacts数据集，旨在推动法律事实核查和系统的研究。"}
{"llm_update_time": "20260128", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2601.17222", "html_url": "https://arxiv.org/abs/2601.17222", "title": "提升光谱红移模型的一般化和不确定性量化", "title_en": "Improving Generalization and Uncertainty Quantification of Photometric Redshift Models", "authors": "Jonathan Soriano,Tuan Do,Srinath Saikrishnan,Vikram Seenivasan,Bernie Boscoe,Jack Singal,Evan Jones", "background": "精确的红移估计在理解星系演化和精确宇宙学中至关重要。本文探讨了如何通过机器学习模型提高光谱红移估计的适用性，以便对更广泛的星系类型进行估计。传统模型通常使用光谱红移数据训练，但限制了其适用范围。文章通过结合光谱红移和多波段（约35个滤镜）光度学红移数据（两种类型星系不同）来测试两种方法：复合数据集训练和从一个数据集到另一个的迁移学习。选定的光度学红移数据来自COSMOS2020目录（TransferZ），补充了一个既有的光谱红移数据集（GalaxiesML）。使用了确定性神经网络（NN）和贝叶斯神经网络（BNN）两种架构，考察其性能，并利用split conformal预测对BNN和NN的不确定性估计进行校准。", "innovation": "本文提出了两种提高光谱红移模型适用性和不确定度量化的方法：复合数据集训练和迁移学习。通过比较仅使用光谱红移数据训练的模型与以上两种方法的性能，发现NN在红移范围内0.3<z<1.5的偏差、散射和异常率分别为四分之一、十分之一和四分之一。BNN虽然提供了可靠的不确定性估计，但对于不同数据集的性能敏感。", "conclusion": "本研究通过结合不同来源的真实数据，发展出了能够更准确预测更广泛星系样本光谱红移的模型，对Euclid和LSST等此类调查至关重要。"}
