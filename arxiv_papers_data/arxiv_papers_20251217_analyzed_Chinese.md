# 20251217
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - AGAPI-Agents: 一个基于AtomGPT.org的开源自主人工智能平台，加速材料设计 [PDF](https://arxiv.org/pdf/2512.11935), [HTML](https://arxiv.org/abs/2512.11935)
### Authors
Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary
### Background
尽管人工智能正在重塑科学发现，但在材料研究中的应用仍受到计算生态系统碎片化、重复性挑战和对商业大型语言模型的依赖的限制。
### Innovation
提出一个名为AGAPI的开源自主人工智能平台，该平台整合了多个开源大型语言模型和材料科学API端点，通过统一的编排框架实现数据库、模拟工具和机器学习模型的整合，并采用Agent-Planner-Executor-Summarizer架构自主构建和执行涉及多种材料数据检索、图神经网络性质预测、机器学习力场优化、紧束缚计算、衍射分析和逆设计的多步骤工作流。
### Conclusion
AGAPI 提供了一个可扩展且透明的基础，用于推动可重复、AI加速的材料发现。AGAPI 的代码库在AtomGPT.org上可供超过 1,000 名活跃用户使用。
## 2. `cs.AI` - 概率模型对于低质量数据的健壮性：多视角分析 [PDF](https://arxiv.org/pdf/2512.11912), [HTML](https://arxiv.org/abs/2512.11912)
### Authors
Liu Peng,Yaochu Jin
### Background
本文系统性地比较了现代概率模型在低质量数据下的效应，揭示了这些模型在不同条件下的稳健性差异。研究表明，自回归语言模型在面对50%的标记污染时，依然表现出较强的抗扰能力（GPT-2测试负对数似然值从2.87增加到3.59）。相比之下，在相同程度的数据污染下，类别条件扩散模型表现极为糟糕（图像标签一致性下降了56.81%），而分类器则表现适中，且随数据集规模增大而减弱。
### Innovation
本文通过将信息理论、PAC学习和梯度动力学整合来多维度分析这些差异，揭示了模型抵御低质量数据的能力与两大关键原则密切相关：丰富的条件信息量能够限制学习问题，而训练数据中的绝对信息内容则使得正确信息的信号能够主导统计噪声。
### Conclusion
研究结果表明，不同概率模型在面对低质量数据时的稳健性表现各异，主要机制包括条件信息的丰富性和训练数据的信息内容。
## 3. `cs.AI` - 使用大型语言模型进行日志异常检测的知识增强融合 [PDF](https://arxiv.org/pdf/2512.11997), [HTML](https://arxiv.org/abs/2512.11997)
### Authors
Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee
### Background
系统日志对于监控和管理分布式系统至关重要，提供了有关故障和异常行为的见解。传统日志分析技术，如基于模板和序列驱动的方法，通常会丢失重要的语义信息或难以处理模糊的日志模式。
### Innovation
我们提出了一个无需训练、基于入口的日志异常检测框架EnrichLog，通过将语境信息（包括历史示例和从语境中推导出的推理）融入其中，增强原始日志条目中的语境知识，从而实现更准确且可解释的异常检测。该框架利用检索增强生成技术，无需重新训练即可整合相关语境知识。
### Conclusion
我们通过四个大规模系统日志基准数据集评估了EnrichLog，并与五种基线方法进行了比较。结果显示，EnrichLog在异常检测性能方面始终表现优越，能够有效处理模糊日志条目，保持高效推理。结合语境特异性知识和样本特异性知识可提升模型的置信度和检测准确性，使EnrichLog适用于实际部署。
## 4. `cs.AI` - 使用日历约束的工序顺序和累积资源约束并行机调度求解 [PDF](https://arxiv.org/pdf/2512.11864), [HTML](https://arxiv.org/abs/2512.11864)
### Authors
Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter
### Background
在大多数工业制造领域，找到高效的生产排程是一个挑战，特别是对于现代大型工厂而言，通过自动化排程技术来减少生产成本具有巨大的潜力。在过去的研究中，已经对多种机器调度问题进行了研究，即使是最基本的变种也被证明是NP难问题。然而，在当今的实际生产环境中，额外的复杂前置顺序约束和基于日历的资源限制等需要满足的要求出现了，这些约束目前无法得到有效解决。因此，迫切需要开发和分析能够解决这些实际应用场景中的并行机调度问题的自动化方法。
### Innovation
本文提出了一种新的并行机调度变种，它包含工序间的前置顺序和基于日历的累积资源约束。为了解决小型排程案例，提出了一种约束建模方法和最先进的约束求解技术。此外，还提出了一种构建启发式方法和一种量身定制的基于局部搜索的元启发式方法，以有效地解决大型规模的排程问题实例。这种方法已被部署并在一个实际工业环境中使用。
### Conclusion
本文通过对包含工序顺序和基于日历的累积资源约束的并行机调度问题的研究，提出了一套包括精确求解方法和高效求解大型问题实例的方法。所提出的方法已经在实际工业环境中得到应用。
## 5. `cs.AI` - 因果强度与漏斗信念：通过诺伊西-OR因果贝叶斯网解释LLM推理 [PDF](https://arxiv.org/pdf/2512.11909), [HTML](https://arxiv.org/abs/2512.11909)
### Authors
Hanna Dettki
### Background
关于人类和机器智能的本质，长久以来都是一个悬而未决的问题。尽管没有一种普遍接受的定义，但因果推理的能力常被视为智能的关键方面之一。因此，对比LLM和人类在同一任务上的因果推理能力，可以提供对其优缺点的更全面理解。
### Innovation
本研究通过评估20多种LLM在由碰撞图（$C_1to E /leftarrow C_2$）形式化的11个语义上有意义的因果任务上的因果推理能力，探讨了LLM与人类的对齐情况、因果推理一致性以及各自的推理特征。采用直接（直接作答）和链式思维（CoT，思考后作答）两种方式，并通过漏斗NOISY-OR因果贝叶斯网（CBN）模型对判断进行建模，参数$theta=(b,m_1,m_2,p(C))$包括共享先验$p(C)$，选择模型通过AIC方法判断三参对称因果强度（$m_1=m_2$）与四参非对称（$m_1eq m_2$）变种。
### Conclusion
研究结果表明，LLM在因果推理任务上与人类有相似的模式，但在某些情况下表现出不同的推理特征。通过因果贝叶斯网模型的分析，可以更清晰地理解LLM的推理机制，提供对其因果推理能力的洞见。
## 6. `cs.AI` - 基于莱布尼兹单子论的法条架构用于大型语言模型的人工年龄分数(AAS) [PDF](https://arxiv.org/pdf/2512.11835), [HTML](https://arxiv.org/abs/2512.11835)
### Authors
Seyma Yaman Kayadibi
### Background
大型语言模型（LLMs）通常作为强大的但不透明的系统部署，这让人们对其内部记忆和‘自身体’行为应该如何在原则性和可追溯性方面进行治理的方法不够清楚。因此，本文在之前介绍并经过数学证明的人工记忆退化度量（AAS）基础上，开发了一种基于法条的、以语句为基础的架构，以此对LLM的记忆和控制进行法律般的约束。
### Innovation
本文提出了一个基于莱布尼兹单子论的法条架构，通过将20个选定的莱布尼兹单子分组为六个模块，并构建在AAS内核之上的可执行规范，实现了对LLM的约束。通过六个最小的Python实现，这些语句家族在数值实验中被具体化为诸如召回分数、冗余和权重等通道级别量的表现形式。实验表明，该架构使得AAS轨迹保持连续且速度受限，矛盾和缺乏证据的主张触发明确的惩罚，并通过层次细化揭示出有机结构。
### Conclusion
基于AAS的单子法条框架通过提供透明的代码级蓝图，约束和分析人工智能代理的内部动力学。具体体现了法哲学动机基础上的直接可实现性，通过和谐术语调整双重视图和目标行动对，并在理想分数的窗中分离持续改进与持续退化，展示了法条系统的有界和可解释的行为。
## 7. `cs.AI` - 结构化个性化建模，将约束表示为偏序集以实现数据最少的大型语言模型代理 [PDF](https://arxiv.org/pdf/2512.11907), [HTML](https://arxiv.org/abs/2512.11907)
### Authors
Daniel Platnick,Marjan Alirezaie,Hossein Rahnama
### Background
个人化大型语言模型（LLM）代理需要通过用户特定数据对其进行条件性设置，这在提高任务实用性的同时还存在数据泄露的风险。用户数据的附加价值通常会逐渐下降（即递减性质），导致近似贪婪选择的有效性，但在实际应用场景中，个性化过程受到了结构约束的影响，如逻辑依赖关系、类别限额和层级规则。这些约束破坏了标准子集选择算法的基本假设。
### Innovation
提出了一个原则性的方法来正式建模这些约束。《论文》引入了一个编译过程，将用户的包含依赖关系的知识图转换成宏观特征的集合。核心成果是证明了在这些宏观特征上常见的层级约束和配额约束形成了有效的分层偏序集。这一理论特征使得将结构化个性化任务转换为在基序约束下的亚模最大化问题，进而通过贪婪算法和连续贪婪算法可以提供恒定因子保证和(1-1/e)的近似保证，适用于更为丰富和现实的问题类别。
### Conclusion
《论文》提供了在存在复杂约束的情况下，大型语言模型代理的有效个人化方法，通过将约束转化为偏序集的形式，使得能够利用理论公式化实现更高效的亚模最大化算法，并在数据最小化的前提下实现个性化目标。
## 8. `cs.AI` - Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning [PDF](https://arxiv.org/pdf/2512.11902), [HTML](https://arxiv.org/abs/2512.11902)
### Authors
Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat
### Background
在回合制游戏中，敌人的策略应该令人惊讶且不可预测。为挑战玩家，提出了一种名为Mirror Mode的新游戏模式，其中敌方AI模仿玩家个人策略。Unity中构建了一个简化版的Nintendo策略视频游戏《火焰之纹章heroes》，其中包含标准模式和Mirror Mode。
### Innovation
研究提出了一种新的游戏模式Mirror Mode，其中敌方AI模仿玩家个人策略。实验利用Reinforcement Learning和Imitation Learning结合使用Generative Adversarial Imitation Learning、Behavioral Cloning和Proximal Policy Optimization建立了一个合适的模型，用于模仿玩家的行为。研究还评估了模型在参与者测试中的表现。
### Conclusion
实验结果显示，玩家在防御行为中的模仿表现良好，但在进攻策略方面不尽如人意。参与者调查表明，他们能够识别自己的撤退战术，整体而言，Mirror Mode提高了玩家满意度。进一步优化模型可能会提高模仿质量并增加玩家的满意度，特别是在玩家面对自己的策略时。
## 9. `cs.AI` - 超博弈理性化：解决智能体错位的战略玩法 [PDF](https://arxiv.org/pdf/2512.11942), [HTML](https://arxiv.org/abs/2512.11942)
### Authors
Vince Trencsenyi
### Background
不同的感知、信息不对称和有限理性使博弈论玩家对游戏形成私有的主观视角，这些视角可能与底层真实场景不同且可能与其他玩家的理解不一致。典型博弈论假设往往忽视这种异质性，而超博弈理论提供了处理这种错误认知模型的数学框架。尽管超博弈最近在涉及不确定性动态应用中受到了关注，但在多智能体系统研究中的实际应用受到缺乏统一、形式化和实用的编码语言的阻碍，同时缺乏处理复杂超博弈结构和均衡的可扩展算法。
### Innovation
本文通过引入一种基于逻辑的、声明式的领域特定语言来编码超博弈结构和超博弈解决方案概念，利用回答集编程开发了一个自动化流程，用于实例化超博弈结构并运行新的超博弈理性化程序，这为找到解释看似不合理结果的信任结构提供了机制。提出的新语言为超博弈建立了一个统一的形式主义，并为开发基于信念的复杂多样的推理器奠定了基础，提供了一个具有逻辑保证的可验证上下文。
### Conclusion
本文的工作建立了超博弈理论、多智能体系统和战略人工智能之间的联系，通过提供一种统一的形式化方法和一种可验证且具有逻辑保证的上下文，填补了超博弈结构和解决方案表示的空白，同时提出了新的算法来处理复杂的超博弈结构和均衡。
## 10. `cs.AI` - CXL-SpecKV: 数据中心大型语言模型服务的分解 FPGA 预测式 KV 缓存 [PDF](https://arxiv.org/pdf/2512.11920), [HTML](https://arxiv.org/abs/2512.11920)
### Authors
Dong Liu,Yanxuan Yu
### Background
大型语言模型（LLMs）在自然语言处理任务中取得了革命性的进展，但在数据中心环境中部署时面临着巨大的挑战，主要是由于关键值（KV）缓存所需的大量内存需求。在自回归解码过程中，KV缓存消耗了大量的GPU内存，这限制了批量大小和整个系统的吞吐量。
### Innovation
我们提出了一种名为CXL-SpecKV的新颖分解KV缓存架构，该架构利用Compute Express Link (CXL)互连和FPGA加速器来实现高效的推测执行和内存分解。我们的方法包括三个关键创新点：(i) 基于CXL的内存分解框架，将KV缓存卸载到远程FPGA内存，具有低延迟；(ii) 预测式KV缓存预取机制，预测并预加载未来token的缓存条目；(iii) FPGA加速的KV缓存压缩和解压缩引擎，通过多达4倍的减少内存带宽需求。
### Conclusion
我们的系统证明了智能内存分解与推测执行的有效结合可以在大规模LLM服务中有效地解决内存墙挑战。与仅使用GPU的基线相比，CXL-SpecKV在最先进的LLM模型上实现了高达3.2倍的吞吐量，同时减少了2.8倍的内存成本并保持了准确性。
## 11. `cs.AI` - MedCEG：使用关键证据图强化可验证医疗推理 [PDF](https://arxiv.org/pdf/2512.13510), [HTML](https://arxiv.org/abs/2512.13510)
### Authors
Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang
### Background
大型语言模型在多个领域展现出卓越性能。在临床应用中，透明且逐步的推理过程能为医生提供有力证据支持决策。尽管强化学习在提升医疗推理方面取得成功，但这类推理过程在临床中的可靠性仍有限，因为其准确性和有效性往往未能在训练过程中得到足够关注。
### Innovation
我们提出了一种名为MedCEG的框架，通过显式监督推理过程中的临床有效推理路径，增强医疗语言模型的推理能力。MedCEG利用关键证据图（CEG）构造数据集中的每个案例的高质量可验证推理路径，并引入临床推理程序奖励，评估节点覆盖、结构正确性和链完整度，从而提供整体推理质量评估。
### Conclusion
实验证明，MedCEG 在性能上超越现有方法并生成了临床有效的推理链，这代表了可靠医疗AI推理的一大进步。相关代码和模型已发布。
## 12. `cs.AI` - 极权主义技术：医疗保健中AI速记员的隐藏成本 [PDF](https://arxiv.org/pdf/2512.11814), [HTML](https://arxiv.org/abs/2512.11814)
### Authors
Hugh Brosnahan
### Background
讨论了人工智能（AI）速记系统在医疗保健中的应用，这些系统能够记录并总结患者与医护人员的互动，被宣传为解决行政负担的解决方案。然而，文章认为其重要性不在于效率提升，而在于它们如何重塑医疗服务本身。
### Innovation
文章从概念分析的角度出发，将AI速记系统置于更广泛的哲学背景中讨论，特别是Iain McGilchrist的大脑半球理论和Lewis Mumford的技术哲学。透过这两种理论，文章考察了技术如何体现和放大特定的注意力模式。
### Conclusion
文章指出，AI速记系统体现了左半球计算思维的主导地位，这种思维强调可测量性和程序性而非直觉性和关系性。随着这种注意力模式在医疗实践中进一步固化，医疗关怀的范畴可能会变得狭窄，临床专业知识也会受到侵蚀，医生可能会被塑造为机械化系统中的操作员。
## 13. `cs.AI` - 一个多任务VAE用于时间序列预处理和血糖水平预测 [PDF](https://arxiv.org/pdf/2410.00015), [HTML](https://arxiv.org/abs/2410.00015)
### Authors
Ali AbuSaleh,Mehdi Rahim
### Background
时间序列数据预处理是数据分析的关键部分。连接的医疗设备采集的数据常常存在缺失或异常值情况，这需要额外的假设和专业知识来处理。这些处理可能导致时间消耗且引入显著偏差，影响预测模型的准确性及临床解释。
### Innovation
提出了一种新的深度学习模型来减少预处理假设。该模型架构依赖于变分自编码器（VAE）生成预处理潜空间，并且通过递归VAE保留数据的时间动态。
### Conclusion
该方法在远程监测数据上用于预测糖尿病患者的血糖水平，结果显示在准确度上优于现有最先进的方法和架构。
## 14. `cs.AI` - 可微进化强化学习 [PDF](https://arxiv.org/pdf/2512.13399), [HTML](https://arxiv.org/abs/2512.13399)
### Authors
Sitao Cheng,Tianle Li,Xuhan Huang,Xunjian Yin,Difan Zou
### Background
在强化学习(强化学习)中设计有效的奖励函数是一个核心且难以解决的挑战，尤其是在开发复杂推理任务的自主代理时。虽然已经存在自动奖励优化方法，但它们通常依赖于无导数的进化启发式算法，将奖励函数视为黑盒，无法捕捉奖励结构与任务性能之间的因果关系。
### Innovation
我们提出了一个新的双层框架——可微进化强化学习(DERL)，它通过组成结构化的原子原语来自主发现最优的奖励信号。与之前的进化方法不同，DERL在元优化中是可微的，通过强化学习信号更新元优化器来逼近任务成功的“元梯度”。实验结果表明，DERL在ALFWorld和ScienceWorld中达到了最先进的性能，显著优于依赖启发式奖励的方法，特别是超出数据分布的情况下。
### Conclusion
对进化轨迹的分析表明，DERL成功捕捉了任务的内在结构，无需人类干预，实现了自主改进的代理对齐。
## 15. `cs.AI` - 形而上学的和谐失调假设：AI引发的妄想性观念作为Technological folie a deux [PDF](https://arxiv.org/pdf/2512.11818), [HTML](https://arxiv.org/abs/2512.11818)
### Authors
Izabela Lipinska,Hugh Brosnahan
### Background
本文探讨了当代大型语言模型（LLMs）如何通过生成类似于folie a deux的关系动态来参与精神病理过程。通过借鉴巴特森的双重困境理论、临床关于共享精神病态的文献以及麦金克里斯的半球理论，文章分析了高语言连贯性与缺乏主体性之间的结构性张力如何在情感需求或心理不稳定的背景下促使用户通过想象投射，将内部性、意图或存在赋予一个实际上不具备这些特性的系统。
### Innovation
本文创新性地将AI技术与精神病理联系起来，提出了'Technological folie a deux'的概念，利用多重理论来解释现代LLMs如何引发类似的妄想性观念。同时，文章认为当前以增强用户参与为目标的设计选择可能加剧了这种风险，并提出了'形而上学诚实'作为缓解这种现象的设计原则。
### Conclusion
最终，本文提出'形而上学诚实'作为减轻技术中介下Technological folie a deux的关键设计原则，并呼吁在设计过程中要保持真实性和透明性。
## 16. `cs.AI` - 大型语言模型在组合优化中的行为与表示：从特征提取到算法选择 [PDF](https://arxiv.org/pdf/2512.13374), [HTML](https://arxiv.org/abs/2512.13374)
### Authors
Francesca Da Ros,Luca Di Gaspero,Kevin Roitero
### Background
最近，大型语言模型（LLMs）在优化自动化方面开启了新的视角。尽管已有研究探讨了LLMs生成或解决优化模型的能力，但它们如何学习问题结构或算法行为仍不明确。这项研究旨在探索LLMs如何内部表示组合优化问题，以及这种表示是否能支持决策任务。
### Innovation
研究采用了一种两步法，结合直接查询和探针分析。直接查询评估语言模型提取实例特征的能力，探针分析则检查这种信息是否隐含地编码在隐藏层中。研究进一步扩展了探针框架，用于每实例的算法选择任务，评估从LLMs中获得的表示是否能预测最有效的求解器。
### Conclusion
实验表明，LLMs在通过直接查询或探针从问题实例中提取特征信息方面表现出中等的能力。值得注意的是，通过LLMs隐藏层表征的预测能力与传统特征提取方法相当，表明LLMs捕捉到了对优化性能有意义的结构信息。
## 17. `cs.AI` - EMNLP: 教师角色道德和规范大型语言模型画像 [PDF](https://arxiv.org/pdf/2508.15250), [HTML](https://arxiv.org/abs/2508.15250)
### Authors
Yilin Jiang,Mingzi Zhang,Sheng Jin,Zengyi Yu,Xiangjie Kong,Binghao Tu
### Background
Simulating Professions (SP) 让大型语言模型（LLMs）能够模拟专业角色。然而，在这些背景下缺乏全面的心理学和伦理评价。
### Innovation
EMNLP 是一个基于教师角色的道德和规范大型语言模型画像框架，用于个性画像、道德发展阶段测量和伦理风险评估。它扩展了现有量表并构建了88个教师特定道德困境，使其能够针对职业进行人类教师的比较。它还通过特定的软提示注入集评估教师角色LLMs在道德规范下的合规性和脆弱性。
### Conclusion
实验证明，在教师角色方面，LLMs表现出比人类教师更具理想化和极化的性格特征，擅长抽象的道德推理，但在情感上复杂的情况中却表现不佳。更强的推理能力使模型更容易受到有害提示的注入影响，揭示了能力和安全之间的悖论。模型温度和其他超参数对风险行为的影响有限。该论文提出了一项基准测试，以评估教育AI中教师角色LLMs的伦理和心理一致性。
## 18. `cs.AI` - 神经FOMO: 大型语言模型能在第二名时应对吗？多智能体环境中嫉妒倾向的测量 [PDF](https://arxiv.org/pdf/2512.13481), [HTML](https://arxiv.org/abs/2512.13481)
### Authors
Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar
### Background
嫉妒是一种常见的人类行为，会影响竞争性并改变团队设置的结果。随着大型语言模型（LLMs）越来越多地代表人类参与协作和竞争流程，评估它们是否会在某些条件下表现出类似嫉妒的偏好变得紧迫。本文旨在测试LLMs是否互相表现出类似嫉妒的行为，并考虑了两种场景：（1）点分配游戏，测试模型是否试图超越其同僚；（2）工作场所情境，观察当认可不公时的行为。研究发现某些LLMs表现出一致的类似嫉妒的模式，但不同模型和背景下的表现差异很大。
### Innovation
本文创新点在于通过两种情景（点分配游戏与工作场所情境）测试了LLMs在多智能体设置中的类似嫉妒行为，揭示了不同模型间的差异。
### Conclusion
研究结果强调在基于LLM的多智能体系统中需要考虑竞争性倾向的安全性和设计因素。
## 19. `cs.AI` - 通过LLM引导的注意力增强城市视觉地名识别以提升众包洪水影像 [PDF](https://arxiv.org/pdf/2512.11811), [HTML](https://arxiv.org/abs/2512.11811)
### Authors
Fengyi Xu,Jun Ma,Waishan Qiu,Cui Guo
### Background
社交媒体上的街景图像对城市洪涝和其他危机事件的实时视觉证据提供了宝贵的参考，但由于缺乏可靠的地理元数据，往往不适合紧急响应。现有的视觉位置识别（VPR）模型应用于此类图像时，由于视觉失真和跨源的领域转移问题，展现出了显著的性能下降。
### Innovation
本文提出了VPR-AttLLM，一种模型无关的框架，通过注意力指导描述符增强方式将大型语言模型（LLMs）的语义推理和地理空间知识整合到现有的VPR管道中。通过利用LLMs识别城市背景下具有位置信息的区域并抑制时间视觉噪点，VPR-AttLLM能够提升检索性能，而无需重新训练模型或额外的数据。该研究在包括SF-XL、合成洪水场景、Mapillary照片以及新的HK-URBAN数据集的扩展基准上进行了全面评估，且与三种最先进的VPR模型——CosPlace、EigenPlaces和SALAD——结合使用时，一致提高了召回率，平均提升在1-3%，最高达到8%。
### Conclusion
该研究不仅仅在检索准确性方面取得了可测量的提升，还确立了LLM引导的多模态融合在视觉检索系统的普遍范式。通过将城市感知理论原理嵌入注意力机制中，VPR-AttLLM实现了人类似的空间推理与现代VPR架构的集成。其即插即用的设计、强大的跨源鲁棒性以及可解释性表明了其在大规模城市监控和众包危机图像地理定位中的潜在应用。
## 20. `cs.CL` - 语言模型能否发现标度律？ [PDF](https://arxiv.org/pdf/2507.21184), [HTML](https://arxiv.org/abs/2507.21184)
### Authors
Haowei Lin,Haotian Ye,Wenzheng Feng,Quzhe Huang,Yujun Li,Hubert Lim,Zhengrui Li,Xiangyu Wang,Jianzhu Ma,James Zou,Yitao Liang
### Background
大规模语言模型性能预测的标度律发现是一项基础但尚未完全解决的挑战，主要依赖于缓慢的人类案例特定实验。这项研究旨在通过收集超过5000个现有文献中的实验，发现语言模型是否可以自动化这一过程，从而可能改变传统的研究方式。
### Innovation
提出了一种基于演化的方法，即SLDAgent，它能够同时优化标度律模型和参数，使其能够自主探索变量之间的复杂关系。该研究首次展示了SLDAgent能够自动发现准确度更高且跨任务一致的标度律，优于现有的手工构建的标度律。
### Conclusion
这项工作确立了新的自主科学发现范式，表明人工智能系统可以理解它们自身的标度行为，并可以为研究社区贡献新颖和实用的知识。
## 21. `cs.CL` - 使用神经符号方法实现LLMs可靠证明生成 [PDF](https://arxiv.org/pdf/2505.14479), [HTML](https://arxiv.org/abs/2505.14479)
### Authors
Oren Sultan,Eitan Stern,Dafna Shahaf
### Background
大型语言模型（LLMs）在涉及严格逻辑推理和符号推理的正式领域中表现不佳，例如数学证明生成。通过结合LLMs的生成优势和结构化组件，提出了一种神经符号方法以应对这一挑战。
### Innovation
提出了一种两步方法：（1）检索类似问题并利用它们的证明来指导LLM；（2）形式验证器评估生成的证明并提供反馈，帮助模型修正错误的证明。这种方法显著提高了OpenAI o1模型的证明准确性（58%-70%的提升），并证明了转向能够生成可验证正确结论的LLMs可能显著提高其可靠性和一致性。
### Conclusion
将LLMs的输出转变为可验证正确的结论，可以大大提升其可靠性和准确性，进一步解锁需要诚信的关键现实世界应用的复杂任务。
## 22. `cs.CL` - 在基于LLM的评估系统中盲攻击检测的反事实评估 [PDF](https://arxiv.org/pdf/2507.23453), [HTML](https://arxiv.org/abs/2507.23453)
### Authors
Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima
### Background
本文探讨了对于基于大语言模型（LLM）的评估系统，如何防御提示注入攻击。在这种攻击中，候选答案被独立于真实答案构建，以欺骗评估者。背景介绍了当前标准评估方法对于此类盲攻击的高脆弱性。
### Innovation
提出了一种通过将标准评估（SE）与反事实评估（CFE）结合的框架来检测盲攻击的方法。反事实评估针对欺诈性的虚假真实答案重新评估提交内容。如果评估系统在标准和反事实条件下都能验证答案，则认为存在攻击。实验展示了该方法在保持最小性能损失的同时显著提高了安全性。
### Conclusion
标准评估对盲攻击极其容易被利用，但结合反事实评估（SE+CFE）框架能有效提升安全性，通过增强攻击检测能力，同时几乎不对性能造成负面影响。
## 23. `cs.CL` - Pass@K 策略优化：解决更难的强化学习问题 [PDF](https://arxiv.org/pdf/2505.15201), [HTML](https://arxiv.org/abs/2505.15201)
### Authors
Christian Walder,Deep Karkhanis
### Background
在现有的强化学习（RL）算法中，每个问题尝试多次n>1的解法，并独立奖励各个解法。这种做法优化了 pass@1 的性能，但为了独立解法的强度而牺牲了样本集的多样性和整体效用。这导致了采样能力未被充分利用，探索受限，对更难的问题改善有限。
### Innovation
本文提出了 Pass-at-k 策略优化（PKPO），这是一种通过最终奖励的转换直接优化 pass@k 表现的新方法，从而最大化考虑在一起时的样本集的奖励。贡献在于提出了 pass@k 及其梯度的新型低方差无偏估计器，适用于二元奖励和连续奖励设置。此外，在训练过程中可以调整 k 的值，同时优化多个指标，且在面对困难任务集时它能重新激活学习。
### Conclusion
通过我们的奖励转换，我们在玩具实验中验证了 pass@k 目标的有效性，发现较高 k 值能解决更多和更难的问题。同时，调整 k 的值能提升 pass@1 和 pass@k 的表现。在传统 pass@1 优化停滞的任务集中，我们的 pass@k 方法能促进学习，因为优先考虑联合效用有助于更好地探索。
## 24. `cs.CL` - Cost-aware LLM-based Online Dataset Annotation [PDF](https://arxiv.org/pdf/2505.15101), [HTML](https://arxiv.org/abs/2505.15101)
### Authors
Eray Can Elumar,Cem Tekin,Osman Yagan
### Background
近年来，大型语言模型（LLMs）的发展使得在最小的人类监督下自动进行数据集标签化成为可能。虽然通过跨多个LLM的多数投票可以提高标签可靠性，减轻单个模型的偏差，但由于多次查询会导致高昂的计算成本。
### Innovation
本文提出了一种新型在线框架Cost-aware Majority Voting（CaMVo），以实现高效且准确的基于LLM的数据集标注。CaMVo根据上下文嵌入动态选择每个数据实例的一部分LLM，平衡信心和成本，无需预训练或真实标签。通过基于LinUCB的选取机制和置信分数的贝叶斯估计，CaMVo估算每个LLM的标签准确性下界，并通过对加权多数投票聚合响应。
### Conclusion
我们在MMLU和IMDB影评数据集上的实验表明，CaMVo在显著降低标注成本的同时，达到了与完全多数投票相媲美的或更优的准确性。这确立了CaMVo作为成本效率标注在动态标注环境中的一种实用和稳健的解决方案。
## 25. `cs.CL` - 利用负信号：从教师数据进行强化蒸馏以增强LLM推理 [PDF](https://arxiv.org/pdf/2505.24850), [HTML](https://arxiv.org/abs/2505.24850)
### Authors
Shuyao Xu,Cheng Peng,Jiangxuan Long,Weidi Xu,Wei Chu,Yuan Qi
### Background
近年来，模型蒸馏的进步表明，高级推理模型的数据可以有效地训练较小的学生模型。然而，标准做法会丢弃错误的推理痕迹，这些信息是宝贵的，但尚未被充分利用。
### Innovation
本研究提出了一个两阶段训练方法：首先是正向推理痕迹的监督微调，然后是使用正向和负向推理痕迹进行精炼阶段。此外，研究发现了一种简单的目标函数，称为REINFORCE样式的强化蒸馏（REDI）目标，这种目标在用作蒸馏目标时优于现有的偏好优化方法（如DPO和SimPO）。实验结果表明，这种方法的有效性。特别地，通过赎回的131,000条负向数据痕迹训练的Qwen-REDI-1.5B模型在MATH-500上的得分为83.1%，其表现与使用800,000个专有数据训练的DeepSeek-R1-Distill-Qwen-1.5B相同。
### Conclusion
该研究表明，利用先前丢弃的负向数据痕迹可以显著提升LLM的推理性能，展示了这种方法的数据效率。
## 26. `cs.CL` - MALLM: 多代理大型语言模型框架 [PDF](https://arxiv.org/pdf/2509.11656), [HTML](https://arxiv.org/abs/2509.11656)
### Authors
Jonas Becker,Lars Benedikt Kaesberg,Niklas Bauer,Jan Philip Wahle,Terry Ruas,Bela Gipp
### Background
多代理辩论（MAD）展示了通过扩展测试时的计算能力和利用专业知识来增强集体智能的能力。当前的MAD框架往往侧重于工具使用，缺乏集成评估，或者在代理人物、响应生成器、讨论模式和决策协议的可配置性方面非常有限。
### Innovation
本文介绍了MALLM（多代理大型语言模型）框架，该框架提供超过144种独特的MAD配置，包括代理人物、响应生成器、讨论模式和决策协议。此外，MALLM使用简单的配置文件定义辩论，可以加载任何文本Hugging Face数据集，并提供一个易于比较MAD配置的评估管道。
### Conclusion
MALLM使研究人员能够系统地配置、运行和评估辩论，以理解和掌握组件及其相互作用，从而解决问题并促进多代理辩论的理解和探索。
## 27. `cs.CL` - 通过经验驱动的终身学习构建自演化代理：框架和基准 [PDF](https://arxiv.org/pdf/2508.19005), [HTML](https://arxiv.org/abs/2508.19005)
### Authors
Yuxuan Cai,Yipeng Hao,Jie Zhou,Hang Yan,Zhikai Lei,Rui Zhen,Zhenhua Han,Yutao Yang,Junsong Li,Qianjun Pan,Tianyu Huai,Qin Chen,Xin Li,Kai Chen,Bo Zhang,Xipeng Qiu,Liang He
### Background
随着人工智能向通用智能发展，研究重点从优化静态任务的系统转向创建能够持续学习的开放式代理。本文提出了一种基于经验驱动的终身学习（Experience-driven Lifelong Learning，ELL）框架，该框架用于构建能够通过现实世界交互实现持续成长的自演化代理。
### Innovation
该论文介绍了Experience-driven Lifelong Learning (ELL)框架，包含四个核心原则：经验探索（通过自我驱动的交互学习）、长时记忆（保存和结构化历史知识）、技能学习（通过抽象经验技能进行自主改进）以及知识内化（将显式经验转化为直观能力）。此外，还介绍了StuLife数据集，模拟学生的完整大学旅程。
### Conclusion
ELL框架和StuLife数据集将指导开发能够自主改进并适应动态环境的代理，促进人工智能向通用智能的方向发展。
## 28. `cs.CL` - IA2: 与ICL激活模式的对齐改进了监督微调 [PDF](https://arxiv.org/pdf/2509.22621), [HTML](https://arxiv.org/abs/2509.22621)
### Authors
Aayush Mishra,Daniel Khashabi,Anqi Liu
### Background
监督微调(SFT)通过训练模型权重以对特定查询产生预期的目标响应来使模型行为特定化。与此相反，在推理过程中，上下文学习(ICL)通过提示中的指令或示范来适应模型。ICL在数据稀缺的环境中比SFT提供了更好的泛化能力和更校准的响应，但同时增加了推理计算的负担。本文提出了一个关键问题：ICL的内部计算能否被用来改进SFT的质量？研究解释了SFT和ICL产生了不同的激活模式，表明这两种方法通过不同的功能机制实现适应。为利用ICL丰富的功能，引入了一种新的技术——ICL激活对齐（IA2），该技术旨在复制ICL的激活模式，从而激励类似ICL的内部推理。实证结果表明，IA2作为SFT之前的一个预热步骤能够显著提高模型输出的准确性和校准。
### Innovation
提出了ICL激活对齐（IA2）技术，这是一种自我蒸馏方法，旨在复制ICL的激活模式，从而在SFT模型中激励类似ICL的内部推理。研究发现，IA2作为SFT之前的一个步骤，可以显著提高模型输出的准确性和校准。
### Conclusion
这项研究不仅在实践上是非常有用的，而且还能为模型适应的内部机制提供概念性窗口。通过这种技术，SFT模型能够更接近ICL的效果，而无需承担类似的计算成本，从而提高模型在各种任务中的表现。
## 29. `cs.CL` - 使用大型语言模型解决不等式证明 [PDF](https://arxiv.org/pdf/2506.07927), [HTML](https://arxiv.org/abs/2506.07927)
### Authors
Pan Lu,Jiayi Sheng,Luna Lyu,Jikai Jin,Tony Xia,Alex Gu,James Zou
### Background
不等式证明在多个科学和数学领域中至关重要，它考验着复杂的推理能力，如发现紧密界线和战略定理应用。这一领域是大型语言模型（LLMs）一个独特的、极具挑战性的前沿阵地，提供超越一般数学问题解决的新见解。现有的数据集稀缺、合成或形式严格，限制了这一领域的进展。
### Innovation
本文通过提出一种非正式但可验证的任务形式，将不等式证明重新定义为两个自动检查的子任务：边界估计和关系预测，从而解决现有数据集的问题。此外，作者公开了一个由专家整理的名为IneqMath的数据集，包含奥林匹克级别的不等式问题，包括测试集和培训语料，以及逐步解决方案和定理注解。同时，作者还开发了一种新颖的LLM作为法官的评估框架，结合最终答案法官和四个逐步法官，以检测常见推理错误。系统地评估39种领先的大语言模型在IneqMath上的表现揭示了即便使用顶级模型也只能在逐步审视下获得不到10%的整体准确率，这比仅考虑最终答案等价性时的准确率下降了65.5%，这一差异揭示了目前的LLMs之间脆弱的推理链，并表明需要从找到答案到构建严谨证明之间的重要差距。通过增加模型规模和测试时的计算量对证明的正确性提高有限，但更多强调定理引导推理和自我改进的研究方向。
### Conclusion
初步评价表明，在逐步审查中领先模型的表现恶性下降，揭示出大规模语言模型推理链的脆弱性和自证过程中的重要差距。研究表明提高证明正确性的方向包括定理导向推理和自我改进。
## 30. `cs.LG` - PolySet: 通过恢复聚合物的统计集合性质进行机器学习 [PDF](https://arxiv.org/pdf/2512.13186), [HTML](https://arxiv.org/abs/2512.13186)
### Authors
Khalid Ferji
### Background
当前的机器学习模型在聚合科学研究中通常会将聚合物视为单一且完全定义的分子图，但实际上真实材料由具有不同长度的链式的随机集合组成。这种物理现实与数字表示之间的不匹配限制了现有模型捕捉聚合物行为的能力。
### Innovation
PolySet框架以有限的、加权的链集合形式表示聚合物，这些链从假设的聚合物质量分布中抽取。这种基于集合的编码与化学细节无关，并且可以与任何分子表示兼容。PolySet通过保留更高的分布矩（如Mz和Mz+1），使得机器学习模型能够以显著提高的稳定性和准确性学习链端敏感的属性。
### Conclusion
通过明确承认聚合物物质的统计性质，PolySet为未来的聚合物机器学习建立了坚实的物理基础，并且可以根据需要自然地扩展至共聚物、块状架构和其他复杂拓扑结构。
## 31. `cs.LG` - WAY：全球AIS轨迹中的船舶目的地估计 [PDF](https://arxiv.org/pdf/2512.13190), [HTML](https://arxiv.org/abs/2512.13190)
### Authors
Jin Sob Kim,Hyun Joon Park,Wooseok Shin,Dongil Park,Sung Won Han
### Background
自动识别系统（AIS）能够进行基于数据的海洋监控，但由于可靠性问题和不规则的时间间隔，导致其应用受限。为了解决这个问题，论文提出了一种新的方法，通过将航程重构为嵌套序列结构，使用空间网格来减少时空偏见，同时保持详细分辨率，这对于船舶目的地的估计至关重要。
### Innovation
1. 使用一种新的深度学习架构WAY，该架构能够处理重构后的航程，并提前数天到数周进行长时间的目的地估计。2. 架构包括轨迹表示层和通道聚集序列处理(CASP)模块，其中CASP模块利用多头通道和自我注意力来聚合和传递序列信息。3. 提出了任务特定的梯度丢弃（GD）技术，用于在单标签上实现多对多训练，从而避免由于梯度流被随机阻止而导致的反馈量潮。
### Conclusion
在5年AIS数据上的实验表明，WAY在各种轨迹进展下都优于传统的基于网格的空间方法，并且引入GD技术可以提升性能。此外，研究还探讨了WAY在真实世界应用中的潜力，通过多任务学习进行了预计到达时间（ETA）估计的探索。
## 32. `cs.LG` - 从过度拟合到可靠性：引入层次近似贝叶斯神经网络 [PDF](https://arxiv.org/pdf/2512.13111), [HTML](https://arxiv.org/abs/2512.13111)
### Authors
Hayk Amirkhanian,Marco F. Huber
### Background
近年来，神经网络已经颠覆了诸多领域，但超参数调优和过拟合等问题仍然是重要的挑战。贝叶斯神经网络通过将不确定性直接引入模型中，解决这些挑战，从而提供更可靠的预测，特别是在处理非分布数据时。
### Innovation
本文提出了一种新颖的方法——层次近似贝叶斯神经网络（HABNN）。该方法通过使用高斯-逆威沙特分布作为网络权重的超先验，提高了模型的鲁棒性和性能。研究表明，HABNN不仅能够匹配当前最优模型，而且在某些情况下甚至可以超越它们，显示出在安全关键环境中应用的前景。
### Conclusion
实验结果表明，HABNN不仅能够提供可靠的预测，还能有效解决过拟合问题，并提供可靠的不确定性估算。总体而言，HABNN是一种有前景的模型，特别是在处理非分布任务时。
## 33. `cs.LG` - 通过缓解局部依赖增强节点级图域适应 [PDF](https://arxiv.org/pdf/2512.13149), [HTML](https://arxiv.org/abs/2512.13149)
### Authors
Xinwei Tai,Dongmian Zou,Hongfei Wang
### Background
近年来，图上的机器学习方法取得了显著进展，但如何有效地将一个图上的知识转移到另一个图上仍是一个关键挑战。这凸显了需要能够将来源图中提取的信息应用于未标记的目标图的需求，这个任务被称为无监督图域适应（GDA）。无监督GDA的关键难点之一是条件性偏移，它阻碍了知识的转移。
### Innovation
作者通过深入分析和提出使用马尔可夫链模拟节点特征依赖性，并基于此提出理论发现。为了克服条件性偏移，作者提出通过解相关节点特征来改进GDA。具体实施可通过去相关GCN层和图变换器层来实现。实验结果证明了该方法的有效性，并在学习表示中展示了类别内较小的距离。
### Conclusion
本文通过缓解局部依赖性，显著提升了节点级的图域适应性能，并通过清晰的可视化结果展示了去相关节点特征的方法对性能的提升。
## 34. `cs.LG` - 评估温度预测中联邦学习的对抗性攻击 [PDF](https://arxiv.org/pdf/2512.13207), [HTML](https://arxiv.org/abs/2512.13207)
### Authors
Karina Chichifoi,Fabio Merizzi,Michele Colajanni
### Background
深度学习与联邦学习（FL）正在成为下一代天气预报的强大工具。深度学习能够提供高分辨率的时空预报，可能超越传统的数值模型，而FL允许不同地理位置的机构在无需共享原始数据的情况下协作训练模型，解决了效率和安全问题。然而，FL的分布式特性也带来了新的漏洞，尤其是在不同地区部署的环境中，数据中毒攻击可能导致性能下降或引入系统偏差。这种威胁在气象数据的空间依赖性中被放大，局部的扰动可以通过全局模型聚合影响更广泛的区域。
### Innovation
本研究通过模拟地理分布的客户端并评估基于补丁和全局偏置攻击，研究了对抗客户端如何扭曲基于Copernicus欧洲区域再分析（CERRA）数据集训练的联合表面温度预报。研究发现即使少量被污染的客户端也可能误导大范围的时空预报。此外，研究还评估了截断平均聚合作为防御机制，发现它能够有效抵御全局偏差攻击，但对基于补丁的攻击效果不佳，揭示了在空间相关数据中基于离群值的防御机制的局限性。
### Conclusion
本研究揭示了联邦学习在温度预报中面临的对抗性攻击问题，并评估了防御机制的有效性。尽管截断平均聚合可以减轻全局偏差攻击的影响，但它对基于补丁的攻击效果较差，表明在空间相关数据中需要更有效的防御策略来应对这些攻击。
## 35. `cs.LG` - Quanvolutional Neural Networks for Spectrum Peak-Finding [PDF](https://arxiv.org/pdf/2512.13125), [HTML](https://arxiv.org/abs/2512.13125)
### Authors
Lukas Bischof,Rudolf M. Füchslin,Kurt Stockinger,Pavel Sulimov
### Background
核磁共振（NMR）光谱等光谱数据的综合表征在化学分析中是一个充满挑战的任务，特别是对于复杂的分子。这一过程称为去卷积，包括识别和量化光谱中的峰值。目前，机器学习技术在自动化这一过程方面取得了显著成果。随着量子计算的出现，该领域存在进一步增强这些技术的潜力。
### Innovation
受经典卷积神经网络（CNNs）成功的启发，作者探索使用量子卷积神经网络（QuanvNNs）解决涉及峰值计数和位置估计的多任务峰值检测问题。通过直接比较QuanvNN架构与其经典CNN的性能，研究结果表明，在具有挑战性的光谱中，QuanvNNs表现优于经典CNN，在F1分数上提高了11%，在峰值位置估计的平均绝对误差上减少了30%。此外，QuanvNNs在更难的问题上表现出更好的收敛稳定性。
### Conclusion
研究结果表明，QuanvNNs在具有挑战性的光谱去卷积任务中表现出色，特别是在峰值位置估计的F1分数和平均绝对误差方面有显著改善。这种架构在更困难的问题上表现出更好的收敛稳定性。
## 36. `cs.LG` - ModSSC：异质数据上半监督分类的模块化框架 [PDF](https://arxiv.org/pdf/2512.13228), [HTML](https://arxiv.org/abs/2512.13228)
### Authors
Melvin Barbaux(IMB)
### Background
现有的半监督分类软件支持是基于方法和模式碎片化的，面向不同类型的半监督分类方法，Module Semi-supervised Classification (ModSSC) 旨在解决这一问题。
### Innovation
ModSSC 提供了一个开源的统一框架，将归纳和推导半监督分类整合到一个模块化的代码集中。它实现了多种经典和现代算法，并提供了多种数据集的加载器，同时通过单一配置接口来指定数据集、模型和评估协议。
### Conclusion
ModSSC 通过声明性的 YAML 描述实验，简化了复现现有工作和运行大规模比较研究。其 1.0.0 版本在 MIT 许可证下发布，并附有详尽的文档和测试，可通过以下链接访问：this https URL.
## 37. `cs.LG` - SACn: 与n步回报相结合的软actor- Critic [PDF](https://arxiv.org/pdf/2512.13165), [HTML](https://arxiv.org/abs/2512.13165)
### Authors
Jakub Łyskawa,Jakub Lewandowski,Paweł Wawrzyński
### Background
软 actor-critic (SAC) 广泛应用于实际场景中，已成为最相关的离线无模型在线强化学习 (RL) 方法之一。尽管n步回报能提高 RL 算法的收敛速度，但将其与 SAC 结合使用却面临挑战，主要是因为它们的结合会导致基于行动分布的变化引起偏倚。重要采样虽能解决这一问题，但可能导致数值不稳定。
### Innovation
提出了将 SAC 与 n 步回报结合的方式，采用数值稳定的重要性采样方法，并简化了超参数选择。进一步分析了 Soft Actor-Critic 的熵估计方法在n步最大熵框架下的应用，并提出了 τ 样本熵估计方法来减少学习目标的方差。最后，形成了 SACn 算法，已在 MuJoCo 模拟环境中进行了实验验证。
### Conclusion
提出了 SACn 算法，并通过在 MuJoCo 模拟环境中实验验证了该算法的有效性。
## 38. `cs.LG` - Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning [PDF](https://arxiv.org/pdf/2512.13196), [HTML](https://arxiv.org/abs/2512.13196)
### Authors
Chethana Prasad Kabgere,Sudarshan T S B
### Background
高级驾驶辅助系统（ADAS）越来越多地利用联邦学习（FL）在分布式车辆节点之间协作训练模型，同时保护数据隐私。然而，传统的FL聚合仍然容易受到实时车辆网络中的噪声、延迟和安全限制的影响。
### Innovation
 paper引入了 Noise-Resilient Quantum Federated Learning (NR-QFL)，这是一个混合量子-经典框架，通过在噪声中介尺度量子（NISQ）条件下运行变量子电路（VQC）实现安全、低延迟的聚合。该框架通过自适应门重新参数化将模型参数编码为量子态，确保有界误差收敛，并在完全正迹保留（CPTP）动力学下具备可证明的鲁棒性。NR-QFL 使用基于量子熵的客户端选择和多服务器协调来实现公平性和稳定性。实验证明，该框架在受限边缘条件下保持一致收敛，减少梯度方差，降低通信开销，并增强噪声容忍度。
### Conclusion
该框架为量子增强的联邦学习建立了可扩展的基础，实现了ADAS在车辆边缘的安全、高效和动态稳定的智能。
## 39. `cs.LG` - TraPO: 半监督强化学习框架以提升大型语言模型推理能力 [PDF](https://arxiv.org/pdf/2512.13106), [HTML](https://arxiv.org/abs/2512.13106)
### Authors
Shenzhi Yang,Guangcheng Zhu,Xing Zheng,Yingfan MA,Zhongqi Chen,Bowen Song,Weiqiang Wang,Junbo Zhao,Gang Chen,Haobo Wang
### Background
强化学习通过利用可验证的答案信号指导策略优化，有效训练大型推理模型（LRMs），然而这种方法受到了高标注成本的限制。先前的研究探索了无需外部监督，仅依靠模型内部一致性（如熵和多数表决）来推导奖励的无监督RLVR方法，尽管看起来很有前景，但在训练后期这些方法经常会导致模型崩溃，即强化了错误的推理模式。
### Innovation
本文提出了一种新颖的半监督RLVR范式，通过有限的标注集指导对未标注样本进行训练。本文的关键见解是，监督奖励对于在未标注样本上稳定一致性训练至关重要，确保仅将被验证为正确的推理模式纳入强化学习训练中。技术上，本文提出了一种有效的策略优化算法TraPO，通过匹配学习轨迹相似度来识别可靠的未标注样本。TraPO在六个广泛应用的数学推理基准测试（AIME24/25、AMC、MATH-500、Minerva、奥林匹亚德）和三个离分布任务（ARC-c、GPQA-diamond、MMLU-pro）上表现出色。使用仅1000个标注和3000个未标注样本，TraPO获得了42.6%的平均准确率，超过了使用45000个未标注样本训练的最佳无监督方法（38.3%）。进一步使用4000个标注和12000个未标注样本时，TraPO在所有基准测试中超过了完全监督模型在完整45000个标注样本上的表现，仅使用了10%的标注数据。
### Conclusion
本文证明了半监督RLVR范式在提升大型语言模型推理能力方面的有效性和效率，即使使用非常有限的标注数据也能获得优于完全监督模型的表现，为进一步研究提供了新的途径。
## 40. `cs.AI` - 捍卫基于结果的层次结构模型 [PDF](https://arxiv.org/pdf/2512.13505), [HTML](https://arxiv.org/abs/2512.13505)
### Authors
Henry Prakken,Wijnand van Woerkom
### Background
近年来，已经提出了层次化的案例推理模型，这些模型包含了前例约束的关系。特雷弗·本奇-康普在多篇文章中批评了这些模型，认为这些模型在某些情况下会给出错误的结果，特别是这些模型没有考虑到不同底层因素可能以不同的强度建立中间因素的可能性。
### Innovation
本文针对 van Woerkom 的基于结果的层次模型提出了反驳特雷弗·本奇-康普的批评，作者认为本奇-康普似乎将中间因素理解为维度，通过将 van Woerkom 的基于维度的层次结果模型应用于这些例子，可以避开本奇-康普的批评。
### Conclusion
本文通过应用 van Woerkom 的基于维度的层次结果模型，解决了特雷弗·本奇-康普提出的批评，从而支持了基于结果的层次模型的有效性。
