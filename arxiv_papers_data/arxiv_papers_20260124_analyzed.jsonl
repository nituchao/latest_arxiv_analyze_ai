{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15322", "html_url": "https://arxiv.org/abs/2601.15322", "title": "可重复使用的金融代理：一种用于工具有用的大语言模型代理的确定性和忠实保障框架", "title_en": "Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents", "authors": "Raffi Khatchadourian", "background": "大语言模型（LLM）代理在金融服务中的应用正变得越来越普遍，但这些代理在应对监管审计回放时表现出困难。当被要求重现已标记的交易决策时，大多数部署的代理不能提供一致的结果。因此，需要一种新的框架来评估这些代理的确定性和忠实性。", "innovation": "本文提出了一个名为DFAH（Determinism-Faithfulness Assurance Harness）的框架，用于测量金融服务中部署的工具使用代理的轨迹的确定性和条件证据的忠实性。研究发现，不同的模型和提供者在非代理性的基线实验中表现出不同的性能，且具有确定性的模型也倾向于更忠实于证据。", "conclusion": "在DFAH的评估设置下，具有架构优先级的顶级模型达到了符合审计回放需求的确定性水平。同时，研究发现确定性和忠实性之间存在正相关关系，即能够产生一致输出的模型更倾向于忠实于证据。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15305", "html_url": "https://arxiv.org/abs/2601.15305", "title": "Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models", "title_en": "Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models", "authors": "Alfred Shen,Aaron Shen", "background": "长上下文语言模型中的注意机制计算负担促使了两个相对独立的研究方向：稀疏注意机制通过选择性地关注部分令牌来降低复杂性，以及门控注意变体通过改进训练稳定性和缓解注意陷阱现象来提高性能。", "innovation": "提出了Gated Sparse Attention (GSA) 架构，结合了稀疏注意和门控注意的优点，包括：门控闪电索引器接入sigmoid激活，生成有界且可解释的选择分数；自适应稀疏控制器根据当地不确定性调节关注令牌的数量；以及在值和输出阶段的双重门控。此外还建立了该方法的理论基础，包括复杂性分析、表达性结果和收敛性保证。", "conclusion": "GSA在1.7B参数模型上匹配了稀疏模型的效率（在128K上下文时，速度提升12-16倍），同时在质量方面达到了门控注意的优势：困惑度从6.03降至5.70，RULER得分几乎翻倍，对第一令牌的关注度从47%降至不到4%，训练稳定性显著提高，损失峰值减少了98%。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15311", "html_url": "https://arxiv.org/abs/2601.15311", "title": "Aeon: 高性能神经符号型内存管理对长时 horizon 语言模型代理", "title_en": "Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents", "authors": "Mustafa Arslan", "background": "大规模语言模型（LLMs）的基本问题是计算成本中的二次自注意力机制，以及当上下文窗口扩大时推理能力的下降现象，即“迷失在中间”问题。现有解决方案主要是依赖向量数据库的“扁平RAG”架构，这种方法忽略了记忆中的层次结构和时间顺序，导致“向量迷雾”，即检索到的孤立事实缺乏连续性的情节记忆。", "innovation": "作者提出了Aeon，一个神经符号认知操作系统，它将内存重新定义为可管理的OS资源。Aeon通过Memory Palace（一种使用Atlas实现的空间索引，Atlas是一种通过结合小世界图导航和具有B+树特征的磁盘本地性来加速页簇向量索引读取放大减少的技术）和Trace（一个神经符号情节图）来结构化内存。此外，Aeon引入了语义旁路缓冲区（SLB），这是一种预测缓存机制，利用对话局部性以实现亚毫秒级的检索延迟。", "conclusion": "Aeon 通过零拷贝C++/Python桥梁确保了状态一致性，实现了亚毫秒级的检索延迟，同时为自主代理提供了可持续结构化的内存。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15306", "html_url": "https://arxiv.org/abs/2601.15306", "title": "通过代理变量揭示基于LLM的急诊分级中的潜在偏见", "title_en": "Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables", "authors": "Ethan Zhang", "background": "大型语言模型（LLMs）在临床决策中的应用取得了进展，但存在的患者偏见问题依然存在，这些偏见可能源自种族、社会经济和临床背景。本文研究了LLM在急诊分诊中的偏见问题，使用了32个患者级别的代理变量来分析其影响。", "innovation": "采用32个患者级别的代理变量评估LLM偏见，结合公共数据集（如MIMIC-IV-ED Demo, MIMIC-IV Demo）和受限访问的认证数据集（如MIMIC-IV-ED和MIMIC-IV），揭示了代理变量在急诊分诊中的隐性偏见，说明即使在正面或负面情境下，某些特定词的出现也可能导致病情严重性感知的修改。", "conclusion": "AI系统是在噪声信号上进行训练的，且这些信号有时是非因果的，不能可靠地反映真实的患者病情。因此，在临床环境中部署AI技术时，需要更加确保安全和负责任的操作。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15307", "html_url": "https://arxiv.org/abs/2601.15307", "title": "DeepSurvey-Bench: 评估自动生成的科学调查的学术价值", "title_en": "DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey", "authors": "Guo-Biao Zhang,Ding-Yuan Liu,Da-Yi Wu,Tian Lan,Heyan Huang,Zhijing Wu,Xian-Ling Mao", "background": "自动化科学调查生成技术的飞速发展使得建立一个全面的基准来评估生成调查的质量变得越来越重要。现有的评估基准依赖于不全面的选择标准，如引用计数和结构连贯性来选择作为真实基准的数据集，然后仅使用表面性质如结构质量和参考相关性进行评价。已有的基准有两个主要问题：（1）由于缺乏学术维度的标注，真实基准数据集不可靠；（2）仅关注表面质量，例如逻辑连贯性。这些问题导致现有基准无法评估生成调查的深层“学术价值”，如核心研究目标和不同研究的关键分析。", "innovation": "我们提出了DeepSurvey-Bench，这是一种新型基准，旨在全面评估生成调查的学术价值。我们的基准提供了一个综合性的学术价值评价标准，涵盖指示性价值、学术交流价值和研究指导价值三个维度。基于该标准，我们构建了一个带有学术价值标注的可靠数据集，并评估了生成调查的深层学术价值。广泛的实验结果表明，我们的基准在评估生成调查的学术价值方面与人类表现高度一致。", "conclusion": "我们的基准能够全面评估生成调查的学术价值，并且与人类评估结果高度一致。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15392", "html_url": "https://arxiv.org/abs/2601.15392", "title": "GeMM-GAN: 一种条件于组织病理学图像和临床描述的多模态生成模型用于基因表达谱生成", "title_en": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation", "authors": "Francesca Pia Panaccione,Carlo Sgaravatti,Pietro Pinoli", "background": "生物医学研究越来越多地依赖于整合各种数据模态，包括基因表达谱、医学影像和临床元数据。尽管医学影像和临床元数据在临床实践中通常会被收集，但基因表达数据在广泛应用研究中面临独特挑战，主要是由于严格的隐私法规和昂贵的实验室实验。为了应对这些限制，我们提出了一种新颖的生成对抗网络GeMM-GAN，该网络基于组织病理学组织切片和临床元数据进行训练，旨在生成逼真的基因表达谱。GeMM-GAN结合了Transformer编码器处理图像片段，并通过片段和文本标记之间的最终交叉注意力机制生成一个条件向量，以引导生成模型生成具有生物连贯性的基因表达谱。", "innovation": "GeMM-GAN通过整合组织病理学组织切片和临床元数据，创新地提出了一个基于生成对抗网络的多模态生成模型。此模型采用Transformer编码器处理图像片段，并结合交叉注意力机制生成指导性向量，以生成符合生物学特性的基因表达谱。并且与标准生成模型相比，GeMM-GAN在TCGA数据集的下游疾病类型预测上表现出色，准确率提高了超过11%。", "conclusion": "研究表明，GeMM-GAN框架在生成更加真实且具有功能意义的基因表达谱方面优于现有的标准生成模型，这提升了下游疾病类型预测的准确性超过11%。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15324", "html_url": "https://arxiv.org/abs/2601.15324", "title": "Prometheus Mind: 向冻结的语言模型嵌入记忆", "title_en": "Prometheus Mind: Retrofitting Memory to Frozen Language Models", "authors": "Mark Wind", "background": "通常在为预训练语言模型添加记忆时需要进行架构调整或权重修改。本文介绍了一种名为Prometheus Mind的新方法，该方法通过使用11个模块化的适配器（530MB，7%的额外开销）将记忆嵌入到冻结的Qwen3-4B模型中，且该系统完全可逆，只需移除适配器即可。构建此系统需要解决四个问题：首先，提出对比方向发现（CDD）方法，用于通过最小对找到语义方向，无需标记数据；其次，端到端优化失败，通过依次训练每个适配器完成简单代理任务获得成功；再次，注入过程中学到的编码器无法泛化，发现原模型已给出需要的映射，无需额外训练便可实现；最后，潜在状态坍缩，通过训练投影恢复区分度。", "innovation": "Prometheus Mind是首个无需架构调整和权重修改而能通过11个模块化适配器将记忆嵌入冻结模型的系统，并且该系统是可逆的。研究过程中开发了对比方向发现（CDD）方法，解决了端到端优化失败的问题，并找到了不需要额外训练就能完成任务的方法。此外，还通过训练投影解决了潜在状态的坍缩问题。", "conclusion": "在PrometheusExtract-132任务上的实验结果表明，系统在干净输入上实现了94.4%的召回率（置信区间：[84.9%, 98.1%]），而对于含有省略、填充词或隐式主语的非正式输入，召回率降为19.4%。主要瓶颈在于关系分类的准确率仅为47.3%，对大多数提取错误负责。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15347", "html_url": "https://arxiv.org/abs/2601.15347", "title": "知识图谱网络上的逻辑编程及其在医疗领域的应用", "title_en": "Logic Programming on Knowledge Graph Networks And its Application in Medical Domain", "authors": "Chuanqing Wang,Zhenmin Zhao,Shanshan Du,Chaoqun Fei,Songmao Zhang,Ruqian Lu", "background": "知识图谱的研究快速发展，已经在多个领域得到广泛应用，特别是在医疗和健康护理领域。然而，一些主要的信息处理技术在知识图谱的应用中仍存在不足，如未能充分使用先进的逻辑推理、人工智能技术和特殊编程语言，现代概率和统计理论等。特别的是，关于知识图谱的合作与竞争技术研究不足。", "innovation": "本文提出了‘知识图谱网络’的概念及其在医疗和健康护理领域的应用，其涵盖定义、开发、推理、计算和在不同条件下（如模糊、不确定、多模态、矢量化、分布式、联邦）的应用。每个案例均提供了实际数据和实验结果。", "conclusion": "本文提出了创新理论、技术和应用场景，并总结了这些方面的贡献。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15397", "html_url": "https://arxiv.org/abs/2601.15397", "title": "超越提示：通过逻辑空间整合实现高效稳健的声音LLM上下文偏向（LOGIC）", "title_en": "Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)", "authors": "Peidong Wang", "background": "由于文化转变、新兴趋势和个性化的用户数据，新实体以快速涌现的形式出现，这一现象对现有的语音大语言模型构成了重大挑战。虽然这些模型在一般对话任务中表现出色，但它们静态的训练知识限制了它们识别特定领域的术语（如联系人名称、播放列表或技术术语）的能力。现有的解决方案主要依赖于提示，但这种做法存在不可扩展的问题：随着实体列表的增长，提示遇到上下文窗口限制、推断延迟增加以及“丧失中间内容”现象。另一方面，生成纠错（GEC）通过后处理重写转录文本，但经常导致“过度纠错”，引入从未说过实体的幻觉。", "innovation": "我们提出了LOGIC（逻辑空间整合用于上下文偏置）框架，这是一个在解码层直接操作的高效和稳健的方法。与提示不同，LOGIC将上下文注入与输入处理分离，确保常量时间复杂度相对于提示长度。在使用Phi-4-MM模型的11个跨语言场景中进行了广泛的实验，结果显示LOGIC在实体错误率（Entity WER）上平均减少了9%，同时错误警报率（False Alarm Rate）仅仅增加了0.30%。", "conclusion": "LOGIC框架通过直接在解码层操作，实现了上下文偏置的高效和稳健方法，解决了现有解决方案在扩展性上的不足，并显著减少了实体错误率，同时保持了较低的错误警报率。"}
{"llm_update_time": "20260124", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.15316", "html_url": "https://arxiv.org/abs/2601.15316", "title": "大型视觉语言模型在多模态假新闻检测中的范式转变：全面综述", "title_en": "The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection", "authors": "Wei Ai,Yilong Tan,Yuntao Shou,Tao Meng,Haowen Chen,Zhixiong He,Keqin Li", "background": "近年来，大型视觉-语言模型（LVLMs）的迅速演进推动了多模态假新闻检测（MFND）范式的转变，从传统的特征工程方法转变为统一的端到端多模态推理框架。早期方法主要依赖于浅层融合技术来捕捉文本和图像之间的关联，但面临着高层次语义理解和复杂跨模态交互的挑战。大型视觉-语言模型的出现彻底改变了这一格局，通过强大的表征学习实现了视觉和语言的联合建模，从而增强检测利用文本叙述和视觉内容的虚假信息的能力。尽管取得了这些进展，该领域仍然缺乏一个系统性的文献综述，以追踪这一过渡并汇总最近的发展。为了填补这一空白，本文提供了通过大型视觉-语言模型视角进行的全面综述。", "innovation": "本文提供了通过大型视觉-语言模型视角进行的全面综述，从传统多模态检测管道，到基于基础模型的范式，描绘了这一过渡过程。进一步建立了涵盖模型架构、数据集和性能基准的结构化分类体系。此外，分析了剩下的技术挑战，包括可解释性、时间推理和领域泛化能力。最后，指出了未来研究方向，以指导这一范式转变的下一阶段。", "conclusion": "据我们所知，这是首篇系统地记载并分析大型视觉-语言模型在应对多模态假新闻中的变革作用的全面综述。现有方法的总结已在我们的GitHub：[this https URL]中提供。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.15872", "html_url": "https://arxiv.org/abs/2601.15872", "title": "PF-D2M：无需姿态的用于通用舞蹈音乐生成的扩散模型", "title_en": "PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation", "authors": "Jaekwon Im,Natalia Polouliakh,Taketo Akama", "background": "舞蹈和音乐的同步生成旨在根据舞蹈动作生成音乐。现有方法通常依赖单一人体舞者的动作特征以及有限的舞蹈音乐数据集，这限制了它们在涉及多个舞者和非人舞者的真实世界场景中的性能和适用性。", "innovation": "本文提出了一种新的扩散基础的舞蹈音乐生成模型PF-D2M，该模型结合了从舞蹈视频中提取的视觉特征。PF-D2M采用逐阶段的训练策略，有效解决了数据稀缺性和泛化挑战。", "conclusion": "客观和主观的评估均表明，PF-D2M在舞蹈音乐对齐和音乐质量方面均取得最先进的性能。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.15909", "html_url": "https://arxiv.org/abs/2601.15909", "title": "从ImageNet迁移学习进行基于MEG的想象言语解码", "title_en": "Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech", "authors": "Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud", "background": "非侵入式解码想象言语依然具有挑战性，原因在于信号微弱且分散，以及标记数据有限。该研究介绍了将磁源成像学（MEG）信号转化为与预训练视觉模型兼容的时间-频率表示的方法。", "innovation": "采用了基于图像的方法，将MEG信号转换成时间-频率表示，再通过learnable传感器空间卷积将这些数据投影到三个空间音频绘图混合中，生成可用于预训练的视觉架构的图像式输入。这种方法优于经典和未预训练模型，对于想象言语与静默之间的准确率高达90.4%，与静默阅读的区别为81.0%，而元音解码则为60.6%。跨受试者评估证明了预训练模型能够捕捉到共享的神经表征，时间分析显示区别性信息集中在想象锁定的时间区间。", "conclusion": "预训练的视觉模型应用于图像化的MEG表示，能够有效捕捉想象言语的结构在非侵入神经信号中的表现。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16046", "html_url": "https://arxiv.org/abs/2601.16046", "title": "DextER：基于语言驱动的具身推理联动精确抓取生成", "title_en": "DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning", "authors": "Junha Lee,Eunha Park,Minsu Cho", "background": "语言驱动的灵巧抓取生成要求模型理解任务语义、3D几何形状和复杂的手与物体的交互。现有的基于视觉-语言模型的方法直接将观测结果映射到抓取参数，而缺乏对物理交互的中间推理。", "innovation": "DextER 提出了一种新的框架，引入基于接触的具身推理，用于多指操作。其核心洞察是预测哪个手指接触物体表面的特定位置可以提供一种任务语义与物理约束间的具身感知中间表示。", "conclusion": "DextER 在 DexGYS 上实现了 67.14% 的成功率，明显优于当前最先进的方法。同时，该方法还展示了部分接触信息的主动生成能力，实现了对抓取合成的细粒度控制。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2308.11551", "html_url": "https://arxiv.org/abs/2308.11551", "title": "多事件视频-文本检索", "title_en": "Multi-event Video-Text Retrieval", "authors": "Gengyuan Zhang,Jisen Ren,Jindong Gu,Volker Tresp", "background": "在互联网上存在大量视频和文本数据的时代，视频-文本检索（VTR）是一项关键的跨模态任务。以往的工作主要采用基于双流视觉-语言模型架构的方法，学习视频-文本对的联合表示，但这些模型假设视频-文本之间的是一一对应的，忽略了实际上视频内容通常包含多个事件，而用户查询或网页元数据通常对应单一事件的场景。这种假设导致现有模型在实际应用中表现不佳。", "innovation": "本文提出了多事件视频-文本检索（MeVTR）任务，针对视频中包含多个不同事件的场景，引入了一个简单的Me-Retriever模型，该模型结合了关键事件视频表示和一种新的MeVTR损失函数。", "conclusion": "全面的实验表明，该简单框架在视频到文本和文本到视频任务上优于其他模型，有效地为MeVTR任务建立了稳健的基线。我们相信这项工作为后续的研究奠定了坚实的基础。相关代码可以在该链接下载。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16200", "html_url": "https://arxiv.org/abs/2601.16200", "title": "通过特征空间平滑在多模态大型语言模型中实现可证明的鲁棒性", "title_en": "Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing", "authors": "Song Xia,Meiwen Ding,Chenqi Kong,Wenhan Yang,Xudong Jiang", "background": "多模态大型语言模型（MLLMs）在各种应用中展现了强大的功能，但它们仍然容易受到对抗性扰动的影响，这些扰动会扭曲其特征表示并导致错误的预测。", "innovation": "该研究提出了特征空间平滑（FS）技术，证明FS能够提供在MLLMs特征表示上的可证明鲁棒性。此外，引入了净化器和光滑映射器（PSM），这是一种即插即用模块，它能够提高MLLMs的高斯鲁棒性评分，从而增强在FS下的认证鲁棒性，而无需对MLLMs进行重新训练。", "conclusion": "实验结果表明，结合了FS和PSM不仅提供了强大的理论鲁棒性保证，而且在对抗训练中也展示了优越的实际性能。广泛的研究表明，FS-PSM极大地提高了各类白盒攻击下的攻击成功率率，从接近90%降低到约1%。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16096", "html_url": "https://arxiv.org/abs/2601.16096", "title": "Neural Particle Automata: 学习自主组织的颗粒动力学", "title_en": "Neural Particle Automata: Learning Self-Organizing Particle Dynamics", "authors": "Hyunsoo Kim,Ehsan Pajouheshgar,Sabine Süsstrunk,Wenzel Jakob,Jinah Park", "background": "研究从静态网格转换到动态颗粒系统的拉格朗日模型，旨在解决传统欧拉模型的局限性，如固定的细胞位置。作者开发了一种称为神经粒子自动机（NPA）的新模型，该模型能够处理异质性动力学并在活动区域进行计算。", "innovation": "提出了将神经细胞自动机（NCA）从静态网格扩展到动态颗粒系统的Neural Particle Automata (NPA)。通过使用基于光滑粒子 hydromechanics (SPH) 的可微分操作符替代基于网格的邻域感知，并利用内存高效的CUDA加速内核，使得NPA能够实现可扩展的端到端训练。此外，NPA还保留了NCA的关键行为如鲁棒性和自我再生，同时也引入了适用于颗粒系统的新型行为。", "conclusion": "实验结果显示，NPA不仅保持了关键的NCA特性，还能够实现新类型的动力学行为，从而确立了它作为学习自主组织颗粒动力学的紧凑神经模型的地位。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16117", "html_url": "https://arxiv.org/abs/2601.16117", "title": "基于蒸馏的层删除（DLD）有效的端到端框架用于动态语音网络", "title_en": "Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks", "authors": "Abdul Hannan,Daniele Falavigna,Shah Nawaz,Mubashir Noman,Markus Schedl,Alessio Brutti", "background": "边缘设备在受限制和变化的资源环境下运行，需要能够适应可用资源限制的动态架构。为了满足这些需求，通常会使用层删除（$\text{LD}$）方法将静态模型转换成动态模型，通过跳过网络的某些部分并减少整体计算复杂性来实现。但是现有的$\text{LD}$方法在低和高删除率情况下严重影响了动态模型的性能，破坏了性能和计算的需求权衡。", "innovation": "提出了一个基于蒸馏的层删除（DLD）框架，该框架将知识蒸馏和$\text{LD}$能力在端到端的过程中有效结合，从而实现了动态语音网络的最佳性能。通过在三个公开基准上使用众所周知的语音识别方法（如Conformer和WavLM）进行全面的实验，证明了该框架的有效性，高删除率情况下且在无删除情况下分别降低了9.32%和2.25%的字错误率，同时减少了33.3%的训练时间。", "conclusion": "实验结果表明，DLD框架有效地解决了现有$\text{LD}$方法在动态语音网络中的性能和计算效率问题，实现了最优的性能表现，并显著减少了训练时间。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.15859", "html_url": "https://arxiv.org/abs/2601.15859", "title": "不确定性引导的暗场放射图像生成", "title_en": "Uncertainty-guided Generation of Dark-field Radiographs", "authors": "Lina Felsner,Henriette Bast,Tina Dorosti,Florian Schaff,Franz Pfeiffer,Daniela Pfeiffer,Julia Schnabel", "background": "X射线暗场成像通过小角度散射可视化微结构组织变化，提供与传统衰减成像互补的诊断信息。然而，这类数据的有限可用性限制了开发稳健的深度学习模型。", "innovation": "提出了首个直接从标准衰减胸部X射线生成暗场图像的不确定性引导分步生成对抗网络框架，该模型结合了先验和后验不确定性以提高解释性和可靠性。", "conclusion": "实验结果表明生成的图像具有高的结构保真度，并在各个阶段一致提高了定量指标。进一步的离群值评估证实了所提出模型的良好泛化能力。研究结果显示，不确定性引导的生成建模可以实现可靠的暗场图像合成，并为未来的临床应用提供坚实的基础。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16113", "html_url": "https://arxiv.org/abs/2601.16113", "title": "SynthOCR-Gen: 一种为低资源语言生成合成OCR数据集的工具——打破数据障碍", "title_en": "synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier", "authors": "Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi", "background": "低资源语言的光学字符识别（OCR）仍面临重大挑战，主要是因为缺乏大规模标注训练数据集。例如，具有约700万使用者和具有独特重音标记的波斯-阿拉伯书写系统的克什米尔语目前在Tesseract、TrOCR和PaddleOCR等主要OCR系统中缺乏支持。手动创建此类语言的训练数据集成本高昂、耗时且错误率高，经常需要逐词转录印刷或手写文本。", "innovation": "SynthOCR-Gen是一个专为低资源语言设计的开源合成OCR数据集生成器。该工具通过将数字Unicode文本语料库转换为可立即使用的训练数据集，来解决OCR开发中的根本瓶颈。系统包含文本分段（字符、词、n元、句子和行级别）、Unicode规范化与剧本清洁、多字体渲染与可配置分布，以及25种以上模拟真实世界文档退化的数据增强技术。", "conclusion": "通过生成包含60万个分词样本的克什米尔语OCR数据集，该研究展示了其方法的有效性，并公开发布在HuggingFace以供研究和实践者使用。这项工作为低资源语言引入视觉-语言AI模型提供了实用途径，该工具对全球无法获得服务的书写系统的研究人员和实践者都是公开可用的。"}
{"llm_update_time": "20260124", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2601.16064", "html_url": "https://arxiv.org/abs/2601.16064", "title": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation", "title_en": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation", "authors": "Shams Nafisa Ali,Taufiq Hasan", "background": "尽管深度学习大大推动了医学图像分割的进步，但在不同成像模态和解剖结构间的鲁棒泛化仍然面临重大挑战。现有架构如卷积神经网络（CNNs）、变换器（Transformers）及它们的混合体主要编码空间信息，而忽略了频域表示，这些表示能捕捉丰富的结构和纹理线索。虽然一些近期研究开始探索特征级的谱信息，但在特征级结合频率线索（对于精细对象定位至关重要）的监督机制仍未充分开发。", "innovation": "为了应对上述挑战，本文提出了一种名为Phi-SegNet的CNN架构，它在架构和优化层面上都融入了相位感知信息。该网络结合了Bi-Feature Mask Former（BFMF）模块，通过融合相邻编码器特征来减少语义差距，以及Reverse Fourier Attention（RFA）块，使用相位正则化特征细化解码器输出。还提出了一种专门的相位感知损失来对齐这些特征与结构先验，从而形成闭环反馈回路，强调边界精度。该模型在X射线、超声、组织病理学、MRI和肠镜等五个公共数据集上进行了测试，结果显示，在IOU和F1分数上，Phi-SegNet相较于次优模型有平均1.54±1.26%和0.98±0.71%的提升。在涉及未知域的交叉数据集泛化测试中，Phi-SegNet展示了稳健且优越的表现，突显了其适应能力和跨模态设计。", "conclusion": "这些发现证明了利用谱先验在特征表示和监督中的潜力，为泛化的分割框架提供了一条提高精细对象定位能力的新途径。"}
